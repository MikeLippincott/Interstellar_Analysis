{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Correlate Channels"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This notebook calculates the correlations between channels for this Cell Painting data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import itertools\n",
                "import pathlib\n",
                "import warnings\n",
                "from typing import Tuple\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import scipy.stats\n",
                "import tqdm"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Import data and set paths"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "52\n"
                    ]
                }
            ],
            "source": [
                "output_dir = pathlib.Path(\"../output\").resolve()\n",
                "output_dir.mkdir(exist_ok=True, parents=True)\n",
                "\n",
                "bulk_profile_path = pathlib.Path(\n",
                "    \"../../data/PBMC_preprocess_sc_norm_no_fs_aggregated_nomic.parquet\"\n",
                ").resolve(strict=True)\n",
                "# import jump data\n",
                "jump_data_path = pathlib.Path(\"/home/lippincm/Desktop/18TB/normalized_sc_data\").resolve(\n",
                "    strict=True\n",
                ")\n",
                "# get a list of all the jump data files\n",
                "plates_to_get_channel_correlations_from = list(jump_data_path.glob(\"*agg*.parquet\"))\n",
                "# set up dictionary for each plate's channels\n",
                "plates_dict = {}\n",
                "for plate in plates_to_get_channel_correlations_from:\n",
                "    plates_dict[plate] = {\"channels\": [\"ER\", \"Mito\", \"DNA\", \"AGP\", \"RNA\"]}\n",
                "plates_dict[bulk_profile_path] = {\n",
                "    \"channels\": [\"CorrER\", \"CorrMito\", \"CorrDNA\", \"CorrPM\", \"CorrGasdermin\"]\n",
                "}\n",
                "print(len(plates_dict))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Define class to calculate correlations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "class GetChannelCorrelations:\n",
                "    \"\"\"\n",
                "    Class to get the correlations between channels in a profile dataframe\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    profile_df : pd.DataFrame\n",
                "        profile dataframe of features\n",
                "    channels : list, optional\n",
                "        list of channels to calculate correlations for, by default [\"CorrER\", \"CorrMito\", \"CorrDNA\", \"CorrPM\", \"CorrGasdermin\"]\n",
                "    compartments : list, optional\n",
                "        list of compartments to calculate correlations for, by default [\"Cytoplasm\", \"Nuclei\", \"Cell\"]\n",
                "\n",
                "    Methods\n",
                "    -------\n",
                "    extract_feature_names()\n",
                "        Extract the feature names from the profile dataframe\n",
                "        Returns\n",
                "        -------\n",
                "        Tuple[AssertionError, None]\n",
                "            AssertionError if the length of the feature names is not equal to the length of the compartments, feature types, feature info, and channels\n",
                "    calculate_correlation()\n",
                "        Calculate the correlation between all the channels in the profile dataframe\n",
                "        Returns\n",
                "        -------\n",
                "        None\n",
                "    call_all_class_methods()\n",
                "        Call all class methods and return the correlation dataframe\n",
                "        Returns\n",
                "        -------\n",
                "        pd.DataFrame\n",
                "            correlation dataframe\n",
                "    \"\"\"\n",
                "\n",
                "    def __init__(\n",
                "        self,\n",
                "        profile_df: pd.DataFrame,\n",
                "        channels: list = [\"CorrER\", \"CorrMito\", \"CorrDNA\", \"CorrPM\", \"CorrGasdermin\"],\n",
                "        compartments: list = [\"Cytoplasm\", \"Nuclei\", \"Cell\"],\n",
                "    ) -> None:\n",
                "        \"\"\"\n",
                "        Initialize the class\n",
                "\n",
                "        Parameters\n",
                "        ----------\n",
                "        profile_df : pd.DataFrame\n",
                "            profile dataframe of features\n",
                "        channels : list, optional\n",
                "            list of channels to calculate correlations for, by default [\"CorrER\", \"CorrMito\", \"CorrDNA\", \"CorrPM\", \"CorrGasdermin\"]\n",
                "        compartments : list, optional\n",
                "            list of compartments to calculate correlations for, by default [\"Cytoplasm\", \"Nuclei\", \"Cell\"]\n",
                "\n",
                "        Returns\n",
                "        -------\n",
                "        None\n",
                "        \"\"\"\n",
                "        self.profile_df = profile_df\n",
                "        self.channels = channels\n",
                "        self.compartments = compartments\n",
                "\n",
                "    def extract_feature_names(self) -> Tuple[AssertionError, None]:\n",
                "        \"\"\"\n",
                "        Extract the feature names from the profile dataframe\n",
                "\n",
                "        Returns\n",
                "        -------\n",
                "        Tuple[AssertionError, None]\n",
                "            AssertionError if the length of the feature names is not equal to the length of the compartments, feature types, feature info, and channels\n",
                "        \"\"\"\n",
                "        cols = [col for col in self.profile_df.columns]\n",
                "        dict_feature_names = {\n",
                "            \"feature\": [],\n",
                "            \"compartment\": [],\n",
                "            \"feature_type\": [],\n",
                "            \"feature_info\": [],\n",
                "            \"channel\": [],\n",
                "        }\n",
                "        # iterate through the columns and extract the feature names\n",
                "        for col in cols:\n",
                "            if \"Metadata\" in col:\n",
                "                continue\n",
                "            dict_feature_names[\"feature\"].append(col)\n",
                "            dict_feature_names[\"compartment\"].append(col.split(\"_\")[0])\n",
                "            feature_type = col.split(\"_\")[1]\n",
                "            # do not include correlation features in channel comparisions\n",
                "            if feature_type != \"Correlation\":\n",
                "                dict_feature_names[\"feature_type\"].append(feature_type)\n",
                "                feature_info = col\n",
                "                dict_feature_names[\"feature_info\"].append(feature_info)\n",
                "                for channel in self.channels:\n",
                "                    if channel in feature_info:\n",
                "                        dict_feature_names[\"channel\"].append(channel)\n",
                "                        break\n",
                "                else:\n",
                "                    dict_feature_names[\"channel\"].append(feature_info)\n",
                "\n",
                "            else:\n",
                "                dict_feature_names[\"feature_type\"].append(\"Correlation\")\n",
                "                dict_feature_names[\"channel\"].append(\"Correlation\")\n",
                "                feature_info = \"_\".join(col.split(\"_\")[2:])\n",
                "                dict_feature_names[\"feature_info\"].append(feature_info)\n",
                "\n",
                "        assert (\n",
                "            len(dict_feature_names[\"feature\"])\n",
                "            == len(dict_feature_names[\"compartment\"])\n",
                "            == len(dict_feature_names[\"feature_type\"])\n",
                "            == len(dict_feature_names[\"feature_info\"])\n",
                "            == len(dict_feature_names[\"channel\"])\n",
                "        )\n",
                "        self.extracted_feature_names = pd.DataFrame(dict_feature_names)\n",
                "\n",
                "    def calculate_correlation(self) -> None:\n",
                "        \"\"\"\n",
                "        Calculate the correlation between all the channels in the profile dataframe\n",
                "\n",
                "        Returns\n",
                "        -------\n",
                "        None\n",
                "        \"\"\"\n",
                "        bulk_profile_long = pd.melt(\n",
                "            self.profile_df,\n",
                "            id_vars=[\"Metadata_Well\"],\n",
                "            value_vars=self.profile_df,\n",
                "            var_name=\"feature\",\n",
                "            value_name=\"feature_value\",\n",
                "        )\n",
                "        bulk_profile_long = bulk_profile_long.merge(\n",
                "            self.extracted_feature_names, on=\"feature\"\n",
                "        )\n",
                "        # keep well, feature_value, compartment, feature_type, and channel\n",
                "        # bulk_profile_long = bulk_profile_long[[\"Metadata_Well\", \"feature_value\", \"compartment\", \"channel\"]]\n",
                "        # drop the channels that are not in the channel list\n",
                "        bulk_profile_long = bulk_profile_long[\n",
                "            bulk_profile_long[\"channel\"].isin(self.channels)\n",
                "        ]\n",
                "        dict_of_correlations = {}\n",
                "\n",
                "        index = 0\n",
                "        for channel1, channel2 in itertools.permutations(self.channels, 2):\n",
                "            c1_array = np.array(\n",
                "                bulk_profile_long[bulk_profile_long[\"channel\"] == channel1][\n",
                "                    \"feature_value\"\n",
                "                ]\n",
                "            )\n",
                "            c2_array = np.array(\n",
                "                bulk_profile_long[bulk_profile_long[\"channel\"] == channel2][\n",
                "                    \"feature_value\"\n",
                "                ]\n",
                "            )\n",
                "            corr, p = scipy.stats.pearsonr(c1_array, c2_array)  # corr and p value\n",
                "\n",
                "            # write to dictionary\n",
                "            dict_of_correlations[index] = {\n",
                "                \"channel1\": channel1,\n",
                "                \"channel2\": channel2,\n",
                "                \"correlation\": corr,\n",
                "            }\n",
                "            index += 1\n",
                "        # add self correlations\n",
                "        for channel in self.channels:\n",
                "            dict_of_correlations[index] = {\n",
                "                \"channel1\": channel,\n",
                "                \"channel2\": channel,\n",
                "                \"correlation\": 1.0,\n",
                "            }\n",
                "            index += 1\n",
                "        self.correlation_df = pd.DataFrame(dict_of_correlations).T\n",
                "\n",
                "    def call_all_class_methods(self) -> pd.DataFrame:\n",
                "        \"\"\"\n",
                "        Call all class methods and return the correlation dataframe\n",
                "\n",
                "        Returns\n",
                "        -------\n",
                "        pd.DataFrame\n",
                "            correlation dataframe\n",
                "        \"\"\"\n",
                "        self.extract_feature_names()\n",
                "        self.calculate_correlation()\n",
                "        return self.correlation_df"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Calculate correlations for each plate and save to file"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [03:28<00:00,  1.84it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [03:35<00:00,  1.78it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [03:36<00:00,  1.77it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [03:24<00:00,  1.87it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [03:50<00:00,  1.67it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [03:48<00:00,  1.68it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [03:49<00:00,  1.67it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [03:51<00:00,  1.66it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [03:59<00:00,  1.61it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [03:49<00:00,  1.68it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 301/301 [02:43<00:00,  1.84it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [04:00<00:00,  1.60it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [03:59<00:00,  1.61it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [04:00<00:00,  1.60it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [03:52<00:00,  1.65it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [03:57<00:00,  1.62it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [03:51<00:00,  1.66it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [03:33<00:00,  1.80it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [03:55<00:00,  1.63it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [03:51<00:00,  1.66it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [03:55<00:00,  1.63it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [04:09<00:00,  1.54it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [04:05<00:00,  1.57it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 383/383 [03:31<00:00,  1.81it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [04:01<00:00,  1.59it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [04:00<00:00,  1.59it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [04:08<00:00,  1.55it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [03:51<00:00,  1.66it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [03:50<00:00,  1.67it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [03:57<00:00,  1.62it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [04:06<00:00,  1.56it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [03:54<00:00,  1.64it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [04:14<00:00,  1.51it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 383/383 [03:54<00:00,  1.63it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [04:09<00:00,  1.54it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [03:46<00:00,  1.69it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 383/383 [03:58<00:00,  1.61it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [04:17<00:00,  1.49it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [04:11<00:00,  1.53it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [04:09<00:00,  1.54it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [03:58<00:00,  1.61it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [04:00<00:00,  1.60it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [03:38<00:00,  1.76it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [04:16<00:00,  1.50it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [04:15<00:00,  1.50it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [03:51<00:00,  1.66it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [04:04<00:00,  1.57it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [04:04<00:00,  1.57it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [03:38<00:00,  1.75it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [04:14<00:00,  1.51it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 384/384 [04:09<00:00,  1.54it/s]\n",
                        "Wells: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 154/154 [00:45<00:00,  3.42it/s]\n"
                    ]
                }
            ],
            "source": [
                "# supress future warnings\n",
                "\n",
                "\n",
                "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
                "\n",
                "df_list = []\n",
                "for file in plates_dict:\n",
                "    for well in tqdm.tqdm(\n",
                "        pd.read_parquet(file, columns=[\"Metadata_Well\"])[\"Metadata_Well\"].unique(),\n",
                "        desc=\"Wells\",\n",
                "    ):\n",
                "        get_corr = GetChannelCorrelations(\n",
                "            profile_df=pd.read_parquet(file).loc[\n",
                "                pd.read_parquet(file)[\"Metadata_Well\"] == well\n",
                "            ],\n",
                "            channels=plates_dict[file][\"channels\"],\n",
                "            compartments=[\"Cytoplasm\", \"Nuclei\", \"Cell\"],\n",
                "        )\n",
                "        corr_df = get_corr.call_all_class_methods()\n",
                "        corr_df[\"plate\"] = file.stem\n",
                "        corr_df[\"well\"] = well\n",
                "        df_list.append(corr_df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(491300, 5)\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>channel1</th>\n",
                            "      <th>channel2</th>\n",
                            "      <th>correlation</th>\n",
                            "      <th>plate</th>\n",
                            "      <th>well</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>ER</td>\n",
                            "      <td>Mito</td>\n",
                            "      <td>0.719883</td>\n",
                            "      <td>BR00117004_normalized_sc_agg</td>\n",
                            "      <td>A01</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>ER</td>\n",
                            "      <td>DNA</td>\n",
                            "      <td>0.517936</td>\n",
                            "      <td>BR00117004_normalized_sc_agg</td>\n",
                            "      <td>A01</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>ER</td>\n",
                            "      <td>AGP</td>\n",
                            "      <td>0.91621</td>\n",
                            "      <td>BR00117004_normalized_sc_agg</td>\n",
                            "      <td>A01</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>ER</td>\n",
                            "      <td>RNA</td>\n",
                            "      <td>0.9632</td>\n",
                            "      <td>BR00117004_normalized_sc_agg</td>\n",
                            "      <td>A01</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>Mito</td>\n",
                            "      <td>ER</td>\n",
                            "      <td>0.719883</td>\n",
                            "      <td>BR00117004_normalized_sc_agg</td>\n",
                            "      <td>A01</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "  channel1 channel2 correlation                         plate well\n",
                            "0       ER     Mito    0.719883  BR00117004_normalized_sc_agg  A01\n",
                            "1       ER      DNA    0.517936  BR00117004_normalized_sc_agg  A01\n",
                            "2       ER      AGP     0.91621  BR00117004_normalized_sc_agg  A01\n",
                            "3       ER      RNA      0.9632  BR00117004_normalized_sc_agg  A01\n",
                            "4     Mito       ER    0.719883  BR00117004_normalized_sc_agg  A01"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "all_plate_channel_correlations = pd.concat(df_list)\n",
                "all_plate_channel_correlations.to_parquet(\n",
                "    pathlib.Path(output_dir / \"all_plate_channel_correlations.parquet\"), index=False\n",
                ")\n",
                "print(all_plate_channel_correlations.shape)\n",
                "all_plate_channel_correlations.head()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Interstellar_python",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.15"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
