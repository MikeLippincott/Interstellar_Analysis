{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import logging\n",
    "import pathlib\n",
    "import sys\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import toml\n",
    "from copairs.map import run_pipeline\n",
    "from pycytominer import feature_select\n",
    "\n",
    "# imports src\n",
    "sys.path.append(\"../\")\n",
    "from src import utils\n",
    "\n",
    "# setting up logger\n",
    "logging.basicConfig(\n",
    "    filename=\"map_analysis_testing.log\",\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(levelname)s:%(asctime)s:%(name)s:%(message)s\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "Set of helper functions to help out throughout the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper function\n",
    "\n",
    "\n",
    "def shuffle_meta_labels(\n",
    "    dataset: pd.DataFrame, target_col: str, seed: Optional[int] = 0\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"shuffles labels or values within a single selected column\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : pd.DataFrame\n",
    "        dataframe containing the dataset\n",
    "\n",
    "    target_col : str\n",
    "        Column to select in order to conduct the shuffling\n",
    "\n",
    "    seed : int\n",
    "        setting random seed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        shuffled dataset\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    TypeError\n",
    "        raised if incorrect types are provided\n",
    "    \"\"\"\n",
    "    # setting seed\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # type checking\n",
    "    if not isinstance(target_col, str):\n",
    "        raise TypeError(\"'target_col' must be a string type\")\n",
    "    if not isinstance(dataset, pd.DataFrame):\n",
    "        raise TypeError(\"'dataset' must be a pandas dataframe\")\n",
    "\n",
    "    # selecting column, shuffle values within column, add to dataframe\n",
    "    dataset[target_col] = np.random.permutation(dataset[target_col].values)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def shuffle_features(feature_vals: np.array, seed: Optional[int] = 0) -> np.array:\n",
    "    \"\"\"suffles all values within feature space\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_vals : np.array\n",
    "        shuffled\n",
    "\n",
    "    seed : Optional[int]\n",
    "        setting random seed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        Returns shuffled values within the feature space\n",
    "\n",
    "    Raisespairs(sameby=pos_s\n",
    "    TypeError\n",
    "        Raised if a numpy array is not provided\n",
    "    \"\"\"\n",
    "    # setting seed\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # shuffle given array\n",
    "    if not isinstance(feature_vals, np.ndarray):\n",
    "        raise TypeError(\"'feature_vals' must be a numpy array\")\n",
    "    if feature_vals.ndim != 2:\n",
    "        raise TypeError(\"'feature_vals' must be a 2x2 matrix\")\n",
    "\n",
    "    # creating a copy for feature vales to prevent overwriting of global variables\n",
    "    feature_vals = np.copy(feature_vals)\n",
    "\n",
    "    # shuffling feature space\n",
    "    n_cols = feature_vals.shape[1]\n",
    "    for col_idx in range(0, n_cols):\n",
    "        # selecting column, shuffle, and update:\n",
    "        feature_vals[:, col_idx] = np.random.permutation(feature_vals[:, col_idx])\n",
    "\n",
    "    return feature_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Paths and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the treatment groups\n",
    "ground_truth = pathlib.Path(\n",
    "    \"../../4.sc_Morphology_Neural_Network_MLP_Model/MLP_utils/ground_truth.toml\"\n",
    ").resolve(strict=True)\n",
    "# load in the ground truth\n",
    "ground_truth = toml.load(ground_truth)\n",
    "apoptosis_ground_truth = ground_truth[\"Apoptosis\"][\"apoptosis_groups_list\"]\n",
    "pyroptosis_ground_truth = ground_truth[\"Pyroptosis\"][\"pyroptosis_groups_list\"]\n",
    "control_ground_truth = ground_truth[\"Healthy\"][\"healthy_groups_list\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cell_data = pathlib.Path(\n",
    "    f\"../../data/PBMC_preprocessed_sc_norm_aggregated.parquet\"\n",
    ").resolve(strict=True)\n",
    "df = pd.read_parquet(single_cell_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out paths\n",
    "map_out_dir = pathlib.Path(\"../data/processed/mAP_scores/morphology/\")\n",
    "map_out_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# regular data output\n",
    "# saving to csv\n",
    "regular_feat_map_path = pathlib.Path(map_out_dir / \"mAP_scores_regular_class.csv\")\n",
    "\n",
    "# shuffled data output\n",
    "shuffled_feat_map_path = pathlib.Path(map_out_dir / \"mAP_scores_shuffled_class.csv\")\n",
    "\n",
    "# shuffled feature space output\n",
    "shuffled_feat_space_map_path = pathlib.Path(\n",
    "    map_out_dir / \"mAP_scores_shuffled_feature_space_class.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add apoptosis, pyroptosis and healthy columns to dataframe\n",
    "df[\"Apoptosis\"] = df.apply(\n",
    "    lambda row: row[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"]\n",
    "    in apoptosis_ground_truth,\n",
    "    axis=1,\n",
    ")\n",
    "df[\"Pyroptosis\"] = df.apply(\n",
    "    lambda row: row[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"]\n",
    "    in pyroptosis_ground_truth,\n",
    "    axis=1,\n",
    ")\n",
    "df[\"Control\"] = df.apply(\n",
    "    lambda row: row[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"]\n",
    "    in control_ground_truth,\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# merge apoptosis, pyroptosis, and healthy columns into one column\n",
    "df[\"Metadata_labels\"] = df.apply(\n",
    "    lambda row: \"Apoptosis\"\n",
    "    if row[\"Apoptosis\"]\n",
    "    else \"Pyroptosis\"\n",
    "    if row[\"Pyroptosis\"]\n",
    "    else \"Control\",\n",
    "    axis=1,\n",
    ")\n",
    "# # drop apoptosis, pyroptosis, and healthy columns\n",
    "df.drop(columns=[\"Apoptosis\", \"Pyroptosis\", \"Control\"], inplace=True)\n",
    "df.drop(columns=[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output directories\n",
    "map_out_dir = pathlib.Path(\"../data/processed/mAP_scores/\")\n",
    "map_out_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mAP Pipeline Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null size needs to be determined for the mAP pipeline. This is the size of the null class that is used to determine the mAP score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = (\n",
    "    df.groupby([\"Metadata_labels\"])\n",
    "    .count()\n",
    "    .reset_index()[[\"Metadata_Well\", \"Metadata_labels\"]]\n",
    ")\n",
    "# get the Pyroptosis number of Metadata_Well\n",
    "Pyroptosis_count = tmp[tmp[\"Metadata_labels\"] == \"Pyroptosis\"][\"Metadata_Well\"].values[\n",
    "    0\n",
    "]\n",
    "Pyroptosis_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B09', 'B10',\n",
       "       'B11', 'B12', 'C02', 'C03', 'C04', 'C05', 'C06', 'C07', 'C08',\n",
       "       'C09', 'C10', 'C11', 'C12', 'D02', 'D03', 'D04', 'D05', 'D06',\n",
       "       'D07', 'D08', 'D09', 'D10', 'D11', 'D12', 'E02', 'E03', 'E04',\n",
       "       'E05', 'E06', 'E07', 'E08', 'E09', 'E10', 'E11', 'E12', 'F02',\n",
       "       'F03', 'F04', 'F05', 'F06', 'F07', 'F08', 'F09', 'F10', 'F11',\n",
       "       'F12', 'G02', 'G03', 'G04', 'G05', 'G06', 'G07', 'G08', 'G09',\n",
       "       'G10', 'G11', 'G12', 'H02', 'H03', 'H04', 'H05', 'H06', 'H07',\n",
       "       'H08', 'H09', 'H10', 'H11', 'H12', 'I02', 'I03', 'I04', 'I05',\n",
       "       'I06', 'I07', 'I08', 'I09', 'I10', 'I11', 'I12', 'J02', 'J03',\n",
       "       'J04', 'J05', 'J06', 'J07', 'J08', 'J09', 'J10', 'J11', 'J12',\n",
       "       'K02', 'K03', 'K04', 'K05', 'K06', 'K07', 'K08', 'K09', 'K10',\n",
       "       'K11', 'K12', 'L02', 'L03', 'L04', 'L05', 'L06', 'L07', 'L08',\n",
       "       'L09', 'L10', 'L11', 'L12', 'M02', 'M03', 'M04', 'M05', 'M06',\n",
       "       'M07', 'M08', 'M09', 'M10', 'M11', 'M12', 'N02', 'N03', 'N04',\n",
       "       'N05', 'N06', 'N07', 'N08', 'N09', 'N10', 'N11', 'N12', 'O02',\n",
       "       'O03', 'O04', 'O05', 'O06', 'O07', 'O08', 'O09', 'O10', 'O11',\n",
       "       'O12'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Metadata_Well\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Pyroptosis', 'Control', 'Apoptosis'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Metadata_labels\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sameby = [\n",
    "    \"Metadata_labels\",\n",
    "]\n",
    "pos_diffby = [\"Metadata_Well\"]\n",
    "\n",
    "neg_sameby = []\n",
    "neg_diffby = [\"Metadata_labels\"]\n",
    "\n",
    "null_size = Pyroptosis_count\n",
    "batch_size = 1\n",
    "\n",
    "# number of resampling\n",
    "n_resamples = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mAP analysis for non-shuffled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the permutations of cell death labels via itertools\n",
    "pos_samby_permutations = list(itertools.combinations(df[\"Metadata_labels\"].unique(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Pyroptosis', 'Apoptosis')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_samby_permutations[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"Metadata_Well\",\n",
    "        \"Metadata_labels\",\n",
    "        \"average_precision\",\n",
    "        \"p_value\",\n",
    "        \"n_pos_pairs\",\n",
    "        \"n_total_pairs\",\n",
    "        \"shuffled\",\n",
    "        \"comparison\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f91a797e829d4e08829f51cbe4afaaa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b70f562eca44192852132f3578ef5d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6433 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fafcf9921c844740a216931f4111ea7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22560/362100143.py:39: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, result], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80204757535641d9b96bd28fb38b5f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb9d02d6ad54ab9ae9994ef32e2073b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6433 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a9c1954e484671b4f1253dcca78bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e62e62976641f0bf610d2c27d714c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3618b5af61c1430c88a8cf49a9ed4d37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6433 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9076e954142446c7a41bbb835639a06a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in pos_samby_permutations:\n",
    "    # print(i)\n",
    "    tmp = df.copy()\n",
    "    # get only the rows with the current permutation\n",
    "    tmp = tmp[tmp[\"Metadata_labels\"].isin(i)]\n",
    "    # This will generated 100 values [0..100] as seed values\n",
    "    # This will occur per phenotype\n",
    "\n",
    "    # spliting metadata and raw feature values\n",
    "    logging.info(\"splitting data set into metadata and raw feature values\")\n",
    "    df_meta, df_feats = utils.split_data(df)\n",
    "    df_feats = np.array(df_feats)\n",
    "\n",
    "    # execute pipeline on negative control with training dataset with cp features\n",
    "    try:\n",
    "        # execute pipeline on negative control with trianing dataset with cp features\n",
    "\n",
    "        logging.info(f\"Running pipeline on CP features using phenotype\")\n",
    "        result = run_pipeline(\n",
    "            meta=df_meta,\n",
    "            feats=df_feats,\n",
    "            pos_sameby=pos_sameby,\n",
    "            pos_diffby=pos_diffby,\n",
    "            neg_sameby=neg_sameby,\n",
    "            neg_diffby=neg_diffby,\n",
    "            batch_size=batch_size,\n",
    "            null_size=null_size,\n",
    "        )\n",
    "\n",
    "        # adding columns\n",
    "        result[\"shuffled\"] = \"non-shuffled\"\n",
    "        result[\"comparison\"] = \"_vs_\".join(i)\n",
    "\n",
    "    except ZeroDivisionError as e:\n",
    "        logging.warning(f\"{e} captured on phenotye:. Skipping\")\n",
    "\n",
    "    # concatenating all datasets\n",
    "    results_df = pd.concat([results_df, result], ignore_index=True)\n",
    "    result.to_csv(regular_feat_map_path, index=False)\n",
    "    result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mAP analysis for shuffled data (Feature space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"Metadata_Well\",\n",
    "        \"Metadata_labels\",\n",
    "        \"average_precision\",\n",
    "        \"p_value\",\n",
    "        \"n_pos_pairs\",\n",
    "        \"n_total_pairs\",\n",
    "        \"shuffled\",\n",
    "        \"comparison\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb15a56c3694aedbc52063a2dd7c32a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f1adfdcba354122985599360a9a0e97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6433 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8a7abb0e2e4c788325dd8c0756cfbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22560/1924883967.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, shuffled_feat_map], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de88577ee9b476482a486fba45818f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3df6596aa9432b870166878fadca4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6433 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "941249cd53ef4e1ab91c7e4930eac21d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703ff8f555fa4bcfbf47f258f53a1cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "120bb87874cc4775a017e0eb504e9ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6433 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d50925e2664cdab6a33791f7b2efe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metadata_Well</th>\n",
       "      <th>Metadata_labels</th>\n",
       "      <th>average_precision</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n_pos_pairs</th>\n",
       "      <th>n_total_pairs</th>\n",
       "      <th>shuffled</th>\n",
       "      <th>comparison</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B02</td>\n",
       "      <td>Pyroptosis</td>\n",
       "      <td>0.445783</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>64</td>\n",
       "      <td>153</td>\n",
       "      <td>shuffled_baseline</td>\n",
       "      <td>Pyroptosis_vs_Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B03</td>\n",
       "      <td>Pyroptosis</td>\n",
       "      <td>0.392328</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>64</td>\n",
       "      <td>153</td>\n",
       "      <td>shuffled_baseline</td>\n",
       "      <td>Pyroptosis_vs_Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B04</td>\n",
       "      <td>Pyroptosis</td>\n",
       "      <td>0.393081</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>64</td>\n",
       "      <td>153</td>\n",
       "      <td>shuffled_baseline</td>\n",
       "      <td>Pyroptosis_vs_Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B05</td>\n",
       "      <td>Pyroptosis</td>\n",
       "      <td>0.419327</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>64</td>\n",
       "      <td>153</td>\n",
       "      <td>shuffled_baseline</td>\n",
       "      <td>Pyroptosis_vs_Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B06</td>\n",
       "      <td>Control</td>\n",
       "      <td>0.519952</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>80</td>\n",
       "      <td>153</td>\n",
       "      <td>shuffled_baseline</td>\n",
       "      <td>Pyroptosis_vs_Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>O08</td>\n",
       "      <td>Control</td>\n",
       "      <td>0.522033</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>80</td>\n",
       "      <td>153</td>\n",
       "      <td>shuffled_baseline</td>\n",
       "      <td>Control_vs_Apoptosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>O09</td>\n",
       "      <td>Control</td>\n",
       "      <td>0.532334</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>80</td>\n",
       "      <td>153</td>\n",
       "      <td>shuffled_baseline</td>\n",
       "      <td>Control_vs_Apoptosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>O10</td>\n",
       "      <td>Control</td>\n",
       "      <td>0.516417</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>80</td>\n",
       "      <td>153</td>\n",
       "      <td>shuffled_baseline</td>\n",
       "      <td>Control_vs_Apoptosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>O11</td>\n",
       "      <td>Control</td>\n",
       "      <td>0.540210</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>80</td>\n",
       "      <td>153</td>\n",
       "      <td>shuffled_baseline</td>\n",
       "      <td>Control_vs_Apoptosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>O12</td>\n",
       "      <td>Control</td>\n",
       "      <td>0.546963</td>\n",
       "      <td>0.348485</td>\n",
       "      <td>80</td>\n",
       "      <td>153</td>\n",
       "      <td>shuffled_baseline</td>\n",
       "      <td>Control_vs_Apoptosis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>462 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Metadata_Well Metadata_labels  average_precision   p_value n_pos_pairs  \\\n",
       "0             B02      Pyroptosis           0.445783  0.393939          64   \n",
       "1             B03      Pyroptosis           0.392328  0.848485          64   \n",
       "2             B04      Pyroptosis           0.393081  0.848485          64   \n",
       "3             B05      Pyroptosis           0.419327  0.636364          64   \n",
       "4             B06         Control           0.519952  0.666667          80   \n",
       "..            ...             ...                ...       ...         ...   \n",
       "457           O08         Control           0.522033  0.636364          80   \n",
       "458           O09         Control           0.532334  0.606061          80   \n",
       "459           O10         Control           0.516417  0.696970          80   \n",
       "460           O11         Control           0.540210  0.484848          80   \n",
       "461           O12         Control           0.546963  0.348485          80   \n",
       "\n",
       "    n_total_pairs           shuffled             comparison  \n",
       "0             153  shuffled_baseline  Pyroptosis_vs_Control  \n",
       "1             153  shuffled_baseline  Pyroptosis_vs_Control  \n",
       "2             153  shuffled_baseline  Pyroptosis_vs_Control  \n",
       "3             153  shuffled_baseline  Pyroptosis_vs_Control  \n",
       "4             153  shuffled_baseline  Pyroptosis_vs_Control  \n",
       "..            ...                ...                    ...  \n",
       "457           153  shuffled_baseline   Control_vs_Apoptosis  \n",
       "458           153  shuffled_baseline   Control_vs_Apoptosis  \n",
       "459           153  shuffled_baseline   Control_vs_Apoptosis  \n",
       "460           153  shuffled_baseline   Control_vs_Apoptosis  \n",
       "461           153  shuffled_baseline   Control_vs_Apoptosis  \n",
       "\n",
       "[462 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in pos_samby_permutations:\n",
    "    # print(i)\n",
    "    tmp = df.copy()\n",
    "    # get only the rows with the current permutation\n",
    "    tmp = tmp[tmp[\"Metadata_labels\"].isin(i)]\n",
    "    # This will generated 100 values [0..100] as seed values\n",
    "    # This will occur per phenotype\n",
    "\n",
    "    # spliting metadata and raw feature values\n",
    "    seed = 0\n",
    "\n",
    "    # split the shuffled dataset\n",
    "    # spliting metadata and raw feature values\n",
    "    logging.info(\"splitting shuffled data set into metadata and raw feature values\")\n",
    "    (\n",
    "        df_meta,\n",
    "        df_feats,\n",
    "    ) = utils.split_data(df)\n",
    "\n",
    "    df_feats = np.array(df_feats)\n",
    "\n",
    "    # shuffling the features, this will overwrite the generated feature space from above with the shuffled one\n",
    "    df_feats = shuffle_features(feature_vals=df_feats, seed=seed)\n",
    "\n",
    "    try:\n",
    "        # execute pipeline on negative control with trianing dataset with cp features\n",
    "        logging.info(\n",
    "            f\"Running pipeline on CP features using phenotype, feature space is shuffled\"\n",
    "        )\n",
    "        shuffled_feat_map = run_pipeline(\n",
    "            meta=df_meta,\n",
    "            feats=df_feats,\n",
    "            pos_sameby=pos_sameby,\n",
    "            pos_diffby=pos_diffby,\n",
    "            neg_sameby=neg_sameby,\n",
    "            neg_diffby=neg_diffby,\n",
    "            batch_size=batch_size,\n",
    "            null_size=null_size,\n",
    "        )\n",
    "\n",
    "        # adding shuffle label column\n",
    "        shuffled_feat_map[\"shuffled\"] = \"shuffled_baseline\"\n",
    "        shuffled_feat_map[\"comparison\"] = \"_vs_\".join(i)\n",
    "\n",
    "    except ZeroDivisionError as e:\n",
    "        logging.warning(f\"{e} captured on phenotype:  Skipping\")\n",
    "\n",
    "    # concatenating all datasets\n",
    "    results_df = pd.concat([results_df, shuffled_feat_map], ignore_index=True)\n",
    "    # saving to csv\n",
    "    results_df.to_csv(shuffled_feat_space_map_path, index=False)\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "map",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
