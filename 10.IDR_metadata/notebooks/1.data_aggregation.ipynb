{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "cb7abef8",
            "metadata": {
                "tags": [
                    "papermill-error-cell-tag"
                ]
            },
            "source": [
                "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [4]</a>'.</span>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "67de461b",
            "metadata": {
                "papermill": {
                    "duration": 0.003139,
                    "end_time": "2024-03-04T19:14:57.200882",
                    "exception": false,
                    "start_time": "2024-03-04T19:14:57.197743",
                    "status": "completed"
                },
                "tags": []
            },
            "source": [
                "This noteboook aggregates the data from the previous notebooks and creates the final dataset for the analysis barring the data are aggregated in the analysis."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "3ebfd6b0",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2024-03-04T19:14:57.206346Z",
                    "iopub.status.busy": "2024-03-04T19:14:57.205887Z",
                    "iopub.status.idle": "2024-03-04T19:14:57.790609Z",
                    "shell.execute_reply": "2024-03-04T19:14:57.790079Z"
                },
                "papermill": {
                    "duration": 0.588142,
                    "end_time": "2024-03-04T19:14:57.791732",
                    "exception": false,
                    "start_time": "2024-03-04T19:14:57.203590",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "import pathlib\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "aba8553e",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2024-03-04T19:14:57.796357Z",
                    "iopub.status.busy": "2024-03-04T19:14:57.795731Z",
                    "iopub.status.idle": "2024-03-04T19:14:57.798465Z",
                    "shell.execute_reply": "2024-03-04T19:14:57.798092Z"
                },
                "papermill": {
                    "duration": 0.005975,
                    "end_time": "2024-03-04T19:14:57.799371",
                    "exception": false,
                    "start_time": "2024-03-04T19:14:57.793396",
                    "status": "completed"
                },
                "tags": [
                    "injected-parameters"
                ]
            },
            "outputs": [],
            "source": [
                "# Parameters\n",
                "cell_type = \"PBMC\"\n",
                "aggregation = True\n",
                "nomic = True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "41eb9cfd",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2024-03-04T19:14:57.803438Z",
                    "iopub.status.busy": "2024-03-04T19:14:57.803030Z",
                    "iopub.status.idle": "2024-03-04T19:14:57.806143Z",
                    "shell.execute_reply": "2024-03-04T19:14:57.805764Z"
                },
                "papermill": {
                    "duration": 0.0062,
                    "end_time": "2024-03-04T19:14:57.807069",
                    "exception": false,
                    "start_time": "2024-03-04T19:14:57.800869",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "if aggregation and nomic:\n",
                "    aggregated_data_path = pathlib.Path(\n",
                "        f\"../data/{cell_type}_preprocess_sc_norm_no_fs_aggregated_nomic.parquet\"\n",
                "    )\n",
                "elif not aggregation and nomic:\n",
                "    aggregated_data_path = pathlib.Path(\n",
                "        f\"../data/{cell_type}_preprocess_sc_norm_no_fs_nomic.parquet\"\n",
                "    )\n",
                "elif aggregation and not nomic:\n",
                "    aggregated_data_path = pathlib.Path(\n",
                "        f\"../data/{cell_type}_preprocess_sc_norm_no_fs_aggregated.parquet\"\n",
                "    )\n",
                "elif not aggregation and not nomic:\n",
                "    pass\n",
                "else:\n",
                "    raise ValueError(\"Wrong parameters\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d65cd3d9",
            "metadata": {
                "tags": [
                    "papermill-error-cell-tag"
                ]
            },
            "source": [
                "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "ba5278c5",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2024-03-04T19:14:57.811257Z",
                    "iopub.status.busy": "2024-03-04T19:14:57.810782Z",
                    "iopub.status.idle": "2024-03-04T19:14:58.186239Z",
                    "shell.execute_reply": "2024-03-04T19:14:58.185676Z"
                },
                "papermill": {
                    "duration": 0.378394,
                    "end_time": "2024-03-04T19:14:58.187019",
                    "exception": true,
                    "start_time": "2024-03-04T19:14:57.808625",
                    "status": "failed"
                },
                "tags": []
            },
            "outputs": [
                {
                    "ename": "FileNotFoundError",
                    "evalue": "[Errno 2] No such file or directory: '../data/PBMC_preprocess_sc_norm_no_fs.parquet'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcell_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_preprocess_sc_norm_no_fs.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m data_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m data_df\u001b[38;5;241m.\u001b[39mhead()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nomic:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# import nomic data\u001b[39;00m\n",
                        "File \u001b[0;32m/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/pandas/io/parquet.py:670\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    667\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    668\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 670\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/pandas/io/parquet.py:265\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    263\u001b[0m     to_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_blocks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    272\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[1;32m    273\u001b[0m         path_or_handle,\n\u001b[1;32m    274\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    278\u001b[0m     )\n",
                        "File \u001b[0;32m/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/pandas/io/parquet.py:139\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    129\u001b[0m handles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m     handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     path_or_handle \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
                        "File \u001b[0;32m/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/pandas/io/common.py:872\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    873\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
                        "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/PBMC_preprocess_sc_norm_no_fs.parquet'"
                    ]
                }
            ],
            "source": [
                "path = pathlib.Path(f\"../data/{cell_type}_preprocess_sc_norm_no_fs.parquet\")\n",
                "\n",
                "data_df = pd.read_parquet(path)\n",
                "\n",
                "data_df.head()\n",
                "\n",
                "if nomic:\n",
                "    # import nomic data\n",
                "    nomic_df_path = pathlib.Path(\n",
                "        f\"../2.Nomic_nELISA_Analysis/Data/clean/Plate2/nELISA_plate_430420_{cell_type}_clean.parquet\"\n",
                "    )\n",
                "    df_nomic = pd.read_parquet(nomic_df_path)\n",
                "\n",
                "    # drop columns that contain [pgML]\n",
                "    df_nomic = df_nomic.drop(\n",
                "        columns=[col for col in df_nomic.columns if \"[pgML]\" in col]\n",
                "    )\n",
                "    # drop first 25 columns (metadata that does not contain metadata in the title)\n",
                "    df_nomic = df_nomic.drop(columns=df_nomic.columns[3:25])\n",
                "    df_nomic = df_nomic.drop(columns=df_nomic.columns[0:2])\n",
                "elif not nomic:\n",
                "    pass\n",
                "else:\n",
                "    raise ValueError(\"Nomic data not imported\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "073ab83f",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-10-29T21:54:51.581836Z",
                    "iopub.status.busy": "2023-10-29T21:54:51.581584Z",
                    "iopub.status.idle": "2023-10-29T21:54:53.002244Z",
                    "shell.execute_reply": "2023-10-29T21:54:53.001727Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "pending"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# subset each column that contains metadata\n",
                "metadata = data_df.filter(regex=\"Metadata\")\n",
                "\n",
                "# get all columns that are not metadata except for metadata_Well\n",
                "data = data_df.drop(metadata.columns, axis=1)\n",
                "\n",
                "# get the metadata_Well column\n",
                "metadata_well = metadata[\n",
                "    [\"Metadata_Well\", \"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"]\n",
                "]\n",
                "\n",
                "data_df = pd.merge(data, metadata_well, left_index=True, right_index=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d3712b16",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-10-29T21:54:53.011003Z",
                    "iopub.status.busy": "2023-10-29T21:54:53.010370Z",
                    "iopub.status.idle": "2023-10-29T21:54:53.014319Z",
                    "shell.execute_reply": "2023-10-29T21:54:53.013832Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "pending"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "if nomic:\n",
                "    df_nomic.drop(\n",
                "        columns=[\n",
                "            \"Treatment\",\n",
                "            \"Dose\",\n",
                "            \"twob_Treatment_Dose_Inhibitor_Dose\",\n",
                "            \"threeb_Treatment_Dose_Inhibitor_Dose\",\n",
                "            \"fourb_Treatment_Dose_Inhibitor_Dose\",\n",
                "        ],\n",
                "        inplace=True,\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "510c7356",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-10-29T21:54:53.019750Z",
                    "iopub.status.busy": "2023-10-29T21:54:53.019305Z",
                    "iopub.status.idle": "2023-10-29T21:54:56.083208Z",
                    "shell.execute_reply": "2023-10-29T21:54:56.082599Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "pending"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "if aggregation and nomic:\n",
                "\n",
                "    # subset each column that contains metadata\n",
                "    metadata = data_df.filter(regex=\"Metadata\")\n",
                "    data_df = data_df.drop(metadata.columns, axis=1)\n",
                "    data_df = pd.concat([data_df, metadata[\"Metadata_Well\"]], axis=1)\n",
                "    # groupby well and take mean of each well\n",
                "    data_df = data_df.groupby(\"Metadata_Well\").mean()\n",
                "    # drop duplicate rows in the metadata_well column\n",
                "    metadata = metadata.drop_duplicates(subset=[\"Metadata_Well\"])\n",
                "    # get the metadata for each well\n",
                "    data_df = pd.merge(\n",
                "        data_df, metadata, left_on=\"Metadata_Well\", right_on=\"Metadata_Well\"\n",
                "    )\n",
                "    data_df = pd.merge(\n",
                "        data_df,\n",
                "        df_nomic,\n",
                "        left_on=[\"Metadata_Well\", \"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"],\n",
                "        right_on=[\"position_x\", \"oneb_Treatment_Dose_Inhibitor_Dose\"],\n",
                "    )\n",
                "    data_df = data_df.drop(columns=[\"position_x\"])\n",
                "    # drop all metadata columns\n",
                "    labeled_data = data_df[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"]\n",
                "    data_x = data_df.drop(metadata.columns, axis=1)\n",
                "    # set path to save the data\n",
                "    aggregated_data_path = pathlib.Path(\n",
                "        f\"../data/{cell_type}_preprocessed_sc_norm_aggregated_nomic.parquet\"\n",
                "    )\n",
                "\n",
                "\n",
                "elif aggregation and not nomic:\n",
                "    # get metadata columns\n",
                "    metadata = data_df.filter(regex=\"Metadata\")\n",
                "    data_df = data_df.drop(metadata.columns, axis=1)\n",
                "    metadata\n",
                "    data_df = pd.concat([data_df, metadata], axis=1)\n",
                "    # groupby well and take mean of each well\n",
                "    data_df = data_df.groupby(\n",
                "        [\"Metadata_Well\", \"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"]\n",
                "    ).mean()\n",
                "    # # drop duplicate rows in the metadata_well column\n",
                "    metadata = metadata.drop_duplicates(subset=[\"Metadata_Well\"])\n",
                "    # # get the metadata for each well\n",
                "    # # set path to save the data\n",
                "    aggregated_data_path = pathlib.Path(\n",
                "        f\"../data/{cell_type}_preprocessed_sc_norm_aggregated.parquet\"\n",
                "    )\n",
                "    # reset the index\n",
                "    data_df = data_df.reset_index()\n",
                "\n",
                "elif not aggregation and nomic:\n",
                "    data_df = pd.merge(\n",
                "        data_df,\n",
                "        df_nomic,\n",
                "        left_on=[\"Metadata_Well\", \"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"],\n",
                "        right_on=[\"position_x\", \"oneb_Treatment_Dose_Inhibitor_Dose\"],\n",
                "    )\n",
                "    data_df = data_df.drop(columns=[\"position_x\"])\n",
                "    # set path to save the data\n",
                "    aggregated_data_path = pathlib.Path(\n",
                "        f\"../data/{cell_type}_preprocessed_sc_norm_with_nomic.parquet\"\n",
                "    )\n",
                "elif aggregation == False and nomic == False:\n",
                "    pass\n",
                "else:\n",
                "    raise ValueError(\"Wrong parameters nomica and/or aggregation not defined\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8977efc6",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-10-29T21:54:56.090427Z",
                    "iopub.status.busy": "2023-10-29T21:54:56.089957Z",
                    "iopub.status.idle": "2023-10-29T21:55:13.191602Z",
                    "shell.execute_reply": "2023-10-29T21:55:13.191085Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "pending"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# save the data\n",
                "data_df.to_parquet(aggregated_data_path)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Interstellar",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.13"
        },
        "papermill": {
            "default_parameters": {},
            "duration": 2.829835,
            "end_time": "2024-03-04T19:14:58.405414",
            "environment_variables": {},
            "exception": true,
            "input_path": "1.data_aggregation.ipynb",
            "output_path": "1.data_aggregation.ipynb",
            "parameters": {
                "aggregation": true,
                "cell_type": "PBMC",
                "nomic": true
            },
            "start_time": "2024-03-04T19:14:55.575579",
            "version": "2.4.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
