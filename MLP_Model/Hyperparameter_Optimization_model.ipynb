{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e60628c",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning via Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fac71a5",
   "metadata": {},
   "source": [
    "### Being a binary model this notebook will be limited to predicting one class 1 or 0, yes or no.\n",
    "### Here I will be predicting if a cell received a treatment or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "860a61dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import seaborn as sns\n",
    "import toml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from MLP_utils.parameters import Parameters\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from MLP_utils.utils import (\n",
    "    Dataset_formatter,\n",
    "    data_split,\n",
    "    extract_best_trial_params,\n",
    "    objective_model_optimizer,\n",
    "    optimized_model_create,\n",
    "    plot_metric_vs_epoch,\n",
    "    results_output,\n",
    "    test_optimized_model,\n",
    "    train_optimized_model,\n",
    "    un_nest,\n",
    ")\n",
    "\n",
    "from utils.utils import df_stats\n",
    "from MLP_utils.utils import parameter_set\n",
    "from configparser import ConfigParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44baa945",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Import Data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# set data file path under pathlib path for multi-system use\u001b[39;00m\n\u001b[1;32m      3\u001b[0m file_path \u001b[39m=\u001b[39m Path(\n\u001b[1;32m      4\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m../../Extracted_Features_(CSV_files)/interstellar_wave3_sc_norm_fs_cellprofiler.csv.gz\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 6\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\n\u001b[1;32m      7\u001b[0m     file_path,\n\u001b[1;32m      8\u001b[0m     low_memory\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m      9\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/Interstellar/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/Interstellar/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/Interstellar/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/miniconda3/envs/Interstellar/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[1;32m    610\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[0;32m--> 611\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[0;32m~/miniconda3/envs/Interstellar/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1771\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[1;32m   1772\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1773\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m     (\n\u001b[1;32m   1775\u001b[0m         index,\n\u001b[1;32m   1776\u001b[0m         columns,\n\u001b[1;32m   1777\u001b[0m         col_dict,\n\u001b[0;32m-> 1778\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1779\u001b[0m         nrows\n\u001b[1;32m   1780\u001b[0m     )\n\u001b[1;32m   1781\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1782\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/Interstellar/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:235\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n\u001b[1;32m    234\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 235\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread(nrows)\n\u001b[1;32m    236\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    237\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_first_chunk:\n",
      "File \u001b[0;32m~/miniconda3/envs/Interstellar/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:790\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/Interstellar/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:890\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/Interstellar/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1037\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/Interstellar/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1083\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/Interstellar/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1158\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/Interstellar/lib/python3.10/site-packages/pandas/core/dtypes/common.py:1433\u001b[0m, in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[39m# Note: if other EA dtypes are ever held in HybridBlock, exclude those\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m     \u001b[39m#  here too.\u001b[39;00m\n\u001b[1;32m   1426\u001b[0m     \u001b[39m# NB: need to check DatetimeTZDtype and not is_datetime64tz_dtype\u001b[39;00m\n\u001b[1;32m   1427\u001b[0m     \u001b[39m#  to exclude ArrowTimestampUSDtype\u001b[39;00m\n\u001b[1;32m   1428\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, ExtensionDtype) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m   1429\u001b[0m         dtype, (DatetimeTZDtype, PeriodDtype)\n\u001b[1;32m   1430\u001b[0m     )\n\u001b[0;32m-> 1433\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_extension_array_dtype\u001b[39m(arr_or_dtype) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m   1434\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1435\u001b[0m \u001b[39m    Check if an object is a pandas extension array type.\u001b[39;00m\n\u001b[1;32m   1436\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[39m    False\u001b[39;00m\n\u001b[1;32m   1477\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1478\u001b[0m     dtype \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(arr_or_dtype, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, arr_or_dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Import Data\n",
    "# set data file path under pathlib path for multi-system use\n",
    "file_path = Path(\n",
    "    \"../../Extracted_Features_(CSV_files)/interstellar_wave3_sc_norm_fs_cellprofiler.csv.gz\"\n",
    ")\n",
    "df = pd.read_csv(\n",
    "    file_path,\n",
    "    low_memory=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394294ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Path(\"MLP_utils/config.toml\")\n",
    "config = toml.load(data)\n",
    "params = Parameters()\n",
    "params = parameter_set(params, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786e3a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine treatment with dosage to be able to discern treatments with different doses as a different condition\n",
    "# Combine treatment and dose\n",
    "df = df.assign(\n",
    "    Metadata_Treatment_and_Dose=lambda x: df[\"Metadata_treatment\"]\n",
    "    + \"_\"\n",
    "    + df[\"Metadata_dose\"]\n",
    ")\n",
    "\n",
    "# df[\"Metadata_treatment\"] = df[\"Metadata_treatment\"] + \"_\" + df[\"Metadata_dose\"]\n",
    "print(df[\"Metadata_Treatment_and_Dose\"].unique())\n",
    "\n",
    "# Generate df speceific to analysis and model\n",
    "# df = df.query(\n",
    "#     \"Metadata_Treatment_and_Dose == 'LPS_10µg/ml'| Metadata_Treatment_and_Dose == 'Media only_0' | Metadata_Treatment_and_Dose == 'Disulfiram_2.5µM'\"\n",
    "# )\n",
    "df = df.query(\n",
    "    \"Metadata_Treatment_and_Dose == 'LPS_10µg/ml'| Metadata_Treatment_and_Dose == 'Media only_0'\"\n",
    ")\n",
    "print(df[\"Metadata_Treatment_and_Dose\"].unique())\n",
    "\n",
    "df_stats(df)\n",
    "# Drop na and reindex accordingly\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Check for Nans again\n",
    "df_stats(df)\n",
    "# Understand categorical data such as treatment and dosing\n",
    "df[[\"Metadata_Treatment_and_Dose\"]].drop_duplicates()\n",
    "print(params.DATA_SUBSET_OPTION)\n",
    "print(params.DATA_SUBSET_NUMBER)\n",
    "if params.DATA_SUBSET_OPTION == True:\n",
    "    df = df.sample(n=params.DATA_SUBSET_NUMBER)\n",
    "    print(\"yes\")\n",
    "else:\n",
    "    pass\n",
    "\n",
    "# Code snippet for metadata extraction by Jenna Tomkinson\n",
    "df_metadata = list(df.columns[df.columns.str.startswith(\"Metadata\")])\n",
    "\n",
    "# define which columns are data and which are descriptive\n",
    "df_descriptive = df[df_metadata]\n",
    "df_values = df.drop(columns=df_metadata)\n",
    "print(len(df_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca90059d",
   "metadata": {},
   "source": [
    " ### Setting up data for network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4feb87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating label encoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "# Converting strings into numbers\n",
    "df_values[\"Metadata_Treatment_and_Dose\"] = le.fit_transform(\n",
    "    df_descriptive[\"Metadata_Treatment_and_Dose\"]\n",
    ")\n",
    "# split into X and Y where Y are the predictive column and x are the observable data\n",
    "df_values_X = df_values.drop(\"Metadata_Treatment_and_Dose\", axis=1)\n",
    "df_values_Y = df_values[\"Metadata_Treatment_and_Dose\"]\n",
    "\n",
    "df_values_X.head()\n",
    "\n",
    "X_train, X_test, X_val, Y_train, Y_test, Y_val = data_split(\n",
    "    X_vals=df_values_X,\n",
    "    y_vals=df_values_Y,\n",
    "    train_proportion=0.8,\n",
    "    val_proportion=0.1,\n",
    "    test_proportion=0.1,\n",
    "    seed=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36894826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce data objects for train, val and test datasets\n",
    "train_data = Dataset_formatter(\n",
    "    torch.FloatTensor(X_train.values), torch.FloatTensor(Y_train.values)\n",
    ")\n",
    "val_data = Dataset_formatter(\n",
    "    torch.FloatTensor(X_val.values), torch.FloatTensor(Y_val.values)\n",
    ")\n",
    "test_data = Dataset_formatter(\n",
    "    torch.FloatTensor(X_test.values), torch.FloatTensor(Y_test.values)\n",
    ")\n",
    "\n",
    "params.IN_FEATURES = X_train.shape[1]\n",
    "print(\"Number of in features: \", params.IN_FEATURES)\n",
    "params.OUT_FEATURES = len(df_values[\"Metadata_Treatment_and_Dose\"].unique())\n",
    "print(\"Number of out features: \", params.OUT_FEATURES)\n",
    "\n",
    "if params.OUT_FEATURES > 2:\n",
    "    params.MODEL_TYPE = \"Multi_Class\"\n",
    "elif params.OUT_FEATURES <= 2:\n",
    "    params.OUT_FEATURES = params.OUT_FEATURES - 1\n",
    "    params.MODEL_TYPE = \"Binary_Classification\"\n",
    "else:\n",
    "    pass\n",
    "print(params.MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77effa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data class into a dataloader to be compatible with pytorch\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_data, batch_size=params.BATCH_SIZE\n",
    ")\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    dataset=val_data, batch_size=params.BATCH_SIZE\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a969042f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap the objective function inside of a lambda function to pass args...\n",
    "objective_lambda_func = lambda trial: objective_model_optimizer(\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    trial=trial,\n",
    "    params=params,\n",
    "    metric=params.METRIC,\n",
    "    return_info=False,\n",
    ")\n",
    "# Study is the object for model optimization\n",
    "study = optuna.create_study(direction=f\"{params.DIRECTION}\")\n",
    "# Here I apply the optimize function of the study to the objective function\n",
    "# This optimizes each parameter specified to be optimized from the defined search space\n",
    "study.optimize(objective_lambda_func, n_trials=params.N_TRIALS)\n",
    "# Prints out the best trial's optimized parameters\n",
    "objective_model_optimizer(\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    trial=study.best_trial,\n",
    "    params=params,\n",
    "    metric=params.METRIC,\n",
    "    return_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2620589",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92103de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_intermediate_values(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325a1ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call function for best trial parameter extraction\n",
    "param_dict = extract_best_trial_params(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e946e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the optimized training model\n",
    "train_loss, train_acc, valid_loss, valid_acc, epochs_ran, model = train_optimized_model(\n",
    "    params.TRAIN_EPOCHS,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    param_dict,\n",
    "    params,\n",
    ")\n",
    "# create a DataFrame of each stat\n",
    "training_stats = pd.DataFrame(\n",
    "    zip(train_loss, train_acc, valid_loss, valid_acc, epochs_ran),\n",
    "    columns=[\"train_loss\", \"train_acc\", \"valid_loss\", \"valid_acc\", \"epochs_ran\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1340d8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_vs_epoch(\n",
    "    training_stats,\n",
    "    x=\"epochs_ran\",\n",
    "    y1=\"train_acc\",\n",
    "    y2=\"valid_acc\",\n",
    "    title=\"Accuracy vs. Epochs\",\n",
    "    x_axis_label=\"Epochs\",\n",
    "    y_axis_label=\"Accuracy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41991221",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_vs_epoch(\n",
    "    training_stats,\n",
    "    x=\"epochs_ran\",\n",
    "    y1=\"train_loss\",\n",
    "    y2=\"valid_loss\",\n",
    "    title=\"Loss vs. Epochs\",\n",
    "    x_axis_label=\"Epochs\",\n",
    "    y_axis_label=\"Loss\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2c848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the testing function and outputing list values of tested model\n",
    "if params.MODEL_TYPE == \"Multi_Class\":\n",
    "    y_pred_list = test_optimized_model(model, test_loader, param_dict, params)\n",
    "elif params.MODEL_TYPE == \"Binary_Classification\":\n",
    "    y_pred_list, y_pred_prob_list = test_optimized_model(model, test_loader, params)\n",
    "else:\n",
    "    raise Exception(\"Model type must be specified for proper model testing\")\n",
    "\n",
    "\n",
    "# un-nest list if nested i.e. length of input data does not match length of output data\n",
    "if len(y_pred_list) != len(Y_test):\n",
    "    y_pred_list = un_nest(y_pred_list)\n",
    "    y_pred_prob_list = un_nest(y_pred_prob_list)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c53f7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call visualization function\n",
    "# calling the testing function and outputing list values of tested model\n",
    "if params.MODEL_TYPE == \"Multi_Class\":\n",
    "    results_output(y_pred_list, Y_test)\n",
    "elif params.MODEL_TYPE == \"Binary_Classification\":\n",
    "    results_output(y_pred_list, Y_test, y_pred_prob_list)\n",
    "else:\n",
    "    raise Exception(\"Model type must be specified for proper model testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04345ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "formats": "ipynb,py",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "72ae02083a9ca7d143c492d1aec380c7bf553ec51bd66e90e72bba65228121b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
