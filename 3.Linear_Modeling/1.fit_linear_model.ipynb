{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import plotly.express as px\n",
    "from pycytominer.cyto_utils import infer_cp_features\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pdfkit\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# import Union\n",
    "from typing import Union\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "# from ..utils.utils import df_stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"mode.chained_assignment\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define inputs\n",
    "feature_file = pathlib.Path(\n",
    "    \"../../Extracted_Features_(CSV_files)/feature_df_sc_norm.parquet\"\n",
    ")\n",
    "feature_df = pq.read_table(feature_file).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define output file path\n",
    "one_beta_output_file_path = pathlib.Path(\"./results/lm_one_beta.tsv\")\n",
    "two_beta_output_file_path = pathlib.Path(\"./results/lm_two_beta.tsv\")\n",
    "three_beta_output_file_path = pathlib.Path(\"./results/lm_three_beta.tsv\")\n",
    "four_beta_output_file_path = pathlib.Path(\"./results/lm_four_beta.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are testing 2907 CellProfiler features\n",
      "The unique Treatment-Dosages are: media ctr_0_Media ctr_0.0, \n",
      "DMSO_0.100_DMSO_1.0, \n",
      "DMSO_0.100_Z-VAD-FMK_100.0, \n",
      "DMSO_0.100_Z-VAD-FMK_30.0, \n",
      "DMSO_0.100_DMSO_0.025, \n",
      "Thapsigargin_1.000_DMSO_0.025, \n",
      "Thapsigargin_10.000_DMSO_0.025, \n",
      "Topotecan_5.000_DMSO_0.025, \n",
      "Topotecan_10.000_DMSO_0.025, \n",
      "Topotecan_20.000_DMSO_0.025, \n",
      "LPS_0.010_DMSO_0.025, \n",
      "LPS_0.100_DMSO_0.025, \n",
      "LPS_1.000_DMSO_0.025, \n",
      "LPS_10.000_DMSO_0.025, \n",
      "LPS_10.000_Disulfiram_0.1, \n",
      "LPS_10.000_Disulfiram_1.0, \n",
      "LPS_10.000_Disulfiram_2.5, \n",
      "LPS_Nigericin_100.000_1.0_DMSO_0.025, \n",
      "LPS_Nigericin_100.000_3.0_DMSO_0.025, \n",
      "LPS_Nigericin_100.000_10.0_DMSO_0.025, \n",
      "Disulfiram_0.100_DMSO_0.025, \n",
      "Disulfiram_1.000_DMSO_0.025, \n",
      "Disulfiram_2.500_DMSO_0.025, \n",
      "H2O2_100.000_DMSO_0.025, \n",
      "LPS_10.000_Z-VAD-FMK_100.0, \n",
      "LPS_100.000_DMSO_0.025, \n",
      "LPS_Nigericin_1.000_1.0_DMSO_0.025, \n",
      "LPS_Nigericin_1.000_3.0_DMSO_0.025, \n",
      "LPS_Nigericin_1.000_10.0_DMSO_0.025, \n",
      "LPS_Nigericin_1.000_10.0_Disulfiram_1.0, \n",
      "LPS_Nigericin_1.000_10.0_Z-VAD-FMK_100.0, \n",
      "H2O2_100.000_Disulfiram_1.0, \n",
      "H2O2_100.000_Z-VAD-FMK_100.0, \n",
      "Flagellin_0.100_DMSO_0.025, \n",
      "Flagellin_1.000_DMSO_0.025, \n",
      "Flagellin_1.000_Disulfiram_1.0\n"
     ]
    }
   ],
   "source": [
    "cp_features = infer_cp_features(feature_df)\n",
    "print(f\"We are testing {len(cp_features)} CellProfiler features\")\n",
    "\n",
    "new_line = \"\\n\"\n",
    "print(\n",
    "    f\"The unique Treatment-Dosages are: {f', {new_line}'.join((feature_df['oneb_Metadata_Treatment_Dose_Inhibitor_Dose'].unique()))}\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Here I plot the beta coefficients for each treatment against the number of cells per well. Data points the drift heavily in the Y axis are features that are affected the most by the y-axis treatment while data points that drift more in the x-axis are features that are most affected by the number of cells in a well.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Linear Modeling (cell count beta + 1 beta approach)\n",
    "Here I merged the treatment and dosage and used DMSO 0.1% as the control simply comparing one dosage/treatment at a time and outputting each graph for each treatment for all features. All features and treatments will be exported into 1 file.\n",
    "\n",
    "Linear Model:  \n",
    "$y = \\beta _{0}x+ \\beta _{1}x+ \\epsilon$ where;  \n",
    "$y$ is each feature    \n",
    "$x$ is the inputed variables  \n",
    "$\\beta _{0}$ is the beta coefficient attributed to cell count.  \n",
    "$\\beta _{1}$ is the beta coefficient attributed to Inducer, Inhibitor,Inhibitor Dose and, Inducer dose.  \n",
    "$\\epsilon$ is the residual variance not explained by factors in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['media ctr_0_Media ctr_0.0', 'DMSO_0.100__DMSO_0.025']\n",
      "['DMSO_0.100_DMSO_1.0', 'DMSO_0.100__DMSO_0.025']\n",
      "['DMSO_0.100_Z-VAD-FMK_100.0', 'DMSO_0.100__DMSO_0.025']\n",
      "['DMSO_0.100_Z-VAD-FMK_30.0', 'DMSO_0.100__DMSO_0.025']\n",
      "['DMSO_0.100_DMSO_0.025', 'DMSO_0.100__DMSO_0.025']\n",
      "['Thapsigargin_1.000_DMSO_0.025', 'DMSO_0.100__DMSO_0.025']\n",
      "['Thapsigargin_10.000_DMSO_0.025', 'DMSO_0.100__DMSO_0.025']\n",
      "['Topotecan_5.000_DMSO_0.025', 'DMSO_0.100__DMSO_0.025']\n",
      "['Topotecan_10.000_DMSO_0.025', 'DMSO_0.100__DMSO_0.025']\n",
      "['Topotecan_20.000_DMSO_0.025', 'DMSO_0.100__DMSO_0.025']\n",
      "['LPS_0.010_DMSO_0.025', 'DMSO_0.100__DMSO_0.025']\n",
      "['LPS_0.100_DMSO_0.025', 'DMSO_0.100__DMSO_0.025']\n",
      "['LPS_1.000_DMSO_0.025', 'DMSO_0.100__DMSO_0.025']\n",
      "['LPS_10.000_DMSO_0.025', 'DMSO_0.100__DMSO_0.025']\n",
      "['LPS_10.000_Disulfiram_0.1', 'DMSO_0.100__DMSO_0.025']\n",
      "['LPS_10.000_Disulfiram_1.0', 'DMSO_0.100__DMSO_0.025']\n",
      "['LPS_10.000_Disulfiram_2.5', 'DMSO_0.100__DMSO_0.025']\n",
      "['LPS_Nigericin_100.000_1.0_DMSO_0.025', 'DMSO_0.100__DMSO_0.025']\n",
      "['LPS_Nigericin_100.000_3.0_DMSO_0.025', 'DMSO_0.100__DMSO_0.025']\n",
      "['LPS_Nigericin_100.000_10.0_DMSO_0.025', 'DMSO_0.100__DMSO_0.025']\n",
      "['Disulfiram_0.100_DMSO_0.025', 'DMSO_0.100__DMSO_0.025']\n",
      "['Disulfiram_1.000_DMSO_0.025', 'DMSO_0.100__DMSO_0.025']\n",
      "['Disulfiram_2.500_DMSO_0.025', 'DMSO_0.100__DMSO_0.025']\n",
      "['H2O2_100.000_DMSO_0.025', 'DMSO_0.100__DMSO_0.025']\n",
      "['LPS_10.000_Z-VAD-FMK_100.0', 'DMSO_0.100__DMSO_0.025']\n",
      "['LPS_100.000_DMSO_0.025', 'DMSO_0.100__DMSO_0.025']\n",
      "['LPS_Nigericin_1.000_1.0_DMSO_0.025', 'DMSO_0.100__DMSO_0.025']\n",
      "['LPS_Nigericin_1.000_3.0_DMSO_0.025', 'DMSO_0.100__DMSO_0.025']\n",
      "['LPS_Nigericin_1.000_10.0_DMSO_0.025', 'DMSO_0.100__DMSO_0.025']\n",
      "['LPS_Nigericin_1.000_10.0_Disulfiram_1.0', 'DMSO_0.100__DMSO_0.025']\n",
      "['LPS_Nigericin_1.000_10.0_Z-VAD-FMK_100.0', 'DMSO_0.100__DMSO_0.025']\n",
      "['H2O2_100.000_Disulfiram_1.0', 'DMSO_0.100__DMSO_0.025']\n",
      "['H2O2_100.000_Z-VAD-FMK_100.0', 'DMSO_0.100__DMSO_0.025']\n",
      "['Flagellin_0.100_DMSO_0.025', 'DMSO_0.100__DMSO_0.025']\n",
      "['Flagellin_1.000_DMSO_0.025', 'DMSO_0.100__DMSO_0.025']\n",
      "['Flagellin_1.000_Disulfiram_1.0', 'DMSO_0.100__DMSO_0.025']\n"
     ]
    }
   ],
   "source": [
    "model_covariates = [\"Metadata_number_of_singlecells\"]\n",
    "control = \"DMSO_0.100__DMSO_0.025\"\n",
    "lm_results = []\n",
    "for treatment in feature_df[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"].unique():\n",
    "    dosage_treatments_list = [treatment, control]\n",
    "    print(dosage_treatments_list)\n",
    "    # filter df for treatment and dose\n",
    "    df = feature_df.query(\n",
    "        \"oneb_Metadata_Treatment_Dose_Inhibitor_Dose in @dosage_treatments_list\"\n",
    "    )\n",
    "    # encode treatment and dose as integers\n",
    "\n",
    "    df[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"] = LabelEncoder().fit_transform(\n",
    "        df[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"]\n",
    "    )\n",
    "\n",
    "    # Setup linear modeling framework\n",
    "\n",
    "    X = df.loc[:, model_covariates]\n",
    "    X = pd.concat([X, df[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"]], axis=1)\n",
    "\n",
    "    columns_list = (\n",
    "        [\"feature\", \"r2_score\"] + X.columns.tolist() + [\"dosage_treatments_list\"]\n",
    "    )\n",
    "\n",
    "    # Fit linear model for each feature\n",
    "    for cp_feature in cp_features:\n",
    "        # Subset CP data to each individual feature (univariate test)\n",
    "        cp_subset_df = df.loc[:, cp_feature]\n",
    "\n",
    "        # Fit linear model\n",
    "        lm = LinearRegression(fit_intercept=True)\n",
    "        lm_result = lm.fit(X=X, y=cp_subset_df)\n",
    "\n",
    "        # Extract Beta coefficients(contribution of feature to X covariates)\n",
    "        coef = list(lm_result.coef_)\n",
    "        # Estimate fit (R^2)\n",
    "        r2_score = lm.score(X=X, y=cp_subset_df)\n",
    "\n",
    "        # Add results to a growing list\n",
    "        lm_results.append(\n",
    "            [cp_feature, r2_score] + coef + [f\"{'-'.join(dosage_treatments_list)}\"]\n",
    "        )\n",
    "lm_results\n",
    "# Convert results to a pandas DataFrame\n",
    "lm_results_df = pd.DataFrame(lm_results, columns=columns_list)\n",
    "\n",
    "# write output to file\n",
    "lm_results_df.to_csv(one_beta_output_file_path, sep=\"\\t\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complex Linear Modeling (cell count btea + 2 beta approach)\n",
    "Here I run the same analysis as above but with dosage of a treatment being a factor in the linear model. All features and treatments will be exported into 1 file.\n",
    "\n",
    "Linear Model:  \n",
    "$y = \\beta _{0}x+ \\beta _{1}x+ \\beta _{2}x+ \\epsilon$ where;  \n",
    "$y$ is each feature    \n",
    "$x$ is the inputed variables  \n",
    "$\\beta _{0}$ is the beta coefficient attributed to cell count.  \n",
    "$\\beta _{1}$ is the beta coefficient attributed to Inducer, Inhibitor, and Inhibitor Dose.  \n",
    "$\\beta _{2}$ is the beta coefficient attributed to Inducer dose.  \n",
    "$\\epsilon$ is the residual variance not explained by factors in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['media ctr_Media ctr_0.0__0', 'DMSO_DMSO_0.025__0.100']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39m# Fit linear model\u001b[39;00m\n\u001b[1;32m     34\u001b[0m lm \u001b[39m=\u001b[39m LinearRegression(fit_intercept\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 35\u001b[0m lm_result \u001b[39m=\u001b[39m lm\u001b[39m.\u001b[39;49mfit(X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49mcp_subset_df)\n\u001b[1;32m     37\u001b[0m \u001b[39m# Extract Beta coefficients\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[39m# (contribution of feature to X covariates)\u001b[39;00m\n\u001b[1;32m     39\u001b[0m coef \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(lm_result\u001b[39m.\u001b[39mcoef_)\n",
      "File \u001b[0;32m~/miniconda3/envs/Interstellar/lib/python3.10/site-packages/sklearn/linear_model/_base.py:648\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    644\u001b[0m n_jobs_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs\n\u001b[1;32m    646\u001b[0m accept_sparse \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositive \u001b[39melse\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcoo\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> 648\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    649\u001b[0m     X, y, accept_sparse\u001b[39m=\u001b[39;49maccept_sparse, y_numeric\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m    650\u001b[0m )\n\u001b[1;32m    652\u001b[0m sample_weight \u001b[39m=\u001b[39m _check_sample_weight(\n\u001b[1;32m    653\u001b[0m     sample_weight, X, dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype, only_non_negative\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    654\u001b[0m )\n\u001b[1;32m    656\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[39m=\u001b[39m _preprocess_data(\n\u001b[1;32m    657\u001b[0m     X,\n\u001b[1;32m    658\u001b[0m     y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    661\u001b[0m     sample_weight\u001b[39m=\u001b[39msample_weight,\n\u001b[1;32m    662\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/Interstellar/lib/python3.10/site-packages/sklearn/base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    583\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 584\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/envs/Interstellar/lib/python3.10/site-packages/sklearn/utils/validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1103\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[0;32m-> 1106\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1107\u001b[0m     X,\n\u001b[1;32m   1108\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m   1109\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m   1110\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1111\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m   1112\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   1113\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m   1114\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[1;32m   1115\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[1;32m   1116\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[1;32m   1117\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[1;32m   1118\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m   1119\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1120\u001b[0m )\n\u001b[1;32m   1122\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/miniconda3/envs/Interstellar/lib/python3.10/site-packages/sklearn/utils/validation.py:761\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    759\u001b[0m dtypes_orig \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    760\u001b[0m pandas_requires_conversion \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 761\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39;49m(array, \u001b[39m\"\u001b[39;49m\u001b[39mdtypes\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(array\u001b[39m.\u001b[39mdtypes, \u001b[39m\"\u001b[39m\u001b[39m__array__\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    762\u001b[0m     \u001b[39m# throw warning if columns are sparse. If all columns are sparse, then\u001b[39;00m\n\u001b[1;32m    763\u001b[0m     \u001b[39m# array.sparse exists and sparsity will be preserved (later).\u001b[39;00m\n\u001b[1;32m    764\u001b[0m     \u001b[39mwith\u001b[39;00m suppress(\u001b[39mImportError\u001b[39;00m):\n\u001b[1;32m    765\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m is_sparse\n",
      "File \u001b[0;32m~/miniconda3/envs/Interstellar/lib/python3.10/site-packages/pandas/core/generic.py:6159\u001b[0m, in \u001b[0;36mNDFrame.dtypes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   6132\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   6133\u001b[0m \u001b[39mReturn the dtypes in the DataFrame.\u001b[39;00m\n\u001b[1;32m   6134\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6156\u001b[0m \u001b[39mdtype: object\u001b[39;00m\n\u001b[1;32m   6157\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   6158\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39mget_dtypes()\n\u001b[0;32m-> 6159\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_constructor_sliced(data, index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_info_axis, dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mobject_)\n",
      "File \u001b[0;32m~/miniconda3/envs/Interstellar/lib/python3.10/site-packages/pandas/core/series.py:428\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    425\u001b[0m     index \u001b[39m=\u001b[39m ensure_index(index)\n\u001b[1;32m    427\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 428\u001b[0m     dtype \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_dtype(dtype)\n\u001b[1;32m    430\u001b[0m \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    431\u001b[0m     index \u001b[39m=\u001b[39m index \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m default_index(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/Interstellar/lib/python3.10/site-packages/pandas/core/generic.py:458\u001b[0m, in \u001b[0;36mNDFrame._validate_dtype\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"validate the passed dtype\"\"\"\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m     dtype \u001b[39m=\u001b[39m pandas_dtype(dtype)\n\u001b[1;32m    460\u001b[0m     \u001b[39m# a compound dtype\u001b[39;00m\n\u001b[1;32m    461\u001b[0m     \u001b[39mif\u001b[39;00m dtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mV\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/Interstellar/lib/python3.10/site-packages/pandas/core/dtypes/common.py:1686\u001b[0m, in \u001b[0;36mpandas_dtype\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m   1683\u001b[0m \u001b[39m# try a numpy dtype\u001b[39;00m\n\u001b[1;32m   1684\u001b[0m \u001b[39m# raise a consistent TypeError if failed\u001b[39;00m\n\u001b[1;32m   1685\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1686\u001b[0m     \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39;49mcatch_warnings():\n\u001b[1;32m   1687\u001b[0m         \u001b[39m# GH#51523 - Series.astype(np.integer) doesn't show\u001b[39;00m\n\u001b[1;32m   1688\u001b[0m         \u001b[39m# numpy deprication warning of np.integer\u001b[39;00m\n\u001b[1;32m   1689\u001b[0m         \u001b[39m# Hence enabling DeprecationWarning\u001b[39;00m\n\u001b[1;32m   1690\u001b[0m         warnings\u001b[39m.\u001b[39msimplefilter(\u001b[39m\"\u001b[39m\u001b[39malways\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m   1691\u001b[0m         npdtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdtype(dtype)\n",
      "File \u001b[0;32m~/miniconda3/envs/Interstellar/lib/python3.10/warnings.py:437\u001b[0m, in \u001b[0;36mcatch_warnings.__init__\u001b[0;34m(self, record, module)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mcatch_warnings\u001b[39;00m(\u001b[39mobject\u001b[39m):\n\u001b[1;32m    422\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"A context manager that copies and restores the warnings filter upon\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[39m    exiting the context.\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    434\u001b[0m \n\u001b[1;32m    435\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 437\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m, record\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, module\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    438\u001b[0m \u001b[39m        \u001b[39m\u001b[39m\"\"\"Specify whether to record warnings and if an alternative module\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[39m        should be used other than sys.modules['warnings'].\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    443\u001b[0m \n\u001b[1;32m    444\u001b[0m \u001b[39m        \"\"\"\u001b[39;00m\n\u001b[1;32m    445\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_record \u001b[39m=\u001b[39m record\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Loop for each treatment then each feature\n",
    "\n",
    "# define the control and treatment\n",
    "# Setup linear modeling framework\n",
    "model_covariates = [\"Metadata_number_of_singlecells\"]\n",
    "control = \"DMSO_DMSO_0.025__0.100\"\n",
    "lm_results = []\n",
    "for treatment in feature_df[\"twob_Metadata_Treatment_Dose_Inhibitor_Dose\"].unique():\n",
    "    dosage_treatments_list = [treatment, control]\n",
    "    print(dosage_treatments_list)\n",
    "    df = feature_df.query(\n",
    "        \"twob_Metadata_Treatment_Dose_Inhibitor_Dose in @dosage_treatments_list\"\n",
    "    )\n",
    "    # Add dummy matrix of categorical genotypes\n",
    "    # treatment_df = feature_df[[\"Metadata_inducer1\", \"Metadata_inducer1_concentration\"]]\n",
    "    df[[\"twob_Metadata_Treatment_Inhibitor_Dose\", \"Treatment_Dose\"]] = df[\n",
    "        \"twob_Metadata_Treatment_Dose_Inhibitor_Dose\"\n",
    "    ].str.split(\"__\", expand=True)\n",
    "    tmp_df = df.loc[\n",
    "        :,\n",
    "        (\n",
    "            \"twob_Metadata_Treatment_Inhibitor_Dose\",\n",
    "            \"Treatment_Dose\",\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    tmp_df[\"twob_Metadata_Treatment_Inhibitor_Dose\"] = LabelEncoder().fit_transform(\n",
    "        tmp_df[\"twob_Metadata_Treatment_Inhibitor_Dose\"]\n",
    "    )\n",
    "    tmp_df[\"Treatment_Dose\"] = LabelEncoder().fit_transform(tmp_df[\"Treatment_Dose\"])\n",
    "\n",
    "    X = pd.concat([df.loc[:, model_covariates], tmp_df], axis=1)\n",
    "    columns_list = (\n",
    "        [\"feature\", \"r2_score\"]\n",
    "        + X.columns.tolist()\n",
    "        + [\n",
    "            \"inducer1\",\n",
    "            \"inducer1_dose\",\n",
    "            \"inducer2\",\n",
    "            \"inducer2_dose\",\n",
    "            \"inhibitor\",\n",
    "            \"inhibitor_dose\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Fit linear model for each feature\n",
    "    # lm_results = []\n",
    "    for cp_feature in cp_features:\n",
    "        # Subset CP data to each individual feature (univariate test)\n",
    "        cp_subset_df = df.loc[:, cp_feature]\n",
    "\n",
    "        # Fit linear model\n",
    "        lm = LinearRegression(fit_intercept=True)\n",
    "        lm_result = lm.fit(X=X, y=cp_subset_df)\n",
    "\n",
    "        # Extract Beta coefficients\n",
    "        # (contribution of feature to X covariates)\n",
    "        coef = list(lm_result.coef_)\n",
    "        # Estimate fit (R^2)\n",
    "        r2_score = lm.score(X=X, y=cp_subset_df)\n",
    "\n",
    "        # Add results to a growing list\n",
    "        lm_results.append(\n",
    "            [cp_feature, r2_score]\n",
    "            + coef\n",
    "            + [\n",
    "                treatment,\n",
    "                \"_\".join(df[\"Metadata_inducer1_concentration\"].astype(str).unique()),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "# Convert results to a pandas DataFrame\n",
    "lm_results_df = pd.DataFrame(lm_results, columns=columns_list)\n",
    "\n",
    "# write output to file\n",
    "lm_results_df.to_csv(two_beta_output_file_path, sep=\"\\t\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complex Linear Modeling (cell count beta + 3 beta approach)\n",
    "Here I run the same analysis as above but with dosage of a treatment being a factor in the linear model. All features and treatments will be exported into 1 file.\n",
    "\n",
    "Linear Model:  \n",
    "$y = \\beta _{0}x+ \\beta _{1}x+ \\beta _{2}x+ \\beta _{3}x+ \\epsilon$ where;  \n",
    "$y$ is each feature    \n",
    "$x$ is the inputed variables  \n",
    "$\\beta _{0}$ is the beta coefficient attributed to cell count.  \n",
    "$\\beta _{1}$ is the beta coefficient attributed to Inducer.   \n",
    "$\\beta _{2}$ is the beta coefficient attributed to Inducer dose.    \n",
    "$\\beta _{3}$ is the beta coefficient attributed to Inhibitor, and Inhibitor Dose.   \n",
    "$\\epsilon$ is the residual variance not explained by factors in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop for each treatment then each feature\n",
    "\n",
    "# define the control and treatment\n",
    "# Setup linear modeling framework\n",
    "model_covariates = [\"Metadata_number_of_singlecells\"]\n",
    "control = \"DMSO__0.100__DMSO_0.025\"\n",
    "lm_results = []\n",
    "for treatment in feature_df[\"threeb_Metadata_Treatment_Dose_Inhibitor_Dose\"].unique():\n",
    "    dosage_treatments_list = [treatment, control]\n",
    "    print(dosage_treatments_list)\n",
    "    df = feature_df.query(\n",
    "        \"threeb_Metadata_Treatment_Dose_Inhibitor_Dose in @dosage_treatments_list\"\n",
    "    )\n",
    "    # Add dummy matrix of categorical genotypes\n",
    "    df[\n",
    "        [\n",
    "            \"threeb_Treatment\",\n",
    "            \"threeb_Treatment_Dose\",\n",
    "            \"threeb_Inhibitor_and_Dose\",\n",
    "        ]\n",
    "    ] = df[\"threeb_Metadata_Treatment_Dose_Inhibitor_Dose\"].str.split(\"__\", expand=True)\n",
    "    tmp_df = df.loc[\n",
    "        :, (\"threeb_Treatment\", \"threeb_Treatment_Dose\", \"threeb_Inhibitor_and_Dose\")\n",
    "    ]\n",
    "\n",
    "    tmp_df[\"threeb_Treatment\"] = LabelEncoder().fit_transform(\n",
    "        tmp_df[\"threeb_Treatment\"]\n",
    "    )\n",
    "    tmp_df[\"threeb_Treatment_Dose\"] = LabelEncoder().fit_transform(\n",
    "        tmp_df[\"threeb_Treatment_Dose\"]\n",
    "    )\n",
    "    tmp_df[\"threeb_Inhibitor_and_Dose\"] = LabelEncoder().fit_transform(\n",
    "        tmp_df[\"threeb_Inhibitor_and_Dose\"]\n",
    "    )\n",
    "\n",
    "    X = pd.concat([df.loc[:, model_covariates], tmp_df], axis=1)\n",
    "    columns_list = (\n",
    "        [\"feature\", \"r2_score\"]\n",
    "        + X.columns.tolist()\n",
    "        + [\n",
    "            \"inducer1\",\n",
    "            \"inducer1_dose\",\n",
    "            \"inducer2\",\n",
    "            \"inducer2_dose\",\n",
    "            \"inhibitor\",\n",
    "            \"inhibitor_dose\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Fit linear model for each feature\n",
    "    # lm_results = []\n",
    "    for cp_feature in cp_features:\n",
    "        # Subset CP data to each individual feature (univariate test)\n",
    "        cp_subset_df = df.loc[:, cp_feature]\n",
    "\n",
    "        # Fit linear model\n",
    "        lm = LinearRegression(fit_intercept=True)\n",
    "        lm_result = lm.fit(X=X, y=cp_subset_df)\n",
    "\n",
    "        # Extract Beta coefficients\n",
    "        # (contribution of feature to X covariates)\n",
    "        coef = list(lm_result.coef_)\n",
    "        # Estimate fit (R^2)\n",
    "        r2_score = lm.score(X=X, y=cp_subset_df)\n",
    "\n",
    "        # Add results to a growing list\n",
    "        lm_results.append(\n",
    "            [cp_feature, r2_score]\n",
    "            + coef\n",
    "            + [\n",
    "                treatment,\n",
    "                \"_\".join(df[\"Metadata_inducer1_concentration\"].astype(str).unique()),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "# Convert results to a pandas DataFrame\n",
    "lm_results_df = pd.DataFrame(lm_results, columns=columns_list)\n",
    "\n",
    "# write output to file\n",
    "lm_results_df.to_csv(three_beta_output_file_path, sep=\"\\t\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complex Linear Modeling (cell count beta + 4 beta approach)\n",
    "Here I run the same analysis as above but with dosage of a treatment being a factor in the linear model. All features and treatments will be exported into 1 file.\n",
    "\n",
    "Linear Model:  \n",
    "$y = \\beta _{0}x+ \\beta _{1}x+ \\beta _{2}x+ \\beta _{3}x+ \\beta _{4}x+ \\epsilon$ where;  \n",
    "$y$ is each feature    \n",
    "$x$ is the inputed variables  \n",
    "$\\beta _{0}$ is the beta coefficient attributed to cell count.    \n",
    "$\\beta _{1}$ is the beta coefficient attributed to Inducer.   \n",
    "$\\beta _{2}$ is the beta coefficient attributed to Inducer dose.    \n",
    "$\\beta _{3}$ is the beta coefficient attributed to Inhibitor.    \n",
    "$\\beta _{4}$ is the beta coefficient attributed to Inhibitor Dose.   \n",
    "$\\epsilon$ is the residual variance not explained by factors in the model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop for each treatment then each feature\n",
    "\n",
    "# define the control and treatment\n",
    "# Setup linear modeling framework\n",
    "model_covariates = [\"Metadata_number_of_singlecells\"]\n",
    "control = \"DMSO__0.100__DMSO__0.025\"\n",
    "lm_results = []\n",
    "for treatment in feature_df[\"fourb_Metadata_Treatment_Dose_Inhibitor_Dose\"].unique():\n",
    "    dosage_treatments_list = [treatment, control]\n",
    "    print(dosage_treatments_list)\n",
    "    df = feature_df.query(\n",
    "        \"fourb_Metadata_Treatment_Dose_Inhibitor_Dose in @dosage_treatments_list\"\n",
    "    )\n",
    "    # Add dummy matrix of categorical genotypes\n",
    "    df[\n",
    "        [\n",
    "            \"fourb_Treatment\",\n",
    "            \"fourb_Treatment_Dose\",\n",
    "            \"fourb_Inhibitor\",\n",
    "            \"fourb_Inhibitor_Dose\",\n",
    "        ]\n",
    "    ] = df[\"fourb_Metadata_Treatment_Dose_Inhibitor_Dose\"].str.split(\"__\", expand=True)\n",
    "    tmp_df = df.loc[\n",
    "        :,\n",
    "        (\n",
    "            \"fourb_Treatment\",\n",
    "            \"fourb_Treatment_Dose\",\n",
    "            \"fourb_Inhibitor\",\n",
    "            \"fourb_Inhibitor_Dose\",\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    tmp_df[\"fourb_Treatment\"] = LabelEncoder().fit_transform(tmp_df[\"fourb_Treatment\"])\n",
    "    tmp_df[\"fourb_Treatment_Dose\"] = LabelEncoder().fit_transform(\n",
    "        tmp_df[\"fourb_Treatment_Dose\"]\n",
    "    )\n",
    "    tmp_df[\"fourb_Inhibitor\"] = LabelEncoder().fit_transform(tmp_df[\"fourb_Inhibitor\"])\n",
    "    tmp_df[\"fourb_Inhibitor_Dose\"] = LabelEncoder().fit_transform(\n",
    "        tmp_df[\"fourb_Inhibitor_Dose\"]\n",
    "    )\n",
    "\n",
    "    X = pd.concat([df.loc[:, model_covariates], tmp_df], axis=1)\n",
    "    columns_list = (\n",
    "        [\"feature\", \"r2_score\"]\n",
    "        + X.columns.tolist()\n",
    "        + [\n",
    "            \"inducer1\",\n",
    "            \"inducer1_dose\",\n",
    "            \"inducer2\",\n",
    "            \"inducer2_dose\",\n",
    "            \"inhibitor\",\n",
    "            \"inhibitor_dose\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Fit linear model for each feature\n",
    "    # lm_results = []\n",
    "    for cp_feature in cp_features:\n",
    "        # Subset CP data to each individual feature (univariate test)\n",
    "        cp_subset_df = df.loc[:, cp_feature]\n",
    "\n",
    "        # Fit linear model\n",
    "        lm = LinearRegression(fit_intercept=True)\n",
    "        lm_result = lm.fit(X=X, y=cp_subset_df)\n",
    "\n",
    "        # Extract Beta coefficients\n",
    "        # (contribution of feature to X covariates)\n",
    "        coef = list(lm_result.coef_)\n",
    "        # Estimate fit (R^2)\n",
    "        r2_score = lm.score(X=X, y=cp_subset_df)\n",
    "\n",
    "        # Add results to a growing list\n",
    "        lm_results.append(\n",
    "            [cp_feature, r2_score]\n",
    "            + coef\n",
    "            + [\n",
    "                treatment,\n",
    "                \"_\".join(df[\"Metadata_inducer1_concentration\"].astype(str).unique()),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "# Convert results to a pandas DataFrame\n",
    "lm_results_df = pd.DataFrame(lm_results, columns=columns_list)\n",
    "\n",
    "# write output to file\n",
    "lm_results_df.to_csv(four_beta_output_file_path, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Interstellar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72ae02083a9ca7d143c492d1aec380c7bf553ec51bd66e90e72bba65228121b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
