{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "76db0f62",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-10-18T18:21:55.318585Z",
                    "iopub.status.busy": "2023-10-18T18:21:55.318429Z",
                    "iopub.status.idle": "2023-10-18T18:21:56.764566Z",
                    "shell.execute_reply": "2023-10-18T18:21:56.764197Z"
                },
                "papermill": {
                    "duration": 1.453218,
                    "end_time": "2023-10-18T18:21:56.766140",
                    "exception": false,
                    "start_time": "2023-10-18T18:21:55.312922",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "import ast\n",
                "import pathlib\n",
                "import sys\n",
                "\n",
                "import numpy as np\n",
                "import optuna\n",
                "import pandas as pd\n",
                "import pyarrow.parquet as pq\n",
                "import toml\n",
                "import torch\n",
                "from sklearn import preprocessing\n",
                "\n",
                "sys.path.append(\"../..\")\n",
                "\n",
                "import json\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from MLP_utils.parameters import Parameters\n",
                "from MLP_utils.utils import (\n",
                "    Dataset_formatter,\n",
                "    data_split,\n",
                "    extract_best_trial_params,\n",
                "    objective_model_optimizer,\n",
                "    optimized_model_create,\n",
                "    output_stats,\n",
                "    parameter_set,\n",
                "    plot_metric_vs_epoch,\n",
                "    results_output,\n",
                "    test_optimized_model,\n",
                "    train_optimized_model,\n",
                "    un_nest,\n",
                ")\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "sys.path.append(\"../../..\")\n",
                "from utils.utils import df_stats"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7773f676",
            "metadata": {
                "papermill": {
                    "duration": 0.004964,
                    "end_time": "2023-10-18T18:21:56.776597",
                    "exception": false,
                    "start_time": "2023-10-18T18:21:56.771633",
                    "status": "completed"
                },
                "tags": []
            },
            "source": [
                "## Papermill is used for executing notebooks in the CLI with multiple parameters\n",
                "Here the `injected-parameters` cell is used to inject parameters into the notebook via papermill.\n",
                "This enables multiple notebooks to be executed with different parameters, preventing to manually update parameters or have multiple copies of the notebook."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b3502f1e",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-10-18T18:21:56.787247Z",
                    "iopub.status.busy": "2023-10-18T18:21:56.787004Z",
                    "iopub.status.idle": "2023-10-18T18:21:56.789480Z",
                    "shell.execute_reply": "2023-10-18T18:21:56.789142Z"
                },
                "papermill": {
                    "duration": 0.008892,
                    "end_time": "2023-10-18T18:21:56.790441",
                    "exception": false,
                    "start_time": "2023-10-18T18:21:56.781549",
                    "status": "completed"
                },
                "tags": [
                    "injected-parameters"
                ]
            },
            "outputs": [],
            "source": [
                "# Parameters\n",
                "CELL_TYPE = \"SHSY5Y\"\n",
                "MODEL_NAME = \"MultiClass_MLP\"\n",
                "SHUFFLE = False"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7fe861fc",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-10-18T18:21:56.801290Z",
                    "iopub.status.busy": "2023-10-18T18:21:56.801143Z",
                    "iopub.status.idle": "2023-10-18T18:21:56.804166Z",
                    "shell.execute_reply": "2023-10-18T18:21:56.803905Z"
                },
                "papermill": {
                    "duration": 0.009611,
                    "end_time": "2023-10-18T18:21:56.805265",
                    "exception": false,
                    "start_time": "2023-10-18T18:21:56.795654",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "ml_configs_file = pathlib.Path(\"../../MLP_utils/multi_class_config.toml\").resolve(\n",
                "    strict=True\n",
                ")\n",
                "ml_configs = toml.load(ml_configs_file)\n",
                "params = Parameters()\n",
                "mlp_params = parameter_set(params, ml_configs)\n",
                "\n",
                "# overwrite params via command line arguments from papermill\n",
                "mlp_params.CELL_TYPE = CELL_TYPE\n",
                "mlp_params.MODEL_NAME = MODEL_NAME\n",
                "\n",
                "mlp_params.MODEL_NAME = MODEL_NAME\n",
                "mlp_params.SHUFFLE = SHUFFLE\n",
                "\n",
                "# load in the class weights\n",
                "class_weights_file_path = pathlib.Path(\n",
                "    f\"../../0.hyperparameter_optimization/class_weights/{CELL_TYPE}/multi_class/class_weights.txt\"\n",
                ").resolve(strict=True)\n",
                "# read the class weights into a list for use in the loss function as a list\n",
                "class_weights = []\n",
                "with open(class_weights_file_path, \"r\") as f:\n",
                "    for line in f:\n",
                "        class_weights.append(float(line.strip()))\n",
                "# check the class weights are correct\n",
                "print(class_weights)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5f05b3f4",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-10-18T18:21:56.816606Z",
                    "iopub.status.busy": "2023-10-18T18:21:56.816502Z"
                },
                "papermill": {
                    "duration": 11.557813,
                    "end_time": "2023-10-18T18:22:08.369011",
                    "exception": false,
                    "start_time": "2023-10-18T18:21:56.811198",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# Import Data\n",
                "# set data file path under pathlib path for multi-system use\n",
                "\n",
                "file_path = pathlib.Path(\n",
                "    f\"../../../data/{mlp_params.CELL_TYPE}_preprocessed_sc_norm.parquet\"\n",
                ").resolve(strict=True)\n",
                "\n",
                "df1 = pd.read_parquet(file_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "72eaf455",
            "metadata": {},
            "outputs": [],
            "source": [
                "# df1['oneb_Metadata_Treatment_Dose_Inhibitor_Dose'].unique()\n",
                "# # drop H2O2_100.000_uM_DMSO_0.025_% and H2O2_100.000_nM_DMSO_0.025_%\n",
                "# df1 = df1[df1['oneb_Metadata_Treatment_Dose_Inhibitor_Dose'] != 'H2O2_100.000_uM_DMSO_0.025_%']\n",
                "# df1 = df1[df1['oneb_Metadata_Treatment_Dose_Inhibitor_Dose'] != 'H2O2_100.000_nM_DMSO_0.025_%']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d660c06e",
            "metadata": {},
            "outputs": [],
            "source": [
                "df1.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6c372a03",
            "metadata": {},
            "outputs": [],
            "source": [
                "# get paths for toml files\n",
                "ground_truth_file_path = pathlib.Path(f\"../../MLP_utils/ground_truth.toml\").resolve(\n",
                "    strict=True\n",
                ")\n",
                "treatment_splits_file_path = pathlib.Path(f\"../../MLP_utils/splits.toml\").resolve(\n",
                "    strict=True\n",
                ")\n",
                "# read toml files\n",
                "ground_truth = toml.load(ground_truth_file_path)\n",
                "treatment_splits = toml.load(treatment_splits_file_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "63523a09",
            "metadata": {},
            "outputs": [],
            "source": [
                "# get information from toml files\n",
                "apoptosis_groups_list = ground_truth[\"Apoptosis\"][\"apoptosis_groups_list\"]\n",
                "pyroptosis_groups_list = ground_truth[\"Pyroptosis\"][\"pyroptosis_groups_list\"]\n",
                "healthy_groups_list = ground_truth[\"Healthy\"][\"healthy_groups_list\"]"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7c5e28b5",
            "metadata": {
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "source": [
                "#### Set up Data to be compatible with model"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5efd38f4",
            "metadata": {
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "source": [
                "##### Classification Models:\n",
                "Comment out code if using regression"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "892c99cb",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-08-18T18:02:17.367529Z",
                    "iopub.status.busy": "2023-08-18T18:02:17.367201Z",
                    "iopub.status.idle": "2023-08-18T18:02:18.678324Z",
                    "shell.execute_reply": "2023-08-18T18:02:18.677713Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "np.random.seed(0)\n",
                "if ast.literal_eval(mlp_params.DATA_SUBSET_OPTION):\n",
                "    df1 = df1.groupby(\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\").apply(\n",
                "        lambda x: x.sample(n=mlp_params.DATA_SUBSET_NUMBER, random_state=0)\n",
                "    )\n",
                "    print(\"Data Subset Is On\")\n",
                "    print(f\"Data is subset to {mlp_params.DATA_SUBSET_NUMBER} per treatment group\")\n",
                "    print(df1.shape)\n",
                "    df1.reset_index(drop=True, inplace=True)\n",
                "else:\n",
                "    print(\"Data Subset Is Off\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "48b83d0d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# add apoptosis, pyroptosis and healthy columns to dataframe\n",
                "df1[\"apoptosis\"] = df1.apply(\n",
                "    lambda row: row[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"]\n",
                "    in apoptosis_groups_list,\n",
                "    axis=1,\n",
                ")\n",
                "df1[\"pyroptosis\"] = df1.apply(\n",
                "    lambda row: row[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"]\n",
                "    in pyroptosis_groups_list,\n",
                "    axis=1,\n",
                ")\n",
                "df1[\"healthy\"] = df1.apply(\n",
                "    lambda row: row[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"]\n",
                "    in healthy_groups_list,\n",
                "    axis=1,\n",
                ")\n",
                "\n",
                "# merge apoptosis, pyroptosis, and healthy columns into one column\n",
                "df1[\"labels\"] = df1.apply(\n",
                "    lambda row: \"apoptosis\"\n",
                "    if row[\"apoptosis\"]\n",
                "    else \"pyroptosis\"\n",
                "    if row[\"pyroptosis\"]\n",
                "    else \"healthy\",\n",
                "    axis=1,\n",
                ")\n",
                "# drop apoptosis, pyroptosis, and healthy columns\n",
                "df1.drop(columns=[\"apoptosis\", \"pyroptosis\", \"healthy\"], inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "46013a3d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# # randomly select wells to hold out for testing one per treatment group\n",
                "# # stratified by treatment group\n",
                "# np.random.seed(seed=0)\n",
                "# wells_to_hold = (\n",
                "#     df1.groupby(\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\")\n",
                "#     .agg(np.random.choice)[\"Metadata_Well\"]\n",
                "#     .to_list()\n",
                "# )\n",
                "# df_holdout = df1[df1[\"Metadata_Well\"].isin(wells_to_hold)]\n",
                "# df = df1[~df1[\"Metadata_Well\"].isin(wells_to_hold)]\n",
                "\n",
                "\n",
                "# print(\"Wells held out for testing:\", df_holdout[\"Metadata_Well\"].unique())\n",
                "# print(\n",
                "#     \"Wells to use for training, validation, and testing\", df1[\"Metadata_Well\"].unique()\n",
                "# )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5f7e0516",
            "metadata": {},
            "outputs": [],
            "source": [
                "# # downsample healthy and pyroptosis to match number of apoptosis\n",
                "# # to balance classes\n",
                "# df_healthy = df1[df1[\"labels\"] == \"healthy\"]\n",
                "# df_pyroptosis = df1[df1[\"labels\"] == \"pyroptosis\"]\n",
                "# df_apoptosis = df1[df1[\"labels\"] == \"apoptosis\"]\n",
                "# print(df_healthy.shape, df_pyroptosis.shape, df_apoptosis.shape)\n",
                "# df_healthy = df_healthy.sample(n=df_apoptosis.shape[0], random_state=0)\n",
                "# df_pyroptosis = df_pyroptosis.sample(n=df_apoptosis.shape[0], random_state=0)\n",
                "# print(df_healthy.shape, df_pyroptosis.shape, df_apoptosis.shape)\n",
                "# df = pd.concat([df_healthy, df_pyroptosis, df_apoptosis])\n",
                "# print(df.shape)\n",
                "# # show that the df was downsampled and recombined correctly\n",
                "# assert (df_healthy + df_pyroptosis + df_apoptosis).shape[0] == df1.shape[0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "615a24e0",
            "metadata": {},
            "outputs": [],
            "source": [
                "# set path for index file\n",
                "index_file_path = pathlib.Path(\n",
                "    f\"../../0.hyperparameter_optimization/indexes/SHSY5Y/multi_class/multi_class_data_split_indexes.tsv\"\n",
                ").resolve(strict=True)\n",
                "\n",
                "# read index file\n",
                "index_df = pd.read_csv(index_file_path, sep=\"\\t\")\n",
                "index_df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d7eb7489",
            "metadata": {},
            "outputs": [],
            "source": [
                "# get train, validation, test, and holdout indexes\n",
                "train_indexes = index_df.loc[index_df[\"label\"] == \"train\"][\"labeled_data_index\"]\n",
                "val_indexes = index_df.loc[index_df[\"label\"] == \"val\"][\"labeled_data_index\"]\n",
                "test_indexes = index_df.loc[index_df[\"label\"] == \"test\"][\"labeled_data_index\"]\n",
                "holdout_indexes = index_df.loc[index_df[\"label\"] == \"holdout\"][\"labeled_data_index\"]\n",
                "print(train_indexes.shape, val_indexes.shape, test_indexes.shape, holdout_indexes.shape)\n",
                "assert (\n",
                "    train_indexes.shape[0]\n",
                "    + val_indexes.shape[0]\n",
                "    + test_indexes.shape[0]\n",
                "    + holdout_indexes.shape[0]\n",
                ") == index_df.shape[0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3d9db49e",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-08-18T18:02:22.044888Z",
                    "iopub.status.busy": "2023-08-18T18:02:22.044473Z",
                    "iopub.status.idle": "2023-08-18T18:02:22.349293Z",
                    "shell.execute_reply": "2023-08-18T18:02:22.348707Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# Code snippet for metadata extraction by Jenna Tomkinson\n",
                "df_metadata = list(df1.columns[df1.columns.str.startswith(\"Metadata\")])\n",
                "\n",
                "# define which columns are data and which are descriptive\n",
                "df_descriptive = df1[df_metadata]\n",
                "df_values = df1.drop(columns=df_metadata)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8924c31e",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-08-18T18:02:22.363098Z",
                    "iopub.status.busy": "2023-08-18T18:02:22.362689Z",
                    "iopub.status.idle": "2023-08-18T18:02:22.714639Z",
                    "shell.execute_reply": "2023-08-18T18:02:22.714027Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# Creating label encoder\n",
                "le = preprocessing.LabelEncoder()\n",
                "# Converting strings into numbers\n",
                "df_values[\"new_labels\"] = le.fit_transform(df_values[\"labels\"])\n",
                "# get mini dataframe that contains the decoder\n",
                "df_labels = df_values[[\"labels\", \"new_labels\"]]\n",
                "# split into X and Y where Y are the predictive column and x are the observable data\n",
                "df_values_X = df_values.drop(\n",
                "    [\n",
                "        \"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\",\n",
                "        \"twob_Metadata_Treatment_Dose_Inhibitor_Dose\",\n",
                "        \"threeb_Metadata_Treatment_Dose_Inhibitor_Dose\",\n",
                "        \"fourb_Metadata_Treatment_Dose_Inhibitor_Dose\",\n",
                "        \"labels\",\n",
                "        \"new_labels\",\n",
                "    ],\n",
                "    axis=1,\n",
                ")\n",
                "df_values_Y = df_values[\"new_labels\"]\n",
                "df_values_Y.unique()\n",
                "df_labels.drop_duplicates(inplace=True)\n",
                "# pandas chaining to reset index and drop old index\n",
                "df_labels.reset_index(drop=True, inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5551d56b",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(df_values_X.shape, df_values_Y.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b18afc16",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(train_indexes.shape, val_indexes.shape, test_indexes.shape, holdout_indexes.shape)\n",
                "print(\n",
                "    train_indexes.shape[0]\n",
                "    + val_indexes.shape[0]\n",
                "    + test_indexes.shape[0]\n",
                "    + holdout_indexes.shape[0]\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "47d6c16d",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "62be33d8",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "84c24e0f",
            "metadata": {},
            "outputs": [],
            "source": [
                "# get the train, validation, test, and holdout dataframes from the indexes\n",
                "X_train = df_values_X.iloc[train_indexes.values]\n",
                "X_val = df_values_X.iloc[val_indexes.values]\n",
                "X_test = df_values_X.iloc[test_indexes.values]\n",
                "X_holdout = df_values_X.iloc[holdout_indexes.values]\n",
                "\n",
                "Y_train = df_values_Y.iloc[train_indexes.values]\n",
                "Y_val = df_values_Y.iloc[val_indexes.values]\n",
                "Y_test = df_values_Y.iloc[test_indexes.values]\n",
                "Y_holdout = df_values_Y.iloc[holdout_indexes.values]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ea706992",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\n",
                "    Y_train[Y_train == 0].shape,\n",
                "    Y_train[Y_train == 1].shape,\n",
                "    Y_train[Y_train == 2].shape,\n",
                ")\n",
                "print(Y_val[Y_val == 0].shape, Y_val[Y_val == 1].shape, Y_val[Y_val == 2].shape)\n",
                "print(Y_test[Y_test == 0].shape, Y_test[Y_test == 1].shape, Y_test[Y_test == 2].shape)\n",
                "print(\n",
                "    Y_holdout[Y_holdout == 0].shape,\n",
                "    Y_holdout[Y_holdout == 1].shape,\n",
                "    Y_holdout[Y_holdout == 2].shape,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "42b8cb44",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "99dc42ca",
            "metadata": {},
            "outputs": [],
            "source": [
                "# reset indexes for all dataframes\n",
                "X_train.reset_index(drop=True, inplace=True)\n",
                "X_val.reset_index(drop=True, inplace=True)\n",
                "X_test.reset_index(drop=True, inplace=True)\n",
                "X_holdout.reset_index(drop=True, inplace=True)\n",
                "\n",
                "Y_train.reset_index(drop=True, inplace=True)\n",
                "Y_val.reset_index(drop=True, inplace=True)\n",
                "Y_test.reset_index(drop=True, inplace=True)\n",
                "Y_holdout.reset_index(drop=True, inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "91c0f8c0",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(X_train.shape, X_val.shape, X_test.shape, X_holdout.shape)\n",
                "print(Y_train.shape, Y_val.shape, Y_test.shape, Y_holdout.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4dfa9d10",
            "metadata": {
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "source": [
                "#### Split Data - All Models can proceed through this point"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "aa28922f",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-08-18T18:02:26.214603Z",
                    "iopub.status.busy": "2023-08-18T18:02:26.214181Z",
                    "iopub.status.idle": "2023-08-18T18:02:26.355468Z",
                    "shell.execute_reply": "2023-08-18T18:02:26.354945Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# produce data objects for train, val and test datasets\n",
                "train_data = Dataset_formatter(\n",
                "    torch.FloatTensor(X_train.values), torch.FloatTensor(Y_train.values)\n",
                ")\n",
                "val_data = Dataset_formatter(\n",
                "    torch.FloatTensor(X_val.values), torch.FloatTensor(Y_val.values)\n",
                ")\n",
                "test_data = Dataset_formatter(\n",
                "    torch.FloatTensor(X_test.values), torch.FloatTensor(Y_test.values)\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7c628ee1",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-08-18T18:02:26.368928Z",
                    "iopub.status.busy": "2023-08-18T18:02:26.368608Z",
                    "iopub.status.idle": "2023-08-18T18:02:26.374145Z",
                    "shell.execute_reply": "2023-08-18T18:02:26.373695Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "mlp_params.IN_FEATURES = X_train.shape[1]\n",
                "print(\"Number of in features: \", mlp_params.IN_FEATURES)\n",
                "if mlp_params.MODEL_TYPE == \"Regression\":\n",
                "    mlp_params.OUT_FEATURES = 1\n",
                "else:\n",
                "    mlp_params.OUT_FEATURES = len(df_values[\"labels\"].unique())\n",
                "\n",
                "print(\"Number of out features: \", mlp_params.OUT_FEATURES)\n",
                "\n",
                "if mlp_params.OUT_FEATURES > 2:\n",
                "    mlp_params.MODEL_TYPE = \"Multi_Class\"\n",
                "elif mlp_params.OUT_FEATURES == 2:\n",
                "    mlp_params.OUT_FEATURES = mlp_params.OUT_FEATURES - 1\n",
                "    mlp_params.MODEL_TYPE = \"Binary_Classification\"\n",
                "elif mlp_params.OUT_FEATURES == 1:\n",
                "    mlp_params.MODEL_TYPE = \"Regression\"\n",
                "else:\n",
                "    pass\n",
                "print(mlp_params.MODEL_TYPE)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "35e3c505",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-08-18T18:02:26.386004Z",
                    "iopub.status.busy": "2023-08-18T18:02:26.385649Z",
                    "iopub.status.idle": "2023-08-18T18:02:26.388855Z",
                    "shell.execute_reply": "2023-08-18T18:02:26.388450Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# convert data class into a dataloader to be compatible with pytorch\n",
                "train_loader = torch.utils.data.DataLoader(\n",
                "    dataset=train_data, batch_size=mlp_params.BATCH_SIZE, shuffle=mlp_params.SHUFFLE\n",
                ")\n",
                "valid_loader = torch.utils.data.DataLoader(\n",
                "    dataset=val_data, batch_size=mlp_params.BATCH_SIZE, shuffle=mlp_params.SHUFFLE\n",
                ")\n",
                "test_loader = torch.utils.data.DataLoader(\n",
                "    dataset=test_data, batch_size=1, shuffle=mlp_params.SHUFFLE\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4ab763c4",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-08-18T18:02:26.400664Z",
                    "iopub.status.busy": "2023-08-18T18:02:26.400329Z",
                    "iopub.status.idle": "2023-08-18T18:07:21.469351Z",
                    "shell.execute_reply": "2023-08-18T18:07:21.468771Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# call the optimized training model\n",
                "train_loss, train_acc, valid_loss, valid_acc, epochs_ran, model = train_optimized_model(\n",
                "    mlp_params.TRAIN_EPOCHS,\n",
                "    train_loader,\n",
                "    valid_loader,\n",
                "    params,\n",
                "    mlp_params.MODEL_NAME,\n",
                "    mlp_params.SHUFFLE,\n",
                "    class_weights=class_weights,\n",
                ")\n",
                "# get training_metrics\n",
                "if mlp_params.MODEL_TYPE == \"Regression\":\n",
                "    training_stats = pd.DataFrame(\n",
                "        zip(train_loss, valid_loss, epochs_ran),\n",
                "        columns=[\"train_loss\", \"valid_loss\", \"epochs_ran\"],\n",
                "    )\n",
                "else:\n",
                "    training_stats = pd.DataFrame(\n",
                "        zip(train_loss, train_acc, valid_loss, valid_acc, epochs_ran),\n",
                "        columns=[\"train_loss\", \"train_acc\", \"valid_loss\", \"valid_acc\", \"epochs_ran\"],\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3d5115e3",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-08-18T18:07:21.496512Z",
                    "iopub.status.busy": "2023-08-18T18:07:21.495991Z",
                    "iopub.status.idle": "2023-08-18T18:07:21.532582Z",
                    "shell.execute_reply": "2023-08-18T18:07:21.532113Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# create a dataframe to store the model stats\n",
                "model_stats_df = pd.DataFrame(\n",
                "    columns=[\n",
                "        \"label\",\n",
                "        \"metric\",\n",
                "        \"value\",\n",
                "        \"group\",\n",
                "        \"shuffled_data\",\n",
                "    ]\n",
                ")\n",
                "# check empty dataframe\n",
                "model_stats_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d4f283d4",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-08-18T18:07:21.560470Z",
                    "iopub.status.busy": "2023-08-18T18:07:21.559840Z",
                    "iopub.status.idle": "2023-08-18T18:07:22.063995Z",
                    "shell.execute_reply": "2023-08-18T18:07:22.063372Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "if mlp_params.MODEL_TYPE == \"Regression\":\n",
                "    pass\n",
                "else:\n",
                "    plot_metric_vs_epoch(\n",
                "        training_stats,\n",
                "        x=\"epochs_ran\",\n",
                "        y1=\"train_acc\",\n",
                "        y2=\"valid_acc\",\n",
                "        title=\"Accuracy vs. Epochs\",\n",
                "        x_axis_label=\"Epochs\",\n",
                "        y_axis_label=\"Accuracy\",\n",
                "        params=params,\n",
                "        model_name=mlp_params.MODEL_NAME,\n",
                "        shuffle=mlp_params.SHUFFLE,\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5e491e00",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-08-18T18:07:22.097974Z",
                    "iopub.status.busy": "2023-08-18T18:07:22.097445Z",
                    "iopub.status.idle": "2023-08-18T18:07:22.396234Z",
                    "shell.execute_reply": "2023-08-18T18:07:22.395649Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "plot_metric_vs_epoch(\n",
                "    training_stats,\n",
                "    x=\"epochs_ran\",\n",
                "    y1=\"train_loss\",\n",
                "    y2=\"valid_loss\",\n",
                "    title=\"Loss vs. Epochs\",\n",
                "    x_axis_label=\"Epochs\",\n",
                "    y_axis_label=\"Loss\",\n",
                "    params=params,\n",
                "    model_name=mlp_params.MODEL_NAME,\n",
                "    shuffle=mlp_params.SHUFFLE,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1d6993ae",
            "metadata": {},
            "source": [
                "### Test Models on training data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9c595792",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-08-18T18:07:22.431650Z",
                    "iopub.status.busy": "2023-08-18T18:07:22.431265Z",
                    "iopub.status.idle": "2023-08-18T18:07:25.400014Z",
                    "shell.execute_reply": "2023-08-18T18:07:25.399178Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# test the model on training data\n",
                "# calling the testing function and outputting list values of tested model\n",
                "if any(\n",
                "    model_type == mlp_params.MODEL_TYPE for model_type in [\"Multi_Class\", \"Regression\"]\n",
                "):\n",
                "    y_pred_list = test_optimized_model(\n",
                "        model,\n",
                "        train_loader,\n",
                "        mlp_params,\n",
                "        model_name=mlp_params.MODEL_NAME,\n",
                "        shuffle=mlp_params.SHUFFLE,\n",
                "    )\n",
                "elif mlp_params.MODEL_TYPE == \"Binary_Classification\":\n",
                "    y_pred_list, y_pred_prob_list = test_optimized_model(\n",
                "        model,\n",
                "        train_loader,\n",
                "        mlp_params,\n",
                "        model_name=mlp_params.MODEL_NAME,\n",
                "        shuffle=mlp_params.SHUFFLE,\n",
                "    )\n",
                "else:\n",
                "    raise Exception(\"Model type must be specified for proper model testing\")\n",
                "\n",
                "# un-nest list if nested i.e. length of input data does not match length of output data\n",
                "if len(y_pred_list) != len(Y_test):\n",
                "    y_pred_list = un_nest(y_pred_list)\n",
                "    if mlp_params.MODEL_TYPE == \"Binary_Classification\":\n",
                "        y_pred_prob_list = un_nest(y_pred_prob_list)\n",
                "else:\n",
                "    pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4b269c1d",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-08-18T18:07:25.452781Z",
                    "iopub.status.busy": "2023-08-18T18:07:25.452411Z",
                    "iopub.status.idle": "2023-08-18T18:07:28.834781Z",
                    "shell.execute_reply": "2023-08-18T18:07:28.833953Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "stats_df = output_stats(\n",
                "    y_pred_list,\n",
                "    Y_train,\n",
                "    mlp_params,\n",
                "    test_name=f\"{mlp_params.MODEL_NAME}_train\",\n",
                "    model_name=mlp_params.MODEL_NAME,\n",
                "    title=mlp_params.MODEL_NAME,\n",
                "    shuffle=mlp_params.SHUFFLE,\n",
                ")\n",
                "# make into a dataframe\n",
                "stats_df = pd.DataFrame.from_dict(stats_df).transpose()\n",
                "stats_df.reset_index(inplace=True)\n",
                "stats_df.rename(columns={\"index\": \"label\"}, inplace=True)\n",
                "stats_df = stats_df.melt(id_vars=[\"label\"], var_name=\"metric\", value_name=\"value\")\n",
                "# if accuracy in row of column 1 then change value of column 2 to accuracy\n",
                "stats_df.loc[stats_df[\"label\"] == \"accuracy\", \"metric\"] = \"accuracy\"\n",
                "# create a decoder dictionary from df_labels\n",
                "df_labels[\"new_labels\"] = df_labels[\"new_labels\"].astype(str)\n",
                "decoder = df_labels.set_index(\"new_labels\").to_dict()[\"labels\"]\n",
                "decoder[\"accuracy\"] = \"accuracy\"\n",
                "decoder[\"macro avg\"] = \"macro avg\"\n",
                "decoder[\"weighted avg\"] = \"weighted avg\"\n",
                "stats_df[\"label\"] = stats_df[\"label\"].map(decoder)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fdde3d70",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-08-18T18:07:28.885930Z",
                    "iopub.status.busy": "2023-08-18T18:07:28.885661Z",
                    "iopub.status.idle": "2023-08-18T18:07:28.904686Z",
                    "shell.execute_reply": "2023-08-18T18:07:28.904041Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "stats_df[\"group\"] = \"train\"\n",
                "stats_df[\"shuffled_data\"] = mlp_params.SHUFFLE\n",
                "stats_df\n",
                "model_stats_df = pd.concat([model_stats_df, stats_df], axis=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dd00a92e",
            "metadata": {},
            "source": [
                "### Test models on Validation data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "52b5399f",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-08-18T18:07:28.939348Z",
                    "iopub.status.busy": "2023-08-18T18:07:28.938980Z",
                    "iopub.status.idle": "2023-08-18T18:07:29.285555Z",
                    "shell.execute_reply": "2023-08-18T18:07:29.285024Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# test the model on training data\n",
                "# calling the testing function and outputting list values of tested model\n",
                "if any(\n",
                "    model_type == mlp_params.MODEL_TYPE for model_type in [\"Multi_Class\", \"Regression\"]\n",
                "):\n",
                "    y_pred_list = test_optimized_model(\n",
                "        model,\n",
                "        valid_loader,\n",
                "        mlp_params,\n",
                "        model_name=mlp_params.MODEL_NAME,\n",
                "        shuffle=mlp_params.SHUFFLE,\n",
                "    )\n",
                "elif mlp_params.MODEL_TYPE == \"Binary_Classification\":\n",
                "    y_pred_list, y_pred_prob_list = test_optimized_model(\n",
                "        model,\n",
                "        valid_loader,\n",
                "        mlp_params,\n",
                "        model_name=mlp_params.MODEL_NAME,\n",
                "        shuffle=mlp_params.SHUFFLE,\n",
                "    )\n",
                "else:\n",
                "    raise Exception(\"Model type must be specified for proper model testing\")\n",
                "\n",
                "# un-nest list if nested i.e. length of input data does not match length of output data\n",
                "if len(y_pred_list) != len(Y_test):\n",
                "    y_pred_list = un_nest(y_pred_list)\n",
                "    if mlp_params.MODEL_TYPE == \"Binary_Classification\":\n",
                "        y_pred_prob_list = un_nest(y_pred_prob_list)\n",
                "else:\n",
                "    pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "444b8e3e",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-08-18T18:07:29.341721Z",
                    "iopub.status.busy": "2023-08-18T18:07:29.341405Z",
                    "iopub.status.idle": "2023-08-18T18:07:29.553197Z",
                    "shell.execute_reply": "2023-08-18T18:07:29.552613Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "stats_df = output_stats(\n",
                "    y_pred_list,\n",
                "    Y_val,\n",
                "    mlp_params,\n",
                "    test_name=f\"{mlp_params.MODEL_NAME}_train\",\n",
                "    model_name=mlp_params.MODEL_NAME,\n",
                "    title=mlp_params.MODEL_NAME,\n",
                "    shuffle=mlp_params.SHUFFLE,\n",
                ")\n",
                "# make into a dataframe\n",
                "stats_df = pd.DataFrame.from_dict(stats_df).transpose()\n",
                "stats_df.reset_index(inplace=True)\n",
                "stats_df.rename(columns={\"index\": \"label\"}, inplace=True)\n",
                "stats_df = stats_df.melt(id_vars=[\"label\"], var_name=\"metric\", value_name=\"value\")\n",
                "# if accuracy in row of column 1 then change value of column 2 to accuracy\n",
                "stats_df.loc[stats_df[\"label\"] == \"accuracy\", \"metric\"] = \"accuracy\"\n",
                "# create a decoder dictionary from df_labels\n",
                "df_labels[\"new_labels\"] = df_labels[\"new_labels\"].astype(str)\n",
                "decoder = df_labels.set_index(\"new_labels\").to_dict()[\"labels\"]\n",
                "decoder[\"accuracy\"] = \"accuracy\"\n",
                "decoder[\"macro avg\"] = \"macro avg\"\n",
                "decoder[\"weighted avg\"] = \"weighted avg\"\n",
                "stats_df[\"label\"] = stats_df[\"label\"].map(decoder)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2573e7a6",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-08-18T18:07:29.574980Z",
                    "iopub.status.busy": "2023-08-18T18:07:29.574587Z",
                    "iopub.status.idle": "2023-08-18T18:07:29.592044Z",
                    "shell.execute_reply": "2023-08-18T18:07:29.591512Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "stats_df[\"group\"] = \"validation\"\n",
                "stats_df[\"shuffled_data\"] = mlp_params.SHUFFLE\n",
                "\n",
                "model_stats_df = pd.concat([model_stats_df, stats_df], axis=0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f179b14f",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-08-18T18:07:29.614554Z",
                    "iopub.status.busy": "2023-08-18T18:07:29.614173Z",
                    "iopub.status.idle": "2023-08-18T18:07:29.617863Z",
                    "shell.execute_reply": "2023-08-18T18:07:29.617415Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "mlp_params.MODEL_NAME"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b1a18529",
            "metadata": {},
            "source": [
                "### Testing on the test data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5b5e76f8",
            "metadata": {},
            "outputs": [],
            "source": [
                "# create a dataframe to store the model confusion matrix\n",
                "data_split_conf_mat_df_all = pd.DataFrame(\n",
                "    columns=[\"True_Label\", \"Predicted_Label\", \"Count\", \"data_split\", \"Recall\"]\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d30cef39",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-08-18T18:07:29.639335Z",
                    "iopub.status.busy": "2023-08-18T18:07:29.638900Z",
                    "iopub.status.idle": "2023-08-18T18:07:33.734569Z",
                    "shell.execute_reply": "2023-08-18T18:07:33.734048Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# calling the testing function and outputting list values of tested model\n",
                "if any(\n",
                "    model_type == mlp_params.MODEL_TYPE for model_type in [\"Multi_Class\", \"Regression\"]\n",
                "):\n",
                "    y_pred_list = test_optimized_model(\n",
                "        model,\n",
                "        test_loader,\n",
                "        params,\n",
                "        model_name=mlp_params.MODEL_NAME,\n",
                "        shuffle=mlp_params.SHUFFLE,\n",
                "    )\n",
                "elif mlp_params.MODEL_TYPE == \"Binary_Classification\":\n",
                "    y_pred_list, y_pred_prob_list = test_optimized_model(\n",
                "        model,\n",
                "        test_loader,\n",
                "        params,\n",
                "        model_name=mlp_params.MODEL_NAME,\n",
                "        shuffle=mlp_params.SHUFFLE,\n",
                "    )\n",
                "else:\n",
                "    raise Exception(\"Model type must be specified for proper model testing\")\n",
                "\n",
                "\n",
                "# un-nest list if nested i.e. length of input data does not match length of output data\n",
                "if len(y_pred_list) != len(Y_test):\n",
                "    y_pred_list = un_nest(y_pred_list)\n",
                "    if mlp_params.MODEL_TYPE == \"Binary_Classification\":\n",
                "        y_pred_prob_list = un_nest(y_pred_prob_list)\n",
                "else:\n",
                "    pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ba2c00bd",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-08-18T18:07:33.760660Z",
                    "iopub.status.busy": "2023-08-18T18:07:33.760204Z",
                    "iopub.status.idle": "2023-08-18T18:07:34.366964Z",
                    "shell.execute_reply": "2023-08-18T18:07:34.366542Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# Call visualization function\n",
                "# calling the testing function and outputing list values of tested model\n",
                "if any(\n",
                "    model_type == mlp_params.MODEL_TYPE for model_type in [\"Multi_Class\", \"Regression\"]\n",
                "):\n",
                "    confusion_matrix_df = results_output(\n",
                "        y_pred_list,\n",
                "        Y_test,\n",
                "        params,\n",
                "        test_name=f\"{mlp_params.MODEL_NAME}_testing\",\n",
                "        model_name=mlp_params.MODEL_NAME,\n",
                "        title=mlp_params.MODEL_NAME,\n",
                "        shuffle=mlp_params.SHUFFLE,\n",
                "    )\n",
                "elif mlp_params.MODEL_TYPE == \"Binary_Classification\":\n",
                "    results_output(\n",
                "        y_pred_list,\n",
                "        Y_test,\n",
                "        params,\n",
                "        y_pred_prob_list,\n",
                "        test_name=f\"{mlp_params.MODEL_NAME}_testing\",\n",
                "        model_name=mlp_params.MODEL_NAME,\n",
                "        title=mlp_params.MODEL_NAME,\n",
                "        shuffle=mlp_params.SHUFFLE,\n",
                "    )\n",
                "else:\n",
                "    raise Exception(\"Model type must be specified for proper model testing\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7d74124b",
            "metadata": {},
            "outputs": [],
            "source": [
                "# rename columns from the decoder dictionary\n",
                "confusion_matrix_df.rename(\n",
                "    columns={0: \"apoptosis\", 1: \"healthy\", 2: \"pyroptosis\"}, inplace=True\n",
                ")\n",
                "# rename index from the decoder dictionary\n",
                "confusion_matrix_df.rename(\n",
                "    index={0: \"apoptosis\", 1: \"healthy\", 2: \"pyroptosis\"}, inplace=True\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a570c014",
            "metadata": {},
            "outputs": [],
            "source": [
                "confusion_matrices = confusion_matrix_df.reset_index()\n",
                "# melt the DataFrame to a long format\n",
                "confusion_matrices = pd.melt(\n",
                "    confusion_matrices,\n",
                "    id_vars=[\"index\"],\n",
                "    value_vars=[\"healthy\", \"apoptosis\", \"pyroptosis\"],\n",
                ")\n",
                "\n",
                "# rename the columns\n",
                "confusion_matrices.columns = [\"True_Label\", \"Predicted_Label\", \"Count\"]\n",
                "confusion_matrices[\"data_split\"] = \"holdout\"\n",
                "# sum of the columns of the confusion matrix gives the total number of samples per class\n",
                "sum_of_columns = confusion_matrix_df.sum(axis=0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "09c57815",
            "metadata": {},
            "outputs": [],
            "source": [
                "# normalize confusion matrix\n",
                "# get the sum of each column to normalize the confusion matrix by the total number of samples per class\n",
                "\n",
                "# divide the apotosis column by the sum of the apotosis column\n",
                "confusion_matrix_df[\"apoptosis\"] = confusion_matrix_df[\"apoptosis\"] / sum_of_columns[0]\n",
                "# divide the healthy column by the sum of the healthy column\n",
                "confusion_matrix_df[\"healthy\"] = confusion_matrix_df[\"healthy\"] / sum_of_columns[1]\n",
                "# divide the pyroptosis column by the sum of the pyroptosis column\n",
                "confusion_matrix_df[\"pyroptosis\"] = (\n",
                "    confusion_matrix_df[\"pyroptosis\"] / sum_of_columns[2]\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b44241ba",
            "metadata": {},
            "outputs": [],
            "source": [
                "# change the order of the columns\n",
                "confusion_matrix_df = confusion_matrix_df[[\"healthy\", \"apoptosis\", \"pyroptosis\"]]\n",
                "# change the order of the index\n",
                "confusion_matrix_df = confusion_matrix_df.reindex(\n",
                "    index=[\"healthy\", \"apoptosis\", \"pyroptosis\"]\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b394f6ad",
            "metadata": {},
            "outputs": [],
            "source": [
                "confusion_matrices_recall = confusion_matrix_df.reset_index()\n",
                "# melt the DataFrame to a long format\n",
                "confusion_matrices_recall = pd.melt(\n",
                "    confusion_matrices_recall,\n",
                "    id_vars=[\"index\"],\n",
                "    value_vars=[\"healthy\", \"apoptosis\", \"pyroptosis\"],\n",
                ")\n",
                "\n",
                "# rename the columns\n",
                "confusion_matrices_recall.columns = [\"True_Label\", \"Predicted_Label\", \"Count\"]\n",
                "confusion_matrices_recall[\"data_split\"] = \"holdout\"\n",
                "confusion_matrices_recall.rename(columns={\"Count\": \"Recall\"}, inplace=True)\n",
                "data_split_conf_mat_df = pd.merge(\n",
                "    confusion_matrices,\n",
                "    confusion_matrices_recall,\n",
                "    on=[\"True_Label\", \"Predicted_Label\", \"data_split\"],\n",
                ")\n",
                "data_split_conf_mat_df_all = pd.concat(\n",
                "    [data_split_conf_mat_df_all, data_split_conf_mat_df], axis=0\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d40e590c",
            "metadata": {},
            "outputs": [],
            "source": [
                "confusion_matrix_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1ff8a8fd",
            "metadata": {},
            "outputs": [],
            "source": [
                "ax = sns.heatmap(confusion_matrix_df, annot=True)\n",
                "ax.invert_xaxis()\n",
                "ax.invert_yaxis()\n",
                "plt.xlabel(\"Actual Values\", size=15)\n",
                "plt.ylabel(\"Predicted Values\", size=15)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6e9b9cc1",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-08-18T18:07:34.455389Z",
                    "iopub.status.busy": "2023-08-18T18:07:34.455037Z",
                    "iopub.status.idle": "2023-08-18T18:07:34.616814Z",
                    "shell.execute_reply": "2023-08-18T18:07:34.616373Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "stats_df = output_stats(\n",
                "    y_pred_list,\n",
                "    Y_test,\n",
                "    mlp_params,\n",
                "    test_name=f\"{mlp_params.MODEL_NAME}_train\",\n",
                "    model_name=mlp_params.MODEL_NAME,\n",
                "    title=mlp_params.MODEL_NAME,\n",
                "    shuffle=mlp_params.SHUFFLE,\n",
                ")\n",
                "# make into a dataframe\n",
                "stats_df = pd.DataFrame.from_dict(stats_df).transpose()\n",
                "stats_df.reset_index(inplace=True)\n",
                "stats_df.rename(columns={\"index\": \"label\"}, inplace=True)\n",
                "stats_df = stats_df.melt(id_vars=[\"label\"], var_name=\"metric\", value_name=\"value\")\n",
                "# if accuracy in row of column 1 then change value of column 2 to accuracy\n",
                "stats_df.loc[stats_df[\"label\"] == \"accuracy\", \"metric\"] = \"accuracy\"\n",
                "# create a decoder dictionary from df_labels\n",
                "df_labels[\"new_labels\"] = df_labels[\"new_labels\"].astype(str)\n",
                "decoder = df_labels.set_index(\"new_labels\").to_dict()[\"labels\"]\n",
                "decoder[\"accuracy\"] = \"accuracy\"\n",
                "decoder[\"macro avg\"] = \"macro avg\"\n",
                "decoder[\"weighted avg\"] = \"weighted avg\"\n",
                "stats_df[\"label\"] = stats_df[\"label\"].map(decoder)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5e49a4d0",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-08-18T18:07:34.640121Z",
                    "iopub.status.busy": "2023-08-18T18:07:34.639772Z",
                    "iopub.status.idle": "2023-08-18T18:07:34.649248Z",
                    "shell.execute_reply": "2023-08-18T18:07:34.648773Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "stats_df[\"group\"] = \"test\"\n",
                "stats_df[\"shuffled_data\"] = mlp_params.SHUFFLE\n",
                "\n",
                "model_stats_df = pd.concat([model_stats_df, stats_df], axis=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bd07fbb7",
            "metadata": {
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "source": [
                "## Test the hold out wells"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3c45de2b",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-08-18T18:07:34.913932Z",
                    "iopub.status.busy": "2023-08-18T18:07:34.913660Z",
                    "iopub.status.idle": "2023-08-18T18:07:44.681233Z",
                    "shell.execute_reply": "2023-08-18T18:07:44.680781Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "holdout_data = Dataset_formatter(\n",
                "    torch.FloatTensor(X_holdout.values), torch.FloatTensor(Y_holdout.values)\n",
                ")\n",
                "\n",
                "# convert data class into a dataloader to be compatible with pytorch\n",
                "holdout_loader = torch.utils.data.DataLoader(\n",
                "    dataset=holdout_data, batch_size=1, shuffle=mlp_params.SHUFFLE\n",
                ")\n",
                "\n",
                "# calling the testing function and outputting list values of tested model\n",
                "if any(\n",
                "    model_type == mlp_params.MODEL_TYPE for model_type in [\"Multi_Class\", \"Regression\"]\n",
                "):\n",
                "    y_pred_list = test_optimized_model(\n",
                "        model,\n",
                "        holdout_loader,\n",
                "        params,\n",
                "        model_name=mlp_params.MODEL_NAME,\n",
                "        shuffle=mlp_params.SHUFFLE,\n",
                "    )\n",
                "elif mlp_params.MODEL_TYPE == \"Binary_Classification\":\n",
                "    y_pred_list, y_pred_prob_list = test_optimized_model(\n",
                "        model,\n",
                "        holdout_loader,\n",
                "        params,\n",
                "        model_name=mlp_params.MODEL_NAME,\n",
                "        shuffle=mlp_params.SHUFFLE,\n",
                "    )\n",
                "else:\n",
                "    raise Exception(\"Model type must be specified for proper model testing\")\n",
                "\n",
                "# un-nest list if nested i.e. length of input data does not match length of output data\n",
                "if len(y_pred_list) != len(Y_holdout):\n",
                "    y_pred_list = un_nest(y_pred_list)\n",
                "    if mlp_params.MODEL_TYPE == \"Binary_Classification\":\n",
                "        y_pred_prob_list = un_nest(y_pred_prob_list)\n",
                "else:\n",
                "    pass\n",
                "\n",
                "# Call visualization function\n",
                "# calling the testing function and outputing list values of tested model\n",
                "if any(\n",
                "    model_type == mlp_params.MODEL_TYPE for model_type in [\"Multi_Class\", \"Regression\"]\n",
                "):\n",
                "    confusion_matrix_df = results_output(\n",
                "        y_pred_list,\n",
                "        Y_holdout,\n",
                "        params,\n",
                "        test_name=f\"{mlp_params.MODEL_NAME}_hold_out\",\n",
                "        model_name=mlp_params.MODEL_NAME,\n",
                "        title=mlp_params.MODEL_NAME,\n",
                "        shuffle=mlp_params.SHUFFLE,\n",
                "    )\n",
                "elif mlp_params.MODEL_TYPE == \"Binary_Classification\":\n",
                "    results_output(\n",
                "        y_pred_list,\n",
                "        Y_holdout,\n",
                "        params,\n",
                "        y_pred_prob_list,\n",
                "        test_name=f\"{mlp_params.MODEL_NAME}_hold_out\",\n",
                "        model_name=mlp_params.MODEL_NAME,\n",
                "        title=mlp_params.MODEL_NAME,\n",
                "        shuffle=mlp_params.SHUFFLE,\n",
                "    )\n",
                "else:\n",
                "    raise Exception(\"Model type must be specified for proper model testing\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "075f1ff0",
            "metadata": {},
            "outputs": [],
            "source": [
                "# rename columns from the decoder dictionary\n",
                "confusion_matrix_df.rename(\n",
                "    columns={0: \"apoptosis\", 1: \"healthy\", 2: \"pyroptosis\"}, inplace=True\n",
                ")\n",
                "# rename index from the decoder dictionary\n",
                "confusion_matrix_df.rename(\n",
                "    index={0: \"apoptosis\", 1: \"healthy\", 2: \"pyroptosis\"}, inplace=True\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "eb3690d8",
            "metadata": {},
            "outputs": [],
            "source": [
                "confusion_matrices = confusion_matrix_df.reset_index()\n",
                "# melt the DataFrame to a long format\n",
                "confusion_matrices = pd.melt(\n",
                "    confusion_matrices,\n",
                "    id_vars=[\"index\"],\n",
                "    value_vars=[\"healthy\", \"apoptosis\", \"pyroptosis\"],\n",
                ")\n",
                "\n",
                "# rename the columns\n",
                "confusion_matrices.columns = [\"True_Label\", \"Predicted_Label\", \"Count\"]\n",
                "confusion_matrices[\"data_split\"] = \"holdout\"\n",
                "# sum of the columns of the confusion matrix gives the total number of samples per class\n",
                "sum_of_columns = confusion_matrix_df.sum(axis=0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "31d1f6af",
            "metadata": {},
            "outputs": [],
            "source": [
                "# normalize confusion matrix\n",
                "# get the sum of each column to normalize the confusion matrix by the total number of samples per class\n",
                "\n",
                "# divide the apotosis column by the sum of the apotosis column\n",
                "confusion_matrix_df[\"apoptosis\"] = confusion_matrix_df[\"apoptosis\"] / sum_of_columns[0]\n",
                "# divide the healthy column by the sum of the healthy column\n",
                "confusion_matrix_df[\"healthy\"] = confusion_matrix_df[\"healthy\"] / sum_of_columns[1]\n",
                "# divide the pyroptosis column by the sum of the pyroptosis column\n",
                "confusion_matrix_df[\"pyroptosis\"] = (\n",
                "    confusion_matrix_df[\"pyroptosis\"] / sum_of_columns[2]\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cfe647ce",
            "metadata": {},
            "outputs": [],
            "source": [
                "# change the order of the columns\n",
                "confusion_matrix_df = confusion_matrix_df[[\"healthy\", \"apoptosis\", \"pyroptosis\"]]\n",
                "# change the order of the index\n",
                "confusion_matrix_df = confusion_matrix_df.reindex(\n",
                "    index=[\"healthy\", \"apoptosis\", \"pyroptosis\"]\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "001cd8ef",
            "metadata": {},
            "outputs": [],
            "source": [
                "confusion_matrices_recall = confusion_matrix_df.reset_index()\n",
                "# melt the DataFrame to a long format\n",
                "confusion_matrices_recall = pd.melt(\n",
                "    confusion_matrices_recall,\n",
                "    id_vars=[\"index\"],\n",
                "    value_vars=[\"healthy\", \"apoptosis\", \"pyroptosis\"],\n",
                ")\n",
                "\n",
                "# rename the columns\n",
                "confusion_matrices_recall.columns = [\"True_Label\", \"Predicted_Label\", \"Count\"]\n",
                "confusion_matrices_recall[\"data_split\"] = \"holdout\"\n",
                "confusion_matrices_recall.rename(columns={\"Count\": \"Recall\"}, inplace=True)\n",
                "data_split_conf_mat_df = pd.merge(\n",
                "    confusion_matrices,\n",
                "    confusion_matrices_recall,\n",
                "    on=[\"True_Label\", \"Predicted_Label\", \"data_split\"],\n",
                ")\n",
                "data_split_conf_mat_df_all = pd.concat(\n",
                "    [data_split_conf_mat_df_all, data_split_conf_mat_df], axis=0\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7c326b32",
            "metadata": {},
            "outputs": [],
            "source": [
                "ax = sns.heatmap(confusion_matrix_df, annot=True)\n",
                "\n",
                "plt.xlabel(\"Actual Values\", size=15)\n",
                "plt.ylabel(\"Predicted Values\", size=15)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d9c38144",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-08-18T18:07:44.709508Z",
                    "iopub.status.busy": "2023-08-18T18:07:44.709067Z",
                    "iopub.status.idle": "2023-08-18T18:07:45.015420Z",
                    "shell.execute_reply": "2023-08-18T18:07:45.014993Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "stats_df = output_stats(\n",
                "    y_pred_list,\n",
                "    Y_holdout,\n",
                "    mlp_params,\n",
                "    test_name=f\"{mlp_params.MODEL_NAME}_train\",\n",
                "    model_name=mlp_params.MODEL_NAME,\n",
                "    title=mlp_params.MODEL_NAME,\n",
                "    shuffle=mlp_params.SHUFFLE,\n",
                ")\n",
                "# make into a dataframe\n",
                "stats_df = pd.DataFrame.from_dict(stats_df).transpose()\n",
                "stats_df.reset_index(inplace=True)\n",
                "stats_df.rename(columns={\"index\": \"label\"}, inplace=True)\n",
                "stats_df = stats_df.melt(id_vars=[\"label\"], var_name=\"metric\", value_name=\"value\")\n",
                "# if accuracy in row of column 1 then change value of column 2 to accuracy\n",
                "stats_df.loc[stats_df[\"label\"] == \"accuracy\", \"metric\"] = \"accuracy\"\n",
                "# create a decoder dictionary from df_labels\n",
                "df_labels[\"new_labels\"] = df_labels[\"new_labels\"].astype(str)\n",
                "decoder = df_labels.set_index(\"new_labels\").to_dict()[\"labels\"]\n",
                "decoder[\"accuracy\"] = \"accuracy\"\n",
                "decoder[\"macro avg\"] = \"macro avg\"\n",
                "decoder[\"weighted avg\"] = \"weighted avg\"\n",
                "stats_df[\"label\"] = stats_df[\"label\"].map(decoder)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "61319294",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-08-18T18:07:45.041316Z",
                    "iopub.status.busy": "2023-08-18T18:07:45.041043Z",
                    "iopub.status.idle": "2023-08-18T18:07:45.052677Z",
                    "shell.execute_reply": "2023-08-18T18:07:45.052239Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "stats_df[\"group\"] = \"holdout\"\n",
                "stats_df[\"shuffled_data\"] = mlp_params.SHUFFLE\n",
                "\n",
                "model_stats_df = pd.concat([model_stats_df, stats_df], axis=0)\n",
                "model_stats_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6320cb8d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# set path for the model confusion matrices\n",
                "matrix_path = pathlib.Path(\n",
                "    f\"../../results/{mlp_params.MODEL_TYPE}/{mlp_params.MODEL_NAME}/{mlp_params.CELL_TYPE}\"\n",
                ")\n",
                "matrix_path.mkdir(parents=True, exist_ok=True)\n",
                "# check if the model training metrics file exists\n",
                "matrix_file = pathlib.Path(f\"{matrix_path}/confusion_matrices.csv\")\n",
                "if matrix_file.exists():\n",
                "    metrics_df = pd.read_csv(matrix_file)\n",
                "    if len(metrics_df[\"shuffled_data\"].unique()) > 1:\n",
                "        pass\n",
                "    elif metrics_df[\"shuffled_data\"].unique() == mlp_params.SHUFFLE:\n",
                "        pass\n",
                "    else:\n",
                "        metrics_df = pd.concat([metrics_df, data_split_conf_mat_df_all], axis=0)\n",
                "        metrics_df.to_csv(matrix_file, index=False)\n",
                "else:\n",
                "    data_split_conf_mat_df_all.to_csv(matrix_file, index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e1e4b224",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-08-18T18:07:45.112412Z",
                    "iopub.status.busy": "2023-08-18T18:07:45.112158Z",
                    "iopub.status.idle": "2023-08-18T18:07:48.147873Z",
                    "shell.execute_reply": "2023-08-18T18:07:48.147334Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# set path for the model training metrics\n",
                "metrics_path = pathlib.Path(\n",
                "    f\"../../results/{mlp_params.MODEL_TYPE}/{mlp_params.MODEL_NAME}/{mlp_params.CELL_TYPE}\"\n",
                ")\n",
                "metrics_path.mkdir(parents=True, exist_ok=True)\n",
                "# check if the model training metrics file exists\n",
                "metrics_file = pathlib.Path(f\"{metrics_path}/training_metrics.csv\")\n",
                "if metrics_file.exists():\n",
                "    metrics_df = pd.read_csv(metrics_file)\n",
                "    if len(metrics_df[\"shuffled_data\"].unique()) > 1:\n",
                "        pass\n",
                "    elif metrics_df[\"shuffled_data\"].unique() == mlp_params.SHUFFLE:\n",
                "        pass\n",
                "    else:\n",
                "        metrics_df = pd.concat([metrics_df, model_stats_df], axis=0)\n",
                "        metrics_df.to_csv(metrics_file, index=False)\n",
                "else:\n",
                "    model_stats_df.to_csv(metrics_file, index=False)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Interstellar",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        },
        "papermill": {
            "default_parameters": {},
            "duration": 13.889414,
            "end_time": "2023-10-18T18:22:08.538383",
            "environment_variables": {},
            "exception": null,
            "input_path": "train_binary_model.ipynb",
            "output_path": "train_binary_model.ipynb",
            "parameters": {
                "CELL_TYPE": "SHSY5Y",
                "CONTROL_NAME": "DMSO_0.100_%_DMSO_0.025_%",
                "MODEL_NAME": "DMSO_0.025_vs_LPS_100",
                "SHUFFLE": true,
                "TREATMENT_NAME": "LPS_100.000_ug_per_ml_DMSO_0.025_%"
            },
            "start_time": "2023-10-18T18:21:54.648969",
            "version": "2.4.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
