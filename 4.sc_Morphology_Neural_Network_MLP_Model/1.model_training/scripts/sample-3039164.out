[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'e0b7bc3b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '46dbbeba'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'c5ccafd1'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '78a5d697'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_0.100_DMSO_0.025 treatment_name: Thapsigargin_10.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: Thapsigargin_10.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (28140, 1276)
Number of total missing values across all columns: 56280
Data Subset Is Off
Wells held out for testing: ['E14' 'L22']
Wells to use for training, validation, and testing ['E15' 'L14' 'L15' 'L18' 'L19' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.600843).  Saving model ...
	 Train_Loss: 0.6587 Train_Acc: 55.535 Val_Loss: 0.6008  BEST VAL Loss: 0.6008  Val_Acc: 68.802

Epoch 1: Validation loss decreased (0.600843 --> 0.541290).  Saving model ...
	 Train_Loss: 0.6029 Train_Acc: 74.043 Val_Loss: 0.5413  BEST VAL Loss: 0.5413  Val_Acc: 84.910

Epoch 2: Validation loss decreased (0.541290 --> 0.500184).  Saving model ...
	 Train_Loss: 0.5609 Train_Acc: 75.936 Val_Loss: 0.5002  BEST VAL Loss: 0.5002  Val_Acc: 85.590

Epoch 3: Validation loss decreased (0.500184 --> 0.470151).  Saving model ...
	 Train_Loss: 0.5315 Train_Acc: 76.463 Val_Loss: 0.4702  BEST VAL Loss: 0.4702  Val_Acc: 86.463

Epoch 4: Validation loss decreased (0.470151 --> 0.447474).  Saving model ...
	 Train_Loss: 0.5098 Train_Acc: 77.149 Val_Loss: 0.4475  BEST VAL Loss: 0.4475  Val_Acc: 87.191

Epoch 5: Validation loss decreased (0.447474 --> 0.429173).  Saving model ...
	 Train_Loss: 0.4923 Train_Acc: 77.919 Val_Loss: 0.4292  BEST VAL Loss: 0.4292  Val_Acc: 87.239

Epoch 6: Validation loss decreased (0.429173 --> 0.413956).  Saving model ...
	 Train_Loss: 0.4774 Train_Acc: 78.514 Val_Loss: 0.4140  BEST VAL Loss: 0.4140  Val_Acc: 87.627

Epoch 7: Validation loss decreased (0.413956 --> 0.401014).  Saving model ...
	 Train_Loss: 0.4649 Train_Acc: 78.981 Val_Loss: 0.4010  BEST VAL Loss: 0.4010  Val_Acc: 87.627

Epoch 8: Validation loss decreased (0.401014 --> 0.389944).  Saving model ...
	 Train_Loss: 0.4547 Train_Acc: 78.574 Val_Loss: 0.3899  BEST VAL Loss: 0.3899  Val_Acc: 87.724

Epoch 9: Validation loss decreased (0.389944 --> 0.380147).  Saving model ...
	 Train_Loss: 0.4451 Train_Acc: 79.466 Val_Loss: 0.3801  BEST VAL Loss: 0.3801  Val_Acc: 88.064

Epoch 10: Validation loss decreased (0.380147 --> 0.371474).  Saving model ...
	 Train_Loss: 0.4364 Train_Acc: 79.824 Val_Loss: 0.3715  BEST VAL Loss: 0.3715  Val_Acc: 88.113

Epoch 11: Validation loss decreased (0.371474 --> 0.363817).  Saving model ...
	 Train_Loss: 0.4288 Train_Acc: 79.970 Val_Loss: 0.3638  BEST VAL Loss: 0.3638  Val_Acc: 88.549

Epoch 12: Validation loss decreased (0.363817 --> 0.356913).  Saving model ...
	 Train_Loss: 0.4215 Train_Acc: 80.485 Val_Loss: 0.3569  BEST VAL Loss: 0.3569  Val_Acc: 88.792

Epoch 13: Validation loss decreased (0.356913 --> 0.350550).  Saving model ...
	 Train_Loss: 0.4145 Train_Acc: 81.043 Val_Loss: 0.3505  BEST VAL Loss: 0.3505  Val_Acc: 88.937

Epoch 14: Validation loss decreased (0.350550 --> 0.344648).  Saving model ...
	 Train_Loss: 0.4082 Train_Acc: 81.140 Val_Loss: 0.3446  BEST VAL Loss: 0.3446  Val_Acc: 89.326

Epoch 15: Validation loss decreased (0.344648 --> 0.339223).  Saving model ...
	 Train_Loss: 0.4024 Train_Acc: 81.001 Val_Loss: 0.3392  BEST VAL Loss: 0.3392  Val_Acc: 89.568

Epoch 16: Validation loss decreased (0.339223 --> 0.334183).  Saving model ...
	 Train_Loss: 0.3972 Train_Acc: 81.122 Val_Loss: 0.3342  BEST VAL Loss: 0.3342  Val_Acc: 90.005

Epoch 17: Validation loss decreased (0.334183 --> 0.329470).  Saving model ...
	 Train_Loss: 0.3920 Train_Acc: 81.547 Val_Loss: 0.3295  BEST VAL Loss: 0.3295  Val_Acc: 90.005

Epoch 18: Validation loss decreased (0.329470 --> 0.325134).  Saving model ...
	 Train_Loss: 0.3874 Train_Acc: 81.213 Val_Loss: 0.3251  BEST VAL Loss: 0.3251  Val_Acc: 90.247

Epoch 19: Validation loss decreased (0.325134 --> 0.321130).  Saving model ...
	 Train_Loss: 0.3831 Train_Acc: 81.256 Val_Loss: 0.3211  BEST VAL Loss: 0.3211  Val_Acc: 90.393

Epoch 20: Validation loss decreased (0.321130 --> 0.317305).  Saving model ...
	 Train_Loss: 0.3789 Train_Acc: 81.753 Val_Loss: 0.3173  BEST VAL Loss: 0.3173  Val_Acc: 90.587

Epoch 21: Validation loss decreased (0.317305 --> 0.313701).  Saving model ...
	 Train_Loss: 0.3747 Train_Acc: 81.771 Val_Loss: 0.3137  BEST VAL Loss: 0.3137  Val_Acc: 90.878

Epoch 22: Validation loss decreased (0.313701 --> 0.310295).  Saving model ...
	 Train_Loss: 0.3708 Train_Acc: 81.777 Val_Loss: 0.3103  BEST VAL Loss: 0.3103  Val_Acc: 91.072

Epoch 23: Validation loss decreased (0.310295 --> 0.307039).  Saving model ...
	 Train_Loss: 0.3670 Train_Acc: 82.342 Val_Loss: 0.3070  BEST VAL Loss: 0.3070  Val_Acc: 90.878

Epoch 24: Validation loss decreased (0.307039 --> 0.303914).  Saving model ...
	 Train_Loss: 0.3633 Train_Acc: 82.293 Val_Loss: 0.3039  BEST VAL Loss: 0.3039  Val_Acc: 91.121

Epoch 25: Validation loss decreased (0.303914 --> 0.300959).  Saving model ...
	 Train_Loss: 0.3599 Train_Acc: 82.426 Val_Loss: 0.3010  BEST VAL Loss: 0.3010  Val_Acc: 91.266

Epoch 26: Validation loss decreased (0.300959 --> 0.298159).  Saving model ...
	 Train_Loss: 0.3565 Train_Acc: 85.999 Val_Loss: 0.2982  BEST VAL Loss: 0.2982  Val_Acc: 90.975

Epoch 27: Validation loss decreased (0.298159 --> 0.295454).  Saving model ...
	 Train_Loss: 0.3531 Train_Acc: 89.342 Val_Loss: 0.2955  BEST VAL Loss: 0.2955  Val_Acc: 91.072

Epoch 28: Validation loss decreased (0.295454 --> 0.292900).  Saving model ...
	 Train_Loss: 0.3500 Train_Acc: 89.281 Val_Loss: 0.2929  BEST VAL Loss: 0.2929  Val_Acc: 91.121

Epoch 29: Validation loss decreased (0.292900 --> 0.290397).  Saving model ...
	 Train_Loss: 0.3469 Train_Acc: 89.694 Val_Loss: 0.2904  BEST VAL Loss: 0.2904  Val_Acc: 91.315

Epoch 30: Validation loss decreased (0.290397 --> 0.288026).  Saving model ...
	 Train_Loss: 0.3438 Train_Acc: 90.003 Val_Loss: 0.2880  BEST VAL Loss: 0.2880  Val_Acc: 91.509

Epoch 31: Validation loss decreased (0.288026 --> 0.285739).  Saving model ...
	 Train_Loss: 0.3409 Train_Acc: 90.264 Val_Loss: 0.2857  BEST VAL Loss: 0.2857  Val_Acc: 91.557

Epoch 32: Validation loss decreased (0.285739 --> 0.283523).  Saving model ...
	 Train_Loss: 0.3381 Train_Acc: 90.385 Val_Loss: 0.2835  BEST VAL Loss: 0.2835  Val_Acc: 91.509

Epoch 33: Validation loss decreased (0.283523 --> 0.281433).  Saving model ...
	 Train_Loss: 0.3353 Train_Acc: 90.579 Val_Loss: 0.2814  BEST VAL Loss: 0.2814  Val_Acc: 91.557

Epoch 34: Validation loss decreased (0.281433 --> 0.279393).  Saving model ...
	 Train_Loss: 0.3326 Train_Acc: 90.840 Val_Loss: 0.2794  BEST VAL Loss: 0.2794  Val_Acc: 91.557

Epoch 35: Validation loss decreased (0.279393 --> 0.277472).  Saving model ...
	 Train_Loss: 0.3300 Train_Acc: 90.961 Val_Loss: 0.2775  BEST VAL Loss: 0.2775  Val_Acc: 91.752

Epoch 36: Validation loss decreased (0.277472 --> 0.275598).  Saving model ...
	 Train_Loss: 0.3274 Train_Acc: 91.016 Val_Loss: 0.2756  BEST VAL Loss: 0.2756  Val_Acc: 92.043

Epoch 37: Validation loss decreased (0.275598 --> 0.273819).  Saving model ...
	 Train_Loss: 0.3249 Train_Acc: 91.107 Val_Loss: 0.2738  BEST VAL Loss: 0.2738  Val_Acc: 92.237

Epoch 38: Validation loss decreased (0.273819 --> 0.272077).  Saving model ...
	 Train_Loss: 0.3225 Train_Acc: 91.356 Val_Loss: 0.2721  BEST VAL Loss: 0.2721  Val_Acc: 92.091

Epoch 39: Validation loss decreased (0.272077 --> 0.270366).  Saving model ...
	 Train_Loss: 0.3201 Train_Acc: 91.580 Val_Loss: 0.2704  BEST VAL Loss: 0.2704  Val_Acc: 92.285

Epoch 40: Validation loss decreased (0.270366 --> 0.268730).  Saving model ...
	 Train_Loss: 0.3177 Train_Acc: 91.586 Val_Loss: 0.2687  BEST VAL Loss: 0.2687  Val_Acc: 92.237

Epoch 41: Validation loss decreased (0.268730 --> 0.267171).  Saving model ...
	 Train_Loss: 0.3154 Train_Acc: 91.902 Val_Loss: 0.2672  BEST VAL Loss: 0.2672  Val_Acc: 92.334

Epoch 42: Validation loss decreased (0.267171 --> 0.265684).  Saving model ...
	 Train_Loss: 0.3132 Train_Acc: 91.793 Val_Loss: 0.2657  BEST VAL Loss: 0.2657  Val_Acc: 92.237

Epoch 43: Validation loss decreased (0.265684 --> 0.264221).  Saving model ...
	 Train_Loss: 0.3110 Train_Acc: 92.023 Val_Loss: 0.2642  BEST VAL Loss: 0.2642  Val_Acc: 92.237

Epoch 44: Validation loss decreased (0.264221 --> 0.262775).  Saving model ...
	 Train_Loss: 0.3089 Train_Acc: 92.187 Val_Loss: 0.2628  BEST VAL Loss: 0.2628  Val_Acc: 92.334

Epoch 45: Validation loss decreased (0.262775 --> 0.261392).  Saving model ...
	 Train_Loss: 0.3068 Train_Acc: 92.150 Val_Loss: 0.2614  BEST VAL Loss: 0.2614  Val_Acc: 92.188

Epoch 46: Validation loss decreased (0.261392 --> 0.260045).  Saving model ...
	 Train_Loss: 0.3048 Train_Acc: 92.338 Val_Loss: 0.2600  BEST VAL Loss: 0.2600  Val_Acc: 92.431

Epoch 47: Validation loss decreased (0.260045 --> 0.258703).  Saving model ...
	 Train_Loss: 0.3028 Train_Acc: 92.290 Val_Loss: 0.2587  BEST VAL Loss: 0.2587  Val_Acc: 92.673

Epoch 48: Validation loss decreased (0.258703 --> 0.257411).  Saving model ...
	 Train_Loss: 0.3008 Train_Acc: 92.539 Val_Loss: 0.2574  BEST VAL Loss: 0.2574  Val_Acc: 92.819

Epoch 49: Validation loss decreased (0.257411 --> 0.256176).  Saving model ...
	 Train_Loss: 0.2988 Train_Acc: 92.830 Val_Loss: 0.2562  BEST VAL Loss: 0.2562  Val_Acc: 92.770

Epoch 50: Validation loss decreased (0.256176 --> 0.254942).  Saving model ...
	 Train_Loss: 0.2968 Train_Acc: 92.757 Val_Loss: 0.2549  BEST VAL Loss: 0.2549  Val_Acc: 92.819

Epoch 51: Validation loss decreased (0.254942 --> 0.253787).  Saving model ...
	 Train_Loss: 0.2950 Train_Acc: 92.933 Val_Loss: 0.2538  BEST VAL Loss: 0.2538  Val_Acc: 92.722

Epoch 52: Validation loss decreased (0.253787 --> 0.252644).  Saving model ...
	 Train_Loss: 0.2932 Train_Acc: 92.587 Val_Loss: 0.2526  BEST VAL Loss: 0.2526  Val_Acc: 92.625

Epoch 53: Validation loss decreased (0.252644 --> 0.251566).  Saving model ...
	 Train_Loss: 0.2914 Train_Acc: 92.981 Val_Loss: 0.2516  BEST VAL Loss: 0.2516  Val_Acc: 92.868

Epoch 54: Validation loss decreased (0.251566 --> 0.250518).  Saving model ...
	 Train_Loss: 0.2897 Train_Acc: 93.127 Val_Loss: 0.2505  BEST VAL Loss: 0.2505  Val_Acc: 92.965

Epoch 55: Validation loss decreased (0.250518 --> 0.249493).  Saving model ...
	 Train_Loss: 0.2879 Train_Acc: 93.145 Val_Loss: 0.2495  BEST VAL Loss: 0.2495  Val_Acc: 92.722

Epoch 56: Validation loss decreased (0.249493 --> 0.248500).  Saving model ...
	 Train_Loss: 0.2862 Train_Acc: 93.309 Val_Loss: 0.2485  BEST VAL Loss: 0.2485  Val_Acc: 92.868

Epoch 57: Validation loss decreased (0.248500 --> 0.247535).  Saving model ...
	 Train_Loss: 0.2845 Train_Acc: 93.297 Val_Loss: 0.2475  BEST VAL Loss: 0.2475  Val_Acc: 92.819

Epoch 58: Validation loss decreased (0.247535 --> 0.246609).  Saving model ...
	 Train_Loss: 0.2828 Train_Acc: 93.527 Val_Loss: 0.2466  BEST VAL Loss: 0.2466  Val_Acc: 92.770

Epoch 59: Validation loss decreased (0.246609 --> 0.245712).  Saving model ...
	 Train_Loss: 0.2812 Train_Acc: 93.582 Val_Loss: 0.2457  BEST VAL Loss: 0.2457  Val_Acc: 92.965

Epoch 60: Validation loss decreased (0.245712 --> 0.244855).  Saving model ...
	 Train_Loss: 0.2796 Train_Acc: 93.424 Val_Loss: 0.2449  BEST VAL Loss: 0.2449  Val_Acc: 92.916

Epoch 61: Validation loss decreased (0.244855 --> 0.243974).  Saving model ...
	 Train_Loss: 0.2780 Train_Acc: 93.485 Val_Loss: 0.2440  BEST VAL Loss: 0.2440  Val_Acc: 93.013

Epoch 62: Validation loss decreased (0.243974 --> 0.243131).  Saving model ...
	 Train_Loss: 0.2765 Train_Acc: 93.697 Val_Loss: 0.2431  BEST VAL Loss: 0.2431  Val_Acc: 93.062

Epoch 63: Validation loss decreased (0.243131 --> 0.242343).  Saving model ...
	 Train_Loss: 0.2750 Train_Acc: 93.637 Val_Loss: 0.2423  BEST VAL Loss: 0.2423  Val_Acc: 92.965

Epoch 64: Validation loss decreased (0.242343 --> 0.241576).  Saving model ...
	 Train_Loss: 0.2736 Train_Acc: 93.534 Val_Loss: 0.2416  BEST VAL Loss: 0.2416  Val_Acc: 92.916

Epoch 65: Validation loss decreased (0.241576 --> 0.240826).  Saving model ...
	 Train_Loss: 0.2721 Train_Acc: 93.709 Val_Loss: 0.2408  BEST VAL Loss: 0.2408  Val_Acc: 93.062

Epoch 66: Validation loss decreased (0.240826 --> 0.240094).  Saving model ...
	 Train_Loss: 0.2706 Train_Acc: 93.837 Val_Loss: 0.2401  BEST VAL Loss: 0.2401  Val_Acc: 92.965

Epoch 67: Validation loss decreased (0.240094 --> 0.239385).  Saving model ...
	 Train_Loss: 0.2692 Train_Acc: 93.770 Val_Loss: 0.2394  BEST VAL Loss: 0.2394  Val_Acc: 92.770

Epoch 68: Validation loss decreased (0.239385 --> 0.238689).  Saving model ...
	 Train_Loss: 0.2678 Train_Acc: 94.013 Val_Loss: 0.2387  BEST VAL Loss: 0.2387  Val_Acc: 92.965

Epoch 69: Validation loss decreased (0.238689 --> 0.237988).  Saving model ...
	 Train_Loss: 0.2664 Train_Acc: 94.213 Val_Loss: 0.2380  BEST VAL Loss: 0.2380  Val_Acc: 92.916

Epoch 70: Validation loss decreased (0.237988 --> 0.237305).  Saving model ...
	 Train_Loss: 0.2650 Train_Acc: 94.061 Val_Loss: 0.2373  BEST VAL Loss: 0.2373  Val_Acc: 92.916

Epoch 71: Validation loss decreased (0.237305 --> 0.236657).  Saving model ...
	 Train_Loss: 0.2637 Train_Acc: 93.885 Val_Loss: 0.2367  BEST VAL Loss: 0.2367  Val_Acc: 93.013

Epoch 72: Validation loss decreased (0.236657 --> 0.236005).  Saving model ...
	 Train_Loss: 0.2623 Train_Acc: 94.559 Val_Loss: 0.2360  BEST VAL Loss: 0.2360  Val_Acc: 93.353

Epoch 73: Validation loss decreased (0.236005 --> 0.235372).  Saving model ...
	 Train_Loss: 0.2611 Train_Acc: 94.158 Val_Loss: 0.2354  BEST VAL Loss: 0.2354  Val_Acc: 93.013

Epoch 74: Validation loss decreased (0.235372 --> 0.234755).  Saving model ...
	 Train_Loss: 0.2598 Train_Acc: 94.304 Val_Loss: 0.2348  BEST VAL Loss: 0.2348  Val_Acc: 93.401

Epoch 75: Validation loss decreased (0.234755 --> 0.234161).  Saving model ...
	 Train_Loss: 0.2585 Train_Acc: 94.425 Val_Loss: 0.2342  BEST VAL Loss: 0.2342  Val_Acc: 93.013

Epoch 76: Validation loss decreased (0.234161 --> 0.233586).  Saving model ...
	 Train_Loss: 0.2572 Train_Acc: 94.559 Val_Loss: 0.2336  BEST VAL Loss: 0.2336  Val_Acc: 92.965

Epoch 77: Validation loss decreased (0.233586 --> 0.233021).  Saving model ...
	 Train_Loss: 0.2559 Train_Acc: 94.650 Val_Loss: 0.2330  BEST VAL Loss: 0.2330  Val_Acc: 93.207

Epoch 78: Validation loss decreased (0.233021 --> 0.232475).  Saving model ...
	 Train_Loss: 0.2547 Train_Acc: 94.613 Val_Loss: 0.2325  BEST VAL Loss: 0.2325  Val_Acc: 93.207

Epoch 79: Validation loss decreased (0.232475 --> 0.231903).  Saving model ...
	 Train_Loss: 0.2535 Train_Acc: 94.486 Val_Loss: 0.2319  BEST VAL Loss: 0.2319  Val_Acc: 93.304

Epoch 80: Validation loss decreased (0.231903 --> 0.231397).  Saving model ...
	 Train_Loss: 0.2523 Train_Acc: 94.716 Val_Loss: 0.2314  BEST VAL Loss: 0.2314  Val_Acc: 93.013

Epoch 81: Validation loss decreased (0.231397 --> 0.230860).  Saving model ...
	 Train_Loss: 0.2511 Train_Acc: 94.601 Val_Loss: 0.2309  BEST VAL Loss: 0.2309  Val_Acc: 93.159

Epoch 82: Validation loss decreased (0.230860 --> 0.230352).  Saving model ...
	 Train_Loss: 0.2499 Train_Acc: 95.038 Val_Loss: 0.2304  BEST VAL Loss: 0.2304  Val_Acc: 93.256

Epoch 83: Validation loss decreased (0.230352 --> 0.229884).  Saving model ...
	 Train_Loss: 0.2488 Train_Acc: 94.638 Val_Loss: 0.2299  BEST VAL Loss: 0.2299  Val_Acc: 93.450

Epoch 84: Validation loss decreased (0.229884 --> 0.229413).  Saving model ...
	 Train_Loss: 0.2477 Train_Acc: 94.722 Val_Loss: 0.2294  BEST VAL Loss: 0.2294  Val_Acc: 93.256

Epoch 85: Validation loss decreased (0.229413 --> 0.228938).  Saving model ...
	 Train_Loss: 0.2466 Train_Acc: 94.983 Val_Loss: 0.2289  BEST VAL Loss: 0.2289  Val_Acc: 93.256

Epoch 86: Validation loss decreased (0.228938 --> 0.228456).  Saving model ...
	 Train_Loss: 0.2455 Train_Acc: 94.856 Val_Loss: 0.2285  BEST VAL Loss: 0.2285  Val_Acc: 93.256

Epoch 87: Validation loss decreased (0.228456 --> 0.228017).  Saving model ...
	 Train_Loss: 0.2444 Train_Acc: 94.777 Val_Loss: 0.2280  BEST VAL Loss: 0.2280  Val_Acc: 93.110

Epoch 88: Validation loss decreased (0.228017 --> 0.227594).  Saving model ...
	 Train_Loss: 0.2434 Train_Acc: 94.807 Val_Loss: 0.2276  BEST VAL Loss: 0.2276  Val_Acc: 93.256

Epoch 89: Validation loss decreased (0.227594 --> 0.227181).  Saving model ...
	 Train_Loss: 0.2423 Train_Acc: 95.141 Val_Loss: 0.2272  BEST VAL Loss: 0.2272  Val_Acc: 93.256

Epoch 90: Validation loss decreased (0.227181 --> 0.226758).  Saving model ...
	 Train_Loss: 0.2412 Train_Acc: 95.105 Val_Loss: 0.2268  BEST VAL Loss: 0.2268  Val_Acc: 93.353

Epoch 91: Validation loss decreased (0.226758 --> 0.226353).  Saving model ...
	 Train_Loss: 0.2402 Train_Acc: 94.941 Val_Loss: 0.2264  BEST VAL Loss: 0.2264  Val_Acc: 93.353

Epoch 92: Validation loss decreased (0.226353 --> 0.225960).  Saving model ...
	 Train_Loss: 0.2392 Train_Acc: 95.171 Val_Loss: 0.2260  BEST VAL Loss: 0.2260  Val_Acc: 93.450

Epoch 93: Validation loss decreased (0.225960 --> 0.225557).  Saving model ...
	 Train_Loss: 0.2382 Train_Acc: 95.044 Val_Loss: 0.2256  BEST VAL Loss: 0.2256  Val_Acc: 93.498

Epoch 94: Validation loss decreased (0.225557 --> 0.225198).  Saving model ...
	 Train_Loss: 0.2372 Train_Acc: 94.904 Val_Loss: 0.2252  BEST VAL Loss: 0.2252  Val_Acc: 93.595

Epoch 95: Validation loss decreased (0.225198 --> 0.224840).  Saving model ...
	 Train_Loss: 0.2362 Train_Acc: 95.274 Val_Loss: 0.2248  BEST VAL Loss: 0.2248  Val_Acc: 93.450

Epoch 96: Validation loss decreased (0.224840 --> 0.224499).  Saving model ...
	 Train_Loss: 0.2352 Train_Acc: 95.268 Val_Loss: 0.2245  BEST VAL Loss: 0.2245  Val_Acc: 93.304

Epoch 97: Validation loss decreased (0.224499 --> 0.224140).  Saving model ...
	 Train_Loss: 0.2343 Train_Acc: 95.159 Val_Loss: 0.2241  BEST VAL Loss: 0.2241  Val_Acc: 93.304

Epoch 98: Validation loss decreased (0.224140 --> 0.223819).  Saving model ...
	 Train_Loss: 0.2333 Train_Acc: 95.220 Val_Loss: 0.2238  BEST VAL Loss: 0.2238  Val_Acc: 93.353

Epoch 99: Validation loss decreased (0.223819 --> 0.223493).  Saving model ...
	 Train_Loss: 0.2323 Train_Acc: 95.432 Val_Loss: 0.2235  BEST VAL Loss: 0.2235  Val_Acc: 93.353

Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.97      0.98      8634
           1       0.97      0.98      0.98      7851

    accuracy                           0.98     16485
   macro avg       0.98      0.98      0.98     16485
weighted avg       0.98      0.98      0.98     16485

Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.94      0.93      0.94      1079
           1       0.93      0.93      0.93       982

    accuracy                           0.93      2061
   macro avg       0.93      0.93      0.93      2061
weighted avg       0.93      0.93      0.93      2061

Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.94      0.94      0.94      1080
           1       0.93      0.93      0.93       981

    accuracy                           0.93      2061
   macro avg       0.93      0.93      0.93      2061
weighted avg       0.93      0.93      0.93      2061

              precision    recall  f1-score   support

           0       0.94      0.94      0.94      1080
           1       0.93      0.93      0.93       981

    accuracy                           0.93      2061
   macro avg       0.93      0.93      0.93      2061
weighted avg       0.93      0.93      0.93      2061

Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.96      0.94      0.95      4135
           1       0.93      0.95      0.94      3398

    accuracy                           0.94      7533
   macro avg       0.94      0.94      0.94      7533
weighted avg       0.94      0.94      0.94      7533

              precision    recall  f1-score   support

           0       0.96      0.94      0.95      4135
           1       0.93      0.95      0.94      3398

    accuracy                           0.94      7533
   macro avg       0.94      0.94      0.94      7533
weighted avg       0.94      0.94      0.94      7533

completed
