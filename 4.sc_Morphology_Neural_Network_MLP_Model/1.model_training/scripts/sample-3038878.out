[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '91e52284'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '872f5c85'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1827292e'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '8fdf77ca'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_0.100_DMSO_0.025 treatment_name: LPS_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: LPS_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (31386, 1276)
Number of total missing values across all columns: 62772
Data Subset Is Off
Wells held out for testing: ['D21' 'L22']
Wells to use for training, validation, and testing ['D16' 'D17' 'D20' 'L18' 'L19' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.691371).  Saving model ...
	 Train_Loss: 0.7423 Train_Acc: 49.019 Val_Loss: 0.6914  BEST VAL Loss: 0.6914  Val_Acc: 53.751

Epoch 1: Validation loss decreased (0.691371 --> 0.691074).  Saving model ...
	 Train_Loss: 0.7170 Train_Acc: 53.606 Val_Loss: 0.6911  BEST VAL Loss: 0.6911  Val_Acc: 53.751

Epoch 2: Validation loss decreased (0.691074 --> 0.690619).  Saving model ...
	 Train_Loss: 0.7078 Train_Acc: 53.735 Val_Loss: 0.6906  BEST VAL Loss: 0.6906  Val_Acc: 54.736

Epoch 3: Validation loss decreased (0.690619 --> 0.690059).  Saving model ...
	 Train_Loss: 0.7027 Train_Acc: 54.769 Val_Loss: 0.6901  BEST VAL Loss: 0.6901  Val_Acc: 55.422

Epoch 4: Validation loss did not decrease
	 Train_Loss: 0.6993 Train_Acc: 56.221 Val_Loss: 0.6902  BEST VAL Loss: 0.6901  Val_Acc: 54.436

Epoch 5: Validation loss decreased (0.690059 --> 0.689821).  Saving model ...
	 Train_Loss: 0.6971 Train_Acc: 56.275 Val_Loss: 0.6898  BEST VAL Loss: 0.6898  Val_Acc: 56.365

Epoch 6: Validation loss decreased (0.689821 --> 0.688742).  Saving model ...
	 Train_Loss: 0.6949 Train_Acc: 57.904 Val_Loss: 0.6887  BEST VAL Loss: 0.6887  Val_Acc: 57.994

Epoch 7: Validation loss decreased (0.688742 --> 0.687787).  Saving model ...
	 Train_Loss: 0.6932 Train_Acc: 57.989 Val_Loss: 0.6878  BEST VAL Loss: 0.6878  Val_Acc: 57.651

Epoch 8: Validation loss decreased (0.687787 --> 0.686560).  Saving model ...
	 Train_Loss: 0.6914 Train_Acc: 58.831 Val_Loss: 0.6866  BEST VAL Loss: 0.6866  Val_Acc: 59.666

Epoch 9: Validation loss decreased (0.686560 --> 0.685086).  Saving model ...
	 Train_Loss: 0.6897 Train_Acc: 59.902 Val_Loss: 0.6851  BEST VAL Loss: 0.6851  Val_Acc: 60.180

Epoch 10: Validation loss decreased (0.685086 --> 0.683849).  Saving model ...
	 Train_Loss: 0.6879 Train_Acc: 60.556 Val_Loss: 0.6838  BEST VAL Loss: 0.6838  Val_Acc: 60.694

Epoch 11: Validation loss decreased (0.683849 --> 0.682192).  Saving model ...
	 Train_Loss: 0.6860 Train_Acc: 61.371 Val_Loss: 0.6822  BEST VAL Loss: 0.6822  Val_Acc: 62.280

Epoch 12: Validation loss decreased (0.682192 --> 0.680860).  Saving model ...
	 Train_Loss: 0.6841 Train_Acc: 62.759 Val_Loss: 0.6809  BEST VAL Loss: 0.6809  Val_Acc: 62.880

Epoch 13: Validation loss decreased (0.680860 --> 0.679135).  Saving model ...
	 Train_Loss: 0.6822 Train_Acc: 63.101 Val_Loss: 0.6791  BEST VAL Loss: 0.6791  Val_Acc: 63.480

Epoch 14: Validation loss decreased (0.679135 --> 0.677564).  Saving model ...
	 Train_Loss: 0.6803 Train_Acc: 63.568 Val_Loss: 0.6776  BEST VAL Loss: 0.6776  Val_Acc: 63.909

Epoch 15: Validation loss decreased (0.677564 --> 0.676054).  Saving model ...
	 Train_Loss: 0.6785 Train_Acc: 64.002 Val_Loss: 0.6761  BEST VAL Loss: 0.6761  Val_Acc: 64.681

Epoch 16: Validation loss decreased (0.676054 --> 0.674769).  Saving model ...
	 Train_Loss: 0.6767 Train_Acc: 64.741 Val_Loss: 0.6748  BEST VAL Loss: 0.6748  Val_Acc: 63.652

Epoch 17: Validation loss decreased (0.674769 --> 0.672987).  Saving model ...
	 Train_Loss: 0.6746 Train_Acc: 65.920 Val_Loss: 0.6730  BEST VAL Loss: 0.6730  Val_Acc: 65.409

Epoch 18: Validation loss decreased (0.672987 --> 0.671132).  Saving model ...
	 Train_Loss: 0.6727 Train_Acc: 66.017 Val_Loss: 0.6711  BEST VAL Loss: 0.6711  Val_Acc: 66.095

Epoch 19: Validation loss decreased (0.671132 --> 0.669270).  Saving model ...
	 Train_Loss: 0.6709 Train_Acc: 66.515 Val_Loss: 0.6693  BEST VAL Loss: 0.6693  Val_Acc: 66.438

Epoch 20: Validation loss decreased (0.669270 --> 0.667780).  Saving model ...
	 Train_Loss: 0.6693 Train_Acc: 66.263 Val_Loss: 0.6678  BEST VAL Loss: 0.6678  Val_Acc: 65.366

Epoch 21: Validation loss decreased (0.667780 --> 0.666248).  Saving model ...
	 Train_Loss: 0.6676 Train_Acc: 66.911 Val_Loss: 0.6662  BEST VAL Loss: 0.6662  Val_Acc: 66.524

Epoch 22: Validation loss decreased (0.666248 --> 0.664948).  Saving model ...
	 Train_Loss: 0.6658 Train_Acc: 67.554 Val_Loss: 0.6649  BEST VAL Loss: 0.6649  Val_Acc: 66.224

Epoch 23: Validation loss decreased (0.664948 --> 0.663547).  Saving model ...
	 Train_Loss: 0.6643 Train_Acc: 67.195 Val_Loss: 0.6635  BEST VAL Loss: 0.6635  Val_Acc: 66.910

Epoch 24: Validation loss decreased (0.663547 --> 0.662195).  Saving model ...
	 Train_Loss: 0.6625 Train_Acc: 68.653 Val_Loss: 0.6622  BEST VAL Loss: 0.6622  Val_Acc: 67.338

Epoch 25: Validation loss decreased (0.662195 --> 0.660821).  Saving model ...
	 Train_Loss: 0.6608 Train_Acc: 68.696 Val_Loss: 0.6608  BEST VAL Loss: 0.6608  Val_Acc: 67.467

Epoch 26: Validation loss decreased (0.660821 --> 0.659509).  Saving model ...
	 Train_Loss: 0.6592 Train_Acc: 68.744 Val_Loss: 0.6595  BEST VAL Loss: 0.6595  Val_Acc: 68.067

Epoch 27: Validation loss decreased (0.659509 --> 0.658393).  Saving model ...
	 Train_Loss: 0.6576 Train_Acc: 69.285 Val_Loss: 0.6584  BEST VAL Loss: 0.6584  Val_Acc: 67.338

Epoch 28: Validation loss decreased (0.658393 --> 0.657105).  Saving model ...
	 Train_Loss: 0.6561 Train_Acc: 69.210 Val_Loss: 0.6571  BEST VAL Loss: 0.6571  Val_Acc: 68.495

Epoch 29: Validation loss decreased (0.657105 --> 0.655832).  Saving model ...
	 Train_Loss: 0.6547 Train_Acc: 69.103 Val_Loss: 0.6558  BEST VAL Loss: 0.6558  Val_Acc: 68.495

Epoch 30: Validation loss decreased (0.655832 --> 0.654635).  Saving model ...
	 Train_Loss: 0.6533 Train_Acc: 69.692 Val_Loss: 0.6546  BEST VAL Loss: 0.6546  Val_Acc: 68.967

Epoch 31: Validation loss decreased (0.654635 --> 0.653572).  Saving model ...
	 Train_Loss: 0.6518 Train_Acc: 70.132 Val_Loss: 0.6536  BEST VAL Loss: 0.6536  Val_Acc: 68.495

Epoch 32: Validation loss decreased (0.653572 --> 0.652631).  Saving model ...
	 Train_Loss: 0.6504 Train_Acc: 70.116 Val_Loss: 0.6526  BEST VAL Loss: 0.6526  Val_Acc: 68.581

Epoch 33: Validation loss decreased (0.652631 --> 0.651368).  Saving model ...
	 Train_Loss: 0.6490 Train_Acc: 70.357 Val_Loss: 0.6514  BEST VAL Loss: 0.6514  Val_Acc: 69.824

Epoch 34: Validation loss decreased (0.651368 --> 0.650309).  Saving model ...
	 Train_Loss: 0.6477 Train_Acc: 70.544 Val_Loss: 0.6503  BEST VAL Loss: 0.6503  Val_Acc: 69.567

Epoch 35: Validation loss decreased (0.650309 --> 0.649411).  Saving model ...
	 Train_Loss: 0.6462 Train_Acc: 71.246 Val_Loss: 0.6494  BEST VAL Loss: 0.6494  Val_Acc: 68.453

Epoch 36: Validation loss decreased (0.649411 --> 0.648498).  Saving model ...
	 Train_Loss: 0.6450 Train_Acc: 71.279 Val_Loss: 0.6485  BEST VAL Loss: 0.6485  Val_Acc: 68.367

Epoch 37: Validation loss decreased (0.648498 --> 0.647646).  Saving model ...
	 Train_Loss: 0.6438 Train_Acc: 71.225 Val_Loss: 0.6476  BEST VAL Loss: 0.6476  Val_Acc: 68.624

Epoch 38: Validation loss decreased (0.647646 --> 0.646623).  Saving model ...
	 Train_Loss: 0.6425 Train_Acc: 71.734 Val_Loss: 0.6466  BEST VAL Loss: 0.6466  Val_Acc: 69.739

Epoch 39: Validation loss decreased (0.646623 --> 0.645974).  Saving model ...
	 Train_Loss: 0.6413 Train_Acc: 71.557 Val_Loss: 0.6460  BEST VAL Loss: 0.6460  Val_Acc: 68.324

Epoch 40: Validation loss decreased (0.645974 --> 0.644972).  Saving model ...
	 Train_Loss: 0.6401 Train_Acc: 71.471 Val_Loss: 0.6450  BEST VAL Loss: 0.6450  Val_Acc: 70.253

Epoch 41: Validation loss decreased (0.644972 --> 0.644056).  Saving model ...
	 Train_Loss: 0.6391 Train_Acc: 71.321 Val_Loss: 0.6441  BEST VAL Loss: 0.6441  Val_Acc: 70.296

Epoch 42: Validation loss decreased (0.644056 --> 0.643076).  Saving model ...
	 Train_Loss: 0.6378 Train_Acc: 72.323 Val_Loss: 0.6431  BEST VAL Loss: 0.6431  Val_Acc: 70.682

Epoch 43: Validation loss decreased (0.643076 --> 0.642287).  Saving model ...
	 Train_Loss: 0.6368 Train_Acc: 71.466 Val_Loss: 0.6423  BEST VAL Loss: 0.6423  Val_Acc: 70.124

Epoch 44: Validation loss decreased (0.642287 --> 0.641527).  Saving model ...
	 Train_Loss: 0.6357 Train_Acc: 72.184 Val_Loss: 0.6415  BEST VAL Loss: 0.6415  Val_Acc: 70.124

Epoch 45: Validation loss decreased (0.641527 --> 0.640814).  Saving model ...
	 Train_Loss: 0.6346 Train_Acc: 72.098 Val_Loss: 0.6408  BEST VAL Loss: 0.6408  Val_Acc: 69.953

Epoch 46: Validation loss decreased (0.640814 --> 0.640053).  Saving model ...
	 Train_Loss: 0.6335 Train_Acc: 72.291 Val_Loss: 0.6401  BEST VAL Loss: 0.6401  Val_Acc: 70.253

Epoch 47: Validation loss decreased (0.640053 --> 0.639253).  Saving model ...
	 Train_Loss: 0.6325 Train_Acc: 72.323 Val_Loss: 0.6393  BEST VAL Loss: 0.6393  Val_Acc: 70.339

Epoch 48: Validation loss decreased (0.639253 --> 0.638541).  Saving model ...
	 Train_Loss: 0.6315 Train_Acc: 72.806 Val_Loss: 0.6385  BEST VAL Loss: 0.6385  Val_Acc: 69.953

Epoch 49: Validation loss decreased (0.638541 --> 0.637917).  Saving model ...
	 Train_Loss: 0.6306 Train_Acc: 72.307 Val_Loss: 0.6379  BEST VAL Loss: 0.6379  Val_Acc: 69.739

Epoch 50: Validation loss decreased (0.637917 --> 0.637342).  Saving model ...
	 Train_Loss: 0.6295 Train_Acc: 72.908 Val_Loss: 0.6373  BEST VAL Loss: 0.6373  Val_Acc: 70.039

Epoch 51: Validation loss decreased (0.637342 --> 0.636794).  Saving model ...
	 Train_Loss: 0.6285 Train_Acc: 73.234 Val_Loss: 0.6368  BEST VAL Loss: 0.6368  Val_Acc: 70.510

Epoch 52: Validation loss decreased (0.636794 --> 0.636296).  Saving model ...
	 Train_Loss: 0.6276 Train_Acc: 72.548 Val_Loss: 0.6363  BEST VAL Loss: 0.6363  Val_Acc: 70.510

Epoch 53: Validation loss decreased (0.636296 --> 0.635743).  Saving model ...
	 Train_Loss: 0.6266 Train_Acc: 73.138 Val_Loss: 0.6357  BEST VAL Loss: 0.6357  Val_Acc: 70.253

Epoch 54: Validation loss decreased (0.635743 --> 0.635401).  Saving model ...
	 Train_Loss: 0.6257 Train_Acc: 73.116 Val_Loss: 0.6354  BEST VAL Loss: 0.6354  Val_Acc: 69.696

Epoch 55: Validation loss decreased (0.635401 --> 0.634981).  Saving model ...
	 Train_Loss: 0.6249 Train_Acc: 72.811 Val_Loss: 0.6350  BEST VAL Loss: 0.6350  Val_Acc: 69.653

Epoch 56: Validation loss decreased (0.634981 --> 0.634446).  Saving model ...
	 Train_Loss: 0.6241 Train_Acc: 72.661 Val_Loss: 0.6344  BEST VAL Loss: 0.6344  Val_Acc: 70.039

Epoch 57: Validation loss decreased (0.634446 --> 0.633982).  Saving model ...
	 Train_Loss: 0.6233 Train_Acc: 73.615 Val_Loss: 0.6340  BEST VAL Loss: 0.6340  Val_Acc: 70.039

Epoch 58: Validation loss decreased (0.633982 --> 0.633493).  Saving model ...
	 Train_Loss: 0.6225 Train_Acc: 73.149 Val_Loss: 0.6335  BEST VAL Loss: 0.6335  Val_Acc: 70.039

Epoch 59: Validation loss decreased (0.633493 --> 0.633184).  Saving model ...
	 Train_Loss: 0.6218 Train_Acc: 73.261 Val_Loss: 0.6332  BEST VAL Loss: 0.6332  Val_Acc: 69.267

Epoch 60: Validation loss decreased (0.633184 --> 0.632827).  Saving model ...
	 Train_Loss: 0.6210 Train_Acc: 73.701 Val_Loss: 0.6328  BEST VAL Loss: 0.6328  Val_Acc: 69.396

Epoch 61: Validation loss decreased (0.632827 --> 0.632457).  Saving model ...
	 Train_Loss: 0.6202 Train_Acc: 73.690 Val_Loss: 0.6325  BEST VAL Loss: 0.6325  Val_Acc: 69.824

Epoch 62: Validation loss decreased (0.632457 --> 0.632128).  Saving model ...
	 Train_Loss: 0.6194 Train_Acc: 73.706 Val_Loss: 0.6321  BEST VAL Loss: 0.6321  Val_Acc: 69.610

Epoch 63: Validation loss decreased (0.632128 --> 0.631708).  Saving model ...
	 Train_Loss: 0.6186 Train_Acc: 74.242 Val_Loss: 0.6317  BEST VAL Loss: 0.6317  Val_Acc: 70.467

Epoch 64: Validation loss decreased (0.631708 --> 0.631369).  Saving model ...
	 Train_Loss: 0.6177 Train_Acc: 74.467 Val_Loss: 0.6314  BEST VAL Loss: 0.6314  Val_Acc: 69.996

Epoch 65: Validation loss decreased (0.631369 --> 0.631089).  Saving model ...
	 Train_Loss: 0.6170 Train_Acc: 73.840 Val_Loss: 0.6311  BEST VAL Loss: 0.6311  Val_Acc: 69.953

Epoch 66: Validation loss decreased (0.631089 --> 0.630743).  Saving model ...
	 Train_Loss: 0.6162 Train_Acc: 73.995 Val_Loss: 0.6307  BEST VAL Loss: 0.6307  Val_Acc: 70.424

Epoch 67: Validation loss decreased (0.630743 --> 0.630516).  Saving model ...
	 Train_Loss: 0.6155 Train_Acc: 73.829 Val_Loss: 0.6305  BEST VAL Loss: 0.6305  Val_Acc: 69.053

Epoch 68: Validation loss decreased (0.630516 --> 0.630263).  Saving model ...
	 Train_Loss: 0.6148 Train_Acc: 74.097 Val_Loss: 0.6303  BEST VAL Loss: 0.6303  Val_Acc: 70.596

Epoch 69: Validation loss decreased (0.630263 --> 0.629942).  Saving model ...
	 Train_Loss: 0.6141 Train_Acc: 74.306 Val_Loss: 0.6299  BEST VAL Loss: 0.6299  Val_Acc: 70.510

Epoch 70: Validation loss decreased (0.629942 --> 0.629680).  Saving model ...
	 Train_Loss: 0.6134 Train_Acc: 74.499 Val_Loss: 0.6297  BEST VAL Loss: 0.6297  Val_Acc: 69.953

Epoch 71: Validation loss decreased (0.629680 --> 0.629536).  Saving model ...
	 Train_Loss: 0.6127 Train_Acc: 74.403 Val_Loss: 0.6295  BEST VAL Loss: 0.6295  Val_Acc: 69.696

Epoch 72: Validation loss decreased (0.629536 --> 0.629258).  Saving model ...
	 Train_Loss: 0.6120 Train_Acc: 74.220 Val_Loss: 0.6293  BEST VAL Loss: 0.6293  Val_Acc: 70.081

Epoch 73: Validation loss decreased (0.629258 --> 0.629189).  Saving model ...
	 Train_Loss: 0.6113 Train_Acc: 74.740 Val_Loss: 0.6292  BEST VAL Loss: 0.6292  Val_Acc: 69.267

Epoch 74: Validation loss decreased (0.629189 --> 0.629033).  Saving model ...
	 Train_Loss: 0.6107 Train_Acc: 74.311 Val_Loss: 0.6290  BEST VAL Loss: 0.6290  Val_Acc: 69.696

Epoch 75: Validation loss decreased (0.629033 --> 0.628921).  Saving model ...
	 Train_Loss: 0.6100 Train_Acc: 74.735 Val_Loss: 0.6289  BEST VAL Loss: 0.6289  Val_Acc: 69.996

Epoch 76: Validation loss decreased (0.628921 --> 0.628903).  Saving model ...
	 Train_Loss: 0.6094 Train_Acc: 74.413 Val_Loss: 0.6289  BEST VAL Loss: 0.6289  Val_Acc: 69.696

Epoch 77: Validation loss decreased (0.628903 --> 0.628734).  Saving model ...
	 Train_Loss: 0.6087 Train_Acc: 74.794 Val_Loss: 0.6287  BEST VAL Loss: 0.6287  Val_Acc: 70.039

Epoch 78: Validation loss decreased (0.628734 --> 0.628490).  Saving model ...
	 Train_Loss: 0.6082 Train_Acc: 74.419 Val_Loss: 0.6285  BEST VAL Loss: 0.6285  Val_Acc: 70.124

Epoch 79: Validation loss decreased (0.628490 --> 0.628265).  Saving model ...
	 Train_Loss: 0.6076 Train_Acc: 74.542 Val_Loss: 0.6283  BEST VAL Loss: 0.6283  Val_Acc: 71.453

Epoch 80: Validation loss decreased (0.628265 --> 0.628079).  Saving model ...
	 Train_Loss: 0.6069 Train_Acc: 74.595 Val_Loss: 0.6281  BEST VAL Loss: 0.6281  Val_Acc: 70.381

Epoch 81: Validation loss decreased (0.628079 --> 0.627942).  Saving model ...
	 Train_Loss: 0.6063 Train_Acc: 74.954 Val_Loss: 0.6279  BEST VAL Loss: 0.6279  Val_Acc: 69.610

Epoch 82: Validation loss decreased (0.627942 --> 0.627715).  Saving model ...
	 Train_Loss: 0.6057 Train_Acc: 75.206 Val_Loss: 0.6277  BEST VAL Loss: 0.6277  Val_Acc: 71.153

Epoch 83: Validation loss decreased (0.627715 --> 0.627509).  Saving model ...
	 Train_Loss: 0.6051 Train_Acc: 75.003 Val_Loss: 0.6275  BEST VAL Loss: 0.6275  Val_Acc: 70.210

Epoch 84: Validation loss decreased (0.627509 --> 0.627301).  Saving model ...
	 Train_Loss: 0.6045 Train_Acc: 75.196 Val_Loss: 0.6273  BEST VAL Loss: 0.6273  Val_Acc: 70.124

Epoch 85: Validation loss decreased (0.627301 --> 0.627116).  Saving model ...
	 Train_Loss: 0.6038 Train_Acc: 75.587 Val_Loss: 0.6271  BEST VAL Loss: 0.6271  Val_Acc: 69.996

Epoch 86: Validation loss decreased (0.627116 --> 0.626920).  Saving model ...
	 Train_Loss: 0.6032 Train_Acc: 75.726 Val_Loss: 0.6269  BEST VAL Loss: 0.6269  Val_Acc: 70.896

Epoch 87: Validation loss decreased (0.626920 --> 0.626740).  Saving model ...
	 Train_Loss: 0.6026 Train_Acc: 75.667 Val_Loss: 0.6267  BEST VAL Loss: 0.6267  Val_Acc: 69.824

Epoch 88: Validation loss decreased (0.626740 --> 0.626655).  Saving model ...
	 Train_Loss: 0.6021 Train_Acc: 74.853 Val_Loss: 0.6267  BEST VAL Loss: 0.6267  Val_Acc: 69.396

Epoch 89: Validation loss decreased (0.626655 --> 0.626482).  Saving model ...
	 Train_Loss: 0.6016 Train_Acc: 75.147 Val_Loss: 0.6265  BEST VAL Loss: 0.6265  Val_Acc: 70.596

Epoch 90: Validation loss decreased (0.626482 --> 0.626427).  Saving model ...
	 Train_Loss: 0.6010 Train_Acc: 75.501 Val_Loss: 0.6264  BEST VAL Loss: 0.6264  Val_Acc: 69.696

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.6004 Train_Acc: 75.881 Val_Loss: 0.6264  BEST VAL Loss: 0.6264  Val_Acc: 69.524

Epoch 92: Validation loss decreased (0.626427 --> 0.626305).  Saving model ...
	 Train_Loss: 0.5998 Train_Acc: 75.876 Val_Loss: 0.6263  BEST VAL Loss: 0.6263  Val_Acc: 70.724

Epoch 93: Validation loss decreased (0.626305 --> 0.626235).  Saving model ...
	 Train_Loss: 0.5993 Train_Acc: 75.362 Val_Loss: 0.6262  BEST VAL Loss: 0.6262  Val_Acc: 70.124

Epoch 94: Validation loss decreased (0.626235 --> 0.626122).  Saving model ...
	 Train_Loss: 0.5988 Train_Acc: 75.437 Val_Loss: 0.6261  BEST VAL Loss: 0.6261  Val_Acc: 69.996

Epoch 95: Validation loss decreased (0.626122 --> 0.626004).  Saving model ...
	 Train_Loss: 0.5983 Train_Acc: 75.415 Val_Loss: 0.6260  BEST VAL Loss: 0.6260  Val_Acc: 70.039

Epoch 96: Validation loss decreased (0.626004 --> 0.625929).  Saving model ...
	 Train_Loss: 0.5977 Train_Acc: 76.010 Val_Loss: 0.6259  BEST VAL Loss: 0.6259  Val_Acc: 70.210

Epoch 97: Validation loss decreased (0.625929 --> 0.625807).  Saving model ...
	 Train_Loss: 0.5973 Train_Acc: 75.410 Val_Loss: 0.6258  BEST VAL Loss: 0.6258  Val_Acc: 70.424

Epoch 98: Validation loss decreased (0.625807 --> 0.625738).  Saving model ...
	 Train_Loss: 0.5968 Train_Acc: 75.710 Val_Loss: 0.6257  BEST VAL Loss: 0.6257  Val_Acc: 69.781

Epoch 99: Validation loss decreased (0.625738 --> 0.625686).  Saving model ...
	 Train_Loss: 0.5962 Train_Acc: 76.080 Val_Loss: 0.6257  BEST VAL Loss: 0.6257  Val_Acc: 70.124

Flagellin_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.91      0.67      0.77      8635
           1       0.77      0.94      0.85     10027

    accuracy                           0.81     18662
   macro avg       0.84      0.80      0.81     18662
weighted avg       0.83      0.81      0.81     18662

Flagellin_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.75      0.54      0.62      1079
           1       0.68      0.84      0.75      1254

    accuracy                           0.70      2333
   macro avg       0.71      0.69      0.69      2333
weighted avg       0.71      0.70      0.69      2333

Flagellin_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.72      0.53      0.61      1079
           1       0.67      0.83      0.74      1254

    accuracy                           0.69      2333
   macro avg       0.70      0.68      0.67      2333
weighted avg       0.69      0.69      0.68      2333

              precision    recall  f1-score   support

           0       0.72      0.53      0.61      1079
           1       0.67      0.83      0.74      1254

    accuracy                           0.69      2333
   macro avg       0.70      0.68      0.67      2333
weighted avg       0.69      0.69      0.68      2333

Flagellin_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.37      0.27      0.31      4135
           1       0.40      0.51      0.45      3923

    accuracy                           0.39      8058
   macro avg       0.38      0.39      0.38      8058
weighted avg       0.38      0.39      0.38      8058

              precision    recall  f1-score   support

           0       0.37      0.27      0.31      4135
           1       0.40      0.51      0.45      3923

    accuracy                           0.39      8058
   macro avg       0.38      0.39      0.38      8058
weighted avg       0.38      0.39      0.38      8058

completed
