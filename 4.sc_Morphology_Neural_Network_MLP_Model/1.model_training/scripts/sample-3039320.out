[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '5ffc5410'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '655cb285'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '32d9f352'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '0895fb8e'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_0.010_DMSO_0.025 treatment_name: H2O2_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_0.010_DMSO_0.025
TREATMENT_NAME: H2O2_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (42759, 1276)
Number of total missing values across all columns: 85518
Data Subset Is Off
Wells held out for testing: ['B16' 'H22']
Wells to use for training, validation, and testing ['B17' 'H18' 'H19' 'B20' 'B21' 'H23' 'I18' 'I19' 'I22' 'I23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.715490).  Saving model ...
	 Train_Loss: 0.7362 Train_Acc: 34.302 Val_Loss: 0.7155  BEST VAL Loss: 0.7155  Val_Acc: 34.297

Epoch 1: Validation loss decreased (0.715490 --> 0.705656).  Saving model ...
	 Train_Loss: 0.7190 Train_Acc: 34.302 Val_Loss: 0.7057  BEST VAL Loss: 0.7057  Val_Acc: 34.297

Epoch 2: Validation loss decreased (0.705656 --> 0.697814).  Saving model ...
	 Train_Loss: 0.7071 Train_Acc: 40.758 Val_Loss: 0.6978  BEST VAL Loss: 0.6978  Val_Acc: 67.235

Epoch 3: Validation loss decreased (0.697814 --> 0.689953).  Saving model ...
	 Train_Loss: 0.6971 Train_Acc: 72.248 Val_Loss: 0.6900  BEST VAL Loss: 0.6900  Val_Acc: 70.619

Epoch 4: Validation loss decreased (0.689953 --> 0.683060).  Saving model ...
	 Train_Loss: 0.6878 Train_Acc: 73.766 Val_Loss: 0.6831  BEST VAL Loss: 0.6831  Val_Acc: 72.094

Epoch 5: Validation loss decreased (0.683060 --> 0.675278).  Saving model ...
	 Train_Loss: 0.6793 Train_Acc: 74.724 Val_Loss: 0.6753  BEST VAL Loss: 0.6753  Val_Acc: 73.193

Epoch 6: Validation loss decreased (0.675278 --> 0.668503).  Saving model ...
	 Train_Loss: 0.6709 Train_Acc: 75.653 Val_Loss: 0.6685  BEST VAL Loss: 0.6685  Val_Acc: 73.250

Epoch 7: Validation loss decreased (0.668503 --> 0.662010).  Saving model ...
	 Train_Loss: 0.6630 Train_Acc: 76.369 Val_Loss: 0.6620  BEST VAL Loss: 0.6620  Val_Acc: 73.077

Epoch 8: Validation loss decreased (0.662010 --> 0.656238).  Saving model ...
	 Train_Loss: 0.6554 Train_Acc: 76.807 Val_Loss: 0.6562  BEST VAL Loss: 0.6562  Val_Acc: 73.742

Epoch 9: Validation loss decreased (0.656238 --> 0.650949).  Saving model ...
	 Train_Loss: 0.6481 Train_Acc: 77.428 Val_Loss: 0.6509  BEST VAL Loss: 0.6509  Val_Acc: 74.349

Epoch 10: Validation loss decreased (0.650949 --> 0.644968).  Saving model ...
	 Train_Loss: 0.6413 Train_Acc: 77.486 Val_Loss: 0.6450  BEST VAL Loss: 0.6450  Val_Acc: 75.014

Epoch 11: Validation loss decreased (0.644968 --> 0.639532).  Saving model ...
	 Train_Loss: 0.6346 Train_Acc: 77.887 Val_Loss: 0.6395  BEST VAL Loss: 0.6395  Val_Acc: 75.593

Epoch 12: Validation loss decreased (0.639532 --> 0.634359).  Saving model ...
	 Train_Loss: 0.6284 Train_Acc: 78.061 Val_Loss: 0.6344  BEST VAL Loss: 0.6344  Val_Acc: 75.940

Epoch 13: Validation loss decreased (0.634359 --> 0.629334).  Saving model ...
	 Train_Loss: 0.6225 Train_Acc: 78.574 Val_Loss: 0.6293  BEST VAL Loss: 0.6293  Val_Acc: 76.374

Epoch 14: Validation loss decreased (0.629334 --> 0.624440).  Saving model ...
	 Train_Loss: 0.6167 Train_Acc: 78.730 Val_Loss: 0.6244  BEST VAL Loss: 0.6244  Val_Acc: 75.737

Epoch 15: Validation loss decreased (0.624440 --> 0.619851).  Saving model ...
	 Train_Loss: 0.6112 Train_Acc: 79.196 Val_Loss: 0.6199  BEST VAL Loss: 0.6199  Val_Acc: 76.171

Epoch 16: Validation loss decreased (0.619851 --> 0.615482).  Saving model ...
	 Train_Loss: 0.6058 Train_Acc: 79.333 Val_Loss: 0.6155  BEST VAL Loss: 0.6155  Val_Acc: 76.403

Epoch 17: Validation loss decreased (0.615482 --> 0.611556).  Saving model ...
	 Train_Loss: 0.6008 Train_Acc: 79.536 Val_Loss: 0.6116  BEST VAL Loss: 0.6116  Val_Acc: 76.750

Epoch 18: Validation loss decreased (0.611556 --> 0.607655).  Saving model ...
	 Train_Loss: 0.5960 Train_Acc: 79.464 Val_Loss: 0.6077  BEST VAL Loss: 0.6077  Val_Acc: 76.663

Epoch 19: Validation loss decreased (0.607655 --> 0.603926).  Saving model ...
	 Train_Loss: 0.5914 Train_Acc: 80.027 Val_Loss: 0.6039  BEST VAL Loss: 0.6039  Val_Acc: 76.287

Epoch 20: Validation loss decreased (0.603926 --> 0.600178).  Saving model ...
	 Train_Loss: 0.5870 Train_Acc: 79.854 Val_Loss: 0.6002  BEST VAL Loss: 0.6002  Val_Acc: 77.530

Epoch 21: Validation loss decreased (0.600178 --> 0.596609).  Saving model ...
	 Train_Loss: 0.5829 Train_Acc: 79.655 Val_Loss: 0.5966  BEST VAL Loss: 0.5966  Val_Acc: 77.154

Epoch 22: Validation loss decreased (0.596609 --> 0.593591).  Saving model ...
	 Train_Loss: 0.5788 Train_Acc: 80.262 Val_Loss: 0.5936  BEST VAL Loss: 0.5936  Val_Acc: 76.721

Epoch 23: Validation loss decreased (0.593591 --> 0.590654).  Saving model ...
	 Train_Loss: 0.5750 Train_Acc: 79.959 Val_Loss: 0.5907  BEST VAL Loss: 0.5907  Val_Acc: 76.229

Epoch 24: Validation loss decreased (0.590654 --> 0.587850).  Saving model ...
	 Train_Loss: 0.5714 Train_Acc: 80.338 Val_Loss: 0.5879  BEST VAL Loss: 0.5879  Val_Acc: 77.299

Epoch 25: Validation loss decreased (0.587850 --> 0.584916).  Saving model ...
	 Train_Loss: 0.5677 Train_Acc: 80.461 Val_Loss: 0.5849  BEST VAL Loss: 0.5849  Val_Acc: 77.270

Epoch 26: Validation loss decreased (0.584916 --> 0.582101).  Saving model ...
	 Train_Loss: 0.5644 Train_Acc: 80.508 Val_Loss: 0.5821  BEST VAL Loss: 0.5821  Val_Acc: 76.836

Epoch 27: Validation loss decreased (0.582101 --> 0.579454).  Saving model ...
	 Train_Loss: 0.5611 Train_Acc: 80.620 Val_Loss: 0.5795  BEST VAL Loss: 0.5795  Val_Acc: 77.154

Epoch 28: Validation loss decreased (0.579454 --> 0.576971).  Saving model ...
	 Train_Loss: 0.5580 Train_Acc: 80.823 Val_Loss: 0.5770  BEST VAL Loss: 0.5770  Val_Acc: 77.241

Epoch 29: Validation loss decreased (0.576971 --> 0.574467).  Saving model ...
	 Train_Loss: 0.5551 Train_Acc: 80.429 Val_Loss: 0.5745  BEST VAL Loss: 0.5745  Val_Acc: 77.791

Epoch 30: Validation loss decreased (0.574467 --> 0.572251).  Saving model ...
	 Train_Loss: 0.5522 Train_Acc: 80.812 Val_Loss: 0.5723  BEST VAL Loss: 0.5723  Val_Acc: 77.415

Epoch 31: Validation loss decreased (0.572251 --> 0.570056).  Saving model ...
	 Train_Loss: 0.5494 Train_Acc: 80.989 Val_Loss: 0.5701  BEST VAL Loss: 0.5701  Val_Acc: 77.646

Epoch 32: Validation loss decreased (0.570056 --> 0.568215).  Saving model ...
	 Train_Loss: 0.5466 Train_Acc: 81.144 Val_Loss: 0.5682  BEST VAL Loss: 0.5682  Val_Acc: 76.894

Epoch 33: Validation loss decreased (0.568215 --> 0.566271).  Saving model ...
	 Train_Loss: 0.5440 Train_Acc: 81.163 Val_Loss: 0.5663  BEST VAL Loss: 0.5663  Val_Acc: 77.501

Epoch 34: Validation loss decreased (0.566271 --> 0.564270).  Saving model ...
	 Train_Loss: 0.5416 Train_Acc: 80.826 Val_Loss: 0.5643  BEST VAL Loss: 0.5643  Val_Acc: 77.473

Epoch 35: Validation loss decreased (0.564270 --> 0.562559).  Saving model ...
	 Train_Loss: 0.5392 Train_Acc: 81.163 Val_Loss: 0.5626  BEST VAL Loss: 0.5626  Val_Acc: 77.646

Epoch 36: Validation loss decreased (0.562559 --> 0.560875).  Saving model ...
	 Train_Loss: 0.5369 Train_Acc: 81.155 Val_Loss: 0.5609  BEST VAL Loss: 0.5609  Val_Acc: 77.386

Epoch 37: Validation loss decreased (0.560875 --> 0.559247).  Saving model ...
	 Train_Loss: 0.5347 Train_Acc: 81.152 Val_Loss: 0.5592  BEST VAL Loss: 0.5592  Val_Acc: 78.109

Epoch 38: Validation loss decreased (0.559247 --> 0.557802).  Saving model ...
	 Train_Loss: 0.5326 Train_Acc: 80.870 Val_Loss: 0.5578  BEST VAL Loss: 0.5578  Val_Acc: 77.501

Epoch 39: Validation loss decreased (0.557802 --> 0.556224).  Saving model ...
	 Train_Loss: 0.5306 Train_Acc: 81.144 Val_Loss: 0.5562  BEST VAL Loss: 0.5562  Val_Acc: 77.154

Epoch 40: Validation loss decreased (0.556224 --> 0.554811).  Saving model ...
	 Train_Loss: 0.5287 Train_Acc: 80.989 Val_Loss: 0.5548  BEST VAL Loss: 0.5548  Val_Acc: 77.183

Epoch 41: Validation loss decreased (0.554811 --> 0.553328).  Saving model ...
	 Train_Loss: 0.5267 Train_Acc: 81.307 Val_Loss: 0.5533  BEST VAL Loss: 0.5533  Val_Acc: 77.068

Epoch 42: Validation loss decreased (0.553328 --> 0.552103).  Saving model ...
	 Train_Loss: 0.5250 Train_Acc: 80.993 Val_Loss: 0.5521  BEST VAL Loss: 0.5521  Val_Acc: 77.010

Epoch 43: Validation loss decreased (0.552103 --> 0.550788).  Saving model ...
	 Train_Loss: 0.5232 Train_Acc: 80.910 Val_Loss: 0.5508  BEST VAL Loss: 0.5508  Val_Acc: 77.906

Epoch 44: Validation loss decreased (0.550788 --> 0.549604).  Saving model ...
	 Train_Loss: 0.5215 Train_Acc: 81.376 Val_Loss: 0.5496  BEST VAL Loss: 0.5496  Val_Acc: 76.981

Epoch 45: Validation loss decreased (0.549604 --> 0.548127).  Saving model ...
	 Train_Loss: 0.5197 Train_Acc: 81.488 Val_Loss: 0.5481  BEST VAL Loss: 0.5481  Val_Acc: 77.877

Epoch 46: Validation loss decreased (0.548127 --> 0.547077).  Saving model ...
	 Train_Loss: 0.5180 Train_Acc: 81.463 Val_Loss: 0.5471  BEST VAL Loss: 0.5471  Val_Acc: 78.138

Epoch 47: Validation loss decreased (0.547077 --> 0.545895).  Saving model ...
	 Train_Loss: 0.5164 Train_Acc: 81.575 Val_Loss: 0.5459  BEST VAL Loss: 0.5459  Val_Acc: 77.588

Epoch 48: Validation loss decreased (0.545895 --> 0.544822).  Saving model ...
	 Train_Loss: 0.5148 Train_Acc: 81.452 Val_Loss: 0.5448  BEST VAL Loss: 0.5448  Val_Acc: 78.109

Epoch 49: Validation loss decreased (0.544822 --> 0.543827).  Saving model ...
	 Train_Loss: 0.5134 Train_Acc: 81.188 Val_Loss: 0.5438  BEST VAL Loss: 0.5438  Val_Acc: 77.357

Epoch 50: Validation loss decreased (0.543827 --> 0.542767).  Saving model ...
	 Train_Loss: 0.5119 Train_Acc: 81.419 Val_Loss: 0.5428  BEST VAL Loss: 0.5428  Val_Acc: 78.282

Epoch 51: Validation loss decreased (0.542767 --> 0.541831).  Saving model ...
	 Train_Loss: 0.5105 Train_Acc: 81.723 Val_Loss: 0.5418  BEST VAL Loss: 0.5418  Val_Acc: 78.195

Epoch 52: Validation loss decreased (0.541831 --> 0.540923).  Saving model ...
	 Train_Loss: 0.5091 Train_Acc: 81.752 Val_Loss: 0.5409  BEST VAL Loss: 0.5409  Val_Acc: 77.964

Epoch 53: Validation loss decreased (0.540923 --> 0.539961).  Saving model ...
	 Train_Loss: 0.5079 Train_Acc: 81.253 Val_Loss: 0.5400  BEST VAL Loss: 0.5400  Val_Acc: 78.311

Epoch 54: Validation loss decreased (0.539961 --> 0.539014).  Saving model ...
	 Train_Loss: 0.5066 Train_Acc: 81.495 Val_Loss: 0.5390  BEST VAL Loss: 0.5390  Val_Acc: 77.762

Epoch 55: Validation loss decreased (0.539014 --> 0.538165).  Saving model ...
	 Train_Loss: 0.5053 Train_Acc: 81.510 Val_Loss: 0.5382  BEST VAL Loss: 0.5382  Val_Acc: 78.369

Epoch 56: Validation loss decreased (0.538165 --> 0.537489).  Saving model ...
	 Train_Loss: 0.5041 Train_Acc: 81.484 Val_Loss: 0.5375  BEST VAL Loss: 0.5375  Val_Acc: 78.022

Epoch 57: Validation loss decreased (0.537489 --> 0.536569).  Saving model ...
	 Train_Loss: 0.5029 Train_Acc: 81.607 Val_Loss: 0.5366  BEST VAL Loss: 0.5366  Val_Acc: 78.514

Epoch 58: Validation loss decreased (0.536569 --> 0.535864).  Saving model ...
	 Train_Loss: 0.5017 Train_Acc: 81.849 Val_Loss: 0.5359  BEST VAL Loss: 0.5359  Val_Acc: 78.109

Epoch 59: Validation loss decreased (0.535864 --> 0.534991).  Saving model ...
	 Train_Loss: 0.5006 Train_Acc: 81.839 Val_Loss: 0.5350  BEST VAL Loss: 0.5350  Val_Acc: 78.224

Epoch 60: Validation loss decreased (0.534991 --> 0.534156).  Saving model ...
	 Train_Loss: 0.4995 Train_Acc: 81.669 Val_Loss: 0.5342  BEST VAL Loss: 0.5342  Val_Acc: 77.993

Epoch 61: Validation loss decreased (0.534156 --> 0.533339).  Saving model ...
	 Train_Loss: 0.4984 Train_Acc: 81.911 Val_Loss: 0.5333  BEST VAL Loss: 0.5333  Val_Acc: 78.224

Epoch 62: Validation loss decreased (0.533339 --> 0.532616).  Saving model ...
	 Train_Loss: 0.4974 Train_Acc: 81.571 Val_Loss: 0.5326  BEST VAL Loss: 0.5326  Val_Acc: 77.444

Epoch 63: Validation loss decreased (0.532616 --> 0.531919).  Saving model ...
	 Train_Loss: 0.4963 Train_Acc: 81.806 Val_Loss: 0.5319  BEST VAL Loss: 0.5319  Val_Acc: 77.906

Epoch 64: Validation loss decreased (0.531919 --> 0.531261).  Saving model ...
	 Train_Loss: 0.4953 Train_Acc: 81.820 Val_Loss: 0.5313  BEST VAL Loss: 0.5313  Val_Acc: 78.340

Epoch 65: Validation loss decreased (0.531261 --> 0.530555).  Saving model ...
	 Train_Loss: 0.4943 Train_Acc: 81.947 Val_Loss: 0.5306  BEST VAL Loss: 0.5306  Val_Acc: 78.167

Epoch 66: Validation loss decreased (0.530555 --> 0.529893).  Saving model ...
	 Train_Loss: 0.4933 Train_Acc: 81.849 Val_Loss: 0.5299  BEST VAL Loss: 0.5299  Val_Acc: 78.340

Epoch 67: Validation loss decreased (0.529893 --> 0.529202).  Saving model ...
	 Train_Loss: 0.4924 Train_Acc: 82.081 Val_Loss: 0.5292  BEST VAL Loss: 0.5292  Val_Acc: 78.051

Epoch 68: Validation loss decreased (0.529202 --> 0.528519).  Saving model ...
	 Train_Loss: 0.4915 Train_Acc: 81.755 Val_Loss: 0.5285  BEST VAL Loss: 0.5285  Val_Acc: 78.022

Epoch 69: Validation loss decreased (0.528519 --> 0.527998).  Saving model ...
	 Train_Loss: 0.4905 Train_Acc: 81.792 Val_Loss: 0.5280  BEST VAL Loss: 0.5280  Val_Acc: 78.456

Epoch 70: Validation loss decreased (0.527998 --> 0.527367).  Saving model ...
	 Train_Loss: 0.4897 Train_Acc: 81.802 Val_Loss: 0.5274  BEST VAL Loss: 0.5274  Val_Acc: 77.993

Epoch 71: Validation loss decreased (0.527367 --> 0.526787).  Saving model ...
	 Train_Loss: 0.4888 Train_Acc: 81.813 Val_Loss: 0.5268  BEST VAL Loss: 0.5268  Val_Acc: 78.340

Epoch 72: Validation loss decreased (0.526787 --> 0.526247).  Saving model ...
	 Train_Loss: 0.4880 Train_Acc: 81.564 Val_Loss: 0.5262  BEST VAL Loss: 0.5262  Val_Acc: 78.167

Epoch 73: Validation loss decreased (0.526247 --> 0.525775).  Saving model ...
	 Train_Loss: 0.4872 Train_Acc: 81.972 Val_Loss: 0.5258  BEST VAL Loss: 0.5258  Val_Acc: 78.138

Epoch 74: Validation loss decreased (0.525775 --> 0.525128).  Saving model ...
	 Train_Loss: 0.4864 Train_Acc: 81.886 Val_Loss: 0.5251  BEST VAL Loss: 0.5251  Val_Acc: 77.964

Epoch 75: Validation loss decreased (0.525128 --> 0.524577).  Saving model ...
	 Train_Loss: 0.4856 Train_Acc: 81.947 Val_Loss: 0.5246  BEST VAL Loss: 0.5246  Val_Acc: 78.167

Epoch 76: Validation loss decreased (0.524577 --> 0.524096).  Saving model ...
	 Train_Loss: 0.4849 Train_Acc: 81.806 Val_Loss: 0.5241  BEST VAL Loss: 0.5241  Val_Acc: 77.877

Epoch 77: Validation loss decreased (0.524096 --> 0.523587).  Saving model ...
	 Train_Loss: 0.4842 Train_Acc: 81.629 Val_Loss: 0.5236  BEST VAL Loss: 0.5236  Val_Acc: 78.398

Epoch 78: Validation loss decreased (0.523587 --> 0.523144).  Saving model ...
	 Train_Loss: 0.4834 Train_Acc: 81.726 Val_Loss: 0.5231  BEST VAL Loss: 0.5231  Val_Acc: 78.051

Epoch 79: Validation loss decreased (0.523144 --> 0.522605).  Saving model ...
	 Train_Loss: 0.4827 Train_Acc: 82.095 Val_Loss: 0.5226  BEST VAL Loss: 0.5226  Val_Acc: 78.543

Epoch 80: Validation loss decreased (0.522605 --> 0.522113).  Saving model ...
	 Train_Loss: 0.4820 Train_Acc: 81.766 Val_Loss: 0.5221  BEST VAL Loss: 0.5221  Val_Acc: 78.051

Epoch 81: Validation loss decreased (0.522113 --> 0.521683).  Saving model ...
	 Train_Loss: 0.4813 Train_Acc: 81.987 Val_Loss: 0.5217  BEST VAL Loss: 0.5217  Val_Acc: 78.195

Epoch 82: Validation loss decreased (0.521683 --> 0.521266).  Saving model ...
	 Train_Loss: 0.4806 Train_Acc: 81.980 Val_Loss: 0.5213  BEST VAL Loss: 0.5213  Val_Acc: 78.109

Epoch 83: Validation loss decreased (0.521266 --> 0.520869).  Saving model ...
	 Train_Loss: 0.4800 Train_Acc: 81.726 Val_Loss: 0.5209  BEST VAL Loss: 0.5209  Val_Acc: 78.138

Epoch 84: Validation loss decreased (0.520869 --> 0.520503).  Saving model ...
	 Train_Loss: 0.4794 Train_Acc: 81.860 Val_Loss: 0.5205  BEST VAL Loss: 0.5205  Val_Acc: 78.369

Epoch 85: Validation loss decreased (0.520503 --> 0.520046).  Saving model ...
	 Train_Loss: 0.4787 Train_Acc: 81.961 Val_Loss: 0.5200  BEST VAL Loss: 0.5200  Val_Acc: 78.253

Epoch 86: Validation loss decreased (0.520046 --> 0.519695).  Saving model ...
	 Train_Loss: 0.4781 Train_Acc: 82.005 Val_Loss: 0.5197  BEST VAL Loss: 0.5197  Val_Acc: 78.109

Epoch 87: Validation loss decreased (0.519695 --> 0.519328).  Saving model ...
	 Train_Loss: 0.4775 Train_Acc: 81.987 Val_Loss: 0.5193  BEST VAL Loss: 0.5193  Val_Acc: 78.051

Epoch 88: Validation loss decreased (0.519328 --> 0.518895).  Saving model ...
	 Train_Loss: 0.4768 Train_Acc: 82.355 Val_Loss: 0.5189  BEST VAL Loss: 0.5189  Val_Acc: 78.745

Epoch 89: Validation loss decreased (0.518895 --> 0.518634).  Saving model ...
	 Train_Loss: 0.4762 Train_Acc: 82.084 Val_Loss: 0.5186  BEST VAL Loss: 0.5186  Val_Acc: 78.514

Epoch 90: Validation loss decreased (0.518634 --> 0.518233).  Saving model ...
	 Train_Loss: 0.4757 Train_Acc: 82.124 Val_Loss: 0.5182  BEST VAL Loss: 0.5182  Val_Acc: 78.485

Epoch 91: Validation loss decreased (0.518233 --> 0.517795).  Saving model ...
	 Train_Loss: 0.4751 Train_Acc: 81.972 Val_Loss: 0.5178  BEST VAL Loss: 0.5178  Val_Acc: 78.629

Epoch 92: Validation loss decreased (0.517795 --> 0.517501).  Saving model ...
	 Train_Loss: 0.4746 Train_Acc: 81.933 Val_Loss: 0.5175  BEST VAL Loss: 0.5175  Val_Acc: 78.282

Epoch 93: Validation loss decreased (0.517501 --> 0.517109).  Saving model ...
	 Train_Loss: 0.4740 Train_Acc: 82.153 Val_Loss: 0.5171  BEST VAL Loss: 0.5171  Val_Acc: 78.282

Epoch 94: Validation loss decreased (0.517109 --> 0.516823).  Saving model ...
	 Train_Loss: 0.4735 Train_Acc: 82.142 Val_Loss: 0.5168  BEST VAL Loss: 0.5168  Val_Acc: 78.253

Epoch 95: Validation loss decreased (0.516823 --> 0.516432).  Saving model ...
	 Train_Loss: 0.4729 Train_Acc: 82.301 Val_Loss: 0.5164  BEST VAL Loss: 0.5164  Val_Acc: 78.514

Epoch 96: Validation loss decreased (0.516432 --> 0.516263).  Saving model ...
	 Train_Loss: 0.4724 Train_Acc: 82.092 Val_Loss: 0.5163  BEST VAL Loss: 0.5163  Val_Acc: 78.195

Epoch 97: Validation loss decreased (0.516263 --> 0.515892).  Saving model ...
	 Train_Loss: 0.4719 Train_Acc: 81.936 Val_Loss: 0.5159  BEST VAL Loss: 0.5159  Val_Acc: 78.080

Epoch 98: Validation loss decreased (0.515892 --> 0.515652).  Saving model ...
	 Train_Loss: 0.4714 Train_Acc: 82.308 Val_Loss: 0.5157  BEST VAL Loss: 0.5157  Val_Acc: 77.877

Epoch 99: Validation loss decreased (0.515652 --> 0.515281).  Saving model ...
	 Train_Loss: 0.4709 Train_Acc: 82.128 Val_Loss: 0.5153  BEST VAL Loss: 0.5153  Val_Acc: 77.993

LPS_0.010_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.66      0.73      0.69     18174
           1       0.35      0.28      0.31      9489

    accuracy                           0.57     27663
   macro avg       0.50      0.50      0.50     27663
weighted avg       0.55      0.57      0.56     27663

LPS_0.010_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.66      0.74      0.70      2272
           1       0.35      0.27      0.31      1186

    accuracy                           0.58      3458
   macro avg       0.50      0.50      0.50      3458
weighted avg       0.55      0.58      0.56      3458

LPS_0.010_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.66      0.73      0.69      2272
           1       0.35      0.28      0.31      1187

    accuracy                           0.58      3459
   macro avg       0.50      0.50      0.50      3459
weighted avg       0.55      0.58      0.56      3459

              precision    recall  f1-score   support

           0       0.66      0.73      0.69      2272
           1       0.35      0.28      0.31      1187

    accuracy                           0.58      3459
   macro avg       0.50      0.50      0.50      3459
weighted avg       0.55      0.58      0.56      3459

LPS_0.010_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.58      0.54      4182
           1       0.49      0.42      0.45      3997

    accuracy                           0.50      8179
   macro avg       0.50      0.50      0.50      8179
weighted avg       0.50      0.50      0.50      8179

              precision    recall  f1-score   support

           0       0.51      0.58      0.54      4182
           1       0.49      0.42      0.45      3997

    accuracy                           0.50      8179
   macro avg       0.50      0.50      0.50      8179
weighted avg       0.50      0.50      0.50      8179

completed
