[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd39c02bf'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '9ed19062'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'c93a8a87'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '79411534'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_1.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_1.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (30110, 1276)
Number of total missing values across all columns: 32916
Data Subset Is Off
Wells held out for testing: ['D20' 'L16']
Wells to use for training, validation, and testing ['D16' 'D17' 'D21' 'L17' 'L20' 'L21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.530180).  Saving model ...
	 Train_Loss: 0.6352 Train_Acc: 56.295 Val_Loss: 0.5302  BEST VAL Loss: 0.5302  Val_Acc: 75.158

Epoch 1: Validation loss decreased (0.530180 --> 0.450999).  Saving model ...
	 Train_Loss: 0.5741 Train_Acc: 73.848 Val_Loss: 0.4510  BEST VAL Loss: 0.4510  Val_Acc: 87.579

Epoch 2: Validation loss decreased (0.450999 --> 0.412817).  Saving model ...
	 Train_Loss: 0.5303 Train_Acc: 78.828 Val_Loss: 0.4128  BEST VAL Loss: 0.4128  Val_Acc: 88.209

Epoch 3: Validation loss decreased (0.412817 --> 0.391415).  Saving model ...
	 Train_Loss: 0.5018 Train_Acc: 81.991 Val_Loss: 0.3914  BEST VAL Loss: 0.3914  Val_Acc: 88.839

Epoch 4: Validation loss decreased (0.391415 --> 0.367771).  Saving model ...
	 Train_Loss: 0.4786 Train_Acc: 83.843 Val_Loss: 0.3678  BEST VAL Loss: 0.3678  Val_Acc: 91.179

Epoch 5: Validation loss decreased (0.367771 --> 0.347860).  Saving model ...
	 Train_Loss: 0.4592 Train_Acc: 85.250 Val_Loss: 0.3479  BEST VAL Loss: 0.3479  Val_Acc: 91.719

Epoch 6: Validation loss decreased (0.347860 --> 0.331204).  Saving model ...
	 Train_Loss: 0.4432 Train_Acc: 86.099 Val_Loss: 0.3312  BEST VAL Loss: 0.3312  Val_Acc: 92.844

Epoch 7: Validation loss decreased (0.331204 --> 0.315260).  Saving model ...
	 Train_Loss: 0.4304 Train_Acc: 86.600 Val_Loss: 0.3153  BEST VAL Loss: 0.3153  Val_Acc: 94.419

Epoch 8: Validation loss decreased (0.315260 --> 0.302947).  Saving model ...
	 Train_Loss: 0.4191 Train_Acc: 87.315 Val_Loss: 0.3029  BEST VAL Loss: 0.3029  Val_Acc: 94.194

Epoch 9: Validation loss decreased (0.302947 --> 0.292235).  Saving model ...
	 Train_Loss: 0.4091 Train_Acc: 87.664 Val_Loss: 0.2922  BEST VAL Loss: 0.2922  Val_Acc: 94.734

Epoch 10: Validation loss decreased (0.292235 --> 0.282207).  Saving model ...
	 Train_Loss: 0.3993 Train_Acc: 88.818 Val_Loss: 0.2822  BEST VAL Loss: 0.2822  Val_Acc: 95.230

Epoch 11: Validation loss decreased (0.282207 --> 0.273708).  Saving model ...
	 Train_Loss: 0.3907 Train_Acc: 89.144 Val_Loss: 0.2737  BEST VAL Loss: 0.2737  Val_Acc: 95.185

Epoch 12: Validation loss decreased (0.273708 --> 0.265942).  Saving model ...
	 Train_Loss: 0.3831 Train_Acc: 89.257 Val_Loss: 0.2659  BEST VAL Loss: 0.2659  Val_Acc: 95.905

Epoch 13: Validation loss decreased (0.265942 --> 0.259200).  Saving model ...
	 Train_Loss: 0.3763 Train_Acc: 89.527 Val_Loss: 0.2592  BEST VAL Loss: 0.2592  Val_Acc: 95.725

Epoch 14: Validation loss decreased (0.259200 --> 0.252543).  Saving model ...
	 Train_Loss: 0.3704 Train_Acc: 89.409 Val_Loss: 0.2525  BEST VAL Loss: 0.2525  Val_Acc: 96.085

Epoch 15: Validation loss decreased (0.252543 --> 0.246783).  Saving model ...
	 Train_Loss: 0.3649 Train_Acc: 89.898 Val_Loss: 0.2468  BEST VAL Loss: 0.2468  Val_Acc: 96.130

Epoch 16: Validation loss decreased (0.246783 --> 0.242103).  Saving model ...
	 Train_Loss: 0.3602 Train_Acc: 89.696 Val_Loss: 0.2421  BEST VAL Loss: 0.2421  Val_Acc: 96.265

Epoch 17: Validation loss decreased (0.242103 --> 0.237470).  Saving model ...
	 Train_Loss: 0.3556 Train_Acc: 90.230 Val_Loss: 0.2375  BEST VAL Loss: 0.2375  Val_Acc: 96.355

Epoch 18: Validation loss decreased (0.237470 --> 0.234293).  Saving model ...
	 Train_Loss: 0.3512 Train_Acc: 90.444 Val_Loss: 0.2343  BEST VAL Loss: 0.2343  Val_Acc: 96.130

Epoch 19: Validation loss decreased (0.234293 --> 0.231727).  Saving model ...
	 Train_Loss: 0.3479 Train_Acc: 89.904 Val_Loss: 0.2317  BEST VAL Loss: 0.2317  Val_Acc: 95.680

Epoch 20: Validation loss decreased (0.231727 --> 0.229040).  Saving model ...
	 Train_Loss: 0.3446 Train_Acc: 90.331 Val_Loss: 0.2290  BEST VAL Loss: 0.2290  Val_Acc: 95.770

Epoch 21: Validation loss decreased (0.229040 --> 0.226512).  Saving model ...
	 Train_Loss: 0.3415 Train_Acc: 90.185 Val_Loss: 0.2265  BEST VAL Loss: 0.2265  Val_Acc: 96.085

Epoch 22: Validation loss decreased (0.226512 --> 0.223446).  Saving model ...
	 Train_Loss: 0.3386 Train_Acc: 90.444 Val_Loss: 0.2234  BEST VAL Loss: 0.2234  Val_Acc: 96.715

Epoch 23: Validation loss decreased (0.223446 --> 0.220794).  Saving model ...
	 Train_Loss: 0.3357 Train_Acc: 90.709 Val_Loss: 0.2208  BEST VAL Loss: 0.2208  Val_Acc: 96.625

Epoch 24: Validation loss decreased (0.220794 --> 0.218145).  Saving model ...
	 Train_Loss: 0.3335 Train_Acc: 90.095 Val_Loss: 0.2181  BEST VAL Loss: 0.2181  Val_Acc: 96.625

Epoch 25: Validation loss decreased (0.218145 --> 0.215798).  Saving model ...
	 Train_Loss: 0.3309 Train_Acc: 90.680 Val_Loss: 0.2158  BEST VAL Loss: 0.2158  Val_Acc: 96.715

Epoch 26: Validation loss decreased (0.215798 --> 0.213449).  Saving model ...
	 Train_Loss: 0.3284 Train_Acc: 91.069 Val_Loss: 0.2134  BEST VAL Loss: 0.2134  Val_Acc: 96.580

Epoch 27: Validation loss decreased (0.213449 --> 0.211197).  Saving model ...
	 Train_Loss: 0.3263 Train_Acc: 90.607 Val_Loss: 0.2112  BEST VAL Loss: 0.2112  Val_Acc: 96.760

Epoch 28: Validation loss decreased (0.211197 --> 0.209060).  Saving model ...
	 Train_Loss: 0.3242 Train_Acc: 91.074 Val_Loss: 0.2091  BEST VAL Loss: 0.2091  Val_Acc: 96.715

Epoch 29: Validation loss decreased (0.209060 --> 0.207356).  Saving model ...
	 Train_Loss: 0.3224 Train_Acc: 90.652 Val_Loss: 0.2074  BEST VAL Loss: 0.2074  Val_Acc: 96.760

Epoch 30: Validation loss decreased (0.207356 --> 0.205579).  Saving model ...
	 Train_Loss: 0.3204 Train_Acc: 90.928 Val_Loss: 0.2056  BEST VAL Loss: 0.2056  Val_Acc: 96.400

Epoch 31: Validation loss decreased (0.205579 --> 0.204243).  Saving model ...
	 Train_Loss: 0.3189 Train_Acc: 90.489 Val_Loss: 0.2042  BEST VAL Loss: 0.2042  Val_Acc: 96.085

Epoch 32: Validation loss decreased (0.204243 --> 0.202289).  Saving model ...
	 Train_Loss: 0.3172 Train_Acc: 90.928 Val_Loss: 0.2023  BEST VAL Loss: 0.2023  Val_Acc: 96.895

Epoch 33: Validation loss decreased (0.202289 --> 0.200594).  Saving model ...
	 Train_Loss: 0.3154 Train_Acc: 91.305 Val_Loss: 0.2006  BEST VAL Loss: 0.2006  Val_Acc: 96.535

Epoch 34: Validation loss decreased (0.200594 --> 0.199194).  Saving model ...
	 Train_Loss: 0.3138 Train_Acc: 91.249 Val_Loss: 0.1992  BEST VAL Loss: 0.1992  Val_Acc: 96.355

Epoch 35: Validation loss decreased (0.199194 --> 0.197866).  Saving model ...
	 Train_Loss: 0.3123 Train_Acc: 91.204 Val_Loss: 0.1979  BEST VAL Loss: 0.1979  Val_Acc: 96.985

Epoch 36: Validation loss decreased (0.197866 --> 0.196700).  Saving model ...
	 Train_Loss: 0.3108 Train_Acc: 91.283 Val_Loss: 0.1967  BEST VAL Loss: 0.1967  Val_Acc: 96.625

Epoch 37: Validation loss decreased (0.196700 --> 0.195542).  Saving model ...
	 Train_Loss: 0.3095 Train_Acc: 91.125 Val_Loss: 0.1955  BEST VAL Loss: 0.1955  Val_Acc: 96.850

Epoch 38: Validation loss decreased (0.195542 --> 0.194603).  Saving model ...
	 Train_Loss: 0.3081 Train_Acc: 91.536 Val_Loss: 0.1946  BEST VAL Loss: 0.1946  Val_Acc: 96.490

Epoch 39: Validation loss decreased (0.194603 --> 0.193786).  Saving model ...
	 Train_Loss: 0.3067 Train_Acc: 91.401 Val_Loss: 0.1938  BEST VAL Loss: 0.1938  Val_Acc: 96.715

Epoch 40: Validation loss decreased (0.193786 --> 0.193217).  Saving model ...
	 Train_Loss: 0.3054 Train_Acc: 91.328 Val_Loss: 0.1932  BEST VAL Loss: 0.1932  Val_Acc: 96.580

Epoch 41: Validation loss decreased (0.193217 --> 0.192879).  Saving model ...
	 Train_Loss: 0.3042 Train_Acc: 91.384 Val_Loss: 0.1929  BEST VAL Loss: 0.1929  Val_Acc: 96.445

Epoch 42: Validation loss decreased (0.192879 --> 0.192436).  Saving model ...
	 Train_Loss: 0.3032 Train_Acc: 91.198 Val_Loss: 0.1924  BEST VAL Loss: 0.1924  Val_Acc: 96.040

Epoch 43: Validation loss decreased (0.192436 --> 0.191448).  Saving model ...
	 Train_Loss: 0.3023 Train_Acc: 91.091 Val_Loss: 0.1914  BEST VAL Loss: 0.1914  Val_Acc: 96.940

Epoch 44: Validation loss decreased (0.191448 --> 0.190539).  Saving model ...
	 Train_Loss: 0.3013 Train_Acc: 91.153 Val_Loss: 0.1905  BEST VAL Loss: 0.1905  Val_Acc: 96.670

Epoch 45: Validation loss decreased (0.190539 --> 0.189913).  Saving model ...
	 Train_Loss: 0.3004 Train_Acc: 91.148 Val_Loss: 0.1899  BEST VAL Loss: 0.1899  Val_Acc: 96.310

Epoch 46: Validation loss decreased (0.189913 --> 0.189056).  Saving model ...
	 Train_Loss: 0.2997 Train_Acc: 90.765 Val_Loss: 0.1891  BEST VAL Loss: 0.1891  Val_Acc: 97.390

Epoch 47: Validation loss decreased (0.189056 --> 0.188316).  Saving model ...
	 Train_Loss: 0.2989 Train_Acc: 90.877 Val_Loss: 0.1883  BEST VAL Loss: 0.1883  Val_Acc: 96.895

Epoch 48: Validation loss decreased (0.188316 --> 0.187865).  Saving model ...
	 Train_Loss: 0.2982 Train_Acc: 91.108 Val_Loss: 0.1879  BEST VAL Loss: 0.1879  Val_Acc: 97.120

Epoch 49: Validation loss decreased (0.187865 --> 0.187324).  Saving model ...
	 Train_Loss: 0.2974 Train_Acc: 91.316 Val_Loss: 0.1873  BEST VAL Loss: 0.1873  Val_Acc: 96.940

Epoch 50: Validation loss decreased (0.187324 --> 0.186785).  Saving model ...
	 Train_Loss: 0.2966 Train_Acc: 91.097 Val_Loss: 0.1868  BEST VAL Loss: 0.1868  Val_Acc: 97.120

Epoch 51: Validation loss decreased (0.186785 --> 0.186089).  Saving model ...
	 Train_Loss: 0.2960 Train_Acc: 91.136 Val_Loss: 0.1861  BEST VAL Loss: 0.1861  Val_Acc: 96.895

Epoch 52: Validation loss decreased (0.186089 --> 0.185303).  Saving model ...
	 Train_Loss: 0.2952 Train_Acc: 91.513 Val_Loss: 0.1853  BEST VAL Loss: 0.1853  Val_Acc: 97.030

Epoch 53: Validation loss decreased (0.185303 --> 0.184297).  Saving model ...
	 Train_Loss: 0.2944 Train_Acc: 91.525 Val_Loss: 0.1843  BEST VAL Loss: 0.1843  Val_Acc: 97.435

Epoch 54: Validation loss decreased (0.184297 --> 0.183387).  Saving model ...
	 Train_Loss: 0.2937 Train_Acc: 91.412 Val_Loss: 0.1834  BEST VAL Loss: 0.1834  Val_Acc: 97.120

Epoch 55: Validation loss decreased (0.183387 --> 0.182584).  Saving model ...
	 Train_Loss: 0.2930 Train_Acc: 91.451 Val_Loss: 0.1826  BEST VAL Loss: 0.1826  Val_Acc: 97.390

Epoch 56: Validation loss decreased (0.182584 --> 0.181812).  Saving model ...
	 Train_Loss: 0.2924 Train_Acc: 91.266 Val_Loss: 0.1818  BEST VAL Loss: 0.1818  Val_Acc: 97.120

Epoch 57: Validation loss decreased (0.181812 --> 0.181125).  Saving model ...
	 Train_Loss: 0.2917 Train_Acc: 91.395 Val_Loss: 0.1811  BEST VAL Loss: 0.1811  Val_Acc: 97.255

Epoch 58: Validation loss decreased (0.181125 --> 0.180430).  Saving model ...
	 Train_Loss: 0.2910 Train_Acc: 91.485 Val_Loss: 0.1804  BEST VAL Loss: 0.1804  Val_Acc: 97.390

Epoch 59: Validation loss decreased (0.180430 --> 0.179779).  Saving model ...
	 Train_Loss: 0.2904 Train_Acc: 91.108 Val_Loss: 0.1798  BEST VAL Loss: 0.1798  Val_Acc: 97.435

Epoch 60: Validation loss decreased (0.179779 --> 0.179436).  Saving model ...
	 Train_Loss: 0.2897 Train_Acc: 91.491 Val_Loss: 0.1794  BEST VAL Loss: 0.1794  Val_Acc: 97.165

Epoch 61: Validation loss decreased (0.179436 --> 0.178859).  Saving model ...
	 Train_Loss: 0.2891 Train_Acc: 91.620 Val_Loss: 0.1789  BEST VAL Loss: 0.1789  Val_Acc: 97.525

Epoch 62: Validation loss decreased (0.178859 --> 0.178520).  Saving model ...
	 Train_Loss: 0.2886 Train_Acc: 91.435 Val_Loss: 0.1785  BEST VAL Loss: 0.1785  Val_Acc: 96.490

Epoch 63: Validation loss decreased (0.178520 --> 0.178128).  Saving model ...
	 Train_Loss: 0.2882 Train_Acc: 91.142 Val_Loss: 0.1781  BEST VAL Loss: 0.1781  Val_Acc: 96.805

Epoch 64: Validation loss decreased (0.178128 --> 0.177520).  Saving model ...
	 Train_Loss: 0.2876 Train_Acc: 91.688 Val_Loss: 0.1775  BEST VAL Loss: 0.1775  Val_Acc: 97.435

Epoch 65: Validation loss decreased (0.177520 --> 0.177118).  Saving model ...
	 Train_Loss: 0.2870 Train_Acc: 91.547 Val_Loss: 0.1771  BEST VAL Loss: 0.1771  Val_Acc: 97.480

Epoch 66: Validation loss decreased (0.177118 --> 0.176636).  Saving model ...
	 Train_Loss: 0.2864 Train_Acc: 91.986 Val_Loss: 0.1766  BEST VAL Loss: 0.1766  Val_Acc: 97.255

Epoch 67: Validation loss decreased (0.176636 --> 0.176140).  Saving model ...
	 Train_Loss: 0.2857 Train_Acc: 91.986 Val_Loss: 0.1761  BEST VAL Loss: 0.1761  Val_Acc: 97.210

Epoch 68: Validation loss decreased (0.176140 --> 0.175585).  Saving model ...
	 Train_Loss: 0.2852 Train_Acc: 91.862 Val_Loss: 0.1756  BEST VAL Loss: 0.1756  Val_Acc: 97.615

Epoch 69: Validation loss decreased (0.175585 --> 0.175056).  Saving model ...
	 Train_Loss: 0.2846 Train_Acc: 91.778 Val_Loss: 0.1751  BEST VAL Loss: 0.1751  Val_Acc: 97.705

Epoch 70: Validation loss decreased (0.175056 --> 0.174583).  Saving model ...
	 Train_Loss: 0.2841 Train_Acc: 91.699 Val_Loss: 0.1746  BEST VAL Loss: 0.1746  Val_Acc: 97.660

Epoch 71: Validation loss decreased (0.174583 --> 0.174076).  Saving model ...
	 Train_Loss: 0.2836 Train_Acc: 91.682 Val_Loss: 0.1741  BEST VAL Loss: 0.1741  Val_Acc: 97.615

Epoch 72: Validation loss decreased (0.174076 --> 0.173772).  Saving model ...
	 Train_Loss: 0.2831 Train_Acc: 91.722 Val_Loss: 0.1738  BEST VAL Loss: 0.1738  Val_Acc: 97.615

Epoch 73: Validation loss decreased (0.173772 --> 0.173571).  Saving model ...
	 Train_Loss: 0.2827 Train_Acc: 91.496 Val_Loss: 0.1736  BEST VAL Loss: 0.1736  Val_Acc: 97.075

Epoch 74: Validation loss decreased (0.173571 --> 0.173008).  Saving model ...
	 Train_Loss: 0.2823 Train_Acc: 91.744 Val_Loss: 0.1730  BEST VAL Loss: 0.1730  Val_Acc: 97.525

Epoch 75: Validation loss decreased (0.173008 --> 0.172396).  Saving model ...
	 Train_Loss: 0.2818 Train_Acc: 91.935 Val_Loss: 0.1724  BEST VAL Loss: 0.1724  Val_Acc: 97.570

Epoch 76: Validation loss decreased (0.172396 --> 0.171937).  Saving model ...
	 Train_Loss: 0.2813 Train_Acc: 91.986 Val_Loss: 0.1719  BEST VAL Loss: 0.1719  Val_Acc: 97.390

Epoch 77: Validation loss decreased (0.171937 --> 0.171553).  Saving model ...
	 Train_Loss: 0.2809 Train_Acc: 91.485 Val_Loss: 0.1716  BEST VAL Loss: 0.1716  Val_Acc: 97.480

Epoch 78: Validation loss decreased (0.171553 --> 0.170999).  Saving model ...
	 Train_Loss: 0.2804 Train_Acc: 91.986 Val_Loss: 0.1710  BEST VAL Loss: 0.1710  Val_Acc: 97.795

Epoch 79: Validation loss decreased (0.170999 --> 0.170754).  Saving model ...
	 Train_Loss: 0.2800 Train_Acc: 91.800 Val_Loss: 0.1708  BEST VAL Loss: 0.1708  Val_Acc: 97.030

Epoch 80: Validation loss decreased (0.170754 --> 0.170479).  Saving model ...
	 Train_Loss: 0.2796 Train_Acc: 91.778 Val_Loss: 0.1705  BEST VAL Loss: 0.1705  Val_Acc: 96.625

Epoch 81: Validation loss decreased (0.170479 --> 0.170122).  Saving model ...
	 Train_Loss: 0.2793 Train_Acc: 91.423 Val_Loss: 0.1701  BEST VAL Loss: 0.1701  Val_Acc: 97.300

Epoch 82: Validation loss decreased (0.170122 --> 0.169752).  Saving model ...
	 Train_Loss: 0.2789 Train_Acc: 91.885 Val_Loss: 0.1698  BEST VAL Loss: 0.1698  Val_Acc: 96.850

Epoch 83: Validation loss decreased (0.169752 --> 0.169316).  Saving model ...
	 Train_Loss: 0.2785 Train_Acc: 91.913 Val_Loss: 0.1693  BEST VAL Loss: 0.1693  Val_Acc: 97.390

Epoch 84: Validation loss decreased (0.169316 --> 0.168862).  Saving model ...
	 Train_Loss: 0.2782 Train_Acc: 91.817 Val_Loss: 0.1689  BEST VAL Loss: 0.1689  Val_Acc: 97.795

Epoch 85: Validation loss decreased (0.168862 --> 0.168440).  Saving model ...
	 Train_Loss: 0.2778 Train_Acc: 91.660 Val_Loss: 0.1684  BEST VAL Loss: 0.1684  Val_Acc: 97.840

Epoch 86: Validation loss decreased (0.168440 --> 0.168033).  Saving model ...
	 Train_Loss: 0.2774 Train_Acc: 91.969 Val_Loss: 0.1680  BEST VAL Loss: 0.1680  Val_Acc: 97.255

Epoch 87: Validation loss decreased (0.168033 --> 0.167685).  Saving model ...
	 Train_Loss: 0.2771 Train_Acc: 91.463 Val_Loss: 0.1677  BEST VAL Loss: 0.1677  Val_Acc: 97.660

Epoch 88: Validation loss decreased (0.167685 --> 0.167276).  Saving model ...
	 Train_Loss: 0.2768 Train_Acc: 91.857 Val_Loss: 0.1673  BEST VAL Loss: 0.1673  Val_Acc: 97.615

Epoch 89: Validation loss decreased (0.167276 --> 0.166957).  Saving model ...
	 Train_Loss: 0.2765 Train_Acc: 91.817 Val_Loss: 0.1670  BEST VAL Loss: 0.1670  Val_Acc: 97.525

Epoch 90: Validation loss decreased (0.166957 --> 0.166648).  Saving model ...
	 Train_Loss: 0.2760 Train_Acc: 92.234 Val_Loss: 0.1666  BEST VAL Loss: 0.1666  Val_Acc: 97.705

Epoch 91: Validation loss decreased (0.166648 --> 0.166356).  Saving model ...
	 Train_Loss: 0.2757 Train_Acc: 91.857 Val_Loss: 0.1664  BEST VAL Loss: 0.1664  Val_Acc: 97.570

Epoch 92: Validation loss decreased (0.166356 --> 0.165965).  Saving model ...
	 Train_Loss: 0.2753 Train_Acc: 92.110 Val_Loss: 0.1660  BEST VAL Loss: 0.1660  Val_Acc: 97.795

Epoch 93: Validation loss decreased (0.165965 --> 0.165649).  Saving model ...
	 Train_Loss: 0.2749 Train_Acc: 91.896 Val_Loss: 0.1656  BEST VAL Loss: 0.1656  Val_Acc: 97.660

Epoch 94: Validation loss decreased (0.165649 --> 0.165323).  Saving model ...
	 Train_Loss: 0.2746 Train_Acc: 92.093 Val_Loss: 0.1653  BEST VAL Loss: 0.1653  Val_Acc: 97.660

Epoch 95: Validation loss decreased (0.165323 --> 0.165122).  Saving model ...
	 Train_Loss: 0.2743 Train_Acc: 91.648 Val_Loss: 0.1651  BEST VAL Loss: 0.1651  Val_Acc: 97.705

Epoch 96: Validation loss decreased (0.165122 --> 0.164879).  Saving model ...
	 Train_Loss: 0.2740 Train_Acc: 91.834 Val_Loss: 0.1649  BEST VAL Loss: 0.1649  Val_Acc: 97.300

Epoch 97: Validation loss decreased (0.164879 --> 0.164585).  Saving model ...
	 Train_Loss: 0.2737 Train_Acc: 91.851 Val_Loss: 0.1646  BEST VAL Loss: 0.1646  Val_Acc: 97.345

Epoch 98: Validation loss decreased (0.164585 --> 0.164255).  Saving model ...
	 Train_Loss: 0.2734 Train_Acc: 92.014 Val_Loss: 0.1643  BEST VAL Loss: 0.1643  Val_Acc: 97.255

Epoch 99: Validation loss decreased (0.164255 --> 0.163960).  Saving model ...
	 Train_Loss: 0.2730 Train_Acc: 92.267 Val_Loss: 0.1640  BEST VAL Loss: 0.1640  Val_Acc: 97.525

LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       1.00      0.98      0.99      9832
           1       0.98      1.00      0.99      7937

    accuracy                           0.99     17769
   macro avg       0.99      0.99      0.99     17769
weighted avg       0.99      0.99      0.99     17769

LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      0.96      0.98      1229
           1       0.96      0.99      0.97       993

    accuracy                           0.98      2222
   macro avg       0.97      0.98      0.98      2222
weighted avg       0.98      0.98      0.98      2222

LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       1.00      0.95      0.97      1229
           1       0.94      0.99      0.97       993

    accuracy                           0.97      2222
   macro avg       0.97      0.97      0.97      2222
weighted avg       0.97      0.97      0.97      2222

              precision    recall  f1-score   support

           0       1.00      0.95      0.97      1229
           1       0.94      0.99      0.97       993

    accuracy                           0.97      2222
   macro avg       0.97      0.97      0.97      2222
weighted avg       0.97      0.97      0.97      2222

LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.97      0.97      4168
           1       0.97      0.97      0.97      3729

    accuracy                           0.97      7897
   macro avg       0.97      0.97      0.97      7897
weighted avg       0.97      0.97      0.97      7897

              precision    recall  f1-score   support

           0       0.97      0.97      0.97      4168
           1       0.97      0.97      0.97      3729

    accuracy                           0.97      7897
   macro avg       0.97      0.97      0.97      7897
weighted avg       0.97      0.97      0.97      7897

completed
