[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '9f676c61'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '45109bfd'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'c86e50c6'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'cebc47ba'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: LPS_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: LPS_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (30110, 1276)
Number of total missing values across all columns: 32916
Data Subset Is Off
Wells held out for testing: ['D20' 'L16']
Wells to use for training, validation, and testing ['D16' 'D17' 'D21' 'L17' 'L20' 'L21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.228032).  Saving model ...
	 Train_Loss: 1.1770 Train_Acc: 79.098 Val_Loss: 0.2280  BEST VAL Loss: 0.2280  Val_Acc: 90.369

Epoch 1: Validation loss decreased (0.228032 --> 0.201459).  Saving model ...
	 Train_Loss: 0.7179 Train_Acc: 89.138 Val_Loss: 0.2015  BEST VAL Loss: 0.2015  Val_Acc: 94.284

Epoch 2: Validation loss decreased (0.201459 --> 0.181189).  Saving model ...
	 Train_Loss: 0.5510 Train_Acc: 91.153 Val_Loss: 0.1812  BEST VAL Loss: 0.1812  Val_Acc: 94.869

Epoch 3: Validation loss decreased (0.181189 --> 0.166993).  Saving model ...
	 Train_Loss: 0.4608 Train_Acc: 91.997 Val_Loss: 0.1670  BEST VAL Loss: 0.1670  Val_Acc: 95.635

Epoch 4: Validation loss decreased (0.166993 --> 0.159059).  Saving model ...
	 Train_Loss: 0.4035 Train_Acc: 92.611 Val_Loss: 0.1591  BEST VAL Loss: 0.1591  Val_Acc: 95.545

Epoch 5: Validation loss decreased (0.159059 --> 0.150486).  Saving model ...
	 Train_Loss: 0.3625 Train_Acc: 93.134 Val_Loss: 0.1505  BEST VAL Loss: 0.1505  Val_Acc: 95.815

Epoch 6: Validation loss decreased (0.150486 --> 0.145772).  Saving model ...
	 Train_Loss: 0.3315 Train_Acc: 93.798 Val_Loss: 0.1458  BEST VAL Loss: 0.1458  Val_Acc: 95.905

Epoch 7: Validation loss decreased (0.145772 --> 0.142890).  Saving model ...
	 Train_Loss: 0.3077 Train_Acc: 93.815 Val_Loss: 0.1429  BEST VAL Loss: 0.1429  Val_Acc: 95.905

Epoch 8: Validation loss decreased (0.142890 --> 0.138353).  Saving model ...
	 Train_Loss: 0.2880 Train_Acc: 94.192 Val_Loss: 0.1384  BEST VAL Loss: 0.1384  Val_Acc: 95.815

Epoch 9: Validation loss decreased (0.138353 --> 0.134237).  Saving model ...
	 Train_Loss: 0.2729 Train_Acc: 93.866 Val_Loss: 0.1342  BEST VAL Loss: 0.1342  Val_Acc: 96.175

Epoch 10: Validation loss decreased (0.134237 --> 0.130659).  Saving model ...
	 Train_Loss: 0.2588 Train_Acc: 94.338 Val_Loss: 0.1307  BEST VAL Loss: 0.1307  Val_Acc: 96.715

Epoch 11: Validation loss decreased (0.130659 --> 0.127967).  Saving model ...
	 Train_Loss: 0.2476 Train_Acc: 94.277 Val_Loss: 0.1280  BEST VAL Loss: 0.1280  Val_Acc: 96.310

Epoch 12: Validation loss decreased (0.127967 --> 0.125030).  Saving model ...
	 Train_Loss: 0.2375 Train_Acc: 94.625 Val_Loss: 0.1250  BEST VAL Loss: 0.1250  Val_Acc: 96.445

Epoch 13: Validation loss decreased (0.125030 --> 0.124069).  Saving model ...
	 Train_Loss: 0.2283 Train_Acc: 94.845 Val_Loss: 0.1241  BEST VAL Loss: 0.1241  Val_Acc: 96.355

Epoch 14: Validation loss decreased (0.124069 --> 0.122663).  Saving model ...
	 Train_Loss: 0.2202 Train_Acc: 94.890 Val_Loss: 0.1227  BEST VAL Loss: 0.1227  Val_Acc: 96.715

Epoch 15: Validation loss decreased (0.122663 --> 0.122165).  Saving model ...
	 Train_Loss: 0.2132 Train_Acc: 94.710 Val_Loss: 0.1222  BEST VAL Loss: 0.1222  Val_Acc: 96.985

Epoch 16: Validation loss decreased (0.122165 --> 0.121173).  Saving model ...
	 Train_Loss: 0.2071 Train_Acc: 94.721 Val_Loss: 0.1212  BEST VAL Loss: 0.1212  Val_Acc: 96.535

Epoch 17: Validation loss decreased (0.121173 --> 0.119560).  Saving model ...
	 Train_Loss: 0.2017 Train_Acc: 94.699 Val_Loss: 0.1196  BEST VAL Loss: 0.1196  Val_Acc: 96.715

Epoch 18: Validation loss decreased (0.119560 --> 0.117942).  Saving model ...
	 Train_Loss: 0.1965 Train_Acc: 94.918 Val_Loss: 0.1179  BEST VAL Loss: 0.1179  Val_Acc: 96.580

Epoch 19: Validation loss decreased (0.117942 --> 0.115974).  Saving model ...
	 Train_Loss: 0.1915 Train_Acc: 95.194 Val_Loss: 0.1160  BEST VAL Loss: 0.1160  Val_Acc: 96.940

Epoch 20: Validation loss decreased (0.115974 --> 0.114176).  Saving model ...
	 Train_Loss: 0.1867 Train_Acc: 95.487 Val_Loss: 0.1142  BEST VAL Loss: 0.1142  Val_Acc: 97.390

Epoch 21: Validation loss decreased (0.114176 --> 0.113173).  Saving model ...
	 Train_Loss: 0.1837 Train_Acc: 94.457 Val_Loss: 0.1132  BEST VAL Loss: 0.1132  Val_Acc: 96.895

Epoch 22: Validation loss decreased (0.113173 --> 0.111770).  Saving model ...
	 Train_Loss: 0.1797 Train_Acc: 95.368 Val_Loss: 0.1118  BEST VAL Loss: 0.1118  Val_Acc: 97.075

Epoch 23: Validation loss decreased (0.111770 --> 0.110781).  Saving model ...
	 Train_Loss: 0.1758 Train_Acc: 95.503 Val_Loss: 0.1108  BEST VAL Loss: 0.1108  Val_Acc: 96.805

Epoch 24: Validation loss decreased (0.110781 --> 0.110233).  Saving model ...
	 Train_Loss: 0.1722 Train_Acc: 95.323 Val_Loss: 0.1102  BEST VAL Loss: 0.1102  Val_Acc: 97.165

Epoch 25: Validation loss decreased (0.110233 --> 0.108752).  Saving model ...
	 Train_Loss: 0.1689 Train_Acc: 95.498 Val_Loss: 0.1088  BEST VAL Loss: 0.1088  Val_Acc: 97.075

Epoch 26: Validation loss decreased (0.108752 --> 0.108165).  Saving model ...
	 Train_Loss: 0.1658 Train_Acc: 95.520 Val_Loss: 0.1082  BEST VAL Loss: 0.1082  Val_Acc: 96.985

Epoch 27: Validation loss decreased (0.108165 --> 0.107208).  Saving model ...
	 Train_Loss: 0.1631 Train_Acc: 95.425 Val_Loss: 0.1072  BEST VAL Loss: 0.1072  Val_Acc: 97.255

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.1602 Train_Acc: 95.790 Val_Loss: 0.1074  BEST VAL Loss: 0.1072  Val_Acc: 97.255

Epoch 29: Validation loss decreased (0.107208 --> 0.106616).  Saving model ...
	 Train_Loss: 0.1575 Train_Acc: 95.864 Val_Loss: 0.1066  BEST VAL Loss: 0.1066  Val_Acc: 96.805

Epoch 30: Validation loss decreased (0.106616 --> 0.106277).  Saving model ...
	 Train_Loss: 0.1549 Train_Acc: 95.661 Val_Loss: 0.1063  BEST VAL Loss: 0.1063  Val_Acc: 96.850

Epoch 31: Validation loss decreased (0.106277 --> 0.105775).  Saving model ...
	 Train_Loss: 0.1524 Train_Acc: 95.835 Val_Loss: 0.1058  BEST VAL Loss: 0.1058  Val_Acc: 96.850

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.1501 Train_Acc: 95.672 Val_Loss: 0.1058  BEST VAL Loss: 0.1058  Val_Acc: 96.895

Epoch 33: Validation loss decreased (0.105775 --> 0.105376).  Saving model ...
	 Train_Loss: 0.1479 Train_Acc: 95.954 Val_Loss: 0.1054  BEST VAL Loss: 0.1054  Val_Acc: 97.570

Epoch 34: Validation loss decreased (0.105376 --> 0.104775).  Saving model ...
	 Train_Loss: 0.1462 Train_Acc: 95.278 Val_Loss: 0.1048  BEST VAL Loss: 0.1048  Val_Acc: 97.210

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.1442 Train_Acc: 95.532 Val_Loss: 0.1049  BEST VAL Loss: 0.1048  Val_Acc: 96.580

Epoch 36: Validation loss decreased (0.104775 --> 0.104211).  Saving model ...
	 Train_Loss: 0.1423 Train_Acc: 95.830 Val_Loss: 0.1042  BEST VAL Loss: 0.1042  Val_Acc: 97.570

Epoch 37: Validation loss decreased (0.104211 --> 0.104184).  Saving model ...
	 Train_Loss: 0.1404 Train_Acc: 95.937 Val_Loss: 0.1042  BEST VAL Loss: 0.1042  Val_Acc: 97.210

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.1385 Train_Acc: 96.179 Val_Loss: 0.1042  BEST VAL Loss: 0.1042  Val_Acc: 97.345

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.1369 Train_Acc: 95.616 Val_Loss: 0.1044  BEST VAL Loss: 0.1042  Val_Acc: 96.985

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.1352 Train_Acc: 96.100 Val_Loss: 0.1048  BEST VAL Loss: 0.1042  Val_Acc: 97.165

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.1337 Train_Acc: 95.982 Val_Loss: 0.1046  BEST VAL Loss: 0.1042  Val_Acc: 97.210

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.1323 Train_Acc: 95.847 Val_Loss: 0.1048  BEST VAL Loss: 0.1042  Val_Acc: 97.930

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.1308 Train_Acc: 96.122 Val_Loss: 0.1043  BEST VAL Loss: 0.1042  Val_Acc: 97.885

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.1293 Train_Acc: 96.077 Val_Loss: 0.1045  BEST VAL Loss: 0.1042  Val_Acc: 96.670

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.1279 Train_Acc: 96.612 Val_Loss: 0.1045  BEST VAL Loss: 0.1042  Val_Acc: 96.625

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.1266 Train_Acc: 96.044 Val_Loss: 0.1045  BEST VAL Loss: 0.1042  Val_Acc: 97.435

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.1253 Train_Acc: 95.999 Val_Loss: 0.1049  BEST VAL Loss: 0.1042  Val_Acc: 97.570

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.1243 Train_Acc: 95.734 Val_Loss: 0.1052  BEST VAL Loss: 0.1042  Val_Acc: 97.345

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.1232 Train_Acc: 95.869 Val_Loss: 0.1044  BEST VAL Loss: 0.1042  Val_Acc: 97.885

Epoch 50: Validation loss decreased (0.104184 --> 0.104101).  Saving model ...
	 Train_Loss: 0.1220 Train_Acc: 96.263 Val_Loss: 0.1041  BEST VAL Loss: 0.1041  Val_Acc: 97.390

Epoch 51: Validation loss decreased (0.104101 --> 0.103921).  Saving model ...
	 Train_Loss: 0.1208 Train_Acc: 96.516 Val_Loss: 0.1039  BEST VAL Loss: 0.1039  Val_Acc: 97.885

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.1196 Train_Acc: 96.533 Val_Loss: 0.1041  BEST VAL Loss: 0.1039  Val_Acc: 98.020

Epoch 53: Validation loss decreased (0.103921 --> 0.103868).  Saving model ...
	 Train_Loss: 0.1187 Train_Acc: 96.342 Val_Loss: 0.1039  BEST VAL Loss: 0.1039  Val_Acc: 97.435

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.1177 Train_Acc: 96.713 Val_Loss: 0.1041  BEST VAL Loss: 0.1039  Val_Acc: 97.120

Epoch 55: Validation loss decreased (0.103868 --> 0.103718).  Saving model ...
	 Train_Loss: 0.1166 Train_Acc: 97.051 Val_Loss: 0.1037  BEST VAL Loss: 0.1037  Val_Acc: 97.390

Epoch 56: Validation loss decreased (0.103718 --> 0.103288).  Saving model ...
	 Train_Loss: 0.1155 Train_Acc: 97.220 Val_Loss: 0.1033  BEST VAL Loss: 0.1033  Val_Acc: 97.210

Epoch 57: Validation loss decreased (0.103288 --> 0.102678).  Saving model ...
	 Train_Loss: 0.1145 Train_Acc: 96.989 Val_Loss: 0.1027  BEST VAL Loss: 0.1027  Val_Acc: 97.525

Epoch 58: Validation loss decreased (0.102678 --> 0.102235).  Saving model ...
	 Train_Loss: 0.1135 Train_Acc: 96.984 Val_Loss: 0.1022  BEST VAL Loss: 0.1022  Val_Acc: 97.390

Epoch 59: Validation loss decreased (0.102235 --> 0.101815).  Saving model ...
	 Train_Loss: 0.1125 Train_Acc: 97.012 Val_Loss: 0.1018  BEST VAL Loss: 0.1018  Val_Acc: 97.300

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.1116 Train_Acc: 96.961 Val_Loss: 0.1022  BEST VAL Loss: 0.1018  Val_Acc: 97.210

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.1108 Train_Acc: 96.910 Val_Loss: 0.1019  BEST VAL Loss: 0.1018  Val_Acc: 97.210

Epoch 62: Validation loss decreased (0.101815 --> 0.101553).  Saving model ...
	 Train_Loss: 0.1099 Train_Acc: 97.141 Val_Loss: 0.1016  BEST VAL Loss: 0.1016  Val_Acc: 97.210

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.1092 Train_Acc: 96.848 Val_Loss: 0.1020  BEST VAL Loss: 0.1016  Val_Acc: 97.255

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.1084 Train_Acc: 97.029 Val_Loss: 0.1019  BEST VAL Loss: 0.1016  Val_Acc: 96.895

Epoch 65: Validation loss decreased (0.101553 --> 0.101526).  Saving model ...
	 Train_Loss: 0.1077 Train_Acc: 97.045 Val_Loss: 0.1015  BEST VAL Loss: 0.1015  Val_Acc: 97.210

Epoch 66: Validation loss decreased (0.101526 --> 0.101009).  Saving model ...
	 Train_Loss: 0.1069 Train_Acc: 96.933 Val_Loss: 0.1010  BEST VAL Loss: 0.1010  Val_Acc: 97.210

Epoch 67: Validation loss decreased (0.101009 --> 0.100639).  Saving model ...
	 Train_Loss: 0.1062 Train_Acc: 96.888 Val_Loss: 0.1006  BEST VAL Loss: 0.1006  Val_Acc: 97.525

Epoch 68: Validation loss decreased (0.100639 --> 0.100603).  Saving model ...
	 Train_Loss: 0.1055 Train_Acc: 96.944 Val_Loss: 0.1006  BEST VAL Loss: 0.1006  Val_Acc: 97.255

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.1048 Train_Acc: 97.079 Val_Loss: 0.1007  BEST VAL Loss: 0.1006  Val_Acc: 97.435

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.1040 Train_Acc: 97.507 Val_Loss: 0.1007  BEST VAL Loss: 0.1006  Val_Acc: 97.480

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.1033 Train_Acc: 97.175 Val_Loss: 0.1006  BEST VAL Loss: 0.1006  Val_Acc: 97.300

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.1027 Train_Acc: 97.304 Val_Loss: 0.1007  BEST VAL Loss: 0.1006  Val_Acc: 97.705

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.1020 Train_Acc: 97.282 Val_Loss: 0.1006  BEST VAL Loss: 0.1006  Val_Acc: 97.480

Epoch 74: Validation loss decreased (0.100603 --> 0.100376).  Saving model ...
	 Train_Loss: 0.1014 Train_Acc: 97.394 Val_Loss: 0.1004  BEST VAL Loss: 0.1004  Val_Acc: 97.480

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.1007 Train_Acc: 97.372 Val_Loss: 0.1004  BEST VAL Loss: 0.1004  Val_Acc: 97.435

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.1001 Train_Acc: 97.304 Val_Loss: 0.1005  BEST VAL Loss: 0.1004  Val_Acc: 97.390

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.0995 Train_Acc: 97.428 Val_Loss: 0.1009  BEST VAL Loss: 0.1004  Val_Acc: 96.985

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.0989 Train_Acc: 97.293 Val_Loss: 0.1011  BEST VAL Loss: 0.1004  Val_Acc: 97.255

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.0983 Train_Acc: 97.490 Val_Loss: 0.1010  BEST VAL Loss: 0.1004  Val_Acc: 97.435

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.0978 Train_Acc: 97.141 Val_Loss: 0.1007  BEST VAL Loss: 0.1004  Val_Acc: 97.075

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.0972 Train_Acc: 97.473 Val_Loss: 0.1004  BEST VAL Loss: 0.1004  Val_Acc: 97.525

Epoch 82: Validation loss decreased (0.100376 --> 0.100190).  Saving model ...
	 Train_Loss: 0.0966 Train_Acc: 97.445 Val_Loss: 0.1002  BEST VAL Loss: 0.1002  Val_Acc: 97.390

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.0961 Train_Acc: 97.507 Val_Loss: 0.1008  BEST VAL Loss: 0.1002  Val_Acc: 97.570

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.0957 Train_Acc: 97.254 Val_Loss: 0.1006  BEST VAL Loss: 0.1002  Val_Acc: 97.480

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.0952 Train_Acc: 97.377 Val_Loss: 0.1006  BEST VAL Loss: 0.1002  Val_Acc: 97.525

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.0946 Train_Acc: 97.541 Val_Loss: 0.1009  BEST VAL Loss: 0.1002  Val_Acc: 97.570

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.0941 Train_Acc: 97.501 Val_Loss: 0.1011  BEST VAL Loss: 0.1002  Val_Acc: 97.615

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.0936 Train_Acc: 97.591 Val_Loss: 0.1010  BEST VAL Loss: 0.1002  Val_Acc: 97.300

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.0931 Train_Acc: 97.400 Val_Loss: 0.1009  BEST VAL Loss: 0.1002  Val_Acc: 97.390

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.0926 Train_Acc: 97.445 Val_Loss: 0.1008  BEST VAL Loss: 0.1002  Val_Acc: 97.885

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.0921 Train_Acc: 97.631 Val_Loss: 0.1007  BEST VAL Loss: 0.1002  Val_Acc: 97.570

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.0916 Train_Acc: 97.552 Val_Loss: 0.1008  BEST VAL Loss: 0.1002  Val_Acc: 97.570

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.0912 Train_Acc: 97.411 Val_Loss: 0.1005  BEST VAL Loss: 0.1002  Val_Acc: 97.570

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.0907 Train_Acc: 97.541 Val_Loss: 0.1005  BEST VAL Loss: 0.1002  Val_Acc: 97.795

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.0903 Train_Acc: 97.496 Val_Loss: 0.1006  BEST VAL Loss: 0.1002  Val_Acc: 97.705

Epoch 96: Validation loss did not decrease
	 Train_Loss: 0.0899 Train_Acc: 97.597 Val_Loss: 0.1006  BEST VAL Loss: 0.1002  Val_Acc: 97.390

Epoch 97: Validation loss did not decrease
	 Train_Loss: 0.0894 Train_Acc: 97.597 Val_Loss: 0.1006  BEST VAL Loss: 0.1002  Val_Acc: 97.705

Epoch 98: Validation loss did not decrease
Early stopped at epoch : 98
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.55      0.55      9832
           1       0.45      0.45      0.45      7937

    accuracy                           0.51     17769
   macro avg       0.50      0.50      0.50     17769
weighted avg       0.51      0.51      0.51     17769

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.54      0.54      1229
           1       0.44      0.45      0.44       993

    accuracy                           0.50      2222
   macro avg       0.49      0.49      0.49      2222
weighted avg       0.50      0.50      0.50      2222

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.56      0.55      0.55      1229
           1       0.46      0.47      0.46       993

    accuracy                           0.51      2222
   macro avg       0.51      0.51      0.51      2222
weighted avg       0.51      0.51      0.51      2222

              precision    recall  f1-score   support

           0       0.56      0.55      0.55      1229
           1       0.46      0.47      0.46       993

    accuracy                           0.51      2222
   macro avg       0.51      0.51      0.51      2222
weighted avg       0.51      0.51      0.51      2222

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.54      0.53      4168
           1       0.47      0.47      0.47      3729

    accuracy                           0.50      7897
   macro avg       0.50      0.50      0.50      7897
weighted avg       0.50      0.50      0.50      7897

              precision    recall  f1-score   support

           0       0.53      0.54      0.53      4168
           1       0.47      0.47      0.47      3729

    accuracy                           0.50      7897
   macro avg       0.50      0.50      0.50      7897
weighted avg       0.50      0.50      0.50      7897

completed
