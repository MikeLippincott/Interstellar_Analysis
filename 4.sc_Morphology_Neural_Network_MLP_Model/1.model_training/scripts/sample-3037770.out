[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '2827db45'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '484073c6'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '38d34637'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'fc20aab5'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_0.010_DMSO_0.025 treatment_name: DMSO_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_0.010_DMSO_0.025
TREATMENT_NAME: DMSO_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'DMSO_0.100_DMSO_0.025']
The dimensions of the data are: (358210, 1270)
Number of total missing values across all columns: 716420
Data Subset Is Off
Wells held out for testing: ['B09' 'J06']
Wells to use for training, validation, and testing ['B02' 'B03' 'B06' 'C06' 'B07' 'C07' 'B08' 'I06' 'I07' 'J07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.389044).  Saving model ...
	 Train_Loss: 0.4882 Train_Acc: 75.007 Val_Loss: 0.3890  BEST VAL Loss: 0.3890  Val_Acc: 81.980

Epoch 1: Validation loss decreased (0.389044 --> 0.376951).  Saving model ...
	 Train_Loss: 0.4484 Train_Acc: 80.638 Val_Loss: 0.3770  BEST VAL Loss: 0.3770  Val_Acc: 83.494

Epoch 2: Validation loss decreased (0.376951 --> 0.366171).  Saving model ...
	 Train_Loss: 0.4284 Train_Acc: 81.878 Val_Loss: 0.3662  BEST VAL Loss: 0.3662  Val_Acc: 84.888

Epoch 3: Validation loss decreased (0.366171 --> 0.358780).  Saving model ...
	 Train_Loss: 0.4147 Train_Acc: 82.901 Val_Loss: 0.3588  BEST VAL Loss: 0.3588  Val_Acc: 85.296

Epoch 4: Validation loss decreased (0.358780 --> 0.354375).  Saving model ...
	 Train_Loss: 0.4049 Train_Acc: 83.280 Val_Loss: 0.3544  BEST VAL Loss: 0.3544  Val_Acc: 85.228

Epoch 5: Validation loss decreased (0.354375 --> 0.348925).  Saving model ...
	 Train_Loss: 0.3972 Train_Acc: 83.636 Val_Loss: 0.3489  BEST VAL Loss: 0.3489  Val_Acc: 85.932

Epoch 6: Validation loss decreased (0.348925 --> 0.345152).  Saving model ...
	 Train_Loss: 0.3914 Train_Acc: 83.881 Val_Loss: 0.3452  BEST VAL Loss: 0.3452  Val_Acc: 85.898

Epoch 7: Validation loss decreased (0.345152 --> 0.341923).  Saving model ...
	 Train_Loss: 0.3867 Train_Acc: 84.045 Val_Loss: 0.3419  BEST VAL Loss: 0.3419  Val_Acc: 86.078

Epoch 8: Validation loss decreased (0.341923 --> 0.338902).  Saving model ...
	 Train_Loss: 0.3824 Train_Acc: 84.237 Val_Loss: 0.3389  BEST VAL Loss: 0.3389  Val_Acc: 86.381

Epoch 9: Validation loss decreased (0.338902 --> 0.337196).  Saving model ...
	 Train_Loss: 0.3791 Train_Acc: 84.250 Val_Loss: 0.3372  BEST VAL Loss: 0.3372  Val_Acc: 86.041

Epoch 10: Validation loss decreased (0.337196 --> 0.335373).  Saving model ...
	 Train_Loss: 0.3760 Train_Acc: 84.430 Val_Loss: 0.3354  BEST VAL Loss: 0.3354  Val_Acc: 86.371

Epoch 11: Validation loss decreased (0.335373 --> 0.333683).  Saving model ...
	 Train_Loss: 0.3731 Train_Acc: 84.652 Val_Loss: 0.3337  BEST VAL Loss: 0.3337  Val_Acc: 86.337

Epoch 12: Validation loss decreased (0.333683 --> 0.332079).  Saving model ...
	 Train_Loss: 0.3708 Train_Acc: 84.608 Val_Loss: 0.3321  BEST VAL Loss: 0.3321  Val_Acc: 86.490

Epoch 13: Validation loss decreased (0.332079 --> 0.330414).  Saving model ...
	 Train_Loss: 0.3686 Train_Acc: 84.768 Val_Loss: 0.3304  BEST VAL Loss: 0.3304  Val_Acc: 87.095

Epoch 14: Validation loss decreased (0.330414 --> 0.328544).  Saving model ...
	 Train_Loss: 0.3666 Train_Acc: 84.773 Val_Loss: 0.3285  BEST VAL Loss: 0.3285  Val_Acc: 86.918

Epoch 15: Validation loss decreased (0.328544 --> 0.326934).  Saving model ...
	 Train_Loss: 0.3647 Train_Acc: 84.950 Val_Loss: 0.3269  BEST VAL Loss: 0.3269  Val_Acc: 86.802

Epoch 16: Validation loss decreased (0.326934 --> 0.326081).  Saving model ...
	 Train_Loss: 0.3630 Train_Acc: 84.944 Val_Loss: 0.3261  BEST VAL Loss: 0.3261  Val_Acc: 86.836

Epoch 17: Validation loss decreased (0.326081 --> 0.325219).  Saving model ...
	 Train_Loss: 0.3615 Train_Acc: 84.932 Val_Loss: 0.3252  BEST VAL Loss: 0.3252  Val_Acc: 86.802

Epoch 18: Validation loss decreased (0.325219 --> 0.324203).  Saving model ...
	 Train_Loss: 0.3601 Train_Acc: 85.072 Val_Loss: 0.3242  BEST VAL Loss: 0.3242  Val_Acc: 87.170

Epoch 19: Validation loss decreased (0.324203 --> 0.323212).  Saving model ...
	 Train_Loss: 0.3587 Train_Acc: 85.178 Val_Loss: 0.3232  BEST VAL Loss: 0.3232  Val_Acc: 86.823

Epoch 20: Validation loss decreased (0.323212 --> 0.322341).  Saving model ...
	 Train_Loss: 0.3573 Train_Acc: 85.237 Val_Loss: 0.3223  BEST VAL Loss: 0.3223  Val_Acc: 87.092

Epoch 21: Validation loss decreased (0.322341 --> 0.321611).  Saving model ...
	 Train_Loss: 0.3561 Train_Acc: 85.161 Val_Loss: 0.3216  BEST VAL Loss: 0.3216  Val_Acc: 86.636

Epoch 22: Validation loss decreased (0.321611 --> 0.320467).  Saving model ...
	 Train_Loss: 0.3550 Train_Acc: 85.262 Val_Loss: 0.3205  BEST VAL Loss: 0.3205  Val_Acc: 87.353

Epoch 23: Validation loss decreased (0.320467 --> 0.319459).  Saving model ...
	 Train_Loss: 0.3539 Train_Acc: 85.265 Val_Loss: 0.3195  BEST VAL Loss: 0.3195  Val_Acc: 87.289

Epoch 24: Validation loss decreased (0.319459 --> 0.318489).  Saving model ...
	 Train_Loss: 0.3529 Train_Acc: 85.391 Val_Loss: 0.3185  BEST VAL Loss: 0.3185  Val_Acc: 87.394

Epoch 25: Validation loss decreased (0.318489 --> 0.317809).  Saving model ...
	 Train_Loss: 0.3519 Train_Acc: 85.407 Val_Loss: 0.3178  BEST VAL Loss: 0.3178  Val_Acc: 87.034

Epoch 26: Validation loss decreased (0.317809 --> 0.316894).  Saving model ...
	 Train_Loss: 0.3510 Train_Acc: 85.418 Val_Loss: 0.3169  BEST VAL Loss: 0.3169  Val_Acc: 87.330

Epoch 27: Validation loss decreased (0.316894 --> 0.316157).  Saving model ...
	 Train_Loss: 0.3501 Train_Acc: 85.447 Val_Loss: 0.3162  BEST VAL Loss: 0.3162  Val_Acc: 87.340

Epoch 28: Validation loss decreased (0.316157 --> 0.315355).  Saving model ...
	 Train_Loss: 0.3493 Train_Acc: 85.464 Val_Loss: 0.3154  BEST VAL Loss: 0.3154  Val_Acc: 87.540

Epoch 29: Validation loss decreased (0.315355 --> 0.314595).  Saving model ...
	 Train_Loss: 0.3485 Train_Acc: 85.546 Val_Loss: 0.3146  BEST VAL Loss: 0.3146  Val_Acc: 87.629

Epoch 30: Validation loss decreased (0.314595 --> 0.314055).  Saving model ...
	 Train_Loss: 0.3477 Train_Acc: 85.554 Val_Loss: 0.3141  BEST VAL Loss: 0.3141  Val_Acc: 87.187

Epoch 31: Validation loss decreased (0.314055 --> 0.313347).  Saving model ...
	 Train_Loss: 0.3470 Train_Acc: 85.604 Val_Loss: 0.3133  BEST VAL Loss: 0.3133  Val_Acc: 87.571

Epoch 32: Validation loss decreased (0.313347 --> 0.312844).  Saving model ...
	 Train_Loss: 0.3462 Train_Acc: 85.705 Val_Loss: 0.3128  BEST VAL Loss: 0.3128  Val_Acc: 87.268

Epoch 33: Validation loss decreased (0.312844 --> 0.312614).  Saving model ...
	 Train_Loss: 0.3455 Train_Acc: 85.810 Val_Loss: 0.3126  BEST VAL Loss: 0.3126  Val_Acc: 87.194

Epoch 34: Validation loss decreased (0.312614 --> 0.312096).  Saving model ...
	 Train_Loss: 0.3448 Train_Acc: 85.670 Val_Loss: 0.3121  BEST VAL Loss: 0.3121  Val_Acc: 87.585

Epoch 35: Validation loss decreased (0.312096 --> 0.311832).  Saving model ...
	 Train_Loss: 0.3441 Train_Acc: 85.770 Val_Loss: 0.3118  BEST VAL Loss: 0.3118  Val_Acc: 86.734

Epoch 36: Validation loss decreased (0.311832 --> 0.311219).  Saving model ...
	 Train_Loss: 0.3435 Train_Acc: 85.683 Val_Loss: 0.3112  BEST VAL Loss: 0.3112  Val_Acc: 87.666

Epoch 37: Validation loss decreased (0.311219 --> 0.310808).  Saving model ...
	 Train_Loss: 0.3429 Train_Acc: 85.733 Val_Loss: 0.3108  BEST VAL Loss: 0.3108  Val_Acc: 87.707

Epoch 38: Validation loss decreased (0.310808 --> 0.310326).  Saving model ...
	 Train_Loss: 0.3423 Train_Acc: 85.768 Val_Loss: 0.3103  BEST VAL Loss: 0.3103  Val_Acc: 87.690

Epoch 39: Validation loss decreased (0.310326 --> 0.309998).  Saving model ...
	 Train_Loss: 0.3417 Train_Acc: 85.884 Val_Loss: 0.3100  BEST VAL Loss: 0.3100  Val_Acc: 87.724

Epoch 40: Validation loss decreased (0.309998 --> 0.309429).  Saving model ...
	 Train_Loss: 0.3412 Train_Acc: 85.785 Val_Loss: 0.3094  BEST VAL Loss: 0.3094  Val_Acc: 87.853

Epoch 41: Validation loss decreased (0.309429 --> 0.308953).  Saving model ...
	 Train_Loss: 0.3406 Train_Acc: 85.840 Val_Loss: 0.3090  BEST VAL Loss: 0.3090  Val_Acc: 87.676

Epoch 42: Validation loss decreased (0.308953 --> 0.308598).  Saving model ...
	 Train_Loss: 0.3401 Train_Acc: 85.872 Val_Loss: 0.3086  BEST VAL Loss: 0.3086  Val_Acc: 87.656

Epoch 43: Validation loss decreased (0.308598 --> 0.308386).  Saving model ...
	 Train_Loss: 0.3396 Train_Acc: 85.823 Val_Loss: 0.3084  BEST VAL Loss: 0.3084  Val_Acc: 87.714

Epoch 44: Validation loss decreased (0.308386 --> 0.307925).  Saving model ...
	 Train_Loss: 0.3391 Train_Acc: 85.959 Val_Loss: 0.3079  BEST VAL Loss: 0.3079  Val_Acc: 87.826

Epoch 45: Validation loss decreased (0.307925 --> 0.307577).  Saving model ...
	 Train_Loss: 0.3386 Train_Acc: 85.965 Val_Loss: 0.3076  BEST VAL Loss: 0.3076  Val_Acc: 87.850

Epoch 46: Validation loss decreased (0.307577 --> 0.307262).  Saving model ...
	 Train_Loss: 0.3381 Train_Acc: 86.036 Val_Loss: 0.3073  BEST VAL Loss: 0.3073  Val_Acc: 87.670

Epoch 47: Validation loss decreased (0.307262 --> 0.306865).  Saving model ...
	 Train_Loss: 0.3377 Train_Acc: 85.961 Val_Loss: 0.3069  BEST VAL Loss: 0.3069  Val_Acc: 87.840

Epoch 48: Validation loss decreased (0.306865 --> 0.306455).  Saving model ...
	 Train_Loss: 0.3372 Train_Acc: 86.007 Val_Loss: 0.3065  BEST VAL Loss: 0.3065  Val_Acc: 87.979

Epoch 49: Validation loss decreased (0.306455 --> 0.306245).  Saving model ...
	 Train_Loss: 0.3368 Train_Acc: 86.050 Val_Loss: 0.3062  BEST VAL Loss: 0.3062  Val_Acc: 87.466

Epoch 50: Validation loss decreased (0.306245 --> 0.305972).  Saving model ...
	 Train_Loss: 0.3364 Train_Acc: 85.935 Val_Loss: 0.3060  BEST VAL Loss: 0.3060  Val_Acc: 87.717

Epoch 51: Validation loss decreased (0.305972 --> 0.305661).  Saving model ...
	 Train_Loss: 0.3360 Train_Acc: 86.125 Val_Loss: 0.3057  BEST VAL Loss: 0.3057  Val_Acc: 87.659

Epoch 52: Validation loss decreased (0.305661 --> 0.305291).  Saving model ...
	 Train_Loss: 0.3356 Train_Acc: 86.075 Val_Loss: 0.3053  BEST VAL Loss: 0.3053  Val_Acc: 88.054

Epoch 53: Validation loss decreased (0.305291 --> 0.304997).  Saving model ...
	 Train_Loss: 0.3352 Train_Acc: 86.090 Val_Loss: 0.3050  BEST VAL Loss: 0.3050  Val_Acc: 87.710

Epoch 54: Validation loss decreased (0.304997 --> 0.304835).  Saving model ...
	 Train_Loss: 0.3348 Train_Acc: 86.162 Val_Loss: 0.3048  BEST VAL Loss: 0.3048  Val_Acc: 87.979

Epoch 55: Validation loss decreased (0.304835 --> 0.304481).  Saving model ...
	 Train_Loss: 0.3344 Train_Acc: 86.257 Val_Loss: 0.3045  BEST VAL Loss: 0.3045  Val_Acc: 87.812

Epoch 56: Validation loss decreased (0.304481 --> 0.304309).  Saving model ...
	 Train_Loss: 0.3340 Train_Acc: 86.237 Val_Loss: 0.3043  BEST VAL Loss: 0.3043  Val_Acc: 87.700

Epoch 57: Validation loss decreased (0.304309 --> 0.304105).  Saving model ...
	 Train_Loss: 0.3336 Train_Acc: 86.210 Val_Loss: 0.3041  BEST VAL Loss: 0.3041  Val_Acc: 87.846

Epoch 58: Validation loss decreased (0.304105 --> 0.303803).  Saving model ...
	 Train_Loss: 0.3332 Train_Acc: 86.278 Val_Loss: 0.3038  BEST VAL Loss: 0.3038  Val_Acc: 87.931

Epoch 59: Validation loss decreased (0.303803 --> 0.303630).  Saving model ...
	 Train_Loss: 0.3329 Train_Acc: 86.263 Val_Loss: 0.3036  BEST VAL Loss: 0.3036  Val_Acc: 87.931

Epoch 60: Validation loss decreased (0.303630 --> 0.303333).  Saving model ...
	 Train_Loss: 0.3325 Train_Acc: 86.188 Val_Loss: 0.3033  BEST VAL Loss: 0.3033  Val_Acc: 87.755

Epoch 61: Validation loss decreased (0.303333 --> 0.303100).  Saving model ...
	 Train_Loss: 0.3322 Train_Acc: 86.276 Val_Loss: 0.3031  BEST VAL Loss: 0.3031  Val_Acc: 87.795

Epoch 62: Validation loss decreased (0.303100 --> 0.302762).  Saving model ...
	 Train_Loss: 0.3319 Train_Acc: 86.216 Val_Loss: 0.3028  BEST VAL Loss: 0.3028  Val_Acc: 87.993

Epoch 63: Validation loss decreased (0.302762 --> 0.302505).  Saving model ...
	 Train_Loss: 0.3316 Train_Acc: 86.277 Val_Loss: 0.3025  BEST VAL Loss: 0.3025  Val_Acc: 88.033

Epoch 64: Validation loss decreased (0.302505 --> 0.302325).  Saving model ...
	 Train_Loss: 0.3312 Train_Acc: 86.286 Val_Loss: 0.3023  BEST VAL Loss: 0.3023  Val_Acc: 87.860

Epoch 65: Validation loss decreased (0.302325 --> 0.302081).  Saving model ...
	 Train_Loss: 0.3309 Train_Acc: 86.306 Val_Loss: 0.3021  BEST VAL Loss: 0.3021  Val_Acc: 88.040

Epoch 66: Validation loss decreased (0.302081 --> 0.301859).  Saving model ...
	 Train_Loss: 0.3306 Train_Acc: 86.354 Val_Loss: 0.3019  BEST VAL Loss: 0.3019  Val_Acc: 87.857

Epoch 67: Validation loss decreased (0.301859 --> 0.301682).  Saving model ...
	 Train_Loss: 0.3303 Train_Acc: 86.257 Val_Loss: 0.3017  BEST VAL Loss: 0.3017  Val_Acc: 87.476

Epoch 68: Validation loss decreased (0.301682 --> 0.301548).  Saving model ...
	 Train_Loss: 0.3300 Train_Acc: 86.406 Val_Loss: 0.3015  BEST VAL Loss: 0.3015  Val_Acc: 87.445

Epoch 69: Validation loss decreased (0.301548 --> 0.301468).  Saving model ...
	 Train_Loss: 0.3297 Train_Acc: 86.278 Val_Loss: 0.3015  BEST VAL Loss: 0.3015  Val_Acc: 88.088

Epoch 70: Validation loss decreased (0.301468 --> 0.301254).  Saving model ...
	 Train_Loss: 0.3295 Train_Acc: 86.321 Val_Loss: 0.3013  BEST VAL Loss: 0.3013  Val_Acc: 87.738

Epoch 71: Validation loss decreased (0.301254 --> 0.301179).  Saving model ...
	 Train_Loss: 0.3292 Train_Acc: 86.368 Val_Loss: 0.3012  BEST VAL Loss: 0.3012  Val_Acc: 87.731

Epoch 72: Validation loss decreased (0.301179 --> 0.300891).  Saving model ...
	 Train_Loss: 0.3289 Train_Acc: 86.355 Val_Loss: 0.3009  BEST VAL Loss: 0.3009  Val_Acc: 88.105

Epoch 73: Validation loss decreased (0.300891 --> 0.300585).  Saving model ...
	 Train_Loss: 0.3286 Train_Acc: 86.417 Val_Loss: 0.3006  BEST VAL Loss: 0.3006  Val_Acc: 88.220

Epoch 74: Validation loss decreased (0.300585 --> 0.300385).  Saving model ...
	 Train_Loss: 0.3284 Train_Acc: 86.364 Val_Loss: 0.3004  BEST VAL Loss: 0.3004  Val_Acc: 87.812

Epoch 75: Validation loss decreased (0.300385 --> 0.300230).  Saving model ...
	 Train_Loss: 0.3281 Train_Acc: 86.363 Val_Loss: 0.3002  BEST VAL Loss: 0.3002  Val_Acc: 87.785

Epoch 76: Validation loss decreased (0.300230 --> 0.300022).  Saving model ...
	 Train_Loss: 0.3278 Train_Acc: 86.486 Val_Loss: 0.3000  BEST VAL Loss: 0.3000  Val_Acc: 88.163

Epoch 77: Validation loss decreased (0.300022 --> 0.299915).  Saving model ...
	 Train_Loss: 0.3276 Train_Acc: 86.416 Val_Loss: 0.2999  BEST VAL Loss: 0.2999  Val_Acc: 87.561

Epoch 78: Validation loss decreased (0.299915 --> 0.299676).  Saving model ...
	 Train_Loss: 0.3273 Train_Acc: 86.587 Val_Loss: 0.2997  BEST VAL Loss: 0.2997  Val_Acc: 88.346

Epoch 79: Validation loss decreased (0.299676 --> 0.299496).  Saving model ...
	 Train_Loss: 0.3270 Train_Acc: 86.387 Val_Loss: 0.2995  BEST VAL Loss: 0.2995  Val_Acc: 88.193

Epoch 80: Validation loss decreased (0.299496 --> 0.299340).  Saving model ...
	 Train_Loss: 0.3268 Train_Acc: 86.433 Val_Loss: 0.2993  BEST VAL Loss: 0.2993  Val_Acc: 87.860

Epoch 81: Validation loss decreased (0.299340 --> 0.299149).  Saving model ...
	 Train_Loss: 0.3265 Train_Acc: 86.561 Val_Loss: 0.2991  BEST VAL Loss: 0.2991  Val_Acc: 88.285

Epoch 82: Validation loss decreased (0.299149 --> 0.298941).  Saving model ...
	 Train_Loss: 0.3263 Train_Acc: 86.460 Val_Loss: 0.2989  BEST VAL Loss: 0.2989  Val_Acc: 88.146

Epoch 83: Validation loss decreased (0.298941 --> 0.298767).  Saving model ...
	 Train_Loss: 0.3261 Train_Acc: 86.555 Val_Loss: 0.2988  BEST VAL Loss: 0.2988  Val_Acc: 88.040

Epoch 84: Validation loss decreased (0.298767 --> 0.298596).  Saving model ...
	 Train_Loss: 0.3259 Train_Acc: 86.408 Val_Loss: 0.2986  BEST VAL Loss: 0.2986  Val_Acc: 87.863

Epoch 85: Validation loss decreased (0.298596 --> 0.298365).  Saving model ...
	 Train_Loss: 0.3256 Train_Acc: 86.585 Val_Loss: 0.2984  BEST VAL Loss: 0.2984  Val_Acc: 88.159

Epoch 86: Validation loss decreased (0.298365 --> 0.298153).  Saving model ...
	 Train_Loss: 0.3254 Train_Acc: 86.387 Val_Loss: 0.2982  BEST VAL Loss: 0.2982  Val_Acc: 88.142

Epoch 87: Validation loss decreased (0.298153 --> 0.297999).  Saving model ...
	 Train_Loss: 0.3252 Train_Acc: 86.532 Val_Loss: 0.2980  BEST VAL Loss: 0.2980  Val_Acc: 88.125

Epoch 88: Validation loss decreased (0.297999 --> 0.297873).  Saving model ...
	 Train_Loss: 0.3250 Train_Acc: 86.493 Val_Loss: 0.2979  BEST VAL Loss: 0.2979  Val_Acc: 87.812

Epoch 89: Validation loss decreased (0.297873 --> 0.297816).  Saving model ...
	 Train_Loss: 0.3248 Train_Acc: 86.595 Val_Loss: 0.2978  BEST VAL Loss: 0.2978  Val_Acc: 87.850

Epoch 90: Validation loss decreased (0.297816 --> 0.297602).  Saving model ...
	 Train_Loss: 0.3246 Train_Acc: 86.614 Val_Loss: 0.2976  BEST VAL Loss: 0.2976  Val_Acc: 88.200

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.3243 Train_Acc: 86.552 Val_Loss: 0.2976  BEST VAL Loss: 0.2976  Val_Acc: 87.897

Epoch 92: Validation loss decreased (0.297602 --> 0.297467).  Saving model ...
	 Train_Loss: 0.3241 Train_Acc: 86.457 Val_Loss: 0.2975  BEST VAL Loss: 0.2975  Val_Acc: 88.268

Epoch 93: Validation loss decreased (0.297467 --> 0.297359).  Saving model ...
	 Train_Loss: 0.3239 Train_Acc: 86.633 Val_Loss: 0.2974  BEST VAL Loss: 0.2974  Val_Acc: 87.704

Epoch 94: Validation loss decreased (0.297359 --> 0.297210).  Saving model ...
	 Train_Loss: 0.3237 Train_Acc: 86.444 Val_Loss: 0.2972  BEST VAL Loss: 0.2972  Val_Acc: 88.112

Epoch 95: Validation loss decreased (0.297210 --> 0.297032).  Saving model ...
	 Train_Loss: 0.3235 Train_Acc: 86.638 Val_Loss: 0.2970  BEST VAL Loss: 0.2970  Val_Acc: 88.200

Epoch 96: Validation loss decreased (0.297032 --> 0.296925).  Saving model ...
	 Train_Loss: 0.3233 Train_Acc: 86.719 Val_Loss: 0.2969  BEST VAL Loss: 0.2969  Val_Acc: 87.826

Epoch 97: Validation loss decreased (0.296925 --> 0.296866).  Saving model ...
	 Train_Loss: 0.3231 Train_Acc: 86.675 Val_Loss: 0.2969  BEST VAL Loss: 0.2969  Val_Acc: 87.374

Epoch 98: Validation loss decreased (0.296866 --> 0.296811).  Saving model ...
	 Train_Loss: 0.3229 Train_Acc: 86.581 Val_Loss: 0.2968  BEST VAL Loss: 0.2968  Val_Acc: 87.615

Epoch 99: Validation loss decreased (0.296811 --> 0.296777).  Saving model ...
	 Train_Loss: 0.3228 Train_Acc: 86.696 Val_Loss: 0.2968  BEST VAL Loss: 0.2968  Val_Acc: 88.115

LPS_0.010_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.64      0.65      0.64    149884
           1       0.36      0.35      0.36     85371

    accuracy                           0.54    235255
   macro avg       0.50      0.50      0.50    235255
weighted avg       0.54      0.54      0.54    235255

LPS_0.010_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.64      0.65      0.65     18736
           1       0.37      0.36      0.36     10671

    accuracy                           0.55     29407
   macro avg       0.50      0.50      0.50     29407
weighted avg       0.54      0.55      0.54     29407

LPS_0.010_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.64      0.65      0.64     18736
           1       0.36      0.35      0.36     10672

    accuracy                           0.54     29408
   macro avg       0.50      0.50      0.50     29408
weighted avg       0.54      0.54      0.54     29408

              precision    recall  f1-score   support

           0       0.64      0.65      0.64     18736
           1       0.36      0.35      0.36     10672

    accuracy                           0.54     29408
   macro avg       0.50      0.50      0.50     29408
weighted avg       0.54      0.54      0.54     29408

LPS_0.010_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.43      0.71      0.54     27774
           1       0.57      0.29      0.38     36366

    accuracy                           0.47     64140
   macro avg       0.50      0.50      0.46     64140
weighted avg       0.51      0.47      0.45     64140

              precision    recall  f1-score   support

           0       0.43      0.71      0.54     27774
           1       0.57      0.29      0.38     36366

    accuracy                           0.47     64140
   macro avg       0.50      0.50      0.46     64140
weighted avg       0.51      0.47      0.45     64140

completed
