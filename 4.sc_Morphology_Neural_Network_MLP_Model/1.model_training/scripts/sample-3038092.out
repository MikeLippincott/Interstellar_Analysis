[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'e31df03d'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '1599caff'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'a31a553f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '0caec3e3'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: DMSO_0.100_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: DMSO_0.100_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (396296, 1270)
Number of total missing values across all columns: 430260
Data Subset Is Off
Wells held out for testing: ['J06' 'M08']
Wells to use for training, validation, and testing ['B06' 'C06' 'B07' 'C07' 'I06' 'I07' 'J07' 'M02' 'M03' 'M09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.242199).  Saving model ...
	 Train_Loss: 0.3578 Train_Acc: 86.306 Val_Loss: 0.2422  BEST VAL Loss: 0.2422  Val_Acc: 91.102

Epoch 1: Validation loss decreased (0.242199 --> 0.217037).  Saving model ...
	 Train_Loss: 0.2953 Train_Acc: 91.239 Val_Loss: 0.2170  BEST VAL Loss: 0.2170  Val_Acc: 92.860

Epoch 2: Validation loss decreased (0.217037 --> 0.200233).  Saving model ...
	 Train_Loss: 0.2631 Train_Acc: 92.515 Val_Loss: 0.2002  BEST VAL Loss: 0.2002  Val_Acc: 93.871

Epoch 3: Validation loss decreased (0.200233 --> 0.188193).  Saving model ...
	 Train_Loss: 0.2422 Train_Acc: 93.179 Val_Loss: 0.1882  BEST VAL Loss: 0.1882  Val_Acc: 94.454

Epoch 4: Validation loss decreased (0.188193 --> 0.178963).  Saving model ...
	 Train_Loss: 0.2270 Train_Acc: 93.751 Val_Loss: 0.1790  BEST VAL Loss: 0.1790  Val_Acc: 94.827

Epoch 5: Validation loss decreased (0.178963 --> 0.171504).  Saving model ...
	 Train_Loss: 0.2154 Train_Acc: 94.134 Val_Loss: 0.1715  BEST VAL Loss: 0.1715  Val_Acc: 95.095

Epoch 6: Validation loss decreased (0.171504 --> 0.165421).  Saving model ...
	 Train_Loss: 0.2061 Train_Acc: 94.332 Val_Loss: 0.1654  BEST VAL Loss: 0.1654  Val_Acc: 95.335

Epoch 7: Validation loss decreased (0.165421 --> 0.160239).  Saving model ...
	 Train_Loss: 0.1985 Train_Acc: 94.568 Val_Loss: 0.1602  BEST VAL Loss: 0.1602  Val_Acc: 95.480

Epoch 8: Validation loss decreased (0.160239 --> 0.155771).  Saving model ...
	 Train_Loss: 0.1921 Train_Acc: 94.743 Val_Loss: 0.1558  BEST VAL Loss: 0.1558  Val_Acc: 95.705

Epoch 9: Validation loss decreased (0.155771 --> 0.151930).  Saving model ...
	 Train_Loss: 0.1865 Train_Acc: 94.906 Val_Loss: 0.1519  BEST VAL Loss: 0.1519  Val_Acc: 95.804

Epoch 10: Validation loss decreased (0.151930 --> 0.148431).  Saving model ...
	 Train_Loss: 0.1817 Train_Acc: 95.074 Val_Loss: 0.1484  BEST VAL Loss: 0.1484  Val_Acc: 95.890

Epoch 11: Validation loss decreased (0.148431 --> 0.145412).  Saving model ...
	 Train_Loss: 0.1773 Train_Acc: 95.212 Val_Loss: 0.1454  BEST VAL Loss: 0.1454  Val_Acc: 95.946

Epoch 12: Validation loss decreased (0.145412 --> 0.142616).  Saving model ...
	 Train_Loss: 0.1735 Train_Acc: 95.251 Val_Loss: 0.1426  BEST VAL Loss: 0.1426  Val_Acc: 96.112

Epoch 13: Validation loss decreased (0.142616 --> 0.140085).  Saving model ...
	 Train_Loss: 0.1700 Train_Acc: 95.370 Val_Loss: 0.1401  BEST VAL Loss: 0.1401  Val_Acc: 96.137

Epoch 14: Validation loss decreased (0.140085 --> 0.137846).  Saving model ...
	 Train_Loss: 0.1669 Train_Acc: 95.436 Val_Loss: 0.1378  BEST VAL Loss: 0.1378  Val_Acc: 96.199

Epoch 15: Validation loss decreased (0.137846 --> 0.135718).  Saving model ...
	 Train_Loss: 0.1640 Train_Acc: 95.538 Val_Loss: 0.1357  BEST VAL Loss: 0.1357  Val_Acc: 96.205

Epoch 16: Validation loss decreased (0.135718 --> 0.133813).  Saving model ...
	 Train_Loss: 0.1613 Train_Acc: 95.575 Val_Loss: 0.1338  BEST VAL Loss: 0.1338  Val_Acc: 96.223

Epoch 17: Validation loss decreased (0.133813 --> 0.132058).  Saving model ...
	 Train_Loss: 0.1589 Train_Acc: 95.647 Val_Loss: 0.1321  BEST VAL Loss: 0.1321  Val_Acc: 96.362

Epoch 18: Validation loss decreased (0.132058 --> 0.130357).  Saving model ...
	 Train_Loss: 0.1566 Train_Acc: 95.695 Val_Loss: 0.1304  BEST VAL Loss: 0.1304  Val_Acc: 96.362

Epoch 19: Validation loss decreased (0.130357 --> 0.128797).  Saving model ...
	 Train_Loss: 0.1545 Train_Acc: 95.734 Val_Loss: 0.1288  BEST VAL Loss: 0.1288  Val_Acc: 96.402

Epoch 20: Validation loss decreased (0.128797 --> 0.127307).  Saving model ...
	 Train_Loss: 0.1526 Train_Acc: 95.787 Val_Loss: 0.1273  BEST VAL Loss: 0.1273  Val_Acc: 96.473

Epoch 21: Validation loss decreased (0.127307 --> 0.125922).  Saving model ...
	 Train_Loss: 0.1507 Train_Acc: 95.861 Val_Loss: 0.1259  BEST VAL Loss: 0.1259  Val_Acc: 96.448

Epoch 22: Validation loss decreased (0.125922 --> 0.124677).  Saving model ...
	 Train_Loss: 0.1490 Train_Acc: 95.899 Val_Loss: 0.1247  BEST VAL Loss: 0.1247  Val_Acc: 96.544

Epoch 23: Validation loss decreased (0.124677 --> 0.123475).  Saving model ...
	 Train_Loss: 0.1473 Train_Acc: 95.920 Val_Loss: 0.1235  BEST VAL Loss: 0.1235  Val_Acc: 96.501

Epoch 24: Validation loss decreased (0.123475 --> 0.122358).  Saving model ...
	 Train_Loss: 0.1458 Train_Acc: 95.946 Val_Loss: 0.1224  BEST VAL Loss: 0.1224  Val_Acc: 96.575

Epoch 25: Validation loss decreased (0.122358 --> 0.121296).  Saving model ...
	 Train_Loss: 0.1443 Train_Acc: 96.001 Val_Loss: 0.1213  BEST VAL Loss: 0.1213  Val_Acc: 96.535

Epoch 26: Validation loss decreased (0.121296 --> 0.120251).  Saving model ...
	 Train_Loss: 0.1430 Train_Acc: 96.027 Val_Loss: 0.1203  BEST VAL Loss: 0.1203  Val_Acc: 96.627

Epoch 27: Validation loss decreased (0.120251 --> 0.119260).  Saving model ...
	 Train_Loss: 0.1416 Train_Acc: 96.118 Val_Loss: 0.1193  BEST VAL Loss: 0.1193  Val_Acc: 96.603

Epoch 28: Validation loss decreased (0.119260 --> 0.118342).  Saving model ...
	 Train_Loss: 0.1404 Train_Acc: 96.114 Val_Loss: 0.1183  BEST VAL Loss: 0.1183  Val_Acc: 96.630

Epoch 29: Validation loss decreased (0.118342 --> 0.117497).  Saving model ...
	 Train_Loss: 0.1392 Train_Acc: 96.135 Val_Loss: 0.1175  BEST VAL Loss: 0.1175  Val_Acc: 96.643

Epoch 30: Validation loss decreased (0.117497 --> 0.116652).  Saving model ...
	 Train_Loss: 0.1381 Train_Acc: 96.149 Val_Loss: 0.1167  BEST VAL Loss: 0.1167  Val_Acc: 96.686

Epoch 31: Validation loss decreased (0.116652 --> 0.115823).  Saving model ...
	 Train_Loss: 0.1369 Train_Acc: 96.196 Val_Loss: 0.1158  BEST VAL Loss: 0.1158  Val_Acc: 96.698

Epoch 32: Validation loss decreased (0.115823 --> 0.115081).  Saving model ...
	 Train_Loss: 0.1359 Train_Acc: 96.206 Val_Loss: 0.1151  BEST VAL Loss: 0.1151  Val_Acc: 96.661

Epoch 33: Validation loss decreased (0.115081 --> 0.114340).  Saving model ...
	 Train_Loss: 0.1349 Train_Acc: 96.239 Val_Loss: 0.1143  BEST VAL Loss: 0.1143  Val_Acc: 96.735

Epoch 34: Validation loss decreased (0.114340 --> 0.113631).  Saving model ...
	 Train_Loss: 0.1339 Train_Acc: 96.283 Val_Loss: 0.1136  BEST VAL Loss: 0.1136  Val_Acc: 96.704

Epoch 35: Validation loss decreased (0.113631 --> 0.113058).  Saving model ...
	 Train_Loss: 0.1330 Train_Acc: 96.283 Val_Loss: 0.1131  BEST VAL Loss: 0.1131  Val_Acc: 96.590

Epoch 36: Validation loss decreased (0.113058 --> 0.112428).  Saving model ...
	 Train_Loss: 0.1321 Train_Acc: 96.329 Val_Loss: 0.1124  BEST VAL Loss: 0.1124  Val_Acc: 96.729

Epoch 37: Validation loss decreased (0.112428 --> 0.111812).  Saving model ...
	 Train_Loss: 0.1312 Train_Acc: 96.348 Val_Loss: 0.1118  BEST VAL Loss: 0.1118  Val_Acc: 96.707

Epoch 38: Validation loss decreased (0.111812 --> 0.111203).  Saving model ...
	 Train_Loss: 0.1304 Train_Acc: 96.377 Val_Loss: 0.1112  BEST VAL Loss: 0.1112  Val_Acc: 96.741

Epoch 39: Validation loss decreased (0.111203 --> 0.110643).  Saving model ...
	 Train_Loss: 0.1296 Train_Acc: 96.342 Val_Loss: 0.1106  BEST VAL Loss: 0.1106  Val_Acc: 96.717

Epoch 40: Validation loss decreased (0.110643 --> 0.110089).  Saving model ...
	 Train_Loss: 0.1288 Train_Acc: 96.397 Val_Loss: 0.1101  BEST VAL Loss: 0.1101  Val_Acc: 96.766

Epoch 41: Validation loss decreased (0.110089 --> 0.109543).  Saving model ...
	 Train_Loss: 0.1280 Train_Acc: 96.366 Val_Loss: 0.1095  BEST VAL Loss: 0.1095  Val_Acc: 96.837

Epoch 42: Validation loss decreased (0.109543 --> 0.109007).  Saving model ...
	 Train_Loss: 0.1273 Train_Acc: 96.444 Val_Loss: 0.1090  BEST VAL Loss: 0.1090  Val_Acc: 96.794

Epoch 43: Validation loss decreased (0.109007 --> 0.108497).  Saving model ...
	 Train_Loss: 0.1265 Train_Acc: 96.514 Val_Loss: 0.1085  BEST VAL Loss: 0.1085  Val_Acc: 96.778

Epoch 44: Validation loss decreased (0.108497 --> 0.107993).  Saving model ...
	 Train_Loss: 0.1258 Train_Acc: 96.532 Val_Loss: 0.1080  BEST VAL Loss: 0.1080  Val_Acc: 96.825

Epoch 45: Validation loss decreased (0.107993 --> 0.107528).  Saving model ...
	 Train_Loss: 0.1252 Train_Acc: 96.511 Val_Loss: 0.1075  BEST VAL Loss: 0.1075  Val_Acc: 96.831

Epoch 46: Validation loss decreased (0.107528 --> 0.107071).  Saving model ...
	 Train_Loss: 0.1245 Train_Acc: 96.491 Val_Loss: 0.1071  BEST VAL Loss: 0.1071  Val_Acc: 96.877

Epoch 47: Validation loss decreased (0.107071 --> 0.106632).  Saving model ...
	 Train_Loss: 0.1239 Train_Acc: 96.523 Val_Loss: 0.1066  BEST VAL Loss: 0.1066  Val_Acc: 96.886

Epoch 48: Validation loss decreased (0.106632 --> 0.106209).  Saving model ...
	 Train_Loss: 0.1233 Train_Acc: 96.538 Val_Loss: 0.1062  BEST VAL Loss: 0.1062  Val_Acc: 96.929

Epoch 49: Validation loss decreased (0.106209 --> 0.105773).  Saving model ...
	 Train_Loss: 0.1227 Train_Acc: 96.551 Val_Loss: 0.1058  BEST VAL Loss: 0.1058  Val_Acc: 96.892

Epoch 50: Validation loss decreased (0.105773 --> 0.105354).  Saving model ...
	 Train_Loss: 0.1221 Train_Acc: 96.600 Val_Loss: 0.1054  BEST VAL Loss: 0.1054  Val_Acc: 96.889

Epoch 51: Validation loss decreased (0.105354 --> 0.104974).  Saving model ...
	 Train_Loss: 0.1215 Train_Acc: 96.583 Val_Loss: 0.1050  BEST VAL Loss: 0.1050  Val_Acc: 96.871

Epoch 52: Validation loss decreased (0.104974 --> 0.104568).  Saving model ...
	 Train_Loss: 0.1209 Train_Acc: 96.636 Val_Loss: 0.1046  BEST VAL Loss: 0.1046  Val_Acc: 96.871

Epoch 53: Validation loss decreased (0.104568 --> 0.104200).  Saving model ...
	 Train_Loss: 0.1204 Train_Acc: 96.634 Val_Loss: 0.1042  BEST VAL Loss: 0.1042  Val_Acc: 96.914

Epoch 54: Validation loss decreased (0.104200 --> 0.103836).  Saving model ...
	 Train_Loss: 0.1198 Train_Acc: 96.603 Val_Loss: 0.1038  BEST VAL Loss: 0.1038  Val_Acc: 96.892

Epoch 55: Validation loss decreased (0.103836 --> 0.103488).  Saving model ...
	 Train_Loss: 0.1193 Train_Acc: 96.620 Val_Loss: 0.1035  BEST VAL Loss: 0.1035  Val_Acc: 96.895

Epoch 56: Validation loss decreased (0.103488 --> 0.103143).  Saving model ...
	 Train_Loss: 0.1188 Train_Acc: 96.650 Val_Loss: 0.1031  BEST VAL Loss: 0.1031  Val_Acc: 96.923

Epoch 57: Validation loss decreased (0.103143 --> 0.102780).  Saving model ...
	 Train_Loss: 0.1183 Train_Acc: 96.679 Val_Loss: 0.1028  BEST VAL Loss: 0.1028  Val_Acc: 97.000

Epoch 58: Validation loss decreased (0.102780 --> 0.102466).  Saving model ...
	 Train_Loss: 0.1178 Train_Acc: 96.700 Val_Loss: 0.1025  BEST VAL Loss: 0.1025  Val_Acc: 96.932

Epoch 59: Validation loss decreased (0.102466 --> 0.102139).  Saving model ...
	 Train_Loss: 0.1174 Train_Acc: 96.702 Val_Loss: 0.1021  BEST VAL Loss: 0.1021  Val_Acc: 96.985

Epoch 60: Validation loss decreased (0.102139 --> 0.101812).  Saving model ...
	 Train_Loss: 0.1169 Train_Acc: 96.718 Val_Loss: 0.1018  BEST VAL Loss: 0.1018  Val_Acc: 97.009

Epoch 61: Validation loss decreased (0.101812 --> 0.101506).  Saving model ...
	 Train_Loss: 0.1164 Train_Acc: 96.732 Val_Loss: 0.1015  BEST VAL Loss: 0.1015  Val_Acc: 96.997

Epoch 62: Validation loss decreased (0.101506 --> 0.101197).  Saving model ...
	 Train_Loss: 0.1160 Train_Acc: 96.733 Val_Loss: 0.1012  BEST VAL Loss: 0.1012  Val_Acc: 96.972

Epoch 63: Validation loss decreased (0.101197 --> 0.100897).  Saving model ...
	 Train_Loss: 0.1156 Train_Acc: 96.727 Val_Loss: 0.1009  BEST VAL Loss: 0.1009  Val_Acc: 97.000

Epoch 64: Validation loss decreased (0.100897 --> 0.100604).  Saving model ...
	 Train_Loss: 0.1151 Train_Acc: 96.755 Val_Loss: 0.1006  BEST VAL Loss: 0.1006  Val_Acc: 97.000

Epoch 65: Validation loss decreased (0.100604 --> 0.100341).  Saving model ...
	 Train_Loss: 0.1147 Train_Acc: 96.759 Val_Loss: 0.1003  BEST VAL Loss: 0.1003  Val_Acc: 97.019

Epoch 66: Validation loss decreased (0.100341 --> 0.100058).  Saving model ...
	 Train_Loss: 0.1143 Train_Acc: 96.790 Val_Loss: 0.1001  BEST VAL Loss: 0.1001  Val_Acc: 97.068

Epoch 67: Validation loss decreased (0.100058 --> 0.099785).  Saving model ...
	 Train_Loss: 0.1139 Train_Acc: 96.764 Val_Loss: 0.0998  BEST VAL Loss: 0.0998  Val_Acc: 96.997

Epoch 68: Validation loss decreased (0.099785 --> 0.099515).  Saving model ...
	 Train_Loss: 0.1135 Train_Acc: 96.799 Val_Loss: 0.0995  BEST VAL Loss: 0.0995  Val_Acc: 97.003

Epoch 69: Validation loss decreased (0.099515 --> 0.099267).  Saving model ...
	 Train_Loss: 0.1131 Train_Acc: 96.765 Val_Loss: 0.0993  BEST VAL Loss: 0.0993  Val_Acc: 97.019

Epoch 70: Validation loss decreased (0.099267 --> 0.099017).  Saving model ...
	 Train_Loss: 0.1127 Train_Acc: 96.798 Val_Loss: 0.0990  BEST VAL Loss: 0.0990  Val_Acc: 97.043

Epoch 71: Validation loss decreased (0.099017 --> 0.098777).  Saving model ...
	 Train_Loss: 0.1124 Train_Acc: 96.795 Val_Loss: 0.0988  BEST VAL Loss: 0.0988  Val_Acc: 97.016

Epoch 72: Validation loss decreased (0.098777 --> 0.098544).  Saving model ...
	 Train_Loss: 0.1120 Train_Acc: 96.825 Val_Loss: 0.0985  BEST VAL Loss: 0.0985  Val_Acc: 96.963

Epoch 73: Validation loss decreased (0.098544 --> 0.098302).  Saving model ...
	 Train_Loss: 0.1116 Train_Acc: 96.844 Val_Loss: 0.0983  BEST VAL Loss: 0.0983  Val_Acc: 97.065

Epoch 74: Validation loss decreased (0.098302 --> 0.098054).  Saving model ...
	 Train_Loss: 0.1113 Train_Acc: 96.857 Val_Loss: 0.0981  BEST VAL Loss: 0.0981  Val_Acc: 97.074

Epoch 75: Validation loss decreased (0.098054 --> 0.097827).  Saving model ...
	 Train_Loss: 0.1110 Train_Acc: 96.838 Val_Loss: 0.0978  BEST VAL Loss: 0.0978  Val_Acc: 97.093

Epoch 76: Validation loss decreased (0.097827 --> 0.097599).  Saving model ...
	 Train_Loss: 0.1106 Train_Acc: 96.897 Val_Loss: 0.0976  BEST VAL Loss: 0.0976  Val_Acc: 97.093

Epoch 77: Validation loss decreased (0.097599 --> 0.097364).  Saving model ...
	 Train_Loss: 0.1103 Train_Acc: 96.859 Val_Loss: 0.0974  BEST VAL Loss: 0.0974  Val_Acc: 97.136

Epoch 78: Validation loss decreased (0.097364 --> 0.097150).  Saving model ...
	 Train_Loss: 0.1099 Train_Acc: 96.866 Val_Loss: 0.0972  BEST VAL Loss: 0.0972  Val_Acc: 97.102

Epoch 79: Validation loss decreased (0.097150 --> 0.096937).  Saving model ...
	 Train_Loss: 0.1096 Train_Acc: 96.888 Val_Loss: 0.0969  BEST VAL Loss: 0.0969  Val_Acc: 97.068

Epoch 80: Validation loss decreased (0.096937 --> 0.096730).  Saving model ...
	 Train_Loss: 0.1093 Train_Acc: 96.906 Val_Loss: 0.0967  BEST VAL Loss: 0.0967  Val_Acc: 97.108

Epoch 81: Validation loss decreased (0.096730 --> 0.096522).  Saving model ...
	 Train_Loss: 0.1090 Train_Acc: 96.900 Val_Loss: 0.0965  BEST VAL Loss: 0.0965  Val_Acc: 97.164

Epoch 82: Validation loss decreased (0.096522 --> 0.096326).  Saving model ...
	 Train_Loss: 0.1087 Train_Acc: 96.921 Val_Loss: 0.0963  BEST VAL Loss: 0.0963  Val_Acc: 97.170

Epoch 83: Validation loss decreased (0.096326 --> 0.096123).  Saving model ...
	 Train_Loss: 0.1084 Train_Acc: 96.878 Val_Loss: 0.0961  BEST VAL Loss: 0.0961  Val_Acc: 97.148

Epoch 84: Validation loss decreased (0.096123 --> 0.095934).  Saving model ...
	 Train_Loss: 0.1081 Train_Acc: 96.884 Val_Loss: 0.0959  BEST VAL Loss: 0.0959  Val_Acc: 97.145

Epoch 85: Validation loss decreased (0.095934 --> 0.095749).  Saving model ...
	 Train_Loss: 0.1078 Train_Acc: 96.881 Val_Loss: 0.0957  BEST VAL Loss: 0.0957  Val_Acc: 97.142

Epoch 86: Validation loss decreased (0.095749 --> 0.095571).  Saving model ...
	 Train_Loss: 0.1075 Train_Acc: 96.956 Val_Loss: 0.0956  BEST VAL Loss: 0.0956  Val_Acc: 97.093

Epoch 87: Validation loss decreased (0.095571 --> 0.095395).  Saving model ...
	 Train_Loss: 0.1073 Train_Acc: 96.892 Val_Loss: 0.0954  BEST VAL Loss: 0.0954  Val_Acc: 97.127

Epoch 88: Validation loss decreased (0.095395 --> 0.095247).  Saving model ...
	 Train_Loss: 0.1070 Train_Acc: 96.939 Val_Loss: 0.0952  BEST VAL Loss: 0.0952  Val_Acc: 97.071

Epoch 89: Validation loss decreased (0.095247 --> 0.095078).  Saving model ...
	 Train_Loss: 0.1067 Train_Acc: 96.930 Val_Loss: 0.0951  BEST VAL Loss: 0.0951  Val_Acc: 97.188

Epoch 90: Validation loss decreased (0.095078 --> 0.094899).  Saving model ...
	 Train_Loss: 0.1064 Train_Acc: 96.971 Val_Loss: 0.0949  BEST VAL Loss: 0.0949  Val_Acc: 97.182

Epoch 91: Validation loss decreased (0.094899 --> 0.094738).  Saving model ...
	 Train_Loss: 0.1062 Train_Acc: 96.965 Val_Loss: 0.0947  BEST VAL Loss: 0.0947  Val_Acc: 97.080

Epoch 92: Validation loss decreased (0.094738 --> 0.094594).  Saving model ...
	 Train_Loss: 0.1059 Train_Acc: 96.973 Val_Loss: 0.0946  BEST VAL Loss: 0.0946  Val_Acc: 97.093

Epoch 93: Validation loss decreased (0.094594 --> 0.094436).  Saving model ...
	 Train_Loss: 0.1056 Train_Acc: 96.961 Val_Loss: 0.0944  BEST VAL Loss: 0.0944  Val_Acc: 97.188

Epoch 94: Validation loss decreased (0.094436 --> 0.094281).  Saving model ...
	 Train_Loss: 0.1054 Train_Acc: 96.974 Val_Loss: 0.0943  BEST VAL Loss: 0.0943  Val_Acc: 97.191

Epoch 95: Validation loss decreased (0.094281 --> 0.094135).  Saving model ...
	 Train_Loss: 0.1051 Train_Acc: 96.990 Val_Loss: 0.0941  BEST VAL Loss: 0.0941  Val_Acc: 97.154

Epoch 96: Validation loss decreased (0.094135 --> 0.093978).  Saving model ...
	 Train_Loss: 0.1049 Train_Acc: 96.968 Val_Loss: 0.0940  BEST VAL Loss: 0.0940  Val_Acc: 97.268

Epoch 97: Validation loss decreased (0.093978 --> 0.093820).  Saving model ...
	 Train_Loss: 0.1046 Train_Acc: 96.989 Val_Loss: 0.0938  BEST VAL Loss: 0.0938  Val_Acc: 97.219

Epoch 98: Validation loss decreased (0.093820 --> 0.093667).  Saving model ...
	 Train_Loss: 0.1044 Train_Acc: 97.012 Val_Loss: 0.0937  BEST VAL Loss: 0.0937  Val_Acc: 97.139

Epoch 99: Validation loss decreased (0.093667 --> 0.093511).  Saving model ...
	 Train_Loss: 0.1042 Train_Acc: 97.020 Val_Loss: 0.0935  BEST VAL Loss: 0.0935  Val_Acc: 97.194

DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.58      0.58      0.58    149884
           1       0.42      0.42      0.42    109598

    accuracy                           0.51    259482
   macro avg       0.50      0.50      0.50    259482
weighted avg       0.51      0.51      0.51    259482

DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.58      0.58      0.58     18736
           1       0.43      0.42      0.42     13700

    accuracy                           0.52     32436
   macro avg       0.50      0.50      0.50     32436
weighted avg       0.51      0.52      0.51     32436

DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.57      0.58      0.58     18736
           1       0.42      0.41      0.42     13700

    accuracy                           0.51     32436
   macro avg       0.50      0.50      0.50     32436
weighted avg       0.51      0.51      0.51     32436

              precision    recall  f1-score   support

           0       0.57      0.58      0.58     18736
           1       0.42      0.41      0.42     13700

    accuracy                           0.51     32436
   macro avg       0.50      0.50      0.50     32436
weighted avg       0.51      0.51      0.51     32436

DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.39      0.47      0.42     27774
           1       0.61      0.53      0.57     44168

    accuracy                           0.51     71942
   macro avg       0.50      0.50      0.50     71942
weighted avg       0.53      0.51      0.51     71942

              precision    recall  f1-score   support

           0       0.39      0.47      0.42     27774
           1       0.61      0.53      0.57     44168

    accuracy                           0.51     71942
   macro avg       0.50      0.50      0.50     71942
weighted avg       0.53      0.51      0.51     71942

completed
