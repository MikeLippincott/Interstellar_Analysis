[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'bd8fdd76'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '55e86aa0'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '9e31ffb6'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '3a88045c'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (319763, 1270)
Number of total missing values across all columns: 277194
Data Subset Is Off
Wells held out for testing: ['C09' 'M09']
Wells to use for training, validation, and testing ['C02' 'C03' 'C08' 'M02' 'M03' 'M08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.240745).  Saving model ...
	 Train_Loss: 0.3713 Train_Acc: 83.553 Val_Loss: 0.2407  BEST VAL Loss: 0.2407  Val_Acc: 90.425

Epoch 1: Validation loss decreased (0.240745 --> 0.224449).  Saving model ...
	 Train_Loss: 0.3296 Train_Acc: 87.884 Val_Loss: 0.2244  BEST VAL Loss: 0.2244  Val_Acc: 91.852

Epoch 2: Validation loss decreased (0.224449 --> 0.216215).  Saving model ...
	 Train_Loss: 0.3094 Train_Acc: 88.504 Val_Loss: 0.2162  BEST VAL Loss: 0.2162  Val_Acc: 92.451

Epoch 3: Validation loss decreased (0.216215 --> 0.209237).  Saving model ...
	 Train_Loss: 0.2979 Train_Acc: 88.830 Val_Loss: 0.2092  BEST VAL Loss: 0.2092  Val_Acc: 92.736

Epoch 4: Validation loss decreased (0.209237 --> 0.206163).  Saving model ...
	 Train_Loss: 0.2892 Train_Acc: 89.124 Val_Loss: 0.2062  BEST VAL Loss: 0.2062  Val_Acc: 92.619

Epoch 5: Validation loss decreased (0.206163 --> 0.202189).  Saving model ...
	 Train_Loss: 0.2831 Train_Acc: 89.266 Val_Loss: 0.2022  BEST VAL Loss: 0.2022  Val_Acc: 93.094

Epoch 6: Validation loss decreased (0.202189 --> 0.199327).  Saving model ...
	 Train_Loss: 0.2777 Train_Acc: 89.450 Val_Loss: 0.1993  BEST VAL Loss: 0.1993  Val_Acc: 92.882

Epoch 7: Validation loss decreased (0.199327 --> 0.197620).  Saving model ...
	 Train_Loss: 0.2739 Train_Acc: 89.508 Val_Loss: 0.1976  BEST VAL Loss: 0.1976  Val_Acc: 92.714

Epoch 8: Validation loss decreased (0.197620 --> 0.195877).  Saving model ...
	 Train_Loss: 0.2704 Train_Acc: 89.492 Val_Loss: 0.1959  BEST VAL Loss: 0.1959  Val_Acc: 92.964

Epoch 9: Validation loss decreased (0.195877 --> 0.194014).  Saving model ...
	 Train_Loss: 0.2673 Train_Acc: 89.695 Val_Loss: 0.1940  BEST VAL Loss: 0.1940  Val_Acc: 93.102

Epoch 10: Validation loss decreased (0.194014 --> 0.192973).  Saving model ...
	 Train_Loss: 0.2646 Train_Acc: 89.733 Val_Loss: 0.1930  BEST VAL Loss: 0.1930  Val_Acc: 92.917

Epoch 11: Validation loss decreased (0.192973 --> 0.191871).  Saving model ...
	 Train_Loss: 0.2623 Train_Acc: 89.754 Val_Loss: 0.1919  BEST VAL Loss: 0.1919  Val_Acc: 92.938

Epoch 12: Validation loss decreased (0.191871 --> 0.190237).  Saving model ...
	 Train_Loss: 0.2604 Train_Acc: 89.686 Val_Loss: 0.1902  BEST VAL Loss: 0.1902  Val_Acc: 93.197

Epoch 13: Validation loss decreased (0.190237 --> 0.188916).  Saving model ...
	 Train_Loss: 0.2585 Train_Acc: 89.831 Val_Loss: 0.1889  BEST VAL Loss: 0.1889  Val_Acc: 93.309

Epoch 14: Validation loss decreased (0.188916 --> 0.188244).  Saving model ...
	 Train_Loss: 0.2568 Train_Acc: 89.848 Val_Loss: 0.1882  BEST VAL Loss: 0.1882  Val_Acc: 92.982

Epoch 15: Validation loss decreased (0.188244 --> 0.187598).  Saving model ...
	 Train_Loss: 0.2555 Train_Acc: 89.822 Val_Loss: 0.1876  BEST VAL Loss: 0.1876  Val_Acc: 93.275

Epoch 16: Validation loss decreased (0.187598 --> 0.186763).  Saving model ...
	 Train_Loss: 0.2539 Train_Acc: 90.039 Val_Loss: 0.1868  BEST VAL Loss: 0.1868  Val_Acc: 93.223

Epoch 17: Validation loss decreased (0.186763 --> 0.185937).  Saving model ...
	 Train_Loss: 0.2526 Train_Acc: 90.006 Val_Loss: 0.1859  BEST VAL Loss: 0.1859  Val_Acc: 93.301

Epoch 18: Validation loss decreased (0.185937 --> 0.185142).  Saving model ...
	 Train_Loss: 0.2513 Train_Acc: 90.075 Val_Loss: 0.1851  BEST VAL Loss: 0.1851  Val_Acc: 93.378

Epoch 19: Validation loss decreased (0.185142 --> 0.184427).  Saving model ...
	 Train_Loss: 0.2502 Train_Acc: 90.014 Val_Loss: 0.1844  BEST VAL Loss: 0.1844  Val_Acc: 93.512

Epoch 20: Validation loss decreased (0.184427 --> 0.183692).  Saving model ...
	 Train_Loss: 0.2492 Train_Acc: 90.022 Val_Loss: 0.1837  BEST VAL Loss: 0.1837  Val_Acc: 93.495

Epoch 21: Validation loss decreased (0.183692 --> 0.183014).  Saving model ...
	 Train_Loss: 0.2483 Train_Acc: 90.006 Val_Loss: 0.1830  BEST VAL Loss: 0.1830  Val_Acc: 93.417

Epoch 22: Validation loss decreased (0.183014 --> 0.182427).  Saving model ...
	 Train_Loss: 0.2474 Train_Acc: 89.957 Val_Loss: 0.1824  BEST VAL Loss: 0.1824  Val_Acc: 93.357

Epoch 23: Validation loss did not decrease
	 Train_Loss: 0.2465 Train_Acc: 90.075 Val_Loss: 0.1825  BEST VAL Loss: 0.1824  Val_Acc: 93.275

Epoch 24: Validation loss decreased (0.182427 --> 0.181914).  Saving model ...
	 Train_Loss: 0.2458 Train_Acc: 90.019 Val_Loss: 0.1819  BEST VAL Loss: 0.1819  Val_Acc: 93.395

Epoch 25: Validation loss decreased (0.181914 --> 0.181360).  Saving model ...
	 Train_Loss: 0.2450 Train_Acc: 90.143 Val_Loss: 0.1814  BEST VAL Loss: 0.1814  Val_Acc: 93.654

Epoch 26: Validation loss decreased (0.181360 --> 0.181077).  Saving model ...
	 Train_Loss: 0.2444 Train_Acc: 90.020 Val_Loss: 0.1811  BEST VAL Loss: 0.1811  Val_Acc: 93.568

Epoch 27: Validation loss decreased (0.181077 --> 0.180608).  Saving model ...
	 Train_Loss: 0.2435 Train_Acc: 90.195 Val_Loss: 0.1806  BEST VAL Loss: 0.1806  Val_Acc: 93.633

Epoch 28: Validation loss decreased (0.180608 --> 0.180140).  Saving model ...
	 Train_Loss: 0.2427 Train_Acc: 90.187 Val_Loss: 0.1801  BEST VAL Loss: 0.1801  Val_Acc: 93.706

Epoch 29: Validation loss decreased (0.180140 --> 0.179743).  Saving model ...
	 Train_Loss: 0.2421 Train_Acc: 90.078 Val_Loss: 0.1797  BEST VAL Loss: 0.1797  Val_Acc: 93.792

Epoch 30: Validation loss decreased (0.179743 --> 0.179371).  Saving model ...
	 Train_Loss: 0.2415 Train_Acc: 90.198 Val_Loss: 0.1794  BEST VAL Loss: 0.1794  Val_Acc: 93.680

Epoch 31: Validation loss decreased (0.179371 --> 0.179093).  Saving model ...
	 Train_Loss: 0.2409 Train_Acc: 90.318 Val_Loss: 0.1791  BEST VAL Loss: 0.1791  Val_Acc: 93.702

Epoch 32: Validation loss decreased (0.179093 --> 0.178792).  Saving model ...
	 Train_Loss: 0.2402 Train_Acc: 90.289 Val_Loss: 0.1788  BEST VAL Loss: 0.1788  Val_Acc: 93.413

Epoch 33: Validation loss decreased (0.178792 --> 0.178537).  Saving model ...
	 Train_Loss: 0.2397 Train_Acc: 90.189 Val_Loss: 0.1785  BEST VAL Loss: 0.1785  Val_Acc: 93.762

Epoch 34: Validation loss decreased (0.178537 --> 0.178348).  Saving model ...
	 Train_Loss: 0.2392 Train_Acc: 90.237 Val_Loss: 0.1783  BEST VAL Loss: 0.1783  Val_Acc: 93.736

Epoch 35: Validation loss decreased (0.178348 --> 0.178188).  Saving model ...
	 Train_Loss: 0.2388 Train_Acc: 90.019 Val_Loss: 0.1782  BEST VAL Loss: 0.1782  Val_Acc: 93.559

Epoch 36: Validation loss decreased (0.178188 --> 0.177863).  Saving model ...
	 Train_Loss: 0.2383 Train_Acc: 90.256 Val_Loss: 0.1779  BEST VAL Loss: 0.1779  Val_Acc: 93.814

Epoch 37: Validation loss decreased (0.177863 --> 0.177489).  Saving model ...
	 Train_Loss: 0.2378 Train_Acc: 90.253 Val_Loss: 0.1775  BEST VAL Loss: 0.1775  Val_Acc: 93.809

Epoch 38: Validation loss decreased (0.177489 --> 0.177157).  Saving model ...
	 Train_Loss: 0.2372 Train_Acc: 90.330 Val_Loss: 0.1772  BEST VAL Loss: 0.1772  Val_Acc: 93.831

Epoch 39: Validation loss decreased (0.177157 --> 0.176696).  Saving model ...
	 Train_Loss: 0.2367 Train_Acc: 90.373 Val_Loss: 0.1767  BEST VAL Loss: 0.1767  Val_Acc: 93.710

Epoch 40: Validation loss decreased (0.176696 --> 0.176323).  Saving model ...
	 Train_Loss: 0.2362 Train_Acc: 90.470 Val_Loss: 0.1763  BEST VAL Loss: 0.1763  Val_Acc: 93.913

Epoch 41: Validation loss decreased (0.176323 --> 0.176077).  Saving model ...
	 Train_Loss: 0.2357 Train_Acc: 90.352 Val_Loss: 0.1761  BEST VAL Loss: 0.1761  Val_Acc: 93.839

Epoch 42: Validation loss decreased (0.176077 --> 0.175771).  Saving model ...
	 Train_Loss: 0.2353 Train_Acc: 90.381 Val_Loss: 0.1758  BEST VAL Loss: 0.1758  Val_Acc: 93.990

Epoch 43: Validation loss decreased (0.175771 --> 0.175490).  Saving model ...
	 Train_Loss: 0.2350 Train_Acc: 90.217 Val_Loss: 0.1755  BEST VAL Loss: 0.1755  Val_Acc: 93.930

Epoch 44: Validation loss decreased (0.175490 --> 0.175204).  Saving model ...
	 Train_Loss: 0.2347 Train_Acc: 90.201 Val_Loss: 0.1752  BEST VAL Loss: 0.1752  Val_Acc: 93.762

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.2343 Train_Acc: 90.263 Val_Loss: 0.1752  BEST VAL Loss: 0.1752  Val_Acc: 93.753

Epoch 46: Validation loss decreased (0.175204 --> 0.174892).  Saving model ...
	 Train_Loss: 0.2339 Train_Acc: 90.182 Val_Loss: 0.1749  BEST VAL Loss: 0.1749  Val_Acc: 94.072

Epoch 47: Validation loss decreased (0.174892 --> 0.174685).  Saving model ...
	 Train_Loss: 0.2335 Train_Acc: 90.360 Val_Loss: 0.1747  BEST VAL Loss: 0.1747  Val_Acc: 93.969

Epoch 48: Validation loss decreased (0.174685 --> 0.174494).  Saving model ...
	 Train_Loss: 0.2332 Train_Acc: 90.311 Val_Loss: 0.1745  BEST VAL Loss: 0.1745  Val_Acc: 93.857

Epoch 49: Validation loss decreased (0.174494 --> 0.174252).  Saving model ...
	 Train_Loss: 0.2328 Train_Acc: 90.294 Val_Loss: 0.1743  BEST VAL Loss: 0.1743  Val_Acc: 93.835

Epoch 50: Validation loss decreased (0.174252 --> 0.173970).  Saving model ...
	 Train_Loss: 0.2325 Train_Acc: 90.477 Val_Loss: 0.1740  BEST VAL Loss: 0.1740  Val_Acc: 93.895

Epoch 51: Validation loss decreased (0.173970 --> 0.173710).  Saving model ...
	 Train_Loss: 0.2322 Train_Acc: 90.466 Val_Loss: 0.1737  BEST VAL Loss: 0.1737  Val_Acc: 94.051

Epoch 52: Validation loss decreased (0.173710 --> 0.173610).  Saving model ...
	 Train_Loss: 0.2319 Train_Acc: 90.270 Val_Loss: 0.1736  BEST VAL Loss: 0.1736  Val_Acc: 94.089

Epoch 53: Validation loss decreased (0.173610 --> 0.173559).  Saving model ...
	 Train_Loss: 0.2316 Train_Acc: 90.066 Val_Loss: 0.1736  BEST VAL Loss: 0.1736  Val_Acc: 93.180

Epoch 54: Validation loss decreased (0.173559 --> 0.173394).  Saving model ...
	 Train_Loss: 0.2313 Train_Acc: 90.348 Val_Loss: 0.1734  BEST VAL Loss: 0.1734  Val_Acc: 93.788

Epoch 55: Validation loss decreased (0.173394 --> 0.173150).  Saving model ...
	 Train_Loss: 0.2310 Train_Acc: 90.480 Val_Loss: 0.1732  BEST VAL Loss: 0.1732  Val_Acc: 93.900

Epoch 56: Validation loss decreased (0.173150 --> 0.172964).  Saving model ...
	 Train_Loss: 0.2306 Train_Acc: 90.470 Val_Loss: 0.1730  BEST VAL Loss: 0.1730  Val_Acc: 94.068

Epoch 57: Validation loss decreased (0.172964 --> 0.172774).  Saving model ...
	 Train_Loss: 0.2304 Train_Acc: 90.443 Val_Loss: 0.1728  BEST VAL Loss: 0.1728  Val_Acc: 93.874

Epoch 58: Validation loss decreased (0.172774 --> 0.172565).  Saving model ...
	 Train_Loss: 0.2301 Train_Acc: 90.516 Val_Loss: 0.1726  BEST VAL Loss: 0.1726  Val_Acc: 93.908

Epoch 59: Validation loss decreased (0.172565 --> 0.172463).  Saving model ...
	 Train_Loss: 0.2297 Train_Acc: 90.582 Val_Loss: 0.1725  BEST VAL Loss: 0.1725  Val_Acc: 93.921

Epoch 60: Validation loss decreased (0.172463 --> 0.172249).  Saving model ...
	 Train_Loss: 0.2295 Train_Acc: 90.303 Val_Loss: 0.1722  BEST VAL Loss: 0.1722  Val_Acc: 94.059

Epoch 61: Validation loss decreased (0.172249 --> 0.172136).  Saving model ...
	 Train_Loss: 0.2292 Train_Acc: 90.559 Val_Loss: 0.1721  BEST VAL Loss: 0.1721  Val_Acc: 93.990

Epoch 62: Validation loss decreased (0.172136 --> 0.171959).  Saving model ...
	 Train_Loss: 0.2289 Train_Acc: 90.525 Val_Loss: 0.1720  BEST VAL Loss: 0.1720  Val_Acc: 94.016

Epoch 63: Validation loss decreased (0.171959 --> 0.171752).  Saving model ...
	 Train_Loss: 0.2287 Train_Acc: 90.445 Val_Loss: 0.1718  BEST VAL Loss: 0.1718  Val_Acc: 94.141

Epoch 64: Validation loss decreased (0.171752 --> 0.171666).  Saving model ...
	 Train_Loss: 0.2284 Train_Acc: 90.600 Val_Loss: 0.1717  BEST VAL Loss: 0.1717  Val_Acc: 94.025

Epoch 65: Validation loss decreased (0.171666 --> 0.171516).  Saving model ...
	 Train_Loss: 0.2282 Train_Acc: 90.470 Val_Loss: 0.1715  BEST VAL Loss: 0.1715  Val_Acc: 93.852

Epoch 66: Validation loss decreased (0.171516 --> 0.171266).  Saving model ...
	 Train_Loss: 0.2279 Train_Acc: 90.569 Val_Loss: 0.1713  BEST VAL Loss: 0.1713  Val_Acc: 94.085

Epoch 67: Validation loss decreased (0.171266 --> 0.171108).  Saving model ...
	 Train_Loss: 0.2277 Train_Acc: 90.318 Val_Loss: 0.1711  BEST VAL Loss: 0.1711  Val_Acc: 93.934

Epoch 68: Validation loss decreased (0.171108 --> 0.170897).  Saving model ...
	 Train_Loss: 0.2275 Train_Acc: 90.493 Val_Loss: 0.1709  BEST VAL Loss: 0.1709  Val_Acc: 94.033

Epoch 69: Validation loss decreased (0.170897 --> 0.170780).  Saving model ...
	 Train_Loss: 0.2273 Train_Acc: 90.384 Val_Loss: 0.1708  BEST VAL Loss: 0.1708  Val_Acc: 94.102

Epoch 70: Validation loss decreased (0.170780 --> 0.170686).  Saving model ...
	 Train_Loss: 0.2271 Train_Acc: 90.390 Val_Loss: 0.1707  BEST VAL Loss: 0.1707  Val_Acc: 93.982

Epoch 71: Validation loss decreased (0.170686 --> 0.170488).  Saving model ...
	 Train_Loss: 0.2268 Train_Acc: 90.555 Val_Loss: 0.1705  BEST VAL Loss: 0.1705  Val_Acc: 94.003

Epoch 72: Validation loss decreased (0.170488 --> 0.170367).  Saving model ...
	 Train_Loss: 0.2266 Train_Acc: 90.476 Val_Loss: 0.1704  BEST VAL Loss: 0.1704  Val_Acc: 94.016

Epoch 73: Validation loss decreased (0.170367 --> 0.170249).  Saving model ...
	 Train_Loss: 0.2263 Train_Acc: 90.484 Val_Loss: 0.1702  BEST VAL Loss: 0.1702  Val_Acc: 94.197

Epoch 74: Validation loss decreased (0.170249 --> 0.170136).  Saving model ...
	 Train_Loss: 0.2261 Train_Acc: 90.512 Val_Loss: 0.1701  BEST VAL Loss: 0.1701  Val_Acc: 94.072

Epoch 75: Validation loss decreased (0.170136 --> 0.170036).  Saving model ...
	 Train_Loss: 0.2259 Train_Acc: 90.504 Val_Loss: 0.1700  BEST VAL Loss: 0.1700  Val_Acc: 93.848

Epoch 76: Validation loss decreased (0.170036 --> 0.169892).  Saving model ...
	 Train_Loss: 0.2257 Train_Acc: 90.506 Val_Loss: 0.1699  BEST VAL Loss: 0.1699  Val_Acc: 94.150

Epoch 77: Validation loss decreased (0.169892 --> 0.169703).  Saving model ...
	 Train_Loss: 0.2255 Train_Acc: 90.588 Val_Loss: 0.1697  BEST VAL Loss: 0.1697  Val_Acc: 94.141

Epoch 78: Validation loss decreased (0.169703 --> 0.169637).  Saving model ...
	 Train_Loss: 0.2253 Train_Acc: 90.492 Val_Loss: 0.1696  BEST VAL Loss: 0.1696  Val_Acc: 94.033

Epoch 79: Validation loss decreased (0.169637 --> 0.169512).  Saving model ...
	 Train_Loss: 0.2251 Train_Acc: 90.451 Val_Loss: 0.1695  BEST VAL Loss: 0.1695  Val_Acc: 94.094

Epoch 80: Validation loss decreased (0.169512 --> 0.169305).  Saving model ...
	 Train_Loss: 0.2249 Train_Acc: 90.537 Val_Loss: 0.1693  BEST VAL Loss: 0.1693  Val_Acc: 94.296

Epoch 81: Validation loss decreased (0.169305 --> 0.169256).  Saving model ...
	 Train_Loss: 0.2247 Train_Acc: 90.504 Val_Loss: 0.1693  BEST VAL Loss: 0.1693  Val_Acc: 94.046

Epoch 82: Validation loss decreased (0.169256 --> 0.169124).  Saving model ...
	 Train_Loss: 0.2246 Train_Acc: 90.375 Val_Loss: 0.1691  BEST VAL Loss: 0.1691  Val_Acc: 94.098

Epoch 83: Validation loss decreased (0.169124 --> 0.169065).  Saving model ...
	 Train_Loss: 0.2244 Train_Acc: 90.660 Val_Loss: 0.1691  BEST VAL Loss: 0.1691  Val_Acc: 93.921

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.2243 Train_Acc: 90.280 Val_Loss: 0.1693  BEST VAL Loss: 0.1691  Val_Acc: 93.374

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.2242 Train_Acc: 90.436 Val_Loss: 0.1691  BEST VAL Loss: 0.1691  Val_Acc: 93.990

Epoch 86: Validation loss decreased (0.169065 --> 0.169053).  Saving model ...
	 Train_Loss: 0.2240 Train_Acc: 90.620 Val_Loss: 0.1691  BEST VAL Loss: 0.1691  Val_Acc: 94.202

Epoch 87: Validation loss decreased (0.169053 --> 0.168885).  Saving model ...
	 Train_Loss: 0.2238 Train_Acc: 90.644 Val_Loss: 0.1689  BEST VAL Loss: 0.1689  Val_Acc: 94.111

Epoch 88: Validation loss decreased (0.168885 --> 0.168798).  Saving model ...
	 Train_Loss: 0.2236 Train_Acc: 90.644 Val_Loss: 0.1688  BEST VAL Loss: 0.1688  Val_Acc: 94.245

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.2234 Train_Acc: 90.544 Val_Loss: 0.1688  BEST VAL Loss: 0.1688  Val_Acc: 94.206

Epoch 90: Validation loss decreased (0.168798 --> 0.168798).  Saving model ...
	 Train_Loss: 0.2233 Train_Acc: 90.466 Val_Loss: 0.1688  BEST VAL Loss: 0.1688  Val_Acc: 93.982

Epoch 91: Validation loss decreased (0.168798 --> 0.168672).  Saving model ...
	 Train_Loss: 0.2231 Train_Acc: 90.576 Val_Loss: 0.1687  BEST VAL Loss: 0.1687  Val_Acc: 94.111

Epoch 92: Validation loss decreased (0.168672 --> 0.168526).  Saving model ...
	 Train_Loss: 0.2229 Train_Acc: 90.669 Val_Loss: 0.1685  BEST VAL Loss: 0.1685  Val_Acc: 94.128

Epoch 93: Validation loss decreased (0.168526 --> 0.168449).  Saving model ...
	 Train_Loss: 0.2228 Train_Acc: 90.639 Val_Loss: 0.1684  BEST VAL Loss: 0.1684  Val_Acc: 94.146

Epoch 94: Validation loss decreased (0.168449 --> 0.168310).  Saving model ...
	 Train_Loss: 0.2226 Train_Acc: 90.722 Val_Loss: 0.1683  BEST VAL Loss: 0.1683  Val_Acc: 94.279

Epoch 95: Validation loss decreased (0.168310 --> 0.168269).  Saving model ...
	 Train_Loss: 0.2225 Train_Acc: 90.624 Val_Loss: 0.1683  BEST VAL Loss: 0.1683  Val_Acc: 94.167

Epoch 96: Validation loss decreased (0.168269 --> 0.168166).  Saving model ...
	 Train_Loss: 0.2223 Train_Acc: 90.558 Val_Loss: 0.1682  BEST VAL Loss: 0.1682  Val_Acc: 94.124

Epoch 97: Validation loss decreased (0.168166 --> 0.168085).  Saving model ...
	 Train_Loss: 0.2221 Train_Acc: 90.692 Val_Loss: 0.1681  BEST VAL Loss: 0.1681  Val_Acc: 94.008

Epoch 98: Validation loss decreased (0.168085 --> 0.167965).  Saving model ...
	 Train_Loss: 0.2219 Train_Acc: 90.565 Val_Loss: 0.1680  BEST VAL Loss: 0.1680  Val_Acc: 94.176

Epoch 99: Validation loss decreased (0.167965 --> 0.167903).  Saving model ...
	 Train_Loss: 0.2218 Train_Acc: 90.631 Val_Loss: 0.1679  BEST VAL Loss: 0.1679  Val_Acc: 93.943

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.96      0.91      0.94     80324
           1       0.94      0.97      0.95    105242

    accuracy                           0.95    185566
   macro avg       0.95      0.94      0.95    185566
weighted avg       0.95      0.95      0.95    185566

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.96      0.90      0.93     10041
           1       0.93      0.97      0.95     13155

    accuracy                           0.94     23196
   macro avg       0.94      0.94      0.94     23196
weighted avg       0.94      0.94      0.94     23196

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.95      0.90      0.93     10041
           1       0.93      0.96      0.95     13155

    accuracy                           0.94     23196
   macro avg       0.94      0.93      0.94     23196
weighted avg       0.94      0.94      0.94     23196

              precision    recall  f1-score   support

           0       0.95      0.90      0.93     10041
           1       0.93      0.96      0.95     13155

    accuracy                           0.94     23196
   macro avg       0.94      0.93      0.94     23196
weighted avg       0.94      0.94      0.94     23196

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.90      0.94     38191
           1       0.93      0.99      0.96     49614

    accuracy                           0.95     87805
   macro avg       0.96      0.94      0.95     87805
weighted avg       0.95      0.95      0.95     87805

              precision    recall  f1-score   support

           0       0.98      0.90      0.94     38191
           1       0.93      0.99      0.96     49614

    accuracy                           0.95     87805
   macro avg       0.96      0.94      0.95     87805
weighted avg       0.95      0.95      0.95     87805

completed
