[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '568d1f20'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'f652eaf2'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '85570767'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'f619539b'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_10.000_DMSO_0.025 treatment_name: H2O2_100.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: H2O2_100.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (43710, 1276)
Number of total missing values across all columns: 87420
Data Subset Is Off
Wells held out for testing: ['E21' 'H22']
Wells to use for training, validation, and testing ['E16' 'E17' 'H18' 'H19' 'E20' 'H23' 'I18' 'I19' 'I22' 'I23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.597057).  Saving model ...
	 Train_Loss: 0.7083 Train_Acc: 61.307 Val_Loss: 0.5971  BEST VAL Loss: 0.5971  Val_Acc: 64.508

Epoch 1: Validation loss decreased (0.597057 --> 0.561452).  Saving model ...
	 Train_Loss: 0.6430 Train_Acc: 68.052 Val_Loss: 0.5615  BEST VAL Loss: 0.5615  Val_Acc: 72.229

Epoch 2: Validation loss decreased (0.561452 --> 0.539602).  Saving model ...
	 Train_Loss: 0.6056 Train_Acc: 71.711 Val_Loss: 0.5396  BEST VAL Loss: 0.5396  Val_Acc: 74.689

Epoch 3: Validation loss decreased (0.539602 --> 0.522849).  Saving model ...
	 Train_Loss: 0.5789 Train_Acc: 73.808 Val_Loss: 0.5228  BEST VAL Loss: 0.5228  Val_Acc: 76.442

Epoch 4: Validation loss decreased (0.522849 --> 0.510390).  Saving model ...
	 Train_Loss: 0.5587 Train_Acc: 75.600 Val_Loss: 0.5104  BEST VAL Loss: 0.5104  Val_Acc: 76.980

Epoch 5: Validation loss decreased (0.510390 --> 0.500710).  Saving model ...
	 Train_Loss: 0.5441 Train_Acc: 75.681 Val_Loss: 0.5007  BEST VAL Loss: 0.5007  Val_Acc: 77.743

Epoch 6: Validation loss decreased (0.500710 --> 0.492934).  Saving model ...
	 Train_Loss: 0.5319 Train_Acc: 76.784 Val_Loss: 0.4929  BEST VAL Loss: 0.4929  Val_Acc: 77.715

Epoch 7: Validation loss decreased (0.492934 --> 0.486797).  Saving model ...
	 Train_Loss: 0.5218 Train_Acc: 77.184 Val_Loss: 0.4868  BEST VAL Loss: 0.4868  Val_Acc: 77.885

Epoch 8: Validation loss decreased (0.486797 --> 0.482868).  Saving model ...
	 Train_Loss: 0.5138 Train_Acc: 77.081 Val_Loss: 0.4829  BEST VAL Loss: 0.4829  Val_Acc: 78.676

Epoch 9: Validation loss decreased (0.482868 --> 0.479581).  Saving model ...
	 Train_Loss: 0.5065 Train_Acc: 77.877 Val_Loss: 0.4796  BEST VAL Loss: 0.4796  Val_Acc: 78.790

Epoch 10: Validation loss decreased (0.479581 --> 0.476931).  Saving model ...
	 Train_Loss: 0.5006 Train_Acc: 77.247 Val_Loss: 0.4769  BEST VAL Loss: 0.4769  Val_Acc: 79.016

Epoch 11: Validation loss decreased (0.476931 --> 0.474315).  Saving model ...
	 Train_Loss: 0.4964 Train_Acc: 77.400 Val_Loss: 0.4743  BEST VAL Loss: 0.4743  Val_Acc: 79.383

Epoch 12: Validation loss decreased (0.474315 --> 0.472061).  Saving model ...
	 Train_Loss: 0.4914 Train_Acc: 78.050 Val_Loss: 0.4721  BEST VAL Loss: 0.4721  Val_Acc: 79.016

Epoch 13: Validation loss decreased (0.472061 --> 0.469702).  Saving model ...
	 Train_Loss: 0.4870 Train_Acc: 77.887 Val_Loss: 0.4697  BEST VAL Loss: 0.4697  Val_Acc: 79.412

Epoch 14: Validation loss decreased (0.469702 --> 0.467025).  Saving model ...
	 Train_Loss: 0.4829 Train_Acc: 78.457 Val_Loss: 0.4670  BEST VAL Loss: 0.4670  Val_Acc: 79.581

Epoch 15: Validation loss decreased (0.467025 --> 0.464392).  Saving model ...
	 Train_Loss: 0.4791 Train_Acc: 78.718 Val_Loss: 0.4644  BEST VAL Loss: 0.4644  Val_Acc: 80.232

Epoch 16: Validation loss decreased (0.464392 --> 0.462157).  Saving model ...
	 Train_Loss: 0.4757 Train_Acc: 78.566 Val_Loss: 0.4622  BEST VAL Loss: 0.4622  Val_Acc: 79.751

Epoch 17: Validation loss decreased (0.462157 --> 0.461140).  Saving model ...
	 Train_Loss: 0.4727 Train_Acc: 78.888 Val_Loss: 0.4611  BEST VAL Loss: 0.4611  Val_Acc: 79.355

Epoch 18: Validation loss decreased (0.461140 --> 0.459984).  Saving model ...
	 Train_Loss: 0.4703 Train_Acc: 77.919 Val_Loss: 0.4600  BEST VAL Loss: 0.4600  Val_Acc: 79.242

Epoch 19: Validation loss decreased (0.459984 --> 0.458527).  Saving model ...
	 Train_Loss: 0.4674 Train_Acc: 79.040 Val_Loss: 0.4585  BEST VAL Loss: 0.4585  Val_Acc: 80.006

Epoch 20: Validation loss decreased (0.458527 --> 0.457489).  Saving model ...
	 Train_Loss: 0.4649 Train_Acc: 79.040 Val_Loss: 0.4575  BEST VAL Loss: 0.4575  Val_Acc: 78.988

Epoch 21: Validation loss decreased (0.457489 --> 0.456718).  Saving model ...
	 Train_Loss: 0.4628 Train_Acc: 78.244 Val_Loss: 0.4567  BEST VAL Loss: 0.4567  Val_Acc: 79.270

Epoch 22: Validation loss decreased (0.456718 --> 0.455322).  Saving model ...
	 Train_Loss: 0.4604 Train_Acc: 78.860 Val_Loss: 0.4553  BEST VAL Loss: 0.4553  Val_Acc: 79.864

Epoch 23: Validation loss decreased (0.455322 --> 0.454463).  Saving model ...
	 Train_Loss: 0.4583 Train_Acc: 79.280 Val_Loss: 0.4545  BEST VAL Loss: 0.4545  Val_Acc: 79.751

Epoch 24: Validation loss decreased (0.454463 --> 0.453625).  Saving model ...
	 Train_Loss: 0.4560 Train_Acc: 79.277 Val_Loss: 0.4536  BEST VAL Loss: 0.4536  Val_Acc: 80.317

Epoch 25: Validation loss decreased (0.453625 --> 0.452735).  Saving model ...
	 Train_Loss: 0.4541 Train_Acc: 78.835 Val_Loss: 0.4527  BEST VAL Loss: 0.4527  Val_Acc: 79.581

Epoch 26: Validation loss decreased (0.452735 --> 0.451886).  Saving model ...
	 Train_Loss: 0.4522 Train_Acc: 78.814 Val_Loss: 0.4519  BEST VAL Loss: 0.4519  Val_Acc: 79.751

Epoch 27: Validation loss decreased (0.451886 --> 0.451746).  Saving model ...
	 Train_Loss: 0.4503 Train_Acc: 79.648 Val_Loss: 0.4517  BEST VAL Loss: 0.4517  Val_Acc: 80.684

Epoch 28: Validation loss decreased (0.451746 --> 0.451015).  Saving model ...
	 Train_Loss: 0.4486 Train_Acc: 79.796 Val_Loss: 0.4510  BEST VAL Loss: 0.4510  Val_Acc: 80.175

Epoch 29: Validation loss decreased (0.451015 --> 0.450877).  Saving model ...
	 Train_Loss: 0.4469 Train_Acc: 79.227 Val_Loss: 0.4509  BEST VAL Loss: 0.4509  Val_Acc: 79.949

Epoch 30: Validation loss decreased (0.450877 --> 0.450554).  Saving model ...
	 Train_Loss: 0.4453 Train_Acc: 79.019 Val_Loss: 0.4506  BEST VAL Loss: 0.4506  Val_Acc: 80.260

Epoch 31: Validation loss decreased (0.450554 --> 0.450148).  Saving model ...
	 Train_Loss: 0.4437 Train_Acc: 79.337 Val_Loss: 0.4501  BEST VAL Loss: 0.4501  Val_Acc: 80.345

Epoch 32: Validation loss decreased (0.450148 --> 0.449970).  Saving model ...
	 Train_Loss: 0.4422 Train_Acc: 79.552 Val_Loss: 0.4500  BEST VAL Loss: 0.4500  Val_Acc: 80.090

Epoch 33: Validation loss decreased (0.449970 --> 0.449943).  Saving model ...
	 Train_Loss: 0.4406 Train_Acc: 80.030 Val_Loss: 0.4499  BEST VAL Loss: 0.4499  Val_Acc: 80.006

Epoch 34: Validation loss decreased (0.449943 --> 0.449793).  Saving model ...
	 Train_Loss: 0.4392 Train_Acc: 79.135 Val_Loss: 0.4498  BEST VAL Loss: 0.4498  Val_Acc: 80.486

Epoch 35: Validation loss decreased (0.449793 --> 0.449379).  Saving model ...
	 Train_Loss: 0.4377 Train_Acc: 80.143 Val_Loss: 0.4494  BEST VAL Loss: 0.4494  Val_Acc: 80.175

Epoch 36: Validation loss decreased (0.449379 --> 0.449009).  Saving model ...
	 Train_Loss: 0.4365 Train_Acc: 79.309 Val_Loss: 0.4490  BEST VAL Loss: 0.4490  Val_Acc: 79.864

Epoch 37: Validation loss decreased (0.449009 --> 0.448618).  Saving model ...
	 Train_Loss: 0.4353 Train_Acc: 79.747 Val_Loss: 0.4486  BEST VAL Loss: 0.4486  Val_Acc: 80.175

Epoch 38: Validation loss decreased (0.448618 --> 0.448325).  Saving model ...
	 Train_Loss: 0.4340 Train_Acc: 80.323 Val_Loss: 0.4483  BEST VAL Loss: 0.4483  Val_Acc: 80.798

Epoch 39: Validation loss decreased (0.448325 --> 0.448039).  Saving model ...
	 Train_Loss: 0.4327 Train_Acc: 79.878 Val_Loss: 0.4480  BEST VAL Loss: 0.4480  Val_Acc: 80.543

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.4314 Train_Acc: 79.924 Val_Loss: 0.4481  BEST VAL Loss: 0.4480  Val_Acc: 80.232

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.4302 Train_Acc: 79.828 Val_Loss: 0.4481  BEST VAL Loss: 0.4480  Val_Acc: 79.864

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.4290 Train_Acc: 80.274 Val_Loss: 0.4482  BEST VAL Loss: 0.4480  Val_Acc: 80.373

Epoch 43: Validation loss decreased (0.448039 --> 0.447800).  Saving model ...
	 Train_Loss: 0.4280 Train_Acc: 79.453 Val_Loss: 0.4478  BEST VAL Loss: 0.4478  Val_Acc: 79.921

Epoch 44: Validation loss decreased (0.447800 --> 0.447659).  Saving model ...
	 Train_Loss: 0.4270 Train_Acc: 80.097 Val_Loss: 0.4477  BEST VAL Loss: 0.4477  Val_Acc: 79.808

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.4258 Train_Acc: 80.337 Val_Loss: 0.4480  BEST VAL Loss: 0.4477  Val_Acc: 80.288

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.4249 Train_Acc: 79.648 Val_Loss: 0.4481  BEST VAL Loss: 0.4477  Val_Acc: 79.921

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.4239 Train_Acc: 80.376 Val_Loss: 0.4480  BEST VAL Loss: 0.4477  Val_Acc: 80.204

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.4229 Train_Acc: 80.323 Val_Loss: 0.4480  BEST VAL Loss: 0.4477  Val_Acc: 79.751

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.4218 Train_Acc: 80.069 Val_Loss: 0.4479  BEST VAL Loss: 0.4477  Val_Acc: 80.713

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.4209 Train_Acc: 80.401 Val_Loss: 0.4480  BEST VAL Loss: 0.4477  Val_Acc: 80.430

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.4198 Train_Acc: 81.005 Val_Loss: 0.4480  BEST VAL Loss: 0.4477  Val_Acc: 80.600

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.4188 Train_Acc: 80.270 Val_Loss: 0.4478  BEST VAL Loss: 0.4477  Val_Acc: 79.779

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.4177 Train_Acc: 80.609 Val_Loss: 0.4481  BEST VAL Loss: 0.4477  Val_Acc: 80.854

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.4167 Train_Acc: 80.479 Val_Loss: 0.4482  BEST VAL Loss: 0.4477  Val_Acc: 80.006

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.4158 Train_Acc: 80.571 Val_Loss: 0.4483  BEST VAL Loss: 0.4477  Val_Acc: 80.147

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.4149 Train_Acc: 79.991 Val_Loss: 0.4484  BEST VAL Loss: 0.4477  Val_Acc: 80.090

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.4141 Train_Acc: 79.909 Val_Loss: 0.4487  BEST VAL Loss: 0.4477  Val_Acc: 79.921

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.4133 Train_Acc: 80.581 Val_Loss: 0.4490  BEST VAL Loss: 0.4477  Val_Acc: 79.836

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.4125 Train_Acc: 79.987 Val_Loss: 0.4494  BEST VAL Loss: 0.4477  Val_Acc: 80.232

Epoch 60: Validation loss did not decrease
Early stopped at epoch : 60
LPS_10.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.86      0.90      0.88     18174
           1       0.81      0.74      0.77     10113

    accuracy                           0.84     28287
   macro avg       0.83      0.82      0.83     28287
weighted avg       0.84      0.84      0.84     28287

LPS_10.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.82      0.87      0.85      2272
           1       0.74      0.67      0.70      1264

    accuracy                           0.80      3536
   macro avg       0.78      0.77      0.77      3536
weighted avg       0.80      0.80      0.80      3536

LPS_10.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.82      0.87      0.84      2272
           1       0.73      0.66      0.69      1265

    accuracy                           0.79      3537
   macro avg       0.78      0.76      0.77      3537
weighted avg       0.79      0.79      0.79      3537

              precision    recall  f1-score   support

           0       0.82      0.87      0.84      2272
           1       0.73      0.66      0.69      1265

    accuracy                           0.79      3537
   macro avg       0.78      0.76      0.77      3537
weighted avg       0.79      0.79      0.79      3537

LPS_10.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.70      0.80      0.75      4182
           1       0.77      0.65      0.71      4168

    accuracy                           0.73      8350
   macro avg       0.73      0.73      0.73      8350
weighted avg       0.73      0.73      0.73      8350

              precision    recall  f1-score   support

           0       0.70      0.80      0.75      4182
           1       0.77      0.65      0.71      4168

    accuracy                           0.73      8350
   macro avg       0.73      0.73      0.73      8350
weighted avg       0.73      0.73      0.73      8350

completed
