[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '5549853f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '66ecf6a3'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '7ab39b36'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '0567c3b0'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_1.000_DMSO_0.025 treatment_name: DMSO_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_1.000_DMSO_0.025
TREATMENT_NAME: DMSO_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'LPS_1.000_DMSO_0.025']
The dimensions of the data are: (52101, 1276)
Number of total missing values across all columns: 104202
Data Subset Is Off
Wells held out for testing: ['D20' 'I14']
Wells to use for training, validation, and testing ['B14' 'C14' 'B15' 'C15' 'D16' 'D17' 'D21' 'J14' 'I15' 'J15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.530145).  Saving model ...
	 Train_Loss: 0.5989 Train_Acc: 68.349 Val_Loss: 0.5301  BEST VAL Loss: 0.5301  Val_Acc: 72.622

Epoch 1: Validation loss decreased (0.530145 --> 0.519400).  Saving model ...
	 Train_Loss: 0.5580 Train_Acc: 74.397 Val_Loss: 0.5194  BEST VAL Loss: 0.5194  Val_Acc: 74.872

Epoch 2: Validation loss decreased (0.519400 --> 0.512625).  Saving model ...
	 Train_Loss: 0.5379 Train_Acc: 75.618 Val_Loss: 0.5126  BEST VAL Loss: 0.5126  Val_Acc: 76.497

Epoch 3: Validation loss decreased (0.512625 --> 0.506085).  Saving model ...
	 Train_Loss: 0.5247 Train_Acc: 76.210 Val_Loss: 0.5061  BEST VAL Loss: 0.5061  Val_Acc: 76.821

Epoch 4: Validation loss decreased (0.506085 --> 0.501853).  Saving model ...
	 Train_Loss: 0.5150 Train_Acc: 76.627 Val_Loss: 0.5019  BEST VAL Loss: 0.5019  Val_Acc: 76.659

Epoch 5: Validation loss decreased (0.501853 --> 0.498211).  Saving model ...
	 Train_Loss: 0.5069 Train_Acc: 77.260 Val_Loss: 0.4982  BEST VAL Loss: 0.4982  Val_Acc: 77.216

Epoch 6: Validation loss decreased (0.498211 --> 0.495162).  Saving model ...
	 Train_Loss: 0.5003 Train_Acc: 77.700 Val_Loss: 0.4952  BEST VAL Loss: 0.4952  Val_Acc: 76.961

Epoch 7: Validation loss decreased (0.495162 --> 0.493130).  Saving model ...
	 Train_Loss: 0.4946 Train_Acc: 78.048 Val_Loss: 0.4931  BEST VAL Loss: 0.4931  Val_Acc: 77.564

Epoch 8: Validation loss decreased (0.493130 --> 0.491646).  Saving model ...
	 Train_Loss: 0.4894 Train_Acc: 78.655 Val_Loss: 0.4916  BEST VAL Loss: 0.4916  Val_Acc: 77.169

Epoch 9: Validation loss decreased (0.491646 --> 0.490434).  Saving model ...
	 Train_Loss: 0.4848 Train_Acc: 78.629 Val_Loss: 0.4904  BEST VAL Loss: 0.4904  Val_Acc: 77.146

Epoch 10: Validation loss decreased (0.490434 --> 0.488915).  Saving model ...
	 Train_Loss: 0.4807 Train_Acc: 78.861 Val_Loss: 0.4889  BEST VAL Loss: 0.4889  Val_Acc: 77.332

Epoch 11: Validation loss decreased (0.488915 --> 0.487549).  Saving model ...
	 Train_Loss: 0.4768 Train_Acc: 79.368 Val_Loss: 0.4875  BEST VAL Loss: 0.4875  Val_Acc: 77.425

Epoch 12: Validation loss decreased (0.487549 --> 0.486349).  Saving model ...
	 Train_Loss: 0.4729 Train_Acc: 79.435 Val_Loss: 0.4863  BEST VAL Loss: 0.4863  Val_Acc: 77.425

Epoch 13: Validation loss decreased (0.486349 --> 0.485203).  Saving model ...
	 Train_Loss: 0.4694 Train_Acc: 79.638 Val_Loss: 0.4852  BEST VAL Loss: 0.4852  Val_Acc: 77.773

Epoch 14: Validation loss decreased (0.485203 --> 0.484493).  Saving model ...
	 Train_Loss: 0.4663 Train_Acc: 79.934 Val_Loss: 0.4845  BEST VAL Loss: 0.4845  Val_Acc: 77.309

Epoch 15: Validation loss decreased (0.484493 --> 0.483634).  Saving model ...
	 Train_Loss: 0.4632 Train_Acc: 80.183 Val_Loss: 0.4836  BEST VAL Loss: 0.4836  Val_Acc: 77.517

Epoch 16: Validation loss decreased (0.483634 --> 0.483349).  Saving model ...
	 Train_Loss: 0.4604 Train_Acc: 80.427 Val_Loss: 0.4833  BEST VAL Loss: 0.4833  Val_Acc: 77.564

Epoch 17: Validation loss decreased (0.483349 --> 0.482869).  Saving model ...
	 Train_Loss: 0.4576 Train_Acc: 80.639 Val_Loss: 0.4829  BEST VAL Loss: 0.4829  Val_Acc: 78.213

Epoch 18: Validation loss decreased (0.482869 --> 0.482711).  Saving model ...
	 Train_Loss: 0.4549 Train_Acc: 80.891 Val_Loss: 0.4827  BEST VAL Loss: 0.4827  Val_Acc: 77.494

Epoch 19: Validation loss decreased (0.482711 --> 0.482335).  Saving model ...
	 Train_Loss: 0.4525 Train_Acc: 80.952 Val_Loss: 0.4823  BEST VAL Loss: 0.4823  Val_Acc: 77.262

Epoch 20: Validation loss decreased (0.482335 --> 0.482074).  Saving model ...
	 Train_Loss: 0.4501 Train_Acc: 80.990 Val_Loss: 0.4821  BEST VAL Loss: 0.4821  Val_Acc: 77.842

Epoch 21: Validation loss decreased (0.482074 --> 0.481863).  Saving model ...
	 Train_Loss: 0.4477 Train_Acc: 81.291 Val_Loss: 0.4819  BEST VAL Loss: 0.4819  Val_Acc: 78.097

Epoch 22: Validation loss decreased (0.481863 --> 0.481402).  Saving model ...
	 Train_Loss: 0.4455 Train_Acc: 81.341 Val_Loss: 0.4814  BEST VAL Loss: 0.4814  Val_Acc: 77.889

Epoch 23: Validation loss decreased (0.481402 --> 0.481108).  Saving model ...
	 Train_Loss: 0.4432 Train_Acc: 81.590 Val_Loss: 0.4811  BEST VAL Loss: 0.4811  Val_Acc: 77.796

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.4410 Train_Acc: 81.660 Val_Loss: 0.4811  BEST VAL Loss: 0.4811  Val_Acc: 77.935

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.4388 Train_Acc: 82.048 Val_Loss: 0.4811  BEST VAL Loss: 0.4811  Val_Acc: 77.796

Epoch 26: Validation loss decreased (0.481108 --> 0.481026).  Saving model ...
	 Train_Loss: 0.4368 Train_Acc: 82.315 Val_Loss: 0.4810  BEST VAL Loss: 0.4810  Val_Acc: 77.703

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.4348 Train_Acc: 82.202 Val_Loss: 0.4814  BEST VAL Loss: 0.4810  Val_Acc: 77.332

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.4328 Train_Acc: 82.547 Val_Loss: 0.4815  BEST VAL Loss: 0.4810  Val_Acc: 77.517

Epoch 29: Validation loss did not decrease
	 Train_Loss: 0.4310 Train_Acc: 82.272 Val_Loss: 0.4817  BEST VAL Loss: 0.4810  Val_Acc: 77.517

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.4291 Train_Acc: 82.515 Val_Loss: 0.4819  BEST VAL Loss: 0.4810  Val_Acc: 77.239

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.4272 Train_Acc: 82.924 Val_Loss: 0.4821  BEST VAL Loss: 0.4810  Val_Acc: 77.100

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.4255 Train_Acc: 82.948 Val_Loss: 0.4823  BEST VAL Loss: 0.4810  Val_Acc: 76.937

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.4237 Train_Acc: 82.817 Val_Loss: 0.4827  BEST VAL Loss: 0.4810  Val_Acc: 77.309

Epoch 34: Validation loss did not decrease
	 Train_Loss: 0.4220 Train_Acc: 83.156 Val_Loss: 0.4831  BEST VAL Loss: 0.4810  Val_Acc: 76.659

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.4203 Train_Acc: 83.191 Val_Loss: 0.4834  BEST VAL Loss: 0.4810  Val_Acc: 76.891

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.4187 Train_Acc: 83.362 Val_Loss: 0.4839  BEST VAL Loss: 0.4810  Val_Acc: 77.123

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.4170 Train_Acc: 83.275 Val_Loss: 0.4844  BEST VAL Loss: 0.4810  Val_Acc: 76.937

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.4154 Train_Acc: 83.560 Val_Loss: 0.4849  BEST VAL Loss: 0.4810  Val_Acc: 76.868

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.4139 Train_Acc: 83.661 Val_Loss: 0.4856  BEST VAL Loss: 0.4810  Val_Acc: 77.146

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.4123 Train_Acc: 83.844 Val_Loss: 0.4860  BEST VAL Loss: 0.4810  Val_Acc: 77.262

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.4108 Train_Acc: 83.824 Val_Loss: 0.4866  BEST VAL Loss: 0.4810  Val_Acc: 77.053

Epoch 42: Validation loss did not decrease
Early stopped at epoch : 42
LPS_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.88      0.92      0.90     24644
           1       0.78      0.68      0.73      9832

    accuracy                           0.85     34476
   macro avg       0.83      0.80      0.81     34476
weighted avg       0.85      0.85      0.85     34476

LPS_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.82      0.87      0.85      3081
           1       0.63      0.53      0.58      1229

    accuracy                           0.78      4310
   macro avg       0.73      0.70      0.71      4310
weighted avg       0.77      0.78      0.77      4310

LPS_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.82      0.88      0.85      3081
           1       0.63      0.52      0.57      1229

    accuracy                           0.78      4310
   macro avg       0.73      0.70      0.71      4310
weighted avg       0.77      0.78      0.77      4310

              precision    recall  f1-score   support

           0       0.82      0.88      0.85      3081
           1       0.63      0.52      0.57      1229

    accuracy                           0.78      4310
   macro avg       0.73      0.70      0.71      4310
weighted avg       0.77      0.78      0.77      4310

LPS_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.63      0.74      0.68      4837
           1       0.62      0.49      0.55      4168

    accuracy                           0.63      9005
   macro avg       0.62      0.62      0.61      9005
weighted avg       0.62      0.63      0.62      9005

              precision    recall  f1-score   support

           0       0.63      0.74      0.68      4837
           1       0.62      0.49      0.55      4168

    accuracy                           0.63      9005
   macro avg       0.62      0.62      0.61      9005
weighted avg       0.62      0.63      0.62      9005

completed
