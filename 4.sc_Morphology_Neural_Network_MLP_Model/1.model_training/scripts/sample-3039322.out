[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '8bacbc3b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'ef3e9db9'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'a5081674'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'd0c3629d'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_0.010_DMSO_0.025 treatment_name: H2O2_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_0.010_DMSO_0.025
TREATMENT_NAME: H2O2_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (383616, 1270)
Number of total missing values across all columns: 767232
Data Subset Is Off
Wells held out for testing: ['B09' 'I10']
Wells to use for training, validation, and testing ['B02' 'B03' 'B08' 'H04' 'I04' 'H05' 'I05' 'H10' 'H11' 'I11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.369875).  Saving model ...
	 Train_Loss: 0.4762 Train_Acc: 76.696 Val_Loss: 0.3699  BEST VAL Loss: 0.3699  Val_Acc: 83.434

Epoch 1: Validation loss decreased (0.369875 --> 0.351516).  Saving model ...
	 Train_Loss: 0.4305 Train_Acc: 82.240 Val_Loss: 0.3515  BEST VAL Loss: 0.3515  Val_Acc: 85.188

Epoch 2: Validation loss decreased (0.351516 --> 0.340106).  Saving model ...
	 Train_Loss: 0.4075 Train_Acc: 83.573 Val_Loss: 0.3401  BEST VAL Loss: 0.3401  Val_Acc: 86.083

Epoch 3: Validation loss decreased (0.340106 --> 0.335359).  Saving model ...
	 Train_Loss: 0.3926 Train_Acc: 84.219 Val_Loss: 0.3354  BEST VAL Loss: 0.3354  Val_Acc: 85.694

Epoch 4: Validation loss decreased (0.335359 --> 0.329173).  Saving model ...
	 Train_Loss: 0.3823 Train_Acc: 84.565 Val_Loss: 0.3292  BEST VAL Loss: 0.3292  Val_Acc: 86.757

Epoch 5: Validation loss decreased (0.329173 --> 0.325005).  Saving model ...
	 Train_Loss: 0.3743 Train_Acc: 84.994 Val_Loss: 0.3250  BEST VAL Loss: 0.3250  Val_Acc: 86.779

Epoch 6: Validation loss decreased (0.325005 --> 0.320553).  Saving model ...
	 Train_Loss: 0.3681 Train_Acc: 85.174 Val_Loss: 0.3206  BEST VAL Loss: 0.3206  Val_Acc: 87.344

Epoch 7: Validation loss decreased (0.320553 --> 0.316574).  Saving model ...
	 Train_Loss: 0.3628 Train_Acc: 85.424 Val_Loss: 0.3166  BEST VAL Loss: 0.3166  Val_Acc: 87.573

Epoch 8: Validation loss decreased (0.316574 --> 0.313654).  Saving model ...
	 Train_Loss: 0.3584 Train_Acc: 85.564 Val_Loss: 0.3137  BEST VAL Loss: 0.3137  Val_Acc: 87.511

Epoch 9: Validation loss decreased (0.313654 --> 0.310590).  Saving model ...
	 Train_Loss: 0.3545 Train_Acc: 85.673 Val_Loss: 0.3106  BEST VAL Loss: 0.3106  Val_Acc: 87.771

Epoch 10: Validation loss decreased (0.310590 --> 0.307537).  Saving model ...
	 Train_Loss: 0.3512 Train_Acc: 85.760 Val_Loss: 0.3075  BEST VAL Loss: 0.3075  Val_Acc: 88.013

Epoch 11: Validation loss decreased (0.307537 --> 0.305453).  Saving model ...
	 Train_Loss: 0.3482 Train_Acc: 85.941 Val_Loss: 0.3055  BEST VAL Loss: 0.3055  Val_Acc: 87.862

Epoch 12: Validation loss decreased (0.305453 --> 0.303206).  Saving model ...
	 Train_Loss: 0.3455 Train_Acc: 86.039 Val_Loss: 0.3032  BEST VAL Loss: 0.3032  Val_Acc: 88.163

Epoch 13: Validation loss decreased (0.303206 --> 0.301354).  Saving model ...
	 Train_Loss: 0.3430 Train_Acc: 86.086 Val_Loss: 0.3014  BEST VAL Loss: 0.3014  Val_Acc: 88.242

Epoch 14: Validation loss decreased (0.301354 --> 0.299606).  Saving model ...
	 Train_Loss: 0.3409 Train_Acc: 86.092 Val_Loss: 0.2996  BEST VAL Loss: 0.2996  Val_Acc: 88.283

Epoch 15: Validation loss decreased (0.299606 --> 0.298015).  Saving model ...
	 Train_Loss: 0.3388 Train_Acc: 86.267 Val_Loss: 0.2980  BEST VAL Loss: 0.2980  Val_Acc: 88.261

Epoch 16: Validation loss decreased (0.298015 --> 0.297016).  Saving model ...
	 Train_Loss: 0.3370 Train_Acc: 86.334 Val_Loss: 0.2970  BEST VAL Loss: 0.2970  Val_Acc: 87.856

Epoch 17: Validation loss decreased (0.297016 --> 0.295424).  Saving model ...
	 Train_Loss: 0.3353 Train_Acc: 86.311 Val_Loss: 0.2954  BEST VAL Loss: 0.2954  Val_Acc: 88.587

Epoch 18: Validation loss decreased (0.295424 --> 0.294222).  Saving model ...
	 Train_Loss: 0.3337 Train_Acc: 86.447 Val_Loss: 0.2942  BEST VAL Loss: 0.2942  Val_Acc: 88.330

Epoch 19: Validation loss decreased (0.294222 --> 0.292899).  Saving model ...
	 Train_Loss: 0.3323 Train_Acc: 86.492 Val_Loss: 0.2929  BEST VAL Loss: 0.2929  Val_Acc: 88.603

Epoch 20: Validation loss decreased (0.292899 --> 0.291866).  Saving model ...
	 Train_Loss: 0.3309 Train_Acc: 86.452 Val_Loss: 0.2919  BEST VAL Loss: 0.2919  Val_Acc: 88.606

Epoch 21: Validation loss decreased (0.291866 --> 0.290908).  Saving model ...
	 Train_Loss: 0.3296 Train_Acc: 86.587 Val_Loss: 0.2909  BEST VAL Loss: 0.2909  Val_Acc: 88.433

Epoch 22: Validation loss decreased (0.290908 --> 0.290075).  Saving model ...
	 Train_Loss: 0.3283 Train_Acc: 86.634 Val_Loss: 0.2901  BEST VAL Loss: 0.2901  Val_Acc: 88.289

Epoch 23: Validation loss decreased (0.290075 --> 0.289264).  Saving model ...
	 Train_Loss: 0.3272 Train_Acc: 86.680 Val_Loss: 0.2893  BEST VAL Loss: 0.2893  Val_Acc: 88.477

Epoch 24: Validation loss decreased (0.289264 --> 0.288474).  Saving model ...
	 Train_Loss: 0.3261 Train_Acc: 86.578 Val_Loss: 0.2885  BEST VAL Loss: 0.2885  Val_Acc: 88.568

Epoch 25: Validation loss decreased (0.288474 --> 0.287493).  Saving model ...
	 Train_Loss: 0.3250 Train_Acc: 86.777 Val_Loss: 0.2875  BEST VAL Loss: 0.2875  Val_Acc: 88.819

Epoch 26: Validation loss decreased (0.287493 --> 0.286931).  Saving model ...
	 Train_Loss: 0.3240 Train_Acc: 86.760 Val_Loss: 0.2869  BEST VAL Loss: 0.2869  Val_Acc: 88.471

Epoch 27: Validation loss decreased (0.286931 --> 0.286199).  Saving model ...
	 Train_Loss: 0.3231 Train_Acc: 86.707 Val_Loss: 0.2862  BEST VAL Loss: 0.2862  Val_Acc: 88.590

Epoch 28: Validation loss decreased (0.286199 --> 0.285480).  Saving model ...
	 Train_Loss: 0.3222 Train_Acc: 86.841 Val_Loss: 0.2855  BEST VAL Loss: 0.2855  Val_Acc: 88.725

Epoch 29: Validation loss decreased (0.285480 --> 0.284687).  Saving model ...
	 Train_Loss: 0.3213 Train_Acc: 86.802 Val_Loss: 0.2847  BEST VAL Loss: 0.2847  Val_Acc: 88.760

Epoch 30: Validation loss decreased (0.284687 --> 0.284002).  Saving model ...
	 Train_Loss: 0.3205 Train_Acc: 86.869 Val_Loss: 0.2840  BEST VAL Loss: 0.2840  Val_Acc: 88.882

Epoch 31: Validation loss decreased (0.284002 --> 0.283510).  Saving model ...
	 Train_Loss: 0.3198 Train_Acc: 86.834 Val_Loss: 0.2835  BEST VAL Loss: 0.2835  Val_Acc: 88.568

Epoch 32: Validation loss decreased (0.283510 --> 0.282830).  Saving model ...
	 Train_Loss: 0.3190 Train_Acc: 86.868 Val_Loss: 0.2828  BEST VAL Loss: 0.2828  Val_Acc: 88.803

Epoch 33: Validation loss decreased (0.282830 --> 0.282189).  Saving model ...
	 Train_Loss: 0.3183 Train_Acc: 86.971 Val_Loss: 0.2822  BEST VAL Loss: 0.2822  Val_Acc: 88.813

Epoch 34: Validation loss decreased (0.282189 --> 0.281736).  Saving model ...
	 Train_Loss: 0.3176 Train_Acc: 86.955 Val_Loss: 0.2817  BEST VAL Loss: 0.2817  Val_Acc: 88.593

Epoch 35: Validation loss decreased (0.281736 --> 0.281229).  Saving model ...
	 Train_Loss: 0.3169 Train_Acc: 86.953 Val_Loss: 0.2812  BEST VAL Loss: 0.2812  Val_Acc: 88.803

Epoch 36: Validation loss decreased (0.281229 --> 0.280679).  Saving model ...
	 Train_Loss: 0.3163 Train_Acc: 87.029 Val_Loss: 0.2807  BEST VAL Loss: 0.2807  Val_Acc: 89.051

Epoch 37: Validation loss decreased (0.280679 --> 0.280157).  Saving model ...
	 Train_Loss: 0.3156 Train_Acc: 87.010 Val_Loss: 0.2802  BEST VAL Loss: 0.2802  Val_Acc: 88.995

Epoch 38: Validation loss decreased (0.280157 --> 0.279625).  Saving model ...
	 Train_Loss: 0.3150 Train_Acc: 86.953 Val_Loss: 0.2796  BEST VAL Loss: 0.2796  Val_Acc: 88.832

Epoch 39: Validation loss decreased (0.279625 --> 0.279274).  Saving model ...
	 Train_Loss: 0.3144 Train_Acc: 87.078 Val_Loss: 0.2793  BEST VAL Loss: 0.2793  Val_Acc: 88.672

Epoch 40: Validation loss decreased (0.279274 --> 0.278682).  Saving model ...
	 Train_Loss: 0.3139 Train_Acc: 87.029 Val_Loss: 0.2787  BEST VAL Loss: 0.2787  Val_Acc: 89.265

Epoch 41: Validation loss decreased (0.278682 --> 0.278169).  Saving model ...
	 Train_Loss: 0.3133 Train_Acc: 87.069 Val_Loss: 0.2782  BEST VAL Loss: 0.2782  Val_Acc: 88.888

Epoch 42: Validation loss decreased (0.278169 --> 0.277813).  Saving model ...
	 Train_Loss: 0.3128 Train_Acc: 87.076 Val_Loss: 0.2778  BEST VAL Loss: 0.2778  Val_Acc: 88.766

Epoch 43: Validation loss decreased (0.277813 --> 0.277419).  Saving model ...
	 Train_Loss: 0.3123 Train_Acc: 87.160 Val_Loss: 0.2774  BEST VAL Loss: 0.2774  Val_Acc: 88.851

Epoch 44: Validation loss decreased (0.277419 --> 0.277042).  Saving model ...
	 Train_Loss: 0.3118 Train_Acc: 87.070 Val_Loss: 0.2770  BEST VAL Loss: 0.2770  Val_Acc: 88.982

Epoch 45: Validation loss decreased (0.277042 --> 0.276640).  Saving model ...
	 Train_Loss: 0.3113 Train_Acc: 87.156 Val_Loss: 0.2766  BEST VAL Loss: 0.2766  Val_Acc: 89.098

Epoch 46: Validation loss decreased (0.276640 --> 0.276201).  Saving model ...
	 Train_Loss: 0.3108 Train_Acc: 87.163 Val_Loss: 0.2762  BEST VAL Loss: 0.2762  Val_Acc: 89.089

Epoch 47: Validation loss decreased (0.276201 --> 0.275922).  Saving model ...
	 Train_Loss: 0.3104 Train_Acc: 87.130 Val_Loss: 0.2759  BEST VAL Loss: 0.2759  Val_Acc: 88.851

Epoch 48: Validation loss decreased (0.275922 --> 0.275528).  Saving model ...
	 Train_Loss: 0.3099 Train_Acc: 87.217 Val_Loss: 0.2755  BEST VAL Loss: 0.2755  Val_Acc: 89.127

Epoch 49: Validation loss decreased (0.275528 --> 0.275104).  Saving model ...
	 Train_Loss: 0.3095 Train_Acc: 87.258 Val_Loss: 0.2751  BEST VAL Loss: 0.2751  Val_Acc: 89.127

Epoch 50: Validation loss decreased (0.275104 --> 0.274754).  Saving model ...
	 Train_Loss: 0.3091 Train_Acc: 87.251 Val_Loss: 0.2748  BEST VAL Loss: 0.2748  Val_Acc: 89.202

Epoch 51: Validation loss decreased (0.274754 --> 0.274406).  Saving model ...
	 Train_Loss: 0.3087 Train_Acc: 87.110 Val_Loss: 0.2744  BEST VAL Loss: 0.2744  Val_Acc: 89.133

Epoch 52: Validation loss decreased (0.274406 --> 0.274032).  Saving model ...
	 Train_Loss: 0.3083 Train_Acc: 87.291 Val_Loss: 0.2740  BEST VAL Loss: 0.2740  Val_Acc: 89.136

Epoch 53: Validation loss decreased (0.274032 --> 0.273813).  Saving model ...
	 Train_Loss: 0.3079 Train_Acc: 87.251 Val_Loss: 0.2738  BEST VAL Loss: 0.2738  Val_Acc: 88.888

Epoch 54: Validation loss decreased (0.273813 --> 0.273465).  Saving model ...
	 Train_Loss: 0.3075 Train_Acc: 87.282 Val_Loss: 0.2735  BEST VAL Loss: 0.2735  Val_Acc: 89.189

Epoch 55: Validation loss decreased (0.273465 --> 0.273192).  Saving model ...
	 Train_Loss: 0.3071 Train_Acc: 87.302 Val_Loss: 0.2732  BEST VAL Loss: 0.2732  Val_Acc: 89.124

Epoch 56: Validation loss decreased (0.273192 --> 0.272864).  Saving model ...
	 Train_Loss: 0.3067 Train_Acc: 87.357 Val_Loss: 0.2729  BEST VAL Loss: 0.2729  Val_Acc: 89.384

Epoch 57: Validation loss decreased (0.272864 --> 0.272554).  Saving model ...
	 Train_Loss: 0.3063 Train_Acc: 87.334 Val_Loss: 0.2726  BEST VAL Loss: 0.2726  Val_Acc: 89.240

Epoch 58: Validation loss decreased (0.272554 --> 0.272362).  Saving model ...
	 Train_Loss: 0.3059 Train_Acc: 87.329 Val_Loss: 0.2724  BEST VAL Loss: 0.2724  Val_Acc: 89.130

Epoch 59: Validation loss decreased (0.272362 --> 0.272079).  Saving model ...
	 Train_Loss: 0.3056 Train_Acc: 87.361 Val_Loss: 0.2721  BEST VAL Loss: 0.2721  Val_Acc: 89.164

Epoch 60: Validation loss decreased (0.272079 --> 0.271895).  Saving model ...
	 Train_Loss: 0.3052 Train_Acc: 87.304 Val_Loss: 0.2719  BEST VAL Loss: 0.2719  Val_Acc: 88.901

Epoch 61: Validation loss decreased (0.271895 --> 0.271568).  Saving model ...
	 Train_Loss: 0.3049 Train_Acc: 87.344 Val_Loss: 0.2716  BEST VAL Loss: 0.2716  Val_Acc: 89.215

Epoch 62: Validation loss decreased (0.271568 --> 0.271342).  Saving model ...
	 Train_Loss: 0.3046 Train_Acc: 87.369 Val_Loss: 0.2713  BEST VAL Loss: 0.2713  Val_Acc: 89.114

Epoch 63: Validation loss decreased (0.271342 --> 0.271094).  Saving model ...
	 Train_Loss: 0.3043 Train_Acc: 87.353 Val_Loss: 0.2711  BEST VAL Loss: 0.2711  Val_Acc: 89.368

Epoch 64: Validation loss decreased (0.271094 --> 0.270804).  Saving model ...
	 Train_Loss: 0.3040 Train_Acc: 87.346 Val_Loss: 0.2708  BEST VAL Loss: 0.2708  Val_Acc: 89.365

Epoch 65: Validation loss decreased (0.270804 --> 0.270617).  Saving model ...
	 Train_Loss: 0.3037 Train_Acc: 87.331 Val_Loss: 0.2706  BEST VAL Loss: 0.2706  Val_Acc: 89.014

Epoch 66: Validation loss decreased (0.270617 --> 0.270388).  Saving model ...
	 Train_Loss: 0.3034 Train_Acc: 87.404 Val_Loss: 0.2704  BEST VAL Loss: 0.2704  Val_Acc: 89.343

Epoch 67: Validation loss decreased (0.270388 --> 0.270131).  Saving model ...
	 Train_Loss: 0.3031 Train_Acc: 87.419 Val_Loss: 0.2701  BEST VAL Loss: 0.2701  Val_Acc: 89.356

Epoch 68: Validation loss decreased (0.270131 --> 0.269911).  Saving model ...
	 Train_Loss: 0.3028 Train_Acc: 87.391 Val_Loss: 0.2699  BEST VAL Loss: 0.2699  Val_Acc: 89.183

Epoch 69: Validation loss decreased (0.269911 --> 0.269721).  Saving model ...
	 Train_Loss: 0.3025 Train_Acc: 87.379 Val_Loss: 0.2697  BEST VAL Loss: 0.2697  Val_Acc: 89.171

Epoch 70: Validation loss decreased (0.269721 --> 0.269520).  Saving model ...
	 Train_Loss: 0.3022 Train_Acc: 87.497 Val_Loss: 0.2695  BEST VAL Loss: 0.2695  Val_Acc: 89.255

Epoch 71: Validation loss decreased (0.269520 --> 0.269299).  Saving model ...
	 Train_Loss: 0.3019 Train_Acc: 87.490 Val_Loss: 0.2693  BEST VAL Loss: 0.2693  Val_Acc: 89.174

Epoch 72: Validation loss decreased (0.269299 --> 0.269064).  Saving model ...
	 Train_Loss: 0.3017 Train_Acc: 87.457 Val_Loss: 0.2691  BEST VAL Loss: 0.2691  Val_Acc: 89.299

Epoch 73: Validation loss decreased (0.269064 --> 0.268811).  Saving model ...
	 Train_Loss: 0.3014 Train_Acc: 87.519 Val_Loss: 0.2688  BEST VAL Loss: 0.2688  Val_Acc: 89.415

Epoch 74: Validation loss decreased (0.268811 --> 0.268641).  Saving model ...
	 Train_Loss: 0.3012 Train_Acc: 87.469 Val_Loss: 0.2686  BEST VAL Loss: 0.2686  Val_Acc: 89.193

Epoch 75: Validation loss decreased (0.268641 --> 0.268382).  Saving model ...
	 Train_Loss: 0.3009 Train_Acc: 87.469 Val_Loss: 0.2684  BEST VAL Loss: 0.2684  Val_Acc: 89.375

Epoch 76: Validation loss decreased (0.268382 --> 0.268157).  Saving model ...
	 Train_Loss: 0.3006 Train_Acc: 87.494 Val_Loss: 0.2682  BEST VAL Loss: 0.2682  Val_Acc: 89.302

Epoch 77: Validation loss decreased (0.268157 --> 0.267925).  Saving model ...
	 Train_Loss: 0.3004 Train_Acc: 87.502 Val_Loss: 0.2679  BEST VAL Loss: 0.2679  Val_Acc: 89.353

Epoch 78: Validation loss decreased (0.267925 --> 0.267705).  Saving model ...
	 Train_Loss: 0.3001 Train_Acc: 87.534 Val_Loss: 0.2677  BEST VAL Loss: 0.2677  Val_Acc: 89.284

Epoch 79: Validation loss decreased (0.267705 --> 0.267488).  Saving model ...
	 Train_Loss: 0.2999 Train_Acc: 87.500 Val_Loss: 0.2675  BEST VAL Loss: 0.2675  Val_Acc: 89.359

Epoch 80: Validation loss decreased (0.267488 --> 0.267300).  Saving model ...
	 Train_Loss: 0.2997 Train_Acc: 87.524 Val_Loss: 0.2673  BEST VAL Loss: 0.2673  Val_Acc: 89.221

Epoch 81: Validation loss decreased (0.267300 --> 0.267086).  Saving model ...
	 Train_Loss: 0.2994 Train_Acc: 87.465 Val_Loss: 0.2671  BEST VAL Loss: 0.2671  Val_Acc: 89.585

Epoch 82: Validation loss decreased (0.267086 --> 0.266883).  Saving model ...
	 Train_Loss: 0.2992 Train_Acc: 87.472 Val_Loss: 0.2669  BEST VAL Loss: 0.2669  Val_Acc: 89.406

Epoch 83: Validation loss decreased (0.266883 --> 0.266686).  Saving model ...
	 Train_Loss: 0.2990 Train_Acc: 87.516 Val_Loss: 0.2667  BEST VAL Loss: 0.2667  Val_Acc: 89.356

Epoch 84: Validation loss decreased (0.266686 --> 0.266504).  Saving model ...
	 Train_Loss: 0.2988 Train_Acc: 87.502 Val_Loss: 0.2665  BEST VAL Loss: 0.2665  Val_Acc: 89.346

Epoch 85: Validation loss decreased (0.266504 --> 0.266317).  Saving model ...
	 Train_Loss: 0.2986 Train_Acc: 87.516 Val_Loss: 0.2663  BEST VAL Loss: 0.2663  Val_Acc: 89.246

Epoch 86: Validation loss decreased (0.266317 --> 0.266126).  Saving model ...
	 Train_Loss: 0.2984 Train_Acc: 87.582 Val_Loss: 0.2661  BEST VAL Loss: 0.2661  Val_Acc: 89.331

Epoch 87: Validation loss decreased (0.266126 --> 0.265974).  Saving model ...
	 Train_Loss: 0.2982 Train_Acc: 87.542 Val_Loss: 0.2660  BEST VAL Loss: 0.2660  Val_Acc: 89.249

Epoch 88: Validation loss decreased (0.265974 --> 0.265835).  Saving model ...
	 Train_Loss: 0.2980 Train_Acc: 87.414 Val_Loss: 0.2658  BEST VAL Loss: 0.2658  Val_Acc: 89.105

Epoch 89: Validation loss decreased (0.265835 --> 0.265650).  Saving model ...
	 Train_Loss: 0.2977 Train_Acc: 87.650 Val_Loss: 0.2656  BEST VAL Loss: 0.2656  Val_Acc: 89.440

Epoch 90: Validation loss decreased (0.265650 --> 0.265475).  Saving model ...
	 Train_Loss: 0.2975 Train_Acc: 87.654 Val_Loss: 0.2655  BEST VAL Loss: 0.2655  Val_Acc: 89.513

Epoch 91: Validation loss decreased (0.265475 --> 0.265315).  Saving model ...
	 Train_Loss: 0.2973 Train_Acc: 87.606 Val_Loss: 0.2653  BEST VAL Loss: 0.2653  Val_Acc: 89.365

Epoch 92: Validation loss decreased (0.265315 --> 0.265158).  Saving model ...
	 Train_Loss: 0.2971 Train_Acc: 87.641 Val_Loss: 0.2652  BEST VAL Loss: 0.2652  Val_Acc: 89.299

Epoch 93: Validation loss decreased (0.265158 --> 0.264979).  Saving model ...
	 Train_Loss: 0.2970 Train_Acc: 87.582 Val_Loss: 0.2650  BEST VAL Loss: 0.2650  Val_Acc: 89.557

Epoch 94: Validation loss decreased (0.264979 --> 0.264817).  Saving model ...
	 Train_Loss: 0.2968 Train_Acc: 87.529 Val_Loss: 0.2648  BEST VAL Loss: 0.2648  Val_Acc: 89.397

Epoch 95: Validation loss decreased (0.264817 --> 0.264661).  Saving model ...
	 Train_Loss: 0.2966 Train_Acc: 87.623 Val_Loss: 0.2647  BEST VAL Loss: 0.2647  Val_Acc: 89.381

Epoch 96: Validation loss decreased (0.264661 --> 0.264505).  Saving model ...
	 Train_Loss: 0.2964 Train_Acc: 87.597 Val_Loss: 0.2645  BEST VAL Loss: 0.2645  Val_Acc: 89.400

Epoch 97: Validation loss decreased (0.264505 --> 0.264380).  Saving model ...
	 Train_Loss: 0.2962 Train_Acc: 87.676 Val_Loss: 0.2644  BEST VAL Loss: 0.2644  Val_Acc: 89.293

Epoch 98: Validation loss decreased (0.264380 --> 0.264232).  Saving model ...
	 Train_Loss: 0.2960 Train_Acc: 87.601 Val_Loss: 0.2642  BEST VAL Loss: 0.2642  Val_Acc: 89.503

Epoch 99: Validation loss decreased (0.264232 --> 0.264080).  Saving model ...
	 Train_Loss: 0.2959 Train_Acc: 87.637 Val_Loss: 0.2641  BEST VAL Loss: 0.2641  Val_Acc: 89.375

LPS_0.010_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.67      0.69      0.68    169561
           1       0.34      0.31      0.32     85371

    accuracy                           0.56    254932
   macro avg       0.50      0.50      0.50    254932
weighted avg       0.55      0.56      0.56    254932

LPS_0.010_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.67      0.69      0.68     21195
           1       0.34      0.31      0.32     10672

    accuracy                           0.56     31867
   macro avg       0.50      0.50      0.50     31867
weighted avg       0.55      0.56      0.56     31867

LPS_0.010_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.66      0.68      0.67     21196
           1       0.32      0.30      0.31     10671

    accuracy                           0.56     31867
   macro avg       0.49      0.49      0.49     31867
weighted avg       0.55      0.56      0.55     31867

              precision    recall  f1-score   support

           0       0.66      0.68      0.67     21196
           1       0.32      0.30      0.31     10671

    accuracy                           0.56     31867
   macro avg       0.49      0.49      0.49     31867
weighted avg       0.55      0.56      0.55     31867

LPS_0.010_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.44      0.68      0.54     28584
           1       0.56      0.31      0.40     36366

    accuracy                           0.48     64950
   macro avg       0.50      0.50      0.47     64950
weighted avg       0.51      0.48      0.46     64950

              precision    recall  f1-score   support

           0       0.44      0.68      0.54     28584
           1       0.56      0.31      0.40     36366

    accuracy                           0.48     64950
   macro avg       0.50      0.50      0.47     64950
weighted avg       0.51      0.48      0.46     64950

completed
