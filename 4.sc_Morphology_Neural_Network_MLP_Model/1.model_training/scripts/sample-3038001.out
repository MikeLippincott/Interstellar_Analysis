[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '9644f3d0'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '79197209'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'cf30cb3a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '5e17e1d2'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_0.100_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_Nigericin_1.000_3.0_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (28580, 1276)
Number of total missing values across all columns: 29856
Data Subset Is Off
Wells held out for testing: ['L16' 'L22']
Wells to use for training, validation, and testing ['L17' 'L18' 'L19' 'L20' 'L21' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.256947).  Saving model ...
	 Train_Loss: 0.4117 Train_Acc: 82.289 Val_Loss: 0.2569  BEST VAL Loss: 0.2569  Val_Acc: 90.251

Epoch 1: Validation loss decreased (0.256947 --> 0.230081).  Saving model ...
	 Train_Loss: 0.3372 Train_Acc: 89.567 Val_Loss: 0.2301  BEST VAL Loss: 0.2301  Val_Acc: 92.326

Epoch 2: Validation loss decreased (0.230081 --> 0.208197).  Saving model ...
	 Train_Loss: 0.2949 Train_Acc: 92.210 Val_Loss: 0.2082  BEST VAL Loss: 0.2082  Val_Acc: 93.533

Epoch 3: Validation loss decreased (0.208197 --> 0.191270).  Saving model ...
	 Train_Loss: 0.2662 Train_Acc: 93.139 Val_Loss: 0.1913  BEST VAL Loss: 0.1913  Val_Acc: 94.450

Epoch 4: Validation loss decreased (0.191270 --> 0.177691).  Saving model ...
	 Train_Loss: 0.2441 Train_Acc: 94.141 Val_Loss: 0.1777  BEST VAL Loss: 0.1777  Val_Acc: 94.884

Epoch 5: Validation loss decreased (0.177691 --> 0.165978).  Saving model ...
	 Train_Loss: 0.2266 Train_Acc: 94.931 Val_Loss: 0.1660  BEST VAL Loss: 0.1660  Val_Acc: 95.512

Epoch 6: Validation loss decreased (0.165978 --> 0.156121).  Saving model ...
	 Train_Loss: 0.2125 Train_Acc: 95.474 Val_Loss: 0.1561  BEST VAL Loss: 0.1561  Val_Acc: 95.512

Epoch 7: Validation loss decreased (0.156121 --> 0.148100).  Saving model ...
	 Train_Loss: 0.2006 Train_Acc: 95.854 Val_Loss: 0.1481  BEST VAL Loss: 0.1481  Val_Acc: 95.415

Epoch 8: Validation loss decreased (0.148100 --> 0.141299).  Saving model ...
	 Train_Loss: 0.1905 Train_Acc: 96.078 Val_Loss: 0.1413  BEST VAL Loss: 0.1413  Val_Acc: 96.284

Epoch 9: Validation loss decreased (0.141299 --> 0.135931).  Saving model ...
	 Train_Loss: 0.1815 Train_Acc: 96.542 Val_Loss: 0.1359  BEST VAL Loss: 0.1359  Val_Acc: 96.187

Epoch 10: Validation loss decreased (0.135931 --> 0.131328).  Saving model ...
	 Train_Loss: 0.1739 Train_Acc: 96.434 Val_Loss: 0.1313  BEST VAL Loss: 0.1313  Val_Acc: 96.187

Epoch 11: Validation loss decreased (0.131328 --> 0.127105).  Saving model ...
	 Train_Loss: 0.1673 Train_Acc: 96.675 Val_Loss: 0.1271  BEST VAL Loss: 0.1271  Val_Acc: 96.380

Epoch 12: Validation loss decreased (0.127105 --> 0.123642).  Saving model ...
	 Train_Loss: 0.1611 Train_Acc: 96.874 Val_Loss: 0.1236  BEST VAL Loss: 0.1236  Val_Acc: 96.332

Epoch 13: Validation loss decreased (0.123642 --> 0.120575).  Saving model ...
	 Train_Loss: 0.1555 Train_Acc: 96.941 Val_Loss: 0.1206  BEST VAL Loss: 0.1206  Val_Acc: 96.380

Epoch 14: Validation loss decreased (0.120575 --> 0.117574).  Saving model ...
	 Train_Loss: 0.1505 Train_Acc: 97.055 Val_Loss: 0.1176  BEST VAL Loss: 0.1176  Val_Acc: 96.477

Epoch 15: Validation loss decreased (0.117574 --> 0.115429).  Saving model ...
	 Train_Loss: 0.1458 Train_Acc: 97.224 Val_Loss: 0.1154  BEST VAL Loss: 0.1154  Val_Acc: 96.525

Epoch 16: Validation loss decreased (0.115429 --> 0.113986).  Saving model ...
	 Train_Loss: 0.1415 Train_Acc: 97.363 Val_Loss: 0.1140  BEST VAL Loss: 0.1140  Val_Acc: 96.187

Epoch 17: Validation loss decreased (0.113986 --> 0.112238).  Saving model ...
	 Train_Loss: 0.1375 Train_Acc: 97.285 Val_Loss: 0.1122  BEST VAL Loss: 0.1122  Val_Acc: 96.332

Epoch 18: Validation loss decreased (0.112238 --> 0.110804).  Saving model ...
	 Train_Loss: 0.1339 Train_Acc: 97.598 Val_Loss: 0.1108  BEST VAL Loss: 0.1108  Val_Acc: 96.766

Epoch 19: Validation loss decreased (0.110804 --> 0.109416).  Saving model ...
	 Train_Loss: 0.1306 Train_Acc: 97.586 Val_Loss: 0.1094  BEST VAL Loss: 0.1094  Val_Acc: 96.670

Epoch 20: Validation loss decreased (0.109416 --> 0.108551).  Saving model ...
	 Train_Loss: 0.1274 Train_Acc: 97.544 Val_Loss: 0.1086  BEST VAL Loss: 0.1086  Val_Acc: 96.380

Epoch 21: Validation loss decreased (0.108551 --> 0.107631).  Saving model ...
	 Train_Loss: 0.1245 Train_Acc: 97.797 Val_Loss: 0.1076  BEST VAL Loss: 0.1076  Val_Acc: 96.622

Epoch 22: Validation loss decreased (0.107631 --> 0.106570).  Saving model ...
	 Train_Loss: 0.1217 Train_Acc: 97.677 Val_Loss: 0.1066  BEST VAL Loss: 0.1066  Val_Acc: 96.863

Epoch 23: Validation loss decreased (0.106570 --> 0.105393).  Saving model ...
	 Train_Loss: 0.1190 Train_Acc: 97.791 Val_Loss: 0.1054  BEST VAL Loss: 0.1054  Val_Acc: 96.766

Epoch 24: Validation loss decreased (0.105393 --> 0.104578).  Saving model ...
	 Train_Loss: 0.1165 Train_Acc: 98.063 Val_Loss: 0.1046  BEST VAL Loss: 0.1046  Val_Acc: 96.863

Epoch 25: Validation loss decreased (0.104578 --> 0.103752).  Saving model ...
	 Train_Loss: 0.1142 Train_Acc: 97.991 Val_Loss: 0.1038  BEST VAL Loss: 0.1038  Val_Acc: 97.056

Epoch 26: Validation loss decreased (0.103752 --> 0.103268).  Saving model ...
	 Train_Loss: 0.1120 Train_Acc: 98.075 Val_Loss: 0.1033  BEST VAL Loss: 0.1033  Val_Acc: 96.477

Epoch 27: Validation loss decreased (0.103268 --> 0.102717).  Saving model ...
	 Train_Loss: 0.1099 Train_Acc: 98.214 Val_Loss: 0.1027  BEST VAL Loss: 0.1027  Val_Acc: 96.525

Epoch 28: Validation loss decreased (0.102717 --> 0.102338).  Saving model ...
	 Train_Loss: 0.1078 Train_Acc: 98.214 Val_Loss: 0.1023  BEST VAL Loss: 0.1023  Val_Acc: 96.477

Epoch 29: Validation loss decreased (0.102338 --> 0.102102).  Saving model ...
	 Train_Loss: 0.1058 Train_Acc: 98.389 Val_Loss: 0.1021  BEST VAL Loss: 0.1021  Val_Acc: 96.477

Epoch 30: Validation loss decreased (0.102102 --> 0.101342).  Saving model ...
	 Train_Loss: 0.1040 Train_Acc: 98.292 Val_Loss: 0.1013  BEST VAL Loss: 0.1013  Val_Acc: 97.297

Epoch 31: Validation loss decreased (0.101342 --> 0.100907).  Saving model ...
	 Train_Loss: 0.1023 Train_Acc: 98.389 Val_Loss: 0.1009  BEST VAL Loss: 0.1009  Val_Acc: 96.573

Epoch 32: Validation loss decreased (0.100907 --> 0.100241).  Saving model ...
	 Train_Loss: 0.1005 Train_Acc: 98.528 Val_Loss: 0.1002  BEST VAL Loss: 0.1002  Val_Acc: 97.056

Epoch 33: Validation loss decreased (0.100241 --> 0.099941).  Saving model ...
	 Train_Loss: 0.0989 Train_Acc: 98.341 Val_Loss: 0.0999  BEST VAL Loss: 0.0999  Val_Acc: 96.911

Epoch 34: Validation loss decreased (0.099941 --> 0.099429).  Saving model ...
	 Train_Loss: 0.0973 Train_Acc: 98.316 Val_Loss: 0.0994  BEST VAL Loss: 0.0994  Val_Acc: 96.766

Epoch 35: Validation loss decreased (0.099429 --> 0.099142).  Saving model ...
	 Train_Loss: 0.0959 Train_Acc: 98.280 Val_Loss: 0.0991  BEST VAL Loss: 0.0991  Val_Acc: 96.622

Epoch 36: Validation loss decreased (0.099142 --> 0.098664).  Saving model ...
	 Train_Loss: 0.0945 Train_Acc: 98.443 Val_Loss: 0.0987  BEST VAL Loss: 0.0987  Val_Acc: 96.863

Epoch 37: Validation loss decreased (0.098664 --> 0.098212).  Saving model ...
	 Train_Loss: 0.0931 Train_Acc: 98.437 Val_Loss: 0.0982  BEST VAL Loss: 0.0982  Val_Acc: 96.959

Epoch 38: Validation loss decreased (0.098212 --> 0.097741).  Saving model ...
	 Train_Loss: 0.0919 Train_Acc: 98.401 Val_Loss: 0.0977  BEST VAL Loss: 0.0977  Val_Acc: 97.104

Epoch 39: Validation loss decreased (0.097741 --> 0.097645).  Saving model ...
	 Train_Loss: 0.0906 Train_Acc: 98.564 Val_Loss: 0.0976  BEST VAL Loss: 0.0976  Val_Acc: 96.766

Epoch 40: Validation loss decreased (0.097645 --> 0.097055).  Saving model ...
	 Train_Loss: 0.0894 Train_Acc: 98.612 Val_Loss: 0.0971  BEST VAL Loss: 0.0971  Val_Acc: 96.911

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.0882 Train_Acc: 98.570 Val_Loss: 0.0971  BEST VAL Loss: 0.0971  Val_Acc: 96.670

Epoch 42: Validation loss decreased (0.097055 --> 0.096823).  Saving model ...
	 Train_Loss: 0.0871 Train_Acc: 98.528 Val_Loss: 0.0968  BEST VAL Loss: 0.0968  Val_Acc: 96.670

Epoch 43: Validation loss decreased (0.096823 --> 0.096654).  Saving model ...
	 Train_Loss: 0.0860 Train_Acc: 98.534 Val_Loss: 0.0967  BEST VAL Loss: 0.0967  Val_Acc: 97.008

Epoch 44: Validation loss decreased (0.096654 --> 0.096405).  Saving model ...
	 Train_Loss: 0.0849 Train_Acc: 98.691 Val_Loss: 0.0964  BEST VAL Loss: 0.0964  Val_Acc: 96.815

Epoch 45: Validation loss decreased (0.096405 --> 0.095902).  Saving model ...
	 Train_Loss: 0.0840 Train_Acc: 98.600 Val_Loss: 0.0959  BEST VAL Loss: 0.0959  Val_Acc: 97.297

Epoch 46: Validation loss decreased (0.095902 --> 0.095844).  Saving model ...
	 Train_Loss: 0.0830 Train_Acc: 98.666 Val_Loss: 0.0958  BEST VAL Loss: 0.0958  Val_Acc: 97.008

Epoch 47: Validation loss decreased (0.095844 --> 0.095584).  Saving model ...
	 Train_Loss: 0.0821 Train_Acc: 98.606 Val_Loss: 0.0956  BEST VAL Loss: 0.0956  Val_Acc: 97.346

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.0812 Train_Acc: 98.709 Val_Loss: 0.0957  BEST VAL Loss: 0.0956  Val_Acc: 97.056

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.0803 Train_Acc: 98.757 Val_Loss: 0.0957  BEST VAL Loss: 0.0956  Val_Acc: 97.056

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.0794 Train_Acc: 98.793 Val_Loss: 0.0958  BEST VAL Loss: 0.0956  Val_Acc: 96.911

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.0786 Train_Acc: 98.594 Val_Loss: 0.0957  BEST VAL Loss: 0.0956  Val_Acc: 97.297

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.0779 Train_Acc: 98.715 Val_Loss: 0.0958  BEST VAL Loss: 0.0956  Val_Acc: 97.297

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.0771 Train_Acc: 98.727 Val_Loss: 0.0962  BEST VAL Loss: 0.0956  Val_Acc: 96.959

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.0764 Train_Acc: 98.582 Val_Loss: 0.0963  BEST VAL Loss: 0.0956  Val_Acc: 96.718

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.0757 Train_Acc: 98.540 Val_Loss: 0.0966  BEST VAL Loss: 0.0956  Val_Acc: 96.622

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.0751 Train_Acc: 98.341 Val_Loss: 0.0967  BEST VAL Loss: 0.0956  Val_Acc: 96.622

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.0745 Train_Acc: 98.697 Val_Loss: 0.0968  BEST VAL Loss: 0.0956  Val_Acc: 96.959

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.0738 Train_Acc: 98.835 Val_Loss: 0.0971  BEST VAL Loss: 0.0956  Val_Acc: 96.766

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.0732 Train_Acc: 98.672 Val_Loss: 0.0972  BEST VAL Loss: 0.0956  Val_Acc: 97.153

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.0726 Train_Acc: 98.721 Val_Loss: 0.0976  BEST VAL Loss: 0.0956  Val_Acc: 96.766

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.0721 Train_Acc: 98.503 Val_Loss: 0.0977  BEST VAL Loss: 0.0956  Val_Acc: 96.622

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.0716 Train_Acc: 98.407 Val_Loss: 0.0980  BEST VAL Loss: 0.0956  Val_Acc: 96.573

Epoch 63: Validation loss did not decrease
Early stopped at epoch : 63
Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       1.00      0.99      1.00      8634
           1       0.99      1.00      0.99      7938

    accuracy                           1.00     16572
   macro avg       1.00      1.00      1.00     16572
weighted avg       1.00      1.00      1.00     16572

Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.97      0.97      1080
           1       0.96      0.98      0.97       992

    accuracy                           0.97      2072
   macro avg       0.97      0.97      0.97      2072
weighted avg       0.97      0.97      0.97      2072

Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.97      0.97      1079
           1       0.97      0.98      0.97       993

    accuracy                           0.97      2072
   macro avg       0.97      0.97      0.97      2072
weighted avg       0.97      0.97      0.97      2072

              precision    recall  f1-score   support

           0       0.98      0.97      0.97      1079
           1       0.97      0.98      0.97       993

    accuracy                           0.97      2072
   macro avg       0.97      0.97      0.97      2072
weighted avg       0.97      0.97      0.97      2072

Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.95      0.96      0.95      4135
           1       0.95      0.94      0.95      3729

    accuracy                           0.95      7864
   macro avg       0.95      0.95      0.95      7864
weighted avg       0.95      0.95      0.95      7864

              precision    recall  f1-score   support

           0       0.95      0.96      0.95      4135
           1       0.95      0.94      0.95      3729

    accuracy                           0.95      7864
   macro avg       0.95      0.95      0.95      7864
weighted avg       0.95      0.95      0.95      7864

completed
