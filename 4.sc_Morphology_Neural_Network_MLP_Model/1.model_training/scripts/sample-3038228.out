[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '87dd1db2'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '829c269b'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b0b99a25'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '8ec6b92b'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 treatment_name: LPS_10.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
TREATMENT_NAME: LPS_10.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (322503, 1270)
Number of total missing values across all columns: 312980
Data Subset Is Off
Wells held out for testing: ['E09' 'K08']
Wells to use for training, validation, and testing ['E02' 'E03' 'E08' 'K02' 'K03' 'K09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.306895).  Saving model ...
	 Train_Loss: 0.4247 Train_Acc: 81.937 Val_Loss: 0.3069  BEST VAL Loss: 0.3069  Val_Acc: 87.542

Epoch 1: Validation loss decreased (0.306895 --> 0.261134).  Saving model ...
	 Train_Loss: 0.3484 Train_Acc: 89.514 Val_Loss: 0.2611  BEST VAL Loss: 0.2611  Val_Acc: 92.200

Epoch 2: Validation loss decreased (0.261134 --> 0.234055).  Saving model ...
	 Train_Loss: 0.3032 Train_Acc: 91.861 Val_Loss: 0.2341  BEST VAL Loss: 0.2341  Val_Acc: 93.476

Epoch 3: Validation loss decreased (0.234055 --> 0.215782).  Saving model ...
	 Train_Loss: 0.2741 Train_Acc: 92.740 Val_Loss: 0.2158  BEST VAL Loss: 0.2158  Val_Acc: 94.108

Epoch 4: Validation loss decreased (0.215782 --> 0.204060).  Saving model ...
	 Train_Loss: 0.2537 Train_Acc: 93.240 Val_Loss: 0.2041  BEST VAL Loss: 0.2041  Val_Acc: 94.320

Epoch 5: Validation loss decreased (0.204060 --> 0.194096).  Saving model ...
	 Train_Loss: 0.2383 Train_Acc: 93.664 Val_Loss: 0.1941  BEST VAL Loss: 0.1941  Val_Acc: 94.548

Epoch 6: Validation loss decreased (0.194096 --> 0.185865).  Saving model ...
	 Train_Loss: 0.2263 Train_Acc: 93.889 Val_Loss: 0.1859  BEST VAL Loss: 0.1859  Val_Acc: 94.797

Epoch 7: Validation loss decreased (0.185865 --> 0.178931).  Saving model ...
	 Train_Loss: 0.2165 Train_Acc: 94.175 Val_Loss: 0.1789  BEST VAL Loss: 0.1789  Val_Acc: 94.951

Epoch 8: Validation loss decreased (0.178931 --> 0.173683).  Saving model ...
	 Train_Loss: 0.2083 Train_Acc: 94.371 Val_Loss: 0.1737  BEST VAL Loss: 0.1737  Val_Acc: 94.922

Epoch 9: Validation loss decreased (0.173683 --> 0.168977).  Saving model ...
	 Train_Loss: 0.2013 Train_Acc: 94.642 Val_Loss: 0.1690  BEST VAL Loss: 0.1690  Val_Acc: 95.213

Epoch 10: Validation loss decreased (0.168977 --> 0.164888).  Saving model ...
	 Train_Loss: 0.1952 Train_Acc: 94.801 Val_Loss: 0.1649  BEST VAL Loss: 0.1649  Val_Acc: 95.176

Epoch 11: Validation loss decreased (0.164888 --> 0.161947).  Saving model ...
	 Train_Loss: 0.1900 Train_Acc: 94.883 Val_Loss: 0.1619  BEST VAL Loss: 0.1619  Val_Acc: 95.092

Epoch 12: Validation loss decreased (0.161947 --> 0.158522).  Saving model ...
	 Train_Loss: 0.1853 Train_Acc: 95.042 Val_Loss: 0.1585  BEST VAL Loss: 0.1585  Val_Acc: 95.554

Epoch 13: Validation loss decreased (0.158522 --> 0.155421).  Saving model ...
	 Train_Loss: 0.1810 Train_Acc: 95.154 Val_Loss: 0.1554  BEST VAL Loss: 0.1554  Val_Acc: 95.674

Epoch 14: Validation loss decreased (0.155421 --> 0.153000).  Saving model ...
	 Train_Loss: 0.1772 Train_Acc: 95.230 Val_Loss: 0.1530  BEST VAL Loss: 0.1530  Val_Acc: 95.537

Epoch 15: Validation loss decreased (0.153000 --> 0.150575).  Saving model ...
	 Train_Loss: 0.1738 Train_Acc: 95.302 Val_Loss: 0.1506  BEST VAL Loss: 0.1506  Val_Acc: 95.695

Epoch 16: Validation loss decreased (0.150575 --> 0.148619).  Saving model ...
	 Train_Loss: 0.1706 Train_Acc: 95.445 Val_Loss: 0.1486  BEST VAL Loss: 0.1486  Val_Acc: 95.753

Epoch 17: Validation loss decreased (0.148619 --> 0.146432).  Saving model ...
	 Train_Loss: 0.1676 Train_Acc: 95.553 Val_Loss: 0.1464  BEST VAL Loss: 0.1464  Val_Acc: 95.870

Epoch 18: Validation loss decreased (0.146432 --> 0.144446).  Saving model ...
	 Train_Loss: 0.1648 Train_Acc: 95.651 Val_Loss: 0.1444  BEST VAL Loss: 0.1444  Val_Acc: 95.886

Epoch 19: Validation loss decreased (0.144446 --> 0.142444).  Saving model ...
	 Train_Loss: 0.1622 Train_Acc: 95.667 Val_Loss: 0.1424  BEST VAL Loss: 0.1424  Val_Acc: 95.924

Epoch 20: Validation loss decreased (0.142444 --> 0.140942).  Saving model ...
	 Train_Loss: 0.1599 Train_Acc: 95.706 Val_Loss: 0.1409  BEST VAL Loss: 0.1409  Val_Acc: 95.778

Epoch 21: Validation loss decreased (0.140942 --> 0.139277).  Saving model ...
	 Train_Loss: 0.1576 Train_Acc: 95.780 Val_Loss: 0.1393  BEST VAL Loss: 0.1393  Val_Acc: 96.052

Epoch 22: Validation loss decreased (0.139277 --> 0.137705).  Saving model ...
	 Train_Loss: 0.1555 Train_Acc: 95.853 Val_Loss: 0.1377  BEST VAL Loss: 0.1377  Val_Acc: 96.111

Epoch 23: Validation loss decreased (0.137705 --> 0.136376).  Saving model ...
	 Train_Loss: 0.1535 Train_Acc: 95.894 Val_Loss: 0.1364  BEST VAL Loss: 0.1364  Val_Acc: 96.185

Epoch 24: Validation loss decreased (0.136376 --> 0.135181).  Saving model ...
	 Train_Loss: 0.1516 Train_Acc: 95.996 Val_Loss: 0.1352  BEST VAL Loss: 0.1352  Val_Acc: 96.061

Epoch 25: Validation loss decreased (0.135181 --> 0.133863).  Saving model ...
	 Train_Loss: 0.1499 Train_Acc: 96.046 Val_Loss: 0.1339  BEST VAL Loss: 0.1339  Val_Acc: 96.160

Epoch 26: Validation loss decreased (0.133863 --> 0.132819).  Saving model ...
	 Train_Loss: 0.1482 Train_Acc: 96.057 Val_Loss: 0.1328  BEST VAL Loss: 0.1328  Val_Acc: 96.244

Epoch 27: Validation loss decreased (0.132819 --> 0.131832).  Saving model ...
	 Train_Loss: 0.1466 Train_Acc: 96.055 Val_Loss: 0.1318  BEST VAL Loss: 0.1318  Val_Acc: 96.135

Epoch 28: Validation loss decreased (0.131832 --> 0.130758).  Saving model ...
	 Train_Loss: 0.1451 Train_Acc: 96.132 Val_Loss: 0.1308  BEST VAL Loss: 0.1308  Val_Acc: 96.227

Epoch 29: Validation loss decreased (0.130758 --> 0.129714).  Saving model ...
	 Train_Loss: 0.1436 Train_Acc: 96.191 Val_Loss: 0.1297  BEST VAL Loss: 0.1297  Val_Acc: 96.189

Epoch 30: Validation loss decreased (0.129714 --> 0.128739).  Saving model ...
	 Train_Loss: 0.1422 Train_Acc: 96.203 Val_Loss: 0.1287  BEST VAL Loss: 0.1287  Val_Acc: 96.189

Epoch 31: Validation loss decreased (0.128739 --> 0.127997).  Saving model ...
	 Train_Loss: 0.1409 Train_Acc: 96.242 Val_Loss: 0.1280  BEST VAL Loss: 0.1280  Val_Acc: 95.969

Epoch 32: Validation loss decreased (0.127997 --> 0.127218).  Saving model ...
	 Train_Loss: 0.1396 Train_Acc: 96.303 Val_Loss: 0.1272  BEST VAL Loss: 0.1272  Val_Acc: 96.160

Epoch 33: Validation loss decreased (0.127218 --> 0.126328).  Saving model ...
	 Train_Loss: 0.1384 Train_Acc: 96.356 Val_Loss: 0.1263  BEST VAL Loss: 0.1263  Val_Acc: 96.322

Epoch 34: Validation loss decreased (0.126328 --> 0.125539).  Saving model ...
	 Train_Loss: 0.1372 Train_Acc: 96.371 Val_Loss: 0.1255  BEST VAL Loss: 0.1255  Val_Acc: 96.073

Epoch 35: Validation loss decreased (0.125539 --> 0.124787).  Saving model ...
	 Train_Loss: 0.1361 Train_Acc: 96.375 Val_Loss: 0.1248  BEST VAL Loss: 0.1248  Val_Acc: 96.298

Epoch 36: Validation loss decreased (0.124787 --> 0.124144).  Saving model ...
	 Train_Loss: 0.1350 Train_Acc: 96.418 Val_Loss: 0.1241  BEST VAL Loss: 0.1241  Val_Acc: 96.327

Epoch 37: Validation loss decreased (0.124144 --> 0.123441).  Saving model ...
	 Train_Loss: 0.1339 Train_Acc: 96.487 Val_Loss: 0.1234  BEST VAL Loss: 0.1234  Val_Acc: 96.364

Epoch 38: Validation loss decreased (0.123441 --> 0.122767).  Saving model ...
	 Train_Loss: 0.1329 Train_Acc: 96.441 Val_Loss: 0.1228  BEST VAL Loss: 0.1228  Val_Acc: 96.352

Epoch 39: Validation loss decreased (0.122767 --> 0.122040).  Saving model ...
	 Train_Loss: 0.1319 Train_Acc: 96.490 Val_Loss: 0.1220  BEST VAL Loss: 0.1220  Val_Acc: 96.472

Epoch 40: Validation loss decreased (0.122040 --> 0.121396).  Saving model ...
	 Train_Loss: 0.1310 Train_Acc: 96.511 Val_Loss: 0.1214  BEST VAL Loss: 0.1214  Val_Acc: 96.389

Epoch 41: Validation loss decreased (0.121396 --> 0.120757).  Saving model ...
	 Train_Loss: 0.1301 Train_Acc: 96.522 Val_Loss: 0.1208  BEST VAL Loss: 0.1208  Val_Acc: 96.468

Epoch 42: Validation loss decreased (0.120757 --> 0.120174).  Saving model ...
	 Train_Loss: 0.1292 Train_Acc: 96.591 Val_Loss: 0.1202  BEST VAL Loss: 0.1202  Val_Acc: 96.476

Epoch 43: Validation loss decreased (0.120174 --> 0.119679).  Saving model ...
	 Train_Loss: 0.1283 Train_Acc: 96.569 Val_Loss: 0.1197  BEST VAL Loss: 0.1197  Val_Acc: 96.406

Epoch 44: Validation loss decreased (0.119679 --> 0.119122).  Saving model ...
	 Train_Loss: 0.1274 Train_Acc: 96.580 Val_Loss: 0.1191  BEST VAL Loss: 0.1191  Val_Acc: 96.468

Epoch 45: Validation loss decreased (0.119122 --> 0.118698).  Saving model ...
	 Train_Loss: 0.1266 Train_Acc: 96.577 Val_Loss: 0.1187  BEST VAL Loss: 0.1187  Val_Acc: 96.302

Epoch 46: Validation loss decreased (0.118698 --> 0.118131).  Saving model ...
	 Train_Loss: 0.1258 Train_Acc: 96.658 Val_Loss: 0.1181  BEST VAL Loss: 0.1181  Val_Acc: 96.555

Epoch 47: Validation loss decreased (0.118131 --> 0.117630).  Saving model ...
	 Train_Loss: 0.1251 Train_Acc: 96.658 Val_Loss: 0.1176  BEST VAL Loss: 0.1176  Val_Acc: 96.526

Epoch 48: Validation loss decreased (0.117630 --> 0.117111).  Saving model ...
	 Train_Loss: 0.1243 Train_Acc: 96.712 Val_Loss: 0.1171  BEST VAL Loss: 0.1171  Val_Acc: 96.593

Epoch 49: Validation loss decreased (0.117111 --> 0.116689).  Saving model ...
	 Train_Loss: 0.1236 Train_Acc: 96.697 Val_Loss: 0.1167  BEST VAL Loss: 0.1167  Val_Acc: 96.601

Epoch 50: Validation loss decreased (0.116689 --> 0.116313).  Saving model ...
	 Train_Loss: 0.1229 Train_Acc: 96.734 Val_Loss: 0.1163  BEST VAL Loss: 0.1163  Val_Acc: 96.451

Epoch 51: Validation loss decreased (0.116313 --> 0.115842).  Saving model ...
	 Train_Loss: 0.1222 Train_Acc: 96.704 Val_Loss: 0.1158  BEST VAL Loss: 0.1158  Val_Acc: 96.651

Epoch 52: Validation loss decreased (0.115842 --> 0.115400).  Saving model ...
	 Train_Loss: 0.1216 Train_Acc: 96.734 Val_Loss: 0.1154  BEST VAL Loss: 0.1154  Val_Acc: 96.543

Epoch 53: Validation loss decreased (0.115400 --> 0.114987).  Saving model ...
	 Train_Loss: 0.1209 Train_Acc: 96.774 Val_Loss: 0.1150  BEST VAL Loss: 0.1150  Val_Acc: 96.563

Epoch 54: Validation loss decreased (0.114987 --> 0.114621).  Saving model ...
	 Train_Loss: 0.1203 Train_Acc: 96.784 Val_Loss: 0.1146  BEST VAL Loss: 0.1146  Val_Acc: 96.680

Epoch 55: Validation loss decreased (0.114621 --> 0.114214).  Saving model ...
	 Train_Loss: 0.1197 Train_Acc: 96.782 Val_Loss: 0.1142  BEST VAL Loss: 0.1142  Val_Acc: 96.613

Epoch 56: Validation loss decreased (0.114214 --> 0.113800).  Saving model ...
	 Train_Loss: 0.1191 Train_Acc: 96.839 Val_Loss: 0.1138  BEST VAL Loss: 0.1138  Val_Acc: 96.563

Epoch 57: Validation loss decreased (0.113800 --> 0.113556).  Saving model ...
	 Train_Loss: 0.1185 Train_Acc: 96.835 Val_Loss: 0.1136  BEST VAL Loss: 0.1136  Val_Acc: 96.622

Epoch 58: Validation loss decreased (0.113556 --> 0.113232).  Saving model ...
	 Train_Loss: 0.1179 Train_Acc: 96.845 Val_Loss: 0.1132  BEST VAL Loss: 0.1132  Val_Acc: 96.518

Epoch 59: Validation loss decreased (0.113232 --> 0.112902).  Saving model ...
	 Train_Loss: 0.1173 Train_Acc: 96.864 Val_Loss: 0.1129  BEST VAL Loss: 0.1129  Val_Acc: 96.576

Epoch 60: Validation loss decreased (0.112902 --> 0.112550).  Saving model ...
	 Train_Loss: 0.1168 Train_Acc: 96.866 Val_Loss: 0.1125  BEST VAL Loss: 0.1125  Val_Acc: 96.630

Epoch 61: Validation loss decreased (0.112550 --> 0.112170).  Saving model ...
	 Train_Loss: 0.1162 Train_Acc: 96.880 Val_Loss: 0.1122  BEST VAL Loss: 0.1122  Val_Acc: 96.638

Epoch 62: Validation loss decreased (0.112170 --> 0.111781).  Saving model ...
	 Train_Loss: 0.1157 Train_Acc: 96.921 Val_Loss: 0.1118  BEST VAL Loss: 0.1118  Val_Acc: 96.734

Epoch 63: Validation loss decreased (0.111781 --> 0.111446).  Saving model ...
	 Train_Loss: 0.1152 Train_Acc: 96.868 Val_Loss: 0.1114  BEST VAL Loss: 0.1114  Val_Acc: 96.634

Epoch 64: Validation loss decreased (0.111446 --> 0.111151).  Saving model ...
	 Train_Loss: 0.1147 Train_Acc: 96.891 Val_Loss: 0.1112  BEST VAL Loss: 0.1112  Val_Acc: 96.692

Epoch 65: Validation loss decreased (0.111151 --> 0.110868).  Saving model ...
	 Train_Loss: 0.1142 Train_Acc: 96.920 Val_Loss: 0.1109  BEST VAL Loss: 0.1109  Val_Acc: 96.676

Epoch 66: Validation loss decreased (0.110868 --> 0.110580).  Saving model ...
	 Train_Loss: 0.1137 Train_Acc: 96.937 Val_Loss: 0.1106  BEST VAL Loss: 0.1106  Val_Acc: 96.730

Epoch 67: Validation loss decreased (0.110580 --> 0.110273).  Saving model ...
	 Train_Loss: 0.1132 Train_Acc: 96.927 Val_Loss: 0.1103  BEST VAL Loss: 0.1103  Val_Acc: 96.709

Epoch 68: Validation loss decreased (0.110273 --> 0.110025).  Saving model ...
	 Train_Loss: 0.1128 Train_Acc: 96.952 Val_Loss: 0.1100  BEST VAL Loss: 0.1100  Val_Acc: 96.717

Epoch 69: Validation loss decreased (0.110025 --> 0.109751).  Saving model ...
	 Train_Loss: 0.1123 Train_Acc: 96.972 Val_Loss: 0.1098  BEST VAL Loss: 0.1098  Val_Acc: 96.692

Epoch 70: Validation loss decreased (0.109751 --> 0.109472).  Saving model ...
	 Train_Loss: 0.1119 Train_Acc: 96.973 Val_Loss: 0.1095  BEST VAL Loss: 0.1095  Val_Acc: 96.750

Epoch 71: Validation loss decreased (0.109472 --> 0.109168).  Saving model ...
	 Train_Loss: 0.1114 Train_Acc: 97.033 Val_Loss: 0.1092  BEST VAL Loss: 0.1092  Val_Acc: 96.684

Epoch 72: Validation loss decreased (0.109168 --> 0.108903).  Saving model ...
	 Train_Loss: 0.1110 Train_Acc: 97.006 Val_Loss: 0.1089  BEST VAL Loss: 0.1089  Val_Acc: 96.651

Epoch 73: Validation loss decreased (0.108903 --> 0.108609).  Saving model ...
	 Train_Loss: 0.1106 Train_Acc: 97.030 Val_Loss: 0.1086  BEST VAL Loss: 0.1086  Val_Acc: 96.788

Epoch 74: Validation loss decreased (0.108609 --> 0.108343).  Saving model ...
	 Train_Loss: 0.1102 Train_Acc: 97.055 Val_Loss: 0.1083  BEST VAL Loss: 0.1083  Val_Acc: 96.713

Epoch 75: Validation loss decreased (0.108343 --> 0.108112).  Saving model ...
	 Train_Loss: 0.1098 Train_Acc: 97.050 Val_Loss: 0.1081  BEST VAL Loss: 0.1081  Val_Acc: 96.784

Epoch 76: Validation loss decreased (0.108112 --> 0.107892).  Saving model ...
	 Train_Loss: 0.1094 Train_Acc: 97.057 Val_Loss: 0.1079  BEST VAL Loss: 0.1079  Val_Acc: 96.667

Epoch 77: Validation loss decreased (0.107892 --> 0.107631).  Saving model ...
	 Train_Loss: 0.1090 Train_Acc: 97.057 Val_Loss: 0.1076  BEST VAL Loss: 0.1076  Val_Acc: 96.767

Epoch 78: Validation loss decreased (0.107631 --> 0.107388).  Saving model ...
	 Train_Loss: 0.1086 Train_Acc: 97.078 Val_Loss: 0.1074  BEST VAL Loss: 0.1074  Val_Acc: 96.809

Epoch 79: Validation loss decreased (0.107388 --> 0.107250).  Saving model ...
	 Train_Loss: 0.1082 Train_Acc: 97.059 Val_Loss: 0.1072  BEST VAL Loss: 0.1072  Val_Acc: 96.780

Epoch 80: Validation loss decreased (0.107250 --> 0.107065).  Saving model ...
	 Train_Loss: 0.1078 Train_Acc: 97.093 Val_Loss: 0.1071  BEST VAL Loss: 0.1071  Val_Acc: 96.804

Epoch 81: Validation loss decreased (0.107065 --> 0.106864).  Saving model ...
	 Train_Loss: 0.1075 Train_Acc: 97.048 Val_Loss: 0.1069  BEST VAL Loss: 0.1069  Val_Acc: 96.825

Epoch 82: Validation loss decreased (0.106864 --> 0.106665).  Saving model ...
	 Train_Loss: 0.1071 Train_Acc: 97.092 Val_Loss: 0.1067  BEST VAL Loss: 0.1067  Val_Acc: 96.688

Epoch 83: Validation loss decreased (0.106665 --> 0.106445).  Saving model ...
	 Train_Loss: 0.1068 Train_Acc: 97.113 Val_Loss: 0.1064  BEST VAL Loss: 0.1064  Val_Acc: 96.796

Epoch 84: Validation loss decreased (0.106445 --> 0.106233).  Saving model ...
	 Train_Loss: 0.1064 Train_Acc: 97.125 Val_Loss: 0.1062  BEST VAL Loss: 0.1062  Val_Acc: 96.863

Epoch 85: Validation loss decreased (0.106233 --> 0.106020).  Saving model ...
	 Train_Loss: 0.1061 Train_Acc: 97.140 Val_Loss: 0.1060  BEST VAL Loss: 0.1060  Val_Acc: 96.975

Epoch 86: Validation loss decreased (0.106020 --> 0.105834).  Saving model ...
	 Train_Loss: 0.1057 Train_Acc: 97.150 Val_Loss: 0.1058  BEST VAL Loss: 0.1058  Val_Acc: 96.746

Epoch 87: Validation loss decreased (0.105834 --> 0.105672).  Saving model ...
	 Train_Loss: 0.1054 Train_Acc: 97.148 Val_Loss: 0.1057  BEST VAL Loss: 0.1057  Val_Acc: 96.809

Epoch 88: Validation loss decreased (0.105672 --> 0.105482).  Saving model ...
	 Train_Loss: 0.1051 Train_Acc: 97.214 Val_Loss: 0.1055  BEST VAL Loss: 0.1055  Val_Acc: 96.784

Epoch 89: Validation loss decreased (0.105482 --> 0.105326).  Saving model ...
	 Train_Loss: 0.1048 Train_Acc: 97.132 Val_Loss: 0.1053  BEST VAL Loss: 0.1053  Val_Acc: 96.871

Epoch 90: Validation loss decreased (0.105326 --> 0.105152).  Saving model ...
	 Train_Loss: 0.1044 Train_Acc: 97.197 Val_Loss: 0.1052  BEST VAL Loss: 0.1052  Val_Acc: 96.800

Epoch 91: Validation loss decreased (0.105152 --> 0.105043).  Saving model ...
	 Train_Loss: 0.1041 Train_Acc: 97.152 Val_Loss: 0.1050  BEST VAL Loss: 0.1050  Val_Acc: 96.896

Epoch 92: Validation loss decreased (0.105043 --> 0.104857).  Saving model ...
	 Train_Loss: 0.1038 Train_Acc: 97.186 Val_Loss: 0.1049  BEST VAL Loss: 0.1049  Val_Acc: 96.842

Epoch 93: Validation loss decreased (0.104857 --> 0.104693).  Saving model ...
	 Train_Loss: 0.1035 Train_Acc: 97.159 Val_Loss: 0.1047  BEST VAL Loss: 0.1047  Val_Acc: 96.605

Epoch 94: Validation loss decreased (0.104693 --> 0.104505).  Saving model ...
	 Train_Loss: 0.1032 Train_Acc: 97.173 Val_Loss: 0.1045  BEST VAL Loss: 0.1045  Val_Acc: 96.913

Epoch 95: Validation loss decreased (0.104505 --> 0.104344).  Saving model ...
	 Train_Loss: 0.1029 Train_Acc: 97.225 Val_Loss: 0.1043  BEST VAL Loss: 0.1043  Val_Acc: 96.817

Epoch 96: Validation loss decreased (0.104344 --> 0.104204).  Saving model ...
	 Train_Loss: 0.1027 Train_Acc: 97.178 Val_Loss: 0.1042  BEST VAL Loss: 0.1042  Val_Acc: 96.875

Epoch 97: Validation loss decreased (0.104204 --> 0.104094).  Saving model ...
	 Train_Loss: 0.1024 Train_Acc: 97.216 Val_Loss: 0.1041  BEST VAL Loss: 0.1041  Val_Acc: 96.937

Epoch 98: Validation loss decreased (0.104094 --> 0.104028).  Saving model ...
	 Train_Loss: 0.1021 Train_Acc: 97.179 Val_Loss: 0.1040  BEST VAL Loss: 0.1040  Val_Acc: 96.883

Epoch 99: Validation loss decreased (0.104028 --> 0.103827).  Saving model ...
	 Train_Loss: 0.1018 Train_Acc: 97.287 Val_Loss: 0.1038  BEST VAL Loss: 0.1038  Val_Acc: 96.838

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.48      0.48     92173
           1       0.52      0.52      0.52    100339

    accuracy                           0.50    192512
   macro avg       0.50      0.50      0.50    192512
weighted avg       0.50      0.50      0.50    192512

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.48      0.48     11522
           1       0.53      0.53      0.53     12543

    accuracy                           0.51     24065
   macro avg       0.50      0.50      0.50     24065
weighted avg       0.51      0.51      0.51     24065

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.48      0.48     11522
           1       0.52      0.52      0.52     12543

    accuracy                           0.50     24065
   macro avg       0.50      0.50      0.50     24065
weighted avg       0.50      0.50      0.50     24065

              precision    recall  f1-score   support

           0       0.48      0.48      0.48     11522
           1       0.52      0.52      0.52     12543

    accuracy                           0.50     24065
   macro avg       0.50      0.50      0.50     24065
weighted avg       0.50      0.50      0.50     24065

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.47      0.49     41273
           1       0.50      0.53      0.51     40588

    accuracy                           0.50     81861
   macro avg       0.50      0.50      0.50     81861
weighted avg       0.50      0.50      0.50     81861

              precision    recall  f1-score   support

           0       0.51      0.47      0.49     41273
           1       0.50      0.53      0.51     40588

    accuracy                           0.50     81861
   macro avg       0.50      0.50      0.50     81861
weighted avg       0.50      0.50      0.50     81861

completed
