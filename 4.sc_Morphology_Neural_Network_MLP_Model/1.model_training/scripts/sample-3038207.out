[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'c32decdb'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'f50dfadc'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'e23f888a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'cc109ceb'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Thapsigargin_1.000_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Thapsigargin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (307891, 1270)
Number of total missing values across all columns: 615782
Data Subset Is Off
Wells held out for testing: ['K06' 'J09']
Wells to use for training, validation, and testing ['D06' 'D07' 'J02' 'J03' 'K07' 'J08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.534212).  Saving model ...
	 Train_Loss: 0.6278 Train_Acc: 64.785 Val_Loss: 0.5342  BEST VAL Loss: 0.5342  Val_Acc: 75.821

Epoch 1: Validation loss decreased (0.534212 --> 0.499603).  Saving model ...
	 Train_Loss: 0.5853 Train_Acc: 74.433 Val_Loss: 0.4996  BEST VAL Loss: 0.4996  Val_Acc: 79.015

Epoch 2: Validation loss decreased (0.499603 --> 0.476879).  Saving model ...
	 Train_Loss: 0.5575 Train_Acc: 77.263 Val_Loss: 0.4769  BEST VAL Loss: 0.4769  Val_Acc: 80.845

Epoch 3: Validation loss decreased (0.476879 --> 0.460770).  Saving model ...
	 Train_Loss: 0.5376 Train_Acc: 78.675 Val_Loss: 0.4608  BEST VAL Loss: 0.4608  Val_Acc: 81.840

Epoch 4: Validation loss decreased (0.460770 --> 0.448270).  Saving model ...
	 Train_Loss: 0.5224 Train_Acc: 79.737 Val_Loss: 0.4483  BEST VAL Loss: 0.4483  Val_Acc: 82.896

Epoch 5: Validation loss decreased (0.448270 --> 0.436942).  Saving model ...
	 Train_Loss: 0.5104 Train_Acc: 80.256 Val_Loss: 0.4369  BEST VAL Loss: 0.4369  Val_Acc: 83.469

Epoch 6: Validation loss decreased (0.436942 --> 0.427095).  Saving model ...
	 Train_Loss: 0.5002 Train_Acc: 80.894 Val_Loss: 0.4271  BEST VAL Loss: 0.4271  Val_Acc: 84.026

Epoch 7: Validation loss decreased (0.427095 --> 0.419922).  Saving model ...
	 Train_Loss: 0.4913 Train_Acc: 81.256 Val_Loss: 0.4199  BEST VAL Loss: 0.4199  Val_Acc: 83.874

Epoch 8: Validation loss decreased (0.419922 --> 0.412724).  Saving model ...
	 Train_Loss: 0.4838 Train_Acc: 81.561 Val_Loss: 0.4127  BEST VAL Loss: 0.4127  Val_Acc: 84.121

Epoch 9: Validation loss decreased (0.412724 --> 0.406185).  Saving model ...
	 Train_Loss: 0.4770 Train_Acc: 82.034 Val_Loss: 0.4062  BEST VAL Loss: 0.4062  Val_Acc: 85.038

Epoch 10: Validation loss decreased (0.406185 --> 0.400126).  Saving model ...
	 Train_Loss: 0.4707 Train_Acc: 82.388 Val_Loss: 0.4001  BEST VAL Loss: 0.4001  Val_Acc: 85.464

Epoch 11: Validation loss decreased (0.400126 --> 0.394622).  Saving model ...
	 Train_Loss: 0.4649 Train_Acc: 82.642 Val_Loss: 0.3946  BEST VAL Loss: 0.3946  Val_Acc: 85.173

Epoch 12: Validation loss decreased (0.394622 --> 0.389947).  Saving model ...
	 Train_Loss: 0.4598 Train_Acc: 82.760 Val_Loss: 0.3899  BEST VAL Loss: 0.3899  Val_Acc: 85.568

Epoch 13: Validation loss decreased (0.389947 --> 0.385068).  Saving model ...
	 Train_Loss: 0.4551 Train_Acc: 83.065 Val_Loss: 0.3851  BEST VAL Loss: 0.3851  Val_Acc: 85.781

Epoch 14: Validation loss decreased (0.385068 --> 0.380806).  Saving model ...
	 Train_Loss: 0.4507 Train_Acc: 83.190 Val_Loss: 0.3808  BEST VAL Loss: 0.3808  Val_Acc: 85.933

Epoch 15: Validation loss decreased (0.380806 --> 0.377045).  Saving model ...
	 Train_Loss: 0.4468 Train_Acc: 83.313 Val_Loss: 0.3770  BEST VAL Loss: 0.3770  Val_Acc: 85.912

Epoch 16: Validation loss decreased (0.377045 --> 0.373731).  Saving model ...
	 Train_Loss: 0.4432 Train_Acc: 83.414 Val_Loss: 0.3737  BEST VAL Loss: 0.3737  Val_Acc: 85.851

Epoch 17: Validation loss decreased (0.373731 --> 0.370817).  Saving model ...
	 Train_Loss: 0.4400 Train_Acc: 83.539 Val_Loss: 0.3708  BEST VAL Loss: 0.3708  Val_Acc: 85.716

Epoch 18: Validation loss decreased (0.370817 --> 0.367709).  Saving model ...
	 Train_Loss: 0.4370 Train_Acc: 83.482 Val_Loss: 0.3677  BEST VAL Loss: 0.3677  Val_Acc: 85.838

Epoch 19: Validation loss decreased (0.367709 --> 0.365176).  Saving model ...
	 Train_Loss: 0.4341 Train_Acc: 83.607 Val_Loss: 0.3652  BEST VAL Loss: 0.3652  Val_Acc: 86.233

Epoch 20: Validation loss decreased (0.365176 --> 0.362760).  Saving model ...
	 Train_Loss: 0.4313 Train_Acc: 83.958 Val_Loss: 0.3628  BEST VAL Loss: 0.3628  Val_Acc: 86.272

Epoch 21: Validation loss decreased (0.362760 --> 0.360326).  Saving model ...
	 Train_Loss: 0.4288 Train_Acc: 83.982 Val_Loss: 0.3603  BEST VAL Loss: 0.3603  Val_Acc: 86.568

Epoch 22: Validation loss decreased (0.360326 --> 0.359159).  Saving model ...
	 Train_Loss: 0.4265 Train_Acc: 83.911 Val_Loss: 0.3592  BEST VAL Loss: 0.3592  Val_Acc: 86.394

Epoch 23: Validation loss decreased (0.359159 --> 0.356966).  Saving model ...
	 Train_Loss: 0.4242 Train_Acc: 84.132 Val_Loss: 0.3570  BEST VAL Loss: 0.3570  Val_Acc: 86.381

Epoch 24: Validation loss decreased (0.356966 --> 0.354930).  Saving model ...
	 Train_Loss: 0.4221 Train_Acc: 84.153 Val_Loss: 0.3549  BEST VAL Loss: 0.3549  Val_Acc: 86.442

Epoch 25: Validation loss decreased (0.354930 --> 0.353582).  Saving model ...
	 Train_Loss: 0.4200 Train_Acc: 84.214 Val_Loss: 0.3536  BEST VAL Loss: 0.3536  Val_Acc: 86.585

Epoch 26: Validation loss decreased (0.353582 --> 0.351988).  Saving model ...
	 Train_Loss: 0.4181 Train_Acc: 84.123 Val_Loss: 0.3520  BEST VAL Loss: 0.3520  Val_Acc: 86.520

Epoch 27: Validation loss decreased (0.351988 --> 0.350777).  Saving model ...
	 Train_Loss: 0.4163 Train_Acc: 84.274 Val_Loss: 0.3508  BEST VAL Loss: 0.3508  Val_Acc: 86.294

Epoch 28: Validation loss decreased (0.350777 --> 0.349188).  Saving model ...
	 Train_Loss: 0.4146 Train_Acc: 84.300 Val_Loss: 0.3492  BEST VAL Loss: 0.3492  Val_Acc: 86.659

Epoch 29: Validation loss decreased (0.349188 --> 0.347523).  Saving model ...
	 Train_Loss: 0.4130 Train_Acc: 84.354 Val_Loss: 0.3475  BEST VAL Loss: 0.3475  Val_Acc: 86.833

Epoch 30: Validation loss decreased (0.347523 --> 0.346228).  Saving model ...
	 Train_Loss: 0.4114 Train_Acc: 84.429 Val_Loss: 0.3462  BEST VAL Loss: 0.3462  Val_Acc: 86.785

Epoch 31: Validation loss decreased (0.346228 --> 0.344705).  Saving model ...
	 Train_Loss: 0.4100 Train_Acc: 84.451 Val_Loss: 0.3447  BEST VAL Loss: 0.3447  Val_Acc: 86.624

Epoch 32: Validation loss decreased (0.344705 --> 0.343318).  Saving model ...
	 Train_Loss: 0.4087 Train_Acc: 84.403 Val_Loss: 0.3433  BEST VAL Loss: 0.3433  Val_Acc: 86.729

Epoch 33: Validation loss decreased (0.343318 --> 0.342011).  Saving model ...
	 Train_Loss: 0.4073 Train_Acc: 84.408 Val_Loss: 0.3420  BEST VAL Loss: 0.3420  Val_Acc: 86.577

Epoch 34: Validation loss decreased (0.342011 --> 0.340997).  Saving model ...
	 Train_Loss: 0.4060 Train_Acc: 84.688 Val_Loss: 0.3410  BEST VAL Loss: 0.3410  Val_Acc: 86.776

Epoch 35: Validation loss decreased (0.340997 --> 0.339607).  Saving model ...
	 Train_Loss: 0.4048 Train_Acc: 84.628 Val_Loss: 0.3396  BEST VAL Loss: 0.3396  Val_Acc: 86.946

Epoch 36: Validation loss decreased (0.339607 --> 0.338620).  Saving model ...
	 Train_Loss: 0.4036 Train_Acc: 84.727 Val_Loss: 0.3386  BEST VAL Loss: 0.3386  Val_Acc: 86.772

Epoch 37: Validation loss decreased (0.338620 --> 0.337639).  Saving model ...
	 Train_Loss: 0.4025 Train_Acc: 84.660 Val_Loss: 0.3376  BEST VAL Loss: 0.3376  Val_Acc: 86.829

Epoch 38: Validation loss decreased (0.337639 --> 0.336846).  Saving model ...
	 Train_Loss: 0.4014 Train_Acc: 84.817 Val_Loss: 0.3368  BEST VAL Loss: 0.3368  Val_Acc: 87.207

Epoch 39: Validation loss decreased (0.336846 --> 0.336120).  Saving model ...
	 Train_Loss: 0.4003 Train_Acc: 84.736 Val_Loss: 0.3361  BEST VAL Loss: 0.3361  Val_Acc: 87.042

Epoch 40: Validation loss decreased (0.336120 --> 0.335510).  Saving model ...
	 Train_Loss: 0.3993 Train_Acc: 84.812 Val_Loss: 0.3355  BEST VAL Loss: 0.3355  Val_Acc: 87.050

Epoch 41: Validation loss decreased (0.335510 --> 0.334969).  Saving model ...
	 Train_Loss: 0.3983 Train_Acc: 84.976 Val_Loss: 0.3350  BEST VAL Loss: 0.3350  Val_Acc: 87.333

Epoch 42: Validation loss decreased (0.334969 --> 0.333983).  Saving model ...
	 Train_Loss: 0.3974 Train_Acc: 84.813 Val_Loss: 0.3340  BEST VAL Loss: 0.3340  Val_Acc: 87.202

Epoch 43: Validation loss decreased (0.333983 --> 0.333195).  Saving model ...
	 Train_Loss: 0.3964 Train_Acc: 84.954 Val_Loss: 0.3332  BEST VAL Loss: 0.3332  Val_Acc: 86.981

Epoch 44: Validation loss decreased (0.333195 --> 0.332371).  Saving model ...
	 Train_Loss: 0.3955 Train_Acc: 84.897 Val_Loss: 0.3324  BEST VAL Loss: 0.3324  Val_Acc: 87.155

Epoch 45: Validation loss decreased (0.332371 --> 0.331599).  Saving model ...
	 Train_Loss: 0.3947 Train_Acc: 84.882 Val_Loss: 0.3316  BEST VAL Loss: 0.3316  Val_Acc: 87.372

Epoch 46: Validation loss decreased (0.331599 --> 0.330672).  Saving model ...
	 Train_Loss: 0.3939 Train_Acc: 84.903 Val_Loss: 0.3307  BEST VAL Loss: 0.3307  Val_Acc: 87.233

Epoch 47: Validation loss decreased (0.330672 --> 0.329881).  Saving model ...
	 Train_Loss: 0.3930 Train_Acc: 84.992 Val_Loss: 0.3299  BEST VAL Loss: 0.3299  Val_Acc: 87.376

Epoch 48: Validation loss decreased (0.329881 --> 0.329130).  Saving model ...
	 Train_Loss: 0.3923 Train_Acc: 84.934 Val_Loss: 0.3291  BEST VAL Loss: 0.3291  Val_Acc: 87.128

Epoch 49: Validation loss decreased (0.329130 --> 0.328641).  Saving model ...
	 Train_Loss: 0.3915 Train_Acc: 84.949 Val_Loss: 0.3286  BEST VAL Loss: 0.3286  Val_Acc: 87.115

Epoch 50: Validation loss decreased (0.328641 --> 0.327868).  Saving model ...
	 Train_Loss: 0.3909 Train_Acc: 84.767 Val_Loss: 0.3279  BEST VAL Loss: 0.3279  Val_Acc: 87.146

Epoch 51: Validation loss decreased (0.327868 --> 0.327152).  Saving model ...
	 Train_Loss: 0.3901 Train_Acc: 85.006 Val_Loss: 0.3272  BEST VAL Loss: 0.3272  Val_Acc: 87.367

Epoch 52: Validation loss decreased (0.327152 --> 0.326477).  Saving model ...
	 Train_Loss: 0.3894 Train_Acc: 84.975 Val_Loss: 0.3265  BEST VAL Loss: 0.3265  Val_Acc: 87.450

Epoch 53: Validation loss decreased (0.326477 --> 0.325909).  Saving model ...
	 Train_Loss: 0.3888 Train_Acc: 85.003 Val_Loss: 0.3259  BEST VAL Loss: 0.3259  Val_Acc: 87.394

Epoch 54: Validation loss decreased (0.325909 --> 0.325219).  Saving model ...
	 Train_Loss: 0.3881 Train_Acc: 84.991 Val_Loss: 0.3252  BEST VAL Loss: 0.3252  Val_Acc: 87.546

Epoch 55: Validation loss decreased (0.325219 --> 0.324583).  Saving model ...
	 Train_Loss: 0.3874 Train_Acc: 85.130 Val_Loss: 0.3246  BEST VAL Loss: 0.3246  Val_Acc: 87.333

Epoch 56: Validation loss decreased (0.324583 --> 0.324169).  Saving model ...
	 Train_Loss: 0.3868 Train_Acc: 85.218 Val_Loss: 0.3242  BEST VAL Loss: 0.3242  Val_Acc: 87.220

Epoch 57: Validation loss decreased (0.324169 --> 0.323729).  Saving model ...
	 Train_Loss: 0.3862 Train_Acc: 85.003 Val_Loss: 0.3237  BEST VAL Loss: 0.3237  Val_Acc: 86.920

Epoch 58: Validation loss decreased (0.323729 --> 0.323250).  Saving model ...
	 Train_Loss: 0.3856 Train_Acc: 85.192 Val_Loss: 0.3232  BEST VAL Loss: 0.3232  Val_Acc: 87.007

Epoch 59: Validation loss decreased (0.323250 --> 0.322682).  Saving model ...
	 Train_Loss: 0.3851 Train_Acc: 84.933 Val_Loss: 0.3227  BEST VAL Loss: 0.3227  Val_Acc: 87.524

Epoch 60: Validation loss decreased (0.322682 --> 0.322158).  Saving model ...
	 Train_Loss: 0.3845 Train_Acc: 85.302 Val_Loss: 0.3222  BEST VAL Loss: 0.3222  Val_Acc: 87.133

Epoch 61: Validation loss decreased (0.322158 --> 0.321602).  Saving model ...
	 Train_Loss: 0.3839 Train_Acc: 85.052 Val_Loss: 0.3216  BEST VAL Loss: 0.3216  Val_Acc: 87.346

Epoch 62: Validation loss decreased (0.321602 --> 0.321136).  Saving model ...
	 Train_Loss: 0.3834 Train_Acc: 85.113 Val_Loss: 0.3211  BEST VAL Loss: 0.3211  Val_Acc: 87.437

Epoch 63: Validation loss decreased (0.321136 --> 0.320644).  Saving model ...
	 Train_Loss: 0.3828 Train_Acc: 85.281 Val_Loss: 0.3206  BEST VAL Loss: 0.3206  Val_Acc: 87.780

Epoch 64: Validation loss decreased (0.320644 --> 0.320228).  Saving model ...
	 Train_Loss: 0.3823 Train_Acc: 85.169 Val_Loss: 0.3202  BEST VAL Loss: 0.3202  Val_Acc: 87.415

Epoch 65: Validation loss decreased (0.320228 --> 0.319670).  Saving model ...
	 Train_Loss: 0.3818 Train_Acc: 85.311 Val_Loss: 0.3197  BEST VAL Loss: 0.3197  Val_Acc: 87.459

Epoch 66: Validation loss decreased (0.319670 --> 0.319180).  Saving model ...
	 Train_Loss: 0.3813 Train_Acc: 85.249 Val_Loss: 0.3192  BEST VAL Loss: 0.3192  Val_Acc: 87.350

Epoch 67: Validation loss decreased (0.319180 --> 0.318911).  Saving model ...
	 Train_Loss: 0.3808 Train_Acc: 85.278 Val_Loss: 0.3189  BEST VAL Loss: 0.3189  Val_Acc: 87.263

Epoch 68: Validation loss decreased (0.318911 --> 0.318460).  Saving model ...
	 Train_Loss: 0.3803 Train_Acc: 85.394 Val_Loss: 0.3185  BEST VAL Loss: 0.3185  Val_Acc: 87.876

Epoch 69: Validation loss decreased (0.318460 --> 0.318089).  Saving model ...
	 Train_Loss: 0.3798 Train_Acc: 85.390 Val_Loss: 0.3181  BEST VAL Loss: 0.3181  Val_Acc: 87.254

Epoch 70: Validation loss decreased (0.318089 --> 0.317614).  Saving model ...
	 Train_Loss: 0.3793 Train_Acc: 85.360 Val_Loss: 0.3176  BEST VAL Loss: 0.3176  Val_Acc: 87.281

Epoch 71: Validation loss decreased (0.317614 --> 0.317253).  Saving model ...
	 Train_Loss: 0.3788 Train_Acc: 85.403 Val_Loss: 0.3173  BEST VAL Loss: 0.3173  Val_Acc: 87.633

Epoch 72: Validation loss decreased (0.317253 --> 0.316865).  Saving model ...
	 Train_Loss: 0.3783 Train_Acc: 85.462 Val_Loss: 0.3169  BEST VAL Loss: 0.3169  Val_Acc: 87.241

Epoch 73: Validation loss decreased (0.316865 --> 0.316500).  Saving model ...
	 Train_Loss: 0.3779 Train_Acc: 85.326 Val_Loss: 0.3165  BEST VAL Loss: 0.3165  Val_Acc: 87.507

Epoch 74: Validation loss decreased (0.316500 --> 0.316087).  Saving model ...
	 Train_Loss: 0.3774 Train_Acc: 85.371 Val_Loss: 0.3161  BEST VAL Loss: 0.3161  Val_Acc: 87.689

Epoch 75: Validation loss decreased (0.316087 --> 0.315695).  Saving model ...
	 Train_Loss: 0.3770 Train_Acc: 85.493 Val_Loss: 0.3157  BEST VAL Loss: 0.3157  Val_Acc: 87.859

Epoch 76: Validation loss decreased (0.315695 --> 0.315352).  Saving model ...
	 Train_Loss: 0.3766 Train_Acc: 85.491 Val_Loss: 0.3154  BEST VAL Loss: 0.3154  Val_Acc: 87.380

Epoch 77: Validation loss decreased (0.315352 --> 0.314981).  Saving model ...
	 Train_Loss: 0.3762 Train_Acc: 85.429 Val_Loss: 0.3150  BEST VAL Loss: 0.3150  Val_Acc: 87.576

Epoch 78: Validation loss decreased (0.314981 --> 0.314580).  Saving model ...
	 Train_Loss: 0.3758 Train_Acc: 85.501 Val_Loss: 0.3146  BEST VAL Loss: 0.3146  Val_Acc: 87.576

Epoch 79: Validation loss decreased (0.314580 --> 0.314250).  Saving model ...
	 Train_Loss: 0.3754 Train_Acc: 85.224 Val_Loss: 0.3142  BEST VAL Loss: 0.3142  Val_Acc: 87.524

Epoch 80: Validation loss decreased (0.314250 --> 0.313995).  Saving model ...
	 Train_Loss: 0.3750 Train_Acc: 85.365 Val_Loss: 0.3140  BEST VAL Loss: 0.3140  Val_Acc: 87.515

Epoch 81: Validation loss decreased (0.313995 --> 0.313715).  Saving model ...
	 Train_Loss: 0.3747 Train_Acc: 85.360 Val_Loss: 0.3137  BEST VAL Loss: 0.3137  Val_Acc: 87.498

Epoch 82: Validation loss decreased (0.313715 --> 0.313385).  Saving model ...
	 Train_Loss: 0.3743 Train_Acc: 85.453 Val_Loss: 0.3134  BEST VAL Loss: 0.3134  Val_Acc: 87.285

Epoch 83: Validation loss decreased (0.313385 --> 0.313077).  Saving model ...
	 Train_Loss: 0.3739 Train_Acc: 85.448 Val_Loss: 0.3131  BEST VAL Loss: 0.3131  Val_Acc: 87.341

Epoch 84: Validation loss decreased (0.313077 --> 0.312785).  Saving model ...
	 Train_Loss: 0.3736 Train_Acc: 85.450 Val_Loss: 0.3128  BEST VAL Loss: 0.3128  Val_Acc: 87.654

Epoch 85: Validation loss decreased (0.312785 --> 0.312576).  Saving model ...
	 Train_Loss: 0.3732 Train_Acc: 85.499 Val_Loss: 0.3126  BEST VAL Loss: 0.3126  Val_Acc: 87.715

Epoch 86: Validation loss decreased (0.312576 --> 0.312380).  Saving model ...
	 Train_Loss: 0.3729 Train_Acc: 85.447 Val_Loss: 0.3124  BEST VAL Loss: 0.3124  Val_Acc: 87.498

Epoch 87: Validation loss decreased (0.312380 --> 0.312085).  Saving model ...
	 Train_Loss: 0.3725 Train_Acc: 85.499 Val_Loss: 0.3121  BEST VAL Loss: 0.3121  Val_Acc: 87.567

Epoch 88: Validation loss decreased (0.312085 --> 0.311894).  Saving model ...
	 Train_Loss: 0.3722 Train_Acc: 85.546 Val_Loss: 0.3119  BEST VAL Loss: 0.3119  Val_Acc: 87.354

Epoch 89: Validation loss decreased (0.311894 --> 0.311588).  Saving model ...
	 Train_Loss: 0.3719 Train_Acc: 85.442 Val_Loss: 0.3116  BEST VAL Loss: 0.3116  Val_Acc: 87.363

Epoch 90: Validation loss decreased (0.311588 --> 0.311262).  Saving model ...
	 Train_Loss: 0.3715 Train_Acc: 85.596 Val_Loss: 0.3113  BEST VAL Loss: 0.3113  Val_Acc: 87.398

Epoch 91: Validation loss decreased (0.311262 --> 0.311049).  Saving model ...
	 Train_Loss: 0.3712 Train_Acc: 85.484 Val_Loss: 0.3110  BEST VAL Loss: 0.3110  Val_Acc: 87.493

Epoch 92: Validation loss decreased (0.311049 --> 0.310850).  Saving model ...
	 Train_Loss: 0.3709 Train_Acc: 85.465 Val_Loss: 0.3109  BEST VAL Loss: 0.3109  Val_Acc: 87.372

Epoch 93: Validation loss decreased (0.310850 --> 0.310526).  Saving model ...
	 Train_Loss: 0.3706 Train_Acc: 85.561 Val_Loss: 0.3105  BEST VAL Loss: 0.3105  Val_Acc: 87.728

Epoch 94: Validation loss decreased (0.310526 --> 0.310243).  Saving model ...
	 Train_Loss: 0.3703 Train_Acc: 85.478 Val_Loss: 0.3102  BEST VAL Loss: 0.3102  Val_Acc: 87.554

Epoch 95: Validation loss decreased (0.310243 --> 0.309968).  Saving model ...
	 Train_Loss: 0.3700 Train_Acc: 85.624 Val_Loss: 0.3100  BEST VAL Loss: 0.3100  Val_Acc: 87.611

Epoch 96: Validation loss decreased (0.309968 --> 0.309650).  Saving model ...
	 Train_Loss: 0.3696 Train_Acc: 85.627 Val_Loss: 0.3097  BEST VAL Loss: 0.3097  Val_Acc: 87.641

Epoch 97: Validation loss decreased (0.309650 --> 0.309374).  Saving model ...
	 Train_Loss: 0.3693 Train_Acc: 85.612 Val_Loss: 0.3094  BEST VAL Loss: 0.3094  Val_Acc: 87.315

Epoch 98: Validation loss decreased (0.309374 --> 0.309178).  Saving model ...
	 Train_Loss: 0.3691 Train_Acc: 85.500 Val_Loss: 0.3092  BEST VAL Loss: 0.3092  Val_Acc: 87.394

Epoch 99: Validation loss decreased (0.309178 --> 0.308811).  Saving model ...
	 Train_Loss: 0.3688 Train_Acc: 85.683 Val_Loss: 0.3088  BEST VAL Loss: 0.3088  Val_Acc: 87.937

Thapsigargin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.50      0.51     95989
           1       0.48      0.50      0.49     88099

    accuracy                           0.50    184088
   macro avg       0.50      0.50      0.50    184088
weighted avg       0.50      0.50      0.50    184088

Thapsigargin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.50      0.51     11999
           1       0.48      0.50      0.49     11013

    accuracy                           0.50     23012
   macro avg       0.50      0.50      0.50     23012
weighted avg       0.50      0.50      0.50     23012

Thapsigargin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.49      0.51     11999
           1       0.48      0.51      0.49     11012

    accuracy                           0.50     23011
   macro avg       0.50      0.50      0.50     23011
weighted avg       0.50      0.50      0.50     23011

              precision    recall  f1-score   support

           0       0.52      0.49      0.51     11999
           1       0.48      0.51      0.49     11012

    accuracy                           0.50     23011
   macro avg       0.50      0.50      0.50     23011
weighted avg       0.50      0.50      0.50     23011

Thapsigargin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.35      0.41     39448
           1       0.49      0.65      0.56     38332

    accuracy                           0.50     77780
   macro avg       0.50      0.50      0.49     77780
weighted avg       0.50      0.50      0.49     77780

              precision    recall  f1-score   support

           0       0.51      0.35      0.41     39448
           1       0.49      0.65      0.56     38332

    accuracy                           0.50     77780
   macro avg       0.50      0.50      0.49     77780
weighted avg       0.50      0.50      0.49     77780

completed
