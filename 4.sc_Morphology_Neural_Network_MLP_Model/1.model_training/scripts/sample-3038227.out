[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd2523e31'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'd212e123'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '572af39b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'abd513b4'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 treatment_name: LPS_10.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
TREATMENT_NAME: LPS_10.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (33028, 1276)
Number of total missing values across all columns: 33620
Data Subset Is Off
Wells held out for testing: ['E20' 'K16']
Wells to use for training, validation, and testing ['E16' 'E17' 'E21' 'K17' 'K20' 'K21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.580752).  Saving model ...
	 Train_Loss: 0.6455 Train_Acc: 62.217 Val_Loss: 0.5808  BEST VAL Loss: 0.5808  Val_Acc: 73.915

Epoch 1: Validation loss decreased (0.580752 --> 0.529760).  Saving model ...
	 Train_Loss: 0.5906 Train_Acc: 76.326 Val_Loss: 0.5298  BEST VAL Loss: 0.5298  Val_Acc: 80.162

Epoch 2: Validation loss decreased (0.529760 --> 0.490503).  Saving model ...
	 Train_Loss: 0.5463 Train_Acc: 80.683 Val_Loss: 0.4905  BEST VAL Loss: 0.4905  Val_Acc: 83.732

Epoch 3: Validation loss decreased (0.490503 --> 0.459033).  Saving model ...
	 Train_Loss: 0.5114 Train_Acc: 83.137 Val_Loss: 0.4590  BEST VAL Loss: 0.4590  Val_Acc: 85.233

Epoch 4: Validation loss decreased (0.459033 --> 0.433192).  Saving model ...
	 Train_Loss: 0.4827 Train_Acc: 84.856 Val_Loss: 0.4332  BEST VAL Loss: 0.4332  Val_Acc: 87.059

Epoch 5: Validation loss decreased (0.433192 --> 0.411304).  Saving model ...
	 Train_Loss: 0.4583 Train_Acc: 86.571 Val_Loss: 0.4113  BEST VAL Loss: 0.4113  Val_Acc: 88.073

Epoch 6: Validation loss decreased (0.411304 --> 0.392516).  Saving model ...
	 Train_Loss: 0.4370 Train_Acc: 87.742 Val_Loss: 0.3925  BEST VAL Loss: 0.3925  Val_Acc: 89.047

Epoch 7: Validation loss decreased (0.392516 --> 0.376099).  Saving model ...
	 Train_Loss: 0.4189 Train_Acc: 88.270 Val_Loss: 0.3761  BEST VAL Loss: 0.3761  Val_Acc: 90.020

Epoch 8: Validation loss decreased (0.376099 --> 0.361665).  Saving model ...
	 Train_Loss: 0.4026 Train_Acc: 89.071 Val_Loss: 0.3617  BEST VAL Loss: 0.3617  Val_Acc: 90.629

Epoch 9: Validation loss decreased (0.361665 --> 0.348775).  Saving model ...
	 Train_Loss: 0.3880 Train_Acc: 89.857 Val_Loss: 0.3488  BEST VAL Loss: 0.3488  Val_Acc: 91.602

Epoch 10: Validation loss decreased (0.348775 --> 0.337142).  Saving model ...
	 Train_Loss: 0.3749 Train_Acc: 90.242 Val_Loss: 0.3371  BEST VAL Loss: 0.3371  Val_Acc: 92.414

Epoch 11: Validation loss decreased (0.337142 --> 0.326626).  Saving model ...
	 Train_Loss: 0.3633 Train_Acc: 90.471 Val_Loss: 0.3266  BEST VAL Loss: 0.3266  Val_Acc: 92.617

Epoch 12: Validation loss decreased (0.326626 --> 0.317059).  Saving model ...
	 Train_Loss: 0.3525 Train_Acc: 91.135 Val_Loss: 0.3171  BEST VAL Loss: 0.3171  Val_Acc: 92.941

Epoch 13: Validation loss decreased (0.317059 --> 0.308311).  Saving model ...
	 Train_Loss: 0.3426 Train_Acc: 91.505 Val_Loss: 0.3083  BEST VAL Loss: 0.3083  Val_Acc: 93.428

Epoch 14: Validation loss decreased (0.308311 --> 0.300189).  Saving model ...
	 Train_Loss: 0.3335 Train_Acc: 91.911 Val_Loss: 0.3002  BEST VAL Loss: 0.3002  Val_Acc: 93.550

Epoch 15: Validation loss decreased (0.300189 --> 0.292804).  Saving model ...
	 Train_Loss: 0.3251 Train_Acc: 92.210 Val_Loss: 0.2928  BEST VAL Loss: 0.2928  Val_Acc: 93.996

Epoch 16: Validation loss decreased (0.292804 --> 0.285919).  Saving model ...
	 Train_Loss: 0.3174 Train_Acc: 92.367 Val_Loss: 0.2859  BEST VAL Loss: 0.2859  Val_Acc: 94.239

Epoch 17: Validation loss decreased (0.285919 --> 0.279513).  Saving model ...
	 Train_Loss: 0.3101 Train_Acc: 92.839 Val_Loss: 0.2795  BEST VAL Loss: 0.2795  Val_Acc: 94.158

Epoch 18: Validation loss decreased (0.279513 --> 0.273572).  Saving model ...
	 Train_Loss: 0.3034 Train_Acc: 93.032 Val_Loss: 0.2736  BEST VAL Loss: 0.2736  Val_Acc: 94.361

Epoch 19: Validation loss decreased (0.273572 --> 0.268041).  Saving model ...
	 Train_Loss: 0.2970 Train_Acc: 93.128 Val_Loss: 0.2680  BEST VAL Loss: 0.2680  Val_Acc: 94.442

Epoch 20: Validation loss decreased (0.268041 --> 0.262870).  Saving model ...
	 Train_Loss: 0.2910 Train_Acc: 93.311 Val_Loss: 0.2629  BEST VAL Loss: 0.2629  Val_Acc: 94.604

Epoch 21: Validation loss decreased (0.262870 --> 0.257996).  Saving model ...
	 Train_Loss: 0.2854 Train_Acc: 93.483 Val_Loss: 0.2580  BEST VAL Loss: 0.2580  Val_Acc: 94.726

Epoch 22: Validation loss decreased (0.257996 --> 0.253438).  Saving model ...
	 Train_Loss: 0.2800 Train_Acc: 93.564 Val_Loss: 0.2534  BEST VAL Loss: 0.2534  Val_Acc: 94.604

Epoch 23: Validation loss decreased (0.253438 --> 0.249177).  Saving model ...
	 Train_Loss: 0.2748 Train_Acc: 93.909 Val_Loss: 0.2492  BEST VAL Loss: 0.2492  Val_Acc: 95.010

Epoch 24: Validation loss decreased (0.249177 --> 0.245199).  Saving model ...
	 Train_Loss: 0.2699 Train_Acc: 93.980 Val_Loss: 0.2452  BEST VAL Loss: 0.2452  Val_Acc: 94.848

Epoch 25: Validation loss decreased (0.245199 --> 0.241459).  Saving model ...
	 Train_Loss: 0.2653 Train_Acc: 94.137 Val_Loss: 0.2415  BEST VAL Loss: 0.2415  Val_Acc: 95.091

Epoch 26: Validation loss decreased (0.241459 --> 0.237864).  Saving model ...
	 Train_Loss: 0.2609 Train_Acc: 94.518 Val_Loss: 0.2379  BEST VAL Loss: 0.2379  Val_Acc: 94.888

Epoch 27: Validation loss decreased (0.237864 --> 0.234526).  Saving model ...
	 Train_Loss: 0.2567 Train_Acc: 94.396 Val_Loss: 0.2345  BEST VAL Loss: 0.2345  Val_Acc: 95.172

Epoch 28: Validation loss decreased (0.234526 --> 0.231310).  Saving model ...
	 Train_Loss: 0.2527 Train_Acc: 94.573 Val_Loss: 0.2313  BEST VAL Loss: 0.2313  Val_Acc: 95.051

Epoch 29: Validation loss decreased (0.231310 --> 0.228307).  Saving model ...
	 Train_Loss: 0.2490 Train_Acc: 94.452 Val_Loss: 0.2283  BEST VAL Loss: 0.2283  Val_Acc: 95.132

Epoch 30: Validation loss decreased (0.228307 --> 0.225419).  Saving model ...
	 Train_Loss: 0.2453 Train_Acc: 94.437 Val_Loss: 0.2254  BEST VAL Loss: 0.2254  Val_Acc: 95.132

Epoch 31: Validation loss decreased (0.225419 --> 0.222675).  Saving model ...
	 Train_Loss: 0.2419 Train_Acc: 94.852 Val_Loss: 0.2227  BEST VAL Loss: 0.2227  Val_Acc: 95.497

Epoch 32: Validation loss decreased (0.222675 --> 0.220048).  Saving model ...
	 Train_Loss: 0.2386 Train_Acc: 94.604 Val_Loss: 0.2200  BEST VAL Loss: 0.2200  Val_Acc: 95.375

Epoch 33: Validation loss decreased (0.220048 --> 0.217557).  Saving model ...
	 Train_Loss: 0.2354 Train_Acc: 94.746 Val_Loss: 0.2176  BEST VAL Loss: 0.2176  Val_Acc: 95.578

Epoch 34: Validation loss decreased (0.217557 --> 0.215141).  Saving model ...
	 Train_Loss: 0.2323 Train_Acc: 95.167 Val_Loss: 0.2151  BEST VAL Loss: 0.2151  Val_Acc: 95.416

Epoch 35: Validation loss decreased (0.215141 --> 0.212857).  Saving model ...
	 Train_Loss: 0.2293 Train_Acc: 95.147 Val_Loss: 0.2129  BEST VAL Loss: 0.2129  Val_Acc: 95.335

Epoch 36: Validation loss decreased (0.212857 --> 0.210702).  Saving model ...
	 Train_Loss: 0.2264 Train_Acc: 95.218 Val_Loss: 0.2107  BEST VAL Loss: 0.2107  Val_Acc: 95.456

Epoch 37: Validation loss decreased (0.210702 --> 0.208603).  Saving model ...
	 Train_Loss: 0.2237 Train_Acc: 95.091 Val_Loss: 0.2086  BEST VAL Loss: 0.2086  Val_Acc: 95.619

Epoch 38: Validation loss decreased (0.208603 --> 0.206594).  Saving model ...
	 Train_Loss: 0.2210 Train_Acc: 95.248 Val_Loss: 0.2066  BEST VAL Loss: 0.2066  Val_Acc: 95.497

Epoch 39: Validation loss decreased (0.206594 --> 0.204637).  Saving model ...
	 Train_Loss: 0.2184 Train_Acc: 95.304 Val_Loss: 0.2046  BEST VAL Loss: 0.2046  Val_Acc: 95.659

Epoch 40: Validation loss decreased (0.204637 --> 0.202762).  Saving model ...
	 Train_Loss: 0.2159 Train_Acc: 95.537 Val_Loss: 0.2028  BEST VAL Loss: 0.2028  Val_Acc: 95.740

Epoch 41: Validation loss decreased (0.202762 --> 0.200960).  Saving model ...
	 Train_Loss: 0.2134 Train_Acc: 95.385 Val_Loss: 0.2010  BEST VAL Loss: 0.2010  Val_Acc: 95.659

Epoch 42: Validation loss decreased (0.200960 --> 0.199248).  Saving model ...
	 Train_Loss: 0.2111 Train_Acc: 95.466 Val_Loss: 0.1992  BEST VAL Loss: 0.1992  Val_Acc: 95.619

Epoch 43: Validation loss decreased (0.199248 --> 0.197611).  Saving model ...
	 Train_Loss: 0.2089 Train_Acc: 95.633 Val_Loss: 0.1976  BEST VAL Loss: 0.1976  Val_Acc: 95.740

Epoch 44: Validation loss decreased (0.197611 --> 0.196008).  Saving model ...
	 Train_Loss: 0.2066 Train_Acc: 95.811 Val_Loss: 0.1960  BEST VAL Loss: 0.1960  Val_Acc: 95.659

Epoch 45: Validation loss decreased (0.196008 --> 0.194465).  Saving model ...
	 Train_Loss: 0.2045 Train_Acc: 95.664 Val_Loss: 0.1945  BEST VAL Loss: 0.1945  Val_Acc: 95.659

Epoch 46: Validation loss decreased (0.194465 --> 0.192961).  Saving model ...
	 Train_Loss: 0.2024 Train_Acc: 95.573 Val_Loss: 0.1930  BEST VAL Loss: 0.1930  Val_Acc: 95.497

Epoch 47: Validation loss decreased (0.192961 --> 0.191510).  Saving model ...
	 Train_Loss: 0.2004 Train_Acc: 95.897 Val_Loss: 0.1915  BEST VAL Loss: 0.1915  Val_Acc: 95.538

Epoch 48: Validation loss decreased (0.191510 --> 0.190117).  Saving model ...
	 Train_Loss: 0.1984 Train_Acc: 95.963 Val_Loss: 0.1901  BEST VAL Loss: 0.1901  Val_Acc: 95.740

Epoch 49: Validation loss decreased (0.190117 --> 0.188764).  Saving model ...
	 Train_Loss: 0.1965 Train_Acc: 95.806 Val_Loss: 0.1888  BEST VAL Loss: 0.1888  Val_Acc: 95.781

Epoch 50: Validation loss decreased (0.188764 --> 0.187446).  Saving model ...
	 Train_Loss: 0.1947 Train_Acc: 95.750 Val_Loss: 0.1874  BEST VAL Loss: 0.1874  Val_Acc: 95.903

Epoch 51: Validation loss decreased (0.187446 --> 0.186169).  Saving model ...
	 Train_Loss: 0.1929 Train_Acc: 95.801 Val_Loss: 0.1862  BEST VAL Loss: 0.1862  Val_Acc: 95.781

Epoch 52: Validation loss decreased (0.186169 --> 0.184952).  Saving model ...
	 Train_Loss: 0.1911 Train_Acc: 95.928 Val_Loss: 0.1850  BEST VAL Loss: 0.1850  Val_Acc: 95.862

Epoch 53: Validation loss decreased (0.184952 --> 0.183770).  Saving model ...
	 Train_Loss: 0.1894 Train_Acc: 95.897 Val_Loss: 0.1838  BEST VAL Loss: 0.1838  Val_Acc: 95.862

Epoch 54: Validation loss decreased (0.183770 --> 0.182649).  Saving model ...
	 Train_Loss: 0.1878 Train_Acc: 95.928 Val_Loss: 0.1826  BEST VAL Loss: 0.1826  Val_Acc: 95.822

Epoch 55: Validation loss decreased (0.182649 --> 0.181533).  Saving model ...
	 Train_Loss: 0.1861 Train_Acc: 96.090 Val_Loss: 0.1815  BEST VAL Loss: 0.1815  Val_Acc: 95.943

Epoch 56: Validation loss decreased (0.181533 --> 0.180452).  Saving model ...
	 Train_Loss: 0.1845 Train_Acc: 96.186 Val_Loss: 0.1805  BEST VAL Loss: 0.1805  Val_Acc: 95.862

Epoch 57: Validation loss decreased (0.180452 --> 0.179410).  Saving model ...
	 Train_Loss: 0.1830 Train_Acc: 95.902 Val_Loss: 0.1794  BEST VAL Loss: 0.1794  Val_Acc: 95.822

Epoch 58: Validation loss decreased (0.179410 --> 0.178385).  Saving model ...
	 Train_Loss: 0.1815 Train_Acc: 96.085 Val_Loss: 0.1784  BEST VAL Loss: 0.1784  Val_Acc: 95.903

Epoch 59: Validation loss decreased (0.178385 --> 0.177397).  Saving model ...
	 Train_Loss: 0.1800 Train_Acc: 96.262 Val_Loss: 0.1774  BEST VAL Loss: 0.1774  Val_Acc: 95.903

Epoch 60: Validation loss decreased (0.177397 --> 0.176438).  Saving model ...
	 Train_Loss: 0.1785 Train_Acc: 96.288 Val_Loss: 0.1764  BEST VAL Loss: 0.1764  Val_Acc: 95.822

Epoch 61: Validation loss decreased (0.176438 --> 0.175519).  Saving model ...
	 Train_Loss: 0.1771 Train_Acc: 96.262 Val_Loss: 0.1755  BEST VAL Loss: 0.1755  Val_Acc: 95.903

Epoch 62: Validation loss decreased (0.175519 --> 0.174622).  Saving model ...
	 Train_Loss: 0.1757 Train_Acc: 96.283 Val_Loss: 0.1746  BEST VAL Loss: 0.1746  Val_Acc: 95.903

Epoch 63: Validation loss decreased (0.174622 --> 0.173734).  Saving model ...
	 Train_Loss: 0.1743 Train_Acc: 96.328 Val_Loss: 0.1737  BEST VAL Loss: 0.1737  Val_Acc: 95.984

Epoch 64: Validation loss decreased (0.173734 --> 0.172902).  Saving model ...
	 Train_Loss: 0.1730 Train_Acc: 96.404 Val_Loss: 0.1729  BEST VAL Loss: 0.1729  Val_Acc: 95.903

Epoch 65: Validation loss decreased (0.172902 --> 0.172087).  Saving model ...
	 Train_Loss: 0.1717 Train_Acc: 96.425 Val_Loss: 0.1721  BEST VAL Loss: 0.1721  Val_Acc: 95.903

Epoch 66: Validation loss decreased (0.172087 --> 0.171304).  Saving model ...
	 Train_Loss: 0.1704 Train_Acc: 96.445 Val_Loss: 0.1713  BEST VAL Loss: 0.1713  Val_Acc: 96.105

Epoch 67: Validation loss decreased (0.171304 --> 0.170525).  Saving model ...
	 Train_Loss: 0.1692 Train_Acc: 96.450 Val_Loss: 0.1705  BEST VAL Loss: 0.1705  Val_Acc: 96.187

Epoch 68: Validation loss decreased (0.170525 --> 0.169800).  Saving model ...
	 Train_Loss: 0.1680 Train_Acc: 96.617 Val_Loss: 0.1698  BEST VAL Loss: 0.1698  Val_Acc: 95.984

Epoch 69: Validation loss decreased (0.169800 --> 0.169062).  Saving model ...
	 Train_Loss: 0.1668 Train_Acc: 96.374 Val_Loss: 0.1691  BEST VAL Loss: 0.1691  Val_Acc: 95.984

Epoch 70: Validation loss decreased (0.169062 --> 0.168349).  Saving model ...
	 Train_Loss: 0.1656 Train_Acc: 96.820 Val_Loss: 0.1683  BEST VAL Loss: 0.1683  Val_Acc: 95.862

Epoch 71: Validation loss decreased (0.168349 --> 0.167636).  Saving model ...
	 Train_Loss: 0.1644 Train_Acc: 96.414 Val_Loss: 0.1676  BEST VAL Loss: 0.1676  Val_Acc: 96.024

Epoch 72: Validation loss decreased (0.167636 --> 0.166941).  Saving model ...
	 Train_Loss: 0.1633 Train_Acc: 96.709 Val_Loss: 0.1669  BEST VAL Loss: 0.1669  Val_Acc: 96.024

Epoch 73: Validation loss decreased (0.166941 --> 0.166279).  Saving model ...
	 Train_Loss: 0.1621 Train_Acc: 96.602 Val_Loss: 0.1663  BEST VAL Loss: 0.1663  Val_Acc: 95.862

Epoch 74: Validation loss decreased (0.166279 --> 0.165629).  Saving model ...
	 Train_Loss: 0.1610 Train_Acc: 96.800 Val_Loss: 0.1656  BEST VAL Loss: 0.1656  Val_Acc: 95.822

Epoch 75: Validation loss decreased (0.165629 --> 0.165003).  Saving model ...
	 Train_Loss: 0.1599 Train_Acc: 96.688 Val_Loss: 0.1650  BEST VAL Loss: 0.1650  Val_Acc: 95.903

Epoch 76: Validation loss decreased (0.165003 --> 0.164385).  Saving model ...
	 Train_Loss: 0.1589 Train_Acc: 96.511 Val_Loss: 0.1644  BEST VAL Loss: 0.1644  Val_Acc: 95.984

Epoch 77: Validation loss decreased (0.164385 --> 0.163781).  Saving model ...
	 Train_Loss: 0.1579 Train_Acc: 96.587 Val_Loss: 0.1638  BEST VAL Loss: 0.1638  Val_Acc: 96.024

Epoch 78: Validation loss decreased (0.163781 --> 0.163189).  Saving model ...
	 Train_Loss: 0.1568 Train_Acc: 96.886 Val_Loss: 0.1632  BEST VAL Loss: 0.1632  Val_Acc: 96.105

Epoch 79: Validation loss decreased (0.163189 --> 0.162619).  Saving model ...
	 Train_Loss: 0.1558 Train_Acc: 96.633 Val_Loss: 0.1626  BEST VAL Loss: 0.1626  Val_Acc: 95.943

Epoch 80: Validation loss decreased (0.162619 --> 0.162062).  Saving model ...
	 Train_Loss: 0.1548 Train_Acc: 96.795 Val_Loss: 0.1621  BEST VAL Loss: 0.1621  Val_Acc: 96.065

Epoch 81: Validation loss decreased (0.162062 --> 0.161506).  Saving model ...
	 Train_Loss: 0.1539 Train_Acc: 96.932 Val_Loss: 0.1615  BEST VAL Loss: 0.1615  Val_Acc: 96.268

Epoch 82: Validation loss decreased (0.161506 --> 0.160957).  Saving model ...
	 Train_Loss: 0.1529 Train_Acc: 96.739 Val_Loss: 0.1610  BEST VAL Loss: 0.1610  Val_Acc: 96.065

Epoch 83: Validation loss decreased (0.160957 --> 0.160426).  Saving model ...
	 Train_Loss: 0.1520 Train_Acc: 96.830 Val_Loss: 0.1604  BEST VAL Loss: 0.1604  Val_Acc: 96.227

Epoch 84: Validation loss decreased (0.160426 --> 0.159909).  Saving model ...
	 Train_Loss: 0.1511 Train_Acc: 96.775 Val_Loss: 0.1599  BEST VAL Loss: 0.1599  Val_Acc: 96.146

Epoch 85: Validation loss decreased (0.159909 --> 0.159433).  Saving model ...
	 Train_Loss: 0.1502 Train_Acc: 96.744 Val_Loss: 0.1594  BEST VAL Loss: 0.1594  Val_Acc: 96.308

Epoch 86: Validation loss decreased (0.159433 --> 0.158945).  Saving model ...
	 Train_Loss: 0.1493 Train_Acc: 96.972 Val_Loss: 0.1589  BEST VAL Loss: 0.1589  Val_Acc: 96.187

Epoch 87: Validation loss decreased (0.158945 --> 0.158450).  Saving model ...
	 Train_Loss: 0.1484 Train_Acc: 96.937 Val_Loss: 0.1585  BEST VAL Loss: 0.1585  Val_Acc: 96.349

Epoch 88: Validation loss decreased (0.158450 --> 0.157980).  Saving model ...
	 Train_Loss: 0.1476 Train_Acc: 96.764 Val_Loss: 0.1580  BEST VAL Loss: 0.1580  Val_Acc: 96.308

Epoch 89: Validation loss decreased (0.157980 --> 0.157517).  Saving model ...
	 Train_Loss: 0.1468 Train_Acc: 96.856 Val_Loss: 0.1575  BEST VAL Loss: 0.1575  Val_Acc: 96.268

Epoch 90: Validation loss decreased (0.157517 --> 0.157062).  Saving model ...
	 Train_Loss: 0.1459 Train_Acc: 96.993 Val_Loss: 0.1571  BEST VAL Loss: 0.1571  Val_Acc: 96.227

Epoch 91: Validation loss decreased (0.157062 --> 0.156599).  Saving model ...
	 Train_Loss: 0.1451 Train_Acc: 96.866 Val_Loss: 0.1566  BEST VAL Loss: 0.1566  Val_Acc: 96.105

Epoch 92: Validation loss decreased (0.156599 --> 0.156160).  Saving model ...
	 Train_Loss: 0.1443 Train_Acc: 96.962 Val_Loss: 0.1562  BEST VAL Loss: 0.1562  Val_Acc: 96.227

Epoch 93: Validation loss decreased (0.156160 --> 0.155732).  Saving model ...
	 Train_Loss: 0.1435 Train_Acc: 96.851 Val_Loss: 0.1557  BEST VAL Loss: 0.1557  Val_Acc: 96.308

Epoch 94: Validation loss decreased (0.155732 --> 0.155307).  Saving model ...
	 Train_Loss: 0.1427 Train_Acc: 97.018 Val_Loss: 0.1553  BEST VAL Loss: 0.1553  Val_Acc: 96.187

Epoch 95: Validation loss decreased (0.155307 --> 0.154902).  Saving model ...
	 Train_Loss: 0.1419 Train_Acc: 97.048 Val_Loss: 0.1549  BEST VAL Loss: 0.1549  Val_Acc: 96.146

Epoch 96: Validation loss decreased (0.154902 --> 0.154491).  Saving model ...
	 Train_Loss: 0.1412 Train_Acc: 97.003 Val_Loss: 0.1545  BEST VAL Loss: 0.1545  Val_Acc: 96.227

Epoch 97: Validation loss decreased (0.154491 --> 0.154085).  Saving model ...
	 Train_Loss: 0.1404 Train_Acc: 97.160 Val_Loss: 0.1541  BEST VAL Loss: 0.1541  Val_Acc: 96.430

Epoch 98: Validation loss decreased (0.154085 --> 0.153686).  Saving model ...
	 Train_Loss: 0.1397 Train_Acc: 97.124 Val_Loss: 0.1537  BEST VAL Loss: 0.1537  Val_Acc: 96.105

Epoch 99: Validation loss decreased (0.153686 --> 0.153292).  Saving model ...
	 Train_Loss: 0.1390 Train_Acc: 97.043 Val_Loss: 0.1533  BEST VAL Loss: 0.1533  Val_Acc: 96.227

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      0.99      0.99     10114
           1       0.99      0.99      0.99      9604

    accuracy                           0.99     19718
   macro avg       0.99      0.99      0.99     19718
weighted avg       0.99      0.99      0.99     19718

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.96      0.96      0.96      1264
           1       0.96      0.96      0.96      1201

    accuracy                           0.96      2465
   macro avg       0.96      0.96      0.96      2465
weighted avg       0.96      0.96      0.96      2465

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.96      0.97      0.96      1264
           1       0.97      0.95      0.96      1201

    accuracy                           0.96      2465
   macro avg       0.96      0.96      0.96      2465
weighted avg       0.96      0.96      0.96      2465

              precision    recall  f1-score   support

           0       0.96      0.97      0.96      1264
           1       0.97      0.95      0.96      1201

    accuracy                           0.96      2465
   macro avg       0.96      0.96      0.96      2465
weighted avg       0.96      0.96      0.96      2465

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.97      0.97      4168
           1       0.97      0.98      0.97      4212

    accuracy                           0.97      8380
   macro avg       0.97      0.97      0.97      8380
weighted avg       0.97      0.97      0.97      8380

              precision    recall  f1-score   support

           0       0.98      0.97      0.97      4168
           1       0.97      0.98      0.97      4212

    accuracy                           0.97      8380
   macro avg       0.97      0.97      0.97      8380
weighted avg       0.97      0.97      0.97      8380

completed
