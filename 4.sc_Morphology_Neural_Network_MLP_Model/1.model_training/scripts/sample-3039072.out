[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '5bb15b93'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '341ed721'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ecf1e4d2'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '1af53e0b'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_10.000_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_10.000_DMSO_0.025']
The dimensions of the data are: (295087, 1270)
Number of total missing values across all columns: 590174
Data Subset Is Off
Wells held out for testing: ['C08' 'E08']
Wells to use for training, validation, and testing ['C02' 'C03' 'C09' 'E02' 'E03' 'E09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.626077).  Saving model ...
	 Train_Loss: 0.6621 Train_Acc: 60.206 Val_Loss: 0.6261  BEST VAL Loss: 0.6261  Val_Acc: 64.294

Epoch 1: Validation loss decreased (0.626077 --> 0.615348).  Saving model ...
	 Train_Loss: 0.6425 Train_Acc: 64.344 Val_Loss: 0.6153  BEST VAL Loss: 0.6153  Val_Acc: 66.677

Epoch 2: Validation loss decreased (0.615348 --> 0.609402).  Saving model ...
	 Train_Loss: 0.6312 Train_Acc: 65.893 Val_Loss: 0.6094  BEST VAL Loss: 0.6094  Val_Acc: 67.460

Epoch 3: Validation loss decreased (0.609402 --> 0.603359).  Saving model ...
	 Train_Loss: 0.6237 Train_Acc: 66.748 Val_Loss: 0.6034  BEST VAL Loss: 0.6034  Val_Acc: 68.132

Epoch 4: Validation loss decreased (0.603359 --> 0.599869).  Saving model ...
	 Train_Loss: 0.6179 Train_Acc: 67.302 Val_Loss: 0.5999  BEST VAL Loss: 0.5999  Val_Acc: 68.265

Epoch 5: Validation loss decreased (0.599869 --> 0.597095).  Saving model ...
	 Train_Loss: 0.6136 Train_Acc: 67.674 Val_Loss: 0.5971  BEST VAL Loss: 0.5971  Val_Acc: 68.754

Epoch 6: Validation loss decreased (0.597095 --> 0.594032).  Saving model ...
	 Train_Loss: 0.6096 Train_Acc: 68.077 Val_Loss: 0.5940  BEST VAL Loss: 0.5940  Val_Acc: 69.093

Epoch 7: Validation loss decreased (0.594032 --> 0.591763).  Saving model ...
	 Train_Loss: 0.6064 Train_Acc: 68.400 Val_Loss: 0.5918  BEST VAL Loss: 0.5918  Val_Acc: 69.061

Epoch 8: Validation loss decreased (0.591763 --> 0.589951).  Saving model ...
	 Train_Loss: 0.6035 Train_Acc: 68.680 Val_Loss: 0.5900  BEST VAL Loss: 0.5900  Val_Acc: 69.258

Epoch 9: Validation loss decreased (0.589951 --> 0.588109).  Saving model ...
	 Train_Loss: 0.6010 Train_Acc: 68.671 Val_Loss: 0.5881  BEST VAL Loss: 0.5881  Val_Acc: 69.372

Epoch 10: Validation loss decreased (0.588109 --> 0.586496).  Saving model ...
	 Train_Loss: 0.5989 Train_Acc: 68.822 Val_Loss: 0.5865  BEST VAL Loss: 0.5865  Val_Acc: 69.591

Epoch 11: Validation loss decreased (0.586496 --> 0.585090).  Saving model ...
	 Train_Loss: 0.5970 Train_Acc: 68.915 Val_Loss: 0.5851  BEST VAL Loss: 0.5851  Val_Acc: 69.701

Epoch 12: Validation loss decreased (0.585090 --> 0.583742).  Saving model ...
	 Train_Loss: 0.5953 Train_Acc: 69.120 Val_Loss: 0.5837  BEST VAL Loss: 0.5837  Val_Acc: 69.957

Epoch 13: Validation loss decreased (0.583742 --> 0.582384).  Saving model ...
	 Train_Loss: 0.5937 Train_Acc: 69.168 Val_Loss: 0.5824  BEST VAL Loss: 0.5824  Val_Acc: 70.049

Epoch 14: Validation loss decreased (0.582384 --> 0.581340).  Saving model ...
	 Train_Loss: 0.5922 Train_Acc: 69.333 Val_Loss: 0.5813  BEST VAL Loss: 0.5813  Val_Acc: 69.784

Epoch 15: Validation loss decreased (0.581340 --> 0.580339).  Saving model ...
	 Train_Loss: 0.5909 Train_Acc: 69.230 Val_Loss: 0.5803  BEST VAL Loss: 0.5803  Val_Acc: 70.182

Epoch 16: Validation loss decreased (0.580339 --> 0.579362).  Saving model ...
	 Train_Loss: 0.5897 Train_Acc: 69.328 Val_Loss: 0.5794  BEST VAL Loss: 0.5794  Val_Acc: 70.182

Epoch 17: Validation loss decreased (0.579362 --> 0.578440).  Saving model ...
	 Train_Loss: 0.5886 Train_Acc: 69.341 Val_Loss: 0.5784  BEST VAL Loss: 0.5784  Val_Acc: 70.118

Epoch 18: Validation loss decreased (0.578440 --> 0.577611).  Saving model ...
	 Train_Loss: 0.5875 Train_Acc: 69.442 Val_Loss: 0.5776  BEST VAL Loss: 0.5776  Val_Acc: 70.365

Epoch 19: Validation loss decreased (0.577611 --> 0.576858).  Saving model ...
	 Train_Loss: 0.5865 Train_Acc: 69.559 Val_Loss: 0.5769  BEST VAL Loss: 0.5769  Val_Acc: 70.227

Epoch 20: Validation loss decreased (0.576858 --> 0.576229).  Saving model ...
	 Train_Loss: 0.5856 Train_Acc: 69.595 Val_Loss: 0.5762  BEST VAL Loss: 0.5762  Val_Acc: 70.237

Epoch 21: Validation loss decreased (0.576229 --> 0.575511).  Saving model ...
	 Train_Loss: 0.5847 Train_Acc: 69.466 Val_Loss: 0.5755  BEST VAL Loss: 0.5755  Val_Acc: 70.516

Epoch 22: Validation loss decreased (0.575511 --> 0.574857).  Saving model ...
	 Train_Loss: 0.5838 Train_Acc: 69.786 Val_Loss: 0.5749  BEST VAL Loss: 0.5749  Val_Acc: 70.182

Epoch 23: Validation loss decreased (0.574857 --> 0.574204).  Saving model ...
	 Train_Loss: 0.5831 Train_Acc: 69.707 Val_Loss: 0.5742  BEST VAL Loss: 0.5742  Val_Acc: 70.406

Epoch 24: Validation loss decreased (0.574204 --> 0.573517).  Saving model ...
	 Train_Loss: 0.5823 Train_Acc: 69.844 Val_Loss: 0.5735  BEST VAL Loss: 0.5735  Val_Acc: 70.877

Epoch 25: Validation loss decreased (0.573517 --> 0.572890).  Saving model ...
	 Train_Loss: 0.5816 Train_Acc: 69.746 Val_Loss: 0.5729  BEST VAL Loss: 0.5729  Val_Acc: 70.465

Epoch 26: Validation loss decreased (0.572890 --> 0.572291).  Saving model ...
	 Train_Loss: 0.5810 Train_Acc: 69.804 Val_Loss: 0.5723  BEST VAL Loss: 0.5723  Val_Acc: 70.785

Epoch 27: Validation loss decreased (0.572291 --> 0.571633).  Saving model ...
	 Train_Loss: 0.5803 Train_Acc: 69.846 Val_Loss: 0.5716  BEST VAL Loss: 0.5716  Val_Acc: 70.731

Epoch 28: Validation loss decreased (0.571633 --> 0.571210).  Saving model ...
	 Train_Loss: 0.5797 Train_Acc: 69.942 Val_Loss: 0.5712  BEST VAL Loss: 0.5712  Val_Acc: 70.584

Epoch 29: Validation loss decreased (0.571210 --> 0.570714).  Saving model ...
	 Train_Loss: 0.5791 Train_Acc: 69.944 Val_Loss: 0.5707  BEST VAL Loss: 0.5707  Val_Acc: 70.804

Epoch 30: Validation loss decreased (0.570714 --> 0.570221).  Saving model ...
	 Train_Loss: 0.5786 Train_Acc: 69.927 Val_Loss: 0.5702  BEST VAL Loss: 0.5702  Val_Acc: 70.850

Epoch 31: Validation loss decreased (0.570221 --> 0.569693).  Saving model ...
	 Train_Loss: 0.5780 Train_Acc: 70.074 Val_Loss: 0.5697  BEST VAL Loss: 0.5697  Val_Acc: 70.982

Epoch 32: Validation loss decreased (0.569693 --> 0.569237).  Saving model ...
	 Train_Loss: 0.5775 Train_Acc: 69.905 Val_Loss: 0.5692  BEST VAL Loss: 0.5692  Val_Acc: 71.010

Epoch 33: Validation loss decreased (0.569237 --> 0.568809).  Saving model ...
	 Train_Loss: 0.5770 Train_Acc: 70.128 Val_Loss: 0.5688  BEST VAL Loss: 0.5688  Val_Acc: 70.822

Epoch 34: Validation loss decreased (0.568809 --> 0.568371).  Saving model ...
	 Train_Loss: 0.5765 Train_Acc: 70.112 Val_Loss: 0.5684  BEST VAL Loss: 0.5684  Val_Acc: 70.955

Epoch 35: Validation loss decreased (0.568371 --> 0.567925).  Saving model ...
	 Train_Loss: 0.5760 Train_Acc: 70.167 Val_Loss: 0.5679  BEST VAL Loss: 0.5679  Val_Acc: 70.932

Epoch 36: Validation loss decreased (0.567925 --> 0.567508).  Saving model ...
	 Train_Loss: 0.5755 Train_Acc: 70.252 Val_Loss: 0.5675  BEST VAL Loss: 0.5675  Val_Acc: 70.804

Epoch 37: Validation loss decreased (0.567508 --> 0.567105).  Saving model ...
	 Train_Loss: 0.5751 Train_Acc: 70.114 Val_Loss: 0.5671  BEST VAL Loss: 0.5671  Val_Acc: 71.065

Epoch 38: Validation loss decreased (0.567105 --> 0.566709).  Saving model ...
	 Train_Loss: 0.5746 Train_Acc: 70.193 Val_Loss: 0.5667  BEST VAL Loss: 0.5667  Val_Acc: 70.863

Epoch 39: Validation loss decreased (0.566709 --> 0.566360).  Saving model ...
	 Train_Loss: 0.5742 Train_Acc: 70.251 Val_Loss: 0.5664  BEST VAL Loss: 0.5664  Val_Acc: 70.781

Epoch 40: Validation loss decreased (0.566360 --> 0.566017).  Saving model ...
	 Train_Loss: 0.5738 Train_Acc: 70.221 Val_Loss: 0.5660  BEST VAL Loss: 0.5660  Val_Acc: 70.927

Epoch 41: Validation loss decreased (0.566017 --> 0.565680).  Saving model ...
	 Train_Loss: 0.5735 Train_Acc: 70.289 Val_Loss: 0.5657  BEST VAL Loss: 0.5657  Val_Acc: 70.877

Epoch 42: Validation loss decreased (0.565680 --> 0.565372).  Saving model ...
	 Train_Loss: 0.5731 Train_Acc: 70.382 Val_Loss: 0.5654  BEST VAL Loss: 0.5654  Val_Acc: 70.795

Epoch 43: Validation loss decreased (0.565372 --> 0.565097).  Saving model ...
	 Train_Loss: 0.5727 Train_Acc: 70.260 Val_Loss: 0.5651  BEST VAL Loss: 0.5651  Val_Acc: 70.891

Epoch 44: Validation loss decreased (0.565097 --> 0.564860).  Saving model ...
	 Train_Loss: 0.5724 Train_Acc: 70.359 Val_Loss: 0.5649  BEST VAL Loss: 0.5649  Val_Acc: 70.763

Epoch 45: Validation loss decreased (0.564860 --> 0.564557).  Saving model ...
	 Train_Loss: 0.5720 Train_Acc: 70.337 Val_Loss: 0.5646  BEST VAL Loss: 0.5646  Val_Acc: 70.923

Epoch 46: Validation loss decreased (0.564557 --> 0.564291).  Saving model ...
	 Train_Loss: 0.5716 Train_Acc: 70.403 Val_Loss: 0.5643  BEST VAL Loss: 0.5643  Val_Acc: 70.763

Epoch 47: Validation loss decreased (0.564291 --> 0.564022).  Saving model ...
	 Train_Loss: 0.5713 Train_Acc: 70.327 Val_Loss: 0.5640  BEST VAL Loss: 0.5640  Val_Acc: 71.188

Epoch 48: Validation loss decreased (0.564022 --> 0.563795).  Saving model ...
	 Train_Loss: 0.5710 Train_Acc: 70.467 Val_Loss: 0.5638  BEST VAL Loss: 0.5638  Val_Acc: 70.868

Epoch 49: Validation loss decreased (0.563795 --> 0.563555).  Saving model ...
	 Train_Loss: 0.5707 Train_Acc: 70.367 Val_Loss: 0.5636  BEST VAL Loss: 0.5636  Val_Acc: 70.982

Epoch 50: Validation loss decreased (0.563555 --> 0.563338).  Saving model ...
	 Train_Loss: 0.5704 Train_Acc: 70.509 Val_Loss: 0.5633  BEST VAL Loss: 0.5633  Val_Acc: 71.206

Epoch 51: Validation loss decreased (0.563338 --> 0.563135).  Saving model ...
	 Train_Loss: 0.5701 Train_Acc: 70.455 Val_Loss: 0.5631  BEST VAL Loss: 0.5631  Val_Acc: 70.955

Epoch 52: Validation loss decreased (0.563135 --> 0.562893).  Saving model ...
	 Train_Loss: 0.5698 Train_Acc: 70.354 Val_Loss: 0.5629  BEST VAL Loss: 0.5629  Val_Acc: 71.083

Epoch 53: Validation loss decreased (0.562893 --> 0.562647).  Saving model ...
	 Train_Loss: 0.5695 Train_Acc: 70.569 Val_Loss: 0.5626  BEST VAL Loss: 0.5626  Val_Acc: 71.101

Epoch 54: Validation loss decreased (0.562647 --> 0.562439).  Saving model ...
	 Train_Loss: 0.5692 Train_Acc: 70.483 Val_Loss: 0.5624  BEST VAL Loss: 0.5624  Val_Acc: 71.243

Epoch 55: Validation loss decreased (0.562439 --> 0.562267).  Saving model ...
	 Train_Loss: 0.5690 Train_Acc: 70.534 Val_Loss: 0.5623  BEST VAL Loss: 0.5623  Val_Acc: 71.055

Epoch 56: Validation loss decreased (0.562267 --> 0.561994).  Saving model ...
	 Train_Loss: 0.5687 Train_Acc: 70.630 Val_Loss: 0.5620  BEST VAL Loss: 0.5620  Val_Acc: 71.458

Epoch 57: Validation loss decreased (0.561994 --> 0.561781).  Saving model ...
	 Train_Loss: 0.5684 Train_Acc: 70.646 Val_Loss: 0.5618  BEST VAL Loss: 0.5618  Val_Acc: 71.087

Epoch 58: Validation loss decreased (0.561781 --> 0.561578).  Saving model ...
	 Train_Loss: 0.5681 Train_Acc: 70.687 Val_Loss: 0.5616  BEST VAL Loss: 0.5616  Val_Acc: 71.101

Epoch 59: Validation loss decreased (0.561578 --> 0.561390).  Saving model ...
	 Train_Loss: 0.5679 Train_Acc: 70.585 Val_Loss: 0.5614  BEST VAL Loss: 0.5614  Val_Acc: 71.220

Epoch 60: Validation loss decreased (0.561390 --> 0.561192).  Saving model ...
	 Train_Loss: 0.5676 Train_Acc: 70.639 Val_Loss: 0.5612  BEST VAL Loss: 0.5612  Val_Acc: 71.270

Epoch 61: Validation loss decreased (0.561192 --> 0.560993).  Saving model ...
	 Train_Loss: 0.5674 Train_Acc: 70.632 Val_Loss: 0.5610  BEST VAL Loss: 0.5610  Val_Acc: 71.270

Epoch 62: Validation loss decreased (0.560993 --> 0.560822).  Saving model ...
	 Train_Loss: 0.5672 Train_Acc: 70.659 Val_Loss: 0.5608  BEST VAL Loss: 0.5608  Val_Acc: 71.069

Epoch 63: Validation loss decreased (0.560822 --> 0.560671).  Saving model ...
	 Train_Loss: 0.5669 Train_Acc: 70.601 Val_Loss: 0.5607  BEST VAL Loss: 0.5607  Val_Acc: 71.005

Epoch 64: Validation loss decreased (0.560671 --> 0.560470).  Saving model ...
	 Train_Loss: 0.5667 Train_Acc: 70.735 Val_Loss: 0.5605  BEST VAL Loss: 0.5605  Val_Acc: 71.440

Epoch 65: Validation loss decreased (0.560470 --> 0.560305).  Saving model ...
	 Train_Loss: 0.5665 Train_Acc: 70.624 Val_Loss: 0.5603  BEST VAL Loss: 0.5603  Val_Acc: 70.991

Epoch 66: Validation loss decreased (0.560305 --> 0.560115).  Saving model ...
	 Train_Loss: 0.5663 Train_Acc: 70.674 Val_Loss: 0.5601  BEST VAL Loss: 0.5601  Val_Acc: 71.234

Epoch 67: Validation loss decreased (0.560115 --> 0.559978).  Saving model ...
	 Train_Loss: 0.5661 Train_Acc: 70.652 Val_Loss: 0.5600  BEST VAL Loss: 0.5600  Val_Acc: 71.097

Epoch 68: Validation loss decreased (0.559978 --> 0.559796).  Saving model ...
	 Train_Loss: 0.5659 Train_Acc: 70.671 Val_Loss: 0.5598  BEST VAL Loss: 0.5598  Val_Acc: 71.248

Epoch 69: Validation loss decreased (0.559796 --> 0.559606).  Saving model ...
	 Train_Loss: 0.5656 Train_Acc: 70.736 Val_Loss: 0.5596  BEST VAL Loss: 0.5596  Val_Acc: 71.394

Epoch 70: Validation loss decreased (0.559606 --> 0.559413).  Saving model ...
	 Train_Loss: 0.5654 Train_Acc: 70.715 Val_Loss: 0.5594  BEST VAL Loss: 0.5594  Val_Acc: 71.202

Epoch 71: Validation loss decreased (0.559413 --> 0.559193).  Saving model ...
	 Train_Loss: 0.5652 Train_Acc: 70.736 Val_Loss: 0.5592  BEST VAL Loss: 0.5592  Val_Acc: 71.668

Epoch 72: Validation loss decreased (0.559193 --> 0.559053).  Saving model ...
	 Train_Loss: 0.5650 Train_Acc: 70.727 Val_Loss: 0.5591  BEST VAL Loss: 0.5591  Val_Acc: 71.280

Epoch 73: Validation loss decreased (0.559053 --> 0.558874).  Saving model ...
	 Train_Loss: 0.5648 Train_Acc: 70.796 Val_Loss: 0.5589  BEST VAL Loss: 0.5589  Val_Acc: 71.334

Epoch 74: Validation loss decreased (0.558874 --> 0.558737).  Saving model ...
	 Train_Loss: 0.5647 Train_Acc: 70.880 Val_Loss: 0.5587  BEST VAL Loss: 0.5587  Val_Acc: 71.289

Epoch 75: Validation loss decreased (0.558737 --> 0.558578).  Saving model ...
	 Train_Loss: 0.5645 Train_Acc: 70.751 Val_Loss: 0.5586  BEST VAL Loss: 0.5586  Val_Acc: 71.412

Epoch 76: Validation loss decreased (0.558578 --> 0.558431).  Saving model ...
	 Train_Loss: 0.5643 Train_Acc: 70.878 Val_Loss: 0.5584  BEST VAL Loss: 0.5584  Val_Acc: 71.412

Epoch 77: Validation loss decreased (0.558431 --> 0.558333).  Saving model ...
	 Train_Loss: 0.5641 Train_Acc: 70.879 Val_Loss: 0.5583  BEST VAL Loss: 0.5583  Val_Acc: 71.261

Epoch 78: Validation loss decreased (0.558333 --> 0.558201).  Saving model ...
	 Train_Loss: 0.5639 Train_Acc: 70.852 Val_Loss: 0.5582  BEST VAL Loss: 0.5582  Val_Acc: 71.252

Epoch 79: Validation loss decreased (0.558201 --> 0.558071).  Saving model ...
	 Train_Loss: 0.5637 Train_Acc: 70.822 Val_Loss: 0.5581  BEST VAL Loss: 0.5581  Val_Acc: 71.298

Epoch 80: Validation loss decreased (0.558071 --> 0.557917).  Saving model ...
	 Train_Loss: 0.5636 Train_Acc: 70.708 Val_Loss: 0.5579  BEST VAL Loss: 0.5579  Val_Acc: 71.549

Epoch 81: Validation loss decreased (0.557917 --> 0.557781).  Saving model ...
	 Train_Loss: 0.5634 Train_Acc: 70.910 Val_Loss: 0.5578  BEST VAL Loss: 0.5578  Val_Acc: 71.426

Epoch 82: Validation loss decreased (0.557781 --> 0.557649).  Saving model ...
	 Train_Loss: 0.5632 Train_Acc: 70.842 Val_Loss: 0.5576  BEST VAL Loss: 0.5576  Val_Acc: 71.051

Epoch 83: Validation loss decreased (0.557649 --> 0.557544).  Saving model ...
	 Train_Loss: 0.5630 Train_Acc: 70.836 Val_Loss: 0.5575  BEST VAL Loss: 0.5575  Val_Acc: 71.188

Epoch 84: Validation loss decreased (0.557544 --> 0.557403).  Saving model ...
	 Train_Loss: 0.5629 Train_Acc: 70.763 Val_Loss: 0.5574  BEST VAL Loss: 0.5574  Val_Acc: 71.312

Epoch 85: Validation loss decreased (0.557403 --> 0.557279).  Saving model ...
	 Train_Loss: 0.5627 Train_Acc: 70.863 Val_Loss: 0.5573  BEST VAL Loss: 0.5573  Val_Acc: 71.229

Epoch 86: Validation loss decreased (0.557279 --> 0.557121).  Saving model ...
	 Train_Loss: 0.5626 Train_Acc: 70.967 Val_Loss: 0.5571  BEST VAL Loss: 0.5571  Val_Acc: 71.508

Epoch 87: Validation loss decreased (0.557121 --> 0.557019).  Saving model ...
	 Train_Loss: 0.5624 Train_Acc: 70.952 Val_Loss: 0.5570  BEST VAL Loss: 0.5570  Val_Acc: 71.138

Epoch 88: Validation loss decreased (0.557019 --> 0.556895).  Saving model ...
	 Train_Loss: 0.5623 Train_Acc: 70.870 Val_Loss: 0.5569  BEST VAL Loss: 0.5569  Val_Acc: 71.334

Epoch 89: Validation loss decreased (0.556895 --> 0.556804).  Saving model ...
	 Train_Loss: 0.5621 Train_Acc: 70.990 Val_Loss: 0.5568  BEST VAL Loss: 0.5568  Val_Acc: 71.408

Epoch 90: Validation loss decreased (0.556804 --> 0.556720).  Saving model ...
	 Train_Loss: 0.5619 Train_Acc: 70.930 Val_Loss: 0.5567  BEST VAL Loss: 0.5567  Val_Acc: 71.339

Epoch 91: Validation loss decreased (0.556720 --> 0.556637).  Saving model ...
	 Train_Loss: 0.5618 Train_Acc: 70.912 Val_Loss: 0.5566  BEST VAL Loss: 0.5566  Val_Acc: 71.412

Epoch 92: Validation loss decreased (0.556637 --> 0.556554).  Saving model ...
	 Train_Loss: 0.5617 Train_Acc: 70.876 Val_Loss: 0.5566  BEST VAL Loss: 0.5566  Val_Acc: 71.330

Epoch 93: Validation loss decreased (0.556554 --> 0.556486).  Saving model ...
	 Train_Loss: 0.5615 Train_Acc: 70.904 Val_Loss: 0.5565  BEST VAL Loss: 0.5565  Val_Acc: 71.330

Epoch 94: Validation loss decreased (0.556486 --> 0.556364).  Saving model ...
	 Train_Loss: 0.5614 Train_Acc: 70.934 Val_Loss: 0.5564  BEST VAL Loss: 0.5564  Val_Acc: 71.362

Epoch 95: Validation loss decreased (0.556364 --> 0.556284).  Saving model ...
	 Train_Loss: 0.5612 Train_Acc: 71.127 Val_Loss: 0.5563  BEST VAL Loss: 0.5563  Val_Acc: 71.330

Epoch 96: Validation loss decreased (0.556284 --> 0.556180).  Saving model ...
	 Train_Loss: 0.5611 Train_Acc: 71.007 Val_Loss: 0.5562  BEST VAL Loss: 0.5562  Val_Acc: 71.650

Epoch 97: Validation loss decreased (0.556180 --> 0.556080).  Saving model ...
	 Train_Loss: 0.5609 Train_Acc: 71.000 Val_Loss: 0.5561  BEST VAL Loss: 0.5561  Val_Acc: 71.257

Epoch 98: Validation loss decreased (0.556080 --> 0.555975).  Saving model ...
	 Train_Loss: 0.5608 Train_Acc: 71.062 Val_Loss: 0.5560  BEST VAL Loss: 0.5560  Val_Acc: 71.421

Epoch 99: Validation loss decreased (0.555975 --> 0.555864).  Saving model ...
	 Train_Loss: 0.5607 Train_Acc: 70.894 Val_Loss: 0.5559  BEST VAL Loss: 0.5559  Val_Acc: 71.485

LPS_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.81      0.58      0.67     82968
           1       0.70      0.88      0.78     91897

    accuracy                           0.73    174865
   macro avg       0.75      0.73      0.73    174865
weighted avg       0.75      0.73      0.73    174865

LPS_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.78      0.56      0.65     10371
           1       0.68      0.86      0.76     11488

    accuracy                           0.71     21859
   macro avg       0.73      0.71      0.70     21859
weighted avg       0.73      0.71      0.71     21859

LPS_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.77      0.55      0.64     10371
           1       0.68      0.85      0.76     11488

    accuracy                           0.71     21859
   macro avg       0.73      0.70      0.70     21859
weighted avg       0.72      0.71      0.70     21859

              precision    recall  f1-score   support

           0       0.77      0.55      0.64     10371
           1       0.68      0.85      0.76     11488

    accuracy                           0.71     21859
   macro avg       0.73      0.70      0.70     21859
weighted avg       0.72      0.71      0.70     21859

LPS_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.51      0.34      0.41     34887
           1       0.57      0.73      0.64     41617

    accuracy                           0.55     76504
   macro avg       0.54      0.53      0.52     76504
weighted avg       0.54      0.55      0.53     76504

              precision    recall  f1-score   support

           0       0.51      0.34      0.41     34887
           1       0.57      0.73      0.64     41617

    accuracy                           0.55     76504
   macro avg       0.54      0.53      0.52     76504
weighted avg       0.54      0.55      0.53     76504

completed
