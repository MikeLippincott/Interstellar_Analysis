[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '98ed26de'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'f0234f8c'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'c82665c9'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '85d21387'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 treatment_name: H2O2_100.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
TREATMENT_NAME: H2O2_100.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['H2O2_100.000_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (406549, 1270)
Number of total missing values across all columns: 481072
Data Subset Is Off
Wells held out for testing: ['I10' 'K08']
Wells to use for training, validation, and testing ['H04' 'I04' 'H05' 'I05' 'H10' 'H11' 'I11' 'K02' 'K03' 'K09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.379832).  Saving model ...
	 Train_Loss: 0.4724 Train_Acc: 78.819 Val_Loss: 0.3798  BEST VAL Loss: 0.3798  Val_Acc: 84.068

Epoch 1: Validation loss decreased (0.379832 --> 0.352666).  Saving model ...
	 Train_Loss: 0.4209 Train_Acc: 83.841 Val_Loss: 0.3527  BEST VAL Loss: 0.3527  Val_Acc: 86.108

Epoch 2: Validation loss decreased (0.352666 --> 0.334361).  Saving model ...
	 Train_Loss: 0.3911 Train_Acc: 85.656 Val_Loss: 0.3344  BEST VAL Loss: 0.3344  Val_Acc: 87.353

Epoch 3: Validation loss decreased (0.334361 --> 0.320740).  Saving model ...
	 Train_Loss: 0.3709 Train_Acc: 86.552 Val_Loss: 0.3207  BEST VAL Loss: 0.3207  Val_Acc: 88.123

Epoch 4: Validation loss decreased (0.320740 --> 0.310118).  Saving model ...
	 Train_Loss: 0.3558 Train_Acc: 87.239 Val_Loss: 0.3101  BEST VAL Loss: 0.3101  Val_Acc: 88.710

Epoch 5: Validation loss decreased (0.310118 --> 0.301544).  Saving model ...
	 Train_Loss: 0.3439 Train_Acc: 87.771 Val_Loss: 0.3015  BEST VAL Loss: 0.3015  Val_Acc: 89.078

Epoch 6: Validation loss decreased (0.301544 --> 0.294357).  Saving model ...
	 Train_Loss: 0.3342 Train_Acc: 88.151 Val_Loss: 0.2944  BEST VAL Loss: 0.2944  Val_Acc: 89.436

Epoch 7: Validation loss decreased (0.294357 --> 0.288246).  Saving model ...
	 Train_Loss: 0.3262 Train_Acc: 88.503 Val_Loss: 0.2882  BEST VAL Loss: 0.2882  Val_Acc: 89.638

Epoch 8: Validation loss decreased (0.288246 --> 0.282985).  Saving model ...
	 Train_Loss: 0.3193 Train_Acc: 88.737 Val_Loss: 0.2830  BEST VAL Loss: 0.2830  Val_Acc: 89.919

Epoch 9: Validation loss decreased (0.282985 --> 0.278321).  Saving model ...
	 Train_Loss: 0.3133 Train_Acc: 88.970 Val_Loss: 0.2783  BEST VAL Loss: 0.2783  Val_Acc: 90.142

Epoch 10: Validation loss decreased (0.278321 --> 0.274107).  Saving model ...
	 Train_Loss: 0.3080 Train_Acc: 89.179 Val_Loss: 0.2741  BEST VAL Loss: 0.2741  Val_Acc: 90.325

Epoch 11: Validation loss decreased (0.274107 --> 0.270329).  Saving model ...
	 Train_Loss: 0.3033 Train_Acc: 89.323 Val_Loss: 0.2703  BEST VAL Loss: 0.2703  Val_Acc: 90.494

Epoch 12: Validation loss decreased (0.270329 --> 0.266869).  Saving model ...
	 Train_Loss: 0.2991 Train_Acc: 89.541 Val_Loss: 0.2669  BEST VAL Loss: 0.2669  Val_Acc: 90.654

Epoch 13: Validation loss decreased (0.266869 --> 0.263666).  Saving model ...
	 Train_Loss: 0.2951 Train_Acc: 89.635 Val_Loss: 0.2637  BEST VAL Loss: 0.2637  Val_Acc: 90.806

Epoch 14: Validation loss decreased (0.263666 --> 0.260764).  Saving model ...
	 Train_Loss: 0.2916 Train_Acc: 89.765 Val_Loss: 0.2608  BEST VAL Loss: 0.2608  Val_Acc: 90.865

Epoch 15: Validation loss decreased (0.260764 --> 0.258055).  Saving model ...
	 Train_Loss: 0.2884 Train_Acc: 89.798 Val_Loss: 0.2581  BEST VAL Loss: 0.2581  Val_Acc: 91.016

Epoch 16: Validation loss decreased (0.258055 --> 0.255527).  Saving model ...
	 Train_Loss: 0.2854 Train_Acc: 89.950 Val_Loss: 0.2555  BEST VAL Loss: 0.2555  Val_Acc: 91.244

Epoch 17: Validation loss decreased (0.255527 --> 0.253203).  Saving model ...
	 Train_Loss: 0.2826 Train_Acc: 90.060 Val_Loss: 0.2532  BEST VAL Loss: 0.2532  Val_Acc: 91.191

Epoch 18: Validation loss decreased (0.253203 --> 0.251001).  Saving model ...
	 Train_Loss: 0.2800 Train_Acc: 90.086 Val_Loss: 0.2510  BEST VAL Loss: 0.2510  Val_Acc: 91.345

Epoch 19: Validation loss decreased (0.251001 --> 0.248935).  Saving model ...
	 Train_Loss: 0.2776 Train_Acc: 90.185 Val_Loss: 0.2489  BEST VAL Loss: 0.2489  Val_Acc: 91.392

Epoch 20: Validation loss decreased (0.248935 --> 0.247004).  Saving model ...
	 Train_Loss: 0.2753 Train_Acc: 90.287 Val_Loss: 0.2470  BEST VAL Loss: 0.2470  Val_Acc: 91.422

Epoch 21: Validation loss decreased (0.247004 --> 0.245183).  Saving model ...
	 Train_Loss: 0.2731 Train_Acc: 90.355 Val_Loss: 0.2452  BEST VAL Loss: 0.2452  Val_Acc: 91.475

Epoch 22: Validation loss decreased (0.245183 --> 0.243456).  Saving model ...
	 Train_Loss: 0.2711 Train_Acc: 90.394 Val_Loss: 0.2435  BEST VAL Loss: 0.2435  Val_Acc: 91.636

Epoch 23: Validation loss decreased (0.243456 --> 0.241832).  Saving model ...
	 Train_Loss: 0.2692 Train_Acc: 90.505 Val_Loss: 0.2418  BEST VAL Loss: 0.2418  Val_Acc: 91.612

Epoch 24: Validation loss decreased (0.241832 --> 0.240265).  Saving model ...
	 Train_Loss: 0.2674 Train_Acc: 90.529 Val_Loss: 0.2403  BEST VAL Loss: 0.2403  Val_Acc: 91.680

Epoch 25: Validation loss decreased (0.240265 --> 0.238774).  Saving model ...
	 Train_Loss: 0.2656 Train_Acc: 90.588 Val_Loss: 0.2388  BEST VAL Loss: 0.2388  Val_Acc: 91.630

Epoch 26: Validation loss decreased (0.238774 --> 0.237331).  Saving model ...
	 Train_Loss: 0.2640 Train_Acc: 90.585 Val_Loss: 0.2373  BEST VAL Loss: 0.2373  Val_Acc: 91.733

Epoch 27: Validation loss decreased (0.237331 --> 0.235964).  Saving model ...
	 Train_Loss: 0.2624 Train_Acc: 90.655 Val_Loss: 0.2360  BEST VAL Loss: 0.2360  Val_Acc: 91.769

Epoch 28: Validation loss decreased (0.235964 --> 0.234677).  Saving model ...
	 Train_Loss: 0.2609 Train_Acc: 90.720 Val_Loss: 0.2347  BEST VAL Loss: 0.2347  Val_Acc: 91.828

Epoch 29: Validation loss decreased (0.234677 --> 0.233441).  Saving model ...
	 Train_Loss: 0.2595 Train_Acc: 90.730 Val_Loss: 0.2334  BEST VAL Loss: 0.2334  Val_Acc: 91.890

Epoch 30: Validation loss decreased (0.233441 --> 0.232268).  Saving model ...
	 Train_Loss: 0.2581 Train_Acc: 90.828 Val_Loss: 0.2323  BEST VAL Loss: 0.2323  Val_Acc: 91.887

Epoch 31: Validation loss decreased (0.232268 --> 0.231145).  Saving model ...
	 Train_Loss: 0.2568 Train_Acc: 90.813 Val_Loss: 0.2311  BEST VAL Loss: 0.2311  Val_Acc: 91.873

Epoch 32: Validation loss decreased (0.231145 --> 0.230085).  Saving model ...
	 Train_Loss: 0.2556 Train_Acc: 90.894 Val_Loss: 0.2301  BEST VAL Loss: 0.2301  Val_Acc: 91.920

Epoch 33: Validation loss decreased (0.230085 --> 0.229079).  Saving model ...
	 Train_Loss: 0.2544 Train_Acc: 90.881 Val_Loss: 0.2291  BEST VAL Loss: 0.2291  Val_Acc: 91.950

Epoch 34: Validation loss decreased (0.229079 --> 0.228095).  Saving model ...
	 Train_Loss: 0.2532 Train_Acc: 90.909 Val_Loss: 0.2281  BEST VAL Loss: 0.2281  Val_Acc: 92.009

Epoch 35: Validation loss decreased (0.228095 --> 0.227129).  Saving model ...
	 Train_Loss: 0.2521 Train_Acc: 91.020 Val_Loss: 0.2271  BEST VAL Loss: 0.2271  Val_Acc: 91.988

Epoch 36: Validation loss decreased (0.227129 --> 0.226210).  Saving model ...
	 Train_Loss: 0.2510 Train_Acc: 91.000 Val_Loss: 0.2262  BEST VAL Loss: 0.2262  Val_Acc: 92.083

Epoch 37: Validation loss decreased (0.226210 --> 0.225338).  Saving model ...
	 Train_Loss: 0.2499 Train_Acc: 91.134 Val_Loss: 0.2253  BEST VAL Loss: 0.2253  Val_Acc: 92.077

Epoch 38: Validation loss decreased (0.225338 --> 0.224492).  Saving model ...
	 Train_Loss: 0.2489 Train_Acc: 91.079 Val_Loss: 0.2245  BEST VAL Loss: 0.2245  Val_Acc: 92.074

Epoch 39: Validation loss decreased (0.224492 --> 0.223675).  Saving model ...
	 Train_Loss: 0.2480 Train_Acc: 91.111 Val_Loss: 0.2237  BEST VAL Loss: 0.2237  Val_Acc: 92.092

Epoch 40: Validation loss decreased (0.223675 --> 0.222913).  Saving model ...
	 Train_Loss: 0.2470 Train_Acc: 91.098 Val_Loss: 0.2229  BEST VAL Loss: 0.2229  Val_Acc: 92.116

Epoch 41: Validation loss decreased (0.222913 --> 0.222146).  Saving model ...
	 Train_Loss: 0.2461 Train_Acc: 91.168 Val_Loss: 0.2221  BEST VAL Loss: 0.2221  Val_Acc: 92.080

Epoch 42: Validation loss decreased (0.222146 --> 0.221408).  Saving model ...
	 Train_Loss: 0.2452 Train_Acc: 91.127 Val_Loss: 0.2214  BEST VAL Loss: 0.2214  Val_Acc: 92.181

Epoch 43: Validation loss decreased (0.221408 --> 0.220693).  Saving model ...
	 Train_Loss: 0.2444 Train_Acc: 91.160 Val_Loss: 0.2207  BEST VAL Loss: 0.2207  Val_Acc: 92.166

Epoch 44: Validation loss decreased (0.220693 --> 0.220005).  Saving model ...
	 Train_Loss: 0.2436 Train_Acc: 91.175 Val_Loss: 0.2200  BEST VAL Loss: 0.2200  Val_Acc: 92.211

Epoch 45: Validation loss decreased (0.220005 --> 0.219333).  Saving model ...
	 Train_Loss: 0.2428 Train_Acc: 91.223 Val_Loss: 0.2193  BEST VAL Loss: 0.2193  Val_Acc: 92.211

Epoch 46: Validation loss decreased (0.219333 --> 0.218670).  Saving model ...
	 Train_Loss: 0.2420 Train_Acc: 91.200 Val_Loss: 0.2187  BEST VAL Loss: 0.2187  Val_Acc: 92.190

Epoch 47: Validation loss decreased (0.218670 --> 0.218042).  Saving model ...
	 Train_Loss: 0.2413 Train_Acc: 91.233 Val_Loss: 0.2180  BEST VAL Loss: 0.2180  Val_Acc: 92.178

Epoch 48: Validation loss decreased (0.218042 --> 0.217427).  Saving model ...
	 Train_Loss: 0.2405 Train_Acc: 91.302 Val_Loss: 0.2174  BEST VAL Loss: 0.2174  Val_Acc: 92.255

Epoch 49: Validation loss decreased (0.217427 --> 0.216840).  Saving model ...
	 Train_Loss: 0.2398 Train_Acc: 91.287 Val_Loss: 0.2168  BEST VAL Loss: 0.2168  Val_Acc: 92.119

Epoch 50: Validation loss decreased (0.216840 --> 0.216268).  Saving model ...
	 Train_Loss: 0.2391 Train_Acc: 91.352 Val_Loss: 0.2163  BEST VAL Loss: 0.2163  Val_Acc: 92.193

Epoch 51: Validation loss decreased (0.216268 --> 0.215699).  Saving model ...
	 Train_Loss: 0.2384 Train_Acc: 91.349 Val_Loss: 0.2157  BEST VAL Loss: 0.2157  Val_Acc: 92.279

Epoch 52: Validation loss decreased (0.215699 --> 0.215155).  Saving model ...
	 Train_Loss: 0.2378 Train_Acc: 91.369 Val_Loss: 0.2152  BEST VAL Loss: 0.2152  Val_Acc: 92.264

Epoch 53: Validation loss decreased (0.215155 --> 0.214627).  Saving model ...
	 Train_Loss: 0.2372 Train_Acc: 91.307 Val_Loss: 0.2146  BEST VAL Loss: 0.2146  Val_Acc: 92.365

Epoch 54: Validation loss decreased (0.214627 --> 0.214105).  Saving model ...
	 Train_Loss: 0.2365 Train_Acc: 91.328 Val_Loss: 0.2141  BEST VAL Loss: 0.2141  Val_Acc: 92.385

Epoch 55: Validation loss decreased (0.214105 --> 0.213589).  Saving model ...
	 Train_Loss: 0.2359 Train_Acc: 91.441 Val_Loss: 0.2136  BEST VAL Loss: 0.2136  Val_Acc: 92.374

Epoch 56: Validation loss decreased (0.213589 --> 0.213101).  Saving model ...
	 Train_Loss: 0.2353 Train_Acc: 91.422 Val_Loss: 0.2131  BEST VAL Loss: 0.2131  Val_Acc: 92.391

Epoch 57: Validation loss decreased (0.213101 --> 0.212621).  Saving model ...
	 Train_Loss: 0.2348 Train_Acc: 91.384 Val_Loss: 0.2126  BEST VAL Loss: 0.2126  Val_Acc: 92.374

Epoch 58: Validation loss decreased (0.212621 --> 0.212164).  Saving model ...
	 Train_Loss: 0.2342 Train_Acc: 91.409 Val_Loss: 0.2122  BEST VAL Loss: 0.2122  Val_Acc: 92.294

Epoch 59: Validation loss decreased (0.212164 --> 0.211712).  Saving model ...
	 Train_Loss: 0.2336 Train_Acc: 91.481 Val_Loss: 0.2117  BEST VAL Loss: 0.2117  Val_Acc: 92.418

Epoch 60: Validation loss decreased (0.211712 --> 0.211258).  Saving model ...
	 Train_Loss: 0.2331 Train_Acc: 91.395 Val_Loss: 0.2113  BEST VAL Loss: 0.2113  Val_Acc: 92.454

Epoch 61: Validation loss decreased (0.211258 --> 0.210821).  Saving model ...
	 Train_Loss: 0.2326 Train_Acc: 91.488 Val_Loss: 0.2108  BEST VAL Loss: 0.2108  Val_Acc: 92.480

Epoch 62: Validation loss decreased (0.210821 --> 0.210394).  Saving model ...
	 Train_Loss: 0.2321 Train_Acc: 91.494 Val_Loss: 0.2104  BEST VAL Loss: 0.2104  Val_Acc: 92.424

Epoch 63: Validation loss decreased (0.210394 --> 0.209987).  Saving model ...
	 Train_Loss: 0.2315 Train_Acc: 91.478 Val_Loss: 0.2100  BEST VAL Loss: 0.2100  Val_Acc: 92.442

Epoch 64: Validation loss decreased (0.209987 --> 0.209587).  Saving model ...
	 Train_Loss: 0.2311 Train_Acc: 91.526 Val_Loss: 0.2096  BEST VAL Loss: 0.2096  Val_Acc: 92.338

Epoch 65: Validation loss decreased (0.209587 --> 0.209209).  Saving model ...
	 Train_Loss: 0.2306 Train_Acc: 91.514 Val_Loss: 0.2092  BEST VAL Loss: 0.2092  Val_Acc: 92.415

Epoch 66: Validation loss decreased (0.209209 --> 0.208825).  Saving model ...
	 Train_Loss: 0.2301 Train_Acc: 91.522 Val_Loss: 0.2088  BEST VAL Loss: 0.2088  Val_Acc: 92.374

Epoch 67: Validation loss decreased (0.208825 --> 0.208458).  Saving model ...
	 Train_Loss: 0.2296 Train_Acc: 91.517 Val_Loss: 0.2085  BEST VAL Loss: 0.2085  Val_Acc: 92.477

Epoch 68: Validation loss decreased (0.208458 --> 0.208098).  Saving model ...
	 Train_Loss: 0.2292 Train_Acc: 91.542 Val_Loss: 0.2081  BEST VAL Loss: 0.2081  Val_Acc: 92.483

Epoch 69: Validation loss decreased (0.208098 --> 0.207744).  Saving model ...
	 Train_Loss: 0.2287 Train_Acc: 91.541 Val_Loss: 0.2077  BEST VAL Loss: 0.2077  Val_Acc: 92.442

Epoch 70: Validation loss decreased (0.207744 --> 0.207402).  Saving model ...
	 Train_Loss: 0.2283 Train_Acc: 91.546 Val_Loss: 0.2074  BEST VAL Loss: 0.2074  Val_Acc: 92.412

Epoch 71: Validation loss decreased (0.207402 --> 0.207059).  Saving model ...
	 Train_Loss: 0.2279 Train_Acc: 91.570 Val_Loss: 0.2071  BEST VAL Loss: 0.2071  Val_Acc: 92.448

Epoch 72: Validation loss decreased (0.207059 --> 0.206730).  Saving model ...
	 Train_Loss: 0.2275 Train_Acc: 91.540 Val_Loss: 0.2067  BEST VAL Loss: 0.2067  Val_Acc: 92.388

Epoch 73: Validation loss decreased (0.206730 --> 0.206403).  Saving model ...
	 Train_Loss: 0.2271 Train_Acc: 91.531 Val_Loss: 0.2064  BEST VAL Loss: 0.2064  Val_Acc: 92.471

Epoch 74: Validation loss decreased (0.206403 --> 0.206086).  Saving model ...
	 Train_Loss: 0.2267 Train_Acc: 91.608 Val_Loss: 0.2061  BEST VAL Loss: 0.2061  Val_Acc: 92.454

Epoch 75: Validation loss decreased (0.206086 --> 0.205779).  Saving model ...
	 Train_Loss: 0.2263 Train_Acc: 91.618 Val_Loss: 0.2058  BEST VAL Loss: 0.2058  Val_Acc: 92.471

Epoch 76: Validation loss decreased (0.205779 --> 0.205468).  Saving model ...
	 Train_Loss: 0.2259 Train_Acc: 91.603 Val_Loss: 0.2055  BEST VAL Loss: 0.2055  Val_Acc: 92.474

Epoch 77: Validation loss decreased (0.205468 --> 0.205174).  Saving model ...
	 Train_Loss: 0.2255 Train_Acc: 91.578 Val_Loss: 0.2052  BEST VAL Loss: 0.2052  Val_Acc: 92.436

Epoch 78: Validation loss decreased (0.205174 --> 0.204883).  Saving model ...
	 Train_Loss: 0.2251 Train_Acc: 91.552 Val_Loss: 0.2049  BEST VAL Loss: 0.2049  Val_Acc: 92.495

Epoch 79: Validation loss decreased (0.204883 --> 0.204593).  Saving model ...
	 Train_Loss: 0.2248 Train_Acc: 91.675 Val_Loss: 0.2046  BEST VAL Loss: 0.2046  Val_Acc: 92.454

Epoch 80: Validation loss decreased (0.204593 --> 0.204314).  Saving model ...
	 Train_Loss: 0.2244 Train_Acc: 91.632 Val_Loss: 0.2043  BEST VAL Loss: 0.2043  Val_Acc: 92.602

Epoch 81: Validation loss decreased (0.204314 --> 0.204032).  Saving model ...
	 Train_Loss: 0.2241 Train_Acc: 91.619 Val_Loss: 0.2040  BEST VAL Loss: 0.2040  Val_Acc: 92.590

Epoch 82: Validation loss decreased (0.204032 --> 0.203755).  Saving model ...
	 Train_Loss: 0.2237 Train_Acc: 91.654 Val_Loss: 0.2038  BEST VAL Loss: 0.2038  Val_Acc: 92.575

Epoch 83: Validation loss decreased (0.203755 --> 0.203498).  Saving model ...
	 Train_Loss: 0.2234 Train_Acc: 91.628 Val_Loss: 0.2035  BEST VAL Loss: 0.2035  Val_Acc: 92.510

Epoch 84: Validation loss decreased (0.203498 --> 0.203240).  Saving model ...
	 Train_Loss: 0.2230 Train_Acc: 91.683 Val_Loss: 0.2032  BEST VAL Loss: 0.2032  Val_Acc: 92.581

Epoch 85: Validation loss decreased (0.203240 --> 0.202981).  Saving model ...
	 Train_Loss: 0.2227 Train_Acc: 91.623 Val_Loss: 0.2030  BEST VAL Loss: 0.2030  Val_Acc: 92.575

Epoch 86: Validation loss decreased (0.202981 --> 0.202725).  Saving model ...
	 Train_Loss: 0.2224 Train_Acc: 91.658 Val_Loss: 0.2027  BEST VAL Loss: 0.2027  Val_Acc: 92.643

Epoch 87: Validation loss decreased (0.202725 --> 0.202476).  Saving model ...
	 Train_Loss: 0.2221 Train_Acc: 91.666 Val_Loss: 0.2025  BEST VAL Loss: 0.2025  Val_Acc: 92.578

Epoch 88: Validation loss decreased (0.202476 --> 0.202231).  Saving model ...
	 Train_Loss: 0.2218 Train_Acc: 91.707 Val_Loss: 0.2022  BEST VAL Loss: 0.2022  Val_Acc: 92.646

Epoch 89: Validation loss decreased (0.202231 --> 0.202004).  Saving model ...
	 Train_Loss: 0.2214 Train_Acc: 91.730 Val_Loss: 0.2020  BEST VAL Loss: 0.2020  Val_Acc: 92.572

Epoch 90: Validation loss decreased (0.202004 --> 0.201769).  Saving model ...
	 Train_Loss: 0.2211 Train_Acc: 91.682 Val_Loss: 0.2018  BEST VAL Loss: 0.2018  Val_Acc: 92.623

Epoch 91: Validation loss decreased (0.201769 --> 0.201548).  Saving model ...
	 Train_Loss: 0.2208 Train_Acc: 91.708 Val_Loss: 0.2015  BEST VAL Loss: 0.2015  Val_Acc: 92.637

Epoch 92: Validation loss decreased (0.201548 --> 0.201322).  Saving model ...
	 Train_Loss: 0.2206 Train_Acc: 91.720 Val_Loss: 0.2013  BEST VAL Loss: 0.2013  Val_Acc: 92.602

Epoch 93: Validation loss decreased (0.201322 --> 0.201097).  Saving model ...
	 Train_Loss: 0.2203 Train_Acc: 91.744 Val_Loss: 0.2011  BEST VAL Loss: 0.2011  Val_Acc: 92.631

Epoch 94: Validation loss decreased (0.201097 --> 0.200874).  Saving model ...
	 Train_Loss: 0.2200 Train_Acc: 91.694 Val_Loss: 0.2009  BEST VAL Loss: 0.2009  Val_Acc: 92.602

Epoch 95: Validation loss decreased (0.200874 --> 0.200651).  Saving model ...
	 Train_Loss: 0.2197 Train_Acc: 91.743 Val_Loss: 0.2007  BEST VAL Loss: 0.2007  Val_Acc: 92.673

Epoch 96: Validation loss decreased (0.200651 --> 0.200442).  Saving model ...
	 Train_Loss: 0.2194 Train_Acc: 91.738 Val_Loss: 0.2004  BEST VAL Loss: 0.2004  Val_Acc: 92.575

Epoch 97: Validation loss decreased (0.200442 --> 0.200245).  Saving model ...
	 Train_Loss: 0.2191 Train_Acc: 91.763 Val_Loss: 0.2002  BEST VAL Loss: 0.2002  Val_Acc: 92.563

Epoch 98: Validation loss decreased (0.200245 --> 0.200048).  Saving model ...
	 Train_Loss: 0.2189 Train_Acc: 91.732 Val_Loss: 0.2000  BEST VAL Loss: 0.2000  Val_Acc: 92.646

Epoch 99: Validation loss decreased (0.200048 --> 0.199853).  Saving model ...
	 Train_Loss: 0.2186 Train_Acc: 91.744 Val_Loss: 0.1999  BEST VAL Loss: 0.1999  Val_Acc: 92.676

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.95      0.95      0.95    169562
           1       0.92      0.91      0.92    100339

    accuracy                           0.94    269901
   macro avg       0.93      0.93      0.93    269901
weighted avg       0.94      0.94      0.94    269901

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.94      0.94      0.94     21195
           1       0.91      0.90      0.90     12543

    accuracy                           0.93     33738
   macro avg       0.92      0.92      0.92     33738
weighted avg       0.93      0.93      0.93     33738

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.94      0.94      0.94     21195
           1       0.90      0.89      0.90     12543

    accuracy                           0.92     33738
   macro avg       0.92      0.92      0.92     33738
weighted avg       0.92      0.92      0.92     33738

              precision    recall  f1-score   support

           0       0.94      0.94      0.94     21195
           1       0.90      0.89      0.90     12543

    accuracy                           0.92     33738
   macro avg       0.92      0.92      0.92     33738
weighted avg       0.92      0.92      0.92     33738

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.84      1.00      0.91     28584
           1       1.00      0.87      0.93     40588

    accuracy                           0.92     69172
   macro avg       0.92      0.93      0.92     69172
weighted avg       0.93      0.92      0.92     69172

              precision    recall  f1-score   support

           0       0.84      1.00      0.91     28584
           1       1.00      0.87      0.93     40588

    accuracy                           0.92     69172
   macro avg       0.92      0.93      0.92     69172
weighted avg       0.93      0.92      0.92     69172

completed
