[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'e142726c'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '219617a3'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '54929cd5'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '8f843a3a'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_10.000_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (31738, 1276)
Number of total missing values across all columns: 63476
Data Subset Is Off
Wells held out for testing: ['E21' 'L22']
Wells to use for training, validation, and testing ['E16' 'E17' 'E20' 'L18' 'L19' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.676135).  Saving model ...
	 Train_Loss: 0.6874 Train_Acc: 53.827 Val_Loss: 0.6761  BEST VAL Loss: 0.6761  Val_Acc: 57.935

Epoch 1: Validation loss decreased (0.676135 --> 0.672246).  Saving model ...
	 Train_Loss: 0.6811 Train_Acc: 57.561 Val_Loss: 0.6722  BEST VAL Loss: 0.6722  Val_Acc: 60.154

Epoch 2: Validation loss decreased (0.672246 --> 0.669590).  Saving model ...
	 Train_Loss: 0.6762 Train_Acc: 59.279 Val_Loss: 0.6696  BEST VAL Loss: 0.6696  Val_Acc: 60.879

Epoch 3: Validation loss decreased (0.669590 --> 0.665775).  Saving model ...
	 Train_Loss: 0.6718 Train_Acc: 60.906 Val_Loss: 0.6658  BEST VAL Loss: 0.6658  Val_Acc: 61.305

Epoch 4: Validation loss decreased (0.665775 --> 0.662067).  Saving model ...
	 Train_Loss: 0.6679 Train_Acc: 62.319 Val_Loss: 0.6621  BEST VAL Loss: 0.6621  Val_Acc: 63.183

Epoch 5: Validation loss decreased (0.662067 --> 0.659609).  Saving model ...
	 Train_Loss: 0.6640 Train_Acc: 63.375 Val_Loss: 0.6596  BEST VAL Loss: 0.6596  Val_Acc: 63.993

Epoch 6: Validation loss decreased (0.659609 --> 0.656961).  Saving model ...
	 Train_Loss: 0.6603 Train_Acc: 64.682 Val_Loss: 0.6570  BEST VAL Loss: 0.6570  Val_Acc: 63.737

Epoch 7: Validation loss decreased (0.656961 --> 0.654261).  Saving model ...
	 Train_Loss: 0.6565 Train_Acc: 65.659 Val_Loss: 0.6543  BEST VAL Loss: 0.6543  Val_Acc: 65.060

Epoch 8: Validation loss decreased (0.654261 --> 0.651230).  Saving model ...
	 Train_Loss: 0.6528 Train_Acc: 66.331 Val_Loss: 0.6512  BEST VAL Loss: 0.6512  Val_Acc: 66.084

Epoch 9: Validation loss decreased (0.651230 --> 0.648154).  Saving model ...
	 Train_Loss: 0.6491 Train_Acc: 66.859 Val_Loss: 0.6482  BEST VAL Loss: 0.6482  Val_Acc: 66.297

Epoch 10: Validation loss decreased (0.648154 --> 0.645425).  Saving model ...
	 Train_Loss: 0.6456 Train_Acc: 67.477 Val_Loss: 0.6454  BEST VAL Loss: 0.6454  Val_Acc: 66.766

Epoch 11: Validation loss decreased (0.645425 --> 0.642246).  Saving model ...
	 Train_Loss: 0.6419 Train_Acc: 68.512 Val_Loss: 0.6422  BEST VAL Loss: 0.6422  Val_Acc: 67.662

Epoch 12: Validation loss decreased (0.642246 --> 0.639325).  Saving model ...
	 Train_Loss: 0.6381 Train_Acc: 69.014 Val_Loss: 0.6393  BEST VAL Loss: 0.6393  Val_Acc: 68.003

Epoch 13: Validation loss decreased (0.639325 --> 0.636550).  Saving model ...
	 Train_Loss: 0.6344 Train_Acc: 69.654 Val_Loss: 0.6365  BEST VAL Loss: 0.6365  Val_Acc: 68.857

Epoch 14: Validation loss decreased (0.636550 --> 0.633529).  Saving model ...
	 Train_Loss: 0.6308 Train_Acc: 70.225 Val_Loss: 0.6335  BEST VAL Loss: 0.6335  Val_Acc: 68.985

Epoch 15: Validation loss decreased (0.633529 --> 0.630470).  Saving model ...
	 Train_Loss: 0.6272 Train_Acc: 71.009 Val_Loss: 0.6305  BEST VAL Loss: 0.6305  Val_Acc: 69.326

Epoch 16: Validation loss decreased (0.630470 --> 0.627530).  Saving model ...
	 Train_Loss: 0.6236 Train_Acc: 71.393 Val_Loss: 0.6275  BEST VAL Loss: 0.6275  Val_Acc: 69.753

Epoch 17: Validation loss decreased (0.627530 --> 0.624817).  Saving model ...
	 Train_Loss: 0.6199 Train_Acc: 72.044 Val_Loss: 0.6248  BEST VAL Loss: 0.6248  Val_Acc: 70.734

Epoch 18: Validation loss decreased (0.624817 --> 0.622119).  Saving model ...
	 Train_Loss: 0.6165 Train_Acc: 72.390 Val_Loss: 0.6221  BEST VAL Loss: 0.6221  Val_Acc: 70.307

Epoch 19: Validation loss decreased (0.622119 --> 0.619474).  Saving model ...
	 Train_Loss: 0.6130 Train_Acc: 72.940 Val_Loss: 0.6195  BEST VAL Loss: 0.6195  Val_Acc: 70.435

Epoch 20: Validation loss decreased (0.619474 --> 0.616783).  Saving model ...
	 Train_Loss: 0.6097 Train_Acc: 72.897 Val_Loss: 0.6168  BEST VAL Loss: 0.6168  Val_Acc: 70.179

Epoch 21: Validation loss decreased (0.616783 --> 0.614257).  Saving model ...
	 Train_Loss: 0.6063 Train_Acc: 73.676 Val_Loss: 0.6143  BEST VAL Loss: 0.6143  Val_Acc: 71.502

Epoch 22: Validation loss decreased (0.614257 --> 0.611492).  Saving model ...
	 Train_Loss: 0.6030 Train_Acc: 74.071 Val_Loss: 0.6115  BEST VAL Loss: 0.6115  Val_Acc: 71.928

Epoch 23: Validation loss decreased (0.611492 --> 0.609112).  Saving model ...
	 Train_Loss: 0.5998 Train_Acc: 74.257 Val_Loss: 0.6091  BEST VAL Loss: 0.6091  Val_Acc: 72.270

Epoch 24: Validation loss decreased (0.609112 --> 0.606092).  Saving model ...
	 Train_Loss: 0.5966 Train_Acc: 74.679 Val_Loss: 0.6061  BEST VAL Loss: 0.6061  Val_Acc: 71.800

Epoch 25: Validation loss decreased (0.606092 --> 0.603872).  Saving model ...
	 Train_Loss: 0.5934 Train_Acc: 75.404 Val_Loss: 0.6039  BEST VAL Loss: 0.6039  Val_Acc: 71.672

Epoch 26: Validation loss decreased (0.603872 --> 0.601524).  Saving model ...
	 Train_Loss: 0.5903 Train_Acc: 75.431 Val_Loss: 0.6015  BEST VAL Loss: 0.6015  Val_Acc: 71.971

Epoch 27: Validation loss decreased (0.601524 --> 0.599213).  Saving model ...
	 Train_Loss: 0.5873 Train_Acc: 75.788 Val_Loss: 0.5992  BEST VAL Loss: 0.5992  Val_Acc: 72.483

Epoch 28: Validation loss decreased (0.599213 --> 0.596588).  Saving model ...
	 Train_Loss: 0.5843 Train_Acc: 76.327 Val_Loss: 0.5966  BEST VAL Loss: 0.5966  Val_Acc: 73.038

Epoch 29: Validation loss decreased (0.596588 --> 0.594310).  Saving model ...
	 Train_Loss: 0.5814 Train_Acc: 76.460 Val_Loss: 0.5943  BEST VAL Loss: 0.5943  Val_Acc: 73.080

Epoch 30: Validation loss decreased (0.594310 --> 0.592226).  Saving model ...
	 Train_Loss: 0.5785 Train_Acc: 76.572 Val_Loss: 0.5922  BEST VAL Loss: 0.5922  Val_Acc: 72.995

Epoch 31: Validation loss decreased (0.592226 --> 0.590220).  Saving model ...
	 Train_Loss: 0.5757 Train_Acc: 76.898 Val_Loss: 0.5902  BEST VAL Loss: 0.5902  Val_Acc: 73.336

Epoch 32: Validation loss decreased (0.590220 --> 0.588241).  Saving model ...
	 Train_Loss: 0.5727 Train_Acc: 77.820 Val_Loss: 0.5882  BEST VAL Loss: 0.5882  Val_Acc: 73.166

Epoch 33: Validation loss decreased (0.588241 --> 0.585915).  Saving model ...
	 Train_Loss: 0.5699 Train_Acc: 77.586 Val_Loss: 0.5859  BEST VAL Loss: 0.5859  Val_Acc: 74.104

Epoch 34: Validation loss decreased (0.585915 --> 0.583753).  Saving model ...
	 Train_Loss: 0.5672 Train_Acc: 77.532 Val_Loss: 0.5838  BEST VAL Loss: 0.5838  Val_Acc: 73.720

Epoch 35: Validation loss decreased (0.583753 --> 0.581644).  Saving model ...
	 Train_Loss: 0.5645 Train_Acc: 77.836 Val_Loss: 0.5816  BEST VAL Loss: 0.5816  Val_Acc: 74.659

Epoch 36: Validation loss decreased (0.581644 --> 0.579783).  Saving model ...
	 Train_Loss: 0.5617 Train_Acc: 78.450 Val_Loss: 0.5798  BEST VAL Loss: 0.5798  Val_Acc: 74.744

Epoch 37: Validation loss decreased (0.579783 --> 0.577732).  Saving model ...
	 Train_Loss: 0.5591 Train_Acc: 78.487 Val_Loss: 0.5777  BEST VAL Loss: 0.5777  Val_Acc: 75.341

Epoch 38: Validation loss decreased (0.577732 --> 0.575861).  Saving model ...
	 Train_Loss: 0.5565 Train_Acc: 78.551 Val_Loss: 0.5759  BEST VAL Loss: 0.5759  Val_Acc: 75.811

Epoch 39: Validation loss decreased (0.575861 --> 0.573909).  Saving model ...
	 Train_Loss: 0.5539 Train_Acc: 79.079 Val_Loss: 0.5739  BEST VAL Loss: 0.5739  Val_Acc: 75.299

Epoch 40: Validation loss decreased (0.573909 --> 0.572091).  Saving model ...
	 Train_Loss: 0.5513 Train_Acc: 79.271 Val_Loss: 0.5721  BEST VAL Loss: 0.5721  Val_Acc: 76.152

Epoch 41: Validation loss decreased (0.572091 --> 0.570033).  Saving model ...
	 Train_Loss: 0.5487 Train_Acc: 79.442 Val_Loss: 0.5700  BEST VAL Loss: 0.5700  Val_Acc: 75.427

Epoch 42: Validation loss decreased (0.570033 --> 0.568107).  Saving model ...
	 Train_Loss: 0.5462 Train_Acc: 79.901 Val_Loss: 0.5681  BEST VAL Loss: 0.5681  Val_Acc: 76.067

Epoch 43: Validation loss decreased (0.568107 --> 0.566447).  Saving model ...
	 Train_Loss: 0.5437 Train_Acc: 80.135 Val_Loss: 0.5664  BEST VAL Loss: 0.5664  Val_Acc: 76.195

Epoch 44: Validation loss decreased (0.566447 --> 0.564628).  Saving model ...
	 Train_Loss: 0.5412 Train_Acc: 80.360 Val_Loss: 0.5646  BEST VAL Loss: 0.5646  Val_Acc: 76.024

Epoch 45: Validation loss decreased (0.564628 --> 0.562673).  Saving model ...
	 Train_Loss: 0.5389 Train_Acc: 80.034 Val_Loss: 0.5627  BEST VAL Loss: 0.5627  Val_Acc: 75.981

Epoch 46: Validation loss decreased (0.562673 --> 0.561212).  Saving model ...
	 Train_Loss: 0.5365 Train_Acc: 80.701 Val_Loss: 0.5612  BEST VAL Loss: 0.5612  Val_Acc: 76.323

Epoch 47: Validation loss decreased (0.561212 --> 0.559544).  Saving model ...
	 Train_Loss: 0.5341 Train_Acc: 80.605 Val_Loss: 0.5595  BEST VAL Loss: 0.5595  Val_Acc: 76.451

Epoch 48: Validation loss decreased (0.559544 --> 0.557872).  Saving model ...
	 Train_Loss: 0.5318 Train_Acc: 80.477 Val_Loss: 0.5579  BEST VAL Loss: 0.5579  Val_Acc: 76.451

Epoch 49: Validation loss decreased (0.557872 --> 0.556382).  Saving model ...
	 Train_Loss: 0.5295 Train_Acc: 80.984 Val_Loss: 0.5564  BEST VAL Loss: 0.5564  Val_Acc: 76.493

Epoch 50: Validation loss decreased (0.556382 --> 0.555024).  Saving model ...
	 Train_Loss: 0.5273 Train_Acc: 81.021 Val_Loss: 0.5550  BEST VAL Loss: 0.5550  Val_Acc: 75.427

Epoch 51: Validation loss decreased (0.555024 --> 0.553652).  Saving model ...
	 Train_Loss: 0.5252 Train_Acc: 80.589 Val_Loss: 0.5537  BEST VAL Loss: 0.5537  Val_Acc: 76.152

Epoch 52: Validation loss decreased (0.553652 --> 0.552324).  Saving model ...
	 Train_Loss: 0.5231 Train_Acc: 81.144 Val_Loss: 0.5523  BEST VAL Loss: 0.5523  Val_Acc: 76.706

Epoch 53: Validation loss decreased (0.552324 --> 0.550953).  Saving model ...
	 Train_Loss: 0.5209 Train_Acc: 81.544 Val_Loss: 0.5510  BEST VAL Loss: 0.5510  Val_Acc: 76.493

Epoch 54: Validation loss decreased (0.550953 --> 0.549611).  Saving model ...
	 Train_Loss: 0.5188 Train_Acc: 81.896 Val_Loss: 0.5496  BEST VAL Loss: 0.5496  Val_Acc: 76.706

Epoch 55: Validation loss decreased (0.549611 --> 0.548256).  Saving model ...
	 Train_Loss: 0.5167 Train_Acc: 81.629 Val_Loss: 0.5483  BEST VAL Loss: 0.5483  Val_Acc: 76.792

Epoch 56: Validation loss decreased (0.548256 --> 0.546886).  Saving model ...
	 Train_Loss: 0.5147 Train_Acc: 82.008 Val_Loss: 0.5469  BEST VAL Loss: 0.5469  Val_Acc: 76.664

Epoch 57: Validation loss decreased (0.546886 --> 0.545966).  Saving model ...
	 Train_Loss: 0.5127 Train_Acc: 81.917 Val_Loss: 0.5460  BEST VAL Loss: 0.5460  Val_Acc: 74.829

Epoch 58: Validation loss decreased (0.545966 --> 0.544884).  Saving model ...
	 Train_Loss: 0.5108 Train_Acc: 81.842 Val_Loss: 0.5449  BEST VAL Loss: 0.5449  Val_Acc: 76.621

Epoch 59: Validation loss decreased (0.544884 --> 0.543662).  Saving model ...
	 Train_Loss: 0.5087 Train_Acc: 82.477 Val_Loss: 0.5437  BEST VAL Loss: 0.5437  Val_Acc: 76.621

Epoch 60: Validation loss decreased (0.543662 --> 0.542478).  Saving model ...
	 Train_Loss: 0.5067 Train_Acc: 82.733 Val_Loss: 0.5425  BEST VAL Loss: 0.5425  Val_Acc: 76.493

Epoch 61: Validation loss decreased (0.542478 --> 0.541422).  Saving model ...
	 Train_Loss: 0.5048 Train_Acc: 82.728 Val_Loss: 0.5414  BEST VAL Loss: 0.5414  Val_Acc: 77.261

Epoch 62: Validation loss decreased (0.541422 --> 0.540528).  Saving model ...
	 Train_Loss: 0.5030 Train_Acc: 81.880 Val_Loss: 0.5405  BEST VAL Loss: 0.5405  Val_Acc: 76.792

Epoch 63: Validation loss decreased (0.540528 --> 0.539529).  Saving model ...
	 Train_Loss: 0.5012 Train_Acc: 82.883 Val_Loss: 0.5395  BEST VAL Loss: 0.5395  Val_Acc: 76.365

Epoch 64: Validation loss decreased (0.539529 --> 0.538644).  Saving model ...
	 Train_Loss: 0.4995 Train_Acc: 82.056 Val_Loss: 0.5386  BEST VAL Loss: 0.5386  Val_Acc: 75.811

Epoch 65: Validation loss decreased (0.538644 --> 0.537545).  Saving model ...
	 Train_Loss: 0.4978 Train_Acc: 82.691 Val_Loss: 0.5375  BEST VAL Loss: 0.5375  Val_Acc: 76.536

Epoch 66: Validation loss decreased (0.537545 --> 0.536445).  Saving model ...
	 Train_Loss: 0.4960 Train_Acc: 83.208 Val_Loss: 0.5364  BEST VAL Loss: 0.5364  Val_Acc: 76.749

Epoch 67: Validation loss decreased (0.536445 --> 0.535412).  Saving model ...
	 Train_Loss: 0.4942 Train_Acc: 83.341 Val_Loss: 0.5354  BEST VAL Loss: 0.5354  Val_Acc: 76.962

Epoch 68: Validation loss decreased (0.535412 --> 0.534348).  Saving model ...
	 Train_Loss: 0.4925 Train_Acc: 83.592 Val_Loss: 0.5343  BEST VAL Loss: 0.5343  Val_Acc: 77.389

Epoch 69: Validation loss decreased (0.534348 --> 0.533448).  Saving model ...
	 Train_Loss: 0.4908 Train_Acc: 83.464 Val_Loss: 0.5334  BEST VAL Loss: 0.5334  Val_Acc: 77.005

Epoch 70: Validation loss decreased (0.533448 --> 0.532603).  Saving model ...
	 Train_Loss: 0.4891 Train_Acc: 83.203 Val_Loss: 0.5326  BEST VAL Loss: 0.5326  Val_Acc: 77.261

Epoch 71: Validation loss decreased (0.532603 --> 0.531563).  Saving model ...
	 Train_Loss: 0.4875 Train_Acc: 83.779 Val_Loss: 0.5316  BEST VAL Loss: 0.5316  Val_Acc: 77.474

Epoch 72: Validation loss decreased (0.531563 --> 0.530649).  Saving model ...
	 Train_Loss: 0.4858 Train_Acc: 83.763 Val_Loss: 0.5306  BEST VAL Loss: 0.5306  Val_Acc: 76.621

Epoch 73: Validation loss decreased (0.530649 --> 0.529750).  Saving model ...
	 Train_Loss: 0.4842 Train_Acc: 83.912 Val_Loss: 0.5298  BEST VAL Loss: 0.5298  Val_Acc: 77.432

Epoch 74: Validation loss decreased (0.529750 --> 0.529126).  Saving model ...
	 Train_Loss: 0.4826 Train_Acc: 83.560 Val_Loss: 0.5291  BEST VAL Loss: 0.5291  Val_Acc: 76.664

Epoch 75: Validation loss decreased (0.529126 --> 0.528179).  Saving model ...
	 Train_Loss: 0.4810 Train_Acc: 83.944 Val_Loss: 0.5282  BEST VAL Loss: 0.5282  Val_Acc: 77.389

Epoch 76: Validation loss decreased (0.528179 --> 0.527660).  Saving model ...
	 Train_Loss: 0.4794 Train_Acc: 83.971 Val_Loss: 0.5277  BEST VAL Loss: 0.5277  Val_Acc: 76.408

Epoch 77: Validation loss decreased (0.527660 --> 0.526850).  Saving model ...
	 Train_Loss: 0.4779 Train_Acc: 84.157 Val_Loss: 0.5268  BEST VAL Loss: 0.5268  Val_Acc: 77.474

Epoch 78: Validation loss decreased (0.526850 --> 0.526056).  Saving model ...
	 Train_Loss: 0.4763 Train_Acc: 84.307 Val_Loss: 0.5261  BEST VAL Loss: 0.5261  Val_Acc: 77.133

Epoch 79: Validation loss decreased (0.526056 --> 0.525339).  Saving model ...
	 Train_Loss: 0.4749 Train_Acc: 83.741 Val_Loss: 0.5253  BEST VAL Loss: 0.5253  Val_Acc: 77.389

Epoch 80: Validation loss decreased (0.525339 --> 0.524622).  Saving model ...
	 Train_Loss: 0.4735 Train_Acc: 84.317 Val_Loss: 0.5246  BEST VAL Loss: 0.5246  Val_Acc: 77.133

Epoch 81: Validation loss decreased (0.524622 --> 0.523927).  Saving model ...
	 Train_Loss: 0.4720 Train_Acc: 84.099 Val_Loss: 0.5239  BEST VAL Loss: 0.5239  Val_Acc: 77.474

Epoch 82: Validation loss decreased (0.523927 --> 0.523695).  Saving model ...
	 Train_Loss: 0.4706 Train_Acc: 83.912 Val_Loss: 0.5237  BEST VAL Loss: 0.5237  Val_Acc: 75.640

Epoch 83: Validation loss decreased (0.523695 --> 0.523126).  Saving model ...
	 Train_Loss: 0.4693 Train_Acc: 83.741 Val_Loss: 0.5231  BEST VAL Loss: 0.5231  Val_Acc: 76.749

Epoch 84: Validation loss decreased (0.523126 --> 0.522588).  Saving model ...
	 Train_Loss: 0.4679 Train_Acc: 84.211 Val_Loss: 0.5226  BEST VAL Loss: 0.5226  Val_Acc: 77.901

Epoch 85: Validation loss decreased (0.522588 --> 0.522079).  Saving model ...
	 Train_Loss: 0.4665 Train_Acc: 84.899 Val_Loss: 0.5221  BEST VAL Loss: 0.5221  Val_Acc: 76.749

Epoch 86: Validation loss decreased (0.522079 --> 0.521470).  Saving model ...
	 Train_Loss: 0.4652 Train_Acc: 84.248 Val_Loss: 0.5215  BEST VAL Loss: 0.5215  Val_Acc: 76.792

Epoch 87: Validation loss decreased (0.521470 --> 0.520945).  Saving model ...
	 Train_Loss: 0.4639 Train_Acc: 84.712 Val_Loss: 0.5209  BEST VAL Loss: 0.5209  Val_Acc: 77.304

Epoch 88: Validation loss decreased (0.520945 --> 0.520220).  Saving model ...
	 Train_Loss: 0.4625 Train_Acc: 84.904 Val_Loss: 0.5202  BEST VAL Loss: 0.5202  Val_Acc: 77.090

Epoch 89: Validation loss decreased (0.520220 --> 0.519733).  Saving model ...
	 Train_Loss: 0.4612 Train_Acc: 84.627 Val_Loss: 0.5197  BEST VAL Loss: 0.5197  Val_Acc: 76.109

Epoch 90: Validation loss decreased (0.519733 --> 0.519156).  Saving model ...
	 Train_Loss: 0.4599 Train_Acc: 84.990 Val_Loss: 0.5192  BEST VAL Loss: 0.5192  Val_Acc: 77.773

Epoch 91: Validation loss decreased (0.519156 --> 0.518549).  Saving model ...
	 Train_Loss: 0.4586 Train_Acc: 85.262 Val_Loss: 0.5185  BEST VAL Loss: 0.5185  Val_Acc: 77.346

Epoch 92: Validation loss decreased (0.518549 --> 0.518059).  Saving model ...
	 Train_Loss: 0.4574 Train_Acc: 85.118 Val_Loss: 0.5181  BEST VAL Loss: 0.5181  Val_Acc: 76.706

Epoch 93: Validation loss decreased (0.518059 --> 0.517578).  Saving model ...
	 Train_Loss: 0.4561 Train_Acc: 84.856 Val_Loss: 0.5176  BEST VAL Loss: 0.5176  Val_Acc: 76.962

Epoch 94: Validation loss decreased (0.517578 --> 0.517124).  Saving model ...
	 Train_Loss: 0.4548 Train_Acc: 85.688 Val_Loss: 0.5171  BEST VAL Loss: 0.5171  Val_Acc: 77.261

Epoch 95: Validation loss decreased (0.517124 --> 0.516600).  Saving model ...
	 Train_Loss: 0.4535 Train_Acc: 85.438 Val_Loss: 0.5166  BEST VAL Loss: 0.5166  Val_Acc: 77.261

Epoch 96: Validation loss decreased (0.516600 --> 0.516255).  Saving model ...
	 Train_Loss: 0.4523 Train_Acc: 85.699 Val_Loss: 0.5163  BEST VAL Loss: 0.5163  Val_Acc: 77.005

Epoch 97: Validation loss decreased (0.516255 --> 0.515757).  Saving model ...
	 Train_Loss: 0.4511 Train_Acc: 85.203 Val_Loss: 0.5158  BEST VAL Loss: 0.5158  Val_Acc: 77.346

Epoch 98: Validation loss decreased (0.515757 --> 0.515383).  Saving model ...
	 Train_Loss: 0.4499 Train_Acc: 85.747 Val_Loss: 0.5154  BEST VAL Loss: 0.5154  Val_Acc: 76.195

Epoch 99: Validation loss decreased (0.515383 --> 0.514918).  Saving model ...
	 Train_Loss: 0.4488 Train_Acc: 85.416 Val_Loss: 0.5149  BEST VAL Loss: 0.5149  Val_Acc: 77.816

LPS_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.44      0.45      8634
           1       0.54      0.56      0.55     10113

    accuracy                           0.50     18747
   macro avg       0.50      0.50      0.50     18747
weighted avg       0.50      0.50      0.50     18747

LPS_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.44      0.42      0.43      1080
           1       0.53      0.55      0.54      1264

    accuracy                           0.49      2344
   macro avg       0.48      0.48      0.48      2344
weighted avg       0.49      0.49      0.49      2344

LPS_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.45      0.45      1079
           1       0.54      0.55      0.54      1265

    accuracy                           0.50      2344
   macro avg       0.50      0.50      0.50      2344
weighted avg       0.50      0.50      0.50      2344

              precision    recall  f1-score   support

           0       0.46      0.45      0.45      1079
           1       0.54      0.55      0.54      1265

    accuracy                           0.50      2344
   macro avg       0.50      0.50      0.50      2344
weighted avg       0.50      0.50      0.50      2344

LPS_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.34      0.41      4135
           1       0.50      0.66      0.57      4168

    accuracy                           0.50      8303
   macro avg       0.50      0.50      0.49      8303
weighted avg       0.50      0.50      0.49      8303

              precision    recall  f1-score   support

           0       0.50      0.34      0.41      4135
           1       0.50      0.66      0.57      4168

    accuracy                           0.50      8303
   macro avg       0.50      0.50      0.49      8303
weighted avg       0.50      0.50      0.49      8303

completed
