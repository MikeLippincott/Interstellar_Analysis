[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '14e72b8c'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '6b228e9e'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '145a586c'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '3ac58fe1'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 treatment_name: Thapsigargin_10.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
TREATMENT_NAME: Thapsigargin_10.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (27614, 1276)
Number of total missing values across all columns: 26424
Data Subset Is Off
Wells held out for testing: ['E14' 'M20']
Wells to use for training, validation, and testing ['E15' 'L14' 'L15' 'M16' 'M17' 'M21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.170628).  Saving model ...
	 Train_Loss: 0.4564 Train_Acc: 80.409 Val_Loss: 0.1706  BEST VAL Loss: 0.1706  Val_Acc: 92.742

Epoch 1: Validation loss decreased (0.170628 --> 0.135129).  Saving model ...
	 Train_Loss: 0.3500 Train_Acc: 90.738 Val_Loss: 0.1351  BEST VAL Loss: 0.1351  Val_Acc: 94.899

Epoch 2: Validation loss decreased (0.135129 --> 0.128960).  Saving model ...
	 Train_Loss: 0.2959 Train_Acc: 92.768 Val_Loss: 0.1290  BEST VAL Loss: 0.1290  Val_Acc: 94.262

Epoch 3: Validation loss decreased (0.128960 --> 0.119391).  Saving model ...
	 Train_Loss: 0.2606 Train_Acc: 94.154 Val_Loss: 0.1194  BEST VAL Loss: 0.1194  Val_Acc: 96.224

Epoch 4: Validation loss decreased (0.119391 --> 0.108010).  Saving model ...
	 Train_Loss: 0.2373 Train_Acc: 94.602 Val_Loss: 0.1080  BEST VAL Loss: 0.1080  Val_Acc: 96.616

Epoch 5: Validation loss decreased (0.108010 --> 0.101435).  Saving model ...
	 Train_Loss: 0.2193 Train_Acc: 94.780 Val_Loss: 0.1014  BEST VAL Loss: 0.1014  Val_Acc: 96.518

Epoch 6: Validation loss did not decrease
	 Train_Loss: 0.2034 Train_Acc: 95.682 Val_Loss: 0.1016  BEST VAL Loss: 0.1014  Val_Acc: 96.126

Epoch 7: Validation loss did not decrease
	 Train_Loss: 0.1926 Train_Acc: 95.271 Val_Loss: 0.1017  BEST VAL Loss: 0.1014  Val_Acc: 95.782

Epoch 8: Validation loss decreased (0.101435 --> 0.097205).  Saving model ...
	 Train_Loss: 0.1833 Train_Acc: 95.909 Val_Loss: 0.0972  BEST VAL Loss: 0.0972  Val_Acc: 96.027

Epoch 9: Validation loss decreased (0.097205 --> 0.095591).  Saving model ...
	 Train_Loss: 0.1758 Train_Acc: 95.755 Val_Loss: 0.0956  BEST VAL Loss: 0.0956  Val_Acc: 97.057

Epoch 10: Validation loss decreased (0.095591 --> 0.091870).  Saving model ...
	 Train_Loss: 0.1695 Train_Acc: 95.541 Val_Loss: 0.0919  BEST VAL Loss: 0.0919  Val_Acc: 96.714

Epoch 11: Validation loss decreased (0.091870 --> 0.090584).  Saving model ...
	 Train_Loss: 0.1632 Train_Acc: 96.136 Val_Loss: 0.0906  BEST VAL Loss: 0.0906  Val_Acc: 97.450

Epoch 12: Validation loss did not decrease
	 Train_Loss: 0.1582 Train_Acc: 96.080 Val_Loss: 0.0906  BEST VAL Loss: 0.0906  Val_Acc: 96.469

Epoch 13: Validation loss decreased (0.090584 --> 0.090122).  Saving model ...
	 Train_Loss: 0.1534 Train_Acc: 96.031 Val_Loss: 0.0901  BEST VAL Loss: 0.0901  Val_Acc: 97.106

Epoch 14: Validation loss decreased (0.090122 --> 0.088942).  Saving model ...
	 Train_Loss: 0.1490 Train_Acc: 96.338 Val_Loss: 0.0889  BEST VAL Loss: 0.0889  Val_Acc: 97.548

Epoch 15: Validation loss decreased (0.088942 --> 0.087962).  Saving model ...
	 Train_Loss: 0.1453 Train_Acc: 96.307 Val_Loss: 0.0880  BEST VAL Loss: 0.0880  Val_Acc: 97.352

Epoch 16: Validation loss did not decrease
	 Train_Loss: 0.1419 Train_Acc: 96.375 Val_Loss: 0.0908  BEST VAL Loss: 0.0880  Val_Acc: 96.812

Epoch 17: Validation loss did not decrease
	 Train_Loss: 0.1386 Train_Acc: 96.344 Val_Loss: 0.0890  BEST VAL Loss: 0.0880  Val_Acc: 97.106

Epoch 18: Validation loss did not decrease
	 Train_Loss: 0.1353 Train_Acc: 96.767 Val_Loss: 0.0889  BEST VAL Loss: 0.0880  Val_Acc: 97.891

Epoch 19: Validation loss decreased (0.087962 --> 0.087925).  Saving model ...
	 Train_Loss: 0.1326 Train_Acc: 96.804 Val_Loss: 0.0879  BEST VAL Loss: 0.0879  Val_Acc: 97.401

Epoch 20: Validation loss decreased (0.087925 --> 0.086681).  Saving model ...
	 Train_Loss: 0.1296 Train_Acc: 97.050 Val_Loss: 0.0867  BEST VAL Loss: 0.0867  Val_Acc: 97.008

Epoch 21: Validation loss decreased (0.086681 --> 0.086334).  Saving model ...
	 Train_Loss: 0.1271 Train_Acc: 96.780 Val_Loss: 0.0863  BEST VAL Loss: 0.0863  Val_Acc: 97.499

Epoch 22: Validation loss decreased (0.086334 --> 0.085659).  Saving model ...
	 Train_Loss: 0.1244 Train_Acc: 97.270 Val_Loss: 0.0857  BEST VAL Loss: 0.0857  Val_Acc: 97.597

Epoch 23: Validation loss decreased (0.085659 --> 0.085277).  Saving model ...
	 Train_Loss: 0.1225 Train_Acc: 97.037 Val_Loss: 0.0853  BEST VAL Loss: 0.0853  Val_Acc: 96.861

Epoch 24: Validation loss decreased (0.085277 --> 0.084231).  Saving model ...
	 Train_Loss: 0.1205 Train_Acc: 96.712 Val_Loss: 0.0842  BEST VAL Loss: 0.0842  Val_Acc: 97.352

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.1185 Train_Acc: 97.043 Val_Loss: 0.0845  BEST VAL Loss: 0.0842  Val_Acc: 97.940

Epoch 26: Validation loss did not decrease
	 Train_Loss: 0.1166 Train_Acc: 97.270 Val_Loss: 0.0845  BEST VAL Loss: 0.0842  Val_Acc: 98.038

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.1150 Train_Acc: 96.878 Val_Loss: 0.0861  BEST VAL Loss: 0.0842  Val_Acc: 98.136

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.1138 Train_Acc: 96.835 Val_Loss: 0.0855  BEST VAL Loss: 0.0842  Val_Acc: 98.087

Epoch 29: Validation loss did not decrease
	 Train_Loss: 0.1126 Train_Acc: 96.878 Val_Loss: 0.0857  BEST VAL Loss: 0.0842  Val_Acc: 96.812

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.1111 Train_Acc: 97.142 Val_Loss: 0.0854  BEST VAL Loss: 0.0842  Val_Acc: 97.450

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.1099 Train_Acc: 97.277 Val_Loss: 0.0850  BEST VAL Loss: 0.0842  Val_Acc: 97.155

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.1087 Train_Acc: 97.405 Val_Loss: 0.0857  BEST VAL Loss: 0.0842  Val_Acc: 96.420

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.1079 Train_Acc: 96.970 Val_Loss: 0.0854  BEST VAL Loss: 0.0842  Val_Acc: 97.548

Epoch 34: Validation loss did not decrease
	 Train_Loss: 0.1071 Train_Acc: 96.792 Val_Loss: 0.0896  BEST VAL Loss: 0.0842  Val_Acc: 96.910

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.1060 Train_Acc: 96.976 Val_Loss: 0.0895  BEST VAL Loss: 0.0842  Val_Acc: 97.793

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.1050 Train_Acc: 97.307 Val_Loss: 0.0896  BEST VAL Loss: 0.0842  Val_Acc: 97.499

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.1038 Train_Acc: 97.424 Val_Loss: 0.0889  BEST VAL Loss: 0.0842  Val_Acc: 97.499

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.1026 Train_Acc: 97.356 Val_Loss: 0.0881  BEST VAL Loss: 0.0842  Val_Acc: 98.185

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.1016 Train_Acc: 97.142 Val_Loss: 0.0881  BEST VAL Loss: 0.0842  Val_Acc: 98.038

Epoch 40: Validation loss did not decrease
Early stopped at epoch : 40
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.53      0.53      8453
           1       0.48      0.47      0.48      7850

    accuracy                           0.50     16303
   macro avg       0.50      0.50      0.50     16303
weighted avg       0.50      0.50      0.50     16303

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.51      0.51      1057
           1       0.46      0.45      0.46       982

    accuracy                           0.48      2039
   macro avg       0.48      0.48      0.48      2039
weighted avg       0.48      0.48      0.48      2039

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.53      0.52      1057
           1       0.47      0.46      0.47       982

    accuracy                           0.49      2039
   macro avg       0.49      0.49      0.49      2039
weighted avg       0.49      0.49      0.49      2039

              precision    recall  f1-score   support

           0       0.51      0.53      0.52      1057
           1       0.47      0.46      0.47       982

    accuracy                           0.49      2039
   macro avg       0.49      0.49      0.49      2039
weighted avg       0.49      0.49      0.49      2039

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.54      0.54      3835
           1       0.47      0.46      0.47      3398

    accuracy                           0.51      7233
   macro avg       0.50      0.50      0.50      7233
weighted avg       0.50      0.51      0.50      7233

              precision    recall  f1-score   support

           0       0.53      0.54      0.54      3835
           1       0.47      0.46      0.47      3398

    accuracy                           0.51      7233
   macro avg       0.50      0.50      0.50      7233
weighted avg       0.50      0.51      0.50      7233

completed
