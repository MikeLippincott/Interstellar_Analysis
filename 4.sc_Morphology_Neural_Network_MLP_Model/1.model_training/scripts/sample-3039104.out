[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '4210c1ce'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'f7b08182'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '4529b2ff'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'd1e3c5d3'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_0.100_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (30787, 1276)
Number of total missing values across all columns: 61574
Data Subset Is Off
Wells held out for testing: ['B16' 'L22']
Wells to use for training, validation, and testing ['B17' 'B20' 'B21' 'L18' 'L19' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.695320).  Saving model ...
	 Train_Loss: 0.6978 Train_Acc: 47.972 Val_Loss: 0.6953  BEST VAL Loss: 0.6953  Val_Acc: 47.882

Epoch 1: Validation loss decreased (0.695320 --> 0.693640).  Saving model ...
	 Train_Loss: 0.6957 Train_Acc: 50.494 Val_Loss: 0.6936  BEST VAL Loss: 0.6936  Val_Acc: 53.663

Epoch 2: Validation loss decreased (0.693640 --> 0.692469).  Saving model ...
	 Train_Loss: 0.6945 Train_Acc: 50.273 Val_Loss: 0.6925  BEST VAL Loss: 0.6925  Val_Acc: 52.736

Epoch 3: Validation loss decreased (0.692469 --> 0.691572).  Saving model ...
	 Train_Loss: 0.6936 Train_Acc: 50.830 Val_Loss: 0.6916  BEST VAL Loss: 0.6916  Val_Acc: 52.339

Epoch 4: Validation loss decreased (0.691572 --> 0.690778).  Saving model ...
	 Train_Loss: 0.6929 Train_Acc: 50.836 Val_Loss: 0.6908  BEST VAL Loss: 0.6908  Val_Acc: 52.339

Epoch 5: Validation loss decreased (0.690778 --> 0.689978).  Saving model ...
	 Train_Loss: 0.6921 Train_Acc: 51.597 Val_Loss: 0.6900  BEST VAL Loss: 0.6900  Val_Acc: 52.339

Epoch 6: Validation loss decreased (0.689978 --> 0.689168).  Saving model ...
	 Train_Loss: 0.6913 Train_Acc: 51.338 Val_Loss: 0.6892  BEST VAL Loss: 0.6892  Val_Acc: 52.339

Epoch 7: Validation loss decreased (0.689168 --> 0.688283).  Saving model ...
	 Train_Loss: 0.6906 Train_Acc: 51.614 Val_Loss: 0.6883  BEST VAL Loss: 0.6883  Val_Acc: 52.339

Epoch 8: Validation loss decreased (0.688283 --> 0.687354).  Saving model ...
	 Train_Loss: 0.6900 Train_Acc: 51.465 Val_Loss: 0.6874  BEST VAL Loss: 0.6874  Val_Acc: 52.339

Epoch 9: Validation loss decreased (0.687354 --> 0.686385).  Saving model ...
	 Train_Loss: 0.6894 Train_Acc: 51.371 Val_Loss: 0.6864  BEST VAL Loss: 0.6864  Val_Acc: 52.339

Epoch 10: Validation loss decreased (0.686385 --> 0.685354).  Saving model ...
	 Train_Loss: 0.6887 Train_Acc: 52.116 Val_Loss: 0.6854  BEST VAL Loss: 0.6854  Val_Acc: 56.134

Epoch 11: Validation loss decreased (0.685354 --> 0.684263).  Saving model ...
	 Train_Loss: 0.6880 Train_Acc: 53.214 Val_Loss: 0.6843  BEST VAL Loss: 0.6843  Val_Acc: 58.870

Epoch 12: Validation loss decreased (0.684263 --> 0.683152).  Saving model ...
	 Train_Loss: 0.6872 Train_Acc: 54.318 Val_Loss: 0.6832  BEST VAL Loss: 0.6832  Val_Acc: 60.900

Epoch 13: Validation loss decreased (0.683152 --> 0.682024).  Saving model ...
	 Train_Loss: 0.6865 Train_Acc: 55.675 Val_Loss: 0.6820  BEST VAL Loss: 0.6820  Val_Acc: 61.121

Epoch 14: Validation loss decreased (0.682024 --> 0.680882).  Saving model ...
	 Train_Loss: 0.6857 Train_Acc: 56.668 Val_Loss: 0.6809  BEST VAL Loss: 0.6809  Val_Acc: 62.004

Epoch 15: Validation loss decreased (0.680882 --> 0.679741).  Saving model ...
	 Train_Loss: 0.6848 Train_Acc: 56.729 Val_Loss: 0.6797  BEST VAL Loss: 0.6797  Val_Acc: 62.577

Epoch 16: Validation loss decreased (0.679741 --> 0.678600).  Saving model ...
	 Train_Loss: 0.6840 Train_Acc: 57.788 Val_Loss: 0.6786  BEST VAL Loss: 0.6786  Val_Acc: 63.416

Epoch 17: Validation loss decreased (0.678600 --> 0.677451).  Saving model ...
	 Train_Loss: 0.6832 Train_Acc: 58.175 Val_Loss: 0.6775  BEST VAL Loss: 0.6775  Val_Acc: 63.283

Epoch 18: Validation loss decreased (0.677451 --> 0.676330).  Saving model ...
	 Train_Loss: 0.6825 Train_Acc: 57.579 Val_Loss: 0.6763  BEST VAL Loss: 0.6763  Val_Acc: 63.813

Epoch 19: Validation loss decreased (0.676330 --> 0.675181).  Saving model ...
	 Train_Loss: 0.6817 Train_Acc: 58.500 Val_Loss: 0.6752  BEST VAL Loss: 0.6752  Val_Acc: 64.210

Epoch 20: Validation loss decreased (0.675181 --> 0.673998).  Saving model ...
	 Train_Loss: 0.6808 Train_Acc: 58.815 Val_Loss: 0.6740  BEST VAL Loss: 0.6740  Val_Acc: 64.740

Epoch 21: Validation loss decreased (0.673998 --> 0.672858).  Saving model ...
	 Train_Loss: 0.6801 Train_Acc: 59.146 Val_Loss: 0.6729  BEST VAL Loss: 0.6729  Val_Acc: 64.607

Epoch 22: Validation loss decreased (0.672858 --> 0.671732).  Saving model ...
	 Train_Loss: 0.6794 Train_Acc: 59.714 Val_Loss: 0.6717  BEST VAL Loss: 0.6717  Val_Acc: 64.784

Epoch 23: Validation loss decreased (0.671732 --> 0.670535).  Saving model ...
	 Train_Loss: 0.6785 Train_Acc: 60.001 Val_Loss: 0.6705  BEST VAL Loss: 0.6705  Val_Acc: 65.269

Epoch 24: Validation loss decreased (0.670535 --> 0.669327).  Saving model ...
	 Train_Loss: 0.6776 Train_Acc: 60.718 Val_Loss: 0.6693  BEST VAL Loss: 0.6693  Val_Acc: 65.313

Epoch 25: Validation loss decreased (0.669327 --> 0.668161).  Saving model ...
	 Train_Loss: 0.6768 Train_Acc: 60.746 Val_Loss: 0.6682  BEST VAL Loss: 0.6682  Val_Acc: 65.711

Epoch 26: Validation loss decreased (0.668161 --> 0.666979).  Saving model ...
	 Train_Loss: 0.6760 Train_Acc: 61.259 Val_Loss: 0.6670  BEST VAL Loss: 0.6670  Val_Acc: 65.887

Epoch 27: Validation loss decreased (0.666979 --> 0.665773).  Saving model ...
	 Train_Loss: 0.6752 Train_Acc: 61.673 Val_Loss: 0.6658  BEST VAL Loss: 0.6658  Val_Acc: 65.666

Epoch 28: Validation loss decreased (0.665773 --> 0.664611).  Saving model ...
	 Train_Loss: 0.6744 Train_Acc: 61.458 Val_Loss: 0.6646  BEST VAL Loss: 0.6646  Val_Acc: 66.284

Epoch 29: Validation loss decreased (0.664611 --> 0.663489).  Saving model ...
	 Train_Loss: 0.6735 Train_Acc: 61.965 Val_Loss: 0.6635  BEST VAL Loss: 0.6635  Val_Acc: 66.196

Epoch 30: Validation loss decreased (0.663489 --> 0.662281).  Saving model ...
	 Train_Loss: 0.6727 Train_Acc: 62.346 Val_Loss: 0.6623  BEST VAL Loss: 0.6623  Val_Acc: 66.284

Epoch 31: Validation loss decreased (0.662281 --> 0.661059).  Saving model ...
	 Train_Loss: 0.6718 Train_Acc: 61.999 Val_Loss: 0.6611  BEST VAL Loss: 0.6611  Val_Acc: 66.461

Epoch 32: Validation loss decreased (0.661059 --> 0.659956).  Saving model ...
	 Train_Loss: 0.6710 Train_Acc: 62.186 Val_Loss: 0.6600  BEST VAL Loss: 0.6600  Val_Acc: 66.417

Epoch 33: Validation loss decreased (0.659956 --> 0.658793).  Saving model ...
	 Train_Loss: 0.6701 Train_Acc: 62.903 Val_Loss: 0.6588  BEST VAL Loss: 0.6588  Val_Acc: 66.196

Epoch 34: Validation loss decreased (0.658793 --> 0.657664).  Saving model ...
	 Train_Loss: 0.6693 Train_Acc: 62.710 Val_Loss: 0.6577  BEST VAL Loss: 0.6577  Val_Acc: 66.372

Epoch 35: Validation loss decreased (0.657664 --> 0.656518).  Saving model ...
	 Train_Loss: 0.6684 Train_Acc: 63.384 Val_Loss: 0.6565  BEST VAL Loss: 0.6565  Val_Acc: 66.549

Epoch 36: Validation loss decreased (0.656518 --> 0.655443).  Saving model ...
	 Train_Loss: 0.6676 Train_Acc: 63.113 Val_Loss: 0.6554  BEST VAL Loss: 0.6554  Val_Acc: 66.814

Epoch 37: Validation loss decreased (0.655443 --> 0.654351).  Saving model ...
	 Train_Loss: 0.6668 Train_Acc: 63.268 Val_Loss: 0.6544  BEST VAL Loss: 0.6544  Val_Acc: 66.152

Epoch 38: Validation loss decreased (0.654351 --> 0.653296).  Saving model ...
	 Train_Loss: 0.6660 Train_Acc: 63.516 Val_Loss: 0.6533  BEST VAL Loss: 0.6533  Val_Acc: 66.505

Epoch 39: Validation loss decreased (0.653296 --> 0.652176).  Saving model ...
	 Train_Loss: 0.6652 Train_Acc: 63.946 Val_Loss: 0.6522  BEST VAL Loss: 0.6522  Val_Acc: 66.814

Epoch 40: Validation loss decreased (0.652176 --> 0.651143).  Saving model ...
	 Train_Loss: 0.6643 Train_Acc: 64.355 Val_Loss: 0.6511  BEST VAL Loss: 0.6511  Val_Acc: 66.637

Epoch 41: Validation loss decreased (0.651143 --> 0.650132).  Saving model ...
	 Train_Loss: 0.6634 Train_Acc: 64.741 Val_Loss: 0.6501  BEST VAL Loss: 0.6501  Val_Acc: 67.520

Epoch 42: Validation loss decreased (0.650132 --> 0.649106).  Saving model ...
	 Train_Loss: 0.6627 Train_Acc: 64.095 Val_Loss: 0.6491  BEST VAL Loss: 0.6491  Val_Acc: 66.417

Epoch 43: Validation loss decreased (0.649106 --> 0.648198).  Saving model ...
	 Train_Loss: 0.6618 Train_Acc: 65.000 Val_Loss: 0.6482  BEST VAL Loss: 0.6482  Val_Acc: 67.476

Epoch 44: Validation loss decreased (0.648198 --> 0.647229).  Saving model ...
	 Train_Loss: 0.6610 Train_Acc: 64.906 Val_Loss: 0.6472  BEST VAL Loss: 0.6472  Val_Acc: 66.858

Epoch 45: Validation loss decreased (0.647229 --> 0.646257).  Saving model ...
	 Train_Loss: 0.6602 Train_Acc: 65.238 Val_Loss: 0.6463  BEST VAL Loss: 0.6463  Val_Acc: 67.873

Epoch 46: Validation loss decreased (0.646257 --> 0.645326).  Saving model ...
	 Train_Loss: 0.6594 Train_Acc: 64.940 Val_Loss: 0.6453  BEST VAL Loss: 0.6453  Val_Acc: 67.917

Epoch 47: Validation loss decreased (0.645326 --> 0.644372).  Saving model ...
	 Train_Loss: 0.6586 Train_Acc: 65.646 Val_Loss: 0.6444  BEST VAL Loss: 0.6444  Val_Acc: 68.182

Epoch 48: Validation loss decreased (0.644372 --> 0.643421).  Saving model ...
	 Train_Loss: 0.6579 Train_Acc: 65.265 Val_Loss: 0.6434  BEST VAL Loss: 0.6434  Val_Acc: 68.711

Epoch 49: Validation loss decreased (0.643421 --> 0.642497).  Saving model ...
	 Train_Loss: 0.6571 Train_Acc: 65.486 Val_Loss: 0.6425  BEST VAL Loss: 0.6425  Val_Acc: 67.476

Epoch 50: Validation loss decreased (0.642497 --> 0.641602).  Saving model ...
	 Train_Loss: 0.6563 Train_Acc: 65.635 Val_Loss: 0.6416  BEST VAL Loss: 0.6416  Val_Acc: 68.049

Epoch 51: Validation loss decreased (0.641602 --> 0.640719).  Saving model ...
	 Train_Loss: 0.6555 Train_Acc: 66.225 Val_Loss: 0.6407  BEST VAL Loss: 0.6407  Val_Acc: 68.182

Epoch 52: Validation loss decreased (0.640719 --> 0.639869).  Saving model ...
	 Train_Loss: 0.6547 Train_Acc: 65.993 Val_Loss: 0.6399  BEST VAL Loss: 0.6399  Val_Acc: 68.976

Epoch 53: Validation loss decreased (0.639869 --> 0.639027).  Saving model ...
	 Train_Loss: 0.6538 Train_Acc: 66.794 Val_Loss: 0.6390  BEST VAL Loss: 0.6390  Val_Acc: 68.358

Epoch 54: Validation loss decreased (0.639027 --> 0.638192).  Saving model ...
	 Train_Loss: 0.6531 Train_Acc: 66.308 Val_Loss: 0.6382  BEST VAL Loss: 0.6382  Val_Acc: 69.064

Epoch 55: Validation loss decreased (0.638192 --> 0.637325).  Saving model ...
	 Train_Loss: 0.6523 Train_Acc: 66.772 Val_Loss: 0.6373  BEST VAL Loss: 0.6373  Val_Acc: 68.888

Epoch 56: Validation loss decreased (0.637325 --> 0.636480).  Saving model ...
	 Train_Loss: 0.6515 Train_Acc: 66.760 Val_Loss: 0.6365  BEST VAL Loss: 0.6365  Val_Acc: 68.976

Epoch 57: Validation loss decreased (0.636480 --> 0.635654).  Saving model ...
	 Train_Loss: 0.6507 Train_Acc: 67.191 Val_Loss: 0.6357  BEST VAL Loss: 0.6357  Val_Acc: 69.153

Epoch 58: Validation loss decreased (0.635654 --> 0.634802).  Saving model ...
	 Train_Loss: 0.6499 Train_Acc: 67.566 Val_Loss: 0.6348  BEST VAL Loss: 0.6348  Val_Acc: 68.976

Epoch 59: Validation loss decreased (0.634802 --> 0.633980).  Saving model ...
	 Train_Loss: 0.6491 Train_Acc: 67.538 Val_Loss: 0.6340  BEST VAL Loss: 0.6340  Val_Acc: 68.711

Epoch 60: Validation loss decreased (0.633980 --> 0.633198).  Saving model ...
	 Train_Loss: 0.6482 Train_Acc: 67.963 Val_Loss: 0.6332  BEST VAL Loss: 0.6332  Val_Acc: 68.358

Epoch 61: Validation loss decreased (0.633198 --> 0.632433).  Saving model ...
	 Train_Loss: 0.6475 Train_Acc: 67.715 Val_Loss: 0.6324  BEST VAL Loss: 0.6324  Val_Acc: 69.020

Epoch 62: Validation loss decreased (0.632433 --> 0.631709).  Saving model ...
	 Train_Loss: 0.6467 Train_Acc: 67.980 Val_Loss: 0.6317  BEST VAL Loss: 0.6317  Val_Acc: 70.079

Epoch 63: Validation loss decreased (0.631709 --> 0.631025).  Saving model ...
	 Train_Loss: 0.6459 Train_Acc: 67.952 Val_Loss: 0.6310  BEST VAL Loss: 0.6310  Val_Acc: 68.226

Epoch 64: Validation loss decreased (0.631025 --> 0.630645).  Saving model ...
	 Train_Loss: 0.6451 Train_Acc: 68.565 Val_Loss: 0.6306  BEST VAL Loss: 0.6306  Val_Acc: 66.593

Epoch 65: Validation loss decreased (0.630645 --> 0.629882).  Saving model ...
	 Train_Loss: 0.6443 Train_Acc: 68.587 Val_Loss: 0.6299  BEST VAL Loss: 0.6299  Val_Acc: 69.991

Epoch 66: Validation loss decreased (0.629882 --> 0.629159).  Saving model ...
	 Train_Loss: 0.6434 Train_Acc: 68.896 Val_Loss: 0.6292  BEST VAL Loss: 0.6292  Val_Acc: 69.109

Epoch 67: Validation loss decreased (0.629159 --> 0.628432).  Saving model ...
	 Train_Loss: 0.6425 Train_Acc: 69.006 Val_Loss: 0.6284  BEST VAL Loss: 0.6284  Val_Acc: 69.020

Epoch 68: Validation loss decreased (0.628432 --> 0.627748).  Saving model ...
	 Train_Loss: 0.6417 Train_Acc: 68.990 Val_Loss: 0.6277  BEST VAL Loss: 0.6277  Val_Acc: 68.535

Epoch 69: Validation loss decreased (0.627748 --> 0.627031).  Saving model ...
	 Train_Loss: 0.6409 Train_Acc: 69.006 Val_Loss: 0.6270  BEST VAL Loss: 0.6270  Val_Acc: 69.638

Epoch 70: Validation loss decreased (0.627031 --> 0.626354).  Saving model ...
	 Train_Loss: 0.6401 Train_Acc: 69.288 Val_Loss: 0.6264  BEST VAL Loss: 0.6264  Val_Acc: 69.109

Epoch 71: Validation loss decreased (0.626354 --> 0.625591).  Saving model ...
	 Train_Loss: 0.6393 Train_Acc: 69.111 Val_Loss: 0.6256  BEST VAL Loss: 0.6256  Val_Acc: 70.344

Epoch 72: Validation loss decreased (0.625591 --> 0.624995).  Saving model ...
	 Train_Loss: 0.6384 Train_Acc: 69.453 Val_Loss: 0.6250  BEST VAL Loss: 0.6250  Val_Acc: 69.064

Epoch 73: Validation loss decreased (0.624995 --> 0.624346).  Saving model ...
	 Train_Loss: 0.6376 Train_Acc: 69.762 Val_Loss: 0.6243  BEST VAL Loss: 0.6243  Val_Acc: 69.815

Epoch 74: Validation loss decreased (0.624346 --> 0.623736).  Saving model ...
	 Train_Loss: 0.6368 Train_Acc: 69.575 Val_Loss: 0.6237  BEST VAL Loss: 0.6237  Val_Acc: 70.344

Epoch 75: Validation loss decreased (0.623736 --> 0.623129).  Saving model ...
	 Train_Loss: 0.6360 Train_Acc: 69.696 Val_Loss: 0.6231  BEST VAL Loss: 0.6231  Val_Acc: 69.417

Epoch 76: Validation loss decreased (0.623129 --> 0.622507).  Saving model ...
	 Train_Loss: 0.6352 Train_Acc: 70.270 Val_Loss: 0.6225  BEST VAL Loss: 0.6225  Val_Acc: 69.771

Epoch 77: Validation loss decreased (0.622507 --> 0.621903).  Saving model ...
	 Train_Loss: 0.6344 Train_Acc: 70.176 Val_Loss: 0.6219  BEST VAL Loss: 0.6219  Val_Acc: 69.109

Epoch 78: Validation loss decreased (0.621903 --> 0.621376).  Saving model ...
	 Train_Loss: 0.6336 Train_Acc: 70.176 Val_Loss: 0.6214  BEST VAL Loss: 0.6214  Val_Acc: 69.506

Epoch 79: Validation loss decreased (0.621376 --> 0.620817).  Saving model ...
	 Train_Loss: 0.6328 Train_Acc: 70.601 Val_Loss: 0.6208  BEST VAL Loss: 0.6208  Val_Acc: 69.815

Epoch 80: Validation loss decreased (0.620817 --> 0.620300).  Saving model ...
	 Train_Loss: 0.6320 Train_Acc: 70.982 Val_Loss: 0.6203  BEST VAL Loss: 0.6203  Val_Acc: 69.153

Epoch 81: Validation loss decreased (0.620300 --> 0.619769).  Saving model ...
	 Train_Loss: 0.6312 Train_Acc: 70.457 Val_Loss: 0.6198  BEST VAL Loss: 0.6198  Val_Acc: 69.594

Epoch 82: Validation loss decreased (0.619769 --> 0.619322).  Saving model ...
	 Train_Loss: 0.6305 Train_Acc: 70.617 Val_Loss: 0.6193  BEST VAL Loss: 0.6193  Val_Acc: 69.241

Epoch 83: Validation loss decreased (0.619322 --> 0.618781).  Saving model ...
	 Train_Loss: 0.6297 Train_Acc: 70.893 Val_Loss: 0.6188  BEST VAL Loss: 0.6188  Val_Acc: 69.903

Epoch 84: Validation loss decreased (0.618781 --> 0.618282).  Saving model ...
	 Train_Loss: 0.6289 Train_Acc: 71.103 Val_Loss: 0.6183  BEST VAL Loss: 0.6183  Val_Acc: 69.373

Epoch 85: Validation loss decreased (0.618282 --> 0.617696).  Saving model ...
	 Train_Loss: 0.6281 Train_Acc: 71.131 Val_Loss: 0.6177  BEST VAL Loss: 0.6177  Val_Acc: 69.462

Epoch 86: Validation loss decreased (0.617696 --> 0.617279).  Saving model ...
	 Train_Loss: 0.6274 Train_Acc: 71.395 Val_Loss: 0.6173  BEST VAL Loss: 0.6173  Val_Acc: 69.550

Epoch 87: Validation loss decreased (0.617279 --> 0.616851).  Saving model ...
	 Train_Loss: 0.6266 Train_Acc: 70.921 Val_Loss: 0.6169  BEST VAL Loss: 0.6169  Val_Acc: 68.358

Epoch 88: Validation loss decreased (0.616851 --> 0.616435).  Saving model ...
	 Train_Loss: 0.6259 Train_Acc: 71.671 Val_Loss: 0.6164  BEST VAL Loss: 0.6164  Val_Acc: 69.329

Epoch 89: Validation loss decreased (0.616435 --> 0.616049).  Saving model ...
	 Train_Loss: 0.6251 Train_Acc: 71.859 Val_Loss: 0.6160  BEST VAL Loss: 0.6160  Val_Acc: 69.682

Epoch 90: Validation loss decreased (0.616049 --> 0.615637).  Saving model ...
	 Train_Loss: 0.6243 Train_Acc: 72.190 Val_Loss: 0.6156  BEST VAL Loss: 0.6156  Val_Acc: 70.212

Epoch 91: Validation loss decreased (0.615637 --> 0.615162).  Saving model ...
	 Train_Loss: 0.6235 Train_Acc: 72.173 Val_Loss: 0.6152  BEST VAL Loss: 0.6152  Val_Acc: 70.609

Epoch 92: Validation loss decreased (0.615162 --> 0.614755).  Saving model ...
	 Train_Loss: 0.6228 Train_Acc: 72.036 Val_Loss: 0.6148  BEST VAL Loss: 0.6148  Val_Acc: 69.682

Epoch 93: Validation loss decreased (0.614755 --> 0.614318).  Saving model ...
	 Train_Loss: 0.6220 Train_Acc: 71.986 Val_Loss: 0.6143  BEST VAL Loss: 0.6143  Val_Acc: 69.462

Epoch 94: Validation loss decreased (0.614318 --> 0.613834).  Saving model ...
	 Train_Loss: 0.6212 Train_Acc: 71.754 Val_Loss: 0.6138  BEST VAL Loss: 0.6138  Val_Acc: 70.168

Epoch 95: Validation loss decreased (0.613834 --> 0.613393).  Saving model ...
	 Train_Loss: 0.6205 Train_Acc: 72.240 Val_Loss: 0.6134  BEST VAL Loss: 0.6134  Val_Acc: 70.079

Epoch 96: Validation loss decreased (0.613393 --> 0.613013).  Saving model ...
	 Train_Loss: 0.6198 Train_Acc: 72.339 Val_Loss: 0.6130  BEST VAL Loss: 0.6130  Val_Acc: 69.903

Epoch 97: Validation loss decreased (0.613013 --> 0.612706).  Saving model ...
	 Train_Loss: 0.6190 Train_Acc: 72.367 Val_Loss: 0.6127  BEST VAL Loss: 0.6127  Val_Acc: 69.285

Epoch 98: Validation loss decreased (0.612706 --> 0.612342).  Saving model ...
	 Train_Loss: 0.6183 Train_Acc: 72.808 Val_Loss: 0.6123  BEST VAL Loss: 0.6123  Val_Acc: 69.638

Epoch 99: Validation loss decreased (0.612342 --> 0.612056).  Saving model ...
	 Train_Loss: 0.6175 Train_Acc: 73.167 Val_Loss: 0.6121  BEST VAL Loss: 0.6121  Val_Acc: 70.079

Flagellin_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.74      0.84      0.79      8634
           1       0.84      0.73      0.78      9489

    accuracy                           0.79     18123
   macro avg       0.79      0.79      0.79     18123
weighted avg       0.79      0.79      0.79     18123

Flagellin_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.67      0.73      0.70      1080
           1       0.73      0.67      0.70      1186

    accuracy                           0.70      2266
   macro avg       0.70      0.70      0.70      2266
weighted avg       0.70      0.70      0.70      2266

Flagellin_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.63      0.72      0.67      1079
           1       0.70      0.61      0.65      1187

    accuracy                           0.66      2266
   macro avg       0.67      0.66      0.66      2266
weighted avg       0.67      0.66      0.66      2266

              precision    recall  f1-score   support

           0       0.63      0.72      0.67      1079
           1       0.70      0.61      0.65      1187

    accuracy                           0.66      2266
   macro avg       0.67      0.66      0.66      2266
weighted avg       0.67      0.66      0.66      2266

Flagellin_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.66      0.64      0.65      4135
           1       0.64      0.66      0.65      3997

    accuracy                           0.65      8132
   macro avg       0.65      0.65      0.65      8132
weighted avg       0.65      0.65      0.65      8132

              precision    recall  f1-score   support

           0       0.66      0.64      0.65      4135
           1       0.64      0.66      0.65      3997

    accuracy                           0.65      8132
   macro avg       0.65      0.65      0.65      8132
weighted avg       0.65      0.65      0.65      8132

completed
