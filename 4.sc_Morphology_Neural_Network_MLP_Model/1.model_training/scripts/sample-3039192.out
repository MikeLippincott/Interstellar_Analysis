[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b2baaf76'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e3dde8ca'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'eb942f50'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '7afaff55'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_1.000_DMSO_0.025 treatment_name: Thapsigargin_10.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_1.000_DMSO_0.025
TREATMENT_NAME: Thapsigargin_10.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'LPS_1.000_DMSO_0.025']
The dimensions of the data are: (29670, 1276)
Number of total missing values across all columns: 59340
Data Subset Is Off
Wells held out for testing: ['E14' 'D20']
Wells to use for training, validation, and testing ['E15' 'D16' 'D17' 'D21' 'L14' 'L15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.610906).  Saving model ...
	 Train_Loss: 0.6611 Train_Acc: 58.947 Val_Loss: 0.6109  BEST VAL Loss: 0.6109  Val_Acc: 67.797

Epoch 1: Validation loss decreased (0.610906 --> 0.587748).  Saving model ...
	 Train_Loss: 0.6264 Train_Acc: 69.794 Val_Loss: 0.5877  BEST VAL Loss: 0.5877  Val_Acc: 72.139

Epoch 2: Validation loss decreased (0.587748 --> 0.570609).  Saving model ...
	 Train_Loss: 0.6033 Train_Acc: 73.826 Val_Loss: 0.5706  BEST VAL Loss: 0.5706  Val_Acc: 75.124

Epoch 3: Validation loss decreased (0.570609 --> 0.557801).  Saving model ...
	 Train_Loss: 0.5852 Train_Acc: 76.496 Val_Loss: 0.5578  BEST VAL Loss: 0.5578  Val_Acc: 77.702

Epoch 4: Validation loss decreased (0.557801 --> 0.544488).  Saving model ...
	 Train_Loss: 0.5696 Train_Acc: 78.843 Val_Loss: 0.5445  BEST VAL Loss: 0.5445  Val_Acc: 79.602

Epoch 5: Validation loss decreased (0.544488 --> 0.529499).  Saving model ...
	 Train_Loss: 0.5547 Train_Acc: 80.540 Val_Loss: 0.5295  BEST VAL Loss: 0.5295  Val_Acc: 81.502

Epoch 6: Validation loss decreased (0.529499 --> 0.512607).  Saving model ...
	 Train_Loss: 0.5373 Train_Acc: 82.259 Val_Loss: 0.5126  BEST VAL Loss: 0.5126  Val_Acc: 83.175

Epoch 7: Validation loss decreased (0.512607 --> 0.492899).  Saving model ...
	 Train_Loss: 0.5182 Train_Acc: 83.520 Val_Loss: 0.4929  BEST VAL Loss: 0.4929  Val_Acc: 85.527

Epoch 8: Validation loss decreased (0.492899 --> 0.475144).  Saving model ...
	 Train_Loss: 0.4995 Train_Acc: 85.205 Val_Loss: 0.4751  BEST VAL Loss: 0.4751  Val_Acc: 87.110

Epoch 9: Validation loss decreased (0.475144 --> 0.458738).  Saving model ...
	 Train_Loss: 0.4825 Train_Acc: 85.720 Val_Loss: 0.4587  BEST VAL Loss: 0.4587  Val_Acc: 87.517

Epoch 10: Validation loss decreased (0.458738 --> 0.443802).  Saving model ...
	 Train_Loss: 0.4668 Train_Acc: 86.981 Val_Loss: 0.4438  BEST VAL Loss: 0.4438  Val_Acc: 88.195

Epoch 11: Validation loss decreased (0.443802 --> 0.429682).  Saving model ...
	 Train_Loss: 0.4523 Train_Acc: 87.507 Val_Loss: 0.4297  BEST VAL Loss: 0.4297  Val_Acc: 88.467

Epoch 12: Validation loss decreased (0.429682 --> 0.416790).  Saving model ...
	 Train_Loss: 0.4390 Train_Acc: 88.203 Val_Loss: 0.4168  BEST VAL Loss: 0.4168  Val_Acc: 89.190

Epoch 13: Validation loss decreased (0.416790 --> 0.405114).  Saving model ...
	 Train_Loss: 0.4269 Train_Acc: 88.655 Val_Loss: 0.4051  BEST VAL Loss: 0.4051  Val_Acc: 89.371

Epoch 14: Validation loss decreased (0.405114 --> 0.394474).  Saving model ...
	 Train_Loss: 0.4158 Train_Acc: 89.062 Val_Loss: 0.3945  BEST VAL Loss: 0.3945  Val_Acc: 89.869

Epoch 15: Validation loss decreased (0.394474 --> 0.385051).  Saving model ...
	 Train_Loss: 0.4054 Train_Acc: 89.634 Val_Loss: 0.3851  BEST VAL Loss: 0.3851  Val_Acc: 89.824

Epoch 16: Validation loss decreased (0.385051 --> 0.375661).  Saving model ...
	 Train_Loss: 0.3958 Train_Acc: 89.962 Val_Loss: 0.3757  BEST VAL Loss: 0.3757  Val_Acc: 90.050

Epoch 17: Validation loss decreased (0.375661 --> 0.366697).  Saving model ...
	 Train_Loss: 0.3870 Train_Acc: 90.126 Val_Loss: 0.3667  BEST VAL Loss: 0.3667  Val_Acc: 90.321

Epoch 18: Validation loss decreased (0.366697 --> 0.359678).  Saving model ...
	 Train_Loss: 0.3788 Train_Acc: 90.448 Val_Loss: 0.3597  BEST VAL Loss: 0.3597  Val_Acc: 90.457

Epoch 19: Validation loss decreased (0.359678 --> 0.352599).  Saving model ...
	 Train_Loss: 0.3710 Train_Acc: 90.906 Val_Loss: 0.3526  BEST VAL Loss: 0.3526  Val_Acc: 91.000

Epoch 20: Validation loss decreased (0.352599 --> 0.345780).  Saving model ...
	 Train_Loss: 0.3637 Train_Acc: 91.217 Val_Loss: 0.3458  BEST VAL Loss: 0.3458  Val_Acc: 90.864

Epoch 21: Validation loss decreased (0.345780 --> 0.339972).  Saving model ...
	 Train_Loss: 0.3569 Train_Acc: 91.308 Val_Loss: 0.3400  BEST VAL Loss: 0.3400  Val_Acc: 90.909

Epoch 22: Validation loss decreased (0.339972 --> 0.334246).  Saving model ...
	 Train_Loss: 0.3505 Train_Acc: 91.607 Val_Loss: 0.3342  BEST VAL Loss: 0.3342  Val_Acc: 91.135

Epoch 23: Validation loss decreased (0.334246 --> 0.328918).  Saving model ...
	 Train_Loss: 0.3443 Train_Acc: 92.162 Val_Loss: 0.3289  BEST VAL Loss: 0.3289  Val_Acc: 91.180

Epoch 24: Validation loss decreased (0.328918 --> 0.324187).  Saving model ...
	 Train_Loss: 0.3387 Train_Acc: 91.783 Val_Loss: 0.3242  BEST VAL Loss: 0.3242  Val_Acc: 91.316

Epoch 25: Validation loss decreased (0.324187 --> 0.319558).  Saving model ...
	 Train_Loss: 0.3333 Train_Acc: 91.998 Val_Loss: 0.3196  BEST VAL Loss: 0.3196  Val_Acc: 91.452

Epoch 26: Validation loss decreased (0.319558 --> 0.315663).  Saving model ...
	 Train_Loss: 0.3281 Train_Acc: 92.190 Val_Loss: 0.3157  BEST VAL Loss: 0.3157  Val_Acc: 91.407

Epoch 27: Validation loss decreased (0.315663 --> 0.311345).  Saving model ...
	 Train_Loss: 0.3232 Train_Acc: 92.359 Val_Loss: 0.3113  BEST VAL Loss: 0.3113  Val_Acc: 91.588

Epoch 28: Validation loss decreased (0.311345 --> 0.307797).  Saving model ...
	 Train_Loss: 0.3185 Train_Acc: 92.727 Val_Loss: 0.3078  BEST VAL Loss: 0.3078  Val_Acc: 91.768

Epoch 29: Validation loss decreased (0.307797 --> 0.304314).  Saving model ...
	 Train_Loss: 0.3140 Train_Acc: 92.744 Val_Loss: 0.3043  BEST VAL Loss: 0.3043  Val_Acc: 92.040

Epoch 30: Validation loss decreased (0.304314 --> 0.300835).  Saving model ...
	 Train_Loss: 0.3097 Train_Acc: 92.987 Val_Loss: 0.3008  BEST VAL Loss: 0.3008  Val_Acc: 91.814

Epoch 31: Validation loss decreased (0.300835 --> 0.297568).  Saving model ...
	 Train_Loss: 0.3057 Train_Acc: 92.982 Val_Loss: 0.2976  BEST VAL Loss: 0.2976  Val_Acc: 91.814

Epoch 32: Validation loss decreased (0.297568 --> 0.294465).  Saving model ...
	 Train_Loss: 0.3017 Train_Acc: 93.270 Val_Loss: 0.2945  BEST VAL Loss: 0.2945  Val_Acc: 91.949

Epoch 33: Validation loss decreased (0.294465 --> 0.291777).  Saving model ...
	 Train_Loss: 0.2979 Train_Acc: 93.344 Val_Loss: 0.2918  BEST VAL Loss: 0.2918  Val_Acc: 92.221

Epoch 34: Validation loss decreased (0.291777 --> 0.288763).  Saving model ...
	 Train_Loss: 0.2943 Train_Acc: 93.564 Val_Loss: 0.2888  BEST VAL Loss: 0.2888  Val_Acc: 92.040

Epoch 35: Validation loss decreased (0.288763 --> 0.285941).  Saving model ...
	 Train_Loss: 0.2908 Train_Acc: 93.462 Val_Loss: 0.2859  BEST VAL Loss: 0.2859  Val_Acc: 92.221

Epoch 36: Validation loss decreased (0.285941 --> 0.283470).  Saving model ...
	 Train_Loss: 0.2875 Train_Acc: 93.575 Val_Loss: 0.2835  BEST VAL Loss: 0.2835  Val_Acc: 92.402

Epoch 37: Validation loss decreased (0.283470 --> 0.281202).  Saving model ...
	 Train_Loss: 0.2842 Train_Acc: 93.677 Val_Loss: 0.2812  BEST VAL Loss: 0.2812  Val_Acc: 92.085

Epoch 38: Validation loss decreased (0.281202 --> 0.278784).  Saving model ...
	 Train_Loss: 0.2811 Train_Acc: 93.722 Val_Loss: 0.2788  BEST VAL Loss: 0.2788  Val_Acc: 92.221

Epoch 39: Validation loss decreased (0.278784 --> 0.276424).  Saving model ...
	 Train_Loss: 0.2781 Train_Acc: 93.796 Val_Loss: 0.2764  BEST VAL Loss: 0.2764  Val_Acc: 92.447

Epoch 40: Validation loss decreased (0.276424 --> 0.274207).  Saving model ...
	 Train_Loss: 0.2752 Train_Acc: 93.864 Val_Loss: 0.2742  BEST VAL Loss: 0.2742  Val_Acc: 92.266

Epoch 41: Validation loss decreased (0.274207 --> 0.272285).  Saving model ...
	 Train_Loss: 0.2723 Train_Acc: 94.005 Val_Loss: 0.2723  BEST VAL Loss: 0.2723  Val_Acc: 92.537

Epoch 42: Validation loss decreased (0.272285 --> 0.270065).  Saving model ...
	 Train_Loss: 0.2696 Train_Acc: 93.886 Val_Loss: 0.2701  BEST VAL Loss: 0.2701  Val_Acc: 92.718

Epoch 43: Validation loss decreased (0.270065 --> 0.268231).  Saving model ...
	 Train_Loss: 0.2669 Train_Acc: 94.429 Val_Loss: 0.2682  BEST VAL Loss: 0.2682  Val_Acc: 92.402

Epoch 44: Validation loss decreased (0.268231 --> 0.266508).  Saving model ...
	 Train_Loss: 0.2642 Train_Acc: 94.350 Val_Loss: 0.2665  BEST VAL Loss: 0.2665  Val_Acc: 92.763

Epoch 45: Validation loss decreased (0.266508 --> 0.264530).  Saving model ...
	 Train_Loss: 0.2617 Train_Acc: 94.271 Val_Loss: 0.2645  BEST VAL Loss: 0.2645  Val_Acc: 92.628

Epoch 46: Validation loss decreased (0.264530 --> 0.262563).  Saving model ...
	 Train_Loss: 0.2593 Train_Acc: 94.361 Val_Loss: 0.2626  BEST VAL Loss: 0.2626  Val_Acc: 92.718

Epoch 47: Validation loss decreased (0.262563 --> 0.260753).  Saving model ...
	 Train_Loss: 0.2570 Train_Acc: 94.203 Val_Loss: 0.2608  BEST VAL Loss: 0.2608  Val_Acc: 92.673

Epoch 48: Validation loss decreased (0.260753 --> 0.259201).  Saving model ...
	 Train_Loss: 0.2547 Train_Acc: 94.644 Val_Loss: 0.2592  BEST VAL Loss: 0.2592  Val_Acc: 93.035

Epoch 49: Validation loss decreased (0.259201 --> 0.257499).  Saving model ...
	 Train_Loss: 0.2524 Train_Acc: 94.469 Val_Loss: 0.2575  BEST VAL Loss: 0.2575  Val_Acc: 92.628

Epoch 50: Validation loss decreased (0.257499 --> 0.256043).  Saving model ...
	 Train_Loss: 0.2502 Train_Acc: 94.582 Val_Loss: 0.2560  BEST VAL Loss: 0.2560  Val_Acc: 92.854

Epoch 51: Validation loss decreased (0.256043 --> 0.254632).  Saving model ...
	 Train_Loss: 0.2482 Train_Acc: 94.610 Val_Loss: 0.2546  BEST VAL Loss: 0.2546  Val_Acc: 92.944

Epoch 52: Validation loss decreased (0.254632 --> 0.253296).  Saving model ...
	 Train_Loss: 0.2461 Train_Acc: 94.684 Val_Loss: 0.2533  BEST VAL Loss: 0.2533  Val_Acc: 93.080

Epoch 53: Validation loss decreased (0.253296 --> 0.251768).  Saving model ...
	 Train_Loss: 0.2441 Train_Acc: 94.706 Val_Loss: 0.2518  BEST VAL Loss: 0.2518  Val_Acc: 92.990

Epoch 54: Validation loss decreased (0.251768 --> 0.250240).  Saving model ...
	 Train_Loss: 0.2421 Train_Acc: 94.735 Val_Loss: 0.2502  BEST VAL Loss: 0.2502  Val_Acc: 92.990

Epoch 55: Validation loss decreased (0.250240 --> 0.248679).  Saving model ...
	 Train_Loss: 0.2402 Train_Acc: 94.978 Val_Loss: 0.2487  BEST VAL Loss: 0.2487  Val_Acc: 93.080

Epoch 56: Validation loss decreased (0.248679 --> 0.247351).  Saving model ...
	 Train_Loss: 0.2383 Train_Acc: 95.034 Val_Loss: 0.2474  BEST VAL Loss: 0.2474  Val_Acc: 93.080

Epoch 57: Validation loss decreased (0.247351 --> 0.246157).  Saving model ...
	 Train_Loss: 0.2365 Train_Acc: 95.034 Val_Loss: 0.2462  BEST VAL Loss: 0.2462  Val_Acc: 93.125

Epoch 58: Validation loss decreased (0.246157 --> 0.244960).  Saving model ...
	 Train_Loss: 0.2347 Train_Acc: 95.012 Val_Loss: 0.2450  BEST VAL Loss: 0.2450  Val_Acc: 93.261

Epoch 59: Validation loss decreased (0.244960 --> 0.243734).  Saving model ...
	 Train_Loss: 0.2330 Train_Acc: 95.125 Val_Loss: 0.2437  BEST VAL Loss: 0.2437  Val_Acc: 93.261

Epoch 60: Validation loss decreased (0.243734 --> 0.242398).  Saving model ...
	 Train_Loss: 0.2314 Train_Acc: 94.893 Val_Loss: 0.2424  BEST VAL Loss: 0.2424  Val_Acc: 93.261

Epoch 61: Validation loss decreased (0.242398 --> 0.241253).  Saving model ...
	 Train_Loss: 0.2297 Train_Acc: 95.159 Val_Loss: 0.2413  BEST VAL Loss: 0.2413  Val_Acc: 92.990

Epoch 62: Validation loss decreased (0.241253 --> 0.240004).  Saving model ...
	 Train_Loss: 0.2281 Train_Acc: 95.295 Val_Loss: 0.2400  BEST VAL Loss: 0.2400  Val_Acc: 93.216

Epoch 63: Validation loss decreased (0.240004 --> 0.238691).  Saving model ...
	 Train_Loss: 0.2265 Train_Acc: 95.215 Val_Loss: 0.2387  BEST VAL Loss: 0.2387  Val_Acc: 93.125

Epoch 64: Validation loss decreased (0.238691 --> 0.237860).  Saving model ...
	 Train_Loss: 0.2249 Train_Acc: 95.368 Val_Loss: 0.2379  BEST VAL Loss: 0.2379  Val_Acc: 92.990

Epoch 65: Validation loss decreased (0.237860 --> 0.236945).  Saving model ...
	 Train_Loss: 0.2234 Train_Acc: 95.340 Val_Loss: 0.2369  BEST VAL Loss: 0.2369  Val_Acc: 93.261

Epoch 66: Validation loss decreased (0.236945 --> 0.236027).  Saving model ...
	 Train_Loss: 0.2220 Train_Acc: 95.232 Val_Loss: 0.2360  BEST VAL Loss: 0.2360  Val_Acc: 93.351

Epoch 67: Validation loss decreased (0.236027 --> 0.235124).  Saving model ...
	 Train_Loss: 0.2205 Train_Acc: 95.464 Val_Loss: 0.2351  BEST VAL Loss: 0.2351  Val_Acc: 93.397

Epoch 68: Validation loss decreased (0.235124 --> 0.234169).  Saving model ...
	 Train_Loss: 0.2191 Train_Acc: 95.357 Val_Loss: 0.2342  BEST VAL Loss: 0.2342  Val_Acc: 93.261

Epoch 69: Validation loss decreased (0.234169 --> 0.233224).  Saving model ...
	 Train_Loss: 0.2177 Train_Acc: 95.685 Val_Loss: 0.2332  BEST VAL Loss: 0.2332  Val_Acc: 93.442

Epoch 70: Validation loss decreased (0.233224 --> 0.232284).  Saving model ...
	 Train_Loss: 0.2163 Train_Acc: 95.470 Val_Loss: 0.2323  BEST VAL Loss: 0.2323  Val_Acc: 93.442

Epoch 71: Validation loss decreased (0.232284 --> 0.231627).  Saving model ...
	 Train_Loss: 0.2149 Train_Acc: 95.702 Val_Loss: 0.2316  BEST VAL Loss: 0.2316  Val_Acc: 93.171

Epoch 72: Validation loss decreased (0.231627 --> 0.230656).  Saving model ...
	 Train_Loss: 0.2136 Train_Acc: 95.464 Val_Loss: 0.2307  BEST VAL Loss: 0.2307  Val_Acc: 93.306

Epoch 73: Validation loss decreased (0.230656 --> 0.229900).  Saving model ...
	 Train_Loss: 0.2123 Train_Acc: 95.730 Val_Loss: 0.2299  BEST VAL Loss: 0.2299  Val_Acc: 92.944

Epoch 74: Validation loss decreased (0.229900 --> 0.229139).  Saving model ...
	 Train_Loss: 0.2111 Train_Acc: 95.668 Val_Loss: 0.2291  BEST VAL Loss: 0.2291  Val_Acc: 93.080

Epoch 75: Validation loss decreased (0.229139 --> 0.228378).  Saving model ...
	 Train_Loss: 0.2098 Train_Acc: 95.623 Val_Loss: 0.2284  BEST VAL Loss: 0.2284  Val_Acc: 93.397

Epoch 76: Validation loss decreased (0.228378 --> 0.227641).  Saving model ...
	 Train_Loss: 0.2086 Train_Acc: 95.798 Val_Loss: 0.2276  BEST VAL Loss: 0.2276  Val_Acc: 93.487

Epoch 77: Validation loss decreased (0.227641 --> 0.227124).  Saving model ...
	 Train_Loss: 0.2074 Train_Acc: 95.888 Val_Loss: 0.2271  BEST VAL Loss: 0.2271  Val_Acc: 93.623

Epoch 78: Validation loss decreased (0.227124 --> 0.226280).  Saving model ...
	 Train_Loss: 0.2062 Train_Acc: 95.702 Val_Loss: 0.2263  BEST VAL Loss: 0.2263  Val_Acc: 93.487

Epoch 79: Validation loss decreased (0.226280 --> 0.225366).  Saving model ...
	 Train_Loss: 0.2051 Train_Acc: 95.843 Val_Loss: 0.2254  BEST VAL Loss: 0.2254  Val_Acc: 93.532

Epoch 80: Validation loss decreased (0.225366 --> 0.224932).  Saving model ...
	 Train_Loss: 0.2039 Train_Acc: 95.872 Val_Loss: 0.2249  BEST VAL Loss: 0.2249  Val_Acc: 93.171

Epoch 81: Validation loss decreased (0.224932 --> 0.224212).  Saving model ...
	 Train_Loss: 0.2028 Train_Acc: 95.922 Val_Loss: 0.2242  BEST VAL Loss: 0.2242  Val_Acc: 93.261

Epoch 82: Validation loss decreased (0.224212 --> 0.223712).  Saving model ...
	 Train_Loss: 0.2017 Train_Acc: 95.996 Val_Loss: 0.2237  BEST VAL Loss: 0.2237  Val_Acc: 93.351

Epoch 83: Validation loss decreased (0.223712 --> 0.222981).  Saving model ...
	 Train_Loss: 0.2006 Train_Acc: 95.900 Val_Loss: 0.2230  BEST VAL Loss: 0.2230  Val_Acc: 93.442

Epoch 84: Validation loss decreased (0.222981 --> 0.222496).  Saving model ...
	 Train_Loss: 0.1995 Train_Acc: 96.052 Val_Loss: 0.2225  BEST VAL Loss: 0.2225  Val_Acc: 93.442

Epoch 85: Validation loss decreased (0.222496 --> 0.222141).  Saving model ...
	 Train_Loss: 0.1985 Train_Acc: 95.792 Val_Loss: 0.2221  BEST VAL Loss: 0.2221  Val_Acc: 93.442

Epoch 86: Validation loss decreased (0.222141 --> 0.221510).  Saving model ...
	 Train_Loss: 0.1974 Train_Acc: 96.064 Val_Loss: 0.2215  BEST VAL Loss: 0.2215  Val_Acc: 93.804

Epoch 87: Validation loss decreased (0.221510 --> 0.220896).  Saving model ...
	 Train_Loss: 0.1964 Train_Acc: 95.877 Val_Loss: 0.2209  BEST VAL Loss: 0.2209  Val_Acc: 93.849

Epoch 88: Validation loss decreased (0.220896 --> 0.220229).  Saving model ...
	 Train_Loss: 0.1954 Train_Acc: 96.052 Val_Loss: 0.2202  BEST VAL Loss: 0.2202  Val_Acc: 93.578

Epoch 89: Validation loss decreased (0.220229 --> 0.219613).  Saving model ...
	 Train_Loss: 0.1944 Train_Acc: 96.216 Val_Loss: 0.2196  BEST VAL Loss: 0.2196  Val_Acc: 93.623

Epoch 90: Validation loss decreased (0.219613 --> 0.219210).  Saving model ...
	 Train_Loss: 0.1934 Train_Acc: 96.188 Val_Loss: 0.2192  BEST VAL Loss: 0.2192  Val_Acc: 93.397

Epoch 91: Validation loss decreased (0.219210 --> 0.218713).  Saving model ...
	 Train_Loss: 0.1924 Train_Acc: 96.216 Val_Loss: 0.2187  BEST VAL Loss: 0.2187  Val_Acc: 93.758

Epoch 92: Validation loss decreased (0.218713 --> 0.218176).  Saving model ...
	 Train_Loss: 0.1915 Train_Acc: 96.166 Val_Loss: 0.2182  BEST VAL Loss: 0.2182  Val_Acc: 93.804

Epoch 93: Validation loss decreased (0.218176 --> 0.217692).  Saving model ...
	 Train_Loss: 0.1905 Train_Acc: 96.216 Val_Loss: 0.2177  BEST VAL Loss: 0.2177  Val_Acc: 93.668

Epoch 94: Validation loss decreased (0.217692 --> 0.217148).  Saving model ...
	 Train_Loss: 0.1896 Train_Acc: 96.200 Val_Loss: 0.2171  BEST VAL Loss: 0.2171  Val_Acc: 93.804

Epoch 95: Validation loss decreased (0.217148 --> 0.216714).  Saving model ...
	 Train_Loss: 0.1887 Train_Acc: 96.239 Val_Loss: 0.2167  BEST VAL Loss: 0.2167  Val_Acc: 93.668

Epoch 96: Validation loss decreased (0.216714 --> 0.216244).  Saving model ...
	 Train_Loss: 0.1878 Train_Acc: 96.284 Val_Loss: 0.2162  BEST VAL Loss: 0.2162  Val_Acc: 93.532

Epoch 97: Validation loss decreased (0.216244 --> 0.215824).  Saving model ...
	 Train_Loss: 0.1869 Train_Acc: 96.437 Val_Loss: 0.2158  BEST VAL Loss: 0.2158  Val_Acc: 93.261

Epoch 98: Validation loss decreased (0.215824 --> 0.215504).  Saving model ...
	 Train_Loss: 0.1860 Train_Acc: 96.279 Val_Loss: 0.2155  BEST VAL Loss: 0.2155  Val_Acc: 93.623

Epoch 99: Validation loss decreased (0.215504 --> 0.215160).  Saving model ...
	 Train_Loss: 0.1852 Train_Acc: 96.307 Val_Loss: 0.2152  BEST VAL Loss: 0.2152  Val_Acc: 93.758

LPS_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.54      0.55      9832
           1       0.44      0.44      0.44      7850

    accuracy                           0.50     17682
   macro avg       0.49      0.49      0.49     17682
weighted avg       0.50      0.50      0.50     17682

LPS_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.56      0.54      0.55      1229
           1       0.44      0.45      0.45       982

    accuracy                           0.50      2211
   macro avg       0.50      0.50      0.50      2211
weighted avg       0.51      0.50      0.50      2211

LPS_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.54      0.55      0.55      1229
           1       0.43      0.42      0.42       982

    accuracy                           0.49      2211
   macro avg       0.48      0.48      0.48      2211
weighted avg       0.49      0.49      0.49      2211

              precision    recall  f1-score   support

           0       0.54      0.55      0.55      1229
           1       0.43      0.42      0.42       982

    accuracy                           0.49      2211
   macro avg       0.48      0.48      0.48      2211
weighted avg       0.49      0.49      0.49      2211

LPS_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.54      0.55      4168
           1       0.45      0.47      0.46      3398

    accuracy                           0.51      7566
   macro avg       0.50      0.50      0.50      7566
weighted avg       0.51      0.51      0.51      7566

              precision    recall  f1-score   support

           0       0.55      0.54      0.55      4168
           1       0.45      0.47      0.46      3398

    accuracy                           0.51      7566
   macro avg       0.50      0.50      0.50      7566
weighted avg       0.51      0.51      0.51      7566

completed
