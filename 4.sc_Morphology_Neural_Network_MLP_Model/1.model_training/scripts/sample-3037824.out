[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'a5b260ea'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '8b5730ad'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '390133d2'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'a8a953d6'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_100.000_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_100.000_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_100.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (30915, 1276)
Number of total missing values across all columns: 61830
Data Subset Is Off
Wells held out for testing: ['J16' 'L22']
Wells to use for training, validation, and testing ['J17' 'L18' 'L19' 'J20' 'J21' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.645652).  Saving model ...
	 Train_Loss: 1.0628 Train_Acc: 52.952 Val_Loss: 0.6457  BEST VAL Loss: 0.6457  Val_Acc: 60.097

Epoch 1: Validation loss decreased (0.645652 --> 0.597122).  Saving model ...
	 Train_Loss: 0.8447 Train_Acc: 60.735 Val_Loss: 0.5971  BEST VAL Loss: 0.5971  Val_Acc: 79.674

Epoch 2: Validation loss decreased (0.597122 --> 0.545753).  Saving model ...
	 Train_Loss: 0.7479 Train_Acc: 67.819 Val_Loss: 0.5458  BEST VAL Loss: 0.5458  Val_Acc: 84.744

Epoch 3: Validation loss decreased (0.545753 --> 0.501565).  Saving model ...
	 Train_Loss: 0.6845 Train_Acc: 70.580 Val_Loss: 0.5016  BEST VAL Loss: 0.5016  Val_Acc: 87.390

Epoch 4: Validation loss decreased (0.501565 --> 0.461335).  Saving model ...
	 Train_Loss: 0.6386 Train_Acc: 71.683 Val_Loss: 0.4613  BEST VAL Loss: 0.4613  Val_Acc: 89.550

Epoch 5: Validation loss decreased (0.461335 --> 0.430102).  Saving model ...
	 Train_Loss: 0.6034 Train_Acc: 72.124 Val_Loss: 0.4301  BEST VAL Loss: 0.4301  Val_Acc: 85.626

Epoch 6: Validation loss decreased (0.430102 --> 0.403342).  Saving model ...
	 Train_Loss: 0.5748 Train_Acc: 73.855 Val_Loss: 0.4033  BEST VAL Loss: 0.4033  Val_Acc: 89.683

Epoch 7: Validation loss decreased (0.403342 --> 0.381083).  Saving model ...
	 Train_Loss: 0.5514 Train_Acc: 75.591 Val_Loss: 0.3811  BEST VAL Loss: 0.3811  Val_Acc: 89.418

Epoch 8: Validation loss decreased (0.381083 --> 0.365921).  Saving model ...
	 Train_Loss: 0.5310 Train_Acc: 77.002 Val_Loss: 0.3659  BEST VAL Loss: 0.3659  Val_Acc: 89.683

Epoch 9: Validation loss decreased (0.365921 --> 0.350226).  Saving model ...
	 Train_Loss: 0.5144 Train_Acc: 78.050 Val_Loss: 0.3502  BEST VAL Loss: 0.3502  Val_Acc: 90.432

Epoch 10: Validation loss decreased (0.350226 --> 0.339338).  Saving model ...
	 Train_Loss: 0.4999 Train_Acc: 78.728 Val_Loss: 0.3393  BEST VAL Loss: 0.3393  Val_Acc: 90.388

Epoch 11: Validation loss decreased (0.339338 --> 0.327048).  Saving model ...
	 Train_Loss: 0.4878 Train_Acc: 79.097 Val_Loss: 0.3270  BEST VAL Loss: 0.3270  Val_Acc: 91.005

Epoch 12: Validation loss decreased (0.327048 --> 0.317925).  Saving model ...
	 Train_Loss: 0.4768 Train_Acc: 79.229 Val_Loss: 0.3179  BEST VAL Loss: 0.3179  Val_Acc: 90.520

Epoch 13: Validation loss decreased (0.317925 --> 0.307898).  Saving model ...
	 Train_Loss: 0.4670 Train_Acc: 79.571 Val_Loss: 0.3079  BEST VAL Loss: 0.3079  Val_Acc: 91.843

Epoch 14: Validation loss decreased (0.307898 --> 0.301038).  Saving model ...
	 Train_Loss: 0.4548 Train_Acc: 86.153 Val_Loss: 0.3010  BEST VAL Loss: 0.3010  Val_Acc: 92.196

Epoch 15: Validation loss decreased (0.301038 --> 0.296314).  Saving model ...
	 Train_Loss: 0.4426 Train_Acc: 88.567 Val_Loss: 0.2963  BEST VAL Loss: 0.2963  Val_Acc: 91.534

Epoch 16: Validation loss decreased (0.296314 --> 0.289702).  Saving model ...
	 Train_Loss: 0.4316 Train_Acc: 88.694 Val_Loss: 0.2897  BEST VAL Loss: 0.2897  Val_Acc: 93.519

Epoch 17: Validation loss decreased (0.289702 --> 0.284575).  Saving model ...
	 Train_Loss: 0.4209 Train_Acc: 89.124 Val_Loss: 0.2846  BEST VAL Loss: 0.2846  Val_Acc: 92.945

Epoch 18: Validation loss decreased (0.284575 --> 0.280650).  Saving model ...
	 Train_Loss: 0.4118 Train_Acc: 89.130 Val_Loss: 0.2806  BEST VAL Loss: 0.2806  Val_Acc: 91.975

Epoch 19: Validation loss decreased (0.280650 --> 0.275491).  Saving model ...
	 Train_Loss: 0.4031 Train_Acc: 89.725 Val_Loss: 0.2755  BEST VAL Loss: 0.2755  Val_Acc: 93.078

Epoch 20: Validation loss decreased (0.275491 --> 0.270627).  Saving model ...
	 Train_Loss: 0.3950 Train_Acc: 89.967 Val_Loss: 0.2706  BEST VAL Loss: 0.2706  Val_Acc: 92.372

Epoch 21: Validation loss decreased (0.270627 --> 0.268787).  Saving model ...
	 Train_Loss: 0.3869 Train_Acc: 90.557 Val_Loss: 0.2688  BEST VAL Loss: 0.2688  Val_Acc: 92.725

Epoch 22: Validation loss decreased (0.268787 --> 0.264313).  Saving model ...
	 Train_Loss: 0.3795 Train_Acc: 90.673 Val_Loss: 0.2643  BEST VAL Loss: 0.2643  Val_Acc: 93.827

Epoch 23: Validation loss decreased (0.264313 --> 0.260197).  Saving model ...
	 Train_Loss: 0.3729 Train_Acc: 90.568 Val_Loss: 0.2602  BEST VAL Loss: 0.2602  Val_Acc: 93.695

Epoch 24: Validation loss decreased (0.260197 --> 0.256656).  Saving model ...
	 Train_Loss: 0.3665 Train_Acc: 90.750 Val_Loss: 0.2567  BEST VAL Loss: 0.2567  Val_Acc: 94.048

Epoch 25: Validation loss decreased (0.256656 --> 0.253413).  Saving model ...
	 Train_Loss: 0.3605 Train_Acc: 90.849 Val_Loss: 0.2534  BEST VAL Loss: 0.2534  Val_Acc: 94.312

Epoch 26: Validation loss decreased (0.253413 --> 0.250172).  Saving model ...
	 Train_Loss: 0.3547 Train_Acc: 91.544 Val_Loss: 0.2502  BEST VAL Loss: 0.2502  Val_Acc: 93.783

Epoch 27: Validation loss decreased (0.250172 --> 0.248105).  Saving model ...
	 Train_Loss: 0.3490 Train_Acc: 91.500 Val_Loss: 0.2481  BEST VAL Loss: 0.2481  Val_Acc: 94.268

Epoch 28: Validation loss decreased (0.248105 --> 0.245662).  Saving model ...
	 Train_Loss: 0.3441 Train_Acc: 91.109 Val_Loss: 0.2457  BEST VAL Loss: 0.2457  Val_Acc: 93.739

Epoch 29: Validation loss decreased (0.245662 --> 0.244226).  Saving model ...
	 Train_Loss: 0.3394 Train_Acc: 91.516 Val_Loss: 0.2442  BEST VAL Loss: 0.2442  Val_Acc: 92.945

Epoch 30: Validation loss decreased (0.244226 --> 0.242223).  Saving model ...
	 Train_Loss: 0.3347 Train_Acc: 91.935 Val_Loss: 0.2422  BEST VAL Loss: 0.2422  Val_Acc: 92.945

Epoch 31: Validation loss decreased (0.242223 --> 0.240154).  Saving model ...
	 Train_Loss: 0.3304 Train_Acc: 91.798 Val_Loss: 0.2402  BEST VAL Loss: 0.2402  Val_Acc: 93.210

Epoch 32: Validation loss decreased (0.240154 --> 0.237527).  Saving model ...
	 Train_Loss: 0.3263 Train_Acc: 91.798 Val_Loss: 0.2375  BEST VAL Loss: 0.2375  Val_Acc: 94.797

Epoch 33: Validation loss decreased (0.237527 --> 0.236263).  Saving model ...
	 Train_Loss: 0.3224 Train_Acc: 91.968 Val_Loss: 0.2363  BEST VAL Loss: 0.2363  Val_Acc: 93.078

Epoch 34: Validation loss decreased (0.236263 --> 0.233757).  Saving model ...
	 Train_Loss: 0.3187 Train_Acc: 92.035 Val_Loss: 0.2338  BEST VAL Loss: 0.2338  Val_Acc: 94.180

Epoch 35: Validation loss decreased (0.233757 --> 0.232212).  Saving model ...
	 Train_Loss: 0.3151 Train_Acc: 92.062 Val_Loss: 0.2322  BEST VAL Loss: 0.2322  Val_Acc: 94.312

Epoch 36: Validation loss decreased (0.232212 --> 0.230198).  Saving model ...
	 Train_Loss: 0.3117 Train_Acc: 92.117 Val_Loss: 0.2302  BEST VAL Loss: 0.2302  Val_Acc: 94.312

Epoch 37: Validation loss decreased (0.230198 --> 0.228270).  Saving model ...
	 Train_Loss: 0.3082 Train_Acc: 92.415 Val_Loss: 0.2283  BEST VAL Loss: 0.2283  Val_Acc: 94.400

Epoch 38: Validation loss decreased (0.228270 --> 0.226142).  Saving model ...
	 Train_Loss: 0.3050 Train_Acc: 92.492 Val_Loss: 0.2261  BEST VAL Loss: 0.2261  Val_Acc: 94.797

Epoch 39: Validation loss decreased (0.226142 --> 0.224169).  Saving model ...
	 Train_Loss: 0.3019 Train_Acc: 92.277 Val_Loss: 0.2242  BEST VAL Loss: 0.2242  Val_Acc: 94.797

Epoch 40: Validation loss decreased (0.224169 --> 0.222053).  Saving model ...
	 Train_Loss: 0.2990 Train_Acc: 92.602 Val_Loss: 0.2221  BEST VAL Loss: 0.2221  Val_Acc: 94.753

Epoch 41: Validation loss decreased (0.222053 --> 0.221015).  Saving model ...
	 Train_Loss: 0.2962 Train_Acc: 92.773 Val_Loss: 0.2210  BEST VAL Loss: 0.2210  Val_Acc: 94.929

Epoch 42: Validation loss decreased (0.221015 --> 0.219490).  Saving model ...
	 Train_Loss: 0.2935 Train_Acc: 92.597 Val_Loss: 0.2195  BEST VAL Loss: 0.2195  Val_Acc: 94.268

Epoch 43: Validation loss decreased (0.219490 --> 0.218220).  Saving model ...
	 Train_Loss: 0.2908 Train_Acc: 92.906 Val_Loss: 0.2182  BEST VAL Loss: 0.2182  Val_Acc: 94.929

Epoch 44: Validation loss decreased (0.218220 --> 0.217537).  Saving model ...
	 Train_Loss: 0.2882 Train_Acc: 92.889 Val_Loss: 0.2175  BEST VAL Loss: 0.2175  Val_Acc: 94.753

Epoch 45: Validation loss decreased (0.217537 --> 0.216215).  Saving model ...
	 Train_Loss: 0.2859 Train_Acc: 92.669 Val_Loss: 0.2162  BEST VAL Loss: 0.2162  Val_Acc: 94.753

Epoch 46: Validation loss decreased (0.216215 --> 0.215551).  Saving model ...
	 Train_Loss: 0.2834 Train_Acc: 93.187 Val_Loss: 0.2156  BEST VAL Loss: 0.2156  Val_Acc: 94.577

Epoch 47: Validation loss decreased (0.215551 --> 0.214399).  Saving model ...
	 Train_Loss: 0.2811 Train_Acc: 92.757 Val_Loss: 0.2144  BEST VAL Loss: 0.2144  Val_Acc: 95.282

Epoch 48: Validation loss decreased (0.214399 --> 0.213453).  Saving model ...
	 Train_Loss: 0.2789 Train_Acc: 93.027 Val_Loss: 0.2135  BEST VAL Loss: 0.2135  Val_Acc: 94.929

Epoch 49: Validation loss decreased (0.213453 --> 0.212610).  Saving model ...
	 Train_Loss: 0.2768 Train_Acc: 92.845 Val_Loss: 0.2126  BEST VAL Loss: 0.2126  Val_Acc: 94.885

Epoch 50: Validation loss decreased (0.212610 --> 0.212304).  Saving model ...
	 Train_Loss: 0.2748 Train_Acc: 92.828 Val_Loss: 0.2123  BEST VAL Loss: 0.2123  Val_Acc: 94.180

Epoch 51: Validation loss decreased (0.212304 --> 0.211527).  Saving model ...
	 Train_Loss: 0.2730 Train_Acc: 92.983 Val_Loss: 0.2115  BEST VAL Loss: 0.2115  Val_Acc: 94.224

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.2710 Train_Acc: 93.176 Val_Loss: 0.2119  BEST VAL Loss: 0.2115  Val_Acc: 94.092

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.2693 Train_Acc: 92.867 Val_Loss: 0.2116  BEST VAL Loss: 0.2115  Val_Acc: 94.048

Epoch 54: Validation loss decreased (0.211527 --> 0.210903).  Saving model ...
	 Train_Loss: 0.2674 Train_Acc: 93.308 Val_Loss: 0.2109  BEST VAL Loss: 0.2109  Val_Acc: 94.621

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.2657 Train_Acc: 92.988 Val_Loss: 0.2111  BEST VAL Loss: 0.2109  Val_Acc: 94.841

Epoch 56: Validation loss decreased (0.210903 --> 0.210326).  Saving model ...
	 Train_Loss: 0.2640 Train_Acc: 93.363 Val_Loss: 0.2103  BEST VAL Loss: 0.2103  Val_Acc: 94.621

Epoch 57: Validation loss decreased (0.210326 --> 0.210262).  Saving model ...
	 Train_Loss: 0.2624 Train_Acc: 93.220 Val_Loss: 0.2103  BEST VAL Loss: 0.2103  Val_Acc: 94.356

Epoch 58: Validation loss decreased (0.210262 --> 0.209422).  Saving model ...
	 Train_Loss: 0.2609 Train_Acc: 92.817 Val_Loss: 0.2094  BEST VAL Loss: 0.2094  Val_Acc: 94.797

Epoch 59: Validation loss decreased (0.209422 --> 0.209313).  Saving model ...
	 Train_Loss: 0.2594 Train_Acc: 93.231 Val_Loss: 0.2093  BEST VAL Loss: 0.2093  Val_Acc: 94.797

Epoch 60: Validation loss decreased (0.209313 --> 0.208819).  Saving model ...
	 Train_Loss: 0.2578 Train_Acc: 93.308 Val_Loss: 0.2088  BEST VAL Loss: 0.2088  Val_Acc: 95.150

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.2564 Train_Acc: 93.473 Val_Loss: 0.2115  BEST VAL Loss: 0.2088  Val_Acc: 93.959

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.2552 Train_Acc: 93.016 Val_Loss: 0.2107  BEST VAL Loss: 0.2088  Val_Acc: 94.753

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.2537 Train_Acc: 93.440 Val_Loss: 0.2100  BEST VAL Loss: 0.2088  Val_Acc: 94.974

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.2522 Train_Acc: 93.914 Val_Loss: 0.2095  BEST VAL Loss: 0.2088  Val_Acc: 94.665

Epoch 65: Validation loss decreased (0.208819 --> 0.208750).  Saving model ...
	 Train_Loss: 0.2509 Train_Acc: 93.352 Val_Loss: 0.2087  BEST VAL Loss: 0.2087  Val_Acc: 94.841

Epoch 66: Validation loss decreased (0.208750 --> 0.208449).  Saving model ...
	 Train_Loss: 0.2495 Train_Acc: 93.738 Val_Loss: 0.2084  BEST VAL Loss: 0.2084  Val_Acc: 94.665

Epoch 67: Validation loss decreased (0.208449 --> 0.208042).  Saving model ...
	 Train_Loss: 0.2481 Train_Acc: 93.424 Val_Loss: 0.2080  BEST VAL Loss: 0.2080  Val_Acc: 95.106

Epoch 68: Validation loss decreased (0.208042 --> 0.207400).  Saving model ...
	 Train_Loss: 0.2470 Train_Acc: 93.253 Val_Loss: 0.2074  BEST VAL Loss: 0.2074  Val_Acc: 95.062

Epoch 69: Validation loss decreased (0.207400 --> 0.206991).  Saving model ...
	 Train_Loss: 0.2457 Train_Acc: 93.859 Val_Loss: 0.2070  BEST VAL Loss: 0.2070  Val_Acc: 94.797

Epoch 70: Validation loss decreased (0.206991 --> 0.206444).  Saving model ...
	 Train_Loss: 0.2445 Train_Acc: 93.363 Val_Loss: 0.2064  BEST VAL Loss: 0.2064  Val_Acc: 95.635

Epoch 71: Validation loss decreased (0.206444 --> 0.206183).  Saving model ...
	 Train_Loss: 0.2434 Train_Acc: 93.336 Val_Loss: 0.2062  BEST VAL Loss: 0.2062  Val_Acc: 95.018

Epoch 72: Validation loss decreased (0.206183 --> 0.205698).  Saving model ...
	 Train_Loss: 0.2423 Train_Acc: 93.512 Val_Loss: 0.2057  BEST VAL Loss: 0.2057  Val_Acc: 95.326

Epoch 73: Validation loss decreased (0.205698 --> 0.205369).  Saving model ...
	 Train_Loss: 0.2412 Train_Acc: 93.313 Val_Loss: 0.2054  BEST VAL Loss: 0.2054  Val_Acc: 94.312

Epoch 74: Validation loss decreased (0.205369 --> 0.204953).  Saving model ...
	 Train_Loss: 0.2402 Train_Acc: 93.325 Val_Loss: 0.2050  BEST VAL Loss: 0.2050  Val_Acc: 95.062

Epoch 75: Validation loss decreased (0.204953 --> 0.204465).  Saving model ...
	 Train_Loss: 0.2392 Train_Acc: 93.313 Val_Loss: 0.2045  BEST VAL Loss: 0.2045  Val_Acc: 94.841

Epoch 76: Validation loss decreased (0.204465 --> 0.204188).  Saving model ...
	 Train_Loss: 0.2382 Train_Acc: 93.661 Val_Loss: 0.2042  BEST VAL Loss: 0.2042  Val_Acc: 94.974

Epoch 77: Validation loss decreased (0.204188 --> 0.203786).  Saving model ...
	 Train_Loss: 0.2372 Train_Acc: 93.506 Val_Loss: 0.2038  BEST VAL Loss: 0.2038  Val_Acc: 94.665

Epoch 78: Validation loss decreased (0.203786 --> 0.203580).  Saving model ...
	 Train_Loss: 0.2362 Train_Acc: 93.484 Val_Loss: 0.2036  BEST VAL Loss: 0.2036  Val_Acc: 94.533

Epoch 79: Validation loss decreased (0.203580 --> 0.203233).  Saving model ...
	 Train_Loss: 0.2353 Train_Acc: 93.446 Val_Loss: 0.2032  BEST VAL Loss: 0.2032  Val_Acc: 94.577

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.2346 Train_Acc: 93.275 Val_Loss: 0.2033  BEST VAL Loss: 0.2032  Val_Acc: 94.400

Epoch 81: Validation loss decreased (0.203233 --> 0.203165).  Saving model ...
	 Train_Loss: 0.2337 Train_Acc: 93.396 Val_Loss: 0.2032  BEST VAL Loss: 0.2032  Val_Acc: 94.533

Epoch 82: Validation loss decreased (0.203165 --> 0.202798).  Saving model ...
	 Train_Loss: 0.2328 Train_Acc: 93.451 Val_Loss: 0.2028  BEST VAL Loss: 0.2028  Val_Acc: 95.062

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.2319 Train_Acc: 93.710 Val_Loss: 0.2030  BEST VAL Loss: 0.2028  Val_Acc: 94.577

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.2311 Train_Acc: 93.562 Val_Loss: 0.2053  BEST VAL Loss: 0.2028  Val_Acc: 94.268

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.2303 Train_Acc: 93.622 Val_Loss: 0.2051  BEST VAL Loss: 0.2028  Val_Acc: 94.753

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.2295 Train_Acc: 93.815 Val_Loss: 0.2050  BEST VAL Loss: 0.2028  Val_Acc: 95.194

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.2287 Train_Acc: 93.584 Val_Loss: 0.2052  BEST VAL Loss: 0.2028  Val_Acc: 94.753

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.2279 Train_Acc: 93.495 Val_Loss: 0.2047  BEST VAL Loss: 0.2028  Val_Acc: 94.929

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.2270 Train_Acc: 94.058 Val_Loss: 0.2046  BEST VAL Loss: 0.2028  Val_Acc: 94.841

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.2263 Train_Acc: 93.727 Val_Loss: 0.2053  BEST VAL Loss: 0.2028  Val_Acc: 93.739

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.2257 Train_Acc: 93.021 Val_Loss: 0.2055  BEST VAL Loss: 0.2028  Val_Acc: 94.400

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.2249 Train_Acc: 93.942 Val_Loss: 0.2062  BEST VAL Loss: 0.2028  Val_Acc: 94.665

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.2241 Train_Acc: 93.958 Val_Loss: 0.2064  BEST VAL Loss: 0.2028  Val_Acc: 95.238

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.2234 Train_Acc: 93.804 Val_Loss: 0.2064  BEST VAL Loss: 0.2028  Val_Acc: 94.621

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.2227 Train_Acc: 94.047 Val_Loss: 0.2064  BEST VAL Loss: 0.2028  Val_Acc: 94.444

Epoch 96: Validation loss did not decrease
	 Train_Loss: 0.2219 Train_Acc: 94.157 Val_Loss: 0.2067  BEST VAL Loss: 0.2028  Val_Acc: 94.709

Epoch 97: Validation loss did not decrease
	 Train_Loss: 0.2212 Train_Acc: 93.876 Val_Loss: 0.2075  BEST VAL Loss: 0.2028  Val_Acc: 94.400

Epoch 98: Validation loss did not decrease
Early stopped at epoch : 98
LPS_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       1.00      0.99      0.99      8635
           1       0.99      1.00      0.99      9506

    accuracy                           0.99     18141
   macro avg       0.99      0.99      0.99     18141
weighted avg       0.99      0.99      0.99     18141

LPS_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.95      0.94      0.95      1079
           1       0.95      0.96      0.95      1189

    accuracy                           0.95      2268
   macro avg       0.95      0.95      0.95      2268
weighted avg       0.95      0.95      0.95      2268

LPS_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.95      0.94      0.94      1079
           1       0.94      0.95      0.95      1189

    accuracy                           0.95      2268
   macro avg       0.95      0.95      0.95      2268
weighted avg       0.95      0.95      0.95      2268

              precision    recall  f1-score   support

           0       0.95      0.94      0.94      1079
           1       0.94      0.95      0.95      1189

    accuracy                           0.95      2268
   macro avg       0.95      0.95      0.95      2268
weighted avg       0.95      0.95      0.95      2268

LPS_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.95      0.88      0.91      4135
           1       0.89      0.95      0.92      4103

    accuracy                           0.91      8238
   macro avg       0.92      0.91      0.91      8238
weighted avg       0.92      0.91      0.91      8238

              precision    recall  f1-score   support

           0       0.95      0.88      0.91      4135
           1       0.89      0.95      0.92      4103

    accuracy                           0.91      8238
   macro avg       0.92      0.91      0.91      8238
weighted avg       0.92      0.91      0.91      8238

completed
