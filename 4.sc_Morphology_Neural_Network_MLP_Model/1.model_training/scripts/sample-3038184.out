[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '57d4453d'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '170a56ec'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ceebb10e'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'd2f686ce'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_10.000_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (32797, 1276)
Number of total missing values across all columns: 65594
Data Subset Is Off
Wells held out for testing: ['E20' 'J16']
Wells to use for training, validation, and testing ['E16' 'E17' 'E21' 'J17' 'J20' 'J21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.475566).  Saving model ...
	 Train_Loss: 0.6143 Train_Acc: 64.434 Val_Loss: 0.4756  BEST VAL Loss: 0.4756  Val_Acc: 74.603

Epoch 1: Validation loss decreased (0.475566 --> 0.416700).  Saving model ...
	 Train_Loss: 0.5378 Train_Acc: 73.603 Val_Loss: 0.4167  BEST VAL Loss: 0.4167  Val_Acc: 85.569

Epoch 2: Validation loss decreased (0.416700 --> 0.365772).  Saving model ...
	 Train_Loss: 0.4859 Train_Acc: 78.894 Val_Loss: 0.3658  BEST VAL Loss: 0.3658  Val_Acc: 90.012

Epoch 3: Validation loss decreased (0.365772 --> 0.334967).  Saving model ...
	 Train_Loss: 0.4490 Train_Acc: 81.019 Val_Loss: 0.3350  BEST VAL Loss: 0.3350  Val_Acc: 90.787

Epoch 4: Validation loss decreased (0.334967 --> 0.312081).  Saving model ...
	 Train_Loss: 0.4212 Train_Acc: 82.136 Val_Loss: 0.3121  BEST VAL Loss: 0.3121  Val_Acc: 91.724

Epoch 5: Validation loss decreased (0.312081 --> 0.296001).  Saving model ...
	 Train_Loss: 0.4010 Train_Acc: 82.125 Val_Loss: 0.2960  BEST VAL Loss: 0.2960  Val_Acc: 91.724

Epoch 6: Validation loss decreased (0.296001 --> 0.282070).  Saving model ...
	 Train_Loss: 0.3846 Train_Acc: 82.768 Val_Loss: 0.2821  BEST VAL Loss: 0.2821  Val_Acc: 92.132

Epoch 7: Validation loss decreased (0.282070 --> 0.270367).  Saving model ...
	 Train_Loss: 0.3709 Train_Acc: 83.063 Val_Loss: 0.2704  BEST VAL Loss: 0.2704  Val_Acc: 93.559

Epoch 8: Validation loss decreased (0.270367 --> 0.261320).  Saving model ...
	 Train_Loss: 0.3590 Train_Acc: 83.333 Val_Loss: 0.2613  BEST VAL Loss: 0.2613  Val_Acc: 93.314

Epoch 9: Validation loss decreased (0.261320 --> 0.253249).  Saving model ...
	 Train_Loss: 0.3493 Train_Acc: 84.980 Val_Loss: 0.2532  BEST VAL Loss: 0.2532  Val_Acc: 89.442

Epoch 10: Validation loss decreased (0.253249 --> 0.246092).  Saving model ...
	 Train_Loss: 0.3410 Train_Acc: 86.198 Val_Loss: 0.2461  BEST VAL Loss: 0.2461  Val_Acc: 89.482

Epoch 11: Validation loss decreased (0.246092 --> 0.242572).  Saving model ...
	 Train_Loss: 0.3343 Train_Acc: 86.040 Val_Loss: 0.2426  BEST VAL Loss: 0.2426  Val_Acc: 88.952

Epoch 12: Validation loss decreased (0.242572 --> 0.241924).  Saving model ...
	 Train_Loss: 0.3282 Train_Acc: 86.305 Val_Loss: 0.2419  BEST VAL Loss: 0.2419  Val_Acc: 88.545

Epoch 13: Validation loss decreased (0.241924 --> 0.238720).  Saving model ...
	 Train_Loss: 0.3227 Train_Acc: 86.631 Val_Loss: 0.2387  BEST VAL Loss: 0.2387  Val_Acc: 89.564

Epoch 14: Validation loss decreased (0.238720 --> 0.234681).  Saving model ...
	 Train_Loss: 0.3174 Train_Acc: 87.090 Val_Loss: 0.2347  BEST VAL Loss: 0.2347  Val_Acc: 89.482

Epoch 15: Validation loss decreased (0.234681 --> 0.230989).  Saving model ...
	 Train_Loss: 0.3120 Train_Acc: 87.406 Val_Loss: 0.2310  BEST VAL Loss: 0.2310  Val_Acc: 90.664

Epoch 16: Validation loss decreased (0.230989 --> 0.227974).  Saving model ...
	 Train_Loss: 0.3069 Train_Acc: 88.078 Val_Loss: 0.2280  BEST VAL Loss: 0.2280  Val_Acc: 90.379

Epoch 17: Validation loss decreased (0.227974 --> 0.225401).  Saving model ...
	 Train_Loss: 0.3024 Train_Acc: 87.824 Val_Loss: 0.2254  BEST VAL Loss: 0.2254  Val_Acc: 90.338

Epoch 18: Validation loss decreased (0.225401 --> 0.222562).  Saving model ...
	 Train_Loss: 0.2984 Train_Acc: 87.813 Val_Loss: 0.2226  BEST VAL Loss: 0.2226  Val_Acc: 90.379

Epoch 19: Validation loss decreased (0.222562 --> 0.220802).  Saving model ...
	 Train_Loss: 0.2944 Train_Acc: 88.231 Val_Loss: 0.2208  BEST VAL Loss: 0.2208  Val_Acc: 90.705

Epoch 20: Validation loss decreased (0.220802 --> 0.218659).  Saving model ...
	 Train_Loss: 0.2910 Train_Acc: 88.359 Val_Loss: 0.2187  BEST VAL Loss: 0.2187  Val_Acc: 91.276

Epoch 21: Validation loss decreased (0.218659 --> 0.216951).  Saving model ...
	 Train_Loss: 0.2876 Train_Acc: 88.634 Val_Loss: 0.2170  BEST VAL Loss: 0.2170  Val_Acc: 91.031

Epoch 22: Validation loss decreased (0.216951 --> 0.215147).  Saving model ...
	 Train_Loss: 0.2847 Train_Acc: 88.491 Val_Loss: 0.2151  BEST VAL Loss: 0.2151  Val_Acc: 90.705

Epoch 23: Validation loss decreased (0.215147 --> 0.213744).  Saving model ...
	 Train_Loss: 0.2817 Train_Acc: 88.833 Val_Loss: 0.2137  BEST VAL Loss: 0.2137  Val_Acc: 91.317

Epoch 24: Validation loss decreased (0.213744 --> 0.211660).  Saving model ...
	 Train_Loss: 0.2787 Train_Acc: 89.032 Val_Loss: 0.2117  BEST VAL Loss: 0.2117  Val_Acc: 91.521

Epoch 25: Validation loss decreased (0.211660 --> 0.210443).  Saving model ...
	 Train_Loss: 0.2760 Train_Acc: 88.940 Val_Loss: 0.2104  BEST VAL Loss: 0.2104  Val_Acc: 91.398

Epoch 26: Validation loss decreased (0.210443 --> 0.208834).  Saving model ...
	 Train_Loss: 0.2736 Train_Acc: 89.042 Val_Loss: 0.2088  BEST VAL Loss: 0.2088  Val_Acc: 91.358

Epoch 27: Validation loss decreased (0.208834 --> 0.207021).  Saving model ...
	 Train_Loss: 0.2711 Train_Acc: 89.302 Val_Loss: 0.2070  BEST VAL Loss: 0.2070  Val_Acc: 91.847

Epoch 28: Validation loss decreased (0.207021 --> 0.205198).  Saving model ...
	 Train_Loss: 0.2689 Train_Acc: 89.042 Val_Loss: 0.2052  BEST VAL Loss: 0.2052  Val_Acc: 91.398

Epoch 29: Validation loss decreased (0.205198 --> 0.203639).  Saving model ...
	 Train_Loss: 0.2667 Train_Acc: 89.643 Val_Loss: 0.2036  BEST VAL Loss: 0.2036  Val_Acc: 91.358

Epoch 30: Validation loss decreased (0.203639 --> 0.202140).  Saving model ...
	 Train_Loss: 0.2646 Train_Acc: 89.450 Val_Loss: 0.2021  BEST VAL Loss: 0.2021  Val_Acc: 91.928

Epoch 31: Validation loss decreased (0.202140 --> 0.201295).  Saving model ...
	 Train_Loss: 0.2626 Train_Acc: 89.674 Val_Loss: 0.2013  BEST VAL Loss: 0.2013  Val_Acc: 91.561

Epoch 32: Validation loss decreased (0.201295 --> 0.200406).  Saving model ...
	 Train_Loss: 0.2607 Train_Acc: 89.546 Val_Loss: 0.2004  BEST VAL Loss: 0.2004  Val_Acc: 91.602

Epoch 33: Validation loss decreased (0.200406 --> 0.199459).  Saving model ...
	 Train_Loss: 0.2587 Train_Acc: 90.265 Val_Loss: 0.1995  BEST VAL Loss: 0.1995  Val_Acc: 91.643

Epoch 34: Validation loss decreased (0.199459 --> 0.198325).  Saving model ...
	 Train_Loss: 0.2568 Train_Acc: 90.270 Val_Loss: 0.1983  BEST VAL Loss: 0.1983  Val_Acc: 92.214

Epoch 35: Validation loss decreased (0.198325 --> 0.197407).  Saving model ...
	 Train_Loss: 0.2551 Train_Acc: 89.791 Val_Loss: 0.1974  BEST VAL Loss: 0.1974  Val_Acc: 91.928

Epoch 36: Validation loss decreased (0.197407 --> 0.196195).  Saving model ...
	 Train_Loss: 0.2533 Train_Acc: 90.372 Val_Loss: 0.1962  BEST VAL Loss: 0.1962  Val_Acc: 92.091

Epoch 37: Validation loss decreased (0.196195 --> 0.195597).  Saving model ...
	 Train_Loss: 0.2518 Train_Acc: 90.000 Val_Loss: 0.1956  BEST VAL Loss: 0.1956  Val_Acc: 92.744

Epoch 38: Validation loss decreased (0.195597 --> 0.194648).  Saving model ...
	 Train_Loss: 0.2502 Train_Acc: 90.260 Val_Loss: 0.1946  BEST VAL Loss: 0.1946  Val_Acc: 92.377

Epoch 39: Validation loss decreased (0.194648 --> 0.193567).  Saving model ...
	 Train_Loss: 0.2488 Train_Acc: 90.061 Val_Loss: 0.1936  BEST VAL Loss: 0.1936  Val_Acc: 91.806

Epoch 40: Validation loss decreased (0.193567 --> 0.193020).  Saving model ...
	 Train_Loss: 0.2473 Train_Acc: 90.265 Val_Loss: 0.1930  BEST VAL Loss: 0.1930  Val_Acc: 92.173

Epoch 41: Validation loss decreased (0.193020 --> 0.191948).  Saving model ...
	 Train_Loss: 0.2459 Train_Acc: 90.520 Val_Loss: 0.1919  BEST VAL Loss: 0.1919  Val_Acc: 93.029

Epoch 42: Validation loss decreased (0.191948 --> 0.191380).  Saving model ...
	 Train_Loss: 0.2444 Train_Acc: 90.637 Val_Loss: 0.1914  BEST VAL Loss: 0.1914  Val_Acc: 92.336

Epoch 43: Validation loss decreased (0.191380 --> 0.191233).  Saving model ...
	 Train_Loss: 0.2430 Train_Acc: 90.698 Val_Loss: 0.1912  BEST VAL Loss: 0.1912  Val_Acc: 92.254

Epoch 44: Validation loss decreased (0.191233 --> 0.190923).  Saving model ...
	 Train_Loss: 0.2418 Train_Acc: 90.423 Val_Loss: 0.1909  BEST VAL Loss: 0.1909  Val_Acc: 92.051

Epoch 45: Validation loss decreased (0.190923 --> 0.190271).  Saving model ...
	 Train_Loss: 0.2406 Train_Acc: 90.785 Val_Loss: 0.1903  BEST VAL Loss: 0.1903  Val_Acc: 92.703

Epoch 46: Validation loss decreased (0.190271 --> 0.190005).  Saving model ...
	 Train_Loss: 0.2393 Train_Acc: 90.912 Val_Loss: 0.1900  BEST VAL Loss: 0.1900  Val_Acc: 92.662

Epoch 47: Validation loss decreased (0.190005 --> 0.189419).  Saving model ...
	 Train_Loss: 0.2381 Train_Acc: 90.846 Val_Loss: 0.1894  BEST VAL Loss: 0.1894  Val_Acc: 92.621

Epoch 48: Validation loss decreased (0.189419 --> 0.189036).  Saving model ...
	 Train_Loss: 0.2369 Train_Acc: 91.086 Val_Loss: 0.1890  BEST VAL Loss: 0.1890  Val_Acc: 92.377

Epoch 49: Validation loss decreased (0.189036 --> 0.188599).  Saving model ...
	 Train_Loss: 0.2357 Train_Acc: 91.030 Val_Loss: 0.1886  BEST VAL Loss: 0.1886  Val_Acc: 92.581

Epoch 50: Validation loss decreased (0.188599 --> 0.188326).  Saving model ...
	 Train_Loss: 0.2346 Train_Acc: 91.310 Val_Loss: 0.1883  BEST VAL Loss: 0.1883  Val_Acc: 92.907

Epoch 51: Validation loss decreased (0.188326 --> 0.187937).  Saving model ...
	 Train_Loss: 0.2335 Train_Acc: 91.172 Val_Loss: 0.1879  BEST VAL Loss: 0.1879  Val_Acc: 92.866

Epoch 52: Validation loss decreased (0.187937 --> 0.187356).  Saving model ...
	 Train_Loss: 0.2324 Train_Acc: 91.091 Val_Loss: 0.1874  BEST VAL Loss: 0.1874  Val_Acc: 92.336

Epoch 53: Validation loss decreased (0.187356 --> 0.187008).  Saving model ...
	 Train_Loss: 0.2314 Train_Acc: 90.963 Val_Loss: 0.1870  BEST VAL Loss: 0.1870  Val_Acc: 92.784

Epoch 54: Validation loss decreased (0.187008 --> 0.186945).  Saving model ...
	 Train_Loss: 0.2304 Train_Acc: 91.595 Val_Loss: 0.1869  BEST VAL Loss: 0.1869  Val_Acc: 92.254

Epoch 55: Validation loss decreased (0.186945 --> 0.186607).  Saving model ...
	 Train_Loss: 0.2293 Train_Acc: 91.412 Val_Loss: 0.1866  BEST VAL Loss: 0.1866  Val_Acc: 92.377

Epoch 56: Validation loss decreased (0.186607 --> 0.186176).  Saving model ...
	 Train_Loss: 0.2283 Train_Acc: 91.463 Val_Loss: 0.1862  BEST VAL Loss: 0.1862  Val_Acc: 92.784

Epoch 57: Validation loss decreased (0.186176 --> 0.185814).  Saving model ...
	 Train_Loss: 0.2274 Train_Acc: 91.534 Val_Loss: 0.1858  BEST VAL Loss: 0.1858  Val_Acc: 92.825

Epoch 58: Validation loss decreased (0.185814 --> 0.185654).  Saving model ...
	 Train_Loss: 0.2264 Train_Acc: 91.498 Val_Loss: 0.1857  BEST VAL Loss: 0.1857  Val_Acc: 92.825

Epoch 59: Validation loss decreased (0.185654 --> 0.185095).  Saving model ...
	 Train_Loss: 0.2257 Train_Acc: 91.096 Val_Loss: 0.1851  BEST VAL Loss: 0.1851  Val_Acc: 92.907

Epoch 60: Validation loss decreased (0.185095 --> 0.184836).  Saving model ...
	 Train_Loss: 0.2248 Train_Acc: 91.524 Val_Loss: 0.1848  BEST VAL Loss: 0.1848  Val_Acc: 93.355

Epoch 61: Validation loss decreased (0.184836 --> 0.184732).  Saving model ...
	 Train_Loss: 0.2240 Train_Acc: 91.162 Val_Loss: 0.1847  BEST VAL Loss: 0.1847  Val_Acc: 93.192

Epoch 62: Validation loss decreased (0.184732 --> 0.184437).  Saving model ...
	 Train_Loss: 0.2231 Train_Acc: 91.707 Val_Loss: 0.1844  BEST VAL Loss: 0.1844  Val_Acc: 93.804

Epoch 63: Validation loss decreased (0.184437 --> 0.184232).  Saving model ...
	 Train_Loss: 0.2223 Train_Acc: 91.606 Val_Loss: 0.1842  BEST VAL Loss: 0.1842  Val_Acc: 93.274

Epoch 64: Validation loss decreased (0.184232 --> 0.183884).  Saving model ...
	 Train_Loss: 0.2214 Train_Acc: 92.192 Val_Loss: 0.1839  BEST VAL Loss: 0.1839  Val_Acc: 93.437

Epoch 65: Validation loss decreased (0.183884 --> 0.183533).  Saving model ...
	 Train_Loss: 0.2207 Train_Acc: 91.244 Val_Loss: 0.1835  BEST VAL Loss: 0.1835  Val_Acc: 93.355

Epoch 66: Validation loss decreased (0.183533 --> 0.183176).  Saving model ...
	 Train_Loss: 0.2199 Train_Acc: 91.636 Val_Loss: 0.1832  BEST VAL Loss: 0.1832  Val_Acc: 93.396

Epoch 67: Validation loss decreased (0.183176 --> 0.182810).  Saving model ...
	 Train_Loss: 0.2192 Train_Acc: 91.549 Val_Loss: 0.1828  BEST VAL Loss: 0.1828  Val_Acc: 93.681

Epoch 68: Validation loss decreased (0.182810 --> 0.182477).  Saving model ...
	 Train_Loss: 0.2185 Train_Acc: 91.758 Val_Loss: 0.1825  BEST VAL Loss: 0.1825  Val_Acc: 92.988

Epoch 69: Validation loss decreased (0.182477 --> 0.182288).  Saving model ...
	 Train_Loss: 0.2177 Train_Acc: 92.029 Val_Loss: 0.1823  BEST VAL Loss: 0.1823  Val_Acc: 93.518

Epoch 70: Validation loss decreased (0.182288 --> 0.181937).  Saving model ...
	 Train_Loss: 0.2169 Train_Acc: 91.881 Val_Loss: 0.1819  BEST VAL Loss: 0.1819  Val_Acc: 92.703

Epoch 71: Validation loss decreased (0.181937 --> 0.181864).  Saving model ...
	 Train_Loss: 0.2162 Train_Acc: 91.922 Val_Loss: 0.1819  BEST VAL Loss: 0.1819  Val_Acc: 93.559

Epoch 72: Validation loss decreased (0.181864 --> 0.181724).  Saving model ...
	 Train_Loss: 0.2155 Train_Acc: 91.937 Val_Loss: 0.1817  BEST VAL Loss: 0.1817  Val_Acc: 93.314

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.2148 Train_Acc: 91.998 Val_Loss: 0.1817  BEST VAL Loss: 0.1817  Val_Acc: 92.947

Epoch 74: Validation loss decreased (0.181724 --> 0.181349).  Saving model ...
	 Train_Loss: 0.2141 Train_Acc: 91.825 Val_Loss: 0.1813  BEST VAL Loss: 0.1813  Val_Acc: 93.314

Epoch 75: Validation loss decreased (0.181349 --> 0.181210).  Saving model ...
	 Train_Loss: 0.2135 Train_Acc: 91.962 Val_Loss: 0.1812  BEST VAL Loss: 0.1812  Val_Acc: 93.477

Epoch 76: Validation loss decreased (0.181210 --> 0.180888).  Saving model ...
	 Train_Loss: 0.2129 Train_Acc: 91.820 Val_Loss: 0.1809  BEST VAL Loss: 0.1809  Val_Acc: 93.600

Epoch 77: Validation loss decreased (0.180888 --> 0.180612).  Saving model ...
	 Train_Loss: 0.2123 Train_Acc: 91.937 Val_Loss: 0.1806  BEST VAL Loss: 0.1806  Val_Acc: 92.947

Epoch 78: Validation loss decreased (0.180612 --> 0.180389).  Saving model ...
	 Train_Loss: 0.2117 Train_Acc: 92.243 Val_Loss: 0.1804  BEST VAL Loss: 0.1804  Val_Acc: 93.355

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.2110 Train_Acc: 92.482 Val_Loss: 0.1805  BEST VAL Loss: 0.1804  Val_Acc: 93.029

Epoch 80: Validation loss decreased (0.180389 --> 0.180188).  Saving model ...
	 Train_Loss: 0.2104 Train_Acc: 91.957 Val_Loss: 0.1802  BEST VAL Loss: 0.1802  Val_Acc: 93.681

Epoch 81: Validation loss decreased (0.180188 --> 0.179980).  Saving model ...
	 Train_Loss: 0.2099 Train_Acc: 92.064 Val_Loss: 0.1800  BEST VAL Loss: 0.1800  Val_Acc: 93.274

Epoch 82: Validation loss decreased (0.179980 --> 0.179669).  Saving model ...
	 Train_Loss: 0.2093 Train_Acc: 92.171 Val_Loss: 0.1797  BEST VAL Loss: 0.1797  Val_Acc: 93.681

Epoch 83: Validation loss decreased (0.179669 --> 0.179443).  Saving model ...
	 Train_Loss: 0.2087 Train_Acc: 92.314 Val_Loss: 0.1794  BEST VAL Loss: 0.1794  Val_Acc: 93.518

Epoch 84: Validation loss decreased (0.179443 --> 0.179197).  Saving model ...
	 Train_Loss: 0.2081 Train_Acc: 92.350 Val_Loss: 0.1792  BEST VAL Loss: 0.1792  Val_Acc: 93.844

Epoch 85: Validation loss decreased (0.179197 --> 0.178924).  Saving model ...
	 Train_Loss: 0.2076 Train_Acc: 92.202 Val_Loss: 0.1789  BEST VAL Loss: 0.1789  Val_Acc: 93.844

Epoch 86: Validation loss decreased (0.178924 --> 0.178753).  Saving model ...
	 Train_Loss: 0.2071 Train_Acc: 92.110 Val_Loss: 0.1788  BEST VAL Loss: 0.1788  Val_Acc: 93.233

Epoch 87: Validation loss decreased (0.178753 --> 0.178566).  Saving model ...
	 Train_Loss: 0.2066 Train_Acc: 92.202 Val_Loss: 0.1786  BEST VAL Loss: 0.1786  Val_Acc: 93.681

Epoch 88: Validation loss decreased (0.178566 --> 0.178560).  Saving model ...
	 Train_Loss: 0.2060 Train_Acc: 92.671 Val_Loss: 0.1786  BEST VAL Loss: 0.1786  Val_Acc: 93.926

Epoch 89: Validation loss decreased (0.178560 --> 0.178366).  Saving model ...
	 Train_Loss: 0.2054 Train_Acc: 92.355 Val_Loss: 0.1784  BEST VAL Loss: 0.1784  Val_Acc: 94.211

Epoch 90: Validation loss decreased (0.178366 --> 0.178117).  Saving model ...
	 Train_Loss: 0.2049 Train_Acc: 92.350 Val_Loss: 0.1781  BEST VAL Loss: 0.1781  Val_Acc: 94.048

Epoch 91: Validation loss decreased (0.178117 --> 0.177979).  Saving model ...
	 Train_Loss: 0.2044 Train_Acc: 92.452 Val_Loss: 0.1780  BEST VAL Loss: 0.1780  Val_Acc: 93.559

Epoch 92: Validation loss decreased (0.177979 --> 0.177875).  Saving model ...
	 Train_Loss: 0.2039 Train_Acc: 92.533 Val_Loss: 0.1779  BEST VAL Loss: 0.1779  Val_Acc: 93.926

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.2033 Train_Acc: 92.706 Val_Loss: 0.1779  BEST VAL Loss: 0.1779  Val_Acc: 94.170

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.2028 Train_Acc: 92.569 Val_Loss: 0.1779  BEST VAL Loss: 0.1779  Val_Acc: 93.600

Epoch 95: Validation loss decreased (0.177875 --> 0.177694).  Saving model ...
	 Train_Loss: 0.2023 Train_Acc: 92.594 Val_Loss: 0.1777  BEST VAL Loss: 0.1777  Val_Acc: 93.722

Epoch 96: Validation loss decreased (0.177694 --> 0.177520).  Saving model ...
	 Train_Loss: 0.2018 Train_Acc: 92.671 Val_Loss: 0.1775  BEST VAL Loss: 0.1775  Val_Acc: 93.967

Epoch 97: Validation loss decreased (0.177520 --> 0.177367).  Saving model ...
	 Train_Loss: 0.2013 Train_Acc: 92.793 Val_Loss: 0.1774  BEST VAL Loss: 0.1774  Val_Acc: 94.007

Epoch 98: Validation loss decreased (0.177367 --> 0.177240).  Saving model ...
	 Train_Loss: 0.2008 Train_Acc: 92.599 Val_Loss: 0.1772  BEST VAL Loss: 0.1772  Val_Acc: 94.007

Epoch 99: Validation loss decreased (0.177240 --> 0.176968).  Saving model ...
	 Train_Loss: 0.2004 Train_Acc: 92.497 Val_Loss: 0.1770  BEST VAL Loss: 0.1770  Val_Acc: 93.396

LPS_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      0.94      0.97     10114
           1       0.94      0.99      0.97      9506

    accuracy                           0.97     19620
   macro avg       0.97      0.97      0.97     19620
weighted avg       0.97      0.97      0.97     19620

LPS_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.96      0.91      0.93      1264
           1       0.91      0.96      0.93      1189

    accuracy                           0.93      2453
   macro avg       0.93      0.93      0.93      2453
weighted avg       0.94      0.93      0.93      2453

LPS_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.90      0.93      1264
           1       0.90      0.97      0.93      1189

    accuracy                           0.93      2453
   macro avg       0.93      0.93      0.93      2453
weighted avg       0.93      0.93      0.93      2453

              precision    recall  f1-score   support

           0       0.97      0.90      0.93      1264
           1       0.90      0.97      0.93      1189

    accuracy                           0.93      2453
   macro avg       0.93      0.93      0.93      2453
weighted avg       0.93      0.93      0.93      2453

LPS_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      0.84      0.91      4168
           1       0.86      0.99      0.92      4103

    accuracy                           0.92      8271
   macro avg       0.93      0.92      0.92      8271
weighted avg       0.93      0.92      0.92      8271

              precision    recall  f1-score   support

           0       0.99      0.84      0.91      4168
           1       0.86      0.99      0.92      4103

    accuracy                           0.92      8271
   macro avg       0.93      0.92      0.92      8271
weighted avg       0.93      0.92      0.92      8271

completed
