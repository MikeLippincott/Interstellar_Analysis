[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '177696fb'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'b1fc85ae'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1e7c6c7f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '8eb38382'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Flagellin_1.000_DMSO_0.025 treatment_name: Thapsigargin_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Flagellin_1.000_DMSO_0.025
TREATMENT_NAME: Thapsigargin_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (253003, 1270)
Number of total missing values across all columns: 542622
Data Subset Is Off
Wells held out for testing: ['K07' 'M10']
Wells to use for training, validation, and testing ['D06' 'D07' 'K06' 'M05' 'M11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.453750).  Saving model ...
	 Train_Loss: 0.5484 Train_Acc: 71.729 Val_Loss: 0.4537  BEST VAL Loss: 0.4537  Val_Acc: 78.246

Epoch 1: Validation loss decreased (0.453750 --> 0.439201).  Saving model ...
	 Train_Loss: 0.5081 Train_Acc: 77.183 Val_Loss: 0.4392  BEST VAL Loss: 0.4392  Val_Acc: 80.028

Epoch 2: Validation loss decreased (0.439201 --> 0.427697).  Saving model ...
	 Train_Loss: 0.4865 Train_Acc: 78.726 Val_Loss: 0.4277  BEST VAL Loss: 0.4277  Val_Acc: 81.027

Epoch 3: Validation loss decreased (0.427697 --> 0.417603).  Saving model ...
	 Train_Loss: 0.4717 Train_Acc: 79.828 Val_Loss: 0.4176  BEST VAL Loss: 0.4176  Val_Acc: 81.821

Epoch 4: Validation loss decreased (0.417603 --> 0.409874).  Saving model ...
	 Train_Loss: 0.4609 Train_Acc: 80.366 Val_Loss: 0.4099  BEST VAL Loss: 0.4099  Val_Acc: 82.109

Epoch 5: Validation loss decreased (0.409874 --> 0.403917).  Saving model ...
	 Train_Loss: 0.4521 Train_Acc: 81.008 Val_Loss: 0.4039  BEST VAL Loss: 0.4039  Val_Acc: 82.492

Epoch 6: Validation loss decreased (0.403917 --> 0.399842).  Saving model ...
	 Train_Loss: 0.4451 Train_Acc: 81.347 Val_Loss: 0.3998  BEST VAL Loss: 0.3998  Val_Acc: 82.365

Epoch 7: Validation loss decreased (0.399842 --> 0.395060).  Saving model ...
	 Train_Loss: 0.4389 Train_Acc: 81.674 Val_Loss: 0.3951  BEST VAL Loss: 0.3951  Val_Acc: 83.064

Epoch 8: Validation loss decreased (0.395060 --> 0.390983).  Saving model ...
	 Train_Loss: 0.4337 Train_Acc: 82.034 Val_Loss: 0.3910  BEST VAL Loss: 0.3910  Val_Acc: 83.541

Epoch 9: Validation loss decreased (0.390983 --> 0.387208).  Saving model ...
	 Train_Loss: 0.4292 Train_Acc: 82.202 Val_Loss: 0.3872  BEST VAL Loss: 0.3872  Val_Acc: 83.486

Epoch 10: Validation loss decreased (0.387208 --> 0.383787).  Saving model ...
	 Train_Loss: 0.4251 Train_Acc: 82.673 Val_Loss: 0.3838  BEST VAL Loss: 0.3838  Val_Acc: 83.658

Epoch 11: Validation loss decreased (0.383787 --> 0.380973).  Saving model ...
	 Train_Loss: 0.4215 Train_Acc: 82.685 Val_Loss: 0.3810  BEST VAL Loss: 0.3810  Val_Acc: 83.414

Epoch 12: Validation loss decreased (0.380973 --> 0.378873).  Saving model ...
	 Train_Loss: 0.4183 Train_Acc: 82.886 Val_Loss: 0.3789  BEST VAL Loss: 0.3789  Val_Acc: 83.086

Epoch 13: Validation loss decreased (0.378873 --> 0.376641).  Saving model ...
	 Train_Loss: 0.4153 Train_Acc: 83.018 Val_Loss: 0.3766  BEST VAL Loss: 0.3766  Val_Acc: 83.336

Epoch 14: Validation loss decreased (0.376641 --> 0.374414).  Saving model ...
	 Train_Loss: 0.4127 Train_Acc: 83.004 Val_Loss: 0.3744  BEST VAL Loss: 0.3744  Val_Acc: 84.063

Epoch 15: Validation loss decreased (0.374414 --> 0.372549).  Saving model ...
	 Train_Loss: 0.4102 Train_Acc: 83.307 Val_Loss: 0.3725  BEST VAL Loss: 0.3725  Val_Acc: 84.124

Epoch 16: Validation loss decreased (0.372549 --> 0.370640).  Saving model ...
	 Train_Loss: 0.4078 Train_Acc: 83.490 Val_Loss: 0.3706  BEST VAL Loss: 0.3706  Val_Acc: 84.274

Epoch 17: Validation loss decreased (0.370640 --> 0.369084).  Saving model ...
	 Train_Loss: 0.4057 Train_Acc: 83.425 Val_Loss: 0.3691  BEST VAL Loss: 0.3691  Val_Acc: 84.069

Epoch 18: Validation loss decreased (0.369084 --> 0.367419).  Saving model ...
	 Train_Loss: 0.4037 Train_Acc: 83.426 Val_Loss: 0.3674  BEST VAL Loss: 0.3674  Val_Acc: 84.235

Epoch 19: Validation loss decreased (0.367419 --> 0.366118).  Saving model ...
	 Train_Loss: 0.4019 Train_Acc: 83.498 Val_Loss: 0.3661  BEST VAL Loss: 0.3661  Val_Acc: 84.413

Epoch 20: Validation loss decreased (0.366118 --> 0.364912).  Saving model ...
	 Train_Loss: 0.4002 Train_Acc: 83.677 Val_Loss: 0.3649  BEST VAL Loss: 0.3649  Val_Acc: 84.063

Epoch 21: Validation loss decreased (0.364912 --> 0.363665).  Saving model ...
	 Train_Loss: 0.3986 Train_Acc: 83.802 Val_Loss: 0.3637  BEST VAL Loss: 0.3637  Val_Acc: 84.402

Epoch 22: Validation loss decreased (0.363665 --> 0.362408).  Saving model ...
	 Train_Loss: 0.3971 Train_Acc: 83.791 Val_Loss: 0.3624  BEST VAL Loss: 0.3624  Val_Acc: 84.269

Epoch 23: Validation loss decreased (0.362408 --> 0.361663).  Saving model ...
	 Train_Loss: 0.3957 Train_Acc: 83.795 Val_Loss: 0.3617  BEST VAL Loss: 0.3617  Val_Acc: 84.024

Epoch 24: Validation loss decreased (0.361663 --> 0.360703).  Saving model ...
	 Train_Loss: 0.3944 Train_Acc: 83.779 Val_Loss: 0.3607  BEST VAL Loss: 0.3607  Val_Acc: 84.130

Epoch 25: Validation loss decreased (0.360703 --> 0.359565).  Saving model ...
	 Train_Loss: 0.3932 Train_Acc: 83.887 Val_Loss: 0.3596  BEST VAL Loss: 0.3596  Val_Acc: 84.940

Epoch 26: Validation loss decreased (0.359565 --> 0.358895).  Saving model ...
	 Train_Loss: 0.3920 Train_Acc: 83.834 Val_Loss: 0.3589  BEST VAL Loss: 0.3589  Val_Acc: 84.052

Epoch 27: Validation loss decreased (0.358895 --> 0.358103).  Saving model ...
	 Train_Loss: 0.3909 Train_Acc: 84.031 Val_Loss: 0.3581  BEST VAL Loss: 0.3581  Val_Acc: 84.369

Epoch 28: Validation loss decreased (0.358103 --> 0.357204).  Saving model ...
	 Train_Loss: 0.3898 Train_Acc: 84.167 Val_Loss: 0.3572  BEST VAL Loss: 0.3572  Val_Acc: 84.835

Epoch 29: Validation loss decreased (0.357204 --> 0.356407).  Saving model ...
	 Train_Loss: 0.3887 Train_Acc: 84.022 Val_Loss: 0.3564  BEST VAL Loss: 0.3564  Val_Acc: 84.496

Epoch 30: Validation loss decreased (0.356407 --> 0.355742).  Saving model ...
	 Train_Loss: 0.3877 Train_Acc: 84.203 Val_Loss: 0.3557  BEST VAL Loss: 0.3557  Val_Acc: 84.291

Epoch 31: Validation loss decreased (0.355742 --> 0.355162).  Saving model ...
	 Train_Loss: 0.3868 Train_Acc: 84.148 Val_Loss: 0.3552  BEST VAL Loss: 0.3552  Val_Acc: 84.369

Epoch 32: Validation loss decreased (0.355162 --> 0.354264).  Saving model ...
	 Train_Loss: 0.3859 Train_Acc: 84.169 Val_Loss: 0.3543  BEST VAL Loss: 0.3543  Val_Acc: 85.024

Epoch 33: Validation loss decreased (0.354264 --> 0.353735).  Saving model ...
	 Train_Loss: 0.3850 Train_Acc: 84.296 Val_Loss: 0.3537  BEST VAL Loss: 0.3537  Val_Acc: 84.396

Epoch 34: Validation loss decreased (0.353735 --> 0.353299).  Saving model ...
	 Train_Loss: 0.3841 Train_Acc: 84.317 Val_Loss: 0.3533  BEST VAL Loss: 0.3533  Val_Acc: 84.424

Epoch 35: Validation loss decreased (0.353299 --> 0.352661).  Saving model ...
	 Train_Loss: 0.3832 Train_Acc: 84.376 Val_Loss: 0.3527  BEST VAL Loss: 0.3527  Val_Acc: 84.663

Epoch 36: Validation loss decreased (0.352661 --> 0.352199).  Saving model ...
	 Train_Loss: 0.3824 Train_Acc: 84.300 Val_Loss: 0.3522  BEST VAL Loss: 0.3522  Val_Acc: 84.790

Epoch 37: Validation loss decreased (0.352199 --> 0.351787).  Saving model ...
	 Train_Loss: 0.3816 Train_Acc: 84.415 Val_Loss: 0.3518  BEST VAL Loss: 0.3518  Val_Acc: 84.496

Epoch 38: Validation loss decreased (0.351787 --> 0.351186).  Saving model ...
	 Train_Loss: 0.3809 Train_Acc: 84.471 Val_Loss: 0.3512  BEST VAL Loss: 0.3512  Val_Acc: 85.035

Epoch 39: Validation loss decreased (0.351186 --> 0.350635).  Saving model ...
	 Train_Loss: 0.3801 Train_Acc: 84.460 Val_Loss: 0.3506  BEST VAL Loss: 0.3506  Val_Acc: 84.885

Epoch 40: Validation loss decreased (0.350635 --> 0.350182).  Saving model ...
	 Train_Loss: 0.3794 Train_Acc: 84.464 Val_Loss: 0.3502  BEST VAL Loss: 0.3502  Val_Acc: 84.774

Epoch 41: Validation loss decreased (0.350182 --> 0.349777).  Saving model ...
	 Train_Loss: 0.3787 Train_Acc: 84.561 Val_Loss: 0.3498  BEST VAL Loss: 0.3498  Val_Acc: 84.602

Epoch 42: Validation loss decreased (0.349777 --> 0.349321).  Saving model ...
	 Train_Loss: 0.3781 Train_Acc: 84.555 Val_Loss: 0.3493  BEST VAL Loss: 0.3493  Val_Acc: 84.696

Epoch 43: Validation loss decreased (0.349321 --> 0.348840).  Saving model ...
	 Train_Loss: 0.3774 Train_Acc: 84.719 Val_Loss: 0.3488  BEST VAL Loss: 0.3488  Val_Acc: 84.957

Epoch 44: Validation loss decreased (0.348840 --> 0.348474).  Saving model ...
	 Train_Loss: 0.3768 Train_Acc: 84.625 Val_Loss: 0.3485  BEST VAL Loss: 0.3485  Val_Acc: 84.779

Epoch 45: Validation loss decreased (0.348474 --> 0.347946).  Saving model ...
	 Train_Loss: 0.3762 Train_Acc: 84.651 Val_Loss: 0.3479  BEST VAL Loss: 0.3479  Val_Acc: 85.062

Epoch 46: Validation loss decreased (0.347946 --> 0.347510).  Saving model ...
	 Train_Loss: 0.3756 Train_Acc: 84.666 Val_Loss: 0.3475  BEST VAL Loss: 0.3475  Val_Acc: 84.763

Epoch 47: Validation loss decreased (0.347510 --> 0.347045).  Saving model ...
	 Train_Loss: 0.3751 Train_Acc: 84.718 Val_Loss: 0.3470  BEST VAL Loss: 0.3470  Val_Acc: 84.824

Epoch 48: Validation loss decreased (0.347045 --> 0.346508).  Saving model ...
	 Train_Loss: 0.3745 Train_Acc: 84.797 Val_Loss: 0.3465  BEST VAL Loss: 0.3465  Val_Acc: 85.423

Epoch 49: Validation loss decreased (0.346508 --> 0.346198).  Saving model ...
	 Train_Loss: 0.3739 Train_Acc: 84.805 Val_Loss: 0.3462  BEST VAL Loss: 0.3462  Val_Acc: 84.552

Epoch 50: Validation loss decreased (0.346198 --> 0.345786).  Saving model ...
	 Train_Loss: 0.3734 Train_Acc: 84.752 Val_Loss: 0.3458  BEST VAL Loss: 0.3458  Val_Acc: 85.251

Epoch 51: Validation loss decreased (0.345786 --> 0.345393).  Saving model ...
	 Train_Loss: 0.3729 Train_Acc: 84.806 Val_Loss: 0.3454  BEST VAL Loss: 0.3454  Val_Acc: 85.090

Epoch 52: Validation loss decreased (0.345393 --> 0.344998).  Saving model ...
	 Train_Loss: 0.3724 Train_Acc: 84.825 Val_Loss: 0.3450  BEST VAL Loss: 0.3450  Val_Acc: 85.162

Epoch 53: Validation loss decreased (0.344998 --> 0.344689).  Saving model ...
	 Train_Loss: 0.3719 Train_Acc: 84.846 Val_Loss: 0.3447  BEST VAL Loss: 0.3447  Val_Acc: 84.874

Epoch 54: Validation loss decreased (0.344689 --> 0.344287).  Saving model ...
	 Train_Loss: 0.3714 Train_Acc: 84.972 Val_Loss: 0.3443  BEST VAL Loss: 0.3443  Val_Acc: 85.318

Epoch 55: Validation loss decreased (0.344287 --> 0.343908).  Saving model ...
	 Train_Loss: 0.3710 Train_Acc: 84.890 Val_Loss: 0.3439  BEST VAL Loss: 0.3439  Val_Acc: 85.440

Epoch 56: Validation loss decreased (0.343908 --> 0.343531).  Saving model ...
	 Train_Loss: 0.3705 Train_Acc: 84.944 Val_Loss: 0.3435  BEST VAL Loss: 0.3435  Val_Acc: 85.201

Epoch 57: Validation loss decreased (0.343531 --> 0.343179).  Saving model ...
	 Train_Loss: 0.3701 Train_Acc: 85.033 Val_Loss: 0.3432  BEST VAL Loss: 0.3432  Val_Acc: 85.351

Epoch 58: Validation loss decreased (0.343179 --> 0.342875).  Saving model ...
	 Train_Loss: 0.3696 Train_Acc: 84.958 Val_Loss: 0.3429  BEST VAL Loss: 0.3429  Val_Acc: 85.457

Epoch 59: Validation loss decreased (0.342875 --> 0.342612).  Saving model ...
	 Train_Loss: 0.3692 Train_Acc: 85.104 Val_Loss: 0.3426  BEST VAL Loss: 0.3426  Val_Acc: 84.929

Epoch 60: Validation loss decreased (0.342612 --> 0.342331).  Saving model ...
	 Train_Loss: 0.3687 Train_Acc: 85.117 Val_Loss: 0.3423  BEST VAL Loss: 0.3423  Val_Acc: 85.101

Epoch 61: Validation loss decreased (0.342331 --> 0.342017).  Saving model ...
	 Train_Loss: 0.3683 Train_Acc: 85.027 Val_Loss: 0.3420  BEST VAL Loss: 0.3420  Val_Acc: 85.196

Epoch 62: Validation loss decreased (0.342017 --> 0.341669).  Saving model ...
	 Train_Loss: 0.3679 Train_Acc: 85.169 Val_Loss: 0.3417  BEST VAL Loss: 0.3417  Val_Acc: 85.457

Epoch 63: Validation loss decreased (0.341669 --> 0.341357).  Saving model ...
	 Train_Loss: 0.3675 Train_Acc: 85.070 Val_Loss: 0.3414  BEST VAL Loss: 0.3414  Val_Acc: 85.490

Epoch 64: Validation loss decreased (0.341357 --> 0.341070).  Saving model ...
	 Train_Loss: 0.3671 Train_Acc: 85.023 Val_Loss: 0.3411  BEST VAL Loss: 0.3411  Val_Acc: 85.273

Epoch 65: Validation loss decreased (0.341070 --> 0.340920).  Saving model ...
	 Train_Loss: 0.3667 Train_Acc: 85.039 Val_Loss: 0.3409  BEST VAL Loss: 0.3409  Val_Acc: 84.924

Epoch 66: Validation loss decreased (0.340920 --> 0.340607).  Saving model ...
	 Train_Loss: 0.3664 Train_Acc: 85.152 Val_Loss: 0.3406  BEST VAL Loss: 0.3406  Val_Acc: 85.268

Epoch 67: Validation loss decreased (0.340607 --> 0.340350).  Saving model ...
	 Train_Loss: 0.3660 Train_Acc: 85.251 Val_Loss: 0.3404  BEST VAL Loss: 0.3404  Val_Acc: 85.223

Epoch 68: Validation loss decreased (0.340350 --> 0.340125).  Saving model ...
	 Train_Loss: 0.3656 Train_Acc: 85.187 Val_Loss: 0.3401  BEST VAL Loss: 0.3401  Val_Acc: 85.334

Epoch 69: Validation loss decreased (0.340125 --> 0.339913).  Saving model ...
	 Train_Loss: 0.3652 Train_Acc: 85.270 Val_Loss: 0.3399  BEST VAL Loss: 0.3399  Val_Acc: 85.168

Epoch 70: Validation loss decreased (0.339913 --> 0.339671).  Saving model ...
	 Train_Loss: 0.3649 Train_Acc: 85.321 Val_Loss: 0.3397  BEST VAL Loss: 0.3397  Val_Acc: 85.373

Epoch 71: Validation loss decreased (0.339671 --> 0.339403).  Saving model ...
	 Train_Loss: 0.3645 Train_Acc: 85.154 Val_Loss: 0.3394  BEST VAL Loss: 0.3394  Val_Acc: 85.179

Epoch 72: Validation loss decreased (0.339403 --> 0.339087).  Saving model ...
	 Train_Loss: 0.3642 Train_Acc: 85.258 Val_Loss: 0.3391  BEST VAL Loss: 0.3391  Val_Acc: 85.651

Epoch 73: Validation loss decreased (0.339087 --> 0.338799).  Saving model ...
	 Train_Loss: 0.3638 Train_Acc: 85.355 Val_Loss: 0.3388  BEST VAL Loss: 0.3388  Val_Acc: 85.584

Epoch 74: Validation loss decreased (0.338799 --> 0.338558).  Saving model ...
	 Train_Loss: 0.3635 Train_Acc: 85.223 Val_Loss: 0.3386  BEST VAL Loss: 0.3386  Val_Acc: 85.273

Epoch 75: Validation loss decreased (0.338558 --> 0.338422).  Saving model ...
	 Train_Loss: 0.3631 Train_Acc: 85.216 Val_Loss: 0.3384  BEST VAL Loss: 0.3384  Val_Acc: 85.179

Epoch 76: Validation loss decreased (0.338422 --> 0.338219).  Saving model ...
	 Train_Loss: 0.3628 Train_Acc: 85.298 Val_Loss: 0.3382  BEST VAL Loss: 0.3382  Val_Acc: 85.518

Epoch 77: Validation loss decreased (0.338219 --> 0.338048).  Saving model ...
	 Train_Loss: 0.3625 Train_Acc: 85.319 Val_Loss: 0.3380  BEST VAL Loss: 0.3380  Val_Acc: 85.273

Epoch 78: Validation loss decreased (0.338048 --> 0.337822).  Saving model ...
	 Train_Loss: 0.3622 Train_Acc: 85.425 Val_Loss: 0.3378  BEST VAL Loss: 0.3378  Val_Acc: 85.318

Epoch 79: Validation loss decreased (0.337822 --> 0.337601).  Saving model ...
	 Train_Loss: 0.3619 Train_Acc: 85.318 Val_Loss: 0.3376  BEST VAL Loss: 0.3376  Val_Acc: 85.457

Epoch 80: Validation loss decreased (0.337601 --> 0.337353).  Saving model ...
	 Train_Loss: 0.3616 Train_Acc: 85.502 Val_Loss: 0.3374  BEST VAL Loss: 0.3374  Val_Acc: 85.401

Epoch 81: Validation loss decreased (0.337353 --> 0.337076).  Saving model ...
	 Train_Loss: 0.3613 Train_Acc: 85.285 Val_Loss: 0.3371  BEST VAL Loss: 0.3371  Val_Acc: 85.601

Epoch 82: Validation loss decreased (0.337076 --> 0.336864).  Saving model ...
	 Train_Loss: 0.3610 Train_Acc: 85.336 Val_Loss: 0.3369  BEST VAL Loss: 0.3369  Val_Acc: 85.540

Epoch 83: Validation loss decreased (0.336864 --> 0.336640).  Saving model ...
	 Train_Loss: 0.3607 Train_Acc: 85.480 Val_Loss: 0.3366  BEST VAL Loss: 0.3366  Val_Acc: 85.534

Epoch 84: Validation loss decreased (0.336640 --> 0.336453).  Saving model ...
	 Train_Loss: 0.3604 Train_Acc: 85.411 Val_Loss: 0.3365  BEST VAL Loss: 0.3365  Val_Acc: 85.307

Epoch 85: Validation loss decreased (0.336453 --> 0.336259).  Saving model ...
	 Train_Loss: 0.3601 Train_Acc: 85.367 Val_Loss: 0.3363  BEST VAL Loss: 0.3363  Val_Acc: 85.579

Epoch 86: Validation loss decreased (0.336259 --> 0.336034).  Saving model ...
	 Train_Loss: 0.3599 Train_Acc: 85.430 Val_Loss: 0.3360  BEST VAL Loss: 0.3360  Val_Acc: 85.878

Epoch 87: Validation loss decreased (0.336034 --> 0.335830).  Saving model ...
	 Train_Loss: 0.3596 Train_Acc: 85.480 Val_Loss: 0.3358  BEST VAL Loss: 0.3358  Val_Acc: 85.634

Epoch 88: Validation loss decreased (0.335830 --> 0.335578).  Saving model ...
	 Train_Loss: 0.3593 Train_Acc: 85.421 Val_Loss: 0.3356  BEST VAL Loss: 0.3356  Val_Acc: 85.851

Epoch 89: Validation loss decreased (0.335578 --> 0.335407).  Saving model ...
	 Train_Loss: 0.3590 Train_Acc: 85.534 Val_Loss: 0.3354  BEST VAL Loss: 0.3354  Val_Acc: 85.523

Epoch 90: Validation loss decreased (0.335407 --> 0.335264).  Saving model ...
	 Train_Loss: 0.3588 Train_Acc: 85.411 Val_Loss: 0.3353  BEST VAL Loss: 0.3353  Val_Acc: 85.301

Epoch 91: Validation loss decreased (0.335264 --> 0.335087).  Saving model ...
	 Train_Loss: 0.3585 Train_Acc: 85.513 Val_Loss: 0.3351  BEST VAL Loss: 0.3351  Val_Acc: 85.512

Epoch 92: Validation loss decreased (0.335087 --> 0.334990).  Saving model ...
	 Train_Loss: 0.3583 Train_Acc: 85.502 Val_Loss: 0.3350  BEST VAL Loss: 0.3350  Val_Acc: 85.101

Epoch 93: Validation loss decreased (0.334990 --> 0.334854).  Saving model ...
	 Train_Loss: 0.3580 Train_Acc: 85.631 Val_Loss: 0.3349  BEST VAL Loss: 0.3349  Val_Acc: 85.379

Epoch 94: Validation loss decreased (0.334854 --> 0.334768).  Saving model ...
	 Train_Loss: 0.3578 Train_Acc: 85.412 Val_Loss: 0.3348  BEST VAL Loss: 0.3348  Val_Acc: 85.051

Epoch 95: Validation loss decreased (0.334768 --> 0.334602).  Saving model ...
	 Train_Loss: 0.3575 Train_Acc: 85.562 Val_Loss: 0.3346  BEST VAL Loss: 0.3346  Val_Acc: 85.695

Epoch 96: Validation loss decreased (0.334602 --> 0.334435).  Saving model ...
	 Train_Loss: 0.3573 Train_Acc: 85.474 Val_Loss: 0.3344  BEST VAL Loss: 0.3344  Val_Acc: 85.790

Epoch 97: Validation loss decreased (0.334435 --> 0.334273).  Saving model ...
	 Train_Loss: 0.3570 Train_Acc: 85.600 Val_Loss: 0.3343  BEST VAL Loss: 0.3343  Val_Acc: 85.734

Epoch 98: Validation loss decreased (0.334273 --> 0.334121).  Saving model ...
	 Train_Loss: 0.3568 Train_Acc: 85.551 Val_Loss: 0.3341  BEST VAL Loss: 0.3341  Val_Acc: 85.529

Epoch 99: Validation loss decreased (0.334121 --> 0.333956).  Saving model ...
	 Train_Loss: 0.3566 Train_Acc: 85.636 Val_Loss: 0.3340  BEST VAL Loss: 0.3340  Val_Acc: 85.679

Flagellin_1.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.90      0.78      0.84     56122
           1       0.87      0.95      0.91     87992

    accuracy                           0.88    144114
   macro avg       0.89      0.86      0.87    144114
weighted avg       0.88      0.88      0.88    144114

Flagellin_1.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.87      0.74      0.80      7016
           1       0.85      0.93      0.89     10999

    accuracy                           0.86     18015
   macro avg       0.86      0.84      0.84     18015
weighted avg       0.86      0.86      0.85     18015

Flagellin_1.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.88      0.75      0.81      7015
           1       0.86      0.93      0.89     11000

    accuracy                           0.86     18015
   macro avg       0.87      0.84      0.85     18015
weighted avg       0.86      0.86      0.86     18015

              precision    recall  f1-score   support

           0       0.88      0.75      0.81      7015
           1       0.86      0.93      0.89     11000

    accuracy                           0.86     18015
   macro avg       0.87      0.84      0.85     18015
weighted avg       0.86      0.86      0.86     18015

Flagellin_1.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.51      0.55      0.53     34394
           1       0.57      0.53      0.55     38465

    accuracy                           0.54     72859
   macro avg       0.54      0.54      0.54     72859
weighted avg       0.54      0.54      0.54     72859

              precision    recall  f1-score   support

           0       0.51      0.55      0.53     34394
           1       0.57      0.53      0.55     38465

    accuracy                           0.54     72859
   macro avg       0.54      0.54      0.54     72859
weighted avg       0.54      0.54      0.54     72859

completed
