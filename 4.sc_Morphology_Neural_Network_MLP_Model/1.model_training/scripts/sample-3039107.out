[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ee09eca6'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '4ff4c421'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '3dfaeb5d'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e703d139'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_1.000_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (31668, 1276)
Number of total missing values across all columns: 63336
Data Subset Is Off
Wells held out for testing: ['B16' 'M22']
Wells to use for training, validation, and testing ['B17' 'B20' 'B21' 'M18' 'M19' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.689469).  Saving model ...
	 Train_Loss: 0.7006 Train_Acc: 51.099 Val_Loss: 0.6895  BEST VAL Loss: 0.6895  Val_Acc: 56.171

Epoch 1: Validation loss decreased (0.689469 --> 0.680200).  Saving model ...
	 Train_Loss: 0.6922 Train_Acc: 53.705 Val_Loss: 0.6802  BEST VAL Loss: 0.6802  Val_Acc: 59.848

Epoch 2: Validation loss decreased (0.680200 --> 0.672733).  Saving model ...
	 Train_Loss: 0.6874 Train_Acc: 55.554 Val_Loss: 0.6727  BEST VAL Loss: 0.6727  Val_Acc: 62.342

Epoch 3: Validation loss decreased (0.672733 --> 0.666962).  Saving model ...
	 Train_Loss: 0.6838 Train_Acc: 56.400 Val_Loss: 0.6670  BEST VAL Loss: 0.6670  Val_Acc: 63.018

Epoch 4: Validation loss decreased (0.666962 --> 0.665133).  Saving model ...
	 Train_Loss: 0.6812 Train_Acc: 56.669 Val_Loss: 0.6651  BEST VAL Loss: 0.6651  Val_Acc: 62.215

Epoch 5: Validation loss decreased (0.665133 --> 0.660821).  Saving model ...
	 Train_Loss: 0.6788 Train_Acc: 57.235 Val_Loss: 0.6608  BEST VAL Loss: 0.6608  Val_Acc: 63.905

Epoch 6: Validation loss decreased (0.660821 --> 0.657519).  Saving model ...
	 Train_Loss: 0.6764 Train_Acc: 57.991 Val_Loss: 0.6575  BEST VAL Loss: 0.6575  Val_Acc: 65.089

Epoch 7: Validation loss decreased (0.657519 --> 0.654104).  Saving model ...
	 Train_Loss: 0.6747 Train_Acc: 57.922 Val_Loss: 0.6541  BEST VAL Loss: 0.6541  Val_Acc: 65.300

Epoch 8: Validation loss decreased (0.654104 --> 0.652006).  Saving model ...
	 Train_Loss: 0.6725 Train_Acc: 59.994 Val_Loss: 0.6520  BEST VAL Loss: 0.6520  Val_Acc: 65.216

Epoch 9: Validation loss decreased (0.652006 --> 0.649641).  Saving model ...
	 Train_Loss: 0.6693 Train_Acc: 62.805 Val_Loss: 0.6496  BEST VAL Loss: 0.6496  Val_Acc: 66.061

Epoch 10: Validation loss decreased (0.649641 --> 0.646706).  Saving model ...
	 Train_Loss: 0.6663 Train_Acc: 62.197 Val_Loss: 0.6467  BEST VAL Loss: 0.6467  Val_Acc: 66.610

Epoch 11: Validation loss decreased (0.646706 --> 0.645434).  Saving model ...
	 Train_Loss: 0.6638 Train_Acc: 62.932 Val_Loss: 0.6454  BEST VAL Loss: 0.6454  Val_Acc: 66.906

Epoch 12: Validation loss decreased (0.645434 --> 0.642949).  Saving model ...
	 Train_Loss: 0.6612 Train_Acc: 63.355 Val_Loss: 0.6429  BEST VAL Loss: 0.6429  Val_Acc: 66.399

Epoch 13: Validation loss decreased (0.642949 --> 0.640040).  Saving model ...
	 Train_Loss: 0.6588 Train_Acc: 63.878 Val_Loss: 0.6400  BEST VAL Loss: 0.6400  Val_Acc: 66.906

Epoch 14: Validation loss decreased (0.640040 --> 0.637692).  Saving model ...
	 Train_Loss: 0.6565 Train_Acc: 63.857 Val_Loss: 0.6377  BEST VAL Loss: 0.6377  Val_Acc: 68.132

Epoch 15: Validation loss decreased (0.637692 --> 0.635964).  Saving model ...
	 Train_Loss: 0.6544 Train_Acc: 64.364 Val_Loss: 0.6360  BEST VAL Loss: 0.6360  Val_Acc: 68.005

Epoch 16: Validation loss decreased (0.635964 --> 0.634158).  Saving model ...
	 Train_Loss: 0.6524 Train_Acc: 64.417 Val_Loss: 0.6342  BEST VAL Loss: 0.6342  Val_Acc: 68.681

Epoch 17: Validation loss decreased (0.634158 --> 0.632213).  Saving model ...
	 Train_Loss: 0.6504 Train_Acc: 64.798 Val_Loss: 0.6322  BEST VAL Loss: 0.6322  Val_Acc: 68.132

Epoch 18: Validation loss decreased (0.632213 --> 0.630470).  Saving model ...
	 Train_Loss: 0.6487 Train_Acc: 64.924 Val_Loss: 0.6305  BEST VAL Loss: 0.6305  Val_Acc: 68.428

Epoch 19: Validation loss decreased (0.630470 --> 0.628858).  Saving model ...
	 Train_Loss: 0.6472 Train_Acc: 64.866 Val_Loss: 0.6289  BEST VAL Loss: 0.6289  Val_Acc: 68.681

Epoch 20: Validation loss decreased (0.628858 --> 0.627421).  Saving model ...
	 Train_Loss: 0.6458 Train_Acc: 64.628 Val_Loss: 0.6274  BEST VAL Loss: 0.6274  Val_Acc: 68.555

Epoch 21: Validation loss decreased (0.627421 --> 0.626612).  Saving model ...
	 Train_Loss: 0.6443 Train_Acc: 65.125 Val_Loss: 0.6266  BEST VAL Loss: 0.6266  Val_Acc: 68.681

Epoch 22: Validation loss decreased (0.626612 --> 0.625413).  Saving model ...
	 Train_Loss: 0.6428 Train_Acc: 65.611 Val_Loss: 0.6254  BEST VAL Loss: 0.6254  Val_Acc: 68.681

Epoch 23: Validation loss decreased (0.625413 --> 0.624104).  Saving model ...
	 Train_Loss: 0.6415 Train_Acc: 65.162 Val_Loss: 0.6241  BEST VAL Loss: 0.6241  Val_Acc: 68.935

Epoch 24: Validation loss decreased (0.624104 --> 0.622747).  Saving model ...
	 Train_Loss: 0.6403 Train_Acc: 65.749 Val_Loss: 0.6227  BEST VAL Loss: 0.6227  Val_Acc: 68.850

Epoch 25: Validation loss decreased (0.622747 --> 0.621551).  Saving model ...
	 Train_Loss: 0.6389 Train_Acc: 65.855 Val_Loss: 0.6216  BEST VAL Loss: 0.6216  Val_Acc: 69.358

Epoch 26: Validation loss decreased (0.621551 --> 0.620253).  Saving model ...
	 Train_Loss: 0.6377 Train_Acc: 65.775 Val_Loss: 0.6203  BEST VAL Loss: 0.6203  Val_Acc: 68.850

Epoch 27: Validation loss decreased (0.620253 --> 0.619408).  Saving model ...
	 Train_Loss: 0.6365 Train_Acc: 66.077 Val_Loss: 0.6194  BEST VAL Loss: 0.6194  Val_Acc: 68.555

Epoch 28: Validation loss decreased (0.619408 --> 0.618527).  Saving model ...
	 Train_Loss: 0.6354 Train_Acc: 65.664 Val_Loss: 0.6185  BEST VAL Loss: 0.6185  Val_Acc: 68.301

Epoch 29: Validation loss decreased (0.618527 --> 0.617585).  Saving model ...
	 Train_Loss: 0.6343 Train_Acc: 66.003 Val_Loss: 0.6176  BEST VAL Loss: 0.6176  Val_Acc: 68.343

Epoch 30: Validation loss decreased (0.617585 --> 0.616975).  Saving model ...
	 Train_Loss: 0.6333 Train_Acc: 66.013 Val_Loss: 0.6170  BEST VAL Loss: 0.6170  Val_Acc: 68.512

Epoch 31: Validation loss decreased (0.616975 --> 0.616225).  Saving model ...
	 Train_Loss: 0.6322 Train_Acc: 66.320 Val_Loss: 0.6162  BEST VAL Loss: 0.6162  Val_Acc: 69.189

Epoch 32: Validation loss decreased (0.616225 --> 0.615636).  Saving model ...
	 Train_Loss: 0.6312 Train_Acc: 66.462 Val_Loss: 0.6156  BEST VAL Loss: 0.6156  Val_Acc: 69.146

Epoch 33: Validation loss decreased (0.615636 --> 0.614826).  Saving model ...
	 Train_Loss: 0.6303 Train_Acc: 66.304 Val_Loss: 0.6148  BEST VAL Loss: 0.6148  Val_Acc: 68.977

Epoch 34: Validation loss decreased (0.614826 --> 0.613879).  Saving model ...
	 Train_Loss: 0.6294 Train_Acc: 66.320 Val_Loss: 0.6139  BEST VAL Loss: 0.6139  Val_Acc: 69.780

Epoch 35: Validation loss decreased (0.613879 --> 0.613516).  Saving model ...
	 Train_Loss: 0.6286 Train_Acc: 66.679 Val_Loss: 0.6135  BEST VAL Loss: 0.6135  Val_Acc: 68.850

Epoch 36: Validation loss decreased (0.613516 --> 0.613165).  Saving model ...
	 Train_Loss: 0.6279 Train_Acc: 65.833 Val_Loss: 0.6132  BEST VAL Loss: 0.6132  Val_Acc: 69.442

Epoch 37: Validation loss decreased (0.613165 --> 0.612329).  Saving model ...
	 Train_Loss: 0.6271 Train_Acc: 66.552 Val_Loss: 0.6123  BEST VAL Loss: 0.6123  Val_Acc: 69.527

Epoch 38: Validation loss decreased (0.612329 --> 0.611625).  Saving model ...
	 Train_Loss: 0.6264 Train_Acc: 66.251 Val_Loss: 0.6116  BEST VAL Loss: 0.6116  Val_Acc: 69.992

Epoch 39: Validation loss decreased (0.611625 --> 0.611032).  Saving model ...
	 Train_Loss: 0.6257 Train_Acc: 66.912 Val_Loss: 0.6110  BEST VAL Loss: 0.6110  Val_Acc: 70.161

Epoch 40: Validation loss decreased (0.611032 --> 0.610458).  Saving model ...
	 Train_Loss: 0.6249 Train_Acc: 66.838 Val_Loss: 0.6105  BEST VAL Loss: 0.6105  Val_Acc: 70.034

Epoch 41: Validation loss decreased (0.610458 --> 0.609875).  Saving model ...
	 Train_Loss: 0.6242 Train_Acc: 67.001 Val_Loss: 0.6099  BEST VAL Loss: 0.6099  Val_Acc: 70.161

Epoch 42: Validation loss decreased (0.609875 --> 0.609368).  Saving model ...
	 Train_Loss: 0.6235 Train_Acc: 66.637 Val_Loss: 0.6094  BEST VAL Loss: 0.6094  Val_Acc: 69.907

Epoch 43: Validation loss decreased (0.609368 --> 0.608905).  Saving model ...
	 Train_Loss: 0.6229 Train_Acc: 67.012 Val_Loss: 0.6089  BEST VAL Loss: 0.6089  Val_Acc: 69.569

Epoch 44: Validation loss decreased (0.608905 --> 0.608490).  Saving model ...
	 Train_Loss: 0.6222 Train_Acc: 67.186 Val_Loss: 0.6085  BEST VAL Loss: 0.6085  Val_Acc: 69.738

Epoch 45: Validation loss decreased (0.608490 --> 0.607946).  Saving model ...
	 Train_Loss: 0.6216 Train_Acc: 67.007 Val_Loss: 0.6079  BEST VAL Loss: 0.6079  Val_Acc: 71.217

Epoch 46: Validation loss decreased (0.607946 --> 0.607445).  Saving model ...
	 Train_Loss: 0.6209 Train_Acc: 67.271 Val_Loss: 0.6074  BEST VAL Loss: 0.6074  Val_Acc: 70.245

Epoch 47: Validation loss decreased (0.607445 --> 0.606873).  Saving model ...
	 Train_Loss: 0.6202 Train_Acc: 67.160 Val_Loss: 0.6069  BEST VAL Loss: 0.6069  Val_Acc: 69.992

Epoch 48: Validation loss decreased (0.606873 --> 0.606514).  Saving model ...
	 Train_Loss: 0.6196 Train_Acc: 67.276 Val_Loss: 0.6065  BEST VAL Loss: 0.6065  Val_Acc: 69.484

Epoch 49: Validation loss decreased (0.606514 --> 0.605920).  Saving model ...
	 Train_Loss: 0.6189 Train_Acc: 67.229 Val_Loss: 0.6059  BEST VAL Loss: 0.6059  Val_Acc: 70.330

Epoch 50: Validation loss decreased (0.605920 --> 0.605338).  Saving model ...
	 Train_Loss: 0.6184 Train_Acc: 67.081 Val_Loss: 0.6053  BEST VAL Loss: 0.6053  Val_Acc: 70.752

Epoch 51: Validation loss decreased (0.605338 --> 0.604988).  Saving model ...
	 Train_Loss: 0.6178 Train_Acc: 67.355 Val_Loss: 0.6050  BEST VAL Loss: 0.6050  Val_Acc: 69.653

Epoch 52: Validation loss decreased (0.604988 --> 0.604687).  Saving model ...
	 Train_Loss: 0.6173 Train_Acc: 67.614 Val_Loss: 0.6047  BEST VAL Loss: 0.6047  Val_Acc: 69.949

Epoch 53: Validation loss decreased (0.604687 --> 0.604400).  Saving model ...
	 Train_Loss: 0.6167 Train_Acc: 67.620 Val_Loss: 0.6044  BEST VAL Loss: 0.6044  Val_Acc: 70.076

Epoch 54: Validation loss decreased (0.604400 --> 0.604024).  Saving model ...
	 Train_Loss: 0.6163 Train_Acc: 66.890 Val_Loss: 0.6040  BEST VAL Loss: 0.6040  Val_Acc: 69.273

Epoch 55: Validation loss decreased (0.604024 --> 0.603677).  Saving model ...
	 Train_Loss: 0.6158 Train_Acc: 67.424 Val_Loss: 0.6037  BEST VAL Loss: 0.6037  Val_Acc: 70.287

Epoch 56: Validation loss decreased (0.603677 --> 0.603471).  Saving model ...
	 Train_Loss: 0.6152 Train_Acc: 68.164 Val_Loss: 0.6035  BEST VAL Loss: 0.6035  Val_Acc: 70.710

Epoch 57: Validation loss decreased (0.603471 --> 0.603225).  Saving model ...
	 Train_Loss: 0.6146 Train_Acc: 68.048 Val_Loss: 0.6032  BEST VAL Loss: 0.6032  Val_Acc: 70.330

Epoch 58: Validation loss decreased (0.603225 --> 0.602888).  Saving model ...
	 Train_Loss: 0.6140 Train_Acc: 68.000 Val_Loss: 0.6029  BEST VAL Loss: 0.6029  Val_Acc: 71.555

Epoch 59: Validation loss decreased (0.602888 --> 0.602470).  Saving model ...
	 Train_Loss: 0.6135 Train_Acc: 68.180 Val_Loss: 0.6025  BEST VAL Loss: 0.6025  Val_Acc: 70.626

Epoch 60: Validation loss decreased (0.602470 --> 0.602268).  Saving model ...
	 Train_Loss: 0.6131 Train_Acc: 67.942 Val_Loss: 0.6023  BEST VAL Loss: 0.6023  Val_Acc: 70.203

Epoch 61: Validation loss decreased (0.602268 --> 0.601884).  Saving model ...
	 Train_Loss: 0.6126 Train_Acc: 67.440 Val_Loss: 0.6019  BEST VAL Loss: 0.6019  Val_Acc: 71.386

Epoch 62: Validation loss decreased (0.601884 --> 0.601555).  Saving model ...
	 Train_Loss: 0.6121 Train_Acc: 67.710 Val_Loss: 0.6016  BEST VAL Loss: 0.6016  Val_Acc: 70.287

Epoch 63: Validation loss decreased (0.601555 --> 0.601253).  Saving model ...
	 Train_Loss: 0.6117 Train_Acc: 67.778 Val_Loss: 0.6013  BEST VAL Loss: 0.6013  Val_Acc: 70.752

Epoch 64: Validation loss decreased (0.601253 --> 0.600988).  Saving model ...
	 Train_Loss: 0.6114 Train_Acc: 67.107 Val_Loss: 0.6010  BEST VAL Loss: 0.6010  Val_Acc: 70.456

Epoch 65: Validation loss decreased (0.600988 --> 0.600682).  Saving model ...
	 Train_Loss: 0.6111 Train_Acc: 67.054 Val_Loss: 0.6007  BEST VAL Loss: 0.6007  Val_Acc: 71.344

Epoch 66: Validation loss decreased (0.600682 --> 0.600475).  Saving model ...
	 Train_Loss: 0.6108 Train_Acc: 67.440 Val_Loss: 0.6005  BEST VAL Loss: 0.6005  Val_Acc: 70.964

Epoch 67: Validation loss decreased (0.600475 --> 0.600063).  Saving model ...
	 Train_Loss: 0.6104 Train_Acc: 67.192 Val_Loss: 0.6001  BEST VAL Loss: 0.6001  Val_Acc: 71.555

Epoch 68: Validation loss decreased (0.600063 --> 0.599880).  Saving model ...
	 Train_Loss: 0.6101 Train_Acc: 67.694 Val_Loss: 0.5999  BEST VAL Loss: 0.5999  Val_Acc: 70.583

Epoch 69: Validation loss decreased (0.599880 --> 0.599694).  Saving model ...
	 Train_Loss: 0.6097 Train_Acc: 67.879 Val_Loss: 0.5997  BEST VAL Loss: 0.5997  Val_Acc: 70.541

Epoch 70: Validation loss decreased (0.599694 --> 0.599396).  Saving model ...
	 Train_Loss: 0.6093 Train_Acc: 67.815 Val_Loss: 0.5994  BEST VAL Loss: 0.5994  Val_Acc: 70.795

Epoch 71: Validation loss decreased (0.599396 --> 0.598979).  Saving model ...
	 Train_Loss: 0.6089 Train_Acc: 68.217 Val_Loss: 0.5990  BEST VAL Loss: 0.5990  Val_Acc: 71.936

Epoch 72: Validation loss decreased (0.598979 --> 0.598623).  Saving model ...
	 Train_Loss: 0.6086 Train_Acc: 67.773 Val_Loss: 0.5986  BEST VAL Loss: 0.5986  Val_Acc: 70.795

Epoch 73: Validation loss decreased (0.598623 --> 0.598360).  Saving model ...
	 Train_Loss: 0.6082 Train_Acc: 67.821 Val_Loss: 0.5984  BEST VAL Loss: 0.5984  Val_Acc: 69.907

Epoch 74: Validation loss decreased (0.598360 --> 0.598062).  Saving model ...
	 Train_Loss: 0.6079 Train_Acc: 68.101 Val_Loss: 0.5981  BEST VAL Loss: 0.5981  Val_Acc: 70.076

Epoch 75: Validation loss decreased (0.598062 --> 0.597810).  Saving model ...
	 Train_Loss: 0.6076 Train_Acc: 68.138 Val_Loss: 0.5978  BEST VAL Loss: 0.5978  Val_Acc: 69.696

Epoch 76: Validation loss decreased (0.597810 --> 0.597634).  Saving model ...
	 Train_Loss: 0.6072 Train_Acc: 67.620 Val_Loss: 0.5976  BEST VAL Loss: 0.5976  Val_Acc: 69.653

Epoch 77: Validation loss decreased (0.597634 --> 0.597500).  Saving model ...
	 Train_Loss: 0.6070 Train_Acc: 67.139 Val_Loss: 0.5975  BEST VAL Loss: 0.5975  Val_Acc: 69.611

Epoch 78: Validation loss decreased (0.597500 --> 0.597344).  Saving model ...
	 Train_Loss: 0.6067 Train_Acc: 67.546 Val_Loss: 0.5973  BEST VAL Loss: 0.5973  Val_Acc: 69.907

Epoch 79: Validation loss decreased (0.597344 --> 0.596904).  Saving model ...
	 Train_Loss: 0.6064 Train_Acc: 68.058 Val_Loss: 0.5969  BEST VAL Loss: 0.5969  Val_Acc: 70.964

Epoch 80: Validation loss decreased (0.596904 --> 0.596667).  Saving model ...
	 Train_Loss: 0.6061 Train_Acc: 67.826 Val_Loss: 0.5967  BEST VAL Loss: 0.5967  Val_Acc: 70.161

Epoch 81: Validation loss decreased (0.596667 --> 0.596451).  Saving model ...
	 Train_Loss: 0.6058 Train_Acc: 68.085 Val_Loss: 0.5965  BEST VAL Loss: 0.5965  Val_Acc: 70.456

Epoch 82: Validation loss decreased (0.596451 --> 0.596258).  Saving model ...
	 Train_Loss: 0.6055 Train_Acc: 68.286 Val_Loss: 0.5963  BEST VAL Loss: 0.5963  Val_Acc: 70.626

Epoch 83: Validation loss decreased (0.596258 --> 0.596037).  Saving model ...
	 Train_Loss: 0.6052 Train_Acc: 68.280 Val_Loss: 0.5960  BEST VAL Loss: 0.5960  Val_Acc: 70.414

Epoch 84: Validation loss decreased (0.596037 --> 0.595907).  Saving model ...
	 Train_Loss: 0.6048 Train_Acc: 68.566 Val_Loss: 0.5959  BEST VAL Loss: 0.5959  Val_Acc: 70.879

Epoch 85: Validation loss decreased (0.595907 --> 0.595779).  Saving model ...
	 Train_Loss: 0.6044 Train_Acc: 69.945 Val_Loss: 0.5958  BEST VAL Loss: 0.5958  Val_Acc: 70.583

Epoch 86: Validation loss decreased (0.595779 --> 0.595623).  Saving model ...
	 Train_Loss: 0.6040 Train_Acc: 69.908 Val_Loss: 0.5956  BEST VAL Loss: 0.5956  Val_Acc: 69.822

Epoch 87: Validation loss decreased (0.595623 --> 0.595477).  Saving model ...
	 Train_Loss: 0.6036 Train_Acc: 69.263 Val_Loss: 0.5955  BEST VAL Loss: 0.5955  Val_Acc: 70.668

Epoch 88: Validation loss decreased (0.595477 --> 0.595417).  Saving model ...
	 Train_Loss: 0.6032 Train_Acc: 69.528 Val_Loss: 0.5954  BEST VAL Loss: 0.5954  Val_Acc: 70.541

Epoch 89: Validation loss decreased (0.595417 --> 0.595259).  Saving model ...
	 Train_Loss: 0.6029 Train_Acc: 69.591 Val_Loss: 0.5953  BEST VAL Loss: 0.5953  Val_Acc: 70.541

Epoch 90: Validation loss decreased (0.595259 --> 0.595000).  Saving model ...
	 Train_Loss: 0.6025 Train_Acc: 69.417 Val_Loss: 0.5950  BEST VAL Loss: 0.5950  Val_Acc: 70.414

Epoch 91: Validation loss decreased (0.595000 --> 0.594717).  Saving model ...
	 Train_Loss: 0.6021 Train_Acc: 69.834 Val_Loss: 0.5947  BEST VAL Loss: 0.5947  Val_Acc: 70.626

Epoch 92: Validation loss decreased (0.594717 --> 0.594495).  Saving model ...
	 Train_Loss: 0.6019 Train_Acc: 69.173 Val_Loss: 0.5945  BEST VAL Loss: 0.5945  Val_Acc: 70.964

Epoch 93: Validation loss decreased (0.594495 --> 0.594392).  Saving model ...
	 Train_Loss: 0.6015 Train_Acc: 69.739 Val_Loss: 0.5944  BEST VAL Loss: 0.5944  Val_Acc: 70.287

Epoch 94: Validation loss decreased (0.594392 --> 0.594226).  Saving model ...
	 Train_Loss: 0.6012 Train_Acc: 69.823 Val_Loss: 0.5942  BEST VAL Loss: 0.5942  Val_Acc: 71.682

Epoch 95: Validation loss decreased (0.594226 --> 0.594149).  Saving model ...
	 Train_Loss: 0.6008 Train_Acc: 69.818 Val_Loss: 0.5941  BEST VAL Loss: 0.5941  Val_Acc: 70.626

Epoch 96: Validation loss decreased (0.594149 --> 0.593974).  Saving model ...
	 Train_Loss: 0.6006 Train_Acc: 69.554 Val_Loss: 0.5940  BEST VAL Loss: 0.5940  Val_Acc: 70.752

Epoch 97: Validation loss decreased (0.593974 --> 0.593968).  Saving model ...
	 Train_Loss: 0.6002 Train_Acc: 70.030 Val_Loss: 0.5940  BEST VAL Loss: 0.5940  Val_Acc: 70.668

Epoch 98: Validation loss decreased (0.593968 --> 0.593636).  Saving model ...
	 Train_Loss: 0.5998 Train_Acc: 69.887 Val_Loss: 0.5936  BEST VAL Loss: 0.5936  Val_Acc: 70.668

Epoch 99: Validation loss decreased (0.593636 --> 0.593545).  Saving model ...
	 Train_Loss: 0.5995 Train_Acc: 69.987 Val_Loss: 0.5935  BEST VAL Loss: 0.5935  Val_Acc: 70.795

Flagellin_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.66      0.57      9433
           1       0.50      0.34      0.40      9489

    accuracy                           0.50     18922
   macro avg       0.50      0.50      0.49     18922
weighted avg       0.50      0.50      0.49     18922

Flagellin_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.66      0.57      1179
           1       0.50      0.33      0.40      1187

    accuracy                           0.50      2366
   macro avg       0.50      0.50      0.48      2366
weighted avg       0.50      0.50      0.48      2366

Flagellin_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.64      0.56      1180
           1       0.51      0.37      0.42      1186

    accuracy                           0.50      2366
   macro avg       0.50      0.50      0.49      2366
weighted avg       0.50      0.50      0.49      2366

              precision    recall  f1-score   support

           0       0.50      0.64      0.56      1180
           1       0.51      0.37      0.42      1186

    accuracy                           0.50      2366
   macro avg       0.50      0.50      0.49      2366
weighted avg       0.50      0.50      0.49      2366

Flagellin_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.52      0.51      4017
           1       0.49      0.47      0.48      3997

    accuracy                           0.50      8014
   macro avg       0.50      0.50      0.50      8014
weighted avg       0.50      0.50      0.50      8014

              precision    recall  f1-score   support

           0       0.50      0.52      0.51      4017
           1       0.49      0.47      0.48      3997

    accuracy                           0.50      8014
   macro avg       0.50      0.50      0.50      8014
weighted avg       0.50      0.50      0.50      8014

completed
