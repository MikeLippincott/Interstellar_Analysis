[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ab9720a1'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '7b57c5e5'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '5b6a5f83'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'c2c0389c'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_Nigericin_1.000_1.0_DMSO_0.025'
 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (347179, 1270)
Number of total missing values across all columns: 0
Data Subset Is Off
Wells held out for testing: ['K08' 'M09']
Wells to use for training, validation, and testing ['K02' 'K03' 'K09' 'M02' 'M03' 'M08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.606399).  Saving model ...
	 Train_Loss: 0.6543 Train_Acc: 62.924 Val_Loss: 0.6064  BEST VAL Loss: 0.6064  Val_Acc: 68.336

Epoch 1: Validation loss decreased (0.606399 --> 0.591232).  Saving model ...
	 Train_Loss: 0.6242 Train_Acc: 65.922 Val_Loss: 0.5912  BEST VAL Loss: 0.5912  Val_Acc: 69.885

Epoch 2: Validation loss decreased (0.591232 --> 0.579289).  Saving model ...
	 Train_Loss: 0.6073 Train_Acc: 68.263 Val_Loss: 0.5793  BEST VAL Loss: 0.5793  Val_Acc: 71.760

Epoch 3: Validation loss decreased (0.579289 --> 0.573322).  Saving model ...
	 Train_Loss: 0.5954 Train_Acc: 70.345 Val_Loss: 0.5733  BEST VAL Loss: 0.5733  Val_Acc: 73.111

Epoch 4: Validation loss decreased (0.573322 --> 0.566053).  Saving model ...
	 Train_Loss: 0.5861 Train_Acc: 71.365 Val_Loss: 0.5661  BEST VAL Loss: 0.5661  Val_Acc: 73.161

Epoch 5: Validation loss decreased (0.566053 --> 0.559753).  Saving model ...
	 Train_Loss: 0.5786 Train_Acc: 72.017 Val_Loss: 0.5598  BEST VAL Loss: 0.5598  Val_Acc: 74.189

Epoch 6: Validation loss decreased (0.559753 --> 0.554153).  Saving model ...
	 Train_Loss: 0.5725 Train_Acc: 72.482 Val_Loss: 0.5542  BEST VAL Loss: 0.5542  Val_Acc: 74.687

Epoch 7: Validation loss decreased (0.554153 --> 0.549252).  Saving model ...
	 Train_Loss: 0.5673 Train_Acc: 72.948 Val_Loss: 0.5493  BEST VAL Loss: 0.5493  Val_Acc: 74.994

Epoch 8: Validation loss decreased (0.549252 --> 0.545527).  Saving model ...
	 Train_Loss: 0.5626 Train_Acc: 73.320 Val_Loss: 0.5455  BEST VAL Loss: 0.5455  Val_Acc: 74.239

Epoch 9: Validation loss decreased (0.545527 --> 0.542070).  Saving model ...
	 Train_Loss: 0.5585 Train_Acc: 73.512 Val_Loss: 0.5421  BEST VAL Loss: 0.5421  Val_Acc: 75.200

Epoch 10: Validation loss decreased (0.542070 --> 0.538815).  Saving model ...
	 Train_Loss: 0.5550 Train_Acc: 73.809 Val_Loss: 0.5388  BEST VAL Loss: 0.5388  Val_Acc: 75.360

Epoch 11: Validation loss decreased (0.538815 --> 0.535577).  Saving model ...
	 Train_Loss: 0.5519 Train_Acc: 73.953 Val_Loss: 0.5356  BEST VAL Loss: 0.5356  Val_Acc: 75.971

Epoch 12: Validation loss decreased (0.535577 --> 0.532842).  Saving model ...
	 Train_Loss: 0.5491 Train_Acc: 74.118 Val_Loss: 0.5328  BEST VAL Loss: 0.5328  Val_Acc: 75.691

Epoch 13: Validation loss decreased (0.532842 --> 0.530602).  Saving model ...
	 Train_Loss: 0.5465 Train_Acc: 74.337 Val_Loss: 0.5306  BEST VAL Loss: 0.5306  Val_Acc: 75.527

Epoch 14: Validation loss decreased (0.530602 --> 0.528356).  Saving model ...
	 Train_Loss: 0.5441 Train_Acc: 74.449 Val_Loss: 0.5284  BEST VAL Loss: 0.5284  Val_Acc: 75.870

Epoch 15: Validation loss decreased (0.528356 --> 0.526340).  Saving model ...
	 Train_Loss: 0.5420 Train_Acc: 74.455 Val_Loss: 0.5263  BEST VAL Loss: 0.5263  Val_Acc: 76.146

Epoch 16: Validation loss decreased (0.526340 --> 0.524219).  Saving model ...
	 Train_Loss: 0.5400 Train_Acc: 74.702 Val_Loss: 0.5242  BEST VAL Loss: 0.5242  Val_Acc: 75.994

Epoch 17: Validation loss decreased (0.524219 --> 0.522355).  Saving model ...
	 Train_Loss: 0.5381 Train_Acc: 74.710 Val_Loss: 0.5224  BEST VAL Loss: 0.5224  Val_Acc: 76.021

Epoch 18: Validation loss decreased (0.522355 --> 0.520496).  Saving model ...
	 Train_Loss: 0.5364 Train_Acc: 74.850 Val_Loss: 0.5205  BEST VAL Loss: 0.5205  Val_Acc: 76.496

Epoch 19: Validation loss decreased (0.520496 --> 0.518753).  Saving model ...
	 Train_Loss: 0.5347 Train_Acc: 74.948 Val_Loss: 0.5188  BEST VAL Loss: 0.5188  Val_Acc: 76.839

Epoch 20: Validation loss decreased (0.518753 --> 0.517138).  Saving model ...
	 Train_Loss: 0.5333 Train_Acc: 74.888 Val_Loss: 0.5171  BEST VAL Loss: 0.5171  Val_Acc: 77.150

Epoch 21: Validation loss decreased (0.517138 --> 0.515768).  Saving model ...
	 Train_Loss: 0.5319 Train_Acc: 74.973 Val_Loss: 0.5158  BEST VAL Loss: 0.5158  Val_Acc: 76.718

Epoch 22: Validation loss decreased (0.515768 --> 0.514640).  Saving model ...
	 Train_Loss: 0.5307 Train_Acc: 75.066 Val_Loss: 0.5146  BEST VAL Loss: 0.5146  Val_Acc: 76.601

Epoch 23: Validation loss decreased (0.514640 --> 0.513538).  Saving model ...
	 Train_Loss: 0.5295 Train_Acc: 75.125 Val_Loss: 0.5135  BEST VAL Loss: 0.5135  Val_Acc: 76.846

Epoch 24: Validation loss decreased (0.513538 --> 0.512433).  Saving model ...
	 Train_Loss: 0.5283 Train_Acc: 75.223 Val_Loss: 0.5124  BEST VAL Loss: 0.5124  Val_Acc: 76.699

Epoch 25: Validation loss decreased (0.512433 --> 0.511519).  Saving model ...
	 Train_Loss: 0.5272 Train_Acc: 75.232 Val_Loss: 0.5115  BEST VAL Loss: 0.5115  Val_Acc: 76.337

Epoch 26: Validation loss decreased (0.511519 --> 0.510416).  Saving model ...
	 Train_Loss: 0.5262 Train_Acc: 75.149 Val_Loss: 0.5104  BEST VAL Loss: 0.5104  Val_Acc: 77.204

Epoch 27: Validation loss decreased (0.510416 --> 0.509631).  Saving model ...
	 Train_Loss: 0.5252 Train_Acc: 75.299 Val_Loss: 0.5096  BEST VAL Loss: 0.5096  Val_Acc: 76.990

Epoch 28: Validation loss decreased (0.509631 --> 0.508787).  Saving model ...
	 Train_Loss: 0.5243 Train_Acc: 75.435 Val_Loss: 0.5088  BEST VAL Loss: 0.5088  Val_Acc: 76.769

Epoch 29: Validation loss decreased (0.508787 --> 0.507974).  Saving model ...
	 Train_Loss: 0.5234 Train_Acc: 75.357 Val_Loss: 0.5080  BEST VAL Loss: 0.5080  Val_Acc: 76.819

Epoch 30: Validation loss decreased (0.507974 --> 0.507066).  Saving model ...
	 Train_Loss: 0.5226 Train_Acc: 75.411 Val_Loss: 0.5071  BEST VAL Loss: 0.5071  Val_Acc: 77.138

Epoch 31: Validation loss decreased (0.507066 --> 0.506319).  Saving model ...
	 Train_Loss: 0.5217 Train_Acc: 75.458 Val_Loss: 0.5063  BEST VAL Loss: 0.5063  Val_Acc: 76.706

Epoch 32: Validation loss decreased (0.506319 --> 0.505501).  Saving model ...
	 Train_Loss: 0.5210 Train_Acc: 75.373 Val_Loss: 0.5055  BEST VAL Loss: 0.5055  Val_Acc: 77.022

Epoch 33: Validation loss decreased (0.505501 --> 0.504806).  Saving model ...
	 Train_Loss: 0.5202 Train_Acc: 75.432 Val_Loss: 0.5048  BEST VAL Loss: 0.5048  Val_Acc: 76.987

Epoch 34: Validation loss decreased (0.504806 --> 0.504068).  Saving model ...
	 Train_Loss: 0.5195 Train_Acc: 75.473 Val_Loss: 0.5041  BEST VAL Loss: 0.5041  Val_Acc: 77.033

Epoch 35: Validation loss decreased (0.504068 --> 0.503709).  Saving model ...
	 Train_Loss: 0.5189 Train_Acc: 75.496 Val_Loss: 0.5037  BEST VAL Loss: 0.5037  Val_Acc: 76.477

Epoch 36: Validation loss decreased (0.503709 --> 0.503104).  Saving model ...
	 Train_Loss: 0.5182 Train_Acc: 75.461 Val_Loss: 0.5031  BEST VAL Loss: 0.5031  Val_Acc: 77.022

Epoch 37: Validation loss decreased (0.503104 --> 0.502431).  Saving model ...
	 Train_Loss: 0.5176 Train_Acc: 75.520 Val_Loss: 0.5024  BEST VAL Loss: 0.5024  Val_Acc: 77.426

Epoch 38: Validation loss decreased (0.502431 --> 0.501917).  Saving model ...
	 Train_Loss: 0.5170 Train_Acc: 75.664 Val_Loss: 0.5019  BEST VAL Loss: 0.5019  Val_Acc: 77.516

Epoch 39: Validation loss decreased (0.501917 --> 0.501203).  Saving model ...
	 Train_Loss: 0.5164 Train_Acc: 75.604 Val_Loss: 0.5012  BEST VAL Loss: 0.5012  Val_Acc: 77.714

Epoch 40: Validation loss decreased (0.501203 --> 0.500551).  Saving model ...
	 Train_Loss: 0.5158 Train_Acc: 75.669 Val_Loss: 0.5006  BEST VAL Loss: 0.5006  Val_Acc: 77.504

Epoch 41: Validation loss decreased (0.500551 --> 0.499979).  Saving model ...
	 Train_Loss: 0.5153 Train_Acc: 75.658 Val_Loss: 0.5000  BEST VAL Loss: 0.5000  Val_Acc: 77.430

Epoch 42: Validation loss decreased (0.499979 --> 0.499481).  Saving model ...
	 Train_Loss: 0.5147 Train_Acc: 75.636 Val_Loss: 0.4995  BEST VAL Loss: 0.4995  Val_Acc: 77.329

Epoch 43: Validation loss decreased (0.499481 --> 0.498948).  Saving model ...
	 Train_Loss: 0.5142 Train_Acc: 75.800 Val_Loss: 0.4989  BEST VAL Loss: 0.4989  Val_Acc: 77.321

Epoch 44: Validation loss decreased (0.498948 --> 0.498479).  Saving model ...
	 Train_Loss: 0.5137 Train_Acc: 75.821 Val_Loss: 0.4985  BEST VAL Loss: 0.4985  Val_Acc: 77.329

Epoch 45: Validation loss decreased (0.498479 --> 0.498076).  Saving model ...
	 Train_Loss: 0.5132 Train_Acc: 75.776 Val_Loss: 0.4981  BEST VAL Loss: 0.4981  Val_Acc: 77.294

Epoch 46: Validation loss decreased (0.498076 --> 0.497653).  Saving model ...
	 Train_Loss: 0.5127 Train_Acc: 75.759 Val_Loss: 0.4977  BEST VAL Loss: 0.4977  Val_Acc: 77.827

Epoch 47: Validation loss decreased (0.497653 --> 0.497234).  Saving model ...
	 Train_Loss: 0.5123 Train_Acc: 75.732 Val_Loss: 0.4972  BEST VAL Loss: 0.4972  Val_Acc: 77.963

Epoch 48: Validation loss decreased (0.497234 --> 0.496777).  Saving model ...
	 Train_Loss: 0.5119 Train_Acc: 75.737 Val_Loss: 0.4968  BEST VAL Loss: 0.4968  Val_Acc: 77.286

Epoch 49: Validation loss decreased (0.496777 --> 0.496348).  Saving model ...
	 Train_Loss: 0.5115 Train_Acc: 75.793 Val_Loss: 0.4963  BEST VAL Loss: 0.4963  Val_Acc: 77.827

Epoch 50: Validation loss decreased (0.496348 --> 0.495915).  Saving model ...
	 Train_Loss: 0.5111 Train_Acc: 75.751 Val_Loss: 0.4959  BEST VAL Loss: 0.4959  Val_Acc: 77.804

Epoch 51: Validation loss decreased (0.495915 --> 0.495592).  Saving model ...
	 Train_Loss: 0.5107 Train_Acc: 75.832 Val_Loss: 0.4956  BEST VAL Loss: 0.4956  Val_Acc: 77.173

Epoch 52: Validation loss decreased (0.495592 --> 0.495182).  Saving model ...
	 Train_Loss: 0.5103 Train_Acc: 75.795 Val_Loss: 0.4952  BEST VAL Loss: 0.4952  Val_Acc: 77.586

Epoch 53: Validation loss decreased (0.495182 --> 0.494828).  Saving model ...
	 Train_Loss: 0.5099 Train_Acc: 75.848 Val_Loss: 0.4948  BEST VAL Loss: 0.4948  Val_Acc: 77.520

Epoch 54: Validation loss decreased (0.494828 --> 0.494787).  Saving model ...
	 Train_Loss: 0.5095 Train_Acc: 75.860 Val_Loss: 0.4948  BEST VAL Loss: 0.4948  Val_Acc: 76.504

Epoch 55: Validation loss decreased (0.494787 --> 0.494403).  Saving model ...
	 Train_Loss: 0.5092 Train_Acc: 75.910 Val_Loss: 0.4944  BEST VAL Loss: 0.4944  Val_Acc: 77.710

Epoch 56: Validation loss decreased (0.494403 --> 0.494002).  Saving model ...
	 Train_Loss: 0.5088 Train_Acc: 75.786 Val_Loss: 0.4940  BEST VAL Loss: 0.4940  Val_Acc: 77.613

Epoch 57: Validation loss decreased (0.494002 --> 0.493650).  Saving model ...
	 Train_Loss: 0.5085 Train_Acc: 75.924 Val_Loss: 0.4936  BEST VAL Loss: 0.4936  Val_Acc: 77.815

Epoch 58: Validation loss decreased (0.493650 --> 0.493337).  Saving model ...
	 Train_Loss: 0.5081 Train_Acc: 75.898 Val_Loss: 0.4933  BEST VAL Loss: 0.4933  Val_Acc: 77.882

Epoch 59: Validation loss decreased (0.493337 --> 0.493057).  Saving model ...
	 Train_Loss: 0.5078 Train_Acc: 75.863 Val_Loss: 0.4931  BEST VAL Loss: 0.4931  Val_Acc: 77.434

Epoch 60: Validation loss decreased (0.493057 --> 0.492666).  Saving model ...
	 Train_Loss: 0.5075 Train_Acc: 76.015 Val_Loss: 0.4927  BEST VAL Loss: 0.4927  Val_Acc: 78.162

Epoch 61: Validation loss decreased (0.492666 --> 0.492427).  Saving model ...
	 Train_Loss: 0.5072 Train_Acc: 75.964 Val_Loss: 0.4924  BEST VAL Loss: 0.4924  Val_Acc: 77.547

Epoch 62: Validation loss decreased (0.492427 --> 0.492180).  Saving model ...
	 Train_Loss: 0.5069 Train_Acc: 75.904 Val_Loss: 0.4922  BEST VAL Loss: 0.4922  Val_Acc: 77.815

Epoch 63: Validation loss decreased (0.492180 --> 0.491842).  Saving model ...
	 Train_Loss: 0.5066 Train_Acc: 75.982 Val_Loss: 0.4918  BEST VAL Loss: 0.4918  Val_Acc: 78.092

Epoch 64: Validation loss decreased (0.491842 --> 0.491621).  Saving model ...
	 Train_Loss: 0.5063 Train_Acc: 76.049 Val_Loss: 0.4916  BEST VAL Loss: 0.4916  Val_Acc: 76.998

Epoch 65: Validation loss decreased (0.491621 --> 0.491304).  Saving model ...
	 Train_Loss: 0.5061 Train_Acc: 75.931 Val_Loss: 0.4913  BEST VAL Loss: 0.4913  Val_Acc: 78.049

Epoch 66: Validation loss decreased (0.491304 --> 0.490994).  Saving model ...
	 Train_Loss: 0.5058 Train_Acc: 76.043 Val_Loss: 0.4910  BEST VAL Loss: 0.4910  Val_Acc: 77.800

Epoch 67: Validation loss decreased (0.490994 --> 0.490776).  Saving model ...
	 Train_Loss: 0.5055 Train_Acc: 75.929 Val_Loss: 0.4908  BEST VAL Loss: 0.4908  Val_Acc: 77.477

Epoch 68: Validation loss decreased (0.490776 --> 0.490520).  Saving model ...
	 Train_Loss: 0.5052 Train_Acc: 76.060 Val_Loss: 0.4905  BEST VAL Loss: 0.4905  Val_Acc: 77.819

Epoch 69: Validation loss decreased (0.490520 --> 0.490273).  Saving model ...
	 Train_Loss: 0.5050 Train_Acc: 76.093 Val_Loss: 0.4903  BEST VAL Loss: 0.4903  Val_Acc: 77.823

Epoch 70: Validation loss decreased (0.490273 --> 0.490058).  Saving model ...
	 Train_Loss: 0.5047 Train_Acc: 75.977 Val_Loss: 0.4901  BEST VAL Loss: 0.4901  Val_Acc: 77.893

Epoch 71: Validation loss decreased (0.490058 --> 0.489776).  Saving model ...
	 Train_Loss: 0.5045 Train_Acc: 76.173 Val_Loss: 0.4898  BEST VAL Loss: 0.4898  Val_Acc: 77.998

Epoch 72: Validation loss decreased (0.489776 --> 0.489608).  Saving model ...
	 Train_Loss: 0.5042 Train_Acc: 75.918 Val_Loss: 0.4896  BEST VAL Loss: 0.4896  Val_Acc: 77.574

Epoch 73: Validation loss decreased (0.489608 --> 0.489373).  Saving model ...
	 Train_Loss: 0.5040 Train_Acc: 76.079 Val_Loss: 0.4894  BEST VAL Loss: 0.4894  Val_Acc: 77.348

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.5038 Train_Acc: 76.063 Val_Loss: 0.4895  BEST VAL Loss: 0.4894  Val_Acc: 77.033

Epoch 75: Validation loss decreased (0.489373 --> 0.489277).  Saving model ...
	 Train_Loss: 0.5035 Train_Acc: 76.085 Val_Loss: 0.4893  BEST VAL Loss: 0.4893  Val_Acc: 77.920

Epoch 76: Validation loss decreased (0.489277 --> 0.489035).  Saving model ...
	 Train_Loss: 0.5033 Train_Acc: 76.200 Val_Loss: 0.4890  BEST VAL Loss: 0.4890  Val_Acc: 77.870

Epoch 77: Validation loss decreased (0.489035 --> 0.488762).  Saving model ...
	 Train_Loss: 0.5031 Train_Acc: 76.169 Val_Loss: 0.4888  BEST VAL Loss: 0.4888  Val_Acc: 78.045

Epoch 78: Validation loss decreased (0.488762 --> 0.488598).  Saving model ...
	 Train_Loss: 0.5029 Train_Acc: 76.095 Val_Loss: 0.4886  BEST VAL Loss: 0.4886  Val_Acc: 77.601

Epoch 79: Validation loss decreased (0.488598 --> 0.488445).  Saving model ...
	 Train_Loss: 0.5027 Train_Acc: 76.151 Val_Loss: 0.4884  BEST VAL Loss: 0.4884  Val_Acc: 77.341

Epoch 80: Validation loss decreased (0.488445 --> 0.488199).  Saving model ...
	 Train_Loss: 0.5024 Train_Acc: 76.166 Val_Loss: 0.4882  BEST VAL Loss: 0.4882  Val_Acc: 78.119

Epoch 81: Validation loss decreased (0.488199 --> 0.488024).  Saving model ...
	 Train_Loss: 0.5022 Train_Acc: 76.239 Val_Loss: 0.4880  BEST VAL Loss: 0.4880  Val_Acc: 77.520

Epoch 82: Validation loss decreased (0.488024 --> 0.487820).  Saving model ...
	 Train_Loss: 0.5020 Train_Acc: 76.233 Val_Loss: 0.4878  BEST VAL Loss: 0.4878  Val_Acc: 77.924

Epoch 83: Validation loss decreased (0.487820 --> 0.487655).  Saving model ...
	 Train_Loss: 0.5018 Train_Acc: 76.084 Val_Loss: 0.4877  BEST VAL Loss: 0.4877  Val_Acc: 78.154

Epoch 84: Validation loss decreased (0.487655 --> 0.487480).  Saving model ...
	 Train_Loss: 0.5016 Train_Acc: 76.154 Val_Loss: 0.4875  BEST VAL Loss: 0.4875  Val_Acc: 78.127

Epoch 85: Validation loss decreased (0.487480 --> 0.487305).  Saving model ...
	 Train_Loss: 0.5014 Train_Acc: 76.186 Val_Loss: 0.4873  BEST VAL Loss: 0.4873  Val_Acc: 78.251

Epoch 86: Validation loss decreased (0.487305 --> 0.487151).  Saving model ...
	 Train_Loss: 0.5012 Train_Acc: 76.221 Val_Loss: 0.4872  BEST VAL Loss: 0.4872  Val_Acc: 77.757

Epoch 87: Validation loss decreased (0.487151 --> 0.487060).  Saving model ...
	 Train_Loss: 0.5010 Train_Acc: 76.277 Val_Loss: 0.4871  BEST VAL Loss: 0.4871  Val_Acc: 77.578

Epoch 88: Validation loss decreased (0.487060 --> 0.486933).  Saving model ...
	 Train_Loss: 0.5008 Train_Acc: 76.266 Val_Loss: 0.4869  BEST VAL Loss: 0.4869  Val_Acc: 77.481

Epoch 89: Validation loss decreased (0.486933 --> 0.486778).  Saving model ...
	 Train_Loss: 0.5007 Train_Acc: 76.144 Val_Loss: 0.4868  BEST VAL Loss: 0.4868  Val_Acc: 78.162

Epoch 90: Validation loss decreased (0.486778 --> 0.486578).  Saving model ...
	 Train_Loss: 0.5005 Train_Acc: 76.191 Val_Loss: 0.4866  BEST VAL Loss: 0.4866  Val_Acc: 78.376

Epoch 91: Validation loss decreased (0.486578 --> 0.486396).  Saving model ...
	 Train_Loss: 0.5003 Train_Acc: 76.156 Val_Loss: 0.4864  BEST VAL Loss: 0.4864  Val_Acc: 77.858

Epoch 92: Validation loss decreased (0.486396 --> 0.486277).  Saving model ...
	 Train_Loss: 0.5001 Train_Acc: 76.148 Val_Loss: 0.4863  BEST VAL Loss: 0.4863  Val_Acc: 77.426

Epoch 93: Validation loss decreased (0.486277 --> 0.486076).  Saving model ...
	 Train_Loss: 0.5000 Train_Acc: 76.286 Val_Loss: 0.4861  BEST VAL Loss: 0.4861  Val_Acc: 78.173

Epoch 94: Validation loss decreased (0.486076 --> 0.485891).  Saving model ...
	 Train_Loss: 0.4998 Train_Acc: 76.209 Val_Loss: 0.4859  BEST VAL Loss: 0.4859  Val_Acc: 78.068

Epoch 95: Validation loss decreased (0.485891 --> 0.485696).  Saving model ...
	 Train_Loss: 0.4996 Train_Acc: 76.223 Val_Loss: 0.4857  BEST VAL Loss: 0.4857  Val_Acc: 78.092

Epoch 96: Validation loss decreased (0.485696 --> 0.485521).  Saving model ...
	 Train_Loss: 0.4995 Train_Acc: 76.140 Val_Loss: 0.4855  BEST VAL Loss: 0.4855  Val_Acc: 78.306

Epoch 97: Validation loss decreased (0.485521 --> 0.485418).  Saving model ...
	 Train_Loss: 0.4993 Train_Acc: 76.076 Val_Loss: 0.4854  BEST VAL Loss: 0.4854  Val_Acc: 77.936

Epoch 98: Validation loss decreased (0.485418 --> 0.485259).  Saving model ...
	 Train_Loss: 0.4992 Train_Acc: 76.142 Val_Loss: 0.4853  BEST VAL Loss: 0.4853  Val_Acc: 77.928

Epoch 99: Validation loss decreased (0.485259 --> 0.485103).  Saving model ...
	 Train_Loss: 0.4990 Train_Acc: 76.251 Val_Loss: 0.4851  BEST VAL Loss: 0.4851  Val_Acc: 77.835

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.83      0.73      0.77    100339
           1       0.77      0.86      0.81    105242

    accuracy                           0.79    205581
   macro avg       0.80      0.79      0.79    205581
weighted avg       0.80      0.79      0.79    205581

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.81      0.71      0.76     12543
           1       0.75      0.84      0.80     13155

    accuracy                           0.78     25698
   macro avg       0.78      0.78      0.78     25698
weighted avg       0.78      0.78      0.78     25698

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.81      0.72      0.76     12543
           1       0.76      0.84      0.80     13155

    accuracy                           0.78     25698
   macro avg       0.78      0.78      0.78     25698
weighted avg       0.78      0.78      0.78     25698

              precision    recall  f1-score   support

           0       0.81      0.72      0.76     12543
           1       0.76      0.84      0.80     13155

    accuracy                           0.78     25698
   macro avg       0.78      0.78      0.78     25698
weighted avg       0.78      0.78      0.78     25698

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.55      0.39      0.46     40588
           1       0.60      0.74      0.66     49614

    accuracy                           0.58     90202
   macro avg       0.58      0.57      0.56     90202
weighted avg       0.58      0.58      0.57     90202

              precision    recall  f1-score   support

           0       0.55      0.39      0.46     40588
           1       0.60      0.74      0.66     49614

    accuracy                           0.58     90202
   macro avg       0.58      0.57      0.56     90202
weighted avg       0.58      0.58      0.57     90202

completed
