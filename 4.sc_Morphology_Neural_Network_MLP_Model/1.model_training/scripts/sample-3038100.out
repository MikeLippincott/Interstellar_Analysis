[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '951b6b3a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '62de7c51'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '9c57eec4'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'f2f58900'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_1.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_Nigericin_1.000_10.0_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (30211, 1276)
Number of total missing values across all columns: 31618
Data Subset Is Off
Wells held out for testing: ['M16' 'M22']
Wells to use for training, validation, and testing ['M17' 'M18' 'M19' 'M20' 'M21' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.350899).  Saving model ...
	 Train_Loss: 0.5356 Train_Acc: 73.632 Val_Loss: 0.3509  BEST VAL Loss: 0.3509  Val_Acc: 83.841

Epoch 1: Validation loss decreased (0.350899 --> 0.307591).  Saving model ...
	 Train_Loss: 0.4663 Train_Acc: 81.824 Val_Loss: 0.3076  BEST VAL Loss: 0.3076  Val_Acc: 87.287

Epoch 2: Validation loss decreased (0.307591 --> 0.285767).  Saving model ...
	 Train_Loss: 0.4263 Train_Acc: 83.654 Val_Loss: 0.2858  BEST VAL Loss: 0.2858  Val_Acc: 89.526

Epoch 3: Validation loss decreased (0.285767 --> 0.265424).  Saving model ...
	 Train_Loss: 0.3970 Train_Acc: 86.105 Val_Loss: 0.2654  BEST VAL Loss: 0.2654  Val_Acc: 90.824

Epoch 4: Validation loss decreased (0.265424 --> 0.251298).  Saving model ...
	 Train_Loss: 0.3746 Train_Acc: 87.174 Val_Loss: 0.2513  BEST VAL Loss: 0.2513  Val_Acc: 91.092

Epoch 5: Validation loss decreased (0.251298 --> 0.238751).  Saving model ...
	 Train_Loss: 0.3581 Train_Acc: 87.689 Val_Loss: 0.2388  BEST VAL Loss: 0.2388  Val_Acc: 93.599

Epoch 6: Validation loss decreased (0.238751 --> 0.231028).  Saving model ...
	 Train_Loss: 0.3463 Train_Acc: 87.834 Val_Loss: 0.2310  BEST VAL Loss: 0.2310  Val_Acc: 92.211

Epoch 7: Validation loss decreased (0.231028 --> 0.222635).  Saving model ...
	 Train_Loss: 0.3360 Train_Acc: 88.450 Val_Loss: 0.2226  BEST VAL Loss: 0.2226  Val_Acc: 93.151

Epoch 8: Validation loss decreased (0.222635 --> 0.216222).  Saving model ...
	 Train_Loss: 0.3280 Train_Acc: 88.651 Val_Loss: 0.2162  BEST VAL Loss: 0.2162  Val_Acc: 93.286

Epoch 9: Validation loss decreased (0.216222 --> 0.209293).  Saving model ...
	 Train_Loss: 0.3193 Train_Acc: 89.759 Val_Loss: 0.2093  BEST VAL Loss: 0.2093  Val_Acc: 94.002

Epoch 10: Validation loss decreased (0.209293 --> 0.203890).  Saving model ...
	 Train_Loss: 0.3122 Train_Acc: 89.608 Val_Loss: 0.2039  BEST VAL Loss: 0.2039  Val_Acc: 93.688

Epoch 11: Validation loss decreased (0.203890 --> 0.199246).  Saving model ...
	 Train_Loss: 0.3049 Train_Acc: 91.058 Val_Loss: 0.1992  BEST VAL Loss: 0.1992  Val_Acc: 93.778

Epoch 12: Validation loss decreased (0.199246 --> 0.194405).  Saving model ...
	 Train_Loss: 0.2985 Train_Acc: 91.393 Val_Loss: 0.1944  BEST VAL Loss: 0.1944  Val_Acc: 94.584

Epoch 13: Validation loss decreased (0.194405 --> 0.189943).  Saving model ...
	 Train_Loss: 0.2929 Train_Acc: 91.550 Val_Loss: 0.1899  BEST VAL Loss: 0.1899  Val_Acc: 94.539

Epoch 14: Validation loss decreased (0.189943 --> 0.186879).  Saving model ...
	 Train_Loss: 0.2878 Train_Acc: 91.405 Val_Loss: 0.1869  BEST VAL Loss: 0.1869  Val_Acc: 94.315

Epoch 15: Validation loss decreased (0.186879 --> 0.183616).  Saving model ...
	 Train_Loss: 0.2829 Train_Acc: 92.255 Val_Loss: 0.1836  BEST VAL Loss: 0.1836  Val_Acc: 93.778

Epoch 16: Validation loss decreased (0.183616 --> 0.181493).  Saving model ...
	 Train_Loss: 0.2780 Train_Acc: 92.043 Val_Loss: 0.1815  BEST VAL Loss: 0.1815  Val_Acc: 94.270

Epoch 17: Validation loss decreased (0.181493 --> 0.179439).  Saving model ...
	 Train_Loss: 0.2740 Train_Acc: 92.311 Val_Loss: 0.1794  BEST VAL Loss: 0.1794  Val_Acc: 94.315

Epoch 18: Validation loss decreased (0.179439 --> 0.178347).  Saving model ...
	 Train_Loss: 0.2699 Train_Acc: 92.541 Val_Loss: 0.1783  BEST VAL Loss: 0.1783  Val_Acc: 94.181

Epoch 19: Validation loss decreased (0.178347 --> 0.176811).  Saving model ...
	 Train_Loss: 0.2662 Train_Acc: 92.507 Val_Loss: 0.1768  BEST VAL Loss: 0.1768  Val_Acc: 94.315

Epoch 20: Validation loss decreased (0.176811 --> 0.176158).  Saving model ...
	 Train_Loss: 0.2627 Train_Acc: 92.960 Val_Loss: 0.1762  BEST VAL Loss: 0.1762  Val_Acc: 94.091

Epoch 21: Validation loss decreased (0.176158 --> 0.174342).  Saving model ...
	 Train_Loss: 0.2595 Train_Acc: 93.050 Val_Loss: 0.1743  BEST VAL Loss: 0.1743  Val_Acc: 95.076

Epoch 22: Validation loss decreased (0.174342 --> 0.173003).  Saving model ...
	 Train_Loss: 0.2566 Train_Acc: 92.999 Val_Loss: 0.1730  BEST VAL Loss: 0.1730  Val_Acc: 94.539

Epoch 23: Validation loss decreased (0.173003 --> 0.171247).  Saving model ...
	 Train_Loss: 0.2537 Train_Acc: 93.324 Val_Loss: 0.1712  BEST VAL Loss: 0.1712  Val_Acc: 94.942

Epoch 24: Validation loss decreased (0.171247 --> 0.169344).  Saving model ...
	 Train_Loss: 0.2511 Train_Acc: 93.229 Val_Loss: 0.1693  BEST VAL Loss: 0.1693  Val_Acc: 95.389

Epoch 25: Validation loss decreased (0.169344 --> 0.167830).  Saving model ...
	 Train_Loss: 0.2489 Train_Acc: 92.921 Val_Loss: 0.1678  BEST VAL Loss: 0.1678  Val_Acc: 94.270

Epoch 26: Validation loss decreased (0.167830 --> 0.166020).  Saving model ...
	 Train_Loss: 0.2462 Train_Acc: 93.497 Val_Loss: 0.1660  BEST VAL Loss: 0.1660  Val_Acc: 95.255

Epoch 27: Validation loss decreased (0.166020 --> 0.163984).  Saving model ...
	 Train_Loss: 0.2436 Train_Acc: 93.800 Val_Loss: 0.1640  BEST VAL Loss: 0.1640  Val_Acc: 95.658

Epoch 28: Validation loss decreased (0.163984 --> 0.162489).  Saving model ...
	 Train_Loss: 0.2409 Train_Acc: 94.169 Val_Loss: 0.1625  BEST VAL Loss: 0.1625  Val_Acc: 95.882

Epoch 29: Validation loss decreased (0.162489 --> 0.160739).  Saving model ...
	 Train_Loss: 0.2388 Train_Acc: 93.811 Val_Loss: 0.1607  BEST VAL Loss: 0.1607  Val_Acc: 95.613

Epoch 30: Validation loss decreased (0.160739 --> 0.159184).  Saving model ...
	 Train_Loss: 0.2367 Train_Acc: 93.788 Val_Loss: 0.1592  BEST VAL Loss: 0.1592  Val_Acc: 95.166

Epoch 31: Validation loss decreased (0.159184 --> 0.158185).  Saving model ...
	 Train_Loss: 0.2346 Train_Acc: 94.253 Val_Loss: 0.1582  BEST VAL Loss: 0.1582  Val_Acc: 95.389

Epoch 32: Validation loss decreased (0.158185 --> 0.156838).  Saving model ...
	 Train_Loss: 0.2328 Train_Acc: 93.928 Val_Loss: 0.1568  BEST VAL Loss: 0.1568  Val_Acc: 95.389

Epoch 33: Validation loss decreased (0.156838 --> 0.155813).  Saving model ...
	 Train_Loss: 0.2306 Train_Acc: 94.359 Val_Loss: 0.1558  BEST VAL Loss: 0.1558  Val_Acc: 95.971

Epoch 34: Validation loss decreased (0.155813 --> 0.155151).  Saving model ...
	 Train_Loss: 0.2289 Train_Acc: 93.637 Val_Loss: 0.1552  BEST VAL Loss: 0.1552  Val_Acc: 95.121

Epoch 35: Validation loss decreased (0.155151 --> 0.154268).  Saving model ...
	 Train_Loss: 0.2273 Train_Acc: 93.895 Val_Loss: 0.1543  BEST VAL Loss: 0.1543  Val_Acc: 94.897

Epoch 36: Validation loss decreased (0.154268 --> 0.153977).  Saving model ...
	 Train_Loss: 0.2259 Train_Acc: 93.783 Val_Loss: 0.1540  BEST VAL Loss: 0.1540  Val_Acc: 95.345

Epoch 37: Validation loss decreased (0.153977 --> 0.153629).  Saving model ...
	 Train_Loss: 0.2244 Train_Acc: 93.861 Val_Loss: 0.1536  BEST VAL Loss: 0.1536  Val_Acc: 95.479

Epoch 38: Validation loss decreased (0.153629 --> 0.153252).  Saving model ...
	 Train_Loss: 0.2231 Train_Acc: 94.068 Val_Loss: 0.1533  BEST VAL Loss: 0.1533  Val_Acc: 95.345

Epoch 39: Validation loss decreased (0.153252 --> 0.153223).  Saving model ...
	 Train_Loss: 0.2222 Train_Acc: 93.766 Val_Loss: 0.1532  BEST VAL Loss: 0.1532  Val_Acc: 95.434

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.2215 Train_Acc: 93.464 Val_Loss: 0.1532  BEST VAL Loss: 0.1532  Val_Acc: 95.345

Epoch 41: Validation loss decreased (0.153223 --> 0.152802).  Saving model ...
	 Train_Loss: 0.2207 Train_Acc: 93.201 Val_Loss: 0.1528  BEST VAL Loss: 0.1528  Val_Acc: 95.434

Epoch 42: Validation loss decreased (0.152802 --> 0.152380).  Saving model ...
	 Train_Loss: 0.2197 Train_Acc: 93.861 Val_Loss: 0.1524  BEST VAL Loss: 0.1524  Val_Acc: 95.792

Epoch 43: Validation loss decreased (0.152380 --> 0.151680).  Saving model ...
	 Train_Loss: 0.2186 Train_Acc: 93.973 Val_Loss: 0.1517  BEST VAL Loss: 0.1517  Val_Acc: 96.061

Epoch 44: Validation loss decreased (0.151680 --> 0.150998).  Saving model ...
	 Train_Loss: 0.2176 Train_Acc: 93.833 Val_Loss: 0.1510  BEST VAL Loss: 0.1510  Val_Acc: 95.524

Epoch 45: Validation loss decreased (0.150998 --> 0.150283).  Saving model ...
	 Train_Loss: 0.2163 Train_Acc: 94.466 Val_Loss: 0.1503  BEST VAL Loss: 0.1503  Val_Acc: 95.837

Epoch 46: Validation loss decreased (0.150283 --> 0.149558).  Saving model ...
	 Train_Loss: 0.2149 Train_Acc: 94.751 Val_Loss: 0.1496  BEST VAL Loss: 0.1496  Val_Acc: 95.882

Epoch 47: Validation loss decreased (0.149558 --> 0.148898).  Saving model ...
	 Train_Loss: 0.2138 Train_Acc: 94.292 Val_Loss: 0.1489  BEST VAL Loss: 0.1489  Val_Acc: 95.345

Epoch 48: Validation loss decreased (0.148898 --> 0.148122).  Saving model ...
	 Train_Loss: 0.2128 Train_Acc: 94.253 Val_Loss: 0.1481  BEST VAL Loss: 0.1481  Val_Acc: 95.613

Epoch 49: Validation loss decreased (0.148122 --> 0.147570).  Saving model ...
	 Train_Loss: 0.2117 Train_Acc: 94.516 Val_Loss: 0.1476  BEST VAL Loss: 0.1476  Val_Acc: 95.658

Epoch 50: Validation loss decreased (0.147570 --> 0.147207).  Saving model ...
	 Train_Loss: 0.2105 Train_Acc: 94.650 Val_Loss: 0.1472  BEST VAL Loss: 0.1472  Val_Acc: 95.479

Epoch 51: Validation loss decreased (0.147207 --> 0.146925).  Saving model ...
	 Train_Loss: 0.2093 Train_Acc: 94.868 Val_Loss: 0.1469  BEST VAL Loss: 0.1469  Val_Acc: 95.748

Epoch 52: Validation loss decreased (0.146925 --> 0.146521).  Saving model ...
	 Train_Loss: 0.2083 Train_Acc: 94.572 Val_Loss: 0.1465  BEST VAL Loss: 0.1465  Val_Acc: 95.345

Epoch 53: Validation loss decreased (0.146521 --> 0.146326).  Saving model ...
	 Train_Loss: 0.2074 Train_Acc: 94.768 Val_Loss: 0.1463  BEST VAL Loss: 0.1463  Val_Acc: 95.837

Epoch 54: Validation loss decreased (0.146326 --> 0.145700).  Saving model ...
	 Train_Loss: 0.2064 Train_Acc: 94.605 Val_Loss: 0.1457  BEST VAL Loss: 0.1457  Val_Acc: 95.837

Epoch 55: Validation loss decreased (0.145700 --> 0.145116).  Saving model ...
	 Train_Loss: 0.2055 Train_Acc: 94.639 Val_Loss: 0.1451  BEST VAL Loss: 0.1451  Val_Acc: 95.568

Epoch 56: Validation loss decreased (0.145116 --> 0.144436).  Saving model ...
	 Train_Loss: 0.2045 Train_Acc: 94.622 Val_Loss: 0.1444  BEST VAL Loss: 0.1444  Val_Acc: 95.927

Epoch 57: Validation loss decreased (0.144436 --> 0.144035).  Saving model ...
	 Train_Loss: 0.2036 Train_Acc: 94.936 Val_Loss: 0.1440  BEST VAL Loss: 0.1440  Val_Acc: 95.927

Epoch 58: Validation loss decreased (0.144035 --> 0.143678).  Saving model ...
	 Train_Loss: 0.2026 Train_Acc: 95.159 Val_Loss: 0.1437  BEST VAL Loss: 0.1437  Val_Acc: 96.374

Epoch 59: Validation loss decreased (0.143678 --> 0.143450).  Saving model ...
	 Train_Loss: 0.2017 Train_Acc: 95.020 Val_Loss: 0.1435  BEST VAL Loss: 0.1435  Val_Acc: 96.106

Epoch 60: Validation loss decreased (0.143450 --> 0.143184).  Saving model ...
	 Train_Loss: 0.2007 Train_Acc: 95.238 Val_Loss: 0.1432  BEST VAL Loss: 0.1432  Val_Acc: 95.524

Epoch 61: Validation loss decreased (0.143184 --> 0.143107).  Saving model ...
	 Train_Loss: 0.1998 Train_Acc: 95.266 Val_Loss: 0.1431  BEST VAL Loss: 0.1431  Val_Acc: 95.703

Epoch 62: Validation loss decreased (0.143107 --> 0.142593).  Saving model ...
	 Train_Loss: 0.1990 Train_Acc: 94.801 Val_Loss: 0.1426  BEST VAL Loss: 0.1426  Val_Acc: 96.509

Epoch 63: Validation loss decreased (0.142593 --> 0.142195).  Saving model ...
	 Train_Loss: 0.1982 Train_Acc: 94.975 Val_Loss: 0.1422  BEST VAL Loss: 0.1422  Val_Acc: 95.703

Epoch 64: Validation loss decreased (0.142195 --> 0.141704).  Saving model ...
	 Train_Loss: 0.1974 Train_Acc: 94.902 Val_Loss: 0.1417  BEST VAL Loss: 0.1417  Val_Acc: 96.464

Epoch 65: Validation loss decreased (0.141704 --> 0.141544).  Saving model ...
	 Train_Loss: 0.1966 Train_Acc: 95.064 Val_Loss: 0.1415  BEST VAL Loss: 0.1415  Val_Acc: 96.374

Epoch 66: Validation loss decreased (0.141544 --> 0.141248).  Saving model ...
	 Train_Loss: 0.1957 Train_Acc: 95.339 Val_Loss: 0.1412  BEST VAL Loss: 0.1412  Val_Acc: 96.329

Epoch 67: Validation loss decreased (0.141248 --> 0.140819).  Saving model ...
	 Train_Loss: 0.1950 Train_Acc: 95.064 Val_Loss: 0.1408  BEST VAL Loss: 0.1408  Val_Acc: 96.106

Epoch 68: Validation loss decreased (0.140819 --> 0.140287).  Saving model ...
	 Train_Loss: 0.1943 Train_Acc: 94.936 Val_Loss: 0.1403  BEST VAL Loss: 0.1403  Val_Acc: 96.777

Epoch 69: Validation loss decreased (0.140287 --> 0.140007).  Saving model ...
	 Train_Loss: 0.1936 Train_Acc: 94.896 Val_Loss: 0.1400  BEST VAL Loss: 0.1400  Val_Acc: 96.240

Epoch 70: Validation loss decreased (0.140007 --> 0.139840).  Saving model ...
	 Train_Loss: 0.1929 Train_Acc: 95.171 Val_Loss: 0.1398  BEST VAL Loss: 0.1398  Val_Acc: 95.882

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.1921 Train_Acc: 95.176 Val_Loss: 0.1399  BEST VAL Loss: 0.1398  Val_Acc: 95.927

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.1914 Train_Acc: 95.540 Val_Loss: 0.1399  BEST VAL Loss: 0.1398  Val_Acc: 96.061

Epoch 73: Validation loss decreased (0.139840 --> 0.139614).  Saving model ...
	 Train_Loss: 0.1907 Train_Acc: 95.311 Val_Loss: 0.1396  BEST VAL Loss: 0.1396  Val_Acc: 96.285

Epoch 74: Validation loss decreased (0.139614 --> 0.139482).  Saving model ...
	 Train_Loss: 0.1900 Train_Acc: 95.199 Val_Loss: 0.1395  BEST VAL Loss: 0.1395  Val_Acc: 96.195

Epoch 75: Validation loss decreased (0.139482 --> 0.139205).  Saving model ...
	 Train_Loss: 0.1894 Train_Acc: 95.232 Val_Loss: 0.1392  BEST VAL Loss: 0.1392  Val_Acc: 96.419

Epoch 76: Validation loss decreased (0.139205 --> 0.139029).  Saving model ...
	 Train_Loss: 0.1887 Train_Acc: 95.238 Val_Loss: 0.1390  BEST VAL Loss: 0.1390  Val_Acc: 96.285

Epoch 77: Validation loss decreased (0.139029 --> 0.138859).  Saving model ...
	 Train_Loss: 0.1881 Train_Acc: 95.395 Val_Loss: 0.1389  BEST VAL Loss: 0.1389  Val_Acc: 96.285

Epoch 78: Validation loss decreased (0.138859 --> 0.138700).  Saving model ...
	 Train_Loss: 0.1874 Train_Acc: 95.355 Val_Loss: 0.1387  BEST VAL Loss: 0.1387  Val_Acc: 96.061

Epoch 79: Validation loss decreased (0.138700 --> 0.138426).  Saving model ...
	 Train_Loss: 0.1868 Train_Acc: 95.210 Val_Loss: 0.1384  BEST VAL Loss: 0.1384  Val_Acc: 96.106

Epoch 80: Validation loss decreased (0.138426 --> 0.138266).  Saving model ...
	 Train_Loss: 0.1862 Train_Acc: 95.456 Val_Loss: 0.1383  BEST VAL Loss: 0.1383  Val_Acc: 96.329

Epoch 81: Validation loss decreased (0.138266 --> 0.137925).  Saving model ...
	 Train_Loss: 0.1855 Train_Acc: 95.551 Val_Loss: 0.1379  BEST VAL Loss: 0.1379  Val_Acc: 95.748

Epoch 82: Validation loss decreased (0.137925 --> 0.137892).  Saving model ...
	 Train_Loss: 0.1848 Train_Acc: 95.635 Val_Loss: 0.1379  BEST VAL Loss: 0.1379  Val_Acc: 96.598

Epoch 83: Validation loss decreased (0.137892 --> 0.137743).  Saving model ...
	 Train_Loss: 0.1842 Train_Acc: 95.428 Val_Loss: 0.1377  BEST VAL Loss: 0.1377  Val_Acc: 96.061

Epoch 84: Validation loss decreased (0.137743 --> 0.137470).  Saving model ...
	 Train_Loss: 0.1837 Train_Acc: 95.641 Val_Loss: 0.1375  BEST VAL Loss: 0.1375  Val_Acc: 95.748

Epoch 85: Validation loss decreased (0.137470 --> 0.137363).  Saving model ...
	 Train_Loss: 0.1831 Train_Acc: 95.098 Val_Loss: 0.1374  BEST VAL Loss: 0.1374  Val_Acc: 96.106

Epoch 86: Validation loss decreased (0.137363 --> 0.137360).  Saving model ...
	 Train_Loss: 0.1825 Train_Acc: 95.534 Val_Loss: 0.1374  BEST VAL Loss: 0.1374  Val_Acc: 95.927

Epoch 87: Validation loss decreased (0.137360 --> 0.137071).  Saving model ...
	 Train_Loss: 0.1821 Train_Acc: 95.311 Val_Loss: 0.1371  BEST VAL Loss: 0.1371  Val_Acc: 96.061

Epoch 88: Validation loss decreased (0.137071 --> 0.136944).  Saving model ...
	 Train_Loss: 0.1815 Train_Acc: 95.456 Val_Loss: 0.1369  BEST VAL Loss: 0.1369  Val_Acc: 96.464

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.1810 Train_Acc: 95.271 Val_Loss: 0.1370  BEST VAL Loss: 0.1369  Val_Acc: 96.374

Epoch 90: Validation loss decreased (0.136944 --> 0.136796).  Saving model ...
	 Train_Loss: 0.1804 Train_Acc: 95.921 Val_Loss: 0.1368  BEST VAL Loss: 0.1368  Val_Acc: 96.150

Epoch 91: Validation loss decreased (0.136796 --> 0.136711).  Saving model ...
	 Train_Loss: 0.1799 Train_Acc: 95.518 Val_Loss: 0.1367  BEST VAL Loss: 0.1367  Val_Acc: 96.150

Epoch 92: Validation loss decreased (0.136711 --> 0.136600).  Saving model ...
	 Train_Loss: 0.1794 Train_Acc: 95.641 Val_Loss: 0.1366  BEST VAL Loss: 0.1366  Val_Acc: 96.195

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.1788 Train_Acc: 95.674 Val_Loss: 0.1367  BEST VAL Loss: 0.1366  Val_Acc: 96.016

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.1784 Train_Acc: 95.014 Val_Loss: 0.1368  BEST VAL Loss: 0.1366  Val_Acc: 95.792

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.1780 Train_Acc: 95.450 Val_Loss: 0.1368  BEST VAL Loss: 0.1366  Val_Acc: 95.927

Epoch 96: Validation loss did not decrease
	 Train_Loss: 0.1775 Train_Acc: 95.462 Val_Loss: 0.1366  BEST VAL Loss: 0.1366  Val_Acc: 96.285

Epoch 97: Validation loss decreased (0.136600 --> 0.136549).  Saving model ...
	 Train_Loss: 0.1771 Train_Acc: 95.557 Val_Loss: 0.1365  BEST VAL Loss: 0.1365  Val_Acc: 95.971

Epoch 98: Validation loss decreased (0.136549 --> 0.136359).  Saving model ...
	 Train_Loss: 0.1766 Train_Acc: 95.546 Val_Loss: 0.1364  BEST VAL Loss: 0.1364  Val_Acc: 96.509

Epoch 99: Validation loss decreased (0.136359 --> 0.136227).  Saving model ...
	 Train_Loss: 0.1762 Train_Acc: 95.512 Val_Loss: 0.1362  BEST VAL Loss: 0.1362  Val_Acc: 95.837

Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      0.99      0.99      9434
           1       0.99      0.99      0.99      8436

    accuracy                           0.99     17870
   macro avg       0.99      0.99      0.99     17870
weighted avg       0.99      0.99      0.99     17870

Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.96      0.97      0.96      1179
           1       0.96      0.95      0.96      1055

    accuracy                           0.96      2234
   macro avg       0.96      0.96      0.96      2234
weighted avg       0.96      0.96      0.96      2234

Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.95      0.97      0.96      1179
           1       0.97      0.94      0.95      1055

    accuracy                           0.96      2234
   macro avg       0.96      0.96      0.96      2234
weighted avg       0.96      0.96      0.96      2234

              precision    recall  f1-score   support

           0       0.95      0.97      0.96      1179
           1       0.97      0.94      0.95      1055

    accuracy                           0.96      2234
   macro avg       0.96      0.96      0.96      2234
weighted avg       0.96      0.96      0.96      2234

Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.94      0.97      0.95      4017
           1       0.96      0.93      0.95      3856

    accuracy                           0.95      7873
   macro avg       0.95      0.95      0.95      7873
weighted avg       0.95      0.95      0.95      7873

              precision    recall  f1-score   support

           0       0.94      0.97      0.95      4017
           1       0.96      0.93      0.95      3856

    accuracy                           0.95      7873
   macro avg       0.95      0.95      0.95      7873
weighted avg       0.95      0.95      0.95      7873

completed
