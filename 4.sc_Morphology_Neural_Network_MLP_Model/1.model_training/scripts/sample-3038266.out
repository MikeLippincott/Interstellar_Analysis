[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '6ebaac89'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'a2335b99'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '63b614e1'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'dd589950'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Thapsigargin_1.000_DMSO_0.025 treatment_name: LPS_10.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Thapsigargin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_10.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'Thapsigargin_1.000_DMSO_0.025']
The dimensions of the data are: (304946, 1270)
Number of total missing values across all columns: 609892
Data Subset Is Off
Wells held out for testing: ['E09' 'K06']
Wells to use for training, validation, and testing ['E02' 'E03' 'D06' 'D07' 'E08' 'K07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.500247).  Saving model ...
	 Train_Loss: 0.6197 Train_Acc: 64.779 Val_Loss: 0.5002  BEST VAL Loss: 0.5002  Val_Acc: 75.576

Epoch 1: Validation loss decreased (0.500247 --> 0.486849).  Saving model ...
	 Train_Loss: 0.5732 Train_Acc: 71.205 Val_Loss: 0.4868  BEST VAL Loss: 0.4868  Val_Acc: 76.765

Epoch 2: Validation loss decreased (0.486849 --> 0.481854).  Saving model ...
	 Train_Loss: 0.5542 Train_Acc: 71.586 Val_Loss: 0.4819  BEST VAL Loss: 0.4819  Val_Acc: 76.809

Epoch 3: Validation loss decreased (0.481854 --> 0.477759).  Saving model ...
	 Train_Loss: 0.5438 Train_Acc: 71.895 Val_Loss: 0.4778  BEST VAL Loss: 0.4778  Val_Acc: 77.324

Epoch 4: Validation loss decreased (0.477759 --> 0.477211).  Saving model ...
	 Train_Loss: 0.5366 Train_Acc: 72.108 Val_Loss: 0.4772  BEST VAL Loss: 0.4772  Val_Acc: 76.228

Epoch 5: Validation loss decreased (0.477211 --> 0.474736).  Saving model ...
	 Train_Loss: 0.5312 Train_Acc: 72.266 Val_Loss: 0.4747  BEST VAL Loss: 0.4747  Val_Acc: 77.147

Epoch 6: Validation loss decreased (0.474736 --> 0.472860).  Saving model ...
	 Train_Loss: 0.5268 Train_Acc: 72.428 Val_Loss: 0.4729  BEST VAL Loss: 0.4729  Val_Acc: 76.774

Epoch 7: Validation loss did not decrease
	 Train_Loss: 0.5235 Train_Acc: 72.302 Val_Loss: 0.4734  BEST VAL Loss: 0.4729  Val_Acc: 76.832

Epoch 8: Validation loss decreased (0.472860 --> 0.472560).  Saving model ...
	 Train_Loss: 0.5209 Train_Acc: 72.378 Val_Loss: 0.4726  BEST VAL Loss: 0.4726  Val_Acc: 77.320

Epoch 9: Validation loss decreased (0.472560 --> 0.471079).  Saving model ...
	 Train_Loss: 0.5188 Train_Acc: 72.372 Val_Loss: 0.4711  BEST VAL Loss: 0.4711  Val_Acc: 77.333

Epoch 10: Validation loss decreased (0.471079 --> 0.469698).  Saving model ...
	 Train_Loss: 0.5170 Train_Acc: 72.326 Val_Loss: 0.4697  BEST VAL Loss: 0.4697  Val_Acc: 77.222

Epoch 11: Validation loss decreased (0.469698 --> 0.468780).  Saving model ...
	 Train_Loss: 0.5153 Train_Acc: 72.429 Val_Loss: 0.4688  BEST VAL Loss: 0.4688  Val_Acc: 77.422

Epoch 12: Validation loss decreased (0.468780 --> 0.468554).  Saving model ...
	 Train_Loss: 0.5139 Train_Acc: 72.509 Val_Loss: 0.4686  BEST VAL Loss: 0.4686  Val_Acc: 77.746

Epoch 13: Validation loss decreased (0.468554 --> 0.467528).  Saving model ...
	 Train_Loss: 0.5127 Train_Acc: 72.346 Val_Loss: 0.4675  BEST VAL Loss: 0.4675  Val_Acc: 77.479

Epoch 14: Validation loss decreased (0.467528 --> 0.466574).  Saving model ...
	 Train_Loss: 0.5116 Train_Acc: 72.384 Val_Loss: 0.4666  BEST VAL Loss: 0.4666  Val_Acc: 77.382

Epoch 15: Validation loss did not decrease
	 Train_Loss: 0.5106 Train_Acc: 72.287 Val_Loss: 0.4666  BEST VAL Loss: 0.4666  Val_Acc: 77.045

Epoch 16: Validation loss did not decrease
	 Train_Loss: 0.5094 Train_Acc: 72.655 Val_Loss: 0.4676  BEST VAL Loss: 0.4666  Val_Acc: 76.588

Epoch 17: Validation loss did not decrease
	 Train_Loss: 0.5087 Train_Acc: 72.297 Val_Loss: 0.4672  BEST VAL Loss: 0.4666  Val_Acc: 77.209

Epoch 18: Validation loss did not decrease
	 Train_Loss: 0.5079 Train_Acc: 72.301 Val_Loss: 0.4671  BEST VAL Loss: 0.4666  Val_Acc: 77.262

Epoch 19: Validation loss decreased (0.466574 --> 0.466332).  Saving model ...
	 Train_Loss: 0.5071 Train_Acc: 72.626 Val_Loss: 0.4663  BEST VAL Loss: 0.4663  Val_Acc: 77.528

Epoch 20: Validation loss decreased (0.466332 --> 0.466266).  Saving model ...
	 Train_Loss: 0.5064 Train_Acc: 72.456 Val_Loss: 0.4663  BEST VAL Loss: 0.4663  Val_Acc: 77.235

Epoch 21: Validation loss decreased (0.466266 --> 0.466153).  Saving model ...
	 Train_Loss: 0.5059 Train_Acc: 72.350 Val_Loss: 0.4662  BEST VAL Loss: 0.4662  Val_Acc: 76.250

Epoch 22: Validation loss did not decrease
	 Train_Loss: 0.5053 Train_Acc: 72.553 Val_Loss: 0.4663  BEST VAL Loss: 0.4662  Val_Acc: 77.595

Epoch 23: Validation loss decreased (0.466153 --> 0.465925).  Saving model ...
	 Train_Loss: 0.5048 Train_Acc: 72.397 Val_Loss: 0.4659  BEST VAL Loss: 0.4659  Val_Acc: 76.818

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.5043 Train_Acc: 72.381 Val_Loss: 0.4661  BEST VAL Loss: 0.4659  Val_Acc: 76.978

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.5039 Train_Acc: 72.617 Val_Loss: 0.4688  BEST VAL Loss: 0.4659  Val_Acc: 76.814

Epoch 26: Validation loss did not decrease
	 Train_Loss: 0.5052 Train_Acc: 72.000 Val_Loss: 0.4683  BEST VAL Loss: 0.4659  Val_Acc: 77.493

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.5047 Train_Acc: 72.561 Val_Loss: 0.4682  BEST VAL Loss: 0.4659  Val_Acc: 76.583

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.5043 Train_Acc: 72.324 Val_Loss: 0.4678  BEST VAL Loss: 0.4659  Val_Acc: 76.836

Epoch 29: Validation loss did not decrease
	 Train_Loss: 0.5039 Train_Acc: 72.505 Val_Loss: 0.4678  BEST VAL Loss: 0.4659  Val_Acc: 76.508

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.5034 Train_Acc: 72.489 Val_Loss: 0.4673  BEST VAL Loss: 0.4659  Val_Acc: 77.053

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.5031 Train_Acc: 72.438 Val_Loss: 0.4668  BEST VAL Loss: 0.4659  Val_Acc: 77.320

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.5025 Train_Acc: 72.806 Val_Loss: 0.4664  BEST VAL Loss: 0.4659  Val_Acc: 77.457

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.5021 Train_Acc: 72.678 Val_Loss: 0.4663  BEST VAL Loss: 0.4659  Val_Acc: 76.991

Epoch 34: Validation loss decreased (0.465925 --> 0.465798).  Saving model ...
	 Train_Loss: 0.5019 Train_Acc: 72.129 Val_Loss: 0.4658  BEST VAL Loss: 0.4658  Val_Acc: 77.364

Epoch 35: Validation loss decreased (0.465798 --> 0.465361).  Saving model ...
	 Train_Loss: 0.5016 Train_Acc: 72.454 Val_Loss: 0.4654  BEST VAL Loss: 0.4654  Val_Acc: 77.209

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.5013 Train_Acc: 72.366 Val_Loss: 0.4664  BEST VAL Loss: 0.4654  Val_Acc: 76.517

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.5010 Train_Acc: 72.444 Val_Loss: 0.4662  BEST VAL Loss: 0.4654  Val_Acc: 77.289

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.5007 Train_Acc: 72.560 Val_Loss: 0.4659  BEST VAL Loss: 0.4654  Val_Acc: 77.018

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.5004 Train_Acc: 72.588 Val_Loss: 0.4657  BEST VAL Loss: 0.4654  Val_Acc: 77.360

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.5001 Train_Acc: 72.493 Val_Loss: 0.4662  BEST VAL Loss: 0.4654  Val_Acc: 76.796

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.5000 Train_Acc: 72.208 Val_Loss: 0.4658  BEST VAL Loss: 0.4654  Val_Acc: 76.920

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.5013 Train_Acc: 72.069 Val_Loss: 0.4658  BEST VAL Loss: 0.4654  Val_Acc: 76.925

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.5012 Train_Acc: 72.312 Val_Loss: 0.4657  BEST VAL Loss: 0.4654  Val_Acc: 77.413

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.5010 Train_Acc: 72.657 Val_Loss: 0.4654  BEST VAL Loss: 0.4654  Val_Acc: 77.200

Epoch 45: Validation loss decreased (0.465361 --> 0.465056).  Saving model ...
	 Train_Loss: 0.5008 Train_Acc: 72.375 Val_Loss: 0.4651  BEST VAL Loss: 0.4651  Val_Acc: 77.586

Epoch 46: Validation loss decreased (0.465056 --> 0.464926).  Saving model ...
	 Train_Loss: 0.5004 Train_Acc: 72.814 Val_Loss: 0.4649  BEST VAL Loss: 0.4649  Val_Acc: 77.608

Epoch 47: Validation loss decreased (0.464926 --> 0.464694).  Saving model ...
	 Train_Loss: 0.5003 Train_Acc: 71.941 Val_Loss: 0.4647  BEST VAL Loss: 0.4647  Val_Acc: 77.329

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.5001 Train_Acc: 72.593 Val_Loss: 0.4649  BEST VAL Loss: 0.4647  Val_Acc: 75.558

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.4999 Train_Acc: 72.432 Val_Loss: 0.4649  BEST VAL Loss: 0.4647  Val_Acc: 77.275

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.4997 Train_Acc: 72.630 Val_Loss: 0.4650  BEST VAL Loss: 0.4647  Val_Acc: 77.195

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.4994 Train_Acc: 72.652 Val_Loss: 0.4647  BEST VAL Loss: 0.4647  Val_Acc: 77.533

Epoch 52: Validation loss decreased (0.464694 --> 0.464615).  Saving model ...
	 Train_Loss: 0.4994 Train_Acc: 72.348 Val_Loss: 0.4646  BEST VAL Loss: 0.4646  Val_Acc: 77.599

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.4993 Train_Acc: 72.437 Val_Loss: 0.4650  BEST VAL Loss: 0.4646  Val_Acc: 75.283

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.4991 Train_Acc: 72.189 Val_Loss: 0.4649  BEST VAL Loss: 0.4646  Val_Acc: 76.144

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.4990 Train_Acc: 72.448 Val_Loss: 0.4649  BEST VAL Loss: 0.4646  Val_Acc: 77.377

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.4988 Train_Acc: 71.817 Val_Loss: 0.4647  BEST VAL Loss: 0.4646  Val_Acc: 77.382

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.4987 Train_Acc: 72.645 Val_Loss: 0.4647  BEST VAL Loss: 0.4646  Val_Acc: 76.894

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.5002 Train_Acc: 72.381 Val_Loss: 0.4682  BEST VAL Loss: 0.4646  Val_Acc: 75.598

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.5003 Train_Acc: 72.434 Val_Loss: 0.4682  BEST VAL Loss: 0.4646  Val_Acc: 76.960

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.5003 Train_Acc: 72.288 Val_Loss: 0.4692  BEST VAL Loss: 0.4646  Val_Acc: 74.129

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.5002 Train_Acc: 72.175 Val_Loss: 0.4691  BEST VAL Loss: 0.4646  Val_Acc: 76.099

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.5002 Train_Acc: 72.068 Val_Loss: 0.4689  BEST VAL Loss: 0.4646  Val_Acc: 76.738

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.5000 Train_Acc: 72.439 Val_Loss: 0.4687  BEST VAL Loss: 0.4646  Val_Acc: 76.614

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.4998 Train_Acc: 72.456 Val_Loss: 0.4691  BEST VAL Loss: 0.4646  Val_Acc: 76.601

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.4996 Train_Acc: 72.599 Val_Loss: 0.4689  BEST VAL Loss: 0.4646  Val_Acc: 77.244

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.4995 Train_Acc: 72.576 Val_Loss: 0.4687  BEST VAL Loss: 0.4646  Val_Acc: 76.654

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.4993 Train_Acc: 72.656 Val_Loss: 0.4687  BEST VAL Loss: 0.4646  Val_Acc: 76.388

Epoch 68: Validation loss did not decrease
Early stopped at epoch : 68
Thapsigargin_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.42      0.46     92173
           1       0.49      0.58      0.53     88099

    accuracy                           0.50    180272
   macro avg       0.50      0.50      0.50    180272
weighted avg       0.50      0.50      0.50    180272

Thapsigargin_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.41      0.45     11522
           1       0.48      0.57      0.52     11013

    accuracy                           0.49     22535
   macro avg       0.49      0.49      0.49     22535
weighted avg       0.49      0.49      0.49     22535

Thapsigargin_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.42      0.46     11522
           1       0.49      0.58      0.53     11012

    accuracy                           0.50     22534
   macro avg       0.50      0.50      0.50     22534
weighted avg       0.50      0.50      0.50     22534

              precision    recall  f1-score   support

           0       0.51      0.42      0.46     11522
           1       0.49      0.58      0.53     11012

    accuracy                           0.50     22534
   macro avg       0.50      0.50      0.50     22534
weighted avg       0.50      0.50      0.50     22534

Thapsigargin_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.25      0.34     41273
           1       0.48      0.75      0.59     38332

    accuracy                           0.49     79605
   macro avg       0.50      0.50      0.46     79605
weighted avg       0.50      0.49      0.46     79605

              precision    recall  f1-score   support

           0       0.52      0.25      0.34     41273
           1       0.48      0.75      0.59     38332

    accuracy                           0.49     79605
   macro avg       0.50      0.50      0.46     79605
weighted avg       0.50      0.49      0.46     79605

completed
