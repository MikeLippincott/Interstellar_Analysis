[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '749cf49f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'cad610af'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'fb566ed7'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'ec7be687'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_0.010_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_0.010_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (238995, 1270)
Number of total missing values across all columns: 477990
Data Subset Is Off
Wells held out for testing: ['B09' 'L10']
Wells to use for training, validation, and testing ['B02' 'B03' 'B08' 'L05' 'L11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.476639).  Saving model ...
	 Train_Loss: 0.5445 Train_Acc: 72.415 Val_Loss: 0.4766  BEST VAL Loss: 0.4766  Val_Acc: 77.155

Epoch 1: Validation loss decreased (0.476639 --> 0.462518).  Saving model ...
	 Train_Loss: 0.5156 Train_Acc: 76.320 Val_Loss: 0.4625  BEST VAL Loss: 0.4625  Val_Acc: 78.439

Epoch 2: Validation loss decreased (0.462518 --> 0.451478).  Saving model ...
	 Train_Loss: 0.4986 Train_Acc: 77.695 Val_Loss: 0.4515  BEST VAL Loss: 0.4515  Val_Acc: 79.546

Epoch 3: Validation loss decreased (0.451478 --> 0.442065).  Saving model ...
	 Train_Loss: 0.4862 Train_Acc: 78.558 Val_Loss: 0.4421  BEST VAL Loss: 0.4421  Val_Acc: 80.459

Epoch 4: Validation loss decreased (0.442065 --> 0.434482).  Saving model ...
	 Train_Loss: 0.4769 Train_Acc: 79.003 Val_Loss: 0.4345  BEST VAL Loss: 0.4345  Val_Acc: 81.125

Epoch 5: Validation loss decreased (0.434482 --> 0.429255).  Saving model ...
	 Train_Loss: 0.4695 Train_Acc: 79.402 Val_Loss: 0.4293  BEST VAL Loss: 0.4293  Val_Acc: 80.689

Epoch 6: Validation loss decreased (0.429255 --> 0.423708).  Saving model ...
	 Train_Loss: 0.4632 Train_Acc: 79.884 Val_Loss: 0.4237  BEST VAL Loss: 0.4237  Val_Acc: 81.661

Epoch 7: Validation loss decreased (0.423708 --> 0.419484).  Saving model ...
	 Train_Loss: 0.4577 Train_Acc: 80.082 Val_Loss: 0.4195  BEST VAL Loss: 0.4195  Val_Acc: 81.649

Epoch 8: Validation loss decreased (0.419484 --> 0.416183).  Saving model ...
	 Train_Loss: 0.4528 Train_Acc: 80.290 Val_Loss: 0.4162  BEST VAL Loss: 0.4162  Val_Acc: 81.820

Epoch 9: Validation loss decreased (0.416183 --> 0.412741).  Saving model ...
	 Train_Loss: 0.4483 Train_Acc: 80.541 Val_Loss: 0.4127  BEST VAL Loss: 0.4127  Val_Acc: 82.174

Epoch 10: Validation loss decreased (0.412741 --> 0.410301).  Saving model ...
	 Train_Loss: 0.4446 Train_Acc: 80.581 Val_Loss: 0.4103  BEST VAL Loss: 0.4103  Val_Acc: 81.591

Epoch 11: Validation loss decreased (0.410301 --> 0.407251).  Saving model ...
	 Train_Loss: 0.4412 Train_Acc: 80.676 Val_Loss: 0.4073  BEST VAL Loss: 0.4073  Val_Acc: 82.627

Epoch 12: Validation loss decreased (0.407251 --> 0.405125).  Saving model ...
	 Train_Loss: 0.4381 Train_Acc: 80.860 Val_Loss: 0.4051  BEST VAL Loss: 0.4051  Val_Acc: 82.197

Epoch 13: Validation loss decreased (0.405125 --> 0.402724).  Saving model ...
	 Train_Loss: 0.4354 Train_Acc: 80.996 Val_Loss: 0.4027  BEST VAL Loss: 0.4027  Val_Acc: 82.551

Epoch 14: Validation loss decreased (0.402724 --> 0.400790).  Saving model ...
	 Train_Loss: 0.4329 Train_Acc: 80.997 Val_Loss: 0.4008  BEST VAL Loss: 0.4008  Val_Acc: 82.203

Epoch 15: Validation loss decreased (0.400790 --> 0.398669).  Saving model ...
	 Train_Loss: 0.4305 Train_Acc: 81.162 Val_Loss: 0.3987  BEST VAL Loss: 0.3987  Val_Acc: 83.110

Epoch 16: Validation loss decreased (0.398669 --> 0.396918).  Saving model ...
	 Train_Loss: 0.4283 Train_Acc: 81.304 Val_Loss: 0.3969  BEST VAL Loss: 0.3969  Val_Acc: 82.863

Epoch 17: Validation loss decreased (0.396918 --> 0.395061).  Saving model ...
	 Train_Loss: 0.4261 Train_Acc: 81.396 Val_Loss: 0.3951  BEST VAL Loss: 0.3951  Val_Acc: 83.370

Epoch 18: Validation loss decreased (0.395061 --> 0.393552).  Saving model ...
	 Train_Loss: 0.4243 Train_Acc: 81.260 Val_Loss: 0.3936  BEST VAL Loss: 0.3936  Val_Acc: 83.116

Epoch 19: Validation loss decreased (0.393552 --> 0.392110).  Saving model ...
	 Train_Loss: 0.4225 Train_Acc: 81.504 Val_Loss: 0.3921  BEST VAL Loss: 0.3921  Val_Acc: 83.028

Epoch 20: Validation loss decreased (0.392110 --> 0.390873).  Saving model ...
	 Train_Loss: 0.4207 Train_Acc: 81.544 Val_Loss: 0.3909  BEST VAL Loss: 0.3909  Val_Acc: 82.792

Epoch 21: Validation loss decreased (0.390873 --> 0.389393).  Saving model ...
	 Train_Loss: 0.4192 Train_Acc: 81.479 Val_Loss: 0.3894  BEST VAL Loss: 0.3894  Val_Acc: 83.299

Epoch 22: Validation loss decreased (0.389393 --> 0.388029).  Saving model ...
	 Train_Loss: 0.4176 Train_Acc: 81.679 Val_Loss: 0.3880  BEST VAL Loss: 0.3880  Val_Acc: 83.381

Epoch 23: Validation loss decreased (0.388029 --> 0.386739).  Saving model ...
	 Train_Loss: 0.4163 Train_Acc: 81.597 Val_Loss: 0.3867  BEST VAL Loss: 0.3867  Val_Acc: 83.535

Epoch 24: Validation loss decreased (0.386739 --> 0.385459).  Saving model ...
	 Train_Loss: 0.4149 Train_Acc: 81.700 Val_Loss: 0.3855  BEST VAL Loss: 0.3855  Val_Acc: 83.617

Epoch 25: Validation loss decreased (0.385459 --> 0.384488).  Saving model ...
	 Train_Loss: 0.4136 Train_Acc: 81.747 Val_Loss: 0.3845  BEST VAL Loss: 0.3845  Val_Acc: 83.181

Epoch 26: Validation loss decreased (0.384488 --> 0.383524).  Saving model ...
	 Train_Loss: 0.4124 Train_Acc: 81.823 Val_Loss: 0.3835  BEST VAL Loss: 0.3835  Val_Acc: 83.293

Epoch 27: Validation loss decreased (0.383524 --> 0.382497).  Saving model ...
	 Train_Loss: 0.4113 Train_Acc: 81.696 Val_Loss: 0.3825  BEST VAL Loss: 0.3825  Val_Acc: 83.711

Epoch 28: Validation loss decreased (0.382497 --> 0.381540).  Saving model ...
	 Train_Loss: 0.4102 Train_Acc: 81.819 Val_Loss: 0.3815  BEST VAL Loss: 0.3815  Val_Acc: 83.588

Epoch 29: Validation loss decreased (0.381540 --> 0.380467).  Saving model ...
	 Train_Loss: 0.4092 Train_Acc: 81.866 Val_Loss: 0.3805  BEST VAL Loss: 0.3805  Val_Acc: 83.923

Epoch 30: Validation loss decreased (0.380467 --> 0.379538).  Saving model ...
	 Train_Loss: 0.4082 Train_Acc: 81.841 Val_Loss: 0.3795  BEST VAL Loss: 0.3795  Val_Acc: 83.605

Epoch 31: Validation loss decreased (0.379538 --> 0.378736).  Saving model ...
	 Train_Loss: 0.4072 Train_Acc: 81.939 Val_Loss: 0.3787  BEST VAL Loss: 0.3787  Val_Acc: 83.470

Epoch 32: Validation loss decreased (0.378736 --> 0.377952).  Saving model ...
	 Train_Loss: 0.4062 Train_Acc: 81.957 Val_Loss: 0.3780  BEST VAL Loss: 0.3780  Val_Acc: 83.487

Epoch 33: Validation loss decreased (0.377952 --> 0.377341).  Saving model ...
	 Train_Loss: 0.4054 Train_Acc: 81.986 Val_Loss: 0.3773  BEST VAL Loss: 0.3773  Val_Acc: 83.317

Epoch 34: Validation loss decreased (0.377341 --> 0.376603).  Saving model ...
	 Train_Loss: 0.4045 Train_Acc: 82.131 Val_Loss: 0.3766  BEST VAL Loss: 0.3766  Val_Acc: 83.906

Epoch 35: Validation loss decreased (0.376603 --> 0.375841).  Saving model ...
	 Train_Loss: 0.4036 Train_Acc: 82.003 Val_Loss: 0.3758  BEST VAL Loss: 0.3758  Val_Acc: 83.758

Epoch 36: Validation loss decreased (0.375841 --> 0.375143).  Saving model ...
	 Train_Loss: 0.4029 Train_Acc: 82.084 Val_Loss: 0.3751  BEST VAL Loss: 0.3751  Val_Acc: 83.676

Epoch 37: Validation loss decreased (0.375143 --> 0.374560).  Saving model ...
	 Train_Loss: 0.4021 Train_Acc: 82.076 Val_Loss: 0.3746  BEST VAL Loss: 0.3746  Val_Acc: 83.594

Epoch 38: Validation loss decreased (0.374560 --> 0.373930).  Saving model ...
	 Train_Loss: 0.4013 Train_Acc: 82.176 Val_Loss: 0.3739  BEST VAL Loss: 0.3739  Val_Acc: 83.853

Epoch 39: Validation loss decreased (0.373930 --> 0.373234).  Saving model ...
	 Train_Loss: 0.4006 Train_Acc: 82.059 Val_Loss: 0.3732  BEST VAL Loss: 0.3732  Val_Acc: 84.071

Epoch 40: Validation loss decreased (0.373234 --> 0.372550).  Saving model ...
	 Train_Loss: 0.3999 Train_Acc: 82.179 Val_Loss: 0.3726  BEST VAL Loss: 0.3726  Val_Acc: 83.976

Epoch 41: Validation loss decreased (0.372550 --> 0.372080).  Saving model ...
	 Train_Loss: 0.3992 Train_Acc: 82.239 Val_Loss: 0.3721  BEST VAL Loss: 0.3721  Val_Acc: 83.617

Epoch 42: Validation loss decreased (0.372080 --> 0.371420).  Saving model ...
	 Train_Loss: 0.3985 Train_Acc: 82.405 Val_Loss: 0.3714  BEST VAL Loss: 0.3714  Val_Acc: 84.353

Epoch 43: Validation loss decreased (0.371420 --> 0.370948).  Saving model ...
	 Train_Loss: 0.3979 Train_Acc: 82.223 Val_Loss: 0.3709  BEST VAL Loss: 0.3709  Val_Acc: 83.682

Epoch 44: Validation loss decreased (0.370948 --> 0.370501).  Saving model ...
	 Train_Loss: 0.3972 Train_Acc: 82.341 Val_Loss: 0.3705  BEST VAL Loss: 0.3705  Val_Acc: 83.723

Epoch 45: Validation loss decreased (0.370501 --> 0.370030).  Saving model ...
	 Train_Loss: 0.3966 Train_Acc: 82.319 Val_Loss: 0.3700  BEST VAL Loss: 0.3700  Val_Acc: 83.965

Epoch 46: Validation loss decreased (0.370030 --> 0.369490).  Saving model ...
	 Train_Loss: 0.3960 Train_Acc: 82.342 Val_Loss: 0.3695  BEST VAL Loss: 0.3695  Val_Acc: 84.059

Epoch 47: Validation loss decreased (0.369490 --> 0.368940).  Saving model ...
	 Train_Loss: 0.3954 Train_Acc: 82.302 Val_Loss: 0.3689  BEST VAL Loss: 0.3689  Val_Acc: 83.971

Epoch 48: Validation loss decreased (0.368940 --> 0.368485).  Saving model ...
	 Train_Loss: 0.3948 Train_Acc: 82.427 Val_Loss: 0.3685  BEST VAL Loss: 0.3685  Val_Acc: 83.882

Epoch 49: Validation loss decreased (0.368485 --> 0.368162).  Saving model ...
	 Train_Loss: 0.3943 Train_Acc: 82.460 Val_Loss: 0.3682  BEST VAL Loss: 0.3682  Val_Acc: 83.134

Epoch 50: Validation loss decreased (0.368162 --> 0.367726).  Saving model ...
	 Train_Loss: 0.3937 Train_Acc: 82.333 Val_Loss: 0.3677  BEST VAL Loss: 0.3677  Val_Acc: 83.906

Epoch 51: Validation loss decreased (0.367726 --> 0.367288).  Saving model ...
	 Train_Loss: 0.3932 Train_Acc: 82.427 Val_Loss: 0.3673  BEST VAL Loss: 0.3673  Val_Acc: 83.764

Epoch 52: Validation loss decreased (0.367288 --> 0.366864).  Saving model ...
	 Train_Loss: 0.3927 Train_Acc: 82.441 Val_Loss: 0.3669  BEST VAL Loss: 0.3669  Val_Acc: 83.912

Epoch 53: Validation loss decreased (0.366864 --> 0.366427).  Saving model ...
	 Train_Loss: 0.3922 Train_Acc: 82.492 Val_Loss: 0.3664  BEST VAL Loss: 0.3664  Val_Acc: 84.059

Epoch 54: Validation loss decreased (0.366427 --> 0.366016).  Saving model ...
	 Train_Loss: 0.3917 Train_Acc: 82.518 Val_Loss: 0.3660  BEST VAL Loss: 0.3660  Val_Acc: 84.077

Epoch 55: Validation loss decreased (0.366016 --> 0.365630).  Saving model ...
	 Train_Loss: 0.3912 Train_Acc: 82.472 Val_Loss: 0.3656  BEST VAL Loss: 0.3656  Val_Acc: 84.183

Epoch 56: Validation loss decreased (0.365630 --> 0.365196).  Saving model ...
	 Train_Loss: 0.3907 Train_Acc: 82.529 Val_Loss: 0.3652  BEST VAL Loss: 0.3652  Val_Acc: 84.236

Epoch 57: Validation loss decreased (0.365196 --> 0.364757).  Saving model ...
	 Train_Loss: 0.3903 Train_Acc: 82.537 Val_Loss: 0.3648  BEST VAL Loss: 0.3648  Val_Acc: 84.359

Epoch 58: Validation loss decreased (0.364757 --> 0.364335).  Saving model ...
	 Train_Loss: 0.3898 Train_Acc: 82.593 Val_Loss: 0.3643  BEST VAL Loss: 0.3643  Val_Acc: 84.094

Epoch 59: Validation loss decreased (0.364335 --> 0.363964).  Saving model ...
	 Train_Loss: 0.3894 Train_Acc: 82.422 Val_Loss: 0.3640  BEST VAL Loss: 0.3640  Val_Acc: 83.882

Epoch 60: Validation loss decreased (0.363964 --> 0.363585).  Saving model ...
	 Train_Loss: 0.3890 Train_Acc: 82.588 Val_Loss: 0.3636  BEST VAL Loss: 0.3636  Val_Acc: 84.513

Epoch 61: Validation loss decreased (0.363585 --> 0.363313).  Saving model ...
	 Train_Loss: 0.3886 Train_Acc: 82.573 Val_Loss: 0.3633  BEST VAL Loss: 0.3633  Val_Acc: 84.012

Epoch 62: Validation loss decreased (0.363313 --> 0.363018).  Saving model ...
	 Train_Loss: 0.3881 Train_Acc: 82.594 Val_Loss: 0.3630  BEST VAL Loss: 0.3630  Val_Acc: 84.153

Epoch 63: Validation loss decreased (0.363018 --> 0.362681).  Saving model ...
	 Train_Loss: 0.3878 Train_Acc: 82.626 Val_Loss: 0.3627  BEST VAL Loss: 0.3627  Val_Acc: 84.118

Epoch 64: Validation loss decreased (0.362681 --> 0.362330).  Saving model ...
	 Train_Loss: 0.3873 Train_Acc: 82.641 Val_Loss: 0.3623  BEST VAL Loss: 0.3623  Val_Acc: 84.283

Epoch 65: Validation loss decreased (0.362330 --> 0.362024).  Saving model ...
	 Train_Loss: 0.3870 Train_Acc: 82.556 Val_Loss: 0.3620  BEST VAL Loss: 0.3620  Val_Acc: 84.065

Epoch 66: Validation loss decreased (0.362024 --> 0.361667).  Saving model ...
	 Train_Loss: 0.3866 Train_Acc: 82.600 Val_Loss: 0.3617  BEST VAL Loss: 0.3617  Val_Acc: 84.171

Epoch 67: Validation loss decreased (0.361667 --> 0.361338).  Saving model ...
	 Train_Loss: 0.3862 Train_Acc: 82.671 Val_Loss: 0.3613  BEST VAL Loss: 0.3613  Val_Acc: 84.348

Epoch 68: Validation loss decreased (0.361338 --> 0.361124).  Saving model ...
	 Train_Loss: 0.3858 Train_Acc: 82.724 Val_Loss: 0.3611  BEST VAL Loss: 0.3611  Val_Acc: 84.247

Epoch 69: Validation loss decreased (0.361124 --> 0.360867).  Saving model ...
	 Train_Loss: 0.3855 Train_Acc: 82.750 Val_Loss: 0.3609  BEST VAL Loss: 0.3609  Val_Acc: 84.230

Epoch 70: Validation loss decreased (0.360867 --> 0.360500).  Saving model ...
	 Train_Loss: 0.3851 Train_Acc: 82.556 Val_Loss: 0.3605  BEST VAL Loss: 0.3605  Val_Acc: 84.566

Epoch 71: Validation loss decreased (0.360500 --> 0.360261).  Saving model ...
	 Train_Loss: 0.3848 Train_Acc: 82.590 Val_Loss: 0.3603  BEST VAL Loss: 0.3603  Val_Acc: 83.959

Epoch 72: Validation loss decreased (0.360261 --> 0.359971).  Saving model ...
	 Train_Loss: 0.3845 Train_Acc: 82.716 Val_Loss: 0.3600  BEST VAL Loss: 0.3600  Val_Acc: 84.300

Epoch 73: Validation loss decreased (0.359971 --> 0.359813).  Saving model ...
	 Train_Loss: 0.3841 Train_Acc: 82.676 Val_Loss: 0.3598  BEST VAL Loss: 0.3598  Val_Acc: 83.811

Epoch 74: Validation loss decreased (0.359813 --> 0.359552).  Saving model ...
	 Train_Loss: 0.3838 Train_Acc: 82.741 Val_Loss: 0.3596  BEST VAL Loss: 0.3596  Val_Acc: 84.206

Epoch 75: Validation loss decreased (0.359552 --> 0.359364).  Saving model ...
	 Train_Loss: 0.3835 Train_Acc: 82.797 Val_Loss: 0.3594  BEST VAL Loss: 0.3594  Val_Acc: 84.165

Epoch 76: Validation loss decreased (0.359364 --> 0.359069).  Saving model ...
	 Train_Loss: 0.3831 Train_Acc: 82.802 Val_Loss: 0.3591  BEST VAL Loss: 0.3591  Val_Acc: 84.518

Epoch 77: Validation loss decreased (0.359069 --> 0.358883).  Saving model ...
	 Train_Loss: 0.3828 Train_Acc: 82.838 Val_Loss: 0.3589  BEST VAL Loss: 0.3589  Val_Acc: 84.224

Epoch 78: Validation loss decreased (0.358883 --> 0.358692).  Saving model ...
	 Train_Loss: 0.3825 Train_Acc: 82.824 Val_Loss: 0.3587  BEST VAL Loss: 0.3587  Val_Acc: 84.000

Epoch 79: Validation loss decreased (0.358692 --> 0.358478).  Saving model ...
	 Train_Loss: 0.3822 Train_Acc: 82.831 Val_Loss: 0.3585  BEST VAL Loss: 0.3585  Val_Acc: 84.348

Epoch 80: Validation loss decreased (0.358478 --> 0.358255).  Saving model ...
	 Train_Loss: 0.3819 Train_Acc: 82.827 Val_Loss: 0.3583  BEST VAL Loss: 0.3583  Val_Acc: 84.230

Epoch 81: Validation loss decreased (0.358255 --> 0.357995).  Saving model ...
	 Train_Loss: 0.3816 Train_Acc: 82.909 Val_Loss: 0.3580  BEST VAL Loss: 0.3580  Val_Acc: 84.459

Epoch 82: Validation loss decreased (0.357995 --> 0.357750).  Saving model ...
	 Train_Loss: 0.3813 Train_Acc: 82.745 Val_Loss: 0.3578  BEST VAL Loss: 0.3578  Val_Acc: 84.448

Epoch 83: Validation loss decreased (0.357750 --> 0.357521).  Saving model ...
	 Train_Loss: 0.3810 Train_Acc: 82.865 Val_Loss: 0.3575  BEST VAL Loss: 0.3575  Val_Acc: 84.242

Epoch 84: Validation loss decreased (0.357521 --> 0.357288).  Saving model ...
	 Train_Loss: 0.3808 Train_Acc: 82.849 Val_Loss: 0.3573  BEST VAL Loss: 0.3573  Val_Acc: 84.230

Epoch 85: Validation loss decreased (0.357288 --> 0.357049).  Saving model ...
	 Train_Loss: 0.3805 Train_Acc: 82.838 Val_Loss: 0.3570  BEST VAL Loss: 0.3570  Val_Acc: 84.206

Epoch 86: Validation loss decreased (0.357049 --> 0.356853).  Saving model ...
	 Train_Loss: 0.3802 Train_Acc: 82.900 Val_Loss: 0.3569  BEST VAL Loss: 0.3569  Val_Acc: 84.247

Epoch 87: Validation loss decreased (0.356853 --> 0.356641).  Saving model ...
	 Train_Loss: 0.3799 Train_Acc: 83.018 Val_Loss: 0.3566  BEST VAL Loss: 0.3566  Val_Acc: 84.353

Epoch 88: Validation loss decreased (0.356641 --> 0.356417).  Saving model ...
	 Train_Loss: 0.3797 Train_Acc: 82.888 Val_Loss: 0.3564  BEST VAL Loss: 0.3564  Val_Acc: 84.353

Epoch 89: Validation loss decreased (0.356417 --> 0.356258).  Saving model ...
	 Train_Loss: 0.3794 Train_Acc: 82.947 Val_Loss: 0.3563  BEST VAL Loss: 0.3563  Val_Acc: 84.153

Epoch 90: Validation loss decreased (0.356258 --> 0.356052).  Saving model ...
	 Train_Loss: 0.3792 Train_Acc: 82.757 Val_Loss: 0.3561  BEST VAL Loss: 0.3561  Val_Acc: 84.306

Epoch 91: Validation loss decreased (0.356052 --> 0.355827).  Saving model ...
	 Train_Loss: 0.3789 Train_Acc: 82.791 Val_Loss: 0.3558  BEST VAL Loss: 0.3558  Val_Acc: 84.253

Epoch 92: Validation loss decreased (0.355827 --> 0.355608).  Saving model ...
	 Train_Loss: 0.3787 Train_Acc: 82.773 Val_Loss: 0.3556  BEST VAL Loss: 0.3556  Val_Acc: 84.242

Epoch 93: Validation loss decreased (0.355608 --> 0.355487).  Saving model ...
	 Train_Loss: 0.3784 Train_Acc: 83.089 Val_Loss: 0.3555  BEST VAL Loss: 0.3555  Val_Acc: 84.000

Epoch 94: Validation loss decreased (0.355487 --> 0.355315).  Saving model ...
	 Train_Loss: 0.3782 Train_Acc: 83.023 Val_Loss: 0.3553  BEST VAL Loss: 0.3553  Val_Acc: 84.324

Epoch 95: Validation loss decreased (0.355315 --> 0.355139).  Saving model ...
	 Train_Loss: 0.3779 Train_Acc: 82.983 Val_Loss: 0.3551  BEST VAL Loss: 0.3551  Val_Acc: 84.236

Epoch 96: Validation loss decreased (0.355139 --> 0.354954).  Saving model ...
	 Train_Loss: 0.3777 Train_Acc: 82.831 Val_Loss: 0.3550  BEST VAL Loss: 0.3550  Val_Acc: 84.495

Epoch 97: Validation loss decreased (0.354954 --> 0.354797).  Saving model ...
	 Train_Loss: 0.3775 Train_Acc: 82.850 Val_Loss: 0.3548  BEST VAL Loss: 0.3548  Val_Acc: 84.412

Epoch 98: Validation loss decreased (0.354797 --> 0.354614).  Saving model ...
	 Train_Loss: 0.3772 Train_Acc: 82.977 Val_Loss: 0.3546  BEST VAL Loss: 0.3546  Val_Acc: 84.412

Epoch 99: Validation loss decreased (0.354614 --> 0.354455).  Saving model ...
	 Train_Loss: 0.3770 Train_Acc: 82.922 Val_Loss: 0.3545  BEST VAL Loss: 0.3545  Val_Acc: 84.483

LPS_0.010_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.37      0.31      0.34     50422
           1       0.63      0.69      0.66     85370

    accuracy                           0.55    135792
   macro avg       0.50      0.50      0.50    135792
weighted avg       0.53      0.55      0.54    135792

LPS_0.010_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.37      0.30      0.33      6303
           1       0.63      0.69      0.66     10672

    accuracy                           0.55     16975
   macro avg       0.50      0.50      0.50     16975
weighted avg       0.53      0.55      0.54     16975

LPS_0.010_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.37      0.31      0.34      6303
           1       0.63      0.69      0.66     10672

    accuracy                           0.55     16975
   macro avg       0.50      0.50      0.50     16975
weighted avg       0.53      0.55      0.54     16975

              precision    recall  f1-score   support

           0       0.37      0.31      0.34      6303
           1       0.63      0.69      0.66     10672

    accuracy                           0.55     16975
   macro avg       0.50      0.50      0.50     16975
weighted avg       0.53      0.55      0.54     16975

LPS_0.010_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.48      0.48     32887
           1       0.53      0.53      0.53     36366

    accuracy                           0.50     69253
   macro avg       0.50      0.50      0.50     69253
weighted avg       0.50      0.50      0.50     69253

              precision    recall  f1-score   support

           0       0.48      0.48      0.48     32887
           1       0.53      0.53      0.53     36366

    accuracy                           0.50     69253
   macro avg       0.50      0.50      0.50     69253
weighted avg       0.50      0.50      0.50     69253

completed
