[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '27ee34a0'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '38560ca5'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '5d66683b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '03fb1bba'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_Nigericin_1.000_3.0_DMSO_0.025'
 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (355427, 1270)
Number of total missing values across all columns: 0
Data Subset Is Off
Wells held out for testing: ['M08' 'L09']
Wells to use for training, validation, and testing ['L02' 'M02' 'L03' 'M03' 'L08' 'M09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.686271).  Saving model ...
	 Train_Loss: 0.6910 Train_Acc: 52.394 Val_Loss: 0.6863  BEST VAL Loss: 0.6863  Val_Acc: 55.202

Epoch 1: Validation loss decreased (0.686271 --> 0.683175).  Saving model ...
	 Train_Loss: 0.6881 Train_Acc: 54.832 Val_Loss: 0.6832  BEST VAL Loss: 0.6832  Val_Acc: 56.800

Epoch 2: Validation loss decreased (0.683175 --> 0.679843).  Saving model ...
	 Train_Loss: 0.6851 Train_Acc: 56.324 Val_Loss: 0.6798  BEST VAL Loss: 0.6798  Val_Acc: 58.606

Epoch 3: Validation loss decreased (0.679843 --> 0.676271).  Saving model ...
	 Train_Loss: 0.6823 Train_Acc: 57.713 Val_Loss: 0.6763  BEST VAL Loss: 0.6763  Val_Acc: 59.677

Epoch 4: Validation loss decreased (0.676271 --> 0.672844).  Saving model ...
	 Train_Loss: 0.6793 Train_Acc: 58.881 Val_Loss: 0.6728  BEST VAL Loss: 0.6728  Val_Acc: 60.744

Epoch 5: Validation loss decreased (0.672844 --> 0.669134).  Saving model ...
	 Train_Loss: 0.6764 Train_Acc: 59.881 Val_Loss: 0.6691  BEST VAL Loss: 0.6691  Val_Acc: 62.185

Epoch 6: Validation loss decreased (0.669134 --> 0.665536).  Saving model ...
	 Train_Loss: 0.6734 Train_Acc: 61.138 Val_Loss: 0.6655  BEST VAL Loss: 0.6655  Val_Acc: 63.380

Epoch 7: Validation loss decreased (0.665536 --> 0.661940).  Saving model ...
	 Train_Loss: 0.6704 Train_Acc: 62.004 Val_Loss: 0.6619  BEST VAL Loss: 0.6619  Val_Acc: 64.126

Epoch 8: Validation loss decreased (0.661940 --> 0.658548).  Saving model ...
	 Train_Loss: 0.6675 Train_Acc: 62.736 Val_Loss: 0.6585  BEST VAL Loss: 0.6585  Val_Acc: 64.916

Epoch 9: Validation loss decreased (0.658548 --> 0.655190).  Saving model ...
	 Train_Loss: 0.6646 Train_Acc: 63.453 Val_Loss: 0.6552  BEST VAL Loss: 0.6552  Val_Acc: 65.420

Epoch 10: Validation loss decreased (0.655190 --> 0.652053).  Saving model ...
	 Train_Loss: 0.6618 Train_Acc: 64.027 Val_Loss: 0.6521  BEST VAL Loss: 0.6521  Val_Acc: 65.808

Epoch 11: Validation loss decreased (0.652053 --> 0.649162).  Saving model ...
	 Train_Loss: 0.6592 Train_Acc: 64.425 Val_Loss: 0.6492  BEST VAL Loss: 0.6492  Val_Acc: 66.312

Epoch 12: Validation loss decreased (0.649162 --> 0.646490).  Saving model ...
	 Train_Loss: 0.6568 Train_Acc: 64.753 Val_Loss: 0.6465  BEST VAL Loss: 0.6465  Val_Acc: 66.469

Epoch 13: Validation loss decreased (0.646490 --> 0.644111).  Saving model ...
	 Train_Loss: 0.6544 Train_Acc: 65.297 Val_Loss: 0.6441  BEST VAL Loss: 0.6441  Val_Acc: 66.254

Epoch 14: Validation loss decreased (0.644111 --> 0.641758).  Saving model ...
	 Train_Loss: 0.6522 Train_Acc: 65.452 Val_Loss: 0.6418  BEST VAL Loss: 0.6418  Val_Acc: 67.102

Epoch 15: Validation loss decreased (0.641758 --> 0.639441).  Saving model ...
	 Train_Loss: 0.6500 Train_Acc: 65.767 Val_Loss: 0.6394  BEST VAL Loss: 0.6394  Val_Acc: 67.014

Epoch 16: Validation loss decreased (0.639441 --> 0.637360).  Saving model ...
	 Train_Loss: 0.6480 Train_Acc: 66.001 Val_Loss: 0.6374  BEST VAL Loss: 0.6374  Val_Acc: 67.146

Epoch 17: Validation loss decreased (0.637360 --> 0.635303).  Saving model ...
	 Train_Loss: 0.6461 Train_Acc: 66.207 Val_Loss: 0.6353  BEST VAL Loss: 0.6353  Val_Acc: 67.577

Epoch 18: Validation loss decreased (0.635303 --> 0.633442).  Saving model ...
	 Train_Loss: 0.6444 Train_Acc: 66.425 Val_Loss: 0.6334  BEST VAL Loss: 0.6334  Val_Acc: 67.577

Epoch 19: Validation loss decreased (0.633442 --> 0.631649).  Saving model ...
	 Train_Loss: 0.6426 Train_Acc: 66.680 Val_Loss: 0.6316  BEST VAL Loss: 0.6316  Val_Acc: 67.968

Epoch 20: Validation loss decreased (0.631649 --> 0.629944).  Saving model ...
	 Train_Loss: 0.6410 Train_Acc: 66.827 Val_Loss: 0.6299  BEST VAL Loss: 0.6299  Val_Acc: 68.008

Epoch 21: Validation loss decreased (0.629944 --> 0.628347).  Saving model ...
	 Train_Loss: 0.6395 Train_Acc: 67.008 Val_Loss: 0.6283  BEST VAL Loss: 0.6283  Val_Acc: 67.957

Epoch 22: Validation loss decreased (0.628347 --> 0.626849).  Saving model ...
	 Train_Loss: 0.6381 Train_Acc: 67.129 Val_Loss: 0.6268  BEST VAL Loss: 0.6268  Val_Acc: 68.038

Epoch 23: Validation loss decreased (0.626849 --> 0.625423).  Saving model ...
	 Train_Loss: 0.6367 Train_Acc: 67.299 Val_Loss: 0.6254  BEST VAL Loss: 0.6254  Val_Acc: 68.403

Epoch 24: Validation loss decreased (0.625423 --> 0.624078).  Saving model ...
	 Train_Loss: 0.6354 Train_Acc: 67.263 Val_Loss: 0.6241  BEST VAL Loss: 0.6241  Val_Acc: 68.268

Epoch 25: Validation loss decreased (0.624078 --> 0.622848).  Saving model ...
	 Train_Loss: 0.6341 Train_Acc: 67.464 Val_Loss: 0.6228  BEST VAL Loss: 0.6228  Val_Acc: 68.246

Epoch 26: Validation loss decreased (0.622848 --> 0.621775).  Saving model ...
	 Train_Loss: 0.6329 Train_Acc: 67.581 Val_Loss: 0.6218  BEST VAL Loss: 0.6218  Val_Acc: 67.880

Epoch 27: Validation loss decreased (0.621775 --> 0.620621).  Saving model ...
	 Train_Loss: 0.6317 Train_Acc: 67.756 Val_Loss: 0.6206  BEST VAL Loss: 0.6206  Val_Acc: 68.246

Epoch 28: Validation loss decreased (0.620621 --> 0.619521).  Saving model ...
	 Train_Loss: 0.6306 Train_Acc: 67.864 Val_Loss: 0.6195  BEST VAL Loss: 0.6195  Val_Acc: 68.374

Epoch 29: Validation loss decreased (0.619521 --> 0.618508).  Saving model ...
	 Train_Loss: 0.6295 Train_Acc: 67.924 Val_Loss: 0.6185  BEST VAL Loss: 0.6185  Val_Acc: 68.520

Epoch 30: Validation loss decreased (0.618508 --> 0.617446).  Saving model ...
	 Train_Loss: 0.6285 Train_Acc: 67.920 Val_Loss: 0.6174  BEST VAL Loss: 0.6174  Val_Acc: 68.743

Epoch 31: Validation loss decreased (0.617446 --> 0.616458).  Saving model ...
	 Train_Loss: 0.6275 Train_Acc: 67.962 Val_Loss: 0.6165  BEST VAL Loss: 0.6165  Val_Acc: 68.630

Epoch 32: Validation loss decreased (0.616458 --> 0.615580).  Saving model ...
	 Train_Loss: 0.6265 Train_Acc: 68.115 Val_Loss: 0.6156  BEST VAL Loss: 0.6156  Val_Acc: 68.005

Epoch 33: Validation loss decreased (0.615580 --> 0.614808).  Saving model ...
	 Train_Loss: 0.6256 Train_Acc: 68.113 Val_Loss: 0.6148  BEST VAL Loss: 0.6148  Val_Acc: 68.279

Epoch 34: Validation loss decreased (0.614808 --> 0.614010).  Saving model ...
	 Train_Loss: 0.6247 Train_Acc: 68.199 Val_Loss: 0.6140  BEST VAL Loss: 0.6140  Val_Acc: 68.228

Epoch 35: Validation loss decreased (0.614010 --> 0.613428).  Saving model ...
	 Train_Loss: 0.6239 Train_Acc: 68.135 Val_Loss: 0.6134  BEST VAL Loss: 0.6134  Val_Acc: 67.866

Epoch 36: Validation loss decreased (0.613428 --> 0.612725).  Saving model ...
	 Train_Loss: 0.6230 Train_Acc: 68.314 Val_Loss: 0.6127  BEST VAL Loss: 0.6127  Val_Acc: 68.345

Epoch 37: Validation loss decreased (0.612725 --> 0.612015).  Saving model ...
	 Train_Loss: 0.6222 Train_Acc: 68.375 Val_Loss: 0.6120  BEST VAL Loss: 0.6120  Val_Acc: 68.699

Epoch 38: Validation loss decreased (0.612015 --> 0.611199).  Saving model ...
	 Train_Loss: 0.6215 Train_Acc: 68.280 Val_Loss: 0.6112  BEST VAL Loss: 0.6112  Val_Acc: 69.098

Epoch 39: Validation loss decreased (0.611199 --> 0.610538).  Saving model ...
	 Train_Loss: 0.6207 Train_Acc: 68.544 Val_Loss: 0.6105  BEST VAL Loss: 0.6105  Val_Acc: 68.630

Epoch 40: Validation loss decreased (0.610538 --> 0.609869).  Saving model ...
	 Train_Loss: 0.6200 Train_Acc: 68.443 Val_Loss: 0.6099  BEST VAL Loss: 0.6099  Val_Acc: 68.601

Epoch 41: Validation loss decreased (0.609869 --> 0.609164).  Saving model ...
	 Train_Loss: 0.6193 Train_Acc: 68.666 Val_Loss: 0.6092  BEST VAL Loss: 0.6092  Val_Acc: 68.798

Epoch 42: Validation loss decreased (0.609164 --> 0.608500).  Saving model ...
	 Train_Loss: 0.6185 Train_Acc: 68.781 Val_Loss: 0.6085  BEST VAL Loss: 0.6085  Val_Acc: 69.061

Epoch 43: Validation loss decreased (0.608500 --> 0.607999).  Saving model ...
	 Train_Loss: 0.6179 Train_Acc: 68.687 Val_Loss: 0.6080  BEST VAL Loss: 0.6080  Val_Acc: 68.520

Epoch 44: Validation loss decreased (0.607999 --> 0.607530).  Saving model ...
	 Train_Loss: 0.6172 Train_Acc: 68.679 Val_Loss: 0.6075  BEST VAL Loss: 0.6075  Val_Acc: 68.348

Epoch 45: Validation loss decreased (0.607530 --> 0.606891).  Saving model ...
	 Train_Loss: 0.6166 Train_Acc: 68.819 Val_Loss: 0.6069  BEST VAL Loss: 0.6069  Val_Acc: 69.109

Epoch 46: Validation loss decreased (0.606891 --> 0.606300).  Saving model ...
	 Train_Loss: 0.6160 Train_Acc: 68.811 Val_Loss: 0.6063  BEST VAL Loss: 0.6063  Val_Acc: 68.820

Epoch 47: Validation loss decreased (0.606300 --> 0.605692).  Saving model ...
	 Train_Loss: 0.6153 Train_Acc: 69.007 Val_Loss: 0.6057  BEST VAL Loss: 0.6057  Val_Acc: 69.171

Epoch 48: Validation loss decreased (0.605692 --> 0.605122).  Saving model ...
	 Train_Loss: 0.6147 Train_Acc: 68.727 Val_Loss: 0.6051  BEST VAL Loss: 0.6051  Val_Acc: 69.281

Epoch 49: Validation loss decreased (0.605122 --> 0.604564).  Saving model ...
	 Train_Loss: 0.6142 Train_Acc: 68.893 Val_Loss: 0.6046  BEST VAL Loss: 0.6046  Val_Acc: 69.127

Epoch 50: Validation loss decreased (0.604564 --> 0.604062).  Saving model ...
	 Train_Loss: 0.6136 Train_Acc: 68.937 Val_Loss: 0.6041  BEST VAL Loss: 0.6041  Val_Acc: 69.006

Epoch 51: Validation loss decreased (0.604062 --> 0.603750).  Saving model ...
	 Train_Loss: 0.6130 Train_Acc: 68.958 Val_Loss: 0.6038  BEST VAL Loss: 0.6038  Val_Acc: 68.356

Epoch 52: Validation loss decreased (0.603750 --> 0.603251).  Saving model ...
	 Train_Loss: 0.6125 Train_Acc: 69.215 Val_Loss: 0.6033  BEST VAL Loss: 0.6033  Val_Acc: 69.101

Epoch 53: Validation loss decreased (0.603251 --> 0.602766).  Saving model ...
	 Train_Loss: 0.6120 Train_Acc: 69.085 Val_Loss: 0.6028  BEST VAL Loss: 0.6028  Val_Acc: 69.050

Epoch 54: Validation loss decreased (0.602766 --> 0.602285).  Saving model ...
	 Train_Loss: 0.6114 Train_Acc: 69.144 Val_Loss: 0.6023  BEST VAL Loss: 0.6023  Val_Acc: 69.171

Epoch 55: Validation loss decreased (0.602285 --> 0.601802).  Saving model ...
	 Train_Loss: 0.6109 Train_Acc: 69.264 Val_Loss: 0.6018  BEST VAL Loss: 0.6018  Val_Acc: 69.142

Epoch 56: Validation loss decreased (0.601802 --> 0.601339).  Saving model ...
	 Train_Loss: 0.6104 Train_Acc: 69.201 Val_Loss: 0.6013  BEST VAL Loss: 0.6013  Val_Acc: 69.240

Epoch 57: Validation loss decreased (0.601339 --> 0.600913).  Saving model ...
	 Train_Loss: 0.6099 Train_Acc: 69.207 Val_Loss: 0.6009  BEST VAL Loss: 0.6009  Val_Acc: 69.043

Epoch 58: Validation loss decreased (0.600913 --> 0.600472).  Saving model ...
	 Train_Loss: 0.6094 Train_Acc: 69.137 Val_Loss: 0.6005  BEST VAL Loss: 0.6005  Val_Acc: 69.215

Epoch 59: Validation loss decreased (0.600472 --> 0.600020).  Saving model ...
	 Train_Loss: 0.6089 Train_Acc: 69.392 Val_Loss: 0.6000  BEST VAL Loss: 0.6000  Val_Acc: 69.485

Epoch 60: Validation loss decreased (0.600020 --> 0.599573).  Saving model ...
	 Train_Loss: 0.6085 Train_Acc: 69.396 Val_Loss: 0.5996  BEST VAL Loss: 0.5996  Val_Acc: 69.628

Epoch 61: Validation loss decreased (0.599573 --> 0.599364).  Saving model ...
	 Train_Loss: 0.6080 Train_Acc: 69.335 Val_Loss: 0.5994  BEST VAL Loss: 0.5994  Val_Acc: 68.421

Epoch 62: Validation loss decreased (0.599364 --> 0.598920).  Saving model ...
	 Train_Loss: 0.6076 Train_Acc: 69.379 Val_Loss: 0.5989  BEST VAL Loss: 0.5989  Val_Acc: 69.642

Epoch 63: Validation loss decreased (0.598920 --> 0.598619).  Saving model ...
	 Train_Loss: 0.6071 Train_Acc: 69.393 Val_Loss: 0.5986  BEST VAL Loss: 0.5986  Val_Acc: 68.860

Epoch 64: Validation loss decreased (0.598619 --> 0.598369).  Saving model ...
	 Train_Loss: 0.6067 Train_Acc: 69.422 Val_Loss: 0.5984  BEST VAL Loss: 0.5984  Val_Acc: 68.816

Epoch 65: Validation loss decreased (0.598369 --> 0.598084).  Saving model ...
	 Train_Loss: 0.6063 Train_Acc: 69.605 Val_Loss: 0.5981  BEST VAL Loss: 0.5981  Val_Acc: 68.944

Epoch 66: Validation loss decreased (0.598084 --> 0.597687).  Saving model ...
	 Train_Loss: 0.6059 Train_Acc: 69.456 Val_Loss: 0.5977  BEST VAL Loss: 0.5977  Val_Acc: 69.727

Epoch 67: Validation loss decreased (0.597687 --> 0.597317).  Saving model ...
	 Train_Loss: 0.6055 Train_Acc: 69.584 Val_Loss: 0.5973  BEST VAL Loss: 0.5973  Val_Acc: 69.467

Epoch 68: Validation loss decreased (0.597317 --> 0.597036).  Saving model ...
	 Train_Loss: 0.6051 Train_Acc: 69.611 Val_Loss: 0.5970  BEST VAL Loss: 0.5970  Val_Acc: 68.984

Epoch 69: Validation loss decreased (0.597036 --> 0.596728).  Saving model ...
	 Train_Loss: 0.6047 Train_Acc: 69.667 Val_Loss: 0.5967  BEST VAL Loss: 0.5967  Val_Acc: 69.087

Epoch 70: Validation loss decreased (0.596728 --> 0.596359).  Saving model ...
	 Train_Loss: 0.6043 Train_Acc: 69.595 Val_Loss: 0.5964  BEST VAL Loss: 0.5964  Val_Acc: 69.580

Epoch 71: Validation loss decreased (0.596359 --> 0.596052).  Saving model ...
	 Train_Loss: 0.6039 Train_Acc: 69.693 Val_Loss: 0.5961  BEST VAL Loss: 0.5961  Val_Acc: 69.211

Epoch 72: Validation loss decreased (0.596052 --> 0.595780).  Saving model ...
	 Train_Loss: 0.6035 Train_Acc: 69.707 Val_Loss: 0.5958  BEST VAL Loss: 0.5958  Val_Acc: 68.955

Epoch 73: Validation loss decreased (0.595780 --> 0.595452).  Saving model ...
	 Train_Loss: 0.6032 Train_Acc: 69.658 Val_Loss: 0.5955  BEST VAL Loss: 0.5955  Val_Acc: 69.515

Epoch 74: Validation loss decreased (0.595452 --> 0.595104).  Saving model ...
	 Train_Loss: 0.6028 Train_Acc: 69.756 Val_Loss: 0.5951  BEST VAL Loss: 0.5951  Val_Acc: 69.610

Epoch 75: Validation loss decreased (0.595104 --> 0.594774).  Saving model ...
	 Train_Loss: 0.6024 Train_Acc: 69.815 Val_Loss: 0.5948  BEST VAL Loss: 0.5948  Val_Acc: 69.474

Epoch 76: Validation loss decreased (0.594774 --> 0.594442).  Saving model ...
	 Train_Loss: 0.6021 Train_Acc: 69.801 Val_Loss: 0.5944  BEST VAL Loss: 0.5944  Val_Acc: 69.778

Epoch 77: Validation loss decreased (0.594442 --> 0.594183).  Saving model ...
	 Train_Loss: 0.6017 Train_Acc: 69.858 Val_Loss: 0.5942  BEST VAL Loss: 0.5942  Val_Acc: 69.419

Epoch 78: Validation loss decreased (0.594183 --> 0.593853).  Saving model ...
	 Train_Loss: 0.6014 Train_Acc: 69.789 Val_Loss: 0.5939  BEST VAL Loss: 0.5939  Val_Acc: 69.979

Epoch 79: Validation loss decreased (0.593853 --> 0.593548).  Saving model ...
	 Train_Loss: 0.6011 Train_Acc: 69.851 Val_Loss: 0.5935  BEST VAL Loss: 0.5935  Val_Acc: 69.668

Epoch 80: Validation loss decreased (0.593548 --> 0.593276).  Saving model ...
	 Train_Loss: 0.6007 Train_Acc: 69.818 Val_Loss: 0.5933  BEST VAL Loss: 0.5933  Val_Acc: 69.427

Epoch 81: Validation loss decreased (0.593276 --> 0.592975).  Saving model ...
	 Train_Loss: 0.6004 Train_Acc: 69.880 Val_Loss: 0.5930  BEST VAL Loss: 0.5930  Val_Acc: 69.628

Epoch 82: Validation loss decreased (0.592975 --> 0.592732).  Saving model ...
	 Train_Loss: 0.6001 Train_Acc: 69.912 Val_Loss: 0.5927  BEST VAL Loss: 0.5927  Val_Acc: 69.284

Epoch 83: Validation loss decreased (0.592732 --> 0.592457).  Saving model ...
	 Train_Loss: 0.5998 Train_Acc: 69.941 Val_Loss: 0.5925  BEST VAL Loss: 0.5925  Val_Acc: 69.686

Epoch 84: Validation loss decreased (0.592457 --> 0.592190).  Saving model ...
	 Train_Loss: 0.5995 Train_Acc: 69.888 Val_Loss: 0.5922  BEST VAL Loss: 0.5922  Val_Acc: 69.738

Epoch 85: Validation loss decreased (0.592190 --> 0.591920).  Saving model ...
	 Train_Loss: 0.5991 Train_Acc: 69.948 Val_Loss: 0.5919  BEST VAL Loss: 0.5919  Val_Acc: 69.840

Epoch 86: Validation loss decreased (0.591920 --> 0.591666).  Saving model ...
	 Train_Loss: 0.5988 Train_Acc: 69.954 Val_Loss: 0.5917  BEST VAL Loss: 0.5917  Val_Acc: 69.723

Epoch 87: Validation loss decreased (0.591666 --> 0.591415).  Saving model ...
	 Train_Loss: 0.5985 Train_Acc: 70.010 Val_Loss: 0.5914  BEST VAL Loss: 0.5914  Val_Acc: 69.887

Epoch 88: Validation loss decreased (0.591415 --> 0.591137).  Saving model ...
	 Train_Loss: 0.5983 Train_Acc: 69.874 Val_Loss: 0.5911  BEST VAL Loss: 0.5911  Val_Acc: 70.125

Epoch 89: Validation loss decreased (0.591137 --> 0.590909).  Saving model ...
	 Train_Loss: 0.5980 Train_Acc: 70.007 Val_Loss: 0.5909  BEST VAL Loss: 0.5909  Val_Acc: 69.730

Epoch 90: Validation loss decreased (0.590909 --> 0.590699).  Saving model ...
	 Train_Loss: 0.5977 Train_Acc: 70.101 Val_Loss: 0.5907  BEST VAL Loss: 0.5907  Val_Acc: 69.862

Epoch 91: Validation loss decreased (0.590699 --> 0.590500).  Saving model ...
	 Train_Loss: 0.5974 Train_Acc: 70.058 Val_Loss: 0.5905  BEST VAL Loss: 0.5905  Val_Acc: 69.602

Epoch 92: Validation loss decreased (0.590500 --> 0.590228).  Saving model ...
	 Train_Loss: 0.5971 Train_Acc: 70.143 Val_Loss: 0.5902  BEST VAL Loss: 0.5902  Val_Acc: 69.957

Epoch 93: Validation loss decreased (0.590228 --> 0.590066).  Saving model ...
	 Train_Loss: 0.5968 Train_Acc: 70.155 Val_Loss: 0.5901  BEST VAL Loss: 0.5901  Val_Acc: 69.376

Epoch 94: Validation loss decreased (0.590066 --> 0.589876).  Saving model ...
	 Train_Loss: 0.5966 Train_Acc: 70.192 Val_Loss: 0.5899  BEST VAL Loss: 0.5899  Val_Acc: 69.595

Epoch 95: Validation loss decreased (0.589876 --> 0.589697).  Saving model ...
	 Train_Loss: 0.5963 Train_Acc: 70.066 Val_Loss: 0.5897  BEST VAL Loss: 0.5897  Val_Acc: 69.460

Epoch 96: Validation loss decreased (0.589697 --> 0.589487).  Saving model ...
	 Train_Loss: 0.5960 Train_Acc: 70.326 Val_Loss: 0.5895  BEST VAL Loss: 0.5895  Val_Acc: 69.748

Epoch 97: Validation loss decreased (0.589487 --> 0.589225).  Saving model ...
	 Train_Loss: 0.5958 Train_Acc: 70.166 Val_Loss: 0.5892  BEST VAL Loss: 0.5892  Val_Acc: 70.165

Epoch 98: Validation loss decreased (0.589225 --> 0.588962).  Saving model ...
	 Train_Loss: 0.5955 Train_Acc: 70.246 Val_Loss: 0.5890  BEST VAL Loss: 0.5890  Val_Acc: 70.227

Epoch 99: Validation loss decreased (0.588962 --> 0.588726).  Saving model ...
	 Train_Loss: 0.5952 Train_Acc: 70.178 Val_Loss: 0.5887  BEST VAL Loss: 0.5887  Val_Acc: 70.129

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.70      0.81      0.75    109598
           1       0.77      0.66      0.71    109228

    accuracy                           0.73    218826
   macro avg       0.74      0.73      0.73    218826
weighted avg       0.74      0.73      0.73    218826

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.68      0.78      0.72     13700
           1       0.74      0.63      0.68     13654

    accuracy                           0.70     27354
   macro avg       0.71      0.70      0.70     27354
weighted avg       0.71      0.70      0.70     27354

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.68      0.77      0.72     13700
           1       0.73      0.63      0.68     13654

    accuracy                           0.70     27354
   macro avg       0.71      0.70      0.70     27354
weighted avg       0.71      0.70      0.70     27354

              precision    recall  f1-score   support

           0       0.68      0.77      0.72     13700
           1       0.73      0.63      0.68     13654

    accuracy                           0.70     27354
   macro avg       0.71      0.70      0.70     27354
weighted avg       0.71      0.70      0.70     27354

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.46      0.55      0.50     44168
           1       0.32      0.25      0.28     37725

    accuracy                           0.41     81893
   macro avg       0.39      0.40      0.39     81893
weighted avg       0.40      0.41      0.40     81893

              precision    recall  f1-score   support

           0       0.46      0.55      0.50     44168
           1       0.32      0.25      0.28     37725

    accuracy                           0.41     81893
   macro avg       0.39      0.40      0.39     81893
weighted avg       0.40      0.41      0.40     81893

completed
