[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ff73338d'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '09b5f6e9'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '4242612a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'd1d6c505'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Flagellin_1.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Flagellin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_Nigericin_1.000_1.0_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (270560, 1270)
Number of total missing values across all columns: 245710
Data Subset Is Off
Wells held out for testing: ['K08' 'M10']
Wells to use for training, validation, and testing ['K02' 'K03' 'K09' 'M05' 'M11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.158558).  Saving model ...
	 Train_Loss: 0.2868 Train_Acc: 88.234 Val_Loss: 0.1586  BEST VAL Loss: 0.1586  Val_Acc: 94.054

Epoch 1: Validation loss decreased (0.158558 --> 0.148648).  Saving model ...
	 Train_Loss: 0.2332 Train_Acc: 93.148 Val_Loss: 0.1486  BEST VAL Loss: 0.1486  Val_Acc: 94.907

Epoch 2: Validation loss decreased (0.148648 --> 0.141829).  Saving model ...
	 Train_Loss: 0.2072 Train_Acc: 94.258 Val_Loss: 0.1418  BEST VAL Loss: 0.1418  Val_Acc: 95.265

Epoch 3: Validation loss decreased (0.141829 --> 0.139377).  Saving model ...
	 Train_Loss: 0.1919 Train_Acc: 94.511 Val_Loss: 0.1394  BEST VAL Loss: 0.1394  Val_Acc: 95.020

Epoch 4: Validation loss decreased (0.139377 --> 0.138073).  Saving model ...
	 Train_Loss: 0.1809 Train_Acc: 94.905 Val_Loss: 0.1381  BEST VAL Loss: 0.1381  Val_Acc: 95.286

Epoch 5: Validation loss decreased (0.138073 --> 0.134056).  Saving model ...
	 Train_Loss: 0.1734 Train_Acc: 94.976 Val_Loss: 0.1341  BEST VAL Loss: 0.1341  Val_Acc: 95.766

Epoch 6: Validation loss decreased (0.134056 --> 0.131358).  Saving model ...
	 Train_Loss: 0.1673 Train_Acc: 95.040 Val_Loss: 0.1314  BEST VAL Loss: 0.1314  Val_Acc: 95.669

Epoch 7: Validation loss decreased (0.131358 --> 0.129906).  Saving model ...
	 Train_Loss: 0.1631 Train_Acc: 94.954 Val_Loss: 0.1299  BEST VAL Loss: 0.1299  Val_Acc: 95.501

Epoch 8: Validation loss decreased (0.129906 --> 0.128061).  Saving model ...
	 Train_Loss: 0.1597 Train_Acc: 94.751 Val_Loss: 0.1281  BEST VAL Loss: 0.1281  Val_Acc: 95.756

Epoch 9: Validation loss decreased (0.128061 --> 0.126330).  Saving model ...
	 Train_Loss: 0.1562 Train_Acc: 95.192 Val_Loss: 0.1263  BEST VAL Loss: 0.1263  Val_Acc: 96.078

Epoch 10: Validation loss decreased (0.126330 --> 0.124664).  Saving model ...
	 Train_Loss: 0.1527 Train_Acc: 95.300 Val_Loss: 0.1247  BEST VAL Loss: 0.1247  Val_Acc: 96.073

Epoch 11: Validation loss decreased (0.124664 --> 0.123711).  Saving model ...
	 Train_Loss: 0.1496 Train_Acc: 95.585 Val_Loss: 0.1237  BEST VAL Loss: 0.1237  Val_Acc: 96.216

Epoch 12: Validation loss decreased (0.123711 --> 0.122351).  Saving model ...
	 Train_Loss: 0.1468 Train_Acc: 95.619 Val_Loss: 0.1224  BEST VAL Loss: 0.1224  Val_Acc: 95.659

Epoch 13: Validation loss decreased (0.122351 --> 0.121340).  Saving model ...
	 Train_Loss: 0.1442 Train_Acc: 95.740 Val_Loss: 0.1213  BEST VAL Loss: 0.1213  Val_Acc: 96.160

Epoch 14: Validation loss did not decrease
	 Train_Loss: 0.1421 Train_Acc: 95.720 Val_Loss: 0.1216  BEST VAL Loss: 0.1213  Val_Acc: 95.797

Epoch 15: Validation loss did not decrease
	 Train_Loss: 0.1411 Train_Acc: 95.166 Val_Loss: 0.1227  BEST VAL Loss: 0.1213  Val_Acc: 95.122

Epoch 16: Validation loss did not decrease
	 Train_Loss: 0.1407 Train_Acc: 95.051 Val_Loss: 0.1225  BEST VAL Loss: 0.1213  Val_Acc: 96.191

Epoch 17: Validation loss did not decrease
	 Train_Loss: 0.1394 Train_Acc: 95.659 Val_Loss: 0.1223  BEST VAL Loss: 0.1213  Val_Acc: 96.140

Epoch 18: Validation loss did not decrease
	 Train_Loss: 0.1382 Train_Acc: 95.717 Val_Loss: 0.1225  BEST VAL Loss: 0.1213  Val_Acc: 95.419

Epoch 19: Validation loss did not decrease
	 Train_Loss: 0.1373 Train_Acc: 95.522 Val_Loss: 0.1217  BEST VAL Loss: 0.1213  Val_Acc: 96.201

Epoch 20: Validation loss decreased (0.121340 --> 0.121109).  Saving model ...
	 Train_Loss: 0.1361 Train_Acc: 95.887 Val_Loss: 0.1211  BEST VAL Loss: 0.1211  Val_Acc: 96.058

Epoch 21: Validation loss decreased (0.121109 --> 0.120139).  Saving model ...
	 Train_Loss: 0.1350 Train_Acc: 95.963 Val_Loss: 0.1201  BEST VAL Loss: 0.1201  Val_Acc: 96.441

Epoch 22: Validation loss decreased (0.120139 --> 0.119417).  Saving model ...
	 Train_Loss: 0.1338 Train_Acc: 96.046 Val_Loss: 0.1194  BEST VAL Loss: 0.1194  Val_Acc: 96.053

Epoch 23: Validation loss decreased (0.119417 --> 0.118992).  Saving model ...
	 Train_Loss: 0.1325 Train_Acc: 96.129 Val_Loss: 0.1190  BEST VAL Loss: 0.1190  Val_Acc: 96.354

Epoch 24: Validation loss decreased (0.118992 --> 0.118494).  Saving model ...
	 Train_Loss: 0.1315 Train_Acc: 96.032 Val_Loss: 0.1185  BEST VAL Loss: 0.1185  Val_Acc: 96.109

Epoch 25: Validation loss decreased (0.118494 --> 0.118060).  Saving model ...
	 Train_Loss: 0.1304 Train_Acc: 96.170 Val_Loss: 0.1181  BEST VAL Loss: 0.1181  Val_Acc: 96.492

Epoch 26: Validation loss decreased (0.118060 --> 0.117984).  Saving model ...
	 Train_Loss: 0.1295 Train_Acc: 96.114 Val_Loss: 0.1180  BEST VAL Loss: 0.1180  Val_Acc: 96.048

Epoch 27: Validation loss decreased (0.117984 --> 0.117707).  Saving model ...
	 Train_Loss: 0.1286 Train_Acc: 96.160 Val_Loss: 0.1177  BEST VAL Loss: 0.1177  Val_Acc: 96.446

Epoch 28: Validation loss decreased (0.117707 --> 0.117407).  Saving model ...
	 Train_Loss: 0.1277 Train_Acc: 96.083 Val_Loss: 0.1174  BEST VAL Loss: 0.1174  Val_Acc: 96.487

Epoch 29: Validation loss decreased (0.117407 --> 0.116969).  Saving model ...
	 Train_Loss: 0.1269 Train_Acc: 96.269 Val_Loss: 0.1170  BEST VAL Loss: 0.1170  Val_Acc: 95.986

Epoch 30: Validation loss decreased (0.116969 --> 0.116849).  Saving model ...
	 Train_Loss: 0.1262 Train_Acc: 96.008 Val_Loss: 0.1168  BEST VAL Loss: 0.1168  Val_Acc: 96.518

Epoch 31: Validation loss decreased (0.116849 --> 0.116399).  Saving model ...
	 Train_Loss: 0.1255 Train_Acc: 96.124 Val_Loss: 0.1164  BEST VAL Loss: 0.1164  Val_Acc: 96.666

Epoch 32: Validation loss decreased (0.116399 --> 0.116380).  Saving model ...
	 Train_Loss: 0.1246 Train_Acc: 96.425 Val_Loss: 0.1164  BEST VAL Loss: 0.1164  Val_Acc: 96.656

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.1239 Train_Acc: 96.256 Val_Loss: 0.1169  BEST VAL Loss: 0.1164  Val_Acc: 96.508

Epoch 34: Validation loss did not decrease
	 Train_Loss: 0.1233 Train_Acc: 96.242 Val_Loss: 0.1166  BEST VAL Loss: 0.1164  Val_Acc: 96.492

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.1227 Train_Acc: 96.251 Val_Loss: 0.1170  BEST VAL Loss: 0.1164  Val_Acc: 96.349

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.1221 Train_Acc: 96.357 Val_Loss: 0.1167  BEST VAL Loss: 0.1164  Val_Acc: 96.406

Epoch 37: Validation loss decreased (0.116380 --> 0.116290).  Saving model ...
	 Train_Loss: 0.1214 Train_Acc: 96.277 Val_Loss: 0.1163  BEST VAL Loss: 0.1163  Val_Acc: 96.717

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.1208 Train_Acc: 96.436 Val_Loss: 0.1166  BEST VAL Loss: 0.1163  Val_Acc: 96.441

Epoch 39: Validation loss decreased (0.116290 --> 0.116255).  Saving model ...
	 Train_Loss: 0.1202 Train_Acc: 96.356 Val_Loss: 0.1163  BEST VAL Loss: 0.1163  Val_Acc: 96.462

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.1197 Train_Acc: 96.478 Val_Loss: 0.1163  BEST VAL Loss: 0.1163  Val_Acc: 95.802

Epoch 41: Validation loss decreased (0.116255 --> 0.115964).  Saving model ...
	 Train_Loss: 0.1191 Train_Acc: 96.359 Val_Loss: 0.1160  BEST VAL Loss: 0.1160  Val_Acc: 96.804

Epoch 42: Validation loss decreased (0.115964 --> 0.115746).  Saving model ...
	 Train_Loss: 0.1185 Train_Acc: 96.594 Val_Loss: 0.1157  BEST VAL Loss: 0.1157  Val_Acc: 96.109

Epoch 43: Validation loss decreased (0.115746 --> 0.115536).  Saving model ...
	 Train_Loss: 0.1179 Train_Acc: 96.422 Val_Loss: 0.1155  BEST VAL Loss: 0.1155  Val_Acc: 96.569

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.1174 Train_Acc: 96.490 Val_Loss: 0.1157  BEST VAL Loss: 0.1155  Val_Acc: 96.431

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.1169 Train_Acc: 96.455 Val_Loss: 0.1156  BEST VAL Loss: 0.1155  Val_Acc: 96.564

Epoch 46: Validation loss decreased (0.115536 --> 0.115119).  Saving model ...
	 Train_Loss: 0.1164 Train_Acc: 96.577 Val_Loss: 0.1151  BEST VAL Loss: 0.1151  Val_Acc: 96.656

Epoch 47: Validation loss decreased (0.115119 --> 0.114956).  Saving model ...
	 Train_Loss: 0.1158 Train_Acc: 96.614 Val_Loss: 0.1150  BEST VAL Loss: 0.1150  Val_Acc: 96.344

Epoch 48: Validation loss decreased (0.114956 --> 0.114886).  Saving model ...
	 Train_Loss: 0.1153 Train_Acc: 96.532 Val_Loss: 0.1149  BEST VAL Loss: 0.1149  Val_Acc: 96.569

Epoch 49: Validation loss decreased (0.114886 --> 0.114600).  Saving model ...
	 Train_Loss: 0.1148 Train_Acc: 96.623 Val_Loss: 0.1146  BEST VAL Loss: 0.1146  Val_Acc: 96.610

Epoch 50: Validation loss decreased (0.114600 --> 0.114359).  Saving model ...
	 Train_Loss: 0.1144 Train_Acc: 96.456 Val_Loss: 0.1144  BEST VAL Loss: 0.1144  Val_Acc: 96.651

Epoch 51: Validation loss decreased (0.114359 --> 0.114207).  Saving model ...
	 Train_Loss: 0.1140 Train_Acc: 96.659 Val_Loss: 0.1142  BEST VAL Loss: 0.1142  Val_Acc: 96.753

Epoch 52: Validation loss decreased (0.114207 --> 0.114142).  Saving model ...
	 Train_Loss: 0.1135 Train_Acc: 96.634 Val_Loss: 0.1141  BEST VAL Loss: 0.1141  Val_Acc: 96.017

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.1130 Train_Acc: 96.666 Val_Loss: 0.1144  BEST VAL Loss: 0.1141  Val_Acc: 96.600

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.1126 Train_Acc: 96.510 Val_Loss: 0.1142  BEST VAL Loss: 0.1141  Val_Acc: 96.712

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.1127 Train_Acc: 96.034 Val_Loss: 0.1144  BEST VAL Loss: 0.1141  Val_Acc: 96.728

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.1126 Train_Acc: 96.400 Val_Loss: 0.1144  BEST VAL Loss: 0.1141  Val_Acc: 96.375

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.1125 Train_Acc: 96.296 Val_Loss: 0.1148  BEST VAL Loss: 0.1141  Val_Acc: 96.620

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.1123 Train_Acc: 96.354 Val_Loss: 0.1151  BEST VAL Loss: 0.1141  Val_Acc: 96.605

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.1121 Train_Acc: 96.503 Val_Loss: 0.1151  BEST VAL Loss: 0.1141  Val_Acc: 96.421

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.1119 Train_Acc: 96.439 Val_Loss: 0.1153  BEST VAL Loss: 0.1141  Val_Acc: 96.677

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.1117 Train_Acc: 96.463 Val_Loss: 0.1158  BEST VAL Loss: 0.1141  Val_Acc: 96.498

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.1115 Train_Acc: 96.525 Val_Loss: 0.1160  BEST VAL Loss: 0.1141  Val_Acc: 96.585

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.1113 Train_Acc: 96.426 Val_Loss: 0.1161  BEST VAL Loss: 0.1141  Val_Acc: 96.605

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.1111 Train_Acc: 96.615 Val_Loss: 0.1163  BEST VAL Loss: 0.1141  Val_Acc: 96.518

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.1109 Train_Acc: 96.497 Val_Loss: 0.1164  BEST VAL Loss: 0.1141  Val_Acc: 96.661

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.1107 Train_Acc: 96.567 Val_Loss: 0.1164  BEST VAL Loss: 0.1141  Val_Acc: 96.544

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.1105 Train_Acc: 96.537 Val_Loss: 0.1165  BEST VAL Loss: 0.1141  Val_Acc: 96.400

Epoch 68: Validation loss did not decrease
Early stopped at epoch : 68
Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.36      0.37      0.36     56123
           1       0.64      0.63      0.64    100339

    accuracy                           0.54    156462
   macro avg       0.50      0.50      0.50    156462
weighted avg       0.54      0.54      0.54    156462

Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.36      0.37      0.36      7015
           1       0.64      0.63      0.63     12543

    accuracy                           0.54     19558
   macro avg       0.50      0.50      0.50     19558
weighted avg       0.54      0.54      0.54     19558

Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.36      0.37      0.36      7015
           1       0.64      0.63      0.63     12543

    accuracy                           0.53     19558
   macro avg       0.50      0.50      0.50     19558
weighted avg       0.54      0.53      0.54     19558

              precision    recall  f1-score   support

           0       0.36      0.37      0.36      7015
           1       0.64      0.63      0.63     12543

    accuracy                           0.53     19558
   macro avg       0.50      0.50      0.50     19558
weighted avg       0.54      0.53      0.54     19558

Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.38      0.41     34394
           1       0.54      0.62      0.58     40588

    accuracy                           0.51     74982
   macro avg       0.50      0.50      0.50     74982
weighted avg       0.50      0.51      0.50     74982

              precision    recall  f1-score   support

           0       0.46      0.38      0.41     34394
           1       0.54      0.62      0.58     40588

    accuracy                           0.51     74982
   macro avg       0.50      0.50      0.50     74982
weighted avg       0.50      0.51      0.50     74982

completed
