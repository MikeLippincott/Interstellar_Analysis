[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1737d0a9'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'd830dd65'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '9e1ab485'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '4d5c1c44'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: H2O2_100.000_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['H2O2_100.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (41828, 1276)
Number of total missing values across all columns: 83656
Data Subset Is Off
Wells held out for testing: ['I22' 'L22']
Wells to use for training, validation, and testing ['H18' 'H19' 'H22' 'H23' 'I18' 'L18' 'I19' 'L19' 'I23' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.607707).  Saving model ...
	 Train_Loss: 0.6813 Train_Acc: 47.243 Val_Loss: 0.6077  BEST VAL Loss: 0.6077  Val_Acc: 63.702

Epoch 1: Validation loss decreased (0.607707 --> 0.592276).  Saving model ...
	 Train_Loss: 0.6521 Train_Acc: 56.837 Val_Loss: 0.5923  BEST VAL Loss: 0.5923  Val_Acc: 69.315

Epoch 2: Validation loss decreased (0.592276 --> 0.579268).  Saving model ...
	 Train_Loss: 0.6330 Train_Acc: 60.285 Val_Loss: 0.5793  BEST VAL Loss: 0.5793  Val_Acc: 70.409

Epoch 3: Validation loss decreased (0.579268 --> 0.570815).  Saving model ...
	 Train_Loss: 0.6195 Train_Acc: 67.864 Val_Loss: 0.5708  BEST VAL Loss: 0.5708  Val_Acc: 71.474

Epoch 4: Validation loss decreased (0.570815 --> 0.564922).  Saving model ...
	 Train_Loss: 0.6086 Train_Acc: 70.689 Val_Loss: 0.5649  BEST VAL Loss: 0.5649  Val_Acc: 72.280

Epoch 5: Validation loss decreased (0.564922 --> 0.560751).  Saving model ...
	 Train_Loss: 0.6006 Train_Acc: 71.034 Val_Loss: 0.5608  BEST VAL Loss: 0.5608  Val_Acc: 72.568

Epoch 6: Validation loss decreased (0.560751 --> 0.556781).  Saving model ...
	 Train_Loss: 0.5939 Train_Acc: 71.329 Val_Loss: 0.5568  BEST VAL Loss: 0.5568  Val_Acc: 72.999

Epoch 7: Validation loss decreased (0.556781 --> 0.554185).  Saving model ...
	 Train_Loss: 0.5881 Train_Acc: 71.898 Val_Loss: 0.5542  BEST VAL Loss: 0.5542  Val_Acc: 73.805

Epoch 8: Validation loss decreased (0.554185 --> 0.551242).  Saving model ...
	 Train_Loss: 0.5828 Train_Acc: 72.276 Val_Loss: 0.5512  BEST VAL Loss: 0.5512  Val_Acc: 72.827

Epoch 9: Validation loss decreased (0.551242 --> 0.548030).  Saving model ...
	 Train_Loss: 0.5781 Train_Acc: 72.247 Val_Loss: 0.5480  BEST VAL Loss: 0.5480  Val_Acc: 73.086

Epoch 10: Validation loss decreased (0.548030 --> 0.546296).  Saving model ...
	 Train_Loss: 0.5739 Train_Acc: 72.628 Val_Loss: 0.5463  BEST VAL Loss: 0.5463  Val_Acc: 73.028

Epoch 11: Validation loss decreased (0.546296 --> 0.544564).  Saving model ...
	 Train_Loss: 0.5701 Train_Acc: 72.614 Val_Loss: 0.5446  BEST VAL Loss: 0.5446  Val_Acc: 73.201

Epoch 12: Validation loss decreased (0.544564 --> 0.542625).  Saving model ...
	 Train_Loss: 0.5669 Train_Acc: 72.585 Val_Loss: 0.5426  BEST VAL Loss: 0.5426  Val_Acc: 73.316

Epoch 13: Validation loss decreased (0.542625 --> 0.540722).  Saving model ...
	 Train_Loss: 0.5639 Train_Acc: 72.521 Val_Loss: 0.5407  BEST VAL Loss: 0.5407  Val_Acc: 73.374

Epoch 14: Validation loss decreased (0.540722 --> 0.539518).  Saving model ...
	 Train_Loss: 0.5613 Train_Acc: 72.808 Val_Loss: 0.5395  BEST VAL Loss: 0.5395  Val_Acc: 72.798

Epoch 15: Validation loss decreased (0.539518 --> 0.538325).  Saving model ...
	 Train_Loss: 0.5587 Train_Acc: 73.125 Val_Loss: 0.5383  BEST VAL Loss: 0.5383  Val_Acc: 73.345

Epoch 16: Validation loss decreased (0.538325 --> 0.536841).  Saving model ...
	 Train_Loss: 0.5563 Train_Acc: 72.960 Val_Loss: 0.5368  BEST VAL Loss: 0.5368  Val_Acc: 73.575

Epoch 17: Validation loss decreased (0.536841 --> 0.535386).  Saving model ...
	 Train_Loss: 0.5542 Train_Acc: 72.963 Val_Loss: 0.5354  BEST VAL Loss: 0.5354  Val_Acc: 74.352

Epoch 18: Validation loss decreased (0.535386 --> 0.534103).  Saving model ...
	 Train_Loss: 0.5522 Train_Acc: 73.068 Val_Loss: 0.5341  BEST VAL Loss: 0.5341  Val_Acc: 73.287

Epoch 19: Validation loss decreased (0.534103 --> 0.533151).  Saving model ...
	 Train_Loss: 0.5500 Train_Acc: 73.575 Val_Loss: 0.5332  BEST VAL Loss: 0.5332  Val_Acc: 73.230

Epoch 20: Validation loss decreased (0.533151 --> 0.532414).  Saving model ...
	 Train_Loss: 0.5483 Train_Acc: 73.269 Val_Loss: 0.5324  BEST VAL Loss: 0.5324  Val_Acc: 73.892

Epoch 21: Validation loss decreased (0.532414 --> 0.531710).  Saving model ...
	 Train_Loss: 0.5466 Train_Acc: 73.532 Val_Loss: 0.5317  BEST VAL Loss: 0.5317  Val_Acc: 73.575

Epoch 22: Validation loss decreased (0.531710 --> 0.530762).  Saving model ...
	 Train_Loss: 0.5451 Train_Acc: 73.640 Val_Loss: 0.5308  BEST VAL Loss: 0.5308  Val_Acc: 73.834

Epoch 23: Validation loss decreased (0.530762 --> 0.530022).  Saving model ...
	 Train_Loss: 0.5437 Train_Acc: 73.769 Val_Loss: 0.5300  BEST VAL Loss: 0.5300  Val_Acc: 73.834

Epoch 24: Validation loss decreased (0.530022 --> 0.529291).  Saving model ...
	 Train_Loss: 0.5422 Train_Acc: 73.467 Val_Loss: 0.5293  BEST VAL Loss: 0.5293  Val_Acc: 73.431

Epoch 25: Validation loss decreased (0.529291 --> 0.528782).  Saving model ...
	 Train_Loss: 0.5409 Train_Acc: 73.535 Val_Loss: 0.5288  BEST VAL Loss: 0.5288  Val_Acc: 73.690

Epoch 26: Validation loss decreased (0.528782 --> 0.528103).  Saving model ...
	 Train_Loss: 0.5397 Train_Acc: 73.442 Val_Loss: 0.5281  BEST VAL Loss: 0.5281  Val_Acc: 73.719

Epoch 27: Validation loss decreased (0.528103 --> 0.527496).  Saving model ...
	 Train_Loss: 0.5385 Train_Acc: 73.593 Val_Loss: 0.5275  BEST VAL Loss: 0.5275  Val_Acc: 74.122

Epoch 28: Validation loss decreased (0.527496 --> 0.526912).  Saving model ...
	 Train_Loss: 0.5373 Train_Acc: 73.668 Val_Loss: 0.5269  BEST VAL Loss: 0.5269  Val_Acc: 73.690

Epoch 29: Validation loss decreased (0.526912 --> 0.526137).  Saving model ...
	 Train_Loss: 0.5362 Train_Acc: 74.057 Val_Loss: 0.5261  BEST VAL Loss: 0.5261  Val_Acc: 73.777

Epoch 30: Validation loss decreased (0.526137 --> 0.525641).  Saving model ...
	 Train_Loss: 0.5352 Train_Acc: 74.032 Val_Loss: 0.5256  BEST VAL Loss: 0.5256  Val_Acc: 74.151

Epoch 31: Validation loss decreased (0.525641 --> 0.525453).  Saving model ...
	 Train_Loss: 0.5341 Train_Acc: 74.093 Val_Loss: 0.5255  BEST VAL Loss: 0.5255  Val_Acc: 73.345

Epoch 32: Validation loss decreased (0.525453 --> 0.525151).  Saving model ...
	 Train_Loss: 0.5332 Train_Acc: 74.036 Val_Loss: 0.5252  BEST VAL Loss: 0.5252  Val_Acc: 73.316

Epoch 33: Validation loss decreased (0.525151 --> 0.524842).  Saving model ...
	 Train_Loss: 0.5323 Train_Acc: 73.571 Val_Loss: 0.5248  BEST VAL Loss: 0.5248  Val_Acc: 73.575

Epoch 34: Validation loss decreased (0.524842 --> 0.524559).  Saving model ...
	 Train_Loss: 0.5314 Train_Acc: 73.895 Val_Loss: 0.5246  BEST VAL Loss: 0.5246  Val_Acc: 73.489

Epoch 35: Validation loss decreased (0.524559 --> 0.524176).  Saving model ...
	 Train_Loss: 0.5304 Train_Acc: 73.956 Val_Loss: 0.5242  BEST VAL Loss: 0.5242  Val_Acc: 73.921

Epoch 36: Validation loss decreased (0.524176 --> 0.523789).  Saving model ...
	 Train_Loss: 0.5296 Train_Acc: 74.169 Val_Loss: 0.5238  BEST VAL Loss: 0.5238  Val_Acc: 74.007

Epoch 37: Validation loss decreased (0.523789 --> 0.523547).  Saving model ...
	 Train_Loss: 0.5288 Train_Acc: 74.054 Val_Loss: 0.5235  BEST VAL Loss: 0.5235  Val_Acc: 73.834

Epoch 38: Validation loss decreased (0.523547 --> 0.523324).  Saving model ...
	 Train_Loss: 0.5279 Train_Acc: 74.219 Val_Loss: 0.5233  BEST VAL Loss: 0.5233  Val_Acc: 74.122

Epoch 39: Validation loss decreased (0.523324 --> 0.523070).  Saving model ...
	 Train_Loss: 0.5272 Train_Acc: 74.147 Val_Loss: 0.5231  BEST VAL Loss: 0.5231  Val_Acc: 73.777

Epoch 40: Validation loss decreased (0.523070 --> 0.522879).  Saving model ...
	 Train_Loss: 0.5264 Train_Acc: 74.133 Val_Loss: 0.5229  BEST VAL Loss: 0.5229  Val_Acc: 73.546

Epoch 41: Validation loss decreased (0.522879 --> 0.522645).  Saving model ...
	 Train_Loss: 0.5257 Train_Acc: 73.924 Val_Loss: 0.5226  BEST VAL Loss: 0.5226  Val_Acc: 73.604

Epoch 42: Validation loss decreased (0.522645 --> 0.522283).  Saving model ...
	 Train_Loss: 0.5251 Train_Acc: 73.946 Val_Loss: 0.5223  BEST VAL Loss: 0.5223  Val_Acc: 74.093

Epoch 43: Validation loss decreased (0.522283 --> 0.522162).  Saving model ...
	 Train_Loss: 0.5244 Train_Acc: 74.529 Val_Loss: 0.5222  BEST VAL Loss: 0.5222  Val_Acc: 74.180

Epoch 44: Validation loss decreased (0.522162 --> 0.521837).  Saving model ...
	 Train_Loss: 0.5238 Train_Acc: 74.205 Val_Loss: 0.5218  BEST VAL Loss: 0.5218  Val_Acc: 73.690

Epoch 45: Validation loss decreased (0.521837 --> 0.521726).  Saving model ...
	 Train_Loss: 0.5231 Train_Acc: 74.133 Val_Loss: 0.5217  BEST VAL Loss: 0.5217  Val_Acc: 73.863

Epoch 46: Validation loss decreased (0.521726 --> 0.521499).  Saving model ...
	 Train_Loss: 0.5225 Train_Acc: 74.277 Val_Loss: 0.5215  BEST VAL Loss: 0.5215  Val_Acc: 73.719

Epoch 47: Validation loss decreased (0.521499 --> 0.521382).  Saving model ...
	 Train_Loss: 0.5219 Train_Acc: 74.370 Val_Loss: 0.5214  BEST VAL Loss: 0.5214  Val_Acc: 73.518

Epoch 48: Validation loss decreased (0.521382 --> 0.521255).  Saving model ...
	 Train_Loss: 0.5212 Train_Acc: 74.359 Val_Loss: 0.5213  BEST VAL Loss: 0.5213  Val_Acc: 73.863

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.5207 Train_Acc: 74.057 Val_Loss: 0.5213  BEST VAL Loss: 0.5213  Val_Acc: 73.777

Epoch 50: Validation loss decreased (0.521255 --> 0.521178).  Saving model ...
	 Train_Loss: 0.5202 Train_Acc: 74.190 Val_Loss: 0.5212  BEST VAL Loss: 0.5212  Val_Acc: 73.057

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.5196 Train_Acc: 74.410 Val_Loss: 0.5213  BEST VAL Loss: 0.5212  Val_Acc: 72.913

Epoch 52: Validation loss decreased (0.521178 --> 0.521100).  Saving model ...
	 Train_Loss: 0.5191 Train_Acc: 74.104 Val_Loss: 0.5211  BEST VAL Loss: 0.5211  Val_Acc: 74.439

Epoch 53: Validation loss decreased (0.521100 --> 0.520939).  Saving model ...
	 Train_Loss: 0.5186 Train_Acc: 74.496 Val_Loss: 0.5209  BEST VAL Loss: 0.5209  Val_Acc: 73.748

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.5181 Train_Acc: 74.550 Val_Loss: 0.5209  BEST VAL Loss: 0.5209  Val_Acc: 72.884

Epoch 55: Validation loss decreased (0.520939 --> 0.520804).  Saving model ...
	 Train_Loss: 0.5176 Train_Acc: 74.298 Val_Loss: 0.5208  BEST VAL Loss: 0.5208  Val_Acc: 73.661

Epoch 56: Validation loss decreased (0.520804 --> 0.520634).  Saving model ...
	 Train_Loss: 0.5171 Train_Acc: 74.543 Val_Loss: 0.5206  BEST VAL Loss: 0.5206  Val_Acc: 73.143

Epoch 57: Validation loss decreased (0.520634 --> 0.520608).  Saving model ...
	 Train_Loss: 0.5166 Train_Acc: 74.367 Val_Loss: 0.5206  BEST VAL Loss: 0.5206  Val_Acc: 73.978

Epoch 58: Validation loss decreased (0.520608 --> 0.520410).  Saving model ...
	 Train_Loss: 0.5161 Train_Acc: 74.313 Val_Loss: 0.5204  BEST VAL Loss: 0.5204  Val_Acc: 74.640

Epoch 59: Validation loss decreased (0.520410 --> 0.520330).  Saving model ...
	 Train_Loss: 0.5157 Train_Acc: 74.316 Val_Loss: 0.5203  BEST VAL Loss: 0.5203  Val_Acc: 73.863

Epoch 60: Validation loss decreased (0.520330 --> 0.520274).  Saving model ...
	 Train_Loss: 0.5152 Train_Acc: 74.460 Val_Loss: 0.5203  BEST VAL Loss: 0.5203  Val_Acc: 73.748

Epoch 61: Validation loss decreased (0.520274 --> 0.520179).  Saving model ...
	 Train_Loss: 0.5148 Train_Acc: 74.435 Val_Loss: 0.5202  BEST VAL Loss: 0.5202  Val_Acc: 74.036

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.5143 Train_Acc: 74.453 Val_Loss: 0.5202  BEST VAL Loss: 0.5202  Val_Acc: 73.805

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.5139 Train_Acc: 74.266 Val_Loss: 0.5202  BEST VAL Loss: 0.5202  Val_Acc: 74.180

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.5134 Train_Acc: 74.791 Val_Loss: 0.5203  BEST VAL Loss: 0.5202  Val_Acc: 74.007

Epoch 65: Validation loss decreased (0.520179 --> 0.520170).  Saving model ...
	 Train_Loss: 0.5130 Train_Acc: 74.349 Val_Loss: 0.5202  BEST VAL Loss: 0.5202  Val_Acc: 73.834

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.5126 Train_Acc: 74.431 Val_Loss: 0.5203  BEST VAL Loss: 0.5202  Val_Acc: 74.007

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.5122 Train_Acc: 74.485 Val_Loss: 0.5203  BEST VAL Loss: 0.5202  Val_Acc: 74.122

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.5119 Train_Acc: 74.496 Val_Loss: 0.5204  BEST VAL Loss: 0.5202  Val_Acc: 73.661

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.5115 Train_Acc: 74.780 Val_Loss: 0.5205  BEST VAL Loss: 0.5202  Val_Acc: 73.633

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.5111 Train_Acc: 74.500 Val_Loss: 0.5204  BEST VAL Loss: 0.5202  Val_Acc: 74.122

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.5108 Train_Acc: 74.485 Val_Loss: 0.5203  BEST VAL Loss: 0.5202  Val_Acc: 74.093

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.5104 Train_Acc: 74.762 Val_Loss: 0.5202  BEST VAL Loss: 0.5202  Val_Acc: 74.352

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.5100 Train_Acc: 74.950 Val_Loss: 0.5202  BEST VAL Loss: 0.5202  Val_Acc: 74.151

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.5096 Train_Acc: 74.536 Val_Loss: 0.5203  BEST VAL Loss: 0.5202  Val_Acc: 73.949

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.5093 Train_Acc: 74.262 Val_Loss: 0.5202  BEST VAL Loss: 0.5202  Val_Acc: 73.546

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.5090 Train_Acc: 74.503 Val_Loss: 0.5202  BEST VAL Loss: 0.5202  Val_Acc: 74.208

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.5087 Train_Acc: 74.673 Val_Loss: 0.5203  BEST VAL Loss: 0.5202  Val_Acc: 73.719

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.5084 Train_Acc: 74.514 Val_Loss: 0.5203  BEST VAL Loss: 0.5202  Val_Acc: 73.719

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.5080 Train_Acc: 74.568 Val_Loss: 0.5204  BEST VAL Loss: 0.5202  Val_Acc: 74.007

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.5077 Train_Acc: 74.532 Val_Loss: 0.5204  BEST VAL Loss: 0.5202  Val_Acc: 73.633

Epoch 81: Validation loss did not decrease
Early stopped at epoch : 81
H2O2_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.32      0.16      0.21      8635
           1       0.69      0.85      0.76     19153

    accuracy                           0.64     27788
   macro avg       0.51      0.50      0.49     27788
weighted avg       0.58      0.64      0.59     27788

H2O2_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.31      0.15      0.20      1079
           1       0.69      0.85      0.76      2395

    accuracy                           0.63      3474
   macro avg       0.50      0.50      0.48      3474
weighted avg       0.57      0.63      0.59      3474

H2O2_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.30      0.14      0.19      1079
           1       0.69      0.85      0.76      2395

    accuracy                           0.63      3474
   macro avg       0.49      0.50      0.48      3474
weighted avg       0.57      0.63      0.58      3474

              precision    recall  f1-score   support

           0       0.30      0.14      0.19      1079
           1       0.69      0.85      0.76      2395

    accuracy                           0.63      3474
   macro avg       0.49      0.50      0.48      3474
weighted avg       0.57      0.63      0.58      3474

H2O2_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.61      0.16      0.25      4135
           1       0.42      0.86      0.56      2957

    accuracy                           0.45      7092
   macro avg       0.51      0.51      0.41      7092
weighted avg       0.53      0.45      0.38      7092

              precision    recall  f1-score   support

           0       0.61      0.16      0.25      4135
           1       0.42      0.86      0.56      2957

    accuracy                           0.45      7092
   macro avg       0.51      0.51      0.41      7092
weighted avg       0.53      0.45      0.38      7092

completed
