[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '8dad325e'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '189fabe6'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'a5e3cba5'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '2c2b2659'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: Thapsigargin_10.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: Thapsigargin_10.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (341245, 1270)
Number of total missing values across all columns: 333968
Data Subset Is Off
Wells held out for testing: ['L06' 'L09']
Wells to use for training, validation, and testing ['E06' 'E07' 'L02' 'L03' 'L07' 'L08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.105859).  Saving model ...
	 Train_Loss: 0.2555 Train_Acc: 90.922 Val_Loss: 0.1059  BEST VAL Loss: 0.1059  Val_Acc: 96.098

Epoch 1: Validation loss decreased (0.105859 --> 0.095234).  Saving model ...
	 Train_Loss: 0.1963 Train_Acc: 95.348 Val_Loss: 0.0952  BEST VAL Loss: 0.0952  Val_Acc: 96.852

Epoch 2: Validation loss decreased (0.095234 --> 0.089998).  Saving model ...
	 Train_Loss: 0.1705 Train_Acc: 95.829 Val_Loss: 0.0900  BEST VAL Loss: 0.0900  Val_Acc: 97.077

Epoch 3: Validation loss decreased (0.089998 --> 0.085833).  Saving model ...
	 Train_Loss: 0.1554 Train_Acc: 96.090 Val_Loss: 0.0858  BEST VAL Loss: 0.0858  Val_Acc: 97.293

Epoch 4: Validation loss decreased (0.085833 --> 0.082207).  Saving model ...
	 Train_Loss: 0.1450 Train_Acc: 96.323 Val_Loss: 0.0822  BEST VAL Loss: 0.0822  Val_Acc: 97.552

Epoch 5: Validation loss decreased (0.082207 --> 0.079150).  Saving model ...
	 Train_Loss: 0.1371 Train_Acc: 96.563 Val_Loss: 0.0791  BEST VAL Loss: 0.0791  Val_Acc: 97.649

Epoch 6: Validation loss decreased (0.079150 --> 0.076723).  Saving model ...
	 Train_Loss: 0.1311 Train_Acc: 96.633 Val_Loss: 0.0767  BEST VAL Loss: 0.0767  Val_Acc: 97.591

Epoch 7: Validation loss decreased (0.076723 --> 0.074826).  Saving model ...
	 Train_Loss: 0.1264 Train_Acc: 96.654 Val_Loss: 0.0748  BEST VAL Loss: 0.0748  Val_Acc: 97.703

Epoch 8: Validation loss decreased (0.074826 --> 0.072866).  Saving model ...
	 Train_Loss: 0.1224 Train_Acc: 96.741 Val_Loss: 0.0729  BEST VAL Loss: 0.0729  Val_Acc: 97.846

Epoch 9: Validation loss decreased (0.072866 --> 0.071422).  Saving model ...
	 Train_Loss: 0.1190 Train_Acc: 96.815 Val_Loss: 0.0714  BEST VAL Loss: 0.0714  Val_Acc: 97.842

Epoch 10: Validation loss decreased (0.071422 --> 0.070056).  Saving model ...
	 Train_Loss: 0.1160 Train_Acc: 96.923 Val_Loss: 0.0701  BEST VAL Loss: 0.0701  Val_Acc: 98.043

Epoch 11: Validation loss decreased (0.070056 --> 0.069078).  Saving model ...
	 Train_Loss: 0.1135 Train_Acc: 96.928 Val_Loss: 0.0691  BEST VAL Loss: 0.0691  Val_Acc: 97.954

Epoch 12: Validation loss decreased (0.069078 --> 0.068358).  Saving model ...
	 Train_Loss: 0.1113 Train_Acc: 96.943 Val_Loss: 0.0684  BEST VAL Loss: 0.0684  Val_Acc: 97.947

Epoch 13: Validation loss decreased (0.068358 --> 0.067425).  Saving model ...
	 Train_Loss: 0.1093 Train_Acc: 97.008 Val_Loss: 0.0674  BEST VAL Loss: 0.0674  Val_Acc: 97.896

Epoch 14: Validation loss decreased (0.067425 --> 0.066725).  Saving model ...
	 Train_Loss: 0.1076 Train_Acc: 97.083 Val_Loss: 0.0667  BEST VAL Loss: 0.0667  Val_Acc: 98.012

Epoch 15: Validation loss decreased (0.066725 --> 0.065870).  Saving model ...
	 Train_Loss: 0.1059 Train_Acc: 97.118 Val_Loss: 0.0659  BEST VAL Loss: 0.0659  Val_Acc: 98.047

Epoch 16: Validation loss decreased (0.065870 --> 0.065206).  Saving model ...
	 Train_Loss: 0.1044 Train_Acc: 97.103 Val_Loss: 0.0652  BEST VAL Loss: 0.0652  Val_Acc: 98.070

Epoch 17: Validation loss decreased (0.065206 --> 0.064524).  Saving model ...
	 Train_Loss: 0.1028 Train_Acc: 97.202 Val_Loss: 0.0645  BEST VAL Loss: 0.0645  Val_Acc: 98.105

Epoch 18: Validation loss decreased (0.064524 --> 0.064012).  Saving model ...
	 Train_Loss: 0.1015 Train_Acc: 97.214 Val_Loss: 0.0640  BEST VAL Loss: 0.0640  Val_Acc: 98.005

Epoch 19: Validation loss decreased (0.064012 --> 0.063595).  Saving model ...
	 Train_Loss: 0.1004 Train_Acc: 97.191 Val_Loss: 0.0636  BEST VAL Loss: 0.0636  Val_Acc: 97.924

Epoch 20: Validation loss decreased (0.063595 --> 0.063176).  Saving model ...
	 Train_Loss: 0.0992 Train_Acc: 97.249 Val_Loss: 0.0632  BEST VAL Loss: 0.0632  Val_Acc: 98.074

Epoch 21: Validation loss decreased (0.063176 --> 0.062722).  Saving model ...
	 Train_Loss: 0.0982 Train_Acc: 97.217 Val_Loss: 0.0627  BEST VAL Loss: 0.0627  Val_Acc: 98.059

Epoch 22: Validation loss decreased (0.062722 --> 0.062373).  Saving model ...
	 Train_Loss: 0.0973 Train_Acc: 97.235 Val_Loss: 0.0624  BEST VAL Loss: 0.0624  Val_Acc: 98.055

Epoch 23: Validation loss decreased (0.062373 --> 0.061971).  Saving model ...
	 Train_Loss: 0.0964 Train_Acc: 97.267 Val_Loss: 0.0620  BEST VAL Loss: 0.0620  Val_Acc: 98.105

Epoch 24: Validation loss decreased (0.061971 --> 0.061586).  Saving model ...
	 Train_Loss: 0.0955 Train_Acc: 97.319 Val_Loss: 0.0616  BEST VAL Loss: 0.0616  Val_Acc: 98.194

Epoch 25: Validation loss decreased (0.061586 --> 0.061298).  Saving model ...
	 Train_Loss: 0.0946 Train_Acc: 97.353 Val_Loss: 0.0613  BEST VAL Loss: 0.0613  Val_Acc: 98.128

Epoch 26: Validation loss decreased (0.061298 --> 0.060846).  Saving model ...
	 Train_Loss: 0.0938 Train_Acc: 97.294 Val_Loss: 0.0608  BEST VAL Loss: 0.0608  Val_Acc: 98.318

Epoch 27: Validation loss decreased (0.060846 --> 0.060508).  Saving model ...
	 Train_Loss: 0.0930 Train_Acc: 97.425 Val_Loss: 0.0605  BEST VAL Loss: 0.0605  Val_Acc: 98.306

Epoch 28: Validation loss decreased (0.060508 --> 0.060278).  Saving model ...
	 Train_Loss: 0.0923 Train_Acc: 97.370 Val_Loss: 0.0603  BEST VAL Loss: 0.0603  Val_Acc: 98.221

Epoch 29: Validation loss decreased (0.060278 --> 0.059902).  Saving model ...
	 Train_Loss: 0.0916 Train_Acc: 97.460 Val_Loss: 0.0599  BEST VAL Loss: 0.0599  Val_Acc: 98.283

Epoch 30: Validation loss decreased (0.059902 --> 0.059694).  Saving model ...
	 Train_Loss: 0.0910 Train_Acc: 97.425 Val_Loss: 0.0597  BEST VAL Loss: 0.0597  Val_Acc: 98.098

Epoch 31: Validation loss decreased (0.059694 --> 0.059345).  Saving model ...
	 Train_Loss: 0.0904 Train_Acc: 97.361 Val_Loss: 0.0593  BEST VAL Loss: 0.0593  Val_Acc: 98.268

Epoch 32: Validation loss decreased (0.059345 --> 0.059162).  Saving model ...
	 Train_Loss: 0.0898 Train_Acc: 97.424 Val_Loss: 0.0592  BEST VAL Loss: 0.0592  Val_Acc: 98.156

Epoch 33: Validation loss decreased (0.059162 --> 0.058879).  Saving model ...
	 Train_Loss: 0.0892 Train_Acc: 97.491 Val_Loss: 0.0589  BEST VAL Loss: 0.0589  Val_Acc: 98.260

Epoch 34: Validation loss decreased (0.058879 --> 0.058674).  Saving model ...
	 Train_Loss: 0.0887 Train_Acc: 97.422 Val_Loss: 0.0587  BEST VAL Loss: 0.0587  Val_Acc: 98.210

Epoch 35: Validation loss decreased (0.058674 --> 0.058476).  Saving model ...
	 Train_Loss: 0.0882 Train_Acc: 97.472 Val_Loss: 0.0585  BEST VAL Loss: 0.0585  Val_Acc: 98.229

Epoch 36: Validation loss decreased (0.058476 --> 0.058283).  Saving model ...
	 Train_Loss: 0.0877 Train_Acc: 97.465 Val_Loss: 0.0583  BEST VAL Loss: 0.0583  Val_Acc: 98.171

Epoch 37: Validation loss decreased (0.058283 --> 0.058016).  Saving model ...
	 Train_Loss: 0.0872 Train_Acc: 97.441 Val_Loss: 0.0580  BEST VAL Loss: 0.0580  Val_Acc: 98.306

Epoch 38: Validation loss decreased (0.058016 --> 0.057865).  Saving model ...
	 Train_Loss: 0.0868 Train_Acc: 97.432 Val_Loss: 0.0579  BEST VAL Loss: 0.0579  Val_Acc: 98.299

Epoch 39: Validation loss decreased (0.057865 --> 0.057768).  Saving model ...
	 Train_Loss: 0.0863 Train_Acc: 97.506 Val_Loss: 0.0578  BEST VAL Loss: 0.0578  Val_Acc: 98.248

Epoch 40: Validation loss decreased (0.057768 --> 0.057550).  Saving model ...
	 Train_Loss: 0.0859 Train_Acc: 97.532 Val_Loss: 0.0575  BEST VAL Loss: 0.0575  Val_Acc: 98.287

Epoch 41: Validation loss decreased (0.057550 --> 0.057363).  Saving model ...
	 Train_Loss: 0.0854 Train_Acc: 97.537 Val_Loss: 0.0574  BEST VAL Loss: 0.0574  Val_Acc: 98.337

Epoch 42: Validation loss decreased (0.057363 --> 0.057198).  Saving model ...
	 Train_Loss: 0.0850 Train_Acc: 97.481 Val_Loss: 0.0572  BEST VAL Loss: 0.0572  Val_Acc: 98.345

Epoch 43: Validation loss decreased (0.057198 --> 0.056985).  Saving model ...
	 Train_Loss: 0.0846 Train_Acc: 97.501 Val_Loss: 0.0570  BEST VAL Loss: 0.0570  Val_Acc: 98.186

Epoch 44: Validation loss decreased (0.056985 --> 0.056838).  Saving model ...
	 Train_Loss: 0.0843 Train_Acc: 97.501 Val_Loss: 0.0568  BEST VAL Loss: 0.0568  Val_Acc: 98.380

Epoch 45: Validation loss decreased (0.056838 --> 0.056689).  Saving model ...
	 Train_Loss: 0.0839 Train_Acc: 97.522 Val_Loss: 0.0567  BEST VAL Loss: 0.0567  Val_Acc: 98.295

Epoch 46: Validation loss decreased (0.056689 --> 0.056570).  Saving model ...
	 Train_Loss: 0.0836 Train_Acc: 97.547 Val_Loss: 0.0566  BEST VAL Loss: 0.0566  Val_Acc: 98.248

Epoch 47: Validation loss decreased (0.056570 --> 0.056352).  Saving model ...
	 Train_Loss: 0.0832 Train_Acc: 97.564 Val_Loss: 0.0564  BEST VAL Loss: 0.0564  Val_Acc: 98.388

Epoch 48: Validation loss decreased (0.056352 --> 0.056176).  Saving model ...
	 Train_Loss: 0.0829 Train_Acc: 97.512 Val_Loss: 0.0562  BEST VAL Loss: 0.0562  Val_Acc: 98.395

Epoch 49: Validation loss decreased (0.056176 --> 0.056032).  Saving model ...
	 Train_Loss: 0.0825 Train_Acc: 97.569 Val_Loss: 0.0560  BEST VAL Loss: 0.0560  Val_Acc: 98.372

Epoch 50: Validation loss decreased (0.056032 --> 0.055938).  Saving model ...
	 Train_Loss: 0.0822 Train_Acc: 97.611 Val_Loss: 0.0559  BEST VAL Loss: 0.0559  Val_Acc: 98.341

Epoch 51: Validation loss decreased (0.055938 --> 0.055853).  Saving model ...
	 Train_Loss: 0.0819 Train_Acc: 97.577 Val_Loss: 0.0559  BEST VAL Loss: 0.0559  Val_Acc: 98.380

Epoch 52: Validation loss decreased (0.055853 --> 0.055752).  Saving model ...
	 Train_Loss: 0.0816 Train_Acc: 97.567 Val_Loss: 0.0558  BEST VAL Loss: 0.0558  Val_Acc: 98.272

Epoch 53: Validation loss decreased (0.055752 --> 0.055672).  Saving model ...
	 Train_Loss: 0.0813 Train_Acc: 97.640 Val_Loss: 0.0557  BEST VAL Loss: 0.0557  Val_Acc: 98.314

Epoch 54: Validation loss decreased (0.055672 --> 0.055585).  Saving model ...
	 Train_Loss: 0.0810 Train_Acc: 97.604 Val_Loss: 0.0556  BEST VAL Loss: 0.0556  Val_Acc: 98.380

Epoch 55: Validation loss decreased (0.055585 --> 0.055490).  Saving model ...
	 Train_Loss: 0.0807 Train_Acc: 97.637 Val_Loss: 0.0555  BEST VAL Loss: 0.0555  Val_Acc: 98.368

Epoch 56: Validation loss decreased (0.055490 --> 0.055426).  Saving model ...
	 Train_Loss: 0.0804 Train_Acc: 97.678 Val_Loss: 0.0554  BEST VAL Loss: 0.0554  Val_Acc: 98.349

Epoch 57: Validation loss decreased (0.055426 --> 0.055322).  Saving model ...
	 Train_Loss: 0.0801 Train_Acc: 97.661 Val_Loss: 0.0553  BEST VAL Loss: 0.0553  Val_Acc: 98.291

Epoch 58: Validation loss decreased (0.055322 --> 0.055242).  Saving model ...
	 Train_Loss: 0.0799 Train_Acc: 97.680 Val_Loss: 0.0552  BEST VAL Loss: 0.0552  Val_Acc: 98.333

Epoch 59: Validation loss decreased (0.055242 --> 0.055172).  Saving model ...
	 Train_Loss: 0.0796 Train_Acc: 97.617 Val_Loss: 0.0552  BEST VAL Loss: 0.0552  Val_Acc: 98.372

Epoch 60: Validation loss decreased (0.055172 --> 0.055069).  Saving model ...
	 Train_Loss: 0.0794 Train_Acc: 97.647 Val_Loss: 0.0551  BEST VAL Loss: 0.0551  Val_Acc: 98.380

Epoch 61: Validation loss decreased (0.055069 --> 0.054965).  Saving model ...
	 Train_Loss: 0.0791 Train_Acc: 97.641 Val_Loss: 0.0550  BEST VAL Loss: 0.0550  Val_Acc: 98.418

Epoch 62: Validation loss decreased (0.054965 --> 0.054837).  Saving model ...
	 Train_Loss: 0.0788 Train_Acc: 97.704 Val_Loss: 0.0548  BEST VAL Loss: 0.0548  Val_Acc: 98.395

Epoch 63: Validation loss decreased (0.054837 --> 0.054735).  Saving model ...
	 Train_Loss: 0.0786 Train_Acc: 97.691 Val_Loss: 0.0547  BEST VAL Loss: 0.0547  Val_Acc: 98.449

Epoch 64: Validation loss decreased (0.054735 --> 0.054717).  Saving model ...
	 Train_Loss: 0.0784 Train_Acc: 97.679 Val_Loss: 0.0547  BEST VAL Loss: 0.0547  Val_Acc: 98.364

Epoch 65: Validation loss decreased (0.054717 --> 0.054603).  Saving model ...
	 Train_Loss: 0.0781 Train_Acc: 97.695 Val_Loss: 0.0546  BEST VAL Loss: 0.0546  Val_Acc: 98.357

Epoch 66: Validation loss decreased (0.054603 --> 0.054554).  Saving model ...
	 Train_Loss: 0.0779 Train_Acc: 97.729 Val_Loss: 0.0546  BEST VAL Loss: 0.0546  Val_Acc: 98.283

Epoch 67: Validation loss decreased (0.054554 --> 0.054528).  Saving model ...
	 Train_Loss: 0.0777 Train_Acc: 97.660 Val_Loss: 0.0545  BEST VAL Loss: 0.0545  Val_Acc: 98.341

Epoch 68: Validation loss decreased (0.054528 --> 0.054469).  Saving model ...
	 Train_Loss: 0.0774 Train_Acc: 97.701 Val_Loss: 0.0545  BEST VAL Loss: 0.0545  Val_Acc: 98.337

Epoch 69: Validation loss decreased (0.054469 --> 0.054386).  Saving model ...
	 Train_Loss: 0.0772 Train_Acc: 97.709 Val_Loss: 0.0544  BEST VAL Loss: 0.0544  Val_Acc: 98.395

Epoch 70: Validation loss decreased (0.054386 --> 0.054343).  Saving model ...
	 Train_Loss: 0.0770 Train_Acc: 97.709 Val_Loss: 0.0543  BEST VAL Loss: 0.0543  Val_Acc: 98.422

Epoch 71: Validation loss decreased (0.054343 --> 0.054291).  Saving model ...
	 Train_Loss: 0.0768 Train_Acc: 97.741 Val_Loss: 0.0543  BEST VAL Loss: 0.0543  Val_Acc: 98.403

Epoch 72: Validation loss decreased (0.054291 --> 0.054216).  Saving model ...
	 Train_Loss: 0.0766 Train_Acc: 97.743 Val_Loss: 0.0542  BEST VAL Loss: 0.0542  Val_Acc: 98.380

Epoch 73: Validation loss decreased (0.054216 --> 0.054145).  Saving model ...
	 Train_Loss: 0.0764 Train_Acc: 97.742 Val_Loss: 0.0541  BEST VAL Loss: 0.0541  Val_Acc: 98.446

Epoch 74: Validation loss decreased (0.054145 --> 0.054139).  Saving model ...
	 Train_Loss: 0.0762 Train_Acc: 97.749 Val_Loss: 0.0541  BEST VAL Loss: 0.0541  Val_Acc: 98.302

Epoch 75: Validation loss decreased (0.054139 --> 0.054087).  Saving model ...
	 Train_Loss: 0.0761 Train_Acc: 97.654 Val_Loss: 0.0541  BEST VAL Loss: 0.0541  Val_Acc: 98.395

Epoch 76: Validation loss decreased (0.054087 --> 0.054059).  Saving model ...
	 Train_Loss: 0.0759 Train_Acc: 97.770 Val_Loss: 0.0541  BEST VAL Loss: 0.0541  Val_Acc: 98.415

Epoch 77: Validation loss decreased (0.054059 --> 0.053975).  Saving model ...
	 Train_Loss: 0.0757 Train_Acc: 97.767 Val_Loss: 0.0540  BEST VAL Loss: 0.0540  Val_Acc: 98.476

Epoch 78: Validation loss decreased (0.053975 --> 0.053932).  Saving model ...
	 Train_Loss: 0.0755 Train_Acc: 97.780 Val_Loss: 0.0539  BEST VAL Loss: 0.0539  Val_Acc: 98.422

Epoch 79: Validation loss decreased (0.053932 --> 0.053855).  Saving model ...
	 Train_Loss: 0.0753 Train_Acc: 97.750 Val_Loss: 0.0539  BEST VAL Loss: 0.0539  Val_Acc: 98.492

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.0752 Train_Acc: 97.762 Val_Loss: 0.0539  BEST VAL Loss: 0.0539  Val_Acc: 98.353

Epoch 81: Validation loss decreased (0.053855 --> 0.053823).  Saving model ...
	 Train_Loss: 0.0750 Train_Acc: 97.774 Val_Loss: 0.0538  BEST VAL Loss: 0.0538  Val_Acc: 98.337

Epoch 82: Validation loss decreased (0.053823 --> 0.053751).  Saving model ...
	 Train_Loss: 0.0748 Train_Acc: 97.788 Val_Loss: 0.0538  BEST VAL Loss: 0.0538  Val_Acc: 98.395

Epoch 83: Validation loss decreased (0.053751 --> 0.053704).  Saving model ...
	 Train_Loss: 0.0746 Train_Acc: 97.821 Val_Loss: 0.0537  BEST VAL Loss: 0.0537  Val_Acc: 98.496

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.0745 Train_Acc: 97.746 Val_Loss: 0.0537  BEST VAL Loss: 0.0537  Val_Acc: 98.322

Epoch 85: Validation loss decreased (0.053704 --> 0.053670).  Saving model ...
	 Train_Loss: 0.0743 Train_Acc: 97.816 Val_Loss: 0.0537  BEST VAL Loss: 0.0537  Val_Acc: 98.360

Epoch 86: Validation loss decreased (0.053670 --> 0.053653).  Saving model ...
	 Train_Loss: 0.0741 Train_Acc: 97.799 Val_Loss: 0.0537  BEST VAL Loss: 0.0537  Val_Acc: 98.438

Epoch 87: Validation loss decreased (0.053653 --> 0.053602).  Saving model ...
	 Train_Loss: 0.0740 Train_Acc: 97.837 Val_Loss: 0.0536  BEST VAL Loss: 0.0536  Val_Acc: 98.403

Epoch 88: Validation loss decreased (0.053602 --> 0.053558).  Saving model ...
	 Train_Loss: 0.0738 Train_Acc: 97.838 Val_Loss: 0.0536  BEST VAL Loss: 0.0536  Val_Acc: 98.415

Epoch 89: Validation loss decreased (0.053558 --> 0.053522).  Saving model ...
	 Train_Loss: 0.0737 Train_Acc: 97.825 Val_Loss: 0.0535  BEST VAL Loss: 0.0535  Val_Acc: 98.407

Epoch 90: Validation loss decreased (0.053522 --> 0.053493).  Saving model ...
	 Train_Loss: 0.0735 Train_Acc: 97.783 Val_Loss: 0.0535  BEST VAL Loss: 0.0535  Val_Acc: 98.426

Epoch 91: Validation loss decreased (0.053493 --> 0.053475).  Saving model ...
	 Train_Loss: 0.0734 Train_Acc: 97.827 Val_Loss: 0.0535  BEST VAL Loss: 0.0535  Val_Acc: 98.411

Epoch 92: Validation loss decreased (0.053475 --> 0.053447).  Saving model ...
	 Train_Loss: 0.0732 Train_Acc: 97.787 Val_Loss: 0.0534  BEST VAL Loss: 0.0534  Val_Acc: 98.411

Epoch 93: Validation loss decreased (0.053447 --> 0.053383).  Saving model ...
	 Train_Loss: 0.0731 Train_Acc: 97.858 Val_Loss: 0.0534  BEST VAL Loss: 0.0534  Val_Acc: 98.480

Epoch 94: Validation loss decreased (0.053383 --> 0.053378).  Saving model ...
	 Train_Loss: 0.0729 Train_Acc: 97.814 Val_Loss: 0.0534  BEST VAL Loss: 0.0534  Val_Acc: 98.395

Epoch 95: Validation loss decreased (0.053378 --> 0.053335).  Saving model ...
	 Train_Loss: 0.0728 Train_Acc: 97.848 Val_Loss: 0.0533  BEST VAL Loss: 0.0533  Val_Acc: 98.457

Epoch 96: Validation loss did not decrease
	 Train_Loss: 0.0726 Train_Acc: 97.810 Val_Loss: 0.0533  BEST VAL Loss: 0.0533  Val_Acc: 98.469

Epoch 97: Validation loss decreased (0.053335 --> 0.053301).  Saving model ...
	 Train_Loss: 0.0725 Train_Acc: 97.789 Val_Loss: 0.0533  BEST VAL Loss: 0.0533  Val_Acc: 98.426

Epoch 98: Validation loss decreased (0.053301 --> 0.053289).  Saving model ...
	 Train_Loss: 0.0724 Train_Acc: 97.895 Val_Loss: 0.0533  BEST VAL Loss: 0.0533  Val_Acc: 98.418

Epoch 99: Validation loss decreased (0.053289 --> 0.053273).  Saving model ...
	 Train_Loss: 0.0722 Train_Acc: 97.872 Val_Loss: 0.0533  BEST VAL Loss: 0.0533  Val_Acc: 98.380

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      0.99      0.99    109228
           1       0.99      0.99      0.99     97655

    accuracy                           0.99    206883
   macro avg       0.99      0.99      0.99    206883
weighted avg       0.99      0.99      0.99    206883

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      0.98      0.98     13654
           1       0.98      0.99      0.98     12207

    accuracy                           0.98     25861
   macro avg       0.98      0.98      0.98     25861
weighted avg       0.98      0.98      0.98     25861

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      0.98      0.99     13654
           1       0.98      0.99      0.98     12207

    accuracy                           0.98     25861
   macro avg       0.98      0.99      0.98     25861
weighted avg       0.98      0.98      0.98     25861

              precision    recall  f1-score   support

           0       0.99      0.98      0.99     13654
           1       0.98      0.99      0.98     12207

    accuracy                           0.98     25861
   macro avg       0.98      0.99      0.98     25861
weighted avg       0.98      0.98      0.98     25861

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.96      1.00      0.98     37725
           1       1.00      0.97      0.98     44915

    accuracy                           0.98     82640
   macro avg       0.98      0.98      0.98     82640
weighted avg       0.98      0.98      0.98     82640

              precision    recall  f1-score   support

           0       0.96      1.00      0.98     37725
           1       1.00      0.97      0.98     44915

    accuracy                           0.98     82640
   macro avg       0.98      0.98      0.98     82640
weighted avg       0.98      0.98      0.98     82640

completed
