[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd4bf0f37'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '750035a5'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '79a519df'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'ab48aae5'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Thapsigargin_10.000_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Thapsigargin_10.000_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (326419, 1270)
Number of total missing values across all columns: 652838
Data Subset Is Off
Wells held out for testing: ['J09' 'L06']
Wells to use for training, validation, and testing ['E06' 'E07' 'J02' 'J03' 'J08' 'L07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.367569).  Saving model ...
	 Train_Loss: 0.4932 Train_Acc: 76.594 Val_Loss: 0.3676  BEST VAL Loss: 0.3676  Val_Acc: 83.421

Epoch 1: Validation loss decreased (0.367569 --> 0.361099).  Saving model ...
	 Train_Loss: 0.4485 Train_Acc: 81.519 Val_Loss: 0.3611  BEST VAL Loss: 0.3611  Val_Acc: 84.743

Epoch 2: Validation loss decreased (0.361099 --> 0.346094).  Saving model ...
	 Train_Loss: 0.4249 Train_Acc: 82.785 Val_Loss: 0.3461  BEST VAL Loss: 0.3461  Val_Acc: 86.049

Epoch 3: Validation loss decreased (0.346094 --> 0.336739).  Saving model ...
	 Train_Loss: 0.4096 Train_Acc: 83.502 Val_Loss: 0.3367  BEST VAL Loss: 0.3367  Val_Acc: 86.813

Epoch 4: Validation loss decreased (0.336739 --> 0.328198).  Saving model ...
	 Train_Loss: 0.3983 Train_Acc: 84.025 Val_Loss: 0.3282  BEST VAL Loss: 0.3282  Val_Acc: 87.383

Epoch 5: Validation loss decreased (0.328198 --> 0.322569).  Saving model ...
	 Train_Loss: 0.3894 Train_Acc: 84.334 Val_Loss: 0.3226  BEST VAL Loss: 0.3226  Val_Acc: 87.553

Epoch 6: Validation loss decreased (0.322569 --> 0.316663).  Saving model ...
	 Train_Loss: 0.3824 Train_Acc: 84.417 Val_Loss: 0.3167  BEST VAL Loss: 0.3167  Val_Acc: 87.958

Epoch 7: Validation loss decreased (0.316663 --> 0.311823).  Saving model ...
	 Train_Loss: 0.3764 Train_Acc: 84.845 Val_Loss: 0.3118  BEST VAL Loss: 0.3118  Val_Acc: 87.821

Epoch 8: Validation loss decreased (0.311823 --> 0.307976).  Saving model ...
	 Train_Loss: 0.3715 Train_Acc: 84.936 Val_Loss: 0.3080  BEST VAL Loss: 0.3080  Val_Acc: 88.342

Epoch 9: Validation loss decreased (0.307976 --> 0.303897).  Saving model ...
	 Train_Loss: 0.3670 Train_Acc: 85.190 Val_Loss: 0.3039  BEST VAL Loss: 0.3039  Val_Acc: 88.875

Epoch 10: Validation loss decreased (0.303897 --> 0.301320).  Saving model ...
	 Train_Loss: 0.3631 Train_Acc: 85.314 Val_Loss: 0.3013  BEST VAL Loss: 0.3013  Val_Acc: 88.230

Epoch 11: Validation loss decreased (0.301320 --> 0.298688).  Saving model ...
	 Train_Loss: 0.3597 Train_Acc: 85.371 Val_Loss: 0.2987  BEST VAL Loss: 0.2987  Val_Acc: 88.412

Epoch 12: Validation loss decreased (0.298688 --> 0.295938).  Saving model ...
	 Train_Loss: 0.3568 Train_Acc: 85.320 Val_Loss: 0.2959  BEST VAL Loss: 0.2959  Val_Acc: 89.147

Epoch 13: Validation loss decreased (0.295938 --> 0.293940).  Saving model ...
	 Train_Loss: 0.3542 Train_Acc: 85.345 Val_Loss: 0.2939  BEST VAL Loss: 0.2939  Val_Acc: 88.466

Epoch 14: Validation loss decreased (0.293940 --> 0.291688).  Saving model ...
	 Train_Loss: 0.3517 Train_Acc: 85.486 Val_Loss: 0.2917  BEST VAL Loss: 0.2917  Val_Acc: 89.015

Epoch 15: Validation loss decreased (0.291688 --> 0.289443).  Saving model ...
	 Train_Loss: 0.3495 Train_Acc: 85.566 Val_Loss: 0.2894  BEST VAL Loss: 0.2894  Val_Acc: 89.284

Epoch 16: Validation loss decreased (0.289443 --> 0.287619).  Saving model ...
	 Train_Loss: 0.3474 Train_Acc: 85.665 Val_Loss: 0.2876  BEST VAL Loss: 0.2876  Val_Acc: 89.432

Epoch 17: Validation loss decreased (0.287619 --> 0.286471).  Saving model ...
	 Train_Loss: 0.3455 Train_Acc: 85.680 Val_Loss: 0.2865  BEST VAL Loss: 0.2865  Val_Acc: 88.532

Epoch 18: Validation loss decreased (0.286471 --> 0.284745).  Saving model ...
	 Train_Loss: 0.3437 Train_Acc: 85.781 Val_Loss: 0.2847  BEST VAL Loss: 0.2847  Val_Acc: 89.317

Epoch 19: Validation loss decreased (0.284745 --> 0.283103).  Saving model ...
	 Train_Loss: 0.3420 Train_Acc: 85.790 Val_Loss: 0.2831  BEST VAL Loss: 0.2831  Val_Acc: 89.515

Epoch 20: Validation loss decreased (0.283103 --> 0.281817).  Saving model ...
	 Train_Loss: 0.3404 Train_Acc: 85.912 Val_Loss: 0.2818  BEST VAL Loss: 0.2818  Val_Acc: 89.147

Epoch 21: Validation loss decreased (0.281817 --> 0.280869).  Saving model ...
	 Train_Loss: 0.3389 Train_Acc: 85.833 Val_Loss: 0.2809  BEST VAL Loss: 0.2809  Val_Acc: 89.056

Epoch 22: Validation loss decreased (0.280869 --> 0.279866).  Saving model ...
	 Train_Loss: 0.3376 Train_Acc: 85.887 Val_Loss: 0.2799  BEST VAL Loss: 0.2799  Val_Acc: 89.370

Epoch 23: Validation loss decreased (0.279866 --> 0.278867).  Saving model ...
	 Train_Loss: 0.3363 Train_Acc: 85.930 Val_Loss: 0.2789  BEST VAL Loss: 0.2789  Val_Acc: 89.023

Epoch 24: Validation loss decreased (0.278867 --> 0.277514).  Saving model ...
	 Train_Loss: 0.3351 Train_Acc: 85.910 Val_Loss: 0.2775  BEST VAL Loss: 0.2775  Val_Acc: 89.920

Epoch 25: Validation loss decreased (0.277514 --> 0.276329).  Saving model ...
	 Train_Loss: 0.3339 Train_Acc: 85.997 Val_Loss: 0.2763  BEST VAL Loss: 0.2763  Val_Acc: 89.655

Epoch 26: Validation loss decreased (0.276329 --> 0.275247).  Saving model ...
	 Train_Loss: 0.3329 Train_Acc: 86.012 Val_Loss: 0.2752  BEST VAL Loss: 0.2752  Val_Acc: 89.643

Epoch 27: Validation loss decreased (0.275247 --> 0.274224).  Saving model ...
	 Train_Loss: 0.3318 Train_Acc: 85.996 Val_Loss: 0.2742  BEST VAL Loss: 0.2742  Val_Acc: 89.490

Epoch 28: Validation loss decreased (0.274224 --> 0.273563).  Saving model ...
	 Train_Loss: 0.3308 Train_Acc: 86.064 Val_Loss: 0.2736  BEST VAL Loss: 0.2736  Val_Acc: 89.482

Epoch 29: Validation loss decreased (0.273563 --> 0.272717).  Saving model ...
	 Train_Loss: 0.3298 Train_Acc: 86.072 Val_Loss: 0.2727  BEST VAL Loss: 0.2727  Val_Acc: 89.668

Epoch 30: Validation loss decreased (0.272717 --> 0.271870).  Saving model ...
	 Train_Loss: 0.3289 Train_Acc: 86.183 Val_Loss: 0.2719  BEST VAL Loss: 0.2719  Val_Acc: 89.767

Epoch 31: Validation loss decreased (0.271870 --> 0.270908).  Saving model ...
	 Train_Loss: 0.3280 Train_Acc: 86.126 Val_Loss: 0.2709  BEST VAL Loss: 0.2709  Val_Acc: 89.932

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.3271 Train_Acc: 86.226 Val_Loss: 0.2710  BEST VAL Loss: 0.2709  Val_Acc: 88.218

Epoch 33: Validation loss decreased (0.270908 --> 0.270075).  Saving model ...
	 Train_Loss: 0.3263 Train_Acc: 86.294 Val_Loss: 0.2701  BEST VAL Loss: 0.2701  Val_Acc: 90.106

Epoch 34: Validation loss decreased (0.270075 --> 0.269237).  Saving model ...
	 Train_Loss: 0.3255 Train_Acc: 86.137 Val_Loss: 0.2692  BEST VAL Loss: 0.2692  Val_Acc: 90.002

Epoch 35: Validation loss decreased (0.269237 --> 0.268571).  Saving model ...
	 Train_Loss: 0.3248 Train_Acc: 86.182 Val_Loss: 0.2686  BEST VAL Loss: 0.2686  Val_Acc: 89.854

Epoch 36: Validation loss decreased (0.268571 --> 0.267756).  Saving model ...
	 Train_Loss: 0.3240 Train_Acc: 86.340 Val_Loss: 0.2678  BEST VAL Loss: 0.2678  Val_Acc: 89.994

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.3233 Train_Acc: 86.337 Val_Loss: 0.2678  BEST VAL Loss: 0.2678  Val_Acc: 88.400

Epoch 38: Validation loss decreased (0.267756 --> 0.267168).  Saving model ...
	 Train_Loss: 0.3226 Train_Acc: 86.308 Val_Loss: 0.2672  BEST VAL Loss: 0.2672  Val_Acc: 89.978

Epoch 39: Validation loss decreased (0.267168 --> 0.266485).  Saving model ...
	 Train_Loss: 0.3219 Train_Acc: 86.266 Val_Loss: 0.2665  BEST VAL Loss: 0.2665  Val_Acc: 90.048

Epoch 40: Validation loss decreased (0.266485 --> 0.265860).  Saving model ...
	 Train_Loss: 0.3213 Train_Acc: 86.365 Val_Loss: 0.2659  BEST VAL Loss: 0.2659  Val_Acc: 89.932

Epoch 41: Validation loss decreased (0.265860 --> 0.265335).  Saving model ...
	 Train_Loss: 0.3207 Train_Acc: 86.315 Val_Loss: 0.2653  BEST VAL Loss: 0.2653  Val_Acc: 89.916

Epoch 42: Validation loss decreased (0.265335 --> 0.264815).  Saving model ...
	 Train_Loss: 0.3201 Train_Acc: 86.364 Val_Loss: 0.2648  BEST VAL Loss: 0.2648  Val_Acc: 89.821

Epoch 43: Validation loss decreased (0.264815 --> 0.264329).  Saving model ...
	 Train_Loss: 0.3195 Train_Acc: 86.357 Val_Loss: 0.2643  BEST VAL Loss: 0.2643  Val_Acc: 89.969

Epoch 44: Validation loss decreased (0.264329 --> 0.263782).  Saving model ...
	 Train_Loss: 0.3189 Train_Acc: 86.319 Val_Loss: 0.2638  BEST VAL Loss: 0.2638  Val_Acc: 89.858

Epoch 45: Validation loss decreased (0.263782 --> 0.263353).  Saving model ...
	 Train_Loss: 0.3184 Train_Acc: 86.417 Val_Loss: 0.2634  BEST VAL Loss: 0.2634  Val_Acc: 89.784

Epoch 46: Validation loss decreased (0.263353 --> 0.262807).  Saving model ...
	 Train_Loss: 0.3179 Train_Acc: 86.388 Val_Loss: 0.2628  BEST VAL Loss: 0.2628  Val_Acc: 90.188

Epoch 47: Validation loss decreased (0.262807 --> 0.262318).  Saving model ...
	 Train_Loss: 0.3174 Train_Acc: 86.410 Val_Loss: 0.2623  BEST VAL Loss: 0.2623  Val_Acc: 90.114

Epoch 48: Validation loss decreased (0.262318 --> 0.261748).  Saving model ...
	 Train_Loss: 0.3168 Train_Acc: 86.542 Val_Loss: 0.2617  BEST VAL Loss: 0.2617  Val_Acc: 90.213

Epoch 49: Validation loss decreased (0.261748 --> 0.261358).  Saving model ...
	 Train_Loss: 0.3163 Train_Acc: 86.530 Val_Loss: 0.2614  BEST VAL Loss: 0.2614  Val_Acc: 89.965

Epoch 50: Validation loss decreased (0.261358 --> 0.260922).  Saving model ...
	 Train_Loss: 0.3159 Train_Acc: 86.411 Val_Loss: 0.2609  BEST VAL Loss: 0.2609  Val_Acc: 89.994

Epoch 51: Validation loss decreased (0.260922 --> 0.260567).  Saving model ...
	 Train_Loss: 0.3154 Train_Acc: 86.464 Val_Loss: 0.2606  BEST VAL Loss: 0.2606  Val_Acc: 90.085

Epoch 52: Validation loss decreased (0.260567 --> 0.260149).  Saving model ...
	 Train_Loss: 0.3150 Train_Acc: 86.571 Val_Loss: 0.2601  BEST VAL Loss: 0.2601  Val_Acc: 89.969

Epoch 53: Validation loss decreased (0.260149 --> 0.259713).  Saving model ...
	 Train_Loss: 0.3145 Train_Acc: 86.445 Val_Loss: 0.2597  BEST VAL Loss: 0.2597  Val_Acc: 90.374

Epoch 54: Validation loss decreased (0.259713 --> 0.259252).  Saving model ...
	 Train_Loss: 0.3141 Train_Acc: 86.630 Val_Loss: 0.2593  BEST VAL Loss: 0.2593  Val_Acc: 90.391

Epoch 55: Validation loss decreased (0.259252 --> 0.258995).  Saving model ...
	 Train_Loss: 0.3136 Train_Acc: 86.560 Val_Loss: 0.2590  BEST VAL Loss: 0.2590  Val_Acc: 89.680

Epoch 56: Validation loss decreased (0.258995 --> 0.258645).  Saving model ...
	 Train_Loss: 0.3132 Train_Acc: 86.499 Val_Loss: 0.2586  BEST VAL Loss: 0.2586  Val_Acc: 90.118

Epoch 57: Validation loss decreased (0.258645 --> 0.258261).  Saving model ...
	 Train_Loss: 0.3129 Train_Acc: 86.525 Val_Loss: 0.2583  BEST VAL Loss: 0.2583  Val_Acc: 90.159

Epoch 58: Validation loss decreased (0.258261 --> 0.257877).  Saving model ...
	 Train_Loss: 0.3125 Train_Acc: 86.477 Val_Loss: 0.2579  BEST VAL Loss: 0.2579  Val_Acc: 90.126

Epoch 59: Validation loss decreased (0.257877 --> 0.257509).  Saving model ...
	 Train_Loss: 0.3121 Train_Acc: 86.622 Val_Loss: 0.2575  BEST VAL Loss: 0.2575  Val_Acc: 90.308

Epoch 60: Validation loss decreased (0.257509 --> 0.257110).  Saving model ...
	 Train_Loss: 0.3117 Train_Acc: 86.542 Val_Loss: 0.2571  BEST VAL Loss: 0.2571  Val_Acc: 90.201

Epoch 61: Validation loss decreased (0.257110 --> 0.256717).  Saving model ...
	 Train_Loss: 0.3114 Train_Acc: 86.647 Val_Loss: 0.2567  BEST VAL Loss: 0.2567  Val_Acc: 90.333

Epoch 62: Validation loss decreased (0.256717 --> 0.256304).  Saving model ...
	 Train_Loss: 0.3110 Train_Acc: 86.714 Val_Loss: 0.2563  BEST VAL Loss: 0.2563  Val_Acc: 90.391

Epoch 63: Validation loss decreased (0.256304 --> 0.256063).  Saving model ...
	 Train_Loss: 0.3107 Train_Acc: 86.525 Val_Loss: 0.2561  BEST VAL Loss: 0.2561  Val_Acc: 90.060

Epoch 64: Validation loss decreased (0.256063 --> 0.255764).  Saving model ...
	 Train_Loss: 0.3103 Train_Acc: 86.704 Val_Loss: 0.2558  BEST VAL Loss: 0.2558  Val_Acc: 90.197

Epoch 65: Validation loss decreased (0.255764 --> 0.255471).  Saving model ...
	 Train_Loss: 0.3100 Train_Acc: 86.602 Val_Loss: 0.2555  BEST VAL Loss: 0.2555  Val_Acc: 90.188

Epoch 66: Validation loss decreased (0.255471 --> 0.255414).  Saving model ...
	 Train_Loss: 0.3096 Train_Acc: 86.656 Val_Loss: 0.2554  BEST VAL Loss: 0.2554  Val_Acc: 89.474

Epoch 67: Validation loss decreased (0.255414 --> 0.255221).  Saving model ...
	 Train_Loss: 0.3093 Train_Acc: 86.566 Val_Loss: 0.2552  BEST VAL Loss: 0.2552  Val_Acc: 89.713

Epoch 68: Validation loss decreased (0.255221 --> 0.254887).  Saving model ...
	 Train_Loss: 0.3090 Train_Acc: 86.711 Val_Loss: 0.2549  BEST VAL Loss: 0.2549  Val_Acc: 90.188

Epoch 69: Validation loss decreased (0.254887 --> 0.254649).  Saving model ...
	 Train_Loss: 0.3087 Train_Acc: 86.747 Val_Loss: 0.2546  BEST VAL Loss: 0.2546  Val_Acc: 90.242

Epoch 70: Validation loss decreased (0.254649 --> 0.254436).  Saving model ...
	 Train_Loss: 0.3084 Train_Acc: 86.651 Val_Loss: 0.2544  BEST VAL Loss: 0.2544  Val_Acc: 90.172

Epoch 71: Validation loss decreased (0.254436 --> 0.254160).  Saving model ...
	 Train_Loss: 0.3081 Train_Acc: 86.745 Val_Loss: 0.2542  BEST VAL Loss: 0.2542  Val_Acc: 90.399

Epoch 72: Validation loss decreased (0.254160 --> 0.253913).  Saving model ...
	 Train_Loss: 0.3078 Train_Acc: 86.745 Val_Loss: 0.2539  BEST VAL Loss: 0.2539  Val_Acc: 90.089

Epoch 73: Validation loss decreased (0.253913 --> 0.253702).  Saving model ...
	 Train_Loss: 0.3075 Train_Acc: 86.576 Val_Loss: 0.2537  BEST VAL Loss: 0.2537  Val_Acc: 90.445

Epoch 74: Validation loss decreased (0.253702 --> 0.253426).  Saving model ...
	 Train_Loss: 0.3073 Train_Acc: 86.682 Val_Loss: 0.2534  BEST VAL Loss: 0.2534  Val_Acc: 90.358

Epoch 75: Validation loss decreased (0.253426 --> 0.253164).  Saving model ...
	 Train_Loss: 0.3070 Train_Acc: 86.712 Val_Loss: 0.2532  BEST VAL Loss: 0.2532  Val_Acc: 90.473

Epoch 76: Validation loss decreased (0.253164 --> 0.252939).  Saving model ...
	 Train_Loss: 0.3067 Train_Acc: 86.674 Val_Loss: 0.2529  BEST VAL Loss: 0.2529  Val_Acc: 90.300

Epoch 77: Validation loss decreased (0.252939 --> 0.252726).  Saving model ...
	 Train_Loss: 0.3065 Train_Acc: 86.723 Val_Loss: 0.2527  BEST VAL Loss: 0.2527  Val_Acc: 90.378

Epoch 78: Validation loss decreased (0.252726 --> 0.252456).  Saving model ...
	 Train_Loss: 0.3062 Train_Acc: 86.709 Val_Loss: 0.2525  BEST VAL Loss: 0.2525  Val_Acc: 90.275

Epoch 79: Validation loss decreased (0.252456 --> 0.252291).  Saving model ...
	 Train_Loss: 0.3059 Train_Acc: 86.742 Val_Loss: 0.2523  BEST VAL Loss: 0.2523  Val_Acc: 90.523

Epoch 80: Validation loss decreased (0.252291 --> 0.252074).  Saving model ...
	 Train_Loss: 0.3057 Train_Acc: 86.790 Val_Loss: 0.2521  BEST VAL Loss: 0.2521  Val_Acc: 90.622

Epoch 81: Validation loss decreased (0.252074 --> 0.251826).  Saving model ...
	 Train_Loss: 0.3054 Train_Acc: 86.826 Val_Loss: 0.2518  BEST VAL Loss: 0.2518  Val_Acc: 90.560

Epoch 82: Validation loss decreased (0.251826 --> 0.251562).  Saving model ...
	 Train_Loss: 0.3052 Train_Acc: 86.786 Val_Loss: 0.2516  BEST VAL Loss: 0.2516  Val_Acc: 90.486

Epoch 83: Validation loss decreased (0.251562 --> 0.251391).  Saving model ...
	 Train_Loss: 0.3049 Train_Acc: 86.814 Val_Loss: 0.2514  BEST VAL Loss: 0.2514  Val_Acc: 90.085

Epoch 84: Validation loss decreased (0.251391 --> 0.251258).  Saving model ...
	 Train_Loss: 0.3047 Train_Acc: 86.798 Val_Loss: 0.2513  BEST VAL Loss: 0.2513  Val_Acc: 90.271

Epoch 85: Validation loss decreased (0.251258 --> 0.251067).  Saving model ...
	 Train_Loss: 0.3045 Train_Acc: 86.829 Val_Loss: 0.2511  BEST VAL Loss: 0.2511  Val_Acc: 90.288

Epoch 86: Validation loss decreased (0.251067 --> 0.250865).  Saving model ...
	 Train_Loss: 0.3042 Train_Acc: 86.759 Val_Loss: 0.2509  BEST VAL Loss: 0.2509  Val_Acc: 90.193

Epoch 87: Validation loss decreased (0.250865 --> 0.250607).  Saving model ...
	 Train_Loss: 0.3040 Train_Acc: 86.835 Val_Loss: 0.2506  BEST VAL Loss: 0.2506  Val_Acc: 90.593

Epoch 88: Validation loss decreased (0.250607 --> 0.250464).  Saving model ...
	 Train_Loss: 0.3038 Train_Acc: 86.844 Val_Loss: 0.2505  BEST VAL Loss: 0.2505  Val_Acc: 89.978

Epoch 89: Validation loss decreased (0.250464 --> 0.250279).  Saving model ...
	 Train_Loss: 0.3036 Train_Acc: 86.787 Val_Loss: 0.2503  BEST VAL Loss: 0.2503  Val_Acc: 90.490

Epoch 90: Validation loss decreased (0.250279 --> 0.250144).  Saving model ...
	 Train_Loss: 0.3033 Train_Acc: 86.883 Val_Loss: 0.2501  BEST VAL Loss: 0.2501  Val_Acc: 90.362

Epoch 91: Validation loss decreased (0.250144 --> 0.249963).  Saving model ...
	 Train_Loss: 0.3031 Train_Acc: 86.760 Val_Loss: 0.2500  BEST VAL Loss: 0.2500  Val_Acc: 90.341

Epoch 92: Validation loss decreased (0.249963 --> 0.249735).  Saving model ...
	 Train_Loss: 0.3029 Train_Acc: 86.841 Val_Loss: 0.2497  BEST VAL Loss: 0.2497  Val_Acc: 90.589

Epoch 93: Validation loss decreased (0.249735 --> 0.249541).  Saving model ...
	 Train_Loss: 0.3027 Train_Acc: 86.890 Val_Loss: 0.2495  BEST VAL Loss: 0.2495  Val_Acc: 90.527

Epoch 94: Validation loss decreased (0.249541 --> 0.249363).  Saving model ...
	 Train_Loss: 0.3025 Train_Acc: 86.739 Val_Loss: 0.2494  BEST VAL Loss: 0.2494  Val_Acc: 90.370

Epoch 95: Validation loss decreased (0.249363 --> 0.249286).  Saving model ...
	 Train_Loss: 0.3023 Train_Acc: 86.801 Val_Loss: 0.2493  BEST VAL Loss: 0.2493  Val_Acc: 90.131

Epoch 96: Validation loss decreased (0.249286 --> 0.249148).  Saving model ...
	 Train_Loss: 0.3021 Train_Acc: 86.895 Val_Loss: 0.2491  BEST VAL Loss: 0.2491  Val_Acc: 90.304

Epoch 97: Validation loss decreased (0.249148 --> 0.249001).  Saving model ...
	 Train_Loss: 0.3019 Train_Acc: 86.876 Val_Loss: 0.2490  BEST VAL Loss: 0.2490  Val_Acc: 90.391

Epoch 98: Validation loss decreased (0.249001 --> 0.248776).  Saving model ...
	 Train_Loss: 0.3017 Train_Acc: 86.757 Val_Loss: 0.2488  BEST VAL Loss: 0.2488  Val_Acc: 90.820

Epoch 99: Validation loss decreased (0.248776 --> 0.248618).  Saving model ...
	 Train_Loss: 0.3015 Train_Acc: 86.809 Val_Loss: 0.2486  BEST VAL Loss: 0.2486  Val_Acc: 90.498

Thapsigargin_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.52      0.51     95989
           1       0.50      0.48      0.49     97655

    accuracy                           0.50    193644
   macro avg       0.50      0.50      0.50    193644
weighted avg       0.50      0.50      0.50    193644

Thapsigargin_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.51      0.50     11999
           1       0.50      0.48      0.49     12207

    accuracy                           0.50     24206
   macro avg       0.50      0.50      0.50     24206
weighted avg       0.50      0.50      0.50     24206

Thapsigargin_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.52      0.51     11999
           1       0.51      0.48      0.50     12207

    accuracy                           0.50     24206
   macro avg       0.50      0.50      0.50     24206
weighted avg       0.50      0.50      0.50     24206

              precision    recall  f1-score   support

           0       0.50      0.52      0.51     11999
           1       0.51      0.48      0.50     12207

    accuracy                           0.50     24206
   macro avg       0.50      0.50      0.50     24206
weighted avg       0.50      0.50      0.50     24206

Thapsigargin_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.42      0.45     39448
           1       0.53      0.58      0.55     44915

    accuracy                           0.51     84363
   macro avg       0.50      0.50      0.50     84363
weighted avg       0.50      0.51      0.50     84363

              precision    recall  f1-score   support

           0       0.47      0.42      0.45     39448
           1       0.53      0.58      0.55     44915

    accuracy                           0.51     84363
   macro avg       0.50      0.50      0.50     84363
weighted avg       0.50      0.51      0.50     84363

completed
