[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'f8f4ce44'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '1e0e9af9'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '8cbfcae4'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '8dde9d9b'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Thapsigargin_1.000_DMSO_0.025 treatment_name: Thapsigargin_10.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Thapsigargin_1.000_DMSO_0.025
TREATMENT_NAME: Thapsigargin_10.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'Thapsigargin_10.000_DMSO_0.025']
The dimensions of the data are: (315440, 1270)
Number of total missing values across all columns: 630880
Data Subset Is Off
Wells held out for testing: ['K06' 'L06']
Wells to use for training, validation, and testing ['D06' 'E06' 'D07' 'E07' 'K07' 'L07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.645427).  Saving model ...
	 Train_Loss: 0.6763 Train_Acc: 69.056 Val_Loss: 0.6454  BEST VAL Loss: 0.6454  Val_Acc: 68.734

Epoch 1: Validation loss did not decrease
	 Train_Loss: 0.5630 Train_Acc: 78.724 Val_Loss: 0.6651  BEST VAL Loss: 0.6454  Val_Acc: 69.027

Epoch 2: Validation loss decreased (0.645427 --> 0.578047).  Saving model ...
	 Train_Loss: 0.5095 Train_Acc: 81.475 Val_Loss: 0.5780  BEST VAL Loss: 0.5780  Val_Acc: 81.197

Epoch 3: Validation loss decreased (0.578047 --> 0.542591).  Saving model ...
	 Train_Loss: 0.4749 Train_Acc: 83.071 Val_Loss: 0.5426  BEST VAL Loss: 0.5426  Val_Acc: 80.413

Epoch 4: Validation loss did not decrease
	 Train_Loss: 0.4521 Train_Acc: 83.818 Val_Loss: 0.5692  BEST VAL Loss: 0.5426  Val_Acc: 72.799

Epoch 5: Validation loss decreased (0.542591 --> 0.525897).  Saving model ...
	 Train_Loss: 0.4345 Train_Acc: 84.588 Val_Loss: 0.5259  BEST VAL Loss: 0.5259  Val_Acc: 86.141

Epoch 6: Validation loss decreased (0.525897 --> 0.491425).  Saving model ...
	 Train_Loss: 0.4198 Train_Acc: 85.189 Val_Loss: 0.4914  BEST VAL Loss: 0.4914  Val_Acc: 87.438

Epoch 7: Validation loss decreased (0.491425 --> 0.470320).  Saving model ...
	 Train_Loss: 0.4073 Train_Acc: 85.656 Val_Loss: 0.4703  BEST VAL Loss: 0.4703  Val_Acc: 85.521

Epoch 8: Validation loss decreased (0.470320 --> 0.451293).  Saving model ...
	 Train_Loss: 0.3972 Train_Acc: 85.865 Val_Loss: 0.4513  BEST VAL Loss: 0.4513  Val_Acc: 86.839

Epoch 9: Validation loss decreased (0.451293 --> 0.434272).  Saving model ...
	 Train_Loss: 0.3885 Train_Acc: 86.257 Val_Loss: 0.4343  BEST VAL Loss: 0.4343  Val_Acc: 87.705

Epoch 10: Validation loss decreased (0.434272 --> 0.421434).  Saving model ...
	 Train_Loss: 0.3804 Train_Acc: 86.644 Val_Loss: 0.4214  BEST VAL Loss: 0.4214  Val_Acc: 87.071

Epoch 11: Validation loss decreased (0.421434 --> 0.410479).  Saving model ...
	 Train_Loss: 0.3735 Train_Acc: 86.761 Val_Loss: 0.4105  BEST VAL Loss: 0.4105  Val_Acc: 87.278

Epoch 12: Validation loss decreased (0.410479 --> 0.399577).  Saving model ...
	 Train_Loss: 0.3672 Train_Acc: 87.025 Val_Loss: 0.3996  BEST VAL Loss: 0.3996  Val_Acc: 88.303

Epoch 13: Validation loss decreased (0.399577 --> 0.399357).  Saving model ...
	 Train_Loss: 0.3615 Train_Acc: 87.190 Val_Loss: 0.3994  BEST VAL Loss: 0.3994  Val_Acc: 83.320

Epoch 14: Validation loss decreased (0.399357 --> 0.390473).  Saving model ...
	 Train_Loss: 0.3565 Train_Acc: 87.200 Val_Loss: 0.3905  BEST VAL Loss: 0.3905  Val_Acc: 88.506

Epoch 15: Validation loss decreased (0.390473 --> 0.382153).  Saving model ...
	 Train_Loss: 0.3518 Train_Acc: 87.428 Val_Loss: 0.3822  BEST VAL Loss: 0.3822  Val_Acc: 88.988

Epoch 16: Validation loss did not decrease
	 Train_Loss: 0.3475 Train_Acc: 87.552 Val_Loss: 0.3903  BEST VAL Loss: 0.3822  Val_Acc: 77.959

Epoch 17: Validation loss did not decrease
	 Train_Loss: 0.3433 Train_Acc: 87.938 Val_Loss: 0.3844  BEST VAL Loss: 0.3822  Val_Acc: 87.972

Epoch 18: Validation loss decreased (0.382153 --> 0.379628).  Saving model ...
	 Train_Loss: 0.3396 Train_Acc: 87.844 Val_Loss: 0.3796  BEST VAL Loss: 0.3796  Val_Acc: 87.494

Epoch 19: Validation loss decreased (0.379628 --> 0.375571).  Saving model ...
	 Train_Loss: 0.3360 Train_Acc: 88.171 Val_Loss: 0.3756  BEST VAL Loss: 0.3756  Val_Acc: 87.300

Epoch 20: Validation loss decreased (0.375571 --> 0.370781).  Saving model ...
	 Train_Loss: 0.3328 Train_Acc: 87.988 Val_Loss: 0.3708  BEST VAL Loss: 0.3708  Val_Acc: 88.419

Epoch 21: Validation loss decreased (0.370781 --> 0.364950).  Saving model ...
	 Train_Loss: 0.3296 Train_Acc: 88.332 Val_Loss: 0.3650  BEST VAL Loss: 0.3650  Val_Acc: 89.647

Epoch 22: Validation loss did not decrease
	 Train_Loss: 0.3268 Train_Acc: 88.136 Val_Loss: 0.3759  BEST VAL Loss: 0.3650  Val_Acc: 76.761

Epoch 23: Validation loss did not decrease
	 Train_Loss: 0.3241 Train_Acc: 88.399 Val_Loss: 0.3700  BEST VAL Loss: 0.3650  Val_Acc: 90.181

Epoch 24: Validation loss decreased (0.364950 --> 0.364868).  Saving model ...
	 Train_Loss: 0.3213 Train_Acc: 88.690 Val_Loss: 0.3649  BEST VAL Loss: 0.3649  Val_Acc: 89.647

Epoch 25: Validation loss decreased (0.364868 --> 0.360920).  Saving model ...
	 Train_Loss: 0.3189 Train_Acc: 88.336 Val_Loss: 0.3609  BEST VAL Loss: 0.3609  Val_Acc: 88.652

Epoch 26: Validation loss decreased (0.360920 --> 0.356999).  Saving model ...
	 Train_Loss: 0.3166 Train_Acc: 88.551 Val_Loss: 0.3570  BEST VAL Loss: 0.3570  Val_Acc: 89.014

Epoch 27: Validation loss decreased (0.356999 --> 0.352772).  Saving model ...
	 Train_Loss: 0.3145 Train_Acc: 88.543 Val_Loss: 0.3528  BEST VAL Loss: 0.3528  Val_Acc: 89.798

Epoch 28: Validation loss decreased (0.352772 --> 0.348621).  Saving model ...
	 Train_Loss: 0.3124 Train_Acc: 88.789 Val_Loss: 0.3486  BEST VAL Loss: 0.3486  Val_Acc: 90.129

Epoch 29: Validation loss decreased (0.348621 --> 0.345072).  Saving model ...
	 Train_Loss: 0.3102 Train_Acc: 88.902 Val_Loss: 0.3451  BEST VAL Loss: 0.3451  Val_Acc: 89.690

Epoch 30: Validation loss decreased (0.345072 --> 0.341110).  Saving model ...
	 Train_Loss: 0.3082 Train_Acc: 88.807 Val_Loss: 0.3411  BEST VAL Loss: 0.3411  Val_Acc: 90.633

Epoch 31: Validation loss decreased (0.341110 --> 0.338197).  Saving model ...
	 Train_Loss: 0.3064 Train_Acc: 88.733 Val_Loss: 0.3382  BEST VAL Loss: 0.3382  Val_Acc: 89.432

Epoch 32: Validation loss decreased (0.338197 --> 0.335036).  Saving model ...
	 Train_Loss: 0.3046 Train_Acc: 89.091 Val_Loss: 0.3350  BEST VAL Loss: 0.3350  Val_Acc: 90.082

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.3029 Train_Acc: 88.933 Val_Loss: 0.3361  BEST VAL Loss: 0.3350  Val_Acc: 85.039

Epoch 34: Validation loss decreased (0.335036 --> 0.333126).  Saving model ...
	 Train_Loss: 0.3013 Train_Acc: 89.041 Val_Loss: 0.3331  BEST VAL Loss: 0.3331  Val_Acc: 90.241

Epoch 35: Validation loss decreased (0.333126 --> 0.330231).  Saving model ...
	 Train_Loss: 0.2996 Train_Acc: 89.187 Val_Loss: 0.3302  BEST VAL Loss: 0.3302  Val_Acc: 90.435

Epoch 36: Validation loss decreased (0.330231 --> 0.327450).  Saving model ...
	 Train_Loss: 0.2981 Train_Acc: 89.181 Val_Loss: 0.3275  BEST VAL Loss: 0.3275  Val_Acc: 90.172

Epoch 37: Validation loss decreased (0.327450 --> 0.326462).  Saving model ...
	 Train_Loss: 0.2966 Train_Acc: 89.247 Val_Loss: 0.3265  BEST VAL Loss: 0.3265  Val_Acc: 88.127

Epoch 38: Validation loss decreased (0.326462 --> 0.324049).  Saving model ...
	 Train_Loss: 0.2951 Train_Acc: 89.332 Val_Loss: 0.3240  BEST VAL Loss: 0.3240  Val_Acc: 90.254

Epoch 39: Validation loss decreased (0.324049 --> 0.321832).  Saving model ...
	 Train_Loss: 0.2938 Train_Acc: 89.171 Val_Loss: 0.3218  BEST VAL Loss: 0.3218  Val_Acc: 90.078

Epoch 40: Validation loss decreased (0.321832 --> 0.319646).  Saving model ...
	 Train_Loss: 0.2924 Train_Acc: 89.416 Val_Loss: 0.3196  BEST VAL Loss: 0.3196  Val_Acc: 90.082

Epoch 41: Validation loss decreased (0.319646 --> 0.317704).  Saving model ...
	 Train_Loss: 0.2911 Train_Acc: 89.360 Val_Loss: 0.3177  BEST VAL Loss: 0.3177  Val_Acc: 90.254

Epoch 42: Validation loss decreased (0.317704 --> 0.315484).  Saving model ...
	 Train_Loss: 0.2899 Train_Acc: 89.360 Val_Loss: 0.3155  BEST VAL Loss: 0.3155  Val_Acc: 90.474

Epoch 43: Validation loss decreased (0.315484 --> 0.313338).  Saving model ...
	 Train_Loss: 0.2886 Train_Acc: 89.431 Val_Loss: 0.3133  BEST VAL Loss: 0.3133  Val_Acc: 90.646

Epoch 44: Validation loss decreased (0.313338 --> 0.311284).  Saving model ...
	 Train_Loss: 0.2875 Train_Acc: 89.360 Val_Loss: 0.3113  BEST VAL Loss: 0.3113  Val_Acc: 90.698

Epoch 45: Validation loss decreased (0.311284 --> 0.310603).  Saving model ...
	 Train_Loss: 0.2863 Train_Acc: 89.462 Val_Loss: 0.3106  BEST VAL Loss: 0.3106  Val_Acc: 88.506

Epoch 46: Validation loss decreased (0.310603 --> 0.309122).  Saving model ...
	 Train_Loss: 0.2852 Train_Acc: 89.496 Val_Loss: 0.3091  BEST VAL Loss: 0.3091  Val_Acc: 89.733

Epoch 47: Validation loss decreased (0.309122 --> 0.307210).  Saving model ...
	 Train_Loss: 0.2842 Train_Acc: 89.437 Val_Loss: 0.3072  BEST VAL Loss: 0.3072  Val_Acc: 90.831

Epoch 48: Validation loss decreased (0.307210 --> 0.305632).  Saving model ...
	 Train_Loss: 0.2832 Train_Acc: 89.462 Val_Loss: 0.3056  BEST VAL Loss: 0.3056  Val_Acc: 90.401

Epoch 49: Validation loss decreased (0.305632 --> 0.304474).  Saving model ...
	 Train_Loss: 0.2821 Train_Acc: 89.742 Val_Loss: 0.3045  BEST VAL Loss: 0.3045  Val_Acc: 89.647

Epoch 50: Validation loss decreased (0.304474 --> 0.302990).  Saving model ...
	 Train_Loss: 0.2811 Train_Acc: 89.547 Val_Loss: 0.3030  BEST VAL Loss: 0.3030  Val_Acc: 90.581

Epoch 51: Validation loss decreased (0.302990 --> 0.301964).  Saving model ...
	 Train_Loss: 0.2802 Train_Acc: 89.541 Val_Loss: 0.3020  BEST VAL Loss: 0.3020  Val_Acc: 89.841

Epoch 52: Validation loss decreased (0.301964 --> 0.300619).  Saving model ...
	 Train_Loss: 0.2793 Train_Acc: 89.572 Val_Loss: 0.3006  BEST VAL Loss: 0.3006  Val_Acc: 90.426

Epoch 53: Validation loss decreased (0.300619 --> 0.299454).  Saving model ...
	 Train_Loss: 0.2784 Train_Acc: 89.695 Val_Loss: 0.2995  BEST VAL Loss: 0.2995  Val_Acc: 90.043

Epoch 54: Validation loss decreased (0.299454 --> 0.297957).  Saving model ...
	 Train_Loss: 0.2775 Train_Acc: 89.706 Val_Loss: 0.2980  BEST VAL Loss: 0.2980  Val_Acc: 91.098

Epoch 55: Validation loss decreased (0.297957 --> 0.296703).  Saving model ...
	 Train_Loss: 0.2766 Train_Acc: 89.744 Val_Loss: 0.2967  BEST VAL Loss: 0.2967  Val_Acc: 90.581

Epoch 56: Validation loss decreased (0.296703 --> 0.295510).  Saving model ...
	 Train_Loss: 0.2757 Train_Acc: 89.729 Val_Loss: 0.2955  BEST VAL Loss: 0.2955  Val_Acc: 90.340

Epoch 57: Validation loss decreased (0.295510 --> 0.294403).  Saving model ...
	 Train_Loss: 0.2749 Train_Acc: 89.749 Val_Loss: 0.2944  BEST VAL Loss: 0.2944  Val_Acc: 90.306

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.2741 Train_Acc: 89.754 Val_Loss: 0.2966  BEST VAL Loss: 0.2944  Val_Acc: 84.871

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.2734 Train_Acc: 89.698 Val_Loss: 0.2955  BEST VAL Loss: 0.2944  Val_Acc: 90.603

Epoch 60: Validation loss decreased (0.294403 --> 0.294276).  Saving model ...
	 Train_Loss: 0.2726 Train_Acc: 89.802 Val_Loss: 0.2943  BEST VAL Loss: 0.2943  Val_Acc: 90.792

Epoch 61: Validation loss decreased (0.294276 --> 0.293061).  Saving model ...
	 Train_Loss: 0.2718 Train_Acc: 89.873 Val_Loss: 0.2931  BEST VAL Loss: 0.2931  Val_Acc: 91.047

Epoch 62: Validation loss decreased (0.293061 --> 0.292065).  Saving model ...
	 Train_Loss: 0.2711 Train_Acc: 89.821 Val_Loss: 0.2921  BEST VAL Loss: 0.2921  Val_Acc: 90.599

Epoch 63: Validation loss decreased (0.292065 --> 0.291135).  Saving model ...
	 Train_Loss: 0.2704 Train_Acc: 89.989 Val_Loss: 0.2911  BEST VAL Loss: 0.2911  Val_Acc: 90.392

Epoch 64: Validation loss decreased (0.291135 --> 0.290114).  Saving model ...
	 Train_Loss: 0.2696 Train_Acc: 89.979 Val_Loss: 0.2901  BEST VAL Loss: 0.2901  Val_Acc: 90.823

Epoch 65: Validation loss decreased (0.290114 --> 0.289061).  Saving model ...
	 Train_Loss: 0.2689 Train_Acc: 89.896 Val_Loss: 0.2891  BEST VAL Loss: 0.2891  Val_Acc: 90.969

Epoch 66: Validation loss decreased (0.289061 --> 0.288127).  Saving model ...
	 Train_Loss: 0.2683 Train_Acc: 89.867 Val_Loss: 0.2881  BEST VAL Loss: 0.2881  Val_Acc: 90.517

Epoch 67: Validation loss decreased (0.288127 --> 0.287105).  Saving model ...
	 Train_Loss: 0.2676 Train_Acc: 89.927 Val_Loss: 0.2871  BEST VAL Loss: 0.2871  Val_Acc: 90.995

Epoch 68: Validation loss decreased (0.287105 --> 0.286118).  Saving model ...
	 Train_Loss: 0.2670 Train_Acc: 89.959 Val_Loss: 0.2861  BEST VAL Loss: 0.2861  Val_Acc: 90.896

Epoch 69: Validation loss decreased (0.286118 --> 0.285179).  Saving model ...
	 Train_Loss: 0.2663 Train_Acc: 90.053 Val_Loss: 0.2852  BEST VAL Loss: 0.2852  Val_Acc: 90.758

Epoch 70: Validation loss decreased (0.285179 --> 0.284414).  Saving model ...
	 Train_Loss: 0.2657 Train_Acc: 90.076 Val_Loss: 0.2844  BEST VAL Loss: 0.2844  Val_Acc: 90.848

Epoch 71: Validation loss decreased (0.284414 --> 0.283584).  Saving model ...
	 Train_Loss: 0.2651 Train_Acc: 89.956 Val_Loss: 0.2836  BEST VAL Loss: 0.2836  Val_Acc: 90.866

Epoch 72: Validation loss decreased (0.283584 --> 0.282744).  Saving model ...
	 Train_Loss: 0.2645 Train_Acc: 89.984 Val_Loss: 0.2827  BEST VAL Loss: 0.2827  Val_Acc: 90.917

Epoch 73: Validation loss decreased (0.282744 --> 0.281943).  Saving model ...
	 Train_Loss: 0.2639 Train_Acc: 89.980 Val_Loss: 0.2819  BEST VAL Loss: 0.2819  Val_Acc: 90.857

Epoch 74: Validation loss decreased (0.281943 --> 0.281127).  Saving model ...
	 Train_Loss: 0.2633 Train_Acc: 90.026 Val_Loss: 0.2811  BEST VAL Loss: 0.2811  Val_Acc: 91.047

Epoch 75: Validation loss decreased (0.281127 --> 0.280398).  Saving model ...
	 Train_Loss: 0.2627 Train_Acc: 90.086 Val_Loss: 0.2804  BEST VAL Loss: 0.2804  Val_Acc: 90.698

Epoch 76: Validation loss decreased (0.280398 --> 0.279959).  Saving model ...
	 Train_Loss: 0.2622 Train_Acc: 90.115 Val_Loss: 0.2800  BEST VAL Loss: 0.2800  Val_Acc: 90.056

Epoch 77: Validation loss decreased (0.279959 --> 0.279284).  Saving model ...
	 Train_Loss: 0.2616 Train_Acc: 90.045 Val_Loss: 0.2793  BEST VAL Loss: 0.2793  Val_Acc: 90.999

Epoch 78: Validation loss decreased (0.279284 --> 0.278578).  Saving model ...
	 Train_Loss: 0.2611 Train_Acc: 90.155 Val_Loss: 0.2786  BEST VAL Loss: 0.2786  Val_Acc: 90.853

Epoch 79: Validation loss decreased (0.278578 --> 0.277920).  Saving model ...
	 Train_Loss: 0.2606 Train_Acc: 90.078 Val_Loss: 0.2779  BEST VAL Loss: 0.2779  Val_Acc: 91.025

Epoch 80: Validation loss decreased (0.277920 --> 0.277261).  Saving model ...
	 Train_Loss: 0.2601 Train_Acc: 90.063 Val_Loss: 0.2773  BEST VAL Loss: 0.2773  Val_Acc: 91.059

Epoch 81: Validation loss decreased (0.277261 --> 0.276540).  Saving model ...
	 Train_Loss: 0.2596 Train_Acc: 90.282 Val_Loss: 0.2765  BEST VAL Loss: 0.2765  Val_Acc: 91.275

Epoch 82: Validation loss decreased (0.276540 --> 0.275944).  Saving model ...
	 Train_Loss: 0.2590 Train_Acc: 90.229 Val_Loss: 0.2759  BEST VAL Loss: 0.2759  Val_Acc: 90.736

Epoch 83: Validation loss decreased (0.275944 --> 0.275327).  Saving model ...
	 Train_Loss: 0.2585 Train_Acc: 90.201 Val_Loss: 0.2753  BEST VAL Loss: 0.2753  Val_Acc: 90.861

Epoch 84: Validation loss decreased (0.275327 --> 0.274694).  Saving model ...
	 Train_Loss: 0.2581 Train_Acc: 90.189 Val_Loss: 0.2747  BEST VAL Loss: 0.2747  Val_Acc: 90.952

Epoch 85: Validation loss decreased (0.274694 --> 0.274265).  Saving model ...
	 Train_Loss: 0.2576 Train_Acc: 90.238 Val_Loss: 0.2743  BEST VAL Loss: 0.2743  Val_Acc: 90.560

Epoch 86: Validation loss decreased (0.274265 --> 0.273717).  Saving model ...
	 Train_Loss: 0.2571 Train_Acc: 90.259 Val_Loss: 0.2737  BEST VAL Loss: 0.2737  Val_Acc: 90.810

Epoch 87: Validation loss decreased (0.273717 --> 0.273429).  Saving model ...
	 Train_Loss: 0.2566 Train_Acc: 90.237 Val_Loss: 0.2734  BEST VAL Loss: 0.2734  Val_Acc: 90.116

Epoch 88: Validation loss decreased (0.273429 --> 0.272921).  Saving model ...
	 Train_Loss: 0.2562 Train_Acc: 90.289 Val_Loss: 0.2729  BEST VAL Loss: 0.2729  Val_Acc: 91.051

Epoch 89: Validation loss decreased (0.272921 --> 0.272340).  Saving model ...
	 Train_Loss: 0.2557 Train_Acc: 90.323 Val_Loss: 0.2723  BEST VAL Loss: 0.2723  Val_Acc: 91.288

Epoch 90: Validation loss decreased (0.272340 --> 0.271966).  Saving model ...
	 Train_Loss: 0.2553 Train_Acc: 90.217 Val_Loss: 0.2720  BEST VAL Loss: 0.2720  Val_Acc: 90.607

Epoch 91: Validation loss decreased (0.271966 --> 0.271495).  Saving model ...
	 Train_Loss: 0.2548 Train_Acc: 90.310 Val_Loss: 0.2715  BEST VAL Loss: 0.2715  Val_Acc: 90.999

Epoch 92: Validation loss decreased (0.271495 --> 0.271079).  Saving model ...
	 Train_Loss: 0.2544 Train_Acc: 90.253 Val_Loss: 0.2711  BEST VAL Loss: 0.2711  Val_Acc: 91.003

Epoch 93: Validation loss decreased (0.271079 --> 0.270573).  Saving model ...
	 Train_Loss: 0.2539 Train_Acc: 90.359 Val_Loss: 0.2706  BEST VAL Loss: 0.2706  Val_Acc: 90.883

Epoch 94: Validation loss decreased (0.270573 --> 0.270117).  Saving model ...
	 Train_Loss: 0.2535 Train_Acc: 90.345 Val_Loss: 0.2701  BEST VAL Loss: 0.2701  Val_Acc: 91.150

Epoch 95: Validation loss decreased (0.270117 --> 0.269567).  Saving model ...
	 Train_Loss: 0.2531 Train_Acc: 90.311 Val_Loss: 0.2696  BEST VAL Loss: 0.2696  Val_Acc: 91.094

Epoch 96: Validation loss decreased (0.269567 --> 0.269145).  Saving model ...
	 Train_Loss: 0.2527 Train_Acc: 90.347 Val_Loss: 0.2691  BEST VAL Loss: 0.2691  Val_Acc: 91.120

Epoch 97: Validation loss decreased (0.269145 --> 0.268693).  Saving model ...
	 Train_Loss: 0.2523 Train_Acc: 90.289 Val_Loss: 0.2687  BEST VAL Loss: 0.2687  Val_Acc: 90.995

Epoch 98: Validation loss decreased (0.268693 --> 0.268248).  Saving model ...
	 Train_Loss: 0.2519 Train_Acc: 90.349 Val_Loss: 0.2682  BEST VAL Loss: 0.2682  Val_Acc: 91.227

Epoch 99: Validation loss decreased (0.268248 --> 0.267823).  Saving model ...
	 Train_Loss: 0.2515 Train_Acc: 90.347 Val_Loss: 0.2678  BEST VAL Loss: 0.2678  Val_Acc: 91.301

Thapsigargin_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.92      0.93      0.92     88098
           1       0.93      0.93      0.93     97655

    accuracy                           0.93    185753
   macro avg       0.93      0.93      0.93    185753
weighted avg       0.93      0.93      0.93    185753

Thapsigargin_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.91      0.91      0.91     11013
           1       0.92      0.92      0.92     12207

    accuracy                           0.91     23220
   macro avg       0.91      0.91      0.91     23220
weighted avg       0.91      0.91      0.91     23220

Thapsigargin_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.90      0.90      0.90     11013
           1       0.91      0.91      0.91     12207

    accuracy                           0.91     23220
   macro avg       0.91      0.91      0.91     23220
weighted avg       0.91      0.91      0.91     23220

              precision    recall  f1-score   support

           0       0.90      0.90      0.90     11013
           1       0.91      0.91      0.91     12207

    accuracy                           0.91     23220
   macro avg       0.91      0.91      0.91     23220
weighted avg       0.91      0.91      0.91     23220

Thapsigargin_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.86      0.80      0.83     38332
           1       0.84      0.89      0.86     44915

    accuracy                           0.85     83247
   macro avg       0.85      0.84      0.85     83247
weighted avg       0.85      0.85      0.85     83247

              precision    recall  f1-score   support

           0       0.86      0.80      0.83     38332
           1       0.84      0.89      0.86     44915

    accuracy                           0.85     83247
   macro avg       0.85      0.84      0.85     83247
weighted avg       0.85      0.85      0.85     83247

completed
