[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '46cb2618'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'a6b4ca6c'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '4d4be16d'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'c36f0854'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Thapsigargin_1.000_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Thapsigargin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'LPS_0.100_DMSO_0.025']
The dimensions of the data are: (31276, 1276)
Number of total missing values across all columns: 62552
Data Subset Is Off
Wells held out for testing: ['D14' 'C20']
Wells to use for training, validation, and testing ['D15' 'C16' 'C17' 'C21' 'K14' 'K15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.598185).  Saving model ...
	 Train_Loss: 0.6509 Train_Acc: 63.814 Val_Loss: 0.5982  BEST VAL Loss: 0.5982  Val_Acc: 72.163

Epoch 1: Validation loss decreased (0.598185 --> 0.572741).  Saving model ...
	 Train_Loss: 0.6011 Train_Acc: 72.824 Val_Loss: 0.5727  BEST VAL Loss: 0.5727  Val_Acc: 73.311

Epoch 2: Validation loss decreased (0.572741 --> 0.547461).  Saving model ...
	 Train_Loss: 0.5685 Train_Acc: 75.098 Val_Loss: 0.5475  BEST VAL Loss: 0.5475  Val_Acc: 76.966

Epoch 3: Validation loss decreased (0.547461 --> 0.531428).  Saving model ...
	 Train_Loss: 0.5447 Train_Acc: 77.192 Val_Loss: 0.5314  BEST VAL Loss: 0.5314  Val_Acc: 79.048

Epoch 4: Validation loss decreased (0.531428 --> 0.514754).  Saving model ...
	 Train_Loss: 0.5245 Train_Acc: 79.795 Val_Loss: 0.5148  BEST VAL Loss: 0.5148  Val_Acc: 81.258

Epoch 5: Validation loss decreased (0.514754 --> 0.500140).  Saving model ...
	 Train_Loss: 0.5071 Train_Acc: 81.065 Val_Loss: 0.5001  BEST VAL Loss: 0.5001  Val_Acc: 83.425

Epoch 6: Validation loss decreased (0.500140 --> 0.484997).  Saving model ...
	 Train_Loss: 0.4914 Train_Acc: 82.898 Val_Loss: 0.4850  BEST VAL Loss: 0.4850  Val_Acc: 83.553

Epoch 7: Validation loss decreased (0.484997 --> 0.473466).  Saving model ...
	 Train_Loss: 0.4777 Train_Acc: 83.780 Val_Loss: 0.4735  BEST VAL Loss: 0.4735  Val_Acc: 84.785

Epoch 8: Validation loss decreased (0.473466 --> 0.464417).  Saving model ...
	 Train_Loss: 0.4663 Train_Acc: 84.205 Val_Loss: 0.4644  BEST VAL Loss: 0.4644  Val_Acc: 84.488

Epoch 9: Validation loss decreased (0.464417 --> 0.455625).  Saving model ...
	 Train_Loss: 0.4565 Train_Acc: 84.561 Val_Loss: 0.4556  BEST VAL Loss: 0.4556  Val_Acc: 85.890

Epoch 10: Validation loss decreased (0.455625 --> 0.448243).  Saving model ...
	 Train_Loss: 0.4472 Train_Acc: 85.177 Val_Loss: 0.4482  BEST VAL Loss: 0.4482  Val_Acc: 85.295

Epoch 11: Validation loss decreased (0.448243 --> 0.442580).  Saving model ...
	 Train_Loss: 0.4383 Train_Acc: 86.048 Val_Loss: 0.4426  BEST VAL Loss: 0.4426  Val_Acc: 85.465

Epoch 12: Validation loss decreased (0.442580 --> 0.438133).  Saving model ...
	 Train_Loss: 0.4308 Train_Acc: 86.234 Val_Loss: 0.4381  BEST VAL Loss: 0.4381  Val_Acc: 84.870

Epoch 13: Validation loss decreased (0.438133 --> 0.434181).  Saving model ...
	 Train_Loss: 0.4239 Train_Acc: 86.468 Val_Loss: 0.4342  BEST VAL Loss: 0.4342  Val_Acc: 84.445

Epoch 14: Validation loss decreased (0.434181 --> 0.429037).  Saving model ...
	 Train_Loss: 0.4182 Train_Acc: 86.505 Val_Loss: 0.4290  BEST VAL Loss: 0.4290  Val_Acc: 86.400

Epoch 15: Validation loss decreased (0.429037 --> 0.424751).  Saving model ...
	 Train_Loss: 0.4129 Train_Acc: 86.526 Val_Loss: 0.4248  BEST VAL Loss: 0.4248  Val_Acc: 86.995

Epoch 16: Validation loss decreased (0.424751 --> 0.420909).  Saving model ...
	 Train_Loss: 0.4077 Train_Acc: 87.116 Val_Loss: 0.4209  BEST VAL Loss: 0.4209  Val_Acc: 86.825

Epoch 17: Validation loss decreased (0.420909 --> 0.417486).  Saving model ...
	 Train_Loss: 0.4034 Train_Acc: 86.824 Val_Loss: 0.4175  BEST VAL Loss: 0.4175  Val_Acc: 86.400

Epoch 18: Validation loss decreased (0.417486 --> 0.413734).  Saving model ...
	 Train_Loss: 0.3992 Train_Acc: 87.228 Val_Loss: 0.4137  BEST VAL Loss: 0.4137  Val_Acc: 86.783

Epoch 19: Validation loss decreased (0.413734 --> 0.410520).  Saving model ...
	 Train_Loss: 0.3953 Train_Acc: 87.111 Val_Loss: 0.4105  BEST VAL Loss: 0.4105  Val_Acc: 86.783

Epoch 20: Validation loss decreased (0.410520 --> 0.406731).  Saving model ...
	 Train_Loss: 0.3915 Train_Acc: 87.653 Val_Loss: 0.4067  BEST VAL Loss: 0.4067  Val_Acc: 87.930

Epoch 21: Validation loss decreased (0.406731 --> 0.404200).  Saving model ...
	 Train_Loss: 0.3874 Train_Acc: 88.397 Val_Loss: 0.4042  BEST VAL Loss: 0.4042  Val_Acc: 86.825

Epoch 22: Validation loss decreased (0.404200 --> 0.401808).  Saving model ...
	 Train_Loss: 0.3839 Train_Acc: 88.094 Val_Loss: 0.4018  BEST VAL Loss: 0.4018  Val_Acc: 87.293

Epoch 23: Validation loss decreased (0.401808 --> 0.400300).  Saving model ...
	 Train_Loss: 0.3804 Train_Acc: 88.567 Val_Loss: 0.4003  BEST VAL Loss: 0.4003  Val_Acc: 86.400

Epoch 24: Validation loss decreased (0.400300 --> 0.398255).  Saving model ...
	 Train_Loss: 0.3772 Train_Acc: 88.556 Val_Loss: 0.3983  BEST VAL Loss: 0.3983  Val_Acc: 86.783

Epoch 25: Validation loss decreased (0.398255 --> 0.396360).  Saving model ...
	 Train_Loss: 0.3742 Train_Acc: 88.471 Val_Loss: 0.3964  BEST VAL Loss: 0.3964  Val_Acc: 86.740

Epoch 26: Validation loss decreased (0.396360 --> 0.394139).  Saving model ...
	 Train_Loss: 0.3719 Train_Acc: 87.770 Val_Loss: 0.3941  BEST VAL Loss: 0.3941  Val_Acc: 88.100

Epoch 27: Validation loss decreased (0.394139 --> 0.392664).  Saving model ...
	 Train_Loss: 0.3694 Train_Acc: 88.211 Val_Loss: 0.3927  BEST VAL Loss: 0.3927  Val_Acc: 87.123

Epoch 28: Validation loss decreased (0.392664 --> 0.390765).  Saving model ...
	 Train_Loss: 0.3670 Train_Acc: 88.466 Val_Loss: 0.3908  BEST VAL Loss: 0.3908  Val_Acc: 87.080

Epoch 29: Validation loss decreased (0.390765 --> 0.389136).  Saving model ...
	 Train_Loss: 0.3646 Train_Acc: 88.630 Val_Loss: 0.3891  BEST VAL Loss: 0.3891  Val_Acc: 87.548

Epoch 30: Validation loss decreased (0.389136 --> 0.387233).  Saving model ...
	 Train_Loss: 0.3622 Train_Acc: 88.737 Val_Loss: 0.3872  BEST VAL Loss: 0.3872  Val_Acc: 87.165

Epoch 31: Validation loss decreased (0.387233 --> 0.385460).  Saving model ...
	 Train_Loss: 0.3600 Train_Acc: 88.912 Val_Loss: 0.3855  BEST VAL Loss: 0.3855  Val_Acc: 87.463

Epoch 32: Validation loss decreased (0.385460 --> 0.383983).  Saving model ...
	 Train_Loss: 0.3578 Train_Acc: 89.209 Val_Loss: 0.3840  BEST VAL Loss: 0.3840  Val_Acc: 87.378

Epoch 33: Validation loss decreased (0.383983 --> 0.382581).  Saving model ...
	 Train_Loss: 0.3558 Train_Acc: 89.093 Val_Loss: 0.3826  BEST VAL Loss: 0.3826  Val_Acc: 87.378

Epoch 34: Validation loss decreased (0.382581 --> 0.381353).  Saving model ...
	 Train_Loss: 0.3538 Train_Acc: 89.082 Val_Loss: 0.3814  BEST VAL Loss: 0.3814  Val_Acc: 87.293

Epoch 35: Validation loss decreased (0.381353 --> 0.380201).  Saving model ...
	 Train_Loss: 0.3521 Train_Acc: 88.827 Val_Loss: 0.3802  BEST VAL Loss: 0.3802  Val_Acc: 86.783

Epoch 36: Validation loss decreased (0.380201 --> 0.378954).  Saving model ...
	 Train_Loss: 0.3504 Train_Acc: 88.944 Val_Loss: 0.3790  BEST VAL Loss: 0.3790  Val_Acc: 87.250

Epoch 37: Validation loss decreased (0.378954 --> 0.377603).  Saving model ...
	 Train_Loss: 0.3488 Train_Acc: 88.954 Val_Loss: 0.3776  BEST VAL Loss: 0.3776  Val_Acc: 87.505

Epoch 38: Validation loss decreased (0.377603 --> 0.376755).  Saving model ...
	 Train_Loss: 0.3469 Train_Acc: 89.719 Val_Loss: 0.3768  BEST VAL Loss: 0.3768  Val_Acc: 87.420

Epoch 39: Validation loss decreased (0.376755 --> 0.375475).  Saving model ...
	 Train_Loss: 0.3450 Train_Acc: 89.789 Val_Loss: 0.3755  BEST VAL Loss: 0.3755  Val_Acc: 88.143

Epoch 40: Validation loss decreased (0.375475 --> 0.374419).  Saving model ...
	 Train_Loss: 0.3432 Train_Acc: 90.044 Val_Loss: 0.3744  BEST VAL Loss: 0.3744  Val_Acc: 87.930

Epoch 41: Validation loss decreased (0.374419 --> 0.373184).  Saving model ...
	 Train_Loss: 0.3415 Train_Acc: 90.208 Val_Loss: 0.3732  BEST VAL Loss: 0.3732  Val_Acc: 87.803

Epoch 42: Validation loss decreased (0.373184 --> 0.371852).  Saving model ...
	 Train_Loss: 0.3399 Train_Acc: 90.129 Val_Loss: 0.3719  BEST VAL Loss: 0.3719  Val_Acc: 88.143

Epoch 43: Validation loss decreased (0.371852 --> 0.371049).  Saving model ...
	 Train_Loss: 0.3383 Train_Acc: 90.139 Val_Loss: 0.3710  BEST VAL Loss: 0.3710  Val_Acc: 87.845

Epoch 44: Validation loss decreased (0.371049 --> 0.370067).  Saving model ...
	 Train_Loss: 0.3367 Train_Acc: 90.240 Val_Loss: 0.3701  BEST VAL Loss: 0.3701  Val_Acc: 88.185

Epoch 45: Validation loss decreased (0.370067 --> 0.369002).  Saving model ...
	 Train_Loss: 0.3352 Train_Acc: 90.129 Val_Loss: 0.3690  BEST VAL Loss: 0.3690  Val_Acc: 88.015

Epoch 46: Validation loss decreased (0.369002 --> 0.367961).  Saving model ...
	 Train_Loss: 0.3338 Train_Acc: 90.245 Val_Loss: 0.3680  BEST VAL Loss: 0.3680  Val_Acc: 88.568

Epoch 47: Validation loss decreased (0.367961 --> 0.367011).  Saving model ...
	 Train_Loss: 0.3324 Train_Acc: 90.001 Val_Loss: 0.3670  BEST VAL Loss: 0.3670  Val_Acc: 87.420

Epoch 48: Validation loss decreased (0.367011 --> 0.366132).  Saving model ...
	 Train_Loss: 0.3312 Train_Acc: 89.990 Val_Loss: 0.3661  BEST VAL Loss: 0.3661  Val_Acc: 88.185

Epoch 49: Validation loss decreased (0.366132 --> 0.365326).  Saving model ...
	 Train_Loss: 0.3298 Train_Acc: 90.389 Val_Loss: 0.3653  BEST VAL Loss: 0.3653  Val_Acc: 88.738

Epoch 50: Validation loss decreased (0.365326 --> 0.364744).  Saving model ...
	 Train_Loss: 0.3284 Train_Acc: 90.346 Val_Loss: 0.3647  BEST VAL Loss: 0.3647  Val_Acc: 88.015

Epoch 51: Validation loss decreased (0.364744 --> 0.364123).  Saving model ...
	 Train_Loss: 0.3272 Train_Acc: 90.362 Val_Loss: 0.3641  BEST VAL Loss: 0.3641  Val_Acc: 88.143

Epoch 52: Validation loss decreased (0.364123 --> 0.363392).  Saving model ...
	 Train_Loss: 0.3260 Train_Acc: 90.362 Val_Loss: 0.3634  BEST VAL Loss: 0.3634  Val_Acc: 88.865

Epoch 53: Validation loss decreased (0.363392 --> 0.362767).  Saving model ...
	 Train_Loss: 0.3248 Train_Acc: 90.676 Val_Loss: 0.3628  BEST VAL Loss: 0.3628  Val_Acc: 88.568

Epoch 54: Validation loss decreased (0.362767 --> 0.362355).  Saving model ...
	 Train_Loss: 0.3237 Train_Acc: 90.415 Val_Loss: 0.3624  BEST VAL Loss: 0.3624  Val_Acc: 88.143

Epoch 55: Validation loss decreased (0.362355 --> 0.361572).  Saving model ...
	 Train_Loss: 0.3227 Train_Acc: 90.235 Val_Loss: 0.3616  BEST VAL Loss: 0.3616  Val_Acc: 88.738

Epoch 56: Validation loss decreased (0.361572 --> 0.361010).  Saving model ...
	 Train_Loss: 0.3218 Train_Acc: 90.070 Val_Loss: 0.3610  BEST VAL Loss: 0.3610  Val_Acc: 87.378

Epoch 57: Validation loss decreased (0.361010 --> 0.360247).  Saving model ...
	 Train_Loss: 0.3209 Train_Acc: 90.049 Val_Loss: 0.3602  BEST VAL Loss: 0.3602  Val_Acc: 88.610

Epoch 58: Validation loss decreased (0.360247 --> 0.359633).  Saving model ...
	 Train_Loss: 0.3200 Train_Acc: 90.469 Val_Loss: 0.3596  BEST VAL Loss: 0.3596  Val_Acc: 88.398

Epoch 59: Validation loss decreased (0.359633 --> 0.359064).  Saving model ...
	 Train_Loss: 0.3189 Train_Acc: 90.500 Val_Loss: 0.3591  BEST VAL Loss: 0.3591  Val_Acc: 89.035

Epoch 60: Validation loss decreased (0.359064 --> 0.358695).  Saving model ...
	 Train_Loss: 0.3179 Train_Acc: 90.766 Val_Loss: 0.3587  BEST VAL Loss: 0.3587  Val_Acc: 88.568

Epoch 61: Validation loss decreased (0.358695 --> 0.358498).  Saving model ...
	 Train_Loss: 0.3169 Train_Acc: 90.676 Val_Loss: 0.3585  BEST VAL Loss: 0.3585  Val_Acc: 87.845

Epoch 62: Validation loss decreased (0.358498 --> 0.358006).  Saving model ...
	 Train_Loss: 0.3160 Train_Acc: 90.469 Val_Loss: 0.3580  BEST VAL Loss: 0.3580  Val_Acc: 88.440

Epoch 63: Validation loss decreased (0.358006 --> 0.357932).  Saving model ...
	 Train_Loss: 0.3150 Train_Acc: 90.904 Val_Loss: 0.3579  BEST VAL Loss: 0.3579  Val_Acc: 87.505

Epoch 64: Validation loss decreased (0.357932 --> 0.357448).  Saving model ...
	 Train_Loss: 0.3141 Train_Acc: 90.639 Val_Loss: 0.3574  BEST VAL Loss: 0.3574  Val_Acc: 88.440

Epoch 65: Validation loss decreased (0.357448 --> 0.356963).  Saving model ...
	 Train_Loss: 0.3133 Train_Acc: 90.559 Val_Loss: 0.3570  BEST VAL Loss: 0.3570  Val_Acc: 88.823

Epoch 66: Validation loss decreased (0.356963 --> 0.356845).  Saving model ...
	 Train_Loss: 0.3125 Train_Acc: 90.538 Val_Loss: 0.3568  BEST VAL Loss: 0.3568  Val_Acc: 88.780

Epoch 67: Validation loss decreased (0.356845 --> 0.356552).  Saving model ...
	 Train_Loss: 0.3116 Train_Acc: 90.888 Val_Loss: 0.3566  BEST VAL Loss: 0.3566  Val_Acc: 87.888

Epoch 68: Validation loss decreased (0.356552 --> 0.356324).  Saving model ...
	 Train_Loss: 0.3109 Train_Acc: 90.740 Val_Loss: 0.3563  BEST VAL Loss: 0.3563  Val_Acc: 88.568

Epoch 69: Validation loss decreased (0.356324 --> 0.356074).  Saving model ...
	 Train_Loss: 0.3100 Train_Acc: 91.122 Val_Loss: 0.3561  BEST VAL Loss: 0.3561  Val_Acc: 88.015

Epoch 70: Validation loss decreased (0.356074 --> 0.355979).  Saving model ...
	 Train_Loss: 0.3093 Train_Acc: 90.447 Val_Loss: 0.3560  BEST VAL Loss: 0.3560  Val_Acc: 88.015

Epoch 71: Validation loss decreased (0.355979 --> 0.355634).  Saving model ...
	 Train_Loss: 0.3086 Train_Acc: 90.495 Val_Loss: 0.3556  BEST VAL Loss: 0.3556  Val_Acc: 88.823

Epoch 72: Validation loss decreased (0.355634 --> 0.355352).  Saving model ...
	 Train_Loss: 0.3080 Train_Acc: 90.384 Val_Loss: 0.3554  BEST VAL Loss: 0.3554  Val_Acc: 88.738

Epoch 73: Validation loss decreased (0.355352 --> 0.354946).  Saving model ...
	 Train_Loss: 0.3073 Train_Acc: 90.782 Val_Loss: 0.3549  BEST VAL Loss: 0.3549  Val_Acc: 89.290

Epoch 74: Validation loss decreased (0.354946 --> 0.354635).  Saving model ...
	 Train_Loss: 0.3066 Train_Acc: 90.904 Val_Loss: 0.3546  BEST VAL Loss: 0.3546  Val_Acc: 89.418

Epoch 75: Validation loss decreased (0.354635 --> 0.354607).  Saving model ...
	 Train_Loss: 0.3058 Train_Acc: 91.111 Val_Loss: 0.3546  BEST VAL Loss: 0.3546  Val_Acc: 88.440

Epoch 76: Validation loss decreased (0.354607 --> 0.354258).  Saving model ...
	 Train_Loss: 0.3051 Train_Acc: 90.660 Val_Loss: 0.3543  BEST VAL Loss: 0.3543  Val_Acc: 88.440

Epoch 77: Validation loss decreased (0.354258 --> 0.354048).  Saving model ...
	 Train_Loss: 0.3045 Train_Acc: 90.867 Val_Loss: 0.3540  BEST VAL Loss: 0.3540  Val_Acc: 88.610

Epoch 78: Validation loss decreased (0.354048 --> 0.353645).  Saving model ...
	 Train_Loss: 0.3039 Train_Acc: 90.867 Val_Loss: 0.3536  BEST VAL Loss: 0.3536  Val_Acc: 88.568

Epoch 79: Validation loss decreased (0.353645 --> 0.353279).  Saving model ...
	 Train_Loss: 0.3033 Train_Acc: 90.623 Val_Loss: 0.3533  BEST VAL Loss: 0.3533  Val_Acc: 88.610

Epoch 80: Validation loss decreased (0.353279 --> 0.352926).  Saving model ...
	 Train_Loss: 0.3027 Train_Acc: 90.793 Val_Loss: 0.3529  BEST VAL Loss: 0.3529  Val_Acc: 88.823

Epoch 81: Validation loss decreased (0.352926 --> 0.352609).  Saving model ...
	 Train_Loss: 0.3021 Train_Acc: 91.218 Val_Loss: 0.3526  BEST VAL Loss: 0.3526  Val_Acc: 88.738

Epoch 82: Validation loss decreased (0.352609 --> 0.352551).  Saving model ...
	 Train_Loss: 0.3015 Train_Acc: 90.676 Val_Loss: 0.3526  BEST VAL Loss: 0.3526  Val_Acc: 89.503

Epoch 83: Validation loss decreased (0.352551 --> 0.352468).  Saving model ...
	 Train_Loss: 0.3008 Train_Acc: 91.441 Val_Loss: 0.3525  BEST VAL Loss: 0.3525  Val_Acc: 89.588

Epoch 84: Validation loss decreased (0.352468 --> 0.352280).  Saving model ...
	 Train_Loss: 0.3001 Train_Acc: 91.340 Val_Loss: 0.3523  BEST VAL Loss: 0.3523  Val_Acc: 88.993

Epoch 85: Validation loss decreased (0.352280 --> 0.352019).  Saving model ...
	 Train_Loss: 0.2994 Train_Acc: 91.324 Val_Loss: 0.3520  BEST VAL Loss: 0.3520  Val_Acc: 88.908

Epoch 86: Validation loss decreased (0.352019 --> 0.351770).  Saving model ...
	 Train_Loss: 0.2988 Train_Acc: 91.250 Val_Loss: 0.3518  BEST VAL Loss: 0.3518  Val_Acc: 88.653

Epoch 87: Validation loss decreased (0.351770 --> 0.351570).  Saving model ...
	 Train_Loss: 0.2982 Train_Acc: 91.085 Val_Loss: 0.3516  BEST VAL Loss: 0.3516  Val_Acc: 88.908

Epoch 88: Validation loss decreased (0.351570 --> 0.351302).  Saving model ...
	 Train_Loss: 0.2976 Train_Acc: 91.143 Val_Loss: 0.3513  BEST VAL Loss: 0.3513  Val_Acc: 88.993

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.2972 Train_Acc: 90.713 Val_Loss: 0.3514  BEST VAL Loss: 0.3513  Val_Acc: 88.568

Epoch 90: Validation loss decreased (0.351302 --> 0.351295).  Saving model ...
	 Train_Loss: 0.2967 Train_Acc: 91.111 Val_Loss: 0.3513  BEST VAL Loss: 0.3513  Val_Acc: 89.205

Epoch 91: Validation loss decreased (0.351295 --> 0.351165).  Saving model ...
	 Train_Loss: 0.2961 Train_Acc: 91.335 Val_Loss: 0.3512  BEST VAL Loss: 0.3512  Val_Acc: 89.248

Epoch 92: Validation loss decreased (0.351165 --> 0.351008).  Saving model ...
	 Train_Loss: 0.2955 Train_Acc: 91.563 Val_Loss: 0.3510  BEST VAL Loss: 0.3510  Val_Acc: 88.270

Epoch 93: Validation loss decreased (0.351008 --> 0.350990).  Saving model ...
	 Train_Loss: 0.2949 Train_Acc: 91.595 Val_Loss: 0.3510  BEST VAL Loss: 0.3510  Val_Acc: 89.290

Epoch 94: Validation loss decreased (0.350990 --> 0.350872).  Saving model ...
	 Train_Loss: 0.2943 Train_Acc: 91.420 Val_Loss: 0.3509  BEST VAL Loss: 0.3509  Val_Acc: 89.035

Epoch 95: Validation loss decreased (0.350872 --> 0.350698).  Saving model ...
	 Train_Loss: 0.2937 Train_Acc: 91.712 Val_Loss: 0.3507  BEST VAL Loss: 0.3507  Val_Acc: 89.078

Epoch 96: Validation loss decreased (0.350698 --> 0.350442).  Saving model ...
	 Train_Loss: 0.2931 Train_Acc: 91.781 Val_Loss: 0.3504  BEST VAL Loss: 0.3504  Val_Acc: 88.780

Epoch 97: Validation loss decreased (0.350442 --> 0.350159).  Saving model ...
	 Train_Loss: 0.2926 Train_Acc: 91.335 Val_Loss: 0.3502  BEST VAL Loss: 0.3502  Val_Acc: 89.418

Epoch 98: Validation loss decreased (0.350159 --> 0.350012).  Saving model ...
	 Train_Loss: 0.2921 Train_Acc: 91.659 Val_Loss: 0.3500  BEST VAL Loss: 0.3500  Val_Acc: 89.375

Epoch 99: Validation loss decreased (0.350012 --> 0.350001).  Saving model ...
	 Train_Loss: 0.2916 Train_Acc: 91.584 Val_Loss: 0.3500  BEST VAL Loss: 0.3500  Val_Acc: 89.163

Thapsigargin_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.96      0.93      0.95     10451
           1       0.92      0.96      0.94      8371

    accuracy                           0.94     18822
   macro avg       0.94      0.94      0.94     18822
weighted avg       0.94      0.94      0.94     18822

Thapsigargin_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.92      0.88      0.90      1307
           1       0.86      0.90      0.88      1046

    accuracy                           0.89      2353
   macro avg       0.89      0.89      0.89      2353
weighted avg       0.89      0.89      0.89      2353

Thapsigargin_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.91      0.89      0.90      1307
           1       0.87      0.89      0.88      1046

    accuracy                           0.89      2353
   macro avg       0.89      0.89      0.89      2353
weighted avg       0.89      0.89      0.89      2353

              precision    recall  f1-score   support

           0       0.91      0.89      0.90      1307
           1       0.87      0.89      0.88      1046

    accuracy                           0.89      2353
   macro avg       0.89      0.89      0.89      2353
weighted avg       0.89      0.89      0.89      2353

Thapsigargin_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.88      0.91      4445
           1       0.85      0.92      0.88      3303

    accuracy                           0.90      7748
   macro avg       0.89      0.90      0.90      7748
weighted avg       0.90      0.90      0.90      7748

              precision    recall  f1-score   support

           0       0.93      0.88      0.91      4445
           1       0.85      0.92      0.88      3303

    accuracy                           0.90      7748
   macro avg       0.89      0.90      0.90      7748
weighted avg       0.90      0.90      0.90      7748

completed
