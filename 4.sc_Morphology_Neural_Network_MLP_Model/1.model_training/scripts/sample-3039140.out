[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b03b8038'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '08cd6cc8'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'a7bda239'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '37dbeff5'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_0.100_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_0.100_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_0.100_DMSO_0.025']
The dimensions of the data are: (33369, 1276)
Number of total missing values across all columns: 66738
Data Subset Is Off
Wells held out for testing: ['B20' 'C21']
Wells to use for training, validation, and testing ['B16' 'C16' 'B17' 'C17' 'C20' 'B21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.680448).  Saving model ...
	 Train_Loss: 0.6902 Train_Acc: 52.795 Val_Loss: 0.6804  BEST VAL Loss: 0.6804  Val_Acc: 57.955

Epoch 1: Validation loss decreased (0.680448 --> 0.671776).  Saving model ...
	 Train_Loss: 0.6849 Train_Acc: 56.062 Val_Loss: 0.6718  BEST VAL Loss: 0.6718  Val_Acc: 61.734

Epoch 2: Validation loss decreased (0.671776 --> 0.663803).  Saving model ...
	 Train_Loss: 0.6790 Train_Acc: 58.827 Val_Loss: 0.6638  BEST VAL Loss: 0.6638  Val_Acc: 63.922

Epoch 3: Validation loss decreased (0.663803 --> 0.656419).  Saving model ...
	 Train_Loss: 0.6728 Train_Acc: 59.941 Val_Loss: 0.6564  BEST VAL Loss: 0.6564  Val_Acc: 64.280

Epoch 4: Validation loss decreased (0.656419 --> 0.649411).  Saving model ...
	 Train_Loss: 0.6664 Train_Acc: 61.747 Val_Loss: 0.6494  BEST VAL Loss: 0.6494  Val_Acc: 66.627

Epoch 5: Validation loss decreased (0.649411 --> 0.643244).  Saving model ...
	 Train_Loss: 0.6606 Train_Acc: 62.945 Val_Loss: 0.6432  BEST VAL Loss: 0.6432  Val_Acc: 67.900

Epoch 6: Validation loss decreased (0.643244 --> 0.637922).  Saving model ...
	 Train_Loss: 0.6546 Train_Acc: 63.840 Val_Loss: 0.6379  BEST VAL Loss: 0.6379  Val_Acc: 67.582

Epoch 7: Validation loss decreased (0.637922 --> 0.633899).  Saving model ...
	 Train_Loss: 0.6499 Train_Acc: 64.452 Val_Loss: 0.6339  BEST VAL Loss: 0.6339  Val_Acc: 67.582

Epoch 8: Validation loss decreased (0.633899 --> 0.630004).  Saving model ...
	 Train_Loss: 0.6456 Train_Acc: 65.183 Val_Loss: 0.6300  BEST VAL Loss: 0.6300  Val_Acc: 68.298

Epoch 9: Validation loss decreased (0.630004 --> 0.626401).  Saving model ...
	 Train_Loss: 0.6411 Train_Acc: 65.536 Val_Loss: 0.6264  BEST VAL Loss: 0.6264  Val_Acc: 68.576

Epoch 10: Validation loss decreased (0.626401 --> 0.623458).  Saving model ...
	 Train_Loss: 0.6372 Train_Acc: 65.675 Val_Loss: 0.6235  BEST VAL Loss: 0.6235  Val_Acc: 68.218

Epoch 11: Validation loss decreased (0.623458 --> 0.620188).  Saving model ...
	 Train_Loss: 0.6337 Train_Acc: 66.690 Val_Loss: 0.6202  BEST VAL Loss: 0.6202  Val_Acc: 67.940

Epoch 12: Validation loss decreased (0.620188 --> 0.617293).  Saving model ...
	 Train_Loss: 0.6308 Train_Acc: 66.909 Val_Loss: 0.6173  BEST VAL Loss: 0.6173  Val_Acc: 68.854

Epoch 13: Validation loss decreased (0.617293 --> 0.614720).  Saving model ...
	 Train_Loss: 0.6275 Train_Acc: 67.381 Val_Loss: 0.6147  BEST VAL Loss: 0.6147  Val_Acc: 69.411

Epoch 14: Validation loss decreased (0.614720 --> 0.612171).  Saving model ...
	 Train_Loss: 0.6246 Train_Acc: 67.744 Val_Loss: 0.6122  BEST VAL Loss: 0.6122  Val_Acc: 69.133

Epoch 15: Validation loss decreased (0.612171 --> 0.610141).  Saving model ...
	 Train_Loss: 0.6216 Train_Acc: 68.401 Val_Loss: 0.6101  BEST VAL Loss: 0.6101  Val_Acc: 68.377

Epoch 16: Validation loss decreased (0.610141 --> 0.608445).  Saving model ...
	 Train_Loss: 0.6192 Train_Acc: 67.794 Val_Loss: 0.6084  BEST VAL Loss: 0.6084  Val_Acc: 68.854

Epoch 17: Validation loss decreased (0.608445 --> 0.606644).  Saving model ...
	 Train_Loss: 0.6169 Train_Acc: 68.326 Val_Loss: 0.6066  BEST VAL Loss: 0.6066  Val_Acc: 69.372

Epoch 18: Validation loss decreased (0.606644 --> 0.604916).  Saving model ...
	 Train_Loss: 0.6150 Train_Acc: 68.555 Val_Loss: 0.6049  BEST VAL Loss: 0.6049  Val_Acc: 69.769

Epoch 19: Validation loss decreased (0.604916 --> 0.603221).  Saving model ...
	 Train_Loss: 0.6130 Train_Acc: 68.341 Val_Loss: 0.6032  BEST VAL Loss: 0.6032  Val_Acc: 69.928

Epoch 20: Validation loss decreased (0.603221 --> 0.601590).  Saving model ...
	 Train_Loss: 0.6110 Train_Acc: 68.311 Val_Loss: 0.6016  BEST VAL Loss: 0.6016  Val_Acc: 70.048

Epoch 21: Validation loss decreased (0.601590 --> 0.600085).  Saving model ...
	 Train_Loss: 0.6091 Train_Acc: 68.440 Val_Loss: 0.6001  BEST VAL Loss: 0.6001  Val_Acc: 69.690

Epoch 22: Validation loss decreased (0.600085 --> 0.598681).  Saving model ...
	 Train_Loss: 0.6074 Train_Acc: 68.605 Val_Loss: 0.5987  BEST VAL Loss: 0.5987  Val_Acc: 69.451

Epoch 23: Validation loss decreased (0.598681 --> 0.597486).  Saving model ...
	 Train_Loss: 0.6059 Train_Acc: 68.798 Val_Loss: 0.5975  BEST VAL Loss: 0.5975  Val_Acc: 69.411

Epoch 24: Validation loss decreased (0.597486 --> 0.596330).  Saving model ...
	 Train_Loss: 0.6046 Train_Acc: 68.246 Val_Loss: 0.5963  BEST VAL Loss: 0.5963  Val_Acc: 70.684

Epoch 25: Validation loss decreased (0.596330 --> 0.595062).  Saving model ...
	 Train_Loss: 0.6031 Train_Acc: 68.754 Val_Loss: 0.5951  BEST VAL Loss: 0.5951  Val_Acc: 69.769

Epoch 26: Validation loss decreased (0.595062 --> 0.593991).  Saving model ...
	 Train_Loss: 0.6016 Train_Acc: 68.938 Val_Loss: 0.5940  BEST VAL Loss: 0.5940  Val_Acc: 69.292

Epoch 27: Validation loss decreased (0.593991 --> 0.593082).  Saving model ...
	 Train_Loss: 0.6004 Train_Acc: 68.629 Val_Loss: 0.5931  BEST VAL Loss: 0.5931  Val_Acc: 69.491

Epoch 28: Validation loss decreased (0.593082 --> 0.592133).  Saving model ...
	 Train_Loss: 0.5991 Train_Acc: 68.913 Val_Loss: 0.5921  BEST VAL Loss: 0.5921  Val_Acc: 70.247

Epoch 29: Validation loss decreased (0.592133 --> 0.591129).  Saving model ...
	 Train_Loss: 0.5979 Train_Acc: 69.162 Val_Loss: 0.5911  BEST VAL Loss: 0.5911  Val_Acc: 70.207

Epoch 30: Validation loss decreased (0.591129 --> 0.590338).  Saving model ...
	 Train_Loss: 0.5968 Train_Acc: 68.848 Val_Loss: 0.5903  BEST VAL Loss: 0.5903  Val_Acc: 69.292

Epoch 31: Validation loss decreased (0.590338 --> 0.589450).  Saving model ...
	 Train_Loss: 0.5957 Train_Acc: 69.370 Val_Loss: 0.5894  BEST VAL Loss: 0.5894  Val_Acc: 70.088

Epoch 32: Validation loss decreased (0.589450 --> 0.588566).  Saving model ...
	 Train_Loss: 0.5944 Train_Acc: 69.937 Val_Loss: 0.5886  BEST VAL Loss: 0.5886  Val_Acc: 70.843

Epoch 33: Validation loss decreased (0.588566 --> 0.587656).  Saving model ...
	 Train_Loss: 0.5932 Train_Acc: 69.704 Val_Loss: 0.5877  BEST VAL Loss: 0.5877  Val_Acc: 70.406

Epoch 34: Validation loss decreased (0.587656 --> 0.587016).  Saving model ...
	 Train_Loss: 0.5922 Train_Acc: 69.435 Val_Loss: 0.5870  BEST VAL Loss: 0.5870  Val_Acc: 70.048

Epoch 35: Validation loss decreased (0.587016 --> 0.586236).  Saving model ...
	 Train_Loss: 0.5911 Train_Acc: 69.460 Val_Loss: 0.5862  BEST VAL Loss: 0.5862  Val_Acc: 71.082

Epoch 36: Validation loss decreased (0.586236 --> 0.585521).  Saving model ...
	 Train_Loss: 0.5900 Train_Acc: 69.773 Val_Loss: 0.5855  BEST VAL Loss: 0.5855  Val_Acc: 71.042

Epoch 37: Validation loss decreased (0.585521 --> 0.584751).  Saving model ...
	 Train_Loss: 0.5890 Train_Acc: 70.032 Val_Loss: 0.5848  BEST VAL Loss: 0.5848  Val_Acc: 70.525

Epoch 38: Validation loss decreased (0.584751 --> 0.584031).  Saving model ...
	 Train_Loss: 0.5880 Train_Acc: 69.793 Val_Loss: 0.5840  BEST VAL Loss: 0.5840  Val_Acc: 70.804

Epoch 39: Validation loss decreased (0.584031 --> 0.583352).  Saving model ...
	 Train_Loss: 0.5871 Train_Acc: 69.927 Val_Loss: 0.5834  BEST VAL Loss: 0.5834  Val_Acc: 70.843

Epoch 40: Validation loss decreased (0.583352 --> 0.582872).  Saving model ...
	 Train_Loss: 0.5862 Train_Acc: 69.395 Val_Loss: 0.5829  BEST VAL Loss: 0.5829  Val_Acc: 69.451

Epoch 41: Validation loss decreased (0.582872 --> 0.582259).  Saving model ...
	 Train_Loss: 0.5855 Train_Acc: 69.395 Val_Loss: 0.5823  BEST VAL Loss: 0.5823  Val_Acc: 70.088

Epoch 42: Validation loss decreased (0.582259 --> 0.581706).  Saving model ...
	 Train_Loss: 0.5847 Train_Acc: 69.644 Val_Loss: 0.5817  BEST VAL Loss: 0.5817  Val_Acc: 70.764

Epoch 43: Validation loss decreased (0.581706 --> 0.581143).  Saving model ...
	 Train_Loss: 0.5840 Train_Acc: 69.689 Val_Loss: 0.5811  BEST VAL Loss: 0.5811  Val_Acc: 70.406

Epoch 44: Validation loss decreased (0.581143 --> 0.580629).  Saving model ...
	 Train_Loss: 0.5830 Train_Acc: 70.295 Val_Loss: 0.5806  BEST VAL Loss: 0.5806  Val_Acc: 70.406

Epoch 45: Validation loss decreased (0.580629 --> 0.580097).  Saving model ...
	 Train_Loss: 0.5823 Train_Acc: 69.689 Val_Loss: 0.5801  BEST VAL Loss: 0.5801  Val_Acc: 70.644

Epoch 46: Validation loss decreased (0.580097 --> 0.579715).  Saving model ...
	 Train_Loss: 0.5815 Train_Acc: 69.907 Val_Loss: 0.5797  BEST VAL Loss: 0.5797  Val_Acc: 70.127

Epoch 47: Validation loss decreased (0.579715 --> 0.579275).  Saving model ...
	 Train_Loss: 0.5808 Train_Acc: 70.012 Val_Loss: 0.5793  BEST VAL Loss: 0.5793  Val_Acc: 70.207

Epoch 48: Validation loss decreased (0.579275 --> 0.578738).  Saving model ...
	 Train_Loss: 0.5801 Train_Acc: 70.186 Val_Loss: 0.5787  BEST VAL Loss: 0.5787  Val_Acc: 70.644

Epoch 49: Validation loss decreased (0.578738 --> 0.578200).  Saving model ...
	 Train_Loss: 0.5793 Train_Acc: 69.868 Val_Loss: 0.5782  BEST VAL Loss: 0.5782  Val_Acc: 71.281

Epoch 50: Validation loss decreased (0.578200 --> 0.577684).  Saving model ...
	 Train_Loss: 0.5787 Train_Acc: 69.942 Val_Loss: 0.5777  BEST VAL Loss: 0.5777  Val_Acc: 70.644

Epoch 51: Validation loss decreased (0.577684 --> 0.577288).  Saving model ...
	 Train_Loss: 0.5780 Train_Acc: 70.216 Val_Loss: 0.5773  BEST VAL Loss: 0.5773  Val_Acc: 70.446

Epoch 52: Validation loss decreased (0.577288 --> 0.576909).  Saving model ...
	 Train_Loss: 0.5774 Train_Acc: 70.360 Val_Loss: 0.5769  BEST VAL Loss: 0.5769  Val_Acc: 70.565

Epoch 53: Validation loss decreased (0.576909 --> 0.576596).  Saving model ...
	 Train_Loss: 0.5768 Train_Acc: 69.719 Val_Loss: 0.5766  BEST VAL Loss: 0.5766  Val_Acc: 70.923

Epoch 54: Validation loss decreased (0.576596 --> 0.576270).  Saving model ...
	 Train_Loss: 0.5763 Train_Acc: 69.311 Val_Loss: 0.5763  BEST VAL Loss: 0.5763  Val_Acc: 69.769

Epoch 55: Validation loss decreased (0.576270 --> 0.575898).  Saving model ...
	 Train_Loss: 0.5758 Train_Acc: 69.699 Val_Loss: 0.5759  BEST VAL Loss: 0.5759  Val_Acc: 70.605

Epoch 56: Validation loss decreased (0.575898 --> 0.575629).  Saving model ...
	 Train_Loss: 0.5752 Train_Acc: 69.803 Val_Loss: 0.5756  BEST VAL Loss: 0.5756  Val_Acc: 70.048

Epoch 57: Validation loss decreased (0.575629 --> 0.575239).  Saving model ...
	 Train_Loss: 0.5747 Train_Acc: 70.216 Val_Loss: 0.5752  BEST VAL Loss: 0.5752  Val_Acc: 70.684

Epoch 58: Validation loss decreased (0.575239 --> 0.574909).  Saving model ...
	 Train_Loss: 0.5741 Train_Acc: 69.783 Val_Loss: 0.5749  BEST VAL Loss: 0.5749  Val_Acc: 71.161

Epoch 59: Validation loss decreased (0.574909 --> 0.574622).  Saving model ...
	 Train_Loss: 0.5736 Train_Acc: 69.748 Val_Loss: 0.5746  BEST VAL Loss: 0.5746  Val_Acc: 70.605

Epoch 60: Validation loss decreased (0.574622 --> 0.574409).  Saving model ...
	 Train_Loss: 0.5730 Train_Acc: 70.315 Val_Loss: 0.5744  BEST VAL Loss: 0.5744  Val_Acc: 70.684

Epoch 61: Validation loss decreased (0.574409 --> 0.574182).  Saving model ...
	 Train_Loss: 0.5726 Train_Acc: 69.813 Val_Loss: 0.5742  BEST VAL Loss: 0.5742  Val_Acc: 70.286

Epoch 62: Validation loss decreased (0.574182 --> 0.573900).  Saving model ...
	 Train_Loss: 0.5722 Train_Acc: 69.898 Val_Loss: 0.5739  BEST VAL Loss: 0.5739  Val_Acc: 70.644

Epoch 63: Validation loss decreased (0.573900 --> 0.573659).  Saving model ...
	 Train_Loss: 0.5716 Train_Acc: 69.967 Val_Loss: 0.5737  BEST VAL Loss: 0.5737  Val_Acc: 70.843

Epoch 64: Validation loss decreased (0.573659 --> 0.573508).  Saving model ...
	 Train_Loss: 0.5711 Train_Acc: 70.300 Val_Loss: 0.5735  BEST VAL Loss: 0.5735  Val_Acc: 70.565

Epoch 65: Validation loss decreased (0.573508 --> 0.573316).  Saving model ...
	 Train_Loss: 0.5706 Train_Acc: 69.798 Val_Loss: 0.5733  BEST VAL Loss: 0.5733  Val_Acc: 71.201

Epoch 66: Validation loss decreased (0.573316 --> 0.573105).  Saving model ...
	 Train_Loss: 0.5701 Train_Acc: 70.196 Val_Loss: 0.5731  BEST VAL Loss: 0.5731  Val_Acc: 71.559

Epoch 67: Validation loss decreased (0.573105 --> 0.572892).  Saving model ...
	 Train_Loss: 0.5697 Train_Acc: 69.927 Val_Loss: 0.5729  BEST VAL Loss: 0.5729  Val_Acc: 71.042

Epoch 68: Validation loss decreased (0.572892 --> 0.572669).  Saving model ...
	 Train_Loss: 0.5693 Train_Acc: 69.863 Val_Loss: 0.5727  BEST VAL Loss: 0.5727  Val_Acc: 71.161

Epoch 69: Validation loss decreased (0.572669 --> 0.572423).  Saving model ...
	 Train_Loss: 0.5688 Train_Acc: 70.450 Val_Loss: 0.5724  BEST VAL Loss: 0.5724  Val_Acc: 70.485

Epoch 70: Validation loss decreased (0.572423 --> 0.572191).  Saving model ...
	 Train_Loss: 0.5684 Train_Acc: 70.474 Val_Loss: 0.5722  BEST VAL Loss: 0.5722  Val_Acc: 70.963

Epoch 71: Validation loss decreased (0.572191 --> 0.572104).  Saving model ...
	 Train_Loss: 0.5679 Train_Acc: 69.888 Val_Loss: 0.5721  BEST VAL Loss: 0.5721  Val_Acc: 71.440

Epoch 72: Validation loss decreased (0.572104 --> 0.571951).  Saving model ...
	 Train_Loss: 0.5675 Train_Acc: 70.539 Val_Loss: 0.5720  BEST VAL Loss: 0.5720  Val_Acc: 70.406

Epoch 73: Validation loss decreased (0.571951 --> 0.571700).  Saving model ...
	 Train_Loss: 0.5671 Train_Acc: 70.474 Val_Loss: 0.5717  BEST VAL Loss: 0.5717  Val_Acc: 70.525

Epoch 74: Validation loss decreased (0.571700 --> 0.571432).  Saving model ...
	 Train_Loss: 0.5667 Train_Acc: 69.917 Val_Loss: 0.5714  BEST VAL Loss: 0.5714  Val_Acc: 71.241

Epoch 75: Validation loss decreased (0.571432 --> 0.571297).  Saving model ...
	 Train_Loss: 0.5664 Train_Acc: 69.723 Val_Loss: 0.5713  BEST VAL Loss: 0.5713  Val_Acc: 71.201

Epoch 76: Validation loss decreased (0.571297 --> 0.571194).  Saving model ...
	 Train_Loss: 0.5660 Train_Acc: 69.365 Val_Loss: 0.5712  BEST VAL Loss: 0.5712  Val_Acc: 70.644

Epoch 77: Validation loss decreased (0.571194 --> 0.570972).  Saving model ...
	 Train_Loss: 0.5657 Train_Acc: 70.330 Val_Loss: 0.5710  BEST VAL Loss: 0.5710  Val_Acc: 71.599

Epoch 78: Validation loss decreased (0.570972 --> 0.570802).  Saving model ...
	 Train_Loss: 0.5654 Train_Acc: 69.564 Val_Loss: 0.5708  BEST VAL Loss: 0.5708  Val_Acc: 70.605

Epoch 79: Validation loss decreased (0.570802 --> 0.570644).  Saving model ...
	 Train_Loss: 0.5650 Train_Acc: 69.629 Val_Loss: 0.5706  BEST VAL Loss: 0.5706  Val_Acc: 70.605

Epoch 80: Validation loss decreased (0.570644 --> 0.570427).  Saving model ...
	 Train_Loss: 0.5647 Train_Acc: 70.211 Val_Loss: 0.5704  BEST VAL Loss: 0.5704  Val_Acc: 70.843

Epoch 81: Validation loss decreased (0.570427 --> 0.570249).  Saving model ...
	 Train_Loss: 0.5643 Train_Acc: 70.067 Val_Loss: 0.5702  BEST VAL Loss: 0.5702  Val_Acc: 70.963

Epoch 82: Validation loss decreased (0.570249 --> 0.570058).  Saving model ...
	 Train_Loss: 0.5639 Train_Acc: 70.241 Val_Loss: 0.5701  BEST VAL Loss: 0.5701  Val_Acc: 71.400

Epoch 83: Validation loss decreased (0.570058 --> 0.569940).  Saving model ...
	 Train_Loss: 0.5635 Train_Acc: 70.325 Val_Loss: 0.5699  BEST VAL Loss: 0.5699  Val_Acc: 71.122

Epoch 84: Validation loss decreased (0.569940 --> 0.569835).  Saving model ...
	 Train_Loss: 0.5631 Train_Acc: 70.942 Val_Loss: 0.5698  BEST VAL Loss: 0.5698  Val_Acc: 70.485

Epoch 85: Validation loss decreased (0.569835 --> 0.569669).  Saving model ...
	 Train_Loss: 0.5627 Train_Acc: 70.101 Val_Loss: 0.5697  BEST VAL Loss: 0.5697  Val_Acc: 71.002

Epoch 86: Validation loss decreased (0.569669 --> 0.569501).  Saving model ...
	 Train_Loss: 0.5624 Train_Acc: 70.072 Val_Loss: 0.5695  BEST VAL Loss: 0.5695  Val_Acc: 70.644

Epoch 87: Validation loss decreased (0.569501 --> 0.569348).  Saving model ...
	 Train_Loss: 0.5620 Train_Acc: 70.952 Val_Loss: 0.5693  BEST VAL Loss: 0.5693  Val_Acc: 70.167

Epoch 88: Validation loss decreased (0.569348 --> 0.569151).  Saving model ...
	 Train_Loss: 0.5617 Train_Acc: 70.539 Val_Loss: 0.5692  BEST VAL Loss: 0.5692  Val_Acc: 70.963

Epoch 89: Validation loss decreased (0.569151 --> 0.568965).  Saving model ...
	 Train_Loss: 0.5614 Train_Acc: 69.803 Val_Loss: 0.5690  BEST VAL Loss: 0.5690  Val_Acc: 70.724

Epoch 90: Validation loss decreased (0.568965 --> 0.568839).  Saving model ...
	 Train_Loss: 0.5611 Train_Acc: 70.469 Val_Loss: 0.5688  BEST VAL Loss: 0.5688  Val_Acc: 70.724

Epoch 91: Validation loss decreased (0.568839 --> 0.568741).  Saving model ...
	 Train_Loss: 0.5608 Train_Acc: 69.992 Val_Loss: 0.5687  BEST VAL Loss: 0.5687  Val_Acc: 70.286

Epoch 92: Validation loss decreased (0.568741 --> 0.568648).  Saving model ...
	 Train_Loss: 0.5604 Train_Acc: 70.141 Val_Loss: 0.5686  BEST VAL Loss: 0.5686  Val_Acc: 69.928

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.5601 Train_Acc: 70.768 Val_Loss: 0.5687  BEST VAL Loss: 0.5686  Val_Acc: 70.326

Epoch 94: Validation loss decreased (0.568648 --> 0.568641).  Saving model ...
	 Train_Loss: 0.5598 Train_Acc: 69.813 Val_Loss: 0.5686  BEST VAL Loss: 0.5686  Val_Acc: 70.684

Epoch 95: Validation loss decreased (0.568641 --> 0.568571).  Saving model ...
	 Train_Loss: 0.5595 Train_Acc: 70.276 Val_Loss: 0.5686  BEST VAL Loss: 0.5686  Val_Acc: 70.525

Epoch 96: Validation loss decreased (0.568571 --> 0.568489).  Saving model ...
	 Train_Loss: 0.5593 Train_Acc: 70.450 Val_Loss: 0.5685  BEST VAL Loss: 0.5685  Val_Acc: 70.167

Epoch 97: Validation loss decreased (0.568489 --> 0.568473).  Saving model ...
	 Train_Loss: 0.5590 Train_Acc: 70.131 Val_Loss: 0.5685  BEST VAL Loss: 0.5685  Val_Acc: 69.690

Epoch 98: Validation loss decreased (0.568473 --> 0.568411).  Saving model ...
	 Train_Loss: 0.5587 Train_Acc: 70.305 Val_Loss: 0.5684  BEST VAL Loss: 0.5684  Val_Acc: 70.207

Epoch 99: Validation loss decreased (0.568411 --> 0.568396).  Saving model ...
	 Train_Loss: 0.5585 Train_Acc: 70.196 Val_Loss: 0.5684  BEST VAL Loss: 0.5684  Val_Acc: 70.167

LPS_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.80      0.72      0.76      9707
           1       0.76      0.83      0.80     10401

    accuracy                           0.78     20108
   macro avg       0.78      0.78      0.78     20108
weighted avg       0.78      0.78      0.78     20108

LPS_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.70      0.66      0.68      1214
           1       0.70      0.74      0.72      1300

    accuracy                           0.70      2514
   macro avg       0.70      0.70      0.70      2514
weighted avg       0.70      0.70      0.70      2514

LPS_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.73      0.66      0.69      1214
           1       0.71      0.77      0.74      1300

    accuracy                           0.72      2514
   macro avg       0.72      0.72      0.72      2514
weighted avg       0.72      0.72      0.72      2514

              precision    recall  f1-score   support

           0       0.73      0.66      0.69      1214
           1       0.71      0.77      0.74      1300

    accuracy                           0.72      2514
   macro avg       0.72      0.72      0.72      2514
weighted avg       0.72      0.72      0.72      2514

LPS_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.64      0.68      0.66      3724
           1       0.72      0.68      0.70      4509

    accuracy                           0.68      8233
   macro avg       0.68      0.68      0.68      8233
weighted avg       0.68      0.68      0.68      8233

              precision    recall  f1-score   support

           0       0.64      0.68      0.66      3724
           1       0.72      0.68      0.70      4509

    accuracy                           0.68      8233
   macro avg       0.68      0.68      0.68      8233
weighted avg       0.68      0.68      0.68      8233

completed
