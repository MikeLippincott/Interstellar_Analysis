[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'bbc0e7ed'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '78675c6c'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '2838bca6'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e3d603ad'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: H2O2_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: H2O2_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['H2O2_100.000_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (414797, 1270)
Number of total missing values across all columns: 481072
Data Subset Is Off
Wells held out for testing: ['I10' 'L08']
Wells to use for training, validation, and testing ['H04' 'I04' 'H05' 'I05' 'H10' 'H11' 'I11' 'L02' 'L03' 'L09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.230703).  Saving model ...
	 Train_Loss: 0.4126 Train_Acc: 79.056 Val_Loss: 0.2307  BEST VAL Loss: 0.2307  Val_Acc: 94.923

Epoch 1: Validation loss decreased (0.230703 --> 0.221386).  Saving model ...
	 Train_Loss: 0.3928 Train_Acc: 81.373 Val_Loss: 0.2214  BEST VAL Loss: 0.2214  Val_Acc: 95.601

Epoch 2: Validation loss decreased (0.221386 --> 0.217632).  Saving model ...
	 Train_Loss: 0.3840 Train_Acc: 81.773 Val_Loss: 0.2176  BEST VAL Loss: 0.2176  Val_Acc: 95.848

Epoch 3: Validation loss decreased (0.217632 --> 0.213759).  Saving model ...
	 Train_Loss: 0.3784 Train_Acc: 82.104 Val_Loss: 0.2138  BEST VAL Loss: 0.2138  Val_Acc: 96.010

Epoch 4: Validation loss decreased (0.213759 --> 0.211971).  Saving model ...
	 Train_Loss: 0.3748 Train_Acc: 82.177 Val_Loss: 0.2120  BEST VAL Loss: 0.2120  Val_Acc: 95.925

Epoch 5: Validation loss decreased (0.211971 --> 0.209090).  Saving model ...
	 Train_Loss: 0.3718 Train_Acc: 82.367 Val_Loss: 0.2091  BEST VAL Loss: 0.2091  Val_Acc: 96.299

Epoch 6: Validation loss decreased (0.209090 --> 0.208081).  Saving model ...
	 Train_Loss: 0.3694 Train_Acc: 82.503 Val_Loss: 0.2081  BEST VAL Loss: 0.2081  Val_Acc: 96.278

Epoch 7: Validation loss decreased (0.208081 --> 0.207420).  Saving model ...
	 Train_Loss: 0.3675 Train_Acc: 82.613 Val_Loss: 0.2074  BEST VAL Loss: 0.2074  Val_Acc: 96.087

Epoch 8: Validation loss decreased (0.207420 --> 0.205882).  Saving model ...
	 Train_Loss: 0.3659 Train_Acc: 82.687 Val_Loss: 0.2059  BEST VAL Loss: 0.2059  Val_Acc: 96.349

Epoch 9: Validation loss decreased (0.205882 --> 0.204948).  Saving model ...
	 Train_Loss: 0.3643 Train_Acc: 82.842 Val_Loss: 0.2049  BEST VAL Loss: 0.2049  Val_Acc: 96.520

Epoch 10: Validation loss decreased (0.204948 --> 0.204402).  Saving model ...
	 Train_Loss: 0.3632 Train_Acc: 82.687 Val_Loss: 0.2044  BEST VAL Loss: 0.2044  Val_Acc: 96.302

Epoch 11: Validation loss decreased (0.204402 --> 0.203420).  Saving model ...
	 Train_Loss: 0.3621 Train_Acc: 82.849 Val_Loss: 0.2034  BEST VAL Loss: 0.2034  Val_Acc: 96.432

Epoch 12: Validation loss did not decrease
	 Train_Loss: 0.3612 Train_Acc: 82.766 Val_Loss: 0.2036  BEST VAL Loss: 0.2034  Val_Acc: 96.237

Epoch 13: Validation loss decreased (0.203420 --> 0.202712).  Saving model ...
	 Train_Loss: 0.3603 Train_Acc: 82.934 Val_Loss: 0.2027  BEST VAL Loss: 0.2027  Val_Acc: 96.546

Epoch 14: Validation loss decreased (0.202712 --> 0.201968).  Saving model ...
	 Train_Loss: 0.3595 Train_Acc: 82.893 Val_Loss: 0.2020  BEST VAL Loss: 0.2020  Val_Acc: 96.541

Epoch 15: Validation loss decreased (0.201968 --> 0.201824).  Saving model ...
	 Train_Loss: 0.3588 Train_Acc: 82.914 Val_Loss: 0.2018  BEST VAL Loss: 0.2018  Val_Acc: 96.228

Epoch 16: Validation loss decreased (0.201824 --> 0.201594).  Saving model ...
	 Train_Loss: 0.3582 Train_Acc: 82.926 Val_Loss: 0.2016  BEST VAL Loss: 0.2016  Val_Acc: 96.588

Epoch 17: Validation loss decreased (0.201594 --> 0.200850).  Saving model ...
	 Train_Loss: 0.3575 Train_Acc: 83.112 Val_Loss: 0.2008  BEST VAL Loss: 0.2008  Val_Acc: 96.779

Epoch 18: Validation loss decreased (0.200850 --> 0.200189).  Saving model ...
	 Train_Loss: 0.3569 Train_Acc: 83.042 Val_Loss: 0.2002  BEST VAL Loss: 0.2002  Val_Acc: 96.644

Epoch 19: Validation loss decreased (0.200189 --> 0.199449).  Saving model ...
	 Train_Loss: 0.3564 Train_Acc: 82.903 Val_Loss: 0.1994  BEST VAL Loss: 0.1994  Val_Acc: 96.829

Epoch 20: Validation loss decreased (0.199449 --> 0.199068).  Saving model ...
	 Train_Loss: 0.3559 Train_Acc: 83.017 Val_Loss: 0.1991  BEST VAL Loss: 0.1991  Val_Acc: 96.644

Epoch 21: Validation loss decreased (0.199068 --> 0.198859).  Saving model ...
	 Train_Loss: 0.3555 Train_Acc: 82.994 Val_Loss: 0.1989  BEST VAL Loss: 0.1989  Val_Acc: 96.576

Epoch 22: Validation loss decreased (0.198859 --> 0.198375).  Saving model ...
	 Train_Loss: 0.3550 Train_Acc: 83.148 Val_Loss: 0.1984  BEST VAL Loss: 0.1984  Val_Acc: 96.818

Epoch 23: Validation loss decreased (0.198375 --> 0.197925).  Saving model ...
	 Train_Loss: 0.3546 Train_Acc: 83.137 Val_Loss: 0.1979  BEST VAL Loss: 0.1979  Val_Acc: 96.744

Epoch 24: Validation loss decreased (0.197925 --> 0.197586).  Saving model ...
	 Train_Loss: 0.3542 Train_Acc: 83.044 Val_Loss: 0.1976  BEST VAL Loss: 0.1976  Val_Acc: 96.856

Epoch 25: Validation loss decreased (0.197586 --> 0.197078).  Saving model ...
	 Train_Loss: 0.3538 Train_Acc: 83.174 Val_Loss: 0.1971  BEST VAL Loss: 0.1971  Val_Acc: 96.661

Epoch 26: Validation loss decreased (0.197078 --> 0.196595).  Saving model ...
	 Train_Loss: 0.3535 Train_Acc: 83.110 Val_Loss: 0.1966  BEST VAL Loss: 0.1966  Val_Acc: 96.930

Epoch 27: Validation loss decreased (0.196595 --> 0.196278).  Saving model ...
	 Train_Loss: 0.3531 Train_Acc: 83.148 Val_Loss: 0.1963  BEST VAL Loss: 0.1963  Val_Acc: 96.826

Epoch 28: Validation loss decreased (0.196278 --> 0.195939).  Saving model ...
	 Train_Loss: 0.3529 Train_Acc: 83.039 Val_Loss: 0.1959  BEST VAL Loss: 0.1959  Val_Acc: 96.829

Epoch 29: Validation loss decreased (0.195939 --> 0.195419).  Saving model ...
	 Train_Loss: 0.3526 Train_Acc: 83.129 Val_Loss: 0.1954  BEST VAL Loss: 0.1954  Val_Acc: 96.879

Epoch 30: Validation loss decreased (0.195419 --> 0.195087).  Saving model ...
	 Train_Loss: 0.3522 Train_Acc: 83.251 Val_Loss: 0.1951  BEST VAL Loss: 0.1951  Val_Acc: 96.835

Epoch 31: Validation loss decreased (0.195087 --> 0.194937).  Saving model ...
	 Train_Loss: 0.3519 Train_Acc: 83.260 Val_Loss: 0.1949  BEST VAL Loss: 0.1949  Val_Acc: 96.944

Epoch 32: Validation loss decreased (0.194937 --> 0.194671).  Saving model ...
	 Train_Loss: 0.3516 Train_Acc: 83.291 Val_Loss: 0.1947  BEST VAL Loss: 0.1947  Val_Acc: 96.871

Epoch 33: Validation loss decreased (0.194671 --> 0.194592).  Saving model ...
	 Train_Loss: 0.3514 Train_Acc: 83.084 Val_Loss: 0.1946  BEST VAL Loss: 0.1946  Val_Acc: 96.673

Epoch 34: Validation loss decreased (0.194592 --> 0.194355).  Saving model ...
	 Train_Loss: 0.3511 Train_Acc: 83.281 Val_Loss: 0.1944  BEST VAL Loss: 0.1944  Val_Acc: 96.977

Epoch 35: Validation loss decreased (0.194355 --> 0.194074).  Saving model ...
	 Train_Loss: 0.3509 Train_Acc: 83.278 Val_Loss: 0.1941  BEST VAL Loss: 0.1941  Val_Acc: 96.906

Epoch 36: Validation loss decreased (0.194074 --> 0.193785).  Saving model ...
	 Train_Loss: 0.3506 Train_Acc: 83.254 Val_Loss: 0.1938  BEST VAL Loss: 0.1938  Val_Acc: 96.599

Epoch 37: Validation loss decreased (0.193785 --> 0.193449).  Saving model ...
	 Train_Loss: 0.3504 Train_Acc: 83.280 Val_Loss: 0.1934  BEST VAL Loss: 0.1934  Val_Acc: 96.968

Epoch 38: Validation loss decreased (0.193449 --> 0.193346).  Saving model ...
	 Train_Loss: 0.3502 Train_Acc: 83.134 Val_Loss: 0.1933  BEST VAL Loss: 0.1933  Val_Acc: 96.756

Epoch 39: Validation loss decreased (0.193346 --> 0.193248).  Saving model ...
	 Train_Loss: 0.3500 Train_Acc: 83.281 Val_Loss: 0.1932  BEST VAL Loss: 0.1932  Val_Acc: 96.785

Epoch 40: Validation loss decreased (0.193248 --> 0.192940).  Saving model ...
	 Train_Loss: 0.3498 Train_Acc: 83.387 Val_Loss: 0.1929  BEST VAL Loss: 0.1929  Val_Acc: 96.797

Epoch 41: Validation loss decreased (0.192940 --> 0.192746).  Saving model ...
	 Train_Loss: 0.3496 Train_Acc: 83.334 Val_Loss: 0.1927  BEST VAL Loss: 0.1927  Val_Acc: 96.800

Epoch 42: Validation loss decreased (0.192746 --> 0.192608).  Saving model ...
	 Train_Loss: 0.3494 Train_Acc: 83.274 Val_Loss: 0.1926  BEST VAL Loss: 0.1926  Val_Acc: 96.941

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.3492 Train_Acc: 83.328 Val_Loss: 0.1927  BEST VAL Loss: 0.1926  Val_Acc: 96.744

Epoch 44: Validation loss decreased (0.192608 --> 0.192478).  Saving model ...
	 Train_Loss: 0.3490 Train_Acc: 83.403 Val_Loss: 0.1925  BEST VAL Loss: 0.1925  Val_Acc: 96.971

Epoch 45: Validation loss decreased (0.192478 --> 0.192414).  Saving model ...
	 Train_Loss: 0.3488 Train_Acc: 83.416 Val_Loss: 0.1924  BEST VAL Loss: 0.1924  Val_Acc: 96.953

Epoch 46: Validation loss decreased (0.192414 --> 0.192249).  Saving model ...
	 Train_Loss: 0.3486 Train_Acc: 83.384 Val_Loss: 0.1922  BEST VAL Loss: 0.1922  Val_Acc: 96.891

Epoch 47: Validation loss decreased (0.192249 --> 0.192238).  Saving model ...
	 Train_Loss: 0.3484 Train_Acc: 83.377 Val_Loss: 0.1922  BEST VAL Loss: 0.1922  Val_Acc: 96.897

Epoch 48: Validation loss decreased (0.192238 --> 0.192177).  Saving model ...
	 Train_Loss: 0.3483 Train_Acc: 83.221 Val_Loss: 0.1922  BEST VAL Loss: 0.1922  Val_Acc: 96.782

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.3481 Train_Acc: 83.308 Val_Loss: 0.1922  BEST VAL Loss: 0.1922  Val_Acc: 96.888

Epoch 50: Validation loss decreased (0.192177 --> 0.192108).  Saving model ...
	 Train_Loss: 0.3479 Train_Acc: 83.519 Val_Loss: 0.1921  BEST VAL Loss: 0.1921  Val_Acc: 96.818

Epoch 51: Validation loss decreased (0.192108 --> 0.192033).  Saving model ...
	 Train_Loss: 0.3478 Train_Acc: 83.303 Val_Loss: 0.1920  BEST VAL Loss: 0.1920  Val_Acc: 96.959

Epoch 52: Validation loss decreased (0.192033 --> 0.191954).  Saving model ...
	 Train_Loss: 0.3476 Train_Acc: 83.380 Val_Loss: 0.1920  BEST VAL Loss: 0.1920  Val_Acc: 96.938

Epoch 53: Validation loss decreased (0.191954 --> 0.191801).  Saving model ...
	 Train_Loss: 0.3475 Train_Acc: 83.506 Val_Loss: 0.1918  BEST VAL Loss: 0.1918  Val_Acc: 96.806

Epoch 54: Validation loss decreased (0.191801 --> 0.191685).  Saving model ...
	 Train_Loss: 0.3473 Train_Acc: 83.401 Val_Loss: 0.1917  BEST VAL Loss: 0.1917  Val_Acc: 96.897

Epoch 55: Validation loss decreased (0.191685 --> 0.191674).  Saving model ...
	 Train_Loss: 0.3472 Train_Acc: 83.442 Val_Loss: 0.1917  BEST VAL Loss: 0.1917  Val_Acc: 96.991

Epoch 56: Validation loss decreased (0.191674 --> 0.191632).  Saving model ...
	 Train_Loss: 0.3470 Train_Acc: 83.396 Val_Loss: 0.1916  BEST VAL Loss: 0.1916  Val_Acc: 96.971

Epoch 57: Validation loss decreased (0.191632 --> 0.191519).  Saving model ...
	 Train_Loss: 0.3469 Train_Acc: 83.391 Val_Loss: 0.1915  BEST VAL Loss: 0.1915  Val_Acc: 96.900

Epoch 58: Validation loss decreased (0.191519 --> 0.191425).  Saving model ...
	 Train_Loss: 0.3467 Train_Acc: 83.501 Val_Loss: 0.1914  BEST VAL Loss: 0.1914  Val_Acc: 96.938

Epoch 59: Validation loss decreased (0.191425 --> 0.191338).  Saving model ...
	 Train_Loss: 0.3466 Train_Acc: 83.455 Val_Loss: 0.1913  BEST VAL Loss: 0.1913  Val_Acc: 96.850

Epoch 60: Validation loss decreased (0.191338 --> 0.191245).  Saving model ...
	 Train_Loss: 0.3465 Train_Acc: 83.341 Val_Loss: 0.1912  BEST VAL Loss: 0.1912  Val_Acc: 96.850

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.3464 Train_Acc: 83.456 Val_Loss: 0.1913  BEST VAL Loss: 0.1912  Val_Acc: 97.036

Epoch 62: Validation loss decreased (0.191245 --> 0.191100).  Saving model ...
	 Train_Loss: 0.3462 Train_Acc: 83.482 Val_Loss: 0.1911  BEST VAL Loss: 0.1911  Val_Acc: 96.882

Epoch 63: Validation loss decreased (0.191100 --> 0.191013).  Saving model ...
	 Train_Loss: 0.3461 Train_Acc: 83.454 Val_Loss: 0.1910  BEST VAL Loss: 0.1910  Val_Acc: 96.980

Epoch 64: Validation loss decreased (0.191013 --> 0.190890).  Saving model ...
	 Train_Loss: 0.3460 Train_Acc: 83.511 Val_Loss: 0.1909  BEST VAL Loss: 0.1909  Val_Acc: 96.938

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.3459 Train_Acc: 83.421 Val_Loss: 0.1910  BEST VAL Loss: 0.1909  Val_Acc: 96.876

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.3458 Train_Acc: 83.506 Val_Loss: 0.1909  BEST VAL Loss: 0.1909  Val_Acc: 96.835

Epoch 67: Validation loss decreased (0.190890 --> 0.190849).  Saving model ...
	 Train_Loss: 0.3457 Train_Acc: 83.502 Val_Loss: 0.1908  BEST VAL Loss: 0.1908  Val_Acc: 96.962

Epoch 68: Validation loss decreased (0.190849 --> 0.190734).  Saving model ...
	 Train_Loss: 0.3455 Train_Acc: 83.555 Val_Loss: 0.1907  BEST VAL Loss: 0.1907  Val_Acc: 97.021

Epoch 69: Validation loss decreased (0.190734 --> 0.190718).  Saving model ...
	 Train_Loss: 0.3454 Train_Acc: 83.464 Val_Loss: 0.1907  BEST VAL Loss: 0.1907  Val_Acc: 96.653

Epoch 70: Validation loss decreased (0.190718 --> 0.190686).  Saving model ...
	 Train_Loss: 0.3453 Train_Acc: 83.462 Val_Loss: 0.1907  BEST VAL Loss: 0.1907  Val_Acc: 96.888

Epoch 71: Validation loss decreased (0.190686 --> 0.190672).  Saving model ...
	 Train_Loss: 0.3452 Train_Acc: 83.463 Val_Loss: 0.1907  BEST VAL Loss: 0.1907  Val_Acc: 96.918

Epoch 72: Validation loss decreased (0.190672 --> 0.190633).  Saving model ...
	 Train_Loss: 0.3451 Train_Acc: 83.495 Val_Loss: 0.1906  BEST VAL Loss: 0.1906  Val_Acc: 96.753

Epoch 73: Validation loss decreased (0.190633 --> 0.190559).  Saving model ...
	 Train_Loss: 0.3450 Train_Acc: 83.547 Val_Loss: 0.1906  BEST VAL Loss: 0.1906  Val_Acc: 97.074

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.3449 Train_Acc: 83.502 Val_Loss: 0.1906  BEST VAL Loss: 0.1906  Val_Acc: 96.968

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.3448 Train_Acc: 83.490 Val_Loss: 0.1906  BEST VAL Loss: 0.1906  Val_Acc: 96.956

Epoch 76: Validation loss decreased (0.190559 --> 0.190545).  Saving model ...
	 Train_Loss: 0.3447 Train_Acc: 83.654 Val_Loss: 0.1905  BEST VAL Loss: 0.1905  Val_Acc: 96.735

Epoch 77: Validation loss decreased (0.190545 --> 0.190500).  Saving model ...
	 Train_Loss: 0.3446 Train_Acc: 83.487 Val_Loss: 0.1905  BEST VAL Loss: 0.1905  Val_Acc: 96.962

Epoch 78: Validation loss decreased (0.190500 --> 0.190474).  Saving model ...
	 Train_Loss: 0.3445 Train_Acc: 83.551 Val_Loss: 0.1905  BEST VAL Loss: 0.1905  Val_Acc: 97.021

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.3444 Train_Acc: 83.525 Val_Loss: 0.1906  BEST VAL Loss: 0.1905  Val_Acc: 96.953

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.3443 Train_Acc: 83.643 Val_Loss: 0.1905  BEST VAL Loss: 0.1905  Val_Acc: 96.853

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.3442 Train_Acc: 83.510 Val_Loss: 0.1905  BEST VAL Loss: 0.1905  Val_Acc: 96.891

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.3441 Train_Acc: 83.490 Val_Loss: 0.1905  BEST VAL Loss: 0.1905  Val_Acc: 96.924

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.3440 Train_Acc: 83.622 Val_Loss: 0.1905  BEST VAL Loss: 0.1905  Val_Acc: 96.959

Epoch 84: Validation loss decreased (0.190474 --> 0.190388).  Saving model ...
	 Train_Loss: 0.3439 Train_Acc: 83.590 Val_Loss: 0.1904  BEST VAL Loss: 0.1904  Val_Acc: 97.018

Epoch 85: Validation loss decreased (0.190388 --> 0.190326).  Saving model ...
	 Train_Loss: 0.3438 Train_Acc: 83.605 Val_Loss: 0.1903  BEST VAL Loss: 0.1903  Val_Acc: 96.980

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.3437 Train_Acc: 83.609 Val_Loss: 0.1903  BEST VAL Loss: 0.1903  Val_Acc: 96.726

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.3437 Train_Acc: 83.689 Val_Loss: 0.1904  BEST VAL Loss: 0.1903  Val_Acc: 96.927

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.3436 Train_Acc: 83.649 Val_Loss: 0.1904  BEST VAL Loss: 0.1903  Val_Acc: 96.900

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.3435 Train_Acc: 83.538 Val_Loss: 0.1903  BEST VAL Loss: 0.1903  Val_Acc: 96.991

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.3434 Train_Acc: 83.546 Val_Loss: 0.1904  BEST VAL Loss: 0.1903  Val_Acc: 96.844

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.3433 Train_Acc: 83.499 Val_Loss: 0.1903  BEST VAL Loss: 0.1903  Val_Acc: 96.927

Epoch 92: Validation loss decreased (0.190326 --> 0.190237).  Saving model ...
	 Train_Loss: 0.3433 Train_Acc: 83.604 Val_Loss: 0.1902  BEST VAL Loss: 0.1902  Val_Acc: 96.938

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.3432 Train_Acc: 83.634 Val_Loss: 0.1904  BEST VAL Loss: 0.1902  Val_Acc: 97.047

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.3431 Train_Acc: 83.482 Val_Loss: 0.1903  BEST VAL Loss: 0.1902  Val_Acc: 96.927

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.3430 Train_Acc: 83.498 Val_Loss: 0.1903  BEST VAL Loss: 0.1902  Val_Acc: 96.891

Epoch 96: Validation loss decreased (0.190237 --> 0.190189).  Saving model ...
	 Train_Loss: 0.3430 Train_Acc: 83.554 Val_Loss: 0.1902  BEST VAL Loss: 0.1902  Val_Acc: 96.918

Epoch 97: Validation loss did not decrease
	 Train_Loss: 0.3429 Train_Acc: 83.637 Val_Loss: 0.1902  BEST VAL Loss: 0.1902  Val_Acc: 96.921

Epoch 98: Validation loss did not decrease
	 Train_Loss: 0.3428 Train_Acc: 83.590 Val_Loss: 0.1903  BEST VAL Loss: 0.1902  Val_Acc: 96.874

Epoch 99: Validation loss did not decrease
	 Train_Loss: 0.3428 Train_Acc: 83.549 Val_Loss: 0.1902  BEST VAL Loss: 0.1902  Val_Acc: 96.956

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.62      0.61      0.62    169560
           1       0.37      0.39      0.38    101922

    accuracy                           0.53    271482
   macro avg       0.50      0.50      0.50    271482
weighted avg       0.53      0.53      0.53    271482

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.63      0.62      0.62     21196
           1       0.38      0.39      0.38     12740

    accuracy                           0.53     33936
   macro avg       0.50      0.50      0.50     33936
weighted avg       0.53      0.53      0.53     33936

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.62      0.61      0.62     21196
           1       0.37      0.38      0.38     12740

    accuracy                           0.53     33936
   macro avg       0.50      0.50      0.50     33936
weighted avg       0.53      0.53      0.53     33936

              precision    recall  f1-score   support

           0       0.62      0.61      0.62     21196
           1       0.37      0.38      0.38     12740

    accuracy                           0.53     33936
   macro avg       0.50      0.50      0.50     33936
weighted avg       0.53      0.53      0.53     33936

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.38      0.51      0.44     28584
           1       0.62      0.50      0.55     46859

    accuracy                           0.50     75443
   macro avg       0.50      0.50      0.49     75443
weighted avg       0.53      0.50      0.51     75443

              precision    recall  f1-score   support

           0       0.38      0.51      0.44     28584
           1       0.62      0.50      0.55     46859

    accuracy                           0.50     75443
   macro avg       0.50      0.50      0.49     75443
weighted avg       0.53      0.50      0.51     75443

completed
