[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'e882a276'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '56e616df'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '2a8364c1'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '1c2f1df8'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Flagellin_0.100_DMSO_0.025 treatment_name: LPS_10.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: LPS_10.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (252405, 1270)
Number of total missing values across all columns: 504810
Data Subset Is Off
Wells held out for testing: ['E09' 'L10']
Wells to use for training, validation, and testing ['E02' 'E03' 'E08' 'L05' 'L11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.504909).  Saving model ...
	 Train_Loss: 0.5647 Train_Acc: 69.636 Val_Loss: 0.5049  BEST VAL Loss: 0.5049  Val_Acc: 74.738

Epoch 1: Validation loss decreased (0.504909 --> 0.487432).  Saving model ...
	 Train_Loss: 0.5319 Train_Acc: 75.125 Val_Loss: 0.4874  BEST VAL Loss: 0.4874  Val_Acc: 77.268

Epoch 2: Validation loss decreased (0.487432 --> 0.472218).  Saving model ...
	 Train_Loss: 0.5094 Train_Acc: 77.621 Val_Loss: 0.4722  BEST VAL Loss: 0.4722  Val_Acc: 79.136

Epoch 3: Validation loss decreased (0.472218 --> 0.459976).  Saving model ...
	 Train_Loss: 0.4936 Train_Acc: 78.878 Val_Loss: 0.4600  BEST VAL Loss: 0.4600  Val_Acc: 80.281

Epoch 4: Validation loss decreased (0.459976 --> 0.450533).  Saving model ...
	 Train_Loss: 0.4812 Train_Acc: 79.696 Val_Loss: 0.4505  BEST VAL Loss: 0.4505  Val_Acc: 81.128

Epoch 5: Validation loss decreased (0.450533 --> 0.442903).  Saving model ...
	 Train_Loss: 0.4718 Train_Acc: 80.262 Val_Loss: 0.4429  BEST VAL Loss: 0.4429  Val_Acc: 80.886

Epoch 6: Validation loss decreased (0.442903 --> 0.436609).  Saving model ...
	 Train_Loss: 0.4640 Train_Acc: 80.523 Val_Loss: 0.4366  BEST VAL Loss: 0.4366  Val_Acc: 81.380

Epoch 7: Validation loss decreased (0.436609 --> 0.431425).  Saving model ...
	 Train_Loss: 0.4574 Train_Acc: 80.890 Val_Loss: 0.4314  BEST VAL Loss: 0.4314  Val_Acc: 81.907

Epoch 8: Validation loss decreased (0.431425 --> 0.427577).  Saving model ...
	 Train_Loss: 0.4519 Train_Acc: 80.999 Val_Loss: 0.4276  BEST VAL Loss: 0.4276  Val_Acc: 81.739

Epoch 9: Validation loss decreased (0.427577 --> 0.423144).  Saving model ...
	 Train_Loss: 0.4468 Train_Acc: 81.326 Val_Loss: 0.4231  BEST VAL Loss: 0.4231  Val_Acc: 82.233

Epoch 10: Validation loss decreased (0.423144 --> 0.420094).  Saving model ...
	 Train_Loss: 0.4422 Train_Acc: 81.641 Val_Loss: 0.4201  BEST VAL Loss: 0.4201  Val_Acc: 82.356

Epoch 11: Validation loss decreased (0.420094 --> 0.417021).  Saving model ...
	 Train_Loss: 0.4384 Train_Acc: 81.642 Val_Loss: 0.4170  BEST VAL Loss: 0.4170  Val_Acc: 82.334

Epoch 12: Validation loss decreased (0.417021 --> 0.414217).  Saving model ...
	 Train_Loss: 0.4347 Train_Acc: 82.107 Val_Loss: 0.4142  BEST VAL Loss: 0.4142  Val_Acc: 82.581

Epoch 13: Validation loss decreased (0.414217 --> 0.411544).  Saving model ...
	 Train_Loss: 0.4313 Train_Acc: 82.051 Val_Loss: 0.4115  BEST VAL Loss: 0.4115  Val_Acc: 82.844

Epoch 14: Validation loss decreased (0.411544 --> 0.409157).  Saving model ...
	 Train_Loss: 0.4284 Train_Acc: 82.013 Val_Loss: 0.4092  BEST VAL Loss: 0.4092  Val_Acc: 82.895

Epoch 15: Validation loss decreased (0.409157 --> 0.406994).  Saving model ...
	 Train_Loss: 0.4256 Train_Acc: 82.181 Val_Loss: 0.4070  BEST VAL Loss: 0.4070  Val_Acc: 82.867

Epoch 16: Validation loss decreased (0.406994 --> 0.404972).  Saving model ...
	 Train_Loss: 0.4228 Train_Acc: 82.544 Val_Loss: 0.4050  BEST VAL Loss: 0.4050  Val_Acc: 83.018

Epoch 17: Validation loss decreased (0.404972 --> 0.403160).  Saving model ...
	 Train_Loss: 0.4202 Train_Acc: 82.566 Val_Loss: 0.4032  BEST VAL Loss: 0.4032  Val_Acc: 82.923

Epoch 18: Validation loss decreased (0.403160 --> 0.401406).  Saving model ...
	 Train_Loss: 0.4179 Train_Acc: 82.530 Val_Loss: 0.4014  BEST VAL Loss: 0.4014  Val_Acc: 83.164

Epoch 19: Validation loss decreased (0.401406 --> 0.399770).  Saving model ...
	 Train_Loss: 0.4157 Train_Acc: 82.533 Val_Loss: 0.3998  BEST VAL Loss: 0.3998  Val_Acc: 83.203

Epoch 20: Validation loss decreased (0.399770 --> 0.397936).  Saving model ...
	 Train_Loss: 0.4137 Train_Acc: 82.691 Val_Loss: 0.3979  BEST VAL Loss: 0.3979  Val_Acc: 83.759

Epoch 21: Validation loss decreased (0.397936 --> 0.396439).  Saving model ...
	 Train_Loss: 0.4117 Train_Acc: 82.799 Val_Loss: 0.3964  BEST VAL Loss: 0.3964  Val_Acc: 83.282

Epoch 22: Validation loss decreased (0.396439 --> 0.394694).  Saving model ...
	 Train_Loss: 0.4098 Train_Acc: 82.811 Val_Loss: 0.3947  BEST VAL Loss: 0.3947  Val_Acc: 83.865

Epoch 23: Validation loss decreased (0.394694 --> 0.393317).  Saving model ...
	 Train_Loss: 0.4081 Train_Acc: 82.816 Val_Loss: 0.3933  BEST VAL Loss: 0.3933  Val_Acc: 83.467

Epoch 24: Validation loss decreased (0.393317 --> 0.392057).  Saving model ...
	 Train_Loss: 0.4064 Train_Acc: 83.030 Val_Loss: 0.3921  BEST VAL Loss: 0.3921  Val_Acc: 83.635

Epoch 25: Validation loss decreased (0.392057 --> 0.390869).  Saving model ...
	 Train_Loss: 0.4048 Train_Acc: 82.994 Val_Loss: 0.3909  BEST VAL Loss: 0.3909  Val_Acc: 83.489

Epoch 26: Validation loss decreased (0.390869 --> 0.389609).  Saving model ...
	 Train_Loss: 0.4032 Train_Acc: 83.101 Val_Loss: 0.3896  BEST VAL Loss: 0.3896  Val_Acc: 83.854

Epoch 27: Validation loss decreased (0.389609 --> 0.388470).  Saving model ...
	 Train_Loss: 0.4018 Train_Acc: 83.141 Val_Loss: 0.3885  BEST VAL Loss: 0.3885  Val_Acc: 83.888

Epoch 28: Validation loss decreased (0.388470 --> 0.387475).  Saving model ...
	 Train_Loss: 0.4004 Train_Acc: 83.255 Val_Loss: 0.3875  BEST VAL Loss: 0.3875  Val_Acc: 83.916

Epoch 29: Validation loss decreased (0.387475 --> 0.386685).  Saving model ...
	 Train_Loss: 0.3990 Train_Acc: 83.178 Val_Loss: 0.3867  BEST VAL Loss: 0.3867  Val_Acc: 83.624

Epoch 30: Validation loss decreased (0.386685 --> 0.385667).  Saving model ...
	 Train_Loss: 0.3978 Train_Acc: 83.384 Val_Loss: 0.3857  BEST VAL Loss: 0.3857  Val_Acc: 83.882

Epoch 31: Validation loss decreased (0.385667 --> 0.384602).  Saving model ...
	 Train_Loss: 0.3966 Train_Acc: 83.326 Val_Loss: 0.3846  BEST VAL Loss: 0.3846  Val_Acc: 83.927

Epoch 32: Validation loss decreased (0.384602 --> 0.383670).  Saving model ...
	 Train_Loss: 0.3954 Train_Acc: 83.318 Val_Loss: 0.3837  BEST VAL Loss: 0.3837  Val_Acc: 83.944

Epoch 33: Validation loss decreased (0.383670 --> 0.382971).  Saving model ...
	 Train_Loss: 0.3942 Train_Acc: 83.377 Val_Loss: 0.3830  BEST VAL Loss: 0.3830  Val_Acc: 83.669

Epoch 34: Validation loss decreased (0.382971 --> 0.382058).  Saving model ...
	 Train_Loss: 0.3931 Train_Acc: 83.565 Val_Loss: 0.3821  BEST VAL Loss: 0.3821  Val_Acc: 84.213

Epoch 35: Validation loss decreased (0.382058 --> 0.381159).  Saving model ...
	 Train_Loss: 0.3921 Train_Acc: 83.467 Val_Loss: 0.3812  BEST VAL Loss: 0.3812  Val_Acc: 84.157

Epoch 36: Validation loss decreased (0.381159 --> 0.380388).  Saving model ...
	 Train_Loss: 0.3910 Train_Acc: 83.421 Val_Loss: 0.3804  BEST VAL Loss: 0.3804  Val_Acc: 84.241

Epoch 37: Validation loss decreased (0.380388 --> 0.379702).  Saving model ...
	 Train_Loss: 0.3901 Train_Acc: 83.488 Val_Loss: 0.3797  BEST VAL Loss: 0.3797  Val_Acc: 84.090

Epoch 38: Validation loss decreased (0.379702 --> 0.378978).  Saving model ...
	 Train_Loss: 0.3891 Train_Acc: 83.603 Val_Loss: 0.3790  BEST VAL Loss: 0.3790  Val_Acc: 83.989

Epoch 39: Validation loss decreased (0.378978 --> 0.378479).  Saving model ...
	 Train_Loss: 0.3882 Train_Acc: 83.567 Val_Loss: 0.3785  BEST VAL Loss: 0.3785  Val_Acc: 83.882

Epoch 40: Validation loss decreased (0.378479 --> 0.377676).  Saving model ...
	 Train_Loss: 0.3873 Train_Acc: 83.586 Val_Loss: 0.3777  BEST VAL Loss: 0.3777  Val_Acc: 84.370

Epoch 41: Validation loss decreased (0.377676 --> 0.376941).  Saving model ...
	 Train_Loss: 0.3864 Train_Acc: 83.730 Val_Loss: 0.3769  BEST VAL Loss: 0.3769  Val_Acc: 84.252

Epoch 42: Validation loss decreased (0.376941 --> 0.376333).  Saving model ...
	 Train_Loss: 0.3856 Train_Acc: 83.757 Val_Loss: 0.3763  BEST VAL Loss: 0.3763  Val_Acc: 84.034

Epoch 43: Validation loss decreased (0.376333 --> 0.375741).  Saving model ...
	 Train_Loss: 0.3847 Train_Acc: 83.831 Val_Loss: 0.3757  BEST VAL Loss: 0.3757  Val_Acc: 84.140

Epoch 44: Validation loss decreased (0.375741 --> 0.375167).  Saving model ...
	 Train_Loss: 0.3839 Train_Acc: 83.682 Val_Loss: 0.3752  BEST VAL Loss: 0.3752  Val_Acc: 84.034

Epoch 45: Validation loss decreased (0.375167 --> 0.374630).  Saving model ...
	 Train_Loss: 0.3831 Train_Acc: 83.801 Val_Loss: 0.3746  BEST VAL Loss: 0.3746  Val_Acc: 84.028

Epoch 46: Validation loss decreased (0.374630 --> 0.374036).  Saving model ...
	 Train_Loss: 0.3823 Train_Acc: 83.814 Val_Loss: 0.3740  BEST VAL Loss: 0.3740  Val_Acc: 84.527

Epoch 47: Validation loss decreased (0.374036 --> 0.373380).  Saving model ...
	 Train_Loss: 0.3816 Train_Acc: 83.816 Val_Loss: 0.3734  BEST VAL Loss: 0.3734  Val_Acc: 84.449

Epoch 48: Validation loss decreased (0.373380 --> 0.372891).  Saving model ...
	 Train_Loss: 0.3809 Train_Acc: 83.850 Val_Loss: 0.3729  BEST VAL Loss: 0.3729  Val_Acc: 84.135

Epoch 49: Validation loss decreased (0.372891 --> 0.372410).  Saving model ...
	 Train_Loss: 0.3802 Train_Acc: 83.921 Val_Loss: 0.3724  BEST VAL Loss: 0.3724  Val_Acc: 84.325

Epoch 50: Validation loss decreased (0.372410 --> 0.371909).  Saving model ...
	 Train_Loss: 0.3795 Train_Acc: 83.854 Val_Loss: 0.3719  BEST VAL Loss: 0.3719  Val_Acc: 84.471

Epoch 51: Validation loss decreased (0.371909 --> 0.371346).  Saving model ...
	 Train_Loss: 0.3788 Train_Acc: 83.990 Val_Loss: 0.3713  BEST VAL Loss: 0.3713  Val_Acc: 84.662

Epoch 52: Validation loss decreased (0.371346 --> 0.370888).  Saving model ...
	 Train_Loss: 0.3782 Train_Acc: 84.002 Val_Loss: 0.3709  BEST VAL Loss: 0.3709  Val_Acc: 84.297

Epoch 53: Validation loss decreased (0.370888 --> 0.370498).  Saving model ...
	 Train_Loss: 0.3775 Train_Acc: 84.028 Val_Loss: 0.3705  BEST VAL Loss: 0.3705  Val_Acc: 84.387

Epoch 54: Validation loss decreased (0.370498 --> 0.370000).  Saving model ...
	 Train_Loss: 0.3769 Train_Acc: 83.929 Val_Loss: 0.3700  BEST VAL Loss: 0.3700  Val_Acc: 84.325

Epoch 55: Validation loss decreased (0.370000 --> 0.369609).  Saving model ...
	 Train_Loss: 0.3763 Train_Acc: 83.921 Val_Loss: 0.3696  BEST VAL Loss: 0.3696  Val_Acc: 84.410

Epoch 56: Validation loss decreased (0.369609 --> 0.369158).  Saving model ...
	 Train_Loss: 0.3757 Train_Acc: 83.944 Val_Loss: 0.3692  BEST VAL Loss: 0.3692  Val_Acc: 84.567

Epoch 57: Validation loss decreased (0.369158 --> 0.368702).  Saving model ...
	 Train_Loss: 0.3751 Train_Acc: 84.056 Val_Loss: 0.3687  BEST VAL Loss: 0.3687  Val_Acc: 84.679

Epoch 58: Validation loss decreased (0.368702 --> 0.368265).  Saving model ...
	 Train_Loss: 0.3745 Train_Acc: 84.085 Val_Loss: 0.3683  BEST VAL Loss: 0.3683  Val_Acc: 84.567

Epoch 59: Validation loss decreased (0.368265 --> 0.367915).  Saving model ...
	 Train_Loss: 0.3740 Train_Acc: 84.143 Val_Loss: 0.3679  BEST VAL Loss: 0.3679  Val_Acc: 84.449

Epoch 60: Validation loss decreased (0.367915 --> 0.367539).  Saving model ...
	 Train_Loss: 0.3735 Train_Acc: 83.910 Val_Loss: 0.3675  BEST VAL Loss: 0.3675  Val_Acc: 84.454

Epoch 61: Validation loss decreased (0.367539 --> 0.367147).  Saving model ...
	 Train_Loss: 0.3730 Train_Acc: 83.999 Val_Loss: 0.3671  BEST VAL Loss: 0.3671  Val_Acc: 84.606

Epoch 62: Validation loss decreased (0.367147 --> 0.366802).  Saving model ...
	 Train_Loss: 0.3724 Train_Acc: 84.083 Val_Loss: 0.3668  BEST VAL Loss: 0.3668  Val_Acc: 84.656

Epoch 63: Validation loss decreased (0.366802 --> 0.366454).  Saving model ...
	 Train_Loss: 0.3720 Train_Acc: 84.057 Val_Loss: 0.3665  BEST VAL Loss: 0.3665  Val_Acc: 84.583

Epoch 64: Validation loss decreased (0.366454 --> 0.366121).  Saving model ...
	 Train_Loss: 0.3715 Train_Acc: 84.046 Val_Loss: 0.3661  BEST VAL Loss: 0.3661  Val_Acc: 84.415

Epoch 65: Validation loss decreased (0.366121 --> 0.365813).  Saving model ...
	 Train_Loss: 0.3710 Train_Acc: 84.152 Val_Loss: 0.3658  BEST VAL Loss: 0.3658  Val_Acc: 84.460

Epoch 66: Validation loss decreased (0.365813 --> 0.365442).  Saving model ...
	 Train_Loss: 0.3705 Train_Acc: 84.087 Val_Loss: 0.3654  BEST VAL Loss: 0.3654  Val_Acc: 84.757

Epoch 67: Validation loss decreased (0.365442 --> 0.365126).  Saving model ...
	 Train_Loss: 0.3700 Train_Acc: 84.128 Val_Loss: 0.3651  BEST VAL Loss: 0.3651  Val_Acc: 84.516

Epoch 68: Validation loss decreased (0.365126 --> 0.364854).  Saving model ...
	 Train_Loss: 0.3696 Train_Acc: 84.275 Val_Loss: 0.3649  BEST VAL Loss: 0.3649  Val_Acc: 84.135

Epoch 69: Validation loss decreased (0.364854 --> 0.364567).  Saving model ...
	 Train_Loss: 0.3691 Train_Acc: 84.258 Val_Loss: 0.3646  BEST VAL Loss: 0.3646  Val_Acc: 84.499

Epoch 70: Validation loss decreased (0.364567 --> 0.364274).  Saving model ...
	 Train_Loss: 0.3687 Train_Acc: 84.249 Val_Loss: 0.3643  BEST VAL Loss: 0.3643  Val_Acc: 84.741

Epoch 71: Validation loss decreased (0.364274 --> 0.363915).  Saving model ...
	 Train_Loss: 0.3682 Train_Acc: 84.229 Val_Loss: 0.3639  BEST VAL Loss: 0.3639  Val_Acc: 84.836

Epoch 72: Validation loss decreased (0.363915 --> 0.363605).  Saving model ...
	 Train_Loss: 0.3678 Train_Acc: 84.175 Val_Loss: 0.3636  BEST VAL Loss: 0.3636  Val_Acc: 84.499

Epoch 73: Validation loss decreased (0.363605 --> 0.363379).  Saving model ...
	 Train_Loss: 0.3674 Train_Acc: 84.265 Val_Loss: 0.3634  BEST VAL Loss: 0.3634  Val_Acc: 84.208

Epoch 74: Validation loss decreased (0.363379 --> 0.363071).  Saving model ...
	 Train_Loss: 0.3669 Train_Acc: 84.392 Val_Loss: 0.3631  BEST VAL Loss: 0.3631  Val_Acc: 84.499

Epoch 75: Validation loss decreased (0.363071 --> 0.362786).  Saving model ...
	 Train_Loss: 0.3665 Train_Acc: 84.288 Val_Loss: 0.3628  BEST VAL Loss: 0.3628  Val_Acc: 84.645

Epoch 76: Validation loss decreased (0.362786 --> 0.362559).  Saving model ...
	 Train_Loss: 0.3661 Train_Acc: 84.234 Val_Loss: 0.3626  BEST VAL Loss: 0.3626  Val_Acc: 84.539

Epoch 77: Validation loss decreased (0.362559 --> 0.362345).  Saving model ...
	 Train_Loss: 0.3658 Train_Acc: 84.282 Val_Loss: 0.3623  BEST VAL Loss: 0.3623  Val_Acc: 84.651

Epoch 78: Validation loss decreased (0.362345 --> 0.362120).  Saving model ...
	 Train_Loss: 0.3654 Train_Acc: 84.265 Val_Loss: 0.3621  BEST VAL Loss: 0.3621  Val_Acc: 84.836

Epoch 79: Validation loss decreased (0.362120 --> 0.361870).  Saving model ...
	 Train_Loss: 0.3650 Train_Acc: 84.199 Val_Loss: 0.3619  BEST VAL Loss: 0.3619  Val_Acc: 84.785

Epoch 80: Validation loss decreased (0.361870 --> 0.361628).  Saving model ...
	 Train_Loss: 0.3646 Train_Acc: 84.361 Val_Loss: 0.3616  BEST VAL Loss: 0.3616  Val_Acc: 84.735

Epoch 81: Validation loss decreased (0.361628 --> 0.361417).  Saving model ...
	 Train_Loss: 0.3642 Train_Acc: 84.422 Val_Loss: 0.3614  BEST VAL Loss: 0.3614  Val_Acc: 84.791

Epoch 82: Validation loss decreased (0.361417 --> 0.361229).  Saving model ...
	 Train_Loss: 0.3639 Train_Acc: 84.292 Val_Loss: 0.3612  BEST VAL Loss: 0.3612  Val_Acc: 84.533

Epoch 83: Validation loss decreased (0.361229 --> 0.361000).  Saving model ...
	 Train_Loss: 0.3635 Train_Acc: 84.396 Val_Loss: 0.3610  BEST VAL Loss: 0.3610  Val_Acc: 84.550

Epoch 84: Validation loss decreased (0.361000 --> 0.360796).  Saving model ...
	 Train_Loss: 0.3632 Train_Acc: 84.280 Val_Loss: 0.3608  BEST VAL Loss: 0.3608  Val_Acc: 84.684

Epoch 85: Validation loss decreased (0.360796 --> 0.360600).  Saving model ...
	 Train_Loss: 0.3628 Train_Acc: 84.401 Val_Loss: 0.3606  BEST VAL Loss: 0.3606  Val_Acc: 84.668

Epoch 86: Validation loss decreased (0.360600 --> 0.360398).  Saving model ...
	 Train_Loss: 0.3625 Train_Acc: 84.301 Val_Loss: 0.3604  BEST VAL Loss: 0.3604  Val_Acc: 84.662

Epoch 87: Validation loss decreased (0.360398 --> 0.360255).  Saving model ...
	 Train_Loss: 0.3622 Train_Acc: 84.366 Val_Loss: 0.3603  BEST VAL Loss: 0.3603  Val_Acc: 84.550

Epoch 88: Validation loss decreased (0.360255 --> 0.360046).  Saving model ...
	 Train_Loss: 0.3619 Train_Acc: 84.354 Val_Loss: 0.3600  BEST VAL Loss: 0.3600  Val_Acc: 84.864

Epoch 89: Validation loss decreased (0.360046 --> 0.359832).  Saving model ...
	 Train_Loss: 0.3616 Train_Acc: 84.429 Val_Loss: 0.3598  BEST VAL Loss: 0.3598  Val_Acc: 84.712

Epoch 90: Validation loss decreased (0.359832 --> 0.359711).  Saving model ...
	 Train_Loss: 0.3613 Train_Acc: 84.293 Val_Loss: 0.3597  BEST VAL Loss: 0.3597  Val_Acc: 84.421

Epoch 91: Validation loss decreased (0.359711 --> 0.359491).  Saving model ...
	 Train_Loss: 0.3610 Train_Acc: 84.488 Val_Loss: 0.3595  BEST VAL Loss: 0.3595  Val_Acc: 84.858

Epoch 92: Validation loss decreased (0.359491 --> 0.359361).  Saving model ...
	 Train_Loss: 0.3606 Train_Acc: 84.433 Val_Loss: 0.3594  BEST VAL Loss: 0.3594  Val_Acc: 84.628

Epoch 93: Validation loss decreased (0.359361 --> 0.359288).  Saving model ...
	 Train_Loss: 0.3603 Train_Acc: 84.389 Val_Loss: 0.3593  BEST VAL Loss: 0.3593  Val_Acc: 84.365

Epoch 94: Validation loss decreased (0.359288 --> 0.359149).  Saving model ...
	 Train_Loss: 0.3600 Train_Acc: 84.343 Val_Loss: 0.3591  BEST VAL Loss: 0.3591  Val_Acc: 84.746

Epoch 95: Validation loss decreased (0.359149 --> 0.358967).  Saving model ...
	 Train_Loss: 0.3598 Train_Acc: 84.334 Val_Loss: 0.3590  BEST VAL Loss: 0.3590  Val_Acc: 84.712

Epoch 96: Validation loss decreased (0.358967 --> 0.358809).  Saving model ...
	 Train_Loss: 0.3595 Train_Acc: 84.534 Val_Loss: 0.3588  BEST VAL Loss: 0.3588  Val_Acc: 84.628

Epoch 97: Validation loss decreased (0.358809 --> 0.358662).  Saving model ...
	 Train_Loss: 0.3592 Train_Acc: 84.484 Val_Loss: 0.3587  BEST VAL Loss: 0.3587  Val_Acc: 84.628

Epoch 98: Validation loss decreased (0.358662 --> 0.358464).  Saving model ...
	 Train_Loss: 0.3589 Train_Acc: 84.550 Val_Loss: 0.3585  BEST VAL Loss: 0.3585  Val_Acc: 84.763

Epoch 99: Validation loss decreased (0.358464 --> 0.358319).  Saving model ...
	 Train_Loss: 0.3586 Train_Acc: 84.377 Val_Loss: 0.3583  BEST VAL Loss: 0.3583  Val_Acc: 84.645

Flagellin_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.36      0.28      0.31     50422
           1       0.65      0.72      0.68     92173

    accuracy                           0.57    142595
   macro avg       0.50      0.50      0.50    142595
weighted avg       0.54      0.57      0.55    142595

Flagellin_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.35      0.28      0.31      6303
           1       0.65      0.72      0.68     11522

    accuracy                           0.56     17825
   macro avg       0.50      0.50      0.50     17825
weighted avg       0.54      0.56      0.55     17825

Flagellin_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.36      0.28      0.32      6303
           1       0.65      0.72      0.68     11522

    accuracy                           0.57     17825
   macro avg       0.50      0.50      0.50     17825
weighted avg       0.55      0.57      0.55     17825

              precision    recall  f1-score   support

           0       0.36      0.28      0.32      6303
           1       0.65      0.72      0.68     11522

    accuracy                           0.57     17825
   macro avg       0.50      0.50      0.50     17825
weighted avg       0.55      0.57      0.55     17825

Flagellin_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.44      0.43      0.44     32887
           1       0.56      0.57      0.56     41273

    accuracy                           0.51     74160
   macro avg       0.50      0.50      0.50     74160
weighted avg       0.51      0.51      0.51     74160

              precision    recall  f1-score   support

           0       0.44      0.43      0.44     32887
           1       0.56      0.57      0.56     41273

    accuracy                           0.51     74160
   macro avg       0.50      0.50      0.50     74160
weighted avg       0.51      0.51      0.51     74160

completed
