[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '11c4b63e'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '06abcf05'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '107dcbe7'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '99677673'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 treatment_name: LPS_10.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
TREATMENT_NAME: LPS_10.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (337656, 1270)
Number of total missing values across all columns: 312980
Data Subset Is Off
Wells held out for testing: ['E09' 'M09']
Wells to use for training, validation, and testing ['E02' 'E03' 'E08' 'M02' 'M03' 'M08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.173179).  Saving model ...
	 Train_Loss: 0.3086 Train_Acc: 87.013 Val_Loss: 0.1732  BEST VAL Loss: 0.1732  Val_Acc: 93.233

Epoch 1: Validation loss decreased (0.173179 --> 0.159735).  Saving model ...
	 Train_Loss: 0.2718 Train_Acc: 91.618 Val_Loss: 0.1597  BEST VAL Loss: 0.1597  Val_Acc: 94.712

Epoch 2: Validation loss decreased (0.159735 --> 0.154627).  Saving model ...
	 Train_Loss: 0.2544 Train_Acc: 92.345 Val_Loss: 0.1546  BEST VAL Loss: 0.1546  Val_Acc: 94.959

Epoch 3: Validation loss decreased (0.154627 --> 0.149961).  Saving model ...
	 Train_Loss: 0.2441 Train_Acc: 92.671 Val_Loss: 0.1500  BEST VAL Loss: 0.1500  Val_Acc: 95.275

Epoch 4: Validation loss decreased (0.149961 --> 0.146315).  Saving model ...
	 Train_Loss: 0.2367 Train_Acc: 92.864 Val_Loss: 0.1463  BEST VAL Loss: 0.1463  Val_Acc: 95.291

Epoch 5: Validation loss decreased (0.146315 --> 0.143769).  Saving model ...
	 Train_Loss: 0.2314 Train_Acc: 92.971 Val_Loss: 0.1438  BEST VAL Loss: 0.1438  Val_Acc: 95.376

Epoch 6: Validation loss decreased (0.143769 --> 0.141934).  Saving model ...
	 Train_Loss: 0.2276 Train_Acc: 92.940 Val_Loss: 0.1419  BEST VAL Loss: 0.1419  Val_Acc: 95.417

Epoch 7: Validation loss decreased (0.141934 --> 0.140642).  Saving model ...
	 Train_Loss: 0.2241 Train_Acc: 93.220 Val_Loss: 0.1406  BEST VAL Loss: 0.1406  Val_Acc: 95.275

Epoch 8: Validation loss decreased (0.140642 --> 0.140004).  Saving model ...
	 Train_Loss: 0.2214 Train_Acc: 93.197 Val_Loss: 0.1400  BEST VAL Loss: 0.1400  Val_Acc: 95.178

Epoch 9: Validation loss decreased (0.140004 --> 0.138636).  Saving model ...
	 Train_Loss: 0.2188 Train_Acc: 93.385 Val_Loss: 0.1386  BEST VAL Loss: 0.1386  Val_Acc: 95.555

Epoch 10: Validation loss decreased (0.138636 --> 0.137291).  Saving model ...
	 Train_Loss: 0.2168 Train_Acc: 93.347 Val_Loss: 0.1373  BEST VAL Loss: 0.1373  Val_Acc: 95.619

Epoch 11: Validation loss decreased (0.137291 --> 0.135926).  Saving model ...
	 Train_Loss: 0.2147 Train_Acc: 93.523 Val_Loss: 0.1359  BEST VAL Loss: 0.1359  Val_Acc: 95.737

Epoch 12: Validation loss decreased (0.135926 --> 0.135541).  Saving model ...
	 Train_Loss: 0.2130 Train_Acc: 93.465 Val_Loss: 0.1355  BEST VAL Loss: 0.1355  Val_Acc: 95.089

Epoch 13: Validation loss decreased (0.135541 --> 0.134547).  Saving model ...
	 Train_Loss: 0.2113 Train_Acc: 93.682 Val_Loss: 0.1345  BEST VAL Loss: 0.1345  Val_Acc: 95.915

Epoch 14: Validation loss decreased (0.134547 --> 0.134267).  Saving model ...
	 Train_Loss: 0.2097 Train_Acc: 93.645 Val_Loss: 0.1343  BEST VAL Loss: 0.1343  Val_Acc: 95.336

Epoch 15: Validation loss decreased (0.134267 --> 0.134119).  Saving model ...
	 Train_Loss: 0.2086 Train_Acc: 93.546 Val_Loss: 0.1341  BEST VAL Loss: 0.1341  Val_Acc: 95.214

Epoch 16: Validation loss decreased (0.134119 --> 0.133973).  Saving model ...
	 Train_Loss: 0.2076 Train_Acc: 93.573 Val_Loss: 0.1340  BEST VAL Loss: 0.1340  Val_Acc: 95.498

Epoch 17: Validation loss decreased (0.133973 --> 0.133443).  Saving model ...
	 Train_Loss: 0.2068 Train_Acc: 93.422 Val_Loss: 0.1334  BEST VAL Loss: 0.1334  Val_Acc: 95.530

Epoch 18: Validation loss decreased (0.133443 --> 0.133163).  Saving model ...
	 Train_Loss: 0.2060 Train_Acc: 93.532 Val_Loss: 0.1332  BEST VAL Loss: 0.1332  Val_Acc: 95.538

Epoch 19: Validation loss decreased (0.133163 --> 0.132533).  Saving model ...
	 Train_Loss: 0.2052 Train_Acc: 93.655 Val_Loss: 0.1325  BEST VAL Loss: 0.1325  Val_Acc: 96.057

Epoch 20: Validation loss decreased (0.132533 --> 0.132077).  Saving model ...
	 Train_Loss: 0.2044 Train_Acc: 93.728 Val_Loss: 0.1321  BEST VAL Loss: 0.1321  Val_Acc: 95.486

Epoch 21: Validation loss decreased (0.132077 --> 0.131483).  Saving model ...
	 Train_Loss: 0.2036 Train_Acc: 93.750 Val_Loss: 0.1315  BEST VAL Loss: 0.1315  Val_Acc: 95.838

Epoch 22: Validation loss decreased (0.131483 --> 0.131226).  Saving model ...
	 Train_Loss: 0.2029 Train_Acc: 93.654 Val_Loss: 0.1312  BEST VAL Loss: 0.1312  Val_Acc: 95.603

Epoch 23: Validation loss decreased (0.131226 --> 0.130646).  Saving model ...
	 Train_Loss: 0.2023 Train_Acc: 93.741 Val_Loss: 0.1306  BEST VAL Loss: 0.1306  Val_Acc: 95.911

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.2019 Train_Acc: 93.493 Val_Loss: 0.1308  BEST VAL Loss: 0.1306  Val_Acc: 95.040

Epoch 25: Validation loss decreased (0.130646 --> 0.130449).  Saving model ...
	 Train_Loss: 0.2016 Train_Acc: 93.464 Val_Loss: 0.1304  BEST VAL Loss: 0.1304  Val_Acc: 95.826

Epoch 26: Validation loss decreased (0.130449 --> 0.130129).  Saving model ...
	 Train_Loss: 0.2011 Train_Acc: 93.700 Val_Loss: 0.1301  BEST VAL Loss: 0.1301  Val_Acc: 95.806

Epoch 27: Validation loss decreased (0.130129 --> 0.129777).  Saving model ...
	 Train_Loss: 0.2006 Train_Acc: 93.697 Val_Loss: 0.1298  BEST VAL Loss: 0.1298  Val_Acc: 95.931

Epoch 28: Validation loss decreased (0.129777 --> 0.129420).  Saving model ...
	 Train_Loss: 0.2001 Train_Acc: 93.878 Val_Loss: 0.1294  BEST VAL Loss: 0.1294  Val_Acc: 95.903

Epoch 29: Validation loss decreased (0.129420 --> 0.129132).  Saving model ...
	 Train_Loss: 0.1998 Train_Acc: 93.529 Val_Loss: 0.1291  BEST VAL Loss: 0.1291  Val_Acc: 95.611

Epoch 30: Validation loss decreased (0.129132 --> 0.128824).  Saving model ...
	 Train_Loss: 0.1994 Train_Acc: 93.760 Val_Loss: 0.1288  BEST VAL Loss: 0.1288  Val_Acc: 95.863

Epoch 31: Validation loss decreased (0.128824 --> 0.128591).  Saving model ...
	 Train_Loss: 0.1990 Train_Acc: 93.776 Val_Loss: 0.1286  BEST VAL Loss: 0.1286  Val_Acc: 95.688

Epoch 32: Validation loss decreased (0.128591 --> 0.128303).  Saving model ...
	 Train_Loss: 0.1986 Train_Acc: 93.889 Val_Loss: 0.1283  BEST VAL Loss: 0.1283  Val_Acc: 95.931

Epoch 33: Validation loss decreased (0.128303 --> 0.128024).  Saving model ...
	 Train_Loss: 0.1982 Train_Acc: 93.845 Val_Loss: 0.1280  BEST VAL Loss: 0.1280  Val_Acc: 95.980

Epoch 34: Validation loss decreased (0.128024 --> 0.127846).  Saving model ...
	 Train_Loss: 0.1982 Train_Acc: 93.190 Val_Loss: 0.1278  BEST VAL Loss: 0.1278  Val_Acc: 95.563

Epoch 35: Validation loss decreased (0.127846 --> 0.127580).  Saving model ...
	 Train_Loss: 0.1979 Train_Acc: 93.757 Val_Loss: 0.1276  BEST VAL Loss: 0.1276  Val_Acc: 95.749

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.1976 Train_Acc: 93.721 Val_Loss: 0.1277  BEST VAL Loss: 0.1276  Val_Acc: 95.247

Epoch 37: Validation loss decreased (0.127580 --> 0.127532).  Saving model ...
	 Train_Loss: 0.1974 Train_Acc: 93.539 Val_Loss: 0.1275  BEST VAL Loss: 0.1275  Val_Acc: 95.664

Epoch 38: Validation loss decreased (0.127532 --> 0.127285).  Saving model ...
	 Train_Loss: 0.1972 Train_Acc: 93.641 Val_Loss: 0.1273  BEST VAL Loss: 0.1273  Val_Acc: 95.850

Epoch 39: Validation loss decreased (0.127285 --> 0.127090).  Saving model ...
	 Train_Loss: 0.1971 Train_Acc: 93.517 Val_Loss: 0.1271  BEST VAL Loss: 0.1271  Val_Acc: 95.879

Epoch 40: Validation loss decreased (0.127090 --> 0.126980).  Saving model ...
	 Train_Loss: 0.1969 Train_Acc: 93.491 Val_Loss: 0.1270  BEST VAL Loss: 0.1270  Val_Acc: 95.818

Epoch 41: Validation loss decreased (0.126980 --> 0.126867).  Saving model ...
	 Train_Loss: 0.1968 Train_Acc: 93.660 Val_Loss: 0.1269  BEST VAL Loss: 0.1269  Val_Acc: 95.850

Epoch 42: Validation loss decreased (0.126867 --> 0.126713).  Saving model ...
	 Train_Loss: 0.1967 Train_Acc: 93.522 Val_Loss: 0.1267  BEST VAL Loss: 0.1267  Val_Acc: 95.846

Epoch 43: Validation loss decreased (0.126713 --> 0.126601).  Saving model ...
	 Train_Loss: 0.1965 Train_Acc: 93.682 Val_Loss: 0.1266  BEST VAL Loss: 0.1266  Val_Acc: 95.891

Epoch 44: Validation loss decreased (0.126601 --> 0.126452).  Saving model ...
	 Train_Loss: 0.1963 Train_Acc: 93.756 Val_Loss: 0.1265  BEST VAL Loss: 0.1265  Val_Acc: 96.146

Epoch 45: Validation loss decreased (0.126452 --> 0.126272).  Saving model ...
	 Train_Loss: 0.1961 Train_Acc: 93.677 Val_Loss: 0.1263  BEST VAL Loss: 0.1263  Val_Acc: 95.944

Epoch 46: Validation loss decreased (0.126272 --> 0.126137).  Saving model ...
	 Train_Loss: 0.1958 Train_Acc: 93.794 Val_Loss: 0.1261  BEST VAL Loss: 0.1261  Val_Acc: 95.786

Epoch 47: Validation loss decreased (0.126137 --> 0.126097).  Saving model ...
	 Train_Loss: 0.1956 Train_Acc: 93.806 Val_Loss: 0.1261  BEST VAL Loss: 0.1261  Val_Acc: 95.660

Epoch 48: Validation loss decreased (0.126097 --> 0.125861).  Saving model ...
	 Train_Loss: 0.1954 Train_Acc: 93.760 Val_Loss: 0.1259  BEST VAL Loss: 0.1259  Val_Acc: 96.110

Epoch 49: Validation loss decreased (0.125861 --> 0.125649).  Saving model ...
	 Train_Loss: 0.1952 Train_Acc: 94.018 Val_Loss: 0.1256  BEST VAL Loss: 0.1256  Val_Acc: 96.069

Epoch 50: Validation loss decreased (0.125649 --> 0.125503).  Saving model ...
	 Train_Loss: 0.1950 Train_Acc: 93.806 Val_Loss: 0.1255  BEST VAL Loss: 0.1255  Val_Acc: 95.923

Epoch 51: Validation loss decreased (0.125503 --> 0.125239).  Saving model ...
	 Train_Loss: 0.1947 Train_Acc: 94.061 Val_Loss: 0.1252  BEST VAL Loss: 0.1252  Val_Acc: 96.142

Epoch 52: Validation loss decreased (0.125239 --> 0.125137).  Saving model ...
	 Train_Loss: 0.1944 Train_Acc: 94.012 Val_Loss: 0.1251  BEST VAL Loss: 0.1251  Val_Acc: 95.887

Epoch 53: Validation loss decreased (0.125137 --> 0.124960).  Saving model ...
	 Train_Loss: 0.1942 Train_Acc: 93.987 Val_Loss: 0.1250  BEST VAL Loss: 0.1250  Val_Acc: 96.162

Epoch 54: Validation loss decreased (0.124960 --> 0.124813).  Saving model ...
	 Train_Loss: 0.1939 Train_Acc: 94.136 Val_Loss: 0.1248  BEST VAL Loss: 0.1248  Val_Acc: 95.822

Epoch 55: Validation loss decreased (0.124813 --> 0.124695).  Saving model ...
	 Train_Loss: 0.1936 Train_Acc: 94.049 Val_Loss: 0.1247  BEST VAL Loss: 0.1247  Val_Acc: 95.907

Epoch 56: Validation loss decreased (0.124695 --> 0.124548).  Saving model ...
	 Train_Loss: 0.1934 Train_Acc: 94.086 Val_Loss: 0.1245  BEST VAL Loss: 0.1245  Val_Acc: 96.021

Epoch 57: Validation loss decreased (0.124548 --> 0.124387).  Saving model ...
	 Train_Loss: 0.1932 Train_Acc: 94.067 Val_Loss: 0.1244  BEST VAL Loss: 0.1244  Val_Acc: 96.033

Epoch 58: Validation loss decreased (0.124387 --> 0.124289).  Saving model ...
	 Train_Loss: 0.1930 Train_Acc: 93.889 Val_Loss: 0.1243  BEST VAL Loss: 0.1243  Val_Acc: 95.887

Epoch 59: Validation loss decreased (0.124289 --> 0.124211).  Saving model ...
	 Train_Loss: 0.1930 Train_Acc: 93.338 Val_Loss: 0.1242  BEST VAL Loss: 0.1242  Val_Acc: 95.984

Epoch 60: Validation loss decreased (0.124211 --> 0.124180).  Saving model ...
	 Train_Loss: 0.1929 Train_Acc: 93.838 Val_Loss: 0.1242  BEST VAL Loss: 0.1242  Val_Acc: 95.729

Epoch 61: Validation loss decreased (0.124180 --> 0.124166).  Saving model ...
	 Train_Loss: 0.1928 Train_Acc: 93.637 Val_Loss: 0.1242  BEST VAL Loss: 0.1242  Val_Acc: 95.623

Epoch 62: Validation loss decreased (0.124166 --> 0.124043).  Saving model ...
	 Train_Loss: 0.1928 Train_Acc: 93.566 Val_Loss: 0.1240  BEST VAL Loss: 0.1240  Val_Acc: 96.069

Epoch 63: Validation loss decreased (0.124043 --> 0.123880).  Saving model ...
	 Train_Loss: 0.1926 Train_Acc: 94.084 Val_Loss: 0.1239  BEST VAL Loss: 0.1239  Val_Acc: 96.130

Epoch 64: Validation loss decreased (0.123880 --> 0.123775).  Saving model ...
	 Train_Loss: 0.1924 Train_Acc: 93.958 Val_Loss: 0.1238  BEST VAL Loss: 0.1238  Val_Acc: 96.008

Epoch 65: Validation loss decreased (0.123775 --> 0.123665).  Saving model ...
	 Train_Loss: 0.1922 Train_Acc: 94.059 Val_Loss: 0.1237  BEST VAL Loss: 0.1237  Val_Acc: 95.968

Epoch 66: Validation loss decreased (0.123665 --> 0.123575).  Saving model ...
	 Train_Loss: 0.1920 Train_Acc: 94.118 Val_Loss: 0.1236  BEST VAL Loss: 0.1236  Val_Acc: 95.737

Epoch 67: Validation loss decreased (0.123575 --> 0.123444).  Saving model ...
	 Train_Loss: 0.1918 Train_Acc: 94.180 Val_Loss: 0.1234  BEST VAL Loss: 0.1234  Val_Acc: 95.964

Epoch 68: Validation loss decreased (0.123444 --> 0.123276).  Saving model ...
	 Train_Loss: 0.1915 Train_Acc: 94.214 Val_Loss: 0.1233  BEST VAL Loss: 0.1233  Val_Acc: 96.025

Epoch 69: Validation loss decreased (0.123276 --> 0.123101).  Saving model ...
	 Train_Loss: 0.1913 Train_Acc: 94.319 Val_Loss: 0.1231  BEST VAL Loss: 0.1231  Val_Acc: 96.138

Epoch 70: Validation loss decreased (0.123101 --> 0.122933).  Saving model ...
	 Train_Loss: 0.1910 Train_Acc: 94.246 Val_Loss: 0.1229  BEST VAL Loss: 0.1229  Val_Acc: 96.280

Epoch 71: Validation loss decreased (0.122933 --> 0.122814).  Saving model ...
	 Train_Loss: 0.1908 Train_Acc: 94.249 Val_Loss: 0.1228  BEST VAL Loss: 0.1228  Val_Acc: 96.037

Epoch 72: Validation loss decreased (0.122814 --> 0.122750).  Saving model ...
	 Train_Loss: 0.1905 Train_Acc: 94.278 Val_Loss: 0.1227  BEST VAL Loss: 0.1227  Val_Acc: 95.709

Epoch 73: Validation loss decreased (0.122750 --> 0.122607).  Saving model ...
	 Train_Loss: 0.1903 Train_Acc: 94.240 Val_Loss: 0.1226  BEST VAL Loss: 0.1226  Val_Acc: 96.110

Epoch 74: Validation loss decreased (0.122607 --> 0.122481).  Saving model ...
	 Train_Loss: 0.1901 Train_Acc: 94.325 Val_Loss: 0.1225  BEST VAL Loss: 0.1225  Val_Acc: 96.231

Epoch 75: Validation loss decreased (0.122481 --> 0.122309).  Saving model ...
	 Train_Loss: 0.1899 Train_Acc: 94.466 Val_Loss: 0.1223  BEST VAL Loss: 0.1223  Val_Acc: 96.183

Epoch 76: Validation loss decreased (0.122309 --> 0.122155).  Saving model ...
	 Train_Loss: 0.1897 Train_Acc: 94.091 Val_Loss: 0.1222  BEST VAL Loss: 0.1222  Val_Acc: 96.280

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.1896 Train_Acc: 94.088 Val_Loss: 0.1222  BEST VAL Loss: 0.1222  Val_Acc: 95.101

Epoch 78: Validation loss decreased (0.122155 --> 0.122109).  Saving model ...
	 Train_Loss: 0.1894 Train_Acc: 94.369 Val_Loss: 0.1221  BEST VAL Loss: 0.1221  Val_Acc: 96.008

Epoch 79: Validation loss decreased (0.122109 --> 0.121958).  Saving model ...
	 Train_Loss: 0.1891 Train_Acc: 94.504 Val_Loss: 0.1220  BEST VAL Loss: 0.1220  Val_Acc: 96.130

Epoch 80: Validation loss decreased (0.121958 --> 0.121787).  Saving model ...
	 Train_Loss: 0.1889 Train_Acc: 94.548 Val_Loss: 0.1218  BEST VAL Loss: 0.1218  Val_Acc: 96.341

Epoch 81: Validation loss decreased (0.121787 --> 0.121643).  Saving model ...
	 Train_Loss: 0.1886 Train_Acc: 94.470 Val_Loss: 0.1216  BEST VAL Loss: 0.1216  Val_Acc: 96.231

Epoch 82: Validation loss decreased (0.121643 --> 0.121496).  Saving model ...
	 Train_Loss: 0.1884 Train_Acc: 94.306 Val_Loss: 0.1215  BEST VAL Loss: 0.1215  Val_Acc: 96.215

Epoch 83: Validation loss decreased (0.121496 --> 0.121388).  Saving model ...
	 Train_Loss: 0.1883 Train_Acc: 93.999 Val_Loss: 0.1214  BEST VAL Loss: 0.1214  Val_Acc: 95.960

Epoch 84: Validation loss decreased (0.121388 --> 0.121248).  Saving model ...
	 Train_Loss: 0.1881 Train_Acc: 94.340 Val_Loss: 0.1212  BEST VAL Loss: 0.1212  Val_Acc: 96.381

Epoch 85: Validation loss decreased (0.121248 --> 0.121105).  Saving model ...
	 Train_Loss: 0.1879 Train_Acc: 94.390 Val_Loss: 0.1211  BEST VAL Loss: 0.1211  Val_Acc: 96.397

Epoch 86: Validation loss decreased (0.121105 --> 0.120983).  Saving model ...
	 Train_Loss: 0.1878 Train_Acc: 94.138 Val_Loss: 0.1210  BEST VAL Loss: 0.1210  Val_Acc: 96.264

Epoch 87: Validation loss decreased (0.120983 --> 0.120831).  Saving model ...
	 Train_Loss: 0.1876 Train_Acc: 94.366 Val_Loss: 0.1208  BEST VAL Loss: 0.1208  Val_Acc: 96.377

Epoch 88: Validation loss decreased (0.120831 --> 0.120689).  Saving model ...
	 Train_Loss: 0.1873 Train_Acc: 94.546 Val_Loss: 0.1207  BEST VAL Loss: 0.1207  Val_Acc: 96.207

Epoch 89: Validation loss decreased (0.120689 --> 0.120592).  Saving model ...
	 Train_Loss: 0.1871 Train_Acc: 94.587 Val_Loss: 0.1206  BEST VAL Loss: 0.1206  Val_Acc: 96.264

Epoch 90: Validation loss decreased (0.120592 --> 0.120462).  Saving model ...
	 Train_Loss: 0.1869 Train_Acc: 94.405 Val_Loss: 0.1205  BEST VAL Loss: 0.1205  Val_Acc: 96.235

Epoch 91: Validation loss decreased (0.120462 --> 0.120348).  Saving model ...
	 Train_Loss: 0.1867 Train_Acc: 94.522 Val_Loss: 0.1203  BEST VAL Loss: 0.1203  Val_Acc: 96.272

Epoch 92: Validation loss decreased (0.120348 --> 0.120277).  Saving model ...
	 Train_Loss: 0.1866 Train_Acc: 94.458 Val_Loss: 0.1203  BEST VAL Loss: 0.1203  Val_Acc: 96.292

Epoch 93: Validation loss decreased (0.120277 --> 0.120141).  Saving model ...
	 Train_Loss: 0.1864 Train_Acc: 94.576 Val_Loss: 0.1201  BEST VAL Loss: 0.1201  Val_Acc: 96.418

Epoch 94: Validation loss decreased (0.120141 --> 0.120064).  Saving model ...
	 Train_Loss: 0.1862 Train_Acc: 94.592 Val_Loss: 0.1201  BEST VAL Loss: 0.1201  Val_Acc: 96.162

Epoch 95: Validation loss decreased (0.120064 --> 0.119983).  Saving model ...
	 Train_Loss: 0.1859 Train_Acc: 94.690 Val_Loss: 0.1200  BEST VAL Loss: 0.1200  Val_Acc: 96.268

Epoch 96: Validation loss decreased (0.119983 --> 0.119851).  Saving model ...
	 Train_Loss: 0.1857 Train_Acc: 94.560 Val_Loss: 0.1199  BEST VAL Loss: 0.1199  Val_Acc: 96.385

Epoch 97: Validation loss decreased (0.119851 --> 0.119703).  Saving model ...
	 Train_Loss: 0.1856 Train_Acc: 94.563 Val_Loss: 0.1197  BEST VAL Loss: 0.1197  Val_Acc: 96.450

Epoch 98: Validation loss decreased (0.119703 --> 0.119539).  Saving model ...
	 Train_Loss: 0.1854 Train_Acc: 94.620 Val_Loss: 0.1195  BEST VAL Loss: 0.1195  Val_Acc: 96.560

Epoch 99: Validation loss decreased (0.119539 --> 0.119390).  Saving model ...
	 Train_Loss: 0.1851 Train_Acc: 94.710 Val_Loss: 0.1194  BEST VAL Loss: 0.1194  Val_Acc: 96.495

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.95      0.98      0.97     92173
           1       0.99      0.95      0.97    105242

    accuracy                           0.97    197415
   macro avg       0.97      0.97      0.97    197415
weighted avg       0.97      0.97      0.97    197415

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.95      0.98      0.96     11522
           1       0.98      0.95      0.97     13155

    accuracy                           0.96     24677
   macro avg       0.96      0.97      0.96     24677
weighted avg       0.97      0.96      0.96     24677

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.94      0.98      0.96     11522
           1       0.98      0.95      0.97     13155

    accuracy                           0.96     24677
   macro avg       0.96      0.97      0.96     24677
weighted avg       0.96      0.96      0.96     24677

              precision    recall  f1-score   support

           0       0.94      0.98      0.96     11522
           1       0.98      0.95      0.97     13155

    accuracy                           0.96     24677
   macro avg       0.96      0.97      0.96     24677
weighted avg       0.96      0.96      0.96     24677

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.95      0.96     41273
           1       0.96      0.98      0.97     49614

    accuracy                           0.97     90887
   macro avg       0.97      0.97      0.97     90887
weighted avg       0.97      0.97      0.97     90887

              precision    recall  f1-score   support

           0       0.98      0.95      0.96     41273
           1       0.96      0.98      0.97     49614

    accuracy                           0.97     90887
   macro avg       0.97      0.97      0.97     90887
weighted avg       0.97      0.97      0.97     90887

completed
