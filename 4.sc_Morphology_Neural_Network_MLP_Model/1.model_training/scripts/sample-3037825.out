[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '20d217b1'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e853566f'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '86dbcf7d'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '61a6548c'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_100.000_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_100.000_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_100.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (255350, 1270)
Number of total missing values across all columns: 510700
Data Subset Is Off
Wells held out for testing: ['J08' 'L10']
Wells to use for training, validation, and testing ['J02' 'J03' 'J09' 'L05' 'L11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.497964).  Saving model ...
	 Train_Loss: 0.5610 Train_Acc: 71.423 Val_Loss: 0.4980  BEST VAL Loss: 0.4980  Val_Acc: 75.289

Epoch 1: Validation loss decreased (0.497964 --> 0.482063).  Saving model ...
	 Train_Loss: 0.5251 Train_Acc: 75.471 Val_Loss: 0.4821  BEST VAL Loss: 0.4821  Val_Acc: 76.898

Epoch 2: Validation loss decreased (0.482063 --> 0.472199).  Saving model ...
	 Train_Loss: 0.5061 Train_Acc: 76.858 Val_Loss: 0.4722  BEST VAL Loss: 0.4722  Val_Acc: 77.567

Epoch 3: Validation loss decreased (0.472199 --> 0.466032).  Saving model ...
	 Train_Loss: 0.4941 Train_Acc: 77.439 Val_Loss: 0.4660  BEST VAL Loss: 0.4660  Val_Acc: 77.810

Epoch 4: Validation loss decreased (0.466032 --> 0.461209).  Saving model ...
	 Train_Loss: 0.4855 Train_Acc: 77.803 Val_Loss: 0.4612  BEST VAL Loss: 0.4612  Val_Acc: 78.258

Epoch 5: Validation loss decreased (0.461209 --> 0.458989).  Saving model ...
	 Train_Loss: 0.4787 Train_Acc: 78.044 Val_Loss: 0.4590  BEST VAL Loss: 0.4590  Val_Acc: 77.821

Epoch 6: Validation loss decreased (0.458989 --> 0.456799).  Saving model ...
	 Train_Loss: 0.4734 Train_Acc: 78.431 Val_Loss: 0.4568  BEST VAL Loss: 0.4568  Val_Acc: 78.107

Epoch 7: Validation loss decreased (0.456799 --> 0.454611).  Saving model ...
	 Train_Loss: 0.4689 Train_Acc: 78.590 Val_Loss: 0.4546  BEST VAL Loss: 0.4546  Val_Acc: 78.485

Epoch 8: Validation loss did not decrease
	 Train_Loss: 0.4650 Train_Acc: 78.843 Val_Loss: 0.4550  BEST VAL Loss: 0.4546  Val_Acc: 77.173

Epoch 9: Validation loss decreased (0.454611 --> 0.451953).  Saving model ...
	 Train_Loss: 0.4616 Train_Acc: 78.927 Val_Loss: 0.4520  BEST VAL Loss: 0.4520  Val_Acc: 79.268

Epoch 10: Validation loss decreased (0.451953 --> 0.449230).  Saving model ...
	 Train_Loss: 0.4584 Train_Acc: 79.207 Val_Loss: 0.4492  BEST VAL Loss: 0.4492  Val_Acc: 78.820

Epoch 11: Validation loss decreased (0.449230 --> 0.447033).  Saving model ...
	 Train_Loss: 0.4557 Train_Acc: 79.327 Val_Loss: 0.4470  BEST VAL Loss: 0.4470  Val_Acc: 79.106

Epoch 12: Validation loss decreased (0.447033 --> 0.445072).  Saving model ...
	 Train_Loss: 0.4532 Train_Acc: 79.463 Val_Loss: 0.4451  BEST VAL Loss: 0.4451  Val_Acc: 79.300

Epoch 13: Validation loss decreased (0.445072 --> 0.443395).  Saving model ...
	 Train_Loss: 0.4510 Train_Acc: 79.395 Val_Loss: 0.4434  BEST VAL Loss: 0.4434  Val_Acc: 79.700

Epoch 14: Validation loss decreased (0.443395 --> 0.441880).  Saving model ...
	 Train_Loss: 0.4488 Train_Acc: 79.806 Val_Loss: 0.4419  BEST VAL Loss: 0.4419  Val_Acc: 79.500

Epoch 15: Validation loss decreased (0.441880 --> 0.440854).  Saving model ...
	 Train_Loss: 0.4468 Train_Acc: 79.730 Val_Loss: 0.4409  BEST VAL Loss: 0.4409  Val_Acc: 78.820

Epoch 16: Validation loss decreased (0.440854 --> 0.439376).  Saving model ...
	 Train_Loss: 0.4449 Train_Acc: 79.844 Val_Loss: 0.4394  BEST VAL Loss: 0.4394  Val_Acc: 79.640

Epoch 17: Validation loss decreased (0.439376 --> 0.438207).  Saving model ...
	 Train_Loss: 0.4434 Train_Acc: 79.684 Val_Loss: 0.4382  BEST VAL Loss: 0.4382  Val_Acc: 79.721

Epoch 18: Validation loss decreased (0.438207 --> 0.437579).  Saving model ...
	 Train_Loss: 0.4419 Train_Acc: 79.804 Val_Loss: 0.4376  BEST VAL Loss: 0.4376  Val_Acc: 79.084

Epoch 19: Validation loss decreased (0.437579 --> 0.436674).  Saving model ...
	 Train_Loss: 0.4404 Train_Acc: 80.075 Val_Loss: 0.4367  BEST VAL Loss: 0.4367  Val_Acc: 79.408

Epoch 20: Validation loss decreased (0.436674 --> 0.435739).  Saving model ...
	 Train_Loss: 0.4390 Train_Acc: 80.110 Val_Loss: 0.4357  BEST VAL Loss: 0.4357  Val_Acc: 79.732

Epoch 21: Validation loss decreased (0.435739 --> 0.434821).  Saving model ...
	 Train_Loss: 0.4376 Train_Acc: 80.269 Val_Loss: 0.4348  BEST VAL Loss: 0.4348  Val_Acc: 79.640

Epoch 22: Validation loss decreased (0.434821 --> 0.434402).  Saving model ...
	 Train_Loss: 0.4363 Train_Acc: 80.178 Val_Loss: 0.4344  BEST VAL Loss: 0.4344  Val_Acc: 79.101

Epoch 23: Validation loss decreased (0.434402 --> 0.433467).  Saving model ...
	 Train_Loss: 0.4351 Train_Acc: 80.242 Val_Loss: 0.4335  BEST VAL Loss: 0.4335  Val_Acc: 80.229

Epoch 24: Validation loss decreased (0.433467 --> 0.432775).  Saving model ...
	 Train_Loss: 0.4339 Train_Acc: 80.346 Val_Loss: 0.4328  BEST VAL Loss: 0.4328  Val_Acc: 80.083

Epoch 25: Validation loss decreased (0.432775 --> 0.431840).  Saving model ...
	 Train_Loss: 0.4328 Train_Acc: 80.502 Val_Loss: 0.4318  BEST VAL Loss: 0.4318  Val_Acc: 80.385

Epoch 26: Validation loss decreased (0.431840 --> 0.431401).  Saving model ...
	 Train_Loss: 0.4317 Train_Acc: 80.610 Val_Loss: 0.4314  BEST VAL Loss: 0.4314  Val_Acc: 79.792

Epoch 27: Validation loss decreased (0.431401 --> 0.430789).  Saving model ...
	 Train_Loss: 0.4306 Train_Acc: 80.614 Val_Loss: 0.4308  BEST VAL Loss: 0.4308  Val_Acc: 79.505

Epoch 28: Validation loss decreased (0.430789 --> 0.430376).  Saving model ...
	 Train_Loss: 0.4297 Train_Acc: 80.444 Val_Loss: 0.4304  BEST VAL Loss: 0.4304  Val_Acc: 79.667

Epoch 29: Validation loss decreased (0.430376 --> 0.429813).  Saving model ...
	 Train_Loss: 0.4288 Train_Acc: 80.580 Val_Loss: 0.4298  BEST VAL Loss: 0.4298  Val_Acc: 80.321

Epoch 30: Validation loss decreased (0.429813 --> 0.429093).  Saving model ...
	 Train_Loss: 0.4279 Train_Acc: 80.657 Val_Loss: 0.4291  BEST VAL Loss: 0.4291  Val_Acc: 80.412

Epoch 31: Validation loss decreased (0.429093 --> 0.428562).  Saving model ...
	 Train_Loss: 0.4271 Train_Acc: 80.713 Val_Loss: 0.4286  BEST VAL Loss: 0.4286  Val_Acc: 80.321

Epoch 32: Validation loss decreased (0.428562 --> 0.428227).  Saving model ...
	 Train_Loss: 0.4262 Train_Acc: 80.762 Val_Loss: 0.4282  BEST VAL Loss: 0.4282  Val_Acc: 80.008

Epoch 33: Validation loss decreased (0.428227 --> 0.427665).  Saving model ...
	 Train_Loss: 0.4254 Train_Acc: 80.828 Val_Loss: 0.4277  BEST VAL Loss: 0.4277  Val_Acc: 80.002

Epoch 34: Validation loss decreased (0.427665 --> 0.427271).  Saving model ...
	 Train_Loss: 0.4246 Train_Acc: 80.821 Val_Loss: 0.4273  BEST VAL Loss: 0.4273  Val_Acc: 79.732

Epoch 35: Validation loss decreased (0.427271 --> 0.426962).  Saving model ...
	 Train_Loss: 0.4238 Train_Acc: 81.075 Val_Loss: 0.4270  BEST VAL Loss: 0.4270  Val_Acc: 79.570

Epoch 36: Validation loss decreased (0.426962 --> 0.426531).  Saving model ...
	 Train_Loss: 0.4230 Train_Acc: 80.920 Val_Loss: 0.4265  BEST VAL Loss: 0.4265  Val_Acc: 80.029

Epoch 37: Validation loss decreased (0.426531 --> 0.426240).  Saving model ...
	 Train_Loss: 0.4223 Train_Acc: 80.996 Val_Loss: 0.4262  BEST VAL Loss: 0.4262  Val_Acc: 80.418

Epoch 38: Validation loss decreased (0.426240 --> 0.425830).  Saving model ...
	 Train_Loss: 0.4216 Train_Acc: 80.970 Val_Loss: 0.4258  BEST VAL Loss: 0.4258  Val_Acc: 79.937

Epoch 39: Validation loss decreased (0.425830 --> 0.425433).  Saving model ...
	 Train_Loss: 0.4209 Train_Acc: 80.992 Val_Loss: 0.4254  BEST VAL Loss: 0.4254  Val_Acc: 80.267

Epoch 40: Validation loss decreased (0.425433 --> 0.424983).  Saving model ...
	 Train_Loss: 0.4201 Train_Acc: 81.250 Val_Loss: 0.4250  BEST VAL Loss: 0.4250  Val_Acc: 80.461

Epoch 41: Validation loss decreased (0.424983 --> 0.424705).  Saving model ...
	 Train_Loss: 0.4195 Train_Acc: 81.235 Val_Loss: 0.4247  BEST VAL Loss: 0.4247  Val_Acc: 80.537

Epoch 42: Validation loss decreased (0.424705 --> 0.424263).  Saving model ...
	 Train_Loss: 0.4189 Train_Acc: 81.163 Val_Loss: 0.4243  BEST VAL Loss: 0.4243  Val_Acc: 80.191

Epoch 43: Validation loss decreased (0.424263 --> 0.424062).  Saving model ...
	 Train_Loss: 0.4182 Train_Acc: 81.263 Val_Loss: 0.4241  BEST VAL Loss: 0.4241  Val_Acc: 80.094

Epoch 44: Validation loss decreased (0.424062 --> 0.423702).  Saving model ...
	 Train_Loss: 0.4176 Train_Acc: 81.210 Val_Loss: 0.4237  BEST VAL Loss: 0.4237  Val_Acc: 80.126

Epoch 45: Validation loss decreased (0.423702 --> 0.423459).  Saving model ...
	 Train_Loss: 0.4170 Train_Acc: 81.343 Val_Loss: 0.4235  BEST VAL Loss: 0.4235  Val_Acc: 80.472

Epoch 46: Validation loss decreased (0.423459 --> 0.423090).  Saving model ...
	 Train_Loss: 0.4164 Train_Acc: 81.427 Val_Loss: 0.4231  BEST VAL Loss: 0.4231  Val_Acc: 80.499

Epoch 47: Validation loss decreased (0.423090 --> 0.422632).  Saving model ...
	 Train_Loss: 0.4158 Train_Acc: 81.372 Val_Loss: 0.4226  BEST VAL Loss: 0.4226  Val_Acc: 80.402

Epoch 48: Validation loss decreased (0.422632 --> 0.422284).  Saving model ...
	 Train_Loss: 0.4152 Train_Acc: 81.322 Val_Loss: 0.4223  BEST VAL Loss: 0.4223  Val_Acc: 80.558

Epoch 49: Validation loss decreased (0.422284 --> 0.421954).  Saving model ...
	 Train_Loss: 0.4146 Train_Acc: 81.477 Val_Loss: 0.4220  BEST VAL Loss: 0.4220  Val_Acc: 80.574

Epoch 50: Validation loss decreased (0.421954 --> 0.421706).  Saving model ...
	 Train_Loss: 0.4141 Train_Acc: 81.362 Val_Loss: 0.4217  BEST VAL Loss: 0.4217  Val_Acc: 80.337

Epoch 51: Validation loss decreased (0.421706 --> 0.421428).  Saving model ...
	 Train_Loss: 0.4136 Train_Acc: 81.325 Val_Loss: 0.4214  BEST VAL Loss: 0.4214  Val_Acc: 80.731

Epoch 52: Validation loss decreased (0.421428 --> 0.421311).  Saving model ...
	 Train_Loss: 0.4132 Train_Acc: 81.253 Val_Loss: 0.4213  BEST VAL Loss: 0.4213  Val_Acc: 79.867

Epoch 53: Validation loss decreased (0.421311 --> 0.420998).  Saving model ...
	 Train_Loss: 0.4126 Train_Acc: 81.535 Val_Loss: 0.4210  BEST VAL Loss: 0.4210  Val_Acc: 80.591

Epoch 54: Validation loss decreased (0.420998 --> 0.420873).  Saving model ...
	 Train_Loss: 0.4122 Train_Acc: 81.555 Val_Loss: 0.4209  BEST VAL Loss: 0.4209  Val_Acc: 80.078

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.4117 Train_Acc: 81.554 Val_Loss: 0.4209  BEST VAL Loss: 0.4209  Val_Acc: 80.337

Epoch 56: Validation loss decreased (0.420873 --> 0.420652).  Saving model ...
	 Train_Loss: 0.4112 Train_Acc: 81.604 Val_Loss: 0.4207  BEST VAL Loss: 0.4207  Val_Acc: 80.747

Epoch 57: Validation loss decreased (0.420652 --> 0.420393).  Saving model ...
	 Train_Loss: 0.4107 Train_Acc: 81.614 Val_Loss: 0.4204  BEST VAL Loss: 0.4204  Val_Acc: 80.585

Epoch 58: Validation loss decreased (0.420393 --> 0.420268).  Saving model ...
	 Train_Loss: 0.4103 Train_Acc: 81.689 Val_Loss: 0.4203  BEST VAL Loss: 0.4203  Val_Acc: 80.132

Epoch 59: Validation loss decreased (0.420268 --> 0.420010).  Saving model ...
	 Train_Loss: 0.4099 Train_Acc: 81.550 Val_Loss: 0.4200  BEST VAL Loss: 0.4200  Val_Acc: 80.915

Epoch 60: Validation loss decreased (0.420010 --> 0.419795).  Saving model ...
	 Train_Loss: 0.4094 Train_Acc: 81.631 Val_Loss: 0.4198  BEST VAL Loss: 0.4198  Val_Acc: 80.585

Epoch 61: Validation loss decreased (0.419795 --> 0.419551).  Saving model ...
	 Train_Loss: 0.4090 Train_Acc: 81.670 Val_Loss: 0.4196  BEST VAL Loss: 0.4196  Val_Acc: 80.844

Epoch 62: Validation loss decreased (0.419551 --> 0.419300).  Saving model ...
	 Train_Loss: 0.4086 Train_Acc: 81.711 Val_Loss: 0.4193  BEST VAL Loss: 0.4193  Val_Acc: 80.672

Epoch 63: Validation loss decreased (0.419300 --> 0.419070).  Saving model ...
	 Train_Loss: 0.4081 Train_Acc: 81.757 Val_Loss: 0.4191  BEST VAL Loss: 0.4191  Val_Acc: 80.634

Epoch 64: Validation loss decreased (0.419070 --> 0.418821).  Saving model ...
	 Train_Loss: 0.4077 Train_Acc: 81.735 Val_Loss: 0.4188  BEST VAL Loss: 0.4188  Val_Acc: 80.920

Epoch 65: Validation loss decreased (0.418821 --> 0.418544).  Saving model ...
	 Train_Loss: 0.4073 Train_Acc: 81.710 Val_Loss: 0.4185  BEST VAL Loss: 0.4185  Val_Acc: 80.817

Epoch 66: Validation loss decreased (0.418544 --> 0.418377).  Saving model ...
	 Train_Loss: 0.4069 Train_Acc: 81.844 Val_Loss: 0.4184  BEST VAL Loss: 0.4184  Val_Acc: 80.337

Epoch 67: Validation loss decreased (0.418377 --> 0.418199).  Saving model ...
	 Train_Loss: 0.4066 Train_Acc: 81.737 Val_Loss: 0.4182  BEST VAL Loss: 0.4182  Val_Acc: 80.834

Epoch 68: Validation loss decreased (0.418199 --> 0.418007).  Saving model ...
	 Train_Loss: 0.4062 Train_Acc: 81.742 Val_Loss: 0.4180  BEST VAL Loss: 0.4180  Val_Acc: 80.391

Epoch 69: Validation loss decreased (0.418007 --> 0.417789).  Saving model ...
	 Train_Loss: 0.4058 Train_Acc: 81.613 Val_Loss: 0.4178  BEST VAL Loss: 0.4178  Val_Acc: 80.693

Epoch 70: Validation loss decreased (0.417789 --> 0.417607).  Saving model ...
	 Train_Loss: 0.4055 Train_Acc: 81.940 Val_Loss: 0.4176  BEST VAL Loss: 0.4176  Val_Acc: 80.828

Epoch 71: Validation loss decreased (0.417607 --> 0.417529).  Saving model ...
	 Train_Loss: 0.4051 Train_Acc: 81.825 Val_Loss: 0.4175  BEST VAL Loss: 0.4175  Val_Acc: 80.758

Epoch 72: Validation loss decreased (0.417529 --> 0.417349).  Saving model ...
	 Train_Loss: 0.4047 Train_Acc: 81.744 Val_Loss: 0.4173  BEST VAL Loss: 0.4173  Val_Acc: 80.396

Epoch 73: Validation loss decreased (0.417349 --> 0.417146).  Saving model ...
	 Train_Loss: 0.4044 Train_Acc: 81.853 Val_Loss: 0.4171  BEST VAL Loss: 0.4171  Val_Acc: 80.601

Epoch 74: Validation loss decreased (0.417146 --> 0.416994).  Saving model ...
	 Train_Loss: 0.4040 Train_Acc: 81.959 Val_Loss: 0.4170  BEST VAL Loss: 0.4170  Val_Acc: 80.753

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.4037 Train_Acc: 81.892 Val_Loss: 0.4170  BEST VAL Loss: 0.4170  Val_Acc: 80.186

Epoch 76: Validation loss decreased (0.416994 --> 0.416830).  Saving model ...
	 Train_Loss: 0.4034 Train_Acc: 81.942 Val_Loss: 0.4168  BEST VAL Loss: 0.4168  Val_Acc: 80.645

Epoch 77: Validation loss decreased (0.416830 --> 0.416563).  Saving model ...
	 Train_Loss: 0.4030 Train_Acc: 81.968 Val_Loss: 0.4166  BEST VAL Loss: 0.4166  Val_Acc: 80.963

Epoch 78: Validation loss decreased (0.416563 --> 0.416321).  Saving model ...
	 Train_Loss: 0.4027 Train_Acc: 82.013 Val_Loss: 0.4163  BEST VAL Loss: 0.4163  Val_Acc: 80.893

Epoch 79: Validation loss decreased (0.416321 --> 0.416121).  Saving model ...
	 Train_Loss: 0.4024 Train_Acc: 81.826 Val_Loss: 0.4161  BEST VAL Loss: 0.4161  Val_Acc: 80.574

Epoch 80: Validation loss decreased (0.416121 --> 0.415926).  Saving model ...
	 Train_Loss: 0.4020 Train_Acc: 82.032 Val_Loss: 0.4159  BEST VAL Loss: 0.4159  Val_Acc: 80.747

Epoch 81: Validation loss decreased (0.415926 --> 0.415821).  Saving model ...
	 Train_Loss: 0.4017 Train_Acc: 81.982 Val_Loss: 0.4158  BEST VAL Loss: 0.4158  Val_Acc: 80.466

Epoch 82: Validation loss decreased (0.415821 --> 0.415683).  Saving model ...
	 Train_Loss: 0.4014 Train_Acc: 82.027 Val_Loss: 0.4157  BEST VAL Loss: 0.4157  Val_Acc: 81.060

Epoch 83: Validation loss decreased (0.415683 --> 0.415555).  Saving model ...
	 Train_Loss: 0.4011 Train_Acc: 81.939 Val_Loss: 0.4156  BEST VAL Loss: 0.4156  Val_Acc: 80.369

Epoch 84: Validation loss decreased (0.415555 --> 0.415371).  Saving model ...
	 Train_Loss: 0.4008 Train_Acc: 82.054 Val_Loss: 0.4154  BEST VAL Loss: 0.4154  Val_Acc: 80.920

Epoch 85: Validation loss decreased (0.415371 --> 0.415166).  Saving model ...
	 Train_Loss: 0.4005 Train_Acc: 82.128 Val_Loss: 0.4152  BEST VAL Loss: 0.4152  Val_Acc: 80.861

Epoch 86: Validation loss decreased (0.415166 --> 0.414988).  Saving model ...
	 Train_Loss: 0.4002 Train_Acc: 82.117 Val_Loss: 0.4150  BEST VAL Loss: 0.4150  Val_Acc: 81.158

Epoch 87: Validation loss decreased (0.414988 --> 0.414867).  Saving model ...
	 Train_Loss: 0.3999 Train_Acc: 82.094 Val_Loss: 0.4149  BEST VAL Loss: 0.4149  Val_Acc: 81.141

Epoch 88: Validation loss decreased (0.414867 --> 0.414797).  Saving model ...
	 Train_Loss: 0.3996 Train_Acc: 82.096 Val_Loss: 0.4148  BEST VAL Loss: 0.4148  Val_Acc: 80.682

Epoch 89: Validation loss decreased (0.414797 --> 0.414687).  Saving model ...
	 Train_Loss: 0.3994 Train_Acc: 82.065 Val_Loss: 0.4147  BEST VAL Loss: 0.4147  Val_Acc: 81.190

Epoch 90: Validation loss decreased (0.414687 --> 0.414570).  Saving model ...
	 Train_Loss: 0.3991 Train_Acc: 81.975 Val_Loss: 0.4146  BEST VAL Loss: 0.4146  Val_Acc: 80.828

Epoch 91: Validation loss decreased (0.414570 --> 0.414486).  Saving model ...
	 Train_Loss: 0.3988 Train_Acc: 82.194 Val_Loss: 0.4145  BEST VAL Loss: 0.4145  Val_Acc: 80.828

Epoch 92: Validation loss decreased (0.414486 --> 0.414389).  Saving model ...
	 Train_Loss: 0.3985 Train_Acc: 82.175 Val_Loss: 0.4144  BEST VAL Loss: 0.4144  Val_Acc: 80.418

Epoch 93: Validation loss decreased (0.414389 --> 0.414310).  Saving model ...
	 Train_Loss: 0.3982 Train_Acc: 82.133 Val_Loss: 0.4143  BEST VAL Loss: 0.4143  Val_Acc: 80.709

Epoch 94: Validation loss decreased (0.414310 --> 0.414307).  Saving model ...
	 Train_Loss: 0.3980 Train_Acc: 82.200 Val_Loss: 0.4143  BEST VAL Loss: 0.4143  Val_Acc: 80.596

Epoch 95: Validation loss decreased (0.414307 --> 0.414200).  Saving model ...
	 Train_Loss: 0.3977 Train_Acc: 82.090 Val_Loss: 0.4142  BEST VAL Loss: 0.4142  Val_Acc: 80.839

Epoch 96: Validation loss decreased (0.414200 --> 0.414059).  Saving model ...
	 Train_Loss: 0.3975 Train_Acc: 82.262 Val_Loss: 0.4141  BEST VAL Loss: 0.4141  Val_Acc: 81.017

Epoch 97: Validation loss decreased (0.414059 --> 0.413949).  Saving model ...
	 Train_Loss: 0.3972 Train_Acc: 82.218 Val_Loss: 0.4139  BEST VAL Loss: 0.4139  Val_Acc: 80.758

Epoch 98: Validation loss decreased (0.413949 --> 0.413901).  Saving model ...
	 Train_Loss: 0.3970 Train_Acc: 82.116 Val_Loss: 0.4139  BEST VAL Loss: 0.4139  Val_Acc: 80.763

Epoch 99: Validation loss decreased (0.413901 --> 0.413811).  Saving model ...
	 Train_Loss: 0.3967 Train_Acc: 82.241 Val_Loss: 0.4138  BEST VAL Loss: 0.4138  Val_Acc: 80.720

LPS_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.34      0.30      0.32     50422
           1       0.66      0.70      0.68     97754

    accuracy                           0.57    148176
   macro avg       0.50      0.50      0.50    148176
weighted avg       0.55      0.57      0.56    148176

LPS_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.34      0.30      0.31      6303
           1       0.66      0.70      0.68     12219

    accuracy                           0.56     18522
   macro avg       0.50      0.50      0.50     18522
weighted avg       0.55      0.56      0.55     18522

LPS_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.35      0.30      0.32      6303
           1       0.66      0.71      0.69     12219

    accuracy                           0.57     18522
   macro avg       0.51      0.51      0.51     18522
weighted avg       0.56      0.57      0.56     18522

              precision    recall  f1-score   support

           0       0.35      0.30      0.32      6303
           1       0.66      0.71      0.69     12219

    accuracy                           0.57     18522
   macro avg       0.51      0.51      0.51     18522
weighted avg       0.56      0.57      0.56     18522

LPS_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.38      0.42     32887
           1       0.53      0.62      0.57     37243

    accuracy                           0.51     70130
   macro avg       0.50      0.50      0.50     70130
weighted avg       0.50      0.51      0.50     70130

              precision    recall  f1-score   support

           0       0.47      0.38      0.42     32887
           1       0.53      0.62      0.57     37243

    accuracy                           0.51     70130
   macro avg       0.50      0.50      0.50     70130
weighted avg       0.50      0.51      0.50     70130

completed
