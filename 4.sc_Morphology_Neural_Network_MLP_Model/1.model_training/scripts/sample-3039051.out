[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'a464e8d5'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '560df24b'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'dac360a1'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '76efbb9c'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (33728, 1276)
Number of total missing values across all columns: 35020
Data Subset Is Off
Wells held out for testing: ['C20' 'K16']
Wells to use for training, validation, and testing ['C16' 'C17' 'C21' 'K17' 'K20' 'K21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.486126).  Saving model ...
	 Train_Loss: 0.5892 Train_Acc: 66.982 Val_Loss: 0.4861  BEST VAL Loss: 0.4861  Val_Acc: 80.742

Epoch 1: Validation loss decreased (0.486126 --> 0.449988).  Saving model ...
	 Train_Loss: 0.5336 Train_Acc: 78.730 Val_Loss: 0.4500  BEST VAL Loss: 0.4500  Val_Acc: 85.726

Epoch 2: Validation loss decreased (0.449988 --> 0.416463).  Saving model ...
	 Train_Loss: 0.4961 Train_Acc: 80.968 Val_Loss: 0.4165  BEST VAL Loss: 0.4165  Val_Acc: 87.440

Epoch 3: Validation loss decreased (0.416463 --> 0.390780).  Saving model ...
	 Train_Loss: 0.4668 Train_Acc: 82.913 Val_Loss: 0.3908  BEST VAL Loss: 0.3908  Val_Acc: 88.876

Epoch 4: Validation loss decreased (0.390780 --> 0.370574).  Saving model ...
	 Train_Loss: 0.4437 Train_Acc: 84.384 Val_Loss: 0.3706  BEST VAL Loss: 0.3706  Val_Acc: 89.673

Epoch 5: Validation loss decreased (0.370574 --> 0.354700).  Saving model ...
	 Train_Loss: 0.4246 Train_Acc: 85.620 Val_Loss: 0.3547  BEST VAL Loss: 0.3547  Val_Acc: 90.311

Epoch 6: Validation loss decreased (0.354700 --> 0.341363).  Saving model ...
	 Train_Loss: 0.4083 Train_Acc: 86.453 Val_Loss: 0.3414  BEST VAL Loss: 0.3414  Val_Acc: 91.906

Epoch 7: Validation loss decreased (0.341363 --> 0.328814).  Saving model ...
	 Train_Loss: 0.3942 Train_Acc: 87.221 Val_Loss: 0.3288  BEST VAL Loss: 0.3288  Val_Acc: 92.065

Epoch 8: Validation loss decreased (0.328814 --> 0.316775).  Saving model ...
	 Train_Loss: 0.3817 Train_Acc: 87.704 Val_Loss: 0.3168  BEST VAL Loss: 0.3168  Val_Acc: 92.982

Epoch 9: Validation loss decreased (0.316775 --> 0.307830).  Saving model ...
	 Train_Loss: 0.3704 Train_Acc: 88.288 Val_Loss: 0.3078  BEST VAL Loss: 0.3078  Val_Acc: 92.145

Epoch 10: Validation loss decreased (0.307830 --> 0.298666).  Saving model ...
	 Train_Loss: 0.3611 Train_Acc: 88.328 Val_Loss: 0.2987  BEST VAL Loss: 0.2987  Val_Acc: 93.501

Epoch 11: Validation loss decreased (0.298666 --> 0.290814).  Saving model ...
	 Train_Loss: 0.3523 Train_Acc: 88.986 Val_Loss: 0.2908  BEST VAL Loss: 0.2908  Val_Acc: 93.022

Epoch 12: Validation loss decreased (0.290814 --> 0.283539).  Saving model ...
	 Train_Loss: 0.3445 Train_Acc: 89.180 Val_Loss: 0.2835  BEST VAL Loss: 0.2835  Val_Acc: 93.022

Epoch 13: Validation loss decreased (0.283539 --> 0.277642).  Saving model ...
	 Train_Loss: 0.3370 Train_Acc: 89.509 Val_Loss: 0.2776  BEST VAL Loss: 0.2776  Val_Acc: 93.341

Epoch 14: Validation loss decreased (0.277642 --> 0.271724).  Saving model ...
	 Train_Loss: 0.3301 Train_Acc: 89.445 Val_Loss: 0.2717  BEST VAL Loss: 0.2717  Val_Acc: 93.262

Epoch 15: Validation loss decreased (0.271724 --> 0.266044).  Saving model ...
	 Train_Loss: 0.3241 Train_Acc: 89.789 Val_Loss: 0.2660  BEST VAL Loss: 0.2660  Val_Acc: 94.099

Epoch 16: Validation loss decreased (0.266044 --> 0.260614).  Saving model ...
	 Train_Loss: 0.3181 Train_Acc: 90.113 Val_Loss: 0.2606  BEST VAL Loss: 0.2606  Val_Acc: 94.537

Epoch 17: Validation loss decreased (0.260614 --> 0.256223).  Saving model ...
	 Train_Loss: 0.3125 Train_Acc: 90.412 Val_Loss: 0.2562  BEST VAL Loss: 0.2562  Val_Acc: 93.860

Epoch 18: Validation loss decreased (0.256223 --> 0.252292).  Saving model ...
	 Train_Loss: 0.3074 Train_Acc: 90.606 Val_Loss: 0.2523  BEST VAL Loss: 0.2523  Val_Acc: 93.939

Epoch 19: Validation loss decreased (0.252292 --> 0.248780).  Saving model ...
	 Train_Loss: 0.3027 Train_Acc: 90.656 Val_Loss: 0.2488  BEST VAL Loss: 0.2488  Val_Acc: 93.740

Epoch 20: Validation loss decreased (0.248780 --> 0.244566).  Saving model ...
	 Train_Loss: 0.2980 Train_Acc: 90.751 Val_Loss: 0.2446  BEST VAL Loss: 0.2446  Val_Acc: 94.537

Epoch 21: Validation loss decreased (0.244566 --> 0.240604).  Saving model ...
	 Train_Loss: 0.2939 Train_Acc: 90.611 Val_Loss: 0.2406  BEST VAL Loss: 0.2406  Val_Acc: 94.817

Epoch 22: Validation loss decreased (0.240604 --> 0.237695).  Saving model ...
	 Train_Loss: 0.2900 Train_Acc: 90.781 Val_Loss: 0.2377  BEST VAL Loss: 0.2377  Val_Acc: 94.219

Epoch 23: Validation loss decreased (0.237695 --> 0.234459).  Saving model ...
	 Train_Loss: 0.2860 Train_Acc: 91.170 Val_Loss: 0.2345  BEST VAL Loss: 0.2345  Val_Acc: 94.577

Epoch 24: Validation loss decreased (0.234459 --> 0.232372).  Saving model ...
	 Train_Loss: 0.2823 Train_Acc: 91.080 Val_Loss: 0.2324  BEST VAL Loss: 0.2324  Val_Acc: 94.338

Epoch 25: Validation loss decreased (0.232372 --> 0.229597).  Saving model ...
	 Train_Loss: 0.2790 Train_Acc: 91.070 Val_Loss: 0.2296  BEST VAL Loss: 0.2296  Val_Acc: 94.059

Epoch 26: Validation loss decreased (0.229597 --> 0.227034).  Saving model ...
	 Train_Loss: 0.2757 Train_Acc: 91.274 Val_Loss: 0.2270  BEST VAL Loss: 0.2270  Val_Acc: 94.856

Epoch 27: Validation loss decreased (0.227034 --> 0.224534).  Saving model ...
	 Train_Loss: 0.2726 Train_Acc: 91.559 Val_Loss: 0.2245  BEST VAL Loss: 0.2245  Val_Acc: 94.936

Epoch 28: Validation loss decreased (0.224534 --> 0.221838).  Saving model ...
	 Train_Loss: 0.2695 Train_Acc: 91.663 Val_Loss: 0.2218  BEST VAL Loss: 0.2218  Val_Acc: 95.494

Epoch 29: Validation loss decreased (0.221838 --> 0.220283).  Saving model ...
	 Train_Loss: 0.2665 Train_Acc: 91.743 Val_Loss: 0.2203  BEST VAL Loss: 0.2203  Val_Acc: 94.258

Epoch 30: Validation loss decreased (0.220283 --> 0.217727).  Saving model ...
	 Train_Loss: 0.2637 Train_Acc: 91.708 Val_Loss: 0.2177  BEST VAL Loss: 0.2177  Val_Acc: 94.657

Epoch 31: Validation loss decreased (0.217727 --> 0.215407).  Saving model ...
	 Train_Loss: 0.2609 Train_Acc: 91.798 Val_Loss: 0.2154  BEST VAL Loss: 0.2154  Val_Acc: 95.295

Epoch 32: Validation loss decreased (0.215407 --> 0.214639).  Saving model ...
	 Train_Loss: 0.2583 Train_Acc: 91.967 Val_Loss: 0.2146  BEST VAL Loss: 0.2146  Val_Acc: 93.900

Epoch 33: Validation loss decreased (0.214639 --> 0.212437).  Saving model ...
	 Train_Loss: 0.2559 Train_Acc: 91.718 Val_Loss: 0.2124  BEST VAL Loss: 0.2124  Val_Acc: 95.295

Epoch 34: Validation loss decreased (0.212437 --> 0.210498).  Saving model ...
	 Train_Loss: 0.2535 Train_Acc: 91.928 Val_Loss: 0.2105  BEST VAL Loss: 0.2105  Val_Acc: 95.335

Epoch 35: Validation loss decreased (0.210498 --> 0.209870).  Saving model ...
	 Train_Loss: 0.2511 Train_Acc: 92.037 Val_Loss: 0.2099  BEST VAL Loss: 0.2099  Val_Acc: 90.869

Epoch 36: Validation loss decreased (0.209870 --> 0.207985).  Saving model ...
	 Train_Loss: 0.2490 Train_Acc: 91.574 Val_Loss: 0.2080  BEST VAL Loss: 0.2080  Val_Acc: 95.455

Epoch 37: Validation loss decreased (0.207985 --> 0.206674).  Saving model ...
	 Train_Loss: 0.2468 Train_Acc: 92.242 Val_Loss: 0.2067  BEST VAL Loss: 0.2067  Val_Acc: 94.617

Epoch 38: Validation loss decreased (0.206674 --> 0.204985).  Saving model ...
	 Train_Loss: 0.2448 Train_Acc: 92.007 Val_Loss: 0.2050  BEST VAL Loss: 0.2050  Val_Acc: 95.295

Epoch 39: Validation loss decreased (0.204985 --> 0.203635).  Saving model ...
	 Train_Loss: 0.2428 Train_Acc: 92.032 Val_Loss: 0.2036  BEST VAL Loss: 0.2036  Val_Acc: 94.976

Epoch 40: Validation loss decreased (0.203635 --> 0.202026).  Saving model ...
	 Train_Loss: 0.2407 Train_Acc: 92.531 Val_Loss: 0.2020  BEST VAL Loss: 0.2020  Val_Acc: 95.455

Epoch 41: Validation loss decreased (0.202026 --> 0.200627).  Saving model ...
	 Train_Loss: 0.2388 Train_Acc: 92.272 Val_Loss: 0.2006  BEST VAL Loss: 0.2006  Val_Acc: 94.777

Epoch 42: Validation loss decreased (0.200627 --> 0.198987).  Saving model ...
	 Train_Loss: 0.2369 Train_Acc: 92.356 Val_Loss: 0.1990  BEST VAL Loss: 0.1990  Val_Acc: 96.013

Epoch 43: Validation loss decreased (0.198987 --> 0.197685).  Saving model ...
	 Train_Loss: 0.2350 Train_Acc: 92.401 Val_Loss: 0.1977  BEST VAL Loss: 0.1977  Val_Acc: 95.494

Epoch 44: Validation loss decreased (0.197685 --> 0.196469).  Saving model ...
	 Train_Loss: 0.2333 Train_Acc: 92.167 Val_Loss: 0.1965  BEST VAL Loss: 0.1965  Val_Acc: 95.534

Epoch 45: Validation loss decreased (0.196469 --> 0.195017).  Saving model ...
	 Train_Loss: 0.2316 Train_Acc: 92.401 Val_Loss: 0.1950  BEST VAL Loss: 0.1950  Val_Acc: 96.013

Epoch 46: Validation loss decreased (0.195017 --> 0.194140).  Saving model ...
	 Train_Loss: 0.2299 Train_Acc: 92.710 Val_Loss: 0.1941  BEST VAL Loss: 0.1941  Val_Acc: 95.215

Epoch 47: Validation loss decreased (0.194140 --> 0.192911).  Saving model ...
	 Train_Loss: 0.2283 Train_Acc: 92.576 Val_Loss: 0.1929  BEST VAL Loss: 0.1929  Val_Acc: 95.455

Epoch 48: Validation loss decreased (0.192911 --> 0.192008).  Saving model ...
	 Train_Loss: 0.2267 Train_Acc: 92.611 Val_Loss: 0.1920  BEST VAL Loss: 0.1920  Val_Acc: 95.415

Epoch 49: Validation loss decreased (0.192008 --> 0.190905).  Saving model ...
	 Train_Loss: 0.2252 Train_Acc: 92.411 Val_Loss: 0.1909  BEST VAL Loss: 0.1909  Val_Acc: 95.255

Epoch 50: Validation loss decreased (0.190905 --> 0.190550).  Saving model ...
	 Train_Loss: 0.2238 Train_Acc: 92.636 Val_Loss: 0.1905  BEST VAL Loss: 0.1905  Val_Acc: 91.986

Epoch 51: Validation loss decreased (0.190550 --> 0.189354).  Saving model ...
	 Train_Loss: 0.2226 Train_Acc: 91.289 Val_Loss: 0.1894  BEST VAL Loss: 0.1894  Val_Acc: 95.534

Epoch 52: Validation loss decreased (0.189354 --> 0.188486).  Saving model ...
	 Train_Loss: 0.2211 Train_Acc: 92.606 Val_Loss: 0.1885  BEST VAL Loss: 0.1885  Val_Acc: 95.295

Epoch 53: Validation loss decreased (0.188486 --> 0.187371).  Saving model ...
	 Train_Loss: 0.2197 Train_Acc: 92.521 Val_Loss: 0.1874  BEST VAL Loss: 0.1874  Val_Acc: 96.013

Epoch 54: Validation loss decreased (0.187371 --> 0.186452).  Saving model ...
	 Train_Loss: 0.2184 Train_Acc: 92.840 Val_Loss: 0.1865  BEST VAL Loss: 0.1865  Val_Acc: 94.936

Epoch 55: Validation loss decreased (0.186452 --> 0.185364).  Saving model ...
	 Train_Loss: 0.2171 Train_Acc: 92.511 Val_Loss: 0.1854  BEST VAL Loss: 0.1854  Val_Acc: 95.774

Epoch 56: Validation loss decreased (0.185364 --> 0.184454).  Saving model ...
	 Train_Loss: 0.2158 Train_Acc: 92.526 Val_Loss: 0.1845  BEST VAL Loss: 0.1845  Val_Acc: 95.973

Epoch 57: Validation loss decreased (0.184454 --> 0.183334).  Saving model ...
	 Train_Loss: 0.2145 Train_Acc: 92.930 Val_Loss: 0.1833  BEST VAL Loss: 0.1833  Val_Acc: 95.933

Epoch 58: Validation loss decreased (0.183334 --> 0.182338).  Saving model ...
	 Train_Loss: 0.2132 Train_Acc: 92.740 Val_Loss: 0.1823  BEST VAL Loss: 0.1823  Val_Acc: 96.212

Epoch 59: Validation loss decreased (0.182338 --> 0.181375).  Saving model ...
	 Train_Loss: 0.2119 Train_Acc: 93.000 Val_Loss: 0.1814  BEST VAL Loss: 0.1814  Val_Acc: 95.734

Epoch 60: Validation loss decreased (0.181375 --> 0.180731).  Saving model ...
	 Train_Loss: 0.2107 Train_Acc: 92.715 Val_Loss: 0.1807  BEST VAL Loss: 0.1807  Val_Acc: 96.013

Epoch 61: Validation loss decreased (0.180731 --> 0.179791).  Saving model ...
	 Train_Loss: 0.2096 Train_Acc: 92.666 Val_Loss: 0.1798  BEST VAL Loss: 0.1798  Val_Acc: 95.734

Epoch 62: Validation loss decreased (0.179791 --> 0.179152).  Saving model ...
	 Train_Loss: 0.2084 Train_Acc: 92.725 Val_Loss: 0.1792  BEST VAL Loss: 0.1792  Val_Acc: 96.172

Epoch 63: Validation loss decreased (0.179152 --> 0.178434).  Saving model ...
	 Train_Loss: 0.2072 Train_Acc: 92.915 Val_Loss: 0.1784  BEST VAL Loss: 0.1784  Val_Acc: 95.614

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.2061 Train_Acc: 93.015 Val_Loss: 0.1786  BEST VAL Loss: 0.1784  Val_Acc: 94.378

Epoch 65: Validation loss decreased (0.178434 --> 0.177740).  Saving model ...
	 Train_Loss: 0.2050 Train_Acc: 92.760 Val_Loss: 0.1777  BEST VAL Loss: 0.1777  Val_Acc: 96.053

Epoch 66: Validation loss decreased (0.177740 --> 0.176959).  Saving model ...
	 Train_Loss: 0.2039 Train_Acc: 92.860 Val_Loss: 0.1770  BEST VAL Loss: 0.1770  Val_Acc: 96.053

Epoch 67: Validation loss decreased (0.176959 --> 0.176376).  Saving model ...
	 Train_Loss: 0.2029 Train_Acc: 93.089 Val_Loss: 0.1764  BEST VAL Loss: 0.1764  Val_Acc: 96.292

Epoch 68: Validation loss decreased (0.176376 --> 0.176128).  Saving model ...
	 Train_Loss: 0.2020 Train_Acc: 92.481 Val_Loss: 0.1761  BEST VAL Loss: 0.1761  Val_Acc: 95.136

Epoch 69: Validation loss decreased (0.176128 --> 0.175856).  Saving model ...
	 Train_Loss: 0.2010 Train_Acc: 92.815 Val_Loss: 0.1759  BEST VAL Loss: 0.1759  Val_Acc: 95.255

Epoch 70: Validation loss decreased (0.175856 --> 0.175206).  Saving model ...
	 Train_Loss: 0.2001 Train_Acc: 93.069 Val_Loss: 0.1752  BEST VAL Loss: 0.1752  Val_Acc: 95.813

Epoch 71: Validation loss decreased (0.175206 --> 0.174495).  Saving model ...
	 Train_Loss: 0.1992 Train_Acc: 92.775 Val_Loss: 0.1745  BEST VAL Loss: 0.1745  Val_Acc: 95.933

Epoch 72: Validation loss decreased (0.174495 --> 0.173880).  Saving model ...
	 Train_Loss: 0.1982 Train_Acc: 92.845 Val_Loss: 0.1739  BEST VAL Loss: 0.1739  Val_Acc: 96.053

Epoch 73: Validation loss decreased (0.173880 --> 0.173285).  Saving model ...
	 Train_Loss: 0.1974 Train_Acc: 92.865 Val_Loss: 0.1733  BEST VAL Loss: 0.1733  Val_Acc: 95.893

Epoch 74: Validation loss decreased (0.173285 --> 0.172842).  Saving model ...
	 Train_Loss: 0.1965 Train_Acc: 93.000 Val_Loss: 0.1728  BEST VAL Loss: 0.1728  Val_Acc: 95.893

Epoch 75: Validation loss decreased (0.172842 --> 0.172382).  Saving model ...
	 Train_Loss: 0.1956 Train_Acc: 92.855 Val_Loss: 0.1724  BEST VAL Loss: 0.1724  Val_Acc: 95.494

Epoch 76: Validation loss decreased (0.172382 --> 0.171686).  Saving model ...
	 Train_Loss: 0.1947 Train_Acc: 93.109 Val_Loss: 0.1717  BEST VAL Loss: 0.1717  Val_Acc: 96.132

Epoch 77: Validation loss decreased (0.171686 --> 0.171183).  Saving model ...
	 Train_Loss: 0.1938 Train_Acc: 93.129 Val_Loss: 0.1712  BEST VAL Loss: 0.1712  Val_Acc: 94.577

Epoch 78: Validation loss decreased (0.171183 --> 0.170521).  Saving model ...
	 Train_Loss: 0.1930 Train_Acc: 93.005 Val_Loss: 0.1705  BEST VAL Loss: 0.1705  Val_Acc: 96.252

Epoch 79: Validation loss decreased (0.170521 --> 0.170061).  Saving model ...
	 Train_Loss: 0.1922 Train_Acc: 93.064 Val_Loss: 0.1701  BEST VAL Loss: 0.1701  Val_Acc: 95.574

Epoch 80: Validation loss decreased (0.170061 --> 0.169454).  Saving model ...
	 Train_Loss: 0.1914 Train_Acc: 92.451 Val_Loss: 0.1695  BEST VAL Loss: 0.1695  Val_Acc: 96.093

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.1906 Train_Acc: 92.940 Val_Loss: 0.1709  BEST VAL Loss: 0.1695  Val_Acc: 93.222

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.1900 Train_Acc: 92.820 Val_Loss: 0.1705  BEST VAL Loss: 0.1695  Val_Acc: 95.734

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.1892 Train_Acc: 93.423 Val_Loss: 0.1700  BEST VAL Loss: 0.1695  Val_Acc: 95.694

Epoch 84: Validation loss decreased (0.169454 --> 0.169374).  Saving model ...
	 Train_Loss: 0.1885 Train_Acc: 92.835 Val_Loss: 0.1694  BEST VAL Loss: 0.1694  Val_Acc: 96.132

Epoch 85: Validation loss decreased (0.169374 --> 0.169032).  Saving model ...
	 Train_Loss: 0.1877 Train_Acc: 93.169 Val_Loss: 0.1690  BEST VAL Loss: 0.1690  Val_Acc: 95.096

Epoch 86: Validation loss decreased (0.169032 --> 0.168890).  Saving model ...
	 Train_Loss: 0.1871 Train_Acc: 92.725 Val_Loss: 0.1689  BEST VAL Loss: 0.1689  Val_Acc: 92.344

Epoch 87: Validation loss decreased (0.168890 --> 0.168355).  Saving model ...
	 Train_Loss: 0.1865 Train_Acc: 92.032 Val_Loss: 0.1684  BEST VAL Loss: 0.1684  Val_Acc: 96.172

Epoch 88: Validation loss decreased (0.168355 --> 0.167864).  Saving model ...
	 Train_Loss: 0.1857 Train_Acc: 93.089 Val_Loss: 0.1679  BEST VAL Loss: 0.1679  Val_Acc: 96.013

Epoch 89: Validation loss decreased (0.167864 --> 0.167314).  Saving model ...
	 Train_Loss: 0.1850 Train_Acc: 93.134 Val_Loss: 0.1673  BEST VAL Loss: 0.1673  Val_Acc: 96.292

Epoch 90: Validation loss decreased (0.167314 --> 0.166761).  Saving model ...
	 Train_Loss: 0.1842 Train_Acc: 93.114 Val_Loss: 0.1668  BEST VAL Loss: 0.1668  Val_Acc: 96.372

Epoch 91: Validation loss decreased (0.166761 --> 0.166464).  Saving model ...
	 Train_Loss: 0.1835 Train_Acc: 93.618 Val_Loss: 0.1665  BEST VAL Loss: 0.1665  Val_Acc: 94.617

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.1828 Train_Acc: 92.581 Val_Loss: 0.1667  BEST VAL Loss: 0.1665  Val_Acc: 94.896

Epoch 93: Validation loss decreased (0.166464 --> 0.166052).  Saving model ...
	 Train_Loss: 0.1821 Train_Acc: 93.064 Val_Loss: 0.1661  BEST VAL Loss: 0.1661  Val_Acc: 96.212

Epoch 94: Validation loss decreased (0.166052 --> 0.165573).  Saving model ...
	 Train_Loss: 0.1815 Train_Acc: 92.945 Val_Loss: 0.1656  BEST VAL Loss: 0.1656  Val_Acc: 96.212

Epoch 95: Validation loss decreased (0.165573 --> 0.165079).  Saving model ...
	 Train_Loss: 0.1808 Train_Acc: 93.553 Val_Loss: 0.1651  BEST VAL Loss: 0.1651  Val_Acc: 96.411

Epoch 96: Validation loss decreased (0.165079 --> 0.164644).  Saving model ...
	 Train_Loss: 0.1801 Train_Acc: 93.538 Val_Loss: 0.1646  BEST VAL Loss: 0.1646  Val_Acc: 96.132

Epoch 97: Validation loss decreased (0.164644 --> 0.164277).  Saving model ...
	 Train_Loss: 0.1794 Train_Acc: 93.513 Val_Loss: 0.1643  BEST VAL Loss: 0.1643  Val_Acc: 96.491

Epoch 98: Validation loss decreased (0.164277 --> 0.163854).  Saving model ...
	 Train_Loss: 0.1787 Train_Acc: 93.369 Val_Loss: 0.1639  BEST VAL Loss: 0.1639  Val_Acc: 96.132

Epoch 99: Validation loss decreased (0.163854 --> 0.163399).  Saving model ...
	 Train_Loss: 0.1781 Train_Acc: 93.099 Val_Loss: 0.1634  BEST VAL Loss: 0.1634  Val_Acc: 96.332

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.51      0.52     10452
           1       0.47      0.47      0.47      9604

    accuracy                           0.50     20056
   macro avg       0.49      0.49      0.49     20056
weighted avg       0.50      0.50      0.50     20056

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.51      0.52      1307
           1       0.48      0.49      0.48      1201

    accuracy                           0.50      2508
   macro avg       0.50      0.50      0.50      2508
weighted avg       0.50      0.50      0.50      2508

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.52      0.52      1306
           1       0.49      0.49      0.49      1201

    accuracy                           0.51      2507
   macro avg       0.51      0.51      0.51      2507
weighted avg       0.51      0.51      0.51      2507

              precision    recall  f1-score   support

           0       0.53      0.52      0.52      1306
           1       0.49      0.49      0.49      1201

    accuracy                           0.51      2507
   macro avg       0.51      0.51      0.51      2507
weighted avg       0.51      0.51      0.51      2507

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.51      0.51      4445
           1       0.48      0.48      0.48      4212

    accuracy                           0.50      8657
   macro avg       0.50      0.50      0.50      8657
weighted avg       0.50      0.50      0.50      8657

              precision    recall  f1-score   support

           0       0.51      0.51      0.51      4445
           1       0.48      0.48      0.48      4212

    accuracy                           0.50      8657
   macro avg       0.50      0.50      0.50      8657
weighted avg       0.50      0.50      0.50      8657

completed
