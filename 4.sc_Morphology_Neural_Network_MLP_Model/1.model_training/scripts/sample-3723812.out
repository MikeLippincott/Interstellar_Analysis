[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 18688 bytes to train_binary_model.py
[NbConvertApp] Converting notebook ../notebooks/train_multiclass_model.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: MissingIDFieldWarning: Code cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.
  validate(nb)
[NbConvertApp] Writing 31143 bytes to train_multiclass_model.py
[NbConvertApp] Converting notebook ../notebooks/train_regression_model.ipynb to script
[NbConvertApp] Writing 25120 bytes to train_regression_model.py
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:314: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels.drop_duplicates(inplace=True)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1015: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1016: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1015: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1016: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1036: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:578: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:652: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1219: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:880: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1219: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:1096: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
PBMC MultiClass_MLP False
[0.9436581681188537, 0.5245113046249099, 0.5318305272562364]
Data Subset Is Off
(1483474,) (370869,) (2207496,) (1536843,)
(1483474,) (370869,) (2207496,) (1536843,)
5598682
(95928,) (749319,) (638227,)
(23982,) (187329,) (159558,)
(119911,) (936644,) (1150941,)
(75619,) (788818,) (672406,)
(1483474, 1245) (370869, 1245) (2207496, 1245) (1536843, 1245)
(1483474,) (370869,) (2207496,) (1536843,)
Number of in features:  1245
Number of out features:  3
Multi_Class
Adam
Epoch 0: Validation loss decreased (inf --> 0.769291).  Saving model ...
	 Train_Loss: 0.8280 Train_Acc: 65.462 Val_Loss: 0.7693  BEST VAL Loss: 0.7693  Val_Acc: 67.157

Epoch 1: Validation loss decreased (0.769291 --> 0.755439).  Saving model ...
	 Train_Loss: 0.8151 Train_Acc: 67.312 Val_Loss: 0.7554  BEST VAL Loss: 0.7554  Val_Acc: 69.204

Epoch 2: Validation loss decreased (0.755439 --> 0.745663).  Saving model ...
	 Train_Loss: 0.8090 Train_Acc: 66.641 Val_Loss: 0.7457  BEST VAL Loss: 0.7457  Val_Acc: 70.230

Epoch 3: Validation loss decreased (0.745663 --> 0.739426).  Saving model ...
	 Train_Loss: 0.8025 Train_Acc: 66.444 Val_Loss: 0.7394  BEST VAL Loss: 0.7394  Val_Acc: 69.842

Epoch 4: Validation loss decreased (0.739426 --> 0.733077).  Saving model ...
	 Train_Loss: 0.7957 Train_Acc: 67.389 Val_Loss: 0.7331  BEST VAL Loss: 0.7331  Val_Acc: 71.234

Epoch 5: Validation loss decreased (0.733077 --> 0.725011).  Saving model ...
	 Train_Loss: 0.7910 Train_Acc: 67.368 Val_Loss: 0.7250  BEST VAL Loss: 0.7250  Val_Acc: 71.637

Epoch 6: Validation loss decreased (0.725011 --> 0.719011).  Saving model ...
	 Train_Loss: 0.7856 Train_Acc: 67.915 Val_Loss: 0.7190  BEST VAL Loss: 0.7190  Val_Acc: 72.291

Epoch 7: Validation loss decreased (0.719011 --> 0.713477).  Saving model ...
	 Train_Loss: 0.7825 Train_Acc: 67.355 Val_Loss: 0.7135  BEST VAL Loss: 0.7135  Val_Acc: 72.059

Epoch 8: Validation loss decreased (0.713477 --> 0.710018).  Saving model ...
	 Train_Loss: 0.7782 Train_Acc: 68.216 Val_Loss: 0.7100  BEST VAL Loss: 0.7100  Val_Acc: 72.045

Epoch 9: Validation loss decreased (0.710018 --> 0.706323).  Saving model ...
	 Train_Loss: 0.7747 Train_Acc: 68.307 Val_Loss: 0.7063  BEST VAL Loss: 0.7063  Val_Acc: 72.681

Epoch 10: Validation loss decreased (0.706323 --> 0.702891).  Saving model ...
	 Train_Loss: 0.7719 Train_Acc: 68.609 Val_Loss: 0.7029  BEST VAL Loss: 0.7029  Val_Acc: 72.882

Epoch 11: Validation loss decreased (0.702891 --> 0.699124).  Saving model ...
	 Train_Loss: 0.7689 Train_Acc: 68.570 Val_Loss: 0.6991  BEST VAL Loss: 0.6991  Val_Acc: 72.513

Epoch 12: Validation loss decreased (0.699124 --> 0.697498).  Saving model ...
	 Train_Loss: 0.7671 Train_Acc: 68.826 Val_Loss: 0.6975  BEST VAL Loss: 0.6975  Val_Acc: 73.033

Epoch 13: Validation loss decreased (0.697498 --> 0.694893).  Saving model ...
	 Train_Loss: 0.7661 Train_Acc: 69.033 Val_Loss: 0.6949  BEST VAL Loss: 0.6949  Val_Acc: 73.860

Epoch 14: Validation loss decreased (0.694893 --> 0.693331).  Saving model ...
	 Train_Loss: 0.7651 Train_Acc: 69.164 Val_Loss: 0.6933  BEST VAL Loss: 0.6933  Val_Acc: 73.091

Epoch 15: Validation loss decreased (0.693331 --> 0.691835).  Saving model ...
	 Train_Loss: 0.7642 Train_Acc: 69.246 Val_Loss: 0.6918  BEST VAL Loss: 0.6918  Val_Acc: 73.576

Epoch 16: Validation loss decreased (0.691835 --> 0.689891).  Saving model ...
	 Train_Loss: 0.7633 Train_Acc: 69.263 Val_Loss: 0.6899  BEST VAL Loss: 0.6899  Val_Acc: 73.454

Epoch 17: Validation loss decreased (0.689891 --> 0.688906).  Saving model ...
	 Train_Loss: 0.7625 Train_Acc: 69.350 Val_Loss: 0.6889  BEST VAL Loss: 0.6889  Val_Acc: 72.366

Epoch 18: Validation loss decreased (0.688906 --> 0.687489).  Saving model ...
	 Train_Loss: 0.7617 Train_Acc: 69.382 Val_Loss: 0.6875  BEST VAL Loss: 0.6875  Val_Acc: 73.108

Epoch 19: Validation loss decreased (0.687489 --> 0.686682).  Saving model ...
	 Train_Loss: 0.7613 Train_Acc: 70.285 Val_Loss: 0.6867  BEST VAL Loss: 0.6867  Val_Acc: 75.461

Epoch 20: Validation loss decreased (0.686682 --> 0.686549).  Saving model ...
	 Train_Loss: 0.7608 Train_Acc: 71.182 Val_Loss: 0.6865  BEST VAL Loss: 0.6865  Val_Acc: 74.976

Epoch 21: Validation loss decreased (0.686549 --> 0.685716).  Saving model ...
	 Train_Loss: 0.7602 Train_Acc: 71.361 Val_Loss: 0.6857  BEST VAL Loss: 0.6857  Val_Acc: 75.185

Epoch 22: Validation loss did not decrease
	 Train_Loss: 0.7596 Train_Acc: 71.433 Val_Loss: 0.6858  BEST VAL Loss: 0.6857  Val_Acc: 74.864

Epoch 23: Validation loss decreased (0.685716 --> 0.685260).  Saving model ...
	 Train_Loss: 0.7590 Train_Acc: 71.581 Val_Loss: 0.6853  BEST VAL Loss: 0.6853  Val_Acc: 75.122

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.7584 Train_Acc: 71.643 Val_Loss: 0.6867  BEST VAL Loss: 0.6853  Val_Acc: 74.707

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.7578 Train_Acc: 71.634 Val_Loss: 0.6854  BEST VAL Loss: 0.6853  Val_Acc: 76.806

Epoch 26: Validation loss decreased (0.685260 --> 0.684543).  Saving model ...
	 Train_Loss: 0.7571 Train_Acc: 71.797 Val_Loss: 0.6845  BEST VAL Loss: 0.6845  Val_Acc: 74.984

Epoch 27: Validation loss decreased (0.684543 --> 0.684076).  Saving model ...
	 Train_Loss: 0.7565 Train_Acc: 71.795 Val_Loss: 0.6841  BEST VAL Loss: 0.6841  Val_Acc: 74.281

Epoch 28: Validation loss decreased (0.684076 --> 0.682526).  Saving model ...
	 Train_Loss: 0.7559 Train_Acc: 71.840 Val_Loss: 0.6825  BEST VAL Loss: 0.6825  Val_Acc: 76.824

Epoch 29: Validation loss decreased (0.682526 --> 0.681771).  Saving model ...
	 Train_Loss: 0.7553 Train_Acc: 71.907 Val_Loss: 0.6818  BEST VAL Loss: 0.6818  Val_Acc: 76.607

Epoch 30: Validation loss decreased (0.681771 --> 0.680848).  Saving model ...
	 Train_Loss: 0.7548 Train_Acc: 71.854 Val_Loss: 0.6808  BEST VAL Loss: 0.6808  Val_Acc: 76.737

Epoch 31: Validation loss decreased (0.680848 --> 0.680577).  Saving model ...
	 Train_Loss: 0.7544 Train_Acc: 71.823 Val_Loss: 0.6806  BEST VAL Loss: 0.6806  Val_Acc: 75.648

Epoch 32: Validation loss decreased (0.680577 --> 0.679618).  Saving model ...
	 Train_Loss: 0.7539 Train_Acc: 71.976 Val_Loss: 0.6796  BEST VAL Loss: 0.6796  Val_Acc: 76.681

Epoch 33: Validation loss decreased (0.679618 --> 0.678493).  Saving model ...
	 Train_Loss: 0.7534 Train_Acc: 71.983 Val_Loss: 0.6785  BEST VAL Loss: 0.6785  Val_Acc: 76.828

Epoch 34: Validation loss decreased (0.678493 --> 0.677368).  Saving model ...
	 Train_Loss: 0.7529 Train_Acc: 72.058 Val_Loss: 0.6774  BEST VAL Loss: 0.6774  Val_Acc: 77.152

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.7525 Train_Acc: 71.963 Val_Loss: 0.6776  BEST VAL Loss: 0.6774  Val_Acc: 75.666

Epoch 36: Validation loss decreased (0.677368 --> 0.676936).  Saving model ...
	 Train_Loss: 0.7520 Train_Acc: 72.090 Val_Loss: 0.6769  BEST VAL Loss: 0.6769  Val_Acc: 76.464

Epoch 37: Validation loss decreased (0.676936 --> 0.676043).  Saving model ...
	 Train_Loss: 0.7516 Train_Acc: 72.134 Val_Loss: 0.6760  BEST VAL Loss: 0.6760  Val_Acc: 77.027

Epoch 38: Validation loss decreased (0.676043 --> 0.675338).  Saving model ...
	 Train_Loss: 0.7513 Train_Acc: 70.941 Val_Loss: 0.6753  BEST VAL Loss: 0.6753  Val_Acc: 74.552

Epoch 39: Validation loss decreased (0.675338 --> 0.674647).  Saving model ...
	 Train_Loss: 0.7510 Train_Acc: 71.334 Val_Loss: 0.6746  BEST VAL Loss: 0.6746  Val_Acc: 77.146

Epoch 40: Validation loss decreased (0.674647 --> 0.673837).  Saving model ...
	 Train_Loss: 0.7505 Train_Acc: 72.146 Val_Loss: 0.6738  BEST VAL Loss: 0.6738  Val_Acc: 77.160

Epoch 41: Validation loss decreased (0.673837 --> 0.673130).  Saving model ...
	 Train_Loss: 0.7501 Train_Acc: 72.141 Val_Loss: 0.6731  BEST VAL Loss: 0.6731  Val_Acc: 77.155

Epoch 42: Validation loss decreased (0.673130 --> 0.672401).  Saving model ...
	 Train_Loss: 0.7497 Train_Acc: 72.274 Val_Loss: 0.6724  BEST VAL Loss: 0.6724  Val_Acc: 77.359

Epoch 43: Validation loss decreased (0.672401 --> 0.671956).  Saving model ...
	 Train_Loss: 0.7493 Train_Acc: 72.232 Val_Loss: 0.6720  BEST VAL Loss: 0.6720  Val_Acc: 75.619

Epoch 44: Validation loss decreased (0.671956 --> 0.671451).  Saving model ...
	 Train_Loss: 0.7489 Train_Acc: 72.321 Val_Loss: 0.6715  BEST VAL Loss: 0.6715  Val_Acc: 76.923

Epoch 45: Validation loss decreased (0.671451 --> 0.671070).  Saving model ...
	 Train_Loss: 0.7485 Train_Acc: 72.350 Val_Loss: 0.6711  BEST VAL Loss: 0.6711  Val_Acc: 76.995

Epoch 46: Validation loss decreased (0.671070 --> 0.670361).  Saving model ...
	 Train_Loss: 0.7481 Train_Acc: 72.314 Val_Loss: 0.6704  BEST VAL Loss: 0.6704  Val_Acc: 77.237

Epoch 47: Validation loss decreased (0.670361 --> 0.669909).  Saving model ...
	 Train_Loss: 0.7478 Train_Acc: 72.366 Val_Loss: 0.6699  BEST VAL Loss: 0.6699  Val_Acc: 75.967

Epoch 48: Validation loss decreased (0.669909 --> 0.669557).  Saving model ...
	 Train_Loss: 0.7474 Train_Acc: 72.421 Val_Loss: 0.6696  BEST VAL Loss: 0.6696  Val_Acc: 77.089

Epoch 49: Validation loss decreased (0.669557 --> 0.668756).  Saving model ...
	 Train_Loss: 0.7470 Train_Acc: 72.381 Val_Loss: 0.6688  BEST VAL Loss: 0.6688  Val_Acc: 77.841

Epoch 50: Validation loss decreased (0.668756 --> 0.668259).  Saving model ...
	 Train_Loss: 0.7467 Train_Acc: 72.357 Val_Loss: 0.6683  BEST VAL Loss: 0.6683  Val_Acc: 77.583

Epoch 51: Validation loss decreased (0.668259 --> 0.667881).  Saving model ...
	 Train_Loss: 0.7464 Train_Acc: 72.457 Val_Loss: 0.6679  BEST VAL Loss: 0.6679  Val_Acc: 76.637

Epoch 52: Validation loss decreased (0.667881 --> 0.667599).  Saving model ...
	 Train_Loss: 0.7460 Train_Acc: 72.445 Val_Loss: 0.6676  BEST VAL Loss: 0.6676  Val_Acc: 76.954

Epoch 53: Validation loss decreased (0.667599 --> 0.667261).  Saving model ...
	 Train_Loss: 0.7457 Train_Acc: 72.544 Val_Loss: 0.6673  BEST VAL Loss: 0.6673  Val_Acc: 77.143

Epoch 54: Validation loss decreased (0.667261 --> 0.666598).  Saving model ...
	 Train_Loss: 0.7454 Train_Acc: 72.482 Val_Loss: 0.6666  BEST VAL Loss: 0.6666  Val_Acc: 77.849

Epoch 55: Validation loss decreased (0.666598 --> 0.666271).  Saving model ...
	 Train_Loss: 0.7450 Train_Acc: 72.547 Val_Loss: 0.6663  BEST VAL Loss: 0.6663  Val_Acc: 75.791

Epoch 56: Validation loss decreased (0.666271 --> 0.665643).  Saving model ...
	 Train_Loss: 0.7447 Train_Acc: 72.524 Val_Loss: 0.6656  BEST VAL Loss: 0.6656  Val_Acc: 78.102

Epoch 57: Validation loss decreased (0.665643 --> 0.665301).  Saving model ...
	 Train_Loss: 0.7444 Train_Acc: 72.537 Val_Loss: 0.6653  BEST VAL Loss: 0.6653  Val_Acc: 77.662

Epoch 58: Validation loss decreased (0.665301 --> 0.664953).  Saving model ...
	 Train_Loss: 0.7441 Train_Acc: 72.585 Val_Loss: 0.6650  BEST VAL Loss: 0.6650  Val_Acc: 77.618

Epoch 59: Validation loss decreased (0.664953 --> 0.664435).  Saving model ...
	 Train_Loss: 0.7439 Train_Acc: 72.527 Val_Loss: 0.6644  BEST VAL Loss: 0.6644  Val_Acc: 77.993

Epoch 60: Validation loss decreased (0.664435 --> 0.663964).  Saving model ...
	 Train_Loss: 0.7436 Train_Acc: 72.537 Val_Loss: 0.6640  BEST VAL Loss: 0.6640  Val_Acc: 77.583

Epoch 61: Validation loss decreased (0.663964 --> 0.663577).  Saving model ...
	 Train_Loss: 0.7433 Train_Acc: 72.562 Val_Loss: 0.6636  BEST VAL Loss: 0.6636  Val_Acc: 77.548

Epoch 62: Validation loss decreased (0.663577 --> 0.663200).  Saving model ...
	 Train_Loss: 0.7431 Train_Acc: 72.597 Val_Loss: 0.6632  BEST VAL Loss: 0.6632  Val_Acc: 77.514

Epoch 63: Validation loss decreased (0.663200 --> 0.662908).  Saving model ...
	 Train_Loss: 0.7428 Train_Acc: 72.641 Val_Loss: 0.6629  BEST VAL Loss: 0.6629  Val_Acc: 75.645

Epoch 64: Validation loss decreased (0.662908 --> 0.662686).  Saving model ...
	 Train_Loss: 0.7425 Train_Acc: 72.679 Val_Loss: 0.6627  BEST VAL Loss: 0.6627  Val_Acc: 77.481

Epoch 65: Validation loss decreased (0.662686 --> 0.662208).  Saving model ...
	 Train_Loss: 0.7423 Train_Acc: 72.624 Val_Loss: 0.6622  BEST VAL Loss: 0.6622  Val_Acc: 77.967

Epoch 66: Validation loss decreased (0.662208 --> 0.661770).  Saving model ...
	 Train_Loss: 0.7420 Train_Acc: 72.673 Val_Loss: 0.6618  BEST VAL Loss: 0.6618  Val_Acc: 77.790

Epoch 67: Validation loss decreased (0.661770 --> 0.661372).  Saving model ...
	 Train_Loss: 0.7418 Train_Acc: 72.705 Val_Loss: 0.6614  BEST VAL Loss: 0.6614  Val_Acc: 77.855

Epoch 68: Validation loss decreased (0.661372 --> 0.661020).  Saving model ...
	 Train_Loss: 0.7415 Train_Acc: 72.586 Val_Loss: 0.6610  BEST VAL Loss: 0.6610  Val_Acc: 77.748

Epoch 69: Validation loss decreased (0.661020 --> 0.660710).  Saving model ...
	 Train_Loss: 0.7413 Train_Acc: 72.694 Val_Loss: 0.6607  BEST VAL Loss: 0.6607  Val_Acc: 77.764

Epoch 70: Validation loss decreased (0.660710 --> 0.660550).  Saving model ...
	 Train_Loss: 0.7411 Train_Acc: 72.724 Val_Loss: 0.6606  BEST VAL Loss: 0.6606  Val_Acc: 77.178

Epoch 71: Validation loss decreased (0.660550 --> 0.660297).  Saving model ...
	 Train_Loss: 0.7408 Train_Acc: 72.735 Val_Loss: 0.6603  BEST VAL Loss: 0.6603  Val_Acc: 77.553

Epoch 72: Validation loss decreased (0.660297 --> 0.660053).  Saving model ...
	 Train_Loss: 0.7406 Train_Acc: 72.761 Val_Loss: 0.6601  BEST VAL Loss: 0.6601  Val_Acc: 77.330

Epoch 73: Validation loss decreased (0.660053 --> 0.659707).  Saving model ...
	 Train_Loss: 0.7404 Train_Acc: 72.810 Val_Loss: 0.6597  BEST VAL Loss: 0.6597  Val_Acc: 77.846

Epoch 74: Validation loss decreased (0.659707 --> 0.659480).  Saving model ...
	 Train_Loss: 0.7402 Train_Acc: 72.754 Val_Loss: 0.6595  BEST VAL Loss: 0.6595  Val_Acc: 77.212

Epoch 75: Validation loss decreased (0.659480 --> 0.659080).  Saving model ...
	 Train_Loss: 0.7400 Train_Acc: 72.788 Val_Loss: 0.6591  BEST VAL Loss: 0.6591  Val_Acc: 77.942

Epoch 76: Validation loss decreased (0.659080 --> 0.658735).  Saving model ...
	 Train_Loss: 0.7397 Train_Acc: 72.804 Val_Loss: 0.6587  BEST VAL Loss: 0.6587  Val_Acc: 77.724

Epoch 77: Validation loss decreased (0.658735 --> 0.658300).  Saving model ...
	 Train_Loss: 0.7395 Train_Acc: 72.757 Val_Loss: 0.6583  BEST VAL Loss: 0.6583  Val_Acc: 78.252

Epoch 78: Validation loss decreased (0.658300 --> 0.657971).  Saving model ...
	 Train_Loss: 0.7393 Train_Acc: 72.863 Val_Loss: 0.6580  BEST VAL Loss: 0.6580  Val_Acc: 77.822

Epoch 79: Validation loss decreased (0.657971 --> 0.657853).  Saving model ...
	 Train_Loss: 0.7391 Train_Acc: 72.833 Val_Loss: 0.6579  BEST VAL Loss: 0.6579  Val_Acc: 76.980

Epoch 80: Validation loss decreased (0.657853 --> 0.657494).  Saving model ...
	 Train_Loss: 0.7389 Train_Acc: 72.824 Val_Loss: 0.6575  BEST VAL Loss: 0.6575  Val_Acc: 77.936

Epoch 81: Validation loss decreased (0.657494 --> 0.657287).  Saving model ...
	 Train_Loss: 0.7387 Train_Acc: 72.807 Val_Loss: 0.6573  BEST VAL Loss: 0.6573  Val_Acc: 77.688

Epoch 82: Validation loss decreased (0.657287 --> 0.657196).  Saving model ...
	 Train_Loss: 0.7385 Train_Acc: 72.813 Val_Loss: 0.6572  BEST VAL Loss: 0.6572  Val_Acc: 77.246

Epoch 83: Validation loss decreased (0.657196 --> 0.656998).  Saving model ...
	 Train_Loss: 0.7383 Train_Acc: 72.903 Val_Loss: 0.6570  BEST VAL Loss: 0.6570  Val_Acc: 77.810

Epoch 84: Validation loss decreased (0.656998 --> 0.656631).  Saving model ...
	 Train_Loss: 0.7381 Train_Acc: 72.864 Val_Loss: 0.6566  BEST VAL Loss: 0.6566  Val_Acc: 78.196

Epoch 85: Validation loss decreased (0.656631 --> 0.656283).  Saving model ...
	 Train_Loss: 0.7380 Train_Acc: 72.814 Val_Loss: 0.6563  BEST VAL Loss: 0.6563  Val_Acc: 78.174

Epoch 86: Validation loss decreased (0.656283 --> 0.656078).  Saving model ...
	 Train_Loss: 0.7378 Train_Acc: 72.827 Val_Loss: 0.6561  BEST VAL Loss: 0.6561  Val_Acc: 78.057

Epoch 87: Validation loss decreased (0.656078 --> 0.655787).  Saving model ...
	 Train_Loss: 0.7376 Train_Acc: 72.889 Val_Loss: 0.6558  BEST VAL Loss: 0.6558  Val_Acc: 77.982

Epoch 88: Validation loss decreased (0.655787 --> 0.655479).  Saving model ...
	 Train_Loss: 0.7374 Train_Acc: 72.930 Val_Loss: 0.6555  BEST VAL Loss: 0.6555  Val_Acc: 78.083

Epoch 89: Validation loss decreased (0.655479 --> 0.655207).  Saving model ...
	 Train_Loss: 0.7373 Train_Acc: 72.911 Val_Loss: 0.6552  BEST VAL Loss: 0.6552  Val_Acc: 78.044

Epoch 90: Validation loss decreased (0.655207 --> 0.655195).  Saving model ...
	 Train_Loss: 0.7371 Train_Acc: 72.900 Val_Loss: 0.6552  BEST VAL Loss: 0.6552  Val_Acc: 75.187

Epoch 91: Validation loss decreased (0.655195 --> 0.654979).  Saving model ...
	 Train_Loss: 0.7369 Train_Acc: 72.903 Val_Loss: 0.6550  BEST VAL Loss: 0.6550  Val_Acc: 78.008

Epoch 92: Validation loss decreased (0.654979 --> 0.654726).  Saving model ...
	 Train_Loss: 0.7368 Train_Acc: 72.907 Val_Loss: 0.6547  BEST VAL Loss: 0.6547  Val_Acc: 78.285

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.7366 Train_Acc: 72.953 Val_Loss: 0.6548  BEST VAL Loss: 0.6547  Val_Acc: 74.913

Epoch 94: Validation loss decreased (0.654726 --> 0.654648).  Saving model ...
	 Train_Loss: 0.7364 Train_Acc: 72.925 Val_Loss: 0.6546  BEST VAL Loss: 0.6546  Val_Acc: 77.529

Epoch 95: Validation loss decreased (0.654648 --> 0.654385).  Saving model ...
	 Train_Loss: 0.7363 Train_Acc: 72.921 Val_Loss: 0.6544  BEST VAL Loss: 0.6544  Val_Acc: 78.069

Epoch 96: Validation loss decreased (0.654385 --> 0.654352).  Saving model ...
	 Train_Loss: 0.7361 Train_Acc: 72.946 Val_Loss: 0.6544  BEST VAL Loss: 0.6544  Val_Acc: 76.766

Epoch 97: Validation loss decreased (0.654352 --> 0.654225).  Saving model ...
	 Train_Loss: 0.7359 Train_Acc: 72.946 Val_Loss: 0.6542  BEST VAL Loss: 0.6542  Val_Acc: 77.832

Epoch 98: Validation loss decreased (0.654225 --> 0.654051).  Saving model ...
	 Train_Loss: 0.7358 Train_Acc: 72.963 Val_Loss: 0.6541  BEST VAL Loss: 0.6541  Val_Acc: 77.944

Epoch 99: Validation loss decreased (0.654051 --> 0.653892).  Saving model ...
	 Train_Loss: 0.7356 Train_Acc: 73.034 Val_Loss: 0.6539  BEST VAL Loss: 0.6539  Val_Acc: 77.961

MultiClass_MLP
              precision    recall  f1-score   support

           0       0.82      0.24      0.37     95928
           1       0.77      0.90      0.83    749319
           2       0.82      0.74      0.78    638227

    accuracy                           0.79   1483474
   macro avg       0.80      0.63      0.66   1483474
weighted avg       0.79      0.79      0.78   1483474

MultiClass_MLP
              precision    recall  f1-score   support

           0       0.80      0.23      0.36     23982
           1       0.76      0.89      0.82    187329
           2       0.81      0.74      0.77    159558

    accuracy                           0.78    370869
   macro avg       0.79      0.62      0.65    370869
weighted avg       0.78      0.78      0.77    370869

MultiClass_MLP
              precision    recall  f1-score   support

           0       0.73      0.23      0.35    119911
           1       0.70      0.89      0.78    936644
           2       0.86      0.73      0.79   1150941

    accuracy                           0.77   2207496
   macro avg       0.76      0.62      0.64   2207496
weighted avg       0.78      0.77      0.76   2207496

Precision for class 0: 0.7339796516273371
Recall for class 0: 0.22982045016720734
Precision for class 1: 0.7000933648646714
Recall for class 1: 0.8878293140189869
Precision for class 2: 0.8584983561356512
Recall for class 2: 0.7325857711211956
3
              precision    recall  f1-score   support

           0       0.73      0.23      0.35    119911
           1       0.70      0.89      0.78    936644
           2       0.86      0.73      0.79   1150941

    accuracy                           0.77   2207496
   macro avg       0.76      0.62      0.64   2207496
weighted avg       0.78      0.77      0.76   2207496

MultiClass_MLP
              precision    recall  f1-score   support

           0       0.63      0.17      0.27     75619
           1       0.75      0.80      0.77    788818
           2       0.71      0.72      0.71    672406

    accuracy                           0.73   1536843
   macro avg       0.70      0.56      0.58   1536843
weighted avg       0.73      0.73      0.72   1536843

Precision for class 0: 0.6258957494846373
Recall for class 0: 0.1686348668985308
Precision for class 1: 0.7506663810747776
Recall for class 1: 0.7997155237329777
Precision for class 2: 0.7122638509471106
Recall for class 2: 0.71618635169823
3
              precision    recall  f1-score   support

           0       0.63      0.17      0.27     75619
           1       0.75      0.80      0.77    788818
           2       0.71      0.72      0.71    672406

    accuracy                           0.73   1536843
   macro avg       0.70      0.56      0.58   1536843
weighted avg       0.73      0.73      0.72   1536843

Done
