[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ea7d4080'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '6e1262c5'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'bae8860a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '74357505'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_Nigericin_1.000_1.0_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (261928, 1270)
Number of total missing values across all columns: 191830
Data Subset Is Off
Wells held out for testing: ['K08' 'L10']
Wells to use for training, validation, and testing ['K02' 'K03' 'K09' 'L05' 'L11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.169095).  Saving model ...
	 Train_Loss: 0.3186 Train_Acc: 87.653 Val_Loss: 0.1691  BEST VAL Loss: 0.1691  Val_Acc: 93.617

Epoch 1: Validation loss decreased (0.169095 --> 0.159643).  Saving model ...
	 Train_Loss: 0.2599 Train_Acc: 91.817 Val_Loss: 0.1596  BEST VAL Loss: 0.1596  Val_Acc: 93.978

Epoch 2: Validation loss decreased (0.159643 --> 0.148951).  Saving model ...
	 Train_Loss: 0.2328 Train_Acc: 92.852 Val_Loss: 0.1490  BEST VAL Loss: 0.1490  Val_Acc: 95.235

Epoch 3: Validation loss decreased (0.148951 --> 0.145335).  Saving model ...
	 Train_Loss: 0.2164 Train_Acc: 93.297 Val_Loss: 0.1453  BEST VAL Loss: 0.1453  Val_Acc: 94.789

Epoch 4: Validation loss decreased (0.145335 --> 0.139589).  Saving model ...
	 Train_Loss: 0.2050 Train_Acc: 93.472 Val_Loss: 0.1396  BEST VAL Loss: 0.1396  Val_Acc: 95.490

Epoch 5: Validation loss decreased (0.139589 --> 0.133592).  Saving model ...
	 Train_Loss: 0.1961 Train_Acc: 93.780 Val_Loss: 0.1336  BEST VAL Loss: 0.1336  Val_Acc: 96.105

Epoch 6: Validation loss decreased (0.133592 --> 0.129308).  Saving model ...
	 Train_Loss: 0.1892 Train_Acc: 93.946 Val_Loss: 0.1293  BEST VAL Loss: 0.1293  Val_Acc: 96.089

Epoch 7: Validation loss decreased (0.129308 --> 0.126948).  Saving model ...
	 Train_Loss: 0.1834 Train_Acc: 94.133 Val_Loss: 0.1269  BEST VAL Loss: 0.1269  Val_Acc: 95.660

Epoch 8: Validation loss did not decrease
	 Train_Loss: 0.1787 Train_Acc: 94.196 Val_Loss: 0.1275  BEST VAL Loss: 0.1269  Val_Acc: 95.102

Epoch 9: Validation loss decreased (0.126948 --> 0.125790).  Saving model ...
	 Train_Loss: 0.1746 Train_Acc: 94.357 Val_Loss: 0.1258  BEST VAL Loss: 0.1258  Val_Acc: 95.702

Epoch 10: Validation loss decreased (0.125790 --> 0.123382).  Saving model ...
	 Train_Loss: 0.1711 Train_Acc: 94.419 Val_Loss: 0.1234  BEST VAL Loss: 0.1234  Val_Acc: 96.254

Epoch 11: Validation loss decreased (0.123382 --> 0.120987).  Saving model ...
	 Train_Loss: 0.1680 Train_Acc: 94.469 Val_Loss: 0.1210  BEST VAL Loss: 0.1210  Val_Acc: 96.455

Epoch 12: Validation loss decreased (0.120987 --> 0.119727).  Saving model ...
	 Train_Loss: 0.1652 Train_Acc: 94.533 Val_Loss: 0.1197  BEST VAL Loss: 0.1197  Val_Acc: 95.925

Epoch 13: Validation loss decreased (0.119727 --> 0.118415).  Saving model ...
	 Train_Loss: 0.1628 Train_Acc: 94.601 Val_Loss: 0.1184  BEST VAL Loss: 0.1184  Val_Acc: 96.180

Epoch 14: Validation loss decreased (0.118415 --> 0.116501).  Saving model ...
	 Train_Loss: 0.1606 Train_Acc: 94.534 Val_Loss: 0.1165  BEST VAL Loss: 0.1165  Val_Acc: 96.593

Epoch 15: Validation loss decreased (0.116501 --> 0.115422).  Saving model ...
	 Train_Loss: 0.1586 Train_Acc: 94.676 Val_Loss: 0.1154  BEST VAL Loss: 0.1154  Val_Acc: 96.010

Epoch 16: Validation loss decreased (0.115422 --> 0.113960).  Saving model ...
	 Train_Loss: 0.1566 Train_Acc: 94.772 Val_Loss: 0.1140  BEST VAL Loss: 0.1140  Val_Acc: 96.519

Epoch 17: Validation loss decreased (0.113960 --> 0.112593).  Saving model ...
	 Train_Loss: 0.1549 Train_Acc: 94.768 Val_Loss: 0.1126  BEST VAL Loss: 0.1126  Val_Acc: 96.588

Epoch 18: Validation loss decreased (0.112593 --> 0.111480).  Saving model ...
	 Train_Loss: 0.1533 Train_Acc: 94.768 Val_Loss: 0.1115  BEST VAL Loss: 0.1115  Val_Acc: 96.450

Epoch 19: Validation loss decreased (0.111480 --> 0.110264).  Saving model ...
	 Train_Loss: 0.1518 Train_Acc: 94.812 Val_Loss: 0.1103  BEST VAL Loss: 0.1103  Val_Acc: 96.710

Epoch 20: Validation loss decreased (0.110264 --> 0.109477).  Saving model ...
	 Train_Loss: 0.1504 Train_Acc: 94.825 Val_Loss: 0.1095  BEST VAL Loss: 0.1095  Val_Acc: 96.397

Epoch 21: Validation loss decreased (0.109477 --> 0.108742).  Saving model ...
	 Train_Loss: 0.1491 Train_Acc: 94.913 Val_Loss: 0.1087  BEST VAL Loss: 0.1087  Val_Acc: 96.471

Epoch 22: Validation loss decreased (0.108742 --> 0.108041).  Saving model ...
	 Train_Loss: 0.1478 Train_Acc: 94.941 Val_Loss: 0.1080  BEST VAL Loss: 0.1080  Val_Acc: 96.562

Epoch 23: Validation loss decreased (0.108041 --> 0.107341).  Saving model ...
	 Train_Loss: 0.1467 Train_Acc: 94.873 Val_Loss: 0.1073  BEST VAL Loss: 0.1073  Val_Acc: 96.445

Epoch 24: Validation loss decreased (0.107341 --> 0.106549).  Saving model ...
	 Train_Loss: 0.1456 Train_Acc: 94.961 Val_Loss: 0.1065  BEST VAL Loss: 0.1065  Val_Acc: 96.684

Epoch 25: Validation loss decreased (0.106549 --> 0.105975).  Saving model ...
	 Train_Loss: 0.1446 Train_Acc: 95.021 Val_Loss: 0.1060  BEST VAL Loss: 0.1060  Val_Acc: 96.535

Epoch 26: Validation loss decreased (0.105975 --> 0.105340).  Saving model ...
	 Train_Loss: 0.1436 Train_Acc: 95.023 Val_Loss: 0.1053  BEST VAL Loss: 0.1053  Val_Acc: 96.684

Epoch 27: Validation loss decreased (0.105340 --> 0.104496).  Saving model ...
	 Train_Loss: 0.1427 Train_Acc: 94.974 Val_Loss: 0.1045  BEST VAL Loss: 0.1045  Val_Acc: 96.912

Epoch 28: Validation loss decreased (0.104496 --> 0.103861).  Saving model ...
	 Train_Loss: 0.1418 Train_Acc: 95.068 Val_Loss: 0.1039  BEST VAL Loss: 0.1039  Val_Acc: 96.572

Epoch 29: Validation loss decreased (0.103861 --> 0.103259).  Saving model ...
	 Train_Loss: 0.1409 Train_Acc: 95.080 Val_Loss: 0.1033  BEST VAL Loss: 0.1033  Val_Acc: 96.668

Epoch 30: Validation loss decreased (0.103259 --> 0.102607).  Saving model ...
	 Train_Loss: 0.1401 Train_Acc: 95.099 Val_Loss: 0.1026  BEST VAL Loss: 0.1026  Val_Acc: 96.816

Epoch 31: Validation loss decreased (0.102607 --> 0.101995).  Saving model ...
	 Train_Loss: 0.1393 Train_Acc: 95.077 Val_Loss: 0.1020  BEST VAL Loss: 0.1020  Val_Acc: 96.838

Epoch 32: Validation loss decreased (0.101995 --> 0.101421).  Saving model ...
	 Train_Loss: 0.1386 Train_Acc: 95.077 Val_Loss: 0.1014  BEST VAL Loss: 0.1014  Val_Acc: 96.832

Epoch 33: Validation loss decreased (0.101421 --> 0.101279).  Saving model ...
	 Train_Loss: 0.1379 Train_Acc: 95.081 Val_Loss: 0.1013  BEST VAL Loss: 0.1013  Val_Acc: 96.477

Epoch 34: Validation loss decreased (0.101279 --> 0.100742).  Saving model ...
	 Train_Loss: 0.1372 Train_Acc: 95.159 Val_Loss: 0.1007  BEST VAL Loss: 0.1007  Val_Acc: 96.901

Epoch 35: Validation loss decreased (0.100742 --> 0.100463).  Saving model ...
	 Train_Loss: 0.1365 Train_Acc: 95.166 Val_Loss: 0.1005  BEST VAL Loss: 0.1005  Val_Acc: 96.599

Epoch 36: Validation loss decreased (0.100463 --> 0.099941).  Saving model ...
	 Train_Loss: 0.1359 Train_Acc: 95.236 Val_Loss: 0.0999  BEST VAL Loss: 0.0999  Val_Acc: 96.800

Epoch 37: Validation loss decreased (0.099941 --> 0.099599).  Saving model ...
	 Train_Loss: 0.1353 Train_Acc: 95.208 Val_Loss: 0.0996  BEST VAL Loss: 0.0996  Val_Acc: 96.737

Epoch 38: Validation loss decreased (0.099599 --> 0.099242).  Saving model ...
	 Train_Loss: 0.1347 Train_Acc: 95.248 Val_Loss: 0.0992  BEST VAL Loss: 0.0992  Val_Acc: 96.572

Epoch 39: Validation loss decreased (0.099242 --> 0.098857).  Saving model ...
	 Train_Loss: 0.1341 Train_Acc: 95.223 Val_Loss: 0.0989  BEST VAL Loss: 0.0989  Val_Acc: 96.737

Epoch 40: Validation loss decreased (0.098857 --> 0.098427).  Saving model ...
	 Train_Loss: 0.1335 Train_Acc: 95.312 Val_Loss: 0.0984  BEST VAL Loss: 0.0984  Val_Acc: 96.965

Epoch 41: Validation loss decreased (0.098427 --> 0.098003).  Saving model ...
	 Train_Loss: 0.1330 Train_Acc: 95.243 Val_Loss: 0.0980  BEST VAL Loss: 0.0980  Val_Acc: 97.044

Epoch 42: Validation loss decreased (0.098003 --> 0.097802).  Saving model ...
	 Train_Loss: 0.1324 Train_Acc: 95.194 Val_Loss: 0.0978  BEST VAL Loss: 0.0978  Val_Acc: 96.694

Epoch 43: Validation loss decreased (0.097802 --> 0.097455).  Saving model ...
	 Train_Loss: 0.1320 Train_Acc: 95.257 Val_Loss: 0.0975  BEST VAL Loss: 0.0975  Val_Acc: 96.726

Epoch 44: Validation loss decreased (0.097455 --> 0.097127).  Saving model ...
	 Train_Loss: 0.1315 Train_Acc: 95.226 Val_Loss: 0.0971  BEST VAL Loss: 0.0971  Val_Acc: 96.864

Epoch 45: Validation loss decreased (0.097127 --> 0.096806).  Saving model ...
	 Train_Loss: 0.1310 Train_Acc: 95.235 Val_Loss: 0.0968  BEST VAL Loss: 0.0968  Val_Acc: 96.832

Epoch 46: Validation loss decreased (0.096806 --> 0.096437).  Saving model ...
	 Train_Loss: 0.1306 Train_Acc: 95.304 Val_Loss: 0.0964  BEST VAL Loss: 0.0964  Val_Acc: 96.970

Epoch 47: Validation loss decreased (0.096437 --> 0.096183).  Saving model ...
	 Train_Loss: 0.1301 Train_Acc: 95.344 Val_Loss: 0.0962  BEST VAL Loss: 0.0962  Val_Acc: 96.880

Epoch 48: Validation loss decreased (0.096183 --> 0.095853).  Saving model ...
	 Train_Loss: 0.1297 Train_Acc: 95.399 Val_Loss: 0.0959  BEST VAL Loss: 0.0959  Val_Acc: 96.960

Epoch 49: Validation loss decreased (0.095853 --> 0.095531).  Saving model ...
	 Train_Loss: 0.1293 Train_Acc: 95.410 Val_Loss: 0.0955  BEST VAL Loss: 0.0955  Val_Acc: 96.938

Epoch 50: Validation loss decreased (0.095531 --> 0.095279).  Saving model ...
	 Train_Loss: 0.1289 Train_Acc: 95.339 Val_Loss: 0.0953  BEST VAL Loss: 0.0953  Val_Acc: 96.880

Epoch 51: Validation loss decreased (0.095279 --> 0.094962).  Saving model ...
	 Train_Loss: 0.1284 Train_Acc: 95.336 Val_Loss: 0.0950  BEST VAL Loss: 0.0950  Val_Acc: 97.087

Epoch 52: Validation loss decreased (0.094962 --> 0.094837).  Saving model ...
	 Train_Loss: 0.1281 Train_Acc: 95.390 Val_Loss: 0.0948  BEST VAL Loss: 0.0948  Val_Acc: 96.588

Epoch 53: Validation loss decreased (0.094837 --> 0.094608).  Saving model ...
	 Train_Loss: 0.1277 Train_Acc: 95.410 Val_Loss: 0.0946  BEST VAL Loss: 0.0946  Val_Acc: 96.848

Epoch 54: Validation loss decreased (0.094608 --> 0.094396).  Saving model ...
	 Train_Loss: 0.1273 Train_Acc: 95.491 Val_Loss: 0.0944  BEST VAL Loss: 0.0944  Val_Acc: 96.843

Epoch 55: Validation loss decreased (0.094396 --> 0.094166).  Saving model ...
	 Train_Loss: 0.1270 Train_Acc: 95.438 Val_Loss: 0.0942  BEST VAL Loss: 0.0942  Val_Acc: 96.928

Epoch 56: Validation loss decreased (0.094166 --> 0.093984).  Saving model ...
	 Train_Loss: 0.1266 Train_Acc: 95.413 Val_Loss: 0.0940  BEST VAL Loss: 0.0940  Val_Acc: 96.901

Epoch 57: Validation loss decreased (0.093984 --> 0.093762).  Saving model ...
	 Train_Loss: 0.1262 Train_Acc: 95.441 Val_Loss: 0.0938  BEST VAL Loss: 0.0938  Val_Acc: 96.901

Epoch 58: Validation loss decreased (0.093762 --> 0.093526).  Saving model ...
	 Train_Loss: 0.1259 Train_Acc: 95.478 Val_Loss: 0.0935  BEST VAL Loss: 0.0935  Val_Acc: 96.970

Epoch 59: Validation loss decreased (0.093526 --> 0.093349).  Saving model ...
	 Train_Loss: 0.1255 Train_Acc: 95.405 Val_Loss: 0.0933  BEST VAL Loss: 0.0933  Val_Acc: 96.827

Epoch 60: Validation loss decreased (0.093349 --> 0.093107).  Saving model ...
	 Train_Loss: 0.1252 Train_Acc: 95.418 Val_Loss: 0.0931  BEST VAL Loss: 0.0931  Val_Acc: 97.002

Epoch 61: Validation loss decreased (0.093107 --> 0.092901).  Saving model ...
	 Train_Loss: 0.1249 Train_Acc: 95.458 Val_Loss: 0.0929  BEST VAL Loss: 0.0929  Val_Acc: 96.859

Epoch 62: Validation loss decreased (0.092901 --> 0.092717).  Saving model ...
	 Train_Loss: 0.1246 Train_Acc: 95.476 Val_Loss: 0.0927  BEST VAL Loss: 0.0927  Val_Acc: 96.954

Epoch 63: Validation loss decreased (0.092717 --> 0.092513).  Saving model ...
	 Train_Loss: 0.1243 Train_Acc: 95.455 Val_Loss: 0.0925  BEST VAL Loss: 0.0925  Val_Acc: 97.071

Epoch 64: Validation loss decreased (0.092513 --> 0.092282).  Saving model ...
	 Train_Loss: 0.1240 Train_Acc: 95.469 Val_Loss: 0.0923  BEST VAL Loss: 0.0923  Val_Acc: 97.002

Epoch 65: Validation loss decreased (0.092282 --> 0.092145).  Saving model ...
	 Train_Loss: 0.1237 Train_Acc: 95.476 Val_Loss: 0.0921  BEST VAL Loss: 0.0921  Val_Acc: 96.965

Epoch 66: Validation loss decreased (0.092145 --> 0.091989).  Saving model ...
	 Train_Loss: 0.1234 Train_Acc: 95.431 Val_Loss: 0.0920  BEST VAL Loss: 0.0920  Val_Acc: 96.933

Epoch 67: Validation loss decreased (0.091989 --> 0.091799).  Saving model ...
	 Train_Loss: 0.1231 Train_Acc: 95.507 Val_Loss: 0.0918  BEST VAL Loss: 0.0918  Val_Acc: 96.827

Epoch 68: Validation loss decreased (0.091799 --> 0.091657).  Saving model ...
	 Train_Loss: 0.1228 Train_Acc: 95.521 Val_Loss: 0.0917  BEST VAL Loss: 0.0917  Val_Acc: 97.002

Epoch 69: Validation loss decreased (0.091657 --> 0.091573).  Saving model ...
	 Train_Loss: 0.1226 Train_Acc: 95.455 Val_Loss: 0.0916  BEST VAL Loss: 0.0916  Val_Acc: 96.715

Epoch 70: Validation loss decreased (0.091573 --> 0.091425).  Saving model ...
	 Train_Loss: 0.1223 Train_Acc: 95.603 Val_Loss: 0.0914  BEST VAL Loss: 0.0914  Val_Acc: 96.997

Epoch 71: Validation loss decreased (0.091425 --> 0.091271).  Saving model ...
	 Train_Loss: 0.1220 Train_Acc: 95.546 Val_Loss: 0.0913  BEST VAL Loss: 0.0913  Val_Acc: 96.917

Epoch 72: Validation loss decreased (0.091271 --> 0.091109).  Saving model ...
	 Train_Loss: 0.1218 Train_Acc: 95.553 Val_Loss: 0.0911  BEST VAL Loss: 0.0911  Val_Acc: 96.975

Epoch 73: Validation loss decreased (0.091109 --> 0.090941).  Saving model ...
	 Train_Loss: 0.1215 Train_Acc: 95.497 Val_Loss: 0.0909  BEST VAL Loss: 0.0909  Val_Acc: 97.023

Epoch 74: Validation loss decreased (0.090941 --> 0.090827).  Saving model ...
	 Train_Loss: 0.1212 Train_Acc: 95.656 Val_Loss: 0.0908  BEST VAL Loss: 0.0908  Val_Acc: 96.944

Epoch 75: Validation loss decreased (0.090827 --> 0.090699).  Saving model ...
	 Train_Loss: 0.1210 Train_Acc: 95.604 Val_Loss: 0.0907  BEST VAL Loss: 0.0907  Val_Acc: 96.933

Epoch 76: Validation loss decreased (0.090699 --> 0.090598).  Saving model ...
	 Train_Loss: 0.1208 Train_Acc: 95.469 Val_Loss: 0.0906  BEST VAL Loss: 0.0906  Val_Acc: 97.039

Epoch 77: Validation loss decreased (0.090598 --> 0.090520).  Saving model ...
	 Train_Loss: 0.1205 Train_Acc: 95.611 Val_Loss: 0.0905  BEST VAL Loss: 0.0905  Val_Acc: 96.827

Epoch 78: Validation loss decreased (0.090520 --> 0.090409).  Saving model ...
	 Train_Loss: 0.1203 Train_Acc: 95.576 Val_Loss: 0.0904  BEST VAL Loss: 0.0904  Val_Acc: 96.938

Epoch 79: Validation loss decreased (0.090409 --> 0.090318).  Saving model ...
	 Train_Loss: 0.1200 Train_Acc: 95.600 Val_Loss: 0.0903  BEST VAL Loss: 0.0903  Val_Acc: 96.949

Epoch 80: Validation loss decreased (0.090318 --> 0.090203).  Saving model ...
	 Train_Loss: 0.1198 Train_Acc: 95.580 Val_Loss: 0.0902  BEST VAL Loss: 0.0902  Val_Acc: 96.912

Epoch 81: Validation loss decreased (0.090203 --> 0.090067).  Saving model ...
	 Train_Loss: 0.1196 Train_Acc: 95.556 Val_Loss: 0.0901  BEST VAL Loss: 0.0901  Val_Acc: 97.055

Epoch 82: Validation loss decreased (0.090067 --> 0.089973).  Saving model ...
	 Train_Loss: 0.1194 Train_Acc: 95.688 Val_Loss: 0.0900  BEST VAL Loss: 0.0900  Val_Acc: 97.092

Epoch 83: Validation loss decreased (0.089973 --> 0.089861).  Saving model ...
	 Train_Loss: 0.1192 Train_Acc: 95.596 Val_Loss: 0.0899  BEST VAL Loss: 0.0899  Val_Acc: 97.071

Epoch 84: Validation loss decreased (0.089861 --> 0.089792).  Saving model ...
	 Train_Loss: 0.1190 Train_Acc: 95.681 Val_Loss: 0.0898  BEST VAL Loss: 0.0898  Val_Acc: 96.949

Epoch 85: Validation loss decreased (0.089792 --> 0.089755).  Saving model ...
	 Train_Loss: 0.1187 Train_Acc: 95.651 Val_Loss: 0.0898  BEST VAL Loss: 0.0898  Val_Acc: 96.891

Epoch 86: Validation loss decreased (0.089755 --> 0.089655).  Saving model ...
	 Train_Loss: 0.1186 Train_Acc: 95.565 Val_Loss: 0.0897  BEST VAL Loss: 0.0897  Val_Acc: 96.949

Epoch 87: Validation loss decreased (0.089655 --> 0.089592).  Saving model ...
	 Train_Loss: 0.1183 Train_Acc: 95.630 Val_Loss: 0.0896  BEST VAL Loss: 0.0896  Val_Acc: 96.944

Epoch 88: Validation loss decreased (0.089592 --> 0.089508).  Saving model ...
	 Train_Loss: 0.1181 Train_Acc: 95.636 Val_Loss: 0.0895  BEST VAL Loss: 0.0895  Val_Acc: 97.066

Epoch 89: Validation loss decreased (0.089508 --> 0.089407).  Saving model ...
	 Train_Loss: 0.1180 Train_Acc: 95.591 Val_Loss: 0.0894  BEST VAL Loss: 0.0894  Val_Acc: 96.928

Epoch 90: Validation loss decreased (0.089407 --> 0.089319).  Saving model ...
	 Train_Loss: 0.1178 Train_Acc: 95.665 Val_Loss: 0.0893  BEST VAL Loss: 0.0893  Val_Acc: 97.050

Epoch 91: Validation loss decreased (0.089319 --> 0.089228).  Saving model ...
	 Train_Loss: 0.1176 Train_Acc: 95.657 Val_Loss: 0.0892  BEST VAL Loss: 0.0892  Val_Acc: 97.082

Epoch 92: Validation loss decreased (0.089228 --> 0.089114).  Saving model ...
	 Train_Loss: 0.1174 Train_Acc: 95.592 Val_Loss: 0.0891  BEST VAL Loss: 0.0891  Val_Acc: 97.082

Epoch 93: Validation loss decreased (0.089114 --> 0.089044).  Saving model ...
	 Train_Loss: 0.1172 Train_Acc: 95.667 Val_Loss: 0.0890  BEST VAL Loss: 0.0890  Val_Acc: 96.960

Epoch 94: Validation loss decreased (0.089044 --> 0.088950).  Saving model ...
	 Train_Loss: 0.1170 Train_Acc: 95.692 Val_Loss: 0.0890  BEST VAL Loss: 0.0890  Val_Acc: 97.066

Epoch 95: Validation loss decreased (0.088950 --> 0.088847).  Saving model ...
	 Train_Loss: 0.1169 Train_Acc: 95.759 Val_Loss: 0.0888  BEST VAL Loss: 0.0888  Val_Acc: 97.140

Epoch 96: Validation loss decreased (0.088847 --> 0.088765).  Saving model ...
	 Train_Loss: 0.1167 Train_Acc: 95.693 Val_Loss: 0.0888  BEST VAL Loss: 0.0888  Val_Acc: 97.098

Epoch 97: Validation loss decreased (0.088765 --> 0.088729).  Saving model ...
	 Train_Loss: 0.1165 Train_Acc: 95.740 Val_Loss: 0.0887  BEST VAL Loss: 0.0887  Val_Acc: 96.917

Epoch 98: Validation loss decreased (0.088729 --> 0.088635).  Saving model ...
	 Train_Loss: 0.1163 Train_Acc: 95.744 Val_Loss: 0.0886  BEST VAL Loss: 0.0886  Val_Acc: 97.013

Epoch 99: Validation loss decreased (0.088635 --> 0.088597).  Saving model ...
	 Train_Loss: 0.1161 Train_Acc: 95.723 Val_Loss: 0.0886  BEST VAL Loss: 0.0886  Val_Acc: 96.912

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.34      0.33      0.33     50422
           1       0.67      0.67      0.67    100339

    accuracy                           0.56    150761
   macro avg       0.50      0.50      0.50    150761
weighted avg       0.56      0.56      0.56    150761

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.34      0.33      0.34      6303
           1       0.67      0.68      0.67     12543

    accuracy                           0.56     18846
   macro avg       0.51      0.50      0.50     18846
weighted avg       0.56      0.56      0.56     18846

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.33      0.32      0.32      6303
           1       0.66      0.67      0.66     12543

    accuracy                           0.55     18846
   macro avg       0.49      0.49      0.49     18846
weighted avg       0.55      0.55      0.55     18846

              precision    recall  f1-score   support

           0       0.33      0.32      0.32      6303
           1       0.66      0.67      0.66     12543

    accuracy                           0.55     18846
   macro avg       0.49      0.49      0.49     18846
weighted avg       0.55      0.55      0.55     18846

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.45      0.43      0.44     32887
           1       0.55      0.57      0.56     40588

    accuracy                           0.51     73475
   macro avg       0.50      0.50      0.50     73475
weighted avg       0.50      0.51      0.51     73475

              precision    recall  f1-score   support

           0       0.45      0.43      0.44     32887
           1       0.55      0.57      0.56     40588

    accuracy                           0.51     73475
   macro avg       0.50      0.50      0.50     73475
weighted avg       0.50      0.51      0.51     73475

completed
