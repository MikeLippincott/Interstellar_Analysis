[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '18f561ba'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '8ce1dc78'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '7ef3b5df'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '7974ed8f'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Thapsigargin_1.000_DMSO_0.025 treatment_name: LPS_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Thapsigargin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'Thapsigargin_1.000_DMSO_0.025']
The dimensions of the data are: (287889, 1270)
Number of total missing values across all columns: 575778
Data Subset Is Off
Wells held out for testing: ['D08' 'K06']
Wells to use for training, validation, and testing ['D02' 'D03' 'D06' 'D07' 'D09' 'K07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.667741).  Saving model ...
	 Train_Loss: 0.6840 Train_Acc: 56.066 Val_Loss: 0.6677  BEST VAL Loss: 0.6677  Val_Acc: 63.973

Epoch 1: Validation loss decreased (0.667741 --> 0.644543).  Saving model ...
	 Train_Loss: 0.6687 Train_Acc: 63.227 Val_Loss: 0.6445  BEST VAL Loss: 0.6445  Val_Acc: 69.491

Epoch 2: Validation loss decreased (0.644543 --> 0.618756).  Saving model ...
	 Train_Loss: 0.6494 Train_Acc: 67.724 Val_Loss: 0.6188  BEST VAL Loss: 0.6188  Val_Acc: 72.512

Epoch 3: Validation loss decreased (0.618756 --> 0.597969).  Saving model ...
	 Train_Loss: 0.6307 Train_Acc: 70.239 Val_Loss: 0.5980  BEST VAL Loss: 0.5980  Val_Acc: 73.636

Epoch 4: Validation loss decreased (0.597969 --> 0.581552).  Saving model ...
	 Train_Loss: 0.6155 Train_Acc: 71.675 Val_Loss: 0.5816  BEST VAL Loss: 0.5816  Val_Acc: 74.594

Epoch 5: Validation loss decreased (0.581552 --> 0.568068).  Saving model ...
	 Train_Loss: 0.6029 Train_Acc: 72.728 Val_Loss: 0.5681  BEST VAL Loss: 0.5681  Val_Acc: 75.380

Epoch 6: Validation loss decreased (0.568068 --> 0.556408).  Saving model ...
	 Train_Loss: 0.5919 Train_Acc: 73.771 Val_Loss: 0.5564  BEST VAL Loss: 0.5564  Val_Acc: 76.252

Epoch 7: Validation loss decreased (0.556408 --> 0.545946).  Saving model ...
	 Train_Loss: 0.5821 Train_Acc: 74.669 Val_Loss: 0.5459  BEST VAL Loss: 0.5459  Val_Acc: 77.443

Epoch 8: Validation loss decreased (0.545946 --> 0.536470).  Saving model ...
	 Train_Loss: 0.5733 Train_Acc: 75.535 Val_Loss: 0.5365  BEST VAL Loss: 0.5365  Val_Acc: 78.277

Epoch 9: Validation loss decreased (0.536470 --> 0.527889).  Saving model ...
	 Train_Loss: 0.5654 Train_Acc: 76.037 Val_Loss: 0.5279  BEST VAL Loss: 0.5279  Val_Acc: 78.958

Epoch 10: Validation loss decreased (0.527889 --> 0.520203).  Saving model ...
	 Train_Loss: 0.5582 Train_Acc: 76.638 Val_Loss: 0.5202  BEST VAL Loss: 0.5202  Val_Acc: 79.378

Epoch 11: Validation loss decreased (0.520203 --> 0.512975).  Saving model ...
	 Train_Loss: 0.5515 Train_Acc: 77.248 Val_Loss: 0.5130  BEST VAL Loss: 0.5130  Val_Acc: 80.193

Epoch 12: Validation loss decreased (0.512975 --> 0.506446).  Saving model ...
	 Train_Loss: 0.5456 Train_Acc: 77.700 Val_Loss: 0.5064  BEST VAL Loss: 0.5064  Val_Acc: 80.450

Epoch 13: Validation loss decreased (0.506446 --> 0.500382).  Saving model ...
	 Train_Loss: 0.5400 Train_Acc: 77.985 Val_Loss: 0.5004  BEST VAL Loss: 0.5004  Val_Acc: 80.655

Epoch 14: Validation loss decreased (0.500382 --> 0.494910).  Saving model ...
	 Train_Loss: 0.5348 Train_Acc: 78.377 Val_Loss: 0.4949  BEST VAL Loss: 0.4949  Val_Acc: 81.041

Epoch 15: Validation loss decreased (0.494910 --> 0.489640).  Saving model ...
	 Train_Loss: 0.5300 Train_Acc: 78.557 Val_Loss: 0.4896  BEST VAL Loss: 0.4896  Val_Acc: 81.408

Epoch 16: Validation loss decreased (0.489640 --> 0.485027).  Saving model ...
	 Train_Loss: 0.5254 Train_Acc: 78.885 Val_Loss: 0.4850  BEST VAL Loss: 0.4850  Val_Acc: 81.155

Epoch 17: Validation loss decreased (0.485027 --> 0.480402).  Saving model ...
	 Train_Loss: 0.5211 Train_Acc: 79.300 Val_Loss: 0.4804  BEST VAL Loss: 0.4804  Val_Acc: 82.208

Epoch 18: Validation loss decreased (0.480402 --> 0.476182).  Saving model ...
	 Train_Loss: 0.5170 Train_Acc: 79.350 Val_Loss: 0.4762  BEST VAL Loss: 0.4762  Val_Acc: 81.917

Epoch 19: Validation loss decreased (0.476182 --> 0.472213).  Saving model ...
	 Train_Loss: 0.5132 Train_Acc: 79.637 Val_Loss: 0.4722  BEST VAL Loss: 0.4722  Val_Acc: 82.146

Epoch 20: Validation loss decreased (0.472213 --> 0.468233).  Saving model ...
	 Train_Loss: 0.5095 Train_Acc: 79.868 Val_Loss: 0.4682  BEST VAL Loss: 0.4682  Val_Acc: 82.746

Epoch 21: Validation loss decreased (0.468233 --> 0.464629).  Saving model ...
	 Train_Loss: 0.5060 Train_Acc: 80.055 Val_Loss: 0.4646  BEST VAL Loss: 0.4646  Val_Acc: 82.561

Epoch 22: Validation loss decreased (0.464629 --> 0.461216).  Saving model ...
	 Train_Loss: 0.5027 Train_Acc: 80.234 Val_Loss: 0.4612  BEST VAL Loss: 0.4612  Val_Acc: 82.494

Epoch 23: Validation loss decreased (0.461216 --> 0.457834).  Saving model ...
	 Train_Loss: 0.4994 Train_Acc: 80.544 Val_Loss: 0.4578  BEST VAL Loss: 0.4578  Val_Acc: 83.013

Epoch 24: Validation loss decreased (0.457834 --> 0.454595).  Saving model ...
	 Train_Loss: 0.4963 Train_Acc: 80.655 Val_Loss: 0.4546  BEST VAL Loss: 0.4546  Val_Acc: 83.175

Epoch 25: Validation loss decreased (0.454595 --> 0.451487).  Saving model ...
	 Train_Loss: 0.4932 Train_Acc: 80.995 Val_Loss: 0.4515  BEST VAL Loss: 0.4515  Val_Acc: 83.366

Epoch 26: Validation loss decreased (0.451487 --> 0.448407).  Saving model ...
	 Train_Loss: 0.4903 Train_Acc: 81.210 Val_Loss: 0.4484  BEST VAL Loss: 0.4484  Val_Acc: 83.704

Epoch 27: Validation loss decreased (0.448407 --> 0.445489).  Saving model ...
	 Train_Loss: 0.4875 Train_Acc: 81.343 Val_Loss: 0.4455  BEST VAL Loss: 0.4455  Val_Acc: 83.847

Epoch 28: Validation loss decreased (0.445489 --> 0.442766).  Saving model ...
	 Train_Loss: 0.4848 Train_Acc: 81.455 Val_Loss: 0.4428  BEST VAL Loss: 0.4428  Val_Acc: 83.680

Epoch 29: Validation loss decreased (0.442766 --> 0.439984).  Saving model ...
	 Train_Loss: 0.4822 Train_Acc: 81.666 Val_Loss: 0.4400  BEST VAL Loss: 0.4400  Val_Acc: 84.367

Epoch 30: Validation loss decreased (0.439984 --> 0.437414).  Saving model ...
	 Train_Loss: 0.4796 Train_Acc: 81.820 Val_Loss: 0.4374  BEST VAL Loss: 0.4374  Val_Acc: 84.047

Epoch 31: Validation loss decreased (0.437414 --> 0.434947).  Saving model ...
	 Train_Loss: 0.4771 Train_Acc: 81.883 Val_Loss: 0.4349  BEST VAL Loss: 0.4349  Val_Acc: 84.224

Epoch 32: Validation loss decreased (0.434947 --> 0.432483).  Saving model ...
	 Train_Loss: 0.4748 Train_Acc: 82.076 Val_Loss: 0.4325  BEST VAL Loss: 0.4325  Val_Acc: 84.490

Epoch 33: Validation loss decreased (0.432483 --> 0.430177).  Saving model ...
	 Train_Loss: 0.4725 Train_Acc: 82.196 Val_Loss: 0.4302  BEST VAL Loss: 0.4302  Val_Acc: 84.238

Epoch 34: Validation loss decreased (0.430177 --> 0.427850).  Saving model ...
	 Train_Loss: 0.4702 Train_Acc: 82.319 Val_Loss: 0.4279  BEST VAL Loss: 0.4279  Val_Acc: 84.695

Epoch 35: Validation loss decreased (0.427850 --> 0.425695).  Saving model ...
	 Train_Loss: 0.4681 Train_Acc: 82.357 Val_Loss: 0.4257  BEST VAL Loss: 0.4257  Val_Acc: 84.695

Epoch 36: Validation loss decreased (0.425695 --> 0.423520).  Saving model ...
	 Train_Loss: 0.4660 Train_Acc: 82.528 Val_Loss: 0.4235  BEST VAL Loss: 0.4235  Val_Acc: 84.819

Epoch 37: Validation loss decreased (0.423520 --> 0.421614).  Saving model ...
	 Train_Loss: 0.4640 Train_Acc: 82.553 Val_Loss: 0.4216  BEST VAL Loss: 0.4216  Val_Acc: 84.691

Epoch 38: Validation loss decreased (0.421614 --> 0.419642).  Saving model ...
	 Train_Loss: 0.4620 Train_Acc: 82.751 Val_Loss: 0.4196  BEST VAL Loss: 0.4196  Val_Acc: 85.053

Epoch 39: Validation loss decreased (0.419642 --> 0.417766).  Saving model ...
	 Train_Loss: 0.4601 Train_Acc: 82.887 Val_Loss: 0.4178  BEST VAL Loss: 0.4178  Val_Acc: 84.810

Epoch 40: Validation loss decreased (0.417766 --> 0.415815).  Saving model ...
	 Train_Loss: 0.4582 Train_Acc: 83.046 Val_Loss: 0.4158  BEST VAL Loss: 0.4158  Val_Acc: 85.219

Epoch 41: Validation loss decreased (0.415815 --> 0.413927).  Saving model ...
	 Train_Loss: 0.4564 Train_Acc: 83.067 Val_Loss: 0.4139  BEST VAL Loss: 0.4139  Val_Acc: 85.339

Epoch 42: Validation loss decreased (0.413927 --> 0.412153).  Saving model ...
	 Train_Loss: 0.4546 Train_Acc: 83.048 Val_Loss: 0.4122  BEST VAL Loss: 0.4122  Val_Acc: 85.410

Epoch 43: Validation loss decreased (0.412153 --> 0.410440).  Saving model ...
	 Train_Loss: 0.4529 Train_Acc: 83.327 Val_Loss: 0.4104  BEST VAL Loss: 0.4104  Val_Acc: 85.167

Epoch 44: Validation loss decreased (0.410440 --> 0.408805).  Saving model ...
	 Train_Loss: 0.4512 Train_Acc: 83.216 Val_Loss: 0.4088  BEST VAL Loss: 0.4088  Val_Acc: 85.310

Epoch 45: Validation loss decreased (0.408805 --> 0.407165).  Saving model ...
	 Train_Loss: 0.4496 Train_Acc: 83.375 Val_Loss: 0.4072  BEST VAL Loss: 0.4072  Val_Acc: 85.396

Epoch 46: Validation loss decreased (0.407165 --> 0.405687).  Saving model ...
	 Train_Loss: 0.4480 Train_Acc: 83.339 Val_Loss: 0.4057  BEST VAL Loss: 0.4057  Val_Acc: 85.177

Epoch 47: Validation loss decreased (0.405687 --> 0.404234).  Saving model ...
	 Train_Loss: 0.4465 Train_Acc: 83.511 Val_Loss: 0.4042  BEST VAL Loss: 0.4042  Val_Acc: 85.543

Epoch 48: Validation loss decreased (0.404234 --> 0.402832).  Saving model ...
	 Train_Loss: 0.4449 Train_Acc: 83.611 Val_Loss: 0.4028  BEST VAL Loss: 0.4028  Val_Acc: 85.367

Epoch 49: Validation loss decreased (0.402832 --> 0.401397).  Saving model ...
	 Train_Loss: 0.4435 Train_Acc: 83.509 Val_Loss: 0.4014  BEST VAL Loss: 0.4014  Val_Acc: 85.567

Epoch 50: Validation loss decreased (0.401397 --> 0.399964).  Saving model ...
	 Train_Loss: 0.4420 Train_Acc: 83.669 Val_Loss: 0.4000  BEST VAL Loss: 0.4000  Val_Acc: 85.686

Epoch 51: Validation loss decreased (0.399964 --> 0.398611).  Saving model ...
	 Train_Loss: 0.4406 Train_Acc: 83.685 Val_Loss: 0.3986  BEST VAL Loss: 0.3986  Val_Acc: 85.720

Epoch 52: Validation loss decreased (0.398611 --> 0.397289).  Saving model ...
	 Train_Loss: 0.4392 Train_Acc: 83.742 Val_Loss: 0.3973  BEST VAL Loss: 0.3973  Val_Acc: 85.782

Epoch 53: Validation loss decreased (0.397289 --> 0.396097).  Saving model ...
	 Train_Loss: 0.4378 Train_Acc: 83.900 Val_Loss: 0.3961  BEST VAL Loss: 0.3961  Val_Acc: 85.543

Epoch 54: Validation loss decreased (0.396097 --> 0.394893).  Saving model ...
	 Train_Loss: 0.4365 Train_Acc: 83.900 Val_Loss: 0.3949  BEST VAL Loss: 0.3949  Val_Acc: 85.572

Epoch 55: Validation loss decreased (0.394893 --> 0.393632).  Saving model ...
	 Train_Loss: 0.4352 Train_Acc: 83.785 Val_Loss: 0.3936  BEST VAL Loss: 0.3936  Val_Acc: 86.182

Epoch 56: Validation loss decreased (0.393632 --> 0.392578).  Saving model ...
	 Train_Loss: 0.4340 Train_Acc: 84.103 Val_Loss: 0.3926  BEST VAL Loss: 0.3926  Val_Acc: 85.658

Epoch 57: Validation loss decreased (0.392578 --> 0.391493).  Saving model ...
	 Train_Loss: 0.4327 Train_Acc: 84.111 Val_Loss: 0.3915  BEST VAL Loss: 0.3915  Val_Acc: 85.782

Epoch 58: Validation loss decreased (0.391493 --> 0.390375).  Saving model ...
	 Train_Loss: 0.4315 Train_Acc: 84.100 Val_Loss: 0.3904  BEST VAL Loss: 0.3904  Val_Acc: 85.987

Epoch 59: Validation loss decreased (0.390375 --> 0.389332).  Saving model ...
	 Train_Loss: 0.4304 Train_Acc: 84.022 Val_Loss: 0.3893  BEST VAL Loss: 0.3893  Val_Acc: 86.053

Epoch 60: Validation loss decreased (0.389332 --> 0.388207).  Saving model ...
	 Train_Loss: 0.4293 Train_Acc: 84.107 Val_Loss: 0.3882  BEST VAL Loss: 0.3882  Val_Acc: 86.153

Epoch 61: Validation loss decreased (0.388207 --> 0.387095).  Saving model ...
	 Train_Loss: 0.4282 Train_Acc: 84.126 Val_Loss: 0.3871  BEST VAL Loss: 0.3871  Val_Acc: 86.191

Epoch 62: Validation loss decreased (0.387095 --> 0.386143).  Saving model ...
	 Train_Loss: 0.4270 Train_Acc: 84.280 Val_Loss: 0.3861  BEST VAL Loss: 0.3861  Val_Acc: 85.825

Epoch 63: Validation loss decreased (0.386143 --> 0.385148).  Saving model ...
	 Train_Loss: 0.4260 Train_Acc: 84.308 Val_Loss: 0.3851  BEST VAL Loss: 0.3851  Val_Acc: 85.963

Epoch 64: Validation loss decreased (0.385148 --> 0.384215).  Saving model ...
	 Train_Loss: 0.4249 Train_Acc: 84.339 Val_Loss: 0.3842  BEST VAL Loss: 0.3842  Val_Acc: 86.177

Epoch 65: Validation loss decreased (0.384215 --> 0.383308).  Saving model ...
	 Train_Loss: 0.4238 Train_Acc: 84.397 Val_Loss: 0.3833  BEST VAL Loss: 0.3833  Val_Acc: 86.020

Epoch 66: Validation loss decreased (0.383308 --> 0.382374).  Saving model ...
	 Train_Loss: 0.4228 Train_Acc: 84.344 Val_Loss: 0.3824  BEST VAL Loss: 0.3824  Val_Acc: 86.015

Epoch 67: Validation loss decreased (0.382374 --> 0.381502).  Saving model ...
	 Train_Loss: 0.4219 Train_Acc: 84.461 Val_Loss: 0.3815  BEST VAL Loss: 0.3815  Val_Acc: 85.948

Epoch 68: Validation loss decreased (0.381502 --> 0.380627).  Saving model ...
	 Train_Loss: 0.4209 Train_Acc: 84.494 Val_Loss: 0.3806  BEST VAL Loss: 0.3806  Val_Acc: 86.044

Epoch 69: Validation loss decreased (0.380627 --> 0.379775).  Saving model ...
	 Train_Loss: 0.4199 Train_Acc: 84.440 Val_Loss: 0.3798  BEST VAL Loss: 0.3798  Val_Acc: 85.901

Epoch 70: Validation loss decreased (0.379775 --> 0.378990).  Saving model ...
	 Train_Loss: 0.4190 Train_Acc: 84.499 Val_Loss: 0.3790  BEST VAL Loss: 0.3790  Val_Acc: 85.815

Epoch 71: Validation loss decreased (0.378990 --> 0.378293).  Saving model ...
	 Train_Loss: 0.4180 Train_Acc: 84.623 Val_Loss: 0.3783  BEST VAL Loss: 0.3783  Val_Acc: 85.910

Epoch 72: Validation loss decreased (0.378293 --> 0.377498).  Saving model ...
	 Train_Loss: 0.4171 Train_Acc: 84.580 Val_Loss: 0.3775  BEST VAL Loss: 0.3775  Val_Acc: 86.087

Epoch 73: Validation loss decreased (0.377498 --> 0.376673).  Saving model ...
	 Train_Loss: 0.4162 Train_Acc: 84.666 Val_Loss: 0.3767  BEST VAL Loss: 0.3767  Val_Acc: 86.401

Epoch 74: Validation loss decreased (0.376673 --> 0.376000).  Saving model ...
	 Train_Loss: 0.4154 Train_Acc: 84.828 Val_Loss: 0.3760  BEST VAL Loss: 0.3760  Val_Acc: 85.844

Epoch 75: Validation loss decreased (0.376000 --> 0.375321).  Saving model ...
	 Train_Loss: 0.4145 Train_Acc: 84.769 Val_Loss: 0.3753  BEST VAL Loss: 0.3753  Val_Acc: 85.877

Epoch 76: Validation loss decreased (0.375321 --> 0.374573).  Saving model ...
	 Train_Loss: 0.4136 Train_Acc: 84.770 Val_Loss: 0.3746  BEST VAL Loss: 0.3746  Val_Acc: 86.115

Epoch 77: Validation loss decreased (0.374573 --> 0.373795).  Saving model ...
	 Train_Loss: 0.4128 Train_Acc: 84.736 Val_Loss: 0.3738  BEST VAL Loss: 0.3738  Val_Acc: 86.320

Epoch 78: Validation loss decreased (0.373795 --> 0.373132).  Saving model ...
	 Train_Loss: 0.4120 Train_Acc: 84.744 Val_Loss: 0.3731  BEST VAL Loss: 0.3731  Val_Acc: 86.106

Epoch 79: Validation loss decreased (0.373132 --> 0.372478).  Saving model ...
	 Train_Loss: 0.4112 Train_Acc: 84.837 Val_Loss: 0.3725  BEST VAL Loss: 0.3725  Val_Acc: 86.106

Epoch 80: Validation loss decreased (0.372478 --> 0.371807).  Saving model ...
	 Train_Loss: 0.4104 Train_Acc: 84.851 Val_Loss: 0.3718  BEST VAL Loss: 0.3718  Val_Acc: 86.292

Epoch 81: Validation loss decreased (0.371807 --> 0.371101).  Saving model ...
	 Train_Loss: 0.4096 Train_Acc: 84.953 Val_Loss: 0.3711  BEST VAL Loss: 0.3711  Val_Acc: 86.463

Epoch 82: Validation loss decreased (0.371101 --> 0.370438).  Saving model ...
	 Train_Loss: 0.4088 Train_Acc: 84.860 Val_Loss: 0.3704  BEST VAL Loss: 0.3704  Val_Acc: 86.320

Epoch 83: Validation loss decreased (0.370438 --> 0.369792).  Saving model ...
	 Train_Loss: 0.4081 Train_Acc: 84.948 Val_Loss: 0.3698  BEST VAL Loss: 0.3698  Val_Acc: 86.301

Epoch 84: Validation loss decreased (0.369792 --> 0.369095).  Saving model ...
	 Train_Loss: 0.4073 Train_Acc: 84.985 Val_Loss: 0.3691  BEST VAL Loss: 0.3691  Val_Acc: 86.444

Epoch 85: Validation loss decreased (0.369095 --> 0.368453).  Saving model ...
	 Train_Loss: 0.4066 Train_Acc: 84.992 Val_Loss: 0.3685  BEST VAL Loss: 0.3685  Val_Acc: 86.315

Epoch 86: Validation loss decreased (0.368453 --> 0.367849).  Saving model ...
	 Train_Loss: 0.4059 Train_Acc: 85.009 Val_Loss: 0.3678  BEST VAL Loss: 0.3678  Val_Acc: 86.230

Epoch 87: Validation loss decreased (0.367849 --> 0.367261).  Saving model ...
	 Train_Loss: 0.4051 Train_Acc: 85.002 Val_Loss: 0.3673  BEST VAL Loss: 0.3673  Val_Acc: 86.325

Epoch 88: Validation loss decreased (0.367261 --> 0.366658).  Saving model ...
	 Train_Loss: 0.4045 Train_Acc: 84.967 Val_Loss: 0.3667  BEST VAL Loss: 0.3667  Val_Acc: 86.458

Epoch 89: Validation loss decreased (0.366658 --> 0.366053).  Saving model ...
	 Train_Loss: 0.4038 Train_Acc: 85.082 Val_Loss: 0.3661  BEST VAL Loss: 0.3661  Val_Acc: 86.387

Epoch 90: Validation loss decreased (0.366053 --> 0.365473).  Saving model ...
	 Train_Loss: 0.4031 Train_Acc: 85.041 Val_Loss: 0.3655  BEST VAL Loss: 0.3655  Val_Acc: 86.482

Epoch 91: Validation loss decreased (0.365473 --> 0.364902).  Saving model ...
	 Train_Loss: 0.4024 Train_Acc: 85.115 Val_Loss: 0.3649  BEST VAL Loss: 0.3649  Val_Acc: 86.592

Epoch 92: Validation loss decreased (0.364902 --> 0.364358).  Saving model ...
	 Train_Loss: 0.4018 Train_Acc: 85.099 Val_Loss: 0.3644  BEST VAL Loss: 0.3644  Val_Acc: 86.444

Epoch 93: Validation loss decreased (0.364358 --> 0.363760).  Saving model ...
	 Train_Loss: 0.4011 Train_Acc: 85.184 Val_Loss: 0.3638  BEST VAL Loss: 0.3638  Val_Acc: 86.887

Epoch 94: Validation loss decreased (0.363760 --> 0.363233).  Saving model ...
	 Train_Loss: 0.4005 Train_Acc: 85.157 Val_Loss: 0.3632  BEST VAL Loss: 0.3632  Val_Acc: 86.549

Epoch 95: Validation loss decreased (0.363233 --> 0.362617).  Saving model ...
	 Train_Loss: 0.3998 Train_Acc: 85.141 Val_Loss: 0.3626  BEST VAL Loss: 0.3626  Val_Acc: 86.954

Epoch 96: Validation loss decreased (0.362617 --> 0.362145).  Saving model ...
	 Train_Loss: 0.3992 Train_Acc: 85.281 Val_Loss: 0.3621  BEST VAL Loss: 0.3621  Val_Acc: 86.482

Epoch 97: Validation loss decreased (0.362145 --> 0.361606).  Saving model ...
	 Train_Loss: 0.3986 Train_Acc: 85.150 Val_Loss: 0.3616  BEST VAL Loss: 0.3616  Val_Acc: 86.530

Epoch 98: Validation loss decreased (0.361606 --> 0.361078).  Saving model ...
	 Train_Loss: 0.3980 Train_Acc: 85.258 Val_Loss: 0.3611  BEST VAL Loss: 0.3611  Val_Acc: 86.630

Epoch 99: Validation loss decreased (0.361078 --> 0.360565).  Saving model ...
	 Train_Loss: 0.3974 Train_Acc: 85.199 Val_Loss: 0.3606  BEST VAL Loss: 0.3606  Val_Acc: 86.649

Thapsigargin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.88      0.90      0.89     79796
           1       0.90      0.89      0.90     88100

    accuracy                           0.89    167896
   macro avg       0.89      0.89      0.89    167896
weighted avg       0.89      0.89      0.89    167896

Thapsigargin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.85      0.87      0.86      9975
           1       0.88      0.86      0.87     11012

    accuracy                           0.87     20987
   macro avg       0.87      0.87      0.87     20987
weighted avg       0.87      0.87      0.87     20987

Thapsigargin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.86      0.87      0.86      9975
           1       0.88      0.87      0.87     11012

    accuracy                           0.87     20987
   macro avg       0.87      0.87      0.87     20987
weighted avg       0.87      0.87      0.87     20987

              precision    recall  f1-score   support

           0       0.86      0.87      0.86      9975
           1       0.88      0.87      0.87     11012

    accuracy                           0.87     20987
   macro avg       0.87      0.87      0.87     20987
weighted avg       0.87      0.87      0.87     20987

Thapsigargin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.74      0.34      0.46     39687
           1       0.56      0.87      0.68     38332

    accuracy                           0.60     78019
   macro avg       0.65      0.61      0.57     78019
weighted avg       0.65      0.60      0.57     78019

              precision    recall  f1-score   support

           0       0.74      0.34      0.46     39687
           1       0.56      0.87      0.68     38332

    accuracy                           0.60     78019
   macro avg       0.65      0.61      0.57     78019
weighted avg       0.65      0.60      0.57     78019

completed
