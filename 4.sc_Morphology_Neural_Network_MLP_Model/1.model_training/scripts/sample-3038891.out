[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ac3389b1'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '72495ae6'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '51dc9db6'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '697de2e7'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 treatment_name: LPS_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
TREATMENT_NAME: LPS_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (305446, 1270)
Number of total missing values across all columns: 278866
Data Subset Is Off
Wells held out for testing: ['D08' 'K08']
Wells to use for training, validation, and testing ['D02' 'D03' 'D09' 'K02' 'K03' 'K09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.357722).  Saving model ...
	 Train_Loss: 0.4591 Train_Acc: 77.901 Val_Loss: 0.3577  BEST VAL Loss: 0.3577  Val_Acc: 83.742

Epoch 1: Validation loss decreased (0.357722 --> 0.336220).  Saving model ...
	 Train_Loss: 0.4116 Train_Acc: 83.426 Val_Loss: 0.3362  BEST VAL Loss: 0.3362  Val_Acc: 86.207

Epoch 2: Validation loss decreased (0.336220 --> 0.326088).  Saving model ...
	 Train_Loss: 0.3859 Train_Acc: 85.026 Val_Loss: 0.3261  BEST VAL Loss: 0.3261  Val_Acc: 86.549

Epoch 3: Validation loss decreased (0.326088 --> 0.317081).  Saving model ...
	 Train_Loss: 0.3689 Train_Acc: 85.769 Val_Loss: 0.3171  BEST VAL Loss: 0.3171  Val_Acc: 87.210

Epoch 4: Validation loss decreased (0.317081 --> 0.311711).  Saving model ...
	 Train_Loss: 0.3565 Train_Acc: 86.323 Val_Loss: 0.3117  BEST VAL Loss: 0.3117  Val_Acc: 87.272

Epoch 5: Validation loss decreased (0.311711 --> 0.306885).  Saving model ...
	 Train_Loss: 0.3469 Train_Acc: 86.761 Val_Loss: 0.3069  BEST VAL Loss: 0.3069  Val_Acc: 87.752

Epoch 6: Validation loss decreased (0.306885 --> 0.303289).  Saving model ...
	 Train_Loss: 0.3393 Train_Acc: 86.999 Val_Loss: 0.3033  BEST VAL Loss: 0.3033  Val_Acc: 88.001

Epoch 7: Validation loss decreased (0.303289 --> 0.299733).  Saving model ...
	 Train_Loss: 0.3330 Train_Acc: 87.242 Val_Loss: 0.2997  BEST VAL Loss: 0.2997  Val_Acc: 88.352

Epoch 8: Validation loss decreased (0.299733 --> 0.296643).  Saving model ...
	 Train_Loss: 0.3277 Train_Acc: 87.552 Val_Loss: 0.2966  BEST VAL Loss: 0.2966  Val_Acc: 88.560

Epoch 9: Validation loss decreased (0.296643 --> 0.294687).  Saving model ...
	 Train_Loss: 0.3232 Train_Acc: 87.539 Val_Loss: 0.2947  BEST VAL Loss: 0.2947  Val_Acc: 88.027

Epoch 10: Validation loss decreased (0.294687 --> 0.291627).  Saving model ...
	 Train_Loss: 0.3191 Train_Acc: 87.727 Val_Loss: 0.2916  BEST VAL Loss: 0.2916  Val_Acc: 89.000

Epoch 11: Validation loss decreased (0.291627 --> 0.289201).  Saving model ...
	 Train_Loss: 0.3155 Train_Acc: 87.831 Val_Loss: 0.2892  BEST VAL Loss: 0.2892  Val_Acc: 88.987

Epoch 12: Validation loss decreased (0.289201 --> 0.286645).  Saving model ...
	 Train_Loss: 0.3122 Train_Acc: 88.034 Val_Loss: 0.2866  BEST VAL Loss: 0.2866  Val_Acc: 89.271

Epoch 13: Validation loss decreased (0.286645 --> 0.285039).  Saving model ...
	 Train_Loss: 0.3091 Train_Acc: 88.249 Val_Loss: 0.2850  BEST VAL Loss: 0.2850  Val_Acc: 88.956

Epoch 14: Validation loss decreased (0.285039 --> 0.283540).  Saving model ...
	 Train_Loss: 0.3063 Train_Acc: 88.198 Val_Loss: 0.2835  BEST VAL Loss: 0.2835  Val_Acc: 89.213

Epoch 15: Validation loss decreased (0.283540 --> 0.282200).  Saving model ...
	 Train_Loss: 0.3039 Train_Acc: 88.217 Val_Loss: 0.2822  BEST VAL Loss: 0.2822  Val_Acc: 88.800

Epoch 16: Validation loss decreased (0.282200 --> 0.280280).  Saving model ...
	 Train_Loss: 0.3017 Train_Acc: 88.257 Val_Loss: 0.2803  BEST VAL Loss: 0.2803  Val_Acc: 89.573

Epoch 17: Validation loss decreased (0.280280 --> 0.279140).  Saving model ...
	 Train_Loss: 0.2997 Train_Acc: 88.325 Val_Loss: 0.2791  BEST VAL Loss: 0.2791  Val_Acc: 89.271

Epoch 18: Validation loss decreased (0.279140 --> 0.277953).  Saving model ...
	 Train_Loss: 0.2977 Train_Acc: 88.472 Val_Loss: 0.2780  BEST VAL Loss: 0.2780  Val_Acc: 89.400

Epoch 19: Validation loss decreased (0.277953 --> 0.276229).  Saving model ...
	 Train_Loss: 0.2959 Train_Acc: 88.441 Val_Loss: 0.2762  BEST VAL Loss: 0.2762  Val_Acc: 89.759

Epoch 20: Validation loss decreased (0.276229 --> 0.275069).  Saving model ...
	 Train_Loss: 0.2941 Train_Acc: 88.681 Val_Loss: 0.2751  BEST VAL Loss: 0.2751  Val_Acc: 89.400

Epoch 21: Validation loss decreased (0.275069 --> 0.274045).  Saving model ...
	 Train_Loss: 0.2923 Train_Acc: 88.694 Val_Loss: 0.2740  BEST VAL Loss: 0.2740  Val_Acc: 89.582

Epoch 22: Validation loss decreased (0.274045 --> 0.272901).  Saving model ...
	 Train_Loss: 0.2908 Train_Acc: 88.639 Val_Loss: 0.2729  BEST VAL Loss: 0.2729  Val_Acc: 89.702

Epoch 23: Validation loss decreased (0.272901 --> 0.271895).  Saving model ...
	 Train_Loss: 0.2893 Train_Acc: 88.642 Val_Loss: 0.2719  BEST VAL Loss: 0.2719  Val_Acc: 89.480

Epoch 24: Validation loss decreased (0.271895 --> 0.271268).  Saving model ...
	 Train_Loss: 0.2880 Train_Acc: 88.714 Val_Loss: 0.2713  BEST VAL Loss: 0.2713  Val_Acc: 89.404

Epoch 25: Validation loss decreased (0.271268 --> 0.270784).  Saving model ...
	 Train_Loss: 0.2867 Train_Acc: 88.720 Val_Loss: 0.2708  BEST VAL Loss: 0.2708  Val_Acc: 89.506

Epoch 26: Validation loss decreased (0.270784 --> 0.270024).  Saving model ...
	 Train_Loss: 0.2855 Train_Acc: 88.739 Val_Loss: 0.2700  BEST VAL Loss: 0.2700  Val_Acc: 89.675

Epoch 27: Validation loss decreased (0.270024 --> 0.269194).  Saving model ...
	 Train_Loss: 0.2842 Train_Acc: 88.916 Val_Loss: 0.2692  BEST VAL Loss: 0.2692  Val_Acc: 89.817

Epoch 28: Validation loss decreased (0.269194 --> 0.269063).  Saving model ...
	 Train_Loss: 0.2831 Train_Acc: 89.004 Val_Loss: 0.2691  BEST VAL Loss: 0.2691  Val_Acc: 89.124

Epoch 29: Validation loss decreased (0.269063 --> 0.268095).  Saving model ...
	 Train_Loss: 0.2820 Train_Acc: 88.902 Val_Loss: 0.2681  BEST VAL Loss: 0.2681  Val_Acc: 90.168

Epoch 30: Validation loss decreased (0.268095 --> 0.267413).  Saving model ...
	 Train_Loss: 0.2809 Train_Acc: 88.993 Val_Loss: 0.2674  BEST VAL Loss: 0.2674  Val_Acc: 89.755

Epoch 31: Validation loss decreased (0.267413 --> 0.266745).  Saving model ...
	 Train_Loss: 0.2800 Train_Acc: 88.884 Val_Loss: 0.2667  BEST VAL Loss: 0.2667  Val_Acc: 89.835

Epoch 32: Validation loss decreased (0.266745 --> 0.266096).  Saving model ...
	 Train_Loss: 0.2790 Train_Acc: 89.037 Val_Loss: 0.2661  BEST VAL Loss: 0.2661  Val_Acc: 89.853

Epoch 33: Validation loss decreased (0.266096 --> 0.265518).  Saving model ...
	 Train_Loss: 0.2780 Train_Acc: 89.032 Val_Loss: 0.2655  BEST VAL Loss: 0.2655  Val_Acc: 89.675

Epoch 34: Validation loss decreased (0.265518 --> 0.265315).  Saving model ...
	 Train_Loss: 0.2772 Train_Acc: 89.005 Val_Loss: 0.2653  BEST VAL Loss: 0.2653  Val_Acc: 89.733

Epoch 35: Validation loss decreased (0.265315 --> 0.264956).  Saving model ...
	 Train_Loss: 0.2764 Train_Acc: 89.018 Val_Loss: 0.2650  BEST VAL Loss: 0.2650  Val_Acc: 89.697

Epoch 36: Validation loss decreased (0.264956 --> 0.264494).  Saving model ...
	 Train_Loss: 0.2756 Train_Acc: 89.078 Val_Loss: 0.2645  BEST VAL Loss: 0.2645  Val_Acc: 89.959

Epoch 37: Validation loss decreased (0.264494 --> 0.264088).  Saving model ...
	 Train_Loss: 0.2748 Train_Acc: 89.067 Val_Loss: 0.2641  BEST VAL Loss: 0.2641  Val_Acc: 89.782

Epoch 38: Validation loss decreased (0.264088 --> 0.263787).  Saving model ...
	 Train_Loss: 0.2740 Train_Acc: 89.116 Val_Loss: 0.2638  BEST VAL Loss: 0.2638  Val_Acc: 89.773

Epoch 39: Validation loss decreased (0.263787 --> 0.263510).  Saving model ...
	 Train_Loss: 0.2733 Train_Acc: 89.088 Val_Loss: 0.2635  BEST VAL Loss: 0.2635  Val_Acc: 89.835

Epoch 40: Validation loss decreased (0.263510 --> 0.263140).  Saving model ...
	 Train_Loss: 0.2726 Train_Acc: 89.081 Val_Loss: 0.2631  BEST VAL Loss: 0.2631  Val_Acc: 89.950

Epoch 41: Validation loss decreased (0.263140 --> 0.262933).  Saving model ...
	 Train_Loss: 0.2719 Train_Acc: 89.206 Val_Loss: 0.2629  BEST VAL Loss: 0.2629  Val_Acc: 89.919

Epoch 42: Validation loss decreased (0.262933 --> 0.262683).  Saving model ...
	 Train_Loss: 0.2712 Train_Acc: 89.201 Val_Loss: 0.2627  BEST VAL Loss: 0.2627  Val_Acc: 89.932

Epoch 43: Validation loss decreased (0.262683 --> 0.262570).  Saving model ...
	 Train_Loss: 0.2705 Train_Acc: 89.134 Val_Loss: 0.2626  BEST VAL Loss: 0.2626  Val_Acc: 89.591

Epoch 44: Validation loss decreased (0.262570 --> 0.262363).  Saving model ...
	 Train_Loss: 0.2699 Train_Acc: 89.255 Val_Loss: 0.2624  BEST VAL Loss: 0.2624  Val_Acc: 89.608

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.2693 Train_Acc: 89.201 Val_Loss: 0.2624  BEST VAL Loss: 0.2624  Val_Acc: 89.635

Epoch 46: Validation loss decreased (0.262363 --> 0.262131).  Saving model ...
	 Train_Loss: 0.2688 Train_Acc: 89.209 Val_Loss: 0.2621  BEST VAL Loss: 0.2621  Val_Acc: 89.733

Epoch 47: Validation loss decreased (0.262131 --> 0.261940).  Saving model ...
	 Train_Loss: 0.2682 Train_Acc: 89.278 Val_Loss: 0.2619  BEST VAL Loss: 0.2619  Val_Acc: 89.777

Epoch 48: Validation loss decreased (0.261940 --> 0.261930).  Saving model ...
	 Train_Loss: 0.2677 Train_Acc: 89.157 Val_Loss: 0.2619  BEST VAL Loss: 0.2619  Val_Acc: 89.533

Epoch 49: Validation loss decreased (0.261930 --> 0.261826).  Saving model ...
	 Train_Loss: 0.2671 Train_Acc: 89.268 Val_Loss: 0.2618  BEST VAL Loss: 0.2618  Val_Acc: 89.950

Epoch 50: Validation loss decreased (0.261826 --> 0.261635).  Saving model ...
	 Train_Loss: 0.2666 Train_Acc: 89.252 Val_Loss: 0.2616  BEST VAL Loss: 0.2616  Val_Acc: 89.879

Epoch 51: Validation loss decreased (0.261635 --> 0.261538).  Saving model ...
	 Train_Loss: 0.2661 Train_Acc: 89.276 Val_Loss: 0.2615  BEST VAL Loss: 0.2615  Val_Acc: 89.844

Epoch 52: Validation loss decreased (0.261538 --> 0.261358).  Saving model ...
	 Train_Loss: 0.2656 Train_Acc: 89.326 Val_Loss: 0.2614  BEST VAL Loss: 0.2614  Val_Acc: 90.021

Epoch 53: Validation loss decreased (0.261358 --> 0.261300).  Saving model ...
	 Train_Loss: 0.2651 Train_Acc: 89.386 Val_Loss: 0.2613  BEST VAL Loss: 0.2613  Val_Acc: 89.906

Epoch 54: Validation loss decreased (0.261300 --> 0.261278).  Saving model ...
	 Train_Loss: 0.2646 Train_Acc: 89.345 Val_Loss: 0.2613  BEST VAL Loss: 0.2613  Val_Acc: 89.715

Epoch 55: Validation loss decreased (0.261278 --> 0.261124).  Saving model ...
	 Train_Loss: 0.2642 Train_Acc: 89.326 Val_Loss: 0.2611  BEST VAL Loss: 0.2611  Val_Acc: 90.195

Epoch 56: Validation loss decreased (0.261124 --> 0.260888).  Saving model ...
	 Train_Loss: 0.2637 Train_Acc: 89.431 Val_Loss: 0.2609  BEST VAL Loss: 0.2609  Val_Acc: 90.035

Epoch 57: Validation loss decreased (0.260888 --> 0.260711).  Saving model ...
	 Train_Loss: 0.2632 Train_Acc: 89.250 Val_Loss: 0.2607  BEST VAL Loss: 0.2607  Val_Acc: 90.123

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.2628 Train_Acc: 89.415 Val_Loss: 0.2607  BEST VAL Loss: 0.2607  Val_Acc: 89.702

Epoch 59: Validation loss decreased (0.260711 --> 0.260624).  Saving model ...
	 Train_Loss: 0.2624 Train_Acc: 89.407 Val_Loss: 0.2606  BEST VAL Loss: 0.2606  Val_Acc: 89.821

Epoch 60: Validation loss decreased (0.260624 --> 0.260489).  Saving model ...
	 Train_Loss: 0.2620 Train_Acc: 89.354 Val_Loss: 0.2605  BEST VAL Loss: 0.2605  Val_Acc: 90.106

Epoch 61: Validation loss decreased (0.260489 --> 0.260293).  Saving model ...
	 Train_Loss: 0.2616 Train_Acc: 89.490 Val_Loss: 0.2603  BEST VAL Loss: 0.2603  Val_Acc: 90.039

Epoch 62: Validation loss decreased (0.260293 --> 0.260243).  Saving model ...
	 Train_Loss: 0.2612 Train_Acc: 89.430 Val_Loss: 0.2602  BEST VAL Loss: 0.2602  Val_Acc: 89.813

Epoch 63: Validation loss decreased (0.260243 --> 0.260206).  Saving model ...
	 Train_Loss: 0.2607 Train_Acc: 89.523 Val_Loss: 0.2602  BEST VAL Loss: 0.2602  Val_Acc: 90.035

Epoch 64: Validation loss decreased (0.260206 --> 0.260156).  Saving model ...
	 Train_Loss: 0.2604 Train_Acc: 89.487 Val_Loss: 0.2602  BEST VAL Loss: 0.2602  Val_Acc: 89.870

Epoch 65: Validation loss decreased (0.260156 --> 0.260043).  Saving model ...
	 Train_Loss: 0.2600 Train_Acc: 89.474 Val_Loss: 0.2600  BEST VAL Loss: 0.2600  Val_Acc: 90.052

Epoch 66: Validation loss decreased (0.260043 --> 0.259973).  Saving model ...
	 Train_Loss: 0.2596 Train_Acc: 89.320 Val_Loss: 0.2600  BEST VAL Loss: 0.2600  Val_Acc: 90.030

Epoch 67: Validation loss decreased (0.259973 --> 0.259862).  Saving model ...
	 Train_Loss: 0.2593 Train_Acc: 89.426 Val_Loss: 0.2599  BEST VAL Loss: 0.2599  Val_Acc: 89.995

Epoch 68: Validation loss decreased (0.259862 --> 0.259797).  Saving model ...
	 Train_Loss: 0.2589 Train_Acc: 89.444 Val_Loss: 0.2598  BEST VAL Loss: 0.2598  Val_Acc: 89.968

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.2586 Train_Acc: 89.481 Val_Loss: 0.2598  BEST VAL Loss: 0.2598  Val_Acc: 89.679

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.2583 Train_Acc: 89.430 Val_Loss: 0.2599  BEST VAL Loss: 0.2598  Val_Acc: 89.728

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.2580 Train_Acc: 89.454 Val_Loss: 0.2600  BEST VAL Loss: 0.2598  Val_Acc: 89.799

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.2576 Train_Acc: 89.456 Val_Loss: 0.2601  BEST VAL Loss: 0.2598  Val_Acc: 89.742

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.2573 Train_Acc: 89.492 Val_Loss: 0.2601  BEST VAL Loss: 0.2598  Val_Acc: 90.146

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.2570 Train_Acc: 89.466 Val_Loss: 0.2601  BEST VAL Loss: 0.2598  Val_Acc: 89.750

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.2567 Train_Acc: 89.535 Val_Loss: 0.2600  BEST VAL Loss: 0.2598  Val_Acc: 89.986

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.2564 Train_Acc: 89.494 Val_Loss: 0.2600  BEST VAL Loss: 0.2598  Val_Acc: 90.075

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.2561 Train_Acc: 89.697 Val_Loss: 0.2599  BEST VAL Loss: 0.2598  Val_Acc: 90.057

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.2558 Train_Acc: 89.560 Val_Loss: 0.2600  BEST VAL Loss: 0.2598  Val_Acc: 89.937

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.2555 Train_Acc: 89.502 Val_Loss: 0.2600  BEST VAL Loss: 0.2598  Val_Acc: 89.710

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.2552 Train_Acc: 89.602 Val_Loss: 0.2600  BEST VAL Loss: 0.2598  Val_Acc: 90.035

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.2549 Train_Acc: 89.656 Val_Loss: 0.2601  BEST VAL Loss: 0.2598  Val_Acc: 89.968

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.2547 Train_Acc: 89.479 Val_Loss: 0.2601  BEST VAL Loss: 0.2598  Val_Acc: 89.697

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.2544 Train_Acc: 89.555 Val_Loss: 0.2602  BEST VAL Loss: 0.2598  Val_Acc: 89.657

Epoch 84: Validation loss did not decrease
Early stopped at epoch : 84
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.88      0.90     79796
           1       0.91      0.94      0.93    100340

    accuracy                           0.92    180136
   macro avg       0.92      0.91      0.91    180136
weighted avg       0.92      0.92      0.92    180136

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.91      0.86      0.88      9975
           1       0.89      0.93      0.91     12543

    accuracy                           0.90     22518
   macro avg       0.90      0.90      0.90     22518
weighted avg       0.90      0.90      0.90     22518

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.90      0.86      0.88      9975
           1       0.89      0.93      0.91     12542

    accuracy                           0.90     22517
   macro avg       0.90      0.89      0.90     22517
weighted avg       0.90      0.90      0.90     22517

              precision    recall  f1-score   support

           0       0.90      0.86      0.88      9975
           1       0.89      0.93      0.91     12542

    accuracy                           0.90     22517
   macro avg       0.90      0.89      0.90     22517
weighted avg       0.90      0.90      0.90     22517

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.86      0.94      0.90     39687
           1       0.93      0.85      0.89     40588

    accuracy                           0.89     80275
   macro avg       0.89      0.89      0.89     80275
weighted avg       0.89      0.89      0.89     80275

              precision    recall  f1-score   support

           0       0.86      0.94      0.90     39687
           1       0.93      0.85      0.89     40588

    accuracy                           0.89     80275
   macro avg       0.89      0.89      0.89     80275
weighted avg       0.89      0.89      0.89     80275

completed
