[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '93d2faa7'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'b41e3f9f'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'a3ec91ae'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '93cdf041'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: H2O2_100.000_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (379133, 1270)
Number of total missing values across all columns: 758266
Data Subset Is Off
Wells held out for testing: ['C09' 'I10']
Wells to use for training, validation, and testing ['C02' 'C03' 'C08' 'H04' 'I04' 'H05' 'I05' 'H10' 'H11' 'I11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.462858).  Saving model ...
	 Train_Loss: 0.5551 Train_Acc: 70.088 Val_Loss: 0.4629  BEST VAL Loss: 0.4629  Val_Acc: 79.511

Epoch 1: Validation loss decreased (0.462858 --> 0.441943).  Saving model ...
	 Train_Loss: 0.5213 Train_Acc: 76.515 Val_Loss: 0.4419  BEST VAL Loss: 0.4419  Val_Acc: 81.701

Epoch 2: Validation loss decreased (0.441943 --> 0.431348).  Saving model ...
	 Train_Loss: 0.5030 Train_Acc: 78.111 Val_Loss: 0.4313  BEST VAL Loss: 0.4313  Val_Acc: 82.555

Epoch 3: Validation loss decreased (0.431348 --> 0.420873).  Saving model ...
	 Train_Loss: 0.4905 Train_Acc: 78.971 Val_Loss: 0.4209  BEST VAL Loss: 0.4209  Val_Acc: 83.737

Epoch 4: Validation loss decreased (0.420873 --> 0.411964).  Saving model ...
	 Train_Loss: 0.4817 Train_Acc: 79.528 Val_Loss: 0.4120  BEST VAL Loss: 0.4120  Val_Acc: 84.800

Epoch 5: Validation loss decreased (0.411964 --> 0.405950).  Saving model ...
	 Train_Loss: 0.4742 Train_Acc: 80.072 Val_Loss: 0.4059  BEST VAL Loss: 0.4059  Val_Acc: 84.118

Epoch 6: Validation loss did not decrease
	 Train_Loss: 0.4684 Train_Acc: 80.309 Val_Loss: 0.4066  BEST VAL Loss: 0.4059  Val_Acc: 82.911

Epoch 7: Validation loss decreased (0.405950 --> 0.401253).  Saving model ...
	 Train_Loss: 0.4635 Train_Acc: 80.592 Val_Loss: 0.4013  BEST VAL Loss: 0.4013  Val_Acc: 85.193

Epoch 8: Validation loss decreased (0.401253 --> 0.397197).  Saving model ...
	 Train_Loss: 0.4592 Train_Acc: 80.729 Val_Loss: 0.3972  BEST VAL Loss: 0.3972  Val_Acc: 85.245

Epoch 9: Validation loss decreased (0.397197 --> 0.394655).  Saving model ...
	 Train_Loss: 0.4555 Train_Acc: 80.887 Val_Loss: 0.3947  BEST VAL Loss: 0.3947  Val_Acc: 85.113

Epoch 10: Validation loss decreased (0.394655 --> 0.391571).  Saving model ...
	 Train_Loss: 0.4521 Train_Acc: 81.095 Val_Loss: 0.3916  BEST VAL Loss: 0.3916  Val_Acc: 85.206

Epoch 11: Validation loss decreased (0.391571 --> 0.391174).  Saving model ...
	 Train_Loss: 0.4491 Train_Acc: 81.284 Val_Loss: 0.3912  BEST VAL Loss: 0.3912  Val_Acc: 84.111

Epoch 12: Validation loss decreased (0.391174 --> 0.388246).  Saving model ...
	 Train_Loss: 0.4464 Train_Acc: 81.301 Val_Loss: 0.3882  BEST VAL Loss: 0.3882  Val_Acc: 85.616

Epoch 13: Validation loss decreased (0.388246 --> 0.385924).  Saving model ...
	 Train_Loss: 0.4440 Train_Acc: 81.396 Val_Loss: 0.3859  BEST VAL Loss: 0.3859  Val_Acc: 85.462

Epoch 14: Validation loss decreased (0.385924 --> 0.384912).  Saving model ...
	 Train_Loss: 0.4418 Train_Acc: 81.406 Val_Loss: 0.3849  BEST VAL Loss: 0.3849  Val_Acc: 84.822

Epoch 15: Validation loss decreased (0.384912 --> 0.383072).  Saving model ...
	 Train_Loss: 0.4398 Train_Acc: 81.514 Val_Loss: 0.3831  BEST VAL Loss: 0.3831  Val_Acc: 85.315

Epoch 16: Validation loss decreased (0.383072 --> 0.380946).  Saving model ...
	 Train_Loss: 0.4379 Train_Acc: 81.603 Val_Loss: 0.3809  BEST VAL Loss: 0.3809  Val_Acc: 86.093

Epoch 17: Validation loss decreased (0.380946 --> 0.379203).  Saving model ...
	 Train_Loss: 0.4362 Train_Acc: 81.624 Val_Loss: 0.3792  BEST VAL Loss: 0.3792  Val_Acc: 85.491

Epoch 18: Validation loss decreased (0.379203 --> 0.377590).  Saving model ...
	 Train_Loss: 0.4346 Train_Acc: 81.574 Val_Loss: 0.3776  BEST VAL Loss: 0.3776  Val_Acc: 85.872

Epoch 19: Validation loss decreased (0.377590 --> 0.375858).  Saving model ...
	 Train_Loss: 0.4331 Train_Acc: 81.581 Val_Loss: 0.3759  BEST VAL Loss: 0.3759  Val_Acc: 86.170

Epoch 20: Validation loss decreased (0.375858 --> 0.374214).  Saving model ...
	 Train_Loss: 0.4318 Train_Acc: 81.656 Val_Loss: 0.3742  BEST VAL Loss: 0.3742  Val_Acc: 86.141

Epoch 21: Validation loss decreased (0.374214 --> 0.373611).  Saving model ...
	 Train_Loss: 0.4305 Train_Acc: 81.694 Val_Loss: 0.3736  BEST VAL Loss: 0.3736  Val_Acc: 85.216

Epoch 22: Validation loss decreased (0.373611 --> 0.372581).  Saving model ...
	 Train_Loss: 0.4293 Train_Acc: 81.649 Val_Loss: 0.3726  BEST VAL Loss: 0.3726  Val_Acc: 86.019

Epoch 23: Validation loss decreased (0.372581 --> 0.371564).  Saving model ...
	 Train_Loss: 0.4282 Train_Acc: 81.665 Val_Loss: 0.3716  BEST VAL Loss: 0.3716  Val_Acc: 85.600

Epoch 24: Validation loss decreased (0.371564 --> 0.370424).  Saving model ...
	 Train_Loss: 0.4271 Train_Acc: 81.809 Val_Loss: 0.3704  BEST VAL Loss: 0.3704  Val_Acc: 85.837

Epoch 25: Validation loss decreased (0.370424 --> 0.369250).  Saving model ...
	 Train_Loss: 0.4261 Train_Acc: 81.755 Val_Loss: 0.3692  BEST VAL Loss: 0.3692  Val_Acc: 86.138

Epoch 26: Validation loss decreased (0.369250 --> 0.368052).  Saving model ...
	 Train_Loss: 0.4251 Train_Acc: 81.692 Val_Loss: 0.3681  BEST VAL Loss: 0.3681  Val_Acc: 86.247

Epoch 27: Validation loss decreased (0.368052 --> 0.367137).  Saving model ...
	 Train_Loss: 0.4241 Train_Acc: 81.738 Val_Loss: 0.3671  BEST VAL Loss: 0.3671  Val_Acc: 86.003

Epoch 28: Validation loss decreased (0.367137 --> 0.366561).  Saving model ...
	 Train_Loss: 0.4232 Train_Acc: 81.794 Val_Loss: 0.3666  BEST VAL Loss: 0.3666  Val_Acc: 85.776

Epoch 29: Validation loss decreased (0.366561 --> 0.365970).  Saving model ...
	 Train_Loss: 0.4224 Train_Acc: 81.794 Val_Loss: 0.3660  BEST VAL Loss: 0.3660  Val_Acc: 85.949

Epoch 30: Validation loss decreased (0.365970 --> 0.365193).  Saving model ...
	 Train_Loss: 0.4216 Train_Acc: 81.669 Val_Loss: 0.3652  BEST VAL Loss: 0.3652  Val_Acc: 86.167

Epoch 31: Validation loss decreased (0.365193 --> 0.364180).  Saving model ...
	 Train_Loss: 0.4208 Train_Acc: 81.776 Val_Loss: 0.3642  BEST VAL Loss: 0.3642  Val_Acc: 86.644

Epoch 32: Validation loss decreased (0.364180 --> 0.363443).  Saving model ...
	 Train_Loss: 0.4200 Train_Acc: 81.861 Val_Loss: 0.3634  BEST VAL Loss: 0.3634  Val_Acc: 86.352

Epoch 33: Validation loss decreased (0.363443 --> 0.362573).  Saving model ...
	 Train_Loss: 0.4193 Train_Acc: 81.965 Val_Loss: 0.3626  BEST VAL Loss: 0.3626  Val_Acc: 86.525

Epoch 34: Validation loss decreased (0.362573 --> 0.361708).  Saving model ...
	 Train_Loss: 0.4186 Train_Acc: 81.823 Val_Loss: 0.3617  BEST VAL Loss: 0.3617  Val_Acc: 86.608

Epoch 35: Validation loss decreased (0.361708 --> 0.361127).  Saving model ...
	 Train_Loss: 0.4180 Train_Acc: 81.906 Val_Loss: 0.3611  BEST VAL Loss: 0.3611  Val_Acc: 86.080

Epoch 36: Validation loss decreased (0.361127 --> 0.360368).  Saving model ...
	 Train_Loss: 0.4173 Train_Acc: 81.948 Val_Loss: 0.3604  BEST VAL Loss: 0.3604  Val_Acc: 86.378

Epoch 37: Validation loss decreased (0.360368 --> 0.359624).  Saving model ...
	 Train_Loss: 0.4167 Train_Acc: 82.004 Val_Loss: 0.3596  BEST VAL Loss: 0.3596  Val_Acc: 86.602

Epoch 38: Validation loss decreased (0.359624 --> 0.358983).  Saving model ...
	 Train_Loss: 0.4162 Train_Acc: 81.841 Val_Loss: 0.3590  BEST VAL Loss: 0.3590  Val_Acc: 86.445

Epoch 39: Validation loss decreased (0.358983 --> 0.358395).  Saving model ...
	 Train_Loss: 0.4156 Train_Acc: 82.079 Val_Loss: 0.3584  BEST VAL Loss: 0.3584  Val_Acc: 86.452

Epoch 40: Validation loss decreased (0.358395 --> 0.357749).  Saving model ...
	 Train_Loss: 0.4150 Train_Acc: 81.995 Val_Loss: 0.3577  BEST VAL Loss: 0.3577  Val_Acc: 86.250

Epoch 41: Validation loss decreased (0.357749 --> 0.357043).  Saving model ...
	 Train_Loss: 0.4145 Train_Acc: 81.929 Val_Loss: 0.3570  BEST VAL Loss: 0.3570  Val_Acc: 86.759

Epoch 42: Validation loss decreased (0.357043 --> 0.356724).  Saving model ...
	 Train_Loss: 0.4140 Train_Acc: 81.951 Val_Loss: 0.3567  BEST VAL Loss: 0.3567  Val_Acc: 85.632

Epoch 43: Validation loss decreased (0.356724 --> 0.356212).  Saving model ...
	 Train_Loss: 0.4135 Train_Acc: 82.039 Val_Loss: 0.3562  BEST VAL Loss: 0.3562  Val_Acc: 86.295

Epoch 44: Validation loss decreased (0.356212 --> 0.355707).  Saving model ...
	 Train_Loss: 0.4130 Train_Acc: 82.055 Val_Loss: 0.3557  BEST VAL Loss: 0.3557  Val_Acc: 86.173

Epoch 45: Validation loss decreased (0.355707 --> 0.355257).  Saving model ...
	 Train_Loss: 0.4125 Train_Acc: 82.091 Val_Loss: 0.3553  BEST VAL Loss: 0.3553  Val_Acc: 86.368

Epoch 46: Validation loss decreased (0.355257 --> 0.354919).  Saving model ...
	 Train_Loss: 0.4120 Train_Acc: 81.937 Val_Loss: 0.3549  BEST VAL Loss: 0.3549  Val_Acc: 85.978

Epoch 47: Validation loss decreased (0.354919 --> 0.354498).  Saving model ...
	 Train_Loss: 0.4116 Train_Acc: 82.032 Val_Loss: 0.3545  BEST VAL Loss: 0.3545  Val_Acc: 86.420

Epoch 48: Validation loss decreased (0.354498 --> 0.354204).  Saving model ...
	 Train_Loss: 0.4111 Train_Acc: 82.127 Val_Loss: 0.3542  BEST VAL Loss: 0.3542  Val_Acc: 86.003

Epoch 49: Validation loss decreased (0.354204 --> 0.353679).  Saving model ...
	 Train_Loss: 0.4107 Train_Acc: 82.021 Val_Loss: 0.3537  BEST VAL Loss: 0.3537  Val_Acc: 86.519

Epoch 50: Validation loss decreased (0.353679 --> 0.353299).  Saving model ...
	 Train_Loss: 0.4103 Train_Acc: 82.127 Val_Loss: 0.3533  BEST VAL Loss: 0.3533  Val_Acc: 86.487

Epoch 51: Validation loss decreased (0.353299 --> 0.352863).  Saving model ...
	 Train_Loss: 0.4099 Train_Acc: 82.012 Val_Loss: 0.3529  BEST VAL Loss: 0.3529  Val_Acc: 86.612

Epoch 52: Validation loss decreased (0.352863 --> 0.352512).  Saving model ...
	 Train_Loss: 0.4095 Train_Acc: 82.101 Val_Loss: 0.3525  BEST VAL Loss: 0.3525  Val_Acc: 86.368

Epoch 53: Validation loss decreased (0.352512 --> 0.352092).  Saving model ...
	 Train_Loss: 0.4092 Train_Acc: 82.197 Val_Loss: 0.3521  BEST VAL Loss: 0.3521  Val_Acc: 86.602

Epoch 54: Validation loss decreased (0.352092 --> 0.351898).  Saving model ...
	 Train_Loss: 0.4088 Train_Acc: 82.171 Val_Loss: 0.3519  BEST VAL Loss: 0.3519  Val_Acc: 86.093

Epoch 55: Validation loss decreased (0.351898 --> 0.351492).  Saving model ...
	 Train_Loss: 0.4084 Train_Acc: 82.107 Val_Loss: 0.3515  BEST VAL Loss: 0.3515  Val_Acc: 86.749

Epoch 56: Validation loss decreased (0.351492 --> 0.351039).  Saving model ...
	 Train_Loss: 0.4080 Train_Acc: 82.218 Val_Loss: 0.3510  BEST VAL Loss: 0.3510  Val_Acc: 86.720

Epoch 57: Validation loss decreased (0.351039 --> 0.350839).  Saving model ...
	 Train_Loss: 0.4077 Train_Acc: 81.956 Val_Loss: 0.3508  BEST VAL Loss: 0.3508  Val_Acc: 86.179

Epoch 58: Validation loss decreased (0.350839 --> 0.350576).  Saving model ...
	 Train_Loss: 0.4074 Train_Acc: 82.062 Val_Loss: 0.3506  BEST VAL Loss: 0.3506  Val_Acc: 86.115

Epoch 59: Validation loss decreased (0.350576 --> 0.350343).  Saving model ...
	 Train_Loss: 0.4070 Train_Acc: 82.276 Val_Loss: 0.3503  BEST VAL Loss: 0.3503  Val_Acc: 86.061

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.4067 Train_Acc: 82.087 Val_Loss: 0.3503  BEST VAL Loss: 0.3503  Val_Acc: 85.731

Epoch 61: Validation loss decreased (0.350343 --> 0.350019).  Saving model ...
	 Train_Loss: 0.4064 Train_Acc: 82.050 Val_Loss: 0.3500  BEST VAL Loss: 0.3500  Val_Acc: 86.448

Epoch 62: Validation loss decreased (0.350019 --> 0.349615).  Saving model ...
	 Train_Loss: 0.4060 Train_Acc: 82.164 Val_Loss: 0.3496  BEST VAL Loss: 0.3496  Val_Acc: 86.749

Epoch 63: Validation loss decreased (0.349615 --> 0.349530).  Saving model ...
	 Train_Loss: 0.4057 Train_Acc: 82.213 Val_Loss: 0.3495  BEST VAL Loss: 0.3495  Val_Acc: 86.016

Epoch 64: Validation loss decreased (0.349530 --> 0.349259).  Saving model ...
	 Train_Loss: 0.4055 Train_Acc: 82.082 Val_Loss: 0.3493  BEST VAL Loss: 0.3493  Val_Acc: 86.189

Epoch 65: Validation loss decreased (0.349259 --> 0.348862).  Saving model ...
	 Train_Loss: 0.4052 Train_Acc: 82.205 Val_Loss: 0.3489  BEST VAL Loss: 0.3489  Val_Acc: 87.085

Epoch 66: Validation loss decreased (0.348862 --> 0.348449).  Saving model ...
	 Train_Loss: 0.4049 Train_Acc: 82.099 Val_Loss: 0.3484  BEST VAL Loss: 0.3484  Val_Acc: 86.948

Epoch 67: Validation loss decreased (0.348449 --> 0.348142).  Saving model ...
	 Train_Loss: 0.4046 Train_Acc: 82.143 Val_Loss: 0.3481  BEST VAL Loss: 0.3481  Val_Acc: 86.282

Epoch 68: Validation loss decreased (0.348142 --> 0.347919).  Saving model ...
	 Train_Loss: 0.4043 Train_Acc: 82.149 Val_Loss: 0.3479  BEST VAL Loss: 0.3479  Val_Acc: 86.359

Epoch 69: Validation loss decreased (0.347919 --> 0.347629).  Saving model ...
	 Train_Loss: 0.4040 Train_Acc: 82.221 Val_Loss: 0.3476  BEST VAL Loss: 0.3476  Val_Acc: 86.804

Epoch 70: Validation loss decreased (0.347629 --> 0.347273).  Saving model ...
	 Train_Loss: 0.4038 Train_Acc: 82.097 Val_Loss: 0.3473  BEST VAL Loss: 0.3473  Val_Acc: 86.874

Epoch 71: Validation loss decreased (0.347273 --> 0.347057).  Saving model ...
	 Train_Loss: 0.4035 Train_Acc: 82.206 Val_Loss: 0.3471  BEST VAL Loss: 0.3471  Val_Acc: 86.605

Epoch 72: Validation loss decreased (0.347057 --> 0.346968).  Saving model ...
	 Train_Loss: 0.4032 Train_Acc: 82.090 Val_Loss: 0.3470  BEST VAL Loss: 0.3470  Val_Acc: 85.907

Epoch 73: Validation loss decreased (0.346968 --> 0.346741).  Saving model ...
	 Train_Loss: 0.4030 Train_Acc: 82.211 Val_Loss: 0.3467  BEST VAL Loss: 0.3467  Val_Acc: 86.291

Epoch 74: Validation loss decreased (0.346741 --> 0.346499).  Saving model ...
	 Train_Loss: 0.4027 Train_Acc: 82.146 Val_Loss: 0.3465  BEST VAL Loss: 0.3465  Val_Acc: 86.736

Epoch 75: Validation loss decreased (0.346499 --> 0.346301).  Saving model ...
	 Train_Loss: 0.4025 Train_Acc: 82.071 Val_Loss: 0.3463  BEST VAL Loss: 0.3463  Val_Acc: 86.256

Epoch 76: Validation loss decreased (0.346301 --> 0.346129).  Saving model ...
	 Train_Loss: 0.4022 Train_Acc: 82.096 Val_Loss: 0.3461  BEST VAL Loss: 0.3461  Val_Acc: 86.327

Epoch 77: Validation loss decreased (0.346129 --> 0.345856).  Saving model ...
	 Train_Loss: 0.4020 Train_Acc: 82.199 Val_Loss: 0.3459  BEST VAL Loss: 0.3459  Val_Acc: 86.339

Epoch 78: Validation loss decreased (0.345856 --> 0.345594).  Saving model ...
	 Train_Loss: 0.4018 Train_Acc: 82.159 Val_Loss: 0.3456  BEST VAL Loss: 0.3456  Val_Acc: 86.637

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.4015 Train_Acc: 82.179 Val_Loss: 0.3457  BEST VAL Loss: 0.3456  Val_Acc: 85.453

Epoch 80: Validation loss decreased (0.345594 --> 0.345454).  Saving model ...
	 Train_Loss: 0.4013 Train_Acc: 82.285 Val_Loss: 0.3455  BEST VAL Loss: 0.3455  Val_Acc: 86.506

Epoch 81: Validation loss decreased (0.345454 --> 0.345235).  Saving model ...
	 Train_Loss: 0.4011 Train_Acc: 82.203 Val_Loss: 0.3452  BEST VAL Loss: 0.3452  Val_Acc: 86.471

Epoch 82: Validation loss decreased (0.345235 --> 0.345196).  Saving model ...
	 Train_Loss: 0.4008 Train_Acc: 82.023 Val_Loss: 0.3452  BEST VAL Loss: 0.3452  Val_Acc: 85.398

Epoch 83: Validation loss decreased (0.345196 --> 0.345018).  Saving model ...
	 Train_Loss: 0.4006 Train_Acc: 82.128 Val_Loss: 0.3450  BEST VAL Loss: 0.3450  Val_Acc: 86.227

Epoch 84: Validation loss decreased (0.345018 --> 0.344975).  Saving model ...
	 Train_Loss: 0.4004 Train_Acc: 82.232 Val_Loss: 0.3450  BEST VAL Loss: 0.3450  Val_Acc: 85.449

Epoch 85: Validation loss decreased (0.344975 --> 0.344717).  Saving model ...
	 Train_Loss: 0.4002 Train_Acc: 82.161 Val_Loss: 0.3447  BEST VAL Loss: 0.3447  Val_Acc: 86.656

Epoch 86: Validation loss decreased (0.344717 --> 0.344439).  Saving model ...
	 Train_Loss: 0.3999 Train_Acc: 82.201 Val_Loss: 0.3444  BEST VAL Loss: 0.3444  Val_Acc: 86.865

Epoch 87: Validation loss decreased (0.344439 --> 0.344255).  Saving model ...
	 Train_Loss: 0.3997 Train_Acc: 82.222 Val_Loss: 0.3443  BEST VAL Loss: 0.3443  Val_Acc: 86.173

Epoch 88: Validation loss decreased (0.344255 --> 0.344212).  Saving model ...
	 Train_Loss: 0.3995 Train_Acc: 82.147 Val_Loss: 0.3442  BEST VAL Loss: 0.3442  Val_Acc: 85.795

Epoch 89: Validation loss decreased (0.344212 --> 0.343951).  Saving model ...
	 Train_Loss: 0.3993 Train_Acc: 82.126 Val_Loss: 0.3440  BEST VAL Loss: 0.3440  Val_Acc: 86.676

Epoch 90: Validation loss decreased (0.343951 --> 0.343692).  Saving model ...
	 Train_Loss: 0.3991 Train_Acc: 82.139 Val_Loss: 0.3437  BEST VAL Loss: 0.3437  Val_Acc: 86.989

Epoch 91: Validation loss decreased (0.343692 --> 0.343445).  Saving model ...
	 Train_Loss: 0.3989 Train_Acc: 82.037 Val_Loss: 0.3434  BEST VAL Loss: 0.3434  Val_Acc: 86.733

Epoch 92: Validation loss decreased (0.343445 --> 0.343227).  Saving model ...
	 Train_Loss: 0.3987 Train_Acc: 82.196 Val_Loss: 0.3432  BEST VAL Loss: 0.3432  Val_Acc: 86.608

Epoch 93: Validation loss decreased (0.343227 --> 0.342979).  Saving model ...
	 Train_Loss: 0.3985 Train_Acc: 82.241 Val_Loss: 0.3430  BEST VAL Loss: 0.3430  Val_Acc: 87.009

Epoch 94: Validation loss decreased (0.342979 --> 0.342687).  Saving model ...
	 Train_Loss: 0.3983 Train_Acc: 82.160 Val_Loss: 0.3427  BEST VAL Loss: 0.3427  Val_Acc: 87.130

Epoch 95: Validation loss decreased (0.342687 --> 0.342431).  Saving model ...
	 Train_Loss: 0.3981 Train_Acc: 82.119 Val_Loss: 0.3424  BEST VAL Loss: 0.3424  Val_Acc: 87.149

Epoch 96: Validation loss decreased (0.342431 --> 0.342200).  Saving model ...
	 Train_Loss: 0.3979 Train_Acc: 82.119 Val_Loss: 0.3422  BEST VAL Loss: 0.3422  Val_Acc: 87.037

Epoch 97: Validation loss decreased (0.342200 --> 0.342033).  Saving model ...
	 Train_Loss: 0.3977 Train_Acc: 82.037 Val_Loss: 0.3420  BEST VAL Loss: 0.3420  Val_Acc: 86.509

Epoch 98: Validation loss decreased (0.342033 --> 0.341841).  Saving model ...
	 Train_Loss: 0.3975 Train_Acc: 82.246 Val_Loss: 0.3418  BEST VAL Loss: 0.3418  Val_Acc: 86.631

Epoch 99: Validation loss decreased (0.341841 --> 0.341675).  Saving model ...
	 Train_Loss: 0.3973 Train_Acc: 82.336 Val_Loss: 0.3417  BEST VAL Loss: 0.3417  Val_Acc: 86.413

H2O2_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.68      0.63      0.65    169562
           1       0.32      0.36      0.34     80324

    accuracy                           0.55    249886
   macro avg       0.50      0.50      0.50    249886
weighted avg       0.56      0.55      0.55    249886

H2O2_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.68      0.64      0.66     21195
           1       0.32      0.36      0.34     10041

    accuracy                           0.55     31236
   macro avg       0.50      0.50      0.50     31236
weighted avg       0.57      0.55      0.56     31236

H2O2_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.68      0.64      0.66     21195
           1       0.32      0.37      0.35     10041

    accuracy                           0.55     31236
   macro avg       0.50      0.50      0.50     31236
weighted avg       0.57      0.55      0.56     31236

              precision    recall  f1-score   support

           0       0.68      0.64      0.66     21195
           1       0.32      0.37      0.35     10041

    accuracy                           0.55     31236
   macro avg       0.50      0.50      0.50     31236
weighted avg       0.57      0.55      0.56     31236

H2O2_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.43      0.47      0.44     28584
           1       0.57      0.53      0.55     38191

    accuracy                           0.50     66775
   macro avg       0.50      0.50      0.50     66775
weighted avg       0.51      0.50      0.50     66775

              precision    recall  f1-score   support

           0       0.43      0.47      0.44     28584
           1       0.57      0.53      0.55     38191

    accuracy                           0.50     66775
   macro avg       0.50      0.50      0.50     66775
weighted avg       0.51      0.50      0.50     66775

completed
