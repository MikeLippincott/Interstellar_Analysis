[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '40cd169d'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '156be2ce'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '38f3cf59'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '6dda1cde'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: H2O2_100.000_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['H2O2_100.000_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (399971, 1270)
Number of total missing values across all columns: 799942
Data Subset Is Off
Wells held out for testing: ['I10' 'J08']
Wells to use for training, validation, and testing ['H04' 'I04' 'H05' 'I05' 'H10' 'H11' 'I11' 'J02' 'J03' 'J09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.388699).  Saving model ...
	 Train_Loss: 0.4807 Train_Acc: 76.151 Val_Loss: 0.3887  BEST VAL Loss: 0.3887  Val_Acc: 82.062

Epoch 1: Validation loss decreased (0.388699 --> 0.373651).  Saving model ...
	 Train_Loss: 0.4383 Train_Acc: 81.341 Val_Loss: 0.3737  BEST VAL Loss: 0.3737  Val_Acc: 83.579

Epoch 2: Validation loss decreased (0.373651 --> 0.363640).  Saving model ...
	 Train_Loss: 0.4170 Train_Acc: 82.526 Val_Loss: 0.3636  BEST VAL Loss: 0.3636  Val_Acc: 84.444

Epoch 3: Validation loss decreased (0.363640 --> 0.357257).  Saving model ...
	 Train_Loss: 0.4031 Train_Acc: 83.171 Val_Loss: 0.3573  BEST VAL Loss: 0.3573  Val_Acc: 84.959

Epoch 4: Validation loss decreased (0.357257 --> 0.352411).  Saving model ...
	 Train_Loss: 0.3934 Train_Acc: 83.521 Val_Loss: 0.3524  BEST VAL Loss: 0.3524  Val_Acc: 85.177

Epoch 5: Validation loss decreased (0.352411 --> 0.348486).  Saving model ...
	 Train_Loss: 0.3858 Train_Acc: 83.850 Val_Loss: 0.3485  BEST VAL Loss: 0.3485  Val_Acc: 85.411

Epoch 6: Validation loss decreased (0.348486 --> 0.344523).  Saving model ...
	 Train_Loss: 0.3797 Train_Acc: 84.210 Val_Loss: 0.3445  BEST VAL Loss: 0.3445  Val_Acc: 85.695

Epoch 7: Validation loss decreased (0.344523 --> 0.341645).  Saving model ...
	 Train_Loss: 0.3746 Train_Acc: 84.361 Val_Loss: 0.3416  BEST VAL Loss: 0.3416  Val_Acc: 85.800

Epoch 8: Validation loss decreased (0.341645 --> 0.338988).  Saving model ...
	 Train_Loss: 0.3705 Train_Acc: 84.440 Val_Loss: 0.3390  BEST VAL Loss: 0.3390  Val_Acc: 85.599

Epoch 9: Validation loss decreased (0.338988 --> 0.337052).  Saving model ...
	 Train_Loss: 0.3668 Train_Acc: 84.628 Val_Loss: 0.3371  BEST VAL Loss: 0.3371  Val_Acc: 85.779

Epoch 10: Validation loss decreased (0.337052 --> 0.334982).  Saving model ...
	 Train_Loss: 0.3636 Train_Acc: 84.668 Val_Loss: 0.3350  BEST VAL Loss: 0.3350  Val_Acc: 86.105

Epoch 11: Validation loss decreased (0.334982 --> 0.333002).  Saving model ...
	 Train_Loss: 0.3608 Train_Acc: 84.771 Val_Loss: 0.3330  BEST VAL Loss: 0.3330  Val_Acc: 86.309

Epoch 12: Validation loss decreased (0.333002 --> 0.331252).  Saving model ...
	 Train_Loss: 0.3582 Train_Acc: 84.937 Val_Loss: 0.3313  BEST VAL Loss: 0.3313  Val_Acc: 86.204

Epoch 13: Validation loss decreased (0.331252 --> 0.329831).  Saving model ...
	 Train_Loss: 0.3559 Train_Acc: 85.069 Val_Loss: 0.3298  BEST VAL Loss: 0.3298  Val_Acc: 86.111

Epoch 14: Validation loss decreased (0.329831 --> 0.328424).  Saving model ...
	 Train_Loss: 0.3538 Train_Acc: 85.077 Val_Loss: 0.3284  BEST VAL Loss: 0.3284  Val_Acc: 86.024

Epoch 15: Validation loss decreased (0.328424 --> 0.327383).  Saving model ...
	 Train_Loss: 0.3519 Train_Acc: 85.085 Val_Loss: 0.3274  BEST VAL Loss: 0.3274  Val_Acc: 86.267

Epoch 16: Validation loss decreased (0.327383 --> 0.326218).  Saving model ...
	 Train_Loss: 0.3502 Train_Acc: 85.138 Val_Loss: 0.3262  BEST VAL Loss: 0.3262  Val_Acc: 86.228

Epoch 17: Validation loss decreased (0.326218 --> 0.325436).  Saving model ...
	 Train_Loss: 0.3486 Train_Acc: 85.239 Val_Loss: 0.3254  BEST VAL Loss: 0.3254  Val_Acc: 85.988

Epoch 18: Validation loss decreased (0.325436 --> 0.324580).  Saving model ...
	 Train_Loss: 0.3470 Train_Acc: 85.266 Val_Loss: 0.3246  BEST VAL Loss: 0.3246  Val_Acc: 86.240

Epoch 19: Validation loss decreased (0.324580 --> 0.323756).  Saving model ...
	 Train_Loss: 0.3456 Train_Acc: 85.371 Val_Loss: 0.3238  BEST VAL Loss: 0.3238  Val_Acc: 86.306

Epoch 20: Validation loss decreased (0.323756 --> 0.323024).  Saving model ...
	 Train_Loss: 0.3443 Train_Acc: 85.427 Val_Loss: 0.3230  BEST VAL Loss: 0.3230  Val_Acc: 86.527

Epoch 21: Validation loss decreased (0.323024 --> 0.322214).  Saving model ...
	 Train_Loss: 0.3431 Train_Acc: 85.511 Val_Loss: 0.3222  BEST VAL Loss: 0.3222  Val_Acc: 86.240

Epoch 22: Validation loss decreased (0.322214 --> 0.321468).  Saving model ...
	 Train_Loss: 0.3419 Train_Acc: 85.450 Val_Loss: 0.3215  BEST VAL Loss: 0.3215  Val_Acc: 86.503

Epoch 23: Validation loss decreased (0.321468 --> 0.320885).  Saving model ...
	 Train_Loss: 0.3408 Train_Acc: 85.472 Val_Loss: 0.3209  BEST VAL Loss: 0.3209  Val_Acc: 86.440

Epoch 24: Validation loss decreased (0.320885 --> 0.320129).  Saving model ...
	 Train_Loss: 0.3398 Train_Acc: 85.397 Val_Loss: 0.3201  BEST VAL Loss: 0.3201  Val_Acc: 86.554

Epoch 25: Validation loss decreased (0.320129 --> 0.319575).  Saving model ...
	 Train_Loss: 0.3388 Train_Acc: 85.539 Val_Loss: 0.3196  BEST VAL Loss: 0.3196  Val_Acc: 86.461

Epoch 26: Validation loss decreased (0.319575 --> 0.319096).  Saving model ...
	 Train_Loss: 0.3378 Train_Acc: 85.599 Val_Loss: 0.3191  BEST VAL Loss: 0.3191  Val_Acc: 86.545

Epoch 27: Validation loss decreased (0.319096 --> 0.318599).  Saving model ...
	 Train_Loss: 0.3369 Train_Acc: 85.610 Val_Loss: 0.3186  BEST VAL Loss: 0.3186  Val_Acc: 86.503

Epoch 28: Validation loss decreased (0.318599 --> 0.318062).  Saving model ...
	 Train_Loss: 0.3361 Train_Acc: 85.606 Val_Loss: 0.3181  BEST VAL Loss: 0.3181  Val_Acc: 86.512

Epoch 29: Validation loss decreased (0.318062 --> 0.317735).  Saving model ...
	 Train_Loss: 0.3352 Train_Acc: 85.685 Val_Loss: 0.3177  BEST VAL Loss: 0.3177  Val_Acc: 86.401

Epoch 30: Validation loss decreased (0.317735 --> 0.317417).  Saving model ...
	 Train_Loss: 0.3345 Train_Acc: 85.716 Val_Loss: 0.3174  BEST VAL Loss: 0.3174  Val_Acc: 86.431

Epoch 31: Validation loss decreased (0.317417 --> 0.316960).  Saving model ...
	 Train_Loss: 0.3337 Train_Acc: 85.701 Val_Loss: 0.3170  BEST VAL Loss: 0.3170  Val_Acc: 86.506

Epoch 32: Validation loss decreased (0.316960 --> 0.316537).  Saving model ...
	 Train_Loss: 0.3329 Train_Acc: 85.735 Val_Loss: 0.3165  BEST VAL Loss: 0.3165  Val_Acc: 86.572

Epoch 33: Validation loss decreased (0.316537 --> 0.316129).  Saving model ...
	 Train_Loss: 0.3322 Train_Acc: 85.807 Val_Loss: 0.3161  BEST VAL Loss: 0.3161  Val_Acc: 86.662

Epoch 34: Validation loss decreased (0.316129 --> 0.315828).  Saving model ...
	 Train_Loss: 0.3315 Train_Acc: 85.742 Val_Loss: 0.3158  BEST VAL Loss: 0.3158  Val_Acc: 86.548

Epoch 35: Validation loss decreased (0.315828 --> 0.315410).  Saving model ...
	 Train_Loss: 0.3309 Train_Acc: 85.805 Val_Loss: 0.3154  BEST VAL Loss: 0.3154  Val_Acc: 86.581

Epoch 36: Validation loss decreased (0.315410 --> 0.315109).  Saving model ...
	 Train_Loss: 0.3303 Train_Acc: 85.820 Val_Loss: 0.3151  BEST VAL Loss: 0.3151  Val_Acc: 86.626

Epoch 37: Validation loss decreased (0.315109 --> 0.314849).  Saving model ...
	 Train_Loss: 0.3297 Train_Acc: 85.883 Val_Loss: 0.3148  BEST VAL Loss: 0.3148  Val_Acc: 86.584

Epoch 38: Validation loss decreased (0.314849 --> 0.314491).  Saving model ...
	 Train_Loss: 0.3292 Train_Acc: 85.891 Val_Loss: 0.3145  BEST VAL Loss: 0.3145  Val_Acc: 86.745

Epoch 39: Validation loss decreased (0.314491 --> 0.314285).  Saving model ...
	 Train_Loss: 0.3286 Train_Acc: 85.894 Val_Loss: 0.3143  BEST VAL Loss: 0.3143  Val_Acc: 86.710

Epoch 40: Validation loss decreased (0.314285 --> 0.314057).  Saving model ...
	 Train_Loss: 0.3280 Train_Acc: 85.950 Val_Loss: 0.3141  BEST VAL Loss: 0.3141  Val_Acc: 86.581

Epoch 41: Validation loss decreased (0.314057 --> 0.313745).  Saving model ...
	 Train_Loss: 0.3275 Train_Acc: 85.917 Val_Loss: 0.3137  BEST VAL Loss: 0.3137  Val_Acc: 86.614

Epoch 42: Validation loss decreased (0.313745 --> 0.313503).  Saving model ...
	 Train_Loss: 0.3270 Train_Acc: 85.950 Val_Loss: 0.3135  BEST VAL Loss: 0.3135  Val_Acc: 86.641

Epoch 43: Validation loss decreased (0.313503 --> 0.313276).  Saving model ...
	 Train_Loss: 0.3265 Train_Acc: 85.945 Val_Loss: 0.3133  BEST VAL Loss: 0.3133  Val_Acc: 86.641

Epoch 44: Validation loss decreased (0.313276 --> 0.313126).  Saving model ...
	 Train_Loss: 0.3260 Train_Acc: 85.938 Val_Loss: 0.3131  BEST VAL Loss: 0.3131  Val_Acc: 86.665

Epoch 45: Validation loss decreased (0.313126 --> 0.312823).  Saving model ...
	 Train_Loss: 0.3256 Train_Acc: 86.032 Val_Loss: 0.3128  BEST VAL Loss: 0.3128  Val_Acc: 86.686

Epoch 46: Validation loss decreased (0.312823 --> 0.312637).  Saving model ...
	 Train_Loss: 0.3251 Train_Acc: 86.046 Val_Loss: 0.3126  BEST VAL Loss: 0.3126  Val_Acc: 86.632

Epoch 47: Validation loss decreased (0.312637 --> 0.312419).  Saving model ...
	 Train_Loss: 0.3246 Train_Acc: 86.127 Val_Loss: 0.3124  BEST VAL Loss: 0.3124  Val_Acc: 86.656

Epoch 48: Validation loss decreased (0.312419 --> 0.312200).  Saving model ...
	 Train_Loss: 0.3242 Train_Acc: 86.078 Val_Loss: 0.3122  BEST VAL Loss: 0.3122  Val_Acc: 86.515

Epoch 49: Validation loss decreased (0.312200 --> 0.311935).  Saving model ...
	 Train_Loss: 0.3237 Train_Acc: 86.126 Val_Loss: 0.3119  BEST VAL Loss: 0.3119  Val_Acc: 86.692

Epoch 50: Validation loss decreased (0.311935 --> 0.311720).  Saving model ...
	 Train_Loss: 0.3233 Train_Acc: 86.143 Val_Loss: 0.3117  BEST VAL Loss: 0.3117  Val_Acc: 86.728

Epoch 51: Validation loss decreased (0.311720 --> 0.311520).  Saving model ...
	 Train_Loss: 0.3229 Train_Acc: 86.121 Val_Loss: 0.3115  BEST VAL Loss: 0.3115  Val_Acc: 86.901

Epoch 52: Validation loss decreased (0.311520 --> 0.311233).  Saving model ...
	 Train_Loss: 0.3225 Train_Acc: 86.064 Val_Loss: 0.3112  BEST VAL Loss: 0.3112  Val_Acc: 86.865

Epoch 53: Validation loss decreased (0.311233 --> 0.311088).  Saving model ...
	 Train_Loss: 0.3221 Train_Acc: 86.053 Val_Loss: 0.3111  BEST VAL Loss: 0.3111  Val_Acc: 86.611

Epoch 54: Validation loss decreased (0.311088 --> 0.310925).  Saving model ...
	 Train_Loss: 0.3217 Train_Acc: 86.104 Val_Loss: 0.3109  BEST VAL Loss: 0.3109  Val_Acc: 86.751

Epoch 55: Validation loss decreased (0.310925 --> 0.310759).  Saving model ...
	 Train_Loss: 0.3214 Train_Acc: 86.073 Val_Loss: 0.3108  BEST VAL Loss: 0.3108  Val_Acc: 86.671

Epoch 56: Validation loss decreased (0.310759 --> 0.310595).  Saving model ...
	 Train_Loss: 0.3210 Train_Acc: 86.132 Val_Loss: 0.3106  BEST VAL Loss: 0.3106  Val_Acc: 86.898

Epoch 57: Validation loss decreased (0.310595 --> 0.310479).  Saving model ...
	 Train_Loss: 0.3206 Train_Acc: 86.183 Val_Loss: 0.3105  BEST VAL Loss: 0.3105  Val_Acc: 86.503

Epoch 58: Validation loss decreased (0.310479 --> 0.310266).  Saving model ...
	 Train_Loss: 0.3203 Train_Acc: 86.152 Val_Loss: 0.3103  BEST VAL Loss: 0.3103  Val_Acc: 86.790

Epoch 59: Validation loss decreased (0.310266 --> 0.310129).  Saving model ...
	 Train_Loss: 0.3199 Train_Acc: 86.191 Val_Loss: 0.3101  BEST VAL Loss: 0.3101  Val_Acc: 86.742

Epoch 60: Validation loss decreased (0.310129 --> 0.309967).  Saving model ...
	 Train_Loss: 0.3196 Train_Acc: 86.209 Val_Loss: 0.3100  BEST VAL Loss: 0.3100  Val_Acc: 86.739

Epoch 61: Validation loss decreased (0.309967 --> 0.309773).  Saving model ...
	 Train_Loss: 0.3193 Train_Acc: 86.236 Val_Loss: 0.3098  BEST VAL Loss: 0.3098  Val_Acc: 86.862

Epoch 62: Validation loss decreased (0.309773 --> 0.309624).  Saving model ...
	 Train_Loss: 0.3189 Train_Acc: 86.301 Val_Loss: 0.3096  BEST VAL Loss: 0.3096  Val_Acc: 86.823

Epoch 63: Validation loss decreased (0.309624 --> 0.309449).  Saving model ...
	 Train_Loss: 0.3186 Train_Acc: 86.216 Val_Loss: 0.3094  BEST VAL Loss: 0.3094  Val_Acc: 86.760

Epoch 64: Validation loss decreased (0.309449 --> 0.309250).  Saving model ...
	 Train_Loss: 0.3183 Train_Acc: 86.299 Val_Loss: 0.3092  BEST VAL Loss: 0.3092  Val_Acc: 86.850

Epoch 65: Validation loss decreased (0.309250 --> 0.309083).  Saving model ...
	 Train_Loss: 0.3180 Train_Acc: 86.368 Val_Loss: 0.3091  BEST VAL Loss: 0.3091  Val_Acc: 86.862

Epoch 66: Validation loss decreased (0.309083 --> 0.308884).  Saving model ...
	 Train_Loss: 0.3177 Train_Acc: 86.375 Val_Loss: 0.3089  BEST VAL Loss: 0.3089  Val_Acc: 86.775

Epoch 67: Validation loss decreased (0.308884 --> 0.308700).  Saving model ...
	 Train_Loss: 0.3174 Train_Acc: 86.269 Val_Loss: 0.3087  BEST VAL Loss: 0.3087  Val_Acc: 86.754

Epoch 68: Validation loss decreased (0.308700 --> 0.308563).  Saving model ...
	 Train_Loss: 0.3171 Train_Acc: 86.360 Val_Loss: 0.3086  BEST VAL Loss: 0.3086  Val_Acc: 86.689

Epoch 69: Validation loss decreased (0.308563 --> 0.308383).  Saving model ...
	 Train_Loss: 0.3168 Train_Acc: 86.355 Val_Loss: 0.3084  BEST VAL Loss: 0.3084  Val_Acc: 86.889

Epoch 70: Validation loss decreased (0.308383 --> 0.308177).  Saving model ...
	 Train_Loss: 0.3165 Train_Acc: 86.248 Val_Loss: 0.3082  BEST VAL Loss: 0.3082  Val_Acc: 86.943

Epoch 71: Validation loss decreased (0.308177 --> 0.308017).  Saving model ...
	 Train_Loss: 0.3163 Train_Acc: 86.310 Val_Loss: 0.3080  BEST VAL Loss: 0.3080  Val_Acc: 86.868

Epoch 72: Validation loss decreased (0.308017 --> 0.307857).  Saving model ...
	 Train_Loss: 0.3160 Train_Acc: 86.376 Val_Loss: 0.3079  BEST VAL Loss: 0.3079  Val_Acc: 86.910

Epoch 73: Validation loss decreased (0.307857 --> 0.307724).  Saving model ...
	 Train_Loss: 0.3157 Train_Acc: 86.373 Val_Loss: 0.3077  BEST VAL Loss: 0.3077  Val_Acc: 86.823

Epoch 74: Validation loss decreased (0.307724 --> 0.307582).  Saving model ...
	 Train_Loss: 0.3155 Train_Acc: 86.398 Val_Loss: 0.3076  BEST VAL Loss: 0.3076  Val_Acc: 86.820

Epoch 75: Validation loss decreased (0.307582 --> 0.307436).  Saving model ...
	 Train_Loss: 0.3152 Train_Acc: 86.404 Val_Loss: 0.3074  BEST VAL Loss: 0.3074  Val_Acc: 86.698

Epoch 76: Validation loss decreased (0.307436 --> 0.307317).  Saving model ...
	 Train_Loss: 0.3150 Train_Acc: 86.345 Val_Loss: 0.3073  BEST VAL Loss: 0.3073  Val_Acc: 86.913

Epoch 77: Validation loss decreased (0.307317 --> 0.307155).  Saving model ...
	 Train_Loss: 0.3147 Train_Acc: 86.383 Val_Loss: 0.3072  BEST VAL Loss: 0.3072  Val_Acc: 86.871

Epoch 78: Validation loss decreased (0.307155 --> 0.307025).  Saving model ...
	 Train_Loss: 0.3145 Train_Acc: 86.377 Val_Loss: 0.3070  BEST VAL Loss: 0.3070  Val_Acc: 86.901

Epoch 79: Validation loss decreased (0.307025 --> 0.306887).  Saving model ...
	 Train_Loss: 0.3143 Train_Acc: 86.472 Val_Loss: 0.3069  BEST VAL Loss: 0.3069  Val_Acc: 86.844

Epoch 80: Validation loss decreased (0.306887 --> 0.306768).  Saving model ...
	 Train_Loss: 0.3140 Train_Acc: 86.408 Val_Loss: 0.3068  BEST VAL Loss: 0.3068  Val_Acc: 86.955

Epoch 81: Validation loss decreased (0.306768 --> 0.306646).  Saving model ...
	 Train_Loss: 0.3138 Train_Acc: 86.454 Val_Loss: 0.3066  BEST VAL Loss: 0.3066  Val_Acc: 86.895

Epoch 82: Validation loss decreased (0.306646 --> 0.306487).  Saving model ...
	 Train_Loss: 0.3136 Train_Acc: 86.429 Val_Loss: 0.3065  BEST VAL Loss: 0.3065  Val_Acc: 86.979

Epoch 83: Validation loss decreased (0.306487 --> 0.306360).  Saving model ...
	 Train_Loss: 0.3134 Train_Acc: 86.441 Val_Loss: 0.3064  BEST VAL Loss: 0.3064  Val_Acc: 86.991

Epoch 84: Validation loss decreased (0.306360 --> 0.306256).  Saving model ...
	 Train_Loss: 0.3131 Train_Acc: 86.457 Val_Loss: 0.3063  BEST VAL Loss: 0.3063  Val_Acc: 86.886

Epoch 85: Validation loss decreased (0.306256 --> 0.306152).  Saving model ...
	 Train_Loss: 0.3129 Train_Acc: 86.441 Val_Loss: 0.3062  BEST VAL Loss: 0.3062  Val_Acc: 87.051

Epoch 86: Validation loss decreased (0.306152 --> 0.306026).  Saving model ...
	 Train_Loss: 0.3127 Train_Acc: 86.391 Val_Loss: 0.3060  BEST VAL Loss: 0.3060  Val_Acc: 86.979

Epoch 87: Validation loss decreased (0.306026 --> 0.305952).  Saving model ...
	 Train_Loss: 0.3125 Train_Acc: 86.437 Val_Loss: 0.3060  BEST VAL Loss: 0.3060  Val_Acc: 86.820

Epoch 88: Validation loss decreased (0.305952 --> 0.305867).  Saving model ...
	 Train_Loss: 0.3123 Train_Acc: 86.508 Val_Loss: 0.3059  BEST VAL Loss: 0.3059  Val_Acc: 86.814

Epoch 89: Validation loss decreased (0.305867 --> 0.305767).  Saving model ...
	 Train_Loss: 0.3121 Train_Acc: 86.555 Val_Loss: 0.3058  BEST VAL Loss: 0.3058  Val_Acc: 86.793

Epoch 90: Validation loss decreased (0.305767 --> 0.305701).  Saving model ...
	 Train_Loss: 0.3119 Train_Acc: 86.457 Val_Loss: 0.3057  BEST VAL Loss: 0.3057  Val_Acc: 86.898

Epoch 91: Validation loss decreased (0.305701 --> 0.305601).  Saving model ...
	 Train_Loss: 0.3117 Train_Acc: 86.463 Val_Loss: 0.3056  BEST VAL Loss: 0.3056  Val_Acc: 87.042

Epoch 92: Validation loss decreased (0.305601 --> 0.305529).  Saving model ...
	 Train_Loss: 0.3115 Train_Acc: 86.537 Val_Loss: 0.3055  BEST VAL Loss: 0.3055  Val_Acc: 86.841

Epoch 93: Validation loss decreased (0.305529 --> 0.305466).  Saving model ...
	 Train_Loss: 0.3113 Train_Acc: 86.483 Val_Loss: 0.3055  BEST VAL Loss: 0.3055  Val_Acc: 86.722

Epoch 94: Validation loss decreased (0.305466 --> 0.305352).  Saving model ...
	 Train_Loss: 0.3111 Train_Acc: 86.496 Val_Loss: 0.3054  BEST VAL Loss: 0.3054  Val_Acc: 86.901

Epoch 95: Validation loss decreased (0.305352 --> 0.305267).  Saving model ...
	 Train_Loss: 0.3109 Train_Acc: 86.492 Val_Loss: 0.3053  BEST VAL Loss: 0.3053  Val_Acc: 86.973

Epoch 96: Validation loss decreased (0.305267 --> 0.305174).  Saving model ...
	 Train_Loss: 0.3107 Train_Acc: 86.521 Val_Loss: 0.3052  BEST VAL Loss: 0.3052  Val_Acc: 86.871

Epoch 97: Validation loss decreased (0.305174 --> 0.305042).  Saving model ...
	 Train_Loss: 0.3105 Train_Acc: 86.498 Val_Loss: 0.3050  BEST VAL Loss: 0.3050  Val_Acc: 86.952

Epoch 98: Validation loss decreased (0.305042 --> 0.304926).  Saving model ...
	 Train_Loss: 0.3103 Train_Acc: 86.510 Val_Loss: 0.3049  BEST VAL Loss: 0.3049  Val_Acc: 86.925

Epoch 99: Validation loss decreased (0.304926 --> 0.304824).  Saving model ...
	 Train_Loss: 0.3102 Train_Acc: 86.576 Val_Loss: 0.3048  BEST VAL Loss: 0.3048  Val_Acc: 87.060

H2O2_100.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.92      0.91      0.91    169560
           1       0.84      0.86      0.85     97754

    accuracy                           0.89    267314
   macro avg       0.88      0.88      0.88    267314
weighted avg       0.89      0.89      0.89    267314

H2O2_100.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.90      0.89      0.90     21196
           1       0.82      0.83      0.82     12219

    accuracy                           0.87     33415
   macro avg       0.86      0.86      0.86     33415
weighted avg       0.87      0.87      0.87     33415

H2O2_100.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.90      0.90      0.90     21196
           1       0.82      0.84      0.83     12219

    accuracy                           0.87     33415
   macro avg       0.86      0.87      0.86     33415
weighted avg       0.87      0.87      0.87     33415

              precision    recall  f1-score   support

           0       0.90      0.90      0.90     21196
           1       0.82      0.84      0.83     12219

    accuracy                           0.87     33415
   macro avg       0.86      0.87      0.86     33415
weighted avg       0.87      0.87      0.87     33415

H2O2_100.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.67      0.88      0.76     28584
           1       0.88      0.66      0.75     37243

    accuracy                           0.76     65827
   macro avg       0.77      0.77      0.76     65827
weighted avg       0.79      0.76      0.76     65827

              precision    recall  f1-score   support

           0       0.67      0.88      0.76     28584
           1       0.88      0.66      0.75     37243

    accuracy                           0.76     65827
   macro avg       0.77      0.77      0.76     65827
weighted avg       0.79      0.76      0.76     65827

completed
