[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '9e3db8e2'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '8fd82d8b'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '6b1aae2f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '9ddad257'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: H2O2_100.000_DMSO_0.025 treatment_name: Thapsigargin_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: Thapsigargin_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (388992, 1270)
Number of total missing values across all columns: 777984
Data Subset Is Off
Wells held out for testing: ['I10' 'K07']
Wells to use for training, validation, and testing ['D06' 'D07' 'H04' 'I04' 'H05' 'I05' 'H10' 'H11' 'I11' 'K06']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.541408).  Saving model ...
	 Train_Loss: 0.6390 Train_Acc: 67.088 Val_Loss: 0.5414  BEST VAL Loss: 0.5414  Val_Acc: 72.446

Epoch 1: Validation loss decreased (0.541408 --> 0.514381).  Saving model ...
	 Train_Loss: 0.5898 Train_Acc: 71.849 Val_Loss: 0.5144  BEST VAL Loss: 0.5144  Val_Acc: 75.822

Epoch 2: Validation loss decreased (0.514381 --> 0.501949).  Saving model ...
	 Train_Loss: 0.5643 Train_Acc: 73.557 Val_Loss: 0.5019  BEST VAL Loss: 0.5019  Val_Acc: 75.577

Epoch 3: Validation loss decreased (0.501949 --> 0.491441).  Saving model ...
	 Train_Loss: 0.5469 Train_Acc: 74.669 Val_Loss: 0.4914  BEST VAL Loss: 0.4914  Val_Acc: 76.655

Epoch 4: Validation loss decreased (0.491441 --> 0.484426).  Saving model ...
	 Train_Loss: 0.5346 Train_Acc: 75.208 Val_Loss: 0.4844  BEST VAL Loss: 0.4844  Val_Acc: 77.500

Epoch 5: Validation loss decreased (0.484426 --> 0.476263).  Saving model ...
	 Train_Loss: 0.5251 Train_Acc: 75.707 Val_Loss: 0.4763  BEST VAL Loss: 0.4763  Val_Acc: 79.115

Epoch 6: Validation loss decreased (0.476263 --> 0.470985).  Saving model ...
	 Train_Loss: 0.5170 Train_Acc: 76.298 Val_Loss: 0.4710  BEST VAL Loss: 0.4710  Val_Acc: 78.363

Epoch 7: Validation loss decreased (0.470985 --> 0.464397).  Saving model ...
	 Train_Loss: 0.5104 Train_Acc: 76.659 Val_Loss: 0.4644  BEST VAL Loss: 0.4644  Val_Acc: 79.919

Epoch 8: Validation loss decreased (0.464397 --> 0.459423).  Saving model ...
	 Train_Loss: 0.5044 Train_Acc: 76.980 Val_Loss: 0.4594  BEST VAL Loss: 0.4594  Val_Acc: 79.904

Epoch 9: Validation loss decreased (0.459423 --> 0.454756).  Saving model ...
	 Train_Loss: 0.4994 Train_Acc: 77.214 Val_Loss: 0.4548  BEST VAL Loss: 0.4548  Val_Acc: 80.047

Epoch 10: Validation loss decreased (0.454756 --> 0.450625).  Saving model ...
	 Train_Loss: 0.4949 Train_Acc: 77.330 Val_Loss: 0.4506  BEST VAL Loss: 0.4506  Val_Acc: 80.078

Epoch 11: Validation loss decreased (0.450625 --> 0.447198).  Saving model ...
	 Train_Loss: 0.4909 Train_Acc: 77.527 Val_Loss: 0.4472  BEST VAL Loss: 0.4472  Val_Acc: 80.929

Epoch 12: Validation loss decreased (0.447198 --> 0.443472).  Saving model ...
	 Train_Loss: 0.4874 Train_Acc: 77.645 Val_Loss: 0.4435  BEST VAL Loss: 0.4435  Val_Acc: 81.065

Epoch 13: Validation loss decreased (0.443472 --> 0.440386).  Saving model ...
	 Train_Loss: 0.4841 Train_Acc: 77.828 Val_Loss: 0.4404  BEST VAL Loss: 0.4404  Val_Acc: 80.770

Epoch 14: Validation loss decreased (0.440386 --> 0.438431).  Saving model ...
	 Train_Loss: 0.4813 Train_Acc: 77.726 Val_Loss: 0.4384  BEST VAL Loss: 0.4384  Val_Acc: 79.873

Epoch 15: Validation loss decreased (0.438431 --> 0.436081).  Saving model ...
	 Train_Loss: 0.4788 Train_Acc: 77.838 Val_Loss: 0.4361  BEST VAL Loss: 0.4361  Val_Acc: 80.963

Epoch 16: Validation loss decreased (0.436081 --> 0.433856).  Saving model ...
	 Train_Loss: 0.4764 Train_Acc: 77.876 Val_Loss: 0.4339  BEST VAL Loss: 0.4339  Val_Acc: 80.882

Epoch 17: Validation loss decreased (0.433856 --> 0.431719).  Saving model ...
	 Train_Loss: 0.4743 Train_Acc: 77.889 Val_Loss: 0.4317  BEST VAL Loss: 0.4317  Val_Acc: 81.193

Epoch 18: Validation loss decreased (0.431719 --> 0.429826).  Saving model ...
	 Train_Loss: 0.4722 Train_Acc: 78.286 Val_Loss: 0.4298  BEST VAL Loss: 0.4298  Val_Acc: 81.295

Epoch 19: Validation loss decreased (0.429826 --> 0.428018).  Saving model ...
	 Train_Loss: 0.4702 Train_Acc: 78.288 Val_Loss: 0.4280  BEST VAL Loss: 0.4280  Val_Acc: 81.544

Epoch 20: Validation loss decreased (0.428018 --> 0.427068).  Saving model ...
	 Train_Loss: 0.4683 Train_Acc: 78.239 Val_Loss: 0.4271  BEST VAL Loss: 0.4271  Val_Acc: 80.789

Epoch 21: Validation loss decreased (0.427068 --> 0.425632).  Saving model ...
	 Train_Loss: 0.4667 Train_Acc: 78.173 Val_Loss: 0.4256  BEST VAL Loss: 0.4256  Val_Acc: 81.146

Epoch 22: Validation loss decreased (0.425632 --> 0.423842).  Saving model ...
	 Train_Loss: 0.4651 Train_Acc: 78.387 Val_Loss: 0.4238  BEST VAL Loss: 0.4238  Val_Acc: 81.587

Epoch 23: Validation loss decreased (0.423842 --> 0.422483).  Saving model ...
	 Train_Loss: 0.4636 Train_Acc: 78.461 Val_Loss: 0.4225  BEST VAL Loss: 0.4225  Val_Acc: 81.718

Epoch 24: Validation loss decreased (0.422483 --> 0.421600).  Saving model ...
	 Train_Loss: 0.4621 Train_Acc: 78.550 Val_Loss: 0.4216  BEST VAL Loss: 0.4216  Val_Acc: 80.671

Epoch 25: Validation loss decreased (0.421600 --> 0.420303).  Saving model ...
	 Train_Loss: 0.4607 Train_Acc: 78.462 Val_Loss: 0.4203  BEST VAL Loss: 0.4203  Val_Acc: 81.155

Epoch 26: Validation loss decreased (0.420303 --> 0.418866).  Saving model ...
	 Train_Loss: 0.4595 Train_Acc: 78.478 Val_Loss: 0.4189  BEST VAL Loss: 0.4189  Val_Acc: 81.864

Epoch 27: Validation loss decreased (0.418866 --> 0.417739).  Saving model ...
	 Train_Loss: 0.4584 Train_Acc: 78.587 Val_Loss: 0.4177  BEST VAL Loss: 0.4177  Val_Acc: 81.392

Epoch 28: Validation loss decreased (0.417739 --> 0.416721).  Saving model ...
	 Train_Loss: 0.4572 Train_Acc: 78.644 Val_Loss: 0.4167  BEST VAL Loss: 0.4167  Val_Acc: 81.457

Epoch 29: Validation loss decreased (0.416721 --> 0.415986).  Saving model ...
	 Train_Loss: 0.4561 Train_Acc: 78.470 Val_Loss: 0.4160  BEST VAL Loss: 0.4160  Val_Acc: 81.500

Epoch 30: Validation loss decreased (0.415986 --> 0.414914).  Saving model ...
	 Train_Loss: 0.4553 Train_Acc: 78.361 Val_Loss: 0.4149  BEST VAL Loss: 0.4149  Val_Acc: 81.994

Epoch 31: Validation loss decreased (0.414914 --> 0.413672).  Saving model ...
	 Train_Loss: 0.4542 Train_Acc: 78.735 Val_Loss: 0.4137  BEST VAL Loss: 0.4137  Val_Acc: 82.451

Epoch 32: Validation loss decreased (0.413672 --> 0.412751).  Saving model ...
	 Train_Loss: 0.4532 Train_Acc: 78.740 Val_Loss: 0.4128  BEST VAL Loss: 0.4128  Val_Acc: 81.892

Epoch 33: Validation loss decreased (0.412751 --> 0.412068).  Saving model ...
	 Train_Loss: 0.4523 Train_Acc: 78.854 Val_Loss: 0.4121  BEST VAL Loss: 0.4121  Val_Acc: 81.227

Epoch 34: Validation loss decreased (0.412068 --> 0.410992).  Saving model ...
	 Train_Loss: 0.4513 Train_Acc: 78.914 Val_Loss: 0.4110  BEST VAL Loss: 0.4110  Val_Acc: 82.010

Epoch 35: Validation loss decreased (0.410992 --> 0.410238).  Saving model ...
	 Train_Loss: 0.4506 Train_Acc: 78.661 Val_Loss: 0.4102  BEST VAL Loss: 0.4102  Val_Acc: 81.972

Epoch 36: Validation loss decreased (0.410238 --> 0.409357).  Saving model ...
	 Train_Loss: 0.4497 Train_Acc: 78.870 Val_Loss: 0.4094  BEST VAL Loss: 0.4094  Val_Acc: 82.507

Epoch 37: Validation loss decreased (0.409357 --> 0.408816).  Saving model ...
	 Train_Loss: 0.4489 Train_Acc: 78.998 Val_Loss: 0.4088  BEST VAL Loss: 0.4088  Val_Acc: 81.764

Epoch 38: Validation loss decreased (0.408816 --> 0.407978).  Saving model ...
	 Train_Loss: 0.4481 Train_Acc: 78.931 Val_Loss: 0.4080  BEST VAL Loss: 0.4080  Val_Acc: 82.305

Epoch 39: Validation loss decreased (0.407978 --> 0.407131).  Saving model ...
	 Train_Loss: 0.4473 Train_Acc: 78.966 Val_Loss: 0.4071  BEST VAL Loss: 0.4071  Val_Acc: 82.224

Epoch 40: Validation loss decreased (0.407131 --> 0.406412).  Saving model ...
	 Train_Loss: 0.4466 Train_Acc: 78.820 Val_Loss: 0.4064  BEST VAL Loss: 0.4064  Val_Acc: 82.295

Epoch 41: Validation loss decreased (0.406412 --> 0.405718).  Saving model ...
	 Train_Loss: 0.4459 Train_Acc: 78.871 Val_Loss: 0.4057  BEST VAL Loss: 0.4057  Val_Acc: 82.171

Epoch 42: Validation loss decreased (0.405718 --> 0.405156).  Saving model ...
	 Train_Loss: 0.4453 Train_Acc: 78.855 Val_Loss: 0.4052  BEST VAL Loss: 0.4052  Val_Acc: 82.243

Epoch 43: Validation loss decreased (0.405156 --> 0.404661).  Saving model ...
	 Train_Loss: 0.4447 Train_Acc: 79.007 Val_Loss: 0.4047  BEST VAL Loss: 0.4047  Val_Acc: 82.277

Epoch 44: Validation loss decreased (0.404661 --> 0.403916).  Saving model ...
	 Train_Loss: 0.4440 Train_Acc: 79.168 Val_Loss: 0.4039  BEST VAL Loss: 0.4039  Val_Acc: 82.438

Epoch 45: Validation loss decreased (0.403916 --> 0.403433).  Saving model ...
	 Train_Loss: 0.4434 Train_Acc: 78.979 Val_Loss: 0.4034  BEST VAL Loss: 0.4034  Val_Acc: 81.882

Epoch 46: Validation loss decreased (0.403433 --> 0.402792).  Saving model ...
	 Train_Loss: 0.4428 Train_Acc: 78.978 Val_Loss: 0.4028  BEST VAL Loss: 0.4028  Val_Acc: 82.538

Epoch 47: Validation loss decreased (0.402792 --> 0.402438).  Saving model ...
	 Train_Loss: 0.4422 Train_Acc: 79.061 Val_Loss: 0.4024  BEST VAL Loss: 0.4024  Val_Acc: 81.770

Epoch 48: Validation loss decreased (0.402438 --> 0.401852).  Saving model ...
	 Train_Loss: 0.4416 Train_Acc: 79.118 Val_Loss: 0.4019  BEST VAL Loss: 0.4019  Val_Acc: 82.426

Epoch 49: Validation loss decreased (0.401852 --> 0.401203).  Saving model ...
	 Train_Loss: 0.4411 Train_Acc: 78.955 Val_Loss: 0.4012  BEST VAL Loss: 0.4012  Val_Acc: 82.488

Epoch 50: Validation loss decreased (0.401203 --> 0.400589).  Saving model ...
	 Train_Loss: 0.4406 Train_Acc: 79.246 Val_Loss: 0.4006  BEST VAL Loss: 0.4006  Val_Acc: 82.547

Epoch 51: Validation loss decreased (0.400589 --> 0.400110).  Saving model ...
	 Train_Loss: 0.4400 Train_Acc: 79.062 Val_Loss: 0.4001  BEST VAL Loss: 0.4001  Val_Acc: 82.581

Epoch 52: Validation loss decreased (0.400110 --> 0.399644).  Saving model ...
	 Train_Loss: 0.4395 Train_Acc: 79.193 Val_Loss: 0.3996  BEST VAL Loss: 0.3996  Val_Acc: 82.239

Epoch 53: Validation loss decreased (0.399644 --> 0.399054).  Saving model ...
	 Train_Loss: 0.4390 Train_Acc: 79.285 Val_Loss: 0.3991  BEST VAL Loss: 0.3991  Val_Acc: 82.904

Epoch 54: Validation loss decreased (0.399054 --> 0.398675).  Saving model ...
	 Train_Loss: 0.4385 Train_Acc: 79.220 Val_Loss: 0.3987  BEST VAL Loss: 0.3987  Val_Acc: 82.600

Epoch 55: Validation loss decreased (0.398675 --> 0.398161).  Saving model ...
	 Train_Loss: 0.4380 Train_Acc: 79.188 Val_Loss: 0.3982  BEST VAL Loss: 0.3982  Val_Acc: 82.615

Epoch 56: Validation loss decreased (0.398161 --> 0.397708).  Saving model ...
	 Train_Loss: 0.4376 Train_Acc: 79.137 Val_Loss: 0.3977  BEST VAL Loss: 0.3977  Val_Acc: 82.566

Epoch 57: Validation loss decreased (0.397708 --> 0.397192).  Saving model ...
	 Train_Loss: 0.4371 Train_Acc: 79.257 Val_Loss: 0.3972  BEST VAL Loss: 0.3972  Val_Acc: 82.913

Epoch 58: Validation loss decreased (0.397192 --> 0.396745).  Saving model ...
	 Train_Loss: 0.4367 Train_Acc: 79.345 Val_Loss: 0.3967  BEST VAL Loss: 0.3967  Val_Acc: 82.674

Epoch 59: Validation loss decreased (0.396745 --> 0.396336).  Saving model ...
	 Train_Loss: 0.4362 Train_Acc: 79.309 Val_Loss: 0.3963  BEST VAL Loss: 0.3963  Val_Acc: 82.317

Epoch 60: Validation loss decreased (0.396336 --> 0.396005).  Saving model ...
	 Train_Loss: 0.4358 Train_Acc: 79.169 Val_Loss: 0.3960  BEST VAL Loss: 0.3960  Val_Acc: 82.389

Epoch 61: Validation loss decreased (0.396005 --> 0.395654).  Saving model ...
	 Train_Loss: 0.4354 Train_Acc: 79.281 Val_Loss: 0.3957  BEST VAL Loss: 0.3957  Val_Acc: 82.302

Epoch 62: Validation loss decreased (0.395654 --> 0.395511).  Saving model ...
	 Train_Loss: 0.4350 Train_Acc: 79.238 Val_Loss: 0.3955  BEST VAL Loss: 0.3955  Val_Acc: 80.702

Epoch 63: Validation loss decreased (0.395511 --> 0.395142).  Saving model ...
	 Train_Loss: 0.4346 Train_Acc: 79.310 Val_Loss: 0.3951  BEST VAL Loss: 0.3951  Val_Acc: 82.320

Epoch 64: Validation loss decreased (0.395142 --> 0.394801).  Saving model ...
	 Train_Loss: 0.4342 Train_Acc: 79.376 Val_Loss: 0.3948  BEST VAL Loss: 0.3948  Val_Acc: 82.078

Epoch 65: Validation loss decreased (0.394801 --> 0.394517).  Saving model ...
	 Train_Loss: 0.4339 Train_Acc: 79.229 Val_Loss: 0.3945  BEST VAL Loss: 0.3945  Val_Acc: 82.274

Epoch 66: Validation loss decreased (0.394517 --> 0.394178).  Saving model ...
	 Train_Loss: 0.4335 Train_Acc: 79.452 Val_Loss: 0.3942  BEST VAL Loss: 0.3942  Val_Acc: 82.718

Epoch 67: Validation loss decreased (0.394178 --> 0.393844).  Saving model ...
	 Train_Loss: 0.4331 Train_Acc: 79.432 Val_Loss: 0.3938  BEST VAL Loss: 0.3938  Val_Acc: 82.587

Epoch 68: Validation loss decreased (0.393844 --> 0.393488).  Saving model ...
	 Train_Loss: 0.4328 Train_Acc: 79.329 Val_Loss: 0.3935  BEST VAL Loss: 0.3935  Val_Acc: 82.665

Epoch 69: Validation loss decreased (0.393488 --> 0.393052).  Saving model ...
	 Train_Loss: 0.4325 Train_Acc: 79.382 Val_Loss: 0.3931  BEST VAL Loss: 0.3931  Val_Acc: 83.122

Epoch 70: Validation loss decreased (0.393052 --> 0.392846).  Saving model ...
	 Train_Loss: 0.4321 Train_Acc: 79.454 Val_Loss: 0.3928  BEST VAL Loss: 0.3928  Val_Acc: 81.913

Epoch 71: Validation loss decreased (0.392846 --> 0.392447).  Saving model ...
	 Train_Loss: 0.4318 Train_Acc: 79.436 Val_Loss: 0.3924  BEST VAL Loss: 0.3924  Val_Acc: 83.125

Epoch 72: Validation loss decreased (0.392447 --> 0.392199).  Saving model ...
	 Train_Loss: 0.4314 Train_Acc: 79.547 Val_Loss: 0.3922  BEST VAL Loss: 0.3922  Val_Acc: 82.575

Epoch 73: Validation loss decreased (0.392199 --> 0.392156).  Saving model ...
	 Train_Loss: 0.4311 Train_Acc: 79.506 Val_Loss: 0.3922  BEST VAL Loss: 0.3922  Val_Acc: 81.221

Epoch 74: Validation loss decreased (0.392156 --> 0.391914).  Saving model ...
	 Train_Loss: 0.4307 Train_Acc: 79.537 Val_Loss: 0.3919  BEST VAL Loss: 0.3919  Val_Acc: 82.581

Epoch 75: Validation loss decreased (0.391914 --> 0.391678).  Saving model ...
	 Train_Loss: 0.4304 Train_Acc: 79.463 Val_Loss: 0.3917  BEST VAL Loss: 0.3917  Val_Acc: 82.295

Epoch 76: Validation loss decreased (0.391678 --> 0.391422).  Saving model ...
	 Train_Loss: 0.4301 Train_Acc: 79.561 Val_Loss: 0.3914  BEST VAL Loss: 0.3914  Val_Acc: 82.435

Epoch 77: Validation loss decreased (0.391422 --> 0.391164).  Saving model ...
	 Train_Loss: 0.4298 Train_Acc: 79.619 Val_Loss: 0.3912  BEST VAL Loss: 0.3912  Val_Acc: 82.482

Epoch 78: Validation loss decreased (0.391164 --> 0.390919).  Saving model ...
	 Train_Loss: 0.4295 Train_Acc: 79.456 Val_Loss: 0.3909  BEST VAL Loss: 0.3909  Val_Acc: 82.817

Epoch 79: Validation loss decreased (0.390919 --> 0.390671).  Saving model ...
	 Train_Loss: 0.4292 Train_Acc: 79.596 Val_Loss: 0.3907  BEST VAL Loss: 0.3907  Val_Acc: 82.559

Epoch 80: Validation loss decreased (0.390671 --> 0.390485).  Saving model ...
	 Train_Loss: 0.4289 Train_Acc: 79.466 Val_Loss: 0.3905  BEST VAL Loss: 0.3905  Val_Acc: 82.115

Epoch 81: Validation loss decreased (0.390485 --> 0.390431).  Saving model ...
	 Train_Loss: 0.4286 Train_Acc: 79.514 Val_Loss: 0.3904  BEST VAL Loss: 0.3904  Val_Acc: 80.929

Epoch 82: Validation loss decreased (0.390431 --> 0.390209).  Saving model ...
	 Train_Loss: 0.4284 Train_Acc: 79.533 Val_Loss: 0.3902  BEST VAL Loss: 0.3902  Val_Acc: 82.420

Epoch 83: Validation loss decreased (0.390209 --> 0.390013).  Saving model ...
	 Train_Loss: 0.4281 Train_Acc: 79.605 Val_Loss: 0.3900  BEST VAL Loss: 0.3900  Val_Acc: 82.472

Epoch 84: Validation loss decreased (0.390013 --> 0.389814).  Saving model ...
	 Train_Loss: 0.4278 Train_Acc: 79.533 Val_Loss: 0.3898  BEST VAL Loss: 0.3898  Val_Acc: 82.460

Epoch 85: Validation loss decreased (0.389814 --> 0.389569).  Saving model ...
	 Train_Loss: 0.4276 Train_Acc: 79.413 Val_Loss: 0.3896  BEST VAL Loss: 0.3896  Val_Acc: 82.945

Epoch 86: Validation loss decreased (0.389569 --> 0.389414).  Saving model ...
	 Train_Loss: 0.4273 Train_Acc: 79.524 Val_Loss: 0.3894  BEST VAL Loss: 0.3894  Val_Acc: 81.969

Epoch 87: Validation loss decreased (0.389414 --> 0.389139).  Saving model ...
	 Train_Loss: 0.4271 Train_Acc: 79.597 Val_Loss: 0.3891  BEST VAL Loss: 0.3891  Val_Acc: 82.330

Epoch 88: Validation loss decreased (0.389139 --> 0.388878).  Saving model ...
	 Train_Loss: 0.4268 Train_Acc: 79.564 Val_Loss: 0.3889  BEST VAL Loss: 0.3889  Val_Acc: 82.997

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.4266 Train_Acc: 79.633 Val_Loss: 0.3889  BEST VAL Loss: 0.3889  Val_Acc: 79.950

Epoch 90: Validation loss decreased (0.388878 --> 0.388718).  Saving model ...
	 Train_Loss: 0.4263 Train_Acc: 79.478 Val_Loss: 0.3887  BEST VAL Loss: 0.3887  Val_Acc: 82.435

Epoch 91: Validation loss decreased (0.388718 --> 0.388501).  Saving model ...
	 Train_Loss: 0.4261 Train_Acc: 79.503 Val_Loss: 0.3885  BEST VAL Loss: 0.3885  Val_Acc: 82.525

Epoch 92: Validation loss decreased (0.388501 --> 0.388236).  Saving model ...
	 Train_Loss: 0.4259 Train_Acc: 79.550 Val_Loss: 0.3882  BEST VAL Loss: 0.3882  Val_Acc: 82.923

Epoch 93: Validation loss decreased (0.388236 --> 0.388046).  Saving model ...
	 Train_Loss: 0.4257 Train_Acc: 79.615 Val_Loss: 0.3880  BEST VAL Loss: 0.3880  Val_Acc: 81.848

Epoch 94: Validation loss decreased (0.388046 --> 0.387901).  Saving model ...
	 Train_Loss: 0.4254 Train_Acc: 79.759 Val_Loss: 0.3879  BEST VAL Loss: 0.3879  Val_Acc: 82.252

Epoch 95: Validation loss decreased (0.387901 --> 0.387770).  Saving model ...
	 Train_Loss: 0.4252 Train_Acc: 79.701 Val_Loss: 0.3878  BEST VAL Loss: 0.3878  Val_Acc: 81.795

Epoch 96: Validation loss decreased (0.387770 --> 0.387688).  Saving model ...
	 Train_Loss: 0.4250 Train_Acc: 79.565 Val_Loss: 0.3877  BEST VAL Loss: 0.3877  Val_Acc: 82.246

Epoch 97: Validation loss decreased (0.387688 --> 0.387507).  Saving model ...
	 Train_Loss: 0.4247 Train_Acc: 79.585 Val_Loss: 0.3875  BEST VAL Loss: 0.3875  Val_Acc: 82.128

Epoch 98: Validation loss decreased (0.387507 --> 0.387284).  Saving model ...
	 Train_Loss: 0.4245 Train_Acc: 79.802 Val_Loss: 0.3873  BEST VAL Loss: 0.3873  Val_Acc: 82.969

Epoch 99: Validation loss decreased (0.387284 --> 0.387096).  Saving model ...
	 Train_Loss: 0.4243 Train_Acc: 79.716 Val_Loss: 0.3871  BEST VAL Loss: 0.3871  Val_Acc: 82.041

H2O2_100.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.83      0.95      0.88    169560
           1       0.86      0.62      0.72     87993

    accuracy                           0.84    257553
   macro avg       0.84      0.78      0.80    257553
weighted avg       0.84      0.84      0.83    257553

H2O2_100.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.82      0.94      0.87     21196
           1       0.84      0.59      0.69     10999

    accuracy                           0.82     32195
   macro avg       0.83      0.77      0.78     32195
weighted avg       0.82      0.82      0.81     32195

H2O2_100.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.81      0.94      0.87     21196
           1       0.84      0.59      0.69     10999

    accuracy                           0.82     32195
   macro avg       0.83      0.76      0.78     32195
weighted avg       0.82      0.82      0.81     32195

              precision    recall  f1-score   support

           0       0.81      0.94      0.87     21196
           1       0.84      0.59      0.69     10999

    accuracy                           0.82     32195
   macro avg       0.83      0.76      0.78     32195
weighted avg       0.82      0.82      0.81     32195

H2O2_100.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.63      0.90      0.74     28584
           1       0.89      0.61      0.72     38465

    accuracy                           0.73     67049
   macro avg       0.76      0.75      0.73     67049
weighted avg       0.78      0.73      0.73     67049

              precision    recall  f1-score   support

           0       0.63      0.90      0.74     28584
           1       0.89      0.61      0.72     38465

    accuracy                           0.73     67049
   macro avg       0.76      0.75      0.73     67049
weighted avg       0.78      0.73      0.73     67049

completed
