[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '4c2f5012'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '463d9f34'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1dce118b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '3a0f8797'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_100.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_100.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_100.000_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (32205, 1276)
Number of total missing values across all columns: 31974
Data Subset Is Off
Wells held out for testing: ['K16' 'J20']
Wells to use for training, validation, and testing ['J16' 'J17' 'K17' 'K20' 'J21' 'K21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.316903).  Saving model ...
	 Train_Loss: 0.5010 Train_Acc: 72.410 Val_Loss: 0.3169  BEST VAL Loss: 0.3169  Val_Acc: 88.925

Epoch 1: Validation loss decreased (0.316903 --> 0.255814).  Saving model ...
	 Train_Loss: 0.3933 Train_Acc: 83.838 Val_Loss: 0.2558  BEST VAL Loss: 0.2558  Val_Acc: 93.847

Epoch 2: Validation loss decreased (0.255814 --> 0.220928).  Saving model ...
	 Train_Loss: 0.3326 Train_Acc: 86.423 Val_Loss: 0.2209  BEST VAL Loss: 0.2209  Val_Acc: 95.242

Epoch 3: Validation loss decreased (0.220928 --> 0.196814).  Saving model ...
	 Train_Loss: 0.2943 Train_Acc: 87.172 Val_Loss: 0.1968  BEST VAL Loss: 0.1968  Val_Acc: 95.652

Epoch 4: Validation loss decreased (0.196814 --> 0.179997).  Saving model ...
	 Train_Loss: 0.2666 Train_Acc: 87.849 Val_Loss: 0.1800  BEST VAL Loss: 0.1800  Val_Acc: 96.267

Epoch 5: Validation loss decreased (0.179997 --> 0.166635).  Saving model ...
	 Train_Loss: 0.2449 Train_Acc: 94.455 Val_Loss: 0.1666  BEST VAL Loss: 0.1666  Val_Acc: 96.555

Epoch 6: Validation loss decreased (0.166635 --> 0.155422).  Saving model ...
	 Train_Loss: 0.2281 Train_Acc: 96.522 Val_Loss: 0.1554  BEST VAL Loss: 0.1554  Val_Acc: 96.637

Epoch 7: Validation loss decreased (0.155422 --> 0.146578).  Saving model ...
	 Train_Loss: 0.2142 Train_Acc: 96.820 Val_Loss: 0.1466  BEST VAL Loss: 0.1466  Val_Acc: 96.883

Epoch 8: Validation loss decreased (0.146578 --> 0.139047).  Saving model ...
	 Train_Loss: 0.2028 Train_Acc: 96.897 Val_Loss: 0.1390  BEST VAL Loss: 0.1390  Val_Acc: 96.924

Epoch 9: Validation loss decreased (0.139047 --> 0.132436).  Saving model ...
	 Train_Loss: 0.1933 Train_Acc: 96.881 Val_Loss: 0.1324  BEST VAL Loss: 0.1324  Val_Acc: 97.375

Epoch 10: Validation loss decreased (0.132436 --> 0.126903).  Saving model ...
	 Train_Loss: 0.1848 Train_Acc: 97.240 Val_Loss: 0.1269  BEST VAL Loss: 0.1269  Val_Acc: 97.047

Epoch 11: Validation loss decreased (0.126903 --> 0.121887).  Saving model ...
	 Train_Loss: 0.1770 Train_Acc: 97.630 Val_Loss: 0.1219  BEST VAL Loss: 0.1219  Val_Acc: 97.293

Epoch 12: Validation loss decreased (0.121887 --> 0.117680).  Saving model ...
	 Train_Loss: 0.1699 Train_Acc: 97.825 Val_Loss: 0.1177  BEST VAL Loss: 0.1177  Val_Acc: 97.457

Epoch 13: Validation loss decreased (0.117680 --> 0.113656).  Saving model ...
	 Train_Loss: 0.1637 Train_Acc: 97.882 Val_Loss: 0.1137  BEST VAL Loss: 0.1137  Val_Acc: 97.498

Epoch 14: Validation loss decreased (0.113656 --> 0.110393).  Saving model ...
	 Train_Loss: 0.1582 Train_Acc: 98.010 Val_Loss: 0.1104  BEST VAL Loss: 0.1104  Val_Acc: 97.457

Epoch 15: Validation loss decreased (0.110393 --> 0.107256).  Saving model ...
	 Train_Loss: 0.1531 Train_Acc: 98.005 Val_Loss: 0.1073  BEST VAL Loss: 0.1073  Val_Acc: 97.498

Epoch 16: Validation loss decreased (0.107256 --> 0.104549).  Saving model ...
	 Train_Loss: 0.1484 Train_Acc: 98.102 Val_Loss: 0.1045  BEST VAL Loss: 0.1045  Val_Acc: 97.457

Epoch 17: Validation loss decreased (0.104549 --> 0.102272).  Saving model ...
	 Train_Loss: 0.1442 Train_Acc: 98.159 Val_Loss: 0.1023  BEST VAL Loss: 0.1023  Val_Acc: 97.580

Epoch 18: Validation loss decreased (0.102272 --> 0.100021).  Saving model ...
	 Train_Loss: 0.1403 Train_Acc: 98.035 Val_Loss: 0.1000  BEST VAL Loss: 0.1000  Val_Acc: 97.580

Epoch 19: Validation loss decreased (0.100021 --> 0.098361).  Saving model ...
	 Train_Loss: 0.1365 Train_Acc: 98.364 Val_Loss: 0.0984  BEST VAL Loss: 0.0984  Val_Acc: 97.744

Epoch 20: Validation loss decreased (0.098361 --> 0.096529).  Saving model ...
	 Train_Loss: 0.1331 Train_Acc: 98.292 Val_Loss: 0.0965  BEST VAL Loss: 0.0965  Val_Acc: 97.867

Epoch 21: Validation loss decreased (0.096529 --> 0.094915).  Saving model ...
	 Train_Loss: 0.1301 Train_Acc: 98.189 Val_Loss: 0.0949  BEST VAL Loss: 0.0949  Val_Acc: 97.539

Epoch 22: Validation loss decreased (0.094915 --> 0.093147).  Saving model ...
	 Train_Loss: 0.1271 Train_Acc: 98.292 Val_Loss: 0.0931  BEST VAL Loss: 0.0931  Val_Acc: 97.949

Epoch 23: Validation loss decreased (0.093147 --> 0.091719).  Saving model ...
	 Train_Loss: 0.1243 Train_Acc: 98.410 Val_Loss: 0.0917  BEST VAL Loss: 0.0917  Val_Acc: 97.703

Epoch 24: Validation loss decreased (0.091719 --> 0.090246).  Saving model ...
	 Train_Loss: 0.1217 Train_Acc: 98.369 Val_Loss: 0.0902  BEST VAL Loss: 0.0902  Val_Acc: 97.990

Epoch 25: Validation loss decreased (0.090246 --> 0.089293).  Saving model ...
	 Train_Loss: 0.1193 Train_Acc: 98.343 Val_Loss: 0.0893  BEST VAL Loss: 0.0893  Val_Acc: 97.621

Epoch 26: Validation loss decreased (0.089293 --> 0.088135).  Saving model ...
	 Train_Loss: 0.1169 Train_Acc: 98.564 Val_Loss: 0.0881  BEST VAL Loss: 0.0881  Val_Acc: 97.949

Epoch 27: Validation loss decreased (0.088135 --> 0.086836).  Saving model ...
	 Train_Loss: 0.1146 Train_Acc: 98.630 Val_Loss: 0.0868  BEST VAL Loss: 0.0868  Val_Acc: 97.908

Epoch 28: Validation loss decreased (0.086836 --> 0.085541).  Saving model ...
	 Train_Loss: 0.1125 Train_Acc: 98.436 Val_Loss: 0.0855  BEST VAL Loss: 0.0855  Val_Acc: 98.154

Epoch 29: Validation loss decreased (0.085541 --> 0.084882).  Saving model ...
	 Train_Loss: 0.1105 Train_Acc: 98.672 Val_Loss: 0.0849  BEST VAL Loss: 0.0849  Val_Acc: 98.072

Epoch 30: Validation loss decreased (0.084882 --> 0.083956).  Saving model ...
	 Train_Loss: 0.1086 Train_Acc: 98.569 Val_Loss: 0.0840  BEST VAL Loss: 0.0840  Val_Acc: 97.867

Epoch 31: Validation loss decreased (0.083956 --> 0.083111).  Saving model ...
	 Train_Loss: 0.1066 Train_Acc: 98.820 Val_Loss: 0.0831  BEST VAL Loss: 0.0831  Val_Acc: 97.785

Epoch 32: Validation loss decreased (0.083111 --> 0.082497).  Saving model ...
	 Train_Loss: 0.1048 Train_Acc: 98.764 Val_Loss: 0.0825  BEST VAL Loss: 0.0825  Val_Acc: 97.662

Epoch 33: Validation loss decreased (0.082497 --> 0.081924).  Saving model ...
	 Train_Loss: 0.1032 Train_Acc: 98.559 Val_Loss: 0.0819  BEST VAL Loss: 0.0819  Val_Acc: 98.031

Epoch 34: Validation loss decreased (0.081924 --> 0.081355).  Saving model ...
	 Train_Loss: 0.1016 Train_Acc: 98.672 Val_Loss: 0.0814  BEST VAL Loss: 0.0814  Val_Acc: 97.826

Epoch 35: Validation loss decreased (0.081355 --> 0.080785).  Saving model ...
	 Train_Loss: 0.1000 Train_Acc: 98.682 Val_Loss: 0.0808  BEST VAL Loss: 0.0808  Val_Acc: 98.113

Epoch 36: Validation loss decreased (0.080785 --> 0.080305).  Saving model ...
	 Train_Loss: 0.0985 Train_Acc: 98.707 Val_Loss: 0.0803  BEST VAL Loss: 0.0803  Val_Acc: 98.072

Epoch 37: Validation loss decreased (0.080305 --> 0.080091).  Saving model ...
	 Train_Loss: 0.0971 Train_Acc: 98.784 Val_Loss: 0.0801  BEST VAL Loss: 0.0801  Val_Acc: 97.908

Epoch 38: Validation loss decreased (0.080091 --> 0.079620).  Saving model ...
	 Train_Loss: 0.0958 Train_Acc: 98.697 Val_Loss: 0.0796  BEST VAL Loss: 0.0796  Val_Acc: 97.826

Epoch 39: Validation loss decreased (0.079620 --> 0.079264).  Saving model ...
	 Train_Loss: 0.0945 Train_Acc: 98.707 Val_Loss: 0.0793  BEST VAL Loss: 0.0793  Val_Acc: 98.195

Epoch 40: Validation loss decreased (0.079264 --> 0.078859).  Saving model ...
	 Train_Loss: 0.0933 Train_Acc: 98.610 Val_Loss: 0.0789  BEST VAL Loss: 0.0789  Val_Acc: 97.867

Epoch 41: Validation loss decreased (0.078859 --> 0.078723).  Saving model ...
	 Train_Loss: 0.0921 Train_Acc: 98.815 Val_Loss: 0.0787  BEST VAL Loss: 0.0787  Val_Acc: 97.867

Epoch 42: Validation loss decreased (0.078723 --> 0.078458).  Saving model ...
	 Train_Loss: 0.0911 Train_Acc: 98.420 Val_Loss: 0.0785  BEST VAL Loss: 0.0785  Val_Acc: 97.744

Epoch 43: Validation loss decreased (0.078458 --> 0.077983).  Saving model ...
	 Train_Loss: 0.0902 Train_Acc: 98.389 Val_Loss: 0.0780  BEST VAL Loss: 0.0780  Val_Acc: 97.785

Epoch 44: Validation loss decreased (0.077983 --> 0.077593).  Saving model ...
	 Train_Loss: 0.0892 Train_Acc: 98.559 Val_Loss: 0.0776  BEST VAL Loss: 0.0776  Val_Acc: 97.990

Epoch 45: Validation loss decreased (0.077593 --> 0.077504).  Saving model ...
	 Train_Loss: 0.0882 Train_Acc: 98.589 Val_Loss: 0.0775  BEST VAL Loss: 0.0775  Val_Acc: 97.826

Epoch 46: Validation loss decreased (0.077504 --> 0.077092).  Saving model ...
	 Train_Loss: 0.0874 Train_Acc: 98.569 Val_Loss: 0.0771  BEST VAL Loss: 0.0771  Val_Acc: 97.785

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.0864 Train_Acc: 98.687 Val_Loss: 0.0771  BEST VAL Loss: 0.0771  Val_Acc: 97.990

Epoch 48: Validation loss decreased (0.077092 --> 0.076960).  Saving model ...
	 Train_Loss: 0.0855 Train_Acc: 98.866 Val_Loss: 0.0770  BEST VAL Loss: 0.0770  Val_Acc: 98.031

Epoch 49: Validation loss decreased (0.076960 --> 0.076900).  Saving model ...
	 Train_Loss: 0.0846 Train_Acc: 98.677 Val_Loss: 0.0769  BEST VAL Loss: 0.0769  Val_Acc: 97.785

Epoch 50: Validation loss decreased (0.076900 --> 0.076712).  Saving model ...
	 Train_Loss: 0.0838 Train_Acc: 98.569 Val_Loss: 0.0767  BEST VAL Loss: 0.0767  Val_Acc: 98.154

Epoch 51: Validation loss decreased (0.076712 --> 0.076609).  Saving model ...
	 Train_Loss: 0.0831 Train_Acc: 98.641 Val_Loss: 0.0766  BEST VAL Loss: 0.0766  Val_Acc: 98.031

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.0822 Train_Acc: 98.800 Val_Loss: 0.0767  BEST VAL Loss: 0.0766  Val_Acc: 98.154

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.0814 Train_Acc: 98.805 Val_Loss: 0.0768  BEST VAL Loss: 0.0766  Val_Acc: 98.072

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.0807 Train_Acc: 98.759 Val_Loss: 0.0769  BEST VAL Loss: 0.0766  Val_Acc: 97.744

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.0801 Train_Acc: 98.543 Val_Loss: 0.0771  BEST VAL Loss: 0.0766  Val_Acc: 98.031

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.0794 Train_Acc: 98.692 Val_Loss: 0.0772  BEST VAL Loss: 0.0766  Val_Acc: 98.195

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.0788 Train_Acc: 98.661 Val_Loss: 0.0779  BEST VAL Loss: 0.0766  Val_Acc: 97.580

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.0782 Train_Acc: 98.656 Val_Loss: 0.0783  BEST VAL Loss: 0.0766  Val_Acc: 97.949

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.0776 Train_Acc: 98.779 Val_Loss: 0.0783  BEST VAL Loss: 0.0766  Val_Acc: 98.195

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.0770 Train_Acc: 98.872 Val_Loss: 0.0787  BEST VAL Loss: 0.0766  Val_Acc: 97.949

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.0765 Train_Acc: 98.574 Val_Loss: 0.0786  BEST VAL Loss: 0.0766  Val_Acc: 98.154

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.0759 Train_Acc: 98.769 Val_Loss: 0.0788  BEST VAL Loss: 0.0766  Val_Acc: 97.744

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.0753 Train_Acc: 98.723 Val_Loss: 0.0792  BEST VAL Loss: 0.0766  Val_Acc: 97.826

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.0748 Train_Acc: 98.754 Val_Loss: 0.0791  BEST VAL Loss: 0.0766  Val_Acc: 98.031

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.0743 Train_Acc: 98.769 Val_Loss: 0.0792  BEST VAL Loss: 0.0766  Val_Acc: 97.785

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.0737 Train_Acc: 98.872 Val_Loss: 0.0794  BEST VAL Loss: 0.0766  Val_Acc: 97.867

Epoch 67: Validation loss did not decrease
Early stopped at epoch : 67
LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025
              precision    recall  f1-score   support

           0       1.00      0.99      1.00      9892
           1       0.99      1.00      1.00      9604

    accuracy                           1.00     19496
   macro avg       1.00      1.00      1.00     19496
weighted avg       1.00      1.00      1.00     19496

LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.98      0.98      1237
           1       0.98      0.98      0.98      1201

    accuracy                           0.98      2438
   macro avg       0.98      0.98      0.98      2438
weighted avg       0.98      0.98      0.98      2438

LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.99      0.98      1236
           1       0.99      0.98      0.98      1201

    accuracy                           0.98      2437
   macro avg       0.98      0.98      0.98      2437
weighted avg       0.98      0.98      0.98      2437

              precision    recall  f1-score   support

           0       0.98      0.99      0.98      1236
           1       0.99      0.98      0.98      1201

    accuracy                           0.98      2437
   macro avg       0.98      0.98      0.98      2437
weighted avg       0.98      0.98      0.98      2437

LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.95      0.97      3622
           1       0.96      0.99      0.97      4212

    accuracy                           0.97      7834
   macro avg       0.97      0.97      0.97      7834
weighted avg       0.97      0.97      0.97      7834

              precision    recall  f1-score   support

           0       0.98      0.95      0.97      3622
           1       0.96      0.99      0.97      4212

    accuracy                           0.97      7834
   macro avg       0.97      0.97      0.97      7834
weighted avg       0.97      0.97      0.97      7834

completed
