[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'fb3b0f2f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e7ba0b38'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'e6dd33b8'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'faa0286d'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: DMSO_0.100_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: DMSO_0.100_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (311045, 1270)
Number of total missing values across all columns: 622090
Data Subset Is Off
Wells held out for testing: ['J06' 'L10']
Wells to use for training, validation, and testing ['B06' 'C06' 'B07' 'C07' 'I06' 'I07' 'J07' 'L05' 'L11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.502623).  Saving model ...
	 Train_Loss: 0.5619 Train_Acc: 71.873 Val_Loss: 0.5026  BEST VAL Loss: 0.5026  Val_Acc: 75.350

Epoch 1: Validation loss decreased (0.502623 --> 0.483768).  Saving model ...
	 Train_Loss: 0.5325 Train_Acc: 75.817 Val_Loss: 0.4838  BEST VAL Loss: 0.4838  Val_Acc: 76.493

Epoch 2: Validation loss decreased (0.483768 --> 0.469381).  Saving model ...
	 Train_Loss: 0.5122 Train_Acc: 77.326 Val_Loss: 0.4694  BEST VAL Loss: 0.4694  Val_Acc: 79.216

Epoch 3: Validation loss decreased (0.469381 --> 0.457548).  Saving model ...
	 Train_Loss: 0.4956 Train_Acc: 78.956 Val_Loss: 0.4575  BEST VAL Loss: 0.4575  Val_Acc: 81.014

Epoch 4: Validation loss decreased (0.457548 --> 0.444646).  Saving model ...
	 Train_Loss: 0.4820 Train_Acc: 80.056 Val_Loss: 0.4446  BEST VAL Loss: 0.4446  Val_Acc: 82.040

Epoch 5: Validation loss decreased (0.444646 --> 0.434675).  Saving model ...
	 Train_Loss: 0.4707 Train_Acc: 80.732 Val_Loss: 0.4347  BEST VAL Loss: 0.4347  Val_Acc: 82.008

Epoch 6: Validation loss decreased (0.434675 --> 0.425568).  Saving model ...
	 Train_Loss: 0.4612 Train_Acc: 81.268 Val_Loss: 0.4256  BEST VAL Loss: 0.4256  Val_Acc: 82.935

Epoch 7: Validation loss decreased (0.425568 --> 0.418281).  Saving model ...
	 Train_Loss: 0.4530 Train_Acc: 81.701 Val_Loss: 0.4183  BEST VAL Loss: 0.4183  Val_Acc: 83.410

Epoch 8: Validation loss decreased (0.418281 --> 0.411794).  Saving model ...
	 Train_Loss: 0.4458 Train_Acc: 82.105 Val_Loss: 0.4118  BEST VAL Loss: 0.4118  Val_Acc: 83.626

Epoch 9: Validation loss decreased (0.411794 --> 0.406476).  Saving model ...
	 Train_Loss: 0.4395 Train_Acc: 82.285 Val_Loss: 0.4065  BEST VAL Loss: 0.4065  Val_Acc: 83.630

Epoch 10: Validation loss decreased (0.406476 --> 0.401007).  Saving model ...
	 Train_Loss: 0.4340 Train_Acc: 82.544 Val_Loss: 0.4010  BEST VAL Loss: 0.4010  Val_Acc: 84.005

Epoch 11: Validation loss decreased (0.401007 --> 0.396166).  Saving model ...
	 Train_Loss: 0.4290 Train_Acc: 82.724 Val_Loss: 0.3962  BEST VAL Loss: 0.3962  Val_Acc: 84.077

Epoch 12: Validation loss decreased (0.396166 --> 0.392381).  Saving model ...
	 Train_Loss: 0.4244 Train_Acc: 82.878 Val_Loss: 0.3924  BEST VAL Loss: 0.3924  Val_Acc: 83.502

Epoch 13: Validation loss decreased (0.392381 --> 0.388828).  Saving model ...
	 Train_Loss: 0.4204 Train_Acc: 83.048 Val_Loss: 0.3888  BEST VAL Loss: 0.3888  Val_Acc: 84.472

Epoch 14: Validation loss decreased (0.388828 --> 0.386011).  Saving model ...
	 Train_Loss: 0.4168 Train_Acc: 83.177 Val_Loss: 0.3860  BEST VAL Loss: 0.3860  Val_Acc: 84.273

Epoch 15: Validation loss decreased (0.386011 --> 0.382919).  Saving model ...
	 Train_Loss: 0.4134 Train_Acc: 83.312 Val_Loss: 0.3829  BEST VAL Loss: 0.3829  Val_Acc: 84.189

Epoch 16: Validation loss decreased (0.382919 --> 0.380313).  Saving model ...
	 Train_Loss: 0.4102 Train_Acc: 83.528 Val_Loss: 0.3803  BEST VAL Loss: 0.3803  Val_Acc: 84.464

Epoch 17: Validation loss decreased (0.380313 --> 0.377632).  Saving model ...
	 Train_Loss: 0.4073 Train_Acc: 83.479 Val_Loss: 0.3776  BEST VAL Loss: 0.3776  Val_Acc: 84.716

Epoch 18: Validation loss decreased (0.377632 --> 0.375307).  Saving model ...
	 Train_Loss: 0.4046 Train_Acc: 83.606 Val_Loss: 0.3753  BEST VAL Loss: 0.3753  Val_Acc: 84.644

Epoch 19: Validation loss decreased (0.375307 --> 0.373053).  Saving model ...
	 Train_Loss: 0.4022 Train_Acc: 83.619 Val_Loss: 0.3731  BEST VAL Loss: 0.3731  Val_Acc: 84.744

Epoch 20: Validation loss decreased (0.373053 --> 0.371196).  Saving model ...
	 Train_Loss: 0.3998 Train_Acc: 83.818 Val_Loss: 0.3712  BEST VAL Loss: 0.3712  Val_Acc: 84.744

Epoch 21: Validation loss decreased (0.371196 --> 0.369168).  Saving model ...
	 Train_Loss: 0.3977 Train_Acc: 83.898 Val_Loss: 0.3692  BEST VAL Loss: 0.3692  Val_Acc: 85.059

Epoch 22: Validation loss decreased (0.369168 --> 0.367371).  Saving model ...
	 Train_Loss: 0.3956 Train_Acc: 84.029 Val_Loss: 0.3674  BEST VAL Loss: 0.3674  Val_Acc: 84.792

Epoch 23: Validation loss decreased (0.367371 --> 0.365754).  Saving model ...
	 Train_Loss: 0.3936 Train_Acc: 84.095 Val_Loss: 0.3658  BEST VAL Loss: 0.3658  Val_Acc: 84.892

Epoch 24: Validation loss decreased (0.365754 --> 0.364400).  Saving model ...
	 Train_Loss: 0.3918 Train_Acc: 84.090 Val_Loss: 0.3644  BEST VAL Loss: 0.3644  Val_Acc: 84.688

Epoch 25: Validation loss decreased (0.364400 --> 0.362623).  Saving model ...
	 Train_Loss: 0.3901 Train_Acc: 84.027 Val_Loss: 0.3626  BEST VAL Loss: 0.3626  Val_Acc: 85.223

Epoch 26: Validation loss decreased (0.362623 --> 0.361017).  Saving model ...
	 Train_Loss: 0.3885 Train_Acc: 84.189 Val_Loss: 0.3610  BEST VAL Loss: 0.3610  Val_Acc: 84.872

Epoch 27: Validation loss decreased (0.361017 --> 0.359852).  Saving model ...
	 Train_Loss: 0.3869 Train_Acc: 84.298 Val_Loss: 0.3599  BEST VAL Loss: 0.3599  Val_Acc: 84.999

Epoch 28: Validation loss decreased (0.359852 --> 0.358593).  Saving model ...
	 Train_Loss: 0.3853 Train_Acc: 84.381 Val_Loss: 0.3586  BEST VAL Loss: 0.3586  Val_Acc: 85.307

Epoch 29: Validation loss decreased (0.358593 --> 0.357848).  Saving model ...
	 Train_Loss: 0.3839 Train_Acc: 84.390 Val_Loss: 0.3578  BEST VAL Loss: 0.3578  Val_Acc: 84.632

Epoch 30: Validation loss decreased (0.357848 --> 0.356635).  Saving model ...
	 Train_Loss: 0.3825 Train_Acc: 84.444 Val_Loss: 0.3566  BEST VAL Loss: 0.3566  Val_Acc: 85.235

Epoch 31: Validation loss decreased (0.356635 --> 0.355630).  Saving model ...
	 Train_Loss: 0.3812 Train_Acc: 84.448 Val_Loss: 0.3556  BEST VAL Loss: 0.3556  Val_Acc: 85.563

Epoch 32: Validation loss decreased (0.355630 --> 0.354227).  Saving model ...
	 Train_Loss: 0.3800 Train_Acc: 84.452 Val_Loss: 0.3542  BEST VAL Loss: 0.3542  Val_Acc: 85.359

Epoch 33: Validation loss decreased (0.354227 --> 0.353063).  Saving model ...
	 Train_Loss: 0.3788 Train_Acc: 84.501 Val_Loss: 0.3531  BEST VAL Loss: 0.3531  Val_Acc: 85.311

Epoch 34: Validation loss decreased (0.353063 --> 0.352030).  Saving model ...
	 Train_Loss: 0.3777 Train_Acc: 84.514 Val_Loss: 0.3520  BEST VAL Loss: 0.3520  Val_Acc: 85.726

Epoch 35: Validation loss decreased (0.352030 --> 0.351152).  Saving model ...
	 Train_Loss: 0.3766 Train_Acc: 84.597 Val_Loss: 0.3512  BEST VAL Loss: 0.3512  Val_Acc: 85.483

Epoch 36: Validation loss decreased (0.351152 --> 0.350167).  Saving model ...
	 Train_Loss: 0.3755 Train_Acc: 84.607 Val_Loss: 0.3502  BEST VAL Loss: 0.3502  Val_Acc: 85.487

Epoch 37: Validation loss decreased (0.350167 --> 0.349228).  Saving model ...
	 Train_Loss: 0.3745 Train_Acc: 84.650 Val_Loss: 0.3492  BEST VAL Loss: 0.3492  Val_Acc: 85.774

Epoch 38: Validation loss decreased (0.349228 --> 0.348347).  Saving model ...
	 Train_Loss: 0.3735 Train_Acc: 84.771 Val_Loss: 0.3483  BEST VAL Loss: 0.3483  Val_Acc: 85.483

Epoch 39: Validation loss decreased (0.348347 --> 0.347481).  Saving model ...
	 Train_Loss: 0.3725 Train_Acc: 84.697 Val_Loss: 0.3475  BEST VAL Loss: 0.3475  Val_Acc: 85.559

Epoch 40: Validation loss decreased (0.347481 --> 0.346638).  Saving model ...
	 Train_Loss: 0.3716 Train_Acc: 84.769 Val_Loss: 0.3466  BEST VAL Loss: 0.3466  Val_Acc: 85.467

Epoch 41: Validation loss decreased (0.346638 --> 0.346291).  Saving model ...
	 Train_Loss: 0.3707 Train_Acc: 84.730 Val_Loss: 0.3463  BEST VAL Loss: 0.3463  Val_Acc: 84.632

Epoch 42: Validation loss decreased (0.346291 --> 0.345559).  Saving model ...
	 Train_Loss: 0.3699 Train_Acc: 84.710 Val_Loss: 0.3456  BEST VAL Loss: 0.3456  Val_Acc: 85.267

Epoch 43: Validation loss decreased (0.345559 --> 0.344820).  Saving model ...
	 Train_Loss: 0.3690 Train_Acc: 84.806 Val_Loss: 0.3448  BEST VAL Loss: 0.3448  Val_Acc: 85.507

Epoch 44: Validation loss decreased (0.344820 --> 0.344075).  Saving model ...
	 Train_Loss: 0.3683 Train_Acc: 84.772 Val_Loss: 0.3441  BEST VAL Loss: 0.3441  Val_Acc: 85.650

Epoch 45: Validation loss decreased (0.344075 --> 0.343221).  Saving model ...
	 Train_Loss: 0.3675 Train_Acc: 84.846 Val_Loss: 0.3432  BEST VAL Loss: 0.3432  Val_Acc: 85.734

Epoch 46: Validation loss decreased (0.343221 --> 0.342443).  Saving model ...
	 Train_Loss: 0.3667 Train_Acc: 84.709 Val_Loss: 0.3424  BEST VAL Loss: 0.3424  Val_Acc: 85.842

Epoch 47: Validation loss decreased (0.342443 --> 0.341710).  Saving model ...
	 Train_Loss: 0.3660 Train_Acc: 84.928 Val_Loss: 0.3417  BEST VAL Loss: 0.3417  Val_Acc: 85.471

Epoch 48: Validation loss decreased (0.341710 --> 0.340940).  Saving model ...
	 Train_Loss: 0.3653 Train_Acc: 84.986 Val_Loss: 0.3409  BEST VAL Loss: 0.3409  Val_Acc: 85.826

Epoch 49: Validation loss decreased (0.340940 --> 0.340311).  Saving model ...
	 Train_Loss: 0.3646 Train_Acc: 84.897 Val_Loss: 0.3403  BEST VAL Loss: 0.3403  Val_Acc: 85.626

Epoch 50: Validation loss decreased (0.340311 --> 0.339608).  Saving model ...
	 Train_Loss: 0.3639 Train_Acc: 84.868 Val_Loss: 0.3396  BEST VAL Loss: 0.3396  Val_Acc: 85.706

Epoch 51: Validation loss decreased (0.339608 --> 0.339026).  Saving model ...
	 Train_Loss: 0.3632 Train_Acc: 84.837 Val_Loss: 0.3390  BEST VAL Loss: 0.3390  Val_Acc: 85.666

Epoch 52: Validation loss decreased (0.339026 --> 0.338446).  Saving model ...
	 Train_Loss: 0.3626 Train_Acc: 84.929 Val_Loss: 0.3384  BEST VAL Loss: 0.3384  Val_Acc: 85.878

Epoch 53: Validation loss decreased (0.338446 --> 0.338031).  Saving model ...
	 Train_Loss: 0.3620 Train_Acc: 84.929 Val_Loss: 0.3380  BEST VAL Loss: 0.3380  Val_Acc: 85.523

Epoch 54: Validation loss decreased (0.338031 --> 0.337392).  Saving model ...
	 Train_Loss: 0.3614 Train_Acc: 85.010 Val_Loss: 0.3374  BEST VAL Loss: 0.3374  Val_Acc: 85.950

Epoch 55: Validation loss decreased (0.337392 --> 0.336777).  Saving model ...
	 Train_Loss: 0.3608 Train_Acc: 84.991 Val_Loss: 0.3368  BEST VAL Loss: 0.3368  Val_Acc: 85.942

Epoch 56: Validation loss decreased (0.336777 --> 0.336200).  Saving model ...
	 Train_Loss: 0.3603 Train_Acc: 84.999 Val_Loss: 0.3362  BEST VAL Loss: 0.3362  Val_Acc: 85.686

Epoch 57: Validation loss decreased (0.336200 --> 0.335712).  Saving model ...
	 Train_Loss: 0.3597 Train_Acc: 85.005 Val_Loss: 0.3357  BEST VAL Loss: 0.3357  Val_Acc: 86.018

Epoch 58: Validation loss decreased (0.335712 --> 0.335301).  Saving model ...
	 Train_Loss: 0.3592 Train_Acc: 84.986 Val_Loss: 0.3353  BEST VAL Loss: 0.3353  Val_Acc: 85.567

Epoch 59: Validation loss decreased (0.335301 --> 0.334852).  Saving model ...
	 Train_Loss: 0.3586 Train_Acc: 85.050 Val_Loss: 0.3349  BEST VAL Loss: 0.3349  Val_Acc: 85.582

Epoch 60: Validation loss decreased (0.334852 --> 0.334285).  Saving model ...
	 Train_Loss: 0.3581 Train_Acc: 85.119 Val_Loss: 0.3343  BEST VAL Loss: 0.3343  Val_Acc: 86.206

Epoch 61: Validation loss decreased (0.334285 --> 0.334041).  Saving model ...
	 Train_Loss: 0.3576 Train_Acc: 85.119 Val_Loss: 0.3340  BEST VAL Loss: 0.3340  Val_Acc: 86.090

Epoch 62: Validation loss decreased (0.334041 --> 0.333666).  Saving model ...
	 Train_Loss: 0.3571 Train_Acc: 85.191 Val_Loss: 0.3337  BEST VAL Loss: 0.3337  Val_Acc: 85.854

Epoch 63: Validation loss decreased (0.333666 --> 0.333195).  Saving model ...
	 Train_Loss: 0.3566 Train_Acc: 85.137 Val_Loss: 0.3332  BEST VAL Loss: 0.3332  Val_Acc: 85.946

Epoch 64: Validation loss decreased (0.333195 --> 0.332733).  Saving model ...
	 Train_Loss: 0.3561 Train_Acc: 85.158 Val_Loss: 0.3327  BEST VAL Loss: 0.3327  Val_Acc: 86.154

Epoch 65: Validation loss decreased (0.332733 --> 0.332300).  Saving model ...
	 Train_Loss: 0.3557 Train_Acc: 85.177 Val_Loss: 0.3323  BEST VAL Loss: 0.3323  Val_Acc: 85.866

Epoch 66: Validation loss decreased (0.332300 --> 0.331863).  Saving model ...
	 Train_Loss: 0.3552 Train_Acc: 85.134 Val_Loss: 0.3319  BEST VAL Loss: 0.3319  Val_Acc: 85.842

Epoch 67: Validation loss decreased (0.331863 --> 0.331443).  Saving model ...
	 Train_Loss: 0.3547 Train_Acc: 85.210 Val_Loss: 0.3314  BEST VAL Loss: 0.3314  Val_Acc: 85.826

Epoch 68: Validation loss decreased (0.331443 --> 0.331144).  Saving model ...
	 Train_Loss: 0.3543 Train_Acc: 85.093 Val_Loss: 0.3311  BEST VAL Loss: 0.3311  Val_Acc: 85.946

Epoch 69: Validation loss decreased (0.331144 --> 0.330683).  Saving model ...
	 Train_Loss: 0.3539 Train_Acc: 85.208 Val_Loss: 0.3307  BEST VAL Loss: 0.3307  Val_Acc: 86.166

Epoch 70: Validation loss decreased (0.330683 --> 0.330309).  Saving model ...
	 Train_Loss: 0.3535 Train_Acc: 85.186 Val_Loss: 0.3303  BEST VAL Loss: 0.3303  Val_Acc: 85.966

Epoch 71: Validation loss decreased (0.330309 --> 0.329970).  Saving model ...
	 Train_Loss: 0.3531 Train_Acc: 85.175 Val_Loss: 0.3300  BEST VAL Loss: 0.3300  Val_Acc: 85.882

Epoch 72: Validation loss decreased (0.329970 --> 0.329612).  Saving model ...
	 Train_Loss: 0.3527 Train_Acc: 85.220 Val_Loss: 0.3296  BEST VAL Loss: 0.3296  Val_Acc: 86.018

Epoch 73: Validation loss decreased (0.329612 --> 0.329268).  Saving model ...
	 Train_Loss: 0.3523 Train_Acc: 85.214 Val_Loss: 0.3293  BEST VAL Loss: 0.3293  Val_Acc: 86.353

Epoch 74: Validation loss decreased (0.329268 --> 0.328859).  Saving model ...
	 Train_Loss: 0.3519 Train_Acc: 85.252 Val_Loss: 0.3289  BEST VAL Loss: 0.3289  Val_Acc: 86.158

Epoch 75: Validation loss decreased (0.328859 --> 0.328479).  Saving model ...
	 Train_Loss: 0.3515 Train_Acc: 85.316 Val_Loss: 0.3285  BEST VAL Loss: 0.3285  Val_Acc: 86.074

Epoch 76: Validation loss decreased (0.328479 --> 0.328186).  Saving model ...
	 Train_Loss: 0.3511 Train_Acc: 85.295 Val_Loss: 0.3282  BEST VAL Loss: 0.3282  Val_Acc: 86.293

Epoch 77: Validation loss decreased (0.328186 --> 0.327864).  Saving model ...
	 Train_Loss: 0.3508 Train_Acc: 85.201 Val_Loss: 0.3279  BEST VAL Loss: 0.3279  Val_Acc: 85.930

Epoch 78: Validation loss decreased (0.327864 --> 0.327597).  Saving model ...
	 Train_Loss: 0.3504 Train_Acc: 85.271 Val_Loss: 0.3276  BEST VAL Loss: 0.3276  Val_Acc: 86.409

Epoch 79: Validation loss decreased (0.327597 --> 0.327241).  Saving model ...
	 Train_Loss: 0.3501 Train_Acc: 85.345 Val_Loss: 0.3272  BEST VAL Loss: 0.3272  Val_Acc: 86.229

Epoch 80: Validation loss decreased (0.327241 --> 0.326914).  Saving model ...
	 Train_Loss: 0.3497 Train_Acc: 85.361 Val_Loss: 0.3269  BEST VAL Loss: 0.3269  Val_Acc: 86.154

Epoch 81: Validation loss decreased (0.326914 --> 0.326657).  Saving model ...
	 Train_Loss: 0.3494 Train_Acc: 85.249 Val_Loss: 0.3267  BEST VAL Loss: 0.3267  Val_Acc: 86.186

Epoch 82: Validation loss decreased (0.326657 --> 0.326303).  Saving model ...
	 Train_Loss: 0.3491 Train_Acc: 85.227 Val_Loss: 0.3263  BEST VAL Loss: 0.3263  Val_Acc: 86.413

Epoch 83: Validation loss decreased (0.326303 --> 0.326013).  Saving model ...
	 Train_Loss: 0.3487 Train_Acc: 85.359 Val_Loss: 0.3260  BEST VAL Loss: 0.3260  Val_Acc: 86.281

Epoch 84: Validation loss decreased (0.326013 --> 0.325719).  Saving model ...
	 Train_Loss: 0.3484 Train_Acc: 85.340 Val_Loss: 0.3257  BEST VAL Loss: 0.3257  Val_Acc: 86.465

Epoch 85: Validation loss decreased (0.325719 --> 0.325461).  Saving model ...
	 Train_Loss: 0.3481 Train_Acc: 85.312 Val_Loss: 0.3255  BEST VAL Loss: 0.3255  Val_Acc: 86.034

Epoch 86: Validation loss decreased (0.325461 --> 0.325187).  Saving model ...
	 Train_Loss: 0.3478 Train_Acc: 85.386 Val_Loss: 0.3252  BEST VAL Loss: 0.3252  Val_Acc: 86.090

Epoch 87: Validation loss decreased (0.325187 --> 0.324987).  Saving model ...
	 Train_Loss: 0.3475 Train_Acc: 85.340 Val_Loss: 0.3250  BEST VAL Loss: 0.3250  Val_Acc: 86.349

Epoch 88: Validation loss decreased (0.324987 --> 0.324723).  Saving model ...
	 Train_Loss: 0.3472 Train_Acc: 85.334 Val_Loss: 0.3247  BEST VAL Loss: 0.3247  Val_Acc: 86.381

Epoch 89: Validation loss decreased (0.324723 --> 0.324409).  Saving model ...
	 Train_Loss: 0.3469 Train_Acc: 85.294 Val_Loss: 0.3244  BEST VAL Loss: 0.3244  Val_Acc: 86.353

Epoch 90: Validation loss decreased (0.324409 --> 0.324145).  Saving model ...
	 Train_Loss: 0.3466 Train_Acc: 85.303 Val_Loss: 0.3241  BEST VAL Loss: 0.3241  Val_Acc: 86.329

Epoch 91: Validation loss decreased (0.324145 --> 0.323866).  Saving model ...
	 Train_Loss: 0.3463 Train_Acc: 85.279 Val_Loss: 0.3239  BEST VAL Loss: 0.3239  Val_Acc: 85.990

Epoch 92: Validation loss decreased (0.323866 --> 0.323575).  Saving model ...
	 Train_Loss: 0.3460 Train_Acc: 85.301 Val_Loss: 0.3236  BEST VAL Loss: 0.3236  Val_Acc: 86.537

Epoch 93: Validation loss decreased (0.323575 --> 0.323313).  Saving model ...
	 Train_Loss: 0.3458 Train_Acc: 85.347 Val_Loss: 0.3233  BEST VAL Loss: 0.3233  Val_Acc: 86.621

Epoch 94: Validation loss decreased (0.323313 --> 0.323129).  Saving model ...
	 Train_Loss: 0.3455 Train_Acc: 85.449 Val_Loss: 0.3231  BEST VAL Loss: 0.3231  Val_Acc: 85.994

Epoch 95: Validation loss decreased (0.323129 --> 0.322914).  Saving model ...
	 Train_Loss: 0.3452 Train_Acc: 85.393 Val_Loss: 0.3229  BEST VAL Loss: 0.3229  Val_Acc: 86.070

Epoch 96: Validation loss decreased (0.322914 --> 0.322664).  Saving model ...
	 Train_Loss: 0.3449 Train_Acc: 85.449 Val_Loss: 0.3227  BEST VAL Loss: 0.3227  Val_Acc: 86.397

Epoch 97: Validation loss decreased (0.322664 --> 0.322431).  Saving model ...
	 Train_Loss: 0.3447 Train_Acc: 85.399 Val_Loss: 0.3224  BEST VAL Loss: 0.3224  Val_Acc: 86.214

Epoch 98: Validation loss decreased (0.322431 --> 0.322187).  Saving model ...
	 Train_Loss: 0.3444 Train_Acc: 85.328 Val_Loss: 0.3222  BEST VAL Loss: 0.3222  Val_Acc: 86.214

Epoch 99: Validation loss decreased (0.322187 --> 0.322001).  Saving model ...
	 Train_Loss: 0.3442 Train_Acc: 85.396 Val_Loss: 0.3220  BEST VAL Loss: 0.3220  Val_Acc: 86.237

DMSO_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.75      0.82      0.78    149884
           1       0.25      0.18      0.21     50422

    accuracy                           0.66    200306
   macro avg       0.50      0.50      0.50    200306
weighted avg       0.62      0.66      0.64    200306

DMSO_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.75      0.82      0.78     18736
           1       0.25      0.18      0.21      6303

    accuracy                           0.66     25039
   macro avg       0.50      0.50      0.50     25039
weighted avg       0.62      0.66      0.64     25039

DMSO_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.75      0.82      0.78     18736
           1       0.25      0.18      0.21      6303

    accuracy                           0.66     25039
   macro avg       0.50      0.50      0.50     25039
weighted avg       0.62      0.66      0.64     25039

              precision    recall  f1-score   support

           0       0.75      0.82      0.78     18736
           1       0.25      0.18      0.21      6303

    accuracy                           0.66     25039
   macro avg       0.50      0.50      0.50     25039
weighted avg       0.62      0.66      0.64     25039

DMSO_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.62      0.53     27774
           1       0.54      0.39      0.45     32887

    accuracy                           0.49     60661
   macro avg       0.50      0.50      0.49     60661
weighted avg       0.51      0.49      0.49     60661

              precision    recall  f1-score   support

           0       0.46      0.62      0.53     27774
           1       0.54      0.39      0.45     32887

    accuracy                           0.49     60661
   macro avg       0.50      0.50      0.49     60661
weighted avg       0.51      0.49      0.49     60661

completed
