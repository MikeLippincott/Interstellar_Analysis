[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '7c693860'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '953e0bfa'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '8858f34c'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'c81ec91e'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_1.000_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_1.000_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Flagellin_0.100_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (30737, 1276)
Number of total missing values across all columns: 61474
Data Subset Is Off
Wells held out for testing: ['M18' 'L22']
Wells to use for training, validation, and testing ['L18' 'L19' 'M19' 'M22' 'L23' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.684418).  Saving model ...
	 Train_Loss: 0.6925 Train_Acc: 52.852 Val_Loss: 0.6844  BEST VAL Loss: 0.6844  Val_Acc: 52.108

Epoch 1: Validation loss decreased (0.684418 --> 0.682023).  Saving model ...
	 Train_Loss: 0.6878 Train_Acc: 52.697 Val_Loss: 0.6820  BEST VAL Loss: 0.6820  Val_Acc: 55.881

Epoch 2: Validation loss decreased (0.682023 --> 0.679735).  Saving model ...
	 Train_Loss: 0.6859 Train_Acc: 54.528 Val_Loss: 0.6797  BEST VAL Loss: 0.6797  Val_Acc: 58.012

Epoch 3: Validation loss decreased (0.679735 --> 0.677066).  Saving model ...
	 Train_Loss: 0.6837 Train_Acc: 54.511 Val_Loss: 0.6771  BEST VAL Loss: 0.6771  Val_Acc: 58.278

Epoch 4: Validation loss decreased (0.677066 --> 0.676689).  Saving model ...
	 Train_Loss: 0.6823 Train_Acc: 56.398 Val_Loss: 0.6767  BEST VAL Loss: 0.6767  Val_Acc: 58.367

Epoch 5: Validation loss decreased (0.676689 --> 0.672462).  Saving model ...
	 Train_Loss: 0.6808 Train_Acc: 57.274 Val_Loss: 0.6725  BEST VAL Loss: 0.6725  Val_Acc: 61.562

Epoch 6: Validation loss decreased (0.672462 --> 0.669931).  Saving model ...
	 Train_Loss: 0.6784 Train_Acc: 58.839 Val_Loss: 0.6699  BEST VAL Loss: 0.6699  Val_Acc: 61.429

Epoch 7: Validation loss did not decrease
	 Train_Loss: 0.6760 Train_Acc: 59.938 Val_Loss: 0.6701  BEST VAL Loss: 0.6699  Val_Acc: 60.852

Epoch 8: Validation loss decreased (0.669931 --> 0.668558).  Saving model ...
	 Train_Loss: 0.6736 Train_Acc: 60.587 Val_Loss: 0.6686  BEST VAL Loss: 0.6686  Val_Acc: 62.361

Epoch 9: Validation loss decreased (0.668558 --> 0.665582).  Saving model ...
	 Train_Loss: 0.6709 Train_Acc: 61.469 Val_Loss: 0.6656  BEST VAL Loss: 0.6656  Val_Acc: 63.071

Epoch 10: Validation loss decreased (0.665582 --> 0.663051).  Saving model ...
	 Train_Loss: 0.6686 Train_Acc: 61.436 Val_Loss: 0.6631  BEST VAL Loss: 0.6631  Val_Acc: 63.249

Epoch 11: Validation loss decreased (0.663051 --> 0.661657).  Saving model ...
	 Train_Loss: 0.6670 Train_Acc: 61.930 Val_Loss: 0.6617  BEST VAL Loss: 0.6617  Val_Acc: 64.581

Epoch 12: Validation loss decreased (0.661657 --> 0.659890).  Saving model ...
	 Train_Loss: 0.6652 Train_Acc: 61.408 Val_Loss: 0.6599  BEST VAL Loss: 0.6599  Val_Acc: 64.403

Epoch 13: Validation loss decreased (0.659890 --> 0.657857).  Saving model ...
	 Train_Loss: 0.6637 Train_Acc: 61.730 Val_Loss: 0.6579  BEST VAL Loss: 0.6579  Val_Acc: 64.492

Epoch 14: Validation loss decreased (0.657857 --> 0.655683).  Saving model ...
	 Train_Loss: 0.6625 Train_Acc: 61.697 Val_Loss: 0.6557  BEST VAL Loss: 0.6557  Val_Acc: 64.758

Epoch 15: Validation loss decreased (0.655683 --> 0.654238).  Saving model ...
	 Train_Loss: 0.6608 Train_Acc: 62.929 Val_Loss: 0.6542  BEST VAL Loss: 0.6542  Val_Acc: 66.090

Epoch 16: Validation loss decreased (0.654238 --> 0.651870).  Saving model ...
	 Train_Loss: 0.6585 Train_Acc: 64.194 Val_Loss: 0.6519  BEST VAL Loss: 0.6519  Val_Acc: 65.690

Epoch 17: Validation loss decreased (0.651870 --> 0.650928).  Saving model ...
	 Train_Loss: 0.6570 Train_Acc: 63.927 Val_Loss: 0.6509  BEST VAL Loss: 0.6509  Val_Acc: 65.246

Epoch 18: Validation loss decreased (0.650928 --> 0.649313).  Saving model ...
	 Train_Loss: 0.6557 Train_Acc: 63.977 Val_Loss: 0.6493  BEST VAL Loss: 0.6493  Val_Acc: 67.554

Epoch 19: Validation loss decreased (0.649313 --> 0.648188).  Saving model ...
	 Train_Loss: 0.6542 Train_Acc: 64.677 Val_Loss: 0.6482  BEST VAL Loss: 0.6482  Val_Acc: 64.536

Epoch 20: Validation loss decreased (0.648188 --> 0.647564).  Saving model ...
	 Train_Loss: 0.6539 Train_Acc: 61.514 Val_Loss: 0.6476  BEST VAL Loss: 0.6476  Val_Acc: 63.560

Epoch 21: Validation loss decreased (0.647564 --> 0.646812).  Saving model ...
	 Train_Loss: 0.6534 Train_Acc: 61.392 Val_Loss: 0.6468  BEST VAL Loss: 0.6468  Val_Acc: 65.246

Epoch 22: Validation loss decreased (0.646812 --> 0.645813).  Saving model ...
	 Train_Loss: 0.6528 Train_Acc: 63.051 Val_Loss: 0.6458  BEST VAL Loss: 0.6458  Val_Acc: 66.045

Epoch 23: Validation loss decreased (0.645813 --> 0.645069).  Saving model ...
	 Train_Loss: 0.6519 Train_Acc: 64.249 Val_Loss: 0.6451  BEST VAL Loss: 0.6451  Val_Acc: 66.800

Epoch 24: Validation loss decreased (0.645069 --> 0.644112).  Saving model ...
	 Train_Loss: 0.6512 Train_Acc: 64.155 Val_Loss: 0.6441  BEST VAL Loss: 0.6441  Val_Acc: 66.667

Epoch 25: Validation loss decreased (0.644112 --> 0.643014).  Saving model ...
	 Train_Loss: 0.6503 Train_Acc: 64.954 Val_Loss: 0.6430  BEST VAL Loss: 0.6430  Val_Acc: 67.155

Epoch 26: Validation loss decreased (0.643014 --> 0.642288).  Saving model ...
	 Train_Loss: 0.6495 Train_Acc: 63.545 Val_Loss: 0.6423  BEST VAL Loss: 0.6423  Val_Acc: 69.063

Epoch 27: Validation loss decreased (0.642288 --> 0.641242).  Saving model ...
	 Train_Loss: 0.6485 Train_Acc: 65.686 Val_Loss: 0.6412  BEST VAL Loss: 0.6412  Val_Acc: 67.111

Epoch 28: Validation loss decreased (0.641242 --> 0.640898).  Saving model ...
	 Train_Loss: 0.6479 Train_Acc: 64.937 Val_Loss: 0.6409  BEST VAL Loss: 0.6409  Val_Acc: 65.957

Epoch 29: Validation loss did not decrease
	 Train_Loss: 0.6475 Train_Acc: 63.961 Val_Loss: 0.6411  BEST VAL Loss: 0.6409  Val_Acc: 62.406

Epoch 30: Validation loss decreased (0.640898 --> 0.640202).  Saving model ...
	 Train_Loss: 0.6474 Train_Acc: 61.919 Val_Loss: 0.6402  BEST VAL Loss: 0.6402  Val_Acc: 64.758

Epoch 31: Validation loss decreased (0.640202 --> 0.639743).  Saving model ...
	 Train_Loss: 0.6469 Train_Acc: 64.233 Val_Loss: 0.6397  BEST VAL Loss: 0.6397  Val_Acc: 66.001

Epoch 32: Validation loss decreased (0.639743 --> 0.639255).  Saving model ...
	 Train_Loss: 0.6462 Train_Acc: 64.088 Val_Loss: 0.6393  BEST VAL Loss: 0.6393  Val_Acc: 66.667

Epoch 33: Validation loss decreased (0.639255 --> 0.638156).  Saving model ...
	 Train_Loss: 0.6453 Train_Acc: 64.926 Val_Loss: 0.6382  BEST VAL Loss: 0.6382  Val_Acc: 67.421

Epoch 34: Validation loss decreased (0.638156 --> 0.637724).  Saving model ...
	 Train_Loss: 0.6447 Train_Acc: 64.832 Val_Loss: 0.6377  BEST VAL Loss: 0.6377  Val_Acc: 66.400

Epoch 35: Validation loss decreased (0.637724 --> 0.636962).  Saving model ...
	 Train_Loss: 0.6440 Train_Acc: 65.281 Val_Loss: 0.6370  BEST VAL Loss: 0.6370  Val_Acc: 66.578

Epoch 36: Validation loss decreased (0.636962 --> 0.636314).  Saving model ...
	 Train_Loss: 0.6435 Train_Acc: 63.872 Val_Loss: 0.6363  BEST VAL Loss: 0.6363  Val_Acc: 65.468

Epoch 37: Validation loss decreased (0.636314 --> 0.635613).  Saving model ...
	 Train_Loss: 0.6425 Train_Acc: 65.548 Val_Loss: 0.6356  BEST VAL Loss: 0.6356  Val_Acc: 67.599

Epoch 38: Validation loss decreased (0.635613 --> 0.634914).  Saving model ...
	 Train_Loss: 0.6416 Train_Acc: 65.564 Val_Loss: 0.6349  BEST VAL Loss: 0.6349  Val_Acc: 67.377

Epoch 39: Validation loss decreased (0.634914 --> 0.634014).  Saving model ...
	 Train_Loss: 0.6409 Train_Acc: 65.270 Val_Loss: 0.6340  BEST VAL Loss: 0.6340  Val_Acc: 67.554

Epoch 40: Validation loss decreased (0.634014 --> 0.633049).  Saving model ...
	 Train_Loss: 0.6399 Train_Acc: 66.247 Val_Loss: 0.6330  BEST VAL Loss: 0.6330  Val_Acc: 68.531

Epoch 41: Validation loss decreased (0.633049 --> 0.631961).  Saving model ...
	 Train_Loss: 0.6391 Train_Acc: 66.358 Val_Loss: 0.6320  BEST VAL Loss: 0.6320  Val_Acc: 68.043

Epoch 42: Validation loss decreased (0.631961 --> 0.631098).  Saving model ...
	 Train_Loss: 0.6382 Train_Acc: 66.685 Val_Loss: 0.6311  BEST VAL Loss: 0.6311  Val_Acc: 67.377

Epoch 43: Validation loss decreased (0.631098 --> 0.630434).  Saving model ...
	 Train_Loss: 0.6375 Train_Acc: 66.158 Val_Loss: 0.6304  BEST VAL Loss: 0.6304  Val_Acc: 68.353

Epoch 44: Validation loss decreased (0.630434 --> 0.629784).  Saving model ...
	 Train_Loss: 0.6368 Train_Acc: 67.173 Val_Loss: 0.6298  BEST VAL Loss: 0.6298  Val_Acc: 67.599

Epoch 45: Validation loss decreased (0.629784 --> 0.629603).  Saving model ...
	 Train_Loss: 0.6361 Train_Acc: 67.001 Val_Loss: 0.6296  BEST VAL Loss: 0.6296  Val_Acc: 65.912

Epoch 46: Validation loss decreased (0.629603 --> 0.629173).  Saving model ...
	 Train_Loss: 0.6355 Train_Acc: 66.641 Val_Loss: 0.6292  BEST VAL Loss: 0.6292  Val_Acc: 67.022

Epoch 47: Validation loss decreased (0.629173 --> 0.628674).  Saving model ...
	 Train_Loss: 0.6352 Train_Acc: 65.392 Val_Loss: 0.6287  BEST VAL Loss: 0.6287  Val_Acc: 68.087

Epoch 48: Validation loss decreased (0.628674 --> 0.628485).  Saving model ...
	 Train_Loss: 0.6347 Train_Acc: 65.592 Val_Loss: 0.6285  BEST VAL Loss: 0.6285  Val_Acc: 67.998

Epoch 49: Validation loss decreased (0.628485 --> 0.627781).  Saving model ...
	 Train_Loss: 0.6342 Train_Acc: 65.958 Val_Loss: 0.6278  BEST VAL Loss: 0.6278  Val_Acc: 67.998

Epoch 50: Validation loss decreased (0.627781 --> 0.627141).  Saving model ...
	 Train_Loss: 0.6337 Train_Acc: 66.175 Val_Loss: 0.6271  BEST VAL Loss: 0.6271  Val_Acc: 66.755

Epoch 51: Validation loss decreased (0.627141 --> 0.626818).  Saving model ...
	 Train_Loss: 0.6337 Train_Acc: 64.271 Val_Loss: 0.6268  BEST VAL Loss: 0.6268  Val_Acc: 65.424

Epoch 52: Validation loss decreased (0.626818 --> 0.626522).  Saving model ...
	 Train_Loss: 0.6335 Train_Acc: 64.538 Val_Loss: 0.6265  BEST VAL Loss: 0.6265  Val_Acc: 67.332

Epoch 53: Validation loss decreased (0.626522 --> 0.626275).  Saving model ...
	 Train_Loss: 0.6331 Train_Acc: 65.409 Val_Loss: 0.6263  BEST VAL Loss: 0.6263  Val_Acc: 67.111

Epoch 54: Validation loss decreased (0.626275 --> 0.625567).  Saving model ...
	 Train_Loss: 0.6326 Train_Acc: 65.337 Val_Loss: 0.6256  BEST VAL Loss: 0.6256  Val_Acc: 67.332

Epoch 55: Validation loss decreased (0.625567 --> 0.624897).  Saving model ...
	 Train_Loss: 0.6322 Train_Acc: 65.381 Val_Loss: 0.6249  BEST VAL Loss: 0.6249  Val_Acc: 68.575

Epoch 56: Validation loss decreased (0.624897 --> 0.624821).  Saving model ...
	 Train_Loss: 0.6320 Train_Acc: 65.831 Val_Loss: 0.6248  BEST VAL Loss: 0.6248  Val_Acc: 66.090

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.6318 Train_Acc: 65.664 Val_Loss: 0.6249  BEST VAL Loss: 0.6248  Val_Acc: 64.936

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.6322 Train_Acc: 60.082 Val_Loss: 0.6253  BEST VAL Loss: 0.6248  Val_Acc: 61.163

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.6324 Train_Acc: 60.903 Val_Loss: 0.6253  BEST VAL Loss: 0.6248  Val_Acc: 61.696

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.6326 Train_Acc: 62.440 Val_Loss: 0.6260  BEST VAL Loss: 0.6248  Val_Acc: 56.458

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.6328 Train_Acc: 60.409 Val_Loss: 0.6261  BEST VAL Loss: 0.6248  Val_Acc: 63.205

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.6328 Train_Acc: 62.729 Val_Loss: 0.6262  BEST VAL Loss: 0.6248  Val_Acc: 65.424

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.6327 Train_Acc: 62.901 Val_Loss: 0.6258  BEST VAL Loss: 0.6248  Val_Acc: 64.758

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.6325 Train_Acc: 63.944 Val_Loss: 0.6253  BEST VAL Loss: 0.6248  Val_Acc: 65.069

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.6322 Train_Acc: 65.520 Val_Loss: 0.6251  BEST VAL Loss: 0.6248  Val_Acc: 66.711

Epoch 66: Validation loss decreased (0.624821 --> 0.624740).  Saving model ...
	 Train_Loss: 0.6320 Train_Acc: 64.893 Val_Loss: 0.6247  BEST VAL Loss: 0.6247  Val_Acc: 68.708

Epoch 67: Validation loss decreased (0.624740 --> 0.624443).  Saving model ...
	 Train_Loss: 0.6317 Train_Acc: 65.487 Val_Loss: 0.6244  BEST VAL Loss: 0.6244  Val_Acc: 67.776

Epoch 68: Validation loss decreased (0.624443 --> 0.624109).  Saving model ...
	 Train_Loss: 0.6316 Train_Acc: 64.405 Val_Loss: 0.6241  BEST VAL Loss: 0.6241  Val_Acc: 68.176

Epoch 69: Validation loss decreased (0.624109 --> 0.623610).  Saving model ...
	 Train_Loss: 0.6312 Train_Acc: 66.114 Val_Loss: 0.6236  BEST VAL Loss: 0.6236  Val_Acc: 68.486

Epoch 70: Validation loss decreased (0.623610 --> 0.623345).  Saving model ...
	 Train_Loss: 0.6309 Train_Acc: 66.480 Val_Loss: 0.6233  BEST VAL Loss: 0.6233  Val_Acc: 67.776

Epoch 71: Validation loss decreased (0.623345 --> 0.623162).  Saving model ...
	 Train_Loss: 0.6307 Train_Acc: 66.413 Val_Loss: 0.6232  BEST VAL Loss: 0.6232  Val_Acc: 67.599

Epoch 72: Validation loss decreased (0.623162 --> 0.622953).  Saving model ...
	 Train_Loss: 0.6307 Train_Acc: 61.774 Val_Loss: 0.6230  BEST VAL Loss: 0.6230  Val_Acc: 63.160

Epoch 73: Validation loss decreased (0.622953 --> 0.622675).  Saving model ...
	 Train_Loss: 0.6306 Train_Acc: 63.112 Val_Loss: 0.6227  BEST VAL Loss: 0.6227  Val_Acc: 67.466

Epoch 74: Validation loss decreased (0.622675 --> 0.622312).  Saving model ...
	 Train_Loss: 0.6304 Train_Acc: 63.600 Val_Loss: 0.6223  BEST VAL Loss: 0.6223  Val_Acc: 67.510

Epoch 75: Validation loss decreased (0.622312 --> 0.621839).  Saving model ...
	 Train_Loss: 0.6301 Train_Acc: 65.792 Val_Loss: 0.6218  BEST VAL Loss: 0.6218  Val_Acc: 68.398

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.6300 Train_Acc: 64.466 Val_Loss: 0.6219  BEST VAL Loss: 0.6218  Val_Acc: 65.690

Epoch 77: Validation loss decreased (0.621839 --> 0.621482).  Saving model ...
	 Train_Loss: 0.6299 Train_Acc: 63.134 Val_Loss: 0.6215  BEST VAL Loss: 0.6215  Val_Acc: 67.510

Epoch 78: Validation loss decreased (0.621482 --> 0.621099).  Saving model ...
	 Train_Loss: 0.6298 Train_Acc: 63.972 Val_Loss: 0.6211  BEST VAL Loss: 0.6211  Val_Acc: 67.909

Epoch 79: Validation loss decreased (0.621099 --> 0.620857).  Saving model ...
	 Train_Loss: 0.6295 Train_Acc: 65.620 Val_Loss: 0.6209  BEST VAL Loss: 0.6209  Val_Acc: 69.108

Epoch 80: Validation loss decreased (0.620857 --> 0.620625).  Saving model ...
	 Train_Loss: 0.6292 Train_Acc: 66.358 Val_Loss: 0.6206  BEST VAL Loss: 0.6206  Val_Acc: 68.309

Epoch 81: Validation loss decreased (0.620625 --> 0.620192).  Saving model ...
	 Train_Loss: 0.6288 Train_Acc: 67.101 Val_Loss: 0.6202  BEST VAL Loss: 0.6202  Val_Acc: 69.374

Epoch 82: Validation loss decreased (0.620192 --> 0.619945).  Saving model ...
	 Train_Loss: 0.6285 Train_Acc: 66.241 Val_Loss: 0.6199  BEST VAL Loss: 0.6199  Val_Acc: 68.220

Epoch 83: Validation loss decreased (0.619945 --> 0.619734).  Saving model ...
	 Train_Loss: 0.6283 Train_Acc: 64.921 Val_Loss: 0.6197  BEST VAL Loss: 0.6197  Val_Acc: 67.199

Epoch 84: Validation loss decreased (0.619734 --> 0.619421).  Saving model ...
	 Train_Loss: 0.6282 Train_Acc: 63.916 Val_Loss: 0.6194  BEST VAL Loss: 0.6194  Val_Acc: 68.486

Epoch 85: Validation loss decreased (0.619421 --> 0.619109).  Saving model ...
	 Train_Loss: 0.6280 Train_Acc: 65.076 Val_Loss: 0.6191  BEST VAL Loss: 0.6191  Val_Acc: 67.111

Epoch 86: Validation loss decreased (0.619109 --> 0.618924).  Saving model ...
	 Train_Loss: 0.6278 Train_Acc: 65.781 Val_Loss: 0.6189  BEST VAL Loss: 0.6189  Val_Acc: 68.043

Epoch 87: Validation loss decreased (0.618924 --> 0.618660).  Saving model ...
	 Train_Loss: 0.6275 Train_Acc: 66.380 Val_Loss: 0.6187  BEST VAL Loss: 0.6187  Val_Acc: 67.909

Epoch 88: Validation loss decreased (0.618660 --> 0.618564).  Saving model ...
	 Train_Loss: 0.6272 Train_Acc: 67.013 Val_Loss: 0.6186  BEST VAL Loss: 0.6186  Val_Acc: 67.643

Epoch 89: Validation loss decreased (0.618564 --> 0.618367).  Saving model ...
	 Train_Loss: 0.6270 Train_Acc: 65.587 Val_Loss: 0.6184  BEST VAL Loss: 0.6184  Val_Acc: 67.954

Epoch 90: Validation loss decreased (0.618367 --> 0.618124).  Saving model ...
	 Train_Loss: 0.6269 Train_Acc: 65.254 Val_Loss: 0.6181  BEST VAL Loss: 0.6181  Val_Acc: 67.022

Epoch 91: Validation loss decreased (0.618124 --> 0.617873).  Saving model ...
	 Train_Loss: 0.6267 Train_Acc: 65.476 Val_Loss: 0.6179  BEST VAL Loss: 0.6179  Val_Acc: 68.620

Epoch 92: Validation loss decreased (0.617873 --> 0.617687).  Saving model ...
	 Train_Loss: 0.6265 Train_Acc: 66.763 Val_Loss: 0.6177  BEST VAL Loss: 0.6177  Val_Acc: 68.398

Epoch 93: Validation loss decreased (0.617687 --> 0.617468).  Saving model ...
	 Train_Loss: 0.6262 Train_Acc: 66.119 Val_Loss: 0.6175  BEST VAL Loss: 0.6175  Val_Acc: 68.930

Epoch 94: Validation loss decreased (0.617468 --> 0.617404).  Saving model ...
	 Train_Loss: 0.6260 Train_Acc: 66.574 Val_Loss: 0.6174  BEST VAL Loss: 0.6174  Val_Acc: 66.933

Epoch 95: Validation loss decreased (0.617404 --> 0.617239).  Saving model ...
	 Train_Loss: 0.6258 Train_Acc: 66.114 Val_Loss: 0.6172  BEST VAL Loss: 0.6172  Val_Acc: 68.131

Epoch 96: Validation loss decreased (0.617239 --> 0.616925).  Saving model ...
	 Train_Loss: 0.6255 Train_Acc: 66.669 Val_Loss: 0.6169  BEST VAL Loss: 0.6169  Val_Acc: 68.309

Epoch 97: Validation loss decreased (0.616925 --> 0.616921).  Saving model ...
	 Train_Loss: 0.6253 Train_Acc: 67.057 Val_Loss: 0.6169  BEST VAL Loss: 0.6169  Val_Acc: 66.223

Epoch 98: Validation loss decreased (0.616921 --> 0.616629).  Saving model ...
	 Train_Loss: 0.6250 Train_Acc: 66.485 Val_Loss: 0.6166  BEST VAL Loss: 0.6166  Val_Acc: 67.865

Epoch 99: Validation loss decreased (0.616629 --> 0.616349).  Saving model ...
	 Train_Loss: 0.6247 Train_Acc: 66.885 Val_Loss: 0.6163  BEST VAL Loss: 0.6163  Val_Acc: 68.842

Flagellin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.47      0.47      8635
           1       0.52      0.53      0.52      9387

    accuracy                           0.50     18022
   macro avg       0.50      0.50      0.50     18022
weighted avg       0.50      0.50      0.50     18022

Flagellin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.46      0.47      1079
           1       0.52      0.53      0.52      1174

    accuracy                           0.50      2253
   macro avg       0.49      0.49      0.49      2253
weighted avg       0.50      0.50      0.50      2253

Flagellin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.47      0.47      1079
           1       0.51      0.52      0.51      1174

    accuracy                           0.49      2253
   macro avg       0.49      0.49      0.49      2253
weighted avg       0.49      0.49      0.49      2253

              precision    recall  f1-score   support

           0       0.47      0.47      0.47      1079
           1       0.51      0.52      0.51      1174

    accuracy                           0.49      2253
   macro avg       0.49      0.49      0.49      2253
weighted avg       0.49      0.49      0.49      2253

Flagellin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.56      0.53      4135
           1       0.49      0.43      0.46      4074

    accuracy                           0.49      8209
   macro avg       0.49      0.49      0.49      8209
weighted avg       0.49      0.49      0.49      8209

              precision    recall  f1-score   support

           0       0.50      0.56      0.53      4135
           1       0.49      0.43      0.46      4074

    accuracy                           0.49      8209
   macro avg       0.49      0.49      0.49      8209
weighted avg       0.49      0.49      0.49      8209

completed
