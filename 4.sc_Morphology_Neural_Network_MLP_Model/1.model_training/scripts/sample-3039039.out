[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1ddde5d4'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'fcc86b71'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '8ce46f4d'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'ad1956aa'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: DMSO_0.100_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: DMSO_0.100_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'LPS_0.100_DMSO_0.025']
The dimensions of the data are: (53153, 1276)
Number of total missing values across all columns: 106306
Data Subset Is Off
Wells held out for testing: ['C20' 'I14']
Wells to use for training, validation, and testing ['B14' 'C14' 'B15' 'C15' 'C16' 'C17' 'C21' 'J14' 'I15' 'J15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.600309).  Saving model ...
	 Train_Loss: 0.6360 Train_Acc: 68.999 Val_Loss: 0.6003  BEST VAL Loss: 0.6003  Val_Acc: 70.214

Epoch 1: Validation loss decreased (0.600309 --> 0.598109).  Saving model ...
	 Train_Loss: 0.6246 Train_Acc: 70.193 Val_Loss: 0.5981  BEST VAL Loss: 0.5981  Val_Acc: 70.214

Epoch 2: Validation loss decreased (0.598109 --> 0.591177).  Saving model ...
	 Train_Loss: 0.6168 Train_Acc: 70.213 Val_Loss: 0.5912  BEST VAL Loss: 0.5912  Val_Acc: 70.214

Epoch 3: Validation loss decreased (0.591177 --> 0.589984).  Saving model ...
	 Train_Loss: 0.6118 Train_Acc: 70.219 Val_Loss: 0.5900  BEST VAL Loss: 0.5900  Val_Acc: 70.214

Epoch 4: Validation loss decreased (0.589984 --> 0.588056).  Saving model ...
	 Train_Loss: 0.6083 Train_Acc: 70.219 Val_Loss: 0.5881  BEST VAL Loss: 0.5881  Val_Acc: 70.214

Epoch 5: Validation loss decreased (0.588056 --> 0.586099).  Saving model ...
	 Train_Loss: 0.6052 Train_Acc: 70.219 Val_Loss: 0.5861  BEST VAL Loss: 0.5861  Val_Acc: 70.214

Epoch 6: Validation loss decreased (0.586099 --> 0.586040).  Saving model ...
	 Train_Loss: 0.6024 Train_Acc: 70.219 Val_Loss: 0.5860  BEST VAL Loss: 0.5860  Val_Acc: 70.214

Epoch 7: Validation loss decreased (0.586040 --> 0.584095).  Saving model ...
	 Train_Loss: 0.5993 Train_Acc: 70.219 Val_Loss: 0.5841  BEST VAL Loss: 0.5841  Val_Acc: 70.214

Epoch 8: Validation loss decreased (0.584095 --> 0.583710).  Saving model ...
	 Train_Loss: 0.5970 Train_Acc: 70.222 Val_Loss: 0.5837  BEST VAL Loss: 0.5837  Val_Acc: 70.214

Epoch 9: Validation loss decreased (0.583710 --> 0.582615).  Saving model ...
	 Train_Loss: 0.5950 Train_Acc: 70.244 Val_Loss: 0.5826  BEST VAL Loss: 0.5826  Val_Acc: 70.214

Epoch 10: Validation loss decreased (0.582615 --> 0.581266).  Saving model ...
	 Train_Loss: 0.5928 Train_Acc: 70.455 Val_Loss: 0.5813  BEST VAL Loss: 0.5813  Val_Acc: 70.283

Epoch 11: Validation loss decreased (0.581266 --> 0.580370).  Saving model ...
	 Train_Loss: 0.5907 Train_Acc: 70.837 Val_Loss: 0.5804  BEST VAL Loss: 0.5804  Val_Acc: 70.647

Epoch 12: Validation loss decreased (0.580370 --> 0.578960).  Saving model ...
	 Train_Loss: 0.5885 Train_Acc: 71.165 Val_Loss: 0.5790  BEST VAL Loss: 0.5790  Val_Acc: 71.171

Epoch 13: Validation loss decreased (0.578960 --> 0.578065).  Saving model ...
	 Train_Loss: 0.5863 Train_Acc: 71.427 Val_Loss: 0.5781  BEST VAL Loss: 0.5781  Val_Acc: 70.852

Epoch 14: Validation loss decreased (0.578065 --> 0.577285).  Saving model ...
	 Train_Loss: 0.5843 Train_Acc: 71.250 Val_Loss: 0.5773  BEST VAL Loss: 0.5773  Val_Acc: 71.103

Epoch 15: Validation loss decreased (0.577285 --> 0.576050).  Saving model ...
	 Train_Loss: 0.5824 Train_Acc: 71.777 Val_Loss: 0.5761  BEST VAL Loss: 0.5761  Val_Acc: 71.308

Epoch 16: Validation loss decreased (0.576050 --> 0.574844).  Saving model ...
	 Train_Loss: 0.5805 Train_Acc: 71.629 Val_Loss: 0.5748  BEST VAL Loss: 0.5748  Val_Acc: 71.582

Epoch 17: Validation loss decreased (0.574844 --> 0.573967).  Saving model ...
	 Train_Loss: 0.5787 Train_Acc: 71.957 Val_Loss: 0.5740  BEST VAL Loss: 0.5740  Val_Acc: 71.331

Epoch 18: Validation loss decreased (0.573967 --> 0.573708).  Saving model ...
	 Train_Loss: 0.5770 Train_Acc: 72.000 Val_Loss: 0.5737  BEST VAL Loss: 0.5737  Val_Acc: 71.331

Epoch 19: Validation loss decreased (0.573708 --> 0.572825).  Saving model ...
	 Train_Loss: 0.5753 Train_Acc: 72.364 Val_Loss: 0.5728  BEST VAL Loss: 0.5728  Val_Acc: 71.696

Epoch 20: Validation loss decreased (0.572825 --> 0.572122).  Saving model ...
	 Train_Loss: 0.5736 Train_Acc: 72.302 Val_Loss: 0.5721  BEST VAL Loss: 0.5721  Val_Acc: 72.060

Epoch 21: Validation loss decreased (0.572122 --> 0.571298).  Saving model ...
	 Train_Loss: 0.5721 Train_Acc: 72.376 Val_Loss: 0.5713  BEST VAL Loss: 0.5713  Val_Acc: 71.855

Epoch 22: Validation loss decreased (0.571298 --> 0.570537).  Saving model ...
	 Train_Loss: 0.5706 Train_Acc: 72.359 Val_Loss: 0.5705  BEST VAL Loss: 0.5705  Val_Acc: 71.673

Epoch 23: Validation loss decreased (0.570537 --> 0.569676).  Saving model ...
	 Train_Loss: 0.5692 Train_Acc: 72.686 Val_Loss: 0.5697  BEST VAL Loss: 0.5697  Val_Acc: 71.696

Epoch 24: Validation loss decreased (0.569676 --> 0.569416).  Saving model ...
	 Train_Loss: 0.5679 Train_Acc: 72.530 Val_Loss: 0.5694  BEST VAL Loss: 0.5694  Val_Acc: 72.037

Epoch 25: Validation loss decreased (0.569416 --> 0.569035).  Saving model ...
	 Train_Loss: 0.5665 Train_Acc: 72.675 Val_Loss: 0.5690  BEST VAL Loss: 0.5690  Val_Acc: 71.992

Epoch 26: Validation loss decreased (0.569035 --> 0.568600).  Saving model ...
	 Train_Loss: 0.5652 Train_Acc: 72.943 Val_Loss: 0.5686  BEST VAL Loss: 0.5686  Val_Acc: 72.379

Epoch 27: Validation loss decreased (0.568600 --> 0.568334).  Saving model ...
	 Train_Loss: 0.5639 Train_Acc: 72.860 Val_Loss: 0.5683  BEST VAL Loss: 0.5683  Val_Acc: 72.060

Epoch 28: Validation loss decreased (0.568334 --> 0.567731).  Saving model ...
	 Train_Loss: 0.5627 Train_Acc: 72.792 Val_Loss: 0.5677  BEST VAL Loss: 0.5677  Val_Acc: 72.311

Epoch 29: Validation loss decreased (0.567731 --> 0.567591).  Saving model ...
	 Train_Loss: 0.5615 Train_Acc: 72.860 Val_Loss: 0.5676  BEST VAL Loss: 0.5676  Val_Acc: 71.718

Epoch 30: Validation loss decreased (0.567591 --> 0.567302).  Saving model ...
	 Train_Loss: 0.5603 Train_Acc: 73.037 Val_Loss: 0.5673  BEST VAL Loss: 0.5673  Val_Acc: 71.741

Epoch 31: Validation loss decreased (0.567302 --> 0.566915).  Saving model ...
	 Train_Loss: 0.5592 Train_Acc: 73.367 Val_Loss: 0.5669  BEST VAL Loss: 0.5669  Val_Acc: 72.334

Epoch 32: Validation loss decreased (0.566915 --> 0.566773).  Saving model ...
	 Train_Loss: 0.5580 Train_Acc: 73.510 Val_Loss: 0.5668  BEST VAL Loss: 0.5668  Val_Acc: 72.220

Epoch 33: Validation loss decreased (0.566773 --> 0.566560).  Saving model ...
	 Train_Loss: 0.5570 Train_Acc: 73.236 Val_Loss: 0.5666  BEST VAL Loss: 0.5666  Val_Acc: 71.832

Epoch 34: Validation loss decreased (0.566560 --> 0.566239).  Saving model ...
	 Train_Loss: 0.5560 Train_Acc: 73.290 Val_Loss: 0.5662  BEST VAL Loss: 0.5662  Val_Acc: 72.379

Epoch 35: Validation loss decreased (0.566239 --> 0.565943).  Saving model ...
	 Train_Loss: 0.5549 Train_Acc: 73.681 Val_Loss: 0.5659  BEST VAL Loss: 0.5659  Val_Acc: 72.493

Epoch 36: Validation loss decreased (0.565943 --> 0.565763).  Saving model ...
	 Train_Loss: 0.5539 Train_Acc: 73.618 Val_Loss: 0.5658  BEST VAL Loss: 0.5658  Val_Acc: 71.741

Epoch 37: Validation loss decreased (0.565763 --> 0.565421).  Saving model ...
	 Train_Loss: 0.5529 Train_Acc: 73.629 Val_Loss: 0.5654  BEST VAL Loss: 0.5654  Val_Acc: 72.334

Epoch 38: Validation loss decreased (0.565421 --> 0.565136).  Saving model ...
	 Train_Loss: 0.5520 Train_Acc: 73.686 Val_Loss: 0.5651  BEST VAL Loss: 0.5651  Val_Acc: 71.992

Epoch 39: Validation loss decreased (0.565136 --> 0.564945).  Saving model ...
	 Train_Loss: 0.5510 Train_Acc: 73.746 Val_Loss: 0.5649  BEST VAL Loss: 0.5649  Val_Acc: 72.493

Epoch 40: Validation loss decreased (0.564945 --> 0.564879).  Saving model ...
	 Train_Loss: 0.5501 Train_Acc: 73.686 Val_Loss: 0.5649  BEST VAL Loss: 0.5649  Val_Acc: 72.539

Epoch 41: Validation loss decreased (0.564879 --> 0.564602).  Saving model ...
	 Train_Loss: 0.5492 Train_Acc: 73.980 Val_Loss: 0.5646  BEST VAL Loss: 0.5646  Val_Acc: 72.584

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.5483 Train_Acc: 74.083 Val_Loss: 0.5647  BEST VAL Loss: 0.5646  Val_Acc: 72.242

Epoch 43: Validation loss decreased (0.564602 --> 0.564332).  Saving model ...
	 Train_Loss: 0.5474 Train_Acc: 73.869 Val_Loss: 0.5643  BEST VAL Loss: 0.5643  Val_Acc: 72.356

Epoch 44: Validation loss decreased (0.564332 --> 0.563937).  Saving model ...
	 Train_Loss: 0.5466 Train_Acc: 73.960 Val_Loss: 0.5639  BEST VAL Loss: 0.5639  Val_Acc: 72.242

Epoch 45: Validation loss decreased (0.563937 --> 0.563779).  Saving model ...
	 Train_Loss: 0.5458 Train_Acc: 73.820 Val_Loss: 0.5638  BEST VAL Loss: 0.5638  Val_Acc: 71.696

Epoch 46: Validation loss decreased (0.563779 --> 0.563603).  Saving model ...
	 Train_Loss: 0.5450 Train_Acc: 74.023 Val_Loss: 0.5636  BEST VAL Loss: 0.5636  Val_Acc: 72.242

Epoch 47: Validation loss decreased (0.563603 --> 0.563572).  Saving model ...
	 Train_Loss: 0.5442 Train_Acc: 74.319 Val_Loss: 0.5636  BEST VAL Loss: 0.5636  Val_Acc: 71.992

Epoch 48: Validation loss decreased (0.563572 --> 0.563402).  Saving model ...
	 Train_Loss: 0.5434 Train_Acc: 74.177 Val_Loss: 0.5634  BEST VAL Loss: 0.5634  Val_Acc: 72.379

Epoch 49: Validation loss decreased (0.563402 --> 0.563160).  Saving model ...
	 Train_Loss: 0.5427 Train_Acc: 74.273 Val_Loss: 0.5632  BEST VAL Loss: 0.5632  Val_Acc: 72.265

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.5419 Train_Acc: 74.527 Val_Loss: 0.5633  BEST VAL Loss: 0.5632  Val_Acc: 71.832

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.5411 Train_Acc: 74.920 Val_Loss: 0.5633  BEST VAL Loss: 0.5632  Val_Acc: 72.288

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.5404 Train_Acc: 74.131 Val_Loss: 0.5633  BEST VAL Loss: 0.5632  Val_Acc: 71.764

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.5398 Train_Acc: 74.228 Val_Loss: 0.5632  BEST VAL Loss: 0.5632  Val_Acc: 72.288

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.5391 Train_Acc: 74.430 Val_Loss: 0.5632  BEST VAL Loss: 0.5632  Val_Acc: 72.129

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.5384 Train_Acc: 74.801 Val_Loss: 0.5632  BEST VAL Loss: 0.5632  Val_Acc: 72.675

Epoch 56: Validation loss decreased (0.563160 --> 0.563158).  Saving model ...
	 Train_Loss: 0.5377 Train_Acc: 74.823 Val_Loss: 0.5632  BEST VAL Loss: 0.5632  Val_Acc: 72.197

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.5371 Train_Acc: 74.792 Val_Loss: 0.5632  BEST VAL Loss: 0.5632  Val_Acc: 72.379

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.5365 Train_Acc: 74.618 Val_Loss: 0.5633  BEST VAL Loss: 0.5632  Val_Acc: 72.083

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.5358 Train_Acc: 74.892 Val_Loss: 0.5633  BEST VAL Loss: 0.5632  Val_Acc: 72.015

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.5352 Train_Acc: 75.080 Val_Loss: 0.5633  BEST VAL Loss: 0.5632  Val_Acc: 71.992

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.5346 Train_Acc: 74.444 Val_Loss: 0.5632  BEST VAL Loss: 0.5632  Val_Acc: 72.356

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.5340 Train_Acc: 74.772 Val_Loss: 0.5632  BEST VAL Loss: 0.5632  Val_Acc: 73.040

Epoch 63: Validation loss decreased (0.563158 --> 0.563052).  Saving model ...
	 Train_Loss: 0.5334 Train_Acc: 74.607 Val_Loss: 0.5631  BEST VAL Loss: 0.5631  Val_Acc: 72.562

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.5328 Train_Acc: 74.957 Val_Loss: 0.5632  BEST VAL Loss: 0.5631  Val_Acc: 72.493

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.5322 Train_Acc: 75.020 Val_Loss: 0.5633  BEST VAL Loss: 0.5631  Val_Acc: 72.698

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.5316 Train_Acc: 75.390 Val_Loss: 0.5633  BEST VAL Loss: 0.5631  Val_Acc: 72.356

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.5310 Train_Acc: 75.228 Val_Loss: 0.5634  BEST VAL Loss: 0.5631  Val_Acc: 72.015

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.5305 Train_Acc: 74.778 Val_Loss: 0.5634  BEST VAL Loss: 0.5631  Val_Acc: 72.425

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.5300 Train_Acc: 75.484 Val_Loss: 0.5635  BEST VAL Loss: 0.5631  Val_Acc: 72.060

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.5294 Train_Acc: 75.299 Val_Loss: 0.5636  BEST VAL Loss: 0.5631  Val_Acc: 72.607

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.5288 Train_Acc: 75.521 Val_Loss: 0.5636  BEST VAL Loss: 0.5631  Val_Acc: 72.060

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.5283 Train_Acc: 75.539 Val_Loss: 0.5636  BEST VAL Loss: 0.5631  Val_Acc: 72.425

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.5278 Train_Acc: 75.291 Val_Loss: 0.5637  BEST VAL Loss: 0.5631  Val_Acc: 72.379

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.5273 Train_Acc: 75.373 Val_Loss: 0.5637  BEST VAL Loss: 0.5631  Val_Acc: 72.562

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.5268 Train_Acc: 75.456 Val_Loss: 0.5635  BEST VAL Loss: 0.5631  Val_Acc: 72.470

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.5263 Train_Acc: 75.633 Val_Loss: 0.5636  BEST VAL Loss: 0.5631  Val_Acc: 72.083

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.5258 Train_Acc: 75.630 Val_Loss: 0.5636  BEST VAL Loss: 0.5631  Val_Acc: 71.673

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.5253 Train_Acc: 75.994 Val_Loss: 0.5638  BEST VAL Loss: 0.5631  Val_Acc: 71.240

Epoch 79: Validation loss did not decrease
Early stopped at epoch : 79
DMSO_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.70      0.89      0.78     24644
           1       0.29      0.11      0.16     10452

    accuracy                           0.66     35096
   macro avg       0.50      0.50      0.47     35096
weighted avg       0.58      0.66      0.60     35096

DMSO_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.70      0.90      0.79      3081
           1       0.31      0.10      0.15      1307

    accuracy                           0.66      4388
   macro avg       0.51      0.50      0.47      4388
weighted avg       0.59      0.66      0.60      4388

DMSO_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.71      0.91      0.80      3081
           1       0.34      0.11      0.16      1306

    accuracy                           0.67      4387
   macro avg       0.52      0.51      0.48      4387
weighted avg       0.60      0.67      0.61      4387

              precision    recall  f1-score   support

           0       0.71      0.91      0.80      3081
           1       0.34      0.11      0.16      1306

    accuracy                           0.67      4387
   macro avg       0.52      0.51      0.48      4387
weighted avg       0.60      0.67      0.61      4387

DMSO_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.89      0.66      4837
           1       0.46      0.10      0.17      4445

    accuracy                           0.51      9282
   macro avg       0.49      0.50      0.41      9282
weighted avg       0.49      0.51      0.42      9282

              precision    recall  f1-score   support

           0       0.52      0.89      0.66      4837
           1       0.46      0.10      0.17      4445

    accuracy                           0.51      9282
   macro avg       0.49      0.50      0.41      9282
weighted avg       0.49      0.51      0.42      9282

completed
