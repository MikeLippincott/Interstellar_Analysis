[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '39f66a06'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'c27da0ed'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd58c13cd'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '0ff979ba'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: H2O2_100.000_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['H2O2_100.000_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (42887, 1276)
Number of total missing values across all columns: 85774
Data Subset Is Off
Wells held out for testing: ['H22' 'J16']
Wells to use for training, validation, and testing ['H18' 'H19' 'H23' 'J17' 'I18' 'I19' 'J20' 'J21' 'I22' 'I23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.399948).  Saving model ...
	 Train_Loss: 0.7218 Train_Acc: 72.034 Val_Loss: 0.3999  BEST VAL Loss: 0.3999  Val_Acc: 83.964

Epoch 1: Validation loss decreased (0.399948 --> 0.328582).  Saving model ...
	 Train_Loss: 0.5528 Train_Acc: 82.930 Val_Loss: 0.3286  BEST VAL Loss: 0.3286  Val_Acc: 91.130

Epoch 2: Validation loss decreased (0.328582 --> 0.286930).  Saving model ...
	 Train_Loss: 0.4705 Train_Acc: 86.962 Val_Loss: 0.2869  BEST VAL Loss: 0.2869  Val_Acc: 93.470

Epoch 3: Validation loss decreased (0.286930 --> 0.257570).  Saving model ...
	 Train_Loss: 0.4170 Train_Acc: 89.743 Val_Loss: 0.2576  BEST VAL Loss: 0.2576  Val_Acc: 94.308

Epoch 4: Validation loss decreased (0.257570 --> 0.235717).  Saving model ...
	 Train_Loss: 0.3788 Train_Acc: 91.228 Val_Loss: 0.2357  BEST VAL Loss: 0.2357  Val_Acc: 94.944

Epoch 5: Validation loss decreased (0.235717 --> 0.220760).  Saving model ...
	 Train_Loss: 0.3494 Train_Acc: 92.634 Val_Loss: 0.2208  BEST VAL Loss: 0.2208  Val_Acc: 95.030

Epoch 6: Validation loss decreased (0.220760 --> 0.208006).  Saving model ...
	 Train_Loss: 0.3270 Train_Acc: 92.836 Val_Loss: 0.2080  BEST VAL Loss: 0.2080  Val_Acc: 96.070

Epoch 7: Validation loss decreased (0.208006 --> 0.198104).  Saving model ...
	 Train_Loss: 0.3089 Train_Acc: 93.266 Val_Loss: 0.1981  BEST VAL Loss: 0.1981  Val_Acc: 95.377

Epoch 8: Validation loss decreased (0.198104 --> 0.189646).  Saving model ...
	 Train_Loss: 0.2933 Train_Acc: 93.862 Val_Loss: 0.1896  BEST VAL Loss: 0.1896  Val_Acc: 95.839

Epoch 9: Validation loss decreased (0.189646 --> 0.182780).  Saving model ...
	 Train_Loss: 0.2805 Train_Acc: 93.811 Val_Loss: 0.1828  BEST VAL Loss: 0.1828  Val_Acc: 95.868

Epoch 10: Validation loss decreased (0.182780 --> 0.176723).  Saving model ...
	 Train_Loss: 0.2698 Train_Acc: 93.873 Val_Loss: 0.1767  BEST VAL Loss: 0.1767  Val_Acc: 95.839

Epoch 11: Validation loss decreased (0.176723 --> 0.171578).  Saving model ...
	 Train_Loss: 0.2602 Train_Acc: 94.194 Val_Loss: 0.1716  BEST VAL Loss: 0.1716  Val_Acc: 96.042

Epoch 12: Validation loss decreased (0.171578 --> 0.166980).  Saving model ...
	 Train_Loss: 0.2519 Train_Acc: 94.285 Val_Loss: 0.1670  BEST VAL Loss: 0.1670  Val_Acc: 95.926

Epoch 13: Validation loss decreased (0.166980 --> 0.163172).  Saving model ...
	 Train_Loss: 0.2448 Train_Acc: 94.155 Val_Loss: 0.1632  BEST VAL Loss: 0.1632  Val_Acc: 96.157

Epoch 14: Validation loss decreased (0.163172 --> 0.159475).  Saving model ...
	 Train_Loss: 0.2380 Train_Acc: 94.469 Val_Loss: 0.1595  BEST VAL Loss: 0.1595  Val_Acc: 96.186

Epoch 15: Validation loss decreased (0.159475 --> 0.156676).  Saving model ...
	 Train_Loss: 0.2319 Train_Acc: 94.462 Val_Loss: 0.1567  BEST VAL Loss: 0.1567  Val_Acc: 96.331

Epoch 16: Validation loss decreased (0.156676 --> 0.153737).  Saving model ...
	 Train_Loss: 0.2262 Train_Acc: 94.646 Val_Loss: 0.1537  BEST VAL Loss: 0.1537  Val_Acc: 96.128

Epoch 17: Validation loss decreased (0.153737 --> 0.151018).  Saving model ...
	 Train_Loss: 0.2210 Train_Acc: 94.574 Val_Loss: 0.1510  BEST VAL Loss: 0.1510  Val_Acc: 96.446

Epoch 18: Validation loss decreased (0.151018 --> 0.148340).  Saving model ...
	 Train_Loss: 0.2164 Train_Acc: 94.765 Val_Loss: 0.1483  BEST VAL Loss: 0.1483  Val_Acc: 96.619

Epoch 19: Validation loss decreased (0.148340 --> 0.145977).  Saving model ...
	 Train_Loss: 0.2121 Train_Acc: 94.975 Val_Loss: 0.1460  BEST VAL Loss: 0.1460  Val_Acc: 96.475

Epoch 20: Validation loss decreased (0.145977 --> 0.144096).  Saving model ...
	 Train_Loss: 0.2079 Train_Acc: 94.967 Val_Loss: 0.1441  BEST VAL Loss: 0.1441  Val_Acc: 96.273

Epoch 21: Validation loss decreased (0.144096 --> 0.142822).  Saving model ...
	 Train_Loss: 0.2041 Train_Acc: 95.061 Val_Loss: 0.1428  BEST VAL Loss: 0.1428  Val_Acc: 96.099

Epoch 22: Validation loss decreased (0.142822 --> 0.141203).  Saving model ...
	 Train_Loss: 0.2008 Train_Acc: 94.841 Val_Loss: 0.1412  BEST VAL Loss: 0.1412  Val_Acc: 96.793

Epoch 23: Validation loss decreased (0.141203 --> 0.139309).  Saving model ...
	 Train_Loss: 0.1975 Train_Acc: 95.329 Val_Loss: 0.1393  BEST VAL Loss: 0.1393  Val_Acc: 96.764

Epoch 24: Validation loss decreased (0.139309 --> 0.137764).  Saving model ...
	 Train_Loss: 0.1943 Train_Acc: 95.303 Val_Loss: 0.1378  BEST VAL Loss: 0.1378  Val_Acc: 96.735

Epoch 25: Validation loss decreased (0.137764 --> 0.136300).  Saving model ...
	 Train_Loss: 0.1915 Train_Acc: 95.126 Val_Loss: 0.1363  BEST VAL Loss: 0.1363  Val_Acc: 96.706

Epoch 26: Validation loss decreased (0.136300 --> 0.134856).  Saving model ...
	 Train_Loss: 0.1889 Train_Acc: 95.011 Val_Loss: 0.1349  BEST VAL Loss: 0.1349  Val_Acc: 96.908

Epoch 27: Validation loss decreased (0.134856 --> 0.133644).  Saving model ...
	 Train_Loss: 0.1864 Train_Acc: 95.047 Val_Loss: 0.1336  BEST VAL Loss: 0.1336  Val_Acc: 97.168

Epoch 28: Validation loss decreased (0.133644 --> 0.132679).  Saving model ...
	 Train_Loss: 0.1840 Train_Acc: 95.285 Val_Loss: 0.1327  BEST VAL Loss: 0.1327  Val_Acc: 96.851

Epoch 29: Validation loss decreased (0.132679 --> 0.131386).  Saving model ...
	 Train_Loss: 0.1817 Train_Acc: 95.303 Val_Loss: 0.1314  BEST VAL Loss: 0.1314  Val_Acc: 97.082

Epoch 30: Validation loss decreased (0.131386 --> 0.130109).  Saving model ...
	 Train_Loss: 0.1794 Train_Acc: 95.390 Val_Loss: 0.1301  BEST VAL Loss: 0.1301  Val_Acc: 97.140

Epoch 31: Validation loss decreased (0.130109 --> 0.129337).  Saving model ...
	 Train_Loss: 0.1773 Train_Acc: 95.437 Val_Loss: 0.1293  BEST VAL Loss: 0.1293  Val_Acc: 96.822

Epoch 32: Validation loss decreased (0.129337 --> 0.128405).  Saving model ...
	 Train_Loss: 0.1752 Train_Acc: 95.452 Val_Loss: 0.1284  BEST VAL Loss: 0.1284  Val_Acc: 96.937

Epoch 33: Validation loss decreased (0.128405 --> 0.127836).  Saving model ...
	 Train_Loss: 0.1733 Train_Acc: 95.491 Val_Loss: 0.1278  BEST VAL Loss: 0.1278  Val_Acc: 96.908

Epoch 34: Validation loss decreased (0.127836 --> 0.127128).  Saving model ...
	 Train_Loss: 0.1714 Train_Acc: 95.350 Val_Loss: 0.1271  BEST VAL Loss: 0.1271  Val_Acc: 97.342

Epoch 35: Validation loss decreased (0.127128 --> 0.126673).  Saving model ...
	 Train_Loss: 0.1696 Train_Acc: 95.455 Val_Loss: 0.1267  BEST VAL Loss: 0.1267  Val_Acc: 96.995

Epoch 36: Validation loss decreased (0.126673 --> 0.126094).  Saving model ...
	 Train_Loss: 0.1681 Train_Acc: 95.354 Val_Loss: 0.1261  BEST VAL Loss: 0.1261  Val_Acc: 96.851

Epoch 37: Validation loss decreased (0.126094 --> 0.125184).  Saving model ...
	 Train_Loss: 0.1665 Train_Acc: 95.499 Val_Loss: 0.1252  BEST VAL Loss: 0.1252  Val_Acc: 97.168

Epoch 38: Validation loss decreased (0.125184 --> 0.124668).  Saving model ...
	 Train_Loss: 0.1649 Train_Acc: 95.820 Val_Loss: 0.1247  BEST VAL Loss: 0.1247  Val_Acc: 96.880

Epoch 39: Validation loss decreased (0.124668 --> 0.124270).  Saving model ...
	 Train_Loss: 0.1634 Train_Acc: 95.542 Val_Loss: 0.1243  BEST VAL Loss: 0.1243  Val_Acc: 96.735

Epoch 40: Validation loss decreased (0.124270 --> 0.123500).  Saving model ...
	 Train_Loss: 0.1619 Train_Acc: 95.578 Val_Loss: 0.1235  BEST VAL Loss: 0.1235  Val_Acc: 97.342

Epoch 41: Validation loss decreased (0.123500 --> 0.122716).  Saving model ...
	 Train_Loss: 0.1606 Train_Acc: 95.264 Val_Loss: 0.1227  BEST VAL Loss: 0.1227  Val_Acc: 96.966

Epoch 42: Validation loss decreased (0.122716 --> 0.121938).  Saving model ...
	 Train_Loss: 0.1592 Train_Acc: 95.643 Val_Loss: 0.1219  BEST VAL Loss: 0.1219  Val_Acc: 97.082

Epoch 43: Validation loss decreased (0.121938 --> 0.121095).  Saving model ...
	 Train_Loss: 0.1580 Train_Acc: 95.358 Val_Loss: 0.1211  BEST VAL Loss: 0.1211  Val_Acc: 97.111

Epoch 44: Validation loss decreased (0.121095 --> 0.120619).  Saving model ...
	 Train_Loss: 0.1567 Train_Acc: 95.549 Val_Loss: 0.1206  BEST VAL Loss: 0.1206  Val_Acc: 97.197

Epoch 45: Validation loss decreased (0.120619 --> 0.120000).  Saving model ...
	 Train_Loss: 0.1555 Train_Acc: 95.611 Val_Loss: 0.1200  BEST VAL Loss: 0.1200  Val_Acc: 97.197

Epoch 46: Validation loss decreased (0.120000 --> 0.119443).  Saving model ...
	 Train_Loss: 0.1543 Train_Acc: 95.708 Val_Loss: 0.1194  BEST VAL Loss: 0.1194  Val_Acc: 97.024

Epoch 47: Validation loss decreased (0.119443 --> 0.118935).  Saving model ...
	 Train_Loss: 0.1531 Train_Acc: 95.871 Val_Loss: 0.1189  BEST VAL Loss: 0.1189  Val_Acc: 97.486

Epoch 48: Validation loss decreased (0.118935 --> 0.118609).  Saving model ...
	 Train_Loss: 0.1519 Train_Acc: 95.755 Val_Loss: 0.1186  BEST VAL Loss: 0.1186  Val_Acc: 97.313

Epoch 49: Validation loss decreased (0.118609 --> 0.118242).  Saving model ...
	 Train_Loss: 0.1508 Train_Acc: 95.531 Val_Loss: 0.1182  BEST VAL Loss: 0.1182  Val_Acc: 97.168

Epoch 50: Validation loss decreased (0.118242 --> 0.117709).  Saving model ...
	 Train_Loss: 0.1498 Train_Acc: 95.867 Val_Loss: 0.1177  BEST VAL Loss: 0.1177  Val_Acc: 96.966

Epoch 51: Validation loss decreased (0.117709 --> 0.117211).  Saving model ...
	 Train_Loss: 0.1487 Train_Acc: 95.704 Val_Loss: 0.1172  BEST VAL Loss: 0.1172  Val_Acc: 97.284

Epoch 52: Validation loss decreased (0.117211 --> 0.116752).  Saving model ...
	 Train_Loss: 0.1477 Train_Acc: 95.715 Val_Loss: 0.1168  BEST VAL Loss: 0.1168  Val_Acc: 97.313

Epoch 53: Validation loss decreased (0.116752 --> 0.116205).  Saving model ...
	 Train_Loss: 0.1467 Train_Acc: 95.701 Val_Loss: 0.1162  BEST VAL Loss: 0.1162  Val_Acc: 97.082

Epoch 54: Validation loss decreased (0.116205 --> 0.115824).  Saving model ...
	 Train_Loss: 0.1458 Train_Acc: 95.744 Val_Loss: 0.1158  BEST VAL Loss: 0.1158  Val_Acc: 96.995

Epoch 55: Validation loss decreased (0.115824 --> 0.115286).  Saving model ...
	 Train_Loss: 0.1448 Train_Acc: 95.863 Val_Loss: 0.1153  BEST VAL Loss: 0.1153  Val_Acc: 97.457

Epoch 56: Validation loss decreased (0.115286 --> 0.114906).  Saving model ...
	 Train_Loss: 0.1439 Train_Acc: 95.939 Val_Loss: 0.1149  BEST VAL Loss: 0.1149  Val_Acc: 97.168

Epoch 57: Validation loss decreased (0.114906 --> 0.114655).  Saving model ...
	 Train_Loss: 0.1431 Train_Acc: 95.777 Val_Loss: 0.1147  BEST VAL Loss: 0.1147  Val_Acc: 96.966

Epoch 58: Validation loss decreased (0.114655 --> 0.114219).  Saving model ...
	 Train_Loss: 0.1422 Train_Acc: 95.838 Val_Loss: 0.1142  BEST VAL Loss: 0.1142  Val_Acc: 97.428

Epoch 59: Validation loss decreased (0.114219 --> 0.113778).  Saving model ...
	 Train_Loss: 0.1414 Train_Acc: 95.690 Val_Loss: 0.1138  BEST VAL Loss: 0.1138  Val_Acc: 97.486

Epoch 60: Validation loss decreased (0.113778 --> 0.113609).  Saving model ...
	 Train_Loss: 0.1407 Train_Acc: 95.600 Val_Loss: 0.1136  BEST VAL Loss: 0.1136  Val_Acc: 97.082

Epoch 61: Validation loss decreased (0.113609 --> 0.113334).  Saving model ...
	 Train_Loss: 0.1399 Train_Acc: 95.748 Val_Loss: 0.1133  BEST VAL Loss: 0.1133  Val_Acc: 97.342

Epoch 62: Validation loss decreased (0.113334 --> 0.113088).  Saving model ...
	 Train_Loss: 0.1391 Train_Acc: 95.874 Val_Loss: 0.1131  BEST VAL Loss: 0.1131  Val_Acc: 97.313

Epoch 63: Validation loss decreased (0.113088 --> 0.112963).  Saving model ...
	 Train_Loss: 0.1383 Train_Acc: 95.845 Val_Loss: 0.1130  BEST VAL Loss: 0.1130  Val_Acc: 97.053

Epoch 64: Validation loss decreased (0.112963 --> 0.112769).  Saving model ...
	 Train_Loss: 0.1376 Train_Acc: 95.719 Val_Loss: 0.1128  BEST VAL Loss: 0.1128  Val_Acc: 97.255

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.1369 Train_Acc: 95.954 Val_Loss: 0.1128  BEST VAL Loss: 0.1128  Val_Acc: 97.400

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.1362 Train_Acc: 95.780 Val_Loss: 0.1129  BEST VAL Loss: 0.1128  Val_Acc: 97.226

Epoch 67: Validation loss decreased (0.112769 --> 0.112742).  Saving model ...
	 Train_Loss: 0.1355 Train_Acc: 95.997 Val_Loss: 0.1127  BEST VAL Loss: 0.1127  Val_Acc: 97.342

Epoch 68: Validation loss decreased (0.112742 --> 0.112634).  Saving model ...
	 Train_Loss: 0.1349 Train_Acc: 95.647 Val_Loss: 0.1126  BEST VAL Loss: 0.1126  Val_Acc: 97.255

Epoch 69: Validation loss decreased (0.112634 --> 0.112363).  Saving model ...
	 Train_Loss: 0.1343 Train_Acc: 95.582 Val_Loss: 0.1124  BEST VAL Loss: 0.1124  Val_Acc: 97.284

Epoch 70: Validation loss decreased (0.112363 --> 0.112204).  Saving model ...
	 Train_Loss: 0.1336 Train_Acc: 95.827 Val_Loss: 0.1122  BEST VAL Loss: 0.1122  Val_Acc: 97.428

Epoch 71: Validation loss decreased (0.112204 --> 0.112076).  Saving model ...
	 Train_Loss: 0.1330 Train_Acc: 95.780 Val_Loss: 0.1121  BEST VAL Loss: 0.1121  Val_Acc: 97.284

Epoch 72: Validation loss decreased (0.112076 --> 0.111778).  Saving model ...
	 Train_Loss: 0.1324 Train_Acc: 95.957 Val_Loss: 0.1118  BEST VAL Loss: 0.1118  Val_Acc: 97.313

Epoch 73: Validation loss decreased (0.111778 --> 0.111750).  Saving model ...
	 Train_Loss: 0.1318 Train_Acc: 95.939 Val_Loss: 0.1118  BEST VAL Loss: 0.1118  Val_Acc: 97.486

Epoch 74: Validation loss decreased (0.111750 --> 0.111614).  Saving model ...
	 Train_Loss: 0.1312 Train_Acc: 95.914 Val_Loss: 0.1116  BEST VAL Loss: 0.1116  Val_Acc: 97.111

Epoch 75: Validation loss decreased (0.111614 --> 0.111322).  Saving model ...
	 Train_Loss: 0.1305 Train_Acc: 96.095 Val_Loss: 0.1113  BEST VAL Loss: 0.1113  Val_Acc: 96.735

Epoch 76: Validation loss decreased (0.111322 --> 0.111274).  Saving model ...
	 Train_Loss: 0.1299 Train_Acc: 96.113 Val_Loss: 0.1113  BEST VAL Loss: 0.1113  Val_Acc: 96.851

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.1294 Train_Acc: 95.889 Val_Loss: 0.1113  BEST VAL Loss: 0.1113  Val_Acc: 97.342

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.1289 Train_Acc: 95.816 Val_Loss: 0.1113  BEST VAL Loss: 0.1113  Val_Acc: 97.457

Epoch 79: Validation loss decreased (0.111274 --> 0.111104).  Saving model ...
	 Train_Loss: 0.1283 Train_Acc: 96.120 Val_Loss: 0.1111  BEST VAL Loss: 0.1111  Val_Acc: 97.342

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.1278 Train_Acc: 96.069 Val_Loss: 0.1112  BEST VAL Loss: 0.1111  Val_Acc: 96.735

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.1273 Train_Acc: 95.918 Val_Loss: 0.1112  BEST VAL Loss: 0.1111  Val_Acc: 97.313

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.1268 Train_Acc: 95.853 Val_Loss: 0.1111  BEST VAL Loss: 0.1111  Val_Acc: 97.197

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.1263 Train_Acc: 95.816 Val_Loss: 0.1113  BEST VAL Loss: 0.1111  Val_Acc: 97.053

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.1259 Train_Acc: 95.968 Val_Loss: 0.1112  BEST VAL Loss: 0.1111  Val_Acc: 97.053

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.1254 Train_Acc: 96.203 Val_Loss: 0.1118  BEST VAL Loss: 0.1111  Val_Acc: 97.053

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.1249 Train_Acc: 96.192 Val_Loss: 0.1117  BEST VAL Loss: 0.1111  Val_Acc: 97.371

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.1245 Train_Acc: 95.885 Val_Loss: 0.1115  BEST VAL Loss: 0.1111  Val_Acc: 97.313

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.1240 Train_Acc: 95.972 Val_Loss: 0.1114  BEST VAL Loss: 0.1111  Val_Acc: 97.371

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.1236 Train_Acc: 96.189 Val_Loss: 0.1115  BEST VAL Loss: 0.1111  Val_Acc: 97.053

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.1231 Train_Acc: 95.784 Val_Loss: 0.1113  BEST VAL Loss: 0.1111  Val_Acc: 97.342

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.1227 Train_Acc: 95.842 Val_Loss: 0.1113  BEST VAL Loss: 0.1111  Val_Acc: 97.255

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.1224 Train_Acc: 95.737 Val_Loss: 0.1113  BEST VAL Loss: 0.1111  Val_Acc: 96.793

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.1220 Train_Acc: 95.780 Val_Loss: 0.1112  BEST VAL Loss: 0.1111  Val_Acc: 97.544

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.1216 Train_Acc: 96.207 Val_Loss: 0.1112  BEST VAL Loss: 0.1111  Val_Acc: 97.602

Epoch 95: Validation loss did not decrease
Early stopped at epoch : 95
H2O2_100.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      1.00      0.99     18174
           1       0.99      0.98      0.99      9506

    accuracy                           0.99     27680
   macro avg       0.99      0.99      0.99     27680
weighted avg       0.99      0.99      0.99     27680

H2O2_100.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.98      0.98      2272
           1       0.97      0.96      0.96      1189

    accuracy                           0.97      3461
   macro avg       0.97      0.97      0.97      3461
weighted avg       0.97      0.97      0.97      3461

H2O2_100.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.98      0.98      2272
           1       0.96      0.95      0.96      1189

    accuracy                           0.97      3461
   macro avg       0.97      0.97      0.97      3461
weighted avg       0.97      0.97      0.97      3461

              precision    recall  f1-score   support

           0       0.98      0.98      0.98      2272
           1       0.96      0.95      0.96      1189

    accuracy                           0.97      3461
   macro avg       0.97      0.97      0.97      3461
weighted avg       0.97      0.97      0.97      3461

H2O2_100.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.99      0.96      4182
           1       0.99      0.92      0.95      4103

    accuracy                           0.96      8285
   macro avg       0.96      0.96      0.96      8285
weighted avg       0.96      0.96      0.96      8285

              precision    recall  f1-score   support

           0       0.93      0.99      0.96      4182
           1       0.99      0.92      0.95      4103

    accuracy                           0.96      8285
   macro avg       0.96      0.96      0.96      8285
weighted avg       0.96      0.96      0.96      8285

completed
