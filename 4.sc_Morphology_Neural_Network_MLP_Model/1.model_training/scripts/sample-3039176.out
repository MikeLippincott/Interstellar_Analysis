[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '4a0a7329'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '4d33742b'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '9c08aeeb'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'bc78ea15'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: Thapsigargin_10.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: Thapsigargin_10.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (26864, 1276)
Number of total missing values across all columns: 26424
Data Subset Is Off
Wells held out for testing: ['E14' 'L20']
Wells to use for training, validation, and testing ['E15' 'L14' 'L15' 'L16' 'L17' 'L21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.390554).  Saving model ...
	 Train_Loss: 0.3739 Train_Acc: 89.185 Val_Loss: 0.3906  BEST VAL Loss: 0.3906  Val_Acc: 92.281

Epoch 1: Validation loss decreased (0.390554 --> 0.313521).  Saving model ...
	 Train_Loss: 0.3146 Train_Acc: 95.607 Val_Loss: 0.3135  BEST VAL Loss: 0.3135  Val_Acc: 95.695

Epoch 2: Validation loss decreased (0.313521 --> 0.272341).  Saving model ...
	 Train_Loss: 0.2783 Train_Acc: 96.857 Val_Loss: 0.2723  BEST VAL Loss: 0.2723  Val_Acc: 96.734

Epoch 3: Validation loss decreased (0.272341 --> 0.247728).  Saving model ...
	 Train_Loss: 0.2518 Train_Acc: 97.599 Val_Loss: 0.2477  BEST VAL Loss: 0.2477  Val_Acc: 95.893

Epoch 4: Validation loss decreased (0.247728 --> 0.227856).  Saving model ...
	 Train_Loss: 0.2318 Train_Acc: 97.661 Val_Loss: 0.2279  BEST VAL Loss: 0.2279  Val_Acc: 96.784

Epoch 5: Validation loss decreased (0.227856 --> 0.218546).  Saving model ...
	 Train_Loss: 0.2153 Train_Acc: 98.150 Val_Loss: 0.2185  BEST VAL Loss: 0.2185  Val_Acc: 95.943

Epoch 6: Validation loss decreased (0.218546 --> 0.211342).  Saving model ...
	 Train_Loss: 0.2013 Train_Acc: 98.268 Val_Loss: 0.2113  BEST VAL Loss: 0.2113  Val_Acc: 95.992

Epoch 7: Validation loss decreased (0.211342 --> 0.198832).  Saving model ...
	 Train_Loss: 0.1896 Train_Acc: 98.342 Val_Loss: 0.1988  BEST VAL Loss: 0.1988  Val_Acc: 97.081

Epoch 8: Validation loss decreased (0.198832 --> 0.187989).  Saving model ...
	 Train_Loss: 0.1788 Train_Acc: 98.713 Val_Loss: 0.1880  BEST VAL Loss: 0.1880  Val_Acc: 97.180

Epoch 9: Validation loss decreased (0.187989 --> 0.178686).  Saving model ...
	 Train_Loss: 0.1694 Train_Acc: 98.769 Val_Loss: 0.1787  BEST VAL Loss: 0.1787  Val_Acc: 97.378

Epoch 10: Validation loss decreased (0.178686 --> 0.170769).  Saving model ...
	 Train_Loss: 0.1612 Train_Acc: 98.868 Val_Loss: 0.1708  BEST VAL Loss: 0.1708  Val_Acc: 97.476

Epoch 11: Validation loss decreased (0.170769 --> 0.163902).  Saving model ...
	 Train_Loss: 0.1538 Train_Acc: 98.831 Val_Loss: 0.1639  BEST VAL Loss: 0.1639  Val_Acc: 97.427

Epoch 12: Validation loss decreased (0.163902 --> 0.160260).  Saving model ...
	 Train_Loss: 0.1474 Train_Acc: 98.892 Val_Loss: 0.1603  BEST VAL Loss: 0.1603  Val_Acc: 96.734

Epoch 13: Validation loss decreased (0.160260 --> 0.154341).  Saving model ...
	 Train_Loss: 0.1421 Train_Acc: 98.651 Val_Loss: 0.1543  BEST VAL Loss: 0.1543  Val_Acc: 97.575

Epoch 14: Validation loss decreased (0.154341 --> 0.149492).  Saving model ...
	 Train_Loss: 0.1367 Train_Acc: 98.973 Val_Loss: 0.1495  BEST VAL Loss: 0.1495  Val_Acc: 97.427

Epoch 15: Validation loss decreased (0.149492 --> 0.146465).  Saving model ...
	 Train_Loss: 0.1319 Train_Acc: 98.961 Val_Loss: 0.1465  BEST VAL Loss: 0.1465  Val_Acc: 96.982

Epoch 16: Validation loss decreased (0.146465 --> 0.142492).  Saving model ...
	 Train_Loss: 0.1274 Train_Acc: 99.134 Val_Loss: 0.1425  BEST VAL Loss: 0.1425  Val_Acc: 97.229

Epoch 17: Validation loss decreased (0.142492 --> 0.139313).  Saving model ...
	 Train_Loss: 0.1233 Train_Acc: 99.084 Val_Loss: 0.1393  BEST VAL Loss: 0.1393  Val_Acc: 97.279

Epoch 18: Validation loss decreased (0.139313 --> 0.136718).  Saving model ...
	 Train_Loss: 0.1195 Train_Acc: 99.196 Val_Loss: 0.1367  BEST VAL Loss: 0.1367  Val_Acc: 97.229

Epoch 19: Validation loss did not decrease
	 Train_Loss: 0.1160 Train_Acc: 99.140 Val_Loss: 0.1369  BEST VAL Loss: 0.1367  Val_Acc: 96.586

Epoch 20: Validation loss decreased (0.136718 --> 0.134600).  Saving model ...
	 Train_Loss: 0.1131 Train_Acc: 98.923 Val_Loss: 0.1346  BEST VAL Loss: 0.1346  Val_Acc: 97.279

Epoch 21: Validation loss decreased (0.134600 --> 0.131978).  Saving model ...
	 Train_Loss: 0.1101 Train_Acc: 99.208 Val_Loss: 0.1320  BEST VAL Loss: 0.1320  Val_Acc: 97.724

Epoch 22: Validation loss decreased (0.131978 --> 0.129204).  Saving model ...
	 Train_Loss: 0.1074 Train_Acc: 99.041 Val_Loss: 0.1292  BEST VAL Loss: 0.1292  Val_Acc: 97.773

Epoch 23: Validation loss decreased (0.129204 --> 0.126930).  Saving model ...
	 Train_Loss: 0.1048 Train_Acc: 99.202 Val_Loss: 0.1269  BEST VAL Loss: 0.1269  Val_Acc: 97.674

Epoch 24: Validation loss decreased (0.126930 --> 0.124780).  Saving model ...
	 Train_Loss: 0.1023 Train_Acc: 99.258 Val_Loss: 0.1248  BEST VAL Loss: 0.1248  Val_Acc: 97.476

Epoch 25: Validation loss decreased (0.124780 --> 0.122975).  Saving model ...
	 Train_Loss: 0.1000 Train_Acc: 99.239 Val_Loss: 0.1230  BEST VAL Loss: 0.1230  Val_Acc: 97.427

Epoch 26: Validation loss decreased (0.122975 --> 0.120895).  Saving model ...
	 Train_Loss: 0.0979 Train_Acc: 99.258 Val_Loss: 0.1209  BEST VAL Loss: 0.1209  Val_Acc: 97.724

Epoch 27: Validation loss decreased (0.120895 --> 0.118976).  Saving model ...
	 Train_Loss: 0.0959 Train_Acc: 99.202 Val_Loss: 0.1190  BEST VAL Loss: 0.1190  Val_Acc: 97.575

Epoch 28: Validation loss decreased (0.118976 --> 0.117291).  Saving model ...
	 Train_Loss: 0.0940 Train_Acc: 99.295 Val_Loss: 0.1173  BEST VAL Loss: 0.1173  Val_Acc: 97.526

Epoch 29: Validation loss decreased (0.117291 --> 0.115796).  Saving model ...
	 Train_Loss: 0.0922 Train_Acc: 99.270 Val_Loss: 0.1158  BEST VAL Loss: 0.1158  Val_Acc: 97.575

Epoch 30: Validation loss decreased (0.115796 --> 0.114196).  Saving model ...
	 Train_Loss: 0.0907 Train_Acc: 99.029 Val_Loss: 0.1142  BEST VAL Loss: 0.1142  Val_Acc: 97.526

Epoch 31: Validation loss decreased (0.114196 --> 0.112890).  Saving model ...
	 Train_Loss: 0.0891 Train_Acc: 99.270 Val_Loss: 0.1129  BEST VAL Loss: 0.1129  Val_Acc: 97.724

Epoch 32: Validation loss decreased (0.112890 --> 0.111600).  Saving model ...
	 Train_Loss: 0.0875 Train_Acc: 99.375 Val_Loss: 0.1116  BEST VAL Loss: 0.1116  Val_Acc: 97.625

Epoch 33: Validation loss decreased (0.111600 --> 0.110423).  Saving model ...
	 Train_Loss: 0.0859 Train_Acc: 99.412 Val_Loss: 0.1104  BEST VAL Loss: 0.1104  Val_Acc: 97.575

Epoch 34: Validation loss decreased (0.110423 --> 0.109243).  Saving model ...
	 Train_Loss: 0.0845 Train_Acc: 99.338 Val_Loss: 0.1092  BEST VAL Loss: 0.1092  Val_Acc: 97.724

Epoch 35: Validation loss decreased (0.109243 --> 0.108276).  Saving model ...
	 Train_Loss: 0.0831 Train_Acc: 99.437 Val_Loss: 0.1083  BEST VAL Loss: 0.1083  Val_Acc: 97.773

Epoch 36: Validation loss decreased (0.108276 --> 0.107427).  Saving model ...
	 Train_Loss: 0.0818 Train_Acc: 99.412 Val_Loss: 0.1074  BEST VAL Loss: 0.1074  Val_Acc: 97.823

Epoch 37: Validation loss decreased (0.107427 --> 0.106512).  Saving model ...
	 Train_Loss: 0.0806 Train_Acc: 99.332 Val_Loss: 0.1065  BEST VAL Loss: 0.1065  Val_Acc: 97.773

Epoch 38: Validation loss decreased (0.106512 --> 0.105575).  Saving model ...
	 Train_Loss: 0.0794 Train_Acc: 99.375 Val_Loss: 0.1056  BEST VAL Loss: 0.1056  Val_Acc: 97.971

Epoch 39: Validation loss decreased (0.105575 --> 0.104852).  Saving model ...
	 Train_Loss: 0.0784 Train_Acc: 99.220 Val_Loss: 0.1049  BEST VAL Loss: 0.1049  Val_Acc: 97.724

Epoch 40: Validation loss decreased (0.104852 --> 0.103912).  Saving model ...
	 Train_Loss: 0.0774 Train_Acc: 99.282 Val_Loss: 0.1039  BEST VAL Loss: 0.1039  Val_Acc: 97.773

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.0763 Train_Acc: 99.456 Val_Loss: 0.1072  BEST VAL Loss: 0.1039  Val_Acc: 96.338

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.0755 Train_Acc: 99.214 Val_Loss: 0.1066  BEST VAL Loss: 0.1039  Val_Acc: 97.427

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.0745 Train_Acc: 99.350 Val_Loss: 0.1058  BEST VAL Loss: 0.1039  Val_Acc: 97.476

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.0736 Train_Acc: 99.369 Val_Loss: 0.1053  BEST VAL Loss: 0.1039  Val_Acc: 97.476

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.0727 Train_Acc: 99.418 Val_Loss: 0.1048  BEST VAL Loss: 0.1039  Val_Acc: 97.328

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.0718 Train_Acc: 99.486 Val_Loss: 0.1040  BEST VAL Loss: 0.1039  Val_Acc: 97.625

Epoch 47: Validation loss decreased (0.103912 --> 0.103466).  Saving model ...
	 Train_Loss: 0.0710 Train_Acc: 99.394 Val_Loss: 0.1035  BEST VAL Loss: 0.1035  Val_Acc: 97.476

Epoch 48: Validation loss decreased (0.103466 --> 0.102845).  Saving model ...
	 Train_Loss: 0.0702 Train_Acc: 99.474 Val_Loss: 0.1028  BEST VAL Loss: 0.1028  Val_Acc: 97.724

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.0694 Train_Acc: 99.406 Val_Loss: 0.1050  BEST VAL Loss: 0.1028  Val_Acc: 96.635

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.0687 Train_Acc: 99.381 Val_Loss: 0.1044  BEST VAL Loss: 0.1028  Val_Acc: 97.674

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.0680 Train_Acc: 99.542 Val_Loss: 0.1038  BEST VAL Loss: 0.1028  Val_Acc: 97.625

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.0673 Train_Acc: 99.418 Val_Loss: 0.1038  BEST VAL Loss: 0.1028  Val_Acc: 97.229

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.0666 Train_Acc: 99.431 Val_Loss: 0.1033  BEST VAL Loss: 0.1028  Val_Acc: 97.674

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.0659 Train_Acc: 99.493 Val_Loss: 0.1030  BEST VAL Loss: 0.1028  Val_Acc: 97.378

Epoch 55: Validation loss decreased (0.102845 --> 0.102588).  Saving model ...
	 Train_Loss: 0.0653 Train_Acc: 99.357 Val_Loss: 0.1026  BEST VAL Loss: 0.1026  Val_Acc: 97.328

Epoch 56: Validation loss decreased (0.102588 --> 0.102451).  Saving model ...
	 Train_Loss: 0.0646 Train_Acc: 99.524 Val_Loss: 0.1025  BEST VAL Loss: 0.1025  Val_Acc: 97.625

Epoch 57: Validation loss decreased (0.102451 --> 0.102189).  Saving model ...
	 Train_Loss: 0.0640 Train_Acc: 99.511 Val_Loss: 0.1022  BEST VAL Loss: 0.1022  Val_Acc: 97.674

Epoch 58: Validation loss decreased (0.102189 --> 0.102148).  Saving model ...
	 Train_Loss: 0.0634 Train_Acc: 99.505 Val_Loss: 0.1021  BEST VAL Loss: 0.1021  Val_Acc: 97.229

Epoch 59: Validation loss decreased (0.102148 --> 0.102083).  Saving model ...
	 Train_Loss: 0.0628 Train_Acc: 99.499 Val_Loss: 0.1021  BEST VAL Loss: 0.1021  Val_Acc: 97.180

Epoch 60: Validation loss decreased (0.102083 --> 0.101947).  Saving model ...
	 Train_Loss: 0.0622 Train_Acc: 99.536 Val_Loss: 0.1019  BEST VAL Loss: 0.1019  Val_Acc: 97.180

Epoch 61: Validation loss decreased (0.101947 --> 0.101752).  Saving model ...
	 Train_Loss: 0.0617 Train_Acc: 99.425 Val_Loss: 0.1018  BEST VAL Loss: 0.1018  Val_Acc: 97.526

Epoch 62: Validation loss decreased (0.101752 --> 0.101354).  Saving model ...
	 Train_Loss: 0.0611 Train_Acc: 99.499 Val_Loss: 0.1014  BEST VAL Loss: 0.1014  Val_Acc: 97.872

Epoch 63: Validation loss decreased (0.101354 --> 0.101155).  Saving model ...
	 Train_Loss: 0.0606 Train_Acc: 99.456 Val_Loss: 0.1012  BEST VAL Loss: 0.1012  Val_Acc: 97.575

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.0602 Train_Acc: 99.363 Val_Loss: 0.1033  BEST VAL Loss: 0.1012  Val_Acc: 95.943

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.0598 Train_Acc: 99.326 Val_Loss: 0.1029  BEST VAL Loss: 0.1012  Val_Acc: 97.476

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.0593 Train_Acc: 99.462 Val_Loss: 0.1027  BEST VAL Loss: 0.1012  Val_Acc: 97.625

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.0588 Train_Acc: 99.548 Val_Loss: 0.1024  BEST VAL Loss: 0.1012  Val_Acc: 97.279

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.0584 Train_Acc: 99.493 Val_Loss: 0.1021  BEST VAL Loss: 0.1012  Val_Acc: 97.575

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.0579 Train_Acc: 99.517 Val_Loss: 0.1017  BEST VAL Loss: 0.1012  Val_Acc: 97.625

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.0575 Train_Acc: 99.462 Val_Loss: 0.1014  BEST VAL Loss: 0.1012  Val_Acc: 97.922

Epoch 71: Validation loss decreased (0.101155 --> 0.101021).  Saving model ...
	 Train_Loss: 0.0571 Train_Acc: 99.505 Val_Loss: 0.1010  BEST VAL Loss: 0.1010  Val_Acc: 97.823

Epoch 72: Validation loss decreased (0.101021 --> 0.100821).  Saving model ...
	 Train_Loss: 0.0566 Train_Acc: 99.561 Val_Loss: 0.1008  BEST VAL Loss: 0.1008  Val_Acc: 97.575

Epoch 73: Validation loss decreased (0.100821 --> 0.100416).  Saving model ...
	 Train_Loss: 0.0563 Train_Acc: 99.443 Val_Loss: 0.1004  BEST VAL Loss: 0.1004  Val_Acc: 97.724

Epoch 74: Validation loss decreased (0.100416 --> 0.100020).  Saving model ...
	 Train_Loss: 0.0559 Train_Acc: 99.468 Val_Loss: 0.1000  BEST VAL Loss: 0.1000  Val_Acc: 97.674

Epoch 75: Validation loss decreased (0.100020 --> 0.099679).  Saving model ...
	 Train_Loss: 0.0555 Train_Acc: 99.387 Val_Loss: 0.0997  BEST VAL Loss: 0.0997  Val_Acc: 97.724

Epoch 76: Validation loss decreased (0.099679 --> 0.099347).  Saving model ...
	 Train_Loss: 0.0552 Train_Acc: 99.468 Val_Loss: 0.0993  BEST VAL Loss: 0.0993  Val_Acc: 97.625

Epoch 77: Validation loss decreased (0.099347 --> 0.098977).  Saving model ...
	 Train_Loss: 0.0548 Train_Acc: 99.505 Val_Loss: 0.0990  BEST VAL Loss: 0.0990  Val_Acc: 97.625

Epoch 78: Validation loss decreased (0.098977 --> 0.098829).  Saving model ...
	 Train_Loss: 0.0544 Train_Acc: 99.548 Val_Loss: 0.0988  BEST VAL Loss: 0.0988  Val_Acc: 97.526

Epoch 79: Validation loss decreased (0.098829 --> 0.098486).  Saving model ...
	 Train_Loss: 0.0540 Train_Acc: 99.536 Val_Loss: 0.0985  BEST VAL Loss: 0.0985  Val_Acc: 97.872

Epoch 80: Validation loss decreased (0.098486 --> 0.098170).  Saving model ...
	 Train_Loss: 0.0537 Train_Acc: 99.567 Val_Loss: 0.0982  BEST VAL Loss: 0.0982  Val_Acc: 98.021

Epoch 81: Validation loss decreased (0.098170 --> 0.098024).  Saving model ...
	 Train_Loss: 0.0533 Train_Acc: 99.579 Val_Loss: 0.0980  BEST VAL Loss: 0.0980  Val_Acc: 97.674

Epoch 82: Validation loss decreased (0.098024 --> 0.097756).  Saving model ...
	 Train_Loss: 0.0529 Train_Acc: 99.548 Val_Loss: 0.0978  BEST VAL Loss: 0.0978  Val_Acc: 97.922

Epoch 83: Validation loss decreased (0.097756 --> 0.097518).  Saving model ...
	 Train_Loss: 0.0525 Train_Acc: 99.635 Val_Loss: 0.0975  BEST VAL Loss: 0.0975  Val_Acc: 97.971

Epoch 84: Validation loss decreased (0.097518 --> 0.097258).  Saving model ...
	 Train_Loss: 0.0522 Train_Acc: 99.567 Val_Loss: 0.0973  BEST VAL Loss: 0.0973  Val_Acc: 98.169

Epoch 85: Validation loss decreased (0.097258 --> 0.096969).  Saving model ...
	 Train_Loss: 0.0519 Train_Acc: 99.635 Val_Loss: 0.0970  BEST VAL Loss: 0.0970  Val_Acc: 97.971

Epoch 86: Validation loss decreased (0.096969 --> 0.096688).  Saving model ...
	 Train_Loss: 0.0515 Train_Acc: 99.592 Val_Loss: 0.0967  BEST VAL Loss: 0.0967  Val_Acc: 98.120

Epoch 87: Validation loss decreased (0.096688 --> 0.096508).  Saving model ...
	 Train_Loss: 0.0512 Train_Acc: 99.548 Val_Loss: 0.0965  BEST VAL Loss: 0.0965  Val_Acc: 98.120

Epoch 88: Validation loss decreased (0.096508 --> 0.096250).  Saving model ...
	 Train_Loss: 0.0509 Train_Acc: 99.548 Val_Loss: 0.0963  BEST VAL Loss: 0.0963  Val_Acc: 98.021

Epoch 89: Validation loss decreased (0.096250 --> 0.095945).  Saving model ...
	 Train_Loss: 0.0506 Train_Acc: 99.536 Val_Loss: 0.0959  BEST VAL Loss: 0.0959  Val_Acc: 98.219

Epoch 90: Validation loss decreased (0.095945 --> 0.095769).  Saving model ...
	 Train_Loss: 0.0503 Train_Acc: 99.641 Val_Loss: 0.0958  BEST VAL Loss: 0.0958  Val_Acc: 98.219

Epoch 91: Validation loss decreased (0.095769 --> 0.095553).  Saving model ...
	 Train_Loss: 0.0500 Train_Acc: 99.555 Val_Loss: 0.0956  BEST VAL Loss: 0.0956  Val_Acc: 98.120

Epoch 92: Validation loss decreased (0.095553 --> 0.095427).  Saving model ...
	 Train_Loss: 0.0497 Train_Acc: 99.598 Val_Loss: 0.0954  BEST VAL Loss: 0.0954  Val_Acc: 98.021

Epoch 93: Validation loss decreased (0.095427 --> 0.095261).  Saving model ...
	 Train_Loss: 0.0495 Train_Acc: 99.493 Val_Loss: 0.0953  BEST VAL Loss: 0.0953  Val_Acc: 98.169

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.0492 Train_Acc: 99.468 Val_Loss: 0.0955  BEST VAL Loss: 0.0953  Val_Acc: 97.575

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.0490 Train_Acc: 99.548 Val_Loss: 0.0953  BEST VAL Loss: 0.0953  Val_Acc: 97.773

Epoch 96: Validation loss decreased (0.095261 --> 0.095117).  Saving model ...
	 Train_Loss: 0.0487 Train_Acc: 99.536 Val_Loss: 0.0951  BEST VAL Loss: 0.0951  Val_Acc: 97.971

Epoch 97: Validation loss decreased (0.095117 --> 0.095007).  Saving model ...
	 Train_Loss: 0.0484 Train_Acc: 99.592 Val_Loss: 0.0950  BEST VAL Loss: 0.0950  Val_Acc: 97.674

Epoch 98: Validation loss decreased (0.095007 --> 0.094824).  Saving model ...
	 Train_Loss: 0.0482 Train_Acc: 99.579 Val_Loss: 0.0948  BEST VAL Loss: 0.0948  Val_Acc: 97.922

Epoch 99: Validation loss decreased (0.094824 --> 0.094751).  Saving model ...
	 Train_Loss: 0.0479 Train_Acc: 99.598 Val_Loss: 0.0948  BEST VAL Loss: 0.0948  Val_Acc: 97.872

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      8312
           1       1.00      1.00      1.00      7850

    accuracy                           1.00     16162
   macro avg       1.00      1.00      1.00     16162
weighted avg       1.00      1.00      1.00     16162

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.97      0.98      1039
           1       0.97      0.98      0.98       982

    accuracy                           0.98      2021
   macro avg       0.98      0.98      0.98      2021
weighted avg       0.98      0.98      0.98      2021

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.97      0.98      1039
           1       0.97      0.98      0.97       982

    accuracy                           0.98      2021
   macro avg       0.98      0.98      0.98      2021
weighted avg       0.98      0.98      0.98      2021

              precision    recall  f1-score   support

           0       0.98      0.97      0.98      1039
           1       0.97      0.98      0.97       982

    accuracy                           0.98      2021
   macro avg       0.98      0.98      0.98      2021
weighted avg       0.98      0.98      0.98      2021

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      0.99      0.99      3262
           1       0.99      0.99      0.99      3398

    accuracy                           0.99      6660
   macro avg       0.99      0.99      0.99      6660
weighted avg       0.99      0.99      0.99      6660

              precision    recall  f1-score   support

           0       0.99      0.99      0.99      3262
           1       0.99      0.99      0.99      3398

    accuracy                           0.99      6660
   macro avg       0.99      0.99      0.99      6660
weighted avg       0.99      0.99      0.99      6660

completed
