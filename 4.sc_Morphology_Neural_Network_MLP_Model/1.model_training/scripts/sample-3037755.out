[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ea87f46f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '6c48e4ee'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '95dc5aad'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '40d0cdb4'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_10.000_DMSO_0.025 treatment_name: DMSO_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: DMSO_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'LPS_10.000_DMSO_0.025']
The dimensions of the data are: (52453, 1276)
Number of total missing values across all columns: 104906
Data Subset Is Off
Wells held out for testing: ['E20' 'I14']
Wells to use for training, validation, and testing ['B14' 'C14' 'B15' 'C15' 'E16' 'E17' 'E21' 'J14' 'I15' 'J15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.540036).  Saving model ...
	 Train_Loss: 0.6138 Train_Acc: 62.668 Val_Loss: 0.5400  BEST VAL Loss: 0.5400  Val_Acc: 72.060

Epoch 1: Validation loss decreased (0.540036 --> 0.527414).  Saving model ...
	 Train_Loss: 0.5817 Train_Acc: 71.092 Val_Loss: 0.5274  BEST VAL Loss: 0.5274  Val_Acc: 73.487

Epoch 2: Validation loss decreased (0.527414 --> 0.517468).  Saving model ...
	 Train_Loss: 0.5637 Train_Acc: 72.829 Val_Loss: 0.5175  BEST VAL Loss: 0.5175  Val_Acc: 74.822

Epoch 3: Validation loss decreased (0.517468 --> 0.510481).  Saving model ...
	 Train_Loss: 0.5508 Train_Acc: 73.313 Val_Loss: 0.5105  BEST VAL Loss: 0.5105  Val_Acc: 76.525

Epoch 4: Validation loss decreased (0.510481 --> 0.506119).  Saving model ...
	 Train_Loss: 0.5415 Train_Acc: 73.784 Val_Loss: 0.5061  BEST VAL Loss: 0.5061  Val_Acc: 76.686

Epoch 5: Validation loss decreased (0.506119 --> 0.502039).  Saving model ...
	 Train_Loss: 0.5339 Train_Acc: 74.179 Val_Loss: 0.5020  BEST VAL Loss: 0.5020  Val_Acc: 77.215

Epoch 6: Validation loss decreased (0.502039 --> 0.498219).  Saving model ...
	 Train_Loss: 0.5273 Train_Acc: 74.348 Val_Loss: 0.4982  BEST VAL Loss: 0.4982  Val_Acc: 77.353

Epoch 7: Validation loss decreased (0.498219 --> 0.495104).  Saving model ...
	 Train_Loss: 0.5221 Train_Acc: 74.432 Val_Loss: 0.4951  BEST VAL Loss: 0.4951  Val_Acc: 77.445

Epoch 8: Validation loss decreased (0.495104 --> 0.492740).  Saving model ...
	 Train_Loss: 0.5178 Train_Acc: 74.535 Val_Loss: 0.4927  BEST VAL Loss: 0.4927  Val_Acc: 77.054

Epoch 9: Validation loss decreased (0.492740 --> 0.490897).  Saving model ...
	 Train_Loss: 0.5139 Train_Acc: 74.829 Val_Loss: 0.4909  BEST VAL Loss: 0.4909  Val_Acc: 77.814

Epoch 10: Validation loss decreased (0.490897 --> 0.489070).  Saving model ...
	 Train_Loss: 0.5105 Train_Acc: 74.898 Val_Loss: 0.4891  BEST VAL Loss: 0.4891  Val_Acc: 77.445

Epoch 11: Validation loss decreased (0.489070 --> 0.487901).  Saving model ...
	 Train_Loss: 0.5074 Train_Acc: 75.226 Val_Loss: 0.4879  BEST VAL Loss: 0.4879  Val_Acc: 77.606

Epoch 12: Validation loss decreased (0.487901 --> 0.486653).  Saving model ...
	 Train_Loss: 0.5047 Train_Acc: 74.768 Val_Loss: 0.4867  BEST VAL Loss: 0.4867  Val_Acc: 77.975

Epoch 13: Validation loss decreased (0.486653 --> 0.485797).  Saving model ...
	 Train_Loss: 0.5023 Train_Acc: 75.321 Val_Loss: 0.4858  BEST VAL Loss: 0.4858  Val_Acc: 78.044

Epoch 14: Validation loss decreased (0.485797 --> 0.484866).  Saving model ...
	 Train_Loss: 0.5000 Train_Acc: 75.462 Val_Loss: 0.4849  BEST VAL Loss: 0.4849  Val_Acc: 77.652

Epoch 15: Validation loss decreased (0.484866 --> 0.483834).  Saving model ...
	 Train_Loss: 0.4977 Train_Acc: 75.404 Val_Loss: 0.4838  BEST VAL Loss: 0.4838  Val_Acc: 77.975

Epoch 16: Validation loss decreased (0.483834 --> 0.483277).  Saving model ...
	 Train_Loss: 0.4956 Train_Acc: 75.252 Val_Loss: 0.4833  BEST VAL Loss: 0.4833  Val_Acc: 77.860

Epoch 17: Validation loss decreased (0.483277 --> 0.483158).  Saving model ...
	 Train_Loss: 0.4938 Train_Acc: 75.324 Val_Loss: 0.4832  BEST VAL Loss: 0.4832  Val_Acc: 77.952

Epoch 18: Validation loss decreased (0.483158 --> 0.482433).  Saving model ...
	 Train_Loss: 0.4920 Train_Acc: 75.367 Val_Loss: 0.4824  BEST VAL Loss: 0.4824  Val_Acc: 77.929

Epoch 19: Validation loss decreased (0.482433 --> 0.481666).  Saving model ...
	 Train_Loss: 0.4904 Train_Acc: 75.404 Val_Loss: 0.4817  BEST VAL Loss: 0.4817  Val_Acc: 78.412

Epoch 20: Validation loss decreased (0.481666 --> 0.480854).  Saving model ...
	 Train_Loss: 0.4887 Train_Acc: 75.508 Val_Loss: 0.4809  BEST VAL Loss: 0.4809  Val_Acc: 77.560

Epoch 21: Validation loss decreased (0.480854 --> 0.480272).  Saving model ...
	 Train_Loss: 0.4873 Train_Acc: 75.419 Val_Loss: 0.4803  BEST VAL Loss: 0.4803  Val_Acc: 78.596

Epoch 22: Validation loss decreased (0.480272 --> 0.479842).  Saving model ...
	 Train_Loss: 0.4860 Train_Acc: 75.243 Val_Loss: 0.4798  BEST VAL Loss: 0.4798  Val_Acc: 78.090

Epoch 23: Validation loss decreased (0.479842 --> 0.479517).  Saving model ...
	 Train_Loss: 0.4847 Train_Acc: 75.585 Val_Loss: 0.4795  BEST VAL Loss: 0.4795  Val_Acc: 77.814

Epoch 24: Validation loss decreased (0.479517 --> 0.479141).  Saving model ...
	 Train_Loss: 0.4835 Train_Acc: 75.732 Val_Loss: 0.4791  BEST VAL Loss: 0.4791  Val_Acc: 78.113

Epoch 25: Validation loss decreased (0.479141 --> 0.479062).  Saving model ...
	 Train_Loss: 0.4824 Train_Acc: 75.709 Val_Loss: 0.4791  BEST VAL Loss: 0.4791  Val_Acc: 78.205

Epoch 26: Validation loss decreased (0.479062 --> 0.478944).  Saving model ...
	 Train_Loss: 0.4813 Train_Acc: 75.755 Val_Loss: 0.4789  BEST VAL Loss: 0.4789  Val_Acc: 78.136

Epoch 27: Validation loss decreased (0.478944 --> 0.478473).  Saving model ...
	 Train_Loss: 0.4801 Train_Acc: 75.951 Val_Loss: 0.4785  BEST VAL Loss: 0.4785  Val_Acc: 78.113

Epoch 28: Validation loss decreased (0.478473 --> 0.477942).  Saving model ...
	 Train_Loss: 0.4790 Train_Acc: 75.856 Val_Loss: 0.4779  BEST VAL Loss: 0.4779  Val_Acc: 78.205

Epoch 29: Validation loss decreased (0.477942 --> 0.477709).  Saving model ...
	 Train_Loss: 0.4780 Train_Acc: 76.040 Val_Loss: 0.4777  BEST VAL Loss: 0.4777  Val_Acc: 77.952

Epoch 30: Validation loss decreased (0.477709 --> 0.477629).  Saving model ...
	 Train_Loss: 0.4769 Train_Acc: 76.000 Val_Loss: 0.4776  BEST VAL Loss: 0.4776  Val_Acc: 77.560

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.4760 Train_Acc: 75.712 Val_Loss: 0.4777  BEST VAL Loss: 0.4776  Val_Acc: 78.688

Epoch 32: Validation loss decreased (0.477629 --> 0.477443).  Saving model ...
	 Train_Loss: 0.4751 Train_Acc: 75.695 Val_Loss: 0.4774  BEST VAL Loss: 0.4774  Val_Acc: 78.412

Epoch 33: Validation loss decreased (0.477443 --> 0.477324).  Saving model ...
	 Train_Loss: 0.4742 Train_Acc: 75.678 Val_Loss: 0.4773  BEST VAL Loss: 0.4773  Val_Acc: 78.067

Epoch 34: Validation loss decreased (0.477324 --> 0.476968).  Saving model ...
	 Train_Loss: 0.4733 Train_Acc: 75.793 Val_Loss: 0.4770  BEST VAL Loss: 0.4770  Val_Acc: 78.734

Epoch 35: Validation loss decreased (0.476968 --> 0.476856).  Saving model ...
	 Train_Loss: 0.4725 Train_Acc: 76.264 Val_Loss: 0.4769  BEST VAL Loss: 0.4769  Val_Acc: 78.205

Epoch 36: Validation loss decreased (0.476856 --> 0.476795).  Saving model ...
	 Train_Loss: 0.4717 Train_Acc: 75.899 Val_Loss: 0.4768  BEST VAL Loss: 0.4768  Val_Acc: 78.044

Epoch 37: Validation loss decreased (0.476795 --> 0.476658).  Saving model ...
	 Train_Loss: 0.4710 Train_Acc: 76.066 Val_Loss: 0.4767  BEST VAL Loss: 0.4767  Val_Acc: 78.573

Epoch 38: Validation loss decreased (0.476658 --> 0.476453).  Saving model ...
	 Train_Loss: 0.4702 Train_Acc: 75.911 Val_Loss: 0.4765  BEST VAL Loss: 0.4765  Val_Acc: 78.435

Epoch 39: Validation loss decreased (0.476453 --> 0.476304).  Saving model ...
	 Train_Loss: 0.4695 Train_Acc: 77.807 Val_Loss: 0.4763  BEST VAL Loss: 0.4763  Val_Acc: 78.297

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.4687 Train_Acc: 77.789 Val_Loss: 0.4764  BEST VAL Loss: 0.4763  Val_Acc: 78.389

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.4680 Train_Acc: 77.965 Val_Loss: 0.4768  BEST VAL Loss: 0.4763  Val_Acc: 78.826

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.4673 Train_Acc: 78.206 Val_Loss: 0.4768  BEST VAL Loss: 0.4763  Val_Acc: 78.343

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.4666 Train_Acc: 78.560 Val_Loss: 0.4767  BEST VAL Loss: 0.4763  Val_Acc: 78.458

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.4659 Train_Acc: 78.523 Val_Loss: 0.4767  BEST VAL Loss: 0.4763  Val_Acc: 78.228

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.4652 Train_Acc: 78.635 Val_Loss: 0.4767  BEST VAL Loss: 0.4763  Val_Acc: 78.711

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.4646 Train_Acc: 78.552 Val_Loss: 0.4767  BEST VAL Loss: 0.4763  Val_Acc: 78.941

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.4640 Train_Acc: 78.721 Val_Loss: 0.4765  BEST VAL Loss: 0.4763  Val_Acc: 78.251

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.4634 Train_Acc: 78.750 Val_Loss: 0.4766  BEST VAL Loss: 0.4763  Val_Acc: 78.343

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.4628 Train_Acc: 78.788 Val_Loss: 0.4768  BEST VAL Loss: 0.4763  Val_Acc: 78.481

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.4622 Train_Acc: 78.595 Val_Loss: 0.4768  BEST VAL Loss: 0.4763  Val_Acc: 78.665

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.4617 Train_Acc: 78.494 Val_Loss: 0.4767  BEST VAL Loss: 0.4763  Val_Acc: 78.389

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.4611 Train_Acc: 78.652 Val_Loss: 0.4766  BEST VAL Loss: 0.4763  Val_Acc: 78.527

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.4606 Train_Acc: 78.664 Val_Loss: 0.4766  BEST VAL Loss: 0.4763  Val_Acc: 78.067

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.4600 Train_Acc: 78.739 Val_Loss: 0.4766  BEST VAL Loss: 0.4763  Val_Acc: 78.435

Epoch 55: Validation loss did not decrease
Early stopped at epoch : 55
LPS_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.71      0.80      0.75     24644
           1       0.30      0.20      0.24     10114

    accuracy                           0.63     34758
   macro avg       0.50      0.50      0.50     34758
weighted avg       0.59      0.63      0.60     34758

LPS_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.70      0.80      0.75      3081
           1       0.27      0.18      0.21      1264

    accuracy                           0.62      4345
   macro avg       0.49      0.49      0.48      4345
weighted avg       0.58      0.62      0.59      4345

LPS_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.71      0.81      0.75      3081
           1       0.29      0.19      0.23      1264

    accuracy                           0.63      4345
   macro avg       0.50      0.50      0.49      4345
weighted avg       0.59      0.63      0.60      4345

              precision    recall  f1-score   support

           0       0.71      0.81      0.75      3081
           1       0.29      0.19      0.23      1264

    accuracy                           0.63      4345
   macro avg       0.50      0.50      0.49      4345
weighted avg       0.59      0.63      0.60      4345

LPS_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.54      0.73      0.62      4837
           1       0.46      0.27      0.34      4168

    accuracy                           0.52      9005
   macro avg       0.50      0.50      0.48      9005
weighted avg       0.50      0.52      0.49      9005

              precision    recall  f1-score   support

           0       0.54      0.73      0.62      4837
           1       0.46      0.27      0.34      4168

    accuracy                           0.52      9005
   macro avg       0.50      0.50      0.48      9005
weighted avg       0.50      0.52      0.49      9005

completed
