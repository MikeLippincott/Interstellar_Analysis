[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '2111b003'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'bf2fdbe6'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '81bca9e3'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'd3fdfb09'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Thapsigargin_1.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Thapsigargin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (322717, 1270)
Number of total missing values across all columns: 296912
Data Subset Is Off
Wells held out for testing: ['K06' 'L09']
Wells to use for training, validation, and testing ['D06' 'D07' 'K07' 'L02' 'L03' 'L08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.188351).  Saving model ...
	 Train_Loss: 0.3285 Train_Acc: 85.810 Val_Loss: 0.1884  BEST VAL Loss: 0.1884  Val_Acc: 92.885

Epoch 1: Validation loss decreased (0.188351 --> 0.179456).  Saving model ...
	 Train_Loss: 0.2804 Train_Acc: 91.851 Val_Loss: 0.1795  BEST VAL Loss: 0.1795  Val_Acc: 93.680

Epoch 2: Validation loss decreased (0.179456 --> 0.171592).  Saving model ...
	 Train_Loss: 0.2576 Train_Acc: 92.098 Val_Loss: 0.1716  BEST VAL Loss: 0.1716  Val_Acc: 93.988

Epoch 3: Validation loss decreased (0.171592 --> 0.166632).  Saving model ...
	 Train_Loss: 0.2433 Train_Acc: 92.327 Val_Loss: 0.1666  BEST VAL Loss: 0.1666  Val_Acc: 94.284

Epoch 4: Validation loss decreased (0.166632 --> 0.162063).  Saving model ...
	 Train_Loss: 0.2337 Train_Acc: 92.476 Val_Loss: 0.1621  BEST VAL Loss: 0.1621  Val_Acc: 94.421

Epoch 5: Validation loss decreased (0.162063 --> 0.158743).  Saving model ...
	 Train_Loss: 0.2262 Train_Acc: 92.615 Val_Loss: 0.1587  BEST VAL Loss: 0.1587  Val_Acc: 94.721

Epoch 6: Validation loss decreased (0.158743 --> 0.155804).  Saving model ...
	 Train_Loss: 0.2202 Train_Acc: 92.714 Val_Loss: 0.1558  BEST VAL Loss: 0.1558  Val_Acc: 94.888

Epoch 7: Validation loss decreased (0.155804 --> 0.153598).  Saving model ...
	 Train_Loss: 0.2155 Train_Acc: 92.766 Val_Loss: 0.1536  BEST VAL Loss: 0.1536  Val_Acc: 94.685

Epoch 8: Validation loss decreased (0.153598 --> 0.151435).  Saving model ...
	 Train_Loss: 0.2115 Train_Acc: 92.888 Val_Loss: 0.1514  BEST VAL Loss: 0.1514  Val_Acc: 94.823

Epoch 9: Validation loss decreased (0.151435 --> 0.150085).  Saving model ...
	 Train_Loss: 0.2081 Train_Acc: 92.889 Val_Loss: 0.1501  BEST VAL Loss: 0.1501  Val_Acc: 94.677

Epoch 10: Validation loss decreased (0.150085 --> 0.148719).  Saving model ...
	 Train_Loss: 0.2052 Train_Acc: 92.933 Val_Loss: 0.1487  BEST VAL Loss: 0.1487  Val_Acc: 94.843

Epoch 11: Validation loss decreased (0.148719 --> 0.147538).  Saving model ...
	 Train_Loss: 0.2026 Train_Acc: 93.040 Val_Loss: 0.1475  BEST VAL Loss: 0.1475  Val_Acc: 94.713

Epoch 12: Validation loss decreased (0.147538 --> 0.146207).  Saving model ...
	 Train_Loss: 0.2003 Train_Acc: 93.029 Val_Loss: 0.1462  BEST VAL Loss: 0.1462  Val_Acc: 94.985

Epoch 13: Validation loss decreased (0.146207 --> 0.145005).  Saving model ...
	 Train_Loss: 0.1983 Train_Acc: 93.053 Val_Loss: 0.1450  BEST VAL Loss: 0.1450  Val_Acc: 95.192

Epoch 14: Validation loss decreased (0.145005 --> 0.143982).  Saving model ...
	 Train_Loss: 0.1965 Train_Acc: 93.137 Val_Loss: 0.1440  BEST VAL Loss: 0.1440  Val_Acc: 95.054

Epoch 15: Validation loss decreased (0.143982 --> 0.143048).  Saving model ...
	 Train_Loss: 0.1948 Train_Acc: 93.108 Val_Loss: 0.1430  BEST VAL Loss: 0.1430  Val_Acc: 94.920

Epoch 16: Validation loss decreased (0.143048 --> 0.142244).  Saving model ...
	 Train_Loss: 0.1932 Train_Acc: 93.297 Val_Loss: 0.1422  BEST VAL Loss: 0.1422  Val_Acc: 94.904

Epoch 17: Validation loss decreased (0.142244 --> 0.141339).  Saving model ...
	 Train_Loss: 0.1918 Train_Acc: 93.187 Val_Loss: 0.1413  BEST VAL Loss: 0.1413  Val_Acc: 95.257

Epoch 18: Validation loss decreased (0.141339 --> 0.140707).  Saving model ...
	 Train_Loss: 0.1905 Train_Acc: 93.329 Val_Loss: 0.1407  BEST VAL Loss: 0.1407  Val_Acc: 95.066

Epoch 19: Validation loss decreased (0.140707 --> 0.139887).  Saving model ...
	 Train_Loss: 0.1891 Train_Acc: 93.372 Val_Loss: 0.1399  BEST VAL Loss: 0.1399  Val_Acc: 95.508

Epoch 20: Validation loss decreased (0.139887 --> 0.139369).  Saving model ...
	 Train_Loss: 0.1879 Train_Acc: 93.364 Val_Loss: 0.1394  BEST VAL Loss: 0.1394  Val_Acc: 95.330

Epoch 21: Validation loss decreased (0.139369 --> 0.138960).  Saving model ...
	 Train_Loss: 0.1868 Train_Acc: 93.411 Val_Loss: 0.1390  BEST VAL Loss: 0.1390  Val_Acc: 95.419

Epoch 22: Validation loss decreased (0.138960 --> 0.138452).  Saving model ...
	 Train_Loss: 0.1857 Train_Acc: 93.429 Val_Loss: 0.1385  BEST VAL Loss: 0.1385  Val_Acc: 95.240

Epoch 23: Validation loss decreased (0.138452 --> 0.138007).  Saving model ...
	 Train_Loss: 0.1848 Train_Acc: 93.413 Val_Loss: 0.1380  BEST VAL Loss: 0.1380  Val_Acc: 95.415

Epoch 24: Validation loss decreased (0.138007 --> 0.137533).  Saving model ...
	 Train_Loss: 0.1838 Train_Acc: 93.512 Val_Loss: 0.1375  BEST VAL Loss: 0.1375  Val_Acc: 95.540

Epoch 25: Validation loss decreased (0.137533 --> 0.137170).  Saving model ...
	 Train_Loss: 0.1829 Train_Acc: 93.497 Val_Loss: 0.1372  BEST VAL Loss: 0.1372  Val_Acc: 95.151

Epoch 26: Validation loss decreased (0.137170 --> 0.136640).  Saving model ...
	 Train_Loss: 0.1821 Train_Acc: 93.506 Val_Loss: 0.1366  BEST VAL Loss: 0.1366  Val_Acc: 95.484

Epoch 27: Validation loss decreased (0.136640 --> 0.136260).  Saving model ...
	 Train_Loss: 0.1813 Train_Acc: 93.529 Val_Loss: 0.1363  BEST VAL Loss: 0.1363  Val_Acc: 95.569

Epoch 28: Validation loss decreased (0.136260 --> 0.135800).  Saving model ...
	 Train_Loss: 0.1805 Train_Acc: 93.530 Val_Loss: 0.1358  BEST VAL Loss: 0.1358  Val_Acc: 95.638

Epoch 29: Validation loss decreased (0.135800 --> 0.135444).  Saving model ...
	 Train_Loss: 0.1798 Train_Acc: 93.521 Val_Loss: 0.1354  BEST VAL Loss: 0.1354  Val_Acc: 95.232

Epoch 30: Validation loss decreased (0.135444 --> 0.135236).  Saving model ...
	 Train_Loss: 0.1791 Train_Acc: 93.614 Val_Loss: 0.1352  BEST VAL Loss: 0.1352  Val_Acc: 95.200

Epoch 31: Validation loss decreased (0.135236 --> 0.134838).  Saving model ...
	 Train_Loss: 0.1785 Train_Acc: 93.534 Val_Loss: 0.1348  BEST VAL Loss: 0.1348  Val_Acc: 95.407

Epoch 32: Validation loss decreased (0.134838 --> 0.134449).  Saving model ...
	 Train_Loss: 0.1779 Train_Acc: 93.627 Val_Loss: 0.1344  BEST VAL Loss: 0.1344  Val_Acc: 95.370

Epoch 33: Validation loss decreased (0.134449 --> 0.134099).  Saving model ...
	 Train_Loss: 0.1773 Train_Acc: 93.588 Val_Loss: 0.1341  BEST VAL Loss: 0.1341  Val_Acc: 95.540

Epoch 34: Validation loss decreased (0.134099 --> 0.133827).  Saving model ...
	 Train_Loss: 0.1767 Train_Acc: 93.565 Val_Loss: 0.1338  BEST VAL Loss: 0.1338  Val_Acc: 95.167

Epoch 35: Validation loss decreased (0.133827 --> 0.133480).  Saving model ...
	 Train_Loss: 0.1761 Train_Acc: 93.682 Val_Loss: 0.1335  BEST VAL Loss: 0.1335  Val_Acc: 95.719

Epoch 36: Validation loss decreased (0.133480 --> 0.133094).  Saving model ...
	 Train_Loss: 0.1756 Train_Acc: 93.640 Val_Loss: 0.1331  BEST VAL Loss: 0.1331  Val_Acc: 95.366

Epoch 37: Validation loss decreased (0.133094 --> 0.132799).  Saving model ...
	 Train_Loss: 0.1751 Train_Acc: 93.673 Val_Loss: 0.1328  BEST VAL Loss: 0.1328  Val_Acc: 95.407

Epoch 38: Validation loss decreased (0.132799 --> 0.132546).  Saving model ...
	 Train_Loss: 0.1746 Train_Acc: 93.651 Val_Loss: 0.1325  BEST VAL Loss: 0.1325  Val_Acc: 95.346

Epoch 39: Validation loss decreased (0.132546 --> 0.132273).  Saving model ...
	 Train_Loss: 0.1741 Train_Acc: 93.639 Val_Loss: 0.1323  BEST VAL Loss: 0.1323  Val_Acc: 95.265

Epoch 40: Validation loss decreased (0.132273 --> 0.132030).  Saving model ...
	 Train_Loss: 0.1736 Train_Acc: 93.720 Val_Loss: 0.1320  BEST VAL Loss: 0.1320  Val_Acc: 95.658

Epoch 41: Validation loss decreased (0.132030 --> 0.131813).  Saving model ...
	 Train_Loss: 0.1732 Train_Acc: 93.732 Val_Loss: 0.1318  BEST VAL Loss: 0.1318  Val_Acc: 95.767

Epoch 42: Validation loss decreased (0.131813 --> 0.131650).  Saving model ...
	 Train_Loss: 0.1727 Train_Acc: 93.753 Val_Loss: 0.1317  BEST VAL Loss: 0.1317  Val_Acc: 95.727

Epoch 43: Validation loss decreased (0.131650 --> 0.131496).  Saving model ...
	 Train_Loss: 0.1723 Train_Acc: 93.756 Val_Loss: 0.1315  BEST VAL Loss: 0.1315  Val_Acc: 95.561

Epoch 44: Validation loss decreased (0.131496 --> 0.131266).  Saving model ...
	 Train_Loss: 0.1719 Train_Acc: 93.831 Val_Loss: 0.1313  BEST VAL Loss: 0.1313  Val_Acc: 95.208

Epoch 45: Validation loss decreased (0.131266 --> 0.131110).  Saving model ...
	 Train_Loss: 0.1715 Train_Acc: 93.769 Val_Loss: 0.1311  BEST VAL Loss: 0.1311  Val_Acc: 95.249

Epoch 46: Validation loss decreased (0.131110 --> 0.131075).  Saving model ...
	 Train_Loss: 0.1711 Train_Acc: 93.691 Val_Loss: 0.1311  BEST VAL Loss: 0.1311  Val_Acc: 95.030

Epoch 47: Validation loss decreased (0.131075 --> 0.130830).  Saving model ...
	 Train_Loss: 0.1708 Train_Acc: 93.760 Val_Loss: 0.1308  BEST VAL Loss: 0.1308  Val_Acc: 95.642

Epoch 48: Validation loss decreased (0.130830 --> 0.130621).  Saving model ...
	 Train_Loss: 0.1704 Train_Acc: 93.791 Val_Loss: 0.1306  BEST VAL Loss: 0.1306  Val_Acc: 95.544

Epoch 49: Validation loss decreased (0.130621 --> 0.130411).  Saving model ...
	 Train_Loss: 0.1700 Train_Acc: 93.744 Val_Loss: 0.1304  BEST VAL Loss: 0.1304  Val_Acc: 95.435

Epoch 50: Validation loss decreased (0.130411 --> 0.130215).  Saving model ...
	 Train_Loss: 0.1697 Train_Acc: 93.902 Val_Loss: 0.1302  BEST VAL Loss: 0.1302  Val_Acc: 95.828

Epoch 51: Validation loss decreased (0.130215 --> 0.130021).  Saving model ...
	 Train_Loss: 0.1693 Train_Acc: 93.779 Val_Loss: 0.1300  BEST VAL Loss: 0.1300  Val_Acc: 95.419

Epoch 52: Validation loss decreased (0.130021 --> 0.129910).  Saving model ...
	 Train_Loss: 0.1690 Train_Acc: 93.830 Val_Loss: 0.1299  BEST VAL Loss: 0.1299  Val_Acc: 95.411

Epoch 53: Validation loss decreased (0.129910 --> 0.129767).  Saving model ...
	 Train_Loss: 0.1686 Train_Acc: 93.878 Val_Loss: 0.1298  BEST VAL Loss: 0.1298  Val_Acc: 95.382

Epoch 54: Validation loss decreased (0.129767 --> 0.129631).  Saving model ...
	 Train_Loss: 0.1683 Train_Acc: 93.856 Val_Loss: 0.1296  BEST VAL Loss: 0.1296  Val_Acc: 95.622

Epoch 55: Validation loss decreased (0.129631 --> 0.129443).  Saving model ...
	 Train_Loss: 0.1680 Train_Acc: 93.850 Val_Loss: 0.1294  BEST VAL Loss: 0.1294  Val_Acc: 95.840

Epoch 56: Validation loss decreased (0.129443 --> 0.129286).  Saving model ...
	 Train_Loss: 0.1677 Train_Acc: 93.865 Val_Loss: 0.1293  BEST VAL Loss: 0.1293  Val_Acc: 95.759

Epoch 57: Validation loss decreased (0.129286 --> 0.129134).  Saving model ...
	 Train_Loss: 0.1674 Train_Acc: 93.911 Val_Loss: 0.1291  BEST VAL Loss: 0.1291  Val_Acc: 95.820

Epoch 58: Validation loss decreased (0.129134 --> 0.129036).  Saving model ...
	 Train_Loss: 0.1671 Train_Acc: 93.893 Val_Loss: 0.1290  BEST VAL Loss: 0.1290  Val_Acc: 95.573

Epoch 59: Validation loss decreased (0.129036 --> 0.128872).  Saving model ...
	 Train_Loss: 0.1668 Train_Acc: 93.854 Val_Loss: 0.1289  BEST VAL Loss: 0.1289  Val_Acc: 95.735

Epoch 60: Validation loss decreased (0.128872 --> 0.128717).  Saving model ...
	 Train_Loss: 0.1666 Train_Acc: 93.885 Val_Loss: 0.1287  BEST VAL Loss: 0.1287  Val_Acc: 95.812

Epoch 61: Validation loss decreased (0.128717 --> 0.128572).  Saving model ...
	 Train_Loss: 0.1663 Train_Acc: 93.850 Val_Loss: 0.1286  BEST VAL Loss: 0.1286  Val_Acc: 95.694

Epoch 62: Validation loss decreased (0.128572 --> 0.128487).  Saving model ...
	 Train_Loss: 0.1660 Train_Acc: 93.942 Val_Loss: 0.1285  BEST VAL Loss: 0.1285  Val_Acc: 95.386

Epoch 63: Validation loss decreased (0.128487 --> 0.128339).  Saving model ...
	 Train_Loss: 0.1658 Train_Acc: 93.992 Val_Loss: 0.1283  BEST VAL Loss: 0.1283  Val_Acc: 95.549

Epoch 64: Validation loss decreased (0.128339 --> 0.128272).  Saving model ...
	 Train_Loss: 0.1655 Train_Acc: 93.955 Val_Loss: 0.1283  BEST VAL Loss: 0.1283  Val_Acc: 95.403

Epoch 65: Validation loss decreased (0.128272 --> 0.128151).  Saving model ...
	 Train_Loss: 0.1652 Train_Acc: 93.957 Val_Loss: 0.1282  BEST VAL Loss: 0.1282  Val_Acc: 95.512

Epoch 66: Validation loss decreased (0.128151 --> 0.128039).  Saving model ...
	 Train_Loss: 0.1650 Train_Acc: 94.004 Val_Loss: 0.1280  BEST VAL Loss: 0.1280  Val_Acc: 95.540

Epoch 67: Validation loss decreased (0.128039 --> 0.127942).  Saving model ...
	 Train_Loss: 0.1648 Train_Acc: 93.936 Val_Loss: 0.1279  BEST VAL Loss: 0.1279  Val_Acc: 95.759

Epoch 68: Validation loss decreased (0.127942 --> 0.127835).  Saving model ...
	 Train_Loss: 0.1645 Train_Acc: 93.903 Val_Loss: 0.1278  BEST VAL Loss: 0.1278  Val_Acc: 95.403

Epoch 69: Validation loss decreased (0.127835 --> 0.127689).  Saving model ...
	 Train_Loss: 0.1643 Train_Acc: 94.055 Val_Loss: 0.1277  BEST VAL Loss: 0.1277  Val_Acc: 95.427

Epoch 70: Validation loss decreased (0.127689 --> 0.127642).  Saving model ...
	 Train_Loss: 0.1640 Train_Acc: 94.024 Val_Loss: 0.1276  BEST VAL Loss: 0.1276  Val_Acc: 95.403

Epoch 71: Validation loss decreased (0.127642 --> 0.127551).  Saving model ...
	 Train_Loss: 0.1638 Train_Acc: 94.039 Val_Loss: 0.1276  BEST VAL Loss: 0.1276  Val_Acc: 95.739

Epoch 72: Validation loss decreased (0.127551 --> 0.127474).  Saving model ...
	 Train_Loss: 0.1636 Train_Acc: 93.954 Val_Loss: 0.1275  BEST VAL Loss: 0.1275  Val_Acc: 95.208

Epoch 73: Validation loss decreased (0.127474 --> 0.127423).  Saving model ...
	 Train_Loss: 0.1634 Train_Acc: 93.972 Val_Loss: 0.1274  BEST VAL Loss: 0.1274  Val_Acc: 95.946

Epoch 74: Validation loss decreased (0.127423 --> 0.127332).  Saving model ...
	 Train_Loss: 0.1631 Train_Acc: 94.008 Val_Loss: 0.1273  BEST VAL Loss: 0.1273  Val_Acc: 95.865

Epoch 75: Validation loss decreased (0.127332 --> 0.127274).  Saving model ...
	 Train_Loss: 0.1629 Train_Acc: 94.058 Val_Loss: 0.1273  BEST VAL Loss: 0.1273  Val_Acc: 95.816

Epoch 76: Validation loss decreased (0.127274 --> 0.127192).  Saving model ...
	 Train_Loss: 0.1627 Train_Acc: 94.024 Val_Loss: 0.1272  BEST VAL Loss: 0.1272  Val_Acc: 95.849

Epoch 77: Validation loss decreased (0.127192 --> 0.127169).  Saving model ...
	 Train_Loss: 0.1625 Train_Acc: 93.981 Val_Loss: 0.1272  BEST VAL Loss: 0.1272  Val_Acc: 95.784

Epoch 78: Validation loss decreased (0.127169 --> 0.127064).  Saving model ...
	 Train_Loss: 0.1623 Train_Acc: 94.032 Val_Loss: 0.1271  BEST VAL Loss: 0.1271  Val_Acc: 95.439

Epoch 79: Validation loss decreased (0.127064 --> 0.126978).  Saving model ...
	 Train_Loss: 0.1621 Train_Acc: 94.028 Val_Loss: 0.1270  BEST VAL Loss: 0.1270  Val_Acc: 95.804

Epoch 80: Validation loss decreased (0.126978 --> 0.126904).  Saving model ...
	 Train_Loss: 0.1619 Train_Acc: 94.097 Val_Loss: 0.1269  BEST VAL Loss: 0.1269  Val_Acc: 95.913

Epoch 81: Validation loss decreased (0.126904 --> 0.126857).  Saving model ...
	 Train_Loss: 0.1617 Train_Acc: 93.906 Val_Loss: 0.1269  BEST VAL Loss: 0.1269  Val_Acc: 95.731

Epoch 82: Validation loss decreased (0.126857 --> 0.126757).  Saving model ...
	 Train_Loss: 0.1615 Train_Acc: 94.045 Val_Loss: 0.1268  BEST VAL Loss: 0.1268  Val_Acc: 95.938

Epoch 83: Validation loss decreased (0.126757 --> 0.126684).  Saving model ...
	 Train_Loss: 0.1614 Train_Acc: 94.114 Val_Loss: 0.1267  BEST VAL Loss: 0.1267  Val_Acc: 95.954

Epoch 84: Validation loss decreased (0.126684 --> 0.126569).  Saving model ...
	 Train_Loss: 0.1612 Train_Acc: 94.009 Val_Loss: 0.1266  BEST VAL Loss: 0.1266  Val_Acc: 95.885

Epoch 85: Validation loss decreased (0.126569 --> 0.126501).  Saving model ...
	 Train_Loss: 0.1610 Train_Acc: 94.126 Val_Loss: 0.1265  BEST VAL Loss: 0.1265  Val_Acc: 95.913

Epoch 86: Validation loss decreased (0.126501 --> 0.126461).  Saving model ...
	 Train_Loss: 0.1608 Train_Acc: 94.175 Val_Loss: 0.1265  BEST VAL Loss: 0.1265  Val_Acc: 95.938

Epoch 87: Validation loss decreased (0.126461 --> 0.126390).  Saving model ...
	 Train_Loss: 0.1606 Train_Acc: 94.131 Val_Loss: 0.1264  BEST VAL Loss: 0.1264  Val_Acc: 95.796

Epoch 88: Validation loss decreased (0.126390 --> 0.126294).  Saving model ...
	 Train_Loss: 0.1604 Train_Acc: 94.064 Val_Loss: 0.1263  BEST VAL Loss: 0.1263  Val_Acc: 96.043

Epoch 89: Validation loss decreased (0.126294 --> 0.126214).  Saving model ...
	 Train_Loss: 0.1603 Train_Acc: 94.056 Val_Loss: 0.1262  BEST VAL Loss: 0.1262  Val_Acc: 95.853

Epoch 90: Validation loss decreased (0.126214 --> 0.126132).  Saving model ...
	 Train_Loss: 0.1601 Train_Acc: 94.151 Val_Loss: 0.1261  BEST VAL Loss: 0.1261  Val_Acc: 96.019

Epoch 91: Validation loss decreased (0.126132 --> 0.126111).  Saving model ...
	 Train_Loss: 0.1599 Train_Acc: 93.976 Val_Loss: 0.1261  BEST VAL Loss: 0.1261  Val_Acc: 95.812

Epoch 92: Validation loss decreased (0.126111 --> 0.126022).  Saving model ...
	 Train_Loss: 0.1597 Train_Acc: 94.144 Val_Loss: 0.1260  BEST VAL Loss: 0.1260  Val_Acc: 95.958

Epoch 93: Validation loss decreased (0.126022 --> 0.125965).  Saving model ...
	 Train_Loss: 0.1596 Train_Acc: 94.038 Val_Loss: 0.1260  BEST VAL Loss: 0.1260  Val_Acc: 95.958

Epoch 94: Validation loss decreased (0.125965 --> 0.125947).  Saving model ...
	 Train_Loss: 0.1594 Train_Acc: 94.092 Val_Loss: 0.1259  BEST VAL Loss: 0.1259  Val_Acc: 95.780

Epoch 95: Validation loss decreased (0.125947 --> 0.125886).  Saving model ...
	 Train_Loss: 0.1593 Train_Acc: 94.127 Val_Loss: 0.1259  BEST VAL Loss: 0.1259  Val_Acc: 95.849

Epoch 96: Validation loss decreased (0.125886 --> 0.125804).  Saving model ...
	 Train_Loss: 0.1591 Train_Acc: 94.149 Val_Loss: 0.1258  BEST VAL Loss: 0.1258  Val_Acc: 95.719

Epoch 97: Validation loss decreased (0.125804 --> 0.125756).  Saving model ...
	 Train_Loss: 0.1589 Train_Acc: 94.127 Val_Loss: 0.1258  BEST VAL Loss: 0.1258  Val_Acc: 95.861

Epoch 98: Validation loss decreased (0.125756 --> 0.125725).  Saving model ...
	 Train_Loss: 0.1588 Train_Acc: 94.126 Val_Loss: 0.1257  BEST VAL Loss: 0.1257  Val_Acc: 95.565

Epoch 99: Validation loss decreased (0.125725 --> 0.125678).  Saving model ...
	 Train_Loss: 0.1586 Train_Acc: 94.129 Val_Loss: 0.1257  BEST VAL Loss: 0.1257  Val_Acc: 95.812

Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.96      0.97    109228
           1       0.96      0.97      0.96     88100

    accuracy                           0.97    197328
   macro avg       0.97      0.97      0.97    197328
weighted avg       0.97      0.97      0.97    197328

Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.95      0.96     13654
           1       0.94      0.96      0.95     11012

    accuracy                           0.96     24666
   macro avg       0.96      0.96      0.96     24666
weighted avg       0.96      0.96      0.96     24666

Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.96      0.96     13654
           1       0.95      0.96      0.95     11012

    accuracy                           0.96     24666
   macro avg       0.96      0.96      0.96     24666
weighted avg       0.96      0.96      0.96     24666

              precision    recall  f1-score   support

           0       0.97      0.96      0.96     13654
           1       0.95      0.96      0.95     11012

    accuracy                           0.96     24666
   macro avg       0.96      0.96      0.96     24666
weighted avg       0.96      0.96      0.96     24666

Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.95      0.96     37725
           1       0.95      0.97      0.96     38332

    accuracy                           0.96     76057
   macro avg       0.96      0.96      0.96     76057
weighted avg       0.96      0.96      0.96     76057

              precision    recall  f1-score   support

           0       0.97      0.95      0.96     37725
           1       0.95      0.97      0.96     38332

    accuracy                           0.96     76057
   macro avg       0.96      0.96      0.96     76057
weighted avg       0.96      0.96      0.96     76057

completed
