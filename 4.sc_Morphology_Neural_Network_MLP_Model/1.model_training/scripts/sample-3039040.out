[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '122dbe4e'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'ad566cfc'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd7c83fb8'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'a07b329f'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: DMSO_0.100_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: DMSO_0.100_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'LPS_0.100_DMSO_0.025']
The dimensions of the data are: (53153, 1276)
Number of total missing values across all columns: 106306
Data Subset Is Off
Wells held out for testing: ['C20' 'I14']
Wells to use for training, validation, and testing ['B14' 'C14' 'B15' 'C15' 'C16' 'C17' 'C21' 'J14' 'I15' 'J15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.601879).  Saving model ...
	 Train_Loss: 0.6450 Train_Acc: 64.506 Val_Loss: 0.6019  BEST VAL Loss: 0.6019  Val_Acc: 70.214

Epoch 1: Validation loss decreased (0.601879 --> 0.598028).  Saving model ...
	 Train_Loss: 0.6291 Train_Acc: 69.957 Val_Loss: 0.5980  BEST VAL Loss: 0.5980  Val_Acc: 70.214

Epoch 2: Validation loss decreased (0.598028 --> 0.592481).  Saving model ...
	 Train_Loss: 0.6192 Train_Acc: 70.367 Val_Loss: 0.5925  BEST VAL Loss: 0.5925  Val_Acc: 70.351

Epoch 3: Validation loss decreased (0.592481 --> 0.588658).  Saving model ...
	 Train_Loss: 0.6120 Train_Acc: 70.672 Val_Loss: 0.5887  BEST VAL Loss: 0.5887  Val_Acc: 70.830

Epoch 4: Validation loss decreased (0.588658 --> 0.585569).  Saving model ...
	 Train_Loss: 0.6068 Train_Acc: 70.997 Val_Loss: 0.5856  BEST VAL Loss: 0.5856  Val_Acc: 71.171

Epoch 5: Validation loss decreased (0.585569 --> 0.582796).  Saving model ...
	 Train_Loss: 0.6016 Train_Acc: 71.435 Val_Loss: 0.5828  BEST VAL Loss: 0.5828  Val_Acc: 71.399

Epoch 6: Validation loss decreased (0.582796 --> 0.580517).  Saving model ...
	 Train_Loss: 0.5974 Train_Acc: 71.723 Val_Loss: 0.5805  BEST VAL Loss: 0.5805  Val_Acc: 71.764

Epoch 7: Validation loss decreased (0.580517 --> 0.578368).  Saving model ...
	 Train_Loss: 0.5938 Train_Acc: 72.074 Val_Loss: 0.5784  BEST VAL Loss: 0.5784  Val_Acc: 71.901

Epoch 8: Validation loss decreased (0.578368 --> 0.576755).  Saving model ...
	 Train_Loss: 0.5906 Train_Acc: 71.963 Val_Loss: 0.5768  BEST VAL Loss: 0.5768  Val_Acc: 71.741

Epoch 9: Validation loss decreased (0.576755 --> 0.575257).  Saving model ...
	 Train_Loss: 0.5875 Train_Acc: 72.279 Val_Loss: 0.5753  BEST VAL Loss: 0.5753  Val_Acc: 71.604

Epoch 10: Validation loss decreased (0.575257 --> 0.573962).  Saving model ...
	 Train_Loss: 0.5845 Train_Acc: 72.735 Val_Loss: 0.5740  BEST VAL Loss: 0.5740  Val_Acc: 71.764

Epoch 11: Validation loss decreased (0.573962 --> 0.572942).  Saving model ...
	 Train_Loss: 0.5821 Train_Acc: 72.595 Val_Loss: 0.5729  BEST VAL Loss: 0.5729  Val_Acc: 71.513

Epoch 12: Validation loss decreased (0.572942 --> 0.571866).  Saving model ...
	 Train_Loss: 0.5797 Train_Acc: 72.738 Val_Loss: 0.5719  BEST VAL Loss: 0.5719  Val_Acc: 71.696

Epoch 13: Validation loss decreased (0.571866 --> 0.570752).  Saving model ...
	 Train_Loss: 0.5775 Train_Acc: 72.701 Val_Loss: 0.5708  BEST VAL Loss: 0.5708  Val_Acc: 71.741

Epoch 14: Validation loss decreased (0.570752 --> 0.569919).  Saving model ...
	 Train_Loss: 0.5754 Train_Acc: 73.139 Val_Loss: 0.5699  BEST VAL Loss: 0.5699  Val_Acc: 71.832

Epoch 15: Validation loss decreased (0.569919 --> 0.569187).  Saving model ...
	 Train_Loss: 0.5735 Train_Acc: 73.091 Val_Loss: 0.5692  BEST VAL Loss: 0.5692  Val_Acc: 71.946

Epoch 16: Validation loss decreased (0.569187 --> 0.568299).  Saving model ...
	 Train_Loss: 0.5716 Train_Acc: 73.285 Val_Loss: 0.5683  BEST VAL Loss: 0.5683  Val_Acc: 72.675

Epoch 17: Validation loss decreased (0.568299 --> 0.567656).  Saving model ...
	 Train_Loss: 0.5698 Train_Acc: 73.564 Val_Loss: 0.5677  BEST VAL Loss: 0.5677  Val_Acc: 72.242

Epoch 18: Validation loss decreased (0.567656 --> 0.566989).  Saving model ...
	 Train_Loss: 0.5682 Train_Acc: 73.627 Val_Loss: 0.5670  BEST VAL Loss: 0.5670  Val_Acc: 72.402

Epoch 19: Validation loss decreased (0.566989 --> 0.566288).  Saving model ...
	 Train_Loss: 0.5666 Train_Acc: 73.376 Val_Loss: 0.5663  BEST VAL Loss: 0.5663  Val_Acc: 72.379

Epoch 20: Validation loss decreased (0.566288 --> 0.565675).  Saving model ...
	 Train_Loss: 0.5651 Train_Acc: 73.701 Val_Loss: 0.5657  BEST VAL Loss: 0.5657  Val_Acc: 72.539

Epoch 21: Validation loss decreased (0.565675 --> 0.565238).  Saving model ...
	 Train_Loss: 0.5635 Train_Acc: 73.704 Val_Loss: 0.5652  BEST VAL Loss: 0.5652  Val_Acc: 72.334

Epoch 22: Validation loss decreased (0.565238 --> 0.564726).  Saving model ...
	 Train_Loss: 0.5621 Train_Acc: 73.686 Val_Loss: 0.5647  BEST VAL Loss: 0.5647  Val_Acc: 72.265

Epoch 23: Validation loss decreased (0.564726 --> 0.564522).  Saving model ...
	 Train_Loss: 0.5607 Train_Acc: 73.729 Val_Loss: 0.5645  BEST VAL Loss: 0.5645  Val_Acc: 72.015

Epoch 24: Validation loss decreased (0.564522 --> 0.563995).  Saving model ...
	 Train_Loss: 0.5595 Train_Acc: 73.498 Val_Loss: 0.5640  BEST VAL Loss: 0.5640  Val_Acc: 72.425

Epoch 25: Validation loss decreased (0.563995 --> 0.563614).  Saving model ...
	 Train_Loss: 0.5581 Train_Acc: 74.194 Val_Loss: 0.5636  BEST VAL Loss: 0.5636  Val_Acc: 72.288

Epoch 26: Validation loss decreased (0.563614 --> 0.563338).  Saving model ...
	 Train_Loss: 0.5568 Train_Acc: 74.111 Val_Loss: 0.5633  BEST VAL Loss: 0.5633  Val_Acc: 72.129

Epoch 27: Validation loss decreased (0.563338 --> 0.563072).  Saving model ...
	 Train_Loss: 0.5556 Train_Acc: 74.063 Val_Loss: 0.5631  BEST VAL Loss: 0.5631  Val_Acc: 72.356

Epoch 28: Validation loss decreased (0.563072 --> 0.562733).  Saving model ...
	 Train_Loss: 0.5543 Train_Acc: 74.185 Val_Loss: 0.5627  BEST VAL Loss: 0.5627  Val_Acc: 72.858

Epoch 29: Validation loss decreased (0.562733 --> 0.562372).  Saving model ...
	 Train_Loss: 0.5532 Train_Acc: 74.376 Val_Loss: 0.5624  BEST VAL Loss: 0.5624  Val_Acc: 72.698

Epoch 30: Validation loss decreased (0.562372 --> 0.562113).  Saving model ...
	 Train_Loss: 0.5520 Train_Acc: 74.182 Val_Loss: 0.5621  BEST VAL Loss: 0.5621  Val_Acc: 72.448

Epoch 31: Validation loss decreased (0.562113 --> 0.561798).  Saving model ...
	 Train_Loss: 0.5509 Train_Acc: 74.191 Val_Loss: 0.5618  BEST VAL Loss: 0.5618  Val_Acc: 72.835

Epoch 32: Validation loss decreased (0.561798 --> 0.561615).  Saving model ...
	 Train_Loss: 0.5498 Train_Acc: 74.669 Val_Loss: 0.5616  BEST VAL Loss: 0.5616  Val_Acc: 72.425

Epoch 33: Validation loss decreased (0.561615 --> 0.561453).  Saving model ...
	 Train_Loss: 0.5488 Train_Acc: 74.595 Val_Loss: 0.5615  BEST VAL Loss: 0.5615  Val_Acc: 72.448

Epoch 34: Validation loss did not decrease
	 Train_Loss: 0.5478 Train_Acc: 74.709 Val_Loss: 0.5616  BEST VAL Loss: 0.5615  Val_Acc: 72.037

Epoch 35: Validation loss decreased (0.561453 --> 0.561380).  Saving model ...
	 Train_Loss: 0.5469 Train_Acc: 74.447 Val_Loss: 0.5614  BEST VAL Loss: 0.5614  Val_Acc: 72.584

Epoch 36: Validation loss decreased (0.561380 --> 0.561236).  Saving model ...
	 Train_Loss: 0.5459 Train_Acc: 74.801 Val_Loss: 0.5612  BEST VAL Loss: 0.5612  Val_Acc: 72.425

Epoch 37: Validation loss decreased (0.561236 --> 0.561074).  Saving model ...
	 Train_Loss: 0.5449 Train_Acc: 75.014 Val_Loss: 0.5611  BEST VAL Loss: 0.5611  Val_Acc: 72.379

Epoch 38: Validation loss decreased (0.561074 --> 0.561043).  Saving model ...
	 Train_Loss: 0.5440 Train_Acc: 74.940 Val_Loss: 0.5610  BEST VAL Loss: 0.5610  Val_Acc: 72.060

Epoch 39: Validation loss decreased (0.561043 --> 0.561037).  Saving model ...
	 Train_Loss: 0.5430 Train_Acc: 74.997 Val_Loss: 0.5610  BEST VAL Loss: 0.5610  Val_Acc: 72.425

Epoch 40: Validation loss decreased (0.561037 --> 0.561014).  Saving model ...
	 Train_Loss: 0.5421 Train_Acc: 75.382 Val_Loss: 0.5610  BEST VAL Loss: 0.5610  Val_Acc: 72.242

Epoch 41: Validation loss decreased (0.561014 --> 0.560915).  Saving model ...
	 Train_Loss: 0.5412 Train_Acc: 75.103 Val_Loss: 0.5609  BEST VAL Loss: 0.5609  Val_Acc: 72.356

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.5404 Train_Acc: 75.268 Val_Loss: 0.5610  BEST VAL Loss: 0.5609  Val_Acc: 71.878

Epoch 43: Validation loss decreased (0.560915 --> 0.560889).  Saving model ...
	 Train_Loss: 0.5395 Train_Acc: 75.328 Val_Loss: 0.5609  BEST VAL Loss: 0.5609  Val_Acc: 72.493

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.5387 Train_Acc: 75.151 Val_Loss: 0.5610  BEST VAL Loss: 0.5609  Val_Acc: 72.425

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.5379 Train_Acc: 75.254 Val_Loss: 0.5609  BEST VAL Loss: 0.5609  Val_Acc: 72.493

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.5372 Train_Acc: 75.373 Val_Loss: 0.5610  BEST VAL Loss: 0.5609  Val_Acc: 71.901

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.5364 Train_Acc: 75.558 Val_Loss: 0.5611  BEST VAL Loss: 0.5609  Val_Acc: 72.493

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.5356 Train_Acc: 75.459 Val_Loss: 0.5611  BEST VAL Loss: 0.5609  Val_Acc: 72.356

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.5349 Train_Acc: 75.533 Val_Loss: 0.5610  BEST VAL Loss: 0.5609  Val_Acc: 72.562

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.5341 Train_Acc: 75.786 Val_Loss: 0.5610  BEST VAL Loss: 0.5609  Val_Acc: 72.083

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.5334 Train_Acc: 75.709 Val_Loss: 0.5610  BEST VAL Loss: 0.5609  Val_Acc: 72.129

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.5327 Train_Acc: 75.547 Val_Loss: 0.5611  BEST VAL Loss: 0.5609  Val_Acc: 72.288

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.5320 Train_Acc: 75.781 Val_Loss: 0.5612  BEST VAL Loss: 0.5609  Val_Acc: 72.129

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.5314 Train_Acc: 75.940 Val_Loss: 0.5611  BEST VAL Loss: 0.5609  Val_Acc: 72.379

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.5308 Train_Acc: 75.647 Val_Loss: 0.5612  BEST VAL Loss: 0.5609  Val_Acc: 72.493

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.5301 Train_Acc: 75.997 Val_Loss: 0.5613  BEST VAL Loss: 0.5609  Val_Acc: 72.356

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.5295 Train_Acc: 75.641 Val_Loss: 0.5613  BEST VAL Loss: 0.5609  Val_Acc: 72.311

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.5290 Train_Acc: 75.453 Val_Loss: 0.5613  BEST VAL Loss: 0.5609  Val_Acc: 72.174

Epoch 59: Validation loss did not decrease
Early stopped at epoch : 59
DMSO_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.79      0.96      0.87     24644
           1       0.80      0.41      0.54     10452

    accuracy                           0.79     35096
   macro avg       0.80      0.68      0.70     35096
weighted avg       0.80      0.79      0.77     35096

DMSO_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.75      0.91      0.82      3081
           1       0.58      0.28      0.38      1307

    accuracy                           0.72      4388
   macro avg       0.66      0.60      0.60      4388
weighted avg       0.70      0.72      0.69      4388

DMSO_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.75      0.92      0.82      3081
           1       0.58      0.26      0.36      1306

    accuracy                           0.72      4387
   macro avg       0.66      0.59      0.59      4387
weighted avg       0.70      0.72      0.69      4387

              precision    recall  f1-score   support

           0       0.75      0.92      0.82      3081
           1       0.58      0.26      0.36      1306

    accuracy                           0.72      4387
   macro avg       0.66      0.59      0.59      4387
weighted avg       0.70      0.72      0.69      4387

DMSO_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.54      0.89      0.67      4837
           1       0.61      0.19      0.29      4445

    accuracy                           0.55      9282
   macro avg       0.58      0.54      0.48      9282
weighted avg       0.58      0.55      0.49      9282

              precision    recall  f1-score   support

           0       0.54      0.89      0.67      4837
           1       0.61      0.19      0.29      4445

    accuracy                           0.55      9282
   macro avg       0.58      0.54      0.48      9282
weighted avg       0.58      0.55      0.49      9282

completed
