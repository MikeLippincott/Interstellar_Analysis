[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd684fcee'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '9d864869'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '3e373e07'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '1c20ee4a'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: H2O2_100.000_DMSO_0.025 treatment_name: LPS_10.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: LPS_10.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (43710, 1276)
Number of total missing values across all columns: 87420
Data Subset Is Off
Wells held out for testing: ['E21' 'H22']
Wells to use for training, validation, and testing ['E16' 'E17' 'H18' 'H19' 'E20' 'H23' 'I18' 'I19' 'I22' 'I23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.604769).  Saving model ...
	 Train_Loss: 0.6331 Train_Acc: 63.223 Val_Loss: 0.6048  BEST VAL Loss: 0.6048  Val_Acc: 67.506

Epoch 1: Validation loss decreased (0.604769 --> 0.586372).  Saving model ...
	 Train_Loss: 0.6120 Train_Acc: 69.000 Val_Loss: 0.5864  BEST VAL Loss: 0.5864  Val_Acc: 70.305

Epoch 2: Validation loss decreased (0.586372 --> 0.570889).  Saving model ...
	 Train_Loss: 0.5934 Train_Acc: 71.467 Val_Loss: 0.5709  BEST VAL Loss: 0.5709  Val_Acc: 72.426

Epoch 3: Validation loss decreased (0.570889 --> 0.558511).  Saving model ...
	 Train_Loss: 0.5782 Train_Acc: 72.768 Val_Loss: 0.5585  BEST VAL Loss: 0.5585  Val_Acc: 73.812

Epoch 4: Validation loss decreased (0.558511 --> 0.548234).  Saving model ...
	 Train_Loss: 0.5653 Train_Acc: 73.854 Val_Loss: 0.5482  BEST VAL Loss: 0.5482  Val_Acc: 74.745

Epoch 5: Validation loss decreased (0.548234 --> 0.539432).  Saving model ...
	 Train_Loss: 0.5541 Train_Acc: 74.635 Val_Loss: 0.5394  BEST VAL Loss: 0.5394  Val_Acc: 75.141

Epoch 6: Validation loss decreased (0.539432 --> 0.531789).  Saving model ...
	 Train_Loss: 0.5443 Train_Acc: 75.360 Val_Loss: 0.5318  BEST VAL Loss: 0.5318  Val_Acc: 75.368

Epoch 7: Validation loss decreased (0.531789 --> 0.524999).  Saving model ...
	 Train_Loss: 0.5358 Train_Acc: 76.120 Val_Loss: 0.5250  BEST VAL Loss: 0.5250  Val_Acc: 76.131

Epoch 8: Validation loss decreased (0.524999 --> 0.518900).  Saving model ...
	 Train_Loss: 0.5279 Train_Acc: 76.997 Val_Loss: 0.5189  BEST VAL Loss: 0.5189  Val_Acc: 76.782

Epoch 9: Validation loss decreased (0.518900 --> 0.513512).  Saving model ...
	 Train_Loss: 0.5208 Train_Acc: 77.332 Val_Loss: 0.5135  BEST VAL Loss: 0.5135  Val_Acc: 77.064

Epoch 10: Validation loss decreased (0.513512 --> 0.508629).  Saving model ...
	 Train_Loss: 0.5144 Train_Acc: 77.880 Val_Loss: 0.5086  BEST VAL Loss: 0.5086  Val_Acc: 77.885

Epoch 11: Validation loss decreased (0.508629 --> 0.504142).  Saving model ...
	 Train_Loss: 0.5085 Train_Acc: 77.923 Val_Loss: 0.5041  BEST VAL Loss: 0.5041  Val_Acc: 77.998

Epoch 12: Validation loss decreased (0.504142 --> 0.500058).  Saving model ...
	 Train_Loss: 0.5030 Train_Acc: 78.305 Val_Loss: 0.5001  BEST VAL Loss: 0.5001  Val_Acc: 78.224

Epoch 13: Validation loss decreased (0.500058 --> 0.496320).  Saving model ...
	 Train_Loss: 0.4979 Train_Acc: 78.739 Val_Loss: 0.4963  BEST VAL Loss: 0.4963  Val_Acc: 78.422

Epoch 14: Validation loss decreased (0.496320 --> 0.492795).  Saving model ...
	 Train_Loss: 0.4932 Train_Acc: 79.043 Val_Loss: 0.4928  BEST VAL Loss: 0.4928  Val_Acc: 78.394

Epoch 15: Validation loss decreased (0.492795 --> 0.489526).  Saving model ...
	 Train_Loss: 0.4888 Train_Acc: 79.086 Val_Loss: 0.4895  BEST VAL Loss: 0.4895  Val_Acc: 78.479

Epoch 16: Validation loss decreased (0.489526 --> 0.486443).  Saving model ...
	 Train_Loss: 0.4847 Train_Acc: 79.245 Val_Loss: 0.4864  BEST VAL Loss: 0.4864  Val_Acc: 78.620

Epoch 17: Validation loss decreased (0.486443 --> 0.483601).  Saving model ...
	 Train_Loss: 0.4807 Train_Acc: 79.842 Val_Loss: 0.4836  BEST VAL Loss: 0.4836  Val_Acc: 78.648

Epoch 18: Validation loss decreased (0.483601 --> 0.480885).  Saving model ...
	 Train_Loss: 0.4770 Train_Acc: 79.917 Val_Loss: 0.4809  BEST VAL Loss: 0.4809  Val_Acc: 78.846

Epoch 19: Validation loss decreased (0.480885 --> 0.478366).  Saving model ...
	 Train_Loss: 0.4734 Train_Acc: 80.468 Val_Loss: 0.4784  BEST VAL Loss: 0.4784  Val_Acc: 79.129

Epoch 20: Validation loss decreased (0.478366 --> 0.476022).  Saving model ...
	 Train_Loss: 0.4701 Train_Acc: 80.518 Val_Loss: 0.4760  BEST VAL Loss: 0.4760  Val_Acc: 79.101

Epoch 21: Validation loss decreased (0.476022 --> 0.473825).  Saving model ...
	 Train_Loss: 0.4669 Train_Acc: 80.595 Val_Loss: 0.4738  BEST VAL Loss: 0.4738  Val_Acc: 79.440

Epoch 22: Validation loss decreased (0.473825 --> 0.471756).  Saving model ...
	 Train_Loss: 0.4640 Train_Acc: 80.673 Val_Loss: 0.4718  BEST VAL Loss: 0.4718  Val_Acc: 79.497

Epoch 23: Validation loss decreased (0.471756 --> 0.469818).  Saving model ...
	 Train_Loss: 0.4611 Train_Acc: 80.815 Val_Loss: 0.4698  BEST VAL Loss: 0.4698  Val_Acc: 79.157

Epoch 24: Validation loss decreased (0.469818 --> 0.467985).  Saving model ...
	 Train_Loss: 0.4583 Train_Acc: 81.150 Val_Loss: 0.4680  BEST VAL Loss: 0.4680  Val_Acc: 79.327

Epoch 25: Validation loss decreased (0.467985 --> 0.466215).  Saving model ...
	 Train_Loss: 0.4557 Train_Acc: 81.161 Val_Loss: 0.4662  BEST VAL Loss: 0.4662  Val_Acc: 79.779

Epoch 26: Validation loss decreased (0.466215 --> 0.464554).  Saving model ...
	 Train_Loss: 0.4532 Train_Acc: 81.362 Val_Loss: 0.4646  BEST VAL Loss: 0.4646  Val_Acc: 79.440

Epoch 27: Validation loss decreased (0.464554 --> 0.462983).  Saving model ...
	 Train_Loss: 0.4508 Train_Acc: 81.394 Val_Loss: 0.4630  BEST VAL Loss: 0.4630  Val_Acc: 80.006

Epoch 28: Validation loss decreased (0.462983 --> 0.461481).  Saving model ...
	 Train_Loss: 0.4484 Train_Acc: 81.613 Val_Loss: 0.4615  BEST VAL Loss: 0.4615  Val_Acc: 79.893

Epoch 29: Validation loss decreased (0.461481 --> 0.460070).  Saving model ...
	 Train_Loss: 0.4460 Train_Acc: 81.896 Val_Loss: 0.4601  BEST VAL Loss: 0.4601  Val_Acc: 80.147

Epoch 30: Validation loss decreased (0.460070 --> 0.458766).  Saving model ...
	 Train_Loss: 0.4438 Train_Acc: 81.893 Val_Loss: 0.4588  BEST VAL Loss: 0.4588  Val_Acc: 79.949

Epoch 31: Validation loss decreased (0.458766 --> 0.457450).  Saving model ...
	 Train_Loss: 0.4417 Train_Acc: 82.009 Val_Loss: 0.4574  BEST VAL Loss: 0.4574  Val_Acc: 80.260

Epoch 32: Validation loss decreased (0.457450 --> 0.456165).  Saving model ...
	 Train_Loss: 0.4396 Train_Acc: 82.211 Val_Loss: 0.4562  BEST VAL Loss: 0.4562  Val_Acc: 80.571

Epoch 33: Validation loss decreased (0.456165 --> 0.454969).  Saving model ...
	 Train_Loss: 0.4375 Train_Acc: 82.328 Val_Loss: 0.4550  BEST VAL Loss: 0.4550  Val_Acc: 80.656

Epoch 34: Validation loss decreased (0.454969 --> 0.453816).  Saving model ...
	 Train_Loss: 0.4356 Train_Acc: 82.214 Val_Loss: 0.4538  BEST VAL Loss: 0.4538  Val_Acc: 80.600

Epoch 35: Validation loss decreased (0.453816 --> 0.452691).  Saving model ...
	 Train_Loss: 0.4336 Train_Acc: 82.543 Val_Loss: 0.4527  BEST VAL Loss: 0.4527  Val_Acc: 80.741

Epoch 36: Validation loss decreased (0.452691 --> 0.451621).  Saving model ...
	 Train_Loss: 0.4318 Train_Acc: 82.741 Val_Loss: 0.4516  BEST VAL Loss: 0.4516  Val_Acc: 80.684

Epoch 37: Validation loss decreased (0.451621 --> 0.450620).  Saving model ...
	 Train_Loss: 0.4299 Train_Acc: 83.052 Val_Loss: 0.4506  BEST VAL Loss: 0.4506  Val_Acc: 80.656

Epoch 38: Validation loss decreased (0.450620 --> 0.449691).  Saving model ...
	 Train_Loss: 0.4282 Train_Acc: 82.830 Val_Loss: 0.4497  BEST VAL Loss: 0.4497  Val_Acc: 80.741

Epoch 39: Validation loss decreased (0.449691 --> 0.448738).  Saving model ...
	 Train_Loss: 0.4265 Train_Acc: 82.996 Val_Loss: 0.4487  BEST VAL Loss: 0.4487  Val_Acc: 80.798

Epoch 40: Validation loss decreased (0.448738 --> 0.447820).  Saving model ...
	 Train_Loss: 0.4248 Train_Acc: 82.907 Val_Loss: 0.4478  BEST VAL Loss: 0.4478  Val_Acc: 80.713

Epoch 41: Validation loss decreased (0.447820 --> 0.446944).  Saving model ...
	 Train_Loss: 0.4231 Train_Acc: 83.279 Val_Loss: 0.4469  BEST VAL Loss: 0.4469  Val_Acc: 80.684

Epoch 42: Validation loss decreased (0.446944 --> 0.446079).  Saving model ...
	 Train_Loss: 0.4215 Train_Acc: 83.339 Val_Loss: 0.4461  BEST VAL Loss: 0.4461  Val_Acc: 80.600

Epoch 43: Validation loss decreased (0.446079 --> 0.445254).  Saving model ...
	 Train_Loss: 0.4199 Train_Acc: 83.646 Val_Loss: 0.4453  BEST VAL Loss: 0.4453  Val_Acc: 80.543

Epoch 44: Validation loss decreased (0.445254 --> 0.444464).  Saving model ...
	 Train_Loss: 0.4184 Train_Acc: 83.607 Val_Loss: 0.4445  BEST VAL Loss: 0.4445  Val_Acc: 80.486

Epoch 45: Validation loss decreased (0.444464 --> 0.443712).  Saving model ...
	 Train_Loss: 0.4169 Train_Acc: 83.650 Val_Loss: 0.4437  BEST VAL Loss: 0.4437  Val_Acc: 80.741

Epoch 46: Validation loss decreased (0.443712 --> 0.442955).  Saving model ...
	 Train_Loss: 0.4154 Train_Acc: 83.685 Val_Loss: 0.4430  BEST VAL Loss: 0.4430  Val_Acc: 80.769

Epoch 47: Validation loss decreased (0.442955 --> 0.442262).  Saving model ...
	 Train_Loss: 0.4140 Train_Acc: 83.692 Val_Loss: 0.4423  BEST VAL Loss: 0.4423  Val_Acc: 80.402

Epoch 48: Validation loss decreased (0.442262 --> 0.441568).  Saving model ...
	 Train_Loss: 0.4125 Train_Acc: 83.979 Val_Loss: 0.4416  BEST VAL Loss: 0.4416  Val_Acc: 80.826

Epoch 49: Validation loss decreased (0.441568 --> 0.440897).  Saving model ...
	 Train_Loss: 0.4111 Train_Acc: 83.929 Val_Loss: 0.4409  BEST VAL Loss: 0.4409  Val_Acc: 80.600

Epoch 50: Validation loss decreased (0.440897 --> 0.440245).  Saving model ...
	 Train_Loss: 0.4097 Train_Acc: 84.113 Val_Loss: 0.4402  BEST VAL Loss: 0.4402  Val_Acc: 80.656

Epoch 51: Validation loss decreased (0.440245 --> 0.439601).  Saving model ...
	 Train_Loss: 0.4084 Train_Acc: 84.049 Val_Loss: 0.4396  BEST VAL Loss: 0.4396  Val_Acc: 80.854

Epoch 52: Validation loss decreased (0.439601 --> 0.438983).  Saving model ...
	 Train_Loss: 0.4070 Train_Acc: 84.166 Val_Loss: 0.4390  BEST VAL Loss: 0.4390  Val_Acc: 81.193

Epoch 53: Validation loss decreased (0.438983 --> 0.438387).  Saving model ...
	 Train_Loss: 0.4057 Train_Acc: 84.463 Val_Loss: 0.4384  BEST VAL Loss: 0.4384  Val_Acc: 80.769

Epoch 54: Validation loss decreased (0.438387 --> 0.437812).  Saving model ...
	 Train_Loss: 0.4045 Train_Acc: 84.445 Val_Loss: 0.4378  BEST VAL Loss: 0.4378  Val_Acc: 80.741

Epoch 55: Validation loss decreased (0.437812 --> 0.437282).  Saving model ...
	 Train_Loss: 0.4032 Train_Acc: 84.343 Val_Loss: 0.4373  BEST VAL Loss: 0.4373  Val_Acc: 80.684

Epoch 56: Validation loss decreased (0.437282 --> 0.436757).  Saving model ...
	 Train_Loss: 0.4020 Train_Acc: 84.601 Val_Loss: 0.4368  BEST VAL Loss: 0.4368  Val_Acc: 80.684

Epoch 57: Validation loss decreased (0.436757 --> 0.436252).  Saving model ...
	 Train_Loss: 0.4007 Train_Acc: 84.898 Val_Loss: 0.4363  BEST VAL Loss: 0.4363  Val_Acc: 80.798

Epoch 58: Validation loss decreased (0.436252 --> 0.435736).  Saving model ...
	 Train_Loss: 0.3995 Train_Acc: 84.675 Val_Loss: 0.4357  BEST VAL Loss: 0.4357  Val_Acc: 80.882

Epoch 59: Validation loss decreased (0.435736 --> 0.435233).  Saving model ...
	 Train_Loss: 0.3983 Train_Acc: 84.710 Val_Loss: 0.4352  BEST VAL Loss: 0.4352  Val_Acc: 80.826

Epoch 60: Validation loss decreased (0.435233 --> 0.434762).  Saving model ...
	 Train_Loss: 0.3972 Train_Acc: 85.021 Val_Loss: 0.4348  BEST VAL Loss: 0.4348  Val_Acc: 81.080

Epoch 61: Validation loss decreased (0.434762 --> 0.434293).  Saving model ...
	 Train_Loss: 0.3960 Train_Acc: 84.884 Val_Loss: 0.4343  BEST VAL Loss: 0.4343  Val_Acc: 80.967

Epoch 62: Validation loss decreased (0.434293 --> 0.433861).  Saving model ...
	 Train_Loss: 0.3949 Train_Acc: 84.940 Val_Loss: 0.4339  BEST VAL Loss: 0.4339  Val_Acc: 81.109

Epoch 63: Validation loss decreased (0.433861 --> 0.433401).  Saving model ...
	 Train_Loss: 0.3938 Train_Acc: 85.276 Val_Loss: 0.4334  BEST VAL Loss: 0.4334  Val_Acc: 81.165

Epoch 64: Validation loss decreased (0.433401 --> 0.432973).  Saving model ...
	 Train_Loss: 0.3926 Train_Acc: 85.230 Val_Loss: 0.4330  BEST VAL Loss: 0.4330  Val_Acc: 81.052

Epoch 65: Validation loss decreased (0.432973 --> 0.432566).  Saving model ...
	 Train_Loss: 0.3916 Train_Acc: 85.131 Val_Loss: 0.4326  BEST VAL Loss: 0.4326  Val_Acc: 80.713

Epoch 66: Validation loss decreased (0.432566 --> 0.432152).  Saving model ...
	 Train_Loss: 0.3905 Train_Acc: 85.439 Val_Loss: 0.4322  BEST VAL Loss: 0.4322  Val_Acc: 80.798

Epoch 67: Validation loss decreased (0.432152 --> 0.431762).  Saving model ...
	 Train_Loss: 0.3895 Train_Acc: 85.375 Val_Loss: 0.4318  BEST VAL Loss: 0.4318  Val_Acc: 80.939

Epoch 68: Validation loss decreased (0.431762 --> 0.431420).  Saving model ...
	 Train_Loss: 0.3884 Train_Acc: 85.279 Val_Loss: 0.4314  BEST VAL Loss: 0.4314  Val_Acc: 80.713

Epoch 69: Validation loss decreased (0.431420 --> 0.431049).  Saving model ...
	 Train_Loss: 0.3874 Train_Acc: 85.255 Val_Loss: 0.4310  BEST VAL Loss: 0.4310  Val_Acc: 81.505

Epoch 70: Validation loss decreased (0.431049 --> 0.430695).  Saving model ...
	 Train_Loss: 0.3864 Train_Acc: 85.605 Val_Loss: 0.4307  BEST VAL Loss: 0.4307  Val_Acc: 80.826

Epoch 71: Validation loss decreased (0.430695 --> 0.430337).  Saving model ...
	 Train_Loss: 0.3854 Train_Acc: 85.545 Val_Loss: 0.4303  BEST VAL Loss: 0.4303  Val_Acc: 81.222

Epoch 72: Validation loss decreased (0.430337 --> 0.430003).  Saving model ...
	 Train_Loss: 0.3844 Train_Acc: 85.435 Val_Loss: 0.4300  BEST VAL Loss: 0.4300  Val_Acc: 81.222

Epoch 73: Validation loss decreased (0.430003 --> 0.429683).  Saving model ...
	 Train_Loss: 0.3835 Train_Acc: 85.587 Val_Loss: 0.4297  BEST VAL Loss: 0.4297  Val_Acc: 81.052

Epoch 74: Validation loss decreased (0.429683 --> 0.429364).  Saving model ...
	 Train_Loss: 0.3825 Train_Acc: 86.029 Val_Loss: 0.4294  BEST VAL Loss: 0.4294  Val_Acc: 80.826

Epoch 75: Validation loss decreased (0.429364 --> 0.429032).  Saving model ...
	 Train_Loss: 0.3815 Train_Acc: 85.824 Val_Loss: 0.4290  BEST VAL Loss: 0.4290  Val_Acc: 81.307

Epoch 76: Validation loss decreased (0.429032 --> 0.428744).  Saving model ...
	 Train_Loss: 0.3806 Train_Acc: 85.916 Val_Loss: 0.4287  BEST VAL Loss: 0.4287  Val_Acc: 80.995

Epoch 77: Validation loss decreased (0.428744 --> 0.428475).  Saving model ...
	 Train_Loss: 0.3797 Train_Acc: 86.160 Val_Loss: 0.4285  BEST VAL Loss: 0.4285  Val_Acc: 81.080

Epoch 78: Validation loss decreased (0.428475 --> 0.428191).  Saving model ...
	 Train_Loss: 0.3787 Train_Acc: 86.015 Val_Loss: 0.4282  BEST VAL Loss: 0.4282  Val_Acc: 81.222

Epoch 79: Validation loss decreased (0.428191 --> 0.427920).  Saving model ...
	 Train_Loss: 0.3778 Train_Acc: 86.160 Val_Loss: 0.4279  BEST VAL Loss: 0.4279  Val_Acc: 81.222

Epoch 80: Validation loss decreased (0.427920 --> 0.427670).  Saving model ...
	 Train_Loss: 0.3769 Train_Acc: 86.054 Val_Loss: 0.4277  BEST VAL Loss: 0.4277  Val_Acc: 80.798

Epoch 81: Validation loss decreased (0.427670 --> 0.427419).  Saving model ...
	 Train_Loss: 0.3760 Train_Acc: 86.291 Val_Loss: 0.4274  BEST VAL Loss: 0.4274  Val_Acc: 81.193

Epoch 82: Validation loss decreased (0.427419 --> 0.427178).  Saving model ...
	 Train_Loss: 0.3751 Train_Acc: 86.407 Val_Loss: 0.4272  BEST VAL Loss: 0.4272  Val_Acc: 81.165

Epoch 83: Validation loss decreased (0.427178 --> 0.426957).  Saving model ...
	 Train_Loss: 0.3743 Train_Acc: 86.488 Val_Loss: 0.4270  BEST VAL Loss: 0.4270  Val_Acc: 81.307

Epoch 84: Validation loss decreased (0.426957 --> 0.426737).  Saving model ...
	 Train_Loss: 0.3734 Train_Acc: 86.305 Val_Loss: 0.4267  BEST VAL Loss: 0.4267  Val_Acc: 81.052

Epoch 85: Validation loss decreased (0.426737 --> 0.426504).  Saving model ...
	 Train_Loss: 0.3726 Train_Acc: 86.085 Val_Loss: 0.4265  BEST VAL Loss: 0.4265  Val_Acc: 81.307

Epoch 86: Validation loss decreased (0.426504 --> 0.426280).  Saving model ...
	 Train_Loss: 0.3717 Train_Acc: 86.474 Val_Loss: 0.4263  BEST VAL Loss: 0.4263  Val_Acc: 81.505

Epoch 87: Validation loss decreased (0.426280 --> 0.426072).  Saving model ...
	 Train_Loss: 0.3709 Train_Acc: 86.503 Val_Loss: 0.4261  BEST VAL Loss: 0.4261  Val_Acc: 81.307

Epoch 88: Validation loss decreased (0.426072 --> 0.425865).  Saving model ...
	 Train_Loss: 0.3701 Train_Acc: 86.347 Val_Loss: 0.4259  BEST VAL Loss: 0.4259  Val_Acc: 80.882

Epoch 89: Validation loss decreased (0.425865 --> 0.425681).  Saving model ...
	 Train_Loss: 0.3693 Train_Acc: 86.842 Val_Loss: 0.4257  BEST VAL Loss: 0.4257  Val_Acc: 81.052

Epoch 90: Validation loss decreased (0.425681 --> 0.425493).  Saving model ...
	 Train_Loss: 0.3684 Train_Acc: 86.542 Val_Loss: 0.4255  BEST VAL Loss: 0.4255  Val_Acc: 81.307

Epoch 91: Validation loss decreased (0.425493 --> 0.425289).  Saving model ...
	 Train_Loss: 0.3676 Train_Acc: 86.630 Val_Loss: 0.4253  BEST VAL Loss: 0.4253  Val_Acc: 81.052

Epoch 92: Validation loss decreased (0.425289 --> 0.425108).  Saving model ...
	 Train_Loss: 0.3668 Train_Acc: 86.892 Val_Loss: 0.4251  BEST VAL Loss: 0.4251  Val_Acc: 81.165

Epoch 93: Validation loss decreased (0.425108 --> 0.424927).  Saving model ...
	 Train_Loss: 0.3661 Train_Acc: 86.771 Val_Loss: 0.4249  BEST VAL Loss: 0.4249  Val_Acc: 81.363

Epoch 94: Validation loss decreased (0.424927 --> 0.424767).  Saving model ...
	 Train_Loss: 0.3653 Train_Acc: 87.001 Val_Loss: 0.4248  BEST VAL Loss: 0.4248  Val_Acc: 81.193

Epoch 95: Validation loss decreased (0.424767 --> 0.424608).  Saving model ...
	 Train_Loss: 0.3646 Train_Acc: 86.945 Val_Loss: 0.4246  BEST VAL Loss: 0.4246  Val_Acc: 81.024

Epoch 96: Validation loss decreased (0.424608 --> 0.424457).  Saving model ...
	 Train_Loss: 0.3638 Train_Acc: 87.022 Val_Loss: 0.4245  BEST VAL Loss: 0.4245  Val_Acc: 81.137

Epoch 97: Validation loss decreased (0.424457 --> 0.424283).  Saving model ...
	 Train_Loss: 0.3630 Train_Acc: 87.164 Val_Loss: 0.4243  BEST VAL Loss: 0.4243  Val_Acc: 81.335

Epoch 98: Validation loss decreased (0.424283 --> 0.424114).  Saving model ...
	 Train_Loss: 0.3623 Train_Acc: 87.252 Val_Loss: 0.4241  BEST VAL Loss: 0.4241  Val_Acc: 81.024

Epoch 99: Validation loss decreased (0.424114 --> 0.423966).  Saving model ...
	 Train_Loss: 0.3615 Train_Acc: 87.316 Val_Loss: 0.4240  BEST VAL Loss: 0.4240  Val_Acc: 81.278

H2O2_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.92      0.93      0.92     18174
           1       0.86      0.85      0.86     10113

    accuracy                           0.90     28287
   macro avg       0.89      0.89      0.89     28287
weighted avg       0.90      0.90      0.90     28287

H2O2_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.85      0.86      0.86      2272
           1       0.75      0.72      0.73      1264

    accuracy                           0.81      3536
   macro avg       0.80      0.79      0.79      3536
weighted avg       0.81      0.81      0.81      3536

H2O2_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.84      0.85      0.85      2272
           1       0.73      0.70      0.72      1265

    accuracy                           0.80      3537
   macro avg       0.78      0.78      0.78      3537
weighted avg       0.80      0.80      0.80      3537

              precision    recall  f1-score   support

           0       0.84      0.85      0.85      2272
           1       0.73      0.70      0.72      1265

    accuracy                           0.80      3537
   macro avg       0.78      0.78      0.78      3537
weighted avg       0.80      0.80      0.80      3537

H2O2_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.72      0.79      0.75      4182
           1       0.77      0.69      0.73      4168

    accuracy                           0.74      8350
   macro avg       0.74      0.74      0.74      8350
weighted avg       0.74      0.74      0.74      8350

              precision    recall  f1-score   support

           0       0.72      0.79      0.75      4182
           1       0.77      0.69      0.73      4168

    accuracy                           0.74      8350
   macro avg       0.74      0.74      0.74      8350
weighted avg       0.74      0.74      0.74      8350

completed
