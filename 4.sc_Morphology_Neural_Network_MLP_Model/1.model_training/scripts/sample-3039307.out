[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd8801353'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '8fd7a942'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '79256706'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'bbcb5ddb'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_100.000_DMSO_0.025 treatment_name: H2O2_100.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_100.000_DMSO_0.025
TREATMENT_NAME: H2O2_100.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['H2O2_100.000_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (399971, 1270)
Number of total missing values across all columns: 799942
Data Subset Is Off
Wells held out for testing: ['I10' 'J08']
Wells to use for training, validation, and testing ['H04' 'I04' 'H05' 'I05' 'H10' 'H11' 'I11' 'J02' 'J03' 'J09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.485800).  Saving model ...
	 Train_Loss: 0.5585 Train_Acc: 71.403 Val_Loss: 0.4858  BEST VAL Loss: 0.4858  Val_Acc: 76.466

Epoch 1: Validation loss decreased (0.485800 --> 0.457392).  Saving model ...
	 Train_Loss: 0.5171 Train_Acc: 77.019 Val_Loss: 0.4574  BEST VAL Loss: 0.4574  Val_Acc: 80.422

Epoch 2: Validation loss decreased (0.457392 --> 0.438151).  Saving model ...
	 Train_Loss: 0.4922 Train_Acc: 79.056 Val_Loss: 0.4382  BEST VAL Loss: 0.4382  Val_Acc: 81.867

Epoch 3: Validation loss decreased (0.438151 --> 0.424335).  Saving model ...
	 Train_Loss: 0.4746 Train_Acc: 80.201 Val_Loss: 0.4243  BEST VAL Loss: 0.4243  Val_Acc: 82.777

Epoch 4: Validation loss decreased (0.424335 --> 0.413152).  Saving model ...
	 Train_Loss: 0.4610 Train_Acc: 81.098 Val_Loss: 0.4132  BEST VAL Loss: 0.4132  Val_Acc: 83.549

Epoch 5: Validation loss decreased (0.413152 --> 0.404617).  Saving model ...
	 Train_Loss: 0.4502 Train_Acc: 81.569 Val_Loss: 0.4046  BEST VAL Loss: 0.4046  Val_Acc: 83.660

Epoch 6: Validation loss decreased (0.404617 --> 0.397309).  Saving model ...
	 Train_Loss: 0.4414 Train_Acc: 81.920 Val_Loss: 0.3973  BEST VAL Loss: 0.3973  Val_Acc: 84.211

Epoch 7: Validation loss decreased (0.397309 --> 0.390654).  Saving model ...
	 Train_Loss: 0.4337 Train_Acc: 82.390 Val_Loss: 0.3907  BEST VAL Loss: 0.3907  Val_Acc: 84.504

Epoch 8: Validation loss decreased (0.390654 --> 0.385781).  Saving model ...
	 Train_Loss: 0.4274 Train_Acc: 82.478 Val_Loss: 0.3858  BEST VAL Loss: 0.3858  Val_Acc: 84.663

Epoch 9: Validation loss decreased (0.385781 --> 0.382367).  Saving model ...
	 Train_Loss: 0.4217 Train_Acc: 82.843 Val_Loss: 0.3824  BEST VAL Loss: 0.3824  Val_Acc: 84.348

Epoch 10: Validation loss decreased (0.382367 --> 0.378283).  Saving model ...
	 Train_Loss: 0.4167 Train_Acc: 82.828 Val_Loss: 0.3783  BEST VAL Loss: 0.3783  Val_Acc: 84.872

Epoch 11: Validation loss decreased (0.378283 --> 0.375048).  Saving model ...
	 Train_Loss: 0.4122 Train_Acc: 83.147 Val_Loss: 0.3750  BEST VAL Loss: 0.3750  Val_Acc: 84.908

Epoch 12: Validation loss decreased (0.375048 --> 0.371550).  Saving model ...
	 Train_Loss: 0.4082 Train_Acc: 83.266 Val_Loss: 0.3715  BEST VAL Loss: 0.3715  Val_Acc: 85.309

Epoch 13: Validation loss decreased (0.371550 --> 0.368750).  Saving model ...
	 Train_Loss: 0.4046 Train_Acc: 83.286 Val_Loss: 0.3687  BEST VAL Loss: 0.3687  Val_Acc: 85.067

Epoch 14: Validation loss decreased (0.368750 --> 0.366459).  Saving model ...
	 Train_Loss: 0.4013 Train_Acc: 83.430 Val_Loss: 0.3665  BEST VAL Loss: 0.3665  Val_Acc: 85.231

Epoch 15: Validation loss decreased (0.366459 --> 0.363894).  Saving model ...
	 Train_Loss: 0.3983 Train_Acc: 83.578 Val_Loss: 0.3639  BEST VAL Loss: 0.3639  Val_Acc: 85.429

Epoch 16: Validation loss decreased (0.363894 --> 0.361651).  Saving model ...
	 Train_Loss: 0.3955 Train_Acc: 83.699 Val_Loss: 0.3617  BEST VAL Loss: 0.3617  Val_Acc: 85.498

Epoch 17: Validation loss decreased (0.361651 --> 0.359621).  Saving model ...
	 Train_Loss: 0.3930 Train_Acc: 83.678 Val_Loss: 0.3596  BEST VAL Loss: 0.3596  Val_Acc: 85.740

Epoch 18: Validation loss decreased (0.359621 --> 0.357712).  Saving model ...
	 Train_Loss: 0.3907 Train_Acc: 83.768 Val_Loss: 0.3577  BEST VAL Loss: 0.3577  Val_Acc: 85.617

Epoch 19: Validation loss decreased (0.357712 --> 0.355871).  Saving model ...
	 Train_Loss: 0.3885 Train_Acc: 83.877 Val_Loss: 0.3559  BEST VAL Loss: 0.3559  Val_Acc: 85.701

Epoch 20: Validation loss decreased (0.355871 --> 0.354779).  Saving model ...
	 Train_Loss: 0.3864 Train_Acc: 83.985 Val_Loss: 0.3548  BEST VAL Loss: 0.3548  Val_Acc: 85.396

Epoch 21: Validation loss decreased (0.354779 --> 0.353072).  Saving model ...
	 Train_Loss: 0.3844 Train_Acc: 84.075 Val_Loss: 0.3531  BEST VAL Loss: 0.3531  Val_Acc: 85.997

Epoch 22: Validation loss decreased (0.353072 --> 0.351470).  Saving model ...
	 Train_Loss: 0.3825 Train_Acc: 84.058 Val_Loss: 0.3515  BEST VAL Loss: 0.3515  Val_Acc: 86.264

Epoch 23: Validation loss decreased (0.351470 --> 0.349951).  Saving model ...
	 Train_Loss: 0.3808 Train_Acc: 84.116 Val_Loss: 0.3500  BEST VAL Loss: 0.3500  Val_Acc: 86.072

Epoch 24: Validation loss decreased (0.349951 --> 0.348760).  Saving model ...
	 Train_Loss: 0.3792 Train_Acc: 84.155 Val_Loss: 0.3488  BEST VAL Loss: 0.3488  Val_Acc: 85.755

Epoch 25: Validation loss decreased (0.348760 --> 0.347580).  Saving model ...
	 Train_Loss: 0.3777 Train_Acc: 84.144 Val_Loss: 0.3476  BEST VAL Loss: 0.3476  Val_Acc: 85.946

Epoch 26: Validation loss decreased (0.347580 --> 0.346471).  Saving model ...
	 Train_Loss: 0.3762 Train_Acc: 84.245 Val_Loss: 0.3465  BEST VAL Loss: 0.3465  Val_Acc: 85.824

Epoch 27: Validation loss decreased (0.346471 --> 0.345152).  Saving model ...
	 Train_Loss: 0.3748 Train_Acc: 84.266 Val_Loss: 0.3452  BEST VAL Loss: 0.3452  Val_Acc: 86.371

Epoch 28: Validation loss decreased (0.345152 --> 0.344293).  Saving model ...
	 Train_Loss: 0.3735 Train_Acc: 84.281 Val_Loss: 0.3443  BEST VAL Loss: 0.3443  Val_Acc: 85.973

Epoch 29: Validation loss decreased (0.344293 --> 0.343192).  Saving model ...
	 Train_Loss: 0.3722 Train_Acc: 84.340 Val_Loss: 0.3432  BEST VAL Loss: 0.3432  Val_Acc: 86.201

Epoch 30: Validation loss decreased (0.343192 --> 0.342136).  Saving model ...
	 Train_Loss: 0.3710 Train_Acc: 84.347 Val_Loss: 0.3421  BEST VAL Loss: 0.3421  Val_Acc: 86.285

Epoch 31: Validation loss decreased (0.342136 --> 0.341181).  Saving model ...
	 Train_Loss: 0.3699 Train_Acc: 84.357 Val_Loss: 0.3412  BEST VAL Loss: 0.3412  Val_Acc: 86.386

Epoch 32: Validation loss decreased (0.341181 --> 0.340254).  Saving model ...
	 Train_Loss: 0.3688 Train_Acc: 84.508 Val_Loss: 0.3403  BEST VAL Loss: 0.3403  Val_Acc: 86.303

Epoch 33: Validation loss decreased (0.340254 --> 0.339405).  Saving model ...
	 Train_Loss: 0.3677 Train_Acc: 84.506 Val_Loss: 0.3394  BEST VAL Loss: 0.3394  Val_Acc: 86.174

Epoch 34: Validation loss decreased (0.339405 --> 0.338427).  Saving model ...
	 Train_Loss: 0.3667 Train_Acc: 84.488 Val_Loss: 0.3384  BEST VAL Loss: 0.3384  Val_Acc: 86.542

Epoch 35: Validation loss decreased (0.338427 --> 0.337666).  Saving model ...
	 Train_Loss: 0.3657 Train_Acc: 84.599 Val_Loss: 0.3377  BEST VAL Loss: 0.3377  Val_Acc: 86.303

Epoch 36: Validation loss decreased (0.337666 --> 0.336896).  Saving model ...
	 Train_Loss: 0.3647 Train_Acc: 84.575 Val_Loss: 0.3369  BEST VAL Loss: 0.3369  Val_Acc: 86.512

Epoch 37: Validation loss decreased (0.336896 --> 0.336107).  Saving model ...
	 Train_Loss: 0.3638 Train_Acc: 84.624 Val_Loss: 0.3361  BEST VAL Loss: 0.3361  Val_Acc: 86.404

Epoch 38: Validation loss decreased (0.336107 --> 0.335395).  Saving model ...
	 Train_Loss: 0.3629 Train_Acc: 84.696 Val_Loss: 0.3354  BEST VAL Loss: 0.3354  Val_Acc: 86.467

Epoch 39: Validation loss decreased (0.335395 --> 0.334607).  Saving model ...
	 Train_Loss: 0.3620 Train_Acc: 84.661 Val_Loss: 0.3346  BEST VAL Loss: 0.3346  Val_Acc: 86.497

Epoch 40: Validation loss decreased (0.334607 --> 0.333846).  Saving model ...
	 Train_Loss: 0.3612 Train_Acc: 84.716 Val_Loss: 0.3338  BEST VAL Loss: 0.3338  Val_Acc: 86.653

Epoch 41: Validation loss decreased (0.333846 --> 0.333154).  Saving model ...
	 Train_Loss: 0.3604 Train_Acc: 84.780 Val_Loss: 0.3332  BEST VAL Loss: 0.3332  Val_Acc: 86.611

Epoch 42: Validation loss decreased (0.333154 --> 0.332641).  Saving model ...
	 Train_Loss: 0.3596 Train_Acc: 84.683 Val_Loss: 0.3326  BEST VAL Loss: 0.3326  Val_Acc: 86.315

Epoch 43: Validation loss decreased (0.332641 --> 0.331944).  Saving model ...
	 Train_Loss: 0.3589 Train_Acc: 84.678 Val_Loss: 0.3319  BEST VAL Loss: 0.3319  Val_Acc: 86.805

Epoch 44: Validation loss decreased (0.331944 --> 0.331294).  Saving model ...
	 Train_Loss: 0.3582 Train_Acc: 84.779 Val_Loss: 0.3313  BEST VAL Loss: 0.3313  Val_Acc: 86.713

Epoch 45: Validation loss decreased (0.331294 --> 0.330603).  Saving model ...
	 Train_Loss: 0.3575 Train_Acc: 84.654 Val_Loss: 0.3306  BEST VAL Loss: 0.3306  Val_Acc: 86.674

Epoch 46: Validation loss decreased (0.330603 --> 0.330147).  Saving model ...
	 Train_Loss: 0.3568 Train_Acc: 84.895 Val_Loss: 0.3301  BEST VAL Loss: 0.3301  Val_Acc: 86.509

Epoch 47: Validation loss decreased (0.330147 --> 0.329574).  Saving model ...
	 Train_Loss: 0.3561 Train_Acc: 84.875 Val_Loss: 0.3296  BEST VAL Loss: 0.3296  Val_Acc: 86.458

Epoch 48: Validation loss decreased (0.329574 --> 0.328977).  Saving model ...
	 Train_Loss: 0.3555 Train_Acc: 84.841 Val_Loss: 0.3290  BEST VAL Loss: 0.3290  Val_Acc: 86.898

Epoch 49: Validation loss decreased (0.328977 --> 0.328335).  Saving model ...
	 Train_Loss: 0.3549 Train_Acc: 84.860 Val_Loss: 0.3283  BEST VAL Loss: 0.3283  Val_Acc: 86.937

Epoch 50: Validation loss decreased (0.328335 --> 0.327747).  Saving model ...
	 Train_Loss: 0.3543 Train_Acc: 84.832 Val_Loss: 0.3277  BEST VAL Loss: 0.3277  Val_Acc: 87.009

Epoch 51: Validation loss decreased (0.327747 --> 0.327121).  Saving model ...
	 Train_Loss: 0.3537 Train_Acc: 84.875 Val_Loss: 0.3271  BEST VAL Loss: 0.3271  Val_Acc: 86.964

Epoch 52: Validation loss decreased (0.327121 --> 0.326554).  Saving model ...
	 Train_Loss: 0.3531 Train_Acc: 84.838 Val_Loss: 0.3266  BEST VAL Loss: 0.3266  Val_Acc: 87.105

Epoch 53: Validation loss decreased (0.326554 --> 0.326012).  Saving model ...
	 Train_Loss: 0.3526 Train_Acc: 84.938 Val_Loss: 0.3260  BEST VAL Loss: 0.3260  Val_Acc: 86.874

Epoch 54: Validation loss decreased (0.326012 --> 0.325460).  Saving model ...
	 Train_Loss: 0.3520 Train_Acc: 84.919 Val_Loss: 0.3255  BEST VAL Loss: 0.3255  Val_Acc: 87.108

Epoch 55: Validation loss decreased (0.325460 --> 0.324932).  Saving model ...
	 Train_Loss: 0.3515 Train_Acc: 84.944 Val_Loss: 0.3249  BEST VAL Loss: 0.3249  Val_Acc: 87.141

Epoch 56: Validation loss decreased (0.324932 --> 0.324418).  Saving model ...
	 Train_Loss: 0.3510 Train_Acc: 84.924 Val_Loss: 0.3244  BEST VAL Loss: 0.3244  Val_Acc: 87.075

Epoch 57: Validation loss decreased (0.324418 --> 0.323950).  Saving model ...
	 Train_Loss: 0.3505 Train_Acc: 84.977 Val_Loss: 0.3240  BEST VAL Loss: 0.3240  Val_Acc: 87.018

Epoch 58: Validation loss decreased (0.323950 --> 0.323499).  Saving model ...
	 Train_Loss: 0.3500 Train_Acc: 84.964 Val_Loss: 0.3235  BEST VAL Loss: 0.3235  Val_Acc: 87.129

Epoch 59: Validation loss decreased (0.323499 --> 0.323067).  Saving model ...
	 Train_Loss: 0.3495 Train_Acc: 84.981 Val_Loss: 0.3231  BEST VAL Loss: 0.3231  Val_Acc: 87.003

Epoch 60: Validation loss decreased (0.323067 --> 0.322693).  Saving model ...
	 Train_Loss: 0.3490 Train_Acc: 85.088 Val_Loss: 0.3227  BEST VAL Loss: 0.3227  Val_Acc: 86.698

Epoch 61: Validation loss decreased (0.322693 --> 0.322241).  Saving model ...
	 Train_Loss: 0.3486 Train_Acc: 84.977 Val_Loss: 0.3222  BEST VAL Loss: 0.3222  Val_Acc: 87.039

Epoch 62: Validation loss decreased (0.322241 --> 0.321826).  Saving model ...
	 Train_Loss: 0.3481 Train_Acc: 84.970 Val_Loss: 0.3218  BEST VAL Loss: 0.3218  Val_Acc: 87.024

Epoch 63: Validation loss decreased (0.321826 --> 0.321431).  Saving model ...
	 Train_Loss: 0.3477 Train_Acc: 85.001 Val_Loss: 0.3214  BEST VAL Loss: 0.3214  Val_Acc: 87.057

Epoch 64: Validation loss decreased (0.321431 --> 0.321042).  Saving model ...
	 Train_Loss: 0.3472 Train_Acc: 85.085 Val_Loss: 0.3210  BEST VAL Loss: 0.3210  Val_Acc: 86.952

Epoch 65: Validation loss decreased (0.321042 --> 0.320629).  Saving model ...
	 Train_Loss: 0.3468 Train_Acc: 85.016 Val_Loss: 0.3206  BEST VAL Loss: 0.3206  Val_Acc: 87.105

Epoch 66: Validation loss decreased (0.320629 --> 0.320215).  Saving model ...
	 Train_Loss: 0.3464 Train_Acc: 85.082 Val_Loss: 0.3202  BEST VAL Loss: 0.3202  Val_Acc: 87.308

Epoch 67: Validation loss decreased (0.320215 --> 0.319789).  Saving model ...
	 Train_Loss: 0.3460 Train_Acc: 85.059 Val_Loss: 0.3198  BEST VAL Loss: 0.3198  Val_Acc: 87.272

Epoch 68: Validation loss decreased (0.319789 --> 0.319392).  Saving model ...
	 Train_Loss: 0.3456 Train_Acc: 85.183 Val_Loss: 0.3194  BEST VAL Loss: 0.3194  Val_Acc: 87.135

Epoch 69: Validation loss decreased (0.319392 --> 0.319063).  Saving model ...
	 Train_Loss: 0.3452 Train_Acc: 85.070 Val_Loss: 0.3191  BEST VAL Loss: 0.3191  Val_Acc: 87.096

Epoch 70: Validation loss decreased (0.319063 --> 0.318697).  Saving model ...
	 Train_Loss: 0.3448 Train_Acc: 85.082 Val_Loss: 0.3187  BEST VAL Loss: 0.3187  Val_Acc: 87.227

Epoch 71: Validation loss decreased (0.318697 --> 0.318372).  Saving model ...
	 Train_Loss: 0.3445 Train_Acc: 85.135 Val_Loss: 0.3184  BEST VAL Loss: 0.3184  Val_Acc: 87.158

Epoch 72: Validation loss decreased (0.318372 --> 0.317967).  Saving model ...
	 Train_Loss: 0.3441 Train_Acc: 85.097 Val_Loss: 0.3180  BEST VAL Loss: 0.3180  Val_Acc: 87.320

Epoch 73: Validation loss decreased (0.317967 --> 0.317600).  Saving model ...
	 Train_Loss: 0.3437 Train_Acc: 85.058 Val_Loss: 0.3176  BEST VAL Loss: 0.3176  Val_Acc: 87.227

Epoch 74: Validation loss decreased (0.317600 --> 0.317279).  Saving model ...
	 Train_Loss: 0.3434 Train_Acc: 85.143 Val_Loss: 0.3173  BEST VAL Loss: 0.3173  Val_Acc: 87.123

Epoch 75: Validation loss decreased (0.317279 --> 0.316952).  Saving model ...
	 Train_Loss: 0.3431 Train_Acc: 85.026 Val_Loss: 0.3170  BEST VAL Loss: 0.3170  Val_Acc: 87.296

Epoch 76: Validation loss decreased (0.316952 --> 0.316628).  Saving model ...
	 Train_Loss: 0.3427 Train_Acc: 85.136 Val_Loss: 0.3166  BEST VAL Loss: 0.3166  Val_Acc: 87.164

Epoch 77: Validation loss decreased (0.316628 --> 0.316321).  Saving model ...
	 Train_Loss: 0.3424 Train_Acc: 85.164 Val_Loss: 0.3163  BEST VAL Loss: 0.3163  Val_Acc: 87.263

Epoch 78: Validation loss decreased (0.316321 --> 0.316003).  Saving model ...
	 Train_Loss: 0.3421 Train_Acc: 85.213 Val_Loss: 0.3160  BEST VAL Loss: 0.3160  Val_Acc: 87.290

Epoch 79: Validation loss decreased (0.316003 --> 0.315684).  Saving model ...
	 Train_Loss: 0.3417 Train_Acc: 85.223 Val_Loss: 0.3157  BEST VAL Loss: 0.3157  Val_Acc: 87.374

Epoch 80: Validation loss decreased (0.315684 --> 0.315378).  Saving model ...
	 Train_Loss: 0.3414 Train_Acc: 85.098 Val_Loss: 0.3154  BEST VAL Loss: 0.3154  Val_Acc: 87.329

Epoch 81: Validation loss decreased (0.315378 --> 0.315073).  Saving model ...
	 Train_Loss: 0.3411 Train_Acc: 85.186 Val_Loss: 0.3151  BEST VAL Loss: 0.3151  Val_Acc: 87.084

Epoch 82: Validation loss decreased (0.315073 --> 0.314755).  Saving model ...
	 Train_Loss: 0.3408 Train_Acc: 85.202 Val_Loss: 0.3148  BEST VAL Loss: 0.3148  Val_Acc: 87.275

Epoch 83: Validation loss decreased (0.314755 --> 0.314518).  Saving model ...
	 Train_Loss: 0.3405 Train_Acc: 85.146 Val_Loss: 0.3145  BEST VAL Loss: 0.3145  Val_Acc: 87.054

Epoch 84: Validation loss decreased (0.314518 --> 0.314235).  Saving model ...
	 Train_Loss: 0.3402 Train_Acc: 85.260 Val_Loss: 0.3142  BEST VAL Loss: 0.3142  Val_Acc: 87.272

Epoch 85: Validation loss decreased (0.314235 --> 0.313973).  Saving model ...
	 Train_Loss: 0.3399 Train_Acc: 85.220 Val_Loss: 0.3140  BEST VAL Loss: 0.3140  Val_Acc: 87.335

Epoch 86: Validation loss decreased (0.313973 --> 0.313733).  Saving model ...
	 Train_Loss: 0.3396 Train_Acc: 85.280 Val_Loss: 0.3137  BEST VAL Loss: 0.3137  Val_Acc: 87.332

Epoch 87: Validation loss decreased (0.313733 --> 0.313463).  Saving model ...
	 Train_Loss: 0.3394 Train_Acc: 85.211 Val_Loss: 0.3135  BEST VAL Loss: 0.3135  Val_Acc: 87.335

Epoch 88: Validation loss decreased (0.313463 --> 0.313180).  Saving model ...
	 Train_Loss: 0.3391 Train_Acc: 85.252 Val_Loss: 0.3132  BEST VAL Loss: 0.3132  Val_Acc: 87.374

Epoch 89: Validation loss decreased (0.313180 --> 0.312934).  Saving model ...
	 Train_Loss: 0.3388 Train_Acc: 85.214 Val_Loss: 0.3129  BEST VAL Loss: 0.3129  Val_Acc: 87.338

Epoch 90: Validation loss decreased (0.312934 --> 0.312670).  Saving model ...
	 Train_Loss: 0.3385 Train_Acc: 85.218 Val_Loss: 0.3127  BEST VAL Loss: 0.3127  Val_Acc: 87.257

Epoch 91: Validation loss decreased (0.312670 --> 0.312412).  Saving model ...
	 Train_Loss: 0.3383 Train_Acc: 85.251 Val_Loss: 0.3124  BEST VAL Loss: 0.3124  Val_Acc: 87.353

Epoch 92: Validation loss decreased (0.312412 --> 0.312171).  Saving model ...
	 Train_Loss: 0.3380 Train_Acc: 85.233 Val_Loss: 0.3122  BEST VAL Loss: 0.3122  Val_Acc: 87.347

Epoch 93: Validation loss decreased (0.312171 --> 0.311946).  Saving model ...
	 Train_Loss: 0.3378 Train_Acc: 85.249 Val_Loss: 0.3119  BEST VAL Loss: 0.3119  Val_Acc: 87.356

Epoch 94: Validation loss decreased (0.311946 --> 0.311721).  Saving model ...
	 Train_Loss: 0.3375 Train_Acc: 85.315 Val_Loss: 0.3117  BEST VAL Loss: 0.3117  Val_Acc: 87.287

Epoch 95: Validation loss decreased (0.311721 --> 0.311498).  Saving model ...
	 Train_Loss: 0.3373 Train_Acc: 85.253 Val_Loss: 0.3115  BEST VAL Loss: 0.3115  Val_Acc: 87.431

Epoch 96: Validation loss decreased (0.311498 --> 0.311262).  Saving model ...
	 Train_Loss: 0.3370 Train_Acc: 85.293 Val_Loss: 0.3113  BEST VAL Loss: 0.3113  Val_Acc: 87.613

Epoch 97: Validation loss decreased (0.311262 --> 0.311074).  Saving model ...
	 Train_Loss: 0.3368 Train_Acc: 85.269 Val_Loss: 0.3111  BEST VAL Loss: 0.3111  Val_Acc: 87.123

Epoch 98: Validation loss decreased (0.311074 --> 0.310857).  Saving model ...
	 Train_Loss: 0.3365 Train_Acc: 85.282 Val_Loss: 0.3109  BEST VAL Loss: 0.3109  Val_Acc: 87.536

Epoch 99: Validation loss decreased (0.310857 --> 0.310628).  Saving model ...
	 Train_Loss: 0.3363 Train_Acc: 85.307 Val_Loss: 0.3106  BEST VAL Loss: 0.3106  Val_Acc: 87.341

LPS_100.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.91      0.91      0.91    169560
           1       0.85      0.85      0.85     97754

    accuracy                           0.89    267314
   macro avg       0.88      0.88      0.88    267314
weighted avg       0.89      0.89      0.89    267314

LPS_100.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.90      0.90      0.90     21196
           1       0.83      0.83      0.83     12219

    accuracy                           0.87     33415
   macro avg       0.86      0.86      0.86     33415
weighted avg       0.87      0.87      0.87     33415

LPS_100.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.90      0.90      0.90     21196
           1       0.83      0.83      0.83     12219

    accuracy                           0.87     33415
   macro avg       0.86      0.86      0.86     33415
weighted avg       0.87      0.87      0.87     33415

              precision    recall  f1-score   support

           0       0.90      0.90      0.90     21196
           1       0.83      0.83      0.83     12219

    accuracy                           0.87     33415
   macro avg       0.86      0.86      0.86     33415
weighted avg       0.87      0.87      0.87     33415

LPS_100.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.65      0.89      0.75     28584
           1       0.88      0.63      0.74     37243

    accuracy                           0.74     65827
   macro avg       0.76      0.76      0.74     65827
weighted avg       0.78      0.74      0.74     65827

              precision    recall  f1-score   support

           0       0.65      0.89      0.75     28584
           1       0.88      0.63      0.74     37243

    accuracy                           0.74     65827
   macro avg       0.76      0.76      0.74     65827
weighted avg       0.78      0.74      0.74     65827

completed
