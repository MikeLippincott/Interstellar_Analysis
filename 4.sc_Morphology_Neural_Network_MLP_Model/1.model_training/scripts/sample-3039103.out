[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'e2a2faec'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '7501b8e6'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '4099464b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '2d63578b'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_0.100_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (30787, 1276)
Number of total missing values across all columns: 61574
Data Subset Is Off
Wells held out for testing: ['B16' 'L22']
Wells to use for training, validation, and testing ['B17' 'B20' 'B21' 'L18' 'L19' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.697627).  Saving model ...
	 Train_Loss: 0.7121 Train_Acc: 47.680 Val_Loss: 0.6976  BEST VAL Loss: 0.6976  Val_Acc: 47.661

Epoch 1: Validation loss decreased (0.697627 --> 0.694725).  Saving model ...
	 Train_Loss: 0.7039 Train_Acc: 48.535 Val_Loss: 0.6947  BEST VAL Loss: 0.6947  Val_Acc: 47.661

Epoch 2: Validation loss decreased (0.694725 --> 0.693110).  Saving model ...
	 Train_Loss: 0.6999 Train_Acc: 51.912 Val_Loss: 0.6931  BEST VAL Loss: 0.6931  Val_Acc: 56.443

Epoch 3: Validation loss decreased (0.693110 --> 0.692021).  Saving model ...
	 Train_Loss: 0.6974 Train_Acc: 54.472 Val_Loss: 0.6920  BEST VAL Loss: 0.6920  Val_Acc: 56.443

Epoch 4: Validation loss decreased (0.692021 --> 0.691035).  Saving model ...
	 Train_Loss: 0.6955 Train_Acc: 55.377 Val_Loss: 0.6910  BEST VAL Loss: 0.6910  Val_Acc: 58.208

Epoch 5: Validation loss decreased (0.691035 --> 0.689837).  Saving model ...
	 Train_Loss: 0.6939 Train_Acc: 56.199 Val_Loss: 0.6898  BEST VAL Loss: 0.6898  Val_Acc: 58.959

Epoch 6: Validation loss decreased (0.689837 --> 0.688618).  Saving model ...
	 Train_Loss: 0.6925 Train_Acc: 56.569 Val_Loss: 0.6886  BEST VAL Loss: 0.6886  Val_Acc: 59.312

Epoch 7: Validation loss decreased (0.688618 --> 0.687666).  Saving model ...
	 Train_Loss: 0.6914 Train_Acc: 56.679 Val_Loss: 0.6877  BEST VAL Loss: 0.6877  Val_Acc: 60.327

Epoch 8: Validation loss decreased (0.687666 --> 0.686419).  Saving model ...
	 Train_Loss: 0.6900 Train_Acc: 58.103 Val_Loss: 0.6864  BEST VAL Loss: 0.6864  Val_Acc: 60.944

Epoch 9: Validation loss decreased (0.686419 --> 0.684991).  Saving model ...
	 Train_Loss: 0.6886 Train_Acc: 58.257 Val_Loss: 0.6850  BEST VAL Loss: 0.6850  Val_Acc: 61.077

Epoch 10: Validation loss decreased (0.684991 --> 0.683613).  Saving model ...
	 Train_Loss: 0.6874 Train_Acc: 58.804 Val_Loss: 0.6836  BEST VAL Loss: 0.6836  Val_Acc: 61.165

Epoch 11: Validation loss decreased (0.683613 --> 0.682006).  Saving model ...
	 Train_Loss: 0.6860 Train_Acc: 59.493 Val_Loss: 0.6820  BEST VAL Loss: 0.6820  Val_Acc: 61.650

Epoch 12: Validation loss decreased (0.682006 --> 0.680528).  Saving model ...
	 Train_Loss: 0.6847 Train_Acc: 59.813 Val_Loss: 0.6805  BEST VAL Loss: 0.6805  Val_Acc: 61.871

Epoch 13: Validation loss decreased (0.680528 --> 0.678967).  Saving model ...
	 Train_Loss: 0.6835 Train_Acc: 60.106 Val_Loss: 0.6790  BEST VAL Loss: 0.6790  Val_Acc: 62.268

Epoch 14: Validation loss decreased (0.678967 --> 0.677595).  Saving model ...
	 Train_Loss: 0.6823 Train_Acc: 60.216 Val_Loss: 0.6776  BEST VAL Loss: 0.6776  Val_Acc: 62.886

Epoch 15: Validation loss decreased (0.677595 --> 0.676196).  Saving model ...
	 Train_Loss: 0.6809 Train_Acc: 60.983 Val_Loss: 0.6762  BEST VAL Loss: 0.6762  Val_Acc: 62.357

Epoch 16: Validation loss decreased (0.676196 --> 0.675002).  Saving model ...
	 Train_Loss: 0.6797 Train_Acc: 61.618 Val_Loss: 0.6750  BEST VAL Loss: 0.6750  Val_Acc: 62.798

Epoch 17: Validation loss decreased (0.675002 --> 0.673584).  Saving model ...
	 Train_Loss: 0.6783 Train_Acc: 62.010 Val_Loss: 0.6736  BEST VAL Loss: 0.6736  Val_Acc: 64.431

Epoch 18: Validation loss decreased (0.673584 --> 0.672174).  Saving model ...
	 Train_Loss: 0.6771 Train_Acc: 62.473 Val_Loss: 0.6722  BEST VAL Loss: 0.6722  Val_Acc: 65.093

Epoch 19: Validation loss decreased (0.672174 --> 0.670722).  Saving model ...
	 Train_Loss: 0.6759 Train_Acc: 62.446 Val_Loss: 0.6707  BEST VAL Loss: 0.6707  Val_Acc: 65.269

Epoch 20: Validation loss decreased (0.670722 --> 0.669427).  Saving model ...
	 Train_Loss: 0.6745 Train_Acc: 63.455 Val_Loss: 0.6694  BEST VAL Loss: 0.6694  Val_Acc: 64.210

Epoch 21: Validation loss decreased (0.669427 --> 0.668131).  Saving model ...
	 Train_Loss: 0.6731 Train_Acc: 63.334 Val_Loss: 0.6681  BEST VAL Loss: 0.6681  Val_Acc: 64.475

Epoch 22: Validation loss decreased (0.668131 --> 0.666519).  Saving model ...
	 Train_Loss: 0.6718 Train_Acc: 63.389 Val_Loss: 0.6665  BEST VAL Loss: 0.6665  Val_Acc: 65.181

Epoch 23: Validation loss decreased (0.666519 --> 0.665162).  Saving model ...
	 Train_Loss: 0.6706 Train_Acc: 63.593 Val_Loss: 0.6652  BEST VAL Loss: 0.6652  Val_Acc: 66.064

Epoch 24: Validation loss decreased (0.665162 --> 0.663662).  Saving model ...
	 Train_Loss: 0.6694 Train_Acc: 64.288 Val_Loss: 0.6637  BEST VAL Loss: 0.6637  Val_Acc: 66.108

Epoch 25: Validation loss decreased (0.663662 --> 0.662404).  Saving model ...
	 Train_Loss: 0.6682 Train_Acc: 64.388 Val_Loss: 0.6624  BEST VAL Loss: 0.6624  Val_Acc: 65.490

Epoch 26: Validation loss decreased (0.662404 --> 0.661075).  Saving model ...
	 Train_Loss: 0.6671 Train_Acc: 64.018 Val_Loss: 0.6611  BEST VAL Loss: 0.6611  Val_Acc: 66.152

Epoch 27: Validation loss decreased (0.661075 --> 0.659827).  Saving model ...
	 Train_Loss: 0.6658 Train_Acc: 64.780 Val_Loss: 0.6598  BEST VAL Loss: 0.6598  Val_Acc: 66.240

Epoch 28: Validation loss decreased (0.659827 --> 0.658639).  Saving model ...
	 Train_Loss: 0.6646 Train_Acc: 65.282 Val_Loss: 0.6586  BEST VAL Loss: 0.6586  Val_Acc: 65.843

Epoch 29: Validation loss decreased (0.658639 --> 0.657295).  Saving model ...
	 Train_Loss: 0.6634 Train_Acc: 65.392 Val_Loss: 0.6573  BEST VAL Loss: 0.6573  Val_Acc: 66.019

Epoch 30: Validation loss decreased (0.657295 --> 0.656076).  Saving model ...
	 Train_Loss: 0.6622 Train_Acc: 65.729 Val_Loss: 0.6561  BEST VAL Loss: 0.6561  Val_Acc: 66.152

Epoch 31: Validation loss decreased (0.656076 --> 0.654899).  Saving model ...
	 Train_Loss: 0.6611 Train_Acc: 65.729 Val_Loss: 0.6549  BEST VAL Loss: 0.6549  Val_Acc: 66.108

Epoch 32: Validation loss decreased (0.654899 --> 0.653764).  Saving model ...
	 Train_Loss: 0.6598 Train_Acc: 66.142 Val_Loss: 0.6538  BEST VAL Loss: 0.6538  Val_Acc: 65.887

Epoch 33: Validation loss decreased (0.653764 --> 0.652491).  Saving model ...
	 Train_Loss: 0.6587 Train_Acc: 66.490 Val_Loss: 0.6525  BEST VAL Loss: 0.6525  Val_Acc: 67.079

Epoch 34: Validation loss decreased (0.652491 --> 0.651649).  Saving model ...
	 Train_Loss: 0.6576 Train_Acc: 66.650 Val_Loss: 0.6516  BEST VAL Loss: 0.6516  Val_Acc: 67.034

Epoch 35: Validation loss decreased (0.651649 --> 0.650697).  Saving model ...
	 Train_Loss: 0.6565 Train_Acc: 66.529 Val_Loss: 0.6507  BEST VAL Loss: 0.6507  Val_Acc: 65.975

Epoch 36: Validation loss decreased (0.650697 --> 0.649681).  Saving model ...
	 Train_Loss: 0.6553 Train_Acc: 67.069 Val_Loss: 0.6497  BEST VAL Loss: 0.6497  Val_Acc: 66.108

Epoch 37: Validation loss decreased (0.649681 --> 0.648539).  Saving model ...
	 Train_Loss: 0.6540 Train_Acc: 67.963 Val_Loss: 0.6485  BEST VAL Loss: 0.6485  Val_Acc: 67.785

Epoch 38: Validation loss decreased (0.648539 --> 0.647810).  Saving model ...
	 Train_Loss: 0.6529 Train_Acc: 67.263 Val_Loss: 0.6478  BEST VAL Loss: 0.6478  Val_Acc: 66.152

Epoch 39: Validation loss decreased (0.647810 --> 0.646608).  Saving model ...
	 Train_Loss: 0.6517 Train_Acc: 68.068 Val_Loss: 0.6466  BEST VAL Loss: 0.6466  Val_Acc: 67.741

Epoch 40: Validation loss decreased (0.646608 --> 0.645621).  Saving model ...
	 Train_Loss: 0.6505 Train_Acc: 68.217 Val_Loss: 0.6456  BEST VAL Loss: 0.6456  Val_Acc: 68.182

Epoch 41: Validation loss decreased (0.645621 --> 0.644395).  Saving model ...
	 Train_Loss: 0.6494 Train_Acc: 68.223 Val_Loss: 0.6444  BEST VAL Loss: 0.6444  Val_Acc: 68.314

Epoch 42: Validation loss decreased (0.644395 --> 0.643327).  Saving model ...
	 Train_Loss: 0.6483 Train_Acc: 68.565 Val_Loss: 0.6433  BEST VAL Loss: 0.6433  Val_Acc: 67.785

Epoch 43: Validation loss decreased (0.643327 --> 0.642228).  Saving model ...
	 Train_Loss: 0.6472 Train_Acc: 68.780 Val_Loss: 0.6422  BEST VAL Loss: 0.6422  Val_Acc: 68.844

Epoch 44: Validation loss decreased (0.642228 --> 0.641167).  Saving model ...
	 Train_Loss: 0.6460 Train_Acc: 69.128 Val_Loss: 0.6412  BEST VAL Loss: 0.6412  Val_Acc: 68.623

Epoch 45: Validation loss decreased (0.641167 --> 0.640158).  Saving model ...
	 Train_Loss: 0.6450 Train_Acc: 69.144 Val_Loss: 0.6402  BEST VAL Loss: 0.6402  Val_Acc: 68.491

Epoch 46: Validation loss decreased (0.640158 --> 0.639222).  Saving model ...
	 Train_Loss: 0.6440 Train_Acc: 69.056 Val_Loss: 0.6392  BEST VAL Loss: 0.6392  Val_Acc: 67.652

Epoch 47: Validation loss decreased (0.639222 --> 0.638145).  Saving model ...
	 Train_Loss: 0.6428 Train_Acc: 69.497 Val_Loss: 0.6381  BEST VAL Loss: 0.6381  Val_Acc: 69.285

Epoch 48: Validation loss decreased (0.638145 --> 0.636986).  Saving model ...
	 Train_Loss: 0.6417 Train_Acc: 69.917 Val_Loss: 0.6370  BEST VAL Loss: 0.6370  Val_Acc: 69.064

Epoch 49: Validation loss decreased (0.636986 --> 0.636029).  Saving model ...
	 Train_Loss: 0.6405 Train_Acc: 70.176 Val_Loss: 0.6360  BEST VAL Loss: 0.6360  Val_Acc: 69.550

Epoch 50: Validation loss decreased (0.636029 --> 0.635509).  Saving model ...
	 Train_Loss: 0.6395 Train_Acc: 69.873 Val_Loss: 0.6355  BEST VAL Loss: 0.6355  Val_Acc: 66.946

Epoch 51: Validation loss decreased (0.635509 --> 0.634837).  Saving model ...
	 Train_Loss: 0.6384 Train_Acc: 70.386 Val_Loss: 0.6348  BEST VAL Loss: 0.6348  Val_Acc: 68.226

Epoch 52: Validation loss decreased (0.634837 --> 0.633876).  Saving model ...
	 Train_Loss: 0.6373 Train_Acc: 70.038 Val_Loss: 0.6339  BEST VAL Loss: 0.6339  Val_Acc: 69.462

Epoch 53: Validation loss decreased (0.633876 --> 0.632909).  Saving model ...
	 Train_Loss: 0.6363 Train_Acc: 69.994 Val_Loss: 0.6329  BEST VAL Loss: 0.6329  Val_Acc: 69.859

Epoch 54: Validation loss decreased (0.632909 --> 0.632122).  Saving model ...
	 Train_Loss: 0.6352 Train_Acc: 70.551 Val_Loss: 0.6321  BEST VAL Loss: 0.6321  Val_Acc: 68.623

Epoch 55: Validation loss decreased (0.632122 --> 0.631581).  Saving model ...
	 Train_Loss: 0.6343 Train_Acc: 70.766 Val_Loss: 0.6316  BEST VAL Loss: 0.6316  Val_Acc: 68.138

Epoch 56: Validation loss decreased (0.631581 --> 0.630775).  Saving model ...
	 Train_Loss: 0.6333 Train_Acc: 70.435 Val_Loss: 0.6308  BEST VAL Loss: 0.6308  Val_Acc: 68.844

Epoch 57: Validation loss decreased (0.630775 --> 0.629912).  Saving model ...
	 Train_Loss: 0.6322 Train_Acc: 71.379 Val_Loss: 0.6299  BEST VAL Loss: 0.6299  Val_Acc: 69.153

Epoch 58: Validation loss decreased (0.629912 --> 0.629006).  Saving model ...
	 Train_Loss: 0.6313 Train_Acc: 71.208 Val_Loss: 0.6290  BEST VAL Loss: 0.6290  Val_Acc: 70.256

Epoch 59: Validation loss decreased (0.629006 --> 0.628687).  Saving model ...
	 Train_Loss: 0.6303 Train_Acc: 71.313 Val_Loss: 0.6287  BEST VAL Loss: 0.6287  Val_Acc: 67.696

Epoch 60: Validation loss decreased (0.628687 --> 0.627841).  Saving model ...
	 Train_Loss: 0.6293 Train_Acc: 71.075 Val_Loss: 0.6278  BEST VAL Loss: 0.6278  Val_Acc: 69.109

Epoch 61: Validation loss decreased (0.627841 --> 0.627014).  Saving model ...
	 Train_Loss: 0.6284 Train_Acc: 71.114 Val_Loss: 0.6270  BEST VAL Loss: 0.6270  Val_Acc: 69.064

Epoch 62: Validation loss decreased (0.627014 --> 0.626387).  Saving model ...
	 Train_Loss: 0.6274 Train_Acc: 71.660 Val_Loss: 0.6264  BEST VAL Loss: 0.6264  Val_Acc: 68.182

Epoch 63: Validation loss decreased (0.626387 --> 0.625505).  Saving model ...
	 Train_Loss: 0.6263 Train_Acc: 71.539 Val_Loss: 0.6255  BEST VAL Loss: 0.6255  Val_Acc: 69.638

Epoch 64: Validation loss decreased (0.625505 --> 0.625130).  Saving model ...
	 Train_Loss: 0.6253 Train_Acc: 71.809 Val_Loss: 0.6251  BEST VAL Loss: 0.6251  Val_Acc: 68.226

Epoch 65: Validation loss decreased (0.625130 --> 0.624276).  Saving model ...
	 Train_Loss: 0.6244 Train_Acc: 72.151 Val_Loss: 0.6243  BEST VAL Loss: 0.6243  Val_Acc: 69.947

Epoch 66: Validation loss decreased (0.624276 --> 0.623512).  Saving model ...
	 Train_Loss: 0.6234 Train_Acc: 72.151 Val_Loss: 0.6235  BEST VAL Loss: 0.6235  Val_Acc: 70.168

Epoch 67: Validation loss decreased (0.623512 --> 0.622780).  Saving model ...
	 Train_Loss: 0.6225 Train_Acc: 72.295 Val_Loss: 0.6228  BEST VAL Loss: 0.6228  Val_Acc: 70.035

Epoch 68: Validation loss decreased (0.622780 --> 0.622491).  Saving model ...
	 Train_Loss: 0.6216 Train_Acc: 72.665 Val_Loss: 0.6225  BEST VAL Loss: 0.6225  Val_Acc: 68.314

Epoch 69: Validation loss decreased (0.622491 --> 0.621865).  Saving model ...
	 Train_Loss: 0.6208 Train_Acc: 72.565 Val_Loss: 0.6219  BEST VAL Loss: 0.6219  Val_Acc: 69.506

Epoch 70: Validation loss decreased (0.621865 --> 0.621087).  Saving model ...
	 Train_Loss: 0.6199 Train_Acc: 72.405 Val_Loss: 0.6211  BEST VAL Loss: 0.6211  Val_Acc: 70.344

Epoch 71: Validation loss decreased (0.621087 --> 0.620494).  Saving model ...
	 Train_Loss: 0.6191 Train_Acc: 72.218 Val_Loss: 0.6205  BEST VAL Loss: 0.6205  Val_Acc: 70.477

Epoch 72: Validation loss decreased (0.620494 --> 0.620170).  Saving model ...
	 Train_Loss: 0.6183 Train_Acc: 72.869 Val_Loss: 0.6202  BEST VAL Loss: 0.6202  Val_Acc: 67.343

Epoch 73: Validation loss decreased (0.620170 --> 0.619484).  Saving model ...
	 Train_Loss: 0.6174 Train_Acc: 72.521 Val_Loss: 0.6195  BEST VAL Loss: 0.6195  Val_Acc: 70.918

Epoch 74: Validation loss decreased (0.619484 --> 0.618946).  Saving model ...
	 Train_Loss: 0.6165 Train_Acc: 73.238 Val_Loss: 0.6189  BEST VAL Loss: 0.6189  Val_Acc: 69.373

Epoch 75: Validation loss decreased (0.618946 --> 0.618656).  Saving model ...
	 Train_Loss: 0.6157 Train_Acc: 73.227 Val_Loss: 0.6187  BEST VAL Loss: 0.6187  Val_Acc: 68.447

Epoch 76: Validation loss decreased (0.618656 --> 0.618020).  Saving model ...
	 Train_Loss: 0.6148 Train_Acc: 72.703 Val_Loss: 0.6180  BEST VAL Loss: 0.6180  Val_Acc: 70.256

Epoch 77: Validation loss decreased (0.618020 --> 0.617582).  Saving model ...
	 Train_Loss: 0.6140 Train_Acc: 72.791 Val_Loss: 0.6176  BEST VAL Loss: 0.6176  Val_Acc: 68.314

Epoch 78: Validation loss decreased (0.617582 --> 0.617279).  Saving model ...
	 Train_Loss: 0.6132 Train_Acc: 73.073 Val_Loss: 0.6173  BEST VAL Loss: 0.6173  Val_Acc: 69.726

Epoch 79: Validation loss decreased (0.617279 --> 0.616721).  Saving model ...
	 Train_Loss: 0.6125 Train_Acc: 73.338 Val_Loss: 0.6167  BEST VAL Loss: 0.6167  Val_Acc: 70.609

Epoch 80: Validation loss decreased (0.616721 --> 0.616222).  Saving model ...
	 Train_Loss: 0.6117 Train_Acc: 73.056 Val_Loss: 0.6162  BEST VAL Loss: 0.6162  Val_Acc: 70.168

Epoch 81: Validation loss decreased (0.616222 --> 0.615627).  Saving model ...
	 Train_Loss: 0.6109 Train_Acc: 73.487 Val_Loss: 0.6156  BEST VAL Loss: 0.6156  Val_Acc: 70.521

Epoch 82: Validation loss decreased (0.615627 --> 0.615311).  Saving model ...
	 Train_Loss: 0.6101 Train_Acc: 74.176 Val_Loss: 0.6153  BEST VAL Loss: 0.6153  Val_Acc: 68.888

Epoch 83: Validation loss decreased (0.615311 --> 0.614896).  Saving model ...
	 Train_Loss: 0.6094 Train_Acc: 73.189 Val_Loss: 0.6149  BEST VAL Loss: 0.6149  Val_Acc: 69.020

Epoch 84: Validation loss decreased (0.614896 --> 0.614501).  Saving model ...
	 Train_Loss: 0.6087 Train_Acc: 73.862 Val_Loss: 0.6145  BEST VAL Loss: 0.6145  Val_Acc: 69.373

Epoch 85: Validation loss decreased (0.614501 --> 0.613980).  Saving model ...
	 Train_Loss: 0.6079 Train_Acc: 74.121 Val_Loss: 0.6140  BEST VAL Loss: 0.6140  Val_Acc: 68.756

Epoch 86: Validation loss decreased (0.613980 --> 0.613650).  Saving model ...
	 Train_Loss: 0.6072 Train_Acc: 73.509 Val_Loss: 0.6137  BEST VAL Loss: 0.6137  Val_Acc: 69.329

Epoch 87: Validation loss decreased (0.613650 --> 0.613631).  Saving model ...
	 Train_Loss: 0.6065 Train_Acc: 73.680 Val_Loss: 0.6136  BEST VAL Loss: 0.6136  Val_Acc: 68.667

Epoch 88: Validation loss decreased (0.613631 --> 0.613109).  Saving model ...
	 Train_Loss: 0.6059 Train_Acc: 73.730 Val_Loss: 0.6131  BEST VAL Loss: 0.6131  Val_Acc: 68.844

Epoch 89: Validation loss decreased (0.613109 --> 0.612839).  Saving model ...
	 Train_Loss: 0.6052 Train_Acc: 74.154 Val_Loss: 0.6128  BEST VAL Loss: 0.6128  Val_Acc: 68.491

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.6045 Train_Acc: 74.210 Val_Loss: 0.6129  BEST VAL Loss: 0.6128  Val_Acc: 68.756

Epoch 91: Validation loss decreased (0.612839 --> 0.612413).  Saving model ...
	 Train_Loss: 0.6037 Train_Acc: 74.557 Val_Loss: 0.6124  BEST VAL Loss: 0.6124  Val_Acc: 70.035

Epoch 92: Validation loss decreased (0.612413 --> 0.612100).  Saving model ...
	 Train_Loss: 0.6030 Train_Acc: 74.359 Val_Loss: 0.6121  BEST VAL Loss: 0.6121  Val_Acc: 69.771

Epoch 93: Validation loss decreased (0.612100 --> 0.611606).  Saving model ...
	 Train_Loss: 0.6023 Train_Acc: 74.331 Val_Loss: 0.6116  BEST VAL Loss: 0.6116  Val_Acc: 71.271

Epoch 94: Validation loss decreased (0.611606 --> 0.610973).  Saving model ...
	 Train_Loss: 0.6016 Train_Acc: 73.983 Val_Loss: 0.6110  BEST VAL Loss: 0.6110  Val_Acc: 70.609

Epoch 95: Validation loss decreased (0.610973 --> 0.610633).  Saving model ...
	 Train_Loss: 0.6010 Train_Acc: 74.496 Val_Loss: 0.6106  BEST VAL Loss: 0.6106  Val_Acc: 70.741

Epoch 96: Validation loss decreased (0.610633 --> 0.610234).  Saving model ...
	 Train_Loss: 0.6003 Train_Acc: 74.750 Val_Loss: 0.6102  BEST VAL Loss: 0.6102  Val_Acc: 69.373

Epoch 97: Validation loss decreased (0.610234 --> 0.609800).  Saving model ...
	 Train_Loss: 0.5996 Train_Acc: 74.612 Val_Loss: 0.6098  BEST VAL Loss: 0.6098  Val_Acc: 70.477

Epoch 98: Validation loss decreased (0.609800 --> 0.609640).  Saving model ...
	 Train_Loss: 0.5989 Train_Acc: 75.153 Val_Loss: 0.6096  BEST VAL Loss: 0.6096  Val_Acc: 68.138

Epoch 99: Validation loss decreased (0.609640 --> 0.609545).  Saving model ...
	 Train_Loss: 0.5982 Train_Acc: 74.684 Val_Loss: 0.6095  BEST VAL Loss: 0.6095  Val_Acc: 68.579

Flagellin_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.45      0.46      8634
           1       0.52      0.54      0.53      9489

    accuracy                           0.50     18123
   macro avg       0.50      0.50      0.50     18123
weighted avg       0.50      0.50      0.50     18123

Flagellin_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.46      0.48      1080
           1       0.54      0.59      0.56      1186

    accuracy                           0.52      2266
   macro avg       0.52      0.52      0.52      2266
weighted avg       0.52      0.52      0.52      2266

Flagellin_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.47      0.47      1079
           1       0.52      0.53      0.53      1187

    accuracy                           0.50      2266
   macro avg       0.50      0.50      0.50      2266
weighted avg       0.50      0.50      0.50      2266

              precision    recall  f1-score   support

           0       0.48      0.47      0.47      1079
           1       0.52      0.53      0.53      1187

    accuracy                           0.50      2266
   macro avg       0.50      0.50      0.50      2266
weighted avg       0.50      0.50      0.50      2266

Flagellin_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.40      0.45      4135
           1       0.49      0.60      0.54      3997

    accuracy                           0.50      8132
   macro avg       0.50      0.50      0.49      8132
weighted avg       0.50      0.50      0.49      8132

              precision    recall  f1-score   support

           0       0.51      0.40      0.45      4135
           1       0.49      0.60      0.54      3997

    accuracy                           0.50      8132
   macro avg       0.50      0.50      0.49      8132
weighted avg       0.50      0.50      0.49      8132

completed
