[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'aabe001f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'a473ff67'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '4ca2fc8b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '7369804c'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: DMSO_0.100_DMSO_0.025 treatment_name: H2O2_100.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: DMSO_0.100_DMSO_0.025
TREATMENT_NAME: H2O2_100.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (455666, 1270)
Number of total missing values across all columns: 911332
Data Subset Is Off
Wells held out for testing: ['I05' 'J06']
Wells to use for training, validation, and testing ['B06' 'C06' 'B07' 'C07' 'H04' 'I04' 'H05' 'I06' 'I07' 'H10' 'I10' 'H11'
 'I11' 'J07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.686162).  Saving model ...
	 Train_Loss: 0.6919 Train_Acc: 53.159 Val_Loss: 0.6862  BEST VAL Loss: 0.6862  Val_Acc: 54.710

Epoch 1: Validation loss decreased (0.686162 --> 0.683895).  Saving model ...
	 Train_Loss: 0.6883 Train_Acc: 54.921 Val_Loss: 0.6839  BEST VAL Loss: 0.6839  Val_Acc: 55.608

Epoch 2: Validation loss decreased (0.683895 --> 0.681827).  Saving model ...
	 Train_Loss: 0.6856 Train_Acc: 56.063 Val_Loss: 0.6818  BEST VAL Loss: 0.6818  Val_Acc: 56.501

Epoch 3: Validation loss decreased (0.681827 --> 0.679922).  Saving model ...
	 Train_Loss: 0.6834 Train_Acc: 56.771 Val_Loss: 0.6799  BEST VAL Loss: 0.6799  Val_Acc: 57.092

Epoch 4: Validation loss decreased (0.679922 --> 0.678176).  Saving model ...
	 Train_Loss: 0.6814 Train_Acc: 57.330 Val_Loss: 0.6782  BEST VAL Loss: 0.6782  Val_Acc: 57.927

Epoch 5: Validation loss decreased (0.678176 --> 0.676519).  Saving model ...
	 Train_Loss: 0.6796 Train_Acc: 57.919 Val_Loss: 0.6765  BEST VAL Loss: 0.6765  Val_Acc: 58.335

Epoch 6: Validation loss decreased (0.676519 --> 0.675015).  Saving model ...
	 Train_Loss: 0.6779 Train_Acc: 58.217 Val_Loss: 0.6750  BEST VAL Loss: 0.6750  Val_Acc: 58.477

Epoch 7: Validation loss decreased (0.675015 --> 0.673597).  Saving model ...
	 Train_Loss: 0.6764 Train_Acc: 58.701 Val_Loss: 0.6736  BEST VAL Loss: 0.6736  Val_Acc: 58.766

Epoch 8: Validation loss decreased (0.673597 --> 0.672263).  Saving model ...
	 Train_Loss: 0.6749 Train_Acc: 58.928 Val_Loss: 0.6723  BEST VAL Loss: 0.6723  Val_Acc: 59.177

Epoch 9: Validation loss decreased (0.672263 --> 0.670978).  Saving model ...
	 Train_Loss: 0.6735 Train_Acc: 59.455 Val_Loss: 0.6710  BEST VAL Loss: 0.6710  Val_Acc: 59.456

Epoch 10: Validation loss decreased (0.670978 --> 0.669724).  Saving model ...
	 Train_Loss: 0.6721 Train_Acc: 59.821 Val_Loss: 0.6697  BEST VAL Loss: 0.6697  Val_Acc: 59.695

Epoch 11: Validation loss decreased (0.669724 --> 0.668495).  Saving model ...
	 Train_Loss: 0.6708 Train_Acc: 60.094 Val_Loss: 0.6685  BEST VAL Loss: 0.6685  Val_Acc: 60.179

Epoch 12: Validation loss decreased (0.668495 --> 0.667307).  Saving model ...
	 Train_Loss: 0.6695 Train_Acc: 60.417 Val_Loss: 0.6673  BEST VAL Loss: 0.6673  Val_Acc: 60.443

Epoch 13: Validation loss decreased (0.667307 --> 0.666133).  Saving model ...
	 Train_Loss: 0.6682 Train_Acc: 60.733 Val_Loss: 0.6661  BEST VAL Loss: 0.6661  Val_Acc: 60.679

Epoch 14: Validation loss decreased (0.666133 --> 0.664953).  Saving model ...
	 Train_Loss: 0.6669 Train_Acc: 61.049 Val_Loss: 0.6650  BEST VAL Loss: 0.6650  Val_Acc: 61.014

Epoch 15: Validation loss decreased (0.664953 --> 0.663818).  Saving model ...
	 Train_Loss: 0.6657 Train_Acc: 61.142 Val_Loss: 0.6638  BEST VAL Loss: 0.6638  Val_Acc: 61.206

Epoch 16: Validation loss decreased (0.663818 --> 0.662679).  Saving model ...
	 Train_Loss: 0.6645 Train_Acc: 61.506 Val_Loss: 0.6627  BEST VAL Loss: 0.6627  Val_Acc: 61.660

Epoch 17: Validation loss decreased (0.662679 --> 0.661565).  Saving model ...
	 Train_Loss: 0.6633 Train_Acc: 61.711 Val_Loss: 0.6616  BEST VAL Loss: 0.6616  Val_Acc: 62.051

Epoch 18: Validation loss decreased (0.661565 --> 0.660476).  Saving model ...
	 Train_Loss: 0.6621 Train_Acc: 61.961 Val_Loss: 0.6605  BEST VAL Loss: 0.6605  Val_Acc: 62.378

Epoch 19: Validation loss decreased (0.660476 --> 0.659399).  Saving model ...
	 Train_Loss: 0.6610 Train_Acc: 62.200 Val_Loss: 0.6594  BEST VAL Loss: 0.6594  Val_Acc: 62.406

Epoch 20: Validation loss decreased (0.659399 --> 0.658317).  Saving model ...
	 Train_Loss: 0.6599 Train_Acc: 62.345 Val_Loss: 0.6583  BEST VAL Loss: 0.6583  Val_Acc: 62.650

Epoch 21: Validation loss decreased (0.658317 --> 0.657256).  Saving model ...
	 Train_Loss: 0.6588 Train_Acc: 62.581 Val_Loss: 0.6573  BEST VAL Loss: 0.6573  Val_Acc: 62.627

Epoch 22: Validation loss decreased (0.657256 --> 0.656214).  Saving model ...
	 Train_Loss: 0.6577 Train_Acc: 62.747 Val_Loss: 0.6562  BEST VAL Loss: 0.6562  Val_Acc: 63.104

Epoch 23: Validation loss decreased (0.656214 --> 0.655196).  Saving model ...
	 Train_Loss: 0.6566 Train_Acc: 62.995 Val_Loss: 0.6552  BEST VAL Loss: 0.6552  Val_Acc: 63.116

Epoch 24: Validation loss decreased (0.655196 --> 0.654204).  Saving model ...
	 Train_Loss: 0.6556 Train_Acc: 63.148 Val_Loss: 0.6542  BEST VAL Loss: 0.6542  Val_Acc: 63.096

Epoch 25: Validation loss decreased (0.654204 --> 0.653225).  Saving model ...
	 Train_Loss: 0.6546 Train_Acc: 63.245 Val_Loss: 0.6532  BEST VAL Loss: 0.6532  Val_Acc: 63.530

Epoch 26: Validation loss decreased (0.653225 --> 0.652254).  Saving model ...
	 Train_Loss: 0.6536 Train_Acc: 63.409 Val_Loss: 0.6523  BEST VAL Loss: 0.6523  Val_Acc: 63.464

Epoch 27: Validation loss decreased (0.652254 --> 0.651320).  Saving model ...
	 Train_Loss: 0.6527 Train_Acc: 63.482 Val_Loss: 0.6513  BEST VAL Loss: 0.6513  Val_Acc: 63.446

Epoch 28: Validation loss decreased (0.651320 --> 0.650418).  Saving model ...
	 Train_Loss: 0.6517 Train_Acc: 63.642 Val_Loss: 0.6504  BEST VAL Loss: 0.6504  Val_Acc: 63.616

Epoch 29: Validation loss decreased (0.650418 --> 0.649522).  Saving model ...
	 Train_Loss: 0.6508 Train_Acc: 63.768 Val_Loss: 0.6495  BEST VAL Loss: 0.6495  Val_Acc: 63.882

Epoch 30: Validation loss decreased (0.649522 --> 0.648674).  Saving model ...
	 Train_Loss: 0.6499 Train_Acc: 63.866 Val_Loss: 0.6487  BEST VAL Loss: 0.6487  Val_Acc: 64.073

Epoch 31: Validation loss decreased (0.648674 --> 0.647845).  Saving model ...
	 Train_Loss: 0.6491 Train_Acc: 64.031 Val_Loss: 0.6478  BEST VAL Loss: 0.6478  Val_Acc: 63.976

Epoch 32: Validation loss decreased (0.647845 --> 0.647016).  Saving model ...
	 Train_Loss: 0.6482 Train_Acc: 63.992 Val_Loss: 0.6470  BEST VAL Loss: 0.6470  Val_Acc: 64.085

Epoch 33: Validation loss decreased (0.647016 --> 0.646211).  Saving model ...
	 Train_Loss: 0.6474 Train_Acc: 64.172 Val_Loss: 0.6462  BEST VAL Loss: 0.6462  Val_Acc: 64.458

Epoch 34: Validation loss decreased (0.646211 --> 0.645412).  Saving model ...
	 Train_Loss: 0.6466 Train_Acc: 64.349 Val_Loss: 0.6454  BEST VAL Loss: 0.6454  Val_Acc: 64.329

Epoch 35: Validation loss decreased (0.645412 --> 0.644637).  Saving model ...
	 Train_Loss: 0.6458 Train_Acc: 64.411 Val_Loss: 0.6446  BEST VAL Loss: 0.6446  Val_Acc: 64.575

Epoch 36: Validation loss decreased (0.644637 --> 0.643904).  Saving model ...
	 Train_Loss: 0.6450 Train_Acc: 64.593 Val_Loss: 0.6439  BEST VAL Loss: 0.6439  Val_Acc: 64.674

Epoch 37: Validation loss decreased (0.643904 --> 0.643192).  Saving model ...
	 Train_Loss: 0.6443 Train_Acc: 64.605 Val_Loss: 0.6432  BEST VAL Loss: 0.6432  Val_Acc: 64.872

Epoch 38: Validation loss decreased (0.643192 --> 0.642511).  Saving model ...
	 Train_Loss: 0.6436 Train_Acc: 64.686 Val_Loss: 0.6425  BEST VAL Loss: 0.6425  Val_Acc: 65.014

Epoch 39: Validation loss decreased (0.642511 --> 0.641885).  Saving model ...
	 Train_Loss: 0.6428 Train_Acc: 64.737 Val_Loss: 0.6419  BEST VAL Loss: 0.6419  Val_Acc: 64.988

Epoch 40: Validation loss decreased (0.641885 --> 0.641265).  Saving model ...
	 Train_Loss: 0.6421 Train_Acc: 64.875 Val_Loss: 0.6413  BEST VAL Loss: 0.6413  Val_Acc: 65.019

Epoch 41: Validation loss decreased (0.641265 --> 0.640575).  Saving model ...
	 Train_Loss: 0.6414 Train_Acc: 64.907 Val_Loss: 0.6406  BEST VAL Loss: 0.6406  Val_Acc: 65.009

Epoch 42: Validation loss decreased (0.640575 --> 0.639884).  Saving model ...
	 Train_Loss: 0.6408 Train_Acc: 65.119 Val_Loss: 0.6399  BEST VAL Loss: 0.6399  Val_Acc: 65.214

Epoch 43: Validation loss decreased (0.639884 --> 0.639226).  Saving model ...
	 Train_Loss: 0.6401 Train_Acc: 65.184 Val_Loss: 0.6392  BEST VAL Loss: 0.6392  Val_Acc: 65.526

Epoch 44: Validation loss decreased (0.639226 --> 0.638592).  Saving model ...
	 Train_Loss: 0.6394 Train_Acc: 65.324 Val_Loss: 0.6386  BEST VAL Loss: 0.6386  Val_Acc: 65.498

Epoch 45: Validation loss decreased (0.638592 --> 0.637953).  Saving model ...
	 Train_Loss: 0.6388 Train_Acc: 65.331 Val_Loss: 0.6380  BEST VAL Loss: 0.6380  Val_Acc: 65.387

Epoch 46: Validation loss decreased (0.637953 --> 0.637339).  Saving model ...
	 Train_Loss: 0.6381 Train_Acc: 65.595 Val_Loss: 0.6373  BEST VAL Loss: 0.6373  Val_Acc: 65.709

Epoch 47: Validation loss decreased (0.637339 --> 0.636781).  Saving model ...
	 Train_Loss: 0.6375 Train_Acc: 65.673 Val_Loss: 0.6368  BEST VAL Loss: 0.6368  Val_Acc: 65.691

Epoch 48: Validation loss decreased (0.636781 --> 0.636185).  Saving model ...
	 Train_Loss: 0.6368 Train_Acc: 65.665 Val_Loss: 0.6362  BEST VAL Loss: 0.6362  Val_Acc: 65.726

Epoch 49: Validation loss decreased (0.636185 --> 0.635579).  Saving model ...
	 Train_Loss: 0.6362 Train_Acc: 65.765 Val_Loss: 0.6356  BEST VAL Loss: 0.6356  Val_Acc: 65.967

Epoch 50: Validation loss decreased (0.635579 --> 0.635027).  Saving model ...
	 Train_Loss: 0.6356 Train_Acc: 65.905 Val_Loss: 0.6350  BEST VAL Loss: 0.6350  Val_Acc: 66.005

Epoch 51: Validation loss decreased (0.635027 --> 0.634584).  Saving model ...
	 Train_Loss: 0.6350 Train_Acc: 65.979 Val_Loss: 0.6346  BEST VAL Loss: 0.6346  Val_Acc: 65.577

Epoch 52: Validation loss decreased (0.634584 --> 0.633999).  Saving model ...
	 Train_Loss: 0.6344 Train_Acc: 66.083 Val_Loss: 0.6340  BEST VAL Loss: 0.6340  Val_Acc: 66.021

Epoch 53: Validation loss decreased (0.633999 --> 0.633540).  Saving model ...
	 Train_Loss: 0.6338 Train_Acc: 66.175 Val_Loss: 0.6335  BEST VAL Loss: 0.6335  Val_Acc: 65.546

Epoch 54: Validation loss decreased (0.633540 --> 0.632979).  Saving model ...
	 Train_Loss: 0.6332 Train_Acc: 66.275 Val_Loss: 0.6330  BEST VAL Loss: 0.6330  Val_Acc: 66.003

Epoch 55: Validation loss decreased (0.632979 --> 0.632466).  Saving model ...
	 Train_Loss: 0.6326 Train_Acc: 66.310 Val_Loss: 0.6325  BEST VAL Loss: 0.6325  Val_Acc: 66.082

Epoch 56: Validation loss decreased (0.632466 --> 0.631960).  Saving model ...
	 Train_Loss: 0.6321 Train_Acc: 66.332 Val_Loss: 0.6320  BEST VAL Loss: 0.6320  Val_Acc: 66.269

Epoch 57: Validation loss decreased (0.631960 --> 0.631435).  Saving model ...
	 Train_Loss: 0.6315 Train_Acc: 66.327 Val_Loss: 0.6314  BEST VAL Loss: 0.6314  Val_Acc: 66.411

Epoch 58: Validation loss decreased (0.631435 --> 0.630957).  Saving model ...
	 Train_Loss: 0.6309 Train_Acc: 66.466 Val_Loss: 0.6310  BEST VAL Loss: 0.6310  Val_Acc: 66.246

Epoch 59: Validation loss decreased (0.630957 --> 0.630425).  Saving model ...
	 Train_Loss: 0.6304 Train_Acc: 66.640 Val_Loss: 0.6304  BEST VAL Loss: 0.6304  Val_Acc: 66.612

Epoch 60: Validation loss decreased (0.630425 --> 0.629945).  Saving model ...
	 Train_Loss: 0.6298 Train_Acc: 66.657 Val_Loss: 0.6299  BEST VAL Loss: 0.6299  Val_Acc: 66.173

Epoch 61: Validation loss decreased (0.629945 --> 0.629458).  Saving model ...
	 Train_Loss: 0.6293 Train_Acc: 66.717 Val_Loss: 0.6295  BEST VAL Loss: 0.6295  Val_Acc: 66.614

Epoch 62: Validation loss decreased (0.629458 --> 0.628957).  Saving model ...
	 Train_Loss: 0.6288 Train_Acc: 66.651 Val_Loss: 0.6290  BEST VAL Loss: 0.6290  Val_Acc: 66.835

Epoch 63: Validation loss decreased (0.628957 --> 0.628484).  Saving model ...
	 Train_Loss: 0.6282 Train_Acc: 66.843 Val_Loss: 0.6285  BEST VAL Loss: 0.6285  Val_Acc: 66.711

Epoch 64: Validation loss decreased (0.628484 --> 0.628052).  Saving model ...
	 Train_Loss: 0.6277 Train_Acc: 66.902 Val_Loss: 0.6281  BEST VAL Loss: 0.6281  Val_Acc: 66.708

Epoch 65: Validation loss decreased (0.628052 --> 0.627583).  Saving model ...
	 Train_Loss: 0.6272 Train_Acc: 66.970 Val_Loss: 0.6276  BEST VAL Loss: 0.6276  Val_Acc: 66.835

Epoch 66: Validation loss decreased (0.627583 --> 0.627133).  Saving model ...
	 Train_Loss: 0.6267 Train_Acc: 66.958 Val_Loss: 0.6271  BEST VAL Loss: 0.6271  Val_Acc: 66.969

Epoch 67: Validation loss decreased (0.627133 --> 0.626666).  Saving model ...
	 Train_Loss: 0.6262 Train_Acc: 67.019 Val_Loss: 0.6267  BEST VAL Loss: 0.6267  Val_Acc: 67.010

Epoch 68: Validation loss decreased (0.626666 --> 0.626297).  Saving model ...
	 Train_Loss: 0.6257 Train_Acc: 67.014 Val_Loss: 0.6263  BEST VAL Loss: 0.6263  Val_Acc: 66.543

Epoch 69: Validation loss decreased (0.626297 --> 0.625842).  Saving model ...
	 Train_Loss: 0.6252 Train_Acc: 67.106 Val_Loss: 0.6258  BEST VAL Loss: 0.6258  Val_Acc: 67.291

Epoch 70: Validation loss decreased (0.625842 --> 0.625456).  Saving model ...
	 Train_Loss: 0.6247 Train_Acc: 67.112 Val_Loss: 0.6255  BEST VAL Loss: 0.6255  Val_Acc: 66.967

Epoch 71: Validation loss decreased (0.625456 --> 0.625022).  Saving model ...
	 Train_Loss: 0.6243 Train_Acc: 67.114 Val_Loss: 0.6250  BEST VAL Loss: 0.6250  Val_Acc: 67.172

Epoch 72: Validation loss decreased (0.625022 --> 0.624601).  Saving model ...
	 Train_Loss: 0.6238 Train_Acc: 67.263 Val_Loss: 0.6246  BEST VAL Loss: 0.6246  Val_Acc: 66.952

Epoch 73: Validation loss decreased (0.624601 --> 0.624213).  Saving model ...
	 Train_Loss: 0.6233 Train_Acc: 67.248 Val_Loss: 0.6242  BEST VAL Loss: 0.6242  Val_Acc: 67.279

Epoch 74: Validation loss decreased (0.624213 --> 0.623830).  Saving model ...
	 Train_Loss: 0.6229 Train_Acc: 67.184 Val_Loss: 0.6238  BEST VAL Loss: 0.6238  Val_Acc: 66.997

Epoch 75: Validation loss decreased (0.623830 --> 0.623402).  Saving model ...
	 Train_Loss: 0.6224 Train_Acc: 67.326 Val_Loss: 0.6234  BEST VAL Loss: 0.6234  Val_Acc: 67.241

Epoch 76: Validation loss decreased (0.623402 --> 0.623005).  Saving model ...
	 Train_Loss: 0.6220 Train_Acc: 67.301 Val_Loss: 0.6230  BEST VAL Loss: 0.6230  Val_Acc: 67.190

Epoch 77: Validation loss decreased (0.623005 --> 0.622601).  Saving model ...
	 Train_Loss: 0.6216 Train_Acc: 67.222 Val_Loss: 0.6226  BEST VAL Loss: 0.6226  Val_Acc: 67.418

Epoch 78: Validation loss decreased (0.622601 --> 0.622203).  Saving model ...
	 Train_Loss: 0.6211 Train_Acc: 67.500 Val_Loss: 0.6222  BEST VAL Loss: 0.6222  Val_Acc: 67.530

Epoch 79: Validation loss decreased (0.622203 --> 0.621810).  Saving model ...
	 Train_Loss: 0.6207 Train_Acc: 67.412 Val_Loss: 0.6218  BEST VAL Loss: 0.6218  Val_Acc: 67.385

Epoch 80: Validation loss decreased (0.621810 --> 0.621410).  Saving model ...
	 Train_Loss: 0.6203 Train_Acc: 67.492 Val_Loss: 0.6214  BEST VAL Loss: 0.6214  Val_Acc: 67.357

Epoch 81: Validation loss decreased (0.621410 --> 0.621053).  Saving model ...
	 Train_Loss: 0.6199 Train_Acc: 67.466 Val_Loss: 0.6211  BEST VAL Loss: 0.6211  Val_Acc: 67.243

Epoch 82: Validation loss decreased (0.621053 --> 0.620762).  Saving model ...
	 Train_Loss: 0.6194 Train_Acc: 67.489 Val_Loss: 0.6208  BEST VAL Loss: 0.6208  Val_Acc: 66.919

Epoch 83: Validation loss decreased (0.620762 --> 0.620426).  Saving model ...
	 Train_Loss: 0.6190 Train_Acc: 67.555 Val_Loss: 0.6204  BEST VAL Loss: 0.6204  Val_Acc: 67.357

Epoch 84: Validation loss decreased (0.620426 --> 0.620059).  Saving model ...
	 Train_Loss: 0.6186 Train_Acc: 67.463 Val_Loss: 0.6201  BEST VAL Loss: 0.6201  Val_Acc: 67.515

Epoch 85: Validation loss decreased (0.620059 --> 0.619715).  Saving model ...
	 Train_Loss: 0.6183 Train_Acc: 67.528 Val_Loss: 0.6197  BEST VAL Loss: 0.6197  Val_Acc: 67.510

Epoch 86: Validation loss decreased (0.619715 --> 0.619376).  Saving model ...
	 Train_Loss: 0.6179 Train_Acc: 67.577 Val_Loss: 0.6194  BEST VAL Loss: 0.6194  Val_Acc: 67.510

Epoch 87: Validation loss decreased (0.619376 --> 0.619065).  Saving model ...
	 Train_Loss: 0.6175 Train_Acc: 67.605 Val_Loss: 0.6191  BEST VAL Loss: 0.6191  Val_Acc: 67.403

Epoch 88: Validation loss decreased (0.619065 --> 0.618762).  Saving model ...
	 Train_Loss: 0.6171 Train_Acc: 67.738 Val_Loss: 0.6188  BEST VAL Loss: 0.6188  Val_Acc: 67.337

Epoch 89: Validation loss decreased (0.618762 --> 0.618498).  Saving model ...
	 Train_Loss: 0.6167 Train_Acc: 67.640 Val_Loss: 0.6185  BEST VAL Loss: 0.6185  Val_Acc: 66.949

Epoch 90: Validation loss decreased (0.618498 --> 0.618200).  Saving model ...
	 Train_Loss: 0.6163 Train_Acc: 67.668 Val_Loss: 0.6182  BEST VAL Loss: 0.6182  Val_Acc: 67.512

Epoch 91: Validation loss decreased (0.618200 --> 0.617874).  Saving model ...
	 Train_Loss: 0.6160 Train_Acc: 67.702 Val_Loss: 0.6179  BEST VAL Loss: 0.6179  Val_Acc: 67.581

Epoch 92: Validation loss decreased (0.617874 --> 0.617553).  Saving model ...
	 Train_Loss: 0.6156 Train_Acc: 67.712 Val_Loss: 0.6176  BEST VAL Loss: 0.6176  Val_Acc: 67.360

Epoch 93: Validation loss decreased (0.617553 --> 0.617234).  Saving model ...
	 Train_Loss: 0.6153 Train_Acc: 67.794 Val_Loss: 0.6172  BEST VAL Loss: 0.6172  Val_Acc: 67.728

Epoch 94: Validation loss decreased (0.617234 --> 0.616905).  Saving model ...
	 Train_Loss: 0.6149 Train_Acc: 67.835 Val_Loss: 0.6169  BEST VAL Loss: 0.6169  Val_Acc: 67.591

Epoch 95: Validation loss decreased (0.616905 --> 0.616603).  Saving model ...
	 Train_Loss: 0.6146 Train_Acc: 67.860 Val_Loss: 0.6166  BEST VAL Loss: 0.6166  Val_Acc: 67.667

Epoch 96: Validation loss decreased (0.616603 --> 0.616333).  Saving model ...
	 Train_Loss: 0.6142 Train_Acc: 67.833 Val_Loss: 0.6163  BEST VAL Loss: 0.6163  Val_Acc: 67.352

Epoch 97: Validation loss decreased (0.616333 --> 0.616021).  Saving model ...
	 Train_Loss: 0.6139 Train_Acc: 67.832 Val_Loss: 0.6160  BEST VAL Loss: 0.6160  Val_Acc: 67.740

Epoch 98: Validation loss decreased (0.616021 --> 0.615725).  Saving model ...
	 Train_Loss: 0.6135 Train_Acc: 67.863 Val_Loss: 0.6157  BEST VAL Loss: 0.6157  Val_Acc: 67.611

Epoch 99: Validation loss decreased (0.615725 --> 0.615419).  Saving model ...
	 Train_Loss: 0.6132 Train_Acc: 67.952 Val_Loss: 0.6154  BEST VAL Loss: 0.6154  Val_Acc: 67.707

DMSO_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.67      0.77      0.71    149884
           1       0.76      0.65      0.70    165500

    accuracy                           0.71    315384
   macro avg       0.71      0.71      0.71    315384
weighted avg       0.71      0.71      0.71    315384

DMSO_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.64      0.74      0.68     18736
           1       0.72      0.62      0.67     20688

    accuracy                           0.68     39424
   macro avg       0.68      0.68      0.68     39424
weighted avg       0.68      0.68      0.68     39424

DMSO_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.64      0.74      0.69     18736
           1       0.73      0.63      0.67     20688

    accuracy                           0.68     39424
   macro avg       0.69      0.68      0.68     39424
weighted avg       0.69      0.68      0.68     39424

              precision    recall  f1-score   support

           0       0.64      0.74      0.69     18736
           1       0.73      0.63      0.67     20688

    accuracy                           0.68     39424
   macro avg       0.69      0.68      0.68     39424
weighted avg       0.69      0.68      0.68     39424

DMSO_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.51      0.67      0.58     27774
           1       0.63      0.47      0.54     33660

    accuracy                           0.56     61434
   macro avg       0.57      0.57      0.56     61434
weighted avg       0.58      0.56      0.56     61434

              precision    recall  f1-score   support

           0       0.51      0.67      0.58     27774
           1       0.63      0.47      0.54     33660

    accuracy                           0.56     61434
   macro avg       0.57      0.57      0.56     61434
weighted avg       0.58      0.56      0.56     61434

completed
