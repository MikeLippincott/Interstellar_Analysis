[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '5d208c34'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '11292fad'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'a5682ac5'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'b6d3c339'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Flagellin_0.100_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_Nigericin_1.000_3.0_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (270176, 1270)
Number of total missing values across all columns: 191830
Data Subset Is Off
Wells held out for testing: ['L08' 'L10']
Wells to use for training, validation, and testing ['L02' 'L03' 'L05' 'L09' 'L11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.080457).  Saving model ...
	 Train_Loss: 0.2851 Train_Acc: 87.536 Val_Loss: 0.0805  BEST VAL Loss: 0.0805  Val_Acc: 97.296

Epoch 1: Validation loss decreased (0.080457 --> 0.073440).  Saving model ...
	 Train_Loss: 0.2319 Train_Acc: 93.851 Val_Loss: 0.0734  BEST VAL Loss: 0.0734  Val_Acc: 97.920

Epoch 2: Validation loss decreased (0.073440 --> 0.068074).  Saving model ...
	 Train_Loss: 0.2081 Train_Acc: 94.327 Val_Loss: 0.0681  BEST VAL Loss: 0.0681  Val_Acc: 97.968

Epoch 3: Validation loss decreased (0.068074 --> 0.062818).  Saving model ...
	 Train_Loss: 0.1936 Train_Acc: 94.449 Val_Loss: 0.0628  BEST VAL Loss: 0.0628  Val_Acc: 98.467

Epoch 4: Validation loss decreased (0.062818 --> 0.060646).  Saving model ...
	 Train_Loss: 0.1838 Train_Acc: 94.444 Val_Loss: 0.0606  BEST VAL Loss: 0.0606  Val_Acc: 98.278

Epoch 5: Validation loss decreased (0.060646 --> 0.058592).  Saving model ...
	 Train_Loss: 0.1762 Train_Acc: 94.558 Val_Loss: 0.0586  BEST VAL Loss: 0.0586  Val_Acc: 98.173

Epoch 6: Validation loss decreased (0.058592 --> 0.057049).  Saving model ...
	 Train_Loss: 0.1706 Train_Acc: 94.589 Val_Loss: 0.0570  BEST VAL Loss: 0.0570  Val_Acc: 98.246

Epoch 7: Validation loss decreased (0.057049 --> 0.055471).  Saving model ...
	 Train_Loss: 0.1658 Train_Acc: 94.875 Val_Loss: 0.0555  BEST VAL Loss: 0.0555  Val_Acc: 98.409

Epoch 8: Validation loss decreased (0.055471 --> 0.054841).  Saving model ...
	 Train_Loss: 0.1619 Train_Acc: 94.890 Val_Loss: 0.0548  BEST VAL Loss: 0.0548  Val_Acc: 97.926

Epoch 9: Validation loss decreased (0.054841 --> 0.053498).  Saving model ...
	 Train_Loss: 0.1588 Train_Acc: 94.879 Val_Loss: 0.0535  BEST VAL Loss: 0.0535  Val_Acc: 98.435

Epoch 10: Validation loss decreased (0.053498 --> 0.052482).  Saving model ...
	 Train_Loss: 0.1558 Train_Acc: 95.028 Val_Loss: 0.0525  BEST VAL Loss: 0.0525  Val_Acc: 98.409

Epoch 11: Validation loss decreased (0.052482 --> 0.051916).  Saving model ...
	 Train_Loss: 0.1536 Train_Acc: 94.938 Val_Loss: 0.0519  BEST VAL Loss: 0.0519  Val_Acc: 98.251

Epoch 12: Validation loss decreased (0.051916 --> 0.051005).  Saving model ...
	 Train_Loss: 0.1515 Train_Acc: 94.963 Val_Loss: 0.0510  BEST VAL Loss: 0.0510  Val_Acc: 98.614

Epoch 13: Validation loss decreased (0.051005 --> 0.050171).  Saving model ...
	 Train_Loss: 0.1496 Train_Acc: 95.045 Val_Loss: 0.0502  BEST VAL Loss: 0.0502  Val_Acc: 98.619

Epoch 14: Validation loss decreased (0.050171 --> 0.049560).  Saving model ...
	 Train_Loss: 0.1479 Train_Acc: 95.084 Val_Loss: 0.0496  BEST VAL Loss: 0.0496  Val_Acc: 98.619

Epoch 15: Validation loss decreased (0.049560 --> 0.048895).  Saving model ...
	 Train_Loss: 0.1462 Train_Acc: 95.085 Val_Loss: 0.0489  BEST VAL Loss: 0.0489  Val_Acc: 98.572

Epoch 16: Validation loss decreased (0.048895 --> 0.048124).  Saving model ...
	 Train_Loss: 0.1448 Train_Acc: 95.084 Val_Loss: 0.0481  BEST VAL Loss: 0.0481  Val_Acc: 98.703

Epoch 17: Validation loss decreased (0.048124 --> 0.047640).  Saving model ...
	 Train_Loss: 0.1435 Train_Acc: 95.061 Val_Loss: 0.0476  BEST VAL Loss: 0.0476  Val_Acc: 98.624

Epoch 18: Validation loss decreased (0.047640 --> 0.047221).  Saving model ...
	 Train_Loss: 0.1422 Train_Acc: 95.288 Val_Loss: 0.0472  BEST VAL Loss: 0.0472  Val_Acc: 98.519

Epoch 19: Validation loss decreased (0.047221 --> 0.046729).  Saving model ...
	 Train_Loss: 0.1411 Train_Acc: 95.111 Val_Loss: 0.0467  BEST VAL Loss: 0.0467  Val_Acc: 98.661

Epoch 20: Validation loss decreased (0.046729 --> 0.046365).  Saving model ...
	 Train_Loss: 0.1402 Train_Acc: 95.151 Val_Loss: 0.0464  BEST VAL Loss: 0.0464  Val_Acc: 98.661

Epoch 21: Validation loss decreased (0.046365 --> 0.045993).  Saving model ...
	 Train_Loss: 0.1392 Train_Acc: 95.152 Val_Loss: 0.0460  BEST VAL Loss: 0.0460  Val_Acc: 98.582

Epoch 22: Validation loss decreased (0.045993 --> 0.045651).  Saving model ...
	 Train_Loss: 0.1382 Train_Acc: 95.235 Val_Loss: 0.0457  BEST VAL Loss: 0.0457  Val_Acc: 98.677

Epoch 23: Validation loss decreased (0.045651 --> 0.045315).  Saving model ...
	 Train_Loss: 0.1374 Train_Acc: 95.051 Val_Loss: 0.0453  BEST VAL Loss: 0.0453  Val_Acc: 98.629

Epoch 24: Validation loss decreased (0.045315 --> 0.044996).  Saving model ...
	 Train_Loss: 0.1368 Train_Acc: 95.111 Val_Loss: 0.0450  BEST VAL Loss: 0.0450  Val_Acc: 98.713

Epoch 25: Validation loss decreased (0.044996 --> 0.044838).  Saving model ...
	 Train_Loss: 0.1360 Train_Acc: 95.133 Val_Loss: 0.0448  BEST VAL Loss: 0.0448  Val_Acc: 98.713

Epoch 26: Validation loss decreased (0.044838 --> 0.044507).  Saving model ...
	 Train_Loss: 0.1353 Train_Acc: 95.349 Val_Loss: 0.0445  BEST VAL Loss: 0.0445  Val_Acc: 98.724

Epoch 27: Validation loss decreased (0.044507 --> 0.044090).  Saving model ...
	 Train_Loss: 0.1345 Train_Acc: 95.296 Val_Loss: 0.0441  BEST VAL Loss: 0.0441  Val_Acc: 98.792

Epoch 28: Validation loss decreased (0.044090 --> 0.043776).  Saving model ...
	 Train_Loss: 0.1339 Train_Acc: 95.320 Val_Loss: 0.0438  BEST VAL Loss: 0.0438  Val_Acc: 98.719

Epoch 29: Validation loss decreased (0.043776 --> 0.043463).  Saving model ...
	 Train_Loss: 0.1332 Train_Acc: 95.303 Val_Loss: 0.0435  BEST VAL Loss: 0.0435  Val_Acc: 98.850

Epoch 30: Validation loss decreased (0.043463 --> 0.043165).  Saving model ...
	 Train_Loss: 0.1325 Train_Acc: 95.412 Val_Loss: 0.0432  BEST VAL Loss: 0.0432  Val_Acc: 98.750

Epoch 31: Validation loss decreased (0.043165 --> 0.042889).  Saving model ...
	 Train_Loss: 0.1319 Train_Acc: 95.401 Val_Loss: 0.0429  BEST VAL Loss: 0.0429  Val_Acc: 98.876

Epoch 32: Validation loss decreased (0.042889 --> 0.042596).  Saving model ...
	 Train_Loss: 0.1313 Train_Acc: 95.442 Val_Loss: 0.0426  BEST VAL Loss: 0.0426  Val_Acc: 98.866

Epoch 33: Validation loss decreased (0.042596 --> 0.042312).  Saving model ...
	 Train_Loss: 0.1308 Train_Acc: 95.285 Val_Loss: 0.0423  BEST VAL Loss: 0.0423  Val_Acc: 98.740

Epoch 34: Validation loss decreased (0.042312 --> 0.042012).  Saving model ...
	 Train_Loss: 0.1303 Train_Acc: 95.406 Val_Loss: 0.0420  BEST VAL Loss: 0.0420  Val_Acc: 98.860

Epoch 35: Validation loss decreased (0.042012 --> 0.041861).  Saving model ...
	 Train_Loss: 0.1298 Train_Acc: 95.404 Val_Loss: 0.0419  BEST VAL Loss: 0.0419  Val_Acc: 98.734

Epoch 36: Validation loss decreased (0.041861 --> 0.041668).  Saving model ...
	 Train_Loss: 0.1293 Train_Acc: 95.416 Val_Loss: 0.0417  BEST VAL Loss: 0.0417  Val_Acc: 98.771

Epoch 37: Validation loss decreased (0.041668 --> 0.041546).  Saving model ...
	 Train_Loss: 0.1288 Train_Acc: 95.347 Val_Loss: 0.0415  BEST VAL Loss: 0.0415  Val_Acc: 98.803

Epoch 38: Validation loss decreased (0.041546 --> 0.041312).  Saving model ...
	 Train_Loss: 0.1284 Train_Acc: 95.350 Val_Loss: 0.0413  BEST VAL Loss: 0.0413  Val_Acc: 98.818

Epoch 39: Validation loss decreased (0.041312 --> 0.041114).  Saving model ...
	 Train_Loss: 0.1280 Train_Acc: 95.391 Val_Loss: 0.0411  BEST VAL Loss: 0.0411  Val_Acc: 98.740

Epoch 40: Validation loss decreased (0.041114 --> 0.040915).  Saving model ...
	 Train_Loss: 0.1276 Train_Acc: 95.393 Val_Loss: 0.0409  BEST VAL Loss: 0.0409  Val_Acc: 98.750

Epoch 41: Validation loss decreased (0.040915 --> 0.040811).  Saving model ...
	 Train_Loss: 0.1271 Train_Acc: 95.424 Val_Loss: 0.0408  BEST VAL Loss: 0.0408  Val_Acc: 98.818

Epoch 42: Validation loss decreased (0.040811 --> 0.040680).  Saving model ...
	 Train_Loss: 0.1269 Train_Acc: 95.241 Val_Loss: 0.0407  BEST VAL Loss: 0.0407  Val_Acc: 98.834

Epoch 43: Validation loss decreased (0.040680 --> 0.040556).  Saving model ...
	 Train_Loss: 0.1265 Train_Acc: 95.484 Val_Loss: 0.0406  BEST VAL Loss: 0.0406  Val_Acc: 98.845

Epoch 44: Validation loss decreased (0.040556 --> 0.040370).  Saving model ...
	 Train_Loss: 0.1262 Train_Acc: 95.378 Val_Loss: 0.0404  BEST VAL Loss: 0.0404  Val_Acc: 98.887

Epoch 45: Validation loss decreased (0.040370 --> 0.040262).  Saving model ...
	 Train_Loss: 0.1259 Train_Acc: 95.581 Val_Loss: 0.0403  BEST VAL Loss: 0.0403  Val_Acc: 98.619

Epoch 46: Validation loss decreased (0.040262 --> 0.040156).  Saving model ...
	 Train_Loss: 0.1256 Train_Acc: 95.399 Val_Loss: 0.0402  BEST VAL Loss: 0.0402  Val_Acc: 98.766

Epoch 47: Validation loss decreased (0.040156 --> 0.040006).  Saving model ...
	 Train_Loss: 0.1252 Train_Acc: 95.474 Val_Loss: 0.0400  BEST VAL Loss: 0.0400  Val_Acc: 98.713

Epoch 48: Validation loss decreased (0.040006 --> 0.039915).  Saving model ...
	 Train_Loss: 0.1250 Train_Acc: 95.334 Val_Loss: 0.0399  BEST VAL Loss: 0.0399  Val_Acc: 98.750

Epoch 49: Validation loss decreased (0.039915 --> 0.039800).  Saving model ...
	 Train_Loss: 0.1247 Train_Acc: 95.390 Val_Loss: 0.0398  BEST VAL Loss: 0.0398  Val_Acc: 98.745

Epoch 50: Validation loss decreased (0.039800 --> 0.039658).  Saving model ...
	 Train_Loss: 0.1244 Train_Acc: 95.357 Val_Loss: 0.0397  BEST VAL Loss: 0.0397  Val_Acc: 98.881

Epoch 51: Validation loss decreased (0.039658 --> 0.039564).  Saving model ...
	 Train_Loss: 0.1242 Train_Acc: 95.483 Val_Loss: 0.0396  BEST VAL Loss: 0.0396  Val_Acc: 98.803

Epoch 52: Validation loss decreased (0.039564 --> 0.039514).  Saving model ...
	 Train_Loss: 0.1239 Train_Acc: 95.472 Val_Loss: 0.0395  BEST VAL Loss: 0.0395  Val_Acc: 98.566

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.1236 Train_Acc: 95.475 Val_Loss: 0.0396  BEST VAL Loss: 0.0395  Val_Acc: 98.692

Epoch 54: Validation loss decreased (0.039514 --> 0.039464).  Saving model ...
	 Train_Loss: 0.1234 Train_Acc: 95.415 Val_Loss: 0.0395  BEST VAL Loss: 0.0395  Val_Acc: 98.881

Epoch 55: Validation loss decreased (0.039464 --> 0.039311).  Saving model ...
	 Train_Loss: 0.1232 Train_Acc: 95.416 Val_Loss: 0.0393  BEST VAL Loss: 0.0393  Val_Acc: 98.866

Epoch 56: Validation loss decreased (0.039311 --> 0.039206).  Saving model ...
	 Train_Loss: 0.1229 Train_Acc: 95.566 Val_Loss: 0.0392  BEST VAL Loss: 0.0392  Val_Acc: 98.782

Epoch 57: Validation loss decreased (0.039206 --> 0.039083).  Saving model ...
	 Train_Loss: 0.1226 Train_Acc: 95.608 Val_Loss: 0.0391  BEST VAL Loss: 0.0391  Val_Acc: 98.850

Epoch 58: Validation loss decreased (0.039083 --> 0.038985).  Saving model ...
	 Train_Loss: 0.1224 Train_Acc: 95.428 Val_Loss: 0.0390  BEST VAL Loss: 0.0390  Val_Acc: 98.850

Epoch 59: Validation loss decreased (0.038985 --> 0.038898).  Saving model ...
	 Train_Loss: 0.1222 Train_Acc: 95.404 Val_Loss: 0.0389  BEST VAL Loss: 0.0389  Val_Acc: 98.797

Epoch 60: Validation loss decreased (0.038898 --> 0.038789).  Saving model ...
	 Train_Loss: 0.1220 Train_Acc: 95.494 Val_Loss: 0.0388  BEST VAL Loss: 0.0388  Val_Acc: 98.850

Epoch 61: Validation loss decreased (0.038789 --> 0.038726).  Saving model ...
	 Train_Loss: 0.1217 Train_Acc: 95.471 Val_Loss: 0.0387  BEST VAL Loss: 0.0387  Val_Acc: 98.771

Epoch 62: Validation loss decreased (0.038726 --> 0.038642).  Saving model ...
	 Train_Loss: 0.1215 Train_Acc: 95.476 Val_Loss: 0.0386  BEST VAL Loss: 0.0386  Val_Acc: 98.892

Epoch 63: Validation loss decreased (0.038642 --> 0.038567).  Saving model ...
	 Train_Loss: 0.1214 Train_Acc: 95.305 Val_Loss: 0.0386  BEST VAL Loss: 0.0386  Val_Acc: 98.818

Epoch 64: Validation loss decreased (0.038567 --> 0.038479).  Saving model ...
	 Train_Loss: 0.1211 Train_Acc: 95.589 Val_Loss: 0.0385  BEST VAL Loss: 0.0385  Val_Acc: 98.734

Epoch 65: Validation loss decreased (0.038479 --> 0.038415).  Saving model ...
	 Train_Loss: 0.1209 Train_Acc: 95.563 Val_Loss: 0.0384  BEST VAL Loss: 0.0384  Val_Acc: 98.855

Epoch 66: Validation loss decreased (0.038415 --> 0.038351).  Saving model ...
	 Train_Loss: 0.1208 Train_Acc: 95.445 Val_Loss: 0.0384  BEST VAL Loss: 0.0384  Val_Acc: 98.792

Epoch 67: Validation loss decreased (0.038351 --> 0.038264).  Saving model ...
	 Train_Loss: 0.1206 Train_Acc: 95.375 Val_Loss: 0.0383  BEST VAL Loss: 0.0383  Val_Acc: 98.829

Epoch 68: Validation loss decreased (0.038264 --> 0.038211).  Saving model ...
	 Train_Loss: 0.1204 Train_Acc: 95.542 Val_Loss: 0.0382  BEST VAL Loss: 0.0382  Val_Acc: 98.824

Epoch 69: Validation loss decreased (0.038211 --> 0.038148).  Saving model ...
	 Train_Loss: 0.1202 Train_Acc: 95.494 Val_Loss: 0.0381  BEST VAL Loss: 0.0381  Val_Acc: 98.824

Epoch 70: Validation loss decreased (0.038148 --> 0.038076).  Saving model ...
	 Train_Loss: 0.1200 Train_Acc: 95.432 Val_Loss: 0.0381  BEST VAL Loss: 0.0381  Val_Acc: 98.787

Epoch 71: Validation loss decreased (0.038076 --> 0.038011).  Saving model ...
	 Train_Loss: 0.1198 Train_Acc: 95.466 Val_Loss: 0.0380  BEST VAL Loss: 0.0380  Val_Acc: 98.850

Epoch 72: Validation loss decreased (0.038011 --> 0.037968).  Saving model ...
	 Train_Loss: 0.1197 Train_Acc: 95.529 Val_Loss: 0.0380  BEST VAL Loss: 0.0380  Val_Acc: 98.824

Epoch 73: Validation loss decreased (0.037968 --> 0.037943).  Saving model ...
	 Train_Loss: 0.1195 Train_Acc: 95.434 Val_Loss: 0.0379  BEST VAL Loss: 0.0379  Val_Acc: 98.839

Epoch 74: Validation loss decreased (0.037943 --> 0.037848).  Saving model ...
	 Train_Loss: 0.1194 Train_Acc: 95.554 Val_Loss: 0.0378  BEST VAL Loss: 0.0378  Val_Acc: 98.887

Epoch 75: Validation loss decreased (0.037848 --> 0.037776).  Saving model ...
	 Train_Loss: 0.1192 Train_Acc: 95.600 Val_Loss: 0.0378  BEST VAL Loss: 0.0378  Val_Acc: 98.797

Epoch 76: Validation loss decreased (0.037776 --> 0.037720).  Saving model ...
	 Train_Loss: 0.1190 Train_Acc: 95.624 Val_Loss: 0.0377  BEST VAL Loss: 0.0377  Val_Acc: 98.818

Epoch 77: Validation loss decreased (0.037720 --> 0.037668).  Saving model ...
	 Train_Loss: 0.1188 Train_Acc: 95.661 Val_Loss: 0.0377  BEST VAL Loss: 0.0377  Val_Acc: 98.782

Epoch 78: Validation loss decreased (0.037668 --> 0.037606).  Saving model ...
	 Train_Loss: 0.1186 Train_Acc: 95.628 Val_Loss: 0.0376  BEST VAL Loss: 0.0376  Val_Acc: 98.755

Epoch 79: Validation loss decreased (0.037606 --> 0.037521).  Saving model ...
	 Train_Loss: 0.1184 Train_Acc: 95.619 Val_Loss: 0.0375  BEST VAL Loss: 0.0375  Val_Acc: 98.766

Epoch 80: Validation loss decreased (0.037521 --> 0.037463).  Saving model ...
	 Train_Loss: 0.1183 Train_Acc: 95.504 Val_Loss: 0.0375  BEST VAL Loss: 0.0375  Val_Acc: 98.771

Epoch 81: Validation loss decreased (0.037463 --> 0.037394).  Saving model ...
	 Train_Loss: 0.1181 Train_Acc: 95.602 Val_Loss: 0.0374  BEST VAL Loss: 0.0374  Val_Acc: 98.729

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.1180 Train_Acc: 95.515 Val_Loss: 0.0374  BEST VAL Loss: 0.0374  Val_Acc: 98.866

Epoch 83: Validation loss decreased (0.037394 --> 0.037350).  Saving model ...
	 Train_Loss: 0.1179 Train_Acc: 95.596 Val_Loss: 0.0373  BEST VAL Loss: 0.0373  Val_Acc: 98.745

Epoch 84: Validation loss decreased (0.037350 --> 0.037327).  Saving model ...
	 Train_Loss: 0.1177 Train_Acc: 95.441 Val_Loss: 0.0373  BEST VAL Loss: 0.0373  Val_Acc: 98.845

Epoch 85: Validation loss decreased (0.037327 --> 0.037264).  Saving model ...
	 Train_Loss: 0.1176 Train_Acc: 95.422 Val_Loss: 0.0373  BEST VAL Loss: 0.0373  Val_Acc: 98.944

Epoch 86: Validation loss decreased (0.037264 --> 0.037188).  Saving model ...
	 Train_Loss: 0.1175 Train_Acc: 95.523 Val_Loss: 0.0372  BEST VAL Loss: 0.0372  Val_Acc: 98.834

Epoch 87: Validation loss decreased (0.037188 --> 0.037110).  Saving model ...
	 Train_Loss: 0.1174 Train_Acc: 95.515 Val_Loss: 0.0371  BEST VAL Loss: 0.0371  Val_Acc: 98.976

Epoch 88: Validation loss decreased (0.037110 --> 0.037044).  Saving model ...
	 Train_Loss: 0.1172 Train_Acc: 95.622 Val_Loss: 0.0370  BEST VAL Loss: 0.0370  Val_Acc: 98.792

Epoch 89: Validation loss decreased (0.037044 --> 0.037019).  Saving model ...
	 Train_Loss: 0.1170 Train_Acc: 95.588 Val_Loss: 0.0370  BEST VAL Loss: 0.0370  Val_Acc: 98.766

Epoch 90: Validation loss decreased (0.037019 --> 0.036964).  Saving model ...
	 Train_Loss: 0.1169 Train_Acc: 95.578 Val_Loss: 0.0370  BEST VAL Loss: 0.0370  Val_Acc: 98.866

Epoch 91: Validation loss decreased (0.036964 --> 0.036902).  Saving model ...
	 Train_Loss: 0.1167 Train_Acc: 95.633 Val_Loss: 0.0369  BEST VAL Loss: 0.0369  Val_Acc: 98.892

Epoch 92: Validation loss decreased (0.036902 --> 0.036865).  Saving model ...
	 Train_Loss: 0.1166 Train_Acc: 95.584 Val_Loss: 0.0369  BEST VAL Loss: 0.0369  Val_Acc: 98.902

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.1165 Train_Acc: 95.716 Val_Loss: 0.0370  BEST VAL Loss: 0.0369  Val_Acc: 98.766

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.1164 Train_Acc: 95.649 Val_Loss: 0.0370  BEST VAL Loss: 0.0369  Val_Acc: 98.918

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.1162 Train_Acc: 95.660 Val_Loss: 0.0369  BEST VAL Loss: 0.0369  Val_Acc: 98.845

Epoch 96: Validation loss decreased (0.036865 --> 0.036864).  Saving model ...
	 Train_Loss: 0.1161 Train_Acc: 95.604 Val_Loss: 0.0369  BEST VAL Loss: 0.0369  Val_Acc: 98.755

Epoch 97: Validation loss did not decrease
	 Train_Loss: 0.1161 Train_Acc: 95.412 Val_Loss: 0.0369  BEST VAL Loss: 0.0369  Val_Acc: 98.766

Epoch 98: Validation loss decreased (0.036864 --> 0.036832).  Saving model ...
	 Train_Loss: 0.1160 Train_Acc: 95.618 Val_Loss: 0.0368  BEST VAL Loss: 0.0368  Val_Acc: 98.892

Epoch 99: Validation loss decreased (0.036832 --> 0.036787).  Saving model ...
	 Train_Loss: 0.1158 Train_Acc: 95.571 Val_Loss: 0.0368  BEST VAL Loss: 0.0368  Val_Acc: 98.818

Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.99      0.99     50422
           1       1.00      0.99      0.99    101922

    accuracy                           0.99    152344
   macro avg       0.99      0.99      0.99    152344
weighted avg       0.99      0.99      0.99    152344

Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.99      0.98      6303
           1       0.99      0.99      0.99     12740

    accuracy                           0.99     19043
   macro avg       0.99      0.99      0.99     19043
weighted avg       0.99      0.99      0.99     19043

Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.99      0.98      6303
           1       0.99      0.99      0.99     12740

    accuracy                           0.99     19043
   macro avg       0.99      0.99      0.99     19043
weighted avg       0.99      0.99      0.99     19043

              precision    recall  f1-score   support

           0       0.98      0.99      0.98      6303
           1       0.99      0.99      0.99     12740

    accuracy                           0.99     19043
   macro avg       0.99      0.99      0.99     19043
weighted avg       0.99      0.99      0.99     19043

Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.81      0.98      0.89     32887
           1       0.99      0.84      0.90     46859

    accuracy                           0.90     79746
   macro avg       0.90      0.91      0.90     79746
weighted avg       0.91      0.90      0.90     79746

              precision    recall  f1-score   support

           0       0.81      0.98      0.89     32887
           1       0.99      0.84      0.90     46859

    accuracy                           0.90     79746
   macro avg       0.90      0.91      0.90     79746
weighted avg       0.91      0.90      0.90     79746

completed
