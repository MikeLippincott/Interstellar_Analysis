[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '93d34804'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '8a1e8c57'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'fb32fcff'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '72c1b8f7'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (29511, 1276)
Number of total missing values across all columns: 31718
Data Subset Is Off
Wells held out for testing: ['B20' 'L16']
Wells to use for training, validation, and testing ['B16' 'B17' 'B21' 'L17' 'L20' 'L21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.247765).  Saving model ...
	 Train_Loss: 0.4440 Train_Acc: 74.850 Val_Loss: 0.2478  BEST VAL Loss: 0.2478  Val_Acc: 91.704

Epoch 1: Validation loss decreased (0.247765 --> 0.205326).  Saving model ...
	 Train_Loss: 0.3649 Train_Acc: 85.022 Val_Loss: 0.2053  BEST VAL Loss: 0.2053  Val_Acc: 94.696

Epoch 2: Validation loss decreased (0.205326 --> 0.193146).  Saving model ...
	 Train_Loss: 0.3189 Train_Acc: 90.151 Val_Loss: 0.1931  BEST VAL Loss: 0.1931  Val_Acc: 95.104

Epoch 3: Validation loss decreased (0.193146 --> 0.174051).  Saving model ...
	 Train_Loss: 0.2890 Train_Acc: 92.163 Val_Loss: 0.1741  BEST VAL Loss: 0.1741  Val_Acc: 95.920

Epoch 4: Validation loss decreased (0.174051 --> 0.163332).  Saving model ...
	 Train_Loss: 0.2685 Train_Acc: 92.338 Val_Loss: 0.1633  BEST VAL Loss: 0.1633  Val_Acc: 95.603

Epoch 5: Validation loss decreased (0.163332 --> 0.155811).  Saving model ...
	 Train_Loss: 0.2515 Train_Acc: 93.370 Val_Loss: 0.1558  BEST VAL Loss: 0.1558  Val_Acc: 95.648

Epoch 6: Validation loss decreased (0.155811 --> 0.152156).  Saving model ...
	 Train_Loss: 0.2400 Train_Acc: 93.693 Val_Loss: 0.1522  BEST VAL Loss: 0.1522  Val_Acc: 95.966

Epoch 7: Validation loss decreased (0.152156 --> 0.148841).  Saving model ...
	 Train_Loss: 0.2292 Train_Acc: 94.220 Val_Loss: 0.1488  BEST VAL Loss: 0.1488  Val_Acc: 96.374

Epoch 8: Validation loss decreased (0.148841 --> 0.142876).  Saving model ...
	 Train_Loss: 0.2203 Train_Acc: 94.616 Val_Loss: 0.1429  BEST VAL Loss: 0.1429  Val_Acc: 96.555

Epoch 9: Validation loss decreased (0.142876 --> 0.140675).  Saving model ...
	 Train_Loss: 0.2135 Train_Acc: 94.497 Val_Loss: 0.1407  BEST VAL Loss: 0.1407  Val_Acc: 96.917

Epoch 10: Validation loss decreased (0.140675 --> 0.137124).  Saving model ...
	 Train_Loss: 0.2082 Train_Acc: 94.327 Val_Loss: 0.1371  BEST VAL Loss: 0.1371  Val_Acc: 95.784

Epoch 11: Validation loss decreased (0.137124 --> 0.133027).  Saving model ...
	 Train_Loss: 0.2027 Train_Acc: 94.497 Val_Loss: 0.1330  BEST VAL Loss: 0.1330  Val_Acc: 96.646

Epoch 12: Validation loss decreased (0.133027 --> 0.131083).  Saving model ...
	 Train_Loss: 0.1973 Train_Acc: 95.109 Val_Loss: 0.1311  BEST VAL Loss: 0.1311  Val_Acc: 96.646

Epoch 13: Validation loss decreased (0.131083 --> 0.129095).  Saving model ...
	 Train_Loss: 0.1934 Train_Acc: 93.931 Val_Loss: 0.1291  BEST VAL Loss: 0.1291  Val_Acc: 96.646

Epoch 14: Validation loss decreased (0.129095 --> 0.126899).  Saving model ...
	 Train_Loss: 0.1891 Train_Acc: 94.956 Val_Loss: 0.1269  BEST VAL Loss: 0.1269  Val_Acc: 96.917

Epoch 15: Validation loss decreased (0.126899 --> 0.126128).  Saving model ...
	 Train_Loss: 0.1846 Train_Acc: 95.404 Val_Loss: 0.1261  BEST VAL Loss: 0.1261  Val_Acc: 96.872

Epoch 16: Validation loss did not decrease
	 Train_Loss: 0.1809 Train_Acc: 95.149 Val_Loss: 0.1283  BEST VAL Loss: 0.1261  Val_Acc: 96.555

Epoch 17: Validation loss decreased (0.126128 --> 0.125995).  Saving model ...
	 Train_Loss: 0.1771 Train_Acc: 95.801 Val_Loss: 0.1260  BEST VAL Loss: 0.1260  Val_Acc: 97.325

Epoch 18: Validation loss decreased (0.125995 --> 0.125238).  Saving model ...
	 Train_Loss: 0.1738 Train_Acc: 95.738 Val_Loss: 0.1252  BEST VAL Loss: 0.1252  Val_Acc: 97.416

Epoch 19: Validation loss decreased (0.125238 --> 0.123790).  Saving model ...
	 Train_Loss: 0.1706 Train_Acc: 95.682 Val_Loss: 0.1238  BEST VAL Loss: 0.1238  Val_Acc: 97.053

Epoch 20: Validation loss did not decrease
	 Train_Loss: 0.1679 Train_Acc: 95.092 Val_Loss: 0.1252  BEST VAL Loss: 0.1238  Val_Acc: 96.963

Epoch 21: Validation loss did not decrease
	 Train_Loss: 0.1655 Train_Acc: 95.359 Val_Loss: 0.1243  BEST VAL Loss: 0.1238  Val_Acc: 96.963

Epoch 22: Validation loss decreased (0.123790 --> 0.122647).  Saving model ...
	 Train_Loss: 0.1631 Train_Acc: 95.716 Val_Loss: 0.1226  BEST VAL Loss: 0.1226  Val_Acc: 96.963

Epoch 23: Validation loss decreased (0.122647 --> 0.121734).  Saving model ...
	 Train_Loss: 0.1615 Train_Acc: 95.415 Val_Loss: 0.1217  BEST VAL Loss: 0.1217  Val_Acc: 96.555

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.1598 Train_Acc: 95.319 Val_Loss: 0.1218  BEST VAL Loss: 0.1217  Val_Acc: 97.053

Epoch 25: Validation loss decreased (0.121734 --> 0.121547).  Saving model ...
	 Train_Loss: 0.1581 Train_Acc: 95.489 Val_Loss: 0.1215  BEST VAL Loss: 0.1215  Val_Acc: 96.827

Epoch 26: Validation loss decreased (0.121547 --> 0.120371).  Saving model ...
	 Train_Loss: 0.1565 Train_Acc: 95.551 Val_Loss: 0.1204  BEST VAL Loss: 0.1204  Val_Acc: 96.691

Epoch 27: Validation loss decreased (0.120371 --> 0.118960).  Saving model ...
	 Train_Loss: 0.1547 Train_Acc: 95.795 Val_Loss: 0.1190  BEST VAL Loss: 0.1190  Val_Acc: 97.053

Epoch 28: Validation loss decreased (0.118960 --> 0.118316).  Saving model ...
	 Train_Loss: 0.1531 Train_Acc: 95.761 Val_Loss: 0.1183  BEST VAL Loss: 0.1183  Val_Acc: 97.008

Epoch 29: Validation loss decreased (0.118316 --> 0.117740).  Saving model ...
	 Train_Loss: 0.1518 Train_Acc: 95.574 Val_Loss: 0.1177  BEST VAL Loss: 0.1177  Val_Acc: 96.419

Epoch 30: Validation loss decreased (0.117740 --> 0.116841).  Saving model ...
	 Train_Loss: 0.1505 Train_Acc: 95.557 Val_Loss: 0.1168  BEST VAL Loss: 0.1168  Val_Acc: 96.963

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.1491 Train_Acc: 95.767 Val_Loss: 0.1195  BEST VAL Loss: 0.1168  Val_Acc: 96.827

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.1478 Train_Acc: 95.761 Val_Loss: 0.1226  BEST VAL Loss: 0.1168  Val_Acc: 97.325

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.1465 Train_Acc: 96.056 Val_Loss: 0.1220  BEST VAL Loss: 0.1168  Val_Acc: 96.963

Epoch 34: Validation loss did not decrease
	 Train_Loss: 0.1454 Train_Acc: 95.659 Val_Loss: 0.1210  BEST VAL Loss: 0.1168  Val_Acc: 96.917

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.1443 Train_Acc: 95.976 Val_Loss: 0.1219  BEST VAL Loss: 0.1168  Val_Acc: 96.872

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.1432 Train_Acc: 95.965 Val_Loss: 0.1217  BEST VAL Loss: 0.1168  Val_Acc: 96.963

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.1422 Train_Acc: 95.886 Val_Loss: 0.1208  BEST VAL Loss: 0.1168  Val_Acc: 96.419

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.1418 Train_Acc: 94.554 Val_Loss: 0.1216  BEST VAL Loss: 0.1168  Val_Acc: 97.189

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.1421 Train_Acc: 93.789 Val_Loss: 0.1220  BEST VAL Loss: 0.1168  Val_Acc: 96.238

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.1428 Train_Acc: 92.520 Val_Loss: 0.1219  BEST VAL Loss: 0.1168  Val_Acc: 96.736

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.1433 Train_Acc: 93.103 Val_Loss: 0.1281  BEST VAL Loss: 0.1168  Val_Acc: 96.646

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.1447 Train_Acc: 92.361 Val_Loss: 0.1278  BEST VAL Loss: 0.1168  Val_Acc: 95.875

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.1461 Train_Acc: 91.794 Val_Loss: 0.1278  BEST VAL Loss: 0.1168  Val_Acc: 96.192

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.1478 Train_Acc: 90.853 Val_Loss: 0.1276  BEST VAL Loss: 0.1168  Val_Acc: 95.694

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.1492 Train_Acc: 91.567 Val_Loss: 0.1278  BEST VAL Loss: 0.1168  Val_Acc: 95.150

Epoch 46: Validation loss did not decrease
Early stopped at epoch : 46
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.55      0.55      9707
           1       0.45      0.45      0.45      7939

    accuracy                           0.50     17646
   macro avg       0.50      0.50      0.50     17646
weighted avg       0.50      0.50      0.50     17646

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.54      0.55      0.55      1214
           1       0.44      0.44      0.44       992

    accuracy                           0.50      2206
   macro avg       0.49      0.49      0.49      2206
weighted avg       0.50      0.50      0.50      2206

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.52      0.52      1214
           1       0.42      0.42      0.42       992

    accuracy                           0.48      2206
   macro avg       0.47      0.47      0.47      2206
weighted avg       0.48      0.48      0.48      2206

              precision    recall  f1-score   support

           0       0.53      0.52      0.52      1214
           1       0.42      0.42      0.42       992

    accuracy                           0.48      2206
   macro avg       0.47      0.47      0.47      2206
weighted avg       0.48      0.48      0.48      2206

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.52      0.51      3724
           1       0.50      0.49      0.49      3729

    accuracy                           0.50      7453
   macro avg       0.50      0.50      0.50      7453
weighted avg       0.50      0.50      0.50      7453

              precision    recall  f1-score   support

           0       0.50      0.52      0.51      3724
           1       0.50      0.49      0.49      3729

    accuracy                           0.50      7453
   macro avg       0.50      0.50      0.50      7453
weighted avg       0.50      0.50      0.50      7453

completed
