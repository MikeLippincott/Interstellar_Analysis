[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ad15967d'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'c2049fff'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '0d5ac04b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '93dd37a1'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_0.100_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_0.100_DMSO_0.025
TREATMENT_NAME: Flagellin_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (243144, 1270)
Number of total missing values across all columns: 522904
Data Subset Is Off
Wells held out for testing: ['C09' 'M10']
Wells to use for training, validation, and testing ['C02' 'C03' 'C08' 'M05' 'M11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.661046).  Saving model ...
	 Train_Loss: 0.6706 Train_Acc: 58.941 Val_Loss: 0.6610  BEST VAL Loss: 0.6610  Val_Acc: 58.941

Epoch 1: Validation loss decreased (0.661046 --> 0.645877).  Saving model ...
	 Train_Loss: 0.6612 Train_Acc: 61.297 Val_Loss: 0.6459  BEST VAL Loss: 0.6459  Val_Acc: 65.021

Epoch 2: Validation loss decreased (0.645877 --> 0.633109).  Saving model ...
	 Train_Loss: 0.6506 Train_Acc: 64.449 Val_Loss: 0.6331  BEST VAL Loss: 0.6331  Val_Acc: 68.334

Epoch 3: Validation loss decreased (0.633109 --> 0.622829).  Saving model ...
	 Train_Loss: 0.6407 Train_Acc: 65.775 Val_Loss: 0.6228  BEST VAL Loss: 0.6228  Val_Acc: 69.565

Epoch 4: Validation loss decreased (0.622829 --> 0.614028).  Saving model ...
	 Train_Loss: 0.6322 Train_Acc: 66.643 Val_Loss: 0.6140  BEST VAL Loss: 0.6140  Val_Acc: 70.257

Epoch 5: Validation loss decreased (0.614028 --> 0.605828).  Saving model ...
	 Train_Loss: 0.6249 Train_Acc: 67.082 Val_Loss: 0.6058  BEST VAL Loss: 0.6058  Val_Acc: 70.392

Epoch 6: Validation loss decreased (0.605828 --> 0.598259).  Saving model ...
	 Train_Loss: 0.6184 Train_Acc: 67.697 Val_Loss: 0.5983  BEST VAL Loss: 0.5983  Val_Acc: 71.799

Epoch 7: Validation loss decreased (0.598259 --> 0.592763).  Saving model ...
	 Train_Loss: 0.6123 Train_Acc: 68.394 Val_Loss: 0.5928  BEST VAL Loss: 0.5928  Val_Acc: 72.045

Epoch 8: Validation loss decreased (0.592763 --> 0.586571).  Saving model ...
	 Train_Loss: 0.6068 Train_Acc: 69.891 Val_Loss: 0.5866  BEST VAL Loss: 0.5866  Val_Acc: 72.901

Epoch 9: Validation loss decreased (0.586571 --> 0.581059).  Saving model ...
	 Train_Loss: 0.6016 Train_Acc: 71.494 Val_Loss: 0.5811  BEST VAL Loss: 0.5811  Val_Acc: 73.288

Epoch 10: Validation loss decreased (0.581059 --> 0.576869).  Saving model ...
	 Train_Loss: 0.5970 Train_Acc: 72.127 Val_Loss: 0.5769  BEST VAL Loss: 0.5769  Val_Acc: 73.382

Epoch 11: Validation loss decreased (0.576869 --> 0.571909).  Saving model ...
	 Train_Loss: 0.5926 Train_Acc: 72.542 Val_Loss: 0.5719  BEST VAL Loss: 0.5719  Val_Acc: 74.425

Epoch 12: Validation loss decreased (0.571909 --> 0.568122).  Saving model ...
	 Train_Loss: 0.5887 Train_Acc: 72.781 Val_Loss: 0.5681  BEST VAL Loss: 0.5681  Val_Acc: 74.150

Epoch 13: Validation loss decreased (0.568122 --> 0.564529).  Saving model ...
	 Train_Loss: 0.5851 Train_Acc: 73.026 Val_Loss: 0.5645  BEST VAL Loss: 0.5645  Val_Acc: 74.590

Epoch 14: Validation loss decreased (0.564529 --> 0.560968).  Saving model ...
	 Train_Loss: 0.5817 Train_Acc: 73.369 Val_Loss: 0.5610  BEST VAL Loss: 0.5610  Val_Acc: 74.619

Epoch 15: Validation loss decreased (0.560968 --> 0.557367).  Saving model ...
	 Train_Loss: 0.5785 Train_Acc: 73.515 Val_Loss: 0.5574  BEST VAL Loss: 0.5574  Val_Acc: 75.322

Epoch 16: Validation loss decreased (0.557367 --> 0.554376).  Saving model ...
	 Train_Loss: 0.5756 Train_Acc: 73.670 Val_Loss: 0.5544  BEST VAL Loss: 0.5544  Val_Acc: 74.420

Epoch 17: Validation loss decreased (0.554376 --> 0.551528).  Saving model ...
	 Train_Loss: 0.5729 Train_Acc: 73.760 Val_Loss: 0.5515  BEST VAL Loss: 0.5515  Val_Acc: 75.598

Epoch 18: Validation loss decreased (0.551528 --> 0.548889).  Saving model ...
	 Train_Loss: 0.5702 Train_Acc: 74.074 Val_Loss: 0.5489  BEST VAL Loss: 0.5489  Val_Acc: 75.997

Epoch 19: Validation loss decreased (0.548889 --> 0.547054).  Saving model ...
	 Train_Loss: 0.5679 Train_Acc: 73.992 Val_Loss: 0.5471  BEST VAL Loss: 0.5471  Val_Acc: 75.340

Epoch 20: Validation loss decreased (0.547054 --> 0.544505).  Saving model ...
	 Train_Loss: 0.5657 Train_Acc: 74.239 Val_Loss: 0.5445  BEST VAL Loss: 0.5445  Val_Acc: 75.563

Epoch 21: Validation loss decreased (0.544505 --> 0.542363).  Saving model ...
	 Train_Loss: 0.5635 Train_Acc: 74.175 Val_Loss: 0.5424  BEST VAL Loss: 0.5424  Val_Acc: 75.381

Epoch 22: Validation loss decreased (0.542363 --> 0.540071).  Saving model ...
	 Train_Loss: 0.5614 Train_Acc: 74.330 Val_Loss: 0.5401  BEST VAL Loss: 0.5401  Val_Acc: 76.008

Epoch 23: Validation loss decreased (0.540071 --> 0.538330).  Saving model ...
	 Train_Loss: 0.5595 Train_Acc: 74.444 Val_Loss: 0.5383  BEST VAL Loss: 0.5383  Val_Acc: 75.346

Epoch 24: Validation loss decreased (0.538330 --> 0.536423).  Saving model ...
	 Train_Loss: 0.5577 Train_Acc: 74.502 Val_Loss: 0.5364  BEST VAL Loss: 0.5364  Val_Acc: 75.780

Epoch 25: Validation loss decreased (0.536423 --> 0.534581).  Saving model ...
	 Train_Loss: 0.5559 Train_Acc: 74.630 Val_Loss: 0.5346  BEST VAL Loss: 0.5346  Val_Acc: 75.721

Epoch 26: Validation loss decreased (0.534581 --> 0.532733).  Saving model ...
	 Train_Loss: 0.5542 Train_Acc: 74.732 Val_Loss: 0.5327  BEST VAL Loss: 0.5327  Val_Acc: 76.571

Epoch 27: Validation loss decreased (0.532733 --> 0.531131).  Saving model ...
	 Train_Loss: 0.5526 Train_Acc: 74.522 Val_Loss: 0.5311  BEST VAL Loss: 0.5311  Val_Acc: 76.243

Epoch 28: Validation loss decreased (0.531131 --> 0.529568).  Saving model ...
	 Train_Loss: 0.5510 Train_Acc: 74.743 Val_Loss: 0.5296  BEST VAL Loss: 0.5296  Val_Acc: 76.624

Epoch 29: Validation loss decreased (0.529568 --> 0.528093).  Saving model ...
	 Train_Loss: 0.5495 Train_Acc: 74.832 Val_Loss: 0.5281  BEST VAL Loss: 0.5281  Val_Acc: 75.657

Epoch 30: Validation loss decreased (0.528093 --> 0.526773).  Saving model ...
	 Train_Loss: 0.5480 Train_Acc: 74.788 Val_Loss: 0.5268  BEST VAL Loss: 0.5268  Val_Acc: 76.120

Epoch 31: Validation loss decreased (0.526773 --> 0.525314).  Saving model ...
	 Train_Loss: 0.5466 Train_Acc: 74.934 Val_Loss: 0.5253  BEST VAL Loss: 0.5253  Val_Acc: 76.102

Epoch 32: Validation loss decreased (0.525314 --> 0.524088).  Saving model ...
	 Train_Loss: 0.5452 Train_Acc: 75.097 Val_Loss: 0.5241  BEST VAL Loss: 0.5241  Val_Acc: 76.149

Epoch 33: Validation loss decreased (0.524088 --> 0.522869).  Saving model ...
	 Train_Loss: 0.5440 Train_Acc: 74.919 Val_Loss: 0.5229  BEST VAL Loss: 0.5229  Val_Acc: 75.657

Epoch 34: Validation loss decreased (0.522869 --> 0.521549).  Saving model ...
	 Train_Loss: 0.5427 Train_Acc: 74.987 Val_Loss: 0.5215  BEST VAL Loss: 0.5215  Val_Acc: 76.519

Epoch 35: Validation loss decreased (0.521549 --> 0.520295).  Saving model ...
	 Train_Loss: 0.5415 Train_Acc: 75.154 Val_Loss: 0.5203  BEST VAL Loss: 0.5203  Val_Acc: 76.483

Epoch 36: Validation loss decreased (0.520295 --> 0.519052).  Saving model ...
	 Train_Loss: 0.5403 Train_Acc: 75.124 Val_Loss: 0.5191  BEST VAL Loss: 0.5191  Val_Acc: 76.818

Epoch 37: Validation loss decreased (0.519052 --> 0.517882).  Saving model ...
	 Train_Loss: 0.5391 Train_Acc: 75.157 Val_Loss: 0.5179  BEST VAL Loss: 0.5179  Val_Acc: 76.565

Epoch 38: Validation loss decreased (0.517882 --> 0.516716).  Saving model ...
	 Train_Loss: 0.5380 Train_Acc: 75.129 Val_Loss: 0.5167  BEST VAL Loss: 0.5167  Val_Acc: 76.348

Epoch 39: Validation loss decreased (0.516716 --> 0.515783).  Saving model ...
	 Train_Loss: 0.5369 Train_Acc: 75.278 Val_Loss: 0.5158  BEST VAL Loss: 0.5158  Val_Acc: 75.862

Epoch 40: Validation loss decreased (0.515783 --> 0.514646).  Saving model ...
	 Train_Loss: 0.5359 Train_Acc: 75.160 Val_Loss: 0.5146  BEST VAL Loss: 0.5146  Val_Acc: 76.712

Epoch 41: Validation loss decreased (0.514646 --> 0.513732).  Saving model ...
	 Train_Loss: 0.5349 Train_Acc: 75.029 Val_Loss: 0.5137  BEST VAL Loss: 0.5137  Val_Acc: 76.003

Epoch 42: Validation loss decreased (0.513732 --> 0.512692).  Saving model ...
	 Train_Loss: 0.5339 Train_Acc: 75.139 Val_Loss: 0.5127  BEST VAL Loss: 0.5127  Val_Acc: 76.466

Epoch 43: Validation loss decreased (0.512692 --> 0.511668).  Saving model ...
	 Train_Loss: 0.5329 Train_Acc: 75.189 Val_Loss: 0.5117  BEST VAL Loss: 0.5117  Val_Acc: 76.601

Epoch 44: Validation loss decreased (0.511668 --> 0.510705).  Saving model ...
	 Train_Loss: 0.5320 Train_Acc: 75.278 Val_Loss: 0.5107  BEST VAL Loss: 0.5107  Val_Acc: 76.659

Epoch 45: Validation loss decreased (0.510705 --> 0.509742).  Saving model ...
	 Train_Loss: 0.5311 Train_Acc: 75.286 Val_Loss: 0.5097  BEST VAL Loss: 0.5097  Val_Acc: 76.964

Epoch 46: Validation loss decreased (0.509742 --> 0.508820).  Saving model ...
	 Train_Loss: 0.5302 Train_Acc: 75.257 Val_Loss: 0.5088  BEST VAL Loss: 0.5088  Val_Acc: 76.905

Epoch 47: Validation loss decreased (0.508820 --> 0.508118).  Saving model ...
	 Train_Loss: 0.5293 Train_Acc: 75.350 Val_Loss: 0.5081  BEST VAL Loss: 0.5081  Val_Acc: 76.442

Epoch 48: Validation loss decreased (0.508118 --> 0.507153).  Saving model ...
	 Train_Loss: 0.5284 Train_Acc: 75.319 Val_Loss: 0.5072  BEST VAL Loss: 0.5072  Val_Acc: 76.636

Epoch 49: Validation loss decreased (0.507153 --> 0.506349).  Saving model ...
	 Train_Loss: 0.5276 Train_Acc: 75.377 Val_Loss: 0.5063  BEST VAL Loss: 0.5063  Val_Acc: 76.818

Epoch 50: Validation loss decreased (0.506349 --> 0.505700).  Saving model ...
	 Train_Loss: 0.5268 Train_Acc: 75.374 Val_Loss: 0.5057  BEST VAL Loss: 0.5057  Val_Acc: 76.683

Epoch 51: Validation loss decreased (0.505700 --> 0.505046).  Saving model ...
	 Train_Loss: 0.5260 Train_Acc: 75.388 Val_Loss: 0.5050  BEST VAL Loss: 0.5050  Val_Acc: 76.360

Epoch 52: Validation loss decreased (0.505046 --> 0.504328).  Saving model ...
	 Train_Loss: 0.5252 Train_Acc: 75.416 Val_Loss: 0.5043  BEST VAL Loss: 0.5043  Val_Acc: 76.759

Epoch 53: Validation loss decreased (0.504328 --> 0.503637).  Saving model ...
	 Train_Loss: 0.5244 Train_Acc: 75.316 Val_Loss: 0.5036  BEST VAL Loss: 0.5036  Val_Acc: 76.659

Epoch 54: Validation loss decreased (0.503637 --> 0.502878).  Saving model ...
	 Train_Loss: 0.5236 Train_Acc: 75.563 Val_Loss: 0.5029  BEST VAL Loss: 0.5029  Val_Acc: 76.706

Epoch 55: Validation loss decreased (0.502878 --> 0.502300).  Saving model ...
	 Train_Loss: 0.5229 Train_Acc: 75.398 Val_Loss: 0.5023  BEST VAL Loss: 0.5023  Val_Acc: 76.331

Epoch 56: Validation loss decreased (0.502300 --> 0.501555).  Saving model ...
	 Train_Loss: 0.5222 Train_Acc: 75.400 Val_Loss: 0.5016  BEST VAL Loss: 0.5016  Val_Acc: 76.900

Epoch 57: Validation loss decreased (0.501555 --> 0.500790).  Saving model ...
	 Train_Loss: 0.5215 Train_Acc: 75.393 Val_Loss: 0.5008  BEST VAL Loss: 0.5008  Val_Acc: 76.999

Epoch 58: Validation loss decreased (0.500790 --> 0.500209).  Saving model ...
	 Train_Loss: 0.5209 Train_Acc: 75.553 Val_Loss: 0.5002  BEST VAL Loss: 0.5002  Val_Acc: 76.859

Epoch 59: Validation loss decreased (0.500209 --> 0.499591).  Saving model ...
	 Train_Loss: 0.5202 Train_Acc: 75.503 Val_Loss: 0.4996  BEST VAL Loss: 0.4996  Val_Acc: 76.624

Epoch 60: Validation loss decreased (0.499591 --> 0.498951).  Saving model ...
	 Train_Loss: 0.5195 Train_Acc: 75.425 Val_Loss: 0.4990  BEST VAL Loss: 0.4990  Val_Acc: 76.958

Epoch 61: Validation loss decreased (0.498951 --> 0.498248).  Saving model ...
	 Train_Loss: 0.5189 Train_Acc: 75.608 Val_Loss: 0.4982  BEST VAL Loss: 0.4982  Val_Acc: 77.199

Epoch 62: Validation loss decreased (0.498248 --> 0.497845).  Saving model ...
	 Train_Loss: 0.5182 Train_Acc: 75.618 Val_Loss: 0.4978  BEST VAL Loss: 0.4978  Val_Acc: 76.730

Epoch 63: Validation loss decreased (0.497845 --> 0.497292).  Saving model ...
	 Train_Loss: 0.5176 Train_Acc: 75.499 Val_Loss: 0.4973  BEST VAL Loss: 0.4973  Val_Acc: 76.788

Epoch 64: Validation loss decreased (0.497292 --> 0.496697).  Saving model ...
	 Train_Loss: 0.5170 Train_Acc: 75.509 Val_Loss: 0.4967  BEST VAL Loss: 0.4967  Val_Acc: 76.501

Epoch 65: Validation loss decreased (0.496697 --> 0.496118).  Saving model ...
	 Train_Loss: 0.5164 Train_Acc: 75.679 Val_Loss: 0.4961  BEST VAL Loss: 0.4961  Val_Acc: 76.812

Epoch 66: Validation loss decreased (0.496118 --> 0.495528).  Saving model ...
	 Train_Loss: 0.5158 Train_Acc: 75.586 Val_Loss: 0.4955  BEST VAL Loss: 0.4955  Val_Acc: 77.357

Epoch 67: Validation loss decreased (0.495528 --> 0.495057).  Saving model ...
	 Train_Loss: 0.5152 Train_Acc: 75.697 Val_Loss: 0.4951  BEST VAL Loss: 0.4951  Val_Acc: 76.982

Epoch 68: Validation loss decreased (0.495057 --> 0.494485).  Saving model ...
	 Train_Loss: 0.5147 Train_Acc: 75.684 Val_Loss: 0.4945  BEST VAL Loss: 0.4945  Val_Acc: 76.606

Epoch 69: Validation loss decreased (0.494485 --> 0.493891).  Saving model ...
	 Train_Loss: 0.5141 Train_Acc: 75.629 Val_Loss: 0.4939  BEST VAL Loss: 0.4939  Val_Acc: 76.882

Epoch 70: Validation loss decreased (0.493891 --> 0.493380).  Saving model ...
	 Train_Loss: 0.5136 Train_Acc: 75.709 Val_Loss: 0.4934  BEST VAL Loss: 0.4934  Val_Acc: 76.583

Epoch 71: Validation loss decreased (0.493380 --> 0.492975).  Saving model ...
	 Train_Loss: 0.5130 Train_Acc: 75.538 Val_Loss: 0.4930  BEST VAL Loss: 0.4930  Val_Acc: 77.011

Epoch 72: Validation loss decreased (0.492975 --> 0.492483).  Saving model ...
	 Train_Loss: 0.5125 Train_Acc: 75.626 Val_Loss: 0.4925  BEST VAL Loss: 0.4925  Val_Acc: 76.894

Epoch 73: Validation loss decreased (0.492483 --> 0.491923).  Saving model ...
	 Train_Loss: 0.5119 Train_Acc: 75.810 Val_Loss: 0.4919  BEST VAL Loss: 0.4919  Val_Acc: 77.410

Epoch 74: Validation loss decreased (0.491923 --> 0.491453).  Saving model ...
	 Train_Loss: 0.5114 Train_Acc: 75.671 Val_Loss: 0.4915  BEST VAL Loss: 0.4915  Val_Acc: 76.818

Epoch 75: Validation loss decreased (0.491453 --> 0.490943).  Saving model ...
	 Train_Loss: 0.5109 Train_Acc: 75.780 Val_Loss: 0.4909  BEST VAL Loss: 0.4909  Val_Acc: 76.923

Epoch 76: Validation loss decreased (0.490943 --> 0.490564).  Saving model ...
	 Train_Loss: 0.5104 Train_Acc: 75.914 Val_Loss: 0.4906  BEST VAL Loss: 0.4906  Val_Acc: 77.451

Epoch 77: Validation loss decreased (0.490564 --> 0.490121).  Saving model ...
	 Train_Loss: 0.5099 Train_Acc: 75.813 Val_Loss: 0.4901  BEST VAL Loss: 0.4901  Val_Acc: 76.378

Epoch 78: Validation loss decreased (0.490121 --> 0.489637).  Saving model ...
	 Train_Loss: 0.5094 Train_Acc: 75.824 Val_Loss: 0.4896  BEST VAL Loss: 0.4896  Val_Acc: 77.040

Epoch 79: Validation loss decreased (0.489637 --> 0.489073).  Saving model ...
	 Train_Loss: 0.5089 Train_Acc: 75.808 Val_Loss: 0.4891  BEST VAL Loss: 0.4891  Val_Acc: 77.322

Epoch 80: Validation loss decreased (0.489073 --> 0.488664).  Saving model ...
	 Train_Loss: 0.5085 Train_Acc: 75.836 Val_Loss: 0.4887  BEST VAL Loss: 0.4887  Val_Acc: 77.304

Epoch 81: Validation loss decreased (0.488664 --> 0.488212).  Saving model ...
	 Train_Loss: 0.5080 Train_Acc: 75.745 Val_Loss: 0.4882  BEST VAL Loss: 0.4882  Val_Acc: 77.117

Epoch 82: Validation loss decreased (0.488212 --> 0.487808).  Saving model ...
	 Train_Loss: 0.5076 Train_Acc: 75.846 Val_Loss: 0.4878  BEST VAL Loss: 0.4878  Val_Acc: 77.081

Epoch 83: Validation loss decreased (0.487808 --> 0.487267).  Saving model ...
	 Train_Loss: 0.5071 Train_Acc: 75.948 Val_Loss: 0.4873  BEST VAL Loss: 0.4873  Val_Acc: 77.433

Epoch 84: Validation loss decreased (0.487267 --> 0.487016).  Saving model ...
	 Train_Loss: 0.5066 Train_Acc: 76.063 Val_Loss: 0.4870  BEST VAL Loss: 0.4870  Val_Acc: 77.093

Epoch 85: Validation loss decreased (0.487016 --> 0.486574).  Saving model ...
	 Train_Loss: 0.5062 Train_Acc: 75.895 Val_Loss: 0.4866  BEST VAL Loss: 0.4866  Val_Acc: 77.287

Epoch 86: Validation loss decreased (0.486574 --> 0.486174).  Saving model ...
	 Train_Loss: 0.5058 Train_Acc: 75.955 Val_Loss: 0.4862  BEST VAL Loss: 0.4862  Val_Acc: 77.240

Epoch 87: Validation loss decreased (0.486174 --> 0.485746).  Saving model ...
	 Train_Loss: 0.5053 Train_Acc: 75.779 Val_Loss: 0.4857  BEST VAL Loss: 0.4857  Val_Acc: 77.163

Epoch 88: Validation loss decreased (0.485746 --> 0.485458).  Saving model ...
	 Train_Loss: 0.5049 Train_Acc: 75.936 Val_Loss: 0.4855  BEST VAL Loss: 0.4855  Val_Acc: 77.070

Epoch 89: Validation loss decreased (0.485458 --> 0.484997).  Saving model ...
	 Train_Loss: 0.5045 Train_Acc: 75.797 Val_Loss: 0.4850  BEST VAL Loss: 0.4850  Val_Acc: 77.439

Epoch 90: Validation loss decreased (0.484997 --> 0.484634).  Saving model ...
	 Train_Loss: 0.5041 Train_Acc: 75.955 Val_Loss: 0.4846  BEST VAL Loss: 0.4846  Val_Acc: 76.876

Epoch 91: Validation loss decreased (0.484634 --> 0.484243).  Saving model ...
	 Train_Loss: 0.5037 Train_Acc: 76.080 Val_Loss: 0.4842  BEST VAL Loss: 0.4842  Val_Acc: 77.433

Epoch 92: Validation loss decreased (0.484243 --> 0.483944).  Saving model ...
	 Train_Loss: 0.5033 Train_Acc: 75.947 Val_Loss: 0.4839  BEST VAL Loss: 0.4839  Val_Acc: 77.492

Epoch 93: Validation loss decreased (0.483944 --> 0.483530).  Saving model ...
	 Train_Loss: 0.5029 Train_Acc: 76.052 Val_Loss: 0.4835  BEST VAL Loss: 0.4835  Val_Acc: 77.339

Epoch 94: Validation loss decreased (0.483530 --> 0.483114).  Saving model ...
	 Train_Loss: 0.5025 Train_Acc: 75.926 Val_Loss: 0.4831  BEST VAL Loss: 0.4831  Val_Acc: 77.269

Epoch 95: Validation loss decreased (0.483114 --> 0.482738).  Saving model ...
	 Train_Loss: 0.5022 Train_Acc: 75.941 Val_Loss: 0.4827  BEST VAL Loss: 0.4827  Val_Acc: 77.715

Epoch 96: Validation loss decreased (0.482738 --> 0.482280).  Saving model ...
	 Train_Loss: 0.5018 Train_Acc: 76.018 Val_Loss: 0.4823  BEST VAL Loss: 0.4823  Val_Acc: 77.591

Epoch 97: Validation loss decreased (0.482280 --> 0.481962).  Saving model ...
	 Train_Loss: 0.5014 Train_Acc: 76.018 Val_Loss: 0.4820  BEST VAL Loss: 0.4820  Val_Acc: 77.369

Epoch 98: Validation loss decreased (0.481962 --> 0.481663).  Saving model ...
	 Train_Loss: 0.5010 Train_Acc: 76.055 Val_Loss: 0.4817  BEST VAL Loss: 0.4817  Val_Acc: 76.958

Epoch 99: Validation loss decreased (0.481663 --> 0.481359).  Saving model ...
	 Train_Loss: 0.5007 Train_Acc: 76.002 Val_Loss: 0.4814  BEST VAL Loss: 0.4814  Val_Acc: 77.134

LPS_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.41      0.33      0.36     56123
           1       0.59      0.67      0.63     80324

    accuracy                           0.53    136447
   macro avg       0.50      0.50      0.50    136447
weighted avg       0.51      0.53      0.52    136447

LPS_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.40      0.32      0.36      7015
           1       0.59      0.67      0.62     10041

    accuracy                           0.53     17056
   macro avg       0.49      0.50      0.49     17056
weighted avg       0.51      0.53      0.51     17056

LPS_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.41      0.33      0.36      7015
           1       0.59      0.67      0.63     10041

    accuracy                           0.53     17056
   macro avg       0.50      0.50      0.50     17056
weighted avg       0.52      0.53      0.52     17056

              precision    recall  f1-score   support

           0       0.41      0.33      0.36      7015
           1       0.59      0.67      0.63     10041

    accuracy                           0.53     17056
   macro avg       0.50      0.50      0.50     17056
weighted avg       0.52      0.53      0.52     17056

LPS_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.31      0.37     34394
           1       0.53      0.70      0.60     38191

    accuracy                           0.51     72585
   macro avg       0.50      0.50      0.49     72585
weighted avg       0.51      0.51      0.49     72585

              precision    recall  f1-score   support

           0       0.48      0.31      0.37     34394
           1       0.53      0.70      0.60     38191

    accuracy                           0.51     72585
   macro avg       0.50      0.50      0.49     72585
weighted avg       0.51      0.51      0.49     72585

completed
