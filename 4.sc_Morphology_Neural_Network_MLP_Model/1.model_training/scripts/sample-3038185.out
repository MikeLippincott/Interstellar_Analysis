[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ca196e59'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'fd15b73b'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '86d0b73e'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '670da3ab'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_10.000_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (315925, 1270)
Number of total missing values across all columns: 631850
Data Subset Is Off
Wells held out for testing: ['E09' 'J08']
Wells to use for training, validation, and testing ['E02' 'E03' 'E08' 'J02' 'J03' 'J09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.606111).  Saving model ...
	 Train_Loss: 0.6952 Train_Acc: 58.261 Val_Loss: 0.6061  BEST VAL Loss: 0.6061  Val_Acc: 66.665

Epoch 1: Validation loss decreased (0.606111 --> 0.589840).  Saving model ...
	 Train_Loss: 0.6533 Train_Acc: 65.458 Val_Loss: 0.5898  BEST VAL Loss: 0.5898  Val_Acc: 69.441

Epoch 2: Validation loss decreased (0.589840 --> 0.580284).  Saving model ...
	 Train_Loss: 0.6336 Train_Acc: 67.007 Val_Loss: 0.5803  BEST VAL Loss: 0.5803  Val_Acc: 70.519

Epoch 3: Validation loss decreased (0.580284 --> 0.574717).  Saving model ...
	 Train_Loss: 0.6209 Train_Acc: 68.116 Val_Loss: 0.5747  BEST VAL Loss: 0.5747  Val_Acc: 71.080

Epoch 4: Validation loss decreased (0.574717 --> 0.567496).  Saving model ...
	 Train_Loss: 0.6109 Train_Acc: 68.824 Val_Loss: 0.5675  BEST VAL Loss: 0.5675  Val_Acc: 71.867

Epoch 5: Validation loss decreased (0.567496 --> 0.562095).  Saving model ...
	 Train_Loss: 0.6036 Train_Acc: 69.354 Val_Loss: 0.5621  BEST VAL Loss: 0.5621  Val_Acc: 71.690

Epoch 6: Validation loss decreased (0.562095 --> 0.557683).  Saving model ...
	 Train_Loss: 0.5979 Train_Acc: 69.523 Val_Loss: 0.5577  BEST VAL Loss: 0.5577  Val_Acc: 72.411

Epoch 7: Validation loss decreased (0.557683 --> 0.554932).  Saving model ...
	 Train_Loss: 0.5930 Train_Acc: 69.843 Val_Loss: 0.5549  BEST VAL Loss: 0.5549  Val_Acc: 72.107

Epoch 8: Validation loss decreased (0.554932 --> 0.551682).  Saving model ...
	 Train_Loss: 0.5887 Train_Acc: 70.281 Val_Loss: 0.5517  BEST VAL Loss: 0.5517  Val_Acc: 72.916

Epoch 9: Validation loss decreased (0.551682 --> 0.549589).  Saving model ...
	 Train_Loss: 0.5851 Train_Acc: 70.496 Val_Loss: 0.5496  BEST VAL Loss: 0.5496  Val_Acc: 72.769

Epoch 10: Validation loss decreased (0.549589 --> 0.547232).  Saving model ...
	 Train_Loss: 0.5815 Train_Acc: 70.964 Val_Loss: 0.5472  BEST VAL Loss: 0.5472  Val_Acc: 73.561

Epoch 11: Validation loss decreased (0.547232 --> 0.544357).  Saving model ...
	 Train_Loss: 0.5782 Train_Acc: 71.175 Val_Loss: 0.5444  BEST VAL Loss: 0.5444  Val_Acc: 74.268

Epoch 12: Validation loss decreased (0.544357 --> 0.542202).  Saving model ...
	 Train_Loss: 0.5754 Train_Acc: 71.223 Val_Loss: 0.5422  BEST VAL Loss: 0.5422  Val_Acc: 73.493

Epoch 13: Validation loss decreased (0.542202 --> 0.540317).  Saving model ...
	 Train_Loss: 0.5730 Train_Acc: 71.141 Val_Loss: 0.5403  BEST VAL Loss: 0.5403  Val_Acc: 74.209

Epoch 14: Validation loss decreased (0.540317 --> 0.538050).  Saving model ...
	 Train_Loss: 0.5707 Train_Acc: 71.475 Val_Loss: 0.5381  BEST VAL Loss: 0.5381  Val_Acc: 74.639

Epoch 15: Validation loss decreased (0.538050 --> 0.535885).  Saving model ...
	 Train_Loss: 0.5685 Train_Acc: 71.666 Val_Loss: 0.5359  BEST VAL Loss: 0.5359  Val_Acc: 75.140

Epoch 16: Validation loss decreased (0.535885 --> 0.533631).  Saving model ...
	 Train_Loss: 0.5664 Train_Acc: 71.721 Val_Loss: 0.5336  BEST VAL Loss: 0.5336  Val_Acc: 75.519

Epoch 17: Validation loss decreased (0.533631 --> 0.532762).  Saving model ...
	 Train_Loss: 0.5646 Train_Acc: 71.774 Val_Loss: 0.5328  BEST VAL Loss: 0.5328  Val_Acc: 73.847

Epoch 18: Validation loss decreased (0.532762 --> 0.531802).  Saving model ...
	 Train_Loss: 0.5628 Train_Acc: 71.777 Val_Loss: 0.5318  BEST VAL Loss: 0.5318  Val_Acc: 73.742

Epoch 19: Validation loss decreased (0.531802 --> 0.529821).  Saving model ...
	 Train_Loss: 0.5612 Train_Acc: 71.897 Val_Loss: 0.5298  BEST VAL Loss: 0.5298  Val_Acc: 75.553

Epoch 20: Validation loss decreased (0.529821 --> 0.528432).  Saving model ...
	 Train_Loss: 0.5594 Train_Acc: 72.449 Val_Loss: 0.5284  BEST VAL Loss: 0.5284  Val_Acc: 75.144

Epoch 21: Validation loss decreased (0.528432 --> 0.526751).  Saving model ...
	 Train_Loss: 0.5579 Train_Acc: 72.357 Val_Loss: 0.5268  BEST VAL Loss: 0.5268  Val_Acc: 75.806

Epoch 22: Validation loss decreased (0.526751 --> 0.525928).  Saving model ...
	 Train_Loss: 0.5564 Train_Acc: 72.257 Val_Loss: 0.5259  BEST VAL Loss: 0.5259  Val_Acc: 75.393

Epoch 23: Validation loss decreased (0.525928 --> 0.524608).  Saving model ...
	 Train_Loss: 0.5551 Train_Acc: 72.387 Val_Loss: 0.5246  BEST VAL Loss: 0.5246  Val_Acc: 75.793

Epoch 24: Validation loss decreased (0.524608 --> 0.523291).  Saving model ...
	 Train_Loss: 0.5536 Train_Acc: 72.651 Val_Loss: 0.5233  BEST VAL Loss: 0.5233  Val_Acc: 75.974

Epoch 25: Validation loss decreased (0.523291 --> 0.522156).  Saving model ...
	 Train_Loss: 0.5524 Train_Acc: 72.526 Val_Loss: 0.5222  BEST VAL Loss: 0.5222  Val_Acc: 75.671

Epoch 26: Validation loss decreased (0.522156 --> 0.521117).  Saving model ...
	 Train_Loss: 0.5511 Train_Acc: 72.628 Val_Loss: 0.5211  BEST VAL Loss: 0.5211  Val_Acc: 74.849

Epoch 27: Validation loss decreased (0.521117 --> 0.520186).  Saving model ...
	 Train_Loss: 0.5501 Train_Acc: 72.335 Val_Loss: 0.5202  BEST VAL Loss: 0.5202  Val_Acc: 75.085

Epoch 28: Validation loss decreased (0.520186 --> 0.518847).  Saving model ...
	 Train_Loss: 0.5491 Train_Acc: 72.424 Val_Loss: 0.5188  BEST VAL Loss: 0.5188  Val_Acc: 76.555

Epoch 29: Validation loss decreased (0.518847 --> 0.517838).  Saving model ...
	 Train_Loss: 0.5480 Train_Acc: 72.663 Val_Loss: 0.5178  BEST VAL Loss: 0.5178  Val_Acc: 76.433

Epoch 30: Validation loss decreased (0.517838 --> 0.517081).  Saving model ...
	 Train_Loss: 0.5471 Train_Acc: 72.620 Val_Loss: 0.5171  BEST VAL Loss: 0.5171  Val_Acc: 75.448

Epoch 31: Validation loss decreased (0.517081 --> 0.516180).  Saving model ...
	 Train_Loss: 0.5461 Train_Acc: 72.738 Val_Loss: 0.5162  BEST VAL Loss: 0.5162  Val_Acc: 76.669

Epoch 32: Validation loss decreased (0.516180 --> 0.515116).  Saving model ...
	 Train_Loss: 0.5452 Train_Acc: 72.795 Val_Loss: 0.5151  BEST VAL Loss: 0.5151  Val_Acc: 77.014

Epoch 33: Validation loss decreased (0.515116 --> 0.514321).  Saving model ...
	 Train_Loss: 0.5443 Train_Acc: 72.730 Val_Loss: 0.5143  BEST VAL Loss: 0.5143  Val_Acc: 76.223

Epoch 34: Validation loss decreased (0.514321 --> 0.513399).  Saving model ...
	 Train_Loss: 0.5434 Train_Acc: 72.598 Val_Loss: 0.5134  BEST VAL Loss: 0.5134  Val_Acc: 76.564

Epoch 35: Validation loss decreased (0.513399 --> 0.512457).  Saving model ...
	 Train_Loss: 0.5425 Train_Acc: 73.036 Val_Loss: 0.5125  BEST VAL Loss: 0.5125  Val_Acc: 76.682

Epoch 36: Validation loss decreased (0.512457 --> 0.511685).  Saving model ...
	 Train_Loss: 0.5416 Train_Acc: 73.049 Val_Loss: 0.5117  BEST VAL Loss: 0.5117  Val_Acc: 76.155

Epoch 37: Validation loss decreased (0.511685 --> 0.510962).  Saving model ...
	 Train_Loss: 0.5409 Train_Acc: 72.837 Val_Loss: 0.5110  BEST VAL Loss: 0.5110  Val_Acc: 76.690

Epoch 38: Validation loss decreased (0.510962 --> 0.510317).  Saving model ...
	 Train_Loss: 0.5402 Train_Acc: 72.826 Val_Loss: 0.5103  BEST VAL Loss: 0.5103  Val_Acc: 76.429

Epoch 39: Validation loss decreased (0.510317 --> 0.509733).  Saving model ...
	 Train_Loss: 0.5395 Train_Acc: 72.996 Val_Loss: 0.5097  BEST VAL Loss: 0.5097  Val_Acc: 76.231

Epoch 40: Validation loss decreased (0.509733 --> 0.509085).  Saving model ...
	 Train_Loss: 0.5388 Train_Acc: 72.767 Val_Loss: 0.5091  BEST VAL Loss: 0.5091  Val_Acc: 75.865

Epoch 41: Validation loss decreased (0.509085 --> 0.508535).  Saving model ...
	 Train_Loss: 0.5382 Train_Acc: 72.960 Val_Loss: 0.5085  BEST VAL Loss: 0.5085  Val_Acc: 76.686

Epoch 42: Validation loss decreased (0.508535 --> 0.508038).  Saving model ...
	 Train_Loss: 0.5375 Train_Acc: 73.132 Val_Loss: 0.5080  BEST VAL Loss: 0.5080  Val_Acc: 75.742

Epoch 43: Validation loss decreased (0.508038 --> 0.507512).  Saving model ...
	 Train_Loss: 0.5368 Train_Acc: 73.128 Val_Loss: 0.5075  BEST VAL Loss: 0.5075  Val_Acc: 76.909

Epoch 44: Validation loss decreased (0.507512 --> 0.507143).  Saving model ...
	 Train_Loss: 0.5362 Train_Acc: 73.036 Val_Loss: 0.5071  BEST VAL Loss: 0.5071  Val_Acc: 75.148

Epoch 45: Validation loss decreased (0.507143 --> 0.506414).  Saving model ...
	 Train_Loss: 0.5357 Train_Acc: 72.883 Val_Loss: 0.5064  BEST VAL Loss: 0.5064  Val_Acc: 77.116

Epoch 46: Validation loss decreased (0.506414 --> 0.505771).  Saving model ...
	 Train_Loss: 0.5350 Train_Acc: 73.326 Val_Loss: 0.5058  BEST VAL Loss: 0.5058  Val_Acc: 77.204

Epoch 47: Validation loss decreased (0.505771 --> 0.505170).  Saving model ...
	 Train_Loss: 0.5345 Train_Acc: 73.112 Val_Loss: 0.5052  BEST VAL Loss: 0.5052  Val_Acc: 76.850

Epoch 48: Validation loss decreased (0.505170 --> 0.504773).  Saving model ...
	 Train_Loss: 0.5339 Train_Acc: 73.270 Val_Loss: 0.5048  BEST VAL Loss: 0.5048  Val_Acc: 76.349

Epoch 49: Validation loss decreased (0.504773 --> 0.504310).  Saving model ...
	 Train_Loss: 0.5333 Train_Acc: 73.365 Val_Loss: 0.5043  BEST VAL Loss: 0.5043  Val_Acc: 76.939

Epoch 50: Validation loss decreased (0.504310 --> 0.503754).  Saving model ...
	 Train_Loss: 0.5328 Train_Acc: 72.951 Val_Loss: 0.5038  BEST VAL Loss: 0.5038  Val_Acc: 77.069

Epoch 51: Validation loss decreased (0.503754 --> 0.503301).  Saving model ...
	 Train_Loss: 0.5323 Train_Acc: 73.274 Val_Loss: 0.5033  BEST VAL Loss: 0.5033  Val_Acc: 77.002

Epoch 52: Validation loss decreased (0.503301 --> 0.502917).  Saving model ...
	 Train_Loss: 0.5318 Train_Acc: 73.177 Val_Loss: 0.5029  BEST VAL Loss: 0.5029  Val_Acc: 75.869

Epoch 53: Validation loss decreased (0.502917 --> 0.502385).  Saving model ...
	 Train_Loss: 0.5313 Train_Acc: 73.162 Val_Loss: 0.5024  BEST VAL Loss: 0.5024  Val_Acc: 77.187

Epoch 54: Validation loss decreased (0.502385 --> 0.502029).  Saving model ...
	 Train_Loss: 0.5308 Train_Acc: 73.233 Val_Loss: 0.5020  BEST VAL Loss: 0.5020  Val_Acc: 76.336

Epoch 55: Validation loss decreased (0.502029 --> 0.501594).  Saving model ...
	 Train_Loss: 0.5303 Train_Acc: 73.190 Val_Loss: 0.5016  BEST VAL Loss: 0.5016  Val_Acc: 76.795

Epoch 56: Validation loss decreased (0.501594 --> 0.501120).  Saving model ...
	 Train_Loss: 0.5299 Train_Acc: 73.258 Val_Loss: 0.5011  BEST VAL Loss: 0.5011  Val_Acc: 77.179

Epoch 57: Validation loss decreased (0.501120 --> 0.500652).  Saving model ...
	 Train_Loss: 0.5295 Train_Acc: 73.090 Val_Loss: 0.5007  BEST VAL Loss: 0.5007  Val_Acc: 76.787

Epoch 58: Validation loss decreased (0.500652 --> 0.500346).  Saving model ...
	 Train_Loss: 0.5291 Train_Acc: 73.357 Val_Loss: 0.5003  BEST VAL Loss: 0.5003  Val_Acc: 76.096

Epoch 59: Validation loss decreased (0.500346 --> 0.499948).  Saving model ...
	 Train_Loss: 0.5287 Train_Acc: 73.403 Val_Loss: 0.4999  BEST VAL Loss: 0.4999  Val_Acc: 76.656

Epoch 60: Validation loss decreased (0.499948 --> 0.499606).  Saving model ...
	 Train_Loss: 0.5283 Train_Acc: 73.385 Val_Loss: 0.4996  BEST VAL Loss: 0.4996  Val_Acc: 76.993

Epoch 61: Validation loss decreased (0.499606 --> 0.499304).  Saving model ...
	 Train_Loss: 0.5279 Train_Acc: 73.396 Val_Loss: 0.4993  BEST VAL Loss: 0.4993  Val_Acc: 76.859

Epoch 62: Validation loss decreased (0.499304 --> 0.498983).  Saving model ...
	 Train_Loss: 0.5275 Train_Acc: 73.235 Val_Loss: 0.4990  BEST VAL Loss: 0.4990  Val_Acc: 76.703

Epoch 63: Validation loss decreased (0.498983 --> 0.498604).  Saving model ...
	 Train_Loss: 0.5271 Train_Acc: 73.287 Val_Loss: 0.4986  BEST VAL Loss: 0.4986  Val_Acc: 76.926

Epoch 64: Validation loss decreased (0.498604 --> 0.498356).  Saving model ...
	 Train_Loss: 0.5268 Train_Acc: 73.286 Val_Loss: 0.4984  BEST VAL Loss: 0.4984  Val_Acc: 77.267

Epoch 65: Validation loss decreased (0.498356 --> 0.497996).  Saving model ...
	 Train_Loss: 0.5264 Train_Acc: 73.289 Val_Loss: 0.4980  BEST VAL Loss: 0.4980  Val_Acc: 76.728

Epoch 66: Validation loss decreased (0.497996 --> 0.497567).  Saving model ...
	 Train_Loss: 0.5260 Train_Acc: 73.302 Val_Loss: 0.4976  BEST VAL Loss: 0.4976  Val_Acc: 77.225

Epoch 67: Validation loss decreased (0.497567 --> 0.497398).  Saving model ...
	 Train_Loss: 0.5257 Train_Acc: 73.336 Val_Loss: 0.4974  BEST VAL Loss: 0.4974  Val_Acc: 76.741

Epoch 68: Validation loss decreased (0.497398 --> 0.497133).  Saving model ...
	 Train_Loss: 0.5254 Train_Acc: 73.349 Val_Loss: 0.4971  BEST VAL Loss: 0.4971  Val_Acc: 77.128

Epoch 69: Validation loss decreased (0.497133 --> 0.496911).  Saving model ...
	 Train_Loss: 0.5250 Train_Acc: 73.402 Val_Loss: 0.4969  BEST VAL Loss: 0.4969  Val_Acc: 76.955

Epoch 70: Validation loss decreased (0.496911 --> 0.496827).  Saving model ...
	 Train_Loss: 0.5247 Train_Acc: 73.306 Val_Loss: 0.4968  BEST VAL Loss: 0.4968  Val_Acc: 77.233

Epoch 71: Validation loss decreased (0.496827 --> 0.496396).  Saving model ...
	 Train_Loss: 0.5244 Train_Acc: 73.350 Val_Loss: 0.4964  BEST VAL Loss: 0.4964  Val_Acc: 77.646

Epoch 72: Validation loss decreased (0.496396 --> 0.496122).  Saving model ...
	 Train_Loss: 0.5241 Train_Acc: 73.385 Val_Loss: 0.4961  BEST VAL Loss: 0.4961  Val_Acc: 76.947

Epoch 73: Validation loss decreased (0.496122 --> 0.495998).  Saving model ...
	 Train_Loss: 0.5237 Train_Acc: 73.638 Val_Loss: 0.4960  BEST VAL Loss: 0.4960  Val_Acc: 75.936

Epoch 74: Validation loss decreased (0.495998 --> 0.495879).  Saving model ...
	 Train_Loss: 0.5235 Train_Acc: 73.502 Val_Loss: 0.4959  BEST VAL Loss: 0.4959  Val_Acc: 76.235

Epoch 75: Validation loss decreased (0.495879 --> 0.495622).  Saving model ...
	 Train_Loss: 0.5232 Train_Acc: 73.457 Val_Loss: 0.4956  BEST VAL Loss: 0.4956  Val_Acc: 76.846

Epoch 76: Validation loss decreased (0.495622 --> 0.495333).  Saving model ...
	 Train_Loss: 0.5229 Train_Acc: 73.426 Val_Loss: 0.4953  BEST VAL Loss: 0.4953  Val_Acc: 77.326

Epoch 77: Validation loss decreased (0.495333 --> 0.495036).  Saving model ...
	 Train_Loss: 0.5225 Train_Acc: 73.530 Val_Loss: 0.4950  BEST VAL Loss: 0.4950  Val_Acc: 77.377

Epoch 78: Validation loss decreased (0.495036 --> 0.494719).  Saving model ...
	 Train_Loss: 0.5222 Train_Acc: 73.572 Val_Loss: 0.4947  BEST VAL Loss: 0.4947  Val_Acc: 77.246

Epoch 79: Validation loss decreased (0.494719 --> 0.494591).  Saving model ...
	 Train_Loss: 0.5220 Train_Acc: 73.241 Val_Loss: 0.4946  BEST VAL Loss: 0.4946  Val_Acc: 77.276

Epoch 80: Validation loss decreased (0.494591 --> 0.494466).  Saving model ...
	 Train_Loss: 0.5217 Train_Acc: 73.413 Val_Loss: 0.4945  BEST VAL Loss: 0.4945  Val_Acc: 76.619

Epoch 81: Validation loss decreased (0.494466 --> 0.494230).  Saving model ...
	 Train_Loss: 0.5214 Train_Acc: 73.376 Val_Loss: 0.4942  BEST VAL Loss: 0.4942  Val_Acc: 77.672

Epoch 82: Validation loss decreased (0.494230 --> 0.493971).  Saving model ...
	 Train_Loss: 0.5212 Train_Acc: 73.381 Val_Loss: 0.4940  BEST VAL Loss: 0.4940  Val_Acc: 77.031

Epoch 83: Validation loss decreased (0.493971 --> 0.493700).  Saving model ...
	 Train_Loss: 0.5209 Train_Acc: 73.805 Val_Loss: 0.4937  BEST VAL Loss: 0.4937  Val_Acc: 76.766

Epoch 84: Validation loss decreased (0.493700 --> 0.493594).  Saving model ...
	 Train_Loss: 0.5206 Train_Acc: 73.436 Val_Loss: 0.4936  BEST VAL Loss: 0.4936  Val_Acc: 76.829

Epoch 85: Validation loss decreased (0.493594 --> 0.493326).  Saving model ...
	 Train_Loss: 0.5204 Train_Acc: 73.479 Val_Loss: 0.4933  BEST VAL Loss: 0.4933  Val_Acc: 77.811

Epoch 86: Validation loss decreased (0.493326 --> 0.493092).  Saving model ...
	 Train_Loss: 0.5201 Train_Acc: 73.693 Val_Loss: 0.4931  BEST VAL Loss: 0.4931  Val_Acc: 77.120

Epoch 87: Validation loss decreased (0.493092 --> 0.492966).  Saving model ...
	 Train_Loss: 0.5199 Train_Acc: 73.480 Val_Loss: 0.4930  BEST VAL Loss: 0.4930  Val_Acc: 76.189

Epoch 88: Validation loss decreased (0.492966 --> 0.492859).  Saving model ...
	 Train_Loss: 0.5197 Train_Acc: 73.370 Val_Loss: 0.4929  BEST VAL Loss: 0.4929  Val_Acc: 76.336

Epoch 89: Validation loss decreased (0.492859 --> 0.492811).  Saving model ...
	 Train_Loss: 0.5194 Train_Acc: 73.458 Val_Loss: 0.4928  BEST VAL Loss: 0.4928  Val_Acc: 77.335

Epoch 90: Validation loss decreased (0.492811 --> 0.492697).  Saving model ...
	 Train_Loss: 0.5192 Train_Acc: 73.630 Val_Loss: 0.4927  BEST VAL Loss: 0.4927  Val_Acc: 76.850

Epoch 91: Validation loss decreased (0.492697 --> 0.492540).  Saving model ...
	 Train_Loss: 0.5190 Train_Acc: 73.280 Val_Loss: 0.4925  BEST VAL Loss: 0.4925  Val_Acc: 77.044

Epoch 92: Validation loss decreased (0.492540 --> 0.492274).  Saving model ...
	 Train_Loss: 0.5188 Train_Acc: 73.551 Val_Loss: 0.4923  BEST VAL Loss: 0.4923  Val_Acc: 77.381

Epoch 93: Validation loss decreased (0.492274 --> 0.492123).  Saving model ...
	 Train_Loss: 0.5185 Train_Acc: 73.646 Val_Loss: 0.4921  BEST VAL Loss: 0.4921  Val_Acc: 77.204

Epoch 94: Validation loss decreased (0.492123 --> 0.491894).  Saving model ...
	 Train_Loss: 0.5183 Train_Acc: 73.786 Val_Loss: 0.4919  BEST VAL Loss: 0.4919  Val_Acc: 77.768

Epoch 95: Validation loss decreased (0.491894 --> 0.491689).  Saving model ...
	 Train_Loss: 0.5180 Train_Acc: 73.948 Val_Loss: 0.4917  BEST VAL Loss: 0.4917  Val_Acc: 77.090

Epoch 96: Validation loss decreased (0.491689 --> 0.491507).  Saving model ...
	 Train_Loss: 0.5178 Train_Acc: 73.619 Val_Loss: 0.4915  BEST VAL Loss: 0.4915  Val_Acc: 76.753

Epoch 97: Validation loss decreased (0.491507 --> 0.491339).  Saving model ...
	 Train_Loss: 0.5176 Train_Acc: 73.532 Val_Loss: 0.4913  BEST VAL Loss: 0.4913  Val_Acc: 77.137

Epoch 98: Validation loss decreased (0.491339 --> 0.491282).  Saving model ...
	 Train_Loss: 0.5174 Train_Acc: 73.460 Val_Loss: 0.4913  BEST VAL Loss: 0.4913  Val_Acc: 76.589

Epoch 99: Validation loss decreased (0.491282 --> 0.491158).  Saving model ...
	 Train_Loss: 0.5172 Train_Acc: 73.884 Val_Loss: 0.4912  BEST VAL Loss: 0.4912  Val_Acc: 76.501

LPS_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.60      0.54     92173
           1       0.52      0.40      0.45     97754

    accuracy                           0.50    189927
   macro avg       0.50      0.50      0.49    189927
weighted avg       0.50      0.50      0.49    189927

LPS_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.60      0.53     11522
           1       0.51      0.39      0.44     12219

    accuracy                           0.49     23741
   macro avg       0.50      0.50      0.49     23741
weighted avg       0.50      0.49      0.49     23741

LPS_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.61      0.54     11522
           1       0.52      0.40      0.45     12219

    accuracy                           0.50     23741
   macro avg       0.50      0.50      0.50     23741
weighted avg       0.50      0.50      0.50     23741

              precision    recall  f1-score   support

           0       0.49      0.61      0.54     11522
           1       0.52      0.40      0.45     12219

    accuracy                           0.50     23741
   macro avg       0.50      0.50      0.50     23741
weighted avg       0.50      0.50      0.50     23741

LPS_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.53      0.53     41273
           1       0.47      0.46      0.47     37243

    accuracy                           0.50     78516
   macro avg       0.50      0.50      0.50     78516
weighted avg       0.50      0.50      0.50     78516

              precision    recall  f1-score   support

           0       0.52      0.53      0.53     41273
           1       0.47      0.46      0.47     37243

    accuracy                           0.50     78516
   macro avg       0.50      0.50      0.50     78516
weighted avg       0.50      0.50      0.50     78516

completed
