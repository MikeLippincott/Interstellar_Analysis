[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'e226ac91'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'f00ee1d3'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd622916b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '06bf9404'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_Nigericin_1.000_1.0_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (340274, 1270)
Number of total missing values across all columns: 0
Data Subset Is Off
Wells held out for testing: ['K08' 'L09']
Wells to use for training, validation, and testing ['K02' 'K03' 'K09' 'L02' 'L03' 'L08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.565197).  Saving model ...
	 Train_Loss: 0.6369 Train_Acc: 62.028 Val_Loss: 0.5652  BEST VAL Loss: 0.5652  Val_Acc: 70.260

Epoch 1: Validation loss decreased (0.565197 --> 0.554709).  Saving model ...
	 Train_Loss: 0.6085 Train_Acc: 67.879 Val_Loss: 0.5547  BEST VAL Loss: 0.5547  Val_Acc: 71.894

Epoch 2: Validation loss decreased (0.554709 --> 0.546135).  Saving model ...
	 Train_Loss: 0.5934 Train_Acc: 69.549 Val_Loss: 0.5461  BEST VAL Loss: 0.5461  Val_Acc: 72.844

Epoch 3: Validation loss decreased (0.546135 --> 0.540331).  Saving model ...
	 Train_Loss: 0.5831 Train_Acc: 70.433 Val_Loss: 0.5403  BEST VAL Loss: 0.5403  Val_Acc: 73.718

Epoch 4: Validation loss decreased (0.540331 --> 0.534898).  Saving model ...
	 Train_Loss: 0.5753 Train_Acc: 71.086 Val_Loss: 0.5349  BEST VAL Loss: 0.5349  Val_Acc: 73.959

Epoch 5: Validation loss decreased (0.534898 --> 0.531371).  Saving model ...
	 Train_Loss: 0.5690 Train_Acc: 71.495 Val_Loss: 0.5314  BEST VAL Loss: 0.5314  Val_Acc: 74.050

Epoch 6: Validation loss decreased (0.531371 --> 0.527768).  Saving model ...
	 Train_Loss: 0.5638 Train_Acc: 71.882 Val_Loss: 0.5278  BEST VAL Loss: 0.5278  Val_Acc: 74.745

Epoch 7: Validation loss decreased (0.527768 --> 0.524448).  Saving model ...
	 Train_Loss: 0.5596 Train_Acc: 72.112 Val_Loss: 0.5244  BEST VAL Loss: 0.5244  Val_Acc: 74.913

Epoch 8: Validation loss decreased (0.524448 --> 0.522238).  Saving model ...
	 Train_Loss: 0.5558 Train_Acc: 72.401 Val_Loss: 0.5222  BEST VAL Loss: 0.5222  Val_Acc: 74.493

Epoch 9: Validation loss decreased (0.522238 --> 0.519670).  Saving model ...
	 Train_Loss: 0.5525 Train_Acc: 72.492 Val_Loss: 0.5197  BEST VAL Loss: 0.5197  Val_Acc: 75.005

Epoch 10: Validation loss decreased (0.519670 --> 0.517926).  Saving model ...
	 Train_Loss: 0.5497 Train_Acc: 72.654 Val_Loss: 0.5179  BEST VAL Loss: 0.5179  Val_Acc: 74.764

Epoch 11: Validation loss decreased (0.517926 --> 0.515786).  Saving model ...
	 Train_Loss: 0.5470 Train_Acc: 72.862 Val_Loss: 0.5158  BEST VAL Loss: 0.5158  Val_Acc: 75.333

Epoch 12: Validation loss decreased (0.515786 --> 0.514246).  Saving model ...
	 Train_Loss: 0.5446 Train_Acc: 73.061 Val_Loss: 0.5142  BEST VAL Loss: 0.5142  Val_Acc: 75.314

Epoch 13: Validation loss decreased (0.514246 --> 0.512574).  Saving model ...
	 Train_Loss: 0.5424 Train_Acc: 73.227 Val_Loss: 0.5126  BEST VAL Loss: 0.5126  Val_Acc: 75.089

Epoch 14: Validation loss decreased (0.512574 --> 0.510479).  Saving model ...
	 Train_Loss: 0.5404 Train_Acc: 73.341 Val_Loss: 0.5105  BEST VAL Loss: 0.5105  Val_Acc: 76.035

Epoch 15: Validation loss decreased (0.510479 --> 0.508732).  Saving model ...
	 Train_Loss: 0.5385 Train_Acc: 73.415 Val_Loss: 0.5087  BEST VAL Loss: 0.5087  Val_Acc: 75.768

Epoch 16: Validation loss decreased (0.508732 --> 0.507268).  Saving model ...
	 Train_Loss: 0.5368 Train_Acc: 73.474 Val_Loss: 0.5073  BEST VAL Loss: 0.5073  Val_Acc: 75.711

Epoch 17: Validation loss decreased (0.507268 --> 0.505725).  Saving model ...
	 Train_Loss: 0.5351 Train_Acc: 73.540 Val_Loss: 0.5057  BEST VAL Loss: 0.5057  Val_Acc: 75.971

Epoch 18: Validation loss decreased (0.505725 --> 0.504460).  Saving model ...
	 Train_Loss: 0.5336 Train_Acc: 73.498 Val_Loss: 0.5045  BEST VAL Loss: 0.5045  Val_Acc: 76.402

Epoch 19: Validation loss decreased (0.504460 --> 0.503211).  Saving model ...
	 Train_Loss: 0.5322 Train_Acc: 73.735 Val_Loss: 0.5032  BEST VAL Loss: 0.5032  Val_Acc: 76.215

Epoch 20: Validation loss decreased (0.503211 --> 0.501914).  Saving model ...
	 Train_Loss: 0.5309 Train_Acc: 73.779 Val_Loss: 0.5019  BEST VAL Loss: 0.5019  Val_Acc: 76.287

Epoch 21: Validation loss decreased (0.501914 --> 0.500645).  Saving model ...
	 Train_Loss: 0.5296 Train_Acc: 73.846 Val_Loss: 0.5006  BEST VAL Loss: 0.5006  Val_Acc: 76.452

Epoch 22: Validation loss decreased (0.500645 --> 0.499507).  Saving model ...
	 Train_Loss: 0.5283 Train_Acc: 73.898 Val_Loss: 0.4995  BEST VAL Loss: 0.4995  Val_Acc: 76.455

Epoch 23: Validation loss decreased (0.499507 --> 0.498470).  Saving model ...
	 Train_Loss: 0.5272 Train_Acc: 73.883 Val_Loss: 0.4985  BEST VAL Loss: 0.4985  Val_Acc: 76.906

Epoch 24: Validation loss decreased (0.498470 --> 0.497359).  Saving model ...
	 Train_Loss: 0.5261 Train_Acc: 73.919 Val_Loss: 0.4974  BEST VAL Loss: 0.4974  Val_Acc: 77.162

Epoch 25: Validation loss decreased (0.497359 --> 0.496383).  Saving model ...
	 Train_Loss: 0.5251 Train_Acc: 74.020 Val_Loss: 0.4964  BEST VAL Loss: 0.4964  Val_Acc: 76.780

Epoch 26: Validation loss decreased (0.496383 --> 0.495470).  Saving model ...
	 Train_Loss: 0.5242 Train_Acc: 74.063 Val_Loss: 0.4955  BEST VAL Loss: 0.4955  Val_Acc: 77.013

Epoch 27: Validation loss decreased (0.495470 --> 0.494516).  Saving model ...
	 Train_Loss: 0.5232 Train_Acc: 74.088 Val_Loss: 0.4945  BEST VAL Loss: 0.4945  Val_Acc: 77.127

Epoch 28: Validation loss decreased (0.494516 --> 0.493732).  Saving model ...
	 Train_Loss: 0.5223 Train_Acc: 74.169 Val_Loss: 0.4937  BEST VAL Loss: 0.4937  Val_Acc: 76.711

Epoch 29: Validation loss decreased (0.493732 --> 0.492855).  Saving model ...
	 Train_Loss: 0.5214 Train_Acc: 74.071 Val_Loss: 0.4929  BEST VAL Loss: 0.4929  Val_Acc: 77.265

Epoch 30: Validation loss decreased (0.492855 --> 0.492060).  Saving model ...
	 Train_Loss: 0.5206 Train_Acc: 74.084 Val_Loss: 0.4921  BEST VAL Loss: 0.4921  Val_Acc: 76.822

Epoch 31: Validation loss decreased (0.492060 --> 0.491210).  Saving model ...
	 Train_Loss: 0.5198 Train_Acc: 74.313 Val_Loss: 0.4912  BEST VAL Loss: 0.4912  Val_Acc: 77.497

Epoch 32: Validation loss decreased (0.491210 --> 0.490593).  Saving model ...
	 Train_Loss: 0.5191 Train_Acc: 74.082 Val_Loss: 0.4906  BEST VAL Loss: 0.4906  Val_Acc: 76.787

Epoch 33: Validation loss decreased (0.490593 --> 0.489864).  Saving model ...
	 Train_Loss: 0.5183 Train_Acc: 74.270 Val_Loss: 0.4899  BEST VAL Loss: 0.4899  Val_Acc: 77.123

Epoch 34: Validation loss decreased (0.489864 --> 0.489145).  Saving model ...
	 Train_Loss: 0.5176 Train_Acc: 74.316 Val_Loss: 0.4891  BEST VAL Loss: 0.4891  Val_Acc: 77.009

Epoch 35: Validation loss decreased (0.489145 --> 0.488456).  Saving model ...
	 Train_Loss: 0.5169 Train_Acc: 74.314 Val_Loss: 0.4885  BEST VAL Loss: 0.4885  Val_Acc: 77.093

Epoch 36: Validation loss decreased (0.488456 --> 0.487965).  Saving model ...
	 Train_Loss: 0.5162 Train_Acc: 74.445 Val_Loss: 0.4880  BEST VAL Loss: 0.4880  Val_Acc: 76.829

Epoch 37: Validation loss decreased (0.487965 --> 0.487351).  Saving model ...
	 Train_Loss: 0.5156 Train_Acc: 74.237 Val_Loss: 0.4874  BEST VAL Loss: 0.4874  Val_Acc: 77.226

Epoch 38: Validation loss decreased (0.487351 --> 0.486718).  Saving model ...
	 Train_Loss: 0.5150 Train_Acc: 74.285 Val_Loss: 0.4867  BEST VAL Loss: 0.4867  Val_Acc: 77.120

Epoch 39: Validation loss decreased (0.486718 --> 0.486114).  Saving model ...
	 Train_Loss: 0.5143 Train_Acc: 74.262 Val_Loss: 0.4861  BEST VAL Loss: 0.4861  Val_Acc: 77.326

Epoch 40: Validation loss decreased (0.486114 --> 0.485532).  Saving model ...
	 Train_Loss: 0.5138 Train_Acc: 74.268 Val_Loss: 0.4855  BEST VAL Loss: 0.4855  Val_Acc: 77.467

Epoch 41: Validation loss decreased (0.485532 --> 0.484983).  Saving model ...
	 Train_Loss: 0.5132 Train_Acc: 74.431 Val_Loss: 0.4850  BEST VAL Loss: 0.4850  Val_Acc: 77.375

Epoch 42: Validation loss decreased (0.484983 --> 0.484458).  Saving model ...
	 Train_Loss: 0.5127 Train_Acc: 74.340 Val_Loss: 0.4845  BEST VAL Loss: 0.4845  Val_Acc: 77.517

Epoch 43: Validation loss decreased (0.484458 --> 0.483951).  Saving model ...
	 Train_Loss: 0.5121 Train_Acc: 74.568 Val_Loss: 0.4840  BEST VAL Loss: 0.4840  Val_Acc: 77.226

Epoch 44: Validation loss decreased (0.483951 --> 0.483412).  Saving model ...
	 Train_Loss: 0.5116 Train_Acc: 74.567 Val_Loss: 0.4834  BEST VAL Loss: 0.4834  Val_Acc: 77.276

Epoch 45: Validation loss decreased (0.483412 --> 0.482835).  Saving model ...
	 Train_Loss: 0.5110 Train_Acc: 74.532 Val_Loss: 0.4828  BEST VAL Loss: 0.4828  Val_Acc: 77.600

Epoch 46: Validation loss decreased (0.482835 --> 0.482302).  Saving model ...
	 Train_Loss: 0.5105 Train_Acc: 74.517 Val_Loss: 0.4823  BEST VAL Loss: 0.4823  Val_Acc: 77.413

Epoch 47: Validation loss decreased (0.482302 --> 0.481886).  Saving model ...
	 Train_Loss: 0.5100 Train_Acc: 74.599 Val_Loss: 0.4819  BEST VAL Loss: 0.4819  Val_Acc: 77.150

Epoch 48: Validation loss decreased (0.481886 --> 0.481395).  Saving model ...
	 Train_Loss: 0.5096 Train_Acc: 74.457 Val_Loss: 0.4814  BEST VAL Loss: 0.4814  Val_Acc: 77.341

Epoch 49: Validation loss decreased (0.481395 --> 0.480965).  Saving model ...
	 Train_Loss: 0.5091 Train_Acc: 74.585 Val_Loss: 0.4810  BEST VAL Loss: 0.4810  Val_Acc: 77.574

Epoch 50: Validation loss decreased (0.480965 --> 0.480644).  Saving model ...
	 Train_Loss: 0.5086 Train_Acc: 74.604 Val_Loss: 0.4806  BEST VAL Loss: 0.4806  Val_Acc: 77.284

Epoch 51: Validation loss decreased (0.480644 --> 0.480226).  Saving model ...
	 Train_Loss: 0.5082 Train_Acc: 74.488 Val_Loss: 0.4802  BEST VAL Loss: 0.4802  Val_Acc: 77.600

Epoch 52: Validation loss decreased (0.480226 --> 0.479801).  Saving model ...
	 Train_Loss: 0.5078 Train_Acc: 74.496 Val_Loss: 0.4798  BEST VAL Loss: 0.4798  Val_Acc: 77.566

Epoch 53: Validation loss decreased (0.479801 --> 0.479434).  Saving model ...
	 Train_Loss: 0.5073 Train_Acc: 74.576 Val_Loss: 0.4794  BEST VAL Loss: 0.4794  Val_Acc: 77.608

Epoch 54: Validation loss decreased (0.479434 --> 0.479011).  Saving model ...
	 Train_Loss: 0.5069 Train_Acc: 74.624 Val_Loss: 0.4790  BEST VAL Loss: 0.4790  Val_Acc: 77.524

Epoch 55: Validation loss decreased (0.479011 --> 0.478611).  Saving model ...
	 Train_Loss: 0.5065 Train_Acc: 74.672 Val_Loss: 0.4786  BEST VAL Loss: 0.4786  Val_Acc: 77.635

Epoch 56: Validation loss decreased (0.478611 --> 0.478247).  Saving model ...
	 Train_Loss: 0.5061 Train_Acc: 74.624 Val_Loss: 0.4782  BEST VAL Loss: 0.4782  Val_Acc: 77.497

Epoch 57: Validation loss decreased (0.478247 --> 0.477824).  Saving model ...
	 Train_Loss: 0.5057 Train_Acc: 74.530 Val_Loss: 0.4778  BEST VAL Loss: 0.4778  Val_Acc: 77.852

Epoch 58: Validation loss decreased (0.477824 --> 0.477441).  Saving model ...
	 Train_Loss: 0.5054 Train_Acc: 74.713 Val_Loss: 0.4774  BEST VAL Loss: 0.4774  Val_Acc: 77.650

Epoch 59: Validation loss decreased (0.477441 --> 0.477113).  Saving model ...
	 Train_Loss: 0.5050 Train_Acc: 74.585 Val_Loss: 0.4771  BEST VAL Loss: 0.4771  Val_Acc: 77.673

Epoch 60: Validation loss decreased (0.477113 --> 0.476776).  Saving model ...
	 Train_Loss: 0.5046 Train_Acc: 74.653 Val_Loss: 0.4768  BEST VAL Loss: 0.4768  Val_Acc: 77.314

Epoch 61: Validation loss decreased (0.476776 --> 0.476455).  Saving model ...
	 Train_Loss: 0.5043 Train_Acc: 74.699 Val_Loss: 0.4765  BEST VAL Loss: 0.4765  Val_Acc: 77.673

Epoch 62: Validation loss decreased (0.476455 --> 0.476136).  Saving model ...
	 Train_Loss: 0.5039 Train_Acc: 74.586 Val_Loss: 0.4761  BEST VAL Loss: 0.4761  Val_Acc: 77.891

Epoch 63: Validation loss decreased (0.476136 --> 0.475863).  Saving model ...
	 Train_Loss: 0.5036 Train_Acc: 74.651 Val_Loss: 0.4759  BEST VAL Loss: 0.4759  Val_Acc: 77.749

Epoch 64: Validation loss decreased (0.475863 --> 0.475573).  Saving model ...
	 Train_Loss: 0.5032 Train_Acc: 74.761 Val_Loss: 0.4756  BEST VAL Loss: 0.4756  Val_Acc: 77.822

Epoch 65: Validation loss decreased (0.475573 --> 0.475257).  Saving model ...
	 Train_Loss: 0.5029 Train_Acc: 74.732 Val_Loss: 0.4753  BEST VAL Loss: 0.4753  Val_Acc: 77.726

Epoch 66: Validation loss decreased (0.475257 --> 0.474977).  Saving model ...
	 Train_Loss: 0.5026 Train_Acc: 74.844 Val_Loss: 0.4750  BEST VAL Loss: 0.4750  Val_Acc: 77.978

Epoch 67: Validation loss decreased (0.474977 --> 0.474657).  Saving model ...
	 Train_Loss: 0.5022 Train_Acc: 74.721 Val_Loss: 0.4747  BEST VAL Loss: 0.4747  Val_Acc: 77.841

Epoch 68: Validation loss decreased (0.474657 --> 0.474352).  Saving model ...
	 Train_Loss: 0.5019 Train_Acc: 74.759 Val_Loss: 0.4744  BEST VAL Loss: 0.4744  Val_Acc: 77.933

Epoch 69: Validation loss decreased (0.474352 --> 0.474053).  Saving model ...
	 Train_Loss: 0.5016 Train_Acc: 74.680 Val_Loss: 0.4741  BEST VAL Loss: 0.4741  Val_Acc: 77.730

Epoch 70: Validation loss decreased (0.474053 --> 0.473747).  Saving model ...
	 Train_Loss: 0.5013 Train_Acc: 74.626 Val_Loss: 0.4737  BEST VAL Loss: 0.4737  Val_Acc: 78.024

Epoch 71: Validation loss decreased (0.473747 --> 0.473498).  Saving model ...
	 Train_Loss: 0.5010 Train_Acc: 74.731 Val_Loss: 0.4735  BEST VAL Loss: 0.4735  Val_Acc: 77.833

Epoch 72: Validation loss decreased (0.473498 --> 0.473228).  Saving model ...
	 Train_Loss: 0.5007 Train_Acc: 74.650 Val_Loss: 0.4732  BEST VAL Loss: 0.4732  Val_Acc: 78.097

Epoch 73: Validation loss decreased (0.473228 --> 0.473010).  Saving model ...
	 Train_Loss: 0.5005 Train_Acc: 74.779 Val_Loss: 0.4730  BEST VAL Loss: 0.4730  Val_Acc: 77.578

Epoch 74: Validation loss decreased (0.473010 --> 0.472719).  Saving model ...
	 Train_Loss: 0.5002 Train_Acc: 74.807 Val_Loss: 0.4727  BEST VAL Loss: 0.4727  Val_Acc: 78.127

Epoch 75: Validation loss decreased (0.472719 --> 0.472413).  Saving model ...
	 Train_Loss: 0.4999 Train_Acc: 74.815 Val_Loss: 0.4724  BEST VAL Loss: 0.4724  Val_Acc: 78.204

Epoch 76: Validation loss decreased (0.472413 --> 0.472135).  Saving model ...
	 Train_Loss: 0.4996 Train_Acc: 74.896 Val_Loss: 0.4721  BEST VAL Loss: 0.4721  Val_Acc: 77.826

Epoch 77: Validation loss decreased (0.472135 --> 0.471886).  Saving model ...
	 Train_Loss: 0.4993 Train_Acc: 74.898 Val_Loss: 0.4719  BEST VAL Loss: 0.4719  Val_Acc: 78.173

Epoch 78: Validation loss decreased (0.471886 --> 0.471617).  Saving model ...
	 Train_Loss: 0.4991 Train_Acc: 74.887 Val_Loss: 0.4716  BEST VAL Loss: 0.4716  Val_Acc: 78.097

Epoch 79: Validation loss decreased (0.471617 --> 0.471347).  Saving model ...
	 Train_Loss: 0.4988 Train_Acc: 74.806 Val_Loss: 0.4713  BEST VAL Loss: 0.4713  Val_Acc: 78.085

Epoch 80: Validation loss decreased (0.471347 --> 0.471105).  Saving model ...
	 Train_Loss: 0.4986 Train_Acc: 74.843 Val_Loss: 0.4711  BEST VAL Loss: 0.4711  Val_Acc: 78.207

Epoch 81: Validation loss decreased (0.471105 --> 0.470946).  Saving model ...
	 Train_Loss: 0.4983 Train_Acc: 74.841 Val_Loss: 0.4709  BEST VAL Loss: 0.4709  Val_Acc: 77.715

Epoch 82: Validation loss decreased (0.470946 --> 0.470689).  Saving model ...
	 Train_Loss: 0.4981 Train_Acc: 74.883 Val_Loss: 0.4707  BEST VAL Loss: 0.4707  Val_Acc: 78.204

Epoch 83: Validation loss decreased (0.470689 --> 0.470477).  Saving model ...
	 Train_Loss: 0.4978 Train_Acc: 74.889 Val_Loss: 0.4705  BEST VAL Loss: 0.4705  Val_Acc: 78.188

Epoch 84: Validation loss decreased (0.470477 --> 0.470285).  Saving model ...
	 Train_Loss: 0.4976 Train_Acc: 74.931 Val_Loss: 0.4703  BEST VAL Loss: 0.4703  Val_Acc: 78.020

Epoch 85: Validation loss decreased (0.470285 --> 0.470039).  Saving model ...
	 Train_Loss: 0.4973 Train_Acc: 74.999 Val_Loss: 0.4700  BEST VAL Loss: 0.4700  Val_Acc: 78.272

Epoch 86: Validation loss decreased (0.470039 --> 0.469825).  Saving model ...
	 Train_Loss: 0.4971 Train_Acc: 74.809 Val_Loss: 0.4698  BEST VAL Loss: 0.4698  Val_Acc: 78.284

Epoch 87: Validation loss decreased (0.469825 --> 0.469615).  Saving model ...
	 Train_Loss: 0.4969 Train_Acc: 74.789 Val_Loss: 0.4696  BEST VAL Loss: 0.4696  Val_Acc: 78.013

Epoch 88: Validation loss decreased (0.469615 --> 0.469452).  Saving model ...
	 Train_Loss: 0.4967 Train_Acc: 74.824 Val_Loss: 0.4695  BEST VAL Loss: 0.4695  Val_Acc: 77.849

Epoch 89: Validation loss decreased (0.469452 --> 0.469222).  Saving model ...
	 Train_Loss: 0.4964 Train_Acc: 74.929 Val_Loss: 0.4692  BEST VAL Loss: 0.4692  Val_Acc: 78.188

Epoch 90: Validation loss decreased (0.469222 --> 0.469002).  Saving model ...
	 Train_Loss: 0.4962 Train_Acc: 74.884 Val_Loss: 0.4690  BEST VAL Loss: 0.4690  Val_Acc: 78.307

Epoch 91: Validation loss decreased (0.469002 --> 0.468752).  Saving model ...
	 Train_Loss: 0.4960 Train_Acc: 74.843 Val_Loss: 0.4688  BEST VAL Loss: 0.4688  Val_Acc: 78.379

Epoch 92: Validation loss decreased (0.468752 --> 0.468530).  Saving model ...
	 Train_Loss: 0.4958 Train_Acc: 74.905 Val_Loss: 0.4685  BEST VAL Loss: 0.4685  Val_Acc: 78.154

Epoch 93: Validation loss decreased (0.468530 --> 0.468345).  Saving model ...
	 Train_Loss: 0.4956 Train_Acc: 74.792 Val_Loss: 0.4683  BEST VAL Loss: 0.4683  Val_Acc: 78.230

Epoch 94: Validation loss decreased (0.468345 --> 0.468115).  Saving model ...
	 Train_Loss: 0.4954 Train_Acc: 74.876 Val_Loss: 0.4681  BEST VAL Loss: 0.4681  Val_Acc: 78.421

Epoch 95: Validation loss decreased (0.468115 --> 0.467919).  Saving model ...
	 Train_Loss: 0.4952 Train_Acc: 74.970 Val_Loss: 0.4679  BEST VAL Loss: 0.4679  Val_Acc: 78.326

Epoch 96: Validation loss decreased (0.467919 --> 0.467749).  Saving model ...
	 Train_Loss: 0.4949 Train_Acc: 75.016 Val_Loss: 0.4677  BEST VAL Loss: 0.4677  Val_Acc: 78.009

Epoch 97: Validation loss decreased (0.467749 --> 0.467523).  Saving model ...
	 Train_Loss: 0.4947 Train_Acc: 74.843 Val_Loss: 0.4675  BEST VAL Loss: 0.4675  Val_Acc: 78.459

Epoch 98: Validation loss decreased (0.467523 --> 0.467323).  Saving model ...
	 Train_Loss: 0.4945 Train_Acc: 74.909 Val_Loss: 0.4673  BEST VAL Loss: 0.4673  Val_Acc: 78.524

Epoch 99: Validation loss decreased (0.467323 --> 0.467138).  Saving model ...
	 Train_Loss: 0.4944 Train_Acc: 74.795 Val_Loss: 0.4671  BEST VAL Loss: 0.4671  Val_Acc: 78.360

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.77      0.82      0.80    100340
           1       0.83      0.78      0.80    109228

    accuracy                           0.80    209568
   macro avg       0.80      0.80      0.80    209568
weighted avg       0.80      0.80      0.80    209568

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.76      0.81      0.78     12543
           1       0.81      0.76      0.79     13654

    accuracy                           0.78     26197
   macro avg       0.78      0.78      0.78     26197
weighted avg       0.79      0.78      0.78     26197

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.75      0.81      0.78     12542
           1       0.81      0.76      0.78     13654

    accuracy                           0.78     26196
   macro avg       0.78      0.78      0.78     26196
weighted avg       0.78      0.78      0.78     26196

              precision    recall  f1-score   support

           0       0.75      0.81      0.78     12542
           1       0.81      0.76      0.78     13654

    accuracy                           0.78     26196
   macro avg       0.78      0.78      0.78     26196
weighted avg       0.78      0.78      0.78     26196

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.65      0.57      0.61     40588
           1       0.59      0.66      0.62     37725

    accuracy                           0.61     78313
   macro avg       0.62      0.62      0.61     78313
weighted avg       0.62      0.61      0.61     78313

              precision    recall  f1-score   support

           0       0.65      0.57      0.61     40588
           1       0.59      0.66      0.62     37725

    accuracy                           0.61     78313
   macro avg       0.62      0.62      0.61     78313
weighted avg       0.62      0.61      0.61     78313

completed
