[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '417f7780'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'c56fa2b1'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'c3abe465'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '822b352e'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 treatment_name: Thapsigargin_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
TREATMENT_NAME: Thapsigargin_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (314469, 1270)
Number of total missing values across all columns: 296912
Data Subset Is Off
Wells held out for testing: ['K06' 'K09']
Wells to use for training, validation, and testing ['D06' 'D07' 'K02' 'K03' 'K07' 'K08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.227560).  Saving model ...
	 Train_Loss: 0.3292 Train_Acc: 85.857 Val_Loss: 0.2276  BEST VAL Loss: 0.2276  Val_Acc: 90.773

Epoch 1: Validation loss decreased (0.227560 --> 0.222809).  Saving model ...
	 Train_Loss: 0.2928 Train_Acc: 90.113 Val_Loss: 0.2228  BEST VAL Loss: 0.2228  Val_Acc: 91.353

Epoch 2: Validation loss decreased (0.222809 --> 0.212310).  Saving model ...
	 Train_Loss: 0.2764 Train_Acc: 90.451 Val_Loss: 0.2123  BEST VAL Loss: 0.2123  Val_Acc: 92.386

Epoch 3: Validation loss decreased (0.212310 --> 0.205288).  Saving model ...
	 Train_Loss: 0.2632 Train_Acc: 91.365 Val_Loss: 0.2053  BEST VAL Loss: 0.2053  Val_Acc: 92.898

Epoch 4: Validation loss decreased (0.205288 --> 0.199850).  Saving model ...
	 Train_Loss: 0.2544 Train_Acc: 91.483 Val_Loss: 0.1998  BEST VAL Loss: 0.1998  Val_Acc: 93.058

Epoch 5: Validation loss decreased (0.199850 --> 0.195066).  Saving model ...
	 Train_Loss: 0.2484 Train_Acc: 91.527 Val_Loss: 0.1951  BEST VAL Loss: 0.1951  Val_Acc: 93.177

Epoch 6: Validation loss decreased (0.195066 --> 0.191683).  Saving model ...
	 Train_Loss: 0.2422 Train_Acc: 92.148 Val_Loss: 0.1917  BEST VAL Loss: 0.1917  Val_Acc: 93.291

Epoch 7: Validation loss decreased (0.191683 --> 0.188585).  Saving model ...
	 Train_Loss: 0.2368 Train_Acc: 92.345 Val_Loss: 0.1886  BEST VAL Loss: 0.1886  Val_Acc: 93.533

Epoch 8: Validation loss decreased (0.188585 --> 0.186265).  Saving model ...
	 Train_Loss: 0.2326 Train_Acc: 92.372 Val_Loss: 0.1863  BEST VAL Loss: 0.1863  Val_Acc: 93.444

Epoch 9: Validation loss decreased (0.186265 --> 0.184030).  Saving model ...
	 Train_Loss: 0.2299 Train_Acc: 92.047 Val_Loss: 0.1840  BEST VAL Loss: 0.1840  Val_Acc: 93.592

Epoch 10: Validation loss decreased (0.184030 --> 0.182060).  Saving model ...
	 Train_Loss: 0.2266 Train_Acc: 92.609 Val_Loss: 0.1821  BEST VAL Loss: 0.1821  Val_Acc: 93.740

Epoch 11: Validation loss decreased (0.182060 --> 0.180576).  Saving model ...
	 Train_Loss: 0.2243 Train_Acc: 92.345 Val_Loss: 0.1806  BEST VAL Loss: 0.1806  Val_Acc: 93.583

Epoch 12: Validation loss decreased (0.180576 --> 0.178986).  Saving model ...
	 Train_Loss: 0.2216 Train_Acc: 92.821 Val_Loss: 0.1790  BEST VAL Loss: 0.1790  Val_Acc: 94.002

Epoch 13: Validation loss decreased (0.178986 --> 0.178480).  Saving model ...
	 Train_Loss: 0.2191 Train_Acc: 92.870 Val_Loss: 0.1785  BEST VAL Loss: 0.1785  Val_Acc: 93.414

Epoch 14: Validation loss decreased (0.178480 --> 0.177032).  Saving model ...
	 Train_Loss: 0.2170 Train_Acc: 92.901 Val_Loss: 0.1770  BEST VAL Loss: 0.1770  Val_Acc: 93.994

Epoch 15: Validation loss decreased (0.177032 --> 0.175590).  Saving model ...
	 Train_Loss: 0.2149 Train_Acc: 93.065 Val_Loss: 0.1756  BEST VAL Loss: 0.1756  Val_Acc: 93.952

Epoch 16: Validation loss decreased (0.175590 --> 0.174596).  Saving model ...
	 Train_Loss: 0.2133 Train_Acc: 92.936 Val_Loss: 0.1746  BEST VAL Loss: 0.1746  Val_Acc: 93.825

Epoch 17: Validation loss decreased (0.174596 --> 0.173762).  Saving model ...
	 Train_Loss: 0.2121 Train_Acc: 92.589 Val_Loss: 0.1738  BEST VAL Loss: 0.1738  Val_Acc: 93.753

Epoch 18: Validation loss decreased (0.173762 --> 0.172939).  Saving model ...
	 Train_Loss: 0.2109 Train_Acc: 92.845 Val_Loss: 0.1729  BEST VAL Loss: 0.1729  Val_Acc: 93.833

Epoch 19: Validation loss decreased (0.172939 --> 0.172232).  Saving model ...
	 Train_Loss: 0.2096 Train_Acc: 93.062 Val_Loss: 0.1722  BEST VAL Loss: 0.1722  Val_Acc: 94.134

Epoch 20: Validation loss decreased (0.172232 --> 0.171343).  Saving model ...
	 Train_Loss: 0.2084 Train_Acc: 93.116 Val_Loss: 0.1713  BEST VAL Loss: 0.1713  Val_Acc: 94.159

Epoch 21: Validation loss decreased (0.171343 --> 0.170617).  Saving model ...
	 Train_Loss: 0.2074 Train_Acc: 93.030 Val_Loss: 0.1706  BEST VAL Loss: 0.1706  Val_Acc: 93.977

Epoch 22: Validation loss decreased (0.170617 --> 0.169744).  Saving model ...
	 Train_Loss: 0.2061 Train_Acc: 93.251 Val_Loss: 0.1697  BEST VAL Loss: 0.1697  Val_Acc: 94.261

Epoch 23: Validation loss decreased (0.169744 --> 0.168872).  Saving model ...
	 Train_Loss: 0.2049 Train_Acc: 93.279 Val_Loss: 0.1689  BEST VAL Loss: 0.1689  Val_Acc: 94.256

Epoch 24: Validation loss decreased (0.168872 --> 0.168327).  Saving model ...
	 Train_Loss: 0.2039 Train_Acc: 93.221 Val_Loss: 0.1683  BEST VAL Loss: 0.1683  Val_Acc: 94.011

Epoch 25: Validation loss decreased (0.168327 --> 0.167832).  Saving model ...
	 Train_Loss: 0.2038 Train_Acc: 92.182 Val_Loss: 0.1678  BEST VAL Loss: 0.1678  Val_Acc: 94.100

Epoch 26: Validation loss decreased (0.167832 --> 0.167248).  Saving model ...
	 Train_Loss: 0.2029 Train_Acc: 93.117 Val_Loss: 0.1672  BEST VAL Loss: 0.1672  Val_Acc: 93.693

Epoch 27: Validation loss decreased (0.167248 --> 0.166674).  Saving model ...
	 Train_Loss: 0.2019 Train_Acc: 93.366 Val_Loss: 0.1667  BEST VAL Loss: 0.1667  Val_Acc: 94.193

Epoch 28: Validation loss decreased (0.166674 --> 0.166159).  Saving model ...
	 Train_Loss: 0.2009 Train_Acc: 93.429 Val_Loss: 0.1662  BEST VAL Loss: 0.1662  Val_Acc: 94.277

Epoch 29: Validation loss decreased (0.166159 --> 0.165638).  Saving model ...
	 Train_Loss: 0.2000 Train_Acc: 93.377 Val_Loss: 0.1656  BEST VAL Loss: 0.1656  Val_Acc: 94.311

Epoch 30: Validation loss decreased (0.165638 --> 0.165144).  Saving model ...
	 Train_Loss: 0.1991 Train_Acc: 93.454 Val_Loss: 0.1651  BEST VAL Loss: 0.1651  Val_Acc: 94.159

Epoch 31: Validation loss decreased (0.165144 --> 0.164726).  Saving model ...
	 Train_Loss: 0.1983 Train_Acc: 93.468 Val_Loss: 0.1647  BEST VAL Loss: 0.1647  Val_Acc: 94.062

Epoch 32: Validation loss decreased (0.164726 --> 0.164232).  Saving model ...
	 Train_Loss: 0.1974 Train_Acc: 93.533 Val_Loss: 0.1642  BEST VAL Loss: 0.1642  Val_Acc: 94.201

Epoch 33: Validation loss decreased (0.164232 --> 0.163901).  Saving model ...
	 Train_Loss: 0.1967 Train_Acc: 93.480 Val_Loss: 0.1639  BEST VAL Loss: 0.1639  Val_Acc: 94.265

Epoch 34: Validation loss decreased (0.163901 --> 0.163514).  Saving model ...
	 Train_Loss: 0.1960 Train_Acc: 93.476 Val_Loss: 0.1635  BEST VAL Loss: 0.1635  Val_Acc: 94.222

Epoch 35: Validation loss decreased (0.163514 --> 0.163081).  Saving model ...
	 Train_Loss: 0.1953 Train_Acc: 93.564 Val_Loss: 0.1631  BEST VAL Loss: 0.1631  Val_Acc: 94.498

Epoch 36: Validation loss decreased (0.163081 --> 0.162675).  Saving model ...
	 Train_Loss: 0.1945 Train_Acc: 93.633 Val_Loss: 0.1627  BEST VAL Loss: 0.1627  Val_Acc: 94.392

Epoch 37: Validation loss decreased (0.162675 --> 0.162366).  Saving model ...
	 Train_Loss: 0.1939 Train_Acc: 93.590 Val_Loss: 0.1624  BEST VAL Loss: 0.1624  Val_Acc: 94.227

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.1934 Train_Acc: 93.593 Val_Loss: 0.1626  BEST VAL Loss: 0.1624  Val_Acc: 93.858

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.1932 Train_Acc: 92.682 Val_Loss: 0.1627  BEST VAL Loss: 0.1624  Val_Acc: 94.070

Epoch 40: Validation loss decreased (0.162366 --> 0.162318).  Saving model ...
	 Train_Loss: 0.1931 Train_Acc: 92.863 Val_Loss: 0.1623  BEST VAL Loss: 0.1623  Val_Acc: 94.345

Epoch 41: Validation loss decreased (0.162318 --> 0.162018).  Saving model ...
	 Train_Loss: 0.1926 Train_Acc: 93.337 Val_Loss: 0.1620  BEST VAL Loss: 0.1620  Val_Acc: 94.163

Epoch 42: Validation loss decreased (0.162018 --> 0.161712).  Saving model ...
	 Train_Loss: 0.1923 Train_Acc: 93.349 Val_Loss: 0.1617  BEST VAL Loss: 0.1617  Val_Acc: 94.193

Epoch 43: Validation loss decreased (0.161712 --> 0.161334).  Saving model ...
	 Train_Loss: 0.1917 Train_Acc: 93.722 Val_Loss: 0.1613  BEST VAL Loss: 0.1613  Val_Acc: 94.396

Epoch 44: Validation loss decreased (0.161334 --> 0.161321).  Saving model ...
	 Train_Loss: 0.1912 Train_Acc: 93.694 Val_Loss: 0.1613  BEST VAL Loss: 0.1613  Val_Acc: 94.015

Epoch 45: Validation loss decreased (0.161321 --> 0.161057).  Saving model ...
	 Train_Loss: 0.1907 Train_Acc: 93.572 Val_Loss: 0.1611  BEST VAL Loss: 0.1611  Val_Acc: 94.320

Epoch 46: Validation loss decreased (0.161057 --> 0.160653).  Saving model ...
	 Train_Loss: 0.1902 Train_Acc: 93.762 Val_Loss: 0.1607  BEST VAL Loss: 0.1607  Val_Acc: 94.396

Epoch 47: Validation loss decreased (0.160653 --> 0.160525).  Saving model ...
	 Train_Loss: 0.1898 Train_Acc: 93.512 Val_Loss: 0.1605  BEST VAL Loss: 0.1605  Val_Acc: 93.981

Epoch 48: Validation loss decreased (0.160525 --> 0.160297).  Saving model ...
	 Train_Loss: 0.1894 Train_Acc: 93.522 Val_Loss: 0.1603  BEST VAL Loss: 0.1603  Val_Acc: 94.519

Epoch 49: Validation loss decreased (0.160297 --> 0.160110).  Saving model ...
	 Train_Loss: 0.1890 Train_Acc: 93.711 Val_Loss: 0.1601  BEST VAL Loss: 0.1601  Val_Acc: 94.447

Epoch 50: Validation loss decreased (0.160110 --> 0.159978).  Saving model ...
	 Train_Loss: 0.1885 Train_Acc: 93.790 Val_Loss: 0.1600  BEST VAL Loss: 0.1600  Val_Acc: 94.515

Epoch 51: Validation loss decreased (0.159978 --> 0.159651).  Saving model ...
	 Train_Loss: 0.1881 Train_Acc: 93.803 Val_Loss: 0.1597  BEST VAL Loss: 0.1597  Val_Acc: 94.531

Epoch 52: Validation loss decreased (0.159651 --> 0.159432).  Saving model ...
	 Train_Loss: 0.1876 Train_Acc: 93.763 Val_Loss: 0.1594  BEST VAL Loss: 0.1594  Val_Acc: 94.320

Epoch 53: Validation loss decreased (0.159432 --> 0.159195).  Saving model ...
	 Train_Loss: 0.1875 Train_Acc: 93.096 Val_Loss: 0.1592  BEST VAL Loss: 0.1592  Val_Acc: 94.371

Epoch 54: Validation loss decreased (0.159195 --> 0.158940).  Saving model ...
	 Train_Loss: 0.1872 Train_Acc: 93.699 Val_Loss: 0.1589  BEST VAL Loss: 0.1589  Val_Acc: 94.489

Epoch 55: Validation loss decreased (0.158940 --> 0.158714).  Saving model ...
	 Train_Loss: 0.1869 Train_Acc: 93.643 Val_Loss: 0.1587  BEST VAL Loss: 0.1587  Val_Acc: 94.599

Epoch 56: Validation loss decreased (0.158714 --> 0.158447).  Saving model ...
	 Train_Loss: 0.1864 Train_Acc: 93.953 Val_Loss: 0.1584  BEST VAL Loss: 0.1584  Val_Acc: 94.493

Epoch 57: Validation loss decreased (0.158447 --> 0.158230).  Saving model ...
	 Train_Loss: 0.1861 Train_Acc: 93.760 Val_Loss: 0.1582  BEST VAL Loss: 0.1582  Val_Acc: 94.388

Epoch 58: Validation loss decreased (0.158230 --> 0.157961).  Saving model ...
	 Train_Loss: 0.1858 Train_Acc: 93.601 Val_Loss: 0.1580  BEST VAL Loss: 0.1580  Val_Acc: 94.489

Epoch 59: Validation loss decreased (0.157961 --> 0.157707).  Saving model ...
	 Train_Loss: 0.1854 Train_Acc: 93.833 Val_Loss: 0.1577  BEST VAL Loss: 0.1577  Val_Acc: 94.650

Epoch 60: Validation loss decreased (0.157707 --> 0.157542).  Saving model ...
	 Train_Loss: 0.1850 Train_Acc: 93.972 Val_Loss: 0.1575  BEST VAL Loss: 0.1575  Val_Acc: 94.413

Epoch 61: Validation loss decreased (0.157542 --> 0.157276).  Saving model ...
	 Train_Loss: 0.1846 Train_Acc: 93.998 Val_Loss: 0.1573  BEST VAL Loss: 0.1573  Val_Acc: 94.544

Epoch 62: Validation loss decreased (0.157276 --> 0.157101).  Saving model ...
	 Train_Loss: 0.1843 Train_Acc: 93.823 Val_Loss: 0.1571  BEST VAL Loss: 0.1571  Val_Acc: 94.438

Epoch 63: Validation loss decreased (0.157101 --> 0.156867).  Saving model ...
	 Train_Loss: 0.1840 Train_Acc: 93.766 Val_Loss: 0.1569  BEST VAL Loss: 0.1569  Val_Acc: 94.527

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.1837 Train_Acc: 93.618 Val_Loss: 0.1569  BEST VAL Loss: 0.1569  Val_Acc: 93.905

Epoch 65: Validation loss decreased (0.156867 --> 0.156755).  Saving model ...
	 Train_Loss: 0.1834 Train_Acc: 93.810 Val_Loss: 0.1568  BEST VAL Loss: 0.1568  Val_Acc: 94.553

Epoch 66: Validation loss decreased (0.156755 --> 0.156662).  Saving model ...
	 Train_Loss: 0.1831 Train_Acc: 93.773 Val_Loss: 0.1567  BEST VAL Loss: 0.1567  Val_Acc: 94.375

Epoch 67: Validation loss decreased (0.156662 --> 0.156483).  Saving model ...
	 Train_Loss: 0.1828 Train_Acc: 93.818 Val_Loss: 0.1565  BEST VAL Loss: 0.1565  Val_Acc: 94.417

Epoch 68: Validation loss decreased (0.156483 --> 0.156292).  Saving model ...
	 Train_Loss: 0.1826 Train_Acc: 93.729 Val_Loss: 0.1563  BEST VAL Loss: 0.1563  Val_Acc: 94.544

Epoch 69: Validation loss decreased (0.156292 --> 0.156087).  Saving model ...
	 Train_Loss: 0.1823 Train_Acc: 93.771 Val_Loss: 0.1561  BEST VAL Loss: 0.1561  Val_Acc: 94.527

Epoch 70: Validation loss decreased (0.156087 --> 0.155843).  Saving model ...
	 Train_Loss: 0.1821 Train_Acc: 93.744 Val_Loss: 0.1558  BEST VAL Loss: 0.1558  Val_Acc: 94.684

Epoch 71: Validation loss decreased (0.155843 --> 0.155746).  Saving model ...
	 Train_Loss: 0.1818 Train_Acc: 94.020 Val_Loss: 0.1557  BEST VAL Loss: 0.1557  Val_Acc: 94.265

Epoch 72: Validation loss decreased (0.155746 --> 0.155621).  Saving model ...
	 Train_Loss: 0.1816 Train_Acc: 93.767 Val_Loss: 0.1556  BEST VAL Loss: 0.1556  Val_Acc: 94.472

Epoch 73: Validation loss decreased (0.155621 --> 0.155461).  Saving model ...
	 Train_Loss: 0.1813 Train_Acc: 94.021 Val_Loss: 0.1555  BEST VAL Loss: 0.1555  Val_Acc: 94.658

Epoch 74: Validation loss decreased (0.155461 --> 0.155386).  Saving model ...
	 Train_Loss: 0.1810 Train_Acc: 93.891 Val_Loss: 0.1554  BEST VAL Loss: 0.1554  Val_Acc: 94.396

Epoch 75: Validation loss decreased (0.155386 --> 0.155205).  Saving model ...
	 Train_Loss: 0.1808 Train_Acc: 93.945 Val_Loss: 0.1552  BEST VAL Loss: 0.1552  Val_Acc: 94.658

Epoch 76: Validation loss decreased (0.155205 --> 0.155050).  Saving model ...
	 Train_Loss: 0.1805 Train_Acc: 94.074 Val_Loss: 0.1550  BEST VAL Loss: 0.1550  Val_Acc: 94.612

Epoch 77: Validation loss decreased (0.155050 --> 0.154870).  Saving model ...
	 Train_Loss: 0.1802 Train_Acc: 94.065 Val_Loss: 0.1549  BEST VAL Loss: 0.1549  Val_Acc: 94.565

Epoch 78: Validation loss decreased (0.154870 --> 0.154734).  Saving model ...
	 Train_Loss: 0.1799 Train_Acc: 94.069 Val_Loss: 0.1547  BEST VAL Loss: 0.1547  Val_Acc: 94.726

Epoch 79: Validation loss decreased (0.154734 --> 0.154662).  Saving model ...
	 Train_Loss: 0.1797 Train_Acc: 94.043 Val_Loss: 0.1547  BEST VAL Loss: 0.1547  Val_Acc: 94.311

Epoch 80: Validation loss decreased (0.154662 --> 0.154560).  Saving model ...
	 Train_Loss: 0.1795 Train_Acc: 93.893 Val_Loss: 0.1546  BEST VAL Loss: 0.1546  Val_Acc: 94.362

Epoch 81: Validation loss decreased (0.154560 --> 0.154350).  Saving model ...
	 Train_Loss: 0.1792 Train_Acc: 94.127 Val_Loss: 0.1543  BEST VAL Loss: 0.1543  Val_Acc: 94.722

Epoch 82: Validation loss decreased (0.154350 --> 0.154180).  Saving model ...
	 Train_Loss: 0.1789 Train_Acc: 94.094 Val_Loss: 0.1542  BEST VAL Loss: 0.1542  Val_Acc: 94.595

Epoch 83: Validation loss decreased (0.154180 --> 0.154064).  Saving model ...
	 Train_Loss: 0.1787 Train_Acc: 94.055 Val_Loss: 0.1541  BEST VAL Loss: 0.1541  Val_Acc: 94.519

Epoch 84: Validation loss decreased (0.154064 --> 0.153919).  Saving model ...
	 Train_Loss: 0.1785 Train_Acc: 93.835 Val_Loss: 0.1539  BEST VAL Loss: 0.1539  Val_Acc: 94.582

Epoch 85: Validation loss decreased (0.153919 --> 0.153842).  Saving model ...
	 Train_Loss: 0.1783 Train_Acc: 93.825 Val_Loss: 0.1538  BEST VAL Loss: 0.1538  Val_Acc: 94.434

Epoch 86: Validation loss decreased (0.153842 --> 0.153782).  Saving model ...
	 Train_Loss: 0.1781 Train_Acc: 93.922 Val_Loss: 0.1538  BEST VAL Loss: 0.1538  Val_Acc: 94.519

Epoch 87: Validation loss decreased (0.153782 --> 0.153618).  Saving model ...
	 Train_Loss: 0.1779 Train_Acc: 94.042 Val_Loss: 0.1536  BEST VAL Loss: 0.1536  Val_Acc: 94.730

Epoch 88: Validation loss decreased (0.153618 --> 0.153485).  Saving model ...
	 Train_Loss: 0.1778 Train_Acc: 93.608 Val_Loss: 0.1535  BEST VAL Loss: 0.1535  Val_Acc: 94.438

Epoch 89: Validation loss decreased (0.153485 --> 0.153341).  Saving model ...
	 Train_Loss: 0.1776 Train_Acc: 93.990 Val_Loss: 0.1533  BEST VAL Loss: 0.1533  Val_Acc: 94.768

Epoch 90: Validation loss decreased (0.153341 --> 0.153300).  Saving model ...
	 Train_Loss: 0.1775 Train_Acc: 93.895 Val_Loss: 0.1533  BEST VAL Loss: 0.1533  Val_Acc: 94.485

Epoch 91: Validation loss decreased (0.153300 --> 0.153243).  Saving model ...
	 Train_Loss: 0.1773 Train_Acc: 93.813 Val_Loss: 0.1532  BEST VAL Loss: 0.1532  Val_Acc: 94.527

Epoch 92: Validation loss decreased (0.153243 --> 0.153098).  Saving model ...
	 Train_Loss: 0.1771 Train_Acc: 93.955 Val_Loss: 0.1531  BEST VAL Loss: 0.1531  Val_Acc: 94.548

Epoch 93: Validation loss decreased (0.153098 --> 0.153020).  Saving model ...
	 Train_Loss: 0.1769 Train_Acc: 93.990 Val_Loss: 0.1530  BEST VAL Loss: 0.1530  Val_Acc: 94.713

Epoch 94: Validation loss decreased (0.153020 --> 0.152924).  Saving model ...
	 Train_Loss: 0.1767 Train_Acc: 94.061 Val_Loss: 0.1529  BEST VAL Loss: 0.1529  Val_Acc: 94.667

Epoch 95: Validation loss decreased (0.152924 --> 0.152790).  Saving model ...
	 Train_Loss: 0.1766 Train_Acc: 93.917 Val_Loss: 0.1528  BEST VAL Loss: 0.1528  Val_Acc: 94.781

Epoch 96: Validation loss decreased (0.152790 --> 0.152620).  Saving model ...
	 Train_Loss: 0.1765 Train_Acc: 93.772 Val_Loss: 0.1526  BEST VAL Loss: 0.1526  Val_Acc: 94.760

Epoch 97: Validation loss decreased (0.152620 --> 0.152543).  Saving model ...
	 Train_Loss: 0.1763 Train_Acc: 93.733 Val_Loss: 0.1525  BEST VAL Loss: 0.1525  Val_Acc: 94.654

Epoch 98: Validation loss decreased (0.152543 --> 0.152526).  Saving model ...
	 Train_Loss: 0.1761 Train_Acc: 94.033 Val_Loss: 0.1525  BEST VAL Loss: 0.1525  Val_Acc: 94.320

Epoch 99: Validation loss decreased (0.152526 --> 0.152447).  Saving model ...
	 Train_Loss: 0.1760 Train_Acc: 93.927 Val_Loss: 0.1524  BEST VAL Loss: 0.1524  Val_Acc: 94.553

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.54      0.54    100908
           1       0.47      0.46      0.46     88100

    accuracy                           0.50    189008
   macro avg       0.50      0.50      0.50    189008
weighted avg       0.50      0.50      0.50    189008

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.54      0.54      0.54     12614
           1       0.47      0.46      0.47     11012

    accuracy                           0.51     23626
   macro avg       0.50      0.50      0.50     23626
weighted avg       0.51      0.51      0.51     23626

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.54      0.54      0.54     12614
           1       0.47      0.47      0.47     11012

    accuracy                           0.51     23626
   macro avg       0.51      0.51      0.51     23626
weighted avg       0.51      0.51      0.51     23626

              precision    recall  f1-score   support

           0       0.54      0.54      0.54     12614
           1       0.47      0.47      0.47     11012

    accuracy                           0.51     23626
   macro avg       0.51      0.51      0.51     23626
weighted avg       0.51      0.51      0.51     23626

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.45      0.48     39877
           1       0.49      0.55      0.52     38332

    accuracy                           0.50     78209
   macro avg       0.50      0.50      0.50     78209
weighted avg       0.50      0.50      0.50     78209

              precision    recall  f1-score   support

           0       0.51      0.45      0.48     39877
           1       0.49      0.55      0.52     38332

    accuracy                           0.50     78209
   macro avg       0.50      0.50      0.50     78209
weighted avg       0.50      0.50      0.50     78209

completed
