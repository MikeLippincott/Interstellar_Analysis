[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '30d15bda'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e467754c'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'aea77e3a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '05c083c5'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Thapsigargin_10.000_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Thapsigargin_10.000_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (29199, 1276)
Number of total missing values across all columns: 58398
Data Subset Is Off
Wells held out for testing: ['E14' 'J20']
Wells to use for training, validation, and testing ['E15' 'L14' 'L15' 'J16' 'J17' 'J21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.477538).  Saving model ...
	 Train_Loss: 0.5832 Train_Acc: 58.823 Val_Loss: 0.4775  BEST VAL Loss: 0.4775  Val_Acc: 79.847

Epoch 1: Validation loss decreased (0.477538 --> 0.374922).  Saving model ...
	 Train_Loss: 0.4813 Train_Acc: 87.150 Val_Loss: 0.3749  BEST VAL Loss: 0.3749  Val_Acc: 93.508

Epoch 2: Validation loss decreased (0.374922 --> 0.312836).  Saving model ...
	 Train_Loss: 0.4058 Train_Acc: 91.681 Val_Loss: 0.3128  BEST VAL Loss: 0.3128  Val_Acc: 95.176

Epoch 3: Validation loss decreased (0.312836 --> 0.270250).  Saving model ...
	 Train_Loss: 0.3558 Train_Acc: 93.017 Val_Loss: 0.2702  BEST VAL Loss: 0.2702  Val_Acc: 95.672

Epoch 4: Validation loss decreased (0.270250 --> 0.241867).  Saving model ...
	 Train_Loss: 0.3202 Train_Acc: 93.705 Val_Loss: 0.2419  BEST VAL Loss: 0.2419  Val_Acc: 96.393

Epoch 5: Validation loss decreased (0.241867 --> 0.219506).  Saving model ...
	 Train_Loss: 0.2937 Train_Acc: 94.358 Val_Loss: 0.2195  BEST VAL Loss: 0.2195  Val_Acc: 97.024

Epoch 6: Validation loss decreased (0.219506 --> 0.202892).  Saving model ...
	 Train_Loss: 0.2726 Train_Acc: 94.860 Val_Loss: 0.2029  BEST VAL Loss: 0.2029  Val_Acc: 97.205

Epoch 7: Validation loss decreased (0.202892 --> 0.188482).  Saving model ...
	 Train_Loss: 0.2555 Train_Acc: 95.181 Val_Loss: 0.1885  BEST VAL Loss: 0.1885  Val_Acc: 97.430

Epoch 8: Validation loss decreased (0.188482 --> 0.176607).  Saving model ...
	 Train_Loss: 0.2416 Train_Acc: 95.452 Val_Loss: 0.1766  BEST VAL Loss: 0.1766  Val_Acc: 97.565

Epoch 9: Validation loss decreased (0.176607 --> 0.167855).  Saving model ...
	 Train_Loss: 0.2294 Train_Acc: 95.750 Val_Loss: 0.1679  BEST VAL Loss: 0.1679  Val_Acc: 97.746

Epoch 10: Validation loss decreased (0.167855 --> 0.158861).  Saving model ...
	 Train_Loss: 0.2188 Train_Acc: 95.936 Val_Loss: 0.1589  BEST VAL Loss: 0.1589  Val_Acc: 97.746

Epoch 11: Validation loss decreased (0.158861 --> 0.151298).  Saving model ...
	 Train_Loss: 0.2098 Train_Acc: 96.235 Val_Loss: 0.1513  BEST VAL Loss: 0.1513  Val_Acc: 97.836

Epoch 12: Validation loss decreased (0.151298 --> 0.144364).  Saving model ...
	 Train_Loss: 0.2019 Train_Acc: 96.269 Val_Loss: 0.1444  BEST VAL Loss: 0.1444  Val_Acc: 97.881

Epoch 13: Validation loss decreased (0.144364 --> 0.138572).  Saving model ...
	 Train_Loss: 0.1949 Train_Acc: 96.314 Val_Loss: 0.1386  BEST VAL Loss: 0.1386  Val_Acc: 97.926

Epoch 14: Validation loss decreased (0.138572 --> 0.133689).  Saving model ...
	 Train_Loss: 0.1884 Train_Acc: 96.579 Val_Loss: 0.1337  BEST VAL Loss: 0.1337  Val_Acc: 98.151

Epoch 15: Validation loss decreased (0.133689 --> 0.129163).  Saving model ...
	 Train_Loss: 0.1827 Train_Acc: 96.714 Val_Loss: 0.1292  BEST VAL Loss: 0.1292  Val_Acc: 98.061

Epoch 16: Validation loss decreased (0.129163 --> 0.124744).  Saving model ...
	 Train_Loss: 0.1774 Train_Acc: 96.669 Val_Loss: 0.1247  BEST VAL Loss: 0.1247  Val_Acc: 97.971

Epoch 17: Validation loss decreased (0.124744 --> 0.121171).  Saving model ...
	 Train_Loss: 0.1726 Train_Acc: 96.816 Val_Loss: 0.1212  BEST VAL Loss: 0.1212  Val_Acc: 97.971

Epoch 18: Validation loss decreased (0.121171 --> 0.117760).  Saving model ...
	 Train_Loss: 0.1680 Train_Acc: 96.928 Val_Loss: 0.1178  BEST VAL Loss: 0.1178  Val_Acc: 98.016

Epoch 19: Validation loss decreased (0.117760 --> 0.114628).  Saving model ...
	 Train_Loss: 0.1637 Train_Acc: 97.182 Val_Loss: 0.1146  BEST VAL Loss: 0.1146  Val_Acc: 97.971

Epoch 20: Validation loss decreased (0.114628 --> 0.111631).  Saving model ...
	 Train_Loss: 0.1599 Train_Acc: 96.957 Val_Loss: 0.1116  BEST VAL Loss: 0.1116  Val_Acc: 97.971

Epoch 21: Validation loss decreased (0.111631 --> 0.109035).  Saving model ...
	 Train_Loss: 0.1563 Train_Acc: 97.154 Val_Loss: 0.1090  BEST VAL Loss: 0.1090  Val_Acc: 98.151

Epoch 22: Validation loss decreased (0.109035 --> 0.106219).  Saving model ...
	 Train_Loss: 0.1528 Train_Acc: 97.221 Val_Loss: 0.1062  BEST VAL Loss: 0.1062  Val_Acc: 98.197

Epoch 23: Validation loss decreased (0.106219 --> 0.104096).  Saving model ...
	 Train_Loss: 0.1496 Train_Acc: 97.154 Val_Loss: 0.1041  BEST VAL Loss: 0.1041  Val_Acc: 98.197

Epoch 24: Validation loss decreased (0.104096 --> 0.102177).  Saving model ...
	 Train_Loss: 0.1465 Train_Acc: 97.385 Val_Loss: 0.1022  BEST VAL Loss: 0.1022  Val_Acc: 98.287

Epoch 25: Validation loss decreased (0.102177 --> 0.100606).  Saving model ...
	 Train_Loss: 0.1436 Train_Acc: 97.565 Val_Loss: 0.1006  BEST VAL Loss: 0.1006  Val_Acc: 98.242

Epoch 26: Validation loss decreased (0.100606 --> 0.098835).  Saving model ...
	 Train_Loss: 0.1408 Train_Acc: 97.554 Val_Loss: 0.0988  BEST VAL Loss: 0.0988  Val_Acc: 98.242

Epoch 27: Validation loss decreased (0.098835 --> 0.096898).  Saving model ...
	 Train_Loss: 0.1382 Train_Acc: 97.441 Val_Loss: 0.0969  BEST VAL Loss: 0.0969  Val_Acc: 98.242

Epoch 28: Validation loss decreased (0.096898 --> 0.095221).  Saving model ...
	 Train_Loss: 0.1356 Train_Acc: 97.599 Val_Loss: 0.0952  BEST VAL Loss: 0.0952  Val_Acc: 98.242

Epoch 29: Validation loss decreased (0.095221 --> 0.093564).  Saving model ...
	 Train_Loss: 0.1332 Train_Acc: 97.610 Val_Loss: 0.0936  BEST VAL Loss: 0.0936  Val_Acc: 98.287

Epoch 30: Validation loss decreased (0.093564 --> 0.092000).  Saving model ...
	 Train_Loss: 0.1309 Train_Acc: 97.678 Val_Loss: 0.0920  BEST VAL Loss: 0.0920  Val_Acc: 98.287

Epoch 31: Validation loss decreased (0.092000 --> 0.090398).  Saving model ...
	 Train_Loss: 0.1287 Train_Acc: 97.667 Val_Loss: 0.0904  BEST VAL Loss: 0.0904  Val_Acc: 98.287

Epoch 32: Validation loss decreased (0.090398 --> 0.089159).  Saving model ...
	 Train_Loss: 0.1267 Train_Acc: 97.689 Val_Loss: 0.0892  BEST VAL Loss: 0.0892  Val_Acc: 98.287

Epoch 33: Validation loss decreased (0.089159 --> 0.087969).  Saving model ...
	 Train_Loss: 0.1247 Train_Acc: 97.723 Val_Loss: 0.0880  BEST VAL Loss: 0.0880  Val_Acc: 98.377

Epoch 34: Validation loss decreased (0.087969 --> 0.086672).  Saving model ...
	 Train_Loss: 0.1227 Train_Acc: 97.847 Val_Loss: 0.0867  BEST VAL Loss: 0.0867  Val_Acc: 98.377

Epoch 35: Validation loss decreased (0.086672 --> 0.085378).  Saving model ...
	 Train_Loss: 0.1208 Train_Acc: 97.864 Val_Loss: 0.0854  BEST VAL Loss: 0.0854  Val_Acc: 98.332

Epoch 36: Validation loss decreased (0.085378 --> 0.084333).  Saving model ...
	 Train_Loss: 0.1190 Train_Acc: 97.943 Val_Loss: 0.0843  BEST VAL Loss: 0.0843  Val_Acc: 98.332

Epoch 37: Validation loss decreased (0.084333 --> 0.083188).  Saving model ...
	 Train_Loss: 0.1173 Train_Acc: 97.892 Val_Loss: 0.0832  BEST VAL Loss: 0.0832  Val_Acc: 98.377

Epoch 38: Validation loss decreased (0.083188 --> 0.082055).  Saving model ...
	 Train_Loss: 0.1156 Train_Acc: 98.033 Val_Loss: 0.0821  BEST VAL Loss: 0.0821  Val_Acc: 98.287

Epoch 39: Validation loss decreased (0.082055 --> 0.081206).  Saving model ...
	 Train_Loss: 0.1139 Train_Acc: 98.056 Val_Loss: 0.0812  BEST VAL Loss: 0.0812  Val_Acc: 98.332

Epoch 40: Validation loss decreased (0.081206 --> 0.080244).  Saving model ...
	 Train_Loss: 0.1124 Train_Acc: 97.999 Val_Loss: 0.0802  BEST VAL Loss: 0.0802  Val_Acc: 98.332

Epoch 41: Validation loss decreased (0.080244 --> 0.079312).  Saving model ...
	 Train_Loss: 0.1109 Train_Acc: 97.965 Val_Loss: 0.0793  BEST VAL Loss: 0.0793  Val_Acc: 98.332

Epoch 42: Validation loss decreased (0.079312 --> 0.078837).  Saving model ...
	 Train_Loss: 0.1094 Train_Acc: 98.118 Val_Loss: 0.0788  BEST VAL Loss: 0.0788  Val_Acc: 98.422

Epoch 43: Validation loss decreased (0.078837 --> 0.078026).  Saving model ...
	 Train_Loss: 0.1080 Train_Acc: 98.129 Val_Loss: 0.0780  BEST VAL Loss: 0.0780  Val_Acc: 98.422

Epoch 44: Validation loss decreased (0.078026 --> 0.077256).  Saving model ...
	 Train_Loss: 0.1066 Train_Acc: 98.411 Val_Loss: 0.0773  BEST VAL Loss: 0.0773  Val_Acc: 98.332

Epoch 45: Validation loss decreased (0.077256 --> 0.076438).  Saving model ...
	 Train_Loss: 0.1052 Train_Acc: 98.456 Val_Loss: 0.0764  BEST VAL Loss: 0.0764  Val_Acc: 98.332

Epoch 46: Validation loss decreased (0.076438 --> 0.075605).  Saving model ...
	 Train_Loss: 0.1039 Train_Acc: 98.630 Val_Loss: 0.0756  BEST VAL Loss: 0.0756  Val_Acc: 98.377

Epoch 47: Validation loss decreased (0.075605 --> 0.074918).  Saving model ...
	 Train_Loss: 0.1027 Train_Acc: 98.568 Val_Loss: 0.0749  BEST VAL Loss: 0.0749  Val_Acc: 98.422

Epoch 48: Validation loss decreased (0.074918 --> 0.074363).  Saving model ...
	 Train_Loss: 0.1014 Train_Acc: 98.704 Val_Loss: 0.0744  BEST VAL Loss: 0.0744  Val_Acc: 98.422

Epoch 49: Validation loss decreased (0.074363 --> 0.073754).  Saving model ...
	 Train_Loss: 0.1002 Train_Acc: 98.529 Val_Loss: 0.0738  BEST VAL Loss: 0.0738  Val_Acc: 98.422

Epoch 50: Validation loss decreased (0.073754 --> 0.073206).  Saving model ...
	 Train_Loss: 0.0991 Train_Acc: 98.580 Val_Loss: 0.0732  BEST VAL Loss: 0.0732  Val_Acc: 98.422

Epoch 51: Validation loss decreased (0.073206 --> 0.072611).  Saving model ...
	 Train_Loss: 0.0979 Train_Acc: 98.715 Val_Loss: 0.0726  BEST VAL Loss: 0.0726  Val_Acc: 98.422

Epoch 52: Validation loss decreased (0.072611 --> 0.072063).  Saving model ...
	 Train_Loss: 0.0968 Train_Acc: 98.721 Val_Loss: 0.0721  BEST VAL Loss: 0.0721  Val_Acc: 98.467

Epoch 53: Validation loss decreased (0.072063 --> 0.071482).  Saving model ...
	 Train_Loss: 0.0958 Train_Acc: 98.619 Val_Loss: 0.0715  BEST VAL Loss: 0.0715  Val_Acc: 98.512

Epoch 54: Validation loss decreased (0.071482 --> 0.071039).  Saving model ...
	 Train_Loss: 0.0947 Train_Acc: 98.630 Val_Loss: 0.0710  BEST VAL Loss: 0.0710  Val_Acc: 98.512

Epoch 55: Validation loss decreased (0.071039 --> 0.070447).  Saving model ...
	 Train_Loss: 0.0937 Train_Acc: 98.867 Val_Loss: 0.0704  BEST VAL Loss: 0.0704  Val_Acc: 98.557

Epoch 56: Validation loss decreased (0.070447 --> 0.069901).  Saving model ...
	 Train_Loss: 0.0927 Train_Acc: 98.754 Val_Loss: 0.0699  BEST VAL Loss: 0.0699  Val_Acc: 98.557

Epoch 57: Validation loss decreased (0.069901 --> 0.069446).  Saving model ...
	 Train_Loss: 0.0918 Train_Acc: 98.709 Val_Loss: 0.0694  BEST VAL Loss: 0.0694  Val_Acc: 98.512

Epoch 58: Validation loss decreased (0.069446 --> 0.068889).  Saving model ...
	 Train_Loss: 0.0908 Train_Acc: 98.777 Val_Loss: 0.0689  BEST VAL Loss: 0.0689  Val_Acc: 98.602

Epoch 59: Validation loss decreased (0.068889 --> 0.068346).  Saving model ...
	 Train_Loss: 0.0899 Train_Acc: 98.822 Val_Loss: 0.0683  BEST VAL Loss: 0.0683  Val_Acc: 98.557

Epoch 60: Validation loss decreased (0.068346 --> 0.067963).  Saving model ...
	 Train_Loss: 0.0890 Train_Acc: 98.788 Val_Loss: 0.0680  BEST VAL Loss: 0.0680  Val_Acc: 98.602

Epoch 61: Validation loss decreased (0.067963 --> 0.067557).  Saving model ...
	 Train_Loss: 0.0882 Train_Acc: 98.828 Val_Loss: 0.0676  BEST VAL Loss: 0.0676  Val_Acc: 98.557

Epoch 62: Validation loss decreased (0.067557 --> 0.067065).  Saving model ...
	 Train_Loss: 0.0873 Train_Acc: 98.783 Val_Loss: 0.0671  BEST VAL Loss: 0.0671  Val_Acc: 98.647

Epoch 63: Validation loss decreased (0.067065 --> 0.066643).  Saving model ...
	 Train_Loss: 0.0865 Train_Acc: 98.828 Val_Loss: 0.0666  BEST VAL Loss: 0.0666  Val_Acc: 98.602

Epoch 64: Validation loss decreased (0.066643 --> 0.066181).  Saving model ...
	 Train_Loss: 0.0857 Train_Acc: 98.901 Val_Loss: 0.0662  BEST VAL Loss: 0.0662  Val_Acc: 98.512

Epoch 65: Validation loss decreased (0.066181 --> 0.065733).  Saving model ...
	 Train_Loss: 0.0849 Train_Acc: 98.884 Val_Loss: 0.0657  BEST VAL Loss: 0.0657  Val_Acc: 98.647

Epoch 66: Validation loss decreased (0.065733 --> 0.065484).  Saving model ...
	 Train_Loss: 0.0841 Train_Acc: 98.924 Val_Loss: 0.0655  BEST VAL Loss: 0.0655  Val_Acc: 98.647

Epoch 67: Validation loss decreased (0.065484 --> 0.065148).  Saving model ...
	 Train_Loss: 0.0833 Train_Acc: 99.014 Val_Loss: 0.0651  BEST VAL Loss: 0.0651  Val_Acc: 98.693

Epoch 68: Validation loss decreased (0.065148 --> 0.064787).  Saving model ...
	 Train_Loss: 0.0826 Train_Acc: 98.895 Val_Loss: 0.0648  BEST VAL Loss: 0.0648  Val_Acc: 98.647

Epoch 69: Validation loss decreased (0.064787 --> 0.064475).  Saving model ...
	 Train_Loss: 0.0818 Train_Acc: 98.974 Val_Loss: 0.0645  BEST VAL Loss: 0.0645  Val_Acc: 98.602

Epoch 70: Validation loss decreased (0.064475 --> 0.064076).  Saving model ...
	 Train_Loss: 0.0811 Train_Acc: 98.991 Val_Loss: 0.0641  BEST VAL Loss: 0.0641  Val_Acc: 98.602

Epoch 71: Validation loss decreased (0.064076 --> 0.063762).  Saving model ...
	 Train_Loss: 0.0804 Train_Acc: 99.098 Val_Loss: 0.0638  BEST VAL Loss: 0.0638  Val_Acc: 98.647

Epoch 72: Validation loss decreased (0.063762 --> 0.063567).  Saving model ...
	 Train_Loss: 0.0797 Train_Acc: 98.974 Val_Loss: 0.0636  BEST VAL Loss: 0.0636  Val_Acc: 98.647

Epoch 73: Validation loss decreased (0.063567 --> 0.063306).  Saving model ...
	 Train_Loss: 0.0790 Train_Acc: 99.014 Val_Loss: 0.0633  BEST VAL Loss: 0.0633  Val_Acc: 98.557

Epoch 74: Validation loss decreased (0.063306 --> 0.063008).  Saving model ...
	 Train_Loss: 0.0784 Train_Acc: 99.014 Val_Loss: 0.0630  BEST VAL Loss: 0.0630  Val_Acc: 98.602

Epoch 75: Validation loss decreased (0.063008 --> 0.062684).  Saving model ...
	 Train_Loss: 0.0777 Train_Acc: 99.002 Val_Loss: 0.0627  BEST VAL Loss: 0.0627  Val_Acc: 98.602

Epoch 76: Validation loss decreased (0.062684 --> 0.062407).  Saving model ...
	 Train_Loss: 0.0771 Train_Acc: 98.991 Val_Loss: 0.0624  BEST VAL Loss: 0.0624  Val_Acc: 98.602

Epoch 77: Validation loss decreased (0.062407 --> 0.062132).  Saving model ...
	 Train_Loss: 0.0764 Train_Acc: 99.138 Val_Loss: 0.0621  BEST VAL Loss: 0.0621  Val_Acc: 98.512

Epoch 78: Validation loss decreased (0.062132 --> 0.061810).  Saving model ...
	 Train_Loss: 0.0758 Train_Acc: 99.064 Val_Loss: 0.0618  BEST VAL Loss: 0.0618  Val_Acc: 98.647

Epoch 79: Validation loss decreased (0.061810 --> 0.061701).  Saving model ...
	 Train_Loss: 0.0752 Train_Acc: 99.008 Val_Loss: 0.0617  BEST VAL Loss: 0.0617  Val_Acc: 98.512

Epoch 80: Validation loss decreased (0.061701 --> 0.061406).  Saving model ...
	 Train_Loss: 0.0746 Train_Acc: 99.200 Val_Loss: 0.0614  BEST VAL Loss: 0.0614  Val_Acc: 98.512

Epoch 81: Validation loss decreased (0.061406 --> 0.061275).  Saving model ...
	 Train_Loss: 0.0740 Train_Acc: 99.267 Val_Loss: 0.0613  BEST VAL Loss: 0.0613  Val_Acc: 98.557

Epoch 82: Validation loss decreased (0.061275 --> 0.061010).  Saving model ...
	 Train_Loss: 0.0735 Train_Acc: 99.143 Val_Loss: 0.0610  BEST VAL Loss: 0.0610  Val_Acc: 98.647

Epoch 83: Validation loss decreased (0.061010 --> 0.060865).  Saving model ...
	 Train_Loss: 0.0729 Train_Acc: 99.149 Val_Loss: 0.0609  BEST VAL Loss: 0.0609  Val_Acc: 98.557

Epoch 84: Validation loss decreased (0.060865 --> 0.060540).  Saving model ...
	 Train_Loss: 0.0724 Train_Acc: 99.138 Val_Loss: 0.0605  BEST VAL Loss: 0.0605  Val_Acc: 98.602

Epoch 85: Validation loss decreased (0.060540 --> 0.060393).  Saving model ...
	 Train_Loss: 0.0718 Train_Acc: 99.205 Val_Loss: 0.0604  BEST VAL Loss: 0.0604  Val_Acc: 98.693

Epoch 86: Validation loss decreased (0.060393 --> 0.060166).  Saving model ...
	 Train_Loss: 0.0713 Train_Acc: 99.188 Val_Loss: 0.0602  BEST VAL Loss: 0.0602  Val_Acc: 98.693

Epoch 87: Validation loss decreased (0.060166 --> 0.059946).  Saving model ...
	 Train_Loss: 0.0708 Train_Acc: 99.143 Val_Loss: 0.0599  BEST VAL Loss: 0.0599  Val_Acc: 98.602

Epoch 88: Validation loss decreased (0.059946 --> 0.059730).  Saving model ...
	 Train_Loss: 0.0703 Train_Acc: 99.239 Val_Loss: 0.0597  BEST VAL Loss: 0.0597  Val_Acc: 98.693

Epoch 89: Validation loss decreased (0.059730 --> 0.059561).  Saving model ...
	 Train_Loss: 0.0697 Train_Acc: 99.172 Val_Loss: 0.0596  BEST VAL Loss: 0.0596  Val_Acc: 98.647

Epoch 90: Validation loss decreased (0.059561 --> 0.059410).  Saving model ...
	 Train_Loss: 0.0693 Train_Acc: 99.318 Val_Loss: 0.0594  BEST VAL Loss: 0.0594  Val_Acc: 98.647

Epoch 91: Validation loss decreased (0.059410 --> 0.059189).  Saving model ...
	 Train_Loss: 0.0688 Train_Acc: 99.126 Val_Loss: 0.0592  BEST VAL Loss: 0.0592  Val_Acc: 98.693

Epoch 92: Validation loss decreased (0.059189 --> 0.059067).  Saving model ...
	 Train_Loss: 0.0683 Train_Acc: 99.228 Val_Loss: 0.0591  BEST VAL Loss: 0.0591  Val_Acc: 98.602

Epoch 93: Validation loss decreased (0.059067 --> 0.058917).  Saving model ...
	 Train_Loss: 0.0678 Train_Acc: 99.205 Val_Loss: 0.0589  BEST VAL Loss: 0.0589  Val_Acc: 98.693

Epoch 94: Validation loss decreased (0.058917 --> 0.058679).  Saving model ...
	 Train_Loss: 0.0674 Train_Acc: 99.205 Val_Loss: 0.0587  BEST VAL Loss: 0.0587  Val_Acc: 98.647

Epoch 95: Validation loss decreased (0.058679 --> 0.058490).  Saving model ...
	 Train_Loss: 0.0669 Train_Acc: 99.228 Val_Loss: 0.0585  BEST VAL Loss: 0.0585  Val_Acc: 98.647

Epoch 96: Validation loss decreased (0.058490 --> 0.058264).  Saving model ...
	 Train_Loss: 0.0665 Train_Acc: 99.324 Val_Loss: 0.0583  BEST VAL Loss: 0.0583  Val_Acc: 98.602

Epoch 97: Validation loss decreased (0.058264 --> 0.058088).  Saving model ...
	 Train_Loss: 0.0660 Train_Acc: 99.312 Val_Loss: 0.0581  BEST VAL Loss: 0.0581  Val_Acc: 98.693

Epoch 98: Validation loss decreased (0.058088 --> 0.057976).  Saving model ...
	 Train_Loss: 0.0656 Train_Acc: 99.262 Val_Loss: 0.0580  BEST VAL Loss: 0.0580  Val_Acc: 98.647

Epoch 99: Validation loss decreased (0.057976 --> 0.057778).  Saving model ...
	 Train_Loss: 0.0651 Train_Acc: 99.295 Val_Loss: 0.0578  BEST VAL Loss: 0.0578  Val_Acc: 98.693

Thapsigargin_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.56      0.56      0.56      9891
           1       0.45      0.45      0.45      7852

    accuracy                           0.51     17743
   macro avg       0.50      0.50      0.50     17743
weighted avg       0.51      0.51      0.51     17743

Thapsigargin_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.55      0.55      1237
           1       0.43      0.43      0.43       981

    accuracy                           0.50      2218
   macro avg       0.49      0.49      0.49      2218
weighted avg       0.50      0.50      0.50      2218

Thapsigargin_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.56      0.56      0.56      1237
           1       0.44      0.44      0.44       981

    accuracy                           0.51      2218
   macro avg       0.50      0.50      0.50      2218
weighted avg       0.51      0.51      0.51      2218

              precision    recall  f1-score   support

           0       0.56      0.56      0.56      1237
           1       0.44      0.44      0.44       981

    accuracy                           0.51      2218
   macro avg       0.50      0.50      0.50      2218
weighted avg       0.51      0.51      0.51      2218

Thapsigargin_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.50      0.51      3622
           1       0.48      0.50      0.49      3398

    accuracy                           0.50      7020
   macro avg       0.50      0.50      0.50      7020
weighted avg       0.50      0.50      0.50      7020

              precision    recall  f1-score   support

           0       0.51      0.50      0.51      3622
           1       0.48      0.50      0.49      3398

    accuracy                           0.50      7020
   macro avg       0.50      0.50      0.50      7020
weighted avg       0.50      0.50      0.50      7020

completed
