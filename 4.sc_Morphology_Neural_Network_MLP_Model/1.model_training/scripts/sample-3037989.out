[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ae622e78'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'dd85d291'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '78f2b156'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '2d15e5db'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: H2O2_100.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['H2O2_100.000_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (43118, 1276)
Number of total missing values across all columns: 53800
Data Subset Is Off
Wells held out for testing: ['H22' 'K16']
Wells to use for training, validation, and testing ['H18' 'H19' 'H23' 'K17' 'I18' 'I19' 'K20' 'K21' 'I22' 'I23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.566275).  Saving model ...
	 Train_Loss: 0.6267 Train_Acc: 71.917 Val_Loss: 0.5663  BEST VAL Loss: 0.5663  Val_Acc: 83.271

Epoch 1: Validation loss decreased (0.566275 --> 0.533557).  Saving model ...
	 Train_Loss: 0.5901 Train_Acc: 78.109 Val_Loss: 0.5336  BEST VAL Loss: 0.5336  Val_Acc: 85.920

Epoch 2: Validation loss decreased (0.533557 --> 0.507350).  Saving model ...
	 Train_Loss: 0.5645 Train_Acc: 79.408 Val_Loss: 0.5074  BEST VAL Loss: 0.5074  Val_Acc: 87.734

Epoch 3: Validation loss decreased (0.507350 --> 0.485613).  Saving model ...
	 Train_Loss: 0.5436 Train_Acc: 80.611 Val_Loss: 0.4856  BEST VAL Loss: 0.4856  Val_Acc: 88.540

Epoch 4: Validation loss decreased (0.485613 --> 0.466038).  Saving model ...
	 Train_Loss: 0.5265 Train_Acc: 81.205 Val_Loss: 0.4660  BEST VAL Loss: 0.4660  Val_Acc: 89.433

Epoch 5: Validation loss decreased (0.466038 --> 0.449499).  Saving model ...
	 Train_Loss: 0.5109 Train_Acc: 81.964 Val_Loss: 0.4495  BEST VAL Loss: 0.4495  Val_Acc: 89.375

Epoch 6: Validation loss decreased (0.449499 --> 0.433496).  Saving model ...
	 Train_Loss: 0.4957 Train_Acc: 84.398 Val_Loss: 0.4335  BEST VAL Loss: 0.4335  Val_Acc: 89.980

Epoch 7: Validation loss decreased (0.433496 --> 0.418427).  Saving model ...
	 Train_Loss: 0.4823 Train_Acc: 85.604 Val_Loss: 0.4184  BEST VAL Loss: 0.4184  Val_Acc: 90.441

Epoch 8: Validation loss decreased (0.418427 --> 0.405411).  Saving model ...
	 Train_Loss: 0.4699 Train_Acc: 86.453 Val_Loss: 0.4054  BEST VAL Loss: 0.4054  Val_Acc: 90.844

Epoch 9: Validation loss decreased (0.405411 --> 0.393816).  Saving model ...
	 Train_Loss: 0.4585 Train_Acc: 87.213 Val_Loss: 0.3938  BEST VAL Loss: 0.3938  Val_Acc: 91.420

Epoch 10: Validation loss decreased (0.393816 --> 0.383240).  Saving model ...
	 Train_Loss: 0.4483 Train_Acc: 87.551 Val_Loss: 0.3832  BEST VAL Loss: 0.3832  Val_Acc: 91.189

Epoch 11: Validation loss decreased (0.383240 --> 0.373534).  Saving model ...
	 Train_Loss: 0.4396 Train_Acc: 87.623 Val_Loss: 0.3735  BEST VAL Loss: 0.3735  Val_Acc: 91.736

Epoch 12: Validation loss decreased (0.373534 --> 0.366290).  Saving model ...
	 Train_Loss: 0.4314 Train_Acc: 87.904 Val_Loss: 0.3663  BEST VAL Loss: 0.3663  Val_Acc: 90.181

Epoch 13: Validation loss decreased (0.366290 --> 0.359342).  Saving model ...
	 Train_Loss: 0.4239 Train_Acc: 88.178 Val_Loss: 0.3593  BEST VAL Loss: 0.3593  Val_Acc: 91.045

Epoch 14: Validation loss decreased (0.359342 --> 0.352175).  Saving model ...
	 Train_Loss: 0.4171 Train_Acc: 88.451 Val_Loss: 0.3522  BEST VAL Loss: 0.3522  Val_Acc: 91.736

Epoch 15: Validation loss decreased (0.352175 --> 0.345769).  Saving model ...
	 Train_Loss: 0.4108 Train_Acc: 88.552 Val_Loss: 0.3458  BEST VAL Loss: 0.3458  Val_Acc: 92.082

Epoch 16: Validation loss decreased (0.345769 --> 0.339683).  Saving model ...
	 Train_Loss: 0.4046 Train_Acc: 89.085 Val_Loss: 0.3397  BEST VAL Loss: 0.3397  Val_Acc: 92.370

Epoch 17: Validation loss decreased (0.339683 --> 0.334058).  Saving model ...
	 Train_Loss: 0.3991 Train_Acc: 89.052 Val_Loss: 0.3341  BEST VAL Loss: 0.3341  Val_Acc: 92.370

Epoch 18: Validation loss decreased (0.334058 --> 0.330132).  Saving model ...
	 Train_Loss: 0.3939 Train_Acc: 89.358 Val_Loss: 0.3301  BEST VAL Loss: 0.3301  Val_Acc: 91.132

Epoch 19: Validation loss decreased (0.330132 --> 0.325251).  Saving model ...
	 Train_Loss: 0.3895 Train_Acc: 88.970 Val_Loss: 0.3253  BEST VAL Loss: 0.3253  Val_Acc: 92.283

Epoch 20: Validation loss decreased (0.325251 --> 0.320868).  Saving model ...
	 Train_Loss: 0.3850 Train_Acc: 89.740 Val_Loss: 0.3209  BEST VAL Loss: 0.3209  Val_Acc: 92.485

Epoch 21: Validation loss decreased (0.320868 --> 0.316797).  Saving model ...
	 Train_Loss: 0.3808 Train_Acc: 89.715 Val_Loss: 0.3168  BEST VAL Loss: 0.3168  Val_Acc: 92.197

Epoch 22: Validation loss decreased (0.316797 --> 0.313130).  Saving model ...
	 Train_Loss: 0.3767 Train_Acc: 89.916 Val_Loss: 0.3131  BEST VAL Loss: 0.3131  Val_Acc: 92.024

Epoch 23: Validation loss decreased (0.313130 --> 0.310282).  Saving model ...
	 Train_Loss: 0.3730 Train_Acc: 89.978 Val_Loss: 0.3103  BEST VAL Loss: 0.3103  Val_Acc: 91.650

Epoch 24: Validation loss decreased (0.310282 --> 0.306895).  Saving model ...
	 Train_Loss: 0.3693 Train_Acc: 90.233 Val_Loss: 0.3069  BEST VAL Loss: 0.3069  Val_Acc: 92.341

Epoch 25: Validation loss decreased (0.306895 --> 0.303765).  Saving model ...
	 Train_Loss: 0.3659 Train_Acc: 90.219 Val_Loss: 0.3038  BEST VAL Loss: 0.3038  Val_Acc: 92.341

Epoch 26: Validation loss decreased (0.303765 --> 0.300557).  Saving model ...
	 Train_Loss: 0.3627 Train_Acc: 90.413 Val_Loss: 0.3006  BEST VAL Loss: 0.3006  Val_Acc: 92.974

Epoch 27: Validation loss decreased (0.300557 --> 0.297606).  Saving model ...
	 Train_Loss: 0.3595 Train_Acc: 90.341 Val_Loss: 0.2976  BEST VAL Loss: 0.2976  Val_Acc: 92.686

Epoch 28: Validation loss decreased (0.297606 --> 0.294715).  Saving model ...
	 Train_Loss: 0.3565 Train_Acc: 90.586 Val_Loss: 0.2947  BEST VAL Loss: 0.2947  Val_Acc: 93.118

Epoch 29: Validation loss decreased (0.294715 --> 0.292271).  Saving model ...
	 Train_Loss: 0.3538 Train_Acc: 90.539 Val_Loss: 0.2923  BEST VAL Loss: 0.2923  Val_Acc: 92.946

Epoch 30: Validation loss decreased (0.292271 --> 0.289827).  Saving model ...
	 Train_Loss: 0.3511 Train_Acc: 90.802 Val_Loss: 0.2898  BEST VAL Loss: 0.2898  Val_Acc: 92.571

Epoch 31: Validation loss decreased (0.289827 --> 0.287795).  Saving model ...
	 Train_Loss: 0.3485 Train_Acc: 90.892 Val_Loss: 0.2878  BEST VAL Loss: 0.2878  Val_Acc: 92.283

Epoch 32: Validation loss decreased (0.287795 --> 0.286329).  Saving model ...
	 Train_Loss: 0.3461 Train_Acc: 90.831 Val_Loss: 0.2863  BEST VAL Loss: 0.2863  Val_Acc: 92.139

Epoch 33: Validation loss decreased (0.286329 --> 0.284519).  Saving model ...
	 Train_Loss: 0.3437 Train_Acc: 90.939 Val_Loss: 0.2845  BEST VAL Loss: 0.2845  Val_Acc: 92.802

Epoch 34: Validation loss decreased (0.284519 --> 0.282547).  Saving model ...
	 Train_Loss: 0.3415 Train_Acc: 90.953 Val_Loss: 0.2825  BEST VAL Loss: 0.2825  Val_Acc: 92.658

Epoch 35: Validation loss decreased (0.282547 --> 0.280910).  Saving model ...
	 Train_Loss: 0.3391 Train_Acc: 91.353 Val_Loss: 0.2809  BEST VAL Loss: 0.2809  Val_Acc: 92.773

Epoch 36: Validation loss decreased (0.280910 --> 0.279203).  Saving model ...
	 Train_Loss: 0.3371 Train_Acc: 91.144 Val_Loss: 0.2792  BEST VAL Loss: 0.2792  Val_Acc: 93.032

Epoch 37: Validation loss decreased (0.279203 --> 0.277746).  Saving model ...
	 Train_Loss: 0.3353 Train_Acc: 90.813 Val_Loss: 0.2777  BEST VAL Loss: 0.2777  Val_Acc: 92.686

Epoch 38: Validation loss decreased (0.277746 --> 0.276288).  Saving model ...
	 Train_Loss: 0.3332 Train_Acc: 91.335 Val_Loss: 0.2763  BEST VAL Loss: 0.2763  Val_Acc: 92.744

Epoch 39: Validation loss decreased (0.276288 --> 0.274545).  Saving model ...
	 Train_Loss: 0.3313 Train_Acc: 91.342 Val_Loss: 0.2745  BEST VAL Loss: 0.2745  Val_Acc: 93.234

Epoch 40: Validation loss decreased (0.274545 --> 0.273350).  Saving model ...
	 Train_Loss: 0.3293 Train_Acc: 91.468 Val_Loss: 0.2733  BEST VAL Loss: 0.2733  Val_Acc: 92.658

Epoch 41: Validation loss decreased (0.273350 --> 0.272296).  Saving model ...
	 Train_Loss: 0.3275 Train_Acc: 91.356 Val_Loss: 0.2723  BEST VAL Loss: 0.2723  Val_Acc: 92.571

Epoch 42: Validation loss decreased (0.272296 --> 0.271147).  Saving model ...
	 Train_Loss: 0.3259 Train_Acc: 91.457 Val_Loss: 0.2711  BEST VAL Loss: 0.2711  Val_Acc: 92.686

Epoch 43: Validation loss decreased (0.271147 --> 0.269896).  Saving model ...
	 Train_Loss: 0.3241 Train_Acc: 91.655 Val_Loss: 0.2699  BEST VAL Loss: 0.2699  Val_Acc: 93.176

Epoch 44: Validation loss decreased (0.269896 --> 0.268734).  Saving model ...
	 Train_Loss: 0.3228 Train_Acc: 90.928 Val_Loss: 0.2687  BEST VAL Loss: 0.2687  Val_Acc: 93.090

Epoch 45: Validation loss decreased (0.268734 --> 0.267583).  Saving model ...
	 Train_Loss: 0.3212 Train_Acc: 91.673 Val_Loss: 0.2676  BEST VAL Loss: 0.2676  Val_Acc: 93.377

Epoch 46: Validation loss decreased (0.267583 --> 0.266475).  Saving model ...
	 Train_Loss: 0.3197 Train_Acc: 91.785 Val_Loss: 0.2665  BEST VAL Loss: 0.2665  Val_Acc: 93.147

Epoch 47: Validation loss decreased (0.266475 --> 0.265918).  Saving model ...
	 Train_Loss: 0.3183 Train_Acc: 91.608 Val_Loss: 0.2659  BEST VAL Loss: 0.2659  Val_Acc: 91.967

Epoch 48: Validation loss decreased (0.265918 --> 0.264929).  Saving model ...
	 Train_Loss: 0.3167 Train_Acc: 92.098 Val_Loss: 0.2649  BEST VAL Loss: 0.2649  Val_Acc: 93.262

Epoch 49: Validation loss decreased (0.264929 --> 0.264268).  Saving model ...
	 Train_Loss: 0.3152 Train_Acc: 92.116 Val_Loss: 0.2643  BEST VAL Loss: 0.2643  Val_Acc: 92.283

Epoch 50: Validation loss decreased (0.264268 --> 0.263147).  Saving model ...
	 Train_Loss: 0.3137 Train_Acc: 92.148 Val_Loss: 0.2631  BEST VAL Loss: 0.2631  Val_Acc: 93.464

Epoch 51: Validation loss decreased (0.263147 --> 0.262362).  Saving model ...
	 Train_Loss: 0.3123 Train_Acc: 91.997 Val_Loss: 0.2624  BEST VAL Loss: 0.2624  Val_Acc: 93.061

Epoch 52: Validation loss decreased (0.262362 --> 0.261626).  Saving model ...
	 Train_Loss: 0.3111 Train_Acc: 91.878 Val_Loss: 0.2616  BEST VAL Loss: 0.2616  Val_Acc: 93.090

Epoch 53: Validation loss decreased (0.261626 --> 0.261014).  Saving model ...
	 Train_Loss: 0.3097 Train_Acc: 92.195 Val_Loss: 0.2610  BEST VAL Loss: 0.2610  Val_Acc: 93.032

Epoch 54: Validation loss decreased (0.261014 --> 0.260465).  Saving model ...
	 Train_Loss: 0.3084 Train_Acc: 92.364 Val_Loss: 0.2605  BEST VAL Loss: 0.2605  Val_Acc: 92.399

Epoch 55: Validation loss decreased (0.260465 --> 0.259848).  Saving model ...
	 Train_Loss: 0.3072 Train_Acc: 92.004 Val_Loss: 0.2598  BEST VAL Loss: 0.2598  Val_Acc: 92.830

Epoch 56: Validation loss decreased (0.259848 --> 0.259451).  Saving model ...
	 Train_Loss: 0.3059 Train_Acc: 92.476 Val_Loss: 0.2595  BEST VAL Loss: 0.2595  Val_Acc: 92.283

Epoch 57: Validation loss decreased (0.259451 --> 0.258866).  Saving model ...
	 Train_Loss: 0.3049 Train_Acc: 91.868 Val_Loss: 0.2589  BEST VAL Loss: 0.2589  Val_Acc: 92.888

Epoch 58: Validation loss decreased (0.258866 --> 0.258151).  Saving model ...
	 Train_Loss: 0.3038 Train_Acc: 91.857 Val_Loss: 0.2582  BEST VAL Loss: 0.2582  Val_Acc: 93.118

Epoch 59: Validation loss decreased (0.258151 --> 0.257505).  Saving model ...
	 Train_Loss: 0.3026 Train_Acc: 92.400 Val_Loss: 0.2575  BEST VAL Loss: 0.2575  Val_Acc: 93.090

Epoch 60: Validation loss decreased (0.257505 --> 0.257036).  Saving model ...
	 Train_Loss: 0.3015 Train_Acc: 92.548 Val_Loss: 0.2570  BEST VAL Loss: 0.2570  Val_Acc: 92.802

Epoch 61: Validation loss decreased (0.257036 --> 0.256279).  Saving model ...
	 Train_Loss: 0.3004 Train_Acc: 92.228 Val_Loss: 0.2563  BEST VAL Loss: 0.2563  Val_Acc: 93.406

Epoch 62: Validation loss decreased (0.256279 --> 0.255561).  Saving model ...
	 Train_Loss: 0.2993 Train_Acc: 92.580 Val_Loss: 0.2556  BEST VAL Loss: 0.2556  Val_Acc: 93.262

Epoch 63: Validation loss decreased (0.255561 --> 0.254865).  Saving model ...
	 Train_Loss: 0.2981 Train_Acc: 92.609 Val_Loss: 0.2549  BEST VAL Loss: 0.2549  Val_Acc: 93.032

Epoch 64: Validation loss decreased (0.254865 --> 0.254477).  Saving model ...
	 Train_Loss: 0.2971 Train_Acc: 92.390 Val_Loss: 0.2545  BEST VAL Loss: 0.2545  Val_Acc: 93.003

Epoch 65: Validation loss decreased (0.254477 --> 0.253959).  Saving model ...
	 Train_Loss: 0.2962 Train_Acc: 92.436 Val_Loss: 0.2540  BEST VAL Loss: 0.2540  Val_Acc: 93.118

Epoch 66: Validation loss decreased (0.253959 --> 0.253594).  Saving model ...
	 Train_Loss: 0.2951 Train_Acc: 92.933 Val_Loss: 0.2536  BEST VAL Loss: 0.2536  Val_Acc: 93.205

Epoch 67: Validation loss decreased (0.253594 --> 0.253516).  Saving model ...
	 Train_Loss: 0.2940 Train_Acc: 92.966 Val_Loss: 0.2535  BEST VAL Loss: 0.2535  Val_Acc: 92.053

Epoch 68: Validation loss decreased (0.253516 --> 0.253082).  Saving model ...
	 Train_Loss: 0.2929 Train_Acc: 92.973 Val_Loss: 0.2531  BEST VAL Loss: 0.2531  Val_Acc: 93.234

Epoch 69: Validation loss decreased (0.253082 --> 0.252746).  Saving model ...
	 Train_Loss: 0.2919 Train_Acc: 93.009 Val_Loss: 0.2527  BEST VAL Loss: 0.2527  Val_Acc: 93.090

Epoch 70: Validation loss decreased (0.252746 --> 0.252179).  Saving model ...
	 Train_Loss: 0.2910 Train_Acc: 92.760 Val_Loss: 0.2522  BEST VAL Loss: 0.2522  Val_Acc: 93.262

Epoch 71: Validation loss decreased (0.252179 --> 0.251730).  Saving model ...
	 Train_Loss: 0.2902 Train_Acc: 92.364 Val_Loss: 0.2517  BEST VAL Loss: 0.2517  Val_Acc: 92.974

Epoch 72: Validation loss decreased (0.251730 --> 0.251575).  Saving model ...
	 Train_Loss: 0.2892 Train_Acc: 92.980 Val_Loss: 0.2516  BEST VAL Loss: 0.2516  Val_Acc: 92.715

Epoch 73: Validation loss decreased (0.251575 --> 0.251083).  Saving model ...
	 Train_Loss: 0.2884 Train_Acc: 92.620 Val_Loss: 0.2511  BEST VAL Loss: 0.2511  Val_Acc: 93.262

Epoch 74: Validation loss decreased (0.251083 --> 0.250693).  Saving model ...
	 Train_Loss: 0.2875 Train_Acc: 92.829 Val_Loss: 0.2507  BEST VAL Loss: 0.2507  Val_Acc: 93.090

Epoch 75: Validation loss decreased (0.250693 --> 0.250229).  Saving model ...
	 Train_Loss: 0.2867 Train_Acc: 93.081 Val_Loss: 0.2502  BEST VAL Loss: 0.2502  Val_Acc: 93.521

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.2858 Train_Acc: 93.063 Val_Loss: 0.2504  BEST VAL Loss: 0.2502  Val_Acc: 91.448

Epoch 77: Validation loss decreased (0.250229 --> 0.249953).  Saving model ...
	 Train_Loss: 0.2849 Train_Acc: 93.048 Val_Loss: 0.2500  BEST VAL Loss: 0.2500  Val_Acc: 93.665

Epoch 78: Validation loss decreased (0.249953 --> 0.249542).  Saving model ...
	 Train_Loss: 0.2842 Train_Acc: 92.886 Val_Loss: 0.2495  BEST VAL Loss: 0.2495  Val_Acc: 93.205

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.2832 Train_Acc: 93.426 Val_Loss: 0.2497  BEST VAL Loss: 0.2495  Val_Acc: 91.938

Epoch 80: Validation loss decreased (0.249542 --> 0.249348).  Saving model ...
	 Train_Loss: 0.2826 Train_Acc: 92.638 Val_Loss: 0.2493  BEST VAL Loss: 0.2493  Val_Acc: 93.377

Epoch 81: Validation loss decreased (0.249348 --> 0.248956).  Saving model ...
	 Train_Loss: 0.2818 Train_Acc: 93.074 Val_Loss: 0.2490  BEST VAL Loss: 0.2490  Val_Acc: 93.176

Epoch 82: Validation loss decreased (0.248956 --> 0.248600).  Saving model ...
	 Train_Loss: 0.2810 Train_Acc: 93.401 Val_Loss: 0.2486  BEST VAL Loss: 0.2486  Val_Acc: 93.435

Epoch 83: Validation loss decreased (0.248600 --> 0.248269).  Saving model ...
	 Train_Loss: 0.2802 Train_Acc: 93.124 Val_Loss: 0.2483  BEST VAL Loss: 0.2483  Val_Acc: 93.377

Epoch 84: Validation loss decreased (0.248269 --> 0.247836).  Saving model ...
	 Train_Loss: 0.2794 Train_Acc: 93.545 Val_Loss: 0.2478  BEST VAL Loss: 0.2478  Val_Acc: 93.262

Epoch 85: Validation loss decreased (0.247836 --> 0.247473).  Saving model ...
	 Train_Loss: 0.2786 Train_Acc: 93.419 Val_Loss: 0.2475  BEST VAL Loss: 0.2475  Val_Acc: 93.176

Epoch 86: Validation loss decreased (0.247473 --> 0.247125).  Saving model ...
	 Train_Loss: 0.2779 Train_Acc: 93.171 Val_Loss: 0.2471  BEST VAL Loss: 0.2471  Val_Acc: 92.946

Epoch 87: Validation loss decreased (0.247125 --> 0.246962).  Saving model ...
	 Train_Loss: 0.2771 Train_Acc: 93.329 Val_Loss: 0.2470  BEST VAL Loss: 0.2470  Val_Acc: 92.974

Epoch 88: Validation loss decreased (0.246962 --> 0.246602).  Saving model ...
	 Train_Loss: 0.2763 Train_Acc: 93.599 Val_Loss: 0.2466  BEST VAL Loss: 0.2466  Val_Acc: 93.118

Epoch 89: Validation loss decreased (0.246602 --> 0.246278).  Saving model ...
	 Train_Loss: 0.2756 Train_Acc: 93.606 Val_Loss: 0.2463  BEST VAL Loss: 0.2463  Val_Acc: 93.147

Epoch 90: Validation loss decreased (0.246278 --> 0.246119).  Saving model ...
	 Train_Loss: 0.2748 Train_Acc: 93.477 Val_Loss: 0.2461  BEST VAL Loss: 0.2461  Val_Acc: 93.061

Epoch 91: Validation loss decreased (0.246119 --> 0.245895).  Saving model ...
	 Train_Loss: 0.2741 Train_Acc: 93.610 Val_Loss: 0.2459  BEST VAL Loss: 0.2459  Val_Acc: 93.147

Epoch 92: Validation loss decreased (0.245895 --> 0.245688).  Saving model ...
	 Train_Loss: 0.2735 Train_Acc: 93.210 Val_Loss: 0.2457  BEST VAL Loss: 0.2457  Val_Acc: 93.291

Epoch 93: Validation loss decreased (0.245688 --> 0.245399).  Saving model ...
	 Train_Loss: 0.2728 Train_Acc: 93.488 Val_Loss: 0.2454  BEST VAL Loss: 0.2454  Val_Acc: 93.090

Epoch 94: Validation loss decreased (0.245399 --> 0.245198).  Saving model ...
	 Train_Loss: 0.2722 Train_Acc: 93.430 Val_Loss: 0.2452  BEST VAL Loss: 0.2452  Val_Acc: 93.090

Epoch 95: Validation loss decreased (0.245198 --> 0.244882).  Saving model ...
	 Train_Loss: 0.2715 Train_Acc: 93.369 Val_Loss: 0.2449  BEST VAL Loss: 0.2449  Val_Acc: 92.744

Epoch 96: Validation loss decreased (0.244882 --> 0.244846).  Saving model ...
	 Train_Loss: 0.2708 Train_Acc: 93.678 Val_Loss: 0.2448  BEST VAL Loss: 0.2448  Val_Acc: 92.802

Epoch 97: Validation loss decreased (0.244846 --> 0.244661).  Saving model ...
	 Train_Loss: 0.2702 Train_Acc: 93.610 Val_Loss: 0.2447  BEST VAL Loss: 0.2447  Val_Acc: 93.349

Epoch 98: Validation loss decreased (0.244661 --> 0.244483).  Saving model ...
	 Train_Loss: 0.2695 Train_Acc: 93.765 Val_Loss: 0.2445  BEST VAL Loss: 0.2445  Val_Acc: 93.406

Epoch 99: Validation loss decreased (0.244483 --> 0.244305).  Saving model ...
	 Train_Loss: 0.2689 Train_Acc: 93.329 Val_Loss: 0.2443  BEST VAL Loss: 0.2443  Val_Acc: 92.571

H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.65      0.67      0.66     18174
           1       0.34      0.33      0.33      9604

    accuracy                           0.55     27778
   macro avg       0.50      0.50      0.50     27778
weighted avg       0.55      0.55      0.55     27778

H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.65      0.68      0.67      2272
           1       0.35      0.33      0.34      1201

    accuracy                           0.55      3473
   macro avg       0.50      0.50      0.50      3473
weighted avg       0.55      0.55      0.55      3473

H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.65      0.66      0.66      2272
           1       0.34      0.33      0.34      1201

    accuracy                           0.55      3473
   macro avg       0.50      0.50      0.50      3473
weighted avg       0.55      0.55      0.55      3473

              precision    recall  f1-score   support

           0       0.65      0.66      0.66      2272
           1       0.34      0.33      0.34      1201

    accuracy                           0.55      3473
   macro avg       0.50      0.50      0.50      3473
weighted avg       0.55      0.55      0.55      3473

H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.56      0.53      4182
           1       0.50      0.44      0.47      4212

    accuracy                           0.50      8394
   macro avg       0.50      0.50      0.50      8394
weighted avg       0.50      0.50      0.50      8394

              precision    recall  f1-score   support

           0       0.50      0.56      0.53      4182
           1       0.50      0.44      0.47      4212

    accuracy                           0.50      8394
   macro avg       0.50      0.50      0.50      8394
weighted avg       0.50      0.50      0.50      8394

completed
