[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '3de069e5'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'f3015de5'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1f1805b1'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '871e1e4c'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 treatment_name: H2O2_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
TREATMENT_NAME: H2O2_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['H2O2_100.000_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (406549, 1270)
Number of total missing values across all columns: 481072
Data Subset Is Off
Wells held out for testing: ['I10' 'K08']
Wells to use for training, validation, and testing ['H04' 'I04' 'H05' 'I05' 'H10' 'H11' 'I11' 'K02' 'K03' 'K09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.379152).  Saving model ...
	 Train_Loss: 0.4741 Train_Acc: 78.560 Val_Loss: 0.3792  BEST VAL Loss: 0.3792  Val_Acc: 83.944

Epoch 1: Validation loss decreased (0.379152 --> 0.353634).  Saving model ...
	 Train_Loss: 0.4217 Train_Acc: 83.996 Val_Loss: 0.3536  BEST VAL Loss: 0.3536  Val_Acc: 85.927

Epoch 2: Validation loss decreased (0.353634 --> 0.336715).  Saving model ...
	 Train_Loss: 0.3930 Train_Acc: 85.498 Val_Loss: 0.3367  BEST VAL Loss: 0.3367  Val_Acc: 87.026

Epoch 3: Validation loss decreased (0.336715 --> 0.324276).  Saving model ...
	 Train_Loss: 0.3735 Train_Acc: 86.399 Val_Loss: 0.3243  BEST VAL Loss: 0.3243  Val_Acc: 87.676

Epoch 4: Validation loss decreased (0.324276 --> 0.314334).  Saving model ...
	 Train_Loss: 0.3592 Train_Acc: 87.060 Val_Loss: 0.3143  BEST VAL Loss: 0.3143  Val_Acc: 88.277

Epoch 5: Validation loss decreased (0.314334 --> 0.306140).  Saving model ...
	 Train_Loss: 0.3481 Train_Acc: 87.467 Val_Loss: 0.3061  BEST VAL Loss: 0.3061  Val_Acc: 88.669

Epoch 6: Validation loss decreased (0.306140 --> 0.299459).  Saving model ...
	 Train_Loss: 0.3390 Train_Acc: 87.907 Val_Loss: 0.2995  BEST VAL Loss: 0.2995  Val_Acc: 88.962

Epoch 7: Validation loss decreased (0.299459 --> 0.293852).  Saving model ...
	 Train_Loss: 0.3315 Train_Acc: 88.124 Val_Loss: 0.2939  BEST VAL Loss: 0.2939  Val_Acc: 89.128

Epoch 8: Validation loss decreased (0.293852 --> 0.289007).  Saving model ...
	 Train_Loss: 0.3250 Train_Acc: 88.376 Val_Loss: 0.2890  BEST VAL Loss: 0.2890  Val_Acc: 89.421

Epoch 9: Validation loss decreased (0.289007 --> 0.284640).  Saving model ...
	 Train_Loss: 0.3194 Train_Acc: 88.604 Val_Loss: 0.2846  BEST VAL Loss: 0.2846  Val_Acc: 89.626

Epoch 10: Validation loss decreased (0.284640 --> 0.280717).  Saving model ...
	 Train_Loss: 0.3145 Train_Acc: 88.772 Val_Loss: 0.2807  BEST VAL Loss: 0.2807  Val_Acc: 89.813

Epoch 11: Validation loss decreased (0.280717 --> 0.277267).  Saving model ...
	 Train_Loss: 0.3100 Train_Acc: 88.971 Val_Loss: 0.2773  BEST VAL Loss: 0.2773  Val_Acc: 90.014

Epoch 12: Validation loss decreased (0.277267 --> 0.273913).  Saving model ...
	 Train_Loss: 0.3059 Train_Acc: 89.135 Val_Loss: 0.2739  BEST VAL Loss: 0.2739  Val_Acc: 90.159

Epoch 13: Validation loss decreased (0.273913 --> 0.270901).  Saving model ...
	 Train_Loss: 0.3022 Train_Acc: 89.329 Val_Loss: 0.2709  BEST VAL Loss: 0.2709  Val_Acc: 90.296

Epoch 14: Validation loss decreased (0.270901 --> 0.268115).  Saving model ...
	 Train_Loss: 0.2989 Train_Acc: 89.406 Val_Loss: 0.2681  BEST VAL Loss: 0.2681  Val_Acc: 90.400

Epoch 15: Validation loss decreased (0.268115 --> 0.265463).  Saving model ...
	 Train_Loss: 0.2957 Train_Acc: 89.596 Val_Loss: 0.2655  BEST VAL Loss: 0.2655  Val_Acc: 90.595

Epoch 16: Validation loss decreased (0.265463 --> 0.263044).  Saving model ...
	 Train_Loss: 0.2928 Train_Acc: 89.671 Val_Loss: 0.2630  BEST VAL Loss: 0.2630  Val_Acc: 90.607

Epoch 17: Validation loss decreased (0.263044 --> 0.260717).  Saving model ...
	 Train_Loss: 0.2901 Train_Acc: 89.730 Val_Loss: 0.2607  BEST VAL Loss: 0.2607  Val_Acc: 90.696

Epoch 18: Validation loss decreased (0.260717 --> 0.258561).  Saving model ...
	 Train_Loss: 0.2875 Train_Acc: 89.798 Val_Loss: 0.2586  BEST VAL Loss: 0.2586  Val_Acc: 90.806

Epoch 19: Validation loss decreased (0.258561 --> 0.256522).  Saving model ...
	 Train_Loss: 0.2851 Train_Acc: 89.948 Val_Loss: 0.2565  BEST VAL Loss: 0.2565  Val_Acc: 90.954

Epoch 20: Validation loss decreased (0.256522 --> 0.254591).  Saving model ...
	 Train_Loss: 0.2828 Train_Acc: 89.961 Val_Loss: 0.2546  BEST VAL Loss: 0.2546  Val_Acc: 90.957

Epoch 21: Validation loss decreased (0.254591 --> 0.252748).  Saving model ...
	 Train_Loss: 0.2807 Train_Acc: 90.103 Val_Loss: 0.2527  BEST VAL Loss: 0.2527  Val_Acc: 91.155

Epoch 22: Validation loss decreased (0.252748 --> 0.251071).  Saving model ...
	 Train_Loss: 0.2787 Train_Acc: 90.128 Val_Loss: 0.2511  BEST VAL Loss: 0.2511  Val_Acc: 91.132

Epoch 23: Validation loss decreased (0.251071 --> 0.249423).  Saving model ...
	 Train_Loss: 0.2768 Train_Acc: 90.237 Val_Loss: 0.2494  BEST VAL Loss: 0.2494  Val_Acc: 91.221

Epoch 24: Validation loss decreased (0.249423 --> 0.247911).  Saving model ...
	 Train_Loss: 0.2749 Train_Acc: 90.280 Val_Loss: 0.2479  BEST VAL Loss: 0.2479  Val_Acc: 91.321

Epoch 25: Validation loss decreased (0.247911 --> 0.246342).  Saving model ...
	 Train_Loss: 0.2732 Train_Acc: 90.352 Val_Loss: 0.2463  BEST VAL Loss: 0.2463  Val_Acc: 91.425

Epoch 26: Validation loss decreased (0.246342 --> 0.244856).  Saving model ...
	 Train_Loss: 0.2715 Train_Acc: 90.413 Val_Loss: 0.2449  BEST VAL Loss: 0.2449  Val_Acc: 91.514

Epoch 27: Validation loss decreased (0.244856 --> 0.243444).  Saving model ...
	 Train_Loss: 0.2699 Train_Acc: 90.454 Val_Loss: 0.2434  BEST VAL Loss: 0.2434  Val_Acc: 91.591

Epoch 28: Validation loss decreased (0.243444 --> 0.242072).  Saving model ...
	 Train_Loss: 0.2684 Train_Acc: 90.507 Val_Loss: 0.2421  BEST VAL Loss: 0.2421  Val_Acc: 91.582

Epoch 29: Validation loss decreased (0.242072 --> 0.240755).  Saving model ...
	 Train_Loss: 0.2669 Train_Acc: 90.543 Val_Loss: 0.2408  BEST VAL Loss: 0.2408  Val_Acc: 91.618

Epoch 30: Validation loss decreased (0.240755 --> 0.239531).  Saving model ...
	 Train_Loss: 0.2655 Train_Acc: 90.651 Val_Loss: 0.2395  BEST VAL Loss: 0.2395  Val_Acc: 91.760

Epoch 31: Validation loss decreased (0.239531 --> 0.238321).  Saving model ...
	 Train_Loss: 0.2641 Train_Acc: 90.752 Val_Loss: 0.2383  BEST VAL Loss: 0.2383  Val_Acc: 91.799

Epoch 32: Validation loss decreased (0.238321 --> 0.237150).  Saving model ...
	 Train_Loss: 0.2628 Train_Acc: 90.775 Val_Loss: 0.2372  BEST VAL Loss: 0.2372  Val_Acc: 91.763

Epoch 33: Validation loss decreased (0.237150 --> 0.236041).  Saving model ...
	 Train_Loss: 0.2615 Train_Acc: 90.812 Val_Loss: 0.2360  BEST VAL Loss: 0.2360  Val_Acc: 91.831

Epoch 34: Validation loss decreased (0.236041 --> 0.234965).  Saving model ...
	 Train_Loss: 0.2603 Train_Acc: 90.862 Val_Loss: 0.2350  BEST VAL Loss: 0.2350  Val_Acc: 91.905

Epoch 35: Validation loss decreased (0.234965 --> 0.233939).  Saving model ...
	 Train_Loss: 0.2592 Train_Acc: 90.854 Val_Loss: 0.2339  BEST VAL Loss: 0.2339  Val_Acc: 91.870

Epoch 36: Validation loss decreased (0.233939 --> 0.232914).  Saving model ...
	 Train_Loss: 0.2580 Train_Acc: 90.859 Val_Loss: 0.2329  BEST VAL Loss: 0.2329  Val_Acc: 91.855

Epoch 37: Validation loss decreased (0.232914 --> 0.231950).  Saving model ...
	 Train_Loss: 0.2569 Train_Acc: 90.921 Val_Loss: 0.2320  BEST VAL Loss: 0.2320  Val_Acc: 91.923

Epoch 38: Validation loss decreased (0.231950 --> 0.231001).  Saving model ...
	 Train_Loss: 0.2559 Train_Acc: 90.947 Val_Loss: 0.2310  BEST VAL Loss: 0.2310  Val_Acc: 91.914

Epoch 39: Validation loss decreased (0.231001 --> 0.230093).  Saving model ...
	 Train_Loss: 0.2549 Train_Acc: 91.013 Val_Loss: 0.2301  BEST VAL Loss: 0.2301  Val_Acc: 91.973

Epoch 40: Validation loss decreased (0.230093 --> 0.229202).  Saving model ...
	 Train_Loss: 0.2539 Train_Acc: 91.035 Val_Loss: 0.2292  BEST VAL Loss: 0.2292  Val_Acc: 91.979

Epoch 41: Validation loss decreased (0.229202 --> 0.228340).  Saving model ...
	 Train_Loss: 0.2529 Train_Acc: 91.046 Val_Loss: 0.2283  BEST VAL Loss: 0.2283  Val_Acc: 92.042

Epoch 42: Validation loss decreased (0.228340 --> 0.227544).  Saving model ...
	 Train_Loss: 0.2520 Train_Acc: 91.099 Val_Loss: 0.2275  BEST VAL Loss: 0.2275  Val_Acc: 91.908

Epoch 43: Validation loss decreased (0.227544 --> 0.226732).  Saving model ...
	 Train_Loss: 0.2511 Train_Acc: 91.129 Val_Loss: 0.2267  BEST VAL Loss: 0.2267  Val_Acc: 92.086

Epoch 44: Validation loss decreased (0.226732 --> 0.225961).  Saving model ...
	 Train_Loss: 0.2502 Train_Acc: 91.132 Val_Loss: 0.2260  BEST VAL Loss: 0.2260  Val_Acc: 92.012

Epoch 45: Validation loss decreased (0.225961 --> 0.225186).  Saving model ...
	 Train_Loss: 0.2494 Train_Acc: 91.170 Val_Loss: 0.2252  BEST VAL Loss: 0.2252  Val_Acc: 92.136

Epoch 46: Validation loss decreased (0.225186 --> 0.224455).  Saving model ...
	 Train_Loss: 0.2485 Train_Acc: 91.180 Val_Loss: 0.2245  BEST VAL Loss: 0.2245  Val_Acc: 92.145

Epoch 47: Validation loss decreased (0.224455 --> 0.223729).  Saving model ...
	 Train_Loss: 0.2477 Train_Acc: 91.188 Val_Loss: 0.2237  BEST VAL Loss: 0.2237  Val_Acc: 92.258

Epoch 48: Validation loss decreased (0.223729 --> 0.223033).  Saving model ...
	 Train_Loss: 0.2470 Train_Acc: 91.221 Val_Loss: 0.2230  BEST VAL Loss: 0.2230  Val_Acc: 92.157

Epoch 49: Validation loss decreased (0.223033 --> 0.222351).  Saving model ...
	 Train_Loss: 0.2462 Train_Acc: 91.192 Val_Loss: 0.2224  BEST VAL Loss: 0.2224  Val_Acc: 92.264

Epoch 50: Validation loss decreased (0.222351 --> 0.221686).  Saving model ...
	 Train_Loss: 0.2455 Train_Acc: 91.263 Val_Loss: 0.2217  BEST VAL Loss: 0.2217  Val_Acc: 92.237

Epoch 51: Validation loss decreased (0.221686 --> 0.221080).  Saving model ...
	 Train_Loss: 0.2447 Train_Acc: 91.259 Val_Loss: 0.2211  BEST VAL Loss: 0.2211  Val_Acc: 92.225

Epoch 52: Validation loss decreased (0.221080 --> 0.220441).  Saving model ...
	 Train_Loss: 0.2440 Train_Acc: 91.221 Val_Loss: 0.2204  BEST VAL Loss: 0.2204  Val_Acc: 92.415

Epoch 53: Validation loss decreased (0.220441 --> 0.219849).  Saving model ...
	 Train_Loss: 0.2434 Train_Acc: 91.300 Val_Loss: 0.2198  BEST VAL Loss: 0.2198  Val_Acc: 92.249

Epoch 54: Validation loss decreased (0.219849 --> 0.219279).  Saving model ...
	 Train_Loss: 0.2427 Train_Acc: 91.298 Val_Loss: 0.2193  BEST VAL Loss: 0.2193  Val_Acc: 92.279

Epoch 55: Validation loss decreased (0.219279 --> 0.218738).  Saving model ...
	 Train_Loss: 0.2421 Train_Acc: 91.356 Val_Loss: 0.2187  BEST VAL Loss: 0.2187  Val_Acc: 92.285

Epoch 56: Validation loss decreased (0.218738 --> 0.218176).  Saving model ...
	 Train_Loss: 0.2414 Train_Acc: 91.345 Val_Loss: 0.2182  BEST VAL Loss: 0.2182  Val_Acc: 92.237

Epoch 57: Validation loss decreased (0.218176 --> 0.217635).  Saving model ...
	 Train_Loss: 0.2408 Train_Acc: 91.350 Val_Loss: 0.2176  BEST VAL Loss: 0.2176  Val_Acc: 92.320

Epoch 58: Validation loss decreased (0.217635 --> 0.217108).  Saving model ...
	 Train_Loss: 0.2402 Train_Acc: 91.398 Val_Loss: 0.2171  BEST VAL Loss: 0.2171  Val_Acc: 92.267

Epoch 59: Validation loss decreased (0.217108 --> 0.216631).  Saving model ...
	 Train_Loss: 0.2396 Train_Acc: 91.435 Val_Loss: 0.2166  BEST VAL Loss: 0.2166  Val_Acc: 92.255

Epoch 60: Validation loss decreased (0.216631 --> 0.216107).  Saving model ...
	 Train_Loss: 0.2390 Train_Acc: 91.408 Val_Loss: 0.2161  BEST VAL Loss: 0.2161  Val_Acc: 92.421

Epoch 61: Validation loss decreased (0.216107 --> 0.215606).  Saving model ...
	 Train_Loss: 0.2385 Train_Acc: 91.449 Val_Loss: 0.2156  BEST VAL Loss: 0.2156  Val_Acc: 92.415

Epoch 62: Validation loss decreased (0.215606 --> 0.215118).  Saving model ...
	 Train_Loss: 0.2379 Train_Acc: 91.398 Val_Loss: 0.2151  BEST VAL Loss: 0.2151  Val_Acc: 92.302

Epoch 63: Validation loss decreased (0.215118 --> 0.214666).  Saving model ...
	 Train_Loss: 0.2374 Train_Acc: 91.423 Val_Loss: 0.2147  BEST VAL Loss: 0.2147  Val_Acc: 92.326

Epoch 64: Validation loss decreased (0.214666 --> 0.214231).  Saving model ...
	 Train_Loss: 0.2368 Train_Acc: 91.493 Val_Loss: 0.2142  BEST VAL Loss: 0.2142  Val_Acc: 92.246

Epoch 65: Validation loss decreased (0.214231 --> 0.213787).  Saving model ...
	 Train_Loss: 0.2363 Train_Acc: 91.478 Val_Loss: 0.2138  BEST VAL Loss: 0.2138  Val_Acc: 92.338

Epoch 66: Validation loss decreased (0.213787 --> 0.213360).  Saving model ...
	 Train_Loss: 0.2358 Train_Acc: 91.491 Val_Loss: 0.2134  BEST VAL Loss: 0.2134  Val_Acc: 92.465

Epoch 67: Validation loss decreased (0.213360 --> 0.212950).  Saving model ...
	 Train_Loss: 0.2353 Train_Acc: 91.481 Val_Loss: 0.2129  BEST VAL Loss: 0.2129  Val_Acc: 92.344

Epoch 68: Validation loss decreased (0.212950 --> 0.212541).  Saving model ...
	 Train_Loss: 0.2348 Train_Acc: 91.499 Val_Loss: 0.2125  BEST VAL Loss: 0.2125  Val_Acc: 92.338

Epoch 69: Validation loss decreased (0.212541 --> 0.212146).  Saving model ...
	 Train_Loss: 0.2344 Train_Acc: 91.521 Val_Loss: 0.2121  BEST VAL Loss: 0.2121  Val_Acc: 92.400

Epoch 70: Validation loss decreased (0.212146 --> 0.211744).  Saving model ...
	 Train_Loss: 0.2339 Train_Acc: 91.565 Val_Loss: 0.2117  BEST VAL Loss: 0.2117  Val_Acc: 92.468

Epoch 71: Validation loss decreased (0.211744 --> 0.211342).  Saving model ...
	 Train_Loss: 0.2334 Train_Acc: 91.530 Val_Loss: 0.2113  BEST VAL Loss: 0.2113  Val_Acc: 92.338

Epoch 72: Validation loss decreased (0.211342 --> 0.210946).  Saving model ...
	 Train_Loss: 0.2330 Train_Acc: 91.522 Val_Loss: 0.2109  BEST VAL Loss: 0.2109  Val_Acc: 92.406

Epoch 73: Validation loss decreased (0.210946 --> 0.210572).  Saving model ...
	 Train_Loss: 0.2325 Train_Acc: 91.547 Val_Loss: 0.2106  BEST VAL Loss: 0.2106  Val_Acc: 92.495

Epoch 74: Validation loss decreased (0.210572 --> 0.210207).  Saving model ...
	 Train_Loss: 0.2321 Train_Acc: 91.561 Val_Loss: 0.2102  BEST VAL Loss: 0.2102  Val_Acc: 92.448

Epoch 75: Validation loss decreased (0.210207 --> 0.209848).  Saving model ...
	 Train_Loss: 0.2317 Train_Acc: 91.531 Val_Loss: 0.2098  BEST VAL Loss: 0.2098  Val_Acc: 92.436

Epoch 76: Validation loss decreased (0.209848 --> 0.209512).  Saving model ...
	 Train_Loss: 0.2313 Train_Acc: 91.566 Val_Loss: 0.2095  BEST VAL Loss: 0.2095  Val_Acc: 92.540

Epoch 77: Validation loss decreased (0.209512 --> 0.209164).  Saving model ...
	 Train_Loss: 0.2309 Train_Acc: 91.577 Val_Loss: 0.2092  BEST VAL Loss: 0.2092  Val_Acc: 92.516

Epoch 78: Validation loss decreased (0.209164 --> 0.208832).  Saving model ...
	 Train_Loss: 0.2305 Train_Acc: 91.652 Val_Loss: 0.2088  BEST VAL Loss: 0.2088  Val_Acc: 92.448

Epoch 79: Validation loss decreased (0.208832 --> 0.208514).  Saving model ...
	 Train_Loss: 0.2301 Train_Acc: 91.647 Val_Loss: 0.2085  BEST VAL Loss: 0.2085  Val_Acc: 92.347

Epoch 80: Validation loss decreased (0.208514 --> 0.208196).  Saving model ...
	 Train_Loss: 0.2297 Train_Acc: 91.601 Val_Loss: 0.2082  BEST VAL Loss: 0.2082  Val_Acc: 92.424

Epoch 81: Validation loss decreased (0.208196 --> 0.207894).  Saving model ...
	 Train_Loss: 0.2293 Train_Acc: 91.664 Val_Loss: 0.2079  BEST VAL Loss: 0.2079  Val_Acc: 92.433

Epoch 82: Validation loss decreased (0.207894 --> 0.207579).  Saving model ...
	 Train_Loss: 0.2289 Train_Acc: 91.628 Val_Loss: 0.2076  BEST VAL Loss: 0.2076  Val_Acc: 92.557

Epoch 83: Validation loss decreased (0.207579 --> 0.207283).  Saving model ...
	 Train_Loss: 0.2286 Train_Acc: 91.683 Val_Loss: 0.2073  BEST VAL Loss: 0.2073  Val_Acc: 92.474

Epoch 84: Validation loss decreased (0.207283 --> 0.206972).  Saving model ...
	 Train_Loss: 0.2282 Train_Acc: 91.622 Val_Loss: 0.2070  BEST VAL Loss: 0.2070  Val_Acc: 92.513

Epoch 85: Validation loss decreased (0.206972 --> 0.206673).  Saving model ...
	 Train_Loss: 0.2279 Train_Acc: 91.649 Val_Loss: 0.2067  BEST VAL Loss: 0.2067  Val_Acc: 92.463

Epoch 86: Validation loss decreased (0.206673 --> 0.206394).  Saving model ...
	 Train_Loss: 0.2275 Train_Acc: 91.616 Val_Loss: 0.2064  BEST VAL Loss: 0.2064  Val_Acc: 92.492

Epoch 87: Validation loss decreased (0.206394 --> 0.206121).  Saving model ...
	 Train_Loss: 0.2272 Train_Acc: 91.656 Val_Loss: 0.2061  BEST VAL Loss: 0.2061  Val_Acc: 92.507

Epoch 88: Validation loss decreased (0.206121 --> 0.205860).  Saving model ...
	 Train_Loss: 0.2268 Train_Acc: 91.754 Val_Loss: 0.2059  BEST VAL Loss: 0.2059  Val_Acc: 92.471

Epoch 89: Validation loss decreased (0.205860 --> 0.205579).  Saving model ...
	 Train_Loss: 0.2265 Train_Acc: 91.645 Val_Loss: 0.2056  BEST VAL Loss: 0.2056  Val_Acc: 92.486

Epoch 90: Validation loss decreased (0.205579 --> 0.205309).  Saving model ...
	 Train_Loss: 0.2262 Train_Acc: 91.725 Val_Loss: 0.2053  BEST VAL Loss: 0.2053  Val_Acc: 92.575

Epoch 91: Validation loss decreased (0.205309 --> 0.205063).  Saving model ...
	 Train_Loss: 0.2259 Train_Acc: 91.732 Val_Loss: 0.2051  BEST VAL Loss: 0.2051  Val_Acc: 92.575

Epoch 92: Validation loss decreased (0.205063 --> 0.204817).  Saving model ...
	 Train_Loss: 0.2256 Train_Acc: 91.702 Val_Loss: 0.2048  BEST VAL Loss: 0.2048  Val_Acc: 92.563

Epoch 93: Validation loss decreased (0.204817 --> 0.204545).  Saving model ...
	 Train_Loss: 0.2253 Train_Acc: 91.691 Val_Loss: 0.2045  BEST VAL Loss: 0.2045  Val_Acc: 92.608

Epoch 94: Validation loss decreased (0.204545 --> 0.204300).  Saving model ...
	 Train_Loss: 0.2250 Train_Acc: 91.683 Val_Loss: 0.2043  BEST VAL Loss: 0.2043  Val_Acc: 92.575

Epoch 95: Validation loss decreased (0.204300 --> 0.204041).  Saving model ...
	 Train_Loss: 0.2247 Train_Acc: 91.692 Val_Loss: 0.2040  BEST VAL Loss: 0.2040  Val_Acc: 92.608

Epoch 96: Validation loss decreased (0.204041 --> 0.203799).  Saving model ...
	 Train_Loss: 0.2244 Train_Acc: 91.768 Val_Loss: 0.2038  BEST VAL Loss: 0.2038  Val_Acc: 92.575

Epoch 97: Validation loss decreased (0.203799 --> 0.203575).  Saving model ...
	 Train_Loss: 0.2241 Train_Acc: 91.740 Val_Loss: 0.2036  BEST VAL Loss: 0.2036  Val_Acc: 92.498

Epoch 98: Validation loss decreased (0.203575 --> 0.203347).  Saving model ...
	 Train_Loss: 0.2238 Train_Acc: 91.743 Val_Loss: 0.2033  BEST VAL Loss: 0.2033  Val_Acc: 92.531

Epoch 99: Validation loss decreased (0.203347 --> 0.203130).  Saving model ...
	 Train_Loss: 0.2235 Train_Acc: 91.755 Val_Loss: 0.2031  BEST VAL Loss: 0.2031  Val_Acc: 92.551

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.63      0.63      0.63    169562
           1       0.37      0.37      0.37    100339

    accuracy                           0.53    269901
   macro avg       0.50      0.50      0.50    269901
weighted avg       0.53      0.53      0.53    269901

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.63      0.63      0.63     21195
           1       0.37      0.37      0.37     12543

    accuracy                           0.53     33738
   macro avg       0.50      0.50      0.50     33738
weighted avg       0.53      0.53      0.53     33738

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.63      0.63      0.63     21195
           1       0.37      0.37      0.37     12543

    accuracy                           0.53     33738
   macro avg       0.50      0.50      0.50     33738
weighted avg       0.53      0.53      0.53     33738

              precision    recall  f1-score   support

           0       0.63      0.63      0.63     21195
           1       0.37      0.37      0.37     12543

    accuracy                           0.53     33738
   macro avg       0.50      0.50      0.50     33738
weighted avg       0.53      0.53      0.53     33738

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.41      0.49      0.45     28584
           1       0.59      0.51      0.54     40588

    accuracy                           0.50     69172
   macro avg       0.50      0.50      0.50     69172
weighted avg       0.52      0.50      0.51     69172

              precision    recall  f1-score   support

           0       0.41      0.49      0.45     28584
           1       0.59      0.51      0.54     40588

    accuracy                           0.50     69172
   macro avg       0.50      0.50      0.50     69172
weighted avg       0.52      0.50      0.51     69172

completed
