[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '17967e3e'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '214b4173'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '88789fd7'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '40a1d532'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_10.000_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_10.000_DMSO_0.025']
The dimensions of the data are: (32669, 1276)
Number of total missing values across all columns: 65338
Data Subset Is Off
Wells held out for testing: ['B20' 'E21']
Wells to use for training, validation, and testing ['B16' 'E16' 'B17' 'E17' 'E20' 'B21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.668457).  Saving model ...
	 Train_Loss: 0.6911 Train_Acc: 54.185 Val_Loss: 0.6685  BEST VAL Loss: 0.6685  Val_Acc: 62.712

Epoch 1: Validation loss decreased (0.668457 --> 0.649439).  Saving model ...
	 Train_Loss: 0.6775 Train_Acc: 60.037 Val_Loss: 0.6494  BEST VAL Loss: 0.6494  Val_Acc: 68.039

Epoch 2: Validation loss decreased (0.649439 --> 0.633345).  Saving model ...
	 Train_Loss: 0.6665 Train_Acc: 63.160 Val_Loss: 0.6333  BEST VAL Loss: 0.6333  Val_Acc: 69.613

Epoch 3: Validation loss decreased (0.633345 --> 0.619871).  Saving model ...
	 Train_Loss: 0.6572 Train_Acc: 64.825 Val_Loss: 0.6199  BEST VAL Loss: 0.6199  Val_Acc: 71.065

Epoch 4: Validation loss decreased (0.619871 --> 0.615515).  Saving model ...
	 Train_Loss: 0.6502 Train_Acc: 65.839 Val_Loss: 0.6155  BEST VAL Loss: 0.6155  Val_Acc: 71.146

Epoch 5: Validation loss decreased (0.615515 --> 0.609118).  Saving model ...
	 Train_Loss: 0.6448 Train_Acc: 66.581 Val_Loss: 0.6091  BEST VAL Loss: 0.6091  Val_Acc: 72.760

Epoch 6: Validation loss decreased (0.609118 --> 0.606691).  Saving model ...
	 Train_Loss: 0.6404 Train_Acc: 66.490 Val_Loss: 0.6067  BEST VAL Loss: 0.6067  Val_Acc: 72.276

Epoch 7: Validation loss decreased (0.606691 --> 0.600874).  Saving model ...
	 Train_Loss: 0.6360 Train_Acc: 67.883 Val_Loss: 0.6009  BEST VAL Loss: 0.6009  Val_Acc: 73.890

Epoch 8: Validation loss decreased (0.600874 --> 0.598469).  Saving model ...
	 Train_Loss: 0.6327 Train_Acc: 67.943 Val_Loss: 0.5985  BEST VAL Loss: 0.5985  Val_Acc: 73.608

Epoch 9: Validation loss decreased (0.598469 --> 0.593191).  Saving model ...
	 Train_Loss: 0.6295 Train_Acc: 68.099 Val_Loss: 0.5932  BEST VAL Loss: 0.5932  Val_Acc: 74.738

Epoch 10: Validation loss decreased (0.593191 --> 0.588546).  Saving model ...
	 Train_Loss: 0.6266 Train_Acc: 68.604 Val_Loss: 0.5885  BEST VAL Loss: 0.5885  Val_Acc: 74.092

Epoch 11: Validation loss decreased (0.588546 --> 0.584905).  Saving model ...
	 Train_Loss: 0.6236 Train_Acc: 68.937 Val_Loss: 0.5849  BEST VAL Loss: 0.5849  Val_Acc: 74.173

Epoch 12: Validation loss decreased (0.584905 --> 0.581456).  Saving model ...
	 Train_Loss: 0.6210 Train_Acc: 69.366 Val_Loss: 0.5815  BEST VAL Loss: 0.5815  Val_Acc: 75.545

Epoch 13: Validation loss decreased (0.581456 --> 0.578134).  Saving model ...
	 Train_Loss: 0.6184 Train_Acc: 69.774 Val_Loss: 0.5781  BEST VAL Loss: 0.5781  Val_Acc: 74.738

Epoch 14: Validation loss decreased (0.578134 --> 0.575650).  Saving model ...
	 Train_Loss: 0.6161 Train_Acc: 69.709 Val_Loss: 0.5757  BEST VAL Loss: 0.5757  Val_Acc: 75.343

Epoch 15: Validation loss decreased (0.575650 --> 0.573831).  Saving model ...
	 Train_Loss: 0.6141 Train_Acc: 69.896 Val_Loss: 0.5738  BEST VAL Loss: 0.5738  Val_Acc: 74.415

Epoch 16: Validation loss decreased (0.573831 --> 0.571457).  Saving model ...
	 Train_Loss: 0.6124 Train_Acc: 69.694 Val_Loss: 0.5715  BEST VAL Loss: 0.5715  Val_Acc: 74.738

Epoch 17: Validation loss decreased (0.571457 --> 0.568911).  Saving model ...
	 Train_Loss: 0.6108 Train_Acc: 69.648 Val_Loss: 0.5689  BEST VAL Loss: 0.5689  Val_Acc: 75.626

Epoch 18: Validation loss decreased (0.568911 --> 0.566992).  Saving model ...
	 Train_Loss: 0.6090 Train_Acc: 70.476 Val_Loss: 0.5670  BEST VAL Loss: 0.5670  Val_Acc: 75.464

Epoch 19: Validation loss decreased (0.566992 --> 0.564642).  Saving model ...
	 Train_Loss: 0.6073 Train_Acc: 70.269 Val_Loss: 0.5646  BEST VAL Loss: 0.5646  Val_Acc: 75.464

Epoch 20: Validation loss decreased (0.564642 --> 0.562472).  Saving model ...
	 Train_Loss: 0.6057 Train_Acc: 70.743 Val_Loss: 0.5625  BEST VAL Loss: 0.5625  Val_Acc: 76.312

Epoch 21: Validation loss decreased (0.562472 --> 0.560726).  Saving model ...
	 Train_Loss: 0.6045 Train_Acc: 70.017 Val_Loss: 0.5607  BEST VAL Loss: 0.5607  Val_Acc: 76.513

Epoch 22: Validation loss decreased (0.560726 --> 0.559012).  Saving model ...
	 Train_Loss: 0.6032 Train_Acc: 70.698 Val_Loss: 0.5590  BEST VAL Loss: 0.5590  Val_Acc: 76.231

Epoch 23: Validation loss decreased (0.559012 --> 0.558138).  Saving model ...
	 Train_Loss: 0.6020 Train_Acc: 70.703 Val_Loss: 0.5581  BEST VAL Loss: 0.5581  Val_Acc: 74.939

Epoch 24: Validation loss decreased (0.558138 --> 0.556691).  Saving model ...
	 Train_Loss: 0.6009 Train_Acc: 70.763 Val_Loss: 0.5567  BEST VAL Loss: 0.5567  Val_Acc: 75.747

Epoch 25: Validation loss decreased (0.556691 --> 0.555340).  Saving model ...
	 Train_Loss: 0.5998 Train_Acc: 70.758 Val_Loss: 0.5553  BEST VAL Loss: 0.5553  Val_Acc: 76.473

Epoch 26: Validation loss decreased (0.555340 --> 0.553817).  Saving model ...
	 Train_Loss: 0.5987 Train_Acc: 71.066 Val_Loss: 0.5538  BEST VAL Loss: 0.5538  Val_Acc: 75.868

Epoch 27: Validation loss decreased (0.553817 --> 0.552487).  Saving model ...
	 Train_Loss: 0.5977 Train_Acc: 70.920 Val_Loss: 0.5525  BEST VAL Loss: 0.5525  Val_Acc: 76.433

Epoch 28: Validation loss decreased (0.552487 --> 0.551574).  Saving model ...
	 Train_Loss: 0.5967 Train_Acc: 70.829 Val_Loss: 0.5516  BEST VAL Loss: 0.5516  Val_Acc: 75.424

Epoch 29: Validation loss decreased (0.551574 --> 0.550649).  Saving model ...
	 Train_Loss: 0.5957 Train_Acc: 71.106 Val_Loss: 0.5506  BEST VAL Loss: 0.5506  Val_Acc: 76.957

Epoch 30: Validation loss decreased (0.550649 --> 0.549550).  Saving model ...
	 Train_Loss: 0.5949 Train_Acc: 70.789 Val_Loss: 0.5495  BEST VAL Loss: 0.5495  Val_Acc: 76.755

Epoch 31: Validation loss decreased (0.549550 --> 0.548729).  Saving model ...
	 Train_Loss: 0.5939 Train_Acc: 71.717 Val_Loss: 0.5487  BEST VAL Loss: 0.5487  Val_Acc: 76.715

Epoch 32: Validation loss decreased (0.548729 --> 0.548338).  Saving model ...
	 Train_Loss: 0.5930 Train_Acc: 71.535 Val_Loss: 0.5483  BEST VAL Loss: 0.5483  Val_Acc: 75.868

Epoch 33: Validation loss decreased (0.548338 --> 0.547662).  Saving model ...
	 Train_Loss: 0.5923 Train_Acc: 70.758 Val_Loss: 0.5477  BEST VAL Loss: 0.5477  Val_Acc: 75.747

Epoch 34: Validation loss decreased (0.547662 --> 0.547102).  Saving model ...
	 Train_Loss: 0.5916 Train_Acc: 71.127 Val_Loss: 0.5471  BEST VAL Loss: 0.5471  Val_Acc: 76.352

Epoch 35: Validation loss decreased (0.547102 --> 0.546189).  Saving model ...
	 Train_Loss: 0.5909 Train_Acc: 71.500 Val_Loss: 0.5462  BEST VAL Loss: 0.5462  Val_Acc: 76.473

Epoch 36: Validation loss decreased (0.546189 --> 0.545704).  Saving model ...
	 Train_Loss: 0.5901 Train_Acc: 71.717 Val_Loss: 0.5457  BEST VAL Loss: 0.5457  Val_Acc: 75.504

Epoch 37: Validation loss decreased (0.545704 --> 0.544900).  Saving model ...
	 Train_Loss: 0.5893 Train_Acc: 71.490 Val_Loss: 0.5449  BEST VAL Loss: 0.5449  Val_Acc: 76.312

Epoch 38: Validation loss decreased (0.544900 --> 0.544212).  Saving model ...
	 Train_Loss: 0.5887 Train_Acc: 71.586 Val_Loss: 0.5442  BEST VAL Loss: 0.5442  Val_Acc: 77.199

Epoch 39: Validation loss decreased (0.544212 --> 0.543596).  Saving model ...
	 Train_Loss: 0.5879 Train_Acc: 71.661 Val_Loss: 0.5436  BEST VAL Loss: 0.5436  Val_Acc: 76.231

Epoch 40: Validation loss decreased (0.543596 --> 0.542960).  Saving model ...
	 Train_Loss: 0.5873 Train_Acc: 71.904 Val_Loss: 0.5430  BEST VAL Loss: 0.5430  Val_Acc: 76.715

Epoch 41: Validation loss decreased (0.542960 --> 0.542316).  Saving model ...
	 Train_Loss: 0.5866 Train_Acc: 71.888 Val_Loss: 0.5423  BEST VAL Loss: 0.5423  Val_Acc: 77.280

Epoch 42: Validation loss decreased (0.542316 --> 0.541809).  Saving model ...
	 Train_Loss: 0.5859 Train_Acc: 71.697 Val_Loss: 0.5418  BEST VAL Loss: 0.5418  Val_Acc: 76.352

Epoch 43: Validation loss decreased (0.541809 --> 0.541165).  Saving model ...
	 Train_Loss: 0.5854 Train_Acc: 71.636 Val_Loss: 0.5412  BEST VAL Loss: 0.5412  Val_Acc: 76.877

Epoch 44: Validation loss decreased (0.541165 --> 0.540714).  Saving model ...
	 Train_Loss: 0.5849 Train_Acc: 71.692 Val_Loss: 0.5407  BEST VAL Loss: 0.5407  Val_Acc: 76.594

Epoch 45: Validation loss decreased (0.540714 --> 0.540289).  Saving model ...
	 Train_Loss: 0.5842 Train_Acc: 72.302 Val_Loss: 0.5403  BEST VAL Loss: 0.5403  Val_Acc: 76.433

Epoch 46: Validation loss decreased (0.540289 --> 0.539736).  Saving model ...
	 Train_Loss: 0.5836 Train_Acc: 72.161 Val_Loss: 0.5397  BEST VAL Loss: 0.5397  Val_Acc: 76.352

Epoch 47: Validation loss decreased (0.539736 --> 0.539301).  Saving model ...
	 Train_Loss: 0.5832 Train_Acc: 71.843 Val_Loss: 0.5393  BEST VAL Loss: 0.5393  Val_Acc: 76.473

Epoch 48: Validation loss decreased (0.539301 --> 0.538694).  Saving model ...
	 Train_Loss: 0.5826 Train_Acc: 72.479 Val_Loss: 0.5387  BEST VAL Loss: 0.5387  Val_Acc: 77.199

Epoch 49: Validation loss decreased (0.538694 --> 0.538145).  Saving model ...
	 Train_Loss: 0.5821 Train_Acc: 71.909 Val_Loss: 0.5381  BEST VAL Loss: 0.5381  Val_Acc: 76.433

Epoch 50: Validation loss decreased (0.538145 --> 0.537834).  Saving model ...
	 Train_Loss: 0.5816 Train_Acc: 71.772 Val_Loss: 0.5378  BEST VAL Loss: 0.5378  Val_Acc: 75.827

Epoch 51: Validation loss decreased (0.537834 --> 0.537445).  Saving model ...
	 Train_Loss: 0.5812 Train_Acc: 72.030 Val_Loss: 0.5374  BEST VAL Loss: 0.5374  Val_Acc: 75.787

Epoch 52: Validation loss decreased (0.537445 --> 0.537144).  Saving model ...
	 Train_Loss: 0.5806 Train_Acc: 72.151 Val_Loss: 0.5371  BEST VAL Loss: 0.5371  Val_Acc: 76.029

Epoch 53: Validation loss decreased (0.537144 --> 0.536706).  Saving model ...
	 Train_Loss: 0.5802 Train_Acc: 71.924 Val_Loss: 0.5367  BEST VAL Loss: 0.5367  Val_Acc: 76.069

Epoch 54: Validation loss decreased (0.536706 --> 0.536258).  Saving model ...
	 Train_Loss: 0.5798 Train_Acc: 72.009 Val_Loss: 0.5363  BEST VAL Loss: 0.5363  Val_Acc: 76.594

Epoch 55: Validation loss decreased (0.536258 --> 0.535859).  Saving model ...
	 Train_Loss: 0.5793 Train_Acc: 71.984 Val_Loss: 0.5359  BEST VAL Loss: 0.5359  Val_Acc: 75.827

Epoch 56: Validation loss decreased (0.535859 --> 0.535599).  Saving model ...
	 Train_Loss: 0.5789 Train_Acc: 72.131 Val_Loss: 0.5356  BEST VAL Loss: 0.5356  Val_Acc: 76.473

Epoch 57: Validation loss decreased (0.535599 --> 0.535189).  Saving model ...
	 Train_Loss: 0.5785 Train_Acc: 72.438 Val_Loss: 0.5352  BEST VAL Loss: 0.5352  Val_Acc: 75.868

Epoch 58: Validation loss decreased (0.535189 --> 0.534996).  Saving model ...
	 Train_Loss: 0.5781 Train_Acc: 72.297 Val_Loss: 0.5350  BEST VAL Loss: 0.5350  Val_Acc: 76.836

Epoch 59: Validation loss decreased (0.534996 --> 0.534707).  Saving model ...
	 Train_Loss: 0.5777 Train_Acc: 72.055 Val_Loss: 0.5347  BEST VAL Loss: 0.5347  Val_Acc: 76.594

Epoch 60: Validation loss decreased (0.534707 --> 0.534493).  Saving model ...
	 Train_Loss: 0.5773 Train_Acc: 72.287 Val_Loss: 0.5345  BEST VAL Loss: 0.5345  Val_Acc: 75.948

Epoch 61: Validation loss decreased (0.534493 --> 0.534192).  Saving model ...
	 Train_Loss: 0.5769 Train_Acc: 72.272 Val_Loss: 0.5342  BEST VAL Loss: 0.5342  Val_Acc: 76.513

Epoch 62: Validation loss decreased (0.534192 --> 0.533842).  Saving model ...
	 Train_Loss: 0.5764 Train_Acc: 72.534 Val_Loss: 0.5338  BEST VAL Loss: 0.5338  Val_Acc: 76.433

Epoch 63: Validation loss decreased (0.533842 --> 0.533566).  Saving model ...
	 Train_Loss: 0.5760 Train_Acc: 72.635 Val_Loss: 0.5336  BEST VAL Loss: 0.5336  Val_Acc: 76.069

Epoch 64: Validation loss decreased (0.533566 --> 0.533303).  Saving model ...
	 Train_Loss: 0.5757 Train_Acc: 72.136 Val_Loss: 0.5333  BEST VAL Loss: 0.5333  Val_Acc: 75.908

Epoch 65: Validation loss decreased (0.533303 --> 0.532986).  Saving model ...
	 Train_Loss: 0.5753 Train_Acc: 72.090 Val_Loss: 0.5330  BEST VAL Loss: 0.5330  Val_Acc: 75.827

Epoch 66: Validation loss decreased (0.532986 --> 0.532891).  Saving model ...
	 Train_Loss: 0.5749 Train_Acc: 72.973 Val_Loss: 0.5329  BEST VAL Loss: 0.5329  Val_Acc: 76.110

Epoch 67: Validation loss decreased (0.532891 --> 0.532791).  Saving model ...
	 Train_Loss: 0.5746 Train_Acc: 72.267 Val_Loss: 0.5328  BEST VAL Loss: 0.5328  Val_Acc: 76.029

Epoch 68: Validation loss decreased (0.532791 --> 0.532596).  Saving model ...
	 Train_Loss: 0.5742 Train_Acc: 72.277 Val_Loss: 0.5326  BEST VAL Loss: 0.5326  Val_Acc: 76.554

Epoch 69: Validation loss decreased (0.532596 --> 0.532320).  Saving model ...
	 Train_Loss: 0.5738 Train_Acc: 73.170 Val_Loss: 0.5323  BEST VAL Loss: 0.5323  Val_Acc: 75.908

Epoch 70: Validation loss decreased (0.532320 --> 0.532063).  Saving model ...
	 Train_Loss: 0.5734 Train_Acc: 72.433 Val_Loss: 0.5321  BEST VAL Loss: 0.5321  Val_Acc: 76.513

Epoch 71: Validation loss decreased (0.532063 --> 0.531782).  Saving model ...
	 Train_Loss: 0.5731 Train_Acc: 72.161 Val_Loss: 0.5318  BEST VAL Loss: 0.5318  Val_Acc: 75.626

Epoch 72: Validation loss decreased (0.531782 --> 0.531625).  Saving model ...
	 Train_Loss: 0.5728 Train_Acc: 72.337 Val_Loss: 0.5316  BEST VAL Loss: 0.5316  Val_Acc: 76.271

Epoch 73: Validation loss decreased (0.531625 --> 0.531303).  Saving model ...
	 Train_Loss: 0.5725 Train_Acc: 72.358 Val_Loss: 0.5313  BEST VAL Loss: 0.5313  Val_Acc: 76.998

Epoch 74: Validation loss decreased (0.531303 --> 0.531063).  Saving model ...
	 Train_Loss: 0.5722 Train_Acc: 72.575 Val_Loss: 0.5311  BEST VAL Loss: 0.5311  Val_Acc: 75.948

Epoch 75: Validation loss decreased (0.531063 --> 0.530988).  Saving model ...
	 Train_Loss: 0.5718 Train_Acc: 73.013 Val_Loss: 0.5310  BEST VAL Loss: 0.5310  Val_Acc: 76.352

Epoch 76: Validation loss decreased (0.530988 --> 0.530769).  Saving model ...
	 Train_Loss: 0.5715 Train_Acc: 72.524 Val_Loss: 0.5308  BEST VAL Loss: 0.5308  Val_Acc: 76.554

Epoch 77: Validation loss decreased (0.530769 --> 0.530582).  Saving model ...
	 Train_Loss: 0.5712 Train_Acc: 72.716 Val_Loss: 0.5306  BEST VAL Loss: 0.5306  Val_Acc: 76.715

Epoch 78: Validation loss decreased (0.530582 --> 0.530420).  Saving model ...
	 Train_Loss: 0.5708 Train_Acc: 72.701 Val_Loss: 0.5304  BEST VAL Loss: 0.5304  Val_Acc: 75.747

Epoch 79: Validation loss decreased (0.530420 --> 0.530350).  Saving model ...
	 Train_Loss: 0.5706 Train_Acc: 72.731 Val_Loss: 0.5304  BEST VAL Loss: 0.5304  Val_Acc: 75.141

Epoch 80: Validation loss decreased (0.530350 --> 0.530126).  Saving model ...
	 Train_Loss: 0.5702 Train_Acc: 72.615 Val_Loss: 0.5301  BEST VAL Loss: 0.5301  Val_Acc: 76.190

Epoch 81: Validation loss decreased (0.530126 --> 0.529956).  Saving model ...
	 Train_Loss: 0.5699 Train_Acc: 72.918 Val_Loss: 0.5300  BEST VAL Loss: 0.5300  Val_Acc: 76.190

Epoch 82: Validation loss decreased (0.529956 --> 0.529717).  Saving model ...
	 Train_Loss: 0.5696 Train_Acc: 72.948 Val_Loss: 0.5297  BEST VAL Loss: 0.5297  Val_Acc: 76.513

Epoch 83: Validation loss decreased (0.529717 --> 0.529546).  Saving model ...
	 Train_Loss: 0.5693 Train_Acc: 72.635 Val_Loss: 0.5295  BEST VAL Loss: 0.5295  Val_Acc: 75.747

Epoch 84: Validation loss decreased (0.529546 --> 0.529369).  Saving model ...
	 Train_Loss: 0.5690 Train_Acc: 72.529 Val_Loss: 0.5294  BEST VAL Loss: 0.5294  Val_Acc: 75.747

Epoch 85: Validation loss decreased (0.529369 --> 0.529191).  Saving model ...
	 Train_Loss: 0.5688 Train_Acc: 72.479 Val_Loss: 0.5292  BEST VAL Loss: 0.5292  Val_Acc: 75.182

Epoch 86: Validation loss decreased (0.529191 --> 0.529086).  Saving model ...
	 Train_Loss: 0.5686 Train_Acc: 72.373 Val_Loss: 0.5291  BEST VAL Loss: 0.5291  Val_Acc: 75.343

Epoch 87: Validation loss decreased (0.529086 --> 0.528984).  Saving model ...
	 Train_Loss: 0.5683 Train_Acc: 72.731 Val_Loss: 0.5290  BEST VAL Loss: 0.5290  Val_Acc: 76.877

Epoch 88: Validation loss decreased (0.528984 --> 0.528731).  Saving model ...
	 Train_Loss: 0.5680 Train_Acc: 73.064 Val_Loss: 0.5287  BEST VAL Loss: 0.5287  Val_Acc: 76.513

Epoch 89: Validation loss decreased (0.528731 --> 0.528619).  Saving model ...
	 Train_Loss: 0.5678 Train_Acc: 72.231 Val_Loss: 0.5286  BEST VAL Loss: 0.5286  Val_Acc: 75.666

Epoch 90: Validation loss decreased (0.528619 --> 0.528580).  Saving model ...
	 Train_Loss: 0.5676 Train_Acc: 72.322 Val_Loss: 0.5286  BEST VAL Loss: 0.5286  Val_Acc: 76.190

Epoch 91: Validation loss decreased (0.528580 --> 0.528462).  Saving model ...
	 Train_Loss: 0.5673 Train_Acc: 72.887 Val_Loss: 0.5285  BEST VAL Loss: 0.5285  Val_Acc: 76.796

Epoch 92: Validation loss decreased (0.528462 --> 0.528381).  Saving model ...
	 Train_Loss: 0.5670 Train_Acc: 72.832 Val_Loss: 0.5284  BEST VAL Loss: 0.5284  Val_Acc: 76.271

Epoch 93: Validation loss decreased (0.528381 --> 0.528207).  Saving model ...
	 Train_Loss: 0.5668 Train_Acc: 72.438 Val_Loss: 0.5282  BEST VAL Loss: 0.5282  Val_Acc: 75.747

Epoch 94: Validation loss decreased (0.528207 --> 0.528077).  Saving model ...
	 Train_Loss: 0.5665 Train_Acc: 72.766 Val_Loss: 0.5281  BEST VAL Loss: 0.5281  Val_Acc: 76.836

Epoch 95: Validation loss decreased (0.528077 --> 0.527921).  Saving model ...
	 Train_Loss: 0.5664 Train_Acc: 72.428 Val_Loss: 0.5279  BEST VAL Loss: 0.5279  Val_Acc: 76.271

Epoch 96: Validation loss decreased (0.527921 --> 0.527810).  Saving model ...
	 Train_Loss: 0.5661 Train_Acc: 73.013 Val_Loss: 0.5278  BEST VAL Loss: 0.5278  Val_Acc: 76.069

Epoch 97: Validation loss decreased (0.527810 --> 0.527661).  Saving model ...
	 Train_Loss: 0.5659 Train_Acc: 72.564 Val_Loss: 0.5277  BEST VAL Loss: 0.5277  Val_Acc: 76.473

Epoch 98: Validation loss decreased (0.527661 --> 0.527555).  Saving model ...
	 Train_Loss: 0.5657 Train_Acc: 72.842 Val_Loss: 0.5276  BEST VAL Loss: 0.5276  Val_Acc: 75.989

Epoch 99: Validation loss decreased (0.527555 --> 0.527443).  Saving model ...
	 Train_Loss: 0.5655 Train_Acc: 73.205 Val_Loss: 0.5274  BEST VAL Loss: 0.5274  Val_Acc: 76.594

LPS_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.59      0.53      9707
           1       0.51      0.41      0.46     10114

    accuracy                           0.50     19821
   macro avg       0.50      0.50      0.50     19821
weighted avg       0.50      0.50      0.49     19821

LPS_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.56      0.51      1214
           1       0.49      0.40      0.44      1264

    accuracy                           0.48      2478
   macro avg       0.48      0.48      0.48      2478
weighted avg       0.48      0.48      0.47      2478

LPS_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.60      0.54      1214
           1       0.52      0.41      0.46      1264

    accuracy                           0.50      2478
   macro avg       0.51      0.51      0.50      2478
weighted avg       0.51      0.50      0.50      2478

              precision    recall  f1-score   support

           0       0.49      0.60      0.54      1214
           1       0.52      0.41      0.46      1264

    accuracy                           0.50      2478
   macro avg       0.51      0.51      0.50      2478
weighted avg       0.51      0.50      0.50      2478

LPS_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.56      0.51      3724
           1       0.53      0.45      0.49      4168

    accuracy                           0.50      7892
   macro avg       0.51      0.51      0.50      7892
weighted avg       0.51      0.50      0.50      7892

              precision    recall  f1-score   support

           0       0.48      0.56      0.51      3724
           1       0.53      0.45      0.49      4168

    accuracy                           0.50      7892
   macro avg       0.51      0.51      0.50      7892
weighted avg       0.51      0.50      0.50      7892

completed
