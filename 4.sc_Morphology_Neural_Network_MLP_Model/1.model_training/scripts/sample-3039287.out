[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd8a9144a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '7fc0e0ce'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '3fb52e35'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '3b2bb212'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_1.000_DMSO_0.025 treatment_name: H2O2_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_1.000_DMSO_0.025
TREATMENT_NAME: H2O2_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['H2O2_100.000_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (42709, 1276)
Number of total missing values across all columns: 85418
Data Subset Is Off
Wells held out for testing: ['I22' 'M22']
Wells to use for training, validation, and testing ['H18' 'H19' 'H22' 'H23' 'I18' 'M18' 'I19' 'M19' 'I23' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.587278).  Saving model ...
	 Train_Loss: 0.6294 Train_Acc: 66.723 Val_Loss: 0.5873  BEST VAL Loss: 0.5873  Val_Acc: 67.012

Epoch 1: Validation loss decreased (0.587278 --> 0.575139).  Saving model ...
	 Train_Loss: 0.6080 Train_Acc: 66.999 Val_Loss: 0.5751  BEST VAL Loss: 0.5751  Val_Acc: 67.012

Epoch 2: Validation loss decreased (0.575139 --> 0.566539).  Saving model ...
	 Train_Loss: 0.5936 Train_Acc: 66.999 Val_Loss: 0.5665  BEST VAL Loss: 0.5665  Val_Acc: 67.012

Epoch 3: Validation loss decreased (0.566539 --> 0.557667).  Saving model ...
	 Train_Loss: 0.5821 Train_Acc: 66.999 Val_Loss: 0.5577  BEST VAL Loss: 0.5577  Val_Acc: 67.012

Epoch 4: Validation loss decreased (0.557667 --> 0.549322).  Saving model ...
	 Train_Loss: 0.5725 Train_Acc: 66.999 Val_Loss: 0.5493  BEST VAL Loss: 0.5493  Val_Acc: 67.012

Epoch 5: Validation loss decreased (0.549322 --> 0.541767).  Saving model ...
	 Train_Loss: 0.5639 Train_Acc: 66.999 Val_Loss: 0.5418  BEST VAL Loss: 0.5418  Val_Acc: 67.012

Epoch 6: Validation loss decreased (0.541767 --> 0.534906).  Saving model ...
	 Train_Loss: 0.5560 Train_Acc: 66.999 Val_Loss: 0.5349  BEST VAL Loss: 0.5349  Val_Acc: 67.012

Epoch 7: Validation loss decreased (0.534906 --> 0.529148).  Saving model ...
	 Train_Loss: 0.5489 Train_Acc: 72.302 Val_Loss: 0.5291  BEST VAL Loss: 0.5291  Val_Acc: 74.874

Epoch 8: Validation loss decreased (0.529148 --> 0.523271).  Saving model ...
	 Train_Loss: 0.5422 Train_Acc: 75.790 Val_Loss: 0.5233  BEST VAL Loss: 0.5233  Val_Acc: 76.077

Epoch 9: Validation loss decreased (0.523271 --> 0.517736).  Saving model ...
	 Train_Loss: 0.5361 Train_Acc: 76.720 Val_Loss: 0.5177  BEST VAL Loss: 0.5177  Val_Acc: 76.749

Epoch 10: Validation loss decreased (0.517736 --> 0.512550).  Saving model ...
	 Train_Loss: 0.5303 Train_Acc: 77.091 Val_Loss: 0.5126  BEST VAL Loss: 0.5126  Val_Acc: 77.476

Epoch 11: Validation loss decreased (0.512550 --> 0.507996).  Saving model ...
	 Train_Loss: 0.5248 Train_Acc: 78.144 Val_Loss: 0.5080  BEST VAL Loss: 0.5080  Val_Acc: 77.924

Epoch 12: Validation loss decreased (0.507996 --> 0.503582).  Saving model ...
	 Train_Loss: 0.5198 Train_Acc: 78.385 Val_Loss: 0.5036  BEST VAL Loss: 0.5036  Val_Acc: 78.456

Epoch 13: Validation loss decreased (0.503582 --> 0.499610).  Saving model ...
	 Train_Loss: 0.5150 Train_Acc: 79.085 Val_Loss: 0.4996  BEST VAL Loss: 0.4996  Val_Acc: 78.679

Epoch 14: Validation loss decreased (0.499610 --> 0.495720).  Saving model ...
	 Train_Loss: 0.5105 Train_Acc: 79.449 Val_Loss: 0.4957  BEST VAL Loss: 0.4957  Val_Acc: 78.679

Epoch 15: Validation loss decreased (0.495720 --> 0.492192).  Saving model ...
	 Train_Loss: 0.5064 Train_Acc: 79.487 Val_Loss: 0.4922  BEST VAL Loss: 0.4922  Val_Acc: 79.491

Epoch 16: Validation loss decreased (0.492192 --> 0.488900).  Saving model ...
	 Train_Loss: 0.5025 Train_Acc: 79.949 Val_Loss: 0.4889  BEST VAL Loss: 0.4889  Val_Acc: 79.882

Epoch 17: Validation loss decreased (0.488900 --> 0.485735).  Saving model ...
	 Train_Loss: 0.4986 Train_Acc: 80.043 Val_Loss: 0.4857  BEST VAL Loss: 0.4857  Val_Acc: 79.799

Epoch 18: Validation loss decreased (0.485735 --> 0.483044).  Saving model ...
	 Train_Loss: 0.4950 Train_Acc: 80.610 Val_Loss: 0.4830  BEST VAL Loss: 0.4830  Val_Acc: 80.722

Epoch 19: Validation loss decreased (0.483044 --> 0.480339).  Saving model ...
	 Train_Loss: 0.4917 Train_Acc: 80.505 Val_Loss: 0.4803  BEST VAL Loss: 0.4803  Val_Acc: 80.106

Epoch 20: Validation loss decreased (0.480339 --> 0.477642).  Saving model ...
	 Train_Loss: 0.4885 Train_Acc: 80.876 Val_Loss: 0.4776  BEST VAL Loss: 0.4776  Val_Acc: 80.470

Epoch 21: Validation loss decreased (0.477642 --> 0.475295).  Saving model ...
	 Train_Loss: 0.4856 Train_Acc: 80.932 Val_Loss: 0.4753  BEST VAL Loss: 0.4753  Val_Acc: 80.750

Epoch 22: Validation loss decreased (0.475295 --> 0.472963).  Saving model ...
	 Train_Loss: 0.4826 Train_Acc: 81.289 Val_Loss: 0.4730  BEST VAL Loss: 0.4730  Val_Acc: 80.890

Epoch 23: Validation loss decreased (0.472963 --> 0.470755).  Saving model ...
	 Train_Loss: 0.4799 Train_Acc: 81.152 Val_Loss: 0.4708  BEST VAL Loss: 0.4708  Val_Acc: 80.582

Epoch 24: Validation loss decreased (0.470755 --> 0.468757).  Saving model ...
	 Train_Loss: 0.4774 Train_Acc: 81.380 Val_Loss: 0.4688  BEST VAL Loss: 0.4688  Val_Acc: 81.030

Epoch 25: Validation loss decreased (0.468757 --> 0.467221).  Saving model ...
	 Train_Loss: 0.4749 Train_Acc: 81.359 Val_Loss: 0.4672  BEST VAL Loss: 0.4672  Val_Acc: 81.421

Epoch 26: Validation loss decreased (0.467221 --> 0.465184).  Saving model ...
	 Train_Loss: 0.4725 Train_Acc: 81.694 Val_Loss: 0.4652  BEST VAL Loss: 0.4652  Val_Acc: 81.729

Epoch 27: Validation loss decreased (0.465184 --> 0.463248).  Saving model ...
	 Train_Loss: 0.4702 Train_Acc: 81.715 Val_Loss: 0.4632  BEST VAL Loss: 0.4632  Val_Acc: 81.785

Epoch 28: Validation loss decreased (0.463248 --> 0.461421).  Saving model ...
	 Train_Loss: 0.4680 Train_Acc: 81.705 Val_Loss: 0.4614  BEST VAL Loss: 0.4614  Val_Acc: 82.121

Epoch 29: Validation loss decreased (0.461421 --> 0.459696).  Saving model ...
	 Train_Loss: 0.4660 Train_Acc: 81.569 Val_Loss: 0.4597  BEST VAL Loss: 0.4597  Val_Acc: 81.757

Epoch 30: Validation loss decreased (0.459696 --> 0.458864).  Saving model ...
	 Train_Loss: 0.4640 Train_Acc: 81.810 Val_Loss: 0.4589  BEST VAL Loss: 0.4589  Val_Acc: 79.407

Epoch 31: Validation loss decreased (0.458864 --> 0.457531).  Saving model ...
	 Train_Loss: 0.4621 Train_Acc: 81.894 Val_Loss: 0.4575  BEST VAL Loss: 0.4575  Val_Acc: 81.561

Epoch 32: Validation loss decreased (0.457531 --> 0.456015).  Saving model ...
	 Train_Loss: 0.4602 Train_Acc: 82.044 Val_Loss: 0.4560  BEST VAL Loss: 0.4560  Val_Acc: 82.513

Epoch 33: Validation loss decreased (0.456015 --> 0.454520).  Saving model ...
	 Train_Loss: 0.4585 Train_Acc: 82.013 Val_Loss: 0.4545  BEST VAL Loss: 0.4545  Val_Acc: 82.149

Epoch 34: Validation loss decreased (0.454520 --> 0.453170).  Saving model ...
	 Train_Loss: 0.4568 Train_Acc: 82.286 Val_Loss: 0.4532  BEST VAL Loss: 0.4532  Val_Acc: 82.177

Epoch 35: Validation loss decreased (0.453170 --> 0.451815).  Saving model ...
	 Train_Loss: 0.4552 Train_Acc: 82.328 Val_Loss: 0.4518  BEST VAL Loss: 0.4518  Val_Acc: 82.317

Epoch 36: Validation loss decreased (0.451815 --> 0.450515).  Saving model ...
	 Train_Loss: 0.4536 Train_Acc: 82.118 Val_Loss: 0.4505  BEST VAL Loss: 0.4505  Val_Acc: 82.037

Epoch 37: Validation loss decreased (0.450515 --> 0.449633).  Saving model ...
	 Train_Loss: 0.4520 Train_Acc: 82.408 Val_Loss: 0.4496  BEST VAL Loss: 0.4496  Val_Acc: 81.170

Epoch 38: Validation loss decreased (0.449633 --> 0.448448).  Saving model ...
	 Train_Loss: 0.4506 Train_Acc: 82.303 Val_Loss: 0.4484  BEST VAL Loss: 0.4484  Val_Acc: 82.037

Epoch 39: Validation loss decreased (0.448448 --> 0.447301).  Saving model ...
	 Train_Loss: 0.4492 Train_Acc: 82.370 Val_Loss: 0.4473  BEST VAL Loss: 0.4473  Val_Acc: 82.289

Epoch 40: Validation loss decreased (0.447301 --> 0.446151).  Saving model ...
	 Train_Loss: 0.4478 Train_Acc: 82.789 Val_Loss: 0.4462  BEST VAL Loss: 0.4462  Val_Acc: 82.429

Epoch 41: Validation loss decreased (0.446151 --> 0.445220).  Saving model ...
	 Train_Loss: 0.4465 Train_Acc: 82.534 Val_Loss: 0.4452  BEST VAL Loss: 0.4452  Val_Acc: 81.981

Epoch 42: Validation loss decreased (0.445220 --> 0.444272).  Saving model ...
	 Train_Loss: 0.4451 Train_Acc: 82.887 Val_Loss: 0.4443  BEST VAL Loss: 0.4443  Val_Acc: 82.429

Epoch 43: Validation loss decreased (0.444272 --> 0.443231).  Saving model ...
	 Train_Loss: 0.4439 Train_Acc: 82.632 Val_Loss: 0.4432  BEST VAL Loss: 0.4432  Val_Acc: 81.673

Epoch 44: Validation loss decreased (0.443231 --> 0.442486).  Saving model ...
	 Train_Loss: 0.4427 Train_Acc: 82.698 Val_Loss: 0.4425  BEST VAL Loss: 0.4425  Val_Acc: 82.485

Epoch 45: Validation loss decreased (0.442486 --> 0.441533).  Saving model ...
	 Train_Loss: 0.4415 Train_Acc: 82.940 Val_Loss: 0.4415  BEST VAL Loss: 0.4415  Val_Acc: 82.708

Epoch 46: Validation loss decreased (0.441533 --> 0.440600).  Saving model ...
	 Train_Loss: 0.4403 Train_Acc: 82.747 Val_Loss: 0.4406  BEST VAL Loss: 0.4406  Val_Acc: 82.065

Epoch 47: Validation loss decreased (0.440600 --> 0.439746).  Saving model ...
	 Train_Loss: 0.4392 Train_Acc: 82.919 Val_Loss: 0.4397  BEST VAL Loss: 0.4397  Val_Acc: 81.841

Epoch 48: Validation loss decreased (0.439746 --> 0.438950).  Saving model ...
	 Train_Loss: 0.4381 Train_Acc: 82.929 Val_Loss: 0.4390  BEST VAL Loss: 0.4390  Val_Acc: 81.393

Epoch 49: Validation loss decreased (0.438950 --> 0.438262).  Saving model ...
	 Train_Loss: 0.4370 Train_Acc: 83.136 Val_Loss: 0.4383  BEST VAL Loss: 0.4383  Val_Acc: 81.757

Epoch 50: Validation loss decreased (0.438262 --> 0.437457).  Saving model ...
	 Train_Loss: 0.4359 Train_Acc: 83.048 Val_Loss: 0.4375  BEST VAL Loss: 0.4375  Val_Acc: 82.680

Epoch 51: Validation loss decreased (0.437457 --> 0.436768).  Saving model ...
	 Train_Loss: 0.4350 Train_Acc: 82.926 Val_Loss: 0.4368  BEST VAL Loss: 0.4368  Val_Acc: 82.037

Epoch 52: Validation loss decreased (0.436768 --> 0.436061).  Saving model ...
	 Train_Loss: 0.4340 Train_Acc: 83.013 Val_Loss: 0.4361  BEST VAL Loss: 0.4361  Val_Acc: 82.541

Epoch 53: Validation loss decreased (0.436061 --> 0.435323).  Saving model ...
	 Train_Loss: 0.4332 Train_Acc: 82.933 Val_Loss: 0.4353  BEST VAL Loss: 0.4353  Val_Acc: 82.485

Epoch 54: Validation loss decreased (0.435323 --> 0.434639).  Saving model ...
	 Train_Loss: 0.4322 Train_Acc: 83.328 Val_Loss: 0.4346  BEST VAL Loss: 0.4346  Val_Acc: 82.680

Epoch 55: Validation loss decreased (0.434639 --> 0.433991).  Saving model ...
	 Train_Loss: 0.4313 Train_Acc: 83.024 Val_Loss: 0.4340  BEST VAL Loss: 0.4340  Val_Acc: 82.317

Epoch 56: Validation loss decreased (0.433991 --> 0.433322).  Saving model ...
	 Train_Loss: 0.4304 Train_Acc: 83.209 Val_Loss: 0.4333  BEST VAL Loss: 0.4333  Val_Acc: 82.820

Epoch 57: Validation loss decreased (0.433322 --> 0.432751).  Saving model ...
	 Train_Loss: 0.4295 Train_Acc: 83.402 Val_Loss: 0.4328  BEST VAL Loss: 0.4328  Val_Acc: 81.953

Epoch 58: Validation loss decreased (0.432751 --> 0.432165).  Saving model ...
	 Train_Loss: 0.4286 Train_Acc: 83.531 Val_Loss: 0.4322  BEST VAL Loss: 0.4322  Val_Acc: 82.680

Epoch 59: Validation loss decreased (0.432165 --> 0.431467).  Saving model ...
	 Train_Loss: 0.4277 Train_Acc: 83.447 Val_Loss: 0.4315  BEST VAL Loss: 0.4315  Val_Acc: 83.072

Epoch 60: Validation loss decreased (0.431467 --> 0.430967).  Saving model ...
	 Train_Loss: 0.4268 Train_Acc: 83.458 Val_Loss: 0.4310  BEST VAL Loss: 0.4310  Val_Acc: 82.513

Epoch 61: Validation loss decreased (0.430967 --> 0.430470).  Saving model ...
	 Train_Loss: 0.4261 Train_Acc: 83.111 Val_Loss: 0.4305  BEST VAL Loss: 0.4305  Val_Acc: 82.848

Epoch 62: Validation loss decreased (0.430470 --> 0.429863).  Saving model ...
	 Train_Loss: 0.4253 Train_Acc: 83.517 Val_Loss: 0.4299  BEST VAL Loss: 0.4299  Val_Acc: 82.988

Epoch 63: Validation loss decreased (0.429863 --> 0.429406).  Saving model ...
	 Train_Loss: 0.4245 Train_Acc: 83.517 Val_Loss: 0.4294  BEST VAL Loss: 0.4294  Val_Acc: 83.100

Epoch 64: Validation loss decreased (0.429406 --> 0.428920).  Saving model ...
	 Train_Loss: 0.4237 Train_Acc: 83.517 Val_Loss: 0.4289  BEST VAL Loss: 0.4289  Val_Acc: 82.876

Epoch 65: Validation loss decreased (0.428920 --> 0.428349).  Saving model ...
	 Train_Loss: 0.4229 Train_Acc: 83.517 Val_Loss: 0.4283  BEST VAL Loss: 0.4283  Val_Acc: 82.652

Epoch 66: Validation loss decreased (0.428349 --> 0.427852).  Saving model ...
	 Train_Loss: 0.4222 Train_Acc: 83.587 Val_Loss: 0.4279  BEST VAL Loss: 0.4279  Val_Acc: 82.904

Epoch 67: Validation loss decreased (0.427852 --> 0.427396).  Saving model ...
	 Train_Loss: 0.4215 Train_Acc: 83.517 Val_Loss: 0.4274  BEST VAL Loss: 0.4274  Val_Acc: 83.100

Epoch 68: Validation loss decreased (0.427396 --> 0.427031).  Saving model ...
	 Train_Loss: 0.4208 Train_Acc: 83.587 Val_Loss: 0.4270  BEST VAL Loss: 0.4270  Val_Acc: 82.792

Epoch 69: Validation loss decreased (0.427031 --> 0.426497).  Saving model ...
	 Train_Loss: 0.4201 Train_Acc: 83.720 Val_Loss: 0.4265  BEST VAL Loss: 0.4265  Val_Acc: 82.876

Epoch 70: Validation loss decreased (0.426497 --> 0.425986).  Saving model ...
	 Train_Loss: 0.4194 Train_Acc: 83.814 Val_Loss: 0.4260  BEST VAL Loss: 0.4260  Val_Acc: 83.296

Epoch 71: Validation loss decreased (0.425986 --> 0.425473).  Saving model ...
	 Train_Loss: 0.4187 Train_Acc: 84.010 Val_Loss: 0.4255  BEST VAL Loss: 0.4255  Val_Acc: 82.792

Epoch 72: Validation loss decreased (0.425473 --> 0.425163).  Saving model ...
	 Train_Loss: 0.4181 Train_Acc: 83.723 Val_Loss: 0.4252  BEST VAL Loss: 0.4252  Val_Acc: 82.904

Epoch 73: Validation loss decreased (0.425163 --> 0.424828).  Saving model ...
	 Train_Loss: 0.4175 Train_Acc: 83.765 Val_Loss: 0.4248  BEST VAL Loss: 0.4248  Val_Acc: 82.764

Epoch 74: Validation loss decreased (0.424828 --> 0.424401).  Saving model ...
	 Train_Loss: 0.4169 Train_Acc: 83.465 Val_Loss: 0.4244  BEST VAL Loss: 0.4244  Val_Acc: 83.464

Epoch 75: Validation loss decreased (0.424401 --> 0.423968).  Saving model ...
	 Train_Loss: 0.4163 Train_Acc: 83.692 Val_Loss: 0.4240  BEST VAL Loss: 0.4240  Val_Acc: 83.016

Epoch 76: Validation loss decreased (0.423968 --> 0.423599).  Saving model ...
	 Train_Loss: 0.4157 Train_Acc: 83.839 Val_Loss: 0.4236  BEST VAL Loss: 0.4236  Val_Acc: 82.792

Epoch 77: Validation loss decreased (0.423599 --> 0.423239).  Saving model ...
	 Train_Loss: 0.4151 Train_Acc: 83.629 Val_Loss: 0.4232  BEST VAL Loss: 0.4232  Val_Acc: 82.764

Epoch 78: Validation loss decreased (0.423239 --> 0.422843).  Saving model ...
	 Train_Loss: 0.4144 Train_Acc: 84.066 Val_Loss: 0.4228  BEST VAL Loss: 0.4228  Val_Acc: 82.932

Epoch 79: Validation loss decreased (0.422843 --> 0.422508).  Saving model ...
	 Train_Loss: 0.4139 Train_Acc: 83.902 Val_Loss: 0.4225  BEST VAL Loss: 0.4225  Val_Acc: 82.485

Epoch 80: Validation loss decreased (0.422508 --> 0.422187).  Saving model ...
	 Train_Loss: 0.4133 Train_Acc: 84.196 Val_Loss: 0.4222  BEST VAL Loss: 0.4222  Val_Acc: 82.597

Epoch 81: Validation loss decreased (0.422187 --> 0.421832).  Saving model ...
	 Train_Loss: 0.4127 Train_Acc: 84.045 Val_Loss: 0.4218  BEST VAL Loss: 0.4218  Val_Acc: 82.792

Epoch 82: Validation loss decreased (0.421832 --> 0.421522).  Saving model ...
	 Train_Loss: 0.4121 Train_Acc: 83.814 Val_Loss: 0.4215  BEST VAL Loss: 0.4215  Val_Acc: 82.960

Epoch 83: Validation loss decreased (0.421522 --> 0.421246).  Saving model ...
	 Train_Loss: 0.4116 Train_Acc: 84.157 Val_Loss: 0.4212  BEST VAL Loss: 0.4212  Val_Acc: 82.960

Epoch 84: Validation loss decreased (0.421246 --> 0.420960).  Saving model ...
	 Train_Loss: 0.4110 Train_Acc: 84.122 Val_Loss: 0.4210  BEST VAL Loss: 0.4210  Val_Acc: 83.184

Epoch 85: Validation loss decreased (0.420960 --> 0.420693).  Saving model ...
	 Train_Loss: 0.4105 Train_Acc: 84.178 Val_Loss: 0.4207  BEST VAL Loss: 0.4207  Val_Acc: 82.736

Epoch 86: Validation loss decreased (0.420693 --> 0.420506).  Saving model ...
	 Train_Loss: 0.4100 Train_Acc: 84.007 Val_Loss: 0.4205  BEST VAL Loss: 0.4205  Val_Acc: 83.296

Epoch 87: Validation loss decreased (0.420506 --> 0.420224).  Saving model ...
	 Train_Loss: 0.4095 Train_Acc: 83.776 Val_Loss: 0.4202  BEST VAL Loss: 0.4202  Val_Acc: 81.925

Epoch 88: Validation loss decreased (0.420224 --> 0.420093).  Saving model ...
	 Train_Loss: 0.4090 Train_Acc: 84.227 Val_Loss: 0.4201  BEST VAL Loss: 0.4201  Val_Acc: 81.869

Epoch 89: Validation loss decreased (0.420093 --> 0.419913).  Saving model ...
	 Train_Loss: 0.4085 Train_Acc: 83.734 Val_Loss: 0.4199  BEST VAL Loss: 0.4199  Val_Acc: 82.289

Epoch 90: Validation loss decreased (0.419913 --> 0.419601).  Saving model ...
	 Train_Loss: 0.4081 Train_Acc: 83.765 Val_Loss: 0.4196  BEST VAL Loss: 0.4196  Val_Acc: 82.652

Epoch 91: Validation loss decreased (0.419601 --> 0.419312).  Saving model ...
	 Train_Loss: 0.4076 Train_Acc: 84.231 Val_Loss: 0.4193  BEST VAL Loss: 0.4193  Val_Acc: 82.960

Epoch 92: Validation loss decreased (0.419312 --> 0.419019).  Saving model ...
	 Train_Loss: 0.4070 Train_Acc: 84.353 Val_Loss: 0.4190  BEST VAL Loss: 0.4190  Val_Acc: 82.569

Epoch 93: Validation loss decreased (0.419019 --> 0.418729).  Saving model ...
	 Train_Loss: 0.4066 Train_Acc: 84.234 Val_Loss: 0.4187  BEST VAL Loss: 0.4187  Val_Acc: 82.401

Epoch 94: Validation loss decreased (0.418729 --> 0.418400).  Saving model ...
	 Train_Loss: 0.4061 Train_Acc: 84.157 Val_Loss: 0.4184  BEST VAL Loss: 0.4184  Val_Acc: 83.660

Epoch 95: Validation loss decreased (0.418400 --> 0.418226).  Saving model ...
	 Train_Loss: 0.4056 Train_Acc: 83.902 Val_Loss: 0.4182  BEST VAL Loss: 0.4182  Val_Acc: 83.072

Epoch 96: Validation loss decreased (0.418226 --> 0.417920).  Saving model ...
	 Train_Loss: 0.4052 Train_Acc: 84.311 Val_Loss: 0.4179  BEST VAL Loss: 0.4179  Val_Acc: 83.380

Epoch 97: Validation loss decreased (0.417920 --> 0.417741).  Saving model ...
	 Train_Loss: 0.4048 Train_Acc: 84.094 Val_Loss: 0.4177  BEST VAL Loss: 0.4177  Val_Acc: 83.548

Epoch 98: Validation loss decreased (0.417741 --> 0.417574).  Saving model ...
	 Train_Loss: 0.4043 Train_Acc: 84.171 Val_Loss: 0.4176  BEST VAL Loss: 0.4176  Val_Acc: 82.708

Epoch 99: Validation loss decreased (0.417574 --> 0.417319).  Saving model ...
	 Train_Loss: 0.4039 Train_Acc: 84.276 Val_Loss: 0.4173  BEST VAL Loss: 0.4173  Val_Acc: 83.156

Flagellin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.33      0.34      0.34      9434
           1       0.67      0.67      0.67     19153

    accuracy                           0.56     28587
   macro avg       0.50      0.50      0.50     28587
weighted avg       0.56      0.56      0.56     28587

Flagellin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.31      0.32      0.32      1179
           1       0.66      0.65      0.66      2395

    accuracy                           0.54      3574
   macro avg       0.49      0.49      0.49      3574
weighted avg       0.55      0.54      0.55      3574

Flagellin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.33      0.34      0.33      1179
           1       0.67      0.67      0.67      2395

    accuracy                           0.56      3574
   macro avg       0.50      0.50      0.50      3574
weighted avg       0.56      0.56      0.56      3574

              precision    recall  f1-score   support

           0       0.33      0.34      0.33      1179
           1       0.67      0.67      0.67      2395

    accuracy                           0.56      3574
   macro avg       0.50      0.50      0.50      3574
weighted avg       0.56      0.56      0.56      3574

Flagellin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.59      0.22      0.32      4017
           1       0.43      0.78      0.55      2957

    accuracy                           0.46      6974
   macro avg       0.51      0.50      0.44      6974
weighted avg       0.52      0.46      0.42      6974

              precision    recall  f1-score   support

           0       0.59      0.22      0.32      4017
           1       0.43      0.78      0.55      2957

    accuracy                           0.46      6974
   macro avg       0.51      0.50      0.44      6974
weighted avg       0.52      0.46      0.42      6974

completed
