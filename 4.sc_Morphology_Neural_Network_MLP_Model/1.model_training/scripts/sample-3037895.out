[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '7aab2353'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '6db1d431'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '0a979b01'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '674c006c'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_100.000_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_100.000_DMSO_0.025
TREATMENT_NAME: Flagellin_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_100.000_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (31796, 1276)
Number of total missing values across all columns: 63592
Data Subset Is Off
Wells held out for testing: ['J16' 'M22']
Wells to use for training, validation, and testing ['J17' 'M18' 'M19' 'J20' 'J21' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.464866).  Saving model ...
	 Train_Loss: 0.5917 Train_Acc: 68.633 Val_Loss: 0.4649  BEST VAL Loss: 0.4649  Val_Acc: 80.236

Epoch 1: Validation loss decreased (0.464866 --> 0.418314).  Saving model ...
	 Train_Loss: 0.5336 Train_Acc: 78.511 Val_Loss: 0.4183  BEST VAL Loss: 0.4183  Val_Acc: 85.811

Epoch 2: Validation loss decreased (0.418314 --> 0.391052).  Saving model ...
	 Train_Loss: 0.4924 Train_Acc: 82.624 Val_Loss: 0.3911  BEST VAL Loss: 0.3911  Val_Acc: 86.444

Epoch 3: Validation loss decreased (0.391052 --> 0.373652).  Saving model ...
	 Train_Loss: 0.4650 Train_Acc: 83.902 Val_Loss: 0.3737  BEST VAL Loss: 0.3737  Val_Acc: 88.471

Epoch 4: Validation loss decreased (0.373652 --> 0.360575).  Saving model ...
	 Train_Loss: 0.4437 Train_Acc: 84.905 Val_Loss: 0.3606  BEST VAL Loss: 0.3606  Val_Acc: 89.485

Epoch 5: Validation loss decreased (0.360575 --> 0.349929).  Saving model ...
	 Train_Loss: 0.4272 Train_Acc: 85.808 Val_Loss: 0.3499  BEST VAL Loss: 0.3499  Val_Acc: 88.302

Epoch 6: Validation loss decreased (0.349929 --> 0.341407).  Saving model ...
	 Train_Loss: 0.4125 Train_Acc: 86.816 Val_Loss: 0.3414  BEST VAL Loss: 0.3414  Val_Acc: 90.329

Epoch 7: Validation loss decreased (0.341407 --> 0.332688).  Saving model ...
	 Train_Loss: 0.3997 Train_Acc: 87.693 Val_Loss: 0.3327  BEST VAL Loss: 0.3327  Val_Acc: 91.090

Epoch 8: Validation loss decreased (0.332688 --> 0.327112).  Saving model ...
	 Train_Loss: 0.3894 Train_Acc: 87.598 Val_Loss: 0.3271  BEST VAL Loss: 0.3271  Val_Acc: 90.625

Epoch 9: Validation loss decreased (0.327112 --> 0.322053).  Saving model ...
	 Train_Loss: 0.3811 Train_Acc: 87.682 Val_Loss: 0.3221  BEST VAL Loss: 0.3221  Val_Acc: 90.709

Epoch 10: Validation loss decreased (0.322053 --> 0.317454).  Saving model ...
	 Train_Loss: 0.3724 Train_Acc: 88.590 Val_Loss: 0.3175  BEST VAL Loss: 0.3175  Val_Acc: 90.878

Epoch 11: Validation loss decreased (0.317454 --> 0.313489).  Saving model ...
	 Train_Loss: 0.3650 Train_Acc: 89.034 Val_Loss: 0.3135  BEST VAL Loss: 0.3135  Val_Acc: 91.090

Epoch 12: Validation loss decreased (0.313489 --> 0.310180).  Saving model ...
	 Train_Loss: 0.3584 Train_Acc: 88.902 Val_Loss: 0.3102  BEST VAL Loss: 0.3102  Val_Acc: 91.596

Epoch 13: Validation loss decreased (0.310180 --> 0.307981).  Saving model ...
	 Train_Loss: 0.3525 Train_Acc: 89.366 Val_Loss: 0.3080  BEST VAL Loss: 0.3080  Val_Acc: 91.470

Epoch 14: Validation loss decreased (0.307981 --> 0.305079).  Saving model ...
	 Train_Loss: 0.3471 Train_Acc: 89.710 Val_Loss: 0.3051  BEST VAL Loss: 0.3051  Val_Acc: 91.681

Epoch 15: Validation loss decreased (0.305079 --> 0.301724).  Saving model ...
	 Train_Loss: 0.3424 Train_Acc: 89.366 Val_Loss: 0.3017  BEST VAL Loss: 0.3017  Val_Acc: 91.596

Epoch 16: Validation loss decreased (0.301724 --> 0.298077).  Saving model ...
	 Train_Loss: 0.3381 Train_Acc: 89.551 Val_Loss: 0.2981  BEST VAL Loss: 0.2981  Val_Acc: 91.807

Epoch 17: Validation loss decreased (0.298077 --> 0.296739).  Saving model ...
	 Train_Loss: 0.3345 Train_Acc: 89.366 Val_Loss: 0.2967  BEST VAL Loss: 0.2967  Val_Acc: 91.427

Epoch 18: Validation loss decreased (0.296739 --> 0.293967).  Saving model ...
	 Train_Loss: 0.3309 Train_Acc: 89.773 Val_Loss: 0.2940  BEST VAL Loss: 0.2940  Val_Acc: 92.019

Epoch 19: Validation loss decreased (0.293967 --> 0.291495).  Saving model ...
	 Train_Loss: 0.3275 Train_Acc: 89.752 Val_Loss: 0.2915  BEST VAL Loss: 0.2915  Val_Acc: 91.892

Epoch 20: Validation loss decreased (0.291495 --> 0.289694).  Saving model ...
	 Train_Loss: 0.3244 Train_Acc: 90.084 Val_Loss: 0.2897  BEST VAL Loss: 0.2897  Val_Acc: 92.061

Epoch 21: Validation loss decreased (0.289694 --> 0.288329).  Saving model ...
	 Train_Loss: 0.3214 Train_Acc: 90.185 Val_Loss: 0.2883  BEST VAL Loss: 0.2883  Val_Acc: 92.441

Epoch 22: Validation loss decreased (0.288329 --> 0.287173).  Saving model ...
	 Train_Loss: 0.3182 Train_Acc: 90.607 Val_Loss: 0.2872  BEST VAL Loss: 0.2872  Val_Acc: 92.019

Epoch 23: Validation loss decreased (0.287173 --> 0.285619).  Saving model ...
	 Train_Loss: 0.3153 Train_Acc: 90.660 Val_Loss: 0.2856  BEST VAL Loss: 0.2856  Val_Acc: 92.103

Epoch 24: Validation loss decreased (0.285619 --> 0.285302).  Saving model ...
	 Train_Loss: 0.3129 Train_Acc: 90.232 Val_Loss: 0.2853  BEST VAL Loss: 0.2853  Val_Acc: 91.639

Epoch 25: Validation loss decreased (0.285302 --> 0.283453).  Saving model ...
	 Train_Loss: 0.3106 Train_Acc: 90.211 Val_Loss: 0.2835  BEST VAL Loss: 0.2835  Val_Acc: 92.736

Epoch 26: Validation loss decreased (0.283453 --> 0.283295).  Saving model ...
	 Train_Loss: 0.3078 Train_Acc: 91.167 Val_Loss: 0.2833  BEST VAL Loss: 0.2833  Val_Acc: 92.272

Epoch 27: Validation loss decreased (0.283295 --> 0.282583).  Saving model ...
	 Train_Loss: 0.3053 Train_Acc: 91.024 Val_Loss: 0.2826  BEST VAL Loss: 0.2826  Val_Acc: 92.525

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.3033 Train_Acc: 90.639 Val_Loss: 0.2828  BEST VAL Loss: 0.2826  Val_Acc: 92.272

Epoch 29: Validation loss decreased (0.282583 --> 0.282162).  Saving model ...
	 Train_Loss: 0.3013 Train_Acc: 90.734 Val_Loss: 0.2822  BEST VAL Loss: 0.2822  Val_Acc: 92.483

Epoch 30: Validation loss decreased (0.282162 --> 0.281018).  Saving model ...
	 Train_Loss: 0.2997 Train_Acc: 90.444 Val_Loss: 0.2810  BEST VAL Loss: 0.2810  Val_Acc: 91.554

Epoch 31: Validation loss decreased (0.281018 --> 0.279923).  Saving model ...
	 Train_Loss: 0.2980 Train_Acc: 90.808 Val_Loss: 0.2799  BEST VAL Loss: 0.2799  Val_Acc: 92.230

Epoch 32: Validation loss decreased (0.279923 --> 0.279573).  Saving model ...
	 Train_Loss: 0.2962 Train_Acc: 90.929 Val_Loss: 0.2796  BEST VAL Loss: 0.2796  Val_Acc: 92.103

Epoch 33: Validation loss decreased (0.279573 --> 0.278889).  Saving model ...
	 Train_Loss: 0.2940 Train_Acc: 91.832 Val_Loss: 0.2789  BEST VAL Loss: 0.2789  Val_Acc: 92.610

Epoch 34: Validation loss decreased (0.278889 --> 0.278173).  Saving model ...
	 Train_Loss: 0.2921 Train_Acc: 91.647 Val_Loss: 0.2782  BEST VAL Loss: 0.2782  Val_Acc: 92.948

Epoch 35: Validation loss decreased (0.278173 --> 0.277571).  Saving model ...
	 Train_Loss: 0.2904 Train_Acc: 91.484 Val_Loss: 0.2776  BEST VAL Loss: 0.2776  Val_Acc: 92.863

Epoch 36: Validation loss decreased (0.277571 --> 0.276343).  Saving model ...
	 Train_Loss: 0.2888 Train_Acc: 91.489 Val_Loss: 0.2763  BEST VAL Loss: 0.2763  Val_Acc: 92.736

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.2873 Train_Acc: 91.325 Val_Loss: 0.2770  BEST VAL Loss: 0.2763  Val_Acc: 92.145

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.2857 Train_Acc: 91.420 Val_Loss: 0.2769  BEST VAL Loss: 0.2763  Val_Acc: 92.188

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.2841 Train_Acc: 91.785 Val_Loss: 0.2771  BEST VAL Loss: 0.2763  Val_Acc: 92.356

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.2825 Train_Acc: 91.779 Val_Loss: 0.2775  BEST VAL Loss: 0.2763  Val_Acc: 91.892

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.2813 Train_Acc: 91.510 Val_Loss: 0.2774  BEST VAL Loss: 0.2763  Val_Acc: 92.652

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.2800 Train_Acc: 91.536 Val_Loss: 0.2781  BEST VAL Loss: 0.2763  Val_Acc: 92.483

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.2788 Train_Acc: 91.573 Val_Loss: 0.2788  BEST VAL Loss: 0.2763  Val_Acc: 92.610

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.2777 Train_Acc: 91.631 Val_Loss: 0.2791  BEST VAL Loss: 0.2763  Val_Acc: 92.483

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.2764 Train_Acc: 91.895 Val_Loss: 0.2790  BEST VAL Loss: 0.2763  Val_Acc: 92.905

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.2754 Train_Acc: 91.642 Val_Loss: 0.2801  BEST VAL Loss: 0.2763  Val_Acc: 93.285

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.2742 Train_Acc: 91.943 Val_Loss: 0.2800  BEST VAL Loss: 0.2763  Val_Acc: 92.821

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.2732 Train_Acc: 91.637 Val_Loss: 0.2798  BEST VAL Loss: 0.2763  Val_Acc: 93.201

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.2722 Train_Acc: 91.742 Val_Loss: 0.2798  BEST VAL Loss: 0.2763  Val_Acc: 93.370

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.2712 Train_Acc: 92.117 Val_Loss: 0.2803  BEST VAL Loss: 0.2763  Val_Acc: 93.074

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.2701 Train_Acc: 92.017 Val_Loss: 0.2821  BEST VAL Loss: 0.2763  Val_Acc: 93.117

Epoch 52: Validation loss did not decrease
Early stopped at epoch : 52
LPS_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.48      0.49      9434
           1       0.50      0.52      0.51      9506

    accuracy                           0.50     18940
   macro avg       0.50      0.50      0.50     18940
weighted avg       0.50      0.50      0.50     18940

LPS_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.47      0.48      1179
           1       0.50      0.52      0.51      1189

    accuracy                           0.49      2368
   macro avg       0.49      0.49      0.49      2368
weighted avg       0.49      0.49      0.49      2368

LPS_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.49      0.50      1179
           1       0.52      0.54      0.53      1189

    accuracy                           0.52      2368
   macro avg       0.52      0.52      0.52      2368
weighted avg       0.52      0.52      0.52      2368

              precision    recall  f1-score   support

           0       0.52      0.49      0.50      1179
           1       0.52      0.54      0.53      1189

    accuracy                           0.52      2368
   macro avg       0.52      0.52      0.52      2368
weighted avg       0.52      0.52      0.52      2368

LPS_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.49      0.49      4017
           1       0.50      0.49      0.50      4103

    accuracy                           0.49      8120
   macro avg       0.49      0.49      0.49      8120
weighted avg       0.49      0.49      0.49      8120

              precision    recall  f1-score   support

           0       0.49      0.49      0.49      4017
           1       0.50      0.49      0.50      4103

    accuracy                           0.49      8120
   macro avg       0.49      0.49      0.49      8120
weighted avg       0.49      0.49      0.49      8120

completed
