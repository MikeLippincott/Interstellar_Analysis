[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd57b2a02'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '92031e27'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '11ba29e4'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '2ade8bae'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Thapsigargin_1.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Thapsigargin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (314469, 1270)
Number of total missing values across all columns: 296912
Data Subset Is Off
Wells held out for testing: ['K06' 'K09']
Wells to use for training, validation, and testing ['D06' 'D07' 'K02' 'K03' 'K07' 'K08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.259886).  Saving model ...
	 Train_Loss: 0.3696 Train_Acc: 83.193 Val_Loss: 0.2599  BEST VAL Loss: 0.2599  Val_Acc: 89.135

Epoch 1: Validation loss did not decrease
	 Train_Loss: 0.3216 Train_Acc: 88.912 Val_Loss: 0.2796  BEST VAL Loss: 0.2599  Val_Acc: 87.251

Epoch 2: Validation loss decreased (0.259886 --> 0.256979).  Saving model ...
	 Train_Loss: 0.2952 Train_Acc: 90.428 Val_Loss: 0.2570  BEST VAL Loss: 0.2570  Val_Acc: 91.336

Epoch 3: Validation loss decreased (0.256979 --> 0.240577).  Saving model ...
	 Train_Loss: 0.2779 Train_Acc: 91.230 Val_Loss: 0.2406  BEST VAL Loss: 0.2406  Val_Acc: 92.415

Epoch 4: Validation loss decreased (0.240577 --> 0.232498).  Saving model ...
	 Train_Loss: 0.2653 Train_Acc: 91.660 Val_Loss: 0.2325  BEST VAL Loss: 0.2325  Val_Acc: 92.038

Epoch 5: Validation loss decreased (0.232498 --> 0.224995).  Saving model ...
	 Train_Loss: 0.2557 Train_Acc: 92.016 Val_Loss: 0.2250  BEST VAL Loss: 0.2250  Val_Acc: 92.589

Epoch 6: Validation loss decreased (0.224995 --> 0.224807).  Saving model ...
	 Train_Loss: 0.2480 Train_Acc: 92.275 Val_Loss: 0.2248  BEST VAL Loss: 0.2248  Val_Acc: 90.282

Epoch 7: Validation loss decreased (0.224807 --> 0.219711).  Saving model ...
	 Train_Loss: 0.2415 Train_Acc: 92.405 Val_Loss: 0.2197  BEST VAL Loss: 0.2197  Val_Acc: 92.720

Epoch 8: Validation loss decreased (0.219711 --> 0.213514).  Saving model ...
	 Train_Loss: 0.2359 Train_Acc: 92.678 Val_Loss: 0.2135  BEST VAL Loss: 0.2135  Val_Acc: 93.549

Epoch 9: Validation loss decreased (0.213514 --> 0.211327).  Saving model ...
	 Train_Loss: 0.2311 Train_Acc: 92.798 Val_Loss: 0.2113  BEST VAL Loss: 0.2113  Val_Acc: 92.271

Epoch 10: Validation loss decreased (0.211327 --> 0.208111).  Saving model ...
	 Train_Loss: 0.2269 Train_Acc: 93.028 Val_Loss: 0.2081  BEST VAL Loss: 0.2081  Val_Acc: 93.067

Epoch 11: Validation loss decreased (0.208111 --> 0.203868).  Saving model ...
	 Train_Loss: 0.2231 Train_Acc: 93.141 Val_Loss: 0.2039  BEST VAL Loss: 0.2039  Val_Acc: 93.854

Epoch 12: Validation loss decreased (0.203868 --> 0.203355).  Saving model ...
	 Train_Loss: 0.2196 Train_Acc: 93.310 Val_Loss: 0.2034  BEST VAL Loss: 0.2034  Val_Acc: 92.191

Epoch 13: Validation loss decreased (0.203355 --> 0.202223).  Saving model ...
	 Train_Loss: 0.2164 Train_Acc: 93.381 Val_Loss: 0.2022  BEST VAL Loss: 0.2022  Val_Acc: 93.012

Epoch 14: Validation loss decreased (0.202223 --> 0.198967).  Saving model ...
	 Train_Loss: 0.2135 Train_Acc: 93.496 Val_Loss: 0.1990  BEST VAL Loss: 0.1990  Val_Acc: 94.083

Epoch 15: Validation loss decreased (0.198967 --> 0.197034).  Saving model ...
	 Train_Loss: 0.2109 Train_Acc: 93.501 Val_Loss: 0.1970  BEST VAL Loss: 0.1970  Val_Acc: 92.991

Epoch 16: Validation loss decreased (0.197034 --> 0.194523).  Saving model ...
	 Train_Loss: 0.2084 Train_Acc: 93.747 Val_Loss: 0.1945  BEST VAL Loss: 0.1945  Val_Acc: 93.935

Epoch 17: Validation loss decreased (0.194523 --> 0.192142).  Saving model ...
	 Train_Loss: 0.2061 Train_Acc: 93.895 Val_Loss: 0.1921  BEST VAL Loss: 0.1921  Val_Acc: 94.011

Epoch 18: Validation loss decreased (0.192142 --> 0.189606).  Saving model ...
	 Train_Loss: 0.2040 Train_Acc: 93.954 Val_Loss: 0.1896  BEST VAL Loss: 0.1896  Val_Acc: 94.438

Epoch 19: Validation loss did not decrease
	 Train_Loss: 0.2020 Train_Acc: 94.039 Val_Loss: 0.1982  BEST VAL Loss: 0.1896  Val_Acc: 86.756

Epoch 20: Validation loss did not decrease
	 Train_Loss: 0.2002 Train_Acc: 93.894 Val_Loss: 0.1965  BEST VAL Loss: 0.1896  Val_Acc: 93.731

Epoch 21: Validation loss did not decrease
	 Train_Loss: 0.1985 Train_Acc: 94.030 Val_Loss: 0.1946  BEST VAL Loss: 0.1896  Val_Acc: 94.189

Epoch 22: Validation loss did not decrease
	 Train_Loss: 0.1968 Train_Acc: 94.119 Val_Loss: 0.1938  BEST VAL Loss: 0.1896  Val_Acc: 93.033

Epoch 23: Validation loss did not decrease
	 Train_Loss: 0.1954 Train_Acc: 94.097 Val_Loss: 0.1949  BEST VAL Loss: 0.1896  Val_Acc: 91.526

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.1940 Train_Acc: 94.163 Val_Loss: 0.1964  BEST VAL Loss: 0.1896  Val_Acc: 91.302

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.1927 Train_Acc: 94.113 Val_Loss: 0.1952  BEST VAL Loss: 0.1896  Val_Acc: 93.274

Epoch 26: Validation loss did not decrease
	 Train_Loss: 0.1915 Train_Acc: 94.239 Val_Loss: 0.1936  BEST VAL Loss: 0.1896  Val_Acc: 94.383

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.1903 Train_Acc: 94.262 Val_Loss: 0.1928  BEST VAL Loss: 0.1896  Val_Acc: 93.533

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.1892 Train_Acc: 94.169 Val_Loss: 0.1910  BEST VAL Loss: 0.1896  Val_Acc: 94.599

Epoch 29: Validation loss did not decrease
	 Train_Loss: 0.1881 Train_Acc: 94.339 Val_Loss: 0.1896  BEST VAL Loss: 0.1896  Val_Acc: 94.193

Epoch 30: Validation loss decreased (0.189606 --> 0.188871).  Saving model ...
	 Train_Loss: 0.1870 Train_Acc: 94.395 Val_Loss: 0.1889  BEST VAL Loss: 0.1889  Val_Acc: 93.651

Epoch 31: Validation loss decreased (0.188871 --> 0.187567).  Saving model ...
	 Train_Loss: 0.1860 Train_Acc: 94.320 Val_Loss: 0.1876  BEST VAL Loss: 0.1876  Val_Acc: 94.371

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.1851 Train_Acc: 94.374 Val_Loss: 0.1883  BEST VAL Loss: 0.1876  Val_Acc: 92.754

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.1842 Train_Acc: 94.371 Val_Loss: 0.1878  BEST VAL Loss: 0.1876  Val_Acc: 93.892

Epoch 34: Validation loss decreased (0.187567 --> 0.186396).  Saving model ...
	 Train_Loss: 0.1833 Train_Acc: 94.445 Val_Loss: 0.1864  BEST VAL Loss: 0.1864  Val_Acc: 94.828

Epoch 35: Validation loss decreased (0.186396 --> 0.185114).  Saving model ...
	 Train_Loss: 0.1824 Train_Acc: 94.538 Val_Loss: 0.1851  BEST VAL Loss: 0.1851  Val_Acc: 94.629

Epoch 36: Validation loss decreased (0.185114 --> 0.183888).  Saving model ...
	 Train_Loss: 0.1815 Train_Acc: 94.512 Val_Loss: 0.1839  BEST VAL Loss: 0.1839  Val_Acc: 94.828

Epoch 37: Validation loss decreased (0.183888 --> 0.182650).  Saving model ...
	 Train_Loss: 0.1807 Train_Acc: 94.492 Val_Loss: 0.1826  BEST VAL Loss: 0.1826  Val_Acc: 94.857

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.1800 Train_Acc: 94.540 Val_Loss: 0.1842  BEST VAL Loss: 0.1826  Val_Acc: 90.853

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.1793 Train_Acc: 94.454 Val_Loss: 0.1830  BEST VAL Loss: 0.1826  Val_Acc: 94.768

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.1785 Train_Acc: 94.623 Val_Loss: 0.1837  BEST VAL Loss: 0.1826  Val_Acc: 92.432

Epoch 41: Validation loss decreased (0.182650 --> 0.182543).  Saving model ...
	 Train_Loss: 0.1778 Train_Acc: 94.570 Val_Loss: 0.1825  BEST VAL Loss: 0.1825  Val_Acc: 95.022

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.1771 Train_Acc: 94.622 Val_Loss: 0.1827  BEST VAL Loss: 0.1825  Val_Acc: 92.407

Epoch 43: Validation loss decreased (0.182543 --> 0.181688).  Saving model ...
	 Train_Loss: 0.1765 Train_Acc: 94.525 Val_Loss: 0.1817  BEST VAL Loss: 0.1817  Val_Acc: 94.658

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.1759 Train_Acc: 94.597 Val_Loss: 0.1833  BEST VAL Loss: 0.1817  Val_Acc: 90.354

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.1753 Train_Acc: 94.589 Val_Loss: 0.1825  BEST VAL Loss: 0.1817  Val_Acc: 94.692

Epoch 46: Validation loss decreased (0.181688 --> 0.181651).  Saving model ...
	 Train_Loss: 0.1747 Train_Acc: 94.708 Val_Loss: 0.1817  BEST VAL Loss: 0.1817  Val_Acc: 94.502

Epoch 47: Validation loss decreased (0.181651 --> 0.180905).  Saving model ...
	 Train_Loss: 0.1742 Train_Acc: 94.675 Val_Loss: 0.1809  BEST VAL Loss: 0.1809  Val_Acc: 94.455

Epoch 48: Validation loss decreased (0.180905 --> 0.180184).  Saving model ...
	 Train_Loss: 0.1736 Train_Acc: 94.675 Val_Loss: 0.1802  BEST VAL Loss: 0.1802  Val_Acc: 94.481

Epoch 49: Validation loss decreased (0.180184 --> 0.179733).  Saving model ...
	 Train_Loss: 0.1730 Train_Acc: 94.738 Val_Loss: 0.1797  BEST VAL Loss: 0.1797  Val_Acc: 93.748

Epoch 50: Validation loss decreased (0.179733 --> 0.178833).  Saving model ...
	 Train_Loss: 0.1725 Train_Acc: 94.662 Val_Loss: 0.1788  BEST VAL Loss: 0.1788  Val_Acc: 94.989

Epoch 51: Validation loss decreased (0.178833 --> 0.178472).  Saving model ...
	 Train_Loss: 0.1720 Train_Acc: 94.725 Val_Loss: 0.1785  BEST VAL Loss: 0.1785  Val_Acc: 93.905

Epoch 52: Validation loss decreased (0.178472 --> 0.178146).  Saving model ...
	 Train_Loss: 0.1714 Train_Acc: 94.712 Val_Loss: 0.1781  BEST VAL Loss: 0.1781  Val_Acc: 94.163

Epoch 53: Validation loss decreased (0.178146 --> 0.177514).  Saving model ...
	 Train_Loss: 0.1709 Train_Acc: 94.782 Val_Loss: 0.1775  BEST VAL Loss: 0.1775  Val_Acc: 94.853

Epoch 54: Validation loss decreased (0.177514 --> 0.176733).  Saving model ...
	 Train_Loss: 0.1704 Train_Acc: 94.770 Val_Loss: 0.1767  BEST VAL Loss: 0.1767  Val_Acc: 94.980

Epoch 55: Validation loss decreased (0.176733 --> 0.176016).  Saving model ...
	 Train_Loss: 0.1700 Train_Acc: 94.785 Val_Loss: 0.1760  BEST VAL Loss: 0.1760  Val_Acc: 94.709

Epoch 56: Validation loss decreased (0.176016 --> 0.175634).  Saving model ...
	 Train_Loss: 0.1695 Train_Acc: 94.811 Val_Loss: 0.1756  BEST VAL Loss: 0.1756  Val_Acc: 94.049

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.1690 Train_Acc: 94.825 Val_Loss: 0.1771  BEST VAL Loss: 0.1756  Val_Acc: 90.646

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.1686 Train_Acc: 94.802 Val_Loss: 0.1765  BEST VAL Loss: 0.1756  Val_Acc: 94.989

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.1682 Train_Acc: 94.894 Val_Loss: 0.1765  BEST VAL Loss: 0.1756  Val_Acc: 92.999

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.1677 Train_Acc: 94.843 Val_Loss: 0.1759  BEST VAL Loss: 0.1756  Val_Acc: 94.768

Epoch 61: Validation loss decreased (0.175634 --> 0.175360).  Saving model ...
	 Train_Loss: 0.1673 Train_Acc: 94.867 Val_Loss: 0.1754  BEST VAL Loss: 0.1754  Val_Acc: 94.654

Epoch 62: Validation loss decreased (0.175360 --> 0.174716).  Saving model ...
	 Train_Loss: 0.1669 Train_Acc: 94.834 Val_Loss: 0.1747  BEST VAL Loss: 0.1747  Val_Acc: 94.900

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.1665 Train_Acc: 94.923 Val_Loss: 0.1750  BEST VAL Loss: 0.1747  Val_Acc: 93.097

Epoch 64: Validation loss decreased (0.174716 --> 0.174408).  Saving model ...
	 Train_Loss: 0.1661 Train_Acc: 94.866 Val_Loss: 0.1744  BEST VAL Loss: 0.1744  Val_Acc: 94.950

Epoch 65: Validation loss decreased (0.174408 --> 0.173817).  Saving model ...
	 Train_Loss: 0.1658 Train_Acc: 94.908 Val_Loss: 0.1738  BEST VAL Loss: 0.1738  Val_Acc: 94.946

Epoch 66: Validation loss decreased (0.173817 --> 0.173581).  Saving model ...
	 Train_Loss: 0.1654 Train_Acc: 94.940 Val_Loss: 0.1736  BEST VAL Loss: 0.1736  Val_Acc: 94.248

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.1651 Train_Acc: 94.854 Val_Loss: 0.1737  BEST VAL Loss: 0.1736  Val_Acc: 92.694

Epoch 68: Validation loss decreased (0.173581 --> 0.173227).  Saving model ...
	 Train_Loss: 0.1648 Train_Acc: 94.713 Val_Loss: 0.1732  BEST VAL Loss: 0.1732  Val_Acc: 94.705

Epoch 69: Validation loss decreased (0.173227 --> 0.172700).  Saving model ...
	 Train_Loss: 0.1645 Train_Acc: 94.959 Val_Loss: 0.1727  BEST VAL Loss: 0.1727  Val_Acc: 94.705

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.1641 Train_Acc: 94.928 Val_Loss: 0.1730  BEST VAL Loss: 0.1727  Val_Acc: 92.881

Epoch 71: Validation loss decreased (0.172700 --> 0.172446).  Saving model ...
	 Train_Loss: 0.1638 Train_Acc: 94.964 Val_Loss: 0.1724  BEST VAL Loss: 0.1724  Val_Acc: 95.006

Epoch 72: Validation loss decreased (0.172446 --> 0.171996).  Saving model ...
	 Train_Loss: 0.1635 Train_Acc: 94.989 Val_Loss: 0.1720  BEST VAL Loss: 0.1720  Val_Acc: 94.811

Epoch 73: Validation loss decreased (0.171996 --> 0.171474).  Saving model ...
	 Train_Loss: 0.1631 Train_Acc: 94.970 Val_Loss: 0.1715  BEST VAL Loss: 0.1715  Val_Acc: 94.845

Epoch 74: Validation loss decreased (0.171474 --> 0.171357).  Saving model ...
	 Train_Loss: 0.1628 Train_Acc: 94.996 Val_Loss: 0.1714  BEST VAL Loss: 0.1714  Val_Acc: 93.990

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.1625 Train_Acc: 94.883 Val_Loss: 0.1767  BEST VAL Loss: 0.1714  Val_Acc: 83.984

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.1623 Train_Acc: 94.674 Val_Loss: 0.1761  BEST VAL Loss: 0.1714  Val_Acc: 94.942

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.1620 Train_Acc: 95.123 Val_Loss: 0.1758  BEST VAL Loss: 0.1714  Val_Acc: 94.489

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.1617 Train_Acc: 95.042 Val_Loss: 0.1756  BEST VAL Loss: 0.1714  Val_Acc: 93.858

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.1614 Train_Acc: 95.051 Val_Loss: 0.1761  BEST VAL Loss: 0.1714  Val_Acc: 92.716

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.1611 Train_Acc: 95.034 Val_Loss: 0.1757  BEST VAL Loss: 0.1714  Val_Acc: 94.646

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.1608 Train_Acc: 95.035 Val_Loss: 0.1753  BEST VAL Loss: 0.1714  Val_Acc: 94.756

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.1605 Train_Acc: 95.136 Val_Loss: 0.1766  BEST VAL Loss: 0.1714  Val_Acc: 90.752

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.1603 Train_Acc: 95.043 Val_Loss: 0.1764  BEST VAL Loss: 0.1714  Val_Acc: 93.693

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.1600 Train_Acc: 95.091 Val_Loss: 0.1761  BEST VAL Loss: 0.1714  Val_Acc: 94.752

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.1597 Train_Acc: 95.086 Val_Loss: 0.1761  BEST VAL Loss: 0.1714  Val_Acc: 93.363

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.1595 Train_Acc: 95.028 Val_Loss: 0.1757  BEST VAL Loss: 0.1714  Val_Acc: 94.819

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.1592 Train_Acc: 95.145 Val_Loss: 0.1752  BEST VAL Loss: 0.1714  Val_Acc: 95.056

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.1589 Train_Acc: 95.087 Val_Loss: 0.1748  BEST VAL Loss: 0.1714  Val_Acc: 94.879

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.1587 Train_Acc: 95.129 Val_Loss: 0.1744  BEST VAL Loss: 0.1714  Val_Acc: 94.781

Epoch 90: Validation loss did not decrease
Early stopped at epoch : 90
Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.52      0.53    100908
           1       0.47      0.48      0.47     88100

    accuracy                           0.50    189008
   macro avg       0.50      0.50      0.50    189008
weighted avg       0.50      0.50      0.50    189008

Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.52      0.53     12614
           1       0.47      0.48      0.47     11012

    accuracy                           0.50     23626
   macro avg       0.50      0.50      0.50     23626
weighted avg       0.50      0.50      0.50     23626

Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.52      0.52     12614
           1       0.46      0.47      0.46     11012

    accuracy                           0.50     23626
   macro avg       0.49      0.49      0.49     23626
weighted avg       0.50      0.50      0.50     23626

              precision    recall  f1-score   support

           0       0.53      0.52      0.52     12614
           1       0.46      0.47      0.46     11012

    accuracy                           0.50     23626
   macro avg       0.49      0.49      0.49     23626
weighted avg       0.50      0.50      0.50     23626

Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.40      0.45     39877
           1       0.49      0.60      0.54     38332

    accuracy                           0.50     78209
   macro avg       0.50      0.50      0.49     78209
weighted avg       0.50      0.50      0.49     78209

              precision    recall  f1-score   support

           0       0.51      0.40      0.45     39877
           1       0.49      0.60      0.54     38332

    accuracy                           0.50     78209
   macro avg       0.50      0.50      0.49     78209
weighted avg       0.50      0.50      0.49     78209

completed
