[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'f9e2224d'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '2bc4c8c3'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '0adb070b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '0de00bbe'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Thapsigargin_1.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Thapsigargin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (322717, 1270)
Number of total missing values across all columns: 296912
Data Subset Is Off
Wells held out for testing: ['K06' 'L09']
Wells to use for training, validation, and testing ['D06' 'D07' 'K07' 'L02' 'L03' 'L08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.179608).  Saving model ...
	 Train_Loss: 0.3160 Train_Acc: 86.412 Val_Loss: 0.1796  BEST VAL Loss: 0.1796  Val_Acc: 92.763

Epoch 1: Validation loss decreased (0.179608 --> 0.168128).  Saving model ...
	 Train_Loss: 0.2688 Train_Acc: 91.660 Val_Loss: 0.1681  BEST VAL Loss: 0.1681  Val_Acc: 93.639

Epoch 2: Validation loss decreased (0.168128 --> 0.163387).  Saving model ...
	 Train_Loss: 0.2477 Train_Acc: 92.195 Val_Loss: 0.1634  BEST VAL Loss: 0.1634  Val_Acc: 93.931

Epoch 3: Validation loss decreased (0.163387 --> 0.159667).  Saving model ...
	 Train_Loss: 0.2350 Train_Acc: 92.381 Val_Loss: 0.1597  BEST VAL Loss: 0.1597  Val_Acc: 94.203

Epoch 4: Validation loss decreased (0.159667 --> 0.156672).  Saving model ...
	 Train_Loss: 0.2267 Train_Acc: 92.571 Val_Loss: 0.1567  BEST VAL Loss: 0.1567  Val_Acc: 94.276

Epoch 5: Validation loss decreased (0.156672 --> 0.153863).  Saving model ...
	 Train_Loss: 0.2202 Train_Acc: 92.840 Val_Loss: 0.1539  BEST VAL Loss: 0.1539  Val_Acc: 94.531

Epoch 6: Validation loss decreased (0.153863 --> 0.151604).  Saving model ...
	 Train_Loss: 0.2152 Train_Acc: 92.841 Val_Loss: 0.1516  BEST VAL Loss: 0.1516  Val_Acc: 94.584

Epoch 7: Validation loss decreased (0.151604 --> 0.149750).  Saving model ...
	 Train_Loss: 0.2108 Train_Acc: 93.107 Val_Loss: 0.1498  BEST VAL Loss: 0.1498  Val_Acc: 94.612

Epoch 8: Validation loss decreased (0.149750 --> 0.147776).  Saving model ...
	 Train_Loss: 0.2070 Train_Acc: 93.134 Val_Loss: 0.1478  BEST VAL Loss: 0.1478  Val_Acc: 94.965

Epoch 9: Validation loss decreased (0.147776 --> 0.146314).  Saving model ...
	 Train_Loss: 0.2038 Train_Acc: 93.194 Val_Loss: 0.1463  BEST VAL Loss: 0.1463  Val_Acc: 94.859

Epoch 10: Validation loss decreased (0.146314 --> 0.145019).  Saving model ...
	 Train_Loss: 0.2011 Train_Acc: 93.239 Val_Loss: 0.1450  BEST VAL Loss: 0.1450  Val_Acc: 94.884

Epoch 11: Validation loss decreased (0.145019 --> 0.143575).  Saving model ...
	 Train_Loss: 0.1988 Train_Acc: 93.351 Val_Loss: 0.1436  BEST VAL Loss: 0.1436  Val_Acc: 94.989

Epoch 12: Validation loss decreased (0.143575 --> 0.142474).  Saving model ...
	 Train_Loss: 0.1966 Train_Acc: 93.454 Val_Loss: 0.1425  BEST VAL Loss: 0.1425  Val_Acc: 95.082

Epoch 13: Validation loss decreased (0.142474 --> 0.141682).  Saving model ...
	 Train_Loss: 0.1946 Train_Acc: 93.410 Val_Loss: 0.1417  BEST VAL Loss: 0.1417  Val_Acc: 95.038

Epoch 14: Validation loss decreased (0.141682 --> 0.140817).  Saving model ...
	 Train_Loss: 0.1929 Train_Acc: 93.385 Val_Loss: 0.1408  BEST VAL Loss: 0.1408  Val_Acc: 95.115

Epoch 15: Validation loss decreased (0.140817 --> 0.140154).  Saving model ...
	 Train_Loss: 0.1913 Train_Acc: 93.441 Val_Loss: 0.1402  BEST VAL Loss: 0.1402  Val_Acc: 95.086

Epoch 16: Validation loss decreased (0.140154 --> 0.139452).  Saving model ...
	 Train_Loss: 0.1898 Train_Acc: 93.530 Val_Loss: 0.1395  BEST VAL Loss: 0.1395  Val_Acc: 95.099

Epoch 17: Validation loss decreased (0.139452 --> 0.138918).  Saving model ...
	 Train_Loss: 0.1885 Train_Acc: 93.474 Val_Loss: 0.1389  BEST VAL Loss: 0.1389  Val_Acc: 95.123

Epoch 18: Validation loss decreased (0.138918 --> 0.138532).  Saving model ...
	 Train_Loss: 0.1871 Train_Acc: 93.531 Val_Loss: 0.1385  BEST VAL Loss: 0.1385  Val_Acc: 95.062

Epoch 19: Validation loss decreased (0.138532 --> 0.137730).  Saving model ...
	 Train_Loss: 0.1860 Train_Acc: 93.533 Val_Loss: 0.1377  BEST VAL Loss: 0.1377  Val_Acc: 95.338

Epoch 20: Validation loss decreased (0.137730 --> 0.137230).  Saving model ...
	 Train_Loss: 0.1848 Train_Acc: 93.622 Val_Loss: 0.1372  BEST VAL Loss: 0.1372  Val_Acc: 95.346

Epoch 21: Validation loss decreased (0.137230 --> 0.136669).  Saving model ...
	 Train_Loss: 0.1838 Train_Acc: 93.625 Val_Loss: 0.1367  BEST VAL Loss: 0.1367  Val_Acc: 95.176

Epoch 22: Validation loss decreased (0.136669 --> 0.136105).  Saving model ...
	 Train_Loss: 0.1828 Train_Acc: 93.710 Val_Loss: 0.1361  BEST VAL Loss: 0.1361  Val_Acc: 95.362

Epoch 23: Validation loss decreased (0.136105 --> 0.135633).  Saving model ...
	 Train_Loss: 0.1819 Train_Acc: 93.666 Val_Loss: 0.1356  BEST VAL Loss: 0.1356  Val_Acc: 95.342

Epoch 24: Validation loss decreased (0.135633 --> 0.135194).  Saving model ...
	 Train_Loss: 0.1810 Train_Acc: 93.792 Val_Loss: 0.1352  BEST VAL Loss: 0.1352  Val_Acc: 95.386

Epoch 25: Validation loss decreased (0.135194 --> 0.134621).  Saving model ...
	 Train_Loss: 0.1802 Train_Acc: 93.736 Val_Loss: 0.1346  BEST VAL Loss: 0.1346  Val_Acc: 95.447

Epoch 26: Validation loss decreased (0.134621 --> 0.134116).  Saving model ...
	 Train_Loss: 0.1794 Train_Acc: 93.714 Val_Loss: 0.1341  BEST VAL Loss: 0.1341  Val_Acc: 95.508

Epoch 27: Validation loss decreased (0.134116 --> 0.133762).  Saving model ...
	 Train_Loss: 0.1787 Train_Acc: 93.735 Val_Loss: 0.1338  BEST VAL Loss: 0.1338  Val_Acc: 95.362

Epoch 28: Validation loss decreased (0.133762 --> 0.133352).  Saving model ...
	 Train_Loss: 0.1779 Train_Acc: 93.723 Val_Loss: 0.1334  BEST VAL Loss: 0.1334  Val_Acc: 95.309

Epoch 29: Validation loss decreased (0.133352 --> 0.132924).  Saving model ...
	 Train_Loss: 0.1773 Train_Acc: 93.786 Val_Loss: 0.1329  BEST VAL Loss: 0.1329  Val_Acc: 95.508

Epoch 30: Validation loss decreased (0.132924 --> 0.132537).  Saving model ...
	 Train_Loss: 0.1766 Train_Acc: 93.829 Val_Loss: 0.1325  BEST VAL Loss: 0.1325  Val_Acc: 95.297

Epoch 31: Validation loss decreased (0.132537 --> 0.132187).  Saving model ...
	 Train_Loss: 0.1760 Train_Acc: 93.740 Val_Loss: 0.1322  BEST VAL Loss: 0.1322  Val_Acc: 95.370

Epoch 32: Validation loss decreased (0.132187 --> 0.131890).  Saving model ...
	 Train_Loss: 0.1754 Train_Acc: 93.860 Val_Loss: 0.1319  BEST VAL Loss: 0.1319  Val_Acc: 95.399

Epoch 33: Validation loss decreased (0.131890 --> 0.131525).  Saving model ...
	 Train_Loss: 0.1748 Train_Acc: 93.926 Val_Loss: 0.1315  BEST VAL Loss: 0.1315  Val_Acc: 95.492

Epoch 34: Validation loss decreased (0.131525 --> 0.131180).  Saving model ...
	 Train_Loss: 0.1742 Train_Acc: 93.867 Val_Loss: 0.1312  BEST VAL Loss: 0.1312  Val_Acc: 95.467

Epoch 35: Validation loss decreased (0.131180 --> 0.130844).  Saving model ...
	 Train_Loss: 0.1736 Train_Acc: 93.940 Val_Loss: 0.1308  BEST VAL Loss: 0.1308  Val_Acc: 95.508

Epoch 36: Validation loss decreased (0.130844 --> 0.130479).  Saving model ...
	 Train_Loss: 0.1731 Train_Acc: 93.909 Val_Loss: 0.1305  BEST VAL Loss: 0.1305  Val_Acc: 95.536

Epoch 37: Validation loss decreased (0.130479 --> 0.130076).  Saving model ...
	 Train_Loss: 0.1726 Train_Acc: 93.901 Val_Loss: 0.1301  BEST VAL Loss: 0.1301  Val_Acc: 95.739

Epoch 38: Validation loss decreased (0.130076 --> 0.129737).  Saving model ...
	 Train_Loss: 0.1721 Train_Acc: 93.925 Val_Loss: 0.1297  BEST VAL Loss: 0.1297  Val_Acc: 95.484

Epoch 39: Validation loss decreased (0.129737 --> 0.129498).  Saving model ...
	 Train_Loss: 0.1716 Train_Acc: 93.947 Val_Loss: 0.1295  BEST VAL Loss: 0.1295  Val_Acc: 95.455

Epoch 40: Validation loss decreased (0.129498 --> 0.129259).  Saving model ...
	 Train_Loss: 0.1711 Train_Acc: 93.941 Val_Loss: 0.1293  BEST VAL Loss: 0.1293  Val_Acc: 95.471

Epoch 41: Validation loss decreased (0.129259 --> 0.128958).  Saving model ...
	 Train_Loss: 0.1707 Train_Acc: 93.934 Val_Loss: 0.1290  BEST VAL Loss: 0.1290  Val_Acc: 95.634

Epoch 42: Validation loss decreased (0.128958 --> 0.128657).  Saving model ...
	 Train_Loss: 0.1703 Train_Acc: 93.932 Val_Loss: 0.1287  BEST VAL Loss: 0.1287  Val_Acc: 95.715

Epoch 43: Validation loss decreased (0.128657 --> 0.128457).  Saving model ...
	 Train_Loss: 0.1698 Train_Acc: 94.009 Val_Loss: 0.1285  BEST VAL Loss: 0.1285  Val_Acc: 95.484

Epoch 44: Validation loss decreased (0.128457 --> 0.128215).  Saving model ...
	 Train_Loss: 0.1694 Train_Acc: 93.943 Val_Loss: 0.1282  BEST VAL Loss: 0.1282  Val_Acc: 95.650

Epoch 45: Validation loss decreased (0.128215 --> 0.127969).  Saving model ...
	 Train_Loss: 0.1690 Train_Acc: 93.893 Val_Loss: 0.1280  BEST VAL Loss: 0.1280  Val_Acc: 95.658

Epoch 46: Validation loss decreased (0.127969 --> 0.127761).  Saving model ...
	 Train_Loss: 0.1687 Train_Acc: 93.965 Val_Loss: 0.1278  BEST VAL Loss: 0.1278  Val_Acc: 95.488

Epoch 47: Validation loss decreased (0.127761 --> 0.127537).  Saving model ...
	 Train_Loss: 0.1683 Train_Acc: 94.013 Val_Loss: 0.1275  BEST VAL Loss: 0.1275  Val_Acc: 95.569

Epoch 48: Validation loss decreased (0.127537 --> 0.127298).  Saving model ...
	 Train_Loss: 0.1679 Train_Acc: 93.973 Val_Loss: 0.1273  BEST VAL Loss: 0.1273  Val_Acc: 95.617

Epoch 49: Validation loss decreased (0.127298 --> 0.127111).  Saving model ...
	 Train_Loss: 0.1676 Train_Acc: 94.061 Val_Loss: 0.1271  BEST VAL Loss: 0.1271  Val_Acc: 95.682

Epoch 50: Validation loss decreased (0.127111 --> 0.126938).  Saving model ...
	 Train_Loss: 0.1672 Train_Acc: 94.105 Val_Loss: 0.1269  BEST VAL Loss: 0.1269  Val_Acc: 95.642

Epoch 51: Validation loss decreased (0.126938 --> 0.126765).  Saving model ...
	 Train_Loss: 0.1669 Train_Acc: 93.977 Val_Loss: 0.1268  BEST VAL Loss: 0.1268  Val_Acc: 95.597

Epoch 52: Validation loss decreased (0.126765 --> 0.126531).  Saving model ...
	 Train_Loss: 0.1665 Train_Acc: 94.036 Val_Loss: 0.1265  BEST VAL Loss: 0.1265  Val_Acc: 95.703

Epoch 53: Validation loss decreased (0.126531 --> 0.126344).  Saving model ...
	 Train_Loss: 0.1662 Train_Acc: 94.022 Val_Loss: 0.1263  BEST VAL Loss: 0.1263  Val_Acc: 95.666

Epoch 54: Validation loss decreased (0.126344 --> 0.126170).  Saving model ...
	 Train_Loss: 0.1659 Train_Acc: 94.075 Val_Loss: 0.1262  BEST VAL Loss: 0.1262  Val_Acc: 95.804

Epoch 55: Validation loss decreased (0.126170 --> 0.125986).  Saving model ...
	 Train_Loss: 0.1656 Train_Acc: 94.073 Val_Loss: 0.1260  BEST VAL Loss: 0.1260  Val_Acc: 95.690

Epoch 56: Validation loss decreased (0.125986 --> 0.125803).  Saving model ...
	 Train_Loss: 0.1653 Train_Acc: 94.050 Val_Loss: 0.1258  BEST VAL Loss: 0.1258  Val_Acc: 95.609

Epoch 57: Validation loss decreased (0.125803 --> 0.125606).  Saving model ...
	 Train_Loss: 0.1650 Train_Acc: 94.117 Val_Loss: 0.1256  BEST VAL Loss: 0.1256  Val_Acc: 95.731

Epoch 58: Validation loss decreased (0.125606 --> 0.125455).  Saving model ...
	 Train_Loss: 0.1647 Train_Acc: 94.101 Val_Loss: 0.1255  BEST VAL Loss: 0.1255  Val_Acc: 95.654

Epoch 59: Validation loss decreased (0.125455 --> 0.125301).  Saving model ...
	 Train_Loss: 0.1645 Train_Acc: 94.094 Val_Loss: 0.1253  BEST VAL Loss: 0.1253  Val_Acc: 95.727

Epoch 60: Validation loss decreased (0.125301 --> 0.125095).  Saving model ...
	 Train_Loss: 0.1642 Train_Acc: 94.123 Val_Loss: 0.1251  BEST VAL Loss: 0.1251  Val_Acc: 95.816

Epoch 61: Validation loss decreased (0.125095 --> 0.124936).  Saving model ...
	 Train_Loss: 0.1639 Train_Acc: 94.068 Val_Loss: 0.1249  BEST VAL Loss: 0.1249  Val_Acc: 95.735

Epoch 62: Validation loss decreased (0.124936 --> 0.124784).  Saving model ...
	 Train_Loss: 0.1636 Train_Acc: 94.102 Val_Loss: 0.1248  BEST VAL Loss: 0.1248  Val_Acc: 95.662

Epoch 63: Validation loss decreased (0.124784 --> 0.124636).  Saving model ...
	 Train_Loss: 0.1634 Train_Acc: 94.072 Val_Loss: 0.1246  BEST VAL Loss: 0.1246  Val_Acc: 95.605

Epoch 64: Validation loss decreased (0.124636 --> 0.124452).  Saving model ...
	 Train_Loss: 0.1632 Train_Acc: 94.088 Val_Loss: 0.1245  BEST VAL Loss: 0.1245  Val_Acc: 95.703

Epoch 65: Validation loss decreased (0.124452 --> 0.124269).  Saving model ...
	 Train_Loss: 0.1629 Train_Acc: 94.162 Val_Loss: 0.1243  BEST VAL Loss: 0.1243  Val_Acc: 95.873

Epoch 66: Validation loss decreased (0.124269 --> 0.124149).  Saving model ...
	 Train_Loss: 0.1627 Train_Acc: 94.223 Val_Loss: 0.1241  BEST VAL Loss: 0.1241  Val_Acc: 95.682

Epoch 67: Validation loss decreased (0.124149 --> 0.124052).  Saving model ...
	 Train_Loss: 0.1624 Train_Acc: 94.200 Val_Loss: 0.1241  BEST VAL Loss: 0.1241  Val_Acc: 95.727

Epoch 68: Validation loss decreased (0.124052 --> 0.123901).  Saving model ...
	 Train_Loss: 0.1622 Train_Acc: 94.203 Val_Loss: 0.1239  BEST VAL Loss: 0.1239  Val_Acc: 95.816

Epoch 69: Validation loss decreased (0.123901 --> 0.123716).  Saving model ...
	 Train_Loss: 0.1620 Train_Acc: 94.163 Val_Loss: 0.1237  BEST VAL Loss: 0.1237  Val_Acc: 95.849

Epoch 70: Validation loss decreased (0.123716 --> 0.123552).  Saving model ...
	 Train_Loss: 0.1617 Train_Acc: 94.236 Val_Loss: 0.1236  BEST VAL Loss: 0.1236  Val_Acc: 95.784

Epoch 71: Validation loss decreased (0.123552 --> 0.123373).  Saving model ...
	 Train_Loss: 0.1615 Train_Acc: 94.245 Val_Loss: 0.1234  BEST VAL Loss: 0.1234  Val_Acc: 95.881

Epoch 72: Validation loss decreased (0.123373 --> 0.123249).  Saving model ...
	 Train_Loss: 0.1613 Train_Acc: 94.120 Val_Loss: 0.1232  BEST VAL Loss: 0.1232  Val_Acc: 95.820

Epoch 73: Validation loss decreased (0.123249 --> 0.123124).  Saving model ...
	 Train_Loss: 0.1611 Train_Acc: 94.171 Val_Loss: 0.1231  BEST VAL Loss: 0.1231  Val_Acc: 95.739

Epoch 74: Validation loss decreased (0.123124 --> 0.123038).  Saving model ...
	 Train_Loss: 0.1609 Train_Acc: 94.259 Val_Loss: 0.1230  BEST VAL Loss: 0.1230  Val_Acc: 95.634

Epoch 75: Validation loss decreased (0.123038 --> 0.122918).  Saving model ...
	 Train_Loss: 0.1607 Train_Acc: 94.216 Val_Loss: 0.1229  BEST VAL Loss: 0.1229  Val_Acc: 95.703

Epoch 76: Validation loss decreased (0.122918 --> 0.122793).  Saving model ...
	 Train_Loss: 0.1605 Train_Acc: 94.193 Val_Loss: 0.1228  BEST VAL Loss: 0.1228  Val_Acc: 95.662

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.1603 Train_Acc: 94.295 Val_Loss: 0.1228  BEST VAL Loss: 0.1228  Val_Acc: 95.792

Epoch 78: Validation loss decreased (0.122793 --> 0.122709).  Saving model ...
	 Train_Loss: 0.1601 Train_Acc: 94.193 Val_Loss: 0.1227  BEST VAL Loss: 0.1227  Val_Acc: 95.901

Epoch 79: Validation loss decreased (0.122709 --> 0.122596).  Saving model ...
	 Train_Loss: 0.1599 Train_Acc: 94.289 Val_Loss: 0.1226  BEST VAL Loss: 0.1226  Val_Acc: 95.812

Epoch 80: Validation loss decreased (0.122596 --> 0.122522).  Saving model ...
	 Train_Loss: 0.1597 Train_Acc: 94.239 Val_Loss: 0.1225  BEST VAL Loss: 0.1225  Val_Acc: 95.719

Epoch 81: Validation loss decreased (0.122522 --> 0.122410).  Saving model ...
	 Train_Loss: 0.1595 Train_Acc: 94.226 Val_Loss: 0.1224  BEST VAL Loss: 0.1224  Val_Acc: 95.699

Epoch 82: Validation loss decreased (0.122410 --> 0.122321).  Saving model ...
	 Train_Loss: 0.1594 Train_Acc: 94.196 Val_Loss: 0.1223  BEST VAL Loss: 0.1223  Val_Acc: 95.857

Epoch 83: Validation loss decreased (0.122321 --> 0.122236).  Saving model ...
	 Train_Loss: 0.1592 Train_Acc: 94.197 Val_Loss: 0.1222  BEST VAL Loss: 0.1222  Val_Acc: 95.865

Epoch 84: Validation loss decreased (0.122236 --> 0.122115).  Saving model ...
	 Train_Loss: 0.1591 Train_Acc: 94.122 Val_Loss: 0.1221  BEST VAL Loss: 0.1221  Val_Acc: 95.828

Epoch 85: Validation loss decreased (0.122115 --> 0.122014).  Saving model ...
	 Train_Loss: 0.1589 Train_Acc: 94.260 Val_Loss: 0.1220  BEST VAL Loss: 0.1220  Val_Acc: 95.767

Epoch 86: Validation loss decreased (0.122014 --> 0.121914).  Saving model ...
	 Train_Loss: 0.1587 Train_Acc: 94.362 Val_Loss: 0.1219  BEST VAL Loss: 0.1219  Val_Acc: 95.836

Epoch 87: Validation loss decreased (0.121914 --> 0.121827).  Saving model ...
	 Train_Loss: 0.1585 Train_Acc: 94.320 Val_Loss: 0.1218  BEST VAL Loss: 0.1218  Val_Acc: 95.877

Epoch 88: Validation loss decreased (0.121827 --> 0.121716).  Saving model ...
	 Train_Loss: 0.1584 Train_Acc: 94.302 Val_Loss: 0.1217  BEST VAL Loss: 0.1217  Val_Acc: 95.869

Epoch 89: Validation loss decreased (0.121716 --> 0.121580).  Saving model ...
	 Train_Loss: 0.1582 Train_Acc: 94.192 Val_Loss: 0.1216  BEST VAL Loss: 0.1216  Val_Acc: 95.994

Epoch 90: Validation loss decreased (0.121580 --> 0.121519).  Saving model ...
	 Train_Loss: 0.1580 Train_Acc: 94.285 Val_Loss: 0.1215  BEST VAL Loss: 0.1215  Val_Acc: 95.828

Epoch 91: Validation loss decreased (0.121519 --> 0.121424).  Saving model ...
	 Train_Loss: 0.1579 Train_Acc: 94.200 Val_Loss: 0.1214  BEST VAL Loss: 0.1214  Val_Acc: 95.946

Epoch 92: Validation loss decreased (0.121424 --> 0.121359).  Saving model ...
	 Train_Loss: 0.1578 Train_Acc: 94.198 Val_Loss: 0.1214  BEST VAL Loss: 0.1214  Val_Acc: 95.893

Epoch 93: Validation loss decreased (0.121359 --> 0.121315).  Saving model ...
	 Train_Loss: 0.1576 Train_Acc: 94.300 Val_Loss: 0.1213  BEST VAL Loss: 0.1213  Val_Acc: 95.840

Epoch 94: Validation loss decreased (0.121315 --> 0.121201).  Saving model ...
	 Train_Loss: 0.1575 Train_Acc: 94.263 Val_Loss: 0.1212  BEST VAL Loss: 0.1212  Val_Acc: 95.958

Epoch 95: Validation loss decreased (0.121201 --> 0.121123).  Saving model ...
	 Train_Loss: 0.1573 Train_Acc: 94.287 Val_Loss: 0.1211  BEST VAL Loss: 0.1211  Val_Acc: 95.905

Epoch 96: Validation loss decreased (0.121123 --> 0.121046).  Saving model ...
	 Train_Loss: 0.1572 Train_Acc: 94.300 Val_Loss: 0.1210  BEST VAL Loss: 0.1210  Val_Acc: 95.804

Epoch 97: Validation loss decreased (0.121046 --> 0.120928).  Saving model ...
	 Train_Loss: 0.1570 Train_Acc: 94.383 Val_Loss: 0.1209  BEST VAL Loss: 0.1209  Val_Acc: 95.909

Epoch 98: Validation loss decreased (0.120928 --> 0.120849).  Saving model ...
	 Train_Loss: 0.1568 Train_Acc: 94.289 Val_Loss: 0.1208  BEST VAL Loss: 0.1208  Val_Acc: 95.840

Epoch 99: Validation loss decreased (0.120849 --> 0.120794).  Saving model ...
	 Train_Loss: 0.1567 Train_Acc: 94.229 Val_Loss: 0.1208  BEST VAL Loss: 0.1208  Val_Acc: 95.715

Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.55      0.55    109228
           1       0.44      0.44      0.44     88100

    accuracy                           0.50    197328
   macro avg       0.50      0.50      0.50    197328
weighted avg       0.50      0.50      0.50    197328

Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.56      0.55      0.55     13654
           1       0.45      0.45      0.45     11012

    accuracy                           0.51     24666
   macro avg       0.50      0.50      0.50     24666
weighted avg       0.51      0.51      0.51     24666

Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.56      0.56      0.56     13654
           1       0.45      0.45      0.45     11012

    accuracy                           0.51     24666
   macro avg       0.50      0.50      0.50     24666
weighted avg       0.51      0.51      0.51     24666

              precision    recall  f1-score   support

           0       0.56      0.56      0.56     13654
           1       0.45      0.45      0.45     11012

    accuracy                           0.51     24666
   macro avg       0.50      0.50      0.50     24666
weighted avg       0.51      0.51      0.51     24666

Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.50      0.50     37725
           1       0.51      0.51      0.51     38332

    accuracy                           0.50     76057
   macro avg       0.50      0.50      0.50     76057
weighted avg       0.50      0.50      0.50     76057

              precision    recall  f1-score   support

           0       0.50      0.50      0.50     37725
           1       0.51      0.51      0.51     38332

    accuracy                           0.50     76057
   macro avg       0.50      0.50      0.50     76057
weighted avg       0.50      0.50      0.50     76057

completed
