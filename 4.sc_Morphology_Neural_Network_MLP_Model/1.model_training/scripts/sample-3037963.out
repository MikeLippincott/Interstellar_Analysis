[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '0565e03e'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e8b8cf49'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '290058b7'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '900f617c'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_10.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (322503, 1270)
Number of total missing values across all columns: 312980
Data Subset Is Off
Wells held out for testing: ['E09' 'K08']
Wells to use for training, validation, and testing ['E02' 'E03' 'E08' 'K02' 'K03' 'K09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.187097).  Saving model ...
	 Train_Loss: 0.3347 Train_Acc: 85.866 Val_Loss: 0.1871  BEST VAL Loss: 0.1871  Val_Acc: 92.836

Epoch 1: Validation loss decreased (0.187097 --> 0.171831).  Saving model ...
	 Train_Loss: 0.2816 Train_Acc: 91.338 Val_Loss: 0.1718  BEST VAL Loss: 0.1718  Val_Acc: 93.854

Epoch 2: Validation loss decreased (0.171831 --> 0.162082).  Saving model ...
	 Train_Loss: 0.2561 Train_Acc: 92.359 Val_Loss: 0.1621  BEST VAL Loss: 0.1621  Val_Acc: 94.623

Epoch 3: Validation loss decreased (0.162082 --> 0.157307).  Saving model ...
	 Train_Loss: 0.2406 Train_Acc: 92.788 Val_Loss: 0.1573  BEST VAL Loss: 0.1573  Val_Acc: 94.257

Epoch 4: Validation loss decreased (0.157307 --> 0.152803).  Saving model ...
	 Train_Loss: 0.2303 Train_Acc: 93.048 Val_Loss: 0.1528  BEST VAL Loss: 0.1528  Val_Acc: 94.893

Epoch 5: Validation loss decreased (0.152803 --> 0.149736).  Saving model ...
	 Train_Loss: 0.2225 Train_Acc: 93.248 Val_Loss: 0.1497  BEST VAL Loss: 0.1497  Val_Acc: 94.723

Epoch 6: Validation loss decreased (0.149736 --> 0.146808).  Saving model ...
	 Train_Loss: 0.2167 Train_Acc: 93.264 Val_Loss: 0.1468  BEST VAL Loss: 0.1468  Val_Acc: 95.217

Epoch 7: Validation loss decreased (0.146808 --> 0.144681).  Saving model ...
	 Train_Loss: 0.2118 Train_Acc: 93.524 Val_Loss: 0.1447  BEST VAL Loss: 0.1447  Val_Acc: 95.300

Epoch 8: Validation loss decreased (0.144681 --> 0.143107).  Saving model ...
	 Train_Loss: 0.2077 Train_Acc: 93.613 Val_Loss: 0.1431  BEST VAL Loss: 0.1431  Val_Acc: 95.088

Epoch 9: Validation loss decreased (0.143107 --> 0.142942).  Saving model ...
	 Train_Loss: 0.2042 Train_Acc: 93.556 Val_Loss: 0.1429  BEST VAL Loss: 0.1429  Val_Acc: 95.180

Epoch 10: Validation loss decreased (0.142942 --> 0.140662).  Saving model ...
	 Train_Loss: 0.2012 Train_Acc: 93.684 Val_Loss: 0.1407  BEST VAL Loss: 0.1407  Val_Acc: 95.475

Epoch 11: Validation loss decreased (0.140662 --> 0.138830).  Saving model ...
	 Train_Loss: 0.1985 Train_Acc: 93.773 Val_Loss: 0.1388  BEST VAL Loss: 0.1388  Val_Acc: 95.550

Epoch 12: Validation loss decreased (0.138830 --> 0.137429).  Saving model ...
	 Train_Loss: 0.1960 Train_Acc: 93.888 Val_Loss: 0.1374  BEST VAL Loss: 0.1374  Val_Acc: 95.238

Epoch 13: Validation loss decreased (0.137429 --> 0.136409).  Saving model ...
	 Train_Loss: 0.1939 Train_Acc: 93.931 Val_Loss: 0.1364  BEST VAL Loss: 0.1364  Val_Acc: 95.196

Epoch 14: Validation loss decreased (0.136409 --> 0.135402).  Saving model ...
	 Train_Loss: 0.1919 Train_Acc: 93.964 Val_Loss: 0.1354  BEST VAL Loss: 0.1354  Val_Acc: 95.504

Epoch 15: Validation loss decreased (0.135402 --> 0.134458).  Saving model ...
	 Train_Loss: 0.1901 Train_Acc: 93.987 Val_Loss: 0.1345  BEST VAL Loss: 0.1345  Val_Acc: 95.691

Epoch 16: Validation loss decreased (0.134458 --> 0.133545).  Saving model ...
	 Train_Loss: 0.1885 Train_Acc: 93.973 Val_Loss: 0.1335  BEST VAL Loss: 0.1335  Val_Acc: 95.421

Epoch 17: Validation loss decreased (0.133545 --> 0.132547).  Saving model ...
	 Train_Loss: 0.1869 Train_Acc: 94.065 Val_Loss: 0.1325  BEST VAL Loss: 0.1325  Val_Acc: 95.624

Epoch 18: Validation loss decreased (0.132547 --> 0.131691).  Saving model ...
	 Train_Loss: 0.1855 Train_Acc: 94.108 Val_Loss: 0.1317  BEST VAL Loss: 0.1317  Val_Acc: 95.629

Epoch 19: Validation loss decreased (0.131691 --> 0.131104).  Saving model ...
	 Train_Loss: 0.1842 Train_Acc: 94.144 Val_Loss: 0.1311  BEST VAL Loss: 0.1311  Val_Acc: 95.130

Epoch 20: Validation loss decreased (0.131104 --> 0.130394).  Saving model ...
	 Train_Loss: 0.1830 Train_Acc: 94.166 Val_Loss: 0.1304  BEST VAL Loss: 0.1304  Val_Acc: 95.583

Epoch 21: Validation loss decreased (0.130394 --> 0.130010).  Saving model ...
	 Train_Loss: 0.1818 Train_Acc: 94.198 Val_Loss: 0.1300  BEST VAL Loss: 0.1300  Val_Acc: 95.292

Epoch 22: Validation loss decreased (0.130010 --> 0.129735).  Saving model ...
	 Train_Loss: 0.1807 Train_Acc: 94.203 Val_Loss: 0.1297  BEST VAL Loss: 0.1297  Val_Acc: 95.333

Epoch 23: Validation loss decreased (0.129735 --> 0.129320).  Saving model ...
	 Train_Loss: 0.1798 Train_Acc: 94.154 Val_Loss: 0.1293  BEST VAL Loss: 0.1293  Val_Acc: 95.799

Epoch 24: Validation loss decreased (0.129320 --> 0.128834).  Saving model ...
	 Train_Loss: 0.1789 Train_Acc: 94.272 Val_Loss: 0.1288  BEST VAL Loss: 0.1288  Val_Acc: 95.658

Epoch 25: Validation loss decreased (0.128834 --> 0.128801).  Saving model ...
	 Train_Loss: 0.1779 Train_Acc: 94.247 Val_Loss: 0.1288  BEST VAL Loss: 0.1288  Val_Acc: 95.828

Epoch 26: Validation loss decreased (0.128801 --> 0.128556).  Saving model ...
	 Train_Loss: 0.1771 Train_Acc: 94.349 Val_Loss: 0.1286  BEST VAL Loss: 0.1286  Val_Acc: 95.766

Epoch 27: Validation loss decreased (0.128556 --> 0.128240).  Saving model ...
	 Train_Loss: 0.1763 Train_Acc: 94.260 Val_Loss: 0.1282  BEST VAL Loss: 0.1282  Val_Acc: 95.865

Epoch 28: Validation loss decreased (0.128240 --> 0.127934).  Saving model ...
	 Train_Loss: 0.1755 Train_Acc: 94.361 Val_Loss: 0.1279  BEST VAL Loss: 0.1279  Val_Acc: 95.728

Epoch 29: Validation loss decreased (0.127934 --> 0.127457).  Saving model ...
	 Train_Loss: 0.1747 Train_Acc: 94.395 Val_Loss: 0.1275  BEST VAL Loss: 0.1275  Val_Acc: 95.824

Epoch 30: Validation loss decreased (0.127457 --> 0.127199).  Saving model ...
	 Train_Loss: 0.1740 Train_Acc: 94.379 Val_Loss: 0.1272  BEST VAL Loss: 0.1272  Val_Acc: 95.599

Epoch 31: Validation loss decreased (0.127199 --> 0.126858).  Saving model ...
	 Train_Loss: 0.1733 Train_Acc: 94.420 Val_Loss: 0.1269  BEST VAL Loss: 0.1269  Val_Acc: 95.774

Epoch 32: Validation loss decreased (0.126858 --> 0.126614).  Saving model ...
	 Train_Loss: 0.1726 Train_Acc: 94.439 Val_Loss: 0.1266  BEST VAL Loss: 0.1266  Val_Acc: 95.753

Epoch 33: Validation loss decreased (0.126614 --> 0.126400).  Saving model ...
	 Train_Loss: 0.1720 Train_Acc: 94.367 Val_Loss: 0.1264  BEST VAL Loss: 0.1264  Val_Acc: 95.795

Epoch 34: Validation loss decreased (0.126400 --> 0.126041).  Saving model ...
	 Train_Loss: 0.1713 Train_Acc: 94.443 Val_Loss: 0.1260  BEST VAL Loss: 0.1260  Val_Acc: 95.720

Epoch 35: Validation loss decreased (0.126041 --> 0.125671).  Saving model ...
	 Train_Loss: 0.1707 Train_Acc: 94.547 Val_Loss: 0.1257  BEST VAL Loss: 0.1257  Val_Acc: 96.007

Epoch 36: Validation loss decreased (0.125671 --> 0.125364).  Saving model ...
	 Train_Loss: 0.1701 Train_Acc: 94.521 Val_Loss: 0.1254  BEST VAL Loss: 0.1254  Val_Acc: 95.928

Epoch 37: Validation loss decreased (0.125364 --> 0.124924).  Saving model ...
	 Train_Loss: 0.1696 Train_Acc: 94.399 Val_Loss: 0.1249  BEST VAL Loss: 0.1249  Val_Acc: 95.865

Epoch 38: Validation loss decreased (0.124924 --> 0.124679).  Saving model ...
	 Train_Loss: 0.1691 Train_Acc: 94.492 Val_Loss: 0.1247  BEST VAL Loss: 0.1247  Val_Acc: 95.828

Epoch 39: Validation loss decreased (0.124679 --> 0.124496).  Saving model ...
	 Train_Loss: 0.1686 Train_Acc: 94.604 Val_Loss: 0.1245  BEST VAL Loss: 0.1245  Val_Acc: 95.886

Epoch 40: Validation loss decreased (0.124496 --> 0.124305).  Saving model ...
	 Train_Loss: 0.1680 Train_Acc: 94.546 Val_Loss: 0.1243  BEST VAL Loss: 0.1243  Val_Acc: 96.027

Epoch 41: Validation loss decreased (0.124305 --> 0.124056).  Saving model ...
	 Train_Loss: 0.1675 Train_Acc: 94.535 Val_Loss: 0.1241  BEST VAL Loss: 0.1241  Val_Acc: 95.753

Epoch 42: Validation loss decreased (0.124056 --> 0.123865).  Saving model ...
	 Train_Loss: 0.1670 Train_Acc: 94.595 Val_Loss: 0.1239  BEST VAL Loss: 0.1239  Val_Acc: 95.969

Epoch 43: Validation loss decreased (0.123865 --> 0.123617).  Saving model ...
	 Train_Loss: 0.1666 Train_Acc: 94.594 Val_Loss: 0.1236  BEST VAL Loss: 0.1236  Val_Acc: 95.928

Epoch 44: Validation loss decreased (0.123617 --> 0.123523).  Saving model ...
	 Train_Loss: 0.1661 Train_Acc: 94.559 Val_Loss: 0.1235  BEST VAL Loss: 0.1235  Val_Acc: 95.795

Epoch 45: Validation loss decreased (0.123523 --> 0.123372).  Saving model ...
	 Train_Loss: 0.1657 Train_Acc: 94.691 Val_Loss: 0.1234  BEST VAL Loss: 0.1234  Val_Acc: 95.932

Epoch 46: Validation loss decreased (0.123372 --> 0.123210).  Saving model ...
	 Train_Loss: 0.1653 Train_Acc: 94.549 Val_Loss: 0.1232  BEST VAL Loss: 0.1232  Val_Acc: 95.475

Epoch 47: Validation loss decreased (0.123210 --> 0.123100).  Saving model ...
	 Train_Loss: 0.1649 Train_Acc: 94.578 Val_Loss: 0.1231  BEST VAL Loss: 0.1231  Val_Acc: 95.969

Epoch 48: Validation loss decreased (0.123100 --> 0.122976).  Saving model ...
	 Train_Loss: 0.1644 Train_Acc: 94.640 Val_Loss: 0.1230  BEST VAL Loss: 0.1230  Val_Acc: 95.683

Epoch 49: Validation loss decreased (0.122976 --> 0.122881).  Saving model ...
	 Train_Loss: 0.1641 Train_Acc: 94.646 Val_Loss: 0.1229  BEST VAL Loss: 0.1229  Val_Acc: 95.911

Epoch 50: Validation loss decreased (0.122881 --> 0.122706).  Saving model ...
	 Train_Loss: 0.1637 Train_Acc: 94.640 Val_Loss: 0.1227  BEST VAL Loss: 0.1227  Val_Acc: 95.840

Epoch 51: Validation loss decreased (0.122706 --> 0.122636).  Saving model ...
	 Train_Loss: 0.1633 Train_Acc: 94.635 Val_Loss: 0.1226  BEST VAL Loss: 0.1226  Val_Acc: 95.915

Epoch 52: Validation loss decreased (0.122636 --> 0.122550).  Saving model ...
	 Train_Loss: 0.1630 Train_Acc: 94.570 Val_Loss: 0.1226  BEST VAL Loss: 0.1226  Val_Acc: 95.882

Epoch 53: Validation loss decreased (0.122550 --> 0.122314).  Saving model ...
	 Train_Loss: 0.1626 Train_Acc: 94.682 Val_Loss: 0.1223  BEST VAL Loss: 0.1223  Val_Acc: 95.894

Epoch 54: Validation loss decreased (0.122314 --> 0.122220).  Saving model ...
	 Train_Loss: 0.1622 Train_Acc: 94.701 Val_Loss: 0.1222  BEST VAL Loss: 0.1222  Val_Acc: 96.131

Epoch 55: Validation loss decreased (0.122220 --> 0.122048).  Saving model ...
	 Train_Loss: 0.1619 Train_Acc: 94.733 Val_Loss: 0.1220  BEST VAL Loss: 0.1220  Val_Acc: 95.911

Epoch 56: Validation loss decreased (0.122048 --> 0.121942).  Saving model ...
	 Train_Loss: 0.1616 Train_Acc: 94.660 Val_Loss: 0.1219  BEST VAL Loss: 0.1219  Val_Acc: 95.728

Epoch 57: Validation loss decreased (0.121942 --> 0.121870).  Saving model ...
	 Train_Loss: 0.1613 Train_Acc: 94.747 Val_Loss: 0.1219  BEST VAL Loss: 0.1219  Val_Acc: 96.061

Epoch 58: Validation loss decreased (0.121870 --> 0.121818).  Saving model ...
	 Train_Loss: 0.1609 Train_Acc: 94.726 Val_Loss: 0.1218  BEST VAL Loss: 0.1218  Val_Acc: 96.102

Epoch 59: Validation loss decreased (0.121818 --> 0.121691).  Saving model ...
	 Train_Loss: 0.1606 Train_Acc: 94.685 Val_Loss: 0.1217  BEST VAL Loss: 0.1217  Val_Acc: 96.111

Epoch 60: Validation loss decreased (0.121691 --> 0.121517).  Saving model ...
	 Train_Loss: 0.1603 Train_Acc: 94.717 Val_Loss: 0.1215  BEST VAL Loss: 0.1215  Val_Acc: 95.882

Epoch 61: Validation loss decreased (0.121517 --> 0.121354).  Saving model ...
	 Train_Loss: 0.1601 Train_Acc: 94.734 Val_Loss: 0.1214  BEST VAL Loss: 0.1214  Val_Acc: 95.886

Epoch 62: Validation loss decreased (0.121354 --> 0.121251).  Saving model ...
	 Train_Loss: 0.1598 Train_Acc: 94.760 Val_Loss: 0.1213  BEST VAL Loss: 0.1213  Val_Acc: 95.616

Epoch 63: Validation loss decreased (0.121251 --> 0.121134).  Saving model ...
	 Train_Loss: 0.1595 Train_Acc: 94.746 Val_Loss: 0.1211  BEST VAL Loss: 0.1211  Val_Acc: 96.044

Epoch 64: Validation loss decreased (0.121134 --> 0.121057).  Saving model ...
	 Train_Loss: 0.1592 Train_Acc: 94.770 Val_Loss: 0.1211  BEST VAL Loss: 0.1211  Val_Acc: 95.973

Epoch 65: Validation loss decreased (0.121057 --> 0.120943).  Saving model ...
	 Train_Loss: 0.1589 Train_Acc: 94.901 Val_Loss: 0.1209  BEST VAL Loss: 0.1209  Val_Acc: 95.799

Epoch 66: Validation loss decreased (0.120943 --> 0.120858).  Saving model ...
	 Train_Loss: 0.1586 Train_Acc: 94.850 Val_Loss: 0.1209  BEST VAL Loss: 0.1209  Val_Acc: 95.957

Epoch 67: Validation loss decreased (0.120858 --> 0.120720).  Saving model ...
	 Train_Loss: 0.1583 Train_Acc: 94.814 Val_Loss: 0.1207  BEST VAL Loss: 0.1207  Val_Acc: 95.990

Epoch 68: Validation loss decreased (0.120720 --> 0.120573).  Saving model ...
	 Train_Loss: 0.1581 Train_Acc: 94.780 Val_Loss: 0.1206  BEST VAL Loss: 0.1206  Val_Acc: 96.289

Epoch 69: Validation loss decreased (0.120573 --> 0.120370).  Saving model ...
	 Train_Loss: 0.1578 Train_Acc: 94.829 Val_Loss: 0.1204  BEST VAL Loss: 0.1204  Val_Acc: 95.928

Epoch 70: Validation loss decreased (0.120370 --> 0.120270).  Saving model ...
	 Train_Loss: 0.1575 Train_Acc: 94.852 Val_Loss: 0.1203  BEST VAL Loss: 0.1203  Val_Acc: 96.052

Epoch 71: Validation loss decreased (0.120270 --> 0.120216).  Saving model ...
	 Train_Loss: 0.1573 Train_Acc: 94.839 Val_Loss: 0.1202  BEST VAL Loss: 0.1202  Val_Acc: 96.011

Epoch 72: Validation loss decreased (0.120216 --> 0.120143).  Saving model ...
	 Train_Loss: 0.1570 Train_Acc: 94.815 Val_Loss: 0.1201  BEST VAL Loss: 0.1201  Val_Acc: 95.982

Epoch 73: Validation loss decreased (0.120143 --> 0.120030).  Saving model ...
	 Train_Loss: 0.1568 Train_Acc: 94.843 Val_Loss: 0.1200  BEST VAL Loss: 0.1200  Val_Acc: 96.007

Epoch 74: Validation loss decreased (0.120030 --> 0.119939).  Saving model ...
	 Train_Loss: 0.1566 Train_Acc: 94.917 Val_Loss: 0.1199  BEST VAL Loss: 0.1199  Val_Acc: 95.973

Epoch 75: Validation loss decreased (0.119939 --> 0.119843).  Saving model ...
	 Train_Loss: 0.1563 Train_Acc: 94.835 Val_Loss: 0.1198  BEST VAL Loss: 0.1198  Val_Acc: 95.699

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.1561 Train_Acc: 94.810 Val_Loss: 0.1200  BEST VAL Loss: 0.1198  Val_Acc: 95.982

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.1559 Train_Acc: 94.899 Val_Loss: 0.1199  BEST VAL Loss: 0.1198  Val_Acc: 96.185

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.1557 Train_Acc: 94.847 Val_Loss: 0.1199  BEST VAL Loss: 0.1198  Val_Acc: 96.165

Epoch 79: Validation loss decreased (0.119843 --> 0.119817).  Saving model ...
	 Train_Loss: 0.1555 Train_Acc: 94.773 Val_Loss: 0.1198  BEST VAL Loss: 0.1198  Val_Acc: 95.724

Epoch 80: Validation loss decreased (0.119817 --> 0.119794).  Saving model ...
	 Train_Loss: 0.1552 Train_Acc: 94.911 Val_Loss: 0.1198  BEST VAL Loss: 0.1198  Val_Acc: 96.069

Epoch 81: Validation loss decreased (0.119794 --> 0.119710).  Saving model ...
	 Train_Loss: 0.1550 Train_Acc: 94.820 Val_Loss: 0.1197  BEST VAL Loss: 0.1197  Val_Acc: 96.019

Epoch 82: Validation loss decreased (0.119710 --> 0.119616).  Saving model ...
	 Train_Loss: 0.1548 Train_Acc: 94.886 Val_Loss: 0.1196  BEST VAL Loss: 0.1196  Val_Acc: 95.919

Epoch 83: Validation loss decreased (0.119616 --> 0.119465).  Saving model ...
	 Train_Loss: 0.1546 Train_Acc: 94.907 Val_Loss: 0.1195  BEST VAL Loss: 0.1195  Val_Acc: 96.015

Epoch 84: Validation loss decreased (0.119465 --> 0.119369).  Saving model ...
	 Train_Loss: 0.1544 Train_Acc: 94.935 Val_Loss: 0.1194  BEST VAL Loss: 0.1194  Val_Acc: 96.032

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.1542 Train_Acc: 94.901 Val_Loss: 0.1194  BEST VAL Loss: 0.1194  Val_Acc: 95.969

Epoch 86: Validation loss decreased (0.119369 --> 0.119336).  Saving model ...
	 Train_Loss: 0.1540 Train_Acc: 94.912 Val_Loss: 0.1193  BEST VAL Loss: 0.1193  Val_Acc: 96.235

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.1538 Train_Acc: 94.935 Val_Loss: 0.1193  BEST VAL Loss: 0.1193  Val_Acc: 96.181

Epoch 88: Validation loss decreased (0.119336 --> 0.119328).  Saving model ...
	 Train_Loss: 0.1536 Train_Acc: 94.994 Val_Loss: 0.1193  BEST VAL Loss: 0.1193  Val_Acc: 96.094

Epoch 89: Validation loss decreased (0.119328 --> 0.119265).  Saving model ...
	 Train_Loss: 0.1534 Train_Acc: 94.874 Val_Loss: 0.1193  BEST VAL Loss: 0.1193  Val_Acc: 95.583

Epoch 90: Validation loss decreased (0.119265 --> 0.119245).  Saving model ...
	 Train_Loss: 0.1532 Train_Acc: 94.953 Val_Loss: 0.1192  BEST VAL Loss: 0.1192  Val_Acc: 96.256

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.1530 Train_Acc: 94.944 Val_Loss: 0.1193  BEST VAL Loss: 0.1192  Val_Acc: 96.214

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.1528 Train_Acc: 94.862 Val_Loss: 0.1193  BEST VAL Loss: 0.1192  Val_Acc: 96.206

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.1526 Train_Acc: 94.995 Val_Loss: 0.1193  BEST VAL Loss: 0.1192  Val_Acc: 95.691

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.1525 Train_Acc: 94.905 Val_Loss: 0.1194  BEST VAL Loss: 0.1192  Val_Acc: 95.948

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.1523 Train_Acc: 94.950 Val_Loss: 0.1193  BEST VAL Loss: 0.1192  Val_Acc: 95.957

Epoch 96: Validation loss decreased (0.119245 --> 0.119232).  Saving model ...
	 Train_Loss: 0.1521 Train_Acc: 95.046 Val_Loss: 0.1192  BEST VAL Loss: 0.1192  Val_Acc: 96.007

Epoch 97: Validation loss decreased (0.119232 --> 0.119185).  Saving model ...
	 Train_Loss: 0.1519 Train_Acc: 95.002 Val_Loss: 0.1192  BEST VAL Loss: 0.1192  Val_Acc: 95.953

Epoch 98: Validation loss decreased (0.119185 --> 0.119146).  Saving model ...
	 Train_Loss: 0.1518 Train_Acc: 95.048 Val_Loss: 0.1191  BEST VAL Loss: 0.1191  Val_Acc: 96.131

Epoch 99: Validation loss decreased (0.119146 --> 0.119056).  Saving model ...
	 Train_Loss: 0.1516 Train_Acc: 95.020 Val_Loss: 0.1191  BEST VAL Loss: 0.1191  Val_Acc: 96.165

LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.47      0.48     92173
           1       0.52      0.52      0.52    100339

    accuracy                           0.50    192512
   macro avg       0.50      0.50      0.50    192512
weighted avg       0.50      0.50      0.50    192512

LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.48      0.48     11522
           1       0.52      0.53      0.53     12543

    accuracy                           0.50     24065
   macro avg       0.50      0.50      0.50     24065
weighted avg       0.50      0.50      0.50     24065

LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.48      0.48     11522
           1       0.52      0.53      0.53     12543

    accuracy                           0.50     24065
   macro avg       0.50      0.50      0.50     24065
weighted avg       0.50      0.50      0.50     24065

              precision    recall  f1-score   support

           0       0.48      0.48      0.48     11522
           1       0.52      0.53      0.53     12543

    accuracy                           0.50     24065
   macro avg       0.50      0.50      0.50     24065
weighted avg       0.50      0.50      0.50     24065

LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.45      0.48     41273
           1       0.49      0.54      0.52     40588

    accuracy                           0.50     81861
   macro avg       0.50      0.50      0.50     81861
weighted avg       0.50      0.50      0.50     81861

              precision    recall  f1-score   support

           0       0.50      0.45      0.48     41273
           1       0.49      0.54      0.52     40588

    accuracy                           0.50     81861
   macro avg       0.50      0.50      0.50     81861
weighted avg       0.50      0.50      0.50     81861

completed
