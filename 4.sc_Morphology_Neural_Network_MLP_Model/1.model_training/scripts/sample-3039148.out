[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '99a9f801'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '4c88259a'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1c3ca74c'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '7a993d11'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Thapsigargin_10.000_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Thapsigargin_10.000_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'LPS_0.010_DMSO_0.025']
The dimensions of the data are: (29071, 1276)
Number of total missing values across all columns: 58142
Data Subset Is Off
Wells held out for testing: ['E14' 'B20']
Wells to use for training, validation, and testing ['E15' 'B16' 'B17' 'B21' 'L14' 'L15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.531858).  Saving model ...
	 Train_Loss: 0.6638 Train_Acc: 57.013 Val_Loss: 0.5319  BEST VAL Loss: 0.5319  Val_Acc: 81.868

Epoch 1: Validation loss decreased (0.531858 --> 0.439109).  Saving model ...
	 Train_Loss: 0.5776 Train_Acc: 80.506 Val_Loss: 0.4391  BEST VAL Loss: 0.4391  Val_Acc: 88.337

Epoch 2: Validation loss decreased (0.439109 --> 0.388358).  Saving model ...
	 Train_Loss: 0.5226 Train_Acc: 83.940 Val_Loss: 0.3884  BEST VAL Loss: 0.3884  Val_Acc: 90.068

Epoch 3: Validation loss decreased (0.388358 --> 0.356937).  Saving model ...
	 Train_Loss: 0.4874 Train_Acc: 85.187 Val_Loss: 0.3569  BEST VAL Loss: 0.3569  Val_Acc: 91.116

Epoch 4: Validation loss decreased (0.356937 --> 0.334168).  Saving model ...
	 Train_Loss: 0.4619 Train_Acc: 85.967 Val_Loss: 0.3342  BEST VAL Loss: 0.3342  Val_Acc: 91.708

Epoch 5: Validation loss decreased (0.334168 --> 0.318016).  Saving model ...
	 Train_Loss: 0.4430 Train_Acc: 87.112 Val_Loss: 0.3180  BEST VAL Loss: 0.3180  Val_Acc: 91.936

Epoch 6: Validation loss decreased (0.318016 --> 0.306298).  Saving model ...
	 Train_Loss: 0.4289 Train_Acc: 87.066 Val_Loss: 0.3063  BEST VAL Loss: 0.3063  Val_Acc: 92.346

Epoch 7: Validation loss decreased (0.306298 --> 0.298810).  Saving model ...
	 Train_Loss: 0.4167 Train_Acc: 87.761 Val_Loss: 0.2988  BEST VAL Loss: 0.2988  Val_Acc: 92.073

Epoch 8: Validation loss decreased (0.298810 --> 0.290257).  Saving model ...
	 Train_Loss: 0.4074 Train_Acc: 87.744 Val_Loss: 0.2903  BEST VAL Loss: 0.2903  Val_Acc: 92.938

Epoch 9: Validation loss decreased (0.290257 --> 0.284103).  Saving model ...
	 Train_Loss: 0.3989 Train_Acc: 88.280 Val_Loss: 0.2841  BEST VAL Loss: 0.2841  Val_Acc: 92.847

Epoch 10: Validation loss decreased (0.284103 --> 0.278006).  Saving model ...
	 Train_Loss: 0.3914 Train_Acc: 88.439 Val_Loss: 0.2780  BEST VAL Loss: 0.2780  Val_Acc: 92.802

Epoch 11: Validation loss decreased (0.278006 --> 0.272512).  Saving model ...
	 Train_Loss: 0.3848 Train_Acc: 88.883 Val_Loss: 0.2725  BEST VAL Loss: 0.2725  Val_Acc: 92.756

Epoch 12: Validation loss decreased (0.272512 --> 0.267561).  Saving model ...
	 Train_Loss: 0.3787 Train_Acc: 88.997 Val_Loss: 0.2676  BEST VAL Loss: 0.2676  Val_Acc: 93.121

Epoch 13: Validation loss decreased (0.267561 --> 0.264598).  Saving model ...
	 Train_Loss: 0.3744 Train_Acc: 88.655 Val_Loss: 0.2646  BEST VAL Loss: 0.2646  Val_Acc: 92.437

Epoch 14: Validation loss decreased (0.264598 --> 0.261270).  Saving model ...
	 Train_Loss: 0.3697 Train_Acc: 89.168 Val_Loss: 0.2613  BEST VAL Loss: 0.2613  Val_Acc: 92.802

Epoch 15: Validation loss decreased (0.261270 --> 0.258617).  Saving model ...
	 Train_Loss: 0.3659 Train_Acc: 88.963 Val_Loss: 0.2586  BEST VAL Loss: 0.2586  Val_Acc: 92.938

Epoch 16: Validation loss decreased (0.258617 --> 0.256600).  Saving model ...
	 Train_Loss: 0.3616 Train_Acc: 89.652 Val_Loss: 0.2566  BEST VAL Loss: 0.2566  Val_Acc: 92.620

Epoch 17: Validation loss decreased (0.256600 --> 0.254145).  Saving model ...
	 Train_Loss: 0.3582 Train_Acc: 89.379 Val_Loss: 0.2541  BEST VAL Loss: 0.2541  Val_Acc: 93.257

Epoch 18: Validation loss decreased (0.254145 --> 0.252861).  Saving model ...
	 Train_Loss: 0.3549 Train_Acc: 89.550 Val_Loss: 0.2529  BEST VAL Loss: 0.2529  Val_Acc: 92.164

Epoch 19: Validation loss decreased (0.252861 --> 0.250977).  Saving model ...
	 Train_Loss: 0.3516 Train_Acc: 89.698 Val_Loss: 0.2510  BEST VAL Loss: 0.2510  Val_Acc: 93.166

Epoch 20: Validation loss decreased (0.250977 --> 0.249065).  Saving model ...
	 Train_Loss: 0.3487 Train_Acc: 89.868 Val_Loss: 0.2491  BEST VAL Loss: 0.2491  Val_Acc: 93.576

Epoch 21: Validation loss decreased (0.249065 --> 0.247247).  Saving model ...
	 Train_Loss: 0.3458 Train_Acc: 90.062 Val_Loss: 0.2472  BEST VAL Loss: 0.2472  Val_Acc: 93.166

Epoch 22: Validation loss decreased (0.247247 --> 0.245679).  Saving model ...
	 Train_Loss: 0.3429 Train_Acc: 90.421 Val_Loss: 0.2457  BEST VAL Loss: 0.2457  Val_Acc: 93.257

Epoch 23: Validation loss decreased (0.245679 --> 0.243981).  Saving model ...
	 Train_Loss: 0.3400 Train_Acc: 90.478 Val_Loss: 0.2440  BEST VAL Loss: 0.2440  Val_Acc: 93.941

Epoch 24: Validation loss decreased (0.243981 --> 0.242499).  Saving model ...
	 Train_Loss: 0.3373 Train_Acc: 90.660 Val_Loss: 0.2425  BEST VAL Loss: 0.2425  Val_Acc: 93.394

Epoch 25: Validation loss decreased (0.242499 --> 0.241084).  Saving model ...
	 Train_Loss: 0.3352 Train_Acc: 90.165 Val_Loss: 0.2411  BEST VAL Loss: 0.2411  Val_Acc: 93.667

Epoch 26: Validation loss decreased (0.241084 --> 0.240069).  Saving model ...
	 Train_Loss: 0.3331 Train_Acc: 90.364 Val_Loss: 0.2401  BEST VAL Loss: 0.2401  Val_Acc: 93.349

Epoch 27: Validation loss decreased (0.240069 --> 0.239074).  Saving model ...
	 Train_Loss: 0.3310 Train_Acc: 90.495 Val_Loss: 0.2391  BEST VAL Loss: 0.2391  Val_Acc: 93.394

Epoch 28: Validation loss decreased (0.239074 --> 0.238064).  Saving model ...
	 Train_Loss: 0.3293 Train_Acc: 90.569 Val_Loss: 0.2381  BEST VAL Loss: 0.2381  Val_Acc: 92.984

Epoch 29: Validation loss decreased (0.238064 --> 0.237372).  Saving model ...
	 Train_Loss: 0.3274 Train_Acc: 90.763 Val_Loss: 0.2374  BEST VAL Loss: 0.2374  Val_Acc: 93.257

Epoch 30: Validation loss decreased (0.237372 --> 0.236299).  Saving model ...
	 Train_Loss: 0.3257 Train_Acc: 90.478 Val_Loss: 0.2363  BEST VAL Loss: 0.2363  Val_Acc: 93.622

Epoch 31: Validation loss decreased (0.236299 --> 0.235241).  Saving model ...
	 Train_Loss: 0.3240 Train_Acc: 90.689 Val_Loss: 0.2352  BEST VAL Loss: 0.2352  Val_Acc: 93.941

Epoch 32: Validation loss decreased (0.235241 --> 0.234783).  Saving model ...
	 Train_Loss: 0.3224 Train_Acc: 90.751 Val_Loss: 0.2348  BEST VAL Loss: 0.2348  Val_Acc: 93.075

Epoch 33: Validation loss decreased (0.234783 --> 0.234292).  Saving model ...
	 Train_Loss: 0.3209 Train_Acc: 90.780 Val_Loss: 0.2343  BEST VAL Loss: 0.2343  Val_Acc: 93.713

Epoch 34: Validation loss decreased (0.234292 --> 0.233575).  Saving model ...
	 Train_Loss: 0.3193 Train_Acc: 91.053 Val_Loss: 0.2336  BEST VAL Loss: 0.2336  Val_Acc: 93.485

Epoch 35: Validation loss decreased (0.233575 --> 0.233040).  Saving model ...
	 Train_Loss: 0.3177 Train_Acc: 91.116 Val_Loss: 0.2330  BEST VAL Loss: 0.2330  Val_Acc: 93.576

Epoch 36: Validation loss decreased (0.233040 --> 0.232685).  Saving model ...
	 Train_Loss: 0.3162 Train_Acc: 91.212 Val_Loss: 0.2327  BEST VAL Loss: 0.2327  Val_Acc: 93.576

Epoch 37: Validation loss decreased (0.232685 --> 0.231883).  Saving model ...
	 Train_Loss: 0.3149 Train_Acc: 90.951 Val_Loss: 0.2319  BEST VAL Loss: 0.2319  Val_Acc: 93.941

Epoch 38: Validation loss decreased (0.231883 --> 0.231296).  Saving model ...
	 Train_Loss: 0.3137 Train_Acc: 91.087 Val_Loss: 0.2313  BEST VAL Loss: 0.2313  Val_Acc: 93.303

Epoch 39: Validation loss decreased (0.231296 --> 0.230806).  Saving model ...
	 Train_Loss: 0.3121 Train_Acc: 91.412 Val_Loss: 0.2308  BEST VAL Loss: 0.2308  Val_Acc: 93.349

Epoch 40: Validation loss decreased (0.230806 --> 0.230388).  Saving model ...
	 Train_Loss: 0.3106 Train_Acc: 91.657 Val_Loss: 0.2304  BEST VAL Loss: 0.2304  Val_Acc: 93.804

Epoch 41: Validation loss decreased (0.230388 --> 0.229778).  Saving model ...
	 Train_Loss: 0.3094 Train_Acc: 91.287 Val_Loss: 0.2298  BEST VAL Loss: 0.2298  Val_Acc: 93.257

Epoch 42: Validation loss decreased (0.229778 --> 0.228979).  Saving model ...
	 Train_Loss: 0.3083 Train_Acc: 90.990 Val_Loss: 0.2290  BEST VAL Loss: 0.2290  Val_Acc: 94.123

Epoch 43: Validation loss decreased (0.228979 --> 0.228324).  Saving model ...
	 Train_Loss: 0.3073 Train_Acc: 90.854 Val_Loss: 0.2283  BEST VAL Loss: 0.2283  Val_Acc: 93.667

Epoch 44: Validation loss decreased (0.228324 --> 0.227993).  Saving model ...
	 Train_Loss: 0.3060 Train_Acc: 91.640 Val_Loss: 0.2280  BEST VAL Loss: 0.2280  Val_Acc: 93.303

Epoch 45: Validation loss decreased (0.227993 --> 0.227577).  Saving model ...
	 Train_Loss: 0.3049 Train_Acc: 91.201 Val_Loss: 0.2276  BEST VAL Loss: 0.2276  Val_Acc: 93.349

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.3038 Train_Acc: 91.361 Val_Loss: 0.2276  BEST VAL Loss: 0.2276  Val_Acc: 93.075

Epoch 47: Validation loss decreased (0.227577 --> 0.227490).  Saving model ...
	 Train_Loss: 0.3028 Train_Acc: 91.304 Val_Loss: 0.2275  BEST VAL Loss: 0.2275  Val_Acc: 93.531

Epoch 48: Validation loss decreased (0.227490 --> 0.227310).  Saving model ...
	 Train_Loss: 0.3019 Train_Acc: 91.492 Val_Loss: 0.2273  BEST VAL Loss: 0.2273  Val_Acc: 93.531

Epoch 49: Validation loss decreased (0.227310 --> 0.227126).  Saving model ...
	 Train_Loss: 0.3011 Train_Acc: 91.013 Val_Loss: 0.2271  BEST VAL Loss: 0.2271  Val_Acc: 93.349

Epoch 50: Validation loss decreased (0.227126 --> 0.226808).  Saving model ...
	 Train_Loss: 0.3002 Train_Acc: 91.526 Val_Loss: 0.2268  BEST VAL Loss: 0.2268  Val_Acc: 93.759

Epoch 51: Validation loss decreased (0.226808 --> 0.226307).  Saving model ...
	 Train_Loss: 0.2992 Train_Acc: 91.526 Val_Loss: 0.2263  BEST VAL Loss: 0.2263  Val_Acc: 93.895

Epoch 52: Validation loss decreased (0.226307 --> 0.225949).  Saving model ...
	 Train_Loss: 0.2985 Train_Acc: 91.064 Val_Loss: 0.2259  BEST VAL Loss: 0.2259  Val_Acc: 93.713

Epoch 53: Validation loss decreased (0.225949 --> 0.225850).  Saving model ...
	 Train_Loss: 0.2975 Train_Acc: 91.520 Val_Loss: 0.2259  BEST VAL Loss: 0.2259  Val_Acc: 93.759

Epoch 54: Validation loss decreased (0.225850 --> 0.225682).  Saving model ...
	 Train_Loss: 0.2965 Train_Acc: 91.879 Val_Loss: 0.2257  BEST VAL Loss: 0.2257  Val_Acc: 94.077

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.2955 Train_Acc: 91.998 Val_Loss: 0.2257  BEST VAL Loss: 0.2257  Val_Acc: 93.895

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.2948 Train_Acc: 91.230 Val_Loss: 0.2258  BEST VAL Loss: 0.2257  Val_Acc: 93.212

Epoch 57: Validation loss decreased (0.225682 --> 0.225546).  Saving model ...
	 Train_Loss: 0.2940 Train_Acc: 91.514 Val_Loss: 0.2255  BEST VAL Loss: 0.2255  Val_Acc: 93.804

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.2932 Train_Acc: 91.765 Val_Loss: 0.2256  BEST VAL Loss: 0.2255  Val_Acc: 93.986

Epoch 59: Validation loss decreased (0.225546 --> 0.225439).  Saving model ...
	 Train_Loss: 0.2924 Train_Acc: 91.594 Val_Loss: 0.2254  BEST VAL Loss: 0.2254  Val_Acc: 93.713

Epoch 60: Validation loss decreased (0.225439 --> 0.225389).  Saving model ...
	 Train_Loss: 0.2916 Train_Acc: 91.719 Val_Loss: 0.2254  BEST VAL Loss: 0.2254  Val_Acc: 93.804

Epoch 61: Validation loss decreased (0.225389 --> 0.225377).  Saving model ...
	 Train_Loss: 0.2910 Train_Acc: 91.480 Val_Loss: 0.2254  BEST VAL Loss: 0.2254  Val_Acc: 93.394

Epoch 62: Validation loss decreased (0.225377 --> 0.225152).  Saving model ...
	 Train_Loss: 0.2903 Train_Acc: 91.452 Val_Loss: 0.2252  BEST VAL Loss: 0.2252  Val_Acc: 93.895

Epoch 63: Validation loss decreased (0.225152 --> 0.225080).  Saving model ...
	 Train_Loss: 0.2896 Train_Acc: 91.566 Val_Loss: 0.2251  BEST VAL Loss: 0.2251  Val_Acc: 93.485

Epoch 64: Validation loss decreased (0.225080 --> 0.224856).  Saving model ...
	 Train_Loss: 0.2889 Train_Acc: 91.816 Val_Loss: 0.2249  BEST VAL Loss: 0.2249  Val_Acc: 93.349

Epoch 65: Validation loss decreased (0.224856 --> 0.224626).  Saving model ...
	 Train_Loss: 0.2882 Train_Acc: 91.702 Val_Loss: 0.2246  BEST VAL Loss: 0.2246  Val_Acc: 94.351

Epoch 66: Validation loss decreased (0.224626 --> 0.224496).  Saving model ...
	 Train_Loss: 0.2874 Train_Acc: 91.953 Val_Loss: 0.2245  BEST VAL Loss: 0.2245  Val_Acc: 94.123

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.2867 Train_Acc: 92.010 Val_Loss: 0.2246  BEST VAL Loss: 0.2245  Val_Acc: 93.531

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.2860 Train_Acc: 91.873 Val_Loss: 0.2250  BEST VAL Loss: 0.2245  Val_Acc: 93.257

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.2854 Train_Acc: 91.719 Val_Loss: 0.2252  BEST VAL Loss: 0.2245  Val_Acc: 93.349

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.2849 Train_Acc: 91.560 Val_Loss: 0.2253  BEST VAL Loss: 0.2245  Val_Acc: 93.804

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.2843 Train_Acc: 91.742 Val_Loss: 0.2251  BEST VAL Loss: 0.2245  Val_Acc: 93.804

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.2838 Train_Acc: 91.509 Val_Loss: 0.2251  BEST VAL Loss: 0.2245  Val_Acc: 93.804

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.2831 Train_Acc: 92.090 Val_Loss: 0.2251  BEST VAL Loss: 0.2245  Val_Acc: 93.531

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.2824 Train_Acc: 92.221 Val_Loss: 0.2250  BEST VAL Loss: 0.2245  Val_Acc: 93.257

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.2818 Train_Acc: 92.141 Val_Loss: 0.2251  BEST VAL Loss: 0.2245  Val_Acc: 93.349

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.2812 Train_Acc: 91.907 Val_Loss: 0.2251  BEST VAL Loss: 0.2245  Val_Acc: 93.030

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.2806 Train_Acc: 92.181 Val_Loss: 0.2252  BEST VAL Loss: 0.2245  Val_Acc: 93.622

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.2800 Train_Acc: 92.186 Val_Loss: 0.2252  BEST VAL Loss: 0.2245  Val_Acc: 93.394

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.2794 Train_Acc: 92.044 Val_Loss: 0.2253  BEST VAL Loss: 0.2245  Val_Acc: 93.576

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.2789 Train_Acc: 92.072 Val_Loss: 0.2253  BEST VAL Loss: 0.2245  Val_Acc: 93.759

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.2784 Train_Acc: 91.879 Val_Loss: 0.2252  BEST VAL Loss: 0.2245  Val_Acc: 93.986

Epoch 82: Validation loss did not decrease
Early stopped at epoch : 82
Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.98      0.98      9707
           1       0.98      0.96      0.97      7852

    accuracy                           0.97     17559
   macro avg       0.97      0.97      0.97     17559
weighted avg       0.97      0.97      0.97     17559

Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.94      0.96      0.95      1214
           1       0.95      0.92      0.93       981

    accuracy                           0.94      2195
   macro avg       0.94      0.94      0.94      2195
weighted avg       0.94      0.94      0.94      2195

Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.96      0.94      1214
           1       0.94      0.91      0.93       981

    accuracy                           0.93      2195
   macro avg       0.94      0.93      0.93      2195
weighted avg       0.93      0.93      0.93      2195

              precision    recall  f1-score   support

           0       0.93      0.96      0.94      1214
           1       0.94      0.91      0.93       981

    accuracy                           0.93      2195
   macro avg       0.94      0.93      0.93      2195
weighted avg       0.93      0.93      0.93      2195

Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.94      0.95      0.94      3724
           1       0.95      0.93      0.94      3398

    accuracy                           0.94      7122
   macro avg       0.94      0.94      0.94      7122
weighted avg       0.94      0.94      0.94      7122

              precision    recall  f1-score   support

           0       0.94      0.95      0.94      3724
           1       0.95      0.93      0.94      3398

    accuracy                           0.94      7122
   macro avg       0.94      0.94      0.94      7122
weighted avg       0.94      0.94      0.94      7122

completed
