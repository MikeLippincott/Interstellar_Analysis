[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '031d865b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '596a06b9'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '95615538'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '5fdcb973'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: DMSO_0.100_DMSO_0.025 treatment_name: LPS_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: DMSO_0.100_DMSO_0.025
TREATMENT_NAME: LPS_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'LPS_1.000_DMSO_0.025']
The dimensions of the data are: (52101, 1276)
Number of total missing values across all columns: 104202
Data Subset Is Off
Wells held out for testing: ['D20' 'I14']
Wells to use for training, validation, and testing ['B14' 'C14' 'B15' 'C15' 'D16' 'D17' 'D21' 'J14' 'I15' 'J15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.530208).  Saving model ...
	 Train_Loss: 0.5882 Train_Acc: 70.408 Val_Loss: 0.5302  BEST VAL Loss: 0.5302  Val_Acc: 74.548

Epoch 1: Validation loss decreased (0.530208 --> 0.518528).  Saving model ...
	 Train_Loss: 0.5561 Train_Acc: 75.171 Val_Loss: 0.5185  BEST VAL Loss: 0.5185  Val_Acc: 75.429

Epoch 2: Validation loss decreased (0.518528 --> 0.513662).  Saving model ...
	 Train_Loss: 0.5395 Train_Acc: 75.693 Val_Loss: 0.5137  BEST VAL Loss: 0.5137  Val_Acc: 76.148

Epoch 3: Validation loss decreased (0.513662 --> 0.508543).  Saving model ...
	 Train_Loss: 0.5285 Train_Acc: 76.468 Val_Loss: 0.5085  BEST VAL Loss: 0.5085  Val_Acc: 76.148

Epoch 4: Validation loss decreased (0.508543 --> 0.505440).  Saving model ...
	 Train_Loss: 0.5207 Train_Acc: 76.459 Val_Loss: 0.5054  BEST VAL Loss: 0.5054  Val_Acc: 76.218

Epoch 5: Validation loss decreased (0.505440 --> 0.502616).  Saving model ...
	 Train_Loss: 0.5142 Train_Acc: 76.824 Val_Loss: 0.5026  BEST VAL Loss: 0.5026  Val_Acc: 76.311

Epoch 6: Validation loss decreased (0.502616 --> 0.500590).  Saving model ...
	 Train_Loss: 0.5092 Train_Acc: 77.030 Val_Loss: 0.5006  BEST VAL Loss: 0.5006  Val_Acc: 75.754

Epoch 7: Validation loss decreased (0.500590 --> 0.497886).  Saving model ...
	 Train_Loss: 0.5053 Train_Acc: 76.932 Val_Loss: 0.4979  BEST VAL Loss: 0.4979  Val_Acc: 76.218

Epoch 8: Validation loss decreased (0.497886 --> 0.497401).  Saving model ...
	 Train_Loss: 0.5017 Train_Acc: 77.486 Val_Loss: 0.4974  BEST VAL Loss: 0.4974  Val_Acc: 76.357

Epoch 9: Validation loss decreased (0.497401 --> 0.495896).  Saving model ...
	 Train_Loss: 0.4984 Train_Acc: 77.692 Val_Loss: 0.4959  BEST VAL Loss: 0.4959  Val_Acc: 76.566

Epoch 10: Validation loss decreased (0.495896 --> 0.495299).  Saving model ...
	 Train_Loss: 0.4955 Train_Acc: 77.637 Val_Loss: 0.4953  BEST VAL Loss: 0.4953  Val_Acc: 76.682

Epoch 11: Validation loss decreased (0.495299 --> 0.493681).  Saving model ...
	 Train_Loss: 0.4926 Train_Acc: 78.327 Val_Loss: 0.4937  BEST VAL Loss: 0.4937  Val_Acc: 77.146

Epoch 12: Validation loss decreased (0.493681 --> 0.492262).  Saving model ...
	 Train_Loss: 0.4902 Train_Acc: 78.205 Val_Loss: 0.4923  BEST VAL Loss: 0.4923  Val_Acc: 76.891

Epoch 13: Validation loss decreased (0.492262 --> 0.491047).  Saving model ...
	 Train_Loss: 0.4879 Train_Acc: 78.246 Val_Loss: 0.4910  BEST VAL Loss: 0.4910  Val_Acc: 77.007

Epoch 14: Validation loss decreased (0.491047 --> 0.490286).  Saving model ...
	 Train_Loss: 0.4858 Train_Acc: 78.385 Val_Loss: 0.4903  BEST VAL Loss: 0.4903  Val_Acc: 77.448

Epoch 15: Validation loss decreased (0.490286 --> 0.489599).  Saving model ...
	 Train_Loss: 0.4839 Train_Acc: 78.681 Val_Loss: 0.4896  BEST VAL Loss: 0.4896  Val_Acc: 77.030

Epoch 16: Validation loss decreased (0.489599 --> 0.488370).  Saving model ...
	 Train_Loss: 0.4820 Train_Acc: 78.730 Val_Loss: 0.4884  BEST VAL Loss: 0.4884  Val_Acc: 77.193

Epoch 17: Validation loss decreased (0.488370 --> 0.487812).  Saving model ...
	 Train_Loss: 0.4803 Train_Acc: 78.426 Val_Loss: 0.4878  BEST VAL Loss: 0.4878  Val_Acc: 76.659

Epoch 18: Validation loss decreased (0.487812 --> 0.487036).  Saving model ...
	 Train_Loss: 0.4787 Train_Acc: 78.788 Val_Loss: 0.4870  BEST VAL Loss: 0.4870  Val_Acc: 77.262

Epoch 19: Validation loss decreased (0.487036 --> 0.486378).  Saving model ...
	 Train_Loss: 0.4772 Train_Acc: 79.090 Val_Loss: 0.4864  BEST VAL Loss: 0.4864  Val_Acc: 77.100

Epoch 20: Validation loss decreased (0.486378 --> 0.485449).  Saving model ...
	 Train_Loss: 0.4755 Train_Acc: 79.186 Val_Loss: 0.4854  BEST VAL Loss: 0.4854  Val_Acc: 76.961

Epoch 21: Validation loss decreased (0.485449 --> 0.485125).  Saving model ...
	 Train_Loss: 0.4740 Train_Acc: 79.270 Val_Loss: 0.4851  BEST VAL Loss: 0.4851  Val_Acc: 77.239

Epoch 22: Validation loss did not decrease
	 Train_Loss: 0.4726 Train_Acc: 79.113 Val_Loss: 0.4851  BEST VAL Loss: 0.4851  Val_Acc: 77.007

Epoch 23: Validation loss decreased (0.485125 --> 0.484776).  Saving model ...
	 Train_Loss: 0.4714 Train_Acc: 79.151 Val_Loss: 0.4848  BEST VAL Loss: 0.4848  Val_Acc: 77.749

Epoch 24: Validation loss decreased (0.484776 --> 0.484576).  Saving model ...
	 Train_Loss: 0.4701 Train_Acc: 79.313 Val_Loss: 0.4846  BEST VAL Loss: 0.4846  Val_Acc: 77.401

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.4689 Train_Acc: 79.432 Val_Loss: 0.4846  BEST VAL Loss: 0.4846  Val_Acc: 77.285

Epoch 26: Validation loss decreased (0.484576 --> 0.483859).  Saving model ...
	 Train_Loss: 0.4678 Train_Acc: 79.052 Val_Loss: 0.4839  BEST VAL Loss: 0.4839  Val_Acc: 77.471

Epoch 27: Validation loss decreased (0.483859 --> 0.483455).  Saving model ...
	 Train_Loss: 0.4665 Train_Acc: 79.780 Val_Loss: 0.4835  BEST VAL Loss: 0.4835  Val_Acc: 77.889

Epoch 28: Validation loss decreased (0.483455 --> 0.483028).  Saving model ...
	 Train_Loss: 0.4653 Train_Acc: 79.702 Val_Loss: 0.4830  BEST VAL Loss: 0.4830  Val_Acc: 78.283

Epoch 29: Validation loss decreased (0.483028 --> 0.482692).  Saving model ...
	 Train_Loss: 0.4644 Train_Acc: 79.261 Val_Loss: 0.4827  BEST VAL Loss: 0.4827  Val_Acc: 77.935

Epoch 30: Validation loss decreased (0.482692 --> 0.482110).  Saving model ...
	 Train_Loss: 0.4632 Train_Acc: 79.719 Val_Loss: 0.4821  BEST VAL Loss: 0.4821  Val_Acc: 78.005

Epoch 31: Validation loss decreased (0.482110 --> 0.482079).  Saving model ...
	 Train_Loss: 0.4622 Train_Acc: 79.893 Val_Loss: 0.4821  BEST VAL Loss: 0.4821  Val_Acc: 77.935

Epoch 32: Validation loss decreased (0.482079 --> 0.481800).  Saving model ...
	 Train_Loss: 0.4612 Train_Acc: 79.931 Val_Loss: 0.4818  BEST VAL Loss: 0.4818  Val_Acc: 77.703

Epoch 33: Validation loss decreased (0.481800 --> 0.481639).  Saving model ...
	 Train_Loss: 0.4602 Train_Acc: 79.977 Val_Loss: 0.4816  BEST VAL Loss: 0.4816  Val_Acc: 77.889

Epoch 34: Validation loss decreased (0.481639 --> 0.481500).  Saving model ...
	 Train_Loss: 0.4593 Train_Acc: 80.015 Val_Loss: 0.4815  BEST VAL Loss: 0.4815  Val_Acc: 77.865

Epoch 35: Validation loss decreased (0.481500 --> 0.481323).  Saving model ...
	 Train_Loss: 0.4583 Train_Acc: 80.325 Val_Loss: 0.4813  BEST VAL Loss: 0.4813  Val_Acc: 77.657

Epoch 36: Validation loss decreased (0.481323 --> 0.481310).  Saving model ...
	 Train_Loss: 0.4575 Train_Acc: 79.989 Val_Loss: 0.4813  BEST VAL Loss: 0.4813  Val_Acc: 78.097

Epoch 37: Validation loss decreased (0.481310 --> 0.481067).  Saving model ...
	 Train_Loss: 0.4567 Train_Acc: 80.146 Val_Loss: 0.4811  BEST VAL Loss: 0.4811  Val_Acc: 77.749

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.4558 Train_Acc: 80.233 Val_Loss: 0.4812  BEST VAL Loss: 0.4811  Val_Acc: 77.378

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.4548 Train_Acc: 80.618 Val_Loss: 0.4813  BEST VAL Loss: 0.4811  Val_Acc: 77.262

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.4540 Train_Acc: 80.201 Val_Loss: 0.4812  BEST VAL Loss: 0.4811  Val_Acc: 77.773

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.4532 Train_Acc: 80.383 Val_Loss: 0.4811  BEST VAL Loss: 0.4811  Val_Acc: 77.981

Epoch 42: Validation loss decreased (0.481067 --> 0.481002).  Saving model ...
	 Train_Loss: 0.4525 Train_Acc: 80.421 Val_Loss: 0.4810  BEST VAL Loss: 0.4810  Val_Acc: 78.028

Epoch 43: Validation loss decreased (0.481002 --> 0.480955).  Saving model ...
	 Train_Loss: 0.4516 Train_Acc: 80.810 Val_Loss: 0.4810  BEST VAL Loss: 0.4810  Val_Acc: 78.353

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.4507 Train_Acc: 80.697 Val_Loss: 0.4810  BEST VAL Loss: 0.4810  Val_Acc: 77.332

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.4500 Train_Acc: 80.575 Val_Loss: 0.4811  BEST VAL Loss: 0.4810  Val_Acc: 77.726

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.4492 Train_Acc: 80.685 Val_Loss: 0.4810  BEST VAL Loss: 0.4810  Val_Acc: 78.237

Epoch 47: Validation loss decreased (0.480955 --> 0.480709).  Saving model ...
	 Train_Loss: 0.4486 Train_Acc: 80.616 Val_Loss: 0.4807  BEST VAL Loss: 0.4807  Val_Acc: 78.260

Epoch 48: Validation loss decreased (0.480709 --> 0.480600).  Saving model ...
	 Train_Loss: 0.4478 Train_Acc: 81.004 Val_Loss: 0.4806  BEST VAL Loss: 0.4806  Val_Acc: 78.190

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.4470 Train_Acc: 81.053 Val_Loss: 0.4808  BEST VAL Loss: 0.4806  Val_Acc: 77.587

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.4463 Train_Acc: 81.120 Val_Loss: 0.4809  BEST VAL Loss: 0.4806  Val_Acc: 77.796

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.4456 Train_Acc: 81.024 Val_Loss: 0.4810  BEST VAL Loss: 0.4806  Val_Acc: 77.657

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.4449 Train_Acc: 80.769 Val_Loss: 0.4810  BEST VAL Loss: 0.4806  Val_Acc: 77.610

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.4443 Train_Acc: 80.946 Val_Loss: 0.4811  BEST VAL Loss: 0.4806  Val_Acc: 77.726

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.4436 Train_Acc: 81.164 Val_Loss: 0.4813  BEST VAL Loss: 0.4806  Val_Acc: 77.610

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.4431 Train_Acc: 81.030 Val_Loss: 0.4811  BEST VAL Loss: 0.4806  Val_Acc: 77.773

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.4424 Train_Acc: 81.013 Val_Loss: 0.4813  BEST VAL Loss: 0.4806  Val_Acc: 77.471

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.4418 Train_Acc: 81.114 Val_Loss: 0.4813  BEST VAL Loss: 0.4806  Val_Acc: 77.680

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.4412 Train_Acc: 81.106 Val_Loss: 0.4813  BEST VAL Loss: 0.4806  Val_Acc: 77.842

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.4406 Train_Acc: 81.242 Val_Loss: 0.4818  BEST VAL Loss: 0.4806  Val_Acc: 78.028

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.4400 Train_Acc: 81.291 Val_Loss: 0.4820  BEST VAL Loss: 0.4806  Val_Acc: 77.541

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.4394 Train_Acc: 81.404 Val_Loss: 0.4821  BEST VAL Loss: 0.4806  Val_Acc: 78.376

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.4389 Train_Acc: 81.297 Val_Loss: 0.4822  BEST VAL Loss: 0.4806  Val_Acc: 78.237

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.4383 Train_Acc: 81.346 Val_Loss: 0.4825  BEST VAL Loss: 0.4806  Val_Acc: 78.237

Epoch 64: Validation loss did not decrease
Early stopped at epoch : 64
DMSO_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.71      0.82      0.77     24644
           1       0.28      0.17      0.22      9832

    accuracy                           0.64     34476
   macro avg       0.50      0.50      0.49     34476
weighted avg       0.59      0.64      0.61     34476

DMSO_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.72      0.84      0.77      3081
           1       0.30      0.17      0.22      1229

    accuracy                           0.65      4310
   macro avg       0.51      0.51      0.50      4310
weighted avg       0.60      0.65      0.61      4310

DMSO_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.71      0.83      0.77      3081
           1       0.28      0.17      0.21      1229

    accuracy                           0.64      4310
   macro avg       0.50      0.50      0.49      4310
weighted avg       0.59      0.64      0.61      4310

              precision    recall  f1-score   support

           0       0.71      0.83      0.77      3081
           1       0.28      0.17      0.21      1229

    accuracy                           0.64      4310
   macro avg       0.50      0.50      0.49      4310
weighted avg       0.59      0.64      0.61      4310

DMSO_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.54      0.72      0.62      4837
           1       0.47      0.28      0.35      4168

    accuracy                           0.52      9005
   macro avg       0.50      0.50      0.49      9005
weighted avg       0.51      0.52      0.50      9005

              precision    recall  f1-score   support

           0       0.54      0.72      0.62      4837
           1       0.47      0.28      0.35      4168

    accuracy                           0.52      9005
   macro avg       0.50      0.50      0.49      9005
weighted avg       0.51      0.52      0.50      9005

completed
