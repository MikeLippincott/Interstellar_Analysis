[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '0dcac23e'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '22eb913b'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '0e2d3365'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '9a4c6697'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_1.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_1.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (305446, 1270)
Number of total missing values across all columns: 278866
Data Subset Is Off
Wells held out for testing: ['D08' 'K08']
Wells to use for training, validation, and testing ['D02' 'D03' 'D09' 'K02' 'K03' 'K09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.405595).  Saving model ...
	 Train_Loss: 0.5149 Train_Acc: 74.347 Val_Loss: 0.4056  BEST VAL Loss: 0.4056  Val_Acc: 81.783

Epoch 1: Validation loss decreased (0.405595 --> 0.389527).  Saving model ...
	 Train_Loss: 0.4832 Train_Acc: 79.282 Val_Loss: 0.3895  BEST VAL Loss: 0.3895  Val_Acc: 83.955

Epoch 2: Validation loss decreased (0.389527 --> 0.385966).  Saving model ...
	 Train_Loss: 0.4660 Train_Acc: 80.476 Val_Loss: 0.3860  BEST VAL Loss: 0.3860  Val_Acc: 84.235

Epoch 3: Validation loss decreased (0.385966 --> 0.381701).  Saving model ...
	 Train_Loss: 0.4551 Train_Acc: 81.059 Val_Loss: 0.3817  BEST VAL Loss: 0.3817  Val_Acc: 83.697

Epoch 4: Validation loss decreased (0.381701 --> 0.375723).  Saving model ...
	 Train_Loss: 0.4473 Train_Acc: 81.576 Val_Loss: 0.3757  BEST VAL Loss: 0.3757  Val_Acc: 85.292

Epoch 5: Validation loss decreased (0.375723 --> 0.370417).  Saving model ...
	 Train_Loss: 0.4414 Train_Acc: 81.762 Val_Loss: 0.3704  BEST VAL Loss: 0.3704  Val_Acc: 85.363

Epoch 6: Validation loss decreased (0.370417 --> 0.366659).  Saving model ...
	 Train_Loss: 0.4362 Train_Acc: 82.253 Val_Loss: 0.3667  BEST VAL Loss: 0.3667  Val_Acc: 85.332

Epoch 7: Validation loss decreased (0.366659 --> 0.365212).  Saving model ...
	 Train_Loss: 0.4321 Train_Acc: 82.189 Val_Loss: 0.3652  BEST VAL Loss: 0.3652  Val_Acc: 85.514

Epoch 8: Validation loss decreased (0.365212 --> 0.361726).  Saving model ...
	 Train_Loss: 0.4285 Train_Acc: 82.420 Val_Loss: 0.3617  BEST VAL Loss: 0.3617  Val_Acc: 86.144

Epoch 9: Validation loss decreased (0.361726 --> 0.361009).  Saving model ...
	 Train_Loss: 0.4257 Train_Acc: 82.510 Val_Loss: 0.3610  BEST VAL Loss: 0.3610  Val_Acc: 85.842

Epoch 10: Validation loss decreased (0.361009 --> 0.358589).  Saving model ...
	 Train_Loss: 0.4234 Train_Acc: 82.586 Val_Loss: 0.3586  BEST VAL Loss: 0.3586  Val_Acc: 85.931

Epoch 11: Validation loss decreased (0.358589 --> 0.357588).  Saving model ...
	 Train_Loss: 0.4212 Train_Acc: 82.833 Val_Loss: 0.3576  BEST VAL Loss: 0.3576  Val_Acc: 86.384

Epoch 12: Validation loss decreased (0.357588 --> 0.356696).  Saving model ...
	 Train_Loss: 0.4191 Train_Acc: 82.960 Val_Loss: 0.3567  BEST VAL Loss: 0.3567  Val_Acc: 86.562

Epoch 13: Validation loss decreased (0.356696 --> 0.354326).  Saving model ...
	 Train_Loss: 0.4174 Train_Acc: 82.856 Val_Loss: 0.3543  BEST VAL Loss: 0.3543  Val_Acc: 86.344

Epoch 14: Validation loss decreased (0.354326 --> 0.352624).  Saving model ...
	 Train_Loss: 0.4159 Train_Acc: 82.869 Val_Loss: 0.3526  BEST VAL Loss: 0.3526  Val_Acc: 85.922

Epoch 15: Validation loss decreased (0.352624 --> 0.350644).  Saving model ...
	 Train_Loss: 0.4146 Train_Acc: 82.894 Val_Loss: 0.3506  BEST VAL Loss: 0.3506  Val_Acc: 86.393

Epoch 16: Validation loss decreased (0.350644 --> 0.349045).  Saving model ...
	 Train_Loss: 0.4134 Train_Acc: 82.852 Val_Loss: 0.3490  BEST VAL Loss: 0.3490  Val_Acc: 86.153

Epoch 17: Validation loss decreased (0.349045 --> 0.348148).  Saving model ...
	 Train_Loss: 0.4124 Train_Acc: 82.937 Val_Loss: 0.3481  BEST VAL Loss: 0.3481  Val_Acc: 86.415

Epoch 18: Validation loss decreased (0.348148 --> 0.347238).  Saving model ...
	 Train_Loss: 0.4113 Train_Acc: 83.051 Val_Loss: 0.3472  BEST VAL Loss: 0.3472  Val_Acc: 85.980

Epoch 19: Validation loss decreased (0.347238 --> 0.346490).  Saving model ...
	 Train_Loss: 0.4103 Train_Acc: 83.099 Val_Loss: 0.3465  BEST VAL Loss: 0.3465  Val_Acc: 86.331

Epoch 20: Validation loss decreased (0.346490 --> 0.345272).  Saving model ...
	 Train_Loss: 0.4095 Train_Acc: 83.132 Val_Loss: 0.3453  BEST VAL Loss: 0.3453  Val_Acc: 86.473

Epoch 21: Validation loss decreased (0.345272 --> 0.344451).  Saving model ...
	 Train_Loss: 0.4085 Train_Acc: 83.277 Val_Loss: 0.3445  BEST VAL Loss: 0.3445  Val_Acc: 86.668

Epoch 22: Validation loss decreased (0.344451 --> 0.343245).  Saving model ...
	 Train_Loss: 0.4074 Train_Acc: 83.345 Val_Loss: 0.3432  BEST VAL Loss: 0.3432  Val_Acc: 86.438

Epoch 23: Validation loss decreased (0.343245 --> 0.342588).  Saving model ...
	 Train_Loss: 0.4065 Train_Acc: 83.366 Val_Loss: 0.3426  BEST VAL Loss: 0.3426  Val_Acc: 86.424

Epoch 24: Validation loss decreased (0.342588 --> 0.341585).  Saving model ...
	 Train_Loss: 0.4056 Train_Acc: 83.470 Val_Loss: 0.3416  BEST VAL Loss: 0.3416  Val_Acc: 86.611

Epoch 25: Validation loss decreased (0.341585 --> 0.341179).  Saving model ...
	 Train_Loss: 0.4049 Train_Acc: 83.284 Val_Loss: 0.3412  BEST VAL Loss: 0.3412  Val_Acc: 86.611

Epoch 26: Validation loss decreased (0.341179 --> 0.340636).  Saving model ...
	 Train_Loss: 0.4042 Train_Acc: 83.353 Val_Loss: 0.3406  BEST VAL Loss: 0.3406  Val_Acc: 86.513

Epoch 27: Validation loss decreased (0.340636 --> 0.340046).  Saving model ...
	 Train_Loss: 0.4035 Train_Acc: 83.400 Val_Loss: 0.3400  BEST VAL Loss: 0.3400  Val_Acc: 86.526

Epoch 28: Validation loss decreased (0.340046 --> 0.339577).  Saving model ...
	 Train_Loss: 0.4029 Train_Acc: 83.381 Val_Loss: 0.3396  BEST VAL Loss: 0.3396  Val_Acc: 86.673

Epoch 29: Validation loss decreased (0.339577 --> 0.339262).  Saving model ...
	 Train_Loss: 0.4022 Train_Acc: 83.592 Val_Loss: 0.3393  BEST VAL Loss: 0.3393  Val_Acc: 86.633

Epoch 30: Validation loss decreased (0.339262 --> 0.338614).  Saving model ...
	 Train_Loss: 0.4016 Train_Acc: 83.473 Val_Loss: 0.3386  BEST VAL Loss: 0.3386  Val_Acc: 86.828

Epoch 31: Validation loss decreased (0.338614 --> 0.338060).  Saving model ...
	 Train_Loss: 0.4010 Train_Acc: 83.511 Val_Loss: 0.3381  BEST VAL Loss: 0.3381  Val_Acc: 86.495

Epoch 32: Validation loss decreased (0.338060 --> 0.337179).  Saving model ...
	 Train_Loss: 0.4004 Train_Acc: 83.555 Val_Loss: 0.3372  BEST VAL Loss: 0.3372  Val_Acc: 87.024

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.3999 Train_Acc: 83.584 Val_Loss: 0.3372  BEST VAL Loss: 0.3372  Val_Acc: 86.908

Epoch 34: Validation loss decreased (0.337179 --> 0.336985).  Saving model ...
	 Train_Loss: 0.3994 Train_Acc: 83.729 Val_Loss: 0.3370  BEST VAL Loss: 0.3370  Val_Acc: 86.788

Epoch 35: Validation loss decreased (0.336985 --> 0.336929).  Saving model ...
	 Train_Loss: 0.3989 Train_Acc: 83.744 Val_Loss: 0.3369  BEST VAL Loss: 0.3369  Val_Acc: 86.673

Epoch 36: Validation loss decreased (0.336929 --> 0.336333).  Saving model ...
	 Train_Loss: 0.3984 Train_Acc: 83.635 Val_Loss: 0.3363  BEST VAL Loss: 0.3363  Val_Acc: 86.708

Epoch 37: Validation loss decreased (0.336333 --> 0.335817).  Saving model ...
	 Train_Loss: 0.3979 Train_Acc: 83.612 Val_Loss: 0.3358  BEST VAL Loss: 0.3358  Val_Acc: 86.828

Epoch 38: Validation loss decreased (0.335817 --> 0.335740).  Saving model ...
	 Train_Loss: 0.3976 Train_Acc: 83.557 Val_Loss: 0.3357  BEST VAL Loss: 0.3357  Val_Acc: 86.744

Epoch 39: Validation loss decreased (0.335740 --> 0.335422).  Saving model ...
	 Train_Loss: 0.3971 Train_Acc: 83.686 Val_Loss: 0.3354  BEST VAL Loss: 0.3354  Val_Acc: 87.179

Epoch 40: Validation loss decreased (0.335422 --> 0.334873).  Saving model ...
	 Train_Loss: 0.3967 Train_Acc: 83.692 Val_Loss: 0.3349  BEST VAL Loss: 0.3349  Val_Acc: 87.286

Epoch 41: Validation loss decreased (0.334873 --> 0.334262).  Saving model ...
	 Train_Loss: 0.3963 Train_Acc: 83.809 Val_Loss: 0.3343  BEST VAL Loss: 0.3343  Val_Acc: 86.806

Epoch 42: Validation loss decreased (0.334262 --> 0.334235).  Saving model ...
	 Train_Loss: 0.3959 Train_Acc: 83.566 Val_Loss: 0.3342  BEST VAL Loss: 0.3342  Val_Acc: 86.970

Epoch 43: Validation loss decreased (0.334235 --> 0.333788).  Saving model ...
	 Train_Loss: 0.3955 Train_Acc: 83.811 Val_Loss: 0.3338  BEST VAL Loss: 0.3338  Val_Acc: 86.926

Epoch 44: Validation loss decreased (0.333788 --> 0.333398).  Saving model ...
	 Train_Loss: 0.3952 Train_Acc: 83.877 Val_Loss: 0.3334  BEST VAL Loss: 0.3334  Val_Acc: 87.264

Epoch 45: Validation loss decreased (0.333398 --> 0.333075).  Saving model ...
	 Train_Loss: 0.3948 Train_Acc: 83.831 Val_Loss: 0.3331  BEST VAL Loss: 0.3331  Val_Acc: 87.108

Epoch 46: Validation loss decreased (0.333075 --> 0.332802).  Saving model ...
	 Train_Loss: 0.3944 Train_Acc: 83.789 Val_Loss: 0.3328  BEST VAL Loss: 0.3328  Val_Acc: 86.997

Epoch 47: Validation loss decreased (0.332802 --> 0.332485).  Saving model ...
	 Train_Loss: 0.3941 Train_Acc: 83.973 Val_Loss: 0.3325  BEST VAL Loss: 0.3325  Val_Acc: 87.130

Epoch 48: Validation loss decreased (0.332485 --> 0.332112).  Saving model ...
	 Train_Loss: 0.3938 Train_Acc: 83.789 Val_Loss: 0.3321  BEST VAL Loss: 0.3321  Val_Acc: 87.135

Epoch 49: Validation loss decreased (0.332112 --> 0.331733).  Saving model ...
	 Train_Loss: 0.3935 Train_Acc: 83.859 Val_Loss: 0.3317  BEST VAL Loss: 0.3317  Val_Acc: 87.281

Epoch 50: Validation loss decreased (0.331733 --> 0.331386).  Saving model ...
	 Train_Loss: 0.3931 Train_Acc: 83.899 Val_Loss: 0.3314  BEST VAL Loss: 0.3314  Val_Acc: 87.033

Epoch 51: Validation loss decreased (0.331386 --> 0.331115).  Saving model ...
	 Train_Loss: 0.3928 Train_Acc: 83.888 Val_Loss: 0.3311  BEST VAL Loss: 0.3311  Val_Acc: 87.153

Epoch 52: Validation loss decreased (0.331115 --> 0.330681).  Saving model ...
	 Train_Loss: 0.3926 Train_Acc: 83.816 Val_Loss: 0.3307  BEST VAL Loss: 0.3307  Val_Acc: 86.793

Epoch 53: Validation loss decreased (0.330681 --> 0.330422).  Saving model ...
	 Train_Loss: 0.3923 Train_Acc: 83.963 Val_Loss: 0.3304  BEST VAL Loss: 0.3304  Val_Acc: 87.010

Epoch 54: Validation loss decreased (0.330422 --> 0.329990).  Saving model ...
	 Train_Loss: 0.3920 Train_Acc: 83.845 Val_Loss: 0.3300  BEST VAL Loss: 0.3300  Val_Acc: 87.321

Epoch 55: Validation loss decreased (0.329990 --> 0.329577).  Saving model ...
	 Train_Loss: 0.3918 Train_Acc: 83.847 Val_Loss: 0.3296  BEST VAL Loss: 0.3296  Val_Acc: 87.330

Epoch 56: Validation loss decreased (0.329577 --> 0.329502).  Saving model ...
	 Train_Loss: 0.3915 Train_Acc: 83.886 Val_Loss: 0.3295  BEST VAL Loss: 0.3295  Val_Acc: 86.944

Epoch 57: Validation loss decreased (0.329502 --> 0.329463).  Saving model ...
	 Train_Loss: 0.3913 Train_Acc: 83.931 Val_Loss: 0.3295  BEST VAL Loss: 0.3295  Val_Acc: 86.975

Epoch 58: Validation loss decreased (0.329463 --> 0.329164).  Saving model ...
	 Train_Loss: 0.3911 Train_Acc: 83.819 Val_Loss: 0.3292  BEST VAL Loss: 0.3292  Val_Acc: 87.104

Epoch 59: Validation loss decreased (0.329164 --> 0.329144).  Saving model ...
	 Train_Loss: 0.3908 Train_Acc: 84.064 Val_Loss: 0.3291  BEST VAL Loss: 0.3291  Val_Acc: 87.246

Epoch 60: Validation loss decreased (0.329144 --> 0.329088).  Saving model ...
	 Train_Loss: 0.3906 Train_Acc: 84.045 Val_Loss: 0.3291  BEST VAL Loss: 0.3291  Val_Acc: 87.037

Epoch 61: Validation loss decreased (0.329088 --> 0.328909).  Saving model ...
	 Train_Loss: 0.3904 Train_Acc: 83.861 Val_Loss: 0.3289  BEST VAL Loss: 0.3289  Val_Acc: 87.321

Epoch 62: Validation loss decreased (0.328909 --> 0.328594).  Saving model ...
	 Train_Loss: 0.3901 Train_Acc: 83.927 Val_Loss: 0.3286  BEST VAL Loss: 0.3286  Val_Acc: 87.272

Epoch 63: Validation loss decreased (0.328594 --> 0.328283).  Saving model ...
	 Train_Loss: 0.3899 Train_Acc: 83.823 Val_Loss: 0.3283  BEST VAL Loss: 0.3283  Val_Acc: 87.406

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.3897 Train_Acc: 84.019 Val_Loss: 0.3287  BEST VAL Loss: 0.3283  Val_Acc: 87.148

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.3895 Train_Acc: 84.018 Val_Loss: 0.3284  BEST VAL Loss: 0.3283  Val_Acc: 87.601

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.3893 Train_Acc: 84.006 Val_Loss: 0.3283  BEST VAL Loss: 0.3283  Val_Acc: 86.926

Epoch 67: Validation loss decreased (0.328283 --> 0.328046).  Saving model ...
	 Train_Loss: 0.3891 Train_Acc: 83.987 Val_Loss: 0.3280  BEST VAL Loss: 0.3280  Val_Acc: 87.388

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.3889 Train_Acc: 83.971 Val_Loss: 0.3281  BEST VAL Loss: 0.3280  Val_Acc: 87.073

Epoch 69: Validation loss decreased (0.328046 --> 0.327855).  Saving model ...
	 Train_Loss: 0.3887 Train_Acc: 83.836 Val_Loss: 0.3279  BEST VAL Loss: 0.3279  Val_Acc: 87.450

Epoch 70: Validation loss decreased (0.327855 --> 0.327741).  Saving model ...
	 Train_Loss: 0.3885 Train_Acc: 84.089 Val_Loss: 0.3277  BEST VAL Loss: 0.3277  Val_Acc: 87.308

Epoch 71: Validation loss decreased (0.327741 --> 0.327500).  Saving model ...
	 Train_Loss: 0.3883 Train_Acc: 84.029 Val_Loss: 0.3275  BEST VAL Loss: 0.3275  Val_Acc: 87.326

Epoch 72: Validation loss decreased (0.327500 --> 0.327460).  Saving model ...
	 Train_Loss: 0.3882 Train_Acc: 83.826 Val_Loss: 0.3275  BEST VAL Loss: 0.3275  Val_Acc: 87.290

Epoch 73: Validation loss decreased (0.327460 --> 0.327249).  Saving model ...
	 Train_Loss: 0.3880 Train_Acc: 84.081 Val_Loss: 0.3272  BEST VAL Loss: 0.3272  Val_Acc: 87.281

Epoch 74: Validation loss decreased (0.327249 --> 0.327027).  Saving model ...
	 Train_Loss: 0.3879 Train_Acc: 83.821 Val_Loss: 0.3270  BEST VAL Loss: 0.3270  Val_Acc: 87.321

Epoch 75: Validation loss decreased (0.327027 --> 0.326933).  Saving model ...
	 Train_Loss: 0.3877 Train_Acc: 84.044 Val_Loss: 0.3269  BEST VAL Loss: 0.3269  Val_Acc: 86.935

Epoch 76: Validation loss decreased (0.326933 --> 0.326910).  Saving model ...
	 Train_Loss: 0.3875 Train_Acc: 84.100 Val_Loss: 0.3269  BEST VAL Loss: 0.3269  Val_Acc: 87.130

Epoch 77: Validation loss decreased (0.326910 --> 0.326746).  Saving model ...
	 Train_Loss: 0.3873 Train_Acc: 84.140 Val_Loss: 0.3267  BEST VAL Loss: 0.3267  Val_Acc: 87.117

Epoch 78: Validation loss decreased (0.326746 --> 0.326469).  Saving model ...
	 Train_Loss: 0.3871 Train_Acc: 84.121 Val_Loss: 0.3265  BEST VAL Loss: 0.3265  Val_Acc: 87.415

Epoch 79: Validation loss decreased (0.326469 --> 0.326296).  Saving model ...
	 Train_Loss: 0.3870 Train_Acc: 84.013 Val_Loss: 0.3263  BEST VAL Loss: 0.3263  Val_Acc: 87.388

Epoch 80: Validation loss decreased (0.326296 --> 0.326095).  Saving model ...
	 Train_Loss: 0.3868 Train_Acc: 84.100 Val_Loss: 0.3261  BEST VAL Loss: 0.3261  Val_Acc: 87.415

Epoch 81: Validation loss decreased (0.326095 --> 0.325829).  Saving model ...
	 Train_Loss: 0.3866 Train_Acc: 84.030 Val_Loss: 0.3258  BEST VAL Loss: 0.3258  Val_Acc: 87.406

Epoch 82: Validation loss decreased (0.325829 --> 0.325534).  Saving model ...
	 Train_Loss: 0.3864 Train_Acc: 84.123 Val_Loss: 0.3255  BEST VAL Loss: 0.3255  Val_Acc: 87.410

Epoch 83: Validation loss decreased (0.325534 --> 0.325419).  Saving model ...
	 Train_Loss: 0.3863 Train_Acc: 84.209 Val_Loss: 0.3254  BEST VAL Loss: 0.3254  Val_Acc: 87.312

Epoch 84: Validation loss decreased (0.325419 --> 0.325401).  Saving model ...
	 Train_Loss: 0.3861 Train_Acc: 84.131 Val_Loss: 0.3254  BEST VAL Loss: 0.3254  Val_Acc: 87.246

Epoch 85: Validation loss decreased (0.325401 --> 0.325201).  Saving model ...
	 Train_Loss: 0.3859 Train_Acc: 84.335 Val_Loss: 0.3252  BEST VAL Loss: 0.3252  Val_Acc: 87.317

Epoch 86: Validation loss decreased (0.325201 --> 0.325112).  Saving model ...
	 Train_Loss: 0.3858 Train_Acc: 84.084 Val_Loss: 0.3251  BEST VAL Loss: 0.3251  Val_Acc: 87.041

Epoch 87: Validation loss decreased (0.325112 --> 0.324944).  Saving model ...
	 Train_Loss: 0.3857 Train_Acc: 84.031 Val_Loss: 0.3249  BEST VAL Loss: 0.3249  Val_Acc: 87.454

Epoch 88: Validation loss decreased (0.324944 --> 0.324805).  Saving model ...
	 Train_Loss: 0.3856 Train_Acc: 84.018 Val_Loss: 0.3248  BEST VAL Loss: 0.3248  Val_Acc: 87.450

Epoch 89: Validation loss decreased (0.324805 --> 0.324531).  Saving model ...
	 Train_Loss: 0.3854 Train_Acc: 84.166 Val_Loss: 0.3245  BEST VAL Loss: 0.3245  Val_Acc: 87.654

Epoch 90: Validation loss decreased (0.324531 --> 0.324359).  Saving model ...
	 Train_Loss: 0.3853 Train_Acc: 84.147 Val_Loss: 0.3244  BEST VAL Loss: 0.3244  Val_Acc: 87.770

Epoch 91: Validation loss decreased (0.324359 --> 0.324241).  Saving model ...
	 Train_Loss: 0.3852 Train_Acc: 84.049 Val_Loss: 0.3242  BEST VAL Loss: 0.3242  Val_Acc: 87.357

Epoch 92: Validation loss decreased (0.324241 --> 0.324062).  Saving model ...
	 Train_Loss: 0.3850 Train_Acc: 84.175 Val_Loss: 0.3241  BEST VAL Loss: 0.3241  Val_Acc: 87.157

Epoch 93: Validation loss decreased (0.324062 --> 0.323981).  Saving model ...
	 Train_Loss: 0.3849 Train_Acc: 84.155 Val_Loss: 0.3240  BEST VAL Loss: 0.3240  Val_Acc: 87.348

Epoch 94: Validation loss decreased (0.323981 --> 0.323869).  Saving model ...
	 Train_Loss: 0.3848 Train_Acc: 83.910 Val_Loss: 0.3239  BEST VAL Loss: 0.3239  Val_Acc: 87.312

Epoch 95: Validation loss decreased (0.323869 --> 0.323641).  Saving model ...
	 Train_Loss: 0.3847 Train_Acc: 84.286 Val_Loss: 0.3236  BEST VAL Loss: 0.3236  Val_Acc: 87.503

Epoch 96: Validation loss decreased (0.323641 --> 0.323586).  Saving model ...
	 Train_Loss: 0.3845 Train_Acc: 84.275 Val_Loss: 0.3236  BEST VAL Loss: 0.3236  Val_Acc: 87.428

Epoch 97: Validation loss decreased (0.323586 --> 0.323432).  Saving model ...
	 Train_Loss: 0.3844 Train_Acc: 84.224 Val_Loss: 0.3234  BEST VAL Loss: 0.3234  Val_Acc: 87.343

Epoch 98: Validation loss decreased (0.323432 --> 0.323254).  Saving model ...
	 Train_Loss: 0.3843 Train_Acc: 84.237 Val_Loss: 0.3233  BEST VAL Loss: 0.3233  Val_Acc: 87.481

Epoch 99: Validation loss decreased (0.323254 --> 0.323126).  Saving model ...
	 Train_Loss: 0.3841 Train_Acc: 84.203 Val_Loss: 0.3231  BEST VAL Loss: 0.3231  Val_Acc: 87.441

LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.44      0.44      0.44     79796
           1       0.56      0.57      0.56    100340

    accuracy                           0.51    180136
   macro avg       0.50      0.50      0.50    180136
weighted avg       0.51      0.51      0.51    180136

LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.44      0.44      0.44      9975
           1       0.56      0.56      0.56     12543

    accuracy                           0.51     22518
   macro avg       0.50      0.50      0.50     22518
weighted avg       0.51      0.51      0.51     22518

LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.45      0.44      0.45      9975
           1       0.56      0.56      0.56     12542

    accuracy                           0.51     22517
   macro avg       0.50      0.50      0.50     22517
weighted avg       0.51      0.51      0.51     22517

              precision    recall  f1-score   support

           0       0.45      0.44      0.45      9975
           1       0.56      0.56      0.56     12542

    accuracy                           0.51     22517
   macro avg       0.50      0.50      0.50     22517
weighted avg       0.51      0.51      0.51     22517

LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.55      0.52     39687
           1       0.51      0.45      0.48     40588

    accuracy                           0.50     80275
   macro avg       0.50      0.50      0.50     80275
weighted avg       0.50      0.50      0.50     80275

              precision    recall  f1-score   support

           0       0.50      0.55      0.52     39687
           1       0.51      0.45      0.48     40588

    accuracy                           0.50     80275
   macro avg       0.50      0.50      0.50     80275
weighted avg       0.50      0.50      0.50     80275

completed
