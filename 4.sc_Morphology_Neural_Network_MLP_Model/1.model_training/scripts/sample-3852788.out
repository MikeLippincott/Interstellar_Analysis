[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 18688 bytes to train_binary_model.py
[NbConvertApp] Converting notebook ../notebooks/train_multiclass_model.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/nbformat/__init__.py:93: MissingIDFieldWarning: Code cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.
  validate(nb)
[NbConvertApp] Writing 40895 bytes to train_multiclass_model.py
[NbConvertApp] Converting notebook ../notebooks/train_regression_model.ipynb to script
[NbConvertApp] Writing 25120 bytes to train_regression_model.py
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:254: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_descriptive["labels"] = df1["labels"]
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:281: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels.drop_duplicates(inplace=True)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1015: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1016: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1015: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1016: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:571: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:585: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  model_stats_df = pd.concat([model_stats_df, stats_df], axis=0)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:645: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:854: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  confusion_matrix_df["apoptosis"] = confusion_matrix_df["apoptosis"] / sum_of_columns[0]
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:856: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  confusion_matrix_df["healthy"] = confusion_matrix_df["healthy"] / sum_of_columns[1]
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:859: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  confusion_matrix_df["pyroptosis"] / sum_of_columns[2]
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:890: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_split_conf_mat_df_all = pd.concat(
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:932: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1133: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless
  warnings.warn(
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1133: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless
  warnings.warn(
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:1131: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  confusion_matrix_df["apoptosis"] = confusion_matrix_df["apoptosis"] / sum_of_columns[0]
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:1133: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  confusion_matrix_df["healthy"] = confusion_matrix_df["healthy"] / sum_of_columns[1]
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:1136: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  confusion_matrix_df["pyroptosis"] / sum_of_columns[2]
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:1213: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:1400: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  confusion_matrix_df["apoptosis"] = confusion_matrix_df["apoptosis"] / sum_of_columns[0]
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:1402: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  confusion_matrix_df["healthy"] = confusion_matrix_df["healthy"] / sum_of_columns[1]
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:1405: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  confusion_matrix_df["pyroptosis"] / sum_of_columns[2]
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:1482: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
SHSY5Y MultiClass_MLP False
[0.954878893196544, 0.4803479499984947, 0.5647731568049614]
Data Subset Is Off
(165097,) (41275,) (218078,) 424450     93196
424451     93197
424452     93198
424453     93199
424454     93200
           ...  
446996    509986
446997    509987
446998    509988
446999    509989
447000    509990
Name: labeled_data_index, Length: 22551, dtype: int64 (150901,)
(165097,) (41275,) (218078,) 424450     93196
424451     93197
424452     93198
424453     93199
424454     93200
           ...  
446996    509986
446997    509987
446998    509988
446999    509989
447000    509990
Name: labeled_data_index, Length: 22551, dtype: int64 (150901,)
597902
(7972,) (93463,) (63662,)
(1993,) (23367,) (15915,)
(9965,) (116830,) (91283,)
(0,) (0,) (22551,)
(7048,) (77041,) (66812,)
(165097, 1251) (41275, 1251) (218078, 1251) (22551, 1251) (150901, 1251)
(165097,) (41275,) (218078,) (22551,) (150901,)
Number of in features:  1251
Number of out features:  3
Multi_Class
SGD
Epoch 0: Validation loss decreased (inf --> 0.657694).  Saving model ...
	 Train_Loss: 0.6737 Train_Acc: 69.047 Val_Loss: 0.6577  BEST VAL Loss: 0.6577  Val_Acc: 66.088

Epoch 1: Validation loss decreased (0.657694 --> 0.631784).  Saving model ...
	 Train_Loss: 0.6488 Train_Acc: 70.954 Val_Loss: 0.6318  BEST VAL Loss: 0.6318  Val_Acc: 70.372

Epoch 2: Validation loss decreased (0.631784 --> 0.627333).  Saving model ...
	 Train_Loss: 0.6330 Train_Acc: 71.692 Val_Loss: 0.6273  BEST VAL Loss: 0.6273  Val_Acc: 69.049

Epoch 3: Validation loss decreased (0.627333 --> 0.618714).  Saving model ...
	 Train_Loss: 0.6221 Train_Acc: 72.400 Val_Loss: 0.6187  BEST VAL Loss: 0.6187  Val_Acc: 70.721

Epoch 4: Validation loss decreased (0.618714 --> 0.611264).  Saving model ...
	 Train_Loss: 0.6130 Train_Acc: 72.877 Val_Loss: 0.6113  BEST VAL Loss: 0.6113  Val_Acc: 71.254

Epoch 5: Validation loss decreased (0.611264 --> 0.609017).  Saving model ...
	 Train_Loss: 0.6052 Train_Acc: 73.268 Val_Loss: 0.6090  BEST VAL Loss: 0.6090  Val_Acc: 69.878

Epoch 6: Validation loss decreased (0.609017 --> 0.604747).  Saving model ...
	 Train_Loss: 0.5986 Train_Acc: 73.648 Val_Loss: 0.6047  BEST VAL Loss: 0.6047  Val_Acc: 72.286

Epoch 7: Validation loss decreased (0.604747 --> 0.602294).  Saving model ...
	 Train_Loss: 0.5925 Train_Acc: 74.106 Val_Loss: 0.6023  BEST VAL Loss: 0.6023  Val_Acc: 70.990

Epoch 8: Validation loss decreased (0.602294 --> 0.600035).  Saving model ...
	 Train_Loss: 0.5869 Train_Acc: 74.381 Val_Loss: 0.6000  BEST VAL Loss: 0.6000  Val_Acc: 71.179

Epoch 9: Validation loss decreased (0.600035 --> 0.597379).  Saving model ...
	 Train_Loss: 0.5818 Train_Acc: 74.648 Val_Loss: 0.5974  BEST VAL Loss: 0.5974  Val_Acc: 73.282

Epoch 10: Validation loss decreased (0.597379 --> 0.594427).  Saving model ...
	 Train_Loss: 0.5772 Train_Acc: 74.885 Val_Loss: 0.5944  BEST VAL Loss: 0.5944  Val_Acc: 73.299

Epoch 11: Validation loss decreased (0.594427 --> 0.592582).  Saving model ...
	 Train_Loss: 0.5732 Train_Acc: 74.997 Val_Loss: 0.5926  BEST VAL Loss: 0.5926  Val_Acc: 72.875

Epoch 12: Validation loss decreased (0.592582 --> 0.590506).  Saving model ...
	 Train_Loss: 0.5694 Train_Acc: 75.236 Val_Loss: 0.5905  BEST VAL Loss: 0.5905  Val_Acc: 73.076

Epoch 13: Validation loss decreased (0.590506 --> 0.588495).  Saving model ...
	 Train_Loss: 0.5658 Train_Acc: 75.247 Val_Loss: 0.5885  BEST VAL Loss: 0.5885  Val_Acc: 73.698

Epoch 14: Validation loss decreased (0.588495 --> 0.587198).  Saving model ...
	 Train_Loss: 0.5623 Train_Acc: 75.678 Val_Loss: 0.5872  BEST VAL Loss: 0.5872  Val_Acc: 73.369

Epoch 15: Validation loss decreased (0.587198 --> 0.586317).  Saving model ...
	 Train_Loss: 0.5592 Train_Acc: 75.616 Val_Loss: 0.5863  BEST VAL Loss: 0.5863  Val_Acc: 73.345

Epoch 16: Validation loss decreased (0.586317 --> 0.585182).  Saving model ...
	 Train_Loss: 0.5561 Train_Acc: 75.894 Val_Loss: 0.5852  BEST VAL Loss: 0.5852  Val_Acc: 73.543

Epoch 17: Validation loss decreased (0.585182 --> 0.584768).  Saving model ...
	 Train_Loss: 0.5532 Train_Acc: 76.193 Val_Loss: 0.5848  BEST VAL Loss: 0.5848  Val_Acc: 73.003

Epoch 18: Validation loss decreased (0.584768 --> 0.583940).  Saving model ...
	 Train_Loss: 0.5504 Train_Acc: 76.214 Val_Loss: 0.5839  BEST VAL Loss: 0.5839  Val_Acc: 73.543

Epoch 19: Validation loss decreased (0.583940 --> 0.583444).  Saving model ...
	 Train_Loss: 0.5477 Train_Acc: 76.371 Val_Loss: 0.5834  BEST VAL Loss: 0.5834  Val_Acc: 73.335

Epoch 20: Validation loss decreased (0.583444 --> 0.582978).  Saving model ...
	 Train_Loss: 0.5453 Train_Acc: 76.346 Val_Loss: 0.5830  BEST VAL Loss: 0.5830  Val_Acc: 73.267

Epoch 21: Validation loss did not decrease
	 Train_Loss: 0.5429 Train_Acc: 76.522 Val_Loss: 0.5831  BEST VAL Loss: 0.5830  Val_Acc: 72.925

Epoch 22: Validation loss decreased (0.582978 --> 0.582847).  Saving model ...
	 Train_Loss: 0.5406 Train_Acc: 76.735 Val_Loss: 0.5828  BEST VAL Loss: 0.5828  Val_Acc: 74.040

Epoch 23: Validation loss decreased (0.582847 --> 0.582463).  Saving model ...
	 Train_Loss: 0.5383 Train_Acc: 76.933 Val_Loss: 0.5825  BEST VAL Loss: 0.5825  Val_Acc: 74.512

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.5362 Train_Acc: 76.950 Val_Loss: 0.5826  BEST VAL Loss: 0.5825  Val_Acc: 73.880

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.5341 Train_Acc: 77.016 Val_Loss: 0.5825  BEST VAL Loss: 0.5825  Val_Acc: 74.047

Epoch 26: Validation loss did not decrease
	 Train_Loss: 0.5321 Train_Acc: 77.193 Val_Loss: 0.5826  BEST VAL Loss: 0.5825  Val_Acc: 74.105

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.5303 Train_Acc: 77.107 Val_Loss: 0.5828  BEST VAL Loss: 0.5825  Val_Acc: 74.491

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.5285 Train_Acc: 77.219 Val_Loss: 0.5826  BEST VAL Loss: 0.5825  Val_Acc: 73.623

Epoch 29: Validation loss did not decrease
	 Train_Loss: 0.5267 Train_Acc: 77.408 Val_Loss: 0.5827  BEST VAL Loss: 0.5825  Val_Acc: 73.856

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.5250 Train_Acc: 77.430 Val_Loss: 0.5828  BEST VAL Loss: 0.5825  Val_Acc: 74.006

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.5234 Train_Acc: 77.620 Val_Loss: 0.5827  BEST VAL Loss: 0.5825  Val_Acc: 73.543

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.5216 Train_Acc: 77.734 Val_Loss: 0.5827  BEST VAL Loss: 0.5825  Val_Acc: 74.171

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.5201 Train_Acc: 77.630 Val_Loss: 0.5825  BEST VAL Loss: 0.5825  Val_Acc: 74.287

Epoch 34: Validation loss did not decrease
	 Train_Loss: 0.5186 Train_Acc: 77.807 Val_Loss: 0.5825  BEST VAL Loss: 0.5825  Val_Acc: 73.933

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.5171 Train_Acc: 77.839 Val_Loss: 0.5825  BEST VAL Loss: 0.5825  Val_Acc: 74.508

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.5157 Train_Acc: 77.937 Val_Loss: 0.5826  BEST VAL Loss: 0.5825  Val_Acc: 74.527

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.5142 Train_Acc: 78.021 Val_Loss: 0.5829  BEST VAL Loss: 0.5825  Val_Acc: 73.953

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.5129 Train_Acc: 78.044 Val_Loss: 0.5830  BEST VAL Loss: 0.5825  Val_Acc: 74.442

Epoch 39: Validation loss did not decrease
Early stopped at epoch : 39
MultiClass_MLP
              precision    recall  f1-score   support

           0       0.91      0.87      0.89      7972
           1       0.80      0.83      0.82     93463
           2       0.74      0.71      0.73     63662

    accuracy                           0.79    165097
   macro avg       0.82      0.80      0.81    165097
weighted avg       0.79      0.79      0.79    165097

MultiClass_MLP
              precision    recall  f1-score   support

           0       0.81      0.73      0.77      1993
           1       0.77      0.80      0.78     23367
           2       0.70      0.67      0.68     15915

    accuracy                           0.75     41275
   macro avg       0.76      0.73      0.74     41275
weighted avg       0.74      0.75      0.74     41275

MultiClass_MLP
              precision    recall  f1-score   support

           0       0.80      0.73      0.76      9965
           1       0.74      0.80      0.77    116830
           2       0.72      0.65      0.68     91283

    accuracy                           0.73    218078
   macro avg       0.75      0.73      0.74    218078
weighted avg       0.73      0.73      0.73    218078

Precision for class 0: 0.7992073976221928
Recall for class 0: 0.728549924736578
Precision for class 1: 0.7363668625054217
Recall for class 1: 0.7992382093640332
Precision for class 2: 0.7198773558505397
Recall for class 2: 0.6481601174369817
3
              precision    recall  f1-score   support

           0       0.80      0.73      0.76      9965
           1       0.74      0.80      0.77    116830
           2       0.72      0.65      0.68     91283

    accuracy                           0.73    218078
   macro avg       0.75      0.73      0.74    218078
weighted avg       0.73      0.73      0.73    218078

MultiClass_MLP
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       0.00      0.00      0.00         0
           2       1.00      0.62      0.77     22551

    accuracy                           0.62     22551
   macro avg       0.33      0.21      0.26     22551
weighted avg       1.00      0.62      0.77     22551

Precision for class 0: 0.0
Recall for class 0: 0.0
Precision for class 1: 0.0
Recall for class 1: 0.0
Precision for class 2: 1.0
Recall for class 2: 0.6232096137643564
3
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       0.00      0.00      0.00         0
           2       1.00      0.62      0.77     22551

    accuracy                           0.62     22551
   macro avg       0.33      0.21      0.26     22551
weighted avg       1.00      0.62      0.77     22551

MultiClass_MLP
              precision    recall  f1-score   support

           0       0.83      0.71      0.76      7048
           1       0.73      0.79      0.76     77041
           2       0.74      0.68      0.70     66812

    accuracy                           0.74    150901
   macro avg       0.76      0.73      0.74    150901
weighted avg       0.74      0.74      0.73    150901

Precision for class 0: 0.8261299901022765
Recall for class 0: 0.7105561861520999
Precision for class 1: 0.7268608182100758
Recall for class 1: 0.7891771913656365
Precision for class 2: 0.7373392381481542
Recall for class 2: 0.6753277854277675
3
              precision    recall  f1-score   support

           0       0.83      0.71      0.76      7048
           1       0.73      0.79      0.76     77041
           2       0.74      0.68      0.70     66812

    accuracy                           0.74    150901
   macro avg       0.76      0.73      0.74    150901
weighted avg       0.74      0.74      0.73    150901

Done
