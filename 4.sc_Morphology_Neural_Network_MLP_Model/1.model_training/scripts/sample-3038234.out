[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '15e5764b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'a3e58b3c'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'e6ad19f4'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '6ea914de'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 treatment_name: LPS_10.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
TREATMENT_NAME: LPS_10.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (31212, 1276)
Number of total missing values across all columns: 33620
Data Subset Is Off
Wells held out for testing: ['E20' 'M16']
Wells to use for training, validation, and testing ['E16' 'E17' 'E21' 'M17' 'M20' 'M21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.447295).  Saving model ...
	 Train_Loss: 0.5731 Train_Acc: 69.412 Val_Loss: 0.4473  BEST VAL Loss: 0.4473  Val_Acc: 84.649

Epoch 1: Validation loss decreased (0.447295 --> 0.398315).  Saving model ...
	 Train_Loss: 0.5216 Train_Acc: 75.089 Val_Loss: 0.3983  BEST VAL Loss: 0.3983  Val_Acc: 84.217

Epoch 2: Validation loss decreased (0.398315 --> 0.363896).  Saving model ...
	 Train_Loss: 0.4892 Train_Acc: 77.709 Val_Loss: 0.3639  BEST VAL Loss: 0.3639  Val_Acc: 87.624

Epoch 3: Validation loss decreased (0.363896 --> 0.340708).  Saving model ...
	 Train_Loss: 0.4663 Train_Acc: 79.089 Val_Loss: 0.3407  BEST VAL Loss: 0.3407  Val_Acc: 89.263

Epoch 4: Validation loss decreased (0.340708 --> 0.327264).  Saving model ...
	 Train_Loss: 0.4484 Train_Acc: 80.394 Val_Loss: 0.3273  BEST VAL Loss: 0.3273  Val_Acc: 89.435

Epoch 5: Validation loss decreased (0.327264 --> 0.316223).  Saving model ...
	 Train_Loss: 0.4348 Train_Acc: 81.806 Val_Loss: 0.3162  BEST VAL Loss: 0.3162  Val_Acc: 89.996

Epoch 6: Validation loss decreased (0.316223 --> 0.304550).  Saving model ...
	 Train_Loss: 0.4239 Train_Acc: 81.779 Val_Loss: 0.3045  BEST VAL Loss: 0.3045  Val_Acc: 91.117

Epoch 7: Validation loss decreased (0.304550 --> 0.294021).  Saving model ...
	 Train_Loss: 0.4139 Train_Acc: 82.733 Val_Loss: 0.2940  BEST VAL Loss: 0.2940  Val_Acc: 91.764

Epoch 8: Validation loss decreased (0.294021 --> 0.285036).  Saving model ...
	 Train_Loss: 0.4059 Train_Acc: 83.267 Val_Loss: 0.2850  BEST VAL Loss: 0.2850  Val_Acc: 91.979

Epoch 9: Validation loss decreased (0.285036 --> 0.278696).  Saving model ...
	 Train_Loss: 0.3988 Train_Acc: 83.817 Val_Loss: 0.2787  BEST VAL Loss: 0.2787  Val_Acc: 92.195

Epoch 10: Validation loss decreased (0.278696 --> 0.273430).  Saving model ...
	 Train_Loss: 0.3931 Train_Acc: 83.137 Val_Loss: 0.2734  BEST VAL Loss: 0.2734  Val_Acc: 92.324

Epoch 11: Validation loss decreased (0.273430 --> 0.268431).  Saving model ...
	 Train_Loss: 0.3881 Train_Acc: 84.846 Val_Loss: 0.2684  BEST VAL Loss: 0.2684  Val_Acc: 92.324

Epoch 12: Validation loss decreased (0.268431 --> 0.263750).  Saving model ...
	 Train_Loss: 0.3835 Train_Acc: 84.323 Val_Loss: 0.2637  BEST VAL Loss: 0.2637  Val_Acc: 92.755

Epoch 13: Validation loss decreased (0.263750 --> 0.260170).  Saving model ...
	 Train_Loss: 0.3788 Train_Acc: 85.962 Val_Loss: 0.2602  BEST VAL Loss: 0.2602  Val_Acc: 92.583

Epoch 14: Validation loss decreased (0.260170 --> 0.257175).  Saving model ...
	 Train_Loss: 0.3745 Train_Acc: 86.027 Val_Loss: 0.2572  BEST VAL Loss: 0.2572  Val_Acc: 92.367

Epoch 15: Validation loss decreased (0.257175 --> 0.253301).  Saving model ...
	 Train_Loss: 0.3709 Train_Acc: 86.049 Val_Loss: 0.2533  BEST VAL Loss: 0.2533  Val_Acc: 93.100

Epoch 16: Validation loss decreased (0.253301 --> 0.250249).  Saving model ...
	 Train_Loss: 0.3677 Train_Acc: 85.919 Val_Loss: 0.2502  BEST VAL Loss: 0.2502  Val_Acc: 93.316

Epoch 17: Validation loss decreased (0.250249 --> 0.247905).  Saving model ...
	 Train_Loss: 0.3650 Train_Acc: 86.092 Val_Loss: 0.2479  BEST VAL Loss: 0.2479  Val_Acc: 93.661

Epoch 18: Validation loss decreased (0.247905 --> 0.245860).  Saving model ...
	 Train_Loss: 0.3620 Train_Acc: 86.566 Val_Loss: 0.2459  BEST VAL Loss: 0.2459  Val_Acc: 93.144

Epoch 19: Validation loss decreased (0.245860 --> 0.243080).  Saving model ...
	 Train_Loss: 0.3594 Train_Acc: 86.410 Val_Loss: 0.2431  BEST VAL Loss: 0.2431  Val_Acc: 93.273

Epoch 20: Validation loss decreased (0.243080 --> 0.241190).  Saving model ...
	 Train_Loss: 0.3568 Train_Acc: 86.933 Val_Loss: 0.2412  BEST VAL Loss: 0.2412  Val_Acc: 93.273

Epoch 21: Validation loss decreased (0.241190 --> 0.239788).  Saving model ...
	 Train_Loss: 0.3546 Train_Acc: 86.674 Val_Loss: 0.2398  BEST VAL Loss: 0.2398  Val_Acc: 93.489

Epoch 22: Validation loss decreased (0.239788 --> 0.237863).  Saving model ...
	 Train_Loss: 0.3526 Train_Acc: 86.960 Val_Loss: 0.2379  BEST VAL Loss: 0.2379  Val_Acc: 93.877

Epoch 23: Validation loss decreased (0.237863 --> 0.236880).  Saving model ...
	 Train_Loss: 0.3505 Train_Acc: 87.148 Val_Loss: 0.2369  BEST VAL Loss: 0.2369  Val_Acc: 94.006

Epoch 24: Validation loss decreased (0.236880 --> 0.235998).  Saving model ...
	 Train_Loss: 0.3487 Train_Acc: 87.003 Val_Loss: 0.2360  BEST VAL Loss: 0.2360  Val_Acc: 94.308

Epoch 25: Validation loss decreased (0.235998 --> 0.234707).  Saving model ...
	 Train_Loss: 0.3470 Train_Acc: 87.019 Val_Loss: 0.2347  BEST VAL Loss: 0.2347  Val_Acc: 94.006

Epoch 26: Validation loss decreased (0.234707 --> 0.233685).  Saving model ...
	 Train_Loss: 0.3452 Train_Acc: 87.164 Val_Loss: 0.2337  BEST VAL Loss: 0.2337  Val_Acc: 94.567

Epoch 27: Validation loss decreased (0.233685 --> 0.231765).  Saving model ...
	 Train_Loss: 0.3435 Train_Acc: 87.256 Val_Loss: 0.2318  BEST VAL Loss: 0.2318  Val_Acc: 94.049

Epoch 28: Validation loss decreased (0.231765 --> 0.229773).  Saving model ...
	 Train_Loss: 0.3418 Train_Acc: 87.580 Val_Loss: 0.2298  BEST VAL Loss: 0.2298  Val_Acc: 94.179

Epoch 29: Validation loss decreased (0.229773 --> 0.228359).  Saving model ...
	 Train_Loss: 0.3403 Train_Acc: 87.418 Val_Loss: 0.2284  BEST VAL Loss: 0.2284  Val_Acc: 94.653

Epoch 30: Validation loss decreased (0.228359 --> 0.227076).  Saving model ...
	 Train_Loss: 0.3389 Train_Acc: 87.509 Val_Loss: 0.2271  BEST VAL Loss: 0.2271  Val_Acc: 94.696

Epoch 31: Validation loss decreased (0.227076 --> 0.225752).  Saving model ...
	 Train_Loss: 0.3375 Train_Acc: 87.747 Val_Loss: 0.2258  BEST VAL Loss: 0.2258  Val_Acc: 94.567

Epoch 32: Validation loss decreased (0.225752 --> 0.224407).  Saving model ...
	 Train_Loss: 0.3360 Train_Acc: 87.844 Val_Loss: 0.2244  BEST VAL Loss: 0.2244  Val_Acc: 94.567

Epoch 33: Validation loss decreased (0.224407 --> 0.223233).  Saving model ...
	 Train_Loss: 0.3346 Train_Acc: 88.027 Val_Loss: 0.2232  BEST VAL Loss: 0.2232  Val_Acc: 94.179

Epoch 34: Validation loss decreased (0.223233 --> 0.222186).  Saving model ...
	 Train_Loss: 0.3335 Train_Acc: 87.736 Val_Loss: 0.2222  BEST VAL Loss: 0.2222  Val_Acc: 95.041

Epoch 35: Validation loss decreased (0.222186 --> 0.221266).  Saving model ...
	 Train_Loss: 0.3324 Train_Acc: 87.520 Val_Loss: 0.2213  BEST VAL Loss: 0.2213  Val_Acc: 95.041

Epoch 36: Validation loss decreased (0.221266 --> 0.220131).  Saving model ...
	 Train_Loss: 0.3313 Train_Acc: 87.995 Val_Loss: 0.2201  BEST VAL Loss: 0.2201  Val_Acc: 94.524

Epoch 37: Validation loss decreased (0.220131 --> 0.219215).  Saving model ...
	 Train_Loss: 0.3302 Train_Acc: 87.962 Val_Loss: 0.2192  BEST VAL Loss: 0.2192  Val_Acc: 94.480

Epoch 38: Validation loss decreased (0.219215 --> 0.218272).  Saving model ...
	 Train_Loss: 0.3291 Train_Acc: 88.119 Val_Loss: 0.2183  BEST VAL Loss: 0.2183  Val_Acc: 95.429

Epoch 39: Validation loss decreased (0.218272 --> 0.217120).  Saving model ...
	 Train_Loss: 0.3280 Train_Acc: 88.226 Val_Loss: 0.2171  BEST VAL Loss: 0.2171  Val_Acc: 94.955

Epoch 40: Validation loss decreased (0.217120 --> 0.216236).  Saving model ...
	 Train_Loss: 0.3270 Train_Acc: 88.059 Val_Loss: 0.2162  BEST VAL Loss: 0.2162  Val_Acc: 94.480

Epoch 41: Validation loss decreased (0.216236 --> 0.215068).  Saving model ...
	 Train_Loss: 0.3260 Train_Acc: 88.183 Val_Loss: 0.2151  BEST VAL Loss: 0.2151  Val_Acc: 94.998

Epoch 42: Validation loss decreased (0.215068 --> 0.213996).  Saving model ...
	 Train_Loss: 0.3251 Train_Acc: 88.302 Val_Loss: 0.2140  BEST VAL Loss: 0.2140  Val_Acc: 95.127

Epoch 43: Validation loss decreased (0.213996 --> 0.213138).  Saving model ...
	 Train_Loss: 0.3243 Train_Acc: 88.054 Val_Loss: 0.2131  BEST VAL Loss: 0.2131  Val_Acc: 95.429

Epoch 44: Validation loss decreased (0.213138 --> 0.212561).  Saving model ...
	 Train_Loss: 0.3233 Train_Acc: 88.620 Val_Loss: 0.2126  BEST VAL Loss: 0.2126  Val_Acc: 95.515

Epoch 45: Validation loss decreased (0.212561 --> 0.211961).  Saving model ...
	 Train_Loss: 0.3225 Train_Acc: 88.291 Val_Loss: 0.2120  BEST VAL Loss: 0.2120  Val_Acc: 95.386

Epoch 46: Validation loss decreased (0.211961 --> 0.211256).  Saving model ...
	 Train_Loss: 0.3218 Train_Acc: 87.968 Val_Loss: 0.2113  BEST VAL Loss: 0.2113  Val_Acc: 95.429

Epoch 47: Validation loss decreased (0.211256 --> 0.210498).  Saving model ...
	 Train_Loss: 0.3209 Train_Acc: 88.518 Val_Loss: 0.2105  BEST VAL Loss: 0.2105  Val_Acc: 95.213

Epoch 48: Validation loss decreased (0.210498 --> 0.209955).  Saving model ...
	 Train_Loss: 0.3202 Train_Acc: 88.243 Val_Loss: 0.2100  BEST VAL Loss: 0.2100  Val_Acc: 94.782

Epoch 49: Validation loss decreased (0.209955 --> 0.208927).  Saving model ...
	 Train_Loss: 0.3195 Train_Acc: 88.388 Val_Loss: 0.2089  BEST VAL Loss: 0.2089  Val_Acc: 95.300

Epoch 50: Validation loss decreased (0.208927 --> 0.208202).  Saving model ...
	 Train_Loss: 0.3187 Train_Acc: 88.652 Val_Loss: 0.2082  BEST VAL Loss: 0.2082  Val_Acc: 95.515

Epoch 51: Validation loss decreased (0.208202 --> 0.207697).  Saving model ...
	 Train_Loss: 0.3179 Train_Acc: 88.695 Val_Loss: 0.2077  BEST VAL Loss: 0.2077  Val_Acc: 95.300

Epoch 52: Validation loss decreased (0.207697 --> 0.207041).  Saving model ...
	 Train_Loss: 0.3172 Train_Acc: 88.561 Val_Loss: 0.2070  BEST VAL Loss: 0.2070  Val_Acc: 95.645

Epoch 53: Validation loss decreased (0.207041 --> 0.206170).  Saving model ...
	 Train_Loss: 0.3165 Train_Acc: 88.501 Val_Loss: 0.2062  BEST VAL Loss: 0.2062  Val_Acc: 95.688

Epoch 54: Validation loss decreased (0.206170 --> 0.205532).  Saving model ...
	 Train_Loss: 0.3157 Train_Acc: 89.116 Val_Loss: 0.2055  BEST VAL Loss: 0.2055  Val_Acc: 95.602

Epoch 55: Validation loss decreased (0.205532 --> 0.204750).  Saving model ...
	 Train_Loss: 0.3149 Train_Acc: 89.100 Val_Loss: 0.2047  BEST VAL Loss: 0.2047  Val_Acc: 95.860

Epoch 56: Validation loss decreased (0.204750 --> 0.203993).  Saving model ...
	 Train_Loss: 0.3142 Train_Acc: 89.137 Val_Loss: 0.2040  BEST VAL Loss: 0.2040  Val_Acc: 95.429

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.3136 Train_Acc: 88.744 Val_Loss: 0.2040  BEST VAL Loss: 0.2040  Val_Acc: 95.257

Epoch 58: Validation loss decreased (0.203993 --> 0.203649).  Saving model ...
	 Train_Loss: 0.3131 Train_Acc: 88.636 Val_Loss: 0.2036  BEST VAL Loss: 0.2036  Val_Acc: 95.170

Epoch 59: Validation loss decreased (0.203649 --> 0.202874).  Saving model ...
	 Train_Loss: 0.3124 Train_Acc: 88.857 Val_Loss: 0.2029  BEST VAL Loss: 0.2029  Val_Acc: 95.774

Epoch 60: Validation loss decreased (0.202874 --> 0.202216).  Saving model ...
	 Train_Loss: 0.3117 Train_Acc: 89.310 Val_Loss: 0.2022  BEST VAL Loss: 0.2022  Val_Acc: 95.990

Epoch 61: Validation loss decreased (0.202216 --> 0.201654).  Saving model ...
	 Train_Loss: 0.3110 Train_Acc: 89.143 Val_Loss: 0.2017  BEST VAL Loss: 0.2017  Val_Acc: 95.472

Epoch 62: Validation loss decreased (0.201654 --> 0.201058).  Saving model ...
	 Train_Loss: 0.3104 Train_Acc: 89.003 Val_Loss: 0.2011  BEST VAL Loss: 0.2011  Val_Acc: 95.903

Epoch 63: Validation loss decreased (0.201058 --> 0.200551).  Saving model ...
	 Train_Loss: 0.3097 Train_Acc: 89.445 Val_Loss: 0.2006  BEST VAL Loss: 0.2006  Val_Acc: 95.990

Epoch 64: Validation loss decreased (0.200551 --> 0.200093).  Saving model ...
	 Train_Loss: 0.3091 Train_Acc: 89.558 Val_Loss: 0.2001  BEST VAL Loss: 0.2001  Val_Acc: 96.119

Epoch 65: Validation loss decreased (0.200093 --> 0.199686).  Saving model ...
	 Train_Loss: 0.3085 Train_Acc: 89.062 Val_Loss: 0.1997  BEST VAL Loss: 0.1997  Val_Acc: 95.429

Epoch 66: Validation loss decreased (0.199686 --> 0.199248).  Saving model ...
	 Train_Loss: 0.3081 Train_Acc: 88.464 Val_Loss: 0.1992  BEST VAL Loss: 0.1992  Val_Acc: 95.817

Epoch 67: Validation loss decreased (0.199248 --> 0.198733).  Saving model ...
	 Train_Loss: 0.3076 Train_Acc: 89.089 Val_Loss: 0.1987  BEST VAL Loss: 0.1987  Val_Acc: 95.472

Epoch 68: Validation loss decreased (0.198733 --> 0.198119).  Saving model ...
	 Train_Loss: 0.3071 Train_Acc: 88.852 Val_Loss: 0.1981  BEST VAL Loss: 0.1981  Val_Acc: 95.817

Epoch 69: Validation loss decreased (0.198119 --> 0.197475).  Saving model ...
	 Train_Loss: 0.3067 Train_Acc: 89.003 Val_Loss: 0.1975  BEST VAL Loss: 0.1975  Val_Acc: 96.378

Epoch 70: Validation loss decreased (0.197475 --> 0.196803).  Saving model ...
	 Train_Loss: 0.3062 Train_Acc: 89.121 Val_Loss: 0.1968  BEST VAL Loss: 0.1968  Val_Acc: 96.205

Epoch 71: Validation loss decreased (0.196803 --> 0.196305).  Saving model ...
	 Train_Loss: 0.3057 Train_Acc: 88.933 Val_Loss: 0.1963  BEST VAL Loss: 0.1963  Val_Acc: 95.817

Epoch 72: Validation loss decreased (0.196305 --> 0.196072).  Saving model ...
	 Train_Loss: 0.3053 Train_Acc: 89.143 Val_Loss: 0.1961  BEST VAL Loss: 0.1961  Val_Acc: 95.257

Epoch 73: Validation loss decreased (0.196072 --> 0.195433).  Saving model ...
	 Train_Loss: 0.3049 Train_Acc: 88.798 Val_Loss: 0.1954  BEST VAL Loss: 0.1954  Val_Acc: 96.076

Epoch 74: Validation loss decreased (0.195433 --> 0.194926).  Saving model ...
	 Train_Loss: 0.3045 Train_Acc: 88.965 Val_Loss: 0.1949  BEST VAL Loss: 0.1949  Val_Acc: 95.903

Epoch 75: Validation loss decreased (0.194926 --> 0.194516).  Saving model ...
	 Train_Loss: 0.3041 Train_Acc: 88.733 Val_Loss: 0.1945  BEST VAL Loss: 0.1945  Val_Acc: 95.731

Epoch 76: Validation loss decreased (0.194516 --> 0.194112).  Saving model ...
	 Train_Loss: 0.3037 Train_Acc: 88.927 Val_Loss: 0.1941  BEST VAL Loss: 0.1941  Val_Acc: 95.127

Epoch 77: Validation loss decreased (0.194112 --> 0.193633).  Saving model ...
	 Train_Loss: 0.3033 Train_Acc: 89.235 Val_Loss: 0.1936  BEST VAL Loss: 0.1936  Val_Acc: 95.558

Epoch 78: Validation loss decreased (0.193633 --> 0.193415).  Saving model ...
	 Train_Loss: 0.3029 Train_Acc: 88.900 Val_Loss: 0.1934  BEST VAL Loss: 0.1934  Val_Acc: 95.257

Epoch 79: Validation loss decreased (0.193415 --> 0.193034).  Saving model ...
	 Train_Loss: 0.3026 Train_Acc: 88.690 Val_Loss: 0.1930  BEST VAL Loss: 0.1930  Val_Acc: 95.774

Epoch 80: Validation loss decreased (0.193034 --> 0.192589).  Saving model ...
	 Train_Loss: 0.3022 Train_Acc: 89.078 Val_Loss: 0.1926  BEST VAL Loss: 0.1926  Val_Acc: 96.119

Epoch 81: Validation loss decreased (0.192589 --> 0.192110).  Saving model ...
	 Train_Loss: 0.3017 Train_Acc: 89.612 Val_Loss: 0.1921  BEST VAL Loss: 0.1921  Val_Acc: 96.119

Epoch 82: Validation loss decreased (0.192110 --> 0.191890).  Saving model ...
	 Train_Loss: 0.3013 Train_Acc: 89.154 Val_Loss: 0.1919  BEST VAL Loss: 0.1919  Val_Acc: 96.033

Epoch 83: Validation loss decreased (0.191890 --> 0.191573).  Saving model ...
	 Train_Loss: 0.3010 Train_Acc: 88.868 Val_Loss: 0.1916  BEST VAL Loss: 0.1916  Val_Acc: 96.076

Epoch 84: Validation loss decreased (0.191573 --> 0.191120).  Saving model ...
	 Train_Loss: 0.3007 Train_Acc: 89.111 Val_Loss: 0.1911  BEST VAL Loss: 0.1911  Val_Acc: 95.731

Epoch 85: Validation loss decreased (0.191120 --> 0.190778).  Saving model ...
	 Train_Loss: 0.3003 Train_Acc: 89.369 Val_Loss: 0.1908  BEST VAL Loss: 0.1908  Val_Acc: 95.817

Epoch 86: Validation loss decreased (0.190778 --> 0.190439).  Saving model ...
	 Train_Loss: 0.3000 Train_Acc: 89.003 Val_Loss: 0.1904  BEST VAL Loss: 0.1904  Val_Acc: 96.033

Epoch 87: Validation loss decreased (0.190439 --> 0.190233).  Saving model ...
	 Train_Loss: 0.2996 Train_Acc: 89.132 Val_Loss: 0.1902  BEST VAL Loss: 0.1902  Val_Acc: 95.860

Epoch 88: Validation loss decreased (0.190233 --> 0.190055).  Saving model ...
	 Train_Loss: 0.2993 Train_Acc: 89.100 Val_Loss: 0.1901  BEST VAL Loss: 0.1901  Val_Acc: 95.817

Epoch 89: Validation loss decreased (0.190055 --> 0.189783).  Saving model ...
	 Train_Loss: 0.2990 Train_Acc: 89.067 Val_Loss: 0.1898  BEST VAL Loss: 0.1898  Val_Acc: 95.860

Epoch 90: Validation loss decreased (0.189783 --> 0.189694).  Saving model ...
	 Train_Loss: 0.2987 Train_Acc: 89.369 Val_Loss: 0.1897  BEST VAL Loss: 0.1897  Val_Acc: 96.119

Epoch 91: Validation loss decreased (0.189694 --> 0.189391).  Saving model ...
	 Train_Loss: 0.2984 Train_Acc: 88.970 Val_Loss: 0.1894  BEST VAL Loss: 0.1894  Val_Acc: 96.248

Epoch 92: Validation loss decreased (0.189391 --> 0.189070).  Saving model ...
	 Train_Loss: 0.2980 Train_Acc: 89.580 Val_Loss: 0.1891  BEST VAL Loss: 0.1891  Val_Acc: 96.464

Epoch 93: Validation loss decreased (0.189070 --> 0.188895).  Saving model ...
	 Train_Loss: 0.2977 Train_Acc: 89.520 Val_Loss: 0.1889  BEST VAL Loss: 0.1889  Val_Acc: 96.162

Epoch 94: Validation loss decreased (0.188895 --> 0.188700).  Saving model ...
	 Train_Loss: 0.2974 Train_Acc: 89.321 Val_Loss: 0.1887  BEST VAL Loss: 0.1887  Val_Acc: 96.335

Epoch 95: Validation loss decreased (0.188700 --> 0.188421).  Saving model ...
	 Train_Loss: 0.2970 Train_Acc: 89.493 Val_Loss: 0.1884  BEST VAL Loss: 0.1884  Val_Acc: 96.076

Epoch 96: Validation loss decreased (0.188421 --> 0.188032).  Saving model ...
	 Train_Loss: 0.2967 Train_Acc: 89.218 Val_Loss: 0.1880  BEST VAL Loss: 0.1880  Val_Acc: 96.335

Epoch 97: Validation loss decreased (0.188032 --> 0.187593).  Saving model ...
	 Train_Loss: 0.2965 Train_Acc: 89.116 Val_Loss: 0.1876  BEST VAL Loss: 0.1876  Val_Acc: 96.507

Epoch 98: Validation loss decreased (0.187593 --> 0.187193).  Saving model ...
	 Train_Loss: 0.2962 Train_Acc: 89.364 Val_Loss: 0.1872  BEST VAL Loss: 0.1872  Val_Acc: 96.205

Epoch 99: Validation loss decreased (0.187193 --> 0.186929).  Saving model ...
	 Train_Loss: 0.2958 Train_Acc: 89.925 Val_Loss: 0.1869  BEST VAL Loss: 0.1869  Val_Acc: 96.292

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.54      0.53      0.54     10114
           1       0.45      0.47      0.46      8436

    accuracy                           0.50     18550
   macro avg       0.50      0.50      0.50     18550
weighted avg       0.50      0.50      0.50     18550

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.52      0.54      1264
           1       0.46      0.49      0.47      1055

    accuracy                           0.51      2319
   macro avg       0.50      0.50      0.50      2319
weighted avg       0.51      0.51      0.51      2319

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.54      0.54      0.54      1264
           1       0.45      0.46      0.46      1055

    accuracy                           0.50      2319
   macro avg       0.50      0.50      0.50      2319
weighted avg       0.50      0.50      0.50      2319

              precision    recall  f1-score   support

           0       0.54      0.54      0.54      1264
           1       0.45      0.46      0.46      1055

    accuracy                           0.50      2319
   macro avg       0.50      0.50      0.50      2319
weighted avg       0.50      0.50      0.50      2319

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.52      0.52      4168
           1       0.48      0.49      0.49      3856

    accuracy                           0.50      8024
   macro avg       0.50      0.50      0.50      8024
weighted avg       0.50      0.50      0.50      8024

              precision    recall  f1-score   support

           0       0.52      0.52      0.52      4168
           1       0.48      0.49      0.49      3856

    accuracy                           0.50      8024
   macro avg       0.50      0.50      0.50      8024
weighted avg       0.50      0.50      0.50      8024

completed
