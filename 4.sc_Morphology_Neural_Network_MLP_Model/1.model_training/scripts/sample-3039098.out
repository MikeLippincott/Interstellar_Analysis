[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '0336ca6d'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'cc3efcad'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'a760277e'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'a36c6a6a'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: H2O2_100.000_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (379133, 1270)
Number of total missing values across all columns: 758266
Data Subset Is Off
Wells held out for testing: ['C09' 'I10']
Wells to use for training, validation, and testing ['C02' 'C03' 'C08' 'H04' 'I04' 'H05' 'I05' 'H10' 'H11' 'I11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.518396).  Saving model ...
	 Train_Loss: 0.5654 Train_Acc: 69.499 Val_Loss: 0.5184  BEST VAL Loss: 0.5184  Val_Acc: 76.140

Epoch 1: Validation loss decreased (0.518396 --> 0.499818).  Saving model ...
	 Train_Loss: 0.5478 Train_Acc: 72.169 Val_Loss: 0.4998  BEST VAL Loss: 0.4998  Val_Acc: 77.568

Epoch 2: Validation loss decreased (0.499818 --> 0.484472).  Saving model ...
	 Train_Loss: 0.5358 Train_Acc: 74.944 Val_Loss: 0.4845  BEST VAL Loss: 0.4845  Val_Acc: 79.069

Epoch 3: Validation loss decreased (0.484472 --> 0.480342).  Saving model ...
	 Train_Loss: 0.5289 Train_Acc: 75.426 Val_Loss: 0.4803  BEST VAL Loss: 0.4803  Val_Acc: 79.111

Epoch 4: Validation loss decreased (0.480342 --> 0.475466).  Saving model ...
	 Train_Loss: 0.5239 Train_Acc: 75.597 Val_Loss: 0.4755  BEST VAL Loss: 0.4755  Val_Acc: 78.906

Epoch 5: Validation loss decreased (0.475466 --> 0.474122).  Saving model ...
	 Train_Loss: 0.5207 Train_Acc: 75.516 Val_Loss: 0.4741  BEST VAL Loss: 0.4741  Val_Acc: 79.335

Epoch 6: Validation loss decreased (0.474122 --> 0.472781).  Saving model ...
	 Train_Loss: 0.5185 Train_Acc: 75.760 Val_Loss: 0.4728  BEST VAL Loss: 0.4728  Val_Acc: 78.730

Epoch 7: Validation loss decreased (0.472781 --> 0.470389).  Saving model ...
	 Train_Loss: 0.5167 Train_Acc: 75.404 Val_Loss: 0.4704  BEST VAL Loss: 0.4704  Val_Acc: 77.737

Epoch 8: Validation loss decreased (0.470389 --> 0.468543).  Saving model ...
	 Train_Loss: 0.5148 Train_Acc: 75.784 Val_Loss: 0.4685  BEST VAL Loss: 0.4685  Val_Acc: 79.802

Epoch 9: Validation loss decreased (0.468543 --> 0.468242).  Saving model ...
	 Train_Loss: 0.5134 Train_Acc: 75.931 Val_Loss: 0.4682  BEST VAL Loss: 0.4682  Val_Acc: 78.157

Epoch 10: Validation loss decreased (0.468242 --> 0.465774).  Saving model ...
	 Train_Loss: 0.5122 Train_Acc: 75.575 Val_Loss: 0.4658  BEST VAL Loss: 0.4658  Val_Acc: 79.296

Epoch 11: Validation loss decreased (0.465774 --> 0.464545).  Saving model ...
	 Train_Loss: 0.5110 Train_Acc: 76.058 Val_Loss: 0.4645  BEST VAL Loss: 0.4645  Val_Acc: 79.927

Epoch 12: Validation loss decreased (0.464545 --> 0.462951).  Saving model ...
	 Train_Loss: 0.5099 Train_Acc: 75.988 Val_Loss: 0.4630  BEST VAL Loss: 0.4630  Val_Acc: 79.517

Epoch 13: Validation loss decreased (0.462951 --> 0.461170).  Saving model ...
	 Train_Loss: 0.5089 Train_Acc: 76.270 Val_Loss: 0.4612  BEST VAL Loss: 0.4612  Val_Acc: 79.556

Epoch 14: Validation loss decreased (0.461170 --> 0.460148).  Saving model ...
	 Train_Loss: 0.5085 Train_Acc: 75.498 Val_Loss: 0.4601  BEST VAL Loss: 0.4601  Val_Acc: 79.354

Epoch 15: Validation loss decreased (0.460148 --> 0.458714).  Saving model ...
	 Train_Loss: 0.5075 Train_Acc: 76.198 Val_Loss: 0.4587  BEST VAL Loss: 0.4587  Val_Acc: 79.399

Epoch 16: Validation loss decreased (0.458714 --> 0.458209).  Saving model ...
	 Train_Loss: 0.5068 Train_Acc: 76.180 Val_Loss: 0.4582  BEST VAL Loss: 0.4582  Val_Acc: 77.235

Epoch 17: Validation loss decreased (0.458209 --> 0.457393).  Saving model ...
	 Train_Loss: 0.5062 Train_Acc: 75.473 Val_Loss: 0.4574  BEST VAL Loss: 0.4574  Val_Acc: 79.216

Epoch 18: Validation loss decreased (0.457393 --> 0.457233).  Saving model ...
	 Train_Loss: 0.5058 Train_Acc: 75.791 Val_Loss: 0.4572  BEST VAL Loss: 0.4572  Val_Acc: 78.512

Epoch 19: Validation loss did not decrease
	 Train_Loss: 0.5055 Train_Acc: 76.205 Val_Loss: 0.4573  BEST VAL Loss: 0.4572  Val_Acc: 79.527

Epoch 20: Validation loss decreased (0.457233 --> 0.457060).  Saving model ...
	 Train_Loss: 0.5051 Train_Acc: 76.063 Val_Loss: 0.4571  BEST VAL Loss: 0.4571  Val_Acc: 80.522

Epoch 21: Validation loss decreased (0.457060 --> 0.456681).  Saving model ...
	 Train_Loss: 0.5049 Train_Acc: 75.952 Val_Loss: 0.4567  BEST VAL Loss: 0.4567  Val_Acc: 80.039

Epoch 22: Validation loss did not decrease
	 Train_Loss: 0.5046 Train_Acc: 75.939 Val_Loss: 0.4572  BEST VAL Loss: 0.4567  Val_Acc: 77.500

Epoch 23: Validation loss decreased (0.456681 --> 0.456350).  Saving model ...
	 Train_Loss: 0.5042 Train_Acc: 76.388 Val_Loss: 0.4563  BEST VAL Loss: 0.4563  Val_Acc: 80.404

Epoch 24: Validation loss decreased (0.456350 --> 0.455732).  Saving model ...
	 Train_Loss: 0.5036 Train_Acc: 76.473 Val_Loss: 0.4557  BEST VAL Loss: 0.4557  Val_Acc: 79.495

Epoch 25: Validation loss decreased (0.455732 --> 0.455307).  Saving model ...
	 Train_Loss: 0.5032 Train_Acc: 76.373 Val_Loss: 0.4553  BEST VAL Loss: 0.4553  Val_Acc: 79.719

Epoch 26: Validation loss decreased (0.455307 --> 0.454945).  Saving model ...
	 Train_Loss: 0.5029 Train_Acc: 76.282 Val_Loss: 0.4549  BEST VAL Loss: 0.4549  Val_Acc: 79.239

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.5027 Train_Acc: 76.282 Val_Loss: 0.4559  BEST VAL Loss: 0.4549  Val_Acc: 78.253

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.5026 Train_Acc: 76.259 Val_Loss: 0.4553  BEST VAL Loss: 0.4549  Val_Acc: 79.956

Epoch 29: Validation loss decreased (0.454945 --> 0.454749).  Saving model ...
	 Train_Loss: 0.5022 Train_Acc: 75.719 Val_Loss: 0.4547  BEST VAL Loss: 0.4547  Val_Acc: 78.022

Epoch 30: Validation loss decreased (0.454749 --> 0.454470).  Saving model ...
	 Train_Loss: 0.5020 Train_Acc: 75.628 Val_Loss: 0.4545  BEST VAL Loss: 0.4545  Val_Acc: 79.572

Epoch 31: Validation loss decreased (0.454470 --> 0.454400).  Saving model ...
	 Train_Loss: 0.5020 Train_Acc: 75.326 Val_Loss: 0.4544  BEST VAL Loss: 0.4544  Val_Acc: 75.054

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.5017 Train_Acc: 76.316 Val_Loss: 0.4545  BEST VAL Loss: 0.4544  Val_Acc: 80.228

Epoch 33: Validation loss decreased (0.454400 --> 0.454356).  Saving model ...
	 Train_Loss: 0.5018 Train_Acc: 75.839 Val_Loss: 0.4544  BEST VAL Loss: 0.4544  Val_Acc: 79.079

Epoch 34: Validation loss did not decrease
	 Train_Loss: 0.5019 Train_Acc: 75.552 Val_Loss: 0.4546  BEST VAL Loss: 0.4544  Val_Acc: 77.744

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.5021 Train_Acc: 75.298 Val_Loss: 0.4544  BEST VAL Loss: 0.4544  Val_Acc: 79.088

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.5023 Train_Acc: 75.330 Val_Loss: 0.4544  BEST VAL Loss: 0.4544  Val_Acc: 79.588

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.5024 Train_Acc: 75.453 Val_Loss: 0.4547  BEST VAL Loss: 0.4544  Val_Acc: 77.596

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.5027 Train_Acc: 74.979 Val_Loss: 0.4544  BEST VAL Loss: 0.4544  Val_Acc: 80.177

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.5030 Train_Acc: 75.343 Val_Loss: 0.4546  BEST VAL Loss: 0.4544  Val_Acc: 77.884

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.5031 Train_Acc: 75.240 Val_Loss: 0.4549  BEST VAL Loss: 0.4544  Val_Acc: 78.749

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.5032 Train_Acc: 75.673 Val_Loss: 0.4549  BEST VAL Loss: 0.4544  Val_Acc: 80.010

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.5033 Train_Acc: 75.284 Val_Loss: 0.4551  BEST VAL Loss: 0.4544  Val_Acc: 78.797

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.5035 Train_Acc: 75.320 Val_Loss: 0.4558  BEST VAL Loss: 0.4544  Val_Acc: 79.107

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.5035 Train_Acc: 75.415 Val_Loss: 0.4559  BEST VAL Loss: 0.4544  Val_Acc: 79.031

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.5035 Train_Acc: 75.725 Val_Loss: 0.4556  BEST VAL Loss: 0.4544  Val_Acc: 79.885

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.5035 Train_Acc: 75.837 Val_Loss: 0.4554  BEST VAL Loss: 0.4544  Val_Acc: 79.873

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.5035 Train_Acc: 75.712 Val_Loss: 0.4552  BEST VAL Loss: 0.4544  Val_Acc: 79.591

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.5037 Train_Acc: 75.225 Val_Loss: 0.4558  BEST VAL Loss: 0.4544  Val_Acc: 78.707

Epoch 49: Validation loss did not decrease
Early stopped at epoch : 49
H2O2_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.79      0.93      0.86    169562
           1       0.78      0.49      0.60     80324

    accuracy                           0.79    249886
   macro avg       0.79      0.71      0.73    249886
weighted avg       0.79      0.79      0.77    249886

H2O2_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.79      0.93      0.86     21195
           1       0.78      0.49      0.60     10041

    accuracy                           0.79     31236
   macro avg       0.79      0.71      0.73     31236
weighted avg       0.79      0.79      0.78     31236

H2O2_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.79      0.93      0.86     21195
           1       0.78      0.48      0.60     10041

    accuracy                           0.79     31236
   macro avg       0.78      0.71      0.73     31236
weighted avg       0.79      0.79      0.77     31236

              precision    recall  f1-score   support

           0       0.79      0.93      0.86     21195
           1       0.78      0.48      0.60     10041

    accuracy                           0.79     31236
   macro avg       0.78      0.71      0.73     31236
weighted avg       0.79      0.79      0.77     31236

H2O2_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.52      0.92      0.67     28584
           1       0.87      0.37      0.52     38191

    accuracy                           0.61     66775
   macro avg       0.69      0.65      0.59     66775
weighted avg       0.72      0.61      0.58     66775

              precision    recall  f1-score   support

           0       0.52      0.92      0.67     28584
           1       0.87      0.37      0.52     38191

    accuracy                           0.61     66775
   macro avg       0.69      0.65      0.59     66775
weighted avg       0.72      0.61      0.58     66775

completed
