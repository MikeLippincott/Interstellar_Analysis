[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '2f4e2799'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'fd608ac7'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b742da13'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '8a457099'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_Nigericin_1.000_3.0_DMSO_0.025'
 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (28054, 1276)
Number of total missing values across all columns: 0
Data Subset Is Off
Wells held out for testing: ['L16' 'M20']
Wells to use for training, validation, and testing ['M16' 'L17' 'M17' 'L20' 'L21' 'M21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.698555).  Saving model ...
	 Train_Loss: 0.7156 Train_Acc: 49.402 Val_Loss: 0.6986  BEST VAL Loss: 0.6986  Val_Acc: 51.196

Epoch 1: Validation loss decreased (0.698555 --> 0.696864).  Saving model ...
	 Train_Loss: 0.7051 Train_Acc: 51.726 Val_Loss: 0.6969  BEST VAL Loss: 0.6969  Val_Acc: 51.342

Epoch 2: Validation loss decreased (0.696864 --> 0.695857).  Saving model ...
	 Train_Loss: 0.7012 Train_Acc: 51.452 Val_Loss: 0.6959  BEST VAL Loss: 0.6959  Val_Acc: 51.147

Epoch 3: Validation loss decreased (0.695857 --> 0.695647).  Saving model ...
	 Train_Loss: 0.6991 Train_Acc: 51.556 Val_Loss: 0.6956  BEST VAL Loss: 0.6956  Val_Acc: 51.196

Epoch 4: Validation loss decreased (0.695647 --> 0.695399).  Saving model ...
	 Train_Loss: 0.6978 Train_Acc: 51.354 Val_Loss: 0.6954  BEST VAL Loss: 0.6954  Val_Acc: 51.489

Epoch 5: Validation loss decreased (0.695399 --> 0.695246).  Saving model ...
	 Train_Loss: 0.6969 Train_Acc: 51.055 Val_Loss: 0.6952  BEST VAL Loss: 0.6952  Val_Acc: 51.830

Epoch 6: Validation loss decreased (0.695246 --> 0.694562).  Saving model ...
	 Train_Loss: 0.6958 Train_Acc: 51.757 Val_Loss: 0.6946  BEST VAL Loss: 0.6946  Val_Acc: 52.025

Epoch 7: Validation loss decreased (0.694562 --> 0.692672).  Saving model ...
	 Train_Loss: 0.6943 Train_Acc: 52.556 Val_Loss: 0.6927  BEST VAL Loss: 0.6927  Val_Acc: 51.879

Epoch 8: Validation loss decreased (0.692672 --> 0.688958).  Saving model ...
	 Train_Loss: 0.6920 Train_Acc: 53.050 Val_Loss: 0.6890  BEST VAL Loss: 0.6890  Val_Acc: 57.540

Epoch 9: Validation loss decreased (0.688958 --> 0.683133).  Saving model ...
	 Train_Loss: 0.6888 Train_Acc: 57.132 Val_Loss: 0.6831  BEST VAL Loss: 0.6831  Val_Acc: 60.957

Epoch 10: Validation loss decreased (0.683133 --> 0.676005).  Saving model ...
	 Train_Loss: 0.6841 Train_Acc: 60.170 Val_Loss: 0.6760  BEST VAL Loss: 0.6760  Val_Acc: 66.423

Epoch 11: Validation loss decreased (0.676005 --> 0.668334).  Saving model ...
	 Train_Loss: 0.6783 Train_Acc: 62.762 Val_Loss: 0.6683  BEST VAL Loss: 0.6683  Val_Acc: 67.984

Epoch 12: Validation loss decreased (0.668334 --> 0.660136).  Saving model ...
	 Train_Loss: 0.6719 Train_Acc: 64.104 Val_Loss: 0.6601  BEST VAL Loss: 0.6601  Val_Acc: 68.765

Epoch 13: Validation loss decreased (0.660136 --> 0.652361).  Saving model ...
	 Train_Loss: 0.6653 Train_Acc: 65.721 Val_Loss: 0.6524  BEST VAL Loss: 0.6524  Val_Acc: 69.351

Epoch 14: Validation loss decreased (0.652361 --> 0.645277).  Saving model ...
	 Train_Loss: 0.6592 Train_Acc: 66.331 Val_Loss: 0.6453  BEST VAL Loss: 0.6453  Val_Acc: 69.985

Epoch 15: Validation loss decreased (0.645277 --> 0.638435).  Saving model ...
	 Train_Loss: 0.6538 Train_Acc: 66.307 Val_Loss: 0.6384  BEST VAL Loss: 0.6384  Val_Acc: 70.571

Epoch 16: Validation loss decreased (0.638435 --> 0.632638).  Saving model ...
	 Train_Loss: 0.6485 Train_Acc: 66.636 Val_Loss: 0.6326  BEST VAL Loss: 0.6326  Val_Acc: 70.766

Epoch 17: Validation loss decreased (0.632638 --> 0.627299).  Saving model ...
	 Train_Loss: 0.6433 Train_Acc: 67.271 Val_Loss: 0.6273  BEST VAL Loss: 0.6273  Val_Acc: 70.376

Epoch 18: Validation loss decreased (0.627299 --> 0.622740).  Saving model ...
	 Train_Loss: 0.6383 Train_Acc: 67.801 Val_Loss: 0.6227  BEST VAL Loss: 0.6227  Val_Acc: 69.644

Epoch 19: Validation loss decreased (0.622740 --> 0.618107).  Saving model ...
	 Train_Loss: 0.6339 Train_Acc: 68.003 Val_Loss: 0.6181  BEST VAL Loss: 0.6181  Val_Acc: 70.229

Epoch 20: Validation loss decreased (0.618107 --> 0.613511).  Saving model ...
	 Train_Loss: 0.6294 Train_Acc: 68.357 Val_Loss: 0.6135  BEST VAL Loss: 0.6135  Val_Acc: 70.913

Epoch 21: Validation loss decreased (0.613511 --> 0.610151).  Saving model ...
	 Train_Loss: 0.6252 Train_Acc: 68.808 Val_Loss: 0.6102  BEST VAL Loss: 0.6102  Val_Acc: 71.157

Epoch 22: Validation loss decreased (0.610151 --> 0.606936).  Saving model ...
	 Train_Loss: 0.6215 Train_Acc: 68.540 Val_Loss: 0.6069  BEST VAL Loss: 0.6069  Val_Acc: 70.815

Epoch 23: Validation loss decreased (0.606936 --> 0.603741).  Saving model ...
	 Train_Loss: 0.6176 Train_Acc: 69.241 Val_Loss: 0.6037  BEST VAL Loss: 0.6037  Val_Acc: 71.108

Epoch 24: Validation loss decreased (0.603741 --> 0.600608).  Saving model ...
	 Train_Loss: 0.6141 Train_Acc: 69.278 Val_Loss: 0.6006  BEST VAL Loss: 0.6006  Val_Acc: 71.791

Epoch 25: Validation loss decreased (0.600608 --> 0.597754).  Saving model ...
	 Train_Loss: 0.6109 Train_Acc: 68.497 Val_Loss: 0.5978  BEST VAL Loss: 0.5978  Val_Acc: 70.278

Epoch 26: Validation loss decreased (0.597754 --> 0.594943).  Saving model ...
	 Train_Loss: 0.6079 Train_Acc: 68.887 Val_Loss: 0.5949  BEST VAL Loss: 0.5949  Val_Acc: 69.741

Epoch 27: Validation loss decreased (0.594943 --> 0.592287).  Saving model ...
	 Train_Loss: 0.6048 Train_Acc: 69.571 Val_Loss: 0.5923  BEST VAL Loss: 0.5923  Val_Acc: 69.937

Epoch 28: Validation loss decreased (0.592287 --> 0.590370).  Saving model ...
	 Train_Loss: 0.6018 Train_Acc: 69.607 Val_Loss: 0.5904  BEST VAL Loss: 0.5904  Val_Acc: 69.595

Epoch 29: Validation loss decreased (0.590370 --> 0.588455).  Saving model ...
	 Train_Loss: 0.5991 Train_Acc: 69.485 Val_Loss: 0.5885  BEST VAL Loss: 0.5885  Val_Acc: 69.107

Epoch 30: Validation loss decreased (0.588455 --> 0.586987).  Saving model ...
	 Train_Loss: 0.5964 Train_Acc: 70.248 Val_Loss: 0.5870  BEST VAL Loss: 0.5870  Val_Acc: 71.108

Epoch 31: Validation loss decreased (0.586987 --> 0.585492).  Saving model ...
	 Train_Loss: 0.5937 Train_Acc: 69.815 Val_Loss: 0.5855  BEST VAL Loss: 0.5855  Val_Acc: 70.815

Epoch 32: Validation loss decreased (0.585492 --> 0.583980).  Saving model ...
	 Train_Loss: 0.5913 Train_Acc: 70.156 Val_Loss: 0.5840  BEST VAL Loss: 0.5840  Val_Acc: 71.352

Epoch 33: Validation loss decreased (0.583980 --> 0.582539).  Saving model ...
	 Train_Loss: 0.5890 Train_Acc: 69.735 Val_Loss: 0.5825  BEST VAL Loss: 0.5825  Val_Acc: 70.278

Epoch 34: Validation loss decreased (0.582539 --> 0.581087).  Saving model ...
	 Train_Loss: 0.5869 Train_Acc: 70.254 Val_Loss: 0.5811  BEST VAL Loss: 0.5811  Val_Acc: 71.059

Epoch 35: Validation loss decreased (0.581087 --> 0.579804).  Saving model ...
	 Train_Loss: 0.5849 Train_Acc: 70.034 Val_Loss: 0.5798  BEST VAL Loss: 0.5798  Val_Acc: 71.498

Epoch 36: Validation loss decreased (0.579804 --> 0.578433).  Saving model ...
	 Train_Loss: 0.5831 Train_Acc: 69.693 Val_Loss: 0.5784  BEST VAL Loss: 0.5784  Val_Acc: 71.157

Epoch 37: Validation loss decreased (0.578433 --> 0.577057).  Saving model ...
	 Train_Loss: 0.5812 Train_Acc: 70.113 Val_Loss: 0.5771  BEST VAL Loss: 0.5771  Val_Acc: 70.181

Epoch 38: Validation loss decreased (0.577057 --> 0.575926).  Saving model ...
	 Train_Loss: 0.5793 Train_Acc: 70.126 Val_Loss: 0.5759  BEST VAL Loss: 0.5759  Val_Acc: 71.108

Epoch 39: Validation loss decreased (0.575926 --> 0.574878).  Saving model ...
	 Train_Loss: 0.5775 Train_Acc: 70.412 Val_Loss: 0.5749  BEST VAL Loss: 0.5749  Val_Acc: 70.961

Epoch 40: Validation loss decreased (0.574878 --> 0.574014).  Saving model ...
	 Train_Loss: 0.5758 Train_Acc: 70.339 Val_Loss: 0.5740  BEST VAL Loss: 0.5740  Val_Acc: 71.010

Epoch 41: Validation loss decreased (0.574014 --> 0.573072).  Saving model ...
	 Train_Loss: 0.5741 Train_Acc: 70.162 Val_Loss: 0.5731  BEST VAL Loss: 0.5731  Val_Acc: 71.596

Epoch 42: Validation loss decreased (0.573072 --> 0.572034).  Saving model ...
	 Train_Loss: 0.5726 Train_Acc: 69.906 Val_Loss: 0.5720  BEST VAL Loss: 0.5720  Val_Acc: 70.913

Epoch 43: Validation loss decreased (0.572034 --> 0.571139).  Saving model ...
	 Train_Loss: 0.5710 Train_Acc: 70.321 Val_Loss: 0.5711  BEST VAL Loss: 0.5711  Val_Acc: 70.181

Epoch 44: Validation loss decreased (0.571139 --> 0.570454).  Saving model ...
	 Train_Loss: 0.5695 Train_Acc: 70.406 Val_Loss: 0.5705  BEST VAL Loss: 0.5705  Val_Acc: 68.863

Epoch 45: Validation loss decreased (0.570454 --> 0.569721).  Saving model ...
	 Train_Loss: 0.5680 Train_Acc: 70.486 Val_Loss: 0.5697  BEST VAL Loss: 0.5697  Val_Acc: 70.181

Epoch 46: Validation loss decreased (0.569721 --> 0.568744).  Saving model ...
	 Train_Loss: 0.5666 Train_Acc: 70.949 Val_Loss: 0.5687  BEST VAL Loss: 0.5687  Val_Acc: 69.741

Epoch 47: Validation loss decreased (0.568744 --> 0.568177).  Saving model ...
	 Train_Loss: 0.5652 Train_Acc: 70.846 Val_Loss: 0.5682  BEST VAL Loss: 0.5682  Val_Acc: 69.009

Epoch 48: Validation loss decreased (0.568177 --> 0.567782).  Saving model ...
	 Train_Loss: 0.5639 Train_Acc: 70.376 Val_Loss: 0.5678  BEST VAL Loss: 0.5678  Val_Acc: 69.107

Epoch 49: Validation loss decreased (0.567782 --> 0.567411).  Saving model ...
	 Train_Loss: 0.5625 Train_Acc: 70.894 Val_Loss: 0.5674  BEST VAL Loss: 0.5674  Val_Acc: 70.717

Epoch 50: Validation loss decreased (0.567411 --> 0.566990).  Saving model ...
	 Train_Loss: 0.5613 Train_Acc: 70.949 Val_Loss: 0.5670  BEST VAL Loss: 0.5670  Val_Acc: 69.351

Epoch 51: Validation loss decreased (0.566990 --> 0.566615).  Saving model ...
	 Train_Loss: 0.5600 Train_Acc: 70.955 Val_Loss: 0.5666  BEST VAL Loss: 0.5666  Val_Acc: 69.449

Epoch 52: Validation loss decreased (0.566615 --> 0.566406).  Saving model ...
	 Train_Loss: 0.5588 Train_Acc: 71.010 Val_Loss: 0.5664  BEST VAL Loss: 0.5664  Val_Acc: 69.888

Epoch 53: Validation loss decreased (0.566406 --> 0.566000).  Saving model ...
	 Train_Loss: 0.5576 Train_Acc: 71.035 Val_Loss: 0.5660  BEST VAL Loss: 0.5660  Val_Acc: 69.449

Epoch 54: Validation loss decreased (0.566000 --> 0.565762).  Saving model ...
	 Train_Loss: 0.5563 Train_Acc: 71.468 Val_Loss: 0.5658  BEST VAL Loss: 0.5658  Val_Acc: 70.083

Epoch 55: Validation loss decreased (0.565762 --> 0.565386).  Saving model ...
	 Train_Loss: 0.5552 Train_Acc: 71.053 Val_Loss: 0.5654  BEST VAL Loss: 0.5654  Val_Acc: 70.083

Epoch 56: Validation loss decreased (0.565386 --> 0.565149).  Saving model ...
	 Train_Loss: 0.5542 Train_Acc: 71.053 Val_Loss: 0.5651  BEST VAL Loss: 0.5651  Val_Acc: 69.107

Epoch 57: Validation loss decreased (0.565149 --> 0.564852).  Saving model ...
	 Train_Loss: 0.5531 Train_Acc: 71.187 Val_Loss: 0.5649  BEST VAL Loss: 0.5649  Val_Acc: 69.888

Epoch 58: Validation loss decreased (0.564852 --> 0.564513).  Saving model ...
	 Train_Loss: 0.5521 Train_Acc: 71.315 Val_Loss: 0.5645  BEST VAL Loss: 0.5645  Val_Acc: 70.473

Epoch 59: Validation loss decreased (0.564513 --> 0.563997).  Saving model ...
	 Train_Loss: 0.5512 Train_Acc: 71.376 Val_Loss: 0.5640  BEST VAL Loss: 0.5640  Val_Acc: 71.010

Epoch 60: Validation loss decreased (0.563997 --> 0.563848).  Saving model ...
	 Train_Loss: 0.5503 Train_Acc: 70.748 Val_Loss: 0.5638  BEST VAL Loss: 0.5638  Val_Acc: 70.717

Epoch 61: Validation loss decreased (0.563848 --> 0.563312).  Saving model ...
	 Train_Loss: 0.5494 Train_Acc: 71.016 Val_Loss: 0.5633  BEST VAL Loss: 0.5633  Val_Acc: 69.497

Epoch 62: Validation loss decreased (0.563312 --> 0.562902).  Saving model ...
	 Train_Loss: 0.5485 Train_Acc: 70.650 Val_Loss: 0.5629  BEST VAL Loss: 0.5629  Val_Acc: 69.546

Epoch 63: Validation loss decreased (0.562902 --> 0.562527).  Saving model ...
	 Train_Loss: 0.5476 Train_Acc: 71.584 Val_Loss: 0.5625  BEST VAL Loss: 0.5625  Val_Acc: 70.522

Epoch 64: Validation loss decreased (0.562527 --> 0.562485).  Saving model ...
	 Train_Loss: 0.5467 Train_Acc: 71.151 Val_Loss: 0.5625  BEST VAL Loss: 0.5625  Val_Acc: 70.327

Epoch 65: Validation loss decreased (0.562485 --> 0.562276).  Saving model ...
	 Train_Loss: 0.5458 Train_Acc: 70.931 Val_Loss: 0.5623  BEST VAL Loss: 0.5623  Val_Acc: 70.961

Epoch 66: Validation loss decreased (0.562276 --> 0.562003).  Saving model ...
	 Train_Loss: 0.5450 Train_Acc: 70.931 Val_Loss: 0.5620  BEST VAL Loss: 0.5620  Val_Acc: 70.132

Epoch 67: Validation loss decreased (0.562003 --> 0.561711).  Saving model ...
	 Train_Loss: 0.5440 Train_Acc: 71.730 Val_Loss: 0.5617  BEST VAL Loss: 0.5617  Val_Acc: 69.058

Epoch 68: Validation loss decreased (0.561711 --> 0.561391).  Saving model ...
	 Train_Loss: 0.5432 Train_Acc: 71.437 Val_Loss: 0.5614  BEST VAL Loss: 0.5614  Val_Acc: 69.595

Epoch 69: Validation loss decreased (0.561391 --> 0.561200).  Saving model ...
	 Train_Loss: 0.5424 Train_Acc: 71.626 Val_Loss: 0.5612  BEST VAL Loss: 0.5612  Val_Acc: 69.058

Epoch 70: Validation loss decreased (0.561200 --> 0.561057).  Saving model ...
	 Train_Loss: 0.5416 Train_Acc: 71.077 Val_Loss: 0.5611  BEST VAL Loss: 0.5611  Val_Acc: 69.351

Epoch 71: Validation loss decreased (0.561057 --> 0.560977).  Saving model ...
	 Train_Loss: 0.5408 Train_Acc: 71.559 Val_Loss: 0.5610  BEST VAL Loss: 0.5610  Val_Acc: 69.741

Epoch 72: Validation loss decreased (0.560977 --> 0.560915).  Saving model ...
	 Train_Loss: 0.5400 Train_Acc: 71.718 Val_Loss: 0.5609  BEST VAL Loss: 0.5609  Val_Acc: 70.132

Epoch 73: Validation loss decreased (0.560915 --> 0.560872).  Saving model ...
	 Train_Loss: 0.5392 Train_Acc: 72.188 Val_Loss: 0.5609  BEST VAL Loss: 0.5609  Val_Acc: 70.181

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.5383 Train_Acc: 71.980 Val_Loss: 0.5611  BEST VAL Loss: 0.5609  Val_Acc: 70.181

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.5376 Train_Acc: 71.474 Val_Loss: 0.5612  BEST VAL Loss: 0.5609  Val_Acc: 70.229

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.5369 Train_Acc: 71.669 Val_Loss: 0.5612  BEST VAL Loss: 0.5609  Val_Acc: 69.302

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.5363 Train_Acc: 71.468 Val_Loss: 0.5611  BEST VAL Loss: 0.5609  Val_Acc: 69.400

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.5356 Train_Acc: 71.950 Val_Loss: 0.5610  BEST VAL Loss: 0.5609  Val_Acc: 69.644

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.5348 Train_Acc: 72.072 Val_Loss: 0.5610  BEST VAL Loss: 0.5609  Val_Acc: 69.888

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.5341 Train_Acc: 72.096 Val_Loss: 0.5611  BEST VAL Loss: 0.5609  Val_Acc: 70.815

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.5335 Train_Acc: 71.773 Val_Loss: 0.5612  BEST VAL Loss: 0.5609  Val_Acc: 69.204

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.5328 Train_Acc: 72.047 Val_Loss: 0.5612  BEST VAL Loss: 0.5609  Val_Acc: 69.693

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.5321 Train_Acc: 72.035 Val_Loss: 0.5612  BEST VAL Loss: 0.5609  Val_Acc: 69.937

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.5314 Train_Acc: 71.950 Val_Loss: 0.5612  BEST VAL Loss: 0.5609  Val_Acc: 70.083

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.5308 Train_Acc: 71.437 Val_Loss: 0.5613  BEST VAL Loss: 0.5609  Val_Acc: 69.497

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.5302 Train_Acc: 72.041 Val_Loss: 0.5611  BEST VAL Loss: 0.5609  Val_Acc: 69.253

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.5295 Train_Acc: 71.889 Val_Loss: 0.5612  BEST VAL Loss: 0.5609  Val_Acc: 69.693

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.5289 Train_Acc: 72.511 Val_Loss: 0.5614  BEST VAL Loss: 0.5609  Val_Acc: 69.888

Epoch 89: Validation loss did not decrease
Early stopped at epoch : 89
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.75      0.92      0.82      8453
           1       0.88      0.67      0.76      7939

    accuracy                           0.80     16392
   macro avg       0.81      0.79      0.79     16392
weighted avg       0.81      0.80      0.79     16392

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.67      0.82      0.74      1057
           1       0.75      0.57      0.65       992

    accuracy                           0.70      2049
   macro avg       0.71      0.70      0.70      2049
weighted avg       0.71      0.70      0.70      2049

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.67      0.84      0.75      1057
           1       0.77      0.56      0.65       992

    accuracy                           0.70      2049
   macro avg       0.72      0.70      0.70      2049
weighted avg       0.72      0.70      0.70      2049

              precision    recall  f1-score   support

           0       0.67      0.84      0.75      1057
           1       0.77      0.56      0.65       992

    accuracy                           0.70      2049
   macro avg       0.72      0.70      0.70      2049
weighted avg       0.72      0.70      0.70      2049

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.56      0.53      0.54      3835
           1       0.54      0.57      0.55      3729

    accuracy                           0.55      7564
   macro avg       0.55      0.55      0.55      7564
weighted avg       0.55      0.55      0.55      7564

              precision    recall  f1-score   support

           0       0.56      0.53      0.54      3835
           1       0.54      0.57      0.55      3729

    accuracy                           0.55      7564
   macro avg       0.55      0.55      0.55      7564
weighted avg       0.55      0.55      0.55      7564

completed
