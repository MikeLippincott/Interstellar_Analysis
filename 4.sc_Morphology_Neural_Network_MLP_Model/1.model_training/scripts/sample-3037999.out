[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '0bf89a90'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '3cdd92a9'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '94a53ce0'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '3fcdd2b1'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: DMSO_0.100_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: DMSO_0.100_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (389391, 1270)
Number of total missing values across all columns: 430260
Data Subset Is Off
Wells held out for testing: ['J06' 'L08']
Wells to use for training, validation, and testing ['B06' 'C06' 'B07' 'C07' 'I06' 'I07' 'J07' 'L02' 'L03' 'L09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.111970).  Saving model ...
	 Train_Loss: 0.2145 Train_Acc: 91.350 Val_Loss: 0.1120  BEST VAL Loss: 0.1120  Val_Acc: 96.022

Epoch 1: Validation loss decreased (0.111970 --> 0.102645).  Saving model ...
	 Train_Loss: 0.1819 Train_Acc: 94.460 Val_Loss: 0.1026  BEST VAL Loss: 0.1026  Val_Acc: 96.597

Epoch 2: Validation loss decreased (0.102645 --> 0.099084).  Saving model ...
	 Train_Loss: 0.1665 Train_Acc: 94.973 Val_Loss: 0.0991  BEST VAL Loss: 0.0991  Val_Acc: 96.709

Epoch 3: Validation loss decreased (0.099084 --> 0.095765).  Saving model ...
	 Train_Loss: 0.1572 Train_Acc: 95.264 Val_Loss: 0.0958  BEST VAL Loss: 0.0958  Val_Acc: 96.982

Epoch 4: Validation loss decreased (0.095765 --> 0.093656).  Saving model ...
	 Train_Loss: 0.1504 Train_Acc: 95.499 Val_Loss: 0.0937  BEST VAL Loss: 0.0937  Val_Acc: 97.026

Epoch 5: Validation loss decreased (0.093656 --> 0.092572).  Saving model ...
	 Train_Loss: 0.1452 Train_Acc: 95.628 Val_Loss: 0.0926  BEST VAL Loss: 0.0926  Val_Acc: 96.998

Epoch 6: Validation loss decreased (0.092572 --> 0.091764).  Saving model ...
	 Train_Loss: 0.1412 Train_Acc: 95.749 Val_Loss: 0.0918  BEST VAL Loss: 0.0918  Val_Acc: 96.979

Epoch 7: Validation loss decreased (0.091764 --> 0.090602).  Saving model ...
	 Train_Loss: 0.1377 Train_Acc: 95.901 Val_Loss: 0.0906  BEST VAL Loss: 0.0906  Val_Acc: 97.217

Epoch 8: Validation loss decreased (0.090602 --> 0.090387).  Saving model ...
	 Train_Loss: 0.1349 Train_Acc: 95.942 Val_Loss: 0.0904  BEST VAL Loss: 0.0904  Val_Acc: 96.944

Epoch 9: Validation loss decreased (0.090387 --> 0.089247).  Saving model ...
	 Train_Loss: 0.1324 Train_Acc: 96.010 Val_Loss: 0.0892  BEST VAL Loss: 0.0892  Val_Acc: 97.287

Epoch 10: Validation loss decreased (0.089247 --> 0.088077).  Saving model ...
	 Train_Loss: 0.1303 Train_Acc: 96.102 Val_Loss: 0.0881  BEST VAL Loss: 0.0881  Val_Acc: 97.338

Epoch 11: Validation loss decreased (0.088077 --> 0.087115).  Saving model ...
	 Train_Loss: 0.1284 Train_Acc: 96.171 Val_Loss: 0.0871  BEST VAL Loss: 0.0871  Val_Acc: 97.376

Epoch 12: Validation loss decreased (0.087115 --> 0.086551).  Saving model ...
	 Train_Loss: 0.1266 Train_Acc: 96.219 Val_Loss: 0.0866  BEST VAL Loss: 0.0866  Val_Acc: 97.379

Epoch 13: Validation loss decreased (0.086551 --> 0.085938).  Saving model ...
	 Train_Loss: 0.1251 Train_Acc: 96.256 Val_Loss: 0.0859  BEST VAL Loss: 0.0859  Val_Acc: 97.338

Epoch 14: Validation loss decreased (0.085938 --> 0.085621).  Saving model ...
	 Train_Loss: 0.1237 Train_Acc: 96.308 Val_Loss: 0.0856  BEST VAL Loss: 0.0856  Val_Acc: 97.239

Epoch 15: Validation loss decreased (0.085621 --> 0.085092).  Saving model ...
	 Train_Loss: 0.1223 Train_Acc: 96.341 Val_Loss: 0.0851  BEST VAL Loss: 0.0851  Val_Acc: 97.408

Epoch 16: Validation loss decreased (0.085092 --> 0.084409).  Saving model ...
	 Train_Loss: 0.1211 Train_Acc: 96.354 Val_Loss: 0.0844  BEST VAL Loss: 0.0844  Val_Acc: 97.525

Epoch 17: Validation loss decreased (0.084409 --> 0.083824).  Saving model ...
	 Train_Loss: 0.1200 Train_Acc: 96.409 Val_Loss: 0.0838  BEST VAL Loss: 0.0838  Val_Acc: 97.481

Epoch 18: Validation loss decreased (0.083824 --> 0.083248).  Saving model ...
	 Train_Loss: 0.1190 Train_Acc: 96.413 Val_Loss: 0.0832  BEST VAL Loss: 0.0832  Val_Acc: 97.531

Epoch 19: Validation loss decreased (0.083248 --> 0.082840).  Saving model ...
	 Train_Loss: 0.1181 Train_Acc: 96.483 Val_Loss: 0.0828  BEST VAL Loss: 0.0828  Val_Acc: 97.477

Epoch 20: Validation loss decreased (0.082840 --> 0.082387).  Saving model ...
	 Train_Loss: 0.1172 Train_Acc: 96.530 Val_Loss: 0.0824  BEST VAL Loss: 0.0824  Val_Acc: 97.535

Epoch 21: Validation loss decreased (0.082387 --> 0.081947).  Saving model ...
	 Train_Loss: 0.1163 Train_Acc: 96.480 Val_Loss: 0.0819  BEST VAL Loss: 0.0819  Val_Acc: 97.525

Epoch 22: Validation loss decreased (0.081947 --> 0.081621).  Saving model ...
	 Train_Loss: 0.1155 Train_Acc: 96.515 Val_Loss: 0.0816  BEST VAL Loss: 0.0816  Val_Acc: 97.525

Epoch 23: Validation loss decreased (0.081621 --> 0.081203).  Saving model ...
	 Train_Loss: 0.1148 Train_Acc: 96.499 Val_Loss: 0.0812  BEST VAL Loss: 0.0812  Val_Acc: 97.551

Epoch 24: Validation loss decreased (0.081203 --> 0.080816).  Saving model ...
	 Train_Loss: 0.1141 Train_Acc: 96.569 Val_Loss: 0.0808  BEST VAL Loss: 0.0808  Val_Acc: 97.535

Epoch 25: Validation loss decreased (0.080816 --> 0.080471).  Saving model ...
	 Train_Loss: 0.1134 Train_Acc: 96.589 Val_Loss: 0.0805  BEST VAL Loss: 0.0805  Val_Acc: 97.528

Epoch 26: Validation loss decreased (0.080471 --> 0.080123).  Saving model ...
	 Train_Loss: 0.1128 Train_Acc: 96.592 Val_Loss: 0.0801  BEST VAL Loss: 0.0801  Val_Acc: 97.582

Epoch 27: Validation loss decreased (0.080123 --> 0.079885).  Saving model ...
	 Train_Loss: 0.1122 Train_Acc: 96.623 Val_Loss: 0.0799  BEST VAL Loss: 0.0799  Val_Acc: 97.535

Epoch 28: Validation loss decreased (0.079885 --> 0.079708).  Saving model ...
	 Train_Loss: 0.1116 Train_Acc: 96.683 Val_Loss: 0.0797  BEST VAL Loss: 0.0797  Val_Acc: 97.388

Epoch 29: Validation loss decreased (0.079708 --> 0.079519).  Saving model ...
	 Train_Loss: 0.1110 Train_Acc: 96.709 Val_Loss: 0.0795  BEST VAL Loss: 0.0795  Val_Acc: 97.490

Epoch 30: Validation loss decreased (0.079519 --> 0.079257).  Saving model ...
	 Train_Loss: 0.1104 Train_Acc: 96.682 Val_Loss: 0.0793  BEST VAL Loss: 0.0793  Val_Acc: 97.611

Epoch 31: Validation loss decreased (0.079257 --> 0.079085).  Saving model ...
	 Train_Loss: 0.1099 Train_Acc: 96.748 Val_Loss: 0.0791  BEST VAL Loss: 0.0791  Val_Acc: 97.512

Epoch 32: Validation loss decreased (0.079085 --> 0.078873).  Saving model ...
	 Train_Loss: 0.1094 Train_Acc: 96.706 Val_Loss: 0.0789  BEST VAL Loss: 0.0789  Val_Acc: 97.582

Epoch 33: Validation loss decreased (0.078873 --> 0.078634).  Saving model ...
	 Train_Loss: 0.1089 Train_Acc: 96.728 Val_Loss: 0.0786  BEST VAL Loss: 0.0786  Val_Acc: 97.589

Epoch 34: Validation loss decreased (0.078634 --> 0.078452).  Saving model ...
	 Train_Loss: 0.1084 Train_Acc: 96.741 Val_Loss: 0.0785  BEST VAL Loss: 0.0785  Val_Acc: 97.551

Epoch 35: Validation loss decreased (0.078452 --> 0.078298).  Saving model ...
	 Train_Loss: 0.1080 Train_Acc: 96.766 Val_Loss: 0.0783  BEST VAL Loss: 0.0783  Val_Acc: 97.655

Epoch 36: Validation loss decreased (0.078298 --> 0.078122).  Saving model ...
	 Train_Loss: 0.1075 Train_Acc: 96.778 Val_Loss: 0.0781  BEST VAL Loss: 0.0781  Val_Acc: 97.582

Epoch 37: Validation loss decreased (0.078122 --> 0.077963).  Saving model ...
	 Train_Loss: 0.1071 Train_Acc: 96.776 Val_Loss: 0.0780  BEST VAL Loss: 0.0780  Val_Acc: 97.605

Epoch 38: Validation loss decreased (0.077963 --> 0.077787).  Saving model ...
	 Train_Loss: 0.1067 Train_Acc: 96.809 Val_Loss: 0.0778  BEST VAL Loss: 0.0778  Val_Acc: 97.620

Epoch 39: Validation loss decreased (0.077787 --> 0.077609).  Saving model ...
	 Train_Loss: 0.1063 Train_Acc: 96.846 Val_Loss: 0.0776  BEST VAL Loss: 0.0776  Val_Acc: 97.659

Epoch 40: Validation loss decreased (0.077609 --> 0.077447).  Saving model ...
	 Train_Loss: 0.1059 Train_Acc: 96.826 Val_Loss: 0.0774  BEST VAL Loss: 0.0774  Val_Acc: 97.665

Epoch 41: Validation loss decreased (0.077447 --> 0.077321).  Saving model ...
	 Train_Loss: 0.1055 Train_Acc: 96.856 Val_Loss: 0.0773  BEST VAL Loss: 0.0773  Val_Acc: 97.617

Epoch 42: Validation loss decreased (0.077321 --> 0.077183).  Saving model ...
	 Train_Loss: 0.1052 Train_Acc: 96.884 Val_Loss: 0.0772  BEST VAL Loss: 0.0772  Val_Acc: 97.652

Epoch 43: Validation loss decreased (0.077183 --> 0.077059).  Saving model ...
	 Train_Loss: 0.1048 Train_Acc: 96.881 Val_Loss: 0.0771  BEST VAL Loss: 0.0771  Val_Acc: 97.624

Epoch 44: Validation loss decreased (0.077059 --> 0.076899).  Saving model ...
	 Train_Loss: 0.1045 Train_Acc: 96.908 Val_Loss: 0.0769  BEST VAL Loss: 0.0769  Val_Acc: 97.684

Epoch 45: Validation loss decreased (0.076899 --> 0.076722).  Saving model ...
	 Train_Loss: 0.1041 Train_Acc: 96.902 Val_Loss: 0.0767  BEST VAL Loss: 0.0767  Val_Acc: 97.779

Epoch 46: Validation loss decreased (0.076722 --> 0.076619).  Saving model ...
	 Train_Loss: 0.1038 Train_Acc: 96.856 Val_Loss: 0.0766  BEST VAL Loss: 0.0766  Val_Acc: 97.605

Epoch 47: Validation loss decreased (0.076619 --> 0.076526).  Saving model ...
	 Train_Loss: 0.1035 Train_Acc: 96.877 Val_Loss: 0.0765  BEST VAL Loss: 0.0765  Val_Acc: 97.643

Epoch 48: Validation loss decreased (0.076526 --> 0.076408).  Saving model ...
	 Train_Loss: 0.1032 Train_Acc: 96.900 Val_Loss: 0.0764  BEST VAL Loss: 0.0764  Val_Acc: 97.713

Epoch 49: Validation loss decreased (0.076408 --> 0.076270).  Saving model ...
	 Train_Loss: 0.1029 Train_Acc: 96.890 Val_Loss: 0.0763  BEST VAL Loss: 0.0763  Val_Acc: 97.751

Epoch 50: Validation loss decreased (0.076270 --> 0.076227).  Saving model ...
	 Train_Loss: 0.1026 Train_Acc: 96.928 Val_Loss: 0.0762  BEST VAL Loss: 0.0762  Val_Acc: 97.538

Epoch 51: Validation loss decreased (0.076227 --> 0.076175).  Saving model ...
	 Train_Loss: 0.1023 Train_Acc: 96.942 Val_Loss: 0.0762  BEST VAL Loss: 0.0762  Val_Acc: 97.652

Epoch 52: Validation loss decreased (0.076175 --> 0.076100).  Saving model ...
	 Train_Loss: 0.1021 Train_Acc: 96.966 Val_Loss: 0.0761  BEST VAL Loss: 0.0761  Val_Acc: 97.636

Epoch 53: Validation loss decreased (0.076100 --> 0.076034).  Saving model ...
	 Train_Loss: 0.1018 Train_Acc: 96.956 Val_Loss: 0.0760  BEST VAL Loss: 0.0760  Val_Acc: 97.706

Epoch 54: Validation loss decreased (0.076034 --> 0.075975).  Saving model ...
	 Train_Loss: 0.1015 Train_Acc: 96.941 Val_Loss: 0.0760  BEST VAL Loss: 0.0760  Val_Acc: 97.659

Epoch 55: Validation loss decreased (0.075975 --> 0.075879).  Saving model ...
	 Train_Loss: 0.1013 Train_Acc: 96.996 Val_Loss: 0.0759  BEST VAL Loss: 0.0759  Val_Acc: 97.690

Epoch 56: Validation loss decreased (0.075879 --> 0.075795).  Saving model ...
	 Train_Loss: 0.1010 Train_Acc: 96.977 Val_Loss: 0.0758  BEST VAL Loss: 0.0758  Val_Acc: 97.716

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.1008 Train_Acc: 97.004 Val_Loss: 0.0758  BEST VAL Loss: 0.0758  Val_Acc: 97.497

Epoch 58: Validation loss decreased (0.075795 --> 0.075750).  Saving model ...
	 Train_Loss: 0.1005 Train_Acc: 96.925 Val_Loss: 0.0757  BEST VAL Loss: 0.0757  Val_Acc: 97.690

Epoch 59: Validation loss decreased (0.075750 --> 0.075675).  Saving model ...
	 Train_Loss: 0.1003 Train_Acc: 97.003 Val_Loss: 0.0757  BEST VAL Loss: 0.0757  Val_Acc: 97.674

Epoch 60: Validation loss decreased (0.075675 --> 0.075619).  Saving model ...
	 Train_Loss: 0.1001 Train_Acc: 96.971 Val_Loss: 0.0756  BEST VAL Loss: 0.0756  Val_Acc: 97.668

Epoch 61: Validation loss decreased (0.075619 --> 0.075539).  Saving model ...
	 Train_Loss: 0.0999 Train_Acc: 96.985 Val_Loss: 0.0755  BEST VAL Loss: 0.0755  Val_Acc: 97.738

Epoch 62: Validation loss decreased (0.075539 --> 0.075478).  Saving model ...
	 Train_Loss: 0.0996 Train_Acc: 97.008 Val_Loss: 0.0755  BEST VAL Loss: 0.0755  Val_Acc: 97.697

Epoch 63: Validation loss decreased (0.075478 --> 0.075406).  Saving model ...
	 Train_Loss: 0.0994 Train_Acc: 96.981 Val_Loss: 0.0754  BEST VAL Loss: 0.0754  Val_Acc: 97.700

Epoch 64: Validation loss decreased (0.075406 --> 0.075342).  Saving model ...
	 Train_Loss: 0.0992 Train_Acc: 97.039 Val_Loss: 0.0753  BEST VAL Loss: 0.0753  Val_Acc: 97.671

Epoch 65: Validation loss decreased (0.075342 --> 0.075294).  Saving model ...
	 Train_Loss: 0.0990 Train_Acc: 97.051 Val_Loss: 0.0753  BEST VAL Loss: 0.0753  Val_Acc: 97.716

Epoch 66: Validation loss decreased (0.075294 --> 0.075211).  Saving model ...
	 Train_Loss: 0.0988 Train_Acc: 97.020 Val_Loss: 0.0752  BEST VAL Loss: 0.0752  Val_Acc: 97.779

Epoch 67: Validation loss decreased (0.075211 --> 0.075135).  Saving model ...
	 Train_Loss: 0.0986 Train_Acc: 97.083 Val_Loss: 0.0751  BEST VAL Loss: 0.0751  Val_Acc: 97.678

Epoch 68: Validation loss decreased (0.075135 --> 0.075082).  Saving model ...
	 Train_Loss: 0.0984 Train_Acc: 97.018 Val_Loss: 0.0751  BEST VAL Loss: 0.0751  Val_Acc: 97.719

Epoch 69: Validation loss decreased (0.075082 --> 0.075041).  Saving model ...
	 Train_Loss: 0.0982 Train_Acc: 97.041 Val_Loss: 0.0750  BEST VAL Loss: 0.0750  Val_Acc: 97.662

Epoch 70: Validation loss decreased (0.075041 --> 0.075020).  Saving model ...
	 Train_Loss: 0.0980 Train_Acc: 97.044 Val_Loss: 0.0750  BEST VAL Loss: 0.0750  Val_Acc: 97.706

Epoch 71: Validation loss decreased (0.075020 --> 0.074951).  Saving model ...
	 Train_Loss: 0.0978 Train_Acc: 97.052 Val_Loss: 0.0750  BEST VAL Loss: 0.0750  Val_Acc: 97.760

Epoch 72: Validation loss decreased (0.074951 --> 0.074898).  Saving model ...
	 Train_Loss: 0.0977 Train_Acc: 97.090 Val_Loss: 0.0749  BEST VAL Loss: 0.0749  Val_Acc: 97.674

Epoch 73: Validation loss decreased (0.074898 --> 0.074888).  Saving model ...
	 Train_Loss: 0.0975 Train_Acc: 97.108 Val_Loss: 0.0749  BEST VAL Loss: 0.0749  Val_Acc: 97.589

Epoch 74: Validation loss decreased (0.074888 --> 0.074860).  Saving model ...
	 Train_Loss: 0.0973 Train_Acc: 97.111 Val_Loss: 0.0749  BEST VAL Loss: 0.0749  Val_Acc: 97.690

Epoch 75: Validation loss decreased (0.074860 --> 0.074838).  Saving model ...
	 Train_Loss: 0.0971 Train_Acc: 97.103 Val_Loss: 0.0748  BEST VAL Loss: 0.0748  Val_Acc: 97.706

Epoch 76: Validation loss decreased (0.074838 --> 0.074809).  Saving model ...
	 Train_Loss: 0.0969 Train_Acc: 97.127 Val_Loss: 0.0748  BEST VAL Loss: 0.0748  Val_Acc: 97.684

Epoch 77: Validation loss decreased (0.074809 --> 0.074794).  Saving model ...
	 Train_Loss: 0.0968 Train_Acc: 97.108 Val_Loss: 0.0748  BEST VAL Loss: 0.0748  Val_Acc: 97.585

Epoch 78: Validation loss decreased (0.074794 --> 0.074792).  Saving model ...
	 Train_Loss: 0.0966 Train_Acc: 97.096 Val_Loss: 0.0748  BEST VAL Loss: 0.0748  Val_Acc: 97.662

Epoch 79: Validation loss decreased (0.074792 --> 0.074747).  Saving model ...
	 Train_Loss: 0.0964 Train_Acc: 97.075 Val_Loss: 0.0747  BEST VAL Loss: 0.0747  Val_Acc: 97.782

Epoch 80: Validation loss decreased (0.074747 --> 0.074739).  Saving model ...
	 Train_Loss: 0.0963 Train_Acc: 97.118 Val_Loss: 0.0747  BEST VAL Loss: 0.0747  Val_Acc: 97.646

Epoch 81: Validation loss decreased (0.074739 --> 0.074704).  Saving model ...
	 Train_Loss: 0.0961 Train_Acc: 97.124 Val_Loss: 0.0747  BEST VAL Loss: 0.0747  Val_Acc: 97.770

Epoch 82: Validation loss decreased (0.074704 --> 0.074688).  Saving model ...
	 Train_Loss: 0.0960 Train_Acc: 97.125 Val_Loss: 0.0747  BEST VAL Loss: 0.0747  Val_Acc: 97.668

Epoch 83: Validation loss decreased (0.074688 --> 0.074681).  Saving model ...
	 Train_Loss: 0.0958 Train_Acc: 97.114 Val_Loss: 0.0747  BEST VAL Loss: 0.0747  Val_Acc: 97.662

Epoch 84: Validation loss decreased (0.074681 --> 0.074635).  Saving model ...
	 Train_Loss: 0.0957 Train_Acc: 97.121 Val_Loss: 0.0746  BEST VAL Loss: 0.0746  Val_Acc: 97.693

Epoch 85: Validation loss decreased (0.074635 --> 0.074595).  Saving model ...
	 Train_Loss: 0.0955 Train_Acc: 97.167 Val_Loss: 0.0746  BEST VAL Loss: 0.0746  Val_Acc: 97.700

Epoch 86: Validation loss decreased (0.074595 --> 0.074561).  Saving model ...
	 Train_Loss: 0.0954 Train_Acc: 97.109 Val_Loss: 0.0746  BEST VAL Loss: 0.0746  Val_Acc: 97.773

Epoch 87: Validation loss decreased (0.074561 --> 0.074521).  Saving model ...
	 Train_Loss: 0.0952 Train_Acc: 97.176 Val_Loss: 0.0745  BEST VAL Loss: 0.0745  Val_Acc: 97.741

Epoch 88: Validation loss decreased (0.074521 --> 0.074474).  Saving model ...
	 Train_Loss: 0.0951 Train_Acc: 97.123 Val_Loss: 0.0745  BEST VAL Loss: 0.0745  Val_Acc: 97.782

Epoch 89: Validation loss decreased (0.074474 --> 0.074446).  Saving model ...
	 Train_Loss: 0.0950 Train_Acc: 97.161 Val_Loss: 0.0744  BEST VAL Loss: 0.0744  Val_Acc: 97.668

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.0948 Train_Acc: 97.184 Val_Loss: 0.0745  BEST VAL Loss: 0.0744  Val_Acc: 97.620

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.0947 Train_Acc: 97.185 Val_Loss: 0.0745  BEST VAL Loss: 0.0744  Val_Acc: 97.713

Epoch 92: Validation loss decreased (0.074446 --> 0.074441).  Saving model ...
	 Train_Loss: 0.0945 Train_Acc: 97.178 Val_Loss: 0.0744  BEST VAL Loss: 0.0744  Val_Acc: 97.732

Epoch 93: Validation loss decreased (0.074441 --> 0.074420).  Saving model ...
	 Train_Loss: 0.0944 Train_Acc: 97.195 Val_Loss: 0.0744  BEST VAL Loss: 0.0744  Val_Acc: 97.652

Epoch 94: Validation loss decreased (0.074420 --> 0.074410).  Saving model ...
	 Train_Loss: 0.0943 Train_Acc: 97.160 Val_Loss: 0.0744  BEST VAL Loss: 0.0744  Val_Acc: 97.713

Epoch 95: Validation loss decreased (0.074410 --> 0.074387).  Saving model ...
	 Train_Loss: 0.0941 Train_Acc: 97.170 Val_Loss: 0.0744  BEST VAL Loss: 0.0744  Val_Acc: 97.716

Epoch 96: Validation loss decreased (0.074387 --> 0.074371).  Saving model ...
	 Train_Loss: 0.0940 Train_Acc: 97.175 Val_Loss: 0.0744  BEST VAL Loss: 0.0744  Val_Acc: 97.767

Epoch 97: Validation loss decreased (0.074371 --> 0.074343).  Saving model ...
	 Train_Loss: 0.0939 Train_Acc: 97.140 Val_Loss: 0.0743  BEST VAL Loss: 0.0743  Val_Acc: 97.735

Epoch 98: Validation loss decreased (0.074343 --> 0.074332).  Saving model ...
	 Train_Loss: 0.0938 Train_Acc: 97.166 Val_Loss: 0.0743  BEST VAL Loss: 0.0743  Val_Acc: 97.716

Epoch 99: Validation loss decreased (0.074332 --> 0.074298).  Saving model ...
	 Train_Loss: 0.0937 Train_Acc: 97.184 Val_Loss: 0.0743  BEST VAL Loss: 0.0743  Val_Acc: 97.776

DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      0.98      0.99    149884
           1       0.97      0.98      0.98    101922

    accuracy                           0.98    251806
   macro avg       0.98      0.98      0.98    251806
weighted avg       0.98      0.98      0.98    251806

DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.98      0.98     18736
           1       0.97      0.98      0.97     12740

    accuracy                           0.98     31476
   macro avg       0.98      0.98      0.98     31476
weighted avg       0.98      0.98      0.98     31476

DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.98      0.98     18736
           1       0.97      0.97      0.97     12740

    accuracy                           0.98     31476
   macro avg       0.97      0.98      0.97     31476
weighted avg       0.98      0.98      0.98     31476

              precision    recall  f1-score   support

           0       0.98      0.98      0.98     18736
           1       0.97      0.97      0.97     12740

    accuracy                           0.98     31476
   macro avg       0.97      0.98      0.97     31476
weighted avg       0.98      0.98      0.98     31476

DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.73      1.00      0.85     27774
           1       1.00      0.79      0.88     46859

    accuracy                           0.86     74633
   macro avg       0.87      0.89      0.86     74633
weighted avg       0.90      0.86      0.87     74633

              precision    recall  f1-score   support

           0       0.73      1.00      0.85     27774
           1       1.00      0.79      0.88     46859

    accuracy                           0.86     74633
   macro avg       0.87      0.89      0.86     74633
weighted avg       0.90      0.86      0.87     74633

completed
