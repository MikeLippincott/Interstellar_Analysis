[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b74fc841'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'fb48cf30'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '419e0d7b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'baa7f3ef'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Flagellin_1.000_DMSO_0.025 treatment_name: DMSO_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Flagellin_1.000_DMSO_0.025
TREATMENT_NAME: DMSO_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (319677, 1270)
Number of total missing values across all columns: 675970
Data Subset Is Off
Wells held out for testing: ['J06' 'M10']
Wells to use for training, validation, and testing ['B06' 'C06' 'B07' 'C07' 'I06' 'I07' 'J07' 'M05' 'M11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.450131).  Saving model ...
	 Train_Loss: 0.5335 Train_Acc: 74.788 Val_Loss: 0.4501  BEST VAL Loss: 0.4501  Val_Acc: 79.849

Epoch 1: Validation loss decreased (0.450131 --> 0.409241).  Saving model ...
	 Train_Loss: 0.4798 Train_Acc: 81.027 Val_Loss: 0.4092  BEST VAL Loss: 0.4092  Val_Acc: 84.614

Epoch 2: Validation loss decreased (0.409241 --> 0.401850).  Saving model ...
	 Train_Loss: 0.4465 Train_Acc: 83.323 Val_Loss: 0.4019  BEST VAL Loss: 0.4019  Val_Acc: 82.540

Epoch 3: Validation loss did not decrease
	 Train_Loss: 0.4241 Train_Acc: 84.385 Val_Loss: 0.4056  BEST VAL Loss: 0.4019  Val_Acc: 81.562

Epoch 4: Validation loss decreased (0.401850 --> 0.387140).  Saving model ...
	 Train_Loss: 0.4073 Train_Acc: 85.142 Val_Loss: 0.3871  BEST VAL Loss: 0.3871  Val_Acc: 86.125

Epoch 5: Validation loss decreased (0.387140 --> 0.374137).  Saving model ...
	 Train_Loss: 0.3942 Train_Acc: 85.596 Val_Loss: 0.3741  BEST VAL Loss: 0.3741  Val_Acc: 86.727

Epoch 6: Validation loss decreased (0.374137 --> 0.364128).  Saving model ...
	 Train_Loss: 0.3833 Train_Acc: 86.191 Val_Loss: 0.3641  BEST VAL Loss: 0.3641  Val_Acc: 87.026

Epoch 7: Validation loss decreased (0.364128 --> 0.356504).  Saving model ...
	 Train_Loss: 0.3745 Train_Acc: 86.427 Val_Loss: 0.3565  BEST VAL Loss: 0.3565  Val_Acc: 87.088

Epoch 8: Validation loss decreased (0.356504 --> 0.352255).  Saving model ...
	 Train_Loss: 0.3669 Train_Acc: 86.716 Val_Loss: 0.3523  BEST VAL Loss: 0.3523  Val_Acc: 86.272

Epoch 9: Validation loss decreased (0.352255 --> 0.345446).  Saving model ...
	 Train_Loss: 0.3605 Train_Acc: 86.834 Val_Loss: 0.3454  BEST VAL Loss: 0.3454  Val_Acc: 87.756

Epoch 10: Validation loss decreased (0.345446 --> 0.338363).  Saving model ...
	 Train_Loss: 0.3549 Train_Acc: 86.987 Val_Loss: 0.3384  BEST VAL Loss: 0.3384  Val_Acc: 88.610

Epoch 11: Validation loss decreased (0.338363 --> 0.331969).  Saving model ...
	 Train_Loss: 0.3497 Train_Acc: 87.306 Val_Loss: 0.3320  BEST VAL Loss: 0.3320  Val_Acc: 88.754

Epoch 12: Validation loss decreased (0.331969 --> 0.330336).  Saving model ...
	 Train_Loss: 0.3452 Train_Acc: 87.423 Val_Loss: 0.3303  BEST VAL Loss: 0.3303  Val_Acc: 86.692

Epoch 13: Validation loss decreased (0.330336 --> 0.328942).  Saving model ...
	 Train_Loss: 0.3412 Train_Acc: 87.506 Val_Loss: 0.3289  BEST VAL Loss: 0.3289  Val_Acc: 86.824

Epoch 14: Validation loss decreased (0.328942 --> 0.323805).  Saving model ...
	 Train_Loss: 0.3375 Train_Acc: 87.596 Val_Loss: 0.3238  BEST VAL Loss: 0.3238  Val_Acc: 89.204

Epoch 15: Validation loss did not decrease
	 Train_Loss: 0.3341 Train_Acc: 87.784 Val_Loss: 0.3336  BEST VAL Loss: 0.3238  Val_Acc: 83.309

Epoch 16: Validation loss did not decrease
	 Train_Loss: 0.3312 Train_Acc: 87.796 Val_Loss: 0.3286  BEST VAL Loss: 0.3238  Val_Acc: 89.290

Epoch 17: Validation loss did not decrease
	 Train_Loss: 0.3283 Train_Acc: 87.862 Val_Loss: 0.3244  BEST VAL Loss: 0.3238  Val_Acc: 89.204

Epoch 18: Validation loss decreased (0.323805 --> 0.320241).  Saving model ...
	 Train_Loss: 0.3257 Train_Acc: 87.996 Val_Loss: 0.3202  BEST VAL Loss: 0.3202  Val_Acc: 89.569

Epoch 19: Validation loss did not decrease
	 Train_Loss: 0.3233 Train_Acc: 88.087 Val_Loss: 0.3227  BEST VAL Loss: 0.3202  Val_Acc: 85.612

Epoch 20: Validation loss decreased (0.320241 --> 0.319038).  Saving model ...
	 Train_Loss: 0.3210 Train_Acc: 88.167 Val_Loss: 0.3190  BEST VAL Loss: 0.3190  Val_Acc: 89.445

Epoch 21: Validation loss did not decrease
	 Train_Loss: 0.3189 Train_Acc: 88.194 Val_Loss: 0.3202  BEST VAL Loss: 0.3190  Val_Acc: 87.092

Epoch 22: Validation loss decreased (0.319038 --> 0.316792).  Saving model ...
	 Train_Loss: 0.3169 Train_Acc: 88.237 Val_Loss: 0.3168  BEST VAL Loss: 0.3168  Val_Acc: 89.697

Epoch 23: Validation loss decreased (0.316792 --> 0.313610).  Saving model ...
	 Train_Loss: 0.3150 Train_Acc: 88.457 Val_Loss: 0.3136  BEST VAL Loss: 0.3136  Val_Acc: 89.732

Epoch 24: Validation loss decreased (0.313610 --> 0.311288).  Saving model ...
	 Train_Loss: 0.3131 Train_Acc: 88.553 Val_Loss: 0.3113  BEST VAL Loss: 0.3113  Val_Acc: 88.983

Epoch 25: Validation loss decreased (0.311288 --> 0.308523).  Saving model ...
	 Train_Loss: 0.3114 Train_Acc: 88.629 Val_Loss: 0.3085  BEST VAL Loss: 0.3085  Val_Acc: 89.779

Epoch 26: Validation loss decreased (0.308523 --> 0.305998).  Saving model ...
	 Train_Loss: 0.3097 Train_Acc: 88.591 Val_Loss: 0.3060  BEST VAL Loss: 0.3060  Val_Acc: 89.732

Epoch 27: Validation loss decreased (0.305998 --> 0.303485).  Saving model ...
	 Train_Loss: 0.3082 Train_Acc: 88.727 Val_Loss: 0.3035  BEST VAL Loss: 0.3035  Val_Acc: 90.051

Epoch 28: Validation loss decreased (0.303485 --> 0.302448).  Saving model ...
	 Train_Loss: 0.3067 Train_Acc: 88.641 Val_Loss: 0.3024  BEST VAL Loss: 0.3024  Val_Acc: 88.591

Epoch 29: Validation loss decreased (0.302448 --> 0.300286).  Saving model ...
	 Train_Loss: 0.3053 Train_Acc: 88.757 Val_Loss: 0.3003  BEST VAL Loss: 0.3003  Val_Acc: 89.868

Epoch 30: Validation loss decreased (0.300286 --> 0.298144).  Saving model ...
	 Train_Loss: 0.3039 Train_Acc: 88.768 Val_Loss: 0.2981  BEST VAL Loss: 0.2981  Val_Acc: 89.969

Epoch 31: Validation loss decreased (0.298144 --> 0.296125).  Saving model ...
	 Train_Loss: 0.3027 Train_Acc: 88.751 Val_Loss: 0.2961  BEST VAL Loss: 0.2961  Val_Acc: 90.222

Epoch 32: Validation loss decreased (0.296125 --> 0.294522).  Saving model ...
	 Train_Loss: 0.3014 Train_Acc: 88.937 Val_Loss: 0.2945  BEST VAL Loss: 0.2945  Val_Acc: 89.845

Epoch 33: Validation loss decreased (0.294522 --> 0.292781).  Saving model ...
	 Train_Loss: 0.3002 Train_Acc: 88.844 Val_Loss: 0.2928  BEST VAL Loss: 0.2928  Val_Acc: 90.160

Epoch 34: Validation loss decreased (0.292781 --> 0.291300).  Saving model ...
	 Train_Loss: 0.2991 Train_Acc: 88.935 Val_Loss: 0.2913  BEST VAL Loss: 0.2913  Val_Acc: 89.628

Epoch 35: Validation loss decreased (0.291300 --> 0.289520).  Saving model ...
	 Train_Loss: 0.2980 Train_Acc: 88.910 Val_Loss: 0.2895  BEST VAL Loss: 0.2895  Val_Acc: 90.389

Epoch 36: Validation loss decreased (0.289520 --> 0.288194).  Saving model ...
	 Train_Loss: 0.2969 Train_Acc: 88.963 Val_Loss: 0.2882  BEST VAL Loss: 0.2882  Val_Acc: 89.721

Epoch 37: Validation loss decreased (0.288194 --> 0.286590).  Saving model ...
	 Train_Loss: 0.2959 Train_Acc: 88.997 Val_Loss: 0.2866  BEST VAL Loss: 0.2866  Val_Acc: 90.330

Epoch 38: Validation loss decreased (0.286590 --> 0.285340).  Saving model ...
	 Train_Loss: 0.2950 Train_Acc: 89.079 Val_Loss: 0.2853  BEST VAL Loss: 0.2853  Val_Acc: 89.670

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.2940 Train_Acc: 89.063 Val_Loss: 0.2875  BEST VAL Loss: 0.2853  Val_Acc: 87.399

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.2931 Train_Acc: 88.967 Val_Loss: 0.2864  BEST VAL Loss: 0.2853  Val_Acc: 89.597

Epoch 41: Validation loss decreased (0.285340 --> 0.285076).  Saving model ...
	 Train_Loss: 0.2923 Train_Acc: 89.105 Val_Loss: 0.2851  BEST VAL Loss: 0.2851  Val_Acc: 90.303

Epoch 42: Validation loss decreased (0.285076 --> 0.283986).  Saving model ...
	 Train_Loss: 0.2914 Train_Acc: 89.105 Val_Loss: 0.2840  BEST VAL Loss: 0.2840  Val_Acc: 89.814

Epoch 43: Validation loss decreased (0.283986 --> 0.282629).  Saving model ...
	 Train_Loss: 0.2906 Train_Acc: 89.157 Val_Loss: 0.2826  BEST VAL Loss: 0.2826  Val_Acc: 90.319

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.2898 Train_Acc: 89.176 Val_Loss: 0.2842  BEST VAL Loss: 0.2826  Val_Acc: 86.346

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.2891 Train_Acc: 89.118 Val_Loss: 0.2829  BEST VAL Loss: 0.2826  Val_Acc: 90.319

Epoch 46: Validation loss decreased (0.282629 --> 0.282241).  Saving model ...
	 Train_Loss: 0.2883 Train_Acc: 89.267 Val_Loss: 0.2822  BEST VAL Loss: 0.2822  Val_Acc: 89.371

Epoch 47: Validation loss decreased (0.282241 --> 0.281014).  Saving model ...
	 Train_Loss: 0.2876 Train_Acc: 89.169 Val_Loss: 0.2810  BEST VAL Loss: 0.2810  Val_Acc: 90.455

Epoch 48: Validation loss decreased (0.281014 --> 0.280230).  Saving model ...
	 Train_Loss: 0.2869 Train_Acc: 89.252 Val_Loss: 0.2802  BEST VAL Loss: 0.2802  Val_Acc: 89.864

Epoch 49: Validation loss decreased (0.280230 --> 0.279239).  Saving model ...
	 Train_Loss: 0.2862 Train_Acc: 89.178 Val_Loss: 0.2792  BEST VAL Loss: 0.2792  Val_Acc: 90.482

Epoch 50: Validation loss decreased (0.279239 --> 0.278193).  Saving model ...
	 Train_Loss: 0.2855 Train_Acc: 89.297 Val_Loss: 0.2782  BEST VAL Loss: 0.2782  Val_Acc: 90.268

Epoch 51: Validation loss decreased (0.278193 --> 0.277435).  Saving model ...
	 Train_Loss: 0.2849 Train_Acc: 89.320 Val_Loss: 0.2774  BEST VAL Loss: 0.2774  Val_Acc: 89.554

Epoch 52: Validation loss decreased (0.277435 --> 0.276992).  Saving model ...
	 Train_Loss: 0.2843 Train_Acc: 89.315 Val_Loss: 0.2770  BEST VAL Loss: 0.2770  Val_Acc: 89.410

Epoch 53: Validation loss decreased (0.276992 --> 0.275918).  Saving model ...
	 Train_Loss: 0.2837 Train_Acc: 89.248 Val_Loss: 0.2759  BEST VAL Loss: 0.2759  Val_Acc: 90.758

Epoch 54: Validation loss decreased (0.275918 --> 0.274890).  Saving model ...
	 Train_Loss: 0.2830 Train_Acc: 89.425 Val_Loss: 0.2749  BEST VAL Loss: 0.2749  Val_Acc: 90.672

Epoch 55: Validation loss decreased (0.274890 --> 0.274136).  Saving model ...
	 Train_Loss: 0.2824 Train_Acc: 89.388 Val_Loss: 0.2741  BEST VAL Loss: 0.2741  Val_Acc: 90.206

Epoch 56: Validation loss decreased (0.274136 --> 0.273231).  Saving model ...
	 Train_Loss: 0.2819 Train_Acc: 89.423 Val_Loss: 0.2732  BEST VAL Loss: 0.2732  Val_Acc: 90.591

Epoch 57: Validation loss decreased (0.273231 --> 0.273162).  Saving model ...
	 Train_Loss: 0.2813 Train_Acc: 89.400 Val_Loss: 0.2732  BEST VAL Loss: 0.2732  Val_Acc: 89.065

Epoch 58: Validation loss decreased (0.273162 --> 0.272282).  Saving model ...
	 Train_Loss: 0.2808 Train_Acc: 89.392 Val_Loss: 0.2723  BEST VAL Loss: 0.2723  Val_Acc: 90.637

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.2803 Train_Acc: 89.371 Val_Loss: 0.2736  BEST VAL Loss: 0.2723  Val_Acc: 87.200

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.2798 Train_Acc: 89.392 Val_Loss: 0.2727  BEST VAL Loss: 0.2723  Val_Acc: 90.626

Epoch 61: Validation loss decreased (0.272282 --> 0.271898).  Saving model ...
	 Train_Loss: 0.2793 Train_Acc: 89.402 Val_Loss: 0.2719  BEST VAL Loss: 0.2719  Val_Acc: 90.595

Epoch 62: Validation loss decreased (0.271898 --> 0.271082).  Saving model ...
	 Train_Loss: 0.2788 Train_Acc: 89.537 Val_Loss: 0.2711  BEST VAL Loss: 0.2711  Val_Acc: 90.571

Epoch 63: Validation loss decreased (0.271082 --> 0.270310).  Saving model ...
	 Train_Loss: 0.2783 Train_Acc: 89.462 Val_Loss: 0.2703  BEST VAL Loss: 0.2703  Val_Acc: 90.672

Epoch 64: Validation loss decreased (0.270310 --> 0.269514).  Saving model ...
	 Train_Loss: 0.2778 Train_Acc: 89.542 Val_Loss: 0.2695  BEST VAL Loss: 0.2695  Val_Acc: 90.738

Epoch 65: Validation loss decreased (0.269514 --> 0.268759).  Saving model ...
	 Train_Loss: 0.2774 Train_Acc: 89.528 Val_Loss: 0.2688  BEST VAL Loss: 0.2688  Val_Acc: 90.637

Epoch 66: Validation loss decreased (0.268759 --> 0.267991).  Saving model ...
	 Train_Loss: 0.2769 Train_Acc: 89.595 Val_Loss: 0.2680  BEST VAL Loss: 0.2680  Val_Acc: 90.754

Epoch 67: Validation loss decreased (0.267991 --> 0.267535).  Saving model ...
	 Train_Loss: 0.2765 Train_Acc: 89.592 Val_Loss: 0.2675  BEST VAL Loss: 0.2675  Val_Acc: 90.035

Epoch 68: Validation loss decreased (0.267535 --> 0.266817).  Saving model ...
	 Train_Loss: 0.2761 Train_Acc: 89.519 Val_Loss: 0.2668  BEST VAL Loss: 0.2668  Val_Acc: 90.727

Epoch 69: Validation loss decreased (0.266817 --> 0.266096).  Saving model ...
	 Train_Loss: 0.2756 Train_Acc: 89.558 Val_Loss: 0.2661  BEST VAL Loss: 0.2661  Val_Acc: 90.909

Epoch 70: Validation loss decreased (0.266096 --> 0.265681).  Saving model ...
	 Train_Loss: 0.2752 Train_Acc: 89.542 Val_Loss: 0.2657  BEST VAL Loss: 0.2657  Val_Acc: 90.097

Epoch 71: Validation loss decreased (0.265681 --> 0.265519).  Saving model ...
	 Train_Loss: 0.2748 Train_Acc: 89.550 Val_Loss: 0.2655  BEST VAL Loss: 0.2655  Val_Acc: 89.169

Epoch 72: Validation loss decreased (0.265519 --> 0.264843).  Saving model ...
	 Train_Loss: 0.2744 Train_Acc: 89.520 Val_Loss: 0.2648  BEST VAL Loss: 0.2648  Val_Acc: 90.859

Epoch 73: Validation loss decreased (0.264843 --> 0.264598).  Saving model ...
	 Train_Loss: 0.2740 Train_Acc: 89.627 Val_Loss: 0.2646  BEST VAL Loss: 0.2646  Val_Acc: 89.593

Epoch 74: Validation loss decreased (0.264598 --> 0.263959).  Saving model ...
	 Train_Loss: 0.2737 Train_Acc: 89.555 Val_Loss: 0.2640  BEST VAL Loss: 0.2640  Val_Acc: 90.859

Epoch 75: Validation loss decreased (0.263959 --> 0.263337).  Saving model ...
	 Train_Loss: 0.2733 Train_Acc: 89.653 Val_Loss: 0.2633  BEST VAL Loss: 0.2633  Val_Acc: 90.851

Epoch 76: Validation loss decreased (0.263337 --> 0.262746).  Saving model ...
	 Train_Loss: 0.2729 Train_Acc: 89.688 Val_Loss: 0.2627  BEST VAL Loss: 0.2627  Val_Acc: 90.835

Epoch 77: Validation loss decreased (0.262746 --> 0.262172).  Saving model ...
	 Train_Loss: 0.2725 Train_Acc: 89.733 Val_Loss: 0.2622  BEST VAL Loss: 0.2622  Val_Acc: 90.796

Epoch 78: Validation loss decreased (0.262172 --> 0.261576).  Saving model ...
	 Train_Loss: 0.2721 Train_Acc: 89.606 Val_Loss: 0.2616  BEST VAL Loss: 0.2616  Val_Acc: 90.828

Epoch 79: Validation loss decreased (0.261576 --> 0.261084).  Saving model ...
	 Train_Loss: 0.2718 Train_Acc: 89.660 Val_Loss: 0.2611  BEST VAL Loss: 0.2611  Val_Acc: 90.633

Epoch 80: Validation loss decreased (0.261084 --> 0.260505).  Saving model ...
	 Train_Loss: 0.2715 Train_Acc: 89.615 Val_Loss: 0.2605  BEST VAL Loss: 0.2605  Val_Acc: 90.909

Epoch 81: Validation loss decreased (0.260505 --> 0.259984).  Saving model ...
	 Train_Loss: 0.2711 Train_Acc: 89.626 Val_Loss: 0.2600  BEST VAL Loss: 0.2600  Val_Acc: 90.800

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.2708 Train_Acc: 89.623 Val_Loss: 0.2602  BEST VAL Loss: 0.2600  Val_Acc: 88.781

Epoch 83: Validation loss decreased (0.259984 --> 0.259694).  Saving model ...
	 Train_Loss: 0.2705 Train_Acc: 89.611 Val_Loss: 0.2597  BEST VAL Loss: 0.2597  Val_Acc: 90.971

Epoch 84: Validation loss decreased (0.259694 --> 0.259306).  Saving model ...
	 Train_Loss: 0.2702 Train_Acc: 89.733 Val_Loss: 0.2593  BEST VAL Loss: 0.2593  Val_Acc: 90.482

Epoch 85: Validation loss decreased (0.259306 --> 0.258795).  Saving model ...
	 Train_Loss: 0.2698 Train_Acc: 89.619 Val_Loss: 0.2588  BEST VAL Loss: 0.2588  Val_Acc: 90.843

Epoch 86: Validation loss decreased (0.258795 --> 0.258306).  Saving model ...
	 Train_Loss: 0.2695 Train_Acc: 89.782 Val_Loss: 0.2583  BEST VAL Loss: 0.2583  Val_Acc: 90.831

Epoch 87: Validation loss decreased (0.258306 --> 0.257828).  Saving model ...
	 Train_Loss: 0.2692 Train_Acc: 89.805 Val_Loss: 0.2578  BEST VAL Loss: 0.2578  Val_Acc: 90.835

Epoch 88: Validation loss decreased (0.257828 --> 0.257393).  Saving model ...
	 Train_Loss: 0.2689 Train_Acc: 89.756 Val_Loss: 0.2574  BEST VAL Loss: 0.2574  Val_Acc: 90.703

Epoch 89: Validation loss decreased (0.257393 --> 0.256917).  Saving model ...
	 Train_Loss: 0.2686 Train_Acc: 89.751 Val_Loss: 0.2569  BEST VAL Loss: 0.2569  Val_Acc: 90.929

Epoch 90: Validation loss decreased (0.256917 --> 0.256490).  Saving model ...
	 Train_Loss: 0.2683 Train_Acc: 89.743 Val_Loss: 0.2565  BEST VAL Loss: 0.2565  Val_Acc: 90.777

Epoch 91: Validation loss decreased (0.256490 --> 0.256073).  Saving model ...
	 Train_Loss: 0.2680 Train_Acc: 89.759 Val_Loss: 0.2561  BEST VAL Loss: 0.2561  Val_Acc: 90.793

Epoch 92: Validation loss decreased (0.256073 --> 0.255644).  Saving model ...
	 Train_Loss: 0.2677 Train_Acc: 89.769 Val_Loss: 0.2556  BEST VAL Loss: 0.2556  Val_Acc: 90.952

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.2674 Train_Acc: 89.764 Val_Loss: 0.2569  BEST VAL Loss: 0.2556  Val_Acc: 87.243

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.2672 Train_Acc: 89.738 Val_Loss: 0.2567  BEST VAL Loss: 0.2556  Val_Acc: 90.257

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.2669 Train_Acc: 89.769 Val_Loss: 0.2563  BEST VAL Loss: 0.2556  Val_Acc: 91.002

Epoch 96: Validation loss did not decrease
	 Train_Loss: 0.2666 Train_Acc: 89.848 Val_Loss: 0.2558  BEST VAL Loss: 0.2556  Val_Acc: 90.839

Epoch 97: Validation loss decreased (0.255644 --> 0.255418).  Saving model ...
	 Train_Loss: 0.2663 Train_Acc: 89.789 Val_Loss: 0.2554  BEST VAL Loss: 0.2554  Val_Acc: 90.897

Epoch 98: Validation loss decreased (0.255418 --> 0.255003).  Saving model ...
	 Train_Loss: 0.2660 Train_Acc: 89.840 Val_Loss: 0.2550  BEST VAL Loss: 0.2550  Val_Acc: 90.835

Epoch 99: Validation loss decreased (0.255003 --> 0.254612).  Saving model ...
	 Train_Loss: 0.2658 Train_Acc: 89.858 Val_Loss: 0.2546  BEST VAL Loss: 0.2546  Val_Acc: 90.851

Flagellin_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.94      0.96      0.95    149884
           1       0.88      0.83      0.85     56123

    accuracy                           0.92    206007
   macro avg       0.91      0.89      0.90    206007
weighted avg       0.92      0.92      0.92    206007

Flagellin_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.95      0.94     18736
           1       0.85      0.81      0.83      7015

    accuracy                           0.91     25751
   macro avg       0.89      0.88      0.88     25751
weighted avg       0.91      0.91      0.91     25751

Flagellin_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.95      0.94     18736
           1       0.85      0.81      0.83      7015

    accuracy                           0.91     25751
   macro avg       0.89      0.88      0.88     25751
weighted avg       0.91      0.91      0.91     25751

              precision    recall  f1-score   support

           0       0.93      0.95      0.94     18736
           1       0.85      0.81      0.83      7015

    accuracy                           0.91     25751
   macro avg       0.89      0.88      0.88     25751
weighted avg       0.91      0.91      0.91     25751

Flagellin_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.58      0.89      0.70     27774
           1       0.84      0.47      0.60     34394

    accuracy                           0.66     62168
   macro avg       0.71      0.68      0.65     62168
weighted avg       0.72      0.66      0.65     62168

              precision    recall  f1-score   support

           0       0.58      0.89      0.70     27774
           1       0.84      0.47      0.60     34394

    accuracy                           0.66     62168
   macro avg       0.71      0.68      0.65     62168
weighted avg       0.72      0.66      0.65     62168

completed
