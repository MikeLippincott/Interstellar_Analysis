[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '0381c6c6'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '8e3cf73d'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '10776d29'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'bc4cc6a7'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_0.100_DMSO_0.025 treatment_name: Thapsigargin_10.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: Thapsigargin_10.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (28140, 1276)
Number of total missing values across all columns: 56280
Data Subset Is Off
Wells held out for testing: ['E14' 'L22']
Wells to use for training, validation, and testing ['E15' 'L14' 'L15' 'L18' 'L19' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.604293).  Saving model ...
	 Train_Loss: 0.6662 Train_Acc: 56.294 Val_Loss: 0.6043  BEST VAL Loss: 0.6043  Val_Acc: 68.025

Epoch 1: Validation loss decreased (0.604293 --> 0.567696).  Saving model ...
	 Train_Loss: 0.6196 Train_Acc: 68.092 Val_Loss: 0.5677  BEST VAL Loss: 0.5677  Val_Acc: 73.557

Epoch 2: Validation loss decreased (0.567696 --> 0.540990).  Saving model ...
	 Train_Loss: 0.5812 Train_Acc: 72.787 Val_Loss: 0.5410  BEST VAL Loss: 0.5410  Val_Acc: 76.904

Epoch 3: Validation loss decreased (0.540990 --> 0.507392).  Saving model ...
	 Train_Loss: 0.5508 Train_Acc: 76.057 Val_Loss: 0.5074  BEST VAL Loss: 0.5074  Val_Acc: 81.223

Epoch 4: Validation loss decreased (0.507392 --> 0.482974).  Saving model ...
	 Train_Loss: 0.5254 Train_Acc: 81.074 Val_Loss: 0.4830  BEST VAL Loss: 0.4830  Val_Acc: 83.212

Epoch 5: Validation loss decreased (0.482974 --> 0.458825).  Saving model ...
	 Train_Loss: 0.5038 Train_Acc: 83.197 Val_Loss: 0.4588  BEST VAL Loss: 0.4588  Val_Acc: 85.444

Epoch 6: Validation loss decreased (0.458825 --> 0.440677).  Saving model ...
	 Train_Loss: 0.4854 Train_Acc: 84.495 Val_Loss: 0.4407  BEST VAL Loss: 0.4407  Val_Acc: 86.269

Epoch 7: Validation loss decreased (0.440677 --> 0.425084).  Saving model ...
	 Train_Loss: 0.4692 Train_Acc: 85.587 Val_Loss: 0.4251  BEST VAL Loss: 0.4251  Val_Acc: 86.705

Epoch 8: Validation loss decreased (0.425084 --> 0.411547).  Saving model ...
	 Train_Loss: 0.4550 Train_Acc: 86.194 Val_Loss: 0.4115  BEST VAL Loss: 0.4115  Val_Acc: 87.870

Epoch 9: Validation loss decreased (0.411547 --> 0.402773).  Saving model ...
	 Train_Loss: 0.4421 Train_Acc: 87.158 Val_Loss: 0.4028  BEST VAL Loss: 0.4028  Val_Acc: 88.161

Epoch 10: Validation loss decreased (0.402773 --> 0.393454).  Saving model ...
	 Train_Loss: 0.4309 Train_Acc: 87.298 Val_Loss: 0.3935  BEST VAL Loss: 0.3935  Val_Acc: 88.549

Epoch 11: Validation loss decreased (0.393454 --> 0.384196).  Saving model ...
	 Train_Loss: 0.4208 Train_Acc: 87.916 Val_Loss: 0.3842  BEST VAL Loss: 0.3842  Val_Acc: 88.695

Epoch 12: Validation loss decreased (0.384196 --> 0.374320).  Saving model ...
	 Train_Loss: 0.4113 Train_Acc: 88.444 Val_Loss: 0.3743  BEST VAL Loss: 0.3743  Val_Acc: 89.083

Epoch 13: Validation loss decreased (0.374320 --> 0.367929).  Saving model ...
	 Train_Loss: 0.4026 Train_Acc: 88.747 Val_Loss: 0.3679  BEST VAL Loss: 0.3679  Val_Acc: 89.471

Epoch 14: Validation loss decreased (0.367929 --> 0.362654).  Saving model ...
	 Train_Loss: 0.3946 Train_Acc: 89.032 Val_Loss: 0.3627  BEST VAL Loss: 0.3627  Val_Acc: 89.568

Epoch 15: Validation loss decreased (0.362654 --> 0.356444).  Saving model ...
	 Train_Loss: 0.3872 Train_Acc: 89.166 Val_Loss: 0.3564  BEST VAL Loss: 0.3564  Val_Acc: 89.568

Epoch 16: Validation loss decreased (0.356444 --> 0.349455).  Saving model ...
	 Train_Loss: 0.3801 Train_Acc: 89.766 Val_Loss: 0.3495  BEST VAL Loss: 0.3495  Val_Acc: 90.150

Epoch 17: Validation loss decreased (0.349455 --> 0.344385).  Saving model ...
	 Train_Loss: 0.3734 Train_Acc: 90.185 Val_Loss: 0.3444  BEST VAL Loss: 0.3444  Val_Acc: 89.714

Epoch 18: Validation loss decreased (0.344385 --> 0.339493).  Saving model ...
	 Train_Loss: 0.3673 Train_Acc: 90.476 Val_Loss: 0.3395  BEST VAL Loss: 0.3395  Val_Acc: 90.005

Epoch 19: Validation loss decreased (0.339493 --> 0.333660).  Saving model ...
	 Train_Loss: 0.3614 Train_Acc: 90.488 Val_Loss: 0.3337  BEST VAL Loss: 0.3337  Val_Acc: 90.199

Epoch 20: Validation loss decreased (0.333660 --> 0.328539).  Saving model ...
	 Train_Loss: 0.3559 Train_Acc: 90.652 Val_Loss: 0.3285  BEST VAL Loss: 0.3285  Val_Acc: 90.490

Epoch 21: Validation loss decreased (0.328539 --> 0.326055).  Saving model ...
	 Train_Loss: 0.3506 Train_Acc: 90.949 Val_Loss: 0.3261  BEST VAL Loss: 0.3261  Val_Acc: 90.539

Epoch 22: Validation loss decreased (0.326055 --> 0.321808).  Saving model ...
	 Train_Loss: 0.3457 Train_Acc: 91.101 Val_Loss: 0.3218  BEST VAL Loss: 0.3218  Val_Acc: 90.830

Epoch 23: Validation loss decreased (0.321808 --> 0.319005).  Saving model ...
	 Train_Loss: 0.3410 Train_Acc: 91.295 Val_Loss: 0.3190  BEST VAL Loss: 0.3190  Val_Acc: 91.072

Epoch 24: Validation loss decreased (0.319005 --> 0.315196).  Saving model ...
	 Train_Loss: 0.3364 Train_Acc: 91.526 Val_Loss: 0.3152  BEST VAL Loss: 0.3152  Val_Acc: 90.927

Epoch 25: Validation loss decreased (0.315196 --> 0.312006).  Saving model ...
	 Train_Loss: 0.3321 Train_Acc: 91.677 Val_Loss: 0.3120  BEST VAL Loss: 0.3120  Val_Acc: 91.121

Epoch 26: Validation loss decreased (0.312006 --> 0.308271).  Saving model ...
	 Train_Loss: 0.3279 Train_Acc: 92.005 Val_Loss: 0.3083  BEST VAL Loss: 0.3083  Val_Acc: 91.412

Epoch 27: Validation loss decreased (0.308271 --> 0.304124).  Saving model ...
	 Train_Loss: 0.3239 Train_Acc: 92.005 Val_Loss: 0.3041  BEST VAL Loss: 0.3041  Val_Acc: 91.169

Epoch 28: Validation loss decreased (0.304124 --> 0.301949).  Saving model ...
	 Train_Loss: 0.3201 Train_Acc: 92.181 Val_Loss: 0.3019  BEST VAL Loss: 0.3019  Val_Acc: 91.509

Epoch 29: Validation loss decreased (0.301949 --> 0.298563).  Saving model ...
	 Train_Loss: 0.3164 Train_Acc: 92.436 Val_Loss: 0.2986  BEST VAL Loss: 0.2986  Val_Acc: 91.412

Epoch 30: Validation loss decreased (0.298563 --> 0.296304).  Saving model ...
	 Train_Loss: 0.3129 Train_Acc: 92.338 Val_Loss: 0.2963  BEST VAL Loss: 0.2963  Val_Acc: 91.509

Epoch 31: Validation loss decreased (0.296304 --> 0.293728).  Saving model ...
	 Train_Loss: 0.3095 Train_Acc: 92.448 Val_Loss: 0.2937  BEST VAL Loss: 0.2937  Val_Acc: 91.703

Epoch 32: Validation loss decreased (0.293728 --> 0.291686).  Saving model ...
	 Train_Loss: 0.3062 Train_Acc: 92.551 Val_Loss: 0.2917  BEST VAL Loss: 0.2917  Val_Acc: 91.655

Epoch 33: Validation loss decreased (0.291686 --> 0.289931).  Saving model ...
	 Train_Loss: 0.3031 Train_Acc: 92.721 Val_Loss: 0.2899  BEST VAL Loss: 0.2899  Val_Acc: 91.849

Epoch 34: Validation loss decreased (0.289931 --> 0.287083).  Saving model ...
	 Train_Loss: 0.3000 Train_Acc: 92.557 Val_Loss: 0.2871  BEST VAL Loss: 0.2871  Val_Acc: 91.994

Epoch 35: Validation loss decreased (0.287083 --> 0.284203).  Saving model ...
	 Train_Loss: 0.2970 Train_Acc: 93.006 Val_Loss: 0.2842  BEST VAL Loss: 0.2842  Val_Acc: 91.897

Epoch 36: Validation loss decreased (0.284203 --> 0.282287).  Saving model ...
	 Train_Loss: 0.2941 Train_Acc: 93.212 Val_Loss: 0.2823  BEST VAL Loss: 0.2823  Val_Acc: 92.188

Epoch 37: Validation loss decreased (0.282287 --> 0.280316).  Saving model ...
	 Train_Loss: 0.2913 Train_Acc: 93.176 Val_Loss: 0.2803  BEST VAL Loss: 0.2803  Val_Acc: 91.606

Epoch 38: Validation loss decreased (0.280316 --> 0.278483).  Saving model ...
	 Train_Loss: 0.2885 Train_Acc: 93.345 Val_Loss: 0.2785  BEST VAL Loss: 0.2785  Val_Acc: 91.849

Epoch 39: Validation loss decreased (0.278483 --> 0.276587).  Saving model ...
	 Train_Loss: 0.2858 Train_Acc: 93.303 Val_Loss: 0.2766  BEST VAL Loss: 0.2766  Val_Acc: 92.091

Epoch 40: Validation loss decreased (0.276587 --> 0.275180).  Saving model ...
	 Train_Loss: 0.2833 Train_Acc: 93.382 Val_Loss: 0.2752  BEST VAL Loss: 0.2752  Val_Acc: 92.285

Epoch 41: Validation loss decreased (0.275180 --> 0.273138).  Saving model ...
	 Train_Loss: 0.2808 Train_Acc: 93.509 Val_Loss: 0.2731  BEST VAL Loss: 0.2731  Val_Acc: 92.431

Epoch 42: Validation loss decreased (0.273138 --> 0.271514).  Saving model ...
	 Train_Loss: 0.2784 Train_Acc: 93.540 Val_Loss: 0.2715  BEST VAL Loss: 0.2715  Val_Acc: 92.382

Epoch 43: Validation loss decreased (0.271514 --> 0.269193).  Saving model ...
	 Train_Loss: 0.2761 Train_Acc: 93.679 Val_Loss: 0.2692  BEST VAL Loss: 0.2692  Val_Acc: 92.576

Epoch 44: Validation loss decreased (0.269193 --> 0.267719).  Saving model ...
	 Train_Loss: 0.2737 Train_Acc: 93.891 Val_Loss: 0.2677  BEST VAL Loss: 0.2677  Val_Acc: 92.576

Epoch 45: Validation loss decreased (0.267719 --> 0.266118).  Saving model ...
	 Train_Loss: 0.2715 Train_Acc: 93.703 Val_Loss: 0.2661  BEST VAL Loss: 0.2661  Val_Acc: 92.722

Epoch 46: Validation loss decreased (0.266118 --> 0.264286).  Saving model ...
	 Train_Loss: 0.2693 Train_Acc: 93.897 Val_Loss: 0.2643  BEST VAL Loss: 0.2643  Val_Acc: 92.091

Epoch 47: Validation loss decreased (0.264286 --> 0.262244).  Saving model ...
	 Train_Loss: 0.2672 Train_Acc: 93.928 Val_Loss: 0.2622  BEST VAL Loss: 0.2622  Val_Acc: 92.528

Epoch 48: Validation loss decreased (0.262244 --> 0.261284).  Saving model ...
	 Train_Loss: 0.2651 Train_Acc: 94.110 Val_Loss: 0.2613  BEST VAL Loss: 0.2613  Val_Acc: 92.868

Epoch 49: Validation loss decreased (0.261284 --> 0.259764).  Saving model ...
	 Train_Loss: 0.2631 Train_Acc: 93.940 Val_Loss: 0.2598  BEST VAL Loss: 0.2598  Val_Acc: 92.479

Epoch 50: Validation loss decreased (0.259764 --> 0.258610).  Saving model ...
	 Train_Loss: 0.2611 Train_Acc: 94.268 Val_Loss: 0.2586  BEST VAL Loss: 0.2586  Val_Acc: 92.479

Epoch 51: Validation loss decreased (0.258610 --> 0.257302).  Saving model ...
	 Train_Loss: 0.2591 Train_Acc: 94.316 Val_Loss: 0.2573  BEST VAL Loss: 0.2573  Val_Acc: 92.965

Epoch 52: Validation loss decreased (0.257302 --> 0.256664).  Saving model ...
	 Train_Loss: 0.2572 Train_Acc: 94.304 Val_Loss: 0.2567  BEST VAL Loss: 0.2567  Val_Acc: 92.868

Epoch 53: Validation loss decreased (0.256664 --> 0.255402).  Saving model ...
	 Train_Loss: 0.2553 Train_Acc: 94.498 Val_Loss: 0.2554  BEST VAL Loss: 0.2554  Val_Acc: 92.528

Epoch 54: Validation loss decreased (0.255402 --> 0.254224).  Saving model ...
	 Train_Loss: 0.2535 Train_Acc: 94.449 Val_Loss: 0.2542  BEST VAL Loss: 0.2542  Val_Acc: 92.334

Epoch 55: Validation loss decreased (0.254224 --> 0.253292).  Saving model ...
	 Train_Loss: 0.2518 Train_Acc: 94.268 Val_Loss: 0.2533  BEST VAL Loss: 0.2533  Val_Acc: 92.528

Epoch 56: Validation loss decreased (0.253292 --> 0.252305).  Saving model ...
	 Train_Loss: 0.2500 Train_Acc: 94.553 Val_Loss: 0.2523  BEST VAL Loss: 0.2523  Val_Acc: 92.965

Epoch 57: Validation loss decreased (0.252305 --> 0.251341).  Saving model ...
	 Train_Loss: 0.2483 Train_Acc: 94.589 Val_Loss: 0.2513  BEST VAL Loss: 0.2513  Val_Acc: 93.013

Epoch 58: Validation loss decreased (0.251341 --> 0.250041).  Saving model ...
	 Train_Loss: 0.2467 Train_Acc: 94.747 Val_Loss: 0.2500  BEST VAL Loss: 0.2500  Val_Acc: 92.528

Epoch 59: Validation loss decreased (0.250041 --> 0.249411).  Saving model ...
	 Train_Loss: 0.2451 Train_Acc: 94.704 Val_Loss: 0.2494  BEST VAL Loss: 0.2494  Val_Acc: 92.770

Epoch 60: Validation loss decreased (0.249411 --> 0.248712).  Saving model ...
	 Train_Loss: 0.2435 Train_Acc: 94.625 Val_Loss: 0.2487  BEST VAL Loss: 0.2487  Val_Acc: 93.062

Epoch 61: Validation loss decreased (0.248712 --> 0.247524).  Saving model ...
	 Train_Loss: 0.2419 Train_Acc: 94.917 Val_Loss: 0.2475  BEST VAL Loss: 0.2475  Val_Acc: 92.916

Epoch 62: Validation loss decreased (0.247524 --> 0.246053).  Saving model ...
	 Train_Loss: 0.2403 Train_Acc: 94.820 Val_Loss: 0.2461  BEST VAL Loss: 0.2461  Val_Acc: 92.673

Epoch 63: Validation loss decreased (0.246053 --> 0.245882).  Saving model ...
	 Train_Loss: 0.2388 Train_Acc: 94.856 Val_Loss: 0.2459  BEST VAL Loss: 0.2459  Val_Acc: 92.868

Epoch 64: Validation loss decreased (0.245882 --> 0.245135).  Saving model ...
	 Train_Loss: 0.2373 Train_Acc: 94.874 Val_Loss: 0.2451  BEST VAL Loss: 0.2451  Val_Acc: 93.013

Epoch 65: Validation loss decreased (0.245135 --> 0.244573).  Saving model ...
	 Train_Loss: 0.2358 Train_Acc: 95.074 Val_Loss: 0.2446  BEST VAL Loss: 0.2446  Val_Acc: 92.916

Epoch 66: Validation loss decreased (0.244573 --> 0.243217).  Saving model ...
	 Train_Loss: 0.2344 Train_Acc: 94.977 Val_Loss: 0.2432  BEST VAL Loss: 0.2432  Val_Acc: 92.916

Epoch 67: Validation loss decreased (0.243217 --> 0.241931).  Saving model ...
	 Train_Loss: 0.2330 Train_Acc: 94.735 Val_Loss: 0.2419  BEST VAL Loss: 0.2419  Val_Acc: 92.916

Epoch 68: Validation loss decreased (0.241931 --> 0.240553).  Saving model ...
	 Train_Loss: 0.2316 Train_Acc: 95.123 Val_Loss: 0.2406  BEST VAL Loss: 0.2406  Val_Acc: 92.819

Epoch 69: Validation loss decreased (0.240553 --> 0.239754).  Saving model ...
	 Train_Loss: 0.2303 Train_Acc: 95.032 Val_Loss: 0.2398  BEST VAL Loss: 0.2398  Val_Acc: 92.916

Epoch 70: Validation loss decreased (0.239754 --> 0.239002).  Saving model ...
	 Train_Loss: 0.2289 Train_Acc: 95.299 Val_Loss: 0.2390  BEST VAL Loss: 0.2390  Val_Acc: 92.868

Epoch 71: Validation loss decreased (0.239002 --> 0.238346).  Saving model ...
	 Train_Loss: 0.2276 Train_Acc: 95.177 Val_Loss: 0.2383  BEST VAL Loss: 0.2383  Val_Acc: 92.916

Epoch 72: Validation loss decreased (0.238346 --> 0.237121).  Saving model ...
	 Train_Loss: 0.2263 Train_Acc: 95.438 Val_Loss: 0.2371  BEST VAL Loss: 0.2371  Val_Acc: 92.965

Epoch 73: Validation loss decreased (0.237121 --> 0.236123).  Saving model ...
	 Train_Loss: 0.2250 Train_Acc: 95.341 Val_Loss: 0.2361  BEST VAL Loss: 0.2361  Val_Acc: 92.868

Epoch 74: Validation loss decreased (0.236123 --> 0.235550).  Saving model ...
	 Train_Loss: 0.2238 Train_Acc: 95.305 Val_Loss: 0.2355  BEST VAL Loss: 0.2355  Val_Acc: 93.159

Epoch 75: Validation loss decreased (0.235550 --> 0.234661).  Saving model ...
	 Train_Loss: 0.2225 Train_Acc: 95.505 Val_Loss: 0.2347  BEST VAL Loss: 0.2347  Val_Acc: 93.256

Epoch 76: Validation loss decreased (0.234661 --> 0.233479).  Saving model ...
	 Train_Loss: 0.2213 Train_Acc: 95.511 Val_Loss: 0.2335  BEST VAL Loss: 0.2335  Val_Acc: 93.207

Epoch 77: Validation loss decreased (0.233479 --> 0.232448).  Saving model ...
	 Train_Loss: 0.2201 Train_Acc: 95.675 Val_Loss: 0.2324  BEST VAL Loss: 0.2324  Val_Acc: 92.819

Epoch 78: Validation loss decreased (0.232448 --> 0.231702).  Saving model ...
	 Train_Loss: 0.2190 Train_Acc: 95.517 Val_Loss: 0.2317  BEST VAL Loss: 0.2317  Val_Acc: 93.110

Epoch 79: Validation loss decreased (0.231702 --> 0.231557).  Saving model ...
	 Train_Loss: 0.2178 Train_Acc: 95.560 Val_Loss: 0.2316  BEST VAL Loss: 0.2316  Val_Acc: 93.353

Epoch 80: Validation loss decreased (0.231557 --> 0.230628).  Saving model ...
	 Train_Loss: 0.2166 Train_Acc: 95.566 Val_Loss: 0.2306  BEST VAL Loss: 0.2306  Val_Acc: 93.304

Epoch 81: Validation loss decreased (0.230628 --> 0.229729).  Saving model ...
	 Train_Loss: 0.2155 Train_Acc: 95.444 Val_Loss: 0.2297  BEST VAL Loss: 0.2297  Val_Acc: 93.207

Epoch 82: Validation loss decreased (0.229729 --> 0.228733).  Saving model ...
	 Train_Loss: 0.2144 Train_Acc: 95.669 Val_Loss: 0.2287  BEST VAL Loss: 0.2287  Val_Acc: 93.207

Epoch 83: Validation loss decreased (0.228733 --> 0.228516).  Saving model ...
	 Train_Loss: 0.2133 Train_Acc: 95.517 Val_Loss: 0.2285  BEST VAL Loss: 0.2285  Val_Acc: 93.110

Epoch 84: Validation loss decreased (0.228516 --> 0.227913).  Saving model ...
	 Train_Loss: 0.2122 Train_Acc: 95.766 Val_Loss: 0.2279  BEST VAL Loss: 0.2279  Val_Acc: 93.013

Epoch 85: Validation loss decreased (0.227913 --> 0.227475).  Saving model ...
	 Train_Loss: 0.2112 Train_Acc: 95.869 Val_Loss: 0.2275  BEST VAL Loss: 0.2275  Val_Acc: 92.965

Epoch 86: Validation loss decreased (0.227475 --> 0.226738).  Saving model ...
	 Train_Loss: 0.2101 Train_Acc: 95.814 Val_Loss: 0.2267  BEST VAL Loss: 0.2267  Val_Acc: 93.062

Epoch 87: Validation loss decreased (0.226738 --> 0.226167).  Saving model ...
	 Train_Loss: 0.2091 Train_Acc: 95.602 Val_Loss: 0.2262  BEST VAL Loss: 0.2262  Val_Acc: 93.013

Epoch 88: Validation loss decreased (0.226167 --> 0.225670).  Saving model ...
	 Train_Loss: 0.2081 Train_Acc: 95.839 Val_Loss: 0.2257  BEST VAL Loss: 0.2257  Val_Acc: 92.868

Epoch 89: Validation loss decreased (0.225670 --> 0.225003).  Saving model ...
	 Train_Loss: 0.2071 Train_Acc: 95.918 Val_Loss: 0.2250  BEST VAL Loss: 0.2250  Val_Acc: 93.353

Epoch 90: Validation loss decreased (0.225003 --> 0.224312).  Saving model ...
	 Train_Loss: 0.2061 Train_Acc: 95.996 Val_Loss: 0.2243  BEST VAL Loss: 0.2243  Val_Acc: 93.207

Epoch 91: Validation loss decreased (0.224312 --> 0.223578).  Saving model ...
	 Train_Loss: 0.2052 Train_Acc: 95.796 Val_Loss: 0.2236  BEST VAL Loss: 0.2236  Val_Acc: 93.256

Epoch 92: Validation loss decreased (0.223578 --> 0.222791).  Saving model ...
	 Train_Loss: 0.2042 Train_Acc: 96.093 Val_Loss: 0.2228  BEST VAL Loss: 0.2228  Val_Acc: 93.595

Epoch 93: Validation loss decreased (0.222791 --> 0.222057).  Saving model ...
	 Train_Loss: 0.2032 Train_Acc: 96.057 Val_Loss: 0.2221  BEST VAL Loss: 0.2221  Val_Acc: 93.256

Epoch 94: Validation loss decreased (0.222057 --> 0.221502).  Saving model ...
	 Train_Loss: 0.2024 Train_Acc: 95.863 Val_Loss: 0.2215  BEST VAL Loss: 0.2215  Val_Acc: 93.110

Epoch 95: Validation loss decreased (0.221502 --> 0.221160).  Saving model ...
	 Train_Loss: 0.2014 Train_Acc: 96.057 Val_Loss: 0.2212  BEST VAL Loss: 0.2212  Val_Acc: 93.110

Epoch 96: Validation loss decreased (0.221160 --> 0.220362).  Saving model ...
	 Train_Loss: 0.2005 Train_Acc: 95.960 Val_Loss: 0.2204  BEST VAL Loss: 0.2204  Val_Acc: 93.013

Epoch 97: Validation loss decreased (0.220362 --> 0.219604).  Saving model ...
	 Train_Loss: 0.1996 Train_Acc: 96.130 Val_Loss: 0.2196  BEST VAL Loss: 0.2196  Val_Acc: 93.207

Epoch 98: Validation loss decreased (0.219604 --> 0.218976).  Saving model ...
	 Train_Loss: 0.1987 Train_Acc: 96.124 Val_Loss: 0.2190  BEST VAL Loss: 0.2190  Val_Acc: 93.159

Epoch 99: Validation loss decreased (0.218976 --> 0.218420).  Saving model ...
	 Train_Loss: 0.1979 Train_Acc: 96.063 Val_Loss: 0.2184  BEST VAL Loss: 0.2184  Val_Acc: 93.207

Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.53      0.53      8634
           1       0.48      0.48      0.48      7851

    accuracy                           0.51     16485
   macro avg       0.51      0.51      0.51     16485
weighted avg       0.51      0.51      0.51     16485

Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.52      0.51      1079
           1       0.46      0.46      0.46       982

    accuracy                           0.49      2061
   macro avg       0.49      0.49      0.49      2061
weighted avg       0.49      0.49      0.49      2061

Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.52      0.52      1080
           1       0.47      0.46      0.46       981

    accuracy                           0.49      2061
   macro avg       0.49      0.49      0.49      2061
weighted avg       0.49      0.49      0.49      2061

              precision    recall  f1-score   support

           0       0.51      0.52      0.52      1080
           1       0.47      0.46      0.46       981

    accuracy                           0.49      2061
   macro avg       0.49      0.49      0.49      2061
weighted avg       0.49      0.49      0.49      2061

Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.54      0.55      4135
           1       0.45      0.46      0.45      3398

    accuracy                           0.51      7533
   macro avg       0.50      0.50      0.50      7533
weighted avg       0.51      0.51      0.51      7533

              precision    recall  f1-score   support

           0       0.55      0.54      0.55      4135
           1       0.45      0.46      0.45      3398

    accuracy                           0.51      7533
   macro avg       0.50      0.50      0.50      7533
weighted avg       0.51      0.51      0.51      7533

completed
