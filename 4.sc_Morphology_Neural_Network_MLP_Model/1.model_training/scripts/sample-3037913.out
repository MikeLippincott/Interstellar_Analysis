[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '859326ff'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '2976cf97'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '5b5209bf'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '0520d643'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_0.010_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_0.010_DMSO_0.025
TREATMENT_NAME: Flagellin_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (31668, 1276)
Number of total missing values across all columns: 63336
Data Subset Is Off
Wells held out for testing: ['B16' 'M22']
Wells to use for training, validation, and testing ['B17' 'B20' 'B21' 'M18' 'M19' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.628216).  Saving model ...
	 Train_Loss: 0.8912 Train_Acc: 58.345 Val_Loss: 0.6282  BEST VAL Loss: 0.6282  Val_Acc: 64.328

Epoch 1: Validation loss decreased (0.628216 --> 0.618032).  Saving model ...
	 Train_Loss: 0.7537 Train_Acc: 65.892 Val_Loss: 0.6180  BEST VAL Loss: 0.6180  Val_Acc: 66.526

Epoch 2: Validation loss decreased (0.618032 --> 0.610246).  Saving model ...
	 Train_Loss: 0.6999 Train_Acc: 66.938 Val_Loss: 0.6102  BEST VAL Loss: 0.6102  Val_Acc: 67.456

Epoch 3: Validation loss decreased (0.610246 --> 0.603499).  Saving model ...
	 Train_Loss: 0.6695 Train_Acc: 68.566 Val_Loss: 0.6035  BEST VAL Loss: 0.6035  Val_Acc: 68.216

Epoch 4: Validation loss decreased (0.603499 --> 0.601945).  Saving model ...
	 Train_Loss: 0.6482 Train_Acc: 69.665 Val_Loss: 0.6019  BEST VAL Loss: 0.6019  Val_Acc: 67.878

Epoch 5: Validation loss decreased (0.601945 --> 0.598816).  Saving model ...
	 Train_Loss: 0.6328 Train_Acc: 70.003 Val_Loss: 0.5988  BEST VAL Loss: 0.5988  Val_Acc: 68.681

Epoch 6: Validation loss decreased (0.598816 --> 0.594136).  Saving model ...
	 Train_Loss: 0.6201 Train_Acc: 71.092 Val_Loss: 0.5941  BEST VAL Loss: 0.5941  Val_Acc: 69.527

Epoch 7: Validation loss decreased (0.594136 --> 0.590304).  Saving model ...
	 Train_Loss: 0.6101 Train_Acc: 71.176 Val_Loss: 0.5903  BEST VAL Loss: 0.5903  Val_Acc: 70.372

Epoch 8: Validation loss decreased (0.590304 --> 0.588278).  Saving model ...
	 Train_Loss: 0.6011 Train_Acc: 72.048 Val_Loss: 0.5883  BEST VAL Loss: 0.5883  Val_Acc: 69.865

Epoch 9: Validation loss decreased (0.588278 --> 0.587131).  Saving model ...
	 Train_Loss: 0.5935 Train_Acc: 72.529 Val_Loss: 0.5871  BEST VAL Loss: 0.5871  Val_Acc: 70.034

Epoch 10: Validation loss decreased (0.587131 --> 0.586235).  Saving model ...
	 Train_Loss: 0.5857 Train_Acc: 73.322 Val_Loss: 0.5862  BEST VAL Loss: 0.5862  Val_Acc: 69.780

Epoch 11: Validation loss decreased (0.586235 --> 0.584503).  Saving model ...
	 Train_Loss: 0.5793 Train_Acc: 73.248 Val_Loss: 0.5845  BEST VAL Loss: 0.5845  Val_Acc: 70.795

Epoch 12: Validation loss decreased (0.584503 --> 0.582232).  Saving model ...
	 Train_Loss: 0.5732 Train_Acc: 73.655 Val_Loss: 0.5822  BEST VAL Loss: 0.5822  Val_Acc: 70.626

Epoch 13: Validation loss did not decrease
	 Train_Loss: 0.5680 Train_Acc: 73.999 Val_Loss: 0.5838  BEST VAL Loss: 0.5822  Val_Acc: 69.273

Epoch 14: Validation loss did not decrease
	 Train_Loss: 0.5634 Train_Acc: 74.146 Val_Loss: 0.5828  BEST VAL Loss: 0.5822  Val_Acc: 70.456

Epoch 15: Validation loss did not decrease
	 Train_Loss: 0.5584 Train_Acc: 74.865 Val_Loss: 0.5824  BEST VAL Loss: 0.5822  Val_Acc: 70.118

Epoch 16: Validation loss decreased (0.582232 --> 0.580285).  Saving model ...
	 Train_Loss: 0.5538 Train_Acc: 75.024 Val_Loss: 0.5803  BEST VAL Loss: 0.5803  Val_Acc: 71.471

Epoch 17: Validation loss decreased (0.580285 --> 0.577994).  Saving model ...
	 Train_Loss: 0.5496 Train_Acc: 75.251 Val_Loss: 0.5780  BEST VAL Loss: 0.5780  Val_Acc: 71.133

Epoch 18: Validation loss decreased (0.577994 --> 0.577117).  Saving model ...
	 Train_Loss: 0.5455 Train_Acc: 75.357 Val_Loss: 0.5771  BEST VAL Loss: 0.5771  Val_Acc: 71.090

Epoch 19: Validation loss decreased (0.577117 --> 0.576911).  Saving model ...
	 Train_Loss: 0.5417 Train_Acc: 75.684 Val_Loss: 0.5769  BEST VAL Loss: 0.5769  Val_Acc: 71.386

Epoch 20: Validation loss did not decrease
	 Train_Loss: 0.5382 Train_Acc: 75.595 Val_Loss: 0.5790  BEST VAL Loss: 0.5769  Val_Acc: 69.865

Epoch 21: Validation loss did not decrease
	 Train_Loss: 0.5347 Train_Acc: 76.075 Val_Loss: 0.5810  BEST VAL Loss: 0.5769  Val_Acc: 70.034

Epoch 22: Validation loss did not decrease
	 Train_Loss: 0.5318 Train_Acc: 75.679 Val_Loss: 0.5799  BEST VAL Loss: 0.5769  Val_Acc: 71.724

Epoch 23: Validation loss did not decrease
	 Train_Loss: 0.5285 Train_Acc: 76.683 Val_Loss: 0.5794  BEST VAL Loss: 0.5769  Val_Acc: 70.668

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.5254 Train_Acc: 76.747 Val_Loss: 0.5790  BEST VAL Loss: 0.5769  Val_Acc: 71.090

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.5225 Train_Acc: 76.578 Val_Loss: 0.5782  BEST VAL Loss: 0.5769  Val_Acc: 71.471

Epoch 26: Validation loss did not decrease
	 Train_Loss: 0.5200 Train_Acc: 76.609 Val_Loss: 0.5776  BEST VAL Loss: 0.5769  Val_Acc: 72.316

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.5172 Train_Acc: 77.222 Val_Loss: 0.5772  BEST VAL Loss: 0.5769  Val_Acc: 72.527

Epoch 28: Validation loss decreased (0.576911 --> 0.576731).  Saving model ...
	 Train_Loss: 0.5148 Train_Acc: 76.704 Val_Loss: 0.5767  BEST VAL Loss: 0.5767  Val_Acc: 71.386

Epoch 29: Validation loss did not decrease
	 Train_Loss: 0.5122 Train_Acc: 77.365 Val_Loss: 0.5768  BEST VAL Loss: 0.5767  Val_Acc: 72.232

Epoch 30: Validation loss decreased (0.576731 --> 0.576602).  Saving model ...
	 Train_Loss: 0.5098 Train_Acc: 77.233 Val_Loss: 0.5766  BEST VAL Loss: 0.5766  Val_Acc: 72.189

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.5076 Train_Acc: 76.810 Val_Loss: 0.5769  BEST VAL Loss: 0.5766  Val_Acc: 71.048

Epoch 32: Validation loss decreased (0.576602 --> 0.576156).  Saving model ...
	 Train_Loss: 0.5054 Train_Acc: 77.344 Val_Loss: 0.5762  BEST VAL Loss: 0.5762  Val_Acc: 72.950

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.5034 Train_Acc: 77.534 Val_Loss: 0.5764  BEST VAL Loss: 0.5762  Val_Acc: 71.682

Epoch 34: Validation loss decreased (0.576156 --> 0.576139).  Saving model ...
	 Train_Loss: 0.5013 Train_Acc: 77.867 Val_Loss: 0.5761  BEST VAL Loss: 0.5761  Val_Acc: 72.823

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.4992 Train_Acc: 77.814 Val_Loss: 0.5763  BEST VAL Loss: 0.5761  Val_Acc: 71.048

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.4971 Train_Acc: 78.448 Val_Loss: 0.5770  BEST VAL Loss: 0.5761  Val_Acc: 71.767

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.4953 Train_Acc: 77.666 Val_Loss: 0.5768  BEST VAL Loss: 0.5761  Val_Acc: 72.020

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.4934 Train_Acc: 78.205 Val_Loss: 0.5765  BEST VAL Loss: 0.5761  Val_Acc: 73.161

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.4916 Train_Acc: 78.237 Val_Loss: 0.5763  BEST VAL Loss: 0.5761  Val_Acc: 73.711

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.4898 Train_Acc: 77.925 Val_Loss: 0.5771  BEST VAL Loss: 0.5761  Val_Acc: 71.260

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.4882 Train_Acc: 78.216 Val_Loss: 0.5775  BEST VAL Loss: 0.5761  Val_Acc: 72.105

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.4866 Train_Acc: 78.084 Val_Loss: 0.5776  BEST VAL Loss: 0.5761  Val_Acc: 72.908

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.4850 Train_Acc: 78.670 Val_Loss: 0.5779  BEST VAL Loss: 0.5761  Val_Acc: 72.274

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.4836 Train_Acc: 77.936 Val_Loss: 0.5783  BEST VAL Loss: 0.5761  Val_Acc: 72.697

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.4819 Train_Acc: 78.797 Val_Loss: 0.5780  BEST VAL Loss: 0.5761  Val_Acc: 72.697

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.4803 Train_Acc: 78.765 Val_Loss: 0.5787  BEST VAL Loss: 0.5761  Val_Acc: 71.513

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.4790 Train_Acc: 77.946 Val_Loss: 0.5784  BEST VAL Loss: 0.5761  Val_Acc: 72.189

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.4774 Train_Acc: 79.278 Val_Loss: 0.5783  BEST VAL Loss: 0.5761  Val_Acc: 74.049

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.4760 Train_Acc: 78.882 Val_Loss: 0.5786  BEST VAL Loss: 0.5761  Val_Acc: 72.485

Epoch 50: Validation loss did not decrease
Early stopped at epoch : 50
LPS_0.010_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.56      0.53      9433
           1       0.50      0.45      0.47      9489

    accuracy                           0.50     18922
   macro avg       0.50      0.50      0.50     18922
weighted avg       0.50      0.50      0.50     18922

LPS_0.010_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.57      0.54      1179
           1       0.52      0.46      0.49      1187

    accuracy                           0.51      2366
   macro avg       0.51      0.51      0.51      2366
weighted avg       0.51      0.51      0.51      2366

LPS_0.010_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.54      0.52      1180
           1       0.50      0.45      0.47      1186

    accuracy                           0.50      2366
   macro avg       0.50      0.50      0.50      2366
weighted avg       0.50      0.50      0.50      2366

              precision    recall  f1-score   support

           0       0.50      0.54      0.52      1180
           1       0.50      0.45      0.47      1186

    accuracy                           0.50      2366
   macro avg       0.50      0.50      0.50      2366
weighted avg       0.50      0.50      0.50      2366

LPS_0.010_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.40      0.44      4017
           1       0.49      0.59      0.54      3997

    accuracy                           0.49      8014
   macro avg       0.49      0.49      0.49      8014
weighted avg       0.49      0.49      0.49      8014

              precision    recall  f1-score   support

           0       0.49      0.40      0.44      4017
           1       0.49      0.59      0.54      3997

    accuracy                           0.49      8014
   macro avg       0.49      0.49      0.49      8014
weighted avg       0.49      0.49      0.49      8014

completed
