[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '5f379ccb'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'f5574d9b'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '55d1d8c3'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'dfd790bd'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (324246, 1270)
Number of total missing values across all columns: 286160
Data Subset Is Off
Wells held out for testing: ['B09' 'M09']
Wells to use for training, validation, and testing ['B02' 'B03' 'B08' 'M02' 'M03' 'M08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.185205).  Saving model ...
	 Train_Loss: 0.2861 Train_Acc: 88.119 Val_Loss: 0.1852  BEST VAL Loss: 0.1852  Val_Acc: 92.752

Epoch 1: Validation loss decreased (0.185205 --> 0.173707).  Saving model ...
	 Train_Loss: 0.2418 Train_Acc: 92.280 Val_Loss: 0.1737  BEST VAL Loss: 0.1737  Val_Acc: 93.822

Epoch 2: Validation loss decreased (0.173707 --> 0.167096).  Saving model ...
	 Train_Loss: 0.2220 Train_Acc: 92.932 Val_Loss: 0.1671  BEST VAL Loss: 0.1671  Val_Acc: 94.179

Epoch 3: Validation loss decreased (0.167096 --> 0.161115).  Saving model ...
	 Train_Loss: 0.2090 Train_Acc: 93.491 Val_Loss: 0.1611  BEST VAL Loss: 0.1611  Val_Acc: 94.649

Epoch 4: Validation loss decreased (0.161115 --> 0.156540).  Saving model ...
	 Train_Loss: 0.2001 Train_Acc: 93.665 Val_Loss: 0.1565  BEST VAL Loss: 0.1565  Val_Acc: 94.913

Epoch 5: Validation loss decreased (0.156540 --> 0.152770).  Saving model ...
	 Train_Loss: 0.1936 Train_Acc: 93.808 Val_Loss: 0.1528  BEST VAL Loss: 0.1528  Val_Acc: 94.959

Epoch 6: Validation loss decreased (0.152770 --> 0.150067).  Saving model ...
	 Train_Loss: 0.1884 Train_Acc: 93.922 Val_Loss: 0.1501  BEST VAL Loss: 0.1501  Val_Acc: 95.035

Epoch 7: Validation loss decreased (0.150067 --> 0.147641).  Saving model ...
	 Train_Loss: 0.1840 Train_Acc: 94.107 Val_Loss: 0.1476  BEST VAL Loss: 0.1476  Val_Acc: 95.178

Epoch 8: Validation loss decreased (0.147641 --> 0.145735).  Saving model ...
	 Train_Loss: 0.1802 Train_Acc: 94.181 Val_Loss: 0.1457  BEST VAL Loss: 0.1457  Val_Acc: 95.073

Epoch 9: Validation loss decreased (0.145735 --> 0.143985).  Saving model ...
	 Train_Loss: 0.1770 Train_Acc: 94.337 Val_Loss: 0.1440  BEST VAL Loss: 0.1440  Val_Acc: 95.228

Epoch 10: Validation loss decreased (0.143985 --> 0.142429).  Saving model ...
	 Train_Loss: 0.1742 Train_Acc: 94.332 Val_Loss: 0.1424  BEST VAL Loss: 0.1424  Val_Acc: 95.320

Epoch 11: Validation loss decreased (0.142429 --> 0.141249).  Saving model ...
	 Train_Loss: 0.1717 Train_Acc: 94.422 Val_Loss: 0.1412  BEST VAL Loss: 0.1412  Val_Acc: 95.236

Epoch 12: Validation loss decreased (0.141249 --> 0.139984).  Saving model ...
	 Train_Loss: 0.1696 Train_Acc: 94.419 Val_Loss: 0.1400  BEST VAL Loss: 0.1400  Val_Acc: 95.346

Epoch 13: Validation loss decreased (0.139984 --> 0.138884).  Saving model ...
	 Train_Loss: 0.1676 Train_Acc: 94.526 Val_Loss: 0.1389  BEST VAL Loss: 0.1389  Val_Acc: 95.488

Epoch 14: Validation loss decreased (0.138884 --> 0.138120).  Saving model ...
	 Train_Loss: 0.1657 Train_Acc: 94.617 Val_Loss: 0.1381  BEST VAL Loss: 0.1381  Val_Acc: 95.346

Epoch 15: Validation loss decreased (0.138120 --> 0.137191).  Saving model ...
	 Train_Loss: 0.1640 Train_Acc: 94.624 Val_Loss: 0.1372  BEST VAL Loss: 0.1372  Val_Acc: 95.467

Epoch 16: Validation loss decreased (0.137191 --> 0.136342).  Saving model ...
	 Train_Loss: 0.1625 Train_Acc: 94.607 Val_Loss: 0.1363  BEST VAL Loss: 0.1363  Val_Acc: 95.497

Epoch 17: Validation loss decreased (0.136342 --> 0.135753).  Saving model ...
	 Train_Loss: 0.1611 Train_Acc: 94.594 Val_Loss: 0.1358  BEST VAL Loss: 0.1358  Val_Acc: 95.539

Epoch 18: Validation loss decreased (0.135753 --> 0.135149).  Saving model ...
	 Train_Loss: 0.1599 Train_Acc: 94.671 Val_Loss: 0.1351  BEST VAL Loss: 0.1351  Val_Acc: 95.459

Epoch 19: Validation loss decreased (0.135149 --> 0.134539).  Saving model ...
	 Train_Loss: 0.1586 Train_Acc: 94.703 Val_Loss: 0.1345  BEST VAL Loss: 0.1345  Val_Acc: 95.526

Epoch 20: Validation loss decreased (0.134539 --> 0.133997).  Saving model ...
	 Train_Loss: 0.1575 Train_Acc: 94.770 Val_Loss: 0.1340  BEST VAL Loss: 0.1340  Val_Acc: 95.438

Epoch 21: Validation loss decreased (0.133997 --> 0.133406).  Saving model ...
	 Train_Loss: 0.1564 Train_Acc: 94.831 Val_Loss: 0.1334  BEST VAL Loss: 0.1334  Val_Acc: 95.555

Epoch 22: Validation loss decreased (0.133406 --> 0.132774).  Saving model ...
	 Train_Loss: 0.1554 Train_Acc: 94.871 Val_Loss: 0.1328  BEST VAL Loss: 0.1328  Val_Acc: 95.665

Epoch 23: Validation loss decreased (0.132774 --> 0.132307).  Saving model ...
	 Train_Loss: 0.1543 Train_Acc: 94.929 Val_Loss: 0.1323  BEST VAL Loss: 0.1323  Val_Acc: 95.631

Epoch 24: Validation loss decreased (0.132307 --> 0.131836).  Saving model ...
	 Train_Loss: 0.1534 Train_Acc: 94.869 Val_Loss: 0.1318  BEST VAL Loss: 0.1318  Val_Acc: 95.547

Epoch 25: Validation loss decreased (0.131836 --> 0.131403).  Saving model ...
	 Train_Loss: 0.1526 Train_Acc: 94.860 Val_Loss: 0.1314  BEST VAL Loss: 0.1314  Val_Acc: 95.522

Epoch 26: Validation loss decreased (0.131403 --> 0.130989).  Saving model ...
	 Train_Loss: 0.1517 Train_Acc: 94.901 Val_Loss: 0.1310  BEST VAL Loss: 0.1310  Val_Acc: 95.526

Epoch 27: Validation loss decreased (0.130989 --> 0.130566).  Saving model ...
	 Train_Loss: 0.1509 Train_Acc: 94.932 Val_Loss: 0.1306  BEST VAL Loss: 0.1306  Val_Acc: 95.602

Epoch 28: Validation loss decreased (0.130566 --> 0.130158).  Saving model ...
	 Train_Loss: 0.1502 Train_Acc: 94.944 Val_Loss: 0.1302  BEST VAL Loss: 0.1302  Val_Acc: 95.690

Epoch 29: Validation loss decreased (0.130158 --> 0.129721).  Saving model ...
	 Train_Loss: 0.1494 Train_Acc: 94.952 Val_Loss: 0.1297  BEST VAL Loss: 0.1297  Val_Acc: 95.715

Epoch 30: Validation loss decreased (0.129721 --> 0.129431).  Saving model ...
	 Train_Loss: 0.1487 Train_Acc: 94.974 Val_Loss: 0.1294  BEST VAL Loss: 0.1294  Val_Acc: 95.446

Epoch 31: Validation loss decreased (0.129431 --> 0.129216).  Saving model ...
	 Train_Loss: 0.1481 Train_Acc: 94.982 Val_Loss: 0.1292  BEST VAL Loss: 0.1292  Val_Acc: 95.493

Epoch 32: Validation loss decreased (0.129216 --> 0.128819).  Saving model ...
	 Train_Loss: 0.1474 Train_Acc: 95.011 Val_Loss: 0.1288  BEST VAL Loss: 0.1288  Val_Acc: 95.715

Epoch 33: Validation loss decreased (0.128819 --> 0.128576).  Saving model ...
	 Train_Loss: 0.1468 Train_Acc: 95.035 Val_Loss: 0.1286  BEST VAL Loss: 0.1286  Val_Acc: 95.723

Epoch 34: Validation loss decreased (0.128576 --> 0.128308).  Saving model ...
	 Train_Loss: 0.1461 Train_Acc: 95.113 Val_Loss: 0.1283  BEST VAL Loss: 0.1283  Val_Acc: 95.635

Epoch 35: Validation loss decreased (0.128308 --> 0.127922).  Saving model ...
	 Train_Loss: 0.1455 Train_Acc: 95.015 Val_Loss: 0.1279  BEST VAL Loss: 0.1279  Val_Acc: 95.891

Epoch 36: Validation loss decreased (0.127922 --> 0.127560).  Saving model ...
	 Train_Loss: 0.1450 Train_Acc: 95.091 Val_Loss: 0.1276  BEST VAL Loss: 0.1276  Val_Acc: 95.749

Epoch 37: Validation loss decreased (0.127560 --> 0.127259).  Saving model ...
	 Train_Loss: 0.1444 Train_Acc: 95.099 Val_Loss: 0.1273  BEST VAL Loss: 0.1273  Val_Acc: 95.715

Epoch 38: Validation loss decreased (0.127259 --> 0.127058).  Saving model ...
	 Train_Loss: 0.1439 Train_Acc: 95.103 Val_Loss: 0.1271  BEST VAL Loss: 0.1271  Val_Acc: 95.740

Epoch 39: Validation loss decreased (0.127058 --> 0.126829).  Saving model ...
	 Train_Loss: 0.1434 Train_Acc: 95.122 Val_Loss: 0.1268  BEST VAL Loss: 0.1268  Val_Acc: 95.782

Epoch 40: Validation loss decreased (0.126829 --> 0.126670).  Saving model ...
	 Train_Loss: 0.1429 Train_Acc: 95.141 Val_Loss: 0.1267  BEST VAL Loss: 0.1267  Val_Acc: 95.669

Epoch 41: Validation loss decreased (0.126670 --> 0.126401).  Saving model ...
	 Train_Loss: 0.1424 Train_Acc: 95.166 Val_Loss: 0.1264  BEST VAL Loss: 0.1264  Val_Acc: 95.782

Epoch 42: Validation loss decreased (0.126401 --> 0.126268).  Saving model ...
	 Train_Loss: 0.1419 Train_Acc: 95.170 Val_Loss: 0.1263  BEST VAL Loss: 0.1263  Val_Acc: 95.551

Epoch 43: Validation loss decreased (0.126268 --> 0.126023).  Saving model ...
	 Train_Loss: 0.1414 Train_Acc: 95.211 Val_Loss: 0.1260  BEST VAL Loss: 0.1260  Val_Acc: 95.711

Epoch 44: Validation loss decreased (0.126023 --> 0.125870).  Saving model ...
	 Train_Loss: 0.1410 Train_Acc: 95.185 Val_Loss: 0.1259  BEST VAL Loss: 0.1259  Val_Acc: 95.660

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.1406 Train_Acc: 95.192 Val_Loss: 0.1259  BEST VAL Loss: 0.1259  Val_Acc: 95.509

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.1401 Train_Acc: 95.160 Val_Loss: 0.1259  BEST VAL Loss: 0.1259  Val_Acc: 95.459

Epoch 47: Validation loss decreased (0.125870 --> 0.125854).  Saving model ...
	 Train_Loss: 0.1398 Train_Acc: 95.145 Val_Loss: 0.1259  BEST VAL Loss: 0.1259  Val_Acc: 95.606

Epoch 48: Validation loss decreased (0.125854 --> 0.125735).  Saving model ...
	 Train_Loss: 0.1394 Train_Acc: 95.208 Val_Loss: 0.1257  BEST VAL Loss: 0.1257  Val_Acc: 95.698

Epoch 49: Validation loss decreased (0.125735 --> 0.125613).  Saving model ...
	 Train_Loss: 0.1390 Train_Acc: 95.253 Val_Loss: 0.1256  BEST VAL Loss: 0.1256  Val_Acc: 95.526

Epoch 50: Validation loss decreased (0.125613 --> 0.125495).  Saving model ...
	 Train_Loss: 0.1386 Train_Acc: 95.260 Val_Loss: 0.1255  BEST VAL Loss: 0.1255  Val_Acc: 95.589

Epoch 51: Validation loss decreased (0.125495 --> 0.125308).  Saving model ...
	 Train_Loss: 0.1382 Train_Acc: 95.192 Val_Loss: 0.1253  BEST VAL Loss: 0.1253  Val_Acc: 95.887

Epoch 52: Validation loss decreased (0.125308 --> 0.125128).  Saving model ...
	 Train_Loss: 0.1378 Train_Acc: 95.296 Val_Loss: 0.1251  BEST VAL Loss: 0.1251  Val_Acc: 95.774

Epoch 53: Validation loss decreased (0.125128 --> 0.124973).  Saving model ...
	 Train_Loss: 0.1375 Train_Acc: 95.306 Val_Loss: 0.1250  BEST VAL Loss: 0.1250  Val_Acc: 95.942

Epoch 54: Validation loss decreased (0.124973 --> 0.124805).  Saving model ...
	 Train_Loss: 0.1371 Train_Acc: 95.287 Val_Loss: 0.1248  BEST VAL Loss: 0.1248  Val_Acc: 95.707

Epoch 55: Validation loss decreased (0.124805 --> 0.124700).  Saving model ...
	 Train_Loss: 0.1368 Train_Acc: 95.276 Val_Loss: 0.1247  BEST VAL Loss: 0.1247  Val_Acc: 95.837

Epoch 56: Validation loss decreased (0.124700 --> 0.124635).  Saving model ...
	 Train_Loss: 0.1364 Train_Acc: 95.322 Val_Loss: 0.1246  BEST VAL Loss: 0.1246  Val_Acc: 95.853

Epoch 57: Validation loss decreased (0.124635 --> 0.124591).  Saving model ...
	 Train_Loss: 0.1361 Train_Acc: 95.318 Val_Loss: 0.1246  BEST VAL Loss: 0.1246  Val_Acc: 95.765

Epoch 58: Validation loss decreased (0.124591 --> 0.124521).  Saving model ...
	 Train_Loss: 0.1358 Train_Acc: 95.307 Val_Loss: 0.1245  BEST VAL Loss: 0.1245  Val_Acc: 95.811

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.1355 Train_Acc: 95.369 Val_Loss: 0.1245  BEST VAL Loss: 0.1245  Val_Acc: 95.631

Epoch 60: Validation loss decreased (0.124521 --> 0.124407).  Saving model ...
	 Train_Loss: 0.1352 Train_Acc: 95.266 Val_Loss: 0.1244  BEST VAL Loss: 0.1244  Val_Acc: 95.799

Epoch 61: Validation loss decreased (0.124407 --> 0.124264).  Saving model ...
	 Train_Loss: 0.1349 Train_Acc: 95.314 Val_Loss: 0.1243  BEST VAL Loss: 0.1243  Val_Acc: 95.761

Epoch 62: Validation loss decreased (0.124264 --> 0.124202).  Saving model ...
	 Train_Loss: 0.1346 Train_Acc: 95.347 Val_Loss: 0.1242  BEST VAL Loss: 0.1242  Val_Acc: 95.618

Epoch 63: Validation loss decreased (0.124202 --> 0.124020).  Saving model ...
	 Train_Loss: 0.1343 Train_Acc: 95.381 Val_Loss: 0.1240  BEST VAL Loss: 0.1240  Val_Acc: 95.816

Epoch 64: Validation loss decreased (0.124020 --> 0.123935).  Saving model ...
	 Train_Loss: 0.1341 Train_Acc: 95.336 Val_Loss: 0.1239  BEST VAL Loss: 0.1239  Val_Acc: 95.623

Epoch 65: Validation loss decreased (0.123935 --> 0.123910).  Saving model ...
	 Train_Loss: 0.1338 Train_Acc: 95.377 Val_Loss: 0.1239  BEST VAL Loss: 0.1239  Val_Acc: 95.803

Epoch 66: Validation loss decreased (0.123910 --> 0.123858).  Saving model ...
	 Train_Loss: 0.1335 Train_Acc: 95.348 Val_Loss: 0.1239  BEST VAL Loss: 0.1239  Val_Acc: 95.853

Epoch 67: Validation loss decreased (0.123858 --> 0.123799).  Saving model ...
	 Train_Loss: 0.1333 Train_Acc: 95.265 Val_Loss: 0.1238  BEST VAL Loss: 0.1238  Val_Acc: 95.677

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.1331 Train_Acc: 95.278 Val_Loss: 0.1238  BEST VAL Loss: 0.1238  Val_Acc: 95.711

Epoch 69: Validation loss decreased (0.123799 --> 0.123752).  Saving model ...
	 Train_Loss: 0.1328 Train_Acc: 95.255 Val_Loss: 0.1238  BEST VAL Loss: 0.1238  Val_Acc: 95.757

Epoch 70: Validation loss decreased (0.123752 --> 0.123702).  Saving model ...
	 Train_Loss: 0.1326 Train_Acc: 95.375 Val_Loss: 0.1237  BEST VAL Loss: 0.1237  Val_Acc: 95.811

Epoch 71: Validation loss decreased (0.123702 --> 0.123595).  Saving model ...
	 Train_Loss: 0.1323 Train_Acc: 95.373 Val_Loss: 0.1236  BEST VAL Loss: 0.1236  Val_Acc: 95.803

Epoch 72: Validation loss decreased (0.123595 --> 0.123549).  Saving model ...
	 Train_Loss: 0.1321 Train_Acc: 95.435 Val_Loss: 0.1235  BEST VAL Loss: 0.1235  Val_Acc: 95.782

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.1319 Train_Acc: 95.443 Val_Loss: 0.1236  BEST VAL Loss: 0.1235  Val_Acc: 95.614

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.1316 Train_Acc: 95.451 Val_Loss: 0.1236  BEST VAL Loss: 0.1235  Val_Acc: 95.883

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.1314 Train_Acc: 95.427 Val_Loss: 0.1236  BEST VAL Loss: 0.1235  Val_Acc: 95.761

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.1312 Train_Acc: 95.391 Val_Loss: 0.1236  BEST VAL Loss: 0.1235  Val_Acc: 95.749

Epoch 77: Validation loss decreased (0.123549 --> 0.123486).  Saving model ...
	 Train_Loss: 0.1309 Train_Acc: 95.430 Val_Loss: 0.1235  BEST VAL Loss: 0.1235  Val_Acc: 95.895

Epoch 78: Validation loss decreased (0.123486 --> 0.123436).  Saving model ...
	 Train_Loss: 0.1307 Train_Acc: 95.510 Val_Loss: 0.1234  BEST VAL Loss: 0.1234  Val_Acc: 95.958

Epoch 79: Validation loss decreased (0.123436 --> 0.123366).  Saving model ...
	 Train_Loss: 0.1305 Train_Acc: 95.488 Val_Loss: 0.1234  BEST VAL Loss: 0.1234  Val_Acc: 95.916

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.1302 Train_Acc: 95.466 Val_Loss: 0.1234  BEST VAL Loss: 0.1234  Val_Acc: 95.820

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.1300 Train_Acc: 95.447 Val_Loss: 0.1234  BEST VAL Loss: 0.1234  Val_Acc: 95.786

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.1298 Train_Acc: 95.427 Val_Loss: 0.1235  BEST VAL Loss: 0.1234  Val_Acc: 95.811

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.1296 Train_Acc: 95.416 Val_Loss: 0.1234  BEST VAL Loss: 0.1234  Val_Acc: 95.694

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.1295 Train_Acc: 95.424 Val_Loss: 0.1234  BEST VAL Loss: 0.1234  Val_Acc: 95.946

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.1293 Train_Acc: 95.461 Val_Loss: 0.1234  BEST VAL Loss: 0.1234  Val_Acc: 95.807

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.1291 Train_Acc: 95.424 Val_Loss: 0.1234  BEST VAL Loss: 0.1234  Val_Acc: 95.770

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.1289 Train_Acc: 95.467 Val_Loss: 0.1234  BEST VAL Loss: 0.1234  Val_Acc: 95.707

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.1287 Train_Acc: 95.483 Val_Loss: 0.1234  BEST VAL Loss: 0.1234  Val_Acc: 95.879

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.1285 Train_Acc: 95.574 Val_Loss: 0.1235  BEST VAL Loss: 0.1234  Val_Acc: 95.845

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.1283 Train_Acc: 95.508 Val_Loss: 0.1235  BEST VAL Loss: 0.1234  Val_Acc: 95.963

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.1281 Train_Acc: 95.486 Val_Loss: 0.1234  BEST VAL Loss: 0.1234  Val_Acc: 95.916

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.1279 Train_Acc: 95.575 Val_Loss: 0.1234  BEST VAL Loss: 0.1234  Val_Acc: 95.719

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.1277 Train_Acc: 95.495 Val_Loss: 0.1234  BEST VAL Loss: 0.1234  Val_Acc: 95.853

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.1275 Train_Acc: 95.522 Val_Loss: 0.1234  BEST VAL Loss: 0.1234  Val_Acc: 95.908

Epoch 95: Validation loss did not decrease
Early stopped at epoch : 95
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.96      0.97     85370
           1       0.97      0.97      0.97    105242

    accuracy                           0.97    190612
   macro avg       0.97      0.97      0.97    190612
weighted avg       0.97      0.97      0.97    190612

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.95      0.95      0.95     10672
           1       0.96      0.96      0.96     13155

    accuracy                           0.96     23827
   macro avg       0.96      0.96      0.96     23827
weighted avg       0.96      0.96      0.96     23827

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.95      0.95      0.95     10672
           1       0.96      0.96      0.96     13155

    accuracy                           0.96     23827
   macro avg       0.96      0.96      0.96     23827
weighted avg       0.96      0.96      0.96     23827

              precision    recall  f1-score   support

           0       0.95      0.95      0.95     10672
           1       0.96      0.96      0.96     13155

    accuracy                           0.96     23827
   macro avg       0.96      0.96      0.96     23827
weighted avg       0.96      0.96      0.96     23827

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      0.86      0.92     36366
           1       0.91      0.99      0.95     49614

    accuracy                           0.94     85980
   macro avg       0.95      0.93      0.93     85980
weighted avg       0.94      0.94      0.94     85980

              precision    recall  f1-score   support

           0       0.99      0.86      0.92     36366
           1       0.91      0.99      0.95     49614

    accuracy                           0.94     85980
   macro avg       0.95      0.93      0.93     85980
weighted avg       0.94      0.94      0.94     85980

completed
