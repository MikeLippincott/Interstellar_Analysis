[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1583d6b4'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'd5de56bc'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'a1a32d60'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '69ac8c06'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Thapsigargin_10.000_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Thapsigargin_10.000_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (29199, 1276)
Number of total missing values across all columns: 58398
Data Subset Is Off
Wells held out for testing: ['E14' 'J20']
Wells to use for training, validation, and testing ['E15' 'L14' 'L15' 'J16' 'J17' 'J21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.284030).  Saving model ...
	 Train_Loss: 0.4685 Train_Acc: 78.549 Val_Loss: 0.2840  BEST VAL Loss: 0.2840  Val_Acc: 92.876

Epoch 1: Validation loss decreased (0.284030 --> 0.235481).  Saving model ...
	 Train_Loss: 0.3670 Train_Acc: 91.523 Val_Loss: 0.2355  BEST VAL Loss: 0.2355  Val_Acc: 94.950

Epoch 2: Validation loss decreased (0.235481 --> 0.205235).  Saving model ...
	 Train_Loss: 0.3137 Train_Acc: 93.699 Val_Loss: 0.2052  BEST VAL Loss: 0.2052  Val_Acc: 95.582

Epoch 3: Validation loss decreased (0.205235 --> 0.184096).  Saving model ...
	 Train_Loss: 0.2790 Train_Acc: 94.601 Val_Loss: 0.1841  BEST VAL Loss: 0.1841  Val_Acc: 96.032

Epoch 4: Validation loss decreased (0.184096 --> 0.168087).  Saving model ...
	 Train_Loss: 0.2532 Train_Acc: 95.215 Val_Loss: 0.1681  BEST VAL Loss: 0.1681  Val_Acc: 96.619

Epoch 5: Validation loss decreased (0.168087 --> 0.155487).  Saving model ...
	 Train_Loss: 0.2338 Train_Acc: 95.587 Val_Loss: 0.1555  BEST VAL Loss: 0.1555  Val_Acc: 96.754

Epoch 6: Validation loss decreased (0.155487 --> 0.145160).  Saving model ...
	 Train_Loss: 0.2186 Train_Acc: 95.728 Val_Loss: 0.1452  BEST VAL Loss: 0.1452  Val_Acc: 97.024

Epoch 7: Validation loss decreased (0.145160 --> 0.136533).  Saving model ...
	 Train_Loss: 0.2054 Train_Acc: 96.173 Val_Loss: 0.1365  BEST VAL Loss: 0.1365  Val_Acc: 97.115

Epoch 8: Validation loss decreased (0.136533 --> 0.129188).  Saving model ...
	 Train_Loss: 0.1945 Train_Acc: 96.229 Val_Loss: 0.1292  BEST VAL Loss: 0.1292  Val_Acc: 97.295

Epoch 9: Validation loss decreased (0.129188 --> 0.122919).  Saving model ...
	 Train_Loss: 0.1851 Train_Acc: 96.596 Val_Loss: 0.1229  BEST VAL Loss: 0.1229  Val_Acc: 97.565

Epoch 10: Validation loss decreased (0.122919 --> 0.117416).  Saving model ...
	 Train_Loss: 0.1767 Train_Acc: 96.731 Val_Loss: 0.1174  BEST VAL Loss: 0.1174  Val_Acc: 97.701

Epoch 11: Validation loss decreased (0.117416 --> 0.112559).  Saving model ...
	 Train_Loss: 0.1696 Train_Acc: 96.754 Val_Loss: 0.1126  BEST VAL Loss: 0.1126  Val_Acc: 97.656

Epoch 12: Validation loss decreased (0.112559 --> 0.108245).  Saving model ...
	 Train_Loss: 0.1630 Train_Acc: 97.052 Val_Loss: 0.1082  BEST VAL Loss: 0.1082  Val_Acc: 97.836

Epoch 13: Validation loss decreased (0.108245 --> 0.104421).  Saving model ...
	 Train_Loss: 0.1572 Train_Acc: 97.193 Val_Loss: 0.1044  BEST VAL Loss: 0.1044  Val_Acc: 97.791

Epoch 14: Validation loss decreased (0.104421 --> 0.100951).  Saving model ...
	 Train_Loss: 0.1519 Train_Acc: 97.244 Val_Loss: 0.1010  BEST VAL Loss: 0.1010  Val_Acc: 97.881

Epoch 15: Validation loss decreased (0.100951 --> 0.097817).  Saving model ...
	 Train_Loss: 0.1471 Train_Acc: 97.205 Val_Loss: 0.0978  BEST VAL Loss: 0.0978  Val_Acc: 97.836

Epoch 16: Validation loss decreased (0.097817 --> 0.095002).  Saving model ...
	 Train_Loss: 0.1426 Train_Acc: 97.458 Val_Loss: 0.0950  BEST VAL Loss: 0.0950  Val_Acc: 97.881

Epoch 17: Validation loss decreased (0.095002 --> 0.092375).  Saving model ...
	 Train_Loss: 0.1386 Train_Acc: 97.520 Val_Loss: 0.0924  BEST VAL Loss: 0.0924  Val_Acc: 98.061

Epoch 18: Validation loss decreased (0.092375 --> 0.089962).  Saving model ...
	 Train_Loss: 0.1349 Train_Acc: 97.436 Val_Loss: 0.0900  BEST VAL Loss: 0.0900  Val_Acc: 98.061

Epoch 19: Validation loss decreased (0.089962 --> 0.087751).  Saving model ...
	 Train_Loss: 0.1314 Train_Acc: 97.588 Val_Loss: 0.0878  BEST VAL Loss: 0.0878  Val_Acc: 98.197

Epoch 20: Validation loss decreased (0.087751 --> 0.085705).  Saving model ...
	 Train_Loss: 0.1282 Train_Acc: 97.684 Val_Loss: 0.0857  BEST VAL Loss: 0.0857  Val_Acc: 98.106

Epoch 21: Validation loss decreased (0.085705 --> 0.083798).  Saving model ...
	 Train_Loss: 0.1251 Train_Acc: 97.791 Val_Loss: 0.0838  BEST VAL Loss: 0.0838  Val_Acc: 98.197

Epoch 22: Validation loss decreased (0.083798 --> 0.082062).  Saving model ...
	 Train_Loss: 0.1223 Train_Acc: 97.740 Val_Loss: 0.0821  BEST VAL Loss: 0.0821  Val_Acc: 98.061

Epoch 23: Validation loss decreased (0.082062 --> 0.080405).  Saving model ...
	 Train_Loss: 0.1196 Train_Acc: 97.819 Val_Loss: 0.0804  BEST VAL Loss: 0.0804  Val_Acc: 98.151

Epoch 24: Validation loss decreased (0.080405 --> 0.078844).  Saving model ...
	 Train_Loss: 0.1171 Train_Acc: 97.853 Val_Loss: 0.0788  BEST VAL Loss: 0.0788  Val_Acc: 98.151

Epoch 25: Validation loss decreased (0.078844 --> 0.077358).  Saving model ...
	 Train_Loss: 0.1147 Train_Acc: 97.853 Val_Loss: 0.0774  BEST VAL Loss: 0.0774  Val_Acc: 98.242

Epoch 26: Validation loss decreased (0.077358 --> 0.075973).  Saving model ...
	 Train_Loss: 0.1124 Train_Acc: 97.977 Val_Loss: 0.0760  BEST VAL Loss: 0.0760  Val_Acc: 98.242

Epoch 27: Validation loss decreased (0.075973 --> 0.074676).  Saving model ...
	 Train_Loss: 0.1103 Train_Acc: 97.960 Val_Loss: 0.0747  BEST VAL Loss: 0.0747  Val_Acc: 98.151

Epoch 28: Validation loss decreased (0.074676 --> 0.073449).  Saving model ...
	 Train_Loss: 0.1082 Train_Acc: 97.920 Val_Loss: 0.0734  BEST VAL Loss: 0.0734  Val_Acc: 98.242

Epoch 29: Validation loss decreased (0.073449 --> 0.072273).  Saving model ...
	 Train_Loss: 0.1063 Train_Acc: 98.123 Val_Loss: 0.0723  BEST VAL Loss: 0.0723  Val_Acc: 98.242

Epoch 30: Validation loss decreased (0.072273 --> 0.071191).  Saving model ...
	 Train_Loss: 0.1045 Train_Acc: 98.151 Val_Loss: 0.0712  BEST VAL Loss: 0.0712  Val_Acc: 98.242

Epoch 31: Validation loss decreased (0.071191 --> 0.070150).  Saving model ...
	 Train_Loss: 0.1027 Train_Acc: 98.010 Val_Loss: 0.0701  BEST VAL Loss: 0.0701  Val_Acc: 98.287

Epoch 32: Validation loss decreased (0.070150 --> 0.069151).  Saving model ...
	 Train_Loss: 0.1010 Train_Acc: 98.168 Val_Loss: 0.0692  BEST VAL Loss: 0.0692  Val_Acc: 98.377

Epoch 33: Validation loss decreased (0.069151 --> 0.068230).  Saving model ...
	 Train_Loss: 0.0994 Train_Acc: 98.242 Val_Loss: 0.0682  BEST VAL Loss: 0.0682  Val_Acc: 98.377

Epoch 34: Validation loss decreased (0.068230 --> 0.067337).  Saving model ...
	 Train_Loss: 0.0978 Train_Acc: 98.309 Val_Loss: 0.0673  BEST VAL Loss: 0.0673  Val_Acc: 98.422

Epoch 35: Validation loss decreased (0.067337 --> 0.066491).  Saving model ...
	 Train_Loss: 0.0964 Train_Acc: 98.196 Val_Loss: 0.0665  BEST VAL Loss: 0.0665  Val_Acc: 98.377

Epoch 36: Validation loss decreased (0.066491 --> 0.065679).  Saving model ...
	 Train_Loss: 0.0950 Train_Acc: 98.106 Val_Loss: 0.0657  BEST VAL Loss: 0.0657  Val_Acc: 98.377

Epoch 37: Validation loss decreased (0.065679 --> 0.064908).  Saving model ...
	 Train_Loss: 0.0935 Train_Acc: 98.467 Val_Loss: 0.0649  BEST VAL Loss: 0.0649  Val_Acc: 98.377

Epoch 38: Validation loss decreased (0.064908 --> 0.064169).  Saving model ...
	 Train_Loss: 0.0922 Train_Acc: 98.354 Val_Loss: 0.0642  BEST VAL Loss: 0.0642  Val_Acc: 98.512

Epoch 39: Validation loss decreased (0.064169 --> 0.063463).  Saving model ...
	 Train_Loss: 0.0910 Train_Acc: 98.275 Val_Loss: 0.0635  BEST VAL Loss: 0.0635  Val_Acc: 98.467

Epoch 40: Validation loss decreased (0.063463 --> 0.062790).  Saving model ...
	 Train_Loss: 0.0897 Train_Acc: 98.366 Val_Loss: 0.0628  BEST VAL Loss: 0.0628  Val_Acc: 98.512

Epoch 41: Validation loss decreased (0.062790 --> 0.062141).  Saving model ...
	 Train_Loss: 0.0885 Train_Acc: 98.416 Val_Loss: 0.0621  BEST VAL Loss: 0.0621  Val_Acc: 98.512

Epoch 42: Validation loss decreased (0.062141 --> 0.061522).  Saving model ...
	 Train_Loss: 0.0873 Train_Acc: 98.495 Val_Loss: 0.0615  BEST VAL Loss: 0.0615  Val_Acc: 98.467

Epoch 43: Validation loss decreased (0.061522 --> 0.060928).  Saving model ...
	 Train_Loss: 0.0862 Train_Acc: 98.411 Val_Loss: 0.0609  BEST VAL Loss: 0.0609  Val_Acc: 98.422

Epoch 44: Validation loss decreased (0.060928 --> 0.060356).  Saving model ...
	 Train_Loss: 0.0852 Train_Acc: 98.377 Val_Loss: 0.0604  BEST VAL Loss: 0.0604  Val_Acc: 98.467

Epoch 45: Validation loss decreased (0.060356 --> 0.059803).  Saving model ...
	 Train_Loss: 0.0842 Train_Acc: 98.287 Val_Loss: 0.0598  BEST VAL Loss: 0.0598  Val_Acc: 98.512

Epoch 46: Validation loss decreased (0.059803 --> 0.059276).  Saving model ...
	 Train_Loss: 0.0831 Train_Acc: 98.450 Val_Loss: 0.0593  BEST VAL Loss: 0.0593  Val_Acc: 98.467

Epoch 47: Validation loss decreased (0.059276 --> 0.058771).  Saving model ...
	 Train_Loss: 0.0822 Train_Acc: 98.399 Val_Loss: 0.0588  BEST VAL Loss: 0.0588  Val_Acc: 98.512

Epoch 48: Validation loss decreased (0.058771 --> 0.058284).  Saving model ...
	 Train_Loss: 0.0812 Train_Acc: 98.552 Val_Loss: 0.0583  BEST VAL Loss: 0.0583  Val_Acc: 98.467

Epoch 49: Validation loss decreased (0.058284 --> 0.057828).  Saving model ...
	 Train_Loss: 0.0803 Train_Acc: 98.484 Val_Loss: 0.0578  BEST VAL Loss: 0.0578  Val_Acc: 98.467

Epoch 50: Validation loss decreased (0.057828 --> 0.057389).  Saving model ...
	 Train_Loss: 0.0794 Train_Acc: 98.535 Val_Loss: 0.0574  BEST VAL Loss: 0.0574  Val_Acc: 98.467

Epoch 51: Validation loss decreased (0.057389 --> 0.056954).  Saving model ...
	 Train_Loss: 0.0786 Train_Acc: 98.574 Val_Loss: 0.0570  BEST VAL Loss: 0.0570  Val_Acc: 98.512

Epoch 52: Validation loss decreased (0.056954 --> 0.056539).  Saving model ...
	 Train_Loss: 0.0777 Train_Acc: 98.574 Val_Loss: 0.0565  BEST VAL Loss: 0.0565  Val_Acc: 98.512

Epoch 53: Validation loss decreased (0.056539 --> 0.056142).  Saving model ...
	 Train_Loss: 0.0769 Train_Acc: 98.467 Val_Loss: 0.0561  BEST VAL Loss: 0.0561  Val_Acc: 98.512

Epoch 54: Validation loss decreased (0.056142 --> 0.055745).  Saving model ...
	 Train_Loss: 0.0761 Train_Acc: 98.506 Val_Loss: 0.0557  BEST VAL Loss: 0.0557  Val_Acc: 98.512

Epoch 55: Validation loss decreased (0.055745 --> 0.055369).  Saving model ...
	 Train_Loss: 0.0753 Train_Acc: 98.636 Val_Loss: 0.0554  BEST VAL Loss: 0.0554  Val_Acc: 98.602

Epoch 56: Validation loss decreased (0.055369 --> 0.055007).  Saving model ...
	 Train_Loss: 0.0746 Train_Acc: 98.709 Val_Loss: 0.0550  BEST VAL Loss: 0.0550  Val_Acc: 98.557

Epoch 57: Validation loss decreased (0.055007 --> 0.054653).  Saving model ...
	 Train_Loss: 0.0738 Train_Acc: 98.608 Val_Loss: 0.0547  BEST VAL Loss: 0.0547  Val_Acc: 98.557

Epoch 58: Validation loss decreased (0.054653 --> 0.054308).  Saving model ...
	 Train_Loss: 0.0731 Train_Acc: 98.659 Val_Loss: 0.0543  BEST VAL Loss: 0.0543  Val_Acc: 98.557

Epoch 59: Validation loss decreased (0.054308 --> 0.053977).  Saving model ...
	 Train_Loss: 0.0724 Train_Acc: 98.642 Val_Loss: 0.0540  BEST VAL Loss: 0.0540  Val_Acc: 98.693

Epoch 60: Validation loss decreased (0.053977 --> 0.053658).  Saving model ...
	 Train_Loss: 0.0717 Train_Acc: 98.608 Val_Loss: 0.0537  BEST VAL Loss: 0.0537  Val_Acc: 98.557

Epoch 61: Validation loss decreased (0.053658 --> 0.053353).  Saving model ...
	 Train_Loss: 0.0710 Train_Acc: 98.681 Val_Loss: 0.0534  BEST VAL Loss: 0.0534  Val_Acc: 98.602

Epoch 62: Validation loss decreased (0.053353 --> 0.053065).  Saving model ...
	 Train_Loss: 0.0704 Train_Acc: 98.681 Val_Loss: 0.0531  BEST VAL Loss: 0.0531  Val_Acc: 98.557

Epoch 63: Validation loss decreased (0.053065 --> 0.052777).  Saving model ...
	 Train_Loss: 0.0697 Train_Acc: 98.743 Val_Loss: 0.0528  BEST VAL Loss: 0.0528  Val_Acc: 98.693

Epoch 64: Validation loss decreased (0.052777 --> 0.052497).  Saving model ...
	 Train_Loss: 0.0691 Train_Acc: 98.647 Val_Loss: 0.0525  BEST VAL Loss: 0.0525  Val_Acc: 98.647

Epoch 65: Validation loss decreased (0.052497 --> 0.052235).  Saving model ...
	 Train_Loss: 0.0685 Train_Acc: 98.602 Val_Loss: 0.0522  BEST VAL Loss: 0.0522  Val_Acc: 98.647

Epoch 66: Validation loss decreased (0.052235 --> 0.051978).  Saving model ...
	 Train_Loss: 0.0679 Train_Acc: 98.732 Val_Loss: 0.0520  BEST VAL Loss: 0.0520  Val_Acc: 98.512

Epoch 67: Validation loss decreased (0.051978 --> 0.051727).  Saving model ...
	 Train_Loss: 0.0673 Train_Acc: 98.653 Val_Loss: 0.0517  BEST VAL Loss: 0.0517  Val_Acc: 98.602

Epoch 68: Validation loss decreased (0.051727 --> 0.051494).  Saving model ...
	 Train_Loss: 0.0667 Train_Acc: 98.726 Val_Loss: 0.0515  BEST VAL Loss: 0.0515  Val_Acc: 98.647

Epoch 69: Validation loss decreased (0.051494 --> 0.051258).  Saving model ...
	 Train_Loss: 0.0662 Train_Acc: 98.664 Val_Loss: 0.0513  BEST VAL Loss: 0.0513  Val_Acc: 98.602

Epoch 70: Validation loss decreased (0.051258 --> 0.051031).  Saving model ...
	 Train_Loss: 0.0656 Train_Acc: 98.805 Val_Loss: 0.0510  BEST VAL Loss: 0.0510  Val_Acc: 98.557

Epoch 71: Validation loss decreased (0.051031 --> 0.050811).  Saving model ...
	 Train_Loss: 0.0651 Train_Acc: 98.676 Val_Loss: 0.0508  BEST VAL Loss: 0.0508  Val_Acc: 98.557

Epoch 72: Validation loss decreased (0.050811 --> 0.050601).  Saving model ...
	 Train_Loss: 0.0646 Train_Acc: 98.771 Val_Loss: 0.0506  BEST VAL Loss: 0.0506  Val_Acc: 98.693

Epoch 73: Validation loss decreased (0.050601 --> 0.050396).  Saving model ...
	 Train_Loss: 0.0640 Train_Acc: 98.704 Val_Loss: 0.0504  BEST VAL Loss: 0.0504  Val_Acc: 98.647

Epoch 74: Validation loss decreased (0.050396 --> 0.050194).  Saving model ...
	 Train_Loss: 0.0635 Train_Acc: 98.862 Val_Loss: 0.0502  BEST VAL Loss: 0.0502  Val_Acc: 98.647

Epoch 75: Validation loss decreased (0.050194 --> 0.050001).  Saving model ...
	 Train_Loss: 0.0630 Train_Acc: 98.895 Val_Loss: 0.0500  BEST VAL Loss: 0.0500  Val_Acc: 98.693

Epoch 76: Validation loss decreased (0.050001 --> 0.049807).  Saving model ...
	 Train_Loss: 0.0626 Train_Acc: 98.738 Val_Loss: 0.0498  BEST VAL Loss: 0.0498  Val_Acc: 98.647

Epoch 77: Validation loss decreased (0.049807 --> 0.049616).  Saving model ...
	 Train_Loss: 0.0621 Train_Acc: 98.777 Val_Loss: 0.0496  BEST VAL Loss: 0.0496  Val_Acc: 98.647

Epoch 78: Validation loss decreased (0.049616 --> 0.049428).  Saving model ...
	 Train_Loss: 0.0616 Train_Acc: 98.766 Val_Loss: 0.0494  BEST VAL Loss: 0.0494  Val_Acc: 98.647

Epoch 79: Validation loss decreased (0.049428 --> 0.049245).  Saving model ...
	 Train_Loss: 0.0611 Train_Acc: 99.110 Val_Loss: 0.0492  BEST VAL Loss: 0.0492  Val_Acc: 98.647

Epoch 80: Validation loss decreased (0.049245 --> 0.049066).  Saving model ...
	 Train_Loss: 0.0607 Train_Acc: 99.172 Val_Loss: 0.0491  BEST VAL Loss: 0.0491  Val_Acc: 98.693

Epoch 81: Validation loss decreased (0.049066 --> 0.048896).  Saving model ...
	 Train_Loss: 0.0603 Train_Acc: 99.279 Val_Loss: 0.0489  BEST VAL Loss: 0.0489  Val_Acc: 98.693

Epoch 82: Validation loss decreased (0.048896 --> 0.048738).  Saving model ...
	 Train_Loss: 0.0598 Train_Acc: 99.301 Val_Loss: 0.0487  BEST VAL Loss: 0.0487  Val_Acc: 98.693

Epoch 83: Validation loss decreased (0.048738 --> 0.048587).  Saving model ...
	 Train_Loss: 0.0594 Train_Acc: 99.239 Val_Loss: 0.0486  BEST VAL Loss: 0.0486  Val_Acc: 98.693

Epoch 84: Validation loss decreased (0.048587 --> 0.048429).  Saving model ...
	 Train_Loss: 0.0590 Train_Acc: 99.188 Val_Loss: 0.0484  BEST VAL Loss: 0.0484  Val_Acc: 98.783

Epoch 85: Validation loss decreased (0.048429 --> 0.048280).  Saving model ...
	 Train_Loss: 0.0586 Train_Acc: 99.234 Val_Loss: 0.0483  BEST VAL Loss: 0.0483  Val_Acc: 98.647

Epoch 86: Validation loss decreased (0.048280 --> 0.048142).  Saving model ...
	 Train_Loss: 0.0582 Train_Acc: 99.245 Val_Loss: 0.0481  BEST VAL Loss: 0.0481  Val_Acc: 98.783

Epoch 87: Validation loss decreased (0.048142 --> 0.047994).  Saving model ...
	 Train_Loss: 0.0577 Train_Acc: 99.250 Val_Loss: 0.0480  BEST VAL Loss: 0.0480  Val_Acc: 98.693

Epoch 88: Validation loss decreased (0.047994 --> 0.047853).  Saving model ...
	 Train_Loss: 0.0574 Train_Acc: 99.205 Val_Loss: 0.0479  BEST VAL Loss: 0.0479  Val_Acc: 98.738

Epoch 89: Validation loss decreased (0.047853 --> 0.047716).  Saving model ...
	 Train_Loss: 0.0570 Train_Acc: 99.301 Val_Loss: 0.0477  BEST VAL Loss: 0.0477  Val_Acc: 98.738

Epoch 90: Validation loss decreased (0.047716 --> 0.047586).  Saving model ...
	 Train_Loss: 0.0566 Train_Acc: 99.177 Val_Loss: 0.0476  BEST VAL Loss: 0.0476  Val_Acc: 98.693

Epoch 91: Validation loss decreased (0.047586 --> 0.047454).  Saving model ...
	 Train_Loss: 0.0563 Train_Acc: 99.295 Val_Loss: 0.0475  BEST VAL Loss: 0.0475  Val_Acc: 98.738

Epoch 92: Validation loss decreased (0.047454 --> 0.047327).  Saving model ...
	 Train_Loss: 0.0559 Train_Acc: 99.374 Val_Loss: 0.0473  BEST VAL Loss: 0.0473  Val_Acc: 98.738

Epoch 93: Validation loss decreased (0.047327 --> 0.047199).  Saving model ...
	 Train_Loss: 0.0555 Train_Acc: 99.318 Val_Loss: 0.0472  BEST VAL Loss: 0.0472  Val_Acc: 98.738

Epoch 94: Validation loss decreased (0.047199 --> 0.047078).  Saving model ...
	 Train_Loss: 0.0552 Train_Acc: 99.357 Val_Loss: 0.0471  BEST VAL Loss: 0.0471  Val_Acc: 98.738

Epoch 95: Validation loss decreased (0.047078 --> 0.046962).  Saving model ...
	 Train_Loss: 0.0548 Train_Acc: 99.250 Val_Loss: 0.0470  BEST VAL Loss: 0.0470  Val_Acc: 98.738

Epoch 96: Validation loss decreased (0.046962 --> 0.046847).  Saving model ...
	 Train_Loss: 0.0545 Train_Acc: 99.256 Val_Loss: 0.0468  BEST VAL Loss: 0.0468  Val_Acc: 98.738

Epoch 97: Validation loss decreased (0.046847 --> 0.046729).  Saving model ...
	 Train_Loss: 0.0541 Train_Acc: 99.369 Val_Loss: 0.0467  BEST VAL Loss: 0.0467  Val_Acc: 98.828

Epoch 98: Validation loss decreased (0.046729 --> 0.046618).  Saving model ...
	 Train_Loss: 0.0538 Train_Acc: 99.391 Val_Loss: 0.0466  BEST VAL Loss: 0.0466  Val_Acc: 98.828

Epoch 99: Validation loss decreased (0.046618 --> 0.046505).  Saving model ...
	 Train_Loss: 0.0535 Train_Acc: 99.228 Val_Loss: 0.0465  BEST VAL Loss: 0.0465  Val_Acc: 98.738

Thapsigargin_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      9891
           1       1.00      1.00      1.00      7852

    accuracy                           1.00     17743
   macro avg       1.00      1.00      1.00     17743
weighted avg       1.00      1.00      1.00     17743

Thapsigargin_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      0.99      0.99      1237
           1       0.99      0.98      0.99       981

    accuracy                           0.99      2218
   macro avg       0.99      0.99      0.99      2218
weighted avg       0.99      0.99      0.99      2218

Thapsigargin_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.99      0.99      1237
           1       0.99      0.98      0.98       981

    accuracy                           0.99      2218
   macro avg       0.99      0.99      0.99      2218
weighted avg       0.99      0.99      0.99      2218

              precision    recall  f1-score   support

           0       0.98      0.99      0.99      1237
           1       0.99      0.98      0.98       981

    accuracy                           0.99      2218
   macro avg       0.99      0.99      0.99      2218
weighted avg       0.99      0.99      0.99      2218

Thapsigargin_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      0.96      0.98      3622
           1       0.96      0.99      0.97      3398

    accuracy                           0.97      7020
   macro avg       0.97      0.98      0.97      7020
weighted avg       0.98      0.97      0.97      7020

              precision    recall  f1-score   support

           0       0.99      0.96      0.98      3622
           1       0.96      0.99      0.97      3398

    accuracy                           0.97      7020
   macro avg       0.97      0.98      0.97      7020
weighted avg       0.98      0.97      0.97      7020

completed
