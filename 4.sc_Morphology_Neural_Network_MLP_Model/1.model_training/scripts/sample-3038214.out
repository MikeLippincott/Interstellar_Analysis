[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '6fe3b6db'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '7535a8b1'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '64a0642a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'f5429eaa'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: DMSO_0.100_DMSO_0.025 treatment_name: LPS_10.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: DMSO_0.100_DMSO_0.025
TREATMENT_NAME: LPS_10.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'LPS_10.000_DMSO_0.025']
The dimensions of the data are: (52453, 1276)
Number of total missing values across all columns: 104906
Data Subset Is Off
Wells held out for testing: ['E20' 'I14']
Wells to use for training, validation, and testing ['B14' 'C14' 'B15' 'C15' 'E16' 'E17' 'E21' 'J14' 'I15' 'J15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.585325).  Saving model ...
	 Train_Loss: 0.6208 Train_Acc: 70.850 Val_Loss: 0.5853  BEST VAL Loss: 0.5853  Val_Acc: 70.909

Epoch 1: Validation loss decreased (0.585325 --> 0.575375).  Saving model ...
	 Train_Loss: 0.6029 Train_Acc: 70.896 Val_Loss: 0.5754  BEST VAL Loss: 0.5754  Val_Acc: 70.909

Epoch 2: Validation loss decreased (0.575375 --> 0.568106).  Saving model ...
	 Train_Loss: 0.5916 Train_Acc: 70.896 Val_Loss: 0.5681  BEST VAL Loss: 0.5681  Val_Acc: 70.909

Epoch 3: Validation loss decreased (0.568106 --> 0.562378).  Saving model ...
	 Train_Loss: 0.5841 Train_Acc: 70.902 Val_Loss: 0.5624  BEST VAL Loss: 0.5624  Val_Acc: 70.909

Epoch 4: Validation loss decreased (0.562378 --> 0.557570).  Saving model ...
	 Train_Loss: 0.5781 Train_Acc: 70.902 Val_Loss: 0.5576  BEST VAL Loss: 0.5576  Val_Acc: 70.909

Epoch 5: Validation loss decreased (0.557570 --> 0.553356).  Saving model ...
	 Train_Loss: 0.5734 Train_Acc: 70.902 Val_Loss: 0.5534  BEST VAL Loss: 0.5534  Val_Acc: 70.909

Epoch 6: Validation loss decreased (0.553356 --> 0.549484).  Saving model ...
	 Train_Loss: 0.5691 Train_Acc: 70.902 Val_Loss: 0.5495  BEST VAL Loss: 0.5495  Val_Acc: 70.909

Epoch 7: Validation loss decreased (0.549484 --> 0.545879).  Saving model ...
	 Train_Loss: 0.5652 Train_Acc: 70.899 Val_Loss: 0.5459  BEST VAL Loss: 0.5459  Val_Acc: 70.909

Epoch 8: Validation loss decreased (0.545879 --> 0.542470).  Saving model ...
	 Train_Loss: 0.5616 Train_Acc: 70.902 Val_Loss: 0.5425  BEST VAL Loss: 0.5425  Val_Acc: 70.909

Epoch 9: Validation loss decreased (0.542470 --> 0.539334).  Saving model ...
	 Train_Loss: 0.5583 Train_Acc: 70.899 Val_Loss: 0.5393  BEST VAL Loss: 0.5393  Val_Acc: 70.909

Epoch 10: Validation loss decreased (0.539334 --> 0.536517).  Saving model ...
	 Train_Loss: 0.5552 Train_Acc: 70.902 Val_Loss: 0.5365  BEST VAL Loss: 0.5365  Val_Acc: 70.909

Epoch 11: Validation loss decreased (0.536517 --> 0.533828).  Saving model ...
	 Train_Loss: 0.5523 Train_Acc: 70.902 Val_Loss: 0.5338  BEST VAL Loss: 0.5338  Val_Acc: 70.909

Epoch 12: Validation loss decreased (0.533828 --> 0.531314).  Saving model ...
	 Train_Loss: 0.5494 Train_Acc: 70.896 Val_Loss: 0.5313  BEST VAL Loss: 0.5313  Val_Acc: 70.909

Epoch 13: Validation loss decreased (0.531314 --> 0.529030).  Saving model ...
	 Train_Loss: 0.5467 Train_Acc: 70.896 Val_Loss: 0.5290  BEST VAL Loss: 0.5290  Val_Acc: 70.909

Epoch 14: Validation loss decreased (0.529030 --> 0.526954).  Saving model ...
	 Train_Loss: 0.5443 Train_Acc: 70.893 Val_Loss: 0.5270  BEST VAL Loss: 0.5270  Val_Acc: 70.909

Epoch 15: Validation loss decreased (0.526954 --> 0.524968).  Saving model ...
	 Train_Loss: 0.5419 Train_Acc: 70.884 Val_Loss: 0.5250  BEST VAL Loss: 0.5250  Val_Acc: 70.909

Epoch 16: Validation loss decreased (0.524968 --> 0.523054).  Saving model ...
	 Train_Loss: 0.5397 Train_Acc: 70.890 Val_Loss: 0.5231  BEST VAL Loss: 0.5231  Val_Acc: 70.909

Epoch 17: Validation loss decreased (0.523054 --> 0.521251).  Saving model ...
	 Train_Loss: 0.5377 Train_Acc: 71.235 Val_Loss: 0.5213  BEST VAL Loss: 0.5213  Val_Acc: 75.397

Epoch 18: Validation loss decreased (0.521251 --> 0.519591).  Saving model ...
	 Train_Loss: 0.5356 Train_Acc: 74.958 Val_Loss: 0.5196  BEST VAL Loss: 0.5196  Val_Acc: 76.203

Epoch 19: Validation loss decreased (0.519591 --> 0.518062).  Saving model ...
	 Train_Loss: 0.5337 Train_Acc: 75.047 Val_Loss: 0.5181  BEST VAL Loss: 0.5181  Val_Acc: 76.157

Epoch 20: Validation loss decreased (0.518062 --> 0.516669).  Saving model ...
	 Train_Loss: 0.5319 Train_Acc: 75.105 Val_Loss: 0.5167  BEST VAL Loss: 0.5167  Val_Acc: 76.180

Epoch 21: Validation loss decreased (0.516669 --> 0.515269).  Saving model ...
	 Train_Loss: 0.5302 Train_Acc: 75.419 Val_Loss: 0.5153  BEST VAL Loss: 0.5153  Val_Acc: 76.663

Epoch 22: Validation loss decreased (0.515269 --> 0.513920).  Saving model ...
	 Train_Loss: 0.5285 Train_Acc: 75.514 Val_Loss: 0.5139  BEST VAL Loss: 0.5139  Val_Acc: 76.479

Epoch 23: Validation loss decreased (0.513920 --> 0.512790).  Saving model ...
	 Train_Loss: 0.5268 Train_Acc: 75.479 Val_Loss: 0.5128  BEST VAL Loss: 0.5128  Val_Acc: 76.732

Epoch 24: Validation loss decreased (0.512790 --> 0.511626).  Saving model ...
	 Train_Loss: 0.5253 Train_Acc: 75.545 Val_Loss: 0.5116  BEST VAL Loss: 0.5116  Val_Acc: 76.801

Epoch 25: Validation loss decreased (0.511626 --> 0.510589).  Saving model ...
	 Train_Loss: 0.5238 Train_Acc: 75.692 Val_Loss: 0.5106  BEST VAL Loss: 0.5106  Val_Acc: 77.238

Epoch 26: Validation loss decreased (0.510589 --> 0.509583).  Saving model ...
	 Train_Loss: 0.5223 Train_Acc: 75.306 Val_Loss: 0.5096  BEST VAL Loss: 0.5096  Val_Acc: 77.100

Epoch 27: Validation loss decreased (0.509583 --> 0.508694).  Saving model ...
	 Train_Loss: 0.5209 Train_Acc: 75.816 Val_Loss: 0.5087  BEST VAL Loss: 0.5087  Val_Acc: 76.824

Epoch 28: Validation loss decreased (0.508694 --> 0.507861).  Saving model ...
	 Train_Loss: 0.5195 Train_Acc: 75.574 Val_Loss: 0.5079  BEST VAL Loss: 0.5079  Val_Acc: 77.077

Epoch 29: Validation loss decreased (0.507861 --> 0.507031).  Saving model ...
	 Train_Loss: 0.5183 Train_Acc: 76.060 Val_Loss: 0.5070  BEST VAL Loss: 0.5070  Val_Acc: 77.008

Epoch 30: Validation loss decreased (0.507031 --> 0.506208).  Saving model ...
	 Train_Loss: 0.5170 Train_Acc: 76.132 Val_Loss: 0.5062  BEST VAL Loss: 0.5062  Val_Acc: 77.537

Epoch 31: Validation loss decreased (0.506208 --> 0.505376).  Saving model ...
	 Train_Loss: 0.5158 Train_Acc: 76.299 Val_Loss: 0.5054  BEST VAL Loss: 0.5054  Val_Acc: 77.307

Epoch 32: Validation loss decreased (0.505376 --> 0.504628).  Saving model ...
	 Train_Loss: 0.5146 Train_Acc: 76.264 Val_Loss: 0.5046  BEST VAL Loss: 0.5046  Val_Acc: 77.100

Epoch 33: Validation loss decreased (0.504628 --> 0.503858).  Saving model ...
	 Train_Loss: 0.5135 Train_Acc: 76.365 Val_Loss: 0.5039  BEST VAL Loss: 0.5039  Val_Acc: 77.675

Epoch 34: Validation loss decreased (0.503858 --> 0.503203).  Saving model ...
	 Train_Loss: 0.5124 Train_Acc: 75.830 Val_Loss: 0.5032  BEST VAL Loss: 0.5032  Val_Acc: 77.307

Epoch 35: Validation loss decreased (0.503203 --> 0.502552).  Saving model ...
	 Train_Loss: 0.5113 Train_Acc: 76.463 Val_Loss: 0.5026  BEST VAL Loss: 0.5026  Val_Acc: 77.399

Epoch 36: Validation loss decreased (0.502552 --> 0.501957).  Saving model ...
	 Train_Loss: 0.5102 Train_Acc: 76.391 Val_Loss: 0.5020  BEST VAL Loss: 0.5020  Val_Acc: 77.054

Epoch 37: Validation loss decreased (0.501957 --> 0.501402).  Saving model ...
	 Train_Loss: 0.5092 Train_Acc: 76.241 Val_Loss: 0.5014  BEST VAL Loss: 0.5014  Val_Acc: 77.169

Epoch 38: Validation loss decreased (0.501402 --> 0.500788).  Saving model ...
	 Train_Loss: 0.5081 Train_Acc: 76.638 Val_Loss: 0.5008  BEST VAL Loss: 0.5008  Val_Acc: 77.929

Epoch 39: Validation loss decreased (0.500788 --> 0.500324).  Saving model ...
	 Train_Loss: 0.5071 Train_Acc: 76.149 Val_Loss: 0.5003  BEST VAL Loss: 0.5003  Val_Acc: 77.376

Epoch 40: Validation loss decreased (0.500324 --> 0.499821).  Saving model ...
	 Train_Loss: 0.5062 Train_Acc: 76.357 Val_Loss: 0.4998  BEST VAL Loss: 0.4998  Val_Acc: 77.768

Epoch 41: Validation loss decreased (0.499821 --> 0.499348).  Saving model ...
	 Train_Loss: 0.5052 Train_Acc: 76.541 Val_Loss: 0.4993  BEST VAL Loss: 0.4993  Val_Acc: 77.699

Epoch 42: Validation loss decreased (0.499348 --> 0.498890).  Saving model ...
	 Train_Loss: 0.5043 Train_Acc: 76.664 Val_Loss: 0.4989  BEST VAL Loss: 0.4989  Val_Acc: 77.445

Epoch 43: Validation loss decreased (0.498890 --> 0.498343).  Saving model ...
	 Train_Loss: 0.5034 Train_Acc: 76.167 Val_Loss: 0.4983  BEST VAL Loss: 0.4983  Val_Acc: 78.159

Epoch 44: Validation loss decreased (0.498343 --> 0.497959).  Saving model ...
	 Train_Loss: 0.5025 Train_Acc: 76.431 Val_Loss: 0.4980  BEST VAL Loss: 0.4980  Val_Acc: 78.320

Epoch 45: Validation loss decreased (0.497959 --> 0.497561).  Saving model ...
	 Train_Loss: 0.5016 Train_Acc: 76.590 Val_Loss: 0.4976  BEST VAL Loss: 0.4976  Val_Acc: 77.814

Epoch 46: Validation loss decreased (0.497561 --> 0.497167).  Saving model ...
	 Train_Loss: 0.5008 Train_Acc: 76.558 Val_Loss: 0.4972  BEST VAL Loss: 0.4972  Val_Acc: 77.330

Epoch 47: Validation loss decreased (0.497167 --> 0.496827).  Saving model ...
	 Train_Loss: 0.5000 Train_Acc: 76.474 Val_Loss: 0.4968  BEST VAL Loss: 0.4968  Val_Acc: 77.906

Epoch 48: Validation loss decreased (0.496827 --> 0.496428).  Saving model ...
	 Train_Loss: 0.4992 Train_Acc: 76.817 Val_Loss: 0.4964  BEST VAL Loss: 0.4964  Val_Acc: 78.067

Epoch 49: Validation loss decreased (0.496428 --> 0.495988).  Saving model ...
	 Train_Loss: 0.4984 Train_Acc: 76.454 Val_Loss: 0.4960  BEST VAL Loss: 0.4960  Val_Acc: 78.067

Epoch 50: Validation loss decreased (0.495988 --> 0.495620).  Saving model ...
	 Train_Loss: 0.4976 Train_Acc: 76.840 Val_Loss: 0.4956  BEST VAL Loss: 0.4956  Val_Acc: 77.768

Epoch 51: Validation loss decreased (0.495620 --> 0.495296).  Saving model ...
	 Train_Loss: 0.4968 Train_Acc: 76.756 Val_Loss: 0.4953  BEST VAL Loss: 0.4953  Val_Acc: 77.445

Epoch 52: Validation loss decreased (0.495296 --> 0.494977).  Saving model ...
	 Train_Loss: 0.4961 Train_Acc: 76.500 Val_Loss: 0.4950  BEST VAL Loss: 0.4950  Val_Acc: 78.090

Epoch 53: Validation loss decreased (0.494977 --> 0.494588).  Saving model ...
	 Train_Loss: 0.4953 Train_Acc: 76.825 Val_Loss: 0.4946  BEST VAL Loss: 0.4946  Val_Acc: 78.205

Epoch 54: Validation loss decreased (0.494588 --> 0.494325).  Saving model ...
	 Train_Loss: 0.4946 Train_Acc: 77.027 Val_Loss: 0.4943  BEST VAL Loss: 0.4943  Val_Acc: 77.883

Epoch 55: Validation loss decreased (0.494325 --> 0.494064).  Saving model ...
	 Train_Loss: 0.4939 Train_Acc: 76.601 Val_Loss: 0.4941  BEST VAL Loss: 0.4941  Val_Acc: 77.837

Epoch 56: Validation loss decreased (0.494064 --> 0.493800).  Saving model ...
	 Train_Loss: 0.4932 Train_Acc: 76.877 Val_Loss: 0.4938  BEST VAL Loss: 0.4938  Val_Acc: 78.044

Epoch 57: Validation loss decreased (0.493800 --> 0.493529).  Saving model ...
	 Train_Loss: 0.4926 Train_Acc: 76.736 Val_Loss: 0.4935  BEST VAL Loss: 0.4935  Val_Acc: 77.860

Epoch 58: Validation loss decreased (0.493529 --> 0.493195).  Saving model ...
	 Train_Loss: 0.4919 Train_Acc: 76.661 Val_Loss: 0.4932  BEST VAL Loss: 0.4932  Val_Acc: 77.975

Epoch 59: Validation loss decreased (0.493195 --> 0.492913).  Saving model ...
	 Train_Loss: 0.4912 Train_Acc: 76.794 Val_Loss: 0.4929  BEST VAL Loss: 0.4929  Val_Acc: 78.159

Epoch 60: Validation loss decreased (0.492913 --> 0.492675).  Saving model ...
	 Train_Loss: 0.4906 Train_Acc: 76.779 Val_Loss: 0.4927  BEST VAL Loss: 0.4927  Val_Acc: 78.366

Epoch 61: Validation loss decreased (0.492675 --> 0.492444).  Saving model ...
	 Train_Loss: 0.4900 Train_Acc: 76.840 Val_Loss: 0.4924  BEST VAL Loss: 0.4924  Val_Acc: 78.228

Epoch 62: Validation loss decreased (0.492444 --> 0.492165).  Saving model ...
	 Train_Loss: 0.4894 Train_Acc: 76.872 Val_Loss: 0.4922  BEST VAL Loss: 0.4922  Val_Acc: 78.090

Epoch 63: Validation loss decreased (0.492165 --> 0.491977).  Saving model ...
	 Train_Loss: 0.4888 Train_Acc: 76.823 Val_Loss: 0.4920  BEST VAL Loss: 0.4920  Val_Acc: 78.274

Epoch 64: Validation loss decreased (0.491977 --> 0.491778).  Saving model ...
	 Train_Loss: 0.4881 Train_Acc: 77.303 Val_Loss: 0.4918  BEST VAL Loss: 0.4918  Val_Acc: 78.044

Epoch 65: Validation loss decreased (0.491778 --> 0.491564).  Saving model ...
	 Train_Loss: 0.4876 Train_Acc: 76.995 Val_Loss: 0.4916  BEST VAL Loss: 0.4916  Val_Acc: 78.619

Epoch 66: Validation loss decreased (0.491564 --> 0.491372).  Saving model ...
	 Train_Loss: 0.4869 Train_Acc: 77.116 Val_Loss: 0.4914  BEST VAL Loss: 0.4914  Val_Acc: 78.182

Epoch 67: Validation loss decreased (0.491372 --> 0.491200).  Saving model ...
	 Train_Loss: 0.4864 Train_Acc: 76.805 Val_Loss: 0.4912  BEST VAL Loss: 0.4912  Val_Acc: 78.435

Epoch 68: Validation loss decreased (0.491200 --> 0.491045).  Saving model ...
	 Train_Loss: 0.4859 Train_Acc: 76.903 Val_Loss: 0.4910  BEST VAL Loss: 0.4910  Val_Acc: 78.366

Epoch 69: Validation loss decreased (0.491045 --> 0.490941).  Saving model ...
	 Train_Loss: 0.4853 Train_Acc: 77.335 Val_Loss: 0.4909  BEST VAL Loss: 0.4909  Val_Acc: 78.228

Epoch 70: Validation loss decreased (0.490941 --> 0.490805).  Saving model ...
	 Train_Loss: 0.4848 Train_Acc: 76.918 Val_Loss: 0.4908  BEST VAL Loss: 0.4908  Val_Acc: 78.527

Epoch 71: Validation loss decreased (0.490805 --> 0.490602).  Saving model ...
	 Train_Loss: 0.4842 Train_Acc: 77.056 Val_Loss: 0.4906  BEST VAL Loss: 0.4906  Val_Acc: 78.389

Epoch 72: Validation loss decreased (0.490602 --> 0.490463).  Saving model ...
	 Train_Loss: 0.4837 Train_Acc: 77.064 Val_Loss: 0.4905  BEST VAL Loss: 0.4905  Val_Acc: 78.780

Epoch 73: Validation loss decreased (0.490463 --> 0.490356).  Saving model ...
	 Train_Loss: 0.4831 Train_Acc: 77.254 Val_Loss: 0.4904  BEST VAL Loss: 0.4904  Val_Acc: 78.642

Epoch 74: Validation loss decreased (0.490356 --> 0.490238).  Saving model ...
	 Train_Loss: 0.4826 Train_Acc: 76.814 Val_Loss: 0.4902  BEST VAL Loss: 0.4902  Val_Acc: 78.481

Epoch 75: Validation loss decreased (0.490238 --> 0.490225).  Saving model ...
	 Train_Loss: 0.4820 Train_Acc: 77.248 Val_Loss: 0.4902  BEST VAL Loss: 0.4902  Val_Acc: 78.297

Epoch 76: Validation loss decreased (0.490225 --> 0.490129).  Saving model ...
	 Train_Loss: 0.4815 Train_Acc: 77.012 Val_Loss: 0.4901  BEST VAL Loss: 0.4901  Val_Acc: 78.389

Epoch 77: Validation loss decreased (0.490129 --> 0.490027).  Saving model ...
	 Train_Loss: 0.4810 Train_Acc: 76.811 Val_Loss: 0.4900  BEST VAL Loss: 0.4900  Val_Acc: 78.159

Epoch 78: Validation loss decreased (0.490027 --> 0.489987).  Saving model ...
	 Train_Loss: 0.4805 Train_Acc: 77.225 Val_Loss: 0.4900  BEST VAL Loss: 0.4900  Val_Acc: 78.159

Epoch 79: Validation loss decreased (0.489987 --> 0.489951).  Saving model ...
	 Train_Loss: 0.4800 Train_Acc: 77.286 Val_Loss: 0.4900  BEST VAL Loss: 0.4900  Val_Acc: 78.366

Epoch 80: Validation loss decreased (0.489951 --> 0.489871).  Saving model ...
	 Train_Loss: 0.4795 Train_Acc: 76.932 Val_Loss: 0.4899  BEST VAL Loss: 0.4899  Val_Acc: 77.906

Epoch 81: Validation loss decreased (0.489871 --> 0.489788).  Saving model ...
	 Train_Loss: 0.4789 Train_Acc: 77.280 Val_Loss: 0.4898  BEST VAL Loss: 0.4898  Val_Acc: 78.481

Epoch 82: Validation loss decreased (0.489788 --> 0.489673).  Saving model ...
	 Train_Loss: 0.4784 Train_Acc: 77.398 Val_Loss: 0.4897  BEST VAL Loss: 0.4897  Val_Acc: 78.412

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.4780 Train_Acc: 77.018 Val_Loss: 0.4897  BEST VAL Loss: 0.4897  Val_Acc: 78.688

Epoch 84: Validation loss decreased (0.489673 --> 0.489663).  Saving model ...
	 Train_Loss: 0.4774 Train_Acc: 77.579 Val_Loss: 0.4897  BEST VAL Loss: 0.4897  Val_Acc: 78.320

Epoch 85: Validation loss decreased (0.489663 --> 0.489636).  Saving model ...
	 Train_Loss: 0.4770 Train_Acc: 77.171 Val_Loss: 0.4896  BEST VAL Loss: 0.4896  Val_Acc: 78.366

Epoch 86: Validation loss decreased (0.489636 --> 0.489626).  Saving model ...
	 Train_Loss: 0.4765 Train_Acc: 77.185 Val_Loss: 0.4896  BEST VAL Loss: 0.4896  Val_Acc: 78.688

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.4760 Train_Acc: 77.125 Val_Loss: 0.4896  BEST VAL Loss: 0.4896  Val_Acc: 78.964

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.4756 Train_Acc: 77.024 Val_Loss: 0.4896  BEST VAL Loss: 0.4896  Val_Acc: 78.527

Epoch 89: Validation loss decreased (0.489626 --> 0.489608).  Saving model ...
	 Train_Loss: 0.4751 Train_Acc: 77.513 Val_Loss: 0.4896  BEST VAL Loss: 0.4896  Val_Acc: 78.757

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.4746 Train_Acc: 77.530 Val_Loss: 0.4896  BEST VAL Loss: 0.4896  Val_Acc: 78.435

Epoch 91: Validation loss decreased (0.489608 --> 0.489565).  Saving model ...
	 Train_Loss: 0.4741 Train_Acc: 77.148 Val_Loss: 0.4896  BEST VAL Loss: 0.4896  Val_Acc: 78.826

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.4737 Train_Acc: 77.317 Val_Loss: 0.4896  BEST VAL Loss: 0.4896  Val_Acc: 78.412

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.4732 Train_Acc: 76.949 Val_Loss: 0.4896  BEST VAL Loss: 0.4896  Val_Acc: 78.320

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.4728 Train_Acc: 77.228 Val_Loss: 0.4896  BEST VAL Loss: 0.4896  Val_Acc: 78.458

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.4723 Train_Acc: 77.231 Val_Loss: 0.4896  BEST VAL Loss: 0.4896  Val_Acc: 78.274

Epoch 96: Validation loss did not decrease
	 Train_Loss: 0.4719 Train_Acc: 77.211 Val_Loss: 0.4896  BEST VAL Loss: 0.4896  Val_Acc: 78.688

Epoch 97: Validation loss decreased (0.489565 --> 0.489560).  Saving model ...
	 Train_Loss: 0.4715 Train_Acc: 77.303 Val_Loss: 0.4896  BEST VAL Loss: 0.4896  Val_Acc: 78.849

Epoch 98: Validation loss decreased (0.489560 --> 0.489531).  Saving model ...
	 Train_Loss: 0.4710 Train_Acc: 77.266 Val_Loss: 0.4895  BEST VAL Loss: 0.4895  Val_Acc: 78.435

Epoch 99: Validation loss decreased (0.489531 --> 0.489529).  Saving model ...
	 Train_Loss: 0.4706 Train_Acc: 77.582 Val_Loss: 0.4895  BEST VAL Loss: 0.4895  Val_Acc: 78.711

DMSO_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.83      0.94      0.88     24644
           1       0.80      0.54      0.64     10114

    accuracy                           0.83     34758
   macro avg       0.81      0.74      0.76     34758
weighted avg       0.82      0.83      0.81     34758

DMSO_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.81      0.92      0.86      3081
           1       0.70      0.47      0.56      1264

    accuracy                           0.79      4345
   macro avg       0.75      0.69      0.71      4345
weighted avg       0.78      0.79      0.77      4345

DMSO_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.80      0.91      0.85      3081
           1       0.67      0.45      0.54      1264

    accuracy                           0.78      4345
   macro avg       0.74      0.68      0.69      4345
weighted avg       0.76      0.78      0.76      4345

              precision    recall  f1-score   support

           0       0.80      0.91      0.85      3081
           1       0.67      0.45      0.54      1264

    accuracy                           0.78      4345
   macro avg       0.74      0.68      0.69      4345
weighted avg       0.76      0.78      0.76      4345

DMSO_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.63      0.86      0.73      4837
           1       0.72      0.42      0.53      4168

    accuracy                           0.66      9005
   macro avg       0.67      0.64      0.63      9005
weighted avg       0.67      0.66      0.64      9005

              precision    recall  f1-score   support

           0       0.63      0.86      0.73      4837
           1       0.72      0.42      0.53      4168

    accuracy                           0.66      9005
   macro avg       0.67      0.64      0.63      9005
weighted avg       0.67      0.66      0.64      9005

completed
