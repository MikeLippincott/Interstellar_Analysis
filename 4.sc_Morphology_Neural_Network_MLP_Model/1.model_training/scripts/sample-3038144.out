[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b7e60b67'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '61399af7'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '7f156f38'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '20fa9e09'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Thapsigargin_1.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Thapsigargin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (28168, 1276)
Number of total missing values across all columns: 27532
Data Subset Is Off
Wells held out for testing: ['D14' 'M20']
Wells to use for training, validation, and testing ['D15' 'K14' 'K15' 'M16' 'M17' 'M21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.270429).  Saving model ...
	 Train_Loss: 0.4345 Train_Acc: 82.757 Val_Loss: 0.2704  BEST VAL Loss: 0.2704  Val_Acc: 91.060

Epoch 1: Validation loss decreased (0.270429 --> 0.225525).  Saving model ...
	 Train_Loss: 0.3411 Train_Acc: 91.863 Val_Loss: 0.2255  BEST VAL Loss: 0.2255  Val_Acc: 93.390

Epoch 2: Validation loss decreased (0.225525 --> 0.198954).  Saving model ...
	 Train_Loss: 0.2907 Train_Acc: 93.937 Val_Loss: 0.1990  BEST VAL Loss: 0.1990  Val_Acc: 94.341

Epoch 3: Validation loss decreased (0.198954 --> 0.179731).  Saving model ...
	 Train_Loss: 0.2574 Train_Acc: 94.960 Val_Loss: 0.1797  BEST VAL Loss: 0.1797  Val_Acc: 95.388

Epoch 4: Validation loss decreased (0.179731 --> 0.162860).  Saving model ...
	 Train_Loss: 0.2332 Train_Acc: 95.459 Val_Loss: 0.1629  BEST VAL Loss: 0.1629  Val_Acc: 95.911

Epoch 5: Validation loss decreased (0.162860 --> 0.155131).  Saving model ...
	 Train_Loss: 0.2152 Train_Acc: 95.905 Val_Loss: 0.1551  BEST VAL Loss: 0.1551  Val_Acc: 96.767

Epoch 6: Validation loss decreased (0.155131 --> 0.147028).  Saving model ...
	 Train_Loss: 0.2002 Train_Acc: 96.362 Val_Loss: 0.1470  BEST VAL Loss: 0.1470  Val_Acc: 96.909

Epoch 7: Validation loss decreased (0.147028 --> 0.140015).  Saving model ...
	 Train_Loss: 0.1880 Train_Acc: 96.517 Val_Loss: 0.1400  BEST VAL Loss: 0.1400  Val_Acc: 97.147

Epoch 8: Validation loss decreased (0.140015 --> 0.133145).  Saving model ...
	 Train_Loss: 0.1775 Train_Acc: 96.939 Val_Loss: 0.1331  BEST VAL Loss: 0.1331  Val_Acc: 97.242

Epoch 9: Validation loss decreased (0.133145 --> 0.128210).  Saving model ...
	 Train_Loss: 0.1684 Train_Acc: 97.218 Val_Loss: 0.1282  BEST VAL Loss: 0.1282  Val_Acc: 97.337

Epoch 10: Validation loss decreased (0.128210 --> 0.122357).  Saving model ...
	 Train_Loss: 0.1604 Train_Acc: 97.456 Val_Loss: 0.1224  BEST VAL Loss: 0.1224  Val_Acc: 97.385

Epoch 11: Validation loss decreased (0.122357 --> 0.119087).  Saving model ...
	 Train_Loss: 0.1533 Train_Acc: 97.563 Val_Loss: 0.1191  BEST VAL Loss: 0.1191  Val_Acc: 97.575

Epoch 12: Validation loss decreased (0.119087 --> 0.115145).  Saving model ...
	 Train_Loss: 0.1470 Train_Acc: 97.729 Val_Loss: 0.1151  BEST VAL Loss: 0.1151  Val_Acc: 97.718

Epoch 13: Validation loss decreased (0.115145 --> 0.110953).  Saving model ...
	 Train_Loss: 0.1413 Train_Acc: 97.878 Val_Loss: 0.1110  BEST VAL Loss: 0.1110  Val_Acc: 97.813

Epoch 14: Validation loss decreased (0.110953 --> 0.109403).  Saving model ...
	 Train_Loss: 0.1362 Train_Acc: 97.937 Val_Loss: 0.1094  BEST VAL Loss: 0.1094  Val_Acc: 97.908

Epoch 15: Validation loss decreased (0.109403 --> 0.106034).  Saving model ...
	 Train_Loss: 0.1316 Train_Acc: 98.080 Val_Loss: 0.1060  BEST VAL Loss: 0.1060  Val_Acc: 97.860

Epoch 16: Validation loss decreased (0.106034 --> 0.103056).  Saving model ...
	 Train_Loss: 0.1273 Train_Acc: 98.169 Val_Loss: 0.1031  BEST VAL Loss: 0.1031  Val_Acc: 97.813

Epoch 17: Validation loss decreased (0.103056 --> 0.101295).  Saving model ...
	 Train_Loss: 0.1234 Train_Acc: 98.312 Val_Loss: 0.1013  BEST VAL Loss: 0.1013  Val_Acc: 98.050

Epoch 18: Validation loss decreased (0.101295 --> 0.099847).  Saving model ...
	 Train_Loss: 0.1198 Train_Acc: 98.264 Val_Loss: 0.0998  BEST VAL Loss: 0.0998  Val_Acc: 98.003

Epoch 19: Validation loss decreased (0.099847 --> 0.097673).  Saving model ...
	 Train_Loss: 0.1164 Train_Acc: 98.359 Val_Loss: 0.0977  BEST VAL Loss: 0.0977  Val_Acc: 98.050

Epoch 20: Validation loss decreased (0.097673 --> 0.095387).  Saving model ...
	 Train_Loss: 0.1132 Train_Acc: 98.508 Val_Loss: 0.0954  BEST VAL Loss: 0.0954  Val_Acc: 98.146

Epoch 21: Validation loss decreased (0.095387 --> 0.093046).  Saving model ...
	 Train_Loss: 0.1103 Train_Acc: 98.490 Val_Loss: 0.0930  BEST VAL Loss: 0.0930  Val_Acc: 98.003

Epoch 22: Validation loss decreased (0.093046 --> 0.092064).  Saving model ...
	 Train_Loss: 0.1075 Train_Acc: 98.686 Val_Loss: 0.0921  BEST VAL Loss: 0.0921  Val_Acc: 98.146

Epoch 23: Validation loss decreased (0.092064 --> 0.090159).  Saving model ...
	 Train_Loss: 0.1048 Train_Acc: 98.686 Val_Loss: 0.0902  BEST VAL Loss: 0.0902  Val_Acc: 98.098

Epoch 24: Validation loss decreased (0.090159 --> 0.088133).  Saving model ...
	 Train_Loss: 0.1024 Train_Acc: 98.710 Val_Loss: 0.0881  BEST VAL Loss: 0.0881  Val_Acc: 98.146

Epoch 25: Validation loss decreased (0.088133 --> 0.086292).  Saving model ...
	 Train_Loss: 0.1001 Train_Acc: 98.758 Val_Loss: 0.0863  BEST VAL Loss: 0.0863  Val_Acc: 98.241

Epoch 26: Validation loss decreased (0.086292 --> 0.084813).  Saving model ...
	 Train_Loss: 0.0980 Train_Acc: 98.716 Val_Loss: 0.0848  BEST VAL Loss: 0.0848  Val_Acc: 98.288

Epoch 27: Validation loss decreased (0.084813 --> 0.083865).  Saving model ...
	 Train_Loss: 0.0958 Train_Acc: 98.918 Val_Loss: 0.0839  BEST VAL Loss: 0.0839  Val_Acc: 98.241

Epoch 28: Validation loss decreased (0.083865 --> 0.082575).  Saving model ...
	 Train_Loss: 0.0939 Train_Acc: 98.924 Val_Loss: 0.0826  BEST VAL Loss: 0.0826  Val_Acc: 98.336

Epoch 29: Validation loss decreased (0.082575 --> 0.081549).  Saving model ...
	 Train_Loss: 0.0920 Train_Acc: 98.912 Val_Loss: 0.0815  BEST VAL Loss: 0.0815  Val_Acc: 98.336

Epoch 30: Validation loss decreased (0.081549 --> 0.080161).  Saving model ...
	 Train_Loss: 0.0902 Train_Acc: 99.025 Val_Loss: 0.0802  BEST VAL Loss: 0.0802  Val_Acc: 98.336

Epoch 31: Validation loss decreased (0.080161 --> 0.078936).  Saving model ...
	 Train_Loss: 0.0886 Train_Acc: 98.995 Val_Loss: 0.0789  BEST VAL Loss: 0.0789  Val_Acc: 98.241

Epoch 32: Validation loss decreased (0.078936 --> 0.078062).  Saving model ...
	 Train_Loss: 0.0869 Train_Acc: 98.984 Val_Loss: 0.0781  BEST VAL Loss: 0.0781  Val_Acc: 98.288

Epoch 33: Validation loss decreased (0.078062 --> 0.076912).  Saving model ...
	 Train_Loss: 0.0854 Train_Acc: 99.091 Val_Loss: 0.0769  BEST VAL Loss: 0.0769  Val_Acc: 98.431

Epoch 34: Validation loss decreased (0.076912 --> 0.076123).  Saving model ...
	 Train_Loss: 0.0839 Train_Acc: 99.073 Val_Loss: 0.0761  BEST VAL Loss: 0.0761  Val_Acc: 98.383

Epoch 35: Validation loss decreased (0.076123 --> 0.075004).  Saving model ...
	 Train_Loss: 0.0824 Train_Acc: 99.114 Val_Loss: 0.0750  BEST VAL Loss: 0.0750  Val_Acc: 98.573

Epoch 36: Validation loss decreased (0.075004 --> 0.074261).  Saving model ...
	 Train_Loss: 0.0810 Train_Acc: 99.174 Val_Loss: 0.0743  BEST VAL Loss: 0.0743  Val_Acc: 98.478

Epoch 37: Validation loss decreased (0.074261 --> 0.073559).  Saving model ...
	 Train_Loss: 0.0797 Train_Acc: 99.204 Val_Loss: 0.0736  BEST VAL Loss: 0.0736  Val_Acc: 98.526

Epoch 38: Validation loss decreased (0.073559 --> 0.072649).  Saving model ...
	 Train_Loss: 0.0785 Train_Acc: 99.209 Val_Loss: 0.0726  BEST VAL Loss: 0.0726  Val_Acc: 98.526

Epoch 39: Validation loss decreased (0.072649 --> 0.071866).  Saving model ...
	 Train_Loss: 0.0772 Train_Acc: 99.269 Val_Loss: 0.0719  BEST VAL Loss: 0.0719  Val_Acc: 98.526

Epoch 40: Validation loss decreased (0.071866 --> 0.071609).  Saving model ...
	 Train_Loss: 0.0760 Train_Acc: 99.275 Val_Loss: 0.0716  BEST VAL Loss: 0.0716  Val_Acc: 98.573

Epoch 41: Validation loss decreased (0.071609 --> 0.071143).  Saving model ...
	 Train_Loss: 0.0749 Train_Acc: 99.209 Val_Loss: 0.0711  BEST VAL Loss: 0.0711  Val_Acc: 98.526

Epoch 42: Validation loss decreased (0.071143 --> 0.070324).  Saving model ...
	 Train_Loss: 0.0738 Train_Acc: 99.394 Val_Loss: 0.0703  BEST VAL Loss: 0.0703  Val_Acc: 98.573

Epoch 43: Validation loss decreased (0.070324 --> 0.069552).  Saving model ...
	 Train_Loss: 0.0728 Train_Acc: 99.287 Val_Loss: 0.0696  BEST VAL Loss: 0.0696  Val_Acc: 98.383

Epoch 44: Validation loss decreased (0.069552 --> 0.068859).  Saving model ...
	 Train_Loss: 0.0717 Train_Acc: 99.400 Val_Loss: 0.0689  BEST VAL Loss: 0.0689  Val_Acc: 98.573

Epoch 45: Validation loss decreased (0.068859 --> 0.068379).  Saving model ...
	 Train_Loss: 0.0707 Train_Acc: 99.269 Val_Loss: 0.0684  BEST VAL Loss: 0.0684  Val_Acc: 98.526

Epoch 46: Validation loss decreased (0.068379 --> 0.067869).  Saving model ...
	 Train_Loss: 0.0698 Train_Acc: 99.328 Val_Loss: 0.0679  BEST VAL Loss: 0.0679  Val_Acc: 98.621

Epoch 47: Validation loss decreased (0.067869 --> 0.067447).  Saving model ...
	 Train_Loss: 0.0688 Train_Acc: 99.400 Val_Loss: 0.0674  BEST VAL Loss: 0.0674  Val_Acc: 98.526

Epoch 48: Validation loss decreased (0.067447 --> 0.066827).  Saving model ...
	 Train_Loss: 0.0679 Train_Acc: 99.417 Val_Loss: 0.0668  BEST VAL Loss: 0.0668  Val_Acc: 98.573

Epoch 49: Validation loss decreased (0.066827 --> 0.066632).  Saving model ...
	 Train_Loss: 0.0670 Train_Acc: 99.322 Val_Loss: 0.0666  BEST VAL Loss: 0.0666  Val_Acc: 98.621

Epoch 50: Validation loss decreased (0.066632 --> 0.066132).  Saving model ...
	 Train_Loss: 0.0662 Train_Acc: 99.340 Val_Loss: 0.0661  BEST VAL Loss: 0.0661  Val_Acc: 98.526

Epoch 51: Validation loss decreased (0.066132 --> 0.065580).  Saving model ...
	 Train_Loss: 0.0654 Train_Acc: 99.406 Val_Loss: 0.0656  BEST VAL Loss: 0.0656  Val_Acc: 98.526

Epoch 52: Validation loss decreased (0.065580 --> 0.065191).  Saving model ...
	 Train_Loss: 0.0646 Train_Acc: 99.447 Val_Loss: 0.0652  BEST VAL Loss: 0.0652  Val_Acc: 98.669

Epoch 53: Validation loss decreased (0.065191 --> 0.064658).  Saving model ...
	 Train_Loss: 0.0638 Train_Acc: 99.471 Val_Loss: 0.0647  BEST VAL Loss: 0.0647  Val_Acc: 98.573

Epoch 54: Validation loss decreased (0.064658 --> 0.064121).  Saving model ...
	 Train_Loss: 0.0630 Train_Acc: 99.483 Val_Loss: 0.0641  BEST VAL Loss: 0.0641  Val_Acc: 98.478

Epoch 55: Validation loss decreased (0.064121 --> 0.063897).  Saving model ...
	 Train_Loss: 0.0623 Train_Acc: 99.447 Val_Loss: 0.0639  BEST VAL Loss: 0.0639  Val_Acc: 98.478

Epoch 56: Validation loss decreased (0.063897 --> 0.063538).  Saving model ...
	 Train_Loss: 0.0616 Train_Acc: 99.412 Val_Loss: 0.0635  BEST VAL Loss: 0.0635  Val_Acc: 98.716

Epoch 57: Validation loss decreased (0.063538 --> 0.063054).  Saving model ...
	 Train_Loss: 0.0609 Train_Acc: 99.400 Val_Loss: 0.0631  BEST VAL Loss: 0.0631  Val_Acc: 98.573

Epoch 58: Validation loss decreased (0.063054 --> 0.062537).  Saving model ...
	 Train_Loss: 0.0602 Train_Acc: 99.423 Val_Loss: 0.0625  BEST VAL Loss: 0.0625  Val_Acc: 98.573

Epoch 59: Validation loss decreased (0.062537 --> 0.062104).  Saving model ...
	 Train_Loss: 0.0596 Train_Acc: 99.459 Val_Loss: 0.0621  BEST VAL Loss: 0.0621  Val_Acc: 98.478

Epoch 60: Validation loss decreased (0.062104 --> 0.061635).  Saving model ...
	 Train_Loss: 0.0590 Train_Acc: 99.447 Val_Loss: 0.0616  BEST VAL Loss: 0.0616  Val_Acc: 98.669

Epoch 61: Validation loss decreased (0.061635 --> 0.061160).  Saving model ...
	 Train_Loss: 0.0583 Train_Acc: 99.530 Val_Loss: 0.0612  BEST VAL Loss: 0.0612  Val_Acc: 98.573

Epoch 62: Validation loss decreased (0.061160 --> 0.061014).  Saving model ...
	 Train_Loss: 0.0577 Train_Acc: 99.524 Val_Loss: 0.0610  BEST VAL Loss: 0.0610  Val_Acc: 98.526

Epoch 63: Validation loss decreased (0.061014 --> 0.060997).  Saving model ...
	 Train_Loss: 0.0571 Train_Acc: 99.554 Val_Loss: 0.0610  BEST VAL Loss: 0.0610  Val_Acc: 98.431

Epoch 64: Validation loss decreased (0.060997 --> 0.060571).  Saving model ...
	 Train_Loss: 0.0565 Train_Acc: 99.542 Val_Loss: 0.0606  BEST VAL Loss: 0.0606  Val_Acc: 98.573

Epoch 65: Validation loss decreased (0.060571 --> 0.060143).  Saving model ...
	 Train_Loss: 0.0560 Train_Acc: 99.489 Val_Loss: 0.0601  BEST VAL Loss: 0.0601  Val_Acc: 98.573

Epoch 66: Validation loss decreased (0.060143 --> 0.059777).  Saving model ...
	 Train_Loss: 0.0554 Train_Acc: 99.572 Val_Loss: 0.0598  BEST VAL Loss: 0.0598  Val_Acc: 98.573

Epoch 67: Validation loss decreased (0.059777 --> 0.059704).  Saving model ...
	 Train_Loss: 0.0549 Train_Acc: 99.519 Val_Loss: 0.0597  BEST VAL Loss: 0.0597  Val_Acc: 98.526

Epoch 68: Validation loss decreased (0.059704 --> 0.059294).  Saving model ...
	 Train_Loss: 0.0543 Train_Acc: 99.572 Val_Loss: 0.0593  BEST VAL Loss: 0.0593  Val_Acc: 98.431

Epoch 69: Validation loss decreased (0.059294 --> 0.058984).  Saving model ...
	 Train_Loss: 0.0538 Train_Acc: 99.560 Val_Loss: 0.0590  BEST VAL Loss: 0.0590  Val_Acc: 98.669

Epoch 70: Validation loss decreased (0.058984 --> 0.058663).  Saving model ...
	 Train_Loss: 0.0533 Train_Acc: 99.584 Val_Loss: 0.0587  BEST VAL Loss: 0.0587  Val_Acc: 98.621

Epoch 71: Validation loss decreased (0.058663 --> 0.058307).  Saving model ...
	 Train_Loss: 0.0528 Train_Acc: 99.554 Val_Loss: 0.0583  BEST VAL Loss: 0.0583  Val_Acc: 98.526

Epoch 72: Validation loss decreased (0.058307 --> 0.057958).  Saving model ...
	 Train_Loss: 0.0523 Train_Acc: 99.530 Val_Loss: 0.0580  BEST VAL Loss: 0.0580  Val_Acc: 98.526

Epoch 73: Validation loss decreased (0.057958 --> 0.057819).  Saving model ...
	 Train_Loss: 0.0518 Train_Acc: 99.614 Val_Loss: 0.0578  BEST VAL Loss: 0.0578  Val_Acc: 98.526

Epoch 74: Validation loss decreased (0.057819 --> 0.057603).  Saving model ...
	 Train_Loss: 0.0514 Train_Acc: 99.620 Val_Loss: 0.0576  BEST VAL Loss: 0.0576  Val_Acc: 98.621

Epoch 75: Validation loss decreased (0.057603 --> 0.057406).  Saving model ...
	 Train_Loss: 0.0509 Train_Acc: 99.584 Val_Loss: 0.0574  BEST VAL Loss: 0.0574  Val_Acc: 98.573

Epoch 76: Validation loss decreased (0.057406 --> 0.057181).  Saving model ...
	 Train_Loss: 0.0505 Train_Acc: 99.643 Val_Loss: 0.0572  BEST VAL Loss: 0.0572  Val_Acc: 98.669

Epoch 77: Validation loss decreased (0.057181 --> 0.057121).  Saving model ...
	 Train_Loss: 0.0500 Train_Acc: 99.631 Val_Loss: 0.0571  BEST VAL Loss: 0.0571  Val_Acc: 98.621

Epoch 78: Validation loss decreased (0.057121 --> 0.056888).  Saving model ...
	 Train_Loss: 0.0496 Train_Acc: 99.620 Val_Loss: 0.0569  BEST VAL Loss: 0.0569  Val_Acc: 98.716

Epoch 79: Validation loss decreased (0.056888 --> 0.056614).  Saving model ...
	 Train_Loss: 0.0491 Train_Acc: 99.709 Val_Loss: 0.0566  BEST VAL Loss: 0.0566  Val_Acc: 98.716

Epoch 80: Validation loss decreased (0.056614 --> 0.056358).  Saving model ...
	 Train_Loss: 0.0487 Train_Acc: 99.679 Val_Loss: 0.0564  BEST VAL Loss: 0.0564  Val_Acc: 98.716

Epoch 81: Validation loss decreased (0.056358 --> 0.056304).  Saving model ...
	 Train_Loss: 0.0483 Train_Acc: 99.721 Val_Loss: 0.0563  BEST VAL Loss: 0.0563  Val_Acc: 98.716

Epoch 82: Validation loss decreased (0.056304 --> 0.056270).  Saving model ...
	 Train_Loss: 0.0479 Train_Acc: 99.620 Val_Loss: 0.0563  BEST VAL Loss: 0.0563  Val_Acc: 98.669

Epoch 83: Validation loss decreased (0.056270 --> 0.055997).  Saving model ...
	 Train_Loss: 0.0475 Train_Acc: 99.673 Val_Loss: 0.0560  BEST VAL Loss: 0.0560  Val_Acc: 98.764

Epoch 84: Validation loss decreased (0.055997 --> 0.055850).  Saving model ...
	 Train_Loss: 0.0471 Train_Acc: 99.661 Val_Loss: 0.0558  BEST VAL Loss: 0.0558  Val_Acc: 98.764

Epoch 85: Validation loss decreased (0.055850 --> 0.055732).  Saving model ...
	 Train_Loss: 0.0467 Train_Acc: 99.673 Val_Loss: 0.0557  BEST VAL Loss: 0.0557  Val_Acc: 98.764

Epoch 86: Validation loss decreased (0.055732 --> 0.055504).  Saving model ...
	 Train_Loss: 0.0464 Train_Acc: 99.661 Val_Loss: 0.0555  BEST VAL Loss: 0.0555  Val_Acc: 98.716

Epoch 87: Validation loss decreased (0.055504 --> 0.055333).  Saving model ...
	 Train_Loss: 0.0460 Train_Acc: 99.673 Val_Loss: 0.0553  BEST VAL Loss: 0.0553  Val_Acc: 98.716

Epoch 88: Validation loss decreased (0.055333 --> 0.055151).  Saving model ...
	 Train_Loss: 0.0456 Train_Acc: 99.697 Val_Loss: 0.0552  BEST VAL Loss: 0.0552  Val_Acc: 98.716

Epoch 89: Validation loss decreased (0.055151 --> 0.055146).  Saving model ...
	 Train_Loss: 0.0453 Train_Acc: 99.750 Val_Loss: 0.0551  BEST VAL Loss: 0.0551  Val_Acc: 98.716

Epoch 90: Validation loss decreased (0.055146 --> 0.054980).  Saving model ...
	 Train_Loss: 0.0449 Train_Acc: 99.733 Val_Loss: 0.0550  BEST VAL Loss: 0.0550  Val_Acc: 98.669

Epoch 91: Validation loss decreased (0.054980 --> 0.054918).  Saving model ...
	 Train_Loss: 0.0446 Train_Acc: 99.744 Val_Loss: 0.0549  BEST VAL Loss: 0.0549  Val_Acc: 98.859

Epoch 92: Validation loss decreased (0.054918 --> 0.054699).  Saving model ...
	 Train_Loss: 0.0443 Train_Acc: 99.715 Val_Loss: 0.0547  BEST VAL Loss: 0.0547  Val_Acc: 98.859

Epoch 93: Validation loss decreased (0.054699 --> 0.054489).  Saving model ...
	 Train_Loss: 0.0439 Train_Acc: 99.703 Val_Loss: 0.0545  BEST VAL Loss: 0.0545  Val_Acc: 98.764

Epoch 94: Validation loss decreased (0.054489 --> 0.054419).  Saving model ...
	 Train_Loss: 0.0436 Train_Acc: 99.733 Val_Loss: 0.0544  BEST VAL Loss: 0.0544  Val_Acc: 98.669

Epoch 95: Validation loss decreased (0.054419 --> 0.054272).  Saving model ...
	 Train_Loss: 0.0433 Train_Acc: 99.691 Val_Loss: 0.0543  BEST VAL Loss: 0.0543  Val_Acc: 98.764

Epoch 96: Validation loss decreased (0.054272 --> 0.054261).  Saving model ...
	 Train_Loss: 0.0430 Train_Acc: 99.810 Val_Loss: 0.0543  BEST VAL Loss: 0.0543  Val_Acc: 98.764

Epoch 97: Validation loss decreased (0.054261 --> 0.054143).  Saving model ...
	 Train_Loss: 0.0427 Train_Acc: 99.685 Val_Loss: 0.0541  BEST VAL Loss: 0.0541  Val_Acc: 98.764

Epoch 98: Validation loss decreased (0.054143 --> 0.053949).  Saving model ...
	 Train_Loss: 0.0424 Train_Acc: 99.691 Val_Loss: 0.0539  BEST VAL Loss: 0.0539  Val_Acc: 98.811

Epoch 99: Validation loss decreased (0.053949 --> 0.053739).  Saving model ...
	 Train_Loss: 0.0421 Train_Acc: 99.727 Val_Loss: 0.0537  BEST VAL Loss: 0.0537  Val_Acc: 98.811

Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.51      0.51      8453
           1       0.51      0.50      0.50      8371

    accuracy                           0.51     16824
   macro avg       0.51      0.51      0.51     16824
weighted avg       0.51      0.51      0.51     16824

Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.51      0.51      1057
           1       0.50      0.50      0.50      1046

    accuracy                           0.51      2103
   macro avg       0.51      0.51      0.51      2103
weighted avg       0.51      0.51      0.51      2103

Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.50      0.50      1057
           1       0.49      0.49      0.49      1046

    accuracy                           0.49      2103
   macro avg       0.49      0.49      0.49      2103
weighted avg       0.49      0.49      0.49      2103

              precision    recall  f1-score   support

           0       0.50      0.50      0.50      1057
           1       0.49      0.49      0.49      1046

    accuracy                           0.49      2103
   macro avg       0.49      0.49      0.49      2103
weighted avg       0.49      0.49      0.49      2103

Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.55      0.55      3835
           1       0.47      0.47      0.47      3303

    accuracy                           0.51      7138
   macro avg       0.51      0.51      0.51      7138
weighted avg       0.51      0.51      0.51      7138

              precision    recall  f1-score   support

           0       0.55      0.55      0.55      3835
           1       0.47      0.47      0.47      3303

    accuracy                           0.51      7138
   macro avg       0.51      0.51      0.51      7138
weighted avg       0.51      0.51      0.51      7138

completed
