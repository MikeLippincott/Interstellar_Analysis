[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '4cc819ee'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '60f3b3e5'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1c1172fd'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '7c7e579a'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Thapsigargin_10.000_DMSO_0.025 treatment_name: DMSO_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Thapsigargin_10.000_DMSO_0.025
TREATMENT_NAME: DMSO_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'Thapsigargin_10.000_DMSO_0.025']
The dimensions of the data are: (48855, 1276)
Number of total missing values across all columns: 97710
Data Subset Is Off
Wells held out for testing: ['I14' 'L14']
Wells to use for training, validation, and testing ['B14' 'C14' 'E14' 'B15' 'C15' 'E15' 'J14' 'I15' 'J15' 'L15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.497675).  Saving model ...
	 Train_Loss: 0.5851 Train_Acc: 70.866 Val_Loss: 0.4977  BEST VAL Loss: 0.4977  Val_Acc: 75.737

Epoch 1: Validation loss decreased (0.497675 --> 0.464056).  Saving model ...
	 Train_Loss: 0.5347 Train_Acc: 75.738 Val_Loss: 0.4641  BEST VAL Loss: 0.4641  Val_Acc: 75.787

Epoch 2: Validation loss decreased (0.464056 --> 0.425365).  Saving model ...
	 Train_Loss: 0.4958 Train_Acc: 81.633 Val_Loss: 0.4254  BEST VAL Loss: 0.4254  Val_Acc: 88.201

Epoch 3: Validation loss decreased (0.425365 --> 0.389573).  Saving model ...
	 Train_Loss: 0.4599 Train_Acc: 86.664 Val_Loss: 0.3896  BEST VAL Loss: 0.3896  Val_Acc: 91.175

Epoch 4: Validation loss decreased (0.389573 --> 0.360873).  Saving model ...
	 Train_Loss: 0.4304 Train_Acc: 88.354 Val_Loss: 0.3609  BEST VAL Loss: 0.3609  Val_Acc: 91.888

Epoch 5: Validation loss decreased (0.360873 --> 0.338019).  Saving model ...
	 Train_Loss: 0.4060 Train_Acc: 89.372 Val_Loss: 0.3380  BEST VAL Loss: 0.3380  Val_Acc: 92.355

Epoch 6: Validation loss decreased (0.338019 --> 0.319619).  Saving model ...
	 Train_Loss: 0.3859 Train_Acc: 90.088 Val_Loss: 0.3196  BEST VAL Loss: 0.3196  Val_Acc: 92.748

Epoch 7: Validation loss decreased (0.319619 --> 0.304301).  Saving model ...
	 Train_Loss: 0.3691 Train_Acc: 90.346 Val_Loss: 0.3043  BEST VAL Loss: 0.3043  Val_Acc: 92.994

Epoch 8: Validation loss decreased (0.304301 --> 0.291158).  Saving model ...
	 Train_Loss: 0.3545 Train_Acc: 90.982 Val_Loss: 0.2912  BEST VAL Loss: 0.2912  Val_Acc: 93.240

Epoch 9: Validation loss decreased (0.291158 --> 0.279820).  Saving model ...
	 Train_Loss: 0.3419 Train_Acc: 91.222 Val_Loss: 0.2798  BEST VAL Loss: 0.2798  Val_Acc: 93.387

Epoch 10: Validation loss decreased (0.279820 --> 0.269862).  Saving model ...
	 Train_Loss: 0.3308 Train_Acc: 91.453 Val_Loss: 0.2699  BEST VAL Loss: 0.2699  Val_Acc: 93.781

Epoch 11: Validation loss decreased (0.269862 --> 0.261087).  Saving model ...
	 Train_Loss: 0.3213 Train_Acc: 91.612 Val_Loss: 0.2611  BEST VAL Loss: 0.2611  Val_Acc: 93.928

Epoch 12: Validation loss decreased (0.261087 --> 0.253310).  Saving model ...
	 Train_Loss: 0.3125 Train_Acc: 92.098 Val_Loss: 0.2533  BEST VAL Loss: 0.2533  Val_Acc: 94.076

Epoch 13: Validation loss decreased (0.253310 --> 0.246314).  Saving model ...
	 Train_Loss: 0.3046 Train_Acc: 92.325 Val_Loss: 0.2463  BEST VAL Loss: 0.2463  Val_Acc: 94.272

Epoch 14: Validation loss decreased (0.246314 --> 0.239934).  Saving model ...
	 Train_Loss: 0.2972 Train_Acc: 92.667 Val_Loss: 0.2399  BEST VAL Loss: 0.2399  Val_Acc: 94.494

Epoch 15: Validation loss decreased (0.239934 --> 0.234153).  Saving model ...
	 Train_Loss: 0.2906 Train_Acc: 92.673 Val_Loss: 0.2342  BEST VAL Loss: 0.2342  Val_Acc: 94.444

Epoch 16: Validation loss decreased (0.234153 --> 0.228860).  Saving model ...
	 Train_Loss: 0.2843 Train_Acc: 92.952 Val_Loss: 0.2289  BEST VAL Loss: 0.2289  Val_Acc: 94.543

Epoch 17: Validation loss decreased (0.228860 --> 0.224023).  Saving model ...
	 Train_Loss: 0.2787 Train_Acc: 92.919 Val_Loss: 0.2240  BEST VAL Loss: 0.2240  Val_Acc: 94.567

Epoch 18: Validation loss decreased (0.224023 --> 0.219538).  Saving model ...
	 Train_Loss: 0.2735 Train_Acc: 93.020 Val_Loss: 0.2195  BEST VAL Loss: 0.2195  Val_Acc: 94.592

Epoch 19: Validation loss decreased (0.219538 --> 0.215373).  Saving model ...
	 Train_Loss: 0.2684 Train_Acc: 93.361 Val_Loss: 0.2154  BEST VAL Loss: 0.2154  Val_Acc: 94.567

Epoch 20: Validation loss decreased (0.215373 --> 0.211528).  Saving model ...
	 Train_Loss: 0.2638 Train_Acc: 93.441 Val_Loss: 0.2115  BEST VAL Loss: 0.2115  Val_Acc: 94.764

Epoch 21: Validation loss decreased (0.211528 --> 0.207975).  Saving model ...
	 Train_Loss: 0.2594 Train_Acc: 93.509 Val_Loss: 0.2080  BEST VAL Loss: 0.2080  Val_Acc: 94.936

Epoch 22: Validation loss decreased (0.207975 --> 0.204632).  Saving model ...
	 Train_Loss: 0.2553 Train_Acc: 93.767 Val_Loss: 0.2046  BEST VAL Loss: 0.2046  Val_Acc: 94.715

Epoch 23: Validation loss decreased (0.204632 --> 0.201501).  Saving model ...
	 Train_Loss: 0.2514 Train_Acc: 93.770 Val_Loss: 0.2015  BEST VAL Loss: 0.2015  Val_Acc: 94.715

Epoch 24: Validation loss decreased (0.201501 --> 0.198549).  Saving model ...
	 Train_Loss: 0.2478 Train_Acc: 93.798 Val_Loss: 0.1985  BEST VAL Loss: 0.1985  Val_Acc: 94.739

Epoch 25: Validation loss decreased (0.198549 --> 0.195793).  Saving model ...
	 Train_Loss: 0.2444 Train_Acc: 93.807 Val_Loss: 0.1958  BEST VAL Loss: 0.1958  Val_Acc: 94.838

Epoch 26: Validation loss decreased (0.195793 --> 0.193227).  Saving model ...
	 Train_Loss: 0.2412 Train_Acc: 93.881 Val_Loss: 0.1932  BEST VAL Loss: 0.1932  Val_Acc: 94.887

Epoch 27: Validation loss decreased (0.193227 --> 0.190797).  Saving model ...
	 Train_Loss: 0.2381 Train_Acc: 93.930 Val_Loss: 0.1908  BEST VAL Loss: 0.1908  Val_Acc: 95.059

Epoch 28: Validation loss decreased (0.190797 --> 0.188496).  Saving model ...
	 Train_Loss: 0.2351 Train_Acc: 94.157 Val_Loss: 0.1885  BEST VAL Loss: 0.1885  Val_Acc: 95.059

Epoch 29: Validation loss decreased (0.188496 --> 0.186311).  Saving model ...
	 Train_Loss: 0.2322 Train_Acc: 94.292 Val_Loss: 0.1863  BEST VAL Loss: 0.1863  Val_Acc: 95.231

Epoch 30: Validation loss decreased (0.186311 --> 0.184230).  Saving model ...
	 Train_Loss: 0.2295 Train_Acc: 94.219 Val_Loss: 0.1842  BEST VAL Loss: 0.1842  Val_Acc: 95.280

Epoch 31: Validation loss decreased (0.184230 --> 0.182230).  Saving model ...
	 Train_Loss: 0.2269 Train_Acc: 94.351 Val_Loss: 0.1822  BEST VAL Loss: 0.1822  Val_Acc: 95.305

Epoch 32: Validation loss decreased (0.182230 --> 0.180386).  Saving model ...
	 Train_Loss: 0.2243 Train_Acc: 94.514 Val_Loss: 0.1804  BEST VAL Loss: 0.1804  Val_Acc: 95.354

Epoch 33: Validation loss decreased (0.180386 --> 0.178595).  Saving model ...
	 Train_Loss: 0.2219 Train_Acc: 94.631 Val_Loss: 0.1786  BEST VAL Loss: 0.1786  Val_Acc: 95.354

Epoch 34: Validation loss decreased (0.178595 --> 0.176895).  Saving model ...
	 Train_Loss: 0.2196 Train_Acc: 94.538 Val_Loss: 0.1769  BEST VAL Loss: 0.1769  Val_Acc: 95.305

Epoch 35: Validation loss decreased (0.176895 --> 0.175242).  Saving model ...
	 Train_Loss: 0.2173 Train_Acc: 94.606 Val_Loss: 0.1752  BEST VAL Loss: 0.1752  Val_Acc: 95.428

Epoch 36: Validation loss decreased (0.175242 --> 0.173680).  Saving model ...
	 Train_Loss: 0.2151 Train_Acc: 94.815 Val_Loss: 0.1737  BEST VAL Loss: 0.1737  Val_Acc: 95.403

Epoch 37: Validation loss decreased (0.173680 --> 0.172180).  Saving model ...
	 Train_Loss: 0.2131 Train_Acc: 94.603 Val_Loss: 0.1722  BEST VAL Loss: 0.1722  Val_Acc: 95.354

Epoch 38: Validation loss decreased (0.172180 --> 0.170750).  Saving model ...
	 Train_Loss: 0.2111 Train_Acc: 94.588 Val_Loss: 0.1708  BEST VAL Loss: 0.1708  Val_Acc: 95.379

Epoch 39: Validation loss decreased (0.170750 --> 0.169364).  Saving model ...
	 Train_Loss: 0.2092 Train_Acc: 94.649 Val_Loss: 0.1694  BEST VAL Loss: 0.1694  Val_Acc: 95.379

Epoch 40: Validation loss decreased (0.169364 --> 0.168075).  Saving model ...
	 Train_Loss: 0.2074 Train_Acc: 94.738 Val_Loss: 0.1681  BEST VAL Loss: 0.1681  Val_Acc: 95.157

Epoch 41: Validation loss decreased (0.168075 --> 0.166807).  Saving model ...
	 Train_Loss: 0.2057 Train_Acc: 94.793 Val_Loss: 0.1668  BEST VAL Loss: 0.1668  Val_Acc: 95.256

Epoch 42: Validation loss decreased (0.166807 --> 0.165582).  Saving model ...
	 Train_Loss: 0.2039 Train_Acc: 94.790 Val_Loss: 0.1656  BEST VAL Loss: 0.1656  Val_Acc: 95.280

Epoch 43: Validation loss decreased (0.165582 --> 0.164407).  Saving model ...
	 Train_Loss: 0.2023 Train_Acc: 94.735 Val_Loss: 0.1644  BEST VAL Loss: 0.1644  Val_Acc: 95.477

Epoch 44: Validation loss decreased (0.164407 --> 0.163314).  Saving model ...
	 Train_Loss: 0.2007 Train_Acc: 94.926 Val_Loss: 0.1633  BEST VAL Loss: 0.1633  Val_Acc: 95.428

Epoch 45: Validation loss decreased (0.163314 --> 0.162227).  Saving model ...
	 Train_Loss: 0.1991 Train_Acc: 94.966 Val_Loss: 0.1622  BEST VAL Loss: 0.1622  Val_Acc: 95.329

Epoch 46: Validation loss decreased (0.162227 --> 0.161184).  Saving model ...
	 Train_Loss: 0.1976 Train_Acc: 94.963 Val_Loss: 0.1612  BEST VAL Loss: 0.1612  Val_Acc: 95.428

Epoch 47: Validation loss decreased (0.161184 --> 0.160159).  Saving model ...
	 Train_Loss: 0.1961 Train_Acc: 95.107 Val_Loss: 0.1602  BEST VAL Loss: 0.1602  Val_Acc: 95.452

Epoch 48: Validation loss decreased (0.160159 --> 0.159167).  Saving model ...
	 Train_Loss: 0.1947 Train_Acc: 94.947 Val_Loss: 0.1592  BEST VAL Loss: 0.1592  Val_Acc: 95.428

Epoch 49: Validation loss decreased (0.159167 --> 0.158211).  Saving model ...
	 Train_Loss: 0.1933 Train_Acc: 95.049 Val_Loss: 0.1582  BEST VAL Loss: 0.1582  Val_Acc: 95.501

Epoch 50: Validation loss decreased (0.158211 --> 0.157282).  Saving model ...
	 Train_Loss: 0.1919 Train_Acc: 95.030 Val_Loss: 0.1573  BEST VAL Loss: 0.1573  Val_Acc: 95.600

Epoch 51: Validation loss decreased (0.157282 --> 0.156416).  Saving model ...
	 Train_Loss: 0.1906 Train_Acc: 95.064 Val_Loss: 0.1564  BEST VAL Loss: 0.1564  Val_Acc: 95.526

Epoch 52: Validation loss decreased (0.156416 --> 0.155569).  Saving model ...
	 Train_Loss: 0.1893 Train_Acc: 95.101 Val_Loss: 0.1556  BEST VAL Loss: 0.1556  Val_Acc: 95.501

Epoch 53: Validation loss decreased (0.155569 --> 0.154762).  Saving model ...
	 Train_Loss: 0.1880 Train_Acc: 95.076 Val_Loss: 0.1548  BEST VAL Loss: 0.1548  Val_Acc: 95.403

Epoch 54: Validation loss decreased (0.154762 --> 0.153936).  Saving model ...
	 Train_Loss: 0.1868 Train_Acc: 95.291 Val_Loss: 0.1539  BEST VAL Loss: 0.1539  Val_Acc: 95.526

Epoch 55: Validation loss decreased (0.153936 --> 0.153155).  Saving model ...
	 Train_Loss: 0.1856 Train_Acc: 95.218 Val_Loss: 0.1532  BEST VAL Loss: 0.1532  Val_Acc: 95.624

Epoch 56: Validation loss decreased (0.153155 --> 0.152385).  Saving model ...
	 Train_Loss: 0.1844 Train_Acc: 95.291 Val_Loss: 0.1524  BEST VAL Loss: 0.1524  Val_Acc: 95.551

Epoch 57: Validation loss decreased (0.152385 --> 0.151644).  Saving model ...
	 Train_Loss: 0.1832 Train_Acc: 95.279 Val_Loss: 0.1516  BEST VAL Loss: 0.1516  Val_Acc: 95.477

Epoch 58: Validation loss decreased (0.151644 --> 0.150923).  Saving model ...
	 Train_Loss: 0.1821 Train_Acc: 95.353 Val_Loss: 0.1509  BEST VAL Loss: 0.1509  Val_Acc: 95.526

Epoch 59: Validation loss decreased (0.150923 --> 0.150232).  Saving model ...
	 Train_Loss: 0.1809 Train_Acc: 95.405 Val_Loss: 0.1502  BEST VAL Loss: 0.1502  Val_Acc: 95.526

Epoch 60: Validation loss decreased (0.150232 --> 0.149553).  Saving model ...
	 Train_Loss: 0.1798 Train_Acc: 95.494 Val_Loss: 0.1496  BEST VAL Loss: 0.1496  Val_Acc: 95.452

Epoch 61: Validation loss decreased (0.149553 --> 0.148893).  Saving model ...
	 Train_Loss: 0.1788 Train_Acc: 95.165 Val_Loss: 0.1489  BEST VAL Loss: 0.1489  Val_Acc: 95.624

Epoch 62: Validation loss decreased (0.148893 --> 0.148266).  Saving model ...
	 Train_Loss: 0.1778 Train_Acc: 95.420 Val_Loss: 0.1483  BEST VAL Loss: 0.1483  Val_Acc: 95.698

Epoch 63: Validation loss decreased (0.148266 --> 0.147660).  Saving model ...
	 Train_Loss: 0.1768 Train_Acc: 95.430 Val_Loss: 0.1477  BEST VAL Loss: 0.1477  Val_Acc: 95.403

Epoch 64: Validation loss decreased (0.147660 --> 0.147054).  Saving model ...
	 Train_Loss: 0.1758 Train_Acc: 95.470 Val_Loss: 0.1471  BEST VAL Loss: 0.1471  Val_Acc: 95.698

Epoch 65: Validation loss decreased (0.147054 --> 0.146454).  Saving model ...
	 Train_Loss: 0.1748 Train_Acc: 95.433 Val_Loss: 0.1465  BEST VAL Loss: 0.1465  Val_Acc: 95.501

Epoch 66: Validation loss decreased (0.146454 --> 0.145901).  Saving model ...
	 Train_Loss: 0.1739 Train_Acc: 95.273 Val_Loss: 0.1459  BEST VAL Loss: 0.1459  Val_Acc: 95.649

Epoch 67: Validation loss decreased (0.145901 --> 0.145339).  Saving model ...
	 Train_Loss: 0.1730 Train_Acc: 95.341 Val_Loss: 0.1453  BEST VAL Loss: 0.1453  Val_Acc: 95.526

Epoch 68: Validation loss decreased (0.145339 --> 0.144815).  Saving model ...
	 Train_Loss: 0.1721 Train_Acc: 95.460 Val_Loss: 0.1448  BEST VAL Loss: 0.1448  Val_Acc: 95.452

Epoch 69: Validation loss decreased (0.144815 --> 0.144282).  Saving model ...
	 Train_Loss: 0.1711 Train_Acc: 95.574 Val_Loss: 0.1443  BEST VAL Loss: 0.1443  Val_Acc: 95.600

Epoch 70: Validation loss decreased (0.144282 --> 0.143792).  Saving model ...
	 Train_Loss: 0.1703 Train_Acc: 95.528 Val_Loss: 0.1438  BEST VAL Loss: 0.1438  Val_Acc: 95.698

Epoch 71: Validation loss decreased (0.143792 --> 0.143270).  Saving model ...
	 Train_Loss: 0.1694 Train_Acc: 95.642 Val_Loss: 0.1433  BEST VAL Loss: 0.1433  Val_Acc: 95.723

Epoch 72: Validation loss decreased (0.143270 --> 0.142782).  Saving model ...
	 Train_Loss: 0.1686 Train_Acc: 95.556 Val_Loss: 0.1428  BEST VAL Loss: 0.1428  Val_Acc: 95.624

Epoch 73: Validation loss decreased (0.142782 --> 0.142314).  Saving model ...
	 Train_Loss: 0.1677 Train_Acc: 95.737 Val_Loss: 0.1423  BEST VAL Loss: 0.1423  Val_Acc: 95.698

Epoch 74: Validation loss decreased (0.142314 --> 0.141854).  Saving model ...
	 Train_Loss: 0.1669 Train_Acc: 95.531 Val_Loss: 0.1419  BEST VAL Loss: 0.1419  Val_Acc: 95.747

Epoch 75: Validation loss decreased (0.141854 --> 0.141416).  Saving model ...
	 Train_Loss: 0.1661 Train_Acc: 95.728 Val_Loss: 0.1414  BEST VAL Loss: 0.1414  Val_Acc: 95.600

Epoch 76: Validation loss decreased (0.141416 --> 0.140978).  Saving model ...
	 Train_Loss: 0.1653 Train_Acc: 95.688 Val_Loss: 0.1410  BEST VAL Loss: 0.1410  Val_Acc: 95.649

Epoch 77: Validation loss decreased (0.140978 --> 0.140561).  Saving model ...
	 Train_Loss: 0.1645 Train_Acc: 95.703 Val_Loss: 0.1406  BEST VAL Loss: 0.1406  Val_Acc: 95.674

Epoch 78: Validation loss decreased (0.140561 --> 0.140171).  Saving model ...
	 Train_Loss: 0.1638 Train_Acc: 95.805 Val_Loss: 0.1402  BEST VAL Loss: 0.1402  Val_Acc: 95.674

Epoch 79: Validation loss decreased (0.140171 --> 0.139773).  Saving model ...
	 Train_Loss: 0.1630 Train_Acc: 95.709 Val_Loss: 0.1398  BEST VAL Loss: 0.1398  Val_Acc: 95.649

Epoch 80: Validation loss decreased (0.139773 --> 0.139372).  Saving model ...
	 Train_Loss: 0.1623 Train_Acc: 95.676 Val_Loss: 0.1394  BEST VAL Loss: 0.1394  Val_Acc: 95.575

Epoch 81: Validation loss decreased (0.139372 --> 0.138965).  Saving model ...
	 Train_Loss: 0.1616 Train_Acc: 95.765 Val_Loss: 0.1390  BEST VAL Loss: 0.1390  Val_Acc: 95.624

Epoch 82: Validation loss decreased (0.138965 --> 0.138575).  Saving model ...
	 Train_Loss: 0.1609 Train_Acc: 95.519 Val_Loss: 0.1386  BEST VAL Loss: 0.1386  Val_Acc: 95.551

Epoch 83: Validation loss decreased (0.138575 --> 0.138200).  Saving model ...
	 Train_Loss: 0.1602 Train_Acc: 95.611 Val_Loss: 0.1382  BEST VAL Loss: 0.1382  Val_Acc: 95.600

Epoch 84: Validation loss decreased (0.138200 --> 0.137830).  Saving model ...
	 Train_Loss: 0.1596 Train_Acc: 95.703 Val_Loss: 0.1378  BEST VAL Loss: 0.1378  Val_Acc: 95.526

Epoch 85: Validation loss decreased (0.137830 --> 0.137470).  Saving model ...
	 Train_Loss: 0.1589 Train_Acc: 95.832 Val_Loss: 0.1375  BEST VAL Loss: 0.1375  Val_Acc: 95.551

Epoch 86: Validation loss decreased (0.137470 --> 0.137119).  Saving model ...
	 Train_Loss: 0.1582 Train_Acc: 95.755 Val_Loss: 0.1371  BEST VAL Loss: 0.1371  Val_Acc: 95.575

Epoch 87: Validation loss decreased (0.137119 --> 0.136789).  Saving model ...
	 Train_Loss: 0.1576 Train_Acc: 95.817 Val_Loss: 0.1368  BEST VAL Loss: 0.1368  Val_Acc: 95.674

Epoch 88: Validation loss decreased (0.136789 --> 0.136454).  Saving model ...
	 Train_Loss: 0.1570 Train_Acc: 95.712 Val_Loss: 0.1365  BEST VAL Loss: 0.1365  Val_Acc: 95.551

Epoch 89: Validation loss decreased (0.136454 --> 0.136138).  Saving model ...
	 Train_Loss: 0.1563 Train_Acc: 95.586 Val_Loss: 0.1361  BEST VAL Loss: 0.1361  Val_Acc: 95.674

Epoch 90: Validation loss decreased (0.136138 --> 0.135819).  Saving model ...
	 Train_Loss: 0.1557 Train_Acc: 95.722 Val_Loss: 0.1358  BEST VAL Loss: 0.1358  Val_Acc: 95.600

Epoch 91: Validation loss decreased (0.135819 --> 0.135507).  Saving model ...
	 Train_Loss: 0.1551 Train_Acc: 95.789 Val_Loss: 0.1355  BEST VAL Loss: 0.1355  Val_Acc: 95.526

Epoch 92: Validation loss decreased (0.135507 --> 0.135202).  Saving model ...
	 Train_Loss: 0.1545 Train_Acc: 95.854 Val_Loss: 0.1352  BEST VAL Loss: 0.1352  Val_Acc: 95.674

Epoch 93: Validation loss decreased (0.135202 --> 0.134910).  Saving model ...
	 Train_Loss: 0.1539 Train_Acc: 95.811 Val_Loss: 0.1349  BEST VAL Loss: 0.1349  Val_Acc: 95.624

Epoch 94: Validation loss decreased (0.134910 --> 0.134602).  Saving model ...
	 Train_Loss: 0.1533 Train_Acc: 95.768 Val_Loss: 0.1346  BEST VAL Loss: 0.1346  Val_Acc: 95.624

Epoch 95: Validation loss decreased (0.134602 --> 0.134324).  Saving model ...
	 Train_Loss: 0.1527 Train_Acc: 96.057 Val_Loss: 0.1343  BEST VAL Loss: 0.1343  Val_Acc: 95.772

Epoch 96: Validation loss decreased (0.134324 --> 0.134038).  Saving model ...
	 Train_Loss: 0.1522 Train_Acc: 95.897 Val_Loss: 0.1340  BEST VAL Loss: 0.1340  Val_Acc: 95.649

Epoch 97: Validation loss decreased (0.134038 --> 0.133756).  Saving model ...
	 Train_Loss: 0.1516 Train_Acc: 95.786 Val_Loss: 0.1338  BEST VAL Loss: 0.1338  Val_Acc: 95.624

Epoch 98: Validation loss decreased (0.133756 --> 0.133489).  Saving model ...
	 Train_Loss: 0.1511 Train_Acc: 95.740 Val_Loss: 0.1335  BEST VAL Loss: 0.1335  Val_Acc: 95.600

Epoch 99: Validation loss decreased (0.133489 --> 0.133218).  Saving model ...
	 Train_Loss: 0.1506 Train_Acc: 95.789 Val_Loss: 0.1332  BEST VAL Loss: 0.1332  Val_Acc: 95.501

Thapsigargin_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.99      0.99     24644
           1       0.98      0.95      0.96      7892

    accuracy                           0.98     32536
   macro avg       0.98      0.97      0.98     32536
weighted avg       0.98      0.98      0.98     32536

Thapsigargin_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.96      0.98      0.97      3081
           1       0.93      0.88      0.91       987

    accuracy                           0.96      4068
   macro avg       0.95      0.93      0.94      4068
weighted avg       0.95      0.96      0.95      4068

Thapsigargin_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.98      0.98      3081
           1       0.93      0.91      0.92       987

    accuracy                           0.96      4068
   macro avg       0.95      0.94      0.95      4068
weighted avg       0.96      0.96      0.96      4068

              precision    recall  f1-score   support

           0       0.97      0.98      0.98      3081
           1       0.93      0.91      0.92       987

    accuracy                           0.96      4068
   macro avg       0.95      0.94      0.95      4068
weighted avg       0.96      0.96      0.96      4068

Thapsigargin_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.94      0.99      0.96      4837
           1       0.98      0.90      0.94      3346

    accuracy                           0.95      8183
   macro avg       0.96      0.95      0.95      8183
weighted avg       0.95      0.95      0.95      8183

              precision    recall  f1-score   support

           0       0.94      0.99      0.96      4837
           1       0.98      0.90      0.94      3346

    accuracy                           0.95      8183
   macro avg       0.96      0.95      0.95      8183
weighted avg       0.95      0.95      0.95      8183

completed
