[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '9dee8013'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '5ed45967'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'cecff159'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '7c73927a'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_1.000_DMSO_0.025 treatment_name: LPS_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (32267, 1276)
Number of total missing values across all columns: 64534
Data Subset Is Off
Wells held out for testing: ['D21' 'M22']
Wells to use for training, validation, and testing ['D16' 'D17' 'D20' 'M18' 'M19' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.669622).  Saving model ...
	 Train_Loss: 0.6891 Train_Acc: 55.398 Val_Loss: 0.6696  BEST VAL Loss: 0.6696  Val_Acc: 60.296

Epoch 1: Validation loss decreased (0.669622 --> 0.661834).  Saving model ...
	 Train_Loss: 0.6783 Train_Acc: 59.123 Val_Loss: 0.6618  BEST VAL Loss: 0.6618  Val_Acc: 62.762

Epoch 2: Validation loss decreased (0.661834 --> 0.655768).  Saving model ...
	 Train_Loss: 0.6709 Train_Acc: 61.081 Val_Loss: 0.6558  BEST VAL Loss: 0.6558  Val_Acc: 64.201

Epoch 3: Validation loss decreased (0.655768 --> 0.651230).  Saving model ...
	 Train_Loss: 0.6648 Train_Acc: 62.104 Val_Loss: 0.6512  BEST VAL Loss: 0.6512  Val_Acc: 65.557

Epoch 4: Validation loss decreased (0.651230 --> 0.646311).  Saving model ...
	 Train_Loss: 0.6600 Train_Acc: 63.275 Val_Loss: 0.6463  BEST VAL Loss: 0.6463  Val_Acc: 66.379

Epoch 5: Validation loss decreased (0.646311 --> 0.642726).  Saving model ...
	 Train_Loss: 0.6550 Train_Acc: 64.539 Val_Loss: 0.6427  BEST VAL Loss: 0.6427  Val_Acc: 66.626

Epoch 6: Validation loss decreased (0.642726 --> 0.638000).  Saving model ...
	 Train_Loss: 0.6507 Train_Acc: 65.207 Val_Loss: 0.6380  BEST VAL Loss: 0.6380  Val_Acc: 68.434

Epoch 7: Validation loss decreased (0.638000 --> 0.634202).  Saving model ...
	 Train_Loss: 0.6464 Train_Acc: 66.019 Val_Loss: 0.6342  BEST VAL Loss: 0.6342  Val_Acc: 68.393

Epoch 8: Validation loss decreased (0.634202 --> 0.630373).  Saving model ...
	 Train_Loss: 0.6424 Train_Acc: 66.430 Val_Loss: 0.6304  BEST VAL Loss: 0.6304  Val_Acc: 68.557

Epoch 9: Validation loss decreased (0.630373 --> 0.626944).  Saving model ...
	 Train_Loss: 0.6381 Train_Acc: 67.792 Val_Loss: 0.6269  BEST VAL Loss: 0.6269  Val_Acc: 69.914

Epoch 10: Validation loss decreased (0.626944 --> 0.623512).  Saving model ...
	 Train_Loss: 0.6344 Train_Acc: 68.049 Val_Loss: 0.6235  BEST VAL Loss: 0.6235  Val_Acc: 70.325

Epoch 11: Validation loss decreased (0.623512 --> 0.620232).  Saving model ...
	 Train_Loss: 0.6306 Train_Acc: 68.588 Val_Loss: 0.6202  BEST VAL Loss: 0.6202  Val_Acc: 70.612

Epoch 12: Validation loss decreased (0.620232 --> 0.617354).  Saving model ...
	 Train_Loss: 0.6276 Train_Acc: 68.455 Val_Loss: 0.6174  BEST VAL Loss: 0.6174  Val_Acc: 70.407

Epoch 13: Validation loss decreased (0.617354 --> 0.614684).  Saving model ...
	 Train_Loss: 0.6245 Train_Acc: 68.907 Val_Loss: 0.6147  BEST VAL Loss: 0.6147  Val_Acc: 70.037

Epoch 14: Validation loss decreased (0.614684 --> 0.612287).  Saving model ...
	 Train_Loss: 0.6217 Train_Acc: 69.534 Val_Loss: 0.6123  BEST VAL Loss: 0.6123  Val_Acc: 70.366

Epoch 15: Validation loss decreased (0.612287 --> 0.610096).  Saving model ...
	 Train_Loss: 0.6190 Train_Acc: 69.626 Val_Loss: 0.6101  BEST VAL Loss: 0.6101  Val_Acc: 70.818

Epoch 16: Validation loss decreased (0.610096 --> 0.607694).  Saving model ...
	 Train_Loss: 0.6165 Train_Acc: 70.104 Val_Loss: 0.6077  BEST VAL Loss: 0.6077  Val_Acc: 70.982

Epoch 17: Validation loss decreased (0.607694 --> 0.605849).  Saving model ...
	 Train_Loss: 0.6141 Train_Acc: 70.156 Val_Loss: 0.6058  BEST VAL Loss: 0.6058  Val_Acc: 71.352

Epoch 18: Validation loss decreased (0.605849 --> 0.603955).  Saving model ...
	 Train_Loss: 0.6120 Train_Acc: 69.919 Val_Loss: 0.6040  BEST VAL Loss: 0.6040  Val_Acc: 72.051

Epoch 19: Validation loss decreased (0.603955 --> 0.602424).  Saving model ...
	 Train_Loss: 0.6099 Train_Acc: 70.464 Val_Loss: 0.6024  BEST VAL Loss: 0.6024  Val_Acc: 72.092

Epoch 20: Validation loss decreased (0.602424 --> 0.600915).  Saving model ...
	 Train_Loss: 0.6081 Train_Acc: 70.115 Val_Loss: 0.6009  BEST VAL Loss: 0.6009  Val_Acc: 72.215

Epoch 21: Validation loss decreased (0.600915 --> 0.599565).  Saving model ...
	 Train_Loss: 0.6063 Train_Acc: 70.793 Val_Loss: 0.5996  BEST VAL Loss: 0.5996  Val_Acc: 71.804

Epoch 22: Validation loss decreased (0.599565 --> 0.598081).  Saving model ...
	 Train_Loss: 0.6044 Train_Acc: 70.906 Val_Loss: 0.5981  BEST VAL Loss: 0.5981  Val_Acc: 73.079

Epoch 23: Validation loss decreased (0.598081 --> 0.596675).  Saving model ...
	 Train_Loss: 0.6027 Train_Acc: 70.798 Val_Loss: 0.5967  BEST VAL Loss: 0.5967  Val_Acc: 72.010

Epoch 24: Validation loss decreased (0.596675 --> 0.595257).  Saving model ...
	 Train_Loss: 0.6009 Train_Acc: 71.276 Val_Loss: 0.5953  BEST VAL Loss: 0.5953  Val_Acc: 73.161

Epoch 25: Validation loss decreased (0.595257 --> 0.594098).  Saving model ...
	 Train_Loss: 0.5992 Train_Acc: 71.682 Val_Loss: 0.5941  BEST VAL Loss: 0.5941  Val_Acc: 73.079

Epoch 26: Validation loss decreased (0.594098 --> 0.592918).  Saving model ...
	 Train_Loss: 0.5977 Train_Acc: 71.481 Val_Loss: 0.5929  BEST VAL Loss: 0.5929  Val_Acc: 72.709

Epoch 27: Validation loss decreased (0.592918 --> 0.591812).  Saving model ...
	 Train_Loss: 0.5961 Train_Acc: 72.088 Val_Loss: 0.5918  BEST VAL Loss: 0.5918  Val_Acc: 73.037

Epoch 28: Validation loss decreased (0.591812 --> 0.590755).  Saving model ...
	 Train_Loss: 0.5946 Train_Acc: 71.718 Val_Loss: 0.5908  BEST VAL Loss: 0.5908  Val_Acc: 72.585

Epoch 29: Validation loss decreased (0.590755 --> 0.589791).  Saving model ...
	 Train_Loss: 0.5931 Train_Acc: 72.180 Val_Loss: 0.5898  BEST VAL Loss: 0.5898  Val_Acc: 72.832

Epoch 30: Validation loss decreased (0.589791 --> 0.588947).  Saving model ...
	 Train_Loss: 0.5919 Train_Acc: 72.036 Val_Loss: 0.5889  BEST VAL Loss: 0.5889  Val_Acc: 73.202

Epoch 31: Validation loss decreased (0.588947 --> 0.587955).  Saving model ...
	 Train_Loss: 0.5905 Train_Acc: 72.304 Val_Loss: 0.5880  BEST VAL Loss: 0.5880  Val_Acc: 73.366

Epoch 32: Validation loss decreased (0.587955 --> 0.587163).  Saving model ...
	 Train_Loss: 0.5894 Train_Acc: 71.754 Val_Loss: 0.5872  BEST VAL Loss: 0.5872  Val_Acc: 73.366

Epoch 33: Validation loss decreased (0.587163 --> 0.586395).  Saving model ...
	 Train_Loss: 0.5883 Train_Acc: 72.129 Val_Loss: 0.5864  BEST VAL Loss: 0.5864  Val_Acc: 73.490

Epoch 34: Validation loss decreased (0.586395 --> 0.585532).  Saving model ...
	 Train_Loss: 0.5872 Train_Acc: 71.949 Val_Loss: 0.5855  BEST VAL Loss: 0.5855  Val_Acc: 73.407

Epoch 35: Validation loss decreased (0.585532 --> 0.584653).  Saving model ...
	 Train_Loss: 0.5861 Train_Acc: 72.088 Val_Loss: 0.5847  BEST VAL Loss: 0.5847  Val_Acc: 73.942

Epoch 36: Validation loss decreased (0.584653 --> 0.583940).  Saving model ...
	 Train_Loss: 0.5850 Train_Acc: 72.586 Val_Loss: 0.5839  BEST VAL Loss: 0.5839  Val_Acc: 73.531

Epoch 37: Validation loss decreased (0.583940 --> 0.583372).  Saving model ...
	 Train_Loss: 0.5840 Train_Acc: 72.473 Val_Loss: 0.5834  BEST VAL Loss: 0.5834  Val_Acc: 73.613

Epoch 38: Validation loss decreased (0.583372 --> 0.582688).  Saving model ...
	 Train_Loss: 0.5829 Train_Acc: 72.632 Val_Loss: 0.5827  BEST VAL Loss: 0.5827  Val_Acc: 73.983

Epoch 39: Validation loss decreased (0.582688 --> 0.581937).  Saving model ...
	 Train_Loss: 0.5820 Train_Acc: 72.622 Val_Loss: 0.5819  BEST VAL Loss: 0.5819  Val_Acc: 74.147

Epoch 40: Validation loss decreased (0.581937 --> 0.581379).  Saving model ...
	 Train_Loss: 0.5811 Train_Acc: 72.355 Val_Loss: 0.5814  BEST VAL Loss: 0.5814  Val_Acc: 73.654

Epoch 41: Validation loss decreased (0.581379 --> 0.580873).  Saving model ...
	 Train_Loss: 0.5802 Train_Acc: 72.812 Val_Loss: 0.5809  BEST VAL Loss: 0.5809  Val_Acc: 73.243

Epoch 42: Validation loss decreased (0.580873 --> 0.580333).  Saving model ...
	 Train_Loss: 0.5793 Train_Acc: 72.751 Val_Loss: 0.5803  BEST VAL Loss: 0.5803  Val_Acc: 73.572

Epoch 43: Validation loss decreased (0.580333 --> 0.579836).  Saving model ...
	 Train_Loss: 0.5784 Train_Acc: 72.787 Val_Loss: 0.5798  BEST VAL Loss: 0.5798  Val_Acc: 74.312

Epoch 44: Validation loss decreased (0.579836 --> 0.579469).  Saving model ...
	 Train_Loss: 0.5776 Train_Acc: 72.725 Val_Loss: 0.5795  BEST VAL Loss: 0.5795  Val_Acc: 73.572

Epoch 45: Validation loss decreased (0.579469 --> 0.578975).  Saving model ...
	 Train_Loss: 0.5768 Train_Acc: 72.843 Val_Loss: 0.5790  BEST VAL Loss: 0.5790  Val_Acc: 74.229

Epoch 46: Validation loss decreased (0.578975 --> 0.578435).  Saving model ...
	 Train_Loss: 0.5760 Train_Acc: 73.033 Val_Loss: 0.5784  BEST VAL Loss: 0.5784  Val_Acc: 74.558

Epoch 47: Validation loss decreased (0.578435 --> 0.577938).  Saving model ...
	 Train_Loss: 0.5751 Train_Acc: 73.110 Val_Loss: 0.5779  BEST VAL Loss: 0.5779  Val_Acc: 73.942

Epoch 48: Validation loss decreased (0.577938 --> 0.577577).  Saving model ...
	 Train_Loss: 0.5744 Train_Acc: 72.848 Val_Loss: 0.5776  BEST VAL Loss: 0.5776  Val_Acc: 73.695

Epoch 49: Validation loss decreased (0.577577 --> 0.577134).  Saving model ...
	 Train_Loss: 0.5737 Train_Acc: 72.802 Val_Loss: 0.5771  BEST VAL Loss: 0.5771  Val_Acc: 73.613

Epoch 50: Validation loss decreased (0.577134 --> 0.576854).  Saving model ...
	 Train_Loss: 0.5730 Train_Acc: 72.797 Val_Loss: 0.5769  BEST VAL Loss: 0.5769  Val_Acc: 73.859

Epoch 51: Validation loss decreased (0.576854 --> 0.576538).  Saving model ...
	 Train_Loss: 0.5723 Train_Acc: 73.126 Val_Loss: 0.5765  BEST VAL Loss: 0.5765  Val_Acc: 74.394

Epoch 52: Validation loss decreased (0.576538 --> 0.576260).  Saving model ...
	 Train_Loss: 0.5716 Train_Acc: 73.306 Val_Loss: 0.5763  BEST VAL Loss: 0.5763  Val_Acc: 74.270

Epoch 53: Validation loss decreased (0.576260 --> 0.575950).  Saving model ...
	 Train_Loss: 0.5710 Train_Acc: 73.290 Val_Loss: 0.5760  BEST VAL Loss: 0.5760  Val_Acc: 74.147

Epoch 54: Validation loss decreased (0.575950 --> 0.575742).  Saving model ...
	 Train_Loss: 0.5704 Train_Acc: 72.766 Val_Loss: 0.5757  BEST VAL Loss: 0.5757  Val_Acc: 73.818

Epoch 55: Validation loss decreased (0.575742 --> 0.575544).  Saving model ...
	 Train_Loss: 0.5698 Train_Acc: 72.951 Val_Loss: 0.5755  BEST VAL Loss: 0.5755  Val_Acc: 73.859

Epoch 56: Validation loss decreased (0.575544 --> 0.575289).  Saving model ...
	 Train_Loss: 0.5692 Train_Acc: 73.352 Val_Loss: 0.5753  BEST VAL Loss: 0.5753  Val_Acc: 74.353

Epoch 57: Validation loss decreased (0.575289 --> 0.575064).  Saving model ...
	 Train_Loss: 0.5686 Train_Acc: 73.290 Val_Loss: 0.5751  BEST VAL Loss: 0.5751  Val_Acc: 73.942

Epoch 58: Validation loss decreased (0.575064 --> 0.574858).  Saving model ...
	 Train_Loss: 0.5680 Train_Acc: 73.038 Val_Loss: 0.5749  BEST VAL Loss: 0.5749  Val_Acc: 73.448

Epoch 59: Validation loss decreased (0.574858 --> 0.574692).  Saving model ...
	 Train_Loss: 0.5675 Train_Acc: 73.234 Val_Loss: 0.5747  BEST VAL Loss: 0.5747  Val_Acc: 73.818

Epoch 60: Validation loss decreased (0.574692 --> 0.574493).  Saving model ...
	 Train_Loss: 0.5669 Train_Acc: 73.511 Val_Loss: 0.5745  BEST VAL Loss: 0.5745  Val_Acc: 73.818

Epoch 61: Validation loss decreased (0.574493 --> 0.574292).  Saving model ...
	 Train_Loss: 0.5664 Train_Acc: 73.203 Val_Loss: 0.5743  BEST VAL Loss: 0.5743  Val_Acc: 73.777

Epoch 62: Validation loss decreased (0.574292 --> 0.573988).  Saving model ...
	 Train_Loss: 0.5659 Train_Acc: 72.956 Val_Loss: 0.5740  BEST VAL Loss: 0.5740  Val_Acc: 73.859

Epoch 63: Validation loss decreased (0.573988 --> 0.573651).  Saving model ...
	 Train_Loss: 0.5653 Train_Acc: 73.557 Val_Loss: 0.5737  BEST VAL Loss: 0.5737  Val_Acc: 74.147

Epoch 64: Validation loss decreased (0.573651 --> 0.573353).  Saving model ...
	 Train_Loss: 0.5648 Train_Acc: 73.044 Val_Loss: 0.5734  BEST VAL Loss: 0.5734  Val_Acc: 74.517

Epoch 65: Validation loss decreased (0.573353 --> 0.573140).  Saving model ...
	 Train_Loss: 0.5643 Train_Acc: 73.059 Val_Loss: 0.5731  BEST VAL Loss: 0.5731  Val_Acc: 74.229

Epoch 66: Validation loss decreased (0.573140 --> 0.572954).  Saving model ...
	 Train_Loss: 0.5638 Train_Acc: 73.311 Val_Loss: 0.5730  BEST VAL Loss: 0.5730  Val_Acc: 73.942

Epoch 67: Validation loss decreased (0.572954 --> 0.572725).  Saving model ...
	 Train_Loss: 0.5634 Train_Acc: 73.136 Val_Loss: 0.5727  BEST VAL Loss: 0.5727  Val_Acc: 74.270

Epoch 68: Validation loss decreased (0.572725 --> 0.572574).  Saving model ...
	 Train_Loss: 0.5630 Train_Acc: 73.028 Val_Loss: 0.5726  BEST VAL Loss: 0.5726  Val_Acc: 73.695

Epoch 69: Validation loss decreased (0.572574 --> 0.572453).  Saving model ...
	 Train_Loss: 0.5625 Train_Acc: 73.568 Val_Loss: 0.5725  BEST VAL Loss: 0.5725  Val_Acc: 73.695

Epoch 70: Validation loss decreased (0.572453 --> 0.572330).  Saving model ...
	 Train_Loss: 0.5621 Train_Acc: 73.306 Val_Loss: 0.5723  BEST VAL Loss: 0.5723  Val_Acc: 74.106

Epoch 71: Validation loss decreased (0.572330 --> 0.572279).  Saving model ...
	 Train_Loss: 0.5617 Train_Acc: 73.378 Val_Loss: 0.5723  BEST VAL Loss: 0.5723  Val_Acc: 73.983

Epoch 72: Validation loss decreased (0.572279 --> 0.572107).  Saving model ...
	 Train_Loss: 0.5612 Train_Acc: 73.521 Val_Loss: 0.5721  BEST VAL Loss: 0.5721  Val_Acc: 74.229

Epoch 73: Validation loss decreased (0.572107 --> 0.571825).  Saving model ...
	 Train_Loss: 0.5608 Train_Acc: 73.855 Val_Loss: 0.5718  BEST VAL Loss: 0.5718  Val_Acc: 74.270

Epoch 74: Validation loss decreased (0.571825 --> 0.571670).  Saving model ...
	 Train_Loss: 0.5604 Train_Acc: 73.182 Val_Loss: 0.5717  BEST VAL Loss: 0.5717  Val_Acc: 74.599

Epoch 75: Validation loss decreased (0.571670 --> 0.571421).  Saving model ...
	 Train_Loss: 0.5601 Train_Acc: 73.239 Val_Loss: 0.5714  BEST VAL Loss: 0.5714  Val_Acc: 74.640

Epoch 76: Validation loss decreased (0.571421 --> 0.571207).  Saving model ...
	 Train_Loss: 0.5597 Train_Acc: 73.552 Val_Loss: 0.5712  BEST VAL Loss: 0.5712  Val_Acc: 74.846

Epoch 77: Validation loss decreased (0.571207 --> 0.571012).  Saving model ...
	 Train_Loss: 0.5593 Train_Acc: 73.624 Val_Loss: 0.5710  BEST VAL Loss: 0.5710  Val_Acc: 74.270

Epoch 78: Validation loss decreased (0.571012 --> 0.570861).  Saving model ...
	 Train_Loss: 0.5589 Train_Acc: 73.809 Val_Loss: 0.5709  BEST VAL Loss: 0.5709  Val_Acc: 74.147

Epoch 79: Validation loss decreased (0.570861 --> 0.570674).  Saving model ...
	 Train_Loss: 0.5585 Train_Acc: 73.717 Val_Loss: 0.5707  BEST VAL Loss: 0.5707  Val_Acc: 74.353

Epoch 80: Validation loss decreased (0.570674 --> 0.570470).  Saving model ...
	 Train_Loss: 0.5581 Train_Acc: 73.989 Val_Loss: 0.5705  BEST VAL Loss: 0.5705  Val_Acc: 74.640

Epoch 81: Validation loss decreased (0.570470 --> 0.570270).  Saving model ...
	 Train_Loss: 0.5577 Train_Acc: 73.578 Val_Loss: 0.5703  BEST VAL Loss: 0.5703  Val_Acc: 74.969

Epoch 82: Validation loss decreased (0.570270 --> 0.570105).  Saving model ...
	 Train_Loss: 0.5573 Train_Acc: 73.444 Val_Loss: 0.5701  BEST VAL Loss: 0.5701  Val_Acc: 74.312

Epoch 83: Validation loss decreased (0.570105 --> 0.569894).  Saving model ...
	 Train_Loss: 0.5569 Train_Acc: 73.758 Val_Loss: 0.5699  BEST VAL Loss: 0.5699  Val_Acc: 74.723

Epoch 84: Validation loss decreased (0.569894 --> 0.569758).  Saving model ...
	 Train_Loss: 0.5566 Train_Acc: 74.220 Val_Loss: 0.5698  BEST VAL Loss: 0.5698  Val_Acc: 75.339

Epoch 85: Validation loss decreased (0.569758 --> 0.569633).  Saving model ...
	 Train_Loss: 0.5562 Train_Acc: 73.866 Val_Loss: 0.5696  BEST VAL Loss: 0.5696  Val_Acc: 75.010

Epoch 86: Validation loss decreased (0.569633 --> 0.569462).  Saving model ...
	 Train_Loss: 0.5559 Train_Acc: 73.701 Val_Loss: 0.5695  BEST VAL Loss: 0.5695  Val_Acc: 74.887

Epoch 87: Validation loss decreased (0.569462 --> 0.569257).  Saving model ...
	 Train_Loss: 0.5556 Train_Acc: 73.809 Val_Loss: 0.5693  BEST VAL Loss: 0.5693  Val_Acc: 75.051

Epoch 88: Validation loss decreased (0.569257 --> 0.569081).  Saving model ...
	 Train_Loss: 0.5552 Train_Acc: 74.020 Val_Loss: 0.5691  BEST VAL Loss: 0.5691  Val_Acc: 74.928

Epoch 89: Validation loss decreased (0.569081 --> 0.568893).  Saving model ...
	 Train_Loss: 0.5548 Train_Acc: 74.297 Val_Loss: 0.5689  BEST VAL Loss: 0.5689  Val_Acc: 74.846

Epoch 90: Validation loss decreased (0.568893 --> 0.568794).  Saving model ...
	 Train_Loss: 0.5545 Train_Acc: 74.148 Val_Loss: 0.5688  BEST VAL Loss: 0.5688  Val_Acc: 74.805

Epoch 91: Validation loss decreased (0.568794 --> 0.568606).  Saving model ...
	 Train_Loss: 0.5541 Train_Acc: 74.236 Val_Loss: 0.5686  BEST VAL Loss: 0.5686  Val_Acc: 74.846

Epoch 92: Validation loss decreased (0.568606 --> 0.568486).  Saving model ...
	 Train_Loss: 0.5537 Train_Acc: 74.431 Val_Loss: 0.5685  BEST VAL Loss: 0.5685  Val_Acc: 74.312

Epoch 93: Validation loss decreased (0.568486 --> 0.568337).  Saving model ...
	 Train_Loss: 0.5534 Train_Acc: 74.421 Val_Loss: 0.5683  BEST VAL Loss: 0.5683  Val_Acc: 74.846

Epoch 94: Validation loss decreased (0.568337 --> 0.568162).  Saving model ...
	 Train_Loss: 0.5530 Train_Acc: 74.333 Val_Loss: 0.5682  BEST VAL Loss: 0.5682  Val_Acc: 74.969

Epoch 95: Validation loss decreased (0.568162 --> 0.568014).  Saving model ...
	 Train_Loss: 0.5527 Train_Acc: 74.153 Val_Loss: 0.5680  BEST VAL Loss: 0.5680  Val_Acc: 74.558

Epoch 96: Validation loss decreased (0.568014 --> 0.567889).  Saving model ...
	 Train_Loss: 0.5523 Train_Acc: 74.236 Val_Loss: 0.5679  BEST VAL Loss: 0.5679  Val_Acc: 74.846

Epoch 97: Validation loss decreased (0.567889 --> 0.567783).  Saving model ...
	 Train_Loss: 0.5521 Train_Acc: 74.010 Val_Loss: 0.5678  BEST VAL Loss: 0.5678  Val_Acc: 74.723

Epoch 98: Validation loss did not decrease
	 Train_Loss: 0.5518 Train_Acc: 73.789 Val_Loss: 0.5678  BEST VAL Loss: 0.5678  Val_Acc: 74.805

Epoch 99: Validation loss decreased (0.567783 --> 0.567582).  Saving model ...
	 Train_Loss: 0.5514 Train_Acc: 74.744 Val_Loss: 0.5676  BEST VAL Loss: 0.5676  Val_Acc: 75.545

Flagellin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.77      0.88      0.82      9434
           1       0.87      0.75      0.81     10027

    accuracy                           0.82     19461
   macro avg       0.82      0.82      0.82     19461
weighted avg       0.82      0.82      0.82     19461

Flagellin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.72      0.82      0.76      1179
           1       0.80      0.69      0.75      1254

    accuracy                           0.76      2433
   macro avg       0.76      0.76      0.76      2433
weighted avg       0.76      0.76      0.75      2433

Flagellin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.70      0.81      0.75      1179
           1       0.79      0.68      0.73      1254

    accuracy                           0.74      2433
   macro avg       0.75      0.74      0.74      2433
weighted avg       0.75      0.74      0.74      2433

              precision    recall  f1-score   support

           0       0.70      0.81      0.75      1179
           1       0.79      0.68      0.73      1254

    accuracy                           0.74      2433
   macro avg       0.75      0.74      0.74      2433
weighted avg       0.75      0.74      0.74      2433

Flagellin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.55      0.55      0.55      4017
           1       0.54      0.53      0.53      3923

    accuracy                           0.54      7940
   macro avg       0.54      0.54      0.54      7940
weighted avg       0.54      0.54      0.54      7940

              precision    recall  f1-score   support

           0       0.55      0.55      0.55      4017
           1       0.54      0.53      0.53      3923

    accuracy                           0.54      7940
   macro avg       0.54      0.54      0.54      7940
weighted avg       0.54      0.54      0.54      7940

completed
