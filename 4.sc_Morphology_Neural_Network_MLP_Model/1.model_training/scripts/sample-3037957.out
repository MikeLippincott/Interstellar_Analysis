[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'aa9ad2ed'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '40218e83'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '39a6c6aa'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'b514f4af'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_100.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_100.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_100.000_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (32205, 1276)
Number of total missing values across all columns: 31974
Data Subset Is Off
Wells held out for testing: ['K16' 'J20']
Wells to use for training, validation, and testing ['J16' 'J17' 'K17' 'K20' 'J21' 'K21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.259689).  Saving model ...
	 Train_Loss: 0.4325 Train_Acc: 79.586 Val_Loss: 0.2597  BEST VAL Loss: 0.2597  Val_Acc: 91.304

Epoch 1: Validation loss decreased (0.259689 --> 0.212813).  Saving model ...
	 Train_Loss: 0.3283 Train_Acc: 91.347 Val_Loss: 0.2128  BEST VAL Loss: 0.2128  Val_Acc: 94.586

Epoch 2: Validation loss decreased (0.212813 --> 0.181473).  Saving model ...
	 Train_Loss: 0.2717 Train_Acc: 93.860 Val_Loss: 0.1815  BEST VAL Loss: 0.1815  Val_Acc: 95.775

Epoch 3: Validation loss decreased (0.181473 --> 0.162820).  Saving model ...
	 Train_Loss: 0.2357 Train_Acc: 94.784 Val_Loss: 0.1628  BEST VAL Loss: 0.1628  Val_Acc: 96.267

Epoch 4: Validation loss decreased (0.162820 --> 0.149071).  Saving model ...
	 Train_Loss: 0.2103 Train_Acc: 95.302 Val_Loss: 0.1491  BEST VAL Loss: 0.1491  Val_Acc: 96.596

Epoch 5: Validation loss decreased (0.149071 --> 0.139298).  Saving model ...
	 Train_Loss: 0.1916 Train_Acc: 95.553 Val_Loss: 0.1393  BEST VAL Loss: 0.1393  Val_Acc: 96.596

Epoch 6: Validation loss decreased (0.139298 --> 0.130902).  Saving model ...
	 Train_Loss: 0.1770 Train_Acc: 95.938 Val_Loss: 0.1309  BEST VAL Loss: 0.1309  Val_Acc: 96.924

Epoch 7: Validation loss decreased (0.130902 --> 0.123967).  Saving model ...
	 Train_Loss: 0.1653 Train_Acc: 96.194 Val_Loss: 0.1240  BEST VAL Loss: 0.1240  Val_Acc: 97.006

Epoch 8: Validation loss decreased (0.123967 --> 0.118631).  Saving model ...
	 Train_Loss: 0.1560 Train_Acc: 96.122 Val_Loss: 0.1186  BEST VAL Loss: 0.1186  Val_Acc: 97.170

Epoch 9: Validation loss decreased (0.118631 --> 0.115014).  Saving model ...
	 Train_Loss: 0.1479 Train_Acc: 96.415 Val_Loss: 0.1150  BEST VAL Loss: 0.1150  Val_Acc: 97.170

Epoch 10: Validation loss decreased (0.115014 --> 0.110950).  Saving model ...
	 Train_Loss: 0.1410 Train_Acc: 96.261 Val_Loss: 0.1110  BEST VAL Loss: 0.1110  Val_Acc: 97.416

Epoch 11: Validation loss decreased (0.110950 --> 0.107692).  Saving model ...
	 Train_Loss: 0.1349 Train_Acc: 96.692 Val_Loss: 0.1077  BEST VAL Loss: 0.1077  Val_Acc: 97.211

Epoch 12: Validation loss decreased (0.107692 --> 0.105327).  Saving model ...
	 Train_Loss: 0.1296 Train_Acc: 96.707 Val_Loss: 0.1053  BEST VAL Loss: 0.1053  Val_Acc: 97.293

Epoch 13: Validation loss decreased (0.105327 --> 0.103234).  Saving model ...
	 Train_Loss: 0.1250 Train_Acc: 96.815 Val_Loss: 0.1032  BEST VAL Loss: 0.1032  Val_Acc: 97.539

Epoch 14: Validation loss decreased (0.103234 --> 0.101133).  Saving model ...
	 Train_Loss: 0.1207 Train_Acc: 96.686 Val_Loss: 0.1011  BEST VAL Loss: 0.1011  Val_Acc: 97.375

Epoch 15: Validation loss decreased (0.101133 --> 0.099565).  Saving model ...
	 Train_Loss: 0.1169 Train_Acc: 96.820 Val_Loss: 0.0996  BEST VAL Loss: 0.0996  Val_Acc: 97.293

Epoch 16: Validation loss decreased (0.099565 --> 0.097828).  Saving model ...
	 Train_Loss: 0.1136 Train_Acc: 96.686 Val_Loss: 0.0978  BEST VAL Loss: 0.0978  Val_Acc: 97.457

Epoch 17: Validation loss decreased (0.097828 --> 0.096200).  Saving model ...
	 Train_Loss: 0.1110 Train_Acc: 96.569 Val_Loss: 0.0962  BEST VAL Loss: 0.0962  Val_Acc: 97.703

Epoch 18: Validation loss decreased (0.096200 --> 0.094399).  Saving model ...
	 Train_Loss: 0.1082 Train_Acc: 97.020 Val_Loss: 0.0944  BEST VAL Loss: 0.0944  Val_Acc: 97.785

Epoch 19: Validation loss decreased (0.094399 --> 0.093053).  Saving model ...
	 Train_Loss: 0.1057 Train_Acc: 96.938 Val_Loss: 0.0931  BEST VAL Loss: 0.0931  Val_Acc: 97.621

Epoch 20: Validation loss decreased (0.093053 --> 0.091753).  Saving model ...
	 Train_Loss: 0.1033 Train_Acc: 97.066 Val_Loss: 0.0918  BEST VAL Loss: 0.0918  Val_Acc: 97.539

Epoch 21: Validation loss decreased (0.091753 --> 0.090544).  Saving model ...
	 Train_Loss: 0.1011 Train_Acc: 97.066 Val_Loss: 0.0905  BEST VAL Loss: 0.0905  Val_Acc: 97.867

Epoch 22: Validation loss decreased (0.090544 --> 0.089669).  Saving model ...
	 Train_Loss: 0.0991 Train_Acc: 96.758 Val_Loss: 0.0897  BEST VAL Loss: 0.0897  Val_Acc: 97.785

Epoch 23: Validation loss decreased (0.089669 --> 0.088594).  Saving model ...
	 Train_Loss: 0.0973 Train_Acc: 97.010 Val_Loss: 0.0886  BEST VAL Loss: 0.0886  Val_Acc: 97.539

Epoch 24: Validation loss decreased (0.088594 --> 0.087540).  Saving model ...
	 Train_Loss: 0.0956 Train_Acc: 96.974 Val_Loss: 0.0875  BEST VAL Loss: 0.0875  Val_Acc: 97.621

Epoch 25: Validation loss decreased (0.087540 --> 0.086773).  Saving model ...
	 Train_Loss: 0.0939 Train_Acc: 96.861 Val_Loss: 0.0868  BEST VAL Loss: 0.0868  Val_Acc: 97.826

Epoch 26: Validation loss decreased (0.086773 --> 0.085877).  Saving model ...
	 Train_Loss: 0.0924 Train_Acc: 97.005 Val_Loss: 0.0859  BEST VAL Loss: 0.0859  Val_Acc: 97.867

Epoch 27: Validation loss decreased (0.085877 --> 0.085221).  Saving model ...
	 Train_Loss: 0.0909 Train_Acc: 96.974 Val_Loss: 0.0852  BEST VAL Loss: 0.0852  Val_Acc: 97.785

Epoch 28: Validation loss decreased (0.085221 --> 0.084466).  Saving model ...
	 Train_Loss: 0.0895 Train_Acc: 97.087 Val_Loss: 0.0845  BEST VAL Loss: 0.0845  Val_Acc: 97.826

Epoch 29: Validation loss decreased (0.084466 --> 0.083887).  Saving model ...
	 Train_Loss: 0.0883 Train_Acc: 96.979 Val_Loss: 0.0839  BEST VAL Loss: 0.0839  Val_Acc: 97.539

Epoch 30: Validation loss decreased (0.083887 --> 0.083073).  Saving model ...
	 Train_Loss: 0.0870 Train_Acc: 97.112 Val_Loss: 0.0831  BEST VAL Loss: 0.0831  Val_Acc: 97.621

Epoch 31: Validation loss decreased (0.083073 --> 0.082537).  Saving model ...
	 Train_Loss: 0.0858 Train_Acc: 97.266 Val_Loss: 0.0825  BEST VAL Loss: 0.0825  Val_Acc: 97.457

Epoch 32: Validation loss decreased (0.082537 --> 0.082078).  Saving model ...
	 Train_Loss: 0.0847 Train_Acc: 97.087 Val_Loss: 0.0821  BEST VAL Loss: 0.0821  Val_Acc: 97.908

Epoch 33: Validation loss decreased (0.082078 --> 0.081466).  Saving model ...
	 Train_Loss: 0.0836 Train_Acc: 97.276 Val_Loss: 0.0815  BEST VAL Loss: 0.0815  Val_Acc: 97.949

Epoch 34: Validation loss decreased (0.081466 --> 0.081068).  Saving model ...
	 Train_Loss: 0.0825 Train_Acc: 97.205 Val_Loss: 0.0811  BEST VAL Loss: 0.0811  Val_Acc: 97.826

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.0815 Train_Acc: 97.287 Val_Loss: 0.0813  BEST VAL Loss: 0.0811  Val_Acc: 97.867

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.0806 Train_Acc: 97.287 Val_Loss: 0.0815  BEST VAL Loss: 0.0811  Val_Acc: 97.662

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.0798 Train_Acc: 96.984 Val_Loss: 0.0811  BEST VAL Loss: 0.0811  Val_Acc: 97.826

Epoch 38: Validation loss decreased (0.081068 --> 0.080932).  Saving model ...
	 Train_Loss: 0.0789 Train_Acc: 97.415 Val_Loss: 0.0809  BEST VAL Loss: 0.0809  Val_Acc: 97.744

Epoch 39: Validation loss decreased (0.080932 --> 0.080389).  Saving model ...
	 Train_Loss: 0.0780 Train_Acc: 97.369 Val_Loss: 0.0804  BEST VAL Loss: 0.0804  Val_Acc: 98.113

Epoch 40: Validation loss decreased (0.080389 --> 0.080298).  Saving model ...
	 Train_Loss: 0.0772 Train_Acc: 97.097 Val_Loss: 0.0803  BEST VAL Loss: 0.0803  Val_Acc: 97.580

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.0765 Train_Acc: 97.138 Val_Loss: 0.0804  BEST VAL Loss: 0.0803  Val_Acc: 97.580

Epoch 42: Validation loss decreased (0.080298 --> 0.080147).  Saving model ...
	 Train_Loss: 0.0758 Train_Acc: 97.205 Val_Loss: 0.0801  BEST VAL Loss: 0.0801  Val_Acc: 97.703

Epoch 43: Validation loss decreased (0.080147 --> 0.079764).  Saving model ...
	 Train_Loss: 0.0751 Train_Acc: 97.179 Val_Loss: 0.0798  BEST VAL Loss: 0.0798  Val_Acc: 97.621

Epoch 44: Validation loss decreased (0.079764 --> 0.079198).  Saving model ...
	 Train_Loss: 0.0745 Train_Acc: 97.215 Val_Loss: 0.0792  BEST VAL Loss: 0.0792  Val_Acc: 97.785

Epoch 45: Validation loss decreased (0.079198 --> 0.079044).  Saving model ...
	 Train_Loss: 0.0739 Train_Acc: 97.235 Val_Loss: 0.0790  BEST VAL Loss: 0.0790  Val_Acc: 98.072

Epoch 46: Validation loss decreased (0.079044 --> 0.078777).  Saving model ...
	 Train_Loss: 0.0733 Train_Acc: 97.117 Val_Loss: 0.0788  BEST VAL Loss: 0.0788  Val_Acc: 97.867

Epoch 47: Validation loss decreased (0.078777 --> 0.078671).  Saving model ...
	 Train_Loss: 0.0727 Train_Acc: 97.194 Val_Loss: 0.0787  BEST VAL Loss: 0.0787  Val_Acc: 98.113

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.0721 Train_Acc: 97.297 Val_Loss: 0.0787  BEST VAL Loss: 0.0787  Val_Acc: 98.072

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.0716 Train_Acc: 97.199 Val_Loss: 0.0791  BEST VAL Loss: 0.0787  Val_Acc: 98.031

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.0711 Train_Acc: 97.281 Val_Loss: 0.0791  BEST VAL Loss: 0.0787  Val_Acc: 98.154

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.0706 Train_Acc: 97.281 Val_Loss: 0.0788  BEST VAL Loss: 0.0787  Val_Acc: 97.990

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.0701 Train_Acc: 97.271 Val_Loss: 0.0793  BEST VAL Loss: 0.0787  Val_Acc: 97.867

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.0696 Train_Acc: 97.415 Val_Loss: 0.0794  BEST VAL Loss: 0.0787  Val_Acc: 98.072

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.0692 Train_Acc: 97.122 Val_Loss: 0.0795  BEST VAL Loss: 0.0787  Val_Acc: 97.826

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.0687 Train_Acc: 97.343 Val_Loss: 0.0794  BEST VAL Loss: 0.0787  Val_Acc: 97.990

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.0683 Train_Acc: 97.205 Val_Loss: 0.0794  BEST VAL Loss: 0.0787  Val_Acc: 97.703

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.0678 Train_Acc: 97.512 Val_Loss: 0.0793  BEST VAL Loss: 0.0787  Val_Acc: 97.908

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.0674 Train_Acc: 97.369 Val_Loss: 0.0791  BEST VAL Loss: 0.0787  Val_Acc: 98.072

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.0670 Train_Acc: 97.184 Val_Loss: 0.0788  BEST VAL Loss: 0.0787  Val_Acc: 97.826

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.0666 Train_Acc: 97.425 Val_Loss: 0.0790  BEST VAL Loss: 0.0787  Val_Acc: 98.154

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.0661 Train_Acc: 97.543 Val_Loss: 0.0789  BEST VAL Loss: 0.0787  Val_Acc: 97.990

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.0658 Train_Acc: 97.317 Val_Loss: 0.0790  BEST VAL Loss: 0.0787  Val_Acc: 97.990

Epoch 63: Validation loss did not decrease
Early stopped at epoch : 63
LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.52      0.52      9892
           1       0.50      0.50      0.50      9604

    accuracy                           0.51     19496
   macro avg       0.51      0.51      0.51     19496
weighted avg       0.51      0.51      0.51     19496

LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.50      0.50      1237
           1       0.48      0.48      0.48      1201

    accuracy                           0.49      2438
   macro avg       0.49      0.49      0.49      2438
weighted avg       0.49      0.49      0.49      2438

LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.52      0.52      1236
           1       0.50      0.49      0.50      1201

    accuracy                           0.51      2437
   macro avg       0.51      0.51      0.51      2437
weighted avg       0.51      0.51      0.51      2437

              precision    recall  f1-score   support

           0       0.51      0.52      0.52      1236
           1       0.50      0.49      0.50      1201

    accuracy                           0.51      2437
   macro avg       0.51      0.51      0.51      2437
weighted avg       0.51      0.51      0.51      2437

LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.46      0.46      3622
           1       0.54      0.55      0.55      4212

    accuracy                           0.51      7834
   macro avg       0.51      0.51      0.51      7834
weighted avg       0.51      0.51      0.51      7834

              precision    recall  f1-score   support

           0       0.47      0.46      0.46      3622
           1       0.54      0.55      0.55      4212

    accuracy                           0.51      7834
   macro avg       0.51      0.51      0.51      7834
weighted avg       0.51      0.51      0.51      7834

completed
