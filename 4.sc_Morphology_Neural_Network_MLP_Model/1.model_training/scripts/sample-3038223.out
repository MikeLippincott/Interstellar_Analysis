[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'f630a5b4'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'd8ce8c5c'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '10485f4b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'a9ebfdc3'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_1.000_DMSO_0.025 treatment_name: LPS_10.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_10.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (32619, 1276)
Number of total missing values across all columns: 65238
Data Subset Is Off
Wells held out for testing: ['E21' 'M22']
Wells to use for training, validation, and testing ['E16' 'E17' 'E20' 'M18' 'M19' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.688470).  Saving model ...
	 Train_Loss: 0.6985 Train_Acc: 50.860 Val_Loss: 0.6885  BEST VAL Loss: 0.6885  Val_Acc: 52.537

Epoch 1: Validation loss decreased (0.688470 --> 0.681918).  Saving model ...
	 Train_Loss: 0.6927 Train_Acc: 52.880 Val_Loss: 0.6819  BEST VAL Loss: 0.6819  Val_Acc: 59.124

Epoch 2: Validation loss decreased (0.681918 --> 0.675831).  Saving model ...
	 Train_Loss: 0.6871 Train_Acc: 57.546 Val_Loss: 0.6758  BEST VAL Loss: 0.6758  Val_Acc: 61.743

Epoch 3: Validation loss decreased (0.675831 --> 0.670624).  Saving model ...
	 Train_Loss: 0.6823 Train_Acc: 59.516 Val_Loss: 0.6706  BEST VAL Loss: 0.6706  Val_Acc: 62.439

Epoch 4: Validation loss decreased (0.670624 --> 0.661592).  Saving model ...
	 Train_Loss: 0.6765 Train_Acc: 61.174 Val_Loss: 0.6616  BEST VAL Loss: 0.6616  Val_Acc: 66.080

Epoch 5: Validation loss decreased (0.661592 --> 0.651253).  Saving model ...
	 Train_Loss: 0.6692 Train_Acc: 63.338 Val_Loss: 0.6513  BEST VAL Loss: 0.6513  Val_Acc: 67.921

Epoch 6: Validation loss decreased (0.651253 --> 0.640459).  Saving model ...
	 Train_Loss: 0.6610 Train_Acc: 65.737 Val_Loss: 0.6405  BEST VAL Loss: 0.6405  Val_Acc: 69.026

Epoch 7: Validation loss decreased (0.640459 --> 0.631698).  Saving model ...
	 Train_Loss: 0.6531 Train_Acc: 66.796 Val_Loss: 0.6317  BEST VAL Loss: 0.6317  Val_Acc: 68.944

Epoch 8: Validation loss decreased (0.631698 --> 0.623208).  Saving model ...
	 Train_Loss: 0.6459 Train_Acc: 67.789 Val_Loss: 0.6232  BEST VAL Loss: 0.6232  Val_Acc: 70.540

Epoch 9: Validation loss decreased (0.623208 --> 0.616600).  Saving model ...
	 Train_Loss: 0.6389 Train_Acc: 68.490 Val_Loss: 0.6166  BEST VAL Loss: 0.6166  Val_Acc: 70.499

Epoch 10: Validation loss decreased (0.616600 --> 0.609294).  Saving model ...
	 Train_Loss: 0.6321 Train_Acc: 69.564 Val_Loss: 0.6093  BEST VAL Loss: 0.6093  Val_Acc: 71.809

Epoch 11: Validation loss decreased (0.609294 --> 0.603214).  Saving model ...
	 Train_Loss: 0.6264 Train_Acc: 69.851 Val_Loss: 0.6032  BEST VAL Loss: 0.6032  Val_Acc: 71.809

Epoch 12: Validation loss decreased (0.603214 --> 0.597798).  Saving model ...
	 Train_Loss: 0.6207 Train_Acc: 70.019 Val_Loss: 0.5978  BEST VAL Loss: 0.5978  Val_Acc: 70.867

Epoch 13: Validation loss decreased (0.597798 --> 0.592807).  Saving model ...
	 Train_Loss: 0.6156 Train_Acc: 70.434 Val_Loss: 0.5928  BEST VAL Loss: 0.5928  Val_Acc: 71.890

Epoch 14: Validation loss decreased (0.592807 --> 0.588224).  Saving model ...
	 Train_Loss: 0.6108 Train_Acc: 70.853 Val_Loss: 0.5882  BEST VAL Loss: 0.5882  Val_Acc: 72.709

Epoch 15: Validation loss decreased (0.588224 --> 0.584463).  Saving model ...
	 Train_Loss: 0.6067 Train_Acc: 70.736 Val_Loss: 0.5845  BEST VAL Loss: 0.5845  Val_Acc: 72.545

Epoch 16: Validation loss decreased (0.584463 --> 0.581195).  Saving model ...
	 Train_Loss: 0.6025 Train_Acc: 71.431 Val_Loss: 0.5812  BEST VAL Loss: 0.5812  Val_Acc: 72.872

Epoch 17: Validation loss decreased (0.581195 --> 0.577983).  Saving model ...
	 Train_Loss: 0.5987 Train_Acc: 71.964 Val_Loss: 0.5780  BEST VAL Loss: 0.5780  Val_Acc: 73.159

Epoch 18: Validation loss decreased (0.577983 --> 0.575259).  Saving model ...
	 Train_Loss: 0.5951 Train_Acc: 71.585 Val_Loss: 0.5753  BEST VAL Loss: 0.5753  Val_Acc: 73.486

Epoch 19: Validation loss decreased (0.575259 --> 0.573188).  Saving model ...
	 Train_Loss: 0.5917 Train_Acc: 71.994 Val_Loss: 0.5732  BEST VAL Loss: 0.5732  Val_Acc: 72.831

Epoch 20: Validation loss decreased (0.573188 --> 0.571046).  Saving model ...
	 Train_Loss: 0.5885 Train_Acc: 72.040 Val_Loss: 0.5710  BEST VAL Loss: 0.5710  Val_Acc: 72.627

Epoch 21: Validation loss decreased (0.571046 --> 0.568696).  Saving model ...
	 Train_Loss: 0.5853 Train_Acc: 72.434 Val_Loss: 0.5687  BEST VAL Loss: 0.5687  Val_Acc: 74.345

Epoch 22: Validation loss decreased (0.568696 --> 0.566832).  Saving model ...
	 Train_Loss: 0.5825 Train_Acc: 72.209 Val_Loss: 0.5668  BEST VAL Loss: 0.5668  Val_Acc: 73.241

Epoch 23: Validation loss decreased (0.566832 --> 0.564759).  Saving model ...
	 Train_Loss: 0.5797 Train_Acc: 72.127 Val_Loss: 0.5648  BEST VAL Loss: 0.5648  Val_Acc: 74.018

Epoch 24: Validation loss decreased (0.564759 --> 0.562472).  Saving model ...
	 Train_Loss: 0.5770 Train_Acc: 72.235 Val_Loss: 0.5625  BEST VAL Loss: 0.5625  Val_Acc: 74.632

Epoch 25: Validation loss decreased (0.562472 --> 0.560768).  Saving model ...
	 Train_Loss: 0.5744 Train_Acc: 72.578 Val_Loss: 0.5608  BEST VAL Loss: 0.5608  Val_Acc: 72.872

Epoch 26: Validation loss decreased (0.560768 --> 0.558964).  Saving model ...
	 Train_Loss: 0.5718 Train_Acc: 72.987 Val_Loss: 0.5590  BEST VAL Loss: 0.5590  Val_Acc: 74.468

Epoch 27: Validation loss decreased (0.558964 --> 0.557198).  Saving model ...
	 Train_Loss: 0.5694 Train_Acc: 73.181 Val_Loss: 0.5572  BEST VAL Loss: 0.5572  Val_Acc: 75.532

Epoch 28: Validation loss decreased (0.557198 --> 0.555807).  Saving model ...
	 Train_Loss: 0.5670 Train_Acc: 73.826 Val_Loss: 0.5558  BEST VAL Loss: 0.5558  Val_Acc: 73.936

Epoch 29: Validation loss decreased (0.555807 --> 0.554463).  Saving model ...
	 Train_Loss: 0.5648 Train_Acc: 73.212 Val_Loss: 0.5545  BEST VAL Loss: 0.5545  Val_Acc: 74.427

Epoch 30: Validation loss decreased (0.554463 --> 0.553295).  Saving model ...
	 Train_Loss: 0.5627 Train_Acc: 73.273 Val_Loss: 0.5533  BEST VAL Loss: 0.5533  Val_Acc: 73.936

Epoch 31: Validation loss decreased (0.553295 --> 0.552188).  Saving model ...
	 Train_Loss: 0.5606 Train_Acc: 73.248 Val_Loss: 0.5522  BEST VAL Loss: 0.5522  Val_Acc: 74.182

Epoch 32: Validation loss decreased (0.552188 --> 0.550849).  Saving model ...
	 Train_Loss: 0.5585 Train_Acc: 73.017 Val_Loss: 0.5508  BEST VAL Loss: 0.5508  Val_Acc: 74.182

Epoch 33: Validation loss decreased (0.550849 --> 0.550168).  Saving model ...
	 Train_Loss: 0.5565 Train_Acc: 73.677 Val_Loss: 0.5502  BEST VAL Loss: 0.5502  Val_Acc: 73.936

Epoch 34: Validation loss decreased (0.550168 --> 0.549178).  Saving model ...
	 Train_Loss: 0.5549 Train_Acc: 73.212 Val_Loss: 0.5492  BEST VAL Loss: 0.5492  Val_Acc: 73.773

Epoch 35: Validation loss decreased (0.549178 --> 0.547821).  Saving model ...
	 Train_Loss: 0.5530 Train_Acc: 73.688 Val_Loss: 0.5478  BEST VAL Loss: 0.5478  Val_Acc: 73.936

Epoch 36: Validation loss decreased (0.547821 --> 0.546881).  Saving model ...
	 Train_Loss: 0.5510 Train_Acc: 74.312 Val_Loss: 0.5469  BEST VAL Loss: 0.5469  Val_Acc: 75.164

Epoch 37: Validation loss decreased (0.546881 --> 0.546040).  Saving model ...
	 Train_Loss: 0.5494 Train_Acc: 74.015 Val_Loss: 0.5460  BEST VAL Loss: 0.5460  Val_Acc: 75.205

Epoch 38: Validation loss decreased (0.546040 --> 0.545166).  Saving model ...
	 Train_Loss: 0.5479 Train_Acc: 73.780 Val_Loss: 0.5452  BEST VAL Loss: 0.5452  Val_Acc: 75.450

Epoch 39: Validation loss decreased (0.545166 --> 0.544372).  Saving model ...
	 Train_Loss: 0.5463 Train_Acc: 73.662 Val_Loss: 0.5444  BEST VAL Loss: 0.5444  Val_Acc: 75.041

Epoch 40: Validation loss decreased (0.544372 --> 0.543703).  Saving model ...
	 Train_Loss: 0.5447 Train_Acc: 74.399 Val_Loss: 0.5437  BEST VAL Loss: 0.5437  Val_Acc: 74.100

Epoch 41: Validation loss decreased (0.543703 --> 0.542557).  Saving model ...
	 Train_Loss: 0.5434 Train_Acc: 73.954 Val_Loss: 0.5426  BEST VAL Loss: 0.5426  Val_Acc: 75.286

Epoch 42: Validation loss decreased (0.542557 --> 0.541790).  Saving model ...
	 Train_Loss: 0.5420 Train_Acc: 74.199 Val_Loss: 0.5418  BEST VAL Loss: 0.5418  Val_Acc: 75.205

Epoch 43: Validation loss decreased (0.541790 --> 0.541304).  Saving model ...
	 Train_Loss: 0.5406 Train_Acc: 73.954 Val_Loss: 0.5413  BEST VAL Loss: 0.5413  Val_Acc: 74.795

Epoch 44: Validation loss decreased (0.541304 --> 0.540889).  Saving model ...
	 Train_Loss: 0.5392 Train_Acc: 74.102 Val_Loss: 0.5409  BEST VAL Loss: 0.5409  Val_Acc: 75.368

Epoch 45: Validation loss decreased (0.540889 --> 0.540183).  Saving model ...
	 Train_Loss: 0.5378 Train_Acc: 74.435 Val_Loss: 0.5402  BEST VAL Loss: 0.5402  Val_Acc: 75.082

Epoch 46: Validation loss decreased (0.540183 --> 0.539850).  Saving model ...
	 Train_Loss: 0.5364 Train_Acc: 74.517 Val_Loss: 0.5399  BEST VAL Loss: 0.5399  Val_Acc: 75.123

Epoch 47: Validation loss decreased (0.539850 --> 0.539323).  Saving model ...
	 Train_Loss: 0.5352 Train_Acc: 74.343 Val_Loss: 0.5393  BEST VAL Loss: 0.5393  Val_Acc: 74.714

Epoch 48: Validation loss decreased (0.539323 --> 0.538753).  Saving model ...
	 Train_Loss: 0.5339 Train_Acc: 74.609 Val_Loss: 0.5388  BEST VAL Loss: 0.5388  Val_Acc: 74.632

Epoch 49: Validation loss decreased (0.538753 --> 0.538207).  Saving model ...
	 Train_Loss: 0.5326 Train_Acc: 74.414 Val_Loss: 0.5382  BEST VAL Loss: 0.5382  Val_Acc: 74.550

Epoch 50: Validation loss decreased (0.538207 --> 0.537863).  Saving model ...
	 Train_Loss: 0.5313 Train_Acc: 74.788 Val_Loss: 0.5379  BEST VAL Loss: 0.5379  Val_Acc: 75.000

Epoch 51: Validation loss decreased (0.537863 --> 0.537288).  Saving model ...
	 Train_Loss: 0.5302 Train_Acc: 74.450 Val_Loss: 0.5373  BEST VAL Loss: 0.5373  Val_Acc: 75.491

Epoch 52: Validation loss decreased (0.537288 --> 0.536815).  Saving model ...
	 Train_Loss: 0.5290 Train_Acc: 74.481 Val_Loss: 0.5368  BEST VAL Loss: 0.5368  Val_Acc: 75.409

Epoch 53: Validation loss decreased (0.536815 --> 0.536335).  Saving model ...
	 Train_Loss: 0.5280 Train_Acc: 74.158 Val_Loss: 0.5363  BEST VAL Loss: 0.5363  Val_Acc: 74.509

Epoch 54: Validation loss decreased (0.536335 --> 0.536001).  Saving model ...
	 Train_Loss: 0.5268 Train_Acc: 74.650 Val_Loss: 0.5360  BEST VAL Loss: 0.5360  Val_Acc: 75.777

Epoch 55: Validation loss decreased (0.536001 --> 0.535776).  Saving model ...
	 Train_Loss: 0.5258 Train_Acc: 74.506 Val_Loss: 0.5358  BEST VAL Loss: 0.5358  Val_Acc: 74.959

Epoch 56: Validation loss decreased (0.535776 --> 0.535649).  Saving model ...
	 Train_Loss: 0.5247 Train_Acc: 74.593 Val_Loss: 0.5356  BEST VAL Loss: 0.5356  Val_Acc: 76.105

Epoch 57: Validation loss decreased (0.535649 --> 0.535412).  Saving model ...
	 Train_Loss: 0.5238 Train_Acc: 74.215 Val_Loss: 0.5354  BEST VAL Loss: 0.5354  Val_Acc: 75.368

Epoch 58: Validation loss decreased (0.535412 --> 0.535250).  Saving model ...
	 Train_Loss: 0.5229 Train_Acc: 74.578 Val_Loss: 0.5352  BEST VAL Loss: 0.5352  Val_Acc: 75.041

Epoch 59: Validation loss decreased (0.535250 --> 0.535188).  Saving model ...
	 Train_Loss: 0.5220 Train_Acc: 74.353 Val_Loss: 0.5352  BEST VAL Loss: 0.5352  Val_Acc: 74.755

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.5211 Train_Acc: 74.455 Val_Loss: 0.5352  BEST VAL Loss: 0.5352  Val_Acc: 75.327

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.5203 Train_Acc: 74.501 Val_Loss: 0.5353  BEST VAL Loss: 0.5352  Val_Acc: 75.450

Epoch 62: Validation loss decreased (0.535188 --> 0.534980).  Saving model ...
	 Train_Loss: 0.5195 Train_Acc: 74.261 Val_Loss: 0.5350  BEST VAL Loss: 0.5350  Val_Acc: 75.409

Epoch 63: Validation loss decreased (0.534980 --> 0.534893).  Saving model ...
	 Train_Loss: 0.5188 Train_Acc: 74.194 Val_Loss: 0.5349  BEST VAL Loss: 0.5349  Val_Acc: 75.245

Epoch 64: Validation loss decreased (0.534893 --> 0.534555).  Saving model ...
	 Train_Loss: 0.5180 Train_Acc: 74.430 Val_Loss: 0.5346  BEST VAL Loss: 0.5346  Val_Acc: 74.795

Epoch 65: Validation loss decreased (0.534555 --> 0.534534).  Saving model ...
	 Train_Loss: 0.5172 Train_Acc: 74.138 Val_Loss: 0.5345  BEST VAL Loss: 0.5345  Val_Acc: 75.450

Epoch 66: Validation loss decreased (0.534534 --> 0.534368).  Saving model ...
	 Train_Loss: 0.5164 Train_Acc: 74.557 Val_Loss: 0.5344  BEST VAL Loss: 0.5344  Val_Acc: 75.491

Epoch 67: Validation loss decreased (0.534368 --> 0.534103).  Saving model ...
	 Train_Loss: 0.5156 Train_Acc: 74.885 Val_Loss: 0.5341  BEST VAL Loss: 0.5341  Val_Acc: 75.082

Epoch 68: Validation loss decreased (0.534103 --> 0.533873).  Saving model ...
	 Train_Loss: 0.5148 Train_Acc: 74.731 Val_Loss: 0.5339  BEST VAL Loss: 0.5339  Val_Acc: 74.673

Epoch 69: Validation loss decreased (0.533873 --> 0.533618).  Saving model ...
	 Train_Loss: 0.5140 Train_Acc: 74.399 Val_Loss: 0.5336  BEST VAL Loss: 0.5336  Val_Acc: 75.655

Epoch 70: Validation loss decreased (0.533618 --> 0.533424).  Saving model ...
	 Train_Loss: 0.5132 Train_Acc: 74.588 Val_Loss: 0.5334  BEST VAL Loss: 0.5334  Val_Acc: 74.795

Epoch 71: Validation loss decreased (0.533424 --> 0.533260).  Saving model ...
	 Train_Loss: 0.5124 Train_Acc: 74.870 Val_Loss: 0.5333  BEST VAL Loss: 0.5333  Val_Acc: 75.327

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.5116 Train_Acc: 74.864 Val_Loss: 0.5333  BEST VAL Loss: 0.5333  Val_Acc: 75.818

Epoch 73: Validation loss decreased (0.533260 --> 0.533075).  Saving model ...
	 Train_Loss: 0.5108 Train_Acc: 74.890 Val_Loss: 0.5331  BEST VAL Loss: 0.5331  Val_Acc: 75.450

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.5101 Train_Acc: 75.003 Val_Loss: 0.5332  BEST VAL Loss: 0.5331  Val_Acc: 75.491

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.5094 Train_Acc: 75.120 Val_Loss: 0.5332  BEST VAL Loss: 0.5331  Val_Acc: 74.836

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.5086 Train_Acc: 75.018 Val_Loss: 0.5333  BEST VAL Loss: 0.5331  Val_Acc: 74.182

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.5079 Train_Acc: 74.941 Val_Loss: 0.5332  BEST VAL Loss: 0.5331  Val_Acc: 74.386

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.5072 Train_Acc: 74.829 Val_Loss: 0.5331  BEST VAL Loss: 0.5331  Val_Acc: 75.082

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.5065 Train_Acc: 75.381 Val_Loss: 0.5334  BEST VAL Loss: 0.5331  Val_Acc: 75.450

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.5059 Train_Acc: 75.238 Val_Loss: 0.5336  BEST VAL Loss: 0.5331  Val_Acc: 74.795

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.5053 Train_Acc: 74.737 Val_Loss: 0.5340  BEST VAL Loss: 0.5331  Val_Acc: 74.386

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.5046 Train_Acc: 75.090 Val_Loss: 0.5340  BEST VAL Loss: 0.5331  Val_Acc: 75.491

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.5039 Train_Acc: 75.079 Val_Loss: 0.5342  BEST VAL Loss: 0.5331  Val_Acc: 75.327

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.5032 Train_Acc: 75.146 Val_Loss: 0.5344  BEST VAL Loss: 0.5331  Val_Acc: 75.205

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.5025 Train_Acc: 75.038 Val_Loss: 0.5345  BEST VAL Loss: 0.5331  Val_Acc: 75.205

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.5020 Train_Acc: 74.660 Val_Loss: 0.5343  BEST VAL Loss: 0.5331  Val_Acc: 75.941

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.5014 Train_Acc: 74.895 Val_Loss: 0.5346  BEST VAL Loss: 0.5331  Val_Acc: 73.773

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.5008 Train_Acc: 74.992 Val_Loss: 0.5345  BEST VAL Loss: 0.5331  Val_Acc: 75.532

Epoch 89: Validation loss did not decrease
Early stopped at epoch : 89
Flagellin_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.79      0.89      0.84      9433
           1       0.89      0.77      0.83     10113

    accuracy                           0.83     19546
   macro avg       0.84      0.83      0.83     19546
weighted avg       0.84      0.83      0.83     19546

Flagellin_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.72      0.81      0.76      1179
           1       0.80      0.70      0.75      1265

    accuracy                           0.75      2444
   macro avg       0.76      0.76      0.75      2444
weighted avg       0.76      0.75      0.75      2444

Flagellin_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.71      0.81      0.75      1180
           1       0.79      0.69      0.74      1264

    accuracy                           0.75      2444
   macro avg       0.75      0.75      0.75      2444
weighted avg       0.75      0.75      0.75      2444

              precision    recall  f1-score   support

           0       0.71      0.81      0.75      1180
           1       0.79      0.69      0.74      1264

    accuracy                           0.75      2444
   macro avg       0.75      0.75      0.75      2444
weighted avg       0.75      0.75      0.75      2444

Flagellin_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.53      0.52      0.52      4017
           1       0.54      0.55      0.55      4168

    accuracy                           0.54      8185
   macro avg       0.54      0.54      0.54      8185
weighted avg       0.54      0.54      0.54      8185

              precision    recall  f1-score   support

           0       0.53      0.52      0.52      4017
           1       0.54      0.55      0.55      4168

    accuracy                           0.54      8185
   macro avg       0.54      0.54      0.54      8185
weighted avg       0.54      0.54      0.54      8185

completed
