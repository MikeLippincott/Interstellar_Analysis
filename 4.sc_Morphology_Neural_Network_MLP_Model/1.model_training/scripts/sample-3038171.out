[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '0cd55ba8'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '99907fdc'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b112989f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '09585c40'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_100.000_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (333696, 1270)
Number of total missing values across all columns: 318870
Data Subset Is Off
Wells held out for testing: ['J08' 'L09']
Wells to use for training, validation, and testing ['J02' 'J03' 'J09' 'L02' 'L03' 'L08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.259075).  Saving model ...
	 Train_Loss: 0.3809 Train_Acc: 83.302 Val_Loss: 0.2591  BEST VAL Loss: 0.2591  Val_Acc: 90.090

Epoch 1: Validation loss decreased (0.259075 --> 0.236643).  Saving model ...
	 Train_Loss: 0.3263 Train_Acc: 89.155 Val_Loss: 0.2366  BEST VAL Loss: 0.2366  Val_Acc: 91.764

Epoch 2: Validation loss decreased (0.236643 --> 0.223586).  Saving model ...
	 Train_Loss: 0.2983 Train_Acc: 90.365 Val_Loss: 0.2236  BEST VAL Loss: 0.2236  Val_Acc: 92.355

Epoch 3: Validation loss decreased (0.223586 --> 0.213860).  Saving model ...
	 Train_Loss: 0.2802 Train_Acc: 90.934 Val_Loss: 0.2139  BEST VAL Loss: 0.2139  Val_Acc: 92.962

Epoch 4: Validation loss decreased (0.213860 --> 0.209288).  Saving model ...
	 Train_Loss: 0.2676 Train_Acc: 91.206 Val_Loss: 0.2093  BEST VAL Loss: 0.2093  Val_Acc: 92.471

Epoch 5: Validation loss decreased (0.209288 --> 0.203177).  Saving model ...
	 Train_Loss: 0.2578 Train_Acc: 91.478 Val_Loss: 0.2032  BEST VAL Loss: 0.2032  Val_Acc: 93.375

Epoch 6: Validation loss decreased (0.203177 --> 0.198217).  Saving model ...
	 Train_Loss: 0.2499 Train_Acc: 91.679 Val_Loss: 0.1982  BEST VAL Loss: 0.1982  Val_Acc: 93.538

Epoch 7: Validation loss decreased (0.198217 --> 0.194184).  Saving model ...
	 Train_Loss: 0.2434 Train_Acc: 91.787 Val_Loss: 0.1942  BEST VAL Loss: 0.1942  Val_Acc: 93.638

Epoch 8: Validation loss decreased (0.194184 --> 0.191246).  Saving model ...
	 Train_Loss: 0.2379 Train_Acc: 92.018 Val_Loss: 0.1912  BEST VAL Loss: 0.1912  Val_Acc: 93.360

Epoch 9: Validation loss decreased (0.191246 --> 0.187869).  Saving model ...
	 Train_Loss: 0.2331 Train_Acc: 92.431 Val_Loss: 0.1879  BEST VAL Loss: 0.1879  Val_Acc: 93.882

Epoch 10: Validation loss decreased (0.187869 --> 0.184940).  Saving model ...
	 Train_Loss: 0.2290 Train_Acc: 92.549 Val_Loss: 0.1849  BEST VAL Loss: 0.1849  Val_Acc: 93.913

Epoch 11: Validation loss decreased (0.184940 --> 0.182506).  Saving model ...
	 Train_Loss: 0.2253 Train_Acc: 92.649 Val_Loss: 0.1825  BEST VAL Loss: 0.1825  Val_Acc: 93.886

Epoch 12: Validation loss decreased (0.182506 --> 0.180216).  Saving model ...
	 Train_Loss: 0.2220 Train_Acc: 92.796 Val_Loss: 0.1802  BEST VAL Loss: 0.1802  Val_Acc: 94.048

Epoch 13: Validation loss decreased (0.180216 --> 0.178248).  Saving model ...
	 Train_Loss: 0.2190 Train_Acc: 92.820 Val_Loss: 0.1782  BEST VAL Loss: 0.1782  Val_Acc: 93.990

Epoch 14: Validation loss decreased (0.178248 --> 0.176441).  Saving model ...
	 Train_Loss: 0.2163 Train_Acc: 92.887 Val_Loss: 0.1764  BEST VAL Loss: 0.1764  Val_Acc: 93.990

Epoch 15: Validation loss decreased (0.176441 --> 0.174995).  Saving model ...
	 Train_Loss: 0.2139 Train_Acc: 92.914 Val_Loss: 0.1750  BEST VAL Loss: 0.1750  Val_Acc: 94.005

Epoch 16: Validation loss decreased (0.174995 --> 0.173466).  Saving model ...
	 Train_Loss: 0.2116 Train_Acc: 93.006 Val_Loss: 0.1735  BEST VAL Loss: 0.1735  Val_Acc: 94.222

Epoch 17: Validation loss decreased (0.173466 --> 0.171964).  Saving model ...
	 Train_Loss: 0.2095 Train_Acc: 93.068 Val_Loss: 0.1720  BEST VAL Loss: 0.1720  Val_Acc: 94.222

Epoch 18: Validation loss decreased (0.171964 --> 0.170661).  Saving model ...
	 Train_Loss: 0.2076 Train_Acc: 93.083 Val_Loss: 0.1707  BEST VAL Loss: 0.1707  Val_Acc: 94.226

Epoch 19: Validation loss decreased (0.170661 --> 0.169439).  Saving model ...
	 Train_Loss: 0.2059 Train_Acc: 93.091 Val_Loss: 0.1694  BEST VAL Loss: 0.1694  Val_Acc: 94.392

Epoch 20: Validation loss decreased (0.169439 --> 0.168319).  Saving model ...
	 Train_Loss: 0.2042 Train_Acc: 93.197 Val_Loss: 0.1683  BEST VAL Loss: 0.1683  Val_Acc: 94.287

Epoch 21: Validation loss decreased (0.168319 --> 0.167233).  Saving model ...
	 Train_Loss: 0.2026 Train_Acc: 93.215 Val_Loss: 0.1672  BEST VAL Loss: 0.1672  Val_Acc: 94.249

Epoch 22: Validation loss decreased (0.167233 --> 0.166299).  Saving model ...
	 Train_Loss: 0.2012 Train_Acc: 93.193 Val_Loss: 0.1663  BEST VAL Loss: 0.1663  Val_Acc: 94.175

Epoch 23: Validation loss decreased (0.166299 --> 0.165337).  Saving model ...
	 Train_Loss: 0.1999 Train_Acc: 93.237 Val_Loss: 0.1653  BEST VAL Loss: 0.1653  Val_Acc: 94.303

Epoch 24: Validation loss decreased (0.165337 --> 0.164423).  Saving model ...
	 Train_Loss: 0.1986 Train_Acc: 93.358 Val_Loss: 0.1644  BEST VAL Loss: 0.1644  Val_Acc: 94.496

Epoch 25: Validation loss decreased (0.164423 --> 0.163544).  Saving model ...
	 Train_Loss: 0.1973 Train_Acc: 93.287 Val_Loss: 0.1635  BEST VAL Loss: 0.1635  Val_Acc: 94.411

Epoch 26: Validation loss decreased (0.163544 --> 0.162695).  Saving model ...
	 Train_Loss: 0.1962 Train_Acc: 93.319 Val_Loss: 0.1627  BEST VAL Loss: 0.1627  Val_Acc: 94.407

Epoch 27: Validation loss decreased (0.162695 --> 0.161923).  Saving model ...
	 Train_Loss: 0.1951 Train_Acc: 93.393 Val_Loss: 0.1619  BEST VAL Loss: 0.1619  Val_Acc: 94.338

Epoch 28: Validation loss decreased (0.161923 --> 0.161202).  Saving model ...
	 Train_Loss: 0.1940 Train_Acc: 93.356 Val_Loss: 0.1612  BEST VAL Loss: 0.1612  Val_Acc: 94.461

Epoch 29: Validation loss decreased (0.161202 --> 0.160481).  Saving model ...
	 Train_Loss: 0.1930 Train_Acc: 93.379 Val_Loss: 0.1605  BEST VAL Loss: 0.1605  Val_Acc: 94.454

Epoch 30: Validation loss decreased (0.160481 --> 0.159779).  Saving model ...
	 Train_Loss: 0.1921 Train_Acc: 93.446 Val_Loss: 0.1598  BEST VAL Loss: 0.1598  Val_Acc: 94.558

Epoch 31: Validation loss decreased (0.159779 --> 0.159143).  Saving model ...
	 Train_Loss: 0.1911 Train_Acc: 93.453 Val_Loss: 0.1591  BEST VAL Loss: 0.1591  Val_Acc: 94.639

Epoch 32: Validation loss decreased (0.159143 --> 0.158581).  Saving model ...
	 Train_Loss: 0.1903 Train_Acc: 93.518 Val_Loss: 0.1586  BEST VAL Loss: 0.1586  Val_Acc: 94.492

Epoch 33: Validation loss decreased (0.158581 --> 0.157994).  Saving model ...
	 Train_Loss: 0.1894 Train_Acc: 93.542 Val_Loss: 0.1580  BEST VAL Loss: 0.1580  Val_Acc: 94.589

Epoch 34: Validation loss decreased (0.157994 --> 0.157485).  Saving model ...
	 Train_Loss: 0.1886 Train_Acc: 93.552 Val_Loss: 0.1575  BEST VAL Loss: 0.1575  Val_Acc: 94.620

Epoch 35: Validation loss decreased (0.157485 --> 0.156970).  Saving model ...
	 Train_Loss: 0.1878 Train_Acc: 93.506 Val_Loss: 0.1570  BEST VAL Loss: 0.1570  Val_Acc: 94.573

Epoch 36: Validation loss decreased (0.156970 --> 0.156437).  Saving model ...
	 Train_Loss: 0.1871 Train_Acc: 93.525 Val_Loss: 0.1564  BEST VAL Loss: 0.1564  Val_Acc: 94.446

Epoch 37: Validation loss decreased (0.156437 --> 0.155981).  Saving model ...
	 Train_Loss: 0.1864 Train_Acc: 93.542 Val_Loss: 0.1560  BEST VAL Loss: 0.1560  Val_Acc: 94.558

Epoch 38: Validation loss decreased (0.155981 --> 0.155503).  Saving model ...
	 Train_Loss: 0.1857 Train_Acc: 93.534 Val_Loss: 0.1555  BEST VAL Loss: 0.1555  Val_Acc: 94.570

Epoch 39: Validation loss decreased (0.155503 --> 0.155115).  Saving model ...
	 Train_Loss: 0.1850 Train_Acc: 93.613 Val_Loss: 0.1551  BEST VAL Loss: 0.1551  Val_Acc: 94.496

Epoch 40: Validation loss decreased (0.155115 --> 0.154719).  Saving model ...
	 Train_Loss: 0.1844 Train_Acc: 93.477 Val_Loss: 0.1547  BEST VAL Loss: 0.1547  Val_Acc: 94.643

Epoch 41: Validation loss decreased (0.154719 --> 0.154319).  Saving model ...
	 Train_Loss: 0.1838 Train_Acc: 93.560 Val_Loss: 0.1543  BEST VAL Loss: 0.1543  Val_Acc: 94.713

Epoch 42: Validation loss decreased (0.154319 --> 0.153928).  Saving model ...
	 Train_Loss: 0.1832 Train_Acc: 93.597 Val_Loss: 0.1539  BEST VAL Loss: 0.1539  Val_Acc: 94.740

Epoch 43: Validation loss decreased (0.153928 --> 0.153555).  Saving model ...
	 Train_Loss: 0.1826 Train_Acc: 93.650 Val_Loss: 0.1536  BEST VAL Loss: 0.1536  Val_Acc: 94.709

Epoch 44: Validation loss decreased (0.153555 --> 0.153224).  Saving model ...
	 Train_Loss: 0.1821 Train_Acc: 93.646 Val_Loss: 0.1532  BEST VAL Loss: 0.1532  Val_Acc: 94.670

Epoch 45: Validation loss decreased (0.153224 --> 0.152877).  Saving model ...
	 Train_Loss: 0.1815 Train_Acc: 93.686 Val_Loss: 0.1529  BEST VAL Loss: 0.1529  Val_Acc: 94.709

Epoch 46: Validation loss decreased (0.152877 --> 0.152515).  Saving model ...
	 Train_Loss: 0.1810 Train_Acc: 93.628 Val_Loss: 0.1525  BEST VAL Loss: 0.1525  Val_Acc: 94.570

Epoch 47: Validation loss decreased (0.152515 --> 0.152178).  Saving model ...
	 Train_Loss: 0.1805 Train_Acc: 93.678 Val_Loss: 0.1522  BEST VAL Loss: 0.1522  Val_Acc: 94.686

Epoch 48: Validation loss decreased (0.152178 --> 0.151928).  Saving model ...
	 Train_Loss: 0.1800 Train_Acc: 93.677 Val_Loss: 0.1519  BEST VAL Loss: 0.1519  Val_Acc: 94.643

Epoch 49: Validation loss decreased (0.151928 --> 0.151615).  Saving model ...
	 Train_Loss: 0.1795 Train_Acc: 93.687 Val_Loss: 0.1516  BEST VAL Loss: 0.1516  Val_Acc: 94.871

Epoch 50: Validation loss decreased (0.151615 --> 0.151284).  Saving model ...
	 Train_Loss: 0.1790 Train_Acc: 93.684 Val_Loss: 0.1513  BEST VAL Loss: 0.1513  Val_Acc: 94.813

Epoch 51: Validation loss decreased (0.151284 --> 0.151099).  Saving model ...
	 Train_Loss: 0.1786 Train_Acc: 93.728 Val_Loss: 0.1511  BEST VAL Loss: 0.1511  Val_Acc: 94.678

Epoch 52: Validation loss decreased (0.151099 --> 0.150764).  Saving model ...
	 Train_Loss: 0.1781 Train_Acc: 93.739 Val_Loss: 0.1508  BEST VAL Loss: 0.1508  Val_Acc: 94.914

Epoch 53: Validation loss decreased (0.150764 --> 0.150445).  Saving model ...
	 Train_Loss: 0.1777 Train_Acc: 93.752 Val_Loss: 0.1504  BEST VAL Loss: 0.1504  Val_Acc: 94.844

Epoch 54: Validation loss decreased (0.150445 --> 0.150130).  Saving model ...
	 Train_Loss: 0.1772 Train_Acc: 93.747 Val_Loss: 0.1501  BEST VAL Loss: 0.1501  Val_Acc: 94.914

Epoch 55: Validation loss decreased (0.150130 --> 0.149959).  Saving model ...
	 Train_Loss: 0.1768 Train_Acc: 93.845 Val_Loss: 0.1500  BEST VAL Loss: 0.1500  Val_Acc: 94.659

Epoch 56: Validation loss decreased (0.149959 --> 0.149683).  Saving model ...
	 Train_Loss: 0.1764 Train_Acc: 93.748 Val_Loss: 0.1497  BEST VAL Loss: 0.1497  Val_Acc: 94.817

Epoch 57: Validation loss decreased (0.149683 --> 0.149438).  Saving model ...
	 Train_Loss: 0.1760 Train_Acc: 93.717 Val_Loss: 0.1494  BEST VAL Loss: 0.1494  Val_Acc: 94.809

Epoch 58: Validation loss decreased (0.149438 --> 0.149213).  Saving model ...
	 Train_Loss: 0.1756 Train_Acc: 93.801 Val_Loss: 0.1492  BEST VAL Loss: 0.1492  Val_Acc: 94.813

Epoch 59: Validation loss decreased (0.149213 --> 0.148986).  Saving model ...
	 Train_Loss: 0.1752 Train_Acc: 93.775 Val_Loss: 0.1490  BEST VAL Loss: 0.1490  Val_Acc: 94.802

Epoch 60: Validation loss decreased (0.148986 --> 0.148782).  Saving model ...
	 Train_Loss: 0.1749 Train_Acc: 93.824 Val_Loss: 0.1488  BEST VAL Loss: 0.1488  Val_Acc: 94.678

Epoch 61: Validation loss decreased (0.148782 --> 0.148559).  Saving model ...
	 Train_Loss: 0.1745 Train_Acc: 93.854 Val_Loss: 0.1486  BEST VAL Loss: 0.1486  Val_Acc: 94.883

Epoch 62: Validation loss decreased (0.148559 --> 0.148354).  Saving model ...
	 Train_Loss: 0.1741 Train_Acc: 93.776 Val_Loss: 0.1484  BEST VAL Loss: 0.1484  Val_Acc: 94.817

Epoch 63: Validation loss decreased (0.148354 --> 0.148143).  Saving model ...
	 Train_Loss: 0.1738 Train_Acc: 93.799 Val_Loss: 0.1481  BEST VAL Loss: 0.1481  Val_Acc: 94.693

Epoch 64: Validation loss decreased (0.148143 --> 0.147907).  Saving model ...
	 Train_Loss: 0.1734 Train_Acc: 93.898 Val_Loss: 0.1479  BEST VAL Loss: 0.1479  Val_Acc: 94.975

Epoch 65: Validation loss decreased (0.147907 --> 0.147679).  Saving model ...
	 Train_Loss: 0.1731 Train_Acc: 93.837 Val_Loss: 0.1477  BEST VAL Loss: 0.1477  Val_Acc: 94.883

Epoch 66: Validation loss decreased (0.147679 --> 0.147474).  Saving model ...
	 Train_Loss: 0.1728 Train_Acc: 93.745 Val_Loss: 0.1475  BEST VAL Loss: 0.1475  Val_Acc: 94.863

Epoch 67: Validation loss decreased (0.147474 --> 0.147293).  Saving model ...
	 Train_Loss: 0.1725 Train_Acc: 93.868 Val_Loss: 0.1473  BEST VAL Loss: 0.1473  Val_Acc: 94.802

Epoch 68: Validation loss decreased (0.147293 --> 0.147068).  Saving model ...
	 Train_Loss: 0.1721 Train_Acc: 93.889 Val_Loss: 0.1471  BEST VAL Loss: 0.1471  Val_Acc: 95.045

Epoch 69: Validation loss decreased (0.147068 --> 0.146877).  Saving model ...
	 Train_Loss: 0.1718 Train_Acc: 93.931 Val_Loss: 0.1469  BEST VAL Loss: 0.1469  Val_Acc: 94.937

Epoch 70: Validation loss decreased (0.146877 --> 0.146666).  Saving model ...
	 Train_Loss: 0.1715 Train_Acc: 93.909 Val_Loss: 0.1467  BEST VAL Loss: 0.1467  Val_Acc: 94.887

Epoch 71: Validation loss decreased (0.146666 --> 0.146473).  Saving model ...
	 Train_Loss: 0.1712 Train_Acc: 93.878 Val_Loss: 0.1465  BEST VAL Loss: 0.1465  Val_Acc: 94.917

Epoch 72: Validation loss decreased (0.146473 --> 0.146292).  Saving model ...
	 Train_Loss: 0.1709 Train_Acc: 93.964 Val_Loss: 0.1463  BEST VAL Loss: 0.1463  Val_Acc: 94.832

Epoch 73: Validation loss decreased (0.146292 --> 0.146113).  Saving model ...
	 Train_Loss: 0.1706 Train_Acc: 93.823 Val_Loss: 0.1461  BEST VAL Loss: 0.1461  Val_Acc: 94.894

Epoch 74: Validation loss decreased (0.146113 --> 0.145938).  Saving model ...
	 Train_Loss: 0.1704 Train_Acc: 93.893 Val_Loss: 0.1459  BEST VAL Loss: 0.1459  Val_Acc: 94.875

Epoch 75: Validation loss decreased (0.145938 --> 0.145763).  Saving model ...
	 Train_Loss: 0.1701 Train_Acc: 93.946 Val_Loss: 0.1458  BEST VAL Loss: 0.1458  Val_Acc: 94.914

Epoch 76: Validation loss decreased (0.145763 --> 0.145574).  Saving model ...
	 Train_Loss: 0.1698 Train_Acc: 93.990 Val_Loss: 0.1456  BEST VAL Loss: 0.1456  Val_Acc: 94.968

Epoch 77: Validation loss decreased (0.145574 --> 0.145389).  Saving model ...
	 Train_Loss: 0.1695 Train_Acc: 93.958 Val_Loss: 0.1454  BEST VAL Loss: 0.1454  Val_Acc: 95.068

Epoch 78: Validation loss decreased (0.145389 --> 0.145230).  Saving model ...
	 Train_Loss: 0.1693 Train_Acc: 93.910 Val_Loss: 0.1452  BEST VAL Loss: 0.1452  Val_Acc: 94.871

Epoch 79: Validation loss decreased (0.145230 --> 0.145074).  Saving model ...
	 Train_Loss: 0.1690 Train_Acc: 93.950 Val_Loss: 0.1451  BEST VAL Loss: 0.1451  Val_Acc: 94.925

Epoch 80: Validation loss decreased (0.145074 --> 0.144893).  Saving model ...
	 Train_Loss: 0.1688 Train_Acc: 93.935 Val_Loss: 0.1449  BEST VAL Loss: 0.1449  Val_Acc: 95.072

Epoch 81: Validation loss decreased (0.144893 --> 0.144743).  Saving model ...
	 Train_Loss: 0.1685 Train_Acc: 93.892 Val_Loss: 0.1447  BEST VAL Loss: 0.1447  Val_Acc: 94.956

Epoch 82: Validation loss decreased (0.144743 --> 0.144576).  Saving model ...
	 Train_Loss: 0.1683 Train_Acc: 93.987 Val_Loss: 0.1446  BEST VAL Loss: 0.1446  Val_Acc: 95.134

Epoch 83: Validation loss decreased (0.144576 --> 0.144452).  Saving model ...
	 Train_Loss: 0.1680 Train_Acc: 93.930 Val_Loss: 0.1445  BEST VAL Loss: 0.1445  Val_Acc: 95.091

Epoch 84: Validation loss decreased (0.144452 --> 0.144290).  Saving model ...
	 Train_Loss: 0.1678 Train_Acc: 93.981 Val_Loss: 0.1443  BEST VAL Loss: 0.1443  Val_Acc: 94.995

Epoch 85: Validation loss decreased (0.144290 --> 0.144120).  Saving model ...
	 Train_Loss: 0.1675 Train_Acc: 93.978 Val_Loss: 0.1441  BEST VAL Loss: 0.1441  Val_Acc: 95.033

Epoch 86: Validation loss decreased (0.144120 --> 0.144006).  Saving model ...
	 Train_Loss: 0.1673 Train_Acc: 93.976 Val_Loss: 0.1440  BEST VAL Loss: 0.1440  Val_Acc: 94.860

Epoch 87: Validation loss decreased (0.144006 --> 0.143856).  Saving model ...
	 Train_Loss: 0.1671 Train_Acc: 93.964 Val_Loss: 0.1439  BEST VAL Loss: 0.1439  Val_Acc: 95.103

Epoch 88: Validation loss decreased (0.143856 --> 0.143691).  Saving model ...
	 Train_Loss: 0.1669 Train_Acc: 93.923 Val_Loss: 0.1437  BEST VAL Loss: 0.1437  Val_Acc: 95.091

Epoch 89: Validation loss decreased (0.143691 --> 0.143636).  Saving model ...
	 Train_Loss: 0.1666 Train_Acc: 94.000 Val_Loss: 0.1436  BEST VAL Loss: 0.1436  Val_Acc: 94.921

Epoch 90: Validation loss decreased (0.143636 --> 0.143485).  Saving model ...
	 Train_Loss: 0.1664 Train_Acc: 94.013 Val_Loss: 0.1435  BEST VAL Loss: 0.1435  Val_Acc: 95.060

Epoch 91: Validation loss decreased (0.143485 --> 0.143319).  Saving model ...
	 Train_Loss: 0.1662 Train_Acc: 94.009 Val_Loss: 0.1433  BEST VAL Loss: 0.1433  Val_Acc: 95.107

Epoch 92: Validation loss decreased (0.143319 --> 0.143188).  Saving model ...
	 Train_Loss: 0.1660 Train_Acc: 94.010 Val_Loss: 0.1432  BEST VAL Loss: 0.1432  Val_Acc: 95.084

Epoch 93: Validation loss decreased (0.143188 --> 0.143050).  Saving model ...
	 Train_Loss: 0.1658 Train_Acc: 94.028 Val_Loss: 0.1430  BEST VAL Loss: 0.1430  Val_Acc: 95.153

Epoch 94: Validation loss decreased (0.143050 --> 0.142898).  Saving model ...
	 Train_Loss: 0.1656 Train_Acc: 94.017 Val_Loss: 0.1429  BEST VAL Loss: 0.1429  Val_Acc: 95.219

Epoch 95: Validation loss decreased (0.142898 --> 0.142767).  Saving model ...
	 Train_Loss: 0.1654 Train_Acc: 93.999 Val_Loss: 0.1428  BEST VAL Loss: 0.1428  Val_Acc: 94.983

Epoch 96: Validation loss decreased (0.142767 --> 0.142615).  Saving model ...
	 Train_Loss: 0.1652 Train_Acc: 94.023 Val_Loss: 0.1426  BEST VAL Loss: 0.1426  Val_Acc: 95.180

Epoch 97: Validation loss decreased (0.142615 --> 0.142473).  Saving model ...
	 Train_Loss: 0.1650 Train_Acc: 94.056 Val_Loss: 0.1425  BEST VAL Loss: 0.1425  Val_Acc: 95.180

Epoch 98: Validation loss decreased (0.142473 --> 0.142364).  Saving model ...
	 Train_Loss: 0.1648 Train_Acc: 94.039 Val_Loss: 0.1424  BEST VAL Loss: 0.1424  Val_Acc: 95.003

Epoch 99: Validation loss decreased (0.142364 --> 0.142228).  Saving model ...
	 Train_Loss: 0.1646 Train_Acc: 94.075 Val_Loss: 0.1422  BEST VAL Loss: 0.1422  Val_Acc: 95.126

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.47      0.47     97754
           1       0.53      0.53      0.53    109228

    accuracy                           0.50    206982
   macro avg       0.50      0.50      0.50    206982
weighted avg       0.50      0.50      0.50    206982

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.47      0.47     12219
           1       0.53      0.53      0.53     13654

    accuracy                           0.50     25873
   macro avg       0.50      0.50      0.50     25873
weighted avg       0.50      0.50      0.50     25873

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.47      0.47     12219
           1       0.53      0.53      0.53     13654

    accuracy                           0.50     25873
   macro avg       0.50      0.50      0.50     25873
weighted avg       0.50      0.50      0.50     25873

              precision    recall  f1-score   support

           0       0.47      0.47      0.47     12219
           1       0.53      0.53      0.53     13654

    accuracy                           0.50     25873
   macro avg       0.50      0.50      0.50     25873
weighted avg       0.50      0.50      0.50     25873

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.40      0.44     37243
           1       0.50      0.61      0.55     37725

    accuracy                           0.50     74968
   macro avg       0.50      0.50      0.50     74968
weighted avg       0.50      0.50      0.50     74968

              precision    recall  f1-score   support

           0       0.50      0.40      0.44     37243
           1       0.50      0.61      0.55     37725

    accuracy                           0.50     74968
   macro avg       0.50      0.50      0.50     74968
weighted avg       0.50      0.50      0.50     74968

completed
