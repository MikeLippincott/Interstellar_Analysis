[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 18688 bytes to train_binary_model.py
[NbConvertApp] Converting notebook ../notebooks/train_multiclass_model.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: MissingIDFieldWarning: Code cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.
  validate(nb)
[NbConvertApp] Writing 31143 bytes to train_multiclass_model.py
[NbConvertApp] Converting notebook ../notebooks/train_regression_model.ipynb to script
[NbConvertApp] Writing 25120 bytes to train_regression_model.py
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:314: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels.drop_duplicates(inplace=True)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1015: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1016: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1015: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1016: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1036: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:578: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:652: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1219: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:880: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1219: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:1096: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
SHSY5Y MultiClass_MLP_h202_remove True
[0.954878893196544, 0.4803479499984947, 0.5647731568049614]
Data Subset Is Off
(156754,) (39189,) (230445,) (144614,)
(156754,) (39189,) (230445,) (144614,)
571002
(7972,) (85003,) (63779,)
(1993,) (21251,) (15945,)
(9965,) (106254,) (114226,)
(7048,) (71293,) (66273,)
(156754, 1251) (39189, 1251) (230445, 1251) (144614, 1251)
(156754,) (39189,) (230445,) (144614,)
Number of in features:  1251
Number of out features:  3
Multi_Class
SGD
Epoch 0: Validation loss decreased (inf --> 0.615915).  Saving model ...
	 Train_Loss: 0.6804 Train_Acc: 68.433 Val_Loss: 0.6159  BEST VAL Loss: 0.6159  Val_Acc: 71.428

Epoch 1: Validation loss decreased (0.615915 --> 0.602214).  Saving model ...
	 Train_Loss: 0.6540 Train_Acc: 70.495 Val_Loss: 0.6022  BEST VAL Loss: 0.6022  Val_Acc: 72.097

Epoch 2: Validation loss decreased (0.602214 --> 0.594080).  Saving model ...
	 Train_Loss: 0.6392 Train_Acc: 71.106 Val_Loss: 0.5941  BEST VAL Loss: 0.5941  Val_Acc: 72.196

Epoch 3: Validation loss decreased (0.594080 --> 0.587092).  Saving model ...
	 Train_Loss: 0.6290 Train_Acc: 71.700 Val_Loss: 0.5871  BEST VAL Loss: 0.5871  Val_Acc: 73.038

Epoch 4: Validation loss decreased (0.587092 --> 0.582466).  Saving model ...
	 Train_Loss: 0.6209 Train_Acc: 72.024 Val_Loss: 0.5825  BEST VAL Loss: 0.5825  Val_Acc: 72.949

Epoch 5: Validation loss decreased (0.582466 --> 0.579122).  Saving model ...
	 Train_Loss: 0.6144 Train_Acc: 72.327 Val_Loss: 0.5791  BEST VAL Loss: 0.5791  Val_Acc: 72.870

Epoch 6: Validation loss decreased (0.579122 --> 0.577539).  Saving model ...
	 Train_Loss: 0.6088 Train_Acc: 72.600 Val_Loss: 0.5775  BEST VAL Loss: 0.5775  Val_Acc: 73.454

Epoch 7: Validation loss decreased (0.577539 --> 0.575754).  Saving model ...
	 Train_Loss: 0.6041 Train_Acc: 72.853 Val_Loss: 0.5758  BEST VAL Loss: 0.5758  Val_Acc: 73.679

Epoch 8: Validation loss decreased (0.575754 --> 0.574009).  Saving model ...
	 Train_Loss: 0.6001 Train_Acc: 73.012 Val_Loss: 0.5740  BEST VAL Loss: 0.5740  Val_Acc: 73.128

Epoch 9: Validation loss decreased (0.574009 --> 0.571566).  Saving model ...
	 Train_Loss: 0.5964 Train_Acc: 73.077 Val_Loss: 0.5716  BEST VAL Loss: 0.5716  Val_Acc: 74.235

Epoch 10: Validation loss decreased (0.571566 --> 0.569746).  Saving model ...
	 Train_Loss: 0.5930 Train_Acc: 73.257 Val_Loss: 0.5697  BEST VAL Loss: 0.5697  Val_Acc: 74.123

Epoch 11: Validation loss decreased (0.569746 --> 0.567603).  Saving model ...
	 Train_Loss: 0.5899 Train_Acc: 73.368 Val_Loss: 0.5676  BEST VAL Loss: 0.5676  Val_Acc: 74.230

Epoch 12: Validation loss decreased (0.567603 --> 0.565660).  Saving model ...
	 Train_Loss: 0.5872 Train_Acc: 73.661 Val_Loss: 0.5657  BEST VAL Loss: 0.5657  Val_Acc: 74.141

Epoch 13: Validation loss decreased (0.565660 --> 0.564278).  Saving model ...
	 Train_Loss: 0.5845 Train_Acc: 73.661 Val_Loss: 0.5643  BEST VAL Loss: 0.5643  Val_Acc: 74.554

Epoch 14: Validation loss decreased (0.564278 --> 0.563163).  Saving model ...
	 Train_Loss: 0.5820 Train_Acc: 73.703 Val_Loss: 0.5632  BEST VAL Loss: 0.5632  Val_Acc: 74.585

Epoch 15: Validation loss decreased (0.563163 --> 0.561949).  Saving model ...
	 Train_Loss: 0.5798 Train_Acc: 73.851 Val_Loss: 0.5619  BEST VAL Loss: 0.5619  Val_Acc: 74.447

Epoch 16: Validation loss decreased (0.561949 --> 0.560587).  Saving model ...
	 Train_Loss: 0.5777 Train_Acc: 73.927 Val_Loss: 0.5606  BEST VAL Loss: 0.5606  Val_Acc: 74.832

Epoch 17: Validation loss decreased (0.560587 --> 0.559890).  Saving model ...
	 Train_Loss: 0.5757 Train_Acc: 74.050 Val_Loss: 0.5599  BEST VAL Loss: 0.5599  Val_Acc: 74.296

Epoch 18: Validation loss decreased (0.559890 --> 0.559337).  Saving model ...
	 Train_Loss: 0.5738 Train_Acc: 74.152 Val_Loss: 0.5593  BEST VAL Loss: 0.5593  Val_Acc: 73.087

Epoch 19: Validation loss decreased (0.559337 --> 0.558285).  Saving model ...
	 Train_Loss: 0.5721 Train_Acc: 74.015 Val_Loss: 0.5583  BEST VAL Loss: 0.5583  Val_Acc: 74.679

Epoch 20: Validation loss decreased (0.558285 --> 0.557444).  Saving model ...
	 Train_Loss: 0.5705 Train_Acc: 74.200 Val_Loss: 0.5574  BEST VAL Loss: 0.5574  Val_Acc: 74.603

Epoch 21: Validation loss decreased (0.557444 --> 0.556684).  Saving model ...
	 Train_Loss: 0.5689 Train_Acc: 74.424 Val_Loss: 0.5567  BEST VAL Loss: 0.5567  Val_Acc: 74.358

Epoch 22: Validation loss decreased (0.556684 --> 0.556036).  Saving model ...
	 Train_Loss: 0.5674 Train_Acc: 74.353 Val_Loss: 0.5560  BEST VAL Loss: 0.5560  Val_Acc: 74.204

Epoch 23: Validation loss decreased (0.556036 --> 0.555400).  Saving model ...
	 Train_Loss: 0.5659 Train_Acc: 74.485 Val_Loss: 0.5554  BEST VAL Loss: 0.5554  Val_Acc: 74.779

Epoch 24: Validation loss decreased (0.555400 --> 0.554864).  Saving model ...
	 Train_Loss: 0.5645 Train_Acc: 74.457 Val_Loss: 0.5549  BEST VAL Loss: 0.5549  Val_Acc: 74.827

Epoch 25: Validation loss decreased (0.554864 --> 0.554498).  Saving model ...
	 Train_Loss: 0.5632 Train_Acc: 74.472 Val_Loss: 0.5545  BEST VAL Loss: 0.5545  Val_Acc: 73.385

Epoch 26: Validation loss decreased (0.554498 --> 0.554069).  Saving model ...
	 Train_Loss: 0.5620 Train_Acc: 74.494 Val_Loss: 0.5541  BEST VAL Loss: 0.5541  Val_Acc: 74.911

Epoch 27: Validation loss decreased (0.554069 --> 0.553448).  Saving model ...
	 Train_Loss: 0.5608 Train_Acc: 74.530 Val_Loss: 0.5534  BEST VAL Loss: 0.5534  Val_Acc: 74.911

Epoch 28: Validation loss decreased (0.553448 --> 0.553291).  Saving model ...
	 Train_Loss: 0.5596 Train_Acc: 74.583 Val_Loss: 0.5533  BEST VAL Loss: 0.5533  Val_Acc: 74.911

Epoch 29: Validation loss decreased (0.553291 --> 0.552971).  Saving model ...
	 Train_Loss: 0.5585 Train_Acc: 74.618 Val_Loss: 0.5530  BEST VAL Loss: 0.5530  Val_Acc: 74.840

Epoch 30: Validation loss decreased (0.552971 --> 0.552626).  Saving model ...
	 Train_Loss: 0.5574 Train_Acc: 74.649 Val_Loss: 0.5526  BEST VAL Loss: 0.5526  Val_Acc: 74.978

Epoch 31: Validation loss decreased (0.552626 --> 0.552619).  Saving model ...
	 Train_Loss: 0.5564 Train_Acc: 74.713 Val_Loss: 0.5526  BEST VAL Loss: 0.5526  Val_Acc: 73.304

Epoch 32: Validation loss decreased (0.552619 --> 0.552485).  Saving model ...
	 Train_Loss: 0.5553 Train_Acc: 74.865 Val_Loss: 0.5525  BEST VAL Loss: 0.5525  Val_Acc: 75.159

Epoch 33: Validation loss decreased (0.552485 --> 0.552207).  Saving model ...
	 Train_Loss: 0.5544 Train_Acc: 74.968 Val_Loss: 0.5522  BEST VAL Loss: 0.5522  Val_Acc: 74.996

Epoch 34: Validation loss decreased (0.552207 --> 0.551999).  Saving model ...
	 Train_Loss: 0.5534 Train_Acc: 74.839 Val_Loss: 0.5520  BEST VAL Loss: 0.5520  Val_Acc: 75.013

Epoch 35: Validation loss decreased (0.551999 --> 0.551654).  Saving model ...
	 Train_Loss: 0.5524 Train_Acc: 74.903 Val_Loss: 0.5517  BEST VAL Loss: 0.5517  Val_Acc: 75.029

Epoch 36: Validation loss decreased (0.551654 --> 0.551535).  Saving model ...
	 Train_Loss: 0.5515 Train_Acc: 74.932 Val_Loss: 0.5515  BEST VAL Loss: 0.5515  Val_Acc: 74.319

Epoch 37: Validation loss decreased (0.551535 --> 0.551449).  Saving model ...
	 Train_Loss: 0.5507 Train_Acc: 74.997 Val_Loss: 0.5514  BEST VAL Loss: 0.5514  Val_Acc: 74.934

Epoch 38: Validation loss decreased (0.551449 --> 0.551066).  Saving model ...
	 Train_Loss: 0.5499 Train_Acc: 74.993 Val_Loss: 0.5511  BEST VAL Loss: 0.5511  Val_Acc: 74.973

Epoch 39: Validation loss decreased (0.551066 --> 0.550945).  Saving model ...
	 Train_Loss: 0.5491 Train_Acc: 75.009 Val_Loss: 0.5509  BEST VAL Loss: 0.5509  Val_Acc: 75.041

Epoch 40: Validation loss decreased (0.550945 --> 0.550744).  Saving model ...
	 Train_Loss: 0.5483 Train_Acc: 75.043 Val_Loss: 0.5507  BEST VAL Loss: 0.5507  Val_Acc: 74.692

Epoch 41: Validation loss decreased (0.550744 --> 0.550509).  Saving model ...
	 Train_Loss: 0.5476 Train_Acc: 74.992 Val_Loss: 0.5505  BEST VAL Loss: 0.5505  Val_Acc: 75.172

Epoch 42: Validation loss decreased (0.550509 --> 0.550236).  Saving model ...
	 Train_Loss: 0.5468 Train_Acc: 75.164 Val_Loss: 0.5502  BEST VAL Loss: 0.5502  Val_Acc: 75.006

Epoch 43: Validation loss decreased (0.550236 --> 0.550031).  Saving model ...
	 Train_Loss: 0.5461 Train_Acc: 75.139 Val_Loss: 0.5500  BEST VAL Loss: 0.5500  Val_Acc: 75.021

Epoch 44: Validation loss decreased (0.550031 --> 0.550025).  Saving model ...
	 Train_Loss: 0.5454 Train_Acc: 75.187 Val_Loss: 0.5500  BEST VAL Loss: 0.5500  Val_Acc: 75.200

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.5447 Train_Acc: 75.173 Val_Loss: 0.5500  BEST VAL Loss: 0.5500  Val_Acc: 74.853

Epoch 46: Validation loss decreased (0.550025 --> 0.549863).  Saving model ...
	 Train_Loss: 0.5440 Train_Acc: 75.189 Val_Loss: 0.5499  BEST VAL Loss: 0.5499  Val_Acc: 75.133

Epoch 47: Validation loss decreased (0.549863 --> 0.549743).  Saving model ...
	 Train_Loss: 0.5433 Train_Acc: 75.337 Val_Loss: 0.5497  BEST VAL Loss: 0.5497  Val_Acc: 75.286

Epoch 48: Validation loss decreased (0.549743 --> 0.549654).  Saving model ...
	 Train_Loss: 0.5427 Train_Acc: 75.176 Val_Loss: 0.5497  BEST VAL Loss: 0.5497  Val_Acc: 75.123

Epoch 49: Validation loss decreased (0.549654 --> 0.549494).  Saving model ...
	 Train_Loss: 0.5421 Train_Acc: 75.252 Val_Loss: 0.5495  BEST VAL Loss: 0.5495  Val_Acc: 75.118

Epoch 50: Validation loss decreased (0.549494 --> 0.549432).  Saving model ...
	 Train_Loss: 0.5415 Train_Acc: 75.278 Val_Loss: 0.5494  BEST VAL Loss: 0.5494  Val_Acc: 74.478

Epoch 51: Validation loss decreased (0.549432 --> 0.549353).  Saving model ...
	 Train_Loss: 0.5409 Train_Acc: 75.203 Val_Loss: 0.5494  BEST VAL Loss: 0.5494  Val_Acc: 74.636

Epoch 52: Validation loss decreased (0.549353 --> 0.549216).  Saving model ...
	 Train_Loss: 0.5404 Train_Acc: 75.213 Val_Loss: 0.5492  BEST VAL Loss: 0.5492  Val_Acc: 74.656

Epoch 53: Validation loss decreased (0.549216 --> 0.549147).  Saving model ...
	 Train_Loss: 0.5398 Train_Acc: 75.499 Val_Loss: 0.5491  BEST VAL Loss: 0.5491  Val_Acc: 74.590

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.5393 Train_Acc: 75.260 Val_Loss: 0.5492  BEST VAL Loss: 0.5491  Val_Acc: 75.371

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.5387 Train_Acc: 75.316 Val_Loss: 0.5493  BEST VAL Loss: 0.5491  Val_Acc: 75.233

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.5382 Train_Acc: 75.445 Val_Loss: 0.5493  BEST VAL Loss: 0.5491  Val_Acc: 75.113

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.5377 Train_Acc: 75.456 Val_Loss: 0.5492  BEST VAL Loss: 0.5491  Val_Acc: 75.496

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.5372 Train_Acc: 75.418 Val_Loss: 0.5493  BEST VAL Loss: 0.5491  Val_Acc: 74.975

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.5367 Train_Acc: 75.402 Val_Loss: 0.5493  BEST VAL Loss: 0.5491  Val_Acc: 74.133

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.5362 Train_Acc: 75.427 Val_Loss: 0.5492  BEST VAL Loss: 0.5491  Val_Acc: 75.304

Epoch 61: Validation loss decreased (0.549147 --> 0.549111).  Saving model ...
	 Train_Loss: 0.5357 Train_Acc: 75.492 Val_Loss: 0.5491  BEST VAL Loss: 0.5491  Val_Acc: 75.149

Epoch 62: Validation loss decreased (0.549111 --> 0.549030).  Saving model ...
	 Train_Loss: 0.5352 Train_Acc: 75.625 Val_Loss: 0.5490  BEST VAL Loss: 0.5490  Val_Acc: 74.682

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.5348 Train_Acc: 75.599 Val_Loss: 0.5491  BEST VAL Loss: 0.5490  Val_Acc: 74.957

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.5343 Train_Acc: 75.474 Val_Loss: 0.5492  BEST VAL Loss: 0.5490  Val_Acc: 74.396

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.5339 Train_Acc: 75.698 Val_Loss: 0.5493  BEST VAL Loss: 0.5490  Val_Acc: 73.814

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.5334 Train_Acc: 75.680 Val_Loss: 0.5492  BEST VAL Loss: 0.5490  Val_Acc: 75.072

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.5330 Train_Acc: 75.691 Val_Loss: 0.5492  BEST VAL Loss: 0.5490  Val_Acc: 75.332

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.5325 Train_Acc: 75.787 Val_Loss: 0.5493  BEST VAL Loss: 0.5490  Val_Acc: 74.079

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.5321 Train_Acc: 75.612 Val_Loss: 0.5493  BEST VAL Loss: 0.5490  Val_Acc: 75.432

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.5317 Train_Acc: 75.685 Val_Loss: 0.5492  BEST VAL Loss: 0.5490  Val_Acc: 75.483

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.5313 Train_Acc: 75.774 Val_Loss: 0.5492  BEST VAL Loss: 0.5490  Val_Acc: 75.241

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.5309 Train_Acc: 75.556 Val_Loss: 0.5492  BEST VAL Loss: 0.5490  Val_Acc: 75.353

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.5305 Train_Acc: 75.839 Val_Loss: 0.5492  BEST VAL Loss: 0.5490  Val_Acc: 75.590

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.5301 Train_Acc: 75.814 Val_Loss: 0.5493  BEST VAL Loss: 0.5490  Val_Acc: 74.694

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.5298 Train_Acc: 75.782 Val_Loss: 0.5493  BEST VAL Loss: 0.5490  Val_Acc: 75.417

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.5294 Train_Acc: 75.985 Val_Loss: 0.5492  BEST VAL Loss: 0.5490  Val_Acc: 74.993

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.5290 Train_Acc: 75.725 Val_Loss: 0.5492  BEST VAL Loss: 0.5490  Val_Acc: 75.700

Epoch 78: Validation loss did not decrease
Early stopped at epoch : 78
MultiClass_MLP_h202_remove_shuffle
              precision    recall  f1-score   support

           0       0.05      0.05      0.05      7972
           1       0.54      0.55      0.55     85003
           2       0.41      0.40      0.40     63779

    accuracy                           0.47    156754
   macro avg       0.33      0.33      0.33    156754
weighted avg       0.46      0.47      0.46    156754

MultiClass_MLP_h202_remove_shuffle
              precision    recall  f1-score   support

           0       0.05      0.04      0.05      1993
           1       0.54      0.55      0.55     21251
           2       0.41      0.40      0.40     15945

    accuracy                           0.46     39189
   macro avg       0.33      0.33      0.33     39189
weighted avg       0.46      0.46      0.46     39189

MultiClass_MLP_h202_remove_shuffle
              precision    recall  f1-score   support

           0       0.04      0.04      0.04      9965
           1       0.46      0.53      0.49    106254
           2       0.50      0.43      0.46    114226

    accuracy                           0.46    230445
   macro avg       0.33      0.33      0.33    230445
weighted avg       0.46      0.46      0.46    230445

Precision for class 0: 0.04389456697149005
Recall for class 0: 0.04094330155544405
Precision for class 1: 0.46036226192813673
Recall for class 1: 0.5295894742786154
Precision for class 2: 0.49509694898805073
Recall for class 2: 0.42874652005672964
3
              precision    recall  f1-score   support

           0       0.04      0.04      0.04      9965
           1       0.46      0.53      0.49    106254
           2       0.50      0.43      0.46    114226

    accuracy                           0.46    230445
   macro avg       0.33      0.33      0.33    230445
weighted avg       0.46      0.46      0.46    230445

MultiClass_MLP_h202_remove_shuffle
              precision    recall  f1-score   support

           0       0.05      0.04      0.04      7048
           1       0.49      0.54      0.51     71293
           2       0.46      0.42      0.44     66273

    accuracy                           0.46    144614
   macro avg       0.33      0.33      0.33    144614
weighted avg       0.45      0.46      0.46    144614

Precision for class 0: 0.04682706281285322
Recall for class 0: 0.04114642451759364
Precision for class 1: 0.4917087423430812
Recall for class 1: 0.5382015064592597
Precision for class 2: 0.4583436832430821
Recall for class 2: 0.4176361414150559
3
              precision    recall  f1-score   support

           0       0.05      0.04      0.04      7048
           1       0.49      0.54      0.51     71293
           2       0.46      0.42      0.44     66273

    accuracy                           0.46    144614
   macro avg       0.33      0.33      0.33    144614
weighted avg       0.45      0.46      0.46    144614

Done
