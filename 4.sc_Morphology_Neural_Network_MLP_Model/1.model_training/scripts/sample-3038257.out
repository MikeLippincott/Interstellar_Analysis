[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1a3f97fb'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '182438d0'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ce4cac54'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e41af48e'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_0.010_DMSO_0.025 treatment_name: LPS_10.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_0.010_DMSO_0.025
TREATMENT_NAME: LPS_10.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_10.000_DMSO_0.025']
The dimensions of the data are: (299570, 1270)
Number of total missing values across all columns: 599140
Data Subset Is Off
Wells held out for testing: ['B08' 'E08']
Wells to use for training, validation, and testing ['B02' 'B03' 'B09' 'E02' 'E03' 'E09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.590774).  Saving model ...
	 Train_Loss: 0.6449 Train_Acc: 62.101 Val_Loss: 0.5908  BEST VAL Loss: 0.5908  Val_Acc: 68.778

Epoch 1: Validation loss decreased (0.590774 --> 0.571454).  Saving model ...
	 Train_Loss: 0.6165 Train_Acc: 68.055 Val_Loss: 0.5715  BEST VAL Loss: 0.5715  Val_Acc: 71.876

Epoch 2: Validation loss decreased (0.571454 --> 0.556856).  Saving model ...
	 Train_Loss: 0.5985 Train_Acc: 70.173 Val_Loss: 0.5569  BEST VAL Loss: 0.5569  Val_Acc: 73.205

Epoch 3: Validation loss decreased (0.556856 --> 0.545336).  Saving model ...
	 Train_Loss: 0.5861 Train_Acc: 71.201 Val_Loss: 0.5453  BEST VAL Loss: 0.5453  Val_Acc: 73.707

Epoch 4: Validation loss decreased (0.545336 --> 0.537184).  Saving model ...
	 Train_Loss: 0.5766 Train_Acc: 71.946 Val_Loss: 0.5372  BEST VAL Loss: 0.5372  Val_Acc: 74.439

Epoch 5: Validation loss decreased (0.537184 --> 0.530744).  Saving model ...
	 Train_Loss: 0.5693 Train_Acc: 72.367 Val_Loss: 0.5307  BEST VAL Loss: 0.5307  Val_Acc: 75.068

Epoch 6: Validation loss decreased (0.530744 --> 0.525209).  Saving model ...
	 Train_Loss: 0.5633 Train_Acc: 72.753 Val_Loss: 0.5252  BEST VAL Loss: 0.5252  Val_Acc: 75.307

Epoch 7: Validation loss decreased (0.525209 --> 0.520764).  Saving model ...
	 Train_Loss: 0.5584 Train_Acc: 73.003 Val_Loss: 0.5208  BEST VAL Loss: 0.5208  Val_Acc: 75.665

Epoch 8: Validation loss decreased (0.520764 --> 0.516740).  Saving model ...
	 Train_Loss: 0.5539 Train_Acc: 73.324 Val_Loss: 0.5167  BEST VAL Loss: 0.5167  Val_Acc: 75.642

Epoch 9: Validation loss decreased (0.516740 --> 0.513200).  Saving model ...
	 Train_Loss: 0.5501 Train_Acc: 73.556 Val_Loss: 0.5132  BEST VAL Loss: 0.5132  Val_Acc: 76.212

Epoch 10: Validation loss decreased (0.513200 --> 0.509971).  Saving model ...
	 Train_Loss: 0.5468 Train_Acc: 73.632 Val_Loss: 0.5100  BEST VAL Loss: 0.5100  Val_Acc: 76.031

Epoch 11: Validation loss decreased (0.509971 --> 0.507141).  Saving model ...
	 Train_Loss: 0.5439 Train_Acc: 73.848 Val_Loss: 0.5071  BEST VAL Loss: 0.5071  Val_Acc: 75.864

Epoch 12: Validation loss decreased (0.507141 --> 0.505104).  Saving model ...
	 Train_Loss: 0.5412 Train_Acc: 73.960 Val_Loss: 0.5051  BEST VAL Loss: 0.5051  Val_Acc: 75.936

Epoch 13: Validation loss decreased (0.505104 --> 0.502851).  Saving model ...
	 Train_Loss: 0.5387 Train_Acc: 74.123 Val_Loss: 0.5029  BEST VAL Loss: 0.5029  Val_Acc: 76.560

Epoch 14: Validation loss decreased (0.502851 --> 0.500802).  Saving model ...
	 Train_Loss: 0.5363 Train_Acc: 74.208 Val_Loss: 0.5008  BEST VAL Loss: 0.5008  Val_Acc: 76.361

Epoch 15: Validation loss decreased (0.500802 --> 0.498943).  Saving model ...
	 Train_Loss: 0.5344 Train_Acc: 74.208 Val_Loss: 0.4989  BEST VAL Loss: 0.4989  Val_Acc: 76.361

Epoch 16: Validation loss decreased (0.498943 --> 0.497636).  Saving model ...
	 Train_Loss: 0.5325 Train_Acc: 74.390 Val_Loss: 0.4976  BEST VAL Loss: 0.4976  Val_Acc: 75.850

Epoch 17: Validation loss decreased (0.497636 --> 0.495950).  Saving model ...
	 Train_Loss: 0.5308 Train_Acc: 74.296 Val_Loss: 0.4960  BEST VAL Loss: 0.4960  Val_Acc: 76.800

Epoch 18: Validation loss decreased (0.495950 --> 0.494370).  Saving model ...
	 Train_Loss: 0.5292 Train_Acc: 74.513 Val_Loss: 0.4944  BEST VAL Loss: 0.4944  Val_Acc: 76.542

Epoch 19: Validation loss decreased (0.494370 --> 0.493000).  Saving model ...
	 Train_Loss: 0.5277 Train_Acc: 74.508 Val_Loss: 0.4930  BEST VAL Loss: 0.4930  Val_Acc: 76.519

Epoch 20: Validation loss decreased (0.493000 --> 0.491845).  Saving model ...
	 Train_Loss: 0.5264 Train_Acc: 74.431 Val_Loss: 0.4918  BEST VAL Loss: 0.4918  Val_Acc: 76.872

Epoch 21: Validation loss decreased (0.491845 --> 0.490701).  Saving model ...
	 Train_Loss: 0.5250 Train_Acc: 74.621 Val_Loss: 0.4907  BEST VAL Loss: 0.4907  Val_Acc: 76.786

Epoch 22: Validation loss decreased (0.490701 --> 0.489481).  Saving model ...
	 Train_Loss: 0.5238 Train_Acc: 74.555 Val_Loss: 0.4895  BEST VAL Loss: 0.4895  Val_Acc: 77.062

Epoch 23: Validation loss decreased (0.489481 --> 0.488337).  Saving model ...
	 Train_Loss: 0.5227 Train_Acc: 74.576 Val_Loss: 0.4883  BEST VAL Loss: 0.4883  Val_Acc: 76.881

Epoch 24: Validation loss decreased (0.488337 --> 0.487369).  Saving model ...
	 Train_Loss: 0.5215 Train_Acc: 74.642 Val_Loss: 0.4874  BEST VAL Loss: 0.4874  Val_Acc: 77.157

Epoch 25: Validation loss decreased (0.487369 --> 0.486403).  Saving model ...
	 Train_Loss: 0.5205 Train_Acc: 74.709 Val_Loss: 0.4864  BEST VAL Loss: 0.4864  Val_Acc: 77.030

Epoch 26: Validation loss decreased (0.486403 --> 0.485403).  Saving model ...
	 Train_Loss: 0.5195 Train_Acc: 74.694 Val_Loss: 0.4854  BEST VAL Loss: 0.4854  Val_Acc: 77.324

Epoch 27: Validation loss decreased (0.485403 --> 0.484468).  Saving model ...
	 Train_Loss: 0.5185 Train_Acc: 74.770 Val_Loss: 0.4845  BEST VAL Loss: 0.4845  Val_Acc: 77.112

Epoch 28: Validation loss decreased (0.484468 --> 0.483514).  Saving model ...
	 Train_Loss: 0.5176 Train_Acc: 74.751 Val_Loss: 0.4835  BEST VAL Loss: 0.4835  Val_Acc: 77.207

Epoch 29: Validation loss decreased (0.483514 --> 0.482739).  Saving model ...
	 Train_Loss: 0.5168 Train_Acc: 74.902 Val_Loss: 0.4827  BEST VAL Loss: 0.4827  Val_Acc: 77.247

Epoch 30: Validation loss decreased (0.482739 --> 0.481982).  Saving model ...
	 Train_Loss: 0.5159 Train_Acc: 74.793 Val_Loss: 0.4820  BEST VAL Loss: 0.4820  Val_Acc: 77.112

Epoch 31: Validation loss decreased (0.481982 --> 0.481174).  Saving model ...
	 Train_Loss: 0.5151 Train_Acc: 74.936 Val_Loss: 0.4812  BEST VAL Loss: 0.4812  Val_Acc: 77.627

Epoch 32: Validation loss decreased (0.481174 --> 0.480408).  Saving model ...
	 Train_Loss: 0.5144 Train_Acc: 74.867 Val_Loss: 0.4804  BEST VAL Loss: 0.4804  Val_Acc: 77.202

Epoch 33: Validation loss decreased (0.480408 --> 0.479586).  Saving model ...
	 Train_Loss: 0.5136 Train_Acc: 74.956 Val_Loss: 0.4796  BEST VAL Loss: 0.4796  Val_Acc: 77.708

Epoch 34: Validation loss decreased (0.479586 --> 0.479048).  Saving model ...
	 Train_Loss: 0.5129 Train_Acc: 75.034 Val_Loss: 0.4790  BEST VAL Loss: 0.4790  Val_Acc: 77.202

Epoch 35: Validation loss decreased (0.479048 --> 0.478383).  Saving model ...
	 Train_Loss: 0.5122 Train_Acc: 74.876 Val_Loss: 0.4784  BEST VAL Loss: 0.4784  Val_Acc: 77.392

Epoch 36: Validation loss decreased (0.478383 --> 0.477735).  Saving model ...
	 Train_Loss: 0.5116 Train_Acc: 74.930 Val_Loss: 0.4777  BEST VAL Loss: 0.4777  Val_Acc: 77.143

Epoch 37: Validation loss decreased (0.477735 --> 0.477033).  Saving model ...
	 Train_Loss: 0.5109 Train_Acc: 74.943 Val_Loss: 0.4770  BEST VAL Loss: 0.4770  Val_Acc: 77.763

Epoch 38: Validation loss decreased (0.477033 --> 0.476456).  Saving model ...
	 Train_Loss: 0.5104 Train_Acc: 74.923 Val_Loss: 0.4765  BEST VAL Loss: 0.4765  Val_Acc: 77.410

Epoch 39: Validation loss decreased (0.476456 --> 0.475830).  Saving model ...
	 Train_Loss: 0.5098 Train_Acc: 74.993 Val_Loss: 0.4758  BEST VAL Loss: 0.4758  Val_Acc: 77.613

Epoch 40: Validation loss decreased (0.475830 --> 0.475133).  Saving model ...
	 Train_Loss: 0.5092 Train_Acc: 75.107 Val_Loss: 0.4751  BEST VAL Loss: 0.4751  Val_Acc: 77.867

Epoch 41: Validation loss decreased (0.475133 --> 0.474622).  Saving model ...
	 Train_Loss: 0.5087 Train_Acc: 75.029 Val_Loss: 0.4746  BEST VAL Loss: 0.4746  Val_Acc: 77.627

Epoch 42: Validation loss decreased (0.474622 --> 0.474011).  Saving model ...
	 Train_Loss: 0.5081 Train_Acc: 74.980 Val_Loss: 0.4740  BEST VAL Loss: 0.4740  Val_Acc: 77.808

Epoch 43: Validation loss decreased (0.474011 --> 0.473410).  Saving model ...
	 Train_Loss: 0.5076 Train_Acc: 74.959 Val_Loss: 0.4734  BEST VAL Loss: 0.4734  Val_Acc: 77.858

Epoch 44: Validation loss decreased (0.473410 --> 0.472765).  Saving model ...
	 Train_Loss: 0.5071 Train_Acc: 75.012 Val_Loss: 0.4728  BEST VAL Loss: 0.4728  Val_Acc: 77.889

Epoch 45: Validation loss decreased (0.472765 --> 0.472285).  Saving model ...
	 Train_Loss: 0.5066 Train_Acc: 75.087 Val_Loss: 0.4723  BEST VAL Loss: 0.4723  Val_Acc: 77.582

Epoch 46: Validation loss decreased (0.472285 --> 0.471811).  Saving model ...
	 Train_Loss: 0.5061 Train_Acc: 75.111 Val_Loss: 0.4718  BEST VAL Loss: 0.4718  Val_Acc: 77.736

Epoch 47: Validation loss decreased (0.471811 --> 0.471330).  Saving model ...
	 Train_Loss: 0.5056 Train_Acc: 75.177 Val_Loss: 0.4713  BEST VAL Loss: 0.4713  Val_Acc: 77.831

Epoch 48: Validation loss decreased (0.471330 --> 0.470913).  Saving model ...
	 Train_Loss: 0.5052 Train_Acc: 75.125 Val_Loss: 0.4709  BEST VAL Loss: 0.4709  Val_Acc: 77.803

Epoch 49: Validation loss decreased (0.470913 --> 0.470476).  Saving model ...
	 Train_Loss: 0.5047 Train_Acc: 75.099 Val_Loss: 0.4705  BEST VAL Loss: 0.4705  Val_Acc: 77.849

Epoch 50: Validation loss decreased (0.470476 --> 0.470084).  Saving model ...
	 Train_Loss: 0.5043 Train_Acc: 75.108 Val_Loss: 0.4701  BEST VAL Loss: 0.4701  Val_Acc: 77.849

Epoch 51: Validation loss decreased (0.470084 --> 0.469580).  Saving model ...
	 Train_Loss: 0.5039 Train_Acc: 75.085 Val_Loss: 0.4696  BEST VAL Loss: 0.4696  Val_Acc: 78.143

Epoch 52: Validation loss decreased (0.469580 --> 0.469156).  Saving model ...
	 Train_Loss: 0.5034 Train_Acc: 75.377 Val_Loss: 0.4692  BEST VAL Loss: 0.4692  Val_Acc: 78.039

Epoch 53: Validation loss decreased (0.469156 --> 0.468631).  Saving model ...
	 Train_Loss: 0.5030 Train_Acc: 75.145 Val_Loss: 0.4686  BEST VAL Loss: 0.4686  Val_Acc: 78.106

Epoch 54: Validation loss decreased (0.468631 --> 0.468216).  Saving model ...
	 Train_Loss: 0.5026 Train_Acc: 75.153 Val_Loss: 0.4682  BEST VAL Loss: 0.4682  Val_Acc: 77.930

Epoch 55: Validation loss decreased (0.468216 --> 0.467805).  Saving model ...
	 Train_Loss: 0.5023 Train_Acc: 75.138 Val_Loss: 0.4678  BEST VAL Loss: 0.4678  Val_Acc: 78.305

Epoch 56: Validation loss decreased (0.467805 --> 0.467435).  Saving model ...
	 Train_Loss: 0.5019 Train_Acc: 75.212 Val_Loss: 0.4674  BEST VAL Loss: 0.4674  Val_Acc: 77.898

Epoch 57: Validation loss decreased (0.467435 --> 0.467025).  Saving model ...
	 Train_Loss: 0.5015 Train_Acc: 75.183 Val_Loss: 0.4670  BEST VAL Loss: 0.4670  Val_Acc: 78.057

Epoch 58: Validation loss decreased (0.467025 --> 0.466670).  Saving model ...
	 Train_Loss: 0.5012 Train_Acc: 75.246 Val_Loss: 0.4667  BEST VAL Loss: 0.4667  Val_Acc: 77.668

Epoch 59: Validation loss decreased (0.466670 --> 0.466255).  Saving model ...
	 Train_Loss: 0.5008 Train_Acc: 75.413 Val_Loss: 0.4663  BEST VAL Loss: 0.4663  Val_Acc: 78.242

Epoch 60: Validation loss decreased (0.466255 --> 0.465886).  Saving model ...
	 Train_Loss: 0.5005 Train_Acc: 75.136 Val_Loss: 0.4659  BEST VAL Loss: 0.4659  Val_Acc: 77.944

Epoch 61: Validation loss decreased (0.465886 --> 0.465498).  Saving model ...
	 Train_Loss: 0.5001 Train_Acc: 75.161 Val_Loss: 0.4655  BEST VAL Loss: 0.4655  Val_Acc: 78.106

Epoch 62: Validation loss decreased (0.465498 --> 0.465152).  Saving model ...
	 Train_Loss: 0.4998 Train_Acc: 75.239 Val_Loss: 0.4652  BEST VAL Loss: 0.4652  Val_Acc: 77.727

Epoch 63: Validation loss decreased (0.465152 --> 0.464759).  Saving model ...
	 Train_Loss: 0.4995 Train_Acc: 75.242 Val_Loss: 0.4648  BEST VAL Loss: 0.4648  Val_Acc: 78.102

Epoch 64: Validation loss decreased (0.464759 --> 0.464421).  Saving model ...
	 Train_Loss: 0.4992 Train_Acc: 75.280 Val_Loss: 0.4644  BEST VAL Loss: 0.4644  Val_Acc: 77.944

Epoch 65: Validation loss decreased (0.464421 --> 0.464199).  Saving model ...
	 Train_Loss: 0.4988 Train_Acc: 75.247 Val_Loss: 0.4642  BEST VAL Loss: 0.4642  Val_Acc: 77.939

Epoch 66: Validation loss decreased (0.464199 --> 0.463825).  Saving model ...
	 Train_Loss: 0.4985 Train_Acc: 75.385 Val_Loss: 0.4638  BEST VAL Loss: 0.4638  Val_Acc: 77.993

Epoch 67: Validation loss decreased (0.463825 --> 0.463505).  Saving model ...
	 Train_Loss: 0.4983 Train_Acc: 75.222 Val_Loss: 0.4635  BEST VAL Loss: 0.4635  Val_Acc: 78.084

Epoch 68: Validation loss decreased (0.463505 --> 0.463207).  Saving model ...
	 Train_Loss: 0.4980 Train_Acc: 75.358 Val_Loss: 0.4632  BEST VAL Loss: 0.4632  Val_Acc: 78.305

Epoch 69: Validation loss decreased (0.463207 --> 0.462920).  Saving model ...
	 Train_Loss: 0.4977 Train_Acc: 75.323 Val_Loss: 0.4629  BEST VAL Loss: 0.4629  Val_Acc: 77.632

Epoch 70: Validation loss decreased (0.462920 --> 0.462589).  Saving model ...
	 Train_Loss: 0.4974 Train_Acc: 75.329 Val_Loss: 0.4626  BEST VAL Loss: 0.4626  Val_Acc: 78.432

Epoch 71: Validation loss decreased (0.462589 --> 0.462262).  Saving model ...
	 Train_Loss: 0.4971 Train_Acc: 75.347 Val_Loss: 0.4623  BEST VAL Loss: 0.4623  Val_Acc: 78.400

Epoch 72: Validation loss decreased (0.462262 --> 0.461962).  Saving model ...
	 Train_Loss: 0.4969 Train_Acc: 75.324 Val_Loss: 0.4620  BEST VAL Loss: 0.4620  Val_Acc: 78.432

Epoch 73: Validation loss decreased (0.461962 --> 0.461649).  Saving model ...
	 Train_Loss: 0.4966 Train_Acc: 75.406 Val_Loss: 0.4616  BEST VAL Loss: 0.4616  Val_Acc: 78.495

Epoch 74: Validation loss decreased (0.461649 --> 0.461374).  Saving model ...
	 Train_Loss: 0.4963 Train_Acc: 75.403 Val_Loss: 0.4614  BEST VAL Loss: 0.4614  Val_Acc: 78.020

Epoch 75: Validation loss decreased (0.461374 --> 0.461075).  Saving model ...
	 Train_Loss: 0.4961 Train_Acc: 75.326 Val_Loss: 0.4611  BEST VAL Loss: 0.4611  Val_Acc: 78.319

Epoch 76: Validation loss decreased (0.461075 --> 0.460758).  Saving model ...
	 Train_Loss: 0.4958 Train_Acc: 75.417 Val_Loss: 0.4608  BEST VAL Loss: 0.4608  Val_Acc: 78.029

Epoch 77: Validation loss decreased (0.460758 --> 0.460497).  Saving model ...
	 Train_Loss: 0.4956 Train_Acc: 75.465 Val_Loss: 0.4605  BEST VAL Loss: 0.4605  Val_Acc: 78.011

Epoch 78: Validation loss decreased (0.460497 --> 0.460222).  Saving model ...
	 Train_Loss: 0.4953 Train_Acc: 75.424 Val_Loss: 0.4602  BEST VAL Loss: 0.4602  Val_Acc: 78.115

Epoch 79: Validation loss decreased (0.460222 --> 0.459952).  Saving model ...
	 Train_Loss: 0.4951 Train_Acc: 75.382 Val_Loss: 0.4600  BEST VAL Loss: 0.4600  Val_Acc: 78.455

Epoch 80: Validation loss decreased (0.459952 --> 0.459656).  Saving model ...
	 Train_Loss: 0.4949 Train_Acc: 75.439 Val_Loss: 0.4597  BEST VAL Loss: 0.4597  Val_Acc: 78.522

Epoch 81: Validation loss decreased (0.459656 --> 0.459395).  Saving model ...
	 Train_Loss: 0.4946 Train_Acc: 75.460 Val_Loss: 0.4594  BEST VAL Loss: 0.4594  Val_Acc: 78.893

Epoch 82: Validation loss decreased (0.459395 --> 0.459139).  Saving model ...
	 Train_Loss: 0.4944 Train_Acc: 75.439 Val_Loss: 0.4591  BEST VAL Loss: 0.4591  Val_Acc: 78.242

Epoch 83: Validation loss decreased (0.459139 --> 0.458890).  Saving model ...
	 Train_Loss: 0.4942 Train_Acc: 75.366 Val_Loss: 0.4589  BEST VAL Loss: 0.4589  Val_Acc: 78.387

Epoch 84: Validation loss decreased (0.458890 --> 0.458668).  Saving model ...
	 Train_Loss: 0.4940 Train_Acc: 75.472 Val_Loss: 0.4587  BEST VAL Loss: 0.4587  Val_Acc: 78.287

Epoch 85: Validation loss decreased (0.458668 --> 0.458416).  Saving model ...
	 Train_Loss: 0.4938 Train_Acc: 75.411 Val_Loss: 0.4584  BEST VAL Loss: 0.4584  Val_Acc: 78.301

Epoch 86: Validation loss decreased (0.458416 --> 0.458190).  Saving model ...
	 Train_Loss: 0.4935 Train_Acc: 75.346 Val_Loss: 0.4582  BEST VAL Loss: 0.4582  Val_Acc: 78.382

Epoch 87: Validation loss decreased (0.458190 --> 0.457997).  Saving model ...
	 Train_Loss: 0.4933 Train_Acc: 75.419 Val_Loss: 0.4580  BEST VAL Loss: 0.4580  Val_Acc: 78.251

Epoch 88: Validation loss decreased (0.457997 --> 0.457731).  Saving model ...
	 Train_Loss: 0.4931 Train_Acc: 75.480 Val_Loss: 0.4577  BEST VAL Loss: 0.4577  Val_Acc: 78.549

Epoch 89: Validation loss decreased (0.457731 --> 0.457515).  Saving model ...
	 Train_Loss: 0.4929 Train_Acc: 75.497 Val_Loss: 0.4575  BEST VAL Loss: 0.4575  Val_Acc: 78.296

Epoch 90: Validation loss decreased (0.457515 --> 0.457291).  Saving model ...
	 Train_Loss: 0.4927 Train_Acc: 75.528 Val_Loss: 0.4573  BEST VAL Loss: 0.4573  Val_Acc: 78.477

Epoch 91: Validation loss decreased (0.457291 --> 0.457044).  Saving model ...
	 Train_Loss: 0.4925 Train_Acc: 75.540 Val_Loss: 0.4570  BEST VAL Loss: 0.4570  Val_Acc: 78.581

Epoch 92: Validation loss decreased (0.457044 --> 0.456795).  Saving model ...
	 Train_Loss: 0.4923 Train_Acc: 75.411 Val_Loss: 0.4568  BEST VAL Loss: 0.4568  Val_Acc: 78.441

Epoch 93: Validation loss decreased (0.456795 --> 0.456575).  Saving model ...
	 Train_Loss: 0.4921 Train_Acc: 75.441 Val_Loss: 0.4566  BEST VAL Loss: 0.4566  Val_Acc: 78.341

Epoch 94: Validation loss decreased (0.456575 --> 0.456379).  Saving model ...
	 Train_Loss: 0.4920 Train_Acc: 75.384 Val_Loss: 0.4564  BEST VAL Loss: 0.4564  Val_Acc: 78.423

Epoch 95: Validation loss decreased (0.456379 --> 0.456122).  Saving model ...
	 Train_Loss: 0.4918 Train_Acc: 75.666 Val_Loss: 0.4561  BEST VAL Loss: 0.4561  Val_Acc: 78.708

Epoch 96: Validation loss decreased (0.456122 --> 0.455875).  Saving model ...
	 Train_Loss: 0.4916 Train_Acc: 75.563 Val_Loss: 0.4559  BEST VAL Loss: 0.4559  Val_Acc: 78.595

Epoch 97: Validation loss decreased (0.455875 --> 0.455670).  Saving model ...
	 Train_Loss: 0.4914 Train_Acc: 75.569 Val_Loss: 0.4557  BEST VAL Loss: 0.4557  Val_Acc: 78.721

Epoch 98: Validation loss decreased (0.455670 --> 0.455433).  Saving model ...
	 Train_Loss: 0.4912 Train_Acc: 75.515 Val_Loss: 0.4554  BEST VAL Loss: 0.4554  Val_Acc: 78.577

Epoch 99: Validation loss decreased (0.455433 --> 0.455221).  Saving model ...
	 Train_Loss: 0.4910 Train_Acc: 75.506 Val_Loss: 0.4552  BEST VAL Loss: 0.4552  Val_Acc: 78.739

LPS_0.010_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.50      0.49     85026
           1       0.52      0.50      0.51     91898

    accuracy                           0.50    176924
   macro avg       0.50      0.50      0.50    176924
weighted avg       0.50      0.50      0.50    176924

LPS_0.010_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.50      0.49     10628
           1       0.52      0.51      0.51     11488

    accuracy                           0.50     22116
   macro avg       0.50      0.50      0.50     22116
weighted avg       0.51      0.50      0.50     22116

LPS_0.010_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.50      0.49     10629
           1       0.52      0.49      0.51     11487

    accuracy                           0.50     22116
   macro avg       0.50      0.50      0.50     22116
weighted avg       0.50      0.50      0.50     22116

              precision    recall  f1-score   support

           0       0.48      0.50      0.49     10629
           1       0.52      0.49      0.51     11487

    accuracy                           0.50     22116
   macro avg       0.50      0.50      0.50     22116
weighted avg       0.50      0.50      0.50     22116

LPS_0.010_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.48      0.47     36797
           1       0.53      0.52      0.52     41617

    accuracy                           0.50     78414
   macro avg       0.50      0.50      0.50     78414
weighted avg       0.50      0.50      0.50     78414

              precision    recall  f1-score   support

           0       0.47      0.48      0.47     36797
           1       0.53      0.52      0.52     41617

    accuracy                           0.50     78414
   macro avg       0.50      0.50      0.50     78414
weighted avg       0.50      0.50      0.50     78414

completed
