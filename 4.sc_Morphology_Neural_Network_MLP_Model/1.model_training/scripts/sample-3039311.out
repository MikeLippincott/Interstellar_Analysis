[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '04fd2809'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'f1ca7f5b'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'f05e84c4'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '45696535'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_10.000_DMSO_0.025 treatment_name: H2O2_100.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: H2O2_100.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (397026, 1270)
Number of total missing values across all columns: 794052
Data Subset Is Off
Wells held out for testing: ['E09' 'I10']
Wells to use for training, validation, and testing ['E02' 'E03' 'E08' 'H04' 'I04' 'H05' 'I05' 'H10' 'H11' 'I11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.503779).  Saving model ...
	 Train_Loss: 0.5961 Train_Acc: 64.103 Val_Loss: 0.5038  BEST VAL Loss: 0.5038  Val_Acc: 64.780

Epoch 1: Validation loss decreased (0.503779 --> 0.464288).  Saving model ...
	 Train_Loss: 0.5475 Train_Acc: 76.388 Val_Loss: 0.4643  BEST VAL Loss: 0.4643  Val_Acc: 81.471

Epoch 2: Validation loss decreased (0.464288 --> 0.429306).  Saving model ...
	 Train_Loss: 0.5154 Train_Acc: 79.987 Val_Loss: 0.4293  BEST VAL Loss: 0.4293  Val_Acc: 86.010

Epoch 3: Validation loss decreased (0.429306 --> 0.405071).  Saving model ...
	 Train_Loss: 0.4923 Train_Acc: 81.598 Val_Loss: 0.4051  BEST VAL Loss: 0.4051  Val_Acc: 87.095

Epoch 4: Validation loss decreased (0.405071 --> 0.387114).  Saving model ...
	 Train_Loss: 0.4738 Train_Acc: 82.682 Val_Loss: 0.3871  BEST VAL Loss: 0.3871  Val_Acc: 87.902

Epoch 5: Validation loss decreased (0.387114 --> 0.373820).  Saving model ...
	 Train_Loss: 0.4578 Train_Acc: 83.834 Val_Loss: 0.3738  BEST VAL Loss: 0.3738  Val_Acc: 88.003

Epoch 6: Validation loss decreased (0.373820 --> 0.365617).  Saving model ...
	 Train_Loss: 0.4441 Train_Acc: 84.693 Val_Loss: 0.3656  BEST VAL Loss: 0.3656  Val_Acc: 87.456

Epoch 7: Validation loss decreased (0.365617 --> 0.355695).  Saving model ...
	 Train_Loss: 0.4324 Train_Acc: 85.151 Val_Loss: 0.3557  BEST VAL Loss: 0.3557  Val_Acc: 88.789

Epoch 8: Validation loss decreased (0.355695 --> 0.350325).  Saving model ...
	 Train_Loss: 0.4227 Train_Acc: 85.409 Val_Loss: 0.3503  BEST VAL Loss: 0.3503  Val_Acc: 87.624

Epoch 9: Validation loss decreased (0.350325 --> 0.343583).  Saving model ...
	 Train_Loss: 0.4144 Train_Acc: 85.684 Val_Loss: 0.3436  BEST VAL Loss: 0.3436  Val_Acc: 89.165

Epoch 10: Validation loss decreased (0.343583 --> 0.337767).  Saving model ...
	 Train_Loss: 0.4069 Train_Acc: 86.025 Val_Loss: 0.3378  BEST VAL Loss: 0.3378  Val_Acc: 89.394

Epoch 11: Validation loss decreased (0.337767 --> 0.332420).  Saving model ...
	 Train_Loss: 0.4004 Train_Acc: 86.194 Val_Loss: 0.3324  BEST VAL Loss: 0.3324  Val_Acc: 89.415

Epoch 12: Validation loss decreased (0.332420 --> 0.328148).  Saving model ...
	 Train_Loss: 0.3947 Train_Acc: 86.294 Val_Loss: 0.3281  BEST VAL Loss: 0.3281  Val_Acc: 89.501

Epoch 13: Validation loss decreased (0.328148 --> 0.323522).  Saving model ...
	 Train_Loss: 0.3896 Train_Acc: 86.311 Val_Loss: 0.3235  BEST VAL Loss: 0.3235  Val_Acc: 89.785

Epoch 14: Validation loss decreased (0.323522 --> 0.319763).  Saving model ...
	 Train_Loss: 0.3847 Train_Acc: 86.566 Val_Loss: 0.3198  BEST VAL Loss: 0.3198  Val_Acc: 89.382

Epoch 15: Validation loss decreased (0.319763 --> 0.315979).  Saving model ...
	 Train_Loss: 0.3799 Train_Acc: 86.862 Val_Loss: 0.3160  BEST VAL Loss: 0.3160  Val_Acc: 89.846

Epoch 16: Validation loss decreased (0.315979 --> 0.312497).  Saving model ...
	 Train_Loss: 0.3753 Train_Acc: 87.142 Val_Loss: 0.3125  BEST VAL Loss: 0.3125  Val_Acc: 89.923

Epoch 17: Validation loss decreased (0.312497 --> 0.308985).  Saving model ...
	 Train_Loss: 0.3712 Train_Acc: 87.193 Val_Loss: 0.3090  BEST VAL Loss: 0.3090  Val_Acc: 89.984

Epoch 18: Validation loss decreased (0.308985 --> 0.306162).  Saving model ...
	 Train_Loss: 0.3673 Train_Acc: 87.429 Val_Loss: 0.3062  BEST VAL Loss: 0.3062  Val_Acc: 89.938

Epoch 19: Validation loss decreased (0.306162 --> 0.303269).  Saving model ...
	 Train_Loss: 0.3637 Train_Acc: 87.555 Val_Loss: 0.3033  BEST VAL Loss: 0.3033  Val_Acc: 90.097

Epoch 20: Validation loss decreased (0.303269 --> 0.300394).  Saving model ...
	 Train_Loss: 0.3603 Train_Acc: 87.618 Val_Loss: 0.3004  BEST VAL Loss: 0.3004  Val_Acc: 90.164

Epoch 21: Validation loss decreased (0.300394 --> 0.298046).  Saving model ...
	 Train_Loss: 0.3572 Train_Acc: 87.742 Val_Loss: 0.2980  BEST VAL Loss: 0.2980  Val_Acc: 90.118

Epoch 22: Validation loss decreased (0.298046 --> 0.295344).  Saving model ...
	 Train_Loss: 0.3542 Train_Acc: 87.779 Val_Loss: 0.2953  BEST VAL Loss: 0.2953  Val_Acc: 90.503

Epoch 23: Validation loss decreased (0.295344 --> 0.293138).  Saving model ...
	 Train_Loss: 0.3514 Train_Acc: 87.915 Val_Loss: 0.2931  BEST VAL Loss: 0.2931  Val_Acc: 90.225

Epoch 24: Validation loss decreased (0.293138 --> 0.290648).  Saving model ...
	 Train_Loss: 0.3488 Train_Acc: 87.913 Val_Loss: 0.2906  BEST VAL Loss: 0.2906  Val_Acc: 90.834

Epoch 25: Validation loss decreased (0.290648 --> 0.288671).  Saving model ...
	 Train_Loss: 0.3464 Train_Acc: 88.024 Val_Loss: 0.2887  BEST VAL Loss: 0.2887  Val_Acc: 90.525

Epoch 26: Validation loss decreased (0.288671 --> 0.286510).  Saving model ...
	 Train_Loss: 0.3440 Train_Acc: 88.116 Val_Loss: 0.2865  BEST VAL Loss: 0.2865  Val_Acc: 90.898

Epoch 27: Validation loss decreased (0.286510 --> 0.284533).  Saving model ...
	 Train_Loss: 0.3418 Train_Acc: 88.162 Val_Loss: 0.2845  BEST VAL Loss: 0.2845  Val_Acc: 90.797

Epoch 28: Validation loss decreased (0.284533 --> 0.282578).  Saving model ...
	 Train_Loss: 0.3396 Train_Acc: 88.297 Val_Loss: 0.2826  BEST VAL Loss: 0.2826  Val_Acc: 91.023

Epoch 29: Validation loss decreased (0.282578 --> 0.280787).  Saving model ...
	 Train_Loss: 0.3376 Train_Acc: 88.263 Val_Loss: 0.2808  BEST VAL Loss: 0.2808  Val_Acc: 90.904

Epoch 30: Validation loss decreased (0.280787 --> 0.279000).  Saving model ...
	 Train_Loss: 0.3357 Train_Acc: 88.294 Val_Loss: 0.2790  BEST VAL Loss: 0.2790  Val_Acc: 90.996

Epoch 31: Validation loss decreased (0.279000 --> 0.277349).  Saving model ...
	 Train_Loss: 0.3339 Train_Acc: 88.329 Val_Loss: 0.2773  BEST VAL Loss: 0.2773  Val_Acc: 90.889

Epoch 32: Validation loss decreased (0.277349 --> 0.275858).  Saving model ...
	 Train_Loss: 0.3322 Train_Acc: 88.215 Val_Loss: 0.2759  BEST VAL Loss: 0.2759  Val_Acc: 90.919

Epoch 33: Validation loss decreased (0.275858 --> 0.274374).  Saving model ...
	 Train_Loss: 0.3305 Train_Acc: 88.388 Val_Loss: 0.2744  BEST VAL Loss: 0.2744  Val_Acc: 91.026

Epoch 34: Validation loss decreased (0.274374 --> 0.272979).  Saving model ...
	 Train_Loss: 0.3289 Train_Acc: 88.465 Val_Loss: 0.2730  BEST VAL Loss: 0.2730  Val_Acc: 91.136

Epoch 35: Validation loss decreased (0.272979 --> 0.271809).  Saving model ...
	 Train_Loss: 0.3274 Train_Acc: 88.550 Val_Loss: 0.2718  BEST VAL Loss: 0.2718  Val_Acc: 90.684

Epoch 36: Validation loss decreased (0.271809 --> 0.270454).  Saving model ...
	 Train_Loss: 0.3259 Train_Acc: 88.483 Val_Loss: 0.2705  BEST VAL Loss: 0.2705  Val_Acc: 91.096

Epoch 37: Validation loss decreased (0.270454 --> 0.269356).  Saving model ...
	 Train_Loss: 0.3245 Train_Acc: 88.625 Val_Loss: 0.2694  BEST VAL Loss: 0.2694  Val_Acc: 90.824

Epoch 38: Validation loss decreased (0.269356 --> 0.268297).  Saving model ...
	 Train_Loss: 0.3231 Train_Acc: 88.589 Val_Loss: 0.2683  BEST VAL Loss: 0.2683  Val_Acc: 90.834

Epoch 39: Validation loss decreased (0.268297 --> 0.267155).  Saving model ...
	 Train_Loss: 0.3219 Train_Acc: 88.472 Val_Loss: 0.2672  BEST VAL Loss: 0.2672  Val_Acc: 91.032

Epoch 40: Validation loss decreased (0.267155 --> 0.266213).  Saving model ...
	 Train_Loss: 0.3207 Train_Acc: 88.625 Val_Loss: 0.2662  BEST VAL Loss: 0.2662  Val_Acc: 90.797

Epoch 41: Validation loss decreased (0.266213 --> 0.265082).  Saving model ...
	 Train_Loss: 0.3195 Train_Acc: 88.567 Val_Loss: 0.2651  BEST VAL Loss: 0.2651  Val_Acc: 91.213

Epoch 42: Validation loss decreased (0.265082 --> 0.264163).  Saving model ...
	 Train_Loss: 0.3183 Train_Acc: 88.583 Val_Loss: 0.2642  BEST VAL Loss: 0.2642  Val_Acc: 90.956

Epoch 43: Validation loss decreased (0.264163 --> 0.263118).  Saving model ...
	 Train_Loss: 0.3172 Train_Acc: 88.534 Val_Loss: 0.2631  BEST VAL Loss: 0.2631  Val_Acc: 91.078

Epoch 44: Validation loss decreased (0.263118 --> 0.262151).  Saving model ...
	 Train_Loss: 0.3162 Train_Acc: 88.687 Val_Loss: 0.2622  BEST VAL Loss: 0.2622  Val_Acc: 91.188

Epoch 45: Validation loss decreased (0.262151 --> 0.261271).  Saving model ...
	 Train_Loss: 0.3151 Train_Acc: 88.602 Val_Loss: 0.2613  BEST VAL Loss: 0.2613  Val_Acc: 91.219

Epoch 46: Validation loss decreased (0.261271 --> 0.260279).  Saving model ...
	 Train_Loss: 0.3141 Train_Acc: 88.692 Val_Loss: 0.2603  BEST VAL Loss: 0.2603  Val_Acc: 91.344

Epoch 47: Validation loss decreased (0.260279 --> 0.259379).  Saving model ...
	 Train_Loss: 0.3132 Train_Acc: 88.804 Val_Loss: 0.2594  BEST VAL Loss: 0.2594  Val_Acc: 91.264

Epoch 48: Validation loss decreased (0.259379 --> 0.258496).  Saving model ...
	 Train_Loss: 0.3122 Train_Acc: 88.696 Val_Loss: 0.2585  BEST VAL Loss: 0.2585  Val_Acc: 91.387

Epoch 49: Validation loss decreased (0.258496 --> 0.257689).  Saving model ...
	 Train_Loss: 0.3113 Train_Acc: 88.771 Val_Loss: 0.2577  BEST VAL Loss: 0.2577  Val_Acc: 91.255

Epoch 50: Validation loss decreased (0.257689 --> 0.256855).  Saving model ...
	 Train_Loss: 0.3104 Train_Acc: 88.762 Val_Loss: 0.2569  BEST VAL Loss: 0.2569  Val_Acc: 91.326

Epoch 51: Validation loss decreased (0.256855 --> 0.256030).  Saving model ...
	 Train_Loss: 0.3096 Train_Acc: 88.846 Val_Loss: 0.2560  BEST VAL Loss: 0.2560  Val_Acc: 91.378

Epoch 52: Validation loss decreased (0.256030 --> 0.255268).  Saving model ...
	 Train_Loss: 0.3088 Train_Acc: 88.801 Val_Loss: 0.2553  BEST VAL Loss: 0.2553  Val_Acc: 91.381

Epoch 53: Validation loss decreased (0.255268 --> 0.254637).  Saving model ...
	 Train_Loss: 0.3080 Train_Acc: 88.843 Val_Loss: 0.2546  BEST VAL Loss: 0.2546  Val_Acc: 91.323

Epoch 54: Validation loss decreased (0.254637 --> 0.253880).  Saving model ...
	 Train_Loss: 0.3072 Train_Acc: 88.776 Val_Loss: 0.2539  BEST VAL Loss: 0.2539  Val_Acc: 91.500

Epoch 55: Validation loss decreased (0.253880 --> 0.253239).  Saving model ...
	 Train_Loss: 0.3064 Train_Acc: 88.783 Val_Loss: 0.2532  BEST VAL Loss: 0.2532  Val_Acc: 91.173

Epoch 56: Validation loss decreased (0.253239 --> 0.252581).  Saving model ...
	 Train_Loss: 0.3057 Train_Acc: 88.898 Val_Loss: 0.2526  BEST VAL Loss: 0.2526  Val_Acc: 91.264

Epoch 57: Validation loss decreased (0.252581 --> 0.251913).  Saving model ...
	 Train_Loss: 0.3050 Train_Acc: 88.904 Val_Loss: 0.2519  BEST VAL Loss: 0.2519  Val_Acc: 91.341

Epoch 58: Validation loss decreased (0.251913 --> 0.251369).  Saving model ...
	 Train_Loss: 0.3043 Train_Acc: 88.895 Val_Loss: 0.2514  BEST VAL Loss: 0.2514  Val_Acc: 91.096

Epoch 59: Validation loss decreased (0.251369 --> 0.250706).  Saving model ...
	 Train_Loss: 0.3036 Train_Acc: 88.918 Val_Loss: 0.2507  BEST VAL Loss: 0.2507  Val_Acc: 91.518

Epoch 60: Validation loss decreased (0.250706 --> 0.250081).  Saving model ...
	 Train_Loss: 0.3030 Train_Acc: 88.885 Val_Loss: 0.2501  BEST VAL Loss: 0.2501  Val_Acc: 91.643

Epoch 61: Validation loss decreased (0.250081 --> 0.249476).  Saving model ...
	 Train_Loss: 0.3023 Train_Acc: 88.859 Val_Loss: 0.2495  BEST VAL Loss: 0.2495  Val_Acc: 91.491

Epoch 62: Validation loss decreased (0.249476 --> 0.248953).  Saving model ...
	 Train_Loss: 0.3017 Train_Acc: 89.003 Val_Loss: 0.2490  BEST VAL Loss: 0.2490  Val_Acc: 91.264

Epoch 63: Validation loss decreased (0.248953 --> 0.248454).  Saving model ...
	 Train_Loss: 0.3011 Train_Acc: 88.965 Val_Loss: 0.2485  BEST VAL Loss: 0.2485  Val_Acc: 91.209

Epoch 64: Validation loss decreased (0.248454 --> 0.247979).  Saving model ...
	 Train_Loss: 0.3005 Train_Acc: 88.851 Val_Loss: 0.2480  BEST VAL Loss: 0.2480  Val_Acc: 91.381

Epoch 65: Validation loss decreased (0.247979 --> 0.247438).  Saving model ...
	 Train_Loss: 0.2999 Train_Acc: 88.936 Val_Loss: 0.2474  BEST VAL Loss: 0.2474  Val_Acc: 91.423

Epoch 66: Validation loss decreased (0.247438 --> 0.246958).  Saving model ...
	 Train_Loss: 0.2993 Train_Acc: 88.873 Val_Loss: 0.2470  BEST VAL Loss: 0.2470  Val_Acc: 91.286

Epoch 67: Validation loss decreased (0.246958 --> 0.246461).  Saving model ...
	 Train_Loss: 0.2988 Train_Acc: 89.026 Val_Loss: 0.2465  BEST VAL Loss: 0.2465  Val_Acc: 91.393

Epoch 68: Validation loss decreased (0.246461 --> 0.245978).  Saving model ...
	 Train_Loss: 0.2982 Train_Acc: 89.062 Val_Loss: 0.2460  BEST VAL Loss: 0.2460  Val_Acc: 91.396

Epoch 69: Validation loss decreased (0.245978 --> 0.245554).  Saving model ...
	 Train_Loss: 0.2977 Train_Acc: 89.023 Val_Loss: 0.2456  BEST VAL Loss: 0.2456  Val_Acc: 91.164

Epoch 70: Validation loss decreased (0.245554 --> 0.245051).  Saving model ...
	 Train_Loss: 0.2971 Train_Acc: 88.925 Val_Loss: 0.2451  BEST VAL Loss: 0.2451  Val_Acc: 91.500

Epoch 71: Validation loss decreased (0.245051 --> 0.244612).  Saving model ...
	 Train_Loss: 0.2966 Train_Acc: 89.033 Val_Loss: 0.2446  BEST VAL Loss: 0.2446  Val_Acc: 91.390

Epoch 72: Validation loss decreased (0.244612 --> 0.244210).  Saving model ...
	 Train_Loss: 0.2961 Train_Acc: 89.000 Val_Loss: 0.2442  BEST VAL Loss: 0.2442  Val_Acc: 91.347

Epoch 73: Validation loss decreased (0.244210 --> 0.243746).  Saving model ...
	 Train_Loss: 0.2957 Train_Acc: 89.072 Val_Loss: 0.2437  BEST VAL Loss: 0.2437  Val_Acc: 91.530

Epoch 74: Validation loss decreased (0.243746 --> 0.243331).  Saving model ...
	 Train_Loss: 0.2952 Train_Acc: 89.038 Val_Loss: 0.2433  BEST VAL Loss: 0.2433  Val_Acc: 91.457

Epoch 75: Validation loss decreased (0.243331 --> 0.242941).  Saving model ...
	 Train_Loss: 0.2947 Train_Acc: 88.987 Val_Loss: 0.2429  BEST VAL Loss: 0.2429  Val_Acc: 91.378

Epoch 76: Validation loss decreased (0.242941 --> 0.242519).  Saving model ...
	 Train_Loss: 0.2943 Train_Acc: 89.083 Val_Loss: 0.2425  BEST VAL Loss: 0.2425  Val_Acc: 91.356

Epoch 77: Validation loss decreased (0.242519 --> 0.242130).  Saving model ...
	 Train_Loss: 0.2938 Train_Acc: 89.128 Val_Loss: 0.2421  BEST VAL Loss: 0.2421  Val_Acc: 91.454

Epoch 78: Validation loss decreased (0.242130 --> 0.241761).  Saving model ...
	 Train_Loss: 0.2934 Train_Acc: 89.105 Val_Loss: 0.2418  BEST VAL Loss: 0.2418  Val_Acc: 91.497

Epoch 79: Validation loss decreased (0.241761 --> 0.241406).  Saving model ...
	 Train_Loss: 0.2929 Train_Acc: 89.129 Val_Loss: 0.2414  BEST VAL Loss: 0.2414  Val_Acc: 91.524

Epoch 80: Validation loss decreased (0.241406 --> 0.241029).  Saving model ...
	 Train_Loss: 0.2925 Train_Acc: 89.175 Val_Loss: 0.2410  BEST VAL Loss: 0.2410  Val_Acc: 91.564

Epoch 81: Validation loss decreased (0.241029 --> 0.240650).  Saving model ...
	 Train_Loss: 0.2921 Train_Acc: 89.185 Val_Loss: 0.2407  BEST VAL Loss: 0.2407  Val_Acc: 91.466

Epoch 82: Validation loss decreased (0.240650 --> 0.240308).  Saving model ...
	 Train_Loss: 0.2916 Train_Acc: 89.177 Val_Loss: 0.2403  BEST VAL Loss: 0.2403  Val_Acc: 91.549

Epoch 83: Validation loss decreased (0.240308 --> 0.240033).  Saving model ...
	 Train_Loss: 0.2913 Train_Acc: 89.142 Val_Loss: 0.2400  BEST VAL Loss: 0.2400  Val_Acc: 91.359

Epoch 84: Validation loss decreased (0.240033 --> 0.239710).  Saving model ...
	 Train_Loss: 0.2909 Train_Acc: 89.086 Val_Loss: 0.2397  BEST VAL Loss: 0.2397  Val_Acc: 91.344

Epoch 85: Validation loss decreased (0.239710 --> 0.239462).  Saving model ...
	 Train_Loss: 0.2905 Train_Acc: 89.203 Val_Loss: 0.2395  BEST VAL Loss: 0.2395  Val_Acc: 91.203

Epoch 86: Validation loss decreased (0.239462 --> 0.239138).  Saving model ...
	 Train_Loss: 0.2901 Train_Acc: 89.141 Val_Loss: 0.2391  BEST VAL Loss: 0.2391  Val_Acc: 91.463

Epoch 87: Validation loss decreased (0.239138 --> 0.238829).  Saving model ...
	 Train_Loss: 0.2897 Train_Acc: 89.256 Val_Loss: 0.2388  BEST VAL Loss: 0.2388  Val_Acc: 91.677

Epoch 88: Validation loss decreased (0.238829 --> 0.238532).  Saving model ...
	 Train_Loss: 0.2893 Train_Acc: 89.142 Val_Loss: 0.2385  BEST VAL Loss: 0.2385  Val_Acc: 91.631

Epoch 89: Validation loss decreased (0.238532 --> 0.238250).  Saving model ...
	 Train_Loss: 0.2890 Train_Acc: 89.255 Val_Loss: 0.2382  BEST VAL Loss: 0.2382  Val_Acc: 91.515

Epoch 90: Validation loss decreased (0.238250 --> 0.237958).  Saving model ...
	 Train_Loss: 0.2886 Train_Acc: 89.173 Val_Loss: 0.2380  BEST VAL Loss: 0.2380  Val_Acc: 91.634

Epoch 91: Validation loss decreased (0.237958 --> 0.237685).  Saving model ...
	 Train_Loss: 0.2883 Train_Acc: 89.207 Val_Loss: 0.2377  BEST VAL Loss: 0.2377  Val_Acc: 91.540

Epoch 92: Validation loss decreased (0.237685 --> 0.237418).  Saving model ...
	 Train_Loss: 0.2879 Train_Acc: 89.142 Val_Loss: 0.2374  BEST VAL Loss: 0.2374  Val_Acc: 91.475

Epoch 93: Validation loss decreased (0.237418 --> 0.237119).  Saving model ...
	 Train_Loss: 0.2876 Train_Acc: 89.187 Val_Loss: 0.2371  BEST VAL Loss: 0.2371  Val_Acc: 91.705

Epoch 94: Validation loss decreased (0.237119 --> 0.236863).  Saving model ...
	 Train_Loss: 0.2873 Train_Acc: 89.138 Val_Loss: 0.2369  BEST VAL Loss: 0.2369  Val_Acc: 91.588

Epoch 95: Validation loss decreased (0.236863 --> 0.236608).  Saving model ...
	 Train_Loss: 0.2869 Train_Acc: 89.198 Val_Loss: 0.2366  BEST VAL Loss: 0.2366  Val_Acc: 91.561

Epoch 96: Validation loss decreased (0.236608 --> 0.236319).  Saving model ...
	 Train_Loss: 0.2866 Train_Acc: 89.234 Val_Loss: 0.2363  BEST VAL Loss: 0.2363  Val_Acc: 91.555

Epoch 97: Validation loss decreased (0.236319 --> 0.236078).  Saving model ...
	 Train_Loss: 0.2863 Train_Acc: 89.237 Val_Loss: 0.2361  BEST VAL Loss: 0.2361  Val_Acc: 91.512

Epoch 98: Validation loss decreased (0.236078 --> 0.235840).  Saving model ...
	 Train_Loss: 0.2860 Train_Acc: 89.237 Val_Loss: 0.2358  BEST VAL Loss: 0.2358  Val_Acc: 91.365

Epoch 99: Validation loss decreased (0.235840 --> 0.235575).  Saving model ...
	 Train_Loss: 0.2857 Train_Acc: 89.189 Val_Loss: 0.2356  BEST VAL Loss: 0.2356  Val_Acc: 91.616

LPS_10.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.95      0.95      0.95    169562
           1       0.90      0.90      0.90     92173

    accuracy                           0.93    261735
   macro avg       0.92      0.92      0.92    261735
weighted avg       0.93      0.93      0.93    261735

LPS_10.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.94      0.94     21195
           1       0.89      0.87      0.88     11522

    accuracy                           0.92     32717
   macro avg       0.91      0.91      0.91     32717
weighted avg       0.92      0.92      0.92     32717

LPS_10.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.94      0.94      0.94     21195
           1       0.88      0.88      0.88     11522

    accuracy                           0.92     32717
   macro avg       0.91      0.91      0.91     32717
weighted avg       0.92      0.92      0.92     32717

              precision    recall  f1-score   support

           0       0.94      0.94      0.94     21195
           1       0.88      0.88      0.88     11522

    accuracy                           0.92     32717
   macro avg       0.91      0.91      0.91     32717
weighted avg       0.92      0.92      0.92     32717

LPS_10.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.62      0.83      0.71     28584
           1       0.85      0.65      0.73     41273

    accuracy                           0.72     69857
   macro avg       0.73      0.74      0.72     69857
weighted avg       0.76      0.72      0.73     69857

              precision    recall  f1-score   support

           0       0.62      0.83      0.71     28584
           1       0.85      0.65      0.73     41273

    accuracy                           0.72     69857
   macro avg       0.73      0.74      0.72     69857
weighted avg       0.76      0.72      0.73     69857

completed
