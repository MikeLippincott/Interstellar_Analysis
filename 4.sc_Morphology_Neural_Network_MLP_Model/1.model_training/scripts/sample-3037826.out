[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'a3dfaa83'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '6a8f00e2'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'f4cdc7a3'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '3faed948'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_100.000_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_100.000_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_100.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (255350, 1270)
Number of total missing values across all columns: 510700
Data Subset Is Off
Wells held out for testing: ['J08' 'L10']
Wells to use for training, validation, and testing ['J02' 'J03' 'J09' 'L05' 'L11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.509266).  Saving model ...
	 Train_Loss: 0.5651 Train_Acc: 70.981 Val_Loss: 0.5093  BEST VAL Loss: 0.5093  Val_Acc: 74.182

Epoch 1: Validation loss decreased (0.509266 --> 0.491957).  Saving model ...
	 Train_Loss: 0.5290 Train_Acc: 74.903 Val_Loss: 0.4920  BEST VAL Loss: 0.4920  Val_Acc: 76.531

Epoch 2: Validation loss decreased (0.491957 --> 0.482677).  Saving model ...
	 Train_Loss: 0.5106 Train_Acc: 76.225 Val_Loss: 0.4827  BEST VAL Loss: 0.4827  Val_Acc: 77.157

Epoch 3: Validation loss decreased (0.482677 --> 0.476641).  Saving model ...
	 Train_Loss: 0.4988 Train_Acc: 76.857 Val_Loss: 0.4766  BEST VAL Loss: 0.4766  Val_Acc: 77.486

Epoch 4: Validation loss decreased (0.476641 --> 0.472743).  Saving model ...
	 Train_Loss: 0.4902 Train_Acc: 77.348 Val_Loss: 0.4727  BEST VAL Loss: 0.4727  Val_Acc: 77.378

Epoch 5: Validation loss decreased (0.472743 --> 0.468005).  Saving model ...
	 Train_Loss: 0.4833 Train_Acc: 77.756 Val_Loss: 0.4680  BEST VAL Loss: 0.4680  Val_Acc: 77.999

Epoch 6: Validation loss decreased (0.468005 --> 0.464319).  Saving model ...
	 Train_Loss: 0.4774 Train_Acc: 78.231 Val_Loss: 0.4643  BEST VAL Loss: 0.4643  Val_Acc: 78.059

Epoch 7: Validation loss decreased (0.464319 --> 0.461277).  Saving model ...
	 Train_Loss: 0.4725 Train_Acc: 78.360 Val_Loss: 0.4613  BEST VAL Loss: 0.4613  Val_Acc: 78.183

Epoch 8: Validation loss decreased (0.461277 --> 0.458863).  Saving model ...
	 Train_Loss: 0.4684 Train_Acc: 78.577 Val_Loss: 0.4589  BEST VAL Loss: 0.4589  Val_Acc: 78.350

Epoch 9: Validation loss decreased (0.458863 --> 0.456193).  Saving model ...
	 Train_Loss: 0.4648 Train_Acc: 78.716 Val_Loss: 0.4562  BEST VAL Loss: 0.4562  Val_Acc: 78.593

Epoch 10: Validation loss decreased (0.456193 --> 0.453947).  Saving model ...
	 Train_Loss: 0.4615 Train_Acc: 78.920 Val_Loss: 0.4539  BEST VAL Loss: 0.4539  Val_Acc: 78.804

Epoch 11: Validation loss decreased (0.453947 --> 0.452485).  Saving model ...
	 Train_Loss: 0.4585 Train_Acc: 79.130 Val_Loss: 0.4525  BEST VAL Loss: 0.4525  Val_Acc: 78.242

Epoch 12: Validation loss decreased (0.452485 --> 0.451028).  Saving model ...
	 Train_Loss: 0.4559 Train_Acc: 79.152 Val_Loss: 0.4510  BEST VAL Loss: 0.4510  Val_Acc: 78.544

Epoch 13: Validation loss decreased (0.451028 --> 0.449486).  Saving model ...
	 Train_Loss: 0.4534 Train_Acc: 79.356 Val_Loss: 0.4495  BEST VAL Loss: 0.4495  Val_Acc: 78.814

Epoch 14: Validation loss decreased (0.449486 --> 0.448764).  Saving model ...
	 Train_Loss: 0.4512 Train_Acc: 79.387 Val_Loss: 0.4488  BEST VAL Loss: 0.4488  Val_Acc: 78.323

Epoch 15: Validation loss decreased (0.448764 --> 0.447779).  Saving model ...
	 Train_Loss: 0.4492 Train_Acc: 79.554 Val_Loss: 0.4478  BEST VAL Loss: 0.4478  Val_Acc: 78.507

Epoch 16: Validation loss decreased (0.447779 --> 0.446686).  Saving model ...
	 Train_Loss: 0.4473 Train_Acc: 79.607 Val_Loss: 0.4467  BEST VAL Loss: 0.4467  Val_Acc: 78.631

Epoch 17: Validation loss decreased (0.446686 --> 0.445281).  Saving model ...
	 Train_Loss: 0.4455 Train_Acc: 79.759 Val_Loss: 0.4453  BEST VAL Loss: 0.4453  Val_Acc: 79.322

Epoch 18: Validation loss decreased (0.445281 --> 0.444623).  Saving model ...
	 Train_Loss: 0.4437 Train_Acc: 79.877 Val_Loss: 0.4446  BEST VAL Loss: 0.4446  Val_Acc: 78.469

Epoch 19: Validation loss decreased (0.444623 --> 0.443697).  Saving model ...
	 Train_Loss: 0.4421 Train_Acc: 79.871 Val_Loss: 0.4437  BEST VAL Loss: 0.4437  Val_Acc: 79.165

Epoch 20: Validation loss decreased (0.443697 --> 0.442868).  Saving model ...
	 Train_Loss: 0.4406 Train_Acc: 79.960 Val_Loss: 0.4429  BEST VAL Loss: 0.4429  Val_Acc: 78.782

Epoch 21: Validation loss decreased (0.442868 --> 0.442233).  Saving model ...
	 Train_Loss: 0.4392 Train_Acc: 80.082 Val_Loss: 0.4422  BEST VAL Loss: 0.4422  Val_Acc: 78.836

Epoch 22: Validation loss decreased (0.442233 --> 0.441777).  Saving model ...
	 Train_Loss: 0.4378 Train_Acc: 79.955 Val_Loss: 0.4418  BEST VAL Loss: 0.4418  Val_Acc: 78.469

Epoch 23: Validation loss decreased (0.441777 --> 0.441197).  Saving model ...
	 Train_Loss: 0.4366 Train_Acc: 80.039 Val_Loss: 0.4412  BEST VAL Loss: 0.4412  Val_Acc: 78.960

Epoch 24: Validation loss decreased (0.441197 --> 0.440669).  Saving model ...
	 Train_Loss: 0.4354 Train_Acc: 80.138 Val_Loss: 0.4407  BEST VAL Loss: 0.4407  Val_Acc: 78.858

Epoch 25: Validation loss decreased (0.440669 --> 0.439997).  Saving model ...
	 Train_Loss: 0.4342 Train_Acc: 80.214 Val_Loss: 0.4400  BEST VAL Loss: 0.4400  Val_Acc: 79.182

Epoch 26: Validation loss decreased (0.439997 --> 0.439486).  Saving model ...
	 Train_Loss: 0.4331 Train_Acc: 80.242 Val_Loss: 0.4395  BEST VAL Loss: 0.4395  Val_Acc: 79.225

Epoch 27: Validation loss decreased (0.439486 --> 0.438881).  Saving model ...
	 Train_Loss: 0.4320 Train_Acc: 80.248 Val_Loss: 0.4389  BEST VAL Loss: 0.4389  Val_Acc: 79.257

Epoch 28: Validation loss decreased (0.438881 --> 0.438412).  Saving model ...
	 Train_Loss: 0.4310 Train_Acc: 80.251 Val_Loss: 0.4384  BEST VAL Loss: 0.4384  Val_Acc: 79.316

Epoch 29: Validation loss decreased (0.438412 --> 0.438125).  Saving model ...
	 Train_Loss: 0.4301 Train_Acc: 80.383 Val_Loss: 0.4381  BEST VAL Loss: 0.4381  Val_Acc: 79.149

Epoch 30: Validation loss decreased (0.438125 --> 0.437531).  Saving model ...
	 Train_Loss: 0.4291 Train_Acc: 80.444 Val_Loss: 0.4375  BEST VAL Loss: 0.4375  Val_Acc: 79.543

Epoch 31: Validation loss decreased (0.437531 --> 0.437392).  Saving model ...
	 Train_Loss: 0.4282 Train_Acc: 80.475 Val_Loss: 0.4374  BEST VAL Loss: 0.4374  Val_Acc: 78.777

Epoch 32: Validation loss decreased (0.437392 --> 0.436879).  Saving model ...
	 Train_Loss: 0.4273 Train_Acc: 80.535 Val_Loss: 0.4369  BEST VAL Loss: 0.4369  Val_Acc: 79.419

Epoch 33: Validation loss decreased (0.436879 --> 0.436531).  Saving model ...
	 Train_Loss: 0.4265 Train_Acc: 80.497 Val_Loss: 0.4365  BEST VAL Loss: 0.4365  Val_Acc: 79.478

Epoch 34: Validation loss decreased (0.436531 --> 0.436102).  Saving model ...
	 Train_Loss: 0.4257 Train_Acc: 80.588 Val_Loss: 0.4361  BEST VAL Loss: 0.4361  Val_Acc: 79.516

Epoch 35: Validation loss decreased (0.436102 --> 0.435835).  Saving model ...
	 Train_Loss: 0.4248 Train_Acc: 80.704 Val_Loss: 0.4358  BEST VAL Loss: 0.4358  Val_Acc: 79.214

Epoch 36: Validation loss decreased (0.435835 --> 0.435470).  Saving model ...
	 Train_Loss: 0.4240 Train_Acc: 80.678 Val_Loss: 0.4355  BEST VAL Loss: 0.4355  Val_Acc: 79.527

Epoch 37: Validation loss decreased (0.435470 --> 0.435157).  Saving model ...
	 Train_Loss: 0.4233 Train_Acc: 80.624 Val_Loss: 0.4352  BEST VAL Loss: 0.4352  Val_Acc: 79.516

Epoch 38: Validation loss decreased (0.435157 --> 0.434863).  Saving model ...
	 Train_Loss: 0.4225 Train_Acc: 80.724 Val_Loss: 0.4349  BEST VAL Loss: 0.4349  Val_Acc: 79.333

Epoch 39: Validation loss decreased (0.434863 --> 0.434651).  Saving model ...
	 Train_Loss: 0.4218 Train_Acc: 80.804 Val_Loss: 0.4347  BEST VAL Loss: 0.4347  Val_Acc: 79.252

Epoch 40: Validation loss decreased (0.434651 --> 0.434290).  Saving model ...
	 Train_Loss: 0.4211 Train_Acc: 80.802 Val_Loss: 0.4343  BEST VAL Loss: 0.4343  Val_Acc: 79.657

Epoch 41: Validation loss decreased (0.434290 --> 0.434010).  Saving model ...
	 Train_Loss: 0.4205 Train_Acc: 80.873 Val_Loss: 0.4340  BEST VAL Loss: 0.4340  Val_Acc: 79.651

Epoch 42: Validation loss decreased (0.434010 --> 0.433764).  Saving model ...
	 Train_Loss: 0.4198 Train_Acc: 80.884 Val_Loss: 0.4338  BEST VAL Loss: 0.4338  Val_Acc: 79.457

Epoch 43: Validation loss decreased (0.433764 --> 0.433513).  Saving model ...
	 Train_Loss: 0.4191 Train_Acc: 80.899 Val_Loss: 0.4335  BEST VAL Loss: 0.4335  Val_Acc: 79.522

Epoch 44: Validation loss decreased (0.433513 --> 0.433289).  Saving model ...
	 Train_Loss: 0.4185 Train_Acc: 80.896 Val_Loss: 0.4333  BEST VAL Loss: 0.4333  Val_Acc: 79.581

Epoch 45: Validation loss decreased (0.433289 --> 0.432941).  Saving model ...
	 Train_Loss: 0.4179 Train_Acc: 80.989 Val_Loss: 0.4329  BEST VAL Loss: 0.4329  Val_Acc: 79.711

Epoch 46: Validation loss decreased (0.432941 --> 0.432662).  Saving model ...
	 Train_Loss: 0.4173 Train_Acc: 81.126 Val_Loss: 0.4327  BEST VAL Loss: 0.4327  Val_Acc: 79.505

Epoch 47: Validation loss decreased (0.432662 --> 0.432350).  Saving model ...
	 Train_Loss: 0.4166 Train_Acc: 81.000 Val_Loss: 0.4323  BEST VAL Loss: 0.4323  Val_Acc: 79.397

Epoch 48: Validation loss decreased (0.432350 --> 0.432048).  Saving model ...
	 Train_Loss: 0.4161 Train_Acc: 81.102 Val_Loss: 0.4320  BEST VAL Loss: 0.4320  Val_Acc: 79.905

Epoch 49: Validation loss decreased (0.432048 --> 0.431958).  Saving model ...
	 Train_Loss: 0.4155 Train_Acc: 81.201 Val_Loss: 0.4320  BEST VAL Loss: 0.4320  Val_Acc: 79.495

Epoch 50: Validation loss decreased (0.431958 --> 0.431607).  Saving model ...
	 Train_Loss: 0.4149 Train_Acc: 81.097 Val_Loss: 0.4316  BEST VAL Loss: 0.4316  Val_Acc: 79.770

Epoch 51: Validation loss decreased (0.431607 --> 0.431461).  Saving model ...
	 Train_Loss: 0.4144 Train_Acc: 81.104 Val_Loss: 0.4315  BEST VAL Loss: 0.4315  Val_Acc: 79.657

Epoch 52: Validation loss decreased (0.431461 --> 0.431298).  Saving model ...
	 Train_Loss: 0.4139 Train_Acc: 81.068 Val_Loss: 0.4313  BEST VAL Loss: 0.4313  Val_Acc: 79.657

Epoch 53: Validation loss decreased (0.431298 --> 0.431160).  Saving model ...
	 Train_Loss: 0.4133 Train_Acc: 81.161 Val_Loss: 0.4312  BEST VAL Loss: 0.4312  Val_Acc: 79.829

Epoch 54: Validation loss decreased (0.431160 --> 0.430945).  Saving model ...
	 Train_Loss: 0.4128 Train_Acc: 81.220 Val_Loss: 0.4309  BEST VAL Loss: 0.4309  Val_Acc: 79.856

Epoch 55: Validation loss decreased (0.430945 --> 0.430664).  Saving model ...
	 Train_Loss: 0.4123 Train_Acc: 81.178 Val_Loss: 0.4307  BEST VAL Loss: 0.4307  Val_Acc: 79.846

Epoch 56: Validation loss decreased (0.430664 --> 0.430478).  Saving model ...
	 Train_Loss: 0.4118 Train_Acc: 81.231 Val_Loss: 0.4305  BEST VAL Loss: 0.4305  Val_Acc: 79.505

Epoch 57: Validation loss decreased (0.430478 --> 0.430329).  Saving model ...
	 Train_Loss: 0.4113 Train_Acc: 81.349 Val_Loss: 0.4303  BEST VAL Loss: 0.4303  Val_Acc: 79.937

Epoch 58: Validation loss decreased (0.430329 --> 0.430198).  Saving model ...
	 Train_Loss: 0.4109 Train_Acc: 81.389 Val_Loss: 0.4302  BEST VAL Loss: 0.4302  Val_Acc: 79.511

Epoch 59: Validation loss decreased (0.430198 --> 0.430167).  Saving model ...
	 Train_Loss: 0.4104 Train_Acc: 81.302 Val_Loss: 0.4302  BEST VAL Loss: 0.4302  Val_Acc: 79.608

Epoch 60: Validation loss decreased (0.430167 --> 0.429971).  Saving model ...
	 Train_Loss: 0.4099 Train_Acc: 81.394 Val_Loss: 0.4300  BEST VAL Loss: 0.4300  Val_Acc: 79.954

Epoch 61: Validation loss decreased (0.429971 --> 0.429746).  Saving model ...
	 Train_Loss: 0.4095 Train_Acc: 81.411 Val_Loss: 0.4297  BEST VAL Loss: 0.4297  Val_Acc: 79.700

Epoch 62: Validation loss decreased (0.429746 --> 0.429574).  Saving model ...
	 Train_Loss: 0.4090 Train_Acc: 81.357 Val_Loss: 0.4296  BEST VAL Loss: 0.4296  Val_Acc: 79.759

Epoch 63: Validation loss decreased (0.429574 --> 0.429431).  Saving model ...
	 Train_Loss: 0.4085 Train_Acc: 81.384 Val_Loss: 0.4294  BEST VAL Loss: 0.4294  Val_Acc: 79.900

Epoch 64: Validation loss decreased (0.429431 --> 0.429330).  Saving model ...
	 Train_Loss: 0.4081 Train_Acc: 81.398 Val_Loss: 0.4293  BEST VAL Loss: 0.4293  Val_Acc: 79.716

Epoch 65: Validation loss decreased (0.429330 --> 0.429146).  Saving model ...
	 Train_Loss: 0.4077 Train_Acc: 81.329 Val_Loss: 0.4291  BEST VAL Loss: 0.4291  Val_Acc: 79.991

Epoch 66: Validation loss decreased (0.429146 --> 0.429018).  Saving model ...
	 Train_Loss: 0.4072 Train_Acc: 81.501 Val_Loss: 0.4290  BEST VAL Loss: 0.4290  Val_Acc: 79.981

Epoch 67: Validation loss decreased (0.429018 --> 0.428967).  Saving model ...
	 Train_Loss: 0.4068 Train_Acc: 81.535 Val_Loss: 0.4290  BEST VAL Loss: 0.4290  Val_Acc: 79.505

Epoch 68: Validation loss decreased (0.428967 --> 0.428889).  Saving model ...
	 Train_Loss: 0.4064 Train_Acc: 81.485 Val_Loss: 0.4289  BEST VAL Loss: 0.4289  Val_Acc: 79.932

Epoch 69: Validation loss decreased (0.428889 --> 0.428711).  Saving model ...
	 Train_Loss: 0.4060 Train_Acc: 81.573 Val_Loss: 0.4287  BEST VAL Loss: 0.4287  Val_Acc: 80.056

Epoch 70: Validation loss decreased (0.428711 --> 0.428649).  Saving model ...
	 Train_Loss: 0.4056 Train_Acc: 81.616 Val_Loss: 0.4286  BEST VAL Loss: 0.4286  Val_Acc: 79.846

Epoch 71: Validation loss decreased (0.428649 --> 0.428482).  Saving model ...
	 Train_Loss: 0.4052 Train_Acc: 81.488 Val_Loss: 0.4285  BEST VAL Loss: 0.4285  Val_Acc: 79.954

Epoch 72: Validation loss decreased (0.428482 --> 0.428269).  Saving model ...
	 Train_Loss: 0.4049 Train_Acc: 81.604 Val_Loss: 0.4283  BEST VAL Loss: 0.4283  Val_Acc: 80.121

Epoch 73: Validation loss decreased (0.428269 --> 0.428012).  Saving model ...
	 Train_Loss: 0.4045 Train_Acc: 81.506 Val_Loss: 0.4280  BEST VAL Loss: 0.4280  Val_Acc: 80.245

Epoch 74: Validation loss decreased (0.428012 --> 0.427815).  Saving model ...
	 Train_Loss: 0.4041 Train_Acc: 81.677 Val_Loss: 0.4278  BEST VAL Loss: 0.4278  Val_Acc: 80.094

Epoch 75: Validation loss decreased (0.427815 --> 0.427643).  Saving model ...
	 Train_Loss: 0.4038 Train_Acc: 81.629 Val_Loss: 0.4276  BEST VAL Loss: 0.4276  Val_Acc: 80.202

Epoch 76: Validation loss decreased (0.427643 --> 0.427562).  Saving model ...
	 Train_Loss: 0.4034 Train_Acc: 81.645 Val_Loss: 0.4276  BEST VAL Loss: 0.4276  Val_Acc: 79.635

Epoch 77: Validation loss decreased (0.427562 --> 0.427404).  Saving model ...
	 Train_Loss: 0.4030 Train_Acc: 81.634 Val_Loss: 0.4274  BEST VAL Loss: 0.4274  Val_Acc: 80.105

Epoch 78: Validation loss decreased (0.427404 --> 0.427326).  Saving model ...
	 Train_Loss: 0.4027 Train_Acc: 81.659 Val_Loss: 0.4273  BEST VAL Loss: 0.4273  Val_Acc: 80.024

Epoch 79: Validation loss decreased (0.427326 --> 0.427229).  Saving model ...
	 Train_Loss: 0.4024 Train_Acc: 81.526 Val_Loss: 0.4272  BEST VAL Loss: 0.4272  Val_Acc: 80.267

Epoch 80: Validation loss decreased (0.427229 --> 0.427077).  Saving model ...
	 Train_Loss: 0.4020 Train_Acc: 81.671 Val_Loss: 0.4271  BEST VAL Loss: 0.4271  Val_Acc: 80.213

Epoch 81: Validation loss decreased (0.427077 --> 0.426834).  Saving model ...
	 Train_Loss: 0.4017 Train_Acc: 81.585 Val_Loss: 0.4268  BEST VAL Loss: 0.4268  Val_Acc: 80.645

Epoch 82: Validation loss decreased (0.426834 --> 0.426689).  Saving model ...
	 Train_Loss: 0.4013 Train_Acc: 81.760 Val_Loss: 0.4267  BEST VAL Loss: 0.4267  Val_Acc: 80.202

Epoch 83: Validation loss decreased (0.426689 --> 0.426584).  Saving model ...
	 Train_Loss: 0.4010 Train_Acc: 81.851 Val_Loss: 0.4266  BEST VAL Loss: 0.4266  Val_Acc: 80.159

Epoch 84: Validation loss decreased (0.426584 --> 0.426400).  Saving model ...
	 Train_Loss: 0.4007 Train_Acc: 81.735 Val_Loss: 0.4264  BEST VAL Loss: 0.4264  Val_Acc: 80.278

Epoch 85: Validation loss decreased (0.426400 --> 0.426312).  Saving model ...
	 Train_Loss: 0.4004 Train_Acc: 81.726 Val_Loss: 0.4263  BEST VAL Loss: 0.4263  Val_Acc: 80.213

Epoch 86: Validation loss decreased (0.426312 --> 0.426260).  Saving model ...
	 Train_Loss: 0.4001 Train_Acc: 81.734 Val_Loss: 0.4263  BEST VAL Loss: 0.4263  Val_Acc: 80.256

Epoch 87: Validation loss decreased (0.426260 --> 0.426234).  Saving model ...
	 Train_Loss: 0.3997 Train_Acc: 81.722 Val_Loss: 0.4262  BEST VAL Loss: 0.4262  Val_Acc: 79.873

Epoch 88: Validation loss decreased (0.426234 --> 0.426161).  Saving model ...
	 Train_Loss: 0.3994 Train_Acc: 81.689 Val_Loss: 0.4262  BEST VAL Loss: 0.4262  Val_Acc: 80.251

Epoch 89: Validation loss decreased (0.426161 --> 0.426091).  Saving model ...
	 Train_Loss: 0.3991 Train_Acc: 81.863 Val_Loss: 0.4261  BEST VAL Loss: 0.4261  Val_Acc: 80.288

Epoch 90: Validation loss decreased (0.426091 --> 0.426073).  Saving model ...
	 Train_Loss: 0.3988 Train_Acc: 81.888 Val_Loss: 0.4261  BEST VAL Loss: 0.4261  Val_Acc: 79.813

Epoch 91: Validation loss decreased (0.426073 --> 0.425974).  Saving model ...
	 Train_Loss: 0.3985 Train_Acc: 81.801 Val_Loss: 0.4260  BEST VAL Loss: 0.4260  Val_Acc: 80.272

Epoch 92: Validation loss decreased (0.425974 --> 0.425935).  Saving model ...
	 Train_Loss: 0.3983 Train_Acc: 81.718 Val_Loss: 0.4259  BEST VAL Loss: 0.4259  Val_Acc: 80.256

Epoch 93: Validation loss decreased (0.425935 --> 0.425814).  Saving model ...
	 Train_Loss: 0.3980 Train_Acc: 81.914 Val_Loss: 0.4258  BEST VAL Loss: 0.4258  Val_Acc: 80.234

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.3977 Train_Acc: 81.799 Val_Loss: 0.4258  BEST VAL Loss: 0.4258  Val_Acc: 79.808

Epoch 95: Validation loss decreased (0.425814 --> 0.425799).  Saving model ...
	 Train_Loss: 0.3974 Train_Acc: 81.809 Val_Loss: 0.4258  BEST VAL Loss: 0.4258  Val_Acc: 80.105

Epoch 96: Validation loss did not decrease
	 Train_Loss: 0.3972 Train_Acc: 81.793 Val_Loss: 0.4258  BEST VAL Loss: 0.4258  Val_Acc: 79.862

Epoch 97: Validation loss did not decrease
	 Train_Loss: 0.3969 Train_Acc: 81.805 Val_Loss: 0.4258  BEST VAL Loss: 0.4258  Val_Acc: 80.153

Epoch 98: Validation loss decreased (0.425799 --> 0.425719).  Saving model ...
	 Train_Loss: 0.3966 Train_Acc: 81.927 Val_Loss: 0.4257  BEST VAL Loss: 0.4257  Val_Acc: 80.445

Epoch 99: Validation loss decreased (0.425719 --> 0.425649).  Saving model ...
	 Train_Loss: 0.3964 Train_Acc: 81.926 Val_Loss: 0.4256  BEST VAL Loss: 0.4256  Val_Acc: 80.294

LPS_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.81      0.67      0.73     50422
           1       0.84      0.92      0.88     97754

    accuracy                           0.83    148176
   macro avg       0.83      0.80      0.81    148176
weighted avg       0.83      0.83      0.83    148176

LPS_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.75      0.63      0.68      6303
           1       0.82      0.89      0.86     12219

    accuracy                           0.80     18522
   macro avg       0.79      0.76      0.77     18522
weighted avg       0.80      0.80      0.80     18522

LPS_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.77      0.63      0.69      6303
           1       0.83      0.90      0.86     12219

    accuracy                           0.81     18522
   macro avg       0.80      0.77      0.78     18522
weighted avg       0.81      0.81      0.80     18522

              precision    recall  f1-score   support

           0       0.77      0.63      0.69      6303
           1       0.83      0.90      0.86     12219

    accuracy                           0.81     18522
   macro avg       0.80      0.77      0.78     18522
weighted avg       0.81      0.81      0.80     18522

LPS_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.70      0.53      0.60     32887
           1       0.66      0.80      0.72     37243

    accuracy                           0.67     70130
   macro avg       0.68      0.66      0.66     70130
weighted avg       0.68      0.67      0.67     70130

              precision    recall  f1-score   support

           0       0.70      0.53      0.60     32887
           1       0.66      0.80      0.72     37243

    accuracy                           0.67     70130
   macro avg       0.68      0.66      0.66     70130
weighted avg       0.68      0.67      0.67     70130

completed
