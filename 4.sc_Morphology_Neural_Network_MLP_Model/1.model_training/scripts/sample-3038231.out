[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'eda69584'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '9d476798'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '90792000'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'a93b9d85'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: LPS_10.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: LPS_10.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (30462, 1276)
Number of total missing values across all columns: 33620
Data Subset Is Off
Wells held out for testing: ['E20' 'L16']
Wells to use for training, validation, and testing ['E16' 'E17' 'E21' 'L17' 'L20' 'L21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.224377).  Saving model ...
	 Train_Loss: 0.4532 Train_Acc: 78.317 Val_Loss: 0.2244  BEST VAL Loss: 0.2244  Val_Acc: 92.113

Epoch 1: Validation loss decreased (0.224377 --> 0.207072).  Saving model ...
	 Train_Loss: 0.3681 Train_Acc: 88.660 Val_Loss: 0.2071  BEST VAL Loss: 0.2071  Val_Acc: 93.531

Epoch 2: Validation loss decreased (0.207072 --> 0.190762).  Saving model ...
	 Train_Loss: 0.3202 Train_Acc: 90.765 Val_Loss: 0.1908  BEST VAL Loss: 0.1908  Val_Acc: 94.329

Epoch 3: Validation loss decreased (0.190762 --> 0.179159).  Saving model ...
	 Train_Loss: 0.2863 Train_Acc: 92.416 Val_Loss: 0.1792  BEST VAL Loss: 0.1792  Val_Acc: 94.417

Epoch 4: Validation loss decreased (0.179159 --> 0.168172).  Saving model ...
	 Train_Loss: 0.2609 Train_Acc: 93.280 Val_Loss: 0.1682  BEST VAL Loss: 0.1682  Val_Acc: 94.860

Epoch 5: Validation loss decreased (0.168172 --> 0.158929).  Saving model ...
	 Train_Loss: 0.2404 Train_Acc: 93.834 Val_Loss: 0.1589  BEST VAL Loss: 0.1589  Val_Acc: 96.234

Epoch 6: Validation loss decreased (0.158929 --> 0.152786).  Saving model ...
	 Train_Loss: 0.2246 Train_Acc: 94.344 Val_Loss: 0.1528  BEST VAL Loss: 0.1528  Val_Acc: 95.747

Epoch 7: Validation loss decreased (0.152786 --> 0.148772).  Saving model ...
	 Train_Loss: 0.2121 Train_Acc: 94.560 Val_Loss: 0.1488  BEST VAL Loss: 0.1488  Val_Acc: 96.012

Epoch 8: Validation loss decreased (0.148772 --> 0.144083).  Saving model ...
	 Train_Loss: 0.2021 Train_Acc: 94.770 Val_Loss: 0.1441  BEST VAL Loss: 0.1441  Val_Acc: 96.323

Epoch 9: Validation loss decreased (0.144083 --> 0.139296).  Saving model ...
	 Train_Loss: 0.1925 Train_Acc: 95.574 Val_Loss: 0.1393  BEST VAL Loss: 0.1393  Val_Acc: 96.588

Epoch 10: Validation loss decreased (0.139296 --> 0.135333).  Saving model ...
	 Train_Loss: 0.1842 Train_Acc: 95.729 Val_Loss: 0.1353  BEST VAL Loss: 0.1353  Val_Acc: 96.721

Epoch 11: Validation loss decreased (0.135333 --> 0.132666).  Saving model ...
	 Train_Loss: 0.1771 Train_Acc: 95.939 Val_Loss: 0.1327  BEST VAL Loss: 0.1327  Val_Acc: 96.588

Epoch 12: Validation loss decreased (0.132666 --> 0.129948).  Saving model ...
	 Train_Loss: 0.1705 Train_Acc: 96.161 Val_Loss: 0.1299  BEST VAL Loss: 0.1299  Val_Acc: 96.411

Epoch 13: Validation loss decreased (0.129948 --> 0.127336).  Saving model ...
	 Train_Loss: 0.1646 Train_Acc: 96.333 Val_Loss: 0.1273  BEST VAL Loss: 0.1273  Val_Acc: 97.076

Epoch 14: Validation loss decreased (0.127336 --> 0.125318).  Saving model ...
	 Train_Loss: 0.1592 Train_Acc: 96.366 Val_Loss: 0.1253  BEST VAL Loss: 0.1253  Val_Acc: 96.899

Epoch 15: Validation loss decreased (0.125318 --> 0.123797).  Saving model ...
	 Train_Loss: 0.1544 Train_Acc: 96.709 Val_Loss: 0.1238  BEST VAL Loss: 0.1238  Val_Acc: 96.810

Epoch 16: Validation loss did not decrease
	 Train_Loss: 0.1500 Train_Acc: 96.432 Val_Loss: 0.1242  BEST VAL Loss: 0.1238  Val_Acc: 96.190

Epoch 17: Validation loss decreased (0.123797 --> 0.122706).  Saving model ...
	 Train_Loss: 0.1462 Train_Acc: 96.632 Val_Loss: 0.1227  BEST VAL Loss: 0.1227  Val_Acc: 96.766

Epoch 18: Validation loss decreased (0.122706 --> 0.121377).  Saving model ...
	 Train_Loss: 0.1424 Train_Acc: 96.576 Val_Loss: 0.1214  BEST VAL Loss: 0.1214  Val_Acc: 97.031

Epoch 19: Validation loss decreased (0.121377 --> 0.120114).  Saving model ...
	 Train_Loss: 0.1388 Train_Acc: 96.876 Val_Loss: 0.1201  BEST VAL Loss: 0.1201  Val_Acc: 96.854

Epoch 20: Validation loss decreased (0.120114 --> 0.119352).  Saving model ...
	 Train_Loss: 0.1356 Train_Acc: 96.643 Val_Loss: 0.1194  BEST VAL Loss: 0.1194  Val_Acc: 96.677

Epoch 21: Validation loss decreased (0.119352 --> 0.118977).  Saving model ...
	 Train_Loss: 0.1333 Train_Acc: 96.687 Val_Loss: 0.1190  BEST VAL Loss: 0.1190  Val_Acc: 96.278

Epoch 22: Validation loss decreased (0.118977 --> 0.118263).  Saving model ...
	 Train_Loss: 0.1310 Train_Acc: 96.366 Val_Loss: 0.1183  BEST VAL Loss: 0.1183  Val_Acc: 96.899

Epoch 23: Validation loss did not decrease
	 Train_Loss: 0.1284 Train_Acc: 96.587 Val_Loss: 0.1184  BEST VAL Loss: 0.1183  Val_Acc: 96.810

Epoch 24: Validation loss decreased (0.118263 --> 0.117545).  Saving model ...
	 Train_Loss: 0.1261 Train_Acc: 96.809 Val_Loss: 0.1175  BEST VAL Loss: 0.1175  Val_Acc: 96.854

Epoch 25: Validation loss decreased (0.117545 --> 0.116542).  Saving model ...
	 Train_Loss: 0.1237 Train_Acc: 96.864 Val_Loss: 0.1165  BEST VAL Loss: 0.1165  Val_Acc: 97.164

Epoch 26: Validation loss decreased (0.116542 --> 0.115952).  Saving model ...
	 Train_Loss: 0.1219 Train_Acc: 96.388 Val_Loss: 0.1160  BEST VAL Loss: 0.1160  Val_Acc: 96.810

Epoch 27: Validation loss decreased (0.115952 --> 0.115419).  Saving model ...
	 Train_Loss: 0.1199 Train_Acc: 96.604 Val_Loss: 0.1154  BEST VAL Loss: 0.1154  Val_Acc: 96.411

Epoch 28: Validation loss decreased (0.115419 --> 0.115094).  Saving model ...
	 Train_Loss: 0.1179 Train_Acc: 96.931 Val_Loss: 0.1151  BEST VAL Loss: 0.1151  Val_Acc: 97.253

Epoch 29: Validation loss decreased (0.115094 --> 0.114967).  Saving model ...
	 Train_Loss: 0.1161 Train_Acc: 96.870 Val_Loss: 0.1150  BEST VAL Loss: 0.1150  Val_Acc: 97.297

Epoch 30: Validation loss decreased (0.114967 --> 0.114566).  Saving model ...
	 Train_Loss: 0.1143 Train_Acc: 96.898 Val_Loss: 0.1146  BEST VAL Loss: 0.1146  Val_Acc: 97.120

Epoch 31: Validation loss decreased (0.114566 --> 0.113999).  Saving model ...
	 Train_Loss: 0.1128 Train_Acc: 96.870 Val_Loss: 0.1140  BEST VAL Loss: 0.1140  Val_Acc: 96.987

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.1112 Train_Acc: 96.876 Val_Loss: 0.1141  BEST VAL Loss: 0.1140  Val_Acc: 96.810

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.1096 Train_Acc: 97.047 Val_Loss: 0.1140  BEST VAL Loss: 0.1140  Val_Acc: 96.899

Epoch 34: Validation loss decreased (0.113999 --> 0.113742).  Saving model ...
	 Train_Loss: 0.1081 Train_Acc: 96.887 Val_Loss: 0.1137  BEST VAL Loss: 0.1137  Val_Acc: 97.076

Epoch 35: Validation loss decreased (0.113742 --> 0.113541).  Saving model ...
	 Train_Loss: 0.1068 Train_Acc: 97.164 Val_Loss: 0.1135  BEST VAL Loss: 0.1135  Val_Acc: 97.209

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.1054 Train_Acc: 97.025 Val_Loss: 0.1144  BEST VAL Loss: 0.1135  Val_Acc: 96.633

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.1043 Train_Acc: 97.485 Val_Loss: 0.1142  BEST VAL Loss: 0.1135  Val_Acc: 97.519

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.1030 Train_Acc: 97.574 Val_Loss: 0.1140  BEST VAL Loss: 0.1135  Val_Acc: 97.342

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.1018 Train_Acc: 97.551 Val_Loss: 0.1143  BEST VAL Loss: 0.1135  Val_Acc: 97.076

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.1006 Train_Acc: 97.413 Val_Loss: 0.1142  BEST VAL Loss: 0.1135  Val_Acc: 97.031

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.0998 Train_Acc: 97.130 Val_Loss: 0.1136  BEST VAL Loss: 0.1135  Val_Acc: 97.297

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.0988 Train_Acc: 97.413 Val_Loss: 0.1136  BEST VAL Loss: 0.1135  Val_Acc: 97.076

Epoch 43: Validation loss decreased (0.113541 --> 0.113150).  Saving model ...
	 Train_Loss: 0.0978 Train_Acc: 97.424 Val_Loss: 0.1132  BEST VAL Loss: 0.1132  Val_Acc: 97.253

Epoch 44: Validation loss decreased (0.113150 --> 0.113148).  Saving model ...
	 Train_Loss: 0.0969 Train_Acc: 97.391 Val_Loss: 0.1131  BEST VAL Loss: 0.1131  Val_Acc: 97.164

Epoch 45: Validation loss decreased (0.113148 --> 0.113031).  Saving model ...
	 Train_Loss: 0.0960 Train_Acc: 97.413 Val_Loss: 0.1130  BEST VAL Loss: 0.1130  Val_Acc: 97.209

Epoch 46: Validation loss decreased (0.113031 --> 0.112761).  Saving model ...
	 Train_Loss: 0.0951 Train_Acc: 97.557 Val_Loss: 0.1128  BEST VAL Loss: 0.1128  Val_Acc: 97.386

Epoch 47: Validation loss decreased (0.112761 --> 0.112702).  Saving model ...
	 Train_Loss: 0.0942 Train_Acc: 97.529 Val_Loss: 0.1127  BEST VAL Loss: 0.1127  Val_Acc: 97.164

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.0932 Train_Acc: 97.540 Val_Loss: 0.1128  BEST VAL Loss: 0.1127  Val_Acc: 97.430

Epoch 49: Validation loss decreased (0.112702 --> 0.112519).  Saving model ...
	 Train_Loss: 0.0925 Train_Acc: 97.308 Val_Loss: 0.1125  BEST VAL Loss: 0.1125  Val_Acc: 97.386

Epoch 50: Validation loss decreased (0.112519 --> 0.112363).  Saving model ...
	 Train_Loss: 0.0917 Train_Acc: 97.507 Val_Loss: 0.1124  BEST VAL Loss: 0.1124  Val_Acc: 97.164

Epoch 51: Validation loss decreased (0.112363 --> 0.112262).  Saving model ...
	 Train_Loss: 0.0909 Train_Acc: 97.723 Val_Loss: 0.1123  BEST VAL Loss: 0.1123  Val_Acc: 97.519

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.0901 Train_Acc: 97.607 Val_Loss: 0.1126  BEST VAL Loss: 0.1123  Val_Acc: 97.120

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.0894 Train_Acc: 97.363 Val_Loss: 0.1125  BEST VAL Loss: 0.1123  Val_Acc: 97.297

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.0887 Train_Acc: 97.441 Val_Loss: 0.1126  BEST VAL Loss: 0.1123  Val_Acc: 97.164

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.0880 Train_Acc: 97.712 Val_Loss: 0.1127  BEST VAL Loss: 0.1123  Val_Acc: 96.987

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.0873 Train_Acc: 97.457 Val_Loss: 0.1127  BEST VAL Loss: 0.1123  Val_Acc: 97.164

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.0867 Train_Acc: 97.801 Val_Loss: 0.1130  BEST VAL Loss: 0.1123  Val_Acc: 97.297

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.0861 Train_Acc: 97.374 Val_Loss: 0.1130  BEST VAL Loss: 0.1123  Val_Acc: 97.386

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.0855 Train_Acc: 97.479 Val_Loss: 0.1127  BEST VAL Loss: 0.1123  Val_Acc: 97.430

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.0850 Train_Acc: 97.579 Val_Loss: 0.1123  BEST VAL Loss: 0.1123  Val_Acc: 97.253

Epoch 61: Validation loss decreased (0.112262 --> 0.112253).  Saving model ...
	 Train_Loss: 0.0844 Train_Acc: 97.662 Val_Loss: 0.1123  BEST VAL Loss: 0.1123  Val_Acc: 97.209

Epoch 62: Validation loss decreased (0.112253 --> 0.111975).  Saving model ...
	 Train_Loss: 0.0838 Train_Acc: 97.751 Val_Loss: 0.1120  BEST VAL Loss: 0.1120  Val_Acc: 97.209

Epoch 63: Validation loss decreased (0.111975 --> 0.111864).  Saving model ...
	 Train_Loss: 0.0832 Train_Acc: 97.684 Val_Loss: 0.1119  BEST VAL Loss: 0.1119  Val_Acc: 97.563

Epoch 64: Validation loss decreased (0.111864 --> 0.111771).  Saving model ...
	 Train_Loss: 0.0826 Train_Acc: 97.513 Val_Loss: 0.1118  BEST VAL Loss: 0.1118  Val_Acc: 97.209

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.0821 Train_Acc: 97.695 Val_Loss: 0.1118  BEST VAL Loss: 0.1118  Val_Acc: 97.253

Epoch 66: Validation loss decreased (0.111771 --> 0.111771).  Saving model ...
	 Train_Loss: 0.0816 Train_Acc: 97.607 Val_Loss: 0.1118  BEST VAL Loss: 0.1118  Val_Acc: 97.342

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.0812 Train_Acc: 97.457 Val_Loss: 0.1118  BEST VAL Loss: 0.1118  Val_Acc: 97.297

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.0807 Train_Acc: 97.690 Val_Loss: 0.1118  BEST VAL Loss: 0.1118  Val_Acc: 97.430

Epoch 69: Validation loss decreased (0.111771 --> 0.111360).  Saving model ...
	 Train_Loss: 0.0804 Train_Acc: 97.335 Val_Loss: 0.1114  BEST VAL Loss: 0.1114  Val_Acc: 96.899

Epoch 70: Validation loss decreased (0.111360 --> 0.111238).  Saving model ...
	 Train_Loss: 0.0803 Train_Acc: 97.291 Val_Loss: 0.1112  BEST VAL Loss: 0.1112  Val_Acc: 96.721

Epoch 71: Validation loss decreased (0.111238 --> 0.111021).  Saving model ...
	 Train_Loss: 0.0801 Train_Acc: 96.964 Val_Loss: 0.1110  BEST VAL Loss: 0.1110  Val_Acc: 96.899

Epoch 72: Validation loss decreased (0.111021 --> 0.110771).  Saving model ...
	 Train_Loss: 0.0797 Train_Acc: 97.402 Val_Loss: 0.1108  BEST VAL Loss: 0.1108  Val_Acc: 96.766

Epoch 73: Validation loss decreased (0.110771 --> 0.110495).  Saving model ...
	 Train_Loss: 0.0793 Train_Acc: 97.596 Val_Loss: 0.1105  BEST VAL Loss: 0.1105  Val_Acc: 97.164

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.0789 Train_Acc: 97.507 Val_Loss: 0.1106  BEST VAL Loss: 0.1105  Val_Acc: 97.386

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.0785 Train_Acc: 97.856 Val_Loss: 0.1112  BEST VAL Loss: 0.1105  Val_Acc: 96.854

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.0782 Train_Acc: 97.452 Val_Loss: 0.1113  BEST VAL Loss: 0.1105  Val_Acc: 97.031

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.0779 Train_Acc: 97.402 Val_Loss: 0.1110  BEST VAL Loss: 0.1105  Val_Acc: 97.297

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.0775 Train_Acc: 97.540 Val_Loss: 0.1109  BEST VAL Loss: 0.1105  Val_Acc: 97.297

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.0771 Train_Acc: 97.546 Val_Loss: 0.1107  BEST VAL Loss: 0.1105  Val_Acc: 97.076

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.0767 Train_Acc: 98.078 Val_Loss: 0.1109  BEST VAL Loss: 0.1105  Val_Acc: 97.120

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.0764 Train_Acc: 97.180 Val_Loss: 0.1110  BEST VAL Loss: 0.1105  Val_Acc: 97.120

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.0761 Train_Acc: 97.540 Val_Loss: 0.1111  BEST VAL Loss: 0.1105  Val_Acc: 97.386

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.0758 Train_Acc: 97.629 Val_Loss: 0.1113  BEST VAL Loss: 0.1105  Val_Acc: 97.120

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.0754 Train_Acc: 97.562 Val_Loss: 0.1114  BEST VAL Loss: 0.1105  Val_Acc: 97.120

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.0750 Train_Acc: 97.895 Val_Loss: 0.1115  BEST VAL Loss: 0.1105  Val_Acc: 97.430

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.0747 Train_Acc: 97.806 Val_Loss: 0.1117  BEST VAL Loss: 0.1105  Val_Acc: 97.519

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.0744 Train_Acc: 97.706 Val_Loss: 0.1119  BEST VAL Loss: 0.1105  Val_Acc: 97.120

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.0740 Train_Acc: 97.745 Val_Loss: 0.1119  BEST VAL Loss: 0.1105  Val_Acc: 97.475

Epoch 89: Validation loss did not decrease
Early stopped at epoch : 89
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      1.00      1.00     10113
           1       1.00      0.99      0.99      7938

    accuracy                           0.99     18051
   macro avg       1.00      0.99      0.99     18051
weighted avg       0.99      0.99      0.99     18051

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.98      0.97      1264
           1       0.98      0.96      0.97       993

    accuracy                           0.97      2257
   macro avg       0.97      0.97      0.97      2257
weighted avg       0.97      0.97      0.97      2257

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.96      0.98      0.97      1265
           1       0.98      0.95      0.96       992

    accuracy                           0.97      2257
   macro avg       0.97      0.97      0.97      2257
weighted avg       0.97      0.97      0.97      2257

              precision    recall  f1-score   support

           0       0.96      0.98      0.97      1265
           1       0.98      0.95      0.96       992

    accuracy                           0.97      2257
   macro avg       0.97      0.97      0.97      2257
weighted avg       0.97      0.97      0.97      2257

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.92      0.99      0.95      4168
           1       0.98      0.90      0.94      3729

    accuracy                           0.95      7897
   macro avg       0.95      0.94      0.95      7897
weighted avg       0.95      0.95      0.95      7897

              precision    recall  f1-score   support

           0       0.92      0.99      0.95      4168
           1       0.98      0.90      0.94      3729

    accuracy                           0.95      7897
   macro avg       0.95      0.94      0.95      7897
weighted avg       0.95      0.95      0.95      7897

completed
