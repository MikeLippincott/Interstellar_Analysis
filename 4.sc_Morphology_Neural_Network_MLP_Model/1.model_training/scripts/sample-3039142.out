[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ebd90d7c'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'b5a0ef5c'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'bec47e25'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '711de47d'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_0.100_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_0.100_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_0.100_DMSO_0.025']
The dimensions of the data are: (281677, 1270)
Number of total missing values across all columns: 563354
Data Subset Is Off
Wells held out for testing: ['B08' 'C08']
Wells to use for training, validation, and testing ['B02' 'C02' 'B03' 'C03' 'B09' 'C09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.685167).  Saving model ...
	 Train_Loss: 0.6903 Train_Acc: 52.375 Val_Loss: 0.6852  BEST VAL Loss: 0.6852  Val_Acc: 54.224

Epoch 1: Validation loss decreased (0.685167 --> 0.683192).  Saving model ...
	 Train_Loss: 0.6867 Train_Acc: 54.490 Val_Loss: 0.6832  BEST VAL Loss: 0.6832  Val_Acc: 55.205

Epoch 2: Validation loss decreased (0.683192 --> 0.681172).  Saving model ...
	 Train_Loss: 0.6843 Train_Acc: 55.476 Val_Loss: 0.6812  BEST VAL Loss: 0.6812  Val_Acc: 55.924

Epoch 3: Validation loss decreased (0.681172 --> 0.679047).  Saving model ...
	 Train_Loss: 0.6819 Train_Acc: 56.482 Val_Loss: 0.6790  BEST VAL Loss: 0.6790  Val_Acc: 57.367

Epoch 4: Validation loss decreased (0.679047 --> 0.676971).  Saving model ...
	 Train_Loss: 0.6796 Train_Acc: 57.216 Val_Loss: 0.6770  BEST VAL Loss: 0.6770  Val_Acc: 57.552

Epoch 5: Validation loss decreased (0.676971 --> 0.674950).  Saving model ...
	 Train_Loss: 0.6775 Train_Acc: 57.657 Val_Loss: 0.6750  BEST VAL Loss: 0.6750  Val_Acc: 58.619

Epoch 6: Validation loss decreased (0.674950 --> 0.672885).  Saving model ...
	 Train_Loss: 0.6754 Train_Acc: 58.487 Val_Loss: 0.6729  BEST VAL Loss: 0.6729  Val_Acc: 59.181

Epoch 7: Validation loss decreased (0.672885 --> 0.670845).  Saving model ...
	 Train_Loss: 0.6735 Train_Acc: 58.865 Val_Loss: 0.6708  BEST VAL Loss: 0.6708  Val_Acc: 59.733

Epoch 8: Validation loss decreased (0.670845 --> 0.668996).  Saving model ...
	 Train_Loss: 0.6717 Train_Acc: 59.214 Val_Loss: 0.6690  BEST VAL Loss: 0.6690  Val_Acc: 60.043

Epoch 9: Validation loss decreased (0.668996 --> 0.667183).  Saving model ...
	 Train_Loss: 0.6701 Train_Acc: 59.610 Val_Loss: 0.6672  BEST VAL Loss: 0.6672  Val_Acc: 60.810

Epoch 10: Validation loss decreased (0.667183 --> 0.665517).  Saving model ...
	 Train_Loss: 0.6684 Train_Acc: 59.988 Val_Loss: 0.6655  BEST VAL Loss: 0.6655  Val_Acc: 60.914

Epoch 11: Validation loss decreased (0.665517 --> 0.663912).  Saving model ...
	 Train_Loss: 0.6668 Train_Acc: 60.376 Val_Loss: 0.6639  BEST VAL Loss: 0.6639  Val_Acc: 61.014

Epoch 12: Validation loss decreased (0.663912 --> 0.662248).  Saving model ...
	 Train_Loss: 0.6653 Train_Acc: 60.567 Val_Loss: 0.6622  BEST VAL Loss: 0.6622  Val_Acc: 61.386

Epoch 13: Validation loss decreased (0.662248 --> 0.660680).  Saving model ...
	 Train_Loss: 0.6639 Train_Acc: 60.898 Val_Loss: 0.6607  BEST VAL Loss: 0.6607  Val_Acc: 61.819

Epoch 14: Validation loss decreased (0.660680 --> 0.659133).  Saving model ...
	 Train_Loss: 0.6625 Train_Acc: 61.184 Val_Loss: 0.6591  BEST VAL Loss: 0.6591  Val_Acc: 62.210

Epoch 15: Validation loss decreased (0.659133 --> 0.657723).  Saving model ...
	 Train_Loss: 0.6611 Train_Acc: 61.389 Val_Loss: 0.6577  BEST VAL Loss: 0.6577  Val_Acc: 62.076

Epoch 16: Validation loss decreased (0.657723 --> 0.656362).  Saving model ...
	 Train_Loss: 0.6598 Train_Acc: 61.569 Val_Loss: 0.6564  BEST VAL Loss: 0.6564  Val_Acc: 62.510

Epoch 17: Validation loss decreased (0.656362 --> 0.655093).  Saving model ...
	 Train_Loss: 0.6586 Train_Acc: 61.898 Val_Loss: 0.6551  BEST VAL Loss: 0.6551  Val_Acc: 62.729

Epoch 18: Validation loss decreased (0.655093 --> 0.653799).  Saving model ...
	 Train_Loss: 0.6574 Train_Acc: 62.020 Val_Loss: 0.6538  BEST VAL Loss: 0.6538  Val_Acc: 62.971

Epoch 19: Validation loss decreased (0.653799 --> 0.652559).  Saving model ...
	 Train_Loss: 0.6563 Train_Acc: 62.272 Val_Loss: 0.6526  BEST VAL Loss: 0.6526  Val_Acc: 63.167

Epoch 20: Validation loss decreased (0.652559 --> 0.651366).  Saving model ...
	 Train_Loss: 0.6551 Train_Acc: 62.508 Val_Loss: 0.6514  BEST VAL Loss: 0.6514  Val_Acc: 63.248

Epoch 21: Validation loss decreased (0.651366 --> 0.650317).  Saving model ...
	 Train_Loss: 0.6540 Train_Acc: 62.670 Val_Loss: 0.6503  BEST VAL Loss: 0.6503  Val_Acc: 63.110

Epoch 22: Validation loss decreased (0.650317 --> 0.649284).  Saving model ...
	 Train_Loss: 0.6530 Train_Acc: 62.754 Val_Loss: 0.6493  BEST VAL Loss: 0.6493  Val_Acc: 63.310

Epoch 23: Validation loss decreased (0.649284 --> 0.648223).  Saving model ...
	 Train_Loss: 0.6520 Train_Acc: 62.916 Val_Loss: 0.6482  BEST VAL Loss: 0.6482  Val_Acc: 63.733

Epoch 24: Validation loss decreased (0.648223 --> 0.647224).  Saving model ...
	 Train_Loss: 0.6511 Train_Acc: 63.112 Val_Loss: 0.6472  BEST VAL Loss: 0.6472  Val_Acc: 63.662

Epoch 25: Validation loss decreased (0.647224 --> 0.646293).  Saving model ...
	 Train_Loss: 0.6501 Train_Acc: 63.052 Val_Loss: 0.6463  BEST VAL Loss: 0.6463  Val_Acc: 63.748

Epoch 26: Validation loss decreased (0.646293 --> 0.645329).  Saving model ...
	 Train_Loss: 0.6492 Train_Acc: 63.357 Val_Loss: 0.6453  BEST VAL Loss: 0.6453  Val_Acc: 64.333

Epoch 27: Validation loss decreased (0.645329 --> 0.644416).  Saving model ...
	 Train_Loss: 0.6482 Train_Acc: 63.546 Val_Loss: 0.6444  BEST VAL Loss: 0.6444  Val_Acc: 64.471

Epoch 28: Validation loss decreased (0.644416 --> 0.643571).  Saving model ...
	 Train_Loss: 0.6473 Train_Acc: 63.690 Val_Loss: 0.6436  BEST VAL Loss: 0.6436  Val_Acc: 64.671

Epoch 29: Validation loss decreased (0.643571 --> 0.642667).  Saving model ...
	 Train_Loss: 0.6465 Train_Acc: 63.739 Val_Loss: 0.6427  BEST VAL Loss: 0.6427  Val_Acc: 64.762

Epoch 30: Validation loss decreased (0.642667 --> 0.641840).  Saving model ...
	 Train_Loss: 0.6457 Train_Acc: 63.646 Val_Loss: 0.6418  BEST VAL Loss: 0.6418  Val_Acc: 64.824

Epoch 31: Validation loss decreased (0.641840 --> 0.641008).  Saving model ...
	 Train_Loss: 0.6448 Train_Acc: 63.806 Val_Loss: 0.6410  BEST VAL Loss: 0.6410  Val_Acc: 64.938

Epoch 32: Validation loss decreased (0.641008 --> 0.640213).  Saving model ...
	 Train_Loss: 0.6440 Train_Acc: 64.062 Val_Loss: 0.6402  BEST VAL Loss: 0.6402  Val_Acc: 65.000

Epoch 33: Validation loss decreased (0.640213 --> 0.639413).  Saving model ...
	 Train_Loss: 0.6432 Train_Acc: 64.254 Val_Loss: 0.6394  BEST VAL Loss: 0.6394  Val_Acc: 65.533

Epoch 34: Validation loss decreased (0.639413 --> 0.638668).  Saving model ...
	 Train_Loss: 0.6424 Train_Acc: 64.350 Val_Loss: 0.6387  BEST VAL Loss: 0.6387  Val_Acc: 65.090

Epoch 35: Validation loss decreased (0.638668 --> 0.637950).  Saving model ...
	 Train_Loss: 0.6417 Train_Acc: 64.380 Val_Loss: 0.6380  BEST VAL Loss: 0.6380  Val_Acc: 65.219

Epoch 36: Validation loss decreased (0.637950 --> 0.637232).  Saving model ...
	 Train_Loss: 0.6409 Train_Acc: 64.578 Val_Loss: 0.6372  BEST VAL Loss: 0.6372  Val_Acc: 65.581

Epoch 37: Validation loss decreased (0.637232 --> 0.636527).  Saving model ...
	 Train_Loss: 0.6402 Train_Acc: 64.595 Val_Loss: 0.6365  BEST VAL Loss: 0.6365  Val_Acc: 65.552

Epoch 38: Validation loss decreased (0.636527 --> 0.635889).  Saving model ...
	 Train_Loss: 0.6395 Train_Acc: 64.453 Val_Loss: 0.6359  BEST VAL Loss: 0.6359  Val_Acc: 65.567

Epoch 39: Validation loss decreased (0.635889 --> 0.635219).  Saving model ...
	 Train_Loss: 0.6388 Train_Acc: 64.738 Val_Loss: 0.6352  BEST VAL Loss: 0.6352  Val_Acc: 66.224

Epoch 40: Validation loss decreased (0.635219 --> 0.634650).  Saving model ...
	 Train_Loss: 0.6381 Train_Acc: 64.743 Val_Loss: 0.6347  BEST VAL Loss: 0.6347  Val_Acc: 65.967

Epoch 41: Validation loss decreased (0.634650 --> 0.634013).  Saving model ...
	 Train_Loss: 0.6374 Train_Acc: 64.890 Val_Loss: 0.6340  BEST VAL Loss: 0.6340  Val_Acc: 66.029

Epoch 42: Validation loss decreased (0.634013 --> 0.633389).  Saving model ...
	 Train_Loss: 0.6367 Train_Acc: 64.888 Val_Loss: 0.6334  BEST VAL Loss: 0.6334  Val_Acc: 66.000

Epoch 43: Validation loss decreased (0.633389 --> 0.632750).  Saving model ...
	 Train_Loss: 0.6360 Train_Acc: 65.009 Val_Loss: 0.6328  BEST VAL Loss: 0.6328  Val_Acc: 66.410

Epoch 44: Validation loss decreased (0.632750 --> 0.632139).  Saving model ...
	 Train_Loss: 0.6354 Train_Acc: 65.005 Val_Loss: 0.6321  BEST VAL Loss: 0.6321  Val_Acc: 66.348

Epoch 45: Validation loss decreased (0.632139 --> 0.631519).  Saving model ...
	 Train_Loss: 0.6348 Train_Acc: 65.057 Val_Loss: 0.6315  BEST VAL Loss: 0.6315  Val_Acc: 66.490

Epoch 46: Validation loss decreased (0.631519 --> 0.630927).  Saving model ...
	 Train_Loss: 0.6342 Train_Acc: 65.152 Val_Loss: 0.6309  BEST VAL Loss: 0.6309  Val_Acc: 66.457

Epoch 47: Validation loss decreased (0.630927 --> 0.630329).  Saving model ...
	 Train_Loss: 0.6336 Train_Acc: 65.179 Val_Loss: 0.6303  BEST VAL Loss: 0.6303  Val_Acc: 66.467

Epoch 48: Validation loss decreased (0.630329 --> 0.629795).  Saving model ...
	 Train_Loss: 0.6330 Train_Acc: 65.172 Val_Loss: 0.6298  BEST VAL Loss: 0.6298  Val_Acc: 66.119

Epoch 49: Validation loss decreased (0.629795 --> 0.629234).  Saving model ...
	 Train_Loss: 0.6324 Train_Acc: 65.350 Val_Loss: 0.6292  BEST VAL Loss: 0.6292  Val_Acc: 66.381

Epoch 50: Validation loss decreased (0.629234 --> 0.628677).  Saving model ...
	 Train_Loss: 0.6318 Train_Acc: 65.274 Val_Loss: 0.6287  BEST VAL Loss: 0.6287  Val_Acc: 66.752

Epoch 51: Validation loss decreased (0.628677 --> 0.628172).  Saving model ...
	 Train_Loss: 0.6312 Train_Acc: 65.289 Val_Loss: 0.6282  BEST VAL Loss: 0.6282  Val_Acc: 66.838

Epoch 52: Validation loss decreased (0.628172 --> 0.627660).  Saving model ...
	 Train_Loss: 0.6307 Train_Acc: 65.497 Val_Loss: 0.6277  BEST VAL Loss: 0.6277  Val_Acc: 66.876

Epoch 53: Validation loss decreased (0.627660 --> 0.627132).  Saving model ...
	 Train_Loss: 0.6301 Train_Acc: 65.477 Val_Loss: 0.6271  BEST VAL Loss: 0.6271  Val_Acc: 66.843

Epoch 54: Validation loss decreased (0.627132 --> 0.626666).  Saving model ...
	 Train_Loss: 0.6296 Train_Acc: 65.463 Val_Loss: 0.6267  BEST VAL Loss: 0.6267  Val_Acc: 66.819

Epoch 55: Validation loss decreased (0.626666 --> 0.626197).  Saving model ...
	 Train_Loss: 0.6290 Train_Acc: 65.634 Val_Loss: 0.6262  BEST VAL Loss: 0.6262  Val_Acc: 66.938

Epoch 56: Validation loss decreased (0.626197 --> 0.625711).  Saving model ...
	 Train_Loss: 0.6285 Train_Acc: 65.644 Val_Loss: 0.6257  BEST VAL Loss: 0.6257  Val_Acc: 67.014

Epoch 57: Validation loss decreased (0.625711 --> 0.625249).  Saving model ...
	 Train_Loss: 0.6280 Train_Acc: 65.675 Val_Loss: 0.6252  BEST VAL Loss: 0.6252  Val_Acc: 66.819

Epoch 58: Validation loss decreased (0.625249 --> 0.624740).  Saving model ...
	 Train_Loss: 0.6274 Train_Acc: 65.973 Val_Loss: 0.6247  BEST VAL Loss: 0.6247  Val_Acc: 66.933

Epoch 59: Validation loss decreased (0.624740 --> 0.624297).  Saving model ...
	 Train_Loss: 0.6269 Train_Acc: 65.599 Val_Loss: 0.6243  BEST VAL Loss: 0.6243  Val_Acc: 67.181

Epoch 60: Validation loss decreased (0.624297 --> 0.623839).  Saving model ...
	 Train_Loss: 0.6264 Train_Acc: 65.962 Val_Loss: 0.6238  BEST VAL Loss: 0.6238  Val_Acc: 67.057

Epoch 61: Validation loss decreased (0.623839 --> 0.623406).  Saving model ...
	 Train_Loss: 0.6259 Train_Acc: 65.952 Val_Loss: 0.6234  BEST VAL Loss: 0.6234  Val_Acc: 67.295

Epoch 62: Validation loss decreased (0.623406 --> 0.622980).  Saving model ...
	 Train_Loss: 0.6254 Train_Acc: 65.796 Val_Loss: 0.6230  BEST VAL Loss: 0.6230  Val_Acc: 67.181

Epoch 63: Validation loss decreased (0.622980 --> 0.622533).  Saving model ...
	 Train_Loss: 0.6249 Train_Acc: 65.910 Val_Loss: 0.6225  BEST VAL Loss: 0.6225  Val_Acc: 67.448

Epoch 64: Validation loss decreased (0.622533 --> 0.622106).  Saving model ...
	 Train_Loss: 0.6245 Train_Acc: 65.827 Val_Loss: 0.6221  BEST VAL Loss: 0.6221  Val_Acc: 66.971

Epoch 65: Validation loss decreased (0.622106 --> 0.621686).  Saving model ...
	 Train_Loss: 0.6240 Train_Acc: 65.967 Val_Loss: 0.6217  BEST VAL Loss: 0.6217  Val_Acc: 66.905

Epoch 66: Validation loss decreased (0.621686 --> 0.621281).  Saving model ...
	 Train_Loss: 0.6235 Train_Acc: 66.041 Val_Loss: 0.6213  BEST VAL Loss: 0.6213  Val_Acc: 67.348

Epoch 67: Validation loss decreased (0.621281 --> 0.620842).  Saving model ...
	 Train_Loss: 0.6231 Train_Acc: 66.002 Val_Loss: 0.6208  BEST VAL Loss: 0.6208  Val_Acc: 67.500

Epoch 68: Validation loss decreased (0.620842 --> 0.620409).  Saving model ...
	 Train_Loss: 0.6227 Train_Acc: 65.982 Val_Loss: 0.6204  BEST VAL Loss: 0.6204  Val_Acc: 67.533

Epoch 69: Validation loss decreased (0.620409 --> 0.619996).  Saving model ...
	 Train_Loss: 0.6222 Train_Acc: 65.953 Val_Loss: 0.6200  BEST VAL Loss: 0.6200  Val_Acc: 67.467

Epoch 70: Validation loss decreased (0.619996 --> 0.619631).  Saving model ...
	 Train_Loss: 0.6218 Train_Acc: 66.062 Val_Loss: 0.6196  BEST VAL Loss: 0.6196  Val_Acc: 67.300

Epoch 71: Validation loss decreased (0.619631 --> 0.619225).  Saving model ...
	 Train_Loss: 0.6214 Train_Acc: 66.207 Val_Loss: 0.6192  BEST VAL Loss: 0.6192  Val_Acc: 67.333

Epoch 72: Validation loss decreased (0.619225 --> 0.618825).  Saving model ...
	 Train_Loss: 0.6209 Train_Acc: 66.164 Val_Loss: 0.6188  BEST VAL Loss: 0.6188  Val_Acc: 67.271

Epoch 73: Validation loss decreased (0.618825 --> 0.618455).  Saving model ...
	 Train_Loss: 0.6205 Train_Acc: 66.119 Val_Loss: 0.6185  BEST VAL Loss: 0.6185  Val_Acc: 67.110

Epoch 74: Validation loss decreased (0.618455 --> 0.618095).  Saving model ...
	 Train_Loss: 0.6201 Train_Acc: 66.214 Val_Loss: 0.6181  BEST VAL Loss: 0.6181  Val_Acc: 67.552

Epoch 75: Validation loss decreased (0.618095 --> 0.617751).  Saving model ...
	 Train_Loss: 0.6197 Train_Acc: 66.268 Val_Loss: 0.6178  BEST VAL Loss: 0.6178  Val_Acc: 67.576

Epoch 76: Validation loss decreased (0.617751 --> 0.617411).  Saving model ...
	 Train_Loss: 0.6193 Train_Acc: 66.283 Val_Loss: 0.6174  BEST VAL Loss: 0.6174  Val_Acc: 67.524

Epoch 77: Validation loss decreased (0.617411 --> 0.617061).  Saving model ...
	 Train_Loss: 0.6189 Train_Acc: 66.430 Val_Loss: 0.6171  BEST VAL Loss: 0.6171  Val_Acc: 67.605

Epoch 78: Validation loss decreased (0.617061 --> 0.616750).  Saving model ...
	 Train_Loss: 0.6185 Train_Acc: 66.448 Val_Loss: 0.6167  BEST VAL Loss: 0.6167  Val_Acc: 67.581

Epoch 79: Validation loss decreased (0.616750 --> 0.616411).  Saving model ...
	 Train_Loss: 0.6181 Train_Acc: 66.400 Val_Loss: 0.6164  BEST VAL Loss: 0.6164  Val_Acc: 67.614

Epoch 80: Validation loss decreased (0.616411 --> 0.616081).  Saving model ...
	 Train_Loss: 0.6177 Train_Acc: 66.425 Val_Loss: 0.6161  BEST VAL Loss: 0.6161  Val_Acc: 67.724

Epoch 81: Validation loss decreased (0.616081 --> 0.615769).  Saving model ...
	 Train_Loss: 0.6174 Train_Acc: 66.291 Val_Loss: 0.6158  BEST VAL Loss: 0.6158  Val_Acc: 67.433

Epoch 82: Validation loss decreased (0.615769 --> 0.615448).  Saving model ...
	 Train_Loss: 0.6170 Train_Acc: 66.425 Val_Loss: 0.6154  BEST VAL Loss: 0.6154  Val_Acc: 67.862

Epoch 83: Validation loss decreased (0.615448 --> 0.615134).  Saving model ...
	 Train_Loss: 0.6167 Train_Acc: 66.422 Val_Loss: 0.6151  BEST VAL Loss: 0.6151  Val_Acc: 67.890

Epoch 84: Validation loss decreased (0.615134 --> 0.614818).  Saving model ...
	 Train_Loss: 0.6163 Train_Acc: 66.537 Val_Loss: 0.6148  BEST VAL Loss: 0.6148  Val_Acc: 67.843

Epoch 85: Validation loss decreased (0.614818 --> 0.614520).  Saving model ...
	 Train_Loss: 0.6159 Train_Acc: 66.328 Val_Loss: 0.6145  BEST VAL Loss: 0.6145  Val_Acc: 67.829

Epoch 86: Validation loss decreased (0.614520 --> 0.614221).  Saving model ...
	 Train_Loss: 0.6156 Train_Acc: 66.581 Val_Loss: 0.6142  BEST VAL Loss: 0.6142  Val_Acc: 67.705

Epoch 87: Validation loss decreased (0.614221 --> 0.613924).  Saving model ...
	 Train_Loss: 0.6152 Train_Acc: 66.546 Val_Loss: 0.6139  BEST VAL Loss: 0.6139  Val_Acc: 68.129

Epoch 88: Validation loss decreased (0.613924 --> 0.613611).  Saving model ...
	 Train_Loss: 0.6149 Train_Acc: 66.448 Val_Loss: 0.6136  BEST VAL Loss: 0.6136  Val_Acc: 67.586

Epoch 89: Validation loss decreased (0.613611 --> 0.613332).  Saving model ...
	 Train_Loss: 0.6146 Train_Acc: 66.424 Val_Loss: 0.6133  BEST VAL Loss: 0.6133  Val_Acc: 68.000

Epoch 90: Validation loss decreased (0.613332 --> 0.613065).  Saving model ...
	 Train_Loss: 0.6142 Train_Acc: 66.777 Val_Loss: 0.6131  BEST VAL Loss: 0.6131  Val_Acc: 67.848

Epoch 91: Validation loss decreased (0.613065 --> 0.612825).  Saving model ...
	 Train_Loss: 0.6139 Train_Acc: 66.583 Val_Loss: 0.6128  BEST VAL Loss: 0.6128  Val_Acc: 67.824

Epoch 92: Validation loss decreased (0.612825 --> 0.612549).  Saving model ...
	 Train_Loss: 0.6136 Train_Acc: 66.601 Val_Loss: 0.6125  BEST VAL Loss: 0.6125  Val_Acc: 67.800

Epoch 93: Validation loss decreased (0.612549 --> 0.612287).  Saving model ...
	 Train_Loss: 0.6133 Train_Acc: 66.636 Val_Loss: 0.6123  BEST VAL Loss: 0.6123  Val_Acc: 67.795

Epoch 94: Validation loss decreased (0.612287 --> 0.612024).  Saving model ...
	 Train_Loss: 0.6129 Train_Acc: 66.694 Val_Loss: 0.6120  BEST VAL Loss: 0.6120  Val_Acc: 67.981

Epoch 95: Validation loss decreased (0.612024 --> 0.611745).  Saving model ...
	 Train_Loss: 0.6126 Train_Acc: 66.408 Val_Loss: 0.6117  BEST VAL Loss: 0.6117  Val_Acc: 67.905

Epoch 96: Validation loss decreased (0.611745 --> 0.611503).  Saving model ...
	 Train_Loss: 0.6123 Train_Acc: 66.488 Val_Loss: 0.6115  BEST VAL Loss: 0.6115  Val_Acc: 67.590

Epoch 97: Validation loss decreased (0.611503 --> 0.611249).  Saving model ...
	 Train_Loss: 0.6120 Train_Acc: 66.600 Val_Loss: 0.6112  BEST VAL Loss: 0.6112  Val_Acc: 67.805

Epoch 98: Validation loss decreased (0.611249 --> 0.611004).  Saving model ...
	 Train_Loss: 0.6118 Train_Acc: 66.528 Val_Loss: 0.6110  BEST VAL Loss: 0.6110  Val_Acc: 67.738

Epoch 99: Validation loss decreased (0.611004 --> 0.610757).  Saving model ...
	 Train_Loss: 0.6115 Train_Acc: 66.649 Val_Loss: 0.6108  BEST VAL Loss: 0.6108  Val_Acc: 68.105

LPS_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.75      0.66      0.70     85025
           1       0.69      0.77      0.73     82968

    accuracy                           0.72    167993
   macro avg       0.72      0.72      0.72    167993
weighted avg       0.72      0.72      0.72    167993

LPS_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.71      0.63      0.67     10629
           1       0.66      0.74      0.69     10371

    accuracy                           0.68     21000
   macro avg       0.68      0.68      0.68     21000
weighted avg       0.68      0.68      0.68     21000

LPS_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.71      0.63      0.67     10629
           1       0.66      0.73      0.69     10371

    accuracy                           0.68     21000
   macro avg       0.68      0.68      0.68     21000
weighted avg       0.68      0.68      0.68     21000

              precision    recall  f1-score   support

           0       0.71      0.63      0.67     10629
           1       0.66      0.73      0.69     10371

    accuracy                           0.68     21000
   macro avg       0.68      0.68      0.68     21000
weighted avg       0.68      0.68      0.68     21000

LPS_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.58      0.32      0.41     36797
           1       0.51      0.76      0.61     34887

    accuracy                           0.53     71684
   macro avg       0.55      0.54      0.51     71684
weighted avg       0.55      0.53      0.51     71684

              precision    recall  f1-score   support

           0       0.58      0.32      0.41     36797
           1       0.51      0.76      0.61     34887

    accuracy                           0.53     71684
   macro avg       0.55      0.54      0.51     71684
weighted avg       0.55      0.53      0.51     71684

completed
