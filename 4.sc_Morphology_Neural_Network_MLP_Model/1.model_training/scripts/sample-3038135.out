[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1fd583cb'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '9b0d8d38'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1ddd9568'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '8b0ab61e'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_0.100_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_0.100_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (319763, 1270)
Number of total missing values across all columns: 277194
Data Subset Is Off
Wells held out for testing: ['C09' 'M09']
Wells to use for training, validation, and testing ['C02' 'C03' 'C08' 'M02' 'M03' 'M08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.223601).  Saving model ...
	 Train_Loss: 0.3169 Train_Acc: 86.270 Val_Loss: 0.2236  BEST VAL Loss: 0.2236  Val_Acc: 90.990

Epoch 1: Validation loss decreased (0.223601 --> 0.212435).  Saving model ...
	 Train_Loss: 0.2834 Train_Acc: 89.532 Val_Loss: 0.2124  BEST VAL Loss: 0.2124  Val_Acc: 92.055

Epoch 2: Validation loss decreased (0.212435 --> 0.204074).  Saving model ...
	 Train_Loss: 0.2675 Train_Acc: 90.096 Val_Loss: 0.2041  BEST VAL Loss: 0.2041  Val_Acc: 92.788

Epoch 3: Validation loss decreased (0.204074 --> 0.200097).  Saving model ...
	 Train_Loss: 0.2574 Train_Acc: 90.469 Val_Loss: 0.2001  BEST VAL Loss: 0.2001  Val_Acc: 92.516

Epoch 4: Validation loss decreased (0.200097 --> 0.195402).  Saving model ...
	 Train_Loss: 0.2495 Train_Acc: 90.856 Val_Loss: 0.1954  BEST VAL Loss: 0.1954  Val_Acc: 93.318

Epoch 5: Validation loss decreased (0.195402 --> 0.191185).  Saving model ...
	 Train_Loss: 0.2437 Train_Acc: 90.969 Val_Loss: 0.1912  BEST VAL Loss: 0.1912  Val_Acc: 93.413

Epoch 6: Validation loss decreased (0.191185 --> 0.188336).  Saving model ...
	 Train_Loss: 0.2390 Train_Acc: 91.178 Val_Loss: 0.1883  BEST VAL Loss: 0.1883  Val_Acc: 93.404

Epoch 7: Validation loss decreased (0.188336 --> 0.185625).  Saving model ...
	 Train_Loss: 0.2353 Train_Acc: 91.274 Val_Loss: 0.1856  BEST VAL Loss: 0.1856  Val_Acc: 93.645

Epoch 8: Validation loss decreased (0.185625 --> 0.183554).  Saving model ...
	 Train_Loss: 0.2319 Train_Acc: 91.422 Val_Loss: 0.1836  BEST VAL Loss: 0.1836  Val_Acc: 93.658

Epoch 9: Validation loss decreased (0.183554 --> 0.181662).  Saving model ...
	 Train_Loss: 0.2291 Train_Acc: 91.439 Val_Loss: 0.1817  BEST VAL Loss: 0.1817  Val_Acc: 93.620

Epoch 10: Validation loss decreased (0.181662 --> 0.179779).  Saving model ...
	 Train_Loss: 0.2266 Train_Acc: 91.446 Val_Loss: 0.1798  BEST VAL Loss: 0.1798  Val_Acc: 93.671

Epoch 11: Validation loss decreased (0.179779 --> 0.178228).  Saving model ...
	 Train_Loss: 0.2244 Train_Acc: 91.570 Val_Loss: 0.1782  BEST VAL Loss: 0.1782  Val_Acc: 93.818

Epoch 12: Validation loss decreased (0.178228 --> 0.176712).  Saving model ...
	 Train_Loss: 0.2225 Train_Acc: 91.592 Val_Loss: 0.1767  BEST VAL Loss: 0.1767  Val_Acc: 93.852

Epoch 13: Validation loss decreased (0.176712 --> 0.175381).  Saving model ...
	 Train_Loss: 0.2206 Train_Acc: 91.818 Val_Loss: 0.1754  BEST VAL Loss: 0.1754  Val_Acc: 93.818

Epoch 14: Validation loss decreased (0.175381 --> 0.174296).  Saving model ...
	 Train_Loss: 0.2189 Train_Acc: 91.746 Val_Loss: 0.1743  BEST VAL Loss: 0.1743  Val_Acc: 93.887

Epoch 15: Validation loss decreased (0.174296 --> 0.172966).  Saving model ...
	 Train_Loss: 0.2174 Train_Acc: 91.842 Val_Loss: 0.1730  BEST VAL Loss: 0.1730  Val_Acc: 93.982

Epoch 16: Validation loss decreased (0.172966 --> 0.171920).  Saving model ...
	 Train_Loss: 0.2160 Train_Acc: 91.850 Val_Loss: 0.1719  BEST VAL Loss: 0.1719  Val_Acc: 93.831

Epoch 17: Validation loss decreased (0.171920 --> 0.170968).  Saving model ...
	 Train_Loss: 0.2147 Train_Acc: 91.873 Val_Loss: 0.1710  BEST VAL Loss: 0.1710  Val_Acc: 94.003

Epoch 18: Validation loss decreased (0.170968 --> 0.170051).  Saving model ...
	 Train_Loss: 0.2135 Train_Acc: 91.896 Val_Loss: 0.1701  BEST VAL Loss: 0.1701  Val_Acc: 94.038

Epoch 19: Validation loss decreased (0.170051 --> 0.169156).  Saving model ...
	 Train_Loss: 0.2124 Train_Acc: 91.951 Val_Loss: 0.1692  BEST VAL Loss: 0.1692  Val_Acc: 94.042

Epoch 20: Validation loss decreased (0.169156 --> 0.168251).  Saving model ...
	 Train_Loss: 0.2113 Train_Acc: 92.026 Val_Loss: 0.1683  BEST VAL Loss: 0.1683  Val_Acc: 94.094

Epoch 21: Validation loss decreased (0.168251 --> 0.167521).  Saving model ...
	 Train_Loss: 0.2103 Train_Acc: 91.995 Val_Loss: 0.1675  BEST VAL Loss: 0.1675  Val_Acc: 94.081

Epoch 22: Validation loss decreased (0.167521 --> 0.166694).  Saving model ...
	 Train_Loss: 0.2094 Train_Acc: 91.964 Val_Loss: 0.1667  BEST VAL Loss: 0.1667  Val_Acc: 94.189

Epoch 23: Validation loss decreased (0.166694 --> 0.165913).  Saving model ...
	 Train_Loss: 0.2085 Train_Acc: 91.938 Val_Loss: 0.1659  BEST VAL Loss: 0.1659  Val_Acc: 94.215

Epoch 24: Validation loss decreased (0.165913 --> 0.165328).  Saving model ...
	 Train_Loss: 0.2077 Train_Acc: 92.061 Val_Loss: 0.1653  BEST VAL Loss: 0.1653  Val_Acc: 94.163

Epoch 25: Validation loss decreased (0.165328 --> 0.164713).  Saving model ...
	 Train_Loss: 0.2069 Train_Acc: 92.035 Val_Loss: 0.1647  BEST VAL Loss: 0.1647  Val_Acc: 94.184

Epoch 26: Validation loss decreased (0.164713 --> 0.164082).  Saving model ...
	 Train_Loss: 0.2062 Train_Acc: 92.093 Val_Loss: 0.1641  BEST VAL Loss: 0.1641  Val_Acc: 94.245

Epoch 27: Validation loss decreased (0.164082 --> 0.163556).  Saving model ...
	 Train_Loss: 0.2054 Train_Acc: 92.144 Val_Loss: 0.1636  BEST VAL Loss: 0.1636  Val_Acc: 94.120

Epoch 28: Validation loss decreased (0.163556 --> 0.163092).  Saving model ...
	 Train_Loss: 0.2047 Train_Acc: 92.179 Val_Loss: 0.1631  BEST VAL Loss: 0.1631  Val_Acc: 94.344

Epoch 29: Validation loss decreased (0.163092 --> 0.162580).  Saving model ...
	 Train_Loss: 0.2041 Train_Acc: 92.208 Val_Loss: 0.1626  BEST VAL Loss: 0.1626  Val_Acc: 94.370

Epoch 30: Validation loss decreased (0.162580 --> 0.162174).  Saving model ...
	 Train_Loss: 0.2034 Train_Acc: 92.188 Val_Loss: 0.1622  BEST VAL Loss: 0.1622  Val_Acc: 94.249

Epoch 31: Validation loss decreased (0.162174 --> 0.161747).  Saving model ...
	 Train_Loss: 0.2028 Train_Acc: 92.231 Val_Loss: 0.1617  BEST VAL Loss: 0.1617  Val_Acc: 94.473

Epoch 32: Validation loss decreased (0.161747 --> 0.161289).  Saving model ...
	 Train_Loss: 0.2023 Train_Acc: 92.239 Val_Loss: 0.1613  BEST VAL Loss: 0.1613  Val_Acc: 94.309

Epoch 33: Validation loss decreased (0.161289 --> 0.160937).  Saving model ...
	 Train_Loss: 0.2017 Train_Acc: 92.219 Val_Loss: 0.1609  BEST VAL Loss: 0.1609  Val_Acc: 94.249

Epoch 34: Validation loss decreased (0.160937 --> 0.160565).  Saving model ...
	 Train_Loss: 0.2012 Train_Acc: 92.286 Val_Loss: 0.1606  BEST VAL Loss: 0.1606  Val_Acc: 94.344

Epoch 35: Validation loss decreased (0.160565 --> 0.160193).  Saving model ...
	 Train_Loss: 0.2006 Train_Acc: 92.324 Val_Loss: 0.1602  BEST VAL Loss: 0.1602  Val_Acc: 94.365

Epoch 36: Validation loss decreased (0.160193 --> 0.159804).  Saving model ...
	 Train_Loss: 0.2001 Train_Acc: 92.235 Val_Loss: 0.1598  BEST VAL Loss: 0.1598  Val_Acc: 94.503

Epoch 37: Validation loss decreased (0.159804 --> 0.159491).  Saving model ...
	 Train_Loss: 0.1996 Train_Acc: 92.409 Val_Loss: 0.1595  BEST VAL Loss: 0.1595  Val_Acc: 94.426

Epoch 38: Validation loss decreased (0.159491 --> 0.159204).  Saving model ...
	 Train_Loss: 0.1991 Train_Acc: 92.362 Val_Loss: 0.1592  BEST VAL Loss: 0.1592  Val_Acc: 94.331

Epoch 39: Validation loss decreased (0.159204 --> 0.158912).  Saving model ...
	 Train_Loss: 0.1986 Train_Acc: 92.371 Val_Loss: 0.1589  BEST VAL Loss: 0.1589  Val_Acc: 94.447

Epoch 40: Validation loss decreased (0.158912 --> 0.158717).  Saving model ...
	 Train_Loss: 0.1982 Train_Acc: 92.363 Val_Loss: 0.1587  BEST VAL Loss: 0.1587  Val_Acc: 94.344

Epoch 41: Validation loss decreased (0.158717 --> 0.158447).  Saving model ...
	 Train_Loss: 0.1978 Train_Acc: 92.417 Val_Loss: 0.1584  BEST VAL Loss: 0.1584  Val_Acc: 94.469

Epoch 42: Validation loss decreased (0.158447 --> 0.158145).  Saving model ...
	 Train_Loss: 0.1974 Train_Acc: 92.352 Val_Loss: 0.1581  BEST VAL Loss: 0.1581  Val_Acc: 94.551

Epoch 43: Validation loss decreased (0.158145 --> 0.157813).  Saving model ...
	 Train_Loss: 0.1970 Train_Acc: 92.379 Val_Loss: 0.1578  BEST VAL Loss: 0.1578  Val_Acc: 94.572

Epoch 44: Validation loss decreased (0.157813 --> 0.157544).  Saving model ...
	 Train_Loss: 0.1965 Train_Acc: 92.491 Val_Loss: 0.1575  BEST VAL Loss: 0.1575  Val_Acc: 94.409

Epoch 45: Validation loss decreased (0.157544 --> 0.157195).  Saving model ...
	 Train_Loss: 0.1961 Train_Acc: 92.470 Val_Loss: 0.1572  BEST VAL Loss: 0.1572  Val_Acc: 94.715

Epoch 46: Validation loss decreased (0.157195 --> 0.156886).  Saving model ...
	 Train_Loss: 0.1958 Train_Acc: 92.480 Val_Loss: 0.1569  BEST VAL Loss: 0.1569  Val_Acc: 94.542

Epoch 47: Validation loss decreased (0.156886 --> 0.156614).  Saving model ...
	 Train_Loss: 0.1954 Train_Acc: 92.430 Val_Loss: 0.1566  BEST VAL Loss: 0.1566  Val_Acc: 94.624

Epoch 48: Validation loss decreased (0.156614 --> 0.156393).  Saving model ...
	 Train_Loss: 0.1950 Train_Acc: 92.461 Val_Loss: 0.1564  BEST VAL Loss: 0.1564  Val_Acc: 94.568

Epoch 49: Validation loss decreased (0.156393 --> 0.156183).  Saving model ...
	 Train_Loss: 0.1947 Train_Acc: 92.516 Val_Loss: 0.1562  BEST VAL Loss: 0.1562  Val_Acc: 94.387

Epoch 50: Validation loss decreased (0.156183 --> 0.155940).  Saving model ...
	 Train_Loss: 0.1943 Train_Acc: 92.523 Val_Loss: 0.1559  BEST VAL Loss: 0.1559  Val_Acc: 94.469

Epoch 51: Validation loss decreased (0.155940 --> 0.155660).  Saving model ...
	 Train_Loss: 0.1940 Train_Acc: 92.512 Val_Loss: 0.1557  BEST VAL Loss: 0.1557  Val_Acc: 94.542

Epoch 52: Validation loss decreased (0.155660 --> 0.155452).  Saving model ...
	 Train_Loss: 0.1937 Train_Acc: 92.498 Val_Loss: 0.1555  BEST VAL Loss: 0.1555  Val_Acc: 94.525

Epoch 53: Validation loss decreased (0.155452 --> 0.155237).  Saving model ...
	 Train_Loss: 0.1933 Train_Acc: 92.486 Val_Loss: 0.1552  BEST VAL Loss: 0.1552  Val_Acc: 94.585

Epoch 54: Validation loss decreased (0.155237 --> 0.155024).  Saving model ...
	 Train_Loss: 0.1930 Train_Acc: 92.454 Val_Loss: 0.1550  BEST VAL Loss: 0.1550  Val_Acc: 94.538

Epoch 55: Validation loss decreased (0.155024 --> 0.154803).  Saving model ...
	 Train_Loss: 0.1927 Train_Acc: 92.565 Val_Loss: 0.1548  BEST VAL Loss: 0.1548  Val_Acc: 94.611

Epoch 56: Validation loss decreased (0.154803 --> 0.154573).  Saving model ...
	 Train_Loss: 0.1924 Train_Acc: 92.556 Val_Loss: 0.1546  BEST VAL Loss: 0.1546  Val_Acc: 94.577

Epoch 57: Validation loss decreased (0.154573 --> 0.154403).  Saving model ...
	 Train_Loss: 0.1921 Train_Acc: 92.588 Val_Loss: 0.1544  BEST VAL Loss: 0.1544  Val_Acc: 94.516

Epoch 58: Validation loss decreased (0.154403 --> 0.154169).  Saving model ...
	 Train_Loss: 0.1918 Train_Acc: 92.572 Val_Loss: 0.1542  BEST VAL Loss: 0.1542  Val_Acc: 94.667

Epoch 59: Validation loss decreased (0.154169 --> 0.153980).  Saving model ...
	 Train_Loss: 0.1916 Train_Acc: 92.597 Val_Loss: 0.1540  BEST VAL Loss: 0.1540  Val_Acc: 94.598

Epoch 60: Validation loss decreased (0.153980 --> 0.153767).  Saving model ...
	 Train_Loss: 0.1913 Train_Acc: 92.595 Val_Loss: 0.1538  BEST VAL Loss: 0.1538  Val_Acc: 94.646

Epoch 61: Validation loss decreased (0.153767 --> 0.153631).  Saving model ...
	 Train_Loss: 0.1910 Train_Acc: 92.644 Val_Loss: 0.1536  BEST VAL Loss: 0.1536  Val_Acc: 94.585

Epoch 62: Validation loss decreased (0.153631 --> 0.153473).  Saving model ...
	 Train_Loss: 0.1908 Train_Acc: 92.602 Val_Loss: 0.1535  BEST VAL Loss: 0.1535  Val_Acc: 94.663

Epoch 63: Validation loss decreased (0.153473 --> 0.153292).  Saving model ...
	 Train_Loss: 0.1905 Train_Acc: 92.665 Val_Loss: 0.1533  BEST VAL Loss: 0.1533  Val_Acc: 94.581

Epoch 64: Validation loss decreased (0.153292 --> 0.153162).  Saving model ...
	 Train_Loss: 0.1902 Train_Acc: 92.657 Val_Loss: 0.1532  BEST VAL Loss: 0.1532  Val_Acc: 94.568

Epoch 65: Validation loss decreased (0.153162 --> 0.153001).  Saving model ...
	 Train_Loss: 0.1900 Train_Acc: 92.713 Val_Loss: 0.1530  BEST VAL Loss: 0.1530  Val_Acc: 94.689

Epoch 66: Validation loss decreased (0.153001 --> 0.152851).  Saving model ...
	 Train_Loss: 0.1897 Train_Acc: 92.687 Val_Loss: 0.1529  BEST VAL Loss: 0.1529  Val_Acc: 94.650

Epoch 67: Validation loss decreased (0.152851 --> 0.152698).  Saving model ...
	 Train_Loss: 0.1895 Train_Acc: 92.660 Val_Loss: 0.1527  BEST VAL Loss: 0.1527  Val_Acc: 94.555

Epoch 68: Validation loss decreased (0.152698 --> 0.152525).  Saving model ...
	 Train_Loss: 0.1892 Train_Acc: 92.627 Val_Loss: 0.1525  BEST VAL Loss: 0.1525  Val_Acc: 94.689

Epoch 69: Validation loss decreased (0.152525 --> 0.152386).  Saving model ...
	 Train_Loss: 0.1890 Train_Acc: 92.646 Val_Loss: 0.1524  BEST VAL Loss: 0.1524  Val_Acc: 94.568

Epoch 70: Validation loss decreased (0.152386 --> 0.152233).  Saving model ...
	 Train_Loss: 0.1888 Train_Acc: 92.709 Val_Loss: 0.1522  BEST VAL Loss: 0.1522  Val_Acc: 94.689

Epoch 71: Validation loss decreased (0.152233 --> 0.152087).  Saving model ...
	 Train_Loss: 0.1886 Train_Acc: 92.694 Val_Loss: 0.1521  BEST VAL Loss: 0.1521  Val_Acc: 94.706

Epoch 72: Validation loss decreased (0.152087 --> 0.151970).  Saving model ...
	 Train_Loss: 0.1883 Train_Acc: 92.660 Val_Loss: 0.1520  BEST VAL Loss: 0.1520  Val_Acc: 94.594

Epoch 73: Validation loss decreased (0.151970 --> 0.151813).  Saving model ...
	 Train_Loss: 0.1881 Train_Acc: 92.668 Val_Loss: 0.1518  BEST VAL Loss: 0.1518  Val_Acc: 94.693

Epoch 74: Validation loss decreased (0.151813 --> 0.151683).  Saving model ...
	 Train_Loss: 0.1879 Train_Acc: 92.676 Val_Loss: 0.1517  BEST VAL Loss: 0.1517  Val_Acc: 94.559

Epoch 75: Validation loss decreased (0.151683 --> 0.151515).  Saving model ...
	 Train_Loss: 0.1877 Train_Acc: 92.687 Val_Loss: 0.1515  BEST VAL Loss: 0.1515  Val_Acc: 94.680

Epoch 76: Validation loss decreased (0.151515 --> 0.151411).  Saving model ...
	 Train_Loss: 0.1875 Train_Acc: 92.672 Val_Loss: 0.1514  BEST VAL Loss: 0.1514  Val_Acc: 94.603

Epoch 77: Validation loss decreased (0.151411 --> 0.151294).  Saving model ...
	 Train_Loss: 0.1873 Train_Acc: 92.714 Val_Loss: 0.1513  BEST VAL Loss: 0.1513  Val_Acc: 94.663

Epoch 78: Validation loss decreased (0.151294 --> 0.151145).  Saving model ...
	 Train_Loss: 0.1871 Train_Acc: 92.724 Val_Loss: 0.1511  BEST VAL Loss: 0.1511  Val_Acc: 94.745

Epoch 79: Validation loss decreased (0.151145 --> 0.151030).  Saving model ...
	 Train_Loss: 0.1869 Train_Acc: 92.748 Val_Loss: 0.1510  BEST VAL Loss: 0.1510  Val_Acc: 94.620

Epoch 80: Validation loss decreased (0.151030 --> 0.150890).  Saving model ...
	 Train_Loss: 0.1867 Train_Acc: 92.681 Val_Loss: 0.1509  BEST VAL Loss: 0.1509  Val_Acc: 94.719

Epoch 81: Validation loss decreased (0.150890 --> 0.150779).  Saving model ...
	 Train_Loss: 0.1865 Train_Acc: 92.701 Val_Loss: 0.1508  BEST VAL Loss: 0.1508  Val_Acc: 94.684

Epoch 82: Validation loss decreased (0.150779 --> 0.150665).  Saving model ...
	 Train_Loss: 0.1863 Train_Acc: 92.784 Val_Loss: 0.1507  BEST VAL Loss: 0.1507  Val_Acc: 94.659

Epoch 83: Validation loss decreased (0.150665 --> 0.150544).  Saving model ...
	 Train_Loss: 0.1861 Train_Acc: 92.707 Val_Loss: 0.1505  BEST VAL Loss: 0.1505  Val_Acc: 94.603

Epoch 84: Validation loss decreased (0.150544 --> 0.150411).  Saving model ...
	 Train_Loss: 0.1859 Train_Acc: 92.807 Val_Loss: 0.1504  BEST VAL Loss: 0.1504  Val_Acc: 94.641

Epoch 85: Validation loss decreased (0.150411 --> 0.150299).  Saving model ...
	 Train_Loss: 0.1858 Train_Acc: 92.722 Val_Loss: 0.1503  BEST VAL Loss: 0.1503  Val_Acc: 94.732

Epoch 86: Validation loss decreased (0.150299 --> 0.150217).  Saving model ...
	 Train_Loss: 0.1856 Train_Acc: 92.775 Val_Loss: 0.1502  BEST VAL Loss: 0.1502  Val_Acc: 94.680

Epoch 87: Validation loss decreased (0.150217 --> 0.150083).  Saving model ...
	 Train_Loss: 0.1854 Train_Acc: 92.742 Val_Loss: 0.1501  BEST VAL Loss: 0.1501  Val_Acc: 94.581

Epoch 88: Validation loss decreased (0.150083 --> 0.149978).  Saving model ...
	 Train_Loss: 0.1852 Train_Acc: 92.755 Val_Loss: 0.1500  BEST VAL Loss: 0.1500  Val_Acc: 94.771

Epoch 89: Validation loss decreased (0.149978 --> 0.149884).  Saving model ...
	 Train_Loss: 0.1851 Train_Acc: 92.874 Val_Loss: 0.1499  BEST VAL Loss: 0.1499  Val_Acc: 94.676

Epoch 90: Validation loss decreased (0.149884 --> 0.149769).  Saving model ...
	 Train_Loss: 0.1849 Train_Acc: 92.783 Val_Loss: 0.1498  BEST VAL Loss: 0.1498  Val_Acc: 94.650

Epoch 91: Validation loss decreased (0.149769 --> 0.149659).  Saving model ...
	 Train_Loss: 0.1847 Train_Acc: 92.831 Val_Loss: 0.1497  BEST VAL Loss: 0.1497  Val_Acc: 94.684

Epoch 92: Validation loss decreased (0.149659 --> 0.149567).  Saving model ...
	 Train_Loss: 0.1846 Train_Acc: 92.854 Val_Loss: 0.1496  BEST VAL Loss: 0.1496  Val_Acc: 94.779

Epoch 93: Validation loss decreased (0.149567 --> 0.149499).  Saving model ...
	 Train_Loss: 0.1844 Train_Acc: 92.839 Val_Loss: 0.1495  BEST VAL Loss: 0.1495  Val_Acc: 94.702

Epoch 94: Validation loss decreased (0.149499 --> 0.149398).  Saving model ...
	 Train_Loss: 0.1842 Train_Acc: 92.907 Val_Loss: 0.1494  BEST VAL Loss: 0.1494  Val_Acc: 94.654

Epoch 95: Validation loss decreased (0.149398 --> 0.149288).  Saving model ...
	 Train_Loss: 0.1841 Train_Acc: 92.835 Val_Loss: 0.1493  BEST VAL Loss: 0.1493  Val_Acc: 94.831

Epoch 96: Validation loss decreased (0.149288 --> 0.149184).  Saving model ...
	 Train_Loss: 0.1839 Train_Acc: 92.866 Val_Loss: 0.1492  BEST VAL Loss: 0.1492  Val_Acc: 94.753

Epoch 97: Validation loss decreased (0.149184 --> 0.149116).  Saving model ...
	 Train_Loss: 0.1838 Train_Acc: 92.886 Val_Loss: 0.1491  BEST VAL Loss: 0.1491  Val_Acc: 94.659

Epoch 98: Validation loss decreased (0.149116 --> 0.149019).  Saving model ...
	 Train_Loss: 0.1836 Train_Acc: 92.866 Val_Loss: 0.1490  BEST VAL Loss: 0.1490  Val_Acc: 94.753

Epoch 99: Validation loss decreased (0.149019 --> 0.148920).  Saving model ...
	 Train_Loss: 0.1835 Train_Acc: 92.798 Val_Loss: 0.1489  BEST VAL Loss: 0.1489  Val_Acc: 94.792

LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.95      0.95      0.95     80324
           1       0.96      0.96      0.96    105242

    accuracy                           0.96    185566
   macro avg       0.96      0.96      0.96    185566
weighted avg       0.96      0.96      0.96    185566

LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.94      0.94      0.94     10041
           1       0.95      0.96      0.95     13155

    accuracy                           0.95     23196
   macro avg       0.95      0.95      0.95     23196
weighted avg       0.95      0.95      0.95     23196

LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.94      0.94      0.94     10041
           1       0.95      0.95      0.95     13155

    accuracy                           0.95     23196
   macro avg       0.95      0.95      0.95     23196
weighted avg       0.95      0.95      0.95     23196

              precision    recall  f1-score   support

           0       0.94      0.94      0.94     10041
           1       0.95      0.95      0.95     13155

    accuracy                           0.95     23196
   macro avg       0.95      0.95      0.95     23196
weighted avg       0.95      0.95      0.95     23196

LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.94      0.96     38191
           1       0.95      0.98      0.97     49614

    accuracy                           0.96     87805
   macro avg       0.97      0.96      0.96     87805
weighted avg       0.96      0.96      0.96     87805

              precision    recall  f1-score   support

           0       0.98      0.94      0.96     38191
           1       0.95      0.98      0.97     49614

    accuracy                           0.96     87805
   macro avg       0.97      0.96      0.96     87805
weighted avg       0.96      0.96      0.96     87805

completed
