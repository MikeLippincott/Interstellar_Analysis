[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '767a89b4'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '1442ea0b'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '431c57cd'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '48562758'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_10.000_DMSO_0.025 treatment_name: LPS_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: LPS_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'LPS_10.000_DMSO_0.025']
The dimensions of the data are: (33268, 1276)
Number of total missing values across all columns: 66536
Data Subset Is Off
Wells held out for testing: ['D20' 'E21']
Wells to use for training, validation, and testing ['D16' 'E16' 'D17' 'E17' 'E20' 'D21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.698656).  Saving model ...
	 Train_Loss: 0.7116 Train_Acc: 51.078 Val_Loss: 0.6987  BEST VAL Loss: 0.6987  Val_Acc: 52.406

Epoch 1: Validation loss decreased (0.698656 --> 0.695841).  Saving model ...
	 Train_Loss: 0.7024 Train_Acc: 53.936 Val_Loss: 0.6958  BEST VAL Loss: 0.6958  Val_Acc: 53.569

Epoch 2: Validation loss decreased (0.695841 --> 0.693570).  Saving model ...
	 Train_Loss: 0.6961 Train_Acc: 55.851 Val_Loss: 0.6936  BEST VAL Loss: 0.6936  Val_Acc: 54.170

Epoch 3: Validation loss decreased (0.693570 --> 0.691422).  Saving model ...
	 Train_Loss: 0.6918 Train_Acc: 56.568 Val_Loss: 0.6914  BEST VAL Loss: 0.6914  Val_Acc: 55.253

Epoch 4: Validation loss decreased (0.691422 --> 0.690086).  Saving model ...
	 Train_Loss: 0.6885 Train_Acc: 57.486 Val_Loss: 0.6901  BEST VAL Loss: 0.6901  Val_Acc: 55.774

Epoch 5: Validation loss decreased (0.690086 --> 0.688301).  Saving model ...
	 Train_Loss: 0.6855 Train_Acc: 58.163 Val_Loss: 0.6883  BEST VAL Loss: 0.6883  Val_Acc: 55.974

Epoch 6: Validation loss decreased (0.688301 --> 0.687135).  Saving model ...
	 Train_Loss: 0.6831 Train_Acc: 58.649 Val_Loss: 0.6871  BEST VAL Loss: 0.6871  Val_Acc: 56.816

Epoch 7: Validation loss decreased (0.687135 --> 0.686114).  Saving model ...
	 Train_Loss: 0.6808 Train_Acc: 59.351 Val_Loss: 0.6861  BEST VAL Loss: 0.6861  Val_Acc: 56.816

Epoch 8: Validation loss decreased (0.686114 --> 0.685052).  Saving model ...
	 Train_Loss: 0.6788 Train_Acc: 59.497 Val_Loss: 0.6851  BEST VAL Loss: 0.6851  Val_Acc: 57.137

Epoch 9: Validation loss decreased (0.685052 --> 0.684135).  Saving model ...
	 Train_Loss: 0.6770 Train_Acc: 59.823 Val_Loss: 0.6841  BEST VAL Loss: 0.6841  Val_Acc: 57.538

Epoch 10: Validation loss decreased (0.684135 --> 0.683510).  Saving model ...
	 Train_Loss: 0.6753 Train_Acc: 59.923 Val_Loss: 0.6835  BEST VAL Loss: 0.6835  Val_Acc: 57.779

Epoch 11: Validation loss decreased (0.683510 --> 0.682708).  Saving model ...
	 Train_Loss: 0.6738 Train_Acc: 60.750 Val_Loss: 0.6827  BEST VAL Loss: 0.6827  Val_Acc: 57.698

Epoch 12: Validation loss decreased (0.682708 --> 0.682036).  Saving model ...
	 Train_Loss: 0.6723 Train_Acc: 60.675 Val_Loss: 0.6820  BEST VAL Loss: 0.6820  Val_Acc: 57.739

Epoch 13: Validation loss decreased (0.682036 --> 0.681426).  Saving model ...
	 Train_Loss: 0.6709 Train_Acc: 61.387 Val_Loss: 0.6814  BEST VAL Loss: 0.6814  Val_Acc: 57.057

Epoch 14: Validation loss decreased (0.681426 --> 0.680905).  Saving model ...
	 Train_Loss: 0.6695 Train_Acc: 61.522 Val_Loss: 0.6809  BEST VAL Loss: 0.6809  Val_Acc: 57.779

Epoch 15: Validation loss decreased (0.680905 --> 0.680400).  Saving model ...
	 Train_Loss: 0.6681 Train_Acc: 61.758 Val_Loss: 0.6804  BEST VAL Loss: 0.6804  Val_Acc: 58.019

Epoch 16: Validation loss decreased (0.680400 --> 0.679838).  Saving model ...
	 Train_Loss: 0.6668 Train_Acc: 61.908 Val_Loss: 0.6798  BEST VAL Loss: 0.6798  Val_Acc: 57.979

Epoch 17: Validation loss decreased (0.679838 --> 0.679244).  Saving model ...
	 Train_Loss: 0.6655 Train_Acc: 62.304 Val_Loss: 0.6792  BEST VAL Loss: 0.6792  Val_Acc: 58.220

Epoch 18: Validation loss decreased (0.679244 --> 0.678642).  Saving model ...
	 Train_Loss: 0.6642 Train_Acc: 62.014 Val_Loss: 0.6786  BEST VAL Loss: 0.6786  Val_Acc: 58.260

Epoch 19: Validation loss decreased (0.678642 --> 0.678058).  Saving model ...
	 Train_Loss: 0.6631 Train_Acc: 62.505 Val_Loss: 0.6781  BEST VAL Loss: 0.6781  Val_Acc: 58.380

Epoch 20: Validation loss decreased (0.678058 --> 0.677525).  Saving model ...
	 Train_Loss: 0.6618 Train_Acc: 63.443 Val_Loss: 0.6775  BEST VAL Loss: 0.6775  Val_Acc: 58.701

Epoch 21: Validation loss decreased (0.677525 --> 0.676959).  Saving model ...
	 Train_Loss: 0.6606 Train_Acc: 63.092 Val_Loss: 0.6770  BEST VAL Loss: 0.6770  Val_Acc: 59.062

Epoch 22: Validation loss decreased (0.676959 --> 0.676302).  Saving model ...
	 Train_Loss: 0.6595 Train_Acc: 63.242 Val_Loss: 0.6763  BEST VAL Loss: 0.6763  Val_Acc: 59.222

Epoch 23: Validation loss decreased (0.676302 --> 0.675868).  Saving model ...
	 Train_Loss: 0.6584 Train_Acc: 63.307 Val_Loss: 0.6759  BEST VAL Loss: 0.6759  Val_Acc: 58.821

Epoch 24: Validation loss decreased (0.675868 --> 0.675324).  Saving model ...
	 Train_Loss: 0.6573 Train_Acc: 63.909 Val_Loss: 0.6753  BEST VAL Loss: 0.6753  Val_Acc: 59.383

Epoch 25: Validation loss decreased (0.675324 --> 0.674937).  Saving model ...
	 Train_Loss: 0.6563 Train_Acc: 63.703 Val_Loss: 0.6749  BEST VAL Loss: 0.6749  Val_Acc: 60.104

Epoch 26: Validation loss decreased (0.674937 --> 0.674471).  Saving model ...
	 Train_Loss: 0.6552 Train_Acc: 64.365 Val_Loss: 0.6745  BEST VAL Loss: 0.6745  Val_Acc: 60.385

Epoch 27: Validation loss decreased (0.674471 --> 0.674024).  Saving model ...
	 Train_Loss: 0.6542 Train_Acc: 64.195 Val_Loss: 0.6740  BEST VAL Loss: 0.6740  Val_Acc: 60.305

Epoch 28: Validation loss decreased (0.674024 --> 0.673703).  Saving model ...
	 Train_Loss: 0.6532 Train_Acc: 64.405 Val_Loss: 0.6737  BEST VAL Loss: 0.6737  Val_Acc: 59.703

Epoch 29: Validation loss decreased (0.673703 --> 0.673331).  Saving model ...
	 Train_Loss: 0.6522 Train_Acc: 64.380 Val_Loss: 0.6733  BEST VAL Loss: 0.6733  Val_Acc: 60.144

Epoch 30: Validation loss decreased (0.673331 --> 0.673112).  Saving model ...
	 Train_Loss: 0.6513 Train_Acc: 64.094 Val_Loss: 0.6731  BEST VAL Loss: 0.6731  Val_Acc: 60.024

Epoch 31: Validation loss decreased (0.673112 --> 0.672806).  Saving model ...
	 Train_Loss: 0.6504 Train_Acc: 64.716 Val_Loss: 0.6728  BEST VAL Loss: 0.6728  Val_Acc: 60.064

Epoch 32: Validation loss decreased (0.672806 --> 0.672295).  Saving model ...
	 Train_Loss: 0.6495 Train_Acc: 64.781 Val_Loss: 0.6723  BEST VAL Loss: 0.6723  Val_Acc: 60.465

Epoch 33: Validation loss decreased (0.672295 --> 0.671820).  Saving model ...
	 Train_Loss: 0.6486 Train_Acc: 64.606 Val_Loss: 0.6718  BEST VAL Loss: 0.6718  Val_Acc: 60.425

Epoch 34: Validation loss decreased (0.671820 --> 0.671449).  Saving model ...
	 Train_Loss: 0.6477 Train_Acc: 64.992 Val_Loss: 0.6714  BEST VAL Loss: 0.6714  Val_Acc: 60.545

Epoch 35: Validation loss decreased (0.671449 --> 0.671001).  Saving model ...
	 Train_Loss: 0.6468 Train_Acc: 64.822 Val_Loss: 0.6710  BEST VAL Loss: 0.6710  Val_Acc: 60.666

Epoch 36: Validation loss decreased (0.671001 --> 0.670647).  Saving model ...
	 Train_Loss: 0.6460 Train_Acc: 65.167 Val_Loss: 0.6706  BEST VAL Loss: 0.6706  Val_Acc: 60.666

Epoch 37: Validation loss decreased (0.670647 --> 0.670303).  Saving model ...
	 Train_Loss: 0.6452 Train_Acc: 65.283 Val_Loss: 0.6703  BEST VAL Loss: 0.6703  Val_Acc: 61.347

Epoch 38: Validation loss decreased (0.670303 --> 0.669979).  Saving model ...
	 Train_Loss: 0.6444 Train_Acc: 65.268 Val_Loss: 0.6700  BEST VAL Loss: 0.6700  Val_Acc: 60.585

Epoch 39: Validation loss decreased (0.669979 --> 0.669585).  Saving model ...
	 Train_Loss: 0.6436 Train_Acc: 65.238 Val_Loss: 0.6696  BEST VAL Loss: 0.6696  Val_Acc: 60.986

Epoch 40: Validation loss decreased (0.669585 --> 0.669347).  Saving model ...
	 Train_Loss: 0.6427 Train_Acc: 65.739 Val_Loss: 0.6693  BEST VAL Loss: 0.6693  Val_Acc: 60.505

Epoch 41: Validation loss decreased (0.669347 --> 0.669057).  Saving model ...
	 Train_Loss: 0.6420 Train_Acc: 65.278 Val_Loss: 0.6691  BEST VAL Loss: 0.6691  Val_Acc: 61.227

Epoch 42: Validation loss decreased (0.669057 --> 0.668671).  Saving model ...
	 Train_Loss: 0.6412 Train_Acc: 65.729 Val_Loss: 0.6687  BEST VAL Loss: 0.6687  Val_Acc: 61.668

Epoch 43: Validation loss decreased (0.668671 --> 0.668424).  Saving model ...
	 Train_Loss: 0.6405 Train_Acc: 65.759 Val_Loss: 0.6684  BEST VAL Loss: 0.6684  Val_Acc: 61.708

Epoch 44: Validation loss decreased (0.668424 --> 0.668187).  Saving model ...
	 Train_Loss: 0.6398 Train_Acc: 66.130 Val_Loss: 0.6682  BEST VAL Loss: 0.6682  Val_Acc: 60.746

Epoch 45: Validation loss decreased (0.668187 --> 0.667841).  Saving model ...
	 Train_Loss: 0.6390 Train_Acc: 65.869 Val_Loss: 0.6678  BEST VAL Loss: 0.6678  Val_Acc: 61.067

Epoch 46: Validation loss decreased (0.667841 --> 0.667533).  Saving model ...
	 Train_Loss: 0.6384 Train_Acc: 66.035 Val_Loss: 0.6675  BEST VAL Loss: 0.6675  Val_Acc: 61.828

Epoch 47: Validation loss decreased (0.667533 --> 0.667165).  Saving model ...
	 Train_Loss: 0.6376 Train_Acc: 66.356 Val_Loss: 0.6672  BEST VAL Loss: 0.6672  Val_Acc: 61.868

Epoch 48: Validation loss decreased (0.667165 --> 0.666844).  Saving model ...
	 Train_Loss: 0.6370 Train_Acc: 65.965 Val_Loss: 0.6668  BEST VAL Loss: 0.6668  Val_Acc: 61.748

Epoch 49: Validation loss decreased (0.666844 --> 0.666551).  Saving model ...
	 Train_Loss: 0.6363 Train_Acc: 66.020 Val_Loss: 0.6666  BEST VAL Loss: 0.6666  Val_Acc: 61.788

Epoch 50: Validation loss decreased (0.666551 --> 0.666273).  Saving model ...
	 Train_Loss: 0.6356 Train_Acc: 66.140 Val_Loss: 0.6663  BEST VAL Loss: 0.6663  Val_Acc: 60.626

Epoch 51: Validation loss decreased (0.666273 --> 0.666077).  Saving model ...
	 Train_Loss: 0.6350 Train_Acc: 66.436 Val_Loss: 0.6661  BEST VAL Loss: 0.6661  Val_Acc: 62.069

Epoch 52: Validation loss decreased (0.666077 --> 0.665912).  Saving model ...
	 Train_Loss: 0.6343 Train_Acc: 66.601 Val_Loss: 0.6659  BEST VAL Loss: 0.6659  Val_Acc: 61.748

Epoch 53: Validation loss decreased (0.665912 --> 0.665579).  Saving model ...
	 Train_Loss: 0.6337 Train_Acc: 66.707 Val_Loss: 0.6656  BEST VAL Loss: 0.6656  Val_Acc: 62.149

Epoch 54: Validation loss decreased (0.665579 --> 0.665276).  Saving model ...
	 Train_Loss: 0.6330 Train_Acc: 66.932 Val_Loss: 0.6653  BEST VAL Loss: 0.6653  Val_Acc: 61.989

Epoch 55: Validation loss decreased (0.665276 --> 0.665023).  Saving model ...
	 Train_Loss: 0.6324 Train_Acc: 66.993 Val_Loss: 0.6650  BEST VAL Loss: 0.6650  Val_Acc: 62.350

Epoch 56: Validation loss decreased (0.665023 --> 0.664847).  Saving model ...
	 Train_Loss: 0.6318 Train_Acc: 66.581 Val_Loss: 0.6648  BEST VAL Loss: 0.6648  Val_Acc: 61.508

Epoch 57: Validation loss decreased (0.664847 --> 0.664597).  Saving model ...
	 Train_Loss: 0.6312 Train_Acc: 67.268 Val_Loss: 0.6646  BEST VAL Loss: 0.6646  Val_Acc: 61.387

Epoch 58: Validation loss decreased (0.664597 --> 0.664463).  Saving model ...
	 Train_Loss: 0.6306 Train_Acc: 66.647 Val_Loss: 0.6645  BEST VAL Loss: 0.6645  Val_Acc: 62.149

Epoch 59: Validation loss decreased (0.664463 --> 0.664267).  Saving model ...
	 Train_Loss: 0.6300 Train_Acc: 67.148 Val_Loss: 0.6643  BEST VAL Loss: 0.6643  Val_Acc: 62.229

Epoch 60: Validation loss decreased (0.664267 --> 0.664034).  Saving model ...
	 Train_Loss: 0.6295 Train_Acc: 66.927 Val_Loss: 0.6640  BEST VAL Loss: 0.6640  Val_Acc: 62.911

Epoch 61: Validation loss decreased (0.664034 --> 0.663772).  Saving model ...
	 Train_Loss: 0.6289 Train_Acc: 66.937 Val_Loss: 0.6638  BEST VAL Loss: 0.6638  Val_Acc: 62.310

Epoch 62: Validation loss decreased (0.663772 --> 0.663579).  Saving model ...
	 Train_Loss: 0.6283 Train_Acc: 67.268 Val_Loss: 0.6636  BEST VAL Loss: 0.6636  Val_Acc: 62.109

Epoch 63: Validation loss decreased (0.663579 --> 0.663469).  Saving model ...
	 Train_Loss: 0.6278 Train_Acc: 67.033 Val_Loss: 0.6635  BEST VAL Loss: 0.6635  Val_Acc: 61.748

Epoch 64: Validation loss decreased (0.663469 --> 0.663332).  Saving model ...
	 Train_Loss: 0.6273 Train_Acc: 67.228 Val_Loss: 0.6633  BEST VAL Loss: 0.6633  Val_Acc: 62.069

Epoch 65: Validation loss decreased (0.663332 --> 0.663254).  Saving model ...
	 Train_Loss: 0.6267 Train_Acc: 67.288 Val_Loss: 0.6633  BEST VAL Loss: 0.6633  Val_Acc: 62.069

Epoch 66: Validation loss decreased (0.663254 --> 0.663194).  Saving model ...
	 Train_Loss: 0.6262 Train_Acc: 67.143 Val_Loss: 0.6632  BEST VAL Loss: 0.6632  Val_Acc: 62.310

Epoch 67: Validation loss decreased (0.663194 --> 0.663026).  Saving model ...
	 Train_Loss: 0.6257 Train_Acc: 67.038 Val_Loss: 0.6630  BEST VAL Loss: 0.6630  Val_Acc: 62.711

Epoch 68: Validation loss decreased (0.663026 --> 0.662818).  Saving model ...
	 Train_Loss: 0.6252 Train_Acc: 67.419 Val_Loss: 0.6628  BEST VAL Loss: 0.6628  Val_Acc: 62.470

Epoch 69: Validation loss decreased (0.662818 --> 0.662708).  Saving model ...
	 Train_Loss: 0.6247 Train_Acc: 67.484 Val_Loss: 0.6627  BEST VAL Loss: 0.6627  Val_Acc: 62.310

Epoch 70: Validation loss decreased (0.662708 --> 0.662616).  Saving model ...
	 Train_Loss: 0.6242 Train_Acc: 67.313 Val_Loss: 0.6626  BEST VAL Loss: 0.6626  Val_Acc: 62.109

Epoch 71: Validation loss decreased (0.662616 --> 0.662551).  Saving model ...
	 Train_Loss: 0.6237 Train_Acc: 67.579 Val_Loss: 0.6626  BEST VAL Loss: 0.6626  Val_Acc: 62.430

Epoch 72: Validation loss decreased (0.662551 --> 0.662467).  Saving model ...
	 Train_Loss: 0.6233 Train_Acc: 67.584 Val_Loss: 0.6625  BEST VAL Loss: 0.6625  Val_Acc: 62.149

Epoch 73: Validation loss decreased (0.662467 --> 0.662402).  Saving model ...
	 Train_Loss: 0.6228 Train_Acc: 67.735 Val_Loss: 0.6624  BEST VAL Loss: 0.6624  Val_Acc: 62.189

Epoch 74: Validation loss decreased (0.662402 --> 0.662321).  Saving model ...
	 Train_Loss: 0.6223 Train_Acc: 67.489 Val_Loss: 0.6623  BEST VAL Loss: 0.6623  Val_Acc: 62.269

Epoch 75: Validation loss decreased (0.662321 --> 0.662308).  Saving model ...
	 Train_Loss: 0.6218 Train_Acc: 68.201 Val_Loss: 0.6623  BEST VAL Loss: 0.6623  Val_Acc: 62.510

Epoch 76: Validation loss decreased (0.662308 --> 0.662218).  Saving model ...
	 Train_Loss: 0.6214 Train_Acc: 67.725 Val_Loss: 0.6622  BEST VAL Loss: 0.6622  Val_Acc: 62.109

Epoch 77: Validation loss decreased (0.662218 --> 0.662118).  Saving model ...
	 Train_Loss: 0.6209 Train_Acc: 67.850 Val_Loss: 0.6621  BEST VAL Loss: 0.6621  Val_Acc: 62.149

Epoch 78: Validation loss decreased (0.662118 --> 0.662075).  Saving model ...
	 Train_Loss: 0.6204 Train_Acc: 67.830 Val_Loss: 0.6621  BEST VAL Loss: 0.6621  Val_Acc: 62.109

Epoch 79: Validation loss decreased (0.662075 --> 0.662048).  Saving model ...
	 Train_Loss: 0.6200 Train_Acc: 67.750 Val_Loss: 0.6620  BEST VAL Loss: 0.6620  Val_Acc: 62.189

Epoch 80: Validation loss decreased (0.662048 --> 0.661931).  Saving model ...
	 Train_Loss: 0.6196 Train_Acc: 67.810 Val_Loss: 0.6619  BEST VAL Loss: 0.6619  Val_Acc: 63.312

Epoch 81: Validation loss decreased (0.661931 --> 0.661883).  Saving model ...
	 Train_Loss: 0.6191 Train_Acc: 68.000 Val_Loss: 0.6619  BEST VAL Loss: 0.6619  Val_Acc: 62.430

Epoch 82: Validation loss decreased (0.661883 --> 0.661796).  Saving model ...
	 Train_Loss: 0.6187 Train_Acc: 68.216 Val_Loss: 0.6618  BEST VAL Loss: 0.6618  Val_Acc: 62.711

Epoch 83: Validation loss decreased (0.661796 --> 0.661723).  Saving model ...
	 Train_Loss: 0.6182 Train_Acc: 67.950 Val_Loss: 0.6617  BEST VAL Loss: 0.6617  Val_Acc: 62.310

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.6178 Train_Acc: 68.417 Val_Loss: 0.6617  BEST VAL Loss: 0.6617  Val_Acc: 62.911

Epoch 85: Validation loss decreased (0.661723 --> 0.661675).  Saving model ...
	 Train_Loss: 0.6174 Train_Acc: 68.291 Val_Loss: 0.6617  BEST VAL Loss: 0.6617  Val_Acc: 62.751

Epoch 86: Validation loss decreased (0.661675 --> 0.661594).  Saving model ...
	 Train_Loss: 0.6169 Train_Acc: 68.211 Val_Loss: 0.6616  BEST VAL Loss: 0.6616  Val_Acc: 62.390

Epoch 87: Validation loss decreased (0.661594 --> 0.661549).  Saving model ...
	 Train_Loss: 0.6165 Train_Acc: 68.341 Val_Loss: 0.6615  BEST VAL Loss: 0.6615  Val_Acc: 62.550

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.6161 Train_Acc: 68.697 Val_Loss: 0.6616  BEST VAL Loss: 0.6615  Val_Acc: 61.628

Epoch 89: Validation loss decreased (0.661549 --> 0.661488).  Saving model ...
	 Train_Loss: 0.6157 Train_Acc: 68.286 Val_Loss: 0.6615  BEST VAL Loss: 0.6615  Val_Acc: 62.310

Epoch 90: Validation loss decreased (0.661488 --> 0.661476).  Saving model ...
	 Train_Loss: 0.6153 Train_Acc: 68.201 Val_Loss: 0.6615  BEST VAL Loss: 0.6615  Val_Acc: 61.989

Epoch 91: Validation loss decreased (0.661476 --> 0.661465).  Saving model ...
	 Train_Loss: 0.6149 Train_Acc: 68.547 Val_Loss: 0.6615  BEST VAL Loss: 0.6615  Val_Acc: 61.828

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.6145 Train_Acc: 68.046 Val_Loss: 0.6615  BEST VAL Loss: 0.6615  Val_Acc: 62.470

Epoch 93: Validation loss decreased (0.661465 --> 0.661449).  Saving model ...
	 Train_Loss: 0.6141 Train_Acc: 68.527 Val_Loss: 0.6614  BEST VAL Loss: 0.6614  Val_Acc: 62.189

Epoch 94: Validation loss decreased (0.661449 --> 0.661442).  Saving model ...
	 Train_Loss: 0.6137 Train_Acc: 68.542 Val_Loss: 0.6614  BEST VAL Loss: 0.6614  Val_Acc: 62.109

Epoch 95: Validation loss decreased (0.661442 --> 0.661404).  Saving model ...
	 Train_Loss: 0.6133 Train_Acc: 68.903 Val_Loss: 0.6614  BEST VAL Loss: 0.6614  Val_Acc: 61.949

Epoch 96: Validation loss decreased (0.661404 --> 0.661398).  Saving model ...
	 Train_Loss: 0.6129 Train_Acc: 68.286 Val_Loss: 0.6614  BEST VAL Loss: 0.6614  Val_Acc: 62.029

Epoch 97: Validation loss decreased (0.661398 --> 0.661373).  Saving model ...
	 Train_Loss: 0.6125 Train_Acc: 68.512 Val_Loss: 0.6614  BEST VAL Loss: 0.6614  Val_Acc: 61.628

Epoch 98: Validation loss did not decrease
	 Train_Loss: 0.6122 Train_Acc: 68.858 Val_Loss: 0.6614  BEST VAL Loss: 0.6614  Val_Acc: 61.828

Epoch 99: Validation loss did not decrease
	 Train_Loss: 0.6118 Train_Acc: 68.492 Val_Loss: 0.6615  BEST VAL Loss: 0.6614  Val_Acc: 62.430

LPS_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.42      0.45      9832
           1       0.51      0.58      0.54     10112

    accuracy                           0.50     19944
   macro avg       0.50      0.50      0.50     19944
weighted avg       0.50      0.50      0.50     19944

LPS_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.41      0.44      1229
           1       0.50      0.58      0.54      1265

    accuracy                           0.50      2494
   macro avg       0.49      0.49      0.49      2494
weighted avg       0.49      0.50      0.49      2494

LPS_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.42      0.45      1229
           1       0.51      0.59      0.55      1265

    accuracy                           0.50      2494
   macro avg       0.50      0.50      0.50      2494
weighted avg       0.50      0.50      0.50      2494

              precision    recall  f1-score   support

           0       0.50      0.42      0.45      1229
           1       0.51      0.59      0.55      1265

    accuracy                           0.50      2494
   macro avg       0.50      0.50      0.50      2494
weighted avg       0.50      0.50      0.50      2494

LPS_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.35      0.41      4168
           1       0.50      0.65      0.57      4168

    accuracy                           0.50      8336
   macro avg       0.50      0.50      0.49      8336
weighted avg       0.50      0.50      0.49      8336

              precision    recall  f1-score   support

           0       0.50      0.35      0.41      4168
           1       0.50      0.65      0.57      4168

    accuracy                           0.50      8336
   macro avg       0.50      0.50      0.49      8336
weighted avg       0.50      0.50      0.49      8336

completed
