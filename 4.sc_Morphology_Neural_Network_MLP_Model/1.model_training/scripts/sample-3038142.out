[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '3ee454f3'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '633b7f74'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'feb97e61'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '0438585f'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Thapsigargin_10.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Thapsigargin_10.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (348150, 1270)
Number of total missing values across all columns: 333968
Data Subset Is Off
Wells held out for testing: ['L07' 'M09']
Wells to use for training, validation, and testing ['E06' 'E07' 'M02' 'M03' 'L06' 'M08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.170055).  Saving model ...
	 Train_Loss: 0.3243 Train_Acc: 83.390 Val_Loss: 0.1701  BEST VAL Loss: 0.1701  Val_Acc: 93.845

Epoch 1: Validation loss decreased (0.170055 --> 0.151700).  Saving model ...
	 Train_Loss: 0.2767 Train_Acc: 88.615 Val_Loss: 0.1517  BEST VAL Loss: 0.1517  Val_Acc: 95.217

Epoch 2: Validation loss decreased (0.151700 --> 0.140990).  Saving model ...
	 Train_Loss: 0.2528 Train_Acc: 91.732 Val_Loss: 0.1410  BEST VAL Loss: 0.1410  Val_Acc: 95.606

Epoch 3: Validation loss decreased (0.140990 --> 0.134582).  Saving model ...
	 Train_Loss: 0.2377 Train_Acc: 92.487 Val_Loss: 0.1346  BEST VAL Loss: 0.1346  Val_Acc: 95.875

Epoch 4: Validation loss decreased (0.134582 --> 0.129586).  Saving model ...
	 Train_Loss: 0.2271 Train_Acc: 92.813 Val_Loss: 0.1296  BEST VAL Loss: 0.1296  Val_Acc: 96.066

Epoch 5: Validation loss decreased (0.129586 --> 0.126620).  Saving model ...
	 Train_Loss: 0.2191 Train_Acc: 93.034 Val_Loss: 0.1266  BEST VAL Loss: 0.1266  Val_Acc: 96.085

Epoch 6: Validation loss decreased (0.126620 --> 0.124305).  Saving model ...
	 Train_Loss: 0.2128 Train_Acc: 93.253 Val_Loss: 0.1243  BEST VAL Loss: 0.1243  Val_Acc: 96.116

Epoch 7: Validation loss decreased (0.124305 --> 0.121965).  Saving model ...
	 Train_Loss: 0.2076 Train_Acc: 93.299 Val_Loss: 0.1220  BEST VAL Loss: 0.1220  Val_Acc: 96.358

Epoch 8: Validation loss decreased (0.121965 --> 0.119646).  Saving model ...
	 Train_Loss: 0.2034 Train_Acc: 93.455 Val_Loss: 0.1196  BEST VAL Loss: 0.1196  Val_Acc: 96.373

Epoch 9: Validation loss decreased (0.119646 --> 0.117540).  Saving model ...
	 Train_Loss: 0.1997 Train_Acc: 93.634 Val_Loss: 0.1175  BEST VAL Loss: 0.1175  Val_Acc: 96.557

Epoch 10: Validation loss decreased (0.117540 --> 0.115757).  Saving model ...
	 Train_Loss: 0.1966 Train_Acc: 93.668 Val_Loss: 0.1158  BEST VAL Loss: 0.1158  Val_Acc: 96.397

Epoch 11: Validation loss decreased (0.115757 --> 0.114196).  Saving model ...
	 Train_Loss: 0.1939 Train_Acc: 93.753 Val_Loss: 0.1142  BEST VAL Loss: 0.1142  Val_Acc: 96.467

Epoch 12: Validation loss decreased (0.114196 --> 0.113229).  Saving model ...
	 Train_Loss: 0.1913 Train_Acc: 93.892 Val_Loss: 0.1132  BEST VAL Loss: 0.1132  Val_Acc: 96.307

Epoch 13: Validation loss decreased (0.113229 --> 0.112220).  Saving model ...
	 Train_Loss: 0.1892 Train_Acc: 93.874 Val_Loss: 0.1122  BEST VAL Loss: 0.1122  Val_Acc: 96.553

Epoch 14: Validation loss decreased (0.112220 --> 0.111007).  Saving model ...
	 Train_Loss: 0.1873 Train_Acc: 93.927 Val_Loss: 0.1110  BEST VAL Loss: 0.1110  Val_Acc: 96.751

Epoch 15: Validation loss decreased (0.111007 --> 0.109974).  Saving model ...
	 Train_Loss: 0.1855 Train_Acc: 93.970 Val_Loss: 0.1100  BEST VAL Loss: 0.1100  Val_Acc: 96.693

Epoch 16: Validation loss decreased (0.109974 --> 0.109015).  Saving model ...
	 Train_Loss: 0.1838 Train_Acc: 94.068 Val_Loss: 0.1090  BEST VAL Loss: 0.1090  Val_Acc: 96.720

Epoch 17: Validation loss decreased (0.109015 --> 0.108308).  Saving model ...
	 Train_Loss: 0.1823 Train_Acc: 94.106 Val_Loss: 0.1083  BEST VAL Loss: 0.1083  Val_Acc: 96.525

Epoch 18: Validation loss decreased (0.108308 --> 0.107561).  Saving model ...
	 Train_Loss: 0.1808 Train_Acc: 94.122 Val_Loss: 0.1076  BEST VAL Loss: 0.1076  Val_Acc: 96.572

Epoch 19: Validation loss decreased (0.107561 --> 0.106911).  Saving model ...
	 Train_Loss: 0.1796 Train_Acc: 94.200 Val_Loss: 0.1069  BEST VAL Loss: 0.1069  Val_Acc: 96.596

Epoch 20: Validation loss decreased (0.106911 --> 0.106548).  Saving model ...
	 Train_Loss: 0.1783 Train_Acc: 94.222 Val_Loss: 0.1065  BEST VAL Loss: 0.1065  Val_Acc: 96.475

Epoch 21: Validation loss decreased (0.106548 --> 0.106217).  Saving model ...
	 Train_Loss: 0.1772 Train_Acc: 94.327 Val_Loss: 0.1062  BEST VAL Loss: 0.1062  Val_Acc: 96.475

Epoch 22: Validation loss decreased (0.106217 --> 0.105615).  Saving model ...
	 Train_Loss: 0.1761 Train_Acc: 94.253 Val_Loss: 0.1056  BEST VAL Loss: 0.1056  Val_Acc: 96.708

Epoch 23: Validation loss decreased (0.105615 --> 0.105006).  Saving model ...
	 Train_Loss: 0.1751 Train_Acc: 94.330 Val_Loss: 0.1050  BEST VAL Loss: 0.1050  Val_Acc: 96.841

Epoch 24: Validation loss decreased (0.105006 --> 0.104486).  Saving model ...
	 Train_Loss: 0.1742 Train_Acc: 94.335 Val_Loss: 0.1045  BEST VAL Loss: 0.1045  Val_Acc: 96.712

Epoch 25: Validation loss decreased (0.104486 --> 0.103966).  Saving model ...
	 Train_Loss: 0.1733 Train_Acc: 94.393 Val_Loss: 0.1040  BEST VAL Loss: 0.1040  Val_Acc: 96.771

Epoch 26: Validation loss decreased (0.103966 --> 0.103480).  Saving model ...
	 Train_Loss: 0.1724 Train_Acc: 94.402 Val_Loss: 0.1035  BEST VAL Loss: 0.1035  Val_Acc: 96.763

Epoch 27: Validation loss decreased (0.103480 --> 0.103058).  Saving model ...
	 Train_Loss: 0.1716 Train_Acc: 94.440 Val_Loss: 0.1031  BEST VAL Loss: 0.1031  Val_Acc: 96.849

Epoch 28: Validation loss decreased (0.103058 --> 0.102641).  Saving model ...
	 Train_Loss: 0.1708 Train_Acc: 94.449 Val_Loss: 0.1026  BEST VAL Loss: 0.1026  Val_Acc: 96.724

Epoch 29: Validation loss decreased (0.102641 --> 0.102333).  Saving model ...
	 Train_Loss: 0.1701 Train_Acc: 94.557 Val_Loss: 0.1023  BEST VAL Loss: 0.1023  Val_Acc: 96.705

Epoch 30: Validation loss decreased (0.102333 --> 0.101925).  Saving model ...
	 Train_Loss: 0.1694 Train_Acc: 94.488 Val_Loss: 0.1019  BEST VAL Loss: 0.1019  Val_Acc: 96.818

Epoch 31: Validation loss decreased (0.101925 --> 0.101624).  Saving model ...
	 Train_Loss: 0.1687 Train_Acc: 94.496 Val_Loss: 0.1016  BEST VAL Loss: 0.1016  Val_Acc: 96.631

Epoch 32: Validation loss decreased (0.101624 --> 0.101301).  Saving model ...
	 Train_Loss: 0.1681 Train_Acc: 94.483 Val_Loss: 0.1013  BEST VAL Loss: 0.1013  Val_Acc: 96.806

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.1674 Train_Acc: 94.556 Val_Loss: 0.1013  BEST VAL Loss: 0.1013  Val_Acc: 96.175

Epoch 34: Validation loss decreased (0.101301 --> 0.101051).  Saving model ...
	 Train_Loss: 0.1669 Train_Acc: 94.514 Val_Loss: 0.1011  BEST VAL Loss: 0.1011  Val_Acc: 96.860

Epoch 35: Validation loss decreased (0.101051 --> 0.100809).  Saving model ...
	 Train_Loss: 0.1663 Train_Acc: 94.570 Val_Loss: 0.1008  BEST VAL Loss: 0.1008  Val_Acc: 96.716

Epoch 36: Validation loss decreased (0.100809 --> 0.100571).  Saving model ...
	 Train_Loss: 0.1658 Train_Acc: 94.518 Val_Loss: 0.1006  BEST VAL Loss: 0.1006  Val_Acc: 96.732

Epoch 37: Validation loss decreased (0.100571 --> 0.100284).  Saving model ...
	 Train_Loss: 0.1652 Train_Acc: 94.585 Val_Loss: 0.1003  BEST VAL Loss: 0.1003  Val_Acc: 96.860

Epoch 38: Validation loss decreased (0.100284 --> 0.100055).  Saving model ...
	 Train_Loss: 0.1647 Train_Acc: 94.660 Val_Loss: 0.1001  BEST VAL Loss: 0.1001  Val_Acc: 96.790

Epoch 39: Validation loss decreased (0.100055 --> 0.099779).  Saving model ...
	 Train_Loss: 0.1643 Train_Acc: 94.602 Val_Loss: 0.0998  BEST VAL Loss: 0.0998  Val_Acc: 96.895

Epoch 40: Validation loss decreased (0.099779 --> 0.099523).  Saving model ...
	 Train_Loss: 0.1638 Train_Acc: 94.623 Val_Loss: 0.0995  BEST VAL Loss: 0.0995  Val_Acc: 96.794

Epoch 41: Validation loss decreased (0.099523 --> 0.099371).  Saving model ...
	 Train_Loss: 0.1633 Train_Acc: 94.670 Val_Loss: 0.0994  BEST VAL Loss: 0.0994  Val_Acc: 96.568

Epoch 42: Validation loss decreased (0.099371 --> 0.099123).  Saving model ...
	 Train_Loss: 0.1629 Train_Acc: 94.742 Val_Loss: 0.0991  BEST VAL Loss: 0.0991  Val_Acc: 96.981

Epoch 43: Validation loss decreased (0.099123 --> 0.099076).  Saving model ...
	 Train_Loss: 0.1624 Train_Acc: 94.731 Val_Loss: 0.0991  BEST VAL Loss: 0.0991  Val_Acc: 96.529

Epoch 44: Validation loss decreased (0.099076 --> 0.098868).  Saving model ...
	 Train_Loss: 0.1620 Train_Acc: 94.668 Val_Loss: 0.0989  BEST VAL Loss: 0.0989  Val_Acc: 96.759

Epoch 45: Validation loss decreased (0.098868 --> 0.098614).  Saving model ...
	 Train_Loss: 0.1616 Train_Acc: 94.738 Val_Loss: 0.0986  BEST VAL Loss: 0.0986  Val_Acc: 96.997

Epoch 46: Validation loss decreased (0.098614 --> 0.098373).  Saving model ...
	 Train_Loss: 0.1612 Train_Acc: 94.732 Val_Loss: 0.0984  BEST VAL Loss: 0.0984  Val_Acc: 97.001

Epoch 47: Validation loss decreased (0.098373 --> 0.098102).  Saving model ...
	 Train_Loss: 0.1609 Train_Acc: 94.716 Val_Loss: 0.0981  BEST VAL Loss: 0.0981  Val_Acc: 96.981

Epoch 48: Validation loss decreased (0.098102 --> 0.097878).  Saving model ...
	 Train_Loss: 0.1605 Train_Acc: 94.691 Val_Loss: 0.0979  BEST VAL Loss: 0.0979  Val_Acc: 96.931

Epoch 49: Validation loss decreased (0.097878 --> 0.097663).  Saving model ...
	 Train_Loss: 0.1601 Train_Acc: 94.787 Val_Loss: 0.0977  BEST VAL Loss: 0.0977  Val_Acc: 96.849

Epoch 50: Validation loss decreased (0.097663 --> 0.097482).  Saving model ...
	 Train_Loss: 0.1597 Train_Acc: 94.836 Val_Loss: 0.0975  BEST VAL Loss: 0.0975  Val_Acc: 96.888

Epoch 51: Validation loss decreased (0.097482 --> 0.097238).  Saving model ...
	 Train_Loss: 0.1594 Train_Acc: 94.790 Val_Loss: 0.0972  BEST VAL Loss: 0.0972  Val_Acc: 97.028

Epoch 52: Validation loss decreased (0.097238 --> 0.097014).  Saving model ...
	 Train_Loss: 0.1591 Train_Acc: 94.755 Val_Loss: 0.0970  BEST VAL Loss: 0.0970  Val_Acc: 97.114

Epoch 53: Validation loss decreased (0.097014 --> 0.096842).  Saving model ...
	 Train_Loss: 0.1587 Train_Acc: 94.807 Val_Loss: 0.0968  BEST VAL Loss: 0.0968  Val_Acc: 96.997

Epoch 54: Validation loss decreased (0.096842 --> 0.096627).  Saving model ...
	 Train_Loss: 0.1584 Train_Acc: 94.809 Val_Loss: 0.0966  BEST VAL Loss: 0.0966  Val_Acc: 97.063

Epoch 55: Validation loss decreased (0.096627 --> 0.096526).  Saving model ...
	 Train_Loss: 0.1581 Train_Acc: 94.793 Val_Loss: 0.0965  BEST VAL Loss: 0.0965  Val_Acc: 96.829

Epoch 56: Validation loss decreased (0.096526 --> 0.096310).  Saving model ...
	 Train_Loss: 0.1578 Train_Acc: 94.837 Val_Loss: 0.0963  BEST VAL Loss: 0.0963  Val_Acc: 97.133

Epoch 57: Validation loss decreased (0.096310 --> 0.096137).  Saving model ...
	 Train_Loss: 0.1575 Train_Acc: 94.857 Val_Loss: 0.0961  BEST VAL Loss: 0.0961  Val_Acc: 97.043

Epoch 58: Validation loss decreased (0.096137 --> 0.095956).  Saving model ...
	 Train_Loss: 0.1572 Train_Acc: 94.802 Val_Loss: 0.0960  BEST VAL Loss: 0.0960  Val_Acc: 97.024

Epoch 59: Validation loss decreased (0.095956 --> 0.095833).  Saving model ...
	 Train_Loss: 0.1569 Train_Acc: 94.887 Val_Loss: 0.0958  BEST VAL Loss: 0.0958  Val_Acc: 96.911

Epoch 60: Validation loss decreased (0.095833 --> 0.095719).  Saving model ...
	 Train_Loss: 0.1567 Train_Acc: 94.816 Val_Loss: 0.0957  BEST VAL Loss: 0.0957  Val_Acc: 96.720

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.1564 Train_Acc: 94.852 Val_Loss: 0.0957  BEST VAL Loss: 0.0957  Val_Acc: 96.498

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.1561 Train_Acc: 94.876 Val_Loss: 0.0960  BEST VAL Loss: 0.0957  Val_Acc: 96.486

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.1559 Train_Acc: 94.839 Val_Loss: 0.0958  BEST VAL Loss: 0.0957  Val_Acc: 96.989

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.1557 Train_Acc: 94.908 Val_Loss: 0.0958  BEST VAL Loss: 0.0957  Val_Acc: 96.927

Epoch 65: Validation loss decreased (0.095719 --> 0.095679).  Saving model ...
	 Train_Loss: 0.1554 Train_Acc: 94.875 Val_Loss: 0.0957  BEST VAL Loss: 0.0957  Val_Acc: 96.732

Epoch 66: Validation loss decreased (0.095679 --> 0.095519).  Saving model ...
	 Train_Loss: 0.1552 Train_Acc: 94.923 Val_Loss: 0.0955  BEST VAL Loss: 0.0955  Val_Acc: 96.981

Epoch 67: Validation loss decreased (0.095519 --> 0.095382).  Saving model ...
	 Train_Loss: 0.1549 Train_Acc: 94.963 Val_Loss: 0.0954  BEST VAL Loss: 0.0954  Val_Acc: 96.892

Epoch 68: Validation loss decreased (0.095382 --> 0.095230).  Saving model ...
	 Train_Loss: 0.1547 Train_Acc: 94.893 Val_Loss: 0.0952  BEST VAL Loss: 0.0952  Val_Acc: 96.966

Epoch 69: Validation loss decreased (0.095230 --> 0.095111).  Saving model ...
	 Train_Loss: 0.1545 Train_Acc: 94.980 Val_Loss: 0.0951  BEST VAL Loss: 0.0951  Val_Acc: 96.884

Epoch 70: Validation loss decreased (0.095111 --> 0.094956).  Saving model ...
	 Train_Loss: 0.1542 Train_Acc: 94.947 Val_Loss: 0.0950  BEST VAL Loss: 0.0950  Val_Acc: 97.176

Epoch 71: Validation loss decreased (0.094956 --> 0.094855).  Saving model ...
	 Train_Loss: 0.1540 Train_Acc: 94.973 Val_Loss: 0.0949  BEST VAL Loss: 0.0949  Val_Acc: 96.876

Epoch 72: Validation loss decreased (0.094855 --> 0.094719).  Saving model ...
	 Train_Loss: 0.1538 Train_Acc: 94.946 Val_Loss: 0.0947  BEST VAL Loss: 0.0947  Val_Acc: 97.047

Epoch 73: Validation loss decreased (0.094719 --> 0.094582).  Saving model ...
	 Train_Loss: 0.1536 Train_Acc: 94.999 Val_Loss: 0.0946  BEST VAL Loss: 0.0946  Val_Acc: 97.090

Epoch 74: Validation loss decreased (0.094582 --> 0.094486).  Saving model ...
	 Train_Loss: 0.1534 Train_Acc: 95.015 Val_Loss: 0.0945  BEST VAL Loss: 0.0945  Val_Acc: 96.864

Epoch 75: Validation loss decreased (0.094486 --> 0.094390).  Saving model ...
	 Train_Loss: 0.1531 Train_Acc: 95.023 Val_Loss: 0.0944  BEST VAL Loss: 0.0944  Val_Acc: 96.985

Epoch 76: Validation loss decreased (0.094390 --> 0.094290).  Saving model ...
	 Train_Loss: 0.1529 Train_Acc: 94.974 Val_Loss: 0.0943  BEST VAL Loss: 0.0943  Val_Acc: 96.938

Epoch 77: Validation loss decreased (0.094290 --> 0.094200).  Saving model ...
	 Train_Loss: 0.1528 Train_Acc: 95.009 Val_Loss: 0.0942  BEST VAL Loss: 0.0942  Val_Acc: 96.981

Epoch 78: Validation loss decreased (0.094200 --> 0.094116).  Saving model ...
	 Train_Loss: 0.1526 Train_Acc: 95.041 Val_Loss: 0.0941  BEST VAL Loss: 0.0941  Val_Acc: 96.868

Epoch 79: Validation loss decreased (0.094116 --> 0.094009).  Saving model ...
	 Train_Loss: 0.1524 Train_Acc: 95.060 Val_Loss: 0.0940  BEST VAL Loss: 0.0940  Val_Acc: 97.012

Epoch 80: Validation loss decreased (0.094009 --> 0.093902).  Saving model ...
	 Train_Loss: 0.1522 Train_Acc: 95.030 Val_Loss: 0.0939  BEST VAL Loss: 0.0939  Val_Acc: 96.969

Epoch 81: Validation loss decreased (0.093902 --> 0.093838).  Saving model ...
	 Train_Loss: 0.1520 Train_Acc: 95.061 Val_Loss: 0.0938  BEST VAL Loss: 0.0938  Val_Acc: 96.782

Epoch 82: Validation loss decreased (0.093838 --> 0.093736).  Saving model ...
	 Train_Loss: 0.1518 Train_Acc: 95.064 Val_Loss: 0.0937  BEST VAL Loss: 0.0937  Val_Acc: 97.121

Epoch 83: Validation loss decreased (0.093736 --> 0.093621).  Saving model ...
	 Train_Loss: 0.1516 Train_Acc: 95.117 Val_Loss: 0.0936  BEST VAL Loss: 0.0936  Val_Acc: 97.086

Epoch 84: Validation loss decreased (0.093621 --> 0.093548).  Saving model ...
	 Train_Loss: 0.1514 Train_Acc: 95.136 Val_Loss: 0.0935  BEST VAL Loss: 0.0935  Val_Acc: 96.923

Epoch 85: Validation loss decreased (0.093548 --> 0.093448).  Saving model ...
	 Train_Loss: 0.1512 Train_Acc: 95.076 Val_Loss: 0.0934  BEST VAL Loss: 0.0934  Val_Acc: 97.117

Epoch 86: Validation loss decreased (0.093448 --> 0.093338).  Saving model ...
	 Train_Loss: 0.1511 Train_Acc: 95.121 Val_Loss: 0.0933  BEST VAL Loss: 0.0933  Val_Acc: 97.102

Epoch 87: Validation loss decreased (0.093338 --> 0.093256).  Saving model ...
	 Train_Loss: 0.1509 Train_Acc: 95.082 Val_Loss: 0.0933  BEST VAL Loss: 0.0933  Val_Acc: 96.950

Epoch 88: Validation loss decreased (0.093256 --> 0.093163).  Saving model ...
	 Train_Loss: 0.1507 Train_Acc: 95.189 Val_Loss: 0.0932  BEST VAL Loss: 0.0932  Val_Acc: 96.981

Epoch 89: Validation loss decreased (0.093163 --> 0.093051).  Saving model ...
	 Train_Loss: 0.1505 Train_Acc: 95.027 Val_Loss: 0.0931  BEST VAL Loss: 0.0931  Val_Acc: 97.117

Epoch 90: Validation loss decreased (0.093051 --> 0.092983).  Saving model ...
	 Train_Loss: 0.1504 Train_Acc: 95.097 Val_Loss: 0.0930  BEST VAL Loss: 0.0930  Val_Acc: 96.903

Epoch 91: Validation loss decreased (0.092983 --> 0.092869).  Saving model ...
	 Train_Loss: 0.1502 Train_Acc: 95.071 Val_Loss: 0.0929  BEST VAL Loss: 0.0929  Val_Acc: 97.246

Epoch 92: Validation loss decreased (0.092869 --> 0.092836).  Saving model ...
	 Train_Loss: 0.1501 Train_Acc: 95.157 Val_Loss: 0.0928  BEST VAL Loss: 0.0928  Val_Acc: 96.810

Epoch 93: Validation loss decreased (0.092836 --> 0.092746).  Saving model ...
	 Train_Loss: 0.1499 Train_Acc: 95.075 Val_Loss: 0.0927  BEST VAL Loss: 0.0927  Val_Acc: 97.059

Epoch 94: Validation loss decreased (0.092746 --> 0.092643).  Saving model ...
	 Train_Loss: 0.1498 Train_Acc: 95.089 Val_Loss: 0.0926  BEST VAL Loss: 0.0926  Val_Acc: 97.067

Epoch 95: Validation loss decreased (0.092643 --> 0.092570).  Saving model ...
	 Train_Loss: 0.1496 Train_Acc: 95.179 Val_Loss: 0.0926  BEST VAL Loss: 0.0926  Val_Acc: 97.051

Epoch 96: Validation loss decreased (0.092570 --> 0.092471).  Saving model ...
	 Train_Loss: 0.1494 Train_Acc: 95.176 Val_Loss: 0.0925  BEST VAL Loss: 0.0925  Val_Acc: 97.137

Epoch 97: Validation loss decreased (0.092471 --> 0.092404).  Saving model ...
	 Train_Loss: 0.1493 Train_Acc: 95.159 Val_Loss: 0.0924  BEST VAL Loss: 0.0924  Val_Acc: 97.051

Epoch 98: Validation loss decreased (0.092404 --> 0.092320).  Saving model ...
	 Train_Loss: 0.1491 Train_Acc: 95.166 Val_Loss: 0.0923  BEST VAL Loss: 0.0923  Val_Acc: 97.086

Epoch 99: Validation loss decreased (0.092320 --> 0.092272).  Saving model ...
	 Train_Loss: 0.1490 Train_Acc: 95.144 Val_Loss: 0.0923  BEST VAL Loss: 0.0923  Val_Acc: 97.047

Thapsigargin_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.51      0.51    105241
           1       0.49      0.49      0.49    100127

    accuracy                           0.50    205368
   macro avg       0.50      0.50      0.50    205368
weighted avg       0.50      0.50      0.50    205368

Thapsigargin_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.52      0.52     13156
           1       0.49      0.49      0.49     12516

    accuracy                           0.50     25672
   macro avg       0.50      0.50      0.50     25672
weighted avg       0.50      0.50      0.50     25672

Thapsigargin_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.51      0.51     13155
           1       0.48      0.49      0.48     12516

    accuracy                           0.50     25671
   macro avg       0.50      0.50      0.50     25671
weighted avg       0.50      0.50      0.50     25671

              precision    recall  f1-score   support

           0       0.51      0.51      0.51     13155
           1       0.48      0.49      0.48     12516

    accuracy                           0.50     25671
   macro avg       0.50      0.50      0.50     25671
weighted avg       0.50      0.50      0.50     25671

Thapsigargin_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.55      0.55     49614
           1       0.46      0.46      0.46     41825

    accuracy                           0.51     91439
   macro avg       0.50      0.50      0.50     91439
weighted avg       0.51      0.51      0.51     91439

              precision    recall  f1-score   support

           0       0.55      0.55      0.55     49614
           1       0.46      0.46      0.46     41825

    accuracy                           0.51     91439
   macro avg       0.50      0.50      0.50     91439
weighted avg       0.51      0.51      0.51     91439

completed
