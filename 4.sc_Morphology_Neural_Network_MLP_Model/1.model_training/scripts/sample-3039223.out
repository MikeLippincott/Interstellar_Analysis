[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '16b4ab5f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'bfc4cfb5'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '4951e2fd'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '96d5ba9d'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: DMSO_0.100_DMSO_0.025 treatment_name: Thapsigargin_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: DMSO_0.100_DMSO_0.025
TREATMENT_NAME: Thapsigargin_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'Thapsigargin_1.000_DMSO_0.025']
The dimensions of the data are: (363586, 1270)
Number of total missing values across all columns: 727172
Data Subset Is Off
Wells held out for testing: ['J06' 'K07']
Wells to use for training, validation, and testing ['B06' 'C06' 'B07' 'C07' 'D06' 'D07' 'I06' 'I07' 'K06' 'J07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.548597).  Saving model ...
	 Train_Loss: 0.6164 Train_Acc: 65.988 Val_Loss: 0.5486  BEST VAL Loss: 0.5486  Val_Acc: 71.754

Epoch 1: Validation loss decreased (0.548597 --> 0.525779).  Saving model ...
	 Train_Loss: 0.5927 Train_Acc: 69.727 Val_Loss: 0.5258  BEST VAL Loss: 0.5258  Val_Acc: 75.023

Epoch 2: Validation loss decreased (0.525779 --> 0.515295).  Saving model ...
	 Train_Loss: 0.5774 Train_Acc: 71.148 Val_Loss: 0.5153  BEST VAL Loss: 0.5153  Val_Acc: 75.672

Epoch 3: Validation loss decreased (0.515295 --> 0.505023).  Saving model ...
	 Train_Loss: 0.5661 Train_Acc: 71.968 Val_Loss: 0.5050  BEST VAL Loss: 0.5050  Val_Acc: 76.842

Epoch 4: Validation loss decreased (0.505023 --> 0.493976).  Saving model ...
	 Train_Loss: 0.5574 Train_Acc: 72.696 Val_Loss: 0.4940  BEST VAL Loss: 0.4940  Val_Acc: 78.366

Epoch 5: Validation loss decreased (0.493976 --> 0.485559).  Saving model ...
	 Train_Loss: 0.5498 Train_Acc: 73.275 Val_Loss: 0.4856  BEST VAL Loss: 0.4856  Val_Acc: 79.364

Epoch 6: Validation loss decreased (0.485559 --> 0.478300).  Saving model ...
	 Train_Loss: 0.5432 Train_Acc: 73.650 Val_Loss: 0.4783  BEST VAL Loss: 0.4783  Val_Acc: 79.738

Epoch 7: Validation loss decreased (0.478300 --> 0.472076).  Saving model ...
	 Train_Loss: 0.5372 Train_Acc: 74.153 Val_Loss: 0.4721  BEST VAL Loss: 0.4721  Val_Acc: 80.286

Epoch 8: Validation loss decreased (0.472076 --> 0.465461).  Saving model ...
	 Train_Loss: 0.5319 Train_Acc: 74.522 Val_Loss: 0.4655  BEST VAL Loss: 0.4655  Val_Acc: 80.911

Epoch 9: Validation loss decreased (0.465461 --> 0.459660).  Saving model ...
	 Train_Loss: 0.5272 Train_Acc: 74.708 Val_Loss: 0.4597  BEST VAL Loss: 0.4597  Val_Acc: 81.110

Epoch 10: Validation loss decreased (0.459660 --> 0.454357).  Saving model ...
	 Train_Loss: 0.5228 Train_Acc: 74.971 Val_Loss: 0.4544  BEST VAL Loss: 0.4544  Val_Acc: 81.500

Epoch 11: Validation loss decreased (0.454357 --> 0.450178).  Saving model ...
	 Train_Loss: 0.5191 Train_Acc: 75.096 Val_Loss: 0.4502  BEST VAL Loss: 0.4502  Val_Acc: 81.675

Epoch 12: Validation loss decreased (0.450178 --> 0.446604).  Saving model ...
	 Train_Loss: 0.5156 Train_Acc: 75.210 Val_Loss: 0.4466  BEST VAL Loss: 0.4466  Val_Acc: 81.564

Epoch 13: Validation loss decreased (0.446604 --> 0.442429).  Saving model ...
	 Train_Loss: 0.5125 Train_Acc: 75.239 Val_Loss: 0.4424  BEST VAL Loss: 0.4424  Val_Acc: 81.900

Epoch 14: Validation loss decreased (0.442429 --> 0.438802).  Saving model ...
	 Train_Loss: 0.5096 Train_Acc: 75.367 Val_Loss: 0.4388  BEST VAL Loss: 0.4388  Val_Acc: 82.593

Epoch 15: Validation loss decreased (0.438802 --> 0.435486).  Saving model ...
	 Train_Loss: 0.5070 Train_Acc: 75.421 Val_Loss: 0.4355  BEST VAL Loss: 0.4355  Val_Acc: 82.768

Epoch 16: Validation loss decreased (0.435486 --> 0.432550).  Saving model ...
	 Train_Loss: 0.5045 Train_Acc: 75.513 Val_Loss: 0.4326  BEST VAL Loss: 0.4326  Val_Acc: 82.838

Epoch 17: Validation loss decreased (0.432550 --> 0.430033).  Saving model ...
	 Train_Loss: 0.5023 Train_Acc: 75.465 Val_Loss: 0.4300  BEST VAL Loss: 0.4300  Val_Acc: 82.317

Epoch 18: Validation loss decreased (0.430033 --> 0.427207).  Saving model ...
	 Train_Loss: 0.5003 Train_Acc: 75.662 Val_Loss: 0.4272  BEST VAL Loss: 0.4272  Val_Acc: 82.741

Epoch 19: Validation loss decreased (0.427207 --> 0.424975).  Saving model ...
	 Train_Loss: 0.4983 Train_Acc: 75.716 Val_Loss: 0.4250  BEST VAL Loss: 0.4250  Val_Acc: 82.956

Epoch 20: Validation loss decreased (0.424975 --> 0.423332).  Saving model ...
	 Train_Loss: 0.4965 Train_Acc: 75.690 Val_Loss: 0.4233  BEST VAL Loss: 0.4233  Val_Acc: 82.304

Epoch 21: Validation loss decreased (0.423332 --> 0.421330).  Saving model ...
	 Train_Loss: 0.4949 Train_Acc: 75.595 Val_Loss: 0.4213  BEST VAL Loss: 0.4213  Val_Acc: 82.798

Epoch 22: Validation loss decreased (0.421330 --> 0.419702).  Saving model ...
	 Train_Loss: 0.4934 Train_Acc: 75.742 Val_Loss: 0.4197  BEST VAL Loss: 0.4197  Val_Acc: 82.943

Epoch 23: Validation loss decreased (0.419702 --> 0.417663).  Saving model ...
	 Train_Loss: 0.4919 Train_Acc: 75.723 Val_Loss: 0.4177  BEST VAL Loss: 0.4177  Val_Acc: 83.578

Epoch 24: Validation loss decreased (0.417663 --> 0.416084).  Saving model ...
	 Train_Loss: 0.4904 Train_Acc: 75.879 Val_Loss: 0.4161  BEST VAL Loss: 0.4161  Val_Acc: 82.788

Epoch 25: Validation loss decreased (0.416084 --> 0.414510).  Saving model ...
	 Train_Loss: 0.4891 Train_Acc: 75.872 Val_Loss: 0.4145  BEST VAL Loss: 0.4145  Val_Acc: 83.114

Epoch 26: Validation loss decreased (0.414510 --> 0.413088).  Saving model ...
	 Train_Loss: 0.4879 Train_Acc: 75.875 Val_Loss: 0.4131  BEST VAL Loss: 0.4131  Val_Acc: 82.986

Epoch 27: Validation loss decreased (0.413088 --> 0.411995).  Saving model ...
	 Train_Loss: 0.4868 Train_Acc: 75.717 Val_Loss: 0.4120  BEST VAL Loss: 0.4120  Val_Acc: 83.044

Epoch 28: Validation loss decreased (0.411995 --> 0.410592).  Saving model ...
	 Train_Loss: 0.4857 Train_Acc: 75.872 Val_Loss: 0.4106  BEST VAL Loss: 0.4106  Val_Acc: 83.017

Epoch 29: Validation loss decreased (0.410592 --> 0.409334).  Saving model ...
	 Train_Loss: 0.4846 Train_Acc: 75.988 Val_Loss: 0.4093  BEST VAL Loss: 0.4093  Val_Acc: 82.885

Epoch 30: Validation loss decreased (0.409334 --> 0.407753).  Saving model ...
	 Train_Loss: 0.4836 Train_Acc: 76.019 Val_Loss: 0.4078  BEST VAL Loss: 0.4078  Val_Acc: 83.820

Epoch 31: Validation loss decreased (0.407753 --> 0.406538).  Saving model ...
	 Train_Loss: 0.4826 Train_Acc: 75.960 Val_Loss: 0.4065  BEST VAL Loss: 0.4065  Val_Acc: 83.561

Epoch 32: Validation loss decreased (0.406538 --> 0.405316).  Saving model ...
	 Train_Loss: 0.4817 Train_Acc: 75.937 Val_Loss: 0.4053  BEST VAL Loss: 0.4053  Val_Acc: 83.730

Epoch 33: Validation loss decreased (0.405316 --> 0.404210).  Saving model ...
	 Train_Loss: 0.4808 Train_Acc: 76.115 Val_Loss: 0.4042  BEST VAL Loss: 0.4042  Val_Acc: 83.481

Epoch 34: Validation loss decreased (0.404210 --> 0.403041).  Saving model ...
	 Train_Loss: 0.4800 Train_Acc: 75.960 Val_Loss: 0.4030  BEST VAL Loss: 0.4030  Val_Acc: 83.683

Epoch 35: Validation loss decreased (0.403041 --> 0.402078).  Saving model ...
	 Train_Loss: 0.4792 Train_Acc: 76.008 Val_Loss: 0.4021  BEST VAL Loss: 0.4021  Val_Acc: 84.026

Epoch 36: Validation loss decreased (0.402078 --> 0.401444).  Saving model ...
	 Train_Loss: 0.4784 Train_Acc: 76.013 Val_Loss: 0.4014  BEST VAL Loss: 0.4014  Val_Acc: 83.605

Epoch 37: Validation loss decreased (0.401444 --> 0.400437).  Saving model ...
	 Train_Loss: 0.4777 Train_Acc: 76.104 Val_Loss: 0.4004  BEST VAL Loss: 0.4004  Val_Acc: 83.565

Epoch 38: Validation loss decreased (0.400437 --> 0.399861).  Saving model ...
	 Train_Loss: 0.4770 Train_Acc: 76.009 Val_Loss: 0.3999  BEST VAL Loss: 0.3999  Val_Acc: 82.912

Epoch 39: Validation loss decreased (0.399861 --> 0.399127).  Saving model ...
	 Train_Loss: 0.4762 Train_Acc: 76.239 Val_Loss: 0.3991  BEST VAL Loss: 0.3991  Val_Acc: 83.514

Epoch 40: Validation loss decreased (0.399127 --> 0.398174).  Saving model ...
	 Train_Loss: 0.4756 Train_Acc: 76.045 Val_Loss: 0.3982  BEST VAL Loss: 0.3982  Val_Acc: 83.639

Epoch 41: Validation loss decreased (0.398174 --> 0.397283).  Saving model ...
	 Train_Loss: 0.4749 Train_Acc: 76.087 Val_Loss: 0.3973  BEST VAL Loss: 0.3973  Val_Acc: 83.867

Epoch 42: Validation loss decreased (0.397283 --> 0.396666).  Saving model ...
	 Train_Loss: 0.4743 Train_Acc: 76.199 Val_Loss: 0.3967  BEST VAL Loss: 0.3967  Val_Acc: 83.020

Epoch 43: Validation loss decreased (0.396666 --> 0.395947).  Saving model ...
	 Train_Loss: 0.4737 Train_Acc: 76.004 Val_Loss: 0.3959  BEST VAL Loss: 0.3959  Val_Acc: 83.501

Epoch 44: Validation loss decreased (0.395947 --> 0.395395).  Saving model ...
	 Train_Loss: 0.4732 Train_Acc: 76.186 Val_Loss: 0.3954  BEST VAL Loss: 0.3954  Val_Acc: 83.585

Epoch 45: Validation loss decreased (0.395395 --> 0.394701).  Saving model ...
	 Train_Loss: 0.4726 Train_Acc: 76.216 Val_Loss: 0.3947  BEST VAL Loss: 0.3947  Val_Acc: 83.770

Epoch 46: Validation loss decreased (0.394701 --> 0.393951).  Saving model ...
	 Train_Loss: 0.4721 Train_Acc: 76.190 Val_Loss: 0.3940  BEST VAL Loss: 0.3940  Val_Acc: 83.881

Epoch 47: Validation loss decreased (0.393951 --> 0.393054).  Saving model ...
	 Train_Loss: 0.4715 Train_Acc: 76.193 Val_Loss: 0.3931  BEST VAL Loss: 0.3931  Val_Acc: 84.227

Epoch 48: Validation loss decreased (0.393054 --> 0.392549).  Saving model ...
	 Train_Loss: 0.4710 Train_Acc: 76.349 Val_Loss: 0.3925  BEST VAL Loss: 0.3925  Val_Acc: 83.878

Epoch 49: Validation loss decreased (0.392549 --> 0.392014).  Saving model ...
	 Train_Loss: 0.4704 Train_Acc: 76.255 Val_Loss: 0.3920  BEST VAL Loss: 0.3920  Val_Acc: 83.588

Epoch 50: Validation loss decreased (0.392014 --> 0.391425).  Saving model ...
	 Train_Loss: 0.4699 Train_Acc: 76.249 Val_Loss: 0.3914  BEST VAL Loss: 0.3914  Val_Acc: 84.063

Epoch 51: Validation loss decreased (0.391425 --> 0.390787).  Saving model ...
	 Train_Loss: 0.4694 Train_Acc: 76.207 Val_Loss: 0.3908  BEST VAL Loss: 0.3908  Val_Acc: 83.696

Epoch 52: Validation loss decreased (0.390787 --> 0.390229).  Saving model ...
	 Train_Loss: 0.4690 Train_Acc: 76.267 Val_Loss: 0.3902  BEST VAL Loss: 0.3902  Val_Acc: 83.450

Epoch 53: Validation loss decreased (0.390229 --> 0.389687).  Saving model ...
	 Train_Loss: 0.4686 Train_Acc: 76.265 Val_Loss: 0.3897  BEST VAL Loss: 0.3897  Val_Acc: 83.955

Epoch 54: Validation loss decreased (0.389687 --> 0.389420).  Saving model ...
	 Train_Loss: 0.4681 Train_Acc: 76.172 Val_Loss: 0.3894  BEST VAL Loss: 0.3894  Val_Acc: 83.101

Epoch 55: Validation loss decreased (0.389420 --> 0.389052).  Saving model ...
	 Train_Loss: 0.4677 Train_Acc: 76.212 Val_Loss: 0.3891  BEST VAL Loss: 0.3891  Val_Acc: 83.952

Epoch 56: Validation loss decreased (0.389052 --> 0.388674).  Saving model ...
	 Train_Loss: 0.4673 Train_Acc: 76.373 Val_Loss: 0.3887  BEST VAL Loss: 0.3887  Val_Acc: 83.309

Epoch 57: Validation loss decreased (0.388674 --> 0.388271).  Saving model ...
	 Train_Loss: 0.4669 Train_Acc: 76.100 Val_Loss: 0.3883  BEST VAL Loss: 0.3883  Val_Acc: 84.237

Epoch 58: Validation loss decreased (0.388271 --> 0.387930).  Saving model ...
	 Train_Loss: 0.4665 Train_Acc: 76.314 Val_Loss: 0.3879  BEST VAL Loss: 0.3879  Val_Acc: 83.952

Epoch 59: Validation loss decreased (0.387930 --> 0.387461).  Saving model ...
	 Train_Loss: 0.4661 Train_Acc: 76.430 Val_Loss: 0.3875  BEST VAL Loss: 0.3875  Val_Acc: 83.904

Epoch 60: Validation loss decreased (0.387461 --> 0.386979).  Saving model ...
	 Train_Loss: 0.4657 Train_Acc: 76.337 Val_Loss: 0.3870  BEST VAL Loss: 0.3870  Val_Acc: 84.066

Epoch 61: Validation loss decreased (0.386979 --> 0.386424).  Saving model ...
	 Train_Loss: 0.4653 Train_Acc: 76.345 Val_Loss: 0.3864  BEST VAL Loss: 0.3864  Val_Acc: 84.029

Epoch 62: Validation loss decreased (0.386424 --> 0.386135).  Saving model ...
	 Train_Loss: 0.4650 Train_Acc: 76.374 Val_Loss: 0.3861  BEST VAL Loss: 0.3861  Val_Acc: 84.026

Epoch 63: Validation loss decreased (0.386135 --> 0.385654).  Saving model ...
	 Train_Loss: 0.4647 Train_Acc: 76.219 Val_Loss: 0.3857  BEST VAL Loss: 0.3857  Val_Acc: 83.958

Epoch 64: Validation loss decreased (0.385654 --> 0.385179).  Saving model ...
	 Train_Loss: 0.4643 Train_Acc: 76.388 Val_Loss: 0.3852  BEST VAL Loss: 0.3852  Val_Acc: 83.847

Epoch 65: Validation loss decreased (0.385179 --> 0.384785).  Saving model ...
	 Train_Loss: 0.4640 Train_Acc: 76.336 Val_Loss: 0.3848  BEST VAL Loss: 0.3848  Val_Acc: 84.194

Epoch 66: Validation loss decreased (0.384785 --> 0.384354).  Saving model ...
	 Train_Loss: 0.4636 Train_Acc: 76.350 Val_Loss: 0.3844  BEST VAL Loss: 0.3844  Val_Acc: 84.170

Epoch 67: Validation loss decreased (0.384354 --> 0.383935).  Saving model ...
	 Train_Loss: 0.4633 Train_Acc: 76.472 Val_Loss: 0.3839  BEST VAL Loss: 0.3839  Val_Acc: 84.379

Epoch 68: Validation loss decreased (0.383935 --> 0.383551).  Saving model ...
	 Train_Loss: 0.4630 Train_Acc: 76.426 Val_Loss: 0.3836  BEST VAL Loss: 0.3836  Val_Acc: 84.106

Epoch 69: Validation loss decreased (0.383551 --> 0.383150).  Saving model ...
	 Train_Loss: 0.4627 Train_Acc: 76.295 Val_Loss: 0.3831  BEST VAL Loss: 0.3831  Val_Acc: 84.224

Epoch 70: Validation loss decreased (0.383150 --> 0.382763).  Saving model ...
	 Train_Loss: 0.4624 Train_Acc: 76.361 Val_Loss: 0.3828  BEST VAL Loss: 0.3828  Val_Acc: 84.147

Epoch 71: Validation loss decreased (0.382763 --> 0.382546).  Saving model ...
	 Train_Loss: 0.4621 Train_Acc: 76.358 Val_Loss: 0.3825  BEST VAL Loss: 0.3825  Val_Acc: 83.262

Epoch 72: Validation loss decreased (0.382546 --> 0.382238).  Saving model ...
	 Train_Loss: 0.4618 Train_Acc: 76.373 Val_Loss: 0.3822  BEST VAL Loss: 0.3822  Val_Acc: 84.100

Epoch 73: Validation loss decreased (0.382238 --> 0.381873).  Saving model ...
	 Train_Loss: 0.4615 Train_Acc: 76.379 Val_Loss: 0.3819  BEST VAL Loss: 0.3819  Val_Acc: 84.116

Epoch 74: Validation loss decreased (0.381873 --> 0.381548).  Saving model ...
	 Train_Loss: 0.4612 Train_Acc: 76.459 Val_Loss: 0.3815  BEST VAL Loss: 0.3815  Val_Acc: 84.143

Epoch 75: Validation loss decreased (0.381548 --> 0.381149).  Saving model ...
	 Train_Loss: 0.4609 Train_Acc: 76.386 Val_Loss: 0.3811  BEST VAL Loss: 0.3811  Val_Acc: 84.052

Epoch 76: Validation loss decreased (0.381149 --> 0.380882).  Saving model ...
	 Train_Loss: 0.4607 Train_Acc: 76.429 Val_Loss: 0.3809  BEST VAL Loss: 0.3809  Val_Acc: 83.763

Epoch 77: Validation loss decreased (0.380882 --> 0.380812).  Saving model ...
	 Train_Loss: 0.4604 Train_Acc: 76.426 Val_Loss: 0.3808  BEST VAL Loss: 0.3808  Val_Acc: 83.683

Epoch 78: Validation loss decreased (0.380812 --> 0.380673).  Saving model ...
	 Train_Loss: 0.4602 Train_Acc: 76.451 Val_Loss: 0.3807  BEST VAL Loss: 0.3807  Val_Acc: 83.837

Epoch 79: Validation loss decreased (0.380673 --> 0.380390).  Saving model ...
	 Train_Loss: 0.4599 Train_Acc: 76.430 Val_Loss: 0.3804  BEST VAL Loss: 0.3804  Val_Acc: 83.841

Epoch 80: Validation loss decreased (0.380390 --> 0.380057).  Saving model ...
	 Train_Loss: 0.4597 Train_Acc: 76.529 Val_Loss: 0.3801  BEST VAL Loss: 0.3801  Val_Acc: 84.059

Epoch 81: Validation loss decreased (0.380057 --> 0.379844).  Saving model ...
	 Train_Loss: 0.4594 Train_Acc: 76.617 Val_Loss: 0.3798  BEST VAL Loss: 0.3798  Val_Acc: 84.130

Epoch 82: Validation loss decreased (0.379844 --> 0.379652).  Saving model ...
	 Train_Loss: 0.4592 Train_Acc: 76.383 Val_Loss: 0.3797  BEST VAL Loss: 0.3797  Val_Acc: 83.676

Epoch 83: Validation loss decreased (0.379652 --> 0.379353).  Saving model ...
	 Train_Loss: 0.4589 Train_Acc: 76.425 Val_Loss: 0.3794  BEST VAL Loss: 0.3794  Val_Acc: 84.342

Epoch 84: Validation loss decreased (0.379353 --> 0.379031).  Saving model ...
	 Train_Loss: 0.4587 Train_Acc: 76.562 Val_Loss: 0.3790  BEST VAL Loss: 0.3790  Val_Acc: 84.248

Epoch 85: Validation loss decreased (0.379031 --> 0.378721).  Saving model ...
	 Train_Loss: 0.4584 Train_Acc: 76.477 Val_Loss: 0.3787  BEST VAL Loss: 0.3787  Val_Acc: 84.419

Epoch 86: Validation loss decreased (0.378721 --> 0.378486).  Saving model ...
	 Train_Loss: 0.4582 Train_Acc: 76.435 Val_Loss: 0.3785  BEST VAL Loss: 0.3785  Val_Acc: 83.867

Epoch 87: Validation loss decreased (0.378486 --> 0.378223).  Saving model ...
	 Train_Loss: 0.4580 Train_Acc: 76.471 Val_Loss: 0.3782  BEST VAL Loss: 0.3782  Val_Acc: 84.288

Epoch 88: Validation loss decreased (0.378223 --> 0.377960).  Saving model ...
	 Train_Loss: 0.4578 Train_Acc: 76.545 Val_Loss: 0.3780  BEST VAL Loss: 0.3780  Val_Acc: 83.915

Epoch 89: Validation loss decreased (0.377960 --> 0.377752).  Saving model ...
	 Train_Loss: 0.4576 Train_Acc: 76.466 Val_Loss: 0.3778  BEST VAL Loss: 0.3778  Val_Acc: 83.844

Epoch 90: Validation loss decreased (0.377752 --> 0.377491).  Saving model ...
	 Train_Loss: 0.4574 Train_Acc: 76.577 Val_Loss: 0.3775  BEST VAL Loss: 0.3775  Val_Acc: 84.076

Epoch 91: Validation loss decreased (0.377491 --> 0.377339).  Saving model ...
	 Train_Loss: 0.4572 Train_Acc: 76.539 Val_Loss: 0.3773  BEST VAL Loss: 0.3773  Val_Acc: 84.042

Epoch 92: Validation loss decreased (0.377339 --> 0.377037).  Saving model ...
	 Train_Loss: 0.4569 Train_Acc: 76.590 Val_Loss: 0.3770  BEST VAL Loss: 0.3770  Val_Acc: 84.496

Epoch 93: Validation loss decreased (0.377037 --> 0.376859).  Saving model ...
	 Train_Loss: 0.4567 Train_Acc: 76.654 Val_Loss: 0.3769  BEST VAL Loss: 0.3769  Val_Acc: 84.177

Epoch 94: Validation loss decreased (0.376859 --> 0.376629).  Saving model ...
	 Train_Loss: 0.4565 Train_Acc: 76.574 Val_Loss: 0.3766  BEST VAL Loss: 0.3766  Val_Acc: 83.867

Epoch 95: Validation loss decreased (0.376629 --> 0.376335).  Saving model ...
	 Train_Loss: 0.4563 Train_Acc: 76.455 Val_Loss: 0.3763  BEST VAL Loss: 0.3763  Val_Acc: 84.308

Epoch 96: Validation loss decreased (0.376335 --> 0.376072).  Saving model ...
	 Train_Loss: 0.4561 Train_Acc: 76.638 Val_Loss: 0.3761  BEST VAL Loss: 0.3761  Val_Acc: 84.466

Epoch 97: Validation loss decreased (0.376072 --> 0.375828).  Saving model ...
	 Train_Loss: 0.4559 Train_Acc: 76.519 Val_Loss: 0.3758  BEST VAL Loss: 0.3758  Val_Acc: 84.305

Epoch 98: Validation loss decreased (0.375828 --> 0.375611).  Saving model ...
	 Train_Loss: 0.4557 Train_Acc: 76.529 Val_Loss: 0.3756  BEST VAL Loss: 0.3756  Val_Acc: 84.449

Epoch 99: Validation loss decreased (0.375611 --> 0.375373).  Saving model ...
	 Train_Loss: 0.4555 Train_Acc: 76.670 Val_Loss: 0.3754  BEST VAL Loss: 0.3754  Val_Acc: 84.305

DMSO_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.63      0.70      0.66    149884
           1       0.37      0.30      0.33     87993

    accuracy                           0.55    237877
   macro avg       0.50      0.50      0.50    237877
weighted avg       0.53      0.55      0.54    237877

DMSO_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.63      0.70      0.66     18736
           1       0.37      0.29      0.33     10999

    accuracy                           0.55     29735
   macro avg       0.50      0.50      0.49     29735
weighted avg       0.53      0.55      0.54     29735

DMSO_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.63      0.70      0.67     18736
           1       0.37      0.30      0.33     10999

    accuracy                           0.55     29735
   macro avg       0.50      0.50      0.50     29735
weighted avg       0.53      0.55      0.54     29735

              precision    recall  f1-score   support

           0       0.63      0.70      0.67     18736
           1       0.37      0.30      0.33     10999

    accuracy                           0.55     29735
   macro avg       0.50      0.50      0.50     29735
weighted avg       0.53      0.55      0.54     29735

DMSO_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.42      0.49      0.45     27774
           1       0.58      0.50      0.54     38465

    accuracy                           0.50     66239
   macro avg       0.50      0.50      0.50     66239
weighted avg       0.51      0.50      0.50     66239

              precision    recall  f1-score   support

           0       0.42      0.49      0.45     27774
           1       0.58      0.50      0.54     38465

    accuracy                           0.50     66239
   macro avg       0.50      0.50      0.50     66239
weighted avg       0.51      0.50      0.50     66239

completed
