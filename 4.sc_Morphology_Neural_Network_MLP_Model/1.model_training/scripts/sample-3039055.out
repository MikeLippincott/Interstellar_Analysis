[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '5a9ed9c0'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'be2acbdb'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '36292afd'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '25348aea'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (31162, 1276)
Number of total missing values across all columns: 35020
Data Subset Is Off
Wells held out for testing: ['C20' 'L16']
Wells to use for training, validation, and testing ['C16' 'C17' 'C21' 'L17' 'L20' 'L21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.191142).  Saving model ...
	 Train_Loss: 0.5623 Train_Acc: 83.203 Val_Loss: 0.1911  BEST VAL Loss: 0.1911  Val_Acc: 93.214

Epoch 1: Validation loss decreased (0.191142 --> 0.170798).  Saving model ...
	 Train_Loss: 0.3816 Train_Acc: 92.512 Val_Loss: 0.1708  BEST VAL Loss: 0.1708  Val_Acc: 93.127

Epoch 2: Validation loss decreased (0.170798 --> 0.157694).  Saving model ...
	 Train_Loss: 0.3076 Train_Acc: 93.883 Val_Loss: 0.1577  BEST VAL Loss: 0.1577  Val_Acc: 94.215

Epoch 3: Validation loss decreased (0.157694 --> 0.149179).  Saving model ...
	 Train_Loss: 0.2650 Train_Acc: 94.791 Val_Loss: 0.1492  BEST VAL Loss: 0.1492  Val_Acc: 95.520

Epoch 4: Validation loss decreased (0.149179 --> 0.142833).  Saving model ...
	 Train_Loss: 0.2357 Train_Acc: 95.487 Val_Loss: 0.1428  BEST VAL Loss: 0.1428  Val_Acc: 94.606

Epoch 5: Validation loss decreased (0.142833 --> 0.136530).  Saving model ...
	 Train_Loss: 0.2139 Train_Acc: 96.030 Val_Loss: 0.1365  BEST VAL Loss: 0.1365  Val_Acc: 95.737

Epoch 6: Validation loss decreased (0.136530 --> 0.131043).  Saving model ...
	 Train_Loss: 0.1966 Train_Acc: 96.618 Val_Loss: 0.1310  BEST VAL Loss: 0.1310  Val_Acc: 95.868

Epoch 7: Validation loss decreased (0.131043 --> 0.128655).  Saving model ...
	 Train_Loss: 0.1832 Train_Acc: 96.710 Val_Loss: 0.1287  BEST VAL Loss: 0.1287  Val_Acc: 95.433

Epoch 8: Validation loss decreased (0.128655 --> 0.124647).  Saving model ...
	 Train_Loss: 0.1719 Train_Acc: 96.884 Val_Loss: 0.1246  BEST VAL Loss: 0.1246  Val_Acc: 96.172

Epoch 9: Validation loss decreased (0.124647 --> 0.120144).  Saving model ...
	 Train_Loss: 0.1622 Train_Acc: 96.998 Val_Loss: 0.1201  BEST VAL Loss: 0.1201  Val_Acc: 96.477

Epoch 10: Validation loss decreased (0.120144 --> 0.116423).  Saving model ...
	 Train_Loss: 0.1539 Train_Acc: 97.384 Val_Loss: 0.1164  BEST VAL Loss: 0.1164  Val_Acc: 96.781

Epoch 11: Validation loss decreased (0.116423 --> 0.113985).  Saving model ...
	 Train_Loss: 0.1465 Train_Acc: 97.346 Val_Loss: 0.1140  BEST VAL Loss: 0.1140  Val_Acc: 96.520

Epoch 12: Validation loss decreased (0.113985 --> 0.111929).  Saving model ...
	 Train_Loss: 0.1398 Train_Acc: 97.694 Val_Loss: 0.1119  BEST VAL Loss: 0.1119  Val_Acc: 96.738

Epoch 13: Validation loss did not decrease
	 Train_Loss: 0.1341 Train_Acc: 97.553 Val_Loss: 0.1120  BEST VAL Loss: 0.1119  Val_Acc: 96.390

Epoch 14: Validation loss decreased (0.111929 --> 0.111332).  Saving model ...
	 Train_Loss: 0.1290 Train_Acc: 97.798 Val_Loss: 0.1113  BEST VAL Loss: 0.1113  Val_Acc: 96.825

Epoch 15: Validation loss decreased (0.111332 --> 0.111073).  Saving model ...
	 Train_Loss: 0.1247 Train_Acc: 97.798 Val_Loss: 0.1111  BEST VAL Loss: 0.1111  Val_Acc: 96.912

Epoch 16: Validation loss decreased (0.111073 --> 0.109531).  Saving model ...
	 Train_Loss: 0.1205 Train_Acc: 97.917 Val_Loss: 0.1095  BEST VAL Loss: 0.1095  Val_Acc: 97.260

Epoch 17: Validation loss decreased (0.109531 --> 0.108567).  Saving model ...
	 Train_Loss: 0.1166 Train_Acc: 98.070 Val_Loss: 0.1086  BEST VAL Loss: 0.1086  Val_Acc: 97.042

Epoch 18: Validation loss decreased (0.108567 --> 0.106997).  Saving model ...
	 Train_Loss: 0.1132 Train_Acc: 98.032 Val_Loss: 0.1070  BEST VAL Loss: 0.1070  Val_Acc: 96.999

Epoch 19: Validation loss decreased (0.106997 --> 0.105232).  Saving model ...
	 Train_Loss: 0.1098 Train_Acc: 98.254 Val_Loss: 0.1052  BEST VAL Loss: 0.1052  Val_Acc: 97.260

Epoch 20: Validation loss decreased (0.105232 --> 0.104718).  Saving model ...
	 Train_Loss: 0.1068 Train_Acc: 98.162 Val_Loss: 0.1047  BEST VAL Loss: 0.1047  Val_Acc: 96.999

Epoch 21: Validation loss decreased (0.104718 --> 0.103618).  Saving model ...
	 Train_Loss: 0.1041 Train_Acc: 98.233 Val_Loss: 0.1036  BEST VAL Loss: 0.1036  Val_Acc: 97.086

Epoch 22: Validation loss decreased (0.103618 --> 0.103106).  Saving model ...
	 Train_Loss: 0.1016 Train_Acc: 98.200 Val_Loss: 0.1031  BEST VAL Loss: 0.1031  Val_Acc: 97.303

Epoch 23: Validation loss decreased (0.103106 --> 0.102317).  Saving model ...
	 Train_Loss: 0.0991 Train_Acc: 98.428 Val_Loss: 0.1023  BEST VAL Loss: 0.1023  Val_Acc: 97.564

Epoch 24: Validation loss decreased (0.102317 --> 0.101510).  Saving model ...
	 Train_Loss: 0.0969 Train_Acc: 98.385 Val_Loss: 0.1015  BEST VAL Loss: 0.1015  Val_Acc: 97.042

Epoch 25: Validation loss decreased (0.101510 --> 0.100824).  Saving model ...
	 Train_Loss: 0.0948 Train_Acc: 98.347 Val_Loss: 0.1008  BEST VAL Loss: 0.1008  Val_Acc: 97.477

Epoch 26: Validation loss decreased (0.100824 --> 0.100579).  Saving model ...
	 Train_Loss: 0.0928 Train_Acc: 98.401 Val_Loss: 0.1006  BEST VAL Loss: 0.1006  Val_Acc: 97.216

Epoch 27: Validation loss decreased (0.100579 --> 0.099779).  Saving model ...
	 Train_Loss: 0.0911 Train_Acc: 98.325 Val_Loss: 0.0998  BEST VAL Loss: 0.0998  Val_Acc: 97.434

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.0893 Train_Acc: 98.532 Val_Loss: 0.1004  BEST VAL Loss: 0.0998  Val_Acc: 96.651

Epoch 29: Validation loss decreased (0.099779 --> 0.099498).  Saving model ...
	 Train_Loss: 0.0877 Train_Acc: 98.488 Val_Loss: 0.0995  BEST VAL Loss: 0.0995  Val_Acc: 97.521

Epoch 30: Validation loss decreased (0.099498 --> 0.098561).  Saving model ...
	 Train_Loss: 0.0861 Train_Acc: 98.603 Val_Loss: 0.0986  BEST VAL Loss: 0.0986  Val_Acc: 97.434

Epoch 31: Validation loss decreased (0.098561 --> 0.098284).  Saving model ...
	 Train_Loss: 0.0846 Train_Acc: 98.559 Val_Loss: 0.0983  BEST VAL Loss: 0.0983  Val_Acc: 97.434

Epoch 32: Validation loss decreased (0.098284 --> 0.097515).  Saving model ...
	 Train_Loss: 0.0833 Train_Acc: 98.548 Val_Loss: 0.0975  BEST VAL Loss: 0.0975  Val_Acc: 97.303

Epoch 33: Validation loss decreased (0.097515 --> 0.096970).  Saving model ...
	 Train_Loss: 0.0820 Train_Acc: 98.543 Val_Loss: 0.0970  BEST VAL Loss: 0.0970  Val_Acc: 97.347

Epoch 34: Validation loss decreased (0.096970 --> 0.096794).  Saving model ...
	 Train_Loss: 0.0806 Train_Acc: 98.657 Val_Loss: 0.0968  BEST VAL Loss: 0.0968  Val_Acc: 97.303

Epoch 35: Validation loss decreased (0.096794 --> 0.096441).  Saving model ...
	 Train_Loss: 0.0793 Train_Acc: 98.864 Val_Loss: 0.0964  BEST VAL Loss: 0.0964  Val_Acc: 97.434

Epoch 36: Validation loss decreased (0.096441 --> 0.096387).  Saving model ...
	 Train_Loss: 0.0779 Train_Acc: 98.820 Val_Loss: 0.0964  BEST VAL Loss: 0.0964  Val_Acc: 96.433

Epoch 37: Validation loss decreased (0.096387 --> 0.095798).  Saving model ...
	 Train_Loss: 0.0770 Train_Acc: 98.499 Val_Loss: 0.0958  BEST VAL Loss: 0.0958  Val_Acc: 97.477

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.0759 Train_Acc: 98.679 Val_Loss: 0.0969  BEST VAL Loss: 0.0958  Val_Acc: 97.521

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.0752 Train_Acc: 98.216 Val_Loss: 0.0970  BEST VAL Loss: 0.0958  Val_Acc: 97.347

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.0742 Train_Acc: 98.673 Val_Loss: 0.0971  BEST VAL Loss: 0.0958  Val_Acc: 97.303

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.0733 Train_Acc: 98.630 Val_Loss: 0.0971  BEST VAL Loss: 0.0958  Val_Acc: 97.782

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.0724 Train_Acc: 98.809 Val_Loss: 0.0981  BEST VAL Loss: 0.0958  Val_Acc: 97.042

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.0715 Train_Acc: 98.755 Val_Loss: 0.0985  BEST VAL Loss: 0.0958  Val_Acc: 97.216

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.0706 Train_Acc: 98.902 Val_Loss: 0.0981  BEST VAL Loss: 0.0958  Val_Acc: 97.738

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.0698 Train_Acc: 98.684 Val_Loss: 0.0983  BEST VAL Loss: 0.0958  Val_Acc: 97.651

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.0690 Train_Acc: 98.733 Val_Loss: 0.0982  BEST VAL Loss: 0.0958  Val_Acc: 97.434

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.0682 Train_Acc: 98.972 Val_Loss: 0.0978  BEST VAL Loss: 0.0958  Val_Acc: 97.695

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.0674 Train_Acc: 98.733 Val_Loss: 0.0974  BEST VAL Loss: 0.0958  Val_Acc: 97.782

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.0668 Train_Acc: 98.597 Val_Loss: 0.0983  BEST VAL Loss: 0.0958  Val_Acc: 96.955

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.0663 Train_Acc: 98.575 Val_Loss: 0.0979  BEST VAL Loss: 0.0958  Val_Acc: 97.912

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.0656 Train_Acc: 98.874 Val_Loss: 0.0975  BEST VAL Loss: 0.0958  Val_Acc: 97.477

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.0649 Train_Acc: 98.891 Val_Loss: 0.0978  BEST VAL Loss: 0.0958  Val_Acc: 97.477

Epoch 53: Validation loss did not decrease
Early stopped at epoch : 53
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.57      0.57      0.57     10451
           1       0.43      0.43      0.43      7939

    accuracy                           0.51     18390
   macro avg       0.50      0.50      0.50     18390
weighted avg       0.51      0.51      0.51     18390

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.58      0.57      0.57      1307
           1       0.45      0.46      0.45       992

    accuracy                           0.52      2299
   macro avg       0.51      0.51      0.51      2299
weighted avg       0.52      0.52      0.52      2299

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.57      0.57      0.57      1307
           1       0.43      0.44      0.43       992

    accuracy                           0.51      2299
   macro avg       0.50      0.50      0.50      2299
weighted avg       0.51      0.51      0.51      2299

              precision    recall  f1-score   support

           0       0.57      0.57      0.57      1307
           1       0.43      0.44      0.43       992

    accuracy                           0.51      2299
   macro avg       0.50      0.50      0.50      2299
weighted avg       0.51      0.51      0.51      2299

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.56      0.56      4445
           1       0.46      0.44      0.45      3729

    accuracy                           0.51      8174
   macro avg       0.50      0.50      0.50      8174
weighted avg       0.51      0.51      0.51      8174

              precision    recall  f1-score   support

           0       0.55      0.56      0.56      4445
           1       0.46      0.44      0.45      3729

    accuracy                           0.51      8174
   macro avg       0.50      0.50      0.50      8174
weighted avg       0.51      0.51      0.51      8174

completed
