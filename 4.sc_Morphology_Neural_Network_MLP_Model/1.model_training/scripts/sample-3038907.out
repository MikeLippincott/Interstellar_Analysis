[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '3db031bb'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'c9ceaf65'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '967cab30'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '991001aa'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_10.000_DMSO_0.025 treatment_name: LPS_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: LPS_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'LPS_10.000_DMSO_0.025']
The dimensions of the data are: (33268, 1276)
Number of total missing values across all columns: 66536
Data Subset Is Off
Wells held out for testing: ['D20' 'E21']
Wells to use for training, validation, and testing ['D16' 'E16' 'D17' 'E17' 'E20' 'D21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.711172).  Saving model ...
	 Train_Loss: 0.7205 Train_Acc: 50.953 Val_Loss: 0.7112  BEST VAL Loss: 0.7112  Val_Acc: 51.203

Epoch 1: Validation loss decreased (0.711172 --> 0.705403).  Saving model ...
	 Train_Loss: 0.7104 Train_Acc: 52.096 Val_Loss: 0.7054  BEST VAL Loss: 0.7054  Val_Acc: 52.847

Epoch 2: Validation loss decreased (0.705403 --> 0.700961).  Saving model ...
	 Train_Loss: 0.7040 Train_Acc: 53.430 Val_Loss: 0.7010  BEST VAL Loss: 0.7010  Val_Acc: 54.210

Epoch 3: Validation loss decreased (0.700961 --> 0.697567).  Saving model ...
	 Train_Loss: 0.6994 Train_Acc: 54.678 Val_Loss: 0.6976  BEST VAL Loss: 0.6976  Val_Acc: 54.932

Epoch 4: Validation loss decreased (0.697567 --> 0.694896).  Saving model ...
	 Train_Loss: 0.6958 Train_Acc: 55.270 Val_Loss: 0.6949  BEST VAL Loss: 0.6949  Val_Acc: 55.253

Epoch 5: Validation loss decreased (0.694896 --> 0.692751).  Saving model ...
	 Train_Loss: 0.6928 Train_Acc: 55.841 Val_Loss: 0.6928  BEST VAL Loss: 0.6928  Val_Acc: 55.774

Epoch 6: Validation loss decreased (0.692751 --> 0.691056).  Saving model ...
	 Train_Loss: 0.6904 Train_Acc: 55.957 Val_Loss: 0.6911  BEST VAL Loss: 0.6911  Val_Acc: 55.613

Epoch 7: Validation loss decreased (0.691056 --> 0.689633).  Saving model ...
	 Train_Loss: 0.6882 Train_Acc: 56.443 Val_Loss: 0.6896  BEST VAL Loss: 0.6896  Val_Acc: 56.375

Epoch 8: Validation loss decreased (0.689633 --> 0.688481).  Saving model ...
	 Train_Loss: 0.6863 Train_Acc: 56.679 Val_Loss: 0.6885  BEST VAL Loss: 0.6885  Val_Acc: 57.017

Epoch 9: Validation loss decreased (0.688481 --> 0.687536).  Saving model ...
	 Train_Loss: 0.6846 Train_Acc: 56.934 Val_Loss: 0.6875  BEST VAL Loss: 0.6875  Val_Acc: 56.977

Epoch 10: Validation loss decreased (0.687536 --> 0.686704).  Saving model ...
	 Train_Loss: 0.6831 Train_Acc: 57.456 Val_Loss: 0.6867  BEST VAL Loss: 0.6867  Val_Acc: 56.897

Epoch 11: Validation loss decreased (0.686704 --> 0.685943).  Saving model ...
	 Train_Loss: 0.6815 Train_Acc: 57.997 Val_Loss: 0.6859  BEST VAL Loss: 0.6859  Val_Acc: 57.057

Epoch 12: Validation loss decreased (0.685943 --> 0.685221).  Saving model ...
	 Train_Loss: 0.6801 Train_Acc: 57.581 Val_Loss: 0.6852  BEST VAL Loss: 0.6852  Val_Acc: 57.177

Epoch 13: Validation loss decreased (0.685221 --> 0.684590).  Saving model ...
	 Train_Loss: 0.6788 Train_Acc: 57.877 Val_Loss: 0.6846  BEST VAL Loss: 0.6846  Val_Acc: 57.057

Epoch 14: Validation loss decreased (0.684590 --> 0.683951).  Saving model ...
	 Train_Loss: 0.6775 Train_Acc: 58.163 Val_Loss: 0.6840  BEST VAL Loss: 0.6840  Val_Acc: 57.257

Epoch 15: Validation loss decreased (0.683951 --> 0.683362).  Saving model ...
	 Train_Loss: 0.6763 Train_Acc: 58.022 Val_Loss: 0.6834  BEST VAL Loss: 0.6834  Val_Acc: 57.298

Epoch 16: Validation loss decreased (0.683362 --> 0.682832).  Saving model ...
	 Train_Loss: 0.6752 Train_Acc: 58.223 Val_Loss: 0.6828  BEST VAL Loss: 0.6828  Val_Acc: 57.097

Epoch 17: Validation loss decreased (0.682832 --> 0.682313).  Saving model ...
	 Train_Loss: 0.6742 Train_Acc: 58.213 Val_Loss: 0.6823  BEST VAL Loss: 0.6823  Val_Acc: 57.618

Epoch 18: Validation loss decreased (0.682313 --> 0.681823).  Saving model ...
	 Train_Loss: 0.6730 Train_Acc: 58.749 Val_Loss: 0.6818  BEST VAL Loss: 0.6818  Val_Acc: 57.618

Epoch 19: Validation loss decreased (0.681823 --> 0.681361).  Saving model ...
	 Train_Loss: 0.6720 Train_Acc: 58.469 Val_Loss: 0.6814  BEST VAL Loss: 0.6814  Val_Acc: 57.859

Epoch 20: Validation loss decreased (0.681361 --> 0.680917).  Saving model ...
	 Train_Loss: 0.6710 Train_Acc: 58.895 Val_Loss: 0.6809  BEST VAL Loss: 0.6809  Val_Acc: 58.099

Epoch 21: Validation loss decreased (0.680917 --> 0.680481).  Saving model ...
	 Train_Loss: 0.6700 Train_Acc: 58.810 Val_Loss: 0.6805  BEST VAL Loss: 0.6805  Val_Acc: 57.578

Epoch 22: Validation loss decreased (0.680481 --> 0.680051).  Saving model ...
	 Train_Loss: 0.6690 Train_Acc: 59.025 Val_Loss: 0.6801  BEST VAL Loss: 0.6801  Val_Acc: 58.019

Epoch 23: Validation loss decreased (0.680051 --> 0.679597).  Saving model ...
	 Train_Loss: 0.6681 Train_Acc: 58.965 Val_Loss: 0.6796  BEST VAL Loss: 0.6796  Val_Acc: 58.019

Epoch 24: Validation loss decreased (0.679597 --> 0.679189).  Saving model ...
	 Train_Loss: 0.6672 Train_Acc: 59.246 Val_Loss: 0.6792  BEST VAL Loss: 0.6792  Val_Acc: 58.340

Epoch 25: Validation loss decreased (0.679189 --> 0.678781).  Saving model ...
	 Train_Loss: 0.6663 Train_Acc: 59.196 Val_Loss: 0.6788  BEST VAL Loss: 0.6788  Val_Acc: 58.500

Epoch 26: Validation loss decreased (0.678781 --> 0.678386).  Saving model ...
	 Train_Loss: 0.6654 Train_Acc: 60.690 Val_Loss: 0.6784  BEST VAL Loss: 0.6784  Val_Acc: 58.901

Epoch 27: Validation loss decreased (0.678386 --> 0.677992).  Saving model ...
	 Train_Loss: 0.6645 Train_Acc: 60.585 Val_Loss: 0.6780  BEST VAL Loss: 0.6780  Val_Acc: 58.500

Epoch 28: Validation loss decreased (0.677992 --> 0.677599).  Saving model ...
	 Train_Loss: 0.6636 Train_Acc: 60.971 Val_Loss: 0.6776  BEST VAL Loss: 0.6776  Val_Acc: 59.342

Epoch 29: Validation loss decreased (0.677599 --> 0.677228).  Saving model ...
	 Train_Loss: 0.6628 Train_Acc: 61.136 Val_Loss: 0.6772  BEST VAL Loss: 0.6772  Val_Acc: 58.941

Epoch 30: Validation loss decreased (0.677228 --> 0.676886).  Saving model ...
	 Train_Loss: 0.6619 Train_Acc: 61.482 Val_Loss: 0.6769  BEST VAL Loss: 0.6769  Val_Acc: 59.222

Epoch 31: Validation loss decreased (0.676886 --> 0.676539).  Saving model ...
	 Train_Loss: 0.6611 Train_Acc: 61.572 Val_Loss: 0.6765  BEST VAL Loss: 0.6765  Val_Acc: 59.222

Epoch 32: Validation loss decreased (0.676539 --> 0.676180).  Saving model ...
	 Train_Loss: 0.6602 Train_Acc: 61.778 Val_Loss: 0.6762  BEST VAL Loss: 0.6762  Val_Acc: 58.821

Epoch 33: Validation loss decreased (0.676180 --> 0.675847).  Saving model ...
	 Train_Loss: 0.6594 Train_Acc: 62.024 Val_Loss: 0.6758  BEST VAL Loss: 0.6758  Val_Acc: 59.703

Epoch 34: Validation loss decreased (0.675847 --> 0.675512).  Saving model ...
	 Train_Loss: 0.6586 Train_Acc: 62.335 Val_Loss: 0.6755  BEST VAL Loss: 0.6755  Val_Acc: 59.222

Epoch 35: Validation loss decreased (0.675512 --> 0.675221).  Saving model ...
	 Train_Loss: 0.6578 Train_Acc: 62.465 Val_Loss: 0.6752  BEST VAL Loss: 0.6752  Val_Acc: 59.423

Epoch 36: Validation loss decreased (0.675221 --> 0.674911).  Saving model ...
	 Train_Loss: 0.6570 Train_Acc: 62.610 Val_Loss: 0.6749  BEST VAL Loss: 0.6749  Val_Acc: 59.583

Epoch 37: Validation loss decreased (0.674911 --> 0.674616).  Saving model ...
	 Train_Loss: 0.6562 Train_Acc: 62.976 Val_Loss: 0.6746  BEST VAL Loss: 0.6746  Val_Acc: 59.583

Epoch 38: Validation loss decreased (0.674616 --> 0.674317).  Saving model ...
	 Train_Loss: 0.6555 Train_Acc: 63.112 Val_Loss: 0.6743  BEST VAL Loss: 0.6743  Val_Acc: 60.144

Epoch 39: Validation loss decreased (0.674317 --> 0.674038).  Saving model ...
	 Train_Loss: 0.6548 Train_Acc: 63.217 Val_Loss: 0.6740  BEST VAL Loss: 0.6740  Val_Acc: 60.104

Epoch 40: Validation loss decreased (0.674038 --> 0.673757).  Saving model ...
	 Train_Loss: 0.6540 Train_Acc: 63.413 Val_Loss: 0.6738  BEST VAL Loss: 0.6738  Val_Acc: 59.944

Epoch 41: Validation loss decreased (0.673757 --> 0.673491).  Saving model ...
	 Train_Loss: 0.6533 Train_Acc: 63.307 Val_Loss: 0.6735  BEST VAL Loss: 0.6735  Val_Acc: 59.743

Epoch 42: Validation loss decreased (0.673491 --> 0.673218).  Saving model ...
	 Train_Loss: 0.6525 Train_Acc: 63.824 Val_Loss: 0.6732  BEST VAL Loss: 0.6732  Val_Acc: 59.703

Epoch 43: Validation loss decreased (0.673218 --> 0.672961).  Saving model ...
	 Train_Loss: 0.6518 Train_Acc: 63.568 Val_Loss: 0.6730  BEST VAL Loss: 0.6730  Val_Acc: 59.503

Epoch 44: Validation loss decreased (0.672961 --> 0.672716).  Saving model ...
	 Train_Loss: 0.6511 Train_Acc: 63.653 Val_Loss: 0.6727  BEST VAL Loss: 0.6727  Val_Acc: 59.824

Epoch 45: Validation loss decreased (0.672716 --> 0.672478).  Saving model ...
	 Train_Loss: 0.6504 Train_Acc: 64.024 Val_Loss: 0.6725  BEST VAL Loss: 0.6725  Val_Acc: 59.984

Epoch 46: Validation loss decreased (0.672478 --> 0.672237).  Saving model ...
	 Train_Loss: 0.6498 Train_Acc: 64.019 Val_Loss: 0.6722  BEST VAL Loss: 0.6722  Val_Acc: 59.904

Epoch 47: Validation loss decreased (0.672237 --> 0.671992).  Saving model ...
	 Train_Loss: 0.6491 Train_Acc: 64.230 Val_Loss: 0.6720  BEST VAL Loss: 0.6720  Val_Acc: 59.182

Epoch 48: Validation loss decreased (0.671992 --> 0.671763).  Saving model ...
	 Train_Loss: 0.6485 Train_Acc: 64.220 Val_Loss: 0.6718  BEST VAL Loss: 0.6718  Val_Acc: 59.743

Epoch 49: Validation loss decreased (0.671763 --> 0.671505).  Saving model ...
	 Train_Loss: 0.6478 Train_Acc: 64.626 Val_Loss: 0.6715  BEST VAL Loss: 0.6715  Val_Acc: 59.904

Epoch 50: Validation loss decreased (0.671505 --> 0.671257).  Saving model ...
	 Train_Loss: 0.6471 Train_Acc: 64.380 Val_Loss: 0.6713  BEST VAL Loss: 0.6713  Val_Acc: 59.944

Epoch 51: Validation loss decreased (0.671257 --> 0.671040).  Saving model ...
	 Train_Loss: 0.6465 Train_Acc: 64.521 Val_Loss: 0.6710  BEST VAL Loss: 0.6710  Val_Acc: 60.225

Epoch 52: Validation loss decreased (0.671040 --> 0.670844).  Saving model ...
	 Train_Loss: 0.6459 Train_Acc: 64.832 Val_Loss: 0.6708  BEST VAL Loss: 0.6708  Val_Acc: 60.465

Epoch 53: Validation loss decreased (0.670844 --> 0.670637).  Saving model ...
	 Train_Loss: 0.6453 Train_Acc: 64.636 Val_Loss: 0.6706  BEST VAL Loss: 0.6706  Val_Acc: 60.104

Epoch 54: Validation loss decreased (0.670637 --> 0.670448).  Saving model ...
	 Train_Loss: 0.6447 Train_Acc: 64.907 Val_Loss: 0.6704  BEST VAL Loss: 0.6704  Val_Acc: 59.503

Epoch 55: Validation loss decreased (0.670448 --> 0.670272).  Saving model ...
	 Train_Loss: 0.6440 Train_Acc: 65.378 Val_Loss: 0.6703  BEST VAL Loss: 0.6703  Val_Acc: 59.383

Epoch 56: Validation loss decreased (0.670272 --> 0.670085).  Saving model ...
	 Train_Loss: 0.6434 Train_Acc: 65.589 Val_Loss: 0.6701  BEST VAL Loss: 0.6701  Val_Acc: 59.743

Epoch 57: Validation loss decreased (0.670085 --> 0.669894).  Saving model ...
	 Train_Loss: 0.6428 Train_Acc: 65.333 Val_Loss: 0.6699  BEST VAL Loss: 0.6699  Val_Acc: 60.465

Epoch 58: Validation loss decreased (0.669894 --> 0.669691).  Saving model ...
	 Train_Loss: 0.6423 Train_Acc: 65.343 Val_Loss: 0.6697  BEST VAL Loss: 0.6697  Val_Acc: 60.786

Epoch 59: Validation loss decreased (0.669691 --> 0.669499).  Saving model ...
	 Train_Loss: 0.6417 Train_Acc: 65.513 Val_Loss: 0.6695  BEST VAL Loss: 0.6695  Val_Acc: 60.265

Epoch 60: Validation loss decreased (0.669499 --> 0.669306).  Saving model ...
	 Train_Loss: 0.6411 Train_Acc: 65.844 Val_Loss: 0.6693  BEST VAL Loss: 0.6693  Val_Acc: 59.663

Epoch 61: Validation loss decreased (0.669306 --> 0.669119).  Saving model ...
	 Train_Loss: 0.6405 Train_Acc: 65.574 Val_Loss: 0.6691  BEST VAL Loss: 0.6691  Val_Acc: 60.225

Epoch 62: Validation loss decreased (0.669119 --> 0.668983).  Saving model ...
	 Train_Loss: 0.6400 Train_Acc: 65.569 Val_Loss: 0.6690  BEST VAL Loss: 0.6690  Val_Acc: 60.104

Epoch 63: Validation loss decreased (0.668983 --> 0.668840).  Saving model ...
	 Train_Loss: 0.6395 Train_Acc: 65.569 Val_Loss: 0.6688  BEST VAL Loss: 0.6688  Val_Acc: 59.703

Epoch 64: Validation loss decreased (0.668840 --> 0.668705).  Saving model ...
	 Train_Loss: 0.6389 Train_Acc: 65.513 Val_Loss: 0.6687  BEST VAL Loss: 0.6687  Val_Acc: 60.144

Epoch 65: Validation loss decreased (0.668705 --> 0.668581).  Saving model ...
	 Train_Loss: 0.6384 Train_Acc: 65.503 Val_Loss: 0.6686  BEST VAL Loss: 0.6686  Val_Acc: 60.305

Epoch 66: Validation loss decreased (0.668581 --> 0.668452).  Saving model ...
	 Train_Loss: 0.6379 Train_Acc: 66.055 Val_Loss: 0.6685  BEST VAL Loss: 0.6685  Val_Acc: 60.305

Epoch 67: Validation loss decreased (0.668452 --> 0.668309).  Saving model ...
	 Train_Loss: 0.6373 Train_Acc: 66.110 Val_Loss: 0.6683  BEST VAL Loss: 0.6683  Val_Acc: 60.545

Epoch 68: Validation loss decreased (0.668309 --> 0.668203).  Saving model ...
	 Train_Loss: 0.6368 Train_Acc: 65.859 Val_Loss: 0.6682  BEST VAL Loss: 0.6682  Val_Acc: 60.184

Epoch 69: Validation loss decreased (0.668203 --> 0.668115).  Saving model ...
	 Train_Loss: 0.6363 Train_Acc: 65.990 Val_Loss: 0.6681  BEST VAL Loss: 0.6681  Val_Acc: 60.465

Epoch 70: Validation loss decreased (0.668115 --> 0.668023).  Saving model ...
	 Train_Loss: 0.6358 Train_Acc: 65.995 Val_Loss: 0.6680  BEST VAL Loss: 0.6680  Val_Acc: 60.545

Epoch 71: Validation loss decreased (0.668023 --> 0.667913).  Saving model ...
	 Train_Loss: 0.6353 Train_Acc: 66.391 Val_Loss: 0.6679  BEST VAL Loss: 0.6679  Val_Acc: 60.184

Epoch 72: Validation loss decreased (0.667913 --> 0.667823).  Saving model ...
	 Train_Loss: 0.6348 Train_Acc: 66.225 Val_Loss: 0.6678  BEST VAL Loss: 0.6678  Val_Acc: 60.545

Epoch 73: Validation loss decreased (0.667823 --> 0.667731).  Saving model ...
	 Train_Loss: 0.6343 Train_Acc: 65.965 Val_Loss: 0.6677  BEST VAL Loss: 0.6677  Val_Acc: 60.265

Epoch 74: Validation loss decreased (0.667731 --> 0.667636).  Saving model ...
	 Train_Loss: 0.6338 Train_Acc: 66.456 Val_Loss: 0.6676  BEST VAL Loss: 0.6676  Val_Acc: 60.345

Epoch 75: Validation loss decreased (0.667636 --> 0.667581).  Saving model ...
	 Train_Loss: 0.6333 Train_Acc: 66.125 Val_Loss: 0.6676  BEST VAL Loss: 0.6676  Val_Acc: 60.746

Epoch 76: Validation loss decreased (0.667581 --> 0.667504).  Saving model ...
	 Train_Loss: 0.6329 Train_Acc: 66.150 Val_Loss: 0.6675  BEST VAL Loss: 0.6675  Val_Acc: 60.946

Epoch 77: Validation loss decreased (0.667504 --> 0.667449).  Saving model ...
	 Train_Loss: 0.6324 Train_Acc: 66.120 Val_Loss: 0.6674  BEST VAL Loss: 0.6674  Val_Acc: 60.225

Epoch 78: Validation loss decreased (0.667449 --> 0.667382).  Saving model ...
	 Train_Loss: 0.6319 Train_Acc: 66.426 Val_Loss: 0.6674  BEST VAL Loss: 0.6674  Val_Acc: 60.345

Epoch 79: Validation loss decreased (0.667382 --> 0.667315).  Saving model ...
	 Train_Loss: 0.6315 Train_Acc: 66.556 Val_Loss: 0.6673  BEST VAL Loss: 0.6673  Val_Acc: 60.666

Epoch 80: Validation loss decreased (0.667315 --> 0.667244).  Saving model ...
	 Train_Loss: 0.6311 Train_Acc: 66.070 Val_Loss: 0.6672  BEST VAL Loss: 0.6672  Val_Acc: 60.585

Epoch 81: Validation loss decreased (0.667244 --> 0.667194).  Saving model ...
	 Train_Loss: 0.6306 Train_Acc: 66.707 Val_Loss: 0.6672  BEST VAL Loss: 0.6672  Val_Acc: 60.265

Epoch 82: Validation loss decreased (0.667194 --> 0.667148).  Saving model ...
	 Train_Loss: 0.6302 Train_Acc: 66.837 Val_Loss: 0.6671  BEST VAL Loss: 0.6671  Val_Acc: 60.706

Epoch 83: Validation loss decreased (0.667148 --> 0.667087).  Saving model ...
	 Train_Loss: 0.6297 Train_Acc: 66.471 Val_Loss: 0.6671  BEST VAL Loss: 0.6671  Val_Acc: 60.305

Epoch 84: Validation loss decreased (0.667087 --> 0.667022).  Saving model ...
	 Train_Loss: 0.6293 Train_Acc: 66.617 Val_Loss: 0.6670  BEST VAL Loss: 0.6670  Val_Acc: 60.666

Epoch 85: Validation loss decreased (0.667022 --> 0.666978).  Saving model ...
	 Train_Loss: 0.6289 Train_Acc: 66.687 Val_Loss: 0.6670  BEST VAL Loss: 0.6670  Val_Acc: 60.425

Epoch 86: Validation loss decreased (0.666978 --> 0.666931).  Saving model ...
	 Train_Loss: 0.6285 Train_Acc: 66.892 Val_Loss: 0.6669  BEST VAL Loss: 0.6669  Val_Acc: 60.826

Epoch 87: Validation loss decreased (0.666931 --> 0.666916).  Saving model ...
	 Train_Loss: 0.6280 Train_Acc: 66.757 Val_Loss: 0.6669  BEST VAL Loss: 0.6669  Val_Acc: 60.425

Epoch 88: Validation loss decreased (0.666916 --> 0.666877).  Saving model ...
	 Train_Loss: 0.6276 Train_Acc: 66.662 Val_Loss: 0.6669  BEST VAL Loss: 0.6669  Val_Acc: 60.305

Epoch 89: Validation loss decreased (0.666877 --> 0.666844).  Saving model ...
	 Train_Loss: 0.6272 Train_Acc: 67.053 Val_Loss: 0.6668  BEST VAL Loss: 0.6668  Val_Acc: 60.826

Epoch 90: Validation loss decreased (0.666844 --> 0.666823).  Saving model ...
	 Train_Loss: 0.6268 Train_Acc: 67.083 Val_Loss: 0.6668  BEST VAL Loss: 0.6668  Val_Acc: 60.706

Epoch 91: Validation loss decreased (0.666823 --> 0.666801).  Saving model ...
	 Train_Loss: 0.6264 Train_Acc: 66.862 Val_Loss: 0.6668  BEST VAL Loss: 0.6668  Val_Acc: 61.227

Epoch 92: Validation loss decreased (0.666801 --> 0.666793).  Saving model ...
	 Train_Loss: 0.6260 Train_Acc: 66.902 Val_Loss: 0.6668  BEST VAL Loss: 0.6668  Val_Acc: 60.545

Epoch 93: Validation loss decreased (0.666793 --> 0.666773).  Saving model ...
	 Train_Loss: 0.6256 Train_Acc: 66.973 Val_Loss: 0.6668  BEST VAL Loss: 0.6668  Val_Acc: 60.585

Epoch 94: Validation loss decreased (0.666773 --> 0.666768).  Saving model ...
	 Train_Loss: 0.6253 Train_Acc: 67.028 Val_Loss: 0.6668  BEST VAL Loss: 0.6668  Val_Acc: 60.345

Epoch 95: Validation loss decreased (0.666768 --> 0.666764).  Saving model ...
	 Train_Loss: 0.6249 Train_Acc: 66.752 Val_Loss: 0.6668  BEST VAL Loss: 0.6668  Val_Acc: 60.585

Epoch 96: Validation loss decreased (0.666764 --> 0.666760).  Saving model ...
	 Train_Loss: 0.6245 Train_Acc: 66.973 Val_Loss: 0.6668  BEST VAL Loss: 0.6668  Val_Acc: 60.305

Epoch 97: Validation loss did not decrease
	 Train_Loss: 0.6241 Train_Acc: 67.163 Val_Loss: 0.6668  BEST VAL Loss: 0.6668  Val_Acc: 60.144

Epoch 98: Validation loss decreased (0.666760 --> 0.666739).  Saving model ...
	 Train_Loss: 0.6237 Train_Acc: 67.013 Val_Loss: 0.6667  BEST VAL Loss: 0.6667  Val_Acc: 61.026

Epoch 99: Validation loss decreased (0.666739 --> 0.666725).  Saving model ...
	 Train_Loss: 0.6234 Train_Acc: 67.118 Val_Loss: 0.6667  BEST VAL Loss: 0.6667  Val_Acc: 60.184

LPS_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.69      0.73      0.71      9832
           1       0.72      0.69      0.70     10112

    accuracy                           0.71     19944
   macro avg       0.71      0.71      0.71     19944
weighted avg       0.71      0.71      0.71     19944

LPS_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.59      0.62      0.60      1229
           1       0.61      0.59      0.60      1265

    accuracy                           0.60      2494
   macro avg       0.60      0.60      0.60      2494
weighted avg       0.60      0.60      0.60      2494

LPS_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.58      0.59      0.58      1229
           1       0.59      0.59      0.59      1265

    accuracy                           0.59      2494
   macro avg       0.59      0.59      0.59      2494
weighted avg       0.59      0.59      0.59      2494

              precision    recall  f1-score   support

           0       0.58      0.59      0.58      1229
           1       0.59      0.59      0.59      1265

    accuracy                           0.59      2494
   macro avg       0.59      0.59      0.59      2494
weighted avg       0.59      0.59      0.59      2494

LPS_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.50      0.44      0.47      4168
           1       0.50      0.57      0.53      4168

    accuracy                           0.50      8336
   macro avg       0.50      0.50      0.50      8336
weighted avg       0.50      0.50      0.50      8336

              precision    recall  f1-score   support

           0       0.50      0.44      0.47      4168
           1       0.50      0.57      0.53      4168

    accuracy                           0.50      8336
   macro avg       0.50      0.50      0.50      8336
weighted avg       0.50      0.50      0.50      8336

completed
