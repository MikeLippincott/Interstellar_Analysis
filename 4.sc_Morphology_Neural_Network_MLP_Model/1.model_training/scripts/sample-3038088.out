[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'c1a59880'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '334dfb60'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '3142b28f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '1cd5febb'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: H2O2_100.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['H2O2_100.000_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (414797, 1270)
Number of total missing values across all columns: 481072
Data Subset Is Off
Wells held out for testing: ['I10' 'L08']
Wells to use for training, validation, and testing ['H04' 'I04' 'H05' 'I05' 'H10' 'H11' 'I11' 'L02' 'L03' 'L09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.188657).  Saving model ...
	 Train_Loss: 0.3902 Train_Acc: 82.569 Val_Loss: 0.1887  BEST VAL Loss: 0.1887  Val_Acc: 93.373

Epoch 1: Validation loss decreased (0.188657 --> 0.165912).  Saving model ...
	 Train_Loss: 0.3062 Train_Acc: 91.350 Val_Loss: 0.1659  BEST VAL Loss: 0.1659  Val_Acc: 94.652

Epoch 2: Validation loss decreased (0.165912 --> 0.152371).  Saving model ...
	 Train_Loss: 0.2673 Train_Acc: 92.831 Val_Loss: 0.1524  BEST VAL Loss: 0.1524  Val_Acc: 95.329

Epoch 3: Validation loss decreased (0.152371 --> 0.143386).  Saving model ...
	 Train_Loss: 0.2430 Train_Acc: 93.460 Val_Loss: 0.1434  BEST VAL Loss: 0.1434  Val_Acc: 95.624

Epoch 4: Validation loss decreased (0.143386 --> 0.136953).  Saving model ...
	 Train_Loss: 0.2257 Train_Acc: 94.058 Val_Loss: 0.1370  BEST VAL Loss: 0.1370  Val_Acc: 95.878

Epoch 5: Validation loss decreased (0.136953 --> 0.132208).  Saving model ...
	 Train_Loss: 0.2129 Train_Acc: 94.321 Val_Loss: 0.1322  BEST VAL Loss: 0.1322  Val_Acc: 95.863

Epoch 6: Validation loss decreased (0.132208 --> 0.128006).  Saving model ...
	 Train_Loss: 0.2028 Train_Acc: 94.582 Val_Loss: 0.1280  BEST VAL Loss: 0.1280  Val_Acc: 96.211

Epoch 7: Validation loss decreased (0.128006 --> 0.124673).  Saving model ...
	 Train_Loss: 0.1946 Train_Acc: 94.749 Val_Loss: 0.1247  BEST VAL Loss: 0.1247  Val_Acc: 96.169

Epoch 8: Validation loss decreased (0.124673 --> 0.121917).  Saving model ...
	 Train_Loss: 0.1877 Train_Acc: 94.890 Val_Loss: 0.1219  BEST VAL Loss: 0.1219  Val_Acc: 96.320

Epoch 9: Validation loss decreased (0.121917 --> 0.119465).  Saving model ...
	 Train_Loss: 0.1819 Train_Acc: 95.027 Val_Loss: 0.1195  BEST VAL Loss: 0.1195  Val_Acc: 96.352

Epoch 10: Validation loss decreased (0.119465 --> 0.117539).  Saving model ...
	 Train_Loss: 0.1770 Train_Acc: 95.178 Val_Loss: 0.1175  BEST VAL Loss: 0.1175  Val_Acc: 96.384

Epoch 11: Validation loss decreased (0.117539 --> 0.115707).  Saving model ...
	 Train_Loss: 0.1726 Train_Acc: 95.209 Val_Loss: 0.1157  BEST VAL Loss: 0.1157  Val_Acc: 96.508

Epoch 12: Validation loss decreased (0.115707 --> 0.114073).  Saving model ...
	 Train_Loss: 0.1688 Train_Acc: 95.303 Val_Loss: 0.1141  BEST VAL Loss: 0.1141  Val_Acc: 96.523

Epoch 13: Validation loss decreased (0.114073 --> 0.112500).  Saving model ...
	 Train_Loss: 0.1654 Train_Acc: 95.360 Val_Loss: 0.1125  BEST VAL Loss: 0.1125  Val_Acc: 96.626

Epoch 14: Validation loss decreased (0.112500 --> 0.111268).  Saving model ...
	 Train_Loss: 0.1623 Train_Acc: 95.472 Val_Loss: 0.1113  BEST VAL Loss: 0.1113  Val_Acc: 96.617

Epoch 15: Validation loss decreased (0.111268 --> 0.110107).  Saving model ...
	 Train_Loss: 0.1595 Train_Acc: 95.497 Val_Loss: 0.1101  BEST VAL Loss: 0.1101  Val_Acc: 96.697

Epoch 16: Validation loss decreased (0.110107 --> 0.108933).  Saving model ...
	 Train_Loss: 0.1569 Train_Acc: 95.585 Val_Loss: 0.1089  BEST VAL Loss: 0.1089  Val_Acc: 96.709

Epoch 17: Validation loss decreased (0.108933 --> 0.107926).  Saving model ...
	 Train_Loss: 0.1546 Train_Acc: 95.596 Val_Loss: 0.1079  BEST VAL Loss: 0.1079  Val_Acc: 96.756

Epoch 18: Validation loss decreased (0.107926 --> 0.107005).  Saving model ...
	 Train_Loss: 0.1524 Train_Acc: 95.658 Val_Loss: 0.1070  BEST VAL Loss: 0.1070  Val_Acc: 96.694

Epoch 19: Validation loss decreased (0.107005 --> 0.106129).  Saving model ...
	 Train_Loss: 0.1505 Train_Acc: 95.676 Val_Loss: 0.1061  BEST VAL Loss: 0.1061  Val_Acc: 96.706

Epoch 20: Validation loss decreased (0.106129 --> 0.105261).  Saving model ...
	 Train_Loss: 0.1487 Train_Acc: 95.732 Val_Loss: 0.1053  BEST VAL Loss: 0.1053  Val_Acc: 96.844

Epoch 21: Validation loss decreased (0.105261 --> 0.104847).  Saving model ...
	 Train_Loss: 0.1469 Train_Acc: 95.794 Val_Loss: 0.1048  BEST VAL Loss: 0.1048  Val_Acc: 96.635

Epoch 22: Validation loss decreased (0.104847 --> 0.104101).  Saving model ...
	 Train_Loss: 0.1454 Train_Acc: 95.829 Val_Loss: 0.1041  BEST VAL Loss: 0.1041  Val_Acc: 96.818

Epoch 23: Validation loss decreased (0.104101 --> 0.103479).  Saving model ...
	 Train_Loss: 0.1438 Train_Acc: 95.850 Val_Loss: 0.1035  BEST VAL Loss: 0.1035  Val_Acc: 96.812

Epoch 24: Validation loss decreased (0.103479 --> 0.103072).  Saving model ...
	 Train_Loss: 0.1425 Train_Acc: 95.842 Val_Loss: 0.1031  BEST VAL Loss: 0.1031  Val_Acc: 96.626

Epoch 25: Validation loss decreased (0.103072 --> 0.102486).  Saving model ...
	 Train_Loss: 0.1411 Train_Acc: 95.898 Val_Loss: 0.1025  BEST VAL Loss: 0.1025  Val_Acc: 96.770

Epoch 26: Validation loss decreased (0.102486 --> 0.101942).  Saving model ...
	 Train_Loss: 0.1399 Train_Acc: 95.932 Val_Loss: 0.1019  BEST VAL Loss: 0.1019  Val_Acc: 96.820

Epoch 27: Validation loss decreased (0.101942 --> 0.101410).  Saving model ...
	 Train_Loss: 0.1387 Train_Acc: 95.961 Val_Loss: 0.1014  BEST VAL Loss: 0.1014  Val_Acc: 96.826

Epoch 28: Validation loss decreased (0.101410 --> 0.100912).  Saving model ...
	 Train_Loss: 0.1376 Train_Acc: 95.960 Val_Loss: 0.1009  BEST VAL Loss: 0.1009  Val_Acc: 96.944

Epoch 29: Validation loss decreased (0.100912 --> 0.100485).  Saving model ...
	 Train_Loss: 0.1365 Train_Acc: 95.961 Val_Loss: 0.1005  BEST VAL Loss: 0.1005  Val_Acc: 96.835

Epoch 30: Validation loss decreased (0.100485 --> 0.100056).  Saving model ...
	 Train_Loss: 0.1354 Train_Acc: 95.977 Val_Loss: 0.1001  BEST VAL Loss: 0.1001  Val_Acc: 96.815

Epoch 31: Validation loss decreased (0.100056 --> 0.099760).  Saving model ...
	 Train_Loss: 0.1345 Train_Acc: 96.014 Val_Loss: 0.0998  BEST VAL Loss: 0.0998  Val_Acc: 96.764

Epoch 32: Validation loss decreased (0.099760 --> 0.099392).  Saving model ...
	 Train_Loss: 0.1336 Train_Acc: 96.026 Val_Loss: 0.0994  BEST VAL Loss: 0.0994  Val_Acc: 96.806

Epoch 33: Validation loss decreased (0.099392 --> 0.099057).  Saving model ...
	 Train_Loss: 0.1327 Train_Acc: 96.076 Val_Loss: 0.0991  BEST VAL Loss: 0.0991  Val_Acc: 96.903

Epoch 34: Validation loss decreased (0.099057 --> 0.098695).  Saving model ...
	 Train_Loss: 0.1319 Train_Acc: 96.077 Val_Loss: 0.0987  BEST VAL Loss: 0.0987  Val_Acc: 96.918

Epoch 35: Validation loss decreased (0.098695 --> 0.098373).  Saving model ...
	 Train_Loss: 0.1310 Train_Acc: 96.093 Val_Loss: 0.0984  BEST VAL Loss: 0.0984  Val_Acc: 96.938

Epoch 36: Validation loss decreased (0.098373 --> 0.098078).  Saving model ...
	 Train_Loss: 0.1303 Train_Acc: 96.067 Val_Loss: 0.0981  BEST VAL Loss: 0.0981  Val_Acc: 96.841

Epoch 37: Validation loss decreased (0.098078 --> 0.097835).  Saving model ...
	 Train_Loss: 0.1295 Train_Acc: 96.090 Val_Loss: 0.0978  BEST VAL Loss: 0.0978  Val_Acc: 96.888

Epoch 38: Validation loss decreased (0.097835 --> 0.097524).  Saving model ...
	 Train_Loss: 0.1288 Train_Acc: 96.132 Val_Loss: 0.0975  BEST VAL Loss: 0.0975  Val_Acc: 96.924

Epoch 39: Validation loss decreased (0.097524 --> 0.097272).  Saving model ...
	 Train_Loss: 0.1282 Train_Acc: 96.100 Val_Loss: 0.0973  BEST VAL Loss: 0.0973  Val_Acc: 96.906

Epoch 40: Validation loss decreased (0.097272 --> 0.096988).  Saving model ...
	 Train_Loss: 0.1275 Train_Acc: 96.123 Val_Loss: 0.0970  BEST VAL Loss: 0.0970  Val_Acc: 97.012

Epoch 41: Validation loss decreased (0.096988 --> 0.096746).  Saving model ...
	 Train_Loss: 0.1269 Train_Acc: 96.203 Val_Loss: 0.0967  BEST VAL Loss: 0.0967  Val_Acc: 96.950

Epoch 42: Validation loss decreased (0.096746 --> 0.096438).  Saving model ...
	 Train_Loss: 0.1262 Train_Acc: 96.191 Val_Loss: 0.0964  BEST VAL Loss: 0.0964  Val_Acc: 97.003

Epoch 43: Validation loss decreased (0.096438 --> 0.096226).  Saving model ...
	 Train_Loss: 0.1256 Train_Acc: 96.217 Val_Loss: 0.0962  BEST VAL Loss: 0.0962  Val_Acc: 96.983

Epoch 44: Validation loss decreased (0.096226 --> 0.096012).  Saving model ...
	 Train_Loss: 0.1250 Train_Acc: 96.210 Val_Loss: 0.0960  BEST VAL Loss: 0.0960  Val_Acc: 96.953

Epoch 45: Validation loss decreased (0.096012 --> 0.095786).  Saving model ...
	 Train_Loss: 0.1244 Train_Acc: 96.271 Val_Loss: 0.0958  BEST VAL Loss: 0.0958  Val_Acc: 96.980

Epoch 46: Validation loss decreased (0.095786 --> 0.095572).  Saving model ...
	 Train_Loss: 0.1239 Train_Acc: 96.237 Val_Loss: 0.0956  BEST VAL Loss: 0.0956  Val_Acc: 96.906

Epoch 47: Validation loss decreased (0.095572 --> 0.095410).  Saving model ...
	 Train_Loss: 0.1234 Train_Acc: 96.253 Val_Loss: 0.0954  BEST VAL Loss: 0.0954  Val_Acc: 96.888

Epoch 48: Validation loss decreased (0.095410 --> 0.095204).  Saving model ...
	 Train_Loss: 0.1228 Train_Acc: 96.273 Val_Loss: 0.0952  BEST VAL Loss: 0.0952  Val_Acc: 96.938

Epoch 49: Validation loss decreased (0.095204 --> 0.095042).  Saving model ...
	 Train_Loss: 0.1223 Train_Acc: 96.274 Val_Loss: 0.0950  BEST VAL Loss: 0.0950  Val_Acc: 97.003

Epoch 50: Validation loss decreased (0.095042 --> 0.094886).  Saving model ...
	 Train_Loss: 0.1218 Train_Acc: 96.311 Val_Loss: 0.0949  BEST VAL Loss: 0.0949  Val_Acc: 96.927

Epoch 51: Validation loss decreased (0.094886 --> 0.094721).  Saving model ...
	 Train_Loss: 0.1213 Train_Acc: 96.313 Val_Loss: 0.0947  BEST VAL Loss: 0.0947  Val_Acc: 96.950

Epoch 52: Validation loss decreased (0.094721 --> 0.094534).  Saving model ...
	 Train_Loss: 0.1209 Train_Acc: 96.311 Val_Loss: 0.0945  BEST VAL Loss: 0.0945  Val_Acc: 97.124

Epoch 53: Validation loss decreased (0.094534 --> 0.094365).  Saving model ...
	 Train_Loss: 0.1204 Train_Acc: 96.324 Val_Loss: 0.0944  BEST VAL Loss: 0.0944  Val_Acc: 97.083

Epoch 54: Validation loss decreased (0.094365 --> 0.094239).  Saving model ...
	 Train_Loss: 0.1200 Train_Acc: 96.350 Val_Loss: 0.0942  BEST VAL Loss: 0.0942  Val_Acc: 96.974

Epoch 55: Validation loss decreased (0.094239 --> 0.094088).  Saving model ...
	 Train_Loss: 0.1195 Train_Acc: 96.385 Val_Loss: 0.0941  BEST VAL Loss: 0.0941  Val_Acc: 96.991

Epoch 56: Validation loss decreased (0.094088 --> 0.093952).  Saving model ...
	 Train_Loss: 0.1191 Train_Acc: 96.365 Val_Loss: 0.0940  BEST VAL Loss: 0.0940  Val_Acc: 96.935

Epoch 57: Validation loss decreased (0.093952 --> 0.093825).  Saving model ...
	 Train_Loss: 0.1187 Train_Acc: 96.415 Val_Loss: 0.0938  BEST VAL Loss: 0.0938  Val_Acc: 96.959

Epoch 58: Validation loss decreased (0.093825 --> 0.093679).  Saving model ...
	 Train_Loss: 0.1183 Train_Acc: 96.393 Val_Loss: 0.0937  BEST VAL Loss: 0.0937  Val_Acc: 97.015

Epoch 59: Validation loss decreased (0.093679 --> 0.093521).  Saving model ...
	 Train_Loss: 0.1180 Train_Acc: 96.337 Val_Loss: 0.0935  BEST VAL Loss: 0.0935  Val_Acc: 97.062

Epoch 60: Validation loss decreased (0.093521 --> 0.093367).  Saving model ...
	 Train_Loss: 0.1176 Train_Acc: 96.400 Val_Loss: 0.0934  BEST VAL Loss: 0.0934  Val_Acc: 97.106

Epoch 61: Validation loss decreased (0.093367 --> 0.093209).  Saving model ...
	 Train_Loss: 0.1172 Train_Acc: 96.354 Val_Loss: 0.0932  BEST VAL Loss: 0.0932  Val_Acc: 97.124

Epoch 62: Validation loss decreased (0.093209 --> 0.093033).  Saving model ...
	 Train_Loss: 0.1168 Train_Acc: 96.421 Val_Loss: 0.0930  BEST VAL Loss: 0.0930  Val_Acc: 97.186

Epoch 63: Validation loss decreased (0.093033 --> 0.092867).  Saving model ...
	 Train_Loss: 0.1165 Train_Acc: 96.421 Val_Loss: 0.0929  BEST VAL Loss: 0.0929  Val_Acc: 97.186

Epoch 64: Validation loss decreased (0.092867 --> 0.092724).  Saving model ...
	 Train_Loss: 0.1162 Train_Acc: 96.421 Val_Loss: 0.0927  BEST VAL Loss: 0.0927  Val_Acc: 97.133

Epoch 65: Validation loss decreased (0.092724 --> 0.092597).  Saving model ...
	 Train_Loss: 0.1158 Train_Acc: 96.457 Val_Loss: 0.0926  BEST VAL Loss: 0.0926  Val_Acc: 97.044

Epoch 66: Validation loss decreased (0.092597 --> 0.092450).  Saving model ...
	 Train_Loss: 0.1155 Train_Acc: 96.453 Val_Loss: 0.0925  BEST VAL Loss: 0.0925  Val_Acc: 97.092

Epoch 67: Validation loss decreased (0.092450 --> 0.092307).  Saving model ...
	 Train_Loss: 0.1151 Train_Acc: 96.461 Val_Loss: 0.0923  BEST VAL Loss: 0.0923  Val_Acc: 97.142

Epoch 68: Validation loss decreased (0.092307 --> 0.092155).  Saving model ...
	 Train_Loss: 0.1148 Train_Acc: 96.490 Val_Loss: 0.0922  BEST VAL Loss: 0.0922  Val_Acc: 97.145

Epoch 69: Validation loss decreased (0.092155 --> 0.092040).  Saving model ...
	 Train_Loss: 0.1145 Train_Acc: 96.480 Val_Loss: 0.0920  BEST VAL Loss: 0.0920  Val_Acc: 97.044

Epoch 70: Validation loss decreased (0.092040 --> 0.091915).  Saving model ...
	 Train_Loss: 0.1142 Train_Acc: 96.487 Val_Loss: 0.0919  BEST VAL Loss: 0.0919  Val_Acc: 97.118

Epoch 71: Validation loss decreased (0.091915 --> 0.091835).  Saving model ...
	 Train_Loss: 0.1139 Train_Acc: 96.515 Val_Loss: 0.0918  BEST VAL Loss: 0.0918  Val_Acc: 97.074

Epoch 72: Validation loss decreased (0.091835 --> 0.091718).  Saving model ...
	 Train_Loss: 0.1136 Train_Acc: 96.518 Val_Loss: 0.0917  BEST VAL Loss: 0.0917  Val_Acc: 97.059

Epoch 73: Validation loss decreased (0.091718 --> 0.091619).  Saving model ...
	 Train_Loss: 0.1133 Train_Acc: 96.481 Val_Loss: 0.0916  BEST VAL Loss: 0.0916  Val_Acc: 97.115

Epoch 74: Validation loss decreased (0.091619 --> 0.091499).  Saving model ...
	 Train_Loss: 0.1130 Train_Acc: 96.528 Val_Loss: 0.0915  BEST VAL Loss: 0.0915  Val_Acc: 97.109

Epoch 75: Validation loss decreased (0.091499 --> 0.091380).  Saving model ...
	 Train_Loss: 0.1127 Train_Acc: 96.532 Val_Loss: 0.0914  BEST VAL Loss: 0.0914  Val_Acc: 97.162

Epoch 76: Validation loss decreased (0.091380 --> 0.091287).  Saving model ...
	 Train_Loss: 0.1124 Train_Acc: 96.526 Val_Loss: 0.0913  BEST VAL Loss: 0.0913  Val_Acc: 97.106

Epoch 77: Validation loss decreased (0.091287 --> 0.091199).  Saving model ...
	 Train_Loss: 0.1121 Train_Acc: 96.601 Val_Loss: 0.0912  BEST VAL Loss: 0.0912  Val_Acc: 97.112

Epoch 78: Validation loss decreased (0.091199 --> 0.091101).  Saving model ...
	 Train_Loss: 0.1118 Train_Acc: 96.616 Val_Loss: 0.0911  BEST VAL Loss: 0.0911  Val_Acc: 97.115

Epoch 79: Validation loss decreased (0.091101 --> 0.091009).  Saving model ...
	 Train_Loss: 0.1116 Train_Acc: 96.563 Val_Loss: 0.0910  BEST VAL Loss: 0.0910  Val_Acc: 97.174

Epoch 80: Validation loss decreased (0.091009 --> 0.090926).  Saving model ...
	 Train_Loss: 0.1113 Train_Acc: 96.517 Val_Loss: 0.0909  BEST VAL Loss: 0.0909  Val_Acc: 97.165

Epoch 81: Validation loss decreased (0.090926 --> 0.090833).  Saving model ...
	 Train_Loss: 0.1111 Train_Acc: 96.560 Val_Loss: 0.0908  BEST VAL Loss: 0.0908  Val_Acc: 97.195

Epoch 82: Validation loss decreased (0.090833 --> 0.090731).  Saving model ...
	 Train_Loss: 0.1108 Train_Acc: 96.584 Val_Loss: 0.0907  BEST VAL Loss: 0.0907  Val_Acc: 97.198

Epoch 83: Validation loss decreased (0.090731 --> 0.090628).  Saving model ...
	 Train_Loss: 0.1106 Train_Acc: 96.595 Val_Loss: 0.0906  BEST VAL Loss: 0.0906  Val_Acc: 97.207

Epoch 84: Validation loss decreased (0.090628 --> 0.090522).  Saving model ...
	 Train_Loss: 0.1103 Train_Acc: 96.537 Val_Loss: 0.0905  BEST VAL Loss: 0.0905  Val_Acc: 97.245

Epoch 85: Validation loss decreased (0.090522 --> 0.090424).  Saving model ...
	 Train_Loss: 0.1101 Train_Acc: 96.589 Val_Loss: 0.0904  BEST VAL Loss: 0.0904  Val_Acc: 97.224

Epoch 86: Validation loss decreased (0.090424 --> 0.090369).  Saving model ...
	 Train_Loss: 0.1099 Train_Acc: 96.604 Val_Loss: 0.0904  BEST VAL Loss: 0.0904  Val_Acc: 97.118

Epoch 87: Validation loss decreased (0.090369 --> 0.090268).  Saving model ...
	 Train_Loss: 0.1096 Train_Acc: 96.617 Val_Loss: 0.0903  BEST VAL Loss: 0.0903  Val_Acc: 97.239

Epoch 88: Validation loss decreased (0.090268 --> 0.090189).  Saving model ...
	 Train_Loss: 0.1094 Train_Acc: 96.596 Val_Loss: 0.0902  BEST VAL Loss: 0.0902  Val_Acc: 97.106

Epoch 89: Validation loss decreased (0.090189 --> 0.090103).  Saving model ...
	 Train_Loss: 0.1092 Train_Acc: 96.614 Val_Loss: 0.0901  BEST VAL Loss: 0.0901  Val_Acc: 97.212

Epoch 90: Validation loss decreased (0.090103 --> 0.090021).  Saving model ...
	 Train_Loss: 0.1089 Train_Acc: 96.715 Val_Loss: 0.0900  BEST VAL Loss: 0.0900  Val_Acc: 97.192

Epoch 91: Validation loss decreased (0.090021 --> 0.089929).  Saving model ...
	 Train_Loss: 0.1087 Train_Acc: 96.626 Val_Loss: 0.0899  BEST VAL Loss: 0.0899  Val_Acc: 97.189

Epoch 92: Validation loss decreased (0.089929 --> 0.089852).  Saving model ...
	 Train_Loss: 0.1085 Train_Acc: 96.634 Val_Loss: 0.0899  BEST VAL Loss: 0.0899  Val_Acc: 97.136

Epoch 93: Validation loss decreased (0.089852 --> 0.089767).  Saving model ...
	 Train_Loss: 0.1083 Train_Acc: 96.635 Val_Loss: 0.0898  BEST VAL Loss: 0.0898  Val_Acc: 97.156

Epoch 94: Validation loss decreased (0.089767 --> 0.089693).  Saving model ...
	 Train_Loss: 0.1080 Train_Acc: 96.663 Val_Loss: 0.0897  BEST VAL Loss: 0.0897  Val_Acc: 97.204

Epoch 95: Validation loss decreased (0.089693 --> 0.089614).  Saving model ...
	 Train_Loss: 0.1078 Train_Acc: 96.661 Val_Loss: 0.0896  BEST VAL Loss: 0.0896  Val_Acc: 97.195

Epoch 96: Validation loss decreased (0.089614 --> 0.089515).  Saving model ...
	 Train_Loss: 0.1076 Train_Acc: 96.683 Val_Loss: 0.0895  BEST VAL Loss: 0.0895  Val_Acc: 97.336

Epoch 97: Validation loss decreased (0.089515 --> 0.089429).  Saving model ...
	 Train_Loss: 0.1074 Train_Acc: 96.698 Val_Loss: 0.0894  BEST VAL Loss: 0.0894  Val_Acc: 97.162

Epoch 98: Validation loss decreased (0.089429 --> 0.089330).  Saving model ...
	 Train_Loss: 0.1072 Train_Acc: 96.708 Val_Loss: 0.0893  BEST VAL Loss: 0.0893  Val_Acc: 97.239

Epoch 99: Validation loss decreased (0.089330 --> 0.089251).  Saving model ...
	 Train_Loss: 0.1070 Train_Acc: 96.666 Val_Loss: 0.0893  BEST VAL Loss: 0.0893  Val_Acc: 97.230

H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.62      0.62      0.62    169560
           1       0.37      0.38      0.38    101922

    accuracy                           0.53    271482
   macro avg       0.50      0.50      0.50    271482
weighted avg       0.53      0.53      0.53    271482

H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.62      0.62      0.62     21196
           1       0.38      0.38      0.38     12740

    accuracy                           0.53     33936
   macro avg       0.50      0.50      0.50     33936
weighted avg       0.53      0.53      0.53     33936

H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.62      0.62      0.62     21196
           1       0.37      0.38      0.38     12740

    accuracy                           0.53     33936
   macro avg       0.50      0.50      0.50     33936
weighted avg       0.53      0.53      0.53     33936

              precision    recall  f1-score   support

           0       0.62      0.62      0.62     21196
           1       0.37      0.38      0.38     12740

    accuracy                           0.53     33936
   macro avg       0.50      0.50      0.50     33936
weighted avg       0.53      0.53      0.53     33936

H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.38      0.51      0.44     28584
           1       0.62      0.49      0.55     46859

    accuracy                           0.50     75443
   macro avg       0.50      0.50      0.49     75443
weighted avg       0.53      0.50      0.51     75443

              precision    recall  f1-score   support

           0       0.38      0.51      0.44     28584
           1       0.62      0.49      0.55     46859

    accuracy                           0.50     75443
   macro avg       0.50      0.50      0.49     75443
weighted avg       0.53      0.50      0.51     75443

completed
