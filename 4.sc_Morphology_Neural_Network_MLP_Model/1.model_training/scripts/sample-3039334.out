[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'c0b1d93c'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '6ee15847'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '7f4a2414'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '462d819f'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Thapsigargin_1.000_DMSO_0.025 treatment_name: H2O2_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Thapsigargin_1.000_DMSO_0.025
TREATMENT_NAME: H2O2_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (40666, 1276)
Number of total missing values across all columns: 81332
Data Subset Is Off
Wells held out for testing: ['D14' 'H22']
Wells to use for training, validation, and testing ['D15' 'H18' 'H19' 'H23' 'K14' 'K15' 'I18' 'I19' 'I22' 'I23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.410825).  Saving model ...
	 Train_Loss: 0.6167 Train_Acc: 72.366 Val_Loss: 0.4108  BEST VAL Loss: 0.4108  Val_Acc: 82.555

Epoch 1: Validation loss decreased (0.410825 --> 0.382307).  Saving model ...
	 Train_Loss: 0.5301 Train_Acc: 81.016 Val_Loss: 0.3823  BEST VAL Loss: 0.3823  Val_Acc: 85.869

Epoch 2: Validation loss decreased (0.382307 --> 0.357263).  Saving model ...
	 Train_Loss: 0.4839 Train_Acc: 83.762 Val_Loss: 0.3573  BEST VAL Loss: 0.3573  Val_Acc: 87.617

Epoch 3: Validation loss decreased (0.357263 --> 0.337778).  Saving model ...
	 Train_Loss: 0.4541 Train_Acc: 84.810 Val_Loss: 0.3378  BEST VAL Loss: 0.3378  Val_Acc: 89.033

Epoch 4: Validation loss decreased (0.337778 --> 0.324828).  Saving model ...
	 Train_Loss: 0.4330 Train_Acc: 85.623 Val_Loss: 0.3248  BEST VAL Loss: 0.3248  Val_Acc: 89.364

Epoch 5: Validation loss decreased (0.324828 --> 0.313897).  Saving model ...
	 Train_Loss: 0.4166 Train_Acc: 86.339 Val_Loss: 0.3139  BEST VAL Loss: 0.3139  Val_Acc: 88.912

Epoch 6: Validation loss decreased (0.313897 --> 0.305302).  Saving model ...
	 Train_Loss: 0.4035 Train_Acc: 86.528 Val_Loss: 0.3053  BEST VAL Loss: 0.3053  Val_Acc: 89.666

Epoch 7: Validation loss decreased (0.305302 --> 0.298186).  Saving model ...
	 Train_Loss: 0.3923 Train_Acc: 87.164 Val_Loss: 0.2982  BEST VAL Loss: 0.2982  Val_Acc: 89.967

Epoch 8: Validation loss decreased (0.298186 --> 0.290456).  Saving model ...
	 Train_Loss: 0.3825 Train_Acc: 87.405 Val_Loss: 0.2905  BEST VAL Loss: 0.2905  Val_Acc: 90.780

Epoch 9: Validation loss decreased (0.290456 --> 0.284228).  Saving model ...
	 Train_Loss: 0.3744 Train_Acc: 87.729 Val_Loss: 0.2842  BEST VAL Loss: 0.2842  Val_Acc: 90.479

Epoch 10: Validation loss decreased (0.284228 --> 0.279555).  Saving model ...
	 Train_Loss: 0.3675 Train_Acc: 87.729 Val_Loss: 0.2796  BEST VAL Loss: 0.2796  Val_Acc: 90.961

Epoch 11: Validation loss decreased (0.279555 --> 0.275454).  Saving model ...
	 Train_Loss: 0.3615 Train_Acc: 87.831 Val_Loss: 0.2755  BEST VAL Loss: 0.2755  Val_Acc: 91.172

Epoch 12: Validation loss decreased (0.275454 --> 0.271335).  Saving model ...
	 Train_Loss: 0.3556 Train_Acc: 88.264 Val_Loss: 0.2713  BEST VAL Loss: 0.2713  Val_Acc: 91.172

Epoch 13: Validation loss decreased (0.271335 --> 0.268309).  Saving model ...
	 Train_Loss: 0.3503 Train_Acc: 88.291 Val_Loss: 0.2683  BEST VAL Loss: 0.2683  Val_Acc: 91.413

Epoch 14: Validation loss decreased (0.268309 --> 0.264634).  Saving model ...
	 Train_Loss: 0.3451 Train_Acc: 88.588 Val_Loss: 0.2646  BEST VAL Loss: 0.2646  Val_Acc: 91.112

Epoch 15: Validation loss decreased (0.264634 --> 0.261743).  Saving model ...
	 Train_Loss: 0.3413 Train_Acc: 88.242 Val_Loss: 0.2617  BEST VAL Loss: 0.2617  Val_Acc: 91.594

Epoch 16: Validation loss decreased (0.261743 --> 0.258425).  Saving model ...
	 Train_Loss: 0.3372 Train_Acc: 88.856 Val_Loss: 0.2584  BEST VAL Loss: 0.2584  Val_Acc: 91.564

Epoch 17: Validation loss decreased (0.258425 --> 0.256088).  Saving model ...
	 Train_Loss: 0.3336 Train_Acc: 88.596 Val_Loss: 0.2561  BEST VAL Loss: 0.2561  Val_Acc: 91.323

Epoch 18: Validation loss decreased (0.256088 --> 0.253793).  Saving model ...
	 Train_Loss: 0.3302 Train_Acc: 88.818 Val_Loss: 0.2538  BEST VAL Loss: 0.2538  Val_Acc: 91.624

Epoch 19: Validation loss decreased (0.253793 --> 0.251715).  Saving model ...
	 Train_Loss: 0.3268 Train_Acc: 89.010 Val_Loss: 0.2517  BEST VAL Loss: 0.2517  Val_Acc: 91.745

Epoch 20: Validation loss decreased (0.251715 --> 0.250160).  Saving model ...
	 Train_Loss: 0.3241 Train_Acc: 88.649 Val_Loss: 0.2502  BEST VAL Loss: 0.2502  Val_Acc: 91.654

Epoch 21: Validation loss decreased (0.250160 --> 0.248089).  Saving model ...
	 Train_Loss: 0.3213 Train_Acc: 89.074 Val_Loss: 0.2481  BEST VAL Loss: 0.2481  Val_Acc: 92.287

Epoch 22: Validation loss decreased (0.248089 --> 0.246135).  Saving model ...
	 Train_Loss: 0.3185 Train_Acc: 89.395 Val_Loss: 0.2461  BEST VAL Loss: 0.2461  Val_Acc: 92.016

Epoch 23: Validation loss decreased (0.246135 --> 0.244348).  Saving model ...
	 Train_Loss: 0.3160 Train_Acc: 89.410 Val_Loss: 0.2443  BEST VAL Loss: 0.2443  Val_Acc: 91.925

Epoch 24: Validation loss decreased (0.244348 --> 0.242922).  Saving model ...
	 Train_Loss: 0.3136 Train_Acc: 89.459 Val_Loss: 0.2429  BEST VAL Loss: 0.2429  Val_Acc: 91.805

Epoch 25: Validation loss decreased (0.242922 --> 0.241234).  Saving model ...
	 Train_Loss: 0.3113 Train_Acc: 89.338 Val_Loss: 0.2412  BEST VAL Loss: 0.2412  Val_Acc: 92.196

Epoch 26: Validation loss decreased (0.241234 --> 0.240564).  Saving model ...
	 Train_Loss: 0.3095 Train_Acc: 88.916 Val_Loss: 0.2406  BEST VAL Loss: 0.2406  Val_Acc: 91.624

Epoch 27: Validation loss decreased (0.240564 --> 0.239245).  Saving model ...
	 Train_Loss: 0.3074 Train_Acc: 89.459 Val_Loss: 0.2392  BEST VAL Loss: 0.2392  Val_Acc: 91.925

Epoch 28: Validation loss decreased (0.239245 --> 0.238204).  Saving model ...
	 Train_Loss: 0.3054 Train_Acc: 89.451 Val_Loss: 0.2382  BEST VAL Loss: 0.2382  Val_Acc: 91.865

Epoch 29: Validation loss decreased (0.238204 --> 0.236871).  Saving model ...
	 Train_Loss: 0.3033 Train_Acc: 89.692 Val_Loss: 0.2369  BEST VAL Loss: 0.2369  Val_Acc: 92.106

Epoch 30: Validation loss decreased (0.236871 --> 0.235630).  Saving model ...
	 Train_Loss: 0.3016 Train_Acc: 89.466 Val_Loss: 0.2356  BEST VAL Loss: 0.2356  Val_Acc: 91.534

Epoch 31: Validation loss decreased (0.235630 --> 0.234526).  Saving model ...
	 Train_Loss: 0.2998 Train_Acc: 89.598 Val_Loss: 0.2345  BEST VAL Loss: 0.2345  Val_Acc: 92.407

Epoch 32: Validation loss decreased (0.234526 --> 0.234209).  Saving model ...
	 Train_Loss: 0.2981 Train_Acc: 89.655 Val_Loss: 0.2342  BEST VAL Loss: 0.2342  Val_Acc: 92.407

Epoch 33: Validation loss decreased (0.234209 --> 0.232978).  Saving model ...
	 Train_Loss: 0.2966 Train_Acc: 89.274 Val_Loss: 0.2330  BEST VAL Loss: 0.2330  Val_Acc: 92.377

Epoch 34: Validation loss decreased (0.232978 --> 0.231941).  Saving model ...
	 Train_Loss: 0.2951 Train_Acc: 89.711 Val_Loss: 0.2319  BEST VAL Loss: 0.2319  Val_Acc: 92.498

Epoch 35: Validation loss decreased (0.231941 --> 0.231052).  Saving model ...
	 Train_Loss: 0.2937 Train_Acc: 89.658 Val_Loss: 0.2311  BEST VAL Loss: 0.2311  Val_Acc: 91.955

Epoch 36: Validation loss decreased (0.231052 --> 0.230466).  Saving model ...
	 Train_Loss: 0.2924 Train_Acc: 89.481 Val_Loss: 0.2305  BEST VAL Loss: 0.2305  Val_Acc: 92.166

Epoch 37: Validation loss decreased (0.230466 --> 0.230156).  Saving model ...
	 Train_Loss: 0.2911 Train_Acc: 89.474 Val_Loss: 0.2302  BEST VAL Loss: 0.2302  Val_Acc: 92.106

Epoch 38: Validation loss decreased (0.230156 --> 0.229291).  Saving model ...
	 Train_Loss: 0.2899 Train_Acc: 89.500 Val_Loss: 0.2293  BEST VAL Loss: 0.2293  Val_Acc: 92.257

Epoch 39: Validation loss decreased (0.229291 --> 0.228600).  Saving model ...
	 Train_Loss: 0.2886 Train_Acc: 89.760 Val_Loss: 0.2286  BEST VAL Loss: 0.2286  Val_Acc: 92.287

Epoch 40: Validation loss decreased (0.228600 --> 0.227509).  Saving model ...
	 Train_Loss: 0.2873 Train_Acc: 89.963 Val_Loss: 0.2275  BEST VAL Loss: 0.2275  Val_Acc: 92.618

Epoch 41: Validation loss decreased (0.227509 --> 0.226924).  Saving model ...
	 Train_Loss: 0.2860 Train_Acc: 90.163 Val_Loss: 0.2269  BEST VAL Loss: 0.2269  Val_Acc: 91.925

Epoch 42: Validation loss decreased (0.226924 --> 0.226088).  Saving model ...
	 Train_Loss: 0.2849 Train_Acc: 89.549 Val_Loss: 0.2261  BEST VAL Loss: 0.2261  Val_Acc: 92.618

Epoch 43: Validation loss decreased (0.226088 --> 0.225128).  Saving model ...
	 Train_Loss: 0.2837 Train_Acc: 90.125 Val_Loss: 0.2251  BEST VAL Loss: 0.2251  Val_Acc: 92.618

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.2827 Train_Acc: 89.775 Val_Loss: 0.2251  BEST VAL Loss: 0.2251  Val_Acc: 91.895

Epoch 45: Validation loss decreased (0.225128 --> 0.224597).  Saving model ...
	 Train_Loss: 0.2816 Train_Acc: 89.952 Val_Loss: 0.2246  BEST VAL Loss: 0.2246  Val_Acc: 92.528

Epoch 46: Validation loss decreased (0.224597 --> 0.224080).  Saving model ...
	 Train_Loss: 0.2805 Train_Acc: 90.137 Val_Loss: 0.2241  BEST VAL Loss: 0.2241  Val_Acc: 92.377

Epoch 47: Validation loss decreased (0.224080 --> 0.223191).  Saving model ...
	 Train_Loss: 0.2794 Train_Acc: 89.847 Val_Loss: 0.2232  BEST VAL Loss: 0.2232  Val_Acc: 92.618

Epoch 48: Validation loss decreased (0.223191 --> 0.222765).  Saving model ...
	 Train_Loss: 0.2785 Train_Acc: 90.009 Val_Loss: 0.2228  BEST VAL Loss: 0.2228  Val_Acc: 92.136

Epoch 49: Validation loss decreased (0.222765 --> 0.222124).  Saving model ...
	 Train_Loss: 0.2777 Train_Acc: 89.975 Val_Loss: 0.2221  BEST VAL Loss: 0.2221  Val_Acc: 92.648

Epoch 50: Validation loss decreased (0.222124 --> 0.221670).  Saving model ...
	 Train_Loss: 0.2768 Train_Acc: 89.858 Val_Loss: 0.2217  BEST VAL Loss: 0.2217  Val_Acc: 92.558

Epoch 51: Validation loss decreased (0.221670 --> 0.221346).  Saving model ...
	 Train_Loss: 0.2759 Train_Acc: 90.190 Val_Loss: 0.2213  BEST VAL Loss: 0.2213  Val_Acc: 92.407

Epoch 52: Validation loss decreased (0.221346 --> 0.220911).  Saving model ...
	 Train_Loss: 0.2751 Train_Acc: 89.982 Val_Loss: 0.2209  BEST VAL Loss: 0.2209  Val_Acc: 92.046

Epoch 53: Validation loss decreased (0.220911 --> 0.220559).  Saving model ...
	 Train_Loss: 0.2743 Train_Acc: 90.265 Val_Loss: 0.2206  BEST VAL Loss: 0.2206  Val_Acc: 92.377

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.2734 Train_Acc: 90.216 Val_Loss: 0.2206  BEST VAL Loss: 0.2206  Val_Acc: 92.347

Epoch 55: Validation loss decreased (0.220559 --> 0.220292).  Saving model ...
	 Train_Loss: 0.2724 Train_Acc: 90.438 Val_Loss: 0.2203  BEST VAL Loss: 0.2203  Val_Acc: 92.407

Epoch 56: Validation loss decreased (0.220292 --> 0.219936).  Saving model ...
	 Train_Loss: 0.2716 Train_Acc: 90.076 Val_Loss: 0.2199  BEST VAL Loss: 0.2199  Val_Acc: 92.618

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.2708 Train_Acc: 90.404 Val_Loss: 0.2200  BEST VAL Loss: 0.2199  Val_Acc: 92.859

Epoch 58: Validation loss decreased (0.219936 --> 0.219592).  Saving model ...
	 Train_Loss: 0.2700 Train_Acc: 90.257 Val_Loss: 0.2196  BEST VAL Loss: 0.2196  Val_Acc: 92.076

Epoch 59: Validation loss decreased (0.219592 --> 0.219175).  Saving model ...
	 Train_Loss: 0.2692 Train_Acc: 90.238 Val_Loss: 0.2192  BEST VAL Loss: 0.2192  Val_Acc: 92.799

Epoch 60: Validation loss decreased (0.219175 --> 0.218937).  Saving model ...
	 Train_Loss: 0.2685 Train_Acc: 90.231 Val_Loss: 0.2189  BEST VAL Loss: 0.2189  Val_Acc: 91.895

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.2678 Train_Acc: 90.186 Val_Loss: 0.2191  BEST VAL Loss: 0.2189  Val_Acc: 92.437

Epoch 62: Validation loss decreased (0.218937 --> 0.218638).  Saving model ...
	 Train_Loss: 0.2671 Train_Acc: 90.404 Val_Loss: 0.2186  BEST VAL Loss: 0.2186  Val_Acc: 92.347

Epoch 63: Validation loss decreased (0.218638 --> 0.218293).  Saving model ...
	 Train_Loss: 0.2663 Train_Acc: 90.348 Val_Loss: 0.2183  BEST VAL Loss: 0.2183  Val_Acc: 92.799

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.2657 Train_Acc: 90.238 Val_Loss: 0.2183  BEST VAL Loss: 0.2183  Val_Acc: 92.588

Epoch 65: Validation loss decreased (0.218293 --> 0.217848).  Saving model ...
	 Train_Loss: 0.2650 Train_Acc: 90.333 Val_Loss: 0.2178  BEST VAL Loss: 0.2178  Val_Acc: 92.468

Epoch 66: Validation loss decreased (0.217848 --> 0.217434).  Saving model ...
	 Train_Loss: 0.2643 Train_Acc: 90.367 Val_Loss: 0.2174  BEST VAL Loss: 0.2174  Val_Acc: 92.859

Epoch 67: Validation loss decreased (0.217434 --> 0.217340).  Saving model ...
	 Train_Loss: 0.2637 Train_Acc: 90.295 Val_Loss: 0.2173  BEST VAL Loss: 0.2173  Val_Acc: 92.437

Epoch 68: Validation loss decreased (0.217340 --> 0.217045).  Saving model ...
	 Train_Loss: 0.2631 Train_Acc: 90.144 Val_Loss: 0.2170  BEST VAL Loss: 0.2170  Val_Acc: 92.377

Epoch 69: Validation loss decreased (0.217045 --> 0.216880).  Saving model ...
	 Train_Loss: 0.2625 Train_Acc: 90.310 Val_Loss: 0.2169  BEST VAL Loss: 0.2169  Val_Acc: 92.287

Epoch 70: Validation loss decreased (0.216880 --> 0.216499).  Saving model ...
	 Train_Loss: 0.2619 Train_Acc: 90.201 Val_Loss: 0.2165  BEST VAL Loss: 0.2165  Val_Acc: 92.588

Epoch 71: Validation loss decreased (0.216499 --> 0.216109).  Saving model ...
	 Train_Loss: 0.2614 Train_Acc: 90.178 Val_Loss: 0.2161  BEST VAL Loss: 0.2161  Val_Acc: 92.739

Epoch 72: Validation loss decreased (0.216109 --> 0.216048).  Saving model ...
	 Train_Loss: 0.2608 Train_Acc: 90.600 Val_Loss: 0.2160  BEST VAL Loss: 0.2160  Val_Acc: 92.468

Epoch 73: Validation loss decreased (0.216048 --> 0.215825).  Saving model ...
	 Train_Loss: 0.2602 Train_Acc: 90.385 Val_Loss: 0.2158  BEST VAL Loss: 0.2158  Val_Acc: 92.679

Epoch 74: Validation loss decreased (0.215825 --> 0.215769).  Saving model ...
	 Train_Loss: 0.2597 Train_Acc: 90.174 Val_Loss: 0.2158  BEST VAL Loss: 0.2158  Val_Acc: 92.196

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.2591 Train_Acc: 90.483 Val_Loss: 0.2163  BEST VAL Loss: 0.2158  Val_Acc: 92.317

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.2586 Train_Acc: 90.321 Val_Loss: 0.2161  BEST VAL Loss: 0.2158  Val_Acc: 92.980

Epoch 77: Validation loss decreased (0.215769 --> 0.215766).  Saving model ...
	 Train_Loss: 0.2580 Train_Acc: 90.498 Val_Loss: 0.2158  BEST VAL Loss: 0.2158  Val_Acc: 92.528

Epoch 78: Validation loss decreased (0.215766 --> 0.215596).  Saving model ...
	 Train_Loss: 0.2575 Train_Acc: 90.562 Val_Loss: 0.2156  BEST VAL Loss: 0.2156  Val_Acc: 92.287

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.2570 Train_Acc: 90.457 Val_Loss: 0.2157  BEST VAL Loss: 0.2156  Val_Acc: 92.347

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.2566 Train_Acc: 89.930 Val_Loss: 0.2157  BEST VAL Loss: 0.2156  Val_Acc: 92.679

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.2562 Train_Acc: 90.416 Val_Loss: 0.2157  BEST VAL Loss: 0.2156  Val_Acc: 92.558

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.2558 Train_Acc: 90.167 Val_Loss: 0.2158  BEST VAL Loss: 0.2156  Val_Acc: 92.437

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.2553 Train_Acc: 90.589 Val_Loss: 0.2159  BEST VAL Loss: 0.2156  Val_Acc: 92.618

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.2549 Train_Acc: 90.370 Val_Loss: 0.2157  BEST VAL Loss: 0.2156  Val_Acc: 92.648

Epoch 85: Validation loss decreased (0.215596 --> 0.215566).  Saving model ...
	 Train_Loss: 0.2545 Train_Acc: 90.412 Val_Loss: 0.2156  BEST VAL Loss: 0.2156  Val_Acc: 92.287

Epoch 86: Validation loss decreased (0.215566 --> 0.215523).  Saving model ...
	 Train_Loss: 0.2540 Train_Acc: 90.378 Val_Loss: 0.2155  BEST VAL Loss: 0.2155  Val_Acc: 92.468

Epoch 87: Validation loss decreased (0.215523 --> 0.215463).  Saving model ...
	 Train_Loss: 0.2536 Train_Acc: 90.551 Val_Loss: 0.2155  BEST VAL Loss: 0.2155  Val_Acc: 92.377

Epoch 88: Validation loss decreased (0.215463 --> 0.215289).  Saving model ...
	 Train_Loss: 0.2531 Train_Acc: 90.676 Val_Loss: 0.2153  BEST VAL Loss: 0.2153  Val_Acc: 92.437

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.2526 Train_Acc: 90.604 Val_Loss: 0.2155  BEST VAL Loss: 0.2153  Val_Acc: 92.166

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.2522 Train_Acc: 90.578 Val_Loss: 0.2155  BEST VAL Loss: 0.2153  Val_Acc: 92.679

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.2517 Train_Acc: 90.981 Val_Loss: 0.2155  BEST VAL Loss: 0.2153  Val_Acc: 92.317

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.2513 Train_Acc: 90.491 Val_Loss: 0.2154  BEST VAL Loss: 0.2153  Val_Acc: 92.076

Epoch 93: Validation loss decreased (0.215289 --> 0.215266).  Saving model ...
	 Train_Loss: 0.2510 Train_Acc: 90.355 Val_Loss: 0.2153  BEST VAL Loss: 0.2153  Val_Acc: 91.805

Epoch 94: Validation loss decreased (0.215266 --> 0.215182).  Saving model ...
	 Train_Loss: 0.2506 Train_Acc: 90.431 Val_Loss: 0.2152  BEST VAL Loss: 0.2152  Val_Acc: 92.558

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.2502 Train_Acc: 90.819 Val_Loss: 0.2152  BEST VAL Loss: 0.2152  Val_Acc: 92.468

Epoch 96: Validation loss decreased (0.215182 --> 0.215170).  Saving model ...
	 Train_Loss: 0.2497 Train_Acc: 90.811 Val_Loss: 0.2152  BEST VAL Loss: 0.2152  Val_Acc: 92.317

Epoch 97: Validation loss decreased (0.215170 --> 0.214929).  Saving model ...
	 Train_Loss: 0.2494 Train_Acc: 90.706 Val_Loss: 0.2149  BEST VAL Loss: 0.2149  Val_Acc: 92.528

Epoch 98: Validation loss decreased (0.214929 --> 0.214724).  Saving model ...
	 Train_Loss: 0.2490 Train_Acc: 90.378 Val_Loss: 0.2147  BEST VAL Loss: 0.2147  Val_Acc: 92.739

Epoch 99: Validation loss did not decrease
	 Train_Loss: 0.2486 Train_Acc: 90.905 Val_Loss: 0.2148  BEST VAL Loss: 0.2147  Val_Acc: 92.859

Thapsigargin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.68      0.71      0.70     18174
           1       0.31      0.29      0.30      8369

    accuracy                           0.58     26543
   macro avg       0.50      0.50      0.50     26543
weighted avg       0.57      0.58      0.57     26543

Thapsigargin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.68      0.72      0.70      2272
           1       0.31      0.28      0.29      1047

    accuracy                           0.58      3319
   macro avg       0.50      0.50      0.49      3319
weighted avg       0.56      0.58      0.57      3319

Thapsigargin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.69      0.72      0.71      2272
           1       0.34      0.31      0.32      1047

    accuracy                           0.59      3319
   macro avg       0.52      0.51      0.51      3319
weighted avg       0.58      0.59      0.59      3319

              precision    recall  f1-score   support

           0       0.69      0.72      0.71      2272
           1       0.34      0.31      0.32      1047

    accuracy                           0.59      3319
   macro avg       0.52      0.51      0.51      3319
weighted avg       0.58      0.59      0.59      3319

Thapsigargin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.59      0.57      4182
           1       0.43      0.39      0.41      3303

    accuracy                           0.51      7485
   macro avg       0.49      0.49      0.49      7485
weighted avg       0.50      0.51      0.50      7485

              precision    recall  f1-score   support

           0       0.55      0.59      0.57      4182
           1       0.43      0.39      0.41      3303

    accuracy                           0.51      7485
   macro avg       0.49      0.49      0.49      7485
weighted avg       0.50      0.51      0.50      7485

completed
