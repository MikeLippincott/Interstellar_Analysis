[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'c965bdf3'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'a488bc42'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd53d4022'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '2a1a1cbe'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_0.010_DMSO_0.025 treatment_name: H2O2_100.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_0.010_DMSO_0.025
TREATMENT_NAME: H2O2_100.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (42759, 1276)
Number of total missing values across all columns: 85518
Data Subset Is Off
Wells held out for testing: ['B16' 'H22']
Wells to use for training, validation, and testing ['B17' 'H18' 'H19' 'B20' 'B21' 'H23' 'I18' 'I19' 'I22' 'I23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.666284).  Saving model ...
	 Train_Loss: 0.6789 Train_Acc: 65.242 Val_Loss: 0.6663  BEST VAL Loss: 0.6663  Val_Acc: 69.375

Epoch 1: Validation loss decreased (0.666284 --> 0.658922).  Saving model ...
	 Train_Loss: 0.6675 Train_Acc: 70.911 Val_Loss: 0.6589  BEST VAL Loss: 0.6589  Val_Acc: 70.735

Epoch 2: Validation loss decreased (0.658922 --> 0.651364).  Saving model ...
	 Train_Loss: 0.6579 Train_Acc: 72.483 Val_Loss: 0.6514  BEST VAL Loss: 0.6514  Val_Acc: 71.862

Epoch 3: Validation loss decreased (0.651364 --> 0.644083).  Saving model ...
	 Train_Loss: 0.6487 Train_Acc: 73.911 Val_Loss: 0.6441  BEST VAL Loss: 0.6441  Val_Acc: 72.961

Epoch 4: Validation loss decreased (0.644083 --> 0.636970).  Saving model ...
	 Train_Loss: 0.6401 Train_Acc: 74.930 Val_Loss: 0.6370  BEST VAL Loss: 0.6370  Val_Acc: 73.916

Epoch 5: Validation loss decreased (0.636970 --> 0.630375).  Saving model ...
	 Train_Loss: 0.6317 Train_Acc: 76.080 Val_Loss: 0.6304  BEST VAL Loss: 0.6304  Val_Acc: 74.639

Epoch 6: Validation loss decreased (0.630375 --> 0.624113).  Saving model ...
	 Train_Loss: 0.6237 Train_Acc: 76.662 Val_Loss: 0.6241  BEST VAL Loss: 0.6241  Val_Acc: 75.043

Epoch 7: Validation loss decreased (0.624113 --> 0.618056).  Saving model ...
	 Train_Loss: 0.6163 Train_Acc: 77.432 Val_Loss: 0.6181  BEST VAL Loss: 0.6181  Val_Acc: 75.304

Epoch 8: Validation loss decreased (0.618056 --> 0.612404).  Saving model ...
	 Train_Loss: 0.6093 Train_Acc: 77.584 Val_Loss: 0.6124  BEST VAL Loss: 0.6124  Val_Acc: 75.795

Epoch 9: Validation loss decreased (0.612404 --> 0.607236).  Saving model ...
	 Train_Loss: 0.6027 Train_Acc: 78.093 Val_Loss: 0.6072  BEST VAL Loss: 0.6072  Val_Acc: 75.882

Epoch 10: Validation loss decreased (0.607236 --> 0.602344).  Saving model ...
	 Train_Loss: 0.5965 Train_Acc: 78.148 Val_Loss: 0.6023  BEST VAL Loss: 0.6023  Val_Acc: 76.229

Epoch 11: Validation loss decreased (0.602344 --> 0.597876).  Saving model ...
	 Train_Loss: 0.5906 Train_Acc: 78.697 Val_Loss: 0.5979  BEST VAL Loss: 0.5979  Val_Acc: 76.142

Epoch 12: Validation loss decreased (0.597876 --> 0.593841).  Saving model ...
	 Train_Loss: 0.5850 Train_Acc: 78.849 Val_Loss: 0.5938  BEST VAL Loss: 0.5938  Val_Acc: 76.200

Epoch 13: Validation loss decreased (0.593841 --> 0.590281).  Saving model ...
	 Train_Loss: 0.5798 Train_Acc: 79.051 Val_Loss: 0.5903  BEST VAL Loss: 0.5903  Val_Acc: 76.229

Epoch 14: Validation loss decreased (0.590281 --> 0.586670).  Saving model ...
	 Train_Loss: 0.5747 Train_Acc: 79.333 Val_Loss: 0.5867  BEST VAL Loss: 0.5867  Val_Acc: 76.489

Epoch 15: Validation loss decreased (0.586670 --> 0.583389).  Saving model ...
	 Train_Loss: 0.5701 Train_Acc: 79.290 Val_Loss: 0.5834  BEST VAL Loss: 0.5834  Val_Acc: 76.316

Epoch 16: Validation loss decreased (0.583389 --> 0.580390).  Saving model ...
	 Train_Loss: 0.5656 Train_Acc: 79.731 Val_Loss: 0.5804  BEST VAL Loss: 0.5804  Val_Acc: 76.345

Epoch 17: Validation loss decreased (0.580390 --> 0.577703).  Saving model ...
	 Train_Loss: 0.5615 Train_Acc: 79.344 Val_Loss: 0.5777  BEST VAL Loss: 0.5777  Val_Acc: 76.316

Epoch 18: Validation loss decreased (0.577703 --> 0.575033).  Saving model ...
	 Train_Loss: 0.5575 Train_Acc: 79.952 Val_Loss: 0.5750  BEST VAL Loss: 0.5750  Val_Acc: 76.778

Epoch 19: Validation loss decreased (0.575033 --> 0.572631).  Saving model ...
	 Train_Loss: 0.5537 Train_Acc: 79.865 Val_Loss: 0.5726  BEST VAL Loss: 0.5726  Val_Acc: 76.894

Epoch 20: Validation loss decreased (0.572631 --> 0.570250).  Saving model ...
	 Train_Loss: 0.5502 Train_Acc: 79.919 Val_Loss: 0.5703  BEST VAL Loss: 0.5703  Val_Acc: 76.605

Epoch 21: Validation loss decreased (0.570250 --> 0.567907).  Saving model ...
	 Train_Loss: 0.5467 Train_Acc: 80.248 Val_Loss: 0.5679  BEST VAL Loss: 0.5679  Val_Acc: 76.721

Epoch 22: Validation loss decreased (0.567907 --> 0.565802).  Saving model ...
	 Train_Loss: 0.5435 Train_Acc: 80.288 Val_Loss: 0.5658  BEST VAL Loss: 0.5658  Val_Acc: 76.807

Epoch 23: Validation loss decreased (0.565802 --> 0.563812).  Saving model ...
	 Train_Loss: 0.5403 Train_Acc: 80.241 Val_Loss: 0.5638  BEST VAL Loss: 0.5638  Val_Acc: 76.663

Epoch 24: Validation loss decreased (0.563812 --> 0.561960).  Saving model ...
	 Train_Loss: 0.5373 Train_Acc: 80.599 Val_Loss: 0.5620  BEST VAL Loss: 0.5620  Val_Acc: 76.952

Epoch 25: Validation loss decreased (0.561960 --> 0.560258).  Saving model ...
	 Train_Loss: 0.5345 Train_Acc: 80.562 Val_Loss: 0.5603  BEST VAL Loss: 0.5603  Val_Acc: 76.865

Epoch 26: Validation loss decreased (0.560258 --> 0.558527).  Saving model ...
	 Train_Loss: 0.5318 Train_Acc: 80.512 Val_Loss: 0.5585  BEST VAL Loss: 0.5585  Val_Acc: 76.894

Epoch 27: Validation loss decreased (0.558527 --> 0.556924).  Saving model ...
	 Train_Loss: 0.5292 Train_Acc: 80.400 Val_Loss: 0.5569  BEST VAL Loss: 0.5569  Val_Acc: 77.588

Epoch 28: Validation loss decreased (0.556924 --> 0.555352).  Saving model ...
	 Train_Loss: 0.5267 Train_Acc: 80.754 Val_Loss: 0.5554  BEST VAL Loss: 0.5554  Val_Acc: 77.126

Epoch 29: Validation loss decreased (0.555352 --> 0.553809).  Saving model ...
	 Train_Loss: 0.5243 Train_Acc: 80.902 Val_Loss: 0.5538  BEST VAL Loss: 0.5538  Val_Acc: 77.357

Epoch 30: Validation loss decreased (0.553809 --> 0.552303).  Saving model ...
	 Train_Loss: 0.5220 Train_Acc: 80.855 Val_Loss: 0.5523  BEST VAL Loss: 0.5523  Val_Acc: 77.241

Epoch 31: Validation loss decreased (0.552303 --> 0.551003).  Saving model ...
	 Train_Loss: 0.5198 Train_Acc: 80.971 Val_Loss: 0.5510  BEST VAL Loss: 0.5510  Val_Acc: 77.270

Epoch 32: Validation loss decreased (0.551003 --> 0.549730).  Saving model ...
	 Train_Loss: 0.5177 Train_Acc: 80.750 Val_Loss: 0.5497  BEST VAL Loss: 0.5497  Val_Acc: 77.241

Epoch 33: Validation loss decreased (0.549730 --> 0.548443).  Saving model ...
	 Train_Loss: 0.5157 Train_Acc: 80.805 Val_Loss: 0.5484  BEST VAL Loss: 0.5484  Val_Acc: 77.154

Epoch 34: Validation loss decreased (0.548443 --> 0.547203).  Saving model ...
	 Train_Loss: 0.5138 Train_Acc: 81.011 Val_Loss: 0.5472  BEST VAL Loss: 0.5472  Val_Acc: 77.328

Epoch 35: Validation loss decreased (0.547203 --> 0.545938).  Saving model ...
	 Train_Loss: 0.5119 Train_Acc: 80.906 Val_Loss: 0.5459  BEST VAL Loss: 0.5459  Val_Acc: 77.415

Epoch 36: Validation loss decreased (0.545938 --> 0.544733).  Saving model ...
	 Train_Loss: 0.5101 Train_Acc: 81.094 Val_Loss: 0.5447  BEST VAL Loss: 0.5447  Val_Acc: 77.357

Epoch 37: Validation loss decreased (0.544733 --> 0.543637).  Saving model ...
	 Train_Loss: 0.5085 Train_Acc: 81.083 Val_Loss: 0.5436  BEST VAL Loss: 0.5436  Val_Acc: 77.588

Epoch 38: Validation loss decreased (0.543637 --> 0.542617).  Saving model ...
	 Train_Loss: 0.5068 Train_Acc: 81.213 Val_Loss: 0.5426  BEST VAL Loss: 0.5426  Val_Acc: 77.386

Epoch 39: Validation loss decreased (0.542617 --> 0.541546).  Saving model ...
	 Train_Loss: 0.5052 Train_Acc: 81.032 Val_Loss: 0.5415  BEST VAL Loss: 0.5415  Val_Acc: 77.704

Epoch 40: Validation loss decreased (0.541546 --> 0.540481).  Saving model ...
	 Train_Loss: 0.5037 Train_Acc: 81.202 Val_Loss: 0.5405  BEST VAL Loss: 0.5405  Val_Acc: 77.617

Epoch 41: Validation loss decreased (0.540481 --> 0.539465).  Saving model ...
	 Train_Loss: 0.5021 Train_Acc: 81.372 Val_Loss: 0.5395  BEST VAL Loss: 0.5395  Val_Acc: 77.848

Epoch 42: Validation loss decreased (0.539465 --> 0.538562).  Saving model ...
	 Train_Loss: 0.5007 Train_Acc: 81.314 Val_Loss: 0.5386  BEST VAL Loss: 0.5386  Val_Acc: 78.051

Epoch 43: Validation loss decreased (0.538562 --> 0.537758).  Saving model ...
	 Train_Loss: 0.4993 Train_Acc: 81.238 Val_Loss: 0.5378  BEST VAL Loss: 0.5378  Val_Acc: 77.530

Epoch 44: Validation loss decreased (0.537758 --> 0.536912).  Saving model ...
	 Train_Loss: 0.4980 Train_Acc: 81.228 Val_Loss: 0.5369  BEST VAL Loss: 0.5369  Val_Acc: 77.473

Epoch 45: Validation loss decreased (0.536912 --> 0.536085).  Saving model ...
	 Train_Loss: 0.4967 Train_Acc: 81.307 Val_Loss: 0.5361  BEST VAL Loss: 0.5361  Val_Acc: 77.473

Epoch 46: Validation loss decreased (0.536085 --> 0.535312).  Saving model ...
	 Train_Loss: 0.4954 Train_Acc: 81.470 Val_Loss: 0.5353  BEST VAL Loss: 0.5353  Val_Acc: 77.877

Epoch 47: Validation loss decreased (0.535312 --> 0.534587).  Saving model ...
	 Train_Loss: 0.4942 Train_Acc: 81.372 Val_Loss: 0.5346  BEST VAL Loss: 0.5346  Val_Acc: 77.733

Epoch 48: Validation loss decreased (0.534587 --> 0.533818).  Saving model ...
	 Train_Loss: 0.4930 Train_Acc: 81.358 Val_Loss: 0.5338  BEST VAL Loss: 0.5338  Val_Acc: 77.791

Epoch 49: Validation loss decreased (0.533818 --> 0.533079).  Saving model ...
	 Train_Loss: 0.4919 Train_Acc: 81.365 Val_Loss: 0.5331  BEST VAL Loss: 0.5331  Val_Acc: 77.675

Epoch 50: Validation loss decreased (0.533079 --> 0.532324).  Saving model ...
	 Train_Loss: 0.4907 Train_Acc: 81.499 Val_Loss: 0.5323  BEST VAL Loss: 0.5323  Val_Acc: 77.791

Epoch 51: Validation loss decreased (0.532324 --> 0.531622).  Saving model ...
	 Train_Loss: 0.4896 Train_Acc: 81.470 Val_Loss: 0.5316  BEST VAL Loss: 0.5316  Val_Acc: 77.473

Epoch 52: Validation loss decreased (0.531622 --> 0.531002).  Saving model ...
	 Train_Loss: 0.4886 Train_Acc: 81.640 Val_Loss: 0.5310  BEST VAL Loss: 0.5310  Val_Acc: 77.877

Epoch 53: Validation loss decreased (0.531002 --> 0.530345).  Saving model ...
	 Train_Loss: 0.4875 Train_Acc: 81.607 Val_Loss: 0.5303  BEST VAL Loss: 0.5303  Val_Acc: 78.109

Epoch 54: Validation loss decreased (0.530345 --> 0.529781).  Saving model ...
	 Train_Loss: 0.4865 Train_Acc: 81.748 Val_Loss: 0.5298  BEST VAL Loss: 0.5298  Val_Acc: 77.704

Epoch 55: Validation loss decreased (0.529781 --> 0.529187).  Saving model ...
	 Train_Loss: 0.4854 Train_Acc: 81.907 Val_Loss: 0.5292  BEST VAL Loss: 0.5292  Val_Acc: 78.167

Epoch 56: Validation loss decreased (0.529187 --> 0.528579).  Saving model ...
	 Train_Loss: 0.4845 Train_Acc: 81.708 Val_Loss: 0.5286  BEST VAL Loss: 0.5286  Val_Acc: 77.820

Epoch 57: Validation loss decreased (0.528579 --> 0.528053).  Saving model ...
	 Train_Loss: 0.4836 Train_Acc: 81.495 Val_Loss: 0.5281  BEST VAL Loss: 0.5281  Val_Acc: 78.109

Epoch 58: Validation loss decreased (0.528053 --> 0.527542).  Saving model ...
	 Train_Loss: 0.4826 Train_Acc: 81.755 Val_Loss: 0.5275  BEST VAL Loss: 0.5275  Val_Acc: 78.224

Epoch 59: Validation loss decreased (0.527542 --> 0.527020).  Saving model ...
	 Train_Loss: 0.4818 Train_Acc: 81.658 Val_Loss: 0.5270  BEST VAL Loss: 0.5270  Val_Acc: 78.282

Epoch 60: Validation loss decreased (0.527020 --> 0.526535).  Saving model ...
	 Train_Loss: 0.4809 Train_Acc: 81.864 Val_Loss: 0.5265  BEST VAL Loss: 0.5265  Val_Acc: 77.762

Epoch 61: Validation loss decreased (0.526535 --> 0.526113).  Saving model ...
	 Train_Loss: 0.4801 Train_Acc: 81.636 Val_Loss: 0.5261  BEST VAL Loss: 0.5261  Val_Acc: 78.253

Epoch 62: Validation loss decreased (0.526113 --> 0.525640).  Saving model ...
	 Train_Loss: 0.4792 Train_Acc: 81.752 Val_Loss: 0.5256  BEST VAL Loss: 0.5256  Val_Acc: 78.369

Epoch 63: Validation loss decreased (0.525640 --> 0.525167).  Saving model ...
	 Train_Loss: 0.4784 Train_Acc: 81.925 Val_Loss: 0.5252  BEST VAL Loss: 0.5252  Val_Acc: 77.473

Epoch 64: Validation loss decreased (0.525167 --> 0.524810).  Saving model ...
	 Train_Loss: 0.4776 Train_Acc: 81.889 Val_Loss: 0.5248  BEST VAL Loss: 0.5248  Val_Acc: 77.964

Epoch 65: Validation loss decreased (0.524810 --> 0.524393).  Saving model ...
	 Train_Loss: 0.4769 Train_Acc: 81.625 Val_Loss: 0.5244  BEST VAL Loss: 0.5244  Val_Acc: 78.138

Epoch 66: Validation loss decreased (0.524393 --> 0.524030).  Saving model ...
	 Train_Loss: 0.4761 Train_Acc: 81.817 Val_Loss: 0.5240  BEST VAL Loss: 0.5240  Val_Acc: 78.080

Epoch 67: Validation loss decreased (0.524030 --> 0.523660).  Saving model ...
	 Train_Loss: 0.4754 Train_Acc: 81.763 Val_Loss: 0.5237  BEST VAL Loss: 0.5237  Val_Acc: 77.704

Epoch 68: Validation loss decreased (0.523660 --> 0.523325).  Saving model ...
	 Train_Loss: 0.4747 Train_Acc: 81.683 Val_Loss: 0.5233  BEST VAL Loss: 0.5233  Val_Acc: 77.791

Epoch 69: Validation loss decreased (0.523325 --> 0.522923).  Saving model ...
	 Train_Loss: 0.4740 Train_Acc: 81.669 Val_Loss: 0.5229  BEST VAL Loss: 0.5229  Val_Acc: 78.195

Epoch 70: Validation loss decreased (0.522923 --> 0.522596).  Saving model ...
	 Train_Loss: 0.4733 Train_Acc: 81.810 Val_Loss: 0.5226  BEST VAL Loss: 0.5226  Val_Acc: 77.935

Epoch 71: Validation loss decreased (0.522596 --> 0.522190).  Saving model ...
	 Train_Loss: 0.4726 Train_Acc: 81.636 Val_Loss: 0.5222  BEST VAL Loss: 0.5222  Val_Acc: 78.253

Epoch 72: Validation loss decreased (0.522190 --> 0.521838).  Saving model ...
	 Train_Loss: 0.4719 Train_Acc: 81.918 Val_Loss: 0.5218  BEST VAL Loss: 0.5218  Val_Acc: 78.195

Epoch 73: Validation loss decreased (0.521838 --> 0.521486).  Saving model ...
	 Train_Loss: 0.4712 Train_Acc: 82.045 Val_Loss: 0.5215  BEST VAL Loss: 0.5215  Val_Acc: 78.195

Epoch 74: Validation loss decreased (0.521486 --> 0.521186).  Saving model ...
	 Train_Loss: 0.4706 Train_Acc: 81.929 Val_Loss: 0.5212  BEST VAL Loss: 0.5212  Val_Acc: 78.022

Epoch 75: Validation loss decreased (0.521186 --> 0.520852).  Saving model ...
	 Train_Loss: 0.4700 Train_Acc: 81.907 Val_Loss: 0.5209  BEST VAL Loss: 0.5209  Val_Acc: 78.282

Epoch 76: Validation loss decreased (0.520852 --> 0.520535).  Saving model ...
	 Train_Loss: 0.4694 Train_Acc: 81.980 Val_Loss: 0.5205  BEST VAL Loss: 0.5205  Val_Acc: 78.051

Epoch 77: Validation loss decreased (0.520535 --> 0.520179).  Saving model ...
	 Train_Loss: 0.4688 Train_Acc: 82.088 Val_Loss: 0.5202  BEST VAL Loss: 0.5202  Val_Acc: 78.051

Epoch 78: Validation loss decreased (0.520179 --> 0.519816).  Saving model ...
	 Train_Loss: 0.4682 Train_Acc: 81.961 Val_Loss: 0.5198  BEST VAL Loss: 0.5198  Val_Acc: 78.080

Epoch 79: Validation loss decreased (0.519816 --> 0.519465).  Saving model ...
	 Train_Loss: 0.4676 Train_Acc: 81.878 Val_Loss: 0.5195  BEST VAL Loss: 0.5195  Val_Acc: 78.253

Epoch 80: Validation loss decreased (0.519465 --> 0.519170).  Saving model ...
	 Train_Loss: 0.4670 Train_Acc: 81.983 Val_Loss: 0.5192  BEST VAL Loss: 0.5192  Val_Acc: 77.675

Epoch 81: Validation loss decreased (0.519170 --> 0.518892).  Saving model ...
	 Train_Loss: 0.4665 Train_Acc: 82.305 Val_Loss: 0.5189  BEST VAL Loss: 0.5189  Val_Acc: 77.820

Epoch 82: Validation loss decreased (0.518892 --> 0.518579).  Saving model ...
	 Train_Loss: 0.4659 Train_Acc: 82.222 Val_Loss: 0.5186  BEST VAL Loss: 0.5186  Val_Acc: 78.195

Epoch 83: Validation loss decreased (0.518579 --> 0.518283).  Saving model ...
	 Train_Loss: 0.4654 Train_Acc: 82.052 Val_Loss: 0.5183  BEST VAL Loss: 0.5183  Val_Acc: 78.311

Epoch 84: Validation loss decreased (0.518283 --> 0.517984).  Saving model ...
	 Train_Loss: 0.4648 Train_Acc: 82.222 Val_Loss: 0.5180  BEST VAL Loss: 0.5180  Val_Acc: 77.993

Epoch 85: Validation loss decreased (0.517984 --> 0.517686).  Saving model ...
	 Train_Loss: 0.4643 Train_Acc: 82.052 Val_Loss: 0.5177  BEST VAL Loss: 0.5177  Val_Acc: 77.935

Epoch 86: Validation loss decreased (0.517686 --> 0.517441).  Saving model ...
	 Train_Loss: 0.4638 Train_Acc: 81.893 Val_Loss: 0.5174  BEST VAL Loss: 0.5174  Val_Acc: 77.617

Epoch 87: Validation loss decreased (0.517441 --> 0.517196).  Saving model ...
	 Train_Loss: 0.4633 Train_Acc: 82.005 Val_Loss: 0.5172  BEST VAL Loss: 0.5172  Val_Acc: 78.051

Epoch 88: Validation loss decreased (0.517196 --> 0.516967).  Saving model ...
	 Train_Loss: 0.4629 Train_Acc: 82.077 Val_Loss: 0.5170  BEST VAL Loss: 0.5170  Val_Acc: 77.906

Epoch 89: Validation loss decreased (0.516967 --> 0.516722).  Saving model ...
	 Train_Loss: 0.4624 Train_Acc: 82.074 Val_Loss: 0.5167  BEST VAL Loss: 0.5167  Val_Acc: 78.051

Epoch 90: Validation loss decreased (0.516722 --> 0.516493).  Saving model ...
	 Train_Loss: 0.4619 Train_Acc: 82.070 Val_Loss: 0.5165  BEST VAL Loss: 0.5165  Val_Acc: 78.022

Epoch 91: Validation loss decreased (0.516493 --> 0.516256).  Saving model ...
	 Train_Loss: 0.4615 Train_Acc: 82.008 Val_Loss: 0.5163  BEST VAL Loss: 0.5163  Val_Acc: 77.935

Epoch 92: Validation loss decreased (0.516256 --> 0.516010).  Saving model ...
	 Train_Loss: 0.4610 Train_Acc: 82.124 Val_Loss: 0.5160  BEST VAL Loss: 0.5160  Val_Acc: 78.311

Epoch 93: Validation loss decreased (0.516010 --> 0.515783).  Saving model ...
	 Train_Loss: 0.4606 Train_Acc: 81.878 Val_Loss: 0.5158  BEST VAL Loss: 0.5158  Val_Acc: 77.877

Epoch 94: Validation loss decreased (0.515783 --> 0.515566).  Saving model ...
	 Train_Loss: 0.4602 Train_Acc: 82.070 Val_Loss: 0.5156  BEST VAL Loss: 0.5156  Val_Acc: 78.051

Epoch 95: Validation loss decreased (0.515566 --> 0.515317).  Saving model ...
	 Train_Loss: 0.4598 Train_Acc: 82.016 Val_Loss: 0.5153  BEST VAL Loss: 0.5153  Val_Acc: 78.253

Epoch 96: Validation loss decreased (0.515317 --> 0.515094).  Saving model ...
	 Train_Loss: 0.4593 Train_Acc: 81.954 Val_Loss: 0.5151  BEST VAL Loss: 0.5151  Val_Acc: 78.224

Epoch 97: Validation loss decreased (0.515094 --> 0.514877).  Saving model ...
	 Train_Loss: 0.4590 Train_Acc: 81.961 Val_Loss: 0.5149  BEST VAL Loss: 0.5149  Val_Acc: 78.253

Epoch 98: Validation loss decreased (0.514877 --> 0.514647).  Saving model ...
	 Train_Loss: 0.4585 Train_Acc: 82.446 Val_Loss: 0.5146  BEST VAL Loss: 0.5146  Val_Acc: 78.571

Epoch 99: Validation loss decreased (0.514647 --> 0.514422).  Saving model ...
	 Train_Loss: 0.4582 Train_Acc: 82.045 Val_Loss: 0.5144  BEST VAL Loss: 0.5144  Val_Acc: 78.514

LPS_0.010_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.84      0.92      0.88     18174
           1       0.82      0.67      0.74      9489

    accuracy                           0.84     27663
   macro avg       0.83      0.80      0.81     27663
weighted avg       0.84      0.84      0.83     27663

LPS_0.010_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.81      0.89      0.84      2272
           1       0.73      0.59      0.65      1186

    accuracy                           0.79      3458
   macro avg       0.77      0.74      0.75      3458
weighted avg       0.78      0.79      0.78      3458

LPS_0.010_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.81      0.89      0.85      2272
           1       0.75      0.60      0.66      1187

    accuracy                           0.79      3459
   macro avg       0.78      0.75      0.76      3459
weighted avg       0.79      0.79      0.79      3459

              precision    recall  f1-score   support

           0       0.81      0.89      0.85      2272
           1       0.75      0.60      0.66      1187

    accuracy                           0.79      3459
   macro avg       0.78      0.75      0.76      3459
weighted avg       0.79      0.79      0.79      3459

LPS_0.010_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.68      0.76      0.71      4182
           1       0.71      0.62      0.66      3997

    accuracy                           0.69      8179
   macro avg       0.69      0.69      0.69      8179
weighted avg       0.69      0.69      0.69      8179

              precision    recall  f1-score   support

           0       0.68      0.76      0.71      4182
           1       0.71      0.62      0.66      3997

    accuracy                           0.69      8179
   macro avg       0.69      0.69      0.69      8179
weighted avg       0.69      0.69      0.69      8179

completed
