[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '18b1b1de'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'd554c603'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '94f88b78'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '5e2ab363'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_0.100_DMSO_0.025 treatment_name: Thapsigargin_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: Thapsigargin_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (28694, 1276)
Number of total missing values across all columns: 57388
Data Subset Is Off
Wells held out for testing: ['D14' 'L22']
Wells to use for training, validation, and testing ['D15' 'K14' 'K15' 'L18' 'L19' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.470931).  Saving model ...
	 Train_Loss: 0.5762 Train_Acc: 64.691 Val_Loss: 0.4709  BEST VAL Loss: 0.4709  Val_Acc: 77.093

Epoch 1: Validation loss decreased (0.470931 --> 0.445828).  Saving model ...
	 Train_Loss: 0.5297 Train_Acc: 70.142 Val_Loss: 0.4458  BEST VAL Loss: 0.4458  Val_Acc: 79.304

Epoch 2: Validation loss decreased (0.445828 --> 0.425930).  Saving model ...
	 Train_Loss: 0.5052 Train_Acc: 71.571 Val_Loss: 0.4259  BEST VAL Loss: 0.4259  Val_Acc: 82.738

Epoch 3: Validation loss decreased (0.425930 --> 0.409337).  Saving model ...
	 Train_Loss: 0.4896 Train_Acc: 73.594 Val_Loss: 0.4093  BEST VAL Loss: 0.4093  Val_Acc: 85.419

Epoch 4: Validation loss decreased (0.409337 --> 0.395896).  Saving model ...
	 Train_Loss: 0.4746 Train_Acc: 75.347 Val_Loss: 0.3959  BEST VAL Loss: 0.3959  Val_Acc: 85.560

Epoch 5: Validation loss decreased (0.395896 --> 0.385119).  Saving model ...
	 Train_Loss: 0.4612 Train_Acc: 75.635 Val_Loss: 0.3851  BEST VAL Loss: 0.3851  Val_Acc: 86.171

Epoch 6: Validation loss decreased (0.385119 --> 0.376829).  Saving model ...
	 Train_Loss: 0.4514 Train_Acc: 76.482 Val_Loss: 0.3768  BEST VAL Loss: 0.3768  Val_Acc: 86.406

Epoch 7: Validation loss decreased (0.376829 --> 0.373761).  Saving model ...
	 Train_Loss: 0.4485 Train_Acc: 73.618 Val_Loss: 0.3738  BEST VAL Loss: 0.3738  Val_Acc: 84.760

Epoch 8: Validation loss decreased (0.373761 --> 0.368184).  Saving model ...
	 Train_Loss: 0.4441 Train_Acc: 75.482 Val_Loss: 0.3682  BEST VAL Loss: 0.3682  Val_Acc: 86.830

Epoch 9: Validation loss decreased (0.368184 --> 0.364518).  Saving model ...
	 Train_Loss: 0.4383 Train_Acc: 75.923 Val_Loss: 0.3645  BEST VAL Loss: 0.3645  Val_Acc: 86.830

Epoch 10: Validation loss decreased (0.364518 --> 0.360438).  Saving model ...
	 Train_Loss: 0.4337 Train_Acc: 76.588 Val_Loss: 0.3604  BEST VAL Loss: 0.3604  Val_Acc: 86.971

Epoch 11: Validation loss decreased (0.360438 --> 0.355356).  Saving model ...
	 Train_Loss: 0.4281 Train_Acc: 77.311 Val_Loss: 0.3554  BEST VAL Loss: 0.3554  Val_Acc: 87.817

Epoch 12: Validation loss decreased (0.355356 --> 0.351167).  Saving model ...
	 Train_Loss: 0.4254 Train_Acc: 77.546 Val_Loss: 0.3512  BEST VAL Loss: 0.3512  Val_Acc: 87.770

Epoch 13: Validation loss decreased (0.351167 --> 0.346804).  Saving model ...
	 Train_Loss: 0.4210 Train_Acc: 77.688 Val_Loss: 0.3468  BEST VAL Loss: 0.3468  Val_Acc: 87.206

Epoch 14: Validation loss decreased (0.346804 --> 0.342781).  Saving model ...
	 Train_Loss: 0.4185 Train_Acc: 77.735 Val_Loss: 0.3428  BEST VAL Loss: 0.3428  Val_Acc: 87.865

Epoch 15: Validation loss decreased (0.342781 --> 0.340876).  Saving model ...
	 Train_Loss: 0.4173 Train_Acc: 75.665 Val_Loss: 0.3409  BEST VAL Loss: 0.3409  Val_Acc: 86.030

Epoch 16: Validation loss decreased (0.340876 --> 0.338658).  Saving model ...
	 Train_Loss: 0.4152 Train_Acc: 76.664 Val_Loss: 0.3387  BEST VAL Loss: 0.3387  Val_Acc: 87.347

Epoch 17: Validation loss decreased (0.338658 --> 0.335549).  Saving model ...
	 Train_Loss: 0.4129 Train_Acc: 76.641 Val_Loss: 0.3355  BEST VAL Loss: 0.3355  Val_Acc: 88.006

Epoch 18: Validation loss decreased (0.335549 --> 0.333496).  Saving model ...
	 Train_Loss: 0.4104 Train_Acc: 77.693 Val_Loss: 0.3335  BEST VAL Loss: 0.3335  Val_Acc: 87.535

Epoch 19: Validation loss decreased (0.333496 --> 0.331014).  Saving model ...
	 Train_Loss: 0.4079 Train_Acc: 77.699 Val_Loss: 0.3310  BEST VAL Loss: 0.3310  Val_Acc: 87.912

Epoch 20: Validation loss decreased (0.331014 --> 0.328430).  Saving model ...
	 Train_Loss: 0.4049 Train_Acc: 78.687 Val_Loss: 0.3284  BEST VAL Loss: 0.3284  Val_Acc: 88.100

Epoch 21: Validation loss decreased (0.328430 --> 0.325636).  Saving model ...
	 Train_Loss: 0.4022 Train_Acc: 78.858 Val_Loss: 0.3256  BEST VAL Loss: 0.3256  Val_Acc: 89.182

Epoch 22: Validation loss decreased (0.325636 --> 0.323197).  Saving model ...
	 Train_Loss: 0.3996 Train_Acc: 78.676 Val_Loss: 0.3232  BEST VAL Loss: 0.3232  Val_Acc: 89.040

Epoch 23: Validation loss decreased (0.323197 --> 0.320650).  Saving model ...
	 Train_Loss: 0.3982 Train_Acc: 78.976 Val_Loss: 0.3207  BEST VAL Loss: 0.3207  Val_Acc: 88.946

Epoch 24: Validation loss decreased (0.320650 --> 0.318376).  Saving model ...
	 Train_Loss: 0.3968 Train_Acc: 79.070 Val_Loss: 0.3184  BEST VAL Loss: 0.3184  Val_Acc: 89.229

Epoch 25: Validation loss decreased (0.318376 --> 0.316297).  Saving model ...
	 Train_Loss: 0.3945 Train_Acc: 78.899 Val_Loss: 0.3163  BEST VAL Loss: 0.3163  Val_Acc: 88.852

Epoch 26: Validation loss decreased (0.316297 --> 0.314242).  Saving model ...
	 Train_Loss: 0.3928 Train_Acc: 79.070 Val_Loss: 0.3142  BEST VAL Loss: 0.3142  Val_Acc: 89.323

Epoch 27: Validation loss decreased (0.314242 --> 0.312814).  Saving model ...
	 Train_Loss: 0.3910 Train_Acc: 78.958 Val_Loss: 0.3128  BEST VAL Loss: 0.3128  Val_Acc: 88.899

Epoch 28: Validation loss decreased (0.312814 --> 0.311252).  Saving model ...
	 Train_Loss: 0.3887 Train_Acc: 79.775 Val_Loss: 0.3113  BEST VAL Loss: 0.3113  Val_Acc: 89.323

Epoch 29: Validation loss decreased (0.311252 --> 0.309837).  Saving model ...
	 Train_Loss: 0.3870 Train_Acc: 79.293 Val_Loss: 0.3098  BEST VAL Loss: 0.3098  Val_Acc: 89.040

Epoch 30: Validation loss decreased (0.309837 --> 0.308264).  Saving model ...
	 Train_Loss: 0.3855 Train_Acc: 79.246 Val_Loss: 0.3083  BEST VAL Loss: 0.3083  Val_Acc: 89.605

Epoch 31: Validation loss decreased (0.308264 --> 0.306490).  Saving model ...
	 Train_Loss: 0.3842 Train_Acc: 79.399 Val_Loss: 0.3065  BEST VAL Loss: 0.3065  Val_Acc: 89.934

Epoch 32: Validation loss decreased (0.306490 --> 0.304895).  Saving model ...
	 Train_Loss: 0.3828 Train_Acc: 79.223 Val_Loss: 0.3049  BEST VAL Loss: 0.3049  Val_Acc: 89.558

Epoch 33: Validation loss decreased (0.304895 --> 0.303431).  Saving model ...
	 Train_Loss: 0.3810 Train_Acc: 79.869 Val_Loss: 0.3034  BEST VAL Loss: 0.3034  Val_Acc: 89.558

Epoch 34: Validation loss decreased (0.303431 --> 0.302285).  Saving model ...
	 Train_Loss: 0.3798 Train_Acc: 79.646 Val_Loss: 0.3023  BEST VAL Loss: 0.3023  Val_Acc: 89.464

Epoch 35: Validation loss decreased (0.302285 --> 0.301350).  Saving model ...
	 Train_Loss: 0.3787 Train_Acc: 79.493 Val_Loss: 0.3014  BEST VAL Loss: 0.3014  Val_Acc: 89.746

Epoch 36: Validation loss decreased (0.301350 --> 0.300044).  Saving model ...
	 Train_Loss: 0.3773 Train_Acc: 79.323 Val_Loss: 0.3000  BEST VAL Loss: 0.3000  Val_Acc: 89.464

Epoch 37: Validation loss decreased (0.300044 --> 0.298979).  Saving model ...
	 Train_Loss: 0.3764 Train_Acc: 79.364 Val_Loss: 0.2990  BEST VAL Loss: 0.2990  Val_Acc: 89.652

Epoch 38: Validation loss decreased (0.298979 --> 0.297756).  Saving model ...
	 Train_Loss: 0.3752 Train_Acc: 79.581 Val_Loss: 0.2978  BEST VAL Loss: 0.2978  Val_Acc: 89.182

Epoch 39: Validation loss decreased (0.297756 --> 0.296777).  Saving model ...
	 Train_Loss: 0.3744 Train_Acc: 79.775 Val_Loss: 0.2968  BEST VAL Loss: 0.2968  Val_Acc: 89.370

Epoch 40: Validation loss decreased (0.296777 --> 0.295813).  Saving model ...
	 Train_Loss: 0.3731 Train_Acc: 79.387 Val_Loss: 0.2958  BEST VAL Loss: 0.2958  Val_Acc: 89.229

Epoch 41: Validation loss decreased (0.295813 --> 0.294945).  Saving model ...
	 Train_Loss: 0.3719 Train_Acc: 79.305 Val_Loss: 0.2949  BEST VAL Loss: 0.2949  Val_Acc: 89.511

Epoch 42: Validation loss decreased (0.294945 --> 0.294032).  Saving model ...
	 Train_Loss: 0.3708 Train_Acc: 79.817 Val_Loss: 0.2940  BEST VAL Loss: 0.2940  Val_Acc: 89.087

Epoch 43: Validation loss decreased (0.294032 --> 0.293055).  Saving model ...
	 Train_Loss: 0.3696 Train_Acc: 79.505 Val_Loss: 0.2931  BEST VAL Loss: 0.2931  Val_Acc: 89.464

Epoch 44: Validation loss decreased (0.293055 --> 0.292740).  Saving model ...
	 Train_Loss: 0.3685 Train_Acc: 79.811 Val_Loss: 0.2927  BEST VAL Loss: 0.2927  Val_Acc: 89.182

Epoch 45: Validation loss decreased (0.292740 --> 0.292103).  Saving model ...
	 Train_Loss: 0.3675 Train_Acc: 79.381 Val_Loss: 0.2921  BEST VAL Loss: 0.2921  Val_Acc: 88.570

Epoch 46: Validation loss decreased (0.292103 --> 0.291595).  Saving model ...
	 Train_Loss: 0.3666 Train_Acc: 79.558 Val_Loss: 0.2916  BEST VAL Loss: 0.2916  Val_Acc: 89.229

Epoch 47: Validation loss decreased (0.291595 --> 0.290813).  Saving model ...
	 Train_Loss: 0.3662 Train_Acc: 79.575 Val_Loss: 0.2908  BEST VAL Loss: 0.2908  Val_Acc: 89.229

Epoch 48: Validation loss decreased (0.290813 --> 0.290102).  Saving model ...
	 Train_Loss: 0.3656 Train_Acc: 79.805 Val_Loss: 0.2901  BEST VAL Loss: 0.2901  Val_Acc: 89.135

Epoch 49: Validation loss decreased (0.290102 --> 0.289448).  Saving model ...
	 Train_Loss: 0.3647 Train_Acc: 80.281 Val_Loss: 0.2894  BEST VAL Loss: 0.2894  Val_Acc: 89.511

Epoch 50: Validation loss decreased (0.289448 --> 0.289129).  Saving model ...
	 Train_Loss: 0.3638 Train_Acc: 80.246 Val_Loss: 0.2891  BEST VAL Loss: 0.2891  Val_Acc: 89.887

Epoch 51: Validation loss decreased (0.289129 --> 0.288607).  Saving model ...
	 Train_Loss: 0.3628 Train_Acc: 79.934 Val_Loss: 0.2886  BEST VAL Loss: 0.2886  Val_Acc: 88.147

Epoch 52: Validation loss decreased (0.288607 --> 0.288151).  Saving model ...
	 Train_Loss: 0.3621 Train_Acc: 79.911 Val_Loss: 0.2882  BEST VAL Loss: 0.2882  Val_Acc: 89.276

Epoch 53: Validation loss decreased (0.288151 --> 0.287584).  Saving model ...
	 Train_Loss: 0.3618 Train_Acc: 79.487 Val_Loss: 0.2876  BEST VAL Loss: 0.2876  Val_Acc: 89.276

Epoch 54: Validation loss decreased (0.287584 --> 0.286912).  Saving model ...
	 Train_Loss: 0.3608 Train_Acc: 79.822 Val_Loss: 0.2869  BEST VAL Loss: 0.2869  Val_Acc: 89.417

Epoch 55: Validation loss decreased (0.286912 --> 0.286268).  Saving model ...
	 Train_Loss: 0.3602 Train_Acc: 80.193 Val_Loss: 0.2863  BEST VAL Loss: 0.2863  Val_Acc: 89.793

Epoch 56: Validation loss decreased (0.286268 --> 0.285811).  Saving model ...
	 Train_Loss: 0.3592 Train_Acc: 80.246 Val_Loss: 0.2858  BEST VAL Loss: 0.2858  Val_Acc: 90.075

Epoch 57: Validation loss decreased (0.285811 --> 0.285207).  Saving model ...
	 Train_Loss: 0.3586 Train_Acc: 80.546 Val_Loss: 0.2852  BEST VAL Loss: 0.2852  Val_Acc: 90.216

Epoch 58: Validation loss decreased (0.285207 --> 0.284713).  Saving model ...
	 Train_Loss: 0.3578 Train_Acc: 80.293 Val_Loss: 0.2847  BEST VAL Loss: 0.2847  Val_Acc: 89.464

Epoch 59: Validation loss decreased (0.284713 --> 0.284271).  Saving model ...
	 Train_Loss: 0.3570 Train_Acc: 79.793 Val_Loss: 0.2843  BEST VAL Loss: 0.2843  Val_Acc: 89.793

Epoch 60: Validation loss decreased (0.284271 --> 0.283780).  Saving model ...
	 Train_Loss: 0.3564 Train_Acc: 80.140 Val_Loss: 0.2838  BEST VAL Loss: 0.2838  Val_Acc: 89.464

Epoch 61: Validation loss decreased (0.283780 --> 0.283319).  Saving model ...
	 Train_Loss: 0.3557 Train_Acc: 80.240 Val_Loss: 0.2833  BEST VAL Loss: 0.2833  Val_Acc: 89.417

Epoch 62: Validation loss decreased (0.283319 --> 0.282819).  Saving model ...
	 Train_Loss: 0.3550 Train_Acc: 80.622 Val_Loss: 0.2828  BEST VAL Loss: 0.2828  Val_Acc: 89.417

Epoch 63: Validation loss decreased (0.282819 --> 0.282333).  Saving model ...
	 Train_Loss: 0.3545 Train_Acc: 80.169 Val_Loss: 0.2823  BEST VAL Loss: 0.2823  Val_Acc: 88.993

Epoch 64: Validation loss decreased (0.282333 --> 0.281702).  Saving model ...
	 Train_Loss: 0.3538 Train_Acc: 80.234 Val_Loss: 0.2817  BEST VAL Loss: 0.2817  Val_Acc: 88.946

Epoch 65: Validation loss decreased (0.281702 --> 0.281412).  Saving model ...
	 Train_Loss: 0.3532 Train_Acc: 79.958 Val_Loss: 0.2814  BEST VAL Loss: 0.2814  Val_Acc: 88.946

Epoch 66: Validation loss decreased (0.281412 --> 0.280941).  Saving model ...
	 Train_Loss: 0.3527 Train_Acc: 79.664 Val_Loss: 0.2809  BEST VAL Loss: 0.2809  Val_Acc: 89.558

Epoch 67: Validation loss decreased (0.280941 --> 0.280665).  Saving model ...
	 Train_Loss: 0.3522 Train_Acc: 80.558 Val_Loss: 0.2807  BEST VAL Loss: 0.2807  Val_Acc: 89.182

Epoch 68: Validation loss decreased (0.280665 --> 0.280296).  Saving model ...
	 Train_Loss: 0.3516 Train_Acc: 80.216 Val_Loss: 0.2803  BEST VAL Loss: 0.2803  Val_Acc: 88.993

Epoch 69: Validation loss decreased (0.280296 --> 0.279917).  Saving model ...
	 Train_Loss: 0.3510 Train_Acc: 80.393 Val_Loss: 0.2799  BEST VAL Loss: 0.2799  Val_Acc: 90.546

Epoch 70: Validation loss decreased (0.279917 --> 0.279594).  Saving model ...
	 Train_Loss: 0.3505 Train_Acc: 80.175 Val_Loss: 0.2796  BEST VAL Loss: 0.2796  Val_Acc: 89.934

Epoch 71: Validation loss decreased (0.279594 --> 0.279586).  Saving model ...
	 Train_Loss: 0.3500 Train_Acc: 80.052 Val_Loss: 0.2796  BEST VAL Loss: 0.2796  Val_Acc: 90.122

Epoch 72: Validation loss decreased (0.279586 --> 0.279566).  Saving model ...
	 Train_Loss: 0.3495 Train_Acc: 80.105 Val_Loss: 0.2796  BEST VAL Loss: 0.2796  Val_Acc: 88.241

Epoch 73: Validation loss decreased (0.279566 --> 0.279500).  Saving model ...
	 Train_Loss: 0.3492 Train_Acc: 79.858 Val_Loss: 0.2795  BEST VAL Loss: 0.2795  Val_Acc: 90.357

Epoch 74: Validation loss decreased (0.279500 --> 0.279239).  Saving model ...
	 Train_Loss: 0.3486 Train_Acc: 80.087 Val_Loss: 0.2792  BEST VAL Loss: 0.2792  Val_Acc: 89.934

Epoch 75: Validation loss decreased (0.279239 --> 0.278961).  Saving model ...
	 Train_Loss: 0.3480 Train_Acc: 80.211 Val_Loss: 0.2790  BEST VAL Loss: 0.2790  Val_Acc: 90.357

Epoch 76: Validation loss decreased (0.278961 --> 0.278700).  Saving model ...
	 Train_Loss: 0.3475 Train_Acc: 79.834 Val_Loss: 0.2787  BEST VAL Loss: 0.2787  Val_Acc: 89.793

Epoch 77: Validation loss decreased (0.278700 --> 0.278417).  Saving model ...
	 Train_Loss: 0.3471 Train_Acc: 80.422 Val_Loss: 0.2784  BEST VAL Loss: 0.2784  Val_Acc: 90.310

Epoch 78: Validation loss decreased (0.278417 --> 0.278268).  Saving model ...
	 Train_Loss: 0.3467 Train_Acc: 80.440 Val_Loss: 0.2783  BEST VAL Loss: 0.2783  Val_Acc: 89.981

Epoch 79: Validation loss decreased (0.278268 --> 0.278258).  Saving model ...
	 Train_Loss: 0.3462 Train_Acc: 80.287 Val_Loss: 0.2783  BEST VAL Loss: 0.2783  Val_Acc: 89.934

Epoch 80: Validation loss decreased (0.278258 --> 0.278215).  Saving model ...
	 Train_Loss: 0.3459 Train_Acc: 80.622 Val_Loss: 0.2782  BEST VAL Loss: 0.2782  Val_Acc: 90.122

Epoch 81: Validation loss decreased (0.278215 --> 0.278002).  Saving model ...
	 Train_Loss: 0.3454 Train_Acc: 80.252 Val_Loss: 0.2780  BEST VAL Loss: 0.2780  Val_Acc: 90.075

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.3449 Train_Acc: 80.334 Val_Loss: 0.2781  BEST VAL Loss: 0.2780  Val_Acc: 89.558

Epoch 83: Validation loss decreased (0.278002 --> 0.277984).  Saving model ...
	 Train_Loss: 0.3448 Train_Acc: 79.817 Val_Loss: 0.2780  BEST VAL Loss: 0.2780  Val_Acc: 90.546

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.3444 Train_Acc: 80.234 Val_Loss: 0.2780  BEST VAL Loss: 0.2780  Val_Acc: 90.405

Epoch 85: Validation loss decreased (0.277984 --> 0.277922).  Saving model ...
	 Train_Loss: 0.3440 Train_Acc: 80.299 Val_Loss: 0.2779  BEST VAL Loss: 0.2779  Val_Acc: 89.793

Epoch 86: Validation loss decreased (0.277922 --> 0.277836).  Saving model ...
	 Train_Loss: 0.3438 Train_Acc: 80.281 Val_Loss: 0.2778  BEST VAL Loss: 0.2778  Val_Acc: 89.511

Epoch 87: Validation loss decreased (0.277836 --> 0.277686).  Saving model ...
	 Train_Loss: 0.3434 Train_Acc: 80.299 Val_Loss: 0.2777  BEST VAL Loss: 0.2777  Val_Acc: 89.934

Epoch 88: Validation loss decreased (0.277686 --> 0.277520).  Saving model ...
	 Train_Loss: 0.3431 Train_Acc: 79.864 Val_Loss: 0.2775  BEST VAL Loss: 0.2775  Val_Acc: 89.558

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.3427 Train_Acc: 80.281 Val_Loss: 0.2777  BEST VAL Loss: 0.2775  Val_Acc: 90.122

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.3425 Train_Acc: 80.275 Val_Loss: 0.2775  BEST VAL Loss: 0.2775  Val_Acc: 89.652

Epoch 91: Validation loss decreased (0.277520 --> 0.277357).  Saving model ...
	 Train_Loss: 0.3421 Train_Acc: 80.410 Val_Loss: 0.2774  BEST VAL Loss: 0.2774  Val_Acc: 89.182

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.3418 Train_Acc: 80.334 Val_Loss: 0.2776  BEST VAL Loss: 0.2774  Val_Acc: 89.464

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.3414 Train_Acc: 80.469 Val_Loss: 0.2777  BEST VAL Loss: 0.2774  Val_Acc: 89.793

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.3411 Train_Acc: 80.428 Val_Loss: 0.2777  BEST VAL Loss: 0.2774  Val_Acc: 89.840

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.3408 Train_Acc: 80.746 Val_Loss: 0.2775  BEST VAL Loss: 0.2774  Val_Acc: 89.605

Epoch 96: Validation loss did not decrease
	 Train_Loss: 0.3406 Train_Acc: 80.340 Val_Loss: 0.2774  BEST VAL Loss: 0.2774  Val_Acc: 89.699

Epoch 97: Validation loss decreased (0.277357 --> 0.277259).  Saving model ...
	 Train_Loss: 0.3402 Train_Acc: 80.434 Val_Loss: 0.2773  BEST VAL Loss: 0.2773  Val_Acc: 89.605

Epoch 98: Validation loss did not decrease
	 Train_Loss: 0.3399 Train_Acc: 81.028 Val_Loss: 0.2778  BEST VAL Loss: 0.2773  Val_Acc: 86.500

Epoch 99: Validation loss did not decrease
	 Train_Loss: 0.3427 Train_Acc: 68.472 Val_Loss: 0.2793  BEST VAL Loss: 0.2773  Val_Acc: 74.882

Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.91      0.97      0.94      8634
           1       0.97      0.90      0.93      8370

    accuracy                           0.93     17004
   macro avg       0.94      0.93      0.93     17004
weighted avg       0.94      0.93      0.93     17004

Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.87      0.94      0.90      1080
           1       0.93      0.86      0.89      1046

    accuracy                           0.90      2126
   macro avg       0.90      0.90      0.90      2126
weighted avg       0.90      0.90      0.90      2126

Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.87      0.93      0.89      1079
           1       0.92      0.85      0.88      1047

    accuracy                           0.89      2126
   macro avg       0.89      0.89      0.89      2126
weighted avg       0.89      0.89      0.89      2126

              precision    recall  f1-score   support

           0       0.87      0.93      0.89      1079
           1       0.92      0.85      0.88      1047

    accuracy                           0.89      2126
   macro avg       0.89      0.89      0.89      2126
weighted avg       0.89      0.89      0.89      2126

Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.90      0.92      0.91      4135
           1       0.90      0.88      0.89      3303

    accuracy                           0.90      7438
   macro avg       0.90      0.90      0.90      7438
weighted avg       0.90      0.90      0.90      7438

              precision    recall  f1-score   support

           0       0.90      0.92      0.91      4135
           1       0.90      0.88      0.89      3303

    accuracy                           0.90      7438
   macro avg       0.90      0.90      0.90      7438
weighted avg       0.90      0.90      0.90      7438

completed
