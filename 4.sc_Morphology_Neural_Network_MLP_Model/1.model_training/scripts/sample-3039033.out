[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '34812380'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'c04cd230'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'c7b5ec9d'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '11fb413a'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Thapsigargin_1.000_DMSO_0.025 treatment_name: LPS_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Thapsigargin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'Thapsigargin_1.000_DMSO_0.025']
The dimensions of the data are: (287889, 1270)
Number of total missing values across all columns: 575778
Data Subset Is Off
Wells held out for testing: ['D08' 'K06']
Wells to use for training, validation, and testing ['D02' 'D03' 'D06' 'D07' 'D09' 'K07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.674062).  Saving model ...
	 Train_Loss: 0.6947 Train_Acc: 50.988 Val_Loss: 0.6741  BEST VAL Loss: 0.6741  Val_Acc: 63.854

Epoch 1: Validation loss decreased (0.674062 --> 0.650289).  Saving model ...
	 Train_Loss: 0.6753 Train_Acc: 64.750 Val_Loss: 0.6503  BEST VAL Loss: 0.6503  Val_Acc: 69.205

Epoch 2: Validation loss decreased (0.650289 --> 0.628314).  Saving model ...
	 Train_Loss: 0.6555 Train_Acc: 68.684 Val_Loss: 0.6283  BEST VAL Loss: 0.6283  Val_Acc: 72.674

Epoch 3: Validation loss decreased (0.628314 --> 0.610280).  Saving model ...
	 Train_Loss: 0.6385 Train_Acc: 70.816 Val_Loss: 0.6103  BEST VAL Loss: 0.6103  Val_Acc: 73.812

Epoch 4: Validation loss decreased (0.610280 --> 0.595547).  Saving model ...
	 Train_Loss: 0.6245 Train_Acc: 71.925 Val_Loss: 0.5955  BEST VAL Loss: 0.5955  Val_Acc: 75.023

Epoch 5: Validation loss decreased (0.595547 --> 0.583140).  Saving model ...
	 Train_Loss: 0.6128 Train_Acc: 72.783 Val_Loss: 0.5831  BEST VAL Loss: 0.5831  Val_Acc: 75.714

Epoch 6: Validation loss decreased (0.583140 --> 0.572015).  Saving model ...
	 Train_Loss: 0.6025 Train_Acc: 73.769 Val_Loss: 0.5720  BEST VAL Loss: 0.5720  Val_Acc: 76.667

Epoch 7: Validation loss decreased (0.572015 --> 0.562177).  Saving model ...
	 Train_Loss: 0.5935 Train_Acc: 74.438 Val_Loss: 0.5622  BEST VAL Loss: 0.5622  Val_Acc: 77.715

Epoch 8: Validation loss decreased (0.562177 --> 0.553091).  Saving model ...
	 Train_Loss: 0.5853 Train_Acc: 75.134 Val_Loss: 0.5531  BEST VAL Loss: 0.5531  Val_Acc: 78.358

Epoch 9: Validation loss decreased (0.553091 --> 0.545178).  Saving model ...
	 Train_Loss: 0.5779 Train_Acc: 75.672 Val_Loss: 0.5452  BEST VAL Loss: 0.5452  Val_Acc: 78.506

Epoch 10: Validation loss decreased (0.545178 --> 0.538034).  Saving model ...
	 Train_Loss: 0.5711 Train_Acc: 76.232 Val_Loss: 0.5380  BEST VAL Loss: 0.5380  Val_Acc: 79.230

Epoch 11: Validation loss decreased (0.538034 --> 0.530714).  Saving model ...
	 Train_Loss: 0.5648 Train_Acc: 76.609 Val_Loss: 0.5307  BEST VAL Loss: 0.5307  Val_Acc: 80.126

Epoch 12: Validation loss decreased (0.530714 --> 0.523897).  Saving model ...
	 Train_Loss: 0.5589 Train_Acc: 77.174 Val_Loss: 0.5239  BEST VAL Loss: 0.5239  Val_Acc: 80.798

Epoch 13: Validation loss decreased (0.523897 --> 0.517513).  Saving model ...
	 Train_Loss: 0.5535 Train_Acc: 77.510 Val_Loss: 0.5175  BEST VAL Loss: 0.5175  Val_Acc: 81.126

Epoch 14: Validation loss decreased (0.517513 --> 0.511424).  Saving model ...
	 Train_Loss: 0.5483 Train_Acc: 77.986 Val_Loss: 0.5114  BEST VAL Loss: 0.5114  Val_Acc: 81.674

Epoch 15: Validation loss decreased (0.511424 --> 0.505760).  Saving model ...
	 Train_Loss: 0.5434 Train_Acc: 78.293 Val_Loss: 0.5058  BEST VAL Loss: 0.5058  Val_Acc: 81.827

Epoch 16: Validation loss decreased (0.505760 --> 0.501112).  Saving model ...
	 Train_Loss: 0.5388 Train_Acc: 78.575 Val_Loss: 0.5011  BEST VAL Loss: 0.5011  Val_Acc: 81.226

Epoch 17: Validation loss decreased (0.501112 --> 0.495946).  Saving model ...
	 Train_Loss: 0.5344 Train_Acc: 78.976 Val_Loss: 0.4959  BEST VAL Loss: 0.4959  Val_Acc: 82.508

Epoch 18: Validation loss decreased (0.495946 --> 0.491164).  Saving model ...
	 Train_Loss: 0.5303 Train_Acc: 79.226 Val_Loss: 0.4912  BEST VAL Loss: 0.4912  Val_Acc: 82.637

Epoch 19: Validation loss decreased (0.491164 --> 0.486849).  Saving model ...
	 Train_Loss: 0.5263 Train_Acc: 79.382 Val_Loss: 0.4868  BEST VAL Loss: 0.4868  Val_Acc: 82.723

Epoch 20: Validation loss decreased (0.486849 --> 0.482332).  Saving model ...
	 Train_Loss: 0.5225 Train_Acc: 79.620 Val_Loss: 0.4823  BEST VAL Loss: 0.4823  Val_Acc: 83.318

Epoch 21: Validation loss decreased (0.482332 --> 0.478402).  Saving model ...
	 Train_Loss: 0.5188 Train_Acc: 79.910 Val_Loss: 0.4784  BEST VAL Loss: 0.4784  Val_Acc: 82.989

Epoch 22: Validation loss decreased (0.478402 --> 0.474399).  Saving model ...
	 Train_Loss: 0.5153 Train_Acc: 80.112 Val_Loss: 0.4744  BEST VAL Loss: 0.4744  Val_Acc: 83.685

Epoch 23: Validation loss decreased (0.474399 --> 0.470792).  Saving model ...
	 Train_Loss: 0.5120 Train_Acc: 80.287 Val_Loss: 0.4708  BEST VAL Loss: 0.4708  Val_Acc: 83.456

Epoch 24: Validation loss decreased (0.470792 --> 0.467252).  Saving model ...
	 Train_Loss: 0.5088 Train_Acc: 80.419 Val_Loss: 0.4673  BEST VAL Loss: 0.4673  Val_Acc: 83.776

Epoch 25: Validation loss decreased (0.467252 --> 0.463818).  Saving model ...
	 Train_Loss: 0.5057 Train_Acc: 80.544 Val_Loss: 0.4638  BEST VAL Loss: 0.4638  Val_Acc: 83.809

Epoch 26: Validation loss decreased (0.463818 --> 0.460468).  Saving model ...
	 Train_Loss: 0.5027 Train_Acc: 80.753 Val_Loss: 0.4605  BEST VAL Loss: 0.4605  Val_Acc: 84.057

Epoch 27: Validation loss decreased (0.460468 --> 0.457231).  Saving model ...
	 Train_Loss: 0.4999 Train_Acc: 80.863 Val_Loss: 0.4572  BEST VAL Loss: 0.4572  Val_Acc: 84.381

Epoch 28: Validation loss decreased (0.457231 --> 0.454484).  Saving model ...
	 Train_Loss: 0.4971 Train_Acc: 81.280 Val_Loss: 0.4545  BEST VAL Loss: 0.4545  Val_Acc: 83.585

Epoch 29: Validation loss decreased (0.454484 --> 0.451666).  Saving model ...
	 Train_Loss: 0.4943 Train_Acc: 81.365 Val_Loss: 0.4517  BEST VAL Loss: 0.4517  Val_Acc: 83.957

Epoch 30: Validation loss decreased (0.451666 --> 0.449018).  Saving model ...
	 Train_Loss: 0.4918 Train_Acc: 81.288 Val_Loss: 0.4490  BEST VAL Loss: 0.4490  Val_Acc: 84.271

Epoch 31: Validation loss decreased (0.449018 --> 0.446238).  Saving model ...
	 Train_Loss: 0.4893 Train_Acc: 81.411 Val_Loss: 0.4462  BEST VAL Loss: 0.4462  Val_Acc: 84.729

Epoch 32: Validation loss decreased (0.446238 --> 0.443584).  Saving model ...
	 Train_Loss: 0.4869 Train_Acc: 81.634 Val_Loss: 0.4436  BEST VAL Loss: 0.4436  Val_Acc: 84.948

Epoch 33: Validation loss decreased (0.443584 --> 0.441185).  Saving model ...
	 Train_Loss: 0.4847 Train_Acc: 81.579 Val_Loss: 0.4412  BEST VAL Loss: 0.4412  Val_Acc: 84.576

Epoch 34: Validation loss decreased (0.441185 --> 0.439069).  Saving model ...
	 Train_Loss: 0.4824 Train_Acc: 81.995 Val_Loss: 0.4391  BEST VAL Loss: 0.4391  Val_Acc: 84.228

Epoch 35: Validation loss decreased (0.439069 --> 0.436687).  Saving model ...
	 Train_Loss: 0.4801 Train_Acc: 82.191 Val_Loss: 0.4367  BEST VAL Loss: 0.4367  Val_Acc: 84.862

Epoch 36: Validation loss decreased (0.436687 --> 0.434410).  Saving model ...
	 Train_Loss: 0.4779 Train_Acc: 82.178 Val_Loss: 0.4344  BEST VAL Loss: 0.4344  Val_Acc: 85.281

Epoch 37: Validation loss decreased (0.434410 --> 0.432336).  Saving model ...
	 Train_Loss: 0.4759 Train_Acc: 82.123 Val_Loss: 0.4323  BEST VAL Loss: 0.4323  Val_Acc: 85.024

Epoch 38: Validation loss decreased (0.432336 --> 0.430198).  Saving model ...
	 Train_Loss: 0.4738 Train_Acc: 82.453 Val_Loss: 0.4302  BEST VAL Loss: 0.4302  Val_Acc: 85.124

Epoch 39: Validation loss decreased (0.430198 --> 0.428635).  Saving model ...
	 Train_Loss: 0.4719 Train_Acc: 82.379 Val_Loss: 0.4286  BEST VAL Loss: 0.4286  Val_Acc: 84.357

Epoch 40: Validation loss decreased (0.428635 --> 0.426772).  Saving model ...
	 Train_Loss: 0.4700 Train_Acc: 82.437 Val_Loss: 0.4268  BEST VAL Loss: 0.4268  Val_Acc: 85.119

Epoch 41: Validation loss decreased (0.426772 --> 0.424848).  Saving model ...
	 Train_Loss: 0.4681 Train_Acc: 82.595 Val_Loss: 0.4248  BEST VAL Loss: 0.4248  Val_Acc: 85.467

Epoch 42: Validation loss decreased (0.424848 --> 0.422926).  Saving model ...
	 Train_Loss: 0.4663 Train_Acc: 82.728 Val_Loss: 0.4229  BEST VAL Loss: 0.4229  Val_Acc: 85.524

Epoch 43: Validation loss decreased (0.422926 --> 0.421252).  Saving model ...
	 Train_Loss: 0.4646 Train_Acc: 82.679 Val_Loss: 0.4213  BEST VAL Loss: 0.4213  Val_Acc: 85.305

Epoch 44: Validation loss decreased (0.421252 --> 0.419436).  Saving model ...
	 Train_Loss: 0.4628 Train_Acc: 82.865 Val_Loss: 0.4194  BEST VAL Loss: 0.4194  Val_Acc: 85.734

Epoch 45: Validation loss decreased (0.419436 --> 0.418283).  Saving model ...
	 Train_Loss: 0.4611 Train_Acc: 82.950 Val_Loss: 0.4183  BEST VAL Loss: 0.4183  Val_Acc: 84.195

Epoch 46: Validation loss decreased (0.418283 --> 0.417402).  Saving model ...
	 Train_Loss: 0.4595 Train_Acc: 82.978 Val_Loss: 0.4174  BEST VAL Loss: 0.4174  Val_Acc: 83.671

Epoch 47: Validation loss decreased (0.417402 --> 0.415795).  Saving model ...
	 Train_Loss: 0.4579 Train_Acc: 82.897 Val_Loss: 0.4158  BEST VAL Loss: 0.4158  Val_Acc: 85.448

Epoch 48: Validation loss decreased (0.415795 --> 0.414119).  Saving model ...
	 Train_Loss: 0.4563 Train_Acc: 83.297 Val_Loss: 0.4141  BEST VAL Loss: 0.4141  Val_Acc: 85.944

Epoch 49: Validation loss decreased (0.414119 --> 0.412594).  Saving model ...
	 Train_Loss: 0.4548 Train_Acc: 83.234 Val_Loss: 0.4126  BEST VAL Loss: 0.4126  Val_Acc: 85.815

Epoch 50: Validation loss decreased (0.412594 --> 0.411124).  Saving model ...
	 Train_Loss: 0.4533 Train_Acc: 83.267 Val_Loss: 0.4111  BEST VAL Loss: 0.4111  Val_Acc: 85.858

Epoch 51: Validation loss decreased (0.411124 --> 0.409607).  Saving model ...
	 Train_Loss: 0.4519 Train_Acc: 83.414 Val_Loss: 0.4096  BEST VAL Loss: 0.4096  Val_Acc: 86.168

Epoch 52: Validation loss decreased (0.409607 --> 0.408155).  Saving model ...
	 Train_Loss: 0.4505 Train_Acc: 83.387 Val_Loss: 0.4082  BEST VAL Loss: 0.4082  Val_Acc: 85.972

Epoch 53: Validation loss decreased (0.408155 --> 0.406763).  Saving model ...
	 Train_Loss: 0.4491 Train_Acc: 83.484 Val_Loss: 0.4068  BEST VAL Loss: 0.4068  Val_Acc: 85.882

Epoch 54: Validation loss decreased (0.406763 --> 0.405429).  Saving model ...
	 Train_Loss: 0.4477 Train_Acc: 83.593 Val_Loss: 0.4054  BEST VAL Loss: 0.4054  Val_Acc: 86.034

Epoch 55: Validation loss decreased (0.405429 --> 0.404125).  Saving model ...
	 Train_Loss: 0.4464 Train_Acc: 83.586 Val_Loss: 0.4041  BEST VAL Loss: 0.4041  Val_Acc: 86.311

Epoch 56: Validation loss decreased (0.404125 --> 0.402885).  Saving model ...
	 Train_Loss: 0.4451 Train_Acc: 83.686 Val_Loss: 0.4029  BEST VAL Loss: 0.4029  Val_Acc: 86.025

Epoch 57: Validation loss decreased (0.402885 --> 0.401600).  Saving model ...
	 Train_Loss: 0.4439 Train_Acc: 83.562 Val_Loss: 0.4016  BEST VAL Loss: 0.4016  Val_Acc: 86.515

Epoch 58: Validation loss decreased (0.401600 --> 0.400438).  Saving model ...
	 Train_Loss: 0.4426 Train_Acc: 83.754 Val_Loss: 0.4004  BEST VAL Loss: 0.4004  Val_Acc: 86.006

Epoch 59: Validation loss decreased (0.400438 --> 0.399302).  Saving model ...
	 Train_Loss: 0.4414 Train_Acc: 83.970 Val_Loss: 0.3993  BEST VAL Loss: 0.3993  Val_Acc: 86.182

Epoch 60: Validation loss decreased (0.399302 --> 0.398541).  Saving model ...
	 Train_Loss: 0.4402 Train_Acc: 83.764 Val_Loss: 0.3985  BEST VAL Loss: 0.3985  Val_Acc: 84.924

Epoch 61: Validation loss decreased (0.398541 --> 0.397464).  Saving model ...
	 Train_Loss: 0.4391 Train_Acc: 83.767 Val_Loss: 0.3975  BEST VAL Loss: 0.3975  Val_Acc: 86.215

Epoch 62: Validation loss decreased (0.397464 --> 0.396287).  Saving model ...
	 Train_Loss: 0.4380 Train_Acc: 83.787 Val_Loss: 0.3963  BEST VAL Loss: 0.3963  Val_Acc: 86.363

Epoch 63: Validation loss decreased (0.396287 --> 0.395197).  Saving model ...
	 Train_Loss: 0.4369 Train_Acc: 83.860 Val_Loss: 0.3952  BEST VAL Loss: 0.3952  Val_Acc: 86.511

Epoch 64: Validation loss decreased (0.395197 --> 0.394096).  Saving model ...
	 Train_Loss: 0.4359 Train_Acc: 83.830 Val_Loss: 0.3941  BEST VAL Loss: 0.3941  Val_Acc: 86.444

Epoch 65: Validation loss decreased (0.394096 --> 0.393085).  Saving model ...
	 Train_Loss: 0.4348 Train_Acc: 84.016 Val_Loss: 0.3931  BEST VAL Loss: 0.3931  Val_Acc: 86.344

Epoch 66: Validation loss decreased (0.393085 --> 0.392109).  Saving model ...
	 Train_Loss: 0.4338 Train_Acc: 84.068 Val_Loss: 0.3921  BEST VAL Loss: 0.3921  Val_Acc: 86.196

Epoch 67: Validation loss decreased (0.392109 --> 0.391176).  Saving model ...
	 Train_Loss: 0.4327 Train_Acc: 84.096 Val_Loss: 0.3912  BEST VAL Loss: 0.3912  Val_Acc: 86.292

Epoch 68: Validation loss decreased (0.391176 --> 0.390155).  Saving model ...
	 Train_Loss: 0.4317 Train_Acc: 84.080 Val_Loss: 0.3902  BEST VAL Loss: 0.3902  Val_Acc: 86.535

Epoch 69: Validation loss decreased (0.390155 --> 0.389282).  Saving model ...
	 Train_Loss: 0.4308 Train_Acc: 84.148 Val_Loss: 0.3893  BEST VAL Loss: 0.3893  Val_Acc: 86.387

Epoch 70: Validation loss decreased (0.389282 --> 0.388377).  Saving model ...
	 Train_Loss: 0.4298 Train_Acc: 84.207 Val_Loss: 0.3884  BEST VAL Loss: 0.3884  Val_Acc: 86.434

Epoch 71: Validation loss decreased (0.388377 --> 0.387482).  Saving model ...
	 Train_Loss: 0.4288 Train_Acc: 84.273 Val_Loss: 0.3875  BEST VAL Loss: 0.3875  Val_Acc: 86.487

Epoch 72: Validation loss decreased (0.387482 --> 0.386560).  Saving model ...
	 Train_Loss: 0.4279 Train_Acc: 84.237 Val_Loss: 0.3866  BEST VAL Loss: 0.3866  Val_Acc: 86.573

Epoch 73: Validation loss decreased (0.386560 --> 0.385713).  Saving model ...
	 Train_Loss: 0.4270 Train_Acc: 84.275 Val_Loss: 0.3857  BEST VAL Loss: 0.3857  Val_Acc: 86.735

Epoch 74: Validation loss decreased (0.385713 --> 0.384880).  Saving model ...
	 Train_Loss: 0.4261 Train_Acc: 84.166 Val_Loss: 0.3849  BEST VAL Loss: 0.3849  Val_Acc: 86.611

Epoch 75: Validation loss decreased (0.384880 --> 0.384061).  Saving model ...
	 Train_Loss: 0.4253 Train_Acc: 84.362 Val_Loss: 0.3841  BEST VAL Loss: 0.3841  Val_Acc: 86.644

Epoch 76: Validation loss decreased (0.384061 --> 0.383214).  Saving model ...
	 Train_Loss: 0.4244 Train_Acc: 84.393 Val_Loss: 0.3832  BEST VAL Loss: 0.3832  Val_Acc: 86.849

Epoch 77: Validation loss decreased (0.383214 --> 0.382509).  Saving model ...
	 Train_Loss: 0.4236 Train_Acc: 84.318 Val_Loss: 0.3825  BEST VAL Loss: 0.3825  Val_Acc: 86.330

Epoch 78: Validation loss decreased (0.382509 --> 0.381740).  Saving model ...
	 Train_Loss: 0.4227 Train_Acc: 84.473 Val_Loss: 0.3817  BEST VAL Loss: 0.3817  Val_Acc: 86.487

Epoch 79: Validation loss decreased (0.381740 --> 0.380961).  Saving model ...
	 Train_Loss: 0.4219 Train_Acc: 84.505 Val_Loss: 0.3810  BEST VAL Loss: 0.3810  Val_Acc: 86.692

Epoch 80: Validation loss decreased (0.380961 --> 0.380318).  Saving model ...
	 Train_Loss: 0.4212 Train_Acc: 84.372 Val_Loss: 0.3803  BEST VAL Loss: 0.3803  Val_Acc: 86.268

Epoch 81: Validation loss decreased (0.380318 --> 0.379584).  Saving model ...
	 Train_Loss: 0.4204 Train_Acc: 84.511 Val_Loss: 0.3796  BEST VAL Loss: 0.3796  Val_Acc: 86.649

Epoch 82: Validation loss decreased (0.379584 --> 0.378852).  Saving model ...
	 Train_Loss: 0.4196 Train_Acc: 84.410 Val_Loss: 0.3789  BEST VAL Loss: 0.3789  Val_Acc: 86.697

Epoch 83: Validation loss decreased (0.378852 --> 0.378152).  Saving model ...
	 Train_Loss: 0.4189 Train_Acc: 84.608 Val_Loss: 0.3782  BEST VAL Loss: 0.3782  Val_Acc: 86.982

Epoch 84: Validation loss decreased (0.378152 --> 0.377444).  Saving model ...
	 Train_Loss: 0.4181 Train_Acc: 84.464 Val_Loss: 0.3774  BEST VAL Loss: 0.3774  Val_Acc: 86.839

Epoch 85: Validation loss decreased (0.377444 --> 0.376755).  Saving model ...
	 Train_Loss: 0.4174 Train_Acc: 84.505 Val_Loss: 0.3768  BEST VAL Loss: 0.3768  Val_Acc: 86.825

Epoch 86: Validation loss decreased (0.376755 --> 0.376152).  Saving model ...
	 Train_Loss: 0.4167 Train_Acc: 84.585 Val_Loss: 0.3762  BEST VAL Loss: 0.3762  Val_Acc: 86.411

Epoch 87: Validation loss decreased (0.376152 --> 0.375488).  Saving model ...
	 Train_Loss: 0.4160 Train_Acc: 84.617 Val_Loss: 0.3755  BEST VAL Loss: 0.3755  Val_Acc: 86.735

Epoch 88: Validation loss decreased (0.375488 --> 0.374794).  Saving model ...
	 Train_Loss: 0.4153 Train_Acc: 84.649 Val_Loss: 0.3748  BEST VAL Loss: 0.3748  Val_Acc: 87.040

Epoch 89: Validation loss decreased (0.374794 --> 0.374175).  Saving model ...
	 Train_Loss: 0.4146 Train_Acc: 84.724 Val_Loss: 0.3742  BEST VAL Loss: 0.3742  Val_Acc: 86.849

Epoch 90: Validation loss decreased (0.374175 --> 0.373601).  Saving model ...
	 Train_Loss: 0.4140 Train_Acc: 84.668 Val_Loss: 0.3736  BEST VAL Loss: 0.3736  Val_Acc: 86.773

Epoch 91: Validation loss decreased (0.373601 --> 0.372973).  Saving model ...
	 Train_Loss: 0.4133 Train_Acc: 84.727 Val_Loss: 0.3730  BEST VAL Loss: 0.3730  Val_Acc: 87.102

Epoch 92: Validation loss decreased (0.372973 --> 0.372383).  Saving model ...
	 Train_Loss: 0.4126 Train_Acc: 84.740 Val_Loss: 0.3724  BEST VAL Loss: 0.3724  Val_Acc: 86.816

Epoch 93: Validation loss decreased (0.372383 --> 0.371841).  Saving model ...
	 Train_Loss: 0.4120 Train_Acc: 84.694 Val_Loss: 0.3718  BEST VAL Loss: 0.3718  Val_Acc: 86.568

Epoch 94: Validation loss decreased (0.371841 --> 0.371271).  Saving model ...
	 Train_Loss: 0.4114 Train_Acc: 84.698 Val_Loss: 0.3713  BEST VAL Loss: 0.3713  Val_Acc: 86.768

Epoch 95: Validation loss decreased (0.371271 --> 0.370774).  Saving model ...
	 Train_Loss: 0.4108 Train_Acc: 84.801 Val_Loss: 0.3708  BEST VAL Loss: 0.3708  Val_Acc: 86.434

Epoch 96: Validation loss decreased (0.370774 --> 0.370260).  Saving model ...
	 Train_Loss: 0.4102 Train_Acc: 84.747 Val_Loss: 0.3703  BEST VAL Loss: 0.3703  Val_Acc: 86.739

Epoch 97: Validation loss decreased (0.370260 --> 0.369750).  Saving model ...
	 Train_Loss: 0.4096 Train_Acc: 84.778 Val_Loss: 0.3697  BEST VAL Loss: 0.3697  Val_Acc: 86.749

Epoch 98: Validation loss decreased (0.369750 --> 0.369227).  Saving model ...
	 Train_Loss: 0.4090 Train_Acc: 84.745 Val_Loss: 0.3692  BEST VAL Loss: 0.3692  Val_Acc: 86.739

Epoch 99: Validation loss decreased (0.369227 --> 0.368755).  Saving model ...
	 Train_Loss: 0.4084 Train_Acc: 84.757 Val_Loss: 0.3688  BEST VAL Loss: 0.3688  Val_Acc: 86.658

Thapsigargin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.46      0.47     79796
           1       0.52      0.54      0.53     88100

    accuracy                           0.50    167896
   macro avg       0.50      0.50      0.50    167896
weighted avg       0.50      0.50      0.50    167896

Thapsigargin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.46      0.47      9975
           1       0.53      0.54      0.54     11012

    accuracy                           0.50     20987
   macro avg       0.50      0.50      0.50     20987
weighted avg       0.50      0.50      0.50     20987

Thapsigargin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.46      0.47      9975
           1       0.53      0.55      0.54     11012

    accuracy                           0.51     20987
   macro avg       0.50      0.50      0.50     20987
weighted avg       0.51      0.51      0.51     20987

              precision    recall  f1-score   support

           0       0.48      0.46      0.47      9975
           1       0.53      0.55      0.54     11012

    accuracy                           0.51     20987
   macro avg       0.50      0.50      0.50     20987
weighted avg       0.51      0.51      0.51     20987

Thapsigargin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.20      0.29     39687
           1       0.49      0.80      0.61     38332

    accuracy                           0.49     78019
   macro avg       0.50      0.50      0.45     78019
weighted avg       0.50      0.49      0.44     78019

              precision    recall  f1-score   support

           0       0.50      0.20      0.29     39687
           1       0.49      0.80      0.61     38332

    accuracy                           0.49     78019
   macro avg       0.50      0.50      0.45     78019
weighted avg       0.50      0.49      0.44     78019

completed
