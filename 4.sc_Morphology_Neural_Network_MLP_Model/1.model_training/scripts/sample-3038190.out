[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'bb6435d3'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '4e9ab361'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '0c18a692'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '5589674c'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_1.000_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_1.000_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (298868, 1270)
Number of total missing values across all columns: 597736
Data Subset Is Off
Wells held out for testing: ['D08' 'J08']
Wells to use for training, validation, and testing ['D02' 'D03' 'D09' 'J02' 'J03' 'J09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.607787).  Saving model ...
	 Train_Loss: 0.6494 Train_Acc: 61.396 Val_Loss: 0.6078  BEST VAL Loss: 0.6078  Val_Acc: 66.878

Epoch 1: Validation loss decreased (0.607787 --> 0.589815).  Saving model ...
	 Train_Loss: 0.6260 Train_Acc: 66.491 Val_Loss: 0.5898  BEST VAL Loss: 0.5898  Val_Acc: 69.154

Epoch 2: Validation loss decreased (0.589815 --> 0.577605).  Saving model ...
	 Train_Loss: 0.6100 Train_Acc: 68.574 Val_Loss: 0.5776  BEST VAL Loss: 0.5776  Val_Acc: 70.825

Epoch 3: Validation loss decreased (0.577605 --> 0.568482).  Saving model ...
	 Train_Loss: 0.5985 Train_Acc: 69.783 Val_Loss: 0.5685  BEST VAL Loss: 0.5685  Val_Acc: 71.695

Epoch 4: Validation loss decreased (0.568482 --> 0.561080).  Saving model ...
	 Train_Loss: 0.5896 Train_Acc: 70.604 Val_Loss: 0.5611  BEST VAL Loss: 0.5611  Val_Acc: 72.587

Epoch 5: Validation loss decreased (0.561080 --> 0.554771).  Saving model ...
	 Train_Loss: 0.5822 Train_Acc: 71.185 Val_Loss: 0.5548  BEST VAL Loss: 0.5548  Val_Acc: 73.204

Epoch 6: Validation loss decreased (0.554771 --> 0.549417).  Saving model ...
	 Train_Loss: 0.5760 Train_Acc: 71.569 Val_Loss: 0.5494  BEST VAL Loss: 0.5494  Val_Acc: 73.642

Epoch 7: Validation loss decreased (0.549417 --> 0.544753).  Saving model ...
	 Train_Loss: 0.5706 Train_Acc: 71.930 Val_Loss: 0.5448  BEST VAL Loss: 0.5448  Val_Acc: 73.853

Epoch 8: Validation loss decreased (0.544753 --> 0.540417).  Saving model ...
	 Train_Loss: 0.5659 Train_Acc: 72.210 Val_Loss: 0.5404  BEST VAL Loss: 0.5404  Val_Acc: 74.272

Epoch 9: Validation loss decreased (0.540417 --> 0.536741).  Saving model ...
	 Train_Loss: 0.5617 Train_Acc: 72.438 Val_Loss: 0.5367  BEST VAL Loss: 0.5367  Val_Acc: 74.538

Epoch 10: Validation loss decreased (0.536741 --> 0.533391).  Saving model ...
	 Train_Loss: 0.5579 Train_Acc: 72.807 Val_Loss: 0.5334  BEST VAL Loss: 0.5334  Val_Acc: 74.660

Epoch 11: Validation loss decreased (0.533391 --> 0.530386).  Saving model ...
	 Train_Loss: 0.5544 Train_Acc: 72.923 Val_Loss: 0.5304  BEST VAL Loss: 0.5304  Val_Acc: 74.966

Epoch 12: Validation loss decreased (0.530386 --> 0.527577).  Saving model ...
	 Train_Loss: 0.5513 Train_Acc: 72.988 Val_Loss: 0.5276  BEST VAL Loss: 0.5276  Val_Acc: 74.872

Epoch 13: Validation loss decreased (0.527577 --> 0.525015).  Saving model ...
	 Train_Loss: 0.5484 Train_Acc: 73.196 Val_Loss: 0.5250  BEST VAL Loss: 0.5250  Val_Acc: 75.237

Epoch 14: Validation loss decreased (0.525015 --> 0.522636).  Saving model ...
	 Train_Loss: 0.5457 Train_Acc: 73.369 Val_Loss: 0.5226  BEST VAL Loss: 0.5226  Val_Acc: 75.313

Epoch 15: Validation loss decreased (0.522636 --> 0.520344).  Saving model ...
	 Train_Loss: 0.5431 Train_Acc: 73.595 Val_Loss: 0.5203  BEST VAL Loss: 0.5203  Val_Acc: 75.534

Epoch 16: Validation loss decreased (0.520344 --> 0.518194).  Saving model ...
	 Train_Loss: 0.5408 Train_Acc: 73.572 Val_Loss: 0.5182  BEST VAL Loss: 0.5182  Val_Acc: 75.502

Epoch 17: Validation loss decreased (0.518194 --> 0.516305).  Saving model ...
	 Train_Loss: 0.5386 Train_Acc: 73.712 Val_Loss: 0.5163  BEST VAL Loss: 0.5163  Val_Acc: 75.399

Epoch 18: Validation loss decreased (0.516305 --> 0.514405).  Saving model ...
	 Train_Loss: 0.5365 Train_Acc: 73.907 Val_Loss: 0.5144  BEST VAL Loss: 0.5144  Val_Acc: 75.750

Epoch 19: Validation loss decreased (0.514405 --> 0.512589).  Saving model ...
	 Train_Loss: 0.5345 Train_Acc: 73.927 Val_Loss: 0.5126  BEST VAL Loss: 0.5126  Val_Acc: 76.066

Epoch 20: Validation loss decreased (0.512589 --> 0.510830).  Saving model ...
	 Train_Loss: 0.5326 Train_Acc: 74.083 Val_Loss: 0.5108  BEST VAL Loss: 0.5108  Val_Acc: 76.079

Epoch 21: Validation loss decreased (0.510830 --> 0.509237).  Saving model ...
	 Train_Loss: 0.5308 Train_Acc: 74.185 Val_Loss: 0.5092  BEST VAL Loss: 0.5092  Val_Acc: 76.223

Epoch 22: Validation loss decreased (0.509237 --> 0.507778).  Saving model ...
	 Train_Loss: 0.5291 Train_Acc: 74.277 Val_Loss: 0.5078  BEST VAL Loss: 0.5078  Val_Acc: 76.039

Epoch 23: Validation loss decreased (0.507778 --> 0.506356).  Saving model ...
	 Train_Loss: 0.5275 Train_Acc: 74.242 Val_Loss: 0.5064  BEST VAL Loss: 0.5064  Val_Acc: 76.138

Epoch 24: Validation loss decreased (0.506356 --> 0.504921).  Saving model ...
	 Train_Loss: 0.5260 Train_Acc: 74.455 Val_Loss: 0.5049  BEST VAL Loss: 0.5049  Val_Acc: 76.151

Epoch 25: Validation loss decreased (0.504921 --> 0.503566).  Saving model ...
	 Train_Loss: 0.5245 Train_Acc: 74.513 Val_Loss: 0.5036  BEST VAL Loss: 0.5036  Val_Acc: 76.462

Epoch 26: Validation loss decreased (0.503566 --> 0.502306).  Saving model ...
	 Train_Loss: 0.5231 Train_Acc: 74.583 Val_Loss: 0.5023  BEST VAL Loss: 0.5023  Val_Acc: 76.485

Epoch 27: Validation loss decreased (0.502306 --> 0.501119).  Saving model ...
	 Train_Loss: 0.5217 Train_Acc: 74.538 Val_Loss: 0.5011  BEST VAL Loss: 0.5011  Val_Acc: 76.624

Epoch 28: Validation loss decreased (0.501119 --> 0.500018).  Saving model ...
	 Train_Loss: 0.5205 Train_Acc: 74.574 Val_Loss: 0.5000  BEST VAL Loss: 0.5000  Val_Acc: 76.687

Epoch 29: Validation loss decreased (0.500018 --> 0.498852).  Saving model ...
	 Train_Loss: 0.5192 Train_Acc: 74.777 Val_Loss: 0.4989  BEST VAL Loss: 0.4989  Val_Acc: 76.678

Epoch 30: Validation loss decreased (0.498852 --> 0.497857).  Saving model ...
	 Train_Loss: 0.5180 Train_Acc: 74.796 Val_Loss: 0.4979  BEST VAL Loss: 0.4979  Val_Acc: 76.358

Epoch 31: Validation loss decreased (0.497857 --> 0.496874).  Saving model ...
	 Train_Loss: 0.5168 Train_Acc: 74.880 Val_Loss: 0.4969  BEST VAL Loss: 0.4969  Val_Acc: 76.778

Epoch 32: Validation loss decreased (0.496874 --> 0.495915).  Saving model ...
	 Train_Loss: 0.5157 Train_Acc: 74.887 Val_Loss: 0.4959  BEST VAL Loss: 0.4959  Val_Acc: 76.980

Epoch 33: Validation loss decreased (0.495915 --> 0.495045).  Saving model ...
	 Train_Loss: 0.5146 Train_Acc: 74.902 Val_Loss: 0.4950  BEST VAL Loss: 0.4950  Val_Acc: 76.602

Epoch 34: Validation loss decreased (0.495045 --> 0.494142).  Saving model ...
	 Train_Loss: 0.5136 Train_Acc: 75.027 Val_Loss: 0.4941  BEST VAL Loss: 0.4941  Val_Acc: 77.061

Epoch 35: Validation loss decreased (0.494142 --> 0.493259).  Saving model ...
	 Train_Loss: 0.5126 Train_Acc: 75.198 Val_Loss: 0.4933  BEST VAL Loss: 0.4933  Val_Acc: 76.917

Epoch 36: Validation loss decreased (0.493259 --> 0.492404).  Saving model ...
	 Train_Loss: 0.5116 Train_Acc: 75.178 Val_Loss: 0.4924  BEST VAL Loss: 0.4924  Val_Acc: 77.210

Epoch 37: Validation loss decreased (0.492404 --> 0.491575).  Saving model ...
	 Train_Loss: 0.5106 Train_Acc: 75.336 Val_Loss: 0.4916  BEST VAL Loss: 0.4916  Val_Acc: 77.300

Epoch 38: Validation loss decreased (0.491575 --> 0.490819).  Saving model ...
	 Train_Loss: 0.5096 Train_Acc: 75.313 Val_Loss: 0.4908  BEST VAL Loss: 0.4908  Val_Acc: 76.971

Epoch 39: Validation loss decreased (0.490819 --> 0.490045).  Saving model ...
	 Train_Loss: 0.5087 Train_Acc: 75.206 Val_Loss: 0.4900  BEST VAL Loss: 0.4900  Val_Acc: 77.129

Epoch 40: Validation loss decreased (0.490045 --> 0.489329).  Saving model ...
	 Train_Loss: 0.5078 Train_Acc: 75.544 Val_Loss: 0.4893  BEST VAL Loss: 0.4893  Val_Acc: 77.156

Epoch 41: Validation loss decreased (0.489329 --> 0.488596).  Saving model ...
	 Train_Loss: 0.5069 Train_Acc: 75.444 Val_Loss: 0.4886  BEST VAL Loss: 0.4886  Val_Acc: 77.318

Epoch 42: Validation loss decreased (0.488596 --> 0.487937).  Saving model ...
	 Train_Loss: 0.5061 Train_Acc: 75.398 Val_Loss: 0.4879  BEST VAL Loss: 0.4879  Val_Acc: 77.219

Epoch 43: Validation loss decreased (0.487937 --> 0.487243).  Saving model ...
	 Train_Loss: 0.5053 Train_Acc: 75.544 Val_Loss: 0.4872  BEST VAL Loss: 0.4872  Val_Acc: 77.489

Epoch 44: Validation loss decreased (0.487243 --> 0.486551).  Saving model ...
	 Train_Loss: 0.5045 Train_Acc: 75.557 Val_Loss: 0.4866  BEST VAL Loss: 0.4866  Val_Acc: 77.616

Epoch 45: Validation loss decreased (0.486551 --> 0.485900).  Saving model ...
	 Train_Loss: 0.5037 Train_Acc: 75.666 Val_Loss: 0.4859  BEST VAL Loss: 0.4859  Val_Acc: 77.516

Epoch 46: Validation loss decreased (0.485900 --> 0.485257).  Saving model ...
	 Train_Loss: 0.5029 Train_Acc: 75.600 Val_Loss: 0.4853  BEST VAL Loss: 0.4853  Val_Acc: 77.413

Epoch 47: Validation loss decreased (0.485257 --> 0.484603).  Saving model ...
	 Train_Loss: 0.5022 Train_Acc: 75.623 Val_Loss: 0.4846  BEST VAL Loss: 0.4846  Val_Acc: 77.589

Epoch 48: Validation loss decreased (0.484603 --> 0.484012).  Saving model ...
	 Train_Loss: 0.5014 Train_Acc: 75.631 Val_Loss: 0.4840  BEST VAL Loss: 0.4840  Val_Acc: 77.543

Epoch 49: Validation loss decreased (0.484012 --> 0.483419).  Saving model ...
	 Train_Loss: 0.5007 Train_Acc: 75.766 Val_Loss: 0.4834  BEST VAL Loss: 0.4834  Val_Acc: 77.607

Epoch 50: Validation loss decreased (0.483419 --> 0.482820).  Saving model ...
	 Train_Loss: 0.5000 Train_Acc: 75.824 Val_Loss: 0.4828  BEST VAL Loss: 0.4828  Val_Acc: 77.593

Epoch 51: Validation loss decreased (0.482820 --> 0.482265).  Saving model ...
	 Train_Loss: 0.4993 Train_Acc: 75.809 Val_Loss: 0.4823  BEST VAL Loss: 0.4823  Val_Acc: 77.598

Epoch 52: Validation loss decreased (0.482265 --> 0.481730).  Saving model ...
	 Train_Loss: 0.4986 Train_Acc: 75.799 Val_Loss: 0.4817  BEST VAL Loss: 0.4817  Val_Acc: 77.823

Epoch 53: Validation loss decreased (0.481730 --> 0.481196).  Saving model ...
	 Train_Loss: 0.4980 Train_Acc: 75.806 Val_Loss: 0.4812  BEST VAL Loss: 0.4812  Val_Acc: 77.899

Epoch 54: Validation loss decreased (0.481196 --> 0.480677).  Saving model ...
	 Train_Loss: 0.4973 Train_Acc: 75.860 Val_Loss: 0.4807  BEST VAL Loss: 0.4807  Val_Acc: 77.809

Epoch 55: Validation loss decreased (0.480677 --> 0.480191).  Saving model ...
	 Train_Loss: 0.4967 Train_Acc: 75.953 Val_Loss: 0.4802  BEST VAL Loss: 0.4802  Val_Acc: 77.854

Epoch 56: Validation loss decreased (0.480191 --> 0.479695).  Saving model ...
	 Train_Loss: 0.4961 Train_Acc: 75.956 Val_Loss: 0.4797  BEST VAL Loss: 0.4797  Val_Acc: 77.706

Epoch 57: Validation loss decreased (0.479695 --> 0.479228).  Saving model ...
	 Train_Loss: 0.4955 Train_Acc: 75.970 Val_Loss: 0.4792  BEST VAL Loss: 0.4792  Val_Acc: 77.818

Epoch 58: Validation loss decreased (0.479228 --> 0.478818).  Saving model ...
	 Train_Loss: 0.4949 Train_Acc: 75.948 Val_Loss: 0.4788  BEST VAL Loss: 0.4788  Val_Acc: 77.656

Epoch 59: Validation loss decreased (0.478818 --> 0.478380).  Saving model ...
	 Train_Loss: 0.4943 Train_Acc: 76.124 Val_Loss: 0.4784  BEST VAL Loss: 0.4784  Val_Acc: 77.908

Epoch 60: Validation loss decreased (0.478380 --> 0.477943).  Saving model ...
	 Train_Loss: 0.4938 Train_Acc: 75.867 Val_Loss: 0.4779  BEST VAL Loss: 0.4779  Val_Acc: 77.922

Epoch 61: Validation loss decreased (0.477943 --> 0.477519).  Saving model ...
	 Train_Loss: 0.4932 Train_Acc: 76.079 Val_Loss: 0.4775  BEST VAL Loss: 0.4775  Val_Acc: 77.773

Epoch 62: Validation loss decreased (0.477519 --> 0.477117).  Saving model ...
	 Train_Loss: 0.4926 Train_Acc: 76.143 Val_Loss: 0.4771  BEST VAL Loss: 0.4771  Val_Acc: 77.931

Epoch 63: Validation loss decreased (0.477117 --> 0.476722).  Saving model ...
	 Train_Loss: 0.4921 Train_Acc: 76.080 Val_Loss: 0.4767  BEST VAL Loss: 0.4767  Val_Acc: 78.246

Epoch 64: Validation loss decreased (0.476722 --> 0.476357).  Saving model ...
	 Train_Loss: 0.4916 Train_Acc: 76.094 Val_Loss: 0.4764  BEST VAL Loss: 0.4764  Val_Acc: 77.954

Epoch 65: Validation loss decreased (0.476357 --> 0.475964).  Saving model ...
	 Train_Loss: 0.4910 Train_Acc: 76.213 Val_Loss: 0.4760  BEST VAL Loss: 0.4760  Val_Acc: 78.116

Epoch 66: Validation loss decreased (0.475964 --> 0.475582).  Saving model ...
	 Train_Loss: 0.4905 Train_Acc: 76.155 Val_Loss: 0.4756  BEST VAL Loss: 0.4756  Val_Acc: 77.999

Epoch 67: Validation loss decreased (0.475582 --> 0.475233).  Saving model ...
	 Train_Loss: 0.4900 Train_Acc: 76.117 Val_Loss: 0.4752  BEST VAL Loss: 0.4752  Val_Acc: 78.120

Epoch 68: Validation loss decreased (0.475233 --> 0.474864).  Saving model ...
	 Train_Loss: 0.4895 Train_Acc: 76.057 Val_Loss: 0.4749  BEST VAL Loss: 0.4749  Val_Acc: 78.012

Epoch 69: Validation loss decreased (0.474864 --> 0.474494).  Saving model ...
	 Train_Loss: 0.4891 Train_Acc: 76.216 Val_Loss: 0.4745  BEST VAL Loss: 0.4745  Val_Acc: 77.899

Epoch 70: Validation loss decreased (0.474494 --> 0.474135).  Saving model ...
	 Train_Loss: 0.4886 Train_Acc: 76.282 Val_Loss: 0.4741  BEST VAL Loss: 0.4741  Val_Acc: 78.084

Epoch 71: Validation loss decreased (0.474135 --> 0.473844).  Saving model ...
	 Train_Loss: 0.4881 Train_Acc: 76.203 Val_Loss: 0.4738  BEST VAL Loss: 0.4738  Val_Acc: 77.791

Epoch 72: Validation loss decreased (0.473844 --> 0.473498).  Saving model ...
	 Train_Loss: 0.4876 Train_Acc: 76.163 Val_Loss: 0.4735  BEST VAL Loss: 0.4735  Val_Acc: 78.129

Epoch 73: Validation loss decreased (0.473498 --> 0.473150).  Saving model ...
	 Train_Loss: 0.4872 Train_Acc: 76.277 Val_Loss: 0.4732  BEST VAL Loss: 0.4732  Val_Acc: 78.098

Epoch 74: Validation loss decreased (0.473150 --> 0.472790).  Saving model ...
	 Train_Loss: 0.4867 Train_Acc: 76.253 Val_Loss: 0.4728  BEST VAL Loss: 0.4728  Val_Acc: 78.219

Epoch 75: Validation loss decreased (0.472790 --> 0.472463).  Saving model ...
	 Train_Loss: 0.4863 Train_Acc: 76.412 Val_Loss: 0.4725  BEST VAL Loss: 0.4725  Val_Acc: 78.255

Epoch 76: Validation loss decreased (0.472463 --> 0.472155).  Saving model ...
	 Train_Loss: 0.4858 Train_Acc: 76.359 Val_Loss: 0.4722  BEST VAL Loss: 0.4722  Val_Acc: 78.089

Epoch 77: Validation loss decreased (0.472155 --> 0.471911).  Saving model ...
	 Train_Loss: 0.4854 Train_Acc: 76.413 Val_Loss: 0.4719  BEST VAL Loss: 0.4719  Val_Acc: 78.192

Epoch 78: Validation loss decreased (0.471911 --> 0.471610).  Saving model ...
	 Train_Loss: 0.4850 Train_Acc: 76.384 Val_Loss: 0.4716  BEST VAL Loss: 0.4716  Val_Acc: 78.255

Epoch 79: Validation loss decreased (0.471610 --> 0.471302).  Saving model ...
	 Train_Loss: 0.4846 Train_Acc: 76.440 Val_Loss: 0.4713  BEST VAL Loss: 0.4713  Val_Acc: 78.269

Epoch 80: Validation loss decreased (0.471302 --> 0.471009).  Saving model ...
	 Train_Loss: 0.4841 Train_Acc: 76.502 Val_Loss: 0.4710  BEST VAL Loss: 0.4710  Val_Acc: 78.201

Epoch 81: Validation loss decreased (0.471009 --> 0.470726).  Saving model ...
	 Train_Loss: 0.4837 Train_Acc: 76.438 Val_Loss: 0.4707  BEST VAL Loss: 0.4707  Val_Acc: 78.138

Epoch 82: Validation loss decreased (0.470726 --> 0.470451).  Saving model ...
	 Train_Loss: 0.4834 Train_Acc: 76.342 Val_Loss: 0.4705  BEST VAL Loss: 0.4705  Val_Acc: 78.183

Epoch 83: Validation loss decreased (0.470451 --> 0.470191).  Saving model ...
	 Train_Loss: 0.4830 Train_Acc: 76.402 Val_Loss: 0.4702  BEST VAL Loss: 0.4702  Val_Acc: 78.233

Epoch 84: Validation loss decreased (0.470191 --> 0.469934).  Saving model ...
	 Train_Loss: 0.4826 Train_Acc: 76.463 Val_Loss: 0.4699  BEST VAL Loss: 0.4699  Val_Acc: 78.350

Epoch 85: Validation loss decreased (0.469934 --> 0.469711).  Saving model ...
	 Train_Loss: 0.4822 Train_Acc: 76.324 Val_Loss: 0.4697  BEST VAL Loss: 0.4697  Val_Acc: 78.075

Epoch 86: Validation loss decreased (0.469711 --> 0.469450).  Saving model ...
	 Train_Loss: 0.4818 Train_Acc: 76.545 Val_Loss: 0.4695  BEST VAL Loss: 0.4695  Val_Acc: 78.237

Epoch 87: Validation loss decreased (0.469450 --> 0.469194).  Saving model ...
	 Train_Loss: 0.4815 Train_Acc: 76.453 Val_Loss: 0.4692  BEST VAL Loss: 0.4692  Val_Acc: 78.264

Epoch 88: Validation loss decreased (0.469194 --> 0.468957).  Saving model ...
	 Train_Loss: 0.4811 Train_Acc: 76.517 Val_Loss: 0.4690  BEST VAL Loss: 0.4690  Val_Acc: 78.179

Epoch 89: Validation loss decreased (0.468957 --> 0.468750).  Saving model ...
	 Train_Loss: 0.4807 Train_Acc: 76.489 Val_Loss: 0.4688  BEST VAL Loss: 0.4688  Val_Acc: 78.044

Epoch 90: Validation loss decreased (0.468750 --> 0.468492).  Saving model ...
	 Train_Loss: 0.4804 Train_Acc: 76.569 Val_Loss: 0.4685  BEST VAL Loss: 0.4685  Val_Acc: 78.517

Epoch 91: Validation loss decreased (0.468492 --> 0.468260).  Saving model ...
	 Train_Loss: 0.4800 Train_Acc: 76.415 Val_Loss: 0.4683  BEST VAL Loss: 0.4683  Val_Acc: 78.183

Epoch 92: Validation loss decreased (0.468260 --> 0.468018).  Saving model ...
	 Train_Loss: 0.4797 Train_Acc: 76.467 Val_Loss: 0.4680  BEST VAL Loss: 0.4680  Val_Acc: 78.260

Epoch 93: Validation loss decreased (0.468018 --> 0.467806).  Saving model ...
	 Train_Loss: 0.4794 Train_Acc: 76.631 Val_Loss: 0.4678  BEST VAL Loss: 0.4678  Val_Acc: 78.282

Epoch 94: Validation loss decreased (0.467806 --> 0.467576).  Saving model ...
	 Train_Loss: 0.4790 Train_Acc: 76.474 Val_Loss: 0.4676  BEST VAL Loss: 0.4676  Val_Acc: 78.197

Epoch 95: Validation loss decreased (0.467576 --> 0.467347).  Saving model ...
	 Train_Loss: 0.4787 Train_Acc: 76.632 Val_Loss: 0.4673  BEST VAL Loss: 0.4673  Val_Acc: 78.355

Epoch 96: Validation loss decreased (0.467347 --> 0.467119).  Saving model ...
	 Train_Loss: 0.4784 Train_Acc: 76.543 Val_Loss: 0.4671  BEST VAL Loss: 0.4671  Val_Acc: 78.494

Epoch 97: Validation loss decreased (0.467119 --> 0.466906).  Saving model ...
	 Train_Loss: 0.4780 Train_Acc: 76.598 Val_Loss: 0.4669  BEST VAL Loss: 0.4669  Val_Acc: 78.400

Epoch 98: Validation loss decreased (0.466906 --> 0.466701).  Saving model ...
	 Train_Loss: 0.4777 Train_Acc: 76.501 Val_Loss: 0.4667  BEST VAL Loss: 0.4667  Val_Acc: 78.129

Epoch 99: Validation loss decreased (0.466701 --> 0.466486).  Saving model ...
	 Train_Loss: 0.4774 Train_Acc: 76.614 Val_Loss: 0.4665  BEST VAL Loss: 0.4665  Val_Acc: 78.625

LPS_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.83      0.72      0.77     79796
           1       0.79      0.88      0.84     97754

    accuracy                           0.81    177550
   macro avg       0.81      0.80      0.80    177550
weighted avg       0.81      0.81      0.81    177550

LPS_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.80      0.69      0.74      9975
           1       0.77      0.86      0.82     12219

    accuracy                           0.79     22194
   macro avg       0.79      0.78      0.78     22194
weighted avg       0.79      0.79      0.78     22194

LPS_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.80      0.70      0.74      9975
           1       0.78      0.86      0.81     12219

    accuracy                           0.78     22194
   macro avg       0.79      0.78      0.78     22194
weighted avg       0.79      0.78      0.78     22194

              precision    recall  f1-score   support

           0       0.80      0.70      0.74      9975
           1       0.78      0.86      0.81     12219

    accuracy                           0.78     22194
   macro avg       0.79      0.78      0.78     22194
weighted avg       0.79      0.78      0.78     22194

LPS_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.41      0.18      0.25     39687
           1       0.45      0.73      0.56     37243

    accuracy                           0.44     76930
   macro avg       0.43      0.45      0.40     76930
weighted avg       0.43      0.44      0.40     76930

              precision    recall  f1-score   support

           0       0.41      0.18      0.25     39687
           1       0.45      0.73      0.56     37243

    accuracy                           0.44     76930
   macro avg       0.43      0.45      0.40     76930
weighted avg       0.43      0.44      0.40     76930

completed
