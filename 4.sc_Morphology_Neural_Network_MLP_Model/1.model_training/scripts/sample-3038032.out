[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '6b8cc285'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'd538f076'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '3e60d9cd'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '6244a3e0'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_10.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (30462, 1276)
Number of total missing values across all columns: 33620
Data Subset Is Off
Wells held out for testing: ['E20' 'L16']
Wells to use for training, validation, and testing ['E16' 'E17' 'E21' 'L17' 'L20' 'L21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.272706).  Saving model ...
	 Train_Loss: 0.5289 Train_Acc: 69.636 Val_Loss: 0.2727  BEST VAL Loss: 0.2727  Val_Acc: 91.272

Epoch 1: Validation loss decreased (0.272706 --> 0.243408).  Saving model ...
	 Train_Loss: 0.4484 Train_Acc: 81.851 Val_Loss: 0.2434  BEST VAL Loss: 0.2434  Val_Acc: 92.379

Epoch 2: Validation loss decreased (0.243408 --> 0.222704).  Saving model ...
	 Train_Loss: 0.4025 Train_Acc: 87.857 Val_Loss: 0.2227  BEST VAL Loss: 0.2227  Val_Acc: 93.930

Epoch 3: Validation loss decreased (0.222704 --> 0.209013).  Saving model ...
	 Train_Loss: 0.3718 Train_Acc: 89.114 Val_Loss: 0.2090  BEST VAL Loss: 0.2090  Val_Acc: 95.082

Epoch 4: Validation loss decreased (0.209013 --> 0.199813).  Saving model ...
	 Train_Loss: 0.3492 Train_Acc: 90.350 Val_Loss: 0.1998  BEST VAL Loss: 0.1998  Val_Acc: 94.949

Epoch 5: Validation loss decreased (0.199813 --> 0.188713).  Saving model ...
	 Train_Loss: 0.3328 Train_Acc: 90.488 Val_Loss: 0.1887  BEST VAL Loss: 0.1887  Val_Acc: 95.525

Epoch 6: Validation loss decreased (0.188713 --> 0.180614).  Saving model ...
	 Train_Loss: 0.3190 Train_Acc: 91.275 Val_Loss: 0.1806  BEST VAL Loss: 0.1806  Val_Acc: 95.658

Epoch 7: Validation loss decreased (0.180614 --> 0.174482).  Saving model ...
	 Train_Loss: 0.3067 Train_Acc: 91.485 Val_Loss: 0.1745  BEST VAL Loss: 0.1745  Val_Acc: 95.702

Epoch 8: Validation loss decreased (0.174482 --> 0.167407).  Saving model ...
	 Train_Loss: 0.2958 Train_Acc: 92.200 Val_Loss: 0.1674  BEST VAL Loss: 0.1674  Val_Acc: 96.455

Epoch 9: Validation loss decreased (0.167407 --> 0.162939).  Saving model ...
	 Train_Loss: 0.2880 Train_Acc: 92.189 Val_Loss: 0.1629  BEST VAL Loss: 0.1629  Val_Acc: 95.968

Epoch 10: Validation loss decreased (0.162939 --> 0.157996).  Saving model ...
	 Train_Loss: 0.2811 Train_Acc: 92.078 Val_Loss: 0.1580  BEST VAL Loss: 0.1580  Val_Acc: 96.190

Epoch 11: Validation loss decreased (0.157996 --> 0.154113).  Saving model ...
	 Train_Loss: 0.2750 Train_Acc: 92.183 Val_Loss: 0.1541  BEST VAL Loss: 0.1541  Val_Acc: 96.234

Epoch 12: Validation loss decreased (0.154113 --> 0.150986).  Saving model ...
	 Train_Loss: 0.2697 Train_Acc: 91.995 Val_Loss: 0.1510  BEST VAL Loss: 0.1510  Val_Acc: 96.101

Epoch 13: Validation loss decreased (0.150986 --> 0.147866).  Saving model ...
	 Train_Loss: 0.2651 Train_Acc: 92.372 Val_Loss: 0.1479  BEST VAL Loss: 0.1479  Val_Acc: 96.544

Epoch 14: Validation loss decreased (0.147866 --> 0.144624).  Saving model ...
	 Train_Loss: 0.2608 Train_Acc: 92.277 Val_Loss: 0.1446  BEST VAL Loss: 0.1446  Val_Acc: 96.544

Epoch 15: Validation loss decreased (0.144624 --> 0.142121).  Saving model ...
	 Train_Loss: 0.2561 Train_Acc: 92.887 Val_Loss: 0.1421  BEST VAL Loss: 0.1421  Val_Acc: 96.278

Epoch 16: Validation loss decreased (0.142121 --> 0.139506).  Saving model ...
	 Train_Loss: 0.2523 Train_Acc: 92.754 Val_Loss: 0.1395  BEST VAL Loss: 0.1395  Val_Acc: 96.544

Epoch 17: Validation loss decreased (0.139506 --> 0.137368).  Saving model ...
	 Train_Loss: 0.2486 Train_Acc: 92.815 Val_Loss: 0.1374  BEST VAL Loss: 0.1374  Val_Acc: 96.766

Epoch 18: Validation loss decreased (0.137368 --> 0.135755).  Saving model ...
	 Train_Loss: 0.2462 Train_Acc: 92.327 Val_Loss: 0.1358  BEST VAL Loss: 0.1358  Val_Acc: 96.500

Epoch 19: Validation loss decreased (0.135755 --> 0.134259).  Saving model ...
	 Train_Loss: 0.2431 Train_Acc: 92.948 Val_Loss: 0.1343  BEST VAL Loss: 0.1343  Val_Acc: 96.810

Epoch 20: Validation loss decreased (0.134259 --> 0.132929).  Saving model ...
	 Train_Loss: 0.2399 Train_Acc: 93.219 Val_Loss: 0.1329  BEST VAL Loss: 0.1329  Val_Acc: 97.120

Epoch 21: Validation loss decreased (0.132929 --> 0.131709).  Saving model ...
	 Train_Loss: 0.2372 Train_Acc: 93.114 Val_Loss: 0.1317  BEST VAL Loss: 0.1317  Val_Acc: 96.943

Epoch 22: Validation loss decreased (0.131709 --> 0.129996).  Saving model ...
	 Train_Loss: 0.2348 Train_Acc: 93.236 Val_Loss: 0.1300  BEST VAL Loss: 0.1300  Val_Acc: 97.475

Epoch 23: Validation loss decreased (0.129996 --> 0.128704).  Saving model ...
	 Train_Loss: 0.2323 Train_Acc: 93.247 Val_Loss: 0.1287  BEST VAL Loss: 0.1287  Val_Acc: 97.120

Epoch 24: Validation loss decreased (0.128704 --> 0.127543).  Saving model ...
	 Train_Loss: 0.2299 Train_Acc: 93.352 Val_Loss: 0.1275  BEST VAL Loss: 0.1275  Val_Acc: 96.899

Epoch 25: Validation loss decreased (0.127543 --> 0.126183).  Saving model ...
	 Train_Loss: 0.2278 Train_Acc: 92.909 Val_Loss: 0.1262  BEST VAL Loss: 0.1262  Val_Acc: 97.297

Epoch 26: Validation loss decreased (0.126183 --> 0.124846).  Saving model ...
	 Train_Loss: 0.2259 Train_Acc: 93.319 Val_Loss: 0.1248  BEST VAL Loss: 0.1248  Val_Acc: 96.987

Epoch 27: Validation loss decreased (0.124846 --> 0.123505).  Saving model ...
	 Train_Loss: 0.2242 Train_Acc: 93.142 Val_Loss: 0.1235  BEST VAL Loss: 0.1235  Val_Acc: 97.120

Epoch 28: Validation loss decreased (0.123505 --> 0.122498).  Saving model ...
	 Train_Loss: 0.2222 Train_Acc: 93.419 Val_Loss: 0.1225  BEST VAL Loss: 0.1225  Val_Acc: 96.633

Epoch 29: Validation loss decreased (0.122498 --> 0.121461).  Saving model ...
	 Train_Loss: 0.2205 Train_Acc: 93.297 Val_Loss: 0.1215  BEST VAL Loss: 0.1215  Val_Acc: 97.386

Epoch 30: Validation loss decreased (0.121461 --> 0.120484).  Saving model ...
	 Train_Loss: 0.2189 Train_Acc: 93.413 Val_Loss: 0.1205  BEST VAL Loss: 0.1205  Val_Acc: 97.209

Epoch 31: Validation loss decreased (0.120484 --> 0.119721).  Saving model ...
	 Train_Loss: 0.2176 Train_Acc: 93.446 Val_Loss: 0.1197  BEST VAL Loss: 0.1197  Val_Acc: 96.943

Epoch 32: Validation loss decreased (0.119721 --> 0.118689).  Saving model ...
	 Train_Loss: 0.2160 Train_Acc: 93.469 Val_Loss: 0.1187  BEST VAL Loss: 0.1187  Val_Acc: 96.899

Epoch 33: Validation loss decreased (0.118689 --> 0.117687).  Saving model ...
	 Train_Loss: 0.2147 Train_Acc: 93.507 Val_Loss: 0.1177  BEST VAL Loss: 0.1177  Val_Acc: 97.209

Epoch 34: Validation loss decreased (0.117687 --> 0.116878).  Saving model ...
	 Train_Loss: 0.2133 Train_Acc: 93.524 Val_Loss: 0.1169  BEST VAL Loss: 0.1169  Val_Acc: 97.519

Epoch 35: Validation loss decreased (0.116878 --> 0.116497).  Saving model ...
	 Train_Loss: 0.2120 Train_Acc: 93.601 Val_Loss: 0.1165  BEST VAL Loss: 0.1165  Val_Acc: 96.810

Epoch 36: Validation loss decreased (0.116497 --> 0.116086).  Saving model ...
	 Train_Loss: 0.2106 Train_Acc: 93.873 Val_Loss: 0.1161  BEST VAL Loss: 0.1161  Val_Acc: 97.209

Epoch 37: Validation loss decreased (0.116086 --> 0.115396).  Saving model ...
	 Train_Loss: 0.2094 Train_Acc: 93.840 Val_Loss: 0.1154  BEST VAL Loss: 0.1154  Val_Acc: 97.297

Epoch 38: Validation loss decreased (0.115396 --> 0.114804).  Saving model ...
	 Train_Loss: 0.2081 Train_Acc: 93.596 Val_Loss: 0.1148  BEST VAL Loss: 0.1148  Val_Acc: 97.209

Epoch 39: Validation loss decreased (0.114804 --> 0.114422).  Saving model ...
	 Train_Loss: 0.2070 Train_Acc: 93.441 Val_Loss: 0.1144  BEST VAL Loss: 0.1144  Val_Acc: 97.475

Epoch 40: Validation loss decreased (0.114422 --> 0.114356).  Saving model ...
	 Train_Loss: 0.2059 Train_Acc: 93.806 Val_Loss: 0.1144  BEST VAL Loss: 0.1144  Val_Acc: 97.253

Epoch 41: Validation loss decreased (0.114356 --> 0.113718).  Saving model ...
	 Train_Loss: 0.2049 Train_Acc: 93.585 Val_Loss: 0.1137  BEST VAL Loss: 0.1137  Val_Acc: 97.652

Epoch 42: Validation loss decreased (0.113718 --> 0.113347).  Saving model ...
	 Train_Loss: 0.2038 Train_Acc: 93.452 Val_Loss: 0.1133  BEST VAL Loss: 0.1133  Val_Acc: 97.031

Epoch 43: Validation loss decreased (0.113347 --> 0.112855).  Saving model ...
	 Train_Loss: 0.2029 Train_Acc: 93.701 Val_Loss: 0.1129  BEST VAL Loss: 0.1129  Val_Acc: 97.430

Epoch 44: Validation loss decreased (0.112855 --> 0.112526).  Saving model ...
	 Train_Loss: 0.2020 Train_Acc: 93.585 Val_Loss: 0.1125  BEST VAL Loss: 0.1125  Val_Acc: 97.652

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.2011 Train_Acc: 93.524 Val_Loss: 0.1127  BEST VAL Loss: 0.1125  Val_Acc: 96.987

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.2002 Train_Acc: 93.956 Val_Loss: 0.1127  BEST VAL Loss: 0.1125  Val_Acc: 97.164

Epoch 47: Validation loss decreased (0.112526 --> 0.112414).  Saving model ...
	 Train_Loss: 0.1992 Train_Acc: 94.095 Val_Loss: 0.1124  BEST VAL Loss: 0.1124  Val_Acc: 97.164

Epoch 48: Validation loss decreased (0.112414 --> 0.112074).  Saving model ...
	 Train_Loss: 0.1984 Train_Acc: 93.795 Val_Loss: 0.1121  BEST VAL Loss: 0.1121  Val_Acc: 97.031

Epoch 49: Validation loss decreased (0.112074 --> 0.111876).  Saving model ...
	 Train_Loss: 0.1976 Train_Acc: 93.806 Val_Loss: 0.1119  BEST VAL Loss: 0.1119  Val_Acc: 97.297

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.1970 Train_Acc: 93.396 Val_Loss: 0.1119  BEST VAL Loss: 0.1119  Val_Acc: 97.031

Epoch 51: Validation loss decreased (0.111876 --> 0.111744).  Saving model ...
	 Train_Loss: 0.1963 Train_Acc: 93.662 Val_Loss: 0.1117  BEST VAL Loss: 0.1117  Val_Acc: 97.120

Epoch 52: Validation loss decreased (0.111744 --> 0.111619).  Saving model ...
	 Train_Loss: 0.1957 Train_Acc: 93.485 Val_Loss: 0.1116  BEST VAL Loss: 0.1116  Val_Acc: 97.164

Epoch 53: Validation loss decreased (0.111619 --> 0.111293).  Saving model ...
	 Train_Loss: 0.1949 Train_Acc: 93.829 Val_Loss: 0.1113  BEST VAL Loss: 0.1113  Val_Acc: 97.563

Epoch 54: Validation loss decreased (0.111293 --> 0.110870).  Saving model ...
	 Train_Loss: 0.1942 Train_Acc: 93.829 Val_Loss: 0.1109  BEST VAL Loss: 0.1109  Val_Acc: 97.297

Epoch 55: Validation loss decreased (0.110870 --> 0.110707).  Saving model ...
	 Train_Loss: 0.1933 Train_Acc: 93.973 Val_Loss: 0.1107  BEST VAL Loss: 0.1107  Val_Acc: 97.430

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.1926 Train_Acc: 94.061 Val_Loss: 0.1108  BEST VAL Loss: 0.1107  Val_Acc: 96.500

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.1934 Train_Acc: 89.319 Val_Loss: 0.1109  BEST VAL Loss: 0.1107  Val_Acc: 96.057

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.1935 Train_Acc: 91.712 Val_Loss: 0.1107  BEST VAL Loss: 0.1107  Val_Acc: 97.342

Epoch 59: Validation loss decreased (0.110707 --> 0.110671).  Saving model ...
	 Train_Loss: 0.1933 Train_Acc: 92.455 Val_Loss: 0.1107  BEST VAL Loss: 0.1107  Val_Acc: 96.987

Epoch 60: Validation loss decreased (0.110671 --> 0.110562).  Saving model ...
	 Train_Loss: 0.1928 Train_Acc: 93.036 Val_Loss: 0.1106  BEST VAL Loss: 0.1106  Val_Acc: 97.076

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.1922 Train_Acc: 93.601 Val_Loss: 0.1106  BEST VAL Loss: 0.1106  Val_Acc: 97.076

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.1915 Train_Acc: 93.502 Val_Loss: 0.1107  BEST VAL Loss: 0.1106  Val_Acc: 97.076

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.1909 Train_Acc: 93.651 Val_Loss: 0.1108  BEST VAL Loss: 0.1106  Val_Acc: 97.297

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.1904 Train_Acc: 93.585 Val_Loss: 0.1109  BEST VAL Loss: 0.1106  Val_Acc: 97.430

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.1898 Train_Acc: 93.867 Val_Loss: 0.1107  BEST VAL Loss: 0.1106  Val_Acc: 97.164

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.1891 Train_Acc: 93.890 Val_Loss: 0.1106  BEST VAL Loss: 0.1106  Val_Acc: 97.253

Epoch 67: Validation loss decreased (0.110562 --> 0.110541).  Saving model ...
	 Train_Loss: 0.1884 Train_Acc: 93.840 Val_Loss: 0.1105  BEST VAL Loss: 0.1105  Val_Acc: 96.987

Epoch 68: Validation loss decreased (0.110541 --> 0.110492).  Saving model ...
	 Train_Loss: 0.1877 Train_Acc: 94.095 Val_Loss: 0.1105  BEST VAL Loss: 0.1105  Val_Acc: 97.430

Epoch 69: Validation loss decreased (0.110492 --> 0.110119).  Saving model ...
	 Train_Loss: 0.1870 Train_Acc: 94.050 Val_Loss: 0.1101  BEST VAL Loss: 0.1101  Val_Acc: 97.696

Epoch 70: Validation loss decreased (0.110119 --> 0.109840).  Saving model ...
	 Train_Loss: 0.1864 Train_Acc: 93.978 Val_Loss: 0.1098  BEST VAL Loss: 0.1098  Val_Acc: 97.475

Epoch 71: Validation loss decreased (0.109840 --> 0.109805).  Saving model ...
	 Train_Loss: 0.1857 Train_Acc: 94.316 Val_Loss: 0.1098  BEST VAL Loss: 0.1098  Val_Acc: 97.430

Epoch 72: Validation loss decreased (0.109805 --> 0.109729).  Saving model ...
	 Train_Loss: 0.1851 Train_Acc: 94.034 Val_Loss: 0.1097  BEST VAL Loss: 0.1097  Val_Acc: 97.342

Epoch 73: Validation loss decreased (0.109729 --> 0.109658).  Saving model ...
	 Train_Loss: 0.1844 Train_Acc: 94.172 Val_Loss: 0.1097  BEST VAL Loss: 0.1097  Val_Acc: 97.563

Epoch 74: Validation loss decreased (0.109658 --> 0.109596).  Saving model ...
	 Train_Loss: 0.1838 Train_Acc: 94.128 Val_Loss: 0.1096  BEST VAL Loss: 0.1096  Val_Acc: 97.297

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.1831 Train_Acc: 94.344 Val_Loss: 0.1097  BEST VAL Loss: 0.1096  Val_Acc: 97.297

Epoch 76: Validation loss decreased (0.109596 --> 0.109498).  Saving model ...
	 Train_Loss: 0.1827 Train_Acc: 93.070 Val_Loss: 0.1095  BEST VAL Loss: 0.1095  Val_Acc: 96.987

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.1822 Train_Acc: 93.707 Val_Loss: 0.1097  BEST VAL Loss: 0.1095  Val_Acc: 97.164

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.1817 Train_Acc: 94.045 Val_Loss: 0.1097  BEST VAL Loss: 0.1095  Val_Acc: 97.475

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.1810 Train_Acc: 94.222 Val_Loss: 0.1098  BEST VAL Loss: 0.1095  Val_Acc: 97.386

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.1804 Train_Acc: 94.155 Val_Loss: 0.1101  BEST VAL Loss: 0.1095  Val_Acc: 97.253

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.1798 Train_Acc: 94.039 Val_Loss: 0.1103  BEST VAL Loss: 0.1095  Val_Acc: 97.652

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.1793 Train_Acc: 94.117 Val_Loss: 0.1104  BEST VAL Loss: 0.1095  Val_Acc: 97.563

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.1787 Train_Acc: 94.554 Val_Loss: 0.1105  BEST VAL Loss: 0.1095  Val_Acc: 97.342

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.1781 Train_Acc: 94.588 Val_Loss: 0.1106  BEST VAL Loss: 0.1095  Val_Acc: 97.563

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.1775 Train_Acc: 94.133 Val_Loss: 0.1106  BEST VAL Loss: 0.1095  Val_Acc: 97.386

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.1769 Train_Acc: 94.610 Val_Loss: 0.1110  BEST VAL Loss: 0.1095  Val_Acc: 97.209

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.1764 Train_Acc: 94.117 Val_Loss: 0.1113  BEST VAL Loss: 0.1095  Val_Acc: 97.297

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.1758 Train_Acc: 94.449 Val_Loss: 0.1114  BEST VAL Loss: 0.1095  Val_Acc: 97.120

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.1753 Train_Acc: 94.466 Val_Loss: 0.1116  BEST VAL Loss: 0.1095  Val_Acc: 97.519

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.1747 Train_Acc: 94.405 Val_Loss: 0.1116  BEST VAL Loss: 0.1095  Val_Acc: 97.475

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.1742 Train_Acc: 94.416 Val_Loss: 0.1117  BEST VAL Loss: 0.1095  Val_Acc: 97.519

Epoch 92: Validation loss did not decrease
Early stopped at epoch : 92
LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      0.98      0.99     10113
           1       0.98      0.99      0.98      7938

    accuracy                           0.99     18051
   macro avg       0.99      0.99      0.99     18051
weighted avg       0.99      0.99      0.99     18051

LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.96      0.97      1264
           1       0.95      0.98      0.97       993

    accuracy                           0.97      2257
   macro avg       0.97      0.97      0.97      2257
weighted avg       0.97      0.97      0.97      2257

LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.96      0.97      1265
           1       0.96      0.97      0.96       992

    accuracy                           0.97      2257
   macro avg       0.97      0.97      0.97      2257
weighted avg       0.97      0.97      0.97      2257

              precision    recall  f1-score   support

           0       0.98      0.96      0.97      1265
           1       0.96      0.97      0.96       992

    accuracy                           0.97      2257
   macro avg       0.97      0.97      0.97      2257
weighted avg       0.97      0.97      0.97      2257

LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.95      0.96      0.96      4168
           1       0.95      0.95      0.95      3729

    accuracy                           0.95      7897
   macro avg       0.95      0.95      0.95      7897
weighted avg       0.95      0.95      0.95      7897

              precision    recall  f1-score   support

           0       0.95      0.96      0.96      4168
           1       0.95      0.95      0.95      3729

    accuracy                           0.95      7897
   macro avg       0.95      0.95      0.95      7897
weighted avg       0.95      0.95      0.95      7897

completed
