[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd35a5fbf'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'cb7999cb'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'f1798b06'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '6fb0a407'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: H2O2_100.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['H2O2_100.000_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (41302, 1276)
Number of total missing values across all columns: 53800
Data Subset Is Off
Wells held out for testing: ['H22' 'M16']
Wells to use for training, validation, and testing ['H18' 'H19' 'H23' 'M17' 'I18' 'I19' 'M20' 'M21' 'I22' 'I23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.618118).  Saving model ...
	 Train_Loss: 0.6381 Train_Acc: 68.283 Val_Loss: 0.6181  BEST VAL Loss: 0.6181  Val_Acc: 68.290

Epoch 1: Validation loss decreased (0.618118 --> 0.572689).  Saving model ...
	 Train_Loss: 0.6145 Train_Acc: 71.969 Val_Loss: 0.5727  BEST VAL Loss: 0.5727  Val_Acc: 80.463

Epoch 2: Validation loss decreased (0.572689 --> 0.530979).  Saving model ...
	 Train_Loss: 0.5810 Train_Acc: 79.962 Val_Loss: 0.5310  BEST VAL Loss: 0.5310  Val_Acc: 88.398

Epoch 3: Validation loss decreased (0.530979 --> 0.493274).  Saving model ...
	 Train_Loss: 0.5536 Train_Acc: 81.548 Val_Loss: 0.4933  BEST VAL Loss: 0.4933  Val_Acc: 90.592

Epoch 4: Validation loss decreased (0.493274 --> 0.459243).  Saving model ...
	 Train_Loss: 0.5296 Train_Acc: 82.187 Val_Loss: 0.4592  BEST VAL Loss: 0.4592  Val_Acc: 92.095

Epoch 5: Validation loss decreased (0.459243 --> 0.431858).  Saving model ...
	 Train_Loss: 0.5087 Train_Acc: 83.130 Val_Loss: 0.4319  BEST VAL Loss: 0.4319  Val_Acc: 92.786

Epoch 6: Validation loss decreased (0.431858 --> 0.408299).  Saving model ...
	 Train_Loss: 0.4908 Train_Acc: 83.743 Val_Loss: 0.4083  BEST VAL Loss: 0.4083  Val_Acc: 93.538

Epoch 7: Validation loss decreased (0.408299 --> 0.387152).  Saving model ...
	 Train_Loss: 0.4760 Train_Acc: 83.792 Val_Loss: 0.3872  BEST VAL Loss: 0.3872  Val_Acc: 94.169

Epoch 8: Validation loss decreased (0.387152 --> 0.369002).  Saving model ...
	 Train_Loss: 0.4628 Train_Acc: 84.506 Val_Loss: 0.3690  BEST VAL Loss: 0.3690  Val_Acc: 94.560

Epoch 9: Validation loss decreased (0.369002 --> 0.353432).  Saving model ...
	 Train_Loss: 0.4514 Train_Acc: 84.438 Val_Loss: 0.3534  BEST VAL Loss: 0.3534  Val_Acc: 94.980

Epoch 10: Validation loss decreased (0.353432 --> 0.339221).  Saving model ...
	 Train_Loss: 0.4412 Train_Acc: 84.660 Val_Loss: 0.3392  BEST VAL Loss: 0.3392  Val_Acc: 95.642

Epoch 11: Validation loss decreased (0.339221 --> 0.325917).  Saving model ...
	 Train_Loss: 0.4318 Train_Acc: 84.934 Val_Loss: 0.3259  BEST VAL Loss: 0.3259  Val_Acc: 95.762

Epoch 12: Validation loss decreased (0.325917 --> 0.315094).  Saving model ...
	 Train_Loss: 0.4234 Train_Acc: 84.837 Val_Loss: 0.3151  BEST VAL Loss: 0.3151  Val_Acc: 95.882

Epoch 13: Validation loss decreased (0.315094 --> 0.304924).  Saving model ...
	 Train_Loss: 0.4154 Train_Acc: 85.194 Val_Loss: 0.3049  BEST VAL Loss: 0.3049  Val_Acc: 96.002

Epoch 14: Validation loss decreased (0.304924 --> 0.295195).  Saving model ...
	 Train_Loss: 0.4078 Train_Acc: 85.415 Val_Loss: 0.2952  BEST VAL Loss: 0.2952  Val_Acc: 95.882

Epoch 15: Validation loss decreased (0.295195 --> 0.286305).  Saving model ...
	 Train_Loss: 0.4009 Train_Acc: 85.419 Val_Loss: 0.2863  BEST VAL Loss: 0.2863  Val_Acc: 96.273

Epoch 16: Validation loss decreased (0.286305 --> 0.277992).  Saving model ...
	 Train_Loss: 0.3947 Train_Acc: 85.596 Val_Loss: 0.2780  BEST VAL Loss: 0.2780  Val_Acc: 96.573

Epoch 17: Validation loss decreased (0.277992 --> 0.270826).  Saving model ...
	 Train_Loss: 0.3885 Train_Acc: 85.806 Val_Loss: 0.2708  BEST VAL Loss: 0.2708  Val_Acc: 96.183

Epoch 18: Validation loss decreased (0.270826 --> 0.263732).  Saving model ...
	 Train_Loss: 0.3829 Train_Acc: 85.532 Val_Loss: 0.2637  BEST VAL Loss: 0.2637  Val_Acc: 96.453

Epoch 19: Validation loss decreased (0.263732 --> 0.257340).  Saving model ...
	 Train_Loss: 0.3775 Train_Acc: 85.483 Val_Loss: 0.2573  BEST VAL Loss: 0.2573  Val_Acc: 96.604

Epoch 20: Validation loss decreased (0.257340 --> 0.251340).  Saving model ...
	 Train_Loss: 0.3724 Train_Acc: 85.660 Val_Loss: 0.2513  BEST VAL Loss: 0.2513  Val_Acc: 96.604

Epoch 21: Validation loss decreased (0.251340 --> 0.245419).  Saving model ...
	 Train_Loss: 0.3674 Train_Acc: 85.832 Val_Loss: 0.2454  BEST VAL Loss: 0.2454  Val_Acc: 96.694

Epoch 22: Validation loss decreased (0.245419 --> 0.239851).  Saving model ...
	 Train_Loss: 0.3627 Train_Acc: 85.877 Val_Loss: 0.2399  BEST VAL Loss: 0.2399  Val_Acc: 96.814

Epoch 23: Validation loss decreased (0.239851 --> 0.234731).  Saving model ...
	 Train_Loss: 0.3581 Train_Acc: 85.746 Val_Loss: 0.2347  BEST VAL Loss: 0.2347  Val_Acc: 96.604

Epoch 24: Validation loss decreased (0.234731 --> 0.229583).  Saving model ...
	 Train_Loss: 0.3537 Train_Acc: 85.769 Val_Loss: 0.2296  BEST VAL Loss: 0.2296  Val_Acc: 96.543

Epoch 25: Validation loss decreased (0.229583 --> 0.225021).  Saving model ...
	 Train_Loss: 0.3495 Train_Acc: 85.742 Val_Loss: 0.2250  BEST VAL Loss: 0.2250  Val_Acc: 96.664

Epoch 26: Validation loss decreased (0.225021 --> 0.220316).  Saving model ...
	 Train_Loss: 0.3455 Train_Acc: 85.682 Val_Loss: 0.2203  BEST VAL Loss: 0.2203  Val_Acc: 97.115

Epoch 27: Validation loss decreased (0.220316 --> 0.215775).  Saving model ...
	 Train_Loss: 0.3415 Train_Acc: 85.885 Val_Loss: 0.2158  BEST VAL Loss: 0.2158  Val_Acc: 97.115

Epoch 28: Validation loss decreased (0.215775 --> 0.211964).  Saving model ...
	 Train_Loss: 0.3375 Train_Acc: 86.110 Val_Loss: 0.2120  BEST VAL Loss: 0.2120  Val_Acc: 96.754

Epoch 29: Validation loss decreased (0.211964 --> 0.208190).  Saving model ...
	 Train_Loss: 0.3337 Train_Acc: 86.783 Val_Loss: 0.2082  BEST VAL Loss: 0.2082  Val_Acc: 97.054

Epoch 30: Validation loss decreased (0.208190 --> 0.204461).  Saving model ...
	 Train_Loss: 0.3301 Train_Acc: 89.241 Val_Loss: 0.2045  BEST VAL Loss: 0.2045  Val_Acc: 97.145

Epoch 31: Validation loss decreased (0.204461 --> 0.201093).  Saving model ...
	 Train_Loss: 0.3264 Train_Acc: 89.455 Val_Loss: 0.2011  BEST VAL Loss: 0.2011  Val_Acc: 96.543

Epoch 32: Validation loss decreased (0.201093 --> 0.197761).  Saving model ...
	 Train_Loss: 0.3229 Train_Acc: 89.196 Val_Loss: 0.1978  BEST VAL Loss: 0.1978  Val_Acc: 97.084

Epoch 33: Validation loss decreased (0.197761 --> 0.194819).  Saving model ...
	 Train_Loss: 0.3195 Train_Acc: 89.331 Val_Loss: 0.1948  BEST VAL Loss: 0.1948  Val_Acc: 97.265

Epoch 34: Validation loss decreased (0.194819 --> 0.191808).  Saving model ...
	 Train_Loss: 0.3161 Train_Acc: 89.699 Val_Loss: 0.1918  BEST VAL Loss: 0.1918  Val_Acc: 97.295

Epoch 35: Validation loss decreased (0.191808 --> 0.188905).  Saving model ...
	 Train_Loss: 0.3129 Train_Acc: 89.722 Val_Loss: 0.1889  BEST VAL Loss: 0.1889  Val_Acc: 97.205

Epoch 36: Validation loss decreased (0.188905 --> 0.186125).  Saving model ...
	 Train_Loss: 0.3097 Train_Acc: 89.775 Val_Loss: 0.1861  BEST VAL Loss: 0.1861  Val_Acc: 96.874

Epoch 37: Validation loss decreased (0.186125 --> 0.183444).  Saving model ...
	 Train_Loss: 0.3066 Train_Acc: 89.876 Val_Loss: 0.1834  BEST VAL Loss: 0.1834  Val_Acc: 96.964

Epoch 38: Validation loss decreased (0.183444 --> 0.180853).  Saving model ...
	 Train_Loss: 0.3037 Train_Acc: 89.748 Val_Loss: 0.1809  BEST VAL Loss: 0.1809  Val_Acc: 96.964

Epoch 39: Validation loss decreased (0.180853 --> 0.178499).  Saving model ...
	 Train_Loss: 0.3007 Train_Acc: 90.233 Val_Loss: 0.1785  BEST VAL Loss: 0.1785  Val_Acc: 96.904

Epoch 40: Validation loss decreased (0.178499 --> 0.176893).  Saving model ...
	 Train_Loss: 0.2978 Train_Acc: 90.210 Val_Loss: 0.1769  BEST VAL Loss: 0.1769  Val_Acc: 96.573

Epoch 41: Validation loss decreased (0.176893 --> 0.174657).  Saving model ...
	 Train_Loss: 0.2951 Train_Acc: 90.331 Val_Loss: 0.1747  BEST VAL Loss: 0.1747  Val_Acc: 97.024

Epoch 42: Validation loss decreased (0.174657 --> 0.172554).  Saving model ...
	 Train_Loss: 0.2925 Train_Acc: 90.304 Val_Loss: 0.1726  BEST VAL Loss: 0.1726  Val_Acc: 97.115

Epoch 43: Validation loss decreased (0.172554 --> 0.170331).  Saving model ...
	 Train_Loss: 0.2898 Train_Acc: 90.673 Val_Loss: 0.1703  BEST VAL Loss: 0.1703  Val_Acc: 96.994

Epoch 44: Validation loss decreased (0.170331 --> 0.168098).  Saving model ...
	 Train_Loss: 0.2872 Train_Acc: 90.710 Val_Loss: 0.1681  BEST VAL Loss: 0.1681  Val_Acc: 97.325

Epoch 45: Validation loss decreased (0.168098 --> 0.166127).  Saving model ...
	 Train_Loss: 0.2847 Train_Acc: 90.831 Val_Loss: 0.1661  BEST VAL Loss: 0.1661  Val_Acc: 97.265

Epoch 46: Validation loss decreased (0.166127 --> 0.164208).  Saving model ...
	 Train_Loss: 0.2823 Train_Acc: 90.793 Val_Loss: 0.1642  BEST VAL Loss: 0.1642  Val_Acc: 97.054

Epoch 47: Validation loss decreased (0.164208 --> 0.162306).  Saving model ...
	 Train_Loss: 0.2800 Train_Acc: 90.838 Val_Loss: 0.1623  BEST VAL Loss: 0.1623  Val_Acc: 96.874

Epoch 48: Validation loss decreased (0.162306 --> 0.160634).  Saving model ...
	 Train_Loss: 0.2778 Train_Acc: 90.643 Val_Loss: 0.1606  BEST VAL Loss: 0.1606  Val_Acc: 97.265

Epoch 49: Validation loss decreased (0.160634 --> 0.158909).  Saving model ...
	 Train_Loss: 0.2755 Train_Acc: 91.082 Val_Loss: 0.1589  BEST VAL Loss: 0.1589  Val_Acc: 96.874

Epoch 50: Validation loss decreased (0.158909 --> 0.157852).  Saving model ...
	 Train_Loss: 0.2733 Train_Acc: 90.891 Val_Loss: 0.1579  BEST VAL Loss: 0.1579  Val_Acc: 96.694

Epoch 51: Validation loss decreased (0.157852 --> 0.156210).  Saving model ...
	 Train_Loss: 0.2712 Train_Acc: 91.120 Val_Loss: 0.1562  BEST VAL Loss: 0.1562  Val_Acc: 97.145

Epoch 52: Validation loss decreased (0.156210 --> 0.154594).  Saving model ...
	 Train_Loss: 0.2692 Train_Acc: 90.996 Val_Loss: 0.1546  BEST VAL Loss: 0.1546  Val_Acc: 97.115

Epoch 53: Validation loss decreased (0.154594 --> 0.152964).  Saving model ...
	 Train_Loss: 0.2670 Train_Acc: 91.537 Val_Loss: 0.1530  BEST VAL Loss: 0.1530  Val_Acc: 97.415

Epoch 54: Validation loss decreased (0.152964 --> 0.151570).  Saving model ...
	 Train_Loss: 0.2649 Train_Acc: 91.484 Val_Loss: 0.1516  BEST VAL Loss: 0.1516  Val_Acc: 97.295

Epoch 55: Validation loss decreased (0.151570 --> 0.150204).  Saving model ...
	 Train_Loss: 0.2630 Train_Acc: 91.248 Val_Loss: 0.1502  BEST VAL Loss: 0.1502  Val_Acc: 97.355

Epoch 56: Validation loss decreased (0.150204 --> 0.148898).  Saving model ...
	 Train_Loss: 0.2611 Train_Acc: 91.368 Val_Loss: 0.1489  BEST VAL Loss: 0.1489  Val_Acc: 97.205

Epoch 57: Validation loss decreased (0.148898 --> 0.147805).  Saving model ...
	 Train_Loss: 0.2592 Train_Acc: 91.631 Val_Loss: 0.1478  BEST VAL Loss: 0.1478  Val_Acc: 96.694

Epoch 58: Validation loss decreased (0.147805 --> 0.146450).  Saving model ...
	 Train_Loss: 0.2574 Train_Acc: 91.436 Val_Loss: 0.1464  BEST VAL Loss: 0.1464  Val_Acc: 97.505

Epoch 59: Validation loss decreased (0.146450 --> 0.145150).  Saving model ...
	 Train_Loss: 0.2555 Train_Acc: 91.484 Val_Loss: 0.1451  BEST VAL Loss: 0.1451  Val_Acc: 97.235

Epoch 60: Validation loss decreased (0.145150 --> 0.144016).  Saving model ...
	 Train_Loss: 0.2538 Train_Acc: 91.725 Val_Loss: 0.1440  BEST VAL Loss: 0.1440  Val_Acc: 97.235

Epoch 61: Validation loss decreased (0.144016 --> 0.142913).  Saving model ...
	 Train_Loss: 0.2520 Train_Acc: 91.879 Val_Loss: 0.1429  BEST VAL Loss: 0.1429  Val_Acc: 97.115

Epoch 62: Validation loss decreased (0.142913 --> 0.141822).  Saving model ...
	 Train_Loss: 0.2503 Train_Acc: 91.638 Val_Loss: 0.1418  BEST VAL Loss: 0.1418  Val_Acc: 97.265

Epoch 63: Validation loss decreased (0.141822 --> 0.140732).  Saving model ...
	 Train_Loss: 0.2486 Train_Acc: 91.811 Val_Loss: 0.1407  BEST VAL Loss: 0.1407  Val_Acc: 97.265

Epoch 64: Validation loss decreased (0.140732 --> 0.139632).  Saving model ...
	 Train_Loss: 0.2470 Train_Acc: 91.920 Val_Loss: 0.1396  BEST VAL Loss: 0.1396  Val_Acc: 96.874

Epoch 65: Validation loss decreased (0.139632 --> 0.138587).  Saving model ...
	 Train_Loss: 0.2455 Train_Acc: 91.774 Val_Loss: 0.1386  BEST VAL Loss: 0.1386  Val_Acc: 96.844

Epoch 66: Validation loss decreased (0.138587 --> 0.137698).  Saving model ...
	 Train_Loss: 0.2439 Train_Acc: 92.052 Val_Loss: 0.1377  BEST VAL Loss: 0.1377  Val_Acc: 97.054

Epoch 67: Validation loss decreased (0.137698 --> 0.136819).  Saving model ...
	 Train_Loss: 0.2424 Train_Acc: 93.540 Val_Loss: 0.1368  BEST VAL Loss: 0.1368  Val_Acc: 97.115

Epoch 68: Validation loss decreased (0.136819 --> 0.135903).  Saving model ...
	 Train_Loss: 0.2408 Train_Acc: 93.931 Val_Loss: 0.1359  BEST VAL Loss: 0.1359  Val_Acc: 97.235

Epoch 69: Validation loss decreased (0.135903 --> 0.134991).  Saving model ...
	 Train_Loss: 0.2393 Train_Acc: 94.014 Val_Loss: 0.1350  BEST VAL Loss: 0.1350  Val_Acc: 96.874

Epoch 70: Validation loss decreased (0.134991 --> 0.134080).  Saving model ...
	 Train_Loss: 0.2378 Train_Acc: 93.912 Val_Loss: 0.1341  BEST VAL Loss: 0.1341  Val_Acc: 97.295

Epoch 71: Validation loss decreased (0.134080 --> 0.133230).  Saving model ...
	 Train_Loss: 0.2364 Train_Acc: 94.002 Val_Loss: 0.1332  BEST VAL Loss: 0.1332  Val_Acc: 97.145

Epoch 72: Validation loss decreased (0.133230 --> 0.132403).  Saving model ...
	 Train_Loss: 0.2350 Train_Acc: 93.803 Val_Loss: 0.1324  BEST VAL Loss: 0.1324  Val_Acc: 97.235

Epoch 73: Validation loss decreased (0.132403 --> 0.131626).  Saving model ...
	 Train_Loss: 0.2337 Train_Acc: 93.848 Val_Loss: 0.1316  BEST VAL Loss: 0.1316  Val_Acc: 97.084

Epoch 74: Validation loss decreased (0.131626 --> 0.130859).  Saving model ...
	 Train_Loss: 0.2323 Train_Acc: 94.145 Val_Loss: 0.1309  BEST VAL Loss: 0.1309  Val_Acc: 97.235

Epoch 75: Validation loss decreased (0.130859 --> 0.130182).  Saving model ...
	 Train_Loss: 0.2310 Train_Acc: 94.096 Val_Loss: 0.1302  BEST VAL Loss: 0.1302  Val_Acc: 96.964

Epoch 76: Validation loss decreased (0.130182 --> 0.129473).  Saving model ...
	 Train_Loss: 0.2297 Train_Acc: 94.314 Val_Loss: 0.1295  BEST VAL Loss: 0.1295  Val_Acc: 97.445

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.2284 Train_Acc: 94.604 Val_Loss: 0.1296  BEST VAL Loss: 0.1295  Val_Acc: 96.243

Epoch 78: Validation loss decreased (0.129473 --> 0.129014).  Saving model ...
	 Train_Loss: 0.2273 Train_Acc: 94.006 Val_Loss: 0.1290  BEST VAL Loss: 0.1290  Val_Acc: 96.814

Epoch 79: Validation loss decreased (0.129014 --> 0.128397).  Saving model ...
	 Train_Loss: 0.2261 Train_Acc: 93.991 Val_Loss: 0.1284  BEST VAL Loss: 0.1284  Val_Acc: 97.415

Epoch 80: Validation loss decreased (0.128397 --> 0.127693).  Saving model ...
	 Train_Loss: 0.2249 Train_Acc: 94.389 Val_Loss: 0.1277  BEST VAL Loss: 0.1277  Val_Acc: 97.475

Epoch 81: Validation loss decreased (0.127693 --> 0.127004).  Saving model ...
	 Train_Loss: 0.2238 Train_Acc: 94.198 Val_Loss: 0.1270  BEST VAL Loss: 0.1270  Val_Acc: 97.325

Epoch 82: Validation loss decreased (0.127004 --> 0.126381).  Saving model ...
	 Train_Loss: 0.2226 Train_Acc: 94.153 Val_Loss: 0.1264  BEST VAL Loss: 0.1264  Val_Acc: 97.084

Epoch 83: Validation loss decreased (0.126381 --> 0.125968).  Saving model ...
	 Train_Loss: 0.2215 Train_Acc: 94.307 Val_Loss: 0.1260  BEST VAL Loss: 0.1260  Val_Acc: 97.024

Epoch 84: Validation loss decreased (0.125968 --> 0.125403).  Saving model ...
	 Train_Loss: 0.2204 Train_Acc: 94.641 Val_Loss: 0.1254  BEST VAL Loss: 0.1254  Val_Acc: 97.295

Epoch 85: Validation loss decreased (0.125403 --> 0.124775).  Saving model ...
	 Train_Loss: 0.2193 Train_Acc: 94.555 Val_Loss: 0.1248  BEST VAL Loss: 0.1248  Val_Acc: 97.385

Epoch 86: Validation loss decreased (0.124775 --> 0.124178).  Saving model ...
	 Train_Loss: 0.2182 Train_Acc: 94.746 Val_Loss: 0.1242  BEST VAL Loss: 0.1242  Val_Acc: 97.625

Epoch 87: Validation loss decreased (0.124178 --> 0.123745).  Saving model ...
	 Train_Loss: 0.2171 Train_Acc: 94.558 Val_Loss: 0.1237  BEST VAL Loss: 0.1237  Val_Acc: 97.295

Epoch 88: Validation loss decreased (0.123745 --> 0.123460).  Saving model ...
	 Train_Loss: 0.2160 Train_Acc: 94.799 Val_Loss: 0.1235  BEST VAL Loss: 0.1235  Val_Acc: 96.964

Epoch 89: Validation loss decreased (0.123460 --> 0.123019).  Saving model ...
	 Train_Loss: 0.2150 Train_Acc: 94.682 Val_Loss: 0.1230  BEST VAL Loss: 0.1230  Val_Acc: 97.054

Epoch 90: Validation loss decreased (0.123019 --> 0.122487).  Saving model ...
	 Train_Loss: 0.2140 Train_Acc: 95.006 Val_Loss: 0.1225  BEST VAL Loss: 0.1225  Val_Acc: 97.355

Epoch 91: Validation loss decreased (0.122487 --> 0.122058).  Saving model ...
	 Train_Loss: 0.2130 Train_Acc: 94.713 Val_Loss: 0.1221  BEST VAL Loss: 0.1221  Val_Acc: 97.175

Epoch 92: Validation loss decreased (0.122058 --> 0.121612).  Saving model ...
	 Train_Loss: 0.2120 Train_Acc: 94.972 Val_Loss: 0.1216  BEST VAL Loss: 0.1216  Val_Acc: 97.295

Epoch 93: Validation loss decreased (0.121612 --> 0.121482).  Saving model ...
	 Train_Loss: 0.2110 Train_Acc: 94.893 Val_Loss: 0.1215  BEST VAL Loss: 0.1215  Val_Acc: 96.213

Epoch 94: Validation loss decreased (0.121482 --> 0.121169).  Saving model ...
	 Train_Loss: 0.2101 Train_Acc: 94.840 Val_Loss: 0.1212  BEST VAL Loss: 0.1212  Val_Acc: 96.994

Epoch 95: Validation loss decreased (0.121169 --> 0.120759).  Saving model ...
	 Train_Loss: 0.2091 Train_Acc: 95.205 Val_Loss: 0.1208  BEST VAL Loss: 0.1208  Val_Acc: 96.453

Epoch 96: Validation loss decreased (0.120759 --> 0.120432).  Saving model ...
	 Train_Loss: 0.2083 Train_Acc: 94.401 Val_Loss: 0.1204  BEST VAL Loss: 0.1204  Val_Acc: 97.355

Epoch 97: Validation loss decreased (0.120432 --> 0.120088).  Saving model ...
	 Train_Loss: 0.2074 Train_Acc: 95.133 Val_Loss: 0.1201  BEST VAL Loss: 0.1201  Val_Acc: 97.145

Epoch 98: Validation loss decreased (0.120088 --> 0.119629).  Saving model ...
	 Train_Loss: 0.2065 Train_Acc: 95.220 Val_Loss: 0.1196  BEST VAL Loss: 0.1196  Val_Acc: 97.235

Epoch 99: Validation loss decreased (0.119629 --> 0.119272).  Saving model ...
	 Train_Loss: 0.2056 Train_Acc: 94.957 Val_Loss: 0.1193  BEST VAL Loss: 0.1193  Val_Acc: 97.175

H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.68      0.68      0.68     18174
           1       0.31      0.32      0.31      8436

    accuracy                           0.56     26610
   macro avg       0.50      0.50      0.50     26610
weighted avg       0.56      0.56      0.56     26610

H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.68      0.68      0.68      2272
           1       0.31      0.31      0.31      1055

    accuracy                           0.56      3327
   macro avg       0.49      0.49      0.49      3327
weighted avg       0.56      0.56      0.56      3327

H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.68      0.68      0.68      2272
           1       0.32      0.32      0.32      1055

    accuracy                           0.57      3327
   macro avg       0.50      0.50      0.50      3327
weighted avg       0.57      0.57      0.57      3327

              precision    recall  f1-score   support

           0       0.68      0.68      0.68      2272
           1       0.32      0.32      0.32      1055

    accuracy                           0.57      3327
   macro avg       0.50      0.50      0.50      3327
weighted avg       0.57      0.57      0.57      3327

H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.55      0.54      4182
           1       0.49      0.47      0.48      3856

    accuracy                           0.51      8038
   macro avg       0.51      0.51      0.51      8038
weighted avg       0.51      0.51      0.51      8038

              precision    recall  f1-score   support

           0       0.53      0.55      0.54      4182
           1       0.49      0.47      0.48      3856

    accuracy                           0.51      8038
   macro avg       0.51      0.51      0.51      8038
weighted avg       0.51      0.51      0.51      8038

completed
