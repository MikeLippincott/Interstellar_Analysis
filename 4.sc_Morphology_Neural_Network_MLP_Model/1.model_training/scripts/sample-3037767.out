[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '188ba6a6'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'eeb758ea'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1ff37baf'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'd6b62354'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_0.010_DMSO_0.025 treatment_name: DMSO_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_0.010_DMSO_0.025
TREATMENT_NAME: DMSO_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'LPS_0.010_DMSO_0.025']
The dimensions of the data are: (51502, 1276)
Number of total missing values across all columns: 103004
Data Subset Is Off
Wells held out for testing: ['B21' 'I14']
Wells to use for training, validation, and testing ['B14' 'C14' 'B15' 'C15' 'B16' 'B17' 'B20' 'J14' 'I15' 'J15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.583233).  Saving model ...
	 Train_Loss: 0.6378 Train_Acc: 65.756 Val_Loss: 0.5832  BEST VAL Loss: 0.5832  Val_Acc: 72.620

Epoch 1: Validation loss decreased (0.583233 --> 0.573001).  Saving model ...
	 Train_Loss: 0.6102 Train_Acc: 72.752 Val_Loss: 0.5730  BEST VAL Loss: 0.5730  Val_Acc: 72.809

Epoch 2: Validation loss decreased (0.573001 --> 0.567719).  Saving model ...
	 Train_Loss: 0.5958 Train_Acc: 72.953 Val_Loss: 0.5677  BEST VAL Loss: 0.5677  Val_Acc: 72.833

Epoch 3: Validation loss decreased (0.567719 --> 0.560530).  Saving model ...
	 Train_Loss: 0.5865 Train_Acc: 73.059 Val_Loss: 0.5605  BEST VAL Loss: 0.5605  Val_Acc: 72.880

Epoch 4: Validation loss decreased (0.560530 --> 0.555335).  Saving model ...
	 Train_Loss: 0.5792 Train_Acc: 73.275 Val_Loss: 0.5553  BEST VAL Loss: 0.5553  Val_Acc: 72.998

Epoch 5: Validation loss decreased (0.555335 --> 0.552055).  Saving model ...
	 Train_Loss: 0.5732 Train_Acc: 73.523 Val_Loss: 0.5521  BEST VAL Loss: 0.5521  Val_Acc: 73.281

Epoch 6: Validation loss decreased (0.552055 --> 0.548822).  Saving model ...
	 Train_Loss: 0.5680 Train_Acc: 73.700 Val_Loss: 0.5488  BEST VAL Loss: 0.5488  Val_Acc: 73.612

Epoch 7: Validation loss decreased (0.548822 --> 0.546235).  Saving model ...
	 Train_Loss: 0.5635 Train_Acc: 73.939 Val_Loss: 0.5462  BEST VAL Loss: 0.5462  Val_Acc: 73.777

Epoch 8: Validation loss decreased (0.546235 --> 0.543401).  Saving model ...
	 Train_Loss: 0.5596 Train_Acc: 74.143 Val_Loss: 0.5434  BEST VAL Loss: 0.5434  Val_Acc: 74.085

Epoch 9: Validation loss decreased (0.543401 --> 0.541035).  Saving model ...
	 Train_Loss: 0.5558 Train_Acc: 74.320 Val_Loss: 0.5410  BEST VAL Loss: 0.5410  Val_Acc: 74.226

Epoch 10: Validation loss decreased (0.541035 --> 0.538208).  Saving model ...
	 Train_Loss: 0.5526 Train_Acc: 74.559 Val_Loss: 0.5382  BEST VAL Loss: 0.5382  Val_Acc: 74.510

Epoch 11: Validation loss decreased (0.538208 --> 0.535741).  Saving model ...
	 Train_Loss: 0.5495 Train_Acc: 74.654 Val_Loss: 0.5357  BEST VAL Loss: 0.5357  Val_Acc: 75.053

Epoch 12: Validation loss decreased (0.535741 --> 0.533698).  Saving model ...
	 Train_Loss: 0.5466 Train_Acc: 74.804 Val_Loss: 0.5337  BEST VAL Loss: 0.5337  Val_Acc: 75.337

Epoch 13: Validation loss decreased (0.533698 --> 0.532020).  Saving model ...
	 Train_Loss: 0.5438 Train_Acc: 75.147 Val_Loss: 0.5320  BEST VAL Loss: 0.5320  Val_Acc: 75.549

Epoch 14: Validation loss decreased (0.532020 --> 0.529787).  Saving model ...
	 Train_Loss: 0.5413 Train_Acc: 75.114 Val_Loss: 0.5298  BEST VAL Loss: 0.5298  Val_Acc: 75.785

Epoch 15: Validation loss decreased (0.529787 --> 0.528239).  Saving model ...
	 Train_Loss: 0.5389 Train_Acc: 75.200 Val_Loss: 0.5282  BEST VAL Loss: 0.5282  Val_Acc: 75.785

Epoch 16: Validation loss decreased (0.528239 --> 0.526681).  Saving model ...
	 Train_Loss: 0.5365 Train_Acc: 75.596 Val_Loss: 0.5267  BEST VAL Loss: 0.5267  Val_Acc: 76.282

Epoch 17: Validation loss decreased (0.526681 --> 0.524878).  Saving model ...
	 Train_Loss: 0.5343 Train_Acc: 75.791 Val_Loss: 0.5249  BEST VAL Loss: 0.5249  Val_Acc: 76.282

Epoch 18: Validation loss decreased (0.524878 --> 0.523406).  Saving model ...
	 Train_Loss: 0.5322 Train_Acc: 75.735 Val_Loss: 0.5234  BEST VAL Loss: 0.5234  Val_Acc: 76.447

Epoch 19: Validation loss decreased (0.523406 --> 0.521824).  Saving model ...
	 Train_Loss: 0.5301 Train_Acc: 75.888 Val_Loss: 0.5218  BEST VAL Loss: 0.5218  Val_Acc: 76.518

Epoch 20: Validation loss decreased (0.521824 --> 0.520158).  Saving model ...
	 Train_Loss: 0.5281 Train_Acc: 76.059 Val_Loss: 0.5202  BEST VAL Loss: 0.5202  Val_Acc: 76.683

Epoch 21: Validation loss decreased (0.520158 --> 0.518873).  Saving model ...
	 Train_Loss: 0.5263 Train_Acc: 76.349 Val_Loss: 0.5189  BEST VAL Loss: 0.5189  Val_Acc: 76.518

Epoch 22: Validation loss decreased (0.518873 --> 0.517643).  Saving model ...
	 Train_Loss: 0.5247 Train_Acc: 76.086 Val_Loss: 0.5176  BEST VAL Loss: 0.5176  Val_Acc: 76.494

Epoch 23: Validation loss decreased (0.517643 --> 0.516163).  Saving model ...
	 Train_Loss: 0.5231 Train_Acc: 76.352 Val_Loss: 0.5162  BEST VAL Loss: 0.5162  Val_Acc: 76.423

Epoch 24: Validation loss decreased (0.516163 --> 0.515045).  Saving model ...
	 Train_Loss: 0.5215 Train_Acc: 76.561 Val_Loss: 0.5150  BEST VAL Loss: 0.5150  Val_Acc: 76.565

Epoch 25: Validation loss decreased (0.515045 --> 0.514181).  Saving model ...
	 Train_Loss: 0.5200 Train_Acc: 76.550 Val_Loss: 0.5142  BEST VAL Loss: 0.5142  Val_Acc: 76.660

Epoch 26: Validation loss decreased (0.514181 --> 0.513401).  Saving model ...
	 Train_Loss: 0.5185 Train_Acc: 76.582 Val_Loss: 0.5134  BEST VAL Loss: 0.5134  Val_Acc: 76.494

Epoch 27: Validation loss decreased (0.513401 --> 0.512506).  Saving model ...
	 Train_Loss: 0.5172 Train_Acc: 76.464 Val_Loss: 0.5125  BEST VAL Loss: 0.5125  Val_Acc: 76.541

Epoch 28: Validation loss decreased (0.512506 --> 0.511537).  Saving model ...
	 Train_Loss: 0.5158 Train_Acc: 76.907 Val_Loss: 0.5115  BEST VAL Loss: 0.5115  Val_Acc: 76.919

Epoch 29: Validation loss decreased (0.511537 --> 0.510875).  Saving model ...
	 Train_Loss: 0.5145 Train_Acc: 76.812 Val_Loss: 0.5109  BEST VAL Loss: 0.5109  Val_Acc: 76.305

Epoch 30: Validation loss decreased (0.510875 --> 0.510114).  Saving model ...
	 Train_Loss: 0.5131 Train_Acc: 76.996 Val_Loss: 0.5101  BEST VAL Loss: 0.5101  Val_Acc: 76.849

Epoch 31: Validation loss decreased (0.510114 --> 0.509238).  Saving model ...
	 Train_Loss: 0.5120 Train_Acc: 76.759 Val_Loss: 0.5092  BEST VAL Loss: 0.5092  Val_Acc: 76.778

Epoch 32: Validation loss decreased (0.509238 --> 0.508713).  Saving model ...
	 Train_Loss: 0.5108 Train_Acc: 76.993 Val_Loss: 0.5087  BEST VAL Loss: 0.5087  Val_Acc: 76.778

Epoch 33: Validation loss decreased (0.508713 --> 0.508175).  Saving model ...
	 Train_Loss: 0.5097 Train_Acc: 76.842 Val_Loss: 0.5082  BEST VAL Loss: 0.5082  Val_Acc: 76.778

Epoch 34: Validation loss decreased (0.508175 --> 0.507672).  Saving model ...
	 Train_Loss: 0.5086 Train_Acc: 76.842 Val_Loss: 0.5077  BEST VAL Loss: 0.5077  Val_Acc: 77.061

Epoch 35: Validation loss decreased (0.507672 --> 0.507329).  Saving model ...
	 Train_Loss: 0.5075 Train_Acc: 77.176 Val_Loss: 0.5073  BEST VAL Loss: 0.5073  Val_Acc: 76.636

Epoch 36: Validation loss decreased (0.507329 --> 0.506724).  Saving model ...
	 Train_Loss: 0.5064 Train_Acc: 77.058 Val_Loss: 0.5067  BEST VAL Loss: 0.5067  Val_Acc: 77.321

Epoch 37: Validation loss decreased (0.506724 --> 0.506025).  Saving model ...
	 Train_Loss: 0.5053 Train_Acc: 77.317 Val_Loss: 0.5060  BEST VAL Loss: 0.5060  Val_Acc: 77.085

Epoch 38: Validation loss decreased (0.506025 --> 0.505252).  Saving model ...
	 Train_Loss: 0.5043 Train_Acc: 77.356 Val_Loss: 0.5053  BEST VAL Loss: 0.5053  Val_Acc: 77.038

Epoch 39: Validation loss decreased (0.505252 --> 0.504622).  Saving model ...
	 Train_Loss: 0.5033 Train_Acc: 77.474 Val_Loss: 0.5046  BEST VAL Loss: 0.5046  Val_Acc: 76.967

Epoch 40: Validation loss decreased (0.504622 --> 0.503912).  Saving model ...
	 Train_Loss: 0.5023 Train_Acc: 77.545 Val_Loss: 0.5039  BEST VAL Loss: 0.5039  Val_Acc: 77.203

Epoch 41: Validation loss decreased (0.503912 --> 0.503484).  Saving model ...
	 Train_Loss: 0.5014 Train_Acc: 77.450 Val_Loss: 0.5035  BEST VAL Loss: 0.5035  Val_Acc: 76.872

Epoch 42: Validation loss decreased (0.503484 --> 0.503159).  Saving model ...
	 Train_Loss: 0.5005 Train_Acc: 77.436 Val_Loss: 0.5032  BEST VAL Loss: 0.5032  Val_Acc: 76.849

Epoch 43: Validation loss decreased (0.503159 --> 0.502598).  Saving model ...
	 Train_Loss: 0.4996 Train_Acc: 77.710 Val_Loss: 0.5026  BEST VAL Loss: 0.5026  Val_Acc: 77.227

Epoch 44: Validation loss decreased (0.502598 --> 0.502225).  Saving model ...
	 Train_Loss: 0.4987 Train_Acc: 77.660 Val_Loss: 0.5022  BEST VAL Loss: 0.5022  Val_Acc: 76.872

Epoch 45: Validation loss decreased (0.502225 --> 0.501836).  Saving model ...
	 Train_Loss: 0.4978 Train_Acc: 77.728 Val_Loss: 0.5018  BEST VAL Loss: 0.5018  Val_Acc: 77.014

Epoch 46: Validation loss decreased (0.501836 --> 0.501450).  Saving model ...
	 Train_Loss: 0.4970 Train_Acc: 77.492 Val_Loss: 0.5015  BEST VAL Loss: 0.5015  Val_Acc: 77.156

Epoch 47: Validation loss decreased (0.501450 --> 0.500737).  Saving model ...
	 Train_Loss: 0.4962 Train_Acc: 77.625 Val_Loss: 0.5007  BEST VAL Loss: 0.5007  Val_Acc: 77.486

Epoch 48: Validation loss decreased (0.500737 --> 0.500396).  Saving model ...
	 Train_Loss: 0.4954 Train_Acc: 77.879 Val_Loss: 0.5004  BEST VAL Loss: 0.5004  Val_Acc: 77.014

Epoch 49: Validation loss decreased (0.500396 --> 0.500059).  Saving model ...
	 Train_Loss: 0.4946 Train_Acc: 77.964 Val_Loss: 0.5001  BEST VAL Loss: 0.5001  Val_Acc: 77.321

Epoch 50: Validation loss decreased (0.500059 --> 0.499509).  Saving model ...
	 Train_Loss: 0.4938 Train_Acc: 77.861 Val_Loss: 0.4995  BEST VAL Loss: 0.4995  Val_Acc: 77.274

Epoch 51: Validation loss decreased (0.499509 --> 0.499226).  Saving model ...
	 Train_Loss: 0.4931 Train_Acc: 77.831 Val_Loss: 0.4992  BEST VAL Loss: 0.4992  Val_Acc: 77.085

Epoch 52: Validation loss decreased (0.499226 --> 0.498801).  Saving model ...
	 Train_Loss: 0.4923 Train_Acc: 78.091 Val_Loss: 0.4988  BEST VAL Loss: 0.4988  Val_Acc: 77.321

Epoch 53: Validation loss decreased (0.498801 --> 0.498419).  Saving model ...
	 Train_Loss: 0.4915 Train_Acc: 78.307 Val_Loss: 0.4984  BEST VAL Loss: 0.4984  Val_Acc: 77.368

Epoch 54: Validation loss decreased (0.498419 --> 0.497926).  Saving model ...
	 Train_Loss: 0.4908 Train_Acc: 77.941 Val_Loss: 0.4979  BEST VAL Loss: 0.4979  Val_Acc: 77.439

Epoch 55: Validation loss decreased (0.497926 --> 0.497585).  Saving model ...
	 Train_Loss: 0.4901 Train_Acc: 78.336 Val_Loss: 0.4976  BEST VAL Loss: 0.4976  Val_Acc: 77.297

Epoch 56: Validation loss decreased (0.497585 --> 0.497352).  Saving model ...
	 Train_Loss: 0.4894 Train_Acc: 77.976 Val_Loss: 0.4974  BEST VAL Loss: 0.4974  Val_Acc: 77.368

Epoch 57: Validation loss decreased (0.497352 --> 0.497108).  Saving model ...
	 Train_Loss: 0.4887 Train_Acc: 78.286 Val_Loss: 0.4971  BEST VAL Loss: 0.4971  Val_Acc: 77.439

Epoch 58: Validation loss decreased (0.497108 --> 0.496908).  Saving model ...
	 Train_Loss: 0.4880 Train_Acc: 78.257 Val_Loss: 0.4969  BEST VAL Loss: 0.4969  Val_Acc: 77.628

Epoch 59: Validation loss decreased (0.496908 --> 0.496519).  Saving model ...
	 Train_Loss: 0.4874 Train_Acc: 78.363 Val_Loss: 0.4965  BEST VAL Loss: 0.4965  Val_Acc: 77.132

Epoch 60: Validation loss decreased (0.496519 --> 0.496413).  Saving model ...
	 Train_Loss: 0.4866 Train_Acc: 78.463 Val_Loss: 0.4964  BEST VAL Loss: 0.4964  Val_Acc: 77.392

Epoch 61: Validation loss decreased (0.496413 --> 0.496259).  Saving model ...
	 Train_Loss: 0.4860 Train_Acc: 78.487 Val_Loss: 0.4963  BEST VAL Loss: 0.4963  Val_Acc: 77.203

Epoch 62: Validation loss decreased (0.496259 --> 0.496256).  Saving model ...
	 Train_Loss: 0.4853 Train_Acc: 78.605 Val_Loss: 0.4963  BEST VAL Loss: 0.4963  Val_Acc: 77.368

Epoch 63: Validation loss decreased (0.496256 --> 0.496014).  Saving model ...
	 Train_Loss: 0.4847 Train_Acc: 78.788 Val_Loss: 0.4960  BEST VAL Loss: 0.4960  Val_Acc: 77.557

Epoch 64: Validation loss decreased (0.496014 --> 0.495827).  Saving model ...
	 Train_Loss: 0.4840 Train_Acc: 78.726 Val_Loss: 0.4958  BEST VAL Loss: 0.4958  Val_Acc: 77.439

Epoch 65: Validation loss decreased (0.495827 --> 0.495660).  Saving model ...
	 Train_Loss: 0.4834 Train_Acc: 78.463 Val_Loss: 0.4957  BEST VAL Loss: 0.4957  Val_Acc: 77.203

Epoch 66: Validation loss decreased (0.495660 --> 0.495397).  Saving model ...
	 Train_Loss: 0.4828 Train_Acc: 78.658 Val_Loss: 0.4954  BEST VAL Loss: 0.4954  Val_Acc: 77.628

Epoch 67: Validation loss decreased (0.495397 --> 0.495076).  Saving model ...
	 Train_Loss: 0.4822 Train_Acc: 78.750 Val_Loss: 0.4951  BEST VAL Loss: 0.4951  Val_Acc: 77.557

Epoch 68: Validation loss decreased (0.495076 --> 0.495015).  Saving model ...
	 Train_Loss: 0.4816 Train_Acc: 78.750 Val_Loss: 0.4950  BEST VAL Loss: 0.4950  Val_Acc: 77.274

Epoch 69: Validation loss decreased (0.495015 --> 0.494881).  Saving model ...
	 Train_Loss: 0.4810 Train_Acc: 79.007 Val_Loss: 0.4949  BEST VAL Loss: 0.4949  Val_Acc: 77.345

Epoch 70: Validation loss decreased (0.494881 --> 0.494528).  Saving model ...
	 Train_Loss: 0.4804 Train_Acc: 78.729 Val_Loss: 0.4945  BEST VAL Loss: 0.4945  Val_Acc: 77.628

Epoch 71: Validation loss decreased (0.494528 --> 0.494306).  Saving model ...
	 Train_Loss: 0.4798 Train_Acc: 78.756 Val_Loss: 0.4943  BEST VAL Loss: 0.4943  Val_Acc: 77.510

Epoch 72: Validation loss decreased (0.494306 --> 0.494122).  Saving model ...
	 Train_Loss: 0.4793 Train_Acc: 79.069 Val_Loss: 0.4941  BEST VAL Loss: 0.4941  Val_Acc: 77.061

Epoch 73: Validation loss decreased (0.494122 --> 0.493928).  Saving model ...
	 Train_Loss: 0.4787 Train_Acc: 78.815 Val_Loss: 0.4939  BEST VAL Loss: 0.4939  Val_Acc: 77.321

Epoch 74: Validation loss decreased (0.493928 --> 0.493777).  Saving model ...
	 Train_Loss: 0.4782 Train_Acc: 78.965 Val_Loss: 0.4938  BEST VAL Loss: 0.4938  Val_Acc: 77.628

Epoch 75: Validation loss decreased (0.493777 --> 0.493705).  Saving model ...
	 Train_Loss: 0.4776 Train_Acc: 79.057 Val_Loss: 0.4937  BEST VAL Loss: 0.4937  Val_Acc: 77.392

Epoch 76: Validation loss decreased (0.493705 --> 0.493533).  Saving model ...
	 Train_Loss: 0.4771 Train_Acc: 79.036 Val_Loss: 0.4935  BEST VAL Loss: 0.4935  Val_Acc: 77.557

Epoch 77: Validation loss decreased (0.493533 --> 0.493419).  Saving model ...
	 Train_Loss: 0.4765 Train_Acc: 79.178 Val_Loss: 0.4934  BEST VAL Loss: 0.4934  Val_Acc: 76.990

Epoch 78: Validation loss decreased (0.493419 --> 0.493345).  Saving model ...
	 Train_Loss: 0.4760 Train_Acc: 79.107 Val_Loss: 0.4933  BEST VAL Loss: 0.4933  Val_Acc: 77.581

Epoch 79: Validation loss decreased (0.493345 --> 0.493183).  Saving model ...
	 Train_Loss: 0.4755 Train_Acc: 79.066 Val_Loss: 0.4932  BEST VAL Loss: 0.4932  Val_Acc: 77.746

Epoch 80: Validation loss decreased (0.493183 --> 0.493064).  Saving model ...
	 Train_Loss: 0.4750 Train_Acc: 79.036 Val_Loss: 0.4931  BEST VAL Loss: 0.4931  Val_Acc: 77.297

Epoch 81: Validation loss decreased (0.493064 --> 0.492914).  Saving model ...
	 Train_Loss: 0.4745 Train_Acc: 79.252 Val_Loss: 0.4929  BEST VAL Loss: 0.4929  Val_Acc: 77.368

Epoch 82: Validation loss decreased (0.492914 --> 0.492788).  Saving model ...
	 Train_Loss: 0.4740 Train_Acc: 79.015 Val_Loss: 0.4928  BEST VAL Loss: 0.4928  Val_Acc: 76.943

Epoch 83: Validation loss decreased (0.492788 --> 0.492707).  Saving model ...
	 Train_Loss: 0.4735 Train_Acc: 79.323 Val_Loss: 0.4927  BEST VAL Loss: 0.4927  Val_Acc: 76.990

Epoch 84: Validation loss decreased (0.492707 --> 0.492623).  Saving model ...
	 Train_Loss: 0.4730 Train_Acc: 79.488 Val_Loss: 0.4926  BEST VAL Loss: 0.4926  Val_Acc: 77.085

Epoch 85: Validation loss decreased (0.492623 --> 0.492433).  Saving model ...
	 Train_Loss: 0.4725 Train_Acc: 79.509 Val_Loss: 0.4924  BEST VAL Loss: 0.4924  Val_Acc: 77.108

Epoch 86: Validation loss decreased (0.492433 --> 0.492208).  Saving model ...
	 Train_Loss: 0.4720 Train_Acc: 79.228 Val_Loss: 0.4922  BEST VAL Loss: 0.4922  Val_Acc: 77.274

Epoch 87: Validation loss decreased (0.492208 --> 0.492017).  Saving model ...
	 Train_Loss: 0.4715 Train_Acc: 79.269 Val_Loss: 0.4920  BEST VAL Loss: 0.4920  Val_Acc: 77.416

Epoch 88: Validation loss decreased (0.492017 --> 0.491842).  Saving model ...
	 Train_Loss: 0.4711 Train_Acc: 79.367 Val_Loss: 0.4918  BEST VAL Loss: 0.4918  Val_Acc: 77.179

Epoch 89: Validation loss decreased (0.491842 --> 0.491653).  Saving model ...
	 Train_Loss: 0.4706 Train_Acc: 79.414 Val_Loss: 0.4917  BEST VAL Loss: 0.4917  Val_Acc: 77.605

Epoch 90: Validation loss decreased (0.491653 --> 0.491496).  Saving model ...
	 Train_Loss: 0.4701 Train_Acc: 79.515 Val_Loss: 0.4915  BEST VAL Loss: 0.4915  Val_Acc: 76.990

Epoch 91: Validation loss decreased (0.491496 --> 0.491412).  Saving model ...
	 Train_Loss: 0.4697 Train_Acc: 79.692 Val_Loss: 0.4914  BEST VAL Loss: 0.4914  Val_Acc: 77.156

Epoch 92: Validation loss decreased (0.491412 --> 0.491255).  Saving model ...
	 Train_Loss: 0.4692 Train_Acc: 79.523 Val_Loss: 0.4913  BEST VAL Loss: 0.4913  Val_Acc: 77.014

Epoch 93: Validation loss decreased (0.491255 --> 0.491228).  Saving model ...
	 Train_Loss: 0.4688 Train_Acc: 79.467 Val_Loss: 0.4912  BEST VAL Loss: 0.4912  Val_Acc: 76.801

Epoch 94: Validation loss decreased (0.491228 --> 0.491142).  Saving model ...
	 Train_Loss: 0.4683 Train_Acc: 79.559 Val_Loss: 0.4911  BEST VAL Loss: 0.4911  Val_Acc: 76.872

Epoch 95: Validation loss decreased (0.491142 --> 0.491058).  Saving model ...
	 Train_Loss: 0.4679 Train_Acc: 79.689 Val_Loss: 0.4911  BEST VAL Loss: 0.4911  Val_Acc: 77.392

Epoch 96: Validation loss decreased (0.491058 --> 0.491017).  Saving model ...
	 Train_Loss: 0.4674 Train_Acc: 79.748 Val_Loss: 0.4910  BEST VAL Loss: 0.4910  Val_Acc: 77.085

Epoch 97: Validation loss decreased (0.491017 --> 0.490927).  Saving model ...
	 Train_Loss: 0.4670 Train_Acc: 79.621 Val_Loss: 0.4909  BEST VAL Loss: 0.4909  Val_Acc: 77.179

Epoch 98: Validation loss decreased (0.490927 --> 0.490800).  Saving model ...
	 Train_Loss: 0.4666 Train_Acc: 79.760 Val_Loss: 0.4908  BEST VAL Loss: 0.4908  Val_Acc: 77.297

Epoch 99: Validation loss decreased (0.490800 --> 0.490724).  Saving model ...
	 Train_Loss: 0.4662 Train_Acc: 79.848 Val_Loss: 0.4907  BEST VAL Loss: 0.4907  Val_Acc: 77.274

LPS_0.010_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.73      0.85      0.78     24644
           1       0.27      0.15      0.20      9219

    accuracy                           0.66     33863
   macro avg       0.50      0.50      0.49     33863
weighted avg       0.60      0.66      0.62     33863

LPS_0.010_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.73      0.85      0.79      3081
           1       0.26      0.14      0.18      1152

    accuracy                           0.66      4233
   macro avg       0.49      0.50      0.48      4233
weighted avg       0.60      0.66      0.62      4233

LPS_0.010_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.73      0.86      0.79      3081
           1       0.27      0.14      0.19      1152

    accuracy                           0.66      4233
   macro avg       0.50      0.50      0.49      4233
weighted avg       0.60      0.66      0.62      4233

              precision    recall  f1-score   support

           0       0.73      0.86      0.79      3081
           1       0.27      0.14      0.19      1152

    accuracy                           0.66      4233
   macro avg       0.50      0.50      0.49      4233
weighted avg       0.60      0.66      0.62      4233

LPS_0.010_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.89      0.66      4837
           1       0.46      0.11      0.17      4336

    accuracy                           0.52      9173
   macro avg       0.49      0.50      0.42      9173
weighted avg       0.49      0.52      0.43      9173

              precision    recall  f1-score   support

           0       0.53      0.89      0.66      4837
           1       0.46      0.11      0.17      4336

    accuracy                           0.52      9173
   macro avg       0.49      0.50      0.42      9173
weighted avg       0.49      0.52      0.43      9173

completed
