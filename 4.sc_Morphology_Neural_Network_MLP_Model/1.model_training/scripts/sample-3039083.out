[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd1bc9ccc'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'b69b74dc'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'fb7a5e98'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e42f0689'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_0.010_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_0.010_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_0.100_DMSO_0.025']
The dimensions of the data are: (281677, 1270)
Number of total missing values across all columns: 563354
Data Subset Is Off
Wells held out for testing: ['B08' 'C08']
Wells to use for training, validation, and testing ['B02' 'C02' 'B03' 'C03' 'B09' 'C09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.684925).  Saving model ...
	 Train_Loss: 0.6899 Train_Acc: 52.286 Val_Loss: 0.6849  BEST VAL Loss: 0.6849  Val_Acc: 54.124

Epoch 1: Validation loss decreased (0.684925 --> 0.682407).  Saving model ...
	 Train_Loss: 0.6859 Train_Acc: 54.578 Val_Loss: 0.6824  BEST VAL Loss: 0.6824  Val_Acc: 55.767

Epoch 2: Validation loss decreased (0.682407 --> 0.680079).  Saving model ...
	 Train_Loss: 0.6829 Train_Acc: 55.719 Val_Loss: 0.6801  BEST VAL Loss: 0.6801  Val_Acc: 56.962

Epoch 3: Validation loss decreased (0.680079 --> 0.677791).  Saving model ...
	 Train_Loss: 0.6802 Train_Acc: 56.919 Val_Loss: 0.6778  BEST VAL Loss: 0.6778  Val_Acc: 57.852

Epoch 4: Validation loss decreased (0.677791 --> 0.675425).  Saving model ...
	 Train_Loss: 0.6776 Train_Acc: 58.080 Val_Loss: 0.6754  BEST VAL Loss: 0.6754  Val_Acc: 58.438

Epoch 5: Validation loss decreased (0.675425 --> 0.673283).  Saving model ...
	 Train_Loss: 0.6749 Train_Acc: 58.944 Val_Loss: 0.6733  BEST VAL Loss: 0.6733  Val_Acc: 59.143

Epoch 6: Validation loss decreased (0.673283 --> 0.670978).  Saving model ...
	 Train_Loss: 0.6724 Train_Acc: 59.744 Val_Loss: 0.6710  BEST VAL Loss: 0.6710  Val_Acc: 60.067

Epoch 7: Validation loss decreased (0.670978 --> 0.668912).  Saving model ...
	 Train_Loss: 0.6701 Train_Acc: 60.212 Val_Loss: 0.6689  BEST VAL Loss: 0.6689  Val_Acc: 60.567

Epoch 8: Validation loss decreased (0.668912 --> 0.666911).  Saving model ...
	 Train_Loss: 0.6679 Train_Acc: 60.533 Val_Loss: 0.6669  BEST VAL Loss: 0.6669  Val_Acc: 60.876

Epoch 9: Validation loss decreased (0.666911 --> 0.664992).  Saving model ...
	 Train_Loss: 0.6659 Train_Acc: 60.988 Val_Loss: 0.6650  BEST VAL Loss: 0.6650  Val_Acc: 61.086

Epoch 10: Validation loss decreased (0.664992 --> 0.663326).  Saving model ...
	 Train_Loss: 0.6640 Train_Acc: 61.251 Val_Loss: 0.6633  BEST VAL Loss: 0.6633  Val_Acc: 61.095

Epoch 11: Validation loss decreased (0.663326 --> 0.661660).  Saving model ...
	 Train_Loss: 0.6622 Train_Acc: 61.528 Val_Loss: 0.6617  BEST VAL Loss: 0.6617  Val_Acc: 61.743

Epoch 12: Validation loss decreased (0.661660 --> 0.660089).  Saving model ...
	 Train_Loss: 0.6605 Train_Acc: 61.818 Val_Loss: 0.6601  BEST VAL Loss: 0.6601  Val_Acc: 61.833

Epoch 13: Validation loss decreased (0.660089 --> 0.658898).  Saving model ...
	 Train_Loss: 0.6589 Train_Acc: 62.139 Val_Loss: 0.6589  BEST VAL Loss: 0.6589  Val_Acc: 61.619

Epoch 14: Validation loss decreased (0.658898 --> 0.657585).  Saving model ...
	 Train_Loss: 0.6574 Train_Acc: 62.298 Val_Loss: 0.6576  BEST VAL Loss: 0.6576  Val_Acc: 62.295

Epoch 15: Validation loss decreased (0.657585 --> 0.656390).  Saving model ...
	 Train_Loss: 0.6560 Train_Acc: 62.599 Val_Loss: 0.6564  BEST VAL Loss: 0.6564  Val_Acc: 62.538

Epoch 16: Validation loss decreased (0.656390 --> 0.655213).  Saving model ...
	 Train_Loss: 0.6547 Train_Acc: 62.651 Val_Loss: 0.6552  BEST VAL Loss: 0.6552  Val_Acc: 62.833

Epoch 17: Validation loss decreased (0.655213 --> 0.654073).  Saving model ...
	 Train_Loss: 0.6535 Train_Acc: 62.972 Val_Loss: 0.6541  BEST VAL Loss: 0.6541  Val_Acc: 62.700

Epoch 18: Validation loss decreased (0.654073 --> 0.652905).  Saving model ...
	 Train_Loss: 0.6523 Train_Acc: 63.110 Val_Loss: 0.6529  BEST VAL Loss: 0.6529  Val_Acc: 63.057

Epoch 19: Validation loss decreased (0.652905 --> 0.651919).  Saving model ...
	 Train_Loss: 0.6511 Train_Acc: 63.300 Val_Loss: 0.6519  BEST VAL Loss: 0.6519  Val_Acc: 62.971

Epoch 20: Validation loss decreased (0.651919 --> 0.650943).  Saving model ...
	 Train_Loss: 0.6500 Train_Acc: 63.530 Val_Loss: 0.6509  BEST VAL Loss: 0.6509  Val_Acc: 63.243

Epoch 21: Validation loss decreased (0.650943 --> 0.649998).  Saving model ...
	 Train_Loss: 0.6490 Train_Acc: 63.537 Val_Loss: 0.6500  BEST VAL Loss: 0.6500  Val_Acc: 63.448

Epoch 22: Validation loss decreased (0.649998 --> 0.649061).  Saving model ...
	 Train_Loss: 0.6479 Train_Acc: 63.818 Val_Loss: 0.6491  BEST VAL Loss: 0.6491  Val_Acc: 63.310

Epoch 23: Validation loss decreased (0.649061 --> 0.648199).  Saving model ...
	 Train_Loss: 0.6470 Train_Acc: 63.753 Val_Loss: 0.6482  BEST VAL Loss: 0.6482  Val_Acc: 63.638

Epoch 24: Validation loss decreased (0.648199 --> 0.647583).  Saving model ...
	 Train_Loss: 0.6461 Train_Acc: 63.825 Val_Loss: 0.6476  BEST VAL Loss: 0.6476  Val_Acc: 63.286

Epoch 25: Validation loss decreased (0.647583 --> 0.646828).  Saving model ...
	 Train_Loss: 0.6452 Train_Acc: 64.069 Val_Loss: 0.6468  BEST VAL Loss: 0.6468  Val_Acc: 63.610

Epoch 26: Validation loss decreased (0.646828 --> 0.646095).  Saving model ...
	 Train_Loss: 0.6443 Train_Acc: 64.124 Val_Loss: 0.6461  BEST VAL Loss: 0.6461  Val_Acc: 63.976

Epoch 27: Validation loss decreased (0.646095 --> 0.645397).  Saving model ...
	 Train_Loss: 0.6435 Train_Acc: 64.286 Val_Loss: 0.6454  BEST VAL Loss: 0.6454  Val_Acc: 63.986

Epoch 28: Validation loss decreased (0.645397 --> 0.644616).  Saving model ...
	 Train_Loss: 0.6427 Train_Acc: 64.442 Val_Loss: 0.6446  BEST VAL Loss: 0.6446  Val_Acc: 64.124

Epoch 29: Validation loss decreased (0.644616 --> 0.643918).  Saving model ...
	 Train_Loss: 0.6419 Train_Acc: 64.451 Val_Loss: 0.6439  BEST VAL Loss: 0.6439  Val_Acc: 64.324

Epoch 30: Validation loss decreased (0.643918 --> 0.643220).  Saving model ...
	 Train_Loss: 0.6412 Train_Acc: 64.604 Val_Loss: 0.6432  BEST VAL Loss: 0.6432  Val_Acc: 64.090

Epoch 31: Validation loss decreased (0.643220 --> 0.642639).  Saving model ...
	 Train_Loss: 0.6404 Train_Acc: 64.750 Val_Loss: 0.6426  BEST VAL Loss: 0.6426  Val_Acc: 64.543

Epoch 32: Validation loss decreased (0.642639 --> 0.642186).  Saving model ...
	 Train_Loss: 0.6397 Train_Acc: 64.752 Val_Loss: 0.6422  BEST VAL Loss: 0.6422  Val_Acc: 63.948

Epoch 33: Validation loss decreased (0.642186 --> 0.641526).  Saving model ...
	 Train_Loss: 0.6390 Train_Acc: 64.880 Val_Loss: 0.6415  BEST VAL Loss: 0.6415  Val_Acc: 64.524

Epoch 34: Validation loss decreased (0.641526 --> 0.640971).  Saving model ...
	 Train_Loss: 0.6383 Train_Acc: 64.882 Val_Loss: 0.6410  BEST VAL Loss: 0.6410  Val_Acc: 64.190

Epoch 35: Validation loss decreased (0.640971 --> 0.640364).  Saving model ...
	 Train_Loss: 0.6376 Train_Acc: 64.896 Val_Loss: 0.6404  BEST VAL Loss: 0.6404  Val_Acc: 64.929

Epoch 36: Validation loss decreased (0.640364 --> 0.639768).  Saving model ...
	 Train_Loss: 0.6369 Train_Acc: 65.097 Val_Loss: 0.6398  BEST VAL Loss: 0.6398  Val_Acc: 64.738

Epoch 37: Validation loss decreased (0.639768 --> 0.639190).  Saving model ...
	 Train_Loss: 0.6363 Train_Acc: 65.060 Val_Loss: 0.6392  BEST VAL Loss: 0.6392  Val_Acc: 64.757

Epoch 38: Validation loss decreased (0.639190 --> 0.638687).  Saving model ...
	 Train_Loss: 0.6357 Train_Acc: 65.230 Val_Loss: 0.6387  BEST VAL Loss: 0.6387  Val_Acc: 64.895

Epoch 39: Validation loss decreased (0.638687 --> 0.638128).  Saving model ...
	 Train_Loss: 0.6350 Train_Acc: 65.190 Val_Loss: 0.6381  BEST VAL Loss: 0.6381  Val_Acc: 64.733

Epoch 40: Validation loss decreased (0.638128 --> 0.637617).  Saving model ...
	 Train_Loss: 0.6345 Train_Acc: 65.255 Val_Loss: 0.6376  BEST VAL Loss: 0.6376  Val_Acc: 65.014

Epoch 41: Validation loss decreased (0.637617 --> 0.637174).  Saving model ...
	 Train_Loss: 0.6339 Train_Acc: 65.329 Val_Loss: 0.6372  BEST VAL Loss: 0.6372  Val_Acc: 64.833

Epoch 42: Validation loss decreased (0.637174 --> 0.636663).  Saving model ...
	 Train_Loss: 0.6333 Train_Acc: 65.583 Val_Loss: 0.6367  BEST VAL Loss: 0.6367  Val_Acc: 64.795

Epoch 43: Validation loss decreased (0.636663 --> 0.636184).  Saving model ...
	 Train_Loss: 0.6327 Train_Acc: 65.597 Val_Loss: 0.6362  BEST VAL Loss: 0.6362  Val_Acc: 64.690

Epoch 44: Validation loss decreased (0.636184 --> 0.635713).  Saving model ...
	 Train_Loss: 0.6321 Train_Acc: 65.666 Val_Loss: 0.6357  BEST VAL Loss: 0.6357  Val_Acc: 65.214

Epoch 45: Validation loss decreased (0.635713 --> 0.635224).  Saving model ...
	 Train_Loss: 0.6316 Train_Acc: 65.607 Val_Loss: 0.6352  BEST VAL Loss: 0.6352  Val_Acc: 65.048

Epoch 46: Validation loss decreased (0.635224 --> 0.634740).  Saving model ...
	 Train_Loss: 0.6311 Train_Acc: 65.541 Val_Loss: 0.6347  BEST VAL Loss: 0.6347  Val_Acc: 65.271

Epoch 47: Validation loss decreased (0.634740 --> 0.634274).  Saving model ...
	 Train_Loss: 0.6305 Train_Acc: 65.837 Val_Loss: 0.6343  BEST VAL Loss: 0.6343  Val_Acc: 65.029

Epoch 48: Validation loss decreased (0.634274 --> 0.633865).  Saving model ...
	 Train_Loss: 0.6300 Train_Acc: 65.808 Val_Loss: 0.6339  BEST VAL Loss: 0.6339  Val_Acc: 65.114

Epoch 49: Validation loss decreased (0.633865 --> 0.633402).  Saving model ...
	 Train_Loss: 0.6295 Train_Acc: 65.849 Val_Loss: 0.6334  BEST VAL Loss: 0.6334  Val_Acc: 65.438

Epoch 50: Validation loss decreased (0.633402 --> 0.633048).  Saving model ...
	 Train_Loss: 0.6290 Train_Acc: 65.828 Val_Loss: 0.6330  BEST VAL Loss: 0.6330  Val_Acc: 64.829

Epoch 51: Validation loss decreased (0.633048 --> 0.632622).  Saving model ...
	 Train_Loss: 0.6285 Train_Acc: 65.985 Val_Loss: 0.6326  BEST VAL Loss: 0.6326  Val_Acc: 65.386

Epoch 52: Validation loss decreased (0.632622 --> 0.632237).  Saving model ...
	 Train_Loss: 0.6280 Train_Acc: 66.070 Val_Loss: 0.6322  BEST VAL Loss: 0.6322  Val_Acc: 65.619

Epoch 53: Validation loss decreased (0.632237 --> 0.631826).  Saving model ...
	 Train_Loss: 0.6276 Train_Acc: 66.035 Val_Loss: 0.6318  BEST VAL Loss: 0.6318  Val_Acc: 65.452

Epoch 54: Validation loss decreased (0.631826 --> 0.631466).  Saving model ...
	 Train_Loss: 0.6271 Train_Acc: 66.156 Val_Loss: 0.6315  BEST VAL Loss: 0.6315  Val_Acc: 65.276

Epoch 55: Validation loss decreased (0.631466 --> 0.631052).  Saving model ...
	 Train_Loss: 0.6267 Train_Acc: 66.102 Val_Loss: 0.6311  BEST VAL Loss: 0.6311  Val_Acc: 65.933

Epoch 56: Validation loss decreased (0.631052 --> 0.630627).  Saving model ...
	 Train_Loss: 0.6262 Train_Acc: 66.077 Val_Loss: 0.6306  BEST VAL Loss: 0.6306  Val_Acc: 66.081

Epoch 57: Validation loss decreased (0.630627 --> 0.630235).  Saving model ...
	 Train_Loss: 0.6258 Train_Acc: 66.125 Val_Loss: 0.6302  BEST VAL Loss: 0.6302  Val_Acc: 65.724

Epoch 58: Validation loss decreased (0.630235 --> 0.629812).  Saving model ...
	 Train_Loss: 0.6254 Train_Acc: 66.145 Val_Loss: 0.6298  BEST VAL Loss: 0.6298  Val_Acc: 66.090

Epoch 59: Validation loss decreased (0.629812 --> 0.629434).  Saving model ...
	 Train_Loss: 0.6250 Train_Acc: 66.288 Val_Loss: 0.6294  BEST VAL Loss: 0.6294  Val_Acc: 66.110

Epoch 60: Validation loss decreased (0.629434 --> 0.629037).  Saving model ...
	 Train_Loss: 0.6246 Train_Acc: 66.247 Val_Loss: 0.6290  BEST VAL Loss: 0.6290  Val_Acc: 65.957

Epoch 61: Validation loss decreased (0.629037 --> 0.628667).  Saving model ...
	 Train_Loss: 0.6242 Train_Acc: 66.338 Val_Loss: 0.6287  BEST VAL Loss: 0.6287  Val_Acc: 65.814

Epoch 62: Validation loss decreased (0.628667 --> 0.628364).  Saving model ...
	 Train_Loss: 0.6238 Train_Acc: 66.205 Val_Loss: 0.6284  BEST VAL Loss: 0.6284  Val_Acc: 65.695

Epoch 63: Validation loss decreased (0.628364 --> 0.628034).  Saving model ...
	 Train_Loss: 0.6234 Train_Acc: 66.468 Val_Loss: 0.6280  BEST VAL Loss: 0.6280  Val_Acc: 65.995

Epoch 64: Validation loss decreased (0.628034 --> 0.627659).  Saving model ...
	 Train_Loss: 0.6230 Train_Acc: 66.340 Val_Loss: 0.6277  BEST VAL Loss: 0.6277  Val_Acc: 66.086

Epoch 65: Validation loss decreased (0.627659 --> 0.627299).  Saving model ...
	 Train_Loss: 0.6226 Train_Acc: 66.489 Val_Loss: 0.6273  BEST VAL Loss: 0.6273  Val_Acc: 66.019

Epoch 66: Validation loss decreased (0.627299 --> 0.626980).  Saving model ...
	 Train_Loss: 0.6222 Train_Acc: 66.463 Val_Loss: 0.6270  BEST VAL Loss: 0.6270  Val_Acc: 66.219

Epoch 67: Validation loss decreased (0.626980 --> 0.626644).  Saving model ...
	 Train_Loss: 0.6219 Train_Acc: 66.458 Val_Loss: 0.6266  BEST VAL Loss: 0.6266  Val_Acc: 66.048

Epoch 68: Validation loss decreased (0.626644 --> 0.626337).  Saving model ...
	 Train_Loss: 0.6215 Train_Acc: 66.540 Val_Loss: 0.6263  BEST VAL Loss: 0.6263  Val_Acc: 65.795

Epoch 69: Validation loss decreased (0.626337 --> 0.626076).  Saving model ...
	 Train_Loss: 0.6211 Train_Acc: 66.634 Val_Loss: 0.6261  BEST VAL Loss: 0.6261  Val_Acc: 65.857

Epoch 70: Validation loss decreased (0.626076 --> 0.625831).  Saving model ...
	 Train_Loss: 0.6208 Train_Acc: 66.544 Val_Loss: 0.6258  BEST VAL Loss: 0.6258  Val_Acc: 65.867

Epoch 71: Validation loss decreased (0.625831 --> 0.625509).  Saving model ...
	 Train_Loss: 0.6205 Train_Acc: 66.505 Val_Loss: 0.6255  BEST VAL Loss: 0.6255  Val_Acc: 66.067

Epoch 72: Validation loss decreased (0.625509 --> 0.625225).  Saving model ...
	 Train_Loss: 0.6201 Train_Acc: 66.703 Val_Loss: 0.6252  BEST VAL Loss: 0.6252  Val_Acc: 66.181

Epoch 73: Validation loss decreased (0.625225 --> 0.624927).  Saving model ...
	 Train_Loss: 0.6198 Train_Acc: 66.706 Val_Loss: 0.6249  BEST VAL Loss: 0.6249  Val_Acc: 66.429

Epoch 74: Validation loss decreased (0.624927 --> 0.624660).  Saving model ...
	 Train_Loss: 0.6195 Train_Acc: 66.709 Val_Loss: 0.6247  BEST VAL Loss: 0.6247  Val_Acc: 66.438

Epoch 75: Validation loss decreased (0.624660 --> 0.624385).  Saving model ...
	 Train_Loss: 0.6191 Train_Acc: 66.728 Val_Loss: 0.6244  BEST VAL Loss: 0.6244  Val_Acc: 66.248

Epoch 76: Validation loss decreased (0.624385 --> 0.624109).  Saving model ...
	 Train_Loss: 0.6188 Train_Acc: 66.674 Val_Loss: 0.6241  BEST VAL Loss: 0.6241  Val_Acc: 66.519

Epoch 77: Validation loss decreased (0.624109 --> 0.623889).  Saving model ...
	 Train_Loss: 0.6185 Train_Acc: 66.797 Val_Loss: 0.6239  BEST VAL Loss: 0.6239  Val_Acc: 66.000

Epoch 78: Validation loss decreased (0.623889 --> 0.623614).  Saving model ...
	 Train_Loss: 0.6182 Train_Acc: 66.777 Val_Loss: 0.6236  BEST VAL Loss: 0.6236  Val_Acc: 66.514

Epoch 79: Validation loss decreased (0.623614 --> 0.623355).  Saving model ...
	 Train_Loss: 0.6179 Train_Acc: 66.833 Val_Loss: 0.6234  BEST VAL Loss: 0.6234  Val_Acc: 66.352

Epoch 80: Validation loss decreased (0.623355 --> 0.623081).  Saving model ...
	 Train_Loss: 0.6176 Train_Acc: 66.858 Val_Loss: 0.6231  BEST VAL Loss: 0.6231  Val_Acc: 66.448

Epoch 81: Validation loss decreased (0.623081 --> 0.622799).  Saving model ...
	 Train_Loss: 0.6173 Train_Acc: 66.832 Val_Loss: 0.6228  BEST VAL Loss: 0.6228  Val_Acc: 66.419

Epoch 82: Validation loss decreased (0.622799 --> 0.622549).  Saving model ...
	 Train_Loss: 0.6170 Train_Acc: 66.895 Val_Loss: 0.6225  BEST VAL Loss: 0.6225  Val_Acc: 66.467

Epoch 83: Validation loss decreased (0.622549 --> 0.622303).  Saving model ...
	 Train_Loss: 0.6167 Train_Acc: 66.881 Val_Loss: 0.6223  BEST VAL Loss: 0.6223  Val_Acc: 66.333

Epoch 84: Validation loss decreased (0.622303 --> 0.622045).  Saving model ...
	 Train_Loss: 0.6164 Train_Acc: 66.912 Val_Loss: 0.6220  BEST VAL Loss: 0.6220  Val_Acc: 66.376

Epoch 85: Validation loss decreased (0.622045 --> 0.621769).  Saving model ...
	 Train_Loss: 0.6161 Train_Acc: 67.086 Val_Loss: 0.6218  BEST VAL Loss: 0.6218  Val_Acc: 66.548

Epoch 86: Validation loss decreased (0.621769 --> 0.621577).  Saving model ...
	 Train_Loss: 0.6158 Train_Acc: 66.977 Val_Loss: 0.6216  BEST VAL Loss: 0.6216  Val_Acc: 66.510

Epoch 87: Validation loss decreased (0.621577 --> 0.621328).  Saving model ...
	 Train_Loss: 0.6155 Train_Acc: 66.990 Val_Loss: 0.6213  BEST VAL Loss: 0.6213  Val_Acc: 66.786

Epoch 88: Validation loss decreased (0.621328 --> 0.621090).  Saving model ...
	 Train_Loss: 0.6152 Train_Acc: 67.047 Val_Loss: 0.6211  BEST VAL Loss: 0.6211  Val_Acc: 66.529

Epoch 89: Validation loss decreased (0.621090 --> 0.620841).  Saving model ...
	 Train_Loss: 0.6150 Train_Acc: 67.025 Val_Loss: 0.6208  BEST VAL Loss: 0.6208  Val_Acc: 66.662

Epoch 90: Validation loss decreased (0.620841 --> 0.620613).  Saving model ...
	 Train_Loss: 0.6147 Train_Acc: 67.258 Val_Loss: 0.6206  BEST VAL Loss: 0.6206  Val_Acc: 66.700

Epoch 91: Validation loss decreased (0.620613 --> 0.620372).  Saving model ...
	 Train_Loss: 0.6144 Train_Acc: 67.151 Val_Loss: 0.6204  BEST VAL Loss: 0.6204  Val_Acc: 66.700

Epoch 92: Validation loss decreased (0.620372 --> 0.620161).  Saving model ...
	 Train_Loss: 0.6141 Train_Acc: 67.267 Val_Loss: 0.6202  BEST VAL Loss: 0.6202  Val_Acc: 66.538

Epoch 93: Validation loss decreased (0.620161 --> 0.619951).  Saving model ...
	 Train_Loss: 0.6139 Train_Acc: 67.296 Val_Loss: 0.6200  BEST VAL Loss: 0.6200  Val_Acc: 66.600

Epoch 94: Validation loss decreased (0.619951 --> 0.619758).  Saving model ...
	 Train_Loss: 0.6136 Train_Acc: 67.291 Val_Loss: 0.6198  BEST VAL Loss: 0.6198  Val_Acc: 66.519

Epoch 95: Validation loss decreased (0.619758 --> 0.619539).  Saving model ...
	 Train_Loss: 0.6134 Train_Acc: 67.244 Val_Loss: 0.6195  BEST VAL Loss: 0.6195  Val_Acc: 66.800

Epoch 96: Validation loss decreased (0.619539 --> 0.619343).  Saving model ...
	 Train_Loss: 0.6131 Train_Acc: 67.191 Val_Loss: 0.6193  BEST VAL Loss: 0.6193  Val_Acc: 66.900

Epoch 97: Validation loss decreased (0.619343 --> 0.619165).  Saving model ...
	 Train_Loss: 0.6129 Train_Acc: 67.241 Val_Loss: 0.6192  BEST VAL Loss: 0.6192  Val_Acc: 66.757

Epoch 98: Validation loss decreased (0.619165 --> 0.618961).  Saving model ...
	 Train_Loss: 0.6126 Train_Acc: 67.215 Val_Loss: 0.6190  BEST VAL Loss: 0.6190  Val_Acc: 66.733

Epoch 99: Validation loss decreased (0.618961 --> 0.618753).  Saving model ...
	 Train_Loss: 0.6124 Train_Acc: 67.143 Val_Loss: 0.6188  BEST VAL Loss: 0.6188  Val_Acc: 66.710

LPS_0.010_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.59      0.55     85025
           1       0.49      0.41      0.45     82968

    accuracy                           0.50    167993
   macro avg       0.50      0.50      0.50    167993
weighted avg       0.50      0.50      0.50    167993

LPS_0.010_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.60      0.55     10629
           1       0.50      0.41      0.45     10371

    accuracy                           0.50     21000
   macro avg       0.50      0.50      0.50     21000
weighted avg       0.50      0.50      0.50     21000

LPS_0.010_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.60      0.55     10629
           1       0.49      0.40      0.44     10371

    accuracy                           0.50     21000
   macro avg       0.50      0.50      0.50     21000
weighted avg       0.50      0.50      0.50     21000

              precision    recall  f1-score   support

           0       0.51      0.60      0.55     10629
           1       0.49      0.40      0.44     10371

    accuracy                           0.50     21000
   macro avg       0.50      0.50      0.50     21000
weighted avg       0.50      0.50      0.50     21000

LPS_0.010_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.44      0.48     36797
           1       0.49      0.55      0.52     34887

    accuracy                           0.50     71684
   macro avg       0.50      0.50      0.50     71684
weighted avg       0.50      0.50      0.50     71684

              precision    recall  f1-score   support

           0       0.51      0.44      0.48     36797
           1       0.49      0.55      0.52     34887

    accuracy                           0.50     71684
   macro avg       0.50      0.50      0.50     71684
weighted avg       0.50      0.50      0.50     71684

completed
