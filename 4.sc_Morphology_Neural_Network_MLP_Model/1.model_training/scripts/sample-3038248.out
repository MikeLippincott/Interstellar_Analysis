[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'f9203db4'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '4e0879ae'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'f4913ac4'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '881c4574'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_1.000_DMSO_0.025 treatment_name: LPS_10.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_1.000_DMSO_0.025
TREATMENT_NAME: LPS_10.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'LPS_10.000_DMSO_0.025']
The dimensions of the data are: (33268, 1276)
Number of total missing values across all columns: 66536
Data Subset Is Off
Wells held out for testing: ['D20' 'E21']
Wells to use for training, validation, and testing ['D16' 'E16' 'D17' 'E17' 'E20' 'D21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.690253).  Saving model ...
	 Train_Loss: 0.6968 Train_Acc: 51.680 Val_Loss: 0.6903  BEST VAL Loss: 0.6903  Val_Acc: 54.210

Epoch 1: Validation loss decreased (0.690253 --> 0.687665).  Saving model ...
	 Train_Loss: 0.6935 Train_Acc: 53.028 Val_Loss: 0.6877  BEST VAL Loss: 0.6877  Val_Acc: 55.213

Epoch 2: Validation loss decreased (0.687665 --> 0.685765).  Saving model ...
	 Train_Loss: 0.6913 Train_Acc: 53.620 Val_Loss: 0.6858  BEST VAL Loss: 0.6858  Val_Acc: 55.373

Epoch 3: Validation loss decreased (0.685765 --> 0.684057).  Saving model ...
	 Train_Loss: 0.6895 Train_Acc: 54.016 Val_Loss: 0.6841  BEST VAL Loss: 0.6841  Val_Acc: 57.057

Epoch 4: Validation loss decreased (0.684057 --> 0.682420).  Saving model ...
	 Train_Loss: 0.6882 Train_Acc: 54.778 Val_Loss: 0.6824  BEST VAL Loss: 0.6824  Val_Acc: 56.375

Epoch 5: Validation loss decreased (0.682420 --> 0.681399).  Saving model ...
	 Train_Loss: 0.6868 Train_Acc: 54.944 Val_Loss: 0.6814  BEST VAL Loss: 0.6814  Val_Acc: 57.779

Epoch 6: Validation loss decreased (0.681399 --> 0.680511).  Saving model ...
	 Train_Loss: 0.6855 Train_Acc: 55.345 Val_Loss: 0.6805  BEST VAL Loss: 0.6805  Val_Acc: 58.019

Epoch 7: Validation loss decreased (0.680511 --> 0.679731).  Saving model ...
	 Train_Loss: 0.6843 Train_Acc: 55.611 Val_Loss: 0.6797  BEST VAL Loss: 0.6797  Val_Acc: 56.816

Epoch 8: Validation loss decreased (0.679731 --> 0.679158).  Saving model ...
	 Train_Loss: 0.6831 Train_Acc: 56.037 Val_Loss: 0.6792  BEST VAL Loss: 0.6792  Val_Acc: 57.418

Epoch 9: Validation loss decreased (0.679158 --> 0.678687).  Saving model ...
	 Train_Loss: 0.6821 Train_Acc: 56.117 Val_Loss: 0.6787  BEST VAL Loss: 0.6787  Val_Acc: 57.498

Epoch 10: Validation loss decreased (0.678687 --> 0.678119).  Saving model ...
	 Train_Loss: 0.6812 Train_Acc: 55.902 Val_Loss: 0.6781  BEST VAL Loss: 0.6781  Val_Acc: 57.578

Epoch 11: Validation loss decreased (0.678119 --> 0.677429).  Saving model ...
	 Train_Loss: 0.6804 Train_Acc: 56.463 Val_Loss: 0.6774  BEST VAL Loss: 0.6774  Val_Acc: 58.701

Epoch 12: Validation loss decreased (0.677429 --> 0.677223).  Saving model ...
	 Train_Loss: 0.6796 Train_Acc: 56.338 Val_Loss: 0.6772  BEST VAL Loss: 0.6772  Val_Acc: 57.739

Epoch 13: Validation loss decreased (0.677223 --> 0.676630).  Saving model ...
	 Train_Loss: 0.6789 Train_Acc: 56.568 Val_Loss: 0.6766  BEST VAL Loss: 0.6766  Val_Acc: 57.899

Epoch 14: Validation loss decreased (0.676630 --> 0.676057).  Saving model ...
	 Train_Loss: 0.6782 Train_Acc: 56.774 Val_Loss: 0.6761  BEST VAL Loss: 0.6761  Val_Acc: 58.260

Epoch 15: Validation loss decreased (0.676057 --> 0.675794).  Saving model ...
	 Train_Loss: 0.6775 Train_Acc: 57.005 Val_Loss: 0.6758  BEST VAL Loss: 0.6758  Val_Acc: 58.420

Epoch 16: Validation loss decreased (0.675794 --> 0.675417).  Saving model ...
	 Train_Loss: 0.6769 Train_Acc: 57.305 Val_Loss: 0.6754  BEST VAL Loss: 0.6754  Val_Acc: 58.460

Epoch 17: Validation loss decreased (0.675417 --> 0.675076).  Saving model ...
	 Train_Loss: 0.6762 Train_Acc: 57.310 Val_Loss: 0.6751  BEST VAL Loss: 0.6751  Val_Acc: 59.423

Epoch 18: Validation loss decreased (0.675076 --> 0.674822).  Saving model ...
	 Train_Loss: 0.6755 Train_Acc: 57.476 Val_Loss: 0.6748  BEST VAL Loss: 0.6748  Val_Acc: 58.581

Epoch 19: Validation loss decreased (0.674822 --> 0.674441).  Saving model ...
	 Train_Loss: 0.6749 Train_Acc: 57.481 Val_Loss: 0.6744  BEST VAL Loss: 0.6744  Val_Acc: 58.540

Epoch 20: Validation loss decreased (0.674441 --> 0.674186).  Saving model ...
	 Train_Loss: 0.6744 Train_Acc: 57.401 Val_Loss: 0.6742  BEST VAL Loss: 0.6742  Val_Acc: 58.460

Epoch 21: Validation loss decreased (0.674186 --> 0.673982).  Saving model ...
	 Train_Loss: 0.6738 Train_Acc: 57.972 Val_Loss: 0.6740  BEST VAL Loss: 0.6740  Val_Acc: 58.019

Epoch 22: Validation loss decreased (0.673982 --> 0.673623).  Saving model ...
	 Train_Loss: 0.6733 Train_Acc: 57.516 Val_Loss: 0.6736  BEST VAL Loss: 0.6736  Val_Acc: 58.540

Epoch 23: Validation loss decreased (0.673623 --> 0.673330).  Saving model ...
	 Train_Loss: 0.6727 Train_Acc: 57.892 Val_Loss: 0.6733  BEST VAL Loss: 0.6733  Val_Acc: 58.982

Epoch 24: Validation loss decreased (0.673330 --> 0.673202).  Saving model ...
	 Train_Loss: 0.6721 Train_Acc: 58.093 Val_Loss: 0.6732  BEST VAL Loss: 0.6732  Val_Acc: 58.741

Epoch 25: Validation loss decreased (0.673202 --> 0.673034).  Saving model ...
	 Train_Loss: 0.6715 Train_Acc: 58.318 Val_Loss: 0.6730  BEST VAL Loss: 0.6730  Val_Acc: 57.899

Epoch 26: Validation loss decreased (0.673034 --> 0.672928).  Saving model ...
	 Train_Loss: 0.6710 Train_Acc: 58.489 Val_Loss: 0.6729  BEST VAL Loss: 0.6729  Val_Acc: 57.859

Epoch 27: Validation loss decreased (0.672928 --> 0.672792).  Saving model ...
	 Train_Loss: 0.6704 Train_Acc: 58.323 Val_Loss: 0.6728  BEST VAL Loss: 0.6728  Val_Acc: 58.701

Epoch 28: Validation loss decreased (0.672792 --> 0.672757).  Saving model ...
	 Train_Loss: 0.6698 Train_Acc: 58.915 Val_Loss: 0.6728  BEST VAL Loss: 0.6728  Val_Acc: 58.099

Epoch 29: Validation loss decreased (0.672757 --> 0.672628).  Saving model ...
	 Train_Loss: 0.6693 Train_Acc: 58.434 Val_Loss: 0.6726  BEST VAL Loss: 0.6726  Val_Acc: 58.260

Epoch 30: Validation loss decreased (0.672628 --> 0.672524).  Saving model ...
	 Train_Loss: 0.6688 Train_Acc: 58.544 Val_Loss: 0.6725  BEST VAL Loss: 0.6725  Val_Acc: 58.099

Epoch 31: Validation loss decreased (0.672524 --> 0.672332).  Saving model ...
	 Train_Loss: 0.6685 Train_Acc: 58.238 Val_Loss: 0.6723  BEST VAL Loss: 0.6723  Val_Acc: 58.500

Epoch 32: Validation loss decreased (0.672332 --> 0.672145).  Saving model ...
	 Train_Loss: 0.6680 Train_Acc: 58.639 Val_Loss: 0.6721  BEST VAL Loss: 0.6721  Val_Acc: 58.540

Epoch 33: Validation loss decreased (0.672145 --> 0.672047).  Saving model ...
	 Train_Loss: 0.6676 Train_Acc: 58.378 Val_Loss: 0.6720  BEST VAL Loss: 0.6720  Val_Acc: 59.102

Epoch 34: Validation loss decreased (0.672047 --> 0.671899).  Saving model ...
	 Train_Loss: 0.6672 Train_Acc: 58.790 Val_Loss: 0.6719  BEST VAL Loss: 0.6719  Val_Acc: 59.142

Epoch 35: Validation loss decreased (0.671899 --> 0.671821).  Saving model ...
	 Train_Loss: 0.6668 Train_Acc: 58.820 Val_Loss: 0.6718  BEST VAL Loss: 0.6718  Val_Acc: 58.140

Epoch 36: Validation loss decreased (0.671821 --> 0.671648).  Saving model ...
	 Train_Loss: 0.6663 Train_Acc: 59.211 Val_Loss: 0.6716  BEST VAL Loss: 0.6716  Val_Acc: 59.222

Epoch 37: Validation loss decreased (0.671648 --> 0.671543).  Saving model ...
	 Train_Loss: 0.6659 Train_Acc: 58.920 Val_Loss: 0.6715  BEST VAL Loss: 0.6715  Val_Acc: 59.062

Epoch 38: Validation loss decreased (0.671543 --> 0.671389).  Saving model ...
	 Train_Loss: 0.6655 Train_Acc: 59.030 Val_Loss: 0.6714  BEST VAL Loss: 0.6714  Val_Acc: 59.383

Epoch 39: Validation loss decreased (0.671389 --> 0.671248).  Saving model ...
	 Train_Loss: 0.6652 Train_Acc: 58.629 Val_Loss: 0.6712  BEST VAL Loss: 0.6712  Val_Acc: 58.540

Epoch 40: Validation loss decreased (0.671248 --> 0.671098).  Saving model ...
	 Train_Loss: 0.6648 Train_Acc: 59.000 Val_Loss: 0.6711  BEST VAL Loss: 0.6711  Val_Acc: 58.781

Epoch 41: Validation loss decreased (0.671098 --> 0.670970).  Saving model ...
	 Train_Loss: 0.6645 Train_Acc: 58.900 Val_Loss: 0.6710  BEST VAL Loss: 0.6710  Val_Acc: 58.982

Epoch 42: Validation loss decreased (0.670970 --> 0.670948).  Saving model ...
	 Train_Loss: 0.6641 Train_Acc: 58.790 Val_Loss: 0.6709  BEST VAL Loss: 0.6709  Val_Acc: 58.180

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.6638 Train_Acc: 59.161 Val_Loss: 0.6710  BEST VAL Loss: 0.6709  Val_Acc: 58.180

Epoch 44: Validation loss decreased (0.670948 --> 0.670866).  Saving model ...
	 Train_Loss: 0.6634 Train_Acc: 59.141 Val_Loss: 0.6709  BEST VAL Loss: 0.6709  Val_Acc: 58.661

Epoch 45: Validation loss decreased (0.670866 --> 0.670780).  Saving model ...
	 Train_Loss: 0.6631 Train_Acc: 58.950 Val_Loss: 0.6708  BEST VAL Loss: 0.6708  Val_Acc: 59.222

Epoch 46: Validation loss decreased (0.670780 --> 0.670643).  Saving model ...
	 Train_Loss: 0.6629 Train_Acc: 58.664 Val_Loss: 0.6706  BEST VAL Loss: 0.6706  Val_Acc: 58.861

Epoch 47: Validation loss decreased (0.670643 --> 0.670563).  Saving model ...
	 Train_Loss: 0.6627 Train_Acc: 58.243 Val_Loss: 0.6706  BEST VAL Loss: 0.6706  Val_Acc: 58.621

Epoch 48: Validation loss decreased (0.670563 --> 0.670553).  Saving model ...
	 Train_Loss: 0.6625 Train_Acc: 58.449 Val_Loss: 0.6706  BEST VAL Loss: 0.6706  Val_Acc: 57.899

Epoch 49: Validation loss decreased (0.670553 --> 0.670522).  Saving model ...
	 Train_Loss: 0.6623 Train_Acc: 59.356 Val_Loss: 0.6705  BEST VAL Loss: 0.6705  Val_Acc: 58.781

Epoch 50: Validation loss decreased (0.670522 --> 0.670485).  Saving model ...
	 Train_Loss: 0.6621 Train_Acc: 58.765 Val_Loss: 0.6705  BEST VAL Loss: 0.6705  Val_Acc: 58.621

Epoch 51: Validation loss decreased (0.670485 --> 0.670436).  Saving model ...
	 Train_Loss: 0.6619 Train_Acc: 58.639 Val_Loss: 0.6704  BEST VAL Loss: 0.6704  Val_Acc: 59.342

Epoch 52: Validation loss decreased (0.670436 --> 0.670413).  Saving model ...
	 Train_Loss: 0.6617 Train_Acc: 59.236 Val_Loss: 0.6704  BEST VAL Loss: 0.6704  Val_Acc: 59.583

Epoch 53: Validation loss decreased (0.670413 --> 0.670400).  Saving model ...
	 Train_Loss: 0.6615 Train_Acc: 58.419 Val_Loss: 0.6704  BEST VAL Loss: 0.6704  Val_Acc: 59.423

Epoch 54: Validation loss decreased (0.670400 --> 0.670380).  Saving model ...
	 Train_Loss: 0.6613 Train_Acc: 58.584 Val_Loss: 0.6704  BEST VAL Loss: 0.6704  Val_Acc: 59.543

Epoch 55: Validation loss decreased (0.670380 --> 0.670352).  Saving model ...
	 Train_Loss: 0.6611 Train_Acc: 59.246 Val_Loss: 0.6704  BEST VAL Loss: 0.6704  Val_Acc: 59.583

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.6609 Train_Acc: 58.905 Val_Loss: 0.6704  BEST VAL Loss: 0.6704  Val_Acc: 59.824

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.6607 Train_Acc: 59.161 Val_Loss: 0.6704  BEST VAL Loss: 0.6704  Val_Acc: 59.302

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.6604 Train_Acc: 59.376 Val_Loss: 0.6704  BEST VAL Loss: 0.6704  Val_Acc: 58.982

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.6602 Train_Acc: 59.191 Val_Loss: 0.6705  BEST VAL Loss: 0.6704  Val_Acc: 60.505

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.6600 Train_Acc: 59.712 Val_Loss: 0.6705  BEST VAL Loss: 0.6704  Val_Acc: 59.824

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.6598 Train_Acc: 59.020 Val_Loss: 0.6707  BEST VAL Loss: 0.6704  Val_Acc: 60.666

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.6596 Train_Acc: 58.855 Val_Loss: 0.6709  BEST VAL Loss: 0.6704  Val_Acc: 59.022

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.6594 Train_Acc: 59.341 Val_Loss: 0.6710  BEST VAL Loss: 0.6704  Val_Acc: 59.583

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.6591 Train_Acc: 59.216 Val_Loss: 0.6712  BEST VAL Loss: 0.6704  Val_Acc: 59.383

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.6589 Train_Acc: 59.291 Val_Loss: 0.6713  BEST VAL Loss: 0.6704  Val_Acc: 60.184

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.6587 Train_Acc: 59.537 Val_Loss: 0.6714  BEST VAL Loss: 0.6704  Val_Acc: 60.225

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.6585 Train_Acc: 59.557 Val_Loss: 0.6716  BEST VAL Loss: 0.6704  Val_Acc: 59.824

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.6582 Train_Acc: 59.652 Val_Loss: 0.6718  BEST VAL Loss: 0.6704  Val_Acc: 59.543

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.6580 Train_Acc: 59.737 Val_Loss: 0.6719  BEST VAL Loss: 0.6704  Val_Acc: 59.423

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.6578 Train_Acc: 59.492 Val_Loss: 0.6720  BEST VAL Loss: 0.6704  Val_Acc: 59.623

Epoch 71: Validation loss did not decrease
Early stopped at epoch : 71
LPS_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.88      0.36      0.51      9832
           1       0.60      0.95      0.74     10112

    accuracy                           0.66     19944
   macro avg       0.74      0.65      0.62     19944
weighted avg       0.74      0.66      0.62     19944

LPS_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.73      0.28      0.41      1229
           1       0.56      0.90      0.69      1265

    accuracy                           0.60      2494
   macro avg       0.65      0.59      0.55      2494
weighted avg       0.65      0.60      0.55      2494

LPS_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.70      0.28      0.40      1229
           1       0.56      0.88      0.68      1265

    accuracy                           0.59      2494
   macro avg       0.63      0.58      0.54      2494
weighted avg       0.63      0.59      0.54      2494

              precision    recall  f1-score   support

           0       0.70      0.28      0.40      1229
           1       0.56      0.88      0.68      1265

    accuracy                           0.59      2494
   macro avg       0.63      0.58      0.54      2494
weighted avg       0.63      0.59      0.54      2494

LPS_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.47      0.13      0.20      4168
           1       0.49      0.85      0.63      4168

    accuracy                           0.49      8336
   macro avg       0.48      0.49      0.42      8336
weighted avg       0.48      0.49      0.42      8336

              precision    recall  f1-score   support

           0       0.47      0.13      0.20      4168
           1       0.49      0.85      0.63      4168

    accuracy                           0.49      8336
   macro avg       0.48      0.49      0.42      8336
weighted avg       0.48      0.49      0.42      8336

completed
