[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '13116714'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '16feb1ef'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '7f6cc8cf'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '3cf45dfb'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_0.100_DMSO_0.025 treatment_name: H2O2_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_0.100_DMSO_0.025
TREATMENT_NAME: H2O2_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (44410, 1276)
Number of total missing values across all columns: 88820
Data Subset Is Off
Wells held out for testing: ['C21' 'H22']
Wells to use for training, validation, and testing ['C16' 'C17' 'H18' 'H19' 'C20' 'H23' 'I18' 'I19' 'I22' 'I23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.612692).  Saving model ...
	 Train_Loss: 0.7335 Train_Acc: 61.004 Val_Loss: 0.6127  BEST VAL Loss: 0.6127  Val_Acc: 66.713

Epoch 1: Validation loss decreased (0.612692 --> 0.584063).  Saving model ...
	 Train_Loss: 0.6662 Train_Acc: 67.489 Val_Loss: 0.5841  BEST VAL Loss: 0.5841  Val_Acc: 71.305

Epoch 2: Validation loss decreased (0.584063 --> 0.560268).  Saving model ...
	 Train_Loss: 0.6305 Train_Acc: 70.117 Val_Loss: 0.5603  BEST VAL Loss: 0.5603  Val_Acc: 73.628

Epoch 3: Validation loss decreased (0.560268 --> 0.547900).  Saving model ...
	 Train_Loss: 0.6054 Train_Acc: 71.682 Val_Loss: 0.5479  BEST VAL Loss: 0.5479  Val_Acc: 74.020

Epoch 4: Validation loss decreased (0.547900 --> 0.535147).  Saving model ...
	 Train_Loss: 0.5871 Train_Acc: 72.213 Val_Loss: 0.5351  BEST VAL Loss: 0.5351  Val_Acc: 75.392

Epoch 5: Validation loss decreased (0.535147 --> 0.523686).  Saving model ...
	 Train_Loss: 0.5726 Train_Acc: 72.721 Val_Loss: 0.5237  BEST VAL Loss: 0.5237  Val_Acc: 76.736

Epoch 6: Validation loss decreased (0.523686 --> 0.515929).  Saving model ...
	 Train_Loss: 0.5624 Train_Acc: 72.868 Val_Loss: 0.5159  BEST VAL Loss: 0.5159  Val_Acc: 76.680

Epoch 7: Validation loss decreased (0.515929 --> 0.510718).  Saving model ...
	 Train_Loss: 0.5526 Train_Acc: 73.302 Val_Loss: 0.5107  BEST VAL Loss: 0.5107  Val_Acc: 76.960

Epoch 8: Validation loss decreased (0.510718 --> 0.504848).  Saving model ...
	 Train_Loss: 0.5447 Train_Acc: 73.589 Val_Loss: 0.5048  BEST VAL Loss: 0.5048  Val_Acc: 77.212

Epoch 9: Validation loss decreased (0.504848 --> 0.499477).  Saving model ...
	 Train_Loss: 0.5377 Train_Acc: 73.732 Val_Loss: 0.4995  BEST VAL Loss: 0.4995  Val_Acc: 78.303

Epoch 10: Validation loss decreased (0.499477 --> 0.495340).  Saving model ...
	 Train_Loss: 0.5314 Train_Acc: 74.376 Val_Loss: 0.4953  BEST VAL Loss: 0.4953  Val_Acc: 77.744

Epoch 11: Validation loss decreased (0.495340 --> 0.491595).  Saving model ...
	 Train_Loss: 0.5260 Train_Acc: 74.208 Val_Loss: 0.4916  BEST VAL Loss: 0.4916  Val_Acc: 77.520

Epoch 12: Validation loss decreased (0.491595 --> 0.488517).  Saving model ...
	 Train_Loss: 0.5215 Train_Acc: 74.012 Val_Loss: 0.4885  BEST VAL Loss: 0.4885  Val_Acc: 76.904

Epoch 13: Validation loss decreased (0.488517 --> 0.486061).  Saving model ...
	 Train_Loss: 0.5174 Train_Acc: 73.935 Val_Loss: 0.4861  BEST VAL Loss: 0.4861  Val_Acc: 76.932

Epoch 14: Validation loss decreased (0.486061 --> 0.483322).  Saving model ...
	 Train_Loss: 0.5136 Train_Acc: 74.425 Val_Loss: 0.4833  BEST VAL Loss: 0.4833  Val_Acc: 77.128

Epoch 15: Validation loss decreased (0.483322 --> 0.480907).  Saving model ...
	 Train_Loss: 0.5103 Train_Acc: 74.432 Val_Loss: 0.4809  BEST VAL Loss: 0.4809  Val_Acc: 77.716

Epoch 16: Validation loss decreased (0.480907 --> 0.479111).  Saving model ...
	 Train_Loss: 0.5073 Train_Acc: 74.345 Val_Loss: 0.4791  BEST VAL Loss: 0.4791  Val_Acc: 78.387

Epoch 17: Validation loss decreased (0.479111 --> 0.477322).  Saving model ...
	 Train_Loss: 0.5045 Train_Acc: 74.656 Val_Loss: 0.4773  BEST VAL Loss: 0.4773  Val_Acc: 78.108

Epoch 18: Validation loss decreased (0.477322 --> 0.475591).  Saving model ...
	 Train_Loss: 0.5019 Train_Acc: 74.751 Val_Loss: 0.4756  BEST VAL Loss: 0.4756  Val_Acc: 77.912

Epoch 19: Validation loss decreased (0.475591 --> 0.473887).  Saving model ...
	 Train_Loss: 0.4999 Train_Acc: 74.761 Val_Loss: 0.4739  BEST VAL Loss: 0.4739  Val_Acc: 77.716

Epoch 20: Validation loss decreased (0.473887 --> 0.472077).  Saving model ...
	 Train_Loss: 0.4977 Train_Acc: 74.460 Val_Loss: 0.4721  BEST VAL Loss: 0.4721  Val_Acc: 77.828

Epoch 21: Validation loss decreased (0.472077 --> 0.470374).  Saving model ...
	 Train_Loss: 0.4956 Train_Acc: 74.625 Val_Loss: 0.4704  BEST VAL Loss: 0.4704  Val_Acc: 78.219

Epoch 22: Validation loss decreased (0.470374 --> 0.468873).  Saving model ...
	 Train_Loss: 0.4936 Train_Acc: 74.695 Val_Loss: 0.4689  BEST VAL Loss: 0.4689  Val_Acc: 77.744

Epoch 23: Validation loss decreased (0.468873 --> 0.467534).  Saving model ...
	 Train_Loss: 0.4919 Train_Acc: 74.807 Val_Loss: 0.4675  BEST VAL Loss: 0.4675  Val_Acc: 78.024

Epoch 24: Validation loss decreased (0.467534 --> 0.466457).  Saving model ...
	 Train_Loss: 0.4900 Train_Acc: 75.073 Val_Loss: 0.4665  BEST VAL Loss: 0.4665  Val_Acc: 77.744

Epoch 25: Validation loss decreased (0.466457 --> 0.465212).  Saving model ...
	 Train_Loss: 0.4882 Train_Acc: 75.052 Val_Loss: 0.4652  BEST VAL Loss: 0.4652  Val_Acc: 78.611

Epoch 26: Validation loss decreased (0.465212 --> 0.464202).  Saving model ...
	 Train_Loss: 0.4866 Train_Acc: 74.744 Val_Loss: 0.4642  BEST VAL Loss: 0.4642  Val_Acc: 77.324

Epoch 27: Validation loss decreased (0.464202 --> 0.463137).  Saving model ...
	 Train_Loss: 0.4851 Train_Acc: 74.481 Val_Loss: 0.4631  BEST VAL Loss: 0.4631  Val_Acc: 78.135

Epoch 28: Validation loss decreased (0.463137 --> 0.462338).  Saving model ...
	 Train_Loss: 0.4836 Train_Acc: 74.968 Val_Loss: 0.4623  BEST VAL Loss: 0.4623  Val_Acc: 78.080

Epoch 29: Validation loss decreased (0.462338 --> 0.461414).  Saving model ...
	 Train_Loss: 0.4822 Train_Acc: 75.192 Val_Loss: 0.4614  BEST VAL Loss: 0.4614  Val_Acc: 78.947

Epoch 30: Validation loss decreased (0.461414 --> 0.460654).  Saving model ...
	 Train_Loss: 0.4808 Train_Acc: 75.230 Val_Loss: 0.4607  BEST VAL Loss: 0.4607  Val_Acc: 77.268

Epoch 31: Validation loss decreased (0.460654 --> 0.459611).  Saving model ...
	 Train_Loss: 0.4796 Train_Acc: 75.143 Val_Loss: 0.4596  BEST VAL Loss: 0.4596  Val_Acc: 79.479

Epoch 32: Validation loss decreased (0.459611 --> 0.458914).  Saving model ...
	 Train_Loss: 0.4785 Train_Acc: 74.702 Val_Loss: 0.4589  BEST VAL Loss: 0.4589  Val_Acc: 77.828

Epoch 33: Validation loss decreased (0.458914 --> 0.458399).  Saving model ...
	 Train_Loss: 0.4775 Train_Acc: 74.768 Val_Loss: 0.4584  BEST VAL Loss: 0.4584  Val_Acc: 78.387

Epoch 34: Validation loss decreased (0.458399 --> 0.457555).  Saving model ...
	 Train_Loss: 0.4764 Train_Acc: 75.220 Val_Loss: 0.4576  BEST VAL Loss: 0.4576  Val_Acc: 79.535

Epoch 35: Validation loss decreased (0.457555 --> 0.456918).  Saving model ...
	 Train_Loss: 0.4753 Train_Acc: 75.318 Val_Loss: 0.4569  BEST VAL Loss: 0.4569  Val_Acc: 78.303

Epoch 36: Validation loss decreased (0.456918 --> 0.456066).  Saving model ...
	 Train_Loss: 0.4742 Train_Acc: 74.950 Val_Loss: 0.4561  BEST VAL Loss: 0.4561  Val_Acc: 78.219

Epoch 37: Validation loss decreased (0.456066 --> 0.455304).  Saving model ...
	 Train_Loss: 0.4733 Train_Acc: 75.353 Val_Loss: 0.4553  BEST VAL Loss: 0.4553  Val_Acc: 78.191

Epoch 38: Validation loss decreased (0.455304 --> 0.454880).  Saving model ...
	 Train_Loss: 0.4724 Train_Acc: 74.814 Val_Loss: 0.4549  BEST VAL Loss: 0.4549  Val_Acc: 78.303

Epoch 39: Validation loss decreased (0.454880 --> 0.454292).  Saving model ...
	 Train_Loss: 0.4714 Train_Acc: 74.740 Val_Loss: 0.4543  BEST VAL Loss: 0.4543  Val_Acc: 79.087

Epoch 40: Validation loss decreased (0.454292 --> 0.453779).  Saving model ...
	 Train_Loss: 0.4706 Train_Acc: 75.167 Val_Loss: 0.4538  BEST VAL Loss: 0.4538  Val_Acc: 78.975

Epoch 41: Validation loss decreased (0.453779 --> 0.453491).  Saving model ...
	 Train_Loss: 0.4699 Train_Acc: 74.593 Val_Loss: 0.4535  BEST VAL Loss: 0.4535  Val_Acc: 78.471

Epoch 42: Validation loss decreased (0.453491 --> 0.452843).  Saving model ...
	 Train_Loss: 0.4691 Train_Acc: 75.083 Val_Loss: 0.4528  BEST VAL Loss: 0.4528  Val_Acc: 78.583

Epoch 43: Validation loss decreased (0.452843 --> 0.452477).  Saving model ...
	 Train_Loss: 0.4683 Train_Acc: 75.013 Val_Loss: 0.4525  BEST VAL Loss: 0.4525  Val_Acc: 78.108

Epoch 44: Validation loss decreased (0.452477 --> 0.452037).  Saving model ...
	 Train_Loss: 0.4675 Train_Acc: 75.269 Val_Loss: 0.4520  BEST VAL Loss: 0.4520  Val_Acc: 78.499

Epoch 45: Validation loss decreased (0.452037 --> 0.451646).  Saving model ...
	 Train_Loss: 0.4668 Train_Acc: 75.164 Val_Loss: 0.4516  BEST VAL Loss: 0.4516  Val_Acc: 77.940

Epoch 46: Validation loss decreased (0.451646 --> 0.451293).  Saving model ...
	 Train_Loss: 0.4661 Train_Acc: 75.171 Val_Loss: 0.4513  BEST VAL Loss: 0.4513  Val_Acc: 77.716

Epoch 47: Validation loss decreased (0.451293 --> 0.450880).  Saving model ...
	 Train_Loss: 0.4654 Train_Acc: 75.276 Val_Loss: 0.4509  BEST VAL Loss: 0.4509  Val_Acc: 79.087

Epoch 48: Validation loss decreased (0.450880 --> 0.450519).  Saving model ...
	 Train_Loss: 0.4647 Train_Acc: 75.059 Val_Loss: 0.4505  BEST VAL Loss: 0.4505  Val_Acc: 77.576

Epoch 49: Validation loss decreased (0.450519 --> 0.450096).  Saving model ...
	 Train_Loss: 0.4641 Train_Acc: 75.220 Val_Loss: 0.4501  BEST VAL Loss: 0.4501  Val_Acc: 77.884

Epoch 50: Validation loss decreased (0.450096 --> 0.449734).  Saving model ...
	 Train_Loss: 0.4634 Train_Acc: 75.167 Val_Loss: 0.4497  BEST VAL Loss: 0.4497  Val_Acc: 77.632

Epoch 51: Validation loss decreased (0.449734 --> 0.449566).  Saving model ...
	 Train_Loss: 0.4628 Train_Acc: 75.122 Val_Loss: 0.4496  BEST VAL Loss: 0.4496  Val_Acc: 78.135

Epoch 52: Validation loss decreased (0.449566 --> 0.449333).  Saving model ...
	 Train_Loss: 0.4622 Train_Acc: 74.744 Val_Loss: 0.4493  BEST VAL Loss: 0.4493  Val_Acc: 78.443

Epoch 53: Validation loss decreased (0.449333 --> 0.449235).  Saving model ...
	 Train_Loss: 0.4616 Train_Acc: 75.087 Val_Loss: 0.4492  BEST VAL Loss: 0.4492  Val_Acc: 77.268

Epoch 54: Validation loss decreased (0.449235 --> 0.449144).  Saving model ...
	 Train_Loss: 0.4611 Train_Acc: 75.073 Val_Loss: 0.4491  BEST VAL Loss: 0.4491  Val_Acc: 78.024

Epoch 55: Validation loss decreased (0.449144 --> 0.448851).  Saving model ...
	 Train_Loss: 0.4604 Train_Acc: 75.146 Val_Loss: 0.4489  BEST VAL Loss: 0.4489  Val_Acc: 78.052

Epoch 56: Validation loss decreased (0.448851 --> 0.448489).  Saving model ...
	 Train_Loss: 0.4598 Train_Acc: 75.090 Val_Loss: 0.4485  BEST VAL Loss: 0.4485  Val_Acc: 77.492

Epoch 57: Validation loss decreased (0.448489 --> 0.448110).  Saving model ...
	 Train_Loss: 0.4592 Train_Acc: 75.146 Val_Loss: 0.4481  BEST VAL Loss: 0.4481  Val_Acc: 78.135

Epoch 58: Validation loss decreased (0.448110 --> 0.447733).  Saving model ...
	 Train_Loss: 0.4586 Train_Acc: 75.370 Val_Loss: 0.4477  BEST VAL Loss: 0.4477  Val_Acc: 78.303

Epoch 59: Validation loss decreased (0.447733 --> 0.447305).  Saving model ...
	 Train_Loss: 0.4580 Train_Acc: 75.650 Val_Loss: 0.4473  BEST VAL Loss: 0.4473  Val_Acc: 78.135

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.4575 Train_Acc: 74.936 Val_Loss: 0.4474  BEST VAL Loss: 0.4473  Val_Acc: 77.548

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.4570 Train_Acc: 75.370 Val_Loss: 0.4475  BEST VAL Loss: 0.4473  Val_Acc: 77.688

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.4566 Train_Acc: 75.199 Val_Loss: 0.4475  BEST VAL Loss: 0.4473  Val_Acc: 78.471

Epoch 63: Validation loss decreased (0.447305 --> 0.447233).  Saving model ...
	 Train_Loss: 0.4561 Train_Acc: 75.367 Val_Loss: 0.4472  BEST VAL Loss: 0.4472  Val_Acc: 77.324

Epoch 64: Validation loss decreased (0.447233 --> 0.447054).  Saving model ...
	 Train_Loss: 0.4556 Train_Acc: 75.318 Val_Loss: 0.4471  BEST VAL Loss: 0.4471  Val_Acc: 79.115

Epoch 65: Validation loss decreased (0.447054 --> 0.446906).  Saving model ...
	 Train_Loss: 0.4551 Train_Acc: 75.157 Val_Loss: 0.4469  BEST VAL Loss: 0.4469  Val_Acc: 77.184

Epoch 66: Validation loss decreased (0.446906 --> 0.446591).  Saving model ...
	 Train_Loss: 0.4546 Train_Acc: 75.174 Val_Loss: 0.4466  BEST VAL Loss: 0.4466  Val_Acc: 77.912

Epoch 67: Validation loss decreased (0.446591 --> 0.446424).  Saving model ...
	 Train_Loss: 0.4541 Train_Acc: 75.258 Val_Loss: 0.4464  BEST VAL Loss: 0.4464  Val_Acc: 78.387

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.4537 Train_Acc: 75.346 Val_Loss: 0.4465  BEST VAL Loss: 0.4464  Val_Acc: 78.135

Epoch 69: Validation loss decreased (0.446424 --> 0.446277).  Saving model ...
	 Train_Loss: 0.4532 Train_Acc: 75.069 Val_Loss: 0.4463  BEST VAL Loss: 0.4463  Val_Acc: 78.835

Epoch 70: Validation loss decreased (0.446277 --> 0.446041).  Saving model ...
	 Train_Loss: 0.4528 Train_Acc: 75.339 Val_Loss: 0.4460  BEST VAL Loss: 0.4460  Val_Acc: 77.828

Epoch 71: Validation loss decreased (0.446041 --> 0.445906).  Saving model ...
	 Train_Loss: 0.4523 Train_Acc: 75.468 Val_Loss: 0.4459  BEST VAL Loss: 0.4459  Val_Acc: 77.436

Epoch 72: Validation loss decreased (0.445906 --> 0.445735).  Saving model ...
	 Train_Loss: 0.4519 Train_Acc: 75.230 Val_Loss: 0.4457  BEST VAL Loss: 0.4457  Val_Acc: 77.464

Epoch 73: Validation loss decreased (0.445735 --> 0.445728).  Saving model ...
	 Train_Loss: 0.4514 Train_Acc: 75.307 Val_Loss: 0.4457  BEST VAL Loss: 0.4457  Val_Acc: 77.520

Epoch 74: Validation loss decreased (0.445728 --> 0.445655).  Saving model ...
	 Train_Loss: 0.4510 Train_Acc: 75.066 Val_Loss: 0.4457  BEST VAL Loss: 0.4457  Val_Acc: 77.436

Epoch 75: Validation loss decreased (0.445655 --> 0.445549).  Saving model ...
	 Train_Loss: 0.4506 Train_Acc: 75.171 Val_Loss: 0.4455  BEST VAL Loss: 0.4455  Val_Acc: 77.828

Epoch 76: Validation loss decreased (0.445549 --> 0.445508).  Saving model ...
	 Train_Loss: 0.4502 Train_Acc: 75.524 Val_Loss: 0.4455  BEST VAL Loss: 0.4455  Val_Acc: 78.052

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.4498 Train_Acc: 75.552 Val_Loss: 0.4455  BEST VAL Loss: 0.4455  Val_Acc: 77.324

Epoch 78: Validation loss decreased (0.445508 --> 0.445463).  Saving model ...
	 Train_Loss: 0.4494 Train_Acc: 75.234 Val_Loss: 0.4455  BEST VAL Loss: 0.4455  Val_Acc: 77.968

Epoch 79: Validation loss decreased (0.445463 --> 0.445371).  Saving model ...
	 Train_Loss: 0.4491 Train_Acc: 75.118 Val_Loss: 0.4454  BEST VAL Loss: 0.4454  Val_Acc: 77.800

Epoch 80: Validation loss decreased (0.445371 --> 0.445175).  Saving model ...
	 Train_Loss: 0.4487 Train_Acc: 75.139 Val_Loss: 0.4452  BEST VAL Loss: 0.4452  Val_Acc: 77.996

Epoch 81: Validation loss decreased (0.445175 --> 0.445059).  Saving model ...
	 Train_Loss: 0.4483 Train_Acc: 75.132 Val_Loss: 0.4451  BEST VAL Loss: 0.4451  Val_Acc: 77.828

Epoch 82: Validation loss decreased (0.445059 --> 0.445021).  Saving model ...
	 Train_Loss: 0.4479 Train_Acc: 75.164 Val_Loss: 0.4450  BEST VAL Loss: 0.4450  Val_Acc: 77.212

Epoch 83: Validation loss decreased (0.445021 --> 0.444913).  Saving model ...
	 Train_Loss: 0.4476 Train_Acc: 74.936 Val_Loss: 0.4449  BEST VAL Loss: 0.4449  Val_Acc: 77.800

Epoch 84: Validation loss decreased (0.444913 --> 0.444844).  Saving model ...
	 Train_Loss: 0.4472 Train_Acc: 75.094 Val_Loss: 0.4448  BEST VAL Loss: 0.4448  Val_Acc: 77.716

Epoch 85: Validation loss decreased (0.444844 --> 0.444761).  Saving model ...
	 Train_Loss: 0.4469 Train_Acc: 75.237 Val_Loss: 0.4448  BEST VAL Loss: 0.4448  Val_Acc: 78.415

Epoch 86: Validation loss decreased (0.444761 --> 0.444709).  Saving model ...
	 Train_Loss: 0.4466 Train_Acc: 75.083 Val_Loss: 0.4447  BEST VAL Loss: 0.4447  Val_Acc: 77.744

Epoch 87: Validation loss decreased (0.444709 --> 0.444604).  Saving model ...
	 Train_Loss: 0.4463 Train_Acc: 75.027 Val_Loss: 0.4446  BEST VAL Loss: 0.4446  Val_Acc: 77.548

Epoch 88: Validation loss decreased (0.444604 --> 0.444550).  Saving model ...
	 Train_Loss: 0.4459 Train_Acc: 75.692 Val_Loss: 0.4446  BEST VAL Loss: 0.4446  Val_Acc: 77.716

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.4457 Train_Acc: 75.076 Val_Loss: 0.4447  BEST VAL Loss: 0.4446  Val_Acc: 77.884

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.4453 Train_Acc: 75.381 Val_Loss: 0.4446  BEST VAL Loss: 0.4446  Val_Acc: 77.912

Epoch 91: Validation loss decreased (0.444550 --> 0.444511).  Saving model ...
	 Train_Loss: 0.4450 Train_Acc: 75.258 Val_Loss: 0.4445  BEST VAL Loss: 0.4445  Val_Acc: 77.856

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.4448 Train_Acc: 74.982 Val_Loss: 0.4446  BEST VAL Loss: 0.4445  Val_Acc: 77.156

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.4446 Train_Acc: 74.758 Val_Loss: 0.4449  BEST VAL Loss: 0.4445  Val_Acc: 76.400

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.4442 Train_Acc: 75.325 Val_Loss: 0.4449  BEST VAL Loss: 0.4445  Val_Acc: 76.820

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.4439 Train_Acc: 75.370 Val_Loss: 0.4448  BEST VAL Loss: 0.4445  Val_Acc: 77.184

Epoch 96: Validation loss did not decrease
	 Train_Loss: 0.4436 Train_Acc: 75.279 Val_Loss: 0.4449  BEST VAL Loss: 0.4445  Val_Acc: 77.716

Epoch 97: Validation loss did not decrease
	 Train_Loss: 0.4433 Train_Acc: 74.982 Val_Loss: 0.4449  BEST VAL Loss: 0.4445  Val_Acc: 77.828

Epoch 98: Validation loss did not decrease
	 Train_Loss: 0.4431 Train_Acc: 75.055 Val_Loss: 0.4450  BEST VAL Loss: 0.4445  Val_Acc: 77.996

Epoch 99: Validation loss did not decrease
	 Train_Loss: 0.4428 Train_Acc: 75.363 Val_Loss: 0.4449  BEST VAL Loss: 0.4445  Val_Acc: 77.632

LPS_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.64      0.76      0.69     18174
           1       0.37      0.25      0.29     10401

    accuracy                           0.57     28575
   macro avg       0.50      0.50      0.49     28575
weighted avg       0.54      0.57      0.55     28575

LPS_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.64      0.76      0.69      2272
           1       0.37      0.24      0.29      1300

    accuracy                           0.57      3572
   macro avg       0.50      0.50      0.49      3572
weighted avg       0.54      0.57      0.55      3572

LPS_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.63      0.76      0.69      2272
           1       0.36      0.24      0.28      1300

    accuracy                           0.57      3572
   macro avg       0.49      0.50      0.49      3572
weighted avg       0.53      0.57      0.54      3572

              precision    recall  f1-score   support

           0       0.63      0.76      0.69      2272
           1       0.36      0.24      0.28      1300

    accuracy                           0.57      3572
   macro avg       0.49      0.50      0.49      3572
weighted avg       0.53      0.57      0.54      3572

LPS_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.75      0.59      4182
           1       0.54      0.27      0.35      4509

    accuracy                           0.50      8691
   macro avg       0.51      0.51      0.47      8691
weighted avg       0.51      0.50      0.47      8691

              precision    recall  f1-score   support

           0       0.49      0.75      0.59      4182
           1       0.54      0.27      0.35      4509

    accuracy                           0.50      8691
   macro avg       0.51      0.51      0.47      8691
weighted avg       0.51      0.50      0.47      8691

completed
