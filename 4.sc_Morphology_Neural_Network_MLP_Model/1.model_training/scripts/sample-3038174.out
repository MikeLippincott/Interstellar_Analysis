[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'fd791aa7'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '3f5f7f48'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'daed2df5'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '55c6572d'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_100.000_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (30389, 1276)
Number of total missing values across all columns: 31974
Data Subset Is Off
Wells held out for testing: ['M16' 'J20']
Wells to use for training, validation, and testing ['J16' 'J17' 'M17' 'M20' 'J21' 'M21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.458290).  Saving model ...
	 Train_Loss: 0.6244 Train_Acc: 62.314 Val_Loss: 0.4583  BEST VAL Loss: 0.4583  Val_Acc: 82.679

Epoch 1: Validation loss decreased (0.458290 --> 0.386067).  Saving model ...
	 Train_Loss: 0.5539 Train_Acc: 75.666 Val_Loss: 0.3861  BEST VAL Loss: 0.3861  Val_Acc: 89.398

Epoch 2: Validation loss decreased (0.386067 --> 0.349094).  Saving model ...
	 Train_Loss: 0.5163 Train_Acc: 78.361 Val_Loss: 0.3491  BEST VAL Loss: 0.3491  Val_Acc: 92.539

Epoch 3: Validation loss decreased (0.349094 --> 0.316961).  Saving model ...
	 Train_Loss: 0.4884 Train_Acc: 80.151 Val_Loss: 0.3170  BEST VAL Loss: 0.3170  Val_Acc: 93.630

Epoch 4: Validation loss decreased (0.316961 --> 0.288023).  Saving model ...
	 Train_Loss: 0.4598 Train_Acc: 80.734 Val_Loss: 0.2880  BEST VAL Loss: 0.2880  Val_Acc: 94.372

Epoch 5: Validation loss decreased (0.288023 --> 0.260351).  Saving model ...
	 Train_Loss: 0.4318 Train_Acc: 82.082 Val_Loss: 0.2604  BEST VAL Loss: 0.2604  Val_Acc: 95.593

Epoch 6: Validation loss decreased (0.260351 --> 0.239940).  Saving model ...
	 Train_Loss: 0.4082 Train_Acc: 83.381 Val_Loss: 0.2399  BEST VAL Loss: 0.2399  Val_Acc: 95.899

Epoch 7: Validation loss decreased (0.239940 --> 0.220697).  Saving model ...
	 Train_Loss: 0.3888 Train_Acc: 83.937 Val_Loss: 0.2207  BEST VAL Loss: 0.2207  Val_Acc: 96.510

Epoch 8: Validation loss decreased (0.220697 --> 0.205106).  Saving model ...
	 Train_Loss: 0.3730 Train_Acc: 84.646 Val_Loss: 0.2051  BEST VAL Loss: 0.2051  Val_Acc: 96.684

Epoch 9: Validation loss decreased (0.205106 --> 0.193478).  Saving model ...
	 Train_Loss: 0.3610 Train_Acc: 84.434 Val_Loss: 0.1935  BEST VAL Loss: 0.1935  Val_Acc: 96.553

Epoch 10: Validation loss decreased (0.193478 --> 0.182790).  Saving model ...
	 Train_Loss: 0.3500 Train_Acc: 84.783 Val_Loss: 0.1828  BEST VAL Loss: 0.1828  Val_Acc: 97.208

Epoch 11: Validation loss decreased (0.182790 --> 0.175673).  Saving model ...
	 Train_Loss: 0.3409 Train_Acc: 84.750 Val_Loss: 0.1757  BEST VAL Loss: 0.1757  Val_Acc: 96.728

Epoch 12: Validation loss decreased (0.175673 --> 0.170514).  Saving model ...
	 Train_Loss: 0.3330 Train_Acc: 84.914 Val_Loss: 0.1705  BEST VAL Loss: 0.1705  Val_Acc: 95.506

Epoch 13: Validation loss decreased (0.170514 --> 0.163839).  Saving model ...
	 Train_Loss: 0.3264 Train_Acc: 84.925 Val_Loss: 0.1638  BEST VAL Loss: 0.1638  Val_Acc: 97.862

Epoch 14: Validation loss decreased (0.163839 --> 0.158254).  Saving model ...
	 Train_Loss: 0.3208 Train_Acc: 85.034 Val_Loss: 0.1583  BEST VAL Loss: 0.1583  Val_Acc: 97.077

Epoch 15: Validation loss decreased (0.158254 --> 0.153518).  Saving model ...
	 Train_Loss: 0.3151 Train_Acc: 85.345 Val_Loss: 0.1535  BEST VAL Loss: 0.1535  Val_Acc: 96.728

Epoch 16: Validation loss decreased (0.153518 --> 0.148909).  Saving model ...
	 Train_Loss: 0.3102 Train_Acc: 84.990 Val_Loss: 0.1489  BEST VAL Loss: 0.1489  Val_Acc: 97.208

Epoch 17: Validation loss decreased (0.148909 --> 0.144891).  Saving model ...
	 Train_Loss: 0.3056 Train_Acc: 85.438 Val_Loss: 0.1449  BEST VAL Loss: 0.1449  Val_Acc: 97.382

Epoch 18: Validation loss decreased (0.144891 --> 0.140647).  Saving model ...
	 Train_Loss: 0.3015 Train_Acc: 85.639 Val_Loss: 0.1406  BEST VAL Loss: 0.1406  Val_Acc: 98.168

Epoch 19: Validation loss decreased (0.140647 --> 0.137320).  Saving model ...
	 Train_Loss: 0.2978 Train_Acc: 85.634 Val_Loss: 0.1373  BEST VAL Loss: 0.1373  Val_Acc: 97.208

Epoch 20: Validation loss decreased (0.137320 --> 0.134036).  Saving model ...
	 Train_Loss: 0.2945 Train_Acc: 85.623 Val_Loss: 0.1340  BEST VAL Loss: 0.1340  Val_Acc: 97.818

Epoch 21: Validation loss decreased (0.134036 --> 0.131001).  Saving model ...
	 Train_Loss: 0.2914 Train_Acc: 85.323 Val_Loss: 0.1310  BEST VAL Loss: 0.1310  Val_Acc: 97.731

Epoch 22: Validation loss decreased (0.131001 --> 0.128688).  Saving model ...
	 Train_Loss: 0.2886 Train_Acc: 85.148 Val_Loss: 0.1287  BEST VAL Loss: 0.1287  Val_Acc: 97.513

Epoch 23: Validation loss decreased (0.128688 --> 0.126327).  Saving model ...
	 Train_Loss: 0.2858 Train_Acc: 85.667 Val_Loss: 0.1263  BEST VAL Loss: 0.1263  Val_Acc: 97.862

Epoch 24: Validation loss decreased (0.126327 --> 0.124097).  Saving model ...
	 Train_Loss: 0.2833 Train_Acc: 85.503 Val_Loss: 0.1241  BEST VAL Loss: 0.1241  Val_Acc: 97.862

Epoch 25: Validation loss decreased (0.124097 --> 0.122081).  Saving model ...
	 Train_Loss: 0.2812 Train_Acc: 85.465 Val_Loss: 0.1221  BEST VAL Loss: 0.1221  Val_Acc: 97.557

Epoch 26: Validation loss decreased (0.122081 --> 0.120785).  Saving model ...
	 Train_Loss: 0.2798 Train_Acc: 85.017 Val_Loss: 0.1208  BEST VAL Loss: 0.1208  Val_Acc: 96.510

Epoch 27: Validation loss decreased (0.120785 --> 0.118634).  Saving model ...
	 Train_Loss: 0.2779 Train_Acc: 85.427 Val_Loss: 0.1186  BEST VAL Loss: 0.1186  Val_Acc: 98.037

Epoch 28: Validation loss decreased (0.118634 --> 0.117243).  Saving model ...
	 Train_Loss: 0.2760 Train_Acc: 85.541 Val_Loss: 0.1172  BEST VAL Loss: 0.1172  Val_Acc: 97.906

Epoch 29: Validation loss decreased (0.117243 --> 0.115798).  Saving model ...
	 Train_Loss: 0.2744 Train_Acc: 85.187 Val_Loss: 0.1158  BEST VAL Loss: 0.1158  Val_Acc: 97.862

Epoch 30: Validation loss decreased (0.115798 --> 0.114262).  Saving model ...
	 Train_Loss: 0.2727 Train_Acc: 85.394 Val_Loss: 0.1143  BEST VAL Loss: 0.1143  Val_Acc: 97.993

Epoch 31: Validation loss decreased (0.114262 --> 0.112555).  Saving model ...
	 Train_Loss: 0.2711 Train_Acc: 85.770 Val_Loss: 0.1126  BEST VAL Loss: 0.1126  Val_Acc: 98.037

Epoch 32: Validation loss decreased (0.112555 --> 0.111133).  Saving model ...
	 Train_Loss: 0.2696 Train_Acc: 85.727 Val_Loss: 0.1111  BEST VAL Loss: 0.1111  Val_Acc: 98.037

Epoch 33: Validation loss decreased (0.111133 --> 0.109651).  Saving model ...
	 Train_Loss: 0.2682 Train_Acc: 85.470 Val_Loss: 0.1097  BEST VAL Loss: 0.1097  Val_Acc: 97.862

Epoch 34: Validation loss decreased (0.109651 --> 0.108606).  Saving model ...
	 Train_Loss: 0.2668 Train_Acc: 85.509 Val_Loss: 0.1086  BEST VAL Loss: 0.1086  Val_Acc: 97.469

Epoch 35: Validation loss decreased (0.108606 --> 0.107761).  Saving model ...
	 Train_Loss: 0.2655 Train_Acc: 85.820 Val_Loss: 0.1078  BEST VAL Loss: 0.1078  Val_Acc: 97.949

Epoch 36: Validation loss decreased (0.107761 --> 0.106548).  Saving model ...
	 Train_Loss: 0.2643 Train_Acc: 85.858 Val_Loss: 0.1065  BEST VAL Loss: 0.1065  Val_Acc: 97.600

Epoch 37: Validation loss decreased (0.106548 --> 0.105687).  Saving model ...
	 Train_Loss: 0.2632 Train_Acc: 85.918 Val_Loss: 0.1057  BEST VAL Loss: 0.1057  Val_Acc: 97.731

Epoch 38: Validation loss decreased (0.105687 --> 0.104699).  Saving model ...
	 Train_Loss: 0.2620 Train_Acc: 86.223 Val_Loss: 0.1047  BEST VAL Loss: 0.1047  Val_Acc: 98.037

Epoch 39: Validation loss decreased (0.104699 --> 0.104170).  Saving model ...
	 Train_Loss: 0.2609 Train_Acc: 85.650 Val_Loss: 0.1042  BEST VAL Loss: 0.1042  Val_Acc: 97.469

Epoch 40: Validation loss decreased (0.104170 --> 0.103701).  Saving model ...
	 Train_Loss: 0.2602 Train_Acc: 85.738 Val_Loss: 0.1037  BEST VAL Loss: 0.1037  Val_Acc: 97.644

Epoch 41: Validation loss decreased (0.103701 --> 0.102968).  Saving model ...
	 Train_Loss: 0.2594 Train_Acc: 85.710 Val_Loss: 0.1030  BEST VAL Loss: 0.1030  Val_Acc: 97.557

Epoch 42: Validation loss decreased (0.102968 --> 0.102221).  Saving model ...
	 Train_Loss: 0.2586 Train_Acc: 85.492 Val_Loss: 0.1022  BEST VAL Loss: 0.1022  Val_Acc: 97.426

Epoch 43: Validation loss decreased (0.102221 --> 0.101201).  Saving model ...
	 Train_Loss: 0.2578 Train_Acc: 85.552 Val_Loss: 0.1012  BEST VAL Loss: 0.1012  Val_Acc: 98.080

Epoch 44: Validation loss decreased (0.101201 --> 0.100412).  Saving model ...
	 Train_Loss: 0.2569 Train_Acc: 85.749 Val_Loss: 0.1004  BEST VAL Loss: 0.1004  Val_Acc: 97.862

Epoch 45: Validation loss decreased (0.100412 --> 0.099474).  Saving model ...
	 Train_Loss: 0.2561 Train_Acc: 85.809 Val_Loss: 0.0995  BEST VAL Loss: 0.0995  Val_Acc: 98.211

Epoch 46: Validation loss decreased (0.099474 --> 0.098706).  Saving model ...
	 Train_Loss: 0.2553 Train_Acc: 85.945 Val_Loss: 0.0987  BEST VAL Loss: 0.0987  Val_Acc: 97.993

Epoch 47: Validation loss decreased (0.098706 --> 0.098017).  Saving model ...
	 Train_Loss: 0.2545 Train_Acc: 85.699 Val_Loss: 0.0980  BEST VAL Loss: 0.0980  Val_Acc: 97.775

Epoch 48: Validation loss decreased (0.098017 --> 0.097261).  Saving model ...
	 Train_Loss: 0.2538 Train_Acc: 85.759 Val_Loss: 0.0973  BEST VAL Loss: 0.0973  Val_Acc: 98.211

Epoch 49: Validation loss decreased (0.097261 --> 0.096546).  Saving model ...
	 Train_Loss: 0.2532 Train_Acc: 85.699 Val_Loss: 0.0965  BEST VAL Loss: 0.0965  Val_Acc: 97.993

Epoch 50: Validation loss decreased (0.096546 --> 0.095938).  Saving model ...
	 Train_Loss: 0.2525 Train_Acc: 85.656 Val_Loss: 0.0959  BEST VAL Loss: 0.0959  Val_Acc: 98.386

Epoch 51: Validation loss decreased (0.095938 --> 0.095259).  Saving model ...
	 Train_Loss: 0.2518 Train_Acc: 85.874 Val_Loss: 0.0953  BEST VAL Loss: 0.0953  Val_Acc: 98.124

Epoch 52: Validation loss decreased (0.095259 --> 0.094675).  Saving model ...
	 Train_Loss: 0.2511 Train_Acc: 85.798 Val_Loss: 0.0947  BEST VAL Loss: 0.0947  Val_Acc: 98.255

Epoch 53: Validation loss decreased (0.094675 --> 0.094215).  Saving model ...
	 Train_Loss: 0.2505 Train_Acc: 85.798 Val_Loss: 0.0942  BEST VAL Loss: 0.0942  Val_Acc: 98.080

Epoch 54: Validation loss decreased (0.094215 --> 0.093651).  Saving model ...
	 Train_Loss: 0.2499 Train_Acc: 85.901 Val_Loss: 0.0937  BEST VAL Loss: 0.0937  Val_Acc: 98.517

Epoch 55: Validation loss decreased (0.093651 --> 0.093046).  Saving model ...
	 Train_Loss: 0.2493 Train_Acc: 86.081 Val_Loss: 0.0930  BEST VAL Loss: 0.0930  Val_Acc: 98.255

Epoch 56: Validation loss decreased (0.093046 --> 0.092640).  Saving model ...
	 Train_Loss: 0.2486 Train_Acc: 86.338 Val_Loss: 0.0926  BEST VAL Loss: 0.0926  Val_Acc: 97.949

Epoch 57: Validation loss decreased (0.092640 --> 0.092232).  Saving model ...
	 Train_Loss: 0.2480 Train_Acc: 85.710 Val_Loss: 0.0922  BEST VAL Loss: 0.0922  Val_Acc: 98.211

Epoch 58: Validation loss decreased (0.092232 --> 0.091929).  Saving model ...
	 Train_Loss: 0.2475 Train_Acc: 85.874 Val_Loss: 0.0919  BEST VAL Loss: 0.0919  Val_Acc: 97.862

Epoch 59: Validation loss decreased (0.091929 --> 0.091697).  Saving model ...
	 Train_Loss: 0.2471 Train_Acc: 85.487 Val_Loss: 0.0917  BEST VAL Loss: 0.0917  Val_Acc: 98.255

Epoch 60: Validation loss decreased (0.091697 --> 0.091402).  Saving model ...
	 Train_Loss: 0.2466 Train_Acc: 86.300 Val_Loss: 0.0914  BEST VAL Loss: 0.0914  Val_Acc: 98.255

Epoch 61: Validation loss decreased (0.091402 --> 0.091006).  Saving model ...
	 Train_Loss: 0.2460 Train_Acc: 86.098 Val_Loss: 0.0910  BEST VAL Loss: 0.0910  Val_Acc: 97.949

Epoch 62: Validation loss decreased (0.091006 --> 0.090575).  Saving model ...
	 Train_Loss: 0.2456 Train_Acc: 85.547 Val_Loss: 0.0906  BEST VAL Loss: 0.0906  Val_Acc: 98.124

Epoch 63: Validation loss decreased (0.090575 --> 0.090130).  Saving model ...
	 Train_Loss: 0.2451 Train_Acc: 86.065 Val_Loss: 0.0901  BEST VAL Loss: 0.0901  Val_Acc: 98.255

Epoch 64: Validation loss decreased (0.090130 --> 0.089764).  Saving model ...
	 Train_Loss: 0.2447 Train_Acc: 85.514 Val_Loss: 0.0898  BEST VAL Loss: 0.0898  Val_Acc: 97.906

Epoch 65: Validation loss decreased (0.089764 --> 0.089432).  Saving model ...
	 Train_Loss: 0.2442 Train_Acc: 85.781 Val_Loss: 0.0894  BEST VAL Loss: 0.0894  Val_Acc: 98.168

Epoch 66: Validation loss decreased (0.089432 --> 0.089100).  Saving model ...
	 Train_Loss: 0.2439 Train_Acc: 85.372 Val_Loss: 0.0891  BEST VAL Loss: 0.0891  Val_Acc: 97.993

Epoch 67: Validation loss decreased (0.089100 --> 0.088711).  Saving model ...
	 Train_Loss: 0.2435 Train_Acc: 85.929 Val_Loss: 0.0887  BEST VAL Loss: 0.0887  Val_Acc: 98.124

Epoch 68: Validation loss decreased (0.088711 --> 0.088371).  Saving model ...
	 Train_Loss: 0.2430 Train_Acc: 85.983 Val_Loss: 0.0884  BEST VAL Loss: 0.0884  Val_Acc: 98.124

Epoch 69: Validation loss decreased (0.088371 --> 0.088001).  Saving model ...
	 Train_Loss: 0.2427 Train_Acc: 85.710 Val_Loss: 0.0880  BEST VAL Loss: 0.0880  Val_Acc: 98.211

Epoch 70: Validation loss decreased (0.088001 --> 0.087733).  Saving model ...
	 Train_Loss: 0.2422 Train_Acc: 86.196 Val_Loss: 0.0877  BEST VAL Loss: 0.0877  Val_Acc: 97.993

Epoch 71: Validation loss decreased (0.087733 --> 0.087507).  Saving model ...
	 Train_Loss: 0.2419 Train_Acc: 85.907 Val_Loss: 0.0875  BEST VAL Loss: 0.0875  Val_Acc: 98.037

Epoch 72: Validation loss decreased (0.087507 --> 0.087211).  Saving model ...
	 Train_Loss: 0.2416 Train_Acc: 85.989 Val_Loss: 0.0872  BEST VAL Loss: 0.0872  Val_Acc: 98.124

Epoch 73: Validation loss decreased (0.087211 --> 0.086914).  Saving model ...
	 Train_Loss: 0.2412 Train_Acc: 85.749 Val_Loss: 0.0869  BEST VAL Loss: 0.0869  Val_Acc: 98.298

Epoch 74: Validation loss decreased (0.086914 --> 0.086659).  Saving model ...
	 Train_Loss: 0.2408 Train_Acc: 86.294 Val_Loss: 0.0867  BEST VAL Loss: 0.0867  Val_Acc: 98.211

Epoch 75: Validation loss decreased (0.086659 --> 0.086581).  Saving model ...
	 Train_Loss: 0.2404 Train_Acc: 85.798 Val_Loss: 0.0866  BEST VAL Loss: 0.0866  Val_Acc: 98.168

Epoch 76: Validation loss decreased (0.086581 --> 0.086222).  Saving model ...
	 Train_Loss: 0.2401 Train_Acc: 85.776 Val_Loss: 0.0862  BEST VAL Loss: 0.0862  Val_Acc: 98.080

Epoch 77: Validation loss decreased (0.086222 --> 0.086027).  Saving model ...
	 Train_Loss: 0.2397 Train_Acc: 86.294 Val_Loss: 0.0860  BEST VAL Loss: 0.0860  Val_Acc: 98.124

Epoch 78: Validation loss decreased (0.086027 --> 0.085948).  Saving model ...
	 Train_Loss: 0.2393 Train_Acc: 86.158 Val_Loss: 0.0859  BEST VAL Loss: 0.0859  Val_Acc: 97.993

Epoch 79: Validation loss decreased (0.085948 --> 0.085702).  Saving model ...
	 Train_Loss: 0.2390 Train_Acc: 86.180 Val_Loss: 0.0857  BEST VAL Loss: 0.0857  Val_Acc: 98.255

Epoch 80: Validation loss decreased (0.085702 --> 0.085409).  Saving model ...
	 Train_Loss: 0.2387 Train_Acc: 85.825 Val_Loss: 0.0854  BEST VAL Loss: 0.0854  Val_Acc: 97.906

Epoch 81: Validation loss decreased (0.085409 --> 0.085114).  Saving model ...
	 Train_Loss: 0.2385 Train_Acc: 85.874 Val_Loss: 0.0851  BEST VAL Loss: 0.0851  Val_Acc: 97.906

Epoch 82: Validation loss decreased (0.085114 --> 0.084919).  Saving model ...
	 Train_Loss: 0.2382 Train_Acc: 86.087 Val_Loss: 0.0849  BEST VAL Loss: 0.0849  Val_Acc: 98.211

Epoch 83: Validation loss decreased (0.084919 --> 0.084690).  Saving model ...
	 Train_Loss: 0.2379 Train_Acc: 85.770 Val_Loss: 0.0847  BEST VAL Loss: 0.0847  Val_Acc: 98.211

Epoch 84: Validation loss decreased (0.084690 --> 0.084469).  Saving model ...
	 Train_Loss: 0.2377 Train_Acc: 85.558 Val_Loss: 0.0845  BEST VAL Loss: 0.0845  Val_Acc: 97.339

Epoch 85: Validation loss decreased (0.084469 --> 0.084403).  Saving model ...
	 Train_Loss: 0.2375 Train_Acc: 85.727 Val_Loss: 0.0844  BEST VAL Loss: 0.0844  Val_Acc: 98.168

Epoch 86: Validation loss decreased (0.084403 --> 0.084147).  Saving model ...
	 Train_Loss: 0.2372 Train_Acc: 85.869 Val_Loss: 0.0841  BEST VAL Loss: 0.0841  Val_Acc: 97.993

Epoch 87: Validation loss decreased (0.084147 --> 0.084043).  Saving model ...
	 Train_Loss: 0.2370 Train_Acc: 85.869 Val_Loss: 0.0840  BEST VAL Loss: 0.0840  Val_Acc: 98.211

Epoch 88: Validation loss decreased (0.084043 --> 0.083991).  Saving model ...
	 Train_Loss: 0.2367 Train_Acc: 86.060 Val_Loss: 0.0840  BEST VAL Loss: 0.0840  Val_Acc: 98.168

Epoch 89: Validation loss decreased (0.083991 --> 0.083865).  Saving model ...
	 Train_Loss: 0.2364 Train_Acc: 86.125 Val_Loss: 0.0839  BEST VAL Loss: 0.0839  Val_Acc: 98.124

Epoch 90: Validation loss decreased (0.083865 --> 0.083648).  Saving model ...
	 Train_Loss: 0.2361 Train_Acc: 86.365 Val_Loss: 0.0836  BEST VAL Loss: 0.0836  Val_Acc: 97.862

Epoch 91: Validation loss decreased (0.083648 --> 0.083450).  Saving model ...
	 Train_Loss: 0.2359 Train_Acc: 85.885 Val_Loss: 0.0834  BEST VAL Loss: 0.0834  Val_Acc: 97.600

Epoch 92: Validation loss decreased (0.083450 --> 0.083321).  Saving model ...
	 Train_Loss: 0.2357 Train_Acc: 85.683 Val_Loss: 0.0833  BEST VAL Loss: 0.0833  Val_Acc: 98.255

Epoch 93: Validation loss decreased (0.083321 --> 0.083115).  Saving model ...
	 Train_Loss: 0.2355 Train_Acc: 85.923 Val_Loss: 0.0831  BEST VAL Loss: 0.0831  Val_Acc: 98.473

Epoch 94: Validation loss decreased (0.083115 --> 0.082920).  Saving model ...
	 Train_Loss: 0.2352 Train_Acc: 86.010 Val_Loss: 0.0829  BEST VAL Loss: 0.0829  Val_Acc: 98.691

Epoch 95: Validation loss decreased (0.082920 --> 0.082680).  Saving model ...
	 Train_Loss: 0.2350 Train_Acc: 86.120 Val_Loss: 0.0827  BEST VAL Loss: 0.0827  Val_Acc: 98.517

Epoch 96: Validation loss decreased (0.082680 --> 0.082448).  Saving model ...
	 Train_Loss: 0.2347 Train_Acc: 85.983 Val_Loss: 0.0824  BEST VAL Loss: 0.0824  Val_Acc: 98.124

Epoch 97: Validation loss decreased (0.082448 --> 0.082253).  Saving model ...
	 Train_Loss: 0.2345 Train_Acc: 86.005 Val_Loss: 0.0823  BEST VAL Loss: 0.0823  Val_Acc: 98.342

Epoch 98: Validation loss decreased (0.082253 --> 0.082056).  Saving model ...
	 Train_Loss: 0.2344 Train_Acc: 85.989 Val_Loss: 0.0821  BEST VAL Loss: 0.0821  Val_Acc: 98.298

Epoch 99: Validation loss decreased (0.082056 --> 0.082019).  Saving model ...
	 Train_Loss: 0.2341 Train_Acc: 86.032 Val_Loss: 0.0820  BEST VAL Loss: 0.0820  Val_Acc: 98.298

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      1.00      1.00      9892
           1       1.00      0.99      0.99      8436

    accuracy                           1.00     18328
   macro avg       1.00      1.00      1.00     18328
weighted avg       1.00      1.00      1.00     18328

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.98      0.98      1237
           1       0.98      0.98      0.98      1055

    accuracy                           0.98      2292
   macro avg       0.98      0.98      0.98      2292
weighted avg       0.98      0.98      0.98      2292

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      0.98      0.99      1236
           1       0.98      0.99      0.98      1055

    accuracy                           0.99      2291
   macro avg       0.99      0.99      0.99      2291
weighted avg       0.99      0.99      0.99      2291

              precision    recall  f1-score   support

           0       0.99      0.98      0.99      1236
           1       0.98      0.99      0.98      1055

    accuracy                           0.99      2291
   macro avg       0.99      0.99      0.99      2291
weighted avg       0.99      0.99      0.99      2291

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.95      0.96      3622
           1       0.95      0.97      0.96      3856

    accuracy                           0.96      7478
   macro avg       0.96      0.96      0.96      7478
weighted avg       0.96      0.96      0.96      7478

              precision    recall  f1-score   support

           0       0.97      0.95      0.96      3622
           1       0.95      0.97      0.96      3856

    accuracy                           0.96      7478
   macro avg       0.96      0.96      0.96      7478
weighted avg       0.96      0.96      0.96      7478

Traceback (most recent call last):
  File "/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_binary_model.py", line 783, in <module>
    metrics_df = pd.read_csv(metrics_file)
  File "/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 1679, in _make_engine
    return mapping[engine](f, **self.options)
  File "/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 93, in __init__
    self._reader = parsers.TextReader(src, **kwds)
  File "pandas/_libs/parsers.pyx", line 557, in pandas._libs.parsers.TextReader.__cinit__
pandas.errors.EmptyDataError: No columns to parse from file
completed
