[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b77e90ae'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'b9d94ed5'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '4e08a627'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '463a2aa3'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: H2O2_100.000_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (44410, 1276)
Number of total missing values across all columns: 88820
Data Subset Is Off
Wells held out for testing: ['C21' 'H22']
Wells to use for training, validation, and testing ['C16' 'C17' 'H18' 'H19' 'C20' 'H23' 'I18' 'I19' 'I22' 'I23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.668307).  Saving model ...
	 Train_Loss: 0.6827 Train_Acc: 58.236 Val_Loss: 0.6683  BEST VAL Loss: 0.6683  Val_Acc: 63.606

Epoch 1: Validation loss decreased (0.668307 --> 0.661951).  Saving model ...
	 Train_Loss: 0.6721 Train_Acc: 63.601 Val_Loss: 0.6620  BEST VAL Loss: 0.6620  Val_Acc: 63.606

Epoch 2: Validation loss decreased (0.661951 --> 0.655658).  Saving model ...
	 Train_Loss: 0.6647 Train_Acc: 63.601 Val_Loss: 0.6557  BEST VAL Loss: 0.6557  Val_Acc: 63.606

Epoch 3: Validation loss decreased (0.655658 --> 0.650537).  Saving model ...
	 Train_Loss: 0.6586 Train_Acc: 63.598 Val_Loss: 0.6505  BEST VAL Loss: 0.6505  Val_Acc: 63.606

Epoch 4: Validation loss decreased (0.650537 --> 0.646157).  Saving model ...
	 Train_Loss: 0.6539 Train_Acc: 63.601 Val_Loss: 0.6462  BEST VAL Loss: 0.6462  Val_Acc: 63.606

Epoch 5: Validation loss decreased (0.646157 --> 0.641896).  Saving model ...
	 Train_Loss: 0.6498 Train_Acc: 63.601 Val_Loss: 0.6419  BEST VAL Loss: 0.6419  Val_Acc: 63.606

Epoch 6: Validation loss decreased (0.641896 --> 0.637523).  Saving model ...
	 Train_Loss: 0.6456 Train_Acc: 63.601 Val_Loss: 0.6375  BEST VAL Loss: 0.6375  Val_Acc: 63.606

Epoch 7: Validation loss decreased (0.637523 --> 0.633019).  Saving model ...
	 Train_Loss: 0.6414 Train_Acc: 63.601 Val_Loss: 0.6330  BEST VAL Loss: 0.6330  Val_Acc: 63.606

Epoch 8: Validation loss decreased (0.633019 --> 0.628297).  Saving model ...
	 Train_Loss: 0.6371 Train_Acc: 63.601 Val_Loss: 0.6283  BEST VAL Loss: 0.6283  Val_Acc: 63.606

Epoch 9: Validation loss decreased (0.628297 --> 0.623226).  Saving model ...
	 Train_Loss: 0.6325 Train_Acc: 63.601 Val_Loss: 0.6232  BEST VAL Loss: 0.6232  Val_Acc: 63.606

Epoch 10: Validation loss decreased (0.623226 --> 0.617960).  Saving model ...
	 Train_Loss: 0.6277 Train_Acc: 63.601 Val_Loss: 0.6180  BEST VAL Loss: 0.6180  Val_Acc: 63.606

Epoch 11: Validation loss decreased (0.617960 --> 0.612496).  Saving model ...
	 Train_Loss: 0.6229 Train_Acc: 63.601 Val_Loss: 0.6125  BEST VAL Loss: 0.6125  Val_Acc: 63.606

Epoch 12: Validation loss decreased (0.612496 --> 0.606955).  Saving model ...
	 Train_Loss: 0.6179 Train_Acc: 63.640 Val_Loss: 0.6070  BEST VAL Loss: 0.6070  Val_Acc: 63.606

Epoch 13: Validation loss decreased (0.606955 --> 0.601374).  Saving model ...
	 Train_Loss: 0.6129 Train_Acc: 65.428 Val_Loss: 0.6014  BEST VAL Loss: 0.6014  Val_Acc: 70.325

Epoch 14: Validation loss decreased (0.601374 --> 0.595838).  Saving model ...
	 Train_Loss: 0.6079 Train_Acc: 70.495 Val_Loss: 0.5958  BEST VAL Loss: 0.5958  Val_Acc: 73.684

Epoch 15: Validation loss decreased (0.595838 --> 0.590419).  Saving model ...
	 Train_Loss: 0.6031 Train_Acc: 72.448 Val_Loss: 0.5904  BEST VAL Loss: 0.5904  Val_Acc: 74.860

Epoch 16: Validation loss decreased (0.590419 --> 0.585191).  Saving model ...
	 Train_Loss: 0.5983 Train_Acc: 74.149 Val_Loss: 0.5852  BEST VAL Loss: 0.5852  Val_Acc: 75.868

Epoch 17: Validation loss decreased (0.585191 --> 0.580171).  Saving model ...
	 Train_Loss: 0.5936 Train_Acc: 74.912 Val_Loss: 0.5802  BEST VAL Loss: 0.5802  Val_Acc: 76.400

Epoch 18: Validation loss decreased (0.580171 --> 0.575287).  Saving model ...
	 Train_Loss: 0.5891 Train_Acc: 75.304 Val_Loss: 0.5753  BEST VAL Loss: 0.5753  Val_Acc: 77.016

Epoch 19: Validation loss decreased (0.575287 --> 0.570596).  Saving model ...
	 Train_Loss: 0.5847 Train_Acc: 75.643 Val_Loss: 0.5706  BEST VAL Loss: 0.5706  Val_Acc: 77.240

Epoch 20: Validation loss decreased (0.570596 --> 0.566110).  Saving model ...
	 Train_Loss: 0.5805 Train_Acc: 76.084 Val_Loss: 0.5661  BEST VAL Loss: 0.5661  Val_Acc: 77.576

Epoch 21: Validation loss decreased (0.566110 --> 0.561886).  Saving model ...
	 Train_Loss: 0.5765 Train_Acc: 76.448 Val_Loss: 0.5619  BEST VAL Loss: 0.5619  Val_Acc: 77.548

Epoch 22: Validation loss decreased (0.561886 --> 0.557897).  Saving model ...
	 Train_Loss: 0.5725 Train_Acc: 76.864 Val_Loss: 0.5579  BEST VAL Loss: 0.5579  Val_Acc: 78.135

Epoch 23: Validation loss decreased (0.557897 --> 0.554020).  Saving model ...
	 Train_Loss: 0.5689 Train_Acc: 76.700 Val_Loss: 0.5540  BEST VAL Loss: 0.5540  Val_Acc: 78.527

Epoch 24: Validation loss decreased (0.554020 --> 0.550417).  Saving model ...
	 Train_Loss: 0.5652 Train_Acc: 76.906 Val_Loss: 0.5504  BEST VAL Loss: 0.5504  Val_Acc: 78.583

Epoch 25: Validation loss decreased (0.550417 --> 0.546932).  Saving model ...
	 Train_Loss: 0.5618 Train_Acc: 77.487 Val_Loss: 0.5469  BEST VAL Loss: 0.5469  Val_Acc: 78.919

Epoch 26: Validation loss decreased (0.546932 --> 0.543628).  Saving model ...
	 Train_Loss: 0.5585 Train_Acc: 77.204 Val_Loss: 0.5436  BEST VAL Loss: 0.5436  Val_Acc: 78.975

Epoch 27: Validation loss decreased (0.543628 --> 0.540477).  Saving model ...
	 Train_Loss: 0.5552 Train_Acc: 77.932 Val_Loss: 0.5405  BEST VAL Loss: 0.5405  Val_Acc: 79.059

Epoch 28: Validation loss decreased (0.540477 --> 0.537542).  Saving model ...
	 Train_Loss: 0.5521 Train_Acc: 77.949 Val_Loss: 0.5375  BEST VAL Loss: 0.5375  Val_Acc: 78.919

Epoch 29: Validation loss decreased (0.537542 --> 0.534763).  Saving model ...
	 Train_Loss: 0.5490 Train_Acc: 78.131 Val_Loss: 0.5348  BEST VAL Loss: 0.5348  Val_Acc: 79.031

Epoch 30: Validation loss decreased (0.534763 --> 0.532090).  Saving model ...
	 Train_Loss: 0.5461 Train_Acc: 78.604 Val_Loss: 0.5321  BEST VAL Loss: 0.5321  Val_Acc: 79.031

Epoch 31: Validation loss decreased (0.532090 --> 0.529570).  Saving model ...
	 Train_Loss: 0.5433 Train_Acc: 78.467 Val_Loss: 0.5296  BEST VAL Loss: 0.5296  Val_Acc: 79.199

Epoch 32: Validation loss decreased (0.529570 --> 0.527192).  Saving model ...
	 Train_Loss: 0.5406 Train_Acc: 78.527 Val_Loss: 0.5272  BEST VAL Loss: 0.5272  Val_Acc: 79.311

Epoch 33: Validation loss decreased (0.527192 --> 0.525044).  Saving model ...
	 Train_Loss: 0.5379 Train_Acc: 78.842 Val_Loss: 0.5250  BEST VAL Loss: 0.5250  Val_Acc: 78.947

Epoch 34: Validation loss decreased (0.525044 --> 0.523281).  Saving model ...
	 Train_Loss: 0.5354 Train_Acc: 78.712 Val_Loss: 0.5233  BEST VAL Loss: 0.5233  Val_Acc: 78.275

Epoch 35: Validation loss decreased (0.523281 --> 0.521231).  Saving model ...
	 Train_Loss: 0.5328 Train_Acc: 79.122 Val_Loss: 0.5212  BEST VAL Loss: 0.5212  Val_Acc: 79.087

Epoch 36: Validation loss decreased (0.521231 --> 0.519366).  Saving model ...
	 Train_Loss: 0.5304 Train_Acc: 79.633 Val_Loss: 0.5194  BEST VAL Loss: 0.5194  Val_Acc: 79.059

Epoch 37: Validation loss decreased (0.519366 --> 0.517563).  Saving model ...
	 Train_Loss: 0.5279 Train_Acc: 79.405 Val_Loss: 0.5176  BEST VAL Loss: 0.5176  Val_Acc: 78.891

Epoch 38: Validation loss decreased (0.517563 --> 0.515870).  Saving model ...
	 Train_Loss: 0.5256 Train_Acc: 79.412 Val_Loss: 0.5159  BEST VAL Loss: 0.5159  Val_Acc: 79.115

Epoch 39: Validation loss decreased (0.515870 --> 0.514374).  Saving model ...
	 Train_Loss: 0.5234 Train_Acc: 79.605 Val_Loss: 0.5144  BEST VAL Loss: 0.5144  Val_Acc: 79.171

Epoch 40: Validation loss decreased (0.514374 --> 0.512703).  Saving model ...
	 Train_Loss: 0.5212 Train_Acc: 79.619 Val_Loss: 0.5127  BEST VAL Loss: 0.5127  Val_Acc: 79.255

Epoch 41: Validation loss decreased (0.512703 --> 0.511120).  Saving model ...
	 Train_Loss: 0.5192 Train_Acc: 79.794 Val_Loss: 0.5111  BEST VAL Loss: 0.5111  Val_Acc: 79.395

Epoch 42: Validation loss decreased (0.511120 --> 0.509610).  Saving model ...
	 Train_Loss: 0.5171 Train_Acc: 80.028 Val_Loss: 0.5096  BEST VAL Loss: 0.5096  Val_Acc: 78.807

Epoch 43: Validation loss decreased (0.509610 --> 0.508135).  Saving model ...
	 Train_Loss: 0.5152 Train_Acc: 79.864 Val_Loss: 0.5081  BEST VAL Loss: 0.5081  Val_Acc: 79.227

Epoch 44: Validation loss decreased (0.508135 --> 0.506739).  Saving model ...
	 Train_Loss: 0.5131 Train_Acc: 80.546 Val_Loss: 0.5067  BEST VAL Loss: 0.5067  Val_Acc: 79.311

Epoch 45: Validation loss decreased (0.506739 --> 0.505401).  Saving model ...
	 Train_Loss: 0.5110 Train_Acc: 80.885 Val_Loss: 0.5054  BEST VAL Loss: 0.5054  Val_Acc: 79.255

Epoch 46: Validation loss decreased (0.505401 --> 0.504046).  Saving model ...
	 Train_Loss: 0.5089 Train_Acc: 80.910 Val_Loss: 0.5040  BEST VAL Loss: 0.5040  Val_Acc: 79.535

Epoch 47: Validation loss decreased (0.504046 --> 0.503410).  Saving model ...
	 Train_Loss: 0.5071 Train_Acc: 80.423 Val_Loss: 0.5034  BEST VAL Loss: 0.5034  Val_Acc: 77.212

Epoch 48: Validation loss decreased (0.503410 --> 0.502306).  Saving model ...
	 Train_Loss: 0.5054 Train_Acc: 80.423 Val_Loss: 0.5023  BEST VAL Loss: 0.5023  Val_Acc: 78.835

Epoch 49: Validation loss decreased (0.502306 --> 0.501155).  Saving model ...
	 Train_Loss: 0.5035 Train_Acc: 80.980 Val_Loss: 0.5012  BEST VAL Loss: 0.5012  Val_Acc: 79.199

Epoch 50: Validation loss decreased (0.501155 --> 0.500156).  Saving model ...
	 Train_Loss: 0.5017 Train_Acc: 81.088 Val_Loss: 0.5002  BEST VAL Loss: 0.5002  Val_Acc: 79.003

Epoch 51: Validation loss decreased (0.500156 --> 0.499966).  Saving model ...
	 Train_Loss: 0.4999 Train_Acc: 81.172 Val_Loss: 0.5000  BEST VAL Loss: 0.5000  Val_Acc: 76.344

Epoch 52: Validation loss decreased (0.499966 --> 0.499196).  Saving model ...
	 Train_Loss: 0.4983 Train_Acc: 81.008 Val_Loss: 0.4992  BEST VAL Loss: 0.4992  Val_Acc: 79.199

Epoch 53: Validation loss decreased (0.499196 --> 0.498353).  Saving model ...
	 Train_Loss: 0.4965 Train_Acc: 81.718 Val_Loss: 0.4984  BEST VAL Loss: 0.4984  Val_Acc: 78.695

Epoch 54: Validation loss decreased (0.498353 --> 0.497397).  Saving model ...
	 Train_Loss: 0.4949 Train_Acc: 81.130 Val_Loss: 0.4974  BEST VAL Loss: 0.4974  Val_Acc: 79.535

Epoch 55: Validation loss decreased (0.497397 --> 0.496617).  Saving model ...
	 Train_Loss: 0.4932 Train_Acc: 81.988 Val_Loss: 0.4966  BEST VAL Loss: 0.4966  Val_Acc: 79.423

Epoch 56: Validation loss decreased (0.496617 --> 0.495759).  Saving model ...
	 Train_Loss: 0.4916 Train_Acc: 81.956 Val_Loss: 0.4958  BEST VAL Loss: 0.4958  Val_Acc: 79.087

Epoch 57: Validation loss decreased (0.495759 --> 0.495333).  Saving model ...
	 Train_Loss: 0.4899 Train_Acc: 82.026 Val_Loss: 0.4953  BEST VAL Loss: 0.4953  Val_Acc: 77.912

Epoch 58: Validation loss decreased (0.495333 --> 0.494641).  Saving model ...
	 Train_Loss: 0.4883 Train_Acc: 82.264 Val_Loss: 0.4946  BEST VAL Loss: 0.4946  Val_Acc: 78.751

Epoch 59: Validation loss decreased (0.494641 --> 0.494533).  Saving model ...
	 Train_Loss: 0.4867 Train_Acc: 82.117 Val_Loss: 0.4945  BEST VAL Loss: 0.4945  Val_Acc: 76.960

Epoch 60: Validation loss decreased (0.494533 --> 0.493913).  Saving model ...
	 Train_Loss: 0.4852 Train_Acc: 82.163 Val_Loss: 0.4939  BEST VAL Loss: 0.4939  Val_Acc: 78.611

Epoch 61: Validation loss decreased (0.493913 --> 0.493326).  Saving model ...
	 Train_Loss: 0.4836 Train_Acc: 82.306 Val_Loss: 0.4933  BEST VAL Loss: 0.4933  Val_Acc: 78.835

Epoch 62: Validation loss decreased (0.493326 --> 0.492725).  Saving model ...
	 Train_Loss: 0.4821 Train_Acc: 82.527 Val_Loss: 0.4927  BEST VAL Loss: 0.4927  Val_Acc: 78.807

Epoch 63: Validation loss decreased (0.492725 --> 0.492212).  Saving model ...
	 Train_Loss: 0.4806 Train_Acc: 82.523 Val_Loss: 0.4922  BEST VAL Loss: 0.4922  Val_Acc: 79.143

Epoch 64: Validation loss decreased (0.492212 --> 0.491720).  Saving model ...
	 Train_Loss: 0.4791 Train_Acc: 82.590 Val_Loss: 0.4917  BEST VAL Loss: 0.4917  Val_Acc: 78.667

Epoch 65: Validation loss decreased (0.491720 --> 0.491529).  Saving model ...
	 Train_Loss: 0.4777 Train_Acc: 82.828 Val_Loss: 0.4915  BEST VAL Loss: 0.4915  Val_Acc: 78.219

Epoch 66: Validation loss decreased (0.491529 --> 0.490992).  Saving model ...
	 Train_Loss: 0.4763 Train_Acc: 82.789 Val_Loss: 0.4910  BEST VAL Loss: 0.4910  Val_Acc: 79.003

Epoch 67: Validation loss decreased (0.490992 --> 0.490429).  Saving model ...
	 Train_Loss: 0.4748 Train_Acc: 83.412 Val_Loss: 0.4904  BEST VAL Loss: 0.4904  Val_Acc: 78.835

Epoch 68: Validation loss decreased (0.490429 --> 0.489963).  Saving model ...
	 Train_Loss: 0.4733 Train_Acc: 83.552 Val_Loss: 0.4900  BEST VAL Loss: 0.4900  Val_Acc: 79.031

Epoch 69: Validation loss decreased (0.489963 --> 0.489529).  Saving model ...
	 Train_Loss: 0.4719 Train_Acc: 83.230 Val_Loss: 0.4895  BEST VAL Loss: 0.4895  Val_Acc: 78.555

Epoch 70: Validation loss decreased (0.489529 --> 0.489194).  Saving model ...
	 Train_Loss: 0.4705 Train_Acc: 83.552 Val_Loss: 0.4892  BEST VAL Loss: 0.4892  Val_Acc: 78.891

Epoch 71: Validation loss decreased (0.489194 --> 0.488842).  Saving model ...
	 Train_Loss: 0.4691 Train_Acc: 83.615 Val_Loss: 0.4888  BEST VAL Loss: 0.4888  Val_Acc: 79.059

Epoch 72: Validation loss decreased (0.488842 --> 0.488500).  Saving model ...
	 Train_Loss: 0.4678 Train_Acc: 83.514 Val_Loss: 0.4885  BEST VAL Loss: 0.4885  Val_Acc: 79.171

Epoch 73: Validation loss decreased (0.488500 --> 0.488306).  Saving model ...
	 Train_Loss: 0.4665 Train_Acc: 83.346 Val_Loss: 0.4883  BEST VAL Loss: 0.4883  Val_Acc: 78.611

Epoch 74: Validation loss decreased (0.488306 --> 0.488017).  Saving model ...
	 Train_Loss: 0.4651 Train_Acc: 83.888 Val_Loss: 0.4880  BEST VAL Loss: 0.4880  Val_Acc: 79.731

Epoch 75: Validation loss decreased (0.488017 --> 0.487819).  Saving model ...
	 Train_Loss: 0.4638 Train_Acc: 84.168 Val_Loss: 0.4878  BEST VAL Loss: 0.4878  Val_Acc: 78.723

Epoch 76: Validation loss decreased (0.487819 --> 0.487706).  Saving model ...
	 Train_Loss: 0.4625 Train_Acc: 84.122 Val_Loss: 0.4877  BEST VAL Loss: 0.4877  Val_Acc: 78.555

Epoch 77: Validation loss decreased (0.487706 --> 0.487463).  Saving model ...
	 Train_Loss: 0.4611 Train_Acc: 84.105 Val_Loss: 0.4875  BEST VAL Loss: 0.4875  Val_Acc: 78.975

Epoch 78: Validation loss decreased (0.487463 --> 0.487292).  Saving model ...
	 Train_Loss: 0.4598 Train_Acc: 84.539 Val_Loss: 0.4873  BEST VAL Loss: 0.4873  Val_Acc: 79.115

Epoch 79: Validation loss decreased (0.487292 --> 0.487113).  Saving model ...
	 Train_Loss: 0.4585 Train_Acc: 84.483 Val_Loss: 0.4871  BEST VAL Loss: 0.4871  Val_Acc: 79.143

Epoch 80: Validation loss decreased (0.487113 --> 0.487038).  Saving model ...
	 Train_Loss: 0.4573 Train_Acc: 84.203 Val_Loss: 0.4870  BEST VAL Loss: 0.4870  Val_Acc: 78.443

Epoch 81: Validation loss decreased (0.487038 --> 0.486839).  Saving model ...
	 Train_Loss: 0.4560 Train_Acc: 84.808 Val_Loss: 0.4868  BEST VAL Loss: 0.4868  Val_Acc: 78.583

Epoch 82: Validation loss decreased (0.486839 --> 0.486798).  Saving model ...
	 Train_Loss: 0.4548 Train_Acc: 84.339 Val_Loss: 0.4868  BEST VAL Loss: 0.4868  Val_Acc: 78.583

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.4537 Train_Acc: 84.455 Val_Loss: 0.4869  BEST VAL Loss: 0.4868  Val_Acc: 78.191

Epoch 84: Validation loss decreased (0.486798 --> 0.486742).  Saving model ...
	 Train_Loss: 0.4524 Train_Acc: 84.903 Val_Loss: 0.4867  BEST VAL Loss: 0.4867  Val_Acc: 79.031

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.4511 Train_Acc: 85.491 Val_Loss: 0.4868  BEST VAL Loss: 0.4867  Val_Acc: 78.751

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.4498 Train_Acc: 85.218 Val_Loss: 0.4871  BEST VAL Loss: 0.4867  Val_Acc: 78.135

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.4488 Train_Acc: 84.626 Val_Loss: 0.4871  BEST VAL Loss: 0.4867  Val_Acc: 78.359

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.4476 Train_Acc: 85.074 Val_Loss: 0.4882  BEST VAL Loss: 0.4867  Val_Acc: 75.812

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.4465 Train_Acc: 85.060 Val_Loss: 0.4882  BEST VAL Loss: 0.4867  Val_Acc: 78.723

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.4454 Train_Acc: 85.176 Val_Loss: 0.4882  BEST VAL Loss: 0.4867  Val_Acc: 79.115

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.4442 Train_Acc: 85.508 Val_Loss: 0.4882  BEST VAL Loss: 0.4867  Val_Acc: 79.087

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.4430 Train_Acc: 85.851 Val_Loss: 0.4884  BEST VAL Loss: 0.4867  Val_Acc: 78.499

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.4418 Train_Acc: 85.907 Val_Loss: 0.4885  BEST VAL Loss: 0.4867  Val_Acc: 78.695

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.4407 Train_Acc: 85.848 Val_Loss: 0.4885  BEST VAL Loss: 0.4867  Val_Acc: 79.255

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.4397 Train_Acc: 85.480 Val_Loss: 0.4886  BEST VAL Loss: 0.4867  Val_Acc: 78.555

Epoch 96: Validation loss did not decrease
	 Train_Loss: 0.4387 Train_Acc: 85.421 Val_Loss: 0.4887  BEST VAL Loss: 0.4867  Val_Acc: 78.639

Epoch 97: Validation loss did not decrease
	 Train_Loss: 0.4375 Train_Acc: 86.509 Val_Loss: 0.4888  BEST VAL Loss: 0.4867  Val_Acc: 78.807

Epoch 98: Validation loss did not decrease
	 Train_Loss: 0.4364 Train_Acc: 85.897 Val_Loss: 0.4890  BEST VAL Loss: 0.4867  Val_Acc: 78.024

Epoch 99: Validation loss did not decrease
	 Train_Loss: 0.4353 Train_Acc: 86.124 Val_Loss: 0.4893  BEST VAL Loss: 0.4867  Val_Acc: 78.471

H2O2_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.90      0.92     18174
           1       0.84      0.89      0.86     10401

    accuracy                           0.90     28575
   macro avg       0.89      0.90      0.89     28575
weighted avg       0.90      0.90      0.90     28575

H2O2_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.84      0.83      0.83      2272
           1       0.71      0.72      0.71      1300

    accuracy                           0.79      3572
   macro avg       0.77      0.77      0.77      3572
weighted avg       0.79      0.79      0.79      3572

H2O2_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.84      0.82      0.83      2272
           1       0.70      0.73      0.72      1300

    accuracy                           0.79      3572
   macro avg       0.77      0.78      0.77      3572
weighted avg       0.79      0.79      0.79      3572

              precision    recall  f1-score   support

           0       0.84      0.82      0.83      2272
           1       0.70      0.73      0.72      1300

    accuracy                           0.79      3572
   macro avg       0.77      0.78      0.77      3572
weighted avg       0.79      0.79      0.79      3572

H2O2_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.69      0.82      0.75      4182
           1       0.80      0.66      0.72      4509

    accuracy                           0.73      8691
   macro avg       0.74      0.74      0.73      8691
weighted avg       0.74      0.73      0.73      8691

              precision    recall  f1-score   support

           0       0.69      0.82      0.75      4182
           1       0.80      0.66      0.72      4509

    accuracy                           0.73      8691
   macro avg       0.74      0.74      0.73      8691
weighted avg       0.74      0.73      0.73      8691

completed
