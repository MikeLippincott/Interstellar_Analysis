[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '9551c565'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'b7f66033'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'a0410f99'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'd62c3fdf'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_100.000_DMSO_0.025 treatment_name: LPS_10.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_100.000_DMSO_0.025
TREATMENT_NAME: LPS_10.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (315925, 1270)
Number of total missing values across all columns: 631850
Data Subset Is Off
Wells held out for testing: ['E09' 'J08']
Wells to use for training, validation, and testing ['E02' 'E03' 'E08' 'J02' 'J03' 'J09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.580135).  Saving model ...
	 Train_Loss: 0.6441 Train_Acc: 62.313 Val_Loss: 0.5801  BEST VAL Loss: 0.5801  Val_Acc: 68.485

Epoch 1: Validation loss decreased (0.580135 --> 0.575278).  Saving model ...
	 Train_Loss: 0.6210 Train_Acc: 67.072 Val_Loss: 0.5753  BEST VAL Loss: 0.5753  Val_Acc: 69.947

Epoch 2: Validation loss decreased (0.575278 --> 0.566080).  Saving model ...
	 Train_Loss: 0.6068 Train_Acc: 68.679 Val_Loss: 0.5661  BEST VAL Loss: 0.5661  Val_Acc: 70.983

Epoch 3: Validation loss decreased (0.566080 --> 0.561402).  Saving model ...
	 Train_Loss: 0.5969 Train_Acc: 69.388 Val_Loss: 0.5614  BEST VAL Loss: 0.5614  Val_Acc: 70.932

Epoch 4: Validation loss decreased (0.561402 --> 0.559151).  Saving model ...
	 Train_Loss: 0.5895 Train_Acc: 69.995 Val_Loss: 0.5592  BEST VAL Loss: 0.5592  Val_Acc: 71.471

Epoch 5: Validation loss decreased (0.559151 --> 0.553790).  Saving model ...
	 Train_Loss: 0.5837 Train_Acc: 70.196 Val_Loss: 0.5538  BEST VAL Loss: 0.5538  Val_Acc: 72.634

Epoch 6: Validation loss decreased (0.553790 --> 0.550344).  Saving model ...
	 Train_Loss: 0.5786 Train_Acc: 70.677 Val_Loss: 0.5503  BEST VAL Loss: 0.5503  Val_Acc: 72.436

Epoch 7: Validation loss decreased (0.550344 --> 0.545848).  Saving model ...
	 Train_Loss: 0.5741 Train_Acc: 71.198 Val_Loss: 0.5458  BEST VAL Loss: 0.5458  Val_Acc: 73.358

Epoch 8: Validation loss decreased (0.545848 --> 0.543081).  Saving model ...
	 Train_Loss: 0.5704 Train_Acc: 71.292 Val_Loss: 0.5431  BEST VAL Loss: 0.5431  Val_Acc: 73.106

Epoch 9: Validation loss decreased (0.543081 --> 0.540086).  Saving model ...
	 Train_Loss: 0.5670 Train_Acc: 71.470 Val_Loss: 0.5401  BEST VAL Loss: 0.5401  Val_Acc: 73.430

Epoch 10: Validation loss decreased (0.540086 --> 0.537256).  Saving model ...
	 Train_Loss: 0.5639 Train_Acc: 71.635 Val_Loss: 0.5373  BEST VAL Loss: 0.5373  Val_Acc: 73.978

Epoch 11: Validation loss decreased (0.537256 --> 0.534237).  Saving model ...
	 Train_Loss: 0.5608 Train_Acc: 72.110 Val_Loss: 0.5342  BEST VAL Loss: 0.5342  Val_Acc: 74.656

Epoch 12: Validation loss decreased (0.534237 --> 0.532139).  Saving model ...
	 Train_Loss: 0.5582 Train_Acc: 72.029 Val_Loss: 0.5321  BEST VAL Loss: 0.5321  Val_Acc: 74.483

Epoch 13: Validation loss decreased (0.532139 --> 0.529748).  Saving model ...
	 Train_Loss: 0.5556 Train_Acc: 72.482 Val_Loss: 0.5297  BEST VAL Loss: 0.5297  Val_Acc: 74.782

Epoch 14: Validation loss decreased (0.529748 --> 0.527611).  Saving model ...
	 Train_Loss: 0.5531 Train_Acc: 72.475 Val_Loss: 0.5276  BEST VAL Loss: 0.5276  Val_Acc: 75.123

Epoch 15: Validation loss decreased (0.527611 --> 0.525500).  Saving model ...
	 Train_Loss: 0.5507 Train_Acc: 72.535 Val_Loss: 0.5255  BEST VAL Loss: 0.5255  Val_Acc: 74.500

Epoch 16: Validation loss decreased (0.525500 --> 0.524467).  Saving model ...
	 Train_Loss: 0.5486 Train_Acc: 72.351 Val_Loss: 0.5245  BEST VAL Loss: 0.5245  Val_Acc: 73.603

Epoch 17: Validation loss decreased (0.524467 --> 0.523054).  Saving model ...
	 Train_Loss: 0.5466 Train_Acc: 72.569 Val_Loss: 0.5231  BEST VAL Loss: 0.5231  Val_Acc: 74.428

Epoch 18: Validation loss decreased (0.523054 --> 0.521708).  Saving model ...
	 Train_Loss: 0.5447 Train_Acc: 72.566 Val_Loss: 0.5217  BEST VAL Loss: 0.5217  Val_Acc: 74.138

Epoch 19: Validation loss decreased (0.521708 --> 0.520506).  Saving model ...
	 Train_Loss: 0.5430 Train_Acc: 72.413 Val_Loss: 0.5205  BEST VAL Loss: 0.5205  Val_Acc: 75.245

Epoch 20: Validation loss decreased (0.520506 --> 0.519065).  Saving model ...
	 Train_Loss: 0.5414 Train_Acc: 72.423 Val_Loss: 0.5191  BEST VAL Loss: 0.5191  Val_Acc: 75.313

Epoch 21: Validation loss decreased (0.519065 --> 0.517676).  Saving model ...
	 Train_Loss: 0.5399 Train_Acc: 72.628 Val_Loss: 0.5177  BEST VAL Loss: 0.5177  Val_Acc: 75.675

Epoch 22: Validation loss decreased (0.517676 --> 0.516271).  Saving model ...
	 Train_Loss: 0.5385 Train_Acc: 72.512 Val_Loss: 0.5163  BEST VAL Loss: 0.5163  Val_Acc: 75.759

Epoch 23: Validation loss decreased (0.516271 --> 0.515109).  Saving model ...
	 Train_Loss: 0.5372 Train_Acc: 72.757 Val_Loss: 0.5151  BEST VAL Loss: 0.5151  Val_Acc: 75.881

Epoch 24: Validation loss decreased (0.515109 --> 0.513816).  Saving model ...
	 Train_Loss: 0.5358 Train_Acc: 72.711 Val_Loss: 0.5138  BEST VAL Loss: 0.5138  Val_Acc: 76.063

Epoch 25: Validation loss decreased (0.513816 --> 0.512457).  Saving model ...
	 Train_Loss: 0.5346 Train_Acc: 72.784 Val_Loss: 0.5125  BEST VAL Loss: 0.5125  Val_Acc: 76.075

Epoch 26: Validation loss decreased (0.512457 --> 0.511407).  Saving model ...
	 Train_Loss: 0.5335 Train_Acc: 72.773 Val_Loss: 0.5114  BEST VAL Loss: 0.5114  Val_Acc: 76.029

Epoch 27: Validation loss decreased (0.511407 --> 0.510376).  Saving model ...
	 Train_Loss: 0.5323 Train_Acc: 72.873 Val_Loss: 0.5104  BEST VAL Loss: 0.5104  Val_Acc: 75.814

Epoch 28: Validation loss decreased (0.510376 --> 0.509676).  Saving model ...
	 Train_Loss: 0.5312 Train_Acc: 72.857 Val_Loss: 0.5097  BEST VAL Loss: 0.5097  Val_Acc: 75.679

Epoch 29: Validation loss decreased (0.509676 --> 0.508836).  Saving model ...
	 Train_Loss: 0.5303 Train_Acc: 72.810 Val_Loss: 0.5088  BEST VAL Loss: 0.5088  Val_Acc: 75.346

Epoch 30: Validation loss decreased (0.508836 --> 0.507913).  Saving model ...
	 Train_Loss: 0.5293 Train_Acc: 72.998 Val_Loss: 0.5079  BEST VAL Loss: 0.5079  Val_Acc: 76.290

Epoch 31: Validation loss decreased (0.507913 --> 0.507285).  Saving model ...
	 Train_Loss: 0.5283 Train_Acc: 72.817 Val_Loss: 0.5073  BEST VAL Loss: 0.5073  Val_Acc: 75.629

Epoch 32: Validation loss decreased (0.507285 --> 0.506337).  Saving model ...
	 Train_Loss: 0.5275 Train_Acc: 72.736 Val_Loss: 0.5063  BEST VAL Loss: 0.5063  Val_Acc: 76.134

Epoch 33: Validation loss decreased (0.506337 --> 0.505619).  Saving model ...
	 Train_Loss: 0.5265 Train_Acc: 73.119 Val_Loss: 0.5056  BEST VAL Loss: 0.5056  Val_Acc: 76.273

Epoch 34: Validation loss decreased (0.505619 --> 0.505266).  Saving model ...
	 Train_Loss: 0.5257 Train_Acc: 73.062 Val_Loss: 0.5053  BEST VAL Loss: 0.5053  Val_Acc: 75.595

Epoch 35: Validation loss decreased (0.505266 --> 0.504533).  Saving model ...
	 Train_Loss: 0.5249 Train_Acc: 72.884 Val_Loss: 0.5045  BEST VAL Loss: 0.5045  Val_Acc: 75.801

Epoch 36: Validation loss decreased (0.504533 --> 0.504011).  Saving model ...
	 Train_Loss: 0.5241 Train_Acc: 73.155 Val_Loss: 0.5040  BEST VAL Loss: 0.5040  Val_Acc: 75.620

Epoch 37: Validation loss decreased (0.504011 --> 0.503359).  Saving model ...
	 Train_Loss: 0.5233 Train_Acc: 73.258 Val_Loss: 0.5034  BEST VAL Loss: 0.5034  Val_Acc: 76.404

Epoch 38: Validation loss decreased (0.503359 --> 0.502718).  Saving model ...
	 Train_Loss: 0.5226 Train_Acc: 73.083 Val_Loss: 0.5027  BEST VAL Loss: 0.5027  Val_Acc: 76.273

Epoch 39: Validation loss decreased (0.502718 --> 0.502193).  Saving model ...
	 Train_Loss: 0.5219 Train_Acc: 73.227 Val_Loss: 0.5022  BEST VAL Loss: 0.5022  Val_Acc: 76.627

Epoch 40: Validation loss decreased (0.502193 --> 0.501721).  Saving model ...
	 Train_Loss: 0.5212 Train_Acc: 73.109 Val_Loss: 0.5017  BEST VAL Loss: 0.5017  Val_Acc: 75.119

Epoch 41: Validation loss decreased (0.501721 --> 0.501419).  Saving model ...
	 Train_Loss: 0.5206 Train_Acc: 73.128 Val_Loss: 0.5014  BEST VAL Loss: 0.5014  Val_Acc: 75.974

Epoch 42: Validation loss decreased (0.501419 --> 0.501050).  Saving model ...
	 Train_Loss: 0.5200 Train_Acc: 73.264 Val_Loss: 0.5010  BEST VAL Loss: 0.5010  Val_Acc: 76.425

Epoch 43: Validation loss decreased (0.501050 --> 0.500562).  Saving model ...
	 Train_Loss: 0.5194 Train_Acc: 73.285 Val_Loss: 0.5006  BEST VAL Loss: 0.5006  Val_Acc: 76.058

Epoch 44: Validation loss decreased (0.500562 --> 0.500144).  Saving model ...
	 Train_Loss: 0.5189 Train_Acc: 73.125 Val_Loss: 0.5001  BEST VAL Loss: 0.5001  Val_Acc: 76.395

Epoch 45: Validation loss decreased (0.500144 --> 0.499594).  Saving model ...
	 Train_Loss: 0.5182 Train_Acc: 73.231 Val_Loss: 0.4996  BEST VAL Loss: 0.4996  Val_Acc: 76.067

Epoch 46: Validation loss decreased (0.499594 --> 0.499080).  Saving model ...
	 Train_Loss: 0.5177 Train_Acc: 73.111 Val_Loss: 0.4991  BEST VAL Loss: 0.4991  Val_Acc: 75.220

Epoch 47: Validation loss decreased (0.499080 --> 0.498961).  Saving model ...
	 Train_Loss: 0.5172 Train_Acc: 73.362 Val_Loss: 0.4990  BEST VAL Loss: 0.4990  Val_Acc: 75.473

Epoch 48: Validation loss decreased (0.498961 --> 0.498451).  Saving model ...
	 Train_Loss: 0.5167 Train_Acc: 73.173 Val_Loss: 0.4985  BEST VAL Loss: 0.4985  Val_Acc: 76.656

Epoch 49: Validation loss decreased (0.498451 --> 0.497902).  Saving model ...
	 Train_Loss: 0.5162 Train_Acc: 73.252 Val_Loss: 0.4979  BEST VAL Loss: 0.4979  Val_Acc: 76.480

Epoch 50: Validation loss decreased (0.497902 --> 0.497447).  Saving model ...
	 Train_Loss: 0.5157 Train_Acc: 73.279 Val_Loss: 0.4974  BEST VAL Loss: 0.4974  Val_Acc: 75.742

Epoch 51: Validation loss decreased (0.497447 --> 0.497148).  Saving model ...
	 Train_Loss: 0.5152 Train_Acc: 73.310 Val_Loss: 0.4971  BEST VAL Loss: 0.4971  Val_Acc: 76.071

Epoch 52: Validation loss decreased (0.497148 --> 0.496674).  Saving model ...
	 Train_Loss: 0.5147 Train_Acc: 73.347 Val_Loss: 0.4967  BEST VAL Loss: 0.4967  Val_Acc: 76.972

Epoch 53: Validation loss decreased (0.496674 --> 0.496315).  Saving model ...
	 Train_Loss: 0.5142 Train_Acc: 73.306 Val_Loss: 0.4963  BEST VAL Loss: 0.4963  Val_Acc: 75.789

Epoch 54: Validation loss decreased (0.496315 --> 0.496016).  Saving model ...
	 Train_Loss: 0.5138 Train_Acc: 73.242 Val_Loss: 0.4960  BEST VAL Loss: 0.4960  Val_Acc: 76.004

Epoch 55: Validation loss decreased (0.496016 --> 0.495632).  Saving model ...
	 Train_Loss: 0.5133 Train_Acc: 73.405 Val_Loss: 0.4956  BEST VAL Loss: 0.4956  Val_Acc: 76.673

Epoch 56: Validation loss decreased (0.495632 --> 0.495433).  Saving model ...
	 Train_Loss: 0.5129 Train_Acc: 73.372 Val_Loss: 0.4954  BEST VAL Loss: 0.4954  Val_Acc: 76.378

Epoch 57: Validation loss decreased (0.495433 --> 0.494945).  Saving model ...
	 Train_Loss: 0.5125 Train_Acc: 73.429 Val_Loss: 0.4949  BEST VAL Loss: 0.4949  Val_Acc: 76.972

Epoch 58: Validation loss decreased (0.494945 --> 0.494695).  Saving model ...
	 Train_Loss: 0.5121 Train_Acc: 73.607 Val_Loss: 0.4947  BEST VAL Loss: 0.4947  Val_Acc: 76.058

Epoch 59: Validation loss decreased (0.494695 --> 0.494266).  Saving model ...
	 Train_Loss: 0.5117 Train_Acc: 73.363 Val_Loss: 0.4943  BEST VAL Loss: 0.4943  Val_Acc: 76.850

Epoch 60: Validation loss decreased (0.494266 --> 0.493969).  Saving model ...
	 Train_Loss: 0.5113 Train_Acc: 73.472 Val_Loss: 0.4940  BEST VAL Loss: 0.4940  Val_Acc: 76.260

Epoch 61: Validation loss decreased (0.493969 --> 0.493709).  Saving model ...
	 Train_Loss: 0.5110 Train_Acc: 73.359 Val_Loss: 0.4937  BEST VAL Loss: 0.4937  Val_Acc: 75.140

Epoch 62: Validation loss decreased (0.493709 --> 0.493540).  Saving model ...
	 Train_Loss: 0.5106 Train_Acc: 73.406 Val_Loss: 0.4935  BEST VAL Loss: 0.4935  Val_Acc: 75.856

Epoch 63: Validation loss decreased (0.493540 --> 0.493238).  Saving model ...
	 Train_Loss: 0.5102 Train_Acc: 73.505 Val_Loss: 0.4932  BEST VAL Loss: 0.4932  Val_Acc: 76.581

Epoch 64: Validation loss decreased (0.493238 --> 0.492823).  Saving model ...
	 Train_Loss: 0.5099 Train_Acc: 73.443 Val_Loss: 0.4928  BEST VAL Loss: 0.4928  Val_Acc: 76.934

Epoch 65: Validation loss decreased (0.492823 --> 0.492512).  Saving model ...
	 Train_Loss: 0.5095 Train_Acc: 73.697 Val_Loss: 0.4925  BEST VAL Loss: 0.4925  Val_Acc: 76.884

Epoch 66: Validation loss decreased (0.492512 --> 0.492268).  Saving model ...
	 Train_Loss: 0.5092 Train_Acc: 73.485 Val_Loss: 0.4923  BEST VAL Loss: 0.4923  Val_Acc: 76.652

Epoch 67: Validation loss decreased (0.492268 --> 0.491972).  Saving model ...
	 Train_Loss: 0.5089 Train_Acc: 73.475 Val_Loss: 0.4920  BEST VAL Loss: 0.4920  Val_Acc: 75.856

Epoch 68: Validation loss decreased (0.491972 --> 0.491616).  Saving model ...
	 Train_Loss: 0.5086 Train_Acc: 73.317 Val_Loss: 0.4916  BEST VAL Loss: 0.4916  Val_Acc: 76.176

Epoch 69: Validation loss decreased (0.491616 --> 0.491329).  Saving model ...
	 Train_Loss: 0.5083 Train_Acc: 73.519 Val_Loss: 0.4913  BEST VAL Loss: 0.4913  Val_Acc: 76.694

Epoch 70: Validation loss decreased (0.491329 --> 0.491181).  Saving model ...
	 Train_Loss: 0.5080 Train_Acc: 73.502 Val_Loss: 0.4912  BEST VAL Loss: 0.4912  Val_Acc: 75.886

Epoch 71: Validation loss decreased (0.491181 --> 0.491042).  Saving model ...
	 Train_Loss: 0.5077 Train_Acc: 73.496 Val_Loss: 0.4910  BEST VAL Loss: 0.4910  Val_Acc: 75.780

Epoch 72: Validation loss decreased (0.491042 --> 0.490867).  Saving model ...
	 Train_Loss: 0.5074 Train_Acc: 73.428 Val_Loss: 0.4909  BEST VAL Loss: 0.4909  Val_Acc: 76.341

Epoch 73: Validation loss decreased (0.490867 --> 0.490710).  Saving model ...
	 Train_Loss: 0.5071 Train_Acc: 73.590 Val_Loss: 0.4907  BEST VAL Loss: 0.4907  Val_Acc: 76.180

Epoch 74: Validation loss decreased (0.490710 --> 0.490572).  Saving model ...
	 Train_Loss: 0.5068 Train_Acc: 73.432 Val_Loss: 0.4906  BEST VAL Loss: 0.4906  Val_Acc: 76.631

Epoch 75: Validation loss decreased (0.490572 --> 0.490407).  Saving model ...
	 Train_Loss: 0.5065 Train_Acc: 73.624 Val_Loss: 0.4904  BEST VAL Loss: 0.4904  Val_Acc: 76.341

Epoch 76: Validation loss decreased (0.490407 --> 0.490344).  Saving model ...
	 Train_Loss: 0.5063 Train_Acc: 73.554 Val_Loss: 0.4903  BEST VAL Loss: 0.4903  Val_Acc: 76.277

Epoch 77: Validation loss decreased (0.490344 --> 0.490094).  Saving model ...
	 Train_Loss: 0.5060 Train_Acc: 73.469 Val_Loss: 0.4901  BEST VAL Loss: 0.4901  Val_Acc: 76.593

Epoch 78: Validation loss decreased (0.490094 --> 0.489878).  Saving model ...
	 Train_Loss: 0.5058 Train_Acc: 73.482 Val_Loss: 0.4899  BEST VAL Loss: 0.4899  Val_Acc: 76.307

Epoch 79: Validation loss decreased (0.489878 --> 0.489775).  Saving model ...
	 Train_Loss: 0.5055 Train_Acc: 73.685 Val_Loss: 0.4898  BEST VAL Loss: 0.4898  Val_Acc: 76.825

Epoch 80: Validation loss decreased (0.489775 --> 0.489542).  Saving model ...
	 Train_Loss: 0.5052 Train_Acc: 73.679 Val_Loss: 0.4895  BEST VAL Loss: 0.4895  Val_Acc: 76.968

Epoch 81: Validation loss decreased (0.489542 --> 0.489402).  Saving model ...
	 Train_Loss: 0.5050 Train_Acc: 73.649 Val_Loss: 0.4894  BEST VAL Loss: 0.4894  Val_Acc: 76.648

Epoch 82: Validation loss decreased (0.489402 --> 0.489126).  Saving model ...
	 Train_Loss: 0.5047 Train_Acc: 73.574 Val_Loss: 0.4891  BEST VAL Loss: 0.4891  Val_Acc: 76.787

Epoch 83: Validation loss decreased (0.489126 --> 0.488936).  Saving model ...
	 Train_Loss: 0.5045 Train_Acc: 73.668 Val_Loss: 0.4889  BEST VAL Loss: 0.4889  Val_Acc: 76.745

Epoch 84: Validation loss decreased (0.488936 --> 0.488706).  Saving model ...
	 Train_Loss: 0.5043 Train_Acc: 73.505 Val_Loss: 0.4887  BEST VAL Loss: 0.4887  Val_Acc: 77.415

Epoch 85: Validation loss decreased (0.488706 --> 0.488552).  Saving model ...
	 Train_Loss: 0.5040 Train_Acc: 73.604 Val_Loss: 0.4886  BEST VAL Loss: 0.4886  Val_Acc: 76.888

Epoch 86: Validation loss decreased (0.488552 --> 0.488360).  Saving model ...
	 Train_Loss: 0.5038 Train_Acc: 73.567 Val_Loss: 0.4884  BEST VAL Loss: 0.4884  Val_Acc: 76.724

Epoch 87: Validation loss decreased (0.488360 --> 0.488181).  Saving model ...
	 Train_Loss: 0.5036 Train_Acc: 73.581 Val_Loss: 0.4882  BEST VAL Loss: 0.4882  Val_Acc: 76.842

Epoch 88: Validation loss decreased (0.488181 --> 0.488004).  Saving model ...
	 Train_Loss: 0.5034 Train_Acc: 73.418 Val_Loss: 0.4880  BEST VAL Loss: 0.4880  Val_Acc: 75.140

Epoch 89: Validation loss decreased (0.488004 --> 0.487818).  Saving model ...
	 Train_Loss: 0.5032 Train_Acc: 73.342 Val_Loss: 0.4878  BEST VAL Loss: 0.4878  Val_Acc: 76.437

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.5030 Train_Acc: 73.575 Val_Loss: 0.4880  BEST VAL Loss: 0.4878  Val_Acc: 76.315

Epoch 91: Validation loss decreased (0.487818 --> 0.487768).  Saving model ...
	 Train_Loss: 0.5028 Train_Acc: 73.588 Val_Loss: 0.4878  BEST VAL Loss: 0.4878  Val_Acc: 76.534

Epoch 92: Validation loss decreased (0.487768 --> 0.487598).  Saving model ...
	 Train_Loss: 0.5026 Train_Acc: 73.642 Val_Loss: 0.4876  BEST VAL Loss: 0.4876  Val_Acc: 76.568

Epoch 93: Validation loss decreased (0.487598 --> 0.487353).  Saving model ...
	 Train_Loss: 0.5024 Train_Acc: 73.737 Val_Loss: 0.4874  BEST VAL Loss: 0.4874  Val_Acc: 77.057

Epoch 94: Validation loss decreased (0.487353 --> 0.487219).  Saving model ...
	 Train_Loss: 0.5022 Train_Acc: 73.672 Val_Loss: 0.4872  BEST VAL Loss: 0.4872  Val_Acc: 77.065

Epoch 95: Validation loss decreased (0.487219 --> 0.487211).  Saving model ...
	 Train_Loss: 0.5020 Train_Acc: 73.646 Val_Loss: 0.4872  BEST VAL Loss: 0.4872  Val_Acc: 76.206

Epoch 96: Validation loss decreased (0.487211 --> 0.487092).  Saving model ...
	 Train_Loss: 0.5018 Train_Acc: 73.641 Val_Loss: 0.4871  BEST VAL Loss: 0.4871  Val_Acc: 76.501

Epoch 97: Validation loss decreased (0.487092 --> 0.486996).  Saving model ...
	 Train_Loss: 0.5016 Train_Acc: 73.810 Val_Loss: 0.4870  BEST VAL Loss: 0.4870  Val_Acc: 77.196

Epoch 98: Validation loss decreased (0.486996 --> 0.486778).  Saving model ...
	 Train_Loss: 0.5014 Train_Acc: 73.820 Val_Loss: 0.4868  BEST VAL Loss: 0.4868  Val_Acc: 77.153

Epoch 99: Validation loss decreased (0.486778 --> 0.486601).  Saving model ...
	 Train_Loss: 0.5011 Train_Acc: 73.711 Val_Loss: 0.4866  BEST VAL Loss: 0.4866  Val_Acc: 76.922

LPS_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.56      0.52     92173
           1       0.51      0.44      0.47     97754

    accuracy                           0.50    189927
   macro avg       0.50      0.50      0.50    189927
weighted avg       0.50      0.50      0.50    189927

LPS_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.56      0.52     11522
           1       0.52      0.44      0.47     12219

    accuracy                           0.50     23741
   macro avg       0.50      0.50      0.50     23741
weighted avg       0.50      0.50      0.50     23741

LPS_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.57      0.53     11522
           1       0.52      0.44      0.48     12219

    accuracy                           0.50     23741
   macro avg       0.51      0.51      0.50     23741
weighted avg       0.51      0.50      0.50     23741

              precision    recall  f1-score   support

           0       0.49      0.57      0.53     11522
           1       0.52      0.44      0.48     12219

    accuracy                           0.50     23741
   macro avg       0.51      0.51      0.50     23741
weighted avg       0.51      0.50      0.50     23741

LPS_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.49      0.51     41273
           1       0.47      0.51      0.49     37243

    accuracy                           0.50     78516
   macro avg       0.50      0.50      0.50     78516
weighted avg       0.50      0.50      0.50     78516

              precision    recall  f1-score   support

           0       0.53      0.49      0.51     41273
           1       0.47      0.51      0.49     37243

    accuracy                           0.50     78516
   macro avg       0.50      0.50      0.50     78516
weighted avg       0.50      0.50      0.50     78516

completed
