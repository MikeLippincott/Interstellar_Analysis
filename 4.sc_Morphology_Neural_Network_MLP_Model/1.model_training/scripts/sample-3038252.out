[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '09fbc4bd'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '4f783a19'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '6831ae04'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'dfd0f0f9'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_0.100_DMSO_0.025 treatment_name: LPS_10.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_0.100_DMSO_0.025
TREATMENT_NAME: LPS_10.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_10.000_DMSO_0.025']
The dimensions of the data are: (34320, 1276)
Number of total missing values across all columns: 68640
Data Subset Is Off
Wells held out for testing: ['C20' 'E21']
Wells to use for training, validation, and testing ['C16' 'E16' 'C17' 'E17' 'E20' 'C21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.685517).  Saving model ...
	 Train_Loss: 0.7633 Train_Acc: 53.951 Val_Loss: 0.6855  BEST VAL Loss: 0.6855  Val_Acc: 56.282

Epoch 1: Validation loss decreased (0.685517 --> 0.675184).  Saving model ...
	 Train_Loss: 0.7223 Train_Acc: 57.048 Val_Loss: 0.6752  BEST VAL Loss: 0.6752  Val_Acc: 59.199

Epoch 2: Validation loss decreased (0.675184 --> 0.669511).  Saving model ...
	 Train_Loss: 0.7028 Train_Acc: 59.903 Val_Loss: 0.6695  BEST VAL Loss: 0.6695  Val_Acc: 60.521

Epoch 3: Validation loss decreased (0.669511 --> 0.666746).  Saving model ...
	 Train_Loss: 0.6913 Train_Acc: 61.089 Val_Loss: 0.6667  BEST VAL Loss: 0.6667  Val_Acc: 61.532

Epoch 4: Validation loss decreased (0.666746 --> 0.662717).  Saving model ...
	 Train_Loss: 0.6821 Train_Acc: 62.237 Val_Loss: 0.6627  BEST VAL Loss: 0.6627  Val_Acc: 61.727

Epoch 5: Validation loss decreased (0.662717 --> 0.659044).  Saving model ...
	 Train_Loss: 0.6740 Train_Acc: 63.521 Val_Loss: 0.6590  BEST VAL Loss: 0.6590  Val_Acc: 62.427

Epoch 6: Validation loss decreased (0.659044 --> 0.656144).  Saving model ...
	 Train_Loss: 0.6673 Train_Acc: 64.337 Val_Loss: 0.6561  BEST VAL Loss: 0.6561  Val_Acc: 63.011

Epoch 7: Validation loss decreased (0.656144 --> 0.654601).  Saving model ...
	 Train_Loss: 0.6614 Train_Acc: 65.198 Val_Loss: 0.6546  BEST VAL Loss: 0.6546  Val_Acc: 63.244

Epoch 8: Validation loss decreased (0.654601 --> 0.652443).  Saving model ...
	 Train_Loss: 0.6566 Train_Acc: 64.960 Val_Loss: 0.6524  BEST VAL Loss: 0.6524  Val_Acc: 64.255

Epoch 9: Validation loss decreased (0.652443 --> 0.650673).  Saving model ...
	 Train_Loss: 0.6519 Train_Acc: 65.889 Val_Loss: 0.6507  BEST VAL Loss: 0.6507  Val_Acc: 64.372

Epoch 10: Validation loss decreased (0.650673 --> 0.649201).  Saving model ...
	 Train_Loss: 0.6476 Train_Acc: 66.229 Val_Loss: 0.6492  BEST VAL Loss: 0.6492  Val_Acc: 63.711

Epoch 11: Validation loss decreased (0.649201 --> 0.647928).  Saving model ...
	 Train_Loss: 0.6439 Train_Acc: 66.312 Val_Loss: 0.6479  BEST VAL Loss: 0.6479  Val_Acc: 63.827

Epoch 12: Validation loss decreased (0.647928 --> 0.647127).  Saving model ...
	 Train_Loss: 0.6403 Train_Acc: 67.294 Val_Loss: 0.6471  BEST VAL Loss: 0.6471  Val_Acc: 63.788

Epoch 13: Validation loss decreased (0.647127 --> 0.646963).  Saving model ...
	 Train_Loss: 0.6370 Train_Acc: 66.837 Val_Loss: 0.6470  BEST VAL Loss: 0.6470  Val_Acc: 63.633

Epoch 14: Validation loss decreased (0.646963 --> 0.646565).  Saving model ...
	 Train_Loss: 0.6343 Train_Acc: 66.725 Val_Loss: 0.6466  BEST VAL Loss: 0.6466  Val_Acc: 62.933

Epoch 15: Validation loss did not decrease
	 Train_Loss: 0.6319 Train_Acc: 66.744 Val_Loss: 0.6467  BEST VAL Loss: 0.6466  Val_Acc: 62.505

Epoch 16: Validation loss did not decrease
	 Train_Loss: 0.6296 Train_Acc: 67.221 Val_Loss: 0.6470  BEST VAL Loss: 0.6466  Val_Acc: 62.855

Epoch 17: Validation loss did not decrease
	 Train_Loss: 0.6274 Train_Acc: 67.333 Val_Loss: 0.6473  BEST VAL Loss: 0.6466  Val_Acc: 63.283

Epoch 18: Validation loss did not decrease
	 Train_Loss: 0.6257 Train_Acc: 66.939 Val_Loss: 0.6467  BEST VAL Loss: 0.6466  Val_Acc: 63.633

Epoch 19: Validation loss did not decrease
	 Train_Loss: 0.6239 Train_Acc: 67.289 Val_Loss: 0.6469  BEST VAL Loss: 0.6466  Val_Acc: 62.855

Epoch 20: Validation loss did not decrease
	 Train_Loss: 0.6220 Train_Acc: 67.790 Val_Loss: 0.6469  BEST VAL Loss: 0.6466  Val_Acc: 64.022

Epoch 21: Validation loss did not decrease
	 Train_Loss: 0.6203 Train_Acc: 67.571 Val_Loss: 0.6472  BEST VAL Loss: 0.6466  Val_Acc: 64.411

Epoch 22: Validation loss did not decrease
	 Train_Loss: 0.6184 Train_Acc: 68.529 Val_Loss: 0.6477  BEST VAL Loss: 0.6466  Val_Acc: 63.555

Epoch 23: Validation loss did not decrease
	 Train_Loss: 0.6167 Train_Acc: 68.023 Val_Loss: 0.6484  BEST VAL Loss: 0.6466  Val_Acc: 63.672

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.6152 Train_Acc: 68.252 Val_Loss: 0.6490  BEST VAL Loss: 0.6466  Val_Acc: 63.516

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.6139 Train_Acc: 68.203 Val_Loss: 0.6496  BEST VAL Loss: 0.6466  Val_Acc: 64.644

Epoch 26: Validation loss did not decrease
	 Train_Loss: 0.6125 Train_Acc: 68.539 Val_Loss: 0.6496  BEST VAL Loss: 0.6466  Val_Acc: 64.100

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.6111 Train_Acc: 68.690 Val_Loss: 0.6495  BEST VAL Loss: 0.6466  Val_Acc: 64.411

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.6098 Train_Acc: 68.874 Val_Loss: 0.6500  BEST VAL Loss: 0.6466  Val_Acc: 63.438

Epoch 29: Validation loss did not decrease
	 Train_Loss: 0.6084 Train_Acc: 69.147 Val_Loss: 0.6504  BEST VAL Loss: 0.6466  Val_Acc: 63.516

Epoch 30: Validation loss did not decrease
Early stopped at epoch : 30
LPS_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.74      0.66      0.70     10451
           1       0.69      0.75      0.72     10114

    accuracy                           0.71     20565
   macro avg       0.71      0.71      0.71     20565
weighted avg       0.71      0.71      0.71     20565

LPS_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.65      0.59      0.62      1307
           1       0.61      0.67      0.64      1264

    accuracy                           0.63      2571
   macro avg       0.63      0.63      0.63      2571
weighted avg       0.63      0.63      0.63      2571

LPS_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.67      0.59      0.63      1307
           1       0.62      0.70      0.66      1264

    accuracy                           0.64      2571
   macro avg       0.65      0.65      0.64      2571
weighted avg       0.65      0.64      0.64      2571

              precision    recall  f1-score   support

           0       0.67      0.59      0.63      1307
           1       0.62      0.70      0.66      1264

    accuracy                           0.64      2571
   macro avg       0.65      0.65      0.64      2571
weighted avg       0.65      0.64      0.64      2571

LPS_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.71      0.68      0.69      4445
           1       0.67      0.70      0.68      4168

    accuracy                           0.69      8613
   macro avg       0.69      0.69      0.69      8613
weighted avg       0.69      0.69      0.69      8613

              precision    recall  f1-score   support

           0       0.71      0.68      0.69      4445
           1       0.67      0.70      0.68      4168

    accuracy                           0.69      8613
   macro avg       0.69      0.69      0.69      8613
weighted avg       0.69      0.69      0.69      8613

completed
