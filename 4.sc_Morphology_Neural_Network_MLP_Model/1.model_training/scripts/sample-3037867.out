[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b19a96c2'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '9d9149c1'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'bd4bd5c2'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '7f77b243'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Flagellin_0.100_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: Flagellin_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['Flagellin_0.100_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (200462, 1270)
Number of total missing values across all columns: 437540
Data Subset Is Off
Wells held out for testing: ['L10' 'M10']
Wells to use for training, validation, and testing ['L05' 'M05' 'L11' 'M11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.669747).  Saving model ...
	 Train_Loss: 1.3353 Train_Acc: 56.147 Val_Loss: 0.6697  BEST VAL Loss: 0.6697  Val_Acc: 59.494

Epoch 1: Validation loss decreased (0.669747 --> 0.658854).  Saving model ...
	 Train_Loss: 1.0003 Train_Acc: 60.235 Val_Loss: 0.6589  BEST VAL Loss: 0.6589  Val_Acc: 63.391

Epoch 2: Validation loss decreased (0.658854 --> 0.647607).  Saving model ...
	 Train_Loss: 0.9279 Train_Acc: 60.823 Val_Loss: 0.6476  BEST VAL Loss: 0.6476  Val_Acc: 65.681

Epoch 3: Validation loss decreased (0.647607 --> 0.637324).  Saving model ...
	 Train_Loss: 0.8621 Train_Acc: 63.462 Val_Loss: 0.6373  BEST VAL Loss: 0.6373  Val_Acc: 66.612

Epoch 4: Validation loss decreased (0.637324 --> 0.631016).  Saving model ...
	 Train_Loss: 0.8325 Train_Acc: 64.324 Val_Loss: 0.6310  BEST VAL Loss: 0.6310  Val_Acc: 64.960

Epoch 5: Validation loss decreased (0.631016 --> 0.621111).  Saving model ...
	 Train_Loss: 0.7940 Train_Acc: 66.535 Val_Loss: 0.6211  BEST VAL Loss: 0.6211  Val_Acc: 70.343

Epoch 6: Validation loss decreased (0.621111 --> 0.619761).  Saving model ...
	 Train_Loss: 0.7861 Train_Acc: 64.807 Val_Loss: 0.6198  BEST VAL Loss: 0.6198  Val_Acc: 64.194

Epoch 7: Validation loss decreased (0.619761 --> 0.611589).  Saving model ...
	 Train_Loss: 0.7609 Train_Acc: 67.915 Val_Loss: 0.6116  BEST VAL Loss: 0.6116  Val_Acc: 71.394

Epoch 8: Validation loss decreased (0.611589 --> 0.605449).  Saving model ...
	 Train_Loss: 0.7416 Train_Acc: 67.795 Val_Loss: 0.6054  BEST VAL Loss: 0.6054  Val_Acc: 70.989

Epoch 9: Validation loss decreased (0.605449 --> 0.599862).  Saving model ...
	 Train_Loss: 0.7277 Train_Acc: 67.418 Val_Loss: 0.5999  BEST VAL Loss: 0.5999  Val_Acc: 70.959

Epoch 10: Validation loss decreased (0.599862 --> 0.595642).  Saving model ...
	 Train_Loss: 0.7218 Train_Acc: 66.544 Val_Loss: 0.5956  BEST VAL Loss: 0.5956  Val_Acc: 70.688

Epoch 11: Validation loss decreased (0.595642 --> 0.591921).  Saving model ...
	 Train_Loss: 0.7090 Train_Acc: 69.548 Val_Loss: 0.5919  BEST VAL Loss: 0.5919  Val_Acc: 70.869

Epoch 12: Validation loss decreased (0.591921 --> 0.588463).  Saving model ...
	 Train_Loss: 0.7020 Train_Acc: 68.567 Val_Loss: 0.5885  BEST VAL Loss: 0.5885  Val_Acc: 70.756

Epoch 13: Validation loss decreased (0.588463 --> 0.585485).  Saving model ...
	 Train_Loss: 0.6916 Train_Acc: 70.616 Val_Loss: 0.5855  BEST VAL Loss: 0.5855  Val_Acc: 71.402

Epoch 14: Validation loss decreased (0.585485 --> 0.583355).  Saving model ...
	 Train_Loss: 0.6882 Train_Acc: 69.591 Val_Loss: 0.5834  BEST VAL Loss: 0.5834  Val_Acc: 72.183

Epoch 15: Validation loss decreased (0.583355 --> 0.581408).  Saving model ...
	 Train_Loss: 0.6791 Train_Acc: 71.773 Val_Loss: 0.5814  BEST VAL Loss: 0.5814  Val_Acc: 73.046

Epoch 16: Validation loss decreased (0.581408 --> 0.579361).  Saving model ...
	 Train_Loss: 0.6722 Train_Acc: 71.064 Val_Loss: 0.5794  BEST VAL Loss: 0.5794  Val_Acc: 72.678

Epoch 17: Validation loss decreased (0.579361 --> 0.576345).  Saving model ...
	 Train_Loss: 0.6697 Train_Acc: 69.932 Val_Loss: 0.5763  BEST VAL Loss: 0.5763  Val_Acc: 72.415

Epoch 18: Validation loss decreased (0.576345 --> 0.572756).  Saving model ...
	 Train_Loss: 0.6619 Train_Acc: 73.112 Val_Loss: 0.5728  BEST VAL Loss: 0.5728  Val_Acc: 74.045

Epoch 19: Validation loss decreased (0.572756 --> 0.571404).  Saving model ...
	 Train_Loss: 0.6557 Train_Acc: 72.210 Val_Loss: 0.5714  BEST VAL Loss: 0.5714  Val_Acc: 71.912

Epoch 20: Validation loss decreased (0.571404 --> 0.568921).  Saving model ...
	 Train_Loss: 0.6534 Train_Acc: 70.166 Val_Loss: 0.5689  BEST VAL Loss: 0.5689  Val_Acc: 73.789

Epoch 21: Validation loss did not decrease
	 Train_Loss: 0.6476 Train_Acc: 73.082 Val_Loss: 0.5710  BEST VAL Loss: 0.5689  Val_Acc: 68.849

Epoch 22: Validation loss did not decrease
	 Train_Loss: 0.6425 Train_Acc: 72.734 Val_Loss: 0.5696  BEST VAL Loss: 0.5689  Val_Acc: 73.722

Epoch 23: Validation loss decreased (0.568921 --> 0.567128).  Saving model ...
	 Train_Loss: 0.6385 Train_Acc: 71.795 Val_Loss: 0.5671  BEST VAL Loss: 0.5671  Val_Acc: 73.909

Epoch 24: Validation loss decreased (0.567128 --> 0.565437).  Saving model ...
	 Train_Loss: 0.6372 Train_Acc: 70.957 Val_Loss: 0.5654  BEST VAL Loss: 0.5654  Val_Acc: 73.481

Epoch 25: Validation loss decreased (0.565437 --> 0.563221).  Saving model ...
	 Train_Loss: 0.6323 Train_Acc: 73.853 Val_Loss: 0.5632  BEST VAL Loss: 0.5632  Val_Acc: 74.608

Epoch 26: Validation loss decreased (0.563221 --> 0.561879).  Saving model ...
	 Train_Loss: 0.6282 Train_Acc: 73.160 Val_Loss: 0.5619  BEST VAL Loss: 0.5619  Val_Acc: 74.232

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.6247 Train_Acc: 72.842 Val_Loss: 0.5628  BEST VAL Loss: 0.5619  Val_Acc: 68.489

Epoch 28: Validation loss decreased (0.561879 --> 0.561114).  Saving model ...
	 Train_Loss: 0.6214 Train_Acc: 72.631 Val_Loss: 0.5611  BEST VAL Loss: 0.5611  Val_Acc: 73.985

Epoch 29: Validation loss decreased (0.561114 --> 0.559936).  Saving model ...
	 Train_Loss: 0.6189 Train_Acc: 72.670 Val_Loss: 0.5599  BEST VAL Loss: 0.5599  Val_Acc: 75.171

Epoch 30: Validation loss decreased (0.559936 --> 0.558864).  Saving model ...
	 Train_Loss: 0.6172 Train_Acc: 72.098 Val_Loss: 0.5589  BEST VAL Loss: 0.5589  Val_Acc: 72.032

Epoch 31: Validation loss decreased (0.558864 --> 0.557139).  Saving model ...
	 Train_Loss: 0.6133 Train_Acc: 74.681 Val_Loss: 0.5571  BEST VAL Loss: 0.5571  Val_Acc: 74.195

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.6104 Train_Acc: 73.618 Val_Loss: 0.5578  BEST VAL Loss: 0.5571  Val_Acc: 71.650

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.6076 Train_Acc: 73.430 Val_Loss: 0.5580  BEST VAL Loss: 0.5571  Val_Acc: 70.253

Epoch 34: Validation loss decreased (0.557139 --> 0.556667).  Saving model ...
	 Train_Loss: 0.6060 Train_Acc: 72.527 Val_Loss: 0.5567  BEST VAL Loss: 0.5567  Val_Acc: 75.043

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.6030 Train_Acc: 74.695 Val_Loss: 0.5567  BEST VAL Loss: 0.5567  Val_Acc: 73.324

Epoch 36: Validation loss decreased (0.556667 --> 0.555934).  Saving model ...
	 Train_Loss: 0.6011 Train_Acc: 72.652 Val_Loss: 0.5559  BEST VAL Loss: 0.5559  Val_Acc: 72.731

Epoch 37: Validation loss decreased (0.555934 --> 0.554790).  Saving model ...
	 Train_Loss: 0.5983 Train_Acc: 74.788 Val_Loss: 0.5548  BEST VAL Loss: 0.5548  Val_Acc: 73.774

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.5962 Train_Acc: 73.827 Val_Loss: 0.5549  BEST VAL Loss: 0.5548  Val_Acc: 73.174

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.5952 Train_Acc: 73.752 Val_Loss: 0.5647  BEST VAL Loss: 0.5548  Val_Acc: 56.431

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.5931 Train_Acc: 74.016 Val_Loss: 0.5671  BEST VAL Loss: 0.5548  Val_Acc: 70.779

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.5907 Train_Acc: 75.204 Val_Loss: 0.5663  BEST VAL Loss: 0.5548  Val_Acc: 74.172

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.5886 Train_Acc: 74.546 Val_Loss: 0.5674  BEST VAL Loss: 0.5548  Val_Acc: 71.980

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.5872 Train_Acc: 73.541 Val_Loss: 0.5672  BEST VAL Loss: 0.5548  Val_Acc: 70.981

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.5850 Train_Acc: 75.266 Val_Loss: 0.5657  BEST VAL Loss: 0.5548  Val_Acc: 75.847

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.5833 Train_Acc: 74.102 Val_Loss: 0.5648  BEST VAL Loss: 0.5548  Val_Acc: 72.828

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.5815 Train_Acc: 74.845 Val_Loss: 0.5655  BEST VAL Loss: 0.5548  Val_Acc: 72.806

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.5798 Train_Acc: 74.446 Val_Loss: 0.5648  BEST VAL Loss: 0.5548  Val_Acc: 73.887

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.5781 Train_Acc: 74.574 Val_Loss: 0.5638  BEST VAL Loss: 0.5548  Val_Acc: 75.389

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.5774 Train_Acc: 73.526 Val_Loss: 0.5624  BEST VAL Loss: 0.5548  Val_Acc: 75.914

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.5756 Train_Acc: 75.147 Val_Loss: 0.5616  BEST VAL Loss: 0.5548  Val_Acc: 74.518

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.5740 Train_Acc: 74.926 Val_Loss: 0.5616  BEST VAL Loss: 0.5548  Val_Acc: 72.363

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.5724 Train_Acc: 75.107 Val_Loss: 0.5609  BEST VAL Loss: 0.5548  Val_Acc: 75.471

Epoch 53: Validation loss did not decrease
Early stopped at epoch : 53
Flagellin_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.80      0.64      0.71     50422
           1       0.73      0.86      0.79     56121

    accuracy                           0.76    106543
   macro avg       0.76      0.75      0.75    106543
weighted avg       0.76      0.76      0.75    106543

Flagellin_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.78      0.62      0.69      6303
           1       0.71      0.84      0.77      7016

    accuracy                           0.74     13319
   macro avg       0.75      0.73      0.73     13319
weighted avg       0.74      0.74      0.73     13319

Flagellin_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.78      0.63      0.70      6303
           1       0.72      0.84      0.78      7016

    accuracy                           0.74     13319
   macro avg       0.75      0.74      0.74     13319
weighted avg       0.75      0.74      0.74     13319

              precision    recall  f1-score   support

           0       0.78      0.63      0.70      6303
           1       0.72      0.84      0.78      7016

    accuracy                           0.74     13319
   macro avg       0.75      0.74      0.74     13319
weighted avg       0.75      0.74      0.74     13319

Flagellin_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.51      0.54      0.53     32887
           1       0.53      0.50      0.52     34394

    accuracy                           0.52     67281
   macro avg       0.52      0.52      0.52     67281
weighted avg       0.52      0.52      0.52     67281

              precision    recall  f1-score   support

           0       0.51      0.54      0.53     32887
           1       0.53      0.50      0.52     34394

    accuracy                           0.52     67281
   macro avg       0.52      0.52      0.52     67281
weighted avg       0.52      0.52      0.52     67281

completed
