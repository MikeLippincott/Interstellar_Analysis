[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '86d6d495'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '6db75798'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '14eb04ed'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'd72bee7b'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_0.100_DMSO_0.025 treatment_name: H2O2_100.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_0.100_DMSO_0.025
TREATMENT_NAME: H2O2_100.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (44410, 1276)
Number of total missing values across all columns: 88820
Data Subset Is Off
Wells held out for testing: ['C21' 'H22']
Wells to use for training, validation, and testing ['C16' 'C17' 'H18' 'H19' 'C20' 'H23' 'I18' 'I19' 'I22' 'I23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.630295).  Saving model ...
	 Train_Loss: 0.7961 Train_Acc: 61.011 Val_Loss: 0.6303  BEST VAL Loss: 0.6303  Val_Acc: 64.614

Epoch 1: Validation loss decreased (0.630295 --> 0.592541).  Saving model ...
	 Train_Loss: 0.7025 Train_Acc: 66.233 Val_Loss: 0.5925  BEST VAL Loss: 0.5925  Val_Acc: 69.989

Epoch 2: Validation loss decreased (0.592541 --> 0.569772).  Saving model ...
	 Train_Loss: 0.6566 Train_Acc: 69.736 Val_Loss: 0.5698  BEST VAL Loss: 0.5698  Val_Acc: 72.816

Epoch 3: Validation loss decreased (0.569772 --> 0.550330).  Saving model ...
	 Train_Loss: 0.6274 Train_Acc: 71.230 Val_Loss: 0.5503  BEST VAL Loss: 0.5503  Val_Acc: 74.636

Epoch 4: Validation loss decreased (0.550330 --> 0.537264).  Saving model ...
	 Train_Loss: 0.6054 Train_Acc: 72.451 Val_Loss: 0.5373  BEST VAL Loss: 0.5373  Val_Acc: 75.196

Epoch 5: Validation loss decreased (0.537264 --> 0.526019).  Saving model ...
	 Train_Loss: 0.5878 Train_Acc: 73.127 Val_Loss: 0.5260  BEST VAL Loss: 0.5260  Val_Acc: 76.260

Epoch 6: Validation loss decreased (0.526019 --> 0.516801).  Saving model ...
	 Train_Loss: 0.5741 Train_Acc: 73.253 Val_Loss: 0.5168  BEST VAL Loss: 0.5168  Val_Acc: 76.932

Epoch 7: Validation loss decreased (0.516801 --> 0.510836).  Saving model ...
	 Train_Loss: 0.5626 Train_Acc: 73.865 Val_Loss: 0.5108  BEST VAL Loss: 0.5108  Val_Acc: 76.652

Epoch 8: Validation loss decreased (0.510836 --> 0.505416).  Saving model ...
	 Train_Loss: 0.5535 Train_Acc: 73.757 Val_Loss: 0.5054  BEST VAL Loss: 0.5054  Val_Acc: 77.604

Epoch 9: Validation loss decreased (0.505416 --> 0.500434).  Saving model ...
	 Train_Loss: 0.5454 Train_Acc: 74.128 Val_Loss: 0.5004  BEST VAL Loss: 0.5004  Val_Acc: 77.380

Epoch 10: Validation loss decreased (0.500434 --> 0.496692).  Saving model ...
	 Train_Loss: 0.5388 Train_Acc: 74.159 Val_Loss: 0.4967  BEST VAL Loss: 0.4967  Val_Acc: 78.471

Epoch 11: Validation loss decreased (0.496692 --> 0.492202).  Saving model ...
	 Train_Loss: 0.5328 Train_Acc: 74.250 Val_Loss: 0.4922  BEST VAL Loss: 0.4922  Val_Acc: 79.087

Epoch 12: Validation loss decreased (0.492202 --> 0.489474).  Saving model ...
	 Train_Loss: 0.5275 Train_Acc: 74.481 Val_Loss: 0.4895  BEST VAL Loss: 0.4895  Val_Acc: 77.548

Epoch 13: Validation loss decreased (0.489474 --> 0.487182).  Saving model ...
	 Train_Loss: 0.5228 Train_Acc: 74.639 Val_Loss: 0.4872  BEST VAL Loss: 0.4872  Val_Acc: 77.632

Epoch 14: Validation loss decreased (0.487182 --> 0.484667).  Saving model ...
	 Train_Loss: 0.5189 Train_Acc: 74.600 Val_Loss: 0.4847  BEST VAL Loss: 0.4847  Val_Acc: 77.940

Epoch 15: Validation loss decreased (0.484667 --> 0.482358).  Saving model ...
	 Train_Loss: 0.5152 Train_Acc: 74.586 Val_Loss: 0.4824  BEST VAL Loss: 0.4824  Val_Acc: 77.828

Epoch 16: Validation loss decreased (0.482358 --> 0.480106).  Saving model ...
	 Train_Loss: 0.5121 Train_Acc: 74.901 Val_Loss: 0.4801  BEST VAL Loss: 0.4801  Val_Acc: 78.527

Epoch 17: Validation loss decreased (0.480106 --> 0.478396).  Saving model ...
	 Train_Loss: 0.5088 Train_Acc: 74.793 Val_Loss: 0.4784  BEST VAL Loss: 0.4784  Val_Acc: 77.632

Epoch 18: Validation loss decreased (0.478396 --> 0.476676).  Saving model ...
	 Train_Loss: 0.5061 Train_Acc: 74.481 Val_Loss: 0.4767  BEST VAL Loss: 0.4767  Val_Acc: 77.352

Epoch 19: Validation loss decreased (0.476676 --> 0.474915).  Saving model ...
	 Train_Loss: 0.5036 Train_Acc: 74.751 Val_Loss: 0.4749  BEST VAL Loss: 0.4749  Val_Acc: 77.660

Epoch 20: Validation loss decreased (0.474915 --> 0.473762).  Saving model ...
	 Train_Loss: 0.5014 Train_Acc: 74.828 Val_Loss: 0.4738  BEST VAL Loss: 0.4738  Val_Acc: 78.471

Epoch 21: Validation loss decreased (0.473762 --> 0.472605).  Saving model ...
	 Train_Loss: 0.4995 Train_Acc: 74.726 Val_Loss: 0.4726  BEST VAL Loss: 0.4726  Val_Acc: 78.331

Epoch 22: Validation loss decreased (0.472605 --> 0.471722).  Saving model ...
	 Train_Loss: 0.4977 Train_Acc: 74.457 Val_Loss: 0.4717  BEST VAL Loss: 0.4717  Val_Acc: 78.163

Epoch 23: Validation loss decreased (0.471722 --> 0.470833).  Saving model ...
	 Train_Loss: 0.4958 Train_Acc: 74.618 Val_Loss: 0.4708  BEST VAL Loss: 0.4708  Val_Acc: 78.163

Epoch 24: Validation loss decreased (0.470833 --> 0.470062).  Saving model ...
	 Train_Loss: 0.4940 Train_Acc: 74.376 Val_Loss: 0.4701  BEST VAL Loss: 0.4701  Val_Acc: 77.940

Epoch 25: Validation loss decreased (0.470062 --> 0.469139).  Saving model ...
	 Train_Loss: 0.4923 Train_Acc: 74.716 Val_Loss: 0.4691  BEST VAL Loss: 0.4691  Val_Acc: 78.275

Epoch 26: Validation loss decreased (0.469139 --> 0.468249).  Saving model ...
	 Train_Loss: 0.4905 Train_Acc: 75.031 Val_Loss: 0.4682  BEST VAL Loss: 0.4682  Val_Acc: 77.772

Epoch 27: Validation loss decreased (0.468249 --> 0.467510).  Saving model ...
	 Train_Loss: 0.4889 Train_Acc: 74.821 Val_Loss: 0.4675  BEST VAL Loss: 0.4675  Val_Acc: 78.080

Epoch 28: Validation loss decreased (0.467510 --> 0.466712).  Saving model ...
	 Train_Loss: 0.4875 Train_Acc: 74.712 Val_Loss: 0.4667  BEST VAL Loss: 0.4667  Val_Acc: 77.296

Epoch 29: Validation loss decreased (0.466712 --> 0.465806).  Saving model ...
	 Train_Loss: 0.4861 Train_Acc: 75.020 Val_Loss: 0.4658  BEST VAL Loss: 0.4658  Val_Acc: 77.464

Epoch 30: Validation loss decreased (0.465806 --> 0.464892).  Saving model ...
	 Train_Loss: 0.4848 Train_Acc: 75.024 Val_Loss: 0.4649  BEST VAL Loss: 0.4649  Val_Acc: 77.660

Epoch 31: Validation loss decreased (0.464892 --> 0.464306).  Saving model ...
	 Train_Loss: 0.4834 Train_Acc: 75.265 Val_Loss: 0.4643  BEST VAL Loss: 0.4643  Val_Acc: 78.443

Epoch 32: Validation loss decreased (0.464306 --> 0.463776).  Saving model ...
	 Train_Loss: 0.4821 Train_Acc: 75.230 Val_Loss: 0.4638  BEST VAL Loss: 0.4638  Val_Acc: 77.716

Epoch 33: Validation loss decreased (0.463776 --> 0.463232).  Saving model ...
	 Train_Loss: 0.4808 Train_Acc: 74.719 Val_Loss: 0.4632  BEST VAL Loss: 0.4632  Val_Acc: 78.108

Epoch 34: Validation loss decreased (0.463232 --> 0.462565).  Saving model ...
	 Train_Loss: 0.4796 Train_Acc: 75.234 Val_Loss: 0.4626  BEST VAL Loss: 0.4626  Val_Acc: 78.024

Epoch 35: Validation loss decreased (0.462565 --> 0.461961).  Saving model ...
	 Train_Loss: 0.4785 Train_Acc: 75.209 Val_Loss: 0.4620  BEST VAL Loss: 0.4620  Val_Acc: 78.024

Epoch 36: Validation loss decreased (0.461961 --> 0.461303).  Saving model ...
	 Train_Loss: 0.4775 Train_Acc: 74.887 Val_Loss: 0.4613  BEST VAL Loss: 0.4613  Val_Acc: 77.996

Epoch 37: Validation loss decreased (0.461303 --> 0.460898).  Saving model ...
	 Train_Loss: 0.4764 Train_Acc: 74.877 Val_Loss: 0.4609  BEST VAL Loss: 0.4609  Val_Acc: 77.688

Epoch 38: Validation loss decreased (0.460898 --> 0.460551).  Saving model ...
	 Train_Loss: 0.4754 Train_Acc: 74.926 Val_Loss: 0.4606  BEST VAL Loss: 0.4606  Val_Acc: 78.443

Epoch 39: Validation loss decreased (0.460551 --> 0.460361).  Saving model ...
	 Train_Loss: 0.4744 Train_Acc: 75.139 Val_Loss: 0.4604  BEST VAL Loss: 0.4604  Val_Acc: 77.240

Epoch 40: Validation loss decreased (0.460361 --> 0.460345).  Saving model ...
	 Train_Loss: 0.4735 Train_Acc: 74.719 Val_Loss: 0.4603  BEST VAL Loss: 0.4603  Val_Acc: 77.380

Epoch 41: Validation loss decreased (0.460345 --> 0.459937).  Saving model ...
	 Train_Loss: 0.4728 Train_Acc: 74.317 Val_Loss: 0.4599  BEST VAL Loss: 0.4599  Val_Acc: 78.247

Epoch 42: Validation loss decreased (0.459937 --> 0.459539).  Saving model ...
	 Train_Loss: 0.4720 Train_Acc: 75.178 Val_Loss: 0.4595  BEST VAL Loss: 0.4595  Val_Acc: 77.100

Epoch 43: Validation loss decreased (0.459539 --> 0.459202).  Saving model ...
	 Train_Loss: 0.4711 Train_Acc: 74.789 Val_Loss: 0.4592  BEST VAL Loss: 0.4592  Val_Acc: 78.695

Epoch 44: Validation loss decreased (0.459202 --> 0.458804).  Saving model ...
	 Train_Loss: 0.4703 Train_Acc: 74.548 Val_Loss: 0.4588  BEST VAL Loss: 0.4588  Val_Acc: 77.604

Epoch 45: Validation loss decreased (0.458804 --> 0.458741).  Saving model ...
	 Train_Loss: 0.4694 Train_Acc: 75.241 Val_Loss: 0.4587  BEST VAL Loss: 0.4587  Val_Acc: 77.912

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.4687 Train_Acc: 75.104 Val_Loss: 0.4589  BEST VAL Loss: 0.4587  Val_Acc: 77.856

Epoch 47: Validation loss decreased (0.458741 --> 0.458681).  Saving model ...
	 Train_Loss: 0.4679 Train_Acc: 74.667 Val_Loss: 0.4587  BEST VAL Loss: 0.4587  Val_Acc: 78.527

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.4671 Train_Acc: 75.223 Val_Loss: 0.4587  BEST VAL Loss: 0.4587  Val_Acc: 78.331

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.4665 Train_Acc: 74.684 Val_Loss: 0.4588  BEST VAL Loss: 0.4587  Val_Acc: 76.876

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.4659 Train_Acc: 74.730 Val_Loss: 0.4590  BEST VAL Loss: 0.4587  Val_Acc: 78.611

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.4653 Train_Acc: 74.730 Val_Loss: 0.4590  BEST VAL Loss: 0.4587  Val_Acc: 78.695

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.4648 Train_Acc: 74.740 Val_Loss: 0.4588  BEST VAL Loss: 0.4587  Val_Acc: 77.324

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.4642 Train_Acc: 74.590 Val_Loss: 0.4588  BEST VAL Loss: 0.4587  Val_Acc: 77.688

Epoch 54: Validation loss decreased (0.458681 --> 0.458618).  Saving model ...
	 Train_Loss: 0.4638 Train_Acc: 74.478 Val_Loss: 0.4586  BEST VAL Loss: 0.4586  Val_Acc: 78.947

Epoch 55: Validation loss decreased (0.458618 --> 0.458455).  Saving model ...
	 Train_Loss: 0.4632 Train_Acc: 74.642 Val_Loss: 0.4585  BEST VAL Loss: 0.4585  Val_Acc: 77.352

Epoch 56: Validation loss decreased (0.458455 --> 0.458241).  Saving model ...
	 Train_Loss: 0.4626 Train_Acc: 74.856 Val_Loss: 0.4582  BEST VAL Loss: 0.4582  Val_Acc: 77.856

Epoch 57: Validation loss decreased (0.458241 --> 0.458089).  Saving model ...
	 Train_Loss: 0.4620 Train_Acc: 74.751 Val_Loss: 0.4581  BEST VAL Loss: 0.4581  Val_Acc: 77.548

Epoch 58: Validation loss decreased (0.458089 --> 0.457864).  Saving model ...
	 Train_Loss: 0.4614 Train_Acc: 74.733 Val_Loss: 0.4579  BEST VAL Loss: 0.4579  Val_Acc: 76.680

Epoch 59: Validation loss decreased (0.457864 --> 0.457765).  Saving model ...
	 Train_Loss: 0.4609 Train_Acc: 74.670 Val_Loss: 0.4578  BEST VAL Loss: 0.4578  Val_Acc: 77.268

Epoch 60: Validation loss decreased (0.457765 --> 0.457672).  Saving model ...
	 Train_Loss: 0.4604 Train_Acc: 74.740 Val_Loss: 0.4577  BEST VAL Loss: 0.4577  Val_Acc: 77.212

Epoch 61: Validation loss decreased (0.457672 --> 0.457518).  Saving model ...
	 Train_Loss: 0.4599 Train_Acc: 74.464 Val_Loss: 0.4575  BEST VAL Loss: 0.4575  Val_Acc: 78.947

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.4593 Train_Acc: 75.258 Val_Loss: 0.4577  BEST VAL Loss: 0.4575  Val_Acc: 78.499

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.4588 Train_Acc: 74.943 Val_Loss: 0.4576  BEST VAL Loss: 0.4575  Val_Acc: 77.268

Epoch 64: Validation loss decreased (0.457518 --> 0.457276).  Saving model ...
	 Train_Loss: 0.4583 Train_Acc: 74.740 Val_Loss: 0.4573  BEST VAL Loss: 0.4573  Val_Acc: 77.324

Epoch 65: Validation loss decreased (0.457276 --> 0.457244).  Saving model ...
	 Train_Loss: 0.4578 Train_Acc: 74.656 Val_Loss: 0.4572  BEST VAL Loss: 0.4572  Val_Acc: 77.016

Epoch 66: Validation loss decreased (0.457244 --> 0.456958).  Saving model ...
	 Train_Loss: 0.4573 Train_Acc: 74.537 Val_Loss: 0.4570  BEST VAL Loss: 0.4570  Val_Acc: 77.100

Epoch 67: Validation loss decreased (0.456958 --> 0.456751).  Saving model ...
	 Train_Loss: 0.4569 Train_Acc: 74.625 Val_Loss: 0.4568  BEST VAL Loss: 0.4568  Val_Acc: 77.380

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.4564 Train_Acc: 74.425 Val_Loss: 0.4568  BEST VAL Loss: 0.4568  Val_Acc: 77.268

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.4560 Train_Acc: 74.541 Val_Loss: 0.4569  BEST VAL Loss: 0.4568  Val_Acc: 78.331

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.4556 Train_Acc: 74.870 Val_Loss: 0.4570  BEST VAL Loss: 0.4568  Val_Acc: 76.204

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.4553 Train_Acc: 74.380 Val_Loss: 0.4570  BEST VAL Loss: 0.4568  Val_Acc: 78.443

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.4549 Train_Acc: 74.870 Val_Loss: 0.4570  BEST VAL Loss: 0.4568  Val_Acc: 77.072

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.4545 Train_Acc: 74.971 Val_Loss: 0.4572  BEST VAL Loss: 0.4568  Val_Acc: 77.128

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.4541 Train_Acc: 75.013 Val_Loss: 0.4573  BEST VAL Loss: 0.4568  Val_Acc: 77.128

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.4537 Train_Acc: 74.789 Val_Loss: 0.4574  BEST VAL Loss: 0.4568  Val_Acc: 76.652

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.4534 Train_Acc: 74.324 Val_Loss: 0.4576  BEST VAL Loss: 0.4568  Val_Acc: 77.016

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.4531 Train_Acc: 74.411 Val_Loss: 0.4576  BEST VAL Loss: 0.4568  Val_Acc: 76.960

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.4528 Train_Acc: 74.194 Val_Loss: 0.4578  BEST VAL Loss: 0.4568  Val_Acc: 77.184

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.4524 Train_Acc: 74.404 Val_Loss: 0.4579  BEST VAL Loss: 0.4568  Val_Acc: 77.016

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.4522 Train_Acc: 74.558 Val_Loss: 0.4581  BEST VAL Loss: 0.4568  Val_Acc: 75.980

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.4519 Train_Acc: 74.695 Val_Loss: 0.4581  BEST VAL Loss: 0.4568  Val_Acc: 76.652

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.4516 Train_Acc: 74.313 Val_Loss: 0.4580  BEST VAL Loss: 0.4568  Val_Acc: 76.848

Epoch 83: Validation loss did not decrease
Early stopped at epoch : 83
LPS_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.77      0.95      0.85     18174
           1       0.86      0.51      0.64     10401

    accuracy                           0.79     28575
   macro avg       0.82      0.73      0.75     28575
weighted avg       0.81      0.79      0.78     28575

LPS_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.76      0.94      0.84      2272
           1       0.82      0.48      0.61      1300

    accuracy                           0.77      3572
   macro avg       0.79      0.71      0.72      3572
weighted avg       0.78      0.77      0.76      3572

LPS_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.76      0.93      0.83      2272
           1       0.80      0.47      0.60      1300

    accuracy                           0.77      3572
   macro avg       0.78      0.70      0.72      3572
weighted avg       0.77      0.77      0.75      3572

              precision    recall  f1-score   support

           0       0.76      0.93      0.83      2272
           1       0.80      0.47      0.60      1300

    accuracy                           0.77      3572
   macro avg       0.78      0.70      0.72      3572
weighted avg       0.77      0.77      0.75      3572

LPS_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.59      0.95      0.73      4182
           1       0.89      0.39      0.55      4509

    accuracy                           0.66      8691
   macro avg       0.74      0.67      0.64      8691
weighted avg       0.74      0.66      0.63      8691

              precision    recall  f1-score   support

           0       0.59      0.95      0.73      4182
           1       0.89      0.39      0.55      4509

    accuracy                           0.66      8691
   macro avg       0.74      0.67      0.64      8691
weighted avg       0.74      0.66      0.63      8691

completed
