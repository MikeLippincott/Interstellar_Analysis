[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '4ae22f02'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '952fe628'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'f54939db'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '9ea3cb96'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Flagellin_0.100_DMSO_0.025 treatment_name: Thapsigargin_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: Thapsigargin_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (244371, 1270)
Number of total missing values across all columns: 488742
Data Subset Is Off
Wells held out for testing: ['K07' 'L10']
Wells to use for training, validation, and testing ['D06' 'D07' 'K06' 'L05' 'L11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.496630).  Saving model ...
	 Train_Loss: 0.5758 Train_Acc: 68.130 Val_Loss: 0.4966  BEST VAL Loss: 0.4966  Val_Acc: 75.945

Epoch 1: Validation loss decreased (0.496630 --> 0.482146).  Saving model ...
	 Train_Loss: 0.5492 Train_Acc: 72.106 Val_Loss: 0.4821  BEST VAL Loss: 0.4821  Val_Acc: 77.488

Epoch 2: Validation loss decreased (0.482146 --> 0.469586).  Saving model ...
	 Train_Loss: 0.5326 Train_Acc: 73.402 Val_Loss: 0.4696  BEST VAL Loss: 0.4696  Val_Acc: 79.592

Epoch 3: Validation loss decreased (0.469586 --> 0.463617).  Saving model ...
	 Train_Loss: 0.5216 Train_Acc: 74.017 Val_Loss: 0.4636  BEST VAL Loss: 0.4636  Val_Acc: 80.014

Epoch 4: Validation loss decreased (0.463617 --> 0.456601).  Saving model ...
	 Train_Loss: 0.5133 Train_Acc: 74.646 Val_Loss: 0.4566  BEST VAL Loss: 0.4566  Val_Acc: 80.314

Epoch 5: Validation loss decreased (0.456601 --> 0.452830).  Saving model ...
	 Train_Loss: 0.5067 Train_Acc: 74.799 Val_Loss: 0.4528  BEST VAL Loss: 0.4528  Val_Acc: 80.459

Epoch 6: Validation loss decreased (0.452830 --> 0.447802).  Saving model ...
	 Train_Loss: 0.5008 Train_Acc: 75.032 Val_Loss: 0.4478  BEST VAL Loss: 0.4478  Val_Acc: 80.679

Epoch 7: Validation loss decreased (0.447802 --> 0.443298).  Saving model ...
	 Train_Loss: 0.4961 Train_Acc: 75.144 Val_Loss: 0.4433  BEST VAL Loss: 0.4433  Val_Acc: 81.505

Epoch 8: Validation loss decreased (0.443298 --> 0.440420).  Saving model ...
	 Train_Loss: 0.4926 Train_Acc: 75.011 Val_Loss: 0.4404  BEST VAL Loss: 0.4404  Val_Acc: 80.702

Epoch 9: Validation loss decreased (0.440420 --> 0.437516).  Saving model ...
	 Train_Loss: 0.4889 Train_Acc: 75.362 Val_Loss: 0.4375  BEST VAL Loss: 0.4375  Val_Acc: 81.413

Epoch 10: Validation loss decreased (0.437516 --> 0.434837).  Saving model ...
	 Train_Loss: 0.4859 Train_Acc: 75.342 Val_Loss: 0.4348  BEST VAL Loss: 0.4348  Val_Acc: 81.430

Epoch 11: Validation loss decreased (0.434837 --> 0.432950).  Saving model ...
	 Train_Loss: 0.4832 Train_Acc: 75.534 Val_Loss: 0.4329  BEST VAL Loss: 0.4329  Val_Acc: 81.152

Epoch 12: Validation loss decreased (0.432950 --> 0.430377).  Saving model ...
	 Train_Loss: 0.4807 Train_Acc: 75.950 Val_Loss: 0.4304  BEST VAL Loss: 0.4304  Val_Acc: 81.898

Epoch 13: Validation loss decreased (0.430377 --> 0.427931).  Saving model ...
	 Train_Loss: 0.4782 Train_Acc: 76.491 Val_Loss: 0.4279  BEST VAL Loss: 0.4279  Val_Acc: 81.632

Epoch 14: Validation loss decreased (0.427931 --> 0.426568).  Saving model ...
	 Train_Loss: 0.4762 Train_Acc: 76.325 Val_Loss: 0.4266  BEST VAL Loss: 0.4266  Val_Acc: 81.488

Epoch 15: Validation loss decreased (0.426568 --> 0.424448).  Saving model ...
	 Train_Loss: 0.4741 Train_Acc: 76.475 Val_Loss: 0.4244  BEST VAL Loss: 0.4244  Val_Acc: 82.303

Epoch 16: Validation loss decreased (0.424448 --> 0.422267).  Saving model ...
	 Train_Loss: 0.4721 Train_Acc: 76.557 Val_Loss: 0.4223  BEST VAL Loss: 0.4223  Val_Acc: 81.852

Epoch 17: Validation loss decreased (0.422267 --> 0.420268).  Saving model ...
	 Train_Loss: 0.4703 Train_Acc: 76.681 Val_Loss: 0.4203  BEST VAL Loss: 0.4203  Val_Acc: 81.939

Epoch 18: Validation loss decreased (0.420268 --> 0.419096).  Saving model ...
	 Train_Loss: 0.4687 Train_Acc: 76.661 Val_Loss: 0.4191  BEST VAL Loss: 0.4191  Val_Acc: 81.632

Epoch 19: Validation loss decreased (0.419096 --> 0.417769).  Saving model ...
	 Train_Loss: 0.4672 Train_Acc: 76.647 Val_Loss: 0.4178  BEST VAL Loss: 0.4178  Val_Acc: 82.412

Epoch 20: Validation loss decreased (0.417769 --> 0.416320).  Saving model ...
	 Train_Loss: 0.4658 Train_Acc: 76.690 Val_Loss: 0.4163  BEST VAL Loss: 0.4163  Val_Acc: 82.233

Epoch 21: Validation loss decreased (0.416320 --> 0.415182).  Saving model ...
	 Train_Loss: 0.4645 Train_Acc: 76.716 Val_Loss: 0.4152  BEST VAL Loss: 0.4152  Val_Acc: 81.875

Epoch 22: Validation loss decreased (0.415182 --> 0.413788).  Saving model ...
	 Train_Loss: 0.4632 Train_Acc: 76.831 Val_Loss: 0.4138  BEST VAL Loss: 0.4138  Val_Acc: 82.499

Epoch 23: Validation loss decreased (0.413788 --> 0.412411).  Saving model ...
	 Train_Loss: 0.4621 Train_Acc: 76.805 Val_Loss: 0.4124  BEST VAL Loss: 0.4124  Val_Acc: 82.493

Epoch 24: Validation loss decreased (0.412411 --> 0.411322).  Saving model ...
	 Train_Loss: 0.4609 Train_Acc: 76.846 Val_Loss: 0.4113  BEST VAL Loss: 0.4113  Val_Acc: 82.332

Epoch 25: Validation loss decreased (0.411322 --> 0.410479).  Saving model ...
	 Train_Loss: 0.4598 Train_Acc: 76.939 Val_Loss: 0.4105  BEST VAL Loss: 0.4105  Val_Acc: 82.268

Epoch 26: Validation loss decreased (0.410479 --> 0.409430).  Saving model ...
	 Train_Loss: 0.4587 Train_Acc: 77.000 Val_Loss: 0.4094  BEST VAL Loss: 0.4094  Val_Acc: 82.303

Epoch 27: Validation loss decreased (0.409430 --> 0.408472).  Saving model ...
	 Train_Loss: 0.4577 Train_Acc: 77.044 Val_Loss: 0.4085  BEST VAL Loss: 0.4085  Val_Acc: 82.193

Epoch 28: Validation loss decreased (0.408472 --> 0.407763).  Saving model ...
	 Train_Loss: 0.4567 Train_Acc: 76.841 Val_Loss: 0.4078  BEST VAL Loss: 0.4078  Val_Acc: 82.152

Epoch 29: Validation loss decreased (0.407763 --> 0.406894).  Saving model ...
	 Train_Loss: 0.4558 Train_Acc: 77.035 Val_Loss: 0.4069  BEST VAL Loss: 0.4069  Val_Acc: 82.707

Epoch 30: Validation loss decreased (0.406894 --> 0.406284).  Saving model ...
	 Train_Loss: 0.4550 Train_Acc: 77.075 Val_Loss: 0.4063  BEST VAL Loss: 0.4063  Val_Acc: 82.366

Epoch 31: Validation loss decreased (0.406284 --> 0.405331).  Saving model ...
	 Train_Loss: 0.4542 Train_Acc: 76.934 Val_Loss: 0.4053  BEST VAL Loss: 0.4053  Val_Acc: 82.973

Epoch 32: Validation loss decreased (0.405331 --> 0.404615).  Saving model ...
	 Train_Loss: 0.4533 Train_Acc: 77.029 Val_Loss: 0.4046  BEST VAL Loss: 0.4046  Val_Acc: 82.291

Epoch 33: Validation loss decreased (0.404615 --> 0.404095).  Saving model ...
	 Train_Loss: 0.4526 Train_Acc: 77.005 Val_Loss: 0.4041  BEST VAL Loss: 0.4041  Val_Acc: 82.308

Epoch 34: Validation loss decreased (0.404095 --> 0.403942).  Saving model ...
	 Train_Loss: 0.4520 Train_Acc: 77.029 Val_Loss: 0.4039  BEST VAL Loss: 0.4039  Val_Acc: 81.811

Epoch 35: Validation loss decreased (0.403942 --> 0.403427).  Saving model ...
	 Train_Loss: 0.4513 Train_Acc: 77.028 Val_Loss: 0.4034  BEST VAL Loss: 0.4034  Val_Acc: 82.436

Epoch 36: Validation loss decreased (0.403427 --> 0.402726).  Saving model ...
	 Train_Loss: 0.4506 Train_Acc: 76.960 Val_Loss: 0.4027  BEST VAL Loss: 0.4027  Val_Acc: 82.696

Epoch 37: Validation loss decreased (0.402726 --> 0.402296).  Saving model ...
	 Train_Loss: 0.4500 Train_Acc: 76.805 Val_Loss: 0.4023  BEST VAL Loss: 0.4023  Val_Acc: 82.609

Epoch 38: Validation loss decreased (0.402296 --> 0.401630).  Saving model ...
	 Train_Loss: 0.4494 Train_Acc: 76.989 Val_Loss: 0.4016  BEST VAL Loss: 0.4016  Val_Acc: 83.025

Epoch 39: Validation loss decreased (0.401630 --> 0.401159).  Saving model ...
	 Train_Loss: 0.4488 Train_Acc: 77.102 Val_Loss: 0.4012  BEST VAL Loss: 0.4012  Val_Acc: 82.227

Epoch 40: Validation loss decreased (0.401159 --> 0.400748).  Saving model ...
	 Train_Loss: 0.4483 Train_Acc: 77.044 Val_Loss: 0.4007  BEST VAL Loss: 0.4007  Val_Acc: 82.118

Epoch 41: Validation loss decreased (0.400748 --> 0.400546).  Saving model ...
	 Train_Loss: 0.4477 Train_Acc: 76.940 Val_Loss: 0.4005  BEST VAL Loss: 0.4005  Val_Acc: 82.956

Epoch 42: Validation loss decreased (0.400546 --> 0.400151).  Saving model ...
	 Train_Loss: 0.4472 Train_Acc: 76.977 Val_Loss: 0.4002  BEST VAL Loss: 0.4002  Val_Acc: 82.199

Epoch 43: Validation loss decreased (0.400151 --> 0.399751).  Saving model ...
	 Train_Loss: 0.4467 Train_Acc: 76.999 Val_Loss: 0.3998  BEST VAL Loss: 0.3998  Val_Acc: 82.857

Epoch 44: Validation loss decreased (0.399751 --> 0.399240).  Saving model ...
	 Train_Loss: 0.4462 Train_Acc: 77.255 Val_Loss: 0.3992  BEST VAL Loss: 0.3992  Val_Acc: 82.545

Epoch 45: Validation loss decreased (0.399240 --> 0.398804).  Saving model ...
	 Train_Loss: 0.4457 Train_Acc: 77.090 Val_Loss: 0.3988  BEST VAL Loss: 0.3988  Val_Acc: 82.308

Epoch 46: Validation loss decreased (0.398804 --> 0.398297).  Saving model ...
	 Train_Loss: 0.4452 Train_Acc: 77.078 Val_Loss: 0.3983  BEST VAL Loss: 0.3983  Val_Acc: 82.621

Epoch 47: Validation loss decreased (0.398297 --> 0.397715).  Saving model ...
	 Train_Loss: 0.4448 Train_Acc: 77.044 Val_Loss: 0.3977  BEST VAL Loss: 0.3977  Val_Acc: 82.730

Epoch 48: Validation loss decreased (0.397715 --> 0.397313).  Saving model ...
	 Train_Loss: 0.4443 Train_Acc: 77.037 Val_Loss: 0.3973  BEST VAL Loss: 0.3973  Val_Acc: 82.499

Epoch 49: Validation loss decreased (0.397313 --> 0.396978).  Saving model ...
	 Train_Loss: 0.4439 Train_Acc: 77.143 Val_Loss: 0.3970  BEST VAL Loss: 0.3970  Val_Acc: 82.083

Epoch 50: Validation loss decreased (0.396978 --> 0.396520).  Saving model ...
	 Train_Loss: 0.4434 Train_Acc: 77.075 Val_Loss: 0.3965  BEST VAL Loss: 0.3965  Val_Acc: 82.464

Epoch 51: Validation loss decreased (0.396520 --> 0.396141).  Saving model ...
	 Train_Loss: 0.4430 Train_Acc: 77.084 Val_Loss: 0.3961  BEST VAL Loss: 0.3961  Val_Acc: 82.933

Epoch 52: Validation loss decreased (0.396141 --> 0.395788).  Saving model ...
	 Train_Loss: 0.4426 Train_Acc: 77.019 Val_Loss: 0.3958  BEST VAL Loss: 0.3958  Val_Acc: 82.170

Epoch 53: Validation loss decreased (0.395788 --> 0.395611).  Saving model ...
	 Train_Loss: 0.4422 Train_Acc: 77.066 Val_Loss: 0.3956  BEST VAL Loss: 0.3956  Val_Acc: 82.118

Epoch 54: Validation loss decreased (0.395611 --> 0.395329).  Saving model ...
	 Train_Loss: 0.4419 Train_Acc: 77.031 Val_Loss: 0.3953  BEST VAL Loss: 0.3953  Val_Acc: 82.476

Epoch 55: Validation loss decreased (0.395329 --> 0.395000).  Saving model ...
	 Train_Loss: 0.4415 Train_Acc: 77.036 Val_Loss: 0.3950  BEST VAL Loss: 0.3950  Val_Acc: 82.886

Epoch 56: Validation loss decreased (0.395000 --> 0.394612).  Saving model ...
	 Train_Loss: 0.4411 Train_Acc: 77.277 Val_Loss: 0.3946  BEST VAL Loss: 0.3946  Val_Acc: 82.869

Epoch 57: Validation loss decreased (0.394612 --> 0.394308).  Saving model ...
	 Train_Loss: 0.4407 Train_Acc: 77.174 Val_Loss: 0.3943  BEST VAL Loss: 0.3943  Val_Acc: 82.470

Epoch 58: Validation loss decreased (0.394308 --> 0.394068).  Saving model ...
	 Train_Loss: 0.4403 Train_Acc: 77.166 Val_Loss: 0.3941  BEST VAL Loss: 0.3941  Val_Acc: 82.782

Epoch 59: Validation loss decreased (0.394068 --> 0.393790).  Saving model ...
	 Train_Loss: 0.4400 Train_Acc: 77.105 Val_Loss: 0.3938  BEST VAL Loss: 0.3938  Val_Acc: 82.447

Epoch 60: Validation loss decreased (0.393790 --> 0.393576).  Saving model ...
	 Train_Loss: 0.4397 Train_Acc: 77.030 Val_Loss: 0.3936  BEST VAL Loss: 0.3936  Val_Acc: 82.869

Epoch 61: Validation loss decreased (0.393576 --> 0.393360).  Saving model ...
	 Train_Loss: 0.4394 Train_Acc: 77.335 Val_Loss: 0.3934  BEST VAL Loss: 0.3934  Val_Acc: 83.042

Epoch 62: Validation loss decreased (0.393360 --> 0.393050).  Saving model ...
	 Train_Loss: 0.4390 Train_Acc: 77.334 Val_Loss: 0.3931  BEST VAL Loss: 0.3931  Val_Acc: 83.083

Epoch 63: Validation loss decreased (0.393050 --> 0.392686).  Saving model ...
	 Train_Loss: 0.4387 Train_Acc: 77.349 Val_Loss: 0.3927  BEST VAL Loss: 0.3927  Val_Acc: 82.881

Epoch 64: Validation loss decreased (0.392686 --> 0.392441).  Saving model ...
	 Train_Loss: 0.4384 Train_Acc: 77.040 Val_Loss: 0.3924  BEST VAL Loss: 0.3924  Val_Acc: 82.511

Epoch 65: Validation loss decreased (0.392441 --> 0.392043).  Saving model ...
	 Train_Loss: 0.4381 Train_Acc: 77.181 Val_Loss: 0.3920  BEST VAL Loss: 0.3920  Val_Acc: 82.551

Epoch 66: Validation loss decreased (0.392043 --> 0.391736).  Saving model ...
	 Train_Loss: 0.4378 Train_Acc: 77.312 Val_Loss: 0.3917  BEST VAL Loss: 0.3917  Val_Acc: 82.649

Epoch 67: Validation loss decreased (0.391736 --> 0.391605).  Saving model ...
	 Train_Loss: 0.4375 Train_Acc: 77.310 Val_Loss: 0.3916  BEST VAL Loss: 0.3916  Val_Acc: 81.927

Epoch 68: Validation loss decreased (0.391605 --> 0.391314).  Saving model ...
	 Train_Loss: 0.4372 Train_Acc: 77.228 Val_Loss: 0.3913  BEST VAL Loss: 0.3913  Val_Acc: 82.563

Epoch 69: Validation loss decreased (0.391314 --> 0.390972).  Saving model ...
	 Train_Loss: 0.4369 Train_Acc: 77.134 Val_Loss: 0.3910  BEST VAL Loss: 0.3910  Val_Acc: 82.944

Epoch 70: Validation loss decreased (0.390972 --> 0.390703).  Saving model ...
	 Train_Loss: 0.4366 Train_Acc: 77.147 Val_Loss: 0.3907  BEST VAL Loss: 0.3907  Val_Acc: 82.869

Epoch 71: Validation loss decreased (0.390703 --> 0.390533).  Saving model ...
	 Train_Loss: 0.4363 Train_Acc: 77.358 Val_Loss: 0.3905  BEST VAL Loss: 0.3905  Val_Acc: 82.424

Epoch 72: Validation loss decreased (0.390533 --> 0.390226).  Saving model ...
	 Train_Loss: 0.4361 Train_Acc: 77.250 Val_Loss: 0.3902  BEST VAL Loss: 0.3902  Val_Acc: 82.898

Epoch 73: Validation loss decreased (0.390226 --> 0.390082).  Saving model ...
	 Train_Loss: 0.4358 Train_Acc: 77.125 Val_Loss: 0.3901  BEST VAL Loss: 0.3901  Val_Acc: 83.135

Epoch 74: Validation loss decreased (0.390082 --> 0.389804).  Saving model ...
	 Train_Loss: 0.4355 Train_Acc: 77.476 Val_Loss: 0.3898  BEST VAL Loss: 0.3898  Val_Acc: 82.921

Epoch 75: Validation loss decreased (0.389804 --> 0.389564).  Saving model ...
	 Train_Loss: 0.4353 Train_Acc: 77.320 Val_Loss: 0.3896  BEST VAL Loss: 0.3896  Val_Acc: 82.811

Epoch 76: Validation loss decreased (0.389564 --> 0.389315).  Saving model ...
	 Train_Loss: 0.4350 Train_Acc: 77.436 Val_Loss: 0.3893  BEST VAL Loss: 0.3893  Val_Acc: 83.100

Epoch 77: Validation loss decreased (0.389315 --> 0.389097).  Saving model ...
	 Train_Loss: 0.4348 Train_Acc: 77.203 Val_Loss: 0.3891  BEST VAL Loss: 0.3891  Val_Acc: 82.736

Epoch 78: Validation loss decreased (0.389097 --> 0.388952).  Saving model ...
	 Train_Loss: 0.4346 Train_Acc: 77.312 Val_Loss: 0.3890  BEST VAL Loss: 0.3890  Val_Acc: 82.782

Epoch 79: Validation loss decreased (0.388952 --> 0.388702).  Saving model ...
	 Train_Loss: 0.4344 Train_Acc: 77.198 Val_Loss: 0.3887  BEST VAL Loss: 0.3887  Val_Acc: 82.985

Epoch 80: Validation loss decreased (0.388702 --> 0.388456).  Saving model ...
	 Train_Loss: 0.4341 Train_Acc: 77.284 Val_Loss: 0.3885  BEST VAL Loss: 0.3885  Val_Acc: 83.152

Epoch 81: Validation loss decreased (0.388456 --> 0.388216).  Saving model ...
	 Train_Loss: 0.4339 Train_Acc: 77.281 Val_Loss: 0.3882  BEST VAL Loss: 0.3882  Val_Acc: 82.944

Epoch 82: Validation loss decreased (0.388216 --> 0.388049).  Saving model ...
	 Train_Loss: 0.4337 Train_Acc: 77.243 Val_Loss: 0.3880  BEST VAL Loss: 0.3880  Val_Acc: 82.892

Epoch 83: Validation loss decreased (0.388049 --> 0.387891).  Saving model ...
	 Train_Loss: 0.4335 Train_Acc: 77.410 Val_Loss: 0.3879  BEST VAL Loss: 0.3879  Val_Acc: 83.112

Epoch 84: Validation loss decreased (0.387891 --> 0.387732).  Saving model ...
	 Train_Loss: 0.4333 Train_Acc: 77.330 Val_Loss: 0.3877  BEST VAL Loss: 0.3877  Val_Acc: 82.580

Epoch 85: Validation loss decreased (0.387732 --> 0.387484).  Saving model ...
	 Train_Loss: 0.4331 Train_Acc: 77.335 Val_Loss: 0.3875  BEST VAL Loss: 0.3875  Val_Acc: 82.915

Epoch 86: Validation loss decreased (0.387484 --> 0.387242).  Saving model ...
	 Train_Loss: 0.4329 Train_Acc: 77.401 Val_Loss: 0.3872  BEST VAL Loss: 0.3872  Val_Acc: 83.031

Epoch 87: Validation loss decreased (0.387242 --> 0.387033).  Saving model ...
	 Train_Loss: 0.4327 Train_Acc: 77.211 Val_Loss: 0.3870  BEST VAL Loss: 0.3870  Val_Acc: 82.990

Epoch 88: Validation loss decreased (0.387033 --> 0.386773).  Saving model ...
	 Train_Loss: 0.4325 Train_Acc: 77.174 Val_Loss: 0.3868  BEST VAL Loss: 0.3868  Val_Acc: 82.944

Epoch 89: Validation loss decreased (0.386773 --> 0.386616).  Saving model ...
	 Train_Loss: 0.4323 Train_Acc: 77.151 Val_Loss: 0.3866  BEST VAL Loss: 0.3866  Val_Acc: 82.927

Epoch 90: Validation loss decreased (0.386616 --> 0.386348).  Saving model ...
	 Train_Loss: 0.4321 Train_Acc: 77.361 Val_Loss: 0.3863  BEST VAL Loss: 0.3863  Val_Acc: 83.077

Epoch 91: Validation loss decreased (0.386348 --> 0.386200).  Saving model ...
	 Train_Loss: 0.4319 Train_Acc: 77.459 Val_Loss: 0.3862  BEST VAL Loss: 0.3862  Val_Acc: 82.667

Epoch 92: Validation loss decreased (0.386200 --> 0.386061).  Saving model ...
	 Train_Loss: 0.4317 Train_Acc: 77.490 Val_Loss: 0.3861  BEST VAL Loss: 0.3861  Val_Acc: 83.187

Epoch 93: Validation loss decreased (0.386061 --> 0.385884).  Saving model ...
	 Train_Loss: 0.4315 Train_Acc: 77.574 Val_Loss: 0.3859  BEST VAL Loss: 0.3859  Val_Acc: 83.048

Epoch 94: Validation loss decreased (0.385884 --> 0.385705).  Saving model ...
	 Train_Loss: 0.4313 Train_Acc: 77.279 Val_Loss: 0.3857  BEST VAL Loss: 0.3857  Val_Acc: 83.141

Epoch 95: Validation loss decreased (0.385705 --> 0.385512).  Saving model ...
	 Train_Loss: 0.4311 Train_Acc: 77.292 Val_Loss: 0.3855  BEST VAL Loss: 0.3855  Val_Acc: 83.407

Epoch 96: Validation loss decreased (0.385512 --> 0.385371).  Saving model ...
	 Train_Loss: 0.4310 Train_Acc: 77.341 Val_Loss: 0.3854  BEST VAL Loss: 0.3854  Val_Acc: 82.568

Epoch 97: Validation loss decreased (0.385371 --> 0.385224).  Saving model ...
	 Train_Loss: 0.4308 Train_Acc: 77.330 Val_Loss: 0.3852  BEST VAL Loss: 0.3852  Val_Acc: 82.973

Epoch 98: Validation loss decreased (0.385224 --> 0.385050).  Saving model ...
	 Train_Loss: 0.4306 Train_Acc: 77.302 Val_Loss: 0.3850  BEST VAL Loss: 0.3850  Val_Acc: 83.193

Epoch 99: Validation loss decreased (0.385050 --> 0.384827).  Saving model ...
	 Train_Loss: 0.4305 Train_Acc: 77.291 Val_Loss: 0.3848  BEST VAL Loss: 0.3848  Val_Acc: 83.089

Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.37      0.27      0.31     50422
           1       0.64      0.73      0.68     87993

    accuracy                           0.56    138415
   macro avg       0.50      0.50      0.50    138415
weighted avg       0.54      0.56      0.55    138415

Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.36      0.27      0.31      6303
           1       0.63      0.73      0.68     10999

    accuracy                           0.56     17302
   macro avg       0.50      0.50      0.49     17302
weighted avg       0.54      0.56      0.54     17302

Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.36      0.27      0.31      6303
           1       0.63      0.73      0.68     10999

    accuracy                           0.56     17302
   macro avg       0.50      0.50      0.49     17302
weighted avg       0.54      0.56      0.54     17302

              precision    recall  f1-score   support

           0       0.36      0.27      0.31      6303
           1       0.63      0.73      0.68     10999

    accuracy                           0.56     17302
   macro avg       0.50      0.50      0.49     17302
weighted avg       0.54      0.56      0.54     17302

Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.32      0.38     32887
           1       0.54      0.68      0.60     38465

    accuracy                           0.51     71352
   macro avg       0.50      0.50      0.49     71352
weighted avg       0.50      0.51      0.50     71352

              precision    recall  f1-score   support

           0       0.46      0.32      0.38     32887
           1       0.54      0.68      0.60     38465

    accuracy                           0.51     71352
   macro avg       0.50      0.50      0.49     71352
weighted avg       0.50      0.51      0.50     71352

completed
