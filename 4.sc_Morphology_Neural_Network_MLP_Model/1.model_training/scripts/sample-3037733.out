[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'eae04554'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '2fc3ce96'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'a6c3b850'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'af17f200'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_1.000_DMSO_0.025 treatment_name: DMSO_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_1.000_DMSO_0.025
TREATMENT_NAME: DMSO_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (51452, 1276)
Number of total missing values across all columns: 102904
Data Subset Is Off
Wells held out for testing: ['I14' 'M23']
Wells to use for training, validation, and testing ['B14' 'C14' 'B15' 'C15' 'J14' 'I15' 'J15' 'M18' 'M19' 'M22']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.592105).  Saving model ...
	 Train_Loss: 0.6578 Train_Acc: 66.932 Val_Loss: 0.5921  BEST VAL Loss: 0.5921  Val_Acc: 72.857

Epoch 1: Validation loss decreased (0.592105 --> 0.573790).  Saving model ...
	 Train_Loss: 0.6169 Train_Acc: 74.011 Val_Loss: 0.5738  BEST VAL Loss: 0.5738  Val_Acc: 74.431

Epoch 2: Validation loss decreased (0.573790 --> 0.559612).  Saving model ...
	 Train_Loss: 0.5946 Train_Acc: 75.194 Val_Loss: 0.5596  BEST VAL Loss: 0.5596  Val_Acc: 75.863

Epoch 3: Validation loss decreased (0.559612 --> 0.549614).  Saving model ...
	 Train_Loss: 0.5800 Train_Acc: 75.226 Val_Loss: 0.5496  BEST VAL Loss: 0.5496  Val_Acc: 75.839

Epoch 4: Validation loss decreased (0.549614 --> 0.541789).  Saving model ...
	 Train_Loss: 0.5681 Train_Acc: 76.045 Val_Loss: 0.5418  BEST VAL Loss: 0.5418  Val_Acc: 76.286

Epoch 5: Validation loss decreased (0.541789 --> 0.535057).  Saving model ...
	 Train_Loss: 0.5591 Train_Acc: 76.159 Val_Loss: 0.5351  BEST VAL Loss: 0.5351  Val_Acc: 77.178

Epoch 6: Validation loss decreased (0.535057 --> 0.529348).  Saving model ...
	 Train_Loss: 0.5520 Train_Acc: 76.467 Val_Loss: 0.5293  BEST VAL Loss: 0.5293  Val_Acc: 76.591

Epoch 7: Validation loss decreased (0.529348 --> 0.524056).  Saving model ...
	 Train_Loss: 0.5458 Train_Acc: 76.814 Val_Loss: 0.5241  BEST VAL Loss: 0.5241  Val_Acc: 77.483

Epoch 8: Validation loss decreased (0.524056 --> 0.519765).  Saving model ...
	 Train_Loss: 0.5407 Train_Acc: 77.090 Val_Loss: 0.5198  BEST VAL Loss: 0.5198  Val_Acc: 77.553

Epoch 9: Validation loss decreased (0.519765 --> 0.516040).  Saving model ...
	 Train_Loss: 0.5361 Train_Acc: 77.398 Val_Loss: 0.5160  BEST VAL Loss: 0.5160  Val_Acc: 77.953

Epoch 10: Validation loss decreased (0.516040 --> 0.512679).  Saving model ...
	 Train_Loss: 0.5321 Train_Acc: 77.700 Val_Loss: 0.5127  BEST VAL Loss: 0.5127  Val_Acc: 77.882

Epoch 11: Validation loss decreased (0.512679 --> 0.509618).  Saving model ...
	 Train_Loss: 0.5287 Train_Acc: 77.709 Val_Loss: 0.5096  BEST VAL Loss: 0.5096  Val_Acc: 78.117

Epoch 12: Validation loss decreased (0.509618 --> 0.507182).  Saving model ...
	 Train_Loss: 0.5256 Train_Acc: 77.603 Val_Loss: 0.5072  BEST VAL Loss: 0.5072  Val_Acc: 78.164

Epoch 13: Validation loss decreased (0.507182 --> 0.505083).  Saving model ...
	 Train_Loss: 0.5229 Train_Acc: 77.979 Val_Loss: 0.5051  BEST VAL Loss: 0.5051  Val_Acc: 78.211

Epoch 14: Validation loss decreased (0.505083 --> 0.502827).  Saving model ...
	 Train_Loss: 0.5203 Train_Acc: 77.991 Val_Loss: 0.5028  BEST VAL Loss: 0.5028  Val_Acc: 78.493

Epoch 15: Validation loss decreased (0.502827 --> 0.501148).  Saving model ...
	 Train_Loss: 0.5180 Train_Acc: 77.964 Val_Loss: 0.5011  BEST VAL Loss: 0.5011  Val_Acc: 77.506

Epoch 16: Validation loss decreased (0.501148 --> 0.499602).  Saving model ...
	 Train_Loss: 0.5161 Train_Acc: 77.958 Val_Loss: 0.4996  BEST VAL Loss: 0.4996  Val_Acc: 77.694

Epoch 17: Validation loss decreased (0.499602 --> 0.498225).  Saving model ...
	 Train_Loss: 0.5143 Train_Acc: 77.997 Val_Loss: 0.4982  BEST VAL Loss: 0.4982  Val_Acc: 78.187

Epoch 18: Validation loss decreased (0.498225 --> 0.496838).  Saving model ...
	 Train_Loss: 0.5124 Train_Acc: 78.440 Val_Loss: 0.4968  BEST VAL Loss: 0.4968  Val_Acc: 78.234

Epoch 19: Validation loss decreased (0.496838 --> 0.495360).  Saving model ...
	 Train_Loss: 0.5107 Train_Acc: 78.135 Val_Loss: 0.4954  BEST VAL Loss: 0.4954  Val_Acc: 78.516

Epoch 20: Validation loss decreased (0.495360 --> 0.493995).  Saving model ...
	 Train_Loss: 0.5091 Train_Acc: 78.469 Val_Loss: 0.4940  BEST VAL Loss: 0.4940  Val_Acc: 78.704

Epoch 21: Validation loss decreased (0.493995 --> 0.492722).  Saving model ...
	 Train_Loss: 0.5075 Train_Acc: 78.660 Val_Loss: 0.4927  BEST VAL Loss: 0.4927  Val_Acc: 78.915

Epoch 22: Validation loss decreased (0.492722 --> 0.491542).  Saving model ...
	 Train_Loss: 0.5061 Train_Acc: 78.628 Val_Loss: 0.4915  BEST VAL Loss: 0.4915  Val_Acc: 79.103

Epoch 23: Validation loss decreased (0.491542 --> 0.490504).  Saving model ...
	 Train_Loss: 0.5047 Train_Acc: 78.827 Val_Loss: 0.4905  BEST VAL Loss: 0.4905  Val_Acc: 78.704

Epoch 24: Validation loss decreased (0.490504 --> 0.489406).  Saving model ...
	 Train_Loss: 0.5034 Train_Acc: 78.780 Val_Loss: 0.4894  BEST VAL Loss: 0.4894  Val_Acc: 78.939

Epoch 25: Validation loss decreased (0.489406 --> 0.488317).  Saving model ...
	 Train_Loss: 0.5022 Train_Acc: 78.983 Val_Loss: 0.4883  BEST VAL Loss: 0.4883  Val_Acc: 79.197

Epoch 26: Validation loss decreased (0.488317 --> 0.487289).  Saving model ...
	 Train_Loss: 0.5011 Train_Acc: 78.815 Val_Loss: 0.4873  BEST VAL Loss: 0.4873  Val_Acc: 79.291

Epoch 27: Validation loss decreased (0.487289 --> 0.486450).  Saving model ...
	 Train_Loss: 0.5001 Train_Acc: 78.898 Val_Loss: 0.4864  BEST VAL Loss: 0.4864  Val_Acc: 78.774

Epoch 28: Validation loss decreased (0.486450 --> 0.485593).  Saving model ...
	 Train_Loss: 0.4991 Train_Acc: 78.942 Val_Loss: 0.4856  BEST VAL Loss: 0.4856  Val_Acc: 79.127

Epoch 29: Validation loss decreased (0.485593 --> 0.484779).  Saving model ...
	 Train_Loss: 0.4981 Train_Acc: 79.270 Val_Loss: 0.4848  BEST VAL Loss: 0.4848  Val_Acc: 79.455

Epoch 30: Validation loss decreased (0.484779 --> 0.484018).  Saving model ...
	 Train_Loss: 0.4972 Train_Acc: 79.018 Val_Loss: 0.4840  BEST VAL Loss: 0.4840  Val_Acc: 79.455

Epoch 31: Validation loss decreased (0.484018 --> 0.483330).  Saving model ...
	 Train_Loss: 0.4964 Train_Acc: 79.047 Val_Loss: 0.4833  BEST VAL Loss: 0.4833  Val_Acc: 79.408

Epoch 32: Validation loss decreased (0.483330 --> 0.482745).  Saving model ...
	 Train_Loss: 0.4957 Train_Acc: 78.719 Val_Loss: 0.4827  BEST VAL Loss: 0.4827  Val_Acc: 79.267

Epoch 33: Validation loss decreased (0.482745 --> 0.482033).  Saving model ...
	 Train_Loss: 0.4949 Train_Acc: 79.200 Val_Loss: 0.4820  BEST VAL Loss: 0.4820  Val_Acc: 78.986

Epoch 34: Validation loss decreased (0.482033 --> 0.481298).  Saving model ...
	 Train_Loss: 0.4940 Train_Acc: 79.323 Val_Loss: 0.4813  BEST VAL Loss: 0.4813  Val_Acc: 79.761

Epoch 35: Validation loss decreased (0.481298 --> 0.480581).  Saving model ...
	 Train_Loss: 0.4932 Train_Acc: 79.479 Val_Loss: 0.4806  BEST VAL Loss: 0.4806  Val_Acc: 79.643

Epoch 36: Validation loss decreased (0.480581 --> 0.480024).  Saving model ...
	 Train_Loss: 0.4925 Train_Acc: 79.270 Val_Loss: 0.4800  BEST VAL Loss: 0.4800  Val_Acc: 79.314

Epoch 37: Validation loss decreased (0.480024 --> 0.479350).  Saving model ...
	 Train_Loss: 0.4918 Train_Acc: 79.631 Val_Loss: 0.4794  BEST VAL Loss: 0.4794  Val_Acc: 79.526

Epoch 38: Validation loss decreased (0.479350 --> 0.478852).  Saving model ...
	 Train_Loss: 0.4911 Train_Acc: 79.593 Val_Loss: 0.4789  BEST VAL Loss: 0.4789  Val_Acc: 79.479

Epoch 39: Validation loss decreased (0.478852 --> 0.478309).  Saving model ...
	 Train_Loss: 0.4903 Train_Acc: 79.693 Val_Loss: 0.4783  BEST VAL Loss: 0.4783  Val_Acc: 79.033

Epoch 40: Validation loss decreased (0.478309 --> 0.477806).  Saving model ...
	 Train_Loss: 0.4897 Train_Acc: 79.285 Val_Loss: 0.4778  BEST VAL Loss: 0.4778  Val_Acc: 79.526

Epoch 41: Validation loss decreased (0.477806 --> 0.477338).  Saving model ...
	 Train_Loss: 0.4891 Train_Acc: 79.637 Val_Loss: 0.4773  BEST VAL Loss: 0.4773  Val_Acc: 79.197

Epoch 42: Validation loss decreased (0.477338 --> 0.476813).  Saving model ...
	 Train_Loss: 0.4885 Train_Acc: 79.458 Val_Loss: 0.4768  BEST VAL Loss: 0.4768  Val_Acc: 79.455

Epoch 43: Validation loss decreased (0.476813 --> 0.476273).  Saving model ...
	 Train_Loss: 0.4879 Train_Acc: 79.587 Val_Loss: 0.4763  BEST VAL Loss: 0.4763  Val_Acc: 79.878

Epoch 44: Validation loss decreased (0.476273 --> 0.475765).  Saving model ...
	 Train_Loss: 0.4873 Train_Acc: 79.781 Val_Loss: 0.4758  BEST VAL Loss: 0.4758  Val_Acc: 79.549

Epoch 45: Validation loss decreased (0.475765 --> 0.475328).  Saving model ...
	 Train_Loss: 0.4867 Train_Acc: 79.807 Val_Loss: 0.4753  BEST VAL Loss: 0.4753  Val_Acc: 79.690

Epoch 46: Validation loss decreased (0.475328 --> 0.474889).  Saving model ...
	 Train_Loss: 0.4863 Train_Acc: 79.473 Val_Loss: 0.4749  BEST VAL Loss: 0.4749  Val_Acc: 79.502

Epoch 47: Validation loss decreased (0.474889 --> 0.474507).  Saving model ...
	 Train_Loss: 0.4858 Train_Acc: 79.716 Val_Loss: 0.4745  BEST VAL Loss: 0.4745  Val_Acc: 79.784

Epoch 48: Validation loss decreased (0.474507 --> 0.474185).  Saving model ...
	 Train_Loss: 0.4853 Train_Acc: 79.705 Val_Loss: 0.4742  BEST VAL Loss: 0.4742  Val_Acc: 79.690

Epoch 49: Validation loss decreased (0.474185 --> 0.473765).  Saving model ...
	 Train_Loss: 0.4848 Train_Acc: 79.992 Val_Loss: 0.4738  BEST VAL Loss: 0.4738  Val_Acc: 79.502

Epoch 50: Validation loss decreased (0.473765 --> 0.473420).  Saving model ...
	 Train_Loss: 0.4843 Train_Acc: 79.722 Val_Loss: 0.4734  BEST VAL Loss: 0.4734  Val_Acc: 79.596

Epoch 51: Validation loss decreased (0.473420 --> 0.473006).  Saving model ...
	 Train_Loss: 0.4838 Train_Acc: 80.033 Val_Loss: 0.4730  BEST VAL Loss: 0.4730  Val_Acc: 79.643

Epoch 52: Validation loss decreased (0.473006 --> 0.472759).  Saving model ...
	 Train_Loss: 0.4834 Train_Acc: 80.095 Val_Loss: 0.4728  BEST VAL Loss: 0.4728  Val_Acc: 79.526

Epoch 53: Validation loss decreased (0.472759 --> 0.472383).  Saving model ...
	 Train_Loss: 0.4830 Train_Acc: 80.060 Val_Loss: 0.4724  BEST VAL Loss: 0.4724  Val_Acc: 79.901

Epoch 54: Validation loss decreased (0.472383 --> 0.472074).  Saving model ...
	 Train_Loss: 0.4825 Train_Acc: 79.998 Val_Loss: 0.4721  BEST VAL Loss: 0.4721  Val_Acc: 79.878

Epoch 55: Validation loss decreased (0.472074 --> 0.471673).  Saving model ...
	 Train_Loss: 0.4821 Train_Acc: 79.737 Val_Loss: 0.4717  BEST VAL Loss: 0.4717  Val_Acc: 79.784

Epoch 56: Validation loss decreased (0.471673 --> 0.471322).  Saving model ...
	 Train_Loss: 0.4816 Train_Acc: 80.488 Val_Loss: 0.4713  BEST VAL Loss: 0.4713  Val_Acc: 80.019

Epoch 57: Validation loss decreased (0.471322 --> 0.470947).  Saving model ...
	 Train_Loss: 0.4812 Train_Acc: 80.236 Val_Loss: 0.4709  BEST VAL Loss: 0.4709  Val_Acc: 79.761

Epoch 58: Validation loss decreased (0.470947 --> 0.470682).  Saving model ...
	 Train_Loss: 0.4808 Train_Acc: 79.922 Val_Loss: 0.4707  BEST VAL Loss: 0.4707  Val_Acc: 79.714

Epoch 59: Validation loss decreased (0.470682 --> 0.470415).  Saving model ...
	 Train_Loss: 0.4804 Train_Acc: 80.154 Val_Loss: 0.4704  BEST VAL Loss: 0.4704  Val_Acc: 79.643

Epoch 60: Validation loss decreased (0.470415 --> 0.470167).  Saving model ...
	 Train_Loss: 0.4800 Train_Acc: 80.251 Val_Loss: 0.4702  BEST VAL Loss: 0.4702  Val_Acc: 79.385

Epoch 61: Validation loss decreased (0.470167 --> 0.469844).  Saving model ...
	 Train_Loss: 0.4797 Train_Acc: 79.913 Val_Loss: 0.4698  BEST VAL Loss: 0.4698  Val_Acc: 79.761

Epoch 62: Validation loss decreased (0.469844 --> 0.469625).  Saving model ...
	 Train_Loss: 0.4794 Train_Acc: 80.060 Val_Loss: 0.4696  BEST VAL Loss: 0.4696  Val_Acc: 79.690

Epoch 63: Validation loss decreased (0.469625 --> 0.469329).  Saving model ...
	 Train_Loss: 0.4791 Train_Acc: 80.218 Val_Loss: 0.4693  BEST VAL Loss: 0.4693  Val_Acc: 80.136

Epoch 64: Validation loss decreased (0.469329 --> 0.468992).  Saving model ...
	 Train_Loss: 0.4787 Train_Acc: 80.122 Val_Loss: 0.4690  BEST VAL Loss: 0.4690  Val_Acc: 79.901

Epoch 65: Validation loss decreased (0.468992 --> 0.468752).  Saving model ...
	 Train_Loss: 0.4784 Train_Acc: 80.224 Val_Loss: 0.4688  BEST VAL Loss: 0.4688  Val_Acc: 79.807

Epoch 66: Validation loss decreased (0.468752 --> 0.468465).  Saving model ...
	 Train_Loss: 0.4780 Train_Acc: 80.233 Val_Loss: 0.4685  BEST VAL Loss: 0.4685  Val_Acc: 80.160

Epoch 67: Validation loss decreased (0.468465 --> 0.468171).  Saving model ...
	 Train_Loss: 0.4776 Train_Acc: 80.462 Val_Loss: 0.4682  BEST VAL Loss: 0.4682  Val_Acc: 80.113

Epoch 68: Validation loss decreased (0.468171 --> 0.467853).  Saving model ...
	 Train_Loss: 0.4773 Train_Acc: 80.342 Val_Loss: 0.4679  BEST VAL Loss: 0.4679  Val_Acc: 80.254

Epoch 69: Validation loss decreased (0.467853 --> 0.467620).  Saving model ...
	 Train_Loss: 0.4770 Train_Acc: 80.195 Val_Loss: 0.4676  BEST VAL Loss: 0.4676  Val_Acc: 79.878

Epoch 70: Validation loss decreased (0.467620 --> 0.467347).  Saving model ...
	 Train_Loss: 0.4766 Train_Acc: 80.556 Val_Loss: 0.4673  BEST VAL Loss: 0.4673  Val_Acc: 79.737

Epoch 71: Validation loss decreased (0.467347 --> 0.467064).  Saving model ...
	 Train_Loss: 0.4763 Train_Acc: 80.306 Val_Loss: 0.4671  BEST VAL Loss: 0.4671  Val_Acc: 79.948

Epoch 72: Validation loss decreased (0.467064 --> 0.466801).  Saving model ...
	 Train_Loss: 0.4760 Train_Acc: 80.160 Val_Loss: 0.4668  BEST VAL Loss: 0.4668  Val_Acc: 80.019

Epoch 73: Validation loss decreased (0.466801 --> 0.466562).  Saving model ...
	 Train_Loss: 0.4757 Train_Acc: 80.245 Val_Loss: 0.4666  BEST VAL Loss: 0.4666  Val_Acc: 79.995

Epoch 74: Validation loss decreased (0.466562 --> 0.466320).  Saving model ...
	 Train_Loss: 0.4754 Train_Acc: 80.083 Val_Loss: 0.4663  BEST VAL Loss: 0.4663  Val_Acc: 79.737

Epoch 75: Validation loss decreased (0.466320 --> 0.466117).  Saving model ...
	 Train_Loss: 0.4751 Train_Acc: 80.377 Val_Loss: 0.4661  BEST VAL Loss: 0.4661  Val_Acc: 79.901

Epoch 76: Validation loss decreased (0.466117 --> 0.465914).  Saving model ...
	 Train_Loss: 0.4748 Train_Acc: 80.280 Val_Loss: 0.4659  BEST VAL Loss: 0.4659  Val_Acc: 80.113

Epoch 77: Validation loss decreased (0.465914 --> 0.465672).  Saving model ...
	 Train_Loss: 0.4745 Train_Acc: 80.383 Val_Loss: 0.4657  BEST VAL Loss: 0.4657  Val_Acc: 80.183

Epoch 78: Validation loss decreased (0.465672 --> 0.465476).  Saving model ...
	 Train_Loss: 0.4743 Train_Acc: 80.427 Val_Loss: 0.4655  BEST VAL Loss: 0.4655  Val_Acc: 80.113

Epoch 79: Validation loss decreased (0.465476 --> 0.465273).  Saving model ...
	 Train_Loss: 0.4740 Train_Acc: 80.623 Val_Loss: 0.4653  BEST VAL Loss: 0.4653  Val_Acc: 80.089

Epoch 80: Validation loss decreased (0.465273 --> 0.465050).  Saving model ...
	 Train_Loss: 0.4737 Train_Acc: 80.741 Val_Loss: 0.4650  BEST VAL Loss: 0.4650  Val_Acc: 80.230

Epoch 81: Validation loss decreased (0.465050 --> 0.464831).  Saving model ...
	 Train_Loss: 0.4734 Train_Acc: 80.286 Val_Loss: 0.4648  BEST VAL Loss: 0.4648  Val_Acc: 80.066

Epoch 82: Validation loss decreased (0.464831 --> 0.464636).  Saving model ...
	 Train_Loss: 0.4731 Train_Acc: 80.483 Val_Loss: 0.4646  BEST VAL Loss: 0.4646  Val_Acc: 80.254

Epoch 83: Validation loss decreased (0.464636 --> 0.464453).  Saving model ...
	 Train_Loss: 0.4729 Train_Acc: 80.714 Val_Loss: 0.4645  BEST VAL Loss: 0.4645  Val_Acc: 80.113

Epoch 84: Validation loss decreased (0.464453 --> 0.464263).  Saving model ...
	 Train_Loss: 0.4726 Train_Acc: 80.538 Val_Loss: 0.4643  BEST VAL Loss: 0.4643  Val_Acc: 80.207

Epoch 85: Validation loss decreased (0.464263 --> 0.464108).  Saving model ...
	 Train_Loss: 0.4724 Train_Acc: 80.521 Val_Loss: 0.4641  BEST VAL Loss: 0.4641  Val_Acc: 80.113

Epoch 86: Validation loss decreased (0.464108 --> 0.463881).  Saving model ...
	 Train_Loss: 0.4722 Train_Acc: 80.538 Val_Loss: 0.4639  BEST VAL Loss: 0.4639  Val_Acc: 80.418

Epoch 87: Validation loss decreased (0.463881 --> 0.463738).  Saving model ...
	 Train_Loss: 0.4719 Train_Acc: 80.438 Val_Loss: 0.4637  BEST VAL Loss: 0.4637  Val_Acc: 80.042

Epoch 88: Validation loss decreased (0.463738 --> 0.463571).  Saving model ...
	 Train_Loss: 0.4717 Train_Acc: 80.932 Val_Loss: 0.4636  BEST VAL Loss: 0.4636  Val_Acc: 80.301

Epoch 89: Validation loss decreased (0.463571 --> 0.463370).  Saving model ...
	 Train_Loss: 0.4714 Train_Acc: 80.409 Val_Loss: 0.4634  BEST VAL Loss: 0.4634  Val_Acc: 80.488

Epoch 90: Validation loss decreased (0.463370 --> 0.463230).  Saving model ...
	 Train_Loss: 0.4712 Train_Acc: 80.606 Val_Loss: 0.4632  BEST VAL Loss: 0.4632  Val_Acc: 80.394

Epoch 91: Validation loss decreased (0.463230 --> 0.463108).  Saving model ...
	 Train_Loss: 0.4709 Train_Acc: 80.708 Val_Loss: 0.4631  BEST VAL Loss: 0.4631  Val_Acc: 79.972

Epoch 92: Validation loss decreased (0.463108 --> 0.462935).  Saving model ...
	 Train_Loss: 0.4707 Train_Acc: 80.635 Val_Loss: 0.4629  BEST VAL Loss: 0.4629  Val_Acc: 80.559

Epoch 93: Validation loss decreased (0.462935 --> 0.462772).  Saving model ...
	 Train_Loss: 0.4705 Train_Acc: 80.835 Val_Loss: 0.4628  BEST VAL Loss: 0.4628  Val_Acc: 80.207

Epoch 94: Validation loss decreased (0.462772 --> 0.462597).  Saving model ...
	 Train_Loss: 0.4703 Train_Acc: 80.949 Val_Loss: 0.4626  BEST VAL Loss: 0.4626  Val_Acc: 80.629

Epoch 95: Validation loss decreased (0.462597 --> 0.462425).  Saving model ...
	 Train_Loss: 0.4700 Train_Acc: 80.964 Val_Loss: 0.4624  BEST VAL Loss: 0.4624  Val_Acc: 80.535

Epoch 96: Validation loss decreased (0.462425 --> 0.462271).  Saving model ...
	 Train_Loss: 0.4698 Train_Acc: 80.785 Val_Loss: 0.4623  BEST VAL Loss: 0.4623  Val_Acc: 80.136

Epoch 97: Validation loss decreased (0.462271 --> 0.462108).  Saving model ...
	 Train_Loss: 0.4695 Train_Acc: 80.973 Val_Loss: 0.4621  BEST VAL Loss: 0.4621  Val_Acc: 80.535

Epoch 98: Validation loss decreased (0.462108 --> 0.461968).  Saving model ...
	 Train_Loss: 0.4693 Train_Acc: 80.776 Val_Loss: 0.4620  BEST VAL Loss: 0.4620  Val_Acc: 80.066

Epoch 99: Validation loss decreased (0.461968 --> 0.461851).  Saving model ...
	 Train_Loss: 0.4691 Train_Acc: 80.788 Val_Loss: 0.4619  BEST VAL Loss: 0.4619  Val_Acc: 80.230

Flagellin_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.84      0.95      0.89     24644
           1       0.80      0.52      0.63      9428

    accuracy                           0.83     34072
   macro avg       0.82      0.74      0.76     34072
weighted avg       0.83      0.83      0.82     34072

Flagellin_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.82      0.93      0.87      3081
           1       0.72      0.46      0.56      1178

    accuracy                           0.80      4259
   macro avg       0.77      0.70      0.72      4259
weighted avg       0.79      0.80      0.79      4259

Flagellin_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.82      0.94      0.87      3081
           1       0.74      0.46      0.57      1178

    accuracy                           0.80      4259
   macro avg       0.78      0.70      0.72      4259
weighted avg       0.80      0.80      0.79      4259

              precision    recall  f1-score   support

           0       0.82      0.94      0.87      3081
           1       0.74      0.46      0.57      1178

    accuracy                           0.80      4259
   macro avg       0.78      0.70      0.72      4259
weighted avg       0.80      0.80      0.79      4259

Flagellin_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.76      0.86      0.81      4837
           1       0.80      0.66      0.73      4025

    accuracy                           0.77      8862
   macro avg       0.78      0.76      0.77      8862
weighted avg       0.78      0.77      0.77      8862

              precision    recall  f1-score   support

           0       0.76      0.86      0.81      4837
           1       0.80      0.66      0.73      4025

    accuracy                           0.77      8862
   macro avg       0.78      0.76      0.77      8862
weighted avg       0.78      0.77      0.77      8862

completed
