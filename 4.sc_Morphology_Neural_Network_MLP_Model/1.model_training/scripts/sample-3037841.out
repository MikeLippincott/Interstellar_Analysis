[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'a270b09c'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'bfd14df1'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '52c23a17'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'da414ae7'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_0.010_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_0.010_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (30787, 1276)
Number of total missing values across all columns: 61574
Data Subset Is Off
Wells held out for testing: ['B16' 'L22']
Wells to use for training, validation, and testing ['B17' 'B20' 'B21' 'L18' 'L19' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.663464).  Saving model ...
	 Train_Loss: 0.6880 Train_Acc: 54.842 Val_Loss: 0.6635  BEST VAL Loss: 0.6635  Val_Acc: 60.635

Epoch 1: Validation loss decreased (0.663464 --> 0.650872).  Saving model ...
	 Train_Loss: 0.6724 Train_Acc: 61.861 Val_Loss: 0.6509  BEST VAL Loss: 0.6509  Val_Acc: 64.519

Epoch 2: Validation loss decreased (0.650872 --> 0.639420).  Saving model ...
	 Train_Loss: 0.6601 Train_Acc: 64.741 Val_Loss: 0.6394  BEST VAL Loss: 0.6394  Val_Acc: 65.225

Epoch 3: Validation loss decreased (0.639420 --> 0.637394).  Saving model ...
	 Train_Loss: 0.6530 Train_Acc: 65.784 Val_Loss: 0.6374  BEST VAL Loss: 0.6374  Val_Acc: 66.064

Epoch 4: Validation loss decreased (0.637394 --> 0.632391).  Saving model ...
	 Train_Loss: 0.6465 Train_Acc: 66.126 Val_Loss: 0.6324  BEST VAL Loss: 0.6324  Val_Acc: 66.240

Epoch 5: Validation loss decreased (0.632391 --> 0.630583).  Saving model ...
	 Train_Loss: 0.6412 Train_Acc: 67.169 Val_Loss: 0.6306  BEST VAL Loss: 0.6306  Val_Acc: 66.064

Epoch 6: Validation loss decreased (0.630583 --> 0.628120).  Saving model ...
	 Train_Loss: 0.6372 Train_Acc: 67.169 Val_Loss: 0.6281  BEST VAL Loss: 0.6281  Val_Acc: 67.211

Epoch 7: Validation loss decreased (0.628120 --> 0.624388).  Saving model ...
	 Train_Loss: 0.6325 Train_Acc: 68.377 Val_Loss: 0.6244  BEST VAL Loss: 0.6244  Val_Acc: 67.123

Epoch 8: Validation loss decreased (0.624388 --> 0.621798).  Saving model ...
	 Train_Loss: 0.6282 Train_Acc: 68.824 Val_Loss: 0.6218  BEST VAL Loss: 0.6218  Val_Acc: 66.814

Epoch 9: Validation loss decreased (0.621798 --> 0.621269).  Saving model ...
	 Train_Loss: 0.6254 Train_Acc: 68.896 Val_Loss: 0.6213  BEST VAL Loss: 0.6213  Val_Acc: 66.770

Epoch 10: Validation loss decreased (0.621269 --> 0.619245).  Saving model ...
	 Train_Loss: 0.6224 Train_Acc: 69.530 Val_Loss: 0.6192  BEST VAL Loss: 0.6192  Val_Acc: 67.829

Epoch 11: Validation loss decreased (0.619245 --> 0.618227).  Saving model ...
	 Train_Loss: 0.6203 Train_Acc: 68.725 Val_Loss: 0.6182  BEST VAL Loss: 0.6182  Val_Acc: 67.608

Epoch 12: Validation loss decreased (0.618227 --> 0.617614).  Saving model ...
	 Train_Loss: 0.6181 Train_Acc: 69.541 Val_Loss: 0.6176  BEST VAL Loss: 0.6176  Val_Acc: 67.829

Epoch 13: Validation loss decreased (0.617614 --> 0.616890).  Saving model ...
	 Train_Loss: 0.6155 Train_Acc: 70.496 Val_Loss: 0.6169  BEST VAL Loss: 0.6169  Val_Acc: 67.785

Epoch 14: Validation loss decreased (0.616890 --> 0.615565).  Saving model ...
	 Train_Loss: 0.6129 Train_Acc: 70.656 Val_Loss: 0.6156  BEST VAL Loss: 0.6156  Val_Acc: 68.844

Epoch 15: Validation loss decreased (0.615565 --> 0.614805).  Saving model ...
	 Train_Loss: 0.6113 Train_Acc: 69.812 Val_Loss: 0.6148  BEST VAL Loss: 0.6148  Val_Acc: 67.829

Epoch 16: Validation loss decreased (0.614805 --> 0.612465).  Saving model ...
	 Train_Loss: 0.6093 Train_Acc: 70.060 Val_Loss: 0.6125  BEST VAL Loss: 0.6125  Val_Acc: 68.711

Epoch 17: Validation loss decreased (0.612465 --> 0.611392).  Saving model ...
	 Train_Loss: 0.6073 Train_Acc: 71.086 Val_Loss: 0.6114  BEST VAL Loss: 0.6114  Val_Acc: 69.153

Epoch 18: Validation loss decreased (0.611392 --> 0.610099).  Saving model ...
	 Train_Loss: 0.6053 Train_Acc: 71.313 Val_Loss: 0.6101  BEST VAL Loss: 0.6101  Val_Acc: 69.241

Epoch 19: Validation loss decreased (0.610099 --> 0.609544).  Saving model ...
	 Train_Loss: 0.6031 Train_Acc: 71.898 Val_Loss: 0.6095  BEST VAL Loss: 0.6095  Val_Acc: 68.402

Epoch 20: Validation loss did not decrease
	 Train_Loss: 0.6015 Train_Acc: 71.633 Val_Loss: 0.6097  BEST VAL Loss: 0.6095  Val_Acc: 68.800

Epoch 21: Validation loss decreased (0.609544 --> 0.608300).  Saving model ...
	 Train_Loss: 0.5997 Train_Acc: 71.782 Val_Loss: 0.6083  BEST VAL Loss: 0.6083  Val_Acc: 68.844

Epoch 22: Validation loss decreased (0.608300 --> 0.606925).  Saving model ...
	 Train_Loss: 0.5981 Train_Acc: 71.550 Val_Loss: 0.6069  BEST VAL Loss: 0.6069  Val_Acc: 69.329

Epoch 23: Validation loss decreased (0.606925 --> 0.605858).  Saving model ...
	 Train_Loss: 0.5965 Train_Acc: 72.245 Val_Loss: 0.6059  BEST VAL Loss: 0.6059  Val_Acc: 69.109

Epoch 24: Validation loss decreased (0.605858 --> 0.605059).  Saving model ...
	 Train_Loss: 0.5949 Train_Acc: 72.295 Val_Loss: 0.6051  BEST VAL Loss: 0.6051  Val_Acc: 68.667

Epoch 25: Validation loss decreased (0.605059 --> 0.604386).  Saving model ...
	 Train_Loss: 0.5935 Train_Acc: 72.124 Val_Loss: 0.6044  BEST VAL Loss: 0.6044  Val_Acc: 68.756

Epoch 26: Validation loss decreased (0.604386 --> 0.603731).  Saving model ...
	 Train_Loss: 0.5919 Train_Acc: 72.935 Val_Loss: 0.6037  BEST VAL Loss: 0.6037  Val_Acc: 69.373

Epoch 27: Validation loss decreased (0.603731 --> 0.603042).  Saving model ...
	 Train_Loss: 0.5906 Train_Acc: 72.907 Val_Loss: 0.6030  BEST VAL Loss: 0.6030  Val_Acc: 68.800

Epoch 28: Validation loss decreased (0.603042 --> 0.602210).  Saving model ...
	 Train_Loss: 0.5892 Train_Acc: 73.321 Val_Loss: 0.6022  BEST VAL Loss: 0.6022  Val_Acc: 69.241

Epoch 29: Validation loss decreased (0.602210 --> 0.601334).  Saving model ...
	 Train_Loss: 0.5876 Train_Acc: 73.779 Val_Loss: 0.6013  BEST VAL Loss: 0.6013  Val_Acc: 69.241

Epoch 30: Validation loss decreased (0.601334 --> 0.600528).  Saving model ...
	 Train_Loss: 0.5862 Train_Acc: 73.746 Val_Loss: 0.6005  BEST VAL Loss: 0.6005  Val_Acc: 68.932

Epoch 31: Validation loss decreased (0.600528 --> 0.599950).  Saving model ...
	 Train_Loss: 0.5848 Train_Acc: 73.829 Val_Loss: 0.6000  BEST VAL Loss: 0.6000  Val_Acc: 69.285

Epoch 32: Validation loss decreased (0.599950 --> 0.599305).  Saving model ...
	 Train_Loss: 0.5836 Train_Acc: 73.768 Val_Loss: 0.5993  BEST VAL Loss: 0.5993  Val_Acc: 69.417

Epoch 33: Validation loss decreased (0.599305 --> 0.599167).  Saving model ...
	 Train_Loss: 0.5826 Train_Acc: 73.603 Val_Loss: 0.5992  BEST VAL Loss: 0.5992  Val_Acc: 68.623

Epoch 34: Validation loss decreased (0.599167 --> 0.598800).  Saving model ...
	 Train_Loss: 0.5814 Train_Acc: 74.099 Val_Loss: 0.5988  BEST VAL Loss: 0.5988  Val_Acc: 69.417

Epoch 35: Validation loss decreased (0.598800 --> 0.598219).  Saving model ...
	 Train_Loss: 0.5802 Train_Acc: 73.972 Val_Loss: 0.5982  BEST VAL Loss: 0.5982  Val_Acc: 68.888

Epoch 36: Validation loss decreased (0.598219 --> 0.597549).  Saving model ...
	 Train_Loss: 0.5790 Train_Acc: 74.331 Val_Loss: 0.5975  BEST VAL Loss: 0.5975  Val_Acc: 69.550

Epoch 37: Validation loss decreased (0.597549 --> 0.597010).  Saving model ...
	 Train_Loss: 0.5779 Train_Acc: 74.232 Val_Loss: 0.5970  BEST VAL Loss: 0.5970  Val_Acc: 70.741

Epoch 38: Validation loss decreased (0.597010 --> 0.596391).  Saving model ...
	 Train_Loss: 0.5770 Train_Acc: 73.156 Val_Loss: 0.5964  BEST VAL Loss: 0.5964  Val_Acc: 71.536

Epoch 39: Validation loss decreased (0.596391 --> 0.595708).  Saving model ...
	 Train_Loss: 0.5761 Train_Acc: 73.669 Val_Loss: 0.5957  BEST VAL Loss: 0.5957  Val_Acc: 70.124

Epoch 40: Validation loss decreased (0.595708 --> 0.595033).  Saving model ...
	 Train_Loss: 0.5753 Train_Acc: 73.713 Val_Loss: 0.5950  BEST VAL Loss: 0.5950  Val_Acc: 70.741

Epoch 41: Validation loss decreased (0.595033 --> 0.594400).  Saving model ...
	 Train_Loss: 0.5743 Train_Acc: 74.099 Val_Loss: 0.5944  BEST VAL Loss: 0.5944  Val_Acc: 70.168

Epoch 42: Validation loss decreased (0.594400 --> 0.594140).  Saving model ...
	 Train_Loss: 0.5734 Train_Acc: 74.325 Val_Loss: 0.5941  BEST VAL Loss: 0.5941  Val_Acc: 70.653

Epoch 43: Validation loss decreased (0.594140 --> 0.593367).  Saving model ...
	 Train_Loss: 0.5724 Train_Acc: 74.651 Val_Loss: 0.5934  BEST VAL Loss: 0.5934  Val_Acc: 71.183

Epoch 44: Validation loss decreased (0.593367 --> 0.593213).  Saving model ...
	 Train_Loss: 0.5716 Train_Acc: 74.546 Val_Loss: 0.5932  BEST VAL Loss: 0.5932  Val_Acc: 70.079

Epoch 45: Validation loss decreased (0.593213 --> 0.592493).  Saving model ...
	 Train_Loss: 0.5709 Train_Acc: 73.840 Val_Loss: 0.5925  BEST VAL Loss: 0.5925  Val_Acc: 70.432

Epoch 46: Validation loss decreased (0.592493 --> 0.591980).  Saving model ...
	 Train_Loss: 0.5700 Train_Acc: 74.524 Val_Loss: 0.5920  BEST VAL Loss: 0.5920  Val_Acc: 70.565

Epoch 47: Validation loss decreased (0.591980 --> 0.591855).  Saving model ...
	 Train_Loss: 0.5694 Train_Acc: 74.408 Val_Loss: 0.5919  BEST VAL Loss: 0.5919  Val_Acc: 70.432

Epoch 48: Validation loss decreased (0.591855 --> 0.591196).  Saving model ...
	 Train_Loss: 0.5685 Train_Acc: 75.026 Val_Loss: 0.5912  BEST VAL Loss: 0.5912  Val_Acc: 69.550

Epoch 49: Validation loss decreased (0.591196 --> 0.590616).  Saving model ...
	 Train_Loss: 0.5676 Train_Acc: 75.109 Val_Loss: 0.5906  BEST VAL Loss: 0.5906  Val_Acc: 70.609

Epoch 50: Validation loss decreased (0.590616 --> 0.590218).  Saving model ...
	 Train_Loss: 0.5673 Train_Acc: 73.459 Val_Loss: 0.5902  BEST VAL Loss: 0.5902  Val_Acc: 69.020

Epoch 51: Validation loss decreased (0.590218 --> 0.589900).  Saving model ...
	 Train_Loss: 0.5668 Train_Acc: 73.851 Val_Loss: 0.5899  BEST VAL Loss: 0.5899  Val_Acc: 69.462

Epoch 52: Validation loss decreased (0.589900 --> 0.589683).  Saving model ...
	 Train_Loss: 0.5662 Train_Acc: 74.353 Val_Loss: 0.5897  BEST VAL Loss: 0.5897  Val_Acc: 68.711

Epoch 53: Validation loss decreased (0.589683 --> 0.589423).  Saving model ...
	 Train_Loss: 0.5655 Train_Acc: 74.298 Val_Loss: 0.5894  BEST VAL Loss: 0.5894  Val_Acc: 69.991

Epoch 54: Validation loss decreased (0.589423 --> 0.589126).  Saving model ...
	 Train_Loss: 0.5649 Train_Acc: 74.287 Val_Loss: 0.5891  BEST VAL Loss: 0.5891  Val_Acc: 70.124

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.5643 Train_Acc: 74.966 Val_Loss: 0.5891  BEST VAL Loss: 0.5891  Val_Acc: 68.932

Epoch 56: Validation loss decreased (0.589126 --> 0.588807).  Saving model ...
	 Train_Loss: 0.5638 Train_Acc: 74.761 Val_Loss: 0.5888  BEST VAL Loss: 0.5888  Val_Acc: 70.741

Epoch 57: Validation loss decreased (0.588807 --> 0.588474).  Saving model ...
	 Train_Loss: 0.5633 Train_Acc: 74.370 Val_Loss: 0.5885  BEST VAL Loss: 0.5885  Val_Acc: 70.079

Epoch 58: Validation loss decreased (0.588474 --> 0.588092).  Saving model ...
	 Train_Loss: 0.5627 Train_Acc: 74.574 Val_Loss: 0.5881  BEST VAL Loss: 0.5881  Val_Acc: 70.609

Epoch 59: Validation loss decreased (0.588092 --> 0.587704).  Saving model ...
	 Train_Loss: 0.5620 Train_Acc: 75.606 Val_Loss: 0.5877  BEST VAL Loss: 0.5877  Val_Acc: 70.344

Epoch 60: Validation loss decreased (0.587704 --> 0.587537).  Saving model ...
	 Train_Loss: 0.5612 Train_Acc: 75.926 Val_Loss: 0.5875  BEST VAL Loss: 0.5875  Val_Acc: 69.550

Epoch 61: Validation loss decreased (0.587537 --> 0.587390).  Saving model ...
	 Train_Loss: 0.5606 Train_Acc: 75.970 Val_Loss: 0.5874  BEST VAL Loss: 0.5874  Val_Acc: 69.241

Epoch 62: Validation loss decreased (0.587390 --> 0.587198).  Saving model ...
	 Train_Loss: 0.5600 Train_Acc: 74.817 Val_Loss: 0.5872  BEST VAL Loss: 0.5872  Val_Acc: 69.903

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.5595 Train_Acc: 74.877 Val_Loss: 0.5872  BEST VAL Loss: 0.5872  Val_Acc: 68.844

Epoch 64: Validation loss decreased (0.587198 --> 0.587134).  Saving model ...
	 Train_Loss: 0.5590 Train_Acc: 75.175 Val_Loss: 0.5871  BEST VAL Loss: 0.5871  Val_Acc: 69.109

Epoch 65: Validation loss decreased (0.587134 --> 0.587120).  Saving model ...
	 Train_Loss: 0.5582 Train_Acc: 75.672 Val_Loss: 0.5871  BEST VAL Loss: 0.5871  Val_Acc: 70.300

Epoch 66: Validation loss decreased (0.587120 --> 0.586710).  Saving model ...
	 Train_Loss: 0.5575 Train_Acc: 76.251 Val_Loss: 0.5867  BEST VAL Loss: 0.5867  Val_Acc: 70.300

Epoch 67: Validation loss decreased (0.586710 --> 0.586634).  Saving model ...
	 Train_Loss: 0.5569 Train_Acc: 76.334 Val_Loss: 0.5866  BEST VAL Loss: 0.5866  Val_Acc: 70.035

Epoch 68: Validation loss decreased (0.586634 --> 0.586089).  Saving model ...
	 Train_Loss: 0.5562 Train_Acc: 75.539 Val_Loss: 0.5861  BEST VAL Loss: 0.5861  Val_Acc: 69.859

Epoch 69: Validation loss decreased (0.586089 --> 0.585954).  Saving model ...
	 Train_Loss: 0.5558 Train_Acc: 74.899 Val_Loss: 0.5860  BEST VAL Loss: 0.5860  Val_Acc: 70.565

Epoch 70: Validation loss decreased (0.585954 --> 0.585774).  Saving model ...
	 Train_Loss: 0.5552 Train_Acc: 76.141 Val_Loss: 0.5858  BEST VAL Loss: 0.5858  Val_Acc: 70.741

Epoch 71: Validation loss decreased (0.585774 --> 0.585444).  Saving model ...
	 Train_Loss: 0.5545 Train_Acc: 76.869 Val_Loss: 0.5854  BEST VAL Loss: 0.5854  Val_Acc: 71.050

Epoch 72: Validation loss decreased (0.585444 --> 0.585171).  Saving model ...
	 Train_Loss: 0.5538 Train_Acc: 76.797 Val_Loss: 0.5852  BEST VAL Loss: 0.5852  Val_Acc: 71.006

Epoch 73: Validation loss decreased (0.585171 --> 0.584955).  Saving model ...
	 Train_Loss: 0.5531 Train_Acc: 76.637 Val_Loss: 0.5850  BEST VAL Loss: 0.5850  Val_Acc: 70.653

Epoch 74: Validation loss decreased (0.584955 --> 0.584846).  Saving model ...
	 Train_Loss: 0.5527 Train_Acc: 75.981 Val_Loss: 0.5848  BEST VAL Loss: 0.5848  Val_Acc: 69.903

Epoch 75: Validation loss decreased (0.584846 --> 0.584641).  Saving model ...
	 Train_Loss: 0.5521 Train_Acc: 75.777 Val_Loss: 0.5846  BEST VAL Loss: 0.5846  Val_Acc: 69.550

Epoch 76: Validation loss decreased (0.584641 --> 0.584519).  Saving model ...
	 Train_Loss: 0.5517 Train_Acc: 75.992 Val_Loss: 0.5845  BEST VAL Loss: 0.5845  Val_Acc: 69.859

Epoch 77: Validation loss decreased (0.584519 --> 0.584141).  Saving model ...
	 Train_Loss: 0.5512 Train_Acc: 76.041 Val_Loss: 0.5841  BEST VAL Loss: 0.5841  Val_Acc: 69.991

Epoch 78: Validation loss decreased (0.584141 --> 0.583789).  Saving model ...
	 Train_Loss: 0.5507 Train_Acc: 76.080 Val_Loss: 0.5838  BEST VAL Loss: 0.5838  Val_Acc: 71.271

Epoch 79: Validation loss decreased (0.583789 --> 0.583606).  Saving model ...
	 Train_Loss: 0.5501 Train_Acc: 76.604 Val_Loss: 0.5836  BEST VAL Loss: 0.5836  Val_Acc: 70.035

Epoch 80: Validation loss decreased (0.583606 --> 0.583352).  Saving model ...
	 Train_Loss: 0.5496 Train_Acc: 76.775 Val_Loss: 0.5834  BEST VAL Loss: 0.5834  Val_Acc: 70.830

Epoch 81: Validation loss decreased (0.583352 --> 0.583209).  Saving model ...
	 Train_Loss: 0.5491 Train_Acc: 76.742 Val_Loss: 0.5832  BEST VAL Loss: 0.5832  Val_Acc: 71.183

Epoch 82: Validation loss decreased (0.583209 --> 0.583037).  Saving model ...
	 Train_Loss: 0.5486 Train_Acc: 76.577 Val_Loss: 0.5830  BEST VAL Loss: 0.5830  Val_Acc: 70.344

Epoch 83: Validation loss decreased (0.583037 --> 0.582920).  Saving model ...
	 Train_Loss: 0.5483 Train_Acc: 75.506 Val_Loss: 0.5829  BEST VAL Loss: 0.5829  Val_Acc: 70.477

Epoch 84: Validation loss decreased (0.582920 --> 0.582730).  Saving model ...
	 Train_Loss: 0.5480 Train_Acc: 75.247 Val_Loss: 0.5827  BEST VAL Loss: 0.5827  Val_Acc: 70.741

Epoch 85: Validation loss decreased (0.582730 --> 0.582578).  Saving model ...
	 Train_Loss: 0.5477 Train_Acc: 75.352 Val_Loss: 0.5826  BEST VAL Loss: 0.5826  Val_Acc: 70.256

Epoch 86: Validation loss decreased (0.582578 --> 0.582496).  Saving model ...
	 Train_Loss: 0.5474 Train_Acc: 75.848 Val_Loss: 0.5825  BEST VAL Loss: 0.5825  Val_Acc: 70.124

Epoch 87: Validation loss decreased (0.582496 --> 0.582342).  Saving model ...
	 Train_Loss: 0.5471 Train_Acc: 75.997 Val_Loss: 0.5823  BEST VAL Loss: 0.5823  Val_Acc: 71.756

Epoch 88: Validation loss decreased (0.582342 --> 0.582249).  Saving model ...
	 Train_Loss: 0.5466 Train_Acc: 76.395 Val_Loss: 0.5822  BEST VAL Loss: 0.5822  Val_Acc: 70.830

Epoch 89: Validation loss decreased (0.582249 --> 0.582125).  Saving model ...
	 Train_Loss: 0.5461 Train_Acc: 76.836 Val_Loss: 0.5821  BEST VAL Loss: 0.5821  Val_Acc: 70.168

Epoch 90: Validation loss decreased (0.582125 --> 0.582036).  Saving model ...
	 Train_Loss: 0.5457 Train_Acc: 76.786 Val_Loss: 0.5820  BEST VAL Loss: 0.5820  Val_Acc: 69.991

Epoch 91: Validation loss decreased (0.582036 --> 0.581947).  Saving model ...
	 Train_Loss: 0.5453 Train_Acc: 76.224 Val_Loss: 0.5819  BEST VAL Loss: 0.5819  Val_Acc: 70.477

Epoch 92: Validation loss decreased (0.581947 --> 0.581873).  Saving model ...
	 Train_Loss: 0.5449 Train_Acc: 75.959 Val_Loss: 0.5819  BEST VAL Loss: 0.5819  Val_Acc: 69.815

Epoch 93: Validation loss decreased (0.581873 --> 0.581711).  Saving model ...
	 Train_Loss: 0.5446 Train_Acc: 75.611 Val_Loss: 0.5817  BEST VAL Loss: 0.5817  Val_Acc: 70.918

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.5441 Train_Acc: 76.494 Val_Loss: 0.5817  BEST VAL Loss: 0.5817  Val_Acc: 71.227

Epoch 95: Validation loss decreased (0.581711 --> 0.581700).  Saving model ...
	 Train_Loss: 0.5438 Train_Acc: 76.179 Val_Loss: 0.5817  BEST VAL Loss: 0.5817  Val_Acc: 70.477

Epoch 96: Validation loss decreased (0.581700 --> 0.581549).  Saving model ...
	 Train_Loss: 0.5434 Train_Acc: 77.007 Val_Loss: 0.5815  BEST VAL Loss: 0.5815  Val_Acc: 70.477

Epoch 97: Validation loss decreased (0.581549 --> 0.581498).  Saving model ...
	 Train_Loss: 0.5430 Train_Acc: 76.687 Val_Loss: 0.5815  BEST VAL Loss: 0.5815  Val_Acc: 69.991

Epoch 98: Validation loss did not decrease
	 Train_Loss: 0.5424 Train_Acc: 77.774 Val_Loss: 0.5816  BEST VAL Loss: 0.5815  Val_Acc: 70.079

Epoch 99: Validation loss decreased (0.581498 --> 0.581432).  Saving model ...
	 Train_Loss: 0.5419 Train_Acc: 77.592 Val_Loss: 0.5814  BEST VAL Loss: 0.5814  Val_Acc: 69.991

LPS_0.010_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.42      0.45      8634
           1       0.52      0.58      0.55      9489

    accuracy                           0.50     18123
   macro avg       0.50      0.50      0.50     18123
weighted avg       0.50      0.50      0.50     18123

LPS_0.010_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.45      0.38      0.41      1080
           1       0.51      0.58      0.54      1186

    accuracy                           0.48      2266
   macro avg       0.48      0.48      0.48      2266
weighted avg       0.48      0.48      0.48      2266

LPS_0.010_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.41      0.44      1079
           1       0.52      0.57      0.54      1187

    accuracy                           0.50      2266
   macro avg       0.49      0.49      0.49      2266
weighted avg       0.49      0.50      0.49      2266

              precision    recall  f1-score   support

           0       0.47      0.41      0.44      1079
           1       0.52      0.57      0.54      1187

    accuracy                           0.50      2266
   macro avg       0.49      0.49      0.49      2266
weighted avg       0.49      0.50      0.49      2266

LPS_0.010_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.35      0.42      4135
           1       0.49      0.65      0.56      3997

    accuracy                           0.50      8132
   macro avg       0.50      0.50      0.49      8132
weighted avg       0.50      0.50      0.49      8132

              precision    recall  f1-score   support

           0       0.51      0.35      0.42      4135
           1       0.49      0.65      0.56      3997

    accuracy                           0.50      8132
   macro avg       0.50      0.50      0.49      8132
weighted avg       0.50      0.50      0.49      8132

completed
