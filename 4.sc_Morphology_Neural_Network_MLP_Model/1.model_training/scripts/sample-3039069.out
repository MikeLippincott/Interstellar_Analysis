[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'a8cd2dca'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '5224b812'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'e3a2be71'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '916623ad'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_10.000_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_10.000_DMSO_0.025']
The dimensions of the data are: (34320, 1276)
Number of total missing values across all columns: 68640
Data Subset Is Off
Wells held out for testing: ['C20' 'E21']
Wells to use for training, validation, and testing ['C16' 'E16' 'C17' 'E17' 'E20' 'C21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.673673).  Saving model ...
	 Train_Loss: 0.6897 Train_Acc: 54.209 Val_Loss: 0.6737  BEST VAL Loss: 0.6737  Val_Acc: 61.416

Epoch 1: Validation loss decreased (0.673673 --> 0.671850).  Saving model ...
	 Train_Loss: 0.6848 Train_Acc: 57.092 Val_Loss: 0.6719  BEST VAL Loss: 0.6719  Val_Acc: 60.755

Epoch 2: Validation loss decreased (0.671850 --> 0.668083).  Saving model ...
	 Train_Loss: 0.6813 Train_Acc: 58.220 Val_Loss: 0.6681  BEST VAL Loss: 0.6681  Val_Acc: 63.244

Epoch 3: Validation loss decreased (0.668083 --> 0.664346).  Saving model ...
	 Train_Loss: 0.6777 Train_Acc: 59.674 Val_Loss: 0.6643  BEST VAL Loss: 0.6643  Val_Acc: 63.283

Epoch 4: Validation loss decreased (0.664346 --> 0.662236).  Saving model ...
	 Train_Loss: 0.6754 Train_Acc: 59.562 Val_Loss: 0.6622  BEST VAL Loss: 0.6622  Val_Acc: 63.827

Epoch 5: Validation loss decreased (0.662236 --> 0.660851).  Saving model ...
	 Train_Loss: 0.6734 Train_Acc: 60.297 Val_Loss: 0.6609  BEST VAL Loss: 0.6609  Val_Acc: 62.855

Epoch 6: Validation loss did not decrease
	 Train_Loss: 0.6715 Train_Acc: 60.695 Val_Loss: 0.6611  BEST VAL Loss: 0.6609  Val_Acc: 61.688

Epoch 7: Validation loss decreased (0.660851 --> 0.660705).  Saving model ...
	 Train_Loss: 0.6695 Train_Acc: 61.347 Val_Loss: 0.6607  BEST VAL Loss: 0.6607  Val_Acc: 61.921

Epoch 8: Validation loss decreased (0.660705 --> 0.659411).  Saving model ...
	 Train_Loss: 0.6681 Train_Acc: 61.556 Val_Loss: 0.6594  BEST VAL Loss: 0.6594  Val_Acc: 63.555

Epoch 9: Validation loss decreased (0.659411 --> 0.658552).  Saving model ...
	 Train_Loss: 0.6664 Train_Acc: 62.285 Val_Loss: 0.6586  BEST VAL Loss: 0.6586  Val_Acc: 63.283

Epoch 10: Validation loss decreased (0.658552 --> 0.657140).  Saving model ...
	 Train_Loss: 0.6650 Train_Acc: 62.913 Val_Loss: 0.6571  BEST VAL Loss: 0.6571  Val_Acc: 64.333

Epoch 11: Validation loss decreased (0.657140 --> 0.656690).  Saving model ...
	 Train_Loss: 0.6637 Train_Acc: 62.864 Val_Loss: 0.6567  BEST VAL Loss: 0.6567  Val_Acc: 64.138

Epoch 12: Validation loss decreased (0.656690 --> 0.655125).  Saving model ...
	 Train_Loss: 0.6622 Train_Acc: 63.681 Val_Loss: 0.6551  BEST VAL Loss: 0.6551  Val_Acc: 64.955

Epoch 13: Validation loss decreased (0.655125 --> 0.653594).  Saving model ...
	 Train_Loss: 0.6609 Train_Acc: 63.803 Val_Loss: 0.6536  BEST VAL Loss: 0.6536  Val_Acc: 65.189

Epoch 14: Validation loss decreased (0.653594 --> 0.652588).  Saving model ...
	 Train_Loss: 0.6598 Train_Acc: 63.978 Val_Loss: 0.6526  BEST VAL Loss: 0.6526  Val_Acc: 65.578

Epoch 15: Validation loss decreased (0.652588 --> 0.651778).  Saving model ...
	 Train_Loss: 0.6587 Train_Acc: 64.094 Val_Loss: 0.6518  BEST VAL Loss: 0.6518  Val_Acc: 64.100

Epoch 16: Validation loss decreased (0.651778 --> 0.651031).  Saving model ...
	 Train_Loss: 0.6575 Train_Acc: 64.391 Val_Loss: 0.6510  BEST VAL Loss: 0.6510  Val_Acc: 64.333

Epoch 17: Validation loss decreased (0.651031 --> 0.650283).  Saving model ...
	 Train_Loss: 0.6565 Train_Acc: 64.600 Val_Loss: 0.6503  BEST VAL Loss: 0.6503  Val_Acc: 64.722

Epoch 18: Validation loss decreased (0.650283 --> 0.649442).  Saving model ...
	 Train_Loss: 0.6554 Train_Acc: 65.115 Val_Loss: 0.6494  BEST VAL Loss: 0.6494  Val_Acc: 64.916

Epoch 19: Validation loss decreased (0.649442 --> 0.648832).  Saving model ...
	 Train_Loss: 0.6544 Train_Acc: 64.974 Val_Loss: 0.6488  BEST VAL Loss: 0.6488  Val_Acc: 64.411

Epoch 20: Validation loss decreased (0.648832 --> 0.648129).  Saving model ...
	 Train_Loss: 0.6534 Train_Acc: 65.305 Val_Loss: 0.6481  BEST VAL Loss: 0.6481  Val_Acc: 65.772

Epoch 21: Validation loss decreased (0.648129 --> 0.647635).  Saving model ...
	 Train_Loss: 0.6525 Train_Acc: 65.125 Val_Loss: 0.6476  BEST VAL Loss: 0.6476  Val_Acc: 63.827

Epoch 22: Validation loss decreased (0.647635 --> 0.647529).  Saving model ...
	 Train_Loss: 0.6518 Train_Acc: 64.965 Val_Loss: 0.6475  BEST VAL Loss: 0.6475  Val_Acc: 63.944

Epoch 23: Validation loss decreased (0.647529 --> 0.647316).  Saving model ...
	 Train_Loss: 0.6510 Train_Acc: 65.456 Val_Loss: 0.6473  BEST VAL Loss: 0.6473  Val_Acc: 63.672

Epoch 24: Validation loss decreased (0.647316 --> 0.647107).  Saving model ...
	 Train_Loss: 0.6502 Train_Acc: 65.524 Val_Loss: 0.6471  BEST VAL Loss: 0.6471  Val_Acc: 64.138

Epoch 25: Validation loss decreased (0.647107 --> 0.646794).  Saving model ...
	 Train_Loss: 0.6495 Train_Acc: 65.456 Val_Loss: 0.6468  BEST VAL Loss: 0.6468  Val_Acc: 64.450

Epoch 26: Validation loss decreased (0.646794 --> 0.646616).  Saving model ...
	 Train_Loss: 0.6489 Train_Acc: 65.077 Val_Loss: 0.6466  BEST VAL Loss: 0.6466  Val_Acc: 64.411

Epoch 27: Validation loss decreased (0.646616 --> 0.646353).  Saving model ...
	 Train_Loss: 0.6483 Train_Acc: 65.650 Val_Loss: 0.6464  BEST VAL Loss: 0.6464  Val_Acc: 64.761

Epoch 28: Validation loss decreased (0.646353 --> 0.646129).  Saving model ...
	 Train_Loss: 0.6475 Train_Acc: 66.010 Val_Loss: 0.6461  BEST VAL Loss: 0.6461  Val_Acc: 63.905

Epoch 29: Validation loss decreased (0.646129 --> 0.645714).  Saving model ...
	 Train_Loss: 0.6469 Train_Acc: 65.855 Val_Loss: 0.6457  BEST VAL Loss: 0.6457  Val_Acc: 65.189

Epoch 30: Validation loss decreased (0.645714 --> 0.645399).  Saving model ...
	 Train_Loss: 0.6463 Train_Acc: 65.840 Val_Loss: 0.6454  BEST VAL Loss: 0.6454  Val_Acc: 63.866

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.6456 Train_Acc: 66.321 Val_Loss: 0.6455  BEST VAL Loss: 0.6454  Val_Acc: 63.399

Epoch 32: Validation loss decreased (0.645399 --> 0.645348).  Saving model ...
	 Train_Loss: 0.6451 Train_Acc: 66.205 Val_Loss: 0.6453  BEST VAL Loss: 0.6453  Val_Acc: 63.905

Epoch 33: Validation loss decreased (0.645348 --> 0.645181).  Saving model ...
	 Train_Loss: 0.6446 Train_Acc: 65.573 Val_Loss: 0.6452  BEST VAL Loss: 0.6452  Val_Acc: 63.672

Epoch 34: Validation loss decreased (0.645181 --> 0.644957).  Saving model ...
	 Train_Loss: 0.6439 Train_Acc: 66.030 Val_Loss: 0.6450  BEST VAL Loss: 0.6450  Val_Acc: 64.955

Epoch 35: Validation loss decreased (0.644957 --> 0.644671).  Saving model ...
	 Train_Loss: 0.6435 Train_Acc: 66.273 Val_Loss: 0.6447  BEST VAL Loss: 0.6447  Val_Acc: 65.072

Epoch 36: Validation loss decreased (0.644671 --> 0.644550).  Saving model ...
	 Train_Loss: 0.6429 Train_Acc: 66.360 Val_Loss: 0.6446  BEST VAL Loss: 0.6446  Val_Acc: 63.827

Epoch 37: Validation loss decreased (0.644550 --> 0.644268).  Saving model ...
	 Train_Loss: 0.6424 Train_Acc: 66.847 Val_Loss: 0.6443  BEST VAL Loss: 0.6443  Val_Acc: 64.644

Epoch 38: Validation loss decreased (0.644268 --> 0.644143).  Saving model ...
	 Train_Loss: 0.6418 Train_Acc: 66.710 Val_Loss: 0.6441  BEST VAL Loss: 0.6441  Val_Acc: 64.605

Epoch 39: Validation loss decreased (0.644143 --> 0.644089).  Saving model ...
	 Train_Loss: 0.6413 Train_Acc: 66.701 Val_Loss: 0.6441  BEST VAL Loss: 0.6441  Val_Acc: 63.750

Epoch 40: Validation loss decreased (0.644089 --> 0.643932).  Saving model ...
	 Train_Loss: 0.6407 Train_Acc: 67.041 Val_Loss: 0.6439  BEST VAL Loss: 0.6439  Val_Acc: 64.761

Epoch 41: Validation loss decreased (0.643932 --> 0.643891).  Saving model ...
	 Train_Loss: 0.6403 Train_Acc: 66.924 Val_Loss: 0.6439  BEST VAL Loss: 0.6439  Val_Acc: 63.866

Epoch 42: Validation loss decreased (0.643891 --> 0.643817).  Saving model ...
	 Train_Loss: 0.6398 Train_Acc: 67.022 Val_Loss: 0.6438  BEST VAL Loss: 0.6438  Val_Acc: 64.566

Epoch 43: Validation loss decreased (0.643817 --> 0.643629).  Saving model ...
	 Train_Loss: 0.6394 Train_Acc: 67.027 Val_Loss: 0.6436  BEST VAL Loss: 0.6436  Val_Acc: 64.489

Epoch 44: Validation loss decreased (0.643629 --> 0.643454).  Saving model ...
	 Train_Loss: 0.6389 Train_Acc: 67.289 Val_Loss: 0.6435  BEST VAL Loss: 0.6435  Val_Acc: 64.566

Epoch 45: Validation loss decreased (0.643454 --> 0.643354).  Saving model ...
	 Train_Loss: 0.6384 Train_Acc: 67.231 Val_Loss: 0.6434  BEST VAL Loss: 0.6434  Val_Acc: 64.955

Epoch 46: Validation loss decreased (0.643354 --> 0.643346).  Saving model ...
	 Train_Loss: 0.6380 Train_Acc: 66.944 Val_Loss: 0.6433  BEST VAL Loss: 0.6433  Val_Acc: 64.022

Epoch 47: Validation loss decreased (0.643346 --> 0.643271).  Saving model ...
	 Train_Loss: 0.6376 Train_Acc: 67.240 Val_Loss: 0.6433  BEST VAL Loss: 0.6433  Val_Acc: 64.177

Epoch 48: Validation loss decreased (0.643271 --> 0.643164).  Saving model ...
	 Train_Loss: 0.6372 Train_Acc: 67.693 Val_Loss: 0.6432  BEST VAL Loss: 0.6432  Val_Acc: 63.672

Epoch 49: Validation loss decreased (0.643164 --> 0.643021).  Saving model ...
	 Train_Loss: 0.6367 Train_Acc: 67.464 Val_Loss: 0.6430  BEST VAL Loss: 0.6430  Val_Acc: 64.333

Epoch 50: Validation loss decreased (0.643021 --> 0.642884).  Saving model ...
	 Train_Loss: 0.6362 Train_Acc: 67.673 Val_Loss: 0.6429  BEST VAL Loss: 0.6429  Val_Acc: 64.644

Epoch 51: Validation loss decreased (0.642884 --> 0.642721).  Saving model ...
	 Train_Loss: 0.6358 Train_Acc: 67.659 Val_Loss: 0.6427  BEST VAL Loss: 0.6427  Val_Acc: 64.644

Epoch 52: Validation loss decreased (0.642721 --> 0.642573).  Saving model ...
	 Train_Loss: 0.6354 Train_Acc: 67.377 Val_Loss: 0.6426  BEST VAL Loss: 0.6426  Val_Acc: 64.800

Epoch 53: Validation loss decreased (0.642573 --> 0.642515).  Saving model ...
	 Train_Loss: 0.6350 Train_Acc: 67.678 Val_Loss: 0.6425  BEST VAL Loss: 0.6425  Val_Acc: 64.722

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.6347 Train_Acc: 67.168 Val_Loss: 0.6426  BEST VAL Loss: 0.6425  Val_Acc: 65.266

Epoch 55: Validation loss decreased (0.642515 --> 0.642455).  Saving model ...
	 Train_Loss: 0.6343 Train_Acc: 67.522 Val_Loss: 0.6425  BEST VAL Loss: 0.6425  Val_Acc: 65.383

Epoch 56: Validation loss decreased (0.642455 --> 0.642442).  Saving model ...
	 Train_Loss: 0.6339 Train_Acc: 67.746 Val_Loss: 0.6424  BEST VAL Loss: 0.6424  Val_Acc: 65.072

Epoch 57: Validation loss decreased (0.642442 --> 0.642352).  Saving model ...
	 Train_Loss: 0.6335 Train_Acc: 67.916 Val_Loss: 0.6424  BEST VAL Loss: 0.6424  Val_Acc: 64.916

Epoch 58: Validation loss decreased (0.642352 --> 0.642290).  Saving model ...
	 Train_Loss: 0.6332 Train_Acc: 67.547 Val_Loss: 0.6423  BEST VAL Loss: 0.6423  Val_Acc: 64.916

Epoch 59: Validation loss decreased (0.642290 --> 0.642242).  Saving model ...
	 Train_Loss: 0.6329 Train_Acc: 67.654 Val_Loss: 0.6422  BEST VAL Loss: 0.6422  Val_Acc: 64.527

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.6325 Train_Acc: 68.252 Val_Loss: 0.6423  BEST VAL Loss: 0.6422  Val_Acc: 64.839

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.6321 Train_Acc: 68.310 Val_Loss: 0.6424  BEST VAL Loss: 0.6422  Val_Acc: 63.672

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.6318 Train_Acc: 67.727 Val_Loss: 0.6423  BEST VAL Loss: 0.6422  Val_Acc: 65.578

Epoch 63: Validation loss decreased (0.642242 --> 0.642224).  Saving model ...
	 Train_Loss: 0.6315 Train_Acc: 68.660 Val_Loss: 0.6422  BEST VAL Loss: 0.6422  Val_Acc: 65.266

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.6311 Train_Acc: 68.398 Val_Loss: 0.6423  BEST VAL Loss: 0.6422  Val_Acc: 63.711

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.6308 Train_Acc: 68.169 Val_Loss: 0.6424  BEST VAL Loss: 0.6422  Val_Acc: 64.022

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.6305 Train_Acc: 68.150 Val_Loss: 0.6425  BEST VAL Loss: 0.6422  Val_Acc: 63.905

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.6302 Train_Acc: 68.179 Val_Loss: 0.6425  BEST VAL Loss: 0.6422  Val_Acc: 65.150

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.6299 Train_Acc: 68.758 Val_Loss: 0.6424  BEST VAL Loss: 0.6422  Val_Acc: 65.539

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.6295 Train_Acc: 68.612 Val_Loss: 0.6424  BEST VAL Loss: 0.6422  Val_Acc: 64.450

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.6292 Train_Acc: 67.936 Val_Loss: 0.6423  BEST VAL Loss: 0.6422  Val_Acc: 64.722

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.6289 Train_Acc: 68.587 Val_Loss: 0.6424  BEST VAL Loss: 0.6422  Val_Acc: 64.839

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.6286 Train_Acc: 68.636 Val_Loss: 0.6424  BEST VAL Loss: 0.6422  Val_Acc: 64.839

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.6283 Train_Acc: 68.456 Val_Loss: 0.6424  BEST VAL Loss: 0.6422  Val_Acc: 64.372

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.6280 Train_Acc: 68.072 Val_Loss: 0.6423  BEST VAL Loss: 0.6422  Val_Acc: 65.111

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.6277 Train_Acc: 68.437 Val_Loss: 0.6425  BEST VAL Loss: 0.6422  Val_Acc: 64.839

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.6274 Train_Acc: 68.597 Val_Loss: 0.6425  BEST VAL Loss: 0.6422  Val_Acc: 64.722

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.6271 Train_Acc: 68.228 Val_Loss: 0.6426  BEST VAL Loss: 0.6422  Val_Acc: 64.061

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.6268 Train_Acc: 68.495 Val_Loss: 0.6425  BEST VAL Loss: 0.6422  Val_Acc: 64.333

Epoch 79: Validation loss did not decrease
Early stopped at epoch : 79
LPS_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.61      0.55     10451
           1       0.49      0.39      0.43     10114

    accuracy                           0.50     20565
   macro avg       0.50      0.50      0.49     20565
weighted avg       0.50      0.50      0.50     20565

LPS_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.61      0.55      1307
           1       0.48      0.38      0.43      1264

    accuracy                           0.50      2571
   macro avg       0.49      0.49      0.49      2571
weighted avg       0.49      0.50      0.49      2571

LPS_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.63      0.57      1307
           1       0.51      0.40      0.45      1264

    accuracy                           0.52      2571
   macro avg       0.52      0.52      0.51      2571
weighted avg       0.52      0.52      0.51      2571

              precision    recall  f1-score   support

           0       0.52      0.63      0.57      1307
           1       0.51      0.40      0.45      1264

    accuracy                           0.52      2571
   macro avg       0.52      0.52      0.51      2571
weighted avg       0.52      0.52      0.51      2571

LPS_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.66      0.58      4445
           1       0.48      0.33      0.39      4168

    accuracy                           0.50      8613
   macro avg       0.49      0.50      0.48      8613
weighted avg       0.50      0.50      0.49      8613

              precision    recall  f1-score   support

           0       0.51      0.66      0.58      4445
           1       0.48      0.33      0.39      4168

    accuracy                           0.50      8613
   macro avg       0.49      0.50      0.48      8613
weighted avg       0.50      0.50      0.49      8613

completed
