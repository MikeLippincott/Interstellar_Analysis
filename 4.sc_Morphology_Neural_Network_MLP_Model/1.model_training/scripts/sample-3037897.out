[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ab00b02f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'afc2e69e'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '6937b7e2'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '9727243a'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_100.000_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_100.000_DMSO_0.025
TREATMENT_NAME: Flagellin_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_100.000_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (263982, 1270)
Number of total missing values across all columns: 564580
Data Subset Is Off
Wells held out for testing: ['J08' 'M10']
Wells to use for training, validation, and testing ['J02' 'J03' 'J09' 'M05' 'M11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.552978).  Saving model ...
	 Train_Loss: 0.6160 Train_Acc: 65.777 Val_Loss: 0.5530  BEST VAL Loss: 0.5530  Val_Acc: 72.987

Epoch 1: Validation loss decreased (0.552978 --> 0.544579).  Saving model ...
	 Train_Loss: 0.5942 Train_Acc: 71.344 Val_Loss: 0.5446  BEST VAL Loss: 0.5446  Val_Acc: 74.838

Epoch 2: Validation loss decreased (0.544579 --> 0.539100).  Saving model ...
	 Train_Loss: 0.5833 Train_Acc: 72.283 Val_Loss: 0.5391  BEST VAL Loss: 0.5391  Val_Acc: 75.898

Epoch 3: Validation loss decreased (0.539100 --> 0.535039).  Saving model ...
	 Train_Loss: 0.5757 Train_Acc: 73.168 Val_Loss: 0.5350  BEST VAL Loss: 0.5350  Val_Acc: 76.194

Epoch 4: Validation loss decreased (0.535039 --> 0.531408).  Saving model ...
	 Train_Loss: 0.5704 Train_Acc: 73.668 Val_Loss: 0.5314  BEST VAL Loss: 0.5314  Val_Acc: 75.175

Epoch 5: Validation loss decreased (0.531408 --> 0.527618).  Saving model ...
	 Train_Loss: 0.5660 Train_Acc: 73.931 Val_Loss: 0.5276  BEST VAL Loss: 0.5276  Val_Acc: 76.444

Epoch 6: Validation loss decreased (0.527618 --> 0.524519).  Saving model ...
	 Train_Loss: 0.5623 Train_Acc: 74.205 Val_Loss: 0.5245  BEST VAL Loss: 0.5245  Val_Acc: 76.548

Epoch 7: Validation loss decreased (0.524519 --> 0.522882).  Saving model ...
	 Train_Loss: 0.5592 Train_Acc: 74.464 Val_Loss: 0.5229  BEST VAL Loss: 0.5229  Val_Acc: 76.834

Epoch 8: Validation loss decreased (0.522882 --> 0.520233).  Saving model ...
	 Train_Loss: 0.5566 Train_Acc: 74.661 Val_Loss: 0.5202  BEST VAL Loss: 0.5202  Val_Acc: 77.297

Epoch 9: Validation loss decreased (0.520233 --> 0.518800).  Saving model ...
	 Train_Loss: 0.5542 Train_Acc: 74.937 Val_Loss: 0.5188  BEST VAL Loss: 0.5188  Val_Acc: 76.486

Epoch 10: Validation loss decreased (0.518800 --> 0.517022).  Saving model ...
	 Train_Loss: 0.5520 Train_Acc: 74.948 Val_Loss: 0.5170  BEST VAL Loss: 0.5170  Val_Acc: 77.416

Epoch 11: Validation loss decreased (0.517022 --> 0.515297).  Saving model ...
	 Train_Loss: 0.5502 Train_Acc: 74.991 Val_Loss: 0.5153  BEST VAL Loss: 0.5153  Val_Acc: 77.515

Epoch 12: Validation loss decreased (0.515297 --> 0.514283).  Saving model ...
	 Train_Loss: 0.5485 Train_Acc: 75.054 Val_Loss: 0.5143  BEST VAL Loss: 0.5143  Val_Acc: 77.208

Epoch 13: Validation loss decreased (0.514283 --> 0.512959).  Saving model ...
	 Train_Loss: 0.5470 Train_Acc: 75.227 Val_Loss: 0.5130  BEST VAL Loss: 0.5130  Val_Acc: 77.749

Epoch 14: Validation loss decreased (0.512959 --> 0.511367).  Saving model ...
	 Train_Loss: 0.5458 Train_Acc: 75.121 Val_Loss: 0.5114  BEST VAL Loss: 0.5114  Val_Acc: 77.910

Epoch 15: Validation loss decreased (0.511367 --> 0.510078).  Saving model ...
	 Train_Loss: 0.5445 Train_Acc: 75.324 Val_Loss: 0.5101  BEST VAL Loss: 0.5101  Val_Acc: 77.811

Epoch 16: Validation loss decreased (0.510078 --> 0.509095).  Saving model ...
	 Train_Loss: 0.5432 Train_Acc: 75.427 Val_Loss: 0.5091  BEST VAL Loss: 0.5091  Val_Acc: 77.661

Epoch 17: Validation loss decreased (0.509095 --> 0.507919).  Saving model ...
	 Train_Loss: 0.5422 Train_Acc: 75.457 Val_Loss: 0.5079  BEST VAL Loss: 0.5079  Val_Acc: 77.702

Epoch 18: Validation loss decreased (0.507919 --> 0.507092).  Saving model ...
	 Train_Loss: 0.5412 Train_Acc: 75.434 Val_Loss: 0.5071  BEST VAL Loss: 0.5071  Val_Acc: 78.227

Epoch 19: Validation loss decreased (0.507092 --> 0.506093).  Saving model ...
	 Train_Loss: 0.5403 Train_Acc: 75.529 Val_Loss: 0.5061  BEST VAL Loss: 0.5061  Val_Acc: 78.321

Epoch 20: Validation loss decreased (0.506093 --> 0.505629).  Saving model ...
	 Train_Loss: 0.5395 Train_Acc: 75.420 Val_Loss: 0.5056  BEST VAL Loss: 0.5056  Val_Acc: 77.957

Epoch 21: Validation loss decreased (0.505629 --> 0.504683).  Saving model ...
	 Train_Loss: 0.5387 Train_Acc: 75.572 Val_Loss: 0.5047  BEST VAL Loss: 0.5047  Val_Acc: 78.570

Epoch 22: Validation loss decreased (0.504683 --> 0.504106).  Saving model ...
	 Train_Loss: 0.5379 Train_Acc: 75.551 Val_Loss: 0.5041  BEST VAL Loss: 0.5041  Val_Acc: 77.130

Epoch 23: Validation loss decreased (0.504106 --> 0.503566).  Saving model ...
	 Train_Loss: 0.5373 Train_Acc: 75.512 Val_Loss: 0.5036  BEST VAL Loss: 0.5036  Val_Acc: 78.394

Epoch 24: Validation loss decreased (0.503566 --> 0.502666).  Saving model ...
	 Train_Loss: 0.5366 Train_Acc: 75.721 Val_Loss: 0.5027  BEST VAL Loss: 0.5027  Val_Acc: 78.352

Epoch 25: Validation loss decreased (0.502666 --> 0.502023).  Saving model ...
	 Train_Loss: 0.5360 Train_Acc: 75.611 Val_Loss: 0.5020  BEST VAL Loss: 0.5020  Val_Acc: 77.707

Epoch 26: Validation loss decreased (0.502023 --> 0.501590).  Saving model ...
	 Train_Loss: 0.5354 Train_Acc: 75.785 Val_Loss: 0.5016  BEST VAL Loss: 0.5016  Val_Acc: 78.113

Epoch 27: Validation loss decreased (0.501590 --> 0.501017).  Saving model ...
	 Train_Loss: 0.5349 Train_Acc: 75.532 Val_Loss: 0.5010  BEST VAL Loss: 0.5010  Val_Acc: 78.201

Epoch 28: Validation loss decreased (0.501017 --> 0.500503).  Saving model ...
	 Train_Loss: 0.5344 Train_Acc: 75.791 Val_Loss: 0.5005  BEST VAL Loss: 0.5005  Val_Acc: 78.310

Epoch 29: Validation loss decreased (0.500503 --> 0.500055).  Saving model ...
	 Train_Loss: 0.5339 Train_Acc: 75.719 Val_Loss: 0.5001  BEST VAL Loss: 0.5001  Val_Acc: 78.383

Epoch 30: Validation loss decreased (0.500055 --> 0.499638).  Saving model ...
	 Train_Loss: 0.5334 Train_Acc: 75.799 Val_Loss: 0.4996  BEST VAL Loss: 0.4996  Val_Acc: 77.931

Epoch 31: Validation loss decreased (0.499638 --> 0.499188).  Saving model ...
	 Train_Loss: 0.5329 Train_Acc: 75.728 Val_Loss: 0.4992  BEST VAL Loss: 0.4992  Val_Acc: 78.882

Epoch 32: Validation loss decreased (0.499188 --> 0.498821).  Saving model ...
	 Train_Loss: 0.5325 Train_Acc: 75.802 Val_Loss: 0.4988  BEST VAL Loss: 0.4988  Val_Acc: 77.588

Epoch 33: Validation loss decreased (0.498821 --> 0.498483).  Saving model ...
	 Train_Loss: 0.5321 Train_Acc: 75.788 Val_Loss: 0.4985  BEST VAL Loss: 0.4985  Val_Acc: 78.326

Epoch 34: Validation loss decreased (0.498483 --> 0.498184).  Saving model ...
	 Train_Loss: 0.5316 Train_Acc: 75.717 Val_Loss: 0.4982  BEST VAL Loss: 0.4982  Val_Acc: 78.565

Epoch 35: Validation loss decreased (0.498184 --> 0.497802).  Saving model ...
	 Train_Loss: 0.5313 Train_Acc: 75.637 Val_Loss: 0.4978  BEST VAL Loss: 0.4978  Val_Acc: 78.388

Epoch 36: Validation loss decreased (0.497802 --> 0.497321).  Saving model ...
	 Train_Loss: 0.5309 Train_Acc: 75.789 Val_Loss: 0.4973  BEST VAL Loss: 0.4973  Val_Acc: 78.201

Epoch 37: Validation loss decreased (0.497321 --> 0.497153).  Saving model ...
	 Train_Loss: 0.5306 Train_Acc: 75.947 Val_Loss: 0.4972  BEST VAL Loss: 0.4972  Val_Acc: 78.555

Epoch 38: Validation loss decreased (0.497153 --> 0.496758).  Saving model ...
	 Train_Loss: 0.5302 Train_Acc: 75.925 Val_Loss: 0.4968  BEST VAL Loss: 0.4968  Val_Acc: 78.420

Epoch 39: Validation loss decreased (0.496758 --> 0.496583).  Saving model ...
	 Train_Loss: 0.5299 Train_Acc: 76.038 Val_Loss: 0.4966  BEST VAL Loss: 0.4966  Val_Acc: 78.700

Epoch 40: Validation loss decreased (0.496583 --> 0.496180).  Saving model ...
	 Train_Loss: 0.5296 Train_Acc: 75.954 Val_Loss: 0.4962  BEST VAL Loss: 0.4962  Val_Acc: 78.867

Epoch 41: Validation loss decreased (0.496180 --> 0.495784).  Saving model ...
	 Train_Loss: 0.5292 Train_Acc: 76.057 Val_Loss: 0.4958  BEST VAL Loss: 0.4958  Val_Acc: 79.106

Epoch 42: Validation loss decreased (0.495784 --> 0.495544).  Saving model ...
	 Train_Loss: 0.5289 Train_Acc: 75.992 Val_Loss: 0.4955  BEST VAL Loss: 0.4955  Val_Acc: 78.716

Epoch 43: Validation loss decreased (0.495544 --> 0.495132).  Saving model ...
	 Train_Loss: 0.5286 Train_Acc: 76.177 Val_Loss: 0.4951  BEST VAL Loss: 0.4951  Val_Acc: 78.768

Epoch 44: Validation loss decreased (0.495132 --> 0.494903).  Saving model ...
	 Train_Loss: 0.5283 Train_Acc: 75.910 Val_Loss: 0.4949  BEST VAL Loss: 0.4949  Val_Acc: 78.331

Epoch 45: Validation loss decreased (0.494903 --> 0.494574).  Saving model ...
	 Train_Loss: 0.5280 Train_Acc: 76.129 Val_Loss: 0.4946  BEST VAL Loss: 0.4946  Val_Acc: 78.716

Epoch 46: Validation loss decreased (0.494574 --> 0.494240).  Saving model ...
	 Train_Loss: 0.5276 Train_Acc: 76.266 Val_Loss: 0.4942  BEST VAL Loss: 0.4942  Val_Acc: 79.043

Epoch 47: Validation loss decreased (0.494240 --> 0.493849).  Saving model ...
	 Train_Loss: 0.5274 Train_Acc: 76.086 Val_Loss: 0.4938  BEST VAL Loss: 0.4938  Val_Acc: 78.716

Epoch 48: Validation loss decreased (0.493849 --> 0.493546).  Saving model ...
	 Train_Loss: 0.5271 Train_Acc: 76.083 Val_Loss: 0.4935  BEST VAL Loss: 0.4935  Val_Acc: 78.856

Epoch 49: Validation loss decreased (0.493546 --> 0.493269).  Saving model ...
	 Train_Loss: 0.5268 Train_Acc: 76.360 Val_Loss: 0.4933  BEST VAL Loss: 0.4933  Val_Acc: 78.763

Epoch 50: Validation loss decreased (0.493269 --> 0.493077).  Saving model ...
	 Train_Loss: 0.5265 Train_Acc: 76.042 Val_Loss: 0.4931  BEST VAL Loss: 0.4931  Val_Acc: 78.705

Epoch 51: Validation loss decreased (0.493077 --> 0.492863).  Saving model ...
	 Train_Loss: 0.5263 Train_Acc: 76.138 Val_Loss: 0.4929  BEST VAL Loss: 0.4929  Val_Acc: 78.705

Epoch 52: Validation loss decreased (0.492863 --> 0.492683).  Saving model ...
	 Train_Loss: 0.5260 Train_Acc: 76.219 Val_Loss: 0.4927  BEST VAL Loss: 0.4927  Val_Acc: 78.726

Epoch 53: Validation loss decreased (0.492683 --> 0.492393).  Saving model ...
	 Train_Loss: 0.5258 Train_Acc: 76.033 Val_Loss: 0.4924  BEST VAL Loss: 0.4924  Val_Acc: 79.142

Epoch 54: Validation loss decreased (0.492393 --> 0.492014).  Saving model ...
	 Train_Loss: 0.5256 Train_Acc: 76.277 Val_Loss: 0.4920  BEST VAL Loss: 0.4920  Val_Acc: 79.080

Epoch 55: Validation loss decreased (0.492014 --> 0.491653).  Saving model ...
	 Train_Loss: 0.5253 Train_Acc: 76.479 Val_Loss: 0.4917  BEST VAL Loss: 0.4917  Val_Acc: 79.023

Epoch 56: Validation loss decreased (0.491653 --> 0.491517).  Saving model ...
	 Train_Loss: 0.5251 Train_Acc: 76.389 Val_Loss: 0.4915  BEST VAL Loss: 0.4915  Val_Acc: 78.472

Epoch 57: Validation loss decreased (0.491517 --> 0.491290).  Saving model ...
	 Train_Loss: 0.5248 Train_Acc: 76.243 Val_Loss: 0.4913  BEST VAL Loss: 0.4913  Val_Acc: 79.132

Epoch 58: Validation loss decreased (0.491290 --> 0.491149).  Saving model ...
	 Train_Loss: 0.5246 Train_Acc: 76.342 Val_Loss: 0.4911  BEST VAL Loss: 0.4911  Val_Acc: 78.846

Epoch 59: Validation loss decreased (0.491149 --> 0.490915).  Saving model ...
	 Train_Loss: 0.5243 Train_Acc: 76.283 Val_Loss: 0.4909  BEST VAL Loss: 0.4909  Val_Acc: 78.950

Epoch 60: Validation loss decreased (0.490915 --> 0.490673).  Saving model ...
	 Train_Loss: 0.5241 Train_Acc: 76.404 Val_Loss: 0.4907  BEST VAL Loss: 0.4907  Val_Acc: 79.309

Epoch 61: Validation loss decreased (0.490673 --> 0.490362).  Saving model ...
	 Train_Loss: 0.5239 Train_Acc: 76.497 Val_Loss: 0.4904  BEST VAL Loss: 0.4904  Val_Acc: 79.371

Epoch 62: Validation loss decreased (0.490362 --> 0.490020).  Saving model ...
	 Train_Loss: 0.5236 Train_Acc: 76.413 Val_Loss: 0.4900  BEST VAL Loss: 0.4900  Val_Acc: 79.215

Epoch 63: Validation loss decreased (0.490020 --> 0.489728).  Saving model ...
	 Train_Loss: 0.5234 Train_Acc: 76.419 Val_Loss: 0.4897  BEST VAL Loss: 0.4897  Val_Acc: 79.225

Epoch 64: Validation loss decreased (0.489728 --> 0.489493).  Saving model ...
	 Train_Loss: 0.5232 Train_Acc: 76.497 Val_Loss: 0.4895  BEST VAL Loss: 0.4895  Val_Acc: 79.293

Epoch 65: Validation loss decreased (0.489493 --> 0.489298).  Saving model ...
	 Train_Loss: 0.5230 Train_Acc: 76.473 Val_Loss: 0.4893  BEST VAL Loss: 0.4893  Val_Acc: 79.085

Epoch 66: Validation loss decreased (0.489298 --> 0.489039).  Saving model ...
	 Train_Loss: 0.5227 Train_Acc: 76.589 Val_Loss: 0.4890  BEST VAL Loss: 0.4890  Val_Acc: 78.960

Epoch 67: Validation loss decreased (0.489039 --> 0.488819).  Saving model ...
	 Train_Loss: 0.5225 Train_Acc: 76.589 Val_Loss: 0.4888  BEST VAL Loss: 0.4888  Val_Acc: 79.007

Epoch 68: Validation loss decreased (0.488819 --> 0.488518).  Saving model ...
	 Train_Loss: 0.5223 Train_Acc: 76.446 Val_Loss: 0.4885  BEST VAL Loss: 0.4885  Val_Acc: 79.028

Epoch 69: Validation loss decreased (0.488518 --> 0.488404).  Saving model ...
	 Train_Loss: 0.5221 Train_Acc: 76.376 Val_Loss: 0.4884  BEST VAL Loss: 0.4884  Val_Acc: 79.620

Epoch 70: Validation loss decreased (0.488404 --> 0.488174).  Saving model ...
	 Train_Loss: 0.5220 Train_Acc: 76.312 Val_Loss: 0.4882  BEST VAL Loss: 0.4882  Val_Acc: 79.142

Epoch 71: Validation loss decreased (0.488174 --> 0.487959).  Saving model ...
	 Train_Loss: 0.5218 Train_Acc: 76.352 Val_Loss: 0.4880  BEST VAL Loss: 0.4880  Val_Acc: 79.085

Epoch 72: Validation loss decreased (0.487959 --> 0.487819).  Saving model ...
	 Train_Loss: 0.5216 Train_Acc: 76.521 Val_Loss: 0.4878  BEST VAL Loss: 0.4878  Val_Acc: 79.277

Epoch 73: Validation loss decreased (0.487819 --> 0.487699).  Saving model ...
	 Train_Loss: 0.5214 Train_Acc: 76.549 Val_Loss: 0.4877  BEST VAL Loss: 0.4877  Val_Acc: 78.492

Epoch 74: Validation loss decreased (0.487699 --> 0.487518).  Saving model ...
	 Train_Loss: 0.5213 Train_Acc: 76.599 Val_Loss: 0.4875  BEST VAL Loss: 0.4875  Val_Acc: 78.809

Epoch 75: Validation loss decreased (0.487518 --> 0.487389).  Saving model ...
	 Train_Loss: 0.5211 Train_Acc: 76.575 Val_Loss: 0.4874  BEST VAL Loss: 0.4874  Val_Acc: 79.350

Epoch 76: Validation loss decreased (0.487389 --> 0.487189).  Saving model ...
	 Train_Loss: 0.5209 Train_Acc: 76.665 Val_Loss: 0.4872  BEST VAL Loss: 0.4872  Val_Acc: 78.752

Epoch 77: Validation loss decreased (0.487189 --> 0.486985).  Saving model ...
	 Train_Loss: 0.5208 Train_Acc: 76.364 Val_Loss: 0.4870  BEST VAL Loss: 0.4870  Val_Acc: 79.220

Epoch 78: Validation loss decreased (0.486985 --> 0.486789).  Saving model ...
	 Train_Loss: 0.5206 Train_Acc: 76.646 Val_Loss: 0.4868  BEST VAL Loss: 0.4868  Val_Acc: 79.194

Epoch 79: Validation loss decreased (0.486789 --> 0.486541).  Saving model ...
	 Train_Loss: 0.5204 Train_Acc: 76.488 Val_Loss: 0.4865  BEST VAL Loss: 0.4865  Val_Acc: 79.314

Epoch 80: Validation loss decreased (0.486541 --> 0.486322).  Saving model ...
	 Train_Loss: 0.5203 Train_Acc: 76.393 Val_Loss: 0.4863  BEST VAL Loss: 0.4863  Val_Acc: 79.423

Epoch 81: Validation loss decreased (0.486322 --> 0.486200).  Saving model ...
	 Train_Loss: 0.5201 Train_Acc: 76.593 Val_Loss: 0.4862  BEST VAL Loss: 0.4862  Val_Acc: 78.726

Epoch 82: Validation loss decreased (0.486200 --> 0.486104).  Saving model ...
	 Train_Loss: 0.5200 Train_Acc: 76.523 Val_Loss: 0.4861  BEST VAL Loss: 0.4861  Val_Acc: 79.158

Epoch 83: Validation loss decreased (0.486104 --> 0.486001).  Saving model ...
	 Train_Loss: 0.5198 Train_Acc: 76.618 Val_Loss: 0.4860  BEST VAL Loss: 0.4860  Val_Acc: 78.544

Epoch 84: Validation loss decreased (0.486001 --> 0.485777).  Saving model ...
	 Train_Loss: 0.5197 Train_Acc: 76.626 Val_Loss: 0.4858  BEST VAL Loss: 0.4858  Val_Acc: 79.646

Epoch 85: Validation loss decreased (0.485777 --> 0.485608).  Saving model ...
	 Train_Loss: 0.5195 Train_Acc: 76.668 Val_Loss: 0.4856  BEST VAL Loss: 0.4856  Val_Acc: 78.887

Epoch 86: Validation loss decreased (0.485608 --> 0.485444).  Saving model ...
	 Train_Loss: 0.5194 Train_Acc: 76.554 Val_Loss: 0.4854  BEST VAL Loss: 0.4854  Val_Acc: 79.116

Epoch 87: Validation loss decreased (0.485444 --> 0.485273).  Saving model ...
	 Train_Loss: 0.5193 Train_Acc: 76.378 Val_Loss: 0.4853  BEST VAL Loss: 0.4853  Val_Acc: 79.397

Epoch 88: Validation loss decreased (0.485273 --> 0.485108).  Saving model ...
	 Train_Loss: 0.5191 Train_Acc: 76.460 Val_Loss: 0.4851  BEST VAL Loss: 0.4851  Val_Acc: 79.428

Epoch 89: Validation loss decreased (0.485108 --> 0.484921).  Saving model ...
	 Train_Loss: 0.5190 Train_Acc: 76.678 Val_Loss: 0.4849  BEST VAL Loss: 0.4849  Val_Acc: 79.132

Epoch 90: Validation loss decreased (0.484921 --> 0.484727).  Saving model ...
	 Train_Loss: 0.5189 Train_Acc: 76.324 Val_Loss: 0.4847  BEST VAL Loss: 0.4847  Val_Acc: 79.340

Epoch 91: Validation loss decreased (0.484727 --> 0.484618).  Saving model ...
	 Train_Loss: 0.5188 Train_Acc: 76.593 Val_Loss: 0.4846  BEST VAL Loss: 0.4846  Val_Acc: 79.366

Epoch 92: Validation loss decreased (0.484618 --> 0.484479).  Saving model ...
	 Train_Loss: 0.5186 Train_Acc: 76.593 Val_Loss: 0.4845  BEST VAL Loss: 0.4845  Val_Acc: 79.454

Epoch 93: Validation loss decreased (0.484479 --> 0.484414).  Saving model ...
	 Train_Loss: 0.5185 Train_Acc: 76.797 Val_Loss: 0.4844  BEST VAL Loss: 0.4844  Val_Acc: 79.184

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.5184 Train_Acc: 76.584 Val_Loss: 0.4844  BEST VAL Loss: 0.4844  Val_Acc: 79.231

Epoch 95: Validation loss decreased (0.484414 --> 0.484247).  Saving model ...
	 Train_Loss: 0.5182 Train_Acc: 76.571 Val_Loss: 0.4842  BEST VAL Loss: 0.4842  Val_Acc: 79.672

Epoch 96: Validation loss decreased (0.484247 --> 0.484170).  Saving model ...
	 Train_Loss: 0.5181 Train_Acc: 76.522 Val_Loss: 0.4842  BEST VAL Loss: 0.4842  Val_Acc: 79.199

Epoch 97: Validation loss decreased (0.484170 --> 0.484045).  Saving model ...
	 Train_Loss: 0.5180 Train_Acc: 76.465 Val_Loss: 0.4840  BEST VAL Loss: 0.4840  Val_Acc: 79.075

Epoch 98: Validation loss decreased (0.484045 --> 0.483896).  Saving model ...
	 Train_Loss: 0.5179 Train_Acc: 76.688 Val_Loss: 0.4839  BEST VAL Loss: 0.4839  Val_Acc: 79.298

Epoch 99: Validation loss decreased (0.483896 --> 0.483738).  Saving model ...
	 Train_Loss: 0.5178 Train_Acc: 76.543 Val_Loss: 0.4837  BEST VAL Loss: 0.4837  Val_Acc: 78.939

LPS_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.36      0.27      0.31     56122
           1       0.63      0.73      0.68     97753

    accuracy                           0.56    153875
   macro avg       0.50      0.50      0.49    153875
weighted avg       0.54      0.56      0.54    153875

LPS_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.37      0.27      0.31      7015
           1       0.64      0.74      0.68     12220

    accuracy                           0.57     19235
   macro avg       0.50      0.50      0.50     19235
weighted avg       0.54      0.57      0.55     19235

LPS_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.36      0.26      0.30      7016
           1       0.63      0.73      0.68     12219

    accuracy                           0.56     19235
   macro avg       0.49      0.50      0.49     19235
weighted avg       0.53      0.56      0.54     19235

              precision    recall  f1-score   support

           0       0.36      0.26      0.30      7016
           1       0.63      0.73      0.68     12219

    accuracy                           0.56     19235
   macro avg       0.49      0.50      0.49     19235
weighted avg       0.53      0.56      0.54     19235

LPS_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.15      0.23     34394
           1       0.52      0.85      0.65     37243

    accuracy                           0.51     71637
   macro avg       0.50      0.50      0.44     71637
weighted avg       0.50      0.51      0.45     71637

              precision    recall  f1-score   support

           0       0.48      0.15      0.23     34394
           1       0.52      0.85      0.65     37243

    accuracy                           0.51     71637
   macro avg       0.50      0.50      0.44     71637
weighted avg       0.50      0.51      0.45     71637

completed
