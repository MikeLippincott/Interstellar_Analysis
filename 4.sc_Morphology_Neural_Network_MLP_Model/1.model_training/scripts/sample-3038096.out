[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1d8940cd'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '07439ee7'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '2ae1c59d'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '2f303ab6'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_0.100_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_Nigericin_1.000_10.0_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (29330, 1276)
Number of total missing values across all columns: 29856
Data Subset Is Off
Wells held out for testing: ['M16' 'L22']
Wells to use for training, validation, and testing ['M17' 'L18' 'L19' 'M20' 'M21' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.359379).  Saving model ...
	 Train_Loss: 0.5737 Train_Acc: 67.044 Val_Loss: 0.3594  BEST VAL Loss: 0.3594  Val_Acc: 85.942

Epoch 1: Validation loss decreased (0.359379 --> 0.314534).  Saving model ...
	 Train_Loss: 0.4867 Train_Acc: 83.557 Val_Loss: 0.3145  BEST VAL Loss: 0.3145  Val_Acc: 90.112

Epoch 2: Validation loss decreased (0.314534 --> 0.275700).  Saving model ...
	 Train_Loss: 0.4343 Train_Acc: 86.767 Val_Loss: 0.2757  BEST VAL Loss: 0.2757  Val_Acc: 92.455

Epoch 3: Validation loss decreased (0.275700 --> 0.267050).  Saving model ...
	 Train_Loss: 0.3937 Train_Acc: 89.280 Val_Loss: 0.2671  BEST VAL Loss: 0.2671  Val_Acc: 92.455

Epoch 4: Validation loss decreased (0.267050 --> 0.256850).  Saving model ...
	 Train_Loss: 0.3658 Train_Acc: 89.901 Val_Loss: 0.2568  BEST VAL Loss: 0.2568  Val_Acc: 93.112

Epoch 5: Validation loss decreased (0.256850 --> 0.244355).  Saving model ...
	 Train_Loss: 0.3454 Train_Acc: 91.055 Val_Loss: 0.2444  BEST VAL Loss: 0.2444  Val_Acc: 94.142

Epoch 6: Validation loss decreased (0.244355 --> 0.236912).  Saving model ...
	 Train_Loss: 0.3293 Train_Acc: 91.653 Val_Loss: 0.2369  BEST VAL Loss: 0.2369  Val_Acc: 94.096

Epoch 7: Validation loss decreased (0.236912 --> 0.227967).  Saving model ...
	 Train_Loss: 0.3165 Train_Acc: 91.401 Val_Loss: 0.2280  BEST VAL Loss: 0.2280  Val_Acc: 94.986

Epoch 8: Validation loss decreased (0.227967 --> 0.220857).  Saving model ...
	 Train_Loss: 0.3051 Train_Acc: 92.115 Val_Loss: 0.2209  BEST VAL Loss: 0.2209  Val_Acc: 95.220

Epoch 9: Validation loss decreased (0.220857 --> 0.215813).  Saving model ...
	 Train_Loss: 0.2944 Train_Acc: 93.176 Val_Loss: 0.2158  BEST VAL Loss: 0.2158  Val_Acc: 94.517

Epoch 10: Validation loss decreased (0.215813 --> 0.209375).  Saving model ...
	 Train_Loss: 0.2857 Train_Acc: 93.099 Val_Loss: 0.2094  BEST VAL Loss: 0.2094  Val_Acc: 94.799

Epoch 11: Validation loss decreased (0.209375 --> 0.204513).  Saving model ...
	 Train_Loss: 0.2771 Train_Acc: 93.603 Val_Loss: 0.2045  BEST VAL Loss: 0.2045  Val_Acc: 95.127

Epoch 12: Validation loss decreased (0.204513 --> 0.201474).  Saving model ...
	 Train_Loss: 0.2703 Train_Acc: 93.463 Val_Loss: 0.2015  BEST VAL Loss: 0.2015  Val_Acc: 95.033

Epoch 13: Validation loss decreased (0.201474 --> 0.197997).  Saving model ...
	 Train_Loss: 0.2641 Train_Acc: 93.580 Val_Loss: 0.1980  BEST VAL Loss: 0.1980  Val_Acc: 94.986

Epoch 14: Validation loss decreased (0.197997 --> 0.195834).  Saving model ...
	 Train_Loss: 0.2580 Train_Acc: 93.791 Val_Loss: 0.1958  BEST VAL Loss: 0.1958  Val_Acc: 95.548

Epoch 15: Validation loss decreased (0.195834 --> 0.193367).  Saving model ...
	 Train_Loss: 0.2530 Train_Acc: 93.843 Val_Loss: 0.1934  BEST VAL Loss: 0.1934  Val_Acc: 95.595

Epoch 16: Validation loss decreased (0.193367 --> 0.191334).  Saving model ...
	 Train_Loss: 0.2478 Train_Acc: 94.148 Val_Loss: 0.1913  BEST VAL Loss: 0.1913  Val_Acc: 95.408

Epoch 17: Validation loss decreased (0.191334 --> 0.190750).  Saving model ...
	 Train_Loss: 0.2431 Train_Acc: 94.505 Val_Loss: 0.1907  BEST VAL Loss: 0.1907  Val_Acc: 95.127

Epoch 18: Validation loss did not decrease
	 Train_Loss: 0.2385 Train_Acc: 94.675 Val_Loss: 0.1917  BEST VAL Loss: 0.1907  Val_Acc: 95.220

Epoch 19: Validation loss did not decrease
	 Train_Loss: 0.2339 Train_Acc: 94.728 Val_Loss: 0.1910  BEST VAL Loss: 0.1907  Val_Acc: 95.923

Epoch 20: Validation loss decreased (0.190750 --> 0.190383).  Saving model ...
	 Train_Loss: 0.2299 Train_Acc: 94.956 Val_Loss: 0.1904  BEST VAL Loss: 0.1904  Val_Acc: 95.080

Epoch 21: Validation loss decreased (0.190383 --> 0.189486).  Saving model ...
	 Train_Loss: 0.2265 Train_Acc: 94.775 Val_Loss: 0.1895  BEST VAL Loss: 0.1895  Val_Acc: 95.829

Epoch 22: Validation loss decreased (0.189486 --> 0.188249).  Saving model ...
	 Train_Loss: 0.2232 Train_Acc: 94.693 Val_Loss: 0.1882  BEST VAL Loss: 0.1882  Val_Acc: 95.361

Epoch 23: Validation loss decreased (0.188249 --> 0.186078).  Saving model ...
	 Train_Loss: 0.2202 Train_Acc: 94.646 Val_Loss: 0.1861  BEST VAL Loss: 0.1861  Val_Acc: 95.548

Epoch 24: Validation loss decreased (0.186078 --> 0.184000).  Saving model ...
	 Train_Loss: 0.2172 Train_Acc: 95.109 Val_Loss: 0.1840  BEST VAL Loss: 0.1840  Val_Acc: 95.548

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.2145 Train_Acc: 94.833 Val_Loss: 0.1850  BEST VAL Loss: 0.1840  Val_Acc: 96.017

Epoch 26: Validation loss did not decrease
	 Train_Loss: 0.2117 Train_Acc: 95.038 Val_Loss: 0.1849  BEST VAL Loss: 0.1840  Val_Acc: 95.829

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.2094 Train_Acc: 94.763 Val_Loss: 0.1853  BEST VAL Loss: 0.1840  Val_Acc: 95.736

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.2069 Train_Acc: 95.267 Val_Loss: 0.1855  BEST VAL Loss: 0.1840  Val_Acc: 95.783

Epoch 29: Validation loss did not decrease
	 Train_Loss: 0.2043 Train_Acc: 95.372 Val_Loss: 0.1861  BEST VAL Loss: 0.1840  Val_Acc: 95.970

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.2020 Train_Acc: 95.448 Val_Loss: 0.1865  BEST VAL Loss: 0.1840  Val_Acc: 96.064

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.1999 Train_Acc: 95.167 Val_Loss: 0.1852  BEST VAL Loss: 0.1840  Val_Acc: 95.970

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.1979 Train_Acc: 95.320 Val_Loss: 0.1857  BEST VAL Loss: 0.1840  Val_Acc: 95.689

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.1959 Train_Acc: 95.548 Val_Loss: 0.1857  BEST VAL Loss: 0.1840  Val_Acc: 96.157

Epoch 34: Validation loss did not decrease
	 Train_Loss: 0.1943 Train_Acc: 95.191 Val_Loss: 0.1863  BEST VAL Loss: 0.1840  Val_Acc: 95.876

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.1927 Train_Acc: 95.074 Val_Loss: 0.1870  BEST VAL Loss: 0.1840  Val_Acc: 95.595

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.1911 Train_Acc: 95.366 Val_Loss: 0.1871  BEST VAL Loss: 0.1840  Val_Acc: 96.064

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.1894 Train_Acc: 95.425 Val_Loss: 0.1868  BEST VAL Loss: 0.1840  Val_Acc: 96.017

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.1877 Train_Acc: 95.683 Val_Loss: 0.1869  BEST VAL Loss: 0.1840  Val_Acc: 95.501

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.1862 Train_Acc: 95.706 Val_Loss: 0.1863  BEST VAL Loss: 0.1840  Val_Acc: 95.829

Epoch 40: Validation loss did not decrease
Early stopped at epoch : 40
Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.99      0.98      8635
           1       0.99      0.97      0.98      8436

    accuracy                           0.98     17071
   macro avg       0.98      0.98      0.98     17071
weighted avg       0.98      0.98      0.98     17071

Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.94      0.97      0.96      1079
           1       0.97      0.94      0.95      1055

    accuracy                           0.96      2134
   macro avg       0.96      0.96      0.96      2134
weighted avg       0.96      0.96      0.96      2134

Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.96      0.97      0.97      1079
           1       0.97      0.96      0.96      1055

    accuracy                           0.97      2134
   macro avg       0.97      0.97      0.97      2134
weighted avg       0.97      0.97      0.97      2134

              precision    recall  f1-score   support

           0       0.96      0.97      0.97      1079
           1       0.97      0.96      0.96      1055

    accuracy                           0.97      2134
   macro avg       0.97      0.97      0.97      2134
weighted avg       0.97      0.97      0.97      2134

Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.94      0.96      0.95      4135
           1       0.96      0.94      0.95      3856

    accuracy                           0.95      7991
   macro avg       0.95      0.95      0.95      7991
weighted avg       0.95      0.95      0.95      7991

              precision    recall  f1-score   support

           0       0.94      0.96      0.95      4135
           1       0.96      0.94      0.95      3856

    accuracy                           0.95      7991
   macro avg       0.95      0.95      0.95      7991
weighted avg       0.95      0.95      0.95      7991

completed
