[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '6a8db0a8'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '0e2d858e'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd19e0ade'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '7f38e7bb'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_10.000_DMSO_0.025 treatment_name: Thapsigargin_10.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: Thapsigargin_10.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'Thapsigargin_10.000_DMSO_0.025']
The dimensions of the data are: (323474, 1270)
Number of total missing values across all columns: 646948
Data Subset Is Off
Wells held out for testing: ['E09' 'L06']
Wells to use for training, validation, and testing ['E02' 'E03' 'E06' 'E07' 'E08' 'L07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.457218).  Saving model ...
	 Train_Loss: 0.5664 Train_Acc: 71.088 Val_Loss: 0.4572  BEST VAL Loss: 0.4572  Val_Acc: 79.965

Epoch 1: Validation loss decreased (0.457218 --> 0.418047).  Saving model ...
	 Train_Loss: 0.5015 Train_Acc: 80.175 Val_Loss: 0.4180  BEST VAL Loss: 0.4180  Val_Acc: 83.910

Epoch 2: Validation loss decreased (0.418047 --> 0.394076).  Saving model ...
	 Train_Loss: 0.4642 Train_Acc: 82.647 Val_Loss: 0.3941  BEST VAL Loss: 0.3941  Val_Acc: 85.275

Epoch 3: Validation loss decreased (0.394076 --> 0.377520).  Saving model ...
	 Train_Loss: 0.4402 Train_Acc: 83.777 Val_Loss: 0.3775  BEST VAL Loss: 0.3775  Val_Acc: 86.287

Epoch 4: Validation loss decreased (0.377520 --> 0.364937).  Saving model ...
	 Train_Loss: 0.4226 Train_Acc: 84.618 Val_Loss: 0.3649  BEST VAL Loss: 0.3649  Val_Acc: 86.873

Epoch 5: Validation loss decreased (0.364937 --> 0.354965).  Saving model ...
	 Train_Loss: 0.4090 Train_Acc: 85.211 Val_Loss: 0.3550  BEST VAL Loss: 0.3550  Val_Acc: 87.096

Epoch 6: Validation loss decreased (0.354965 --> 0.346627).  Saving model ...
	 Train_Loss: 0.3980 Train_Acc: 85.558 Val_Loss: 0.3466  BEST VAL Loss: 0.3466  Val_Acc: 87.505

Epoch 7: Validation loss decreased (0.346627 --> 0.339439).  Saving model ...
	 Train_Loss: 0.3887 Train_Acc: 86.086 Val_Loss: 0.3394  BEST VAL Loss: 0.3394  Val_Acc: 87.791

Epoch 8: Validation loss decreased (0.339439 --> 0.333144).  Saving model ...
	 Train_Loss: 0.3807 Train_Acc: 86.360 Val_Loss: 0.3331  BEST VAL Loss: 0.3331  Val_Acc: 88.242

Epoch 9: Validation loss decreased (0.333144 --> 0.327489).  Saving model ...
	 Train_Loss: 0.3737 Train_Acc: 86.667 Val_Loss: 0.3275  BEST VAL Loss: 0.3275  Val_Acc: 88.529

Epoch 10: Validation loss decreased (0.327489 --> 0.322355).  Saving model ...
	 Train_Loss: 0.3674 Train_Acc: 86.969 Val_Loss: 0.3224  BEST VAL Loss: 0.3224  Val_Acc: 88.773

Epoch 11: Validation loss decreased (0.322355 --> 0.317658).  Saving model ...
	 Train_Loss: 0.3618 Train_Acc: 87.237 Val_Loss: 0.3177  BEST VAL Loss: 0.3177  Val_Acc: 89.098

Epoch 12: Validation loss decreased (0.317658 --> 0.313325).  Saving model ...
	 Train_Loss: 0.3568 Train_Acc: 87.367 Val_Loss: 0.3133  BEST VAL Loss: 0.3133  Val_Acc: 89.266

Epoch 13: Validation loss decreased (0.313325 --> 0.309538).  Saving model ...
	 Train_Loss: 0.3521 Train_Acc: 87.596 Val_Loss: 0.3095  BEST VAL Loss: 0.3095  Val_Acc: 89.060

Epoch 14: Validation loss decreased (0.309538 --> 0.306012).  Saving model ...
	 Train_Loss: 0.3478 Train_Acc: 87.768 Val_Loss: 0.3060  BEST VAL Loss: 0.3060  Val_Acc: 89.199

Epoch 15: Validation loss decreased (0.306012 --> 0.302671).  Saving model ...
	 Train_Loss: 0.3438 Train_Acc: 87.967 Val_Loss: 0.3027  BEST VAL Loss: 0.3027  Val_Acc: 89.629

Epoch 16: Validation loss decreased (0.302671 --> 0.299497).  Saving model ...
	 Train_Loss: 0.3401 Train_Acc: 88.098 Val_Loss: 0.2995  BEST VAL Loss: 0.2995  Val_Acc: 89.793

Epoch 17: Validation loss decreased (0.299497 --> 0.296645).  Saving model ...
	 Train_Loss: 0.3368 Train_Acc: 88.196 Val_Loss: 0.2966  BEST VAL Loss: 0.2966  Val_Acc: 89.768

Epoch 18: Validation loss decreased (0.296645 --> 0.293969).  Saving model ...
	 Train_Loss: 0.3336 Train_Acc: 88.297 Val_Loss: 0.2940  BEST VAL Loss: 0.2940  Val_Acc: 89.890

Epoch 19: Validation loss decreased (0.293969 --> 0.291472).  Saving model ...
	 Train_Loss: 0.3306 Train_Acc: 88.340 Val_Loss: 0.2915  BEST VAL Loss: 0.2915  Val_Acc: 90.021

Epoch 20: Validation loss decreased (0.291472 --> 0.289093).  Saving model ...
	 Train_Loss: 0.3279 Train_Acc: 88.428 Val_Loss: 0.2891  BEST VAL Loss: 0.2891  Val_Acc: 89.991

Epoch 21: Validation loss decreased (0.289093 --> 0.286925).  Saving model ...
	 Train_Loss: 0.3253 Train_Acc: 88.509 Val_Loss: 0.2869  BEST VAL Loss: 0.2869  Val_Acc: 90.029

Epoch 22: Validation loss decreased (0.286925 --> 0.284816).  Saving model ...
	 Train_Loss: 0.3228 Train_Acc: 88.666 Val_Loss: 0.2848  BEST VAL Loss: 0.2848  Val_Acc: 90.257

Epoch 23: Validation loss decreased (0.284816 --> 0.282807).  Saving model ...
	 Train_Loss: 0.3205 Train_Acc: 88.677 Val_Loss: 0.2828  BEST VAL Loss: 0.2828  Val_Acc: 90.358

Epoch 24: Validation loss decreased (0.282807 --> 0.280926).  Saving model ...
	 Train_Loss: 0.3183 Train_Acc: 88.765 Val_Loss: 0.2809  BEST VAL Loss: 0.2809  Val_Acc: 90.295

Epoch 25: Validation loss decreased (0.280926 --> 0.279145).  Saving model ...
	 Train_Loss: 0.3162 Train_Acc: 88.776 Val_Loss: 0.2791  BEST VAL Loss: 0.2791  Val_Acc: 90.370

Epoch 26: Validation loss decreased (0.279145 --> 0.277489).  Saving model ...
	 Train_Loss: 0.3142 Train_Acc: 88.927 Val_Loss: 0.2775  BEST VAL Loss: 0.2775  Val_Acc: 90.282

Epoch 27: Validation loss decreased (0.277489 --> 0.275926).  Saving model ...
	 Train_Loss: 0.3123 Train_Acc: 89.003 Val_Loss: 0.2759  BEST VAL Loss: 0.2759  Val_Acc: 90.379

Epoch 28: Validation loss decreased (0.275926 --> 0.274326).  Saving model ...
	 Train_Loss: 0.3105 Train_Acc: 89.025 Val_Loss: 0.2743  BEST VAL Loss: 0.2743  Val_Acc: 90.484

Epoch 29: Validation loss decreased (0.274326 --> 0.272887).  Saving model ...
	 Train_Loss: 0.3087 Train_Acc: 89.113 Val_Loss: 0.2729  BEST VAL Loss: 0.2729  Val_Acc: 90.446

Epoch 30: Validation loss decreased (0.272887 --> 0.271517).  Saving model ...
	 Train_Loss: 0.3071 Train_Acc: 89.039 Val_Loss: 0.2715  BEST VAL Loss: 0.2715  Val_Acc: 90.404

Epoch 31: Validation loss decreased (0.271517 --> 0.270194).  Saving model ...
	 Train_Loss: 0.3055 Train_Acc: 89.175 Val_Loss: 0.2702  BEST VAL Loss: 0.2702  Val_Acc: 90.497

Epoch 32: Validation loss decreased (0.270194 --> 0.268930).  Saving model ...
	 Train_Loss: 0.3039 Train_Acc: 89.279 Val_Loss: 0.2689  BEST VAL Loss: 0.2689  Val_Acc: 90.526

Epoch 33: Validation loss decreased (0.268930 --> 0.267706).  Saving model ...
	 Train_Loss: 0.3025 Train_Acc: 89.340 Val_Loss: 0.2677  BEST VAL Loss: 0.2677  Val_Acc: 90.590

Epoch 34: Validation loss decreased (0.267706 --> 0.266531).  Saving model ...
	 Train_Loss: 0.3011 Train_Acc: 89.264 Val_Loss: 0.2665  BEST VAL Loss: 0.2665  Val_Acc: 90.598

Epoch 35: Validation loss decreased (0.266531 --> 0.265405).  Saving model ...
	 Train_Loss: 0.2997 Train_Acc: 89.321 Val_Loss: 0.2654  BEST VAL Loss: 0.2654  Val_Acc: 90.577

Epoch 36: Validation loss decreased (0.265405 --> 0.264304).  Saving model ...
	 Train_Loss: 0.2984 Train_Acc: 89.433 Val_Loss: 0.2643  BEST VAL Loss: 0.2643  Val_Acc: 90.640

Epoch 37: Validation loss decreased (0.264304 --> 0.263293).  Saving model ...
	 Train_Loss: 0.2971 Train_Acc: 89.441 Val_Loss: 0.2633  BEST VAL Loss: 0.2633  Val_Acc: 90.632

Epoch 38: Validation loss decreased (0.263293 --> 0.262284).  Saving model ...
	 Train_Loss: 0.2959 Train_Acc: 89.430 Val_Loss: 0.2623  BEST VAL Loss: 0.2623  Val_Acc: 90.762

Epoch 39: Validation loss decreased (0.262284 --> 0.261259).  Saving model ...
	 Train_Loss: 0.2947 Train_Acc: 89.527 Val_Loss: 0.2613  BEST VAL Loss: 0.2613  Val_Acc: 90.935

Epoch 40: Validation loss decreased (0.261259 --> 0.260325).  Saving model ...
	 Train_Loss: 0.2936 Train_Acc: 89.505 Val_Loss: 0.2603  BEST VAL Loss: 0.2603  Val_Acc: 90.737

Epoch 41: Validation loss decreased (0.260325 --> 0.259405).  Saving model ...
	 Train_Loss: 0.2925 Train_Acc: 89.615 Val_Loss: 0.2594  BEST VAL Loss: 0.2594  Val_Acc: 90.935

Epoch 42: Validation loss decreased (0.259405 --> 0.258482).  Saving model ...
	 Train_Loss: 0.2914 Train_Acc: 89.613 Val_Loss: 0.2585  BEST VAL Loss: 0.2585  Val_Acc: 90.885

Epoch 43: Validation loss decreased (0.258482 --> 0.257604).  Saving model ...
	 Train_Loss: 0.2903 Train_Acc: 89.626 Val_Loss: 0.2576  BEST VAL Loss: 0.2576  Val_Acc: 90.817

Epoch 44: Validation loss decreased (0.257604 --> 0.256761).  Saving model ...
	 Train_Loss: 0.2893 Train_Acc: 89.687 Val_Loss: 0.2568  BEST VAL Loss: 0.2568  Val_Acc: 90.838

Epoch 45: Validation loss decreased (0.256761 --> 0.255901).  Saving model ...
	 Train_Loss: 0.2883 Train_Acc: 89.710 Val_Loss: 0.2559  BEST VAL Loss: 0.2559  Val_Acc: 91.019

Epoch 46: Validation loss decreased (0.255901 --> 0.255093).  Saving model ...
	 Train_Loss: 0.2874 Train_Acc: 89.664 Val_Loss: 0.2551  BEST VAL Loss: 0.2551  Val_Acc: 91.019

Epoch 47: Validation loss decreased (0.255093 --> 0.254321).  Saving model ...
	 Train_Loss: 0.2864 Train_Acc: 89.729 Val_Loss: 0.2543  BEST VAL Loss: 0.2543  Val_Acc: 90.868

Epoch 48: Validation loss decreased (0.254321 --> 0.253566).  Saving model ...
	 Train_Loss: 0.2855 Train_Acc: 89.696 Val_Loss: 0.2536  BEST VAL Loss: 0.2536  Val_Acc: 91.078

Epoch 49: Validation loss decreased (0.253566 --> 0.252831).  Saving model ...
	 Train_Loss: 0.2846 Train_Acc: 89.818 Val_Loss: 0.2528  BEST VAL Loss: 0.2528  Val_Acc: 90.973

Epoch 50: Validation loss decreased (0.252831 --> 0.252129).  Saving model ...
	 Train_Loss: 0.2838 Train_Acc: 89.827 Val_Loss: 0.2521  BEST VAL Loss: 0.2521  Val_Acc: 91.062

Epoch 51: Validation loss decreased (0.252129 --> 0.251414).  Saving model ...
	 Train_Loss: 0.2830 Train_Acc: 89.794 Val_Loss: 0.2514  BEST VAL Loss: 0.2514  Val_Acc: 91.133

Epoch 52: Validation loss decreased (0.251414 --> 0.250773).  Saving model ...
	 Train_Loss: 0.2822 Train_Acc: 89.774 Val_Loss: 0.2508  BEST VAL Loss: 0.2508  Val_Acc: 91.019

Epoch 53: Validation loss decreased (0.250773 --> 0.250095).  Saving model ...
	 Train_Loss: 0.2814 Train_Acc: 89.903 Val_Loss: 0.2501  BEST VAL Loss: 0.2501  Val_Acc: 91.133

Epoch 54: Validation loss decreased (0.250095 --> 0.249444).  Saving model ...
	 Train_Loss: 0.2806 Train_Acc: 89.898 Val_Loss: 0.2494  BEST VAL Loss: 0.2494  Val_Acc: 91.217

Epoch 55: Validation loss decreased (0.249444 --> 0.248798).  Saving model ...
	 Train_Loss: 0.2799 Train_Acc: 89.952 Val_Loss: 0.2488  BEST VAL Loss: 0.2488  Val_Acc: 91.074

Epoch 56: Validation loss decreased (0.248798 --> 0.248198).  Saving model ...
	 Train_Loss: 0.2791 Train_Acc: 89.935 Val_Loss: 0.2482  BEST VAL Loss: 0.2482  Val_Acc: 91.095

Epoch 57: Validation loss decreased (0.248198 --> 0.247610).  Saving model ...
	 Train_Loss: 0.2784 Train_Acc: 89.980 Val_Loss: 0.2476  BEST VAL Loss: 0.2476  Val_Acc: 91.239

Epoch 58: Validation loss decreased (0.247610 --> 0.247037).  Saving model ...
	 Train_Loss: 0.2777 Train_Acc: 89.936 Val_Loss: 0.2470  BEST VAL Loss: 0.2470  Val_Acc: 91.146

Epoch 59: Validation loss decreased (0.247037 --> 0.246447).  Saving model ...
	 Train_Loss: 0.2770 Train_Acc: 89.969 Val_Loss: 0.2464  BEST VAL Loss: 0.2464  Val_Acc: 91.234

Epoch 60: Validation loss decreased (0.246447 --> 0.245902).  Saving model ...
	 Train_Loss: 0.2764 Train_Acc: 89.971 Val_Loss: 0.2459  BEST VAL Loss: 0.2459  Val_Acc: 91.260

Epoch 61: Validation loss decreased (0.245902 --> 0.245358).  Saving model ...
	 Train_Loss: 0.2757 Train_Acc: 90.041 Val_Loss: 0.2454  BEST VAL Loss: 0.2454  Val_Acc: 91.163

Epoch 62: Validation loss decreased (0.245358 --> 0.244837).  Saving model ...
	 Train_Loss: 0.2751 Train_Acc: 90.117 Val_Loss: 0.2448  BEST VAL Loss: 0.2448  Val_Acc: 91.196

Epoch 63: Validation loss decreased (0.244837 --> 0.244322).  Saving model ...
	 Train_Loss: 0.2744 Train_Acc: 90.091 Val_Loss: 0.2443  BEST VAL Loss: 0.2443  Val_Acc: 91.099

Epoch 64: Validation loss decreased (0.244322 --> 0.243806).  Saving model ...
	 Train_Loss: 0.2738 Train_Acc: 90.072 Val_Loss: 0.2438  BEST VAL Loss: 0.2438  Val_Acc: 91.302

Epoch 65: Validation loss decreased (0.243806 --> 0.243310).  Saving model ...
	 Train_Loss: 0.2732 Train_Acc: 90.134 Val_Loss: 0.2433  BEST VAL Loss: 0.2433  Val_Acc: 91.247

Epoch 66: Validation loss decreased (0.243310 --> 0.242838).  Saving model ...
	 Train_Loss: 0.2726 Train_Acc: 90.154 Val_Loss: 0.2428  BEST VAL Loss: 0.2428  Val_Acc: 91.260

Epoch 67: Validation loss decreased (0.242838 --> 0.242417).  Saving model ...
	 Train_Loss: 0.2720 Train_Acc: 90.151 Val_Loss: 0.2424  BEST VAL Loss: 0.2424  Val_Acc: 91.083

Epoch 68: Validation loss decreased (0.242417 --> 0.241955).  Saving model ...
	 Train_Loss: 0.2715 Train_Acc: 90.177 Val_Loss: 0.2420  BEST VAL Loss: 0.2420  Val_Acc: 91.213

Epoch 69: Validation loss decreased (0.241955 --> 0.241506).  Saving model ...
	 Train_Loss: 0.2709 Train_Acc: 90.224 Val_Loss: 0.2415  BEST VAL Loss: 0.2415  Val_Acc: 91.306

Epoch 70: Validation loss decreased (0.241506 --> 0.241112).  Saving model ...
	 Train_Loss: 0.2704 Train_Acc: 90.135 Val_Loss: 0.2411  BEST VAL Loss: 0.2411  Val_Acc: 91.116

Epoch 71: Validation loss decreased (0.241112 --> 0.240666).  Saving model ...
	 Train_Loss: 0.2698 Train_Acc: 90.227 Val_Loss: 0.2407  BEST VAL Loss: 0.2407  Val_Acc: 91.365

Epoch 72: Validation loss decreased (0.240666 --> 0.240233).  Saving model ...
	 Train_Loss: 0.2693 Train_Acc: 90.247 Val_Loss: 0.2402  BEST VAL Loss: 0.2402  Val_Acc: 91.298

Epoch 73: Validation loss decreased (0.240233 --> 0.239842).  Saving model ...
	 Train_Loss: 0.2688 Train_Acc: 90.302 Val_Loss: 0.2398  BEST VAL Loss: 0.2398  Val_Acc: 91.205

Epoch 74: Validation loss decreased (0.239842 --> 0.239433).  Saving model ...
	 Train_Loss: 0.2683 Train_Acc: 90.274 Val_Loss: 0.2394  BEST VAL Loss: 0.2394  Val_Acc: 91.390

Epoch 75: Validation loss decreased (0.239433 --> 0.239035).  Saving model ...
	 Train_Loss: 0.2678 Train_Acc: 90.237 Val_Loss: 0.2390  BEST VAL Loss: 0.2390  Val_Acc: 91.323

Epoch 76: Validation loss decreased (0.239035 --> 0.238650).  Saving model ...
	 Train_Loss: 0.2673 Train_Acc: 90.215 Val_Loss: 0.2387  BEST VAL Loss: 0.2387  Val_Acc: 91.403

Epoch 77: Validation loss decreased (0.238650 --> 0.238260).  Saving model ...
	 Train_Loss: 0.2668 Train_Acc: 90.204 Val_Loss: 0.2383  BEST VAL Loss: 0.2383  Val_Acc: 91.331

Epoch 78: Validation loss decreased (0.238260 --> 0.237907).  Saving model ...
	 Train_Loss: 0.2664 Train_Acc: 90.311 Val_Loss: 0.2379  BEST VAL Loss: 0.2379  Val_Acc: 91.357

Epoch 79: Validation loss decreased (0.237907 --> 0.237536).  Saving model ...
	 Train_Loss: 0.2659 Train_Acc: 90.359 Val_Loss: 0.2375  BEST VAL Loss: 0.2375  Val_Acc: 91.260

Epoch 80: Validation loss decreased (0.237536 --> 0.237180).  Saving model ...
	 Train_Loss: 0.2654 Train_Acc: 90.364 Val_Loss: 0.2372  BEST VAL Loss: 0.2372  Val_Acc: 91.352

Epoch 81: Validation loss decreased (0.237180 --> 0.236827).  Saving model ...
	 Train_Loss: 0.2650 Train_Acc: 90.333 Val_Loss: 0.2368  BEST VAL Loss: 0.2368  Val_Acc: 91.352

Epoch 82: Validation loss decreased (0.236827 --> 0.236481).  Saving model ...
	 Train_Loss: 0.2645 Train_Acc: 90.321 Val_Loss: 0.2365  BEST VAL Loss: 0.2365  Val_Acc: 91.348

Epoch 83: Validation loss decreased (0.236481 --> 0.236139).  Saving model ...
	 Train_Loss: 0.2641 Train_Acc: 90.283 Val_Loss: 0.2361  BEST VAL Loss: 0.2361  Val_Acc: 91.357

Epoch 84: Validation loss decreased (0.236139 --> 0.235806).  Saving model ...
	 Train_Loss: 0.2637 Train_Acc: 90.365 Val_Loss: 0.2358  BEST VAL Loss: 0.2358  Val_Acc: 91.196

Epoch 85: Validation loss decreased (0.235806 --> 0.235474).  Saving model ...
	 Train_Loss: 0.2632 Train_Acc: 90.447 Val_Loss: 0.2355  BEST VAL Loss: 0.2355  Val_Acc: 91.411

Epoch 86: Validation loss decreased (0.235474 --> 0.235178).  Saving model ...
	 Train_Loss: 0.2628 Train_Acc: 90.364 Val_Loss: 0.2352  BEST VAL Loss: 0.2352  Val_Acc: 91.264

Epoch 87: Validation loss decreased (0.235178 --> 0.234841).  Saving model ...
	 Train_Loss: 0.2624 Train_Acc: 90.374 Val_Loss: 0.2348  BEST VAL Loss: 0.2348  Val_Acc: 91.470

Epoch 88: Validation loss decreased (0.234841 --> 0.234515).  Saving model ...
	 Train_Loss: 0.2620 Train_Acc: 90.409 Val_Loss: 0.2345  BEST VAL Loss: 0.2345  Val_Acc: 91.310

Epoch 89: Validation loss decreased (0.234515 --> 0.234216).  Saving model ...
	 Train_Loss: 0.2616 Train_Acc: 90.447 Val_Loss: 0.2342  BEST VAL Loss: 0.2342  Val_Acc: 91.420

Epoch 90: Validation loss decreased (0.234216 --> 0.233907).  Saving model ...
	 Train_Loss: 0.2613 Train_Acc: 90.398 Val_Loss: 0.2339  BEST VAL Loss: 0.2339  Val_Acc: 91.386

Epoch 91: Validation loss decreased (0.233907 --> 0.233614).  Saving model ...
	 Train_Loss: 0.2609 Train_Acc: 90.451 Val_Loss: 0.2336  BEST VAL Loss: 0.2336  Val_Acc: 91.432

Epoch 92: Validation loss decreased (0.233614 --> 0.233319).  Saving model ...
	 Train_Loss: 0.2605 Train_Acc: 90.557 Val_Loss: 0.2333  BEST VAL Loss: 0.2333  Val_Acc: 91.508

Epoch 93: Validation loss decreased (0.233319 --> 0.233048).  Saving model ...
	 Train_Loss: 0.2601 Train_Acc: 90.487 Val_Loss: 0.2330  BEST VAL Loss: 0.2330  Val_Acc: 91.365

Epoch 94: Validation loss decreased (0.233048 --> 0.232776).  Saving model ...
	 Train_Loss: 0.2597 Train_Acc: 90.475 Val_Loss: 0.2328  BEST VAL Loss: 0.2328  Val_Acc: 91.298

Epoch 95: Validation loss decreased (0.232776 --> 0.232491).  Saving model ...
	 Train_Loss: 0.2594 Train_Acc: 90.531 Val_Loss: 0.2325  BEST VAL Loss: 0.2325  Val_Acc: 91.550

Epoch 96: Validation loss decreased (0.232491 --> 0.232221).  Saving model ...
	 Train_Loss: 0.2590 Train_Acc: 90.522 Val_Loss: 0.2322  BEST VAL Loss: 0.2322  Val_Acc: 91.500

Epoch 97: Validation loss decreased (0.232221 --> 0.231958).  Saving model ...
	 Train_Loss: 0.2587 Train_Acc: 90.513 Val_Loss: 0.2320  BEST VAL Loss: 0.2320  Val_Acc: 91.449

Epoch 98: Validation loss decreased (0.231958 --> 0.231682).  Saving model ...
	 Train_Loss: 0.2583 Train_Acc: 90.527 Val_Loss: 0.2317  BEST VAL Loss: 0.2317  Val_Acc: 91.466

Epoch 99: Validation loss decreased (0.231682 --> 0.231439).  Saving model ...
	 Train_Loss: 0.2580 Train_Acc: 90.522 Val_Loss: 0.2314  BEST VAL Loss: 0.2314  Val_Acc: 91.319

LPS_10.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.92      0.93     92173
           1       0.93      0.93      0.93     97655

    accuracy                           0.93    189828
   macro avg       0.93      0.93      0.93    189828
weighted avg       0.93      0.93      0.93    189828

LPS_10.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.91      0.91      0.91     11522
           1       0.91      0.92      0.92     12207

    accuracy                           0.91     23729
   macro avg       0.91      0.91      0.91     23729
weighted avg       0.91      0.91      0.91     23729

LPS_10.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.91      0.91      0.91     11522
           1       0.91      0.92      0.92     12207

    accuracy                           0.91     23729
   macro avg       0.91      0.91      0.91     23729
weighted avg       0.91      0.91      0.91     23729

              precision    recall  f1-score   support

           0       0.91      0.91      0.91     11522
           1       0.91      0.92      0.92     12207

    accuracy                           0.91     23729
   macro avg       0.91      0.91      0.91     23729
weighted avg       0.91      0.91      0.91     23729

LPS_10.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.87      0.74      0.80     41273
           1       0.79      0.89      0.84     44915

    accuracy                           0.82     86188
   macro avg       0.83      0.82      0.82     86188
weighted avg       0.83      0.82      0.82     86188

              precision    recall  f1-score   support

           0       0.87      0.74      0.80     41273
           1       0.79      0.89      0.84     44915

    accuracy                           0.82     86188
   macro avg       0.83      0.82      0.82     86188
weighted avg       0.83      0.82      0.82     86188

completed
