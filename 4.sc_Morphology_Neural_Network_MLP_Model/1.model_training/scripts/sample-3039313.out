[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '366aae7a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '21add88f'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '2f68a32a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e48b3057'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_1.000_DMSO_0.025 treatment_name: H2O2_100.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_1.000_DMSO_0.025
TREATMENT_NAME: H2O2_100.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (43358, 1276)
Number of total missing values across all columns: 86716
Data Subset Is Off
Wells held out for testing: ['D21' 'H22']
Wells to use for training, validation, and testing ['D16' 'D17' 'H18' 'H19' 'D20' 'H23' 'I18' 'I19' 'I22' 'I23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.529120).  Saving model ...
	 Train_Loss: 0.6285 Train_Acc: 68.288 Val_Loss: 0.5291  BEST VAL Loss: 0.5291  Val_Acc: 73.568

Epoch 1: Validation loss decreased (0.529120 --> 0.519867).  Saving model ...
	 Train_Loss: 0.5868 Train_Acc: 71.494 Val_Loss: 0.5199  BEST VAL Loss: 0.5199  Val_Acc: 75.638

Epoch 2: Validation loss decreased (0.519867 --> 0.505855).  Saving model ...
	 Train_Loss: 0.5652 Train_Acc: 72.831 Val_Loss: 0.5059  BEST VAL Loss: 0.5059  Val_Acc: 76.602

Epoch 3: Validation loss decreased (0.505855 --> 0.500408).  Saving model ...
	 Train_Loss: 0.5498 Train_Acc: 73.565 Val_Loss: 0.5004  BEST VAL Loss: 0.5004  Val_Acc: 76.829

Epoch 4: Validation loss decreased (0.500408 --> 0.494972).  Saving model ...
	 Train_Loss: 0.5366 Train_Acc: 74.295 Val_Loss: 0.4950  BEST VAL Loss: 0.4950  Val_Acc: 77.708

Epoch 5: Validation loss decreased (0.494972 --> 0.491467).  Saving model ...
	 Train_Loss: 0.5269 Train_Acc: 74.270 Val_Loss: 0.4915  BEST VAL Loss: 0.4915  Val_Acc: 77.964

Epoch 6: Validation loss decreased (0.491467 --> 0.488319).  Saving model ...
	 Train_Loss: 0.5186 Train_Acc: 74.746 Val_Loss: 0.4883  BEST VAL Loss: 0.4883  Val_Acc: 78.417

Epoch 7: Validation loss decreased (0.488319 --> 0.485607).  Saving model ...
	 Train_Loss: 0.5119 Train_Acc: 74.802 Val_Loss: 0.4856  BEST VAL Loss: 0.4856  Val_Acc: 78.417

Epoch 8: Validation loss did not decrease
	 Train_Loss: 0.5061 Train_Acc: 75.139 Val_Loss: 0.4862  BEST VAL Loss: 0.4856  Val_Acc: 78.701

Epoch 9: Validation loss decreased (0.485607 --> 0.483908).  Saving model ...
	 Train_Loss: 0.5011 Train_Acc: 75.125 Val_Loss: 0.4839  BEST VAL Loss: 0.4839  Val_Acc: 78.729

Epoch 10: Validation loss decreased (0.483908 --> 0.481781).  Saving model ...
	 Train_Loss: 0.4967 Train_Acc: 75.263 Val_Loss: 0.4818  BEST VAL Loss: 0.4818  Val_Acc: 79.410

Epoch 11: Validation loss decreased (0.481781 --> 0.479674).  Saving model ...
	 Train_Loss: 0.4931 Train_Acc: 74.976 Val_Loss: 0.4797  BEST VAL Loss: 0.4797  Val_Acc: 79.410

Epoch 12: Validation loss decreased (0.479674 --> 0.478191).  Saving model ...
	 Train_Loss: 0.4895 Train_Acc: 75.512 Val_Loss: 0.4782  BEST VAL Loss: 0.4782  Val_Acc: 78.928

Epoch 13: Validation loss decreased (0.478191 --> 0.476421).  Saving model ...
	 Train_Loss: 0.4866 Train_Acc: 75.199 Val_Loss: 0.4764  BEST VAL Loss: 0.4764  Val_Acc: 78.871

Epoch 14: Validation loss decreased (0.476421 --> 0.475930).  Saving model ...
	 Train_Loss: 0.4841 Train_Acc: 75.277 Val_Loss: 0.4759  BEST VAL Loss: 0.4759  Val_Acc: 79.325

Epoch 15: Validation loss decreased (0.475930 --> 0.475512).  Saving model ...
	 Train_Loss: 0.4812 Train_Acc: 76.004 Val_Loss: 0.4755  BEST VAL Loss: 0.4755  Val_Acc: 79.779

Epoch 16: Validation loss decreased (0.475512 --> 0.474561).  Saving model ...
	 Train_Loss: 0.4789 Train_Acc: 75.848 Val_Loss: 0.4746  BEST VAL Loss: 0.4746  Val_Acc: 79.297

Epoch 17: Validation loss decreased (0.474561 --> 0.473909).  Saving model ...
	 Train_Loss: 0.4766 Train_Acc: 75.816 Val_Loss: 0.4739  BEST VAL Loss: 0.4739  Val_Acc: 79.665

Epoch 18: Validation loss decreased (0.473909 --> 0.473004).  Saving model ...
	 Train_Loss: 0.4745 Train_Acc: 75.891 Val_Loss: 0.4730  BEST VAL Loss: 0.4730  Val_Acc: 79.070

Epoch 19: Validation loss decreased (0.473004 --> 0.472372).  Saving model ...
	 Train_Loss: 0.4727 Train_Acc: 75.799 Val_Loss: 0.4724  BEST VAL Loss: 0.4724  Val_Acc: 79.126

Epoch 20: Validation loss decreased (0.472372 --> 0.472067).  Saving model ...
	 Train_Loss: 0.4709 Train_Acc: 75.880 Val_Loss: 0.4721  BEST VAL Loss: 0.4721  Val_Acc: 79.325

Epoch 21: Validation loss did not decrease
	 Train_Loss: 0.4692 Train_Acc: 76.157 Val_Loss: 0.4723  BEST VAL Loss: 0.4721  Val_Acc: 79.495

Epoch 22: Validation loss decreased (0.472067 --> 0.472004).  Saving model ...
	 Train_Loss: 0.4677 Train_Acc: 76.047 Val_Loss: 0.4720  BEST VAL Loss: 0.4720  Val_Acc: 79.268

Epoch 23: Validation loss decreased (0.472004 --> 0.471780).  Saving model ...
	 Train_Loss: 0.4662 Train_Acc: 75.877 Val_Loss: 0.4718  BEST VAL Loss: 0.4718  Val_Acc: 79.268

Epoch 24: Validation loss decreased (0.471780 --> 0.471665).  Saving model ...
	 Train_Loss: 0.4648 Train_Acc: 76.157 Val_Loss: 0.4717  BEST VAL Loss: 0.4717  Val_Acc: 79.467

Epoch 25: Validation loss decreased (0.471665 --> 0.471520).  Saving model ...
	 Train_Loss: 0.4635 Train_Acc: 75.976 Val_Loss: 0.4715  BEST VAL Loss: 0.4715  Val_Acc: 79.864

Epoch 26: Validation loss decreased (0.471520 --> 0.471465).  Saving model ...
	 Train_Loss: 0.4623 Train_Acc: 76.295 Val_Loss: 0.4715  BEST VAL Loss: 0.4715  Val_Acc: 79.410

Epoch 27: Validation loss decreased (0.471465 --> 0.471442).  Saving model ...
	 Train_Loss: 0.4612 Train_Acc: 75.965 Val_Loss: 0.4714  BEST VAL Loss: 0.4714  Val_Acc: 79.325

Epoch 28: Validation loss decreased (0.471442 --> 0.470701).  Saving model ...
	 Train_Loss: 0.4599 Train_Acc: 76.426 Val_Loss: 0.4707  BEST VAL Loss: 0.4707  Val_Acc: 80.062

Epoch 29: Validation loss decreased (0.470701 --> 0.470474).  Saving model ...
	 Train_Loss: 0.4589 Train_Acc: 76.104 Val_Loss: 0.4705  BEST VAL Loss: 0.4705  Val_Acc: 79.098

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.4579 Train_Acc: 76.111 Val_Loss: 0.4708  BEST VAL Loss: 0.4705  Val_Acc: 79.212

Epoch 31: Validation loss decreased (0.470474 --> 0.470402).  Saving model ...
	 Train_Loss: 0.4570 Train_Acc: 76.090 Val_Loss: 0.4704  BEST VAL Loss: 0.4704  Val_Acc: 80.204

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.4562 Train_Acc: 76.111 Val_Loss: 0.4706  BEST VAL Loss: 0.4704  Val_Acc: 79.609

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.4553 Train_Acc: 76.391 Val_Loss: 0.4709  BEST VAL Loss: 0.4704  Val_Acc: 79.722

Epoch 34: Validation loss did not decrease
	 Train_Loss: 0.4544 Train_Acc: 76.019 Val_Loss: 0.4706  BEST VAL Loss: 0.4704  Val_Acc: 79.665

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.4535 Train_Acc: 76.238 Val_Loss: 0.4706  BEST VAL Loss: 0.4704  Val_Acc: 79.495

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.4527 Train_Acc: 76.448 Val_Loss: 0.4707  BEST VAL Loss: 0.4704  Val_Acc: 80.176

Epoch 37: Validation loss decreased (0.470402 --> 0.470387).  Saving model ...
	 Train_Loss: 0.4520 Train_Acc: 76.221 Val_Loss: 0.4704  BEST VAL Loss: 0.4704  Val_Acc: 79.892

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.4512 Train_Acc: 76.394 Val_Loss: 0.4706  BEST VAL Loss: 0.4704  Val_Acc: 80.091

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.4505 Train_Acc: 76.363 Val_Loss: 0.4707  BEST VAL Loss: 0.4704  Val_Acc: 79.070

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.4497 Train_Acc: 76.405 Val_Loss: 0.4707  BEST VAL Loss: 0.4704  Val_Acc: 80.119

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.4490 Train_Acc: 76.671 Val_Loss: 0.4706  BEST VAL Loss: 0.4704  Val_Acc: 79.580

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.4484 Train_Acc: 76.235 Val_Loss: 0.4706  BEST VAL Loss: 0.4704  Val_Acc: 79.977

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.4477 Train_Acc: 76.760 Val_Loss: 0.4706  BEST VAL Loss: 0.4704  Val_Acc: 79.892

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.4471 Train_Acc: 76.724 Val_Loss: 0.4705  BEST VAL Loss: 0.4704  Val_Acc: 79.892

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.4465 Train_Acc: 76.377 Val_Loss: 0.4705  BEST VAL Loss: 0.4704  Val_Acc: 79.779

Epoch 46: Validation loss decreased (0.470387 --> 0.470376).  Saving model ...
	 Train_Loss: 0.4460 Train_Acc: 76.217 Val_Loss: 0.4704  BEST VAL Loss: 0.4704  Val_Acc: 80.403

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.4454 Train_Acc: 76.338 Val_Loss: 0.4705  BEST VAL Loss: 0.4704  Val_Acc: 79.609

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.4449 Train_Acc: 76.816 Val_Loss: 0.4705  BEST VAL Loss: 0.4704  Val_Acc: 79.665

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.4443 Train_Acc: 76.423 Val_Loss: 0.4707  BEST VAL Loss: 0.4704  Val_Acc: 79.864

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.4438 Train_Acc: 76.292 Val_Loss: 0.4708  BEST VAL Loss: 0.4704  Val_Acc: 79.524

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.4433 Train_Acc: 76.455 Val_Loss: 0.4706  BEST VAL Loss: 0.4704  Val_Acc: 79.807

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.4428 Train_Acc: 76.657 Val_Loss: 0.4705  BEST VAL Loss: 0.4704  Val_Acc: 79.892

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.4423 Train_Acc: 76.554 Val_Loss: 0.4706  BEST VAL Loss: 0.4704  Val_Acc: 80.204

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.4418 Train_Acc: 76.891 Val_Loss: 0.4708  BEST VAL Loss: 0.4704  Val_Acc: 79.864

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.4413 Train_Acc: 76.600 Val_Loss: 0.4709  BEST VAL Loss: 0.4704  Val_Acc: 79.126

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.4408 Train_Acc: 76.533 Val_Loss: 0.4709  BEST VAL Loss: 0.4704  Val_Acc: 80.233

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.4403 Train_Acc: 76.742 Val_Loss: 0.4710  BEST VAL Loss: 0.4704  Val_Acc: 80.516

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.4399 Train_Acc: 76.494 Val_Loss: 0.4709  BEST VAL Loss: 0.4704  Val_Acc: 79.892

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.4394 Train_Acc: 76.792 Val_Loss: 0.4710  BEST VAL Loss: 0.4704  Val_Acc: 79.183

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.4390 Train_Acc: 76.824 Val_Loss: 0.4710  BEST VAL Loss: 0.4704  Val_Acc: 79.836

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.4386 Train_Acc: 76.618 Val_Loss: 0.4713  BEST VAL Loss: 0.4704  Val_Acc: 79.949

Epoch 62: Validation loss did not decrease
Early stopped at epoch : 62
LPS_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.83      0.93      0.88     18174
           1       0.84      0.66      0.74     10027

    accuracy                           0.83     28201
   macro avg       0.84      0.80      0.81     28201
weighted avg       0.84      0.83      0.83     28201

LPS_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.81      0.91      0.86      2272
           1       0.79      0.62      0.69      1254

    accuracy                           0.80      3526
   macro avg       0.80      0.76      0.77      3526
weighted avg       0.80      0.80      0.80      3526

LPS_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.82      0.91      0.86      2272
           1       0.80      0.63      0.70      1254

    accuracy                           0.81      3526
   macro avg       0.81      0.77      0.78      3526
weighted avg       0.81      0.81      0.80      3526

              precision    recall  f1-score   support

           0       0.82      0.91      0.86      2272
           1       0.80      0.63      0.70      1254

    accuracy                           0.81      3526
   macro avg       0.81      0.77      0.78      3526
weighted avg       0.81      0.81      0.80      3526

LPS_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.55      0.86      0.67      4182
           1       0.63      0.27      0.38      3923

    accuracy                           0.57      8105
   macro avg       0.59      0.56      0.52      8105
weighted avg       0.59      0.57      0.53      8105

              precision    recall  f1-score   support

           0       0.55      0.86      0.67      4182
           1       0.63      0.27      0.38      3923

    accuracy                           0.57      8105
   macro avg       0.59      0.56      0.52      8105
weighted avg       0.59      0.57      0.53      8105

completed
