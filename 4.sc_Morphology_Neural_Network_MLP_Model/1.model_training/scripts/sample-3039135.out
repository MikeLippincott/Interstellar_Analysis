[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '49169142'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'a1294e6b'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'edde1595'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '71a62685'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_1.000_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_1.000_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_1.000_DMSO_0.025']
The dimensions of the data are: (32317, 1276)
Number of total missing values across all columns: 64634
Data Subset Is Off
Wells held out for testing: ['B20' 'D21']
Wells to use for training, validation, and testing ['B16' 'D16' 'B17' 'D17' 'D20' 'B21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.642231).  Saving model ...
	 Train_Loss: 0.6694 Train_Acc: 58.816 Val_Loss: 0.6422  BEST VAL Loss: 0.6422  Val_Acc: 65.059

Epoch 1: Validation loss decreased (0.642231 --> 0.631793).  Saving model ...
	 Train_Loss: 0.6513 Train_Acc: 64.197 Val_Loss: 0.6318  BEST VAL Loss: 0.6318  Val_Acc: 66.599

Epoch 2: Validation loss decreased (0.631793 --> 0.624230).  Saving model ...
	 Train_Loss: 0.6375 Train_Acc: 66.700 Val_Loss: 0.6242  BEST VAL Loss: 0.6242  Val_Acc: 67.734

Epoch 3: Validation loss decreased (0.624230 --> 0.617824).  Saving model ...
	 Train_Loss: 0.6271 Train_Acc: 67.957 Val_Loss: 0.6178  BEST VAL Loss: 0.6178  Val_Acc: 68.464

Epoch 4: Validation loss decreased (0.617824 --> 0.612445).  Saving model ...
	 Train_Loss: 0.6187 Train_Acc: 68.697 Val_Loss: 0.6124  BEST VAL Loss: 0.6124  Val_Acc: 69.315

Epoch 5: Validation loss decreased (0.612445 --> 0.607289).  Saving model ...
	 Train_Loss: 0.6114 Train_Acc: 69.741 Val_Loss: 0.6073  BEST VAL Loss: 0.6073  Val_Acc: 69.964

Epoch 6: Validation loss decreased (0.607289 --> 0.602332).  Saving model ...
	 Train_Loss: 0.6048 Train_Acc: 70.470 Val_Loss: 0.6023  BEST VAL Loss: 0.6023  Val_Acc: 70.734

Epoch 7: Validation loss decreased (0.602332 --> 0.598220).  Saving model ...
	 Train_Loss: 0.5990 Train_Acc: 71.408 Val_Loss: 0.5982  BEST VAL Loss: 0.5982  Val_Acc: 71.382

Epoch 8: Validation loss decreased (0.598220 --> 0.594446).  Saving model ...
	 Train_Loss: 0.5937 Train_Acc: 71.762 Val_Loss: 0.5944  BEST VAL Loss: 0.5944  Val_Acc: 71.788

Epoch 9: Validation loss decreased (0.594446 --> 0.590955).  Saving model ...
	 Train_Loss: 0.5889 Train_Acc: 72.000 Val_Loss: 0.5910  BEST VAL Loss: 0.5910  Val_Acc: 71.950

Epoch 10: Validation loss decreased (0.590955 --> 0.587836).  Saving model ...
	 Train_Loss: 0.5845 Train_Acc: 72.396 Val_Loss: 0.5878  BEST VAL Loss: 0.5878  Val_Acc: 72.396

Epoch 11: Validation loss decreased (0.587836 --> 0.584898).  Saving model ...
	 Train_Loss: 0.5802 Train_Acc: 73.130 Val_Loss: 0.5849  BEST VAL Loss: 0.5849  Val_Acc: 72.720

Epoch 12: Validation loss decreased (0.584898 --> 0.582183).  Saving model ...
	 Train_Loss: 0.5767 Train_Acc: 73.140 Val_Loss: 0.5822  BEST VAL Loss: 0.5822  Val_Acc: 72.274

Epoch 13: Validation loss decreased (0.582183 --> 0.579955).  Saving model ...
	 Train_Loss: 0.5733 Train_Acc: 73.379 Val_Loss: 0.5800  BEST VAL Loss: 0.5800  Val_Acc: 72.071

Epoch 14: Validation loss decreased (0.579955 --> 0.577739).  Saving model ...
	 Train_Loss: 0.5700 Train_Acc: 73.693 Val_Loss: 0.5777  BEST VAL Loss: 0.5777  Val_Acc: 72.477

Epoch 15: Validation loss decreased (0.577739 --> 0.575426).  Saving model ...
	 Train_Loss: 0.5670 Train_Acc: 73.728 Val_Loss: 0.5754  BEST VAL Loss: 0.5754  Val_Acc: 73.247

Epoch 16: Validation loss decreased (0.575426 --> 0.573334).  Saving model ...
	 Train_Loss: 0.5641 Train_Acc: 74.503 Val_Loss: 0.5733  BEST VAL Loss: 0.5733  Val_Acc: 73.247

Epoch 17: Validation loss decreased (0.573334 --> 0.571314).  Saving model ...
	 Train_Loss: 0.5612 Train_Acc: 74.691 Val_Loss: 0.5713  BEST VAL Loss: 0.5713  Val_Acc: 73.693

Epoch 18: Validation loss decreased (0.571314 --> 0.569344).  Saving model ...
	 Train_Loss: 0.5585 Train_Acc: 74.757 Val_Loss: 0.5693  BEST VAL Loss: 0.5693  Val_Acc: 74.058

Epoch 19: Validation loss decreased (0.569344 --> 0.567462).  Saving model ...
	 Train_Loss: 0.5558 Train_Acc: 75.086 Val_Loss: 0.5675  BEST VAL Loss: 0.5675  Val_Acc: 74.260

Epoch 20: Validation loss decreased (0.567462 --> 0.565687).  Saving model ...
	 Train_Loss: 0.5534 Train_Acc: 74.995 Val_Loss: 0.5657  BEST VAL Loss: 0.5657  Val_Acc: 74.747

Epoch 21: Validation loss decreased (0.565687 --> 0.564063).  Saving model ...
	 Train_Loss: 0.5509 Train_Acc: 75.892 Val_Loss: 0.5641  BEST VAL Loss: 0.5641  Val_Acc: 73.774

Epoch 22: Validation loss decreased (0.564063 --> 0.562535).  Saving model ...
	 Train_Loss: 0.5486 Train_Acc: 75.790 Val_Loss: 0.5625  BEST VAL Loss: 0.5625  Val_Acc: 74.139

Epoch 23: Validation loss decreased (0.562535 --> 0.561019).  Saving model ...
	 Train_Loss: 0.5465 Train_Acc: 75.603 Val_Loss: 0.5610  BEST VAL Loss: 0.5610  Val_Acc: 74.422

Epoch 24: Validation loss decreased (0.561019 --> 0.559578).  Saving model ...
	 Train_Loss: 0.5442 Train_Acc: 76.094 Val_Loss: 0.5596  BEST VAL Loss: 0.5596  Val_Acc: 74.503

Epoch 25: Validation loss decreased (0.559578 --> 0.558179).  Saving model ...
	 Train_Loss: 0.5421 Train_Acc: 76.150 Val_Loss: 0.5582  BEST VAL Loss: 0.5582  Val_Acc: 74.382

Epoch 26: Validation loss decreased (0.558179 --> 0.556962).  Saving model ...
	 Train_Loss: 0.5402 Train_Acc: 76.049 Val_Loss: 0.5570  BEST VAL Loss: 0.5570  Val_Acc: 74.544

Epoch 27: Validation loss decreased (0.556962 --> 0.555867).  Saving model ...
	 Train_Loss: 0.5383 Train_Acc: 76.388 Val_Loss: 0.5559  BEST VAL Loss: 0.5559  Val_Acc: 74.503

Epoch 28: Validation loss decreased (0.555867 --> 0.554754).  Saving model ...
	 Train_Loss: 0.5364 Train_Acc: 76.510 Val_Loss: 0.5548  BEST VAL Loss: 0.5548  Val_Acc: 75.030

Epoch 29: Validation loss decreased (0.554754 --> 0.553673).  Saving model ...
	 Train_Loss: 0.5345 Train_Acc: 76.459 Val_Loss: 0.5537  BEST VAL Loss: 0.5537  Val_Acc: 75.638

Epoch 30: Validation loss decreased (0.553673 --> 0.552640).  Saving model ...
	 Train_Loss: 0.5327 Train_Acc: 77.245 Val_Loss: 0.5526  BEST VAL Loss: 0.5526  Val_Acc: 75.111

Epoch 31: Validation loss decreased (0.552640 --> 0.551717).  Saving model ...
	 Train_Loss: 0.5310 Train_Acc: 76.490 Val_Loss: 0.5517  BEST VAL Loss: 0.5517  Val_Acc: 74.990

Epoch 32: Validation loss decreased (0.551717 --> 0.550761).  Saving model ...
	 Train_Loss: 0.5294 Train_Acc: 76.733 Val_Loss: 0.5508  BEST VAL Loss: 0.5508  Val_Acc: 75.557

Epoch 33: Validation loss decreased (0.550761 --> 0.549971).  Saving model ...
	 Train_Loss: 0.5277 Train_Acc: 77.108 Val_Loss: 0.5500  BEST VAL Loss: 0.5500  Val_Acc: 75.071

Epoch 34: Validation loss decreased (0.549971 --> 0.549151).  Saving model ...
	 Train_Loss: 0.5262 Train_Acc: 76.789 Val_Loss: 0.5492  BEST VAL Loss: 0.5492  Val_Acc: 75.517

Epoch 35: Validation loss decreased (0.549151 --> 0.548355).  Saving model ...
	 Train_Loss: 0.5249 Train_Acc: 77.052 Val_Loss: 0.5484  BEST VAL Loss: 0.5484  Val_Acc: 75.719

Epoch 36: Validation loss decreased (0.548355 --> 0.547556).  Saving model ...
	 Train_Loss: 0.5235 Train_Acc: 77.402 Val_Loss: 0.5476  BEST VAL Loss: 0.5476  Val_Acc: 75.801

Epoch 37: Validation loss decreased (0.547556 --> 0.546824).  Saving model ...
	 Train_Loss: 0.5221 Train_Acc: 77.518 Val_Loss: 0.5468  BEST VAL Loss: 0.5468  Val_Acc: 74.828

Epoch 38: Validation loss decreased (0.546824 --> 0.546087).  Saving model ...
	 Train_Loss: 0.5208 Train_Acc: 77.194 Val_Loss: 0.5461  BEST VAL Loss: 0.5461  Val_Acc: 75.517

Epoch 39: Validation loss decreased (0.546087 --> 0.545353).  Saving model ...
	 Train_Loss: 0.5194 Train_Acc: 78.015 Val_Loss: 0.5454  BEST VAL Loss: 0.5454  Val_Acc: 75.436

Epoch 40: Validation loss decreased (0.545353 --> 0.544682).  Saving model ...
	 Train_Loss: 0.5181 Train_Acc: 77.858 Val_Loss: 0.5447  BEST VAL Loss: 0.5447  Val_Acc: 75.071

Epoch 41: Validation loss decreased (0.544682 --> 0.544009).  Saving model ...
	 Train_Loss: 0.5168 Train_Acc: 77.589 Val_Loss: 0.5440  BEST VAL Loss: 0.5440  Val_Acc: 75.193

Epoch 42: Validation loss decreased (0.544009 --> 0.543429).  Saving model ...
	 Train_Loss: 0.5156 Train_Acc: 77.777 Val_Loss: 0.5434  BEST VAL Loss: 0.5434  Val_Acc: 75.436

Epoch 43: Validation loss decreased (0.543429 --> 0.542850).  Saving model ...
	 Train_Loss: 0.5143 Train_Acc: 78.162 Val_Loss: 0.5429  BEST VAL Loss: 0.5429  Val_Acc: 75.233

Epoch 44: Validation loss decreased (0.542850 --> 0.542305).  Saving model ...
	 Train_Loss: 0.5130 Train_Acc: 78.253 Val_Loss: 0.5423  BEST VAL Loss: 0.5423  Val_Acc: 75.314

Epoch 45: Validation loss decreased (0.542305 --> 0.541769).  Saving model ...
	 Train_Loss: 0.5119 Train_Acc: 78.228 Val_Loss: 0.5418  BEST VAL Loss: 0.5418  Val_Acc: 75.030

Epoch 46: Validation loss decreased (0.541769 --> 0.541267).  Saving model ...
	 Train_Loss: 0.5108 Train_Acc: 77.924 Val_Loss: 0.5413  BEST VAL Loss: 0.5413  Val_Acc: 75.436

Epoch 47: Validation loss decreased (0.541267 --> 0.540790).  Saving model ...
	 Train_Loss: 0.5097 Train_Acc: 78.000 Val_Loss: 0.5408  BEST VAL Loss: 0.5408  Val_Acc: 75.557

Epoch 48: Validation loss decreased (0.540790 --> 0.540359).  Saving model ...
	 Train_Loss: 0.5086 Train_Acc: 78.157 Val_Loss: 0.5404  BEST VAL Loss: 0.5404  Val_Acc: 75.233

Epoch 49: Validation loss decreased (0.540359 --> 0.539875).  Saving model ...
	 Train_Loss: 0.5075 Train_Acc: 78.694 Val_Loss: 0.5399  BEST VAL Loss: 0.5399  Val_Acc: 75.719

Epoch 50: Validation loss decreased (0.539875 --> 0.539436).  Saving model ...
	 Train_Loss: 0.5064 Train_Acc: 78.415 Val_Loss: 0.5394  BEST VAL Loss: 0.5394  Val_Acc: 75.314

Epoch 51: Validation loss decreased (0.539436 --> 0.539083).  Saving model ...
	 Train_Loss: 0.5053 Train_Acc: 78.633 Val_Loss: 0.5391  BEST VAL Loss: 0.5391  Val_Acc: 74.787

Epoch 52: Validation loss decreased (0.539083 --> 0.538711).  Saving model ...
	 Train_Loss: 0.5043 Train_Acc: 78.380 Val_Loss: 0.5387  BEST VAL Loss: 0.5387  Val_Acc: 75.314

Epoch 53: Validation loss decreased (0.538711 --> 0.538326).  Saving model ...
	 Train_Loss: 0.5034 Train_Acc: 78.400 Val_Loss: 0.5383  BEST VAL Loss: 0.5383  Val_Acc: 75.274

Epoch 54: Validation loss decreased (0.538326 --> 0.537997).  Saving model ...
	 Train_Loss: 0.5024 Train_Acc: 78.927 Val_Loss: 0.5380  BEST VAL Loss: 0.5380  Val_Acc: 75.679

Epoch 55: Validation loss decreased (0.537997 --> 0.537640).  Saving model ...
	 Train_Loss: 0.5014 Train_Acc: 78.734 Val_Loss: 0.5376  BEST VAL Loss: 0.5376  Val_Acc: 75.882

Epoch 56: Validation loss decreased (0.537640 --> 0.537341).  Saving model ...
	 Train_Loss: 0.5004 Train_Acc: 79.089 Val_Loss: 0.5373  BEST VAL Loss: 0.5373  Val_Acc: 75.476

Epoch 57: Validation loss decreased (0.537341 --> 0.537108).  Saving model ...
	 Train_Loss: 0.4995 Train_Acc: 78.354 Val_Loss: 0.5371  BEST VAL Loss: 0.5371  Val_Acc: 75.355

Epoch 58: Validation loss decreased (0.537108 --> 0.536808).  Saving model ...
	 Train_Loss: 0.4986 Train_Acc: 78.527 Val_Loss: 0.5368  BEST VAL Loss: 0.5368  Val_Acc: 75.152

Epoch 59: Validation loss decreased (0.536808 --> 0.536490).  Saving model ...
	 Train_Loss: 0.4977 Train_Acc: 78.962 Val_Loss: 0.5365  BEST VAL Loss: 0.5365  Val_Acc: 74.949

Epoch 60: Validation loss decreased (0.536490 --> 0.536209).  Saving model ...
	 Train_Loss: 0.4969 Train_Acc: 78.831 Val_Loss: 0.5362  BEST VAL Loss: 0.5362  Val_Acc: 75.152

Epoch 61: Validation loss decreased (0.536209 --> 0.535914).  Saving model ...
	 Train_Loss: 0.4960 Train_Acc: 79.454 Val_Loss: 0.5359  BEST VAL Loss: 0.5359  Val_Acc: 75.395

Epoch 62: Validation loss decreased (0.535914 --> 0.535678).  Saving model ...
	 Train_Loss: 0.4951 Train_Acc: 78.729 Val_Loss: 0.5357  BEST VAL Loss: 0.5357  Val_Acc: 75.193

Epoch 63: Validation loss decreased (0.535678 --> 0.535435).  Saving model ...
	 Train_Loss: 0.4943 Train_Acc: 78.623 Val_Loss: 0.5354  BEST VAL Loss: 0.5354  Val_Acc: 75.314

Epoch 64: Validation loss decreased (0.535435 --> 0.535141).  Saving model ...
	 Train_Loss: 0.4935 Train_Acc: 78.663 Val_Loss: 0.5351  BEST VAL Loss: 0.5351  Val_Acc: 76.125

Epoch 65: Validation loss decreased (0.535141 --> 0.534902).  Saving model ...
	 Train_Loss: 0.4927 Train_Acc: 78.841 Val_Loss: 0.5349  BEST VAL Loss: 0.5349  Val_Acc: 75.476

Epoch 66: Validation loss decreased (0.534902 --> 0.534658).  Saving model ...
	 Train_Loss: 0.4919 Train_Acc: 79.180 Val_Loss: 0.5347  BEST VAL Loss: 0.5347  Val_Acc: 75.193

Epoch 67: Validation loss decreased (0.534658 --> 0.534433).  Saving model ...
	 Train_Loss: 0.4911 Train_Acc: 79.251 Val_Loss: 0.5344  BEST VAL Loss: 0.5344  Val_Acc: 75.193

Epoch 68: Validation loss decreased (0.534433 --> 0.534242).  Saving model ...
	 Train_Loss: 0.4903 Train_Acc: 79.074 Val_Loss: 0.5342  BEST VAL Loss: 0.5342  Val_Acc: 75.274

Epoch 69: Validation loss decreased (0.534242 --> 0.534067).  Saving model ...
	 Train_Loss: 0.4895 Train_Acc: 79.109 Val_Loss: 0.5341  BEST VAL Loss: 0.5341  Val_Acc: 75.476

Epoch 70: Validation loss decreased (0.534067 --> 0.533933).  Saving model ...
	 Train_Loss: 0.4888 Train_Acc: 79.033 Val_Loss: 0.5339  BEST VAL Loss: 0.5339  Val_Acc: 75.111

Epoch 71: Validation loss decreased (0.533933 --> 0.533823).  Saving model ...
	 Train_Loss: 0.4881 Train_Acc: 79.175 Val_Loss: 0.5338  BEST VAL Loss: 0.5338  Val_Acc: 75.963

Epoch 72: Validation loss decreased (0.533823 --> 0.533669).  Saving model ...
	 Train_Loss: 0.4874 Train_Acc: 79.069 Val_Loss: 0.5337  BEST VAL Loss: 0.5337  Val_Acc: 75.476

Epoch 73: Validation loss decreased (0.533669 --> 0.533546).  Saving model ...
	 Train_Loss: 0.4867 Train_Acc: 79.413 Val_Loss: 0.5335  BEST VAL Loss: 0.5335  Val_Acc: 75.071

Epoch 74: Validation loss decreased (0.533546 --> 0.533429).  Saving model ...
	 Train_Loss: 0.4860 Train_Acc: 78.967 Val_Loss: 0.5334  BEST VAL Loss: 0.5334  Val_Acc: 75.395

Epoch 75: Validation loss decreased (0.533429 --> 0.533348).  Saving model ...
	 Train_Loss: 0.4853 Train_Acc: 79.439 Val_Loss: 0.5333  BEST VAL Loss: 0.5333  Val_Acc: 75.476

Epoch 76: Validation loss decreased (0.533348 --> 0.533242).  Saving model ...
	 Train_Loss: 0.4845 Train_Acc: 79.971 Val_Loss: 0.5332  BEST VAL Loss: 0.5332  Val_Acc: 75.760

Epoch 77: Validation loss decreased (0.533242 --> 0.533209).  Saving model ...
	 Train_Loss: 0.4839 Train_Acc: 79.200 Val_Loss: 0.5332  BEST VAL Loss: 0.5332  Val_Acc: 75.436

Epoch 78: Validation loss decreased (0.533209 --> 0.533101).  Saving model ...
	 Train_Loss: 0.4832 Train_Acc: 79.692 Val_Loss: 0.5331  BEST VAL Loss: 0.5331  Val_Acc: 75.922

Epoch 79: Validation loss decreased (0.533101 --> 0.533052).  Saving model ...
	 Train_Loss: 0.4825 Train_Acc: 79.398 Val_Loss: 0.5331  BEST VAL Loss: 0.5331  Val_Acc: 75.760

Epoch 80: Validation loss decreased (0.533052 --> 0.532976).  Saving model ...
	 Train_Loss: 0.4819 Train_Acc: 79.332 Val_Loss: 0.5330  BEST VAL Loss: 0.5330  Val_Acc: 76.084

Epoch 81: Validation loss decreased (0.532976 --> 0.532893).  Saving model ...
	 Train_Loss: 0.4812 Train_Acc: 79.434 Val_Loss: 0.5329  BEST VAL Loss: 0.5329  Val_Acc: 75.760

Epoch 82: Validation loss decreased (0.532893 --> 0.532854).  Saving model ...
	 Train_Loss: 0.4806 Train_Acc: 79.535 Val_Loss: 0.5329  BEST VAL Loss: 0.5329  Val_Acc: 75.355

Epoch 83: Validation loss decreased (0.532854 --> 0.532828).  Saving model ...
	 Train_Loss: 0.4799 Train_Acc: 79.540 Val_Loss: 0.5328  BEST VAL Loss: 0.5328  Val_Acc: 74.828

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.4793 Train_Acc: 79.707 Val_Loss: 0.5328  BEST VAL Loss: 0.5328  Val_Acc: 74.666

Epoch 85: Validation loss decreased (0.532828 --> 0.532756).  Saving model ...
	 Train_Loss: 0.4787 Train_Acc: 79.408 Val_Loss: 0.5328  BEST VAL Loss: 0.5328  Val_Acc: 76.409

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.4781 Train_Acc: 80.011 Val_Loss: 0.5328  BEST VAL Loss: 0.5328  Val_Acc: 75.355

Epoch 87: Validation loss decreased (0.532756 --> 0.532746).  Saving model ...
	 Train_Loss: 0.4775 Train_Acc: 79.682 Val_Loss: 0.5327  BEST VAL Loss: 0.5327  Val_Acc: 75.557

Epoch 88: Validation loss decreased (0.532746 --> 0.532722).  Saving model ...
	 Train_Loss: 0.4769 Train_Acc: 79.510 Val_Loss: 0.5327  BEST VAL Loss: 0.5327  Val_Acc: 75.071

Epoch 89: Validation loss decreased (0.532722 --> 0.532705).  Saving model ...
	 Train_Loss: 0.4763 Train_Acc: 80.052 Val_Loss: 0.5327  BEST VAL Loss: 0.5327  Val_Acc: 75.314

Epoch 90: Validation loss decreased (0.532705 --> 0.532692).  Saving model ...
	 Train_Loss: 0.4756 Train_Acc: 79.783 Val_Loss: 0.5327  BEST VAL Loss: 0.5327  Val_Acc: 75.395

Epoch 91: Validation loss decreased (0.532692 --> 0.532661).  Saving model ...
	 Train_Loss: 0.4751 Train_Acc: 79.575 Val_Loss: 0.5327  BEST VAL Loss: 0.5327  Val_Acc: 75.760

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.4745 Train_Acc: 79.814 Val_Loss: 0.5327  BEST VAL Loss: 0.5327  Val_Acc: 75.679

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.4739 Train_Acc: 79.920 Val_Loss: 0.5327  BEST VAL Loss: 0.5327  Val_Acc: 75.517

Epoch 94: Validation loss decreased (0.532661 --> 0.532629).  Saving model ...
	 Train_Loss: 0.4734 Train_Acc: 80.214 Val_Loss: 0.5326  BEST VAL Loss: 0.5326  Val_Acc: 75.719

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.4728 Train_Acc: 80.148 Val_Loss: 0.5326  BEST VAL Loss: 0.5326  Val_Acc: 75.801

Epoch 96: Validation loss decreased (0.532629 --> 0.532574).  Saving model ...
	 Train_Loss: 0.4722 Train_Acc: 80.158 Val_Loss: 0.5326  BEST VAL Loss: 0.5326  Val_Acc: 76.165

Epoch 97: Validation loss decreased (0.532574 --> 0.532547).  Saving model ...
	 Train_Loss: 0.4717 Train_Acc: 79.824 Val_Loss: 0.5325  BEST VAL Loss: 0.5325  Val_Acc: 75.963

Epoch 98: Validation loss did not decrease
	 Train_Loss: 0.4711 Train_Acc: 80.143 Val_Loss: 0.5326  BEST VAL Loss: 0.5325  Val_Acc: 74.990

Epoch 99: Validation loss did not decrease
	 Train_Loss: 0.4706 Train_Acc: 80.153 Val_Loss: 0.5326  BEST VAL Loss: 0.5325  Val_Acc: 76.084

LPS_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.88      0.83      0.86      9708
           1       0.85      0.89      0.87     10028

    accuracy                           0.86     19736
   macro avg       0.87      0.86      0.86     19736
weighted avg       0.87      0.86      0.86     19736

LPS_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.77      0.72      0.75      1213
           1       0.75      0.79      0.77      1254

    accuracy                           0.76      2467
   macro avg       0.76      0.76      0.76      2467
weighted avg       0.76      0.76      0.76      2467

LPS_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.77      0.72      0.74      1214
           1       0.74      0.79      0.77      1253

    accuracy                           0.76      2467
   macro avg       0.76      0.76      0.76      2467
weighted avg       0.76      0.76      0.76      2467

              precision    recall  f1-score   support

           0       0.77      0.72      0.74      1214
           1       0.74      0.79      0.77      1253

    accuracy                           0.76      2467
   macro avg       0.76      0.76      0.76      2467
weighted avg       0.76      0.76      0.76      2467

LPS_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.55      0.69      0.61      3724
           1       0.62      0.47      0.53      3923

    accuracy                           0.58      7647
   macro avg       0.58      0.58      0.57      7647
weighted avg       0.59      0.58      0.57      7647

              precision    recall  f1-score   support

           0       0.55      0.69      0.61      3724
           1       0.62      0.47      0.53      3923

    accuracy                           0.58      7647
   macro avg       0.58      0.58      0.57      7647
weighted avg       0.59      0.58      0.57      7647

completed
