[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '7ac6ec01'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '5476ba5e'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '45b131c2'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '70f0fe7d'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 treatment_name: DMSO_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
TREATMENT_NAME: DMSO_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (396296, 1270)
Number of total missing values across all columns: 430260
Data Subset Is Off
Wells held out for testing: ['J06' 'M08']
Wells to use for training, validation, and testing ['B06' 'C06' 'B07' 'C07' 'I06' 'I07' 'J07' 'M02' 'M03' 'M09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.153575).  Saving model ...
	 Train_Loss: 0.2781 Train_Acc: 88.281 Val_Loss: 0.1536  BEST VAL Loss: 0.1536  Val_Acc: 94.383

Epoch 1: Validation loss decreased (0.153575 --> 0.148174).  Saving model ...
	 Train_Loss: 0.2377 Train_Acc: 92.739 Val_Loss: 0.1482  BEST VAL Loss: 0.1482  Val_Acc: 94.673

Epoch 2: Validation loss decreased (0.148174 --> 0.141372).  Saving model ...
	 Train_Loss: 0.2200 Train_Acc: 93.060 Val_Loss: 0.1414  BEST VAL Loss: 0.1414  Val_Acc: 95.169

Epoch 3: Validation loss decreased (0.141372 --> 0.137186).  Saving model ...
	 Train_Loss: 0.2089 Train_Acc: 93.443 Val_Loss: 0.1372  BEST VAL Loss: 0.1372  Val_Acc: 95.354

Epoch 4: Validation loss decreased (0.137186 --> 0.133616).  Saving model ...
	 Train_Loss: 0.2013 Train_Acc: 93.642 Val_Loss: 0.1336  BEST VAL Loss: 0.1336  Val_Acc: 95.536

Epoch 5: Validation loss decreased (0.133616 --> 0.131426).  Saving model ...
	 Train_Loss: 0.1955 Train_Acc: 93.769 Val_Loss: 0.1314  BEST VAL Loss: 0.1314  Val_Acc: 95.551

Epoch 6: Validation loss decreased (0.131426 --> 0.128908).  Saving model ...
	 Train_Loss: 0.1911 Train_Acc: 93.857 Val_Loss: 0.1289  BEST VAL Loss: 0.1289  Val_Acc: 95.786

Epoch 7: Validation loss decreased (0.128908 --> 0.126768).  Saving model ...
	 Train_Loss: 0.1873 Train_Acc: 94.069 Val_Loss: 0.1268  BEST VAL Loss: 0.1268  Val_Acc: 95.816

Epoch 8: Validation loss decreased (0.126768 --> 0.125040).  Saving model ...
	 Train_Loss: 0.1842 Train_Acc: 94.030 Val_Loss: 0.1250  BEST VAL Loss: 0.1250  Val_Acc: 95.980

Epoch 9: Validation loss decreased (0.125040 --> 0.123727).  Saving model ...
	 Train_Loss: 0.1816 Train_Acc: 94.221 Val_Loss: 0.1237  BEST VAL Loss: 0.1237  Val_Acc: 95.930

Epoch 10: Validation loss decreased (0.123727 --> 0.122533).  Saving model ...
	 Train_Loss: 0.1793 Train_Acc: 94.248 Val_Loss: 0.1225  BEST VAL Loss: 0.1225  Val_Acc: 96.051

Epoch 11: Validation loss decreased (0.122533 --> 0.121470).  Saving model ...
	 Train_Loss: 0.1773 Train_Acc: 94.365 Val_Loss: 0.1215  BEST VAL Loss: 0.1215  Val_Acc: 95.949

Epoch 12: Validation loss decreased (0.121470 --> 0.120571).  Saving model ...
	 Train_Loss: 0.1756 Train_Acc: 94.371 Val_Loss: 0.1206  BEST VAL Loss: 0.1206  Val_Acc: 96.078

Epoch 13: Validation loss decreased (0.120571 --> 0.119938).  Saving model ...
	 Train_Loss: 0.1740 Train_Acc: 94.387 Val_Loss: 0.1199  BEST VAL Loss: 0.1199  Val_Acc: 95.853

Epoch 14: Validation loss decreased (0.119938 --> 0.119045).  Saving model ...
	 Train_Loss: 0.1727 Train_Acc: 94.504 Val_Loss: 0.1190  BEST VAL Loss: 0.1190  Val_Acc: 96.112

Epoch 15: Validation loss decreased (0.119045 --> 0.118188).  Saving model ...
	 Train_Loss: 0.1714 Train_Acc: 94.479 Val_Loss: 0.1182  BEST VAL Loss: 0.1182  Val_Acc: 96.239

Epoch 16: Validation loss decreased (0.118188 --> 0.117624).  Saving model ...
	 Train_Loss: 0.1701 Train_Acc: 94.570 Val_Loss: 0.1176  BEST VAL Loss: 0.1176  Val_Acc: 96.217

Epoch 17: Validation loss decreased (0.117624 --> 0.116910).  Saving model ...
	 Train_Loss: 0.1689 Train_Acc: 94.682 Val_Loss: 0.1169  BEST VAL Loss: 0.1169  Val_Acc: 96.313

Epoch 18: Validation loss decreased (0.116910 --> 0.116296).  Saving model ...
	 Train_Loss: 0.1680 Train_Acc: 94.519 Val_Loss: 0.1163  BEST VAL Loss: 0.1163  Val_Acc: 96.226

Epoch 19: Validation loss decreased (0.116296 --> 0.115942).  Saving model ...
	 Train_Loss: 0.1670 Train_Acc: 94.675 Val_Loss: 0.1159  BEST VAL Loss: 0.1159  Val_Acc: 95.992

Epoch 20: Validation loss decreased (0.115942 --> 0.115590).  Saving model ...
	 Train_Loss: 0.1660 Train_Acc: 94.631 Val_Loss: 0.1156  BEST VAL Loss: 0.1156  Val_Acc: 96.103

Epoch 21: Validation loss decreased (0.115590 --> 0.115152).  Saving model ...
	 Train_Loss: 0.1652 Train_Acc: 94.701 Val_Loss: 0.1152  BEST VAL Loss: 0.1152  Val_Acc: 96.026

Epoch 22: Validation loss decreased (0.115152 --> 0.114860).  Saving model ...
	 Train_Loss: 0.1644 Train_Acc: 94.668 Val_Loss: 0.1149  BEST VAL Loss: 0.1149  Val_Acc: 96.103

Epoch 23: Validation loss decreased (0.114860 --> 0.114392).  Saving model ...
	 Train_Loss: 0.1636 Train_Acc: 94.745 Val_Loss: 0.1144  BEST VAL Loss: 0.1144  Val_Acc: 96.229

Epoch 24: Validation loss decreased (0.114392 --> 0.113926).  Saving model ...
	 Train_Loss: 0.1629 Train_Acc: 94.773 Val_Loss: 0.1139  BEST VAL Loss: 0.1139  Val_Acc: 96.266

Epoch 25: Validation loss decreased (0.113926 --> 0.113528).  Saving model ...
	 Train_Loss: 0.1621 Train_Acc: 94.779 Val_Loss: 0.1135  BEST VAL Loss: 0.1135  Val_Acc: 96.276

Epoch 26: Validation loss decreased (0.113528 --> 0.113117).  Saving model ...
	 Train_Loss: 0.1614 Train_Acc: 94.777 Val_Loss: 0.1131  BEST VAL Loss: 0.1131  Val_Acc: 96.356

Epoch 27: Validation loss decreased (0.113117 --> 0.112734).  Saving model ...
	 Train_Loss: 0.1608 Train_Acc: 94.804 Val_Loss: 0.1127  BEST VAL Loss: 0.1127  Val_Acc: 96.303

Epoch 28: Validation loss decreased (0.112734 --> 0.112355).  Saving model ...
	 Train_Loss: 0.1602 Train_Acc: 94.777 Val_Loss: 0.1124  BEST VAL Loss: 0.1124  Val_Acc: 96.350

Epoch 29: Validation loss decreased (0.112355 --> 0.111971).  Saving model ...
	 Train_Loss: 0.1596 Train_Acc: 94.881 Val_Loss: 0.1120  BEST VAL Loss: 0.1120  Val_Acc: 96.291

Epoch 30: Validation loss decreased (0.111971 --> 0.111597).  Saving model ...
	 Train_Loss: 0.1591 Train_Acc: 94.804 Val_Loss: 0.1116  BEST VAL Loss: 0.1116  Val_Acc: 96.316

Epoch 31: Validation loss decreased (0.111597 --> 0.111297).  Saving model ...
	 Train_Loss: 0.1586 Train_Acc: 94.830 Val_Loss: 0.1113  BEST VAL Loss: 0.1113  Val_Acc: 96.334

Epoch 32: Validation loss decreased (0.111297 --> 0.111080).  Saving model ...
	 Train_Loss: 0.1581 Train_Acc: 94.737 Val_Loss: 0.1111  BEST VAL Loss: 0.1111  Val_Acc: 96.276

Epoch 33: Validation loss decreased (0.111080 --> 0.110862).  Saving model ...
	 Train_Loss: 0.1577 Train_Acc: 94.749 Val_Loss: 0.1109  BEST VAL Loss: 0.1109  Val_Acc: 96.205

Epoch 34: Validation loss decreased (0.110862 --> 0.110684).  Saving model ...
	 Train_Loss: 0.1573 Train_Acc: 94.740 Val_Loss: 0.1107  BEST VAL Loss: 0.1107  Val_Acc: 96.217

Epoch 35: Validation loss decreased (0.110684 --> 0.110462).  Saving model ...
	 Train_Loss: 0.1570 Train_Acc: 94.777 Val_Loss: 0.1105  BEST VAL Loss: 0.1105  Val_Acc: 96.248

Epoch 36: Validation loss decreased (0.110462 --> 0.110293).  Saving model ...
	 Train_Loss: 0.1566 Train_Acc: 94.868 Val_Loss: 0.1103  BEST VAL Loss: 0.1103  Val_Acc: 96.257

Epoch 37: Validation loss decreased (0.110293 --> 0.109992).  Saving model ...
	 Train_Loss: 0.1562 Train_Acc: 94.905 Val_Loss: 0.1100  BEST VAL Loss: 0.1100  Val_Acc: 96.430

Epoch 38: Validation loss decreased (0.109992 --> 0.109828).  Saving model ...
	 Train_Loss: 0.1558 Train_Acc: 94.921 Val_Loss: 0.1098  BEST VAL Loss: 0.1098  Val_Acc: 96.266

Epoch 39: Validation loss decreased (0.109828 --> 0.109679).  Saving model ...
	 Train_Loss: 0.1555 Train_Acc: 94.787 Val_Loss: 0.1097  BEST VAL Loss: 0.1097  Val_Acc: 96.186

Epoch 40: Validation loss decreased (0.109679 --> 0.109456).  Saving model ...
	 Train_Loss: 0.1551 Train_Acc: 94.887 Val_Loss: 0.1095  BEST VAL Loss: 0.1095  Val_Acc: 96.421

Epoch 41: Validation loss decreased (0.109456 --> 0.109329).  Saving model ...
	 Train_Loss: 0.1548 Train_Acc: 94.847 Val_Loss: 0.1093  BEST VAL Loss: 0.1093  Val_Acc: 96.202

Epoch 42: Validation loss decreased (0.109329 --> 0.109140).  Saving model ...
	 Train_Loss: 0.1544 Train_Acc: 94.988 Val_Loss: 0.1091  BEST VAL Loss: 0.1091  Val_Acc: 96.427

Epoch 43: Validation loss decreased (0.109140 --> 0.108902).  Saving model ...
	 Train_Loss: 0.1541 Train_Acc: 94.886 Val_Loss: 0.1089  BEST VAL Loss: 0.1089  Val_Acc: 96.408

Epoch 44: Validation loss decreased (0.108902 --> 0.108668).  Saving model ...
	 Train_Loss: 0.1538 Train_Acc: 94.919 Val_Loss: 0.1087  BEST VAL Loss: 0.1087  Val_Acc: 96.575

Epoch 45: Validation loss decreased (0.108668 --> 0.108491).  Saving model ...
	 Train_Loss: 0.1535 Train_Acc: 94.898 Val_Loss: 0.1085  BEST VAL Loss: 0.1085  Val_Acc: 96.479

Epoch 46: Validation loss decreased (0.108491 --> 0.108335).  Saving model ...
	 Train_Loss: 0.1532 Train_Acc: 94.891 Val_Loss: 0.1083  BEST VAL Loss: 0.1083  Val_Acc: 96.430

Epoch 47: Validation loss decreased (0.108335 --> 0.108284).  Saving model ...
	 Train_Loss: 0.1530 Train_Acc: 94.903 Val_Loss: 0.1083  BEST VAL Loss: 0.1083  Val_Acc: 96.285

Epoch 48: Validation loss decreased (0.108284 --> 0.108217).  Saving model ...
	 Train_Loss: 0.1528 Train_Acc: 94.759 Val_Loss: 0.1082  BEST VAL Loss: 0.1082  Val_Acc: 96.242

Epoch 49: Validation loss decreased (0.108217 --> 0.108079).  Saving model ...
	 Train_Loss: 0.1525 Train_Acc: 94.936 Val_Loss: 0.1081  BEST VAL Loss: 0.1081  Val_Acc: 96.424

Epoch 50: Validation loss decreased (0.108079 --> 0.107971).  Saving model ...
	 Train_Loss: 0.1522 Train_Acc: 94.860 Val_Loss: 0.1080  BEST VAL Loss: 0.1080  Val_Acc: 96.337

Epoch 51: Validation loss decreased (0.107971 --> 0.107839).  Saving model ...
	 Train_Loss: 0.1520 Train_Acc: 94.875 Val_Loss: 0.1078  BEST VAL Loss: 0.1078  Val_Acc: 96.408

Epoch 52: Validation loss decreased (0.107839 --> 0.107725).  Saving model ...
	 Train_Loss: 0.1518 Train_Acc: 95.031 Val_Loss: 0.1077  BEST VAL Loss: 0.1077  Val_Acc: 96.297

Epoch 53: Validation loss decreased (0.107725 --> 0.107628).  Saving model ...
	 Train_Loss: 0.1515 Train_Acc: 94.987 Val_Loss: 0.1076  BEST VAL Loss: 0.1076  Val_Acc: 96.291

Epoch 54: Validation loss decreased (0.107628 --> 0.107553).  Saving model ...
	 Train_Loss: 0.1514 Train_Acc: 94.867 Val_Loss: 0.1076  BEST VAL Loss: 0.1076  Val_Acc: 96.257

Epoch 55: Validation loss decreased (0.107553 --> 0.107502).  Saving model ...
	 Train_Loss: 0.1512 Train_Acc: 94.847 Val_Loss: 0.1075  BEST VAL Loss: 0.1075  Val_Acc: 96.051

Epoch 56: Validation loss decreased (0.107502 --> 0.107380).  Saving model ...
	 Train_Loss: 0.1509 Train_Acc: 94.915 Val_Loss: 0.1074  BEST VAL Loss: 0.1074  Val_Acc: 96.421

Epoch 57: Validation loss decreased (0.107380 --> 0.107286).  Saving model ...
	 Train_Loss: 0.1507 Train_Acc: 95.074 Val_Loss: 0.1073  BEST VAL Loss: 0.1073  Val_Acc: 96.399

Epoch 58: Validation loss decreased (0.107286 --> 0.107124).  Saving model ...
	 Train_Loss: 0.1505 Train_Acc: 94.903 Val_Loss: 0.1071  BEST VAL Loss: 0.1071  Val_Acc: 96.488

Epoch 59: Validation loss decreased (0.107124 --> 0.106984).  Saving model ...
	 Train_Loss: 0.1503 Train_Acc: 95.070 Val_Loss: 0.1070  BEST VAL Loss: 0.1070  Val_Acc: 96.575

Epoch 60: Validation loss decreased (0.106984 --> 0.106885).  Saving model ...
	 Train_Loss: 0.1501 Train_Acc: 94.886 Val_Loss: 0.1069  BEST VAL Loss: 0.1069  Val_Acc: 96.239

Epoch 61: Validation loss decreased (0.106885 --> 0.106753).  Saving model ...
	 Train_Loss: 0.1499 Train_Acc: 95.010 Val_Loss: 0.1068  BEST VAL Loss: 0.1068  Val_Acc: 96.393

Epoch 62: Validation loss decreased (0.106753 --> 0.106578).  Saving model ...
	 Train_Loss: 0.1497 Train_Acc: 95.005 Val_Loss: 0.1066  BEST VAL Loss: 0.1066  Val_Acc: 96.658

Epoch 63: Validation loss decreased (0.106578 --> 0.106388).  Saving model ...
	 Train_Loss: 0.1495 Train_Acc: 94.981 Val_Loss: 0.1064  BEST VAL Loss: 0.1064  Val_Acc: 96.643

Epoch 64: Validation loss decreased (0.106388 --> 0.106277).  Saving model ...
	 Train_Loss: 0.1493 Train_Acc: 94.817 Val_Loss: 0.1063  BEST VAL Loss: 0.1063  Val_Acc: 96.334

Epoch 65: Validation loss decreased (0.106277 --> 0.106235).  Saving model ...
	 Train_Loss: 0.1492 Train_Acc: 95.030 Val_Loss: 0.1062  BEST VAL Loss: 0.1062  Val_Acc: 96.263

Epoch 66: Validation loss decreased (0.106235 --> 0.106142).  Saving model ...
	 Train_Loss: 0.1490 Train_Acc: 95.019 Val_Loss: 0.1061  BEST VAL Loss: 0.1061  Val_Acc: 96.448

Epoch 67: Validation loss decreased (0.106142 --> 0.106064).  Saving model ...
	 Train_Loss: 0.1488 Train_Acc: 95.141 Val_Loss: 0.1061  BEST VAL Loss: 0.1061  Val_Acc: 96.254

Epoch 68: Validation loss decreased (0.106064 --> 0.105912).  Saving model ...
	 Train_Loss: 0.1487 Train_Acc: 94.998 Val_Loss: 0.1059  BEST VAL Loss: 0.1059  Val_Acc: 96.578

Epoch 69: Validation loss decreased (0.105912 --> 0.105805).  Saving model ...
	 Train_Loss: 0.1485 Train_Acc: 95.089 Val_Loss: 0.1058  BEST VAL Loss: 0.1058  Val_Acc: 96.541

Epoch 70: Validation loss decreased (0.105805 --> 0.105739).  Saving model ...
	 Train_Loss: 0.1483 Train_Acc: 95.064 Val_Loss: 0.1057  BEST VAL Loss: 0.1057  Val_Acc: 96.498

Epoch 71: Validation loss decreased (0.105739 --> 0.105617).  Saving model ...
	 Train_Loss: 0.1482 Train_Acc: 94.916 Val_Loss: 0.1056  BEST VAL Loss: 0.1056  Val_Acc: 96.455

Epoch 72: Validation loss decreased (0.105617 --> 0.105517).  Saving model ...
	 Train_Loss: 0.1480 Train_Acc: 95.134 Val_Loss: 0.1055  BEST VAL Loss: 0.1055  Val_Acc: 96.464

Epoch 73: Validation loss decreased (0.105517 --> 0.105434).  Saving model ...
	 Train_Loss: 0.1478 Train_Acc: 95.099 Val_Loss: 0.1054  BEST VAL Loss: 0.1054  Val_Acc: 96.495

Epoch 74: Validation loss decreased (0.105434 --> 0.105324).  Saving model ...
	 Train_Loss: 0.1477 Train_Acc: 95.040 Val_Loss: 0.1053  BEST VAL Loss: 0.1053  Val_Acc: 96.590

Epoch 75: Validation loss decreased (0.105324 --> 0.105210).  Saving model ...
	 Train_Loss: 0.1475 Train_Acc: 95.110 Val_Loss: 0.1052  BEST VAL Loss: 0.1052  Val_Acc: 96.566

Epoch 76: Validation loss decreased (0.105210 --> 0.105162).  Saving model ...
	 Train_Loss: 0.1474 Train_Acc: 94.997 Val_Loss: 0.1052  BEST VAL Loss: 0.1052  Val_Acc: 96.374

Epoch 77: Validation loss decreased (0.105162 --> 0.105090).  Saving model ...
	 Train_Loss: 0.1473 Train_Acc: 94.943 Val_Loss: 0.1051  BEST VAL Loss: 0.1051  Val_Acc: 96.535

Epoch 78: Validation loss decreased (0.105090 --> 0.104948).  Saving model ...
	 Train_Loss: 0.1471 Train_Acc: 95.140 Val_Loss: 0.1049  BEST VAL Loss: 0.1049  Val_Acc: 96.680

Epoch 79: Validation loss decreased (0.104948 --> 0.104851).  Saving model ...
	 Train_Loss: 0.1469 Train_Acc: 95.083 Val_Loss: 0.1049  BEST VAL Loss: 0.1049  Val_Acc: 96.612

Epoch 80: Validation loss decreased (0.104851 --> 0.104829).  Saving model ...
	 Train_Loss: 0.1468 Train_Acc: 95.007 Val_Loss: 0.1048  BEST VAL Loss: 0.1048  Val_Acc: 96.239

Epoch 81: Validation loss decreased (0.104829 --> 0.104714).  Saving model ...
	 Train_Loss: 0.1466 Train_Acc: 95.127 Val_Loss: 0.1047  BEST VAL Loss: 0.1047  Val_Acc: 96.664

Epoch 82: Validation loss decreased (0.104714 --> 0.104665).  Saving model ...
	 Train_Loss: 0.1465 Train_Acc: 95.057 Val_Loss: 0.1047  BEST VAL Loss: 0.1047  Val_Acc: 96.424

Epoch 83: Validation loss decreased (0.104665 --> 0.104546).  Saving model ...
	 Train_Loss: 0.1464 Train_Acc: 94.971 Val_Loss: 0.1045  BEST VAL Loss: 0.1045  Val_Acc: 96.581

Epoch 84: Validation loss decreased (0.104546 --> 0.104511).  Saving model ...
	 Train_Loss: 0.1463 Train_Acc: 95.111 Val_Loss: 0.1045  BEST VAL Loss: 0.1045  Val_Acc: 96.331

Epoch 85: Validation loss decreased (0.104511 --> 0.104446).  Saving model ...
	 Train_Loss: 0.1462 Train_Acc: 95.010 Val_Loss: 0.1044  BEST VAL Loss: 0.1044  Val_Acc: 96.529

Epoch 86: Validation loss decreased (0.104446 --> 0.104387).  Saving model ...
	 Train_Loss: 0.1461 Train_Acc: 94.850 Val_Loss: 0.1044  BEST VAL Loss: 0.1044  Val_Acc: 96.525

Epoch 87: Validation loss decreased (0.104387 --> 0.104291).  Saving model ...
	 Train_Loss: 0.1460 Train_Acc: 94.934 Val_Loss: 0.1043  BEST VAL Loss: 0.1043  Val_Acc: 96.606

Epoch 88: Validation loss decreased (0.104291 --> 0.104220).  Saving model ...
	 Train_Loss: 0.1459 Train_Acc: 95.041 Val_Loss: 0.1042  BEST VAL Loss: 0.1042  Val_Acc: 96.473

Epoch 89: Validation loss decreased (0.104220 --> 0.104119).  Saving model ...
	 Train_Loss: 0.1458 Train_Acc: 95.193 Val_Loss: 0.1041  BEST VAL Loss: 0.1041  Val_Acc: 96.495

Epoch 90: Validation loss decreased (0.104119 --> 0.104053).  Saving model ...
	 Train_Loss: 0.1456 Train_Acc: 95.067 Val_Loss: 0.1041  BEST VAL Loss: 0.1041  Val_Acc: 96.473

Epoch 91: Validation loss decreased (0.104053 --> 0.103972).  Saving model ...
	 Train_Loss: 0.1456 Train_Acc: 94.954 Val_Loss: 0.1040  BEST VAL Loss: 0.1040  Val_Acc: 96.532

Epoch 92: Validation loss decreased (0.103972 --> 0.103897).  Saving model ...
	 Train_Loss: 0.1454 Train_Acc: 94.971 Val_Loss: 0.1039  BEST VAL Loss: 0.1039  Val_Acc: 96.470

Epoch 93: Validation loss decreased (0.103897 --> 0.103840).  Saving model ...
	 Train_Loss: 0.1453 Train_Acc: 95.083 Val_Loss: 0.1038  BEST VAL Loss: 0.1038  Val_Acc: 96.578

Epoch 94: Validation loss decreased (0.103840 --> 0.103776).  Saving model ...
	 Train_Loss: 0.1452 Train_Acc: 95.023 Val_Loss: 0.1038  BEST VAL Loss: 0.1038  Val_Acc: 96.384

Epoch 95: Validation loss decreased (0.103776 --> 0.103716).  Saving model ...
	 Train_Loss: 0.1451 Train_Acc: 95.099 Val_Loss: 0.1037  BEST VAL Loss: 0.1037  Val_Acc: 96.578

Epoch 96: Validation loss decreased (0.103716 --> 0.103620).  Saving model ...
	 Train_Loss: 0.1450 Train_Acc: 95.201 Val_Loss: 0.1036  BEST VAL Loss: 0.1036  Val_Acc: 96.612

Epoch 97: Validation loss decreased (0.103620 --> 0.103531).  Saving model ...
	 Train_Loss: 0.1449 Train_Acc: 95.238 Val_Loss: 0.1035  BEST VAL Loss: 0.1035  Val_Acc: 96.640

Epoch 98: Validation loss decreased (0.103531 --> 0.103499).  Saving model ...
	 Train_Loss: 0.1447 Train_Acc: 95.149 Val_Loss: 0.1035  BEST VAL Loss: 0.1035  Val_Acc: 96.458

Epoch 99: Validation loss decreased (0.103499 --> 0.103476).  Saving model ...
	 Train_Loss: 0.1446 Train_Acc: 95.075 Val_Loss: 0.1035  BEST VAL Loss: 0.1035  Val_Acc: 96.513

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.98      0.97    149884
           1       0.97      0.96      0.96    109598

    accuracy                           0.97    259482
   macro avg       0.97      0.97      0.97    259482
weighted avg       0.97      0.97      0.97    259482

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.97      0.97     18736
           1       0.96      0.96      0.96     13700

    accuracy                           0.97     32436
   macro avg       0.96      0.96      0.96     32436
weighted avg       0.97      0.97      0.97     32436

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.97      0.97     18736
           1       0.96      0.96      0.96     13700

    accuracy                           0.96     32436
   macro avg       0.96      0.96      0.96     32436
weighted avg       0.96      0.96      0.96     32436

              precision    recall  f1-score   support

           0       0.97      0.97      0.97     18736
           1       0.96      0.96      0.96     13700

    accuracy                           0.96     32436
   macro avg       0.96      0.96      0.96     32436
weighted avg       0.96      0.96      0.96     32436

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.81      0.99      0.89     27774
           1       1.00      0.85      0.92     44168

    accuracy                           0.91     71942
   macro avg       0.90      0.92      0.91     71942
weighted avg       0.92      0.91      0.91     71942

              precision    recall  f1-score   support

           0       0.81      0.99      0.89     27774
           1       1.00      0.85      0.92     44168

    accuracy                           0.91     71942
   macro avg       0.90      0.92      0.91     71942
weighted avg       0.92      0.91      0.91     71942

completed
