[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '571aa34a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '6541add2'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '15518e1a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'fdec5b5b'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_100.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_100.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_100.000_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (30389, 1276)
Number of total missing values across all columns: 31974
Data Subset Is Off
Wells held out for testing: ['M16' 'J20']
Wells to use for training, validation, and testing ['J16' 'J17' 'M17' 'M20' 'J21' 'M21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.188143).  Saving model ...
	 Train_Loss: 0.3847 Train_Acc: 81.558 Val_Loss: 0.1881  BEST VAL Loss: 0.1881  Val_Acc: 92.452

Epoch 1: Validation loss decreased (0.188143 --> 0.147463).  Saving model ...
	 Train_Loss: 0.2700 Train_Acc: 93.753 Val_Loss: 0.1475  BEST VAL Loss: 0.1475  Val_Acc: 95.288

Epoch 2: Validation loss decreased (0.147463 --> 0.128120).  Saving model ...
	 Train_Loss: 0.2143 Train_Acc: 95.559 Val_Loss: 0.1281  BEST VAL Loss: 0.1281  Val_Acc: 96.030

Epoch 3: Validation loss decreased (0.128120 --> 0.119473).  Saving model ...
	 Train_Loss: 0.1807 Train_Acc: 96.530 Val_Loss: 0.1195  BEST VAL Loss: 0.1195  Val_Acc: 96.422

Epoch 4: Validation loss decreased (0.119473 --> 0.111936).  Saving model ...
	 Train_Loss: 0.1576 Train_Acc: 97.086 Val_Loss: 0.1119  BEST VAL Loss: 0.1119  Val_Acc: 97.033

Epoch 5: Validation loss decreased (0.111936 --> 0.108632).  Saving model ...
	 Train_Loss: 0.1410 Train_Acc: 97.430 Val_Loss: 0.1086  BEST VAL Loss: 0.1086  Val_Acc: 97.208

Epoch 6: Validation loss decreased (0.108632 --> 0.103088).  Saving model ...
	 Train_Loss: 0.1295 Train_Acc: 97.245 Val_Loss: 0.1031  BEST VAL Loss: 0.1031  Val_Acc: 97.164

Epoch 7: Validation loss decreased (0.103088 --> 0.100034).  Saving model ...
	 Train_Loss: 0.1195 Train_Acc: 97.774 Val_Loss: 0.1000  BEST VAL Loss: 0.1000  Val_Acc: 97.120

Epoch 8: Validation loss decreased (0.100034 --> 0.098626).  Saving model ...
	 Train_Loss: 0.1117 Train_Acc: 97.790 Val_Loss: 0.0986  BEST VAL Loss: 0.0986  Val_Acc: 97.077

Epoch 9: Validation loss decreased (0.098626 --> 0.098060).  Saving model ...
	 Train_Loss: 0.1058 Train_Acc: 97.507 Val_Loss: 0.0981  BEST VAL Loss: 0.0981  Val_Acc: 96.815

Epoch 10: Validation loss decreased (0.098060 --> 0.096817).  Saving model ...
	 Train_Loss: 0.1003 Train_Acc: 97.921 Val_Loss: 0.0968  BEST VAL Loss: 0.0968  Val_Acc: 97.513

Epoch 11: Validation loss decreased (0.096817 --> 0.095700).  Saving model ...
	 Train_Loss: 0.0952 Train_Acc: 98.183 Val_Loss: 0.0957  BEST VAL Loss: 0.0957  Val_Acc: 97.426

Epoch 12: Validation loss decreased (0.095700 --> 0.095220).  Saving model ...
	 Train_Loss: 0.0911 Train_Acc: 98.167 Val_Loss: 0.0952  BEST VAL Loss: 0.0952  Val_Acc: 97.295

Epoch 13: Validation loss decreased (0.095220 --> 0.093603).  Saving model ...
	 Train_Loss: 0.0875 Train_Acc: 98.156 Val_Loss: 0.0936  BEST VAL Loss: 0.0936  Val_Acc: 97.600

Epoch 14: Validation loss decreased (0.093603 --> 0.093076).  Saving model ...
	 Train_Loss: 0.0841 Train_Acc: 98.227 Val_Loss: 0.0931  BEST VAL Loss: 0.0931  Val_Acc: 97.382

Epoch 15: Validation loss decreased (0.093076 --> 0.092145).  Saving model ...
	 Train_Loss: 0.0810 Train_Acc: 98.418 Val_Loss: 0.0921  BEST VAL Loss: 0.0921  Val_Acc: 97.339

Epoch 16: Validation loss did not decrease
	 Train_Loss: 0.0781 Train_Acc: 98.401 Val_Loss: 0.0923  BEST VAL Loss: 0.0921  Val_Acc: 97.077

Epoch 17: Validation loss decreased (0.092145 --> 0.092135).  Saving model ...
	 Train_Loss: 0.0755 Train_Acc: 98.450 Val_Loss: 0.0921  BEST VAL Loss: 0.0921  Val_Acc: 97.382

Epoch 18: Validation loss decreased (0.092135 --> 0.091265).  Saving model ...
	 Train_Loss: 0.0733 Train_Acc: 98.418 Val_Loss: 0.0913  BEST VAL Loss: 0.0913  Val_Acc: 97.382

Epoch 19: Validation loss decreased (0.091265 --> 0.091130).  Saving model ...
	 Train_Loss: 0.0712 Train_Acc: 98.723 Val_Loss: 0.0911  BEST VAL Loss: 0.0911  Val_Acc: 97.644

Epoch 20: Validation loss did not decrease
	 Train_Loss: 0.0695 Train_Acc: 98.374 Val_Loss: 0.0922  BEST VAL Loss: 0.0911  Val_Acc: 97.469

Epoch 21: Validation loss did not decrease
	 Train_Loss: 0.0679 Train_Acc: 98.309 Val_Loss: 0.0939  BEST VAL Loss: 0.0911  Val_Acc: 97.818

Epoch 22: Validation loss did not decrease
	 Train_Loss: 0.0664 Train_Acc: 98.336 Val_Loss: 0.0941  BEST VAL Loss: 0.0911  Val_Acc: 97.339

Epoch 23: Validation loss did not decrease
	 Train_Loss: 0.0651 Train_Acc: 98.429 Val_Loss: 0.0950  BEST VAL Loss: 0.0911  Val_Acc: 97.644

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.0638 Train_Acc: 98.374 Val_Loss: 0.0944  BEST VAL Loss: 0.0911  Val_Acc: 97.775

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.0628 Train_Acc: 98.472 Val_Loss: 0.0943  BEST VAL Loss: 0.0911  Val_Acc: 97.775

Epoch 26: Validation loss did not decrease
	 Train_Loss: 0.0616 Train_Acc: 98.641 Val_Loss: 0.0944  BEST VAL Loss: 0.0911  Val_Acc: 97.906

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.0605 Train_Acc: 98.516 Val_Loss: 0.0935  BEST VAL Loss: 0.0911  Val_Acc: 98.037

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.0596 Train_Acc: 98.434 Val_Loss: 0.0934  BEST VAL Loss: 0.0911  Val_Acc: 97.818

Epoch 29: Validation loss did not decrease
	 Train_Loss: 0.0586 Train_Acc: 98.445 Val_Loss: 0.0926  BEST VAL Loss: 0.0911  Val_Acc: 97.775

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.0577 Train_Acc: 98.620 Val_Loss: 0.0924  BEST VAL Loss: 0.0911  Val_Acc: 98.037

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.0567 Train_Acc: 98.701 Val_Loss: 0.0922  BEST VAL Loss: 0.0911  Val_Acc: 97.949

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.0560 Train_Acc: 98.691 Val_Loss: 0.0917  BEST VAL Loss: 0.0911  Val_Acc: 97.906

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.0553 Train_Acc: 98.712 Val_Loss: 0.0915  BEST VAL Loss: 0.0911  Val_Acc: 98.080

Epoch 34: Validation loss did not decrease
	 Train_Loss: 0.0546 Train_Acc: 98.625 Val_Loss: 0.0919  BEST VAL Loss: 0.0911  Val_Acc: 97.862

Epoch 35: Validation loss did not decrease
Early stopped at epoch : 35
LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.54      0.53      0.54      9892
           1       0.46      0.46      0.46      8436

    accuracy                           0.50     18328
   macro avg       0.50      0.50      0.50     18328
weighted avg       0.50      0.50      0.50     18328

LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.53      0.53      1237
           1       0.45      0.46      0.46      1055

    accuracy                           0.50      2292
   macro avg       0.49      0.49      0.49      2292
weighted avg       0.50      0.50      0.50      2292

LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.56      0.55      0.56      1236
           1       0.48      0.48      0.48      1055

    accuracy                           0.52      2291
   macro avg       0.52      0.52      0.52      2291
weighted avg       0.52      0.52      0.52      2291

              precision    recall  f1-score   support

           0       0.56      0.55      0.56      1236
           1       0.48      0.48      0.48      1055

    accuracy                           0.52      2291
   macro avg       0.52      0.52      0.52      2291
weighted avg       0.52      0.52      0.52      2291

LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.48      0.49      3622
           1       0.52      0.53      0.53      3856

    accuracy                           0.51      7478
   macro avg       0.51      0.51      0.51      7478
weighted avg       0.51      0.51      0.51      7478

              precision    recall  f1-score   support

           0       0.49      0.48      0.49      3622
           1       0.52      0.53      0.53      3856

    accuracy                           0.51      7478
   macro avg       0.51      0.51      0.51      7478
weighted avg       0.51      0.51      0.51      7478

completed
