[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '617f21a8'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e2ba3cfe'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ce49c8f4'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '145925f5'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: DMSO_0.100_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: DMSO_0.100_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'DMSO_0.100_DMSO_0.025']
The dimensions of the data are: (353727, 1270)
Number of total missing values across all columns: 707454
Data Subset Is Off
Wells held out for testing: ['C09' 'J06']
Wells to use for training, validation, and testing ['C02' 'C03' 'B06' 'C06' 'B07' 'C07' 'C08' 'I06' 'I07' 'J07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.480939).  Saving model ...
	 Train_Loss: 0.5860 Train_Acc: 68.267 Val_Loss: 0.4809  BEST VAL Loss: 0.4809  Val_Acc: 77.823

Epoch 1: Validation loss decreased (0.480939 --> 0.443774).  Saving model ...
	 Train_Loss: 0.5363 Train_Acc: 75.356 Val_Loss: 0.4438  BEST VAL Loss: 0.4438  Val_Acc: 81.593

Epoch 2: Validation loss decreased (0.443774 --> 0.422262).  Saving model ...
	 Train_Loss: 0.5065 Train_Acc: 77.695 Val_Loss: 0.4223  BEST VAL Loss: 0.4223  Val_Acc: 83.035

Epoch 3: Validation loss decreased (0.422262 --> 0.407407).  Saving model ...
	 Train_Loss: 0.4866 Train_Acc: 79.122 Val_Loss: 0.4074  BEST VAL Loss: 0.4074  Val_Acc: 83.629

Epoch 4: Validation loss decreased (0.407407 --> 0.397743).  Saving model ...
	 Train_Loss: 0.4723 Train_Acc: 80.705 Val_Loss: 0.3977  BEST VAL Loss: 0.3977  Val_Acc: 83.939

Epoch 5: Validation loss decreased (0.397743 --> 0.389669).  Saving model ...
	 Train_Loss: 0.4614 Train_Acc: 81.237 Val_Loss: 0.3897  BEST VAL Loss: 0.3897  Val_Acc: 84.237

Epoch 6: Validation loss decreased (0.389669 --> 0.383265).  Saving model ...
	 Train_Loss: 0.4528 Train_Acc: 81.506 Val_Loss: 0.3833  BEST VAL Loss: 0.3833  Val_Acc: 84.529

Epoch 7: Validation loss decreased (0.383265 --> 0.378182).  Saving model ...
	 Train_Loss: 0.4459 Train_Acc: 81.829 Val_Loss: 0.3782  BEST VAL Loss: 0.3782  Val_Acc: 84.821

Epoch 8: Validation loss decreased (0.378182 --> 0.373552).  Saving model ...
	 Train_Loss: 0.4401 Train_Acc: 82.062 Val_Loss: 0.3736  BEST VAL Loss: 0.3736  Val_Acc: 84.852

Epoch 9: Validation loss decreased (0.373552 --> 0.369372).  Saving model ...
	 Train_Loss: 0.4350 Train_Acc: 82.316 Val_Loss: 0.3694  BEST VAL Loss: 0.3694  Val_Acc: 85.071

Epoch 10: Validation loss decreased (0.369372 --> 0.365699).  Saving model ...
	 Train_Loss: 0.4307 Train_Acc: 82.388 Val_Loss: 0.3657  BEST VAL Loss: 0.3657  Val_Acc: 85.217

Epoch 11: Validation loss decreased (0.365699 --> 0.362547).  Saving model ...
	 Train_Loss: 0.4269 Train_Acc: 82.521 Val_Loss: 0.3625  BEST VAL Loss: 0.3625  Val_Acc: 85.600

Epoch 12: Validation loss decreased (0.362547 --> 0.359801).  Saving model ...
	 Train_Loss: 0.4235 Train_Acc: 82.624 Val_Loss: 0.3598  BEST VAL Loss: 0.3598  Val_Acc: 85.669

Epoch 13: Validation loss decreased (0.359801 --> 0.357301).  Saving model ...
	 Train_Loss: 0.4205 Train_Acc: 82.679 Val_Loss: 0.3573  BEST VAL Loss: 0.3573  Val_Acc: 85.819

Epoch 14: Validation loss decreased (0.357301 --> 0.354985).  Saving model ...
	 Train_Loss: 0.4177 Train_Acc: 82.893 Val_Loss: 0.3550  BEST VAL Loss: 0.3550  Val_Acc: 85.829

Epoch 15: Validation loss decreased (0.354985 --> 0.352925).  Saving model ...
	 Train_Loss: 0.4152 Train_Acc: 83.071 Val_Loss: 0.3529  BEST VAL Loss: 0.3529  Val_Acc: 85.725

Epoch 16: Validation loss decreased (0.352925 --> 0.350984).  Saving model ...
	 Train_Loss: 0.4128 Train_Acc: 83.127 Val_Loss: 0.3510  BEST VAL Loss: 0.3510  Val_Acc: 86.024

Epoch 17: Validation loss decreased (0.350984 --> 0.349326).  Saving model ...
	 Train_Loss: 0.4108 Train_Acc: 83.202 Val_Loss: 0.3493  BEST VAL Loss: 0.3493  Val_Acc: 85.902

Epoch 18: Validation loss decreased (0.349326 --> 0.347775).  Saving model ...
	 Train_Loss: 0.4088 Train_Acc: 83.133 Val_Loss: 0.3478  BEST VAL Loss: 0.3478  Val_Acc: 86.044

Epoch 19: Validation loss decreased (0.347775 --> 0.346284).  Saving model ...
	 Train_Loss: 0.4070 Train_Acc: 83.153 Val_Loss: 0.3463  BEST VAL Loss: 0.3463  Val_Acc: 86.166

Epoch 20: Validation loss decreased (0.346284 --> 0.344910).  Saving model ...
	 Train_Loss: 0.4054 Train_Acc: 83.178 Val_Loss: 0.3449  BEST VAL Loss: 0.3449  Val_Acc: 86.176

Epoch 21: Validation loss decreased (0.344910 --> 0.343678).  Saving model ...
	 Train_Loss: 0.4038 Train_Acc: 83.320 Val_Loss: 0.3437  BEST VAL Loss: 0.3437  Val_Acc: 85.951

Epoch 22: Validation loss decreased (0.343678 --> 0.342346).  Saving model ...
	 Train_Loss: 0.4024 Train_Acc: 83.345 Val_Loss: 0.3423  BEST VAL Loss: 0.3423  Val_Acc: 86.260

Epoch 23: Validation loss decreased (0.342346 --> 0.341129).  Saving model ...
	 Train_Loss: 0.4009 Train_Acc: 83.491 Val_Loss: 0.3411  BEST VAL Loss: 0.3411  Val_Acc: 86.336

Epoch 24: Validation loss decreased (0.341129 --> 0.340026).  Saving model ...
	 Train_Loss: 0.3997 Train_Acc: 83.529 Val_Loss: 0.3400  BEST VAL Loss: 0.3400  Val_Acc: 86.569

Epoch 25: Validation loss decreased (0.340026 --> 0.338895).  Saving model ...
	 Train_Loss: 0.3985 Train_Acc: 83.390 Val_Loss: 0.3389  BEST VAL Loss: 0.3389  Val_Acc: 86.559

Epoch 26: Validation loss decreased (0.338895 --> 0.337891).  Saving model ...
	 Train_Loss: 0.3973 Train_Acc: 83.494 Val_Loss: 0.3379  BEST VAL Loss: 0.3379  Val_Acc: 86.482

Epoch 27: Validation loss decreased (0.337891 --> 0.336860).  Saving model ...
	 Train_Loss: 0.3962 Train_Acc: 83.627 Val_Loss: 0.3369  BEST VAL Loss: 0.3369  Val_Acc: 86.583

Epoch 28: Validation loss decreased (0.336860 --> 0.335856).  Saving model ...
	 Train_Loss: 0.3951 Train_Acc: 83.645 Val_Loss: 0.3359  BEST VAL Loss: 0.3359  Val_Acc: 86.715

Epoch 29: Validation loss decreased (0.335856 --> 0.334971).  Saving model ...
	 Train_Loss: 0.3941 Train_Acc: 83.635 Val_Loss: 0.3350  BEST VAL Loss: 0.3350  Val_Acc: 86.632

Epoch 30: Validation loss decreased (0.334971 --> 0.334066).  Saving model ...
	 Train_Loss: 0.3932 Train_Acc: 83.543 Val_Loss: 0.3341  BEST VAL Loss: 0.3341  Val_Acc: 86.496

Epoch 31: Validation loss decreased (0.334066 --> 0.333275).  Saving model ...
	 Train_Loss: 0.3923 Train_Acc: 83.617 Val_Loss: 0.3333  BEST VAL Loss: 0.3333  Val_Acc: 86.628

Epoch 32: Validation loss decreased (0.333275 --> 0.332505).  Saving model ...
	 Train_Loss: 0.3915 Train_Acc: 83.633 Val_Loss: 0.3325  BEST VAL Loss: 0.3325  Val_Acc: 86.698

Epoch 33: Validation loss decreased (0.332505 --> 0.331778).  Saving model ...
	 Train_Loss: 0.3907 Train_Acc: 83.622 Val_Loss: 0.3318  BEST VAL Loss: 0.3318  Val_Acc: 86.687

Epoch 34: Validation loss decreased (0.331778 --> 0.331056).  Saving model ...
	 Train_Loss: 0.3899 Train_Acc: 83.613 Val_Loss: 0.3311  BEST VAL Loss: 0.3311  Val_Acc: 86.739

Epoch 35: Validation loss decreased (0.331056 --> 0.330343).  Saving model ...
	 Train_Loss: 0.3892 Train_Acc: 83.637 Val_Loss: 0.3303  BEST VAL Loss: 0.3303  Val_Acc: 86.771

Epoch 36: Validation loss decreased (0.330343 --> 0.329799).  Saving model ...
	 Train_Loss: 0.3885 Train_Acc: 83.625 Val_Loss: 0.3298  BEST VAL Loss: 0.3298  Val_Acc: 86.600

Epoch 37: Validation loss decreased (0.329799 --> 0.329200).  Saving model ...
	 Train_Loss: 0.3878 Train_Acc: 83.795 Val_Loss: 0.3292  BEST VAL Loss: 0.3292  Val_Acc: 86.715

Epoch 38: Validation loss decreased (0.329200 --> 0.328791).  Saving model ...
	 Train_Loss: 0.3871 Train_Acc: 83.801 Val_Loss: 0.3288  BEST VAL Loss: 0.3288  Val_Acc: 86.430

Epoch 39: Validation loss decreased (0.328791 --> 0.328172).  Saving model ...
	 Train_Loss: 0.3865 Train_Acc: 83.745 Val_Loss: 0.3282  BEST VAL Loss: 0.3282  Val_Acc: 87.035

Epoch 40: Validation loss decreased (0.328172 --> 0.327571).  Saving model ...
	 Train_Loss: 0.3859 Train_Acc: 83.875 Val_Loss: 0.3276  BEST VAL Loss: 0.3276  Val_Acc: 86.910

Epoch 41: Validation loss decreased (0.327571 --> 0.326935).  Saving model ...
	 Train_Loss: 0.3853 Train_Acc: 83.835 Val_Loss: 0.3269  BEST VAL Loss: 0.3269  Val_Acc: 87.129

Epoch 42: Validation loss decreased (0.326935 --> 0.326448).  Saving model ...
	 Train_Loss: 0.3847 Train_Acc: 84.022 Val_Loss: 0.3264  BEST VAL Loss: 0.3264  Val_Acc: 86.885

Epoch 43: Validation loss decreased (0.326448 --> 0.325903).  Saving model ...
	 Train_Loss: 0.3841 Train_Acc: 84.027 Val_Loss: 0.3259  BEST VAL Loss: 0.3259  Val_Acc: 86.882

Epoch 44: Validation loss decreased (0.325903 --> 0.325400).  Saving model ...
	 Train_Loss: 0.3835 Train_Acc: 83.890 Val_Loss: 0.3254  BEST VAL Loss: 0.3254  Val_Acc: 86.979

Epoch 45: Validation loss decreased (0.325400 --> 0.324901).  Saving model ...
	 Train_Loss: 0.3830 Train_Acc: 83.968 Val_Loss: 0.3249  BEST VAL Loss: 0.3249  Val_Acc: 87.010

Epoch 46: Validation loss decreased (0.324901 --> 0.324459).  Saving model ...
	 Train_Loss: 0.3824 Train_Acc: 84.051 Val_Loss: 0.3245  BEST VAL Loss: 0.3245  Val_Acc: 87.010

Epoch 47: Validation loss decreased (0.324459 --> 0.323972).  Saving model ...
	 Train_Loss: 0.3819 Train_Acc: 84.028 Val_Loss: 0.3240  BEST VAL Loss: 0.3240  Val_Acc: 87.076

Epoch 48: Validation loss decreased (0.323972 --> 0.323522).  Saving model ...
	 Train_Loss: 0.3814 Train_Acc: 84.009 Val_Loss: 0.3235  BEST VAL Loss: 0.3235  Val_Acc: 87.156

Epoch 49: Validation loss decreased (0.323522 --> 0.323040).  Saving model ...
	 Train_Loss: 0.3809 Train_Acc: 83.948 Val_Loss: 0.3230  BEST VAL Loss: 0.3230  Val_Acc: 87.167

Epoch 50: Validation loss decreased (0.323040 --> 0.322595).  Saving model ...
	 Train_Loss: 0.3805 Train_Acc: 83.924 Val_Loss: 0.3226  BEST VAL Loss: 0.3226  Val_Acc: 87.066

Epoch 51: Validation loss decreased (0.322595 --> 0.322135).  Saving model ...
	 Train_Loss: 0.3800 Train_Acc: 84.029 Val_Loss: 0.3221  BEST VAL Loss: 0.3221  Val_Acc: 87.129

Epoch 52: Validation loss decreased (0.322135 --> 0.321700).  Saving model ...
	 Train_Loss: 0.3796 Train_Acc: 83.908 Val_Loss: 0.3217  BEST VAL Loss: 0.3217  Val_Acc: 87.153

Epoch 53: Validation loss decreased (0.321700 --> 0.321295).  Saving model ...
	 Train_Loss: 0.3792 Train_Acc: 83.969 Val_Loss: 0.3213  BEST VAL Loss: 0.3213  Val_Acc: 87.205

Epoch 54: Validation loss decreased (0.321295 --> 0.320896).  Saving model ...
	 Train_Loss: 0.3788 Train_Acc: 84.120 Val_Loss: 0.3209  BEST VAL Loss: 0.3209  Val_Acc: 87.327

Epoch 55: Validation loss decreased (0.320896 --> 0.320511).  Saving model ...
	 Train_Loss: 0.3784 Train_Acc: 84.083 Val_Loss: 0.3205  BEST VAL Loss: 0.3205  Val_Acc: 87.163

Epoch 56: Validation loss decreased (0.320511 --> 0.320124).  Saving model ...
	 Train_Loss: 0.3780 Train_Acc: 84.155 Val_Loss: 0.3201  BEST VAL Loss: 0.3201  Val_Acc: 87.198

Epoch 57: Validation loss decreased (0.320124 --> 0.319751).  Saving model ...
	 Train_Loss: 0.3776 Train_Acc: 84.037 Val_Loss: 0.3198  BEST VAL Loss: 0.3198  Val_Acc: 87.215

Epoch 58: Validation loss decreased (0.319751 --> 0.319366).  Saving model ...
	 Train_Loss: 0.3772 Train_Acc: 84.133 Val_Loss: 0.3194  BEST VAL Loss: 0.3194  Val_Acc: 87.396

Epoch 59: Validation loss decreased (0.319366 --> 0.319016).  Saving model ...
	 Train_Loss: 0.3768 Train_Acc: 84.022 Val_Loss: 0.3190  BEST VAL Loss: 0.3190  Val_Acc: 87.243

Epoch 60: Validation loss decreased (0.319016 --> 0.318670).  Saving model ...
	 Train_Loss: 0.3765 Train_Acc: 84.067 Val_Loss: 0.3187  BEST VAL Loss: 0.3187  Val_Acc: 87.261

Epoch 61: Validation loss decreased (0.318670 --> 0.318356).  Saving model ...
	 Train_Loss: 0.3761 Train_Acc: 84.052 Val_Loss: 0.3184  BEST VAL Loss: 0.3184  Val_Acc: 87.268

Epoch 62: Validation loss decreased (0.318356 --> 0.318007).  Saving model ...
	 Train_Loss: 0.3758 Train_Acc: 84.091 Val_Loss: 0.3180  BEST VAL Loss: 0.3180  Val_Acc: 87.174

Epoch 63: Validation loss decreased (0.318007 --> 0.317668).  Saving model ...
	 Train_Loss: 0.3754 Train_Acc: 84.229 Val_Loss: 0.3177  BEST VAL Loss: 0.3177  Val_Acc: 87.195

Epoch 64: Validation loss decreased (0.317668 --> 0.317367).  Saving model ...
	 Train_Loss: 0.3751 Train_Acc: 84.172 Val_Loss: 0.3174  BEST VAL Loss: 0.3174  Val_Acc: 87.181

Epoch 65: Validation loss decreased (0.317367 --> 0.317107).  Saving model ...
	 Train_Loss: 0.3748 Train_Acc: 84.130 Val_Loss: 0.3171  BEST VAL Loss: 0.3171  Val_Acc: 87.042

Epoch 66: Validation loss decreased (0.317107 --> 0.316812).  Saving model ...
	 Train_Loss: 0.3745 Train_Acc: 84.101 Val_Loss: 0.3168  BEST VAL Loss: 0.3168  Val_Acc: 87.282

Epoch 67: Validation loss decreased (0.316812 --> 0.316543).  Saving model ...
	 Train_Loss: 0.3741 Train_Acc: 84.279 Val_Loss: 0.3165  BEST VAL Loss: 0.3165  Val_Acc: 87.278

Epoch 68: Validation loss decreased (0.316543 --> 0.316277).  Saving model ...
	 Train_Loss: 0.3739 Train_Acc: 84.184 Val_Loss: 0.3163  BEST VAL Loss: 0.3163  Val_Acc: 87.219

Epoch 69: Validation loss decreased (0.316277 --> 0.316017).  Saving model ...
	 Train_Loss: 0.3736 Train_Acc: 84.260 Val_Loss: 0.3160  BEST VAL Loss: 0.3160  Val_Acc: 87.254

Epoch 70: Validation loss decreased (0.316017 --> 0.315751).  Saving model ...
	 Train_Loss: 0.3733 Train_Acc: 84.296 Val_Loss: 0.3158  BEST VAL Loss: 0.3158  Val_Acc: 87.299

Epoch 71: Validation loss decreased (0.315751 --> 0.315461).  Saving model ...
	 Train_Loss: 0.3730 Train_Acc: 84.291 Val_Loss: 0.3155  BEST VAL Loss: 0.3155  Val_Acc: 87.351

Epoch 72: Validation loss decreased (0.315461 --> 0.315156).  Saving model ...
	 Train_Loss: 0.3727 Train_Acc: 84.223 Val_Loss: 0.3152  BEST VAL Loss: 0.3152  Val_Acc: 87.348

Epoch 73: Validation loss decreased (0.315156 --> 0.314873).  Saving model ...
	 Train_Loss: 0.3724 Train_Acc: 84.308 Val_Loss: 0.3149  BEST VAL Loss: 0.3149  Val_Acc: 87.532

Epoch 74: Validation loss decreased (0.314873 --> 0.314663).  Saving model ...
	 Train_Loss: 0.3721 Train_Acc: 84.215 Val_Loss: 0.3147  BEST VAL Loss: 0.3147  Val_Acc: 87.348

Epoch 75: Validation loss decreased (0.314663 --> 0.314374).  Saving model ...
	 Train_Loss: 0.3719 Train_Acc: 84.206 Val_Loss: 0.3144  BEST VAL Loss: 0.3144  Val_Acc: 87.632

Epoch 76: Validation loss decreased (0.314374 --> 0.314096).  Saving model ...
	 Train_Loss: 0.3716 Train_Acc: 84.353 Val_Loss: 0.3141  BEST VAL Loss: 0.3141  Val_Acc: 87.354

Epoch 77: Validation loss decreased (0.314096 --> 0.313881).  Saving model ...
	 Train_Loss: 0.3713 Train_Acc: 84.408 Val_Loss: 0.3139  BEST VAL Loss: 0.3139  Val_Acc: 87.222

Epoch 78: Validation loss decreased (0.313881 --> 0.313659).  Saving model ...
	 Train_Loss: 0.3711 Train_Acc: 84.312 Val_Loss: 0.3137  BEST VAL Loss: 0.3137  Val_Acc: 87.417

Epoch 79: Validation loss decreased (0.313659 --> 0.313424).  Saving model ...
	 Train_Loss: 0.3708 Train_Acc: 84.425 Val_Loss: 0.3134  BEST VAL Loss: 0.3134  Val_Acc: 87.553

Epoch 80: Validation loss decreased (0.313424 --> 0.313228).  Saving model ...
	 Train_Loss: 0.3705 Train_Acc: 84.401 Val_Loss: 0.3132  BEST VAL Loss: 0.3132  Val_Acc: 87.393

Epoch 81: Validation loss decreased (0.313228 --> 0.312996).  Saving model ...
	 Train_Loss: 0.3703 Train_Acc: 84.358 Val_Loss: 0.3130  BEST VAL Loss: 0.3130  Val_Acc: 87.629

Epoch 82: Validation loss decreased (0.312996 --> 0.312774).  Saving model ...
	 Train_Loss: 0.3701 Train_Acc: 84.298 Val_Loss: 0.3128  BEST VAL Loss: 0.3128  Val_Acc: 87.553

Epoch 83: Validation loss decreased (0.312774 --> 0.312553).  Saving model ...
	 Train_Loss: 0.3698 Train_Acc: 84.448 Val_Loss: 0.3126  BEST VAL Loss: 0.3126  Val_Acc: 87.563

Epoch 84: Validation loss decreased (0.312553 --> 0.312354).  Saving model ...
	 Train_Loss: 0.3696 Train_Acc: 84.359 Val_Loss: 0.3124  BEST VAL Loss: 0.3124  Val_Acc: 87.466

Epoch 85: Validation loss decreased (0.312354 --> 0.312179).  Saving model ...
	 Train_Loss: 0.3694 Train_Acc: 84.254 Val_Loss: 0.3122  BEST VAL Loss: 0.3122  Val_Acc: 87.323

Epoch 86: Validation loss decreased (0.312179 --> 0.311986).  Saving model ...
	 Train_Loss: 0.3692 Train_Acc: 84.269 Val_Loss: 0.3120  BEST VAL Loss: 0.3120  Val_Acc: 87.368

Epoch 87: Validation loss decreased (0.311986 --> 0.311785).  Saving model ...
	 Train_Loss: 0.3689 Train_Acc: 84.363 Val_Loss: 0.3118  BEST VAL Loss: 0.3118  Val_Acc: 87.580

Epoch 88: Validation loss decreased (0.311785 --> 0.311607).  Saving model ...
	 Train_Loss: 0.3688 Train_Acc: 84.345 Val_Loss: 0.3116  BEST VAL Loss: 0.3116  Val_Acc: 87.462

Epoch 89: Validation loss decreased (0.311607 --> 0.311416).  Saving model ...
	 Train_Loss: 0.3686 Train_Acc: 84.335 Val_Loss: 0.3114  BEST VAL Loss: 0.3114  Val_Acc: 87.459

Epoch 90: Validation loss decreased (0.311416 --> 0.311246).  Saving model ...
	 Train_Loss: 0.3683 Train_Acc: 84.481 Val_Loss: 0.3112  BEST VAL Loss: 0.3112  Val_Acc: 87.483

Epoch 91: Validation loss decreased (0.311246 --> 0.311073).  Saving model ...
	 Train_Loss: 0.3681 Train_Acc: 84.388 Val_Loss: 0.3111  BEST VAL Loss: 0.3111  Val_Acc: 87.434

Epoch 92: Validation loss decreased (0.311073 --> 0.310918).  Saving model ...
	 Train_Loss: 0.3679 Train_Acc: 84.572 Val_Loss: 0.3109  BEST VAL Loss: 0.3109  Val_Acc: 87.302

Epoch 93: Validation loss decreased (0.310918 --> 0.310740).  Saving model ...
	 Train_Loss: 0.3677 Train_Acc: 84.453 Val_Loss: 0.3107  BEST VAL Loss: 0.3107  Val_Acc: 87.431

Epoch 94: Validation loss decreased (0.310740 --> 0.310584).  Saving model ...
	 Train_Loss: 0.3675 Train_Acc: 84.411 Val_Loss: 0.3106  BEST VAL Loss: 0.3106  Val_Acc: 87.594

Epoch 95: Validation loss decreased (0.310584 --> 0.310390).  Saving model ...
	 Train_Loss: 0.3673 Train_Acc: 84.536 Val_Loss: 0.3104  BEST VAL Loss: 0.3104  Val_Acc: 87.639

Epoch 96: Validation loss decreased (0.310390 --> 0.310236).  Saving model ...
	 Train_Loss: 0.3671 Train_Acc: 84.455 Val_Loss: 0.3102  BEST VAL Loss: 0.3102  Val_Acc: 87.344

Epoch 97: Validation loss decreased (0.310236 --> 0.310059).  Saving model ...
	 Train_Loss: 0.3669 Train_Acc: 84.416 Val_Loss: 0.3101  BEST VAL Loss: 0.3101  Val_Acc: 87.560

Epoch 98: Validation loss decreased (0.310059 --> 0.309913).  Saving model ...
	 Train_Loss: 0.3668 Train_Acc: 84.379 Val_Loss: 0.3099  BEST VAL Loss: 0.3099  Val_Acc: 87.261

Epoch 99: Validation loss decreased (0.309913 --> 0.309783).  Saving model ...
	 Train_Loss: 0.3666 Train_Acc: 84.410 Val_Loss: 0.3098  BEST VAL Loss: 0.3098  Val_Acc: 87.247

DMSO_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.90      0.92      0.91    149884
           1       0.85      0.81      0.83     80324

    accuracy                           0.89    230208
   macro avg       0.88      0.87      0.87    230208
weighted avg       0.88      0.89      0.88    230208

DMSO_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.89      0.91      0.90     18736
           1       0.83      0.80      0.81     10041

    accuracy                           0.87     28777
   macro avg       0.86      0.85      0.86     28777
weighted avg       0.87      0.87      0.87     28777

DMSO_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.89      0.91      0.90     18736
           1       0.83      0.80      0.81     10041

    accuracy                           0.87     28777
   macro avg       0.86      0.85      0.86     28777
weighted avg       0.87      0.87      0.87     28777

              precision    recall  f1-score   support

           0       0.89      0.91      0.90     18736
           1       0.83      0.80      0.81     10041

    accuracy                           0.87     28777
   macro avg       0.86      0.85      0.86     28777
weighted avg       0.87      0.87      0.87     28777

DMSO_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.65      0.91      0.76     27774
           1       0.91      0.65      0.76     38191

    accuracy                           0.76     65965
   macro avg       0.78      0.78      0.76     65965
weighted avg       0.80      0.76      0.76     65965

              precision    recall  f1-score   support

           0       0.65      0.91      0.76     27774
           1       0.91      0.65      0.76     38191

    accuracy                           0.76     65965
   macro avg       0.78      0.78      0.76     65965
weighted avg       0.80      0.76      0.76     65965

completed
