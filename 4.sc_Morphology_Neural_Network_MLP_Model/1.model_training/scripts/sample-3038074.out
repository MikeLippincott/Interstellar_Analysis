[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '5db931b1'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '6e95aec8'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'f32a0e4b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '2e67ff60'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Thapsigargin_10.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Thapsigargin_10.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (26864, 1276)
Number of total missing values across all columns: 26424
Data Subset Is Off
Wells held out for testing: ['E14' 'L20']
Wells to use for training, validation, and testing ['E15' 'L14' 'L15' 'L16' 'L17' 'L21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.109493).  Saving model ...
	 Train_Loss: 0.2177 Train_Acc: 91.053 Val_Loss: 0.1095  BEST VAL Loss: 0.1095  Val_Acc: 95.398

Epoch 1: Validation loss decreased (0.109493 --> 0.092120).  Saving model ...
	 Train_Loss: 0.1559 Train_Acc: 96.411 Val_Loss: 0.0921  BEST VAL Loss: 0.0921  Val_Acc: 96.338

Epoch 2: Validation loss decreased (0.092120 --> 0.080352).  Saving model ...
	 Train_Loss: 0.1273 Train_Acc: 97.284 Val_Loss: 0.0804  BEST VAL Loss: 0.0804  Val_Acc: 96.883

Epoch 3: Validation loss decreased (0.080352 --> 0.072157).  Saving model ...
	 Train_Loss: 0.1106 Train_Acc: 97.661 Val_Loss: 0.0722  BEST VAL Loss: 0.0722  Val_Acc: 97.229

Epoch 4: Validation loss decreased (0.072157 --> 0.071327).  Saving model ...
	 Train_Loss: 0.0980 Train_Acc: 98.224 Val_Loss: 0.0713  BEST VAL Loss: 0.0713  Val_Acc: 97.378

Epoch 5: Validation loss decreased (0.071327 --> 0.068818).  Saving model ...
	 Train_Loss: 0.0884 Train_Acc: 98.243 Val_Loss: 0.0688  BEST VAL Loss: 0.0688  Val_Acc: 97.378

Epoch 6: Validation loss decreased (0.068818 --> 0.065180).  Saving model ...
	 Train_Loss: 0.0808 Train_Acc: 98.509 Val_Loss: 0.0652  BEST VAL Loss: 0.0652  Val_Acc: 97.328

Epoch 7: Validation loss did not decrease
	 Train_Loss: 0.0749 Train_Acc: 98.620 Val_Loss: 0.0729  BEST VAL Loss: 0.0652  Val_Acc: 97.625

Epoch 8: Validation loss did not decrease
	 Train_Loss: 0.0700 Train_Acc: 98.583 Val_Loss: 0.0752  BEST VAL Loss: 0.0652  Val_Acc: 97.328

Epoch 9: Validation loss did not decrease
	 Train_Loss: 0.0657 Train_Acc: 98.818 Val_Loss: 0.0724  BEST VAL Loss: 0.0652  Val_Acc: 97.229

Epoch 10: Validation loss did not decrease
	 Train_Loss: 0.0623 Train_Acc: 98.775 Val_Loss: 0.0697  BEST VAL Loss: 0.0652  Val_Acc: 97.971

Epoch 11: Validation loss did not decrease
	 Train_Loss: 0.0594 Train_Acc: 98.744 Val_Loss: 0.0676  BEST VAL Loss: 0.0652  Val_Acc: 97.526

Epoch 12: Validation loss did not decrease
	 Train_Loss: 0.0570 Train_Acc: 98.738 Val_Loss: 0.0660  BEST VAL Loss: 0.0652  Val_Acc: 97.823

Epoch 13: Validation loss decreased (0.065180 --> 0.064816).  Saving model ...
	 Train_Loss: 0.0551 Train_Acc: 98.688 Val_Loss: 0.0648  BEST VAL Loss: 0.0648  Val_Acc: 97.378

Epoch 14: Validation loss did not decrease
	 Train_Loss: 0.0533 Train_Acc: 98.812 Val_Loss: 0.0649  BEST VAL Loss: 0.0648  Val_Acc: 97.823

Epoch 15: Validation loss decreased (0.064816 --> 0.064622).  Saving model ...
	 Train_Loss: 0.0517 Train_Acc: 98.886 Val_Loss: 0.0646  BEST VAL Loss: 0.0646  Val_Acc: 97.724

Epoch 16: Validation loss decreased (0.064622 --> 0.063804).  Saving model ...
	 Train_Loss: 0.0499 Train_Acc: 98.917 Val_Loss: 0.0638  BEST VAL Loss: 0.0638  Val_Acc: 97.328

Epoch 17: Validation loss did not decrease
	 Train_Loss: 0.0482 Train_Acc: 99.066 Val_Loss: 0.0649  BEST VAL Loss: 0.0638  Val_Acc: 97.476

Epoch 18: Validation loss did not decrease
	 Train_Loss: 0.0468 Train_Acc: 99.121 Val_Loss: 0.0653  BEST VAL Loss: 0.0638  Val_Acc: 97.823

Epoch 19: Validation loss did not decrease
	 Train_Loss: 0.0456 Train_Acc: 98.985 Val_Loss: 0.0673  BEST VAL Loss: 0.0638  Val_Acc: 97.476

Epoch 20: Validation loss did not decrease
	 Train_Loss: 0.0443 Train_Acc: 99.035 Val_Loss: 0.0662  BEST VAL Loss: 0.0638  Val_Acc: 98.021

Epoch 21: Validation loss did not decrease
	 Train_Loss: 0.0433 Train_Acc: 99.004 Val_Loss: 0.0655  BEST VAL Loss: 0.0638  Val_Acc: 97.378

Epoch 22: Validation loss did not decrease
	 Train_Loss: 0.0422 Train_Acc: 98.973 Val_Loss: 0.0671  BEST VAL Loss: 0.0638  Val_Acc: 97.724

Epoch 23: Validation loss did not decrease
	 Train_Loss: 0.0412 Train_Acc: 99.134 Val_Loss: 0.0664  BEST VAL Loss: 0.0638  Val_Acc: 97.724

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.0404 Train_Acc: 99.029 Val_Loss: 0.0658  BEST VAL Loss: 0.0638  Val_Acc: 97.872

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.0395 Train_Acc: 99.177 Val_Loss: 0.0651  BEST VAL Loss: 0.0638  Val_Acc: 97.724

Epoch 26: Validation loss did not decrease
	 Train_Loss: 0.0386 Train_Acc: 99.363 Val_Loss: 0.0677  BEST VAL Loss: 0.0638  Val_Acc: 97.922

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.0377 Train_Acc: 99.387 Val_Loss: 0.0672  BEST VAL Loss: 0.0638  Val_Acc: 97.724

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.0369 Train_Acc: 99.214 Val_Loss: 0.0731  BEST VAL Loss: 0.0638  Val_Acc: 97.773

Epoch 29: Validation loss did not decrease
	 Train_Loss: 0.0362 Train_Acc: 99.332 Val_Loss: 0.0726  BEST VAL Loss: 0.0638  Val_Acc: 98.120

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.0354 Train_Acc: 99.332 Val_Loss: 0.0721  BEST VAL Loss: 0.0638  Val_Acc: 97.971

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.0349 Train_Acc: 99.295 Val_Loss: 0.0721  BEST VAL Loss: 0.0638  Val_Acc: 97.724

Epoch 32: Validation loss did not decrease
Early stopped at epoch : 32
Thapsigargin_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.52      0.52      8312
           1       0.49      0.49      0.49      7850

    accuracy                           0.50     16162
   macro avg       0.50      0.50      0.50     16162
weighted avg       0.50      0.50      0.50     16162

Thapsigargin_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.52      0.52      1039
           1       0.49      0.49      0.49       982

    accuracy                           0.51      2021
   macro avg       0.51      0.51      0.51      2021
weighted avg       0.51      0.51      0.51      2021

Thapsigargin_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.50      0.50      1039
           1       0.47      0.48      0.47       982

    accuracy                           0.49      2021
   macro avg       0.49      0.49      0.49      2021
weighted avg       0.49      0.49      0.49      2021

              precision    recall  f1-score   support

           0       0.50      0.50      0.50      1039
           1       0.47      0.48      0.47       982

    accuracy                           0.49      2021
   macro avg       0.49      0.49      0.49      2021
weighted avg       0.49      0.49      0.49      2021

Thapsigargin_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.49      0.49      3262
           1       0.51      0.51      0.51      3398

    accuracy                           0.50      6660
   macro avg       0.50      0.50      0.50      6660
weighted avg       0.50      0.50      0.50      6660

              precision    recall  f1-score   support

           0       0.49      0.49      0.49      3262
           1       0.51      0.51      0.51      3398

    accuracy                           0.50      6660
   macro avg       0.50      0.50      0.50      6660
weighted avg       0.50      0.50      0.50      6660

completed
