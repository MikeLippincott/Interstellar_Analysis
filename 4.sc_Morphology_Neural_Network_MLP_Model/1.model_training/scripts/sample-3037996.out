[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'c0c55355'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '56875b1a'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '15e41656'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'dd259656'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: DMSO_0.100_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: DMSO_0.100_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (49295, 1276)
Number of total missing values across all columns: 71286
Data Subset Is Off
Wells held out for testing: ['I14' 'L20']
Wells to use for training, validation, and testing ['B14' 'C14' 'B15' 'C15' 'J14' 'I15' 'J15' 'L16' 'L17' 'L21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.179789).  Saving model ...
	 Train_Loss: 0.3162 Train_Acc: 87.678 Val_Loss: 0.1798  BEST VAL Loss: 0.1798  Val_Acc: 93.762

Epoch 1: Validation loss decreased (0.179789 --> 0.151903).  Saving model ...
	 Train_Loss: 0.2454 Train_Acc: 93.531 Val_Loss: 0.1519  BEST VAL Loss: 0.1519  Val_Acc: 95.777

Epoch 2: Validation loss decreased (0.151903 --> 0.131067).  Saving model ...
	 Train_Loss: 0.2088 Train_Acc: 95.103 Val_Loss: 0.1311  BEST VAL Loss: 0.1311  Val_Acc: 96.529

Epoch 3: Validation loss decreased (0.131067 --> 0.119201).  Saving model ...
	 Train_Loss: 0.1851 Train_Acc: 95.807 Val_Loss: 0.1192  BEST VAL Loss: 0.1192  Val_Acc: 96.966

Epoch 4: Validation loss decreased (0.119201 --> 0.111167).  Saving model ...
	 Train_Loss: 0.1691 Train_Acc: 96.213 Val_Loss: 0.1112  BEST VAL Loss: 0.1112  Val_Acc: 97.379

Epoch 5: Validation loss decreased (0.111167 --> 0.103858).  Saving model ...
	 Train_Loss: 0.1573 Train_Acc: 96.338 Val_Loss: 0.1039  BEST VAL Loss: 0.1039  Val_Acc: 97.160

Epoch 6: Validation loss decreased (0.103858 --> 0.100843).  Saving model ...
	 Train_Loss: 0.1480 Train_Acc: 96.662 Val_Loss: 0.1008  BEST VAL Loss: 0.1008  Val_Acc: 97.087

Epoch 7: Validation loss decreased (0.100843 --> 0.096958).  Saving model ...
	 Train_Loss: 0.1406 Train_Acc: 96.750 Val_Loss: 0.0970  BEST VAL Loss: 0.0970  Val_Acc: 97.549

Epoch 8: Validation loss decreased (0.096958 --> 0.094300).  Saving model ...
	 Train_Loss: 0.1343 Train_Acc: 96.890 Val_Loss: 0.0943  BEST VAL Loss: 0.0943  Val_Acc: 97.184

Epoch 9: Validation loss decreased (0.094300 --> 0.091217).  Saving model ...
	 Train_Loss: 0.1286 Train_Acc: 97.114 Val_Loss: 0.0912  BEST VAL Loss: 0.0912  Val_Acc: 97.621

Epoch 10: Validation loss decreased (0.091217 --> 0.088819).  Saving model ...
	 Train_Loss: 0.1237 Train_Acc: 97.199 Val_Loss: 0.0888  BEST VAL Loss: 0.0888  Val_Acc: 97.670

Epoch 11: Validation loss decreased (0.088819 --> 0.087575).  Saving model ...
	 Train_Loss: 0.1200 Train_Acc: 97.078 Val_Loss: 0.0876  BEST VAL Loss: 0.0876  Val_Acc: 97.257

Epoch 12: Validation loss decreased (0.087575 --> 0.085497).  Saving model ...
	 Train_Loss: 0.1162 Train_Acc: 97.418 Val_Loss: 0.0855  BEST VAL Loss: 0.0855  Val_Acc: 97.816

Epoch 13: Validation loss decreased (0.085497 --> 0.084304).  Saving model ...
	 Train_Loss: 0.1129 Train_Acc: 97.454 Val_Loss: 0.0843  BEST VAL Loss: 0.0843  Val_Acc: 98.010

Epoch 14: Validation loss decreased (0.084304 --> 0.082561).  Saving model ...
	 Train_Loss: 0.1098 Train_Acc: 97.518 Val_Loss: 0.0826  BEST VAL Loss: 0.0826  Val_Acc: 97.767

Epoch 15: Validation loss decreased (0.082561 --> 0.081825).  Saving model ...
	 Train_Loss: 0.1071 Train_Acc: 97.618 Val_Loss: 0.0818  BEST VAL Loss: 0.0818  Val_Acc: 97.646

Epoch 16: Validation loss decreased (0.081825 --> 0.080609).  Saving model ...
	 Train_Loss: 0.1047 Train_Acc: 97.554 Val_Loss: 0.0806  BEST VAL Loss: 0.0806  Val_Acc: 98.083

Epoch 17: Validation loss decreased (0.080609 --> 0.079417).  Saving model ...
	 Train_Loss: 0.1026 Train_Acc: 97.600 Val_Loss: 0.0794  BEST VAL Loss: 0.0794  Val_Acc: 98.204

Epoch 18: Validation loss decreased (0.079417 --> 0.078473).  Saving model ...
	 Train_Loss: 0.1004 Train_Acc: 97.843 Val_Loss: 0.0785  BEST VAL Loss: 0.0785  Val_Acc: 97.840

Epoch 19: Validation loss decreased (0.078473 --> 0.077632).  Saving model ...
	 Train_Loss: 0.0984 Train_Acc: 97.770 Val_Loss: 0.0776  BEST VAL Loss: 0.0776  Val_Acc: 97.888

Epoch 20: Validation loss decreased (0.077632 --> 0.077130).  Saving model ...
	 Train_Loss: 0.0964 Train_Acc: 97.967 Val_Loss: 0.0771  BEST VAL Loss: 0.0771  Val_Acc: 97.937

Epoch 21: Validation loss did not decrease
	 Train_Loss: 0.0948 Train_Acc: 97.697 Val_Loss: 0.0774  BEST VAL Loss: 0.0771  Val_Acc: 97.913

Epoch 22: Validation loss decreased (0.077130 --> 0.077087).  Saving model ...
	 Train_Loss: 0.0933 Train_Acc: 97.770 Val_Loss: 0.0771  BEST VAL Loss: 0.0771  Val_Acc: 97.864

Epoch 23: Validation loss decreased (0.077087 --> 0.076879).  Saving model ...
	 Train_Loss: 0.0918 Train_Acc: 97.973 Val_Loss: 0.0769  BEST VAL Loss: 0.0769  Val_Acc: 97.913

Epoch 24: Validation loss decreased (0.076879 --> 0.076198).  Saving model ...
	 Train_Loss: 0.0904 Train_Acc: 98.019 Val_Loss: 0.0762  BEST VAL Loss: 0.0762  Val_Acc: 98.131

Epoch 25: Validation loss decreased (0.076198 --> 0.076095).  Saving model ...
	 Train_Loss: 0.0890 Train_Acc: 98.028 Val_Loss: 0.0761  BEST VAL Loss: 0.0761  Val_Acc: 97.864

Epoch 26: Validation loss decreased (0.076095 --> 0.075758).  Saving model ...
	 Train_Loss: 0.0877 Train_Acc: 97.876 Val_Loss: 0.0758  BEST VAL Loss: 0.0758  Val_Acc: 98.034

Epoch 27: Validation loss decreased (0.075758 --> 0.075269).  Saving model ...
	 Train_Loss: 0.0864 Train_Acc: 98.143 Val_Loss: 0.0753  BEST VAL Loss: 0.0753  Val_Acc: 98.180

Epoch 28: Validation loss decreased (0.075269 --> 0.074689).  Saving model ...
	 Train_Loss: 0.0852 Train_Acc: 98.201 Val_Loss: 0.0747  BEST VAL Loss: 0.0747  Val_Acc: 97.985

Epoch 29: Validation loss decreased (0.074689 --> 0.074047).  Saving model ...
	 Train_Loss: 0.0842 Train_Acc: 98.076 Val_Loss: 0.0740  BEST VAL Loss: 0.0740  Val_Acc: 98.107

Epoch 30: Validation loss decreased (0.074047 --> 0.073498).  Saving model ...
	 Train_Loss: 0.0831 Train_Acc: 98.140 Val_Loss: 0.0735  BEST VAL Loss: 0.0735  Val_Acc: 98.180

Epoch 31: Validation loss decreased (0.073498 --> 0.073401).  Saving model ...
	 Train_Loss: 0.0821 Train_Acc: 98.207 Val_Loss: 0.0734  BEST VAL Loss: 0.0734  Val_Acc: 98.228

Epoch 32: Validation loss decreased (0.073401 --> 0.073039).  Saving model ...
	 Train_Loss: 0.0812 Train_Acc: 98.222 Val_Loss: 0.0730  BEST VAL Loss: 0.0730  Val_Acc: 98.325

Epoch 33: Validation loss decreased (0.073039 --> 0.072472).  Saving model ...
	 Train_Loss: 0.0802 Train_Acc: 98.210 Val_Loss: 0.0725  BEST VAL Loss: 0.0725  Val_Acc: 98.155

Epoch 34: Validation loss decreased (0.072472 --> 0.072229).  Saving model ...
	 Train_Loss: 0.0793 Train_Acc: 98.249 Val_Loss: 0.0722  BEST VAL Loss: 0.0722  Val_Acc: 98.010

Epoch 35: Validation loss decreased (0.072229 --> 0.071963).  Saving model ...
	 Train_Loss: 0.0784 Train_Acc: 98.346 Val_Loss: 0.0720  BEST VAL Loss: 0.0720  Val_Acc: 98.058

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.0775 Train_Acc: 98.407 Val_Loss: 0.0720  BEST VAL Loss: 0.0720  Val_Acc: 97.937

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.0767 Train_Acc: 98.310 Val_Loss: 0.0723  BEST VAL Loss: 0.0720  Val_Acc: 98.034

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.0760 Train_Acc: 98.267 Val_Loss: 0.0720  BEST VAL Loss: 0.0720  Val_Acc: 98.155

Epoch 39: Validation loss decreased (0.071963 --> 0.071633).  Saving model ...
	 Train_Loss: 0.0753 Train_Acc: 98.173 Val_Loss: 0.0716  BEST VAL Loss: 0.0716  Val_Acc: 98.204

Epoch 40: Validation loss decreased (0.071633 --> 0.071410).  Saving model ...
	 Train_Loss: 0.0747 Train_Acc: 98.249 Val_Loss: 0.0714  BEST VAL Loss: 0.0714  Val_Acc: 98.010

Epoch 41: Validation loss decreased (0.071410 --> 0.071243).  Saving model ...
	 Train_Loss: 0.0741 Train_Acc: 98.289 Val_Loss: 0.0712  BEST VAL Loss: 0.0712  Val_Acc: 97.985

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.0734 Train_Acc: 98.431 Val_Loss: 0.0713  BEST VAL Loss: 0.0712  Val_Acc: 98.083

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.0728 Train_Acc: 98.380 Val_Loss: 0.0714  BEST VAL Loss: 0.0712  Val_Acc: 98.083

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.0721 Train_Acc: 98.389 Val_Loss: 0.0715  BEST VAL Loss: 0.0712  Val_Acc: 98.131

Epoch 45: Validation loss decreased (0.071243 --> 0.071217).  Saving model ...
	 Train_Loss: 0.0715 Train_Acc: 98.495 Val_Loss: 0.0712  BEST VAL Loss: 0.0712  Val_Acc: 98.131

Epoch 46: Validation loss decreased (0.071217 --> 0.071117).  Saving model ...
	 Train_Loss: 0.0710 Train_Acc: 98.307 Val_Loss: 0.0711  BEST VAL Loss: 0.0711  Val_Acc: 98.058

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.0704 Train_Acc: 98.498 Val_Loss: 0.0711  BEST VAL Loss: 0.0711  Val_Acc: 98.107

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.0698 Train_Acc: 98.562 Val_Loss: 0.0711  BEST VAL Loss: 0.0711  Val_Acc: 98.155

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.0692 Train_Acc: 98.410 Val_Loss: 0.0715  BEST VAL Loss: 0.0711  Val_Acc: 98.058

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.0687 Train_Acc: 98.568 Val_Loss: 0.0714  BEST VAL Loss: 0.0711  Val_Acc: 98.131

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.0683 Train_Acc: 98.292 Val_Loss: 0.0714  BEST VAL Loss: 0.0711  Val_Acc: 98.325

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.0678 Train_Acc: 98.434 Val_Loss: 0.0714  BEST VAL Loss: 0.0711  Val_Acc: 97.961

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.0674 Train_Acc: 98.480 Val_Loss: 0.0712  BEST VAL Loss: 0.0711  Val_Acc: 98.204

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.0669 Train_Acc: 98.647 Val_Loss: 0.0711  BEST VAL Loss: 0.0711  Val_Acc: 97.937

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.0665 Train_Acc: 98.449 Val_Loss: 0.0716  BEST VAL Loss: 0.0711  Val_Acc: 98.350

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.0660 Train_Acc: 98.604 Val_Loss: 0.0715  BEST VAL Loss: 0.0711  Val_Acc: 98.350

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.0655 Train_Acc: 98.668 Val_Loss: 0.0714  BEST VAL Loss: 0.0711  Val_Acc: 98.252

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.0651 Train_Acc: 98.610 Val_Loss: 0.0716  BEST VAL Loss: 0.0711  Val_Acc: 98.422

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.0647 Train_Acc: 98.507 Val_Loss: 0.0715  BEST VAL Loss: 0.0711  Val_Acc: 98.277

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.0643 Train_Acc: 98.540 Val_Loss: 0.0717  BEST VAL Loss: 0.0711  Val_Acc: 98.180

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.0640 Train_Acc: 98.452 Val_Loss: 0.0717  BEST VAL Loss: 0.0711  Val_Acc: 98.083

Epoch 62: Validation loss did not decrease
Early stopped at epoch : 62
DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.75      0.75      0.75     24644
           1       0.26      0.25      0.26      8312

    accuracy                           0.63     32956
   macro avg       0.50      0.50      0.50     32956
weighted avg       0.62      0.63      0.63     32956

DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.75      0.75      0.75      3081
           1       0.25      0.25      0.25      1039

    accuracy                           0.62      4120
   macro avg       0.50      0.50      0.50      4120
weighted avg       0.62      0.62      0.62      4120

DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.75      0.75      0.75      3081
           1       0.25      0.25      0.25      1039

    accuracy                           0.63      4120
   macro avg       0.50      0.50      0.50      4120
weighted avg       0.62      0.63      0.62      4120

              precision    recall  f1-score   support

           0       0.75      0.75      0.75      3081
           1       0.25      0.25      0.25      1039

    accuracy                           0.63      4120
   macro avg       0.50      0.50      0.50      4120
weighted avg       0.62      0.63      0.62      4120

DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.60      0.60      0.60      4837
           1       0.40      0.40      0.40      3262

    accuracy                           0.52      8099
   macro avg       0.50      0.50      0.50      8099
weighted avg       0.52      0.52      0.52      8099

              precision    recall  f1-score   support

           0       0.60      0.60      0.60      4837
           1       0.40      0.40      0.40      3262

    accuracy                           0.52      8099
   macro avg       0.50      0.50      0.50      8099
weighted avg       0.52      0.52      0.52      8099

completed
