[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '12d96dbc'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'dfce5d16'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '00c1241d'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'dc6c1104'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_10.000_DMSO_0.025 treatment_name: Thapsigargin_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: Thapsigargin_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'Thapsigargin_1.000_DMSO_0.025']
The dimensions of the data are: (304946, 1270)
Number of total missing values across all columns: 609892
Data Subset Is Off
Wells held out for testing: ['E09' 'K06']
Wells to use for training, validation, and testing ['E02' 'E03' 'D06' 'D07' 'E08' 'K07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.572598).  Saving model ...
	 Train_Loss: 0.6288 Train_Acc: 64.470 Val_Loss: 0.5726  BEST VAL Loss: 0.5726  Val_Acc: 71.351

Epoch 1: Validation loss decreased (0.572598 --> 0.547895).  Saving model ...
	 Train_Loss: 0.5939 Train_Acc: 71.814 Val_Loss: 0.5479  BEST VAL Loss: 0.5479  Val_Acc: 74.360

Epoch 2: Validation loss decreased (0.547895 --> 0.532048).  Saving model ...
	 Train_Loss: 0.5716 Train_Acc: 73.872 Val_Loss: 0.5320  BEST VAL Loss: 0.5320  Val_Acc: 75.642

Epoch 3: Validation loss decreased (0.532048 --> 0.520596).  Saving model ...
	 Train_Loss: 0.5560 Train_Acc: 74.820 Val_Loss: 0.5206  BEST VAL Loss: 0.5206  Val_Acc: 76.055

Epoch 4: Validation loss decreased (0.520596 --> 0.511938).  Saving model ...
	 Train_Loss: 0.5443 Train_Acc: 75.442 Val_Loss: 0.5119  BEST VAL Loss: 0.5119  Val_Acc: 76.632

Epoch 5: Validation loss decreased (0.511938 --> 0.505080).  Saving model ...
	 Train_Loss: 0.5350 Train_Acc: 75.949 Val_Loss: 0.5051  BEST VAL Loss: 0.5051  Val_Acc: 76.805

Epoch 6: Validation loss decreased (0.505080 --> 0.499076).  Saving model ...
	 Train_Loss: 0.5274 Train_Acc: 76.317 Val_Loss: 0.4991  BEST VAL Loss: 0.4991  Val_Acc: 77.431

Epoch 7: Validation loss decreased (0.499076 --> 0.493877).  Saving model ...
	 Train_Loss: 0.5210 Train_Acc: 76.667 Val_Loss: 0.4939  BEST VAL Loss: 0.4939  Val_Acc: 78.021

Epoch 8: Validation loss decreased (0.493877 --> 0.489274).  Saving model ...
	 Train_Loss: 0.5154 Train_Acc: 77.061 Val_Loss: 0.4893  BEST VAL Loss: 0.4893  Val_Acc: 78.172

Epoch 9: Validation loss decreased (0.489274 --> 0.484990).  Saving model ...
	 Train_Loss: 0.5102 Train_Acc: 77.359 Val_Loss: 0.4850  BEST VAL Loss: 0.4850  Val_Acc: 78.154

Epoch 10: Validation loss decreased (0.484990 --> 0.481188).  Saving model ...
	 Train_Loss: 0.5056 Train_Acc: 77.603 Val_Loss: 0.4812  BEST VAL Loss: 0.4812  Val_Acc: 78.922

Epoch 11: Validation loss decreased (0.481188 --> 0.477512).  Saving model ...
	 Train_Loss: 0.5014 Train_Acc: 77.863 Val_Loss: 0.4775  BEST VAL Loss: 0.4775  Val_Acc: 78.944

Epoch 12: Validation loss decreased (0.477512 --> 0.474190).  Saving model ...
	 Train_Loss: 0.4974 Train_Acc: 78.164 Val_Loss: 0.4742  BEST VAL Loss: 0.4742  Val_Acc: 78.979

Epoch 13: Validation loss decreased (0.474190 --> 0.470985).  Saving model ...
	 Train_Loss: 0.4938 Train_Acc: 78.395 Val_Loss: 0.4710  BEST VAL Loss: 0.4710  Val_Acc: 79.503

Epoch 14: Validation loss decreased (0.470985 --> 0.468040).  Saving model ...
	 Train_Loss: 0.4904 Train_Acc: 78.609 Val_Loss: 0.4680  BEST VAL Loss: 0.4680  Val_Acc: 79.596

Epoch 15: Validation loss decreased (0.468040 --> 0.465318).  Saving model ...
	 Train_Loss: 0.4873 Train_Acc: 78.891 Val_Loss: 0.4653  BEST VAL Loss: 0.4653  Val_Acc: 79.791

Epoch 16: Validation loss decreased (0.465318 --> 0.462650).  Saving model ...
	 Train_Loss: 0.4843 Train_Acc: 78.980 Val_Loss: 0.4627  BEST VAL Loss: 0.4627  Val_Acc: 80.146

Epoch 17: Validation loss decreased (0.462650 --> 0.460201).  Saving model ...
	 Train_Loss: 0.4815 Train_Acc: 79.141 Val_Loss: 0.4602  BEST VAL Loss: 0.4602  Val_Acc: 80.297

Epoch 18: Validation loss decreased (0.460201 --> 0.457837).  Saving model ...
	 Train_Loss: 0.4788 Train_Acc: 79.292 Val_Loss: 0.4578  BEST VAL Loss: 0.4578  Val_Acc: 80.439

Epoch 19: Validation loss decreased (0.457837 --> 0.455583).  Saving model ...
	 Train_Loss: 0.4763 Train_Acc: 79.564 Val_Loss: 0.4556  BEST VAL Loss: 0.4556  Val_Acc: 80.541

Epoch 20: Validation loss decreased (0.455583 --> 0.453461).  Saving model ...
	 Train_Loss: 0.4739 Train_Acc: 79.573 Val_Loss: 0.4535  BEST VAL Loss: 0.4535  Val_Acc: 80.759

Epoch 21: Validation loss decreased (0.453461 --> 0.451570).  Saving model ...
	 Train_Loss: 0.4717 Train_Acc: 79.769 Val_Loss: 0.4516  BEST VAL Loss: 0.4516  Val_Acc: 80.848

Epoch 22: Validation loss decreased (0.451570 --> 0.449788).  Saving model ...
	 Train_Loss: 0.4695 Train_Acc: 79.915 Val_Loss: 0.4498  BEST VAL Loss: 0.4498  Val_Acc: 80.750

Epoch 23: Validation loss decreased (0.449788 --> 0.447992).  Saving model ...
	 Train_Loss: 0.4674 Train_Acc: 79.892 Val_Loss: 0.4480  BEST VAL Loss: 0.4480  Val_Acc: 81.123

Epoch 24: Validation loss decreased (0.447992 --> 0.446159).  Saving model ...
	 Train_Loss: 0.4655 Train_Acc: 80.168 Val_Loss: 0.4462  BEST VAL Loss: 0.4462  Val_Acc: 81.247

Epoch 25: Validation loss decreased (0.446159 --> 0.444782).  Saving model ...
	 Train_Loss: 0.4636 Train_Acc: 80.053 Val_Loss: 0.4448  BEST VAL Loss: 0.4448  Val_Acc: 80.799

Epoch 26: Validation loss decreased (0.444782 --> 0.443209).  Saving model ...
	 Train_Loss: 0.4617 Train_Acc: 80.314 Val_Loss: 0.4432  BEST VAL Loss: 0.4432  Val_Acc: 81.163

Epoch 27: Validation loss decreased (0.443209 --> 0.441718).  Saving model ...
	 Train_Loss: 0.4600 Train_Acc: 80.420 Val_Loss: 0.4417  BEST VAL Loss: 0.4417  Val_Acc: 81.420

Epoch 28: Validation loss decreased (0.441718 --> 0.440428).  Saving model ...
	 Train_Loss: 0.4582 Train_Acc: 80.502 Val_Loss: 0.4404  BEST VAL Loss: 0.4404  Val_Acc: 80.808

Epoch 29: Validation loss decreased (0.440428 --> 0.438966).  Saving model ...
	 Train_Loss: 0.4566 Train_Acc: 80.639 Val_Loss: 0.4390  BEST VAL Loss: 0.4390  Val_Acc: 81.549

Epoch 30: Validation loss decreased (0.438966 --> 0.437535).  Saving model ...
	 Train_Loss: 0.4550 Train_Acc: 80.750 Val_Loss: 0.4375  BEST VAL Loss: 0.4375  Val_Acc: 81.553

Epoch 31: Validation loss decreased (0.437535 --> 0.436185).  Saving model ...
	 Train_Loss: 0.4535 Train_Acc: 80.663 Val_Loss: 0.4362  BEST VAL Loss: 0.4362  Val_Acc: 81.584

Epoch 32: Validation loss decreased (0.436185 --> 0.434848).  Saving model ...
	 Train_Loss: 0.4520 Train_Acc: 80.852 Val_Loss: 0.4348  BEST VAL Loss: 0.4348  Val_Acc: 81.575

Epoch 33: Validation loss decreased (0.434848 --> 0.433571).  Saving model ...
	 Train_Loss: 0.4506 Train_Acc: 80.904 Val_Loss: 0.4336  BEST VAL Loss: 0.4336  Val_Acc: 81.926

Epoch 34: Validation loss decreased (0.433571 --> 0.432345).  Saving model ...
	 Train_Loss: 0.4492 Train_Acc: 80.982 Val_Loss: 0.4323  BEST VAL Loss: 0.4323  Val_Acc: 81.784

Epoch 35: Validation loss decreased (0.432345 --> 0.431098).  Saving model ...
	 Train_Loss: 0.4478 Train_Acc: 81.029 Val_Loss: 0.4311  BEST VAL Loss: 0.4311  Val_Acc: 81.890

Epoch 36: Validation loss decreased (0.431098 --> 0.429886).  Saving model ...
	 Train_Loss: 0.4465 Train_Acc: 81.129 Val_Loss: 0.4299  BEST VAL Loss: 0.4299  Val_Acc: 82.015

Epoch 37: Validation loss decreased (0.429886 --> 0.428751).  Saving model ...
	 Train_Loss: 0.4452 Train_Acc: 81.325 Val_Loss: 0.4288  BEST VAL Loss: 0.4288  Val_Acc: 82.095

Epoch 38: Validation loss decreased (0.428751 --> 0.427771).  Saving model ...
	 Train_Loss: 0.4439 Train_Acc: 81.207 Val_Loss: 0.4278  BEST VAL Loss: 0.4278  Val_Acc: 81.655

Epoch 39: Validation loss decreased (0.427771 --> 0.426628).  Saving model ...
	 Train_Loss: 0.4427 Train_Acc: 81.365 Val_Loss: 0.4266  BEST VAL Loss: 0.4266  Val_Acc: 82.361

Epoch 40: Validation loss decreased (0.426628 --> 0.425568).  Saving model ...
	 Train_Loss: 0.4415 Train_Acc: 81.499 Val_Loss: 0.4256  BEST VAL Loss: 0.4256  Val_Acc: 82.006

Epoch 41: Validation loss decreased (0.425568 --> 0.424732).  Saving model ...
	 Train_Loss: 0.4403 Train_Acc: 81.609 Val_Loss: 0.4247  BEST VAL Loss: 0.4247  Val_Acc: 81.859

Epoch 42: Validation loss decreased (0.424732 --> 0.423669).  Saving model ...
	 Train_Loss: 0.4391 Train_Acc: 81.615 Val_Loss: 0.4237  BEST VAL Loss: 0.4237  Val_Acc: 82.498

Epoch 43: Validation loss decreased (0.423669 --> 0.422791).  Saving model ...
	 Train_Loss: 0.4380 Train_Acc: 81.740 Val_Loss: 0.4228  BEST VAL Loss: 0.4228  Val_Acc: 82.330

Epoch 44: Validation loss decreased (0.422791 --> 0.421861).  Saving model ...
	 Train_Loss: 0.4369 Train_Acc: 81.753 Val_Loss: 0.4219  BEST VAL Loss: 0.4219  Val_Acc: 82.321

Epoch 45: Validation loss decreased (0.421861 --> 0.420942).  Saving model ...
	 Train_Loss: 0.4358 Train_Acc: 81.886 Val_Loss: 0.4209  BEST VAL Loss: 0.4209  Val_Acc: 82.432

Epoch 46: Validation loss decreased (0.420942 --> 0.419973).  Saving model ...
	 Train_Loss: 0.4347 Train_Acc: 81.797 Val_Loss: 0.4200  BEST VAL Loss: 0.4200  Val_Acc: 82.663

Epoch 47: Validation loss decreased (0.419973 --> 0.419065).  Saving model ...
	 Train_Loss: 0.4337 Train_Acc: 81.874 Val_Loss: 0.4191  BEST VAL Loss: 0.4191  Val_Acc: 82.698

Epoch 48: Validation loss decreased (0.419065 --> 0.418130).  Saving model ...
	 Train_Loss: 0.4326 Train_Acc: 81.941 Val_Loss: 0.4181  BEST VAL Loss: 0.4181  Val_Acc: 82.796

Epoch 49: Validation loss decreased (0.418130 --> 0.417241).  Saving model ...
	 Train_Loss: 0.4316 Train_Acc: 81.992 Val_Loss: 0.4172  BEST VAL Loss: 0.4172  Val_Acc: 82.867

Epoch 50: Validation loss decreased (0.417241 --> 0.416383).  Saving model ...
	 Train_Loss: 0.4306 Train_Acc: 82.068 Val_Loss: 0.4164  BEST VAL Loss: 0.4164  Val_Acc: 82.742

Epoch 51: Validation loss decreased (0.416383 --> 0.415597).  Saving model ...
	 Train_Loss: 0.4296 Train_Acc: 82.163 Val_Loss: 0.4156  BEST VAL Loss: 0.4156  Val_Acc: 82.765

Epoch 52: Validation loss decreased (0.415597 --> 0.414948).  Saving model ...
	 Train_Loss: 0.4287 Train_Acc: 82.125 Val_Loss: 0.4149  BEST VAL Loss: 0.4149  Val_Acc: 82.356

Epoch 53: Validation loss decreased (0.414948 --> 0.414092).  Saving model ...
	 Train_Loss: 0.4277 Train_Acc: 82.237 Val_Loss: 0.4141  BEST VAL Loss: 0.4141  Val_Acc: 83.089

Epoch 54: Validation loss decreased (0.414092 --> 0.413326).  Saving model ...
	 Train_Loss: 0.4268 Train_Acc: 82.245 Val_Loss: 0.4133  BEST VAL Loss: 0.4133  Val_Acc: 83.018

Epoch 55: Validation loss decreased (0.413326 --> 0.412528).  Saving model ...
	 Train_Loss: 0.4259 Train_Acc: 82.361 Val_Loss: 0.4125  BEST VAL Loss: 0.4125  Val_Acc: 83.102

Epoch 56: Validation loss decreased (0.412528 --> 0.411733).  Saving model ...
	 Train_Loss: 0.4250 Train_Acc: 82.334 Val_Loss: 0.4117  BEST VAL Loss: 0.4117  Val_Acc: 83.231

Epoch 57: Validation loss decreased (0.411733 --> 0.410918).  Saving model ...
	 Train_Loss: 0.4241 Train_Acc: 82.404 Val_Loss: 0.4109  BEST VAL Loss: 0.4109  Val_Acc: 83.528

Epoch 58: Validation loss decreased (0.410918 --> 0.410117).  Saving model ...
	 Train_Loss: 0.4233 Train_Acc: 82.461 Val_Loss: 0.4101  BEST VAL Loss: 0.4101  Val_Acc: 83.275

Epoch 59: Validation loss decreased (0.410117 --> 0.409413).  Saving model ...
	 Train_Loss: 0.4224 Train_Acc: 82.472 Val_Loss: 0.4094  BEST VAL Loss: 0.4094  Val_Acc: 83.164

Epoch 60: Validation loss decreased (0.409413 --> 0.408717).  Saving model ...
	 Train_Loss: 0.4216 Train_Acc: 82.650 Val_Loss: 0.4087  BEST VAL Loss: 0.4087  Val_Acc: 82.995

Epoch 61: Validation loss decreased (0.408717 --> 0.407994).  Saving model ...
	 Train_Loss: 0.4207 Train_Acc: 82.653 Val_Loss: 0.4080  BEST VAL Loss: 0.4080  Val_Acc: 83.310

Epoch 62: Validation loss decreased (0.407994 --> 0.407253).  Saving model ...
	 Train_Loss: 0.4199 Train_Acc: 82.652 Val_Loss: 0.4073  BEST VAL Loss: 0.4073  Val_Acc: 83.364

Epoch 63: Validation loss decreased (0.407253 --> 0.406543).  Saving model ...
	 Train_Loss: 0.4191 Train_Acc: 82.705 Val_Loss: 0.4065  BEST VAL Loss: 0.4065  Val_Acc: 83.235

Epoch 64: Validation loss decreased (0.406543 --> 0.405873).  Saving model ...
	 Train_Loss: 0.4183 Train_Acc: 82.679 Val_Loss: 0.4059  BEST VAL Loss: 0.4059  Val_Acc: 83.559

Epoch 65: Validation loss decreased (0.405873 --> 0.405209).  Saving model ...
	 Train_Loss: 0.4175 Train_Acc: 82.746 Val_Loss: 0.4052  BEST VAL Loss: 0.4052  Val_Acc: 83.457

Epoch 66: Validation loss decreased (0.405209 --> 0.404495).  Saving model ...
	 Train_Loss: 0.4168 Train_Acc: 82.763 Val_Loss: 0.4045  BEST VAL Loss: 0.4045  Val_Acc: 83.554

Epoch 67: Validation loss decreased (0.404495 --> 0.403843).  Saving model ...
	 Train_Loss: 0.4160 Train_Acc: 82.919 Val_Loss: 0.4038  BEST VAL Loss: 0.4038  Val_Acc: 83.501

Epoch 68: Validation loss decreased (0.403843 --> 0.403261).  Saving model ...
	 Train_Loss: 0.4153 Train_Acc: 82.891 Val_Loss: 0.4033  BEST VAL Loss: 0.4033  Val_Acc: 83.368

Epoch 69: Validation loss decreased (0.403261 --> 0.402639).  Saving model ...
	 Train_Loss: 0.4145 Train_Acc: 82.828 Val_Loss: 0.4026  BEST VAL Loss: 0.4026  Val_Acc: 83.741

Epoch 70: Validation loss decreased (0.402639 --> 0.401987).  Saving model ...
	 Train_Loss: 0.4138 Train_Acc: 82.979 Val_Loss: 0.4020  BEST VAL Loss: 0.4020  Val_Acc: 83.843

Epoch 71: Validation loss decreased (0.401987 --> 0.401340).  Saving model ...
	 Train_Loss: 0.4131 Train_Acc: 82.992 Val_Loss: 0.4013  BEST VAL Loss: 0.4013  Val_Acc: 83.696

Epoch 72: Validation loss decreased (0.401340 --> 0.400709).  Saving model ...
	 Train_Loss: 0.4124 Train_Acc: 83.015 Val_Loss: 0.4007  BEST VAL Loss: 0.4007  Val_Acc: 83.781

Epoch 73: Validation loss decreased (0.400709 --> 0.400095).  Saving model ...
	 Train_Loss: 0.4117 Train_Acc: 82.995 Val_Loss: 0.4001  BEST VAL Loss: 0.4001  Val_Acc: 83.710

Epoch 74: Validation loss decreased (0.400095 --> 0.399494).  Saving model ...
	 Train_Loss: 0.4111 Train_Acc: 83.113 Val_Loss: 0.3995  BEST VAL Loss: 0.3995  Val_Acc: 83.683

Epoch 75: Validation loss decreased (0.399494 --> 0.398895).  Saving model ...
	 Train_Loss: 0.4104 Train_Acc: 83.121 Val_Loss: 0.3989  BEST VAL Loss: 0.3989  Val_Acc: 83.807

Epoch 76: Validation loss decreased (0.398895 --> 0.398320).  Saving model ...
	 Train_Loss: 0.4097 Train_Acc: 83.173 Val_Loss: 0.3983  BEST VAL Loss: 0.3983  Val_Acc: 83.852

Epoch 77: Validation loss decreased (0.398320 --> 0.397764).  Saving model ...
	 Train_Loss: 0.4090 Train_Acc: 83.311 Val_Loss: 0.3978  BEST VAL Loss: 0.3978  Val_Acc: 83.865

Epoch 78: Validation loss decreased (0.397764 --> 0.397202).  Saving model ...
	 Train_Loss: 0.4084 Train_Acc: 83.289 Val_Loss: 0.3972  BEST VAL Loss: 0.3972  Val_Acc: 83.861

Epoch 79: Validation loss decreased (0.397202 --> 0.396648).  Saving model ...
	 Train_Loss: 0.4077 Train_Acc: 83.336 Val_Loss: 0.3966  BEST VAL Loss: 0.3966  Val_Acc: 83.896

Epoch 80: Validation loss decreased (0.396648 --> 0.396126).  Saving model ...
	 Train_Loss: 0.4071 Train_Acc: 83.338 Val_Loss: 0.3961  BEST VAL Loss: 0.3961  Val_Acc: 83.803

Epoch 81: Validation loss decreased (0.396126 --> 0.395562).  Saving model ...
	 Train_Loss: 0.4065 Train_Acc: 83.280 Val_Loss: 0.3956  BEST VAL Loss: 0.3956  Val_Acc: 83.843

Epoch 82: Validation loss decreased (0.395562 --> 0.395024).  Saving model ...
	 Train_Loss: 0.4059 Train_Acc: 83.345 Val_Loss: 0.3950  BEST VAL Loss: 0.3950  Val_Acc: 83.967

Epoch 83: Validation loss decreased (0.395024 --> 0.394502).  Saving model ...
	 Train_Loss: 0.4053 Train_Acc: 83.275 Val_Loss: 0.3945  BEST VAL Loss: 0.3945  Val_Acc: 83.985

Epoch 84: Validation loss decreased (0.394502 --> 0.393987).  Saving model ...
	 Train_Loss: 0.4047 Train_Acc: 83.353 Val_Loss: 0.3940  BEST VAL Loss: 0.3940  Val_Acc: 84.207

Epoch 85: Validation loss decreased (0.393987 --> 0.393480).  Saving model ...
	 Train_Loss: 0.4041 Train_Acc: 83.467 Val_Loss: 0.3935  BEST VAL Loss: 0.3935  Val_Acc: 83.954

Epoch 86: Validation loss decreased (0.393480 --> 0.392949).  Saving model ...
	 Train_Loss: 0.4035 Train_Acc: 83.426 Val_Loss: 0.3929  BEST VAL Loss: 0.3929  Val_Acc: 84.105

Epoch 87: Validation loss decreased (0.392949 --> 0.392441).  Saving model ...
	 Train_Loss: 0.4029 Train_Acc: 83.414 Val_Loss: 0.3924  BEST VAL Loss: 0.3924  Val_Acc: 84.145

Epoch 88: Validation loss decreased (0.392441 --> 0.391930).  Saving model ...
	 Train_Loss: 0.4023 Train_Acc: 83.504 Val_Loss: 0.3919  BEST VAL Loss: 0.3919  Val_Acc: 84.353

Epoch 89: Validation loss decreased (0.391930 --> 0.391469).  Saving model ...
	 Train_Loss: 0.4018 Train_Acc: 83.480 Val_Loss: 0.3915  BEST VAL Loss: 0.3915  Val_Acc: 84.154

Epoch 90: Validation loss decreased (0.391469 --> 0.390972).  Saving model ...
	 Train_Loss: 0.4012 Train_Acc: 83.470 Val_Loss: 0.3910  BEST VAL Loss: 0.3910  Val_Acc: 84.078

Epoch 91: Validation loss decreased (0.390972 --> 0.390525).  Saving model ...
	 Train_Loss: 0.4007 Train_Acc: 83.515 Val_Loss: 0.3905  BEST VAL Loss: 0.3905  Val_Acc: 84.020

Epoch 92: Validation loss decreased (0.390525 --> 0.390151).  Saving model ...
	 Train_Loss: 0.4001 Train_Acc: 83.563 Val_Loss: 0.3902  BEST VAL Loss: 0.3902  Val_Acc: 83.581

Epoch 93: Validation loss decreased (0.390151 --> 0.389725).  Saving model ...
	 Train_Loss: 0.3996 Train_Acc: 83.578 Val_Loss: 0.3897  BEST VAL Loss: 0.3897  Val_Acc: 83.945

Epoch 94: Validation loss decreased (0.389725 --> 0.389259).  Saving model ...
	 Train_Loss: 0.3991 Train_Acc: 83.636 Val_Loss: 0.3893  BEST VAL Loss: 0.3893  Val_Acc: 84.207

Epoch 95: Validation loss decreased (0.389259 --> 0.388786).  Saving model ...
	 Train_Loss: 0.3985 Train_Acc: 83.762 Val_Loss: 0.3888  BEST VAL Loss: 0.3888  Val_Acc: 84.415

Epoch 96: Validation loss decreased (0.388786 --> 0.388349).  Saving model ...
	 Train_Loss: 0.3980 Train_Acc: 83.662 Val_Loss: 0.3883  BEST VAL Loss: 0.3883  Val_Acc: 84.287

Epoch 97: Validation loss decreased (0.388349 --> 0.387934).  Saving model ...
	 Train_Loss: 0.3975 Train_Acc: 83.596 Val_Loss: 0.3879  BEST VAL Loss: 0.3879  Val_Acc: 83.905

Epoch 98: Validation loss decreased (0.387934 --> 0.387576).  Saving model ...
	 Train_Loss: 0.3970 Train_Acc: 83.700 Val_Loss: 0.3876  BEST VAL Loss: 0.3876  Val_Acc: 84.038

Epoch 99: Validation loss decreased (0.387576 --> 0.387212).  Saving model ...
	 Train_Loss: 0.3965 Train_Acc: 83.695 Val_Loss: 0.3872  BEST VAL Loss: 0.3872  Val_Acc: 83.648

LPS_10.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.52      0.52     92173
           1       0.49      0.48      0.48     88099

    accuracy                           0.50    180272
   macro avg       0.50      0.50      0.50    180272
weighted avg       0.50      0.50      0.50    180272

LPS_10.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.52      0.51     11522
           1       0.48      0.47      0.48     11013

    accuracy                           0.50     22535
   macro avg       0.50      0.50      0.50     22535
weighted avg       0.50      0.50      0.50     22535

LPS_10.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.53      0.52     11522
           1       0.50      0.49      0.49     11012

    accuracy                           0.51     22534
   macro avg       0.51      0.51      0.51     22534
weighted avg       0.51      0.51      0.51     22534

              precision    recall  f1-score   support

           0       0.52      0.53      0.52     11522
           1       0.50      0.49      0.49     11012

    accuracy                           0.51     22534
   macro avg       0.51      0.51      0.51     22534
weighted avg       0.51      0.51      0.51     22534

LPS_10.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.44      0.48     41273
           1       0.48      0.56      0.52     38332

    accuracy                           0.50     79605
   macro avg       0.50      0.50      0.50     79605
weighted avg       0.50      0.50      0.50     79605

              precision    recall  f1-score   support

           0       0.52      0.44      0.48     41273
           1       0.48      0.56      0.52     38332

    accuracy                           0.50     79605
   macro avg       0.50      0.50      0.50     79605
weighted avg       0.50      0.50      0.50     79605

completed
