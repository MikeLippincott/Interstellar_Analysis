[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '9acf9aa9'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e4f39eaa'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b35b8a68'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '86aa0475'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Thapsigargin_1.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Thapsigargin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (27418, 1276)
Number of total missing values across all columns: 27532
Data Subset Is Off
Wells held out for testing: ['D14' 'L20']
Wells to use for training, validation, and testing ['D15' 'K14' 'K15' 'L16' 'L17' 'L21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.329908).  Saving model ...
	 Train_Loss: 0.4705 Train_Acc: 74.858 Val_Loss: 0.3299  BEST VAL Loss: 0.3299  Val_Acc: 90.892

Epoch 1: Validation loss decreased (0.329908 --> 0.285696).  Saving model ...
	 Train_Loss: 0.3766 Train_Acc: 90.684 Val_Loss: 0.2857  BEST VAL Loss: 0.2857  Val_Acc: 94.056

Epoch 2: Validation loss decreased (0.285696 --> 0.257315).  Saving model ...
	 Train_Loss: 0.3254 Train_Acc: 93.010 Val_Loss: 0.2573  BEST VAL Loss: 0.2573  Val_Acc: 94.823

Epoch 3: Validation loss decreased (0.257315 --> 0.237224).  Saving model ...
	 Train_Loss: 0.2910 Train_Acc: 93.735 Val_Loss: 0.2372  BEST VAL Loss: 0.2372  Val_Acc: 95.350

Epoch 4: Validation loss decreased (0.237224 --> 0.220982).  Saving model ...
	 Train_Loss: 0.2662 Train_Acc: 94.329 Val_Loss: 0.2210  BEST VAL Loss: 0.2210  Val_Acc: 95.781

Epoch 5: Validation loss decreased (0.220982 --> 0.208248).  Saving model ...
	 Train_Loss: 0.2468 Train_Acc: 94.796 Val_Loss: 0.2082  BEST VAL Loss: 0.2082  Val_Acc: 96.117

Epoch 6: Validation loss decreased (0.208248 --> 0.197822).  Saving model ...
	 Train_Loss: 0.2308 Train_Acc: 95.468 Val_Loss: 0.1978  BEST VAL Loss: 0.1978  Val_Acc: 96.213

Epoch 7: Validation loss decreased (0.197822 --> 0.188923).  Saving model ...
	 Train_Loss: 0.2178 Train_Acc: 95.654 Val_Loss: 0.1889  BEST VAL Loss: 0.1889  Val_Acc: 96.405

Epoch 8: Validation loss decreased (0.188923 --> 0.181213).  Saving model ...
	 Train_Loss: 0.2069 Train_Acc: 95.804 Val_Loss: 0.1812  BEST VAL Loss: 0.1812  Val_Acc: 96.596

Epoch 9: Validation loss decreased (0.181213 --> 0.174647).  Saving model ...
	 Train_Loss: 0.1976 Train_Acc: 96.061 Val_Loss: 0.1746  BEST VAL Loss: 0.1746  Val_Acc: 96.884

Epoch 10: Validation loss decreased (0.174647 --> 0.168812).  Saving model ...
	 Train_Loss: 0.1894 Train_Acc: 96.409 Val_Loss: 0.1688  BEST VAL Loss: 0.1688  Val_Acc: 96.980

Epoch 11: Validation loss decreased (0.168812 --> 0.163572).  Saving model ...
	 Train_Loss: 0.1822 Train_Acc: 96.517 Val_Loss: 0.1636  BEST VAL Loss: 0.1636  Val_Acc: 96.980

Epoch 12: Validation loss decreased (0.163572 --> 0.158855).  Saving model ...
	 Train_Loss: 0.1755 Train_Acc: 96.679 Val_Loss: 0.1589  BEST VAL Loss: 0.1589  Val_Acc: 97.124

Epoch 13: Validation loss decreased (0.158855 --> 0.154507).  Saving model ...
	 Train_Loss: 0.1696 Train_Acc: 96.841 Val_Loss: 0.1545  BEST VAL Loss: 0.1545  Val_Acc: 97.267

Epoch 14: Validation loss decreased (0.154507 --> 0.150588).  Saving model ...
	 Train_Loss: 0.1643 Train_Acc: 97.003 Val_Loss: 0.1506  BEST VAL Loss: 0.1506  Val_Acc: 97.267

Epoch 15: Validation loss decreased (0.150588 --> 0.147044).  Saving model ...
	 Train_Loss: 0.1593 Train_Acc: 97.063 Val_Loss: 0.1470  BEST VAL Loss: 0.1470  Val_Acc: 97.459

Epoch 16: Validation loss decreased (0.147044 --> 0.143807).  Saving model ...
	 Train_Loss: 0.1548 Train_Acc: 97.182 Val_Loss: 0.1438  BEST VAL Loss: 0.1438  Val_Acc: 97.603

Epoch 17: Validation loss decreased (0.143807 --> 0.140751).  Saving model ...
	 Train_Loss: 0.1506 Train_Acc: 97.398 Val_Loss: 0.1408  BEST VAL Loss: 0.1408  Val_Acc: 97.747

Epoch 18: Validation loss decreased (0.140751 --> 0.137971).  Saving model ...
	 Train_Loss: 0.1467 Train_Acc: 97.404 Val_Loss: 0.1380  BEST VAL Loss: 0.1380  Val_Acc: 97.747

Epoch 19: Validation loss decreased (0.137971 --> 0.135317).  Saving model ...
	 Train_Loss: 0.1431 Train_Acc: 97.524 Val_Loss: 0.1353  BEST VAL Loss: 0.1353  Val_Acc: 97.795

Epoch 20: Validation loss decreased (0.135317 --> 0.132888).  Saving model ...
	 Train_Loss: 0.1397 Train_Acc: 97.494 Val_Loss: 0.1329  BEST VAL Loss: 0.1329  Val_Acc: 97.795

Epoch 21: Validation loss decreased (0.132888 --> 0.130622).  Saving model ...
	 Train_Loss: 0.1366 Train_Acc: 97.662 Val_Loss: 0.1306  BEST VAL Loss: 0.1306  Val_Acc: 97.891

Epoch 22: Validation loss decreased (0.130622 --> 0.128439).  Saving model ...
	 Train_Loss: 0.1336 Train_Acc: 97.710 Val_Loss: 0.1284  BEST VAL Loss: 0.1284  Val_Acc: 97.891

Epoch 23: Validation loss decreased (0.128439 --> 0.126359).  Saving model ...
	 Train_Loss: 0.1308 Train_Acc: 97.824 Val_Loss: 0.1264  BEST VAL Loss: 0.1264  Val_Acc: 98.035

Epoch 24: Validation loss decreased (0.126359 --> 0.124429).  Saving model ...
	 Train_Loss: 0.1281 Train_Acc: 97.938 Val_Loss: 0.1244  BEST VAL Loss: 0.1244  Val_Acc: 98.035

Epoch 25: Validation loss decreased (0.124429 --> 0.122605).  Saving model ...
	 Train_Loss: 0.1256 Train_Acc: 97.878 Val_Loss: 0.1226  BEST VAL Loss: 0.1226  Val_Acc: 97.987

Epoch 26: Validation loss decreased (0.122605 --> 0.120917).  Saving model ...
	 Train_Loss: 0.1232 Train_Acc: 98.004 Val_Loss: 0.1209  BEST VAL Loss: 0.1209  Val_Acc: 97.987

Epoch 27: Validation loss decreased (0.120917 --> 0.119340).  Saving model ...
	 Train_Loss: 0.1210 Train_Acc: 97.962 Val_Loss: 0.1193  BEST VAL Loss: 0.1193  Val_Acc: 97.843

Epoch 28: Validation loss decreased (0.119340 --> 0.117840).  Saving model ...
	 Train_Loss: 0.1188 Train_Acc: 98.094 Val_Loss: 0.1178  BEST VAL Loss: 0.1178  Val_Acc: 97.939

Epoch 29: Validation loss decreased (0.117840 --> 0.116378).  Saving model ...
	 Train_Loss: 0.1167 Train_Acc: 98.184 Val_Loss: 0.1164  BEST VAL Loss: 0.1164  Val_Acc: 97.939

Epoch 30: Validation loss decreased (0.116378 --> 0.114980).  Saving model ...
	 Train_Loss: 0.1148 Train_Acc: 98.022 Val_Loss: 0.1150  BEST VAL Loss: 0.1150  Val_Acc: 97.987

Epoch 31: Validation loss decreased (0.114980 --> 0.113662).  Saving model ...
	 Train_Loss: 0.1129 Train_Acc: 98.148 Val_Loss: 0.1137  BEST VAL Loss: 0.1137  Val_Acc: 97.939

Epoch 32: Validation loss decreased (0.113662 --> 0.112421).  Saving model ...
	 Train_Loss: 0.1111 Train_Acc: 98.345 Val_Loss: 0.1124  BEST VAL Loss: 0.1124  Val_Acc: 97.939

Epoch 33: Validation loss decreased (0.112421 --> 0.111200).  Saving model ...
	 Train_Loss: 0.1094 Train_Acc: 98.250 Val_Loss: 0.1112  BEST VAL Loss: 0.1112  Val_Acc: 97.987

Epoch 34: Validation loss decreased (0.111200 --> 0.110023).  Saving model ...
	 Train_Loss: 0.1077 Train_Acc: 98.423 Val_Loss: 0.1100  BEST VAL Loss: 0.1100  Val_Acc: 97.987

Epoch 35: Validation loss decreased (0.110023 --> 0.108944).  Saving model ...
	 Train_Loss: 0.1061 Train_Acc: 98.315 Val_Loss: 0.1089  BEST VAL Loss: 0.1089  Val_Acc: 97.939

Epoch 36: Validation loss decreased (0.108944 --> 0.107871).  Saving model ...
	 Train_Loss: 0.1046 Train_Acc: 98.417 Val_Loss: 0.1079  BEST VAL Loss: 0.1079  Val_Acc: 97.939

Epoch 37: Validation loss decreased (0.107871 --> 0.106859).  Saving model ...
	 Train_Loss: 0.1031 Train_Acc: 98.411 Val_Loss: 0.1069  BEST VAL Loss: 0.1069  Val_Acc: 97.891

Epoch 38: Validation loss decreased (0.106859 --> 0.105864).  Saving model ...
	 Train_Loss: 0.1016 Train_Acc: 98.381 Val_Loss: 0.1059  BEST VAL Loss: 0.1059  Val_Acc: 97.843

Epoch 39: Validation loss decreased (0.105864 --> 0.104888).  Saving model ...
	 Train_Loss: 0.1002 Train_Acc: 98.615 Val_Loss: 0.1049  BEST VAL Loss: 0.1049  Val_Acc: 98.035

Epoch 40: Validation loss decreased (0.104888 --> 0.103987).  Saving model ...
	 Train_Loss: 0.0989 Train_Acc: 98.351 Val_Loss: 0.1040  BEST VAL Loss: 0.1040  Val_Acc: 97.939

Epoch 41: Validation loss decreased (0.103987 --> 0.103101).  Saving model ...
	 Train_Loss: 0.0976 Train_Acc: 98.477 Val_Loss: 0.1031  BEST VAL Loss: 0.1031  Val_Acc: 98.035

Epoch 42: Validation loss decreased (0.103101 --> 0.102208).  Saving model ...
	 Train_Loss: 0.0964 Train_Acc: 98.531 Val_Loss: 0.1022  BEST VAL Loss: 0.1022  Val_Acc: 97.987

Epoch 43: Validation loss decreased (0.102208 --> 0.101354).  Saving model ...
	 Train_Loss: 0.0952 Train_Acc: 98.543 Val_Loss: 0.1014  BEST VAL Loss: 0.1014  Val_Acc: 97.939

Epoch 44: Validation loss decreased (0.101354 --> 0.100527).  Saving model ...
	 Train_Loss: 0.0941 Train_Acc: 98.597 Val_Loss: 0.1005  BEST VAL Loss: 0.1005  Val_Acc: 98.035

Epoch 45: Validation loss decreased (0.100527 --> 0.099732).  Saving model ...
	 Train_Loss: 0.0930 Train_Acc: 98.573 Val_Loss: 0.0997  BEST VAL Loss: 0.0997  Val_Acc: 98.082

Epoch 46: Validation loss decreased (0.099732 --> 0.098943).  Saving model ...
	 Train_Loss: 0.0919 Train_Acc: 98.597 Val_Loss: 0.0989  BEST VAL Loss: 0.0989  Val_Acc: 98.035

Epoch 47: Validation loss decreased (0.098943 --> 0.098180).  Saving model ...
	 Train_Loss: 0.0908 Train_Acc: 98.771 Val_Loss: 0.0982  BEST VAL Loss: 0.0982  Val_Acc: 98.082

Epoch 48: Validation loss decreased (0.098180 --> 0.097428).  Saving model ...
	 Train_Loss: 0.0898 Train_Acc: 98.753 Val_Loss: 0.0974  BEST VAL Loss: 0.0974  Val_Acc: 98.035

Epoch 49: Validation loss decreased (0.097428 --> 0.096741).  Saving model ...
	 Train_Loss: 0.0888 Train_Acc: 98.687 Val_Loss: 0.0967  BEST VAL Loss: 0.0967  Val_Acc: 97.987

Epoch 50: Validation loss decreased (0.096741 --> 0.096068).  Saving model ...
	 Train_Loss: 0.0878 Train_Acc: 98.789 Val_Loss: 0.0961  BEST VAL Loss: 0.0961  Val_Acc: 98.130

Epoch 51: Validation loss decreased (0.096068 --> 0.095410).  Saving model ...
	 Train_Loss: 0.0869 Train_Acc: 98.615 Val_Loss: 0.0954  BEST VAL Loss: 0.0954  Val_Acc: 98.035

Epoch 52: Validation loss decreased (0.095410 --> 0.094778).  Saving model ...
	 Train_Loss: 0.0860 Train_Acc: 98.795 Val_Loss: 0.0948  BEST VAL Loss: 0.0948  Val_Acc: 98.082

Epoch 53: Validation loss decreased (0.094778 --> 0.094142).  Saving model ...
	 Train_Loss: 0.0851 Train_Acc: 98.855 Val_Loss: 0.0941  BEST VAL Loss: 0.0941  Val_Acc: 98.035

Epoch 54: Validation loss decreased (0.094142 --> 0.093529).  Saving model ...
	 Train_Loss: 0.0842 Train_Acc: 98.885 Val_Loss: 0.0935  BEST VAL Loss: 0.0935  Val_Acc: 98.082

Epoch 55: Validation loss decreased (0.093529 --> 0.092939).  Saving model ...
	 Train_Loss: 0.0834 Train_Acc: 98.795 Val_Loss: 0.0929  BEST VAL Loss: 0.0929  Val_Acc: 98.178

Epoch 56: Validation loss decreased (0.092939 --> 0.092328).  Saving model ...
	 Train_Loss: 0.0826 Train_Acc: 98.777 Val_Loss: 0.0923  BEST VAL Loss: 0.0923  Val_Acc: 98.082

Epoch 57: Validation loss decreased (0.092328 --> 0.091754).  Saving model ...
	 Train_Loss: 0.0818 Train_Acc: 98.867 Val_Loss: 0.0918  BEST VAL Loss: 0.0918  Val_Acc: 98.035

Epoch 58: Validation loss decreased (0.091754 --> 0.091204).  Saving model ...
	 Train_Loss: 0.0810 Train_Acc: 98.927 Val_Loss: 0.0912  BEST VAL Loss: 0.0912  Val_Acc: 98.082

Epoch 59: Validation loss decreased (0.091204 --> 0.090673).  Saving model ...
	 Train_Loss: 0.0802 Train_Acc: 98.849 Val_Loss: 0.0907  BEST VAL Loss: 0.0907  Val_Acc: 98.130

Epoch 60: Validation loss decreased (0.090673 --> 0.090184).  Saving model ...
	 Train_Loss: 0.0795 Train_Acc: 98.945 Val_Loss: 0.0902  BEST VAL Loss: 0.0902  Val_Acc: 98.130

Epoch 61: Validation loss decreased (0.090184 --> 0.089684).  Saving model ...
	 Train_Loss: 0.0787 Train_Acc: 98.915 Val_Loss: 0.0897  BEST VAL Loss: 0.0897  Val_Acc: 98.082

Epoch 62: Validation loss decreased (0.089684 --> 0.089197).  Saving model ...
	 Train_Loss: 0.0780 Train_Acc: 98.945 Val_Loss: 0.0892  BEST VAL Loss: 0.0892  Val_Acc: 98.178

Epoch 63: Validation loss decreased (0.089197 --> 0.088703).  Saving model ...
	 Train_Loss: 0.0773 Train_Acc: 99.053 Val_Loss: 0.0887  BEST VAL Loss: 0.0887  Val_Acc: 98.082

Epoch 64: Validation loss decreased (0.088703 --> 0.088242).  Saving model ...
	 Train_Loss: 0.0766 Train_Acc: 99.119 Val_Loss: 0.0882  BEST VAL Loss: 0.0882  Val_Acc: 98.130

Epoch 65: Validation loss decreased (0.088242 --> 0.087786).  Saving model ...
	 Train_Loss: 0.0759 Train_Acc: 99.095 Val_Loss: 0.0878  BEST VAL Loss: 0.0878  Val_Acc: 98.178

Epoch 66: Validation loss decreased (0.087786 --> 0.087368).  Saving model ...
	 Train_Loss: 0.0753 Train_Acc: 99.029 Val_Loss: 0.0874  BEST VAL Loss: 0.0874  Val_Acc: 97.987

Epoch 67: Validation loss decreased (0.087368 --> 0.086942).  Saving model ...
	 Train_Loss: 0.0746 Train_Acc: 98.951 Val_Loss: 0.0869  BEST VAL Loss: 0.0869  Val_Acc: 98.082

Epoch 68: Validation loss decreased (0.086942 --> 0.086506).  Saving model ...
	 Train_Loss: 0.0740 Train_Acc: 99.131 Val_Loss: 0.0865  BEST VAL Loss: 0.0865  Val_Acc: 98.130

Epoch 69: Validation loss decreased (0.086506 --> 0.086110).  Saving model ...
	 Train_Loss: 0.0734 Train_Acc: 99.017 Val_Loss: 0.0861  BEST VAL Loss: 0.0861  Val_Acc: 98.130

Epoch 70: Validation loss decreased (0.086110 --> 0.085733).  Saving model ...
	 Train_Loss: 0.0728 Train_Acc: 98.921 Val_Loss: 0.0857  BEST VAL Loss: 0.0857  Val_Acc: 98.082

Epoch 71: Validation loss decreased (0.085733 --> 0.085362).  Saving model ...
	 Train_Loss: 0.0722 Train_Acc: 99.119 Val_Loss: 0.0854  BEST VAL Loss: 0.0854  Val_Acc: 98.130

Epoch 72: Validation loss decreased (0.085362 --> 0.084983).  Saving model ...
	 Train_Loss: 0.0716 Train_Acc: 99.161 Val_Loss: 0.0850  BEST VAL Loss: 0.0850  Val_Acc: 98.082

Epoch 73: Validation loss decreased (0.084983 --> 0.084621).  Saving model ...
	 Train_Loss: 0.0711 Train_Acc: 99.053 Val_Loss: 0.0846  BEST VAL Loss: 0.0846  Val_Acc: 98.130

Epoch 74: Validation loss decreased (0.084621 --> 0.084265).  Saving model ...
	 Train_Loss: 0.0705 Train_Acc: 99.071 Val_Loss: 0.0843  BEST VAL Loss: 0.0843  Val_Acc: 98.178

Epoch 75: Validation loss decreased (0.084265 --> 0.083935).  Saving model ...
	 Train_Loss: 0.0700 Train_Acc: 99.149 Val_Loss: 0.0839  BEST VAL Loss: 0.0839  Val_Acc: 98.178

Epoch 76: Validation loss decreased (0.083935 --> 0.083584).  Saving model ...
	 Train_Loss: 0.0694 Train_Acc: 99.221 Val_Loss: 0.0836  BEST VAL Loss: 0.0836  Val_Acc: 98.130

Epoch 77: Validation loss decreased (0.083584 --> 0.083254).  Saving model ...
	 Train_Loss: 0.0689 Train_Acc: 99.089 Val_Loss: 0.0833  BEST VAL Loss: 0.0833  Val_Acc: 98.178

Epoch 78: Validation loss decreased (0.083254 --> 0.082915).  Saving model ...
	 Train_Loss: 0.0684 Train_Acc: 99.143 Val_Loss: 0.0829  BEST VAL Loss: 0.0829  Val_Acc: 98.226

Epoch 79: Validation loss decreased (0.082915 --> 0.082585).  Saving model ...
	 Train_Loss: 0.0679 Train_Acc: 99.179 Val_Loss: 0.0826  BEST VAL Loss: 0.0826  Val_Acc: 98.130

Epoch 80: Validation loss decreased (0.082585 --> 0.082281).  Saving model ...
	 Train_Loss: 0.0674 Train_Acc: 99.239 Val_Loss: 0.0823  BEST VAL Loss: 0.0823  Val_Acc: 98.035

Epoch 81: Validation loss decreased (0.082281 --> 0.081966).  Saving model ...
	 Train_Loss: 0.0669 Train_Acc: 99.113 Val_Loss: 0.0820  BEST VAL Loss: 0.0820  Val_Acc: 98.178

Epoch 82: Validation loss decreased (0.081966 --> 0.081654).  Saving model ...
	 Train_Loss: 0.0664 Train_Acc: 99.089 Val_Loss: 0.0817  BEST VAL Loss: 0.0817  Val_Acc: 98.226

Epoch 83: Validation loss decreased (0.081654 --> 0.081353).  Saving model ...
	 Train_Loss: 0.0659 Train_Acc: 99.197 Val_Loss: 0.0814  BEST VAL Loss: 0.0814  Val_Acc: 98.274

Epoch 84: Validation loss decreased (0.081353 --> 0.081063).  Saving model ...
	 Train_Loss: 0.0655 Train_Acc: 99.281 Val_Loss: 0.0811  BEST VAL Loss: 0.0811  Val_Acc: 98.226

Epoch 85: Validation loss decreased (0.081063 --> 0.080776).  Saving model ...
	 Train_Loss: 0.0650 Train_Acc: 99.209 Val_Loss: 0.0808  BEST VAL Loss: 0.0808  Val_Acc: 98.130

Epoch 86: Validation loss decreased (0.080776 --> 0.080505).  Saving model ...
	 Train_Loss: 0.0645 Train_Acc: 99.227 Val_Loss: 0.0805  BEST VAL Loss: 0.0805  Val_Acc: 98.178

Epoch 87: Validation loss decreased (0.080505 --> 0.080220).  Saving model ...
	 Train_Loss: 0.0641 Train_Acc: 99.287 Val_Loss: 0.0802  BEST VAL Loss: 0.0802  Val_Acc: 98.226

Epoch 88: Validation loss decreased (0.080220 --> 0.079961).  Saving model ...
	 Train_Loss: 0.0637 Train_Acc: 99.203 Val_Loss: 0.0800  BEST VAL Loss: 0.0800  Val_Acc: 98.226

Epoch 89: Validation loss decreased (0.079961 --> 0.079698).  Saving model ...
	 Train_Loss: 0.0632 Train_Acc: 99.269 Val_Loss: 0.0797  BEST VAL Loss: 0.0797  Val_Acc: 98.226

Epoch 90: Validation loss decreased (0.079698 --> 0.079449).  Saving model ...
	 Train_Loss: 0.0628 Train_Acc: 99.323 Val_Loss: 0.0794  BEST VAL Loss: 0.0794  Val_Acc: 98.130

Epoch 91: Validation loss decreased (0.079449 --> 0.079206).  Saving model ...
	 Train_Loss: 0.0624 Train_Acc: 99.149 Val_Loss: 0.0792  BEST VAL Loss: 0.0792  Val_Acc: 98.226

Epoch 92: Validation loss decreased (0.079206 --> 0.078959).  Saving model ...
	 Train_Loss: 0.0620 Train_Acc: 99.365 Val_Loss: 0.0790  BEST VAL Loss: 0.0790  Val_Acc: 98.226

Epoch 93: Validation loss decreased (0.078959 --> 0.078711).  Saving model ...
	 Train_Loss: 0.0616 Train_Acc: 99.263 Val_Loss: 0.0787  BEST VAL Loss: 0.0787  Val_Acc: 98.274

Epoch 94: Validation loss decreased (0.078711 --> 0.078479).  Saving model ...
	 Train_Loss: 0.0612 Train_Acc: 99.239 Val_Loss: 0.0785  BEST VAL Loss: 0.0785  Val_Acc: 98.274

Epoch 95: Validation loss decreased (0.078479 --> 0.078244).  Saving model ...
	 Train_Loss: 0.0608 Train_Acc: 99.197 Val_Loss: 0.0782  BEST VAL Loss: 0.0782  Val_Acc: 98.370

Epoch 96: Validation loss decreased (0.078244 --> 0.078012).  Saving model ...
	 Train_Loss: 0.0605 Train_Acc: 99.287 Val_Loss: 0.0780  BEST VAL Loss: 0.0780  Val_Acc: 98.322

Epoch 97: Validation loss decreased (0.078012 --> 0.077798).  Saving model ...
	 Train_Loss: 0.0601 Train_Acc: 99.317 Val_Loss: 0.0778  BEST VAL Loss: 0.0778  Val_Acc: 98.370

Epoch 98: Validation loss decreased (0.077798 --> 0.077582).  Saving model ...
	 Train_Loss: 0.0597 Train_Acc: 99.305 Val_Loss: 0.0776  BEST VAL Loss: 0.0776  Val_Acc: 98.322

Epoch 99: Validation loss decreased (0.077582 --> 0.077377).  Saving model ...
	 Train_Loss: 0.0594 Train_Acc: 99.227 Val_Loss: 0.0774  BEST VAL Loss: 0.0774  Val_Acc: 98.322

Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      8312
           1       1.00      1.00      1.00      8369

    accuracy                           1.00     16681
   macro avg       1.00      1.00      1.00     16681
weighted avg       1.00      1.00      1.00     16681

Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.99      0.98      1039
           1       0.99      0.98      0.98      1047

    accuracy                           0.98      2086
   macro avg       0.98      0.98      0.98      2086
weighted avg       0.98      0.98      0.98      2086

Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.99      0.98      1039
           1       0.99      0.98      0.98      1047

    accuracy                           0.98      2086
   macro avg       0.98      0.98      0.98      2086
weighted avg       0.98      0.98      0.98      2086

              precision    recall  f1-score   support

           0       0.98      0.99      0.98      1039
           1       0.99      0.98      0.98      1047

    accuracy                           0.98      2086
   macro avg       0.98      0.98      0.98      2086
weighted avg       0.98      0.98      0.98      2086

Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      1.00      0.99      3262
           1       1.00      0.98      0.99      3303

    accuracy                           0.99      6565
   macro avg       0.99      0.99      0.99      6565
weighted avg       0.99      0.99      0.99      6565

              precision    recall  f1-score   support

           0       0.98      1.00      0.99      3262
           1       1.00      0.98      0.99      3303

    accuracy                           0.99      6565
   macro avg       0.99      0.99      0.99      6565
weighted avg       0.99      0.99      0.99      6565

completed
