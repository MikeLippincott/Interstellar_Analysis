[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ac00af62'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '49d756fa'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'c8785cc7'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '17a6631a'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_1.000_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_1.000_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (298868, 1270)
Number of total missing values across all columns: 597736
Data Subset Is Off
Wells held out for testing: ['D08' 'J08']
Wells to use for training, validation, and testing ['D02' 'D03' 'D09' 'J02' 'J03' 'J09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.620664).  Saving model ...
	 Train_Loss: 0.6574 Train_Acc: 60.109 Val_Loss: 0.6207  BEST VAL Loss: 0.6207  Val_Acc: 65.657

Epoch 1: Validation loss decreased (0.620664 --> 0.602135).  Saving model ...
	 Train_Loss: 0.6344 Train_Acc: 65.585 Val_Loss: 0.6021  BEST VAL Loss: 0.6021  Val_Acc: 68.528

Epoch 2: Validation loss decreased (0.602135 --> 0.587900).  Saving model ...
	 Train_Loss: 0.6182 Train_Acc: 67.927 Val_Loss: 0.5879  BEST VAL Loss: 0.5879  Val_Acc: 70.127

Epoch 3: Validation loss decreased (0.587900 --> 0.577359).  Saving model ...
	 Train_Loss: 0.6058 Train_Acc: 69.122 Val_Loss: 0.5774  BEST VAL Loss: 0.5774  Val_Acc: 71.276

Epoch 4: Validation loss decreased (0.577359 --> 0.569085).  Saving model ...
	 Train_Loss: 0.5959 Train_Acc: 70.140 Val_Loss: 0.5691  BEST VAL Loss: 0.5691  Val_Acc: 72.101

Epoch 5: Validation loss decreased (0.569085 --> 0.563263).  Saving model ...
	 Train_Loss: 0.5877 Train_Acc: 70.967 Val_Loss: 0.5633  BEST VAL Loss: 0.5633  Val_Acc: 72.267

Epoch 6: Validation loss decreased (0.563263 --> 0.557597).  Saving model ...
	 Train_Loss: 0.5808 Train_Acc: 71.536 Val_Loss: 0.5576  BEST VAL Loss: 0.5576  Val_Acc: 72.988

Epoch 7: Validation loss decreased (0.557597 --> 0.552197).  Saving model ...
	 Train_Loss: 0.5748 Train_Acc: 72.104 Val_Loss: 0.5522  BEST VAL Loss: 0.5522  Val_Acc: 73.475

Epoch 8: Validation loss decreased (0.552197 --> 0.547371).  Saving model ...
	 Train_Loss: 0.5695 Train_Acc: 72.442 Val_Loss: 0.5474  BEST VAL Loss: 0.5474  Val_Acc: 73.876

Epoch 9: Validation loss decreased (0.547371 --> 0.543473).  Saving model ...
	 Train_Loss: 0.5648 Train_Acc: 72.647 Val_Loss: 0.5435  BEST VAL Loss: 0.5435  Val_Acc: 74.029

Epoch 10: Validation loss decreased (0.543473 --> 0.539719).  Saving model ...
	 Train_Loss: 0.5605 Train_Acc: 72.982 Val_Loss: 0.5397  BEST VAL Loss: 0.5397  Val_Acc: 74.795

Epoch 11: Validation loss decreased (0.539719 --> 0.536293).  Saving model ...
	 Train_Loss: 0.5565 Train_Acc: 73.372 Val_Loss: 0.5363  BEST VAL Loss: 0.5363  Val_Acc: 74.809

Epoch 12: Validation loss decreased (0.536293 --> 0.533099).  Saving model ...
	 Train_Loss: 0.5530 Train_Acc: 73.610 Val_Loss: 0.5331  BEST VAL Loss: 0.5331  Val_Acc: 75.011

Epoch 13: Validation loss decreased (0.533099 --> 0.530304).  Saving model ...
	 Train_Loss: 0.5497 Train_Acc: 73.699 Val_Loss: 0.5303  BEST VAL Loss: 0.5303  Val_Acc: 75.034

Epoch 14: Validation loss decreased (0.530304 --> 0.527643).  Saving model ...
	 Train_Loss: 0.5467 Train_Acc: 73.986 Val_Loss: 0.5276  BEST VAL Loss: 0.5276  Val_Acc: 75.164

Epoch 15: Validation loss decreased (0.527643 --> 0.525127).  Saving model ...
	 Train_Loss: 0.5439 Train_Acc: 74.177 Val_Loss: 0.5251  BEST VAL Loss: 0.5251  Val_Acc: 75.340

Epoch 16: Validation loss decreased (0.525127 --> 0.522674).  Saving model ...
	 Train_Loss: 0.5413 Train_Acc: 74.221 Val_Loss: 0.5227  BEST VAL Loss: 0.5227  Val_Acc: 75.638

Epoch 17: Validation loss decreased (0.522674 --> 0.520819).  Saving model ...
	 Train_Loss: 0.5388 Train_Acc: 74.488 Val_Loss: 0.5208  BEST VAL Loss: 0.5208  Val_Acc: 75.196

Epoch 18: Validation loss decreased (0.520819 --> 0.518840).  Saving model ...
	 Train_Loss: 0.5366 Train_Acc: 74.547 Val_Loss: 0.5188  BEST VAL Loss: 0.5188  Val_Acc: 75.633

Epoch 19: Validation loss decreased (0.518840 --> 0.516925).  Saving model ...
	 Train_Loss: 0.5345 Train_Acc: 74.750 Val_Loss: 0.5169  BEST VAL Loss: 0.5169  Val_Acc: 76.201

Epoch 20: Validation loss decreased (0.516925 --> 0.515245).  Saving model ...
	 Train_Loss: 0.5325 Train_Acc: 74.811 Val_Loss: 0.5152  BEST VAL Loss: 0.5152  Val_Acc: 75.678

Epoch 21: Validation loss decreased (0.515245 --> 0.513438).  Saving model ...
	 Train_Loss: 0.5306 Train_Acc: 74.918 Val_Loss: 0.5134  BEST VAL Loss: 0.5134  Val_Acc: 75.989

Epoch 22: Validation loss decreased (0.513438 --> 0.512139).  Saving model ...
	 Train_Loss: 0.5288 Train_Acc: 74.995 Val_Loss: 0.5121  BEST VAL Loss: 0.5121  Val_Acc: 75.822

Epoch 23: Validation loss decreased (0.512139 --> 0.510637).  Saving model ...
	 Train_Loss: 0.5270 Train_Acc: 75.143 Val_Loss: 0.5106  BEST VAL Loss: 0.5106  Val_Acc: 76.048

Epoch 24: Validation loss decreased (0.510637 --> 0.509108).  Saving model ...
	 Train_Loss: 0.5254 Train_Acc: 75.135 Val_Loss: 0.5091  BEST VAL Loss: 0.5091  Val_Acc: 76.291

Epoch 25: Validation loss decreased (0.509108 --> 0.507873).  Saving model ...
	 Train_Loss: 0.5239 Train_Acc: 75.148 Val_Loss: 0.5079  BEST VAL Loss: 0.5079  Val_Acc: 76.449

Epoch 26: Validation loss decreased (0.507873 --> 0.506835).  Saving model ...
	 Train_Loss: 0.5224 Train_Acc: 75.203 Val_Loss: 0.5068  BEST VAL Loss: 0.5068  Val_Acc: 75.782

Epoch 27: Validation loss decreased (0.506835 --> 0.505883).  Saving model ...
	 Train_Loss: 0.5210 Train_Acc: 75.388 Val_Loss: 0.5059  BEST VAL Loss: 0.5059  Val_Acc: 76.169

Epoch 28: Validation loss decreased (0.505883 --> 0.504630).  Saving model ...
	 Train_Loss: 0.5196 Train_Acc: 75.507 Val_Loss: 0.5046  BEST VAL Loss: 0.5046  Val_Acc: 76.809

Epoch 29: Validation loss decreased (0.504630 --> 0.503470).  Saving model ...
	 Train_Loss: 0.5183 Train_Acc: 75.494 Val_Loss: 0.5035  BEST VAL Loss: 0.5035  Val_Acc: 76.462

Epoch 30: Validation loss decreased (0.503470 --> 0.502573).  Saving model ...
	 Train_Loss: 0.5170 Train_Acc: 75.541 Val_Loss: 0.5026  BEST VAL Loss: 0.5026  Val_Acc: 76.264

Epoch 31: Validation loss decreased (0.502573 --> 0.501470).  Saving model ...
	 Train_Loss: 0.5158 Train_Acc: 75.678 Val_Loss: 0.5015  BEST VAL Loss: 0.5015  Val_Acc: 76.575

Epoch 32: Validation loss decreased (0.501470 --> 0.500339).  Saving model ...
	 Train_Loss: 0.5146 Train_Acc: 75.731 Val_Loss: 0.5003  BEST VAL Loss: 0.5003  Val_Acc: 77.030

Epoch 33: Validation loss decreased (0.500339 --> 0.499253).  Saving model ...
	 Train_Loss: 0.5135 Train_Acc: 75.778 Val_Loss: 0.4993  BEST VAL Loss: 0.4993  Val_Acc: 76.931

Epoch 34: Validation loss decreased (0.499253 --> 0.498226).  Saving model ...
	 Train_Loss: 0.5124 Train_Acc: 75.848 Val_Loss: 0.4982  BEST VAL Loss: 0.4982  Val_Acc: 76.913

Epoch 35: Validation loss decreased (0.498226 --> 0.497389).  Saving model ...
	 Train_Loss: 0.5113 Train_Acc: 75.919 Val_Loss: 0.4974  BEST VAL Loss: 0.4974  Val_Acc: 77.066

Epoch 36: Validation loss decreased (0.497389 --> 0.496500).  Saving model ...
	 Train_Loss: 0.5103 Train_Acc: 75.904 Val_Loss: 0.4965  BEST VAL Loss: 0.4965  Val_Acc: 76.904

Epoch 37: Validation loss decreased (0.496500 --> 0.495601).  Saving model ...
	 Train_Loss: 0.5093 Train_Acc: 75.935 Val_Loss: 0.4956  BEST VAL Loss: 0.4956  Val_Acc: 77.061

Epoch 38: Validation loss decreased (0.495601 --> 0.494730).  Saving model ...
	 Train_Loss: 0.5084 Train_Acc: 75.980 Val_Loss: 0.4947  BEST VAL Loss: 0.4947  Val_Acc: 77.395

Epoch 39: Validation loss decreased (0.494730 --> 0.493892).  Saving model ...
	 Train_Loss: 0.5074 Train_Acc: 75.948 Val_Loss: 0.4939  BEST VAL Loss: 0.4939  Val_Acc: 77.088

Epoch 40: Validation loss decreased (0.493892 --> 0.493009).  Saving model ...
	 Train_Loss: 0.5065 Train_Acc: 76.084 Val_Loss: 0.4930  BEST VAL Loss: 0.4930  Val_Acc: 77.170

Epoch 41: Validation loss decreased (0.493009 --> 0.492326).  Saving model ...
	 Train_Loss: 0.5056 Train_Acc: 76.130 Val_Loss: 0.4923  BEST VAL Loss: 0.4923  Val_Acc: 77.111

Epoch 42: Validation loss decreased (0.492326 --> 0.491681).  Saving model ...
	 Train_Loss: 0.5048 Train_Acc: 76.112 Val_Loss: 0.4917  BEST VAL Loss: 0.4917  Val_Acc: 77.070

Epoch 43: Validation loss decreased (0.491681 --> 0.490933).  Saving model ...
	 Train_Loss: 0.5040 Train_Acc: 76.202 Val_Loss: 0.4909  BEST VAL Loss: 0.4909  Val_Acc: 77.571

Epoch 44: Validation loss decreased (0.490933 --> 0.490247).  Saving model ...
	 Train_Loss: 0.5032 Train_Acc: 76.290 Val_Loss: 0.4902  BEST VAL Loss: 0.4902  Val_Acc: 77.426

Epoch 45: Validation loss decreased (0.490247 --> 0.489534).  Saving model ...
	 Train_Loss: 0.5024 Train_Acc: 76.160 Val_Loss: 0.4895  BEST VAL Loss: 0.4895  Val_Acc: 77.647

Epoch 46: Validation loss decreased (0.489534 --> 0.488856).  Saving model ...
	 Train_Loss: 0.5016 Train_Acc: 76.260 Val_Loss: 0.4889  BEST VAL Loss: 0.4889  Val_Acc: 77.719

Epoch 47: Validation loss decreased (0.488856 --> 0.488208).  Saving model ...
	 Train_Loss: 0.5008 Train_Acc: 76.357 Val_Loss: 0.4882  BEST VAL Loss: 0.4882  Val_Acc: 77.607

Epoch 48: Validation loss decreased (0.488208 --> 0.487565).  Saving model ...
	 Train_Loss: 0.5001 Train_Acc: 76.363 Val_Loss: 0.4876  BEST VAL Loss: 0.4876  Val_Acc: 77.697

Epoch 49: Validation loss decreased (0.487565 --> 0.486932).  Saving model ...
	 Train_Loss: 0.4994 Train_Acc: 76.393 Val_Loss: 0.4869  BEST VAL Loss: 0.4869  Val_Acc: 77.589

Epoch 50: Validation loss decreased (0.486932 --> 0.486355).  Saving model ...
	 Train_Loss: 0.4987 Train_Acc: 76.404 Val_Loss: 0.4864  BEST VAL Loss: 0.4864  Val_Acc: 77.539

Epoch 51: Validation loss decreased (0.486355 --> 0.485786).  Saving model ...
	 Train_Loss: 0.4980 Train_Acc: 76.560 Val_Loss: 0.4858  BEST VAL Loss: 0.4858  Val_Acc: 77.607

Epoch 52: Validation loss decreased (0.485786 --> 0.485184).  Saving model ...
	 Train_Loss: 0.4973 Train_Acc: 76.500 Val_Loss: 0.4852  BEST VAL Loss: 0.4852  Val_Acc: 77.850

Epoch 53: Validation loss decreased (0.485184 --> 0.484666).  Saving model ...
	 Train_Loss: 0.4966 Train_Acc: 76.507 Val_Loss: 0.4847  BEST VAL Loss: 0.4847  Val_Acc: 77.485

Epoch 54: Validation loss decreased (0.484666 --> 0.484051).  Saving model ...
	 Train_Loss: 0.4960 Train_Acc: 76.575 Val_Loss: 0.4841  BEST VAL Loss: 0.4841  Val_Acc: 77.751

Epoch 55: Validation loss decreased (0.484051 --> 0.483571).  Saving model ...
	 Train_Loss: 0.4953 Train_Acc: 76.591 Val_Loss: 0.4836  BEST VAL Loss: 0.4836  Val_Acc: 77.881

Epoch 56: Validation loss decreased (0.483571 --> 0.483061).  Saving model ...
	 Train_Loss: 0.4947 Train_Acc: 76.524 Val_Loss: 0.4831  BEST VAL Loss: 0.4831  Val_Acc: 77.674

Epoch 57: Validation loss decreased (0.483061 --> 0.482643).  Saving model ...
	 Train_Loss: 0.4941 Train_Acc: 76.568 Val_Loss: 0.4826  BEST VAL Loss: 0.4826  Val_Acc: 77.755

Epoch 58: Validation loss decreased (0.482643 --> 0.482151).  Saving model ...
	 Train_Loss: 0.4935 Train_Acc: 76.478 Val_Loss: 0.4822  BEST VAL Loss: 0.4822  Val_Acc: 78.071

Epoch 59: Validation loss decreased (0.482151 --> 0.481668).  Saving model ...
	 Train_Loss: 0.4930 Train_Acc: 76.555 Val_Loss: 0.4817  BEST VAL Loss: 0.4817  Val_Acc: 77.976

Epoch 60: Validation loss decreased (0.481668 --> 0.481179).  Saving model ...
	 Train_Loss: 0.4924 Train_Acc: 76.680 Val_Loss: 0.4812  BEST VAL Loss: 0.4812  Val_Acc: 78.071

Epoch 61: Validation loss decreased (0.481179 --> 0.480723).  Saving model ...
	 Train_Loss: 0.4919 Train_Acc: 76.663 Val_Loss: 0.4807  BEST VAL Loss: 0.4807  Val_Acc: 78.161

Epoch 62: Validation loss decreased (0.480723 --> 0.480285).  Saving model ...
	 Train_Loss: 0.4913 Train_Acc: 76.671 Val_Loss: 0.4803  BEST VAL Loss: 0.4803  Val_Acc: 78.111

Epoch 63: Validation loss decreased (0.480285 --> 0.479903).  Saving model ...
	 Train_Loss: 0.4908 Train_Acc: 76.789 Val_Loss: 0.4799  BEST VAL Loss: 0.4799  Val_Acc: 77.823

Epoch 64: Validation loss decreased (0.479903 --> 0.479452).  Saving model ...
	 Train_Loss: 0.4902 Train_Acc: 76.801 Val_Loss: 0.4795  BEST VAL Loss: 0.4795  Val_Acc: 78.008

Epoch 65: Validation loss decreased (0.479452 --> 0.479057).  Saving model ...
	 Train_Loss: 0.4897 Train_Acc: 76.738 Val_Loss: 0.4791  BEST VAL Loss: 0.4791  Val_Acc: 77.890

Epoch 66: Validation loss decreased (0.479057 --> 0.478624).  Saving model ...
	 Train_Loss: 0.4892 Train_Acc: 76.765 Val_Loss: 0.4786  BEST VAL Loss: 0.4786  Val_Acc: 78.359

Epoch 67: Validation loss decreased (0.478624 --> 0.478248).  Saving model ...
	 Train_Loss: 0.4887 Train_Acc: 76.788 Val_Loss: 0.4782  BEST VAL Loss: 0.4782  Val_Acc: 78.179

Epoch 68: Validation loss decreased (0.478248 --> 0.477810).  Saving model ...
	 Train_Loss: 0.4882 Train_Acc: 76.905 Val_Loss: 0.4778  BEST VAL Loss: 0.4778  Val_Acc: 78.355

Epoch 69: Validation loss decreased (0.477810 --> 0.477404).  Saving model ...
	 Train_Loss: 0.4877 Train_Acc: 76.758 Val_Loss: 0.4774  BEST VAL Loss: 0.4774  Val_Acc: 78.355

Epoch 70: Validation loss decreased (0.477404 --> 0.477110).  Saving model ...
	 Train_Loss: 0.4873 Train_Acc: 76.828 Val_Loss: 0.4771  BEST VAL Loss: 0.4771  Val_Acc: 77.372

Epoch 71: Validation loss decreased (0.477110 --> 0.476761).  Saving model ...
	 Train_Loss: 0.4868 Train_Acc: 76.813 Val_Loss: 0.4768  BEST VAL Loss: 0.4768  Val_Acc: 78.152

Epoch 72: Validation loss decreased (0.476761 --> 0.476356).  Saving model ...
	 Train_Loss: 0.4863 Train_Acc: 76.785 Val_Loss: 0.4764  BEST VAL Loss: 0.4764  Val_Acc: 78.251

Epoch 73: Validation loss decreased (0.476356 --> 0.475961).  Saving model ...
	 Train_Loss: 0.4859 Train_Acc: 76.961 Val_Loss: 0.4760  BEST VAL Loss: 0.4760  Val_Acc: 78.044

Epoch 74: Validation loss decreased (0.475961 --> 0.475592).  Saving model ...
	 Train_Loss: 0.4854 Train_Acc: 77.001 Val_Loss: 0.4756  BEST VAL Loss: 0.4756  Val_Acc: 78.463

Epoch 75: Validation loss decreased (0.475592 --> 0.475188).  Saving model ...
	 Train_Loss: 0.4850 Train_Acc: 76.978 Val_Loss: 0.4752  BEST VAL Loss: 0.4752  Val_Acc: 78.400

Epoch 76: Validation loss decreased (0.475188 --> 0.474824).  Saving model ...
	 Train_Loss: 0.4846 Train_Acc: 76.897 Val_Loss: 0.4748  BEST VAL Loss: 0.4748  Val_Acc: 78.093

Epoch 77: Validation loss decreased (0.474824 --> 0.474507).  Saving model ...
	 Train_Loss: 0.4842 Train_Acc: 77.080 Val_Loss: 0.4745  BEST VAL Loss: 0.4745  Val_Acc: 78.237

Epoch 78: Validation loss decreased (0.474507 --> 0.474163).  Saving model ...
	 Train_Loss: 0.4837 Train_Acc: 77.012 Val_Loss: 0.4742  BEST VAL Loss: 0.4742  Val_Acc: 78.291

Epoch 79: Validation loss decreased (0.474163 --> 0.473837).  Saving model ...
	 Train_Loss: 0.4833 Train_Acc: 77.034 Val_Loss: 0.4738  BEST VAL Loss: 0.4738  Val_Acc: 78.044

Epoch 80: Validation loss decreased (0.473837 --> 0.473457).  Saving model ...
	 Train_Loss: 0.4829 Train_Acc: 77.081 Val_Loss: 0.4735  BEST VAL Loss: 0.4735  Val_Acc: 78.364

Epoch 81: Validation loss decreased (0.473457 --> 0.473122).  Saving model ...
	 Train_Loss: 0.4825 Train_Acc: 77.074 Val_Loss: 0.4731  BEST VAL Loss: 0.4731  Val_Acc: 78.273

Epoch 82: Validation loss decreased (0.473122 --> 0.472831).  Saving model ...
	 Train_Loss: 0.4821 Train_Acc: 76.919 Val_Loss: 0.4728  BEST VAL Loss: 0.4728  Val_Acc: 78.436

Epoch 83: Validation loss decreased (0.472831 --> 0.472533).  Saving model ...
	 Train_Loss: 0.4817 Train_Acc: 77.058 Val_Loss: 0.4725  BEST VAL Loss: 0.4725  Val_Acc: 78.251

Epoch 84: Validation loss decreased (0.472533 --> 0.472223).  Saving model ...
	 Train_Loss: 0.4814 Train_Acc: 77.037 Val_Loss: 0.4722  BEST VAL Loss: 0.4722  Val_Acc: 78.377

Epoch 85: Validation loss decreased (0.472223 --> 0.471950).  Saving model ...
	 Train_Loss: 0.4810 Train_Acc: 77.077 Val_Loss: 0.4719  BEST VAL Loss: 0.4719  Val_Acc: 77.935

Epoch 86: Validation loss decreased (0.471950 --> 0.471646).  Saving model ...
	 Train_Loss: 0.4806 Train_Acc: 77.008 Val_Loss: 0.4716  BEST VAL Loss: 0.4716  Val_Acc: 78.336

Epoch 87: Validation loss decreased (0.471646 --> 0.471392).  Saving model ...
	 Train_Loss: 0.4803 Train_Acc: 77.057 Val_Loss: 0.4714  BEST VAL Loss: 0.4714  Val_Acc: 78.404

Epoch 88: Validation loss decreased (0.471392 --> 0.471149).  Saving model ...
	 Train_Loss: 0.4799 Train_Acc: 77.088 Val_Loss: 0.4711  BEST VAL Loss: 0.4711  Val_Acc: 78.296

Epoch 89: Validation loss decreased (0.471149 --> 0.470834).  Saving model ...
	 Train_Loss: 0.4795 Train_Acc: 77.181 Val_Loss: 0.4708  BEST VAL Loss: 0.4708  Val_Acc: 78.201

Epoch 90: Validation loss decreased (0.470834 --> 0.470527).  Saving model ...
	 Train_Loss: 0.4792 Train_Acc: 77.071 Val_Loss: 0.4705  BEST VAL Loss: 0.4705  Val_Acc: 78.246

Epoch 91: Validation loss decreased (0.470527 --> 0.470273).  Saving model ...
	 Train_Loss: 0.4789 Train_Acc: 77.140 Val_Loss: 0.4703  BEST VAL Loss: 0.4703  Val_Acc: 78.431

Epoch 92: Validation loss decreased (0.470273 --> 0.470025).  Saving model ...
	 Train_Loss: 0.4785 Train_Acc: 77.224 Val_Loss: 0.4700  BEST VAL Loss: 0.4700  Val_Acc: 78.264

Epoch 93: Validation loss decreased (0.470025 --> 0.469740).  Saving model ...
	 Train_Loss: 0.4782 Train_Acc: 77.151 Val_Loss: 0.4697  BEST VAL Loss: 0.4697  Val_Acc: 78.179

Epoch 94: Validation loss decreased (0.469740 --> 0.469491).  Saving model ...
	 Train_Loss: 0.4779 Train_Acc: 76.996 Val_Loss: 0.4695  BEST VAL Loss: 0.4695  Val_Acc: 78.386

Epoch 95: Validation loss decreased (0.469491 --> 0.469227).  Saving model ...
	 Train_Loss: 0.4775 Train_Acc: 77.190 Val_Loss: 0.4692  BEST VAL Loss: 0.4692  Val_Acc: 78.427

Epoch 96: Validation loss decreased (0.469227 --> 0.469009).  Saving model ...
	 Train_Loss: 0.4772 Train_Acc: 77.213 Val_Loss: 0.4690  BEST VAL Loss: 0.4690  Val_Acc: 78.571

Epoch 97: Validation loss decreased (0.469009 --> 0.468810).  Saving model ...
	 Train_Loss: 0.4769 Train_Acc: 77.151 Val_Loss: 0.4688  BEST VAL Loss: 0.4688  Val_Acc: 77.854

Epoch 98: Validation loss decreased (0.468810 --> 0.468573).  Saving model ...
	 Train_Loss: 0.4766 Train_Acc: 77.150 Val_Loss: 0.4686  BEST VAL Loss: 0.4686  Val_Acc: 78.611

Epoch 99: Validation loss decreased (0.468573 --> 0.468316).  Saving model ...
	 Train_Loss: 0.4763 Train_Acc: 77.198 Val_Loss: 0.4683  BEST VAL Loss: 0.4683  Val_Acc: 78.674

LPS_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.45      0.40      0.42     79796
           1       0.55      0.60      0.57     97754

    accuracy                           0.51    177550
   macro avg       0.50      0.50      0.50    177550
weighted avg       0.50      0.51      0.51    177550

LPS_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.45      0.40      0.42      9975
           1       0.55      0.60      0.57     12219

    accuracy                           0.51     22194
   macro avg       0.50      0.50      0.50     22194
weighted avg       0.50      0.51      0.50     22194

LPS_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.45      0.40      0.42      9975
           1       0.55      0.60      0.58     12219

    accuracy                           0.51     22194
   macro avg       0.50      0.50      0.50     22194
weighted avg       0.51      0.51      0.51     22194

              precision    recall  f1-score   support

           0       0.45      0.40      0.42      9975
           1       0.55      0.60      0.58     12219

    accuracy                           0.51     22194
   macro avg       0.50      0.50      0.50     22194
weighted avg       0.51      0.51      0.51     22194

LPS_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.23      0.32     39687
           1       0.48      0.77      0.59     37243

    accuracy                           0.49     76930
   macro avg       0.50      0.50      0.45     76930
weighted avg       0.50      0.49      0.45     76930

              precision    recall  f1-score   support

           0       0.51      0.23      0.32     39687
           1       0.48      0.77      0.59     37243

    accuracy                           0.49     76930
   macro avg       0.50      0.50      0.45     76930
weighted avg       0.50      0.49      0.45     76930

completed
