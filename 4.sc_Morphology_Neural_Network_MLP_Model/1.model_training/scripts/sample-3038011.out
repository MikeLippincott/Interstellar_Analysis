[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '3d14bd58'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '56a46d30'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '5cdc61f4'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'c87b9b07'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_Nigericin_1.000_1.0_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (29870, 1276)
Number of total missing values across all columns: 0
Data Subset Is Off
Wells held out for testing: ['L16' 'K20']
Wells to use for training, validation, and testing ['K16' 'K17' 'L17' 'L20' 'K21' 'L21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.460393).  Saving model ...
	 Train_Loss: 0.5515 Train_Acc: 72.887 Val_Loss: 0.4604  BEST VAL Loss: 0.4604  Val_Acc: 83.431

Epoch 1: Validation loss decreased (0.460393 --> 0.415532).  Saving model ...
	 Train_Loss: 0.4940 Train_Acc: 83.206 Val_Loss: 0.4155  BEST VAL Loss: 0.4155  Val_Acc: 86.907

Epoch 2: Validation loss decreased (0.415532 --> 0.377578).  Saving model ...
	 Train_Loss: 0.4505 Train_Acc: 86.074 Val_Loss: 0.3776  BEST VAL Loss: 0.3776  Val_Acc: 88.578

Epoch 3: Validation loss decreased (0.377578 --> 0.352031).  Saving model ...
	 Train_Loss: 0.4162 Train_Acc: 88.524 Val_Loss: 0.3520  BEST VAL Loss: 0.3520  Val_Acc: 89.707

Epoch 4: Validation loss decreased (0.352031 --> 0.329818).  Saving model ...
	 Train_Loss: 0.3882 Train_Acc: 90.037 Val_Loss: 0.3298  BEST VAL Loss: 0.3298  Val_Acc: 91.558

Epoch 5: Validation loss decreased (0.329818 --> 0.315326).  Saving model ...
	 Train_Loss: 0.3656 Train_Acc: 90.855 Val_Loss: 0.3153  BEST VAL Loss: 0.3153  Val_Acc: 92.551

Epoch 6: Validation loss decreased (0.315326 --> 0.304151).  Saving model ...
	 Train_Loss: 0.3464 Train_Acc: 91.815 Val_Loss: 0.3042  BEST VAL Loss: 0.3042  Val_Acc: 92.280

Epoch 7: Validation loss decreased (0.304151 --> 0.294672).  Saving model ...
	 Train_Loss: 0.3316 Train_Acc: 91.566 Val_Loss: 0.2947  BEST VAL Loss: 0.2947  Val_Acc: 92.686

Epoch 8: Validation loss decreased (0.294672 --> 0.285890).  Saving model ...
	 Train_Loss: 0.3179 Train_Acc: 92.532 Val_Loss: 0.2859  BEST VAL Loss: 0.2859  Val_Acc: 92.370

Epoch 9: Validation loss decreased (0.285890 --> 0.277385).  Saving model ...
	 Train_Loss: 0.3057 Train_Acc: 92.989 Val_Loss: 0.2774  BEST VAL Loss: 0.2774  Val_Acc: 93.093

Epoch 10: Validation loss decreased (0.277385 --> 0.272052).  Saving model ...
	 Train_Loss: 0.2950 Train_Acc: 93.209 Val_Loss: 0.2721  BEST VAL Loss: 0.2721  Val_Acc: 92.415

Epoch 11: Validation loss decreased (0.272052 --> 0.266352).  Saving model ...
	 Train_Loss: 0.2851 Train_Acc: 93.745 Val_Loss: 0.2664  BEST VAL Loss: 0.2664  Val_Acc: 93.725

Epoch 12: Validation loss decreased (0.266352 --> 0.262315).  Saving model ...
	 Train_Loss: 0.2764 Train_Acc: 93.994 Val_Loss: 0.2623  BEST VAL Loss: 0.2623  Val_Acc: 93.995

Epoch 13: Validation loss decreased (0.262315 --> 0.256553).  Saving model ...
	 Train_Loss: 0.2685 Train_Acc: 94.028 Val_Loss: 0.2566  BEST VAL Loss: 0.2566  Val_Acc: 93.228

Epoch 14: Validation loss decreased (0.256553 --> 0.250953).  Saving model ...
	 Train_Loss: 0.2614 Train_Acc: 94.406 Val_Loss: 0.2510  BEST VAL Loss: 0.2510  Val_Acc: 94.266

Epoch 15: Validation loss decreased (0.250953 --> 0.247745).  Saving model ...
	 Train_Loss: 0.2551 Train_Acc: 94.389 Val_Loss: 0.2477  BEST VAL Loss: 0.2477  Val_Acc: 93.138

Epoch 16: Validation loss decreased (0.247745 --> 0.244662).  Saving model ...
	 Train_Loss: 0.2493 Train_Acc: 94.372 Val_Loss: 0.2447  BEST VAL Loss: 0.2447  Val_Acc: 93.363

Epoch 17: Validation loss decreased (0.244662 --> 0.242074).  Saving model ...
	 Train_Loss: 0.2436 Train_Acc: 94.790 Val_Loss: 0.2421  BEST VAL Loss: 0.2421  Val_Acc: 94.131

Epoch 18: Validation loss decreased (0.242074 --> 0.239719).  Saving model ...
	 Train_Loss: 0.2378 Train_Acc: 95.349 Val_Loss: 0.2397  BEST VAL Loss: 0.2397  Val_Acc: 93.589

Epoch 19: Validation loss decreased (0.239719 --> 0.239392).  Saving model ...
	 Train_Loss: 0.2328 Train_Acc: 95.117 Val_Loss: 0.2394  BEST VAL Loss: 0.2394  Val_Acc: 93.725

Epoch 20: Validation loss did not decrease
	 Train_Loss: 0.2281 Train_Acc: 95.145 Val_Loss: 0.2405  BEST VAL Loss: 0.2394  Val_Acc: 93.860

Epoch 21: Validation loss decreased (0.239392 --> 0.238345).  Saving model ...
	 Train_Loss: 0.2237 Train_Acc: 95.563 Val_Loss: 0.2383  BEST VAL Loss: 0.2383  Val_Acc: 94.492

Epoch 22: Validation loss decreased (0.238345 --> 0.236719).  Saving model ...
	 Train_Loss: 0.2193 Train_Acc: 95.744 Val_Loss: 0.2367  BEST VAL Loss: 0.2367  Val_Acc: 93.454

Epoch 23: Validation loss decreased (0.236719 --> 0.235178).  Saving model ...
	 Train_Loss: 0.2154 Train_Acc: 95.586 Val_Loss: 0.2352  BEST VAL Loss: 0.2352  Val_Acc: 93.770

Epoch 24: Validation loss decreased (0.235178 --> 0.235093).  Saving model ...
	 Train_Loss: 0.2123 Train_Acc: 95.145 Val_Loss: 0.2351  BEST VAL Loss: 0.2351  Val_Acc: 94.041

Epoch 25: Validation loss decreased (0.235093 --> 0.234395).  Saving model ...
	 Train_Loss: 0.2091 Train_Acc: 95.416 Val_Loss: 0.2344  BEST VAL Loss: 0.2344  Val_Acc: 93.950

Epoch 26: Validation loss decreased (0.234395 --> 0.232541).  Saving model ...
	 Train_Loss: 0.2062 Train_Acc: 95.563 Val_Loss: 0.2325  BEST VAL Loss: 0.2325  Val_Acc: 94.176

Epoch 27: Validation loss decreased (0.232541 --> 0.231071).  Saving model ...
	 Train_Loss: 0.2032 Train_Acc: 95.586 Val_Loss: 0.2311  BEST VAL Loss: 0.2311  Val_Acc: 94.086

Epoch 28: Validation loss decreased (0.231071 --> 0.228521).  Saving model ...
	 Train_Loss: 0.2003 Train_Acc: 95.936 Val_Loss: 0.2285  BEST VAL Loss: 0.2285  Val_Acc: 94.086

Epoch 29: Validation loss decreased (0.228521 --> 0.227700).  Saving model ...
	 Train_Loss: 0.1976 Train_Acc: 95.795 Val_Loss: 0.2277  BEST VAL Loss: 0.2277  Val_Acc: 93.995

Epoch 30: Validation loss decreased (0.227700 --> 0.226356).  Saving model ...
	 Train_Loss: 0.1950 Train_Acc: 95.907 Val_Loss: 0.2264  BEST VAL Loss: 0.2264  Val_Acc: 93.273

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.1924 Train_Acc: 95.721 Val_Loss: 0.2265  BEST VAL Loss: 0.2264  Val_Acc: 94.402

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.1900 Train_Acc: 96.049 Val_Loss: 0.2264  BEST VAL Loss: 0.2264  Val_Acc: 94.041

Epoch 33: Validation loss decreased (0.226356 --> 0.225812).  Saving model ...
	 Train_Loss: 0.1879 Train_Acc: 95.845 Val_Loss: 0.2258  BEST VAL Loss: 0.2258  Val_Acc: 93.725

Epoch 34: Validation loss decreased (0.225812 --> 0.225297).  Saving model ...
	 Train_Loss: 0.1857 Train_Acc: 96.003 Val_Loss: 0.2253  BEST VAL Loss: 0.2253  Val_Acc: 94.312

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.1835 Train_Acc: 96.291 Val_Loss: 0.2263  BEST VAL Loss: 0.2253  Val_Acc: 93.995

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.1815 Train_Acc: 96.195 Val_Loss: 0.2257  BEST VAL Loss: 0.2253  Val_Acc: 94.312

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.1794 Train_Acc: 96.410 Val_Loss: 0.2254  BEST VAL Loss: 0.2253  Val_Acc: 94.492

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.1775 Train_Acc: 96.376 Val_Loss: 0.2266  BEST VAL Loss: 0.2253  Val_Acc: 94.312

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.1755 Train_Acc: 96.557 Val_Loss: 0.2274  BEST VAL Loss: 0.2253  Val_Acc: 94.266

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.1738 Train_Acc: 96.246 Val_Loss: 0.2277  BEST VAL Loss: 0.2253  Val_Acc: 94.041

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.1721 Train_Acc: 96.240 Val_Loss: 0.2270  BEST VAL Loss: 0.2253  Val_Acc: 94.131

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.1704 Train_Acc: 96.557 Val_Loss: 0.2260  BEST VAL Loss: 0.2253  Val_Acc: 94.673

Epoch 43: Validation loss decreased (0.225297 --> 0.225086).  Saving model ...
	 Train_Loss: 0.1687 Train_Acc: 96.935 Val_Loss: 0.2251  BEST VAL Loss: 0.2251  Val_Acc: 94.492

Epoch 44: Validation loss decreased (0.225086 --> 0.225033).  Saving model ...
	 Train_Loss: 0.1671 Train_Acc: 96.590 Val_Loss: 0.2250  BEST VAL Loss: 0.2250  Val_Acc: 94.763

Epoch 45: Validation loss decreased (0.225033 --> 0.224835).  Saving model ...
	 Train_Loss: 0.1656 Train_Acc: 96.613 Val_Loss: 0.2248  BEST VAL Loss: 0.2248  Val_Acc: 94.086

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.1641 Train_Acc: 96.709 Val_Loss: 0.2257  BEST VAL Loss: 0.2248  Val_Acc: 94.312

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.1627 Train_Acc: 96.856 Val_Loss: 0.2251  BEST VAL Loss: 0.2248  Val_Acc: 94.357

Epoch 48: Validation loss decreased (0.224835 --> 0.224777).  Saving model ...
	 Train_Loss: 0.1614 Train_Acc: 96.607 Val_Loss: 0.2248  BEST VAL Loss: 0.2248  Val_Acc: 94.131

Epoch 49: Validation loss decreased (0.224777 --> 0.224464).  Saving model ...
	 Train_Loss: 0.1601 Train_Acc: 96.653 Val_Loss: 0.2245  BEST VAL Loss: 0.2245  Val_Acc: 94.402

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.1587 Train_Acc: 96.991 Val_Loss: 0.2253  BEST VAL Loss: 0.2245  Val_Acc: 94.853

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.1574 Train_Acc: 96.918 Val_Loss: 0.2257  BEST VAL Loss: 0.2245  Val_Acc: 93.905

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.1562 Train_Acc: 96.596 Val_Loss: 0.2275  BEST VAL Loss: 0.2245  Val_Acc: 94.447

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.1550 Train_Acc: 96.856 Val_Loss: 0.2277  BEST VAL Loss: 0.2245  Val_Acc: 93.950

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.1540 Train_Acc: 96.743 Val_Loss: 0.2282  BEST VAL Loss: 0.2245  Val_Acc: 94.176

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.1529 Train_Acc: 96.873 Val_Loss: 0.2283  BEST VAL Loss: 0.2245  Val_Acc: 94.944

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.1518 Train_Acc: 96.991 Val_Loss: 0.2278  BEST VAL Loss: 0.2245  Val_Acc: 94.312

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.1507 Train_Acc: 96.952 Val_Loss: 0.2279  BEST VAL Loss: 0.2245  Val_Acc: 94.447

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.1497 Train_Acc: 97.003 Val_Loss: 0.2281  BEST VAL Loss: 0.2245  Val_Acc: 94.673

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.1488 Train_Acc: 96.703 Val_Loss: 0.2286  BEST VAL Loss: 0.2245  Val_Acc: 94.718

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.1478 Train_Acc: 96.749 Val_Loss: 0.2297  BEST VAL Loss: 0.2245  Val_Acc: 94.357

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.1470 Train_Acc: 96.720 Val_Loss: 0.2307  BEST VAL Loss: 0.2245  Val_Acc: 94.402

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.1460 Train_Acc: 97.076 Val_Loss: 0.2307  BEST VAL Loss: 0.2245  Val_Acc: 93.815

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.1450 Train_Acc: 97.166 Val_Loss: 0.2312  BEST VAL Loss: 0.2245  Val_Acc: 94.447

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.1441 Train_Acc: 97.053 Val_Loss: 0.2317  BEST VAL Loss: 0.2245  Val_Acc: 94.357

Epoch 65: Validation loss did not decrease
Early stopped at epoch : 65
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.54      0.55      9777
           1       0.45      0.46      0.45      7938

    accuracy                           0.51     17715
   macro avg       0.50      0.50      0.50     17715
weighted avg       0.51      0.51      0.51     17715

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.54      0.55      1222
           1       0.45      0.45      0.45       993

    accuracy                           0.50      2215
   macro avg       0.50      0.50      0.50      2215
weighted avg       0.50      0.50      0.50      2215

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.54      0.54      1223
           1       0.43      0.43      0.43       992

    accuracy                           0.49      2215
   macro avg       0.48      0.48      0.48      2215
weighted avg       0.49      0.49      0.49      2215

              precision    recall  f1-score   support

           0       0.53      0.54      0.54      1223
           1       0.43      0.43      0.43       992

    accuracy                           0.49      2215
   macro avg       0.48      0.48      0.48      2215
weighted avg       0.49      0.49      0.49      2215

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.59      0.55      3996
           1       0.49      0.42      0.45      3729

    accuracy                           0.51      7725
   macro avg       0.51      0.51      0.50      7725
weighted avg       0.51      0.51      0.51      7725

              precision    recall  f1-score   support

           0       0.52      0.59      0.55      3996
           1       0.49      0.42      0.45      3729

    accuracy                           0.51      7725
   macro avg       0.51      0.51      0.50      7725
weighted avg       0.51      0.51      0.51      7725

completed
