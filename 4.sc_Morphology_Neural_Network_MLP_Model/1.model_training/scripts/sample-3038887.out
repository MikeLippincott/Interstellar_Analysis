[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '08b30e2e'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '2ad62ab3'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1608ad8f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'cfac9474'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 treatment_name: LPS_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
TREATMENT_NAME: LPS_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (32676, 1276)
Number of total missing values across all columns: 32916
Data Subset Is Off
Wells held out for testing: ['D20' 'K16']
Wells to use for training, validation, and testing ['D16' 'D17' 'D21' 'K17' 'K20' 'K21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.521693).  Saving model ...
	 Train_Loss: 0.5904 Train_Acc: 64.782 Val_Loss: 0.5217  BEST VAL Loss: 0.5217  Val_Acc: 79.918

Epoch 1: Validation loss decreased (0.521693 --> 0.491074).  Saving model ...
	 Train_Loss: 0.5392 Train_Acc: 78.761 Val_Loss: 0.4911  BEST VAL Loss: 0.4911  Val_Acc: 82.387

Epoch 2: Validation loss decreased (0.491074 --> 0.462628).  Saving model ...
	 Train_Loss: 0.5068 Train_Acc: 81.586 Val_Loss: 0.4626  BEST VAL Loss: 0.4626  Val_Acc: 84.856

Epoch 3: Validation loss decreased (0.462628 --> 0.442371).  Saving model ...
	 Train_Loss: 0.4816 Train_Acc: 83.423 Val_Loss: 0.4424  BEST VAL Loss: 0.4424  Val_Acc: 85.885

Epoch 4: Validation loss decreased (0.442371 --> 0.422160).  Saving model ...
	 Train_Loss: 0.4615 Train_Acc: 84.472 Val_Loss: 0.4222  BEST VAL Loss: 0.4222  Val_Acc: 87.942

Epoch 5: Validation loss decreased (0.422160 --> 0.407732).  Saving model ...
	 Train_Loss: 0.4454 Train_Acc: 85.306 Val_Loss: 0.4077  BEST VAL Loss: 0.4077  Val_Acc: 88.025

Epoch 6: Validation loss decreased (0.407732 --> 0.395582).  Saving model ...
	 Train_Loss: 0.4319 Train_Acc: 86.201 Val_Loss: 0.3956  BEST VAL Loss: 0.3956  Val_Acc: 88.148

Epoch 7: Validation loss decreased (0.395582 --> 0.385136).  Saving model ...
	 Train_Loss: 0.4205 Train_Acc: 86.561 Val_Loss: 0.3851  BEST VAL Loss: 0.3851  Val_Acc: 89.259

Epoch 8: Validation loss decreased (0.385136 --> 0.375304).  Saving model ...
	 Train_Loss: 0.4106 Train_Acc: 86.823 Val_Loss: 0.3753  BEST VAL Loss: 0.3753  Val_Acc: 90.123

Epoch 9: Validation loss decreased (0.375304 --> 0.371226).  Saving model ...
	 Train_Loss: 0.4021 Train_Acc: 87.276 Val_Loss: 0.3712  BEST VAL Loss: 0.3712  Val_Acc: 88.889

Epoch 10: Validation loss decreased (0.371226 --> 0.364516).  Saving model ...
	 Train_Loss: 0.3947 Train_Acc: 87.631 Val_Loss: 0.3645  BEST VAL Loss: 0.3645  Val_Acc: 89.506

Epoch 11: Validation loss decreased (0.364516 --> 0.357362).  Saving model ...
	 Train_Loss: 0.3879 Train_Acc: 87.909 Val_Loss: 0.3574  BEST VAL Loss: 0.3574  Val_Acc: 90.658

Epoch 12: Validation loss decreased (0.357362 --> 0.351113).  Saving model ...
	 Train_Loss: 0.3812 Train_Acc: 88.598 Val_Loss: 0.3511  BEST VAL Loss: 0.3511  Val_Acc: 90.535

Epoch 13: Validation loss decreased (0.351113 --> 0.345250).  Saving model ...
	 Train_Loss: 0.3752 Train_Acc: 88.753 Val_Loss: 0.3453  BEST VAL Loss: 0.3453  Val_Acc: 90.947

Epoch 14: Validation loss decreased (0.345250 --> 0.339646).  Saving model ...
	 Train_Loss: 0.3696 Train_Acc: 89.092 Val_Loss: 0.3396  BEST VAL Loss: 0.3396  Val_Acc: 91.111

Epoch 15: Validation loss decreased (0.339646 --> 0.334249).  Saving model ...
	 Train_Loss: 0.3646 Train_Acc: 89.211 Val_Loss: 0.3342  BEST VAL Loss: 0.3342  Val_Acc: 91.646

Epoch 16: Validation loss decreased (0.334249 --> 0.329944).  Saving model ...
	 Train_Loss: 0.3599 Train_Acc: 89.334 Val_Loss: 0.3299  BEST VAL Loss: 0.3299  Val_Acc: 91.317

Epoch 17: Validation loss decreased (0.329944 --> 0.326296).  Saving model ...
	 Train_Loss: 0.3558 Train_Acc: 89.355 Val_Loss: 0.3263  BEST VAL Loss: 0.3263  Val_Acc: 91.317

Epoch 18: Validation loss decreased (0.326296 --> 0.322450).  Saving model ...
	 Train_Loss: 0.3516 Train_Acc: 89.864 Val_Loss: 0.3225  BEST VAL Loss: 0.3225  Val_Acc: 91.893

Epoch 19: Validation loss decreased (0.322450 --> 0.318643).  Saving model ...
	 Train_Loss: 0.3477 Train_Acc: 89.988 Val_Loss: 0.3186  BEST VAL Loss: 0.3186  Val_Acc: 92.099

Epoch 20: Validation loss decreased (0.318643 --> 0.314870).  Saving model ...
	 Train_Loss: 0.3441 Train_Acc: 90.039 Val_Loss: 0.3149  BEST VAL Loss: 0.3149  Val_Acc: 92.263

Epoch 21: Validation loss decreased (0.314870 --> 0.312031).  Saving model ...
	 Train_Loss: 0.3410 Train_Acc: 89.787 Val_Loss: 0.3120  BEST VAL Loss: 0.3120  Val_Acc: 91.934

Epoch 22: Validation loss decreased (0.312031 --> 0.309021).  Saving model ...
	 Train_Loss: 0.3378 Train_Acc: 90.394 Val_Loss: 0.3090  BEST VAL Loss: 0.3090  Val_Acc: 92.469

Epoch 23: Validation loss decreased (0.309021 --> 0.306097).  Saving model ...
	 Train_Loss: 0.3350 Train_Acc: 90.106 Val_Loss: 0.3061  BEST VAL Loss: 0.3061  Val_Acc: 92.222

Epoch 24: Validation loss decreased (0.306097 --> 0.303200).  Saving model ...
	 Train_Loss: 0.3320 Train_Acc: 90.610 Val_Loss: 0.3032  BEST VAL Loss: 0.3032  Val_Acc: 93.004

Epoch 25: Validation loss decreased (0.303200 --> 0.301393).  Saving model ...
	 Train_Loss: 0.3294 Train_Acc: 90.518 Val_Loss: 0.3014  BEST VAL Loss: 0.3014  Val_Acc: 92.099

Epoch 26: Validation loss decreased (0.301393 --> 0.299911).  Saving model ...
	 Train_Loss: 0.3270 Train_Acc: 90.389 Val_Loss: 0.2999  BEST VAL Loss: 0.2999  Val_Acc: 91.811

Epoch 27: Validation loss decreased (0.299911 --> 0.297805).  Saving model ...
	 Train_Loss: 0.3248 Train_Acc: 90.446 Val_Loss: 0.2978  BEST VAL Loss: 0.2978  Val_Acc: 92.922

Epoch 28: Validation loss decreased (0.297805 --> 0.296077).  Saving model ...
	 Train_Loss: 0.3225 Train_Acc: 90.579 Val_Loss: 0.2961  BEST VAL Loss: 0.2961  Val_Acc: 92.387

Epoch 29: Validation loss decreased (0.296077 --> 0.294395).  Saving model ...
	 Train_Loss: 0.3204 Train_Acc: 90.708 Val_Loss: 0.2944  BEST VAL Loss: 0.2944  Val_Acc: 92.757

Epoch 30: Validation loss decreased (0.294395 --> 0.292339).  Saving model ...
	 Train_Loss: 0.3182 Train_Acc: 90.965 Val_Loss: 0.2923  BEST VAL Loss: 0.2923  Val_Acc: 93.169

Epoch 31: Validation loss decreased (0.292339 --> 0.290907).  Saving model ...
	 Train_Loss: 0.3160 Train_Acc: 91.217 Val_Loss: 0.2909  BEST VAL Loss: 0.2909  Val_Acc: 92.798

Epoch 32: Validation loss decreased (0.290907 --> 0.289667).  Saving model ...
	 Train_Loss: 0.3141 Train_Acc: 90.981 Val_Loss: 0.2897  BEST VAL Loss: 0.2897  Val_Acc: 92.798

Epoch 33: Validation loss decreased (0.289667 --> 0.288261).  Saving model ...
	 Train_Loss: 0.3122 Train_Acc: 91.243 Val_Loss: 0.2883  BEST VAL Loss: 0.2883  Val_Acc: 92.798

Epoch 34: Validation loss decreased (0.288261 --> 0.286813).  Saving model ...
	 Train_Loss: 0.3104 Train_Acc: 91.120 Val_Loss: 0.2868  BEST VAL Loss: 0.2868  Val_Acc: 93.210

Epoch 35: Validation loss decreased (0.286813 --> 0.285357).  Saving model ...
	 Train_Loss: 0.3087 Train_Acc: 91.207 Val_Loss: 0.2854  BEST VAL Loss: 0.2854  Val_Acc: 93.128

Epoch 36: Validation loss decreased (0.285357 --> 0.283647).  Saving model ...
	 Train_Loss: 0.3071 Train_Acc: 91.315 Val_Loss: 0.2836  BEST VAL Loss: 0.2836  Val_Acc: 93.416

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.3054 Train_Acc: 91.557 Val_Loss: 0.2845  BEST VAL Loss: 0.2836  Val_Acc: 90.082

Epoch 38: Validation loss decreased (0.283647 --> 0.282833).  Saving model ...
	 Train_Loss: 0.3041 Train_Acc: 90.970 Val_Loss: 0.2828  BEST VAL Loss: 0.2828  Val_Acc: 93.704

Epoch 39: Validation loss decreased (0.282833 --> 0.281407).  Saving model ...
	 Train_Loss: 0.3027 Train_Acc: 91.228 Val_Loss: 0.2814  BEST VAL Loss: 0.2814  Val_Acc: 93.663

Epoch 40: Validation loss decreased (0.281407 --> 0.280021).  Saving model ...
	 Train_Loss: 0.3012 Train_Acc: 91.397 Val_Loss: 0.2800  BEST VAL Loss: 0.2800  Val_Acc: 93.621

Epoch 41: Validation loss decreased (0.280021 --> 0.278691).  Saving model ...
	 Train_Loss: 0.2998 Train_Acc: 91.480 Val_Loss: 0.2787  BEST VAL Loss: 0.2787  Val_Acc: 93.580

Epoch 42: Validation loss decreased (0.278691 --> 0.277505).  Saving model ...
	 Train_Loss: 0.2984 Train_Acc: 91.660 Val_Loss: 0.2775  BEST VAL Loss: 0.2775  Val_Acc: 93.251

Epoch 43: Validation loss decreased (0.277505 --> 0.276631).  Saving model ...
	 Train_Loss: 0.2972 Train_Acc: 91.459 Val_Loss: 0.2766  BEST VAL Loss: 0.2766  Val_Acc: 93.374

Epoch 44: Validation loss decreased (0.276631 --> 0.275249).  Saving model ...
	 Train_Loss: 0.2957 Train_Acc: 91.922 Val_Loss: 0.2752  BEST VAL Loss: 0.2752  Val_Acc: 93.992

Epoch 45: Validation loss decreased (0.275249 --> 0.274054).  Saving model ...
	 Train_Loss: 0.2944 Train_Acc: 91.835 Val_Loss: 0.2741  BEST VAL Loss: 0.2741  Val_Acc: 93.786

Epoch 46: Validation loss decreased (0.274054 --> 0.273233).  Saving model ...
	 Train_Loss: 0.2933 Train_Acc: 91.711 Val_Loss: 0.2732  BEST VAL Loss: 0.2732  Val_Acc: 92.716

Epoch 47: Validation loss decreased (0.273233 --> 0.272204).  Saving model ...
	 Train_Loss: 0.2922 Train_Acc: 91.547 Val_Loss: 0.2722  BEST VAL Loss: 0.2722  Val_Acc: 93.992

Epoch 48: Validation loss decreased (0.272204 --> 0.271976).  Saving model ...
	 Train_Loss: 0.2910 Train_Acc: 92.035 Val_Loss: 0.2720  BEST VAL Loss: 0.2720  Val_Acc: 92.469

Epoch 49: Validation loss decreased (0.271976 --> 0.271536).  Saving model ...
	 Train_Loss: 0.2899 Train_Acc: 91.788 Val_Loss: 0.2715  BEST VAL Loss: 0.2715  Val_Acc: 93.498

Epoch 50: Validation loss decreased (0.271536 --> 0.271188).  Saving model ...
	 Train_Loss: 0.2889 Train_Acc: 91.541 Val_Loss: 0.2712  BEST VAL Loss: 0.2712  Val_Acc: 92.634

Epoch 51: Validation loss decreased (0.271188 --> 0.270439).  Saving model ...
	 Train_Loss: 0.2881 Train_Acc: 91.336 Val_Loss: 0.2704  BEST VAL Loss: 0.2704  Val_Acc: 93.539

Epoch 52: Validation loss decreased (0.270439 --> 0.269528).  Saving model ...
	 Train_Loss: 0.2870 Train_Acc: 91.979 Val_Loss: 0.2695  BEST VAL Loss: 0.2695  Val_Acc: 93.992

Epoch 53: Validation loss decreased (0.269528 --> 0.269015).  Saving model ...
	 Train_Loss: 0.2860 Train_Acc: 91.932 Val_Loss: 0.2690  BEST VAL Loss: 0.2690  Val_Acc: 93.251

Epoch 54: Validation loss decreased (0.269015 --> 0.268190).  Saving model ...
	 Train_Loss: 0.2852 Train_Acc: 91.644 Val_Loss: 0.2682  BEST VAL Loss: 0.2682  Val_Acc: 93.951

Epoch 55: Validation loss decreased (0.268190 --> 0.267589).  Saving model ...
	 Train_Loss: 0.2843 Train_Acc: 91.917 Val_Loss: 0.2676  BEST VAL Loss: 0.2676  Val_Acc: 93.498

Epoch 56: Validation loss decreased (0.267589 --> 0.267292).  Saving model ...
	 Train_Loss: 0.2833 Train_Acc: 92.251 Val_Loss: 0.2673  BEST VAL Loss: 0.2673  Val_Acc: 92.305

Epoch 57: Validation loss decreased (0.267292 --> 0.266816).  Saving model ...
	 Train_Loss: 0.2825 Train_Acc: 91.773 Val_Loss: 0.2668  BEST VAL Loss: 0.2668  Val_Acc: 92.757

Epoch 58: Validation loss decreased (0.266816 --> 0.266391).  Saving model ...
	 Train_Loss: 0.2816 Train_Acc: 92.133 Val_Loss: 0.2664  BEST VAL Loss: 0.2664  Val_Acc: 93.333

Epoch 59: Validation loss decreased (0.266391 --> 0.265744).  Saving model ...
	 Train_Loss: 0.2808 Train_Acc: 91.737 Val_Loss: 0.2657  BEST VAL Loss: 0.2657  Val_Acc: 93.663

Epoch 60: Validation loss decreased (0.265744 --> 0.265168).  Saving model ...
	 Train_Loss: 0.2800 Train_Acc: 92.159 Val_Loss: 0.2652  BEST VAL Loss: 0.2652  Val_Acc: 93.827

Epoch 61: Validation loss decreased (0.265168 --> 0.264628).  Saving model ...
	 Train_Loss: 0.2792 Train_Acc: 92.164 Val_Loss: 0.2646  BEST VAL Loss: 0.2646  Val_Acc: 93.786

Epoch 62: Validation loss decreased (0.264628 --> 0.264124).  Saving model ...
	 Train_Loss: 0.2783 Train_Acc: 92.411 Val_Loss: 0.2641  BEST VAL Loss: 0.2641  Val_Acc: 93.827

Epoch 63: Validation loss decreased (0.264124 --> 0.264006).  Saving model ...
	 Train_Loss: 0.2775 Train_Acc: 92.221 Val_Loss: 0.2640  BEST VAL Loss: 0.2640  Val_Acc: 92.840

Epoch 64: Validation loss decreased (0.264006 --> 0.263494).  Saving model ...
	 Train_Loss: 0.2768 Train_Acc: 92.236 Val_Loss: 0.2635  BEST VAL Loss: 0.2635  Val_Acc: 94.115

Epoch 65: Validation loss decreased (0.263494 --> 0.262892).  Saving model ...
	 Train_Loss: 0.2760 Train_Acc: 92.231 Val_Loss: 0.2629  BEST VAL Loss: 0.2629  Val_Acc: 93.951

Epoch 66: Validation loss decreased (0.262892 --> 0.262408).  Saving model ...
	 Train_Loss: 0.2754 Train_Acc: 92.092 Val_Loss: 0.2624  BEST VAL Loss: 0.2624  Val_Acc: 93.992

Epoch 67: Validation loss decreased (0.262408 --> 0.262156).  Saving model ...
	 Train_Loss: 0.2746 Train_Acc: 92.462 Val_Loss: 0.2622  BEST VAL Loss: 0.2622  Val_Acc: 93.663

Epoch 68: Validation loss decreased (0.262156 --> 0.261691).  Saving model ...
	 Train_Loss: 0.2739 Train_Acc: 92.169 Val_Loss: 0.2617  BEST VAL Loss: 0.2617  Val_Acc: 93.621

Epoch 69: Validation loss decreased (0.261691 --> 0.261196).  Saving model ...
	 Train_Loss: 0.2734 Train_Acc: 91.891 Val_Loss: 0.2612  BEST VAL Loss: 0.2612  Val_Acc: 93.868

Epoch 70: Validation loss decreased (0.261196 --> 0.260725).  Saving model ...
	 Train_Loss: 0.2726 Train_Acc: 92.411 Val_Loss: 0.2607  BEST VAL Loss: 0.2607  Val_Acc: 93.786

Epoch 71: Validation loss decreased (0.260725 --> 0.260295).  Saving model ...
	 Train_Loss: 0.2720 Train_Acc: 92.288 Val_Loss: 0.2603  BEST VAL Loss: 0.2603  Val_Acc: 93.457

Epoch 72: Validation loss decreased (0.260295 --> 0.259960).  Saving model ...
	 Train_Loss: 0.2713 Train_Acc: 92.349 Val_Loss: 0.2600  BEST VAL Loss: 0.2600  Val_Acc: 93.416

Epoch 73: Validation loss decreased (0.259960 --> 0.259482).  Saving model ...
	 Train_Loss: 0.2708 Train_Acc: 92.210 Val_Loss: 0.2595  BEST VAL Loss: 0.2595  Val_Acc: 93.868

Epoch 74: Validation loss decreased (0.259482 --> 0.259164).  Saving model ...
	 Train_Loss: 0.2702 Train_Acc: 92.149 Val_Loss: 0.2592  BEST VAL Loss: 0.2592  Val_Acc: 93.951

Epoch 75: Validation loss decreased (0.259164 --> 0.258706).  Saving model ...
	 Train_Loss: 0.2695 Train_Acc: 92.473 Val_Loss: 0.2587  BEST VAL Loss: 0.2587  Val_Acc: 93.951

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.2690 Train_Acc: 92.138 Val_Loss: 0.2588  BEST VAL Loss: 0.2587  Val_Acc: 92.058

Epoch 77: Validation loss decreased (0.258706 --> 0.258257).  Saving model ...
	 Train_Loss: 0.2685 Train_Acc: 92.221 Val_Loss: 0.2583  BEST VAL Loss: 0.2583  Val_Acc: 94.115

Epoch 78: Validation loss decreased (0.258257 --> 0.257964).  Saving model ...
	 Train_Loss: 0.2679 Train_Acc: 92.179 Val_Loss: 0.2580  BEST VAL Loss: 0.2580  Val_Acc: 93.909

Epoch 79: Validation loss decreased (0.257964 --> 0.257553).  Saving model ...
	 Train_Loss: 0.2673 Train_Acc: 92.498 Val_Loss: 0.2576  BEST VAL Loss: 0.2576  Val_Acc: 94.074

Epoch 80: Validation loss decreased (0.257553 --> 0.257546).  Saving model ...
	 Train_Loss: 0.2668 Train_Acc: 92.478 Val_Loss: 0.2575  BEST VAL Loss: 0.2575  Val_Acc: 92.263

Epoch 81: Validation loss decreased (0.257546 --> 0.257146).  Saving model ...
	 Train_Loss: 0.2663 Train_Acc: 92.365 Val_Loss: 0.2571  BEST VAL Loss: 0.2571  Val_Acc: 94.074

Epoch 82: Validation loss decreased (0.257146 --> 0.256773).  Saving model ...
	 Train_Loss: 0.2657 Train_Acc: 92.812 Val_Loss: 0.2568  BEST VAL Loss: 0.2568  Val_Acc: 93.992

Epoch 83: Validation loss decreased (0.256773 --> 0.256276).  Saving model ...
	 Train_Loss: 0.2652 Train_Acc: 92.318 Val_Loss: 0.2563  BEST VAL Loss: 0.2563  Val_Acc: 94.321

Epoch 84: Validation loss decreased (0.256276 --> 0.256097).  Saving model ...
	 Train_Loss: 0.2646 Train_Acc: 92.576 Val_Loss: 0.2561  BEST VAL Loss: 0.2561  Val_Acc: 93.745

Epoch 85: Validation loss decreased (0.256097 --> 0.255715).  Saving model ...
	 Train_Loss: 0.2641 Train_Acc: 92.848 Val_Loss: 0.2557  BEST VAL Loss: 0.2557  Val_Acc: 93.992

Epoch 86: Validation loss decreased (0.255715 --> 0.255510).  Saving model ...
	 Train_Loss: 0.2635 Train_Acc: 92.637 Val_Loss: 0.2555  BEST VAL Loss: 0.2555  Val_Acc: 93.827

Epoch 87: Validation loss decreased (0.255510 --> 0.255336).  Saving model ...
	 Train_Loss: 0.2630 Train_Acc: 92.668 Val_Loss: 0.2553  BEST VAL Loss: 0.2553  Val_Acc: 93.868

Epoch 88: Validation loss decreased (0.255336 --> 0.254950).  Saving model ...
	 Train_Loss: 0.2624 Train_Acc: 92.756 Val_Loss: 0.2549  BEST VAL Loss: 0.2549  Val_Acc: 94.074

Epoch 89: Validation loss decreased (0.254950 --> 0.254611).  Saving model ...
	 Train_Loss: 0.2619 Train_Acc: 92.838 Val_Loss: 0.2546  BEST VAL Loss: 0.2546  Val_Acc: 93.827

Epoch 90: Validation loss decreased (0.254611 --> 0.254392).  Saving model ...
	 Train_Loss: 0.2614 Train_Acc: 92.925 Val_Loss: 0.2544  BEST VAL Loss: 0.2544  Val_Acc: 93.621

Epoch 91: Validation loss decreased (0.254392 --> 0.254170).  Saving model ...
	 Train_Loss: 0.2608 Train_Acc: 92.931 Val_Loss: 0.2542  BEST VAL Loss: 0.2542  Val_Acc: 93.827

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.2603 Train_Acc: 92.761 Val_Loss: 0.2543  BEST VAL Loss: 0.2542  Val_Acc: 92.757

Epoch 93: Validation loss decreased (0.254170 --> 0.253988).  Saving model ...
	 Train_Loss: 0.2600 Train_Acc: 92.210 Val_Loss: 0.2540  BEST VAL Loss: 0.2540  Val_Acc: 94.527

Epoch 94: Validation loss decreased (0.253988 --> 0.253788).  Saving model ...
	 Train_Loss: 0.2595 Train_Acc: 92.967 Val_Loss: 0.2538  BEST VAL Loss: 0.2538  Val_Acc: 93.992

Epoch 95: Validation loss decreased (0.253788 --> 0.253555).  Saving model ...
	 Train_Loss: 0.2590 Train_Acc: 92.792 Val_Loss: 0.2536  BEST VAL Loss: 0.2536  Val_Acc: 94.033

Epoch 96: Validation loss decreased (0.253555 --> 0.253440).  Saving model ...
	 Train_Loss: 0.2585 Train_Acc: 92.962 Val_Loss: 0.2534  BEST VAL Loss: 0.2534  Val_Acc: 93.909

Epoch 97: Validation loss decreased (0.253440 --> 0.253225).  Saving model ...
	 Train_Loss: 0.2580 Train_Acc: 92.843 Val_Loss: 0.2532  BEST VAL Loss: 0.2532  Val_Acc: 94.198

Epoch 98: Validation loss decreased (0.253225 --> 0.252948).  Saving model ...
	 Train_Loss: 0.2575 Train_Acc: 92.987 Val_Loss: 0.2529  BEST VAL Loss: 0.2529  Val_Acc: 94.321

Epoch 99: Validation loss decreased (0.252948 --> 0.252698).  Saving model ...
	 Train_Loss: 0.2571 Train_Acc: 92.874 Val_Loss: 0.2527  BEST VAL Loss: 0.2527  Val_Acc: 94.444

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      0.95      0.97      9832
           1       0.95      0.99      0.97      9604

    accuracy                           0.97     19436
   macro avg       0.97      0.97      0.97     19436
weighted avg       0.97      0.97      0.97     19436

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.96      0.93      0.94      1229
           1       0.93      0.96      0.94      1201

    accuracy                           0.94      2430
   macro avg       0.94      0.94      0.94      2430
weighted avg       0.95      0.94      0.94      2430

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.96      0.94      0.95      1229
           1       0.94      0.96      0.95      1201

    accuracy                           0.95      2430
   macro avg       0.95      0.95      0.95      2430
weighted avg       0.95      0.95      0.95      2430

              precision    recall  f1-score   support

           0       0.96      0.94      0.95      1229
           1       0.94      0.96      0.95      1201

    accuracy                           0.95      2430
   macro avg       0.95      0.95      0.95      2430
weighted avg       0.95      0.95      0.95      2430

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.96      0.95      0.96      4168
           1       0.95      0.97      0.96      4212

    accuracy                           0.96      8380
   macro avg       0.96      0.96      0.96      8380
weighted avg       0.96      0.96      0.96      8380

              precision    recall  f1-score   support

           0       0.96      0.95      0.96      4168
           1       0.95      0.97      0.96      4212

    accuracy                           0.96      8380
   macro avg       0.96      0.96      0.96      8380
weighted avg       0.96      0.96      0.96      8380

completed
