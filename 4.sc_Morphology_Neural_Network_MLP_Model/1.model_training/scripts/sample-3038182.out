[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '0bd3dd80'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '253a5ba8'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '5880b3cf'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '71292a61'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_10.000_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (32797, 1276)
Number of total missing values across all columns: 65594
Data Subset Is Off
Wells held out for testing: ['E20' 'J16']
Wells to use for training, validation, and testing ['E16' 'E17' 'E21' 'J17' 'J20' 'J21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.390869).  Saving model ...
	 Train_Loss: 0.5422 Train_Acc: 69.990 Val_Loss: 0.3909  BEST VAL Loss: 0.3909  Val_Acc: 83.082

Epoch 1: Validation loss decreased (0.390869 --> 0.331790).  Saving model ...
	 Train_Loss: 0.4719 Train_Acc: 77.992 Val_Loss: 0.3318  BEST VAL Loss: 0.3318  Val_Acc: 90.012

Epoch 2: Validation loss decreased (0.331790 --> 0.300735).  Saving model ...
	 Train_Loss: 0.4288 Train_Acc: 80.464 Val_Loss: 0.3007  BEST VAL Loss: 0.3007  Val_Acc: 91.317

Epoch 3: Validation loss decreased (0.300735 --> 0.283586).  Saving model ...
	 Train_Loss: 0.3979 Train_Acc: 81.850 Val_Loss: 0.2836  BEST VAL Loss: 0.2836  Val_Acc: 92.214

Epoch 4: Validation loss decreased (0.283586 --> 0.266438).  Saving model ...
	 Train_Loss: 0.3762 Train_Acc: 82.273 Val_Loss: 0.2664  BEST VAL Loss: 0.2664  Val_Acc: 93.274

Epoch 5: Validation loss decreased (0.266438 --> 0.255893).  Saving model ...
	 Train_Loss: 0.3581 Train_Acc: 85.596 Val_Loss: 0.2559  BEST VAL Loss: 0.2559  Val_Acc: 88.912

Epoch 6: Validation loss decreased (0.255893 --> 0.246782).  Saving model ...
	 Train_Loss: 0.3444 Train_Acc: 86.249 Val_Loss: 0.2468  BEST VAL Loss: 0.2468  Val_Acc: 88.504

Epoch 7: Validation loss decreased (0.246782 --> 0.239544).  Saving model ...
	 Train_Loss: 0.3337 Train_Acc: 86.340 Val_Loss: 0.2395  BEST VAL Loss: 0.2395  Val_Acc: 89.971

Epoch 8: Validation loss decreased (0.239544 --> 0.232620).  Saving model ...
	 Train_Loss: 0.3239 Train_Acc: 87.039 Val_Loss: 0.2326  BEST VAL Loss: 0.2326  Val_Acc: 90.420

Epoch 9: Validation loss decreased (0.232620 --> 0.226796).  Saving model ...
	 Train_Loss: 0.3152 Train_Acc: 87.610 Val_Loss: 0.2268  BEST VAL Loss: 0.2268  Val_Acc: 90.909

Epoch 10: Validation loss decreased (0.226796 --> 0.221698).  Saving model ...
	 Train_Loss: 0.3083 Train_Acc: 87.253 Val_Loss: 0.2217  BEST VAL Loss: 0.2217  Val_Acc: 90.705

Epoch 11: Validation loss decreased (0.221698 --> 0.216794).  Saving model ...
	 Train_Loss: 0.3019 Train_Acc: 87.829 Val_Loss: 0.2168  BEST VAL Loss: 0.2168  Val_Acc: 91.031

Epoch 12: Validation loss decreased (0.216794 --> 0.212797).  Saving model ...
	 Train_Loss: 0.2957 Train_Acc: 88.588 Val_Loss: 0.2128  BEST VAL Loss: 0.2128  Val_Acc: 91.480

Epoch 13: Validation loss decreased (0.212797 --> 0.208544).  Saving model ...
	 Train_Loss: 0.2900 Train_Acc: 88.899 Val_Loss: 0.2085  BEST VAL Loss: 0.2085  Val_Acc: 91.031

Epoch 14: Validation loss decreased (0.208544 --> 0.205386).  Saving model ...
	 Train_Loss: 0.2853 Train_Acc: 88.588 Val_Loss: 0.2054  BEST VAL Loss: 0.2054  Val_Acc: 91.561

Epoch 15: Validation loss decreased (0.205386 --> 0.201636).  Saving model ...
	 Train_Loss: 0.2810 Train_Acc: 88.853 Val_Loss: 0.2016  BEST VAL Loss: 0.2016  Val_Acc: 91.724

Epoch 16: Validation loss decreased (0.201636 --> 0.199100).  Saving model ...
	 Train_Loss: 0.2771 Train_Acc: 88.772 Val_Loss: 0.1991  BEST VAL Loss: 0.1991  Val_Acc: 91.235

Epoch 17: Validation loss decreased (0.199100 --> 0.197267).  Saving model ...
	 Train_Loss: 0.2734 Train_Acc: 89.225 Val_Loss: 0.1973  BEST VAL Loss: 0.1973  Val_Acc: 91.072

Epoch 18: Validation loss decreased (0.197267 --> 0.195411).  Saving model ...
	 Train_Loss: 0.2698 Train_Acc: 89.506 Val_Loss: 0.1954  BEST VAL Loss: 0.1954  Val_Acc: 91.684

Epoch 19: Validation loss decreased (0.195411 --> 0.193668).  Saving model ...
	 Train_Loss: 0.2666 Train_Acc: 89.562 Val_Loss: 0.1937  BEST VAL Loss: 0.1937  Val_Acc: 91.724

Epoch 20: Validation loss decreased (0.193668 --> 0.191547).  Saving model ...
	 Train_Loss: 0.2635 Train_Acc: 89.653 Val_Loss: 0.1915  BEST VAL Loss: 0.1915  Val_Acc: 92.377

Epoch 21: Validation loss decreased (0.191547 --> 0.190055).  Saving model ...
	 Train_Loss: 0.2607 Train_Acc: 89.760 Val_Loss: 0.1901  BEST VAL Loss: 0.1901  Val_Acc: 91.806

Epoch 22: Validation loss decreased (0.190055 --> 0.189142).  Saving model ...
	 Train_Loss: 0.2578 Train_Acc: 90.071 Val_Loss: 0.1891  BEST VAL Loss: 0.1891  Val_Acc: 91.643

Epoch 23: Validation loss decreased (0.189142 --> 0.188152).  Saving model ...
	 Train_Loss: 0.2553 Train_Acc: 90.189 Val_Loss: 0.1882  BEST VAL Loss: 0.1882  Val_Acc: 92.417

Epoch 24: Validation loss decreased (0.188152 --> 0.187500).  Saving model ...
	 Train_Loss: 0.2527 Train_Acc: 90.459 Val_Loss: 0.1875  BEST VAL Loss: 0.1875  Val_Acc: 91.928

Epoch 25: Validation loss decreased (0.187500 --> 0.186409).  Saving model ...
	 Train_Loss: 0.2506 Train_Acc: 90.143 Val_Loss: 0.1864  BEST VAL Loss: 0.1864  Val_Acc: 92.214

Epoch 26: Validation loss decreased (0.186409 --> 0.185376).  Saving model ...
	 Train_Loss: 0.2485 Train_Acc: 90.357 Val_Loss: 0.1854  BEST VAL Loss: 0.1854  Val_Acc: 92.662

Epoch 27: Validation loss decreased (0.185376 --> 0.184788).  Saving model ...
	 Train_Loss: 0.2464 Train_Acc: 90.780 Val_Loss: 0.1848  BEST VAL Loss: 0.1848  Val_Acc: 92.173

Epoch 28: Validation loss decreased (0.184788 --> 0.184421).  Saving model ...
	 Train_Loss: 0.2444 Train_Acc: 90.438 Val_Loss: 0.1844  BEST VAL Loss: 0.1844  Val_Acc: 92.621

Epoch 29: Validation loss decreased (0.184421 --> 0.183411).  Saving model ...
	 Train_Loss: 0.2425 Train_Acc: 90.770 Val_Loss: 0.1834  BEST VAL Loss: 0.1834  Val_Acc: 93.396

Epoch 30: Validation loss decreased (0.183411 --> 0.182463).  Saving model ...
	 Train_Loss: 0.2405 Train_Acc: 90.887 Val_Loss: 0.1825  BEST VAL Loss: 0.1825  Val_Acc: 93.151

Epoch 31: Validation loss decreased (0.182463 --> 0.182050).  Saving model ...
	 Train_Loss: 0.2387 Train_Acc: 90.953 Val_Loss: 0.1820  BEST VAL Loss: 0.1820  Val_Acc: 93.192

Epoch 32: Validation loss decreased (0.182050 --> 0.181611).  Saving model ...
	 Train_Loss: 0.2370 Train_Acc: 90.958 Val_Loss: 0.1816  BEST VAL Loss: 0.1816  Val_Acc: 92.866

Epoch 33: Validation loss decreased (0.181611 --> 0.180901).  Saving model ...
	 Train_Loss: 0.2354 Train_Acc: 90.948 Val_Loss: 0.1809  BEST VAL Loss: 0.1809  Val_Acc: 93.029

Epoch 34: Validation loss decreased (0.180901 --> 0.180329).  Saving model ...
	 Train_Loss: 0.2336 Train_Acc: 91.402 Val_Loss: 0.1803  BEST VAL Loss: 0.1803  Val_Acc: 93.110

Epoch 35: Validation loss decreased (0.180329 --> 0.179489).  Saving model ...
	 Train_Loss: 0.2319 Train_Acc: 91.412 Val_Loss: 0.1795  BEST VAL Loss: 0.1795  Val_Acc: 92.825

Epoch 36: Validation loss decreased (0.179489 --> 0.178732).  Saving model ...
	 Train_Loss: 0.2304 Train_Acc: 91.177 Val_Loss: 0.1787  BEST VAL Loss: 0.1787  Val_Acc: 93.192

Epoch 37: Validation loss decreased (0.178732 --> 0.178271).  Saving model ...
	 Train_Loss: 0.2290 Train_Acc: 91.233 Val_Loss: 0.1783  BEST VAL Loss: 0.1783  Val_Acc: 92.947

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.2275 Train_Acc: 91.570 Val_Loss: 0.1785  BEST VAL Loss: 0.1783  Val_Acc: 93.070

Epoch 39: Validation loss decreased (0.178271 --> 0.178258).  Saving model ...
	 Train_Loss: 0.2263 Train_Acc: 91.131 Val_Loss: 0.1783  BEST VAL Loss: 0.1783  Val_Acc: 93.477

Epoch 40: Validation loss decreased (0.178258 --> 0.177772).  Saving model ...
	 Train_Loss: 0.2250 Train_Acc: 91.641 Val_Loss: 0.1778  BEST VAL Loss: 0.1778  Val_Acc: 93.518

Epoch 41: Validation loss decreased (0.177772 --> 0.177289).  Saving model ...
	 Train_Loss: 0.2237 Train_Acc: 91.682 Val_Loss: 0.1773  BEST VAL Loss: 0.1773  Val_Acc: 93.355

Epoch 42: Validation loss decreased (0.177289 --> 0.176892).  Saving model ...
	 Train_Loss: 0.2226 Train_Acc: 91.611 Val_Loss: 0.1769  BEST VAL Loss: 0.1769  Val_Acc: 93.355

Epoch 43: Validation loss decreased (0.176892 --> 0.176493).  Saving model ...
	 Train_Loss: 0.2213 Train_Acc: 91.779 Val_Loss: 0.1765  BEST VAL Loss: 0.1765  Val_Acc: 93.681

Epoch 44: Validation loss decreased (0.176493 --> 0.175835).  Saving model ...
	 Train_Loss: 0.2203 Train_Acc: 91.305 Val_Loss: 0.1758  BEST VAL Loss: 0.1758  Val_Acc: 93.355

Epoch 45: Validation loss decreased (0.175835 --> 0.175780).  Saving model ...
	 Train_Loss: 0.2192 Train_Acc: 91.692 Val_Loss: 0.1758  BEST VAL Loss: 0.1758  Val_Acc: 93.640

Epoch 46: Validation loss decreased (0.175780 --> 0.175278).  Saving model ...
	 Train_Loss: 0.2182 Train_Acc: 91.758 Val_Loss: 0.1753  BEST VAL Loss: 0.1753  Val_Acc: 93.518

Epoch 47: Validation loss decreased (0.175278 --> 0.175074).  Saving model ...
	 Train_Loss: 0.2170 Train_Acc: 92.049 Val_Loss: 0.1751  BEST VAL Loss: 0.1751  Val_Acc: 93.437

Epoch 48: Validation loss decreased (0.175074 --> 0.174668).  Saving model ...
	 Train_Loss: 0.2161 Train_Acc: 91.453 Val_Loss: 0.1747  BEST VAL Loss: 0.1747  Val_Acc: 93.355

Epoch 49: Validation loss decreased (0.174668 --> 0.174543).  Saving model ...
	 Train_Loss: 0.2152 Train_Acc: 91.509 Val_Loss: 0.1745  BEST VAL Loss: 0.1745  Val_Acc: 93.151

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.2142 Train_Acc: 92.018 Val_Loss: 0.1746  BEST VAL Loss: 0.1745  Val_Acc: 92.377

Epoch 51: Validation loss decreased (0.174543 --> 0.174235).  Saving model ...
	 Train_Loss: 0.2134 Train_Acc: 91.407 Val_Loss: 0.1742  BEST VAL Loss: 0.1742  Val_Acc: 93.192

Epoch 52: Validation loss decreased (0.174235 --> 0.173732).  Saving model ...
	 Train_Loss: 0.2126 Train_Acc: 91.891 Val_Loss: 0.1737  BEST VAL Loss: 0.1737  Val_Acc: 93.763

Epoch 53: Validation loss decreased (0.173732 --> 0.173504).  Saving model ...
	 Train_Loss: 0.2116 Train_Acc: 92.207 Val_Loss: 0.1735  BEST VAL Loss: 0.1735  Val_Acc: 93.926

Epoch 54: Validation loss decreased (0.173504 --> 0.173115).  Saving model ...
	 Train_Loss: 0.2108 Train_Acc: 91.911 Val_Loss: 0.1731  BEST VAL Loss: 0.1731  Val_Acc: 93.518

Epoch 55: Validation loss decreased (0.173115 --> 0.172787).  Saving model ...
	 Train_Loss: 0.2100 Train_Acc: 92.187 Val_Loss: 0.1728  BEST VAL Loss: 0.1728  Val_Acc: 93.559

Epoch 56: Validation loss decreased (0.172787 --> 0.172430).  Saving model ...
	 Train_Loss: 0.2091 Train_Acc: 92.232 Val_Loss: 0.1724  BEST VAL Loss: 0.1724  Val_Acc: 94.089

Epoch 57: Validation loss decreased (0.172430 --> 0.172087).  Saving model ...
	 Train_Loss: 0.2084 Train_Acc: 91.789 Val_Loss: 0.1721  BEST VAL Loss: 0.1721  Val_Acc: 93.926

Epoch 58: Validation loss decreased (0.172087 --> 0.171810).  Saving model ...
	 Train_Loss: 0.2076 Train_Acc: 92.253 Val_Loss: 0.1718  BEST VAL Loss: 0.1718  Val_Acc: 93.233

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.2067 Train_Acc: 92.625 Val_Loss: 0.1720  BEST VAL Loss: 0.1718  Val_Acc: 93.967

Epoch 60: Validation loss decreased (0.171810 --> 0.171786).  Saving model ...
	 Train_Loss: 0.2060 Train_Acc: 91.743 Val_Loss: 0.1718  BEST VAL Loss: 0.1718  Val_Acc: 93.640

Epoch 61: Validation loss decreased (0.171786 --> 0.171533).  Saving model ...
	 Train_Loss: 0.2053 Train_Acc: 92.329 Val_Loss: 0.1715  BEST VAL Loss: 0.1715  Val_Acc: 93.600

Epoch 62: Validation loss decreased (0.171533 --> 0.171426).  Saving model ...
	 Train_Loss: 0.2046 Train_Acc: 92.253 Val_Loss: 0.1714  BEST VAL Loss: 0.1714  Val_Acc: 93.885

Epoch 63: Validation loss decreased (0.171426 --> 0.171355).  Saving model ...
	 Train_Loss: 0.2039 Train_Acc: 92.283 Val_Loss: 0.1714  BEST VAL Loss: 0.1714  Val_Acc: 93.804

Epoch 64: Validation loss decreased (0.171355 --> 0.171126).  Saving model ...
	 Train_Loss: 0.2032 Train_Acc: 92.406 Val_Loss: 0.1711  BEST VAL Loss: 0.1711  Val_Acc: 93.600

Epoch 65: Validation loss decreased (0.171126 --> 0.170698).  Saving model ...
	 Train_Loss: 0.2025 Train_Acc: 92.487 Val_Loss: 0.1707  BEST VAL Loss: 0.1707  Val_Acc: 93.804

Epoch 66: Validation loss decreased (0.170698 --> 0.170652).  Saving model ...
	 Train_Loss: 0.2017 Train_Acc: 92.579 Val_Loss: 0.1707  BEST VAL Loss: 0.1707  Val_Acc: 94.007

Epoch 67: Validation loss decreased (0.170652 --> 0.170158).  Saving model ...
	 Train_Loss: 0.2011 Train_Acc: 92.365 Val_Loss: 0.1702  BEST VAL Loss: 0.1702  Val_Acc: 93.477

Epoch 68: Validation loss decreased (0.170158 --> 0.169980).  Saving model ...
	 Train_Loss: 0.2004 Train_Acc: 92.620 Val_Loss: 0.1700  BEST VAL Loss: 0.1700  Val_Acc: 93.518

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.1998 Train_Acc: 92.712 Val_Loss: 0.1701  BEST VAL Loss: 0.1700  Val_Acc: 94.089

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.1991 Train_Acc: 92.661 Val_Loss: 0.1704  BEST VAL Loss: 0.1700  Val_Acc: 93.844

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.1985 Train_Acc: 92.574 Val_Loss: 0.1703  BEST VAL Loss: 0.1700  Val_Acc: 94.089

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.1978 Train_Acc: 92.844 Val_Loss: 0.1701  BEST VAL Loss: 0.1700  Val_Acc: 93.681

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.1972 Train_Acc: 92.717 Val_Loss: 0.1704  BEST VAL Loss: 0.1700  Val_Acc: 93.722

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.1967 Train_Acc: 92.492 Val_Loss: 0.1704  BEST VAL Loss: 0.1700  Val_Acc: 94.578

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.1963 Train_Acc: 92.161 Val_Loss: 0.1705  BEST VAL Loss: 0.1700  Val_Acc: 93.600

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.1957 Train_Acc: 92.640 Val_Loss: 0.1706  BEST VAL Loss: 0.1700  Val_Acc: 93.559

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.1952 Train_Acc: 92.768 Val_Loss: 0.1705  BEST VAL Loss: 0.1700  Val_Acc: 94.211

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.1947 Train_Acc: 92.655 Val_Loss: 0.1707  BEST VAL Loss: 0.1700  Val_Acc: 94.333

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.1942 Train_Acc: 92.890 Val_Loss: 0.1709  BEST VAL Loss: 0.1700  Val_Acc: 93.844

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.1937 Train_Acc: 92.706 Val_Loss: 0.1709  BEST VAL Loss: 0.1700  Val_Acc: 93.151

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.1932 Train_Acc: 92.676 Val_Loss: 0.1708  BEST VAL Loss: 0.1700  Val_Acc: 94.007

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.1927 Train_Acc: 92.992 Val_Loss: 0.1708  BEST VAL Loss: 0.1700  Val_Acc: 94.048

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.1922 Train_Acc: 92.808 Val_Loss: 0.1705  BEST VAL Loss: 0.1700  Val_Acc: 93.763

Epoch 84: Validation loss did not decrease
Early stopped at epoch : 84
LPS_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.48      0.49     10114
           1       0.48      0.51      0.50      9506

    accuracy                           0.50     19620
   macro avg       0.50      0.50      0.50     19620
weighted avg       0.50      0.50      0.50     19620

LPS_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.47      0.49      1264
           1       0.48      0.51      0.49      1189

    accuracy                           0.49      2453
   macro avg       0.49      0.49      0.49      2453
weighted avg       0.49      0.49      0.49      2453

LPS_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.47      0.49      1264
           1       0.48      0.52      0.50      1189

    accuracy                           0.49      2453
   macro avg       0.49      0.49      0.49      2453
weighted avg       0.49      0.49      0.49      2453

              precision    recall  f1-score   support

           0       0.51      0.47      0.49      1264
           1       0.48      0.52      0.50      1189

    accuracy                           0.49      2453
   macro avg       0.49      0.49      0.49      2453
weighted avg       0.49      0.49      0.49      2453

LPS_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.42      0.46      4168
           1       0.50      0.58      0.54      4103

    accuracy                           0.50      8271
   macro avg       0.50      0.50      0.50      8271
weighted avg       0.50      0.50      0.50      8271

              precision    recall  f1-score   support

           0       0.50      0.42      0.46      4168
           1       0.50      0.58      0.54      4103

    accuracy                           0.50      8271
   macro avg       0.50      0.50      0.50      8271
weighted avg       0.50      0.50      0.50      8271

completed
