[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '71db41ed'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '83648e75'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'cda385d3'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'f5315c0d'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: LPS_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: LPS_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (313694, 1270)
Number of total missing values across all columns: 278866
Data Subset Is Off
Wells held out for testing: ['D09' 'L09']
Wells to use for training, validation, and testing ['D02' 'D03' 'D08' 'L02' 'L03' 'L08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.227418).  Saving model ...
	 Train_Loss: 0.3517 Train_Acc: 84.767 Val_Loss: 0.2274  BEST VAL Loss: 0.2274  Val_Acc: 91.610

Epoch 1: Validation loss decreased (0.227418 --> 0.209148).  Saving model ...
	 Train_Loss: 0.3099 Train_Acc: 89.240 Val_Loss: 0.2091  BEST VAL Loss: 0.2091  Val_Acc: 92.701

Epoch 2: Validation loss decreased (0.209148 --> 0.200302).  Saving model ...
	 Train_Loss: 0.2890 Train_Acc: 89.955 Val_Loss: 0.2003  BEST VAL Loss: 0.2003  Val_Acc: 93.046

Epoch 3: Validation loss decreased (0.200302 --> 0.196584).  Saving model ...
	 Train_Loss: 0.2762 Train_Acc: 90.285 Val_Loss: 0.1966  BEST VAL Loss: 0.1966  Val_Acc: 92.651

Epoch 4: Validation loss decreased (0.196584 --> 0.190790).  Saving model ...
	 Train_Loss: 0.2673 Train_Acc: 90.471 Val_Loss: 0.1908  BEST VAL Loss: 0.1908  Val_Acc: 93.325

Epoch 5: Validation loss decreased (0.190790 --> 0.188610).  Saving model ...
	 Train_Loss: 0.2606 Train_Acc: 90.672 Val_Loss: 0.1886  BEST VAL Loss: 0.1886  Val_Acc: 93.084

Epoch 6: Validation loss decreased (0.188610 --> 0.185165).  Saving model ...
	 Train_Loss: 0.2554 Train_Acc: 90.742 Val_Loss: 0.1852  BEST VAL Loss: 0.1852  Val_Acc: 93.604

Epoch 7: Validation loss decreased (0.185165 --> 0.181644).  Saving model ...
	 Train_Loss: 0.2511 Train_Acc: 90.888 Val_Loss: 0.1816  BEST VAL Loss: 0.1816  Val_Acc: 93.971

Epoch 8: Validation loss decreased (0.181644 --> 0.179054).  Saving model ...
	 Train_Loss: 0.2474 Train_Acc: 90.998 Val_Loss: 0.1791  BEST VAL Loss: 0.1791  Val_Acc: 93.862

Epoch 9: Validation loss decreased (0.179054 --> 0.176883).  Saving model ...
	 Train_Loss: 0.2443 Train_Acc: 90.963 Val_Loss: 0.1769  BEST VAL Loss: 0.1769  Val_Acc: 93.979

Epoch 10: Validation loss decreased (0.176883 --> 0.174894).  Saving model ...
	 Train_Loss: 0.2416 Train_Acc: 91.040 Val_Loss: 0.1749  BEST VAL Loss: 0.1749  Val_Acc: 94.033

Epoch 11: Validation loss decreased (0.174894 --> 0.173217).  Saving model ...
	 Train_Loss: 0.2392 Train_Acc: 91.124 Val_Loss: 0.1732  BEST VAL Loss: 0.1732  Val_Acc: 94.037

Epoch 12: Validation loss decreased (0.173217 --> 0.171515).  Saving model ...
	 Train_Loss: 0.2372 Train_Acc: 91.040 Val_Loss: 0.1715  BEST VAL Loss: 0.1715  Val_Acc: 94.154

Epoch 13: Validation loss decreased (0.171515 --> 0.170184).  Saving model ...
	 Train_Loss: 0.2354 Train_Acc: 91.104 Val_Loss: 0.1702  BEST VAL Loss: 0.1702  Val_Acc: 94.046

Epoch 14: Validation loss decreased (0.170184 --> 0.168805).  Saving model ...
	 Train_Loss: 0.2337 Train_Acc: 91.186 Val_Loss: 0.1688  BEST VAL Loss: 0.1688  Val_Acc: 94.200

Epoch 15: Validation loss decreased (0.168805 --> 0.167544).  Saving model ...
	 Train_Loss: 0.2322 Train_Acc: 91.143 Val_Loss: 0.1675  BEST VAL Loss: 0.1675  Val_Acc: 94.345

Epoch 16: Validation loss decreased (0.167544 --> 0.166499).  Saving model ...
	 Train_Loss: 0.2308 Train_Acc: 91.236 Val_Loss: 0.1665  BEST VAL Loss: 0.1665  Val_Acc: 94.187

Epoch 17: Validation loss decreased (0.166499 --> 0.165468).  Saving model ...
	 Train_Loss: 0.2295 Train_Acc: 91.241 Val_Loss: 0.1655  BEST VAL Loss: 0.1655  Val_Acc: 94.283

Epoch 18: Validation loss decreased (0.165468 --> 0.164511).  Saving model ...
	 Train_Loss: 0.2284 Train_Acc: 91.299 Val_Loss: 0.1645  BEST VAL Loss: 0.1645  Val_Acc: 94.246

Epoch 19: Validation loss decreased (0.164511 --> 0.164101).  Saving model ...
	 Train_Loss: 0.2273 Train_Acc: 91.339 Val_Loss: 0.1641  BEST VAL Loss: 0.1641  Val_Acc: 93.571

Epoch 20: Validation loss decreased (0.164101 --> 0.163823).  Saving model ...
	 Train_Loss: 0.2263 Train_Acc: 91.185 Val_Loss: 0.1638  BEST VAL Loss: 0.1638  Val_Acc: 93.754

Epoch 21: Validation loss decreased (0.163823 --> 0.163012).  Saving model ...
	 Train_Loss: 0.2254 Train_Acc: 91.239 Val_Loss: 0.1630  BEST VAL Loss: 0.1630  Val_Acc: 94.295

Epoch 22: Validation loss decreased (0.163012 --> 0.162501).  Saving model ...
	 Train_Loss: 0.2244 Train_Acc: 91.448 Val_Loss: 0.1625  BEST VAL Loss: 0.1625  Val_Acc: 94.121

Epoch 23: Validation loss decreased (0.162501 --> 0.161811).  Saving model ...
	 Train_Loss: 0.2235 Train_Acc: 91.413 Val_Loss: 0.1618  BEST VAL Loss: 0.1618  Val_Acc: 94.425

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.2227 Train_Acc: 91.437 Val_Loss: 0.1624  BEST VAL Loss: 0.1618  Val_Acc: 93.084

Epoch 25: Validation loss decreased (0.161811 --> 0.161729).  Saving model ...
	 Train_Loss: 0.2220 Train_Acc: 91.345 Val_Loss: 0.1617  BEST VAL Loss: 0.1617  Val_Acc: 94.325

Epoch 26: Validation loss decreased (0.161729 --> 0.161211).  Saving model ...
	 Train_Loss: 0.2212 Train_Acc: 91.501 Val_Loss: 0.1612  BEST VAL Loss: 0.1612  Val_Acc: 94.141

Epoch 27: Validation loss decreased (0.161211 --> 0.160605).  Saving model ...
	 Train_Loss: 0.2206 Train_Acc: 91.425 Val_Loss: 0.1606  BEST VAL Loss: 0.1606  Val_Acc: 94.354

Epoch 28: Validation loss decreased (0.160605 --> 0.160056).  Saving model ...
	 Train_Loss: 0.2199 Train_Acc: 91.500 Val_Loss: 0.1601  BEST VAL Loss: 0.1601  Val_Acc: 94.408

Epoch 29: Validation loss decreased (0.160056 --> 0.159400).  Saving model ...
	 Train_Loss: 0.2193 Train_Acc: 91.458 Val_Loss: 0.1594  BEST VAL Loss: 0.1594  Val_Acc: 94.579

Epoch 30: Validation loss decreased (0.159400 --> 0.159196).  Saving model ...
	 Train_Loss: 0.2187 Train_Acc: 91.514 Val_Loss: 0.1592  BEST VAL Loss: 0.1592  Val_Acc: 93.912

Epoch 31: Validation loss decreased (0.159196 --> 0.158733).  Saving model ...
	 Train_Loss: 0.2181 Train_Acc: 91.531 Val_Loss: 0.1587  BEST VAL Loss: 0.1587  Val_Acc: 94.445

Epoch 32: Validation loss decreased (0.158733 --> 0.158434).  Saving model ...
	 Train_Loss: 0.2176 Train_Acc: 91.503 Val_Loss: 0.1584  BEST VAL Loss: 0.1584  Val_Acc: 94.179

Epoch 33: Validation loss decreased (0.158434 --> 0.158002).  Saving model ...
	 Train_Loss: 0.2171 Train_Acc: 91.539 Val_Loss: 0.1580  BEST VAL Loss: 0.1580  Val_Acc: 94.379

Epoch 34: Validation loss decreased (0.158002 --> 0.157598).  Saving model ...
	 Train_Loss: 0.2166 Train_Acc: 91.513 Val_Loss: 0.1576  BEST VAL Loss: 0.1576  Val_Acc: 94.358

Epoch 35: Validation loss decreased (0.157598 --> 0.157115).  Saving model ...
	 Train_Loss: 0.2161 Train_Acc: 91.578 Val_Loss: 0.1571  BEST VAL Loss: 0.1571  Val_Acc: 94.641

Epoch 36: Validation loss decreased (0.157115 --> 0.156710).  Saving model ...
	 Train_Loss: 0.2157 Train_Acc: 91.608 Val_Loss: 0.1567  BEST VAL Loss: 0.1567  Val_Acc: 94.500

Epoch 37: Validation loss decreased (0.156710 --> 0.156268).  Saving model ...
	 Train_Loss: 0.2152 Train_Acc: 91.560 Val_Loss: 0.1563  BEST VAL Loss: 0.1563  Val_Acc: 94.574

Epoch 38: Validation loss decreased (0.156268 --> 0.155825).  Saving model ...
	 Train_Loss: 0.2147 Train_Acc: 91.632 Val_Loss: 0.1558  BEST VAL Loss: 0.1558  Val_Acc: 94.591

Epoch 39: Validation loss decreased (0.155825 --> 0.155516).  Saving model ...
	 Train_Loss: 0.2143 Train_Acc: 91.594 Val_Loss: 0.1555  BEST VAL Loss: 0.1555  Val_Acc: 94.420

Epoch 40: Validation loss decreased (0.155516 --> 0.155244).  Saving model ...
	 Train_Loss: 0.2139 Train_Acc: 91.577 Val_Loss: 0.1552  BEST VAL Loss: 0.1552  Val_Acc: 94.250

Epoch 41: Validation loss decreased (0.155244 --> 0.154838).  Saving model ...
	 Train_Loss: 0.2135 Train_Acc: 91.645 Val_Loss: 0.1548  BEST VAL Loss: 0.1548  Val_Acc: 94.591

Epoch 42: Validation loss decreased (0.154838 --> 0.154504).  Saving model ...
	 Train_Loss: 0.2131 Train_Acc: 91.613 Val_Loss: 0.1545  BEST VAL Loss: 0.1545  Val_Acc: 94.495

Epoch 43: Validation loss decreased (0.154504 --> 0.154134).  Saving model ...
	 Train_Loss: 0.2128 Train_Acc: 91.626 Val_Loss: 0.1541  BEST VAL Loss: 0.1541  Val_Acc: 94.595

Epoch 44: Validation loss decreased (0.154134 --> 0.154000).  Saving model ...
	 Train_Loss: 0.2124 Train_Acc: 91.622 Val_Loss: 0.1540  BEST VAL Loss: 0.1540  Val_Acc: 94.129

Epoch 45: Validation loss decreased (0.154000 --> 0.153720).  Saving model ...
	 Train_Loss: 0.2121 Train_Acc: 91.689 Val_Loss: 0.1537  BEST VAL Loss: 0.1537  Val_Acc: 94.512

Epoch 46: Validation loss decreased (0.153720 --> 0.153541).  Saving model ...
	 Train_Loss: 0.2117 Train_Acc: 91.723 Val_Loss: 0.1535  BEST VAL Loss: 0.1535  Val_Acc: 94.337

Epoch 47: Validation loss decreased (0.153541 --> 0.153284).  Saving model ...
	 Train_Loss: 0.2114 Train_Acc: 91.634 Val_Loss: 0.1533  BEST VAL Loss: 0.1533  Val_Acc: 94.362

Epoch 48: Validation loss decreased (0.153284 --> 0.152962).  Saving model ...
	 Train_Loss: 0.2111 Train_Acc: 91.743 Val_Loss: 0.1530  BEST VAL Loss: 0.1530  Val_Acc: 94.699

Epoch 49: Validation loss decreased (0.152962 --> 0.152760).  Saving model ...
	 Train_Loss: 0.2108 Train_Acc: 91.696 Val_Loss: 0.1528  BEST VAL Loss: 0.1528  Val_Acc: 94.362

Epoch 50: Validation loss decreased (0.152760 --> 0.152456).  Saving model ...
	 Train_Loss: 0.2105 Train_Acc: 91.574 Val_Loss: 0.1525  BEST VAL Loss: 0.1525  Val_Acc: 94.537

Epoch 51: Validation loss decreased (0.152456 --> 0.152209).  Saving model ...
	 Train_Loss: 0.2102 Train_Acc: 91.765 Val_Loss: 0.1522  BEST VAL Loss: 0.1522  Val_Acc: 94.462

Epoch 52: Validation loss decreased (0.152209 --> 0.151945).  Saving model ...
	 Train_Loss: 0.2099 Train_Acc: 91.708 Val_Loss: 0.1519  BEST VAL Loss: 0.1519  Val_Acc: 94.666

Epoch 53: Validation loss decreased (0.151945 --> 0.151696).  Saving model ...
	 Train_Loss: 0.2096 Train_Acc: 91.675 Val_Loss: 0.1517  BEST VAL Loss: 0.1517  Val_Acc: 94.520

Epoch 54: Validation loss decreased (0.151696 --> 0.151442).  Saving model ...
	 Train_Loss: 0.2094 Train_Acc: 91.749 Val_Loss: 0.1514  BEST VAL Loss: 0.1514  Val_Acc: 94.704

Epoch 55: Validation loss decreased (0.151442 --> 0.151265).  Saving model ...
	 Train_Loss: 0.2091 Train_Acc: 91.682 Val_Loss: 0.1513  BEST VAL Loss: 0.1513  Val_Acc: 94.391

Epoch 56: Validation loss decreased (0.151265 --> 0.151080).  Saving model ...
	 Train_Loss: 0.2088 Train_Acc: 91.700 Val_Loss: 0.1511  BEST VAL Loss: 0.1511  Val_Acc: 94.487

Epoch 57: Validation loss decreased (0.151080 --> 0.150981).  Saving model ...
	 Train_Loss: 0.2086 Train_Acc: 91.729 Val_Loss: 0.1510  BEST VAL Loss: 0.1510  Val_Acc: 94.150

Epoch 58: Validation loss decreased (0.150981 --> 0.150734).  Saving model ...
	 Train_Loss: 0.2083 Train_Acc: 91.750 Val_Loss: 0.1507  BEST VAL Loss: 0.1507  Val_Acc: 94.637

Epoch 59: Validation loss decreased (0.150734 --> 0.150525).  Saving model ...
	 Train_Loss: 0.2081 Train_Acc: 91.755 Val_Loss: 0.1505  BEST VAL Loss: 0.1505  Val_Acc: 94.537

Epoch 60: Validation loss decreased (0.150525 --> 0.150316).  Saving model ...
	 Train_Loss: 0.2078 Train_Acc: 91.810 Val_Loss: 0.1503  BEST VAL Loss: 0.1503  Val_Acc: 94.724

Epoch 61: Validation loss decreased (0.150316 --> 0.150166).  Saving model ...
	 Train_Loss: 0.2076 Train_Acc: 91.718 Val_Loss: 0.1502  BEST VAL Loss: 0.1502  Val_Acc: 94.512

Epoch 62: Validation loss decreased (0.150166 --> 0.150007).  Saving model ...
	 Train_Loss: 0.2074 Train_Acc: 91.738 Val_Loss: 0.1500  BEST VAL Loss: 0.1500  Val_Acc: 94.587

Epoch 63: Validation loss decreased (0.150007 --> 0.149863).  Saving model ...
	 Train_Loss: 0.2072 Train_Acc: 91.858 Val_Loss: 0.1499  BEST VAL Loss: 0.1499  Val_Acc: 94.558

Epoch 64: Validation loss decreased (0.149863 --> 0.149697).  Saving model ...
	 Train_Loss: 0.2070 Train_Acc: 91.827 Val_Loss: 0.1497  BEST VAL Loss: 0.1497  Val_Acc: 94.541

Epoch 65: Validation loss decreased (0.149697 --> 0.149490).  Saving model ...
	 Train_Loss: 0.2068 Train_Acc: 91.824 Val_Loss: 0.1495  BEST VAL Loss: 0.1495  Val_Acc: 94.583

Epoch 66: Validation loss decreased (0.149490 --> 0.149304).  Saving model ...
	 Train_Loss: 0.2066 Train_Acc: 91.832 Val_Loss: 0.1493  BEST VAL Loss: 0.1493  Val_Acc: 94.520

Epoch 67: Validation loss decreased (0.149304 --> 0.149134).  Saving model ...
	 Train_Loss: 0.2064 Train_Acc: 91.751 Val_Loss: 0.1491  BEST VAL Loss: 0.1491  Val_Acc: 94.487

Epoch 68: Validation loss decreased (0.149134 --> 0.148954).  Saving model ...
	 Train_Loss: 0.2062 Train_Acc: 91.794 Val_Loss: 0.1490  BEST VAL Loss: 0.1490  Val_Acc: 94.762

Epoch 69: Validation loss decreased (0.148954 --> 0.148792).  Saving model ...
	 Train_Loss: 0.2060 Train_Acc: 91.866 Val_Loss: 0.1488  BEST VAL Loss: 0.1488  Val_Acc: 94.604

Epoch 70: Validation loss decreased (0.148792 --> 0.148644).  Saving model ...
	 Train_Loss: 0.2058 Train_Acc: 91.797 Val_Loss: 0.1486  BEST VAL Loss: 0.1486  Val_Acc: 94.475

Epoch 71: Validation loss decreased (0.148644 --> 0.148510).  Saving model ...
	 Train_Loss: 0.2056 Train_Acc: 91.837 Val_Loss: 0.1485  BEST VAL Loss: 0.1485  Val_Acc: 94.516

Epoch 72: Validation loss decreased (0.148510 --> 0.148323).  Saving model ...
	 Train_Loss: 0.2054 Train_Acc: 91.801 Val_Loss: 0.1483  BEST VAL Loss: 0.1483  Val_Acc: 94.666

Epoch 73: Validation loss decreased (0.148323 --> 0.148180).  Saving model ...
	 Train_Loss: 0.2053 Train_Acc: 91.819 Val_Loss: 0.1482  BEST VAL Loss: 0.1482  Val_Acc: 94.633

Epoch 74: Validation loss decreased (0.148180 --> 0.148026).  Saving model ...
	 Train_Loss: 0.2051 Train_Acc: 91.789 Val_Loss: 0.1480  BEST VAL Loss: 0.1480  Val_Acc: 94.704

Epoch 75: Validation loss decreased (0.148026 --> 0.147863).  Saving model ...
	 Train_Loss: 0.2049 Train_Acc: 91.892 Val_Loss: 0.1479  BEST VAL Loss: 0.1479  Val_Acc: 94.662

Epoch 76: Validation loss decreased (0.147863 --> 0.147725).  Saving model ...
	 Train_Loss: 0.2047 Train_Acc: 91.925 Val_Loss: 0.1477  BEST VAL Loss: 0.1477  Val_Acc: 94.637

Epoch 77: Validation loss decreased (0.147725 --> 0.147552).  Saving model ...
	 Train_Loss: 0.2046 Train_Acc: 91.797 Val_Loss: 0.1476  BEST VAL Loss: 0.1476  Val_Acc: 94.795

Epoch 78: Validation loss decreased (0.147552 --> 0.147397).  Saving model ...
	 Train_Loss: 0.2044 Train_Acc: 91.899 Val_Loss: 0.1474  BEST VAL Loss: 0.1474  Val_Acc: 94.745

Epoch 79: Validation loss decreased (0.147397 --> 0.147271).  Saving model ...
	 Train_Loss: 0.2042 Train_Acc: 91.835 Val_Loss: 0.1473  BEST VAL Loss: 0.1473  Val_Acc: 94.620

Epoch 80: Validation loss decreased (0.147271 --> 0.147119).  Saving model ...
	 Train_Loss: 0.2041 Train_Acc: 91.898 Val_Loss: 0.1471  BEST VAL Loss: 0.1471  Val_Acc: 94.712

Epoch 81: Validation loss decreased (0.147119 --> 0.146980).  Saving model ...
	 Train_Loss: 0.2039 Train_Acc: 91.915 Val_Loss: 0.1470  BEST VAL Loss: 0.1470  Val_Acc: 94.699

Epoch 82: Validation loss decreased (0.146980 --> 0.146812).  Saving model ...
	 Train_Loss: 0.2038 Train_Acc: 91.837 Val_Loss: 0.1468  BEST VAL Loss: 0.1468  Val_Acc: 94.758

Epoch 83: Validation loss decreased (0.146812 --> 0.146756).  Saving model ...
	 Train_Loss: 0.2036 Train_Acc: 91.882 Val_Loss: 0.1468  BEST VAL Loss: 0.1468  Val_Acc: 94.358

Epoch 84: Validation loss decreased (0.146756 --> 0.146611).  Saving model ...
	 Train_Loss: 0.2035 Train_Acc: 91.817 Val_Loss: 0.1466  BEST VAL Loss: 0.1466  Val_Acc: 94.849

Epoch 85: Validation loss decreased (0.146611 --> 0.146445).  Saving model ...
	 Train_Loss: 0.2033 Train_Acc: 91.881 Val_Loss: 0.1464  BEST VAL Loss: 0.1464  Val_Acc: 94.762

Epoch 86: Validation loss decreased (0.146445 --> 0.146316).  Saving model ...
	 Train_Loss: 0.2032 Train_Acc: 91.970 Val_Loss: 0.1463  BEST VAL Loss: 0.1463  Val_Acc: 94.766

Epoch 87: Validation loss decreased (0.146316 --> 0.146241).  Saving model ...
	 Train_Loss: 0.2030 Train_Acc: 91.882 Val_Loss: 0.1462  BEST VAL Loss: 0.1462  Val_Acc: 94.524

Epoch 88: Validation loss decreased (0.146241 --> 0.146081).  Saving model ...
	 Train_Loss: 0.2029 Train_Acc: 91.849 Val_Loss: 0.1461  BEST VAL Loss: 0.1461  Val_Acc: 94.858

Epoch 89: Validation loss decreased (0.146081 --> 0.145994).  Saving model ...
	 Train_Loss: 0.2027 Train_Acc: 91.934 Val_Loss: 0.1460  BEST VAL Loss: 0.1460  Val_Acc: 94.599

Epoch 90: Validation loss decreased (0.145994 --> 0.145840).  Saving model ...
	 Train_Loss: 0.2026 Train_Acc: 91.880 Val_Loss: 0.1458  BEST VAL Loss: 0.1458  Val_Acc: 94.949

Epoch 91: Validation loss decreased (0.145840 --> 0.145713).  Saving model ...
	 Train_Loss: 0.2024 Train_Acc: 91.932 Val_Loss: 0.1457  BEST VAL Loss: 0.1457  Val_Acc: 94.649

Epoch 92: Validation loss decreased (0.145713 --> 0.145627).  Saving model ...
	 Train_Loss: 0.2023 Train_Acc: 91.972 Val_Loss: 0.1456  BEST VAL Loss: 0.1456  Val_Acc: 94.666

Epoch 93: Validation loss decreased (0.145627 --> 0.145478).  Saving model ...
	 Train_Loss: 0.2022 Train_Acc: 91.923 Val_Loss: 0.1455  BEST VAL Loss: 0.1455  Val_Acc: 94.862

Epoch 94: Validation loss decreased (0.145478 --> 0.145368).  Saving model ...
	 Train_Loss: 0.2021 Train_Acc: 91.858 Val_Loss: 0.1454  BEST VAL Loss: 0.1454  Val_Acc: 94.812

Epoch 95: Validation loss decreased (0.145368 --> 0.145285).  Saving model ...
	 Train_Loss: 0.2019 Train_Acc: 91.971 Val_Loss: 0.1453  BEST VAL Loss: 0.1453  Val_Acc: 94.745

Epoch 96: Validation loss decreased (0.145285 --> 0.145157).  Saving model ...
	 Train_Loss: 0.2018 Train_Acc: 91.931 Val_Loss: 0.1452  BEST VAL Loss: 0.1452  Val_Acc: 94.716

Epoch 97: Validation loss decreased (0.145157 --> 0.145046).  Saving model ...
	 Train_Loss: 0.2017 Train_Acc: 92.007 Val_Loss: 0.1450  BEST VAL Loss: 0.1450  Val_Acc: 94.741

Epoch 98: Validation loss decreased (0.145046 --> 0.144939).  Saving model ...
	 Train_Loss: 0.2016 Train_Acc: 91.962 Val_Loss: 0.1449  BEST VAL Loss: 0.1449  Val_Acc: 94.666

Epoch 99: Validation loss decreased (0.144939 --> 0.144811).  Saving model ...
	 Train_Loss: 0.2014 Train_Acc: 91.990 Val_Loss: 0.1448  BEST VAL Loss: 0.1448  Val_Acc: 94.791

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.94      0.96      0.95     82898
           1       0.97      0.95      0.96    109228

    accuracy                           0.96    192126
   macro avg       0.95      0.96      0.95    192126
weighted avg       0.96      0.96      0.96    192126

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.95      0.94     10362
           1       0.96      0.95      0.95     13654

    accuracy                           0.95     24016
   macro avg       0.95      0.95      0.95     24016
weighted avg       0.95      0.95      0.95     24016

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.95      0.94     10362
           1       0.96      0.95      0.96     13654

    accuracy                           0.95     24016
   macro avg       0.95      0.95      0.95     24016
weighted avg       0.95      0.95      0.95     24016

              precision    recall  f1-score   support

           0       0.93      0.95      0.94     10362
           1       0.96      0.95      0.96     13654

    accuracy                           0.95     24016
   macro avg       0.95      0.95      0.95     24016
weighted avg       0.95      0.95      0.95     24016

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.28      0.43     35811
           1       0.59      0.99      0.74     37725

    accuracy                           0.64     73536
   macro avg       0.78      0.63      0.59     73536
weighted avg       0.77      0.64      0.59     73536

              precision    recall  f1-score   support

           0       0.97      0.28      0.43     35811
           1       0.59      0.99      0.74     37725

    accuracy                           0.64     73536
   macro avg       0.78      0.63      0.59     73536
weighted avg       0.77      0.64      0.59     73536

completed
