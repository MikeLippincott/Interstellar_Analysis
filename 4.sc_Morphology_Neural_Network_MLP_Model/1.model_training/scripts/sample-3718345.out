[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 18688 bytes to train_binary_model.py
[NbConvertApp] Converting notebook ../notebooks/train_multiclass_model.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: MissingIDFieldWarning: Code cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.
  validate(nb)
[NbConvertApp] Writing 31106 bytes to train_multiclass_model.py
[NbConvertApp] Converting notebook ../notebooks/train_regression_model.ipynb to script
[NbConvertApp] Writing 25120 bytes to train_regression_model.py
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:313: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels.drop_duplicates(inplace=True)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1015: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1016: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1015: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1016: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1036: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:577: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:651: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1219: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:879: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1219: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:1095: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
PBMC MultiClass_MLP_h202_remove True
[0.9436581681188537, 0.5245113046249099, 0.5318305272562364]
Data Subset Is Off
(1417094,) (354274,) (2112741,) (1474037,)
(1417094,) (354274,) (2112741,) (1474037,)
5358146
(95929,) (683836,) (637329,)
(23982,) (170959,) (159333,)
(119910,) (854797,) (1138034,)
(75619,) (711982,) (686436,)
(1417094, 1245) (354274, 1245) (2112741, 1245) (1474037, 1245)
(1417094,) (354274,) (2112741,) (1474037,)
Number of in features:  1245
Number of out features:  3
Multi_Class
Adam
Epoch 0: Validation loss decreased (inf --> 0.635657).  Saving model ...
	 Train_Loss: 0.7108 Train_Acc: 70.091 Val_Loss: 0.6357  BEST VAL Loss: 0.6357  Val_Acc: 73.971

Epoch 1: Validation loss decreased (0.635657 --> 0.621516).  Saving model ...
	 Train_Loss: 0.6856 Train_Acc: 72.498 Val_Loss: 0.6215  BEST VAL Loss: 0.6215  Val_Acc: 75.443

Epoch 2: Validation loss decreased (0.621516 --> 0.612241).  Saving model ...
	 Train_Loss: 0.6701 Train_Acc: 73.448 Val_Loss: 0.6122  BEST VAL Loss: 0.6122  Val_Acc: 75.527

Epoch 3: Validation loss decreased (0.612241 --> 0.604496).  Saving model ...
	 Train_Loss: 0.6594 Train_Acc: 74.052 Val_Loss: 0.6045  BEST VAL Loss: 0.6045  Val_Acc: 76.592

Epoch 4: Validation loss decreased (0.604496 --> 0.597920).  Saving model ...
	 Train_Loss: 0.6511 Train_Acc: 74.421 Val_Loss: 0.5979  BEST VAL Loss: 0.5979  Val_Acc: 77.112

Epoch 5: Validation loss decreased (0.597920 --> 0.591999).  Saving model ...
	 Train_Loss: 0.6442 Train_Acc: 74.781 Val_Loss: 0.5920  BEST VAL Loss: 0.5920  Val_Acc: 77.421

Epoch 6: Validation loss decreased (0.591999 --> 0.586364).  Saving model ...
	 Train_Loss: 0.6386 Train_Acc: 75.005 Val_Loss: 0.5864  BEST VAL Loss: 0.5864  Val_Acc: 77.495

Epoch 7: Validation loss decreased (0.586364 --> 0.581559).  Saving model ...
	 Train_Loss: 0.6338 Train_Acc: 75.185 Val_Loss: 0.5816  BEST VAL Loss: 0.5816  Val_Acc: 77.957

Epoch 8: Validation loss decreased (0.581559 --> 0.577944).  Saving model ...
	 Train_Loss: 0.6297 Train_Acc: 75.397 Val_Loss: 0.5779  BEST VAL Loss: 0.5779  Val_Acc: 77.908

Epoch 9: Validation loss decreased (0.577944 --> 0.574787).  Saving model ...
	 Train_Loss: 0.6261 Train_Acc: 75.561 Val_Loss: 0.5748  BEST VAL Loss: 0.5748  Val_Acc: 78.086

Epoch 10: Validation loss decreased (0.574787 --> 0.572007).  Saving model ...
	 Train_Loss: 0.6227 Train_Acc: 75.682 Val_Loss: 0.5720  BEST VAL Loss: 0.5720  Val_Acc: 78.295

Epoch 11: Validation loss decreased (0.572007 --> 0.569071).  Saving model ...
	 Train_Loss: 0.6198 Train_Acc: 75.781 Val_Loss: 0.5691  BEST VAL Loss: 0.5691  Val_Acc: 78.648

Epoch 12: Validation loss decreased (0.569071 --> 0.566179).  Saving model ...
	 Train_Loss: 0.6171 Train_Acc: 75.807 Val_Loss: 0.5662  BEST VAL Loss: 0.5662  Val_Acc: 78.574

Epoch 13: Validation loss decreased (0.566179 --> 0.564145).  Saving model ...
	 Train_Loss: 0.6147 Train_Acc: 75.989 Val_Loss: 0.5641  BEST VAL Loss: 0.5641  Val_Acc: 78.630

Epoch 14: Validation loss decreased (0.564145 --> 0.561585).  Saving model ...
	 Train_Loss: 0.6125 Train_Acc: 76.047 Val_Loss: 0.5616  BEST VAL Loss: 0.5616  Val_Acc: 78.867

Epoch 15: Validation loss decreased (0.561585 --> 0.559543).  Saving model ...
	 Train_Loss: 0.6104 Train_Acc: 76.128 Val_Loss: 0.5595  BEST VAL Loss: 0.5595  Val_Acc: 78.775

Epoch 16: Validation loss decreased (0.559543 --> 0.557567).  Saving model ...
	 Train_Loss: 0.6085 Train_Acc: 76.158 Val_Loss: 0.5576  BEST VAL Loss: 0.5576  Val_Acc: 78.928

Epoch 17: Validation loss decreased (0.557567 --> 0.555424).  Saving model ...
	 Train_Loss: 0.6068 Train_Acc: 76.251 Val_Loss: 0.5554  BEST VAL Loss: 0.5554  Val_Acc: 79.048

Epoch 18: Validation loss decreased (0.555424 --> 0.553632).  Saving model ...
	 Train_Loss: 0.6051 Train_Acc: 76.294 Val_Loss: 0.5536  BEST VAL Loss: 0.5536  Val_Acc: 78.903

Epoch 19: Validation loss decreased (0.553632 --> 0.552125).  Saving model ...
	 Train_Loss: 0.6035 Train_Acc: 76.382 Val_Loss: 0.5521  BEST VAL Loss: 0.5521  Val_Acc: 78.569

Epoch 20: Validation loss decreased (0.552125 --> 0.550547).  Saving model ...
	 Train_Loss: 0.6021 Train_Acc: 76.401 Val_Loss: 0.5505  BEST VAL Loss: 0.5505  Val_Acc: 79.279

Epoch 21: Validation loss decreased (0.550547 --> 0.549101).  Saving model ...
	 Train_Loss: 0.6007 Train_Acc: 76.454 Val_Loss: 0.5491  BEST VAL Loss: 0.5491  Val_Acc: 79.076

Epoch 22: Validation loss decreased (0.549101 --> 0.547798).  Saving model ...
	 Train_Loss: 0.5994 Train_Acc: 76.568 Val_Loss: 0.5478  BEST VAL Loss: 0.5478  Val_Acc: 79.295

Epoch 23: Validation loss decreased (0.547798 --> 0.546604).  Saving model ...
	 Train_Loss: 0.5982 Train_Acc: 76.499 Val_Loss: 0.5466  BEST VAL Loss: 0.5466  Val_Acc: 79.434

Epoch 24: Validation loss decreased (0.546604 --> 0.545397).  Saving model ...
	 Train_Loss: 0.5970 Train_Acc: 76.636 Val_Loss: 0.5454  BEST VAL Loss: 0.5454  Val_Acc: 79.379

Epoch 25: Validation loss decreased (0.545397 --> 0.544527).  Saving model ...
	 Train_Loss: 0.5959 Train_Acc: 76.621 Val_Loss: 0.5445  BEST VAL Loss: 0.5445  Val_Acc: 79.137

Epoch 26: Validation loss decreased (0.544527 --> 0.543453).  Saving model ...
	 Train_Loss: 0.5948 Train_Acc: 76.687 Val_Loss: 0.5435  BEST VAL Loss: 0.5435  Val_Acc: 79.479

Epoch 27: Validation loss decreased (0.543453 --> 0.542466).  Saving model ...
	 Train_Loss: 0.5938 Train_Acc: 76.696 Val_Loss: 0.5425  BEST VAL Loss: 0.5425  Val_Acc: 79.300

Epoch 28: Validation loss decreased (0.542466 --> 0.541533).  Saving model ...
	 Train_Loss: 0.5928 Train_Acc: 76.737 Val_Loss: 0.5415  BEST VAL Loss: 0.5415  Val_Acc: 79.348

Epoch 29: Validation loss decreased (0.541533 --> 0.540737).  Saving model ...
	 Train_Loss: 0.5919 Train_Acc: 76.713 Val_Loss: 0.5407  BEST VAL Loss: 0.5407  Val_Acc: 79.342

Epoch 30: Validation loss decreased (0.540737 --> 0.539750).  Saving model ...
	 Train_Loss: 0.5910 Train_Acc: 76.770 Val_Loss: 0.5397  BEST VAL Loss: 0.5397  Val_Acc: 79.680

Epoch 31: Validation loss decreased (0.539750 --> 0.538828).  Saving model ...
	 Train_Loss: 0.5902 Train_Acc: 76.809 Val_Loss: 0.5388  BEST VAL Loss: 0.5388  Val_Acc: 79.812

Epoch 32: Validation loss decreased (0.538828 --> 0.538004).  Saving model ...
	 Train_Loss: 0.5894 Train_Acc: 76.797 Val_Loss: 0.5380  BEST VAL Loss: 0.5380  Val_Acc: 79.733

Epoch 33: Validation loss decreased (0.538004 --> 0.537171).  Saving model ...
	 Train_Loss: 0.5886 Train_Acc: 76.880 Val_Loss: 0.5372  BEST VAL Loss: 0.5372  Val_Acc: 79.844

Epoch 34: Validation loss decreased (0.537171 --> 0.536492).  Saving model ...
	 Train_Loss: 0.5878 Train_Acc: 76.862 Val_Loss: 0.5365  BEST VAL Loss: 0.5365  Val_Acc: 79.779

Epoch 35: Validation loss decreased (0.536492 --> 0.535791).  Saving model ...
	 Train_Loss: 0.5870 Train_Acc: 76.964 Val_Loss: 0.5358  BEST VAL Loss: 0.5358  Val_Acc: 79.552

Epoch 36: Validation loss decreased (0.535791 --> 0.535034).  Saving model ...
	 Train_Loss: 0.5863 Train_Acc: 76.938 Val_Loss: 0.5350  BEST VAL Loss: 0.5350  Val_Acc: 79.958

Epoch 37: Validation loss decreased (0.535034 --> 0.534378).  Saving model ...
	 Train_Loss: 0.5856 Train_Acc: 76.972 Val_Loss: 0.5344  BEST VAL Loss: 0.5344  Val_Acc: 79.792

Epoch 38: Validation loss decreased (0.534378 --> 0.533700).  Saving model ...
	 Train_Loss: 0.5850 Train_Acc: 76.982 Val_Loss: 0.5337  BEST VAL Loss: 0.5337  Val_Acc: 79.611

Epoch 39: Validation loss decreased (0.533700 --> 0.533038).  Saving model ...
	 Train_Loss: 0.5843 Train_Acc: 77.027 Val_Loss: 0.5330  BEST VAL Loss: 0.5330  Val_Acc: 79.793

Epoch 40: Validation loss decreased (0.533038 --> 0.532599).  Saving model ...
	 Train_Loss: 0.5837 Train_Acc: 77.002 Val_Loss: 0.5326  BEST VAL Loss: 0.5326  Val_Acc: 79.338

Epoch 41: Validation loss decreased (0.532599 --> 0.532041).  Saving model ...
	 Train_Loss: 0.5831 Train_Acc: 77.043 Val_Loss: 0.5320  BEST VAL Loss: 0.5320  Val_Acc: 79.839

Epoch 42: Validation loss decreased (0.532041 --> 0.531400).  Saving model ...
	 Train_Loss: 0.5825 Train_Acc: 77.091 Val_Loss: 0.5314  BEST VAL Loss: 0.5314  Val_Acc: 79.768

Epoch 43: Validation loss decreased (0.531400 --> 0.530853).  Saving model ...
	 Train_Loss: 0.5820 Train_Acc: 77.093 Val_Loss: 0.5309  BEST VAL Loss: 0.5309  Val_Acc: 79.784

Epoch 44: Validation loss decreased (0.530853 --> 0.530301).  Saving model ...
	 Train_Loss: 0.5814 Train_Acc: 77.091 Val_Loss: 0.5303  BEST VAL Loss: 0.5303  Val_Acc: 79.792

Epoch 45: Validation loss decreased (0.530301 --> 0.529854).  Saving model ...
	 Train_Loss: 0.5809 Train_Acc: 77.059 Val_Loss: 0.5299  BEST VAL Loss: 0.5299  Val_Acc: 79.738

Epoch 46: Validation loss decreased (0.529854 --> 0.529338).  Saving model ...
	 Train_Loss: 0.5804 Train_Acc: 77.142 Val_Loss: 0.5293  BEST VAL Loss: 0.5293  Val_Acc: 79.559

Epoch 47: Validation loss decreased (0.529338 --> 0.528818).  Saving model ...
	 Train_Loss: 0.5799 Train_Acc: 77.136 Val_Loss: 0.5288  BEST VAL Loss: 0.5288  Val_Acc: 79.887

Epoch 48: Validation loss decreased (0.528818 --> 0.528219).  Saving model ...
	 Train_Loss: 0.5794 Train_Acc: 77.164 Val_Loss: 0.5282  BEST VAL Loss: 0.5282  Val_Acc: 80.028

Epoch 49: Validation loss decreased (0.528219 --> 0.527733).  Saving model ...
	 Train_Loss: 0.5789 Train_Acc: 77.215 Val_Loss: 0.5277  BEST VAL Loss: 0.5277  Val_Acc: 79.774

Epoch 50: Validation loss decreased (0.527733 --> 0.527241).  Saving model ...
	 Train_Loss: 0.5784 Train_Acc: 77.195 Val_Loss: 0.5272  BEST VAL Loss: 0.5272  Val_Acc: 80.078

Epoch 51: Validation loss decreased (0.527241 --> 0.526783).  Saving model ...
	 Train_Loss: 0.5779 Train_Acc: 77.188 Val_Loss: 0.5268  BEST VAL Loss: 0.5268  Val_Acc: 79.813

Epoch 52: Validation loss decreased (0.526783 --> 0.526275).  Saving model ...
	 Train_Loss: 0.5775 Train_Acc: 77.251 Val_Loss: 0.5263  BEST VAL Loss: 0.5263  Val_Acc: 80.024

Epoch 53: Validation loss decreased (0.526275 --> 0.525931).  Saving model ...
	 Train_Loss: 0.5770 Train_Acc: 77.234 Val_Loss: 0.5259  BEST VAL Loss: 0.5259  Val_Acc: 79.955

Epoch 54: Validation loss decreased (0.525931 --> 0.525474).  Saving model ...
	 Train_Loss: 0.5766 Train_Acc: 77.295 Val_Loss: 0.5255  BEST VAL Loss: 0.5255  Val_Acc: 80.022

Epoch 55: Validation loss decreased (0.525474 --> 0.525078).  Saving model ...
	 Train_Loss: 0.5762 Train_Acc: 77.300 Val_Loss: 0.5251  BEST VAL Loss: 0.5251  Val_Acc: 80.010

Epoch 56: Validation loss decreased (0.525078 --> 0.524613).  Saving model ...
	 Train_Loss: 0.5758 Train_Acc: 77.334 Val_Loss: 0.5246  BEST VAL Loss: 0.5246  Val_Acc: 80.063

Epoch 57: Validation loss decreased (0.524613 --> 0.524136).  Saving model ...
	 Train_Loss: 0.5754 Train_Acc: 77.258 Val_Loss: 0.5241  BEST VAL Loss: 0.5241  Val_Acc: 80.000

Epoch 58: Validation loss decreased (0.524136 --> 0.523686).  Saving model ...
	 Train_Loss: 0.5750 Train_Acc: 77.302 Val_Loss: 0.5237  BEST VAL Loss: 0.5237  Val_Acc: 80.034

Epoch 59: Validation loss decreased (0.523686 --> 0.523289).  Saving model ...
	 Train_Loss: 0.5746 Train_Acc: 77.296 Val_Loss: 0.5233  BEST VAL Loss: 0.5233  Val_Acc: 80.207

Epoch 60: Validation loss decreased (0.523289 --> 0.522824).  Saving model ...
	 Train_Loss: 0.5742 Train_Acc: 77.350 Val_Loss: 0.5228  BEST VAL Loss: 0.5228  Val_Acc: 80.300

Epoch 61: Validation loss decreased (0.522824 --> 0.522523).  Saving model ...
	 Train_Loss: 0.5739 Train_Acc: 77.323 Val_Loss: 0.5225  BEST VAL Loss: 0.5225  Val_Acc: 80.150

Epoch 62: Validation loss decreased (0.522523 --> 0.522183).  Saving model ...
	 Train_Loss: 0.5735 Train_Acc: 77.348 Val_Loss: 0.5222  BEST VAL Loss: 0.5222  Val_Acc: 80.319

Epoch 63: Validation loss decreased (0.522183 --> 0.521799).  Saving model ...
	 Train_Loss: 0.5731 Train_Acc: 77.368 Val_Loss: 0.5218  BEST VAL Loss: 0.5218  Val_Acc: 79.942

Epoch 64: Validation loss decreased (0.521799 --> 0.521435).  Saving model ...
	 Train_Loss: 0.5728 Train_Acc: 77.344 Val_Loss: 0.5214  BEST VAL Loss: 0.5214  Val_Acc: 80.246

Epoch 65: Validation loss decreased (0.521435 --> 0.521192).  Saving model ...
	 Train_Loss: 0.5725 Train_Acc: 77.385 Val_Loss: 0.5212  BEST VAL Loss: 0.5212  Val_Acc: 80.001

Epoch 66: Validation loss decreased (0.521192 --> 0.520850).  Saving model ...
	 Train_Loss: 0.5721 Train_Acc: 77.464 Val_Loss: 0.5208  BEST VAL Loss: 0.5208  Val_Acc: 80.130

Epoch 67: Validation loss decreased (0.520850 --> 0.520508).  Saving model ...
	 Train_Loss: 0.5718 Train_Acc: 77.406 Val_Loss: 0.5205  BEST VAL Loss: 0.5205  Val_Acc: 80.074

Epoch 68: Validation loss decreased (0.520508 --> 0.520149).  Saving model ...
	 Train_Loss: 0.5715 Train_Acc: 77.454 Val_Loss: 0.5201  BEST VAL Loss: 0.5201  Val_Acc: 80.162

Epoch 69: Validation loss decreased (0.520149 --> 0.519836).  Saving model ...
	 Train_Loss: 0.5712 Train_Acc: 77.419 Val_Loss: 0.5198  BEST VAL Loss: 0.5198  Val_Acc: 80.128

Epoch 70: Validation loss decreased (0.519836 --> 0.519537).  Saving model ...
	 Train_Loss: 0.5709 Train_Acc: 77.401 Val_Loss: 0.5195  BEST VAL Loss: 0.5195  Val_Acc: 80.254

Epoch 71: Validation loss decreased (0.519537 --> 0.519205).  Saving model ...
	 Train_Loss: 0.5706 Train_Acc: 77.445 Val_Loss: 0.5192  BEST VAL Loss: 0.5192  Val_Acc: 80.340

Epoch 72: Validation loss decreased (0.519205 --> 0.518837).  Saving model ...
	 Train_Loss: 0.5703 Train_Acc: 77.434 Val_Loss: 0.5188  BEST VAL Loss: 0.5188  Val_Acc: 80.294

Epoch 73: Validation loss decreased (0.518837 --> 0.518557).  Saving model ...
	 Train_Loss: 0.5700 Train_Acc: 77.510 Val_Loss: 0.5186  BEST VAL Loss: 0.5186  Val_Acc: 80.418

Epoch 74: Validation loss decreased (0.518557 --> 0.518249).  Saving model ...
	 Train_Loss: 0.5697 Train_Acc: 77.496 Val_Loss: 0.5182  BEST VAL Loss: 0.5182  Val_Acc: 80.372

Epoch 75: Validation loss decreased (0.518249 --> 0.517989).  Saving model ...
	 Train_Loss: 0.5694 Train_Acc: 77.503 Val_Loss: 0.5180  BEST VAL Loss: 0.5180  Val_Acc: 80.401

Epoch 76: Validation loss decreased (0.517989 --> 0.517658).  Saving model ...
	 Train_Loss: 0.5691 Train_Acc: 77.514 Val_Loss: 0.5177  BEST VAL Loss: 0.5177  Val_Acc: 80.396

Epoch 77: Validation loss decreased (0.517658 --> 0.517357).  Saving model ...
	 Train_Loss: 0.5688 Train_Acc: 77.495 Val_Loss: 0.5174  BEST VAL Loss: 0.5174  Val_Acc: 80.489

Epoch 78: Validation loss decreased (0.517357 --> 0.517119).  Saving model ...
	 Train_Loss: 0.5686 Train_Acc: 77.529 Val_Loss: 0.5171  BEST VAL Loss: 0.5171  Val_Acc: 80.313

Epoch 79: Validation loss decreased (0.517119 --> 0.516891).  Saving model ...
	 Train_Loss: 0.5683 Train_Acc: 77.510 Val_Loss: 0.5169  BEST VAL Loss: 0.5169  Val_Acc: 80.025

Epoch 80: Validation loss decreased (0.516891 --> 0.516667).  Saving model ...
	 Train_Loss: 0.5681 Train_Acc: 77.500 Val_Loss: 0.5167  BEST VAL Loss: 0.5167  Val_Acc: 80.166

Epoch 81: Validation loss decreased (0.516667 --> 0.516408).  Saving model ...
	 Train_Loss: 0.5678 Train_Acc: 77.551 Val_Loss: 0.5164  BEST VAL Loss: 0.5164  Val_Acc: 80.076

Epoch 82: Validation loss decreased (0.516408 --> 0.516115).  Saving model ...
	 Train_Loss: 0.5675 Train_Acc: 77.532 Val_Loss: 0.5161  BEST VAL Loss: 0.5161  Val_Acc: 80.377

Epoch 83: Validation loss decreased (0.516115 --> 0.515828).  Saving model ...
	 Train_Loss: 0.5673 Train_Acc: 77.579 Val_Loss: 0.5158  BEST VAL Loss: 0.5158  Val_Acc: 80.426

Epoch 84: Validation loss decreased (0.515828 --> 0.515553).  Saving model ...
	 Train_Loss: 0.5671 Train_Acc: 77.543 Val_Loss: 0.5156  BEST VAL Loss: 0.5156  Val_Acc: 80.327

Epoch 85: Validation loss decreased (0.515553 --> 0.515332).  Saving model ...
	 Train_Loss: 0.5668 Train_Acc: 77.550 Val_Loss: 0.5153  BEST VAL Loss: 0.5153  Val_Acc: 80.058

Epoch 86: Validation loss decreased (0.515332 --> 0.515108).  Saving model ...
	 Train_Loss: 0.5666 Train_Acc: 77.590 Val_Loss: 0.5151  BEST VAL Loss: 0.5151  Val_Acc: 80.306

Epoch 87: Validation loss decreased (0.515108 --> 0.514893).  Saving model ...
	 Train_Loss: 0.5664 Train_Acc: 77.486 Val_Loss: 0.5149  BEST VAL Loss: 0.5149  Val_Acc: 80.425

Epoch 88: Validation loss decreased (0.514893 --> 0.514688).  Saving model ...
	 Train_Loss: 0.5661 Train_Acc: 77.597 Val_Loss: 0.5147  BEST VAL Loss: 0.5147  Val_Acc: 80.308

Epoch 89: Validation loss decreased (0.514688 --> 0.514452).  Saving model ...
	 Train_Loss: 0.5659 Train_Acc: 77.587 Val_Loss: 0.5145  BEST VAL Loss: 0.5145  Val_Acc: 80.454

Epoch 90: Validation loss decreased (0.514452 --> 0.514219).  Saving model ...
	 Train_Loss: 0.5657 Train_Acc: 77.633 Val_Loss: 0.5142  BEST VAL Loss: 0.5142  Val_Acc: 80.372

Epoch 91: Validation loss decreased (0.514219 --> 0.513985).  Saving model ...
	 Train_Loss: 0.5655 Train_Acc: 77.560 Val_Loss: 0.5140  BEST VAL Loss: 0.5140  Val_Acc: 80.453

Epoch 92: Validation loss decreased (0.513985 --> 0.513736).  Saving model ...
	 Train_Loss: 0.5653 Train_Acc: 77.602 Val_Loss: 0.5137  BEST VAL Loss: 0.5137  Val_Acc: 80.279

Epoch 93: Validation loss decreased (0.513736 --> 0.513543).  Saving model ...
	 Train_Loss: 0.5650 Train_Acc: 77.634 Val_Loss: 0.5135  BEST VAL Loss: 0.5135  Val_Acc: 80.262

Epoch 94: Validation loss decreased (0.513543 --> 0.513303).  Saving model ...
	 Train_Loss: 0.5648 Train_Acc: 77.583 Val_Loss: 0.5133  BEST VAL Loss: 0.5133  Val_Acc: 80.511

Epoch 95: Validation loss decreased (0.513303 --> 0.513102).  Saving model ...
	 Train_Loss: 0.5646 Train_Acc: 77.618 Val_Loss: 0.5131  BEST VAL Loss: 0.5131  Val_Acc: 80.471

Epoch 96: Validation loss decreased (0.513102 --> 0.512905).  Saving model ...
	 Train_Loss: 0.5644 Train_Acc: 77.570 Val_Loss: 0.5129  BEST VAL Loss: 0.5129  Val_Acc: 80.225

Epoch 97: Validation loss decreased (0.512905 --> 0.512771).  Saving model ...
	 Train_Loss: 0.5642 Train_Acc: 77.656 Val_Loss: 0.5128  BEST VAL Loss: 0.5128  Val_Acc: 80.224

Epoch 98: Validation loss decreased (0.512771 --> 0.512566).  Saving model ...
	 Train_Loss: 0.5640 Train_Acc: 77.632 Val_Loss: 0.5126  BEST VAL Loss: 0.5126  Val_Acc: 80.531

Epoch 99: Validation loss decreased (0.512566 --> 0.512366).  Saving model ...
	 Train_Loss: 0.5638 Train_Acc: 77.653 Val_Loss: 0.5124  BEST VAL Loss: 0.5124  Val_Acc: 80.181

MultiClass_MLP_h202_remove_shuffle
              precision    recall  f1-score   support

           0       0.07      0.07      0.07     95929
           1       0.48      0.51      0.50    683836
           2       0.45      0.42      0.43    637329

    accuracy                           0.44   1417094
   macro avg       0.33      0.33      0.33   1417094
weighted avg       0.44      0.44      0.44   1417094

MultiClass_MLP_h202_remove_shuffle
              precision    recall  f1-score   support

           0       0.07      0.07      0.07     23982
           1       0.48      0.51      0.50    170959
           2       0.45      0.42      0.44    159333

    accuracy                           0.44    354274
   macro avg       0.33      0.33      0.33    354274
weighted avg       0.44      0.44      0.44    354274

MultiClass_MLP_h202_remove_shuffle
              precision    recall  f1-score   support

           0       0.06      0.06      0.06    119910
           1       0.40      0.45      0.43    854797
           2       0.54      0.48      0.51   1138034

    accuracy                           0.45   2112741
   macro avg       0.33      0.33      0.33   2112741
weighted avg       0.46      0.45      0.45   2112741

Precision for class 0: 0.05610014820610429
Recall for class 0: 0.06218830789758986
Precision for class 1: 0.40406610143940613
Recall for class 1: 0.4546728638495456
Precision for class 2: 0.5381079665960354
Recall for class 2: 0.4813335981174552
3
              precision    recall  f1-score   support

           0       0.06      0.06      0.06    119910
           1       0.40      0.45      0.43    854797
           2       0.54      0.48      0.51   1138034

    accuracy                           0.45   2112741
   macro avg       0.33      0.33      0.33   2112741
weighted avg       0.46      0.45      0.45   2112741

MultiClass_MLP_h202_remove_shuffle
              precision    recall  f1-score   support

           0       0.05      0.04      0.04     75619
           1       0.48      0.48      0.48    711982
           2       0.47      0.48      0.47    686436

    accuracy                           0.46   1474037
   macro avg       0.33      0.33      0.33   1474037
weighted avg       0.45      0.46      0.46   1474037

Precision for class 0: 0.051250048004915706
Recall for class 0: 0.0352953622766765
Precision for class 1: 0.4828628129338529
Recall for class 1: 0.484589498049108
Precision for class 2: 0.4653499775949881
Recall for class 2: 0.4795829472813197
3
              precision    recall  f1-score   support

           0       0.05      0.04      0.04     75619
           1       0.48      0.48      0.48    711982
           2       0.47      0.48      0.47    686436

    accuracy                           0.46   1474037
   macro avg       0.33      0.33      0.33   1474037
weighted avg       0.45      0.46      0.46   1474037

Done
