[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'bdb950ee'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e858ff19'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '9de6afb6'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '92de4ad4'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (317341, 1270)
Number of total missing values across all columns: 286160
Data Subset Is Off
Wells held out for testing: ['B09' 'L09']
Wells to use for training, validation, and testing ['B02' 'B03' 'B08' 'L02' 'L03' 'L08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.260347).  Saving model ...
	 Train_Loss: 0.3780 Train_Acc: 83.191 Val_Loss: 0.2603  BEST VAL Loss: 0.2603  Val_Acc: 89.603

Epoch 1: Validation loss decreased (0.260347 --> 0.235556).  Saving model ...
	 Train_Loss: 0.3269 Train_Acc: 89.287 Val_Loss: 0.2356  BEST VAL Loss: 0.2356  Val_Acc: 91.708

Epoch 2: Validation loss decreased (0.235556 --> 0.219647).  Saving model ...
	 Train_Loss: 0.2989 Train_Acc: 90.557 Val_Loss: 0.2196  BEST VAL Loss: 0.2196  Val_Acc: 92.633

Epoch 3: Validation loss decreased (0.219647 --> 0.208328).  Saving model ...
	 Train_Loss: 0.2800 Train_Acc: 91.257 Val_Loss: 0.2083  BEST VAL Loss: 0.2083  Val_Acc: 93.192

Epoch 4: Validation loss decreased (0.208328 --> 0.199571).  Saving model ...
	 Train_Loss: 0.2660 Train_Acc: 91.614 Val_Loss: 0.1996  BEST VAL Loss: 0.1996  Val_Acc: 93.533

Epoch 5: Validation loss decreased (0.199571 --> 0.192601).  Saving model ...
	 Train_Loss: 0.2552 Train_Acc: 91.999 Val_Loss: 0.1926  BEST VAL Loss: 0.1926  Val_Acc: 93.764

Epoch 6: Validation loss decreased (0.192601 --> 0.186776).  Saving model ...
	 Train_Loss: 0.2463 Train_Acc: 92.155 Val_Loss: 0.1868  BEST VAL Loss: 0.1868  Val_Acc: 94.125

Epoch 7: Validation loss decreased (0.186776 --> 0.182053).  Saving model ...
	 Train_Loss: 0.2390 Train_Acc: 92.372 Val_Loss: 0.1821  BEST VAL Loss: 0.1821  Val_Acc: 94.105

Epoch 8: Validation loss decreased (0.182053 --> 0.178122).  Saving model ...
	 Train_Loss: 0.2329 Train_Acc: 92.596 Val_Loss: 0.1781  BEST VAL Loss: 0.1781  Val_Acc: 94.277

Epoch 9: Validation loss decreased (0.178122 --> 0.174502).  Saving model ...
	 Train_Loss: 0.2277 Train_Acc: 92.975 Val_Loss: 0.1745  BEST VAL Loss: 0.1745  Val_Acc: 94.508

Epoch 10: Validation loss decreased (0.174502 --> 0.171384).  Saving model ...
	 Train_Loss: 0.2232 Train_Acc: 93.132 Val_Loss: 0.1714  BEST VAL Loss: 0.1714  Val_Acc: 94.569

Epoch 11: Validation loss decreased (0.171384 --> 0.168641).  Saving model ...
	 Train_Loss: 0.2190 Train_Acc: 93.237 Val_Loss: 0.1686  BEST VAL Loss: 0.1686  Val_Acc: 94.598

Epoch 12: Validation loss decreased (0.168641 --> 0.166219).  Saving model ...
	 Train_Loss: 0.2154 Train_Acc: 93.297 Val_Loss: 0.1662  BEST VAL Loss: 0.1662  Val_Acc: 94.643

Epoch 13: Validation loss decreased (0.166219 --> 0.164002).  Saving model ...
	 Train_Loss: 0.2122 Train_Acc: 93.417 Val_Loss: 0.1640  BEST VAL Loss: 0.1640  Val_Acc: 94.816

Epoch 14: Validation loss decreased (0.164002 --> 0.162125).  Saving model ...
	 Train_Loss: 0.2093 Train_Acc: 93.431 Val_Loss: 0.1621  BEST VAL Loss: 0.1621  Val_Acc: 94.812

Epoch 15: Validation loss decreased (0.162125 --> 0.160310).  Saving model ...
	 Train_Loss: 0.2066 Train_Acc: 93.559 Val_Loss: 0.1603  BEST VAL Loss: 0.1603  Val_Acc: 94.943

Epoch 16: Validation loss decreased (0.160310 --> 0.158662).  Saving model ...
	 Train_Loss: 0.2042 Train_Acc: 93.588 Val_Loss: 0.1587  BEST VAL Loss: 0.1587  Val_Acc: 94.997

Epoch 17: Validation loss decreased (0.158662 --> 0.157112).  Saving model ...
	 Train_Loss: 0.2019 Train_Acc: 93.604 Val_Loss: 0.1571  BEST VAL Loss: 0.1571  Val_Acc: 94.976

Epoch 18: Validation loss decreased (0.157112 --> 0.155593).  Saving model ...
	 Train_Loss: 0.1998 Train_Acc: 93.646 Val_Loss: 0.1556  BEST VAL Loss: 0.1556  Val_Acc: 95.087

Epoch 19: Validation loss decreased (0.155593 --> 0.154203).  Saving model ...
	 Train_Loss: 0.1979 Train_Acc: 93.737 Val_Loss: 0.1542  BEST VAL Loss: 0.1542  Val_Acc: 95.104

Epoch 20: Validation loss decreased (0.154203 --> 0.152916).  Saving model ...
	 Train_Loss: 0.1962 Train_Acc: 93.666 Val_Loss: 0.1529  BEST VAL Loss: 0.1529  Val_Acc: 95.186

Epoch 21: Validation loss decreased (0.152916 --> 0.151836).  Saving model ...
	 Train_Loss: 0.1944 Train_Acc: 93.776 Val_Loss: 0.1518  BEST VAL Loss: 0.1518  Val_Acc: 95.116

Epoch 22: Validation loss decreased (0.151836 --> 0.150789).  Saving model ...
	 Train_Loss: 0.1928 Train_Acc: 93.849 Val_Loss: 0.1508  BEST VAL Loss: 0.1508  Val_Acc: 95.087

Epoch 23: Validation loss decreased (0.150789 --> 0.149839).  Saving model ...
	 Train_Loss: 0.1913 Train_Acc: 93.892 Val_Loss: 0.1498  BEST VAL Loss: 0.1498  Val_Acc: 95.124

Epoch 24: Validation loss decreased (0.149839 --> 0.148821).  Saving model ...
	 Train_Loss: 0.1899 Train_Acc: 93.931 Val_Loss: 0.1488  BEST VAL Loss: 0.1488  Val_Acc: 95.260

Epoch 25: Validation loss decreased (0.148821 --> 0.147938).  Saving model ...
	 Train_Loss: 0.1885 Train_Acc: 93.965 Val_Loss: 0.1479  BEST VAL Loss: 0.1479  Val_Acc: 95.207

Epoch 26: Validation loss decreased (0.147938 --> 0.147104).  Saving model ...
	 Train_Loss: 0.1873 Train_Acc: 93.891 Val_Loss: 0.1471  BEST VAL Loss: 0.1471  Val_Acc: 95.256

Epoch 27: Validation loss decreased (0.147104 --> 0.146299).  Saving model ...
	 Train_Loss: 0.1860 Train_Acc: 94.036 Val_Loss: 0.1463  BEST VAL Loss: 0.1463  Val_Acc: 95.318

Epoch 28: Validation loss decreased (0.146299 --> 0.145564).  Saving model ...
	 Train_Loss: 0.1849 Train_Acc: 94.014 Val_Loss: 0.1456  BEST VAL Loss: 0.1456  Val_Acc: 95.326

Epoch 29: Validation loss decreased (0.145564 --> 0.144783).  Saving model ...
	 Train_Loss: 0.1837 Train_Acc: 94.112 Val_Loss: 0.1448  BEST VAL Loss: 0.1448  Val_Acc: 95.408

Epoch 30: Validation loss decreased (0.144783 --> 0.144092).  Saving model ...
	 Train_Loss: 0.1827 Train_Acc: 94.034 Val_Loss: 0.1441  BEST VAL Loss: 0.1441  Val_Acc: 95.379

Epoch 31: Validation loss decreased (0.144092 --> 0.143407).  Saving model ...
	 Train_Loss: 0.1816 Train_Acc: 94.146 Val_Loss: 0.1434  BEST VAL Loss: 0.1434  Val_Acc: 95.318

Epoch 32: Validation loss decreased (0.143407 --> 0.142757).  Saving model ...
	 Train_Loss: 0.1807 Train_Acc: 94.093 Val_Loss: 0.1428  BEST VAL Loss: 0.1428  Val_Acc: 95.359

Epoch 33: Validation loss decreased (0.142757 --> 0.142118).  Saving model ...
	 Train_Loss: 0.1798 Train_Acc: 94.119 Val_Loss: 0.1421  BEST VAL Loss: 0.1421  Val_Acc: 95.408

Epoch 34: Validation loss decreased (0.142118 --> 0.141463).  Saving model ...
	 Train_Loss: 0.1789 Train_Acc: 94.168 Val_Loss: 0.1415  BEST VAL Loss: 0.1415  Val_Acc: 95.437

Epoch 35: Validation loss decreased (0.141463 --> 0.140859).  Saving model ...
	 Train_Loss: 0.1780 Train_Acc: 94.234 Val_Loss: 0.1409  BEST VAL Loss: 0.1409  Val_Acc: 95.490

Epoch 36: Validation loss decreased (0.140859 --> 0.140277).  Saving model ...
	 Train_Loss: 0.1772 Train_Acc: 94.224 Val_Loss: 0.1403  BEST VAL Loss: 0.1403  Val_Acc: 95.511

Epoch 37: Validation loss decreased (0.140277 --> 0.139752).  Saving model ...
	 Train_Loss: 0.1764 Train_Acc: 94.172 Val_Loss: 0.1398  BEST VAL Loss: 0.1398  Val_Acc: 95.445

Epoch 38: Validation loss decreased (0.139752 --> 0.139184).  Saving model ...
	 Train_Loss: 0.1756 Train_Acc: 94.248 Val_Loss: 0.1392  BEST VAL Loss: 0.1392  Val_Acc: 95.626

Epoch 39: Validation loss decreased (0.139184 --> 0.138670).  Saving model ...
	 Train_Loss: 0.1749 Train_Acc: 94.253 Val_Loss: 0.1387  BEST VAL Loss: 0.1387  Val_Acc: 95.540

Epoch 40: Validation loss decreased (0.138670 --> 0.138129).  Saving model ...
	 Train_Loss: 0.1741 Train_Acc: 94.258 Val_Loss: 0.1381  BEST VAL Loss: 0.1381  Val_Acc: 95.622

Epoch 41: Validation loss decreased (0.138129 --> 0.137667).  Saving model ...
	 Train_Loss: 0.1734 Train_Acc: 94.285 Val_Loss: 0.1377  BEST VAL Loss: 0.1377  Val_Acc: 95.531

Epoch 42: Validation loss decreased (0.137667 --> 0.137184).  Saving model ...
	 Train_Loss: 0.1728 Train_Acc: 94.349 Val_Loss: 0.1372  BEST VAL Loss: 0.1372  Val_Acc: 95.642

Epoch 43: Validation loss decreased (0.137184 --> 0.136711).  Saving model ...
	 Train_Loss: 0.1721 Train_Acc: 94.345 Val_Loss: 0.1367  BEST VAL Loss: 0.1367  Val_Acc: 95.651

Epoch 44: Validation loss decreased (0.136711 --> 0.136277).  Saving model ...
	 Train_Loss: 0.1714 Train_Acc: 94.260 Val_Loss: 0.1363  BEST VAL Loss: 0.1363  Val_Acc: 95.589

Epoch 45: Validation loss decreased (0.136277 --> 0.135829).  Saving model ...
	 Train_Loss: 0.1708 Train_Acc: 94.415 Val_Loss: 0.1358  BEST VAL Loss: 0.1358  Val_Acc: 95.655

Epoch 46: Validation loss decreased (0.135829 --> 0.135397).  Saving model ...
	 Train_Loss: 0.1702 Train_Acc: 94.364 Val_Loss: 0.1354  BEST VAL Loss: 0.1354  Val_Acc: 95.729

Epoch 47: Validation loss decreased (0.135397 --> 0.135023).  Saving model ...
	 Train_Loss: 0.1696 Train_Acc: 94.323 Val_Loss: 0.1350  BEST VAL Loss: 0.1350  Val_Acc: 95.634

Epoch 48: Validation loss decreased (0.135023 --> 0.134637).  Saving model ...
	 Train_Loss: 0.1691 Train_Acc: 94.370 Val_Loss: 0.1346  BEST VAL Loss: 0.1346  Val_Acc: 95.618

Epoch 49: Validation loss decreased (0.134637 --> 0.134270).  Saving model ...
	 Train_Loss: 0.1685 Train_Acc: 94.385 Val_Loss: 0.1343  BEST VAL Loss: 0.1343  Val_Acc: 95.733

Epoch 50: Validation loss decreased (0.134270 --> 0.133863).  Saving model ...
	 Train_Loss: 0.1680 Train_Acc: 94.360 Val_Loss: 0.1339  BEST VAL Loss: 0.1339  Val_Acc: 95.786

Epoch 51: Validation loss decreased (0.133863 --> 0.133486).  Saving model ...
	 Train_Loss: 0.1675 Train_Acc: 94.466 Val_Loss: 0.1335  BEST VAL Loss: 0.1335  Val_Acc: 95.712

Epoch 52: Validation loss decreased (0.133486 --> 0.133169).  Saving model ...
	 Train_Loss: 0.1669 Train_Acc: 94.470 Val_Loss: 0.1332  BEST VAL Loss: 0.1332  Val_Acc: 95.741

Epoch 53: Validation loss decreased (0.133169 --> 0.132821).  Saving model ...
	 Train_Loss: 0.1664 Train_Acc: 94.390 Val_Loss: 0.1328  BEST VAL Loss: 0.1328  Val_Acc: 95.749

Epoch 54: Validation loss decreased (0.132821 --> 0.132487).  Saving model ...
	 Train_Loss: 0.1659 Train_Acc: 94.494 Val_Loss: 0.1325  BEST VAL Loss: 0.1325  Val_Acc: 95.716

Epoch 55: Validation loss decreased (0.132487 --> 0.132166).  Saving model ...
	 Train_Loss: 0.1655 Train_Acc: 94.433 Val_Loss: 0.1322  BEST VAL Loss: 0.1322  Val_Acc: 95.638

Epoch 56: Validation loss decreased (0.132166 --> 0.131866).  Saving model ...
	 Train_Loss: 0.1650 Train_Acc: 94.474 Val_Loss: 0.1319  BEST VAL Loss: 0.1319  Val_Acc: 95.618

Epoch 57: Validation loss decreased (0.131866 --> 0.131569).  Saving model ...
	 Train_Loss: 0.1646 Train_Acc: 94.384 Val_Loss: 0.1316  BEST VAL Loss: 0.1316  Val_Acc: 95.790

Epoch 58: Validation loss decreased (0.131569 --> 0.131252).  Saving model ...
	 Train_Loss: 0.1641 Train_Acc: 94.499 Val_Loss: 0.1313  BEST VAL Loss: 0.1313  Val_Acc: 95.778

Epoch 59: Validation loss decreased (0.131252 --> 0.130951).  Saving model ...
	 Train_Loss: 0.1637 Train_Acc: 94.497 Val_Loss: 0.1310  BEST VAL Loss: 0.1310  Val_Acc: 95.786

Epoch 60: Validation loss decreased (0.130951 --> 0.130653).  Saving model ...
	 Train_Loss: 0.1633 Train_Acc: 94.577 Val_Loss: 0.1307  BEST VAL Loss: 0.1307  Val_Acc: 95.729

Epoch 61: Validation loss decreased (0.130653 --> 0.130357).  Saving model ...
	 Train_Loss: 0.1629 Train_Acc: 94.523 Val_Loss: 0.1304  BEST VAL Loss: 0.1304  Val_Acc: 95.868

Epoch 62: Validation loss decreased (0.130357 --> 0.130067).  Saving model ...
	 Train_Loss: 0.1624 Train_Acc: 94.511 Val_Loss: 0.1301  BEST VAL Loss: 0.1301  Val_Acc: 95.823

Epoch 63: Validation loss decreased (0.130067 --> 0.129787).  Saving model ...
	 Train_Loss: 0.1620 Train_Acc: 94.539 Val_Loss: 0.1298  BEST VAL Loss: 0.1298  Val_Acc: 95.840

Epoch 64: Validation loss decreased (0.129787 --> 0.129532).  Saving model ...
	 Train_Loss: 0.1617 Train_Acc: 94.512 Val_Loss: 0.1295  BEST VAL Loss: 0.1295  Val_Acc: 95.819

Epoch 65: Validation loss decreased (0.129532 --> 0.129303).  Saving model ...
	 Train_Loss: 0.1613 Train_Acc: 94.602 Val_Loss: 0.1293  BEST VAL Loss: 0.1293  Val_Acc: 95.720

Epoch 66: Validation loss decreased (0.129303 --> 0.129057).  Saving model ...
	 Train_Loss: 0.1609 Train_Acc: 94.569 Val_Loss: 0.1291  BEST VAL Loss: 0.1291  Val_Acc: 95.819

Epoch 67: Validation loss decreased (0.129057 --> 0.128813).  Saving model ...
	 Train_Loss: 0.1605 Train_Acc: 94.613 Val_Loss: 0.1288  BEST VAL Loss: 0.1288  Val_Acc: 95.930

Epoch 68: Validation loss decreased (0.128813 --> 0.128574).  Saving model ...
	 Train_Loss: 0.1602 Train_Acc: 94.606 Val_Loss: 0.1286  BEST VAL Loss: 0.1286  Val_Acc: 95.893

Epoch 69: Validation loss decreased (0.128574 --> 0.128317).  Saving model ...
	 Train_Loss: 0.1598 Train_Acc: 94.651 Val_Loss: 0.1283  BEST VAL Loss: 0.1283  Val_Acc: 95.959

Epoch 70: Validation loss decreased (0.128317 --> 0.128110).  Saving model ...
	 Train_Loss: 0.1595 Train_Acc: 94.572 Val_Loss: 0.1281  BEST VAL Loss: 0.1281  Val_Acc: 95.836

Epoch 71: Validation loss decreased (0.128110 --> 0.127867).  Saving model ...
	 Train_Loss: 0.1592 Train_Acc: 94.633 Val_Loss: 0.1279  BEST VAL Loss: 0.1279  Val_Acc: 95.873

Epoch 72: Validation loss decreased (0.127867 --> 0.127627).  Saving model ...
	 Train_Loss: 0.1588 Train_Acc: 94.584 Val_Loss: 0.1276  BEST VAL Loss: 0.1276  Val_Acc: 95.947

Epoch 73: Validation loss decreased (0.127627 --> 0.127402).  Saving model ...
	 Train_Loss: 0.1585 Train_Acc: 94.632 Val_Loss: 0.1274  BEST VAL Loss: 0.1274  Val_Acc: 95.868

Epoch 74: Validation loss decreased (0.127402 --> 0.127192).  Saving model ...
	 Train_Loss: 0.1582 Train_Acc: 94.640 Val_Loss: 0.1272  BEST VAL Loss: 0.1272  Val_Acc: 95.947

Epoch 75: Validation loss decreased (0.127192 --> 0.127000).  Saving model ...
	 Train_Loss: 0.1579 Train_Acc: 94.640 Val_Loss: 0.1270  BEST VAL Loss: 0.1270  Val_Acc: 95.881

Epoch 76: Validation loss decreased (0.127000 --> 0.126778).  Saving model ...
	 Train_Loss: 0.1576 Train_Acc: 94.629 Val_Loss: 0.1268  BEST VAL Loss: 0.1268  Val_Acc: 95.971

Epoch 77: Validation loss decreased (0.126778 --> 0.126602).  Saving model ...
	 Train_Loss: 0.1572 Train_Acc: 94.663 Val_Loss: 0.1266  BEST VAL Loss: 0.1266  Val_Acc: 95.811

Epoch 78: Validation loss decreased (0.126602 --> 0.126391).  Saving model ...
	 Train_Loss: 0.1569 Train_Acc: 94.671 Val_Loss: 0.1264  BEST VAL Loss: 0.1264  Val_Acc: 95.979

Epoch 79: Validation loss decreased (0.126391 --> 0.126184).  Saving model ...
	 Train_Loss: 0.1566 Train_Acc: 94.702 Val_Loss: 0.1262  BEST VAL Loss: 0.1262  Val_Acc: 95.975

Epoch 80: Validation loss decreased (0.126184 --> 0.125977).  Saving model ...
	 Train_Loss: 0.1564 Train_Acc: 94.664 Val_Loss: 0.1260  BEST VAL Loss: 0.1260  Val_Acc: 95.885

Epoch 81: Validation loss decreased (0.125977 --> 0.125773).  Saving model ...
	 Train_Loss: 0.1561 Train_Acc: 94.766 Val_Loss: 0.1258  BEST VAL Loss: 0.1258  Val_Acc: 95.914

Epoch 82: Validation loss decreased (0.125773 --> 0.125569).  Saving model ...
	 Train_Loss: 0.1558 Train_Acc: 94.712 Val_Loss: 0.1256  BEST VAL Loss: 0.1256  Val_Acc: 95.975

Epoch 83: Validation loss decreased (0.125569 --> 0.125385).  Saving model ...
	 Train_Loss: 0.1555 Train_Acc: 94.647 Val_Loss: 0.1254  BEST VAL Loss: 0.1254  Val_Acc: 96.062

Epoch 84: Validation loss decreased (0.125385 --> 0.125189).  Saving model ...
	 Train_Loss: 0.1552 Train_Acc: 94.676 Val_Loss: 0.1252  BEST VAL Loss: 0.1252  Val_Acc: 95.963

Epoch 85: Validation loss decreased (0.125189 --> 0.125008).  Saving model ...
	 Train_Loss: 0.1550 Train_Acc: 94.723 Val_Loss: 0.1250  BEST VAL Loss: 0.1250  Val_Acc: 95.938

Epoch 86: Validation loss decreased (0.125008 --> 0.124871).  Saving model ...
	 Train_Loss: 0.1547 Train_Acc: 94.725 Val_Loss: 0.1249  BEST VAL Loss: 0.1249  Val_Acc: 95.790

Epoch 87: Validation loss decreased (0.124871 --> 0.124679).  Saving model ...
	 Train_Loss: 0.1544 Train_Acc: 94.760 Val_Loss: 0.1247  BEST VAL Loss: 0.1247  Val_Acc: 95.942

Epoch 88: Validation loss decreased (0.124679 --> 0.124509).  Saving model ...
	 Train_Loss: 0.1542 Train_Acc: 94.673 Val_Loss: 0.1245  BEST VAL Loss: 0.1245  Val_Acc: 95.938

Epoch 89: Validation loss decreased (0.124509 --> 0.124325).  Saving model ...
	 Train_Loss: 0.1539 Train_Acc: 94.712 Val_Loss: 0.1243  BEST VAL Loss: 0.1243  Val_Acc: 96.012

Epoch 90: Validation loss decreased (0.124325 --> 0.124148).  Saving model ...
	 Train_Loss: 0.1537 Train_Acc: 94.726 Val_Loss: 0.1241  BEST VAL Loss: 0.1241  Val_Acc: 95.992

Epoch 91: Validation loss decreased (0.124148 --> 0.123983).  Saving model ...
	 Train_Loss: 0.1535 Train_Acc: 94.726 Val_Loss: 0.1240  BEST VAL Loss: 0.1240  Val_Acc: 95.901

Epoch 92: Validation loss decreased (0.123983 --> 0.123837).  Saving model ...
	 Train_Loss: 0.1532 Train_Acc: 94.751 Val_Loss: 0.1238  BEST VAL Loss: 0.1238  Val_Acc: 95.901

Epoch 93: Validation loss decreased (0.123837 --> 0.123677).  Saving model ...
	 Train_Loss: 0.1530 Train_Acc: 94.758 Val_Loss: 0.1237  BEST VAL Loss: 0.1237  Val_Acc: 96.070

Epoch 94: Validation loss decreased (0.123677 --> 0.123516).  Saving model ...
	 Train_Loss: 0.1527 Train_Acc: 94.833 Val_Loss: 0.1235  BEST VAL Loss: 0.1235  Val_Acc: 96.016

Epoch 95: Validation loss decreased (0.123516 --> 0.123347).  Saving model ...
	 Train_Loss: 0.1525 Train_Acc: 94.794 Val_Loss: 0.1233  BEST VAL Loss: 0.1233  Val_Acc: 96.045

Epoch 96: Validation loss decreased (0.123347 --> 0.123197).  Saving model ...
	 Train_Loss: 0.1523 Train_Acc: 94.825 Val_Loss: 0.1232  BEST VAL Loss: 0.1232  Val_Acc: 95.901

Epoch 97: Validation loss decreased (0.123197 --> 0.123052).  Saving model ...
	 Train_Loss: 0.1520 Train_Acc: 94.739 Val_Loss: 0.1231  BEST VAL Loss: 0.1231  Val_Acc: 96.053

Epoch 98: Validation loss decreased (0.123052 --> 0.122897).  Saving model ...
	 Train_Loss: 0.1518 Train_Acc: 94.739 Val_Loss: 0.1229  BEST VAL Loss: 0.1229  Val_Acc: 96.029

Epoch 99: Validation loss decreased (0.122897 --> 0.122753).  Saving model ...
	 Train_Loss: 0.1516 Train_Acc: 94.779 Val_Loss: 0.1228  BEST VAL Loss: 0.1228  Val_Acc: 96.045

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.96      0.97      0.96     85372
           1       0.97      0.97      0.97    109228

    accuracy                           0.97    194600
   macro avg       0.97      0.97      0.97    194600
weighted avg       0.97      0.97      0.97    194600

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.95      0.96      0.96     10671
           1       0.97      0.96      0.96     13654

    accuracy                           0.96     24325
   macro avg       0.96      0.96      0.96     24325
weighted avg       0.96      0.96      0.96     24325

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.95      0.96      0.96     10671
           1       0.97      0.96      0.96     13654

    accuracy                           0.96     24325
   macro avg       0.96      0.96      0.96     24325
weighted avg       0.96      0.96      0.96     24325

              precision    recall  f1-score   support

           0       0.95      0.96      0.96     10671
           1       0.97      0.96      0.96     13654

    accuracy                           0.96     24325
   macro avg       0.96      0.96      0.96     24325
weighted avg       0.96      0.96      0.96     24325

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       1.00      0.82      0.90     36366
           1       0.85      1.00      0.92     37725

    accuracy                           0.91     74091
   macro avg       0.93      0.91      0.91     74091
weighted avg       0.92      0.91      0.91     74091

              precision    recall  f1-score   support

           0       1.00      0.82      0.90     36366
           1       0.85      1.00      0.92     37725

    accuracy                           0.91     74091
   macro avg       0.93      0.91      0.91     74091
weighted avg       0.92      0.91      0.91     74091

completed
