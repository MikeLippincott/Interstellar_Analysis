[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'fefb0b3f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '1a9d29b8'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'a1528b31'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'a22e74f8'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_10.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (30462, 1276)
Number of total missing values across all columns: 33620
Data Subset Is Off
Wells held out for testing: ['E20' 'L16']
Wells to use for training, validation, and testing ['E16' 'E17' 'E21' 'L17' 'L20' 'L21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.307158).  Saving model ...
	 Train_Loss: 0.5576 Train_Acc: 65.653 Val_Loss: 0.3072  BEST VAL Loss: 0.3072  Val_Acc: 87.240

Epoch 1: Validation loss decreased (0.307158 --> 0.267870).  Saving model ...
	 Train_Loss: 0.4736 Train_Acc: 81.336 Val_Loss: 0.2679  BEST VAL Loss: 0.2679  Val_Acc: 91.759

Epoch 2: Validation loss decreased (0.267870 --> 0.245549).  Saving model ...
	 Train_Loss: 0.4228 Train_Acc: 87.048 Val_Loss: 0.2455  BEST VAL Loss: 0.2455  Val_Acc: 92.512

Epoch 3: Validation loss decreased (0.245549 --> 0.228016).  Saving model ...
	 Train_Loss: 0.3897 Train_Acc: 88.538 Val_Loss: 0.2280  BEST VAL Loss: 0.2280  Val_Acc: 93.797

Epoch 4: Validation loss decreased (0.228016 --> 0.217772).  Saving model ...
	 Train_Loss: 0.3667 Train_Acc: 89.530 Val_Loss: 0.2178  BEST VAL Loss: 0.2178  Val_Acc: 93.753

Epoch 5: Validation loss decreased (0.217772 --> 0.204454).  Saving model ...
	 Train_Loss: 0.3501 Train_Acc: 89.380 Val_Loss: 0.2045  BEST VAL Loss: 0.2045  Val_Acc: 95.126

Epoch 6: Validation loss decreased (0.204454 --> 0.195515).  Saving model ...
	 Train_Loss: 0.3354 Train_Acc: 90.804 Val_Loss: 0.1955  BEST VAL Loss: 0.1955  Val_Acc: 94.728

Epoch 7: Validation loss decreased (0.195515 --> 0.185699).  Saving model ...
	 Train_Loss: 0.3236 Train_Acc: 91.097 Val_Loss: 0.1857  BEST VAL Loss: 0.1857  Val_Acc: 95.569

Epoch 8: Validation loss decreased (0.185699 --> 0.180093).  Saving model ...
	 Train_Loss: 0.3136 Train_Acc: 91.081 Val_Loss: 0.1801  BEST VAL Loss: 0.1801  Val_Acc: 95.392

Epoch 9: Validation loss decreased (0.180093 --> 0.174834).  Saving model ...
	 Train_Loss: 0.3049 Train_Acc: 91.701 Val_Loss: 0.1748  BEST VAL Loss: 0.1748  Val_Acc: 95.436

Epoch 10: Validation loss decreased (0.174834 --> 0.168940).  Saving model ...
	 Train_Loss: 0.2967 Train_Acc: 91.845 Val_Loss: 0.1689  BEST VAL Loss: 0.1689  Val_Acc: 95.968

Epoch 11: Validation loss decreased (0.168940 --> 0.163638).  Saving model ...
	 Train_Loss: 0.2894 Train_Acc: 91.856 Val_Loss: 0.1636  BEST VAL Loss: 0.1636  Val_Acc: 95.968

Epoch 12: Validation loss decreased (0.163638 --> 0.160485).  Saving model ...
	 Train_Loss: 0.2834 Train_Acc: 91.956 Val_Loss: 0.1605  BEST VAL Loss: 0.1605  Val_Acc: 95.614

Epoch 13: Validation loss decreased (0.160485 --> 0.157761).  Saving model ...
	 Train_Loss: 0.2780 Train_Acc: 92.067 Val_Loss: 0.1578  BEST VAL Loss: 0.1578  Val_Acc: 95.968

Epoch 14: Validation loss decreased (0.157761 --> 0.154782).  Saving model ...
	 Train_Loss: 0.2738 Train_Acc: 91.629 Val_Loss: 0.1548  BEST VAL Loss: 0.1548  Val_Acc: 95.791

Epoch 15: Validation loss decreased (0.154782 --> 0.152149).  Saving model ...
	 Train_Loss: 0.2696 Train_Acc: 92.338 Val_Loss: 0.1521  BEST VAL Loss: 0.1521  Val_Acc: 96.544

Epoch 16: Validation loss decreased (0.152149 --> 0.149777).  Saving model ...
	 Train_Loss: 0.2656 Train_Acc: 92.250 Val_Loss: 0.1498  BEST VAL Loss: 0.1498  Val_Acc: 96.588

Epoch 17: Validation loss decreased (0.149777 --> 0.147708).  Saving model ...
	 Train_Loss: 0.2614 Train_Acc: 92.566 Val_Loss: 0.1477  BEST VAL Loss: 0.1477  Val_Acc: 96.500

Epoch 18: Validation loss decreased (0.147708 --> 0.144969).  Saving model ...
	 Train_Loss: 0.2579 Train_Acc: 92.848 Val_Loss: 0.1450  BEST VAL Loss: 0.1450  Val_Acc: 96.411

Epoch 19: Validation loss decreased (0.144969 --> 0.143593).  Saving model ...
	 Train_Loss: 0.2547 Train_Acc: 92.377 Val_Loss: 0.1436  BEST VAL Loss: 0.1436  Val_Acc: 96.367

Epoch 20: Validation loss decreased (0.143593 --> 0.141066).  Saving model ...
	 Train_Loss: 0.2514 Train_Acc: 92.782 Val_Loss: 0.1411  BEST VAL Loss: 0.1411  Val_Acc: 96.943

Epoch 21: Validation loss decreased (0.141066 --> 0.139743).  Saving model ...
	 Train_Loss: 0.2485 Train_Acc: 93.252 Val_Loss: 0.1397  BEST VAL Loss: 0.1397  Val_Acc: 96.544

Epoch 22: Validation loss decreased (0.139743 --> 0.138021).  Saving model ...
	 Train_Loss: 0.2460 Train_Acc: 92.881 Val_Loss: 0.1380  BEST VAL Loss: 0.1380  Val_Acc: 96.633

Epoch 23: Validation loss decreased (0.138021 --> 0.136275).  Saving model ...
	 Train_Loss: 0.2432 Train_Acc: 93.131 Val_Loss: 0.1363  BEST VAL Loss: 0.1363  Val_Acc: 96.588

Epoch 24: Validation loss decreased (0.136275 --> 0.135120).  Saving model ...
	 Train_Loss: 0.2407 Train_Acc: 93.363 Val_Loss: 0.1351  BEST VAL Loss: 0.1351  Val_Acc: 96.145

Epoch 25: Validation loss decreased (0.135120 --> 0.134137).  Saving model ...
	 Train_Loss: 0.2386 Train_Acc: 93.241 Val_Loss: 0.1341  BEST VAL Loss: 0.1341  Val_Acc: 96.677

Epoch 26: Validation loss decreased (0.134137 --> 0.133407).  Saving model ...
	 Train_Loss: 0.2379 Train_Acc: 91.541 Val_Loss: 0.1334  BEST VAL Loss: 0.1334  Val_Acc: 96.588

Epoch 27: Validation loss decreased (0.133407 --> 0.132747).  Saving model ...
	 Train_Loss: 0.2368 Train_Acc: 92.499 Val_Loss: 0.1327  BEST VAL Loss: 0.1327  Val_Acc: 96.145

Epoch 28: Validation loss decreased (0.132747 --> 0.131831).  Saving model ...
	 Train_Loss: 0.2360 Train_Acc: 92.571 Val_Loss: 0.1318  BEST VAL Loss: 0.1318  Val_Acc: 96.544

Epoch 29: Validation loss decreased (0.131831 --> 0.130501).  Saving model ...
	 Train_Loss: 0.2351 Train_Acc: 92.000 Val_Loss: 0.1305  BEST VAL Loss: 0.1305  Val_Acc: 96.899

Epoch 30: Validation loss decreased (0.130501 --> 0.129822).  Saving model ...
	 Train_Loss: 0.2337 Train_Acc: 92.898 Val_Loss: 0.1298  BEST VAL Loss: 0.1298  Val_Acc: 96.500

Epoch 31: Validation loss decreased (0.129822 --> 0.129173).  Saving model ...
	 Train_Loss: 0.2324 Train_Acc: 92.787 Val_Loss: 0.1292  BEST VAL Loss: 0.1292  Val_Acc: 96.943

Epoch 32: Validation loss decreased (0.129173 --> 0.128470).  Saving model ...
	 Train_Loss: 0.2312 Train_Acc: 92.582 Val_Loss: 0.1285  BEST VAL Loss: 0.1285  Val_Acc: 96.633

Epoch 33: Validation loss decreased (0.128470 --> 0.127851).  Saving model ...
	 Train_Loss: 0.2309 Train_Acc: 91.585 Val_Loss: 0.1279  BEST VAL Loss: 0.1279  Val_Acc: 96.323

Epoch 34: Validation loss decreased (0.127851 --> 0.127229).  Saving model ...
	 Train_Loss: 0.2303 Train_Acc: 92.782 Val_Loss: 0.1272  BEST VAL Loss: 0.1272  Val_Acc: 96.721

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.2292 Train_Acc: 93.496 Val_Loss: 0.1273  BEST VAL Loss: 0.1272  Val_Acc: 96.500

Epoch 36: Validation loss decreased (0.127229 --> 0.126474).  Saving model ...
	 Train_Loss: 0.2284 Train_Acc: 93.086 Val_Loss: 0.1265  BEST VAL Loss: 0.1265  Val_Acc: 96.677

Epoch 37: Validation loss decreased (0.126474 --> 0.125925).  Saving model ...
	 Train_Loss: 0.2274 Train_Acc: 92.898 Val_Loss: 0.1259  BEST VAL Loss: 0.1259  Val_Acc: 96.899

Epoch 38: Validation loss decreased (0.125925 --> 0.125271).  Saving model ...
	 Train_Loss: 0.2263 Train_Acc: 93.712 Val_Loss: 0.1253  BEST VAL Loss: 0.1253  Val_Acc: 97.031

Epoch 39: Validation loss decreased (0.125271 --> 0.125078).  Saving model ...
	 Train_Loss: 0.2252 Train_Acc: 93.524 Val_Loss: 0.1251  BEST VAL Loss: 0.1251  Val_Acc: 97.164

Epoch 40: Validation loss decreased (0.125078 --> 0.124981).  Saving model ...
	 Train_Loss: 0.2241 Train_Acc: 93.651 Val_Loss: 0.1250  BEST VAL Loss: 0.1250  Val_Acc: 97.076

Epoch 41: Validation loss decreased (0.124981 --> 0.124851).  Saving model ...
	 Train_Loss: 0.2230 Train_Acc: 93.668 Val_Loss: 0.1249  BEST VAL Loss: 0.1249  Val_Acc: 97.076

Epoch 42: Validation loss decreased (0.124851 --> 0.124438).  Saving model ...
	 Train_Loss: 0.2220 Train_Acc: 93.552 Val_Loss: 0.1244  BEST VAL Loss: 0.1244  Val_Acc: 97.297

Epoch 43: Validation loss decreased (0.124438 --> 0.123842).  Saving model ...
	 Train_Loss: 0.2208 Train_Acc: 93.679 Val_Loss: 0.1238  BEST VAL Loss: 0.1238  Val_Acc: 97.164

Epoch 44: Validation loss decreased (0.123842 --> 0.123565).  Saving model ...
	 Train_Loss: 0.2197 Train_Acc: 93.729 Val_Loss: 0.1236  BEST VAL Loss: 0.1236  Val_Acc: 97.253

Epoch 45: Validation loss decreased (0.123565 --> 0.122836).  Saving model ...
	 Train_Loss: 0.2185 Train_Acc: 93.901 Val_Loss: 0.1228  BEST VAL Loss: 0.1228  Val_Acc: 97.076

Epoch 46: Validation loss decreased (0.122836 --> 0.122109).  Saving model ...
	 Train_Loss: 0.2174 Train_Acc: 93.751 Val_Loss: 0.1221  BEST VAL Loss: 0.1221  Val_Acc: 97.297

Epoch 47: Validation loss decreased (0.122109 --> 0.121963).  Saving model ...
	 Train_Loss: 0.2163 Train_Acc: 93.829 Val_Loss: 0.1220  BEST VAL Loss: 0.1220  Val_Acc: 97.120

Epoch 48: Validation loss decreased (0.121963 --> 0.121354).  Saving model ...
	 Train_Loss: 0.2153 Train_Acc: 93.923 Val_Loss: 0.1214  BEST VAL Loss: 0.1214  Val_Acc: 97.120

Epoch 49: Validation loss decreased (0.121354 --> 0.120962).  Saving model ...
	 Train_Loss: 0.2144 Train_Acc: 93.757 Val_Loss: 0.1210  BEST VAL Loss: 0.1210  Val_Acc: 97.209

Epoch 50: Validation loss decreased (0.120962 --> 0.120634).  Saving model ...
	 Train_Loss: 0.2135 Train_Acc: 93.978 Val_Loss: 0.1206  BEST VAL Loss: 0.1206  Val_Acc: 97.253

Epoch 51: Validation loss decreased (0.120634 --> 0.119960).  Saving model ...
	 Train_Loss: 0.2126 Train_Acc: 93.862 Val_Loss: 0.1200  BEST VAL Loss: 0.1200  Val_Acc: 97.209

Epoch 52: Validation loss decreased (0.119960 --> 0.119252).  Saving model ...
	 Train_Loss: 0.2116 Train_Acc: 93.851 Val_Loss: 0.1193  BEST VAL Loss: 0.1193  Val_Acc: 97.076

Epoch 53: Validation loss decreased (0.119252 --> 0.118529).  Saving model ...
	 Train_Loss: 0.2108 Train_Acc: 93.851 Val_Loss: 0.1185  BEST VAL Loss: 0.1185  Val_Acc: 97.164

Epoch 54: Validation loss decreased (0.118529 --> 0.117978).  Saving model ...
	 Train_Loss: 0.2104 Train_Acc: 93.424 Val_Loss: 0.1180  BEST VAL Loss: 0.1180  Val_Acc: 96.899

Epoch 55: Validation loss decreased (0.117978 --> 0.117554).  Saving model ...
	 Train_Loss: 0.2098 Train_Acc: 93.081 Val_Loss: 0.1176  BEST VAL Loss: 0.1176  Val_Acc: 97.475

Epoch 56: Validation loss decreased (0.117554 --> 0.117302).  Saving model ...
	 Train_Loss: 0.2092 Train_Acc: 93.541 Val_Loss: 0.1173  BEST VAL Loss: 0.1173  Val_Acc: 97.297

Epoch 57: Validation loss decreased (0.117302 --> 0.116843).  Saving model ...
	 Train_Loss: 0.2086 Train_Acc: 92.676 Val_Loss: 0.1168  BEST VAL Loss: 0.1168  Val_Acc: 96.943

Epoch 58: Validation loss decreased (0.116843 --> 0.116457).  Saving model ...
	 Train_Loss: 0.2083 Train_Acc: 92.505 Val_Loss: 0.1165  BEST VAL Loss: 0.1165  Val_Acc: 96.854

Epoch 59: Validation loss decreased (0.116457 --> 0.115950).  Saving model ...
	 Train_Loss: 0.2077 Train_Acc: 93.391 Val_Loss: 0.1160  BEST VAL Loss: 0.1160  Val_Acc: 97.076

Epoch 60: Validation loss decreased (0.115950 --> 0.115563).  Saving model ...
	 Train_Loss: 0.2069 Train_Acc: 93.557 Val_Loss: 0.1156  BEST VAL Loss: 0.1156  Val_Acc: 97.164

Epoch 61: Validation loss decreased (0.115563 --> 0.115079).  Saving model ...
	 Train_Loss: 0.2064 Train_Acc: 93.840 Val_Loss: 0.1151  BEST VAL Loss: 0.1151  Val_Acc: 97.253

Epoch 62: Validation loss decreased (0.115079 --> 0.114837).  Saving model ...
	 Train_Loss: 0.2060 Train_Acc: 92.632 Val_Loss: 0.1148  BEST VAL Loss: 0.1148  Val_Acc: 96.854

Epoch 63: Validation loss decreased (0.114837 --> 0.114429).  Saving model ...
	 Train_Loss: 0.2055 Train_Acc: 93.119 Val_Loss: 0.1144  BEST VAL Loss: 0.1144  Val_Acc: 97.031

Epoch 64: Validation loss decreased (0.114429 --> 0.114236).  Saving model ...
	 Train_Loss: 0.2048 Train_Acc: 93.906 Val_Loss: 0.1142  BEST VAL Loss: 0.1142  Val_Acc: 97.164

Epoch 65: Validation loss decreased (0.114236 --> 0.113988).  Saving model ...
	 Train_Loss: 0.2043 Train_Acc: 93.419 Val_Loss: 0.1140  BEST VAL Loss: 0.1140  Val_Acc: 97.386

Epoch 66: Validation loss decreased (0.113988 --> 0.113553).  Saving model ...
	 Train_Loss: 0.2037 Train_Acc: 93.635 Val_Loss: 0.1136  BEST VAL Loss: 0.1136  Val_Acc: 97.120

Epoch 67: Validation loss decreased (0.113553 --> 0.113161).  Saving model ...
	 Train_Loss: 0.2033 Train_Acc: 92.804 Val_Loss: 0.1132  BEST VAL Loss: 0.1132  Val_Acc: 97.164

Epoch 68: Validation loss decreased (0.113161 --> 0.112934).  Saving model ...
	 Train_Loss: 0.2028 Train_Acc: 93.408 Val_Loss: 0.1129  BEST VAL Loss: 0.1129  Val_Acc: 97.120

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.2027 Train_Acc: 93.457 Val_Loss: 0.1130  BEST VAL Loss: 0.1129  Val_Acc: 96.943

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.2027 Train_Acc: 91.114 Val_Loss: 0.1130  BEST VAL Loss: 0.1129  Val_Acc: 96.677

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.2024 Train_Acc: 92.571 Val_Loss: 0.1130  BEST VAL Loss: 0.1129  Val_Acc: 97.386

Epoch 72: Validation loss decreased (0.112934 --> 0.112495).  Saving model ...
	 Train_Loss: 0.2021 Train_Acc: 92.804 Val_Loss: 0.1125  BEST VAL Loss: 0.1125  Val_Acc: 97.209

Epoch 73: Validation loss decreased (0.112495 --> 0.112219).  Saving model ...
	 Train_Loss: 0.2016 Train_Acc: 93.529 Val_Loss: 0.1122  BEST VAL Loss: 0.1122  Val_Acc: 97.342

Epoch 74: Validation loss decreased (0.112219 --> 0.111834).  Saving model ...
	 Train_Loss: 0.2011 Train_Acc: 93.601 Val_Loss: 0.1118  BEST VAL Loss: 0.1118  Val_Acc: 97.120

Epoch 75: Validation loss decreased (0.111834 --> 0.111737).  Saving model ...
	 Train_Loss: 0.2005 Train_Acc: 93.978 Val_Loss: 0.1117  BEST VAL Loss: 0.1117  Val_Acc: 97.519

Epoch 76: Validation loss decreased (0.111737 --> 0.111517).  Saving model ...
	 Train_Loss: 0.2000 Train_Acc: 93.740 Val_Loss: 0.1115  BEST VAL Loss: 0.1115  Val_Acc: 97.076

Epoch 77: Validation loss decreased (0.111517 --> 0.111367).  Saving model ...
	 Train_Loss: 0.1995 Train_Acc: 94.211 Val_Loss: 0.1114  BEST VAL Loss: 0.1114  Val_Acc: 97.652

Epoch 78: Validation loss decreased (0.111367 --> 0.111291).  Saving model ...
	 Train_Loss: 0.1989 Train_Acc: 93.873 Val_Loss: 0.1113  BEST VAL Loss: 0.1113  Val_Acc: 97.430

Epoch 79: Validation loss decreased (0.111291 --> 0.111200).  Saving model ...
	 Train_Loss: 0.1984 Train_Acc: 93.923 Val_Loss: 0.1112  BEST VAL Loss: 0.1112  Val_Acc: 97.475

Epoch 80: Validation loss decreased (0.111200 --> 0.111031).  Saving model ...
	 Train_Loss: 0.1979 Train_Acc: 93.989 Val_Loss: 0.1110  BEST VAL Loss: 0.1110  Val_Acc: 97.475

Epoch 81: Validation loss decreased (0.111031 --> 0.110874).  Saving model ...
	 Train_Loss: 0.1974 Train_Acc: 94.122 Val_Loss: 0.1109  BEST VAL Loss: 0.1109  Val_Acc: 97.607

Epoch 82: Validation loss decreased (0.110874 --> 0.110853).  Saving model ...
	 Train_Loss: 0.1969 Train_Acc: 94.117 Val_Loss: 0.1109  BEST VAL Loss: 0.1109  Val_Acc: 97.829

Epoch 83: Validation loss decreased (0.110853 --> 0.110654).  Saving model ...
	 Train_Loss: 0.1965 Train_Acc: 94.283 Val_Loss: 0.1107  BEST VAL Loss: 0.1107  Val_Acc: 97.652

Epoch 84: Validation loss decreased (0.110654 --> 0.110495).  Saving model ...
	 Train_Loss: 0.1961 Train_Acc: 93.685 Val_Loss: 0.1105  BEST VAL Loss: 0.1105  Val_Acc: 97.519

Epoch 85: Validation loss decreased (0.110495 --> 0.110346).  Saving model ...
	 Train_Loss: 0.1960 Train_Acc: 92.061 Val_Loss: 0.1103  BEST VAL Loss: 0.1103  Val_Acc: 97.031

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.1958 Train_Acc: 92.898 Val_Loss: 0.1104  BEST VAL Loss: 0.1103  Val_Acc: 97.297

Epoch 87: Validation loss decreased (0.110346 --> 0.110287).  Saving model ...
	 Train_Loss: 0.1955 Train_Acc: 93.070 Val_Loss: 0.1103  BEST VAL Loss: 0.1103  Val_Acc: 97.430

Epoch 88: Validation loss decreased (0.110287 --> 0.110029).  Saving model ...
	 Train_Loss: 0.1950 Train_Acc: 94.183 Val_Loss: 0.1100  BEST VAL Loss: 0.1100  Val_Acc: 97.430

Epoch 89: Validation loss decreased (0.110029 --> 0.109928).  Saving model ...
	 Train_Loss: 0.1945 Train_Acc: 94.266 Val_Loss: 0.1099  BEST VAL Loss: 0.1099  Val_Acc: 97.342

Epoch 90: Validation loss decreased (0.109928 --> 0.109673).  Saving model ...
	 Train_Loss: 0.1941 Train_Acc: 94.183 Val_Loss: 0.1097  BEST VAL Loss: 0.1097  Val_Acc: 97.563

Epoch 91: Validation loss decreased (0.109673 --> 0.109616).  Saving model ...
	 Train_Loss: 0.1937 Train_Acc: 93.568 Val_Loss: 0.1096  BEST VAL Loss: 0.1096  Val_Acc: 97.209

Epoch 92: Validation loss decreased (0.109616 --> 0.109338).  Saving model ...
	 Train_Loss: 0.1934 Train_Acc: 93.469 Val_Loss: 0.1093  BEST VAL Loss: 0.1093  Val_Acc: 97.563

Epoch 93: Validation loss decreased (0.109338 --> 0.109225).  Saving model ...
	 Train_Loss: 0.1929 Train_Acc: 93.840 Val_Loss: 0.1092  BEST VAL Loss: 0.1092  Val_Acc: 97.563

Epoch 94: Validation loss decreased (0.109225 --> 0.109186).  Saving model ...
	 Train_Loss: 0.1925 Train_Acc: 93.945 Val_Loss: 0.1092  BEST VAL Loss: 0.1092  Val_Acc: 97.386

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.1923 Train_Acc: 94.189 Val_Loss: 0.1095  BEST VAL Loss: 0.1092  Val_Acc: 97.342

Epoch 96: Validation loss did not decrease
	 Train_Loss: 0.1922 Train_Acc: 92.305 Val_Loss: 0.1093  BEST VAL Loss: 0.1092  Val_Acc: 97.031

Epoch 97: Validation loss did not decrease
	 Train_Loss: 0.1920 Train_Acc: 92.698 Val_Loss: 0.1093  BEST VAL Loss: 0.1092  Val_Acc: 97.031

Epoch 98: Validation loss decreased (0.109186 --> 0.108980).  Saving model ...
	 Train_Loss: 0.1918 Train_Acc: 93.275 Val_Loss: 0.1090  BEST VAL Loss: 0.1090  Val_Acc: 97.297

Epoch 99: Validation loss decreased (0.108980 --> 0.108631).  Saving model ...
	 Train_Loss: 0.1914 Train_Acc: 93.768 Val_Loss: 0.1086  BEST VAL Loss: 0.1086  Val_Acc: 97.386

LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.56      0.56      0.56     10113
           1       0.44      0.44      0.44      7938

    accuracy                           0.50     18051
   macro avg       0.50      0.50      0.50     18051
weighted avg       0.50      0.50      0.50     18051

LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.57      0.56      0.56      1264
           1       0.45      0.46      0.45       993

    accuracy                           0.51      2257
   macro avg       0.51      0.51      0.51      2257
weighted avg       0.51      0.51      0.51      2257

LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.56      0.55      0.56      1265
           1       0.44      0.44      0.44       992

    accuracy                           0.51      2257
   macro avg       0.50      0.50      0.50      2257
weighted avg       0.51      0.51      0.51      2257

              precision    recall  f1-score   support

           0       0.56      0.55      0.56      1265
           1       0.44      0.44      0.44       992

    accuracy                           0.51      2257
   macro avg       0.50      0.50      0.50      2257
weighted avg       0.51      0.51      0.51      2257

LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.55      0.54      4168
           1       0.47      0.45      0.46      3729

    accuracy                           0.50      7897
   macro avg       0.50      0.50      0.50      7897
weighted avg       0.50      0.50      0.50      7897

              precision    recall  f1-score   support

           0       0.53      0.55      0.54      4168
           1       0.47      0.45      0.46      3729

    accuracy                           0.50      7897
   macro avg       0.50      0.50      0.50      7897
weighted avg       0.50      0.50      0.50      7897

completed
