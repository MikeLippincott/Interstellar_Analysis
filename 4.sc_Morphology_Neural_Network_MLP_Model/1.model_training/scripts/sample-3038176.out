[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd8617076'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'b16ed4eb'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'cf4ac3db'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '5cc588ba'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_100.000_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (340601, 1270)
Number of total missing values across all columns: 318870
Data Subset Is Off
Wells held out for testing: ['J08' 'M09']
Wells to use for training, validation, and testing ['J02' 'J03' 'J09' 'M02' 'M03' 'M08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.226378).  Saving model ...
	 Train_Loss: 0.3159 Train_Acc: 86.712 Val_Loss: 0.2264  BEST VAL Loss: 0.2264  Val_Acc: 91.054

Epoch 1: Validation loss decreased (0.226378 --> 0.212682).  Saving model ...
	 Train_Loss: 0.2761 Train_Acc: 90.604 Val_Loss: 0.2127  BEST VAL Loss: 0.2127  Val_Acc: 92.394

Epoch 2: Validation loss decreased (0.212682 --> 0.204819).  Saving model ...
	 Train_Loss: 0.2561 Train_Acc: 91.405 Val_Loss: 0.2048  BEST VAL Loss: 0.2048  Val_Acc: 92.824

Epoch 3: Validation loss decreased (0.204819 --> 0.198967).  Saving model ...
	 Train_Loss: 0.2434 Train_Acc: 91.825 Val_Loss: 0.1990  BEST VAL Loss: 0.1990  Val_Acc: 93.163

Epoch 4: Validation loss decreased (0.198967 --> 0.195940).  Saving model ...
	 Train_Loss: 0.2338 Train_Acc: 92.184 Val_Loss: 0.1959  BEST VAL Loss: 0.1959  Val_Acc: 93.017

Epoch 5: Validation loss decreased (0.195940 --> 0.192971).  Saving model ...
	 Train_Loss: 0.2270 Train_Acc: 92.270 Val_Loss: 0.1930  BEST VAL Loss: 0.1930  Val_Acc: 92.946

Epoch 6: Validation loss decreased (0.192971 --> 0.190054).  Saving model ...
	 Train_Loss: 0.2213 Train_Acc: 92.485 Val_Loss: 0.1901  BEST VAL Loss: 0.1901  Val_Acc: 93.561

Epoch 7: Validation loss decreased (0.190054 --> 0.187562).  Saving model ...
	 Train_Loss: 0.2166 Train_Acc: 92.603 Val_Loss: 0.1876  BEST VAL Loss: 0.1876  Val_Acc: 93.525

Epoch 8: Validation loss decreased (0.187562 --> 0.184808).  Saving model ...
	 Train_Loss: 0.2125 Train_Acc: 92.749 Val_Loss: 0.1848  BEST VAL Loss: 0.1848  Val_Acc: 93.702

Epoch 9: Validation loss decreased (0.184808 --> 0.182947).  Saving model ...
	 Train_Loss: 0.2089 Train_Acc: 92.869 Val_Loss: 0.1829  BEST VAL Loss: 0.1829  Val_Acc: 93.710

Epoch 10: Validation loss decreased (0.182947 --> 0.180744).  Saving model ...
	 Train_Loss: 0.2058 Train_Acc: 92.882 Val_Loss: 0.1807  BEST VAL Loss: 0.1807  Val_Acc: 93.844

Epoch 11: Validation loss decreased (0.180744 --> 0.178930).  Saving model ...
	 Train_Loss: 0.2031 Train_Acc: 93.035 Val_Loss: 0.1789  BEST VAL Loss: 0.1789  Val_Acc: 93.978

Epoch 12: Validation loss decreased (0.178930 --> 0.176942).  Saving model ...
	 Train_Loss: 0.2005 Train_Acc: 93.122 Val_Loss: 0.1769  BEST VAL Loss: 0.1769  Val_Acc: 94.077

Epoch 13: Validation loss decreased (0.176942 --> 0.175725).  Saving model ...
	 Train_Loss: 0.1982 Train_Acc: 93.159 Val_Loss: 0.1757  BEST VAL Loss: 0.1757  Val_Acc: 94.128

Epoch 14: Validation loss decreased (0.175725 --> 0.174283).  Saving model ...
	 Train_Loss: 0.1961 Train_Acc: 93.301 Val_Loss: 0.1743  BEST VAL Loss: 0.1743  Val_Acc: 94.207

Epoch 15: Validation loss decreased (0.174283 --> 0.172722).  Saving model ...
	 Train_Loss: 0.1941 Train_Acc: 93.392 Val_Loss: 0.1727  BEST VAL Loss: 0.1727  Val_Acc: 94.337

Epoch 16: Validation loss decreased (0.172722 --> 0.171480).  Saving model ...
	 Train_Loss: 0.1924 Train_Acc: 93.316 Val_Loss: 0.1715  BEST VAL Loss: 0.1715  Val_Acc: 94.140

Epoch 17: Validation loss decreased (0.171480 --> 0.170426).  Saving model ...
	 Train_Loss: 0.1908 Train_Acc: 93.442 Val_Loss: 0.1704  BEST VAL Loss: 0.1704  Val_Acc: 94.254

Epoch 18: Validation loss decreased (0.170426 --> 0.169487).  Saving model ...
	 Train_Loss: 0.1892 Train_Acc: 93.538 Val_Loss: 0.1695  BEST VAL Loss: 0.1695  Val_Acc: 94.132

Epoch 19: Validation loss decreased (0.169487 --> 0.168382).  Saving model ...
	 Train_Loss: 0.1878 Train_Acc: 93.535 Val_Loss: 0.1684  BEST VAL Loss: 0.1684  Val_Acc: 94.483

Epoch 20: Validation loss decreased (0.168382 --> 0.167557).  Saving model ...
	 Train_Loss: 0.1864 Train_Acc: 93.637 Val_Loss: 0.1676  BEST VAL Loss: 0.1676  Val_Acc: 94.282

Epoch 21: Validation loss decreased (0.167557 --> 0.166888).  Saving model ...
	 Train_Loss: 0.1850 Train_Acc: 93.572 Val_Loss: 0.1669  BEST VAL Loss: 0.1669  Val_Acc: 94.333

Epoch 22: Validation loss decreased (0.166888 --> 0.166002).  Saving model ...
	 Train_Loss: 0.1838 Train_Acc: 93.683 Val_Loss: 0.1660  BEST VAL Loss: 0.1660  Val_Acc: 94.554

Epoch 23: Validation loss decreased (0.166002 --> 0.165403).  Saving model ...
	 Train_Loss: 0.1826 Train_Acc: 93.679 Val_Loss: 0.1654  BEST VAL Loss: 0.1654  Val_Acc: 94.420

Epoch 24: Validation loss decreased (0.165403 --> 0.164700).  Saving model ...
	 Train_Loss: 0.1815 Train_Acc: 93.796 Val_Loss: 0.1647  BEST VAL Loss: 0.1647  Val_Acc: 94.483

Epoch 25: Validation loss decreased (0.164700 --> 0.163974).  Saving model ...
	 Train_Loss: 0.1804 Train_Acc: 93.784 Val_Loss: 0.1640  BEST VAL Loss: 0.1640  Val_Acc: 94.483

Epoch 26: Validation loss decreased (0.163974 --> 0.163437).  Saving model ...
	 Train_Loss: 0.1793 Train_Acc: 93.869 Val_Loss: 0.1634  BEST VAL Loss: 0.1634  Val_Acc: 94.601

Epoch 27: Validation loss decreased (0.163437 --> 0.162732).  Saving model ...
	 Train_Loss: 0.1783 Train_Acc: 93.914 Val_Loss: 0.1627  BEST VAL Loss: 0.1627  Val_Acc: 94.711

Epoch 28: Validation loss decreased (0.162732 --> 0.162079).  Saving model ...
	 Train_Loss: 0.1774 Train_Acc: 93.906 Val_Loss: 0.1621  BEST VAL Loss: 0.1621  Val_Acc: 94.629

Epoch 29: Validation loss decreased (0.162079 --> 0.161411).  Saving model ...
	 Train_Loss: 0.1765 Train_Acc: 93.903 Val_Loss: 0.1614  BEST VAL Loss: 0.1614  Val_Acc: 94.782

Epoch 30: Validation loss decreased (0.161411 --> 0.160835).  Saving model ...
	 Train_Loss: 0.1757 Train_Acc: 93.962 Val_Loss: 0.1608  BEST VAL Loss: 0.1608  Val_Acc: 94.727

Epoch 31: Validation loss decreased (0.160835 --> 0.160358).  Saving model ...
	 Train_Loss: 0.1748 Train_Acc: 94.023 Val_Loss: 0.1604  BEST VAL Loss: 0.1604  Val_Acc: 94.617

Epoch 32: Validation loss decreased (0.160358 --> 0.159747).  Saving model ...
	 Train_Loss: 0.1740 Train_Acc: 93.984 Val_Loss: 0.1597  BEST VAL Loss: 0.1597  Val_Acc: 94.727

Epoch 33: Validation loss decreased (0.159747 --> 0.159258).  Saving model ...
	 Train_Loss: 0.1732 Train_Acc: 94.041 Val_Loss: 0.1593  BEST VAL Loss: 0.1593  Val_Acc: 94.495

Epoch 34: Validation loss decreased (0.159258 --> 0.158700).  Saving model ...
	 Train_Loss: 0.1725 Train_Acc: 94.026 Val_Loss: 0.1587  BEST VAL Loss: 0.1587  Val_Acc: 94.794

Epoch 35: Validation loss decreased (0.158700 --> 0.158384).  Saving model ...
	 Train_Loss: 0.1718 Train_Acc: 93.976 Val_Loss: 0.1584  BEST VAL Loss: 0.1584  Val_Acc: 94.629

Epoch 36: Validation loss decreased (0.158384 --> 0.157871).  Saving model ...
	 Train_Loss: 0.1711 Train_Acc: 93.992 Val_Loss: 0.1579  BEST VAL Loss: 0.1579  Val_Acc: 94.841

Epoch 37: Validation loss decreased (0.157871 --> 0.157503).  Saving model ...
	 Train_Loss: 0.1705 Train_Acc: 94.081 Val_Loss: 0.1575  BEST VAL Loss: 0.1575  Val_Acc: 94.932

Epoch 38: Validation loss decreased (0.157503 --> 0.157109).  Saving model ...
	 Train_Loss: 0.1698 Train_Acc: 94.217 Val_Loss: 0.1571  BEST VAL Loss: 0.1571  Val_Acc: 94.960

Epoch 39: Validation loss decreased (0.157109 --> 0.156731).  Saving model ...
	 Train_Loss: 0.1692 Train_Acc: 94.137 Val_Loss: 0.1567  BEST VAL Loss: 0.1567  Val_Acc: 94.971

Epoch 40: Validation loss decreased (0.156731 --> 0.156449).  Saving model ...
	 Train_Loss: 0.1686 Train_Acc: 94.121 Val_Loss: 0.1564  BEST VAL Loss: 0.1564  Val_Acc: 94.696

Epoch 41: Validation loss decreased (0.156449 --> 0.156141).  Saving model ...
	 Train_Loss: 0.1680 Train_Acc: 94.204 Val_Loss: 0.1561  BEST VAL Loss: 0.1561  Val_Acc: 94.861

Epoch 42: Validation loss decreased (0.156141 --> 0.155842).  Saving model ...
	 Train_Loss: 0.1674 Train_Acc: 94.284 Val_Loss: 0.1558  BEST VAL Loss: 0.1558  Val_Acc: 94.822

Epoch 43: Validation loss decreased (0.155842 --> 0.155485).  Saving model ...
	 Train_Loss: 0.1669 Train_Acc: 94.093 Val_Loss: 0.1555  BEST VAL Loss: 0.1555  Val_Acc: 94.920

Epoch 44: Validation loss decreased (0.155485 --> 0.155208).  Saving model ...
	 Train_Loss: 0.1663 Train_Acc: 94.143 Val_Loss: 0.1552  BEST VAL Loss: 0.1552  Val_Acc: 95.019

Epoch 45: Validation loss decreased (0.155208 --> 0.154883).  Saving model ...
	 Train_Loss: 0.1658 Train_Acc: 94.255 Val_Loss: 0.1549  BEST VAL Loss: 0.1549  Val_Acc: 94.727

Epoch 46: Validation loss decreased (0.154883 --> 0.154702).  Saving model ...
	 Train_Loss: 0.1653 Train_Acc: 94.227 Val_Loss: 0.1547  BEST VAL Loss: 0.1547  Val_Acc: 94.696

Epoch 47: Validation loss decreased (0.154702 --> 0.154480).  Saving model ...
	 Train_Loss: 0.1648 Train_Acc: 94.226 Val_Loss: 0.1545  BEST VAL Loss: 0.1545  Val_Acc: 94.786

Epoch 48: Validation loss decreased (0.154480 --> 0.154142).  Saving model ...
	 Train_Loss: 0.1643 Train_Acc: 94.246 Val_Loss: 0.1541  BEST VAL Loss: 0.1541  Val_Acc: 94.964

Epoch 49: Validation loss decreased (0.154142 --> 0.153978).  Saving model ...
	 Train_Loss: 0.1638 Train_Acc: 94.281 Val_Loss: 0.1540  BEST VAL Loss: 0.1540  Val_Acc: 94.948

Epoch 50: Validation loss decreased (0.153978 --> 0.153847).  Saving model ...
	 Train_Loss: 0.1633 Train_Acc: 94.292 Val_Loss: 0.1538  BEST VAL Loss: 0.1538  Val_Acc: 94.605

Epoch 51: Validation loss decreased (0.153847 --> 0.153610).  Saving model ...
	 Train_Loss: 0.1629 Train_Acc: 94.281 Val_Loss: 0.1536  BEST VAL Loss: 0.1536  Val_Acc: 94.810

Epoch 52: Validation loss decreased (0.153610 --> 0.153317).  Saving model ...
	 Train_Loss: 0.1625 Train_Acc: 94.126 Val_Loss: 0.1533  BEST VAL Loss: 0.1533  Val_Acc: 94.818

Epoch 53: Validation loss decreased (0.153317 --> 0.153183).  Saving model ...
	 Train_Loss: 0.1620 Train_Acc: 94.294 Val_Loss: 0.1532  BEST VAL Loss: 0.1532  Val_Acc: 94.857

Epoch 54: Validation loss decreased (0.153183 --> 0.152920).  Saving model ...
	 Train_Loss: 0.1616 Train_Acc: 94.320 Val_Loss: 0.1529  BEST VAL Loss: 0.1529  Val_Acc: 94.956

Epoch 55: Validation loss decreased (0.152920 --> 0.152651).  Saving model ...
	 Train_Loss: 0.1612 Train_Acc: 94.344 Val_Loss: 0.1527  BEST VAL Loss: 0.1527  Val_Acc: 94.987

Epoch 56: Validation loss decreased (0.152651 --> 0.152414).  Saving model ...
	 Train_Loss: 0.1608 Train_Acc: 94.302 Val_Loss: 0.1524  BEST VAL Loss: 0.1524  Val_Acc: 95.058

Epoch 57: Validation loss decreased (0.152414 --> 0.152129).  Saving model ...
	 Train_Loss: 0.1604 Train_Acc: 94.351 Val_Loss: 0.1521  BEST VAL Loss: 0.1521  Val_Acc: 94.920

Epoch 58: Validation loss decreased (0.152129 --> 0.151996).  Saving model ...
	 Train_Loss: 0.1600 Train_Acc: 94.372 Val_Loss: 0.1520  BEST VAL Loss: 0.1520  Val_Acc: 94.763

Epoch 59: Validation loss decreased (0.151996 --> 0.151871).  Saving model ...
	 Train_Loss: 0.1596 Train_Acc: 94.288 Val_Loss: 0.1519  BEST VAL Loss: 0.1519  Val_Acc: 94.845

Epoch 60: Validation loss decreased (0.151871 --> 0.151622).  Saving model ...
	 Train_Loss: 0.1592 Train_Acc: 94.337 Val_Loss: 0.1516  BEST VAL Loss: 0.1516  Val_Acc: 94.928

Epoch 61: Validation loss decreased (0.151622 --> 0.151552).  Saving model ...
	 Train_Loss: 0.1589 Train_Acc: 94.392 Val_Loss: 0.1516  BEST VAL Loss: 0.1516  Val_Acc: 94.786

Epoch 62: Validation loss decreased (0.151552 --> 0.151393).  Saving model ...
	 Train_Loss: 0.1585 Train_Acc: 94.335 Val_Loss: 0.1514  BEST VAL Loss: 0.1514  Val_Acc: 95.216

Epoch 63: Validation loss decreased (0.151393 --> 0.151226).  Saving model ...
	 Train_Loss: 0.1581 Train_Acc: 94.344 Val_Loss: 0.1512  BEST VAL Loss: 0.1512  Val_Acc: 94.893

Epoch 64: Validation loss decreased (0.151226 --> 0.151010).  Saving model ...
	 Train_Loss: 0.1578 Train_Acc: 94.340 Val_Loss: 0.1510  BEST VAL Loss: 0.1510  Val_Acc: 95.161

Epoch 65: Validation loss decreased (0.151010 --> 0.150979).  Saving model ...
	 Train_Loss: 0.1575 Train_Acc: 94.459 Val_Loss: 0.1510  BEST VAL Loss: 0.1510  Val_Acc: 95.078

Epoch 66: Validation loss decreased (0.150979 --> 0.150858).  Saving model ...
	 Train_Loss: 0.1571 Train_Acc: 94.348 Val_Loss: 0.1509  BEST VAL Loss: 0.1509  Val_Acc: 95.153

Epoch 67: Validation loss decreased (0.150858 --> 0.150641).  Saving model ...
	 Train_Loss: 0.1568 Train_Acc: 94.441 Val_Loss: 0.1506  BEST VAL Loss: 0.1506  Val_Acc: 95.101

Epoch 68: Validation loss decreased (0.150641 --> 0.150509).  Saving model ...
	 Train_Loss: 0.1565 Train_Acc: 94.420 Val_Loss: 0.1505  BEST VAL Loss: 0.1505  Val_Acc: 94.806

Epoch 69: Validation loss decreased (0.150509 --> 0.150372).  Saving model ...
	 Train_Loss: 0.1562 Train_Acc: 94.427 Val_Loss: 0.1504  BEST VAL Loss: 0.1504  Val_Acc: 95.074

Epoch 70: Validation loss decreased (0.150372 --> 0.150246).  Saving model ...
	 Train_Loss: 0.1559 Train_Acc: 94.435 Val_Loss: 0.1502  BEST VAL Loss: 0.1502  Val_Acc: 94.853

Epoch 71: Validation loss decreased (0.150246 --> 0.150149).  Saving model ...
	 Train_Loss: 0.1556 Train_Acc: 94.287 Val_Loss: 0.1501  BEST VAL Loss: 0.1501  Val_Acc: 95.031

Epoch 72: Validation loss decreased (0.150149 --> 0.149987).  Saving model ...
	 Train_Loss: 0.1553 Train_Acc: 94.345 Val_Loss: 0.1500  BEST VAL Loss: 0.1500  Val_Acc: 95.129

Epoch 73: Validation loss decreased (0.149987 --> 0.149907).  Saving model ...
	 Train_Loss: 0.1551 Train_Acc: 94.582 Val_Loss: 0.1499  BEST VAL Loss: 0.1499  Val_Acc: 95.157

Epoch 74: Validation loss decreased (0.149907 --> 0.149738).  Saving model ...
	 Train_Loss: 0.1548 Train_Acc: 94.436 Val_Loss: 0.1497  BEST VAL Loss: 0.1497  Val_Acc: 95.314

Epoch 75: Validation loss decreased (0.149738 --> 0.149605).  Saving model ...
	 Train_Loss: 0.1545 Train_Acc: 94.459 Val_Loss: 0.1496  BEST VAL Loss: 0.1496  Val_Acc: 95.098

Epoch 76: Validation loss decreased (0.149605 --> 0.149535).  Saving model ...
	 Train_Loss: 0.1542 Train_Acc: 94.407 Val_Loss: 0.1495  BEST VAL Loss: 0.1495  Val_Acc: 95.180

Epoch 77: Validation loss decreased (0.149535 --> 0.149419).  Saving model ...
	 Train_Loss: 0.1539 Train_Acc: 94.542 Val_Loss: 0.1494  BEST VAL Loss: 0.1494  Val_Acc: 94.897

Epoch 78: Validation loss decreased (0.149419 --> 0.149270).  Saving model ...
	 Train_Loss: 0.1537 Train_Acc: 94.486 Val_Loss: 0.1493  BEST VAL Loss: 0.1493  Val_Acc: 95.074

Epoch 79: Validation loss decreased (0.149270 --> 0.149232).  Saving model ...
	 Train_Loss: 0.1534 Train_Acc: 94.389 Val_Loss: 0.1492  BEST VAL Loss: 0.1492  Val_Acc: 94.786

Epoch 80: Validation loss decreased (0.149232 --> 0.149146).  Saving model ...
	 Train_Loss: 0.1531 Train_Acc: 94.512 Val_Loss: 0.1491  BEST VAL Loss: 0.1491  Val_Acc: 95.168

Epoch 81: Validation loss decreased (0.149146 --> 0.148984).  Saving model ...
	 Train_Loss: 0.1529 Train_Acc: 94.590 Val_Loss: 0.1490  BEST VAL Loss: 0.1490  Val_Acc: 95.165

Epoch 82: Validation loss decreased (0.148984 --> 0.148882).  Saving model ...
	 Train_Loss: 0.1526 Train_Acc: 94.476 Val_Loss: 0.1489  BEST VAL Loss: 0.1489  Val_Acc: 95.129

Epoch 83: Validation loss decreased (0.148882 --> 0.148718).  Saving model ...
	 Train_Loss: 0.1524 Train_Acc: 94.465 Val_Loss: 0.1487  BEST VAL Loss: 0.1487  Val_Acc: 95.291

Epoch 84: Validation loss decreased (0.148718 --> 0.148663).  Saving model ...
	 Train_Loss: 0.1521 Train_Acc: 94.573 Val_Loss: 0.1487  BEST VAL Loss: 0.1487  Val_Acc: 94.991

Epoch 85: Validation loss decreased (0.148663 --> 0.148570).  Saving model ...
	 Train_Loss: 0.1519 Train_Acc: 94.482 Val_Loss: 0.1486  BEST VAL Loss: 0.1486  Val_Acc: 95.224

Epoch 86: Validation loss decreased (0.148570 --> 0.148508).  Saving model ...
	 Train_Loss: 0.1517 Train_Acc: 94.508 Val_Loss: 0.1485  BEST VAL Loss: 0.1485  Val_Acc: 94.944

Epoch 87: Validation loss decreased (0.148508 --> 0.148409).  Saving model ...
	 Train_Loss: 0.1514 Train_Acc: 94.490 Val_Loss: 0.1484  BEST VAL Loss: 0.1484  Val_Acc: 95.070

Epoch 88: Validation loss decreased (0.148409 --> 0.148319).  Saving model ...
	 Train_Loss: 0.1512 Train_Acc: 94.459 Val_Loss: 0.1483  BEST VAL Loss: 0.1483  Val_Acc: 95.137

Epoch 89: Validation loss decreased (0.148319 --> 0.148243).  Saving model ...
	 Train_Loss: 0.1510 Train_Acc: 94.518 Val_Loss: 0.1482  BEST VAL Loss: 0.1482  Val_Acc: 95.003

Epoch 90: Validation loss decreased (0.148243 --> 0.148181).  Saving model ...
	 Train_Loss: 0.1508 Train_Acc: 94.464 Val_Loss: 0.1482  BEST VAL Loss: 0.1482  Val_Acc: 95.145

Epoch 91: Validation loss decreased (0.148181 --> 0.148077).  Saving model ...
	 Train_Loss: 0.1506 Train_Acc: 94.545 Val_Loss: 0.1481  BEST VAL Loss: 0.1481  Val_Acc: 95.220

Epoch 92: Validation loss decreased (0.148077 --> 0.148052).  Saving model ...
	 Train_Loss: 0.1503 Train_Acc: 94.594 Val_Loss: 0.1481  BEST VAL Loss: 0.1481  Val_Acc: 94.731

Epoch 93: Validation loss decreased (0.148052 --> 0.147949).  Saving model ...
	 Train_Loss: 0.1501 Train_Acc: 94.555 Val_Loss: 0.1479  BEST VAL Loss: 0.1479  Val_Acc: 95.228

Epoch 94: Validation loss decreased (0.147949 --> 0.147846).  Saving model ...
	 Train_Loss: 0.1499 Train_Acc: 94.582 Val_Loss: 0.1478  BEST VAL Loss: 0.1478  Val_Acc: 95.066

Epoch 95: Validation loss decreased (0.147846 --> 0.147752).  Saving model ...
	 Train_Loss: 0.1497 Train_Acc: 94.445 Val_Loss: 0.1478  BEST VAL Loss: 0.1478  Val_Acc: 95.263

Epoch 96: Validation loss decreased (0.147752 --> 0.147682).  Saving model ...
	 Train_Loss: 0.1495 Train_Acc: 94.467 Val_Loss: 0.1477  BEST VAL Loss: 0.1477  Val_Acc: 95.141

Epoch 97: Validation loss decreased (0.147682 --> 0.147640).  Saving model ...
	 Train_Loss: 0.1493 Train_Acc: 94.500 Val_Loss: 0.1476  BEST VAL Loss: 0.1476  Val_Acc: 95.062

Epoch 98: Validation loss decreased (0.147640 --> 0.147560).  Saving model ...
	 Train_Loss: 0.1491 Train_Acc: 94.481 Val_Loss: 0.1476  BEST VAL Loss: 0.1476  Val_Acc: 95.098

Epoch 99: Validation loss decreased (0.147560 --> 0.147460).  Saving model ...
	 Train_Loss: 0.1489 Train_Acc: 94.466 Val_Loss: 0.1475  BEST VAL Loss: 0.1475  Val_Acc: 95.007

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.49      0.49     97753
           1       0.52      0.51      0.51    105241

    accuracy                           0.50    202994
   macro avg       0.50      0.50      0.50    202994
weighted avg       0.50      0.50      0.50    202994

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.49      0.49     12219
           1       0.52      0.51      0.52     13156

    accuracy                           0.50     25375
   macro avg       0.50      0.50      0.50     25375
weighted avg       0.50      0.50      0.50     25375

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.49      0.49     12220
           1       0.52      0.51      0.51     13155

    accuracy                           0.50     25375
   macro avg       0.50      0.50      0.50     25375
weighted avg       0.50      0.50      0.50     25375

              precision    recall  f1-score   support

           0       0.48      0.49      0.49     12220
           1       0.52      0.51      0.51     13155

    accuracy                           0.50     25375
   macro avg       0.50      0.50      0.50     25375
weighted avg       0.50      0.50      0.50     25375

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.43      0.36      0.39     37243
           1       0.57      0.65      0.61     49614

    accuracy                           0.52     86857
   macro avg       0.50      0.50      0.50     86857
weighted avg       0.51      0.52      0.51     86857

              precision    recall  f1-score   support

           0       0.43      0.36      0.39     37243
           1       0.57      0.65      0.61     49614

    accuracy                           0.52     86857
   macro avg       0.50      0.50      0.50     86857
weighted avg       0.51      0.52      0.51     86857

completed
