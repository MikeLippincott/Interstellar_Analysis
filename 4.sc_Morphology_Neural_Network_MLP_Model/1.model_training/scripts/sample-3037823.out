[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'efeb6084'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'fbad0867'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '992c2220'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'd75346e2'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_100.000_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_100.000_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_100.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (30915, 1276)
Number of total missing values across all columns: 61830
Data Subset Is Off
Wells held out for testing: ['J16' 'L22']
Wells to use for training, validation, and testing ['J17' 'L18' 'L19' 'J20' 'J21' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.621755).  Saving model ...
	 Train_Loss: 0.9311 Train_Acc: 58.255 Val_Loss: 0.6218  BEST VAL Loss: 0.6218  Val_Acc: 64.859

Epoch 1: Validation loss decreased (0.621755 --> 0.573300).  Saving model ...
	 Train_Loss: 0.7630 Train_Acc: 67.268 Val_Loss: 0.5733  BEST VAL Loss: 0.5733  Val_Acc: 73.986

Epoch 2: Validation loss decreased (0.573300 --> 0.532122).  Saving model ...
	 Train_Loss: 0.6826 Train_Acc: 74.698 Val_Loss: 0.5321  BEST VAL Loss: 0.5321  Val_Acc: 80.820

Epoch 3: Validation loss decreased (0.532122 --> 0.499810).  Saving model ...
	 Train_Loss: 0.6259 Train_Acc: 79.566 Val_Loss: 0.4998  BEST VAL Loss: 0.4998  Val_Acc: 84.788

Epoch 4: Validation loss decreased (0.499810 --> 0.475004).  Saving model ...
	 Train_Loss: 0.5836 Train_Acc: 82.239 Val_Loss: 0.4750  BEST VAL Loss: 0.4750  Val_Acc: 85.494

Epoch 5: Validation loss decreased (0.475004 --> 0.450609).  Saving model ...
	 Train_Loss: 0.5500 Train_Acc: 84.345 Val_Loss: 0.4506  BEST VAL Loss: 0.4506  Val_Acc: 88.668

Epoch 6: Validation loss decreased (0.450609 --> 0.432474).  Saving model ...
	 Train_Loss: 0.5208 Train_Acc: 86.489 Val_Loss: 0.4325  BEST VAL Loss: 0.4325  Val_Acc: 88.492

Epoch 7: Validation loss decreased (0.432474 --> 0.411088).  Saving model ...
	 Train_Loss: 0.4961 Train_Acc: 87.674 Val_Loss: 0.4111  BEST VAL Loss: 0.4111  Val_Acc: 90.520

Epoch 8: Validation loss decreased (0.411088 --> 0.397610).  Saving model ...
	 Train_Loss: 0.4726 Train_Acc: 89.626 Val_Loss: 0.3976  BEST VAL Loss: 0.3976  Val_Acc: 90.256

Epoch 9: Validation loss decreased (0.397610 --> 0.384427).  Saving model ...
	 Train_Loss: 0.4530 Train_Acc: 90.243 Val_Loss: 0.3844  BEST VAL Loss: 0.3844  Val_Acc: 90.300

Epoch 10: Validation loss decreased (0.384427 --> 0.374443).  Saving model ...
	 Train_Loss: 0.4360 Train_Acc: 90.475 Val_Loss: 0.3744  BEST VAL Loss: 0.3744  Val_Acc: 91.887

Epoch 11: Validation loss decreased (0.374443 --> 0.367431).  Saving model ...
	 Train_Loss: 0.4215 Train_Acc: 90.888 Val_Loss: 0.3674  BEST VAL Loss: 0.3674  Val_Acc: 91.182

Epoch 12: Validation loss decreased (0.367431 --> 0.357078).  Saving model ...
	 Train_Loss: 0.4086 Train_Acc: 91.009 Val_Loss: 0.3571  BEST VAL Loss: 0.3571  Val_Acc: 92.989

Epoch 13: Validation loss decreased (0.357078 --> 0.351942).  Saving model ...
	 Train_Loss: 0.3964 Train_Acc: 91.935 Val_Loss: 0.3519  BEST VAL Loss: 0.3519  Val_Acc: 91.799

Epoch 14: Validation loss decreased (0.351942 --> 0.345354).  Saving model ...
	 Train_Loss: 0.3862 Train_Acc: 91.825 Val_Loss: 0.3454  BEST VAL Loss: 0.3454  Val_Acc: 91.226

Epoch 15: Validation loss decreased (0.345354 --> 0.337772).  Saving model ...
	 Train_Loss: 0.3764 Train_Acc: 92.051 Val_Loss: 0.3378  BEST VAL Loss: 0.3378  Val_Acc: 92.240

Epoch 16: Validation loss decreased (0.337772 --> 0.331494).  Saving model ...
	 Train_Loss: 0.3668 Train_Acc: 92.806 Val_Loss: 0.3315  BEST VAL Loss: 0.3315  Val_Acc: 92.989

Epoch 17: Validation loss decreased (0.331494 --> 0.328400).  Saving model ...
	 Train_Loss: 0.3582 Train_Acc: 93.154 Val_Loss: 0.3284  BEST VAL Loss: 0.3284  Val_Acc: 92.196

Epoch 18: Validation loss decreased (0.328400 --> 0.322521).  Saving model ...
	 Train_Loss: 0.3499 Train_Acc: 93.484 Val_Loss: 0.3225  BEST VAL Loss: 0.3225  Val_Acc: 93.386

Epoch 19: Validation loss decreased (0.322521 --> 0.318170).  Saving model ...
	 Train_Loss: 0.3427 Train_Acc: 93.325 Val_Loss: 0.3182  BEST VAL Loss: 0.3182  Val_Acc: 93.519

Epoch 20: Validation loss decreased (0.318170 --> 0.314414).  Saving model ...
	 Train_Loss: 0.3356 Train_Acc: 93.650 Val_Loss: 0.3144  BEST VAL Loss: 0.3144  Val_Acc: 94.136

Epoch 21: Validation loss decreased (0.314414 --> 0.310748).  Saving model ...
	 Train_Loss: 0.3292 Train_Acc: 93.826 Val_Loss: 0.3107  BEST VAL Loss: 0.3107  Val_Acc: 92.769

Epoch 22: Validation loss did not decrease
	 Train_Loss: 0.3232 Train_Acc: 93.947 Val_Loss: 0.3148  BEST VAL Loss: 0.3107  Val_Acc: 92.284

Epoch 23: Validation loss did not decrease
	 Train_Loss: 0.3180 Train_Acc: 93.655 Val_Loss: 0.3147  BEST VAL Loss: 0.3107  Val_Acc: 92.769

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.3130 Train_Acc: 93.898 Val_Loss: 0.3118  BEST VAL Loss: 0.3107  Val_Acc: 93.915

Epoch 25: Validation loss decreased (0.310748 --> 0.308652).  Saving model ...
	 Train_Loss: 0.3080 Train_Acc: 94.157 Val_Loss: 0.3087  BEST VAL Loss: 0.3087  Val_Acc: 93.474

Epoch 26: Validation loss decreased (0.308652 --> 0.305073).  Saving model ...
	 Train_Loss: 0.3034 Train_Acc: 94.173 Val_Loss: 0.3051  BEST VAL Loss: 0.3051  Val_Acc: 93.959

Epoch 27: Validation loss decreased (0.305073 --> 0.303265).  Saving model ...
	 Train_Loss: 0.2992 Train_Acc: 94.306 Val_Loss: 0.3033  BEST VAL Loss: 0.3033  Val_Acc: 93.871

Epoch 28: Validation loss decreased (0.303265 --> 0.300563).  Saving model ...
	 Train_Loss: 0.2952 Train_Acc: 94.532 Val_Loss: 0.3006  BEST VAL Loss: 0.3006  Val_Acc: 94.136

Epoch 29: Validation loss decreased (0.300563 --> 0.298831).  Saving model ...
	 Train_Loss: 0.2912 Train_Acc: 94.306 Val_Loss: 0.2988  BEST VAL Loss: 0.2988  Val_Acc: 93.871

Epoch 30: Validation loss decreased (0.298831 --> 0.297609).  Saving model ...
	 Train_Loss: 0.2870 Train_Acc: 94.890 Val_Loss: 0.2976  BEST VAL Loss: 0.2976  Val_Acc: 94.136

Epoch 31: Validation loss decreased (0.297609 --> 0.297128).  Saving model ...
	 Train_Loss: 0.2832 Train_Acc: 94.962 Val_Loss: 0.2971  BEST VAL Loss: 0.2971  Val_Acc: 94.312

Epoch 32: Validation loss decreased (0.297128 --> 0.296914).  Saving model ...
	 Train_Loss: 0.2796 Train_Acc: 95.055 Val_Loss: 0.2969  BEST VAL Loss: 0.2969  Val_Acc: 93.474

Epoch 33: Validation loss decreased (0.296914 --> 0.295960).  Saving model ...
	 Train_Loss: 0.2763 Train_Acc: 94.923 Val_Loss: 0.2960  BEST VAL Loss: 0.2960  Val_Acc: 94.004

Epoch 34: Validation loss decreased (0.295960 --> 0.295020).  Saving model ...
	 Train_Loss: 0.2730 Train_Acc: 95.441 Val_Loss: 0.2950  BEST VAL Loss: 0.2950  Val_Acc: 89.815

Epoch 35: Validation loss decreased (0.295020 --> 0.294921).  Saving model ...
	 Train_Loss: 0.2710 Train_Acc: 93.716 Val_Loss: 0.2949  BEST VAL Loss: 0.2949  Val_Acc: 93.519

Epoch 36: Validation loss decreased (0.294921 --> 0.294151).  Saving model ...
	 Train_Loss: 0.2682 Train_Acc: 95.248 Val_Loss: 0.2942  BEST VAL Loss: 0.2942  Val_Acc: 93.607

Epoch 37: Validation loss decreased (0.294151 --> 0.293425).  Saving model ...
	 Train_Loss: 0.2656 Train_Acc: 94.714 Val_Loss: 0.2934  BEST VAL Loss: 0.2934  Val_Acc: 94.312

Epoch 38: Validation loss decreased (0.293425 --> 0.292355).  Saving model ...
	 Train_Loss: 0.2627 Train_Acc: 95.480 Val_Loss: 0.2924  BEST VAL Loss: 0.2924  Val_Acc: 94.400

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.2599 Train_Acc: 95.430 Val_Loss: 0.2933  BEST VAL Loss: 0.2924  Val_Acc: 93.959

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.2579 Train_Acc: 94.670 Val_Loss: 0.2958  BEST VAL Loss: 0.2924  Val_Acc: 93.210

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.2558 Train_Acc: 94.818 Val_Loss: 0.2948  BEST VAL Loss: 0.2924  Val_Acc: 94.092

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.2533 Train_Acc: 95.651 Val_Loss: 0.2933  BEST VAL Loss: 0.2924  Val_Acc: 93.959

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.2511 Train_Acc: 95.270 Val_Loss: 0.3018  BEST VAL Loss: 0.2924  Val_Acc: 86.684

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.2505 Train_Acc: 93.396 Val_Loss: 0.3030  BEST VAL Loss: 0.2924  Val_Acc: 93.563

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.2484 Train_Acc: 95.480 Val_Loss: 0.3028  BEST VAL Loss: 0.2924  Val_Acc: 94.048

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.2466 Train_Acc: 95.215 Val_Loss: 0.3012  BEST VAL Loss: 0.2924  Val_Acc: 93.959

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.2445 Train_Acc: 95.700 Val_Loss: 0.3008  BEST VAL Loss: 0.2924  Val_Acc: 94.489

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.2425 Train_Acc: 95.667 Val_Loss: 0.3006  BEST VAL Loss: 0.2924  Val_Acc: 94.577

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.2404 Train_Acc: 95.833 Val_Loss: 0.3007  BEST VAL Loss: 0.2924  Val_Acc: 94.312

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.2385 Train_Acc: 95.827 Val_Loss: 0.3003  BEST VAL Loss: 0.2924  Val_Acc: 94.136

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.2366 Train_Acc: 95.965 Val_Loss: 0.2996  BEST VAL Loss: 0.2924  Val_Acc: 94.136

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.2350 Train_Acc: 95.618 Val_Loss: 0.2985  BEST VAL Loss: 0.2924  Val_Acc: 94.312

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.2333 Train_Acc: 95.678 Val_Loss: 0.2975  BEST VAL Loss: 0.2924  Val_Acc: 93.739

Epoch 54: Validation loss did not decrease
Early stopped at epoch : 54
LPS_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.47      0.47      8635
           1       0.53      0.54      0.53      9506

    accuracy                           0.51     18141
   macro avg       0.50      0.50      0.50     18141
weighted avg       0.50      0.51      0.50     18141

LPS_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.47      0.47      1079
           1       0.53      0.53      0.53      1189

    accuracy                           0.50      2268
   macro avg       0.50      0.50      0.50      2268
weighted avg       0.50      0.50      0.50      2268

LPS_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.48      0.48      1079
           1       0.54      0.54      0.54      1189

    accuracy                           0.51      2268
   macro avg       0.51      0.51      0.51      2268
weighted avg       0.51      0.51      0.51      2268

              precision    recall  f1-score   support

           0       0.49      0.48      0.48      1079
           1       0.54      0.54      0.54      1189

    accuracy                           0.51      2268
   macro avg       0.51      0.51      0.51      2268
weighted avg       0.51      0.51      0.51      2268

LPS_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.46      0.48      4135
           1       0.50      0.54      0.52      4103

    accuracy                           0.50      8238
   macro avg       0.50      0.50      0.50      8238
weighted avg       0.50      0.50      0.50      8238

              precision    recall  f1-score   support

           0       0.50      0.46      0.48      4135
           1       0.50      0.54      0.52      4103

    accuracy                           0.50      8238
   macro avg       0.50      0.50      0.50      8238
weighted avg       0.50      0.50      0.50      8238

completed
