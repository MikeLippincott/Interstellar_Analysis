[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '114a32c9'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '4507e33e'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '77f81620'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'aa739ae2'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_0.010_DMSO_0.025 treatment_name: LPS_10.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_0.010_DMSO_0.025
TREATMENT_NAME: LPS_10.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_10.000_DMSO_0.025']
The dimensions of the data are: (32669, 1276)
Number of total missing values across all columns: 65338
Data Subset Is Off
Wells held out for testing: ['B20' 'E21']
Wells to use for training, validation, and testing ['B16' 'E16' 'B17' 'E17' 'E20' 'B21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.597427).  Saving model ...
	 Train_Loss: 0.6605 Train_Acc: 61.455 Val_Loss: 0.5974  BEST VAL Loss: 0.5974  Val_Acc: 66.828

Epoch 1: Validation loss decreased (0.597427 --> 0.577433).  Saving model ...
	 Train_Loss: 0.6283 Train_Acc: 67.736 Val_Loss: 0.5774  BEST VAL Loss: 0.5774  Val_Acc: 70.258

Epoch 2: Validation loss decreased (0.577433 --> 0.561771).  Saving model ...
	 Train_Loss: 0.6066 Train_Acc: 69.981 Val_Loss: 0.5618  BEST VAL Loss: 0.5618  Val_Acc: 72.115

Epoch 3: Validation loss decreased (0.561771 --> 0.549577).  Saving model ...
	 Train_Loss: 0.5920 Train_Acc: 72.060 Val_Loss: 0.5496  BEST VAL Loss: 0.5496  Val_Acc: 73.850

Epoch 4: Validation loss decreased (0.549577 --> 0.541512).  Saving model ...
	 Train_Loss: 0.5802 Train_Acc: 72.832 Val_Loss: 0.5415  BEST VAL Loss: 0.5415  Val_Acc: 74.173

Epoch 5: Validation loss decreased (0.541512 --> 0.533188).  Saving model ...
	 Train_Loss: 0.5702 Train_Acc: 73.775 Val_Loss: 0.5332  BEST VAL Loss: 0.5332  Val_Acc: 75.020

Epoch 6: Validation loss decreased (0.533188 --> 0.526631).  Saving model ...
	 Train_Loss: 0.5611 Train_Acc: 74.487 Val_Loss: 0.5266  BEST VAL Loss: 0.5266  Val_Acc: 75.101

Epoch 7: Validation loss decreased (0.526631 --> 0.521539).  Saving model ...
	 Train_Loss: 0.5534 Train_Acc: 75.032 Val_Loss: 0.5215  BEST VAL Loss: 0.5215  Val_Acc: 74.697

Epoch 8: Validation loss decreased (0.521539 --> 0.515953).  Saving model ...
	 Train_Loss: 0.5462 Train_Acc: 75.960 Val_Loss: 0.5160  BEST VAL Loss: 0.5160  Val_Acc: 76.392

Epoch 9: Validation loss decreased (0.515953 --> 0.511908).  Saving model ...
	 Train_Loss: 0.5400 Train_Acc: 75.773 Val_Loss: 0.5119  BEST VAL Loss: 0.5119  Val_Acc: 76.634

Epoch 10: Validation loss decreased (0.511908 --> 0.508489).  Saving model ...
	 Train_Loss: 0.5346 Train_Acc: 76.121 Val_Loss: 0.5085  BEST VAL Loss: 0.5085  Val_Acc: 76.554

Epoch 11: Validation loss decreased (0.508489 --> 0.505144).  Saving model ...
	 Train_Loss: 0.5297 Train_Acc: 76.691 Val_Loss: 0.5051  BEST VAL Loss: 0.5051  Val_Acc: 76.675

Epoch 12: Validation loss decreased (0.505144 --> 0.502701).  Saving model ...
	 Train_Loss: 0.5253 Train_Acc: 76.560 Val_Loss: 0.5027  BEST VAL Loss: 0.5027  Val_Acc: 75.868

Epoch 13: Validation loss decreased (0.502701 --> 0.499901).  Saving model ...
	 Train_Loss: 0.5212 Train_Acc: 76.757 Val_Loss: 0.4999  BEST VAL Loss: 0.4999  Val_Acc: 76.433

Epoch 14: Validation loss decreased (0.499901 --> 0.498018).  Saving model ...
	 Train_Loss: 0.5176 Train_Acc: 76.777 Val_Loss: 0.4980  BEST VAL Loss: 0.4980  Val_Acc: 75.706

Epoch 15: Validation loss decreased (0.498018 --> 0.496102).  Saving model ...
	 Train_Loss: 0.5143 Train_Acc: 76.949 Val_Loss: 0.4961  BEST VAL Loss: 0.4961  Val_Acc: 76.715

Epoch 16: Validation loss decreased (0.496102 --> 0.494644).  Saving model ...
	 Train_Loss: 0.5109 Train_Acc: 77.463 Val_Loss: 0.4946  BEST VAL Loss: 0.4946  Val_Acc: 75.989

Epoch 17: Validation loss decreased (0.494644 --> 0.493280).  Saving model ...
	 Train_Loss: 0.5077 Train_Acc: 77.544 Val_Loss: 0.4933  BEST VAL Loss: 0.4933  Val_Acc: 77.159

Epoch 18: Validation loss decreased (0.493280 --> 0.491732).  Saving model ...
	 Train_Loss: 0.5047 Train_Acc: 77.887 Val_Loss: 0.4917  BEST VAL Loss: 0.4917  Val_Acc: 77.240

Epoch 19: Validation loss decreased (0.491732 --> 0.490951).  Saving model ...
	 Train_Loss: 0.5015 Train_Acc: 78.387 Val_Loss: 0.4910  BEST VAL Loss: 0.4910  Val_Acc: 76.029

Epoch 20: Validation loss decreased (0.490951 --> 0.489795).  Saving model ...
	 Train_Loss: 0.4986 Train_Acc: 78.240 Val_Loss: 0.4898  BEST VAL Loss: 0.4898  Val_Acc: 77.805

Epoch 21: Validation loss decreased (0.489795 --> 0.488749).  Saving model ...
	 Train_Loss: 0.4958 Train_Acc: 78.523 Val_Loss: 0.4887  BEST VAL Loss: 0.4887  Val_Acc: 77.563

Epoch 22: Validation loss decreased (0.488749 --> 0.487956).  Saving model ...
	 Train_Loss: 0.4929 Train_Acc: 78.825 Val_Loss: 0.4880  BEST VAL Loss: 0.4880  Val_Acc: 76.554

Epoch 23: Validation loss decreased (0.487956 --> 0.487142).  Saving model ...
	 Train_Loss: 0.4903 Train_Acc: 78.896 Val_Loss: 0.4871  BEST VAL Loss: 0.4871  Val_Acc: 76.917

Epoch 24: Validation loss decreased (0.487142 --> 0.486096).  Saving model ...
	 Train_Loss: 0.4880 Train_Acc: 78.851 Val_Loss: 0.4861  BEST VAL Loss: 0.4861  Val_Acc: 77.361

Epoch 25: Validation loss decreased (0.486096 --> 0.485165).  Saving model ...
	 Train_Loss: 0.4854 Train_Acc: 79.386 Val_Loss: 0.4852  BEST VAL Loss: 0.4852  Val_Acc: 77.401

Epoch 26: Validation loss decreased (0.485165 --> 0.484303).  Saving model ...
	 Train_Loss: 0.4830 Train_Acc: 79.239 Val_Loss: 0.4843  BEST VAL Loss: 0.4843  Val_Acc: 77.522

Epoch 27: Validation loss decreased (0.484303 --> 0.483813).  Saving model ...
	 Train_Loss: 0.4806 Train_Acc: 79.547 Val_Loss: 0.4838  BEST VAL Loss: 0.4838  Val_Acc: 77.563

Epoch 28: Validation loss decreased (0.483813 --> 0.482770).  Saving model ...
	 Train_Loss: 0.4783 Train_Acc: 79.557 Val_Loss: 0.4828  BEST VAL Loss: 0.4828  Val_Acc: 78.128

Epoch 29: Validation loss decreased (0.482770 --> 0.482275).  Saving model ...
	 Train_Loss: 0.4762 Train_Acc: 79.416 Val_Loss: 0.4823  BEST VAL Loss: 0.4823  Val_Acc: 77.401

Epoch 30: Validation loss decreased (0.482275 --> 0.481738).  Saving model ...
	 Train_Loss: 0.4741 Train_Acc: 79.951 Val_Loss: 0.4817  BEST VAL Loss: 0.4817  Val_Acc: 77.684

Epoch 31: Validation loss decreased (0.481738 --> 0.481232).  Saving model ...
	 Train_Loss: 0.4720 Train_Acc: 79.597 Val_Loss: 0.4812  BEST VAL Loss: 0.4812  Val_Acc: 77.320

Epoch 32: Validation loss decreased (0.481232 --> 0.480969).  Saving model ...
	 Train_Loss: 0.4700 Train_Acc: 80.021 Val_Loss: 0.4810  BEST VAL Loss: 0.4810  Val_Acc: 76.755

Epoch 33: Validation loss decreased (0.480969 --> 0.480715).  Saving model ...
	 Train_Loss: 0.4680 Train_Acc: 79.915 Val_Loss: 0.4807  BEST VAL Loss: 0.4807  Val_Acc: 77.280

Epoch 34: Validation loss did not decrease
	 Train_Loss: 0.4659 Train_Acc: 80.379 Val_Loss: 0.4810  BEST VAL Loss: 0.4807  Val_Acc: 76.271

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.4641 Train_Acc: 80.223 Val_Loss: 0.4809  BEST VAL Loss: 0.4807  Val_Acc: 76.634

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.4624 Train_Acc: 79.764 Val_Loss: 0.4810  BEST VAL Loss: 0.4807  Val_Acc: 77.038

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.4608 Train_Acc: 79.552 Val_Loss: 0.4811  BEST VAL Loss: 0.4807  Val_Acc: 76.554

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.4592 Train_Acc: 80.077 Val_Loss: 0.4811  BEST VAL Loss: 0.4807  Val_Acc: 75.747

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.4577 Train_Acc: 80.051 Val_Loss: 0.4813  BEST VAL Loss: 0.4807  Val_Acc: 76.755

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.4560 Train_Acc: 80.299 Val_Loss: 0.4815  BEST VAL Loss: 0.4807  Val_Acc: 77.038

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.4545 Train_Acc: 80.627 Val_Loss: 0.4819  BEST VAL Loss: 0.4807  Val_Acc: 75.827

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.4530 Train_Acc: 80.178 Val_Loss: 0.4823  BEST VAL Loss: 0.4807  Val_Acc: 76.917

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.4517 Train_Acc: 80.425 Val_Loss: 0.4826  BEST VAL Loss: 0.4807  Val_Acc: 76.190

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.4504 Train_Acc: 80.016 Val_Loss: 0.4827  BEST VAL Loss: 0.4807  Val_Acc: 76.473

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.4493 Train_Acc: 79.920 Val_Loss: 0.4828  BEST VAL Loss: 0.4807  Val_Acc: 76.877

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.4479 Train_Acc: 80.551 Val_Loss: 0.4831  BEST VAL Loss: 0.4807  Val_Acc: 76.796

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.4465 Train_Acc: 80.506 Val_Loss: 0.4833  BEST VAL Loss: 0.4807  Val_Acc: 76.594

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.4450 Train_Acc: 81.212 Val_Loss: 0.4836  BEST VAL Loss: 0.4807  Val_Acc: 76.755

Epoch 49: Validation loss did not decrease
Early stopped at epoch : 49
LPS_0.010_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.84      0.87      0.86      9707
           1       0.87      0.84      0.86     10114

    accuracy                           0.86     19821
   macro avg       0.86      0.86      0.86     19821
weighted avg       0.86      0.86      0.86     19821

LPS_0.010_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.76      0.78      0.77      1214
           1       0.78      0.77      0.78      1264

    accuracy                           0.77      2478
   macro avg       0.77      0.77      0.77      2478
weighted avg       0.77      0.77      0.77      2478

LPS_0.010_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.77      0.79      0.78      1214
           1       0.79      0.78      0.79      1264

    accuracy                           0.78      2478
   macro avg       0.78      0.78      0.78      2478
weighted avg       0.78      0.78      0.78      2478

              precision    recall  f1-score   support

           0       0.77      0.79      0.78      1214
           1       0.79      0.78      0.79      1264

    accuracy                           0.78      2478
   macro avg       0.78      0.78      0.78      2478
weighted avg       0.78      0.78      0.78      2478

LPS_0.010_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.72      0.72      0.72      3724
           1       0.75      0.75      0.75      4168

    accuracy                           0.74      7892
   macro avg       0.74      0.74      0.74      7892
weighted avg       0.74      0.74      0.74      7892

              precision    recall  f1-score   support

           0       0.72      0.72      0.72      3724
           1       0.75      0.75      0.75      4168

    accuracy                           0.74      7892
   macro avg       0.74      0.74      0.74      7892
weighted avg       0.74      0.74      0.74      7892

completed
