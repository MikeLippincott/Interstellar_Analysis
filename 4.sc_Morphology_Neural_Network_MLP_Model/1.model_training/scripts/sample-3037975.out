[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '3c161b87'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '34014b64'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'fbe1108d'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '9881ed13'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_0.010_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_0.010_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (32077, 1276)
Number of total missing values across all columns: 31718
Data Subset Is Off
Wells held out for testing: ['B20' 'K16']
Wells to use for training, validation, and testing ['B16' 'B17' 'B21' 'K17' 'K20' 'K21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.401124).  Saving model ...
	 Train_Loss: 0.5178 Train_Acc: 74.617 Val_Loss: 0.4011  BEST VAL Loss: 0.4011  Val_Acc: 84.720

Epoch 1: Validation loss decreased (0.401124 --> 0.365482).  Saving model ...
	 Train_Loss: 0.4622 Train_Acc: 82.674 Val_Loss: 0.3655  BEST VAL Loss: 0.3655  Val_Acc: 87.246

Epoch 2: Validation loss decreased (0.365482 --> 0.341322).  Saving model ...
	 Train_Loss: 0.4265 Train_Acc: 84.854 Val_Loss: 0.3413  BEST VAL Loss: 0.3413  Val_Acc: 88.489

Epoch 3: Validation loss decreased (0.341322 --> 0.321587).  Saving model ...
	 Train_Loss: 0.4005 Train_Acc: 86.568 Val_Loss: 0.3216  BEST VAL Loss: 0.3216  Val_Acc: 89.648

Epoch 4: Validation loss decreased (0.321587 --> 0.306819).  Saving model ...
	 Train_Loss: 0.3795 Train_Acc: 87.526 Val_Loss: 0.3068  BEST VAL Loss: 0.3068  Val_Acc: 90.849

Epoch 5: Validation loss decreased (0.306819 --> 0.293935).  Saving model ...
	 Train_Loss: 0.3625 Train_Acc: 88.422 Val_Loss: 0.2939  BEST VAL Loss: 0.2939  Val_Acc: 91.636

Epoch 6: Validation loss decreased (0.293935 --> 0.281657).  Saving model ...
	 Train_Loss: 0.3486 Train_Acc: 89.002 Val_Loss: 0.2817  BEST VAL Loss: 0.2817  Val_Acc: 92.547

Epoch 7: Validation loss decreased (0.281657 --> 0.271119).  Saving model ...
	 Train_Loss: 0.3358 Train_Acc: 89.758 Val_Loss: 0.2711  BEST VAL Loss: 0.2711  Val_Acc: 92.795

Epoch 8: Validation loss decreased (0.271119 --> 0.261754).  Saving model ...
	 Train_Loss: 0.3246 Train_Acc: 90.348 Val_Loss: 0.2618  BEST VAL Loss: 0.2618  Val_Acc: 93.499

Epoch 9: Validation loss decreased (0.261754 --> 0.253338).  Saving model ...
	 Train_Loss: 0.3147 Train_Acc: 90.452 Val_Loss: 0.2533  BEST VAL Loss: 0.2533  Val_Acc: 93.954

Epoch 10: Validation loss decreased (0.253338 --> 0.246321).  Saving model ...
	 Train_Loss: 0.3060 Train_Acc: 90.705 Val_Loss: 0.2463  BEST VAL Loss: 0.2463  Val_Acc: 93.665

Epoch 11: Validation loss decreased (0.246321 --> 0.239278).  Saving model ...
	 Train_Loss: 0.2977 Train_Acc: 91.347 Val_Loss: 0.2393  BEST VAL Loss: 0.2393  Val_Acc: 94.451

Epoch 12: Validation loss decreased (0.239278 --> 0.233806).  Saving model ...
	 Train_Loss: 0.2904 Train_Acc: 91.518 Val_Loss: 0.2338  BEST VAL Loss: 0.2338  Val_Acc: 93.416

Epoch 13: Validation loss decreased (0.233806 --> 0.229029).  Saving model ...
	 Train_Loss: 0.2835 Train_Acc: 91.870 Val_Loss: 0.2290  BEST VAL Loss: 0.2290  Val_Acc: 93.416

Epoch 14: Validation loss decreased (0.229029 --> 0.223395).  Saving model ...
	 Train_Loss: 0.2774 Train_Acc: 92.015 Val_Loss: 0.2234  BEST VAL Loss: 0.2234  Val_Acc: 94.451

Epoch 15: Validation loss decreased (0.223395 --> 0.218613).  Saving model ...
	 Train_Loss: 0.2717 Train_Acc: 92.041 Val_Loss: 0.2186  BEST VAL Loss: 0.2186  Val_Acc: 94.824

Epoch 16: Validation loss decreased (0.218613 --> 0.213921).  Saving model ...
	 Train_Loss: 0.2662 Train_Acc: 92.471 Val_Loss: 0.2139  BEST VAL Loss: 0.2139  Val_Acc: 95.072

Epoch 17: Validation loss decreased (0.213921 --> 0.209391).  Saving model ...
	 Train_Loss: 0.2609 Train_Acc: 92.699 Val_Loss: 0.2094  BEST VAL Loss: 0.2094  Val_Acc: 95.031

Epoch 18: Validation loss decreased (0.209391 --> 0.205415).  Saving model ...
	 Train_Loss: 0.2561 Train_Acc: 92.720 Val_Loss: 0.2054  BEST VAL Loss: 0.2054  Val_Acc: 95.321

Epoch 19: Validation loss decreased (0.205415 --> 0.201895).  Saving model ...
	 Train_Loss: 0.2516 Train_Acc: 92.782 Val_Loss: 0.2019  BEST VAL Loss: 0.2019  Val_Acc: 94.783

Epoch 20: Validation loss decreased (0.201895 --> 0.198669).  Saving model ...
	 Train_Loss: 0.2473 Train_Acc: 93.103 Val_Loss: 0.1987  BEST VAL Loss: 0.1987  Val_Acc: 95.155

Epoch 21: Validation loss decreased (0.198669 --> 0.195615).  Saving model ...
	 Train_Loss: 0.2432 Train_Acc: 93.419 Val_Loss: 0.1956  BEST VAL Loss: 0.1956  Val_Acc: 95.197

Epoch 22: Validation loss decreased (0.195615 --> 0.192856).  Saving model ...
	 Train_Loss: 0.2394 Train_Acc: 93.237 Val_Loss: 0.1929  BEST VAL Loss: 0.1929  Val_Acc: 95.238

Epoch 23: Validation loss decreased (0.192856 --> 0.190033).  Saving model ...
	 Train_Loss: 0.2357 Train_Acc: 93.450 Val_Loss: 0.1900  BEST VAL Loss: 0.1900  Val_Acc: 95.362

Epoch 24: Validation loss decreased (0.190033 --> 0.187547).  Saving model ...
	 Train_Loss: 0.2323 Train_Acc: 93.263 Val_Loss: 0.1875  BEST VAL Loss: 0.1875  Val_Acc: 95.031

Epoch 25: Validation loss decreased (0.187547 --> 0.185055).  Saving model ...
	 Train_Loss: 0.2291 Train_Acc: 93.429 Val_Loss: 0.1851  BEST VAL Loss: 0.1851  Val_Acc: 95.487

Epoch 26: Validation loss decreased (0.185055 --> 0.182737).  Saving model ...
	 Train_Loss: 0.2259 Train_Acc: 93.729 Val_Loss: 0.1827  BEST VAL Loss: 0.1827  Val_Acc: 95.362

Epoch 27: Validation loss decreased (0.182737 --> 0.180563).  Saving model ...
	 Train_Loss: 0.2230 Train_Acc: 93.724 Val_Loss: 0.1806  BEST VAL Loss: 0.1806  Val_Acc: 95.362

Epoch 28: Validation loss decreased (0.180563 --> 0.178487).  Saving model ...
	 Train_Loss: 0.2201 Train_Acc: 93.734 Val_Loss: 0.1785  BEST VAL Loss: 0.1785  Val_Acc: 95.569

Epoch 29: Validation loss decreased (0.178487 --> 0.176670).  Saving model ...
	 Train_Loss: 0.2175 Train_Acc: 93.553 Val_Loss: 0.1767  BEST VAL Loss: 0.1767  Val_Acc: 95.197

Epoch 30: Validation loss decreased (0.176670 --> 0.174790).  Saving model ...
	 Train_Loss: 0.2150 Train_Acc: 93.636 Val_Loss: 0.1748  BEST VAL Loss: 0.1748  Val_Acc: 95.694

Epoch 31: Validation loss decreased (0.174790 --> 0.172888).  Saving model ...
	 Train_Loss: 0.2126 Train_Acc: 93.781 Val_Loss: 0.1729  BEST VAL Loss: 0.1729  Val_Acc: 95.445

Epoch 32: Validation loss decreased (0.172888 --> 0.171112).  Saving model ...
	 Train_Loss: 0.2100 Train_Acc: 94.206 Val_Loss: 0.1711  BEST VAL Loss: 0.1711  Val_Acc: 95.528

Epoch 33: Validation loss decreased (0.171112 --> 0.169447).  Saving model ...
	 Train_Loss: 0.2077 Train_Acc: 94.081 Val_Loss: 0.1694  BEST VAL Loss: 0.1694  Val_Acc: 95.611

Epoch 34: Validation loss decreased (0.169447 --> 0.167833).  Saving model ...
	 Train_Loss: 0.2054 Train_Acc: 93.957 Val_Loss: 0.1678  BEST VAL Loss: 0.1678  Val_Acc: 95.445

Epoch 35: Validation loss decreased (0.167833 --> 0.166485).  Saving model ...
	 Train_Loss: 0.2032 Train_Acc: 94.340 Val_Loss: 0.1665  BEST VAL Loss: 0.1665  Val_Acc: 95.652

Epoch 36: Validation loss decreased (0.166485 --> 0.165359).  Saving model ...
	 Train_Loss: 0.2011 Train_Acc: 94.475 Val_Loss: 0.1654  BEST VAL Loss: 0.1654  Val_Acc: 95.445

Epoch 37: Validation loss decreased (0.165359 --> 0.163953).  Saving model ...
	 Train_Loss: 0.1991 Train_Acc: 94.164 Val_Loss: 0.1640  BEST VAL Loss: 0.1640  Val_Acc: 95.735

Epoch 38: Validation loss decreased (0.163953 --> 0.162719).  Saving model ...
	 Train_Loss: 0.1971 Train_Acc: 94.309 Val_Loss: 0.1627  BEST VAL Loss: 0.1627  Val_Acc: 95.694

Epoch 39: Validation loss decreased (0.162719 --> 0.161674).  Saving model ...
	 Train_Loss: 0.1952 Train_Acc: 94.273 Val_Loss: 0.1617  BEST VAL Loss: 0.1617  Val_Acc: 95.362

Epoch 40: Validation loss decreased (0.161674 --> 0.160561).  Saving model ...
	 Train_Loss: 0.1933 Train_Acc: 94.625 Val_Loss: 0.1606  BEST VAL Loss: 0.1606  Val_Acc: 95.487

Epoch 41: Validation loss decreased (0.160561 --> 0.159470).  Saving model ...
	 Train_Loss: 0.1916 Train_Acc: 94.418 Val_Loss: 0.1595  BEST VAL Loss: 0.1595  Val_Acc: 95.197

Epoch 42: Validation loss decreased (0.159470 --> 0.158394).  Saving model ...
	 Train_Loss: 0.1899 Train_Acc: 94.496 Val_Loss: 0.1584  BEST VAL Loss: 0.1584  Val_Acc: 95.859

Epoch 43: Validation loss decreased (0.158394 --> 0.157427).  Saving model ...
	 Train_Loss: 0.1882 Train_Acc: 94.749 Val_Loss: 0.1574  BEST VAL Loss: 0.1574  Val_Acc: 95.652

Epoch 44: Validation loss decreased (0.157427 --> 0.156337).  Saving model ...
	 Train_Loss: 0.1865 Train_Acc: 94.568 Val_Loss: 0.1563  BEST VAL Loss: 0.1563  Val_Acc: 95.776

Epoch 45: Validation loss decreased (0.156337 --> 0.155467).  Saving model ...
	 Train_Loss: 0.1850 Train_Acc: 94.677 Val_Loss: 0.1555  BEST VAL Loss: 0.1555  Val_Acc: 95.694

Epoch 46: Validation loss decreased (0.155467 --> 0.154531).  Saving model ...
	 Train_Loss: 0.1835 Train_Acc: 94.459 Val_Loss: 0.1545  BEST VAL Loss: 0.1545  Val_Acc: 95.652

Epoch 47: Validation loss decreased (0.154531 --> 0.153580).  Saving model ...
	 Train_Loss: 0.1820 Train_Acc: 94.687 Val_Loss: 0.1536  BEST VAL Loss: 0.1536  Val_Acc: 95.901

Epoch 48: Validation loss decreased (0.153580 --> 0.152726).  Saving model ...
	 Train_Loss: 0.1805 Train_Acc: 94.553 Val_Loss: 0.1527  BEST VAL Loss: 0.1527  Val_Acc: 95.983

Epoch 49: Validation loss decreased (0.152726 --> 0.151908).  Saving model ...
	 Train_Loss: 0.1792 Train_Acc: 94.568 Val_Loss: 0.1519  BEST VAL Loss: 0.1519  Val_Acc: 95.983

Epoch 50: Validation loss decreased (0.151908 --> 0.151156).  Saving model ...
	 Train_Loss: 0.1778 Train_Acc: 94.594 Val_Loss: 0.1512  BEST VAL Loss: 0.1512  Val_Acc: 95.818

Epoch 51: Validation loss decreased (0.151156 --> 0.150249).  Saving model ...
	 Train_Loss: 0.1765 Train_Acc: 94.713 Val_Loss: 0.1502  BEST VAL Loss: 0.1502  Val_Acc: 95.776

Epoch 52: Validation loss decreased (0.150249 --> 0.149573).  Saving model ...
	 Train_Loss: 0.1751 Train_Acc: 94.755 Val_Loss: 0.1496  BEST VAL Loss: 0.1496  Val_Acc: 95.818

Epoch 53: Validation loss decreased (0.149573 --> 0.148889).  Saving model ...
	 Train_Loss: 0.1739 Train_Acc: 94.568 Val_Loss: 0.1489  BEST VAL Loss: 0.1489  Val_Acc: 95.942

Epoch 54: Validation loss decreased (0.148889 --> 0.148203).  Saving model ...
	 Train_Loss: 0.1726 Train_Acc: 94.584 Val_Loss: 0.1482  BEST VAL Loss: 0.1482  Val_Acc: 95.652

Epoch 55: Validation loss decreased (0.148203 --> 0.147529).  Saving model ...
	 Train_Loss: 0.1714 Train_Acc: 94.843 Val_Loss: 0.1475  BEST VAL Loss: 0.1475  Val_Acc: 96.066

Epoch 56: Validation loss decreased (0.147529 --> 0.146857).  Saving model ...
	 Train_Loss: 0.1702 Train_Acc: 94.796 Val_Loss: 0.1469  BEST VAL Loss: 0.1469  Val_Acc: 96.108

Epoch 57: Validation loss decreased (0.146857 --> 0.146125).  Saving model ...
	 Train_Loss: 0.1690 Train_Acc: 94.936 Val_Loss: 0.1461  BEST VAL Loss: 0.1461  Val_Acc: 95.776

Epoch 58: Validation loss decreased (0.146125 --> 0.145597).  Saving model ...
	 Train_Loss: 0.1679 Train_Acc: 94.744 Val_Loss: 0.1456  BEST VAL Loss: 0.1456  Val_Acc: 95.942

Epoch 59: Validation loss decreased (0.145597 --> 0.144997).  Saving model ...
	 Train_Loss: 0.1668 Train_Acc: 94.863 Val_Loss: 0.1450  BEST VAL Loss: 0.1450  Val_Acc: 96.149

Epoch 60: Validation loss decreased (0.144997 --> 0.144392).  Saving model ...
	 Train_Loss: 0.1657 Train_Acc: 94.946 Val_Loss: 0.1444  BEST VAL Loss: 0.1444  Val_Acc: 96.190

Epoch 61: Validation loss decreased (0.144392 --> 0.143910).  Saving model ...
	 Train_Loss: 0.1647 Train_Acc: 94.920 Val_Loss: 0.1439  BEST VAL Loss: 0.1439  Val_Acc: 95.611

Epoch 62: Validation loss decreased (0.143910 --> 0.143339).  Saving model ...
	 Train_Loss: 0.1636 Train_Acc: 94.936 Val_Loss: 0.1433  BEST VAL Loss: 0.1433  Val_Acc: 96.149

Epoch 63: Validation loss decreased (0.143339 --> 0.142828).  Saving model ...
	 Train_Loss: 0.1626 Train_Acc: 94.780 Val_Loss: 0.1428  BEST VAL Loss: 0.1428  Val_Acc: 96.025

Epoch 64: Validation loss decreased (0.142828 --> 0.142291).  Saving model ...
	 Train_Loss: 0.1616 Train_Acc: 94.977 Val_Loss: 0.1423  BEST VAL Loss: 0.1423  Val_Acc: 95.901

Epoch 65: Validation loss decreased (0.142291 --> 0.141659).  Saving model ...
	 Train_Loss: 0.1606 Train_Acc: 95.324 Val_Loss: 0.1417  BEST VAL Loss: 0.1417  Val_Acc: 95.983

Epoch 66: Validation loss decreased (0.141659 --> 0.141413).  Saving model ...
	 Train_Loss: 0.1597 Train_Acc: 94.837 Val_Loss: 0.1414  BEST VAL Loss: 0.1414  Val_Acc: 95.942

Epoch 67: Validation loss decreased (0.141413 --> 0.140972).  Saving model ...
	 Train_Loss: 0.1587 Train_Acc: 95.148 Val_Loss: 0.1410  BEST VAL Loss: 0.1410  Val_Acc: 95.901

Epoch 68: Validation loss decreased (0.140972 --> 0.140458).  Saving model ...
	 Train_Loss: 0.1578 Train_Acc: 95.205 Val_Loss: 0.1405  BEST VAL Loss: 0.1405  Val_Acc: 95.983

Epoch 69: Validation loss decreased (0.140458 --> 0.140056).  Saving model ...
	 Train_Loss: 0.1568 Train_Acc: 95.381 Val_Loss: 0.1401  BEST VAL Loss: 0.1401  Val_Acc: 95.445

Epoch 70: Validation loss decreased (0.140056 --> 0.139575).  Saving model ...
	 Train_Loss: 0.1559 Train_Acc: 95.050 Val_Loss: 0.1396  BEST VAL Loss: 0.1396  Val_Acc: 96.149

Epoch 71: Validation loss decreased (0.139575 --> 0.139184).  Saving model ...
	 Train_Loss: 0.1550 Train_Acc: 95.158 Val_Loss: 0.1392  BEST VAL Loss: 0.1392  Val_Acc: 96.066

Epoch 72: Validation loss decreased (0.139184 --> 0.138803).  Saving model ...
	 Train_Loss: 0.1542 Train_Acc: 94.894 Val_Loss: 0.1388  BEST VAL Loss: 0.1388  Val_Acc: 96.149

Epoch 73: Validation loss decreased (0.138803 --> 0.138711).  Saving model ...
	 Train_Loss: 0.1533 Train_Acc: 95.241 Val_Loss: 0.1387  BEST VAL Loss: 0.1387  Val_Acc: 95.983

Epoch 74: Validation loss decreased (0.138711 --> 0.138276).  Saving model ...
	 Train_Loss: 0.1525 Train_Acc: 95.215 Val_Loss: 0.1383  BEST VAL Loss: 0.1383  Val_Acc: 96.149

Epoch 75: Validation loss decreased (0.138276 --> 0.138055).  Saving model ...
	 Train_Loss: 0.1517 Train_Acc: 94.988 Val_Loss: 0.1381  BEST VAL Loss: 0.1381  Val_Acc: 95.735

Epoch 76: Validation loss decreased (0.138055 --> 0.137587).  Saving model ...
	 Train_Loss: 0.1509 Train_Acc: 95.329 Val_Loss: 0.1376  BEST VAL Loss: 0.1376  Val_Acc: 96.149

Epoch 77: Validation loss decreased (0.137587 --> 0.137188).  Saving model ...
	 Train_Loss: 0.1501 Train_Acc: 95.045 Val_Loss: 0.1372  BEST VAL Loss: 0.1372  Val_Acc: 96.066

Epoch 78: Validation loss decreased (0.137188 --> 0.136861).  Saving model ...
	 Train_Loss: 0.1493 Train_Acc: 95.029 Val_Loss: 0.1369  BEST VAL Loss: 0.1369  Val_Acc: 96.025

Epoch 79: Validation loss decreased (0.136861 --> 0.136537).  Saving model ...
	 Train_Loss: 0.1486 Train_Acc: 95.003 Val_Loss: 0.1365  BEST VAL Loss: 0.1365  Val_Acc: 95.942

Epoch 80: Validation loss decreased (0.136537 --> 0.136239).  Saving model ...
	 Train_Loss: 0.1478 Train_Acc: 95.272 Val_Loss: 0.1362  BEST VAL Loss: 0.1362  Val_Acc: 96.232

Epoch 81: Validation loss decreased (0.136239 --> 0.135872).  Saving model ...
	 Train_Loss: 0.1471 Train_Acc: 95.205 Val_Loss: 0.1359  BEST VAL Loss: 0.1359  Val_Acc: 95.983

Epoch 82: Validation loss decreased (0.135872 --> 0.135578).  Saving model ...
	 Train_Loss: 0.1463 Train_Acc: 95.624 Val_Loss: 0.1356  BEST VAL Loss: 0.1356  Val_Acc: 95.652

Epoch 83: Validation loss decreased (0.135578 --> 0.135290).  Saving model ...
	 Train_Loss: 0.1456 Train_Acc: 95.091 Val_Loss: 0.1353  BEST VAL Loss: 0.1353  Val_Acc: 96.108

Epoch 84: Validation loss decreased (0.135290 --> 0.135007).  Saving model ...
	 Train_Loss: 0.1450 Train_Acc: 95.096 Val_Loss: 0.1350  BEST VAL Loss: 0.1350  Val_Acc: 96.025

Epoch 85: Validation loss decreased (0.135007 --> 0.134711).  Saving model ...
	 Train_Loss: 0.1443 Train_Acc: 95.448 Val_Loss: 0.1347  BEST VAL Loss: 0.1347  Val_Acc: 96.025

Epoch 86: Validation loss decreased (0.134711 --> 0.134472).  Saving model ...
	 Train_Loss: 0.1436 Train_Acc: 95.360 Val_Loss: 0.1345  BEST VAL Loss: 0.1345  Val_Acc: 96.108

Epoch 87: Validation loss decreased (0.134472 --> 0.134250).  Saving model ...
	 Train_Loss: 0.1429 Train_Acc: 95.454 Val_Loss: 0.1343  BEST VAL Loss: 0.1343  Val_Acc: 96.108

Epoch 88: Validation loss decreased (0.134250 --> 0.134028).  Saving model ...
	 Train_Loss: 0.1422 Train_Acc: 95.397 Val_Loss: 0.1340  BEST VAL Loss: 0.1340  Val_Acc: 95.901

Epoch 89: Validation loss decreased (0.134028 --> 0.133868).  Saving model ...
	 Train_Loss: 0.1415 Train_Acc: 95.454 Val_Loss: 0.1339  BEST VAL Loss: 0.1339  Val_Acc: 95.859

Epoch 90: Validation loss decreased (0.133868 --> 0.133653).  Saving model ...
	 Train_Loss: 0.1409 Train_Acc: 95.226 Val_Loss: 0.1337  BEST VAL Loss: 0.1337  Val_Acc: 95.942

Epoch 91: Validation loss decreased (0.133653 --> 0.133387).  Saving model ...
	 Train_Loss: 0.1403 Train_Acc: 95.060 Val_Loss: 0.1334  BEST VAL Loss: 0.1334  Val_Acc: 96.025

Epoch 92: Validation loss decreased (0.133387 --> 0.133109).  Saving model ...
	 Train_Loss: 0.1396 Train_Acc: 95.309 Val_Loss: 0.1331  BEST VAL Loss: 0.1331  Val_Acc: 96.149

Epoch 93: Validation loss decreased (0.133109 --> 0.132838).  Saving model ...
	 Train_Loss: 0.1390 Train_Acc: 95.298 Val_Loss: 0.1328  BEST VAL Loss: 0.1328  Val_Acc: 96.273

Epoch 94: Validation loss decreased (0.132838 --> 0.132641).  Saving model ...
	 Train_Loss: 0.1384 Train_Acc: 95.288 Val_Loss: 0.1326  BEST VAL Loss: 0.1326  Val_Acc: 95.528

Epoch 95: Validation loss decreased (0.132641 --> 0.132446).  Saving model ...
	 Train_Loss: 0.1379 Train_Acc: 95.272 Val_Loss: 0.1324  BEST VAL Loss: 0.1324  Val_Acc: 95.694

Epoch 96: Validation loss decreased (0.132446 --> 0.132282).  Saving model ...
	 Train_Loss: 0.1373 Train_Acc: 95.428 Val_Loss: 0.1323  BEST VAL Loss: 0.1323  Val_Acc: 95.983

Epoch 97: Validation loss decreased (0.132282 --> 0.132048).  Saving model ...
	 Train_Loss: 0.1367 Train_Acc: 95.386 Val_Loss: 0.1320  BEST VAL Loss: 0.1320  Val_Acc: 96.025

Epoch 98: Validation loss decreased (0.132048 --> 0.131870).  Saving model ...
	 Train_Loss: 0.1361 Train_Acc: 95.448 Val_Loss: 0.1319  BEST VAL Loss: 0.1319  Val_Acc: 95.611

Epoch 99: Validation loss decreased (0.131870 --> 0.131638).  Saving model ...
	 Train_Loss: 0.1355 Train_Acc: 95.552 Val_Loss: 0.1316  BEST VAL Loss: 0.1316  Val_Acc: 95.901

LPS_0.010_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.50      0.50      9708
           1       0.49      0.49      0.49      9604

    accuracy                           0.49     19312
   macro avg       0.49      0.49      0.49     19312
weighted avg       0.49      0.49      0.49     19312

LPS_0.010_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.50      0.51      1214
           1       0.50      0.50      0.50      1201

    accuracy                           0.50      2415
   macro avg       0.50      0.50      0.50      2415
weighted avg       0.50      0.50      0.50      2415

LPS_0.010_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.51      0.51      1213
           1       0.50      0.50      0.50      1201

    accuracy                           0.51      2414
   macro avg       0.51      0.51      0.51      2414
weighted avg       0.51      0.51      0.51      2414

              precision    recall  f1-score   support

           0       0.51      0.51      0.51      1213
           1       0.50      0.50      0.50      1201

    accuracy                           0.51      2414
   macro avg       0.51      0.51      0.51      2414
weighted avg       0.51      0.51      0.51      2414

LPS_0.010_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.48      0.47      3724
           1       0.53      0.53      0.53      4212

    accuracy                           0.51      7936
   macro avg       0.50      0.50      0.50      7936
weighted avg       0.51      0.51      0.51      7936

              precision    recall  f1-score   support

           0       0.47      0.48      0.47      3724
           1       0.53      0.53      0.53      4212

    accuracy                           0.51      7936
   macro avg       0.50      0.50      0.50      7936
weighted avg       0.51      0.51      0.51      7936

completed
