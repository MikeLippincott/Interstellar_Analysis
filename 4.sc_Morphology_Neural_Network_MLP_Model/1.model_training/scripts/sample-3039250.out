[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '5bad60c1'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '2a4ac646'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '4f442aed'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '407219c5'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_10.000_DMSO_0.025 treatment_name: Thapsigargin_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: Thapsigargin_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'LPS_10.000_DMSO_0.025']
The dimensions of the data are: (30576, 1276)
Number of total missing values across all columns: 61152
Data Subset Is Off
Wells held out for testing: ['D14' 'E20']
Wells to use for training, validation, and testing ['D15' 'E16' 'E17' 'E21' 'K14' 'K15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.564077).  Saving model ...
	 Train_Loss: 0.6459 Train_Acc: 64.356 Val_Loss: 0.5641  BEST VAL Loss: 0.5641  Val_Acc: 76.374

Epoch 1: Validation loss decreased (0.564077 --> 0.513590).  Saving model ...
	 Train_Loss: 0.6068 Train_Acc: 71.877 Val_Loss: 0.5136  BEST VAL Loss: 0.5136  Val_Acc: 82.302

Epoch 2: Validation loss decreased (0.513590 --> 0.481740).  Saving model ...
	 Train_Loss: 0.5836 Train_Acc: 74.371 Val_Loss: 0.4817  BEST VAL Loss: 0.4817  Val_Acc: 85.201

Epoch 3: Validation loss decreased (0.481740 --> 0.458556).  Saving model ...
	 Train_Loss: 0.5650 Train_Acc: 76.459 Val_Loss: 0.4586  BEST VAL Loss: 0.4586  Val_Acc: 87.235

Epoch 4: Validation loss decreased (0.458556 --> 0.442438).  Saving model ...
	 Train_Loss: 0.5515 Train_Acc: 77.509 Val_Loss: 0.4424  BEST VAL Loss: 0.4424  Val_Acc: 87.624

Epoch 5: Validation loss decreased (0.442438 --> 0.427920).  Saving model ...
	 Train_Loss: 0.5415 Train_Acc: 78.250 Val_Loss: 0.4279  BEST VAL Loss: 0.4279  Val_Acc: 88.230

Epoch 6: Validation loss decreased (0.427920 --> 0.421493).  Saving model ...
	 Train_Loss: 0.5328 Train_Acc: 79.116 Val_Loss: 0.4215  BEST VAL Loss: 0.4215  Val_Acc: 87.322

Epoch 7: Validation loss decreased (0.421493 --> 0.413395).  Saving model ...
	 Train_Loss: 0.5244 Train_Acc: 80.014 Val_Loss: 0.4134  BEST VAL Loss: 0.4134  Val_Acc: 88.923

Epoch 8: Validation loss decreased (0.413395 --> 0.405739).  Saving model ...
	 Train_Loss: 0.5174 Train_Acc: 80.258 Val_Loss: 0.4057  BEST VAL Loss: 0.4057  Val_Acc: 89.096

Epoch 9: Validation loss decreased (0.405739 --> 0.398194).  Saving model ...
	 Train_Loss: 0.5116 Train_Acc: 80.052 Val_Loss: 0.3982  BEST VAL Loss: 0.3982  Val_Acc: 89.701

Epoch 10: Validation loss decreased (0.398194 --> 0.393043).  Saving model ...
	 Train_Loss: 0.5060 Train_Acc: 81.134 Val_Loss: 0.3930  BEST VAL Loss: 0.3930  Val_Acc: 89.052

Epoch 11: Validation loss decreased (0.393043 --> 0.388796).  Saving model ...
	 Train_Loss: 0.5017 Train_Acc: 80.723 Val_Loss: 0.3888  BEST VAL Loss: 0.3888  Val_Acc: 88.966

Epoch 12: Validation loss decreased (0.388796 --> 0.385254).  Saving model ...
	 Train_Loss: 0.4972 Train_Acc: 81.183 Val_Loss: 0.3853  BEST VAL Loss: 0.3853  Val_Acc: 89.485

Epoch 13: Validation loss decreased (0.385254 --> 0.381359).  Saving model ...
	 Train_Loss: 0.4934 Train_Acc: 81.118 Val_Loss: 0.3814  BEST VAL Loss: 0.3814  Val_Acc: 90.264

Epoch 14: Validation loss decreased (0.381359 --> 0.377447).  Saving model ...
	 Train_Loss: 0.4901 Train_Acc: 81.199 Val_Loss: 0.3774  BEST VAL Loss: 0.3774  Val_Acc: 90.091

Epoch 15: Validation loss decreased (0.377447 --> 0.372980).  Saving model ...
	 Train_Loss: 0.4870 Train_Acc: 81.166 Val_Loss: 0.3730  BEST VAL Loss: 0.3730  Val_Acc: 90.134

Epoch 16: Validation loss decreased (0.372980 --> 0.370595).  Saving model ...
	 Train_Loss: 0.4836 Train_Acc: 82.081 Val_Loss: 0.3706  BEST VAL Loss: 0.3706  Val_Acc: 89.096

Epoch 17: Validation loss decreased (0.370595 --> 0.367834).  Saving model ...
	 Train_Loss: 0.4809 Train_Acc: 81.459 Val_Loss: 0.3678  BEST VAL Loss: 0.3678  Val_Acc: 90.004

Epoch 18: Validation loss decreased (0.367834 --> 0.365045).  Saving model ...
	 Train_Loss: 0.4786 Train_Acc: 81.794 Val_Loss: 0.3650  BEST VAL Loss: 0.3650  Val_Acc: 90.437

Epoch 19: Validation loss decreased (0.365045 --> 0.363975).  Saving model ...
	 Train_Loss: 0.4764 Train_Acc: 81.854 Val_Loss: 0.3640  BEST VAL Loss: 0.3640  Val_Acc: 88.749

Epoch 20: Validation loss decreased (0.363975 --> 0.361542).  Saving model ...
	 Train_Loss: 0.4745 Train_Acc: 81.632 Val_Loss: 0.3615  BEST VAL Loss: 0.3615  Val_Acc: 90.480

Epoch 21: Validation loss decreased (0.361542 --> 0.360350).  Saving model ...
	 Train_Loss: 0.4724 Train_Acc: 82.059 Val_Loss: 0.3604  BEST VAL Loss: 0.3604  Val_Acc: 89.701

Epoch 22: Validation loss decreased (0.360350 --> 0.359008).  Saving model ...
	 Train_Loss: 0.4706 Train_Acc: 82.146 Val_Loss: 0.3590  BEST VAL Loss: 0.3590  Val_Acc: 89.572

Epoch 23: Validation loss decreased (0.359008 --> 0.357126).  Saving model ...
	 Train_Loss: 0.4688 Train_Acc: 82.276 Val_Loss: 0.3571  BEST VAL Loss: 0.3571  Val_Acc: 90.134

Epoch 24: Validation loss decreased (0.357126 --> 0.355709).  Saving model ...
	 Train_Loss: 0.4671 Train_Acc: 82.227 Val_Loss: 0.3557  BEST VAL Loss: 0.3557  Val_Acc: 89.312

Epoch 25: Validation loss decreased (0.355709 --> 0.354815).  Saving model ...
	 Train_Loss: 0.4654 Train_Acc: 82.249 Val_Loss: 0.3548  BEST VAL Loss: 0.3548  Val_Acc: 90.264

Epoch 26: Validation loss decreased (0.354815 --> 0.353386).  Saving model ...
	 Train_Loss: 0.4638 Train_Acc: 82.454 Val_Loss: 0.3534  BEST VAL Loss: 0.3534  Val_Acc: 89.918

Epoch 27: Validation loss decreased (0.353386 --> 0.351805).  Saving model ...
	 Train_Loss: 0.4624 Train_Acc: 82.519 Val_Loss: 0.3518  BEST VAL Loss: 0.3518  Val_Acc: 90.610

Epoch 28: Validation loss decreased (0.351805 --> 0.350221).  Saving model ...
	 Train_Loss: 0.4609 Train_Acc: 82.779 Val_Loss: 0.3502  BEST VAL Loss: 0.3502  Val_Acc: 90.221

Epoch 29: Validation loss decreased (0.350221 --> 0.348825).  Saving model ...
	 Train_Loss: 0.4595 Train_Acc: 82.698 Val_Loss: 0.3488  BEST VAL Loss: 0.3488  Val_Acc: 89.918

Epoch 30: Validation loss decreased (0.348825 --> 0.347291).  Saving model ...
	 Train_Loss: 0.4581 Train_Acc: 82.784 Val_Loss: 0.3473  BEST VAL Loss: 0.3473  Val_Acc: 90.697

Epoch 31: Validation loss decreased (0.347291 --> 0.346179).  Saving model ...
	 Train_Loss: 0.4569 Train_Acc: 82.573 Val_Loss: 0.3462  BEST VAL Loss: 0.3462  Val_Acc: 90.480

Epoch 32: Validation loss decreased (0.346179 --> 0.345257).  Saving model ...
	 Train_Loss: 0.4557 Train_Acc: 82.892 Val_Loss: 0.3453  BEST VAL Loss: 0.3453  Val_Acc: 90.870

Epoch 33: Validation loss decreased (0.345257 --> 0.344210).  Saving model ...
	 Train_Loss: 0.4546 Train_Acc: 82.481 Val_Loss: 0.3442  BEST VAL Loss: 0.3442  Val_Acc: 90.437

Epoch 34: Validation loss decreased (0.344210 --> 0.343134).  Saving model ...
	 Train_Loss: 0.4536 Train_Acc: 82.584 Val_Loss: 0.3431  BEST VAL Loss: 0.3431  Val_Acc: 90.177

Epoch 35: Validation loss decreased (0.343134 --> 0.342347).  Saving model ...
	 Train_Loss: 0.4525 Train_Acc: 82.654 Val_Loss: 0.3423  BEST VAL Loss: 0.3423  Val_Acc: 89.788

Epoch 36: Validation loss decreased (0.342347 --> 0.341480).  Saving model ...
	 Train_Loss: 0.4515 Train_Acc: 82.936 Val_Loss: 0.3415  BEST VAL Loss: 0.3415  Val_Acc: 90.524

Epoch 37: Validation loss decreased (0.341480 --> 0.340592).  Saving model ...
	 Train_Loss: 0.4505 Train_Acc: 82.979 Val_Loss: 0.3406  BEST VAL Loss: 0.3406  Val_Acc: 90.740

Epoch 38: Validation loss decreased (0.340592 --> 0.339832).  Saving model ...
	 Train_Loss: 0.4495 Train_Acc: 82.984 Val_Loss: 0.3398  BEST VAL Loss: 0.3398  Val_Acc: 90.350

Epoch 39: Validation loss decreased (0.339832 --> 0.338713).  Saving model ...
	 Train_Loss: 0.4484 Train_Acc: 83.260 Val_Loss: 0.3387  BEST VAL Loss: 0.3387  Val_Acc: 91.000

Epoch 40: Validation loss decreased (0.338713 --> 0.338108).  Saving model ...
	 Train_Loss: 0.4474 Train_Acc: 83.277 Val_Loss: 0.3381  BEST VAL Loss: 0.3381  Val_Acc: 89.485

Epoch 41: Validation loss decreased (0.338108 --> 0.337668).  Saving model ...
	 Train_Loss: 0.4465 Train_Acc: 83.141 Val_Loss: 0.3377  BEST VAL Loss: 0.3377  Val_Acc: 90.697

Epoch 42: Validation loss decreased (0.337668 --> 0.337224).  Saving model ...
	 Train_Loss: 0.4457 Train_Acc: 83.287 Val_Loss: 0.3372  BEST VAL Loss: 0.3372  Val_Acc: 90.697

Epoch 43: Validation loss decreased (0.337224 --> 0.336419).  Saving model ...
	 Train_Loss: 0.4449 Train_Acc: 83.087 Val_Loss: 0.3364  BEST VAL Loss: 0.3364  Val_Acc: 90.610

Epoch 44: Validation loss decreased (0.336419 --> 0.335746).  Saving model ...
	 Train_Loss: 0.4442 Train_Acc: 83.087 Val_Loss: 0.3357  BEST VAL Loss: 0.3357  Val_Acc: 90.870

Epoch 45: Validation loss decreased (0.335746 --> 0.335224).  Saving model ...
	 Train_Loss: 0.4434 Train_Acc: 83.266 Val_Loss: 0.3352  BEST VAL Loss: 0.3352  Val_Acc: 90.826

Epoch 46: Validation loss decreased (0.335224 --> 0.335137).  Saving model ...
	 Train_Loss: 0.4425 Train_Acc: 83.412 Val_Loss: 0.3351  BEST VAL Loss: 0.3351  Val_Acc: 90.524

Epoch 47: Validation loss decreased (0.335137 --> 0.334573).  Saving model ...
	 Train_Loss: 0.4417 Train_Acc: 83.677 Val_Loss: 0.3346  BEST VAL Loss: 0.3346  Val_Acc: 91.086

Epoch 48: Validation loss decreased (0.334573 --> 0.334059).  Saving model ...
	 Train_Loss: 0.4407 Train_Acc: 83.964 Val_Loss: 0.3341  BEST VAL Loss: 0.3341  Val_Acc: 90.307

Epoch 49: Validation loss decreased (0.334059 --> 0.333955).  Saving model ...
	 Train_Loss: 0.4399 Train_Acc: 83.769 Val_Loss: 0.3340  BEST VAL Loss: 0.3340  Val_Acc: 90.826

Epoch 50: Validation loss decreased (0.333955 --> 0.333441).  Saving model ...
	 Train_Loss: 0.4393 Train_Acc: 83.190 Val_Loss: 0.3334  BEST VAL Loss: 0.3334  Val_Acc: 90.783

Epoch 51: Validation loss decreased (0.333441 --> 0.333152).  Saving model ...
	 Train_Loss: 0.4385 Train_Acc: 83.661 Val_Loss: 0.3332  BEST VAL Loss: 0.3332  Val_Acc: 91.216

Epoch 52: Validation loss decreased (0.333152 --> 0.332552).  Saving model ...
	 Train_Loss: 0.4379 Train_Acc: 83.001 Val_Loss: 0.3326  BEST VAL Loss: 0.3326  Val_Acc: 90.740

Epoch 53: Validation loss decreased (0.332552 --> 0.332005).  Saving model ...
	 Train_Loss: 0.4372 Train_Acc: 83.536 Val_Loss: 0.3320  BEST VAL Loss: 0.3320  Val_Acc: 90.826

Epoch 54: Validation loss decreased (0.332005 --> 0.331530).  Saving model ...
	 Train_Loss: 0.4365 Train_Acc: 83.736 Val_Loss: 0.3315  BEST VAL Loss: 0.3315  Val_Acc: 90.697

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.4360 Train_Acc: 83.114 Val_Loss: 0.3315  BEST VAL Loss: 0.3315  Val_Acc: 91.649

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.4353 Train_Acc: 83.412 Val_Loss: 0.3317  BEST VAL Loss: 0.3315  Val_Acc: 90.783

Epoch 57: Validation loss decreased (0.331530 --> 0.331272).  Saving model ...
	 Train_Loss: 0.4347 Train_Acc: 83.904 Val_Loss: 0.3313  BEST VAL Loss: 0.3313  Val_Acc: 90.221

Epoch 58: Validation loss decreased (0.331272 --> 0.330978).  Saving model ...
	 Train_Loss: 0.4340 Train_Acc: 83.742 Val_Loss: 0.3310  BEST VAL Loss: 0.3310  Val_Acc: 90.653

Epoch 59: Validation loss decreased (0.330978 --> 0.330773).  Saving model ...
	 Train_Loss: 0.4334 Train_Acc: 83.720 Val_Loss: 0.3308  BEST VAL Loss: 0.3308  Val_Acc: 90.913

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.4329 Train_Acc: 83.569 Val_Loss: 0.3309  BEST VAL Loss: 0.3308  Val_Acc: 90.524

Epoch 61: Validation loss decreased (0.330773 --> 0.330708).  Saving model ...
	 Train_Loss: 0.4324 Train_Acc: 83.331 Val_Loss: 0.3307  BEST VAL Loss: 0.3307  Val_Acc: 90.870

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.4319 Train_Acc: 83.444 Val_Loss: 0.3308  BEST VAL Loss: 0.3307  Val_Acc: 90.610

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.4314 Train_Acc: 83.433 Val_Loss: 0.3307  BEST VAL Loss: 0.3307  Val_Acc: 90.048

Epoch 64: Validation loss decreased (0.330708 --> 0.330655).  Saving model ...
	 Train_Loss: 0.4311 Train_Acc: 83.087 Val_Loss: 0.3307  BEST VAL Loss: 0.3307  Val_Acc: 90.870

Epoch 65: Validation loss decreased (0.330655 --> 0.330322).  Saving model ...
	 Train_Loss: 0.4307 Train_Acc: 83.028 Val_Loss: 0.3303  BEST VAL Loss: 0.3303  Val_Acc: 90.826

Epoch 66: Validation loss decreased (0.330322 --> 0.330140).  Saving model ...
	 Train_Loss: 0.4304 Train_Acc: 82.946 Val_Loss: 0.3301  BEST VAL Loss: 0.3301  Val_Acc: 90.697

Epoch 67: Validation loss decreased (0.330140 --> 0.329836).  Saving model ...
	 Train_Loss: 0.4299 Train_Acc: 83.688 Val_Loss: 0.3298  BEST VAL Loss: 0.3298  Val_Acc: 90.567

Epoch 68: Validation loss decreased (0.329836 --> 0.329652).  Saving model ...
	 Train_Loss: 0.4294 Train_Acc: 83.612 Val_Loss: 0.3297  BEST VAL Loss: 0.3297  Val_Acc: 89.701

Epoch 69: Validation loss decreased (0.329652 --> 0.329645).  Saving model ...
	 Train_Loss: 0.4289 Train_Acc: 83.904 Val_Loss: 0.3296  BEST VAL Loss: 0.3296  Val_Acc: 90.264

Epoch 70: Validation loss decreased (0.329645 --> 0.329442).  Saving model ...
	 Train_Loss: 0.4284 Train_Acc: 84.039 Val_Loss: 0.3294  BEST VAL Loss: 0.3294  Val_Acc: 90.048

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.4280 Train_Acc: 83.699 Val_Loss: 0.3296  BEST VAL Loss: 0.3294  Val_Acc: 91.000

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.4276 Train_Acc: 83.753 Val_Loss: 0.3294  BEST VAL Loss: 0.3294  Val_Acc: 89.831

Epoch 73: Validation loss decreased (0.329442 --> 0.329214).  Saving model ...
	 Train_Loss: 0.4271 Train_Acc: 83.920 Val_Loss: 0.3292  BEST VAL Loss: 0.3292  Val_Acc: 90.826

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.4267 Train_Acc: 84.034 Val_Loss: 0.3296  BEST VAL Loss: 0.3292  Val_Acc: 91.389

Epoch 75: Validation loss decreased (0.329214 --> 0.329186).  Saving model ...
	 Train_Loss: 0.4262 Train_Acc: 84.207 Val_Loss: 0.3292  BEST VAL Loss: 0.3292  Val_Acc: 90.437

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.4257 Train_Acc: 84.083 Val_Loss: 0.3293  BEST VAL Loss: 0.3292  Val_Acc: 90.653

Epoch 77: Validation loss decreased (0.329186 --> 0.329046).  Saving model ...
	 Train_Loss: 0.4253 Train_Acc: 83.974 Val_Loss: 0.3290  BEST VAL Loss: 0.3290  Val_Acc: 91.476

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.4248 Train_Acc: 84.332 Val_Loss: 0.3291  BEST VAL Loss: 0.3290  Val_Acc: 91.043

Epoch 79: Validation loss decreased (0.329046 --> 0.328868).  Saving model ...
	 Train_Loss: 0.4244 Train_Acc: 83.791 Val_Loss: 0.3289  BEST VAL Loss: 0.3289  Val_Acc: 91.216

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.4240 Train_Acc: 83.980 Val_Loss: 0.3291  BEST VAL Loss: 0.3289  Val_Acc: 90.826

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.4236 Train_Acc: 83.942 Val_Loss: 0.3290  BEST VAL Loss: 0.3289  Val_Acc: 90.610

Epoch 82: Validation loss decreased (0.328868 --> 0.328596).  Saving model ...
	 Train_Loss: 0.4232 Train_Acc: 84.483 Val_Loss: 0.3286  BEST VAL Loss: 0.3286  Val_Acc: 91.000

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.4229 Train_Acc: 83.910 Val_Loss: 0.3290  BEST VAL Loss: 0.3286  Val_Acc: 90.480

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.4225 Train_Acc: 84.077 Val_Loss: 0.3289  BEST VAL Loss: 0.3286  Val_Acc: 90.394

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.4221 Train_Acc: 84.056 Val_Loss: 0.3289  BEST VAL Loss: 0.3286  Val_Acc: 91.259

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.4217 Train_Acc: 84.115 Val_Loss: 0.3287  BEST VAL Loss: 0.3286  Val_Acc: 91.000

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.4214 Train_Acc: 84.169 Val_Loss: 0.3286  BEST VAL Loss: 0.3286  Val_Acc: 90.697

Epoch 88: Validation loss decreased (0.328596 --> 0.328414).  Saving model ...
	 Train_Loss: 0.4209 Train_Acc: 84.808 Val_Loss: 0.3284  BEST VAL Loss: 0.3284  Val_Acc: 91.476

Epoch 89: Validation loss decreased (0.328414 --> 0.328206).  Saving model ...
	 Train_Loss: 0.4205 Train_Acc: 84.115 Val_Loss: 0.3282  BEST VAL Loss: 0.3282  Val_Acc: 91.043

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.4201 Train_Acc: 84.575 Val_Loss: 0.3283  BEST VAL Loss: 0.3282  Val_Acc: 90.567

Epoch 91: Validation loss decreased (0.328206 --> 0.328074).  Saving model ...
	 Train_Loss: 0.4197 Train_Acc: 84.407 Val_Loss: 0.3281  BEST VAL Loss: 0.3281  Val_Acc: 90.610

Epoch 92: Validation loss decreased (0.328074 --> 0.327768).  Saving model ...
	 Train_Loss: 0.4193 Train_Acc: 84.234 Val_Loss: 0.3278  BEST VAL Loss: 0.3278  Val_Acc: 91.389

Epoch 93: Validation loss decreased (0.327768 --> 0.327546).  Saving model ...
	 Train_Loss: 0.4189 Train_Acc: 84.369 Val_Loss: 0.3275  BEST VAL Loss: 0.3275  Val_Acc: 90.913

Epoch 94: Validation loss decreased (0.327546 --> 0.327300).  Saving model ...
	 Train_Loss: 0.4186 Train_Acc: 84.034 Val_Loss: 0.3273  BEST VAL Loss: 0.3273  Val_Acc: 90.870

Epoch 95: Validation loss decreased (0.327300 --> 0.327239).  Saving model ...
	 Train_Loss: 0.4182 Train_Acc: 84.575 Val_Loss: 0.3272  BEST VAL Loss: 0.3272  Val_Acc: 91.605

Epoch 96: Validation loss decreased (0.327239 --> 0.327121).  Saving model ...
	 Train_Loss: 0.4179 Train_Acc: 84.413 Val_Loss: 0.3271  BEST VAL Loss: 0.3271  Val_Acc: 90.870

Epoch 97: Validation loss did not decrease
	 Train_Loss: 0.4176 Train_Acc: 84.099 Val_Loss: 0.3271  BEST VAL Loss: 0.3271  Val_Acc: 91.259

Epoch 98: Validation loss decreased (0.327121 --> 0.326862).  Saving model ...
	 Train_Loss: 0.4172 Train_Acc: 84.494 Val_Loss: 0.3269  BEST VAL Loss: 0.3269  Val_Acc: 90.437

Epoch 99: Validation loss did not decrease
	 Train_Loss: 0.4169 Train_Acc: 84.223 Val_Loss: 0.3270  BEST VAL Loss: 0.3269  Val_Acc: 90.956

LPS_10.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.58      0.56     10113
           1       0.45      0.42      0.43      8370

    accuracy                           0.51     18483
   macro avg       0.50      0.50      0.50     18483
weighted avg       0.50      0.51      0.50     18483

LPS_10.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.54      0.58      0.56      1264
           1       0.45      0.41      0.43      1047

    accuracy                           0.50      2311
   macro avg       0.49      0.49      0.49      2311
weighted avg       0.50      0.50      0.50      2311

LPS_10.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.54      0.58      0.56      1265
           1       0.44      0.41      0.42      1046

    accuracy                           0.50      2311
   macro avg       0.49      0.49      0.49      2311
weighted avg       0.50      0.50      0.50      2311

              precision    recall  f1-score   support

           0       0.54      0.58      0.56      1265
           1       0.44      0.41      0.42      1046

    accuracy                           0.50      2311
   macro avg       0.49      0.49      0.49      2311
weighted avg       0.50      0.50      0.50      2311

LPS_10.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.56      0.59      0.57      4168
           1       0.44      0.41      0.42      3303

    accuracy                           0.51      7471
   macro avg       0.50      0.50      0.50      7471
weighted avg       0.51      0.51      0.51      7471

              precision    recall  f1-score   support

           0       0.56      0.59      0.57      4168
           1       0.44      0.41      0.42      3303

    accuracy                           0.51      7471
   macro avg       0.50      0.50      0.50      7471
weighted avg       0.51      0.51      0.51      7471

completed
