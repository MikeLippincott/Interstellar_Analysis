[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b921dd7b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '2b40bf78'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1a665c47'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '1527ee7b'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_100.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_100.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_100.000_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (325448, 1270)
Number of total missing values across all columns: 318870
Data Subset Is Off
Wells held out for testing: ['K08' 'J09']
Wells to use for training, validation, and testing ['J02' 'K02' 'J03' 'K03' 'J08' 'K09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.586147).  Saving model ...
	 Train_Loss: 0.6338 Train_Acc: 65.792 Val_Loss: 0.5861  BEST VAL Loss: 0.5861  Val_Acc: 71.490

Epoch 1: Validation loss decreased (0.586147 --> 0.568605).  Saving model ...
	 Train_Loss: 0.6098 Train_Acc: 70.222 Val_Loss: 0.5686  BEST VAL Loss: 0.5686  Val_Acc: 73.727

Epoch 2: Validation loss decreased (0.568605 --> 0.551748).  Saving model ...
	 Train_Loss: 0.5920 Train_Acc: 72.568 Val_Loss: 0.5517  BEST VAL Loss: 0.5517  Val_Acc: 76.298

Epoch 3: Validation loss decreased (0.551748 --> 0.534626).  Saving model ...
	 Train_Loss: 0.5760 Train_Acc: 74.717 Val_Loss: 0.5346  BEST VAL Loss: 0.5346  Val_Acc: 78.844

Epoch 4: Validation loss decreased (0.534626 --> 0.517552).  Saving model ...
	 Train_Loss: 0.5604 Train_Acc: 76.684 Val_Loss: 0.5176  BEST VAL Loss: 0.5176  Val_Acc: 80.910

Epoch 5: Validation loss decreased (0.517552 --> 0.501551).  Saving model ...
	 Train_Loss: 0.5458 Train_Acc: 78.157 Val_Loss: 0.5016  BEST VAL Loss: 0.5016  Val_Acc: 82.186

Epoch 6: Validation loss decreased (0.501551 --> 0.487353).  Saving model ...
	 Train_Loss: 0.5326 Train_Acc: 79.186 Val_Loss: 0.4874  BEST VAL Loss: 0.4874  Val_Acc: 82.931

Epoch 7: Validation loss decreased (0.487353 --> 0.475260).  Saving model ...
	 Train_Loss: 0.5210 Train_Acc: 79.880 Val_Loss: 0.4753  BEST VAL Loss: 0.4753  Val_Acc: 83.241

Epoch 8: Validation loss decreased (0.475260 --> 0.464685).  Saving model ...
	 Train_Loss: 0.5106 Train_Acc: 80.579 Val_Loss: 0.4647  BEST VAL Loss: 0.4647  Val_Acc: 83.518

Epoch 9: Validation loss decreased (0.464685 --> 0.455002).  Saving model ...
	 Train_Loss: 0.5012 Train_Acc: 81.144 Val_Loss: 0.4550  BEST VAL Loss: 0.4550  Val_Acc: 84.272

Epoch 10: Validation loss decreased (0.455002 --> 0.446209).  Saving model ...
	 Train_Loss: 0.4928 Train_Acc: 81.541 Val_Loss: 0.4462  BEST VAL Loss: 0.4462  Val_Acc: 84.582

Epoch 11: Validation loss decreased (0.446209 --> 0.438265).  Saving model ...
	 Train_Loss: 0.4852 Train_Acc: 81.970 Val_Loss: 0.4383  BEST VAL Loss: 0.4383  Val_Acc: 85.018

Epoch 12: Validation loss decreased (0.438265 --> 0.430998).  Saving model ...
	 Train_Loss: 0.4781 Train_Acc: 82.288 Val_Loss: 0.4310  BEST VAL Loss: 0.4310  Val_Acc: 85.209

Epoch 13: Validation loss decreased (0.430998 --> 0.424143).  Saving model ...
	 Train_Loss: 0.4717 Train_Acc: 82.524 Val_Loss: 0.4241  BEST VAL Loss: 0.4241  Val_Acc: 85.804

Epoch 14: Validation loss decreased (0.424143 --> 0.418166).  Saving model ...
	 Train_Loss: 0.4658 Train_Acc: 82.793 Val_Loss: 0.4182  BEST VAL Loss: 0.4182  Val_Acc: 85.621

Epoch 15: Validation loss decreased (0.418166 --> 0.412918).  Saving model ...
	 Train_Loss: 0.4604 Train_Acc: 82.929 Val_Loss: 0.4129  BEST VAL Loss: 0.4129  Val_Acc: 85.572

Epoch 16: Validation loss decreased (0.412918 --> 0.407984).  Saving model ...
	 Train_Loss: 0.4555 Train_Acc: 83.170 Val_Loss: 0.4080  BEST VAL Loss: 0.4080  Val_Acc: 86.012

Epoch 17: Validation loss decreased (0.407984 --> 0.403467).  Saving model ...
	 Train_Loss: 0.4510 Train_Acc: 83.221 Val_Loss: 0.4035  BEST VAL Loss: 0.4035  Val_Acc: 86.020

Epoch 18: Validation loss decreased (0.403467 --> 0.399510).  Saving model ...
	 Train_Loss: 0.4468 Train_Acc: 83.301 Val_Loss: 0.3995  BEST VAL Loss: 0.3995  Val_Acc: 86.069

Epoch 19: Validation loss decreased (0.399510 --> 0.395526).  Saving model ...
	 Train_Loss: 0.4428 Train_Acc: 83.379 Val_Loss: 0.3955  BEST VAL Loss: 0.3955  Val_Acc: 86.448

Epoch 20: Validation loss decreased (0.395526 --> 0.392036).  Saving model ...
	 Train_Loss: 0.4391 Train_Acc: 83.594 Val_Loss: 0.3920  BEST VAL Loss: 0.3920  Val_Acc: 86.297

Epoch 21: Validation loss decreased (0.392036 --> 0.388690).  Saving model ...
	 Train_Loss: 0.4358 Train_Acc: 83.594 Val_Loss: 0.3887  BEST VAL Loss: 0.3887  Val_Acc: 86.415

Epoch 22: Validation loss decreased (0.388690 --> 0.385936).  Saving model ...
	 Train_Loss: 0.4326 Train_Acc: 83.681 Val_Loss: 0.3859  BEST VAL Loss: 0.3859  Val_Acc: 86.036

Epoch 23: Validation loss decreased (0.385936 --> 0.382962).  Saving model ...
	 Train_Loss: 0.4296 Train_Acc: 83.662 Val_Loss: 0.3830  BEST VAL Loss: 0.3830  Val_Acc: 86.615

Epoch 24: Validation loss decreased (0.382962 --> 0.380257).  Saving model ...
	 Train_Loss: 0.4268 Train_Acc: 83.838 Val_Loss: 0.3803  BEST VAL Loss: 0.3803  Val_Acc: 86.586

Epoch 25: Validation loss decreased (0.380257 --> 0.377771).  Saving model ...
	 Train_Loss: 0.4242 Train_Acc: 83.885 Val_Loss: 0.3778  BEST VAL Loss: 0.3778  Val_Acc: 86.395

Epoch 26: Validation loss decreased (0.377771 --> 0.375548).  Saving model ...
	 Train_Loss: 0.4217 Train_Acc: 83.896 Val_Loss: 0.3755  BEST VAL Loss: 0.3755  Val_Acc: 86.427

Epoch 27: Validation loss decreased (0.375548 --> 0.373518).  Saving model ...
	 Train_Loss: 0.4194 Train_Acc: 84.008 Val_Loss: 0.3735  BEST VAL Loss: 0.3735  Val_Acc: 86.419

Epoch 28: Validation loss decreased (0.373518 --> 0.371381).  Saving model ...
	 Train_Loss: 0.4171 Train_Acc: 84.074 Val_Loss: 0.3714  BEST VAL Loss: 0.3714  Val_Acc: 86.778

Epoch 29: Validation loss decreased (0.371381 --> 0.369396).  Saving model ...
	 Train_Loss: 0.4150 Train_Acc: 84.165 Val_Loss: 0.3694  BEST VAL Loss: 0.3694  Val_Acc: 86.668

Epoch 30: Validation loss decreased (0.369396 --> 0.367421).  Saving model ...
	 Train_Loss: 0.4130 Train_Acc: 84.180 Val_Loss: 0.3674  BEST VAL Loss: 0.3674  Val_Acc: 87.071

Epoch 31: Validation loss decreased (0.367421 --> 0.365607).  Saving model ...
	 Train_Loss: 0.4110 Train_Acc: 84.297 Val_Loss: 0.3656  BEST VAL Loss: 0.3656  Val_Acc: 86.851

Epoch 32: Validation loss decreased (0.365607 --> 0.363970).  Saving model ...
	 Train_Loss: 0.4092 Train_Acc: 84.247 Val_Loss: 0.3640  BEST VAL Loss: 0.3640  Val_Acc: 86.839

Epoch 33: Validation loss decreased (0.363970 --> 0.362370).  Saving model ...
	 Train_Loss: 0.4074 Train_Acc: 84.338 Val_Loss: 0.3624  BEST VAL Loss: 0.3624  Val_Acc: 86.847

Epoch 34: Validation loss decreased (0.362370 --> 0.360805).  Saving model ...
	 Train_Loss: 0.4057 Train_Acc: 84.285 Val_Loss: 0.3608  BEST VAL Loss: 0.3608  Val_Acc: 86.843

Epoch 35: Validation loss decreased (0.360805 --> 0.359333).  Saving model ...
	 Train_Loss: 0.4041 Train_Acc: 84.367 Val_Loss: 0.3593  BEST VAL Loss: 0.3593  Val_Acc: 86.920

Epoch 36: Validation loss decreased (0.359333 --> 0.357810).  Saving model ...
	 Train_Loss: 0.4026 Train_Acc: 84.473 Val_Loss: 0.3578  BEST VAL Loss: 0.3578  Val_Acc: 87.291

Epoch 37: Validation loss decreased (0.357810 --> 0.356392).  Saving model ...
	 Train_Loss: 0.4011 Train_Acc: 84.472 Val_Loss: 0.3564  BEST VAL Loss: 0.3564  Val_Acc: 87.132

Epoch 38: Validation loss decreased (0.356392 --> 0.355112).  Saving model ...
	 Train_Loss: 0.3997 Train_Acc: 84.469 Val_Loss: 0.3551  BEST VAL Loss: 0.3551  Val_Acc: 86.819

Epoch 39: Validation loss decreased (0.355112 --> 0.354029).  Saving model ...
	 Train_Loss: 0.3983 Train_Acc: 84.443 Val_Loss: 0.3540  BEST VAL Loss: 0.3540  Val_Acc: 86.472

Epoch 40: Validation loss decreased (0.354029 --> 0.352822).  Saving model ...
	 Train_Loss: 0.3970 Train_Acc: 84.505 Val_Loss: 0.3528  BEST VAL Loss: 0.3528  Val_Acc: 87.010

Epoch 41: Validation loss decreased (0.352822 --> 0.351635).  Saving model ...
	 Train_Loss: 0.3958 Train_Acc: 84.531 Val_Loss: 0.3516  BEST VAL Loss: 0.3516  Val_Acc: 87.197

Epoch 42: Validation loss decreased (0.351635 --> 0.350525).  Saving model ...
	 Train_Loss: 0.3946 Train_Acc: 84.634 Val_Loss: 0.3505  BEST VAL Loss: 0.3505  Val_Acc: 87.092

Epoch 43: Validation loss decreased (0.350525 --> 0.349445).  Saving model ...
	 Train_Loss: 0.3934 Train_Acc: 84.654 Val_Loss: 0.3494  BEST VAL Loss: 0.3494  Val_Acc: 87.189

Epoch 44: Validation loss decreased (0.349445 --> 0.348401).  Saving model ...
	 Train_Loss: 0.3923 Train_Acc: 84.632 Val_Loss: 0.3484  BEST VAL Loss: 0.3484  Val_Acc: 87.218

Epoch 45: Validation loss decreased (0.348401 --> 0.347482).  Saving model ...
	 Train_Loss: 0.3912 Train_Acc: 84.686 Val_Loss: 0.3475  BEST VAL Loss: 0.3475  Val_Acc: 86.920

Epoch 46: Validation loss decreased (0.347482 --> 0.346591).  Saving model ...
	 Train_Loss: 0.3901 Train_Acc: 84.748 Val_Loss: 0.3466  BEST VAL Loss: 0.3466  Val_Acc: 86.892

Epoch 47: Validation loss decreased (0.346591 --> 0.345664).  Saving model ...
	 Train_Loss: 0.3891 Train_Acc: 84.711 Val_Loss: 0.3457  BEST VAL Loss: 0.3457  Val_Acc: 87.144

Epoch 48: Validation loss decreased (0.345664 --> 0.344676).  Saving model ...
	 Train_Loss: 0.3880 Train_Acc: 84.889 Val_Loss: 0.3447  BEST VAL Loss: 0.3447  Val_Acc: 87.413

Epoch 49: Validation loss decreased (0.344676 --> 0.343868).  Saving model ...
	 Train_Loss: 0.3870 Train_Acc: 84.986 Val_Loss: 0.3439  BEST VAL Loss: 0.3439  Val_Acc: 87.100

Epoch 50: Validation loss decreased (0.343868 --> 0.343073).  Saving model ...
	 Train_Loss: 0.3861 Train_Acc: 85.143 Val_Loss: 0.3431  BEST VAL Loss: 0.3431  Val_Acc: 87.173

Epoch 51: Validation loss decreased (0.343073 --> 0.342259).  Saving model ...
	 Train_Loss: 0.3851 Train_Acc: 85.328 Val_Loss: 0.3423  BEST VAL Loss: 0.3423  Val_Acc: 87.206

Epoch 52: Validation loss decreased (0.342259 --> 0.341444).  Saving model ...
	 Train_Loss: 0.3842 Train_Acc: 85.274 Val_Loss: 0.3414  BEST VAL Loss: 0.3414  Val_Acc: 87.340

Epoch 53: Validation loss decreased (0.341444 --> 0.340685).  Saving model ...
	 Train_Loss: 0.3833 Train_Acc: 85.498 Val_Loss: 0.3407  BEST VAL Loss: 0.3407  Val_Acc: 87.169

Epoch 54: Validation loss decreased (0.340685 --> 0.339891).  Saving model ...
	 Train_Loss: 0.3824 Train_Acc: 85.554 Val_Loss: 0.3399  BEST VAL Loss: 0.3399  Val_Acc: 87.511

Epoch 55: Validation loss decreased (0.339891 --> 0.339138).  Saving model ...
	 Train_Loss: 0.3815 Train_Acc: 85.630 Val_Loss: 0.3391  BEST VAL Loss: 0.3391  Val_Acc: 87.462

Epoch 56: Validation loss decreased (0.339138 --> 0.338417).  Saving model ...
	 Train_Loss: 0.3806 Train_Acc: 85.691 Val_Loss: 0.3384  BEST VAL Loss: 0.3384  Val_Acc: 87.259

Epoch 57: Validation loss decreased (0.338417 --> 0.337768).  Saving model ...
	 Train_Loss: 0.3798 Train_Acc: 85.724 Val_Loss: 0.3378  BEST VAL Loss: 0.3378  Val_Acc: 87.149

Epoch 58: Validation loss decreased (0.337768 --> 0.337084).  Saving model ...
	 Train_Loss: 0.3790 Train_Acc: 85.754 Val_Loss: 0.3371  BEST VAL Loss: 0.3371  Val_Acc: 87.279

Epoch 59: Validation loss decreased (0.337084 --> 0.336427).  Saving model ...
	 Train_Loss: 0.3782 Train_Acc: 85.779 Val_Loss: 0.3364  BEST VAL Loss: 0.3364  Val_Acc: 87.250

Epoch 60: Validation loss decreased (0.336427 --> 0.335786).  Saving model ...
	 Train_Loss: 0.3774 Train_Acc: 85.849 Val_Loss: 0.3358  BEST VAL Loss: 0.3358  Val_Acc: 87.295

Epoch 61: Validation loss decreased (0.335786 --> 0.335219).  Saving model ...
	 Train_Loss: 0.3767 Train_Acc: 85.769 Val_Loss: 0.3352  BEST VAL Loss: 0.3352  Val_Acc: 87.087

Epoch 62: Validation loss decreased (0.335219 --> 0.334612).  Saving model ...
	 Train_Loss: 0.3759 Train_Acc: 85.837 Val_Loss: 0.3346  BEST VAL Loss: 0.3346  Val_Acc: 87.320

Epoch 63: Validation loss decreased (0.334612 --> 0.334103).  Saving model ...
	 Train_Loss: 0.3752 Train_Acc: 85.800 Val_Loss: 0.3341  BEST VAL Loss: 0.3341  Val_Acc: 87.006

Epoch 64: Validation loss decreased (0.334103 --> 0.333551).  Saving model ...
	 Train_Loss: 0.3745 Train_Acc: 85.871 Val_Loss: 0.3336  BEST VAL Loss: 0.3336  Val_Acc: 87.120

Epoch 65: Validation loss decreased (0.333551 --> 0.332964).  Saving model ...
	 Train_Loss: 0.3738 Train_Acc: 85.862 Val_Loss: 0.3330  BEST VAL Loss: 0.3330  Val_Acc: 87.483

Epoch 66: Validation loss decreased (0.332964 --> 0.332476).  Saving model ...
	 Train_Loss: 0.3731 Train_Acc: 85.766 Val_Loss: 0.3325  BEST VAL Loss: 0.3325  Val_Acc: 87.185

Epoch 67: Validation loss decreased (0.332476 --> 0.332121).  Saving model ...
	 Train_Loss: 0.3725 Train_Acc: 85.885 Val_Loss: 0.3321  BEST VAL Loss: 0.3321  Val_Acc: 86.590

Epoch 68: Validation loss decreased (0.332121 --> 0.331598).  Saving model ...
	 Train_Loss: 0.3718 Train_Acc: 85.929 Val_Loss: 0.3316  BEST VAL Loss: 0.3316  Val_Acc: 87.413

Epoch 69: Validation loss decreased (0.331598 --> 0.331084).  Saving model ...
	 Train_Loss: 0.3712 Train_Acc: 85.852 Val_Loss: 0.3311  BEST VAL Loss: 0.3311  Val_Acc: 87.430

Epoch 70: Validation loss decreased (0.331084 --> 0.330588).  Saving model ...
	 Train_Loss: 0.3706 Train_Acc: 85.869 Val_Loss: 0.3306  BEST VAL Loss: 0.3306  Val_Acc: 87.519

Epoch 71: Validation loss decreased (0.330588 --> 0.330083).  Saving model ...
	 Train_Loss: 0.3699 Train_Acc: 86.009 Val_Loss: 0.3301  BEST VAL Loss: 0.3301  Val_Acc: 87.393

Epoch 72: Validation loss decreased (0.330083 --> 0.329657).  Saving model ...
	 Train_Loss: 0.3694 Train_Acc: 85.957 Val_Loss: 0.3297  BEST VAL Loss: 0.3297  Val_Acc: 87.018

Epoch 73: Validation loss decreased (0.329657 --> 0.329150).  Saving model ...
	 Train_Loss: 0.3688 Train_Acc: 85.991 Val_Loss: 0.3292  BEST VAL Loss: 0.3292  Val_Acc: 87.532

Epoch 74: Validation loss decreased (0.329150 --> 0.328824).  Saving model ...
	 Train_Loss: 0.3682 Train_Acc: 85.942 Val_Loss: 0.3288  BEST VAL Loss: 0.3288  Val_Acc: 86.835

Epoch 75: Validation loss decreased (0.328824 --> 0.328341).  Saving model ...
	 Train_Loss: 0.3676 Train_Acc: 85.980 Val_Loss: 0.3283  BEST VAL Loss: 0.3283  Val_Acc: 87.544

Epoch 76: Validation loss decreased (0.328341 --> 0.327913).  Saving model ...
	 Train_Loss: 0.3671 Train_Acc: 85.982 Val_Loss: 0.3279  BEST VAL Loss: 0.3279  Val_Acc: 87.405

Epoch 77: Validation loss decreased (0.327913 --> 0.327480).  Saving model ...
	 Train_Loss: 0.3665 Train_Acc: 86.065 Val_Loss: 0.3275  BEST VAL Loss: 0.3275  Val_Acc: 87.430

Epoch 78: Validation loss decreased (0.327480 --> 0.327032).  Saving model ...
	 Train_Loss: 0.3660 Train_Acc: 85.895 Val_Loss: 0.3270  BEST VAL Loss: 0.3270  Val_Acc: 87.430

Epoch 79: Validation loss decreased (0.327032 --> 0.326615).  Saving model ...
	 Train_Loss: 0.3655 Train_Acc: 86.047 Val_Loss: 0.3266  BEST VAL Loss: 0.3266  Val_Acc: 87.409

Epoch 80: Validation loss decreased (0.326615 --> 0.326210).  Saving model ...
	 Train_Loss: 0.3649 Train_Acc: 86.069 Val_Loss: 0.3262  BEST VAL Loss: 0.3262  Val_Acc: 87.446

Epoch 81: Validation loss decreased (0.326210 --> 0.325927).  Saving model ...
	 Train_Loss: 0.3644 Train_Acc: 86.049 Val_Loss: 0.3259  BEST VAL Loss: 0.3259  Val_Acc: 86.676

Epoch 82: Validation loss decreased (0.325927 --> 0.325540).  Saving model ...
	 Train_Loss: 0.3639 Train_Acc: 86.062 Val_Loss: 0.3255  BEST VAL Loss: 0.3255  Val_Acc: 87.385

Epoch 83: Validation loss decreased (0.325540 --> 0.325206).  Saving model ...
	 Train_Loss: 0.3635 Train_Acc: 86.010 Val_Loss: 0.3252  BEST VAL Loss: 0.3252  Val_Acc: 87.039

Epoch 84: Validation loss decreased (0.325206 --> 0.324846).  Saving model ...
	 Train_Loss: 0.3630 Train_Acc: 85.989 Val_Loss: 0.3248  BEST VAL Loss: 0.3248  Val_Acc: 87.401

Epoch 85: Validation loss decreased (0.324846 --> 0.324481).  Saving model ...
	 Train_Loss: 0.3625 Train_Acc: 86.064 Val_Loss: 0.3245  BEST VAL Loss: 0.3245  Val_Acc: 87.568

Epoch 86: Validation loss decreased (0.324481 --> 0.324053).  Saving model ...
	 Train_Loss: 0.3620 Train_Acc: 86.088 Val_Loss: 0.3241  BEST VAL Loss: 0.3241  Val_Acc: 87.633

Epoch 87: Validation loss decreased (0.324053 --> 0.323722).  Saving model ...
	 Train_Loss: 0.3616 Train_Acc: 86.108 Val_Loss: 0.3237  BEST VAL Loss: 0.3237  Val_Acc: 87.393

Epoch 88: Validation loss decreased (0.323722 --> 0.323355).  Saving model ...
	 Train_Loss: 0.3611 Train_Acc: 86.059 Val_Loss: 0.3234  BEST VAL Loss: 0.3234  Val_Acc: 87.470

Epoch 89: Validation loss decreased (0.323355 --> 0.323039).  Saving model ...
	 Train_Loss: 0.3607 Train_Acc: 86.062 Val_Loss: 0.3230  BEST VAL Loss: 0.3230  Val_Acc: 87.234

Epoch 90: Validation loss decreased (0.323039 --> 0.322716).  Saving model ...
	 Train_Loss: 0.3603 Train_Acc: 86.019 Val_Loss: 0.3227  BEST VAL Loss: 0.3227  Val_Acc: 87.287

Epoch 91: Validation loss decreased (0.322716 --> 0.322417).  Saving model ...
	 Train_Loss: 0.3599 Train_Acc: 86.072 Val_Loss: 0.3224  BEST VAL Loss: 0.3224  Val_Acc: 87.153

Epoch 92: Validation loss decreased (0.322417 --> 0.322055).  Saving model ...
	 Train_Loss: 0.3594 Train_Acc: 86.181 Val_Loss: 0.3221  BEST VAL Loss: 0.3221  Val_Acc: 87.711

Epoch 93: Validation loss decreased (0.322055 --> 0.321785).  Saving model ...
	 Train_Loss: 0.3590 Train_Acc: 86.085 Val_Loss: 0.3218  BEST VAL Loss: 0.3218  Val_Acc: 87.120

Epoch 94: Validation loss decreased (0.321785 --> 0.321521).  Saving model ...
	 Train_Loss: 0.3586 Train_Acc: 86.077 Val_Loss: 0.3215  BEST VAL Loss: 0.3215  Val_Acc: 87.287

Epoch 95: Validation loss decreased (0.321521 --> 0.321235).  Saving model ...
	 Train_Loss: 0.3582 Train_Acc: 86.114 Val_Loss: 0.3212  BEST VAL Loss: 0.3212  Val_Acc: 87.202

Epoch 96: Validation loss decreased (0.321235 --> 0.321062).  Saving model ...
	 Train_Loss: 0.3578 Train_Acc: 86.167 Val_Loss: 0.3211  BEST VAL Loss: 0.3211  Val_Acc: 86.733

Epoch 97: Validation loss decreased (0.321062 --> 0.320760).  Saving model ...
	 Train_Loss: 0.3575 Train_Acc: 86.114 Val_Loss: 0.3208  BEST VAL Loss: 0.3208  Val_Acc: 87.625

Epoch 98: Validation loss decreased (0.320760 --> 0.320440).  Saving model ...
	 Train_Loss: 0.3571 Train_Acc: 86.157 Val_Loss: 0.3204  BEST VAL Loss: 0.3204  Val_Acc: 87.678

Epoch 99: Validation loss decreased (0.320440 --> 0.320136).  Saving model ...
	 Train_Loss: 0.3567 Train_Acc: 86.090 Val_Loss: 0.3201  BEST VAL Loss: 0.3201  Val_Acc: 87.792

LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.89      0.89      0.89     95989
           1       0.89      0.89      0.89    100339

    accuracy                           0.89    196328
   macro avg       0.89      0.89      0.89    196328
weighted avg       0.89      0.89      0.89    196328

LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.87      0.88      0.88     11999
           1       0.88      0.88      0.88     12543

    accuracy                           0.88     24542
   macro avg       0.88      0.88      0.88     24542
weighted avg       0.88      0.88      0.88     24542

LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.87      0.88      0.87     11999
           1       0.88      0.88      0.88     12543

    accuracy                           0.88     24542
   macro avg       0.88      0.88      0.88     24542
weighted avg       0.88      0.88      0.88     24542

              precision    recall  f1-score   support

           0       0.87      0.88      0.87     11999
           1       0.88      0.88      0.88     12543

    accuracy                           0.88     24542
   macro avg       0.88      0.88      0.88     24542
weighted avg       0.88      0.88      0.88     24542

LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.92      0.92      0.92     39448
           1       0.92      0.92      0.92     40588

    accuracy                           0.92     80036
   macro avg       0.92      0.92      0.92     80036
weighted avg       0.92      0.92      0.92     80036

              precision    recall  f1-score   support

           0       0.92      0.92      0.92     39448
           1       0.92      0.92      0.92     40588

    accuracy                           0.92     80036
   macro avg       0.92      0.92      0.92     80036
weighted avg       0.92      0.92      0.92     80036

completed
