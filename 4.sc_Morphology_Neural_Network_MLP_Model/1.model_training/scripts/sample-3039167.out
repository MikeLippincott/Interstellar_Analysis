[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd0d27dae'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '595845cf'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '0325c152'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'b6cc7fb8'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_1.000_DMSO_0.025 treatment_name: Thapsigargin_10.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_1.000_DMSO_0.025
TREATMENT_NAME: Thapsigargin_10.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (29021, 1276)
Number of total missing values across all columns: 58042
Data Subset Is Off
Wells held out for testing: ['E14' 'M22']
Wells to use for training, validation, and testing ['E15' 'L14' 'L15' 'M18' 'M19' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.363354).  Saving model ...
	 Train_Loss: 0.5537 Train_Acc: 67.652 Val_Loss: 0.3634  BEST VAL Loss: 0.3634  Val_Acc: 84.359

Epoch 1: Validation loss decreased (0.363354 --> 0.352380).  Saving model ...
	 Train_Loss: 0.4992 Train_Acc: 78.691 Val_Loss: 0.3524  BEST VAL Loss: 0.3524  Val_Acc: 85.331

Epoch 2: Validation loss decreased (0.352380 --> 0.331085).  Saving model ...
	 Train_Loss: 0.4667 Train_Acc: 81.434 Val_Loss: 0.3311  BEST VAL Loss: 0.3311  Val_Acc: 87.691

Epoch 3: Validation loss decreased (0.331085 --> 0.313289).  Saving model ...
	 Train_Loss: 0.4422 Train_Acc: 83.274 Val_Loss: 0.3133  BEST VAL Loss: 0.3133  Val_Acc: 88.801

Epoch 4: Validation loss decreased (0.313289 --> 0.306600).  Saving model ...
	 Train_Loss: 0.4234 Train_Acc: 84.263 Val_Loss: 0.3066  BEST VAL Loss: 0.3066  Val_Acc: 88.200

Epoch 5: Validation loss decreased (0.306600 --> 0.299043).  Saving model ...
	 Train_Loss: 0.4081 Train_Acc: 84.986 Val_Loss: 0.2990  BEST VAL Loss: 0.2990  Val_Acc: 90.421

Epoch 6: Validation loss decreased (0.299043 --> 0.291076).  Saving model ...
	 Train_Loss: 0.3972 Train_Acc: 85.339 Val_Loss: 0.2911  BEST VAL Loss: 0.2911  Val_Acc: 89.449

Epoch 7: Validation loss decreased (0.291076 --> 0.287877).  Saving model ...
	 Train_Loss: 0.3886 Train_Acc: 84.477 Val_Loss: 0.2879  BEST VAL Loss: 0.2879  Val_Acc: 88.987

Epoch 8: Validation loss decreased (0.287877 --> 0.282777).  Saving model ...
	 Train_Loss: 0.3808 Train_Acc: 85.732 Val_Loss: 0.2828  BEST VAL Loss: 0.2828  Val_Acc: 91.485

Epoch 9: Validation loss decreased (0.282777 --> 0.279056).  Saving model ...
	 Train_Loss: 0.3735 Train_Acc: 86.687 Val_Loss: 0.2791  BEST VAL Loss: 0.2791  Val_Acc: 91.485

Epoch 10: Validation loss decreased (0.279056 --> 0.272997).  Saving model ...
	 Train_Loss: 0.3660 Train_Acc: 87.023 Val_Loss: 0.2730  BEST VAL Loss: 0.2730  Val_Acc: 91.624

Epoch 11: Validation loss decreased (0.272997 --> 0.269071).  Saving model ...
	 Train_Loss: 0.3587 Train_Acc: 88.047 Val_Loss: 0.2691  BEST VAL Loss: 0.2691  Val_Acc: 92.133

Epoch 12: Validation loss decreased (0.269071 --> 0.263038).  Saving model ...
	 Train_Loss: 0.3525 Train_Acc: 88.197 Val_Loss: 0.2630  BEST VAL Loss: 0.2630  Val_Acc: 92.689

Epoch 13: Validation loss decreased (0.263038 --> 0.258305).  Saving model ...
	 Train_Loss: 0.3472 Train_Acc: 87.700 Val_Loss: 0.2583  BEST VAL Loss: 0.2583  Val_Acc: 91.161

Epoch 14: Validation loss decreased (0.258305 --> 0.256208).  Saving model ...
	 Train_Loss: 0.3422 Train_Acc: 88.324 Val_Loss: 0.2562  BEST VAL Loss: 0.2562  Val_Acc: 90.097

Epoch 15: Validation loss decreased (0.256208 --> 0.253000).  Saving model ...
	 Train_Loss: 0.3375 Train_Acc: 88.093 Val_Loss: 0.2530  BEST VAL Loss: 0.2530  Val_Acc: 90.745

Epoch 16: Validation loss decreased (0.253000 --> 0.249812).  Saving model ...
	 Train_Loss: 0.3332 Train_Acc: 88.492 Val_Loss: 0.2498  BEST VAL Loss: 0.2498  Val_Acc: 91.300

Epoch 17: Validation loss decreased (0.249812 --> 0.247648).  Saving model ...
	 Train_Loss: 0.3293 Train_Acc: 88.475 Val_Loss: 0.2476  BEST VAL Loss: 0.2476  Val_Acc: 92.041

Epoch 18: Validation loss did not decrease
	 Train_Loss: 0.3259 Train_Acc: 88.573 Val_Loss: 0.2478  BEST VAL Loss: 0.2476  Val_Acc: 92.503

Epoch 19: Validation loss decreased (0.247648 --> 0.246209).  Saving model ...
	 Train_Loss: 0.3222 Train_Acc: 89.360 Val_Loss: 0.2462  BEST VAL Loss: 0.2462  Val_Acc: 91.902

Epoch 20: Validation loss decreased (0.246209 --> 0.243690).  Saving model ...
	 Train_Loss: 0.3195 Train_Acc: 88.429 Val_Loss: 0.2437  BEST VAL Loss: 0.2437  Val_Acc: 91.856

Epoch 21: Validation loss decreased (0.243690 --> 0.241635).  Saving model ...
	 Train_Loss: 0.3166 Train_Acc: 89.302 Val_Loss: 0.2416  BEST VAL Loss: 0.2416  Val_Acc: 92.180

Epoch 22: Validation loss decreased (0.241635 --> 0.240885).  Saving model ...
	 Train_Loss: 0.3134 Train_Acc: 89.424 Val_Loss: 0.2409  BEST VAL Loss: 0.2409  Val_Acc: 92.596

Epoch 23: Validation loss decreased (0.240885 --> 0.238885).  Saving model ...
	 Train_Loss: 0.3111 Train_Acc: 89.030 Val_Loss: 0.2389  BEST VAL Loss: 0.2389  Val_Acc: 92.550

Epoch 24: Validation loss decreased (0.238885 --> 0.237275).  Saving model ...
	 Train_Loss: 0.3080 Train_Acc: 90.205 Val_Loss: 0.2373  BEST VAL Loss: 0.2373  Val_Acc: 91.856

Epoch 25: Validation loss decreased (0.237275 --> 0.235854).  Saving model ...
	 Train_Loss: 0.3056 Train_Acc: 89.505 Val_Loss: 0.2359  BEST VAL Loss: 0.2359  Val_Acc: 91.624

Epoch 26: Validation loss decreased (0.235854 --> 0.235758).  Saving model ...
	 Train_Loss: 0.3033 Train_Acc: 89.592 Val_Loss: 0.2358  BEST VAL Loss: 0.2358  Val_Acc: 92.133

Epoch 27: Validation loss decreased (0.235758 --> 0.235621).  Saving model ...
	 Train_Loss: 0.3013 Train_Acc: 89.383 Val_Loss: 0.2356  BEST VAL Loss: 0.2356  Val_Acc: 92.272

Epoch 28: Validation loss decreased (0.235621 --> 0.234884).  Saving model ...
	 Train_Loss: 0.2991 Train_Acc: 89.979 Val_Loss: 0.2349  BEST VAL Loss: 0.2349  Val_Acc: 92.689

Epoch 29: Validation loss decreased (0.234884 --> 0.233887).  Saving model ...
	 Train_Loss: 0.2972 Train_Acc: 89.875 Val_Loss: 0.2339  BEST VAL Loss: 0.2339  Val_Acc: 92.272

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.2954 Train_Acc: 89.655 Val_Loss: 0.2341  BEST VAL Loss: 0.2339  Val_Acc: 91.856

Epoch 31: Validation loss decreased (0.233887 --> 0.233700).  Saving model ...
	 Train_Loss: 0.2937 Train_Acc: 90.089 Val_Loss: 0.2337  BEST VAL Loss: 0.2337  Val_Acc: 92.365

Epoch 32: Validation loss decreased (0.233700 --> 0.232415).  Saving model ...
	 Train_Loss: 0.2919 Train_Acc: 90.263 Val_Loss: 0.2324  BEST VAL Loss: 0.2324  Val_Acc: 91.161

Epoch 33: Validation loss decreased (0.232415 --> 0.230719).  Saving model ...
	 Train_Loss: 0.2901 Train_Acc: 90.124 Val_Loss: 0.2307  BEST VAL Loss: 0.2307  Val_Acc: 92.226

Epoch 34: Validation loss decreased (0.230719 --> 0.230500).  Saving model ...
	 Train_Loss: 0.2885 Train_Acc: 90.049 Val_Loss: 0.2305  BEST VAL Loss: 0.2305  Val_Acc: 92.272

Epoch 35: Validation loss decreased (0.230500 --> 0.229925).  Saving model ...
	 Train_Loss: 0.2871 Train_Acc: 90.234 Val_Loss: 0.2299  BEST VAL Loss: 0.2299  Val_Acc: 92.365

Epoch 36: Validation loss decreased (0.229925 --> 0.228366).  Saving model ...
	 Train_Loss: 0.2855 Train_Acc: 90.396 Val_Loss: 0.2284  BEST VAL Loss: 0.2284  Val_Acc: 92.781

Epoch 37: Validation loss decreased (0.228366 --> 0.227407).  Saving model ...
	 Train_Loss: 0.2841 Train_Acc: 90.407 Val_Loss: 0.2274  BEST VAL Loss: 0.2274  Val_Acc: 92.272

Epoch 38: Validation loss decreased (0.227407 --> 0.226443).  Saving model ...
	 Train_Loss: 0.2824 Train_Acc: 90.783 Val_Loss: 0.2264  BEST VAL Loss: 0.2264  Val_Acc: 92.457

Epoch 39: Validation loss decreased (0.226443 --> 0.225870).  Saving model ...
	 Train_Loss: 0.2807 Train_Acc: 90.812 Val_Loss: 0.2259  BEST VAL Loss: 0.2259  Val_Acc: 92.503

Epoch 40: Validation loss decreased (0.225870 --> 0.224750).  Saving model ...
	 Train_Loss: 0.2794 Train_Acc: 90.488 Val_Loss: 0.2247  BEST VAL Loss: 0.2247  Val_Acc: 92.642

Epoch 41: Validation loss decreased (0.224750 --> 0.224605).  Saving model ...
	 Train_Loss: 0.2781 Train_Acc: 90.679 Val_Loss: 0.2246  BEST VAL Loss: 0.2246  Val_Acc: 93.151

Epoch 42: Validation loss decreased (0.224605 --> 0.223378).  Saving model ...
	 Train_Loss: 0.2767 Train_Acc: 91.096 Val_Loss: 0.2234  BEST VAL Loss: 0.2234  Val_Acc: 93.151

Epoch 43: Validation loss decreased (0.223378 --> 0.222652).  Saving model ...
	 Train_Loss: 0.2756 Train_Acc: 90.448 Val_Loss: 0.2227  BEST VAL Loss: 0.2227  Val_Acc: 92.874

Epoch 44: Validation loss decreased (0.222652 --> 0.221504).  Saving model ...
	 Train_Loss: 0.2744 Train_Acc: 90.974 Val_Loss: 0.2215  BEST VAL Loss: 0.2215  Val_Acc: 93.012

Epoch 45: Validation loss decreased (0.221504 --> 0.220950).  Saving model ...
	 Train_Loss: 0.2732 Train_Acc: 90.581 Val_Loss: 0.2210  BEST VAL Loss: 0.2210  Val_Acc: 92.689

Epoch 46: Validation loss decreased (0.220950 --> 0.220473).  Saving model ...
	 Train_Loss: 0.2720 Train_Acc: 90.911 Val_Loss: 0.2205  BEST VAL Loss: 0.2205  Val_Acc: 93.012

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.2709 Train_Acc: 90.969 Val_Loss: 0.2207  BEST VAL Loss: 0.2205  Val_Acc: 93.105

Epoch 48: Validation loss decreased (0.220473 --> 0.219958).  Saving model ...
	 Train_Loss: 0.2700 Train_Acc: 90.523 Val_Loss: 0.2200  BEST VAL Loss: 0.2200  Val_Acc: 92.272

Epoch 49: Validation loss decreased (0.219958 --> 0.219704).  Saving model ...
	 Train_Loss: 0.2691 Train_Acc: 90.598 Val_Loss: 0.2197  BEST VAL Loss: 0.2197  Val_Acc: 92.503

Epoch 50: Validation loss decreased (0.219704 --> 0.219647).  Saving model ...
	 Train_Loss: 0.2682 Train_Acc: 90.702 Val_Loss: 0.2196  BEST VAL Loss: 0.2196  Val_Acc: 93.290

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.2673 Train_Acc: 90.835 Val_Loss: 0.2199  BEST VAL Loss: 0.2196  Val_Acc: 92.827

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.2665 Train_Acc: 90.963 Val_Loss: 0.2197  BEST VAL Loss: 0.2196  Val_Acc: 93.198

Epoch 53: Validation loss decreased (0.219647 --> 0.218636).  Saving model ...
	 Train_Loss: 0.2657 Train_Acc: 90.610 Val_Loss: 0.2186  BEST VAL Loss: 0.2186  Val_Acc: 93.059

Epoch 54: Validation loss decreased (0.218636 --> 0.217802).  Saving model ...
	 Train_Loss: 0.2648 Train_Acc: 90.864 Val_Loss: 0.2178  BEST VAL Loss: 0.2178  Val_Acc: 93.198

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.2639 Train_Acc: 91.310 Val_Loss: 0.2184  BEST VAL Loss: 0.2178  Val_Acc: 92.966

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.2632 Train_Acc: 90.737 Val_Loss: 0.2185  BEST VAL Loss: 0.2178  Val_Acc: 93.336

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.2623 Train_Acc: 90.980 Val_Loss: 0.2182  BEST VAL Loss: 0.2178  Val_Acc: 93.105

Epoch 58: Validation loss decreased (0.217802 --> 0.217442).  Saving model ...
	 Train_Loss: 0.2614 Train_Acc: 91.374 Val_Loss: 0.2174  BEST VAL Loss: 0.2174  Val_Acc: 92.781

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.2606 Train_Acc: 91.333 Val_Loss: 0.2175  BEST VAL Loss: 0.2174  Val_Acc: 92.735

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.2597 Train_Acc: 91.576 Val_Loss: 0.2178  BEST VAL Loss: 0.2174  Val_Acc: 93.198

Epoch 61: Validation loss decreased (0.217442 --> 0.217290).  Saving model ...
	 Train_Loss: 0.2590 Train_Acc: 91.426 Val_Loss: 0.2173  BEST VAL Loss: 0.2173  Val_Acc: 93.336

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.2582 Train_Acc: 91.269 Val_Loss: 0.2175  BEST VAL Loss: 0.2173  Val_Acc: 93.429

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.2574 Train_Acc: 91.709 Val_Loss: 0.2174  BEST VAL Loss: 0.2173  Val_Acc: 93.244

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.2565 Train_Acc: 91.865 Val_Loss: 0.2174  BEST VAL Loss: 0.2173  Val_Acc: 93.105

Epoch 65: Validation loss decreased (0.217290 --> 0.216934).  Saving model ...
	 Train_Loss: 0.2557 Train_Acc: 91.507 Val_Loss: 0.2169  BEST VAL Loss: 0.2169  Val_Acc: 93.383

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.2550 Train_Acc: 91.755 Val_Loss: 0.2173  BEST VAL Loss: 0.2169  Val_Acc: 93.614

Epoch 67: Validation loss decreased (0.216934 --> 0.216767).  Saving model ...
	 Train_Loss: 0.2542 Train_Acc: 92.022 Val_Loss: 0.2168  BEST VAL Loss: 0.2168  Val_Acc: 92.920

Epoch 68: Validation loss decreased (0.216767 --> 0.216108).  Saving model ...
	 Train_Loss: 0.2534 Train_Acc: 91.588 Val_Loss: 0.2161  BEST VAL Loss: 0.2161  Val_Acc: 93.151

Epoch 69: Validation loss decreased (0.216108 --> 0.216006).  Saving model ...
	 Train_Loss: 0.2527 Train_Acc: 91.669 Val_Loss: 0.2160  BEST VAL Loss: 0.2160  Val_Acc: 92.874

Epoch 70: Validation loss decreased (0.216006 --> 0.215226).  Saving model ...
	 Train_Loss: 0.2520 Train_Acc: 92.010 Val_Loss: 0.2152  BEST VAL Loss: 0.2152  Val_Acc: 93.198

Epoch 71: Validation loss decreased (0.215226 --> 0.214633).  Saving model ...
	 Train_Loss: 0.2512 Train_Acc: 92.299 Val_Loss: 0.2146  BEST VAL Loss: 0.2146  Val_Acc: 92.966

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.2506 Train_Acc: 91.865 Val_Loss: 0.2146  BEST VAL Loss: 0.2146  Val_Acc: 93.429

Epoch 73: Validation loss decreased (0.214633 --> 0.214594).  Saving model ...
	 Train_Loss: 0.2499 Train_Acc: 91.860 Val_Loss: 0.2146  BEST VAL Loss: 0.2146  Val_Acc: 93.290

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.2492 Train_Acc: 92.172 Val_Loss: 0.2149  BEST VAL Loss: 0.2146  Val_Acc: 93.475

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.2485 Train_Acc: 92.062 Val_Loss: 0.2151  BEST VAL Loss: 0.2146  Val_Acc: 93.845

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.2478 Train_Acc: 92.068 Val_Loss: 0.2150  BEST VAL Loss: 0.2146  Val_Acc: 93.984

Epoch 77: Validation loss decreased (0.214594 --> 0.214533).  Saving model ...
	 Train_Loss: 0.2470 Train_Acc: 92.733 Val_Loss: 0.2145  BEST VAL Loss: 0.2145  Val_Acc: 93.383

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.2464 Train_Acc: 92.212 Val_Loss: 0.2155  BEST VAL Loss: 0.2145  Val_Acc: 92.874

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.2459 Train_Acc: 91.964 Val_Loss: 0.2150  BEST VAL Loss: 0.2145  Val_Acc: 93.059

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.2454 Train_Acc: 91.952 Val_Loss: 0.2151  BEST VAL Loss: 0.2145  Val_Acc: 93.336

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.2448 Train_Acc: 91.860 Val_Loss: 0.2150  BEST VAL Loss: 0.2145  Val_Acc: 93.105

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.2443 Train_Acc: 92.010 Val_Loss: 0.2146  BEST VAL Loss: 0.2145  Val_Acc: 93.244

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.2438 Train_Acc: 91.848 Val_Loss: 0.2146  BEST VAL Loss: 0.2145  Val_Acc: 93.059

Epoch 84: Validation loss decreased (0.214533 --> 0.214409).  Saving model ...
	 Train_Loss: 0.2433 Train_Acc: 91.854 Val_Loss: 0.2144  BEST VAL Loss: 0.2144  Val_Acc: 93.290

Epoch 85: Validation loss decreased (0.214409 --> 0.214035).  Saving model ...
	 Train_Loss: 0.2427 Train_Acc: 92.542 Val_Loss: 0.2140  BEST VAL Loss: 0.2140  Val_Acc: 93.198

Epoch 86: Validation loss decreased (0.214035 --> 0.213671).  Saving model ...
	 Train_Loss: 0.2422 Train_Acc: 92.224 Val_Loss: 0.2137  BEST VAL Loss: 0.2137  Val_Acc: 93.244

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.2418 Train_Acc: 91.790 Val_Loss: 0.2140  BEST VAL Loss: 0.2137  Val_Acc: 93.522

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.2414 Train_Acc: 91.998 Val_Loss: 0.2139  BEST VAL Loss: 0.2137  Val_Acc: 93.753

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.2410 Train_Acc: 92.027 Val_Loss: 0.2139  BEST VAL Loss: 0.2137  Val_Acc: 93.429

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.2406 Train_Acc: 91.651 Val_Loss: 0.2141  BEST VAL Loss: 0.2137  Val_Acc: 93.984

Epoch 91: Validation loss decreased (0.213671 --> 0.213562).  Saving model ...
	 Train_Loss: 0.2402 Train_Acc: 92.033 Val_Loss: 0.2136  BEST VAL Loss: 0.2136  Val_Acc: 92.735

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.2398 Train_Acc: 91.912 Val_Loss: 0.2137  BEST VAL Loss: 0.2136  Val_Acc: 93.522

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.2394 Train_Acc: 92.293 Val_Loss: 0.2137  BEST VAL Loss: 0.2136  Val_Acc: 93.429

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.2389 Train_Acc: 92.160 Val_Loss: 0.2136  BEST VAL Loss: 0.2136  Val_Acc: 93.614

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.2385 Train_Acc: 92.230 Val_Loss: 0.2140  BEST VAL Loss: 0.2136  Val_Acc: 93.383

Epoch 96: Validation loss did not decrease
	 Train_Loss: 0.2381 Train_Acc: 91.640 Val_Loss: 0.2136  BEST VAL Loss: 0.2136  Val_Acc: 93.198

Epoch 97: Validation loss decreased (0.213562 --> 0.213392).  Saving model ...
	 Train_Loss: 0.2378 Train_Acc: 92.039 Val_Loss: 0.2134  BEST VAL Loss: 0.2134  Val_Acc: 93.105

Epoch 98: Validation loss decreased (0.213392 --> 0.213146).  Saving model ...
	 Train_Loss: 0.2375 Train_Acc: 91.304 Val_Loss: 0.2131  BEST VAL Loss: 0.2131  Val_Acc: 93.522

Epoch 99: Validation loss decreased (0.213146 --> 0.212722).  Saving model ...
	 Train_Loss: 0.2372 Train_Acc: 91.669 Val_Loss: 0.2127  BEST VAL Loss: 0.2127  Val_Acc: 93.475

Flagellin_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.52      0.54      9434
           1       0.46      0.48      0.47      7850

    accuracy                           0.51     17284
   macro avg       0.50      0.50      0.50     17284
weighted avg       0.51      0.51      0.51     17284

Flagellin_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.52      0.54      1179
           1       0.46      0.49      0.48       982

    accuracy                           0.51      2161
   macro avg       0.51      0.51      0.51      2161
weighted avg       0.51      0.51      0.51      2161

Flagellin_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.53      0.54      1179
           1       0.46      0.48      0.47       982

    accuracy                           0.51      2161
   macro avg       0.51      0.51      0.51      2161
weighted avg       0.51      0.51      0.51      2161

              precision    recall  f1-score   support

           0       0.55      0.53      0.54      1179
           1       0.46      0.48      0.47       982

    accuracy                           0.51      2161
   macro avg       0.51      0.51      0.51      2161
weighted avg       0.51      0.51      0.51      2161

Flagellin_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.50      0.52      4017
           1       0.46      0.51      0.49      3398

    accuracy                           0.50      7415
   macro avg       0.50      0.50      0.50      7415
weighted avg       0.51      0.50      0.50      7415

              precision    recall  f1-score   support

           0       0.55      0.50      0.52      4017
           1       0.46      0.51      0.49      3398

    accuracy                           0.50      7415
   macro avg       0.50      0.50      0.50      7415
weighted avg       0.51      0.50      0.50      7415

completed
