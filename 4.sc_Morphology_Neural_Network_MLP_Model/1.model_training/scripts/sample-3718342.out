[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 18688 bytes to train_binary_model.py
[NbConvertApp] Converting notebook ../notebooks/train_multiclass_model.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: MissingIDFieldWarning: Code cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.
  validate(nb)
[NbConvertApp] Writing 31106 bytes to train_multiclass_model.py
[NbConvertApp] Converting notebook ../notebooks/train_regression_model.ipynb to script
[NbConvertApp] Writing 25120 bytes to train_regression_model.py
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:313: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels.drop_duplicates(inplace=True)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1015: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1016: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1015: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1016: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1036: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:577: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:651: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1219: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:879: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1219: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:1095: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
PBMC MultiClass_MLP True
[0.9436581681188537, 0.5245113046249099, 0.5318305272562364]
Data Subset Is Off
(1483474,) (370869,) (2207496,) (1536843,)
(1483474,) (370869,) (2207496,) (1536843,)
5598682
(95928,) (749319,) (638227,)
(23982,) (187329,) (159558,)
(119911,) (936644,) (1150941,)
(75619,) (788818,) (672406,)
(1483474, 1245) (370869, 1245) (2207496, 1245) (1536843, 1245)
(1483474,) (370869,) (2207496,) (1536843,)
Number of in features:  1245
Number of out features:  3
Multi_Class
Adam
Epoch 0: Validation loss decreased (inf --> 0.739382).  Saving model ...
	 Train_Loss: 0.8086 Train_Acc: 66.320 Val_Loss: 0.7394  BEST VAL Loss: 0.7394  Val_Acc: 69.717

Epoch 1: Validation loss decreased (0.739382 --> 0.721802).  Saving model ...
	 Train_Loss: 0.7924 Train_Acc: 68.508 Val_Loss: 0.7218  BEST VAL Loss: 0.7218  Val_Acc: 71.941

Epoch 2: Validation loss decreased (0.721802 --> 0.716793).  Saving model ...
	 Train_Loss: 0.7811 Train_Acc: 69.179 Val_Loss: 0.7168  BEST VAL Loss: 0.7168  Val_Acc: 69.714

Epoch 3: Validation loss decreased (0.716793 --> 0.708972).  Saving model ...
	 Train_Loss: 0.7723 Train_Acc: 69.808 Val_Loss: 0.7090  BEST VAL Loss: 0.7090  Val_Acc: 72.547

Epoch 4: Validation loss decreased (0.708972 --> 0.698580).  Saving model ...
	 Train_Loss: 0.7651 Train_Acc: 70.431 Val_Loss: 0.6986  BEST VAL Loss: 0.6986  Val_Acc: 73.240

Epoch 5: Validation loss decreased (0.698580 --> 0.694167).  Saving model ...
	 Train_Loss: 0.7587 Train_Acc: 70.876 Val_Loss: 0.6942  BEST VAL Loss: 0.6942  Val_Acc: 73.504

Epoch 6: Validation loss decreased (0.694167 --> 0.687925).  Saving model ...
	 Train_Loss: 0.7532 Train_Acc: 71.187 Val_Loss: 0.6879  BEST VAL Loss: 0.6879  Val_Acc: 73.972

Epoch 7: Validation loss decreased (0.687925 --> 0.684750).  Saving model ...
	 Train_Loss: 0.7480 Train_Acc: 71.557 Val_Loss: 0.6848  BEST VAL Loss: 0.6848  Val_Acc: 73.990

Epoch 8: Validation loss decreased (0.684750 --> 0.679796).  Saving model ...
	 Train_Loss: 0.7434 Train_Acc: 71.775 Val_Loss: 0.6798  BEST VAL Loss: 0.6798  Val_Acc: 74.116

Epoch 9: Validation loss decreased (0.679796 --> 0.675629).  Saving model ...
	 Train_Loss: 0.7401 Train_Acc: 71.824 Val_Loss: 0.6756  BEST VAL Loss: 0.6756  Val_Acc: 74.264

Epoch 10: Validation loss decreased (0.675629 --> 0.670725).  Saving model ...
	 Train_Loss: 0.7374 Train_Acc: 72.123 Val_Loss: 0.6707  BEST VAL Loss: 0.6707  Val_Acc: 75.072

Epoch 11: Validation loss decreased (0.670725 --> 0.667550).  Saving model ...
	 Train_Loss: 0.7349 Train_Acc: 72.286 Val_Loss: 0.6675  BEST VAL Loss: 0.6675  Val_Acc: 75.087

Epoch 12: Validation loss decreased (0.667550 --> 0.664263).  Saving model ...
	 Train_Loss: 0.7326 Train_Acc: 72.380 Val_Loss: 0.6643  BEST VAL Loss: 0.6643  Val_Acc: 75.076

Epoch 13: Validation loss decreased (0.664263 --> 0.662324).  Saving model ...
	 Train_Loss: 0.7306 Train_Acc: 72.497 Val_Loss: 0.6623  BEST VAL Loss: 0.6623  Val_Acc: 75.420

Epoch 14: Validation loss decreased (0.662324 --> 0.659753).  Saving model ...
	 Train_Loss: 0.7286 Train_Acc: 72.678 Val_Loss: 0.6598  BEST VAL Loss: 0.6598  Val_Acc: 75.065

Epoch 15: Validation loss decreased (0.659753 --> 0.657603).  Saving model ...
	 Train_Loss: 0.7267 Train_Acc: 72.761 Val_Loss: 0.6576  BEST VAL Loss: 0.6576  Val_Acc: 75.667

Epoch 16: Validation loss decreased (0.657603 --> 0.655382).  Saving model ...
	 Train_Loss: 0.7250 Train_Acc: 72.871 Val_Loss: 0.6554  BEST VAL Loss: 0.6554  Val_Acc: 75.950

Epoch 17: Validation loss decreased (0.655382 --> 0.654092).  Saving model ...
	 Train_Loss: 0.7234 Train_Acc: 72.910 Val_Loss: 0.6541  BEST VAL Loss: 0.6541  Val_Acc: 73.111

Epoch 18: Validation loss decreased (0.654092 --> 0.653490).  Saving model ...
	 Train_Loss: 0.7219 Train_Acc: 72.949 Val_Loss: 0.6535  BEST VAL Loss: 0.6535  Val_Acc: 75.891

Epoch 19: Validation loss decreased (0.653490 --> 0.651524).  Saving model ...
	 Train_Loss: 0.7204 Train_Acc: 73.113 Val_Loss: 0.6515  BEST VAL Loss: 0.6515  Val_Acc: 76.184

Epoch 20: Validation loss decreased (0.651524 --> 0.650441).  Saving model ...
	 Train_Loss: 0.7190 Train_Acc: 73.149 Val_Loss: 0.6504  BEST VAL Loss: 0.6504  Val_Acc: 76.324

Epoch 21: Validation loss decreased (0.650441 --> 0.648475).  Saving model ...
	 Train_Loss: 0.7177 Train_Acc: 72.929 Val_Loss: 0.6485  BEST VAL Loss: 0.6485  Val_Acc: 76.489

Epoch 22: Validation loss decreased (0.648475 --> 0.646800).  Saving model ...
	 Train_Loss: 0.7165 Train_Acc: 72.585 Val_Loss: 0.6468  BEST VAL Loss: 0.6468  Val_Acc: 75.791

Epoch 23: Validation loss decreased (0.646800 --> 0.644928).  Saving model ...
	 Train_Loss: 0.7153 Train_Acc: 72.537 Val_Loss: 0.6449  BEST VAL Loss: 0.6449  Val_Acc: 76.445

Epoch 24: Validation loss decreased (0.644928 --> 0.643757).  Saving model ...
	 Train_Loss: 0.7140 Train_Acc: 72.875 Val_Loss: 0.6438  BEST VAL Loss: 0.6438  Val_Acc: 76.408

Epoch 25: Validation loss decreased (0.643757 --> 0.643174).  Saving model ...
	 Train_Loss: 0.7132 Train_Acc: 72.705 Val_Loss: 0.6432  BEST VAL Loss: 0.6432  Val_Acc: 75.758

Epoch 26: Validation loss decreased (0.643174 --> 0.642952).  Saving model ...
	 Train_Loss: 0.7125 Train_Acc: 72.778 Val_Loss: 0.6430  BEST VAL Loss: 0.6430  Val_Acc: 76.288

Epoch 27: Validation loss decreased (0.642952 --> 0.642460).  Saving model ...
	 Train_Loss: 0.7120 Train_Acc: 72.825 Val_Loss: 0.6425  BEST VAL Loss: 0.6425  Val_Acc: 76.373

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.7119 Train_Acc: 72.640 Val_Loss: 0.6431  BEST VAL Loss: 0.6425  Val_Acc: 75.814

Epoch 29: Validation loss did not decrease
	 Train_Loss: 0.7122 Train_Acc: 72.712 Val_Loss: 0.6432  BEST VAL Loss: 0.6425  Val_Acc: 76.952

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.7124 Train_Acc: 72.833 Val_Loss: 0.6431  BEST VAL Loss: 0.6425  Val_Acc: 77.033

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.7126 Train_Acc: 72.891 Val_Loss: 0.6434  BEST VAL Loss: 0.6425  Val_Acc: 75.928

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.7128 Train_Acc: 72.886 Val_Loss: 0.6436  BEST VAL Loss: 0.6425  Val_Acc: 76.939

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.7130 Train_Acc: 72.895 Val_Loss: 0.6437  BEST VAL Loss: 0.6425  Val_Acc: 76.882

Epoch 34: Validation loss did not decrease
	 Train_Loss: 0.7131 Train_Acc: 73.004 Val_Loss: 0.6434  BEST VAL Loss: 0.6425  Val_Acc: 77.158

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.7132 Train_Acc: 72.996 Val_Loss: 0.6437  BEST VAL Loss: 0.6425  Val_Acc: 74.770

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.7133 Train_Acc: 73.056 Val_Loss: 0.6439  BEST VAL Loss: 0.6425  Val_Acc: 76.705

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.7133 Train_Acc: 73.039 Val_Loss: 0.6440  BEST VAL Loss: 0.6425  Val_Acc: 76.710

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.7133 Train_Acc: 73.133 Val_Loss: 0.6441  BEST VAL Loss: 0.6425  Val_Acc: 76.914

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.7134 Train_Acc: 73.136 Val_Loss: 0.6438  BEST VAL Loss: 0.6425  Val_Acc: 77.077

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.7133 Train_Acc: 73.205 Val_Loss: 0.6438  BEST VAL Loss: 0.6425  Val_Acc: 76.886

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.7133 Train_Acc: 73.215 Val_Loss: 0.6437  BEST VAL Loss: 0.6425  Val_Acc: 77.095

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.7133 Train_Acc: 73.202 Val_Loss: 0.6438  BEST VAL Loss: 0.6425  Val_Acc: 76.777

Epoch 43: Validation loss did not decrease
Early stopped at epoch : 43
MultiClass_MLP_shuffle
              precision    recall  f1-score   support

           0       0.07      0.03      0.04     95928
           1       0.51      0.69      0.58    749319
           2       0.43      0.28      0.34    638227

    accuracy                           0.47   1483474
   macro avg       0.33      0.33      0.32   1483474
weighted avg       0.44      0.47      0.44   1483474

MultiClass_MLP_shuffle
              precision    recall  f1-score   support

           0       0.06      0.03      0.04     23982
           1       0.51      0.69      0.58    187329
           2       0.43      0.28      0.34    159558

    accuracy                           0.47    370869
   macro avg       0.33      0.33      0.32    370869
weighted avg       0.44      0.47      0.44    370869

MultiClass_MLP_shuffle
              precision    recall  f1-score   support

           0       0.05      0.03      0.04    119911
           1       0.42      0.64      0.51    936644
           2       0.52      0.33      0.41   1150941

    accuracy                           0.45   2207496
   macro avg       0.33      0.33      0.32   2207496
weighted avg       0.45      0.45      0.43   2207496

Precision for class 0: 0.05415274917360378
Recall for class 0: 0.026094353312039763
Precision for class 1: 0.4241132599998589
Recall for class 1: 0.6417411524549349
Precision for class 2: 0.5215395012594802
Recall for class 2: 0.3319014614997641
3
              precision    recall  f1-score   support

           0       0.05      0.03      0.04    119911
           1       0.42      0.64      0.51    936644
           2       0.52      0.33      0.41   1150941

    accuracy                           0.45   2207496
   macro avg       0.33      0.33      0.32   2207496
weighted avg       0.45      0.45      0.43   2207496

MultiClass_MLP_shuffle
              precision    recall  f1-score   support

           0       0.05      0.02      0.03     75619
           1       0.51      0.56      0.54    788818
           2       0.44      0.41      0.42    672406

    accuracy                           0.47   1536843
   macro avg       0.33      0.33      0.33   1536843
weighted avg       0.46      0.47      0.46   1536843

Precision for class 0: 0.04872193578307008
Recall for class 0: 0.02361840278236951
Precision for class 1: 0.5131631687711026
Recall for class 1: 0.5631856778116118
Precision for class 2: 0.4371488238307261
Recall for class 2: 0.4124888832044925
3
              precision    recall  f1-score   support

           0       0.05      0.02      0.03     75619
           1       0.51      0.56      0.54    788818
           2       0.44      0.41      0.42    672406

    accuracy                           0.47   1536843
   macro avg       0.33      0.33      0.33   1536843
weighted avg       0.46      0.47      0.46   1536843

Done
