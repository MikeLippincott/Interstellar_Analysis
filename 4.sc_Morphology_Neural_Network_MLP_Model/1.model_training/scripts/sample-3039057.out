[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '9933d8d9'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'd7072b86'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '14661df5'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '3711ca20'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (312858, 1270)
Number of total missing values across all columns: 277194
Data Subset Is Off
Wells held out for testing: ['C09' 'L09']
Wells to use for training, validation, and testing ['C02' 'C03' 'C08' 'L02' 'L03' 'L08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.277176).  Saving model ...
	 Train_Loss: 0.4528 Train_Acc: 81.860 Val_Loss: 0.2772  BEST VAL Loss: 0.2772  Val_Acc: 89.918

Epoch 1: Validation loss decreased (0.277176 --> 0.256348).  Saving model ...
	 Train_Loss: 0.3690 Train_Acc: 88.468 Val_Loss: 0.2563  BEST VAL Loss: 0.2563  Val_Acc: 90.825

Epoch 2: Validation loss decreased (0.256348 --> 0.250019).  Saving model ...
	 Train_Loss: 0.3334 Train_Acc: 89.639 Val_Loss: 0.2500  BEST VAL Loss: 0.2500  Val_Acc: 91.876

Epoch 3: Validation loss decreased (0.250019 --> 0.237846).  Saving model ...
	 Train_Loss: 0.3129 Train_Acc: 90.160 Val_Loss: 0.2378  BEST VAL Loss: 0.2378  Val_Acc: 92.285

Epoch 4: Validation loss decreased (0.237846 --> 0.229560).  Saving model ...
	 Train_Loss: 0.2982 Train_Acc: 90.574 Val_Loss: 0.2296  BEST VAL Loss: 0.2296  Val_Acc: 92.868

Epoch 5: Validation loss decreased (0.229560 --> 0.222058).  Saving model ...
	 Train_Loss: 0.2876 Train_Acc: 90.933 Val_Loss: 0.2221  BEST VAL Loss: 0.2221  Val_Acc: 93.159

Epoch 6: Validation loss decreased (0.222058 --> 0.217300).  Saving model ...
	 Train_Loss: 0.2791 Train_Acc: 91.062 Val_Loss: 0.2173  BEST VAL Loss: 0.2173  Val_Acc: 92.931

Epoch 7: Validation loss decreased (0.217300 --> 0.212337).  Saving model ...
	 Train_Loss: 0.2725 Train_Acc: 91.193 Val_Loss: 0.2123  BEST VAL Loss: 0.2123  Val_Acc: 93.176

Epoch 8: Validation loss decreased (0.212337 --> 0.210967).  Saving model ...
	 Train_Loss: 0.2671 Train_Acc: 91.241 Val_Loss: 0.2110  BEST VAL Loss: 0.2110  Val_Acc: 92.728

Epoch 9: Validation loss decreased (0.210967 --> 0.207736).  Saving model ...
	 Train_Loss: 0.2623 Train_Acc: 91.420 Val_Loss: 0.2077  BEST VAL Loss: 0.2077  Val_Acc: 93.264

Epoch 10: Validation loss decreased (0.207736 --> 0.205380).  Saving model ...
	 Train_Loss: 0.2584 Train_Acc: 91.496 Val_Loss: 0.2054  BEST VAL Loss: 0.2054  Val_Acc: 93.138

Epoch 11: Validation loss decreased (0.205380 --> 0.202870).  Saving model ...
	 Train_Loss: 0.2549 Train_Acc: 91.543 Val_Loss: 0.2029  BEST VAL Loss: 0.2029  Val_Acc: 93.433

Epoch 12: Validation loss decreased (0.202870 --> 0.201238).  Saving model ...
	 Train_Loss: 0.2519 Train_Acc: 91.651 Val_Loss: 0.2012  BEST VAL Loss: 0.2012  Val_Acc: 93.142

Epoch 13: Validation loss decreased (0.201238 --> 0.200538).  Saving model ...
	 Train_Loss: 0.2492 Train_Acc: 91.614 Val_Loss: 0.2005  BEST VAL Loss: 0.2005  Val_Acc: 92.353

Epoch 14: Validation loss decreased (0.200538 --> 0.198411).  Saving model ...
	 Train_Loss: 0.2469 Train_Acc: 91.765 Val_Loss: 0.1984  BEST VAL Loss: 0.1984  Val_Acc: 93.594

Epoch 15: Validation loss decreased (0.198411 --> 0.196706).  Saving model ...
	 Train_Loss: 0.2448 Train_Acc: 91.752 Val_Loss: 0.1967  BEST VAL Loss: 0.1967  Val_Acc: 93.623

Epoch 16: Validation loss decreased (0.196706 --> 0.195597).  Saving model ...
	 Train_Loss: 0.2428 Train_Acc: 91.850 Val_Loss: 0.1956  BEST VAL Loss: 0.1956  Val_Acc: 93.598

Epoch 17: Validation loss decreased (0.195597 --> 0.194857).  Saving model ...
	 Train_Loss: 0.2410 Train_Acc: 91.776 Val_Loss: 0.1949  BEST VAL Loss: 0.1949  Val_Acc: 93.281

Epoch 18: Validation loss decreased (0.194857 --> 0.193666).  Saving model ...
	 Train_Loss: 0.2394 Train_Acc: 91.825 Val_Loss: 0.1937  BEST VAL Loss: 0.1937  Val_Acc: 93.678

Epoch 19: Validation loss decreased (0.193666 --> 0.192303).  Saving model ...
	 Train_Loss: 0.2379 Train_Acc: 91.926 Val_Loss: 0.1923  BEST VAL Loss: 0.1923  Val_Acc: 93.754

Epoch 20: Validation loss decreased (0.192303 --> 0.191291).  Saving model ...
	 Train_Loss: 0.2365 Train_Acc: 91.919 Val_Loss: 0.1913  BEST VAL Loss: 0.1913  Val_Acc: 93.682

Epoch 21: Validation loss decreased (0.191291 --> 0.190510).  Saving model ...
	 Train_Loss: 0.2352 Train_Acc: 91.875 Val_Loss: 0.1905  BEST VAL Loss: 0.1905  Val_Acc: 93.345

Epoch 22: Validation loss decreased (0.190510 --> 0.190275).  Saving model ...
	 Train_Loss: 0.2339 Train_Acc: 91.960 Val_Loss: 0.1903  BEST VAL Loss: 0.1903  Val_Acc: 93.264

Epoch 23: Validation loss decreased (0.190275 --> 0.189521).  Saving model ...
	 Train_Loss: 0.2328 Train_Acc: 91.892 Val_Loss: 0.1895  BEST VAL Loss: 0.1895  Val_Acc: 93.699

Epoch 24: Validation loss decreased (0.189521 --> 0.188698).  Saving model ...
	 Train_Loss: 0.2318 Train_Acc: 92.011 Val_Loss: 0.1887  BEST VAL Loss: 0.1887  Val_Acc: 93.404

Epoch 25: Validation loss decreased (0.188698 --> 0.187902).  Saving model ...
	 Train_Loss: 0.2308 Train_Acc: 92.020 Val_Loss: 0.1879  BEST VAL Loss: 0.1879  Val_Acc: 93.648

Epoch 26: Validation loss decreased (0.187902 --> 0.187294).  Saving model ...
	 Train_Loss: 0.2298 Train_Acc: 92.056 Val_Loss: 0.1873  BEST VAL Loss: 0.1873  Val_Acc: 93.733

Epoch 27: Validation loss decreased (0.187294 --> 0.186351).  Saving model ...
	 Train_Loss: 0.2289 Train_Acc: 92.107 Val_Loss: 0.1864  BEST VAL Loss: 0.1864  Val_Acc: 93.923

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.2280 Train_Acc: 92.089 Val_Loss: 0.1880  BEST VAL Loss: 0.1864  Val_Acc: 93.125

Epoch 29: Validation loss did not decrease
	 Train_Loss: 0.2272 Train_Acc: 92.119 Val_Loss: 0.1874  BEST VAL Loss: 0.1864  Val_Acc: 93.602

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.2264 Train_Acc: 92.063 Val_Loss: 0.1866  BEST VAL Loss: 0.1864  Val_Acc: 93.737

Epoch 31: Validation loss decreased (0.186351 --> 0.185946).  Saving model ...
	 Train_Loss: 0.2257 Train_Acc: 92.120 Val_Loss: 0.1859  BEST VAL Loss: 0.1859  Val_Acc: 93.539

Epoch 32: Validation loss decreased (0.185946 --> 0.185393).  Saving model ...
	 Train_Loss: 0.2250 Train_Acc: 92.079 Val_Loss: 0.1854  BEST VAL Loss: 0.1854  Val_Acc: 93.585

Epoch 33: Validation loss decreased (0.185393 --> 0.184712).  Saving model ...
	 Train_Loss: 0.2243 Train_Acc: 92.155 Val_Loss: 0.1847  BEST VAL Loss: 0.1847  Val_Acc: 93.729

Epoch 34: Validation loss decreased (0.184712 --> 0.184249).  Saving model ...
	 Train_Loss: 0.2236 Train_Acc: 92.150 Val_Loss: 0.1842  BEST VAL Loss: 0.1842  Val_Acc: 93.838

Epoch 35: Validation loss decreased (0.184249 --> 0.183505).  Saving model ...
	 Train_Loss: 0.2230 Train_Acc: 92.200 Val_Loss: 0.1835  BEST VAL Loss: 0.1835  Val_Acc: 94.092

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.2224 Train_Acc: 92.199 Val_Loss: 0.1841  BEST VAL Loss: 0.1835  Val_Acc: 92.961

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.2218 Train_Acc: 92.254 Val_Loss: 0.1839  BEST VAL Loss: 0.1835  Val_Acc: 93.703

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.2212 Train_Acc: 92.208 Val_Loss: 0.1837  BEST VAL Loss: 0.1835  Val_Acc: 93.248

Epoch 39: Validation loss decreased (0.183505 --> 0.183060).  Saving model ...
	 Train_Loss: 0.2207 Train_Acc: 92.165 Val_Loss: 0.1831  BEST VAL Loss: 0.1831  Val_Acc: 93.876

Epoch 40: Validation loss decreased (0.183060 --> 0.182596).  Saving model ...
	 Train_Loss: 0.2201 Train_Acc: 92.319 Val_Loss: 0.1826  BEST VAL Loss: 0.1826  Val_Acc: 93.872

Epoch 41: Validation loss decreased (0.182596 --> 0.182082).  Saving model ...
	 Train_Loss: 0.2196 Train_Acc: 92.317 Val_Loss: 0.1821  BEST VAL Loss: 0.1821  Val_Acc: 94.003

Epoch 42: Validation loss decreased (0.182082 --> 0.181580).  Saving model ...
	 Train_Loss: 0.2191 Train_Acc: 92.248 Val_Loss: 0.1816  BEST VAL Loss: 0.1816  Val_Acc: 93.720

Epoch 43: Validation loss decreased (0.181580 --> 0.181540).  Saving model ...
	 Train_Loss: 0.2187 Train_Acc: 92.283 Val_Loss: 0.1815  BEST VAL Loss: 0.1815  Val_Acc: 93.560

Epoch 44: Validation loss decreased (0.181540 --> 0.181522).  Saving model ...
	 Train_Loss: 0.2182 Train_Acc: 92.326 Val_Loss: 0.1815  BEST VAL Loss: 0.1815  Val_Acc: 93.467

Epoch 45: Validation loss decreased (0.181522 --> 0.181222).  Saving model ...
	 Train_Loss: 0.2178 Train_Acc: 92.321 Val_Loss: 0.1812  BEST VAL Loss: 0.1812  Val_Acc: 93.720

Epoch 46: Validation loss decreased (0.181222 --> 0.181021).  Saving model ...
	 Train_Loss: 0.2173 Train_Acc: 92.405 Val_Loss: 0.1810  BEST VAL Loss: 0.1810  Val_Acc: 93.885

Epoch 47: Validation loss decreased (0.181021 --> 0.180742).  Saving model ...
	 Train_Loss: 0.2169 Train_Acc: 92.319 Val_Loss: 0.1807  BEST VAL Loss: 0.1807  Val_Acc: 93.691

Epoch 48: Validation loss decreased (0.180742 --> 0.180280).  Saving model ...
	 Train_Loss: 0.2165 Train_Acc: 92.315 Val_Loss: 0.1803  BEST VAL Loss: 0.1803  Val_Acc: 93.982

Epoch 49: Validation loss decreased (0.180280 --> 0.179765).  Saving model ...
	 Train_Loss: 0.2161 Train_Acc: 92.396 Val_Loss: 0.1798  BEST VAL Loss: 0.1798  Val_Acc: 94.104

Epoch 50: Validation loss decreased (0.179765 --> 0.179354).  Saving model ...
	 Train_Loss: 0.2157 Train_Acc: 92.359 Val_Loss: 0.1794  BEST VAL Loss: 0.1794  Val_Acc: 93.910

Epoch 51: Validation loss decreased (0.179354 --> 0.178861).  Saving model ...
	 Train_Loss: 0.2153 Train_Acc: 92.308 Val_Loss: 0.1789  BEST VAL Loss: 0.1789  Val_Acc: 94.113

Epoch 52: Validation loss decreased (0.178861 --> 0.178450).  Saving model ...
	 Train_Loss: 0.2150 Train_Acc: 92.394 Val_Loss: 0.1785  BEST VAL Loss: 0.1785  Val_Acc: 94.113

Epoch 53: Validation loss decreased (0.178450 --> 0.178178).  Saving model ...
	 Train_Loss: 0.2146 Train_Acc: 92.406 Val_Loss: 0.1782  BEST VAL Loss: 0.1782  Val_Acc: 93.995

Epoch 54: Validation loss decreased (0.178178 --> 0.177786).  Saving model ...
	 Train_Loss: 0.2142 Train_Acc: 92.430 Val_Loss: 0.1778  BEST VAL Loss: 0.1778  Val_Acc: 94.062

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.2139 Train_Acc: 92.470 Val_Loss: 0.1778  BEST VAL Loss: 0.1778  Val_Acc: 93.944

Epoch 56: Validation loss decreased (0.177786 --> 0.177441).  Saving model ...
	 Train_Loss: 0.2135 Train_Acc: 92.430 Val_Loss: 0.1774  BEST VAL Loss: 0.1774  Val_Acc: 94.383

Epoch 57: Validation loss decreased (0.177441 --> 0.177061).  Saving model ...
	 Train_Loss: 0.2132 Train_Acc: 92.464 Val_Loss: 0.1771  BEST VAL Loss: 0.1771  Val_Acc: 94.307

Epoch 58: Validation loss decreased (0.177061 --> 0.176728).  Saving model ...
	 Train_Loss: 0.2129 Train_Acc: 92.411 Val_Loss: 0.1767  BEST VAL Loss: 0.1767  Val_Acc: 93.986

Epoch 59: Validation loss decreased (0.176728 --> 0.176573).  Saving model ...
	 Train_Loss: 0.2126 Train_Acc: 92.465 Val_Loss: 0.1766  BEST VAL Loss: 0.1766  Val_Acc: 93.703

Epoch 60: Validation loss decreased (0.176573 --> 0.176546).  Saving model ...
	 Train_Loss: 0.2122 Train_Acc: 92.498 Val_Loss: 0.1765  BEST VAL Loss: 0.1765  Val_Acc: 93.459

Epoch 61: Validation loss decreased (0.176546 --> 0.176262).  Saving model ...
	 Train_Loss: 0.2119 Train_Acc: 92.484 Val_Loss: 0.1763  BEST VAL Loss: 0.1763  Val_Acc: 94.184

Epoch 62: Validation loss decreased (0.176262 --> 0.175951).  Saving model ...
	 Train_Loss: 0.2117 Train_Acc: 92.533 Val_Loss: 0.1760  BEST VAL Loss: 0.1760  Val_Acc: 94.058

Epoch 63: Validation loss decreased (0.175951 --> 0.175653).  Saving model ...
	 Train_Loss: 0.2114 Train_Acc: 92.504 Val_Loss: 0.1757  BEST VAL Loss: 0.1757  Val_Acc: 94.096

Epoch 64: Validation loss decreased (0.175653 --> 0.175491).  Saving model ...
	 Train_Loss: 0.2111 Train_Acc: 92.478 Val_Loss: 0.1755  BEST VAL Loss: 0.1755  Val_Acc: 93.935

Epoch 65: Validation loss decreased (0.175491 --> 0.175319).  Saving model ...
	 Train_Loss: 0.2108 Train_Acc: 92.460 Val_Loss: 0.1753  BEST VAL Loss: 0.1753  Val_Acc: 93.948

Epoch 66: Validation loss decreased (0.175319 --> 0.175014).  Saving model ...
	 Train_Loss: 0.2106 Train_Acc: 92.591 Val_Loss: 0.1750  BEST VAL Loss: 0.1750  Val_Acc: 94.193

Epoch 67: Validation loss decreased (0.175014 --> 0.174897).  Saving model ...
	 Train_Loss: 0.2103 Train_Acc: 92.538 Val_Loss: 0.1749  BEST VAL Loss: 0.1749  Val_Acc: 93.805

Epoch 68: Validation loss decreased (0.174897 --> 0.174547).  Saving model ...
	 Train_Loss: 0.2100 Train_Acc: 92.489 Val_Loss: 0.1745  BEST VAL Loss: 0.1745  Val_Acc: 94.269

Epoch 69: Validation loss decreased (0.174547 --> 0.174250).  Saving model ...
	 Train_Loss: 0.2098 Train_Acc: 92.499 Val_Loss: 0.1742  BEST VAL Loss: 0.1742  Val_Acc: 94.142

Epoch 70: Validation loss decreased (0.174250 --> 0.174173).  Saving model ...
	 Train_Loss: 0.2095 Train_Acc: 92.580 Val_Loss: 0.1742  BEST VAL Loss: 0.1742  Val_Acc: 93.906

Epoch 71: Validation loss decreased (0.174173 --> 0.173915).  Saving model ...
	 Train_Loss: 0.2093 Train_Acc: 92.493 Val_Loss: 0.1739  BEST VAL Loss: 0.1739  Val_Acc: 94.138

Epoch 72: Validation loss decreased (0.173915 --> 0.173798).  Saving model ...
	 Train_Loss: 0.2090 Train_Acc: 92.560 Val_Loss: 0.1738  BEST VAL Loss: 0.1738  Val_Acc: 94.028

Epoch 73: Validation loss decreased (0.173798 --> 0.173525).  Saving model ...
	 Train_Loss: 0.2088 Train_Acc: 92.522 Val_Loss: 0.1735  BEST VAL Loss: 0.1735  Val_Acc: 94.248

Epoch 74: Validation loss decreased (0.173525 --> 0.173253).  Saving model ...
	 Train_Loss: 0.2086 Train_Acc: 92.660 Val_Loss: 0.1733  BEST VAL Loss: 0.1733  Val_Acc: 94.265

Epoch 75: Validation loss decreased (0.173253 --> 0.173004).  Saving model ...
	 Train_Loss: 0.2084 Train_Acc: 92.528 Val_Loss: 0.1730  BEST VAL Loss: 0.1730  Val_Acc: 94.357

Epoch 76: Validation loss decreased (0.173004 --> 0.172730).  Saving model ...
	 Train_Loss: 0.2081 Train_Acc: 92.653 Val_Loss: 0.1727  BEST VAL Loss: 0.1727  Val_Acc: 94.290

Epoch 77: Validation loss decreased (0.172730 --> 0.172541).  Saving model ...
	 Train_Loss: 0.2079 Train_Acc: 92.658 Val_Loss: 0.1725  BEST VAL Loss: 0.1725  Val_Acc: 94.104

Epoch 78: Validation loss decreased (0.172541 --> 0.172377).  Saving model ...
	 Train_Loss: 0.2077 Train_Acc: 92.517 Val_Loss: 0.1724  BEST VAL Loss: 0.1724  Val_Acc: 94.045

Epoch 79: Validation loss decreased (0.172377 --> 0.172148).  Saving model ...
	 Train_Loss: 0.2075 Train_Acc: 92.546 Val_Loss: 0.1721  BEST VAL Loss: 0.1721  Val_Acc: 94.159

Epoch 80: Validation loss decreased (0.172148 --> 0.171966).  Saving model ...
	 Train_Loss: 0.2073 Train_Acc: 92.595 Val_Loss: 0.1720  BEST VAL Loss: 0.1720  Val_Acc: 94.011

Epoch 81: Validation loss decreased (0.171966 --> 0.171768).  Saving model ...
	 Train_Loss: 0.2071 Train_Acc: 92.629 Val_Loss: 0.1718  BEST VAL Loss: 0.1718  Val_Acc: 94.092

Epoch 82: Validation loss decreased (0.171768 --> 0.171527).  Saving model ...
	 Train_Loss: 0.2069 Train_Acc: 92.533 Val_Loss: 0.1715  BEST VAL Loss: 0.1715  Val_Acc: 94.176

Epoch 83: Validation loss decreased (0.171527 --> 0.171259).  Saving model ...
	 Train_Loss: 0.2067 Train_Acc: 92.586 Val_Loss: 0.1713  BEST VAL Loss: 0.1713  Val_Acc: 94.425

Epoch 84: Validation loss decreased (0.171259 --> 0.171208).  Saving model ...
	 Train_Loss: 0.2065 Train_Acc: 92.606 Val_Loss: 0.1712  BEST VAL Loss: 0.1712  Val_Acc: 93.952

Epoch 85: Validation loss decreased (0.171208 --> 0.171003).  Saving model ...
	 Train_Loss: 0.2063 Train_Acc: 92.645 Val_Loss: 0.1710  BEST VAL Loss: 0.1710  Val_Acc: 94.298

Epoch 86: Validation loss decreased (0.171003 --> 0.170837).  Saving model ...
	 Train_Loss: 0.2061 Train_Acc: 92.638 Val_Loss: 0.1708  BEST VAL Loss: 0.1708  Val_Acc: 94.096

Epoch 87: Validation loss decreased (0.170837 --> 0.170712).  Saving model ...
	 Train_Loss: 0.2059 Train_Acc: 92.685 Val_Loss: 0.1707  BEST VAL Loss: 0.1707  Val_Acc: 94.058

Epoch 88: Validation loss decreased (0.170712 --> 0.170539).  Saving model ...
	 Train_Loss: 0.2058 Train_Acc: 92.630 Val_Loss: 0.1705  BEST VAL Loss: 0.1705  Val_Acc: 94.058

Epoch 89: Validation loss decreased (0.170539 --> 0.170338).  Saving model ...
	 Train_Loss: 0.2056 Train_Acc: 92.677 Val_Loss: 0.1703  BEST VAL Loss: 0.1703  Val_Acc: 94.281

Epoch 90: Validation loss decreased (0.170338 --> 0.170190).  Saving model ...
	 Train_Loss: 0.2054 Train_Acc: 92.651 Val_Loss: 0.1702  BEST VAL Loss: 0.1702  Val_Acc: 94.096

Epoch 91: Validation loss decreased (0.170190 --> 0.170019).  Saving model ...
	 Train_Loss: 0.2052 Train_Acc: 92.541 Val_Loss: 0.1700  BEST VAL Loss: 0.1700  Val_Acc: 94.227

Epoch 92: Validation loss decreased (0.170019 --> 0.169883).  Saving model ...
	 Train_Loss: 0.2050 Train_Acc: 92.666 Val_Loss: 0.1699  BEST VAL Loss: 0.1699  Val_Acc: 94.222

Epoch 93: Validation loss decreased (0.169883 --> 0.169817).  Saving model ...
	 Train_Loss: 0.2049 Train_Acc: 92.695 Val_Loss: 0.1698  BEST VAL Loss: 0.1698  Val_Acc: 94.235

Epoch 94: Validation loss decreased (0.169817 --> 0.169683).  Saving model ...
	 Train_Loss: 0.2047 Train_Acc: 92.609 Val_Loss: 0.1697  BEST VAL Loss: 0.1697  Val_Acc: 94.324

Epoch 95: Validation loss decreased (0.169683 --> 0.169517).  Saving model ...
	 Train_Loss: 0.2045 Train_Acc: 92.694 Val_Loss: 0.1695  BEST VAL Loss: 0.1695  Val_Acc: 94.235

Epoch 96: Validation loss decreased (0.169517 --> 0.169354).  Saving model ...
	 Train_Loss: 0.2044 Train_Acc: 92.706 Val_Loss: 0.1694  BEST VAL Loss: 0.1694  Val_Acc: 94.298

Epoch 97: Validation loss decreased (0.169354 --> 0.169251).  Saving model ...
	 Train_Loss: 0.2042 Train_Acc: 92.722 Val_Loss: 0.1693  BEST VAL Loss: 0.1693  Val_Acc: 94.062

Epoch 98: Validation loss decreased (0.169251 --> 0.169220).  Saving model ...
	 Train_Loss: 0.2040 Train_Acc: 92.717 Val_Loss: 0.1692  BEST VAL Loss: 0.1692  Val_Acc: 94.138

Epoch 99: Validation loss decreased (0.169220 --> 0.169176).  Saving model ...
	 Train_Loss: 0.2039 Train_Acc: 92.667 Val_Loss: 0.1692  BEST VAL Loss: 0.1692  Val_Acc: 93.830

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.42      0.44      0.43     80324
           1       0.58      0.56      0.57    109228

    accuracy                           0.51    189552
   macro avg       0.50      0.50      0.50    189552
weighted avg       0.51      0.51      0.51    189552

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.43      0.45      0.44     10041
           1       0.58      0.56      0.57     13654

    accuracy                           0.51     23695
   macro avg       0.50      0.50      0.50     23695
weighted avg       0.51      0.51      0.51     23695

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.42      0.45      0.44     10041
           1       0.58      0.56      0.57     13654

    accuracy                           0.51     23695
   macro avg       0.50      0.50      0.50     23695
weighted avg       0.51      0.51      0.51     23695

              precision    recall  f1-score   support

           0       0.42      0.45      0.44     10041
           1       0.58      0.56      0.57     13654

    accuracy                           0.51     23695
   macro avg       0.50      0.50      0.50     23695
weighted avg       0.51      0.51      0.51     23695

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.49      0.50     38191
           1       0.50      0.52      0.51     37725

    accuracy                           0.50     75916
   macro avg       0.50      0.50      0.50     75916
weighted avg       0.50      0.50      0.50     75916

              precision    recall  f1-score   support

           0       0.51      0.49      0.50     38191
           1       0.50      0.52      0.51     37725

    accuracy                           0.50     75916
   macro avg       0.50      0.50      0.50     75916
weighted avg       0.50      0.50      0.50     75916

completed
