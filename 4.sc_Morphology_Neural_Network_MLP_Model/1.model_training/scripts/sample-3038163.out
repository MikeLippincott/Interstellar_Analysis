[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '6709e0a6'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '07266f3d'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'a93c3f2a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '4d0d8b71'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Flagellin_1.000_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Flagellin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_100.000_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (263982, 1270)
Number of total missing values across all columns: 564580
Data Subset Is Off
Wells held out for testing: ['J08' 'M10']
Wells to use for training, validation, and testing ['J02' 'J03' 'J09' 'M05' 'M11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.559875).  Saving model ...
	 Train_Loss: 0.6075 Train_Acc: 67.654 Val_Loss: 0.5599  BEST VAL Loss: 0.5599  Val_Acc: 72.389

Epoch 1: Validation loss decreased (0.559875 --> 0.543895).  Saving model ...
	 Train_Loss: 0.5794 Train_Acc: 72.488 Val_Loss: 0.5439  BEST VAL Loss: 0.5439  Val_Acc: 74.567

Epoch 2: Validation loss decreased (0.543895 --> 0.532201).  Saving model ...
	 Train_Loss: 0.5626 Train_Acc: 73.933 Val_Loss: 0.5322  BEST VAL Loss: 0.5322  Val_Acc: 75.524

Epoch 3: Validation loss decreased (0.532201 --> 0.523007).  Saving model ...
	 Train_Loss: 0.5508 Train_Acc: 74.807 Val_Loss: 0.5230  BEST VAL Loss: 0.5230  Val_Acc: 76.465

Epoch 4: Validation loss decreased (0.523007 --> 0.516084).  Saving model ...
	 Train_Loss: 0.5419 Train_Acc: 75.446 Val_Loss: 0.5161  BEST VAL Loss: 0.5161  Val_Acc: 76.948

Epoch 5: Validation loss decreased (0.516084 --> 0.510476).  Saving model ...
	 Train_Loss: 0.5347 Train_Acc: 75.923 Val_Loss: 0.5105  BEST VAL Loss: 0.5105  Val_Acc: 76.860

Epoch 6: Validation loss decreased (0.510476 --> 0.505868).  Saving model ...
	 Train_Loss: 0.5287 Train_Acc: 76.090 Val_Loss: 0.5059  BEST VAL Loss: 0.5059  Val_Acc: 77.728

Epoch 7: Validation loss decreased (0.505868 --> 0.501739).  Saving model ...
	 Train_Loss: 0.5237 Train_Acc: 76.526 Val_Loss: 0.5017  BEST VAL Loss: 0.5017  Val_Acc: 77.754

Epoch 8: Validation loss decreased (0.501739 --> 0.498331).  Saving model ...
	 Train_Loss: 0.5191 Train_Acc: 76.797 Val_Loss: 0.4983  BEST VAL Loss: 0.4983  Val_Acc: 77.874

Epoch 9: Validation loss decreased (0.498331 --> 0.495260).  Saving model ...
	 Train_Loss: 0.5153 Train_Acc: 76.878 Val_Loss: 0.4953  BEST VAL Loss: 0.4953  Val_Acc: 78.118

Epoch 10: Validation loss decreased (0.495260 --> 0.492567).  Saving model ...
	 Train_Loss: 0.5119 Train_Acc: 77.156 Val_Loss: 0.4926  BEST VAL Loss: 0.4926  Val_Acc: 78.321

Epoch 11: Validation loss decreased (0.492567 --> 0.490019).  Saving model ...
	 Train_Loss: 0.5088 Train_Acc: 77.306 Val_Loss: 0.4900  BEST VAL Loss: 0.4900  Val_Acc: 78.529

Epoch 12: Validation loss decreased (0.490019 --> 0.488653).  Saving model ...
	 Train_Loss: 0.5059 Train_Acc: 77.494 Val_Loss: 0.4887  BEST VAL Loss: 0.4887  Val_Acc: 77.910

Epoch 13: Validation loss decreased (0.488653 --> 0.486300).  Saving model ...
	 Train_Loss: 0.5033 Train_Acc: 77.566 Val_Loss: 0.4863  BEST VAL Loss: 0.4863  Val_Acc: 78.747

Epoch 14: Validation loss decreased (0.486300 --> 0.484083).  Saving model ...
	 Train_Loss: 0.5008 Train_Acc: 77.753 Val_Loss: 0.4841  BEST VAL Loss: 0.4841  Val_Acc: 78.991

Epoch 15: Validation loss decreased (0.484083 --> 0.481962).  Saving model ...
	 Train_Loss: 0.4986 Train_Acc: 77.859 Val_Loss: 0.4820  BEST VAL Loss: 0.4820  Val_Acc: 79.101

Epoch 16: Validation loss decreased (0.481962 --> 0.480328).  Saving model ...
	 Train_Loss: 0.4966 Train_Acc: 78.030 Val_Loss: 0.4803  BEST VAL Loss: 0.4803  Val_Acc: 78.841

Epoch 17: Validation loss decreased (0.480328 --> 0.478719).  Saving model ...
	 Train_Loss: 0.4947 Train_Acc: 78.007 Val_Loss: 0.4787  BEST VAL Loss: 0.4787  Val_Acc: 79.371

Epoch 18: Validation loss decreased (0.478719 --> 0.477185).  Saving model ...
	 Train_Loss: 0.4929 Train_Acc: 78.203 Val_Loss: 0.4772  BEST VAL Loss: 0.4772  Val_Acc: 78.955

Epoch 19: Validation loss decreased (0.477185 --> 0.475492).  Saving model ...
	 Train_Loss: 0.4911 Train_Acc: 78.309 Val_Loss: 0.4755  BEST VAL Loss: 0.4755  Val_Acc: 79.444

Epoch 20: Validation loss decreased (0.475492 --> 0.474061).  Saving model ...
	 Train_Loss: 0.4894 Train_Acc: 78.294 Val_Loss: 0.4741  BEST VAL Loss: 0.4741  Val_Acc: 79.392

Epoch 21: Validation loss decreased (0.474061 --> 0.472858).  Saving model ...
	 Train_Loss: 0.4878 Train_Acc: 78.562 Val_Loss: 0.4729  BEST VAL Loss: 0.4729  Val_Acc: 79.023

Epoch 22: Validation loss decreased (0.472858 --> 0.471837).  Saving model ...
	 Train_Loss: 0.4864 Train_Acc: 78.492 Val_Loss: 0.4718  BEST VAL Loss: 0.4718  Val_Acc: 79.168

Epoch 23: Validation loss decreased (0.471837 --> 0.470548).  Saving model ...
	 Train_Loss: 0.4849 Train_Acc: 78.754 Val_Loss: 0.4705  BEST VAL Loss: 0.4705  Val_Acc: 79.683

Epoch 24: Validation loss decreased (0.470548 --> 0.469282).  Saving model ...
	 Train_Loss: 0.4835 Train_Acc: 78.749 Val_Loss: 0.4693  BEST VAL Loss: 0.4693  Val_Acc: 79.574

Epoch 25: Validation loss decreased (0.469282 --> 0.468096).  Saving model ...
	 Train_Loss: 0.4822 Train_Acc: 78.795 Val_Loss: 0.4681  BEST VAL Loss: 0.4681  Val_Acc: 79.984

Epoch 26: Validation loss decreased (0.468096 --> 0.467012).  Saving model ...
	 Train_Loss: 0.4810 Train_Acc: 78.904 Val_Loss: 0.4670  BEST VAL Loss: 0.4670  Val_Acc: 79.782

Epoch 27: Validation loss decreased (0.467012 --> 0.465998).  Saving model ...
	 Train_Loss: 0.4797 Train_Acc: 79.052 Val_Loss: 0.4660  BEST VAL Loss: 0.4660  Val_Acc: 79.698

Epoch 28: Validation loss decreased (0.465998 --> 0.465024).  Saving model ...
	 Train_Loss: 0.4785 Train_Acc: 79.010 Val_Loss: 0.4650  BEST VAL Loss: 0.4650  Val_Acc: 79.719

Epoch 29: Validation loss decreased (0.465024 --> 0.464030).  Saving model ...
	 Train_Loss: 0.4774 Train_Acc: 79.194 Val_Loss: 0.4640  BEST VAL Loss: 0.4640  Val_Acc: 79.880

Epoch 30: Validation loss decreased (0.464030 --> 0.463057).  Saving model ...
	 Train_Loss: 0.4763 Train_Acc: 79.129 Val_Loss: 0.4631  BEST VAL Loss: 0.4631  Val_Acc: 79.932

Epoch 31: Validation loss decreased (0.463057 --> 0.462208).  Saving model ...
	 Train_Loss: 0.4752 Train_Acc: 79.355 Val_Loss: 0.4622  BEST VAL Loss: 0.4622  Val_Acc: 79.782

Epoch 32: Validation loss decreased (0.462208 --> 0.461471).  Saving model ...
	 Train_Loss: 0.4741 Train_Acc: 79.234 Val_Loss: 0.4615  BEST VAL Loss: 0.4615  Val_Acc: 79.730

Epoch 33: Validation loss decreased (0.461471 --> 0.460490).  Saving model ...
	 Train_Loss: 0.4731 Train_Acc: 79.310 Val_Loss: 0.4605  BEST VAL Loss: 0.4605  Val_Acc: 80.130

Epoch 34: Validation loss decreased (0.460490 --> 0.459599).  Saving model ...
	 Train_Loss: 0.4722 Train_Acc: 79.338 Val_Loss: 0.4596  BEST VAL Loss: 0.4596  Val_Acc: 80.239

Epoch 35: Validation loss decreased (0.459599 --> 0.458832).  Saving model ...
	 Train_Loss: 0.4712 Train_Acc: 79.457 Val_Loss: 0.4588  BEST VAL Loss: 0.4588  Val_Acc: 80.130

Epoch 36: Validation loss decreased (0.458832 --> 0.458013).  Saving model ...
	 Train_Loss: 0.4703 Train_Acc: 79.572 Val_Loss: 0.4580  BEST VAL Loss: 0.4580  Val_Acc: 80.364

Epoch 37: Validation loss decreased (0.458013 --> 0.457238).  Saving model ...
	 Train_Loss: 0.4694 Train_Acc: 79.561 Val_Loss: 0.4572  BEST VAL Loss: 0.4572  Val_Acc: 80.270

Epoch 38: Validation loss decreased (0.457238 --> 0.456503).  Saving model ...
	 Train_Loss: 0.4685 Train_Acc: 79.559 Val_Loss: 0.4565  BEST VAL Loss: 0.4565  Val_Acc: 80.421

Epoch 39: Validation loss decreased (0.456503 --> 0.455731).  Saving model ...
	 Train_Loss: 0.4676 Train_Acc: 79.744 Val_Loss: 0.4557  BEST VAL Loss: 0.4557  Val_Acc: 80.187

Epoch 40: Validation loss decreased (0.455731 --> 0.455056).  Saving model ...
	 Train_Loss: 0.4668 Train_Acc: 79.666 Val_Loss: 0.4551  BEST VAL Loss: 0.4551  Val_Acc: 80.322

Epoch 41: Validation loss decreased (0.455056 --> 0.454445).  Saving model ...
	 Train_Loss: 0.4659 Train_Acc: 79.712 Val_Loss: 0.4544  BEST VAL Loss: 0.4544  Val_Acc: 80.380

Epoch 42: Validation loss decreased (0.454445 --> 0.453732).  Saving model ...
	 Train_Loss: 0.4651 Train_Acc: 79.705 Val_Loss: 0.4537  BEST VAL Loss: 0.4537  Val_Acc: 80.374

Epoch 43: Validation loss decreased (0.453732 --> 0.453089).  Saving model ...
	 Train_Loss: 0.4644 Train_Acc: 79.879 Val_Loss: 0.4531  BEST VAL Loss: 0.4531  Val_Acc: 80.400

Epoch 44: Validation loss decreased (0.453089 --> 0.452448).  Saving model ...
	 Train_Loss: 0.4636 Train_Acc: 79.693 Val_Loss: 0.4524  BEST VAL Loss: 0.4524  Val_Acc: 80.348

Epoch 45: Validation loss decreased (0.452448 --> 0.451832).  Saving model ...
	 Train_Loss: 0.4629 Train_Acc: 79.916 Val_Loss: 0.4518  BEST VAL Loss: 0.4518  Val_Acc: 80.676

Epoch 46: Validation loss decreased (0.451832 --> 0.451129).  Saving model ...
	 Train_Loss: 0.4622 Train_Acc: 79.873 Val_Loss: 0.4511  BEST VAL Loss: 0.4511  Val_Acc: 80.572

Epoch 47: Validation loss decreased (0.451129 --> 0.450475).  Saving model ...
	 Train_Loss: 0.4615 Train_Acc: 79.968 Val_Loss: 0.4505  BEST VAL Loss: 0.4505  Val_Acc: 80.801

Epoch 48: Validation loss decreased (0.450475 --> 0.449908).  Saving model ...
	 Train_Loss: 0.4607 Train_Acc: 80.090 Val_Loss: 0.4499  BEST VAL Loss: 0.4499  Val_Acc: 80.551

Epoch 49: Validation loss decreased (0.449908 --> 0.449421).  Saving model ...
	 Train_Loss: 0.4601 Train_Acc: 79.976 Val_Loss: 0.4494  BEST VAL Loss: 0.4494  Val_Acc: 80.535

Epoch 50: Validation loss decreased (0.449421 --> 0.448972).  Saving model ...
	 Train_Loss: 0.4594 Train_Acc: 79.968 Val_Loss: 0.4490  BEST VAL Loss: 0.4490  Val_Acc: 80.556

Epoch 51: Validation loss decreased (0.448972 --> 0.448397).  Saving model ...
	 Train_Loss: 0.4588 Train_Acc: 80.071 Val_Loss: 0.4484  BEST VAL Loss: 0.4484  Val_Acc: 80.541

Epoch 52: Validation loss decreased (0.448397 --> 0.447792).  Saving model ...
	 Train_Loss: 0.4581 Train_Acc: 80.115 Val_Loss: 0.4478  BEST VAL Loss: 0.4478  Val_Acc: 80.775

Epoch 53: Validation loss decreased (0.447792 --> 0.447206).  Saving model ...
	 Train_Loss: 0.4575 Train_Acc: 80.104 Val_Loss: 0.4472  BEST VAL Loss: 0.4472  Val_Acc: 80.650

Epoch 54: Validation loss decreased (0.447206 --> 0.446642).  Saving model ...
	 Train_Loss: 0.4569 Train_Acc: 80.137 Val_Loss: 0.4466  BEST VAL Loss: 0.4466  Val_Acc: 80.983

Epoch 55: Validation loss decreased (0.446642 --> 0.446074).  Saving model ...
	 Train_Loss: 0.4563 Train_Acc: 80.158 Val_Loss: 0.4461  BEST VAL Loss: 0.4461  Val_Acc: 80.936

Epoch 56: Validation loss decreased (0.446074 --> 0.445587).  Saving model ...
	 Train_Loss: 0.4557 Train_Acc: 80.227 Val_Loss: 0.4456  BEST VAL Loss: 0.4456  Val_Acc: 80.795

Epoch 57: Validation loss decreased (0.445587 --> 0.445056).  Saving model ...
	 Train_Loss: 0.4552 Train_Acc: 80.216 Val_Loss: 0.4451  BEST VAL Loss: 0.4451  Val_Acc: 80.946

Epoch 58: Validation loss decreased (0.445056 --> 0.444572).  Saving model ...
	 Train_Loss: 0.4546 Train_Acc: 80.335 Val_Loss: 0.4446  BEST VAL Loss: 0.4446  Val_Acc: 80.832

Epoch 59: Validation loss decreased (0.444572 --> 0.444155).  Saving model ...
	 Train_Loss: 0.4541 Train_Acc: 80.136 Val_Loss: 0.4442  BEST VAL Loss: 0.4442  Val_Acc: 80.837

Epoch 60: Validation loss decreased (0.444155 --> 0.443638).  Saving model ...
	 Train_Loss: 0.4535 Train_Acc: 80.269 Val_Loss: 0.4436  BEST VAL Loss: 0.4436  Val_Acc: 81.081

Epoch 61: Validation loss decreased (0.443638 --> 0.443159).  Saving model ...
	 Train_Loss: 0.4530 Train_Acc: 80.317 Val_Loss: 0.4432  BEST VAL Loss: 0.4432  Val_Acc: 80.946

Epoch 62: Validation loss decreased (0.443159 --> 0.442759).  Saving model ...
	 Train_Loss: 0.4525 Train_Acc: 80.380 Val_Loss: 0.4428  BEST VAL Loss: 0.4428  Val_Acc: 80.837

Epoch 63: Validation loss decreased (0.442759 --> 0.442248).  Saving model ...
	 Train_Loss: 0.4520 Train_Acc: 80.343 Val_Loss: 0.4422  BEST VAL Loss: 0.4422  Val_Acc: 81.040

Epoch 64: Validation loss decreased (0.442248 --> 0.441748).  Saving model ...
	 Train_Loss: 0.4514 Train_Acc: 80.458 Val_Loss: 0.4417  BEST VAL Loss: 0.4417  Val_Acc: 81.284

Epoch 65: Validation loss decreased (0.441748 --> 0.441366).  Saving model ...
	 Train_Loss: 0.4509 Train_Acc: 80.498 Val_Loss: 0.4414  BEST VAL Loss: 0.4414  Val_Acc: 80.884

Epoch 66: Validation loss decreased (0.441366 --> 0.440928).  Saving model ...
	 Train_Loss: 0.4504 Train_Acc: 80.586 Val_Loss: 0.4409  BEST VAL Loss: 0.4409  Val_Acc: 81.102

Epoch 67: Validation loss decreased (0.440928 --> 0.440528).  Saving model ...
	 Train_Loss: 0.4500 Train_Acc: 80.355 Val_Loss: 0.4405  BEST VAL Loss: 0.4405  Val_Acc: 81.206

Epoch 68: Validation loss decreased (0.440528 --> 0.440108).  Saving model ...
	 Train_Loss: 0.4495 Train_Acc: 80.513 Val_Loss: 0.4401  BEST VAL Loss: 0.4401  Val_Acc: 80.957

Epoch 69: Validation loss decreased (0.440108 --> 0.439668).  Saving model ...
	 Train_Loss: 0.4490 Train_Acc: 80.515 Val_Loss: 0.4397  BEST VAL Loss: 0.4397  Val_Acc: 81.211

Epoch 70: Validation loss decreased (0.439668 --> 0.439257).  Saving model ...
	 Train_Loss: 0.4485 Train_Acc: 80.637 Val_Loss: 0.4393  BEST VAL Loss: 0.4393  Val_Acc: 81.123

Epoch 71: Validation loss decreased (0.439257 --> 0.438812).  Saving model ...
	 Train_Loss: 0.4481 Train_Acc: 80.513 Val_Loss: 0.4388  BEST VAL Loss: 0.4388  Val_Acc: 81.269

Epoch 72: Validation loss decreased (0.438812 --> 0.438420).  Saving model ...
	 Train_Loss: 0.4476 Train_Acc: 80.587 Val_Loss: 0.4384  BEST VAL Loss: 0.4384  Val_Acc: 81.243

Epoch 73: Validation loss decreased (0.438420 --> 0.438027).  Saving model ...
	 Train_Loss: 0.4472 Train_Acc: 80.638 Val_Loss: 0.4380  BEST VAL Loss: 0.4380  Val_Acc: 81.248

Epoch 74: Validation loss decreased (0.438027 --> 0.437594).  Saving model ...
	 Train_Loss: 0.4468 Train_Acc: 80.632 Val_Loss: 0.4376  BEST VAL Loss: 0.4376  Val_Acc: 81.456

Epoch 75: Validation loss decreased (0.437594 --> 0.437186).  Saving model ...
	 Train_Loss: 0.4463 Train_Acc: 80.629 Val_Loss: 0.4372  BEST VAL Loss: 0.4372  Val_Acc: 81.159

Epoch 76: Validation loss decreased (0.437186 --> 0.436801).  Saving model ...
	 Train_Loss: 0.4459 Train_Acc: 80.685 Val_Loss: 0.4368  BEST VAL Loss: 0.4368  Val_Acc: 81.357

Epoch 77: Validation loss decreased (0.436801 --> 0.436413).  Saving model ...
	 Train_Loss: 0.4455 Train_Acc: 80.675 Val_Loss: 0.4364  BEST VAL Loss: 0.4364  Val_Acc: 81.196

Epoch 78: Validation loss decreased (0.436413 --> 0.436003).  Saving model ...
	 Train_Loss: 0.4451 Train_Acc: 80.746 Val_Loss: 0.4360  BEST VAL Loss: 0.4360  Val_Acc: 81.508

Epoch 79: Validation loss decreased (0.436003 --> 0.435615).  Saving model ...
	 Train_Loss: 0.4447 Train_Acc: 80.678 Val_Loss: 0.4356  BEST VAL Loss: 0.4356  Val_Acc: 81.367

Epoch 80: Validation loss decreased (0.435615 --> 0.435281).  Saving model ...
	 Train_Loss: 0.4443 Train_Acc: 80.759 Val_Loss: 0.4353  BEST VAL Loss: 0.4353  Val_Acc: 81.258

Epoch 81: Validation loss decreased (0.435281 --> 0.435002).  Saving model ...
	 Train_Loss: 0.4439 Train_Acc: 80.870 Val_Loss: 0.4350  BEST VAL Loss: 0.4350  Val_Acc: 81.461

Epoch 82: Validation loss decreased (0.435002 --> 0.434707).  Saving model ...
	 Train_Loss: 0.4435 Train_Acc: 80.857 Val_Loss: 0.4347  BEST VAL Loss: 0.4347  Val_Acc: 81.149

Epoch 83: Validation loss decreased (0.434707 --> 0.434391).  Saving model ...
	 Train_Loss: 0.4431 Train_Acc: 80.866 Val_Loss: 0.4344  BEST VAL Loss: 0.4344  Val_Acc: 81.487

Epoch 84: Validation loss decreased (0.434391 --> 0.434070).  Saving model ...
	 Train_Loss: 0.4427 Train_Acc: 80.890 Val_Loss: 0.4341  BEST VAL Loss: 0.4341  Val_Acc: 81.315

Epoch 85: Validation loss decreased (0.434070 --> 0.433787).  Saving model ...
	 Train_Loss: 0.4424 Train_Acc: 80.832 Val_Loss: 0.4338  BEST VAL Loss: 0.4338  Val_Acc: 81.450

Epoch 86: Validation loss decreased (0.433787 --> 0.433467).  Saving model ...
	 Train_Loss: 0.4420 Train_Acc: 80.942 Val_Loss: 0.4335  BEST VAL Loss: 0.4335  Val_Acc: 81.492

Epoch 87: Validation loss decreased (0.433467 --> 0.433163).  Saving model ...
	 Train_Loss: 0.4416 Train_Acc: 80.883 Val_Loss: 0.4332  BEST VAL Loss: 0.4332  Val_Acc: 81.388

Epoch 88: Validation loss decreased (0.433163 --> 0.432797).  Saving model ...
	 Train_Loss: 0.4413 Train_Acc: 80.936 Val_Loss: 0.4328  BEST VAL Loss: 0.4328  Val_Acc: 81.539

Epoch 89: Validation loss decreased (0.432797 --> 0.432452).  Saving model ...
	 Train_Loss: 0.4409 Train_Acc: 80.831 Val_Loss: 0.4325  BEST VAL Loss: 0.4325  Val_Acc: 81.658

Epoch 90: Validation loss decreased (0.432452 --> 0.432145).  Saving model ...
	 Train_Loss: 0.4406 Train_Acc: 80.877 Val_Loss: 0.4321  BEST VAL Loss: 0.4321  Val_Acc: 81.362

Epoch 91: Validation loss decreased (0.432145 --> 0.431937).  Saving model ...
	 Train_Loss: 0.4403 Train_Acc: 80.870 Val_Loss: 0.4319  BEST VAL Loss: 0.4319  Val_Acc: 81.128

Epoch 92: Validation loss decreased (0.431937 --> 0.431655).  Saving model ...
	 Train_Loss: 0.4399 Train_Acc: 80.890 Val_Loss: 0.4317  BEST VAL Loss: 0.4317  Val_Acc: 81.372

Epoch 93: Validation loss decreased (0.431655 --> 0.431363).  Saving model ...
	 Train_Loss: 0.4396 Train_Acc: 80.908 Val_Loss: 0.4314  BEST VAL Loss: 0.4314  Val_Acc: 81.404

Epoch 94: Validation loss decreased (0.431363 --> 0.431060).  Saving model ...
	 Train_Loss: 0.4393 Train_Acc: 80.873 Val_Loss: 0.4311  BEST VAL Loss: 0.4311  Val_Acc: 81.565

Epoch 95: Validation loss decreased (0.431060 --> 0.430773).  Saving model ...
	 Train_Loss: 0.4390 Train_Acc: 80.920 Val_Loss: 0.4308  BEST VAL Loss: 0.4308  Val_Acc: 81.482

Epoch 96: Validation loss decreased (0.430773 --> 0.430543).  Saving model ...
	 Train_Loss: 0.4387 Train_Acc: 80.972 Val_Loss: 0.4305  BEST VAL Loss: 0.4305  Val_Acc: 81.502

Epoch 97: Validation loss decreased (0.430543 --> 0.430266).  Saving model ...
	 Train_Loss: 0.4383 Train_Acc: 81.039 Val_Loss: 0.4303  BEST VAL Loss: 0.4303  Val_Acc: 81.653

Epoch 98: Validation loss decreased (0.430266 --> 0.430019).  Saving model ...
	 Train_Loss: 0.4380 Train_Acc: 80.980 Val_Loss: 0.4300  BEST VAL Loss: 0.4300  Val_Acc: 81.159

Epoch 99: Validation loss decreased (0.430019 --> 0.429777).  Saving model ...
	 Train_Loss: 0.4377 Train_Acc: 80.984 Val_Loss: 0.4298  BEST VAL Loss: 0.4298  Val_Acc: 81.601

Flagellin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.37      0.29      0.33     56122
           1       0.64      0.71      0.67     97753

    accuracy                           0.56    153875
   macro avg       0.50      0.50      0.50    153875
weighted avg       0.54      0.56      0.54    153875

Flagellin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.37      0.29      0.33      7015
           1       0.64      0.71      0.67     12220

    accuracy                           0.56     19235
   macro avg       0.50      0.50      0.50     19235
weighted avg       0.54      0.56      0.55     19235

Flagellin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.36      0.28      0.32      7016
           1       0.63      0.71      0.67     12219

    accuracy                           0.55     19235
   macro avg       0.50      0.50      0.49     19235
weighted avg       0.53      0.55      0.54     19235

              precision    recall  f1-score   support

           0       0.36      0.28      0.32      7016
           1       0.63      0.71      0.67     12219

    accuracy                           0.55     19235
   macro avg       0.50      0.50      0.49     19235
weighted avg       0.53      0.55      0.54     19235

Flagellin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.22      0.30     34394
           1       0.52      0.78      0.62     37243

    accuracy                           0.51     71637
   macro avg       0.50      0.50      0.46     71637
weighted avg       0.50      0.51      0.47     71637

              precision    recall  f1-score   support

           0       0.48      0.22      0.30     34394
           1       0.52      0.78      0.62     37243

    accuracy                           0.51     71637
   macro avg       0.50      0.50      0.46     71637
weighted avg       0.50      0.51      0.47     71637

completed
