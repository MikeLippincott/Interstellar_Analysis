[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '34b3a50f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '054a2260'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ab01c8c7'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '2d7ce536'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_0.100_DMSO_0.025 treatment_name: LPS_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: LPS_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (31386, 1276)
Number of total missing values across all columns: 62772
Data Subset Is Off
Wells held out for testing: ['D21' 'L22']
Wells to use for training, validation, and testing ['D16' 'D17' 'D20' 'L18' 'L19' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.690673).  Saving model ...
	 Train_Loss: 0.6956 Train_Acc: 53.617 Val_Loss: 0.6907  BEST VAL Loss: 0.6907  Val_Acc: 53.751

Epoch 1: Validation loss did not decrease
	 Train_Loss: 0.6932 Train_Acc: 53.735 Val_Loss: 0.6908  BEST VAL Loss: 0.6907  Val_Acc: 53.751

Epoch 2: Validation loss decreased (0.690673 --> 0.690652).  Saving model ...
	 Train_Loss: 0.6923 Train_Acc: 53.719 Val_Loss: 0.6907  BEST VAL Loss: 0.6907  Val_Acc: 53.751

Epoch 3: Validation loss decreased (0.690652 --> 0.690257).  Saving model ...
	 Train_Loss: 0.6918 Train_Acc: 53.713 Val_Loss: 0.6903  BEST VAL Loss: 0.6903  Val_Acc: 53.751

Epoch 4: Validation loss decreased (0.690257 --> 0.690144).  Saving model ...
	 Train_Loss: 0.6915 Train_Acc: 53.730 Val_Loss: 0.6901  BEST VAL Loss: 0.6901  Val_Acc: 53.751

Epoch 5: Validation loss decreased (0.690144 --> 0.689912).  Saving model ...
	 Train_Loss: 0.6913 Train_Acc: 53.740 Val_Loss: 0.6899  BEST VAL Loss: 0.6899  Val_Acc: 53.751

Epoch 6: Validation loss decreased (0.689912 --> 0.689864).  Saving model ...
	 Train_Loss: 0.6912 Train_Acc: 53.740 Val_Loss: 0.6899  BEST VAL Loss: 0.6899  Val_Acc: 53.751

Epoch 7: Validation loss decreased (0.689864 --> 0.688988).  Saving model ...
	 Train_Loss: 0.6910 Train_Acc: 53.719 Val_Loss: 0.6890  BEST VAL Loss: 0.6890  Val_Acc: 53.751

Epoch 8: Validation loss decreased (0.688988 --> 0.687463).  Saving model ...
	 Train_Loss: 0.6903 Train_Acc: 53.708 Val_Loss: 0.6875  BEST VAL Loss: 0.6875  Val_Acc: 53.751

Epoch 9: Validation loss decreased (0.687463 --> 0.684294).  Saving model ...
	 Train_Loss: 0.6888 Train_Acc: 55.712 Val_Loss: 0.6843  BEST VAL Loss: 0.6843  Val_Acc: 61.852

Epoch 10: Validation loss decreased (0.684294 --> 0.680711).  Saving model ...
	 Train_Loss: 0.6865 Train_Acc: 58.895 Val_Loss: 0.6807  BEST VAL Loss: 0.6807  Val_Acc: 64.038

Epoch 11: Validation loss decreased (0.680711 --> 0.676727).  Saving model ...
	 Train_Loss: 0.6837 Train_Acc: 61.194 Val_Loss: 0.6767  BEST VAL Loss: 0.6767  Val_Acc: 64.423

Epoch 12: Validation loss decreased (0.676727 --> 0.673327).  Saving model ...
	 Train_Loss: 0.6805 Train_Acc: 63.150 Val_Loss: 0.6733  BEST VAL Loss: 0.6733  Val_Acc: 65.581

Epoch 13: Validation loss decreased (0.673327 --> 0.668724).  Saving model ...
	 Train_Loss: 0.6770 Train_Acc: 64.784 Val_Loss: 0.6687  BEST VAL Loss: 0.6687  Val_Acc: 67.381

Epoch 14: Validation loss decreased (0.668724 --> 0.665037).  Saving model ...
	 Train_Loss: 0.6737 Train_Acc: 65.331 Val_Loss: 0.6650  BEST VAL Loss: 0.6650  Val_Acc: 67.210

Epoch 15: Validation loss decreased (0.665037 --> 0.661715).  Saving model ...
	 Train_Loss: 0.6703 Train_Acc: 66.140 Val_Loss: 0.6617  BEST VAL Loss: 0.6617  Val_Acc: 66.952

Epoch 16: Validation loss decreased (0.661715 --> 0.658303).  Saving model ...
	 Train_Loss: 0.6668 Train_Acc: 67.045 Val_Loss: 0.6583  BEST VAL Loss: 0.6583  Val_Acc: 67.467

Epoch 17: Validation loss decreased (0.658303 --> 0.655783).  Saving model ...
	 Train_Loss: 0.6633 Train_Acc: 67.806 Val_Loss: 0.6558  BEST VAL Loss: 0.6558  Val_Acc: 67.381

Epoch 18: Validation loss decreased (0.655783 --> 0.653319).  Saving model ...
	 Train_Loss: 0.6598 Train_Acc: 68.208 Val_Loss: 0.6533  BEST VAL Loss: 0.6533  Val_Acc: 66.910

Epoch 19: Validation loss decreased (0.653319 --> 0.650090).  Saving model ...
	 Train_Loss: 0.6565 Train_Acc: 68.481 Val_Loss: 0.6501  BEST VAL Loss: 0.6501  Val_Acc: 68.495

Epoch 20: Validation loss decreased (0.650090 --> 0.647381).  Saving model ...
	 Train_Loss: 0.6533 Train_Acc: 69.173 Val_Loss: 0.6474  BEST VAL Loss: 0.6474  Val_Acc: 68.581

Epoch 21: Validation loss decreased (0.647381 --> 0.645067).  Saving model ...
	 Train_Loss: 0.6504 Train_Acc: 68.873 Val_Loss: 0.6451  BEST VAL Loss: 0.6451  Val_Acc: 68.495

Epoch 22: Validation loss decreased (0.645067 --> 0.643189).  Saving model ...
	 Train_Loss: 0.6474 Train_Acc: 69.467 Val_Loss: 0.6432  BEST VAL Loss: 0.6432  Val_Acc: 66.438

Epoch 23: Validation loss decreased (0.643189 --> 0.641224).  Saving model ...
	 Train_Loss: 0.6446 Train_Acc: 69.773 Val_Loss: 0.6412  BEST VAL Loss: 0.6412  Val_Acc: 68.410

Epoch 24: Validation loss decreased (0.641224 --> 0.639283).  Saving model ...
	 Train_Loss: 0.6417 Train_Acc: 70.309 Val_Loss: 0.6393  BEST VAL Loss: 0.6393  Val_Acc: 68.881

Epoch 25: Validation loss decreased (0.639283 --> 0.637410).  Saving model ...
	 Train_Loss: 0.6389 Train_Acc: 70.893 Val_Loss: 0.6374  BEST VAL Loss: 0.6374  Val_Acc: 69.010

Epoch 26: Validation loss decreased (0.637410 --> 0.635285).  Saving model ...
	 Train_Loss: 0.6364 Train_Acc: 71.005 Val_Loss: 0.6353  BEST VAL Loss: 0.6353  Val_Acc: 69.138

Epoch 27: Validation loss decreased (0.635285 --> 0.633239).  Saving model ...
	 Train_Loss: 0.6340 Train_Acc: 70.936 Val_Loss: 0.6332  BEST VAL Loss: 0.6332  Val_Acc: 70.682

Epoch 28: Validation loss decreased (0.633239 --> 0.631404).  Saving model ...
	 Train_Loss: 0.6316 Train_Acc: 71.043 Val_Loss: 0.6314  BEST VAL Loss: 0.6314  Val_Acc: 70.682

Epoch 29: Validation loss decreased (0.631404 --> 0.629700).  Saving model ...
	 Train_Loss: 0.6292 Train_Acc: 71.755 Val_Loss: 0.6297  BEST VAL Loss: 0.6297  Val_Acc: 70.339

Epoch 30: Validation loss decreased (0.629700 --> 0.627998).  Saving model ...
	 Train_Loss: 0.6270 Train_Acc: 71.011 Val_Loss: 0.6280  BEST VAL Loss: 0.6280  Val_Acc: 69.438

Epoch 31: Validation loss decreased (0.627998 --> 0.626821).  Saving model ...
	 Train_Loss: 0.6249 Train_Acc: 71.932 Val_Loss: 0.6268  BEST VAL Loss: 0.6268  Val_Acc: 70.039

Epoch 32: Validation loss decreased (0.626821 --> 0.625015).  Saving model ...
	 Train_Loss: 0.6229 Train_Acc: 71.493 Val_Loss: 0.6250  BEST VAL Loss: 0.6250  Val_Acc: 70.339

Epoch 33: Validation loss decreased (0.625015 --> 0.623813).  Saving model ...
	 Train_Loss: 0.6209 Train_Acc: 71.916 Val_Loss: 0.6238  BEST VAL Loss: 0.6238  Val_Acc: 69.867

Epoch 34: Validation loss decreased (0.623813 --> 0.622520).  Saving model ...
	 Train_Loss: 0.6191 Train_Acc: 71.927 Val_Loss: 0.6225  BEST VAL Loss: 0.6225  Val_Acc: 70.810

Epoch 35: Validation loss decreased (0.622520 --> 0.620971).  Saving model ...
	 Train_Loss: 0.6173 Train_Acc: 72.281 Val_Loss: 0.6210  BEST VAL Loss: 0.6210  Val_Acc: 71.110

Epoch 36: Validation loss decreased (0.620971 --> 0.619974).  Saving model ...
	 Train_Loss: 0.6156 Train_Acc: 71.986 Val_Loss: 0.6200  BEST VAL Loss: 0.6200  Val_Acc: 71.925

Epoch 37: Validation loss decreased (0.619974 --> 0.618894).  Saving model ...
	 Train_Loss: 0.6139 Train_Acc: 72.152 Val_Loss: 0.6189  BEST VAL Loss: 0.6189  Val_Acc: 71.367

Epoch 38: Validation loss decreased (0.618894 --> 0.617969).  Saving model ...
	 Train_Loss: 0.6120 Train_Acc: 72.934 Val_Loss: 0.6180  BEST VAL Loss: 0.6180  Val_Acc: 70.510

Epoch 39: Validation loss decreased (0.617969 --> 0.617094).  Saving model ...
	 Train_Loss: 0.6103 Train_Acc: 72.966 Val_Loss: 0.6171  BEST VAL Loss: 0.6171  Val_Acc: 71.324

Epoch 40: Validation loss decreased (0.617094 --> 0.615887).  Saving model ...
	 Train_Loss: 0.6087 Train_Acc: 72.838 Val_Loss: 0.6159  BEST VAL Loss: 0.6159  Val_Acc: 70.896

Epoch 41: Validation loss decreased (0.615887 --> 0.614838).  Saving model ...
	 Train_Loss: 0.6072 Train_Acc: 73.063 Val_Loss: 0.6148  BEST VAL Loss: 0.6148  Val_Acc: 69.824

Epoch 42: Validation loss decreased (0.614838 --> 0.613980).  Saving model ...
	 Train_Loss: 0.6055 Train_Acc: 73.481 Val_Loss: 0.6140  BEST VAL Loss: 0.6140  Val_Acc: 71.796

Epoch 43: Validation loss decreased (0.613980 --> 0.613284).  Saving model ...
	 Train_Loss: 0.6040 Train_Acc: 73.256 Val_Loss: 0.6133  BEST VAL Loss: 0.6133  Val_Acc: 72.482

Epoch 44: Validation loss decreased (0.613284 --> 0.612248).  Saving model ...
	 Train_Loss: 0.6026 Train_Acc: 73.074 Val_Loss: 0.6122  BEST VAL Loss: 0.6122  Val_Acc: 70.896

Epoch 45: Validation loss decreased (0.612248 --> 0.611650).  Saving model ...
	 Train_Loss: 0.6011 Train_Acc: 73.299 Val_Loss: 0.6117  BEST VAL Loss: 0.6117  Val_Acc: 71.110

Epoch 46: Validation loss decreased (0.611650 --> 0.610597).  Saving model ...
	 Train_Loss: 0.5998 Train_Acc: 73.304 Val_Loss: 0.6106  BEST VAL Loss: 0.6106  Val_Acc: 71.410

Epoch 47: Validation loss decreased (0.610597 --> 0.610099).  Saving model ...
	 Train_Loss: 0.5983 Train_Acc: 73.449 Val_Loss: 0.6101  BEST VAL Loss: 0.6101  Val_Acc: 71.410

Epoch 48: Validation loss decreased (0.610099 --> 0.608813).  Saving model ...
	 Train_Loss: 0.5969 Train_Acc: 73.197 Val_Loss: 0.6088  BEST VAL Loss: 0.6088  Val_Acc: 71.453

Epoch 49: Validation loss decreased (0.608813 --> 0.607666).  Saving model ...
	 Train_Loss: 0.5955 Train_Acc: 73.760 Val_Loss: 0.6077  BEST VAL Loss: 0.6077  Val_Acc: 71.710

Epoch 50: Validation loss decreased (0.607666 --> 0.606733).  Saving model ...
	 Train_Loss: 0.5942 Train_Acc: 73.743 Val_Loss: 0.6067  BEST VAL Loss: 0.6067  Val_Acc: 71.796

Epoch 51: Validation loss decreased (0.606733 --> 0.606281).  Saving model ...
	 Train_Loss: 0.5927 Train_Acc: 74.547 Val_Loss: 0.6063  BEST VAL Loss: 0.6063  Val_Acc: 71.367

Epoch 52: Validation loss decreased (0.606281 --> 0.605747).  Saving model ...
	 Train_Loss: 0.5914 Train_Acc: 74.054 Val_Loss: 0.6057  BEST VAL Loss: 0.6057  Val_Acc: 72.610

Epoch 53: Validation loss decreased (0.605747 --> 0.604914).  Saving model ...
	 Train_Loss: 0.5901 Train_Acc: 74.177 Val_Loss: 0.6049  BEST VAL Loss: 0.6049  Val_Acc: 71.239

Epoch 54: Validation loss decreased (0.604914 --> 0.603870).  Saving model ...
	 Train_Loss: 0.5888 Train_Acc: 73.781 Val_Loss: 0.6039  BEST VAL Loss: 0.6039  Val_Acc: 71.239

Epoch 55: Validation loss decreased (0.603870 --> 0.602850).  Saving model ...
	 Train_Loss: 0.5876 Train_Acc: 73.840 Val_Loss: 0.6028  BEST VAL Loss: 0.6028  Val_Acc: 71.710

Epoch 56: Validation loss decreased (0.602850 --> 0.602049).  Saving model ...
	 Train_Loss: 0.5865 Train_Acc: 74.054 Val_Loss: 0.6020  BEST VAL Loss: 0.6020  Val_Acc: 72.182

Epoch 57: Validation loss decreased (0.602049 --> 0.600967).  Saving model ...
	 Train_Loss: 0.5853 Train_Acc: 74.188 Val_Loss: 0.6010  BEST VAL Loss: 0.6010  Val_Acc: 72.096

Epoch 58: Validation loss decreased (0.600967 --> 0.600026).  Saving model ...
	 Train_Loss: 0.5842 Train_Acc: 74.478 Val_Loss: 0.6000  BEST VAL Loss: 0.6000  Val_Acc: 71.582

Epoch 59: Validation loss decreased (0.600026 --> 0.598856).  Saving model ...
	 Train_Loss: 0.5830 Train_Acc: 74.483 Val_Loss: 0.5989  BEST VAL Loss: 0.5989  Val_Acc: 73.039

Epoch 60: Validation loss decreased (0.598856 --> 0.598215).  Saving model ...
	 Train_Loss: 0.5819 Train_Acc: 74.113 Val_Loss: 0.5982  BEST VAL Loss: 0.5982  Val_Acc: 71.410

Epoch 61: Validation loss decreased (0.598215 --> 0.597419).  Saving model ...
	 Train_Loss: 0.5809 Train_Acc: 74.317 Val_Loss: 0.5974  BEST VAL Loss: 0.5974  Val_Acc: 74.368

Epoch 62: Validation loss decreased (0.597419 --> 0.596357).  Saving model ...
	 Train_Loss: 0.5798 Train_Acc: 74.397 Val_Loss: 0.5964  BEST VAL Loss: 0.5964  Val_Acc: 73.296

Epoch 63: Validation loss decreased (0.596357 --> 0.595612).  Saving model ...
	 Train_Loss: 0.5788 Train_Acc: 74.461 Val_Loss: 0.5956  BEST VAL Loss: 0.5956  Val_Acc: 72.739

Epoch 64: Validation loss decreased (0.595612 --> 0.594891).  Saving model ...
	 Train_Loss: 0.5779 Train_Acc: 74.547 Val_Loss: 0.5949  BEST VAL Loss: 0.5949  Val_Acc: 71.967

Epoch 65: Validation loss decreased (0.594891 --> 0.594093).  Saving model ...
	 Train_Loss: 0.5769 Train_Acc: 74.612 Val_Loss: 0.5941  BEST VAL Loss: 0.5941  Val_Acc: 72.267

Epoch 66: Validation loss decreased (0.594093 --> 0.593684).  Saving model ...
	 Train_Loss: 0.5759 Train_Acc: 74.713 Val_Loss: 0.5937  BEST VAL Loss: 0.5937  Val_Acc: 71.882

Epoch 67: Validation loss decreased (0.593684 --> 0.592860).  Saving model ...
	 Train_Loss: 0.5749 Train_Acc: 74.869 Val_Loss: 0.5929  BEST VAL Loss: 0.5929  Val_Acc: 72.568

Epoch 68: Validation loss decreased (0.592860 --> 0.592205).  Saving model ...
	 Train_Loss: 0.5739 Train_Acc: 74.429 Val_Loss: 0.5922  BEST VAL Loss: 0.5922  Val_Acc: 72.310

Epoch 69: Validation loss decreased (0.592205 --> 0.591561).  Saving model ...
	 Train_Loss: 0.5731 Train_Acc: 74.826 Val_Loss: 0.5916  BEST VAL Loss: 0.5916  Val_Acc: 73.596

Epoch 70: Validation loss decreased (0.591561 --> 0.590747).  Saving model ...
	 Train_Loss: 0.5721 Train_Acc: 75.437 Val_Loss: 0.5907  BEST VAL Loss: 0.5907  Val_Acc: 73.039

Epoch 71: Validation loss decreased (0.590747 --> 0.590215).  Saving model ...
	 Train_Loss: 0.5712 Train_Acc: 75.035 Val_Loss: 0.5902  BEST VAL Loss: 0.5902  Val_Acc: 71.753

Epoch 72: Validation loss decreased (0.590215 --> 0.589646).  Saving model ...
	 Train_Loss: 0.5704 Train_Acc: 74.199 Val_Loss: 0.5896  BEST VAL Loss: 0.5896  Val_Acc: 72.653

Epoch 73: Validation loss decreased (0.589646 --> 0.589031).  Saving model ...
	 Train_Loss: 0.5695 Train_Acc: 74.890 Val_Loss: 0.5890  BEST VAL Loss: 0.5890  Val_Acc: 73.896

Epoch 74: Validation loss decreased (0.589031 --> 0.588544).  Saving model ...
	 Train_Loss: 0.5686 Train_Acc: 74.976 Val_Loss: 0.5885  BEST VAL Loss: 0.5885  Val_Acc: 71.796

Epoch 75: Validation loss decreased (0.588544 --> 0.587919).  Saving model ...
	 Train_Loss: 0.5677 Train_Acc: 74.847 Val_Loss: 0.5879  BEST VAL Loss: 0.5879  Val_Acc: 71.925

Epoch 76: Validation loss decreased (0.587919 --> 0.587236).  Saving model ...
	 Train_Loss: 0.5669 Train_Acc: 75.110 Val_Loss: 0.5872  BEST VAL Loss: 0.5872  Val_Acc: 73.811

Epoch 77: Validation loss decreased (0.587236 --> 0.586627).  Saving model ...
	 Train_Loss: 0.5660 Train_Acc: 75.008 Val_Loss: 0.5866  BEST VAL Loss: 0.5866  Val_Acc: 72.996

Epoch 78: Validation loss decreased (0.586627 --> 0.585956).  Saving model ...
	 Train_Loss: 0.5652 Train_Acc: 74.928 Val_Loss: 0.5860  BEST VAL Loss: 0.5860  Val_Acc: 72.653

Epoch 79: Validation loss decreased (0.585956 --> 0.585473).  Saving model ...
	 Train_Loss: 0.5644 Train_Acc: 75.078 Val_Loss: 0.5855  BEST VAL Loss: 0.5855  Val_Acc: 72.825

Epoch 80: Validation loss decreased (0.585473 --> 0.584987).  Saving model ...
	 Train_Loss: 0.5636 Train_Acc: 75.196 Val_Loss: 0.5850  BEST VAL Loss: 0.5850  Val_Acc: 72.139

Epoch 81: Validation loss decreased (0.584987 --> 0.584327).  Saving model ...
	 Train_Loss: 0.5629 Train_Acc: 74.799 Val_Loss: 0.5843  BEST VAL Loss: 0.5843  Val_Acc: 73.039

Epoch 82: Validation loss decreased (0.584327 --> 0.583876).  Saving model ...
	 Train_Loss: 0.5621 Train_Acc: 75.142 Val_Loss: 0.5839  BEST VAL Loss: 0.5839  Val_Acc: 72.825

Epoch 83: Validation loss decreased (0.583876 --> 0.583753).  Saving model ...
	 Train_Loss: 0.5613 Train_Acc: 75.437 Val_Loss: 0.5838  BEST VAL Loss: 0.5838  Val_Acc: 73.082

Epoch 84: Validation loss decreased (0.583753 --> 0.583392).  Saving model ...
	 Train_Loss: 0.5606 Train_Acc: 75.421 Val_Loss: 0.5834  BEST VAL Loss: 0.5834  Val_Acc: 72.525

Epoch 85: Validation loss decreased (0.583392 --> 0.582747).  Saving model ...
	 Train_Loss: 0.5599 Train_Acc: 75.238 Val_Loss: 0.5827  BEST VAL Loss: 0.5827  Val_Acc: 73.382

Epoch 86: Validation loss decreased (0.582747 --> 0.582401).  Saving model ...
	 Train_Loss: 0.5592 Train_Acc: 75.399 Val_Loss: 0.5824  BEST VAL Loss: 0.5824  Val_Acc: 72.696

Epoch 87: Validation loss decreased (0.582401 --> 0.582007).  Saving model ...
	 Train_Loss: 0.5585 Train_Acc: 75.394 Val_Loss: 0.5820  BEST VAL Loss: 0.5820  Val_Acc: 73.210

Epoch 88: Validation loss decreased (0.582007 --> 0.581668).  Saving model ...
	 Train_Loss: 0.5577 Train_Acc: 75.565 Val_Loss: 0.5817  BEST VAL Loss: 0.5817  Val_Acc: 72.439

Epoch 89: Validation loss decreased (0.581668 --> 0.581198).  Saving model ...
	 Train_Loss: 0.5571 Train_Acc: 75.410 Val_Loss: 0.5812  BEST VAL Loss: 0.5812  Val_Acc: 72.353

Epoch 90: Validation loss decreased (0.581198 --> 0.580825).  Saving model ...
	 Train_Loss: 0.5564 Train_Acc: 75.496 Val_Loss: 0.5808  BEST VAL Loss: 0.5808  Val_Acc: 73.296

Epoch 91: Validation loss decreased (0.580825 --> 0.580346).  Saving model ...
	 Train_Loss: 0.5557 Train_Acc: 75.356 Val_Loss: 0.5803  BEST VAL Loss: 0.5803  Val_Acc: 72.825

Epoch 92: Validation loss decreased (0.580346 --> 0.580101).  Saving model ...
	 Train_Loss: 0.5550 Train_Acc: 75.940 Val_Loss: 0.5801  BEST VAL Loss: 0.5801  Val_Acc: 71.925

Epoch 93: Validation loss decreased (0.580101 --> 0.579632).  Saving model ...
	 Train_Loss: 0.5543 Train_Acc: 75.442 Val_Loss: 0.5796  BEST VAL Loss: 0.5796  Val_Acc: 73.039

Epoch 94: Validation loss decreased (0.579632 --> 0.579112).  Saving model ...
	 Train_Loss: 0.5537 Train_Acc: 75.346 Val_Loss: 0.5791  BEST VAL Loss: 0.5791  Val_Acc: 73.425

Epoch 95: Validation loss decreased (0.579112 --> 0.578675).  Saving model ...
	 Train_Loss: 0.5530 Train_Acc: 75.447 Val_Loss: 0.5787  BEST VAL Loss: 0.5787  Val_Acc: 74.025

Epoch 96: Validation loss decreased (0.578675 --> 0.578364).  Saving model ...
	 Train_Loss: 0.5523 Train_Acc: 75.731 Val_Loss: 0.5784  BEST VAL Loss: 0.5784  Val_Acc: 72.568

Epoch 97: Validation loss decreased (0.578364 --> 0.578054).  Saving model ...
	 Train_Loss: 0.5517 Train_Acc: 75.721 Val_Loss: 0.5781  BEST VAL Loss: 0.5781  Val_Acc: 72.782

Epoch 98: Validation loss decreased (0.578054 --> 0.577919).  Saving model ...
	 Train_Loss: 0.5510 Train_Acc: 75.780 Val_Loss: 0.5779  BEST VAL Loss: 0.5779  Val_Acc: 72.353

Epoch 99: Validation loss decreased (0.577919 --> 0.577871).  Saving model ...
	 Train_Loss: 0.5504 Train_Acc: 75.603 Val_Loss: 0.5779  BEST VAL Loss: 0.5779  Val_Acc: 71.967

Flagellin_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.56      0.51      8635
           1       0.54      0.46      0.50     10027

    accuracy                           0.50     18662
   macro avg       0.51      0.51      0.50     18662
weighted avg       0.51      0.50      0.50     18662

Flagellin_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.54      0.49      1079
           1       0.53      0.45      0.49      1254

    accuracy                           0.49      2333
   macro avg       0.49      0.49      0.49      2333
weighted avg       0.50      0.49      0.49      2333

Flagellin_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.55      0.50      1079
           1       0.53      0.44      0.48      1254

    accuracy                           0.49      2333
   macro avg       0.50      0.50      0.49      2333
weighted avg       0.50      0.49      0.49      2333

              precision    recall  f1-score   support

           0       0.46      0.55      0.50      1079
           1       0.53      0.44      0.48      1254

    accuracy                           0.49      2333
   macro avg       0.50      0.50      0.49      2333
weighted avg       0.50      0.49      0.49      2333

Flagellin_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.64      0.57      4135
           1       0.48      0.35      0.40      3923

    accuracy                           0.50      8058
   macro avg       0.49      0.49      0.48      8058
weighted avg       0.49      0.50      0.49      8058

              precision    recall  f1-score   support

           0       0.51      0.64      0.57      4135
           1       0.48      0.35      0.40      3923

    accuracy                           0.50      8058
   macro avg       0.49      0.49      0.48      8058
weighted avg       0.49      0.50      0.49      8058

completed
