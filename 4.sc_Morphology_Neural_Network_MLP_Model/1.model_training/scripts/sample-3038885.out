[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '5fc666aa'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e805b23d'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '9fc8ec67'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '613badda'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Flagellin_1.000_DMSO_0.025 treatment_name: LPS_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Flagellin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (243980, 1270)
Number of total missing values across all columns: 524576
Data Subset Is Off
Wells held out for testing: ['D09' 'M10']
Wells to use for training, validation, and testing ['D02' 'D03' 'D08' 'M05' 'M11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.662959).  Saving model ...
	 Train_Loss: 0.7134 Train_Acc: 58.034 Val_Loss: 0.6630  BEST VAL Loss: 0.6630  Val_Acc: 59.627

Epoch 1: Validation loss decreased (0.662959 --> 0.656119).  Saving model ...
	 Train_Loss: 0.6856 Train_Acc: 60.138 Val_Loss: 0.6561  BEST VAL Loss: 0.6561  Val_Acc: 65.347

Epoch 2: Validation loss decreased (0.656119 --> 0.648221).  Saving model ...
	 Train_Loss: 0.6702 Train_Acc: 62.629 Val_Loss: 0.6482  BEST VAL Loss: 0.6482  Val_Acc: 66.809

Epoch 3: Validation loss did not decrease
	 Train_Loss: 0.6601 Train_Acc: 64.085 Val_Loss: 0.6509  BEST VAL Loss: 0.6482  Val_Acc: 66.809

Epoch 4: Validation loss did not decrease
	 Train_Loss: 0.6541 Train_Acc: 64.138 Val_Loss: 0.6496  BEST VAL Loss: 0.6482  Val_Acc: 67.787

Epoch 5: Validation loss did not decrease
	 Train_Loss: 0.6499 Train_Acc: 63.839 Val_Loss: 0.6520  BEST VAL Loss: 0.6482  Val_Acc: 67.983

Epoch 6: Validation loss did not decrease
	 Train_Loss: 0.6466 Train_Acc: 64.498 Val_Loss: 0.6489  BEST VAL Loss: 0.6482  Val_Acc: 68.190

Epoch 7: Validation loss decreased (0.648221 --> 0.646104).  Saving model ...
	 Train_Loss: 0.6437 Train_Acc: 65.005 Val_Loss: 0.6461  BEST VAL Loss: 0.6461  Val_Acc: 67.223

Epoch 8: Validation loss decreased (0.646104 --> 0.641302).  Saving model ...
	 Train_Loss: 0.6410 Train_Acc: 65.116 Val_Loss: 0.6413  BEST VAL Loss: 0.6413  Val_Acc: 68.541

Epoch 9: Validation loss decreased (0.641302 --> 0.639563).  Saving model ...
	 Train_Loss: 0.6385 Train_Acc: 65.615 Val_Loss: 0.6396  BEST VAL Loss: 0.6396  Val_Acc: 66.199

Epoch 10: Validation loss decreased (0.639563 --> 0.638130).  Saving model ...
	 Train_Loss: 0.6368 Train_Acc: 65.203 Val_Loss: 0.6381  BEST VAL Loss: 0.6381  Val_Acc: 68.017

Epoch 11: Validation loss decreased (0.638130 --> 0.637269).  Saving model ...
	 Train_Loss: 0.6356 Train_Acc: 64.682 Val_Loss: 0.6373  BEST VAL Loss: 0.6373  Val_Acc: 67.919

Epoch 12: Validation loss decreased (0.637269 --> 0.635193).  Saving model ...
	 Train_Loss: 0.6344 Train_Acc: 65.085 Val_Loss: 0.6352  BEST VAL Loss: 0.6352  Val_Acc: 69.605

Epoch 13: Validation loss decreased (0.635193 --> 0.635111).  Saving model ...
	 Train_Loss: 0.6329 Train_Acc: 65.676 Val_Loss: 0.6351  BEST VAL Loss: 0.6351  Val_Acc: 69.243

Epoch 14: Validation loss decreased (0.635111 --> 0.633935).  Saving model ...
	 Train_Loss: 0.6318 Train_Acc: 65.229 Val_Loss: 0.6339  BEST VAL Loss: 0.6339  Val_Acc: 69.692

Epoch 15: Validation loss did not decrease
	 Train_Loss: 0.6304 Train_Acc: 66.006 Val_Loss: 0.6356  BEST VAL Loss: 0.6339  Val_Acc: 69.847

Epoch 16: Validation loss decreased (0.633935 --> 0.633616).  Saving model ...
	 Train_Loss: 0.6293 Train_Acc: 66.144 Val_Loss: 0.6336  BEST VAL Loss: 0.6336  Val_Acc: 69.697

Epoch 17: Validation loss did not decrease
	 Train_Loss: 0.6284 Train_Acc: 65.893 Val_Loss: 0.6369  BEST VAL Loss: 0.6336  Val_Acc: 68.431

Epoch 18: Validation loss did not decrease
	 Train_Loss: 0.6279 Train_Acc: 65.252 Val_Loss: 0.6354  BEST VAL Loss: 0.6336  Val_Acc: 69.444

Epoch 19: Validation loss did not decrease
	 Train_Loss: 0.6272 Train_Acc: 65.495 Val_Loss: 0.6364  BEST VAL Loss: 0.6336  Val_Acc: 69.427

Epoch 20: Validation loss did not decrease
	 Train_Loss: 0.6274 Train_Acc: 63.326 Val_Loss: 0.6388  BEST VAL Loss: 0.6336  Val_Acc: 68.598

Epoch 21: Validation loss did not decrease
	 Train_Loss: 0.6271 Train_Acc: 64.417 Val_Loss: 0.6375  BEST VAL Loss: 0.6336  Val_Acc: 68.961

Epoch 22: Validation loss did not decrease
	 Train_Loss: 0.6265 Train_Acc: 65.068 Val_Loss: 0.6385  BEST VAL Loss: 0.6336  Val_Acc: 69.398

Epoch 23: Validation loss did not decrease
	 Train_Loss: 0.6263 Train_Acc: 64.475 Val_Loss: 0.6383  BEST VAL Loss: 0.6336  Val_Acc: 70.123

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.6255 Train_Acc: 66.156 Val_Loss: 0.6377  BEST VAL Loss: 0.6336  Val_Acc: 69.634

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.6250 Train_Acc: 65.634 Val_Loss: 0.6377  BEST VAL Loss: 0.6336  Val_Acc: 70.094

Epoch 26: Validation loss did not decrease
	 Train_Loss: 0.6245 Train_Acc: 65.276 Val_Loss: 0.6374  BEST VAL Loss: 0.6336  Val_Acc: 69.559

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.6241 Train_Acc: 65.579 Val_Loss: 0.6379  BEST VAL Loss: 0.6336  Val_Acc: 69.830

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.6238 Train_Acc: 64.817 Val_Loss: 0.6374  BEST VAL Loss: 0.6336  Val_Acc: 69.939

Epoch 29: Validation loss did not decrease
	 Train_Loss: 0.6234 Train_Acc: 65.158 Val_Loss: 0.6374  BEST VAL Loss: 0.6336  Val_Acc: 69.933

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.6230 Train_Acc: 65.774 Val_Loss: 0.6373  BEST VAL Loss: 0.6336  Val_Acc: 69.974

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.6226 Train_Acc: 65.677 Val_Loss: 0.6361  BEST VAL Loss: 0.6336  Val_Acc: 69.387

Epoch 32: Validation loss did not decrease
Early stopped at epoch : 32
Flagellin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.63      0.64      0.64     56122
           1       0.76      0.75      0.75     82897

    accuracy                           0.71    139019
   macro avg       0.70      0.70      0.70    139019
weighted avg       0.71      0.71      0.71    139019

Flagellin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.62      0.63      0.63      7016
           1       0.75      0.74      0.74     10362

    accuracy                           0.70     17378
   macro avg       0.69      0.69      0.69     17378
weighted avg       0.70      0.70      0.70     17378

Flagellin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.63      0.63      0.63      7015
           1       0.75      0.75      0.75     10363

    accuracy                           0.70     17378
   macro avg       0.69      0.69      0.69     17378
weighted avg       0.70      0.70      0.70     17378

              precision    recall  f1-score   support

           0       0.63      0.63      0.63      7015
           1       0.75      0.75      0.75     10363

    accuracy                           0.70     17378
   macro avg       0.69      0.69      0.69     17378
weighted avg       0.70      0.70      0.70     17378

Flagellin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.41      0.57     34394
           1       0.63      0.97      0.76     35811

    accuracy                           0.70     70205
   macro avg       0.78      0.69      0.67     70205
weighted avg       0.78      0.70      0.67     70205

              precision    recall  f1-score   support

           0       0.93      0.41      0.57     34394
           1       0.63      0.97      0.76     35811

    accuracy                           0.70     70205
   macro avg       0.78      0.69      0.67     70205
weighted avg       0.78      0.70      0.67     70205

completed
