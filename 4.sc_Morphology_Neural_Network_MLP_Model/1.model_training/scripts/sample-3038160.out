[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b346dd5f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'a7221e71'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '28a10dfe'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'c5b1001f'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Flagellin_0.100_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_100.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (255350, 1270)
Number of total missing values across all columns: 510700
Data Subset Is Off
Wells held out for testing: ['J08' 'L10']
Wells to use for training, validation, and testing ['J02' 'J03' 'J09' 'L05' 'L11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.511930).  Saving model ...
	 Train_Loss: 0.5807 Train_Acc: 69.571 Val_Loss: 0.5119  BEST VAL Loss: 0.5119  Val_Acc: 73.977

Epoch 1: Validation loss decreased (0.511930 --> 0.500099).  Saving model ...
	 Train_Loss: 0.5467 Train_Acc: 73.496 Val_Loss: 0.5001  BEST VAL Loss: 0.5001  Val_Acc: 75.089

Epoch 2: Validation loss decreased (0.500099 --> 0.490879).  Saving model ...
	 Train_Loss: 0.5311 Train_Acc: 74.266 Val_Loss: 0.4909  BEST VAL Loss: 0.4909  Val_Acc: 76.136

Epoch 3: Validation loss decreased (0.490879 --> 0.486478).  Saving model ...
	 Train_Loss: 0.5209 Train_Acc: 74.729 Val_Loss: 0.4865  BEST VAL Loss: 0.4865  Val_Acc: 75.964

Epoch 4: Validation loss decreased (0.486478 --> 0.482365).  Saving model ...
	 Train_Loss: 0.5136 Train_Acc: 75.070 Val_Loss: 0.4824  BEST VAL Loss: 0.4824  Val_Acc: 76.509

Epoch 5: Validation loss decreased (0.482365 --> 0.478731).  Saving model ...
	 Train_Loss: 0.5084 Train_Acc: 75.064 Val_Loss: 0.4787  BEST VAL Loss: 0.4787  Val_Acc: 76.795

Epoch 6: Validation loss decreased (0.478731 --> 0.476417).  Saving model ...
	 Train_Loss: 0.5042 Train_Acc: 75.347 Val_Loss: 0.4764  BEST VAL Loss: 0.4764  Val_Acc: 76.828

Epoch 7: Validation loss decreased (0.476417 --> 0.474773).  Saving model ...
	 Train_Loss: 0.5007 Train_Acc: 75.653 Val_Loss: 0.4748  BEST VAL Loss: 0.4748  Val_Acc: 76.747

Epoch 8: Validation loss decreased (0.474773 --> 0.473251).  Saving model ...
	 Train_Loss: 0.4976 Train_Acc: 75.688 Val_Loss: 0.4733  BEST VAL Loss: 0.4733  Val_Acc: 76.892

Epoch 9: Validation loss decreased (0.473251 --> 0.472355).  Saving model ...
	 Train_Loss: 0.4948 Train_Acc: 75.765 Val_Loss: 0.4724  BEST VAL Loss: 0.4724  Val_Acc: 76.865

Epoch 10: Validation loss decreased (0.472355 --> 0.471057).  Saving model ...
	 Train_Loss: 0.4924 Train_Acc: 75.804 Val_Loss: 0.4711  BEST VAL Loss: 0.4711  Val_Acc: 77.173

Epoch 11: Validation loss decreased (0.471057 --> 0.470304).  Saving model ...
	 Train_Loss: 0.4901 Train_Acc: 75.914 Val_Loss: 0.4703  BEST VAL Loss: 0.4703  Val_Acc: 76.914

Epoch 12: Validation loss decreased (0.470304 --> 0.469055).  Saving model ...
	 Train_Loss: 0.4882 Train_Acc: 75.937 Val_Loss: 0.4691  BEST VAL Loss: 0.4691  Val_Acc: 77.108

Epoch 13: Validation loss decreased (0.469055 --> 0.467738).  Saving model ...
	 Train_Loss: 0.4863 Train_Acc: 76.153 Val_Loss: 0.4677  BEST VAL Loss: 0.4677  Val_Acc: 77.519

Epoch 14: Validation loss did not decrease
	 Train_Loss: 0.4845 Train_Acc: 76.279 Val_Loss: 0.4679  BEST VAL Loss: 0.4677  Val_Acc: 76.930

Epoch 15: Validation loss decreased (0.467738 --> 0.466736).  Saving model ...
	 Train_Loss: 0.4829 Train_Acc: 76.211 Val_Loss: 0.4667  BEST VAL Loss: 0.4667  Val_Acc: 77.740

Epoch 16: Validation loss decreased (0.466736 --> 0.465867).  Saving model ...
	 Train_Loss: 0.4815 Train_Acc: 76.093 Val_Loss: 0.4659  BEST VAL Loss: 0.4659  Val_Acc: 77.513

Epoch 17: Validation loss decreased (0.465867 --> 0.465589).  Saving model ...
	 Train_Loss: 0.4802 Train_Acc: 76.383 Val_Loss: 0.4656  BEST VAL Loss: 0.4656  Val_Acc: 77.362

Epoch 18: Validation loss decreased (0.465589 --> 0.464925).  Saving model ...
	 Train_Loss: 0.4789 Train_Acc: 76.380 Val_Loss: 0.4649  BEST VAL Loss: 0.4649  Val_Acc: 77.735

Epoch 19: Validation loss decreased (0.464925 --> 0.464718).  Saving model ...
	 Train_Loss: 0.4775 Train_Acc: 76.447 Val_Loss: 0.4647  BEST VAL Loss: 0.4647  Val_Acc: 77.173

Epoch 20: Validation loss decreased (0.464718 --> 0.464172).  Saving model ...
	 Train_Loss: 0.4762 Train_Acc: 76.457 Val_Loss: 0.4642  BEST VAL Loss: 0.4642  Val_Acc: 77.864

Epoch 21: Validation loss decreased (0.464172 --> 0.463586).  Saving model ...
	 Train_Loss: 0.4749 Train_Acc: 76.518 Val_Loss: 0.4636  BEST VAL Loss: 0.4636  Val_Acc: 77.978

Epoch 22: Validation loss decreased (0.463586 --> 0.463081).  Saving model ...
	 Train_Loss: 0.4738 Train_Acc: 76.539 Val_Loss: 0.4631  BEST VAL Loss: 0.4631  Val_Acc: 77.945

Epoch 23: Validation loss decreased (0.463081 --> 0.462202).  Saving model ...
	 Train_Loss: 0.4727 Train_Acc: 76.684 Val_Loss: 0.4622  BEST VAL Loss: 0.4622  Val_Acc: 78.237

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.4716 Train_Acc: 76.567 Val_Loss: 0.4624  BEST VAL Loss: 0.4622  Val_Acc: 77.805

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.4706 Train_Acc: 76.746 Val_Loss: 0.4622  BEST VAL Loss: 0.4622  Val_Acc: 77.918

Epoch 26: Validation loss decreased (0.462202 --> 0.461843).  Saving model ...
	 Train_Loss: 0.4696 Train_Acc: 76.792 Val_Loss: 0.4618  BEST VAL Loss: 0.4618  Val_Acc: 77.805

Epoch 27: Validation loss decreased (0.461843 --> 0.461181).  Saving model ...
	 Train_Loss: 0.4687 Train_Acc: 76.807 Val_Loss: 0.4612  BEST VAL Loss: 0.4612  Val_Acc: 77.897

Epoch 28: Validation loss decreased (0.461181 --> 0.460643).  Saving model ...
	 Train_Loss: 0.4678 Train_Acc: 76.848 Val_Loss: 0.4606  BEST VAL Loss: 0.4606  Val_Acc: 77.843

Epoch 29: Validation loss decreased (0.460643 --> 0.459898).  Saving model ...
	 Train_Loss: 0.4669 Train_Acc: 76.855 Val_Loss: 0.4599  BEST VAL Loss: 0.4599  Val_Acc: 78.177

Epoch 30: Validation loss decreased (0.459898 --> 0.459404).  Saving model ...
	 Train_Loss: 0.4660 Train_Acc: 76.965 Val_Loss: 0.4594  BEST VAL Loss: 0.4594  Val_Acc: 78.296

Epoch 31: Validation loss decreased (0.459404 --> 0.458743).  Saving model ...
	 Train_Loss: 0.4652 Train_Acc: 76.916 Val_Loss: 0.4587  BEST VAL Loss: 0.4587  Val_Acc: 78.426

Epoch 32: Validation loss decreased (0.458743 --> 0.458172).  Saving model ...
	 Train_Loss: 0.4644 Train_Acc: 76.857 Val_Loss: 0.4582  BEST VAL Loss: 0.4582  Val_Acc: 78.701

Epoch 33: Validation loss decreased (0.458172 --> 0.457643).  Saving model ...
	 Train_Loss: 0.4636 Train_Acc: 77.050 Val_Loss: 0.4576  BEST VAL Loss: 0.4576  Val_Acc: 78.312

Epoch 34: Validation loss decreased (0.457643 --> 0.457067).  Saving model ...
	 Train_Loss: 0.4629 Train_Acc: 76.875 Val_Loss: 0.4571  BEST VAL Loss: 0.4571  Val_Acc: 78.609

Epoch 35: Validation loss decreased (0.457067 --> 0.456621).  Saving model ...
	 Train_Loss: 0.4621 Train_Acc: 77.079 Val_Loss: 0.4566  BEST VAL Loss: 0.4566  Val_Acc: 78.966

Epoch 36: Validation loss decreased (0.456621 --> 0.456243).  Saving model ...
	 Train_Loss: 0.4613 Train_Acc: 77.020 Val_Loss: 0.4562  BEST VAL Loss: 0.4562  Val_Acc: 79.041

Epoch 37: Validation loss decreased (0.456243 --> 0.455650).  Saving model ...
	 Train_Loss: 0.4606 Train_Acc: 77.266 Val_Loss: 0.4556  BEST VAL Loss: 0.4556  Val_Acc: 78.831

Epoch 38: Validation loss decreased (0.455650 --> 0.455137).  Saving model ...
	 Train_Loss: 0.4598 Train_Acc: 77.186 Val_Loss: 0.4551  BEST VAL Loss: 0.4551  Val_Acc: 79.020

Epoch 39: Validation loss decreased (0.455137 --> 0.454701).  Saving model ...
	 Train_Loss: 0.4591 Train_Acc: 77.250 Val_Loss: 0.4547  BEST VAL Loss: 0.4547  Val_Acc: 78.739

Epoch 40: Validation loss decreased (0.454701 --> 0.454118).  Saving model ...
	 Train_Loss: 0.4584 Train_Acc: 77.258 Val_Loss: 0.4541  BEST VAL Loss: 0.4541  Val_Acc: 78.852

Epoch 41: Validation loss decreased (0.454118 --> 0.453662).  Saving model ...
	 Train_Loss: 0.4577 Train_Acc: 77.288 Val_Loss: 0.4537  BEST VAL Loss: 0.4537  Val_Acc: 78.631

Epoch 42: Validation loss decreased (0.453662 --> 0.453160).  Saving model ...
	 Train_Loss: 0.4571 Train_Acc: 77.328 Val_Loss: 0.4532  BEST VAL Loss: 0.4532  Val_Acc: 79.009

Epoch 43: Validation loss decreased (0.453160 --> 0.452930).  Saving model ...
	 Train_Loss: 0.4564 Train_Acc: 77.363 Val_Loss: 0.4529  BEST VAL Loss: 0.4529  Val_Acc: 78.490

Epoch 44: Validation loss decreased (0.452930 --> 0.452477).  Saving model ...
	 Train_Loss: 0.4558 Train_Acc: 77.467 Val_Loss: 0.4525  BEST VAL Loss: 0.4525  Val_Acc: 79.068

Epoch 45: Validation loss decreased (0.452477 --> 0.451835).  Saving model ...
	 Train_Loss: 0.4552 Train_Acc: 77.458 Val_Loss: 0.4518  BEST VAL Loss: 0.4518  Val_Acc: 79.338

Epoch 46: Validation loss decreased (0.451835 --> 0.451509).  Saving model ...
	 Train_Loss: 0.4547 Train_Acc: 77.413 Val_Loss: 0.4515  BEST VAL Loss: 0.4515  Val_Acc: 79.111

Epoch 47: Validation loss decreased (0.451509 --> 0.451250).  Saving model ...
	 Train_Loss: 0.4541 Train_Acc: 77.473 Val_Loss: 0.4512  BEST VAL Loss: 0.4512  Val_Acc: 78.998

Epoch 48: Validation loss decreased (0.451250 --> 0.451096).  Saving model ...
	 Train_Loss: 0.4535 Train_Acc: 77.532 Val_Loss: 0.4511  BEST VAL Loss: 0.4511  Val_Acc: 78.053

Epoch 49: Validation loss decreased (0.451096 --> 0.450680).  Saving model ...
	 Train_Loss: 0.4530 Train_Acc: 77.470 Val_Loss: 0.4507  BEST VAL Loss: 0.4507  Val_Acc: 78.847

Epoch 50: Validation loss decreased (0.450680 --> 0.450520).  Saving model ...
	 Train_Loss: 0.4525 Train_Acc: 77.293 Val_Loss: 0.4505  BEST VAL Loss: 0.4505  Val_Acc: 78.739

Epoch 51: Validation loss decreased (0.450520 --> 0.450012).  Saving model ...
	 Train_Loss: 0.4520 Train_Acc: 77.430 Val_Loss: 0.4500  BEST VAL Loss: 0.4500  Val_Acc: 78.933

Epoch 52: Validation loss decreased (0.450012 --> 0.449612).  Saving model ...
	 Train_Loss: 0.4515 Train_Acc: 77.470 Val_Loss: 0.4496  BEST VAL Loss: 0.4496  Val_Acc: 78.836

Epoch 53: Validation loss decreased (0.449612 --> 0.449293).  Saving model ...
	 Train_Loss: 0.4510 Train_Acc: 77.611 Val_Loss: 0.4493  BEST VAL Loss: 0.4493  Val_Acc: 78.825

Epoch 54: Validation loss decreased (0.449293 --> 0.448798).  Saving model ...
	 Train_Loss: 0.4505 Train_Acc: 77.511 Val_Loss: 0.4488  BEST VAL Loss: 0.4488  Val_Acc: 79.138

Epoch 55: Validation loss decreased (0.448798 --> 0.448610).  Saving model ...
	 Train_Loss: 0.4501 Train_Acc: 77.432 Val_Loss: 0.4486  BEST VAL Loss: 0.4486  Val_Acc: 78.895

Epoch 56: Validation loss decreased (0.448610 --> 0.448447).  Saving model ...
	 Train_Loss: 0.4496 Train_Acc: 77.539 Val_Loss: 0.4484  BEST VAL Loss: 0.4484  Val_Acc: 78.512

Epoch 57: Validation loss decreased (0.448447 --> 0.448056).  Saving model ...
	 Train_Loss: 0.4492 Train_Acc: 77.297 Val_Loss: 0.4481  BEST VAL Loss: 0.4481  Val_Acc: 79.063

Epoch 58: Validation loss decreased (0.448056 --> 0.447748).  Saving model ...
	 Train_Loss: 0.4487 Train_Acc: 77.430 Val_Loss: 0.4477  BEST VAL Loss: 0.4477  Val_Acc: 79.025

Epoch 59: Validation loss decreased (0.447748 --> 0.447621).  Saving model ...
	 Train_Loss: 0.4483 Train_Acc: 77.558 Val_Loss: 0.4476  BEST VAL Loss: 0.4476  Val_Acc: 78.485

Epoch 60: Validation loss decreased (0.447621 --> 0.447528).  Saving model ...
	 Train_Loss: 0.4478 Train_Acc: 77.646 Val_Loss: 0.4475  BEST VAL Loss: 0.4475  Val_Acc: 78.355

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.4475 Train_Acc: 77.504 Val_Loss: 0.4477  BEST VAL Loss: 0.4475  Val_Acc: 77.902

Epoch 62: Validation loss decreased (0.447528 --> 0.447267).  Saving model ...
	 Train_Loss: 0.4471 Train_Acc: 77.376 Val_Loss: 0.4473  BEST VAL Loss: 0.4473  Val_Acc: 79.230

Epoch 63: Validation loss decreased (0.447267 --> 0.447002).  Saving model ...
	 Train_Loss: 0.4467 Train_Acc: 77.421 Val_Loss: 0.4470  BEST VAL Loss: 0.4470  Val_Acc: 78.804

Epoch 64: Validation loss decreased (0.447002 --> 0.446706).  Saving model ...
	 Train_Loss: 0.4463 Train_Acc: 77.641 Val_Loss: 0.4467  BEST VAL Loss: 0.4467  Val_Acc: 79.397

Epoch 65: Validation loss decreased (0.446706 --> 0.446443).  Saving model ...
	 Train_Loss: 0.4460 Train_Acc: 77.538 Val_Loss: 0.4464  BEST VAL Loss: 0.4464  Val_Acc: 79.155

Epoch 66: Validation loss decreased (0.446443 --> 0.446178).  Saving model ...
	 Train_Loss: 0.4456 Train_Acc: 77.707 Val_Loss: 0.4462  BEST VAL Loss: 0.4462  Val_Acc: 78.480

Epoch 67: Validation loss decreased (0.446178 --> 0.445867).  Saving model ...
	 Train_Loss: 0.4452 Train_Acc: 77.556 Val_Loss: 0.4459  BEST VAL Loss: 0.4459  Val_Acc: 78.566

Epoch 68: Validation loss decreased (0.445867 --> 0.445640).  Saving model ...
	 Train_Loss: 0.4449 Train_Acc: 77.600 Val_Loss: 0.4456  BEST VAL Loss: 0.4456  Val_Acc: 78.814

Epoch 69: Validation loss decreased (0.445640 --> 0.445411).  Saving model ...
	 Train_Loss: 0.4445 Train_Acc: 77.586 Val_Loss: 0.4454  BEST VAL Loss: 0.4454  Val_Acc: 78.663

Epoch 70: Validation loss decreased (0.445411 --> 0.445045).  Saving model ...
	 Train_Loss: 0.4442 Train_Acc: 77.511 Val_Loss: 0.4450  BEST VAL Loss: 0.4450  Val_Acc: 79.052

Epoch 71: Validation loss decreased (0.445045 --> 0.444890).  Saving model ...
	 Train_Loss: 0.4439 Train_Acc: 77.549 Val_Loss: 0.4449  BEST VAL Loss: 0.4449  Val_Acc: 78.480

Epoch 72: Validation loss decreased (0.444890 --> 0.444776).  Saving model ...
	 Train_Loss: 0.4435 Train_Acc: 77.674 Val_Loss: 0.4448  BEST VAL Loss: 0.4448  Val_Acc: 79.068

Epoch 73: Validation loss decreased (0.444776 --> 0.444405).  Saving model ...
	 Train_Loss: 0.4432 Train_Acc: 77.604 Val_Loss: 0.4444  BEST VAL Loss: 0.4444  Val_Acc: 79.527

Epoch 74: Validation loss decreased (0.444405 --> 0.444029).  Saving model ...
	 Train_Loss: 0.4429 Train_Acc: 77.772 Val_Loss: 0.4440  BEST VAL Loss: 0.4440  Val_Acc: 79.403

Epoch 75: Validation loss decreased (0.444029 --> 0.443803).  Saving model ...
	 Train_Loss: 0.4425 Train_Acc: 77.662 Val_Loss: 0.4438  BEST VAL Loss: 0.4438  Val_Acc: 79.289

Epoch 76: Validation loss decreased (0.443803 --> 0.443694).  Saving model ...
	 Train_Loss: 0.4422 Train_Acc: 77.797 Val_Loss: 0.4437  BEST VAL Loss: 0.4437  Val_Acc: 78.755

Epoch 77: Validation loss decreased (0.443694 --> 0.443534).  Saving model ...
	 Train_Loss: 0.4419 Train_Acc: 77.709 Val_Loss: 0.4435  BEST VAL Loss: 0.4435  Val_Acc: 79.144

Epoch 78: Validation loss decreased (0.443534 --> 0.443302).  Saving model ...
	 Train_Loss: 0.4416 Train_Acc: 77.699 Val_Loss: 0.4433  BEST VAL Loss: 0.4433  Val_Acc: 79.133

Epoch 79: Validation loss decreased (0.443302 --> 0.443022).  Saving model ...
	 Train_Loss: 0.4412 Train_Acc: 77.795 Val_Loss: 0.4430  BEST VAL Loss: 0.4430  Val_Acc: 79.392

Epoch 80: Validation loss decreased (0.443022 --> 0.442803).  Saving model ...
	 Train_Loss: 0.4409 Train_Acc: 77.801 Val_Loss: 0.4428  BEST VAL Loss: 0.4428  Val_Acc: 79.020

Epoch 81: Validation loss decreased (0.442803 --> 0.442545).  Saving model ...
	 Train_Loss: 0.4406 Train_Acc: 77.735 Val_Loss: 0.4425  BEST VAL Loss: 0.4425  Val_Acc: 79.246

Epoch 82: Validation loss decreased (0.442545 --> 0.442254).  Saving model ...
	 Train_Loss: 0.4403 Train_Acc: 77.795 Val_Loss: 0.4423  BEST VAL Loss: 0.4423  Val_Acc: 79.327

Epoch 83: Validation loss decreased (0.442254 --> 0.442069).  Saving model ...
	 Train_Loss: 0.4400 Train_Acc: 77.726 Val_Loss: 0.4421  BEST VAL Loss: 0.4421  Val_Acc: 79.041

Epoch 84: Validation loss decreased (0.442069 --> 0.441989).  Saving model ...
	 Train_Loss: 0.4398 Train_Acc: 77.790 Val_Loss: 0.4420  BEST VAL Loss: 0.4420  Val_Acc: 78.966

Epoch 85: Validation loss decreased (0.441989 --> 0.441884).  Saving model ...
	 Train_Loss: 0.4395 Train_Acc: 77.733 Val_Loss: 0.4419  BEST VAL Loss: 0.4419  Val_Acc: 79.176

Epoch 86: Validation loss decreased (0.441884 --> 0.441666).  Saving model ...
	 Train_Loss: 0.4392 Train_Acc: 77.683 Val_Loss: 0.4417  BEST VAL Loss: 0.4417  Val_Acc: 79.441

Epoch 87: Validation loss decreased (0.441666 --> 0.441607).  Saving model ...
	 Train_Loss: 0.4390 Train_Acc: 77.826 Val_Loss: 0.4416  BEST VAL Loss: 0.4416  Val_Acc: 78.949

Epoch 88: Validation loss decreased (0.441607 --> 0.441433).  Saving model ...
	 Train_Loss: 0.4387 Train_Acc: 77.884 Val_Loss: 0.4414  BEST VAL Loss: 0.4414  Val_Acc: 79.500

Epoch 89: Validation loss decreased (0.441433 --> 0.441254).  Saving model ...
	 Train_Loss: 0.4384 Train_Acc: 77.903 Val_Loss: 0.4413  BEST VAL Loss: 0.4413  Val_Acc: 79.063

Epoch 90: Validation loss decreased (0.441254 --> 0.441009).  Saving model ...
	 Train_Loss: 0.4382 Train_Acc: 77.804 Val_Loss: 0.4410  BEST VAL Loss: 0.4410  Val_Acc: 79.586

Epoch 91: Validation loss decreased (0.441009 --> 0.440824).  Saving model ...
	 Train_Loss: 0.4379 Train_Acc: 77.824 Val_Loss: 0.4408  BEST VAL Loss: 0.4408  Val_Acc: 79.532

Epoch 92: Validation loss decreased (0.440824 --> 0.440807).  Saving model ...
	 Train_Loss: 0.4377 Train_Acc: 77.938 Val_Loss: 0.4408  BEST VAL Loss: 0.4408  Val_Acc: 78.717

Epoch 93: Validation loss decreased (0.440807 --> 0.440651).  Saving model ...
	 Train_Loss: 0.4374 Train_Acc: 77.820 Val_Loss: 0.4407  BEST VAL Loss: 0.4407  Val_Acc: 79.300

Epoch 94: Validation loss decreased (0.440651 --> 0.440561).  Saving model ...
	 Train_Loss: 0.4372 Train_Acc: 77.715 Val_Loss: 0.4406  BEST VAL Loss: 0.4406  Val_Acc: 79.014

Epoch 95: Validation loss decreased (0.440561 --> 0.440356).  Saving model ...
	 Train_Loss: 0.4369 Train_Acc: 77.932 Val_Loss: 0.4404  BEST VAL Loss: 0.4404  Val_Acc: 79.403

Epoch 96: Validation loss decreased (0.440356 --> 0.440078).  Saving model ...
	 Train_Loss: 0.4367 Train_Acc: 77.977 Val_Loss: 0.4401  BEST VAL Loss: 0.4401  Val_Acc: 79.802

Epoch 97: Validation loss decreased (0.440078 --> 0.439913).  Saving model ...
	 Train_Loss: 0.4365 Train_Acc: 77.769 Val_Loss: 0.4399  BEST VAL Loss: 0.4399  Val_Acc: 79.214

Epoch 98: Validation loss decreased (0.439913 --> 0.439902).  Saving model ...
	 Train_Loss: 0.4362 Train_Acc: 77.836 Val_Loss: 0.4399  BEST VAL Loss: 0.4399  Val_Acc: 78.804

Epoch 99: Validation loss decreased (0.439902 --> 0.439770).  Saving model ...
	 Train_Loss: 0.4360 Train_Acc: 77.879 Val_Loss: 0.4398  BEST VAL Loss: 0.4398  Val_Acc: 79.333

Flagellin_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.82      0.58      0.68     50422
           1       0.81      0.93      0.87     97754

    accuracy                           0.81    148176
   macro avg       0.81      0.76      0.77    148176
weighted avg       0.81      0.81      0.80    148176

Flagellin_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.78      0.55      0.64      6303
           1       0.80      0.92      0.85     12219

    accuracy                           0.79     18522
   macro avg       0.79      0.73      0.75     18522
weighted avg       0.79      0.79      0.78     18522

Flagellin_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.79      0.55      0.65      6303
           1       0.80      0.93      0.86     12219

    accuracy                           0.80     18522
   macro avg       0.80      0.74      0.75     18522
weighted avg       0.80      0.80      0.79     18522

              precision    recall  f1-score   support

           0       0.79      0.55      0.65      6303
           1       0.80      0.93      0.86     12219

    accuracy                           0.80     18522
   macro avg       0.80      0.74      0.75     18522
weighted avg       0.80      0.80      0.79     18522

Flagellin_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.73      0.46      0.57     32887
           1       0.64      0.85      0.73     37243

    accuracy                           0.67     70130
   macro avg       0.69      0.66      0.65     70130
weighted avg       0.68      0.67      0.65     70130

              precision    recall  f1-score   support

           0       0.73      0.46      0.57     32887
           1       0.64      0.85      0.73     37243

    accuracy                           0.67     70130
   macro avg       0.69      0.66      0.65     70130
weighted avg       0.68      0.67      0.65     70130

completed
