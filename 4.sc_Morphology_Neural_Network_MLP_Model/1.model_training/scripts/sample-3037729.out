[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'fc893310'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e3a0bbfa'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '76793e79'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '1014a0ca'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_0.100_DMSO_0.025 treatment_name: DMSO_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: DMSO_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (50571, 1276)
Number of total missing values across all columns: 101142
Data Subset Is Off
Wells held out for testing: ['I14' 'L23']
Wells to use for training, validation, and testing ['B14' 'C14' 'B15' 'C15' 'J14' 'I15' 'J15' 'L18' 'L19' 'L22']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.598463).  Saving model ...
	 Train_Loss: 0.6139 Train_Acc: 72.374 Val_Loss: 0.5985  BEST VAL Loss: 0.5985  Val_Acc: 72.375

Epoch 1: Validation loss decreased (0.598463 --> 0.593875).  Saving model ...
	 Train_Loss: 0.6061 Train_Acc: 72.374 Val_Loss: 0.5939  BEST VAL Loss: 0.5939  Val_Acc: 72.375

Epoch 2: Validation loss decreased (0.593875 --> 0.591223).  Saving model ...
	 Train_Loss: 0.6019 Train_Acc: 72.374 Val_Loss: 0.5912  BEST VAL Loss: 0.5912  Val_Acc: 72.375

Epoch 3: Validation loss decreased (0.591223 --> 0.589546).  Saving model ...
	 Train_Loss: 0.5993 Train_Acc: 72.374 Val_Loss: 0.5895  BEST VAL Loss: 0.5895  Val_Acc: 72.375

Epoch 4: Validation loss decreased (0.589546 --> 0.588395).  Saving model ...
	 Train_Loss: 0.5976 Train_Acc: 72.374 Val_Loss: 0.5884  BEST VAL Loss: 0.5884  Val_Acc: 72.375

Epoch 5: Validation loss decreased (0.588395 --> 0.587543).  Saving model ...
	 Train_Loss: 0.5963 Train_Acc: 72.374 Val_Loss: 0.5875  BEST VAL Loss: 0.5875  Val_Acc: 72.375

Epoch 6: Validation loss decreased (0.587543 --> 0.586875).  Saving model ...
	 Train_Loss: 0.5954 Train_Acc: 72.374 Val_Loss: 0.5869  BEST VAL Loss: 0.5869  Val_Acc: 72.375

Epoch 7: Validation loss decreased (0.586875 --> 0.586321).  Saving model ...
	 Train_Loss: 0.5947 Train_Acc: 72.374 Val_Loss: 0.5863  BEST VAL Loss: 0.5863  Val_Acc: 72.375

Epoch 8: Validation loss decreased (0.586321 --> 0.585834).  Saving model ...
	 Train_Loss: 0.5941 Train_Acc: 72.374 Val_Loss: 0.5858  BEST VAL Loss: 0.5858  Val_Acc: 72.375

Epoch 9: Validation loss decreased (0.585834 --> 0.585375).  Saving model ...
	 Train_Loss: 0.5935 Train_Acc: 72.374 Val_Loss: 0.5854  BEST VAL Loss: 0.5854  Val_Acc: 72.375

Epoch 10: Validation loss decreased (0.585375 --> 0.584913).  Saving model ...
	 Train_Loss: 0.5930 Train_Acc: 72.371 Val_Loss: 0.5849  BEST VAL Loss: 0.5849  Val_Acc: 72.375

Epoch 11: Validation loss decreased (0.584913 --> 0.584427).  Saving model ...
	 Train_Loss: 0.5925 Train_Acc: 72.374 Val_Loss: 0.5844  BEST VAL Loss: 0.5844  Val_Acc: 72.375

Epoch 12: Validation loss decreased (0.584427 --> 0.583895).  Saving model ...
	 Train_Loss: 0.5920 Train_Acc: 72.368 Val_Loss: 0.5839  BEST VAL Loss: 0.5839  Val_Acc: 72.375

Epoch 13: Validation loss decreased (0.583895 --> 0.583277).  Saving model ...
	 Train_Loss: 0.5914 Train_Acc: 72.371 Val_Loss: 0.5833  BEST VAL Loss: 0.5833  Val_Acc: 72.351

Epoch 14: Validation loss decreased (0.583277 --> 0.582581).  Saving model ...
	 Train_Loss: 0.5908 Train_Acc: 72.347 Val_Loss: 0.5826  BEST VAL Loss: 0.5826  Val_Acc: 72.351

Epoch 15: Validation loss decreased (0.582581 --> 0.581764).  Saving model ...
	 Train_Loss: 0.5900 Train_Acc: 72.433 Val_Loss: 0.5818  BEST VAL Loss: 0.5818  Val_Acc: 72.375

Epoch 16: Validation loss decreased (0.581764 --> 0.580862).  Saving model ...
	 Train_Loss: 0.5893 Train_Acc: 72.529 Val_Loss: 0.5809  BEST VAL Loss: 0.5809  Val_Acc: 72.375

Epoch 17: Validation loss decreased (0.580862 --> 0.579884).  Saving model ...
	 Train_Loss: 0.5885 Train_Acc: 72.759 Val_Loss: 0.5799  BEST VAL Loss: 0.5799  Val_Acc: 72.375

Epoch 18: Validation loss decreased (0.579884 --> 0.578794).  Saving model ...
	 Train_Loss: 0.5876 Train_Acc: 72.949 Val_Loss: 0.5788  BEST VAL Loss: 0.5788  Val_Acc: 72.375

Epoch 19: Validation loss decreased (0.578794 --> 0.577700).  Saving model ...
	 Train_Loss: 0.5868 Train_Acc: 72.800 Val_Loss: 0.5777  BEST VAL Loss: 0.5777  Val_Acc: 72.398

Epoch 20: Validation loss decreased (0.577700 --> 0.576545).  Saving model ...
	 Train_Loss: 0.5859 Train_Acc: 73.205 Val_Loss: 0.5765  BEST VAL Loss: 0.5765  Val_Acc: 72.398

Epoch 21: Validation loss decreased (0.576545 --> 0.575387).  Saving model ...
	 Train_Loss: 0.5851 Train_Acc: 73.340 Val_Loss: 0.5754  BEST VAL Loss: 0.5754  Val_Acc: 72.375

Epoch 22: Validation loss decreased (0.575387 --> 0.574208).  Saving model ...
	 Train_Loss: 0.5843 Train_Acc: 73.437 Val_Loss: 0.5742  BEST VAL Loss: 0.5742  Val_Acc: 72.398

Epoch 23: Validation loss decreased (0.574208 --> 0.572962).  Saving model ...
	 Train_Loss: 0.5833 Train_Acc: 73.663 Val_Loss: 0.5730  BEST VAL Loss: 0.5730  Val_Acc: 72.563

Epoch 24: Validation loss decreased (0.572962 --> 0.571735).  Saving model ...
	 Train_Loss: 0.5824 Train_Acc: 73.757 Val_Loss: 0.5717  BEST VAL Loss: 0.5717  Val_Acc: 72.563

Epoch 25: Validation loss decreased (0.571735 --> 0.570493).  Saving model ...
	 Train_Loss: 0.5815 Train_Acc: 73.939 Val_Loss: 0.5705  BEST VAL Loss: 0.5705  Val_Acc: 72.680

Epoch 26: Validation loss decreased (0.570493 --> 0.569261).  Saving model ...
	 Train_Loss: 0.5805 Train_Acc: 74.195 Val_Loss: 0.5693  BEST VAL Loss: 0.5693  Val_Acc: 72.774

Epoch 27: Validation loss decreased (0.569261 --> 0.567988).  Saving model ...
	 Train_Loss: 0.5796 Train_Acc: 74.356 Val_Loss: 0.5680  BEST VAL Loss: 0.5680  Val_Acc: 73.033

Epoch 28: Validation loss decreased (0.567988 --> 0.566725).  Saving model ...
	 Train_Loss: 0.5786 Train_Acc: 74.344 Val_Loss: 0.5667  BEST VAL Loss: 0.5667  Val_Acc: 72.962

Epoch 29: Validation loss decreased (0.566725 --> 0.565451).  Saving model ...
	 Train_Loss: 0.5776 Train_Acc: 74.424 Val_Loss: 0.5655  BEST VAL Loss: 0.5655  Val_Acc: 73.409

Epoch 30: Validation loss decreased (0.565451 --> 0.564202).  Saving model ...
	 Train_Loss: 0.5767 Train_Acc: 74.333 Val_Loss: 0.5642  BEST VAL Loss: 0.5642  Val_Acc: 73.291

Epoch 31: Validation loss decreased (0.564202 --> 0.562932).  Saving model ...
	 Train_Loss: 0.5757 Train_Acc: 74.606 Val_Loss: 0.5629  BEST VAL Loss: 0.5629  Val_Acc: 73.620

Epoch 32: Validation loss decreased (0.562932 --> 0.561728).  Saving model ...
	 Train_Loss: 0.5748 Train_Acc: 74.506 Val_Loss: 0.5617  BEST VAL Loss: 0.5617  Val_Acc: 73.409

Epoch 33: Validation loss decreased (0.561728 --> 0.560440).  Saving model ...
	 Train_Loss: 0.5739 Train_Acc: 74.735 Val_Loss: 0.5604  BEST VAL Loss: 0.5604  Val_Acc: 73.784

Epoch 34: Validation loss decreased (0.560440 --> 0.559173).  Saving model ...
	 Train_Loss: 0.5728 Train_Acc: 74.979 Val_Loss: 0.5592  BEST VAL Loss: 0.5592  Val_Acc: 74.747

Epoch 35: Validation loss decreased (0.559173 --> 0.557886).  Saving model ...
	 Train_Loss: 0.5718 Train_Acc: 74.935 Val_Loss: 0.5579  BEST VAL Loss: 0.5579  Val_Acc: 74.419

Epoch 36: Validation loss decreased (0.557886 --> 0.556622).  Saving model ...
	 Train_Loss: 0.5707 Train_Acc: 75.079 Val_Loss: 0.5566  BEST VAL Loss: 0.5566  Val_Acc: 74.771

Epoch 37: Validation loss decreased (0.556622 --> 0.555390).  Saving model ...
	 Train_Loss: 0.5697 Train_Acc: 75.102 Val_Loss: 0.5554  BEST VAL Loss: 0.5554  Val_Acc: 75.288

Epoch 38: Validation loss decreased (0.555390 --> 0.554128).  Saving model ...
	 Train_Loss: 0.5688 Train_Acc: 75.164 Val_Loss: 0.5541  BEST VAL Loss: 0.5541  Val_Acc: 74.912

Epoch 39: Validation loss decreased (0.554128 --> 0.552858).  Saving model ...
	 Train_Loss: 0.5678 Train_Acc: 75.178 Val_Loss: 0.5529  BEST VAL Loss: 0.5529  Val_Acc: 75.264

Epoch 40: Validation loss decreased (0.552858 --> 0.551606).  Saving model ...
	 Train_Loss: 0.5669 Train_Acc: 74.797 Val_Loss: 0.5516  BEST VAL Loss: 0.5516  Val_Acc: 75.523

Epoch 41: Validation loss decreased (0.551606 --> 0.550364).  Saving model ...
	 Train_Loss: 0.5659 Train_Acc: 75.281 Val_Loss: 0.5504  BEST VAL Loss: 0.5504  Val_Acc: 75.593

Epoch 42: Validation loss decreased (0.550364 --> 0.549117).  Saving model ...
	 Train_Loss: 0.5649 Train_Acc: 75.220 Val_Loss: 0.5491  BEST VAL Loss: 0.5491  Val_Acc: 75.664

Epoch 43: Validation loss decreased (0.549117 --> 0.547984).  Saving model ...
	 Train_Loss: 0.5640 Train_Acc: 75.196 Val_Loss: 0.5480  BEST VAL Loss: 0.5480  Val_Acc: 75.640

Epoch 44: Validation loss decreased (0.547984 --> 0.546788).  Saving model ...
	 Train_Loss: 0.5630 Train_Acc: 75.275 Val_Loss: 0.5468  BEST VAL Loss: 0.5468  Val_Acc: 75.546

Epoch 45: Validation loss decreased (0.546788 --> 0.545653).  Saving model ...
	 Train_Loss: 0.5620 Train_Acc: 75.413 Val_Loss: 0.5457  BEST VAL Loss: 0.5457  Val_Acc: 75.992

Epoch 46: Validation loss decreased (0.545653 --> 0.544449).  Saving model ...
	 Train_Loss: 0.5610 Train_Acc: 75.319 Val_Loss: 0.5444  BEST VAL Loss: 0.5444  Val_Acc: 76.157

Epoch 47: Validation loss decreased (0.544449 --> 0.543253).  Saving model ...
	 Train_Loss: 0.5599 Train_Acc: 75.578 Val_Loss: 0.5433  BEST VAL Loss: 0.5433  Val_Acc: 76.580

Epoch 48: Validation loss decreased (0.543253 --> 0.542096).  Saving model ...
	 Train_Loss: 0.5590 Train_Acc: 75.493 Val_Loss: 0.5421  BEST VAL Loss: 0.5421  Val_Acc: 76.086

Epoch 49: Validation loss decreased (0.542096 --> 0.540975).  Saving model ...
	 Train_Loss: 0.5580 Train_Acc: 75.689 Val_Loss: 0.5410  BEST VAL Loss: 0.5410  Val_Acc: 77.003

Epoch 50: Validation loss decreased (0.540975 --> 0.539817).  Saving model ...
	 Train_Loss: 0.5569 Train_Acc: 75.598 Val_Loss: 0.5398  BEST VAL Loss: 0.5398  Val_Acc: 76.721

Epoch 51: Validation loss decreased (0.539817 --> 0.538888).  Saving model ...
	 Train_Loss: 0.5559 Train_Acc: 75.839 Val_Loss: 0.5389  BEST VAL Loss: 0.5389  Val_Acc: 76.133

Epoch 52: Validation loss decreased (0.538888 --> 0.537800).  Saving model ...
	 Train_Loss: 0.5550 Train_Acc: 75.592 Val_Loss: 0.5378  BEST VAL Loss: 0.5378  Val_Acc: 76.862

Epoch 53: Validation loss decreased (0.537800 --> 0.536798).  Saving model ...
	 Train_Loss: 0.5538 Train_Acc: 76.109 Val_Loss: 0.5368  BEST VAL Loss: 0.5368  Val_Acc: 76.979

Epoch 54: Validation loss decreased (0.536798 --> 0.535709).  Saving model ...
	 Train_Loss: 0.5529 Train_Acc: 75.739 Val_Loss: 0.5357  BEST VAL Loss: 0.5357  Val_Acc: 77.097

Epoch 55: Validation loss decreased (0.535709 --> 0.534635).  Saving model ...
	 Train_Loss: 0.5519 Train_Acc: 76.253 Val_Loss: 0.5346  BEST VAL Loss: 0.5346  Val_Acc: 77.191

Epoch 56: Validation loss decreased (0.534635 --> 0.533599).  Saving model ...
	 Train_Loss: 0.5509 Train_Acc: 76.215 Val_Loss: 0.5336  BEST VAL Loss: 0.5336  Val_Acc: 77.355

Epoch 57: Validation loss decreased (0.533599 --> 0.532535).  Saving model ...
	 Train_Loss: 0.5499 Train_Acc: 76.057 Val_Loss: 0.5325  BEST VAL Loss: 0.5325  Val_Acc: 77.543

Epoch 58: Validation loss decreased (0.532535 --> 0.531535).  Saving model ...
	 Train_Loss: 0.5489 Train_Acc: 76.165 Val_Loss: 0.5315  BEST VAL Loss: 0.5315  Val_Acc: 77.566

Epoch 59: Validation loss decreased (0.531535 --> 0.530535).  Saving model ...
	 Train_Loss: 0.5480 Train_Acc: 76.209 Val_Loss: 0.5305  BEST VAL Loss: 0.5305  Val_Acc: 77.966

Epoch 60: Validation loss decreased (0.530535 --> 0.529542).  Saving model ...
	 Train_Loss: 0.5470 Train_Acc: 76.453 Val_Loss: 0.5295  BEST VAL Loss: 0.5295  Val_Acc: 78.154

Epoch 61: Validation loss decreased (0.529542 --> 0.528583).  Saving model ...
	 Train_Loss: 0.5460 Train_Acc: 76.447 Val_Loss: 0.5286  BEST VAL Loss: 0.5286  Val_Acc: 77.707

Epoch 62: Validation loss decreased (0.528583 --> 0.527655).  Saving model ...
	 Train_Loss: 0.5451 Train_Acc: 76.294 Val_Loss: 0.5277  BEST VAL Loss: 0.5277  Val_Acc: 77.566

Epoch 63: Validation loss decreased (0.527655 --> 0.526682).  Saving model ...
	 Train_Loss: 0.5442 Train_Acc: 76.541 Val_Loss: 0.5267  BEST VAL Loss: 0.5267  Val_Acc: 78.083

Epoch 64: Validation loss decreased (0.526682 --> 0.525809).  Saving model ...
	 Train_Loss: 0.5433 Train_Acc: 76.333 Val_Loss: 0.5258  BEST VAL Loss: 0.5258  Val_Acc: 77.496

Epoch 65: Validation loss decreased (0.525809 --> 0.524962).  Saving model ...
	 Train_Loss: 0.5424 Train_Acc: 76.497 Val_Loss: 0.5250  BEST VAL Loss: 0.5250  Val_Acc: 77.754

Epoch 66: Validation loss decreased (0.524962 --> 0.524053).  Saving model ...
	 Train_Loss: 0.5415 Train_Acc: 76.676 Val_Loss: 0.5241  BEST VAL Loss: 0.5241  Val_Acc: 77.989

Epoch 67: Validation loss decreased (0.524053 --> 0.523230).  Saving model ...
	 Train_Loss: 0.5405 Train_Acc: 76.817 Val_Loss: 0.5232  BEST VAL Loss: 0.5232  Val_Acc: 77.731

Epoch 68: Validation loss decreased (0.523230 --> 0.522393).  Saving model ...
	 Train_Loss: 0.5397 Train_Acc: 76.844 Val_Loss: 0.5224  BEST VAL Loss: 0.5224  Val_Acc: 78.318

Epoch 69: Validation loss decreased (0.522393 --> 0.521606).  Saving model ...
	 Train_Loss: 0.5388 Train_Acc: 76.899 Val_Loss: 0.5216  BEST VAL Loss: 0.5216  Val_Acc: 77.519

Epoch 70: Validation loss decreased (0.521606 --> 0.520751).  Saving model ...
	 Train_Loss: 0.5379 Train_Acc: 77.005 Val_Loss: 0.5208  BEST VAL Loss: 0.5208  Val_Acc: 78.459

Epoch 71: Validation loss decreased (0.520751 --> 0.519955).  Saving model ...
	 Train_Loss: 0.5371 Train_Acc: 77.014 Val_Loss: 0.5200  BEST VAL Loss: 0.5200  Val_Acc: 78.506

Epoch 72: Validation loss decreased (0.519955 --> 0.519120).  Saving model ...
	 Train_Loss: 0.5362 Train_Acc: 76.723 Val_Loss: 0.5191  BEST VAL Loss: 0.5191  Val_Acc: 78.271

Epoch 73: Validation loss decreased (0.519120 --> 0.518333).  Saving model ...
	 Train_Loss: 0.5354 Train_Acc: 77.284 Val_Loss: 0.5183  BEST VAL Loss: 0.5183  Val_Acc: 78.412

Epoch 74: Validation loss decreased (0.518333 --> 0.517563).  Saving model ...
	 Train_Loss: 0.5346 Train_Acc: 77.002 Val_Loss: 0.5176  BEST VAL Loss: 0.5176  Val_Acc: 78.506

Epoch 75: Validation loss decreased (0.517563 --> 0.516798).  Saving model ...
	 Train_Loss: 0.5337 Train_Acc: 77.120 Val_Loss: 0.5168  BEST VAL Loss: 0.5168  Val_Acc: 78.271

Epoch 76: Validation loss decreased (0.516798 --> 0.516028).  Saving model ...
	 Train_Loss: 0.5329 Train_Acc: 77.078 Val_Loss: 0.5160  BEST VAL Loss: 0.5160  Val_Acc: 78.318

Epoch 77: Validation loss decreased (0.516028 --> 0.515278).  Saving model ...
	 Train_Loss: 0.5321 Train_Acc: 77.017 Val_Loss: 0.5153  BEST VAL Loss: 0.5153  Val_Acc: 78.694

Epoch 78: Validation loss decreased (0.515278 --> 0.514544).  Saving model ...
	 Train_Loss: 0.5313 Train_Acc: 77.472 Val_Loss: 0.5145  BEST VAL Loss: 0.5145  Val_Acc: 78.248

Epoch 79: Validation loss decreased (0.514544 --> 0.513903).  Saving model ...
	 Train_Loss: 0.5305 Train_Acc: 77.343 Val_Loss: 0.5139  BEST VAL Loss: 0.5139  Val_Acc: 78.107

Epoch 80: Validation loss decreased (0.513903 --> 0.513171).  Saving model ...
	 Train_Loss: 0.5296 Train_Acc: 77.387 Val_Loss: 0.5132  BEST VAL Loss: 0.5132  Val_Acc: 78.295

Epoch 81: Validation loss decreased (0.513171 --> 0.512516).  Saving model ...
	 Train_Loss: 0.5289 Train_Acc: 77.396 Val_Loss: 0.5125  BEST VAL Loss: 0.5125  Val_Acc: 77.825

Epoch 82: Validation loss decreased (0.512516 --> 0.511849).  Saving model ...
	 Train_Loss: 0.5281 Train_Acc: 77.481 Val_Loss: 0.5118  BEST VAL Loss: 0.5118  Val_Acc: 78.389

Epoch 83: Validation loss decreased (0.511849 --> 0.511215).  Saving model ...
	 Train_Loss: 0.5273 Train_Acc: 77.316 Val_Loss: 0.5112  BEST VAL Loss: 0.5112  Val_Acc: 78.013

Epoch 84: Validation loss decreased (0.511215 --> 0.510625).  Saving model ...
	 Train_Loss: 0.5265 Train_Acc: 77.431 Val_Loss: 0.5106  BEST VAL Loss: 0.5106  Val_Acc: 78.201

Epoch 85: Validation loss decreased (0.510625 --> 0.510017).  Saving model ...
	 Train_Loss: 0.5258 Train_Acc: 77.378 Val_Loss: 0.5100  BEST VAL Loss: 0.5100  Val_Acc: 77.613

Epoch 86: Validation loss decreased (0.510017 --> 0.509437).  Saving model ...
	 Train_Loss: 0.5251 Train_Acc: 77.487 Val_Loss: 0.5094  BEST VAL Loss: 0.5094  Val_Acc: 78.154

Epoch 87: Validation loss decreased (0.509437 --> 0.508863).  Saving model ...
	 Train_Loss: 0.5243 Train_Acc: 77.807 Val_Loss: 0.5089  BEST VAL Loss: 0.5089  Val_Acc: 78.647

Epoch 88: Validation loss decreased (0.508863 --> 0.508290).  Saving model ...
	 Train_Loss: 0.5235 Train_Acc: 77.698 Val_Loss: 0.5083  BEST VAL Loss: 0.5083  Val_Acc: 78.130

Epoch 89: Validation loss decreased (0.508290 --> 0.507760).  Saving model ...
	 Train_Loss: 0.5227 Train_Acc: 77.910 Val_Loss: 0.5078  BEST VAL Loss: 0.5078  Val_Acc: 78.459

Epoch 90: Validation loss decreased (0.507760 --> 0.507196).  Saving model ...
	 Train_Loss: 0.5220 Train_Acc: 77.780 Val_Loss: 0.5072  BEST VAL Loss: 0.5072  Val_Acc: 78.788

Epoch 91: Validation loss decreased (0.507196 --> 0.506633).  Saving model ...
	 Train_Loss: 0.5213 Train_Acc: 77.995 Val_Loss: 0.5066  BEST VAL Loss: 0.5066  Val_Acc: 78.506

Epoch 92: Validation loss decreased (0.506633 --> 0.506101).  Saving model ...
	 Train_Loss: 0.5205 Train_Acc: 78.004 Val_Loss: 0.5061  BEST VAL Loss: 0.5061  Val_Acc: 78.318

Epoch 93: Validation loss decreased (0.506101 --> 0.505558).  Saving model ...
	 Train_Loss: 0.5198 Train_Acc: 78.036 Val_Loss: 0.5056  BEST VAL Loss: 0.5056  Val_Acc: 78.295

Epoch 94: Validation loss decreased (0.505558 --> 0.505032).  Saving model ...
	 Train_Loss: 0.5192 Train_Acc: 77.719 Val_Loss: 0.5050  BEST VAL Loss: 0.5050  Val_Acc: 77.989

Epoch 95: Validation loss decreased (0.505032 --> 0.504565).  Saving model ...
	 Train_Loss: 0.5185 Train_Acc: 77.634 Val_Loss: 0.5046  BEST VAL Loss: 0.5046  Val_Acc: 78.248

Epoch 96: Validation loss decreased (0.504565 --> 0.504076).  Saving model ...
	 Train_Loss: 0.5178 Train_Acc: 77.880 Val_Loss: 0.5041  BEST VAL Loss: 0.5041  Val_Acc: 77.989

Epoch 97: Validation loss decreased (0.504076 --> 0.503612).  Saving model ...
	 Train_Loss: 0.5171 Train_Acc: 78.036 Val_Loss: 0.5036  BEST VAL Loss: 0.5036  Val_Acc: 78.271

Epoch 98: Validation loss decreased (0.503612 --> 0.503168).  Saving model ...
	 Train_Loss: 0.5165 Train_Acc: 77.951 Val_Loss: 0.5032  BEST VAL Loss: 0.5032  Val_Acc: 78.694

Epoch 99: Validation loss decreased (0.503168 --> 0.502731).  Saving model ...
	 Train_Loss: 0.5158 Train_Acc: 78.156 Val_Loss: 0.5027  BEST VAL Loss: 0.5027  Val_Acc: 78.201

Flagellin_0.100_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.84      0.93      0.89     24644
           1       0.76      0.54      0.63      9407

    accuracy                           0.83     34051
   macro avg       0.80      0.74      0.76     34051
weighted avg       0.82      0.83      0.82     34051

Flagellin_0.100_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.81      0.91      0.86      3081
           1       0.65      0.46      0.54      1176

    accuracy                           0.78      4257
   macro avg       0.73      0.68      0.70      4257
weighted avg       0.77      0.78      0.77      4257

Flagellin_0.100_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.82      0.91      0.86      3081
           1       0.66      0.46      0.54      1176

    accuracy                           0.79      4257
   macro avg       0.74      0.69      0.70      4257
weighted avg       0.77      0.79      0.77      4257

              precision    recall  f1-score   support

           0       0.82      0.91      0.86      3081
           1       0.66      0.46      0.54      1176

    accuracy                           0.79      4257
   macro avg       0.74      0.69      0.70      4257
weighted avg       0.77      0.79      0.77      4257

Flagellin_0.100_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.73      0.89      0.80      4837
           1       0.75      0.50      0.60      3169

    accuracy                           0.74      8006
   macro avg       0.74      0.70      0.70      8006
weighted avg       0.74      0.74      0.73      8006

              precision    recall  f1-score   support

           0       0.73      0.89      0.80      4837
           1       0.75      0.50      0.60      3169

    accuracy                           0.74      8006
   macro avg       0.74      0.70      0.70      8006
weighted avg       0.74      0.74      0.73      8006

completed
