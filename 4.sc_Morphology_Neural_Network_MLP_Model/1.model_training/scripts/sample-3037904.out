[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '24b7abf4'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '97a23c2d'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '39523059'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '3ed9f6b7'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_1.000_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_1.000_DMSO_0.025
TREATMENT_NAME: Flagellin_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (32267, 1276)
Number of total missing values across all columns: 64534
Data Subset Is Off
Wells held out for testing: ['D21' 'M22']
Wells to use for training, validation, and testing ['D16' 'D17' 'D20' 'M18' 'M19' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.687550).  Saving model ...
	 Train_Loss: 0.6910 Train_Acc: 53.671 Val_Loss: 0.6876  BEST VAL Loss: 0.6876  Val_Acc: 55.364

Epoch 1: Validation loss decreased (0.687550 --> 0.684327).  Saving model ...
	 Train_Loss: 0.6874 Train_Acc: 55.855 Val_Loss: 0.6843  BEST VAL Loss: 0.6843  Val_Acc: 56.309

Epoch 2: Validation loss decreased (0.684327 --> 0.681876).  Saving model ...
	 Train_Loss: 0.6851 Train_Acc: 57.315 Val_Loss: 0.6819  BEST VAL Loss: 0.6819  Val_Acc: 56.967

Epoch 3: Validation loss decreased (0.681876 --> 0.677878).  Saving model ...
	 Train_Loss: 0.6822 Train_Acc: 58.553 Val_Loss: 0.6779  BEST VAL Loss: 0.6779  Val_Acc: 60.830

Epoch 4: Validation loss decreased (0.677878 --> 0.673946).  Saving model ...
	 Train_Loss: 0.6785 Train_Acc: 60.305 Val_Loss: 0.6739  BEST VAL Loss: 0.6739  Val_Acc: 60.912

Epoch 5: Validation loss decreased (0.673946 --> 0.671700).  Saving model ...
	 Train_Loss: 0.6748 Train_Acc: 61.492 Val_Loss: 0.6717  BEST VAL Loss: 0.6717  Val_Acc: 61.200

Epoch 6: Validation loss decreased (0.671700 --> 0.667324).  Saving model ...
	 Train_Loss: 0.6709 Train_Acc: 63.306 Val_Loss: 0.6673  BEST VAL Loss: 0.6673  Val_Acc: 64.118

Epoch 7: Validation loss decreased (0.667324 --> 0.663584).  Saving model ...
	 Train_Loss: 0.6667 Train_Acc: 65.135 Val_Loss: 0.6636  BEST VAL Loss: 0.6636  Val_Acc: 64.982

Epoch 8: Validation loss decreased (0.663584 --> 0.660501).  Saving model ...
	 Train_Loss: 0.6632 Train_Acc: 65.058 Val_Loss: 0.6605  BEST VAL Loss: 0.6605  Val_Acc: 64.283

Epoch 9: Validation loss decreased (0.660501 --> 0.656371).  Saving model ...
	 Train_Loss: 0.6595 Train_Acc: 65.588 Val_Loss: 0.6564  BEST VAL Loss: 0.6564  Val_Acc: 66.132

Epoch 10: Validation loss decreased (0.656371 --> 0.651574).  Saving model ...
	 Train_Loss: 0.6551 Train_Acc: 67.175 Val_Loss: 0.6516  BEST VAL Loss: 0.6516  Val_Acc: 69.133

Epoch 11: Validation loss decreased (0.651574 --> 0.647814).  Saving model ...
	 Train_Loss: 0.6512 Train_Acc: 67.715 Val_Loss: 0.6478  BEST VAL Loss: 0.6478  Val_Acc: 68.516

Epoch 12: Validation loss decreased (0.647814 --> 0.644328).  Saving model ...
	 Train_Loss: 0.6473 Train_Acc: 68.337 Val_Loss: 0.6443  BEST VAL Loss: 0.6443  Val_Acc: 68.311

Epoch 13: Validation loss decreased (0.644328 --> 0.641302).  Saving model ...
	 Train_Loss: 0.6434 Train_Acc: 69.251 Val_Loss: 0.6413  BEST VAL Loss: 0.6413  Val_Acc: 69.338

Epoch 14: Validation loss decreased (0.641302 --> 0.637590).  Saving model ...
	 Train_Loss: 0.6398 Train_Acc: 69.647 Val_Loss: 0.6376  BEST VAL Loss: 0.6376  Val_Acc: 69.790

Epoch 15: Validation loss decreased (0.637590 --> 0.634579).  Saving model ...
	 Train_Loss: 0.6365 Train_Acc: 69.986 Val_Loss: 0.6346  BEST VAL Loss: 0.6346  Val_Acc: 70.201

Epoch 16: Validation loss decreased (0.634579 --> 0.631548).  Saving model ...
	 Train_Loss: 0.6336 Train_Acc: 70.012 Val_Loss: 0.6315  BEST VAL Loss: 0.6315  Val_Acc: 70.571

Epoch 17: Validation loss decreased (0.631548 --> 0.628698).  Saving model ...
	 Train_Loss: 0.6305 Train_Acc: 71.060 Val_Loss: 0.6287  BEST VAL Loss: 0.6287  Val_Acc: 70.941

Epoch 18: Validation loss decreased (0.628698 --> 0.625670).  Saving model ...
	 Train_Loss: 0.6275 Train_Acc: 71.343 Val_Loss: 0.6257  BEST VAL Loss: 0.6257  Val_Acc: 71.845

Epoch 19: Validation loss decreased (0.625670 --> 0.622616).  Saving model ...
	 Train_Loss: 0.6248 Train_Acc: 71.332 Val_Loss: 0.6226  BEST VAL Loss: 0.6226  Val_Acc: 71.434

Epoch 20: Validation loss decreased (0.622616 --> 0.620120).  Saving model ...
	 Train_Loss: 0.6220 Train_Acc: 72.237 Val_Loss: 0.6201  BEST VAL Loss: 0.6201  Val_Acc: 70.366

Epoch 21: Validation loss decreased (0.620120 --> 0.617860).  Saving model ...
	 Train_Loss: 0.6195 Train_Acc: 71.790 Val_Loss: 0.6179  BEST VAL Loss: 0.6179  Val_Acc: 71.804

Epoch 22: Validation loss decreased (0.617860 --> 0.615632).  Saving model ...
	 Train_Loss: 0.6169 Train_Acc: 72.478 Val_Loss: 0.6156  BEST VAL Loss: 0.6156  Val_Acc: 71.434

Epoch 23: Validation loss decreased (0.615632 --> 0.613245).  Saving model ...
	 Train_Loss: 0.6142 Train_Acc: 73.064 Val_Loss: 0.6132  BEST VAL Loss: 0.6132  Val_Acc: 71.270

Epoch 24: Validation loss decreased (0.613245 --> 0.611247).  Saving model ...
	 Train_Loss: 0.6121 Train_Acc: 72.571 Val_Loss: 0.6112  BEST VAL Loss: 0.6112  Val_Acc: 71.106

Epoch 25: Validation loss decreased (0.611247 --> 0.609424).  Saving model ...
	 Train_Loss: 0.6098 Train_Acc: 73.049 Val_Loss: 0.6094  BEST VAL Loss: 0.6094  Val_Acc: 72.544

Epoch 26: Validation loss decreased (0.609424 --> 0.607567).  Saving model ...
	 Train_Loss: 0.6074 Train_Acc: 73.799 Val_Loss: 0.6076  BEST VAL Loss: 0.6076  Val_Acc: 72.544

Epoch 27: Validation loss decreased (0.607567 --> 0.605503).  Saving model ...
	 Train_Loss: 0.6052 Train_Acc: 73.521 Val_Loss: 0.6055  BEST VAL Loss: 0.6055  Val_Acc: 72.709

Epoch 28: Validation loss decreased (0.605503 --> 0.603595).  Saving model ...
	 Train_Loss: 0.6030 Train_Acc: 74.133 Val_Loss: 0.6036  BEST VAL Loss: 0.6036  Val_Acc: 72.462

Epoch 29: Validation loss decreased (0.603595 --> 0.601777).  Saving model ...
	 Train_Loss: 0.6011 Train_Acc: 73.989 Val_Loss: 0.6018  BEST VAL Loss: 0.6018  Val_Acc: 72.051

Epoch 30: Validation loss decreased (0.601777 --> 0.599908).  Saving model ...
	 Train_Loss: 0.5991 Train_Acc: 74.117 Val_Loss: 0.5999  BEST VAL Loss: 0.5999  Val_Acc: 72.955

Epoch 31: Validation loss decreased (0.599908 --> 0.598593).  Saving model ...
	 Train_Loss: 0.5970 Train_Acc: 74.878 Val_Loss: 0.5986  BEST VAL Loss: 0.5986  Val_Acc: 71.763

Epoch 32: Validation loss decreased (0.598593 --> 0.597136).  Saving model ...
	 Train_Loss: 0.5950 Train_Acc: 74.832 Val_Loss: 0.5971  BEST VAL Loss: 0.5971  Val_Acc: 73.695

Epoch 33: Validation loss decreased (0.597136 --> 0.595604).  Saving model ...
	 Train_Loss: 0.5932 Train_Acc: 74.462 Val_Loss: 0.5956  BEST VAL Loss: 0.5956  Val_Acc: 73.407

Epoch 34: Validation loss decreased (0.595604 --> 0.594471).  Saving model ...
	 Train_Loss: 0.5916 Train_Acc: 74.318 Val_Loss: 0.5945  BEST VAL Loss: 0.5945  Val_Acc: 73.490

Epoch 35: Validation loss decreased (0.594471 --> 0.593389).  Saving model ...
	 Train_Loss: 0.5898 Train_Acc: 74.955 Val_Loss: 0.5934  BEST VAL Loss: 0.5934  Val_Acc: 72.626

Epoch 36: Validation loss decreased (0.593389 --> 0.592334).  Saving model ...
	 Train_Loss: 0.5882 Train_Acc: 74.780 Val_Loss: 0.5923  BEST VAL Loss: 0.5923  Val_Acc: 72.914

Epoch 37: Validation loss decreased (0.592334 --> 0.591428).  Saving model ...
	 Train_Loss: 0.5865 Train_Acc: 75.438 Val_Loss: 0.5914  BEST VAL Loss: 0.5914  Val_Acc: 72.544

Epoch 38: Validation loss decreased (0.591428 --> 0.590335).  Saving model ...
	 Train_Loss: 0.5849 Train_Acc: 75.145 Val_Loss: 0.5903  BEST VAL Loss: 0.5903  Val_Acc: 72.503

Epoch 39: Validation loss decreased (0.590335 --> 0.589235).  Saving model ...
	 Train_Loss: 0.5833 Train_Acc: 76.003 Val_Loss: 0.5892  BEST VAL Loss: 0.5892  Val_Acc: 73.202

Epoch 40: Validation loss decreased (0.589235 --> 0.588419).  Saving model ...
	 Train_Loss: 0.5818 Train_Acc: 75.150 Val_Loss: 0.5884  BEST VAL Loss: 0.5884  Val_Acc: 72.791

Epoch 41: Validation loss decreased (0.588419 --> 0.587687).  Saving model ...
	 Train_Loss: 0.5801 Train_Acc: 76.152 Val_Loss: 0.5877  BEST VAL Loss: 0.5877  Val_Acc: 72.585

Epoch 42: Validation loss decreased (0.587687 --> 0.586871).  Saving model ...
	 Train_Loss: 0.5787 Train_Acc: 75.654 Val_Loss: 0.5869  BEST VAL Loss: 0.5869  Val_Acc: 73.613

Epoch 43: Validation loss decreased (0.586871 --> 0.586046).  Saving model ...
	 Train_Loss: 0.5774 Train_Acc: 75.510 Val_Loss: 0.5860  BEST VAL Loss: 0.5860  Val_Acc: 72.709

Epoch 44: Validation loss decreased (0.586046 --> 0.585248).  Saving model ...
	 Train_Loss: 0.5760 Train_Acc: 75.890 Val_Loss: 0.5852  BEST VAL Loss: 0.5852  Val_Acc: 72.709

Epoch 45: Validation loss decreased (0.585248 --> 0.584548).  Saving model ...
	 Train_Loss: 0.5749 Train_Acc: 75.258 Val_Loss: 0.5845  BEST VAL Loss: 0.5845  Val_Acc: 73.284

Epoch 46: Validation loss decreased (0.584548 --> 0.583818).  Saving model ...
	 Train_Loss: 0.5737 Train_Acc: 75.916 Val_Loss: 0.5838  BEST VAL Loss: 0.5838  Val_Acc: 72.626

Epoch 47: Validation loss decreased (0.583818 --> 0.583473).  Saving model ...
	 Train_Loss: 0.5724 Train_Acc: 76.008 Val_Loss: 0.5835  BEST VAL Loss: 0.5835  Val_Acc: 73.859

Epoch 48: Validation loss decreased (0.583473 --> 0.583098).  Saving model ...
	 Train_Loss: 0.5711 Train_Acc: 76.651 Val_Loss: 0.5831  BEST VAL Loss: 0.5831  Val_Acc: 72.421

Epoch 49: Validation loss decreased (0.583098 --> 0.582569).  Saving model ...
	 Train_Loss: 0.5699 Train_Acc: 76.245 Val_Loss: 0.5826  BEST VAL Loss: 0.5826  Val_Acc: 73.366

Epoch 50: Validation loss decreased (0.582569 --> 0.582010).  Saving model ...
	 Train_Loss: 0.5687 Train_Acc: 75.921 Val_Loss: 0.5820  BEST VAL Loss: 0.5820  Val_Acc: 73.695

Epoch 51: Validation loss decreased (0.582010 --> 0.581423).  Saving model ...
	 Train_Loss: 0.5676 Train_Acc: 76.450 Val_Loss: 0.5814  BEST VAL Loss: 0.5814  Val_Acc: 73.777

Epoch 52: Validation loss decreased (0.581423 --> 0.580942).  Saving model ...
	 Train_Loss: 0.5665 Train_Acc: 76.255 Val_Loss: 0.5809  BEST VAL Loss: 0.5809  Val_Acc: 72.832

Epoch 53: Validation loss decreased (0.580942 --> 0.580804).  Saving model ...
	 Train_Loss: 0.5652 Train_Acc: 76.995 Val_Loss: 0.5808  BEST VAL Loss: 0.5808  Val_Acc: 73.202

Epoch 54: Validation loss decreased (0.580804 --> 0.580199).  Saving model ...
	 Train_Loss: 0.5641 Train_Acc: 76.702 Val_Loss: 0.5802  BEST VAL Loss: 0.5802  Val_Acc: 72.544

Epoch 55: Validation loss decreased (0.580199 --> 0.579946).  Saving model ...
	 Train_Loss: 0.5632 Train_Acc: 76.378 Val_Loss: 0.5799  BEST VAL Loss: 0.5799  Val_Acc: 73.161

Epoch 56: Validation loss decreased (0.579946 --> 0.579784).  Saving model ...
	 Train_Loss: 0.5621 Train_Acc: 76.702 Val_Loss: 0.5798  BEST VAL Loss: 0.5798  Val_Acc: 73.407

Epoch 57: Validation loss decreased (0.579784 --> 0.579504).  Saving model ...
	 Train_Loss: 0.5611 Train_Acc: 76.861 Val_Loss: 0.5795  BEST VAL Loss: 0.5795  Val_Acc: 72.914

Epoch 58: Validation loss decreased (0.579504 --> 0.578937).  Saving model ...
	 Train_Loss: 0.5600 Train_Acc: 77.165 Val_Loss: 0.5789  BEST VAL Loss: 0.5789  Val_Acc: 73.366

Epoch 59: Validation loss decreased (0.578937 --> 0.578734).  Saving model ...
	 Train_Loss: 0.5590 Train_Acc: 76.877 Val_Loss: 0.5787  BEST VAL Loss: 0.5787  Val_Acc: 72.544

Epoch 60: Validation loss decreased (0.578734 --> 0.578575).  Saving model ...
	 Train_Loss: 0.5580 Train_Acc: 77.036 Val_Loss: 0.5786  BEST VAL Loss: 0.5786  Val_Acc: 73.325

Epoch 61: Validation loss decreased (0.578575 --> 0.578496).  Saving model ...
	 Train_Loss: 0.5570 Train_Acc: 76.743 Val_Loss: 0.5785  BEST VAL Loss: 0.5785  Val_Acc: 72.051

Epoch 62: Validation loss decreased (0.578496 --> 0.578167).  Saving model ...
	 Train_Loss: 0.5562 Train_Acc: 76.723 Val_Loss: 0.5782  BEST VAL Loss: 0.5782  Val_Acc: 72.914

Epoch 63: Validation loss decreased (0.578167 --> 0.577929).  Saving model ...
	 Train_Loss: 0.5553 Train_Acc: 76.558 Val_Loss: 0.5779  BEST VAL Loss: 0.5779  Val_Acc: 72.667

Epoch 64: Validation loss decreased (0.577929 --> 0.577627).  Saving model ...
	 Train_Loss: 0.5545 Train_Acc: 77.144 Val_Loss: 0.5776  BEST VAL Loss: 0.5776  Val_Acc: 73.037

Epoch 65: Validation loss decreased (0.577627 --> 0.577418).  Saving model ...
	 Train_Loss: 0.5536 Train_Acc: 77.159 Val_Loss: 0.5774  BEST VAL Loss: 0.5774  Val_Acc: 72.544

Epoch 66: Validation loss decreased (0.577418 --> 0.577313).  Saving model ...
	 Train_Loss: 0.5527 Train_Acc: 77.535 Val_Loss: 0.5773  BEST VAL Loss: 0.5773  Val_Acc: 72.914

Epoch 67: Validation loss decreased (0.577313 --> 0.577033).  Saving model ...
	 Train_Loss: 0.5518 Train_Acc: 77.308 Val_Loss: 0.5770  BEST VAL Loss: 0.5770  Val_Acc: 72.873

Epoch 68: Validation loss decreased (0.577033 --> 0.576831).  Saving model ...
	 Train_Loss: 0.5510 Train_Acc: 77.067 Val_Loss: 0.5768  BEST VAL Loss: 0.5768  Val_Acc: 73.120

Epoch 69: Validation loss decreased (0.576831 --> 0.576616).  Saving model ...
	 Train_Loss: 0.5501 Train_Acc: 77.982 Val_Loss: 0.5766  BEST VAL Loss: 0.5766  Val_Acc: 73.161

Epoch 70: Validation loss decreased (0.576616 --> 0.576362).  Saving model ...
	 Train_Loss: 0.5493 Train_Acc: 77.422 Val_Loss: 0.5764  BEST VAL Loss: 0.5764  Val_Acc: 73.654

Epoch 71: Validation loss decreased (0.576362 --> 0.576199).  Saving model ...
	 Train_Loss: 0.5485 Train_Acc: 77.617 Val_Loss: 0.5762  BEST VAL Loss: 0.5762  Val_Acc: 73.284

Epoch 72: Validation loss decreased (0.576199 --> 0.575958).  Saving model ...
	 Train_Loss: 0.5476 Train_Acc: 77.848 Val_Loss: 0.5760  BEST VAL Loss: 0.5760  Val_Acc: 73.448

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.5468 Train_Acc: 78.213 Val_Loss: 0.5760  BEST VAL Loss: 0.5760  Val_Acc: 74.394

Epoch 74: Validation loss decreased (0.575958 --> 0.575693).  Saving model ...
	 Train_Loss: 0.5459 Train_Acc: 78.434 Val_Loss: 0.5757  BEST VAL Loss: 0.5757  Val_Acc: 73.448

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.5450 Train_Acc: 78.490 Val_Loss: 0.5758  BEST VAL Loss: 0.5757  Val_Acc: 73.572

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.5441 Train_Acc: 78.336 Val_Loss: 0.5758  BEST VAL Loss: 0.5757  Val_Acc: 73.572

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.5433 Train_Acc: 78.547 Val_Loss: 0.5759  BEST VAL Loss: 0.5757  Val_Acc: 73.243

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.5425 Train_Acc: 77.982 Val_Loss: 0.5759  BEST VAL Loss: 0.5757  Val_Acc: 73.613

Epoch 79: Validation loss decreased (0.575693 --> 0.575681).  Saving model ...
	 Train_Loss: 0.5418 Train_Acc: 78.197 Val_Loss: 0.5757  BEST VAL Loss: 0.5757  Val_Acc: 74.270

Epoch 80: Validation loss decreased (0.575681 --> 0.575668).  Saving model ...
	 Train_Loss: 0.5411 Train_Acc: 78.156 Val_Loss: 0.5757  BEST VAL Loss: 0.5757  Val_Acc: 73.613

Epoch 81: Validation loss decreased (0.575668 --> 0.575467).  Saving model ...
	 Train_Loss: 0.5403 Train_Acc: 78.573 Val_Loss: 0.5755  BEST VAL Loss: 0.5755  Val_Acc: 74.024

Epoch 82: Validation loss decreased (0.575467 --> 0.575377).  Saving model ...
	 Train_Loss: 0.5396 Train_Acc: 78.187 Val_Loss: 0.5754  BEST VAL Loss: 0.5754  Val_Acc: 73.777

Epoch 83: Validation loss decreased (0.575377 --> 0.575321).  Saving model ...
	 Train_Loss: 0.5388 Train_Acc: 78.352 Val_Loss: 0.5753  BEST VAL Loss: 0.5753  Val_Acc: 73.079

Epoch 84: Validation loss decreased (0.575321 --> 0.575258).  Saving model ...
	 Train_Loss: 0.5381 Train_Acc: 78.434 Val_Loss: 0.5753  BEST VAL Loss: 0.5753  Val_Acc: 73.407

Epoch 85: Validation loss decreased (0.575258 --> 0.575190).  Saving model ...
	 Train_Loss: 0.5374 Train_Acc: 78.254 Val_Loss: 0.5752  BEST VAL Loss: 0.5752  Val_Acc: 73.407

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.5367 Train_Acc: 78.624 Val_Loss: 0.5753  BEST VAL Loss: 0.5752  Val_Acc: 73.983

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.5361 Train_Acc: 77.905 Val_Loss: 0.5752  BEST VAL Loss: 0.5752  Val_Acc: 73.407

Epoch 88: Validation loss decreased (0.575190 --> 0.575094).  Saving model ...
	 Train_Loss: 0.5355 Train_Acc: 77.791 Val_Loss: 0.5751  BEST VAL Loss: 0.5751  Val_Acc: 74.188

Epoch 89: Validation loss decreased (0.575094 --> 0.574840).  Saving model ...
	 Train_Loss: 0.5349 Train_Acc: 78.424 Val_Loss: 0.5748  BEST VAL Loss: 0.5748  Val_Acc: 74.312

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.5342 Train_Acc: 78.573 Val_Loss: 0.5749  BEST VAL Loss: 0.5748  Val_Acc: 73.736

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.5336 Train_Acc: 78.763 Val_Loss: 0.5749  BEST VAL Loss: 0.5748  Val_Acc: 74.435

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.5329 Train_Acc: 78.629 Val_Loss: 0.5749  BEST VAL Loss: 0.5748  Val_Acc: 74.681

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.5323 Train_Acc: 78.732 Val_Loss: 0.5750  BEST VAL Loss: 0.5748  Val_Acc: 72.750

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.5316 Train_Acc: 78.958 Val_Loss: 0.5751  BEST VAL Loss: 0.5748  Val_Acc: 73.572

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.5310 Train_Acc: 79.143 Val_Loss: 0.5752  BEST VAL Loss: 0.5748  Val_Acc: 73.490

Epoch 96: Validation loss did not decrease
	 Train_Loss: 0.5304 Train_Acc: 79.174 Val_Loss: 0.5754  BEST VAL Loss: 0.5748  Val_Acc: 73.695

Epoch 97: Validation loss did not decrease
	 Train_Loss: 0.5298 Train_Acc: 78.583 Val_Loss: 0.5755  BEST VAL Loss: 0.5748  Val_Acc: 73.243

Epoch 98: Validation loss did not decrease
	 Train_Loss: 0.5291 Train_Acc: 79.374 Val_Loss: 0.5756  BEST VAL Loss: 0.5748  Val_Acc: 73.120

Epoch 99: Validation loss did not decrease
	 Train_Loss: 0.5285 Train_Acc: 78.711 Val_Loss: 0.5757  BEST VAL Loss: 0.5748  Val_Acc: 74.065

LPS_1.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.39      0.43      9434
           1       0.51      0.61      0.56     10027

    accuracy                           0.50     19461
   macro avg       0.50      0.50      0.49     19461
weighted avg       0.50      0.50      0.50     19461

LPS_1.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.39      0.43      1179
           1       0.52      0.62      0.57      1254

    accuracy                           0.51      2433
   macro avg       0.51      0.51      0.50      2433
weighted avg       0.51      0.51      0.50      2433

LPS_1.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.39      0.43      1179
           1       0.52      0.63      0.57      1254

    accuracy                           0.51      2433
   macro avg       0.51      0.51      0.50      2433
weighted avg       0.51      0.51      0.50      2433

              precision    recall  f1-score   support

           0       0.49      0.39      0.43      1179
           1       0.52      0.63      0.57      1254

    accuracy                           0.51      2433
   macro avg       0.51      0.51      0.50      2433
weighted avg       0.51      0.51      0.50      2433

LPS_1.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.33      0.40      4017
           1       0.49      0.65      0.56      3923

    accuracy                           0.49      7940
   macro avg       0.49      0.49      0.48      7940
weighted avg       0.49      0.49      0.47      7940

              precision    recall  f1-score   support

           0       0.49      0.33      0.40      4017
           1       0.49      0.65      0.56      3923

    accuracy                           0.49      7940
   macro avg       0.49      0.49      0.48      7940
weighted avg       0.49      0.49      0.47      7940

completed
