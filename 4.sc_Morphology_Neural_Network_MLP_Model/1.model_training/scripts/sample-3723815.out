[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 18688 bytes to train_binary_model.py
[NbConvertApp] Converting notebook ../notebooks/train_multiclass_model.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: MissingIDFieldWarning: Code cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.
  validate(nb)
[NbConvertApp] Writing 31143 bytes to train_multiclass_model.py
[NbConvertApp] Converting notebook ../notebooks/train_regression_model.ipynb to script
[NbConvertApp] Writing 25120 bytes to train_regression_model.py
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:314: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels.drop_duplicates(inplace=True)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1015: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1016: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1015: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1016: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1036: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:578: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:652: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1219: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:880: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1219: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:1096: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
PBMC MultiClass_MLP_h202_remove True
[0.9436581681188537, 0.5245113046249099, 0.5318305272562364]
Data Subset Is Off
(1417094,) (354274,) (2112741,) (1474037,)
(1417094,) (354274,) (2112741,) (1474037,)
5358146
(95929,) (683836,) (637329,)
(23982,) (170959,) (159333,)
(119910,) (854797,) (1138034,)
(75619,) (711982,) (686436,)
(1417094, 1245) (354274, 1245) (2112741, 1245) (1474037, 1245)
(1417094,) (354274,) (2112741,) (1474037,)
Number of in features:  1245
Number of out features:  3
Multi_Class
Adam
Epoch 0: Validation loss decreased (inf --> 0.637462).  Saving model ...
	 Train_Loss: 0.7113 Train_Acc: 70.060 Val_Loss: 0.6375  BEST VAL Loss: 0.6375  Val_Acc: 73.474

Epoch 1: Validation loss decreased (0.637462 --> 0.624032).  Saving model ...
	 Train_Loss: 0.6862 Train_Acc: 72.456 Val_Loss: 0.6240  BEST VAL Loss: 0.6240  Val_Acc: 75.250

Epoch 2: Validation loss decreased (0.624032 --> 0.613295).  Saving model ...
	 Train_Loss: 0.6712 Train_Acc: 73.363 Val_Loss: 0.6133  BEST VAL Loss: 0.6133  Val_Acc: 76.098

Epoch 3: Validation loss decreased (0.613295 --> 0.603638).  Saving model ...
	 Train_Loss: 0.6606 Train_Acc: 73.965 Val_Loss: 0.6036  BEST VAL Loss: 0.6036  Val_Acc: 76.755

Epoch 4: Validation loss decreased (0.603638 --> 0.597130).  Saving model ...
	 Train_Loss: 0.6523 Train_Acc: 74.389 Val_Loss: 0.5971  BEST VAL Loss: 0.5971  Val_Acc: 77.039

Epoch 5: Validation loss decreased (0.597130 --> 0.591537).  Saving model ...
	 Train_Loss: 0.6455 Train_Acc: 74.763 Val_Loss: 0.5915  BEST VAL Loss: 0.5915  Val_Acc: 76.958

Epoch 6: Validation loss decreased (0.591537 --> 0.586138).  Saving model ...
	 Train_Loss: 0.6398 Train_Acc: 75.029 Val_Loss: 0.5861  BEST VAL Loss: 0.5861  Val_Acc: 77.623

Epoch 7: Validation loss decreased (0.586138 --> 0.582031).  Saving model ...
	 Train_Loss: 0.6349 Train_Acc: 75.215 Val_Loss: 0.5820  BEST VAL Loss: 0.5820  Val_Acc: 77.660

Epoch 8: Validation loss decreased (0.582031 --> 0.578069).  Saving model ...
	 Train_Loss: 0.6307 Train_Acc: 75.370 Val_Loss: 0.5781  BEST VAL Loss: 0.5781  Val_Acc: 77.912

Epoch 9: Validation loss decreased (0.578069 --> 0.575089).  Saving model ...
	 Train_Loss: 0.6270 Train_Acc: 75.511 Val_Loss: 0.5751  BEST VAL Loss: 0.5751  Val_Acc: 77.738

Epoch 10: Validation loss decreased (0.575089 --> 0.571908).  Saving model ...
	 Train_Loss: 0.6238 Train_Acc: 75.620 Val_Loss: 0.5719  BEST VAL Loss: 0.5719  Val_Acc: 78.548

Epoch 11: Validation loss decreased (0.571908 --> 0.569260).  Saving model ...
	 Train_Loss: 0.6208 Train_Acc: 75.770 Val_Loss: 0.5693  BEST VAL Loss: 0.5693  Val_Acc: 78.461

Epoch 12: Validation loss decreased (0.569260 --> 0.566845).  Saving model ...
	 Train_Loss: 0.6182 Train_Acc: 75.839 Val_Loss: 0.5668  BEST VAL Loss: 0.5668  Val_Acc: 78.612

Epoch 13: Validation loss decreased (0.566845 --> 0.564809).  Saving model ...
	 Train_Loss: 0.6157 Train_Acc: 75.964 Val_Loss: 0.5648  BEST VAL Loss: 0.5648  Val_Acc: 78.812

Epoch 14: Validation loss decreased (0.564809 --> 0.562303).  Saving model ...
	 Train_Loss: 0.6134 Train_Acc: 76.016 Val_Loss: 0.5623  BEST VAL Loss: 0.5623  Val_Acc: 78.936

Epoch 15: Validation loss decreased (0.562303 --> 0.560085).  Saving model ...
	 Train_Loss: 0.6114 Train_Acc: 76.131 Val_Loss: 0.5601  BEST VAL Loss: 0.5601  Val_Acc: 78.800

Epoch 16: Validation loss decreased (0.560085 --> 0.558121).  Saving model ...
	 Train_Loss: 0.6095 Train_Acc: 76.154 Val_Loss: 0.5581  BEST VAL Loss: 0.5581  Val_Acc: 78.856

Epoch 17: Validation loss decreased (0.558121 --> 0.556443).  Saving model ...
	 Train_Loss: 0.6078 Train_Acc: 76.237 Val_Loss: 0.5564  BEST VAL Loss: 0.5564  Val_Acc: 78.928

Epoch 18: Validation loss decreased (0.556443 --> 0.554589).  Saving model ...
	 Train_Loss: 0.6061 Train_Acc: 76.266 Val_Loss: 0.5546  BEST VAL Loss: 0.5546  Val_Acc: 79.138

Epoch 19: Validation loss decreased (0.554589 --> 0.553156).  Saving model ...
	 Train_Loss: 0.6046 Train_Acc: 76.369 Val_Loss: 0.5532  BEST VAL Loss: 0.5532  Val_Acc: 78.843

Epoch 20: Validation loss decreased (0.553156 --> 0.551682).  Saving model ...
	 Train_Loss: 0.6031 Train_Acc: 76.421 Val_Loss: 0.5517  BEST VAL Loss: 0.5517  Val_Acc: 79.091

Epoch 21: Validation loss decreased (0.551682 --> 0.550438).  Saving model ...
	 Train_Loss: 0.6017 Train_Acc: 76.421 Val_Loss: 0.5504  BEST VAL Loss: 0.5504  Val_Acc: 79.118

Epoch 22: Validation loss decreased (0.550438 --> 0.549052).  Saving model ...
	 Train_Loss: 0.6004 Train_Acc: 76.532 Val_Loss: 0.5491  BEST VAL Loss: 0.5491  Val_Acc: 78.968

Epoch 23: Validation loss decreased (0.549052 --> 0.547929).  Saving model ...
	 Train_Loss: 0.5991 Train_Acc: 76.542 Val_Loss: 0.5479  BEST VAL Loss: 0.5479  Val_Acc: 79.204

Epoch 24: Validation loss decreased (0.547929 --> 0.546836).  Saving model ...
	 Train_Loss: 0.5979 Train_Acc: 76.577 Val_Loss: 0.5468  BEST VAL Loss: 0.5468  Val_Acc: 79.246

Epoch 25: Validation loss decreased (0.546836 --> 0.545632).  Saving model ...
	 Train_Loss: 0.5968 Train_Acc: 76.602 Val_Loss: 0.5456  BEST VAL Loss: 0.5456  Val_Acc: 79.393

Epoch 26: Validation loss decreased (0.545632 --> 0.544484).  Saving model ...
	 Train_Loss: 0.5958 Train_Acc: 76.684 Val_Loss: 0.5445  BEST VAL Loss: 0.5445  Val_Acc: 79.477

Epoch 27: Validation loss decreased (0.544484 --> 0.543464).  Saving model ...
	 Train_Loss: 0.5947 Train_Acc: 76.721 Val_Loss: 0.5435  BEST VAL Loss: 0.5435  Val_Acc: 79.274

Epoch 28: Validation loss decreased (0.543464 --> 0.542404).  Saving model ...
	 Train_Loss: 0.5937 Train_Acc: 76.731 Val_Loss: 0.5424  BEST VAL Loss: 0.5424  Val_Acc: 79.449

Epoch 29: Validation loss decreased (0.542404 --> 0.541480).  Saving model ...
	 Train_Loss: 0.5928 Train_Acc: 76.794 Val_Loss: 0.5415  BEST VAL Loss: 0.5415  Val_Acc: 79.613

Epoch 30: Validation loss decreased (0.541480 --> 0.540649).  Saving model ...
	 Train_Loss: 0.5919 Train_Acc: 76.792 Val_Loss: 0.5406  BEST VAL Loss: 0.5406  Val_Acc: 79.417

Epoch 31: Validation loss decreased (0.540649 --> 0.539772).  Saving model ...
	 Train_Loss: 0.5911 Train_Acc: 76.814 Val_Loss: 0.5398  BEST VAL Loss: 0.5398  Val_Acc: 79.442

Epoch 32: Validation loss decreased (0.539772 --> 0.538817).  Saving model ...
	 Train_Loss: 0.5902 Train_Acc: 76.823 Val_Loss: 0.5388  BEST VAL Loss: 0.5388  Val_Acc: 79.584

Epoch 33: Validation loss decreased (0.538817 --> 0.537909).  Saving model ...
	 Train_Loss: 0.5894 Train_Acc: 76.836 Val_Loss: 0.5379  BEST VAL Loss: 0.5379  Val_Acc: 79.830

Epoch 34: Validation loss decreased (0.537909 --> 0.537014).  Saving model ...
	 Train_Loss: 0.5886 Train_Acc: 76.854 Val_Loss: 0.5370  BEST VAL Loss: 0.5370  Val_Acc: 79.628

Epoch 35: Validation loss decreased (0.537014 --> 0.536320).  Saving model ...
	 Train_Loss: 0.5879 Train_Acc: 76.958 Val_Loss: 0.5363  BEST VAL Loss: 0.5363  Val_Acc: 79.704

Epoch 36: Validation loss decreased (0.536320 --> 0.535581).  Saving model ...
	 Train_Loss: 0.5872 Train_Acc: 76.939 Val_Loss: 0.5356  BEST VAL Loss: 0.5356  Val_Acc: 79.801

Epoch 37: Validation loss decreased (0.535581 --> 0.535033).  Saving model ...
	 Train_Loss: 0.5865 Train_Acc: 76.932 Val_Loss: 0.5350  BEST VAL Loss: 0.5350  Val_Acc: 79.522

Epoch 38: Validation loss decreased (0.535033 --> 0.534324).  Saving model ...
	 Train_Loss: 0.5858 Train_Acc: 76.969 Val_Loss: 0.5343  BEST VAL Loss: 0.5343  Val_Acc: 79.509

Epoch 39: Validation loss decreased (0.534324 --> 0.533745).  Saving model ...
	 Train_Loss: 0.5852 Train_Acc: 76.989 Val_Loss: 0.5337  BEST VAL Loss: 0.5337  Val_Acc: 79.740

Epoch 40: Validation loss decreased (0.533745 --> 0.533168).  Saving model ...
	 Train_Loss: 0.5846 Train_Acc: 76.987 Val_Loss: 0.5332  BEST VAL Loss: 0.5332  Val_Acc: 79.769

Epoch 41: Validation loss decreased (0.533168 --> 0.532565).  Saving model ...
	 Train_Loss: 0.5839 Train_Acc: 77.024 Val_Loss: 0.5326  BEST VAL Loss: 0.5326  Val_Acc: 79.592

Epoch 42: Validation loss decreased (0.532565 --> 0.532057).  Saving model ...
	 Train_Loss: 0.5834 Train_Acc: 77.001 Val_Loss: 0.5321  BEST VAL Loss: 0.5321  Val_Acc: 79.798

Epoch 43: Validation loss decreased (0.532057 --> 0.531539).  Saving model ...
	 Train_Loss: 0.5828 Train_Acc: 77.068 Val_Loss: 0.5315  BEST VAL Loss: 0.5315  Val_Acc: 79.730

Epoch 44: Validation loss decreased (0.531539 --> 0.531008).  Saving model ...
	 Train_Loss: 0.5822 Train_Acc: 77.042 Val_Loss: 0.5310  BEST VAL Loss: 0.5310  Val_Acc: 79.602

Epoch 45: Validation loss decreased (0.531008 --> 0.530539).  Saving model ...
	 Train_Loss: 0.5817 Train_Acc: 77.051 Val_Loss: 0.5305  BEST VAL Loss: 0.5305  Val_Acc: 79.857

Epoch 46: Validation loss decreased (0.530539 --> 0.529997).  Saving model ...
	 Train_Loss: 0.5812 Train_Acc: 77.142 Val_Loss: 0.5300  BEST VAL Loss: 0.5300  Val_Acc: 79.849

Epoch 47: Validation loss decreased (0.529997 --> 0.529494).  Saving model ...
	 Train_Loss: 0.5807 Train_Acc: 77.089 Val_Loss: 0.5295  BEST VAL Loss: 0.5295  Val_Acc: 79.762

Epoch 48: Validation loss decreased (0.529494 --> 0.529033).  Saving model ...
	 Train_Loss: 0.5802 Train_Acc: 77.134 Val_Loss: 0.5290  BEST VAL Loss: 0.5290  Val_Acc: 79.800

Epoch 49: Validation loss decreased (0.529033 --> 0.528597).  Saving model ...
	 Train_Loss: 0.5797 Train_Acc: 77.154 Val_Loss: 0.5286  BEST VAL Loss: 0.5286  Val_Acc: 79.851

Epoch 50: Validation loss decreased (0.528597 --> 0.528052).  Saving model ...
	 Train_Loss: 0.5792 Train_Acc: 77.155 Val_Loss: 0.5281  BEST VAL Loss: 0.5281  Val_Acc: 79.881

Epoch 51: Validation loss decreased (0.528052 --> 0.527596).  Saving model ...
	 Train_Loss: 0.5788 Train_Acc: 77.176 Val_Loss: 0.5276  BEST VAL Loss: 0.5276  Val_Acc: 79.995

Epoch 52: Validation loss decreased (0.527596 --> 0.527104).  Saving model ...
	 Train_Loss: 0.5783 Train_Acc: 77.221 Val_Loss: 0.5271  BEST VAL Loss: 0.5271  Val_Acc: 79.980

Epoch 53: Validation loss decreased (0.527104 --> 0.526736).  Saving model ...
	 Train_Loss: 0.5779 Train_Acc: 77.201 Val_Loss: 0.5267  BEST VAL Loss: 0.5267  Val_Acc: 79.993

Epoch 54: Validation loss decreased (0.526736 --> 0.526323).  Saving model ...
	 Train_Loss: 0.5774 Train_Acc: 77.203 Val_Loss: 0.5263  BEST VAL Loss: 0.5263  Val_Acc: 79.826

Epoch 55: Validation loss decreased (0.526323 --> 0.525898).  Saving model ...
	 Train_Loss: 0.5770 Train_Acc: 77.213 Val_Loss: 0.5259  BEST VAL Loss: 0.5259  Val_Acc: 80.111

Epoch 56: Validation loss decreased (0.525898 --> 0.525466).  Saving model ...
	 Train_Loss: 0.5766 Train_Acc: 77.229 Val_Loss: 0.5255  BEST VAL Loss: 0.5255  Val_Acc: 80.051

Epoch 57: Validation loss decreased (0.525466 --> 0.525064).  Saving model ...
	 Train_Loss: 0.5762 Train_Acc: 77.278 Val_Loss: 0.5251  BEST VAL Loss: 0.5251  Val_Acc: 80.143

Epoch 58: Validation loss decreased (0.525064 --> 0.524643).  Saving model ...
	 Train_Loss: 0.5758 Train_Acc: 77.235 Val_Loss: 0.5246  BEST VAL Loss: 0.5246  Val_Acc: 79.975

Epoch 59: Validation loss decreased (0.524643 --> 0.524355).  Saving model ...
	 Train_Loss: 0.5754 Train_Acc: 77.286 Val_Loss: 0.5244  BEST VAL Loss: 0.5244  Val_Acc: 80.048

Epoch 60: Validation loss decreased (0.524355 --> 0.523935).  Saving model ...
	 Train_Loss: 0.5750 Train_Acc: 77.304 Val_Loss: 0.5239  BEST VAL Loss: 0.5239  Val_Acc: 80.109

Epoch 61: Validation loss decreased (0.523935 --> 0.523569).  Saving model ...
	 Train_Loss: 0.5747 Train_Acc: 77.275 Val_Loss: 0.5236  BEST VAL Loss: 0.5236  Val_Acc: 79.913

Epoch 62: Validation loss decreased (0.523569 --> 0.523185).  Saving model ...
	 Train_Loss: 0.5743 Train_Acc: 77.287 Val_Loss: 0.5232  BEST VAL Loss: 0.5232  Val_Acc: 80.144

Epoch 63: Validation loss decreased (0.523185 --> 0.522797).  Saving model ...
	 Train_Loss: 0.5740 Train_Acc: 77.305 Val_Loss: 0.5228  BEST VAL Loss: 0.5228  Val_Acc: 80.207

Epoch 64: Validation loss decreased (0.522797 --> 0.522419).  Saving model ...
	 Train_Loss: 0.5736 Train_Acc: 77.314 Val_Loss: 0.5224  BEST VAL Loss: 0.5224  Val_Acc: 80.089

Epoch 65: Validation loss decreased (0.522419 --> 0.522099).  Saving model ...
	 Train_Loss: 0.5733 Train_Acc: 77.357 Val_Loss: 0.5221  BEST VAL Loss: 0.5221  Val_Acc: 80.086

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.5729 Train_Acc: 77.365 Val_Loss: 0.5221  BEST VAL Loss: 0.5221  Val_Acc: 78.256

Epoch 67: Validation loss decreased (0.522099 --> 0.521780).  Saving model ...
	 Train_Loss: 0.5726 Train_Acc: 77.318 Val_Loss: 0.5218  BEST VAL Loss: 0.5218  Val_Acc: 80.152

Epoch 68: Validation loss decreased (0.521780 --> 0.521540).  Saving model ...
	 Train_Loss: 0.5723 Train_Acc: 77.387 Val_Loss: 0.5215  BEST VAL Loss: 0.5215  Val_Acc: 80.199

Epoch 69: Validation loss decreased (0.521540 --> 0.521207).  Saving model ...
	 Train_Loss: 0.5720 Train_Acc: 77.342 Val_Loss: 0.5212  BEST VAL Loss: 0.5212  Val_Acc: 80.166

Epoch 70: Validation loss decreased (0.521207 --> 0.520907).  Saving model ...
	 Train_Loss: 0.5717 Train_Acc: 77.333 Val_Loss: 0.5209  BEST VAL Loss: 0.5209  Val_Acc: 79.899

Epoch 71: Validation loss decreased (0.520907 --> 0.520564).  Saving model ...
	 Train_Loss: 0.5714 Train_Acc: 77.350 Val_Loss: 0.5206  BEST VAL Loss: 0.5206  Val_Acc: 80.163

Epoch 72: Validation loss decreased (0.520564 --> 0.520292).  Saving model ...
	 Train_Loss: 0.5711 Train_Acc: 77.391 Val_Loss: 0.5203  BEST VAL Loss: 0.5203  Val_Acc: 80.004

Epoch 73: Validation loss decreased (0.520292 --> 0.519930).  Saving model ...
	 Train_Loss: 0.5708 Train_Acc: 77.394 Val_Loss: 0.5199  BEST VAL Loss: 0.5199  Val_Acc: 80.181

Epoch 74: Validation loss decreased (0.519930 --> 0.519623).  Saving model ...
	 Train_Loss: 0.5705 Train_Acc: 77.426 Val_Loss: 0.5196  BEST VAL Loss: 0.5196  Val_Acc: 80.220

Epoch 75: Validation loss decreased (0.519623 --> 0.519305).  Saving model ...
	 Train_Loss: 0.5702 Train_Acc: 77.421 Val_Loss: 0.5193  BEST VAL Loss: 0.5193  Val_Acc: 80.370

Epoch 76: Validation loss decreased (0.519305 --> 0.519077).  Saving model ...
	 Train_Loss: 0.5699 Train_Acc: 77.419 Val_Loss: 0.5191  BEST VAL Loss: 0.5191  Val_Acc: 80.370

Epoch 77: Validation loss decreased (0.519077 --> 0.518813).  Saving model ...
	 Train_Loss: 0.5697 Train_Acc: 77.421 Val_Loss: 0.5188  BEST VAL Loss: 0.5188  Val_Acc: 80.212

Epoch 78: Validation loss decreased (0.518813 --> 0.518590).  Saving model ...
	 Train_Loss: 0.5694 Train_Acc: 77.451 Val_Loss: 0.5186  BEST VAL Loss: 0.5186  Val_Acc: 79.938

Epoch 79: Validation loss decreased (0.518590 --> 0.518327).  Saving model ...
	 Train_Loss: 0.5691 Train_Acc: 77.418 Val_Loss: 0.5183  BEST VAL Loss: 0.5183  Val_Acc: 79.936

Epoch 80: Validation loss decreased (0.518327 --> 0.518077).  Saving model ...
	 Train_Loss: 0.5689 Train_Acc: 77.404 Val_Loss: 0.5181  BEST VAL Loss: 0.5181  Val_Acc: 79.989

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.5686 Train_Acc: 77.442 Val_Loss: 0.5181  BEST VAL Loss: 0.5181  Val_Acc: 79.064

Epoch 82: Validation loss decreased (0.518077 --> 0.518011).  Saving model ...
	 Train_Loss: 0.5684 Train_Acc: 77.474 Val_Loss: 0.5180  BEST VAL Loss: 0.5180  Val_Acc: 79.850

Epoch 83: Validation loss decreased (0.518011 --> 0.517736).  Saving model ...
	 Train_Loss: 0.5681 Train_Acc: 77.464 Val_Loss: 0.5177  BEST VAL Loss: 0.5177  Val_Acc: 80.308

Epoch 84: Validation loss decreased (0.517736 --> 0.517535).  Saving model ...
	 Train_Loss: 0.5679 Train_Acc: 77.496 Val_Loss: 0.5175  BEST VAL Loss: 0.5175  Val_Acc: 80.378

Epoch 85: Validation loss decreased (0.517535 --> 0.517347).  Saving model ...
	 Train_Loss: 0.5676 Train_Acc: 77.494 Val_Loss: 0.5173  BEST VAL Loss: 0.5173  Val_Acc: 80.025

Epoch 86: Validation loss decreased (0.517347 --> 0.517108).  Saving model ...
	 Train_Loss: 0.5674 Train_Acc: 77.473 Val_Loss: 0.5171  BEST VAL Loss: 0.5171  Val_Acc: 80.386

Epoch 87: Validation loss decreased (0.517108 --> 0.516842).  Saving model ...
	 Train_Loss: 0.5671 Train_Acc: 77.542 Val_Loss: 0.5168  BEST VAL Loss: 0.5168  Val_Acc: 80.301

Epoch 88: Validation loss decreased (0.516842 --> 0.516588).  Saving model ...
	 Train_Loss: 0.5669 Train_Acc: 77.522 Val_Loss: 0.5166  BEST VAL Loss: 0.5166  Val_Acc: 80.381

Epoch 89: Validation loss decreased (0.516588 --> 0.516458).  Saving model ...
	 Train_Loss: 0.5667 Train_Acc: 77.552 Val_Loss: 0.5165  BEST VAL Loss: 0.5165  Val_Acc: 80.039

Epoch 90: Validation loss decreased (0.516458 --> 0.516205).  Saving model ...
	 Train_Loss: 0.5665 Train_Acc: 77.543 Val_Loss: 0.5162  BEST VAL Loss: 0.5162  Val_Acc: 80.354

Epoch 91: Validation loss decreased (0.516205 --> 0.515982).  Saving model ...
	 Train_Loss: 0.5662 Train_Acc: 77.563 Val_Loss: 0.5160  BEST VAL Loss: 0.5160  Val_Acc: 80.377

Epoch 92: Validation loss decreased (0.515982 --> 0.515718).  Saving model ...
	 Train_Loss: 0.5660 Train_Acc: 77.507 Val_Loss: 0.5157  BEST VAL Loss: 0.5157  Val_Acc: 80.484

Epoch 93: Validation loss decreased (0.515718 --> 0.515471).  Saving model ...
	 Train_Loss: 0.5658 Train_Acc: 77.495 Val_Loss: 0.5155  BEST VAL Loss: 0.5155  Val_Acc: 80.443

Epoch 94: Validation loss decreased (0.515471 --> 0.515289).  Saving model ...
	 Train_Loss: 0.5656 Train_Acc: 77.537 Val_Loss: 0.5153  BEST VAL Loss: 0.5153  Val_Acc: 79.924

Epoch 95: Validation loss decreased (0.515289 --> 0.515117).  Saving model ...
	 Train_Loss: 0.5654 Train_Acc: 77.530 Val_Loss: 0.5151  BEST VAL Loss: 0.5151  Val_Acc: 80.216

Epoch 96: Validation loss decreased (0.515117 --> 0.514933).  Saving model ...
	 Train_Loss: 0.5652 Train_Acc: 77.561 Val_Loss: 0.5149  BEST VAL Loss: 0.5149  Val_Acc: 80.312

Epoch 97: Validation loss decreased (0.514933 --> 0.514788).  Saving model ...
	 Train_Loss: 0.5650 Train_Acc: 77.556 Val_Loss: 0.5148  BEST VAL Loss: 0.5148  Val_Acc: 80.299

Epoch 98: Validation loss decreased (0.514788 --> 0.514585).  Saving model ...
	 Train_Loss: 0.5648 Train_Acc: 77.602 Val_Loss: 0.5146  BEST VAL Loss: 0.5146  Val_Acc: 80.333

Epoch 99: Validation loss decreased (0.514585 --> 0.514389).  Saving model ...
	 Train_Loss: 0.5646 Train_Acc: 77.555 Val_Loss: 0.5144  BEST VAL Loss: 0.5144  Val_Acc: 80.532

MultiClass_MLP_h202_remove_shuffle
              precision    recall  f1-score   support

           0       0.07      0.05      0.06     95929
           1       0.48      0.52      0.50    683836
           2       0.45      0.43      0.44    637329

    accuracy                           0.45   1417094
   macro avg       0.33      0.33      0.33   1417094
weighted avg       0.44      0.45      0.44   1417094

MultiClass_MLP_h202_remove_shuffle
              precision    recall  f1-score   support

           0       0.07      0.05      0.06     23982
           1       0.48      0.52      0.50    170959
           2       0.45      0.43      0.44    159333

    accuracy                           0.45    354274
   macro avg       0.33      0.33      0.33    354274
weighted avg       0.44      0.45      0.44    354274

MultiClass_MLP_h202_remove_shuffle
              precision    recall  f1-score   support

           0       0.06      0.04      0.05    119910
           1       0.40      0.46      0.43    854797
           2       0.54      0.50      0.52   1138034

    accuracy                           0.46   2112741
   macro avg       0.33      0.33      0.33   2112741
weighted avg       0.46      0.46      0.46   2112741

Precision for class 0: 0.05739220057582649
Recall for class 0: 0.042723709448753235
Precision for class 1: 0.4047283512629966
Recall for class 1: 0.462308594906159
Precision for class 2: 0.5385790825828264
Recall for class 2: 0.49553001052692625
3
              precision    recall  f1-score   support

           0       0.06      0.04      0.05    119910
           1       0.40      0.46      0.43    854797
           2       0.54      0.50      0.52   1138034

    accuracy                           0.46   2112741
   macro avg       0.33      0.33      0.33   2112741
weighted avg       0.46      0.46      0.46   2112741

MultiClass_MLP_h202_remove_shuffle
              precision    recall  f1-score   support

           0       0.05      0.04      0.04     75619
           1       0.48      0.47      0.48    711982
           2       0.47      0.50      0.48    686436

    accuracy                           0.46   1474037
   macro avg       0.33      0.33      0.33   1474037
weighted avg       0.45      0.46      0.46   1474037

Precision for class 0: 0.05040941176470588
Recall for class 0: 0.03541437998386649
Precision for class 1: 0.48273530850900587
Recall for class 1: 0.4683559415827928
Precision for class 2: 0.4655202167261531
Recall for class 2: 0.4951575966295474
3
              precision    recall  f1-score   support

           0       0.05      0.04      0.04     75619
           1       0.48      0.47      0.48    711982
           2       0.47      0.50      0.48    686436

    accuracy                           0.46   1474037
   macro avg       0.33      0.33      0.33   1474037
weighted avg       0.45      0.46      0.46   1474037

Done
