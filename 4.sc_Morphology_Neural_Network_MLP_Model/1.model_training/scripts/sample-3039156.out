[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'e0581262'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '81a1b68d'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b0120c31'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'd8eb5ea1'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: H2O2_100.000_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (42759, 1276)
Number of total missing values across all columns: 85518
Data Subset Is Off
Wells held out for testing: ['B16' 'H22']
Wells to use for training, validation, and testing ['B17' 'H18' 'H19' 'B20' 'B21' 'H23' 'I18' 'I19' 'I22' 'I23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.556828).  Saving model ...
	 Train_Loss: 0.5957 Train_Acc: 66.623 Val_Loss: 0.5568  BEST VAL Loss: 0.5568  Val_Acc: 68.305

Epoch 1: Validation loss decreased (0.556828 --> 0.531663).  Saving model ...
	 Train_Loss: 0.5605 Train_Acc: 71.279 Val_Loss: 0.5317  BEST VAL Loss: 0.5317  Val_Acc: 71.949

Epoch 2: Validation loss decreased (0.531663 --> 0.519731).  Saving model ...
	 Train_Loss: 0.5363 Train_Acc: 74.385 Val_Loss: 0.5197  BEST VAL Loss: 0.5197  Val_Acc: 74.378

Epoch 3: Validation loss decreased (0.519731 --> 0.510174).  Saving model ...
	 Train_Loss: 0.5161 Train_Acc: 76.868 Val_Loss: 0.5102  BEST VAL Loss: 0.5102  Val_Acc: 75.882

Epoch 4: Validation loss decreased (0.510174 --> 0.502648).  Saving model ...
	 Train_Loss: 0.5002 Train_Acc: 78.151 Val_Loss: 0.5026  BEST VAL Loss: 0.5026  Val_Acc: 76.518

Epoch 5: Validation loss decreased (0.502648 --> 0.496340).  Saving model ...
	 Train_Loss: 0.4873 Train_Acc: 79.203 Val_Loss: 0.4963  BEST VAL Loss: 0.4963  Val_Acc: 77.126

Epoch 6: Validation loss decreased (0.496340 --> 0.492146).  Saving model ...
	 Train_Loss: 0.4764 Train_Acc: 79.565 Val_Loss: 0.4921  BEST VAL Loss: 0.4921  Val_Acc: 77.415

Epoch 7: Validation loss decreased (0.492146 --> 0.488644).  Saving model ...
	 Train_Loss: 0.4672 Train_Acc: 80.248 Val_Loss: 0.4886  BEST VAL Loss: 0.4886  Val_Acc: 77.704

Epoch 8: Validation loss decreased (0.488644 --> 0.485456).  Saving model ...
	 Train_Loss: 0.4590 Train_Acc: 80.928 Val_Loss: 0.4855  BEST VAL Loss: 0.4855  Val_Acc: 77.473

Epoch 9: Validation loss decreased (0.485456 --> 0.482672).  Saving model ...
	 Train_Loss: 0.4523 Train_Acc: 80.819 Val_Loss: 0.4827  BEST VAL Loss: 0.4827  Val_Acc: 77.617

Epoch 10: Validation loss decreased (0.482672 --> 0.480568).  Saving model ...
	 Train_Loss: 0.4459 Train_Acc: 81.448 Val_Loss: 0.4806  BEST VAL Loss: 0.4806  Val_Acc: 77.675

Epoch 11: Validation loss decreased (0.480568 --> 0.478840).  Saving model ...
	 Train_Loss: 0.4402 Train_Acc: 82.034 Val_Loss: 0.4788  BEST VAL Loss: 0.4788  Val_Acc: 77.473

Epoch 12: Validation loss decreased (0.478840 --> 0.477771).  Saving model ...
	 Train_Loss: 0.4349 Train_Acc: 82.178 Val_Loss: 0.4778  BEST VAL Loss: 0.4778  Val_Acc: 77.964

Epoch 13: Validation loss decreased (0.477771 --> 0.477030).  Saving model ...
	 Train_Loss: 0.4305 Train_Acc: 82.023 Val_Loss: 0.4770  BEST VAL Loss: 0.4770  Val_Acc: 77.906

Epoch 14: Validation loss decreased (0.477030 --> 0.476622).  Saving model ...
	 Train_Loss: 0.4264 Train_Acc: 81.925 Val_Loss: 0.4766  BEST VAL Loss: 0.4766  Val_Acc: 78.051

Epoch 15: Validation loss decreased (0.476622 --> 0.476220).  Saving model ...
	 Train_Loss: 0.4228 Train_Acc: 82.442 Val_Loss: 0.4762  BEST VAL Loss: 0.4762  Val_Acc: 77.791

Epoch 16: Validation loss decreased (0.476220 --> 0.475372).  Saving model ...
	 Train_Loss: 0.4193 Train_Acc: 82.590 Val_Loss: 0.4754  BEST VAL Loss: 0.4754  Val_Acc: 78.224

Epoch 17: Validation loss did not decrease
	 Train_Loss: 0.4159 Train_Acc: 83.097 Val_Loss: 0.4754  BEST VAL Loss: 0.4754  Val_Acc: 78.427

Epoch 18: Validation loss decreased (0.475372 --> 0.474603).  Saving model ...
	 Train_Loss: 0.4131 Train_Acc: 82.825 Val_Loss: 0.4746  BEST VAL Loss: 0.4746  Val_Acc: 78.658

Epoch 19: Validation loss decreased (0.474603 --> 0.474000).  Saving model ...
	 Train_Loss: 0.4101 Train_Acc: 83.046 Val_Loss: 0.4740  BEST VAL Loss: 0.4740  Val_Acc: 78.109

Epoch 20: Validation loss decreased (0.474000 --> 0.473318).  Saving model ...
	 Train_Loss: 0.4073 Train_Acc: 83.483 Val_Loss: 0.4733  BEST VAL Loss: 0.4733  Val_Acc: 78.571

Epoch 21: Validation loss decreased (0.473318 --> 0.472986).  Saving model ...
	 Train_Loss: 0.4043 Train_Acc: 83.613 Val_Loss: 0.4730  BEST VAL Loss: 0.4730  Val_Acc: 79.063

Epoch 22: Validation loss decreased (0.472986 --> 0.472661).  Saving model ...
	 Train_Loss: 0.4012 Train_Acc: 83.924 Val_Loss: 0.4727  BEST VAL Loss: 0.4727  Val_Acc: 79.294

Epoch 23: Validation loss decreased (0.472661 --> 0.472623).  Saving model ...
	 Train_Loss: 0.3984 Train_Acc: 84.344 Val_Loss: 0.4726  BEST VAL Loss: 0.4726  Val_Acc: 79.063

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.3957 Train_Acc: 84.409 Val_Loss: 0.4728  BEST VAL Loss: 0.4726  Val_Acc: 78.253

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.3932 Train_Acc: 84.383 Val_Loss: 0.4729  BEST VAL Loss: 0.4726  Val_Acc: 78.340

Epoch 26: Validation loss did not decrease
	 Train_Loss: 0.3907 Train_Acc: 84.712 Val_Loss: 0.4732  BEST VAL Loss: 0.4726  Val_Acc: 78.369

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.3884 Train_Acc: 84.597 Val_Loss: 0.4733  BEST VAL Loss: 0.4726  Val_Acc: 78.514

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.3860 Train_Acc: 85.081 Val_Loss: 0.4738  BEST VAL Loss: 0.4726  Val_Acc: 78.485

Epoch 29: Validation loss did not decrease
	 Train_Loss: 0.3838 Train_Acc: 85.012 Val_Loss: 0.4744  BEST VAL Loss: 0.4726  Val_Acc: 79.005

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.3818 Train_Acc: 85.023 Val_Loss: 0.4749  BEST VAL Loss: 0.4726  Val_Acc: 77.848

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.3797 Train_Acc: 85.435 Val_Loss: 0.4755  BEST VAL Loss: 0.4726  Val_Acc: 78.716

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.3777 Train_Acc: 85.349 Val_Loss: 0.4760  BEST VAL Loss: 0.4726  Val_Acc: 78.195

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.3760 Train_Acc: 85.179 Val_Loss: 0.4770  BEST VAL Loss: 0.4726  Val_Acc: 78.195

Epoch 34: Validation loss did not decrease
	 Train_Loss: 0.3743 Train_Acc: 84.861 Val_Loss: 0.4776  BEST VAL Loss: 0.4726  Val_Acc: 78.195

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.3725 Train_Acc: 85.403 Val_Loss: 0.4788  BEST VAL Loss: 0.4726  Val_Acc: 77.935

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.3708 Train_Acc: 85.609 Val_Loss: 0.4796  BEST VAL Loss: 0.4726  Val_Acc: 77.877

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.3692 Train_Acc: 85.573 Val_Loss: 0.4807  BEST VAL Loss: 0.4726  Val_Acc: 77.501

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.3675 Train_Acc: 85.678 Val_Loss: 0.4817  BEST VAL Loss: 0.4726  Val_Acc: 78.224

Epoch 39: Validation loss did not decrease
Early stopped at epoch : 39
H2O2_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.90      0.89      0.90     18174
           1       0.80      0.82      0.81      9489

    accuracy                           0.87     27663
   macro avg       0.85      0.86      0.85     27663
weighted avg       0.87      0.87      0.87     27663

H2O2_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.84      0.84      0.84      2272
           1       0.70      0.69      0.69      1186

    accuracy                           0.79      3458
   macro avg       0.77      0.77      0.77      3458
weighted avg       0.79      0.79      0.79      3458

H2O2_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.84      0.83      0.84      2272
           1       0.68      0.70      0.69      1187

    accuracy                           0.79      3459
   macro avg       0.76      0.76      0.76      3459
weighted avg       0.79      0.79      0.79      3459

              precision    recall  f1-score   support

           0       0.84      0.83      0.84      2272
           1       0.68      0.70      0.69      1187

    accuracy                           0.79      3459
   macro avg       0.76      0.76      0.76      3459
weighted avg       0.79      0.79      0.79      3459

H2O2_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.70      0.67      0.68      4182
           1       0.67      0.70      0.68      3997

    accuracy                           0.68      8179
   macro avg       0.69      0.69      0.68      8179
weighted avg       0.69      0.68      0.68      8179

              precision    recall  f1-score   support

           0       0.70      0.67      0.68      4182
           1       0.67      0.70      0.68      3997

    accuracy                           0.68      8179
   macro avg       0.69      0.69      0.68      8179
weighted avg       0.69      0.68      0.68      8179

completed
