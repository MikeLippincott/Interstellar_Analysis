[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'f92c15f8'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '9279e076'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'bfb27050'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '33b7c4c8'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_10.000_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_10.000_DMSO_0.025']
The dimensions of the data are: (299570, 1270)
Number of total missing values across all columns: 599140
Data Subset Is Off
Wells held out for testing: ['B08' 'E08']
Wells to use for training, validation, and testing ['B02' 'B03' 'B09' 'E02' 'E03' 'E09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.593012).  Saving model ...
	 Train_Loss: 0.6419 Train_Acc: 63.030 Val_Loss: 0.5930  BEST VAL Loss: 0.5930  Val_Acc: 68.050

Epoch 1: Validation loss decreased (0.593012 --> 0.566684).  Saving model ...
	 Train_Loss: 0.6042 Train_Acc: 70.204 Val_Loss: 0.5667  BEST VAL Loss: 0.5667  Val_Acc: 72.387

Epoch 2: Validation loss decreased (0.566684 --> 0.551668).  Saving model ...
	 Train_Loss: 0.5805 Train_Acc: 72.618 Val_Loss: 0.5517  BEST VAL Loss: 0.5517  Val_Acc: 73.698

Epoch 3: Validation loss decreased (0.551668 --> 0.541713).  Saving model ...
	 Train_Loss: 0.5645 Train_Acc: 73.744 Val_Loss: 0.5417  BEST VAL Loss: 0.5417  Val_Acc: 74.078

Epoch 4: Validation loss decreased (0.541713 --> 0.532800).  Saving model ...
	 Train_Loss: 0.5526 Train_Acc: 74.465 Val_Loss: 0.5328  BEST VAL Loss: 0.5328  Val_Acc: 75.303

Epoch 5: Validation loss decreased (0.532800 --> 0.524835).  Saving model ...
	 Train_Loss: 0.5436 Train_Acc: 74.928 Val_Loss: 0.5248  BEST VAL Loss: 0.5248  Val_Acc: 75.823

Epoch 6: Validation loss decreased (0.524835 --> 0.519880).  Saving model ...
	 Train_Loss: 0.5362 Train_Acc: 75.361 Val_Loss: 0.5199  BEST VAL Loss: 0.5199  Val_Acc: 75.592

Epoch 7: Validation loss decreased (0.519880 --> 0.514667).  Saving model ...
	 Train_Loss: 0.5301 Train_Acc: 75.551 Val_Loss: 0.5147  BEST VAL Loss: 0.5147  Val_Acc: 76.216

Epoch 8: Validation loss decreased (0.514667 --> 0.511724).  Saving model ...
	 Train_Loss: 0.5249 Train_Acc: 75.802 Val_Loss: 0.5117  BEST VAL Loss: 0.5117  Val_Acc: 75.642

Epoch 9: Validation loss decreased (0.511724 --> 0.508030).  Saving model ...
	 Train_Loss: 0.5204 Train_Acc: 76.025 Val_Loss: 0.5080  BEST VAL Loss: 0.5080  Val_Acc: 76.528

Epoch 10: Validation loss decreased (0.508030 --> 0.505119).  Saving model ...
	 Train_Loss: 0.5164 Train_Acc: 76.283 Val_Loss: 0.5051  BEST VAL Loss: 0.5051  Val_Acc: 76.203

Epoch 11: Validation loss decreased (0.505119 --> 0.502300).  Saving model ...
	 Train_Loss: 0.5127 Train_Acc: 76.624 Val_Loss: 0.5023  BEST VAL Loss: 0.5023  Val_Acc: 76.632

Epoch 12: Validation loss decreased (0.502300 --> 0.499271).  Saving model ...
	 Train_Loss: 0.5093 Train_Acc: 76.697 Val_Loss: 0.4993  BEST VAL Loss: 0.4993  Val_Acc: 77.437

Epoch 13: Validation loss decreased (0.499271 --> 0.496790).  Saving model ...
	 Train_Loss: 0.5063 Train_Acc: 76.878 Val_Loss: 0.4968  BEST VAL Loss: 0.4968  Val_Acc: 77.139

Epoch 14: Validation loss decreased (0.496790 --> 0.494227).  Saving model ...
	 Train_Loss: 0.5035 Train_Acc: 77.086 Val_Loss: 0.4942  BEST VAL Loss: 0.4942  Val_Acc: 77.496

Epoch 15: Validation loss decreased (0.494227 --> 0.492132).  Saving model ...
	 Train_Loss: 0.5008 Train_Acc: 77.235 Val_Loss: 0.4921  BEST VAL Loss: 0.4921  Val_Acc: 77.514

Epoch 16: Validation loss decreased (0.492132 --> 0.489776).  Saving model ...
	 Train_Loss: 0.4983 Train_Acc: 77.428 Val_Loss: 0.4898  BEST VAL Loss: 0.4898  Val_Acc: 78.034

Epoch 17: Validation loss decreased (0.489776 --> 0.487443).  Saving model ...
	 Train_Loss: 0.4960 Train_Acc: 77.546 Val_Loss: 0.4874  BEST VAL Loss: 0.4874  Val_Acc: 78.518

Epoch 18: Validation loss decreased (0.487443 --> 0.485406).  Saving model ...
	 Train_Loss: 0.4938 Train_Acc: 77.658 Val_Loss: 0.4854  BEST VAL Loss: 0.4854  Val_Acc: 78.269

Epoch 19: Validation loss decreased (0.485406 --> 0.483347).  Saving model ...
	 Train_Loss: 0.4917 Train_Acc: 77.878 Val_Loss: 0.4833  BEST VAL Loss: 0.4833  Val_Acc: 78.590

Epoch 20: Validation loss decreased (0.483347 --> 0.481585).  Saving model ...
	 Train_Loss: 0.4897 Train_Acc: 78.063 Val_Loss: 0.4816  BEST VAL Loss: 0.4816  Val_Acc: 78.382

Epoch 21: Validation loss decreased (0.481585 --> 0.479838).  Saving model ...
	 Train_Loss: 0.4878 Train_Acc: 78.076 Val_Loss: 0.4798  BEST VAL Loss: 0.4798  Val_Acc: 78.459

Epoch 22: Validation loss decreased (0.479838 --> 0.478275).  Saving model ...
	 Train_Loss: 0.4860 Train_Acc: 78.253 Val_Loss: 0.4783  BEST VAL Loss: 0.4783  Val_Acc: 78.423

Epoch 23: Validation loss decreased (0.478275 --> 0.476771).  Saving model ...
	 Train_Loss: 0.4843 Train_Acc: 78.309 Val_Loss: 0.4768  BEST VAL Loss: 0.4768  Val_Acc: 78.604

Epoch 24: Validation loss decreased (0.476771 --> 0.475417).  Saving model ...
	 Train_Loss: 0.4827 Train_Acc: 78.430 Val_Loss: 0.4754  BEST VAL Loss: 0.4754  Val_Acc: 78.482

Epoch 25: Validation loss decreased (0.475417 --> 0.474009).  Saving model ...
	 Train_Loss: 0.4810 Train_Acc: 78.658 Val_Loss: 0.4740  BEST VAL Loss: 0.4740  Val_Acc: 78.767

Epoch 26: Validation loss decreased (0.474009 --> 0.472610).  Saving model ...
	 Train_Loss: 0.4795 Train_Acc: 78.567 Val_Loss: 0.4726  BEST VAL Loss: 0.4726  Val_Acc: 78.771

Epoch 27: Validation loss decreased (0.472610 --> 0.471382).  Saving model ...
	 Train_Loss: 0.4781 Train_Acc: 78.719 Val_Loss: 0.4714  BEST VAL Loss: 0.4714  Val_Acc: 78.857

Epoch 28: Validation loss decreased (0.471382 --> 0.470094).  Saving model ...
	 Train_Loss: 0.4766 Train_Acc: 78.772 Val_Loss: 0.4701  BEST VAL Loss: 0.4701  Val_Acc: 78.789

Epoch 29: Validation loss decreased (0.470094 --> 0.468985).  Saving model ...
	 Train_Loss: 0.4753 Train_Acc: 78.825 Val_Loss: 0.4690  BEST VAL Loss: 0.4690  Val_Acc: 78.649

Epoch 30: Validation loss decreased (0.468985 --> 0.467818).  Saving model ...
	 Train_Loss: 0.4739 Train_Acc: 78.886 Val_Loss: 0.4678  BEST VAL Loss: 0.4678  Val_Acc: 78.753

Epoch 31: Validation loss decreased (0.467818 --> 0.466806).  Saving model ...
	 Train_Loss: 0.4727 Train_Acc: 78.967 Val_Loss: 0.4668  BEST VAL Loss: 0.4668  Val_Acc: 78.830

Epoch 32: Validation loss decreased (0.466806 --> 0.465716).  Saving model ...
	 Train_Loss: 0.4714 Train_Acc: 79.130 Val_Loss: 0.4657  BEST VAL Loss: 0.4657  Val_Acc: 79.038

Epoch 33: Validation loss decreased (0.465716 --> 0.464647).  Saving model ...
	 Train_Loss: 0.4703 Train_Acc: 79.114 Val_Loss: 0.4646  BEST VAL Loss: 0.4646  Val_Acc: 79.124

Epoch 34: Validation loss decreased (0.464647 --> 0.463632).  Saving model ...
	 Train_Loss: 0.4691 Train_Acc: 79.176 Val_Loss: 0.4636  BEST VAL Loss: 0.4636  Val_Acc: 79.228

Epoch 35: Validation loss decreased (0.463632 --> 0.462736).  Saving model ...
	 Train_Loss: 0.4680 Train_Acc: 79.185 Val_Loss: 0.4627  BEST VAL Loss: 0.4627  Val_Acc: 78.825

Epoch 36: Validation loss decreased (0.462736 --> 0.461837).  Saving model ...
	 Train_Loss: 0.4669 Train_Acc: 79.224 Val_Loss: 0.4618  BEST VAL Loss: 0.4618  Val_Acc: 79.101

Epoch 37: Validation loss decreased (0.461837 --> 0.460997).  Saving model ...
	 Train_Loss: 0.4659 Train_Acc: 79.453 Val_Loss: 0.4610  BEST VAL Loss: 0.4610  Val_Acc: 79.051

Epoch 38: Validation loss decreased (0.460997 --> 0.460282).  Saving model ...
	 Train_Loss: 0.4649 Train_Acc: 79.313 Val_Loss: 0.4603  BEST VAL Loss: 0.4603  Val_Acc: 78.893

Epoch 39: Validation loss decreased (0.460282 --> 0.459448).  Saving model ...
	 Train_Loss: 0.4639 Train_Acc: 79.444 Val_Loss: 0.4594  BEST VAL Loss: 0.4594  Val_Acc: 79.300

Epoch 40: Validation loss decreased (0.459448 --> 0.458603).  Saving model ...
	 Train_Loss: 0.4630 Train_Acc: 79.484 Val_Loss: 0.4586  BEST VAL Loss: 0.4586  Val_Acc: 79.549

Epoch 41: Validation loss decreased (0.458603 --> 0.457806).  Saving model ...
	 Train_Loss: 0.4621 Train_Acc: 79.540 Val_Loss: 0.4578  BEST VAL Loss: 0.4578  Val_Acc: 79.400

Epoch 42: Validation loss decreased (0.457806 --> 0.457019).  Saving model ...
	 Train_Loss: 0.4612 Train_Acc: 79.515 Val_Loss: 0.4570  BEST VAL Loss: 0.4570  Val_Acc: 79.522

Epoch 43: Validation loss decreased (0.457019 --> 0.456265).  Saving model ...
	 Train_Loss: 0.4603 Train_Acc: 79.647 Val_Loss: 0.4563  BEST VAL Loss: 0.4563  Val_Acc: 79.553

Epoch 44: Validation loss decreased (0.456265 --> 0.455529).  Saving model ...
	 Train_Loss: 0.4594 Train_Acc: 79.653 Val_Loss: 0.4555  BEST VAL Loss: 0.4555  Val_Acc: 79.662

Epoch 45: Validation loss decreased (0.455529 --> 0.454839).  Saving model ...
	 Train_Loss: 0.4586 Train_Acc: 79.744 Val_Loss: 0.4548  BEST VAL Loss: 0.4548  Val_Acc: 79.657

Epoch 46: Validation loss decreased (0.454839 --> 0.454207).  Saving model ...
	 Train_Loss: 0.4578 Train_Acc: 79.688 Val_Loss: 0.4542  BEST VAL Loss: 0.4542  Val_Acc: 79.372

Epoch 47: Validation loss decreased (0.454207 --> 0.453556).  Saving model ...
	 Train_Loss: 0.4570 Train_Acc: 79.694 Val_Loss: 0.4536  BEST VAL Loss: 0.4536  Val_Acc: 79.431

Epoch 48: Validation loss decreased (0.453556 --> 0.452935).  Saving model ...
	 Train_Loss: 0.4563 Train_Acc: 79.883 Val_Loss: 0.4529  BEST VAL Loss: 0.4529  Val_Acc: 79.526

Epoch 49: Validation loss decreased (0.452935 --> 0.452329).  Saving model ...
	 Train_Loss: 0.4555 Train_Acc: 79.923 Val_Loss: 0.4523  BEST VAL Loss: 0.4523  Val_Acc: 79.517

Epoch 50: Validation loss decreased (0.452329 --> 0.451686).  Saving model ...
	 Train_Loss: 0.4548 Train_Acc: 79.837 Val_Loss: 0.4517  BEST VAL Loss: 0.4517  Val_Acc: 79.761

Epoch 51: Validation loss decreased (0.451686 --> 0.451142).  Saving model ...
	 Train_Loss: 0.4541 Train_Acc: 79.896 Val_Loss: 0.4511  BEST VAL Loss: 0.4511  Val_Acc: 79.490

Epoch 52: Validation loss decreased (0.451142 --> 0.450579).  Saving model ...
	 Train_Loss: 0.4534 Train_Acc: 79.909 Val_Loss: 0.4506  BEST VAL Loss: 0.4506  Val_Acc: 79.390

Epoch 53: Validation loss decreased (0.450579 --> 0.450006).  Saving model ...
	 Train_Loss: 0.4527 Train_Acc: 79.918 Val_Loss: 0.4500  BEST VAL Loss: 0.4500  Val_Acc: 79.748

Epoch 54: Validation loss decreased (0.450006 --> 0.449476).  Saving model ...
	 Train_Loss: 0.4521 Train_Acc: 79.979 Val_Loss: 0.4495  BEST VAL Loss: 0.4495  Val_Acc: 79.494

Epoch 55: Validation loss decreased (0.449476 --> 0.448969).  Saving model ...
	 Train_Loss: 0.4514 Train_Acc: 80.050 Val_Loss: 0.4490  BEST VAL Loss: 0.4490  Val_Acc: 79.766

Epoch 56: Validation loss decreased (0.448969 --> 0.448508).  Saving model ...
	 Train_Loss: 0.4508 Train_Acc: 80.011 Val_Loss: 0.4485  BEST VAL Loss: 0.4485  Val_Acc: 79.431

Epoch 57: Validation loss decreased (0.448508 --> 0.448002).  Saving model ...
	 Train_Loss: 0.4502 Train_Acc: 79.980 Val_Loss: 0.4480  BEST VAL Loss: 0.4480  Val_Acc: 79.856

Epoch 58: Validation loss decreased (0.448002 --> 0.447522).  Saving model ...
	 Train_Loss: 0.4495 Train_Acc: 80.088 Val_Loss: 0.4475  BEST VAL Loss: 0.4475  Val_Acc: 79.653

Epoch 59: Validation loss decreased (0.447522 --> 0.447055).  Saving model ...
	 Train_Loss: 0.4490 Train_Acc: 80.176 Val_Loss: 0.4471  BEST VAL Loss: 0.4471  Val_Acc: 79.770

Epoch 60: Validation loss decreased (0.447055 --> 0.446590).  Saving model ...
	 Train_Loss: 0.4484 Train_Acc: 80.059 Val_Loss: 0.4466  BEST VAL Loss: 0.4466  Val_Acc: 79.725

Epoch 61: Validation loss decreased (0.446590 --> 0.446160).  Saving model ...
	 Train_Loss: 0.4478 Train_Acc: 80.143 Val_Loss: 0.4462  BEST VAL Loss: 0.4462  Val_Acc: 79.635

Epoch 62: Validation loss decreased (0.446160 --> 0.445733).  Saving model ...
	 Train_Loss: 0.4472 Train_Acc: 80.267 Val_Loss: 0.4457  BEST VAL Loss: 0.4457  Val_Acc: 79.630

Epoch 63: Validation loss decreased (0.445733 --> 0.445333).  Saving model ...
	 Train_Loss: 0.4467 Train_Acc: 80.073 Val_Loss: 0.4453  BEST VAL Loss: 0.4453  Val_Acc: 79.571

Epoch 64: Validation loss decreased (0.445333 --> 0.444937).  Saving model ...
	 Train_Loss: 0.4462 Train_Acc: 80.208 Val_Loss: 0.4449  BEST VAL Loss: 0.4449  Val_Acc: 79.639

Epoch 65: Validation loss decreased (0.444937 --> 0.444526).  Saving model ...
	 Train_Loss: 0.4456 Train_Acc: 80.215 Val_Loss: 0.4445  BEST VAL Loss: 0.4445  Val_Acc: 79.657

Epoch 66: Validation loss decreased (0.444526 --> 0.444118).  Saving model ...
	 Train_Loss: 0.4451 Train_Acc: 80.208 Val_Loss: 0.4441  BEST VAL Loss: 0.4441  Val_Acc: 79.662

Epoch 67: Validation loss decreased (0.444118 --> 0.443717).  Saving model ...
	 Train_Loss: 0.4446 Train_Acc: 80.273 Val_Loss: 0.4437  BEST VAL Loss: 0.4437  Val_Acc: 79.834

Epoch 68: Validation loss decreased (0.443717 --> 0.443373).  Saving model ...
	 Train_Loss: 0.4441 Train_Acc: 80.323 Val_Loss: 0.4434  BEST VAL Loss: 0.4434  Val_Acc: 79.725

Epoch 69: Validation loss decreased (0.443373 --> 0.443012).  Saving model ...
	 Train_Loss: 0.4436 Train_Acc: 80.289 Val_Loss: 0.4430  BEST VAL Loss: 0.4430  Val_Acc: 79.888

Epoch 70: Validation loss decreased (0.443012 --> 0.442626).  Saving model ...
	 Train_Loss: 0.4432 Train_Acc: 80.404 Val_Loss: 0.4426  BEST VAL Loss: 0.4426  Val_Acc: 79.721

Epoch 71: Validation loss decreased (0.442626 --> 0.442246).  Saving model ...
	 Train_Loss: 0.4427 Train_Acc: 80.294 Val_Loss: 0.4422  BEST VAL Loss: 0.4422  Val_Acc: 79.974

Epoch 72: Validation loss decreased (0.442246 --> 0.441870).  Saving model ...
	 Train_Loss: 0.4422 Train_Acc: 80.346 Val_Loss: 0.4419  BEST VAL Loss: 0.4419  Val_Acc: 79.969

Epoch 73: Validation loss decreased (0.441870 --> 0.441504).  Saving model ...
	 Train_Loss: 0.4418 Train_Acc: 80.331 Val_Loss: 0.4415  BEST VAL Loss: 0.4415  Val_Acc: 79.725

Epoch 74: Validation loss decreased (0.441504 --> 0.441184).  Saving model ...
	 Train_Loss: 0.4414 Train_Acc: 80.418 Val_Loss: 0.4412  BEST VAL Loss: 0.4412  Val_Acc: 79.757

Epoch 75: Validation loss decreased (0.441184 --> 0.440893).  Saving model ...
	 Train_Loss: 0.4409 Train_Acc: 80.429 Val_Loss: 0.4409  BEST VAL Loss: 0.4409  Val_Acc: 79.820

Epoch 76: Validation loss decreased (0.440893 --> 0.440545).  Saving model ...
	 Train_Loss: 0.4405 Train_Acc: 80.397 Val_Loss: 0.4405  BEST VAL Loss: 0.4405  Val_Acc: 80.033

Epoch 77: Validation loss decreased (0.440545 --> 0.440225).  Saving model ...
	 Train_Loss: 0.4401 Train_Acc: 80.401 Val_Loss: 0.4402  BEST VAL Loss: 0.4402  Val_Acc: 79.716

Epoch 78: Validation loss decreased (0.440225 --> 0.439956).  Saving model ...
	 Train_Loss: 0.4397 Train_Acc: 80.461 Val_Loss: 0.4400  BEST VAL Loss: 0.4400  Val_Acc: 79.553

Epoch 79: Validation loss decreased (0.439956 --> 0.439652).  Saving model ...
	 Train_Loss: 0.4392 Train_Acc: 80.384 Val_Loss: 0.4397  BEST VAL Loss: 0.4397  Val_Acc: 79.834

Epoch 80: Validation loss decreased (0.439652 --> 0.439392).  Saving model ...
	 Train_Loss: 0.4389 Train_Acc: 80.344 Val_Loss: 0.4394  BEST VAL Loss: 0.4394  Val_Acc: 79.757

Epoch 81: Validation loss decreased (0.439392 --> 0.439129).  Saving model ...
	 Train_Loss: 0.4384 Train_Acc: 80.554 Val_Loss: 0.4391  BEST VAL Loss: 0.4391  Val_Acc: 79.598

Epoch 82: Validation loss decreased (0.439129 --> 0.438828).  Saving model ...
	 Train_Loss: 0.4381 Train_Acc: 80.511 Val_Loss: 0.4388  BEST VAL Loss: 0.4388  Val_Acc: 80.014

Epoch 83: Validation loss decreased (0.438828 --> 0.438515).  Saving model ...
	 Train_Loss: 0.4377 Train_Acc: 80.499 Val_Loss: 0.4385  BEST VAL Loss: 0.4385  Val_Acc: 79.956

Epoch 84: Validation loss decreased (0.438515 --> 0.438227).  Saving model ...
	 Train_Loss: 0.4373 Train_Acc: 80.513 Val_Loss: 0.4382  BEST VAL Loss: 0.4382  Val_Acc: 79.883

Epoch 85: Validation loss decreased (0.438227 --> 0.437951).  Saving model ...
	 Train_Loss: 0.4369 Train_Acc: 80.656 Val_Loss: 0.4380  BEST VAL Loss: 0.4380  Val_Acc: 79.915

Epoch 86: Validation loss decreased (0.437951 --> 0.437680).  Saving model ...
	 Train_Loss: 0.4366 Train_Acc: 80.644 Val_Loss: 0.4377  BEST VAL Loss: 0.4377  Val_Acc: 79.947

Epoch 87: Validation loss decreased (0.437680 --> 0.437425).  Saving model ...
	 Train_Loss: 0.4362 Train_Acc: 80.604 Val_Loss: 0.4374  BEST VAL Loss: 0.4374  Val_Acc: 79.892

Epoch 88: Validation loss decreased (0.437425 --> 0.437155).  Saving model ...
	 Train_Loss: 0.4359 Train_Acc: 80.489 Val_Loss: 0.4372  BEST VAL Loss: 0.4372  Val_Acc: 80.087

Epoch 89: Validation loss decreased (0.437155 --> 0.436890).  Saving model ...
	 Train_Loss: 0.4355 Train_Acc: 80.558 Val_Loss: 0.4369  BEST VAL Loss: 0.4369  Val_Acc: 79.883

Epoch 90: Validation loss decreased (0.436890 --> 0.436624).  Saving model ...
	 Train_Loss: 0.4352 Train_Acc: 80.625 Val_Loss: 0.4366  BEST VAL Loss: 0.4366  Val_Acc: 80.014

Epoch 91: Validation loss decreased (0.436624 --> 0.436371).  Saving model ...
	 Train_Loss: 0.4349 Train_Acc: 80.566 Val_Loss: 0.4364  BEST VAL Loss: 0.4364  Val_Acc: 79.960

Epoch 92: Validation loss decreased (0.436371 --> 0.436109).  Saving model ...
	 Train_Loss: 0.4345 Train_Acc: 80.628 Val_Loss: 0.4361  BEST VAL Loss: 0.4361  Val_Acc: 80.010

Epoch 93: Validation loss decreased (0.436109 --> 0.435860).  Saving model ...
	 Train_Loss: 0.4342 Train_Acc: 80.681 Val_Loss: 0.4359  BEST VAL Loss: 0.4359  Val_Acc: 80.046

Epoch 94: Validation loss decreased (0.435860 --> 0.435596).  Saving model ...
	 Train_Loss: 0.4339 Train_Acc: 80.611 Val_Loss: 0.4356  BEST VAL Loss: 0.4356  Val_Acc: 80.200

Epoch 95: Validation loss decreased (0.435596 --> 0.435367).  Saving model ...
	 Train_Loss: 0.4336 Train_Acc: 80.645 Val_Loss: 0.4354  BEST VAL Loss: 0.4354  Val_Acc: 80.014

Epoch 96: Validation loss decreased (0.435367 --> 0.435127).  Saving model ...
	 Train_Loss: 0.4333 Train_Acc: 80.590 Val_Loss: 0.4351  BEST VAL Loss: 0.4351  Val_Acc: 80.105

Epoch 97: Validation loss decreased (0.435127 --> 0.434895).  Saving model ...
	 Train_Loss: 0.4330 Train_Acc: 80.666 Val_Loss: 0.4349  BEST VAL Loss: 0.4349  Val_Acc: 80.241

Epoch 98: Validation loss decreased (0.434895 --> 0.434653).  Saving model ...
	 Train_Loss: 0.4327 Train_Acc: 80.658 Val_Loss: 0.4347  BEST VAL Loss: 0.4347  Val_Acc: 80.209

Epoch 99: Validation loss decreased (0.434653 --> 0.434445).  Saving model ...
	 Train_Loss: 0.4323 Train_Acc: 80.710 Val_Loss: 0.4344  BEST VAL Loss: 0.4344  Val_Acc: 79.951

LPS_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.82      0.82      0.82     85026
           1       0.83      0.83      0.83     91898

    accuracy                           0.83    176924
   macro avg       0.83      0.83      0.83    176924
weighted avg       0.83      0.83      0.83    176924

LPS_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.79      0.79      0.79     10628
           1       0.81      0.81      0.81     11488

    accuracy                           0.80     22116
   macro avg       0.80      0.80      0.80     22116
weighted avg       0.80      0.80      0.80     22116

LPS_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.79      0.80      0.79     10629
           1       0.81      0.80      0.81     11487

    accuracy                           0.80     22116
   macro avg       0.80      0.80      0.80     22116
weighted avg       0.80      0.80      0.80     22116

              precision    recall  f1-score   support

           0       0.79      0.80      0.79     10629
           1       0.81      0.80      0.81     11487

    accuracy                           0.80     22116
   macro avg       0.80      0.80      0.80     22116
weighted avg       0.80      0.80      0.80     22116

LPS_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.50      0.46      0.48     36797
           1       0.56      0.60      0.58     41617

    accuracy                           0.53     78414
   macro avg       0.53      0.53      0.53     78414
weighted avg       0.53      0.53      0.53     78414

              precision    recall  f1-score   support

           0       0.50      0.46      0.48     36797
           1       0.56      0.60      0.58     41617

    accuracy                           0.53     78414
   macro avg       0.53      0.53      0.53     78414
weighted avg       0.53      0.53      0.53     78414

completed
