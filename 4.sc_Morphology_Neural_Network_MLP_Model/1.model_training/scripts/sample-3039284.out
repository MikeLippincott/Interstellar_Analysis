[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '3f42bb94'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '8830061b'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b660f5ff'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '9b0fb1b9'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_0.100_DMSO_0.025 treatment_name: H2O2_100.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: H2O2_100.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['H2O2_100.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (41828, 1276)
Number of total missing values across all columns: 83656
Data Subset Is Off
Wells held out for testing: ['I22' 'L22']
Wells to use for training, validation, and testing ['H18' 'H19' 'H22' 'H23' 'I18' 'L18' 'I19' 'L19' 'I23' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.579328).  Saving model ...
	 Train_Loss: 0.6818 Train_Acc: 53.984 Val_Loss: 0.5793  BEST VAL Loss: 0.5793  Val_Acc: 68.941

Epoch 1: Validation loss decreased (0.579328 --> 0.570965).  Saving model ...
	 Train_Loss: 0.6397 Train_Acc: 68.148 Val_Loss: 0.5710  BEST VAL Loss: 0.5710  Val_Acc: 68.941

Epoch 2: Validation loss decreased (0.570965 --> 0.564129).  Saving model ...
	 Train_Loss: 0.6182 Train_Acc: 68.925 Val_Loss: 0.5641  BEST VAL Loss: 0.5641  Val_Acc: 68.941

Epoch 3: Validation loss decreased (0.564129 --> 0.558945).  Saving model ...
	 Train_Loss: 0.6050 Train_Acc: 68.925 Val_Loss: 0.5589  BEST VAL Loss: 0.5589  Val_Acc: 68.941

Epoch 4: Validation loss decreased (0.558945 --> 0.554445).  Saving model ...
	 Train_Loss: 0.5958 Train_Acc: 68.925 Val_Loss: 0.5544  BEST VAL Loss: 0.5544  Val_Acc: 68.941

Epoch 5: Validation loss decreased (0.554445 --> 0.550785).  Saving model ...
	 Train_Loss: 0.5887 Train_Acc: 68.925 Val_Loss: 0.5508  BEST VAL Loss: 0.5508  Val_Acc: 68.941

Epoch 6: Validation loss decreased (0.550785 --> 0.547529).  Saving model ...
	 Train_Loss: 0.5828 Train_Acc: 68.925 Val_Loss: 0.5475  BEST VAL Loss: 0.5475  Val_Acc: 68.941

Epoch 7: Validation loss decreased (0.547529 --> 0.545145).  Saving model ...
	 Train_Loss: 0.5778 Train_Acc: 68.925 Val_Loss: 0.5451  BEST VAL Loss: 0.5451  Val_Acc: 68.941

Epoch 8: Validation loss decreased (0.545145 --> 0.543396).  Saving model ...
	 Train_Loss: 0.5738 Train_Acc: 68.925 Val_Loss: 0.5434  BEST VAL Loss: 0.5434  Val_Acc: 68.941

Epoch 9: Validation loss decreased (0.543396 --> 0.541660).  Saving model ...
	 Train_Loss: 0.5702 Train_Acc: 68.925 Val_Loss: 0.5417  BEST VAL Loss: 0.5417  Val_Acc: 68.941

Epoch 10: Validation loss decreased (0.541660 --> 0.540222).  Saving model ...
	 Train_Loss: 0.5671 Train_Acc: 68.925 Val_Loss: 0.5402  BEST VAL Loss: 0.5402  Val_Acc: 68.941

Epoch 11: Validation loss decreased (0.540222 --> 0.539020).  Saving model ...
	 Train_Loss: 0.5643 Train_Acc: 68.925 Val_Loss: 0.5390  BEST VAL Loss: 0.5390  Val_Acc: 68.941

Epoch 12: Validation loss decreased (0.539020 --> 0.538154).  Saving model ...
	 Train_Loss: 0.5615 Train_Acc: 68.925 Val_Loss: 0.5382  BEST VAL Loss: 0.5382  Val_Acc: 68.941

Epoch 13: Validation loss decreased (0.538154 --> 0.537546).  Saving model ...
	 Train_Loss: 0.5591 Train_Acc: 68.925 Val_Loss: 0.5375  BEST VAL Loss: 0.5375  Val_Acc: 68.941

Epoch 14: Validation loss decreased (0.537546 --> 0.536479).  Saving model ...
	 Train_Loss: 0.5568 Train_Acc: 68.925 Val_Loss: 0.5365  BEST VAL Loss: 0.5365  Val_Acc: 68.941

Epoch 15: Validation loss decreased (0.536479 --> 0.535608).  Saving model ...
	 Train_Loss: 0.5544 Train_Acc: 68.925 Val_Loss: 0.5356  BEST VAL Loss: 0.5356  Val_Acc: 68.941

Epoch 16: Validation loss decreased (0.535608 --> 0.534802).  Saving model ...
	 Train_Loss: 0.5523 Train_Acc: 68.925 Val_Loss: 0.5348  BEST VAL Loss: 0.5348  Val_Acc: 68.941

Epoch 17: Validation loss decreased (0.534802 --> 0.534123).  Saving model ...
	 Train_Loss: 0.5504 Train_Acc: 68.925 Val_Loss: 0.5341  BEST VAL Loss: 0.5341  Val_Acc: 68.941

Epoch 18: Validation loss decreased (0.534123 --> 0.533251).  Saving model ...
	 Train_Loss: 0.5483 Train_Acc: 68.760 Val_Loss: 0.5333  BEST VAL Loss: 0.5333  Val_Acc: 68.941

Epoch 19: Validation loss decreased (0.533251 --> 0.532815).  Saving model ...
	 Train_Loss: 0.5465 Train_Acc: 68.796 Val_Loss: 0.5328  BEST VAL Loss: 0.5328  Val_Acc: 68.941

Epoch 20: Validation loss decreased (0.532815 --> 0.532418).  Saving model ...
	 Train_Loss: 0.5448 Train_Acc: 68.490 Val_Loss: 0.5324  BEST VAL Loss: 0.5324  Val_Acc: 68.941

Epoch 21: Validation loss decreased (0.532418 --> 0.532005).  Saving model ...
	 Train_Loss: 0.5433 Train_Acc: 68.925 Val_Loss: 0.5320  BEST VAL Loss: 0.5320  Val_Acc: 68.941

Epoch 22: Validation loss decreased (0.532005 --> 0.531761).  Saving model ...
	 Train_Loss: 0.5418 Train_Acc: 68.925 Val_Loss: 0.5318  BEST VAL Loss: 0.5318  Val_Acc: 68.941

Epoch 23: Validation loss decreased (0.531761 --> 0.531551).  Saving model ...
	 Train_Loss: 0.5403 Train_Acc: 69.131 Val_Loss: 0.5316  BEST VAL Loss: 0.5316  Val_Acc: 71.589

Epoch 24: Validation loss decreased (0.531551 --> 0.531129).  Saving model ...
	 Train_Loss: 0.5389 Train_Acc: 68.763 Val_Loss: 0.5311  BEST VAL Loss: 0.5311  Val_Acc: 68.941

Epoch 25: Validation loss decreased (0.531129 --> 0.530633).  Saving model ...
	 Train_Loss: 0.5375 Train_Acc: 69.404 Val_Loss: 0.5306  BEST VAL Loss: 0.5306  Val_Acc: 72.136

Epoch 26: Validation loss decreased (0.530633 --> 0.530406).  Saving model ...
	 Train_Loss: 0.5362 Train_Acc: 69.494 Val_Loss: 0.5304  BEST VAL Loss: 0.5304  Val_Acc: 71.531

Epoch 27: Validation loss decreased (0.530406 --> 0.530006).  Saving model ...
	 Train_Loss: 0.5348 Train_Acc: 69.602 Val_Loss: 0.5300  BEST VAL Loss: 0.5300  Val_Acc: 72.021

Epoch 28: Validation loss decreased (0.530006 --> 0.529888).  Saving model ...
	 Train_Loss: 0.5336 Train_Acc: 69.728 Val_Loss: 0.5299  BEST VAL Loss: 0.5299  Val_Acc: 71.474

Epoch 29: Validation loss decreased (0.529888 --> 0.529628).  Saving model ...
	 Train_Loss: 0.5324 Train_Acc: 69.724 Val_Loss: 0.5296  BEST VAL Loss: 0.5296  Val_Acc: 72.827

Epoch 30: Validation loss decreased (0.529628 --> 0.529092).  Saving model ...
	 Train_Loss: 0.5313 Train_Acc: 70.286 Val_Loss: 0.5291  BEST VAL Loss: 0.5291  Val_Acc: 73.230

Epoch 31: Validation loss decreased (0.529092 --> 0.528742).  Saving model ...
	 Train_Loss: 0.5299 Train_Acc: 71.160 Val_Loss: 0.5287  BEST VAL Loss: 0.5287  Val_Acc: 73.086

Epoch 32: Validation loss decreased (0.528742 --> 0.528304).  Saving model ...
	 Train_Loss: 0.5284 Train_Acc: 74.169 Val_Loss: 0.5283  BEST VAL Loss: 0.5283  Val_Acc: 73.201

Epoch 33: Validation loss decreased (0.528304 --> 0.527797).  Saving model ...
	 Train_Loss: 0.5270 Train_Acc: 74.349 Val_Loss: 0.5278  BEST VAL Loss: 0.5278  Val_Acc: 73.201

Epoch 34: Validation loss decreased (0.527797 --> 0.527411).  Saving model ...
	 Train_Loss: 0.5255 Train_Acc: 75.166 Val_Loss: 0.5274  BEST VAL Loss: 0.5274  Val_Acc: 73.374

Epoch 35: Validation loss decreased (0.527411 --> 0.526789).  Saving model ...
	 Train_Loss: 0.5240 Train_Acc: 75.029 Val_Loss: 0.5268  BEST VAL Loss: 0.5268  Val_Acc: 73.518

Epoch 36: Validation loss decreased (0.526789 --> 0.526495).  Saving model ...
	 Train_Loss: 0.5225 Train_Acc: 75.133 Val_Loss: 0.5265  BEST VAL Loss: 0.5265  Val_Acc: 73.748

Epoch 37: Validation loss decreased (0.526495 --> 0.526232).  Saving model ...
	 Train_Loss: 0.5210 Train_Acc: 75.309 Val_Loss: 0.5262  BEST VAL Loss: 0.5262  Val_Acc: 73.230

Epoch 38: Validation loss decreased (0.526232 --> 0.525843).  Saving model ...
	 Train_Loss: 0.5196 Train_Acc: 75.342 Val_Loss: 0.5258  BEST VAL Loss: 0.5258  Val_Acc: 73.172

Epoch 39: Validation loss decreased (0.525843 --> 0.525584).  Saving model ...
	 Train_Loss: 0.5182 Train_Acc: 75.551 Val_Loss: 0.5256  BEST VAL Loss: 0.5256  Val_Acc: 73.489

Epoch 40: Validation loss decreased (0.525584 --> 0.525121).  Saving model ...
	 Train_Loss: 0.5170 Train_Acc: 75.576 Val_Loss: 0.5251  BEST VAL Loss: 0.5251  Val_Acc: 73.374

Epoch 41: Validation loss decreased (0.525121 --> 0.524990).  Saving model ...
	 Train_Loss: 0.5156 Train_Acc: 75.720 Val_Loss: 0.5250  BEST VAL Loss: 0.5250  Val_Acc: 73.028

Epoch 42: Validation loss decreased (0.524990 --> 0.524866).  Saving model ...
	 Train_Loss: 0.5143 Train_Acc: 75.871 Val_Loss: 0.5249  BEST VAL Loss: 0.5249  Val_Acc: 73.546

Epoch 43: Validation loss decreased (0.524866 --> 0.524662).  Saving model ...
	 Train_Loss: 0.5130 Train_Acc: 76.260 Val_Loss: 0.5247  BEST VAL Loss: 0.5247  Val_Acc: 73.575

Epoch 44: Validation loss decreased (0.524662 --> 0.524314).  Saving model ...
	 Train_Loss: 0.5117 Train_Acc: 76.177 Val_Loss: 0.5243  BEST VAL Loss: 0.5243  Val_Acc: 74.122

Epoch 45: Validation loss decreased (0.524314 --> 0.524060).  Saving model ...
	 Train_Loss: 0.5104 Train_Acc: 76.206 Val_Loss: 0.5241  BEST VAL Loss: 0.5241  Val_Acc: 73.287

Epoch 46: Validation loss decreased (0.524060 --> 0.523908).  Saving model ...
	 Train_Loss: 0.5091 Train_Acc: 76.457 Val_Loss: 0.5239  BEST VAL Loss: 0.5239  Val_Acc: 73.115

Epoch 47: Validation loss decreased (0.523908 --> 0.523613).  Saving model ...
	 Train_Loss: 0.5080 Train_Acc: 76.026 Val_Loss: 0.5236  BEST VAL Loss: 0.5236  Val_Acc: 73.748

Epoch 48: Validation loss decreased (0.523613 --> 0.523406).  Saving model ...
	 Train_Loss: 0.5068 Train_Acc: 76.558 Val_Loss: 0.5234  BEST VAL Loss: 0.5234  Val_Acc: 73.575

Epoch 49: Validation loss decreased (0.523406 --> 0.523186).  Saving model ...
	 Train_Loss: 0.5057 Train_Acc: 76.364 Val_Loss: 0.5232  BEST VAL Loss: 0.5232  Val_Acc: 73.575

Epoch 50: Validation loss decreased (0.523186 --> 0.522909).  Saving model ...
	 Train_Loss: 0.5046 Train_Acc: 76.627 Val_Loss: 0.5229  BEST VAL Loss: 0.5229  Val_Acc: 73.460

Epoch 51: Validation loss decreased (0.522909 --> 0.522754).  Saving model ...
	 Train_Loss: 0.5034 Train_Acc: 76.907 Val_Loss: 0.5228  BEST VAL Loss: 0.5228  Val_Acc: 73.489

Epoch 52: Validation loss decreased (0.522754 --> 0.522599).  Saving model ...
	 Train_Loss: 0.5022 Train_Acc: 76.724 Val_Loss: 0.5226  BEST VAL Loss: 0.5226  Val_Acc: 73.604

Epoch 53: Validation loss decreased (0.522599 --> 0.522412).  Saving model ...
	 Train_Loss: 0.5010 Train_Acc: 77.109 Val_Loss: 0.5224  BEST VAL Loss: 0.5224  Val_Acc: 73.518

Epoch 54: Validation loss decreased (0.522412 --> 0.522197).  Saving model ...
	 Train_Loss: 0.4999 Train_Acc: 77.019 Val_Loss: 0.5222  BEST VAL Loss: 0.5222  Val_Acc: 74.266

Epoch 55: Validation loss decreased (0.522197 --> 0.522064).  Saving model ...
	 Train_Loss: 0.4988 Train_Acc: 76.871 Val_Loss: 0.5221  BEST VAL Loss: 0.5221  Val_Acc: 73.402

Epoch 56: Validation loss decreased (0.522064 --> 0.521929).  Saving model ...
	 Train_Loss: 0.4979 Train_Acc: 76.853 Val_Loss: 0.5219  BEST VAL Loss: 0.5219  Val_Acc: 73.604

Epoch 57: Validation loss decreased (0.521929 --> 0.521874).  Saving model ...
	 Train_Loss: 0.4968 Train_Acc: 77.112 Val_Loss: 0.5219  BEST VAL Loss: 0.5219  Val_Acc: 73.690

Epoch 58: Validation loss decreased (0.521874 --> 0.521756).  Saving model ...
	 Train_Loss: 0.4959 Train_Acc: 76.990 Val_Loss: 0.5218  BEST VAL Loss: 0.5218  Val_Acc: 73.633

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.4948 Train_Acc: 77.282 Val_Loss: 0.5218  BEST VAL Loss: 0.5218  Val_Acc: 73.489

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.4939 Train_Acc: 77.177 Val_Loss: 0.5218  BEST VAL Loss: 0.5218  Val_Acc: 73.460

Epoch 61: Validation loss decreased (0.521756 --> 0.521647).  Saving model ...
	 Train_Loss: 0.4930 Train_Acc: 77.242 Val_Loss: 0.5216  BEST VAL Loss: 0.5216  Val_Acc: 73.661

Epoch 62: Validation loss decreased (0.521647 --> 0.521571).  Saving model ...
	 Train_Loss: 0.4920 Train_Acc: 77.156 Val_Loss: 0.5216  BEST VAL Loss: 0.5216  Val_Acc: 73.518

Epoch 63: Validation loss decreased (0.521571 --> 0.521498).  Saving model ...
	 Train_Loss: 0.4911 Train_Acc: 77.033 Val_Loss: 0.5215  BEST VAL Loss: 0.5215  Val_Acc: 73.230

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.4902 Train_Acc: 77.246 Val_Loss: 0.5216  BEST VAL Loss: 0.5215  Val_Acc: 73.057

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.4894 Train_Acc: 77.145 Val_Loss: 0.5215  BEST VAL Loss: 0.5215  Val_Acc: 73.230

Epoch 66: Validation loss decreased (0.521498 --> 0.521475).  Saving model ...
	 Train_Loss: 0.4885 Train_Acc: 77.271 Val_Loss: 0.5215  BEST VAL Loss: 0.5215  Val_Acc: 73.172

Epoch 67: Validation loss decreased (0.521475 --> 0.521427).  Saving model ...
	 Train_Loss: 0.4876 Train_Acc: 77.649 Val_Loss: 0.5214  BEST VAL Loss: 0.5214  Val_Acc: 73.402

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.4867 Train_Acc: 77.818 Val_Loss: 0.5214  BEST VAL Loss: 0.5214  Val_Acc: 73.460

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.4859 Train_Acc: 77.814 Val_Loss: 0.5215  BEST VAL Loss: 0.5214  Val_Acc: 73.748

Epoch 70: Validation loss decreased (0.521427 --> 0.521367).  Saving model ...
	 Train_Loss: 0.4850 Train_Acc: 77.685 Val_Loss: 0.5214  BEST VAL Loss: 0.5214  Val_Acc: 73.489

Epoch 71: Validation loss decreased (0.521367 --> 0.521328).  Saving model ...
	 Train_Loss: 0.4842 Train_Acc: 77.357 Val_Loss: 0.5213  BEST VAL Loss: 0.5213  Val_Acc: 73.690

Epoch 72: Validation loss decreased (0.521328 --> 0.521224).  Saving model ...
	 Train_Loss: 0.4835 Train_Acc: 77.195 Val_Loss: 0.5212  BEST VAL Loss: 0.5212  Val_Acc: 73.230

Epoch 73: Validation loss decreased (0.521224 --> 0.521148).  Saving model ...
	 Train_Loss: 0.4827 Train_Acc: 77.519 Val_Loss: 0.5211  BEST VAL Loss: 0.5211  Val_Acc: 73.230

Epoch 74: Validation loss decreased (0.521148 --> 0.521055).  Saving model ...
	 Train_Loss: 0.4819 Train_Acc: 77.688 Val_Loss: 0.5211  BEST VAL Loss: 0.5211  Val_Acc: 73.604

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.4811 Train_Acc: 77.785 Val_Loss: 0.5211  BEST VAL Loss: 0.5211  Val_Acc: 73.546

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.4803 Train_Acc: 78.228 Val_Loss: 0.5212  BEST VAL Loss: 0.5211  Val_Acc: 73.489

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.4795 Train_Acc: 77.569 Val_Loss: 0.5213  BEST VAL Loss: 0.5211  Val_Acc: 72.999

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.4788 Train_Acc: 77.695 Val_Loss: 0.5215  BEST VAL Loss: 0.5211  Val_Acc: 73.057

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.4780 Train_Acc: 78.034 Val_Loss: 0.5217  BEST VAL Loss: 0.5211  Val_Acc: 73.546

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.4772 Train_Acc: 77.706 Val_Loss: 0.5218  BEST VAL Loss: 0.5211  Val_Acc: 73.201

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.4765 Train_Acc: 78.109 Val_Loss: 0.5220  BEST VAL Loss: 0.5211  Val_Acc: 73.431

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.4758 Train_Acc: 78.239 Val_Loss: 0.5222  BEST VAL Loss: 0.5211  Val_Acc: 73.921

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.4751 Train_Acc: 78.077 Val_Loss: 0.5223  BEST VAL Loss: 0.5211  Val_Acc: 74.064

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.4744 Train_Acc: 77.886 Val_Loss: 0.5224  BEST VAL Loss: 0.5211  Val_Acc: 73.690

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.4737 Train_Acc: 77.875 Val_Loss: 0.5225  BEST VAL Loss: 0.5211  Val_Acc: 72.913

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.4730 Train_Acc: 77.767 Val_Loss: 0.5227  BEST VAL Loss: 0.5211  Val_Acc: 73.402

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.4723 Train_Acc: 78.336 Val_Loss: 0.5229  BEST VAL Loss: 0.5211  Val_Acc: 73.086

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.4716 Train_Acc: 78.257 Val_Loss: 0.5230  BEST VAL Loss: 0.5211  Val_Acc: 73.546

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.4709 Train_Acc: 78.228 Val_Loss: 0.5233  BEST VAL Loss: 0.5211  Val_Acc: 73.892

Epoch 90: Validation loss did not decrease
Early stopped at epoch : 90
Flagellin_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.87      0.55      0.67      8635
           1       0.82      0.96      0.89     19153

    accuracy                           0.83     27788
   macro avg       0.85      0.75      0.78     27788
weighted avg       0.84      0.83      0.82     27788

Flagellin_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.63      0.35      0.45      1079
           1       0.76      0.91      0.83      2395

    accuracy                           0.74      3474
   macro avg       0.70      0.63      0.64      3474
weighted avg       0.72      0.74      0.71      3474

Flagellin_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.66      0.36      0.47      1079
           1       0.76      0.92      0.83      2395

    accuracy                           0.74      3474
   macro avg       0.71      0.64      0.65      3474
weighted avg       0.73      0.74      0.72      3474

              precision    recall  f1-score   support

           0       0.66      0.36      0.47      1079
           1       0.76      0.92      0.83      2395

    accuracy                           0.74      3474
   macro avg       0.71      0.64      0.65      3474
weighted avg       0.73      0.74      0.72      3474

Flagellin_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.95      0.29      0.45      4135
           1       0.50      0.98      0.66      2957

    accuracy                           0.58      7092
   macro avg       0.72      0.63      0.55      7092
weighted avg       0.76      0.58      0.53      7092

              precision    recall  f1-score   support

           0       0.95      0.29      0.45      4135
           1       0.50      0.98      0.66      2957

    accuracy                           0.58      7092
   macro avg       0.72      0.63      0.55      7092
weighted avg       0.76      0.58      0.53      7092

completed
