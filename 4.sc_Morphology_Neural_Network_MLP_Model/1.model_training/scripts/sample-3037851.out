[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '9e6a263c'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '05c96fd1'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'f7a265aa'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'fe612d92'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Thapsigargin_1.000_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Thapsigargin_1.000_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (244371, 1270)
Number of total missing values across all columns: 488742
Data Subset Is Off
Wells held out for testing: ['K07' 'L10']
Wells to use for training, validation, and testing ['D06' 'D07' 'K06' 'L05' 'L11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.653417).  Saving model ...
	 Train_Loss: 0.6616 Train_Acc: 62.601 Val_Loss: 0.6534  BEST VAL Loss: 0.6534  Val_Acc: 63.571

Epoch 1: Validation loss decreased (0.653417 --> 0.645600).  Saving model ...
	 Train_Loss: 0.6554 Train_Acc: 63.572 Val_Loss: 0.6456  BEST VAL Loss: 0.6456  Val_Acc: 63.571

Epoch 2: Validation loss decreased (0.645600 --> 0.627625).  Saving model ...
	 Train_Loss: 0.6453 Train_Acc: 63.572 Val_Loss: 0.6276  BEST VAL Loss: 0.6276  Val_Acc: 63.571

Epoch 3: Validation loss decreased (0.627625 --> 0.610018).  Saving model ...
	 Train_Loss: 0.6331 Train_Acc: 63.572 Val_Loss: 0.6100  BEST VAL Loss: 0.6100  Val_Acc: 63.571

Epoch 4: Validation loss decreased (0.610018 --> 0.594181).  Saving model ...
	 Train_Loss: 0.6214 Train_Acc: 67.300 Val_Loss: 0.5942  BEST VAL Loss: 0.5942  Val_Acc: 73.772

Epoch 5: Validation loss decreased (0.594181 --> 0.581360).  Saving model ...
	 Train_Loss: 0.6112 Train_Acc: 71.143 Val_Loss: 0.5814  BEST VAL Loss: 0.5814  Val_Acc: 74.471

Epoch 6: Validation loss decreased (0.581360 --> 0.569435).  Saving model ...
	 Train_Loss: 0.6018 Train_Acc: 72.504 Val_Loss: 0.5694  BEST VAL Loss: 0.5694  Val_Acc: 76.506

Epoch 7: Validation loss decreased (0.569435 --> 0.558847).  Saving model ...
	 Train_Loss: 0.5935 Train_Acc: 73.315 Val_Loss: 0.5588  BEST VAL Loss: 0.5588  Val_Acc: 77.378

Epoch 8: Validation loss decreased (0.558847 --> 0.549666).  Saving model ...
	 Train_Loss: 0.5859 Train_Acc: 74.039 Val_Loss: 0.5497  BEST VAL Loss: 0.5497  Val_Acc: 78.107

Epoch 9: Validation loss decreased (0.549666 --> 0.540475).  Saving model ...
	 Train_Loss: 0.5790 Train_Acc: 74.653 Val_Loss: 0.5405  BEST VAL Loss: 0.5405  Val_Acc: 79.349

Epoch 10: Validation loss decreased (0.540475 --> 0.533362).  Saving model ...
	 Train_Loss: 0.5726 Train_Acc: 75.352 Val_Loss: 0.5334  BEST VAL Loss: 0.5334  Val_Acc: 78.575

Epoch 11: Validation loss decreased (0.533362 --> 0.527890).  Saving model ...
	 Train_Loss: 0.5668 Train_Acc: 75.647 Val_Loss: 0.5279  BEST VAL Loss: 0.5279  Val_Acc: 77.875

Epoch 12: Validation loss decreased (0.527890 --> 0.521716).  Saving model ...
	 Train_Loss: 0.5614 Train_Acc: 76.147 Val_Loss: 0.5217  BEST VAL Loss: 0.5217  Val_Acc: 79.101

Epoch 13: Validation loss decreased (0.521716 --> 0.515929).  Saving model ...
	 Train_Loss: 0.5564 Train_Acc: 76.530 Val_Loss: 0.5159  BEST VAL Loss: 0.5159  Val_Acc: 80.072

Epoch 14: Validation loss decreased (0.515929 --> 0.510623).  Saving model ...
	 Train_Loss: 0.5520 Train_Acc: 76.837 Val_Loss: 0.5106  BEST VAL Loss: 0.5106  Val_Acc: 80.494

Epoch 15: Validation loss decreased (0.510623 --> 0.505269).  Saving model ...
	 Train_Loss: 0.5476 Train_Acc: 77.197 Val_Loss: 0.5053  BEST VAL Loss: 0.5053  Val_Acc: 80.881

Epoch 16: Validation loss decreased (0.505269 --> 0.500453).  Saving model ...
	 Train_Loss: 0.5437 Train_Acc: 77.374 Val_Loss: 0.5005  BEST VAL Loss: 0.5005  Val_Acc: 81.453

Epoch 17: Validation loss decreased (0.500453 --> 0.497284).  Saving model ...
	 Train_Loss: 0.5400 Train_Acc: 77.648 Val_Loss: 0.4973  BEST VAL Loss: 0.4973  Val_Acc: 79.702

Epoch 18: Validation loss decreased (0.497284 --> 0.493503).  Saving model ...
	 Train_Loss: 0.5365 Train_Acc: 77.944 Val_Loss: 0.4935  BEST VAL Loss: 0.4935  Val_Acc: 80.904

Epoch 19: Validation loss decreased (0.493503 --> 0.490109).  Saving model ...
	 Train_Loss: 0.5331 Train_Acc: 77.960 Val_Loss: 0.4901  BEST VAL Loss: 0.4901  Val_Acc: 81.210

Epoch 20: Validation loss decreased (0.490109 --> 0.486368).  Saving model ...
	 Train_Loss: 0.5301 Train_Acc: 77.872 Val_Loss: 0.4864  BEST VAL Loss: 0.4864  Val_Acc: 81.956

Epoch 21: Validation loss decreased (0.486368 --> 0.483195).  Saving model ...
	 Train_Loss: 0.5271 Train_Acc: 78.343 Val_Loss: 0.4832  BEST VAL Loss: 0.4832  Val_Acc: 81.413

Epoch 22: Validation loss decreased (0.483195 --> 0.479944).  Saving model ...
	 Train_Loss: 0.5244 Train_Acc: 78.124 Val_Loss: 0.4799  BEST VAL Loss: 0.4799  Val_Acc: 82.054

Epoch 23: Validation loss decreased (0.479944 --> 0.476894).  Saving model ...
	 Train_Loss: 0.5218 Train_Acc: 78.385 Val_Loss: 0.4769  BEST VAL Loss: 0.4769  Val_Acc: 81.765

Epoch 24: Validation loss decreased (0.476894 --> 0.474217).  Saving model ...
	 Train_Loss: 0.5193 Train_Acc: 78.343 Val_Loss: 0.4742  BEST VAL Loss: 0.4742  Val_Acc: 81.725

Epoch 25: Validation loss decreased (0.474217 --> 0.471743).  Saving model ...
	 Train_Loss: 0.5169 Train_Acc: 78.476 Val_Loss: 0.4717  BEST VAL Loss: 0.4717  Val_Acc: 82.181

Epoch 26: Validation loss decreased (0.471743 --> 0.468987).  Saving model ...
	 Train_Loss: 0.5145 Train_Acc: 78.703 Val_Loss: 0.4690  BEST VAL Loss: 0.4690  Val_Acc: 82.777

Epoch 27: Validation loss decreased (0.468987 --> 0.466507).  Saving model ...
	 Train_Loss: 0.5123 Train_Acc: 78.757 Val_Loss: 0.4665  BEST VAL Loss: 0.4665  Val_Acc: 82.777

Epoch 28: Validation loss decreased (0.466507 --> 0.464177).  Saving model ...
	 Train_Loss: 0.5102 Train_Acc: 78.817 Val_Loss: 0.4642  BEST VAL Loss: 0.4642  Val_Acc: 82.412

Epoch 29: Validation loss decreased (0.464177 --> 0.461998).  Saving model ...
	 Train_Loss: 0.5082 Train_Acc: 78.856 Val_Loss: 0.4620  BEST VAL Loss: 0.4620  Val_Acc: 82.909

Epoch 30: Validation loss decreased (0.461998 --> 0.459653).  Saving model ...
	 Train_Loss: 0.5063 Train_Acc: 79.052 Val_Loss: 0.4597  BEST VAL Loss: 0.4597  Val_Acc: 83.123

Epoch 31: Validation loss decreased (0.459653 --> 0.457666).  Saving model ...
	 Train_Loss: 0.5045 Train_Acc: 79.043 Val_Loss: 0.4577  BEST VAL Loss: 0.4577  Val_Acc: 82.846

Epoch 32: Validation loss decreased (0.457666 --> 0.455850).  Saving model ...
	 Train_Loss: 0.5027 Train_Acc: 79.051 Val_Loss: 0.4559  BEST VAL Loss: 0.4559  Val_Acc: 82.649

Epoch 33: Validation loss decreased (0.455850 --> 0.454308).  Saving model ...
	 Train_Loss: 0.5010 Train_Acc: 78.995 Val_Loss: 0.4543  BEST VAL Loss: 0.4543  Val_Acc: 82.736

Epoch 34: Validation loss decreased (0.454308 --> 0.452682).  Saving model ...
	 Train_Loss: 0.4994 Train_Acc: 79.220 Val_Loss: 0.4527  BEST VAL Loss: 0.4527  Val_Acc: 82.805

Epoch 35: Validation loss decreased (0.452682 --> 0.451511).  Saving model ...
	 Train_Loss: 0.4978 Train_Acc: 79.259 Val_Loss: 0.4515  BEST VAL Loss: 0.4515  Val_Acc: 81.598

Epoch 36: Validation loss decreased (0.451511 --> 0.449771).  Saving model ...
	 Train_Loss: 0.4963 Train_Acc: 79.223 Val_Loss: 0.4498  BEST VAL Loss: 0.4498  Val_Acc: 83.638

Epoch 37: Validation loss decreased (0.449771 --> 0.448258).  Saving model ...
	 Train_Loss: 0.4948 Train_Acc: 79.343 Val_Loss: 0.4483  BEST VAL Loss: 0.4483  Val_Acc: 83.054

Epoch 38: Validation loss decreased (0.448258 --> 0.446729).  Saving model ...
	 Train_Loss: 0.4933 Train_Acc: 79.657 Val_Loss: 0.4467  BEST VAL Loss: 0.4467  Val_Acc: 83.395

Epoch 39: Validation loss decreased (0.446729 --> 0.445177).  Saving model ...
	 Train_Loss: 0.4919 Train_Acc: 79.522 Val_Loss: 0.4452  BEST VAL Loss: 0.4452  Val_Acc: 83.418

Epoch 40: Validation loss decreased (0.445177 --> 0.443860).  Saving model ...
	 Train_Loss: 0.4906 Train_Acc: 79.587 Val_Loss: 0.4439  BEST VAL Loss: 0.4439  Val_Acc: 83.152

Epoch 41: Validation loss decreased (0.443860 --> 0.442483).  Saving model ...
	 Train_Loss: 0.4893 Train_Acc: 79.617 Val_Loss: 0.4425  BEST VAL Loss: 0.4425  Val_Acc: 83.337

Epoch 42: Validation loss decreased (0.442483 --> 0.441244).  Saving model ...
	 Train_Loss: 0.4880 Train_Acc: 79.652 Val_Loss: 0.4412  BEST VAL Loss: 0.4412  Val_Acc: 83.233

Epoch 43: Validation loss decreased (0.441244 --> 0.440131).  Saving model ...
	 Train_Loss: 0.4868 Train_Acc: 79.637 Val_Loss: 0.4401  BEST VAL Loss: 0.4401  Val_Acc: 82.985

Epoch 44: Validation loss decreased (0.440131 --> 0.439071).  Saving model ...
	 Train_Loss: 0.4856 Train_Acc: 79.818 Val_Loss: 0.4391  BEST VAL Loss: 0.4391  Val_Acc: 82.811

Epoch 45: Validation loss decreased (0.439071 --> 0.438061).  Saving model ...
	 Train_Loss: 0.4844 Train_Acc: 79.907 Val_Loss: 0.4381  BEST VAL Loss: 0.4381  Val_Acc: 83.152

Epoch 46: Validation loss decreased (0.438061 --> 0.437280).  Saving model ...
	 Train_Loss: 0.4833 Train_Acc: 79.939 Val_Loss: 0.4373  BEST VAL Loss: 0.4373  Val_Acc: 82.696

Epoch 47: Validation loss decreased (0.437280 --> 0.436289).  Saving model ...
	 Train_Loss: 0.4822 Train_Acc: 79.917 Val_Loss: 0.4363  BEST VAL Loss: 0.4363  Val_Acc: 83.025

Epoch 48: Validation loss decreased (0.436289 --> 0.435137).  Saving model ...
	 Train_Loss: 0.4812 Train_Acc: 79.952 Val_Loss: 0.4351  BEST VAL Loss: 0.4351  Val_Acc: 83.551

Epoch 49: Validation loss decreased (0.435137 --> 0.434232).  Saving model ...
	 Train_Loss: 0.4801 Train_Acc: 79.926 Val_Loss: 0.4342  BEST VAL Loss: 0.4342  Val_Acc: 82.938

Epoch 50: Validation loss decreased (0.434232 --> 0.433103).  Saving model ...
	 Train_Loss: 0.4791 Train_Acc: 80.035 Val_Loss: 0.4331  BEST VAL Loss: 0.4331  Val_Acc: 83.927

Epoch 51: Validation loss decreased (0.433103 --> 0.432115).  Saving model ...
	 Train_Loss: 0.4781 Train_Acc: 80.114 Val_Loss: 0.4321  BEST VAL Loss: 0.4321  Val_Acc: 83.678

Epoch 52: Validation loss decreased (0.432115 --> 0.431178).  Saving model ...
	 Train_Loss: 0.4772 Train_Acc: 80.261 Val_Loss: 0.4312  BEST VAL Loss: 0.4312  Val_Acc: 83.424

Epoch 53: Validation loss decreased (0.431178 --> 0.430187).  Saving model ...
	 Train_Loss: 0.4762 Train_Acc: 80.228 Val_Loss: 0.4302  BEST VAL Loss: 0.4302  Val_Acc: 83.880

Epoch 54: Validation loss decreased (0.430187 --> 0.429428).  Saving model ...
	 Train_Loss: 0.4753 Train_Acc: 80.367 Val_Loss: 0.4294  BEST VAL Loss: 0.4294  Val_Acc: 83.395

Epoch 55: Validation loss decreased (0.429428 --> 0.428610).  Saving model ...
	 Train_Loss: 0.4743 Train_Acc: 80.415 Val_Loss: 0.4286  BEST VAL Loss: 0.4286  Val_Acc: 83.776

Epoch 56: Validation loss decreased (0.428610 --> 0.427748).  Saving model ...
	 Train_Loss: 0.4735 Train_Acc: 80.243 Val_Loss: 0.4277  BEST VAL Loss: 0.4277  Val_Acc: 83.794

Epoch 57: Validation loss decreased (0.427748 --> 0.427034).  Saving model ...
	 Train_Loss: 0.4726 Train_Acc: 80.631 Val_Loss: 0.4270  BEST VAL Loss: 0.4270  Val_Acc: 83.372

Epoch 58: Validation loss decreased (0.427034 --> 0.426213).  Saving model ...
	 Train_Loss: 0.4717 Train_Acc: 80.315 Val_Loss: 0.4262  BEST VAL Loss: 0.4262  Val_Acc: 83.678

Epoch 59: Validation loss decreased (0.426213 --> 0.425737).  Saving model ...
	 Train_Loss: 0.4709 Train_Acc: 80.310 Val_Loss: 0.4257  BEST VAL Loss: 0.4257  Val_Acc: 82.794

Epoch 60: Validation loss decreased (0.425737 --> 0.425092).  Saving model ...
	 Train_Loss: 0.4701 Train_Acc: 80.415 Val_Loss: 0.4251  BEST VAL Loss: 0.4251  Val_Acc: 83.811

Epoch 61: Validation loss decreased (0.425092 --> 0.424353).  Saving model ...
	 Train_Loss: 0.4693 Train_Acc: 80.390 Val_Loss: 0.4244  BEST VAL Loss: 0.4244  Val_Acc: 83.840

Epoch 62: Validation loss decreased (0.424353 --> 0.423603).  Saving model ...
	 Train_Loss: 0.4685 Train_Acc: 80.599 Val_Loss: 0.4236  BEST VAL Loss: 0.4236  Val_Acc: 83.944

Epoch 63: Validation loss decreased (0.423603 --> 0.423070).  Saving model ...
	 Train_Loss: 0.4678 Train_Acc: 80.549 Val_Loss: 0.4231  BEST VAL Loss: 0.4231  Val_Acc: 82.886

Epoch 64: Validation loss decreased (0.423070 --> 0.422542).  Saving model ...
	 Train_Loss: 0.4670 Train_Acc: 80.578 Val_Loss: 0.4225  BEST VAL Loss: 0.4225  Val_Acc: 83.528

Epoch 65: Validation loss decreased (0.422542 --> 0.421843).  Saving model ...
	 Train_Loss: 0.4663 Train_Acc: 80.558 Val_Loss: 0.4218  BEST VAL Loss: 0.4218  Val_Acc: 84.210

Epoch 66: Validation loss decreased (0.421843 --> 0.421115).  Saving model ...
	 Train_Loss: 0.4656 Train_Acc: 80.665 Val_Loss: 0.4211  BEST VAL Loss: 0.4211  Val_Acc: 84.262

Epoch 67: Validation loss decreased (0.421115 --> 0.420515).  Saving model ...
	 Train_Loss: 0.4649 Train_Acc: 80.604 Val_Loss: 0.4205  BEST VAL Loss: 0.4205  Val_Acc: 84.181

Epoch 68: Validation loss decreased (0.420515 --> 0.419887).  Saving model ...
	 Train_Loss: 0.4642 Train_Acc: 80.549 Val_Loss: 0.4199  BEST VAL Loss: 0.4199  Val_Acc: 84.175

Epoch 69: Validation loss decreased (0.419887 --> 0.419257).  Saving model ...
	 Train_Loss: 0.4636 Train_Acc: 80.645 Val_Loss: 0.4193  BEST VAL Loss: 0.4193  Val_Acc: 84.395

Epoch 70: Validation loss decreased (0.419257 --> 0.418628).  Saving model ...
	 Train_Loss: 0.4629 Train_Acc: 80.608 Val_Loss: 0.4186  BEST VAL Loss: 0.4186  Val_Acc: 84.135

Epoch 71: Validation loss decreased (0.418628 --> 0.418073).  Saving model ...
	 Train_Loss: 0.4623 Train_Acc: 80.616 Val_Loss: 0.4181  BEST VAL Loss: 0.4181  Val_Acc: 83.869

Epoch 72: Validation loss decreased (0.418073 --> 0.417581).  Saving model ...
	 Train_Loss: 0.4617 Train_Acc: 80.758 Val_Loss: 0.4176  BEST VAL Loss: 0.4176  Val_Acc: 83.898

Epoch 73: Validation loss decreased (0.417581 --> 0.417041).  Saving model ...
	 Train_Loss: 0.4610 Train_Acc: 80.884 Val_Loss: 0.4170  BEST VAL Loss: 0.4170  Val_Acc: 83.921

Epoch 74: Validation loss decreased (0.417041 --> 0.416433).  Saving model ...
	 Train_Loss: 0.4604 Train_Acc: 80.910 Val_Loss: 0.4164  BEST VAL Loss: 0.4164  Val_Acc: 84.395

Epoch 75: Validation loss decreased (0.416433 --> 0.415856).  Saving model ...
	 Train_Loss: 0.4598 Train_Acc: 80.576 Val_Loss: 0.4159  BEST VAL Loss: 0.4159  Val_Acc: 83.996

Epoch 76: Validation loss decreased (0.415856 --> 0.415360).  Saving model ...
	 Train_Loss: 0.4592 Train_Acc: 80.832 Val_Loss: 0.4154  BEST VAL Loss: 0.4154  Val_Acc: 84.019

Epoch 77: Validation loss decreased (0.415360 --> 0.414833).  Saving model ...
	 Train_Loss: 0.4587 Train_Acc: 80.780 Val_Loss: 0.4148  BEST VAL Loss: 0.4148  Val_Acc: 84.522

Epoch 78: Validation loss decreased (0.414833 --> 0.414355).  Saving model ...
	 Train_Loss: 0.4581 Train_Acc: 80.888 Val_Loss: 0.4144  BEST VAL Loss: 0.4144  Val_Acc: 84.175

Epoch 79: Validation loss decreased (0.414355 --> 0.413839).  Saving model ...
	 Train_Loss: 0.4575 Train_Acc: 80.728 Val_Loss: 0.4138  BEST VAL Loss: 0.4138  Val_Acc: 83.979

Epoch 80: Validation loss decreased (0.413839 --> 0.413322).  Saving model ...
	 Train_Loss: 0.4570 Train_Acc: 80.821 Val_Loss: 0.4133  BEST VAL Loss: 0.4133  Val_Acc: 84.493

Epoch 81: Validation loss decreased (0.413322 --> 0.412854).  Saving model ...
	 Train_Loss: 0.4565 Train_Acc: 80.943 Val_Loss: 0.4129  BEST VAL Loss: 0.4129  Val_Acc: 84.291

Epoch 82: Validation loss decreased (0.412854 --> 0.412425).  Saving model ...
	 Train_Loss: 0.4560 Train_Acc: 80.832 Val_Loss: 0.4124  BEST VAL Loss: 0.4124  Val_Acc: 84.141

Epoch 83: Validation loss decreased (0.412425 --> 0.412096).  Saving model ...
	 Train_Loss: 0.4555 Train_Acc: 80.840 Val_Loss: 0.4121  BEST VAL Loss: 0.4121  Val_Acc: 83.684

Epoch 84: Validation loss decreased (0.412096 --> 0.411686).  Saving model ...
	 Train_Loss: 0.4550 Train_Acc: 80.902 Val_Loss: 0.4117  BEST VAL Loss: 0.4117  Val_Acc: 83.956

Epoch 85: Validation loss decreased (0.411686 --> 0.411251).  Saving model ...
	 Train_Loss: 0.4544 Train_Acc: 81.011 Val_Loss: 0.4113  BEST VAL Loss: 0.4113  Val_Acc: 84.389

Epoch 86: Validation loss decreased (0.411251 --> 0.410770).  Saving model ...
	 Train_Loss: 0.4539 Train_Acc: 80.952 Val_Loss: 0.4108  BEST VAL Loss: 0.4108  Val_Acc: 84.487

Epoch 87: Validation loss decreased (0.410770 --> 0.410471).  Saving model ...
	 Train_Loss: 0.4535 Train_Acc: 80.910 Val_Loss: 0.4105  BEST VAL Loss: 0.4105  Val_Acc: 83.389

Epoch 88: Validation loss decreased (0.410471 --> 0.410016).  Saving model ...
	 Train_Loss: 0.4530 Train_Acc: 81.035 Val_Loss: 0.4100  BEST VAL Loss: 0.4100  Val_Acc: 84.337

Epoch 89: Validation loss decreased (0.410016 --> 0.409583).  Saving model ...
	 Train_Loss: 0.4525 Train_Acc: 81.019 Val_Loss: 0.4096  BEST VAL Loss: 0.4096  Val_Acc: 84.458

Epoch 90: Validation loss decreased (0.409583 --> 0.409163).  Saving model ...
	 Train_Loss: 0.4521 Train_Acc: 81.089 Val_Loss: 0.4092  BEST VAL Loss: 0.4092  Val_Acc: 84.013

Epoch 91: Validation loss decreased (0.409163 --> 0.408733).  Saving model ...
	 Train_Loss: 0.4516 Train_Acc: 81.048 Val_Loss: 0.4087  BEST VAL Loss: 0.4087  Val_Acc: 84.250

Epoch 92: Validation loss decreased (0.408733 --> 0.408356).  Saving model ...
	 Train_Loss: 0.4512 Train_Acc: 81.040 Val_Loss: 0.4084  BEST VAL Loss: 0.4084  Val_Acc: 84.002

Epoch 93: Validation loss decreased (0.408356 --> 0.408157).  Saving model ...
	 Train_Loss: 0.4507 Train_Acc: 81.177 Val_Loss: 0.4082  BEST VAL Loss: 0.4082  Val_Acc: 83.187

Epoch 94: Validation loss decreased (0.408157 --> 0.407795).  Saving model ...
	 Train_Loss: 0.4503 Train_Acc: 81.146 Val_Loss: 0.4078  BEST VAL Loss: 0.4078  Val_Acc: 84.476

Epoch 95: Validation loss decreased (0.407795 --> 0.407411).  Saving model ...
	 Train_Loss: 0.4498 Train_Acc: 81.143 Val_Loss: 0.4074  BEST VAL Loss: 0.4074  Val_Acc: 84.158

Epoch 96: Validation loss decreased (0.407411 --> 0.407070).  Saving model ...
	 Train_Loss: 0.4494 Train_Acc: 81.205 Val_Loss: 0.4071  BEST VAL Loss: 0.4071  Val_Acc: 83.713

Epoch 97: Validation loss decreased (0.407070 --> 0.406685).  Saving model ...
	 Train_Loss: 0.4490 Train_Acc: 80.983 Val_Loss: 0.4067  BEST VAL Loss: 0.4067  Val_Acc: 84.482

Epoch 98: Validation loss decreased (0.406685 --> 0.406288).  Saving model ...
	 Train_Loss: 0.4486 Train_Acc: 81.160 Val_Loss: 0.4063  BEST VAL Loss: 0.4063  Val_Acc: 84.406

Epoch 99: Validation loss decreased (0.406288 --> 0.405980).  Saving model ...
	 Train_Loss: 0.4482 Train_Acc: 81.106 Val_Loss: 0.4060  BEST VAL Loss: 0.4060  Val_Acc: 84.233

Thapsigargin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.36      0.36      0.36     50422
           1       0.64      0.64      0.64     87993

    accuracy                           0.54    138415
   macro avg       0.50      0.50      0.50    138415
weighted avg       0.54      0.54      0.54    138415

Thapsigargin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.37      0.36      0.36      6303
           1       0.64      0.64      0.64     10999

    accuracy                           0.54     17302
   macro avg       0.50      0.50      0.50     17302
weighted avg       0.54      0.54      0.54     17302

Thapsigargin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.36      0.36      0.36      6303
           1       0.64      0.64      0.64     10999

    accuracy                           0.54     17302
   macro avg       0.50      0.50      0.50     17302
weighted avg       0.54      0.54      0.54     17302

              precision    recall  f1-score   support

           0       0.36      0.36      0.36      6303
           1       0.64      0.64      0.64     10999

    accuracy                           0.54     17302
   macro avg       0.50      0.50      0.50     17302
weighted avg       0.54      0.54      0.54     17302

Thapsigargin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.44      0.45     32887
           1       0.54      0.56      0.55     38465

    accuracy                           0.50     71352
   macro avg       0.50      0.50      0.50     71352
weighted avg       0.50      0.50      0.50     71352

              precision    recall  f1-score   support

           0       0.46      0.44      0.45     32887
           1       0.54      0.56      0.55     38465

    accuracy                           0.50     71352
   macro avg       0.50      0.50      0.50     71352
weighted avg       0.50      0.50      0.50     71352

completed
