[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '6623d6ae'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'b7f717de'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'f018b849'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'af5bc2ca'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: DMSO_0.100_DMSO_0.025 treatment_name: LPS_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: DMSO_0.100_DMSO_0.025
TREATMENT_NAME: LPS_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'LPS_1.000_DMSO_0.025']
The dimensions of the data are: (52101, 1276)
Number of total missing values across all columns: 104202
Data Subset Is Off
Wells held out for testing: ['D20' 'I14']
Wells to use for training, validation, and testing ['B14' 'C14' 'B15' 'C15' 'D16' 'D17' 'D21' 'J14' 'I15' 'J15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.525281).  Saving model ...
	 Train_Loss: 0.5842 Train_Acc: 68.369 Val_Loss: 0.5253  BEST VAL Loss: 0.5253  Val_Acc: 73.968

Epoch 1: Validation loss decreased (0.525281 --> 0.514119).  Saving model ...
	 Train_Loss: 0.5555 Train_Acc: 74.002 Val_Loss: 0.5141  BEST VAL Loss: 0.5141  Val_Acc: 75.684

Epoch 2: Validation loss decreased (0.514119 --> 0.507425).  Saving model ...
	 Train_Loss: 0.5403 Train_Acc: 74.838 Val_Loss: 0.5074  BEST VAL Loss: 0.5074  Val_Acc: 75.615

Epoch 3: Validation loss decreased (0.507425 --> 0.503231).  Saving model ...
	 Train_Loss: 0.5302 Train_Acc: 75.241 Val_Loss: 0.5032  BEST VAL Loss: 0.5032  Val_Acc: 76.427

Epoch 4: Validation loss decreased (0.503231 --> 0.499715).  Saving model ...
	 Train_Loss: 0.5222 Train_Acc: 75.725 Val_Loss: 0.4997  BEST VAL Loss: 0.4997  Val_Acc: 76.288

Epoch 5: Validation loss decreased (0.499715 --> 0.496946).  Saving model ...
	 Train_Loss: 0.5161 Train_Acc: 75.911 Val_Loss: 0.4969  BEST VAL Loss: 0.4969  Val_Acc: 76.752

Epoch 6: Validation loss decreased (0.496946 --> 0.494694).  Saving model ...
	 Train_Loss: 0.5110 Train_Acc: 76.175 Val_Loss: 0.4947  BEST VAL Loss: 0.4947  Val_Acc: 76.937

Epoch 7: Validation loss decreased (0.494694 --> 0.492569).  Saving model ...
	 Train_Loss: 0.5070 Train_Acc: 76.140 Val_Loss: 0.4926  BEST VAL Loss: 0.4926  Val_Acc: 76.589

Epoch 8: Validation loss decreased (0.492569 --> 0.490881).  Saving model ...
	 Train_Loss: 0.5031 Train_Acc: 76.471 Val_Loss: 0.4909  BEST VAL Loss: 0.4909  Val_Acc: 76.450

Epoch 9: Validation loss decreased (0.490881 --> 0.489415).  Saving model ...
	 Train_Loss: 0.4998 Train_Acc: 76.592 Val_Loss: 0.4894  BEST VAL Loss: 0.4894  Val_Acc: 76.729

Epoch 10: Validation loss decreased (0.489415 --> 0.487987).  Saving model ...
	 Train_Loss: 0.4967 Train_Acc: 76.624 Val_Loss: 0.4880  BEST VAL Loss: 0.4880  Val_Acc: 77.262

Epoch 11: Validation loss decreased (0.487987 --> 0.486529).  Saving model ...
	 Train_Loss: 0.4937 Train_Acc: 76.952 Val_Loss: 0.4865  BEST VAL Loss: 0.4865  Val_Acc: 76.729

Epoch 12: Validation loss decreased (0.486529 --> 0.485183).  Saving model ...
	 Train_Loss: 0.4911 Train_Acc: 76.819 Val_Loss: 0.4852  BEST VAL Loss: 0.4852  Val_Acc: 76.845

Epoch 13: Validation loss decreased (0.485183 --> 0.484001).  Saving model ...
	 Train_Loss: 0.4886 Train_Acc: 77.222 Val_Loss: 0.4840  BEST VAL Loss: 0.4840  Val_Acc: 77.193

Epoch 14: Validation loss decreased (0.484001 --> 0.482964).  Saving model ...
	 Train_Loss: 0.4865 Train_Acc: 77.149 Val_Loss: 0.4830  BEST VAL Loss: 0.4830  Val_Acc: 77.216

Epoch 15: Validation loss decreased (0.482964 --> 0.482158).  Saving model ...
	 Train_Loss: 0.4844 Train_Acc: 77.268 Val_Loss: 0.4822  BEST VAL Loss: 0.4822  Val_Acc: 77.007

Epoch 16: Validation loss decreased (0.482158 --> 0.481127).  Saving model ...
	 Train_Loss: 0.4823 Train_Acc: 77.280 Val_Loss: 0.4811  BEST VAL Loss: 0.4811  Val_Acc: 77.448

Epoch 17: Validation loss decreased (0.481127 --> 0.480413).  Saving model ...
	 Train_Loss: 0.4805 Train_Acc: 77.045 Val_Loss: 0.4804  BEST VAL Loss: 0.4804  Val_Acc: 77.401

Epoch 18: Validation loss decreased (0.480413 --> 0.479893).  Saving model ...
	 Train_Loss: 0.4787 Train_Acc: 77.393 Val_Loss: 0.4799  BEST VAL Loss: 0.4799  Val_Acc: 77.610

Epoch 19: Validation loss decreased (0.479893 --> 0.479314).  Saving model ...
	 Train_Loss: 0.4771 Train_Acc: 77.364 Val_Loss: 0.4793  BEST VAL Loss: 0.4793  Val_Acc: 77.193

Epoch 20: Validation loss decreased (0.479314 --> 0.478715).  Saving model ...
	 Train_Loss: 0.4753 Train_Acc: 77.764 Val_Loss: 0.4787  BEST VAL Loss: 0.4787  Val_Acc: 77.146

Epoch 21: Validation loss decreased (0.478715 --> 0.478303).  Saving model ...
	 Train_Loss: 0.4736 Train_Acc: 77.645 Val_Loss: 0.4783  BEST VAL Loss: 0.4783  Val_Acc: 77.564

Epoch 22: Validation loss decreased (0.478303 --> 0.478064).  Saving model ...
	 Train_Loss: 0.4721 Train_Acc: 77.637 Val_Loss: 0.4781  BEST VAL Loss: 0.4781  Val_Acc: 77.262

Epoch 23: Validation loss decreased (0.478064 --> 0.477723).  Saving model ...
	 Train_Loss: 0.4707 Train_Acc: 77.518 Val_Loss: 0.4777  BEST VAL Loss: 0.4777  Val_Acc: 77.587

Epoch 24: Validation loss decreased (0.477723 --> 0.477342).  Saving model ...
	 Train_Loss: 0.4693 Train_Acc: 77.671 Val_Loss: 0.4773  BEST VAL Loss: 0.4773  Val_Acc: 77.355

Epoch 25: Validation loss decreased (0.477342 --> 0.477081).  Saving model ...
	 Train_Loss: 0.4679 Train_Acc: 77.651 Val_Loss: 0.4771  BEST VAL Loss: 0.4771  Val_Acc: 77.680

Epoch 26: Validation loss decreased (0.477081 --> 0.476830).  Saving model ...
	 Train_Loss: 0.4666 Train_Acc: 77.854 Val_Loss: 0.4768  BEST VAL Loss: 0.4768  Val_Acc: 77.726

Epoch 27: Validation loss decreased (0.476830 --> 0.476547).  Saving model ...
	 Train_Loss: 0.4654 Train_Acc: 77.657 Val_Loss: 0.4765  BEST VAL Loss: 0.4765  Val_Acc: 77.541

Epoch 28: Validation loss decreased (0.476547 --> 0.476248).  Saving model ...
	 Train_Loss: 0.4642 Train_Acc: 77.877 Val_Loss: 0.4762  BEST VAL Loss: 0.4762  Val_Acc: 78.097

Epoch 29: Validation loss decreased (0.476248 --> 0.475940).  Saving model ...
	 Train_Loss: 0.4630 Train_Acc: 78.017 Val_Loss: 0.4759  BEST VAL Loss: 0.4759  Val_Acc: 77.773

Epoch 30: Validation loss decreased (0.475940 --> 0.475711).  Saving model ...
	 Train_Loss: 0.4618 Train_Acc: 78.130 Val_Loss: 0.4757  BEST VAL Loss: 0.4757  Val_Acc: 77.796

Epoch 31: Validation loss decreased (0.475711 --> 0.475343).  Saving model ...
	 Train_Loss: 0.4607 Train_Acc: 77.718 Val_Loss: 0.4753  BEST VAL Loss: 0.4753  Val_Acc: 77.935

Epoch 32: Validation loss decreased (0.475343 --> 0.475056).  Saving model ...
	 Train_Loss: 0.4597 Train_Acc: 78.156 Val_Loss: 0.4751  BEST VAL Loss: 0.4751  Val_Acc: 77.680

Epoch 33: Validation loss decreased (0.475056 --> 0.474881).  Saving model ...
	 Train_Loss: 0.4586 Train_Acc: 77.883 Val_Loss: 0.4749  BEST VAL Loss: 0.4749  Val_Acc: 78.097

Epoch 34: Validation loss decreased (0.474881 --> 0.474815).  Saving model ...
	 Train_Loss: 0.4576 Train_Acc: 77.970 Val_Loss: 0.4748  BEST VAL Loss: 0.4748  Val_Acc: 77.564

Epoch 35: Validation loss decreased (0.474815 --> 0.474676).  Saving model ...
	 Train_Loss: 0.4566 Train_Acc: 78.022 Val_Loss: 0.4747  BEST VAL Loss: 0.4747  Val_Acc: 77.657

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.4556 Train_Acc: 78.112 Val_Loss: 0.4747  BEST VAL Loss: 0.4747  Val_Acc: 77.633

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.4546 Train_Acc: 78.043 Val_Loss: 0.4747  BEST VAL Loss: 0.4747  Val_Acc: 77.448

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.4537 Train_Acc: 78.350 Val_Loss: 0.4748  BEST VAL Loss: 0.4747  Val_Acc: 77.517

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.4528 Train_Acc: 78.159 Val_Loss: 0.4750  BEST VAL Loss: 0.4747  Val_Acc: 77.657

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.4519 Train_Acc: 78.283 Val_Loss: 0.4750  BEST VAL Loss: 0.4747  Val_Acc: 77.773

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.4510 Train_Acc: 78.220 Val_Loss: 0.4752  BEST VAL Loss: 0.4747  Val_Acc: 77.633

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.4501 Train_Acc: 78.460 Val_Loss: 0.4753  BEST VAL Loss: 0.4747  Val_Acc: 77.726

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.4493 Train_Acc: 78.162 Val_Loss: 0.4755  BEST VAL Loss: 0.4747  Val_Acc: 77.703

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.4486 Train_Acc: 78.286 Val_Loss: 0.4756  BEST VAL Loss: 0.4747  Val_Acc: 77.680

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.4477 Train_Acc: 78.408 Val_Loss: 0.4755  BEST VAL Loss: 0.4747  Val_Acc: 77.378

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.4470 Train_Acc: 78.411 Val_Loss: 0.4756  BEST VAL Loss: 0.4747  Val_Acc: 77.912

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.4462 Train_Acc: 78.283 Val_Loss: 0.4756  BEST VAL Loss: 0.4747  Val_Acc: 77.935

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.4455 Train_Acc: 78.188 Val_Loss: 0.4757  BEST VAL Loss: 0.4747  Val_Acc: 77.749

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.4447 Train_Acc: 78.460 Val_Loss: 0.4759  BEST VAL Loss: 0.4747  Val_Acc: 78.051

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.4440 Train_Acc: 78.521 Val_Loss: 0.4760  BEST VAL Loss: 0.4747  Val_Acc: 77.471

Epoch 51: Validation loss did not decrease
Early stopped at epoch : 51
DMSO_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.83      0.95      0.89     24644
           1       0.81      0.49      0.61      9832

    accuracy                           0.82     34476
   macro avg       0.82      0.72      0.75     34476
weighted avg       0.82      0.82      0.81     34476

DMSO_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.79      0.93      0.86      3081
           1       0.69      0.40      0.50      1229

    accuracy                           0.78      4310
   macro avg       0.74      0.66      0.68      4310
weighted avg       0.76      0.78      0.76      4310

DMSO_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.80      0.93      0.86      3081
           1       0.71      0.42      0.52      1229

    accuracy                           0.78      4310
   macro avg       0.75      0.67      0.69      4310
weighted avg       0.77      0.78      0.76      4310

              precision    recall  f1-score   support

           0       0.80      0.93      0.86      3081
           1       0.71      0.42      0.52      1229

    accuracy                           0.78      4310
   macro avg       0.75      0.67      0.69      4310
weighted avg       0.77      0.78      0.76      4310

DMSO_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.62      0.83      0.71      4837
           1       0.68      0.42      0.52      4168

    accuracy                           0.64      9005
   macro avg       0.65      0.63      0.62      9005
weighted avg       0.65      0.64      0.62      9005

              precision    recall  f1-score   support

           0       0.62      0.83      0.71      4837
           1       0.68      0.42      0.52      4168

    accuracy                           0.64      9005
   macro avg       0.65      0.63      0.62      9005
weighted avg       0.65      0.64      0.62      9005

completed
