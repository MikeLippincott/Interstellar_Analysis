[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '07c04d58'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '401ee054'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '64ed1826'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '836d93ea'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_1.000_DMSO_0.025 treatment_name: H2O2_100.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_1.000_DMSO_0.025
TREATMENT_NAME: H2O2_100.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (379969, 1270)
Number of total missing values across all columns: 759938
Data Subset Is Off
Wells held out for testing: ['D09' 'I10']
Wells to use for training, validation, and testing ['D02' 'D03' 'D08' 'H04' 'I04' 'H05' 'I05' 'H10' 'H11' 'I11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.393381).  Saving model ...
	 Train_Loss: 0.5088 Train_Acc: 75.985 Val_Loss: 0.3934  BEST VAL Loss: 0.3934  Val_Acc: 82.737

Epoch 1: Validation loss decreased (0.393381 --> 0.374244).  Saving model ...
	 Train_Loss: 0.4564 Train_Acc: 81.531 Val_Loss: 0.3742  BEST VAL Loss: 0.3742  Val_Acc: 84.318

Epoch 2: Validation loss decreased (0.374244 --> 0.353494).  Saving model ...
	 Train_Loss: 0.4292 Train_Acc: 82.962 Val_Loss: 0.3535  BEST VAL Loss: 0.3535  Val_Acc: 86.561

Epoch 3: Validation loss decreased (0.353494 --> 0.348691).  Saving model ...
	 Train_Loss: 0.4118 Train_Acc: 83.620 Val_Loss: 0.3487  BEST VAL Loss: 0.3487  Val_Acc: 85.062

Epoch 4: Validation loss decreased (0.348691 --> 0.338408).  Saving model ...
	 Train_Loss: 0.3993 Train_Acc: 84.062 Val_Loss: 0.3384  BEST VAL Loss: 0.3384  Val_Acc: 87.011

Epoch 5: Validation loss decreased (0.338408 --> 0.331736).  Saving model ...
	 Train_Loss: 0.3898 Train_Acc: 84.361 Val_Loss: 0.3317  BEST VAL Loss: 0.3317  Val_Acc: 87.056

Epoch 6: Validation loss decreased (0.331736 --> 0.325279).  Saving model ...
	 Train_Loss: 0.3820 Train_Acc: 84.641 Val_Loss: 0.3253  BEST VAL Loss: 0.3253  Val_Acc: 87.715

Epoch 7: Validation loss decreased (0.325279 --> 0.321119).  Saving model ...
	 Train_Loss: 0.3757 Train_Acc: 84.920 Val_Loss: 0.3211  BEST VAL Loss: 0.3211  Val_Acc: 87.585

Epoch 8: Validation loss decreased (0.321119 --> 0.316151).  Saving model ...
	 Train_Loss: 0.3703 Train_Acc: 85.031 Val_Loss: 0.3162  BEST VAL Loss: 0.3162  Val_Acc: 88.269

Epoch 9: Validation loss decreased (0.316151 --> 0.312335).  Saving model ...
	 Train_Loss: 0.3658 Train_Acc: 85.075 Val_Loss: 0.3123  BEST VAL Loss: 0.3123  Val_Acc: 87.975

Epoch 10: Validation loss decreased (0.312335 --> 0.309653).  Saving model ...
	 Train_Loss: 0.3618 Train_Acc: 85.119 Val_Loss: 0.3097  BEST VAL Loss: 0.3097  Val_Acc: 87.975

Epoch 11: Validation loss decreased (0.309653 --> 0.306568).  Saving model ...
	 Train_Loss: 0.3584 Train_Acc: 85.181 Val_Loss: 0.3066  BEST VAL Loss: 0.3066  Val_Acc: 88.463

Epoch 12: Validation loss decreased (0.306568 --> 0.305203).  Saving model ...
	 Train_Loss: 0.3551 Train_Acc: 85.415 Val_Loss: 0.3052  BEST VAL Loss: 0.3052  Val_Acc: 87.845

Epoch 13: Validation loss decreased (0.305203 --> 0.302620).  Saving model ...
	 Train_Loss: 0.3523 Train_Acc: 85.300 Val_Loss: 0.3026  BEST VAL Loss: 0.3026  Val_Acc: 88.627

Epoch 14: Validation loss decreased (0.302620 --> 0.300321).  Saving model ...
	 Train_Loss: 0.3496 Train_Acc: 85.417 Val_Loss: 0.3003  BEST VAL Loss: 0.3003  Val_Acc: 88.729

Epoch 15: Validation loss decreased (0.300321 --> 0.298225).  Saving model ...
	 Train_Loss: 0.3472 Train_Acc: 85.479 Val_Loss: 0.2982  BEST VAL Loss: 0.2982  Val_Acc: 88.738

Epoch 16: Validation loss decreased (0.298225 --> 0.296693).  Saving model ...
	 Train_Loss: 0.3450 Train_Acc: 85.538 Val_Loss: 0.2967  BEST VAL Loss: 0.2967  Val_Acc: 88.567

Epoch 17: Validation loss decreased (0.296693 --> 0.294960).  Saving model ...
	 Train_Loss: 0.3429 Train_Acc: 85.480 Val_Loss: 0.2950  BEST VAL Loss: 0.2950  Val_Acc: 88.738

Epoch 18: Validation loss decreased (0.294960 --> 0.293085).  Saving model ...
	 Train_Loss: 0.3410 Train_Acc: 85.623 Val_Loss: 0.2931  BEST VAL Loss: 0.2931  Val_Acc: 89.061

Epoch 19: Validation loss decreased (0.293085 --> 0.291745).  Saving model ...
	 Train_Loss: 0.3392 Train_Acc: 85.602 Val_Loss: 0.2917  BEST VAL Loss: 0.2917  Val_Acc: 88.779

Epoch 20: Validation loss decreased (0.291745 --> 0.290623).  Saving model ...
	 Train_Loss: 0.3375 Train_Acc: 85.596 Val_Loss: 0.2906  BEST VAL Loss: 0.2906  Val_Acc: 88.795

Epoch 21: Validation loss decreased (0.290623 --> 0.289237).  Saving model ...
	 Train_Loss: 0.3360 Train_Acc: 85.705 Val_Loss: 0.2892  BEST VAL Loss: 0.2892  Val_Acc: 89.090

Epoch 22: Validation loss decreased (0.289237 --> 0.287809).  Saving model ...
	 Train_Loss: 0.3345 Train_Acc: 85.602 Val_Loss: 0.2878  BEST VAL Loss: 0.2878  Val_Acc: 89.137

Epoch 23: Validation loss decreased (0.287809 --> 0.286751).  Saving model ...
	 Train_Loss: 0.3332 Train_Acc: 85.796 Val_Loss: 0.2868  BEST VAL Loss: 0.2868  Val_Acc: 89.004

Epoch 24: Validation loss decreased (0.286751 --> 0.285799).  Saving model ...
	 Train_Loss: 0.3319 Train_Acc: 85.706 Val_Loss: 0.2858  BEST VAL Loss: 0.2858  Val_Acc: 88.798

Epoch 25: Validation loss decreased (0.285799 --> 0.284770).  Saving model ...
	 Train_Loss: 0.3306 Train_Acc: 85.727 Val_Loss: 0.2848  BEST VAL Loss: 0.2848  Val_Acc: 89.147

Epoch 26: Validation loss decreased (0.284770 --> 0.283827).  Saving model ...
	 Train_Loss: 0.3295 Train_Acc: 85.840 Val_Loss: 0.2838  BEST VAL Loss: 0.2838  Val_Acc: 89.233

Epoch 27: Validation loss decreased (0.283827 --> 0.282913).  Saving model ...
	 Train_Loss: 0.3283 Train_Acc: 85.883 Val_Loss: 0.2829  BEST VAL Loss: 0.2829  Val_Acc: 89.214

Epoch 28: Validation loss decreased (0.282913 --> 0.282072).  Saving model ...
	 Train_Loss: 0.3272 Train_Acc: 85.882 Val_Loss: 0.2821  BEST VAL Loss: 0.2821  Val_Acc: 89.112

Epoch 29: Validation loss decreased (0.282072 --> 0.281431).  Saving model ...
	 Train_Loss: 0.3262 Train_Acc: 85.927 Val_Loss: 0.2814  BEST VAL Loss: 0.2814  Val_Acc: 88.830

Epoch 30: Validation loss decreased (0.281431 --> 0.280599).  Saving model ...
	 Train_Loss: 0.3252 Train_Acc: 85.935 Val_Loss: 0.2806  BEST VAL Loss: 0.2806  Val_Acc: 89.622

Epoch 31: Validation loss decreased (0.280599 --> 0.279714).  Saving model ...
	 Train_Loss: 0.3243 Train_Acc: 85.993 Val_Loss: 0.2797  BEST VAL Loss: 0.2797  Val_Acc: 89.461

Epoch 32: Validation loss decreased (0.279714 --> 0.278878).  Saving model ...
	 Train_Loss: 0.3234 Train_Acc: 85.968 Val_Loss: 0.2789  BEST VAL Loss: 0.2789  Val_Acc: 89.486

Epoch 33: Validation loss decreased (0.278878 --> 0.278179).  Saving model ...
	 Train_Loss: 0.3226 Train_Acc: 86.038 Val_Loss: 0.2782  BEST VAL Loss: 0.2782  Val_Acc: 89.366

Epoch 34: Validation loss decreased (0.278179 --> 0.277404).  Saving model ...
	 Train_Loss: 0.3217 Train_Acc: 86.069 Val_Loss: 0.2774  BEST VAL Loss: 0.2774  Val_Acc: 89.625

Epoch 35: Validation loss decreased (0.277404 --> 0.276910).  Saving model ...
	 Train_Loss: 0.3209 Train_Acc: 86.073 Val_Loss: 0.2769  BEST VAL Loss: 0.2769  Val_Acc: 89.185

Epoch 36: Validation loss decreased (0.276910 --> 0.276250).  Saving model ...
	 Train_Loss: 0.3202 Train_Acc: 86.015 Val_Loss: 0.2763  BEST VAL Loss: 0.2763  Val_Acc: 89.524

Epoch 37: Validation loss decreased (0.276250 --> 0.275736).  Saving model ...
	 Train_Loss: 0.3194 Train_Acc: 86.054 Val_Loss: 0.2757  BEST VAL Loss: 0.2757  Val_Acc: 89.381

Epoch 38: Validation loss decreased (0.275736 --> 0.275298).  Saving model ...
	 Train_Loss: 0.3187 Train_Acc: 86.098 Val_Loss: 0.2753  BEST VAL Loss: 0.2753  Val_Acc: 89.226

Epoch 39: Validation loss decreased (0.275298 --> 0.274696).  Saving model ...
	 Train_Loss: 0.3180 Train_Acc: 86.091 Val_Loss: 0.2747  BEST VAL Loss: 0.2747  Val_Acc: 89.527

Epoch 40: Validation loss decreased (0.274696 --> 0.274086).  Saving model ...
	 Train_Loss: 0.3174 Train_Acc: 86.160 Val_Loss: 0.2741  BEST VAL Loss: 0.2741  Val_Acc: 89.530

Epoch 41: Validation loss decreased (0.274086 --> 0.273573).  Saving model ...
	 Train_Loss: 0.3167 Train_Acc: 86.185 Val_Loss: 0.2736  BEST VAL Loss: 0.2736  Val_Acc: 89.477

Epoch 42: Validation loss decreased (0.273573 --> 0.273048).  Saving model ...
	 Train_Loss: 0.3161 Train_Acc: 86.033 Val_Loss: 0.2730  BEST VAL Loss: 0.2730  Val_Acc: 89.511

Epoch 43: Validation loss decreased (0.273048 --> 0.272501).  Saving model ...
	 Train_Loss: 0.3155 Train_Acc: 86.181 Val_Loss: 0.2725  BEST VAL Loss: 0.2725  Val_Acc: 89.793

Epoch 44: Validation loss decreased (0.272501 --> 0.272175).  Saving model ...
	 Train_Loss: 0.3149 Train_Acc: 86.208 Val_Loss: 0.2722  BEST VAL Loss: 0.2722  Val_Acc: 89.261

Epoch 45: Validation loss decreased (0.272175 --> 0.271843).  Saving model ...
	 Train_Loss: 0.3144 Train_Acc: 86.172 Val_Loss: 0.2718  BEST VAL Loss: 0.2718  Val_Acc: 89.299

Epoch 46: Validation loss decreased (0.271843 --> 0.271474).  Saving model ...
	 Train_Loss: 0.3138 Train_Acc: 86.212 Val_Loss: 0.2715  BEST VAL Loss: 0.2715  Val_Acc: 89.407

Epoch 47: Validation loss decreased (0.271474 --> 0.271097).  Saving model ...
	 Train_Loss: 0.3133 Train_Acc: 86.202 Val_Loss: 0.2711  BEST VAL Loss: 0.2711  Val_Acc: 89.461

Epoch 48: Validation loss decreased (0.271097 --> 0.270584).  Saving model ...
	 Train_Loss: 0.3127 Train_Acc: 86.205 Val_Loss: 0.2706  BEST VAL Loss: 0.2706  Val_Acc: 89.793

Epoch 49: Validation loss decreased (0.270584 --> 0.270205).  Saving model ...
	 Train_Loss: 0.3122 Train_Acc: 86.294 Val_Loss: 0.2702  BEST VAL Loss: 0.2702  Val_Acc: 89.644

Epoch 50: Validation loss decreased (0.270205 --> 0.269720).  Saving model ...
	 Train_Loss: 0.3118 Train_Acc: 86.226 Val_Loss: 0.2697  BEST VAL Loss: 0.2697  Val_Acc: 89.682

Epoch 51: Validation loss decreased (0.269720 --> 0.269242).  Saving model ...
	 Train_Loss: 0.3113 Train_Acc: 86.307 Val_Loss: 0.2692  BEST VAL Loss: 0.2692  Val_Acc: 89.860

Epoch 52: Validation loss decreased (0.269242 --> 0.268800).  Saving model ...
	 Train_Loss: 0.3108 Train_Acc: 86.267 Val_Loss: 0.2688  BEST VAL Loss: 0.2688  Val_Acc: 89.866

Epoch 53: Validation loss decreased (0.268800 --> 0.268420).  Saving model ...
	 Train_Loss: 0.3104 Train_Acc: 86.346 Val_Loss: 0.2684  BEST VAL Loss: 0.2684  Val_Acc: 89.638

Epoch 54: Validation loss decreased (0.268420 --> 0.268004).  Saving model ...
	 Train_Loss: 0.3099 Train_Acc: 86.358 Val_Loss: 0.2680  BEST VAL Loss: 0.2680  Val_Acc: 89.835

Epoch 55: Validation loss decreased (0.268004 --> 0.267629).  Saving model ...
	 Train_Loss: 0.3095 Train_Acc: 86.360 Val_Loss: 0.2676  BEST VAL Loss: 0.2676  Val_Acc: 89.835

Epoch 56: Validation loss decreased (0.267629 --> 0.267369).  Saving model ...
	 Train_Loss: 0.3090 Train_Acc: 86.316 Val_Loss: 0.2674  BEST VAL Loss: 0.2674  Val_Acc: 89.556

Epoch 57: Validation loss decreased (0.267369 --> 0.267099).  Saving model ...
	 Train_Loss: 0.3086 Train_Acc: 86.399 Val_Loss: 0.2671  BEST VAL Loss: 0.2671  Val_Acc: 89.451

Epoch 58: Validation loss decreased (0.267099 --> 0.266732).  Saving model ...
	 Train_Loss: 0.3082 Train_Acc: 86.412 Val_Loss: 0.2667  BEST VAL Loss: 0.2667  Val_Acc: 89.825

Epoch 59: Validation loss decreased (0.266732 --> 0.266526).  Saving model ...
	 Train_Loss: 0.3078 Train_Acc: 86.373 Val_Loss: 0.2665  BEST VAL Loss: 0.2665  Val_Acc: 89.489

Epoch 60: Validation loss decreased (0.266526 --> 0.266163).  Saving model ...
	 Train_Loss: 0.3074 Train_Acc: 86.291 Val_Loss: 0.2662  BEST VAL Loss: 0.2662  Val_Acc: 89.968

Epoch 61: Validation loss decreased (0.266163 --> 0.265843).  Saving model ...
	 Train_Loss: 0.3070 Train_Acc: 86.441 Val_Loss: 0.2658  BEST VAL Loss: 0.2658  Val_Acc: 89.885

Epoch 62: Validation loss decreased (0.265843 --> 0.265569).  Saving model ...
	 Train_Loss: 0.3067 Train_Acc: 86.465 Val_Loss: 0.2656  BEST VAL Loss: 0.2656  Val_Acc: 89.847

Epoch 63: Validation loss decreased (0.265569 --> 0.265322).  Saving model ...
	 Train_Loss: 0.3063 Train_Acc: 86.421 Val_Loss: 0.2653  BEST VAL Loss: 0.2653  Val_Acc: 89.803

Epoch 64: Validation loss decreased (0.265322 --> 0.265020).  Saving model ...
	 Train_Loss: 0.3059 Train_Acc: 86.406 Val_Loss: 0.2650  BEST VAL Loss: 0.2650  Val_Acc: 89.977

Epoch 65: Validation loss decreased (0.265020 --> 0.264773).  Saving model ...
	 Train_Loss: 0.3056 Train_Acc: 86.400 Val_Loss: 0.2648  BEST VAL Loss: 0.2648  Val_Acc: 89.752

Epoch 66: Validation loss decreased (0.264773 --> 0.264479).  Saving model ...
	 Train_Loss: 0.3053 Train_Acc: 86.450 Val_Loss: 0.2645  BEST VAL Loss: 0.2645  Val_Acc: 89.907

Epoch 67: Validation loss decreased (0.264479 --> 0.264214).  Saving model ...
	 Train_Loss: 0.3049 Train_Acc: 86.522 Val_Loss: 0.2642  BEST VAL Loss: 0.2642  Val_Acc: 89.854

Epoch 68: Validation loss decreased (0.264214 --> 0.263929).  Saving model ...
	 Train_Loss: 0.3046 Train_Acc: 86.500 Val_Loss: 0.2639  BEST VAL Loss: 0.2639  Val_Acc: 89.708

Epoch 69: Validation loss decreased (0.263929 --> 0.263626).  Saving model ...
	 Train_Loss: 0.3042 Train_Acc: 86.401 Val_Loss: 0.2636  BEST VAL Loss: 0.2636  Val_Acc: 89.949

Epoch 70: Validation loss decreased (0.263626 --> 0.263375).  Saving model ...
	 Train_Loss: 0.3039 Train_Acc: 86.379 Val_Loss: 0.2634  BEST VAL Loss: 0.2634  Val_Acc: 89.831

Epoch 71: Validation loss decreased (0.263375 --> 0.263110).  Saving model ...
	 Train_Loss: 0.3036 Train_Acc: 86.591 Val_Loss: 0.2631  BEST VAL Loss: 0.2631  Val_Acc: 89.999

Epoch 72: Validation loss decreased (0.263110 --> 0.262941).  Saving model ...
	 Train_Loss: 0.3033 Train_Acc: 86.512 Val_Loss: 0.2629  BEST VAL Loss: 0.2629  Val_Acc: 89.591

Epoch 73: Validation loss decreased (0.262941 --> 0.262674).  Saving model ...
	 Train_Loss: 0.3030 Train_Acc: 86.515 Val_Loss: 0.2627  BEST VAL Loss: 0.2627  Val_Acc: 90.006

Epoch 74: Validation loss decreased (0.262674 --> 0.262438).  Saving model ...
	 Train_Loss: 0.3027 Train_Acc: 86.485 Val_Loss: 0.2624  BEST VAL Loss: 0.2624  Val_Acc: 90.022

Epoch 75: Validation loss decreased (0.262438 --> 0.262254).  Saving model ...
	 Train_Loss: 0.3024 Train_Acc: 86.499 Val_Loss: 0.2623  BEST VAL Loss: 0.2623  Val_Acc: 89.812

Epoch 76: Validation loss decreased (0.262254 --> 0.262030).  Saving model ...
	 Train_Loss: 0.3021 Train_Acc: 86.456 Val_Loss: 0.2620  BEST VAL Loss: 0.2620  Val_Acc: 89.955

Epoch 77: Validation loss decreased (0.262030 --> 0.261788).  Saving model ...
	 Train_Loss: 0.3019 Train_Acc: 86.505 Val_Loss: 0.2618  BEST VAL Loss: 0.2618  Val_Acc: 89.965

Epoch 78: Validation loss decreased (0.261788 --> 0.261573).  Saving model ...
	 Train_Loss: 0.3016 Train_Acc: 86.546 Val_Loss: 0.2616  BEST VAL Loss: 0.2616  Val_Acc: 89.984

Epoch 79: Validation loss decreased (0.261573 --> 0.261335).  Saving model ...
	 Train_Loss: 0.3013 Train_Acc: 86.510 Val_Loss: 0.2613  BEST VAL Loss: 0.2613  Val_Acc: 90.145

Epoch 80: Validation loss decreased (0.261335 --> 0.261091).  Saving model ...
	 Train_Loss: 0.3011 Train_Acc: 86.544 Val_Loss: 0.2611  BEST VAL Loss: 0.2611  Val_Acc: 90.069

Epoch 81: Validation loss decreased (0.261091 --> 0.260868).  Saving model ...
	 Train_Loss: 0.3008 Train_Acc: 86.557 Val_Loss: 0.2609  BEST VAL Loss: 0.2609  Val_Acc: 89.949

Epoch 82: Validation loss decreased (0.260868 --> 0.260639).  Saving model ...
	 Train_Loss: 0.3006 Train_Acc: 86.630 Val_Loss: 0.2606  BEST VAL Loss: 0.2606  Val_Acc: 90.107

Epoch 83: Validation loss decreased (0.260639 --> 0.260484).  Saving model ...
	 Train_Loss: 0.3003 Train_Acc: 86.641 Val_Loss: 0.2605  BEST VAL Loss: 0.2605  Val_Acc: 89.961

Epoch 84: Validation loss decreased (0.260484 --> 0.260296).  Saving model ...
	 Train_Loss: 0.3000 Train_Acc: 86.583 Val_Loss: 0.2603  BEST VAL Loss: 0.2603  Val_Acc: 89.895

Epoch 85: Validation loss decreased (0.260296 --> 0.260135).  Saving model ...
	 Train_Loss: 0.2998 Train_Acc: 86.642 Val_Loss: 0.2601  BEST VAL Loss: 0.2601  Val_Acc: 89.784

Epoch 86: Validation loss decreased (0.260135 --> 0.259934).  Saving model ...
	 Train_Loss: 0.2995 Train_Acc: 86.555 Val_Loss: 0.2599  BEST VAL Loss: 0.2599  Val_Acc: 90.041

Epoch 87: Validation loss decreased (0.259934 --> 0.259767).  Saving model ...
	 Train_Loss: 0.2993 Train_Acc: 86.595 Val_Loss: 0.2598  BEST VAL Loss: 0.2598  Val_Acc: 90.003

Epoch 88: Validation loss decreased (0.259767 --> 0.259606).  Saving model ...
	 Train_Loss: 0.2991 Train_Acc: 86.629 Val_Loss: 0.2596  BEST VAL Loss: 0.2596  Val_Acc: 89.816

Epoch 89: Validation loss decreased (0.259606 --> 0.259444).  Saving model ...
	 Train_Loss: 0.2988 Train_Acc: 86.584 Val_Loss: 0.2594  BEST VAL Loss: 0.2594  Val_Acc: 89.873

Epoch 90: Validation loss decreased (0.259444 --> 0.259256).  Saving model ...
	 Train_Loss: 0.2986 Train_Acc: 86.629 Val_Loss: 0.2593  BEST VAL Loss: 0.2593  Val_Acc: 90.015

Epoch 91: Validation loss decreased (0.259256 --> 0.259098).  Saving model ...
	 Train_Loss: 0.2984 Train_Acc: 86.697 Val_Loss: 0.2591  BEST VAL Loss: 0.2591  Val_Acc: 89.730

Epoch 92: Validation loss decreased (0.259098 --> 0.258929).  Saving model ...
	 Train_Loss: 0.2982 Train_Acc: 86.652 Val_Loss: 0.2589  BEST VAL Loss: 0.2589  Val_Acc: 89.952

Epoch 93: Validation loss decreased (0.258929 --> 0.258720).  Saving model ...
	 Train_Loss: 0.2980 Train_Acc: 86.618 Val_Loss: 0.2587  BEST VAL Loss: 0.2587  Val_Acc: 90.028

Epoch 94: Validation loss decreased (0.258720 --> 0.258544).  Saving model ...
	 Train_Loss: 0.2977 Train_Acc: 86.767 Val_Loss: 0.2585  BEST VAL Loss: 0.2585  Val_Acc: 90.120

Epoch 95: Validation loss decreased (0.258544 --> 0.258378).  Saving model ...
	 Train_Loss: 0.2975 Train_Acc: 86.715 Val_Loss: 0.2584  BEST VAL Loss: 0.2584  Val_Acc: 90.069

Epoch 96: Validation loss decreased (0.258378 --> 0.258261).  Saving model ...
	 Train_Loss: 0.2973 Train_Acc: 86.645 Val_Loss: 0.2583  BEST VAL Loss: 0.2583  Val_Acc: 89.800

Epoch 97: Validation loss decreased (0.258261 --> 0.258089).  Saving model ...
	 Train_Loss: 0.2971 Train_Acc: 86.613 Val_Loss: 0.2581  BEST VAL Loss: 0.2581  Val_Acc: 90.018

Epoch 98: Validation loss decreased (0.258089 --> 0.257984).  Saving model ...
	 Train_Loss: 0.2969 Train_Acc: 86.659 Val_Loss: 0.2580  BEST VAL Loss: 0.2580  Val_Acc: 89.895

Epoch 99: Validation loss decreased (0.257984 --> 0.257801).  Saving model ...
	 Train_Loss: 0.2967 Train_Acc: 86.686 Val_Loss: 0.2578  BEST VAL Loss: 0.2578  Val_Acc: 89.911

LPS_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.94      0.94    169560
           1       0.87      0.86      0.87     82898

    accuracy                           0.91    252458
   macro avg       0.90      0.90      0.90    252458
weighted avg       0.91      0.91      0.91    252458

LPS_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.92      0.93      0.93     21196
           1       0.85      0.84      0.84     10362

    accuracy                           0.90     31558
   macro avg       0.89      0.88      0.88     31558
weighted avg       0.90      0.90      0.90     31558

LPS_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.92      0.93      0.93     21196
           1       0.85      0.84      0.85     10362

    accuracy                           0.90     31558
   macro avg       0.89      0.89      0.89     31558
weighted avg       0.90      0.90      0.90     31558

              precision    recall  f1-score   support

           0       0.92      0.93      0.93     21196
           1       0.85      0.84      0.85     10362

    accuracy                           0.90     31558
   macro avg       0.89      0.89      0.89     31558
weighted avg       0.90      0.90      0.90     31558

LPS_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.49      0.88      0.63     28584
           1       0.74      0.27      0.40     35811

    accuracy                           0.54     64395
   macro avg       0.62      0.58      0.51     64395
weighted avg       0.63      0.54      0.50     64395

              precision    recall  f1-score   support

           0       0.49      0.88      0.63     28584
           1       0.74      0.27      0.40     35811

    accuracy                           0.54     64395
   macro avg       0.62      0.58      0.51     64395
weighted avg       0.63      0.54      0.50     64395

completed
