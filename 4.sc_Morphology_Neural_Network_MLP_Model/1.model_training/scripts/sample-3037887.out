[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '621f100b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '865d5b91'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b4a83c3f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '5146b2af'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: Flagellin_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_Nigericin_1.000_3.0_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (29461, 1276)
Number of total missing values across all columns: 31618
Data Subset Is Off
Wells held out for testing: ['L16' 'M22']
Wells to use for training, validation, and testing ['L17' 'M18' 'M19' 'L20' 'L21' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.371530).  Saving model ...
	 Train_Loss: 0.5060 Train_Acc: 77.831 Val_Loss: 0.3715  BEST VAL Loss: 0.3715  Val_Acc: 86.832

Epoch 1: Validation loss decreased (0.371530 --> 0.338926).  Saving model ...
	 Train_Loss: 0.4336 Train_Acc: 85.470 Val_Loss: 0.3389  BEST VAL Loss: 0.3389  Val_Acc: 90.055

Epoch 2: Validation loss decreased (0.338926 --> 0.303987).  Saving model ...
	 Train_Loss: 0.3904 Train_Acc: 88.337 Val_Loss: 0.3040  BEST VAL Loss: 0.3040  Val_Acc: 91.805

Epoch 3: Validation loss decreased (0.303987 --> 0.279921).  Saving model ...
	 Train_Loss: 0.3593 Train_Acc: 89.995 Val_Loss: 0.2799  BEST VAL Loss: 0.2799  Val_Acc: 92.541

Epoch 4: Validation loss decreased (0.279921 --> 0.262604).  Saving model ...
	 Train_Loss: 0.3353 Train_Acc: 90.824 Val_Loss: 0.2626  BEST VAL Loss: 0.2626  Val_Acc: 93.232

Epoch 5: Validation loss decreased (0.262604 --> 0.244551).  Saving model ...
	 Train_Loss: 0.3155 Train_Acc: 92.102 Val_Loss: 0.2446  BEST VAL Loss: 0.2446  Val_Acc: 93.416

Epoch 6: Validation loss decreased (0.244551 --> 0.233431).  Saving model ...
	 Train_Loss: 0.2988 Train_Acc: 92.482 Val_Loss: 0.2334  BEST VAL Loss: 0.2334  Val_Acc: 93.877

Epoch 7: Validation loss decreased (0.233431 --> 0.221831).  Saving model ...
	 Train_Loss: 0.2844 Train_Acc: 93.178 Val_Loss: 0.2218  BEST VAL Loss: 0.2218  Val_Acc: 94.153

Epoch 8: Validation loss decreased (0.221831 --> 0.212318).  Saving model ...
	 Train_Loss: 0.2722 Train_Acc: 93.599 Val_Loss: 0.2123  BEST VAL Loss: 0.2123  Val_Acc: 94.797

Epoch 9: Validation loss decreased (0.212318 --> 0.204248).  Saving model ...
	 Train_Loss: 0.2617 Train_Acc: 93.627 Val_Loss: 0.2042  BEST VAL Loss: 0.2042  Val_Acc: 94.751

Epoch 10: Validation loss decreased (0.204248 --> 0.197429).  Saving model ...
	 Train_Loss: 0.2522 Train_Acc: 94.048 Val_Loss: 0.1974  BEST VAL Loss: 0.1974  Val_Acc: 95.350

Epoch 11: Validation loss decreased (0.197429 --> 0.190793).  Saving model ...
	 Train_Loss: 0.2433 Train_Acc: 94.468 Val_Loss: 0.1908  BEST VAL Loss: 0.1908  Val_Acc: 95.718

Epoch 12: Validation loss decreased (0.190793 --> 0.184828).  Saving model ...
	 Train_Loss: 0.2353 Train_Acc: 94.675 Val_Loss: 0.1848  BEST VAL Loss: 0.1848  Val_Acc: 95.764

Epoch 13: Validation loss decreased (0.184828 --> 0.179240).  Saving model ...
	 Train_Loss: 0.2281 Train_Acc: 94.923 Val_Loss: 0.1792  BEST VAL Loss: 0.1792  Val_Acc: 96.271

Epoch 14: Validation loss decreased (0.179240 --> 0.173707).  Saving model ...
	 Train_Loss: 0.2215 Train_Acc: 95.136 Val_Loss: 0.1737  BEST VAL Loss: 0.1737  Val_Acc: 95.948

Epoch 15: Validation loss decreased (0.173707 --> 0.169315).  Saving model ...
	 Train_Loss: 0.2153 Train_Acc: 95.556 Val_Loss: 0.1693  BEST VAL Loss: 0.1693  Val_Acc: 96.133

Epoch 16: Validation loss decreased (0.169315 --> 0.165355).  Saving model ...
	 Train_Loss: 0.2096 Train_Acc: 95.521 Val_Loss: 0.1654  BEST VAL Loss: 0.1654  Val_Acc: 96.501

Epoch 17: Validation loss decreased (0.165355 --> 0.161451).  Saving model ...
	 Train_Loss: 0.2043 Train_Acc: 95.723 Val_Loss: 0.1615  BEST VAL Loss: 0.1615  Val_Acc: 96.547

Epoch 18: Validation loss decreased (0.161451 --> 0.157552).  Saving model ...
	 Train_Loss: 0.1996 Train_Acc: 95.930 Val_Loss: 0.1576  BEST VAL Loss: 0.1576  Val_Acc: 96.823

Epoch 19: Validation loss decreased (0.157552 --> 0.154428).  Saving model ...
	 Train_Loss: 0.1949 Train_Acc: 96.091 Val_Loss: 0.1544  BEST VAL Loss: 0.1544  Val_Acc: 96.547

Epoch 20: Validation loss decreased (0.154428 --> 0.150750).  Saving model ...
	 Train_Loss: 0.1906 Train_Acc: 96.085 Val_Loss: 0.1508  BEST VAL Loss: 0.1508  Val_Acc: 96.685

Epoch 21: Validation loss decreased (0.150750 --> 0.147723).  Saving model ...
	 Train_Loss: 0.1866 Train_Acc: 96.103 Val_Loss: 0.1477  BEST VAL Loss: 0.1477  Val_Acc: 96.869

Epoch 22: Validation loss decreased (0.147723 --> 0.145116).  Saving model ...
	 Train_Loss: 0.1827 Train_Acc: 96.252 Val_Loss: 0.1451  BEST VAL Loss: 0.1451  Val_Acc: 96.685

Epoch 23: Validation loss decreased (0.145116 --> 0.143328).  Saving model ...
	 Train_Loss: 0.1790 Train_Acc: 96.483 Val_Loss: 0.1433  BEST VAL Loss: 0.1433  Val_Acc: 96.685

Epoch 24: Validation loss decreased (0.143328 --> 0.140972).  Saving model ...
	 Train_Loss: 0.1756 Train_Acc: 96.500 Val_Loss: 0.1410  BEST VAL Loss: 0.1410  Val_Acc: 96.777

Epoch 25: Validation loss decreased (0.140972 --> 0.138595).  Saving model ...
	 Train_Loss: 0.1723 Train_Acc: 96.661 Val_Loss: 0.1386  BEST VAL Loss: 0.1386  Val_Acc: 96.547

Epoch 26: Validation loss decreased (0.138595 --> 0.136233).  Saving model ...
	 Train_Loss: 0.1692 Train_Acc: 96.845 Val_Loss: 0.1362  BEST VAL Loss: 0.1362  Val_Acc: 96.731

Epoch 27: Validation loss decreased (0.136233 --> 0.134207).  Saving model ...
	 Train_Loss: 0.1662 Train_Acc: 96.834 Val_Loss: 0.1342  BEST VAL Loss: 0.1342  Val_Acc: 96.915

Epoch 28: Validation loss decreased (0.134207 --> 0.132267).  Saving model ...
	 Train_Loss: 0.1634 Train_Acc: 96.874 Val_Loss: 0.1323  BEST VAL Loss: 0.1323  Val_Acc: 97.007

Epoch 29: Validation loss decreased (0.132267 --> 0.130381).  Saving model ...
	 Train_Loss: 0.1606 Train_Acc: 96.932 Val_Loss: 0.1304  BEST VAL Loss: 0.1304  Val_Acc: 97.007

Epoch 30: Validation loss decreased (0.130381 --> 0.128557).  Saving model ...
	 Train_Loss: 0.1581 Train_Acc: 96.822 Val_Loss: 0.1286  BEST VAL Loss: 0.1286  Val_Acc: 97.145

Epoch 31: Validation loss decreased (0.128557 --> 0.127248).  Saving model ...
	 Train_Loss: 0.1556 Train_Acc: 97.047 Val_Loss: 0.1272  BEST VAL Loss: 0.1272  Val_Acc: 97.099

Epoch 32: Validation loss decreased (0.127248 --> 0.125888).  Saving model ...
	 Train_Loss: 0.1532 Train_Acc: 97.104 Val_Loss: 0.1259  BEST VAL Loss: 0.1259  Val_Acc: 97.099

Epoch 33: Validation loss decreased (0.125888 --> 0.124120).  Saving model ...
	 Train_Loss: 0.1509 Train_Acc: 97.266 Val_Loss: 0.1241  BEST VAL Loss: 0.1241  Val_Acc: 97.238

Epoch 34: Validation loss decreased (0.124120 --> 0.122783).  Saving model ...
	 Train_Loss: 0.1486 Train_Acc: 97.358 Val_Loss: 0.1228  BEST VAL Loss: 0.1228  Val_Acc: 97.284

Epoch 35: Validation loss decreased (0.122783 --> 0.121244).  Saving model ...
	 Train_Loss: 0.1465 Train_Acc: 97.139 Val_Loss: 0.1212  BEST VAL Loss: 0.1212  Val_Acc: 97.053

Epoch 36: Validation loss decreased (0.121244 --> 0.119907).  Saving model ...
	 Train_Loss: 0.1445 Train_Acc: 97.323 Val_Loss: 0.1199  BEST VAL Loss: 0.1199  Val_Acc: 97.007

Epoch 37: Validation loss decreased (0.119907 --> 0.118568).  Saving model ...
	 Train_Loss: 0.1425 Train_Acc: 97.409 Val_Loss: 0.1186  BEST VAL Loss: 0.1186  Val_Acc: 97.238

Epoch 38: Validation loss decreased (0.118568 --> 0.117590).  Saving model ...
	 Train_Loss: 0.1405 Train_Acc: 97.582 Val_Loss: 0.1176  BEST VAL Loss: 0.1176  Val_Acc: 97.053

Epoch 39: Validation loss decreased (0.117590 --> 0.116506).  Saving model ...
	 Train_Loss: 0.1387 Train_Acc: 97.369 Val_Loss: 0.1165  BEST VAL Loss: 0.1165  Val_Acc: 97.376

Epoch 40: Validation loss decreased (0.116506 --> 0.115602).  Saving model ...
	 Train_Loss: 0.1369 Train_Acc: 97.530 Val_Loss: 0.1156  BEST VAL Loss: 0.1156  Val_Acc: 97.053

Epoch 41: Validation loss decreased (0.115602 --> 0.114767).  Saving model ...
	 Train_Loss: 0.1352 Train_Acc: 97.473 Val_Loss: 0.1148  BEST VAL Loss: 0.1148  Val_Acc: 97.330

Epoch 42: Validation loss decreased (0.114767 --> 0.113816).  Saving model ...
	 Train_Loss: 0.1336 Train_Acc: 97.479 Val_Loss: 0.1138  BEST VAL Loss: 0.1138  Val_Acc: 97.192

Epoch 43: Validation loss decreased (0.113816 --> 0.113154).  Saving model ...
	 Train_Loss: 0.1320 Train_Acc: 97.571 Val_Loss: 0.1132  BEST VAL Loss: 0.1132  Val_Acc: 97.053

Epoch 44: Validation loss decreased (0.113154 --> 0.112116).  Saving model ...
	 Train_Loss: 0.1304 Train_Acc: 97.738 Val_Loss: 0.1121  BEST VAL Loss: 0.1121  Val_Acc: 97.145

Epoch 45: Validation loss decreased (0.112116 --> 0.111080).  Saving model ...
	 Train_Loss: 0.1289 Train_Acc: 97.582 Val_Loss: 0.1111  BEST VAL Loss: 0.1111  Val_Acc: 97.284

Epoch 46: Validation loss decreased (0.111080 --> 0.110146).  Saving model ...
	 Train_Loss: 0.1275 Train_Acc: 97.611 Val_Loss: 0.1101  BEST VAL Loss: 0.1101  Val_Acc: 97.007

Epoch 47: Validation loss decreased (0.110146 --> 0.109306).  Saving model ...
	 Train_Loss: 0.1261 Train_Acc: 97.761 Val_Loss: 0.1093  BEST VAL Loss: 0.1093  Val_Acc: 97.284

Epoch 48: Validation loss decreased (0.109306 --> 0.108437).  Saving model ...
	 Train_Loss: 0.1247 Train_Acc: 97.853 Val_Loss: 0.1084  BEST VAL Loss: 0.1084  Val_Acc: 97.099

Epoch 49: Validation loss decreased (0.108437 --> 0.107574).  Saving model ...
	 Train_Loss: 0.1234 Train_Acc: 97.766 Val_Loss: 0.1076  BEST VAL Loss: 0.1076  Val_Acc: 97.145

Epoch 50: Validation loss decreased (0.107574 --> 0.106942).  Saving model ...
	 Train_Loss: 0.1221 Train_Acc: 97.674 Val_Loss: 0.1069  BEST VAL Loss: 0.1069  Val_Acc: 96.777

Epoch 51: Validation loss decreased (0.106942 --> 0.106100).  Saving model ...
	 Train_Loss: 0.1208 Train_Acc: 97.824 Val_Loss: 0.1061  BEST VAL Loss: 0.1061  Val_Acc: 97.192

Epoch 52: Validation loss decreased (0.106100 --> 0.105508).  Saving model ...
	 Train_Loss: 0.1195 Train_Acc: 97.858 Val_Loss: 0.1055  BEST VAL Loss: 0.1055  Val_Acc: 96.961

Epoch 53: Validation loss decreased (0.105508 --> 0.104608).  Saving model ...
	 Train_Loss: 0.1183 Train_Acc: 97.945 Val_Loss: 0.1046  BEST VAL Loss: 0.1046  Val_Acc: 97.192

Epoch 54: Validation loss decreased (0.104608 --> 0.103759).  Saving model ...
	 Train_Loss: 0.1171 Train_Acc: 97.945 Val_Loss: 0.1038  BEST VAL Loss: 0.1038  Val_Acc: 97.330

Epoch 55: Validation loss decreased (0.103759 --> 0.102880).  Saving model ...
	 Train_Loss: 0.1160 Train_Acc: 97.795 Val_Loss: 0.1029  BEST VAL Loss: 0.1029  Val_Acc: 97.514

Epoch 56: Validation loss decreased (0.102880 --> 0.102254).  Saving model ...
	 Train_Loss: 0.1149 Train_Acc: 98.014 Val_Loss: 0.1023  BEST VAL Loss: 0.1023  Val_Acc: 97.376

Epoch 57: Validation loss decreased (0.102254 --> 0.101666).  Saving model ...
	 Train_Loss: 0.1138 Train_Acc: 97.991 Val_Loss: 0.1017  BEST VAL Loss: 0.1017  Val_Acc: 97.284

Epoch 58: Validation loss decreased (0.101666 --> 0.101197).  Saving model ...
	 Train_Loss: 0.1128 Train_Acc: 97.882 Val_Loss: 0.1012  BEST VAL Loss: 0.1012  Val_Acc: 97.422

Epoch 59: Validation loss decreased (0.101197 --> 0.100594).  Saving model ...
	 Train_Loss: 0.1118 Train_Acc: 98.054 Val_Loss: 0.1006  BEST VAL Loss: 0.1006  Val_Acc: 97.192

Epoch 60: Validation loss decreased (0.100594 --> 0.100122).  Saving model ...
	 Train_Loss: 0.1108 Train_Acc: 98.031 Val_Loss: 0.1001  BEST VAL Loss: 0.1001  Val_Acc: 97.284

Epoch 61: Validation loss decreased (0.100122 --> 0.099593).  Saving model ...
	 Train_Loss: 0.1098 Train_Acc: 98.048 Val_Loss: 0.0996  BEST VAL Loss: 0.0996  Val_Acc: 97.330

Epoch 62: Validation loss decreased (0.099593 --> 0.099209).  Saving model ...
	 Train_Loss: 0.1088 Train_Acc: 98.106 Val_Loss: 0.0992  BEST VAL Loss: 0.0992  Val_Acc: 97.514

Epoch 63: Validation loss decreased (0.099209 --> 0.099018).  Saving model ...
	 Train_Loss: 0.1079 Train_Acc: 98.002 Val_Loss: 0.0990  BEST VAL Loss: 0.0990  Val_Acc: 97.238

Epoch 64: Validation loss decreased (0.099018 --> 0.098558).  Saving model ...
	 Train_Loss: 0.1070 Train_Acc: 97.997 Val_Loss: 0.0986  BEST VAL Loss: 0.0986  Val_Acc: 97.238

Epoch 65: Validation loss decreased (0.098558 --> 0.098105).  Saving model ...
	 Train_Loss: 0.1061 Train_Acc: 98.089 Val_Loss: 0.0981  BEST VAL Loss: 0.0981  Val_Acc: 97.376

Epoch 66: Validation loss decreased (0.098105 --> 0.097729).  Saving model ...
	 Train_Loss: 0.1053 Train_Acc: 98.043 Val_Loss: 0.0977  BEST VAL Loss: 0.0977  Val_Acc: 97.560

Epoch 67: Validation loss decreased (0.097729 --> 0.097276).  Saving model ...
	 Train_Loss: 0.1044 Train_Acc: 98.129 Val_Loss: 0.0973  BEST VAL Loss: 0.0973  Val_Acc: 97.330

Epoch 68: Validation loss decreased (0.097276 --> 0.096722).  Saving model ...
	 Train_Loss: 0.1036 Train_Acc: 98.077 Val_Loss: 0.0967  BEST VAL Loss: 0.0967  Val_Acc: 97.376

Epoch 69: Validation loss decreased (0.096722 --> 0.096250).  Saving model ...
	 Train_Loss: 0.1028 Train_Acc: 98.181 Val_Loss: 0.0962  BEST VAL Loss: 0.0962  Val_Acc: 97.376

Epoch 70: Validation loss decreased (0.096250 --> 0.096159).  Saving model ...
	 Train_Loss: 0.1020 Train_Acc: 98.031 Val_Loss: 0.0962  BEST VAL Loss: 0.0962  Val_Acc: 97.376

Epoch 71: Validation loss decreased (0.096159 --> 0.095680).  Saving model ...
	 Train_Loss: 0.1012 Train_Acc: 98.095 Val_Loss: 0.0957  BEST VAL Loss: 0.0957  Val_Acc: 97.376

Epoch 72: Validation loss decreased (0.095680 --> 0.095611).  Saving model ...
	 Train_Loss: 0.1004 Train_Acc: 98.256 Val_Loss: 0.0956  BEST VAL Loss: 0.0956  Val_Acc: 97.330

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.0997 Train_Acc: 98.325 Val_Loss: 0.0958  BEST VAL Loss: 0.0956  Val_Acc: 97.284

Epoch 74: Validation loss decreased (0.095611 --> 0.095318).  Saving model ...
	 Train_Loss: 0.0989 Train_Acc: 98.152 Val_Loss: 0.0953  BEST VAL Loss: 0.0953  Val_Acc: 97.238

Epoch 75: Validation loss decreased (0.095318 --> 0.094996).  Saving model ...
	 Train_Loss: 0.0982 Train_Acc: 98.187 Val_Loss: 0.0950  BEST VAL Loss: 0.0950  Val_Acc: 97.422

Epoch 76: Validation loss decreased (0.094996 --> 0.094625).  Saving model ...
	 Train_Loss: 0.0975 Train_Acc: 98.106 Val_Loss: 0.0946  BEST VAL Loss: 0.0946  Val_Acc: 97.560

Epoch 77: Validation loss decreased (0.094625 --> 0.094227).  Saving model ...
	 Train_Loss: 0.0968 Train_Acc: 98.267 Val_Loss: 0.0942  BEST VAL Loss: 0.0942  Val_Acc: 97.330

Epoch 78: Validation loss decreased (0.094227 --> 0.094031).  Saving model ...
	 Train_Loss: 0.0962 Train_Acc: 98.210 Val_Loss: 0.0940  BEST VAL Loss: 0.0940  Val_Acc: 97.560

Epoch 79: Validation loss decreased (0.094031 --> 0.093879).  Saving model ...
	 Train_Loss: 0.0955 Train_Acc: 98.118 Val_Loss: 0.0939  BEST VAL Loss: 0.0939  Val_Acc: 97.376

Epoch 80: Validation loss decreased (0.093879 --> 0.093592).  Saving model ...
	 Train_Loss: 0.0949 Train_Acc: 98.359 Val_Loss: 0.0936  BEST VAL Loss: 0.0936  Val_Acc: 97.330

Epoch 81: Validation loss decreased (0.093592 --> 0.093364).  Saving model ...
	 Train_Loss: 0.0942 Train_Acc: 98.250 Val_Loss: 0.0934  BEST VAL Loss: 0.0934  Val_Acc: 97.514

Epoch 82: Validation loss decreased (0.093364 --> 0.093282).  Saving model ...
	 Train_Loss: 0.0936 Train_Acc: 98.187 Val_Loss: 0.0933  BEST VAL Loss: 0.0933  Val_Acc: 97.145

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.0930 Train_Acc: 98.290 Val_Loss: 0.0934  BEST VAL Loss: 0.0933  Val_Acc: 97.468

Epoch 84: Validation loss decreased (0.093282 --> 0.093241).  Saving model ...
	 Train_Loss: 0.0924 Train_Acc: 98.238 Val_Loss: 0.0932  BEST VAL Loss: 0.0932  Val_Acc: 97.514

Epoch 85: Validation loss decreased (0.093241 --> 0.092875).  Saving model ...
	 Train_Loss: 0.0918 Train_Acc: 98.204 Val_Loss: 0.0929  BEST VAL Loss: 0.0929  Val_Acc: 97.514

Epoch 86: Validation loss decreased (0.092875 --> 0.092672).  Saving model ...
	 Train_Loss: 0.0912 Train_Acc: 98.388 Val_Loss: 0.0927  BEST VAL Loss: 0.0927  Val_Acc: 97.376

Epoch 87: Validation loss decreased (0.092672 --> 0.092477).  Saving model ...
	 Train_Loss: 0.0907 Train_Acc: 98.204 Val_Loss: 0.0925  BEST VAL Loss: 0.0925  Val_Acc: 97.514

Epoch 88: Validation loss decreased (0.092477 --> 0.092231).  Saving model ...
	 Train_Loss: 0.0902 Train_Acc: 98.210 Val_Loss: 0.0922  BEST VAL Loss: 0.0922  Val_Acc: 97.468

Epoch 89: Validation loss decreased (0.092231 --> 0.091908).  Saving model ...
	 Train_Loss: 0.0896 Train_Acc: 98.296 Val_Loss: 0.0919  BEST VAL Loss: 0.0919  Val_Acc: 97.514

Epoch 90: Validation loss decreased (0.091908 --> 0.091899).  Saving model ...
	 Train_Loss: 0.0891 Train_Acc: 98.215 Val_Loss: 0.0919  BEST VAL Loss: 0.0919  Val_Acc: 97.468

Epoch 91: Validation loss decreased (0.091899 --> 0.091787).  Saving model ...
	 Train_Loss: 0.0885 Train_Acc: 98.365 Val_Loss: 0.0918  BEST VAL Loss: 0.0918  Val_Acc: 97.376

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.0880 Train_Acc: 98.348 Val_Loss: 0.0918  BEST VAL Loss: 0.0918  Val_Acc: 97.468

Epoch 93: Validation loss decreased (0.091787 --> 0.091453).  Saving model ...
	 Train_Loss: 0.0875 Train_Acc: 98.336 Val_Loss: 0.0915  BEST VAL Loss: 0.0915  Val_Acc: 97.606

Epoch 94: Validation loss decreased (0.091453 --> 0.091411).  Saving model ...
	 Train_Loss: 0.0870 Train_Acc: 98.313 Val_Loss: 0.0914  BEST VAL Loss: 0.0914  Val_Acc: 97.422

Epoch 95: Validation loss decreased (0.091411 --> 0.091170).  Saving model ...
	 Train_Loss: 0.0865 Train_Acc: 98.480 Val_Loss: 0.0912  BEST VAL Loss: 0.0912  Val_Acc: 97.330

Epoch 96: Validation loss decreased (0.091170 --> 0.090875).  Saving model ...
	 Train_Loss: 0.0860 Train_Acc: 98.365 Val_Loss: 0.0909  BEST VAL Loss: 0.0909  Val_Acc: 97.514

Epoch 97: Validation loss decreased (0.090875 --> 0.090692).  Saving model ...
	 Train_Loss: 0.0855 Train_Acc: 98.342 Val_Loss: 0.0907  BEST VAL Loss: 0.0907  Val_Acc: 97.468

Epoch 98: Validation loss decreased (0.090692 --> 0.090573).  Saving model ...
	 Train_Loss: 0.0850 Train_Acc: 98.336 Val_Loss: 0.0906  BEST VAL Loss: 0.0906  Val_Acc: 97.422

Epoch 99: Validation loss decreased (0.090573 --> 0.090566).  Saving model ...
	 Train_Loss: 0.0845 Train_Acc: 98.365 Val_Loss: 0.0906  BEST VAL Loss: 0.0906  Val_Acc: 97.514

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.54      0.54      0.54      9433
           1       0.45      0.45      0.45      7938

    accuracy                           0.50     17371
   macro avg       0.50      0.50      0.50     17371
weighted avg       0.50      0.50      0.50     17371

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.54      0.54      0.54      1179
           1       0.45      0.44      0.45       993

    accuracy                           0.50      2172
   macro avg       0.49      0.49      0.49      2172
weighted avg       0.50      0.50      0.50      2172

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.54      0.54      0.54      1180
           1       0.45      0.45      0.45       992

    accuracy                           0.50      2172
   macro avg       0.49      0.49      0.49      2172
weighted avg       0.50      0.50      0.50      2172

              precision    recall  f1-score   support

           0       0.54      0.54      0.54      1180
           1       0.45      0.45      0.45       992

    accuracy                           0.50      2172
   macro avg       0.49      0.49      0.49      2172
weighted avg       0.50      0.50      0.50      2172

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.54      0.53      4017
           1       0.48      0.46      0.47      3729

    accuracy                           0.50      7746
   macro avg       0.50      0.50      0.50      7746
weighted avg       0.50      0.50      0.50      7746

              precision    recall  f1-score   support

           0       0.52      0.54      0.53      4017
           1       0.48      0.46      0.47      3729

    accuracy                           0.50      7746
   macro avg       0.50      0.50      0.50      7746
weighted avg       0.50      0.50      0.50      7746

completed
