[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b015fcf4'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '3f07a9d0'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '392fbf63'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'febae8c3'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Flagellin_0.100_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (234512, 1270)
Number of total missing values across all columns: 469024
Data Subset Is Off
Wells held out for testing: ['C09' 'L10']
Wells to use for training, validation, and testing ['C02' 'C03' 'C08' 'L05' 'L11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.561453).  Saving model ...
	 Train_Loss: 0.7455 Train_Acc: 66.704 Val_Loss: 0.5615  BEST VAL Loss: 0.5615  Val_Acc: 71.739

Epoch 1: Validation loss did not decrease
	 Train_Loss: 0.6537 Train_Acc: 71.470 Val_Loss: 0.5898  BEST VAL Loss: 0.5615  Val_Acc: 69.481

Epoch 2: Validation loss did not decrease
	 Train_Loss: 0.6177 Train_Acc: 73.047 Val_Loss: 0.6648  BEST VAL Loss: 0.5615  Val_Acc: 65.345

Epoch 3: Validation loss did not decrease
	 Train_Loss: 0.5980 Train_Acc: 74.305 Val_Loss: 0.6230  BEST VAL Loss: 0.5615  Val_Acc: 76.554

Epoch 4: Validation loss did not decrease
	 Train_Loss: 0.5807 Train_Acc: 74.987 Val_Loss: 0.5949  BEST VAL Loss: 0.5615  Val_Acc: 77.594

Epoch 5: Validation loss did not decrease
	 Train_Loss: 0.5685 Train_Acc: 75.407 Val_Loss: 0.5936  BEST VAL Loss: 0.5615  Val_Acc: 68.643

Epoch 6: Validation loss did not decrease
	 Train_Loss: 0.5595 Train_Acc: 75.605 Val_Loss: 0.5729  BEST VAL Loss: 0.5615  Val_Acc: 78.879

Epoch 7: Validation loss decreased (0.561453 --> 0.559890).  Saving model ...
	 Train_Loss: 0.5506 Train_Acc: 76.165 Val_Loss: 0.5599  BEST VAL Loss: 0.5599  Val_Acc: 78.120

Epoch 8: Validation loss did not decrease
	 Train_Loss: 0.5435 Train_Acc: 76.437 Val_Loss: 0.5602  BEST VAL Loss: 0.5599  Val_Acc: 71.519

Epoch 9: Validation loss decreased (0.559890 --> 0.548805).  Saving model ...
	 Train_Loss: 0.5389 Train_Acc: 76.086 Val_Loss: 0.5488  BEST VAL Loss: 0.5488  Val_Acc: 78.977

Epoch 10: Validation loss decreased (0.548805 --> 0.539433).  Saving model ...
	 Train_Loss: 0.5325 Train_Acc: 77.018 Val_Loss: 0.5394  BEST VAL Loss: 0.5394  Val_Acc: 79.252

Epoch 11: Validation loss decreased (0.539433 --> 0.534111).  Saving model ...
	 Train_Loss: 0.5277 Train_Acc: 76.925 Val_Loss: 0.5341  BEST VAL Loss: 0.5341  Val_Acc: 77.037

Epoch 12: Validation loss decreased (0.534111 --> 0.527539).  Saving model ...
	 Train_Loss: 0.5232 Train_Acc: 77.143 Val_Loss: 0.5275  BEST VAL Loss: 0.5275  Val_Acc: 79.001

Epoch 13: Validation loss decreased (0.527539 --> 0.521325).  Saving model ...
	 Train_Loss: 0.5192 Train_Acc: 77.091 Val_Loss: 0.5213  BEST VAL Loss: 0.5213  Val_Acc: 79.564

Epoch 14: Validation loss decreased (0.521325 --> 0.516515).  Saving model ...
	 Train_Loss: 0.5154 Train_Acc: 77.503 Val_Loss: 0.5165  BEST VAL Loss: 0.5165  Val_Acc: 79.240

Epoch 15: Validation loss decreased (0.516515 --> 0.512347).  Saving model ...
	 Train_Loss: 0.5120 Train_Acc: 77.586 Val_Loss: 0.5123  BEST VAL Loss: 0.5123  Val_Acc: 79.173

Epoch 16: Validation loss decreased (0.512347 --> 0.507651).  Saving model ...
	 Train_Loss: 0.5088 Train_Acc: 77.684 Val_Loss: 0.5077  BEST VAL Loss: 0.5077  Val_Acc: 79.803

Epoch 17: Validation loss decreased (0.507651 --> 0.505027).  Saving model ...
	 Train_Loss: 0.5057 Train_Acc: 77.836 Val_Loss: 0.5050  BEST VAL Loss: 0.5050  Val_Acc: 79.112

Epoch 18: Validation loss decreased (0.505027 --> 0.501276).  Saving model ...
	 Train_Loss: 0.5029 Train_Acc: 77.821 Val_Loss: 0.5013  BEST VAL Loss: 0.5013  Val_Acc: 79.601

Epoch 19: Validation loss decreased (0.501276 --> 0.497697).  Saving model ...
	 Train_Loss: 0.5003 Train_Acc: 78.091 Val_Loss: 0.4977  BEST VAL Loss: 0.4977  Val_Acc: 79.827

Epoch 20: Validation loss decreased (0.497697 --> 0.495131).  Saving model ...
	 Train_Loss: 0.4977 Train_Acc: 78.273 Val_Loss: 0.4951  BEST VAL Loss: 0.4951  Val_Acc: 79.595

Epoch 21: Validation loss decreased (0.495131 --> 0.492178).  Saving model ...
	 Train_Loss: 0.4953 Train_Acc: 78.349 Val_Loss: 0.4922  BEST VAL Loss: 0.4922  Val_Acc: 80.127

Epoch 22: Validation loss decreased (0.492178 --> 0.489431).  Saving model ...
	 Train_Loss: 0.4930 Train_Acc: 78.320 Val_Loss: 0.4894  BEST VAL Loss: 0.4894  Val_Acc: 80.066

Epoch 23: Validation loss decreased (0.489431 --> 0.488515).  Saving model ...
	 Train_Loss: 0.4909 Train_Acc: 78.451 Val_Loss: 0.4885  BEST VAL Loss: 0.4885  Val_Acc: 77.686

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.4889 Train_Acc: 78.464 Val_Loss: 0.4907  BEST VAL Loss: 0.4885  Val_Acc: 73.856

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.4870 Train_Acc: 78.497 Val_Loss: 0.4898  BEST VAL Loss: 0.4885  Val_Acc: 78.169

Epoch 26: Validation loss decreased (0.488515 --> 0.487300).  Saving model ...
	 Train_Loss: 0.4851 Train_Acc: 78.532 Val_Loss: 0.4873  BEST VAL Loss: 0.4873  Val_Acc: 80.354

Epoch 27: Validation loss decreased (0.487300 --> 0.485191).  Saving model ...
	 Train_Loss: 0.4833 Train_Acc: 78.718 Val_Loss: 0.4852  BEST VAL Loss: 0.4852  Val_Acc: 79.962

Epoch 28: Validation loss decreased (0.485191 --> 0.482918).  Saving model ...
	 Train_Loss: 0.4815 Train_Acc: 78.926 Val_Loss: 0.4829  BEST VAL Loss: 0.4829  Val_Acc: 80.225

Epoch 29: Validation loss did not decrease
	 Train_Loss: 0.4798 Train_Acc: 78.887 Val_Loss: 0.4832  BEST VAL Loss: 0.4829  Val_Acc: 77.429

Epoch 30: Validation loss decreased (0.482918 --> 0.482000).  Saving model ...
	 Train_Loss: 0.4782 Train_Acc: 78.975 Val_Loss: 0.4820  BEST VAL Loss: 0.4820  Val_Acc: 79.442

Epoch 31: Validation loss decreased (0.482000 --> 0.480192).  Saving model ...
	 Train_Loss: 0.4767 Train_Acc: 79.055 Val_Loss: 0.4802  BEST VAL Loss: 0.4802  Val_Acc: 79.980

Epoch 32: Validation loss decreased (0.480192 --> 0.478075).  Saving model ...
	 Train_Loss: 0.4752 Train_Acc: 79.099 Val_Loss: 0.4781  BEST VAL Loss: 0.4781  Val_Acc: 80.843

Epoch 33: Validation loss decreased (0.478075 --> 0.476157).  Saving model ...
	 Train_Loss: 0.4737 Train_Acc: 79.105 Val_Loss: 0.4762  BEST VAL Loss: 0.4762  Val_Acc: 80.806

Epoch 34: Validation loss decreased (0.476157 --> 0.474241).  Saving model ...
	 Train_Loss: 0.4723 Train_Acc: 79.225 Val_Loss: 0.4742  BEST VAL Loss: 0.4742  Val_Acc: 81.033

Epoch 35: Validation loss decreased (0.474241 --> 0.473366).  Saving model ...
	 Train_Loss: 0.4709 Train_Acc: 79.322 Val_Loss: 0.4734  BEST VAL Loss: 0.4734  Val_Acc: 79.883

Epoch 36: Validation loss decreased (0.473366 --> 0.471917).  Saving model ...
	 Train_Loss: 0.4695 Train_Acc: 79.281 Val_Loss: 0.4719  BEST VAL Loss: 0.4719  Val_Acc: 80.586

Epoch 37: Validation loss decreased (0.471917 --> 0.471156).  Saving model ...
	 Train_Loss: 0.4683 Train_Acc: 79.370 Val_Loss: 0.4712  BEST VAL Loss: 0.4712  Val_Acc: 79.693

Epoch 38: Validation loss decreased (0.471156 --> 0.470333).  Saving model ...
	 Train_Loss: 0.4670 Train_Acc: 79.446 Val_Loss: 0.4703  BEST VAL Loss: 0.4703  Val_Acc: 79.271

Epoch 39: Validation loss decreased (0.470333 --> 0.468728).  Saving model ...
	 Train_Loss: 0.4658 Train_Acc: 79.482 Val_Loss: 0.4687  BEST VAL Loss: 0.4687  Val_Acc: 80.941

Epoch 40: Validation loss decreased (0.468728 --> 0.468021).  Saving model ...
	 Train_Loss: 0.4646 Train_Acc: 79.467 Val_Loss: 0.4680  BEST VAL Loss: 0.4680  Val_Acc: 79.674

Epoch 41: Validation loss decreased (0.468021 --> 0.466519).  Saving model ...
	 Train_Loss: 0.4634 Train_Acc: 79.671 Val_Loss: 0.4665  BEST VAL Loss: 0.4665  Val_Acc: 81.186

Epoch 42: Validation loss decreased (0.466519 --> 0.465171).  Saving model ...
	 Train_Loss: 0.4623 Train_Acc: 79.477 Val_Loss: 0.4652  BEST VAL Loss: 0.4652  Val_Acc: 81.125

Epoch 43: Validation loss decreased (0.465171 --> 0.463609).  Saving model ...
	 Train_Loss: 0.4612 Train_Acc: 79.525 Val_Loss: 0.4636  BEST VAL Loss: 0.4636  Val_Acc: 81.443

Epoch 44: Validation loss decreased (0.463609 --> 0.462633).  Saving model ...
	 Train_Loss: 0.4601 Train_Acc: 79.690 Val_Loss: 0.4626  BEST VAL Loss: 0.4626  Val_Acc: 80.507

Epoch 45: Validation loss decreased (0.462633 --> 0.461455).  Saving model ...
	 Train_Loss: 0.4592 Train_Acc: 79.558 Val_Loss: 0.4615  BEST VAL Loss: 0.4615  Val_Acc: 80.929

Epoch 46: Validation loss decreased (0.461455 --> 0.460372).  Saving model ...
	 Train_Loss: 0.4581 Train_Acc: 79.765 Val_Loss: 0.4604  BEST VAL Loss: 0.4604  Val_Acc: 80.806

Epoch 47: Validation loss decreased (0.460372 --> 0.459746).  Saving model ...
	 Train_Loss: 0.4571 Train_Acc: 79.722 Val_Loss: 0.4597  BEST VAL Loss: 0.4597  Val_Acc: 79.919

Epoch 48: Validation loss decreased (0.459746 --> 0.458824).  Saving model ...
	 Train_Loss: 0.4562 Train_Acc: 79.746 Val_Loss: 0.4588  BEST VAL Loss: 0.4588  Val_Acc: 81.051

Epoch 49: Validation loss decreased (0.458824 --> 0.457611).  Saving model ...
	 Train_Loss: 0.4553 Train_Acc: 79.702 Val_Loss: 0.4576  BEST VAL Loss: 0.4576  Val_Acc: 80.953

Epoch 50: Validation loss decreased (0.457611 --> 0.456628).  Saving model ...
	 Train_Loss: 0.4544 Train_Acc: 79.652 Val_Loss: 0.4566  BEST VAL Loss: 0.4566  Val_Acc: 80.861

Epoch 51: Validation loss decreased (0.456628 --> 0.455703).  Saving model ...
	 Train_Loss: 0.4535 Train_Acc: 79.986 Val_Loss: 0.4557  BEST VAL Loss: 0.4557  Val_Acc: 81.216

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.4527 Train_Acc: 79.732 Val_Loss: 0.4559  BEST VAL Loss: 0.4557  Val_Acc: 78.732

Epoch 53: Validation loss decreased (0.455703 --> 0.455137).  Saving model ...
	 Train_Loss: 0.4518 Train_Acc: 79.895 Val_Loss: 0.4551  BEST VAL Loss: 0.4551  Val_Acc: 80.390

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.4510 Train_Acc: 79.896 Val_Loss: 0.4554  BEST VAL Loss: 0.4551  Val_Acc: 78.463

Epoch 55: Validation loss decreased (0.455137 --> 0.454307).  Saving model ...
	 Train_Loss: 0.4502 Train_Acc: 79.950 Val_Loss: 0.4543  BEST VAL Loss: 0.4543  Val_Acc: 81.773

Epoch 56: Validation loss decreased (0.454307 --> 0.454094).  Saving model ...
	 Train_Loss: 0.4494 Train_Acc: 80.051 Val_Loss: 0.4541  BEST VAL Loss: 0.4541  Val_Acc: 79.717

Epoch 57: Validation loss decreased (0.454094 --> 0.453131).  Saving model ...
	 Train_Loss: 0.4487 Train_Acc: 79.957 Val_Loss: 0.4531  BEST VAL Loss: 0.4531  Val_Acc: 81.296

Epoch 58: Validation loss decreased (0.453131 --> 0.452419).  Saving model ...
	 Train_Loss: 0.4479 Train_Acc: 80.025 Val_Loss: 0.4524  BEST VAL Loss: 0.4524  Val_Acc: 80.874

Epoch 59: Validation loss decreased (0.452419 --> 0.451772).  Saving model ...
	 Train_Loss: 0.4471 Train_Acc: 79.973 Val_Loss: 0.4518  BEST VAL Loss: 0.4518  Val_Acc: 81.033

Epoch 60: Validation loss decreased (0.451772 --> 0.451749).  Saving model ...
	 Train_Loss: 0.4464 Train_Acc: 80.022 Val_Loss: 0.4517  BEST VAL Loss: 0.4517  Val_Acc: 79.405

Epoch 61: Validation loss decreased (0.451749 --> 0.451643).  Saving model ...
	 Train_Loss: 0.4457 Train_Acc: 79.976 Val_Loss: 0.4516  BEST VAL Loss: 0.4516  Val_Acc: 79.674

Epoch 62: Validation loss decreased (0.451643 --> 0.451161).  Saving model ...
	 Train_Loss: 0.4450 Train_Acc: 80.021 Val_Loss: 0.4512  BEST VAL Loss: 0.4512  Val_Acc: 80.776

Epoch 63: Validation loss decreased (0.451161 --> 0.450963).  Saving model ...
	 Train_Loss: 0.4444 Train_Acc: 79.986 Val_Loss: 0.4510  BEST VAL Loss: 0.4510  Val_Acc: 80.103

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.4437 Train_Acc: 80.117 Val_Loss: 0.4513  BEST VAL Loss: 0.4510  Val_Acc: 78.371

Epoch 65: Validation loss decreased (0.450963 --> 0.450808).  Saving model ...
	 Train_Loss: 0.4431 Train_Acc: 80.194 Val_Loss: 0.4508  BEST VAL Loss: 0.4508  Val_Acc: 80.537

Epoch 66: Validation loss decreased (0.450808 --> 0.449924).  Saving model ...
	 Train_Loss: 0.4425 Train_Acc: 79.999 Val_Loss: 0.4499  BEST VAL Loss: 0.4499  Val_Acc: 81.687

Epoch 67: Validation loss decreased (0.449924 --> 0.449338).  Saving model ...
	 Train_Loss: 0.4419 Train_Acc: 80.041 Val_Loss: 0.4493  BEST VAL Loss: 0.4493  Val_Acc: 81.241

Epoch 68: Validation loss decreased (0.449338 --> 0.448570).  Saving model ...
	 Train_Loss: 0.4413 Train_Acc: 80.183 Val_Loss: 0.4486  BEST VAL Loss: 0.4486  Val_Acc: 81.724

Epoch 69: Validation loss decreased (0.448570 --> 0.448284).  Saving model ...
	 Train_Loss: 0.4407 Train_Acc: 80.129 Val_Loss: 0.4483  BEST VAL Loss: 0.4483  Val_Acc: 80.562

Epoch 70: Validation loss decreased (0.448284 --> 0.447760).  Saving model ...
	 Train_Loss: 0.4401 Train_Acc: 80.101 Val_Loss: 0.4478  BEST VAL Loss: 0.4478  Val_Acc: 80.935

Epoch 71: Validation loss decreased (0.447760 --> 0.447067).  Saving model ...
	 Train_Loss: 0.4395 Train_Acc: 80.088 Val_Loss: 0.4471  BEST VAL Loss: 0.4471  Val_Acc: 81.847

Epoch 72: Validation loss decreased (0.447067 --> 0.446528).  Saving model ...
	 Train_Loss: 0.4390 Train_Acc: 80.134 Val_Loss: 0.4465  BEST VAL Loss: 0.4465  Val_Acc: 81.553

Epoch 73: Validation loss decreased (0.446528 --> 0.445890).  Saving model ...
	 Train_Loss: 0.4384 Train_Acc: 80.272 Val_Loss: 0.4459  BEST VAL Loss: 0.4459  Val_Acc: 81.847

Epoch 74: Validation loss decreased (0.445890 --> 0.445889).  Saving model ...
	 Train_Loss: 0.4379 Train_Acc: 80.181 Val_Loss: 0.4459  BEST VAL Loss: 0.4459  Val_Acc: 79.473

Epoch 75: Validation loss decreased (0.445889 --> 0.445667).  Saving model ...
	 Train_Loss: 0.4373 Train_Acc: 80.202 Val_Loss: 0.4457  BEST VAL Loss: 0.4457  Val_Acc: 80.764

Epoch 76: Validation loss decreased (0.445667 --> 0.445071).  Saving model ...
	 Train_Loss: 0.4368 Train_Acc: 80.249 Val_Loss: 0.4451  BEST VAL Loss: 0.4451  Val_Acc: 81.547

Epoch 77: Validation loss decreased (0.445071 --> 0.444413).  Saving model ...
	 Train_Loss: 0.4363 Train_Acc: 80.225 Val_Loss: 0.4444  BEST VAL Loss: 0.4444  Val_Acc: 81.486

Epoch 78: Validation loss decreased (0.444413 --> 0.443752).  Saving model ...
	 Train_Loss: 0.4358 Train_Acc: 80.138 Val_Loss: 0.4438  BEST VAL Loss: 0.4438  Val_Acc: 81.871

Epoch 79: Validation loss decreased (0.443752 --> 0.443557).  Saving model ...
	 Train_Loss: 0.4353 Train_Acc: 80.154 Val_Loss: 0.4436  BEST VAL Loss: 0.4436  Val_Acc: 80.715

Epoch 80: Validation loss decreased (0.443557 --> 0.442974).  Saving model ...
	 Train_Loss: 0.4348 Train_Acc: 80.257 Val_Loss: 0.4430  BEST VAL Loss: 0.4430  Val_Acc: 81.339

Epoch 81: Validation loss decreased (0.442974 --> 0.442477).  Saving model ...
	 Train_Loss: 0.4343 Train_Acc: 80.351 Val_Loss: 0.4425  BEST VAL Loss: 0.4425  Val_Acc: 81.577

Epoch 82: Validation loss decreased (0.442477 --> 0.442225).  Saving model ...
	 Train_Loss: 0.4339 Train_Acc: 80.267 Val_Loss: 0.4422  BEST VAL Loss: 0.4422  Val_Acc: 80.843

Epoch 83: Validation loss decreased (0.442225 --> 0.441762).  Saving model ...
	 Train_Loss: 0.4334 Train_Acc: 80.374 Val_Loss: 0.4418  BEST VAL Loss: 0.4418  Val_Acc: 81.736

Epoch 84: Validation loss decreased (0.441762 --> 0.441498).  Saving model ...
	 Train_Loss: 0.4329 Train_Acc: 80.311 Val_Loss: 0.4415  BEST VAL Loss: 0.4415  Val_Acc: 80.598

Epoch 85: Validation loss decreased (0.441498 --> 0.441268).  Saving model ...
	 Train_Loss: 0.4325 Train_Acc: 80.328 Val_Loss: 0.4413  BEST VAL Loss: 0.4413  Val_Acc: 80.611

Epoch 86: Validation loss decreased (0.441268 --> 0.440780).  Saving model ...
	 Train_Loss: 0.4320 Train_Acc: 80.295 Val_Loss: 0.4408  BEST VAL Loss: 0.4408  Val_Acc: 81.278

Epoch 87: Validation loss decreased (0.440780 --> 0.440543).  Saving model ...
	 Train_Loss: 0.4316 Train_Acc: 80.383 Val_Loss: 0.4405  BEST VAL Loss: 0.4405  Val_Acc: 80.715

Epoch 88: Validation loss decreased (0.440543 --> 0.440013).  Saving model ...
	 Train_Loss: 0.4312 Train_Acc: 80.288 Val_Loss: 0.4400  BEST VAL Loss: 0.4400  Val_Acc: 81.785

Epoch 89: Validation loss decreased (0.440013 --> 0.439510).  Saving model ...
	 Train_Loss: 0.4307 Train_Acc: 80.279 Val_Loss: 0.4395  BEST VAL Loss: 0.4395  Val_Acc: 81.553

Epoch 90: Validation loss decreased (0.439510 --> 0.439048).  Saving model ...
	 Train_Loss: 0.4303 Train_Acc: 80.284 Val_Loss: 0.4390  BEST VAL Loss: 0.4390  Val_Acc: 81.871

Epoch 91: Validation loss decreased (0.439048 --> 0.438649).  Saving model ...
	 Train_Loss: 0.4299 Train_Acc: 80.423 Val_Loss: 0.4386  BEST VAL Loss: 0.4386  Val_Acc: 81.614

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.4295 Train_Acc: 80.227 Val_Loss: 0.4387  BEST VAL Loss: 0.4386  Val_Acc: 80.286

Epoch 93: Validation loss decreased (0.438649 --> 0.438228).  Saving model ...
	 Train_Loss: 0.4291 Train_Acc: 80.274 Val_Loss: 0.4382  BEST VAL Loss: 0.4382  Val_Acc: 81.871

Epoch 94: Validation loss decreased (0.438228 --> 0.437891).  Saving model ...
	 Train_Loss: 0.4287 Train_Acc: 80.514 Val_Loss: 0.4379  BEST VAL Loss: 0.4379  Val_Acc: 81.486

Epoch 95: Validation loss decreased (0.437891 --> 0.437483).  Saving model ...
	 Train_Loss: 0.4283 Train_Acc: 80.392 Val_Loss: 0.4375  BEST VAL Loss: 0.4375  Val_Acc: 81.883

Epoch 96: Validation loss decreased (0.437483 --> 0.437370).  Saving model ...
	 Train_Loss: 0.4280 Train_Acc: 80.398 Val_Loss: 0.4374  BEST VAL Loss: 0.4374  Val_Acc: 80.965

Epoch 97: Validation loss decreased (0.437370 --> 0.437044).  Saving model ...
	 Train_Loss: 0.4276 Train_Acc: 80.414 Val_Loss: 0.4370  BEST VAL Loss: 0.4370  Val_Acc: 81.155

Epoch 98: Validation loss decreased (0.437044 --> 0.436760).  Saving model ...
	 Train_Loss: 0.4272 Train_Acc: 80.483 Val_Loss: 0.4368  BEST VAL Loss: 0.4368  Val_Acc: 81.400

Epoch 99: Validation loss decreased (0.436760 --> 0.436348).  Saving model ...
	 Train_Loss: 0.4268 Train_Acc: 80.246 Val_Loss: 0.4363  BEST VAL Loss: 0.4363  Val_Acc: 81.632

Flagellin_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.84      0.71      0.77     50422
           1       0.83      0.91      0.87     80324

    accuracy                           0.83    130746
   macro avg       0.84      0.81      0.82    130746
weighted avg       0.83      0.83      0.83    130746

Flagellin_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.81      0.68      0.74      6303
           1       0.82      0.90      0.86     10041

    accuracy                           0.82     16344
   macro avg       0.82      0.79      0.80     16344
weighted avg       0.82      0.82      0.81     16344

Flagellin_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.81      0.68      0.74      6303
           1       0.82      0.90      0.86     10041

    accuracy                           0.82     16344
   macro avg       0.81      0.79      0.80     16344
weighted avg       0.81      0.82      0.81     16344

              precision    recall  f1-score   support

           0       0.81      0.68      0.74      6303
           1       0.82      0.90      0.86     10041

    accuracy                           0.82     16344
   macro avg       0.81      0.79      0.80     16344
weighted avg       0.81      0.82      0.81     16344

Flagellin_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.60      0.57      0.58     32887
           1       0.65      0.68      0.66     38191

    accuracy                           0.63     71078
   macro avg       0.62      0.62      0.62     71078
weighted avg       0.63      0.63      0.63     71078

              precision    recall  f1-score   support

           0       0.60      0.57      0.58     32887
           1       0.65      0.68      0.66     38191

    accuracy                           0.63     71078
   macro avg       0.62      0.62      0.62     71078
weighted avg       0.63      0.63      0.63     71078

completed
