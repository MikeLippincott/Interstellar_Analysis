[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '4b503ab7'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'b4dc0515'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '574d78d7'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '59411460'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: DMSO_0.100_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: DMSO_0.100_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (311045, 1270)
Number of total missing values across all columns: 622090
Data Subset Is Off
Wells held out for testing: ['J06' 'L10']
Wells to use for training, validation, and testing ['B06' 'C06' 'B07' 'C07' 'I06' 'I07' 'J07' 'L05' 'L11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.497966).  Saving model ...
	 Train_Loss: 0.5388 Train_Acc: 74.824 Val_Loss: 0.4980  BEST VAL Loss: 0.4980  Val_Acc: 75.546

Epoch 1: Validation loss decreased (0.497966 --> 0.479428).  Saving model ...
	 Train_Loss: 0.5154 Train_Acc: 76.254 Val_Loss: 0.4794  BEST VAL Loss: 0.4794  Val_Acc: 77.495

Epoch 2: Validation loss decreased (0.479428 --> 0.463099).  Saving model ...
	 Train_Loss: 0.4970 Train_Acc: 78.049 Val_Loss: 0.4631  BEST VAL Loss: 0.4631  Val_Acc: 79.923

Epoch 3: Validation loss decreased (0.463099 --> 0.449839).  Saving model ...
	 Train_Loss: 0.4823 Train_Acc: 79.329 Val_Loss: 0.4498  BEST VAL Loss: 0.4498  Val_Acc: 81.565

Epoch 4: Validation loss decreased (0.449839 --> 0.438776).  Saving model ...
	 Train_Loss: 0.4704 Train_Acc: 80.230 Val_Loss: 0.4388  BEST VAL Loss: 0.4388  Val_Acc: 82.336

Epoch 5: Validation loss decreased (0.438776 --> 0.429477).  Saving model ...
	 Train_Loss: 0.4603 Train_Acc: 80.923 Val_Loss: 0.4295  BEST VAL Loss: 0.4295  Val_Acc: 82.971

Epoch 6: Validation loss decreased (0.429477 --> 0.421556).  Saving model ...
	 Train_Loss: 0.4518 Train_Acc: 81.399 Val_Loss: 0.4216  BEST VAL Loss: 0.4216  Val_Acc: 83.274

Epoch 7: Validation loss decreased (0.421556 --> 0.414816).  Saving model ...
	 Train_Loss: 0.4445 Train_Acc: 81.738 Val_Loss: 0.4148  BEST VAL Loss: 0.4148  Val_Acc: 83.358

Epoch 8: Validation loss decreased (0.414816 --> 0.408819).  Saving model ...
	 Train_Loss: 0.4379 Train_Acc: 82.115 Val_Loss: 0.4088  BEST VAL Loss: 0.4088  Val_Acc: 83.518

Epoch 9: Validation loss decreased (0.408819 --> 0.403638).  Saving model ...
	 Train_Loss: 0.4324 Train_Acc: 82.303 Val_Loss: 0.4036  BEST VAL Loss: 0.4036  Val_Acc: 83.705

Epoch 10: Validation loss decreased (0.403638 --> 0.398925).  Saving model ...
	 Train_Loss: 0.4274 Train_Acc: 82.477 Val_Loss: 0.3989  BEST VAL Loss: 0.3989  Val_Acc: 84.193

Epoch 11: Validation loss decreased (0.398925 --> 0.394687).  Saving model ...
	 Train_Loss: 0.4228 Train_Acc: 82.775 Val_Loss: 0.3947  BEST VAL Loss: 0.3947  Val_Acc: 84.029

Epoch 12: Validation loss decreased (0.394687 --> 0.390883).  Saving model ...
	 Train_Loss: 0.4187 Train_Acc: 82.934 Val_Loss: 0.3909  BEST VAL Loss: 0.3909  Val_Acc: 84.285

Epoch 13: Validation loss decreased (0.390883 --> 0.387469).  Saving model ...
	 Train_Loss: 0.4150 Train_Acc: 82.986 Val_Loss: 0.3875  BEST VAL Loss: 0.3875  Val_Acc: 84.185

Epoch 14: Validation loss decreased (0.387469 --> 0.384317).  Saving model ...
	 Train_Loss: 0.4116 Train_Acc: 83.164 Val_Loss: 0.3843  BEST VAL Loss: 0.3843  Val_Acc: 84.265

Epoch 15: Validation loss decreased (0.384317 --> 0.381382).  Saving model ...
	 Train_Loss: 0.4084 Train_Acc: 83.276 Val_Loss: 0.3814  BEST VAL Loss: 0.3814  Val_Acc: 84.364

Epoch 16: Validation loss decreased (0.381382 --> 0.378934).  Saving model ...
	 Train_Loss: 0.4055 Train_Acc: 83.436 Val_Loss: 0.3789  BEST VAL Loss: 0.3789  Val_Acc: 84.304

Epoch 17: Validation loss decreased (0.378934 --> 0.376579).  Saving model ...
	 Train_Loss: 0.4029 Train_Acc: 83.427 Val_Loss: 0.3766  BEST VAL Loss: 0.3766  Val_Acc: 84.340

Epoch 18: Validation loss decreased (0.376579 --> 0.374284).  Saving model ...
	 Train_Loss: 0.4004 Train_Acc: 83.510 Val_Loss: 0.3743  BEST VAL Loss: 0.3743  Val_Acc: 84.556

Epoch 19: Validation loss decreased (0.374284 --> 0.372114).  Saving model ...
	 Train_Loss: 0.3981 Train_Acc: 83.628 Val_Loss: 0.3721  BEST VAL Loss: 0.3721  Val_Acc: 84.544

Epoch 20: Validation loss decreased (0.372114 --> 0.370062).  Saving model ...
	 Train_Loss: 0.3959 Train_Acc: 83.652 Val_Loss: 0.3701  BEST VAL Loss: 0.3701  Val_Acc: 84.648

Epoch 21: Validation loss decreased (0.370062 --> 0.368228).  Saving model ...
	 Train_Loss: 0.3939 Train_Acc: 83.831 Val_Loss: 0.3682  BEST VAL Loss: 0.3682  Val_Acc: 84.596

Epoch 22: Validation loss decreased (0.368228 --> 0.366596).  Saving model ...
	 Train_Loss: 0.3919 Train_Acc: 83.774 Val_Loss: 0.3666  BEST VAL Loss: 0.3666  Val_Acc: 84.308

Epoch 23: Validation loss decreased (0.366596 --> 0.364885).  Saving model ...
	 Train_Loss: 0.3901 Train_Acc: 83.933 Val_Loss: 0.3649  BEST VAL Loss: 0.3649  Val_Acc: 84.868

Epoch 24: Validation loss decreased (0.364885 --> 0.363342).  Saving model ...
	 Train_Loss: 0.3884 Train_Acc: 83.936 Val_Loss: 0.3633  BEST VAL Loss: 0.3633  Val_Acc: 84.820

Epoch 25: Validation loss decreased (0.363342 --> 0.361843).  Saving model ...
	 Train_Loss: 0.3867 Train_Acc: 84.004 Val_Loss: 0.3618  BEST VAL Loss: 0.3618  Val_Acc: 84.900

Epoch 26: Validation loss decreased (0.361843 --> 0.360341).  Saving model ...
	 Train_Loss: 0.3851 Train_Acc: 84.079 Val_Loss: 0.3603  BEST VAL Loss: 0.3603  Val_Acc: 85.067

Epoch 27: Validation loss decreased (0.360341 --> 0.358953).  Saving model ...
	 Train_Loss: 0.3836 Train_Acc: 84.118 Val_Loss: 0.3590  BEST VAL Loss: 0.3590  Val_Acc: 84.955

Epoch 28: Validation loss decreased (0.358953 --> 0.357570).  Saving model ...
	 Train_Loss: 0.3822 Train_Acc: 84.105 Val_Loss: 0.3576  BEST VAL Loss: 0.3576  Val_Acc: 85.239

Epoch 29: Validation loss decreased (0.357570 --> 0.356257).  Saving model ...
	 Train_Loss: 0.3809 Train_Acc: 84.099 Val_Loss: 0.3563  BEST VAL Loss: 0.3563  Val_Acc: 85.187

Epoch 30: Validation loss decreased (0.356257 --> 0.355104).  Saving model ...
	 Train_Loss: 0.3796 Train_Acc: 84.202 Val_Loss: 0.3551  BEST VAL Loss: 0.3551  Val_Acc: 85.075

Epoch 31: Validation loss decreased (0.355104 --> 0.353960).  Saving model ...
	 Train_Loss: 0.3783 Train_Acc: 84.108 Val_Loss: 0.3540  BEST VAL Loss: 0.3540  Val_Acc: 85.207

Epoch 32: Validation loss decreased (0.353960 --> 0.352782).  Saving model ...
	 Train_Loss: 0.3771 Train_Acc: 84.251 Val_Loss: 0.3528  BEST VAL Loss: 0.3528  Val_Acc: 85.479

Epoch 33: Validation loss decreased (0.352782 --> 0.351845).  Saving model ...
	 Train_Loss: 0.3760 Train_Acc: 84.218 Val_Loss: 0.3518  BEST VAL Loss: 0.3518  Val_Acc: 85.075

Epoch 34: Validation loss decreased (0.351845 --> 0.350797).  Saving model ...
	 Train_Loss: 0.3749 Train_Acc: 84.317 Val_Loss: 0.3508  BEST VAL Loss: 0.3508  Val_Acc: 85.403

Epoch 35: Validation loss decreased (0.350797 --> 0.349902).  Saving model ...
	 Train_Loss: 0.3738 Train_Acc: 84.286 Val_Loss: 0.3499  BEST VAL Loss: 0.3499  Val_Acc: 85.303

Epoch 36: Validation loss decreased (0.349902 --> 0.348944).  Saving model ...
	 Train_Loss: 0.3728 Train_Acc: 84.338 Val_Loss: 0.3489  BEST VAL Loss: 0.3489  Val_Acc: 85.347

Epoch 37: Validation loss decreased (0.348944 --> 0.348033).  Saving model ...
	 Train_Loss: 0.3718 Train_Acc: 84.356 Val_Loss: 0.3480  BEST VAL Loss: 0.3480  Val_Acc: 85.646

Epoch 38: Validation loss decreased (0.348033 --> 0.347188).  Saving model ...
	 Train_Loss: 0.3709 Train_Acc: 84.382 Val_Loss: 0.3472  BEST VAL Loss: 0.3472  Val_Acc: 85.443

Epoch 39: Validation loss decreased (0.347188 --> 0.346281).  Saving model ...
	 Train_Loss: 0.3700 Train_Acc: 84.391 Val_Loss: 0.3463  BEST VAL Loss: 0.3463  Val_Acc: 85.622

Epoch 40: Validation loss decreased (0.346281 --> 0.345432).  Saving model ...
	 Train_Loss: 0.3691 Train_Acc: 84.449 Val_Loss: 0.3454  BEST VAL Loss: 0.3454  Val_Acc: 85.507

Epoch 41: Validation loss decreased (0.345432 --> 0.344596).  Saving model ...
	 Train_Loss: 0.3682 Train_Acc: 84.449 Val_Loss: 0.3446  BEST VAL Loss: 0.3446  Val_Acc: 85.774

Epoch 42: Validation loss decreased (0.344596 --> 0.343854).  Saving model ...
	 Train_Loss: 0.3674 Train_Acc: 84.494 Val_Loss: 0.3439  BEST VAL Loss: 0.3439  Val_Acc: 85.742

Epoch 43: Validation loss decreased (0.343854 --> 0.343189).  Saving model ...
	 Train_Loss: 0.3666 Train_Acc: 84.363 Val_Loss: 0.3432  BEST VAL Loss: 0.3432  Val_Acc: 85.315

Epoch 44: Validation loss decreased (0.343189 --> 0.342400).  Saving model ...
	 Train_Loss: 0.3658 Train_Acc: 84.561 Val_Loss: 0.3424  BEST VAL Loss: 0.3424  Val_Acc: 85.850

Epoch 45: Validation loss decreased (0.342400 --> 0.341692).  Saving model ...
	 Train_Loss: 0.3651 Train_Acc: 84.584 Val_Loss: 0.3417  BEST VAL Loss: 0.3417  Val_Acc: 85.650

Epoch 46: Validation loss decreased (0.341692 --> 0.340976).  Saving model ...
	 Train_Loss: 0.3643 Train_Acc: 84.484 Val_Loss: 0.3410  BEST VAL Loss: 0.3410  Val_Acc: 85.774

Epoch 47: Validation loss decreased (0.340976 --> 0.340298).  Saving model ...
	 Train_Loss: 0.3636 Train_Acc: 84.556 Val_Loss: 0.3403  BEST VAL Loss: 0.3403  Val_Acc: 85.786

Epoch 48: Validation loss decreased (0.340298 --> 0.339635).  Saving model ...
	 Train_Loss: 0.3629 Train_Acc: 84.514 Val_Loss: 0.3396  BEST VAL Loss: 0.3396  Val_Acc: 85.942

Epoch 49: Validation loss decreased (0.339635 --> 0.338979).  Saving model ...
	 Train_Loss: 0.3623 Train_Acc: 84.548 Val_Loss: 0.3390  BEST VAL Loss: 0.3390  Val_Acc: 85.962

Epoch 50: Validation loss decreased (0.338979 --> 0.338373).  Saving model ...
	 Train_Loss: 0.3616 Train_Acc: 84.526 Val_Loss: 0.3384  BEST VAL Loss: 0.3384  Val_Acc: 85.834

Epoch 51: Validation loss decreased (0.338373 --> 0.337797).  Saving model ...
	 Train_Loss: 0.3610 Train_Acc: 84.636 Val_Loss: 0.3378  BEST VAL Loss: 0.3378  Val_Acc: 85.662

Epoch 52: Validation loss decreased (0.337797 --> 0.337206).  Saving model ...
	 Train_Loss: 0.3604 Train_Acc: 84.640 Val_Loss: 0.3372  BEST VAL Loss: 0.3372  Val_Acc: 85.850

Epoch 53: Validation loss decreased (0.337206 --> 0.336695).  Saving model ...
	 Train_Loss: 0.3598 Train_Acc: 84.604 Val_Loss: 0.3367  BEST VAL Loss: 0.3367  Val_Acc: 85.555

Epoch 54: Validation loss decreased (0.336695 --> 0.336134).  Saving model ...
	 Train_Loss: 0.3592 Train_Acc: 84.562 Val_Loss: 0.3361  BEST VAL Loss: 0.3361  Val_Acc: 85.830

Epoch 55: Validation loss decreased (0.336134 --> 0.335558).  Saving model ...
	 Train_Loss: 0.3586 Train_Acc: 84.593 Val_Loss: 0.3356  BEST VAL Loss: 0.3356  Val_Acc: 85.990

Epoch 56: Validation loss decreased (0.335558 --> 0.335032).  Saving model ...
	 Train_Loss: 0.3581 Train_Acc: 84.662 Val_Loss: 0.3350  BEST VAL Loss: 0.3350  Val_Acc: 85.994

Epoch 57: Validation loss decreased (0.335032 --> 0.334512).  Saving model ...
	 Train_Loss: 0.3575 Train_Acc: 84.646 Val_Loss: 0.3345  BEST VAL Loss: 0.3345  Val_Acc: 86.054

Epoch 58: Validation loss decreased (0.334512 --> 0.334018).  Saving model ...
	 Train_Loss: 0.3570 Train_Acc: 84.732 Val_Loss: 0.3340  BEST VAL Loss: 0.3340  Val_Acc: 86.070

Epoch 59: Validation loss decreased (0.334018 --> 0.333509).  Saving model ...
	 Train_Loss: 0.3565 Train_Acc: 84.604 Val_Loss: 0.3335  BEST VAL Loss: 0.3335  Val_Acc: 86.210

Epoch 60: Validation loss decreased (0.333509 --> 0.333065).  Saving model ...
	 Train_Loss: 0.3560 Train_Acc: 84.648 Val_Loss: 0.3331  BEST VAL Loss: 0.3331  Val_Acc: 85.850

Epoch 61: Validation loss decreased (0.333065 --> 0.332589).  Saving model ...
	 Train_Loss: 0.3555 Train_Acc: 84.701 Val_Loss: 0.3326  BEST VAL Loss: 0.3326  Val_Acc: 86.086

Epoch 62: Validation loss decreased (0.332589 --> 0.332153).  Saving model ...
	 Train_Loss: 0.3550 Train_Acc: 84.759 Val_Loss: 0.3322  BEST VAL Loss: 0.3322  Val_Acc: 85.906

Epoch 63: Validation loss decreased (0.332153 --> 0.331734).  Saving model ...
	 Train_Loss: 0.3546 Train_Acc: 84.652 Val_Loss: 0.3317  BEST VAL Loss: 0.3317  Val_Acc: 86.190

Epoch 64: Validation loss decreased (0.331734 --> 0.331306).  Saving model ...
	 Train_Loss: 0.3541 Train_Acc: 84.626 Val_Loss: 0.3313  BEST VAL Loss: 0.3313  Val_Acc: 86.393

Epoch 65: Validation loss decreased (0.331306 --> 0.330868).  Saving model ...
	 Train_Loss: 0.3536 Train_Acc: 84.716 Val_Loss: 0.3309  BEST VAL Loss: 0.3309  Val_Acc: 86.241

Epoch 66: Validation loss decreased (0.330868 --> 0.330447).  Saving model ...
	 Train_Loss: 0.3532 Train_Acc: 84.693 Val_Loss: 0.3304  BEST VAL Loss: 0.3304  Val_Acc: 86.218

Epoch 67: Validation loss decreased (0.330447 --> 0.330004).  Saving model ...
	 Train_Loss: 0.3528 Train_Acc: 84.733 Val_Loss: 0.3300  BEST VAL Loss: 0.3300  Val_Acc: 86.297

Epoch 68: Validation loss decreased (0.330004 --> 0.329616).  Saving model ...
	 Train_Loss: 0.3523 Train_Acc: 84.729 Val_Loss: 0.3296  BEST VAL Loss: 0.3296  Val_Acc: 86.102

Epoch 69: Validation loss decreased (0.329616 --> 0.329281).  Saving model ...
	 Train_Loss: 0.3519 Train_Acc: 84.697 Val_Loss: 0.3293  BEST VAL Loss: 0.3293  Val_Acc: 86.006

Epoch 70: Validation loss decreased (0.329281 --> 0.328925).  Saving model ...
	 Train_Loss: 0.3515 Train_Acc: 84.747 Val_Loss: 0.3289  BEST VAL Loss: 0.3289  Val_Acc: 86.054

Epoch 71: Validation loss decreased (0.328925 --> 0.328535).  Saving model ...
	 Train_Loss: 0.3511 Train_Acc: 84.807 Val_Loss: 0.3285  BEST VAL Loss: 0.3285  Val_Acc: 86.253

Epoch 72: Validation loss decreased (0.328535 --> 0.328197).  Saving model ...
	 Train_Loss: 0.3507 Train_Acc: 84.768 Val_Loss: 0.3282  BEST VAL Loss: 0.3282  Val_Acc: 86.018

Epoch 73: Validation loss decreased (0.328197 --> 0.327816).  Saving model ...
	 Train_Loss: 0.3503 Train_Acc: 84.838 Val_Loss: 0.3278  BEST VAL Loss: 0.3278  Val_Acc: 86.485

Epoch 74: Validation loss decreased (0.327816 --> 0.327480).  Saving model ...
	 Train_Loss: 0.3499 Train_Acc: 84.835 Val_Loss: 0.3275  BEST VAL Loss: 0.3275  Val_Acc: 86.349

Epoch 75: Validation loss decreased (0.327480 --> 0.327100).  Saving model ...
	 Train_Loss: 0.3496 Train_Acc: 84.796 Val_Loss: 0.3271  BEST VAL Loss: 0.3271  Val_Acc: 86.269

Epoch 76: Validation loss decreased (0.327100 --> 0.326758).  Saving model ...
	 Train_Loss: 0.3492 Train_Acc: 84.761 Val_Loss: 0.3268  BEST VAL Loss: 0.3268  Val_Acc: 86.465

Epoch 77: Validation loss decreased (0.326758 --> 0.326423).  Saving model ...
	 Train_Loss: 0.3488 Train_Acc: 84.741 Val_Loss: 0.3264  BEST VAL Loss: 0.3264  Val_Acc: 86.417

Epoch 78: Validation loss decreased (0.326423 --> 0.326120).  Saving model ...
	 Train_Loss: 0.3485 Train_Acc: 84.915 Val_Loss: 0.3261  BEST VAL Loss: 0.3261  Val_Acc: 86.537

Epoch 79: Validation loss decreased (0.326120 --> 0.325800).  Saving model ...
	 Train_Loss: 0.3482 Train_Acc: 84.840 Val_Loss: 0.3258  BEST VAL Loss: 0.3258  Val_Acc: 86.321

Epoch 80: Validation loss decreased (0.325800 --> 0.325482).  Saving model ...
	 Train_Loss: 0.3478 Train_Acc: 84.814 Val_Loss: 0.3255  BEST VAL Loss: 0.3255  Val_Acc: 86.389

Epoch 81: Validation loss decreased (0.325482 --> 0.325186).  Saving model ...
	 Train_Loss: 0.3475 Train_Acc: 84.844 Val_Loss: 0.3252  BEST VAL Loss: 0.3252  Val_Acc: 86.629

Epoch 82: Validation loss decreased (0.325186 --> 0.324902).  Saving model ...
	 Train_Loss: 0.3472 Train_Acc: 84.824 Val_Loss: 0.3249  BEST VAL Loss: 0.3249  Val_Acc: 86.525

Epoch 83: Validation loss decreased (0.324902 --> 0.324601).  Saving model ...
	 Train_Loss: 0.3468 Train_Acc: 84.857 Val_Loss: 0.3246  BEST VAL Loss: 0.3246  Val_Acc: 86.453

Epoch 84: Validation loss decreased (0.324601 --> 0.324349).  Saving model ...
	 Train_Loss: 0.3465 Train_Acc: 84.728 Val_Loss: 0.3243  BEST VAL Loss: 0.3243  Val_Acc: 86.261

Epoch 85: Validation loss decreased (0.324349 --> 0.324073).  Saving model ...
	 Train_Loss: 0.3462 Train_Acc: 84.785 Val_Loss: 0.3241  BEST VAL Loss: 0.3241  Val_Acc: 86.389

Epoch 86: Validation loss decreased (0.324073 --> 0.323823).  Saving model ...
	 Train_Loss: 0.3459 Train_Acc: 84.918 Val_Loss: 0.3238  BEST VAL Loss: 0.3238  Val_Acc: 86.493

Epoch 87: Validation loss decreased (0.323823 --> 0.323536).  Saving model ...
	 Train_Loss: 0.3456 Train_Acc: 84.822 Val_Loss: 0.3235  BEST VAL Loss: 0.3235  Val_Acc: 86.521

Epoch 88: Validation loss decreased (0.323536 --> 0.323282).  Saving model ...
	 Train_Loss: 0.3453 Train_Acc: 84.926 Val_Loss: 0.3233  BEST VAL Loss: 0.3233  Val_Acc: 86.497

Epoch 89: Validation loss decreased (0.323282 --> 0.323036).  Saving model ...
	 Train_Loss: 0.3450 Train_Acc: 84.968 Val_Loss: 0.3230  BEST VAL Loss: 0.3230  Val_Acc: 86.229

Epoch 90: Validation loss decreased (0.323036 --> 0.322773).  Saving model ...
	 Train_Loss: 0.3447 Train_Acc: 84.822 Val_Loss: 0.3228  BEST VAL Loss: 0.3228  Val_Acc: 86.281

Epoch 91: Validation loss decreased (0.322773 --> 0.322517).  Saving model ...
	 Train_Loss: 0.3444 Train_Acc: 84.859 Val_Loss: 0.3225  BEST VAL Loss: 0.3225  Val_Acc: 86.341

Epoch 92: Validation loss decreased (0.322517 --> 0.322256).  Saving model ...
	 Train_Loss: 0.3442 Train_Acc: 84.879 Val_Loss: 0.3223  BEST VAL Loss: 0.3223  Val_Acc: 86.617

Epoch 93: Validation loss decreased (0.322256 --> 0.322017).  Saving model ...
	 Train_Loss: 0.3439 Train_Acc: 84.846 Val_Loss: 0.3220  BEST VAL Loss: 0.3220  Val_Acc: 86.457

Epoch 94: Validation loss decreased (0.322017 --> 0.321763).  Saving model ...
	 Train_Loss: 0.3436 Train_Acc: 84.958 Val_Loss: 0.3218  BEST VAL Loss: 0.3218  Val_Acc: 86.773

Epoch 95: Validation loss decreased (0.321763 --> 0.321544).  Saving model ...
	 Train_Loss: 0.3434 Train_Acc: 84.895 Val_Loss: 0.3215  BEST VAL Loss: 0.3215  Val_Acc: 86.501

Epoch 96: Validation loss decreased (0.321544 --> 0.321288).  Saving model ...
	 Train_Loss: 0.3431 Train_Acc: 84.922 Val_Loss: 0.3213  BEST VAL Loss: 0.3213  Val_Acc: 86.481

Epoch 97: Validation loss decreased (0.321288 --> 0.321039).  Saving model ...
	 Train_Loss: 0.3428 Train_Acc: 84.909 Val_Loss: 0.3210  BEST VAL Loss: 0.3210  Val_Acc: 86.361

Epoch 98: Validation loss decreased (0.321039 --> 0.320794).  Saving model ...
	 Train_Loss: 0.3426 Train_Acc: 84.973 Val_Loss: 0.3208  BEST VAL Loss: 0.3208  Val_Acc: 86.617

Epoch 99: Validation loss decreased (0.320794 --> 0.320556).  Saving model ...
	 Train_Loss: 0.3423 Train_Acc: 84.831 Val_Loss: 0.3206  BEST VAL Loss: 0.3206  Val_Acc: 86.713

DMSO_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.89      0.96      0.92    149884
           1       0.85      0.64      0.73     50422

    accuracy                           0.88    200306
   macro avg       0.87      0.80      0.83    200306
weighted avg       0.88      0.88      0.87    200306

DMSO_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.88      0.95      0.91     18736
           1       0.81      0.62      0.70      6303

    accuracy                           0.87     25039
   macro avg       0.85      0.78      0.81     25039
weighted avg       0.86      0.87      0.86     25039

DMSO_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.88      0.95      0.92     18736
           1       0.81      0.62      0.70      6303

    accuracy                           0.87     25039
   macro avg       0.85      0.79      0.81     25039
weighted avg       0.86      0.87      0.86     25039

              precision    recall  f1-score   support

           0       0.88      0.95      0.92     18736
           1       0.81      0.62      0.70      6303

    accuracy                           0.87     25039
   macro avg       0.85      0.79      0.81     25039
weighted avg       0.86      0.87      0.86     25039

DMSO_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.70      0.93      0.80     27774
           1       0.91      0.67      0.77     32887

    accuracy                           0.79     60661
   macro avg       0.81      0.80      0.79     60661
weighted avg       0.82      0.79      0.79     60661

              precision    recall  f1-score   support

           0       0.70      0.93      0.80     27774
           1       0.91      0.67      0.77     32887

    accuracy                           0.79     60661
   macro avg       0.81      0.80      0.79     60661
weighted avg       0.82      0.79      0.79     60661

completed
