[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'cce4a519'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '9b0e35ee'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '4c0c1218'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e60b4649'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_0.010_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_0.010_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (302515, 1270)
Number of total missing values across all columns: 605030
Data Subset Is Off
Wells held out for testing: ['B08' 'J08']
Wells to use for training, validation, and testing ['B02' 'B03' 'B09' 'J02' 'J03' 'J09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.649850).  Saving model ...
	 Train_Loss: 0.6838 Train_Acc: 56.516 Val_Loss: 0.6499  BEST VAL Loss: 0.6499  Val_Acc: 61.747

Epoch 1: Validation loss decreased (0.649850 --> 0.638414).  Saving model ...
	 Train_Loss: 0.6623 Train_Acc: 62.668 Val_Loss: 0.6384  BEST VAL Loss: 0.6384  Val_Acc: 64.780

Epoch 2: Validation loss decreased (0.638414 --> 0.632705).  Saving model ...
	 Train_Loss: 0.6498 Train_Acc: 64.551 Val_Loss: 0.6327  BEST VAL Loss: 0.6327  Val_Acc: 65.397

Epoch 3: Validation loss decreased (0.632705 --> 0.629176).  Saving model ...
	 Train_Loss: 0.6417 Train_Acc: 65.464 Val_Loss: 0.6292  BEST VAL Loss: 0.6292  Val_Acc: 66.273

Epoch 4: Validation loss decreased (0.629176 --> 0.624125).  Saving model ...
	 Train_Loss: 0.6356 Train_Acc: 66.167 Val_Loss: 0.6241  BEST VAL Loss: 0.6241  Val_Acc: 67.139

Epoch 5: Validation loss decreased (0.624125 --> 0.620044).  Saving model ...
	 Train_Loss: 0.6306 Train_Acc: 66.518 Val_Loss: 0.6200  BEST VAL Loss: 0.6200  Val_Acc: 67.555

Epoch 6: Validation loss decreased (0.620044 --> 0.617093).  Saving model ...
	 Train_Loss: 0.6263 Train_Acc: 67.026 Val_Loss: 0.6171  BEST VAL Loss: 0.6171  Val_Acc: 67.721

Epoch 7: Validation loss decreased (0.617093 --> 0.614148).  Saving model ...
	 Train_Loss: 0.6227 Train_Acc: 67.138 Val_Loss: 0.6141  BEST VAL Loss: 0.6141  Val_Acc: 67.735

Epoch 8: Validation loss decreased (0.614148 --> 0.612001).  Saving model ...
	 Train_Loss: 0.6195 Train_Acc: 67.289 Val_Loss: 0.6120  BEST VAL Loss: 0.6120  Val_Acc: 67.997

Epoch 9: Validation loss decreased (0.612001 --> 0.609415).  Saving model ...
	 Train_Loss: 0.6167 Train_Acc: 67.529 Val_Loss: 0.6094  BEST VAL Loss: 0.6094  Val_Acc: 68.430

Epoch 10: Validation loss decreased (0.609415 --> 0.607224).  Saving model ...
	 Train_Loss: 0.6140 Train_Acc: 67.771 Val_Loss: 0.6072  BEST VAL Loss: 0.6072  Val_Acc: 68.032

Epoch 11: Validation loss decreased (0.607224 --> 0.605430).  Saving model ...
	 Train_Loss: 0.6115 Train_Acc: 67.878 Val_Loss: 0.6054  BEST VAL Loss: 0.6054  Val_Acc: 68.693

Epoch 12: Validation loss decreased (0.605430 --> 0.603880).  Saving model ...
	 Train_Loss: 0.6091 Train_Acc: 68.241 Val_Loss: 0.6039  BEST VAL Loss: 0.6039  Val_Acc: 68.592

Epoch 13: Validation loss decreased (0.603880 --> 0.602307).  Saving model ...
	 Train_Loss: 0.6069 Train_Acc: 68.188 Val_Loss: 0.6023  BEST VAL Loss: 0.6023  Val_Acc: 68.645

Epoch 14: Validation loss decreased (0.602307 --> 0.600745).  Saving model ...
	 Train_Loss: 0.6049 Train_Acc: 68.373 Val_Loss: 0.6007  BEST VAL Loss: 0.6007  Val_Acc: 68.969

Epoch 15: Validation loss decreased (0.600745 --> 0.599080).  Saving model ...
	 Train_Loss: 0.6029 Train_Acc: 68.461 Val_Loss: 0.5991  BEST VAL Loss: 0.5991  Val_Acc: 69.446

Epoch 16: Validation loss decreased (0.599080 --> 0.597342).  Saving model ...
	 Train_Loss: 0.6010 Train_Acc: 68.512 Val_Loss: 0.5973  BEST VAL Loss: 0.5973  Val_Acc: 69.350

Epoch 17: Validation loss decreased (0.597342 --> 0.596099).  Saving model ...
	 Train_Loss: 0.5991 Train_Acc: 68.834 Val_Loss: 0.5961  BEST VAL Loss: 0.5961  Val_Acc: 69.153

Epoch 18: Validation loss decreased (0.596099 --> 0.594343).  Saving model ...
	 Train_Loss: 0.5974 Train_Acc: 68.742 Val_Loss: 0.5943  BEST VAL Loss: 0.5943  Val_Acc: 69.975

Epoch 19: Validation loss decreased (0.594343 --> 0.592705).  Saving model ...
	 Train_Loss: 0.5956 Train_Acc: 68.926 Val_Loss: 0.5927  BEST VAL Loss: 0.5927  Val_Acc: 69.967

Epoch 20: Validation loss decreased (0.592705 --> 0.591144).  Saving model ...
	 Train_Loss: 0.5939 Train_Acc: 69.144 Val_Loss: 0.5911  BEST VAL Loss: 0.5911  Val_Acc: 70.308

Epoch 21: Validation loss decreased (0.591144 --> 0.589826).  Saving model ...
	 Train_Loss: 0.5923 Train_Acc: 69.138 Val_Loss: 0.5898  BEST VAL Loss: 0.5898  Val_Acc: 70.142

Epoch 22: Validation loss decreased (0.589826 --> 0.588637).  Saving model ...
	 Train_Loss: 0.5908 Train_Acc: 69.351 Val_Loss: 0.5886  BEST VAL Loss: 0.5886  Val_Acc: 69.940

Epoch 23: Validation loss decreased (0.588637 --> 0.587298).  Saving model ...
	 Train_Loss: 0.5893 Train_Acc: 69.260 Val_Loss: 0.5873  BEST VAL Loss: 0.5873  Val_Acc: 70.181

Epoch 24: Validation loss decreased (0.587298 --> 0.586039).  Saving model ...
	 Train_Loss: 0.5880 Train_Acc: 69.381 Val_Loss: 0.5860  BEST VAL Loss: 0.5860  Val_Acc: 70.540

Epoch 25: Validation loss decreased (0.586039 --> 0.584790).  Saving model ...
	 Train_Loss: 0.5867 Train_Acc: 69.381 Val_Loss: 0.5848  BEST VAL Loss: 0.5848  Val_Acc: 70.321

Epoch 26: Validation loss decreased (0.584790 --> 0.583677).  Saving model ...
	 Train_Loss: 0.5854 Train_Acc: 69.482 Val_Loss: 0.5837  BEST VAL Loss: 0.5837  Val_Acc: 70.448

Epoch 27: Validation loss decreased (0.583677 --> 0.582499).  Saving model ...
	 Train_Loss: 0.5842 Train_Acc: 69.455 Val_Loss: 0.5825  BEST VAL Loss: 0.5825  Val_Acc: 70.680

Epoch 28: Validation loss decreased (0.582499 --> 0.581451).  Saving model ...
	 Train_Loss: 0.5830 Train_Acc: 69.633 Val_Loss: 0.5815  BEST VAL Loss: 0.5815  Val_Acc: 70.755

Epoch 29: Validation loss decreased (0.581451 --> 0.580461).  Saving model ...
	 Train_Loss: 0.5819 Train_Acc: 69.862 Val_Loss: 0.5805  BEST VAL Loss: 0.5805  Val_Acc: 70.720

Epoch 30: Validation loss decreased (0.580461 --> 0.579484).  Saving model ...
	 Train_Loss: 0.5808 Train_Acc: 70.008 Val_Loss: 0.5795  BEST VAL Loss: 0.5795  Val_Acc: 70.755

Epoch 31: Validation loss decreased (0.579484 --> 0.578520).  Saving model ...
	 Train_Loss: 0.5797 Train_Acc: 70.014 Val_Loss: 0.5785  BEST VAL Loss: 0.5785  Val_Acc: 70.383

Epoch 32: Validation loss decreased (0.578520 --> 0.577669).  Saving model ...
	 Train_Loss: 0.5787 Train_Acc: 69.977 Val_Loss: 0.5777  BEST VAL Loss: 0.5777  Val_Acc: 71.131

Epoch 33: Validation loss decreased (0.577669 --> 0.576771).  Saving model ...
	 Train_Loss: 0.5777 Train_Acc: 70.049 Val_Loss: 0.5768  BEST VAL Loss: 0.5768  Val_Acc: 70.873

Epoch 34: Validation loss decreased (0.576771 --> 0.575902).  Saving model ...
	 Train_Loss: 0.5767 Train_Acc: 70.243 Val_Loss: 0.5759  BEST VAL Loss: 0.5759  Val_Acc: 70.715

Epoch 35: Validation loss decreased (0.575902 --> 0.575150).  Saving model ...
	 Train_Loss: 0.5758 Train_Acc: 70.068 Val_Loss: 0.5751  BEST VAL Loss: 0.5751  Val_Acc: 70.973

Epoch 36: Validation loss decreased (0.575150 --> 0.574355).  Saving model ...
	 Train_Loss: 0.5749 Train_Acc: 70.085 Val_Loss: 0.5744  BEST VAL Loss: 0.5744  Val_Acc: 70.663

Epoch 37: Validation loss decreased (0.574355 --> 0.573521).  Saving model ...
	 Train_Loss: 0.5741 Train_Acc: 70.291 Val_Loss: 0.5735  BEST VAL Loss: 0.5735  Val_Acc: 71.442

Epoch 38: Validation loss decreased (0.573521 --> 0.572880).  Saving model ...
	 Train_Loss: 0.5733 Train_Acc: 70.189 Val_Loss: 0.5729  BEST VAL Loss: 0.5729  Val_Acc: 70.995

Epoch 39: Validation loss decreased (0.572880 --> 0.572183).  Saving model ...
	 Train_Loss: 0.5725 Train_Acc: 70.309 Val_Loss: 0.5722  BEST VAL Loss: 0.5722  Val_Acc: 71.065

Epoch 40: Validation loss decreased (0.572183 --> 0.571584).  Saving model ...
	 Train_Loss: 0.5717 Train_Acc: 70.322 Val_Loss: 0.5716  BEST VAL Loss: 0.5716  Val_Acc: 70.960

Epoch 41: Validation loss decreased (0.571584 --> 0.571013).  Saving model ...
	 Train_Loss: 0.5710 Train_Acc: 70.311 Val_Loss: 0.5710  BEST VAL Loss: 0.5710  Val_Acc: 71.415

Epoch 42: Validation loss decreased (0.571013 --> 0.570355).  Saving model ...
	 Train_Loss: 0.5703 Train_Acc: 70.377 Val_Loss: 0.5704  BEST VAL Loss: 0.5704  Val_Acc: 71.560

Epoch 43: Validation loss decreased (0.570355 --> 0.569846).  Saving model ...
	 Train_Loss: 0.5696 Train_Acc: 70.522 Val_Loss: 0.5698  BEST VAL Loss: 0.5698  Val_Acc: 70.938

Epoch 44: Validation loss decreased (0.569846 --> 0.569392).  Saving model ...
	 Train_Loss: 0.5689 Train_Acc: 70.603 Val_Loss: 0.5694  BEST VAL Loss: 0.5694  Val_Acc: 70.523

Epoch 45: Validation loss decreased (0.569392 --> 0.568767).  Saving model ...
	 Train_Loss: 0.5682 Train_Acc: 70.456 Val_Loss: 0.5688  BEST VAL Loss: 0.5688  Val_Acc: 71.477

Epoch 46: Validation loss decreased (0.568767 --> 0.568191).  Saving model ...
	 Train_Loss: 0.5675 Train_Acc: 70.534 Val_Loss: 0.5682  BEST VAL Loss: 0.5682  Val_Acc: 71.626

Epoch 47: Validation loss decreased (0.568191 --> 0.567793).  Saving model ...
	 Train_Loss: 0.5669 Train_Acc: 70.514 Val_Loss: 0.5678  BEST VAL Loss: 0.5678  Val_Acc: 71.048

Epoch 48: Validation loss decreased (0.567793 --> 0.567276).  Saving model ...
	 Train_Loss: 0.5663 Train_Acc: 70.534 Val_Loss: 0.5673  BEST VAL Loss: 0.5673  Val_Acc: 71.739

Epoch 49: Validation loss decreased (0.567276 --> 0.566755).  Saving model ...
	 Train_Loss: 0.5657 Train_Acc: 70.638 Val_Loss: 0.5668  BEST VAL Loss: 0.5668  Val_Acc: 71.385

Epoch 50: Validation loss decreased (0.566755 --> 0.566323).  Saving model ...
	 Train_Loss: 0.5651 Train_Acc: 70.712 Val_Loss: 0.5663  BEST VAL Loss: 0.5663  Val_Acc: 71.267

Epoch 51: Validation loss decreased (0.566323 --> 0.565871).  Saving model ...
	 Train_Loss: 0.5646 Train_Acc: 70.635 Val_Loss: 0.5659  BEST VAL Loss: 0.5659  Val_Acc: 71.591

Epoch 52: Validation loss decreased (0.565871 --> 0.565445).  Saving model ...
	 Train_Loss: 0.5640 Train_Acc: 70.575 Val_Loss: 0.5654  BEST VAL Loss: 0.5654  Val_Acc: 71.827

Epoch 53: Validation loss decreased (0.565445 --> 0.564952).  Saving model ...
	 Train_Loss: 0.5635 Train_Acc: 70.597 Val_Loss: 0.5650  BEST VAL Loss: 0.5650  Val_Acc: 71.608

Epoch 54: Validation loss decreased (0.564952 --> 0.564513).  Saving model ...
	 Train_Loss: 0.5630 Train_Acc: 70.869 Val_Loss: 0.5645  BEST VAL Loss: 0.5645  Val_Acc: 71.411

Epoch 55: Validation loss decreased (0.564513 --> 0.564094).  Saving model ...
	 Train_Loss: 0.5625 Train_Acc: 70.779 Val_Loss: 0.5641  BEST VAL Loss: 0.5641  Val_Acc: 71.398

Epoch 56: Validation loss decreased (0.564094 --> 0.563675).  Saving model ...
	 Train_Loss: 0.5620 Train_Acc: 70.903 Val_Loss: 0.5637  BEST VAL Loss: 0.5637  Val_Acc: 72.138

Epoch 57: Validation loss decreased (0.563675 --> 0.563272).  Saving model ...
	 Train_Loss: 0.5615 Train_Acc: 70.808 Val_Loss: 0.5633  BEST VAL Loss: 0.5633  Val_Acc: 71.551

Epoch 58: Validation loss decreased (0.563272 --> 0.562946).  Saving model ...
	 Train_Loss: 0.5610 Train_Acc: 70.994 Val_Loss: 0.5629  BEST VAL Loss: 0.5629  Val_Acc: 71.757

Epoch 59: Validation loss decreased (0.562946 --> 0.562578).  Saving model ...
	 Train_Loss: 0.5606 Train_Acc: 70.752 Val_Loss: 0.5626  BEST VAL Loss: 0.5626  Val_Acc: 71.980

Epoch 60: Validation loss decreased (0.562578 --> 0.562283).  Saving model ...
	 Train_Loss: 0.5601 Train_Acc: 71.022 Val_Loss: 0.5623  BEST VAL Loss: 0.5623  Val_Acc: 71.569

Epoch 61: Validation loss decreased (0.562283 --> 0.561957).  Saving model ...
	 Train_Loss: 0.5596 Train_Acc: 70.849 Val_Loss: 0.5620  BEST VAL Loss: 0.5620  Val_Acc: 71.503

Epoch 62: Validation loss decreased (0.561957 --> 0.561612).  Saving model ...
	 Train_Loss: 0.5592 Train_Acc: 70.889 Val_Loss: 0.5616  BEST VAL Loss: 0.5616  Val_Acc: 71.989

Epoch 63: Validation loss decreased (0.561612 --> 0.561388).  Saving model ...
	 Train_Loss: 0.5588 Train_Acc: 70.878 Val_Loss: 0.5614  BEST VAL Loss: 0.5614  Val_Acc: 71.752

Epoch 64: Validation loss decreased (0.561388 --> 0.561037).  Saving model ...
	 Train_Loss: 0.5584 Train_Acc: 71.018 Val_Loss: 0.5610  BEST VAL Loss: 0.5610  Val_Acc: 71.840

Epoch 65: Validation loss decreased (0.561037 --> 0.560736).  Saving model ...
	 Train_Loss: 0.5579 Train_Acc: 70.988 Val_Loss: 0.5607  BEST VAL Loss: 0.5607  Val_Acc: 71.726

Epoch 66: Validation loss decreased (0.560736 --> 0.560427).  Saving model ...
	 Train_Loss: 0.5575 Train_Acc: 70.985 Val_Loss: 0.5604  BEST VAL Loss: 0.5604  Val_Acc: 71.761

Epoch 67: Validation loss decreased (0.560427 --> 0.560064).  Saving model ...
	 Train_Loss: 0.5571 Train_Acc: 71.125 Val_Loss: 0.5601  BEST VAL Loss: 0.5601  Val_Acc: 71.923

Epoch 68: Validation loss decreased (0.560064 --> 0.559728).  Saving model ...
	 Train_Loss: 0.5567 Train_Acc: 71.018 Val_Loss: 0.5597  BEST VAL Loss: 0.5597  Val_Acc: 72.041

Epoch 69: Validation loss decreased (0.559728 --> 0.559456).  Saving model ...
	 Train_Loss: 0.5564 Train_Acc: 70.966 Val_Loss: 0.5595  BEST VAL Loss: 0.5595  Val_Acc: 72.011

Epoch 70: Validation loss decreased (0.559456 --> 0.559254).  Saving model ...
	 Train_Loss: 0.5560 Train_Acc: 70.851 Val_Loss: 0.5593  BEST VAL Loss: 0.5593  Val_Acc: 71.595

Epoch 71: Validation loss decreased (0.559254 --> 0.559036).  Saving model ...
	 Train_Loss: 0.5557 Train_Acc: 71.024 Val_Loss: 0.5590  BEST VAL Loss: 0.5590  Val_Acc: 72.116

Epoch 72: Validation loss decreased (0.559036 --> 0.558802).  Saving model ...
	 Train_Loss: 0.5553 Train_Acc: 71.046 Val_Loss: 0.5588  BEST VAL Loss: 0.5588  Val_Acc: 71.534

Epoch 73: Validation loss decreased (0.558802 --> 0.558526).  Saving model ...
	 Train_Loss: 0.5550 Train_Acc: 71.138 Val_Loss: 0.5585  BEST VAL Loss: 0.5585  Val_Acc: 71.591

Epoch 74: Validation loss decreased (0.558526 --> 0.558271).  Saving model ...
	 Train_Loss: 0.5546 Train_Acc: 71.071 Val_Loss: 0.5583  BEST VAL Loss: 0.5583  Val_Acc: 71.919

Epoch 75: Validation loss decreased (0.558271 --> 0.558006).  Saving model ...
	 Train_Loss: 0.5543 Train_Acc: 71.231 Val_Loss: 0.5580  BEST VAL Loss: 0.5580  Val_Acc: 72.085

Epoch 76: Validation loss decreased (0.558006 --> 0.557741).  Saving model ...
	 Train_Loss: 0.5540 Train_Acc: 71.102 Val_Loss: 0.5577  BEST VAL Loss: 0.5577  Val_Acc: 71.739

Epoch 77: Validation loss decreased (0.557741 --> 0.557486).  Saving model ...
	 Train_Loss: 0.5536 Train_Acc: 71.215 Val_Loss: 0.5575  BEST VAL Loss: 0.5575  Val_Acc: 71.748

Epoch 78: Validation loss decreased (0.557486 --> 0.557273).  Saving model ...
	 Train_Loss: 0.5533 Train_Acc: 71.149 Val_Loss: 0.5573  BEST VAL Loss: 0.5573  Val_Acc: 71.888

Epoch 79: Validation loss decreased (0.557273 --> 0.557014).  Saving model ...
	 Train_Loss: 0.5530 Train_Acc: 71.113 Val_Loss: 0.5570  BEST VAL Loss: 0.5570  Val_Acc: 72.085

Epoch 80: Validation loss decreased (0.557014 --> 0.556803).  Saving model ...
	 Train_Loss: 0.5527 Train_Acc: 71.081 Val_Loss: 0.5568  BEST VAL Loss: 0.5568  Val_Acc: 71.691

Epoch 81: Validation loss decreased (0.556803 --> 0.556607).  Saving model ...
	 Train_Loss: 0.5524 Train_Acc: 71.150 Val_Loss: 0.5566  BEST VAL Loss: 0.5566  Val_Acc: 71.547

Epoch 82: Validation loss decreased (0.556607 --> 0.556341).  Saving model ...
	 Train_Loss: 0.5521 Train_Acc: 71.103 Val_Loss: 0.5563  BEST VAL Loss: 0.5563  Val_Acc: 72.492

Epoch 83: Validation loss decreased (0.556341 --> 0.556131).  Saving model ...
	 Train_Loss: 0.5519 Train_Acc: 71.132 Val_Loss: 0.5561  BEST VAL Loss: 0.5561  Val_Acc: 71.853

Epoch 84: Validation loss decreased (0.556131 --> 0.555954).  Saving model ...
	 Train_Loss: 0.5516 Train_Acc: 71.186 Val_Loss: 0.5560  BEST VAL Loss: 0.5560  Val_Acc: 72.230

Epoch 85: Validation loss decreased (0.555954 --> 0.555812).  Saving model ...
	 Train_Loss: 0.5513 Train_Acc: 71.108 Val_Loss: 0.5558  BEST VAL Loss: 0.5558  Val_Acc: 71.844

Epoch 86: Validation loss decreased (0.555812 --> 0.555608).  Saving model ...
	 Train_Loss: 0.5510 Train_Acc: 71.234 Val_Loss: 0.5556  BEST VAL Loss: 0.5556  Val_Acc: 71.779

Epoch 87: Validation loss decreased (0.555608 --> 0.555453).  Saving model ...
	 Train_Loss: 0.5507 Train_Acc: 71.243 Val_Loss: 0.5555  BEST VAL Loss: 0.5555  Val_Acc: 71.980

Epoch 88: Validation loss decreased (0.555453 --> 0.555314).  Saving model ...
	 Train_Loss: 0.5505 Train_Acc: 71.192 Val_Loss: 0.5553  BEST VAL Loss: 0.5553  Val_Acc: 72.072

Epoch 89: Validation loss decreased (0.555314 --> 0.555120).  Saving model ...
	 Train_Loss: 0.5502 Train_Acc: 71.224 Val_Loss: 0.5551  BEST VAL Loss: 0.5551  Val_Acc: 72.383

Epoch 90: Validation loss decreased (0.555120 --> 0.554969).  Saving model ...
	 Train_Loss: 0.5500 Train_Acc: 71.179 Val_Loss: 0.5550  BEST VAL Loss: 0.5550  Val_Acc: 72.173

Epoch 91: Validation loss decreased (0.554969 --> 0.554785).  Saving model ...
	 Train_Loss: 0.5497 Train_Acc: 71.208 Val_Loss: 0.5548  BEST VAL Loss: 0.5548  Val_Acc: 72.054

Epoch 92: Validation loss decreased (0.554785 --> 0.554607).  Saving model ...
	 Train_Loss: 0.5495 Train_Acc: 71.266 Val_Loss: 0.5546  BEST VAL Loss: 0.5546  Val_Acc: 72.291

Epoch 93: Validation loss decreased (0.554607 --> 0.554450).  Saving model ...
	 Train_Loss: 0.5492 Train_Acc: 71.321 Val_Loss: 0.5544  BEST VAL Loss: 0.5544  Val_Acc: 72.046

Epoch 94: Validation loss decreased (0.554450 --> 0.554238).  Saving model ...
	 Train_Loss: 0.5490 Train_Acc: 71.144 Val_Loss: 0.5542  BEST VAL Loss: 0.5542  Val_Acc: 72.151

Epoch 95: Validation loss decreased (0.554238 --> 0.554053).  Saving model ...
	 Train_Loss: 0.5487 Train_Acc: 71.188 Val_Loss: 0.5541  BEST VAL Loss: 0.5541  Val_Acc: 71.774

Epoch 96: Validation loss decreased (0.554053 --> 0.553899).  Saving model ...
	 Train_Loss: 0.5485 Train_Acc: 71.246 Val_Loss: 0.5539  BEST VAL Loss: 0.5539  Val_Acc: 71.674

Epoch 97: Validation loss decreased (0.553899 --> 0.553728).  Saving model ...
	 Train_Loss: 0.5483 Train_Acc: 71.372 Val_Loss: 0.5537  BEST VAL Loss: 0.5537  Val_Acc: 72.321

Epoch 98: Validation loss decreased (0.553728 --> 0.553587).  Saving model ...
	 Train_Loss: 0.5481 Train_Acc: 71.292 Val_Loss: 0.5536  BEST VAL Loss: 0.5536  Val_Acc: 71.971

Epoch 99: Validation loss decreased (0.553587 --> 0.553519).  Saving model ...
	 Train_Loss: 0.5479 Train_Acc: 71.317 Val_Loss: 0.5535  BEST VAL Loss: 0.5535  Val_Acc: 71.757

LPS_0.010_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.39      0.43     85026
           1       0.54      0.61      0.57     97753

    accuracy                           0.51    182779
   macro avg       0.50      0.50      0.50    182779
weighted avg       0.50      0.51      0.50    182779

LPS_0.010_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.38      0.42     10629
           1       0.53      0.61      0.57     12219

    accuracy                           0.50     22848
   macro avg       0.50      0.50      0.49     22848
weighted avg       0.50      0.50      0.50     22848

LPS_0.010_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.40      0.43     10628
           1       0.54      0.61      0.57     12220

    accuracy                           0.51     22848
   macro avg       0.50      0.50      0.50     22848
weighted avg       0.50      0.51      0.50     22848

              precision    recall  f1-score   support

           0       0.47      0.40      0.43     10628
           1       0.54      0.61      0.57     12220

    accuracy                           0.51     22848
   macro avg       0.50      0.50      0.50     22848
weighted avg       0.50      0.51      0.50     22848

LPS_0.010_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.40      0.45     36797
           1       0.50      0.60      0.55     37243

    accuracy                           0.50     74040
   macro avg       0.50      0.50      0.50     74040
weighted avg       0.50      0.50      0.50     74040

              precision    recall  f1-score   support

           0       0.50      0.40      0.45     36797
           1       0.50      0.60      0.55     37243

    accuracy                           0.50     74040
   macro avg       0.50      0.50      0.50     74040
weighted avg       0.50      0.50      0.50     74040

completed
