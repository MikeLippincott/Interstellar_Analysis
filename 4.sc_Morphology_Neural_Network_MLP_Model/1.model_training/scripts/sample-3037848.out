[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'f1db7bb8'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '8ee9890f'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '88e9d316'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '0a16e7ec'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Thapsigargin_10.000_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Thapsigargin_10.000_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (262899, 1270)
Number of total missing values across all columns: 525798
Data Subset Is Off
Wells held out for testing: ['L06' 'L10']
Wells to use for training, validation, and testing ['E06' 'E07' 'L05' 'L07' 'L11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.454311).  Saving model ...
	 Train_Loss: 0.5079 Train_Acc: 76.350 Val_Loss: 0.4543  BEST VAL Loss: 0.4543  Val_Acc: 78.422

Epoch 1: Validation loss decreased (0.454311 --> 0.396629).  Saving model ...
	 Train_Loss: 0.4431 Train_Acc: 82.287 Val_Loss: 0.3966  BEST VAL Loss: 0.3966  Val_Acc: 85.511

Epoch 2: Validation loss decreased (0.396629 --> 0.368107).  Saving model ...
	 Train_Loss: 0.4089 Train_Acc: 84.380 Val_Loss: 0.3681  BEST VAL Loss: 0.3681  Val_Acc: 86.867

Epoch 3: Validation loss decreased (0.368107 --> 0.362108).  Saving model ...
	 Train_Loss: 0.3865 Train_Acc: 85.699 Val_Loss: 0.3621  BEST VAL Loss: 0.3621  Val_Acc: 85.213

Epoch 4: Validation loss decreased (0.362108 --> 0.339782).  Saving model ...
	 Train_Loss: 0.3699 Train_Acc: 86.441 Val_Loss: 0.3398  BEST VAL Loss: 0.3398  Val_Acc: 89.498

Epoch 5: Validation loss decreased (0.339782 --> 0.334846).  Saving model ...
	 Train_Loss: 0.3571 Train_Acc: 86.935 Val_Loss: 0.3348  BEST VAL Loss: 0.3348  Val_Acc: 87.007

Epoch 6: Validation loss did not decrease
	 Train_Loss: 0.3469 Train_Acc: 87.344 Val_Loss: 0.3354  BEST VAL Loss: 0.3348  Val_Acc: 85.759

Epoch 7: Validation loss decreased (0.334846 --> 0.326824).  Saving model ...
	 Train_Loss: 0.3383 Train_Acc: 87.748 Val_Loss: 0.3268  BEST VAL Loss: 0.3268  Val_Acc: 89.087

Epoch 8: Validation loss decreased (0.326824 --> 0.318828).  Saving model ...
	 Train_Loss: 0.3310 Train_Acc: 87.954 Val_Loss: 0.3188  BEST VAL Loss: 0.3188  Val_Acc: 89.568

Epoch 9: Validation loss decreased (0.318828 --> 0.309555).  Saving model ...
	 Train_Loss: 0.3248 Train_Acc: 88.166 Val_Loss: 0.3096  BEST VAL Loss: 0.3096  Val_Acc: 90.692

Epoch 10: Validation loss decreased (0.309555 --> 0.301537).  Saving model ...
	 Train_Loss: 0.3192 Train_Acc: 88.348 Val_Loss: 0.3015  BEST VAL Loss: 0.3015  Val_Acc: 90.773

Epoch 11: Validation loss decreased (0.301537 --> 0.296639).  Saving model ...
	 Train_Loss: 0.3143 Train_Acc: 88.516 Val_Loss: 0.2966  BEST VAL Loss: 0.2966  Val_Acc: 90.000

Epoch 12: Validation loss decreased (0.296639 --> 0.290424).  Saving model ...
	 Train_Loss: 0.3098 Train_Acc: 88.656 Val_Loss: 0.2904  BEST VAL Loss: 0.2904  Val_Acc: 91.210

Epoch 13: Validation loss decreased (0.290424 --> 0.285693).  Saving model ...
	 Train_Loss: 0.3056 Train_Acc: 88.838 Val_Loss: 0.2857  BEST VAL Loss: 0.2857  Val_Acc: 90.665

Epoch 14: Validation loss decreased (0.285693 --> 0.282391).  Saving model ...
	 Train_Loss: 0.3019 Train_Acc: 88.971 Val_Loss: 0.2824  BEST VAL Loss: 0.2824  Val_Acc: 90.097

Epoch 15: Validation loss decreased (0.282391 --> 0.280900).  Saving model ...
	 Train_Loss: 0.2986 Train_Acc: 89.021 Val_Loss: 0.2809  BEST VAL Loss: 0.2809  Val_Acc: 89.211

Epoch 16: Validation loss decreased (0.280900 --> 0.276416).  Saving model ...
	 Train_Loss: 0.2955 Train_Acc: 88.981 Val_Loss: 0.2764  BEST VAL Loss: 0.2764  Val_Acc: 91.713

Epoch 17: Validation loss decreased (0.276416 --> 0.274367).  Saving model ...
	 Train_Loss: 0.2927 Train_Acc: 89.255 Val_Loss: 0.2744  BEST VAL Loss: 0.2744  Val_Acc: 90.438

Epoch 18: Validation loss decreased (0.274367 --> 0.270874).  Saving model ...
	 Train_Loss: 0.2900 Train_Acc: 89.233 Val_Loss: 0.2709  BEST VAL Loss: 0.2709  Val_Acc: 91.421

Epoch 19: Validation loss decreased (0.270874 --> 0.269117).  Saving model ...
	 Train_Loss: 0.2875 Train_Acc: 89.254 Val_Loss: 0.2691  BEST VAL Loss: 0.2691  Val_Acc: 90.232

Epoch 20: Validation loss decreased (0.269117 --> 0.266776).  Saving model ...
	 Train_Loss: 0.2852 Train_Acc: 89.349 Val_Loss: 0.2668  BEST VAL Loss: 0.2668  Val_Acc: 91.313

Epoch 21: Validation loss decreased (0.266776 --> 0.264553).  Saving model ...
	 Train_Loss: 0.2829 Train_Acc: 89.581 Val_Loss: 0.2646  BEST VAL Loss: 0.2646  Val_Acc: 91.124

Epoch 22: Validation loss decreased (0.264553 --> 0.261465).  Saving model ...
	 Train_Loss: 0.2809 Train_Acc: 89.474 Val_Loss: 0.2615  BEST VAL Loss: 0.2615  Val_Acc: 92.037

Epoch 23: Validation loss decreased (0.261465 --> 0.259215).  Saving model ...
	 Train_Loss: 0.2789 Train_Acc: 89.580 Val_Loss: 0.2592  BEST VAL Loss: 0.2592  Val_Acc: 91.507

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.2770 Train_Acc: 89.610 Val_Loss: 0.2595  BEST VAL Loss: 0.2592  Val_Acc: 89.487

Epoch 25: Validation loss decreased (0.259215 --> 0.257192).  Saving model ...
	 Train_Loss: 0.2752 Train_Acc: 89.693 Val_Loss: 0.2572  BEST VAL Loss: 0.2572  Val_Acc: 91.929

Epoch 26: Validation loss decreased (0.257192 --> 0.254897).  Saving model ...
	 Train_Loss: 0.2736 Train_Acc: 89.636 Val_Loss: 0.2549  BEST VAL Loss: 0.2549  Val_Acc: 92.048

Epoch 27: Validation loss decreased (0.254897 --> 0.252831).  Saving model ...
	 Train_Loss: 0.2720 Train_Acc: 89.728 Val_Loss: 0.2528  BEST VAL Loss: 0.2528  Val_Acc: 91.891

Epoch 28: Validation loss decreased (0.252831 --> 0.250866).  Saving model ...
	 Train_Loss: 0.2705 Train_Acc: 89.671 Val_Loss: 0.2509  BEST VAL Loss: 0.2509  Val_Acc: 91.815

Epoch 29: Validation loss decreased (0.250866 --> 0.250038).  Saving model ...
	 Train_Loss: 0.2690 Train_Acc: 89.886 Val_Loss: 0.2500  BEST VAL Loss: 0.2500  Val_Acc: 90.902

Epoch 30: Validation loss decreased (0.250038 --> 0.248293).  Saving model ...
	 Train_Loss: 0.2676 Train_Acc: 89.909 Val_Loss: 0.2483  BEST VAL Loss: 0.2483  Val_Acc: 92.220

Epoch 31: Validation loss decreased (0.248293 --> 0.247054).  Saving model ...
	 Train_Loss: 0.2663 Train_Acc: 89.816 Val_Loss: 0.2471  BEST VAL Loss: 0.2471  Val_Acc: 91.648

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.2650 Train_Acc: 90.007 Val_Loss: 0.2491  BEST VAL Loss: 0.2471  Val_Acc: 87.218

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.2638 Train_Acc: 90.008 Val_Loss: 0.2471  BEST VAL Loss: 0.2471  Val_Acc: 92.593

Epoch 34: Validation loss decreased (0.247054 --> 0.245782).  Saving model ...
	 Train_Loss: 0.2626 Train_Acc: 89.918 Val_Loss: 0.2458  BEST VAL Loss: 0.2458  Val_Acc: 91.794

Epoch 35: Validation loss decreased (0.245782 --> 0.244023).  Saving model ...
	 Train_Loss: 0.2615 Train_Acc: 89.998 Val_Loss: 0.2440  BEST VAL Loss: 0.2440  Val_Acc: 92.599

Epoch 36: Validation loss decreased (0.244023 --> 0.242819).  Saving model ...
	 Train_Loss: 0.2604 Train_Acc: 89.974 Val_Loss: 0.2428  BEST VAL Loss: 0.2428  Val_Acc: 91.777

Epoch 37: Validation loss decreased (0.242819 --> 0.241358).  Saving model ...
	 Train_Loss: 0.2594 Train_Acc: 90.051 Val_Loss: 0.2414  BEST VAL Loss: 0.2414  Val_Acc: 92.366

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.2584 Train_Acc: 90.058 Val_Loss: 0.2417  BEST VAL Loss: 0.2414  Val_Acc: 89.887

Epoch 39: Validation loss decreased (0.241358 --> 0.240178).  Saving model ...
	 Train_Loss: 0.2574 Train_Acc: 90.080 Val_Loss: 0.2402  BEST VAL Loss: 0.2402  Val_Acc: 92.599

Epoch 40: Validation loss decreased (0.240178 --> 0.238904).  Saving model ...
	 Train_Loss: 0.2565 Train_Acc: 90.098 Val_Loss: 0.2389  BEST VAL Loss: 0.2389  Val_Acc: 92.312

Epoch 41: Validation loss decreased (0.238904 --> 0.237597).  Saving model ...
	 Train_Loss: 0.2555 Train_Acc: 90.259 Val_Loss: 0.2376  BEST VAL Loss: 0.2376  Val_Acc: 92.512

Epoch 42: Validation loss decreased (0.237597 --> 0.236445).  Saving model ...
	 Train_Loss: 0.2546 Train_Acc: 90.175 Val_Loss: 0.2364  BEST VAL Loss: 0.2364  Val_Acc: 92.037

Epoch 43: Validation loss decreased (0.236445 --> 0.235581).  Saving model ...
	 Train_Loss: 0.2538 Train_Acc: 90.308 Val_Loss: 0.2356  BEST VAL Loss: 0.2356  Val_Acc: 92.107

Epoch 44: Validation loss decreased (0.235581 --> 0.234583).  Saving model ...
	 Train_Loss: 0.2529 Train_Acc: 90.182 Val_Loss: 0.2346  BEST VAL Loss: 0.2346  Val_Acc: 92.220

Epoch 45: Validation loss decreased (0.234583 --> 0.233501).  Saving model ...
	 Train_Loss: 0.2521 Train_Acc: 90.279 Val_Loss: 0.2335  BEST VAL Loss: 0.2335  Val_Acc: 92.388

Epoch 46: Validation loss decreased (0.233501 --> 0.232385).  Saving model ...
	 Train_Loss: 0.2513 Train_Acc: 90.249 Val_Loss: 0.2324  BEST VAL Loss: 0.2324  Val_Acc: 92.550

Epoch 47: Validation loss decreased (0.232385 --> 0.231706).  Saving model ...
	 Train_Loss: 0.2505 Train_Acc: 90.244 Val_Loss: 0.2317  BEST VAL Loss: 0.2317  Val_Acc: 92.134

Epoch 48: Validation loss decreased (0.231706 --> 0.230705).  Saving model ...
	 Train_Loss: 0.2498 Train_Acc: 90.285 Val_Loss: 0.2307  BEST VAL Loss: 0.2307  Val_Acc: 92.577

Epoch 49: Validation loss decreased (0.230705 --> 0.230450).  Saving model ...
	 Train_Loss: 0.2490 Train_Acc: 90.363 Val_Loss: 0.2305  BEST VAL Loss: 0.2305  Val_Acc: 91.642

Epoch 50: Validation loss decreased (0.230450 --> 0.229481).  Saving model ...
	 Train_Loss: 0.2484 Train_Acc: 90.306 Val_Loss: 0.2295  BEST VAL Loss: 0.2295  Val_Acc: 92.669

Epoch 51: Validation loss decreased (0.229481 --> 0.228609).  Saving model ...
	 Train_Loss: 0.2476 Train_Acc: 90.438 Val_Loss: 0.2286  BEST VAL Loss: 0.2286  Val_Acc: 92.696

Epoch 52: Validation loss decreased (0.228609 --> 0.227798).  Saving model ...
	 Train_Loss: 0.2470 Train_Acc: 90.354 Val_Loss: 0.2278  BEST VAL Loss: 0.2278  Val_Acc: 92.388

Epoch 53: Validation loss decreased (0.227798 --> 0.227068).  Saving model ...
	 Train_Loss: 0.2463 Train_Acc: 90.352 Val_Loss: 0.2271  BEST VAL Loss: 0.2271  Val_Acc: 92.582

Epoch 54: Validation loss decreased (0.227068 --> 0.226209).  Saving model ...
	 Train_Loss: 0.2457 Train_Acc: 90.448 Val_Loss: 0.2262  BEST VAL Loss: 0.2262  Val_Acc: 92.788

Epoch 55: Validation loss decreased (0.226209 --> 0.225334).  Saving model ...
	 Train_Loss: 0.2450 Train_Acc: 90.491 Val_Loss: 0.2253  BEST VAL Loss: 0.2253  Val_Acc: 92.685

Epoch 56: Validation loss decreased (0.225334 --> 0.224657).  Saving model ...
	 Train_Loss: 0.2444 Train_Acc: 90.429 Val_Loss: 0.2247  BEST VAL Loss: 0.2247  Val_Acc: 92.620

Epoch 57: Validation loss decreased (0.224657 --> 0.224189).  Saving model ...
	 Train_Loss: 0.2438 Train_Acc: 90.479 Val_Loss: 0.2242  BEST VAL Loss: 0.2242  Val_Acc: 92.015

Epoch 58: Validation loss decreased (0.224189 --> 0.223430).  Saving model ...
	 Train_Loss: 0.2433 Train_Acc: 90.413 Val_Loss: 0.2234  BEST VAL Loss: 0.2234  Val_Acc: 92.701

Epoch 59: Validation loss decreased (0.223430 --> 0.222801).  Saving model ...
	 Train_Loss: 0.2427 Train_Acc: 90.468 Val_Loss: 0.2228  BEST VAL Loss: 0.2228  Val_Acc: 92.631

Epoch 60: Validation loss decreased (0.222801 --> 0.222381).  Saving model ...
	 Train_Loss: 0.2421 Train_Acc: 90.560 Val_Loss: 0.2224  BEST VAL Loss: 0.2224  Val_Acc: 92.150

Epoch 61: Validation loss decreased (0.222381 --> 0.221619).  Saving model ...
	 Train_Loss: 0.2415 Train_Acc: 90.628 Val_Loss: 0.2216  BEST VAL Loss: 0.2216  Val_Acc: 92.782

Epoch 62: Validation loss decreased (0.221619 --> 0.221176).  Saving model ...
	 Train_Loss: 0.2410 Train_Acc: 90.555 Val_Loss: 0.2212  BEST VAL Loss: 0.2212  Val_Acc: 92.177

Epoch 63: Validation loss decreased (0.221176 --> 0.220509).  Saving model ...
	 Train_Loss: 0.2404 Train_Acc: 90.612 Val_Loss: 0.2205  BEST VAL Loss: 0.2205  Val_Acc: 92.766

Epoch 64: Validation loss decreased (0.220509 --> 0.219911).  Saving model ...
	 Train_Loss: 0.2399 Train_Acc: 90.564 Val_Loss: 0.2199  BEST VAL Loss: 0.2199  Val_Acc: 92.809

Epoch 65: Validation loss decreased (0.219911 --> 0.219370).  Saving model ...
	 Train_Loss: 0.2394 Train_Acc: 90.593 Val_Loss: 0.2194  BEST VAL Loss: 0.2194  Val_Acc: 92.712

Epoch 66: Validation loss decreased (0.219370 --> 0.219089).  Saving model ...
	 Train_Loss: 0.2389 Train_Acc: 90.538 Val_Loss: 0.2191  BEST VAL Loss: 0.2191  Val_Acc: 92.091

Epoch 67: Validation loss decreased (0.219089 --> 0.218470).  Saving model ...
	 Train_Loss: 0.2384 Train_Acc: 90.595 Val_Loss: 0.2185  BEST VAL Loss: 0.2185  Val_Acc: 93.025

Epoch 68: Validation loss decreased (0.218470 --> 0.217885).  Saving model ...
	 Train_Loss: 0.2380 Train_Acc: 90.618 Val_Loss: 0.2179  BEST VAL Loss: 0.2179  Val_Acc: 92.809

Epoch 69: Validation loss decreased (0.217885 --> 0.217333).  Saving model ...
	 Train_Loss: 0.2375 Train_Acc: 90.640 Val_Loss: 0.2173  BEST VAL Loss: 0.2173  Val_Acc: 92.836

Epoch 70: Validation loss decreased (0.217333 --> 0.217046).  Saving model ...
	 Train_Loss: 0.2370 Train_Acc: 90.624 Val_Loss: 0.2170  BEST VAL Loss: 0.2170  Val_Acc: 92.037

Epoch 71: Validation loss decreased (0.217046 --> 0.216645).  Saving model ...
	 Train_Loss: 0.2366 Train_Acc: 90.595 Val_Loss: 0.2166  BEST VAL Loss: 0.2166  Val_Acc: 92.296

Epoch 72: Validation loss decreased (0.216645 --> 0.216112).  Saving model ...
	 Train_Loss: 0.2361 Train_Acc: 90.677 Val_Loss: 0.2161  BEST VAL Loss: 0.2161  Val_Acc: 92.825

Epoch 73: Validation loss decreased (0.216112 --> 0.215638).  Saving model ...
	 Train_Loss: 0.2357 Train_Acc: 90.674 Val_Loss: 0.2156  BEST VAL Loss: 0.2156  Val_Acc: 92.744

Epoch 74: Validation loss decreased (0.215638 --> 0.215332).  Saving model ...
	 Train_Loss: 0.2353 Train_Acc: 90.622 Val_Loss: 0.2153  BEST VAL Loss: 0.2153  Val_Acc: 92.545

Epoch 75: Validation loss decreased (0.215332 --> 0.214825).  Saving model ...
	 Train_Loss: 0.2349 Train_Acc: 90.693 Val_Loss: 0.2148  BEST VAL Loss: 0.2148  Val_Acc: 92.858

Epoch 76: Validation loss decreased (0.214825 --> 0.214763).  Saving model ...
	 Train_Loss: 0.2344 Train_Acc: 90.706 Val_Loss: 0.2148  BEST VAL Loss: 0.2148  Val_Acc: 91.804

Epoch 77: Validation loss decreased (0.214763 --> 0.214306).  Saving model ...
	 Train_Loss: 0.2340 Train_Acc: 90.686 Val_Loss: 0.2143  BEST VAL Loss: 0.2143  Val_Acc: 92.755

Epoch 78: Validation loss decreased (0.214306 --> 0.213798).  Saving model ...
	 Train_Loss: 0.2336 Train_Acc: 90.611 Val_Loss: 0.2138  BEST VAL Loss: 0.2138  Val_Acc: 93.047

Epoch 79: Validation loss decreased (0.213798 --> 0.213289).  Saving model ...
	 Train_Loss: 0.2333 Train_Acc: 90.676 Val_Loss: 0.2133  BEST VAL Loss: 0.2133  Val_Acc: 93.160

Epoch 80: Validation loss decreased (0.213289 --> 0.212837).  Saving model ...
	 Train_Loss: 0.2329 Train_Acc: 90.704 Val_Loss: 0.2128  BEST VAL Loss: 0.2128  Val_Acc: 92.739

Epoch 81: Validation loss decreased (0.212837 --> 0.212430).  Saving model ...
	 Train_Loss: 0.2325 Train_Acc: 90.728 Val_Loss: 0.2124  BEST VAL Loss: 0.2124  Val_Acc: 92.912

Epoch 82: Validation loss decreased (0.212430 --> 0.212030).  Saving model ...
	 Train_Loss: 0.2321 Train_Acc: 90.829 Val_Loss: 0.2120  BEST VAL Loss: 0.2120  Val_Acc: 92.982

Epoch 83: Validation loss decreased (0.212030 --> 0.211655).  Saving model ...
	 Train_Loss: 0.2317 Train_Acc: 90.787 Val_Loss: 0.2117  BEST VAL Loss: 0.2117  Val_Acc: 92.766

Epoch 84: Validation loss decreased (0.211655 --> 0.211211).  Saving model ...
	 Train_Loss: 0.2314 Train_Acc: 90.760 Val_Loss: 0.2112  BEST VAL Loss: 0.2112  Val_Acc: 93.090

Epoch 85: Validation loss decreased (0.211211 --> 0.210852).  Saving model ...
	 Train_Loss: 0.2310 Train_Acc: 90.729 Val_Loss: 0.2109  BEST VAL Loss: 0.2109  Val_Acc: 93.079

Epoch 86: Validation loss decreased (0.210852 --> 0.210748).  Saving model ...
	 Train_Loss: 0.2306 Train_Acc: 90.797 Val_Loss: 0.2107  BEST VAL Loss: 0.2107  Val_Acc: 92.377

Epoch 87: Validation loss decreased (0.210748 --> 0.210361).  Saving model ...
	 Train_Loss: 0.2303 Train_Acc: 90.895 Val_Loss: 0.2104  BEST VAL Loss: 0.2104  Val_Acc: 93.036

Epoch 88: Validation loss decreased (0.210361 --> 0.209975).  Saving model ...
	 Train_Loss: 0.2299 Train_Acc: 90.784 Val_Loss: 0.2100  BEST VAL Loss: 0.2100  Val_Acc: 92.820

Epoch 89: Validation loss decreased (0.209975 --> 0.209590).  Saving model ...
	 Train_Loss: 0.2296 Train_Acc: 90.753 Val_Loss: 0.2096  BEST VAL Loss: 0.2096  Val_Acc: 93.241

Epoch 90: Validation loss decreased (0.209590 --> 0.209253).  Saving model ...
	 Train_Loss: 0.2293 Train_Acc: 90.770 Val_Loss: 0.2093  BEST VAL Loss: 0.2093  Val_Acc: 92.869

Epoch 91: Validation loss decreased (0.209253 --> 0.208950).  Saving model ...
	 Train_Loss: 0.2289 Train_Acc: 90.864 Val_Loss: 0.2090  BEST VAL Loss: 0.2090  Val_Acc: 92.944

Epoch 92: Validation loss decreased (0.208950 --> 0.208649).  Saving model ...
	 Train_Loss: 0.2286 Train_Acc: 90.760 Val_Loss: 0.2086  BEST VAL Loss: 0.2086  Val_Acc: 92.782

Epoch 93: Validation loss decreased (0.208649 --> 0.208289).  Saving model ...
	 Train_Loss: 0.2283 Train_Acc: 90.852 Val_Loss: 0.2083  BEST VAL Loss: 0.2083  Val_Acc: 92.971

Epoch 94: Validation loss decreased (0.208289 --> 0.207916).  Saving model ...
	 Train_Loss: 0.2280 Train_Acc: 90.859 Val_Loss: 0.2079  BEST VAL Loss: 0.2079  Val_Acc: 93.274

Epoch 95: Validation loss decreased (0.207916 --> 0.207594).  Saving model ...
	 Train_Loss: 0.2277 Train_Acc: 90.766 Val_Loss: 0.2076  BEST VAL Loss: 0.2076  Val_Acc: 92.993

Epoch 96: Validation loss decreased (0.207594 --> 0.207327).  Saving model ...
	 Train_Loss: 0.2274 Train_Acc: 90.893 Val_Loss: 0.2073  BEST VAL Loss: 0.2073  Val_Acc: 92.366

Epoch 97: Validation loss decreased (0.207327 --> 0.207062).  Saving model ...
	 Train_Loss: 0.2271 Train_Acc: 90.943 Val_Loss: 0.2071  BEST VAL Loss: 0.2071  Val_Acc: 92.658

Epoch 98: Validation loss decreased (0.207062 --> 0.206729).  Saving model ...
	 Train_Loss: 0.2268 Train_Acc: 90.762 Val_Loss: 0.2067  BEST VAL Loss: 0.2067  Val_Acc: 93.160

Epoch 99: Validation loss decreased (0.206729 --> 0.206417).  Saving model ...
	 Train_Loss: 0.2265 Train_Acc: 90.948 Val_Loss: 0.2064  BEST VAL Loss: 0.2064  Val_Acc: 93.047

Thapsigargin_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.95      0.89      0.92     50422
           1       0.94      0.98      0.96     97655

    accuracy                           0.95    148077
   macro avg       0.95      0.93      0.94    148077
weighted avg       0.95      0.95      0.95    148077

Thapsigargin_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.86      0.89      6303
           1       0.93      0.96      0.95     12207

    accuracy                           0.93     18510
   macro avg       0.93      0.91      0.92     18510
weighted avg       0.93      0.93      0.93     18510

Thapsigargin_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.86      0.89      6303
           1       0.93      0.97      0.95     12207

    accuracy                           0.93     18510
   macro avg       0.93      0.91      0.92     18510
weighted avg       0.93      0.93      0.93     18510

              precision    recall  f1-score   support

           0       0.93      0.86      0.89      6303
           1       0.93      0.97      0.95     12207

    accuracy                           0.93     18510
   macro avg       0.93      0.91      0.92     18510
weighted avg       0.93      0.93      0.93     18510

Thapsigargin_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.94      0.76      0.84     32887
           1       0.84      0.96      0.90     44915

    accuracy                           0.88     77802
   macro avg       0.89      0.86      0.87     77802
weighted avg       0.88      0.88      0.87     77802

              precision    recall  f1-score   support

           0       0.94      0.76      0.84     32887
           1       0.84      0.96      0.90     44915

    accuracy                           0.88     77802
   macro avg       0.89      0.86      0.87     77802
weighted avg       0.88      0.88      0.87     77802

completed
