[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'dfb0484b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'fc149d3d'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'c3ca5e6d'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '03c3514e'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_1.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_1.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (30110, 1276)
Number of total missing values across all columns: 32916
Data Subset Is Off
Wells held out for testing: ['D20' 'L16']
Wells to use for training, validation, and testing ['D16' 'D17' 'D21' 'L17' 'L20' 'L21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.537393).  Saving model ...
	 Train_Loss: 0.7610 Train_Acc: 60.172 Val_Loss: 0.5374  BEST VAL Loss: 0.5374  Val_Acc: 80.288

Epoch 1: Validation loss decreased (0.537393 --> 0.473113).  Saving model ...
	 Train_Loss: 0.6677 Train_Acc: 71.467 Val_Loss: 0.4731  BEST VAL Loss: 0.4731  Val_Acc: 90.144

Epoch 2: Validation loss decreased (0.473113 --> 0.442160).  Saving model ...
	 Train_Loss: 0.6254 Train_Acc: 73.504 Val_Loss: 0.4422  BEST VAL Loss: 0.4422  Val_Acc: 91.449

Epoch 3: Validation loss decreased (0.442160 --> 0.425548).  Saving model ...
	 Train_Loss: 0.5999 Train_Acc: 74.900 Val_Loss: 0.4255  BEST VAL Loss: 0.4255  Val_Acc: 91.629

Epoch 4: Validation loss decreased (0.425548 --> 0.407564).  Saving model ...
	 Train_Loss: 0.5802 Train_Acc: 77.016 Val_Loss: 0.4076  BEST VAL Loss: 0.4076  Val_Acc: 92.439

Epoch 5: Validation loss decreased (0.407564 --> 0.391097).  Saving model ...
	 Train_Loss: 0.5636 Train_Acc: 78.485 Val_Loss: 0.3911  BEST VAL Loss: 0.3911  Val_Acc: 93.834

Epoch 6: Validation loss decreased (0.391097 --> 0.373252).  Saving model ...
	 Train_Loss: 0.5498 Train_Acc: 79.605 Val_Loss: 0.3733  BEST VAL Loss: 0.3733  Val_Acc: 94.644

Epoch 7: Validation loss decreased (0.373252 --> 0.360161).  Saving model ...
	 Train_Loss: 0.5380 Train_Acc: 80.010 Val_Loss: 0.3602  BEST VAL Loss: 0.3602  Val_Acc: 95.095

Epoch 8: Validation loss decreased (0.360161 --> 0.347963).  Saving model ...
	 Train_Loss: 0.5283 Train_Acc: 79.959 Val_Loss: 0.3480  BEST VAL Loss: 0.3480  Val_Acc: 94.914

Epoch 9: Validation loss decreased (0.347963 --> 0.338540).  Saving model ...
	 Train_Loss: 0.5206 Train_Acc: 80.111 Val_Loss: 0.3385  BEST VAL Loss: 0.3385  Val_Acc: 95.410

Epoch 10: Validation loss decreased (0.338540 --> 0.330417).  Saving model ...
	 Train_Loss: 0.5137 Train_Acc: 80.376 Val_Loss: 0.3304  BEST VAL Loss: 0.3304  Val_Acc: 95.815

Epoch 11: Validation loss decreased (0.330417 --> 0.322406).  Saving model ...
	 Train_Loss: 0.5077 Train_Acc: 80.657 Val_Loss: 0.3224  BEST VAL Loss: 0.3224  Val_Acc: 95.365

Epoch 12: Validation loss decreased (0.322406 --> 0.316416).  Saving model ...
	 Train_Loss: 0.5028 Train_Acc: 80.505 Val_Loss: 0.3164  BEST VAL Loss: 0.3164  Val_Acc: 96.040

Epoch 13: Validation loss decreased (0.316416 --> 0.310397).  Saving model ...
	 Train_Loss: 0.4982 Train_Acc: 80.781 Val_Loss: 0.3104  BEST VAL Loss: 0.3104  Val_Acc: 95.860

Epoch 14: Validation loss decreased (0.310397 --> 0.305747).  Saving model ...
	 Train_Loss: 0.4938 Train_Acc: 81.276 Val_Loss: 0.3057  BEST VAL Loss: 0.3057  Val_Acc: 95.905

Epoch 15: Validation loss decreased (0.305747 --> 0.301326).  Saving model ...
	 Train_Loss: 0.4900 Train_Acc: 81.141 Val_Loss: 0.3013  BEST VAL Loss: 0.3013  Val_Acc: 95.770

Epoch 16: Validation loss decreased (0.301326 --> 0.297222).  Saving model ...
	 Train_Loss: 0.4869 Train_Acc: 80.725 Val_Loss: 0.2972  BEST VAL Loss: 0.2972  Val_Acc: 96.265

Epoch 17: Validation loss decreased (0.297222 --> 0.292508).  Saving model ...
	 Train_Loss: 0.4838 Train_Acc: 81.254 Val_Loss: 0.2925  BEST VAL Loss: 0.2925  Val_Acc: 96.805

Epoch 18: Validation loss decreased (0.292508 --> 0.288597).  Saving model ...
	 Train_Loss: 0.4809 Train_Acc: 81.456 Val_Loss: 0.2886  BEST VAL Loss: 0.2886  Val_Acc: 96.535

Epoch 19: Validation loss decreased (0.288597 --> 0.285760).  Saving model ...
	 Train_Loss: 0.4786 Train_Acc: 81.006 Val_Loss: 0.2858  BEST VAL Loss: 0.2858  Val_Acc: 95.545

Epoch 20: Validation loss decreased (0.285760 --> 0.282126).  Saving model ...
	 Train_Loss: 0.4762 Train_Acc: 81.316 Val_Loss: 0.2821  BEST VAL Loss: 0.2821  Val_Acc: 96.985

Epoch 21: Validation loss decreased (0.282126 --> 0.279908).  Saving model ...
	 Train_Loss: 0.4739 Train_Acc: 81.434 Val_Loss: 0.2799  BEST VAL Loss: 0.2799  Val_Acc: 96.400

Epoch 22: Validation loss decreased (0.279908 --> 0.277522).  Saving model ...
	 Train_Loss: 0.4719 Train_Acc: 81.293 Val_Loss: 0.2775  BEST VAL Loss: 0.2775  Val_Acc: 96.670

Epoch 23: Validation loss decreased (0.277522 --> 0.275134).  Saving model ...
	 Train_Loss: 0.4698 Train_Acc: 81.648 Val_Loss: 0.2751  BEST VAL Loss: 0.2751  Val_Acc: 96.580

Epoch 24: Validation loss decreased (0.275134 --> 0.273067).  Saving model ...
	 Train_Loss: 0.4682 Train_Acc: 81.209 Val_Loss: 0.2731  BEST VAL Loss: 0.2731  Val_Acc: 96.715

Epoch 25: Validation loss decreased (0.273067 --> 0.271112).  Saving model ...
	 Train_Loss: 0.4666 Train_Acc: 81.237 Val_Loss: 0.2711  BEST VAL Loss: 0.2711  Val_Acc: 96.895

Epoch 26: Validation loss decreased (0.271112 --> 0.268769).  Saving model ...
	 Train_Loss: 0.4649 Train_Acc: 81.620 Val_Loss: 0.2688  BEST VAL Loss: 0.2688  Val_Acc: 96.760

Epoch 27: Validation loss decreased (0.268769 --> 0.267035).  Saving model ...
	 Train_Loss: 0.4632 Train_Acc: 81.862 Val_Loss: 0.2670  BEST VAL Loss: 0.2670  Val_Acc: 96.760

Epoch 28: Validation loss decreased (0.267035 --> 0.265124).  Saving model ...
	 Train_Loss: 0.4618 Train_Acc: 81.693 Val_Loss: 0.2651  BEST VAL Loss: 0.2651  Val_Acc: 96.580

Epoch 29: Validation loss decreased (0.265124 --> 0.263109).  Saving model ...
	 Train_Loss: 0.4605 Train_Acc: 81.800 Val_Loss: 0.2631  BEST VAL Loss: 0.2631  Val_Acc: 96.850

Epoch 30: Validation loss decreased (0.263109 --> 0.261328).  Saving model ...
	 Train_Loss: 0.4592 Train_Acc: 81.789 Val_Loss: 0.2613  BEST VAL Loss: 0.2613  Val_Acc: 96.850

Epoch 31: Validation loss decreased (0.261328 --> 0.259778).  Saving model ...
	 Train_Loss: 0.4579 Train_Acc: 81.805 Val_Loss: 0.2598  BEST VAL Loss: 0.2598  Val_Acc: 96.490

Epoch 32: Validation loss decreased (0.259778 --> 0.258584).  Saving model ...
	 Train_Loss: 0.4568 Train_Acc: 81.783 Val_Loss: 0.2586  BEST VAL Loss: 0.2586  Val_Acc: 96.625

Epoch 33: Validation loss decreased (0.258584 --> 0.256920).  Saving model ...
	 Train_Loss: 0.4557 Train_Acc: 81.659 Val_Loss: 0.2569  BEST VAL Loss: 0.2569  Val_Acc: 97.165

Epoch 34: Validation loss decreased (0.256920 --> 0.255251).  Saving model ...
	 Train_Loss: 0.4544 Train_Acc: 82.385 Val_Loss: 0.2553  BEST VAL Loss: 0.2553  Val_Acc: 96.895

Epoch 35: Validation loss decreased (0.255251 --> 0.253976).  Saving model ...
	 Train_Loss: 0.4535 Train_Acc: 81.620 Val_Loss: 0.2540  BEST VAL Loss: 0.2540  Val_Acc: 96.895

Epoch 36: Validation loss decreased (0.253976 --> 0.252585).  Saving model ...
	 Train_Loss: 0.4525 Train_Acc: 81.991 Val_Loss: 0.2526  BEST VAL Loss: 0.2526  Val_Acc: 97.300

Epoch 37: Validation loss decreased (0.252585 --> 0.251434).  Saving model ...
	 Train_Loss: 0.4518 Train_Acc: 81.344 Val_Loss: 0.2514  BEST VAL Loss: 0.2514  Val_Acc: 96.895

Epoch 38: Validation loss decreased (0.251434 --> 0.250153).  Saving model ...
	 Train_Loss: 0.4510 Train_Acc: 81.670 Val_Loss: 0.2502  BEST VAL Loss: 0.2502  Val_Acc: 97.255

Epoch 39: Validation loss decreased (0.250153 --> 0.249047).  Saving model ...
	 Train_Loss: 0.4501 Train_Acc: 82.036 Val_Loss: 0.2490  BEST VAL Loss: 0.2490  Val_Acc: 97.030

Epoch 40: Validation loss decreased (0.249047 --> 0.248121).  Saving model ...
	 Train_Loss: 0.4494 Train_Acc: 81.777 Val_Loss: 0.2481  BEST VAL Loss: 0.2481  Val_Acc: 97.210

Epoch 41: Validation loss decreased (0.248121 --> 0.247223).  Saving model ...
	 Train_Loss: 0.4487 Train_Acc: 81.614 Val_Loss: 0.2472  BEST VAL Loss: 0.2472  Val_Acc: 97.165

Epoch 42: Validation loss decreased (0.247223 --> 0.246125).  Saving model ...
	 Train_Loss: 0.4478 Train_Acc: 82.199 Val_Loss: 0.2461  BEST VAL Loss: 0.2461  Val_Acc: 97.300

Epoch 43: Validation loss decreased (0.246125 --> 0.245047).  Saving model ...
	 Train_Loss: 0.4469 Train_Acc: 82.503 Val_Loss: 0.2450  BEST VAL Loss: 0.2450  Val_Acc: 97.390

Epoch 44: Validation loss decreased (0.245047 --> 0.244202).  Saving model ...
	 Train_Loss: 0.4461 Train_Acc: 82.312 Val_Loss: 0.2442  BEST VAL Loss: 0.2442  Val_Acc: 97.300

Epoch 45: Validation loss decreased (0.244202 --> 0.243266).  Saving model ...
	 Train_Loss: 0.4454 Train_Acc: 82.137 Val_Loss: 0.2433  BEST VAL Loss: 0.2433  Val_Acc: 96.670

Epoch 46: Validation loss decreased (0.243266 --> 0.243064).  Saving model ...
	 Train_Loss: 0.4449 Train_Acc: 81.586 Val_Loss: 0.2431  BEST VAL Loss: 0.2431  Val_Acc: 96.985

Epoch 47: Validation loss decreased (0.243064 --> 0.242563).  Saving model ...
	 Train_Loss: 0.4441 Train_Acc: 82.379 Val_Loss: 0.2426  BEST VAL Loss: 0.2426  Val_Acc: 97.075

Epoch 48: Validation loss decreased (0.242563 --> 0.242015).  Saving model ...
	 Train_Loss: 0.4435 Train_Acc: 81.991 Val_Loss: 0.2420  BEST VAL Loss: 0.2420  Val_Acc: 97.390

Epoch 49: Validation loss decreased (0.242015 --> 0.241303).  Saving model ...
	 Train_Loss: 0.4429 Train_Acc: 82.424 Val_Loss: 0.2413  BEST VAL Loss: 0.2413  Val_Acc: 97.210

Epoch 50: Validation loss decreased (0.241303 --> 0.240739).  Saving model ...
	 Train_Loss: 0.4425 Train_Acc: 81.608 Val_Loss: 0.2407  BEST VAL Loss: 0.2407  Val_Acc: 96.760

Epoch 51: Validation loss decreased (0.240739 --> 0.239976).  Saving model ...
	 Train_Loss: 0.4419 Train_Acc: 82.031 Val_Loss: 0.2400  BEST VAL Loss: 0.2400  Val_Acc: 97.300

Epoch 52: Validation loss decreased (0.239976 --> 0.239466).  Saving model ...
	 Train_Loss: 0.4412 Train_Acc: 82.368 Val_Loss: 0.2395  BEST VAL Loss: 0.2395  Val_Acc: 96.895

Epoch 53: Validation loss decreased (0.239466 --> 0.238978).  Saving model ...
	 Train_Loss: 0.4407 Train_Acc: 82.166 Val_Loss: 0.2390  BEST VAL Loss: 0.2390  Val_Acc: 96.760

Epoch 54: Validation loss decreased (0.238978 --> 0.238627).  Saving model ...
	 Train_Loss: 0.4402 Train_Acc: 81.929 Val_Loss: 0.2386  BEST VAL Loss: 0.2386  Val_Acc: 96.985

Epoch 55: Validation loss decreased (0.238627 --> 0.238201).  Saving model ...
	 Train_Loss: 0.4399 Train_Acc: 81.395 Val_Loss: 0.2382  BEST VAL Loss: 0.2382  Val_Acc: 97.210

Epoch 56: Validation loss decreased (0.238201 --> 0.237557).  Saving model ...
	 Train_Loss: 0.4395 Train_Acc: 81.867 Val_Loss: 0.2376  BEST VAL Loss: 0.2376  Val_Acc: 97.210

Epoch 57: Validation loss decreased (0.237557 --> 0.237149).  Saving model ...
	 Train_Loss: 0.4390 Train_Acc: 82.064 Val_Loss: 0.2371  BEST VAL Loss: 0.2371  Val_Acc: 97.480

Epoch 58: Validation loss decreased (0.237149 --> 0.236445).  Saving model ...
	 Train_Loss: 0.4385 Train_Acc: 82.289 Val_Loss: 0.2364  BEST VAL Loss: 0.2364  Val_Acc: 97.165

Epoch 59: Validation loss decreased (0.236445 --> 0.236071).  Saving model ...
	 Train_Loss: 0.4380 Train_Acc: 82.430 Val_Loss: 0.2361  BEST VAL Loss: 0.2361  Val_Acc: 97.435

Epoch 60: Validation loss decreased (0.236071 --> 0.235782).  Saving model ...
	 Train_Loss: 0.4376 Train_Acc: 82.081 Val_Loss: 0.2358  BEST VAL Loss: 0.2358  Val_Acc: 96.805

Epoch 61: Validation loss decreased (0.235782 --> 0.235736).  Saving model ...
	 Train_Loss: 0.4371 Train_Acc: 82.256 Val_Loss: 0.2357  BEST VAL Loss: 0.2357  Val_Acc: 96.985

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.4367 Train_Acc: 82.166 Val_Loss: 0.2369  BEST VAL Loss: 0.2357  Val_Acc: 97.030

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.4363 Train_Acc: 82.171 Val_Loss: 0.2381  BEST VAL Loss: 0.2357  Val_Acc: 97.480

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.4360 Train_Acc: 81.980 Val_Loss: 0.2377  BEST VAL Loss: 0.2357  Val_Acc: 97.390

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.4357 Train_Acc: 81.856 Val_Loss: 0.2373  BEST VAL Loss: 0.2357  Val_Acc: 97.345

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.4354 Train_Acc: 81.890 Val_Loss: 0.2367  BEST VAL Loss: 0.2357  Val_Acc: 97.075

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.4350 Train_Acc: 82.126 Val_Loss: 0.2363  BEST VAL Loss: 0.2357  Val_Acc: 97.210

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.4347 Train_Acc: 82.182 Val_Loss: 0.2359  BEST VAL Loss: 0.2357  Val_Acc: 97.345

Epoch 69: Validation loss decreased (0.235736 --> 0.235240).  Saving model ...
	 Train_Loss: 0.4344 Train_Acc: 81.957 Val_Loss: 0.2352  BEST VAL Loss: 0.2352  Val_Acc: 97.615

Epoch 70: Validation loss decreased (0.235240 --> 0.235045).  Saving model ...
	 Train_Loss: 0.4341 Train_Acc: 82.092 Val_Loss: 0.2350  BEST VAL Loss: 0.2350  Val_Acc: 97.345

Epoch 71: Validation loss decreased (0.235045 --> 0.234609).  Saving model ...
	 Train_Loss: 0.4337 Train_Acc: 82.334 Val_Loss: 0.2346  BEST VAL Loss: 0.2346  Val_Acc: 97.705

Epoch 72: Validation loss decreased (0.234609 --> 0.234158).  Saving model ...
	 Train_Loss: 0.4334 Train_Acc: 82.205 Val_Loss: 0.2342  BEST VAL Loss: 0.2342  Val_Acc: 97.660

Epoch 73: Validation loss decreased (0.234158 --> 0.233723).  Saving model ...
	 Train_Loss: 0.4331 Train_Acc: 82.357 Val_Loss: 0.2337  BEST VAL Loss: 0.2337  Val_Acc: 97.345

Epoch 74: Validation loss decreased (0.233723 --> 0.233257).  Saving model ...
	 Train_Loss: 0.4328 Train_Acc: 82.323 Val_Loss: 0.2333  BEST VAL Loss: 0.2333  Val_Acc: 97.300

Epoch 75: Validation loss decreased (0.233257 --> 0.232842).  Saving model ...
	 Train_Loss: 0.4324 Train_Acc: 82.391 Val_Loss: 0.2328  BEST VAL Loss: 0.2328  Val_Acc: 97.615

Epoch 76: Validation loss decreased (0.232842 --> 0.232342).  Saving model ...
	 Train_Loss: 0.4322 Train_Acc: 81.980 Val_Loss: 0.2323  BEST VAL Loss: 0.2323  Val_Acc: 97.390

Epoch 77: Validation loss decreased (0.232342 --> 0.231942).  Saving model ...
	 Train_Loss: 0.4319 Train_Acc: 82.199 Val_Loss: 0.2319  BEST VAL Loss: 0.2319  Val_Acc: 96.760

Epoch 78: Validation loss decreased (0.231942 --> 0.231717).  Saving model ...
	 Train_Loss: 0.4318 Train_Acc: 81.271 Val_Loss: 0.2317  BEST VAL Loss: 0.2317  Val_Acc: 97.120

Epoch 79: Validation loss decreased (0.231717 --> 0.231374).  Saving model ...
	 Train_Loss: 0.4315 Train_Acc: 82.014 Val_Loss: 0.2314  BEST VAL Loss: 0.2314  Val_Acc: 97.165

Epoch 80: Validation loss decreased (0.231374 --> 0.230927).  Saving model ...
	 Train_Loss: 0.4313 Train_Acc: 82.227 Val_Loss: 0.2309  BEST VAL Loss: 0.2309  Val_Acc: 97.525

Epoch 81: Validation loss decreased (0.230927 --> 0.230601).  Saving model ...
	 Train_Loss: 0.4311 Train_Acc: 81.834 Val_Loss: 0.2306  BEST VAL Loss: 0.2306  Val_Acc: 97.075

Epoch 82: Validation loss decreased (0.230601 --> 0.230302).  Saving model ...
	 Train_Loss: 0.4307 Train_Acc: 82.644 Val_Loss: 0.2303  BEST VAL Loss: 0.2303  Val_Acc: 97.840

Epoch 83: Validation loss decreased (0.230302 --> 0.229894).  Saving model ...
	 Train_Loss: 0.4304 Train_Acc: 82.565 Val_Loss: 0.2299  BEST VAL Loss: 0.2299  Val_Acc: 97.210

Epoch 84: Validation loss decreased (0.229894 --> 0.229422).  Saving model ...
	 Train_Loss: 0.4302 Train_Acc: 82.261 Val_Loss: 0.2294  BEST VAL Loss: 0.2294  Val_Acc: 97.300

Epoch 85: Validation loss decreased (0.229422 --> 0.229026).  Saving model ...
	 Train_Loss: 0.4299 Train_Acc: 82.323 Val_Loss: 0.2290  BEST VAL Loss: 0.2290  Val_Acc: 97.345

Epoch 86: Validation loss decreased (0.229026 --> 0.228764).  Saving model ...
	 Train_Loss: 0.4297 Train_Acc: 82.059 Val_Loss: 0.2288  BEST VAL Loss: 0.2288  Val_Acc: 97.075

Epoch 87: Validation loss decreased (0.228764 --> 0.228362).  Saving model ...
	 Train_Loss: 0.4296 Train_Acc: 81.856 Val_Loss: 0.2284  BEST VAL Loss: 0.2284  Val_Acc: 97.210

Epoch 88: Validation loss decreased (0.228362 --> 0.228037).  Saving model ...
	 Train_Loss: 0.4293 Train_Acc: 82.149 Val_Loss: 0.2280  BEST VAL Loss: 0.2280  Val_Acc: 97.435

Epoch 89: Validation loss decreased (0.228037 --> 0.227671).  Saving model ...
	 Train_Loss: 0.4292 Train_Acc: 81.766 Val_Loss: 0.2277  BEST VAL Loss: 0.2277  Val_Acc: 97.705

Epoch 90: Validation loss decreased (0.227671 --> 0.227233).  Saving model ...
	 Train_Loss: 0.4290 Train_Acc: 82.351 Val_Loss: 0.2272  BEST VAL Loss: 0.2272  Val_Acc: 97.255

Epoch 91: Validation loss decreased (0.227233 --> 0.227010).  Saving model ...
	 Train_Loss: 0.4288 Train_Acc: 82.109 Val_Loss: 0.2270  BEST VAL Loss: 0.2270  Val_Acc: 97.570

Epoch 92: Validation loss decreased (0.227010 --> 0.226705).  Saving model ...
	 Train_Loss: 0.4286 Train_Acc: 82.092 Val_Loss: 0.2267  BEST VAL Loss: 0.2267  Val_Acc: 97.615

Epoch 93: Validation loss decreased (0.226705 --> 0.226528).  Saving model ...
	 Train_Loss: 0.4283 Train_Acc: 82.633 Val_Loss: 0.2265  BEST VAL Loss: 0.2265  Val_Acc: 97.930

Epoch 94: Validation loss decreased (0.226528 --> 0.226198).  Saving model ...
	 Train_Loss: 0.4282 Train_Acc: 81.991 Val_Loss: 0.2262  BEST VAL Loss: 0.2262  Val_Acc: 97.615

Epoch 95: Validation loss decreased (0.226198 --> 0.225877).  Saving model ...
	 Train_Loss: 0.4279 Train_Acc: 82.683 Val_Loss: 0.2259  BEST VAL Loss: 0.2259  Val_Acc: 97.345

Epoch 96: Validation loss decreased (0.225877 --> 0.225599).  Saving model ...
	 Train_Loss: 0.4277 Train_Acc: 82.306 Val_Loss: 0.2256  BEST VAL Loss: 0.2256  Val_Acc: 97.570

Epoch 97: Validation loss decreased (0.225599 --> 0.225320).  Saving model ...
	 Train_Loss: 0.4275 Train_Acc: 82.340 Val_Loss: 0.2253  BEST VAL Loss: 0.2253  Val_Acc: 97.660

Epoch 98: Validation loss decreased (0.225320 --> 0.225209).  Saving model ...
	 Train_Loss: 0.4273 Train_Acc: 82.424 Val_Loss: 0.2252  BEST VAL Loss: 0.2252  Val_Acc: 97.975

Epoch 99: Validation loss decreased (0.225209 --> 0.224955).  Saving model ...
	 Train_Loss: 0.4271 Train_Acc: 82.244 Val_Loss: 0.2250  BEST VAL Loss: 0.2250  Val_Acc: 97.660

LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.55      0.55      9832
           1       0.44      0.44      0.44      7937

    accuracy                           0.50     17769
   macro avg       0.49      0.49      0.49     17769
weighted avg       0.50      0.50      0.50     17769

LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.56      0.55      0.56      1229
           1       0.45      0.45      0.45       993

    accuracy                           0.51      2222
   macro avg       0.50      0.50      0.50      2222
weighted avg       0.51      0.51      0.51      2222

LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.55      0.55      1229
           1       0.44      0.44      0.44       993

    accuracy                           0.50      2222
   macro avg       0.50      0.50      0.50      2222
weighted avg       0.50      0.50      0.50      2222

              precision    recall  f1-score   support

           0       0.55      0.55      0.55      1229
           1       0.44      0.44      0.44       993

    accuracy                           0.50      2222
   macro avg       0.50      0.50      0.50      2222
weighted avg       0.50      0.50      0.50      2222

LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.55      0.54      4168
           1       0.47      0.44      0.46      3729

    accuracy                           0.50      7897
   macro avg       0.50      0.50      0.50      7897
weighted avg       0.50      0.50      0.50      7897

              precision    recall  f1-score   support

           0       0.53      0.55      0.54      4168
           1       0.47      0.44      0.46      3729

    accuracy                           0.50      7897
   macro avg       0.50      0.50      0.50      7897
weighted avg       0.50      0.50      0.50      7897

completed
