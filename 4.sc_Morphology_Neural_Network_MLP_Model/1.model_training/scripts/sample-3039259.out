[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'e83977d2'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '2abbb5fd'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '59037a7a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '5f9aef1b'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_0.100_DMSO_0.025 treatment_name: Thapsigargin_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_0.100_DMSO_0.025
TREATMENT_NAME: Thapsigargin_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'LPS_0.100_DMSO_0.025']
The dimensions of the data are: (31276, 1276)
Number of total missing values across all columns: 62552
Data Subset Is Off
Wells held out for testing: ['D14' 'C20']
Wells to use for training, validation, and testing ['D15' 'C16' 'C17' 'C21' 'K14' 'K15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.448809).  Saving model ...
	 Train_Loss: 0.6159 Train_Acc: 67.129 Val_Loss: 0.4488  BEST VAL Loss: 0.4488  Val_Acc: 79.261

Epoch 1: Validation loss decreased (0.448809 --> 0.420237).  Saving model ...
	 Train_Loss: 0.5380 Train_Acc: 77.813 Val_Loss: 0.4202  BEST VAL Loss: 0.4202  Val_Acc: 83.255

Epoch 2: Validation loss decreased (0.420237 --> 0.403791).  Saving model ...
	 Train_Loss: 0.4972 Train_Acc: 80.188 Val_Loss: 0.4038  BEST VAL Loss: 0.4038  Val_Acc: 82.788

Epoch 3: Validation loss decreased (0.403791 --> 0.390723).  Saving model ...
	 Train_Loss: 0.4713 Train_Acc: 81.256 Val_Loss: 0.3907  BEST VAL Loss: 0.3907  Val_Acc: 84.105

Epoch 4: Validation loss decreased (0.390723 --> 0.381748).  Saving model ...
	 Train_Loss: 0.4501 Train_Acc: 82.478 Val_Loss: 0.3817  BEST VAL Loss: 0.3817  Val_Acc: 84.573

Epoch 5: Validation loss decreased (0.381748 --> 0.372122).  Saving model ...
	 Train_Loss: 0.4337 Train_Acc: 83.323 Val_Loss: 0.3721  BEST VAL Loss: 0.3721  Val_Acc: 85.975

Epoch 6: Validation loss decreased (0.372122 --> 0.362840).  Saving model ...
	 Train_Loss: 0.4193 Train_Acc: 84.125 Val_Loss: 0.3628  BEST VAL Loss: 0.3628  Val_Acc: 86.188

Epoch 7: Validation loss decreased (0.362840 --> 0.357601).  Saving model ...
	 Train_Loss: 0.4061 Train_Acc: 84.927 Val_Loss: 0.3576  BEST VAL Loss: 0.3576  Val_Acc: 85.763

Epoch 8: Validation loss decreased (0.357601 --> 0.349925).  Saving model ...
	 Train_Loss: 0.3961 Train_Acc: 85.182 Val_Loss: 0.3499  BEST VAL Loss: 0.3499  Val_Acc: 87.335

Epoch 9: Validation loss decreased (0.349925 --> 0.346080).  Saving model ...
	 Train_Loss: 0.3867 Train_Acc: 86.032 Val_Loss: 0.3461  BEST VAL Loss: 0.3461  Val_Acc: 87.718

Epoch 10: Validation loss decreased (0.346080 --> 0.342299).  Saving model ...
	 Train_Loss: 0.3778 Train_Acc: 86.803 Val_Loss: 0.3423  BEST VAL Loss: 0.3423  Val_Acc: 85.805

Epoch 11: Validation loss decreased (0.342299 --> 0.337186).  Saving model ...
	 Train_Loss: 0.3703 Train_Acc: 87.153 Val_Loss: 0.3372  BEST VAL Loss: 0.3372  Val_Acc: 87.590

Epoch 12: Validation loss decreased (0.337186 --> 0.333130).  Saving model ...
	 Train_Loss: 0.3632 Train_Acc: 87.881 Val_Loss: 0.3331  BEST VAL Loss: 0.3331  Val_Acc: 88.100

Epoch 13: Validation loss decreased (0.333130 --> 0.330098).  Saving model ...
	 Train_Loss: 0.3568 Train_Acc: 88.046 Val_Loss: 0.3301  BEST VAL Loss: 0.3301  Val_Acc: 88.143

Epoch 14: Validation loss decreased (0.330098 --> 0.328062).  Saving model ...
	 Train_Loss: 0.3507 Train_Acc: 88.258 Val_Loss: 0.3281  BEST VAL Loss: 0.3281  Val_Acc: 87.505

Epoch 15: Validation loss decreased (0.328062 --> 0.327435).  Saving model ...
	 Train_Loss: 0.3448 Train_Acc: 88.800 Val_Loss: 0.3274  BEST VAL Loss: 0.3274  Val_Acc: 87.845

Epoch 16: Validation loss decreased (0.327435 --> 0.325326).  Saving model ...
	 Train_Loss: 0.3399 Train_Acc: 88.423 Val_Loss: 0.3253  BEST VAL Loss: 0.3253  Val_Acc: 86.953

Epoch 17: Validation loss decreased (0.325326 --> 0.323552).  Saving model ...
	 Train_Loss: 0.3347 Train_Acc: 88.949 Val_Loss: 0.3236  BEST VAL Loss: 0.3236  Val_Acc: 87.803

Epoch 18: Validation loss decreased (0.323552 --> 0.321575).  Saving model ...
	 Train_Loss: 0.3299 Train_Acc: 89.108 Val_Loss: 0.3216  BEST VAL Loss: 0.3216  Val_Acc: 88.143

Epoch 19: Validation loss decreased (0.321575 --> 0.320147).  Saving model ...
	 Train_Loss: 0.3258 Train_Acc: 89.204 Val_Loss: 0.3201  BEST VAL Loss: 0.3201  Val_Acc: 87.378

Epoch 20: Validation loss decreased (0.320147 --> 0.319368).  Saving model ...
	 Train_Loss: 0.3215 Train_Acc: 89.613 Val_Loss: 0.3194  BEST VAL Loss: 0.3194  Val_Acc: 87.930

Epoch 21: Validation loss decreased (0.319368 --> 0.317861).  Saving model ...
	 Train_Loss: 0.3173 Train_Acc: 89.778 Val_Loss: 0.3179  BEST VAL Loss: 0.3179  Val_Acc: 87.845

Epoch 22: Validation loss decreased (0.317861 --> 0.316874).  Saving model ...
	 Train_Loss: 0.3136 Train_Acc: 89.789 Val_Loss: 0.3169  BEST VAL Loss: 0.3169  Val_Acc: 87.760

Epoch 23: Validation loss decreased (0.316874 --> 0.316019).  Saving model ...
	 Train_Loss: 0.3099 Train_Acc: 90.150 Val_Loss: 0.3160  BEST VAL Loss: 0.3160  Val_Acc: 87.080

Epoch 24: Validation loss decreased (0.316019 --> 0.315147).  Saving model ...
	 Train_Loss: 0.3065 Train_Acc: 89.953 Val_Loss: 0.3151  BEST VAL Loss: 0.3151  Val_Acc: 88.270

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.3032 Train_Acc: 90.230 Val_Loss: 0.3155  BEST VAL Loss: 0.3151  Val_Acc: 88.015

Epoch 26: Validation loss did not decrease
	 Train_Loss: 0.3000 Train_Acc: 90.171 Val_Loss: 0.3153  BEST VAL Loss: 0.3151  Val_Acc: 87.633

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.2969 Train_Acc: 90.330 Val_Loss: 0.3160  BEST VAL Loss: 0.3151  Val_Acc: 87.803

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.2941 Train_Acc: 90.500 Val_Loss: 0.3157  BEST VAL Loss: 0.3151  Val_Acc: 87.930

Epoch 29: Validation loss did not decrease
	 Train_Loss: 0.2917 Train_Acc: 90.012 Val_Loss: 0.3152  BEST VAL Loss: 0.3151  Val_Acc: 87.973

Epoch 30: Validation loss decreased (0.315147 --> 0.314769).  Saving model ...
	 Train_Loss: 0.2892 Train_Acc: 90.479 Val_Loss: 0.3148  BEST VAL Loss: 0.3148  Val_Acc: 88.355

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.2866 Train_Acc: 90.415 Val_Loss: 0.3151  BEST VAL Loss: 0.3148  Val_Acc: 87.420

Epoch 32: Validation loss decreased (0.314769 --> 0.314735).  Saving model ...
	 Train_Loss: 0.2843 Train_Acc: 90.803 Val_Loss: 0.3147  BEST VAL Loss: 0.3147  Val_Acc: 87.293

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.2820 Train_Acc: 90.771 Val_Loss: 0.3149  BEST VAL Loss: 0.3147  Val_Acc: 88.228

Epoch 34: Validation loss decreased (0.314735 --> 0.314343).  Saving model ...
	 Train_Loss: 0.2796 Train_Acc: 90.979 Val_Loss: 0.3143  BEST VAL Loss: 0.3143  Val_Acc: 87.888

Epoch 35: Validation loss decreased (0.314343 --> 0.313796).  Saving model ...
	 Train_Loss: 0.2775 Train_Acc: 90.511 Val_Loss: 0.3138  BEST VAL Loss: 0.3138  Val_Acc: 88.100

Epoch 36: Validation loss decreased (0.313796 --> 0.313336).  Saving model ...
	 Train_Loss: 0.2753 Train_Acc: 91.143 Val_Loss: 0.3133  BEST VAL Loss: 0.3133  Val_Acc: 87.378

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.2731 Train_Acc: 91.042 Val_Loss: 0.3137  BEST VAL Loss: 0.3133  Val_Acc: 87.930

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.2711 Train_Acc: 90.761 Val_Loss: 0.3142  BEST VAL Loss: 0.3133  Val_Acc: 88.398

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.2693 Train_Acc: 91.212 Val_Loss: 0.3149  BEST VAL Loss: 0.3133  Val_Acc: 88.270

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.2676 Train_Acc: 90.957 Val_Loss: 0.3148  BEST VAL Loss: 0.3133  Val_Acc: 87.803

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.2658 Train_Acc: 91.228 Val_Loss: 0.3152  BEST VAL Loss: 0.3133  Val_Acc: 88.780

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.2641 Train_Acc: 91.133 Val_Loss: 0.3152  BEST VAL Loss: 0.3133  Val_Acc: 88.185

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.2625 Train_Acc: 90.957 Val_Loss: 0.3189  BEST VAL Loss: 0.3133  Val_Acc: 86.103

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.2612 Train_Acc: 90.702 Val_Loss: 0.3198  BEST VAL Loss: 0.3133  Val_Acc: 88.058

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.2597 Train_Acc: 91.356 Val_Loss: 0.3194  BEST VAL Loss: 0.3133  Val_Acc: 88.100

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.2580 Train_Acc: 91.579 Val_Loss: 0.3199  BEST VAL Loss: 0.3133  Val_Acc: 88.313

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.2566 Train_Acc: 91.223 Val_Loss: 0.3197  BEST VAL Loss: 0.3133  Val_Acc: 88.015

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.2550 Train_Acc: 91.536 Val_Loss: 0.3202  BEST VAL Loss: 0.3133  Val_Acc: 88.355

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.2537 Train_Acc: 91.356 Val_Loss: 0.3201  BEST VAL Loss: 0.3133  Val_Acc: 88.143

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.2524 Train_Acc: 91.181 Val_Loss: 0.3208  BEST VAL Loss: 0.3133  Val_Acc: 88.015

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.2511 Train_Acc: 91.717 Val_Loss: 0.3211  BEST VAL Loss: 0.3133  Val_Acc: 87.760

Epoch 52: Validation loss did not decrease
Early stopped at epoch : 52
LPS_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.52      0.54     10451
           1       0.44      0.47      0.46      8371

    accuracy                           0.50     18822
   macro avg       0.50      0.50      0.50     18822
weighted avg       0.50      0.50      0.50     18822

LPS_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.52      0.54      1307
           1       0.44      0.47      0.45      1046

    accuracy                           0.50      2353
   macro avg       0.50      0.50      0.49      2353
weighted avg       0.50      0.50      0.50      2353

LPS_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.56      0.54      0.55      1307
           1       0.46      0.48      0.47      1046

    accuracy                           0.51      2353
   macro avg       0.51      0.51      0.51      2353
weighted avg       0.52      0.51      0.51      2353

              precision    recall  f1-score   support

           0       0.56      0.54      0.55      1307
           1       0.46      0.48      0.47      1046

    accuracy                           0.51      2353
   macro avg       0.51      0.51      0.51      2353
weighted avg       0.52      0.51      0.51      2353

LPS_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.57      0.53      0.55      4445
           1       0.43      0.47      0.45      3303

    accuracy                           0.51      7748
   macro avg       0.50      0.50      0.50      7748
weighted avg       0.51      0.51      0.51      7748

              precision    recall  f1-score   support

           0       0.57      0.53      0.55      4445
           1       0.43      0.47      0.45      3303

    accuracy                           0.51      7748
   macro avg       0.50      0.50      0.50      7748
weighted avg       0.51      0.51      0.51      7748

completed
