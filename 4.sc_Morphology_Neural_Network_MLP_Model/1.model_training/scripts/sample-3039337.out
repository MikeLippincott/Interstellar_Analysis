[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'e0929c38'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '6d7704db'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'a469fc7c'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '26b88dde'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Thapsigargin_1.000_DMSO_0.025 treatment_name: H2O2_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Thapsigargin_1.000_DMSO_0.025
TREATMENT_NAME: H2O2_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (388992, 1270)
Number of total missing values across all columns: 777984
Data Subset Is Off
Wells held out for testing: ['I10' 'K07']
Wells to use for training, validation, and testing ['D06' 'D07' 'H04' 'I04' 'H05' 'I05' 'H10' 'H11' 'I11' 'K06']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.532519).  Saving model ...
	 Train_Loss: 0.5853 Train_Acc: 69.141 Val_Loss: 0.5325  BEST VAL Loss: 0.5325  Val_Acc: 73.188

Epoch 1: Validation loss decreased (0.532519 --> 0.506724).  Saving model ...
	 Train_Loss: 0.5563 Train_Acc: 73.134 Val_Loss: 0.5067  BEST VAL Loss: 0.5067  Val_Acc: 76.456

Epoch 2: Validation loss decreased (0.506724 --> 0.488214).  Saving model ...
	 Train_Loss: 0.5358 Train_Acc: 75.086 Val_Loss: 0.4882  BEST VAL Loss: 0.4882  Val_Acc: 78.049

Epoch 3: Validation loss decreased (0.488214 --> 0.475450).  Saving model ...
	 Train_Loss: 0.5212 Train_Acc: 76.161 Val_Loss: 0.4755  BEST VAL Loss: 0.4755  Val_Acc: 79.056

Epoch 4: Validation loss decreased (0.475450 --> 0.466599).  Saving model ...
	 Train_Loss: 0.5099 Train_Acc: 76.873 Val_Loss: 0.4666  BEST VAL Loss: 0.4666  Val_Acc: 79.466

Epoch 5: Validation loss decreased (0.466599 --> 0.457760).  Saving model ...
	 Train_Loss: 0.5010 Train_Acc: 77.412 Val_Loss: 0.4578  BEST VAL Loss: 0.4578  Val_Acc: 80.550

Epoch 6: Validation loss decreased (0.457760 --> 0.450576).  Saving model ...
	 Train_Loss: 0.4935 Train_Acc: 77.814 Val_Loss: 0.4506  BEST VAL Loss: 0.4506  Val_Acc: 80.854

Epoch 7: Validation loss decreased (0.450576 --> 0.444347).  Saving model ...
	 Train_Loss: 0.4871 Train_Acc: 78.163 Val_Loss: 0.4443  BEST VAL Loss: 0.4443  Val_Acc: 80.786

Epoch 8: Validation loss decreased (0.444347 --> 0.438919).  Saving model ...
	 Train_Loss: 0.4814 Train_Acc: 78.487 Val_Loss: 0.4389  BEST VAL Loss: 0.4389  Val_Acc: 81.367

Epoch 9: Validation loss decreased (0.438919 --> 0.434146).  Saving model ...
	 Train_Loss: 0.4766 Train_Acc: 78.637 Val_Loss: 0.4341  BEST VAL Loss: 0.4341  Val_Acc: 81.789

Epoch 10: Validation loss decreased (0.434146 --> 0.429741).  Saving model ...
	 Train_Loss: 0.4724 Train_Acc: 78.908 Val_Loss: 0.4297  BEST VAL Loss: 0.4297  Val_Acc: 82.041

Epoch 11: Validation loss decreased (0.429741 --> 0.425963).  Saving model ...
	 Train_Loss: 0.4685 Train_Acc: 79.002 Val_Loss: 0.4260  BEST VAL Loss: 0.4260  Val_Acc: 82.243

Epoch 12: Validation loss decreased (0.425963 --> 0.422697).  Saving model ...
	 Train_Loss: 0.4650 Train_Acc: 79.215 Val_Loss: 0.4227  BEST VAL Loss: 0.4227  Val_Acc: 82.115

Epoch 13: Validation loss decreased (0.422697 --> 0.419360).  Saving model ...
	 Train_Loss: 0.4621 Train_Acc: 79.096 Val_Loss: 0.4194  BEST VAL Loss: 0.4194  Val_Acc: 82.274

Epoch 14: Validation loss decreased (0.419360 --> 0.416218).  Saving model ...
	 Train_Loss: 0.4593 Train_Acc: 79.250 Val_Loss: 0.4162  BEST VAL Loss: 0.4162  Val_Acc: 82.457

Epoch 15: Validation loss decreased (0.416218 --> 0.413509).  Saving model ...
	 Train_Loss: 0.4568 Train_Acc: 79.383 Val_Loss: 0.4135  BEST VAL Loss: 0.4135  Val_Acc: 82.472

Epoch 16: Validation loss decreased (0.413509 --> 0.411094).  Saving model ...
	 Train_Loss: 0.4544 Train_Acc: 79.597 Val_Loss: 0.4111  BEST VAL Loss: 0.4111  Val_Acc: 82.485

Epoch 17: Validation loss decreased (0.411094 --> 0.409020).  Saving model ...
	 Train_Loss: 0.4523 Train_Acc: 79.609 Val_Loss: 0.4090  BEST VAL Loss: 0.4090  Val_Acc: 82.420

Epoch 18: Validation loss decreased (0.409020 --> 0.407045).  Saving model ...
	 Train_Loss: 0.4502 Train_Acc: 79.641 Val_Loss: 0.4070  BEST VAL Loss: 0.4070  Val_Acc: 82.454

Epoch 19: Validation loss decreased (0.407045 --> 0.405177).  Saving model ...
	 Train_Loss: 0.4483 Train_Acc: 79.653 Val_Loss: 0.4052  BEST VAL Loss: 0.4052  Val_Acc: 82.690

Epoch 20: Validation loss decreased (0.405177 --> 0.403491).  Saving model ...
	 Train_Loss: 0.4466 Train_Acc: 79.713 Val_Loss: 0.4035  BEST VAL Loss: 0.4035  Val_Acc: 82.566

Epoch 21: Validation loss decreased (0.403491 --> 0.401831).  Saving model ...
	 Train_Loss: 0.4450 Train_Acc: 79.708 Val_Loss: 0.4018  BEST VAL Loss: 0.4018  Val_Acc: 82.904

Epoch 22: Validation loss decreased (0.401831 --> 0.400241).  Saving model ...
	 Train_Loss: 0.4435 Train_Acc: 79.862 Val_Loss: 0.4002  BEST VAL Loss: 0.4002  Val_Acc: 82.876

Epoch 23: Validation loss decreased (0.400241 --> 0.398958).  Saving model ...
	 Train_Loss: 0.4422 Train_Acc: 79.600 Val_Loss: 0.3990  BEST VAL Loss: 0.3990  Val_Acc: 82.646

Epoch 24: Validation loss decreased (0.398958 --> 0.397507).  Saving model ...
	 Train_Loss: 0.4409 Train_Acc: 79.852 Val_Loss: 0.3975  BEST VAL Loss: 0.3975  Val_Acc: 82.889

Epoch 25: Validation loss decreased (0.397507 --> 0.396091).  Saving model ...
	 Train_Loss: 0.4396 Train_Acc: 79.895 Val_Loss: 0.3961  BEST VAL Loss: 0.3961  Val_Acc: 83.143

Epoch 26: Validation loss decreased (0.396091 --> 0.394997).  Saving model ...
	 Train_Loss: 0.4384 Train_Acc: 79.964 Val_Loss: 0.3950  BEST VAL Loss: 0.3950  Val_Acc: 82.705

Epoch 27: Validation loss decreased (0.394997 --> 0.394127).  Saving model ...
	 Train_Loss: 0.4373 Train_Acc: 79.923 Val_Loss: 0.3941  BEST VAL Loss: 0.3941  Val_Acc: 83.004

Epoch 28: Validation loss decreased (0.394127 --> 0.393271).  Saving model ...
	 Train_Loss: 0.4362 Train_Acc: 79.921 Val_Loss: 0.3933  BEST VAL Loss: 0.3933  Val_Acc: 82.637

Epoch 29: Validation loss decreased (0.393271 --> 0.392313).  Saving model ...
	 Train_Loss: 0.4352 Train_Acc: 80.074 Val_Loss: 0.3923  BEST VAL Loss: 0.3923  Val_Acc: 82.879

Epoch 30: Validation loss decreased (0.392313 --> 0.391425).  Saving model ...
	 Train_Loss: 0.4343 Train_Acc: 80.048 Val_Loss: 0.3914  BEST VAL Loss: 0.3914  Val_Acc: 83.125

Epoch 31: Validation loss decreased (0.391425 --> 0.390610).  Saving model ...
	 Train_Loss: 0.4334 Train_Acc: 79.968 Val_Loss: 0.3906  BEST VAL Loss: 0.3906  Val_Acc: 82.820

Epoch 32: Validation loss decreased (0.390610 --> 0.389841).  Saving model ...
	 Train_Loss: 0.4325 Train_Acc: 80.025 Val_Loss: 0.3898  BEST VAL Loss: 0.3898  Val_Acc: 82.913

Epoch 33: Validation loss decreased (0.389841 --> 0.389081).  Saving model ...
	 Train_Loss: 0.4317 Train_Acc: 80.108 Val_Loss: 0.3891  BEST VAL Loss: 0.3891  Val_Acc: 82.948

Epoch 34: Validation loss decreased (0.389081 --> 0.388262).  Saving model ...
	 Train_Loss: 0.4309 Train_Acc: 80.048 Val_Loss: 0.3883  BEST VAL Loss: 0.3883  Val_Acc: 83.227

Epoch 35: Validation loss decreased (0.388262 --> 0.387423).  Saving model ...
	 Train_Loss: 0.4301 Train_Acc: 80.066 Val_Loss: 0.3874  BEST VAL Loss: 0.3874  Val_Acc: 83.454

Epoch 36: Validation loss decreased (0.387423 --> 0.386656).  Saving model ...
	 Train_Loss: 0.4294 Train_Acc: 80.145 Val_Loss: 0.3867  BEST VAL Loss: 0.3867  Val_Acc: 83.196

Epoch 37: Validation loss decreased (0.386656 --> 0.386047).  Saving model ...
	 Train_Loss: 0.4286 Train_Acc: 80.207 Val_Loss: 0.3860  BEST VAL Loss: 0.3860  Val_Acc: 82.991

Epoch 38: Validation loss decreased (0.386047 --> 0.385407).  Saving model ...
	 Train_Loss: 0.4280 Train_Acc: 80.231 Val_Loss: 0.3854  BEST VAL Loss: 0.3854  Val_Acc: 83.056

Epoch 39: Validation loss decreased (0.385407 --> 0.384870).  Saving model ...
	 Train_Loss: 0.4273 Train_Acc: 80.168 Val_Loss: 0.3849  BEST VAL Loss: 0.3849  Val_Acc: 83.137

Epoch 40: Validation loss decreased (0.384870 --> 0.384204).  Saving model ...
	 Train_Loss: 0.4267 Train_Acc: 80.230 Val_Loss: 0.3842  BEST VAL Loss: 0.3842  Val_Acc: 83.364

Epoch 41: Validation loss decreased (0.384204 --> 0.383572).  Saving model ...
	 Train_Loss: 0.4261 Train_Acc: 80.161 Val_Loss: 0.3836  BEST VAL Loss: 0.3836  Val_Acc: 83.404

Epoch 42: Validation loss decreased (0.383572 --> 0.383041).  Saving model ...
	 Train_Loss: 0.4255 Train_Acc: 80.253 Val_Loss: 0.3830  BEST VAL Loss: 0.3830  Val_Acc: 83.041

Epoch 43: Validation loss decreased (0.383041 --> 0.382505).  Saving model ...
	 Train_Loss: 0.4249 Train_Acc: 80.163 Val_Loss: 0.3825  BEST VAL Loss: 0.3825  Val_Acc: 83.361

Epoch 44: Validation loss decreased (0.382505 --> 0.381961).  Saving model ...
	 Train_Loss: 0.4244 Train_Acc: 80.267 Val_Loss: 0.3820  BEST VAL Loss: 0.3820  Val_Acc: 83.308

Epoch 45: Validation loss decreased (0.381961 --> 0.381424).  Saving model ...
	 Train_Loss: 0.4239 Train_Acc: 80.187 Val_Loss: 0.3814  BEST VAL Loss: 0.3814  Val_Acc: 83.460

Epoch 46: Validation loss decreased (0.381424 --> 0.380969).  Saving model ...
	 Train_Loss: 0.4234 Train_Acc: 80.178 Val_Loss: 0.3810  BEST VAL Loss: 0.3810  Val_Acc: 83.159

Epoch 47: Validation loss decreased (0.380969 --> 0.380540).  Saving model ...
	 Train_Loss: 0.4229 Train_Acc: 80.294 Val_Loss: 0.3805  BEST VAL Loss: 0.3805  Val_Acc: 83.221

Epoch 48: Validation loss decreased (0.380540 --> 0.380115).  Saving model ...
	 Train_Loss: 0.4224 Train_Acc: 80.298 Val_Loss: 0.3801  BEST VAL Loss: 0.3801  Val_Acc: 83.171

Epoch 49: Validation loss decreased (0.380115 --> 0.379733).  Saving model ...
	 Train_Loss: 0.4219 Train_Acc: 80.273 Val_Loss: 0.3797  BEST VAL Loss: 0.3797  Val_Acc: 83.047

Epoch 50: Validation loss decreased (0.379733 --> 0.379346).  Saving model ...
	 Train_Loss: 0.4215 Train_Acc: 80.306 Val_Loss: 0.3793  BEST VAL Loss: 0.3793  Val_Acc: 83.383

Epoch 51: Validation loss decreased (0.379346 --> 0.378911).  Saving model ...
	 Train_Loss: 0.4210 Train_Acc: 80.493 Val_Loss: 0.3789  BEST VAL Loss: 0.3789  Val_Acc: 83.622

Epoch 52: Validation loss decreased (0.378911 --> 0.378520).  Saving model ...
	 Train_Loss: 0.4206 Train_Acc: 80.373 Val_Loss: 0.3785  BEST VAL Loss: 0.3785  Val_Acc: 83.268

Epoch 53: Validation loss decreased (0.378520 --> 0.378166).  Saving model ...
	 Train_Loss: 0.4202 Train_Acc: 80.446 Val_Loss: 0.3782  BEST VAL Loss: 0.3782  Val_Acc: 83.302

Epoch 54: Validation loss decreased (0.378166 --> 0.377786).  Saving model ...
	 Train_Loss: 0.4198 Train_Acc: 80.409 Val_Loss: 0.3778  BEST VAL Loss: 0.3778  Val_Acc: 83.469

Epoch 55: Validation loss decreased (0.377786 --> 0.377396).  Saving model ...
	 Train_Loss: 0.4194 Train_Acc: 80.427 Val_Loss: 0.3774  BEST VAL Loss: 0.3774  Val_Acc: 83.414

Epoch 56: Validation loss decreased (0.377396 --> 0.377067).  Saving model ...
	 Train_Loss: 0.4190 Train_Acc: 80.430 Val_Loss: 0.3771  BEST VAL Loss: 0.3771  Val_Acc: 83.181

Epoch 57: Validation loss decreased (0.377067 --> 0.376733).  Saving model ...
	 Train_Loss: 0.4186 Train_Acc: 80.369 Val_Loss: 0.3767  BEST VAL Loss: 0.3767  Val_Acc: 83.401

Epoch 58: Validation loss decreased (0.376733 --> 0.376421).  Saving model ...
	 Train_Loss: 0.4183 Train_Acc: 80.437 Val_Loss: 0.3764  BEST VAL Loss: 0.3764  Val_Acc: 83.339

Epoch 59: Validation loss decreased (0.376421 --> 0.376037).  Saving model ...
	 Train_Loss: 0.4179 Train_Acc: 80.435 Val_Loss: 0.3760  BEST VAL Loss: 0.3760  Val_Acc: 83.535

Epoch 60: Validation loss decreased (0.376037 --> 0.375678).  Saving model ...
	 Train_Loss: 0.4175 Train_Acc: 80.573 Val_Loss: 0.3757  BEST VAL Loss: 0.3757  Val_Acc: 83.783

Epoch 61: Validation loss decreased (0.375678 --> 0.375367).  Saving model ...
	 Train_Loss: 0.4172 Train_Acc: 80.599 Val_Loss: 0.3754  BEST VAL Loss: 0.3754  Val_Acc: 83.314

Epoch 62: Validation loss decreased (0.375367 --> 0.375140).  Saving model ...
	 Train_Loss: 0.4168 Train_Acc: 80.446 Val_Loss: 0.3751  BEST VAL Loss: 0.3751  Val_Acc: 83.370

Epoch 63: Validation loss decreased (0.375140 --> 0.374860).  Saving model ...
	 Train_Loss: 0.4165 Train_Acc: 80.555 Val_Loss: 0.3749  BEST VAL Loss: 0.3749  Val_Acc: 83.252

Epoch 64: Validation loss decreased (0.374860 --> 0.374515).  Saving model ...
	 Train_Loss: 0.4162 Train_Acc: 80.517 Val_Loss: 0.3745  BEST VAL Loss: 0.3745  Val_Acc: 83.752

Epoch 65: Validation loss decreased (0.374515 --> 0.374239).  Saving model ...
	 Train_Loss: 0.4158 Train_Acc: 80.567 Val_Loss: 0.3742  BEST VAL Loss: 0.3742  Val_Acc: 83.383

Epoch 66: Validation loss decreased (0.374239 --> 0.373983).  Saving model ...
	 Train_Loss: 0.4155 Train_Acc: 80.531 Val_Loss: 0.3740  BEST VAL Loss: 0.3740  Val_Acc: 83.355

Epoch 67: Validation loss decreased (0.373983 --> 0.373725).  Saving model ...
	 Train_Loss: 0.4152 Train_Acc: 80.596 Val_Loss: 0.3737  BEST VAL Loss: 0.3737  Val_Acc: 83.389

Epoch 68: Validation loss decreased (0.373725 --> 0.373523).  Saving model ...
	 Train_Loss: 0.4149 Train_Acc: 80.647 Val_Loss: 0.3735  BEST VAL Loss: 0.3735  Val_Acc: 83.255

Epoch 69: Validation loss decreased (0.373523 --> 0.373233).  Saving model ...
	 Train_Loss: 0.4146 Train_Acc: 80.475 Val_Loss: 0.3732  BEST VAL Loss: 0.3732  Val_Acc: 83.733

Epoch 70: Validation loss decreased (0.373233 --> 0.372965).  Saving model ...
	 Train_Loss: 0.4144 Train_Acc: 80.477 Val_Loss: 0.3730  BEST VAL Loss: 0.3730  Val_Acc: 83.572

Epoch 71: Validation loss decreased (0.372965 --> 0.372758).  Saving model ...
	 Train_Loss: 0.4141 Train_Acc: 80.663 Val_Loss: 0.3728  BEST VAL Loss: 0.3728  Val_Acc: 83.209

Epoch 72: Validation loss decreased (0.372758 --> 0.372493).  Saving model ...
	 Train_Loss: 0.4138 Train_Acc: 80.545 Val_Loss: 0.3725  BEST VAL Loss: 0.3725  Val_Acc: 83.647

Epoch 73: Validation loss decreased (0.372493 --> 0.372286).  Saving model ...
	 Train_Loss: 0.4135 Train_Acc: 80.620 Val_Loss: 0.3723  BEST VAL Loss: 0.3723  Val_Acc: 83.302

Epoch 74: Validation loss decreased (0.372286 --> 0.372074).  Saving model ...
	 Train_Loss: 0.4133 Train_Acc: 80.618 Val_Loss: 0.3721  BEST VAL Loss: 0.3721  Val_Acc: 83.401

Epoch 75: Validation loss decreased (0.372074 --> 0.371854).  Saving model ...
	 Train_Loss: 0.4130 Train_Acc: 80.592 Val_Loss: 0.3719  BEST VAL Loss: 0.3719  Val_Acc: 83.488

Epoch 76: Validation loss decreased (0.371854 --> 0.371584).  Saving model ...
	 Train_Loss: 0.4127 Train_Acc: 80.667 Val_Loss: 0.3716  BEST VAL Loss: 0.3716  Val_Acc: 83.730

Epoch 77: Validation loss decreased (0.371584 --> 0.371323).  Saving model ...
	 Train_Loss: 0.4125 Train_Acc: 80.650 Val_Loss: 0.3713  BEST VAL Loss: 0.3713  Val_Acc: 83.771

Epoch 78: Validation loss decreased (0.371323 --> 0.371056).  Saving model ...
	 Train_Loss: 0.4122 Train_Acc: 80.583 Val_Loss: 0.3711  BEST VAL Loss: 0.3711  Val_Acc: 83.656

Epoch 79: Validation loss decreased (0.371056 --> 0.370838).  Saving model ...
	 Train_Loss: 0.4120 Train_Acc: 80.732 Val_Loss: 0.3708  BEST VAL Loss: 0.3708  Val_Acc: 83.410

Epoch 80: Validation loss decreased (0.370838 --> 0.370640).  Saving model ...
	 Train_Loss: 0.4117 Train_Acc: 80.689 Val_Loss: 0.3706  BEST VAL Loss: 0.3706  Val_Acc: 83.631

Epoch 81: Validation loss decreased (0.370640 --> 0.370458).  Saving model ...
	 Train_Loss: 0.4115 Train_Acc: 80.592 Val_Loss: 0.3705  BEST VAL Loss: 0.3705  Val_Acc: 83.364

Epoch 82: Validation loss decreased (0.370458 --> 0.370259).  Saving model ...
	 Train_Loss: 0.4112 Train_Acc: 80.742 Val_Loss: 0.3703  BEST VAL Loss: 0.3703  Val_Acc: 83.556

Epoch 83: Validation loss decreased (0.370259 --> 0.370062).  Saving model ...
	 Train_Loss: 0.4110 Train_Acc: 80.607 Val_Loss: 0.3701  BEST VAL Loss: 0.3701  Val_Acc: 83.438

Epoch 84: Validation loss decreased (0.370062 --> 0.369869).  Saving model ...
	 Train_Loss: 0.4108 Train_Acc: 80.704 Val_Loss: 0.3699  BEST VAL Loss: 0.3699  Val_Acc: 83.451

Epoch 85: Validation loss decreased (0.369869 --> 0.369717).  Saving model ...
	 Train_Loss: 0.4106 Train_Acc: 80.674 Val_Loss: 0.3697  BEST VAL Loss: 0.3697  Val_Acc: 83.482

Epoch 86: Validation loss decreased (0.369717 --> 0.369533).  Saving model ...
	 Train_Loss: 0.4103 Train_Acc: 80.706 Val_Loss: 0.3695  BEST VAL Loss: 0.3695  Val_Acc: 83.516

Epoch 87: Validation loss decreased (0.369533 --> 0.369315).  Saving model ...
	 Train_Loss: 0.4101 Train_Acc: 80.759 Val_Loss: 0.3693  BEST VAL Loss: 0.3693  Val_Acc: 83.501

Epoch 88: Validation loss decreased (0.369315 --> 0.369123).  Saving model ...
	 Train_Loss: 0.4099 Train_Acc: 80.781 Val_Loss: 0.3691  BEST VAL Loss: 0.3691  Val_Acc: 83.513

Epoch 89: Validation loss decreased (0.369123 --> 0.368924).  Saving model ...
	 Train_Loss: 0.4097 Train_Acc: 80.663 Val_Loss: 0.3689  BEST VAL Loss: 0.3689  Val_Acc: 83.547

Epoch 90: Validation loss decreased (0.368924 --> 0.368770).  Saving model ...
	 Train_Loss: 0.4095 Train_Acc: 80.745 Val_Loss: 0.3688  BEST VAL Loss: 0.3688  Val_Acc: 83.513

Epoch 91: Validation loss decreased (0.368770 --> 0.368559).  Saving model ...
	 Train_Loss: 0.4093 Train_Acc: 80.740 Val_Loss: 0.3686  BEST VAL Loss: 0.3686  Val_Acc: 83.777

Epoch 92: Validation loss decreased (0.368559 --> 0.368384).  Saving model ...
	 Train_Loss: 0.4091 Train_Acc: 80.712 Val_Loss: 0.3684  BEST VAL Loss: 0.3684  Val_Acc: 83.706

Epoch 93: Validation loss decreased (0.368384 --> 0.368226).  Saving model ...
	 Train_Loss: 0.4089 Train_Acc: 80.675 Val_Loss: 0.3682  BEST VAL Loss: 0.3682  Val_Acc: 83.494

Epoch 94: Validation loss decreased (0.368226 --> 0.368047).  Saving model ...
	 Train_Loss: 0.4087 Train_Acc: 80.691 Val_Loss: 0.3680  BEST VAL Loss: 0.3680  Val_Acc: 83.907

Epoch 95: Validation loss decreased (0.368047 --> 0.367887).  Saving model ...
	 Train_Loss: 0.4085 Train_Acc: 80.679 Val_Loss: 0.3679  BEST VAL Loss: 0.3679  Val_Acc: 83.588

Epoch 96: Validation loss decreased (0.367887 --> 0.367707).  Saving model ...
	 Train_Loss: 0.4083 Train_Acc: 80.736 Val_Loss: 0.3677  BEST VAL Loss: 0.3677  Val_Acc: 83.721

Epoch 97: Validation loss decreased (0.367707 --> 0.367528).  Saving model ...
	 Train_Loss: 0.4082 Train_Acc: 80.787 Val_Loss: 0.3675  BEST VAL Loss: 0.3675  Val_Acc: 83.864

Epoch 98: Validation loss decreased (0.367528 --> 0.367383).  Saving model ...
	 Train_Loss: 0.4080 Train_Acc: 80.682 Val_Loss: 0.3674  BEST VAL Loss: 0.3674  Val_Acc: 83.572

Epoch 99: Validation loss decreased (0.367383 --> 0.367225).  Saving model ...
	 Train_Loss: 0.4078 Train_Acc: 80.831 Val_Loss: 0.3672  BEST VAL Loss: 0.3672  Val_Acc: 83.615

Thapsigargin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.66      0.72      0.69    169560
           1       0.34      0.28      0.31     87993

    accuracy                           0.57    257553
   macro avg       0.50      0.50      0.50    257553
weighted avg       0.55      0.57      0.56    257553

Thapsigargin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.66      0.73      0.69     21196
           1       0.34      0.27      0.30     10999

    accuracy                           0.57     32195
   macro avg       0.50      0.50      0.50     32195
weighted avg       0.55      0.57      0.56     32195

Thapsigargin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.66      0.72      0.69     21196
           1       0.33      0.27      0.30     10999

    accuracy                           0.57     32195
   macro avg       0.49      0.50      0.49     32195
weighted avg       0.55      0.57      0.55     32195

              precision    recall  f1-score   support

           0       0.66      0.72      0.69     21196
           1       0.33      0.27      0.30     10999

    accuracy                           0.57     32195
   macro avg       0.49      0.50      0.49     32195
weighted avg       0.55      0.57      0.55     32195

Thapsigargin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.43      0.60      0.50     28584
           1       0.57      0.40      0.47     38465

    accuracy                           0.49     67049
   macro avg       0.50      0.50      0.49     67049
weighted avg       0.51      0.49      0.48     67049

              precision    recall  f1-score   support

           0       0.43      0.60      0.50     28584
           1       0.57      0.40      0.47     38465

    accuracy                           0.49     67049
   macro avg       0.50      0.50      0.49     67049
weighted avg       0.51      0.49      0.48     67049

completed
