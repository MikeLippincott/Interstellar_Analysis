[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '69891444'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'b2b82b3c'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ad9eb83f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e3d66edc'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: H2O2_100.000_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['H2O2_100.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (336451, 1270)
Number of total missing values across all columns: 672902
Data Subset Is Off
Wells held out for testing: ['I05' 'L10']
Wells to use for training, validation, and testing ['H04' 'I04' 'H05' 'H10' 'I10' 'H11' 'I11' 'L05' 'L11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.399731).  Saving model ...
	 Train_Loss: 0.4856 Train_Acc: 76.515 Val_Loss: 0.3997  BEST VAL Loss: 0.3997  Val_Acc: 81.272

Epoch 1: Validation loss decreased (0.399731 --> 0.388039).  Saving model ...
	 Train_Loss: 0.4541 Train_Acc: 80.253 Val_Loss: 0.3880  BEST VAL Loss: 0.3880  Val_Acc: 82.013

Epoch 2: Validation loss decreased (0.388039 --> 0.379189).  Saving model ...
	 Train_Loss: 0.4389 Train_Acc: 80.965 Val_Loss: 0.3792  BEST VAL Loss: 0.3792  Val_Acc: 82.894

Epoch 3: Validation loss decreased (0.379189 --> 0.374685).  Saving model ...
	 Train_Loss: 0.4290 Train_Acc: 81.301 Val_Loss: 0.3747  BEST VAL Loss: 0.3747  Val_Acc: 82.494

Epoch 4: Validation loss decreased (0.374685 --> 0.370408).  Saving model ...
	 Train_Loss: 0.4219 Train_Acc: 81.488 Val_Loss: 0.3704  BEST VAL Loss: 0.3704  Val_Acc: 83.294

Epoch 5: Validation loss decreased (0.370408 --> 0.367072).  Saving model ...
	 Train_Loss: 0.4171 Train_Acc: 81.526 Val_Loss: 0.3671  BEST VAL Loss: 0.3671  Val_Acc: 83.517

Epoch 6: Validation loss decreased (0.367072 --> 0.364440).  Saving model ...
	 Train_Loss: 0.4128 Train_Acc: 81.718 Val_Loss: 0.3644  BEST VAL Loss: 0.3644  Val_Acc: 83.669

Epoch 7: Validation loss decreased (0.364440 --> 0.361896).  Saving model ...
	 Train_Loss: 0.4093 Train_Acc: 81.849 Val_Loss: 0.3619  BEST VAL Loss: 0.3619  Val_Acc: 83.987

Epoch 8: Validation loss decreased (0.361896 --> 0.359117).  Saving model ...
	 Train_Loss: 0.4065 Train_Acc: 81.825 Val_Loss: 0.3591  BEST VAL Loss: 0.3591  Val_Acc: 84.132

Epoch 9: Validation loss decreased (0.359117 --> 0.357895).  Saving model ...
	 Train_Loss: 0.4041 Train_Acc: 81.856 Val_Loss: 0.3579  BEST VAL Loss: 0.3579  Val_Acc: 84.095

Epoch 10: Validation loss decreased (0.357895 --> 0.356272).  Saving model ...
	 Train_Loss: 0.4020 Train_Acc: 82.004 Val_Loss: 0.3563  BEST VAL Loss: 0.3563  Val_Acc: 84.298

Epoch 11: Validation loss decreased (0.356272 --> 0.355188).  Saving model ...
	 Train_Loss: 0.4001 Train_Acc: 82.013 Val_Loss: 0.3552  BEST VAL Loss: 0.3552  Val_Acc: 84.187

Epoch 12: Validation loss decreased (0.355188 --> 0.353581).  Saving model ...
	 Train_Loss: 0.3984 Train_Acc: 82.117 Val_Loss: 0.3536  BEST VAL Loss: 0.3536  Val_Acc: 84.487

Epoch 13: Validation loss decreased (0.353581 --> 0.352052).  Saving model ...
	 Train_Loss: 0.3969 Train_Acc: 82.162 Val_Loss: 0.3521  BEST VAL Loss: 0.3521  Val_Acc: 84.606

Epoch 14: Validation loss decreased (0.352052 --> 0.351283).  Saving model ...
	 Train_Loss: 0.3954 Train_Acc: 82.207 Val_Loss: 0.3513  BEST VAL Loss: 0.3513  Val_Acc: 83.776

Epoch 15: Validation loss decreased (0.351283 --> 0.350642).  Saving model ...
	 Train_Loss: 0.3943 Train_Acc: 82.138 Val_Loss: 0.3506  BEST VAL Loss: 0.3506  Val_Acc: 84.187

Epoch 16: Validation loss decreased (0.350642 --> 0.349582).  Saving model ...
	 Train_Loss: 0.3931 Train_Acc: 82.271 Val_Loss: 0.3496  BEST VAL Loss: 0.3496  Val_Acc: 84.632

Epoch 17: Validation loss decreased (0.349582 --> 0.348763).  Saving model ...
	 Train_Loss: 0.3921 Train_Acc: 82.246 Val_Loss: 0.3488  BEST VAL Loss: 0.3488  Val_Acc: 84.239

Epoch 18: Validation loss decreased (0.348763 --> 0.347926).  Saving model ...
	 Train_Loss: 0.3911 Train_Acc: 82.254 Val_Loss: 0.3479  BEST VAL Loss: 0.3479  Val_Acc: 84.473

Epoch 19: Validation loss decreased (0.347926 --> 0.347017).  Saving model ...
	 Train_Loss: 0.3902 Train_Acc: 82.270 Val_Loss: 0.3470  BEST VAL Loss: 0.3470  Val_Acc: 84.613

Epoch 20: Validation loss decreased (0.347017 --> 0.346630).  Saving model ...
	 Train_Loss: 0.3893 Train_Acc: 82.301 Val_Loss: 0.3466  BEST VAL Loss: 0.3466  Val_Acc: 84.521

Epoch 21: Validation loss decreased (0.346630 --> 0.345936).  Saving model ...
	 Train_Loss: 0.3885 Train_Acc: 82.304 Val_Loss: 0.3459  BEST VAL Loss: 0.3459  Val_Acc: 84.521

Epoch 22: Validation loss decreased (0.345936 --> 0.345170).  Saving model ...
	 Train_Loss: 0.3877 Train_Acc: 82.359 Val_Loss: 0.3452  BEST VAL Loss: 0.3452  Val_Acc: 84.858

Epoch 23: Validation loss decreased (0.345170 --> 0.344480).  Saving model ...
	 Train_Loss: 0.3870 Train_Acc: 82.438 Val_Loss: 0.3445  BEST VAL Loss: 0.3445  Val_Acc: 84.650

Epoch 24: Validation loss decreased (0.344480 --> 0.343987).  Saving model ...
	 Train_Loss: 0.3863 Train_Acc: 82.341 Val_Loss: 0.3440  BEST VAL Loss: 0.3440  Val_Acc: 84.347

Epoch 25: Validation loss decreased (0.343987 --> 0.343517).  Saving model ...
	 Train_Loss: 0.3856 Train_Acc: 82.473 Val_Loss: 0.3435  BEST VAL Loss: 0.3435  Val_Acc: 84.621

Epoch 26: Validation loss decreased (0.343517 --> 0.343193).  Saving model ...
	 Train_Loss: 0.3851 Train_Acc: 82.367 Val_Loss: 0.3432  BEST VAL Loss: 0.3432  Val_Acc: 84.728

Epoch 27: Validation loss decreased (0.343193 --> 0.342703).  Saving model ...
	 Train_Loss: 0.3845 Train_Acc: 82.456 Val_Loss: 0.3427  BEST VAL Loss: 0.3427  Val_Acc: 84.539

Epoch 28: Validation loss decreased (0.342703 --> 0.342141).  Saving model ...
	 Train_Loss: 0.3839 Train_Acc: 82.382 Val_Loss: 0.3421  BEST VAL Loss: 0.3421  Val_Acc: 84.728

Epoch 29: Validation loss decreased (0.342141 --> 0.341764).  Saving model ...
	 Train_Loss: 0.3834 Train_Acc: 82.402 Val_Loss: 0.3418  BEST VAL Loss: 0.3418  Val_Acc: 84.539

Epoch 30: Validation loss decreased (0.341764 --> 0.341447).  Saving model ...
	 Train_Loss: 0.3830 Train_Acc: 82.452 Val_Loss: 0.3414  BEST VAL Loss: 0.3414  Val_Acc: 84.343

Epoch 31: Validation loss decreased (0.341447 --> 0.340941).  Saving model ...
	 Train_Loss: 0.3824 Train_Acc: 82.527 Val_Loss: 0.3409  BEST VAL Loss: 0.3409  Val_Acc: 84.754

Epoch 32: Validation loss decreased (0.340941 --> 0.340836).  Saving model ...
	 Train_Loss: 0.3819 Train_Acc: 82.562 Val_Loss: 0.3408  BEST VAL Loss: 0.3408  Val_Acc: 83.887

Epoch 33: Validation loss decreased (0.340836 --> 0.340580).  Saving model ...
	 Train_Loss: 0.3815 Train_Acc: 82.513 Val_Loss: 0.3406  BEST VAL Loss: 0.3406  Val_Acc: 84.176

Epoch 34: Validation loss decreased (0.340580 --> 0.340149).  Saving model ...
	 Train_Loss: 0.3811 Train_Acc: 82.422 Val_Loss: 0.3401  BEST VAL Loss: 0.3401  Val_Acc: 84.828

Epoch 35: Validation loss decreased (0.340149 --> 0.339735).  Saving model ...
	 Train_Loss: 0.3807 Train_Acc: 82.510 Val_Loss: 0.3397  BEST VAL Loss: 0.3397  Val_Acc: 84.999

Epoch 36: Validation loss decreased (0.339735 --> 0.339434).  Saving model ...
	 Train_Loss: 0.3803 Train_Acc: 82.549 Val_Loss: 0.3394  BEST VAL Loss: 0.3394  Val_Acc: 84.858

Epoch 37: Validation loss decreased (0.339434 --> 0.339148).  Saving model ...
	 Train_Loss: 0.3799 Train_Acc: 82.432 Val_Loss: 0.3391  BEST VAL Loss: 0.3391  Val_Acc: 84.573

Epoch 38: Validation loss decreased (0.339148 --> 0.338901).  Saving model ...
	 Train_Loss: 0.3795 Train_Acc: 82.583 Val_Loss: 0.3389  BEST VAL Loss: 0.3389  Val_Acc: 84.684

Epoch 39: Validation loss decreased (0.338901 --> 0.338665).  Saving model ...
	 Train_Loss: 0.3792 Train_Acc: 82.450 Val_Loss: 0.3387  BEST VAL Loss: 0.3387  Val_Acc: 84.743

Epoch 40: Validation loss decreased (0.338665 --> 0.338351).  Saving model ...
	 Train_Loss: 0.3788 Train_Acc: 82.492 Val_Loss: 0.3384  BEST VAL Loss: 0.3384  Val_Acc: 84.873

Epoch 41: Validation loss decreased (0.338351 --> 0.337939).  Saving model ...
	 Train_Loss: 0.3785 Train_Acc: 82.585 Val_Loss: 0.3379  BEST VAL Loss: 0.3379  Val_Acc: 85.291

Epoch 42: Validation loss decreased (0.337939 --> 0.337725).  Saving model ...
	 Train_Loss: 0.3782 Train_Acc: 82.586 Val_Loss: 0.3377  BEST VAL Loss: 0.3377  Val_Acc: 84.369

Epoch 43: Validation loss decreased (0.337725 --> 0.337558).  Saving model ...
	 Train_Loss: 0.3779 Train_Acc: 82.564 Val_Loss: 0.3376  BEST VAL Loss: 0.3376  Val_Acc: 84.706

Epoch 44: Validation loss decreased (0.337558 --> 0.337297).  Saving model ...
	 Train_Loss: 0.3776 Train_Acc: 82.577 Val_Loss: 0.3373  BEST VAL Loss: 0.3373  Val_Acc: 84.980

Epoch 45: Validation loss decreased (0.337297 --> 0.337232).  Saving model ...
	 Train_Loss: 0.3773 Train_Acc: 82.600 Val_Loss: 0.3372  BEST VAL Loss: 0.3372  Val_Acc: 84.113

Epoch 46: Validation loss decreased (0.337232 --> 0.336993).  Saving model ...
	 Train_Loss: 0.3770 Train_Acc: 82.646 Val_Loss: 0.3370  BEST VAL Loss: 0.3370  Val_Acc: 84.817

Epoch 47: Validation loss decreased (0.336993 --> 0.336794).  Saving model ...
	 Train_Loss: 0.3767 Train_Acc: 82.561 Val_Loss: 0.3368  BEST VAL Loss: 0.3368  Val_Acc: 84.676

Epoch 48: Validation loss decreased (0.336794 --> 0.336557).  Saving model ...
	 Train_Loss: 0.3765 Train_Acc: 82.617 Val_Loss: 0.3366  BEST VAL Loss: 0.3366  Val_Acc: 84.876

Epoch 49: Validation loss decreased (0.336557 --> 0.336296).  Saving model ...
	 Train_Loss: 0.3762 Train_Acc: 82.619 Val_Loss: 0.3363  BEST VAL Loss: 0.3363  Val_Acc: 85.054

Epoch 50: Validation loss decreased (0.336296 --> 0.336097).  Saving model ...
	 Train_Loss: 0.3760 Train_Acc: 82.454 Val_Loss: 0.3361  BEST VAL Loss: 0.3361  Val_Acc: 84.632

Epoch 51: Validation loss decreased (0.336097 --> 0.335813).  Saving model ...
	 Train_Loss: 0.3757 Train_Acc: 82.724 Val_Loss: 0.3358  BEST VAL Loss: 0.3358  Val_Acc: 85.054

Epoch 52: Validation loss decreased (0.335813 --> 0.335585).  Saving model ...
	 Train_Loss: 0.3754 Train_Acc: 82.646 Val_Loss: 0.3356  BEST VAL Loss: 0.3356  Val_Acc: 85.010

Epoch 53: Validation loss decreased (0.335585 --> 0.335404).  Saving model ...
	 Train_Loss: 0.3752 Train_Acc: 82.661 Val_Loss: 0.3354  BEST VAL Loss: 0.3354  Val_Acc: 84.621

Epoch 54: Validation loss decreased (0.335404 --> 0.335212).  Saving model ...
	 Train_Loss: 0.3750 Train_Acc: 82.618 Val_Loss: 0.3352  BEST VAL Loss: 0.3352  Val_Acc: 85.102

Epoch 55: Validation loss decreased (0.335212 --> 0.334965).  Saving model ...
	 Train_Loss: 0.3747 Train_Acc: 82.674 Val_Loss: 0.3350  BEST VAL Loss: 0.3350  Val_Acc: 85.225

Epoch 56: Validation loss decreased (0.334965 --> 0.334789).  Saving model ...
	 Train_Loss: 0.3745 Train_Acc: 82.716 Val_Loss: 0.3348  BEST VAL Loss: 0.3348  Val_Acc: 84.936

Epoch 57: Validation loss decreased (0.334789 --> 0.334629).  Saving model ...
	 Train_Loss: 0.3743 Train_Acc: 82.689 Val_Loss: 0.3346  BEST VAL Loss: 0.3346  Val_Acc: 84.739

Epoch 58: Validation loss decreased (0.334629 --> 0.334439).  Saving model ...
	 Train_Loss: 0.3741 Train_Acc: 82.636 Val_Loss: 0.3344  BEST VAL Loss: 0.3344  Val_Acc: 84.873

Epoch 59: Validation loss decreased (0.334439 --> 0.334269).  Saving model ...
	 Train_Loss: 0.3739 Train_Acc: 82.686 Val_Loss: 0.3343  BEST VAL Loss: 0.3343  Val_Acc: 84.906

Epoch 60: Validation loss decreased (0.334269 --> 0.334116).  Saving model ...
	 Train_Loss: 0.3737 Train_Acc: 82.623 Val_Loss: 0.3341  BEST VAL Loss: 0.3341  Val_Acc: 84.825

Epoch 61: Validation loss decreased (0.334116 --> 0.334001).  Saving model ...
	 Train_Loss: 0.3735 Train_Acc: 82.678 Val_Loss: 0.3340  BEST VAL Loss: 0.3340  Val_Acc: 84.876

Epoch 62: Validation loss decreased (0.334001 --> 0.333817).  Saving model ...
	 Train_Loss: 0.3732 Train_Acc: 82.828 Val_Loss: 0.3338  BEST VAL Loss: 0.3338  Val_Acc: 84.895

Epoch 63: Validation loss decreased (0.333817 --> 0.333642).  Saving model ...
	 Train_Loss: 0.3731 Train_Acc: 82.624 Val_Loss: 0.3336  BEST VAL Loss: 0.3336  Val_Acc: 85.069

Epoch 64: Validation loss decreased (0.333642 --> 0.333536).  Saving model ...
	 Train_Loss: 0.3729 Train_Acc: 82.713 Val_Loss: 0.3335  BEST VAL Loss: 0.3335  Val_Acc: 84.587

Epoch 65: Validation loss decreased (0.333536 --> 0.333335).  Saving model ...
	 Train_Loss: 0.3727 Train_Acc: 82.741 Val_Loss: 0.3333  BEST VAL Loss: 0.3333  Val_Acc: 85.143

Epoch 66: Validation loss decreased (0.333335 --> 0.333171).  Saving model ...
	 Train_Loss: 0.3725 Train_Acc: 82.646 Val_Loss: 0.3332  BEST VAL Loss: 0.3332  Val_Acc: 85.017

Epoch 67: Validation loss decreased (0.333171 --> 0.332959).  Saving model ...
	 Train_Loss: 0.3723 Train_Acc: 82.701 Val_Loss: 0.3330  BEST VAL Loss: 0.3330  Val_Acc: 85.117

Epoch 68: Validation loss decreased (0.332959 --> 0.332835).  Saving model ...
	 Train_Loss: 0.3721 Train_Acc: 82.670 Val_Loss: 0.3328  BEST VAL Loss: 0.3328  Val_Acc: 84.865

Epoch 69: Validation loss decreased (0.332835 --> 0.332769).  Saving model ...
	 Train_Loss: 0.3720 Train_Acc: 82.676 Val_Loss: 0.3328  BEST VAL Loss: 0.3328  Val_Acc: 84.406

Epoch 70: Validation loss decreased (0.332769 --> 0.332678).  Saving model ...
	 Train_Loss: 0.3718 Train_Acc: 82.704 Val_Loss: 0.3327  BEST VAL Loss: 0.3327  Val_Acc: 84.739

Epoch 71: Validation loss decreased (0.332678 --> 0.332507).  Saving model ...
	 Train_Loss: 0.3716 Train_Acc: 82.780 Val_Loss: 0.3325  BEST VAL Loss: 0.3325  Val_Acc: 85.102

Epoch 72: Validation loss decreased (0.332507 --> 0.332380).  Saving model ...
	 Train_Loss: 0.3714 Train_Acc: 82.758 Val_Loss: 0.3324  BEST VAL Loss: 0.3324  Val_Acc: 85.158

Epoch 73: Validation loss decreased (0.332380 --> 0.332246).  Saving model ...
	 Train_Loss: 0.3713 Train_Acc: 82.726 Val_Loss: 0.3322  BEST VAL Loss: 0.3322  Val_Acc: 84.828

Epoch 74: Validation loss decreased (0.332246 --> 0.332139).  Saving model ...
	 Train_Loss: 0.3711 Train_Acc: 82.765 Val_Loss: 0.3321  BEST VAL Loss: 0.3321  Val_Acc: 85.403

Epoch 75: Validation loss decreased (0.332139 --> 0.332034).  Saving model ...
	 Train_Loss: 0.3710 Train_Acc: 82.740 Val_Loss: 0.3320  BEST VAL Loss: 0.3320  Val_Acc: 84.999

Epoch 76: Validation loss decreased (0.332034 --> 0.331846).  Saving model ...
	 Train_Loss: 0.3708 Train_Acc: 82.860 Val_Loss: 0.3318  BEST VAL Loss: 0.3318  Val_Acc: 85.432

Epoch 77: Validation loss decreased (0.331846 --> 0.331747).  Saving model ...
	 Train_Loss: 0.3707 Train_Acc: 82.730 Val_Loss: 0.3317  BEST VAL Loss: 0.3317  Val_Acc: 84.821

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.3705 Train_Acc: 82.810 Val_Loss: 0.3318  BEST VAL Loss: 0.3317  Val_Acc: 84.280

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.3704 Train_Acc: 82.794 Val_Loss: 0.3318  BEST VAL Loss: 0.3317  Val_Acc: 84.250

Epoch 80: Validation loss decreased (0.331747 --> 0.331711).  Saving model ...
	 Train_Loss: 0.3702 Train_Acc: 82.806 Val_Loss: 0.3317  BEST VAL Loss: 0.3317  Val_Acc: 84.880

Epoch 81: Validation loss decreased (0.331711 --> 0.331599).  Saving model ...
	 Train_Loss: 0.3701 Train_Acc: 82.843 Val_Loss: 0.3316  BEST VAL Loss: 0.3316  Val_Acc: 85.114

Epoch 82: Validation loss decreased (0.331599 --> 0.331512).  Saving model ...
	 Train_Loss: 0.3699 Train_Acc: 82.790 Val_Loss: 0.3315  BEST VAL Loss: 0.3315  Val_Acc: 84.847

Epoch 83: Validation loss decreased (0.331512 --> 0.331388).  Saving model ...
	 Train_Loss: 0.3698 Train_Acc: 82.759 Val_Loss: 0.3314  BEST VAL Loss: 0.3314  Val_Acc: 85.173

Epoch 84: Validation loss decreased (0.331388 --> 0.331239).  Saving model ...
	 Train_Loss: 0.3696 Train_Acc: 82.840 Val_Loss: 0.3312  BEST VAL Loss: 0.3312  Val_Acc: 85.254

Epoch 85: Validation loss decreased (0.331239 --> 0.331111).  Saving model ...
	 Train_Loss: 0.3695 Train_Acc: 82.758 Val_Loss: 0.3311  BEST VAL Loss: 0.3311  Val_Acc: 85.369

Epoch 86: Validation loss decreased (0.331111 --> 0.331105).  Saving model ...
	 Train_Loss: 0.3694 Train_Acc: 82.785 Val_Loss: 0.3311  BEST VAL Loss: 0.3311  Val_Acc: 84.254

Epoch 87: Validation loss decreased (0.331105 --> 0.331047).  Saving model ...
	 Train_Loss: 0.3692 Train_Acc: 82.788 Val_Loss: 0.3310  BEST VAL Loss: 0.3310  Val_Acc: 84.669

Epoch 88: Validation loss decreased (0.331047 --> 0.330942).  Saving model ...
	 Train_Loss: 0.3691 Train_Acc: 82.707 Val_Loss: 0.3309  BEST VAL Loss: 0.3309  Val_Acc: 85.291

Epoch 89: Validation loss decreased (0.330942 --> 0.330804).  Saving model ...
	 Train_Loss: 0.3690 Train_Acc: 82.917 Val_Loss: 0.3308  BEST VAL Loss: 0.3308  Val_Acc: 85.254

Epoch 90: Validation loss decreased (0.330804 --> 0.330765).  Saving model ...
	 Train_Loss: 0.3689 Train_Acc: 82.897 Val_Loss: 0.3308  BEST VAL Loss: 0.3308  Val_Acc: 84.851

Epoch 91: Validation loss decreased (0.330765 --> 0.330703).  Saving model ...
	 Train_Loss: 0.3688 Train_Acc: 82.789 Val_Loss: 0.3307  BEST VAL Loss: 0.3307  Val_Acc: 84.495

Epoch 92: Validation loss decreased (0.330703 --> 0.330578).  Saving model ...
	 Train_Loss: 0.3686 Train_Acc: 82.795 Val_Loss: 0.3306  BEST VAL Loss: 0.3306  Val_Acc: 85.354

Epoch 93: Validation loss decreased (0.330578 --> 0.330461).  Saving model ...
	 Train_Loss: 0.3685 Train_Acc: 82.892 Val_Loss: 0.3305  BEST VAL Loss: 0.3305  Val_Acc: 85.195

Epoch 94: Validation loss decreased (0.330461 --> 0.330386).  Saving model ...
	 Train_Loss: 0.3684 Train_Acc: 82.883 Val_Loss: 0.3304  BEST VAL Loss: 0.3304  Val_Acc: 84.791

Epoch 95: Validation loss decreased (0.330386 --> 0.330276).  Saving model ...
	 Train_Loss: 0.3683 Train_Acc: 82.833 Val_Loss: 0.3303  BEST VAL Loss: 0.3303  Val_Acc: 85.195

Epoch 96: Validation loss decreased (0.330276 --> 0.330126).  Saving model ...
	 Train_Loss: 0.3681 Train_Acc: 82.830 Val_Loss: 0.3301  BEST VAL Loss: 0.3301  Val_Acc: 85.391

Epoch 97: Validation loss decreased (0.330126 --> 0.330054).  Saving model ...
	 Train_Loss: 0.3680 Train_Acc: 82.752 Val_Loss: 0.3301  BEST VAL Loss: 0.3301  Val_Acc: 85.136

Epoch 98: Validation loss decreased (0.330054 --> 0.329924).  Saving model ...
	 Train_Loss: 0.3679 Train_Acc: 82.783 Val_Loss: 0.3299  BEST VAL Loss: 0.3299  Val_Acc: 85.277

Epoch 99: Validation loss decreased (0.329924 --> 0.329838).  Saving model ...
	 Train_Loss: 0.3678 Train_Acc: 82.913 Val_Loss: 0.3298  BEST VAL Loss: 0.3298  Val_Acc: 84.854

H2O2_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.23      0.13      0.17     50422
           1       0.77      0.86      0.81    165500

    accuracy                           0.69    215922
   macro avg       0.50      0.50      0.49    215922
weighted avg       0.64      0.69      0.66    215922

H2O2_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.24      0.13      0.17      6303
           1       0.77      0.87      0.81     20688

    accuracy                           0.70     26991
   macro avg       0.50      0.50      0.49     26991
weighted avg       0.64      0.70      0.66     26991

H2O2_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.24      0.14      0.17      6303
           1       0.77      0.86      0.81     20688

    accuracy                           0.69     26991
   macro avg       0.50      0.50      0.49     26991
weighted avg       0.64      0.69      0.66     26991

              precision    recall  f1-score   support

           0       0.24      0.14      0.17      6303
           1       0.77      0.86      0.81     20688

    accuracy                           0.69     26991
   macro avg       0.50      0.50      0.49     26991
weighted avg       0.64      0.69      0.66     26991

H2O2_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.27      0.35     32887
           1       0.50      0.73      0.60     33660

    accuracy                           0.50     66547
   macro avg       0.50      0.50      0.47     66547
weighted avg       0.50      0.50      0.47     66547

              precision    recall  f1-score   support

           0       0.49      0.27      0.35     32887
           1       0.50      0.73      0.60     33660

    accuracy                           0.50     66547
   macro avg       0.50      0.50      0.47     66547
weighted avg       0.50      0.50      0.47     66547

completed
