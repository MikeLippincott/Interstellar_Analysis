[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'dc895952'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'f684b07d'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '82bd506c'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'd381cc59'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Thapsigargin_1.000_DMSO_0.025 treatment_name: Thapsigargin_10.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Thapsigargin_1.000_DMSO_0.025
TREATMENT_NAME: Thapsigargin_10.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'Thapsigargin_10.000_DMSO_0.025']
The dimensions of the data are: (315440, 1270)
Number of total missing values across all columns: 630880
Data Subset Is Off
Wells held out for testing: ['K06' 'L06']
Wells to use for training, validation, and testing ['D06' 'E06' 'D07' 'E07' 'K07' 'L07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.521982).  Saving model ...
	 Train_Loss: 0.6508 Train_Acc: 69.295 Val_Loss: 0.5220  BEST VAL Loss: 0.5220  Val_Acc: 72.485

Epoch 1: Validation loss decreased (0.521982 --> 0.445917).  Saving model ...
	 Train_Loss: 0.5524 Train_Acc: 78.730 Val_Loss: 0.4459  BEST VAL Loss: 0.4459  Val_Acc: 83.450

Epoch 2: Validation loss decreased (0.445917 --> 0.422066).  Saving model ...
	 Train_Loss: 0.5010 Train_Acc: 81.802 Val_Loss: 0.4221  BEST VAL Loss: 0.4221  Val_Acc: 82.459

Epoch 3: Validation loss decreased (0.422066 --> 0.407881).  Saving model ...
	 Train_Loss: 0.4659 Train_Acc: 83.772 Val_Loss: 0.4079  BEST VAL Loss: 0.4079  Val_Acc: 83.316

Epoch 4: Validation loss decreased (0.407881 --> 0.386976).  Saving model ...
	 Train_Loss: 0.4426 Train_Acc: 84.539 Val_Loss: 0.3870  BEST VAL Loss: 0.3870  Val_Acc: 86.671

Epoch 5: Validation loss decreased (0.386976 --> 0.373096).  Saving model ...
	 Train_Loss: 0.4243 Train_Acc: 85.254 Val_Loss: 0.3731  BEST VAL Loss: 0.3731  Val_Acc: 86.189

Epoch 6: Validation loss decreased (0.373096 --> 0.357641).  Saving model ...
	 Train_Loss: 0.4088 Train_Acc: 85.951 Val_Loss: 0.3576  BEST VAL Loss: 0.3576  Val_Acc: 87.709

Epoch 7: Validation loss decreased (0.357641 --> 0.346157).  Saving model ...
	 Train_Loss: 0.3963 Train_Acc: 86.324 Val_Loss: 0.3462  BEST VAL Loss: 0.3462  Val_Acc: 88.049

Epoch 8: Validation loss decreased (0.346157 --> 0.336743).  Saving model ...
	 Train_Loss: 0.3866 Train_Acc: 86.469 Val_Loss: 0.3367  BEST VAL Loss: 0.3367  Val_Acc: 88.312

Epoch 9: Validation loss decreased (0.336743 --> 0.331028).  Saving model ...
	 Train_Loss: 0.3783 Train_Acc: 86.694 Val_Loss: 0.3310  BEST VAL Loss: 0.3310  Val_Acc: 88.075

Epoch 10: Validation loss decreased (0.331028 --> 0.323979).  Saving model ...
	 Train_Loss: 0.3704 Train_Acc: 87.217 Val_Loss: 0.3240  BEST VAL Loss: 0.3240  Val_Acc: 89.061

Epoch 11: Validation loss decreased (0.323979 --> 0.318347).  Saving model ...
	 Train_Loss: 0.3633 Train_Acc: 87.417 Val_Loss: 0.3183  BEST VAL Loss: 0.3183  Val_Acc: 88.398

Epoch 12: Validation loss decreased (0.318347 --> 0.312970).  Saving model ...
	 Train_Loss: 0.3579 Train_Acc: 87.237 Val_Loss: 0.3130  BEST VAL Loss: 0.3130  Val_Acc: 89.233

Epoch 13: Validation loss decreased (0.312970 --> 0.308105).  Saving model ...
	 Train_Loss: 0.3520 Train_Acc: 87.887 Val_Loss: 0.3081  BEST VAL Loss: 0.3081  Val_Acc: 89.388

Epoch 14: Validation loss decreased (0.308105 --> 0.304885).  Saving model ...
	 Train_Loss: 0.3471 Train_Acc: 87.942 Val_Loss: 0.3049  BEST VAL Loss: 0.3049  Val_Acc: 88.028

Epoch 15: Validation loss decreased (0.304885 --> 0.301322).  Saving model ...
	 Train_Loss: 0.3426 Train_Acc: 87.915 Val_Loss: 0.3013  BEST VAL Loss: 0.3013  Val_Acc: 89.173

Epoch 16: Validation loss decreased (0.301322 --> 0.297569).  Saving model ...
	 Train_Loss: 0.3381 Train_Acc: 88.303 Val_Loss: 0.2976  BEST VAL Loss: 0.2976  Val_Acc: 89.625

Epoch 17: Validation loss decreased (0.297569 --> 0.297075).  Saving model ...
	 Train_Loss: 0.3345 Train_Acc: 88.184 Val_Loss: 0.2971  BEST VAL Loss: 0.2971  Val_Acc: 87.270

Epoch 18: Validation loss decreased (0.297075 --> 0.293658).  Saving model ...
	 Train_Loss: 0.3311 Train_Acc: 88.181 Val_Loss: 0.2937  BEST VAL Loss: 0.2937  Val_Acc: 89.966

Epoch 19: Validation loss did not decrease
	 Train_Loss: 0.3277 Train_Acc: 88.561 Val_Loss: 0.2960  BEST VAL Loss: 0.2937  Val_Acc: 85.814

Epoch 20: Validation loss decreased (0.293658 --> 0.293138).  Saving model ...
	 Train_Loss: 0.3246 Train_Acc: 88.472 Val_Loss: 0.2931  BEST VAL Loss: 0.2931  Val_Acc: 89.892

Epoch 21: Validation loss decreased (0.293138 --> 0.290684).  Saving model ...
	 Train_Loss: 0.3215 Train_Acc: 88.775 Val_Loss: 0.2907  BEST VAL Loss: 0.2907  Val_Acc: 89.531

Epoch 22: Validation loss decreased (0.290684 --> 0.288451).  Saving model ...
	 Train_Loss: 0.3187 Train_Acc: 88.786 Val_Loss: 0.2885  BEST VAL Loss: 0.2885  Val_Acc: 89.630

Epoch 23: Validation loss did not decrease
	 Train_Loss: 0.3162 Train_Acc: 88.859 Val_Loss: 0.2922  BEST VAL Loss: 0.2885  Val_Acc: 83.096

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.3137 Train_Acc: 88.898 Val_Loss: 0.2897  BEST VAL Loss: 0.2885  Val_Acc: 89.681

Epoch 25: Validation loss decreased (0.288451 --> 0.287491).  Saving model ...
	 Train_Loss: 0.3113 Train_Acc: 89.049 Val_Loss: 0.2875  BEST VAL Loss: 0.2875  Val_Acc: 89.617

Epoch 26: Validation loss decreased (0.287491 --> 0.285897).  Saving model ...
	 Train_Loss: 0.3091 Train_Acc: 89.141 Val_Loss: 0.2859  BEST VAL Loss: 0.2859  Val_Acc: 89.737

Epoch 27: Validation loss decreased (0.285897 --> 0.283972).  Saving model ...
	 Train_Loss: 0.3069 Train_Acc: 89.252 Val_Loss: 0.2840  BEST VAL Loss: 0.2840  Val_Acc: 89.897

Epoch 28: Validation loss decreased (0.283972 --> 0.282358).  Saving model ...
	 Train_Loss: 0.3049 Train_Acc: 89.234 Val_Loss: 0.2824  BEST VAL Loss: 0.2824  Val_Acc: 89.811

Epoch 29: Validation loss decreased (0.282358 --> 0.281348).  Saving model ...
	 Train_Loss: 0.3029 Train_Acc: 89.291 Val_Loss: 0.2813  BEST VAL Loss: 0.2813  Val_Acc: 89.311

Epoch 30: Validation loss decreased (0.281348 --> 0.279566).  Saving model ...
	 Train_Loss: 0.3010 Train_Acc: 89.425 Val_Loss: 0.2796  BEST VAL Loss: 0.2796  Val_Acc: 90.250

Epoch 31: Validation loss decreased (0.279566 --> 0.277861).  Saving model ...
	 Train_Loss: 0.2992 Train_Acc: 89.350 Val_Loss: 0.2779  BEST VAL Loss: 0.2779  Val_Acc: 90.301

Epoch 32: Validation loss decreased (0.277861 --> 0.276203).  Saving model ...
	 Train_Loss: 0.2976 Train_Acc: 89.445 Val_Loss: 0.2762  BEST VAL Loss: 0.2762  Val_Acc: 90.379

Epoch 33: Validation loss decreased (0.276203 --> 0.274910).  Saving model ...
	 Train_Loss: 0.2959 Train_Acc: 89.583 Val_Loss: 0.2749  BEST VAL Loss: 0.2749  Val_Acc: 90.426

Epoch 34: Validation loss decreased (0.274910 --> 0.273460).  Saving model ...
	 Train_Loss: 0.2943 Train_Acc: 89.425 Val_Loss: 0.2735  BEST VAL Loss: 0.2735  Val_Acc: 90.289

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.2927 Train_Acc: 89.771 Val_Loss: 0.2743  BEST VAL Loss: 0.2735  Val_Acc: 87.567

Epoch 36: Validation loss decreased (0.273460 --> 0.272885).  Saving model ...
	 Train_Loss: 0.2912 Train_Acc: 89.653 Val_Loss: 0.2729  BEST VAL Loss: 0.2729  Val_Acc: 90.512

Epoch 37: Validation loss decreased (0.272885 --> 0.271951).  Saving model ...
	 Train_Loss: 0.2898 Train_Acc: 89.659 Val_Loss: 0.2720  BEST VAL Loss: 0.2720  Val_Acc: 89.897

Epoch 38: Validation loss decreased (0.271951 --> 0.271200).  Saving model ...
	 Train_Loss: 0.2885 Train_Acc: 89.770 Val_Loss: 0.2712  BEST VAL Loss: 0.2712  Val_Acc: 89.143

Epoch 39: Validation loss decreased (0.271200 --> 0.270642).  Saving model ...
	 Train_Loss: 0.2871 Train_Acc: 89.861 Val_Loss: 0.2706  BEST VAL Loss: 0.2706  Val_Acc: 89.612

Epoch 40: Validation loss decreased (0.270642 --> 0.269765).  Saving model ...
	 Train_Loss: 0.2858 Train_Acc: 89.944 Val_Loss: 0.2698  BEST VAL Loss: 0.2698  Val_Acc: 89.772

Epoch 41: Validation loss decreased (0.269765 --> 0.268663).  Saving model ...
	 Train_Loss: 0.2846 Train_Acc: 89.745 Val_Loss: 0.2687  BEST VAL Loss: 0.2687  Val_Acc: 90.801

Epoch 42: Validation loss decreased (0.268663 --> 0.267873).  Saving model ...
	 Train_Loss: 0.2834 Train_Acc: 89.873 Val_Loss: 0.2679  BEST VAL Loss: 0.2679  Val_Acc: 89.966

Epoch 43: Validation loss decreased (0.267873 --> 0.266854).  Saving model ...
	 Train_Loss: 0.2822 Train_Acc: 89.971 Val_Loss: 0.2669  BEST VAL Loss: 0.2669  Val_Acc: 90.995

Epoch 44: Validation loss decreased (0.266854 --> 0.265833).  Saving model ...
	 Train_Loss: 0.2811 Train_Acc: 90.021 Val_Loss: 0.2658  BEST VAL Loss: 0.2658  Val_Acc: 90.943

Epoch 45: Validation loss decreased (0.265833 --> 0.264847).  Saving model ...
	 Train_Loss: 0.2799 Train_Acc: 90.065 Val_Loss: 0.2648  BEST VAL Loss: 0.2648  Val_Acc: 90.556

Epoch 46: Validation loss decreased (0.264847 --> 0.263776).  Saving model ...
	 Train_Loss: 0.2789 Train_Acc: 89.963 Val_Loss: 0.2638  BEST VAL Loss: 0.2638  Val_Acc: 90.904

Epoch 47: Validation loss decreased (0.263776 --> 0.262892).  Saving model ...
	 Train_Loss: 0.2778 Train_Acc: 90.048 Val_Loss: 0.2629  BEST VAL Loss: 0.2629  Val_Acc: 90.405

Epoch 48: Validation loss decreased (0.262892 --> 0.262031).  Saving model ...
	 Train_Loss: 0.2769 Train_Acc: 90.094 Val_Loss: 0.2620  BEST VAL Loss: 0.2620  Val_Acc: 90.508

Epoch 49: Validation loss decreased (0.262031 --> 0.261496).  Saving model ...
	 Train_Loss: 0.2759 Train_Acc: 90.209 Val_Loss: 0.2615  BEST VAL Loss: 0.2615  Val_Acc: 90.099

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.2749 Train_Acc: 90.082 Val_Loss: 0.2616  BEST VAL Loss: 0.2615  Val_Acc: 89.759

Epoch 51: Validation loss decreased (0.261496 --> 0.260841).  Saving model ...
	 Train_Loss: 0.2740 Train_Acc: 90.176 Val_Loss: 0.2608  BEST VAL Loss: 0.2608  Val_Acc: 90.254

Epoch 52: Validation loss decreased (0.260841 --> 0.259937).  Saving model ...
	 Train_Loss: 0.2731 Train_Acc: 90.142 Val_Loss: 0.2599  BEST VAL Loss: 0.2599  Val_Acc: 90.732

Epoch 53: Validation loss decreased (0.259937 --> 0.259936).  Saving model ...
	 Train_Loss: 0.2723 Train_Acc: 90.222 Val_Loss: 0.2599  BEST VAL Loss: 0.2599  Val_Acc: 89.483

Epoch 54: Validation loss decreased (0.259936 --> 0.259246).  Saving model ...
	 Train_Loss: 0.2714 Train_Acc: 90.186 Val_Loss: 0.2592  BEST VAL Loss: 0.2592  Val_Acc: 90.366

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.2706 Train_Acc: 90.320 Val_Loss: 0.2594  BEST VAL Loss: 0.2592  Val_Acc: 88.725

Epoch 56: Validation loss decreased (0.259246 --> 0.258594).  Saving model ...
	 Train_Loss: 0.2698 Train_Acc: 90.337 Val_Loss: 0.2586  BEST VAL Loss: 0.2586  Val_Acc: 90.775

Epoch 57: Validation loss decreased (0.258594 --> 0.257814).  Saving model ...
	 Train_Loss: 0.2690 Train_Acc: 90.299 Val_Loss: 0.2578  BEST VAL Loss: 0.2578  Val_Acc: 91.094

Epoch 58: Validation loss decreased (0.257814 --> 0.257265).  Saving model ...
	 Train_Loss: 0.2682 Train_Acc: 90.466 Val_Loss: 0.2573  BEST VAL Loss: 0.2573  Val_Acc: 90.685

Epoch 59: Validation loss decreased (0.257265 --> 0.256561).  Saving model ...
	 Train_Loss: 0.2674 Train_Acc: 90.262 Val_Loss: 0.2566  BEST VAL Loss: 0.2566  Val_Acc: 90.818

Epoch 60: Validation loss decreased (0.256561 --> 0.255794).  Saving model ...
	 Train_Loss: 0.2667 Train_Acc: 90.437 Val_Loss: 0.2558  BEST VAL Loss: 0.2558  Val_Acc: 91.055

Epoch 61: Validation loss decreased (0.255794 --> 0.255196).  Saving model ...
	 Train_Loss: 0.2659 Train_Acc: 90.426 Val_Loss: 0.2552  BEST VAL Loss: 0.2552  Val_Acc: 90.724

Epoch 62: Validation loss decreased (0.255196 --> 0.254530).  Saving model ...
	 Train_Loss: 0.2652 Train_Acc: 90.557 Val_Loss: 0.2545  BEST VAL Loss: 0.2545  Val_Acc: 91.481

Epoch 63: Validation loss decreased (0.254530 --> 0.254156).  Saving model ...
	 Train_Loss: 0.2645 Train_Acc: 90.410 Val_Loss: 0.2542  BEST VAL Loss: 0.2542  Val_Acc: 90.762

Epoch 64: Validation loss decreased (0.254156 --> 0.253847).  Saving model ...
	 Train_Loss: 0.2638 Train_Acc: 90.546 Val_Loss: 0.2538  BEST VAL Loss: 0.2538  Val_Acc: 90.508

Epoch 65: Validation loss decreased (0.253847 --> 0.253395).  Saving model ...
	 Train_Loss: 0.2631 Train_Acc: 90.624 Val_Loss: 0.2534  BEST VAL Loss: 0.2534  Val_Acc: 90.082

Epoch 66: Validation loss decreased (0.253395 --> 0.252900).  Saving model ...
	 Train_Loss: 0.2625 Train_Acc: 90.519 Val_Loss: 0.2529  BEST VAL Loss: 0.2529  Val_Acc: 91.081

Epoch 67: Validation loss decreased (0.252900 --> 0.252562).  Saving model ...
	 Train_Loss: 0.2619 Train_Acc: 90.532 Val_Loss: 0.2526  BEST VAL Loss: 0.2526  Val_Acc: 90.495

Epoch 68: Validation loss decreased (0.252562 --> 0.252018).  Saving model ...
	 Train_Loss: 0.2612 Train_Acc: 90.579 Val_Loss: 0.2520  BEST VAL Loss: 0.2520  Val_Acc: 90.693

Epoch 69: Validation loss decreased (0.252018 --> 0.251366).  Saving model ...
	 Train_Loss: 0.2606 Train_Acc: 90.582 Val_Loss: 0.2514  BEST VAL Loss: 0.2514  Val_Acc: 91.249

Epoch 70: Validation loss decreased (0.251366 --> 0.250791).  Saving model ...
	 Train_Loss: 0.2600 Train_Acc: 90.584 Val_Loss: 0.2508  BEST VAL Loss: 0.2508  Val_Acc: 91.059

Epoch 71: Validation loss decreased (0.250791 --> 0.250334).  Saving model ...
	 Train_Loss: 0.2595 Train_Acc: 90.530 Val_Loss: 0.2503  BEST VAL Loss: 0.2503  Val_Acc: 91.003

Epoch 72: Validation loss decreased (0.250334 --> 0.249787).  Saving model ...
	 Train_Loss: 0.2589 Train_Acc: 90.724 Val_Loss: 0.2498  BEST VAL Loss: 0.2498  Val_Acc: 91.141

Epoch 73: Validation loss decreased (0.249787 --> 0.249472).  Saving model ...
	 Train_Loss: 0.2583 Train_Acc: 90.590 Val_Loss: 0.2495  BEST VAL Loss: 0.2495  Val_Acc: 90.525

Epoch 74: Validation loss decreased (0.249472 --> 0.248903).  Saving model ...
	 Train_Loss: 0.2578 Train_Acc: 90.641 Val_Loss: 0.2489  BEST VAL Loss: 0.2489  Val_Acc: 91.232

Epoch 75: Validation loss decreased (0.248903 --> 0.248513).  Saving model ...
	 Train_Loss: 0.2572 Train_Acc: 90.724 Val_Loss: 0.2485  BEST VAL Loss: 0.2485  Val_Acc: 91.038

Epoch 76: Validation loss decreased (0.248513 --> 0.248121).  Saving model ...
	 Train_Loss: 0.2566 Train_Acc: 90.740 Val_Loss: 0.2481  BEST VAL Loss: 0.2481  Val_Acc: 91.098

Epoch 77: Validation loss decreased (0.248121 --> 0.247729).  Saving model ...
	 Train_Loss: 0.2561 Train_Acc: 90.642 Val_Loss: 0.2477  BEST VAL Loss: 0.2477  Val_Acc: 90.909

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.2556 Train_Acc: 90.687 Val_Loss: 0.2481  BEST VAL Loss: 0.2477  Val_Acc: 89.475

Epoch 79: Validation loss decreased (0.247729 --> 0.247582).  Saving model ...
	 Train_Loss: 0.2551 Train_Acc: 90.707 Val_Loss: 0.2476  BEST VAL Loss: 0.2476  Val_Acc: 91.025

Epoch 80: Validation loss decreased (0.247582 --> 0.247168).  Saving model ...
	 Train_Loss: 0.2546 Train_Acc: 90.643 Val_Loss: 0.2472  BEST VAL Loss: 0.2472  Val_Acc: 91.176

Epoch 81: Validation loss decreased (0.247168 --> 0.246892).  Saving model ...
	 Train_Loss: 0.2541 Train_Acc: 90.774 Val_Loss: 0.2469  BEST VAL Loss: 0.2469  Val_Acc: 90.151

Epoch 82: Validation loss decreased (0.246892 --> 0.246462).  Saving model ...
	 Train_Loss: 0.2536 Train_Acc: 90.868 Val_Loss: 0.2465  BEST VAL Loss: 0.2465  Val_Acc: 91.283

Epoch 83: Validation loss decreased (0.246462 --> 0.246105).  Saving model ...
	 Train_Loss: 0.2532 Train_Acc: 90.786 Val_Loss: 0.2461  BEST VAL Loss: 0.2461  Val_Acc: 90.947

Epoch 84: Validation loss decreased (0.246105 --> 0.245757).  Saving model ...
	 Train_Loss: 0.2527 Train_Acc: 90.778 Val_Loss: 0.2458  BEST VAL Loss: 0.2458  Val_Acc: 90.857

Epoch 85: Validation loss decreased (0.245757 --> 0.245576).  Saving model ...
	 Train_Loss: 0.2522 Train_Acc: 90.814 Val_Loss: 0.2456  BEST VAL Loss: 0.2456  Val_Acc: 89.836

Epoch 86: Validation loss decreased (0.245576 --> 0.245155).  Saving model ...
	 Train_Loss: 0.2518 Train_Acc: 90.793 Val_Loss: 0.2452  BEST VAL Loss: 0.2452  Val_Acc: 91.115

Epoch 87: Validation loss decreased (0.245155 --> 0.244761).  Saving model ...
	 Train_Loss: 0.2513 Train_Acc: 90.846 Val_Loss: 0.2448  BEST VAL Loss: 0.2448  Val_Acc: 91.391

Epoch 88: Validation loss decreased (0.244761 --> 0.244460).  Saving model ...
	 Train_Loss: 0.2509 Train_Acc: 90.893 Val_Loss: 0.2445  BEST VAL Loss: 0.2445  Val_Acc: 91.133

Epoch 89: Validation loss decreased (0.244460 --> 0.244119).  Saving model ...
	 Train_Loss: 0.2504 Train_Acc: 90.836 Val_Loss: 0.2441  BEST VAL Loss: 0.2441  Val_Acc: 91.042

Epoch 90: Validation loss decreased (0.244119 --> 0.243872).  Saving model ...
	 Train_Loss: 0.2500 Train_Acc: 90.907 Val_Loss: 0.2439  BEST VAL Loss: 0.2439  Val_Acc: 90.530

Epoch 91: Validation loss decreased (0.243872 --> 0.243516).  Saving model ...
	 Train_Loss: 0.2496 Train_Acc: 90.830 Val_Loss: 0.2435  BEST VAL Loss: 0.2435  Val_Acc: 91.270

Epoch 92: Validation loss decreased (0.243516 --> 0.243187).  Saving model ...
	 Train_Loss: 0.2492 Train_Acc: 90.844 Val_Loss: 0.2432  BEST VAL Loss: 0.2432  Val_Acc: 91.240

Epoch 93: Validation loss decreased (0.243187 --> 0.242920).  Saving model ...
	 Train_Loss: 0.2488 Train_Acc: 90.982 Val_Loss: 0.2429  BEST VAL Loss: 0.2429  Val_Acc: 91.296

Epoch 94: Validation loss decreased (0.242920 --> 0.242628).  Saving model ...
	 Train_Loss: 0.2484 Train_Acc: 90.872 Val_Loss: 0.2426  BEST VAL Loss: 0.2426  Val_Acc: 91.167

Epoch 95: Validation loss decreased (0.242628 --> 0.242273).  Saving model ...
	 Train_Loss: 0.2480 Train_Acc: 90.880 Val_Loss: 0.2423  BEST VAL Loss: 0.2423  Val_Acc: 91.072

Epoch 96: Validation loss decreased (0.242273 --> 0.242016).  Saving model ...
	 Train_Loss: 0.2476 Train_Acc: 90.969 Val_Loss: 0.2420  BEST VAL Loss: 0.2420  Val_Acc: 91.180

Epoch 97: Validation loss decreased (0.242016 --> 0.241710).  Saving model ...
	 Train_Loss: 0.2472 Train_Acc: 90.938 Val_Loss: 0.2417  BEST VAL Loss: 0.2417  Val_Acc: 91.227

Epoch 98: Validation loss decreased (0.241710 --> 0.241403).  Saving model ...
	 Train_Loss: 0.2468 Train_Acc: 90.901 Val_Loss: 0.2414  BEST VAL Loss: 0.2414  Val_Acc: 91.163

Epoch 99: Validation loss decreased (0.241403 --> 0.241205).  Saving model ...
	 Train_Loss: 0.2465 Train_Acc: 90.927 Val_Loss: 0.2412  BEST VAL Loss: 0.2412  Val_Acc: 90.874

Thapsigargin_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.47      0.48     88098
           1       0.53      0.53      0.53     97655

    accuracy                           0.50    185753
   macro avg       0.50      0.50      0.50    185753
weighted avg       0.50      0.50      0.50    185753

Thapsigargin_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.47      0.48     11013
           1       0.53      0.53      0.53     12207

    accuracy                           0.50     23220
   macro avg       0.50      0.50      0.50     23220
weighted avg       0.50      0.50      0.50     23220

Thapsigargin_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.47      0.47     11013
           1       0.52      0.52      0.52     12207

    accuracy                           0.50     23220
   macro avg       0.50      0.50      0.50     23220
weighted avg       0.50      0.50      0.50     23220

              precision    recall  f1-score   support

           0       0.47      0.47      0.47     11013
           1       0.52      0.52      0.52     12207

    accuracy                           0.50     23220
   macro avg       0.50      0.50      0.50     23220
weighted avg       0.50      0.50      0.50     23220

Thapsigargin_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.43      0.44     38332
           1       0.54      0.58      0.56     44915

    accuracy                           0.51     83247
   macro avg       0.50      0.50      0.50     83247
weighted avg       0.50      0.51      0.50     83247

              precision    recall  f1-score   support

           0       0.46      0.43      0.44     38332
           1       0.54      0.58      0.56     44915

    accuracy                           0.51     83247
   macro avg       0.50      0.50      0.50     83247
weighted avg       0.50      0.51      0.50     83247

completed
