[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '5d10ba74'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '2a2a3975'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '35f02714'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'aeda6373'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: DMSO_0.100_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: DMSO_0.100_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'LPS_0.010_DMSO_0.025']
The dimensions of the data are: (51502, 1276)
Number of total missing values across all columns: 103004
Data Subset Is Off
Wells held out for testing: ['B21' 'I14']
Wells to use for training, validation, and testing ['B14' 'C14' 'B15' 'C15' 'B16' 'B17' 'B20' 'J14' 'I15' 'J15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.596918).  Saving model ...
	 Train_Loss: 0.6599 Train_Acc: 55.795 Val_Loss: 0.5969  BEST VAL Loss: 0.5969  Val_Acc: 67.824

Epoch 1: Validation loss decreased (0.596918 --> 0.584101).  Saving model ...
	 Train_Loss: 0.6346 Train_Acc: 65.517 Val_Loss: 0.5841  BEST VAL Loss: 0.5841  Val_Acc: 70.777

Epoch 2: Validation loss decreased (0.584101 --> 0.574409).  Saving model ...
	 Train_Loss: 0.6184 Train_Acc: 68.488 Val_Loss: 0.5744  BEST VAL Loss: 0.5744  Val_Acc: 72.029

Epoch 3: Validation loss decreased (0.574409 --> 0.566471).  Saving model ...
	 Train_Loss: 0.6057 Train_Acc: 70.478 Val_Loss: 0.5665  BEST VAL Loss: 0.5665  Val_Acc: 73.045

Epoch 4: Validation loss decreased (0.566471 --> 0.559650).  Saving model ...
	 Train_Loss: 0.5956 Train_Acc: 71.364 Val_Loss: 0.5596  BEST VAL Loss: 0.5596  Val_Acc: 73.754

Epoch 5: Validation loss decreased (0.559650 --> 0.553469).  Saving model ...
	 Train_Loss: 0.5869 Train_Acc: 71.786 Val_Loss: 0.5535  BEST VAL Loss: 0.5535  Val_Acc: 74.274

Epoch 6: Validation loss decreased (0.553469 --> 0.548050).  Saving model ...
	 Train_Loss: 0.5790 Train_Acc: 72.811 Val_Loss: 0.5481  BEST VAL Loss: 0.5481  Val_Acc: 74.533

Epoch 7: Validation loss decreased (0.548050 --> 0.543172).  Saving model ...
	 Train_Loss: 0.5720 Train_Acc: 73.272 Val_Loss: 0.5432  BEST VAL Loss: 0.5432  Val_Acc: 75.030

Epoch 8: Validation loss decreased (0.543172 --> 0.538946).  Saving model ...
	 Train_Loss: 0.5655 Train_Acc: 74.444 Val_Loss: 0.5389  BEST VAL Loss: 0.5389  Val_Acc: 75.762

Epoch 9: Validation loss decreased (0.538946 --> 0.535009).  Saving model ...
	 Train_Loss: 0.5596 Train_Acc: 75.354 Val_Loss: 0.5350  BEST VAL Loss: 0.5350  Val_Acc: 75.856

Epoch 10: Validation loss decreased (0.535009 --> 0.531494).  Saving model ...
	 Train_Loss: 0.5545 Train_Acc: 75.472 Val_Loss: 0.5315  BEST VAL Loss: 0.5315  Val_Acc: 76.140

Epoch 11: Validation loss decreased (0.531494 --> 0.528382).  Saving model ...
	 Train_Loss: 0.5497 Train_Acc: 75.927 Val_Loss: 0.5284  BEST VAL Loss: 0.5284  Val_Acc: 76.116

Epoch 12: Validation loss decreased (0.528382 --> 0.525499).  Saving model ...
	 Train_Loss: 0.5454 Train_Acc: 76.219 Val_Loss: 0.5255  BEST VAL Loss: 0.5255  Val_Acc: 76.447

Epoch 13: Validation loss decreased (0.525499 --> 0.522940).  Saving model ...
	 Train_Loss: 0.5412 Train_Acc: 76.553 Val_Loss: 0.5229  BEST VAL Loss: 0.5229  Val_Acc: 76.423

Epoch 14: Validation loss decreased (0.522940 --> 0.520597).  Saving model ...
	 Train_Loss: 0.5374 Train_Acc: 76.641 Val_Loss: 0.5206  BEST VAL Loss: 0.5206  Val_Acc: 76.471

Epoch 15: Validation loss decreased (0.520597 --> 0.518431).  Saving model ...
	 Train_Loss: 0.5337 Train_Acc: 77.176 Val_Loss: 0.5184  BEST VAL Loss: 0.5184  Val_Acc: 76.589

Epoch 16: Validation loss decreased (0.518431 --> 0.516377).  Saving model ...
	 Train_Loss: 0.5303 Train_Acc: 77.306 Val_Loss: 0.5164  BEST VAL Loss: 0.5164  Val_Acc: 76.494

Epoch 17: Validation loss decreased (0.516377 --> 0.514514).  Saving model ...
	 Train_Loss: 0.5271 Train_Acc: 77.356 Val_Loss: 0.5145  BEST VAL Loss: 0.5145  Val_Acc: 76.376

Epoch 18: Validation loss decreased (0.514514 --> 0.512722).  Saving model ...
	 Train_Loss: 0.5241 Train_Acc: 77.598 Val_Loss: 0.5127  BEST VAL Loss: 0.5127  Val_Acc: 76.636

Epoch 19: Validation loss decreased (0.512722 --> 0.511031).  Saving model ...
	 Train_Loss: 0.5212 Train_Acc: 77.840 Val_Loss: 0.5110  BEST VAL Loss: 0.5110  Val_Acc: 76.730

Epoch 20: Validation loss decreased (0.511031 --> 0.509471).  Saving model ...
	 Train_Loss: 0.5185 Train_Acc: 77.760 Val_Loss: 0.5095  BEST VAL Loss: 0.5095  Val_Acc: 76.423

Epoch 21: Validation loss decreased (0.509471 --> 0.508046).  Saving model ...
	 Train_Loss: 0.5158 Train_Acc: 77.991 Val_Loss: 0.5080  BEST VAL Loss: 0.5080  Val_Acc: 76.163

Epoch 22: Validation loss decreased (0.508046 --> 0.506595).  Saving model ...
	 Train_Loss: 0.5133 Train_Acc: 78.194 Val_Loss: 0.5066  BEST VAL Loss: 0.5066  Val_Acc: 76.423

Epoch 23: Validation loss decreased (0.506595 --> 0.505244).  Saving model ...
	 Train_Loss: 0.5108 Train_Acc: 78.487 Val_Loss: 0.5052  BEST VAL Loss: 0.5052  Val_Acc: 76.447

Epoch 24: Validation loss decreased (0.505244 --> 0.503998).  Saving model ...
	 Train_Loss: 0.5085 Train_Acc: 78.519 Val_Loss: 0.5040  BEST VAL Loss: 0.5040  Val_Acc: 76.471

Epoch 25: Validation loss decreased (0.503998 --> 0.502840).  Saving model ...
	 Train_Loss: 0.5063 Train_Acc: 78.448 Val_Loss: 0.5028  BEST VAL Loss: 0.5028  Val_Acc: 76.163

Epoch 26: Validation loss decreased (0.502840 --> 0.501693).  Saving model ...
	 Train_Loss: 0.5042 Train_Acc: 78.472 Val_Loss: 0.5017  BEST VAL Loss: 0.5017  Val_Acc: 76.234

Epoch 27: Validation loss decreased (0.501693 --> 0.500589).  Saving model ...
	 Train_Loss: 0.5021 Train_Acc: 78.797 Val_Loss: 0.5006  BEST VAL Loss: 0.5006  Val_Acc: 76.707

Epoch 28: Validation loss decreased (0.500589 --> 0.499571).  Saving model ...
	 Train_Loss: 0.5001 Train_Acc: 78.983 Val_Loss: 0.4996  BEST VAL Loss: 0.4996  Val_Acc: 76.825

Epoch 29: Validation loss decreased (0.499571 --> 0.498609).  Saving model ...
	 Train_Loss: 0.4982 Train_Acc: 79.219 Val_Loss: 0.4986  BEST VAL Loss: 0.4986  Val_Acc: 76.494

Epoch 30: Validation loss decreased (0.498609 --> 0.497683).  Saving model ...
	 Train_Loss: 0.4963 Train_Acc: 79.266 Val_Loss: 0.4977  BEST VAL Loss: 0.4977  Val_Acc: 76.565

Epoch 31: Validation loss decreased (0.497683 --> 0.496748).  Saving model ...
	 Train_Loss: 0.4945 Train_Acc: 79.145 Val_Loss: 0.4967  BEST VAL Loss: 0.4967  Val_Acc: 76.872

Epoch 32: Validation loss decreased (0.496748 --> 0.495842).  Saving model ...
	 Train_Loss: 0.4928 Train_Acc: 79.311 Val_Loss: 0.4958  BEST VAL Loss: 0.4958  Val_Acc: 76.754

Epoch 33: Validation loss decreased (0.495842 --> 0.494989).  Saving model ...
	 Train_Loss: 0.4910 Train_Acc: 79.695 Val_Loss: 0.4950  BEST VAL Loss: 0.4950  Val_Acc: 76.801

Epoch 34: Validation loss decreased (0.494989 --> 0.494203).  Saving model ...
	 Train_Loss: 0.4893 Train_Acc: 79.624 Val_Loss: 0.4942  BEST VAL Loss: 0.4942  Val_Acc: 76.943

Epoch 35: Validation loss decreased (0.494203 --> 0.493387).  Saving model ...
	 Train_Loss: 0.4877 Train_Acc: 79.656 Val_Loss: 0.4934  BEST VAL Loss: 0.4934  Val_Acc: 77.203

Epoch 36: Validation loss decreased (0.493387 --> 0.492607).  Saving model ...
	 Train_Loss: 0.4861 Train_Acc: 79.963 Val_Loss: 0.4926  BEST VAL Loss: 0.4926  Val_Acc: 77.416

Epoch 37: Validation loss decreased (0.492607 --> 0.491830).  Saving model ...
	 Train_Loss: 0.4846 Train_Acc: 79.963 Val_Loss: 0.4918  BEST VAL Loss: 0.4918  Val_Acc: 77.297

Epoch 38: Validation loss decreased (0.491830 --> 0.491139).  Saving model ...
	 Train_Loss: 0.4831 Train_Acc: 79.949 Val_Loss: 0.4911  BEST VAL Loss: 0.4911  Val_Acc: 77.439

Epoch 39: Validation loss decreased (0.491139 --> 0.490504).  Saving model ...
	 Train_Loss: 0.4816 Train_Acc: 80.185 Val_Loss: 0.4905  BEST VAL Loss: 0.4905  Val_Acc: 77.345

Epoch 40: Validation loss decreased (0.490504 --> 0.489853).  Saving model ...
	 Train_Loss: 0.4802 Train_Acc: 80.167 Val_Loss: 0.4899  BEST VAL Loss: 0.4899  Val_Acc: 77.439

Epoch 41: Validation loss decreased (0.489853 --> 0.489273).  Saving model ...
	 Train_Loss: 0.4788 Train_Acc: 80.138 Val_Loss: 0.4893  BEST VAL Loss: 0.4893  Val_Acc: 77.557

Epoch 42: Validation loss decreased (0.489273 --> 0.488728).  Saving model ...
	 Train_Loss: 0.4774 Train_Acc: 80.439 Val_Loss: 0.4887  BEST VAL Loss: 0.4887  Val_Acc: 77.014

Epoch 43: Validation loss decreased (0.488728 --> 0.488153).  Saving model ...
	 Train_Loss: 0.4761 Train_Acc: 80.530 Val_Loss: 0.4882  BEST VAL Loss: 0.4882  Val_Acc: 77.297

Epoch 44: Validation loss decreased (0.488153 --> 0.487626).  Saving model ...
	 Train_Loss: 0.4748 Train_Acc: 80.613 Val_Loss: 0.4876  BEST VAL Loss: 0.4876  Val_Acc: 77.227

Epoch 45: Validation loss decreased (0.487626 --> 0.487068).  Saving model ...
	 Train_Loss: 0.4735 Train_Acc: 80.663 Val_Loss: 0.4871  BEST VAL Loss: 0.4871  Val_Acc: 77.250

Epoch 46: Validation loss decreased (0.487068 --> 0.486563).  Saving model ...
	 Train_Loss: 0.4723 Train_Acc: 80.598 Val_Loss: 0.4866  BEST VAL Loss: 0.4866  Val_Acc: 77.297

Epoch 47: Validation loss decreased (0.486563 --> 0.486062).  Saving model ...
	 Train_Loss: 0.4710 Train_Acc: 80.604 Val_Loss: 0.4861  BEST VAL Loss: 0.4861  Val_Acc: 77.605

Epoch 48: Validation loss decreased (0.486062 --> 0.485606).  Saving model ...
	 Train_Loss: 0.4698 Train_Acc: 80.796 Val_Loss: 0.4856  BEST VAL Loss: 0.4856  Val_Acc: 77.534

Epoch 49: Validation loss decreased (0.485606 --> 0.485149).  Saving model ...
	 Train_Loss: 0.4686 Train_Acc: 80.894 Val_Loss: 0.4851  BEST VAL Loss: 0.4851  Val_Acc: 77.557

Epoch 50: Validation loss decreased (0.485149 --> 0.484711).  Saving model ...
	 Train_Loss: 0.4675 Train_Acc: 80.799 Val_Loss: 0.4847  BEST VAL Loss: 0.4847  Val_Acc: 77.770

Epoch 51: Validation loss decreased (0.484711 --> 0.484278).  Saving model ...
	 Train_Loss: 0.4663 Train_Acc: 81.068 Val_Loss: 0.4843  BEST VAL Loss: 0.4843  Val_Acc: 77.699

Epoch 52: Validation loss decreased (0.484278 --> 0.483858).  Saving model ...
	 Train_Loss: 0.4652 Train_Acc: 81.106 Val_Loss: 0.4839  BEST VAL Loss: 0.4839  Val_Acc: 77.486

Epoch 53: Validation loss decreased (0.483858 --> 0.483507).  Saving model ...
	 Train_Loss: 0.4641 Train_Acc: 81.086 Val_Loss: 0.4835  BEST VAL Loss: 0.4835  Val_Acc: 77.605

Epoch 54: Validation loss decreased (0.483507 --> 0.483186).  Saving model ...
	 Train_Loss: 0.4630 Train_Acc: 81.319 Val_Loss: 0.4832  BEST VAL Loss: 0.4832  Val_Acc: 77.888

Epoch 55: Validation loss decreased (0.483186 --> 0.482841).  Saving model ...
	 Train_Loss: 0.4619 Train_Acc: 81.224 Val_Loss: 0.4828  BEST VAL Loss: 0.4828  Val_Acc: 77.652

Epoch 56: Validation loss decreased (0.482841 --> 0.482513).  Saving model ...
	 Train_Loss: 0.4608 Train_Acc: 81.304 Val_Loss: 0.4825  BEST VAL Loss: 0.4825  Val_Acc: 77.463

Epoch 57: Validation loss decreased (0.482513 --> 0.482231).  Saving model ...
	 Train_Loss: 0.4598 Train_Acc: 81.573 Val_Loss: 0.4822  BEST VAL Loss: 0.4822  Val_Acc: 77.652

Epoch 58: Validation loss decreased (0.482231 --> 0.481910).  Saving model ...
	 Train_Loss: 0.4588 Train_Acc: 81.375 Val_Loss: 0.4819  BEST VAL Loss: 0.4819  Val_Acc: 77.723

Epoch 59: Validation loss decreased (0.481910 --> 0.481626).  Saving model ...
	 Train_Loss: 0.4577 Train_Acc: 81.750 Val_Loss: 0.4816  BEST VAL Loss: 0.4816  Val_Acc: 77.699

Epoch 60: Validation loss decreased (0.481626 --> 0.481336).  Saving model ...
	 Train_Loss: 0.4567 Train_Acc: 81.703 Val_Loss: 0.4813  BEST VAL Loss: 0.4813  Val_Acc: 77.699

Epoch 61: Validation loss decreased (0.481336 --> 0.481061).  Saving model ...
	 Train_Loss: 0.4558 Train_Acc: 81.531 Val_Loss: 0.4811  BEST VAL Loss: 0.4811  Val_Acc: 77.794

Epoch 62: Validation loss decreased (0.481061 --> 0.480813).  Saving model ...
	 Train_Loss: 0.4548 Train_Acc: 81.632 Val_Loss: 0.4808  BEST VAL Loss: 0.4808  Val_Acc: 77.675

Epoch 63: Validation loss decreased (0.480813 --> 0.480541).  Saving model ...
	 Train_Loss: 0.4538 Train_Acc: 81.750 Val_Loss: 0.4805  BEST VAL Loss: 0.4805  Val_Acc: 77.888

Epoch 64: Validation loss decreased (0.480541 --> 0.480322).  Saving model ...
	 Train_Loss: 0.4529 Train_Acc: 81.963 Val_Loss: 0.4803  BEST VAL Loss: 0.4803  Val_Acc: 77.675

Epoch 65: Validation loss decreased (0.480322 --> 0.480128).  Saving model ...
	 Train_Loss: 0.4519 Train_Acc: 82.007 Val_Loss: 0.4801  BEST VAL Loss: 0.4801  Val_Acc: 77.675

Epoch 66: Validation loss decreased (0.480128 --> 0.479937).  Saving model ...
	 Train_Loss: 0.4510 Train_Acc: 81.750 Val_Loss: 0.4799  BEST VAL Loss: 0.4799  Val_Acc: 77.888

Epoch 67: Validation loss decreased (0.479937 --> 0.479743).  Saving model ...
	 Train_Loss: 0.4501 Train_Acc: 81.909 Val_Loss: 0.4797  BEST VAL Loss: 0.4797  Val_Acc: 77.817

Epoch 68: Validation loss decreased (0.479743 --> 0.479584).  Saving model ...
	 Train_Loss: 0.4493 Train_Acc: 82.045 Val_Loss: 0.4796  BEST VAL Loss: 0.4796  Val_Acc: 77.368

Epoch 69: Validation loss decreased (0.479584 --> 0.479465).  Saving model ...
	 Train_Loss: 0.4484 Train_Acc: 82.190 Val_Loss: 0.4795  BEST VAL Loss: 0.4795  Val_Acc: 77.675

Epoch 70: Validation loss decreased (0.479465 --> 0.479302).  Saving model ...
	 Train_Loss: 0.4475 Train_Acc: 82.190 Val_Loss: 0.4793  BEST VAL Loss: 0.4793  Val_Acc: 77.746

Epoch 71: Validation loss decreased (0.479302 --> 0.479191).  Saving model ...
	 Train_Loss: 0.4467 Train_Acc: 82.205 Val_Loss: 0.4792  BEST VAL Loss: 0.4792  Val_Acc: 77.628

Epoch 72: Validation loss decreased (0.479191 --> 0.479090).  Saving model ...
	 Train_Loss: 0.4458 Train_Acc: 82.524 Val_Loss: 0.4791  BEST VAL Loss: 0.4791  Val_Acc: 77.770

Epoch 73: Validation loss decreased (0.479090 --> 0.478973).  Saving model ...
	 Train_Loss: 0.4450 Train_Acc: 82.323 Val_Loss: 0.4790  BEST VAL Loss: 0.4790  Val_Acc: 77.652

Epoch 74: Validation loss decreased (0.478973 --> 0.478882).  Saving model ...
	 Train_Loss: 0.4442 Train_Acc: 82.311 Val_Loss: 0.4789  BEST VAL Loss: 0.4789  Val_Acc: 77.297

Epoch 75: Validation loss decreased (0.478882 --> 0.478793).  Saving model ...
	 Train_Loss: 0.4433 Train_Acc: 82.592 Val_Loss: 0.4788  BEST VAL Loss: 0.4788  Val_Acc: 77.439

Epoch 76: Validation loss decreased (0.478793 --> 0.478717).  Saving model ...
	 Train_Loss: 0.4425 Train_Acc: 82.388 Val_Loss: 0.4787  BEST VAL Loss: 0.4787  Val_Acc: 77.841

Epoch 77: Validation loss decreased (0.478717 --> 0.478637).  Saving model ...
	 Train_Loss: 0.4418 Train_Acc: 82.352 Val_Loss: 0.4786  BEST VAL Loss: 0.4786  Val_Acc: 77.628

Epoch 78: Validation loss decreased (0.478637 --> 0.478547).  Saving model ...
	 Train_Loss: 0.4410 Train_Acc: 82.494 Val_Loss: 0.4785  BEST VAL Loss: 0.4785  Val_Acc: 77.723

Epoch 79: Validation loss decreased (0.478547 --> 0.478473).  Saving model ...
	 Train_Loss: 0.4402 Train_Acc: 82.686 Val_Loss: 0.4785  BEST VAL Loss: 0.4785  Val_Acc: 77.439

Epoch 80: Validation loss decreased (0.478473 --> 0.478447).  Saving model ...
	 Train_Loss: 0.4395 Train_Acc: 82.435 Val_Loss: 0.4784  BEST VAL Loss: 0.4784  Val_Acc: 77.368

Epoch 81: Validation loss decreased (0.478447 --> 0.478402).  Saving model ...
	 Train_Loss: 0.4387 Train_Acc: 82.713 Val_Loss: 0.4784  BEST VAL Loss: 0.4784  Val_Acc: 77.416

Epoch 82: Validation loss decreased (0.478402 --> 0.478375).  Saving model ...
	 Train_Loss: 0.4380 Train_Acc: 82.707 Val_Loss: 0.4784  BEST VAL Loss: 0.4784  Val_Acc: 77.534

Epoch 83: Validation loss decreased (0.478375 --> 0.478341).  Saving model ...
	 Train_Loss: 0.4373 Train_Acc: 82.937 Val_Loss: 0.4783  BEST VAL Loss: 0.4783  Val_Acc: 77.416

Epoch 84: Validation loss decreased (0.478341 --> 0.478301).  Saving model ...
	 Train_Loss: 0.4366 Train_Acc: 82.851 Val_Loss: 0.4783  BEST VAL Loss: 0.4783  Val_Acc: 77.368

Epoch 85: Validation loss decreased (0.478301 --> 0.478249).  Saving model ...
	 Train_Loss: 0.4358 Train_Acc: 82.949 Val_Loss: 0.4782  BEST VAL Loss: 0.4782  Val_Acc: 77.156

Epoch 86: Validation loss decreased (0.478249 --> 0.478187).  Saving model ...
	 Train_Loss: 0.4351 Train_Acc: 83.147 Val_Loss: 0.4782  BEST VAL Loss: 0.4782  Val_Acc: 77.439

Epoch 87: Validation loss decreased (0.478187 --> 0.478149).  Saving model ...
	 Train_Loss: 0.4344 Train_Acc: 82.978 Val_Loss: 0.4781  BEST VAL Loss: 0.4781  Val_Acc: 77.274

Epoch 88: Validation loss decreased (0.478149 --> 0.478115).  Saving model ...
	 Train_Loss: 0.4338 Train_Acc: 82.881 Val_Loss: 0.4781  BEST VAL Loss: 0.4781  Val_Acc: 77.534

Epoch 89: Validation loss decreased (0.478115 --> 0.478089).  Saving model ...
	 Train_Loss: 0.4331 Train_Acc: 82.914 Val_Loss: 0.4781  BEST VAL Loss: 0.4781  Val_Acc: 77.557

Epoch 90: Validation loss decreased (0.478089 --> 0.478079).  Saving model ...
	 Train_Loss: 0.4324 Train_Acc: 83.091 Val_Loss: 0.4781  BEST VAL Loss: 0.4781  Val_Acc: 77.179

Epoch 91: Validation loss decreased (0.478079 --> 0.478046).  Saving model ...
	 Train_Loss: 0.4318 Train_Acc: 83.038 Val_Loss: 0.4780  BEST VAL Loss: 0.4780  Val_Acc: 77.534

Epoch 92: Validation loss decreased (0.478046 --> 0.478045).  Saving model ...
	 Train_Loss: 0.4311 Train_Acc: 83.026 Val_Loss: 0.4780  BEST VAL Loss: 0.4780  Val_Acc: 77.557

Epoch 93: Validation loss decreased (0.478045 --> 0.478042).  Saving model ...
	 Train_Loss: 0.4304 Train_Acc: 83.212 Val_Loss: 0.4780  BEST VAL Loss: 0.4780  Val_Acc: 77.605

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.4298 Train_Acc: 83.185 Val_Loss: 0.4780  BEST VAL Loss: 0.4780  Val_Acc: 77.699

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.4292 Train_Acc: 83.156 Val_Loss: 0.4780  BEST VAL Loss: 0.4780  Val_Acc: 77.557

Epoch 96: Validation loss did not decrease
	 Train_Loss: 0.4286 Train_Acc: 83.265 Val_Loss: 0.4781  BEST VAL Loss: 0.4780  Val_Acc: 77.628

Epoch 97: Validation loss did not decrease
	 Train_Loss: 0.4279 Train_Acc: 83.637 Val_Loss: 0.4781  BEST VAL Loss: 0.4780  Val_Acc: 77.227

Epoch 98: Validation loss did not decrease
	 Train_Loss: 0.4273 Train_Acc: 83.312 Val_Loss: 0.4782  BEST VAL Loss: 0.4780  Val_Acc: 77.038

Epoch 99: Validation loss did not decrease
	 Train_Loss: 0.4267 Train_Acc: 83.489 Val_Loss: 0.4782  BEST VAL Loss: 0.4780  Val_Acc: 77.227

DMSO_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.86      0.96      0.91     24644
           1       0.84      0.59      0.69      9219

    accuracy                           0.86     33863
   macro avg       0.85      0.77      0.80     33863
weighted avg       0.86      0.86      0.85     33863

DMSO_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.81      0.91      0.86      3081
           1       0.63      0.43      0.51      1152

    accuracy                           0.78      4233
   macro avg       0.72      0.67      0.68      4233
weighted avg       0.76      0.78      0.76      4233

DMSO_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.80      0.90      0.84      3081
           1       0.59      0.39      0.47      1152

    accuracy                           0.76      4233
   macro avg       0.69      0.64      0.66      4233
weighted avg       0.74      0.76      0.74      4233

              precision    recall  f1-score   support

           0       0.80      0.90      0.84      3081
           1       0.59      0.39      0.47      1152

    accuracy                           0.76      4233
   macro avg       0.69      0.64      0.66      4233
weighted avg       0.74      0.76      0.74      4233

DMSO_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.54      0.87      0.67      4837
           1       0.56      0.18      0.28      4336

    accuracy                           0.55      9173
   macro avg       0.55      0.53      0.47      9173
weighted avg       0.55      0.55      0.48      9173

              precision    recall  f1-score   support

           0       0.54      0.87      0.67      4837
           1       0.56      0.18      0.28      4336

    accuracy                           0.55      9173
   macro avg       0.55      0.53      0.47      9173
weighted avg       0.55      0.55      0.48      9173

completed
