[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ff382aca'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '42895645'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ef22dc36'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '5e06c538'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 treatment_name: LPS_10.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
TREATMENT_NAME: LPS_10.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (33028, 1276)
Number of total missing values across all columns: 33620
Data Subset Is Off
Wells held out for testing: ['E20' 'K16']
Wells to use for training, validation, and testing ['E16' 'E17' 'E21' 'K17' 'K20' 'K21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.585657).  Saving model ...
	 Train_Loss: 0.6507 Train_Acc: 60.772 Val_Loss: 0.5857  BEST VAL Loss: 0.5857  Val_Acc: 70.548

Epoch 1: Validation loss decreased (0.585657 --> 0.541719).  Saving model ...
	 Train_Loss: 0.6033 Train_Acc: 71.026 Val_Loss: 0.5417  BEST VAL Loss: 0.5417  Val_Acc: 76.795

Epoch 2: Validation loss decreased (0.541719 --> 0.504257).  Saving model ...
	 Train_Loss: 0.5636 Train_Acc: 77.346 Val_Loss: 0.5043  BEST VAL Loss: 0.5043  Val_Acc: 81.704

Epoch 3: Validation loss decreased (0.504257 --> 0.474284).  Saving model ...
	 Train_Loss: 0.5308 Train_Acc: 81.413 Val_Loss: 0.4743  BEST VAL Loss: 0.4743  Val_Acc: 84.219

Epoch 4: Validation loss decreased (0.474284 --> 0.449203).  Saving model ...
	 Train_Loss: 0.5029 Train_Acc: 83.660 Val_Loss: 0.4492  BEST VAL Loss: 0.4492  Val_Acc: 86.247

Epoch 5: Validation loss decreased (0.449203 --> 0.426927).  Saving model ...
	 Train_Loss: 0.4793 Train_Acc: 85.211 Val_Loss: 0.4269  BEST VAL Loss: 0.4269  Val_Acc: 87.870

Epoch 6: Validation loss decreased (0.426927 --> 0.407892).  Saving model ...
	 Train_Loss: 0.4585 Train_Acc: 86.479 Val_Loss: 0.4079  BEST VAL Loss: 0.4079  Val_Acc: 88.722

Epoch 7: Validation loss decreased (0.407892 --> 0.390491).  Saving model ...
	 Train_Loss: 0.4402 Train_Acc: 87.377 Val_Loss: 0.3905  BEST VAL Loss: 0.3905  Val_Acc: 90.020

Epoch 8: Validation loss decreased (0.390491 --> 0.375283).  Saving model ...
	 Train_Loss: 0.4235 Train_Acc: 88.498 Val_Loss: 0.3753  BEST VAL Loss: 0.3753  Val_Acc: 90.426

Epoch 9: Validation loss decreased (0.375283 --> 0.362036).  Saving model ...
	 Train_Loss: 0.4087 Train_Acc: 89.061 Val_Loss: 0.3620  BEST VAL Loss: 0.3620  Val_Acc: 91.400

Epoch 10: Validation loss decreased (0.362036 --> 0.350307).  Saving model ...
	 Train_Loss: 0.3953 Train_Acc: 89.573 Val_Loss: 0.3503  BEST VAL Loss: 0.3503  Val_Acc: 92.008

Epoch 11: Validation loss decreased (0.350307 --> 0.339258).  Saving model ...
	 Train_Loss: 0.3829 Train_Acc: 90.329 Val_Loss: 0.3393  BEST VAL Loss: 0.3393  Val_Acc: 92.414

Epoch 12: Validation loss decreased (0.339258 --> 0.329030).  Saving model ...
	 Train_Loss: 0.3716 Train_Acc: 90.663 Val_Loss: 0.3290  BEST VAL Loss: 0.3290  Val_Acc: 92.657

Epoch 13: Validation loss decreased (0.329030 --> 0.319795).  Saving model ...
	 Train_Loss: 0.3611 Train_Acc: 91.394 Val_Loss: 0.3198  BEST VAL Loss: 0.3198  Val_Acc: 93.550

Epoch 14: Validation loss decreased (0.319795 --> 0.311244).  Saving model ...
	 Train_Loss: 0.3513 Train_Acc: 91.789 Val_Loss: 0.3112  BEST VAL Loss: 0.3112  Val_Acc: 93.306

Epoch 15: Validation loss decreased (0.311244 --> 0.303326).  Saving model ...
	 Train_Loss: 0.3423 Train_Acc: 92.109 Val_Loss: 0.3033  BEST VAL Loss: 0.3033  Val_Acc: 93.915

Epoch 16: Validation loss decreased (0.303326 --> 0.296278).  Saving model ...
	 Train_Loss: 0.3338 Train_Acc: 92.575 Val_Loss: 0.2963  BEST VAL Loss: 0.2963  Val_Acc: 93.996

Epoch 17: Validation loss decreased (0.296278 --> 0.289668).  Saving model ...
	 Train_Loss: 0.3258 Train_Acc: 92.631 Val_Loss: 0.2897  BEST VAL Loss: 0.2897  Val_Acc: 94.199

Epoch 18: Validation loss decreased (0.289668 --> 0.283345).  Saving model ...
	 Train_Loss: 0.3185 Train_Acc: 92.991 Val_Loss: 0.2833  BEST VAL Loss: 0.2833  Val_Acc: 94.442

Epoch 19: Validation loss decreased (0.283345 --> 0.277504).  Saving model ...
	 Train_Loss: 0.3115 Train_Acc: 93.295 Val_Loss: 0.2775  BEST VAL Loss: 0.2775  Val_Acc: 94.442

Epoch 20: Validation loss decreased (0.277504 --> 0.271756).  Saving model ...
	 Train_Loss: 0.3050 Train_Acc: 93.514 Val_Loss: 0.2718  BEST VAL Loss: 0.2718  Val_Acc: 94.970

Epoch 21: Validation loss decreased (0.271756 --> 0.266661).  Saving model ...
	 Train_Loss: 0.2988 Train_Acc: 93.656 Val_Loss: 0.2667  BEST VAL Loss: 0.2667  Val_Acc: 94.767

Epoch 22: Validation loss decreased (0.266661 --> 0.261771).  Saving model ...
	 Train_Loss: 0.2931 Train_Acc: 93.706 Val_Loss: 0.2618  BEST VAL Loss: 0.2618  Val_Acc: 94.888

Epoch 23: Validation loss decreased (0.261771 --> 0.257036).  Saving model ...
	 Train_Loss: 0.2877 Train_Acc: 94.092 Val_Loss: 0.2570  BEST VAL Loss: 0.2570  Val_Acc: 95.051

Epoch 24: Validation loss decreased (0.257036 --> 0.252610).  Saving model ...
	 Train_Loss: 0.2825 Train_Acc: 94.188 Val_Loss: 0.2526  BEST VAL Loss: 0.2526  Val_Acc: 94.888

Epoch 25: Validation loss decreased (0.252610 --> 0.248521).  Saving model ...
	 Train_Loss: 0.2775 Train_Acc: 94.528 Val_Loss: 0.2485  BEST VAL Loss: 0.2485  Val_Acc: 94.888

Epoch 26: Validation loss decreased (0.248521 --> 0.244597).  Saving model ...
	 Train_Loss: 0.2726 Train_Acc: 94.736 Val_Loss: 0.2446  BEST VAL Loss: 0.2446  Val_Acc: 94.929

Epoch 27: Validation loss decreased (0.244597 --> 0.241021).  Saving model ...
	 Train_Loss: 0.2681 Train_Acc: 94.736 Val_Loss: 0.2410  BEST VAL Loss: 0.2410  Val_Acc: 95.294

Epoch 28: Validation loss decreased (0.241021 --> 0.237710).  Saving model ...
	 Train_Loss: 0.2637 Train_Acc: 94.761 Val_Loss: 0.2377  BEST VAL Loss: 0.2377  Val_Acc: 95.213

Epoch 29: Validation loss decreased (0.237710 --> 0.234472).  Saving model ...
	 Train_Loss: 0.2596 Train_Acc: 95.015 Val_Loss: 0.2345  BEST VAL Loss: 0.2345  Val_Acc: 95.578

Epoch 30: Validation loss decreased (0.234472 --> 0.231287).  Saving model ...
	 Train_Loss: 0.2556 Train_Acc: 94.994 Val_Loss: 0.2313  BEST VAL Loss: 0.2313  Val_Acc: 95.416

Epoch 31: Validation loss decreased (0.231287 --> 0.228269).  Saving model ...
	 Train_Loss: 0.2517 Train_Acc: 95.390 Val_Loss: 0.2283  BEST VAL Loss: 0.2283  Val_Acc: 95.578

Epoch 32: Validation loss decreased (0.228269 --> 0.225204).  Saving model ...
	 Train_Loss: 0.2481 Train_Acc: 95.268 Val_Loss: 0.2252  BEST VAL Loss: 0.2252  Val_Acc: 95.619

Epoch 33: Validation loss decreased (0.225204 --> 0.222483).  Saving model ...
	 Train_Loss: 0.2446 Train_Acc: 95.329 Val_Loss: 0.2225  BEST VAL Loss: 0.2225  Val_Acc: 95.659

Epoch 34: Validation loss decreased (0.222483 --> 0.219875).  Saving model ...
	 Train_Loss: 0.2412 Train_Acc: 95.522 Val_Loss: 0.2199  BEST VAL Loss: 0.2199  Val_Acc: 95.781

Epoch 35: Validation loss decreased (0.219875 --> 0.217339).  Saving model ...
	 Train_Loss: 0.2379 Train_Acc: 95.471 Val_Loss: 0.2173  BEST VAL Loss: 0.2173  Val_Acc: 95.700

Epoch 36: Validation loss decreased (0.217339 --> 0.214885).  Saving model ...
	 Train_Loss: 0.2348 Train_Acc: 95.862 Val_Loss: 0.2149  BEST VAL Loss: 0.2149  Val_Acc: 95.619

Epoch 37: Validation loss decreased (0.214885 --> 0.212717).  Saving model ...
	 Train_Loss: 0.2318 Train_Acc: 95.669 Val_Loss: 0.2127  BEST VAL Loss: 0.2127  Val_Acc: 95.700

Epoch 38: Validation loss decreased (0.212717 --> 0.210428).  Saving model ...
	 Train_Loss: 0.2288 Train_Acc: 96.059 Val_Loss: 0.2104  BEST VAL Loss: 0.2104  Val_Acc: 95.700

Epoch 39: Validation loss decreased (0.210428 --> 0.208352).  Saving model ...
	 Train_Loss: 0.2260 Train_Acc: 95.816 Val_Loss: 0.2084  BEST VAL Loss: 0.2084  Val_Acc: 95.740

Epoch 40: Validation loss decreased (0.208352 --> 0.206369).  Saving model ...
	 Train_Loss: 0.2232 Train_Acc: 96.039 Val_Loss: 0.2064  BEST VAL Loss: 0.2064  Val_Acc: 95.619

Epoch 41: Validation loss decreased (0.206369 --> 0.204266).  Saving model ...
	 Train_Loss: 0.2205 Train_Acc: 96.252 Val_Loss: 0.2043  BEST VAL Loss: 0.2043  Val_Acc: 95.984

Epoch 42: Validation loss decreased (0.204266 --> 0.202401).  Saving model ...
	 Train_Loss: 0.2179 Train_Acc: 96.181 Val_Loss: 0.2024  BEST VAL Loss: 0.2024  Val_Acc: 95.984

Epoch 43: Validation loss decreased (0.202401 --> 0.200523).  Saving model ...
	 Train_Loss: 0.2153 Train_Acc: 96.237 Val_Loss: 0.2005  BEST VAL Loss: 0.2005  Val_Acc: 96.065

Epoch 44: Validation loss decreased (0.200523 --> 0.198722).  Saving model ...
	 Train_Loss: 0.2129 Train_Acc: 96.278 Val_Loss: 0.1987  BEST VAL Loss: 0.1987  Val_Acc: 95.822

Epoch 45: Validation loss decreased (0.198722 --> 0.196895).  Saving model ...
	 Train_Loss: 0.2106 Train_Acc: 96.298 Val_Loss: 0.1969  BEST VAL Loss: 0.1969  Val_Acc: 95.984

Epoch 46: Validation loss decreased (0.196895 --> 0.195191).  Saving model ...
	 Train_Loss: 0.2084 Train_Acc: 96.267 Val_Loss: 0.1952  BEST VAL Loss: 0.1952  Val_Acc: 95.862

Epoch 47: Validation loss decreased (0.195191 --> 0.193683).  Saving model ...
	 Train_Loss: 0.2062 Train_Acc: 96.384 Val_Loss: 0.1937  BEST VAL Loss: 0.1937  Val_Acc: 95.984

Epoch 48: Validation loss decreased (0.193683 --> 0.192186).  Saving model ...
	 Train_Loss: 0.2040 Train_Acc: 96.440 Val_Loss: 0.1922  BEST VAL Loss: 0.1922  Val_Acc: 96.146

Epoch 49: Validation loss decreased (0.192186 --> 0.190626).  Saving model ...
	 Train_Loss: 0.2019 Train_Acc: 96.577 Val_Loss: 0.1906  BEST VAL Loss: 0.1906  Val_Acc: 96.065

Epoch 50: Validation loss decreased (0.190626 --> 0.189104).  Saving model ...
	 Train_Loss: 0.1999 Train_Acc: 96.734 Val_Loss: 0.1891  BEST VAL Loss: 0.1891  Val_Acc: 96.065

Epoch 51: Validation loss decreased (0.189104 --> 0.187572).  Saving model ...
	 Train_Loss: 0.1979 Train_Acc: 96.627 Val_Loss: 0.1876  BEST VAL Loss: 0.1876  Val_Acc: 95.862

Epoch 52: Validation loss decreased (0.187572 --> 0.186138).  Saving model ...
	 Train_Loss: 0.1959 Train_Acc: 96.653 Val_Loss: 0.1861  BEST VAL Loss: 0.1861  Val_Acc: 96.065

Epoch 53: Validation loss decreased (0.186138 --> 0.184932).  Saving model ...
	 Train_Loss: 0.1941 Train_Acc: 96.835 Val_Loss: 0.1849  BEST VAL Loss: 0.1849  Val_Acc: 96.105

Epoch 54: Validation loss decreased (0.184932 --> 0.183634).  Saving model ...
	 Train_Loss: 0.1922 Train_Acc: 96.846 Val_Loss: 0.1836  BEST VAL Loss: 0.1836  Val_Acc: 96.105

Epoch 55: Validation loss decreased (0.183634 --> 0.182462).  Saving model ...
	 Train_Loss: 0.1904 Train_Acc: 96.800 Val_Loss: 0.1825  BEST VAL Loss: 0.1825  Val_Acc: 96.105

Epoch 56: Validation loss decreased (0.182462 --> 0.181241).  Saving model ...
	 Train_Loss: 0.1887 Train_Acc: 96.866 Val_Loss: 0.1812  BEST VAL Loss: 0.1812  Val_Acc: 96.187

Epoch 57: Validation loss decreased (0.181241 --> 0.180053).  Saving model ...
	 Train_Loss: 0.1870 Train_Acc: 96.835 Val_Loss: 0.1801  BEST VAL Loss: 0.1801  Val_Acc: 95.984

Epoch 58: Validation loss decreased (0.180053 --> 0.178924).  Saving model ...
	 Train_Loss: 0.1854 Train_Acc: 96.795 Val_Loss: 0.1789  BEST VAL Loss: 0.1789  Val_Acc: 96.105

Epoch 59: Validation loss decreased (0.178924 --> 0.177816).  Saving model ...
	 Train_Loss: 0.1837 Train_Acc: 97.109 Val_Loss: 0.1778  BEST VAL Loss: 0.1778  Val_Acc: 96.146

Epoch 60: Validation loss decreased (0.177816 --> 0.176695).  Saving model ...
	 Train_Loss: 0.1821 Train_Acc: 97.028 Val_Loss: 0.1767  BEST VAL Loss: 0.1767  Val_Acc: 96.227

Epoch 61: Validation loss decreased (0.176695 --> 0.175635).  Saving model ...
	 Train_Loss: 0.1806 Train_Acc: 97.038 Val_Loss: 0.1756  BEST VAL Loss: 0.1756  Val_Acc: 96.146

Epoch 62: Validation loss decreased (0.175635 --> 0.174580).  Saving model ...
	 Train_Loss: 0.1791 Train_Acc: 97.231 Val_Loss: 0.1746  BEST VAL Loss: 0.1746  Val_Acc: 95.984

Epoch 63: Validation loss decreased (0.174580 --> 0.173566).  Saving model ...
	 Train_Loss: 0.1776 Train_Acc: 97.089 Val_Loss: 0.1736  BEST VAL Loss: 0.1736  Val_Acc: 96.105

Epoch 64: Validation loss decreased (0.173566 --> 0.172611).  Saving model ...
	 Train_Loss: 0.1761 Train_Acc: 97.190 Val_Loss: 0.1726  BEST VAL Loss: 0.1726  Val_Acc: 96.105

Epoch 65: Validation loss decreased (0.172611 --> 0.171658).  Saving model ...
	 Train_Loss: 0.1747 Train_Acc: 97.195 Val_Loss: 0.1717  BEST VAL Loss: 0.1717  Val_Acc: 95.984

Epoch 66: Validation loss decreased (0.171658 --> 0.170621).  Saving model ...
	 Train_Loss: 0.1733 Train_Acc: 97.307 Val_Loss: 0.1706  BEST VAL Loss: 0.1706  Val_Acc: 96.389

Epoch 67: Validation loss decreased (0.170621 --> 0.169690).  Saving model ...
	 Train_Loss: 0.1719 Train_Acc: 97.302 Val_Loss: 0.1697  BEST VAL Loss: 0.1697  Val_Acc: 96.268

Epoch 68: Validation loss decreased (0.169690 --> 0.168920).  Saving model ...
	 Train_Loss: 0.1706 Train_Acc: 97.135 Val_Loss: 0.1689  BEST VAL Loss: 0.1689  Val_Acc: 96.227

Epoch 69: Validation loss decreased (0.168920 --> 0.168110).  Saving model ...
	 Train_Loss: 0.1693 Train_Acc: 97.414 Val_Loss: 0.1681  BEST VAL Loss: 0.1681  Val_Acc: 96.349

Epoch 70: Validation loss decreased (0.168110 --> 0.167286).  Saving model ...
	 Train_Loss: 0.1679 Train_Acc: 97.566 Val_Loss: 0.1673  BEST VAL Loss: 0.1673  Val_Acc: 96.065

Epoch 71: Validation loss decreased (0.167286 --> 0.166339).  Saving model ...
	 Train_Loss: 0.1667 Train_Acc: 97.515 Val_Loss: 0.1663  BEST VAL Loss: 0.1663  Val_Acc: 96.227

Epoch 72: Validation loss decreased (0.166339 --> 0.165478).  Saving model ...
	 Train_Loss: 0.1654 Train_Acc: 97.332 Val_Loss: 0.1655  BEST VAL Loss: 0.1655  Val_Acc: 96.268

Epoch 73: Validation loss decreased (0.165478 --> 0.164723).  Saving model ...
	 Train_Loss: 0.1642 Train_Acc: 97.419 Val_Loss: 0.1647  BEST VAL Loss: 0.1647  Val_Acc: 95.822

Epoch 74: Validation loss decreased (0.164723 --> 0.163984).  Saving model ...
	 Train_Loss: 0.1630 Train_Acc: 97.373 Val_Loss: 0.1640  BEST VAL Loss: 0.1640  Val_Acc: 96.024

Epoch 75: Validation loss decreased (0.163984 --> 0.163281).  Saving model ...
	 Train_Loss: 0.1619 Train_Acc: 97.429 Val_Loss: 0.1633  BEST VAL Loss: 0.1633  Val_Acc: 96.227

Epoch 76: Validation loss decreased (0.163281 --> 0.162515).  Saving model ...
	 Train_Loss: 0.1607 Train_Acc: 97.616 Val_Loss: 0.1625  BEST VAL Loss: 0.1625  Val_Acc: 95.943

Epoch 77: Validation loss decreased (0.162515 --> 0.161877).  Saving model ...
	 Train_Loss: 0.1596 Train_Acc: 97.637 Val_Loss: 0.1619  BEST VAL Loss: 0.1619  Val_Acc: 96.389

Epoch 78: Validation loss decreased (0.161877 --> 0.161147).  Saving model ...
	 Train_Loss: 0.1585 Train_Acc: 97.490 Val_Loss: 0.1611  BEST VAL Loss: 0.1611  Val_Acc: 96.187

Epoch 79: Validation loss decreased (0.161147 --> 0.160391).  Saving model ...
	 Train_Loss: 0.1574 Train_Acc: 97.403 Val_Loss: 0.1604  BEST VAL Loss: 0.1604  Val_Acc: 96.187

Epoch 80: Validation loss decreased (0.160391 --> 0.159758).  Saving model ...
	 Train_Loss: 0.1563 Train_Acc: 97.708 Val_Loss: 0.1598  BEST VAL Loss: 0.1598  Val_Acc: 96.187

Epoch 81: Validation loss decreased (0.159758 --> 0.159059).  Saving model ...
	 Train_Loss: 0.1553 Train_Acc: 97.540 Val_Loss: 0.1591  BEST VAL Loss: 0.1591  Val_Acc: 96.308

Epoch 82: Validation loss decreased (0.159059 --> 0.158406).  Saving model ...
	 Train_Loss: 0.1543 Train_Acc: 97.601 Val_Loss: 0.1584  BEST VAL Loss: 0.1584  Val_Acc: 96.268

Epoch 83: Validation loss decreased (0.158406 --> 0.157731).  Saving model ...
	 Train_Loss: 0.1533 Train_Acc: 97.753 Val_Loss: 0.1577  BEST VAL Loss: 0.1577  Val_Acc: 96.349

Epoch 84: Validation loss decreased (0.157731 --> 0.157128).  Saving model ...
	 Train_Loss: 0.1522 Train_Acc: 97.738 Val_Loss: 0.1571  BEST VAL Loss: 0.1571  Val_Acc: 96.024

Epoch 85: Validation loss decreased (0.157128 --> 0.156620).  Saving model ...
	 Train_Loss: 0.1513 Train_Acc: 97.824 Val_Loss: 0.1566  BEST VAL Loss: 0.1566  Val_Acc: 96.268

Epoch 86: Validation loss decreased (0.156620 --> 0.155994).  Saving model ...
	 Train_Loss: 0.1503 Train_Acc: 97.627 Val_Loss: 0.1560  BEST VAL Loss: 0.1560  Val_Acc: 96.105

Epoch 87: Validation loss decreased (0.155994 --> 0.155472).  Saving model ...
	 Train_Loss: 0.1494 Train_Acc: 97.571 Val_Loss: 0.1555  BEST VAL Loss: 0.1555  Val_Acc: 96.268

Epoch 88: Validation loss decreased (0.155472 --> 0.154865).  Saving model ...
	 Train_Loss: 0.1484 Train_Acc: 97.824 Val_Loss: 0.1549  BEST VAL Loss: 0.1549  Val_Acc: 96.146

Epoch 89: Validation loss decreased (0.154865 --> 0.154348).  Saving model ...
	 Train_Loss: 0.1475 Train_Acc: 97.976 Val_Loss: 0.1543  BEST VAL Loss: 0.1543  Val_Acc: 96.105

Epoch 90: Validation loss decreased (0.154348 --> 0.153856).  Saving model ...
	 Train_Loss: 0.1466 Train_Acc: 97.799 Val_Loss: 0.1539  BEST VAL Loss: 0.1539  Val_Acc: 96.430

Epoch 91: Validation loss decreased (0.153856 --> 0.153411).  Saving model ...
	 Train_Loss: 0.1457 Train_Acc: 97.733 Val_Loss: 0.1534  BEST VAL Loss: 0.1534  Val_Acc: 96.430

Epoch 92: Validation loss decreased (0.153411 --> 0.152894).  Saving model ...
	 Train_Loss: 0.1448 Train_Acc: 97.885 Val_Loss: 0.1529  BEST VAL Loss: 0.1529  Val_Acc: 96.471

Epoch 93: Validation loss decreased (0.152894 --> 0.152364).  Saving model ...
	 Train_Loss: 0.1439 Train_Acc: 97.895 Val_Loss: 0.1524  BEST VAL Loss: 0.1524  Val_Acc: 96.308

Epoch 94: Validation loss decreased (0.152364 --> 0.151842).  Saving model ...
	 Train_Loss: 0.1431 Train_Acc: 97.895 Val_Loss: 0.1518  BEST VAL Loss: 0.1518  Val_Acc: 96.146

Epoch 95: Validation loss decreased (0.151842 --> 0.151390).  Saving model ...
	 Train_Loss: 0.1422 Train_Acc: 97.819 Val_Loss: 0.1514  BEST VAL Loss: 0.1514  Val_Acc: 96.389

Epoch 96: Validation loss decreased (0.151390 --> 0.150842).  Saving model ...
	 Train_Loss: 0.1414 Train_Acc: 98.118 Val_Loss: 0.1508  BEST VAL Loss: 0.1508  Val_Acc: 96.389

Epoch 97: Validation loss decreased (0.150842 --> 0.150440).  Saving model ...
	 Train_Loss: 0.1406 Train_Acc: 97.890 Val_Loss: 0.1504  BEST VAL Loss: 0.1504  Val_Acc: 96.430

Epoch 98: Validation loss decreased (0.150440 --> 0.149983).  Saving model ...
	 Train_Loss: 0.1398 Train_Acc: 97.911 Val_Loss: 0.1500  BEST VAL Loss: 0.1500  Val_Acc: 96.349

Epoch 99: Validation loss decreased (0.149983 --> 0.149499).  Saving model ...
	 Train_Loss: 0.1390 Train_Acc: 97.946 Val_Loss: 0.1495  BEST VAL Loss: 0.1495  Val_Acc: 96.430

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.52      0.51     10114
           1       0.49      0.49      0.49      9604

    accuracy                           0.50     19718
   macro avg       0.50      0.50      0.50     19718
weighted avg       0.50      0.50      0.50     19718

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.52      0.52      1264
           1       0.49      0.49      0.49      1201

    accuracy                           0.50      2465
   macro avg       0.50      0.50      0.50      2465
weighted avg       0.50      0.50      0.50      2465

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.53      0.53      1264
           1       0.50      0.49      0.50      1201

    accuracy                           0.51      2465
   macro avg       0.51      0.51      0.51      2465
weighted avg       0.51      0.51      0.51      2465

              precision    recall  f1-score   support

           0       0.53      0.53      0.53      1264
           1       0.50      0.49      0.50      1201

    accuracy                           0.51      2465
   macro avg       0.51      0.51      0.51      2465
weighted avg       0.51      0.51      0.51      2465

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.49      0.50      4168
           1       0.50      0.50      0.50      4212

    accuracy                           0.50      8380
   macro avg       0.50      0.50      0.50      8380
weighted avg       0.50      0.50      0.50      8380

              precision    recall  f1-score   support

           0       0.50      0.49      0.50      4168
           1       0.50      0.50      0.50      4212

    accuracy                           0.50      8380
   macro avg       0.50      0.50      0.50      8380
weighted avg       0.50      0.50      0.50      8380

completed
