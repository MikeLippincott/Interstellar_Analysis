[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd2e8f73a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'b0b0140e'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '32e100d3'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '2348c675'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Thapsigargin_1.000_DMSO_0.025 treatment_name: DMSO_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Thapsigargin_1.000_DMSO_0.025
TREATMENT_NAME: DMSO_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'Thapsigargin_1.000_DMSO_0.025']
The dimensions of the data are: (363586, 1270)
Number of total missing values across all columns: 727172
Data Subset Is Off
Wells held out for testing: ['J06' 'K07']
Wells to use for training, validation, and testing ['B06' 'C06' 'B07' 'C07' 'D06' 'D07' 'I06' 'I07' 'K06' 'J07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.567931).  Saving model ...
	 Train_Loss: 0.6291 Train_Acc: 62.917 Val_Loss: 0.5679  BEST VAL Loss: 0.5679  Val_Acc: 71.051

Epoch 1: Validation loss decreased (0.567931 --> 0.550873).  Saving model ...
	 Train_Loss: 0.6067 Train_Acc: 66.863 Val_Loss: 0.5509  BEST VAL Loss: 0.5509  Val_Acc: 74.693

Epoch 2: Validation loss decreased (0.550873 --> 0.537087).  Saving model ...
	 Train_Loss: 0.5922 Train_Acc: 68.348 Val_Loss: 0.5371  BEST VAL Loss: 0.5371  Val_Acc: 75.409

Epoch 3: Validation loss decreased (0.537087 --> 0.526613).  Saving model ...
	 Train_Loss: 0.5833 Train_Acc: 68.698 Val_Loss: 0.5266  BEST VAL Loss: 0.5266  Val_Acc: 76.173

Epoch 4: Validation loss decreased (0.526613 --> 0.519955).  Saving model ...
	 Train_Loss: 0.5761 Train_Acc: 69.072 Val_Loss: 0.5200  BEST VAL Loss: 0.5200  Val_Acc: 77.152

Epoch 5: Validation loss decreased (0.519955 --> 0.514502).  Saving model ...
	 Train_Loss: 0.5705 Train_Acc: 69.453 Val_Loss: 0.5145  BEST VAL Loss: 0.5145  Val_Acc: 76.250

Epoch 6: Validation loss decreased (0.514502 --> 0.510114).  Saving model ...
	 Train_Loss: 0.5661 Train_Acc: 69.429 Val_Loss: 0.5101  BEST VAL Loss: 0.5101  Val_Acc: 75.961

Epoch 7: Validation loss decreased (0.510114 --> 0.506187).  Saving model ...
	 Train_Loss: 0.5623 Train_Acc: 69.816 Val_Loss: 0.5062  BEST VAL Loss: 0.5062  Val_Acc: 77.431

Epoch 8: Validation loss decreased (0.506187 --> 0.502403).  Saving model ...
	 Train_Loss: 0.5589 Train_Acc: 70.042 Val_Loss: 0.5024  BEST VAL Loss: 0.5024  Val_Acc: 77.367

Epoch 9: Validation loss decreased (0.502403 --> 0.499538).  Saving model ...
	 Train_Loss: 0.5560 Train_Acc: 70.032 Val_Loss: 0.4995  BEST VAL Loss: 0.4995  Val_Acc: 77.575

Epoch 10: Validation loss decreased (0.499538 --> 0.496811).  Saving model ...
	 Train_Loss: 0.5537 Train_Acc: 70.027 Val_Loss: 0.4968  BEST VAL Loss: 0.4968  Val_Acc: 77.326

Epoch 11: Validation loss decreased (0.496811 --> 0.494286).  Saving model ...
	 Train_Loss: 0.5515 Train_Acc: 70.150 Val_Loss: 0.4943  BEST VAL Loss: 0.4943  Val_Acc: 76.691

Epoch 12: Validation loss decreased (0.494286 --> 0.493361).  Saving model ...
	 Train_Loss: 0.5496 Train_Acc: 70.392 Val_Loss: 0.4934  BEST VAL Loss: 0.4934  Val_Acc: 76.866

Epoch 13: Validation loss decreased (0.493361 --> 0.491319).  Saving model ...
	 Train_Loss: 0.5478 Train_Acc: 70.446 Val_Loss: 0.4913  BEST VAL Loss: 0.4913  Val_Acc: 77.030

Epoch 14: Validation loss decreased (0.491319 --> 0.489523).  Saving model ...
	 Train_Loss: 0.5462 Train_Acc: 70.356 Val_Loss: 0.4895  BEST VAL Loss: 0.4895  Val_Acc: 78.063

Epoch 15: Validation loss decreased (0.489523 --> 0.487969).  Saving model ...
	 Train_Loss: 0.5448 Train_Acc: 70.388 Val_Loss: 0.4880  BEST VAL Loss: 0.4880  Val_Acc: 77.952

Epoch 16: Validation loss decreased (0.487969 --> 0.486195).  Saving model ...
	 Train_Loss: 0.5434 Train_Acc: 70.364 Val_Loss: 0.4862  BEST VAL Loss: 0.4862  Val_Acc: 78.399

Epoch 17: Validation loss decreased (0.486195 --> 0.485042).  Saving model ...
	 Train_Loss: 0.5421 Train_Acc: 70.678 Val_Loss: 0.4850  BEST VAL Loss: 0.4850  Val_Acc: 78.167

Epoch 18: Validation loss decreased (0.485042 --> 0.483917).  Saving model ...
	 Train_Loss: 0.5410 Train_Acc: 70.475 Val_Loss: 0.4839  BEST VAL Loss: 0.4839  Val_Acc: 78.110

Epoch 19: Validation loss decreased (0.483917 --> 0.482523).  Saving model ...
	 Train_Loss: 0.5399 Train_Acc: 70.606 Val_Loss: 0.4825  BEST VAL Loss: 0.4825  Val_Acc: 78.490

Epoch 20: Validation loss decreased (0.482523 --> 0.481428).  Saving model ...
	 Train_Loss: 0.5388 Train_Acc: 70.558 Val_Loss: 0.4814  BEST VAL Loss: 0.4814  Val_Acc: 78.655

Epoch 21: Validation loss decreased (0.481428 --> 0.480391).  Saving model ...
	 Train_Loss: 0.5378 Train_Acc: 70.724 Val_Loss: 0.4804  BEST VAL Loss: 0.4804  Val_Acc: 78.601

Epoch 22: Validation loss decreased (0.480391 --> 0.479083).  Saving model ...
	 Train_Loss: 0.5369 Train_Acc: 70.718 Val_Loss: 0.4791  BEST VAL Loss: 0.4791  Val_Acc: 78.931

Epoch 23: Validation loss decreased (0.479083 --> 0.477976).  Saving model ...
	 Train_Loss: 0.5361 Train_Acc: 70.669 Val_Loss: 0.4780  BEST VAL Loss: 0.4780  Val_Acc: 78.349

Epoch 24: Validation loss decreased (0.477976 --> 0.477159).  Saving model ...
	 Train_Loss: 0.5353 Train_Acc: 70.666 Val_Loss: 0.4772  BEST VAL Loss: 0.4772  Val_Acc: 78.591

Epoch 25: Validation loss decreased (0.477159 --> 0.476124).  Saving model ...
	 Train_Loss: 0.5344 Train_Acc: 70.894 Val_Loss: 0.4761  BEST VAL Loss: 0.4761  Val_Acc: 78.628

Epoch 26: Validation loss decreased (0.476124 --> 0.475449).  Saving model ...
	 Train_Loss: 0.5337 Train_Acc: 70.870 Val_Loss: 0.4754  BEST VAL Loss: 0.4754  Val_Acc: 78.470

Epoch 27: Validation loss decreased (0.475449 --> 0.474580).  Saving model ...
	 Train_Loss: 0.5329 Train_Acc: 70.983 Val_Loss: 0.4746  BEST VAL Loss: 0.4746  Val_Acc: 78.379

Epoch 28: Validation loss decreased (0.474580 --> 0.473625).  Saving model ...
	 Train_Loss: 0.5322 Train_Acc: 70.923 Val_Loss: 0.4736  BEST VAL Loss: 0.4736  Val_Acc: 78.372

Epoch 29: Validation loss decreased (0.473625 --> 0.472799).  Saving model ...
	 Train_Loss: 0.5316 Train_Acc: 70.943 Val_Loss: 0.4728  BEST VAL Loss: 0.4728  Val_Acc: 78.722

Epoch 30: Validation loss decreased (0.472799 --> 0.472106).  Saving model ...
	 Train_Loss: 0.5310 Train_Acc: 70.921 Val_Loss: 0.4721  BEST VAL Loss: 0.4721  Val_Acc: 78.877

Epoch 31: Validation loss decreased (0.472106 --> 0.471506).  Saving model ...
	 Train_Loss: 0.5304 Train_Acc: 70.857 Val_Loss: 0.4715  BEST VAL Loss: 0.4715  Val_Acc: 78.833

Epoch 32: Validation loss decreased (0.471506 --> 0.470700).  Saving model ...
	 Train_Loss: 0.5299 Train_Acc: 70.954 Val_Loss: 0.4707  BEST VAL Loss: 0.4707  Val_Acc: 78.702

Epoch 33: Validation loss decreased (0.470700 --> 0.469811).  Saving model ...
	 Train_Loss: 0.5293 Train_Acc: 71.033 Val_Loss: 0.4698  BEST VAL Loss: 0.4698  Val_Acc: 78.530

Epoch 34: Validation loss decreased (0.469811 --> 0.469224).  Saving model ...
	 Train_Loss: 0.5288 Train_Acc: 71.077 Val_Loss: 0.4692  BEST VAL Loss: 0.4692  Val_Acc: 78.473

Epoch 35: Validation loss decreased (0.469224 --> 0.468602).  Saving model ...
	 Train_Loss: 0.5283 Train_Acc: 70.930 Val_Loss: 0.4686  BEST VAL Loss: 0.4686  Val_Acc: 78.100

Epoch 36: Validation loss decreased (0.468602 --> 0.467993).  Saving model ...
	 Train_Loss: 0.5278 Train_Acc: 71.033 Val_Loss: 0.4680  BEST VAL Loss: 0.4680  Val_Acc: 78.947

Epoch 37: Validation loss decreased (0.467993 --> 0.467512).  Saving model ...
	 Train_Loss: 0.5273 Train_Acc: 71.146 Val_Loss: 0.4675  BEST VAL Loss: 0.4675  Val_Acc: 77.871

Epoch 38: Validation loss decreased (0.467512 --> 0.467034).  Saving model ...
	 Train_Loss: 0.5269 Train_Acc: 71.008 Val_Loss: 0.4670  BEST VAL Loss: 0.4670  Val_Acc: 78.164

Epoch 39: Validation loss decreased (0.467034 --> 0.466689).  Saving model ...
	 Train_Loss: 0.5265 Train_Acc: 71.216 Val_Loss: 0.4667  BEST VAL Loss: 0.4667  Val_Acc: 77.350

Epoch 40: Validation loss decreased (0.466689 --> 0.466253).  Saving model ...
	 Train_Loss: 0.5260 Train_Acc: 71.163 Val_Loss: 0.4663  BEST VAL Loss: 0.4663  Val_Acc: 78.806

Epoch 41: Validation loss decreased (0.466253 --> 0.465809).  Saving model ...
	 Train_Loss: 0.5256 Train_Acc: 71.301 Val_Loss: 0.4658  BEST VAL Loss: 0.4658  Val_Acc: 78.904

Epoch 42: Validation loss decreased (0.465809 --> 0.465331).  Saving model ...
	 Train_Loss: 0.5252 Train_Acc: 71.130 Val_Loss: 0.4653  BEST VAL Loss: 0.4653  Val_Acc: 78.951

Epoch 43: Validation loss decreased (0.465331 --> 0.465036).  Saving model ...
	 Train_Loss: 0.5248 Train_Acc: 71.025 Val_Loss: 0.4650  BEST VAL Loss: 0.4650  Val_Acc: 78.322

Epoch 44: Validation loss decreased (0.465036 --> 0.464598).  Saving model ...
	 Train_Loss: 0.5244 Train_Acc: 71.291 Val_Loss: 0.4646  BEST VAL Loss: 0.4646  Val_Acc: 79.304

Epoch 45: Validation loss decreased (0.464598 --> 0.464119).  Saving model ...
	 Train_Loss: 0.5241 Train_Acc: 71.166 Val_Loss: 0.4641  BEST VAL Loss: 0.4641  Val_Acc: 78.658

Epoch 46: Validation loss decreased (0.464119 --> 0.463683).  Saving model ...
	 Train_Loss: 0.5237 Train_Acc: 71.036 Val_Loss: 0.4637  BEST VAL Loss: 0.4637  Val_Acc: 79.210

Epoch 47: Validation loss decreased (0.463683 --> 0.463155).  Saving model ...
	 Train_Loss: 0.5234 Train_Acc: 71.395 Val_Loss: 0.4632  BEST VAL Loss: 0.4632  Val_Acc: 79.250

Epoch 48: Validation loss decreased (0.463155 --> 0.462775).  Saving model ...
	 Train_Loss: 0.5230 Train_Acc: 71.247 Val_Loss: 0.4628  BEST VAL Loss: 0.4628  Val_Acc: 79.566

Epoch 49: Validation loss decreased (0.462775 --> 0.462398).  Saving model ...
	 Train_Loss: 0.5227 Train_Acc: 71.267 Val_Loss: 0.4624  BEST VAL Loss: 0.4624  Val_Acc: 79.109

Epoch 50: Validation loss decreased (0.462398 --> 0.462023).  Saving model ...
	 Train_Loss: 0.5224 Train_Acc: 71.214 Val_Loss: 0.4620  BEST VAL Loss: 0.4620  Val_Acc: 78.631

Epoch 51: Validation loss decreased (0.462023 --> 0.461637).  Saving model ...
	 Train_Loss: 0.5221 Train_Acc: 71.336 Val_Loss: 0.4616  BEST VAL Loss: 0.4616  Val_Acc: 79.173

Epoch 52: Validation loss decreased (0.461637 --> 0.461229).  Saving model ...
	 Train_Loss: 0.5217 Train_Acc: 71.318 Val_Loss: 0.4612  BEST VAL Loss: 0.4612  Val_Acc: 78.709

Epoch 53: Validation loss decreased (0.461229 --> 0.460857).  Saving model ...
	 Train_Loss: 0.5215 Train_Acc: 71.292 Val_Loss: 0.4609  BEST VAL Loss: 0.4609  Val_Acc: 78.715

Epoch 54: Validation loss decreased (0.460857 --> 0.460764).  Saving model ...
	 Train_Loss: 0.5212 Train_Acc: 71.092 Val_Loss: 0.4608  BEST VAL Loss: 0.4608  Val_Acc: 78.658

Epoch 55: Validation loss decreased (0.460764 --> 0.460459).  Saving model ...
	 Train_Loss: 0.5209 Train_Acc: 71.323 Val_Loss: 0.4605  BEST VAL Loss: 0.4605  Val_Acc: 78.295

Epoch 56: Validation loss decreased (0.460459 --> 0.460114).  Saving model ...
	 Train_Loss: 0.5206 Train_Acc: 71.357 Val_Loss: 0.4601  BEST VAL Loss: 0.4601  Val_Acc: 79.304

Epoch 57: Validation loss decreased (0.460114 --> 0.459908).  Saving model ...
	 Train_Loss: 0.5204 Train_Acc: 71.143 Val_Loss: 0.4599  BEST VAL Loss: 0.4599  Val_Acc: 78.625

Epoch 58: Validation loss decreased (0.459908 --> 0.459575).  Saving model ...
	 Train_Loss: 0.5201 Train_Acc: 71.459 Val_Loss: 0.4596  BEST VAL Loss: 0.4596  Val_Acc: 79.015

Epoch 59: Validation loss decreased (0.459575 --> 0.459305).  Saving model ...
	 Train_Loss: 0.5198 Train_Acc: 71.341 Val_Loss: 0.4593  BEST VAL Loss: 0.4593  Val_Acc: 78.947

Epoch 60: Validation loss decreased (0.459305 --> 0.459096).  Saving model ...
	 Train_Loss: 0.5196 Train_Acc: 71.370 Val_Loss: 0.4591  BEST VAL Loss: 0.4591  Val_Acc: 78.830

Epoch 61: Validation loss decreased (0.459096 --> 0.458711).  Saving model ...
	 Train_Loss: 0.5193 Train_Acc: 71.267 Val_Loss: 0.4587  BEST VAL Loss: 0.4587  Val_Acc: 79.321

Epoch 62: Validation loss decreased (0.458711 --> 0.458489).  Saving model ...
	 Train_Loss: 0.5191 Train_Acc: 71.423 Val_Loss: 0.4585  BEST VAL Loss: 0.4585  Val_Acc: 79.136

Epoch 63: Validation loss decreased (0.458489 --> 0.458223).  Saving model ...
	 Train_Loss: 0.5188 Train_Acc: 71.320 Val_Loss: 0.4582  BEST VAL Loss: 0.4582  Val_Acc: 79.220

Epoch 64: Validation loss decreased (0.458223 --> 0.457937).  Saving model ...
	 Train_Loss: 0.5186 Train_Acc: 71.404 Val_Loss: 0.4579  BEST VAL Loss: 0.4579  Val_Acc: 79.274

Epoch 65: Validation loss decreased (0.457937 --> 0.457684).  Saving model ...
	 Train_Loss: 0.5184 Train_Acc: 71.464 Val_Loss: 0.4577  BEST VAL Loss: 0.4577  Val_Acc: 79.055

Epoch 66: Validation loss decreased (0.457684 --> 0.457471).  Saving model ...
	 Train_Loss: 0.5182 Train_Acc: 71.376 Val_Loss: 0.4575  BEST VAL Loss: 0.4575  Val_Acc: 78.685

Epoch 67: Validation loss decreased (0.457471 --> 0.457201).  Saving model ...
	 Train_Loss: 0.5179 Train_Acc: 71.589 Val_Loss: 0.4572  BEST VAL Loss: 0.4572  Val_Acc: 79.206

Epoch 68: Validation loss decreased (0.457201 --> 0.456989).  Saving model ...
	 Train_Loss: 0.5177 Train_Acc: 71.373 Val_Loss: 0.4570  BEST VAL Loss: 0.4570  Val_Acc: 79.324

Epoch 69: Validation loss decreased (0.456989 --> 0.456744).  Saving model ...
	 Train_Loss: 0.5175 Train_Acc: 71.524 Val_Loss: 0.4567  BEST VAL Loss: 0.4567  Val_Acc: 79.418

Epoch 70: Validation loss decreased (0.456744 --> 0.456538).  Saving model ...
	 Train_Loss: 0.5172 Train_Acc: 71.577 Val_Loss: 0.4565  BEST VAL Loss: 0.4565  Val_Acc: 79.230

Epoch 71: Validation loss decreased (0.456538 --> 0.456351).  Saving model ...
	 Train_Loss: 0.5170 Train_Acc: 71.473 Val_Loss: 0.4564  BEST VAL Loss: 0.4564  Val_Acc: 78.712

Epoch 72: Validation loss decreased (0.456351 --> 0.456128).  Saving model ...
	 Train_Loss: 0.5168 Train_Acc: 71.476 Val_Loss: 0.4561  BEST VAL Loss: 0.4561  Val_Acc: 79.311

Epoch 73: Validation loss decreased (0.456128 --> 0.455858).  Saving model ...
	 Train_Loss: 0.5166 Train_Acc: 71.659 Val_Loss: 0.4559  BEST VAL Loss: 0.4559  Val_Acc: 79.354

Epoch 74: Validation loss decreased (0.455858 --> 0.455656).  Saving model ...
	 Train_Loss: 0.5164 Train_Acc: 71.573 Val_Loss: 0.4557  BEST VAL Loss: 0.4557  Val_Acc: 78.887

Epoch 75: Validation loss decreased (0.455656 --> 0.455449).  Saving model ...
	 Train_Loss: 0.5162 Train_Acc: 71.461 Val_Loss: 0.4554  BEST VAL Loss: 0.4554  Val_Acc: 78.934

Epoch 76: Validation loss decreased (0.455449 --> 0.455221).  Saving model ...
	 Train_Loss: 0.5161 Train_Acc: 71.448 Val_Loss: 0.4552  BEST VAL Loss: 0.4552  Val_Acc: 79.159

Epoch 77: Validation loss decreased (0.455221 --> 0.455017).  Saving model ...
	 Train_Loss: 0.5159 Train_Acc: 71.631 Val_Loss: 0.4550  BEST VAL Loss: 0.4550  Val_Acc: 78.961

Epoch 78: Validation loss decreased (0.455017 --> 0.454828).  Saving model ...
	 Train_Loss: 0.5157 Train_Acc: 71.616 Val_Loss: 0.4548  BEST VAL Loss: 0.4548  Val_Acc: 79.294

Epoch 79: Validation loss decreased (0.454828 --> 0.454611).  Saving model ...
	 Train_Loss: 0.5155 Train_Acc: 71.404 Val_Loss: 0.4546  BEST VAL Loss: 0.4546  Val_Acc: 79.284

Epoch 80: Validation loss decreased (0.454611 --> 0.454417).  Saving model ...
	 Train_Loss: 0.5153 Train_Acc: 71.679 Val_Loss: 0.4544  BEST VAL Loss: 0.4544  Val_Acc: 79.327

Epoch 81: Validation loss decreased (0.454417 --> 0.454270).  Saving model ...
	 Train_Loss: 0.5152 Train_Acc: 71.571 Val_Loss: 0.4543  BEST VAL Loss: 0.4543  Val_Acc: 78.789

Epoch 82: Validation loss decreased (0.454270 --> 0.454129).  Saving model ...
	 Train_Loss: 0.5150 Train_Acc: 71.431 Val_Loss: 0.4541  BEST VAL Loss: 0.4541  Val_Acc: 79.580

Epoch 83: Validation loss decreased (0.454129 --> 0.453919).  Saving model ...
	 Train_Loss: 0.5148 Train_Acc: 71.587 Val_Loss: 0.4539  BEST VAL Loss: 0.4539  Val_Acc: 79.334

Epoch 84: Validation loss decreased (0.453919 --> 0.453767).  Saving model ...
	 Train_Loss: 0.5146 Train_Acc: 71.656 Val_Loss: 0.4538  BEST VAL Loss: 0.4538  Val_Acc: 79.163

Epoch 85: Validation loss decreased (0.453767 --> 0.453520).  Saving model ...
	 Train_Loss: 0.5145 Train_Acc: 71.652 Val_Loss: 0.4535  BEST VAL Loss: 0.4535  Val_Acc: 79.448

Epoch 86: Validation loss decreased (0.453520 --> 0.453316).  Saving model ...
	 Train_Loss: 0.5143 Train_Acc: 71.725 Val_Loss: 0.4533  BEST VAL Loss: 0.4533  Val_Acc: 78.857

Epoch 87: Validation loss decreased (0.453316 --> 0.453180).  Saving model ...
	 Train_Loss: 0.5142 Train_Acc: 71.811 Val_Loss: 0.4532  BEST VAL Loss: 0.4532  Val_Acc: 79.243

Epoch 88: Validation loss decreased (0.453180 --> 0.453052).  Saving model ...
	 Train_Loss: 0.5140 Train_Acc: 71.698 Val_Loss: 0.4531  BEST VAL Loss: 0.4531  Val_Acc: 78.631

Epoch 89: Validation loss decreased (0.453052 --> 0.452810).  Saving model ...
	 Train_Loss: 0.5138 Train_Acc: 71.680 Val_Loss: 0.4528  BEST VAL Loss: 0.4528  Val_Acc: 79.576

Epoch 90: Validation loss decreased (0.452810 --> 0.452635).  Saving model ...
	 Train_Loss: 0.5137 Train_Acc: 71.712 Val_Loss: 0.4526  BEST VAL Loss: 0.4526  Val_Acc: 78.904

Epoch 91: Validation loss decreased (0.452635 --> 0.452500).  Saving model ...
	 Train_Loss: 0.5135 Train_Acc: 71.656 Val_Loss: 0.4525  BEST VAL Loss: 0.4525  Val_Acc: 79.337

Epoch 92: Validation loss decreased (0.452500 --> 0.452283).  Saving model ...
	 Train_Loss: 0.5134 Train_Acc: 71.664 Val_Loss: 0.4523  BEST VAL Loss: 0.4523  Val_Acc: 79.586

Epoch 93: Validation loss decreased (0.452283 --> 0.452116).  Saving model ...
	 Train_Loss: 0.5132 Train_Acc: 71.727 Val_Loss: 0.4521  BEST VAL Loss: 0.4521  Val_Acc: 79.358

Epoch 94: Validation loss decreased (0.452116 --> 0.451997).  Saving model ...
	 Train_Loss: 0.5131 Train_Acc: 71.636 Val_Loss: 0.4520  BEST VAL Loss: 0.4520  Val_Acc: 79.055

Epoch 95: Validation loss decreased (0.451997 --> 0.451845).  Saving model ...
	 Train_Loss: 0.5129 Train_Acc: 71.756 Val_Loss: 0.4518  BEST VAL Loss: 0.4518  Val_Acc: 79.122

Epoch 96: Validation loss decreased (0.451845 --> 0.451682).  Saving model ...
	 Train_Loss: 0.5128 Train_Acc: 71.502 Val_Loss: 0.4517  BEST VAL Loss: 0.4517  Val_Acc: 79.062

Epoch 97: Validation loss decreased (0.451682 --> 0.451484).  Saving model ...
	 Train_Loss: 0.5126 Train_Acc: 71.624 Val_Loss: 0.4515  BEST VAL Loss: 0.4515  Val_Acc: 79.324

Epoch 98: Validation loss decreased (0.451484 --> 0.451332).  Saving model ...
	 Train_Loss: 0.5125 Train_Acc: 71.555 Val_Loss: 0.4513  BEST VAL Loss: 0.4513  Val_Acc: 79.011

Epoch 99: Validation loss decreased (0.451332 --> 0.451203).  Saving model ...
	 Train_Loss: 0.5124 Train_Acc: 71.627 Val_Loss: 0.4512  BEST VAL Loss: 0.4512  Val_Acc: 78.786

Thapsigargin_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.63      0.56      0.59    149884
           1       0.37      0.43      0.40     87993

    accuracy                           0.52    237877
   macro avg       0.50      0.50      0.50    237877
weighted avg       0.53      0.52      0.52    237877

Thapsigargin_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.62      0.56      0.59     18736
           1       0.36      0.42      0.39     10999

    accuracy                           0.51     29735
   macro avg       0.49      0.49      0.49     29735
weighted avg       0.53      0.51      0.52     29735

Thapsigargin_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.63      0.57      0.60     18736
           1       0.37      0.43      0.40     10999

    accuracy                           0.52     29735
   macro avg       0.50      0.50      0.50     29735
weighted avg       0.53      0.52      0.52     29735

              precision    recall  f1-score   support

           0       0.63      0.57      0.60     18736
           1       0.37      0.43      0.40     10999

    accuracy                           0.52     29735
   macro avg       0.50      0.50      0.50     29735
weighted avg       0.53      0.52      0.52     29735

Thapsigargin_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.42      0.43      0.43     27774
           1       0.58      0.57      0.58     38465

    accuracy                           0.51     66239
   macro avg       0.50      0.50      0.50     66239
weighted avg       0.52      0.51      0.51     66239

              precision    recall  f1-score   support

           0       0.42      0.43      0.43     27774
           1       0.58      0.57      0.58     38465

    accuracy                           0.51     66239
   macro avg       0.50      0.50      0.50     66239
weighted avg       0.52      0.51      0.51     66239

completed
