[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '3b545527'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '4acd2bb7'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '35bb23a1'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e9d98faa'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_0.100_DMSO_0.025 treatment_name: Thapsigargin_10.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_0.100_DMSO_0.025
TREATMENT_NAME: Thapsigargin_10.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'LPS_0.100_DMSO_0.025']
The dimensions of the data are: (30722, 1276)
Number of total missing values across all columns: 61444
Data Subset Is Off
Wells held out for testing: ['E14' 'C20']
Wells to use for training, validation, and testing ['E15' 'C16' 'C17' 'C21' 'L14' 'L15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.581615).  Saving model ...
	 Train_Loss: 0.6566 Train_Acc: 56.849 Val_Loss: 0.5816  BEST VAL Loss: 0.5816  Val_Acc: 67.220

Epoch 1: Validation loss decreased (0.581615 --> 0.540521).  Saving model ...
	 Train_Loss: 0.5958 Train_Acc: 69.857 Val_Loss: 0.5405  BEST VAL Loss: 0.5405  Val_Acc: 73.558

Epoch 2: Validation loss decreased (0.540521 --> 0.510866).  Saving model ...
	 Train_Loss: 0.5543 Train_Acc: 75.305 Val_Loss: 0.5109  BEST VAL Loss: 0.5109  Val_Acc: 79.283

Epoch 3: Validation loss decreased (0.510866 --> 0.487450).  Saving model ...
	 Train_Loss: 0.5237 Train_Acc: 80.320 Val_Loss: 0.4875  BEST VAL Loss: 0.4875  Val_Acc: 83.086

Epoch 4: Validation loss decreased (0.487450 --> 0.467766).  Saving model ...
	 Train_Loss: 0.4987 Train_Acc: 83.800 Val_Loss: 0.4678  BEST VAL Loss: 0.4678  Val_Acc: 85.227

Epoch 5: Validation loss decreased (0.467766 --> 0.450581).  Saving model ...
	 Train_Loss: 0.4780 Train_Acc: 85.500 Val_Loss: 0.4506  BEST VAL Loss: 0.4506  Val_Acc: 86.888

Epoch 6: Validation loss decreased (0.450581 --> 0.435393).  Saving model ...
	 Train_Loss: 0.4596 Train_Acc: 86.789 Val_Loss: 0.4354  BEST VAL Loss: 0.4354  Val_Acc: 87.631

Epoch 7: Validation loss decreased (0.435393 --> 0.421789).  Saving model ...
	 Train_Loss: 0.4441 Train_Acc: 87.565 Val_Loss: 0.4218  BEST VAL Loss: 0.4218  Val_Acc: 88.724

Epoch 8: Validation loss decreased (0.421789 --> 0.409588).  Saving model ...
	 Train_Loss: 0.4300 Train_Acc: 87.947 Val_Loss: 0.4096  BEST VAL Loss: 0.4096  Val_Acc: 89.030

Epoch 9: Validation loss decreased (0.409588 --> 0.398545).  Saving model ...
	 Train_Loss: 0.4172 Train_Acc: 88.505 Val_Loss: 0.3985  BEST VAL Loss: 0.3985  Val_Acc: 89.161

Epoch 10: Validation loss decreased (0.398545 --> 0.388507).  Saving model ...
	 Train_Loss: 0.4059 Train_Acc: 88.893 Val_Loss: 0.3885  BEST VAL Loss: 0.3885  Val_Acc: 89.816

Epoch 11: Validation loss decreased (0.388507 --> 0.379246).  Saving model ...
	 Train_Loss: 0.3955 Train_Acc: 89.198 Val_Loss: 0.3792  BEST VAL Loss: 0.3792  Val_Acc: 89.860

Epoch 12: Validation loss decreased (0.379246 --> 0.370729).  Saving model ...
	 Train_Loss: 0.3859 Train_Acc: 90.111 Val_Loss: 0.3707  BEST VAL Loss: 0.3707  Val_Acc: 90.166

Epoch 13: Validation loss decreased (0.370729 --> 0.362862).  Saving model ...
	 Train_Loss: 0.3771 Train_Acc: 90.144 Val_Loss: 0.3629  BEST VAL Loss: 0.3629  Val_Acc: 90.385

Epoch 14: Validation loss decreased (0.362862 --> 0.355556).  Saving model ...
	 Train_Loss: 0.3689 Train_Acc: 90.570 Val_Loss: 0.3556  BEST VAL Loss: 0.3556  Val_Acc: 90.516

Epoch 15: Validation loss decreased (0.355556 --> 0.348765).  Saving model ...
	 Train_Loss: 0.3614 Train_Acc: 90.444 Val_Loss: 0.3488  BEST VAL Loss: 0.3488  Val_Acc: 90.822

Epoch 16: Validation loss decreased (0.348765 --> 0.342392).  Saving model ...
	 Train_Loss: 0.3543 Train_Acc: 90.930 Val_Loss: 0.3424  BEST VAL Loss: 0.3424  Val_Acc: 90.953

Epoch 17: Validation loss decreased (0.342392 --> 0.336425).  Saving model ...
	 Train_Loss: 0.3476 Train_Acc: 91.171 Val_Loss: 0.3364  BEST VAL Loss: 0.3364  Val_Acc: 91.128

Epoch 18: Validation loss decreased (0.336425 --> 0.330832).  Saving model ...
	 Train_Loss: 0.3413 Train_Acc: 91.466 Val_Loss: 0.3308  BEST VAL Loss: 0.3308  Val_Acc: 91.390

Epoch 19: Validation loss decreased (0.330832 --> 0.325581).  Saving model ...
	 Train_Loss: 0.3355 Train_Acc: 91.510 Val_Loss: 0.3256  BEST VAL Loss: 0.3256  Val_Acc: 91.390

Epoch 20: Validation loss decreased (0.325581 --> 0.320665).  Saving model ...
	 Train_Loss: 0.3301 Train_Acc: 91.575 Val_Loss: 0.3207  BEST VAL Loss: 0.3207  Val_Acc: 91.477

Epoch 21: Validation loss decreased (0.320665 --> 0.315997).  Saving model ...
	 Train_Loss: 0.3248 Train_Acc: 92.089 Val_Loss: 0.3160  BEST VAL Loss: 0.3160  Val_Acc: 91.608

Epoch 22: Validation loss decreased (0.315997 --> 0.311510).  Saving model ...
	 Train_Loss: 0.3198 Train_Acc: 92.089 Val_Loss: 0.3115  BEST VAL Loss: 0.3115  Val_Acc: 91.958

Epoch 23: Validation loss decreased (0.311510 --> 0.307264).  Saving model ...
	 Train_Loss: 0.3151 Train_Acc: 92.050 Val_Loss: 0.3073  BEST VAL Loss: 0.3073  Val_Acc: 92.308

Epoch 24: Validation loss decreased (0.307264 --> 0.303219).  Saving model ...
	 Train_Loss: 0.3106 Train_Acc: 92.231 Val_Loss: 0.3032  BEST VAL Loss: 0.3032  Val_Acc: 92.264

Epoch 25: Validation loss decreased (0.303219 --> 0.299391).  Saving model ...
	 Train_Loss: 0.3062 Train_Acc: 92.635 Val_Loss: 0.2994  BEST VAL Loss: 0.2994  Val_Acc: 92.220

Epoch 26: Validation loss decreased (0.299391 --> 0.295699).  Saving model ...
	 Train_Loss: 0.3020 Train_Acc: 92.744 Val_Loss: 0.2957  BEST VAL Loss: 0.2957  Val_Acc: 92.395

Epoch 27: Validation loss decreased (0.295699 --> 0.292176).  Saving model ...
	 Train_Loss: 0.2981 Train_Acc: 92.886 Val_Loss: 0.2922  BEST VAL Loss: 0.2922  Val_Acc: 92.614

Epoch 28: Validation loss decreased (0.292176 --> 0.288808).  Saving model ...
	 Train_Loss: 0.2943 Train_Acc: 92.881 Val_Loss: 0.2888  BEST VAL Loss: 0.2888  Val_Acc: 92.745

Epoch 29: Validation loss decreased (0.288808 --> 0.285572).  Saving model ...
	 Train_Loss: 0.2907 Train_Acc: 93.089 Val_Loss: 0.2856  BEST VAL Loss: 0.2856  Val_Acc: 92.701

Epoch 30: Validation loss decreased (0.285572 --> 0.282465).  Saving model ...
	 Train_Loss: 0.2872 Train_Acc: 93.171 Val_Loss: 0.2825  BEST VAL Loss: 0.2825  Val_Acc: 92.657

Epoch 31: Validation loss decreased (0.282465 --> 0.279493).  Saving model ...
	 Train_Loss: 0.2838 Train_Acc: 93.263 Val_Loss: 0.2795  BEST VAL Loss: 0.2795  Val_Acc: 92.920

Epoch 32: Validation loss decreased (0.279493 --> 0.276610).  Saving model ...
	 Train_Loss: 0.2805 Train_Acc: 93.438 Val_Loss: 0.2766  BEST VAL Loss: 0.2766  Val_Acc: 93.138

Epoch 33: Validation loss decreased (0.276610 --> 0.273865).  Saving model ...
	 Train_Loss: 0.2774 Train_Acc: 93.580 Val_Loss: 0.2739  BEST VAL Loss: 0.2739  Val_Acc: 93.138

Epoch 34: Validation loss decreased (0.273865 --> 0.271199).  Saving model ...
	 Train_Loss: 0.2744 Train_Acc: 93.673 Val_Loss: 0.2712  BEST VAL Loss: 0.2712  Val_Acc: 93.051

Epoch 35: Validation loss decreased (0.271199 --> 0.268609).  Saving model ...
	 Train_Loss: 0.2714 Train_Acc: 93.930 Val_Loss: 0.2686  BEST VAL Loss: 0.2686  Val_Acc: 93.094

Epoch 36: Validation loss decreased (0.268609 --> 0.266126).  Saving model ...
	 Train_Loss: 0.2685 Train_Acc: 93.930 Val_Loss: 0.2661  BEST VAL Loss: 0.2661  Val_Acc: 93.313

Epoch 37: Validation loss decreased (0.266126 --> 0.263711).  Saving model ...
	 Train_Loss: 0.2658 Train_Acc: 93.875 Val_Loss: 0.2637  BEST VAL Loss: 0.2637  Val_Acc: 93.269

Epoch 38: Validation loss decreased (0.263711 --> 0.261345).  Saving model ...
	 Train_Loss: 0.2632 Train_Acc: 93.815 Val_Loss: 0.2613  BEST VAL Loss: 0.2613  Val_Acc: 93.313

Epoch 39: Validation loss decreased (0.261345 --> 0.259086).  Saving model ...
	 Train_Loss: 0.2605 Train_Acc: 94.252 Val_Loss: 0.2591  BEST VAL Loss: 0.2591  Val_Acc: 93.531

Epoch 40: Validation loss decreased (0.259086 --> 0.256932).  Saving model ...
	 Train_Loss: 0.2580 Train_Acc: 94.198 Val_Loss: 0.2569  BEST VAL Loss: 0.2569  Val_Acc: 93.488

Epoch 41: Validation loss decreased (0.256932 --> 0.254825).  Saving model ...
	 Train_Loss: 0.2556 Train_Acc: 94.274 Val_Loss: 0.2548  BEST VAL Loss: 0.2548  Val_Acc: 93.531

Epoch 42: Validation loss decreased (0.254825 --> 0.252770).  Saving model ...
	 Train_Loss: 0.2532 Train_Acc: 94.471 Val_Loss: 0.2528  BEST VAL Loss: 0.2528  Val_Acc: 93.531

Epoch 43: Validation loss decreased (0.252770 --> 0.250783).  Saving model ...
	 Train_Loss: 0.2509 Train_Acc: 94.542 Val_Loss: 0.2508  BEST VAL Loss: 0.2508  Val_Acc: 93.444

Epoch 44: Validation loss decreased (0.250783 --> 0.248902).  Saving model ...
	 Train_Loss: 0.2487 Train_Acc: 94.318 Val_Loss: 0.2489  BEST VAL Loss: 0.2489  Val_Acc: 93.488

Epoch 45: Validation loss decreased (0.248902 --> 0.247024).  Saving model ...
	 Train_Loss: 0.2465 Train_Acc: 94.553 Val_Loss: 0.2470  BEST VAL Loss: 0.2470  Val_Acc: 93.444

Epoch 46: Validation loss decreased (0.247024 --> 0.245179).  Saving model ...
	 Train_Loss: 0.2443 Train_Acc: 94.635 Val_Loss: 0.2452  BEST VAL Loss: 0.2452  Val_Acc: 93.750

Epoch 47: Validation loss decreased (0.245179 --> 0.243395).  Saving model ...
	 Train_Loss: 0.2422 Train_Acc: 94.848 Val_Loss: 0.2434  BEST VAL Loss: 0.2434  Val_Acc: 93.619

Epoch 48: Validation loss decreased (0.243395 --> 0.241672).  Saving model ...
	 Train_Loss: 0.2402 Train_Acc: 94.897 Val_Loss: 0.2417  BEST VAL Loss: 0.2417  Val_Acc: 93.925

Epoch 49: Validation loss decreased (0.241672 --> 0.240040).  Saving model ...
	 Train_Loss: 0.2383 Train_Acc: 94.826 Val_Loss: 0.2400  BEST VAL Loss: 0.2400  Val_Acc: 93.531

Epoch 50: Validation loss decreased (0.240040 --> 0.238392).  Saving model ...
	 Train_Loss: 0.2364 Train_Acc: 95.017 Val_Loss: 0.2384  BEST VAL Loss: 0.2384  Val_Acc: 94.012

Epoch 51: Validation loss decreased (0.238392 --> 0.236801).  Saving model ...
	 Train_Loss: 0.2345 Train_Acc: 95.072 Val_Loss: 0.2368  BEST VAL Loss: 0.2368  Val_Acc: 93.925

Epoch 52: Validation loss decreased (0.236801 --> 0.235285).  Saving model ...
	 Train_Loss: 0.2327 Train_Acc: 95.099 Val_Loss: 0.2353  BEST VAL Loss: 0.2353  Val_Acc: 93.837

Epoch 53: Validation loss decreased (0.235285 --> 0.233806).  Saving model ...
	 Train_Loss: 0.2308 Train_Acc: 95.077 Val_Loss: 0.2338  BEST VAL Loss: 0.2338  Val_Acc: 94.012

Epoch 54: Validation loss decreased (0.233806 --> 0.232377).  Saving model ...
	 Train_Loss: 0.2291 Train_Acc: 95.159 Val_Loss: 0.2324  BEST VAL Loss: 0.2324  Val_Acc: 94.012

Epoch 55: Validation loss decreased (0.232377 --> 0.230941).  Saving model ...
	 Train_Loss: 0.2274 Train_Acc: 95.301 Val_Loss: 0.2309  BEST VAL Loss: 0.2309  Val_Acc: 94.143

Epoch 56: Validation loss decreased (0.230941 --> 0.229579).  Saving model ...
	 Train_Loss: 0.2257 Train_Acc: 95.219 Val_Loss: 0.2296  BEST VAL Loss: 0.2296  Val_Acc: 94.231

Epoch 57: Validation loss decreased (0.229579 --> 0.228225).  Saving model ...
	 Train_Loss: 0.2241 Train_Acc: 95.176 Val_Loss: 0.2282  BEST VAL Loss: 0.2282  Val_Acc: 94.493

Epoch 58: Validation loss decreased (0.228225 --> 0.226907).  Saving model ...
	 Train_Loss: 0.2225 Train_Acc: 95.340 Val_Loss: 0.2269  BEST VAL Loss: 0.2269  Val_Acc: 94.580

Epoch 59: Validation loss decreased (0.226907 --> 0.225622).  Saving model ...
	 Train_Loss: 0.2209 Train_Acc: 95.290 Val_Loss: 0.2256  BEST VAL Loss: 0.2256  Val_Acc: 94.449

Epoch 60: Validation loss decreased (0.225622 --> 0.224412).  Saving model ...
	 Train_Loss: 0.2194 Train_Acc: 95.334 Val_Loss: 0.2244  BEST VAL Loss: 0.2244  Val_Acc: 94.231

Epoch 61: Validation loss decreased (0.224412 --> 0.223198).  Saving model ...
	 Train_Loss: 0.2180 Train_Acc: 95.301 Val_Loss: 0.2232  BEST VAL Loss: 0.2232  Val_Acc: 94.406

Epoch 62: Validation loss decreased (0.223198 --> 0.221998).  Saving model ...
	 Train_Loss: 0.2165 Train_Acc: 95.482 Val_Loss: 0.2220  BEST VAL Loss: 0.2220  Val_Acc: 94.449

Epoch 63: Validation loss decreased (0.221998 --> 0.220852).  Saving model ...
	 Train_Loss: 0.2150 Train_Acc: 95.651 Val_Loss: 0.2209  BEST VAL Loss: 0.2209  Val_Acc: 94.406

Epoch 64: Validation loss decreased (0.220852 --> 0.219730).  Saving model ...
	 Train_Loss: 0.2136 Train_Acc: 95.585 Val_Loss: 0.2197  BEST VAL Loss: 0.2197  Val_Acc: 94.537

Epoch 65: Validation loss decreased (0.219730 --> 0.218630).  Saving model ...
	 Train_Loss: 0.2122 Train_Acc: 95.656 Val_Loss: 0.2186  BEST VAL Loss: 0.2186  Val_Acc: 94.493

Epoch 66: Validation loss decreased (0.218630 --> 0.217575).  Saving model ...
	 Train_Loss: 0.2109 Train_Acc: 95.695 Val_Loss: 0.2176  BEST VAL Loss: 0.2176  Val_Acc: 94.668

Epoch 67: Validation loss decreased (0.217575 --> 0.216504).  Saving model ...
	 Train_Loss: 0.2095 Train_Acc: 95.733 Val_Loss: 0.2165  BEST VAL Loss: 0.2165  Val_Acc: 94.580

Epoch 68: Validation loss decreased (0.216504 --> 0.215468).  Saving model ...
	 Train_Loss: 0.2082 Train_Acc: 95.613 Val_Loss: 0.2155  BEST VAL Loss: 0.2155  Val_Acc: 94.799

Epoch 69: Validation loss decreased (0.215468 --> 0.214446).  Saving model ...
	 Train_Loss: 0.2070 Train_Acc: 95.689 Val_Loss: 0.2144  BEST VAL Loss: 0.2144  Val_Acc: 94.843

Epoch 70: Validation loss decreased (0.214446 --> 0.213436).  Saving model ...
	 Train_Loss: 0.2057 Train_Acc: 95.733 Val_Loss: 0.2134  BEST VAL Loss: 0.2134  Val_Acc: 94.843

Epoch 71: Validation loss decreased (0.213436 --> 0.212463).  Saving model ...
	 Train_Loss: 0.2045 Train_Acc: 95.979 Val_Loss: 0.2125  BEST VAL Loss: 0.2125  Val_Acc: 94.886

Epoch 72: Validation loss decreased (0.212463 --> 0.211526).  Saving model ...
	 Train_Loss: 0.2033 Train_Acc: 95.717 Val_Loss: 0.2115  BEST VAL Loss: 0.2115  Val_Acc: 94.799

Epoch 73: Validation loss decreased (0.211526 --> 0.210646).  Saving model ...
	 Train_Loss: 0.2021 Train_Acc: 95.727 Val_Loss: 0.2106  BEST VAL Loss: 0.2106  Val_Acc: 94.712

Epoch 74: Validation loss decreased (0.210646 --> 0.209742).  Saving model ...
	 Train_Loss: 0.2010 Train_Acc: 95.809 Val_Loss: 0.2097  BEST VAL Loss: 0.2097  Val_Acc: 94.755

Epoch 75: Validation loss decreased (0.209742 --> 0.208866).  Saving model ...
	 Train_Loss: 0.1998 Train_Acc: 95.842 Val_Loss: 0.2089  BEST VAL Loss: 0.2089  Val_Acc: 94.843

Epoch 76: Validation loss decreased (0.208866 --> 0.208011).  Saving model ...
	 Train_Loss: 0.1987 Train_Acc: 96.094 Val_Loss: 0.2080  BEST VAL Loss: 0.2080  Val_Acc: 94.712

Epoch 77: Validation loss decreased (0.208011 --> 0.207188).  Saving model ...
	 Train_Loss: 0.1976 Train_Acc: 96.170 Val_Loss: 0.2072  BEST VAL Loss: 0.2072  Val_Acc: 94.843

Epoch 78: Validation loss decreased (0.207188 --> 0.206357).  Saving model ...
	 Train_Loss: 0.1965 Train_Acc: 95.962 Val_Loss: 0.2064  BEST VAL Loss: 0.2064  Val_Acc: 94.799

Epoch 79: Validation loss decreased (0.206357 --> 0.205512).  Saving model ...
	 Train_Loss: 0.1954 Train_Acc: 95.886 Val_Loss: 0.2055  BEST VAL Loss: 0.2055  Val_Acc: 94.843

Epoch 80: Validation loss decreased (0.205512 --> 0.204724).  Saving model ...
	 Train_Loss: 0.1944 Train_Acc: 96.159 Val_Loss: 0.2047  BEST VAL Loss: 0.2047  Val_Acc: 94.799

Epoch 81: Validation loss decreased (0.204724 --> 0.203936).  Saving model ...
	 Train_Loss: 0.1933 Train_Acc: 96.192 Val_Loss: 0.2039  BEST VAL Loss: 0.2039  Val_Acc: 94.886

Epoch 82: Validation loss decreased (0.203936 --> 0.203153).  Saving model ...
	 Train_Loss: 0.1923 Train_Acc: 96.197 Val_Loss: 0.2032  BEST VAL Loss: 0.2032  Val_Acc: 94.799

Epoch 83: Validation loss decreased (0.203153 --> 0.202401).  Saving model ...
	 Train_Loss: 0.1913 Train_Acc: 96.214 Val_Loss: 0.2024  BEST VAL Loss: 0.2024  Val_Acc: 94.799

Epoch 84: Validation loss decreased (0.202401 --> 0.201673).  Saving model ...
	 Train_Loss: 0.1903 Train_Acc: 96.165 Val_Loss: 0.2017  BEST VAL Loss: 0.2017  Val_Acc: 94.843

Epoch 85: Validation loss decreased (0.201673 --> 0.200946).  Saving model ...
	 Train_Loss: 0.1893 Train_Acc: 96.339 Val_Loss: 0.2009  BEST VAL Loss: 0.2009  Val_Acc: 94.930

Epoch 86: Validation loss decreased (0.200946 --> 0.200258).  Saving model ...
	 Train_Loss: 0.1883 Train_Acc: 96.274 Val_Loss: 0.2003  BEST VAL Loss: 0.2003  Val_Acc: 94.930

Epoch 87: Validation loss decreased (0.200258 --> 0.199529).  Saving model ...
	 Train_Loss: 0.1873 Train_Acc: 96.361 Val_Loss: 0.1995  BEST VAL Loss: 0.1995  Val_Acc: 95.061

Epoch 88: Validation loss decreased (0.199529 --> 0.198827).  Saving model ...
	 Train_Loss: 0.1864 Train_Acc: 96.334 Val_Loss: 0.1988  BEST VAL Loss: 0.1988  Val_Acc: 94.886

Epoch 89: Validation loss decreased (0.198827 --> 0.198143).  Saving model ...
	 Train_Loss: 0.1854 Train_Acc: 96.252 Val_Loss: 0.1981  BEST VAL Loss: 0.1981  Val_Acc: 94.886

Epoch 90: Validation loss decreased (0.198143 --> 0.197477).  Saving model ...
	 Train_Loss: 0.1845 Train_Acc: 96.350 Val_Loss: 0.1975  BEST VAL Loss: 0.1975  Val_Acc: 95.105

Epoch 91: Validation loss decreased (0.197477 --> 0.196816).  Saving model ...
	 Train_Loss: 0.1836 Train_Acc: 96.427 Val_Loss: 0.1968  BEST VAL Loss: 0.1968  Val_Acc: 94.886

Epoch 92: Validation loss decreased (0.196816 --> 0.196188).  Saving model ...
	 Train_Loss: 0.1827 Train_Acc: 96.454 Val_Loss: 0.1962  BEST VAL Loss: 0.1962  Val_Acc: 94.930

Epoch 93: Validation loss decreased (0.196188 --> 0.195546).  Saving model ...
	 Train_Loss: 0.1819 Train_Acc: 96.383 Val_Loss: 0.1955  BEST VAL Loss: 0.1955  Val_Acc: 95.061

Epoch 94: Validation loss decreased (0.195546 --> 0.194940).  Saving model ...
	 Train_Loss: 0.1810 Train_Acc: 96.471 Val_Loss: 0.1949  BEST VAL Loss: 0.1949  Val_Acc: 94.974

Epoch 95: Validation loss decreased (0.194940 --> 0.194329).  Saving model ...
	 Train_Loss: 0.1801 Train_Acc: 96.416 Val_Loss: 0.1943  BEST VAL Loss: 0.1943  Val_Acc: 94.930

Epoch 96: Validation loss decreased (0.194329 --> 0.193743).  Saving model ...
	 Train_Loss: 0.1793 Train_Acc: 96.268 Val_Loss: 0.1937  BEST VAL Loss: 0.1937  Val_Acc: 94.930

Epoch 97: Validation loss decreased (0.193743 --> 0.193208).  Saving model ...
	 Train_Loss: 0.1785 Train_Acc: 96.465 Val_Loss: 0.1932  BEST VAL Loss: 0.1932  Val_Acc: 94.624

Epoch 98: Validation loss decreased (0.193208 --> 0.192623).  Saving model ...
	 Train_Loss: 0.1777 Train_Acc: 96.531 Val_Loss: 0.1926  BEST VAL Loss: 0.1926  Val_Acc: 95.061

Epoch 99: Validation loss decreased (0.192623 --> 0.192056).  Saving model ...
	 Train_Loss: 0.1769 Train_Acc: 96.542 Val_Loss: 0.1921  BEST VAL Loss: 0.1921  Val_Acc: 95.017

LPS_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.98      0.98     10451
           1       0.98      0.97      0.97      7852

    accuracy                           0.98     18303
   macro avg       0.98      0.98      0.98     18303
weighted avg       0.98      0.98      0.98     18303

LPS_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.95      0.96      0.96      1307
           1       0.95      0.93      0.94       981

    accuracy                           0.95      2288
   macro avg       0.95      0.95      0.95      2288
weighted avg       0.95      0.95      0.95      2288

LPS_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.96      0.97      0.96      1307
           1       0.95      0.94      0.95       981

    accuracy                           0.95      2288
   macro avg       0.95      0.95      0.95      2288
weighted avg       0.95      0.95      0.95      2288

              precision    recall  f1-score   support

           0       0.96      0.97      0.96      1307
           1       0.95      0.94      0.95       981

    accuracy                           0.95      2288
   macro avg       0.95      0.95      0.95      2288
weighted avg       0.95      0.95      0.95      2288

LPS_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.96      0.97      0.96      4445
           1       0.96      0.94      0.95      3398

    accuracy                           0.96      7843
   macro avg       0.96      0.95      0.96      7843
weighted avg       0.96      0.96      0.96      7843

              precision    recall  f1-score   support

           0       0.96      0.97      0.96      4445
           1       0.96      0.94      0.95      3398

    accuracy                           0.96      7843
   macro avg       0.96      0.95      0.96      7843
weighted avg       0.96      0.96      0.96      7843

completed
