[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1e2afd8c'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '108b1f4b'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '89c67873'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '779725b4'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_Nigericin_1.000_3.0_DMSO_0.025'
 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (355427, 1270)
Number of total missing values across all columns: 0
Data Subset Is Off
Wells held out for testing: ['M08' 'L09']
Wells to use for training, validation, and testing ['L02' 'M02' 'L03' 'M03' 'L08' 'M09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.687643).  Saving model ...
	 Train_Loss: 0.6909 Train_Acc: 52.436 Val_Loss: 0.6876  BEST VAL Loss: 0.6876  Val_Acc: 54.570

Epoch 1: Validation loss decreased (0.687643 --> 0.684612).  Saving model ...
	 Train_Loss: 0.6879 Train_Acc: 55.157 Val_Loss: 0.6846  BEST VAL Loss: 0.6846  Val_Acc: 56.394

Epoch 2: Validation loss decreased (0.684612 --> 0.681501).  Saving model ...
	 Train_Loss: 0.6852 Train_Acc: 56.517 Val_Loss: 0.6815  BEST VAL Loss: 0.6815  Val_Acc: 57.487

Epoch 3: Validation loss decreased (0.681501 --> 0.678375).  Saving model ...
	 Train_Loss: 0.6825 Train_Acc: 57.505 Val_Loss: 0.6784  BEST VAL Loss: 0.6784  Val_Acc: 58.606

Epoch 4: Validation loss decreased (0.678375 --> 0.675388).  Saving model ...
	 Train_Loss: 0.6797 Train_Acc: 58.567 Val_Loss: 0.6754  BEST VAL Loss: 0.6754  Val_Acc: 59.450

Epoch 5: Validation loss decreased (0.675388 --> 0.672585).  Saving model ...
	 Train_Loss: 0.6771 Train_Acc: 59.359 Val_Loss: 0.6726  BEST VAL Loss: 0.6726  Val_Acc: 60.243

Epoch 6: Validation loss decreased (0.672585 --> 0.669951).  Saving model ...
	 Train_Loss: 0.6748 Train_Acc: 59.802 Val_Loss: 0.6700  BEST VAL Loss: 0.6700  Val_Acc: 61.318

Epoch 7: Validation loss decreased (0.669951 --> 0.667471).  Saving model ...
	 Train_Loss: 0.6726 Train_Acc: 60.444 Val_Loss: 0.6675  BEST VAL Loss: 0.6675  Val_Acc: 61.932

Epoch 8: Validation loss decreased (0.667471 --> 0.665217).  Saving model ...
	 Train_Loss: 0.6705 Train_Acc: 60.703 Val_Loss: 0.6652  BEST VAL Loss: 0.6652  Val_Acc: 62.715

Epoch 9: Validation loss decreased (0.665217 --> 0.663029).  Saving model ...
	 Train_Loss: 0.6685 Train_Acc: 61.454 Val_Loss: 0.6630  BEST VAL Loss: 0.6630  Val_Acc: 63.292

Epoch 10: Validation loss decreased (0.663029 --> 0.660588).  Saving model ...
	 Train_Loss: 0.6665 Train_Acc: 62.211 Val_Loss: 0.6606  BEST VAL Loss: 0.6606  Val_Acc: 64.188

Epoch 11: Validation loss decreased (0.660588 --> 0.658926).  Saving model ...
	 Train_Loss: 0.6646 Train_Acc: 62.665 Val_Loss: 0.6589  BEST VAL Loss: 0.6589  Val_Acc: 63.208

Epoch 12: Validation loss decreased (0.658926 --> 0.656551).  Saving model ...
	 Train_Loss: 0.6627 Train_Acc: 63.138 Val_Loss: 0.6566  BEST VAL Loss: 0.6566  Val_Acc: 64.821

Epoch 13: Validation loss decreased (0.656551 --> 0.654359).  Saving model ...
	 Train_Loss: 0.6608 Train_Acc: 63.507 Val_Loss: 0.6544  BEST VAL Loss: 0.6544  Val_Acc: 64.996

Epoch 14: Validation loss decreased (0.654359 --> 0.652192).  Saving model ...
	 Train_Loss: 0.6590 Train_Acc: 63.788 Val_Loss: 0.6522  BEST VAL Loss: 0.6522  Val_Acc: 65.756

Epoch 15: Validation loss decreased (0.652192 --> 0.650222).  Saving model ...
	 Train_Loss: 0.6573 Train_Acc: 64.114 Val_Loss: 0.6502  BEST VAL Loss: 0.6502  Val_Acc: 65.581

Epoch 16: Validation loss decreased (0.650222 --> 0.648096).  Saving model ...
	 Train_Loss: 0.6556 Train_Acc: 64.577 Val_Loss: 0.6481  BEST VAL Loss: 0.6481  Val_Acc: 66.104

Epoch 17: Validation loss decreased (0.648096 --> 0.645935).  Saving model ...
	 Train_Loss: 0.6539 Train_Acc: 64.692 Val_Loss: 0.6459  BEST VAL Loss: 0.6459  Val_Acc: 66.787

Epoch 18: Validation loss decreased (0.645935 --> 0.644042).  Saving model ...
	 Train_Loss: 0.6524 Train_Acc: 65.064 Val_Loss: 0.6440  BEST VAL Loss: 0.6440  Val_Acc: 66.860

Epoch 19: Validation loss decreased (0.644042 --> 0.641997).  Saving model ...
	 Train_Loss: 0.6509 Train_Acc: 65.281 Val_Loss: 0.6420  BEST VAL Loss: 0.6420  Val_Acc: 67.131

Epoch 20: Validation loss decreased (0.641997 --> 0.640180).  Saving model ...
	 Train_Loss: 0.6494 Train_Acc: 65.394 Val_Loss: 0.6402  BEST VAL Loss: 0.6402  Val_Acc: 67.427

Epoch 21: Validation loss decreased (0.640180 --> 0.638658).  Saving model ...
	 Train_Loss: 0.6480 Train_Acc: 65.523 Val_Loss: 0.6387  BEST VAL Loss: 0.6387  Val_Acc: 66.374

Epoch 22: Validation loss decreased (0.638658 --> 0.637307).  Saving model ...
	 Train_Loss: 0.6467 Train_Acc: 65.712 Val_Loss: 0.6373  BEST VAL Loss: 0.6373  Val_Acc: 66.981

Epoch 23: Validation loss decreased (0.637307 --> 0.635817).  Saving model ...
	 Train_Loss: 0.6454 Train_Acc: 65.793 Val_Loss: 0.6358  BEST VAL Loss: 0.6358  Val_Acc: 67.347

Epoch 24: Validation loss decreased (0.635817 --> 0.634310).  Saving model ...
	 Train_Loss: 0.6441 Train_Acc: 65.915 Val_Loss: 0.6343  BEST VAL Loss: 0.6343  Val_Acc: 67.953

Epoch 25: Validation loss decreased (0.634310 --> 0.632861).  Saving model ...
	 Train_Loss: 0.6429 Train_Acc: 66.007 Val_Loss: 0.6329  BEST VAL Loss: 0.6329  Val_Acc: 67.668

Epoch 26: Validation loss decreased (0.632861 --> 0.631479).  Saving model ...
	 Train_Loss: 0.6418 Train_Acc: 66.112 Val_Loss: 0.6315  BEST VAL Loss: 0.6315  Val_Acc: 67.624

Epoch 27: Validation loss decreased (0.631479 --> 0.630229).  Saving model ...
	 Train_Loss: 0.6407 Train_Acc: 66.084 Val_Loss: 0.6302  BEST VAL Loss: 0.6302  Val_Acc: 67.449

Epoch 28: Validation loss decreased (0.630229 --> 0.628921).  Saving model ...
	 Train_Loss: 0.6396 Train_Acc: 66.350 Val_Loss: 0.6289  BEST VAL Loss: 0.6289  Val_Acc: 68.337

Epoch 29: Validation loss decreased (0.628921 --> 0.627797).  Saving model ...
	 Train_Loss: 0.6386 Train_Acc: 66.491 Val_Loss: 0.6278  BEST VAL Loss: 0.6278  Val_Acc: 67.818

Epoch 30: Validation loss decreased (0.627797 --> 0.626680).  Saving model ...
	 Train_Loss: 0.6376 Train_Acc: 66.525 Val_Loss: 0.6267  BEST VAL Loss: 0.6267  Val_Acc: 68.400

Epoch 31: Validation loss decreased (0.626680 --> 0.625515).  Saving model ...
	 Train_Loss: 0.6366 Train_Acc: 66.631 Val_Loss: 0.6255  BEST VAL Loss: 0.6255  Val_Acc: 68.374

Epoch 32: Validation loss decreased (0.625515 --> 0.624494).  Saving model ...
	 Train_Loss: 0.6356 Train_Acc: 66.798 Val_Loss: 0.6245  BEST VAL Loss: 0.6245  Val_Acc: 68.198

Epoch 33: Validation loss decreased (0.624494 --> 0.623388).  Saving model ...
	 Train_Loss: 0.6346 Train_Acc: 66.949 Val_Loss: 0.6234  BEST VAL Loss: 0.6234  Val_Acc: 68.418

Epoch 34: Validation loss decreased (0.623388 --> 0.622316).  Saving model ...
	 Train_Loss: 0.6337 Train_Acc: 66.892 Val_Loss: 0.6223  BEST VAL Loss: 0.6223  Val_Acc: 68.356

Epoch 35: Validation loss decreased (0.622316 --> 0.621523).  Saving model ...
	 Train_Loss: 0.6328 Train_Acc: 67.056 Val_Loss: 0.6215  BEST VAL Loss: 0.6215  Val_Acc: 68.067

Epoch 36: Validation loss decreased (0.621523 --> 0.620514).  Saving model ...
	 Train_Loss: 0.6319 Train_Acc: 67.237 Val_Loss: 0.6205  BEST VAL Loss: 0.6205  Val_Acc: 68.681

Epoch 37: Validation loss decreased (0.620514 --> 0.619542).  Saving model ...
	 Train_Loss: 0.6310 Train_Acc: 67.132 Val_Loss: 0.6195  BEST VAL Loss: 0.6195  Val_Acc: 68.655

Epoch 38: Validation loss decreased (0.619542 --> 0.618685).  Saving model ...
	 Train_Loss: 0.6301 Train_Acc: 67.332 Val_Loss: 0.6187  BEST VAL Loss: 0.6187  Val_Acc: 68.283

Epoch 39: Validation loss decreased (0.618685 --> 0.617746).  Saving model ...
	 Train_Loss: 0.6293 Train_Acc: 67.394 Val_Loss: 0.6177  BEST VAL Loss: 0.6177  Val_Acc: 68.860

Epoch 40: Validation loss decreased (0.617746 --> 0.617032).  Saving model ...
	 Train_Loss: 0.6285 Train_Acc: 67.386 Val_Loss: 0.6170  BEST VAL Loss: 0.6170  Val_Acc: 68.180

Epoch 41: Validation loss decreased (0.617032 --> 0.616173).  Saving model ...
	 Train_Loss: 0.6278 Train_Acc: 67.436 Val_Loss: 0.6162  BEST VAL Loss: 0.6162  Val_Acc: 69.079

Epoch 42: Validation loss decreased (0.616173 --> 0.615505).  Saving model ...
	 Train_Loss: 0.6270 Train_Acc: 67.604 Val_Loss: 0.6155  BEST VAL Loss: 0.6155  Val_Acc: 68.516

Epoch 43: Validation loss decreased (0.615505 --> 0.614805).  Saving model ...
	 Train_Loss: 0.6263 Train_Acc: 67.645 Val_Loss: 0.6148  BEST VAL Loss: 0.6148  Val_Acc: 68.549

Epoch 44: Validation loss decreased (0.614805 --> 0.614098).  Saving model ...
	 Train_Loss: 0.6256 Train_Acc: 67.641 Val_Loss: 0.6141  BEST VAL Loss: 0.6141  Val_Acc: 68.323

Epoch 45: Validation loss decreased (0.614098 --> 0.613326).  Saving model ...
	 Train_Loss: 0.6248 Train_Acc: 67.709 Val_Loss: 0.6133  BEST VAL Loss: 0.6133  Val_Acc: 68.897

Epoch 46: Validation loss decreased (0.613326 --> 0.612610).  Saving model ...
	 Train_Loss: 0.6242 Train_Acc: 67.671 Val_Loss: 0.6126  BEST VAL Loss: 0.6126  Val_Acc: 68.853

Epoch 47: Validation loss decreased (0.612610 --> 0.611832).  Saving model ...
	 Train_Loss: 0.6235 Train_Acc: 67.829 Val_Loss: 0.6118  BEST VAL Loss: 0.6118  Val_Acc: 69.299

Epoch 48: Validation loss decreased (0.611832 --> 0.611168).  Saving model ...
	 Train_Loss: 0.6228 Train_Acc: 67.864 Val_Loss: 0.6112  BEST VAL Loss: 0.6112  Val_Acc: 68.685

Epoch 49: Validation loss decreased (0.611168 --> 0.610663).  Saving model ...
	 Train_Loss: 0.6222 Train_Acc: 67.953 Val_Loss: 0.6107  BEST VAL Loss: 0.6107  Val_Acc: 68.308

Epoch 50: Validation loss decreased (0.610663 --> 0.610018).  Saving model ...
	 Train_Loss: 0.6216 Train_Acc: 67.906 Val_Loss: 0.6100  BEST VAL Loss: 0.6100  Val_Acc: 69.401

Epoch 51: Validation loss decreased (0.610018 --> 0.609412).  Saving model ...
	 Train_Loss: 0.6210 Train_Acc: 67.782 Val_Loss: 0.6094  BEST VAL Loss: 0.6094  Val_Acc: 69.061

Epoch 52: Validation loss decreased (0.609412 --> 0.608762).  Saving model ...
	 Train_Loss: 0.6204 Train_Acc: 67.986 Val_Loss: 0.6088  BEST VAL Loss: 0.6088  Val_Acc: 69.284

Epoch 53: Validation loss decreased (0.608762 --> 0.608093).  Saving model ...
	 Train_Loss: 0.6198 Train_Acc: 68.100 Val_Loss: 0.6081  BEST VAL Loss: 0.6081  Val_Acc: 69.504

Epoch 54: Validation loss decreased (0.608093 --> 0.607554).  Saving model ...
	 Train_Loss: 0.6192 Train_Acc: 68.104 Val_Loss: 0.6076  BEST VAL Loss: 0.6076  Val_Acc: 68.926

Epoch 55: Validation loss decreased (0.607554 --> 0.606993).  Saving model ...
	 Train_Loss: 0.6186 Train_Acc: 67.985 Val_Loss: 0.6070  BEST VAL Loss: 0.6070  Val_Acc: 69.065

Epoch 56: Validation loss decreased (0.606993 --> 0.606433).  Saving model ...
	 Train_Loss: 0.6181 Train_Acc: 68.014 Val_Loss: 0.6064  BEST VAL Loss: 0.6064  Val_Acc: 69.595

Epoch 57: Validation loss decreased (0.606433 --> 0.605847).  Saving model ...
	 Train_Loss: 0.6176 Train_Acc: 68.173 Val_Loss: 0.6058  BEST VAL Loss: 0.6058  Val_Acc: 69.237

Epoch 58: Validation loss decreased (0.605847 --> 0.605302).  Saving model ...
	 Train_Loss: 0.6170 Train_Acc: 68.081 Val_Loss: 0.6053  BEST VAL Loss: 0.6053  Val_Acc: 68.955

Epoch 59: Validation loss decreased (0.605302 --> 0.604813).  Saving model ...
	 Train_Loss: 0.6165 Train_Acc: 68.284 Val_Loss: 0.6048  BEST VAL Loss: 0.6048  Val_Acc: 69.482

Epoch 60: Validation loss decreased (0.604813 --> 0.604225).  Saving model ...
	 Train_Loss: 0.6160 Train_Acc: 68.177 Val_Loss: 0.6042  BEST VAL Loss: 0.6042  Val_Acc: 69.730

Epoch 61: Validation loss decreased (0.604225 --> 0.603672).  Saving model ...
	 Train_Loss: 0.6155 Train_Acc: 68.381 Val_Loss: 0.6037  BEST VAL Loss: 0.6037  Val_Acc: 69.266

Epoch 62: Validation loss decreased (0.603672 --> 0.603164).  Saving model ...
	 Train_Loss: 0.6150 Train_Acc: 68.320 Val_Loss: 0.6032  BEST VAL Loss: 0.6032  Val_Acc: 69.869

Epoch 63: Validation loss decreased (0.603164 --> 0.602637).  Saving model ...
	 Train_Loss: 0.6145 Train_Acc: 68.350 Val_Loss: 0.6026  BEST VAL Loss: 0.6026  Val_Acc: 69.683

Epoch 64: Validation loss decreased (0.602637 --> 0.602146).  Saving model ...
	 Train_Loss: 0.6140 Train_Acc: 68.249 Val_Loss: 0.6021  BEST VAL Loss: 0.6021  Val_Acc: 69.463

Epoch 65: Validation loss decreased (0.602146 --> 0.601658).  Saving model ...
	 Train_Loss: 0.6136 Train_Acc: 68.488 Val_Loss: 0.6017  BEST VAL Loss: 0.6017  Val_Acc: 69.789

Epoch 66: Validation loss decreased (0.601658 --> 0.601193).  Saving model ...
	 Train_Loss: 0.6131 Train_Acc: 68.412 Val_Loss: 0.6012  BEST VAL Loss: 0.6012  Val_Acc: 69.675

Epoch 67: Validation loss decreased (0.601193 --> 0.600708).  Saving model ...
	 Train_Loss: 0.6127 Train_Acc: 68.300 Val_Loss: 0.6007  BEST VAL Loss: 0.6007  Val_Acc: 69.646

Epoch 68: Validation loss decreased (0.600708 --> 0.600270).  Saving model ...
	 Train_Loss: 0.6122 Train_Acc: 68.497 Val_Loss: 0.6003  BEST VAL Loss: 0.6003  Val_Acc: 69.284

Epoch 69: Validation loss decreased (0.600270 --> 0.599827).  Saving model ...
	 Train_Loss: 0.6118 Train_Acc: 68.430 Val_Loss: 0.5998  BEST VAL Loss: 0.5998  Val_Acc: 69.639

Epoch 70: Validation loss decreased (0.599827 --> 0.599433).  Saving model ...
	 Train_Loss: 0.6114 Train_Acc: 68.416 Val_Loss: 0.5994  BEST VAL Loss: 0.5994  Val_Acc: 69.547

Epoch 71: Validation loss decreased (0.599433 --> 0.598968).  Saving model ...
	 Train_Loss: 0.6109 Train_Acc: 68.485 Val_Loss: 0.5990  BEST VAL Loss: 0.5990  Val_Acc: 69.979

Epoch 72: Validation loss decreased (0.598968 --> 0.598519).  Saving model ...
	 Train_Loss: 0.6105 Train_Acc: 68.614 Val_Loss: 0.5985  BEST VAL Loss: 0.5985  Val_Acc: 69.924

Epoch 73: Validation loss decreased (0.598519 --> 0.598090).  Saving model ...
	 Train_Loss: 0.6101 Train_Acc: 68.498 Val_Loss: 0.5981  BEST VAL Loss: 0.5981  Val_Acc: 69.752

Epoch 74: Validation loss decreased (0.598090 --> 0.597723).  Saving model ...
	 Train_Loss: 0.6097 Train_Acc: 68.644 Val_Loss: 0.5977  BEST VAL Loss: 0.5977  Val_Acc: 69.390

Epoch 75: Validation loss decreased (0.597723 --> 0.597328).  Saving model ...
	 Train_Loss: 0.6093 Train_Acc: 68.690 Val_Loss: 0.5973  BEST VAL Loss: 0.5973  Val_Acc: 69.335

Epoch 76: Validation loss decreased (0.597328 --> 0.596942).  Saving model ...
	 Train_Loss: 0.6089 Train_Acc: 68.643 Val_Loss: 0.5969  BEST VAL Loss: 0.5969  Val_Acc: 69.679

Epoch 77: Validation loss decreased (0.596942 --> 0.596570).  Saving model ...
	 Train_Loss: 0.6085 Train_Acc: 68.634 Val_Loss: 0.5966  BEST VAL Loss: 0.5966  Val_Acc: 69.811

Epoch 78: Validation loss decreased (0.596570 --> 0.596168).  Saving model ...
	 Train_Loss: 0.6082 Train_Acc: 68.917 Val_Loss: 0.5962  BEST VAL Loss: 0.5962  Val_Acc: 70.180

Epoch 79: Validation loss decreased (0.596168 --> 0.595785).  Saving model ...
	 Train_Loss: 0.6078 Train_Acc: 68.756 Val_Loss: 0.5958  BEST VAL Loss: 0.5958  Val_Acc: 69.920

Epoch 80: Validation loss decreased (0.595785 --> 0.595447).  Saving model ...
	 Train_Loss: 0.6074 Train_Acc: 68.746 Val_Loss: 0.5954  BEST VAL Loss: 0.5954  Val_Acc: 69.789

Epoch 81: Validation loss decreased (0.595447 --> 0.595225).  Saving model ...
	 Train_Loss: 0.6070 Train_Acc: 68.677 Val_Loss: 0.5952  BEST VAL Loss: 0.5952  Val_Acc: 68.487

Epoch 82: Validation loss decreased (0.595225 --> 0.594855).  Saving model ...
	 Train_Loss: 0.6067 Train_Acc: 68.854 Val_Loss: 0.5949  BEST VAL Loss: 0.5949  Val_Acc: 69.584

Epoch 83: Validation loss decreased (0.594855 --> 0.594457).  Saving model ...
	 Train_Loss: 0.6063 Train_Acc: 68.830 Val_Loss: 0.5945  BEST VAL Loss: 0.5945  Val_Acc: 70.220

Epoch 84: Validation loss decreased (0.594457 --> 0.594098).  Saving model ...
	 Train_Loss: 0.6060 Train_Acc: 68.909 Val_Loss: 0.5941  BEST VAL Loss: 0.5941  Val_Acc: 69.829

Epoch 85: Validation loss decreased (0.594098 --> 0.593704).  Saving model ...
	 Train_Loss: 0.6056 Train_Acc: 68.798 Val_Loss: 0.5937  BEST VAL Loss: 0.5937  Val_Acc: 70.114

Epoch 86: Validation loss decreased (0.593704 --> 0.593354).  Saving model ...
	 Train_Loss: 0.6053 Train_Acc: 68.912 Val_Loss: 0.5934  BEST VAL Loss: 0.5934  Val_Acc: 70.070

Epoch 87: Validation loss decreased (0.593354 --> 0.593050).  Saving model ...
	 Train_Loss: 0.6049 Train_Acc: 69.011 Val_Loss: 0.5931  BEST VAL Loss: 0.5931  Val_Acc: 69.387

Epoch 88: Validation loss decreased (0.593050 --> 0.592702).  Saving model ...
	 Train_Loss: 0.6046 Train_Acc: 69.008 Val_Loss: 0.5927  BEST VAL Loss: 0.5927  Val_Acc: 70.290

Epoch 89: Validation loss decreased (0.592702 --> 0.592349).  Saving model ...
	 Train_Loss: 0.6043 Train_Acc: 69.052 Val_Loss: 0.5923  BEST VAL Loss: 0.5923  Val_Acc: 70.304

Epoch 90: Validation loss decreased (0.592349 --> 0.592012).  Saving model ...
	 Train_Loss: 0.6039 Train_Acc: 68.928 Val_Loss: 0.5920  BEST VAL Loss: 0.5920  Val_Acc: 70.015

Epoch 91: Validation loss decreased (0.592012 --> 0.591652).  Saving model ...
	 Train_Loss: 0.6036 Train_Acc: 69.052 Val_Loss: 0.5917  BEST VAL Loss: 0.5917  Val_Acc: 70.081

Epoch 92: Validation loss decreased (0.591652 --> 0.591321).  Saving model ...
	 Train_Loss: 0.6033 Train_Acc: 69.022 Val_Loss: 0.5913  BEST VAL Loss: 0.5913  Val_Acc: 70.187

Epoch 93: Validation loss decreased (0.591321 --> 0.590965).  Saving model ...
	 Train_Loss: 0.6030 Train_Acc: 69.012 Val_Loss: 0.5910  BEST VAL Loss: 0.5910  Val_Acc: 70.333

Epoch 94: Validation loss decreased (0.590965 --> 0.590684).  Saving model ...
	 Train_Loss: 0.6026 Train_Acc: 69.063 Val_Loss: 0.5907  BEST VAL Loss: 0.5907  Val_Acc: 70.311

Epoch 95: Validation loss decreased (0.590684 --> 0.590339).  Saving model ...
	 Train_Loss: 0.6023 Train_Acc: 68.996 Val_Loss: 0.5903  BEST VAL Loss: 0.5903  Val_Acc: 70.359

Epoch 96: Validation loss decreased (0.590339 --> 0.590040).  Saving model ...
	 Train_Loss: 0.6020 Train_Acc: 69.144 Val_Loss: 0.5900  BEST VAL Loss: 0.5900  Val_Acc: 70.209

Epoch 97: Validation loss decreased (0.590040 --> 0.589752).  Saving model ...
	 Train_Loss: 0.6017 Train_Acc: 69.032 Val_Loss: 0.5898  BEST VAL Loss: 0.5898  Val_Acc: 70.322

Epoch 98: Validation loss decreased (0.589752 --> 0.589476).  Saving model ...
	 Train_Loss: 0.6014 Train_Acc: 69.090 Val_Loss: 0.5895  BEST VAL Loss: 0.5895  Val_Acc: 70.622

Epoch 99: Validation loss decreased (0.589476 --> 0.589222).  Saving model ...
	 Train_Loss: 0.6011 Train_Acc: 69.174 Val_Loss: 0.5892  BEST VAL Loss: 0.5892  Val_Acc: 69.957

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.52      0.51    109598
           1       0.50      0.48      0.49    109228

    accuracy                           0.50    218826
   macro avg       0.50      0.50      0.50    218826
weighted avg       0.50      0.50      0.50    218826

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.52      0.51     13700
           1       0.49      0.47      0.48     13654

    accuracy                           0.50     27354
   macro avg       0.50      0.50      0.49     27354
weighted avg       0.50      0.50      0.49     27354

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.51      0.50     13700
           1       0.50      0.49      0.49     13654

    accuracy                           0.50     27354
   macro avg       0.50      0.50      0.50     27354
weighted avg       0.50      0.50      0.50     27354

              precision    recall  f1-score   support

           0       0.50      0.51      0.50     13700
           1       0.50      0.49      0.49     13654

    accuracy                           0.50     27354
   macro avg       0.50      0.50      0.50     27354
weighted avg       0.50      0.50      0.50     27354

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.54      0.62      0.58     44168
           1       0.46      0.38      0.41     37725

    accuracy                           0.51     81893
   macro avg       0.50      0.50      0.50     81893
weighted avg       0.50      0.51      0.50     81893

              precision    recall  f1-score   support

           0       0.54      0.62      0.58     44168
           1       0.46      0.38      0.41     37725

    accuracy                           0.51     81893
   macro avg       0.50      0.50      0.50     81893
weighted avg       0.50      0.51      0.50     81893

completed
