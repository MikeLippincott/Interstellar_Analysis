[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd3b7f015'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '1f950f73'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '3d5519f6'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e2dcd066'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: DMSO_0.100_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: DMSO_0.100_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (51861, 1276)
Number of total missing values across all columns: 71286
Data Subset Is Off
Wells held out for testing: ['I14' 'K21']
Wells to use for training, validation, and testing ['B14' 'C14' 'B15' 'C15' 'J14' 'I15' 'J15' 'K16' 'K17' 'K20']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.239606).  Saving model ...
	 Train_Loss: 0.3965 Train_Acc: 82.100 Val_Loss: 0.2396  BEST VAL Loss: 0.2396  Val_Acc: 91.032

Epoch 1: Validation loss decreased (0.239606 --> 0.203271).  Saving model ...
	 Train_Loss: 0.3232 Train_Acc: 89.663 Val_Loss: 0.2033  BEST VAL Loss: 0.2033  Val_Acc: 93.982

Epoch 2: Validation loss decreased (0.203271 --> 0.177708).  Saving model ...
	 Train_Loss: 0.2850 Train_Acc: 91.647 Val_Loss: 0.1777  BEST VAL Loss: 0.1777  Val_Acc: 94.703

Epoch 3: Validation loss decreased (0.177708 --> 0.165581).  Saving model ...
	 Train_Loss: 0.2590 Train_Acc: 92.693 Val_Loss: 0.1656  BEST VAL Loss: 0.1656  Val_Acc: 95.376

Epoch 4: Validation loss decreased (0.165581 --> 0.158488).  Saving model ...
	 Train_Loss: 0.2415 Train_Acc: 93.337 Val_Loss: 0.1585  BEST VAL Loss: 0.1585  Val_Acc: 95.516

Epoch 5: Validation loss decreased (0.158488 --> 0.154857).  Saving model ...
	 Train_Loss: 0.2279 Train_Acc: 93.689 Val_Loss: 0.1549  BEST VAL Loss: 0.1549  Val_Acc: 95.888

Epoch 6: Validation loss decreased (0.154857 --> 0.149594).  Saving model ...
	 Train_Loss: 0.2180 Train_Acc: 93.886 Val_Loss: 0.1496  BEST VAL Loss: 0.1496  Val_Acc: 96.073

Epoch 7: Validation loss decreased (0.149594 --> 0.147913).  Saving model ...
	 Train_Loss: 0.2092 Train_Acc: 94.241 Val_Loss: 0.1479  BEST VAL Loss: 0.1479  Val_Acc: 96.097

Epoch 8: Validation loss decreased (0.147913 --> 0.144846).  Saving model ...
	 Train_Loss: 0.2015 Train_Acc: 94.618 Val_Loss: 0.1448  BEST VAL Loss: 0.1448  Val_Acc: 96.329

Epoch 9: Validation loss decreased (0.144846 --> 0.142152).  Saving model ...
	 Train_Loss: 0.1951 Train_Acc: 94.659 Val_Loss: 0.1422  BEST VAL Loss: 0.1422  Val_Acc: 96.375

Epoch 10: Validation loss decreased (0.142152 --> 0.139987).  Saving model ...
	 Train_Loss: 0.1893 Train_Acc: 94.836 Val_Loss: 0.1400  BEST VAL Loss: 0.1400  Val_Acc: 96.143

Epoch 11: Validation loss did not decrease
	 Train_Loss: 0.1844 Train_Acc: 94.944 Val_Loss: 0.1406  BEST VAL Loss: 0.1400  Val_Acc: 96.329

Epoch 12: Validation loss decreased (0.139987 --> 0.139375).  Saving model ...
	 Train_Loss: 0.1796 Train_Acc: 95.007 Val_Loss: 0.1394  BEST VAL Loss: 0.1394  Val_Acc: 96.445

Epoch 13: Validation loss decreased (0.139375 --> 0.138527).  Saving model ...
	 Train_Loss: 0.1754 Train_Acc: 95.339 Val_Loss: 0.1385  BEST VAL Loss: 0.1385  Val_Acc: 95.980

Epoch 14: Validation loss decreased (0.138527 --> 0.137395).  Saving model ...
	 Train_Loss: 0.1717 Train_Acc: 95.263 Val_Loss: 0.1374  BEST VAL Loss: 0.1374  Val_Acc: 96.306

Epoch 15: Validation loss did not decrease
	 Train_Loss: 0.1683 Train_Acc: 95.272 Val_Loss: 0.1388  BEST VAL Loss: 0.1374  Val_Acc: 96.422

Epoch 16: Validation loss did not decrease
	 Train_Loss: 0.1652 Train_Acc: 95.524 Val_Loss: 0.1377  BEST VAL Loss: 0.1374  Val_Acc: 96.283

Epoch 17: Validation loss decreased (0.137395 --> 0.137096).  Saving model ...
	 Train_Loss: 0.1626 Train_Acc: 95.217 Val_Loss: 0.1371  BEST VAL Loss: 0.1371  Val_Acc: 96.375

Epoch 18: Validation loss decreased (0.137096 --> 0.136764).  Saving model ...
	 Train_Loss: 0.1599 Train_Acc: 95.431 Val_Loss: 0.1368  BEST VAL Loss: 0.1368  Val_Acc: 96.213

Epoch 19: Validation loss did not decrease
	 Train_Loss: 0.1576 Train_Acc: 95.353 Val_Loss: 0.1369  BEST VAL Loss: 0.1368  Val_Acc: 96.143

Epoch 20: Validation loss decreased (0.136764 --> 0.136556).  Saving model ...
	 Train_Loss: 0.1554 Train_Acc: 95.588 Val_Loss: 0.1366  BEST VAL Loss: 0.1366  Val_Acc: 96.561

Epoch 21: Validation loss decreased (0.136556 --> 0.136050).  Saving model ...
	 Train_Loss: 0.1531 Train_Acc: 95.853 Val_Loss: 0.1360  BEST VAL Loss: 0.1360  Val_Acc: 96.468

Epoch 22: Validation loss decreased (0.136050 --> 0.135507).  Saving model ...
	 Train_Loss: 0.1512 Train_Acc: 95.466 Val_Loss: 0.1355  BEST VAL Loss: 0.1355  Val_Acc: 96.747

Epoch 23: Validation loss decreased (0.135507 --> 0.135358).  Saving model ...
	 Train_Loss: 0.1493 Train_Acc: 95.835 Val_Loss: 0.1354  BEST VAL Loss: 0.1354  Val_Acc: 96.306

Epoch 24: Validation loss decreased (0.135358 --> 0.135053).  Saving model ...
	 Train_Loss: 0.1474 Train_Acc: 95.861 Val_Loss: 0.1351  BEST VAL Loss: 0.1351  Val_Acc: 96.445

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.1456 Train_Acc: 95.940 Val_Loss: 0.1359  BEST VAL Loss: 0.1351  Val_Acc: 96.840

Epoch 26: Validation loss did not decrease
	 Train_Loss: 0.1438 Train_Acc: 96.067 Val_Loss: 0.1356  BEST VAL Loss: 0.1351  Val_Acc: 96.468

Epoch 27: Validation loss decreased (0.135053 --> 0.134877).  Saving model ...
	 Train_Loss: 0.1422 Train_Acc: 96.015 Val_Loss: 0.1349  BEST VAL Loss: 0.1349  Val_Acc: 96.863

Epoch 28: Validation loss decreased (0.134877 --> 0.134804).  Saving model ...
	 Train_Loss: 0.1409 Train_Acc: 95.748 Val_Loss: 0.1348  BEST VAL Loss: 0.1348  Val_Acc: 96.933

Epoch 29: Validation loss decreased (0.134804 --> 0.134736).  Saving model ...
	 Train_Loss: 0.1394 Train_Acc: 96.033 Val_Loss: 0.1347  BEST VAL Loss: 0.1347  Val_Acc: 95.911

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.1382 Train_Acc: 95.873 Val_Loss: 0.1348  BEST VAL Loss: 0.1347  Val_Acc: 96.422

Epoch 31: Validation loss decreased (0.134736 --> 0.134636).  Saving model ...
	 Train_Loss: 0.1369 Train_Acc: 96.111 Val_Loss: 0.1346  BEST VAL Loss: 0.1346  Val_Acc: 96.770

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.1358 Train_Acc: 96.056 Val_Loss: 0.1348  BEST VAL Loss: 0.1346  Val_Acc: 96.445

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.1344 Train_Acc: 96.288 Val_Loss: 0.1351  BEST VAL Loss: 0.1346  Val_Acc: 96.608

Epoch 34: Validation loss did not decrease
	 Train_Loss: 0.1333 Train_Acc: 96.091 Val_Loss: 0.1349  BEST VAL Loss: 0.1346  Val_Acc: 96.468

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.1321 Train_Acc: 96.227 Val_Loss: 0.1348  BEST VAL Loss: 0.1346  Val_Acc: 96.840

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.1310 Train_Acc: 96.137 Val_Loss: 0.1348  BEST VAL Loss: 0.1346  Val_Acc: 96.794

Epoch 37: Validation loss decreased (0.134636 --> 0.134334).  Saving model ...
	 Train_Loss: 0.1301 Train_Acc: 96.059 Val_Loss: 0.1343  BEST VAL Loss: 0.1343  Val_Acc: 96.794

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.1290 Train_Acc: 96.367 Val_Loss: 0.1346  BEST VAL Loss: 0.1343  Val_Acc: 96.608

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.1281 Train_Acc: 96.239 Val_Loss: 0.1362  BEST VAL Loss: 0.1343  Val_Acc: 96.701

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.1272 Train_Acc: 96.282 Val_Loss: 0.1359  BEST VAL Loss: 0.1343  Val_Acc: 96.678

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.1264 Train_Acc: 96.030 Val_Loss: 0.1363  BEST VAL Loss: 0.1343  Val_Acc: 96.654

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.1255 Train_Acc: 96.323 Val_Loss: 0.1363  BEST VAL Loss: 0.1343  Val_Acc: 96.631

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.1246 Train_Acc: 96.381 Val_Loss: 0.1368  BEST VAL Loss: 0.1343  Val_Acc: 96.631

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.1238 Train_Acc: 96.329 Val_Loss: 0.1369  BEST VAL Loss: 0.1343  Val_Acc: 96.585

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.1230 Train_Acc: 96.268 Val_Loss: 0.1370  BEST VAL Loss: 0.1343  Val_Acc: 96.887

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.1222 Train_Acc: 96.515 Val_Loss: 0.1386  BEST VAL Loss: 0.1343  Val_Acc: 96.701

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.1215 Train_Acc: 96.172 Val_Loss: 0.1387  BEST VAL Loss: 0.1343  Val_Acc: 96.770

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.1208 Train_Acc: 96.640 Val_Loss: 0.1392  BEST VAL Loss: 0.1343  Val_Acc: 96.863

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.1201 Train_Acc: 96.117 Val_Loss: 0.1393  BEST VAL Loss: 0.1343  Val_Acc: 96.794

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.1195 Train_Acc: 96.288 Val_Loss: 0.1404  BEST VAL Loss: 0.1343  Val_Acc: 96.956

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.1188 Train_Acc: 96.329 Val_Loss: 0.1406  BEST VAL Loss: 0.1343  Val_Acc: 96.840

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.1182 Train_Acc: 96.558 Val_Loss: 0.1402  BEST VAL Loss: 0.1343  Val_Acc: 96.701

Epoch 53: Validation loss did not decrease
Early stopped at epoch : 53
DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.71      0.72      0.72     24644
           1       0.28      0.28      0.28      9787

    accuracy                           0.59     34431
   macro avg       0.50      0.50      0.50     34431
weighted avg       0.59      0.59      0.59     34431

DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.73      0.73      0.73      3081
           1       0.31      0.31      0.31      1223

    accuracy                           0.61      4304
   macro avg       0.52      0.52      0.52      4304
weighted avg       0.61      0.61      0.61      4304

DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.71      0.72      0.72      3081
           1       0.28      0.28      0.28      1223

    accuracy                           0.59      4304
   macro avg       0.50      0.50      0.50      4304
weighted avg       0.59      0.59      0.59      4304

              precision    recall  f1-score   support

           0       0.71      0.72      0.72      3081
           1       0.28      0.28      0.28      1223

    accuracy                           0.59      4304
   macro avg       0.50      0.50      0.50      4304
weighted avg       0.59      0.59      0.59      4304

DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.57      0.56      4837
           1       0.46      0.44      0.45      3985

    accuracy                           0.51      8822
   macro avg       0.51      0.51      0.51      8822
weighted avg       0.51      0.51      0.51      8822

              precision    recall  f1-score   support

           0       0.55      0.57      0.56      4837
           1       0.46      0.44      0.45      3985

    accuracy                           0.51      8822
   macro avg       0.51      0.51      0.51      8822
weighted avg       0.51      0.51      0.51      8822

completed
