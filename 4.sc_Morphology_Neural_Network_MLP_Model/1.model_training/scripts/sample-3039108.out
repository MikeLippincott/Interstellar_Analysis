[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b63c82aa'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '50851658'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '5d858af2'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'badfc8a5'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_1.000_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (31668, 1276)
Number of total missing values across all columns: 63336
Data Subset Is Off
Wells held out for testing: ['B16' 'M22']
Wells to use for training, validation, and testing ['B17' 'B20' 'B21' 'M18' 'M19' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.692339).  Saving model ...
	 Train_Loss: 0.6989 Train_Acc: 50.518 Val_Loss: 0.6923  BEST VAL Loss: 0.6923  Val_Acc: 53.593

Epoch 1: Validation loss decreased (0.692339 --> 0.690497).  Saving model ...
	 Train_Loss: 0.6955 Train_Acc: 51.903 Val_Loss: 0.6905  BEST VAL Loss: 0.6905  Val_Acc: 58.199

Epoch 2: Validation loss decreased (0.690497 --> 0.688944).  Saving model ...
	 Train_Loss: 0.6939 Train_Acc: 53.303 Val_Loss: 0.6889  BEST VAL Loss: 0.6889  Val_Acc: 57.904

Epoch 3: Validation loss decreased (0.688944 --> 0.687855).  Saving model ...
	 Train_Loss: 0.6930 Train_Acc: 53.721 Val_Loss: 0.6879  BEST VAL Loss: 0.6879  Val_Acc: 59.594

Epoch 4: Validation loss decreased (0.687855 --> 0.686707).  Saving model ...
	 Train_Loss: 0.6923 Train_Acc: 54.418 Val_Loss: 0.6867  BEST VAL Loss: 0.6867  Val_Acc: 60.735

Epoch 5: Validation loss decreased (0.686707 --> 0.685764).  Saving model ...
	 Train_Loss: 0.6916 Train_Acc: 55.116 Val_Loss: 0.6858  BEST VAL Loss: 0.6858  Val_Acc: 61.200

Epoch 6: Validation loss decreased (0.685764 --> 0.684999).  Saving model ...
	 Train_Loss: 0.6911 Train_Acc: 54.577 Val_Loss: 0.6850  BEST VAL Loss: 0.6850  Val_Acc: 61.327

Epoch 7: Validation loss decreased (0.684999 --> 0.684291).  Saving model ...
	 Train_Loss: 0.6906 Train_Acc: 55.544 Val_Loss: 0.6843  BEST VAL Loss: 0.6843  Val_Acc: 61.623

Epoch 8: Validation loss decreased (0.684291 --> 0.683663).  Saving model ...
	 Train_Loss: 0.6902 Train_Acc: 55.322 Val_Loss: 0.6837  BEST VAL Loss: 0.6837  Val_Acc: 62.342

Epoch 9: Validation loss decreased (0.683663 --> 0.683005).  Saving model ...
	 Train_Loss: 0.6898 Train_Acc: 56.252 Val_Loss: 0.6830  BEST VAL Loss: 0.6830  Val_Acc: 61.538

Epoch 10: Validation loss decreased (0.683005 --> 0.682537).  Saving model ...
	 Train_Loss: 0.6895 Train_Acc: 55.734 Val_Loss: 0.6825  BEST VAL Loss: 0.6825  Val_Acc: 61.412

Epoch 11: Validation loss decreased (0.682537 --> 0.681930).  Saving model ...
	 Train_Loss: 0.6892 Train_Acc: 56.485 Val_Loss: 0.6819  BEST VAL Loss: 0.6819  Val_Acc: 61.961

Epoch 12: Validation loss decreased (0.681930 --> 0.681322).  Saving model ...
	 Train_Loss: 0.6889 Train_Acc: 56.315 Val_Loss: 0.6813  BEST VAL Loss: 0.6813  Val_Acc: 63.018

Epoch 13: Validation loss decreased (0.681322 --> 0.680730).  Saving model ...
	 Train_Loss: 0.6887 Train_Acc: 56.130 Val_Loss: 0.6807  BEST VAL Loss: 0.6807  Val_Acc: 63.398

Epoch 14: Validation loss decreased (0.680730 --> 0.680224).  Saving model ...
	 Train_Loss: 0.6884 Train_Acc: 57.150 Val_Loss: 0.6802  BEST VAL Loss: 0.6802  Val_Acc: 63.060

Epoch 15: Validation loss decreased (0.680224 --> 0.679790).  Saving model ...
	 Train_Loss: 0.6883 Train_Acc: 55.650 Val_Loss: 0.6798  BEST VAL Loss: 0.6798  Val_Acc: 62.891

Epoch 16: Validation loss decreased (0.679790 --> 0.679136).  Saving model ...
	 Train_Loss: 0.6880 Train_Acc: 56.733 Val_Loss: 0.6791  BEST VAL Loss: 0.6791  Val_Acc: 64.117

Epoch 17: Validation loss decreased (0.679136 --> 0.678422).  Saving model ...
	 Train_Loss: 0.6877 Train_Acc: 57.785 Val_Loss: 0.6784  BEST VAL Loss: 0.6784  Val_Acc: 65.342

Epoch 18: Validation loss decreased (0.678422 --> 0.677732).  Saving model ...
	 Train_Loss: 0.6874 Train_Acc: 57.832 Val_Loss: 0.6777  BEST VAL Loss: 0.6777  Val_Acc: 64.286

Epoch 19: Validation loss decreased (0.677732 --> 0.677233).  Saving model ...
	 Train_Loss: 0.6872 Train_Acc: 57.547 Val_Loss: 0.6772  BEST VAL Loss: 0.6772  Val_Acc: 64.793

Epoch 20: Validation loss decreased (0.677233 --> 0.676822).  Saving model ...
	 Train_Loss: 0.6869 Train_Acc: 58.102 Val_Loss: 0.6768  BEST VAL Loss: 0.6768  Val_Acc: 64.370

Epoch 21: Validation loss decreased (0.676822 --> 0.676377).  Saving model ...
	 Train_Loss: 0.6867 Train_Acc: 57.689 Val_Loss: 0.6764  BEST VAL Loss: 0.6764  Val_Acc: 65.511

Epoch 22: Validation loss decreased (0.676377 --> 0.675913).  Saving model ...
	 Train_Loss: 0.6864 Train_Acc: 58.651 Val_Loss: 0.6759  BEST VAL Loss: 0.6759  Val_Acc: 64.201

Epoch 23: Validation loss decreased (0.675913 --> 0.675338).  Saving model ...
	 Train_Loss: 0.6862 Train_Acc: 57.240 Val_Loss: 0.6753  BEST VAL Loss: 0.6753  Val_Acc: 65.892

Epoch 24: Validation loss decreased (0.675338 --> 0.674738).  Saving model ...
	 Train_Loss: 0.6859 Train_Acc: 58.572 Val_Loss: 0.6747  BEST VAL Loss: 0.6747  Val_Acc: 66.103

Epoch 25: Validation loss decreased (0.674738 --> 0.674305).  Saving model ...
	 Train_Loss: 0.6857 Train_Acc: 57.552 Val_Loss: 0.6743  BEST VAL Loss: 0.6743  Val_Acc: 65.638

Epoch 26: Validation loss decreased (0.674305 --> 0.673944).  Saving model ...
	 Train_Loss: 0.6855 Train_Acc: 58.244 Val_Loss: 0.6739  BEST VAL Loss: 0.6739  Val_Acc: 64.962

Epoch 27: Validation loss decreased (0.673944 --> 0.673555).  Saving model ...
	 Train_Loss: 0.6853 Train_Acc: 57.748 Val_Loss: 0.6736  BEST VAL Loss: 0.6736  Val_Acc: 65.807

Epoch 28: Validation loss decreased (0.673555 --> 0.673154).  Saving model ...
	 Train_Loss: 0.6850 Train_Acc: 59.502 Val_Loss: 0.6732  BEST VAL Loss: 0.6732  Val_Acc: 66.230

Epoch 29: Validation loss decreased (0.673154 --> 0.672774).  Saving model ...
	 Train_Loss: 0.6849 Train_Acc: 58.461 Val_Loss: 0.6728  BEST VAL Loss: 0.6728  Val_Acc: 65.892

Epoch 30: Validation loss decreased (0.672774 --> 0.672430).  Saving model ...
	 Train_Loss: 0.6847 Train_Acc: 58.197 Val_Loss: 0.6724  BEST VAL Loss: 0.6724  Val_Acc: 66.188

Epoch 31: Validation loss decreased (0.672430 --> 0.672067).  Saving model ...
	 Train_Loss: 0.6845 Train_Acc: 58.308 Val_Loss: 0.6721  BEST VAL Loss: 0.6721  Val_Acc: 66.526

Epoch 32: Validation loss decreased (0.672067 --> 0.671784).  Saving model ...
	 Train_Loss: 0.6844 Train_Acc: 58.059 Val_Loss: 0.6718  BEST VAL Loss: 0.6718  Val_Acc: 66.864

Epoch 33: Validation loss decreased (0.671784 --> 0.671510).  Saving model ...
	 Train_Loss: 0.6842 Train_Acc: 58.773 Val_Loss: 0.6715  BEST VAL Loss: 0.6715  Val_Acc: 65.638

Epoch 34: Validation loss decreased (0.671510 --> 0.671209).  Saving model ...
	 Train_Loss: 0.6841 Train_Acc: 58.292 Val_Loss: 0.6712  BEST VAL Loss: 0.6712  Val_Acc: 65.469

Epoch 35: Validation loss decreased (0.671209 --> 0.670810).  Saving model ...
	 Train_Loss: 0.6839 Train_Acc: 59.492 Val_Loss: 0.6708  BEST VAL Loss: 0.6708  Val_Acc: 66.779

Epoch 36: Validation loss decreased (0.670810 --> 0.670458).  Saving model ...
	 Train_Loss: 0.6837 Train_Acc: 59.359 Val_Loss: 0.6705  BEST VAL Loss: 0.6705  Val_Acc: 66.314

Epoch 37: Validation loss decreased (0.670458 --> 0.670115).  Saving model ...
	 Train_Loss: 0.6835 Train_Acc: 60.047 Val_Loss: 0.6701  BEST VAL Loss: 0.6701  Val_Acc: 66.230

Epoch 38: Validation loss decreased (0.670115 --> 0.669817).  Saving model ...
	 Train_Loss: 0.6833 Train_Acc: 58.715 Val_Loss: 0.6698  BEST VAL Loss: 0.6698  Val_Acc: 66.568

Epoch 39: Validation loss decreased (0.669817 --> 0.669460).  Saving model ...
	 Train_Loss: 0.6832 Train_Acc: 58.852 Val_Loss: 0.6695  BEST VAL Loss: 0.6695  Val_Acc: 67.878

Epoch 40: Validation loss decreased (0.669460 --> 0.669031).  Saving model ...
	 Train_Loss: 0.6831 Train_Acc: 57.911 Val_Loss: 0.6690  BEST VAL Loss: 0.6690  Val_Acc: 67.963

Epoch 41: Validation loss decreased (0.669031 --> 0.668702).  Saving model ...
	 Train_Loss: 0.6830 Train_Acc: 58.561 Val_Loss: 0.6687  BEST VAL Loss: 0.6687  Val_Acc: 68.428

Epoch 42: Validation loss decreased (0.668702 --> 0.668326).  Saving model ...
	 Train_Loss: 0.6828 Train_Acc: 59.581 Val_Loss: 0.6683  BEST VAL Loss: 0.6683  Val_Acc: 67.329

Epoch 43: Validation loss decreased (0.668326 --> 0.667933).  Saving model ...
	 Train_Loss: 0.6827 Train_Acc: 59.597 Val_Loss: 0.6679  BEST VAL Loss: 0.6679  Val_Acc: 67.963

Epoch 44: Validation loss decreased (0.667933 --> 0.667623).  Saving model ...
	 Train_Loss: 0.6825 Train_Acc: 58.588 Val_Loss: 0.6676  BEST VAL Loss: 0.6676  Val_Acc: 68.259

Epoch 45: Validation loss decreased (0.667623 --> 0.667352).  Saving model ...
	 Train_Loss: 0.6824 Train_Acc: 59.629 Val_Loss: 0.6674  BEST VAL Loss: 0.6674  Val_Acc: 67.244

Epoch 46: Validation loss decreased (0.667352 --> 0.667091).  Saving model ...
	 Train_Loss: 0.6822 Train_Acc: 59.798 Val_Loss: 0.6671  BEST VAL Loss: 0.6671  Val_Acc: 66.906

Epoch 47: Validation loss decreased (0.667091 --> 0.666894).  Saving model ...
	 Train_Loss: 0.6821 Train_Acc: 59.428 Val_Loss: 0.6669  BEST VAL Loss: 0.6669  Val_Acc: 66.864

Epoch 48: Validation loss decreased (0.666894 --> 0.666541).  Saving model ...
	 Train_Loss: 0.6820 Train_Acc: 59.925 Val_Loss: 0.6665  BEST VAL Loss: 0.6665  Val_Acc: 67.751

Epoch 49: Validation loss decreased (0.666541 --> 0.666300).  Saving model ...
	 Train_Loss: 0.6819 Train_Acc: 58.588 Val_Loss: 0.6663  BEST VAL Loss: 0.6663  Val_Acc: 67.413

Epoch 50: Validation loss decreased (0.666300 --> 0.666064).  Saving model ...
	 Train_Loss: 0.6818 Train_Acc: 59.285 Val_Loss: 0.6661  BEST VAL Loss: 0.6661  Val_Acc: 66.653

Epoch 51: Validation loss decreased (0.666064 --> 0.665899).  Saving model ...
	 Train_Loss: 0.6817 Train_Acc: 58.503 Val_Loss: 0.6659  BEST VAL Loss: 0.6659  Val_Acc: 66.991

Epoch 52: Validation loss decreased (0.665899 --> 0.665626).  Saving model ...
	 Train_Loss: 0.6816 Train_Acc: 59.587 Val_Loss: 0.6656  BEST VAL Loss: 0.6656  Val_Acc: 67.498

Epoch 53: Validation loss decreased (0.665626 --> 0.665426).  Saving model ...
	 Train_Loss: 0.6815 Train_Acc: 59.486 Val_Loss: 0.6654  BEST VAL Loss: 0.6654  Val_Acc: 66.737

Epoch 54: Validation loss decreased (0.665426 --> 0.665403).  Saving model ...
	 Train_Loss: 0.6814 Train_Acc: 58.979 Val_Loss: 0.6654  BEST VAL Loss: 0.6654  Val_Acc: 63.694

Epoch 55: Validation loss decreased (0.665403 --> 0.665372).  Saving model ...
	 Train_Loss: 0.6814 Train_Acc: 57.726 Val_Loss: 0.6654  BEST VAL Loss: 0.6654  Val_Acc: 65.469

Epoch 56: Validation loss decreased (0.665372 --> 0.665307).  Saving model ...
	 Train_Loss: 0.6814 Train_Acc: 58.165 Val_Loss: 0.6653  BEST VAL Loss: 0.6653  Val_Acc: 65.300

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.6814 Train_Acc: 57.494 Val_Loss: 0.6653  BEST VAL Loss: 0.6653  Val_Acc: 64.708

Epoch 58: Validation loss decreased (0.665307 --> 0.665224).  Saving model ...
	 Train_Loss: 0.6813 Train_Acc: 59.116 Val_Loss: 0.6652  BEST VAL Loss: 0.6652  Val_Acc: 65.469

Epoch 59: Validation loss decreased (0.665224 --> 0.665166).  Saving model ...
	 Train_Loss: 0.6813 Train_Acc: 58.049 Val_Loss: 0.6652  BEST VAL Loss: 0.6652  Val_Acc: 66.188

Epoch 60: Validation loss decreased (0.665166 --> 0.665022).  Saving model ...
	 Train_Loss: 0.6812 Train_Acc: 58.096 Val_Loss: 0.6650  BEST VAL Loss: 0.6650  Val_Acc: 66.441

Epoch 61: Validation loss decreased (0.665022 --> 0.664928).  Saving model ...
	 Train_Loss: 0.6812 Train_Acc: 58.884 Val_Loss: 0.6649  BEST VAL Loss: 0.6649  Val_Acc: 66.103

Epoch 62: Validation loss decreased (0.664928 --> 0.664821).  Saving model ...
	 Train_Loss: 0.6811 Train_Acc: 58.815 Val_Loss: 0.6648  BEST VAL Loss: 0.6648  Val_Acc: 66.188

Epoch 63: Validation loss decreased (0.664821 --> 0.664705).  Saving model ...
	 Train_Loss: 0.6810 Train_Acc: 59.058 Val_Loss: 0.6647  BEST VAL Loss: 0.6647  Val_Acc: 66.188

Epoch 64: Validation loss decreased (0.664705 --> 0.664640).  Saving model ...
	 Train_Loss: 0.6810 Train_Acc: 58.757 Val_Loss: 0.6646  BEST VAL Loss: 0.6646  Val_Acc: 65.638

Epoch 65: Validation loss decreased (0.664640 --> 0.664562).  Saving model ...
	 Train_Loss: 0.6810 Train_Acc: 58.604 Val_Loss: 0.6646  BEST VAL Loss: 0.6646  Val_Acc: 66.188

Epoch 66: Validation loss decreased (0.664562 --> 0.664443).  Saving model ...
	 Train_Loss: 0.6809 Train_Acc: 59.518 Val_Loss: 0.6644  BEST VAL Loss: 0.6644  Val_Acc: 66.610

Epoch 67: Validation loss decreased (0.664443 --> 0.664347).  Saving model ...
	 Train_Loss: 0.6809 Train_Acc: 58.857 Val_Loss: 0.6643  BEST VAL Loss: 0.6643  Val_Acc: 65.511

Epoch 68: Validation loss decreased (0.664347 --> 0.664218).  Saving model ...
	 Train_Loss: 0.6808 Train_Acc: 58.894 Val_Loss: 0.6642  BEST VAL Loss: 0.6642  Val_Acc: 66.610

Epoch 69: Validation loss decreased (0.664218 --> 0.664114).  Saving model ...
	 Train_Loss: 0.6808 Train_Acc: 59.359 Val_Loss: 0.6641  BEST VAL Loss: 0.6641  Val_Acc: 66.653

Epoch 70: Validation loss decreased (0.664114 --> 0.664062).  Saving model ...
	 Train_Loss: 0.6807 Train_Acc: 58.435 Val_Loss: 0.6641  BEST VAL Loss: 0.6641  Val_Acc: 65.934

Epoch 71: Validation loss decreased (0.664062 --> 0.663941).  Saving model ...
	 Train_Loss: 0.6807 Train_Acc: 58.842 Val_Loss: 0.6639  BEST VAL Loss: 0.6639  Val_Acc: 66.399

Epoch 72: Validation loss decreased (0.663941 --> 0.663895).  Saving model ...
	 Train_Loss: 0.6807 Train_Acc: 58.387 Val_Loss: 0.6639  BEST VAL Loss: 0.6639  Val_Acc: 66.399

Epoch 73: Validation loss decreased (0.663895 --> 0.663835).  Saving model ...
	 Train_Loss: 0.6806 Train_Acc: 59.655 Val_Loss: 0.6638  BEST VAL Loss: 0.6638  Val_Acc: 65.892

Epoch 74: Validation loss decreased (0.663835 --> 0.663746).  Saving model ...
	 Train_Loss: 0.6806 Train_Acc: 59.021 Val_Loss: 0.6637  BEST VAL Loss: 0.6637  Val_Acc: 66.441

Epoch 75: Validation loss decreased (0.663746 --> 0.663651).  Saving model ...
	 Train_Loss: 0.6805 Train_Acc: 59.502 Val_Loss: 0.6637  BEST VAL Loss: 0.6637  Val_Acc: 66.357

Epoch 76: Validation loss decreased (0.663651 --> 0.663563).  Saving model ...
	 Train_Loss: 0.6805 Train_Acc: 59.270 Val_Loss: 0.6636  BEST VAL Loss: 0.6636  Val_Acc: 66.061

Epoch 77: Validation loss decreased (0.663563 --> 0.663481).  Saving model ...
	 Train_Loss: 0.6804 Train_Acc: 59.148 Val_Loss: 0.6635  BEST VAL Loss: 0.6635  Val_Acc: 65.723

Epoch 78: Validation loss decreased (0.663481 --> 0.663424).  Saving model ...
	 Train_Loss: 0.6804 Train_Acc: 58.207 Val_Loss: 0.6634  BEST VAL Loss: 0.6634  Val_Acc: 66.653

Epoch 79: Validation loss decreased (0.663424 --> 0.663341).  Saving model ...
	 Train_Loss: 0.6804 Train_Acc: 58.953 Val_Loss: 0.6633  BEST VAL Loss: 0.6633  Val_Acc: 66.526

Epoch 80: Validation loss decreased (0.663341 --> 0.663261).  Saving model ...
	 Train_Loss: 0.6803 Train_Acc: 58.456 Val_Loss: 0.6633  BEST VAL Loss: 0.6633  Val_Acc: 67.329

Epoch 81: Validation loss decreased (0.663261 --> 0.663184).  Saving model ...
	 Train_Loss: 0.6803 Train_Acc: 58.044 Val_Loss: 0.6632  BEST VAL Loss: 0.6632  Val_Acc: 68.174

Epoch 82: Validation loss decreased (0.663184 --> 0.663076).  Saving model ...
	 Train_Loss: 0.6803 Train_Acc: 59.328 Val_Loss: 0.6631  BEST VAL Loss: 0.6631  Val_Acc: 67.582

Epoch 83: Validation loss decreased (0.663076 --> 0.662963).  Saving model ...
	 Train_Loss: 0.6803 Train_Acc: 59.058 Val_Loss: 0.6630  BEST VAL Loss: 0.6630  Val_Acc: 67.202

Epoch 84: Validation loss decreased (0.662963 --> 0.662831).  Saving model ...
	 Train_Loss: 0.6802 Train_Acc: 58.847 Val_Loss: 0.6628  BEST VAL Loss: 0.6628  Val_Acc: 67.709

Epoch 85: Validation loss decreased (0.662831 --> 0.662706).  Saving model ...
	 Train_Loss: 0.6802 Train_Acc: 58.498 Val_Loss: 0.6627  BEST VAL Loss: 0.6627  Val_Acc: 67.329

Epoch 86: Validation loss decreased (0.662706 --> 0.662537).  Saving model ...
	 Train_Loss: 0.6801 Train_Acc: 59.460 Val_Loss: 0.6625  BEST VAL Loss: 0.6625  Val_Acc: 67.751

Epoch 87: Validation loss decreased (0.662537 --> 0.662480).  Saving model ...
	 Train_Loss: 0.6801 Train_Acc: 59.460 Val_Loss: 0.6625  BEST VAL Loss: 0.6625  Val_Acc: 67.498

Epoch 88: Validation loss decreased (0.662480 --> 0.662380).  Saving model ...
	 Train_Loss: 0.6801 Train_Acc: 59.492 Val_Loss: 0.6624  BEST VAL Loss: 0.6624  Val_Acc: 66.991

Epoch 89: Validation loss decreased (0.662380 --> 0.662284).  Saving model ...
	 Train_Loss: 0.6800 Train_Acc: 59.772 Val_Loss: 0.6623  BEST VAL Loss: 0.6623  Val_Acc: 67.963

Epoch 90: Validation loss decreased (0.662284 --> 0.662216).  Saving model ...
	 Train_Loss: 0.6800 Train_Acc: 59.529 Val_Loss: 0.6622  BEST VAL Loss: 0.6622  Val_Acc: 67.709

Epoch 91: Validation loss decreased (0.662216 --> 0.662155).  Saving model ...
	 Train_Loss: 0.6799 Train_Acc: 59.264 Val_Loss: 0.6622  BEST VAL Loss: 0.6622  Val_Acc: 66.737

Epoch 92: Validation loss decreased (0.662155 --> 0.662035).  Saving model ...
	 Train_Loss: 0.6799 Train_Acc: 59.640 Val_Loss: 0.6620  BEST VAL Loss: 0.6620  Val_Acc: 67.582

Epoch 93: Validation loss decreased (0.662035 --> 0.662002).  Saving model ...
	 Train_Loss: 0.6799 Train_Acc: 57.843 Val_Loss: 0.6620  BEST VAL Loss: 0.6620  Val_Acc: 66.822

Epoch 94: Validation loss decreased (0.662002 --> 0.661947).  Saving model ...
	 Train_Loss: 0.6799 Train_Acc: 57.732 Val_Loss: 0.6619  BEST VAL Loss: 0.6619  Val_Acc: 66.484

Epoch 95: Validation loss decreased (0.661947 --> 0.661943).  Saving model ...
	 Train_Loss: 0.6799 Train_Acc: 58.028 Val_Loss: 0.6619  BEST VAL Loss: 0.6619  Val_Acc: 64.159

Epoch 96: Validation loss decreased (0.661943 --> 0.661850).  Saving model ...
	 Train_Loss: 0.6799 Train_Acc: 58.376 Val_Loss: 0.6618  BEST VAL Loss: 0.6618  Val_Acc: 66.695

Epoch 97: Validation loss decreased (0.661850 --> 0.661757).  Saving model ...
	 Train_Loss: 0.6799 Train_Acc: 59.079 Val_Loss: 0.6618  BEST VAL Loss: 0.6618  Val_Acc: 66.948

Epoch 98: Validation loss decreased (0.661757 --> 0.661676).  Saving model ...
	 Train_Loss: 0.6798 Train_Acc: 59.439 Val_Loss: 0.6617  BEST VAL Loss: 0.6617  Val_Acc: 67.202

Epoch 99: Validation loss decreased (0.661676 --> 0.661573).  Saving model ...
	 Train_Loss: 0.6797 Train_Acc: 60.189 Val_Loss: 0.6616  BEST VAL Loss: 0.6616  Val_Acc: 67.667

Flagellin_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.69      0.74      0.72      9433
           1       0.73      0.68      0.70      9489

    accuracy                           0.71     18922
   macro avg       0.71      0.71      0.71     18922
weighted avg       0.71      0.71      0.71     18922

Flagellin_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.67      0.71      0.69      1179
           1       0.69      0.65      0.67      1187

    accuracy                           0.68      2366
   macro avg       0.68      0.68      0.68      2366
weighted avg       0.68      0.68      0.68      2366

Flagellin_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.66      0.68      0.67      1180
           1       0.67      0.65      0.66      1186

    accuracy                           0.67      2366
   macro avg       0.67      0.67      0.67      2366
weighted avg       0.67      0.67      0.67      2366

              precision    recall  f1-score   support

           0       0.66      0.68      0.67      1180
           1       0.67      0.65      0.66      1186

    accuracy                           0.67      2366
   macro avg       0.67      0.67      0.67      2366
weighted avg       0.67      0.67      0.67      2366

Flagellin_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.60      0.51      0.55      4017
           1       0.57      0.66      0.61      3997

    accuracy                           0.59      8014
   macro avg       0.59      0.59      0.58      8014
weighted avg       0.59      0.59      0.58      8014

              precision    recall  f1-score   support

           0       0.60      0.51      0.55      4017
           1       0.57      0.66      0.61      3997

    accuracy                           0.59      8014
   macro avg       0.59      0.59      0.58      8014
weighted avg       0.59      0.59      0.58      8014

completed
