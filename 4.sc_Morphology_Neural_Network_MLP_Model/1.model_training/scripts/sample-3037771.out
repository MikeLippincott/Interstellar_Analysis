[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1bba9543'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'b9cd5497'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '320ba371'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'c232172a'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_0.010_DMSO_0.025 treatment_name: DMSO_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_0.010_DMSO_0.025
TREATMENT_NAME: DMSO_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'DMSO_0.100_DMSO_0.025']
The dimensions of the data are: (358210, 1270)
Number of total missing values across all columns: 716420
Data Subset Is Off
Wells held out for testing: ['B09' 'J06']
Wells to use for training, validation, and testing ['B02' 'B03' 'B06' 'C06' 'B07' 'C07' 'B08' 'I06' 'I07' 'J07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.397170).  Saving model ...
	 Train_Loss: 0.5011 Train_Acc: 75.286 Val_Loss: 0.3972  BEST VAL Loss: 0.3972  Val_Acc: 81.787

Epoch 1: Validation loss decreased (0.397170 --> 0.378960).  Saving model ...
	 Train_Loss: 0.4572 Train_Acc: 80.195 Val_Loss: 0.3790  BEST VAL Loss: 0.3790  Val_Acc: 83.725

Epoch 2: Validation loss decreased (0.378960 --> 0.369092).  Saving model ...
	 Train_Loss: 0.4345 Train_Acc: 81.342 Val_Loss: 0.3691  BEST VAL Loss: 0.3691  Val_Acc: 84.286

Epoch 3: Validation loss decreased (0.369092 --> 0.360341).  Saving model ...
	 Train_Loss: 0.4202 Train_Acc: 82.100 Val_Loss: 0.3603  BEST VAL Loss: 0.3603  Val_Acc: 85.102

Epoch 4: Validation loss decreased (0.360341 --> 0.353931).  Saving model ...
	 Train_Loss: 0.4098 Train_Acc: 82.548 Val_Loss: 0.3539  BEST VAL Loss: 0.3539  Val_Acc: 85.469

Epoch 5: Validation loss decreased (0.353931 --> 0.347719).  Saving model ...
	 Train_Loss: 0.4016 Train_Acc: 83.055 Val_Loss: 0.3477  BEST VAL Loss: 0.3477  Val_Acc: 85.670

Epoch 6: Validation loss decreased (0.347719 --> 0.343361).  Saving model ...
	 Train_Loss: 0.3951 Train_Acc: 83.202 Val_Loss: 0.3434  BEST VAL Loss: 0.3434  Val_Acc: 85.765

Epoch 7: Validation loss decreased (0.343361 --> 0.339209).  Saving model ...
	 Train_Loss: 0.3899 Train_Acc: 83.497 Val_Loss: 0.3392  BEST VAL Loss: 0.3392  Val_Acc: 86.357

Epoch 8: Validation loss decreased (0.339209 --> 0.335860).  Saving model ...
	 Train_Loss: 0.3852 Train_Acc: 83.730 Val_Loss: 0.3359  BEST VAL Loss: 0.3359  Val_Acc: 86.320

Epoch 9: Validation loss decreased (0.335860 --> 0.332489).  Saving model ...
	 Train_Loss: 0.3809 Train_Acc: 83.942 Val_Loss: 0.3325  BEST VAL Loss: 0.3325  Val_Acc: 86.666

Epoch 10: Validation loss decreased (0.332489 --> 0.329877).  Saving model ...
	 Train_Loss: 0.3773 Train_Acc: 84.116 Val_Loss: 0.3299  BEST VAL Loss: 0.3299  Val_Acc: 86.598

Epoch 11: Validation loss decreased (0.329877 --> 0.326774).  Saving model ...
	 Train_Loss: 0.3742 Train_Acc: 84.150 Val_Loss: 0.3268  BEST VAL Loss: 0.3268  Val_Acc: 87.044

Epoch 12: Validation loss decreased (0.326774 --> 0.324432).  Saving model ...
	 Train_Loss: 0.3713 Train_Acc: 84.269 Val_Loss: 0.3244  BEST VAL Loss: 0.3244  Val_Acc: 86.972

Epoch 13: Validation loss decreased (0.324432 --> 0.322016).  Saving model ...
	 Train_Loss: 0.3688 Train_Acc: 84.199 Val_Loss: 0.3220  BEST VAL Loss: 0.3220  Val_Acc: 87.285

Epoch 14: Validation loss decreased (0.322016 --> 0.320054).  Saving model ...
	 Train_Loss: 0.3666 Train_Acc: 84.379 Val_Loss: 0.3201  BEST VAL Loss: 0.3201  Val_Acc: 87.183

Epoch 15: Validation loss decreased (0.320054 --> 0.318113).  Saving model ...
	 Train_Loss: 0.3645 Train_Acc: 84.419 Val_Loss: 0.3181  BEST VAL Loss: 0.3181  Val_Acc: 87.153

Epoch 16: Validation loss decreased (0.318113 --> 0.316308).  Saving model ...
	 Train_Loss: 0.3624 Train_Acc: 84.670 Val_Loss: 0.3163  BEST VAL Loss: 0.3163  Val_Acc: 87.442

Epoch 17: Validation loss decreased (0.316308 --> 0.314766).  Saving model ...
	 Train_Loss: 0.3606 Train_Acc: 84.612 Val_Loss: 0.3148  BEST VAL Loss: 0.3148  Val_Acc: 87.432

Epoch 18: Validation loss decreased (0.314766 --> 0.313568).  Saving model ...
	 Train_Loss: 0.3589 Train_Acc: 84.638 Val_Loss: 0.3136  BEST VAL Loss: 0.3136  Val_Acc: 87.058

Epoch 19: Validation loss decreased (0.313568 --> 0.312269).  Saving model ...
	 Train_Loss: 0.3573 Train_Acc: 84.735 Val_Loss: 0.3123  BEST VAL Loss: 0.3123  Val_Acc: 87.245

Epoch 20: Validation loss decreased (0.312269 --> 0.311083).  Saving model ...
	 Train_Loss: 0.3558 Train_Acc: 84.771 Val_Loss: 0.3111  BEST VAL Loss: 0.3111  Val_Acc: 87.489

Epoch 21: Validation loss decreased (0.311083 --> 0.310228).  Saving model ...
	 Train_Loss: 0.3543 Train_Acc: 84.878 Val_Loss: 0.3102  BEST VAL Loss: 0.3102  Val_Acc: 87.330

Epoch 22: Validation loss decreased (0.310228 --> 0.309227).  Saving model ...
	 Train_Loss: 0.3529 Train_Acc: 84.880 Val_Loss: 0.3092  BEST VAL Loss: 0.3092  Val_Acc: 87.663

Epoch 23: Validation loss decreased (0.309227 --> 0.308286).  Saving model ...
	 Train_Loss: 0.3517 Train_Acc: 84.892 Val_Loss: 0.3083  BEST VAL Loss: 0.3083  Val_Acc: 87.510

Epoch 24: Validation loss decreased (0.308286 --> 0.307262).  Saving model ...
	 Train_Loss: 0.3505 Train_Acc: 84.863 Val_Loss: 0.3073  BEST VAL Loss: 0.3073  Val_Acc: 87.717

Epoch 25: Validation loss decreased (0.307262 --> 0.306263).  Saving model ...
	 Train_Loss: 0.3494 Train_Acc: 84.998 Val_Loss: 0.3063  BEST VAL Loss: 0.3063  Val_Acc: 87.721

Epoch 26: Validation loss decreased (0.306263 --> 0.305573).  Saving model ...
	 Train_Loss: 0.3483 Train_Acc: 84.978 Val_Loss: 0.3056  BEST VAL Loss: 0.3056  Val_Acc: 87.649

Epoch 27: Validation loss decreased (0.305573 --> 0.304746).  Saving model ...
	 Train_Loss: 0.3472 Train_Acc: 85.040 Val_Loss: 0.3047  BEST VAL Loss: 0.3047  Val_Acc: 87.666

Epoch 28: Validation loss decreased (0.304746 --> 0.303955).  Saving model ...
	 Train_Loss: 0.3463 Train_Acc: 85.154 Val_Loss: 0.3040  BEST VAL Loss: 0.3040  Val_Acc: 87.693

Epoch 29: Validation loss decreased (0.303955 --> 0.303259).  Saving model ...
	 Train_Loss: 0.3454 Train_Acc: 85.087 Val_Loss: 0.3033  BEST VAL Loss: 0.3033  Val_Acc: 87.683

Epoch 30: Validation loss decreased (0.303259 --> 0.302506).  Saving model ...
	 Train_Loss: 0.3444 Train_Acc: 85.298 Val_Loss: 0.3025  BEST VAL Loss: 0.3025  Val_Acc: 87.680

Epoch 31: Validation loss decreased (0.302506 --> 0.301965).  Saving model ...
	 Train_Loss: 0.3436 Train_Acc: 85.213 Val_Loss: 0.3020  BEST VAL Loss: 0.3020  Val_Acc: 87.357

Epoch 32: Validation loss decreased (0.301965 --> 0.301210).  Saving model ...
	 Train_Loss: 0.3427 Train_Acc: 85.135 Val_Loss: 0.3012  BEST VAL Loss: 0.3012  Val_Acc: 87.908

Epoch 33: Validation loss decreased (0.301210 --> 0.300710).  Saving model ...
	 Train_Loss: 0.3419 Train_Acc: 85.190 Val_Loss: 0.3007  BEST VAL Loss: 0.3007  Val_Acc: 87.819

Epoch 34: Validation loss decreased (0.300710 --> 0.300140).  Saving model ...
	 Train_Loss: 0.3412 Train_Acc: 85.202 Val_Loss: 0.3001  BEST VAL Loss: 0.3001  Val_Acc: 87.673

Epoch 35: Validation loss decreased (0.300140 --> 0.299608).  Saving model ...
	 Train_Loss: 0.3404 Train_Acc: 85.316 Val_Loss: 0.2996  BEST VAL Loss: 0.2996  Val_Acc: 87.877

Epoch 36: Validation loss decreased (0.299608 --> 0.299059).  Saving model ...
	 Train_Loss: 0.3397 Train_Acc: 85.236 Val_Loss: 0.2991  BEST VAL Loss: 0.2991  Val_Acc: 87.897

Epoch 37: Validation loss decreased (0.299059 --> 0.298569).  Saving model ...
	 Train_Loss: 0.3390 Train_Acc: 85.397 Val_Loss: 0.2986  BEST VAL Loss: 0.2986  Val_Acc: 87.785

Epoch 38: Validation loss decreased (0.298569 --> 0.298002).  Saving model ...
	 Train_Loss: 0.3383 Train_Acc: 85.408 Val_Loss: 0.2980  BEST VAL Loss: 0.2980  Val_Acc: 87.982

Epoch 39: Validation loss decreased (0.298002 --> 0.297537).  Saving model ...
	 Train_Loss: 0.3377 Train_Acc: 85.304 Val_Loss: 0.2975  BEST VAL Loss: 0.2975  Val_Acc: 87.955

Epoch 40: Validation loss decreased (0.297537 --> 0.297133).  Saving model ...
	 Train_Loss: 0.3371 Train_Acc: 85.394 Val_Loss: 0.2971  BEST VAL Loss: 0.2971  Val_Acc: 87.853

Epoch 41: Validation loss decreased (0.297133 --> 0.296624).  Saving model ...
	 Train_Loss: 0.3365 Train_Acc: 85.363 Val_Loss: 0.2966  BEST VAL Loss: 0.2966  Val_Acc: 87.897

Epoch 42: Validation loss decreased (0.296624 --> 0.296246).  Saving model ...
	 Train_Loss: 0.3359 Train_Acc: 85.463 Val_Loss: 0.2962  BEST VAL Loss: 0.2962  Val_Acc: 87.884

Epoch 43: Validation loss decreased (0.296246 --> 0.295787).  Saving model ...
	 Train_Loss: 0.3353 Train_Acc: 85.354 Val_Loss: 0.2958  BEST VAL Loss: 0.2958  Val_Acc: 88.033

Epoch 44: Validation loss decreased (0.295787 --> 0.295353).  Saving model ...
	 Train_Loss: 0.3348 Train_Acc: 85.513 Val_Loss: 0.2954  BEST VAL Loss: 0.2954  Val_Acc: 88.125

Epoch 45: Validation loss decreased (0.295353 --> 0.294951).  Saving model ...
	 Train_Loss: 0.3342 Train_Acc: 85.452 Val_Loss: 0.2950  BEST VAL Loss: 0.2950  Val_Acc: 88.030

Epoch 46: Validation loss decreased (0.294951 --> 0.294645).  Saving model ...
	 Train_Loss: 0.3337 Train_Acc: 85.410 Val_Loss: 0.2946  BEST VAL Loss: 0.2946  Val_Acc: 87.904

Epoch 47: Validation loss decreased (0.294645 --> 0.294323).  Saving model ...
	 Train_Loss: 0.3332 Train_Acc: 85.452 Val_Loss: 0.2943  BEST VAL Loss: 0.2943  Val_Acc: 88.047

Epoch 48: Validation loss decreased (0.294323 --> 0.293992).  Saving model ...
	 Train_Loss: 0.3327 Train_Acc: 85.508 Val_Loss: 0.2940  BEST VAL Loss: 0.2940  Val_Acc: 88.091

Epoch 49: Validation loss decreased (0.293992 --> 0.293571).  Saving model ...
	 Train_Loss: 0.3323 Train_Acc: 85.414 Val_Loss: 0.2936  BEST VAL Loss: 0.2936  Val_Acc: 88.118

Epoch 50: Validation loss decreased (0.293571 --> 0.293200).  Saving model ...
	 Train_Loss: 0.3318 Train_Acc: 85.595 Val_Loss: 0.2932  BEST VAL Loss: 0.2932  Val_Acc: 88.101

Epoch 51: Validation loss decreased (0.293200 --> 0.293032).  Saving model ...
	 Train_Loss: 0.3314 Train_Acc: 85.468 Val_Loss: 0.2930  BEST VAL Loss: 0.2930  Val_Acc: 87.782

Epoch 52: Validation loss decreased (0.293032 --> 0.292629).  Saving model ...
	 Train_Loss: 0.3310 Train_Acc: 85.603 Val_Loss: 0.2926  BEST VAL Loss: 0.2926  Val_Acc: 88.095

Epoch 53: Validation loss decreased (0.292629 --> 0.292348).  Saving model ...
	 Train_Loss: 0.3305 Train_Acc: 85.670 Val_Loss: 0.2923  BEST VAL Loss: 0.2923  Val_Acc: 87.982

Epoch 54: Validation loss decreased (0.292348 --> 0.292017).  Saving model ...
	 Train_Loss: 0.3301 Train_Acc: 85.606 Val_Loss: 0.2920  BEST VAL Loss: 0.2920  Val_Acc: 87.931

Epoch 55: Validation loss decreased (0.292017 --> 0.291778).  Saving model ...
	 Train_Loss: 0.3297 Train_Acc: 85.677 Val_Loss: 0.2918  BEST VAL Loss: 0.2918  Val_Acc: 88.132

Epoch 56: Validation loss decreased (0.291778 --> 0.291436).  Saving model ...
	 Train_Loss: 0.3293 Train_Acc: 85.576 Val_Loss: 0.2914  BEST VAL Loss: 0.2914  Val_Acc: 88.118

Epoch 57: Validation loss decreased (0.291436 --> 0.291127).  Saving model ...
	 Train_Loss: 0.3289 Train_Acc: 85.646 Val_Loss: 0.2911  BEST VAL Loss: 0.2911  Val_Acc: 88.152

Epoch 58: Validation loss decreased (0.291127 --> 0.290848).  Saving model ...
	 Train_Loss: 0.3285 Train_Acc: 85.681 Val_Loss: 0.2908  BEST VAL Loss: 0.2908  Val_Acc: 88.067

Epoch 59: Validation loss decreased (0.290848 --> 0.290583).  Saving model ...
	 Train_Loss: 0.3281 Train_Acc: 85.583 Val_Loss: 0.2906  BEST VAL Loss: 0.2906  Val_Acc: 88.159

Epoch 60: Validation loss decreased (0.290583 --> 0.290307).  Saving model ...
	 Train_Loss: 0.3277 Train_Acc: 85.723 Val_Loss: 0.2903  BEST VAL Loss: 0.2903  Val_Acc: 88.200

Epoch 61: Validation loss decreased (0.290307 --> 0.290134).  Saving model ...
	 Train_Loss: 0.3274 Train_Acc: 85.656 Val_Loss: 0.2901  BEST VAL Loss: 0.2901  Val_Acc: 87.911

Epoch 62: Validation loss decreased (0.290134 --> 0.289877).  Saving model ...
	 Train_Loss: 0.3270 Train_Acc: 85.641 Val_Loss: 0.2899  BEST VAL Loss: 0.2899  Val_Acc: 88.037

Epoch 63: Validation loss decreased (0.289877 --> 0.289693).  Saving model ...
	 Train_Loss: 0.3267 Train_Acc: 85.700 Val_Loss: 0.2897  BEST VAL Loss: 0.2897  Val_Acc: 87.996

Epoch 64: Validation loss decreased (0.289693 --> 0.289394).  Saving model ...
	 Train_Loss: 0.3264 Train_Acc: 85.664 Val_Loss: 0.2894  BEST VAL Loss: 0.2894  Val_Acc: 88.193

Epoch 65: Validation loss decreased (0.289394 --> 0.289143).  Saving model ...
	 Train_Loss: 0.3261 Train_Acc: 85.693 Val_Loss: 0.2891  BEST VAL Loss: 0.2891  Val_Acc: 88.193

Epoch 66: Validation loss decreased (0.289143 --> 0.288964).  Saving model ...
	 Train_Loss: 0.3257 Train_Acc: 85.693 Val_Loss: 0.2890  BEST VAL Loss: 0.2890  Val_Acc: 87.996

Epoch 67: Validation loss decreased (0.288964 --> 0.288743).  Saving model ...
	 Train_Loss: 0.3254 Train_Acc: 85.719 Val_Loss: 0.2887  BEST VAL Loss: 0.2887  Val_Acc: 88.173

Epoch 68: Validation loss decreased (0.288743 --> 0.288529).  Saving model ...
	 Train_Loss: 0.3251 Train_Acc: 85.667 Val_Loss: 0.2885  BEST VAL Loss: 0.2885  Val_Acc: 88.098

Epoch 69: Validation loss decreased (0.288529 --> 0.288298).  Saving model ...
	 Train_Loss: 0.3248 Train_Acc: 85.650 Val_Loss: 0.2883  BEST VAL Loss: 0.2883  Val_Acc: 88.299

Epoch 70: Validation loss decreased (0.288298 --> 0.288118).  Saving model ...
	 Train_Loss: 0.3245 Train_Acc: 85.722 Val_Loss: 0.2881  BEST VAL Loss: 0.2881  Val_Acc: 88.118

Epoch 71: Validation loss decreased (0.288118 --> 0.287932).  Saving model ...
	 Train_Loss: 0.3242 Train_Acc: 85.743 Val_Loss: 0.2879  BEST VAL Loss: 0.2879  Val_Acc: 88.115

Epoch 72: Validation loss decreased (0.287932 --> 0.287764).  Saving model ...
	 Train_Loss: 0.3240 Train_Acc: 85.678 Val_Loss: 0.2878  BEST VAL Loss: 0.2878  Val_Acc: 88.061

Epoch 73: Validation loss decreased (0.287764 --> 0.287594).  Saving model ...
	 Train_Loss: 0.3237 Train_Acc: 85.623 Val_Loss: 0.2876  BEST VAL Loss: 0.2876  Val_Acc: 88.258

Epoch 74: Validation loss decreased (0.287594 --> 0.287403).  Saving model ...
	 Train_Loss: 0.3234 Train_Acc: 85.685 Val_Loss: 0.2874  BEST VAL Loss: 0.2874  Val_Acc: 88.200

Epoch 75: Validation loss decreased (0.287403 --> 0.287199).  Saving model ...
	 Train_Loss: 0.3231 Train_Acc: 85.681 Val_Loss: 0.2872  BEST VAL Loss: 0.2872  Val_Acc: 88.258

Epoch 76: Validation loss decreased (0.287199 --> 0.287018).  Saving model ...
	 Train_Loss: 0.3229 Train_Acc: 85.676 Val_Loss: 0.2870  BEST VAL Loss: 0.2870  Val_Acc: 88.278

Epoch 77: Validation loss decreased (0.287018 --> 0.286875).  Saving model ...
	 Train_Loss: 0.3226 Train_Acc: 85.772 Val_Loss: 0.2869  BEST VAL Loss: 0.2869  Val_Acc: 88.027

Epoch 78: Validation loss decreased (0.286875 --> 0.286716).  Saving model ...
	 Train_Loss: 0.3224 Train_Acc: 85.744 Val_Loss: 0.2867  BEST VAL Loss: 0.2867  Val_Acc: 87.972

Epoch 79: Validation loss decreased (0.286716 --> 0.286659).  Saving model ...
	 Train_Loss: 0.3221 Train_Acc: 85.808 Val_Loss: 0.2867  BEST VAL Loss: 0.2867  Val_Acc: 88.084

Epoch 80: Validation loss decreased (0.286659 --> 0.286492).  Saving model ...
	 Train_Loss: 0.3219 Train_Acc: 85.683 Val_Loss: 0.2865  BEST VAL Loss: 0.2865  Val_Acc: 88.289

Epoch 81: Validation loss decreased (0.286492 --> 0.286364).  Saving model ...
	 Train_Loss: 0.3216 Train_Acc: 85.790 Val_Loss: 0.2864  BEST VAL Loss: 0.2864  Val_Acc: 88.241

Epoch 82: Validation loss decreased (0.286364 --> 0.286195).  Saving model ...
	 Train_Loss: 0.3214 Train_Acc: 85.741 Val_Loss: 0.2862  BEST VAL Loss: 0.2862  Val_Acc: 88.271

Epoch 83: Validation loss decreased (0.286195 --> 0.286097).  Saving model ...
	 Train_Loss: 0.3212 Train_Acc: 85.792 Val_Loss: 0.2861  BEST VAL Loss: 0.2861  Val_Acc: 87.952

Epoch 84: Validation loss decreased (0.286097 --> 0.285952).  Saving model ...
	 Train_Loss: 0.3209 Train_Acc: 85.801 Val_Loss: 0.2860  BEST VAL Loss: 0.2860  Val_Acc: 88.183

Epoch 85: Validation loss decreased (0.285952 --> 0.285807).  Saving model ...
	 Train_Loss: 0.3207 Train_Acc: 85.785 Val_Loss: 0.2858  BEST VAL Loss: 0.2858  Val_Acc: 88.350

Epoch 86: Validation loss decreased (0.285807 --> 0.285640).  Saving model ...
	 Train_Loss: 0.3205 Train_Acc: 85.779 Val_Loss: 0.2856  BEST VAL Loss: 0.2856  Val_Acc: 88.190

Epoch 87: Validation loss decreased (0.285640 --> 0.285476).  Saving model ...
	 Train_Loss: 0.3203 Train_Acc: 85.828 Val_Loss: 0.2855  BEST VAL Loss: 0.2855  Val_Acc: 88.350

Epoch 88: Validation loss decreased (0.285476 --> 0.285386).  Saving model ...
	 Train_Loss: 0.3201 Train_Acc: 85.905 Val_Loss: 0.2854  BEST VAL Loss: 0.2854  Val_Acc: 88.380

Epoch 89: Validation loss decreased (0.285386 --> 0.285242).  Saving model ...
	 Train_Loss: 0.3198 Train_Acc: 85.698 Val_Loss: 0.2852  BEST VAL Loss: 0.2852  Val_Acc: 88.258

Epoch 90: Validation loss decreased (0.285242 --> 0.285112).  Saving model ...
	 Train_Loss: 0.3196 Train_Acc: 85.812 Val_Loss: 0.2851  BEST VAL Loss: 0.2851  Val_Acc: 88.258

Epoch 91: Validation loss decreased (0.285112 --> 0.284992).  Saving model ...
	 Train_Loss: 0.3194 Train_Acc: 85.789 Val_Loss: 0.2850  BEST VAL Loss: 0.2850  Val_Acc: 88.098

Epoch 92: Validation loss decreased (0.284992 --> 0.284895).  Saving model ...
	 Train_Loss: 0.3192 Train_Acc: 85.820 Val_Loss: 0.2849  BEST VAL Loss: 0.2849  Val_Acc: 88.064

Epoch 93: Validation loss decreased (0.284895 --> 0.284781).  Saving model ...
	 Train_Loss: 0.3190 Train_Acc: 85.812 Val_Loss: 0.2848  BEST VAL Loss: 0.2848  Val_Acc: 88.054

Epoch 94: Validation loss decreased (0.284781 --> 0.284624).  Saving model ...
	 Train_Loss: 0.3188 Train_Acc: 85.792 Val_Loss: 0.2846  BEST VAL Loss: 0.2846  Val_Acc: 88.377

Epoch 95: Validation loss decreased (0.284624 --> 0.284532).  Saving model ...
	 Train_Loss: 0.3186 Train_Acc: 85.860 Val_Loss: 0.2845  BEST VAL Loss: 0.2845  Val_Acc: 88.227

Epoch 96: Validation loss decreased (0.284532 --> 0.284382).  Saving model ...
	 Train_Loss: 0.3185 Train_Acc: 85.825 Val_Loss: 0.2844  BEST VAL Loss: 0.2844  Val_Acc: 88.333

Epoch 97: Validation loss decreased (0.284382 --> 0.284208).  Saving model ...
	 Train_Loss: 0.3183 Train_Acc: 85.798 Val_Loss: 0.2842  BEST VAL Loss: 0.2842  Val_Acc: 88.493

Epoch 98: Validation loss decreased (0.284208 --> 0.284110).  Saving model ...
	 Train_Loss: 0.3181 Train_Acc: 85.891 Val_Loss: 0.2841  BEST VAL Loss: 0.2841  Val_Acc: 88.374

Epoch 99: Validation loss decreased (0.284110 --> 0.283995).  Saving model ...
	 Train_Loss: 0.3179 Train_Acc: 85.853 Val_Loss: 0.2840  BEST VAL Loss: 0.2840  Val_Acc: 88.350

LPS_0.010_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.92      0.91      0.92    149884
           1       0.85      0.87      0.86     85371

    accuracy                           0.90    235255
   macro avg       0.89      0.89      0.89    235255
weighted avg       0.90      0.90      0.90    235255

LPS_0.010_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.91      0.91      0.91     18736
           1       0.84      0.85      0.84     10671

    accuracy                           0.88     29407
   macro avg       0.87      0.88      0.87     29407
weighted avg       0.88      0.88      0.88     29407

LPS_0.010_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.91      0.90      0.91     18736
           1       0.83      0.85      0.84     10672

    accuracy                           0.88     29408
   macro avg       0.87      0.87      0.87     29408
weighted avg       0.88      0.88      0.88     29408

              precision    recall  f1-score   support

           0       0.91      0.90      0.91     18736
           1       0.83      0.85      0.84     10672

    accuracy                           0.88     29408
   macro avg       0.87      0.87      0.87     29408
weighted avg       0.88      0.88      0.88     29408

LPS_0.010_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.57      0.90      0.69     27774
           1       0.86      0.48      0.61     36366

    accuracy                           0.66     64140
   macro avg       0.71      0.69      0.65     64140
weighted avg       0.73      0.66      0.65     64140

              precision    recall  f1-score   support

           0       0.57      0.90      0.69     27774
           1       0.86      0.48      0.61     36366

    accuracy                           0.66     64140
   macro avg       0.71      0.69      0.65     64140
weighted avg       0.73      0.66      0.65     64140

completed
