[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'e5bb53bf'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '347011f9'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '91be62d2'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'b0939afa'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Thapsigargin_1.000_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Thapsigargin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (307891, 1270)
Number of total missing values across all columns: 615782
Data Subset Is Off
Wells held out for testing: ['K06' 'J09']
Wells to use for training, validation, and testing ['D06' 'D07' 'J02' 'J03' 'K07' 'J08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.542106).  Saving model ...
	 Train_Loss: 0.6362 Train_Acc: 64.520 Val_Loss: 0.5421  BEST VAL Loss: 0.5421  Val_Acc: 75.439

Epoch 1: Validation loss decreased (0.542106 --> 0.507563).  Saving model ...
	 Train_Loss: 0.5891 Train_Acc: 74.418 Val_Loss: 0.5076  BEST VAL Loss: 0.5076  Val_Acc: 78.659

Epoch 2: Validation loss decreased (0.507563 --> 0.483051).  Saving model ...
	 Train_Loss: 0.5591 Train_Acc: 77.518 Val_Loss: 0.4831  BEST VAL Loss: 0.4831  Val_Acc: 81.184

Epoch 3: Validation loss decreased (0.483051 --> 0.463856).  Saving model ...
	 Train_Loss: 0.5364 Train_Acc: 79.517 Val_Loss: 0.4639  BEST VAL Loss: 0.4639  Val_Acc: 82.774

Epoch 4: Validation loss decreased (0.463856 --> 0.448142).  Saving model ...
	 Train_Loss: 0.5191 Train_Acc: 80.358 Val_Loss: 0.4481  BEST VAL Loss: 0.4481  Val_Acc: 84.004

Epoch 5: Validation loss decreased (0.448142 --> 0.434814).  Saving model ...
	 Train_Loss: 0.5051 Train_Acc: 81.115 Val_Loss: 0.4348  BEST VAL Loss: 0.4348  Val_Acc: 84.617

Epoch 6: Validation loss decreased (0.434814 --> 0.424212).  Saving model ...
	 Train_Loss: 0.4934 Train_Acc: 81.529 Val_Loss: 0.4242  BEST VAL Loss: 0.4242  Val_Acc: 84.873

Epoch 7: Validation loss decreased (0.424212 --> 0.415265).  Saving model ...
	 Train_Loss: 0.4842 Train_Acc: 81.799 Val_Loss: 0.4153  BEST VAL Loss: 0.4153  Val_Acc: 85.621

Epoch 8: Validation loss decreased (0.415265 --> 0.408093).  Saving model ...
	 Train_Loss: 0.4763 Train_Acc: 82.184 Val_Loss: 0.4081  BEST VAL Loss: 0.4081  Val_Acc: 85.873

Epoch 9: Validation loss decreased (0.408093 --> 0.401608).  Saving model ...
	 Train_Loss: 0.4694 Train_Acc: 82.393 Val_Loss: 0.4016  BEST VAL Loss: 0.4016  Val_Acc: 86.029

Epoch 10: Validation loss decreased (0.401608 --> 0.396269).  Saving model ...
	 Train_Loss: 0.4634 Train_Acc: 82.567 Val_Loss: 0.3963  BEST VAL Loss: 0.3963  Val_Acc: 85.929

Epoch 11: Validation loss decreased (0.396269 --> 0.391680).  Saving model ...
	 Train_Loss: 0.4580 Train_Acc: 82.772 Val_Loss: 0.3917  BEST VAL Loss: 0.3917  Val_Acc: 86.103

Epoch 12: Validation loss decreased (0.391680 --> 0.387385).  Saving model ...
	 Train_Loss: 0.4533 Train_Acc: 82.885 Val_Loss: 0.3874  BEST VAL Loss: 0.3874  Val_Acc: 86.329

Epoch 13: Validation loss decreased (0.387385 --> 0.383651).  Saving model ...
	 Train_Loss: 0.4490 Train_Acc: 83.076 Val_Loss: 0.3837  BEST VAL Loss: 0.3837  Val_Acc: 86.320

Epoch 14: Validation loss decreased (0.383651 --> 0.380289).  Saving model ...
	 Train_Loss: 0.4451 Train_Acc: 83.162 Val_Loss: 0.3803  BEST VAL Loss: 0.3803  Val_Acc: 86.438

Epoch 15: Validation loss decreased (0.380289 --> 0.377309).  Saving model ...
	 Train_Loss: 0.4416 Train_Acc: 83.194 Val_Loss: 0.3773  BEST VAL Loss: 0.3773  Val_Acc: 86.329

Epoch 16: Validation loss decreased (0.377309 --> 0.374492).  Saving model ...
	 Train_Loss: 0.4384 Train_Acc: 83.232 Val_Loss: 0.3745  BEST VAL Loss: 0.3745  Val_Acc: 86.642

Epoch 17: Validation loss decreased (0.374492 --> 0.371521).  Saving model ...
	 Train_Loss: 0.4354 Train_Acc: 83.411 Val_Loss: 0.3715  BEST VAL Loss: 0.3715  Val_Acc: 86.598

Epoch 18: Validation loss decreased (0.371521 --> 0.369122).  Saving model ...
	 Train_Loss: 0.4327 Train_Acc: 83.558 Val_Loss: 0.3691  BEST VAL Loss: 0.3691  Val_Acc: 86.746

Epoch 19: Validation loss decreased (0.369122 --> 0.366895).  Saving model ...
	 Train_Loss: 0.4301 Train_Acc: 83.579 Val_Loss: 0.3669  BEST VAL Loss: 0.3669  Val_Acc: 86.863

Epoch 20: Validation loss decreased (0.366895 --> 0.364871).  Saving model ...
	 Train_Loss: 0.4277 Train_Acc: 83.611 Val_Loss: 0.3649  BEST VAL Loss: 0.3649  Val_Acc: 86.694

Epoch 21: Validation loss decreased (0.364871 --> 0.362689).  Saving model ...
	 Train_Loss: 0.4254 Train_Acc: 83.643 Val_Loss: 0.3627  BEST VAL Loss: 0.3627  Val_Acc: 86.750

Epoch 22: Validation loss decreased (0.362689 --> 0.360880).  Saving model ...
	 Train_Loss: 0.4234 Train_Acc: 83.684 Val_Loss: 0.3609  BEST VAL Loss: 0.3609  Val_Acc: 86.716

Epoch 23: Validation loss decreased (0.360880 --> 0.359097).  Saving model ...
	 Train_Loss: 0.4214 Train_Acc: 83.675 Val_Loss: 0.3591  BEST VAL Loss: 0.3591  Val_Acc: 86.920

Epoch 24: Validation loss decreased (0.359097 --> 0.357293).  Saving model ...
	 Train_Loss: 0.4196 Train_Acc: 83.731 Val_Loss: 0.3573  BEST VAL Loss: 0.3573  Val_Acc: 87.159

Epoch 25: Validation loss decreased (0.357293 --> 0.355552).  Saving model ...
	 Train_Loss: 0.4178 Train_Acc: 83.956 Val_Loss: 0.3556  BEST VAL Loss: 0.3556  Val_Acc: 86.911

Epoch 26: Validation loss decreased (0.355552 --> 0.353998).  Saving model ...
	 Train_Loss: 0.4161 Train_Acc: 83.980 Val_Loss: 0.3540  BEST VAL Loss: 0.3540  Val_Acc: 86.807

Epoch 27: Validation loss decreased (0.353998 --> 0.352654).  Saving model ...
	 Train_Loss: 0.4144 Train_Acc: 84.011 Val_Loss: 0.3527  BEST VAL Loss: 0.3527  Val_Acc: 86.629

Epoch 28: Validation loss decreased (0.352654 --> 0.351241).  Saving model ...
	 Train_Loss: 0.4129 Train_Acc: 84.015 Val_Loss: 0.3512  BEST VAL Loss: 0.3512  Val_Acc: 86.768

Epoch 29: Validation loss decreased (0.351241 --> 0.349912).  Saving model ...
	 Train_Loss: 0.4115 Train_Acc: 83.967 Val_Loss: 0.3499  BEST VAL Loss: 0.3499  Val_Acc: 86.968

Epoch 30: Validation loss decreased (0.349912 --> 0.348926).  Saving model ...
	 Train_Loss: 0.4102 Train_Acc: 83.890 Val_Loss: 0.3489  BEST VAL Loss: 0.3489  Val_Acc: 86.703

Epoch 31: Validation loss decreased (0.348926 --> 0.347674).  Saving model ...
	 Train_Loss: 0.4089 Train_Acc: 84.061 Val_Loss: 0.3477  BEST VAL Loss: 0.3477  Val_Acc: 87.050

Epoch 32: Validation loss decreased (0.347674 --> 0.346570).  Saving model ...
	 Train_Loss: 0.4076 Train_Acc: 84.089 Val_Loss: 0.3466  BEST VAL Loss: 0.3466  Val_Acc: 86.933

Epoch 33: Validation loss decreased (0.346570 --> 0.345494).  Saving model ...
	 Train_Loss: 0.4064 Train_Acc: 84.241 Val_Loss: 0.3455  BEST VAL Loss: 0.3455  Val_Acc: 86.902

Epoch 34: Validation loss decreased (0.345494 --> 0.344471).  Saving model ...
	 Train_Loss: 0.4052 Train_Acc: 84.122 Val_Loss: 0.3445  BEST VAL Loss: 0.3445  Val_Acc: 87.155

Epoch 35: Validation loss decreased (0.344471 --> 0.343586).  Saving model ...
	 Train_Loss: 0.4041 Train_Acc: 84.200 Val_Loss: 0.3436  BEST VAL Loss: 0.3436  Val_Acc: 86.616

Epoch 36: Validation loss decreased (0.343586 --> 0.342600).  Saving model ...
	 Train_Loss: 0.4031 Train_Acc: 84.204 Val_Loss: 0.3426  BEST VAL Loss: 0.3426  Val_Acc: 87.102

Epoch 37: Validation loss decreased (0.342600 --> 0.341626).  Saving model ...
	 Train_Loss: 0.4020 Train_Acc: 84.185 Val_Loss: 0.3416  BEST VAL Loss: 0.3416  Val_Acc: 86.907

Epoch 38: Validation loss decreased (0.341626 --> 0.340780).  Saving model ...
	 Train_Loss: 0.4010 Train_Acc: 84.279 Val_Loss: 0.3408  BEST VAL Loss: 0.3408  Val_Acc: 87.029

Epoch 39: Validation loss decreased (0.340780 --> 0.339981).  Saving model ...
	 Train_Loss: 0.4001 Train_Acc: 84.374 Val_Loss: 0.3400  BEST VAL Loss: 0.3400  Val_Acc: 86.968

Epoch 40: Validation loss decreased (0.339981 --> 0.339210).  Saving model ...
	 Train_Loss: 0.3991 Train_Acc: 84.328 Val_Loss: 0.3392  BEST VAL Loss: 0.3392  Val_Acc: 86.955

Epoch 41: Validation loss decreased (0.339210 --> 0.338486).  Saving model ...
	 Train_Loss: 0.3982 Train_Acc: 84.430 Val_Loss: 0.3385  BEST VAL Loss: 0.3385  Val_Acc: 87.198

Epoch 42: Validation loss decreased (0.338486 --> 0.337919).  Saving model ...
	 Train_Loss: 0.3973 Train_Acc: 84.442 Val_Loss: 0.3379  BEST VAL Loss: 0.3379  Val_Acc: 86.681

Epoch 43: Validation loss decreased (0.337919 --> 0.337367).  Saving model ...
	 Train_Loss: 0.3965 Train_Acc: 84.353 Val_Loss: 0.3374  BEST VAL Loss: 0.3374  Val_Acc: 86.885

Epoch 44: Validation loss decreased (0.337367 --> 0.336816).  Saving model ...
	 Train_Loss: 0.3957 Train_Acc: 84.588 Val_Loss: 0.3368  BEST VAL Loss: 0.3368  Val_Acc: 87.094

Epoch 45: Validation loss decreased (0.336816 --> 0.336214).  Saving model ...
	 Train_Loss: 0.3949 Train_Acc: 84.376 Val_Loss: 0.3362  BEST VAL Loss: 0.3362  Val_Acc: 86.959

Epoch 46: Validation loss decreased (0.336214 --> 0.335682).  Saving model ...
	 Train_Loss: 0.3941 Train_Acc: 84.585 Val_Loss: 0.3357  BEST VAL Loss: 0.3357  Val_Acc: 87.011

Epoch 47: Validation loss decreased (0.335682 --> 0.335107).  Saving model ...
	 Train_Loss: 0.3934 Train_Acc: 84.372 Val_Loss: 0.3351  BEST VAL Loss: 0.3351  Val_Acc: 86.859

Epoch 48: Validation loss decreased (0.335107 --> 0.334589).  Saving model ...
	 Train_Loss: 0.3926 Train_Acc: 84.591 Val_Loss: 0.3346  BEST VAL Loss: 0.3346  Val_Acc: 86.781

Epoch 49: Validation loss decreased (0.334589 --> 0.334005).  Saving model ...
	 Train_Loss: 0.3919 Train_Acc: 84.531 Val_Loss: 0.3340  BEST VAL Loss: 0.3340  Val_Acc: 86.959

Epoch 50: Validation loss decreased (0.334005 --> 0.333568).  Saving model ...
	 Train_Loss: 0.3912 Train_Acc: 84.651 Val_Loss: 0.3336  BEST VAL Loss: 0.3336  Val_Acc: 87.159

Epoch 51: Validation loss decreased (0.333568 --> 0.333064).  Saving model ...
	 Train_Loss: 0.3906 Train_Acc: 84.479 Val_Loss: 0.3331  BEST VAL Loss: 0.3331  Val_Acc: 87.120

Epoch 52: Validation loss decreased (0.333064 --> 0.332639).  Saving model ...
	 Train_Loss: 0.3899 Train_Acc: 84.605 Val_Loss: 0.3326  BEST VAL Loss: 0.3326  Val_Acc: 86.946

Epoch 53: Validation loss decreased (0.332639 --> 0.332201).  Saving model ...
	 Train_Loss: 0.3893 Train_Acc: 84.596 Val_Loss: 0.3322  BEST VAL Loss: 0.3322  Val_Acc: 86.807

Epoch 54: Validation loss decreased (0.332201 --> 0.331776).  Saving model ...
	 Train_Loss: 0.3887 Train_Acc: 84.544 Val_Loss: 0.3318  BEST VAL Loss: 0.3318  Val_Acc: 86.885

Epoch 55: Validation loss decreased (0.331776 --> 0.331279).  Saving model ...
	 Train_Loss: 0.3881 Train_Acc: 84.763 Val_Loss: 0.3313  BEST VAL Loss: 0.3313  Val_Acc: 87.029

Epoch 56: Validation loss decreased (0.331279 --> 0.330860).  Saving model ...
	 Train_Loss: 0.3875 Train_Acc: 84.786 Val_Loss: 0.3309  BEST VAL Loss: 0.3309  Val_Acc: 87.081

Epoch 57: Validation loss decreased (0.330860 --> 0.330477).  Saving model ...
	 Train_Loss: 0.3869 Train_Acc: 84.669 Val_Loss: 0.3305  BEST VAL Loss: 0.3305  Val_Acc: 87.198

Epoch 58: Validation loss decreased (0.330477 --> 0.330184).  Saving model ...
	 Train_Loss: 0.3864 Train_Acc: 84.638 Val_Loss: 0.3302  BEST VAL Loss: 0.3302  Val_Acc: 86.981

Epoch 59: Validation loss decreased (0.330184 --> 0.329739).  Saving model ...
	 Train_Loss: 0.3858 Train_Acc: 84.690 Val_Loss: 0.3297  BEST VAL Loss: 0.3297  Val_Acc: 87.246

Epoch 60: Validation loss decreased (0.329739 --> 0.329401).  Saving model ...
	 Train_Loss: 0.3853 Train_Acc: 84.709 Val_Loss: 0.3294  BEST VAL Loss: 0.3294  Val_Acc: 87.324

Epoch 61: Validation loss decreased (0.329401 --> 0.329096).  Saving model ...
	 Train_Loss: 0.3848 Train_Acc: 84.794 Val_Loss: 0.3291  BEST VAL Loss: 0.3291  Val_Acc: 86.763

Epoch 62: Validation loss decreased (0.329096 --> 0.328708).  Saving model ...
	 Train_Loss: 0.3842 Train_Acc: 84.776 Val_Loss: 0.3287  BEST VAL Loss: 0.3287  Val_Acc: 87.015

Epoch 63: Validation loss decreased (0.328708 --> 0.328310).  Saving model ...
	 Train_Loss: 0.3837 Train_Acc: 84.773 Val_Loss: 0.3283  BEST VAL Loss: 0.3283  Val_Acc: 87.333

Epoch 64: Validation loss decreased (0.328310 --> 0.327981).  Saving model ...
	 Train_Loss: 0.3832 Train_Acc: 84.755 Val_Loss: 0.3280  BEST VAL Loss: 0.3280  Val_Acc: 87.046

Epoch 65: Validation loss decreased (0.327981 --> 0.327564).  Saving model ...
	 Train_Loss: 0.3828 Train_Acc: 84.718 Val_Loss: 0.3276  BEST VAL Loss: 0.3276  Val_Acc: 87.107

Epoch 66: Validation loss decreased (0.327564 --> 0.327166).  Saving model ...
	 Train_Loss: 0.3823 Train_Acc: 84.658 Val_Loss: 0.3272  BEST VAL Loss: 0.3272  Val_Acc: 87.172

Epoch 67: Validation loss decreased (0.327166 --> 0.326784).  Saving model ...
	 Train_Loss: 0.3819 Train_Acc: 84.722 Val_Loss: 0.3268  BEST VAL Loss: 0.3268  Val_Acc: 87.133

Epoch 68: Validation loss decreased (0.326784 --> 0.326351).  Saving model ...
	 Train_Loss: 0.3814 Train_Acc: 84.814 Val_Loss: 0.3264  BEST VAL Loss: 0.3264  Val_Acc: 87.315

Epoch 69: Validation loss decreased (0.326351 --> 0.326016).  Saving model ...
	 Train_Loss: 0.3810 Train_Acc: 84.828 Val_Loss: 0.3260  BEST VAL Loss: 0.3260  Val_Acc: 87.146

Epoch 70: Validation loss decreased (0.326016 --> 0.325834).  Saving model ...
	 Train_Loss: 0.3806 Train_Acc: 84.859 Val_Loss: 0.3258  BEST VAL Loss: 0.3258  Val_Acc: 87.094

Epoch 71: Validation loss decreased (0.325834 --> 0.325608).  Saving model ...
	 Train_Loss: 0.3801 Train_Acc: 84.774 Val_Loss: 0.3256  BEST VAL Loss: 0.3256  Val_Acc: 86.859

Epoch 72: Validation loss decreased (0.325608 --> 0.325319).  Saving model ...
	 Train_Loss: 0.3797 Train_Acc: 84.728 Val_Loss: 0.3253  BEST VAL Loss: 0.3253  Val_Acc: 86.998

Epoch 73: Validation loss decreased (0.325319 --> 0.324941).  Saving model ...
	 Train_Loss: 0.3793 Train_Acc: 84.957 Val_Loss: 0.3249  BEST VAL Loss: 0.3249  Val_Acc: 87.394

Epoch 74: Validation loss decreased (0.324941 --> 0.324558).  Saving model ...
	 Train_Loss: 0.3789 Train_Acc: 84.725 Val_Loss: 0.3246  BEST VAL Loss: 0.3246  Val_Acc: 87.437

Epoch 75: Validation loss decreased (0.324558 --> 0.324353).  Saving model ...
	 Train_Loss: 0.3786 Train_Acc: 84.821 Val_Loss: 0.3244  BEST VAL Loss: 0.3244  Val_Acc: 86.807

Epoch 76: Validation loss decreased (0.324353 --> 0.324153).  Saving model ...
	 Train_Loss: 0.3782 Train_Acc: 84.819 Val_Loss: 0.3242  BEST VAL Loss: 0.3242  Val_Acc: 87.055

Epoch 77: Validation loss decreased (0.324153 --> 0.323863).  Saving model ...
	 Train_Loss: 0.3778 Train_Acc: 84.978 Val_Loss: 0.3239  BEST VAL Loss: 0.3239  Val_Acc: 87.089

Epoch 78: Validation loss decreased (0.323863 --> 0.323607).  Saving model ...
	 Train_Loss: 0.3774 Train_Acc: 84.908 Val_Loss: 0.3236  BEST VAL Loss: 0.3236  Val_Acc: 86.863

Epoch 79: Validation loss decreased (0.323607 --> 0.323307).  Saving model ...
	 Train_Loss: 0.3771 Train_Acc: 84.998 Val_Loss: 0.3233  BEST VAL Loss: 0.3233  Val_Acc: 87.337

Epoch 80: Validation loss decreased (0.323307 --> 0.323036).  Saving model ...
	 Train_Loss: 0.3767 Train_Acc: 84.956 Val_Loss: 0.3230  BEST VAL Loss: 0.3230  Val_Acc: 87.189

Epoch 81: Validation loss decreased (0.323036 --> 0.322766).  Saving model ...
	 Train_Loss: 0.3763 Train_Acc: 84.937 Val_Loss: 0.3228  BEST VAL Loss: 0.3228  Val_Acc: 87.259

Epoch 82: Validation loss decreased (0.322766 --> 0.322459).  Saving model ...
	 Train_Loss: 0.3760 Train_Acc: 85.026 Val_Loss: 0.3225  BEST VAL Loss: 0.3225  Val_Acc: 87.072

Epoch 83: Validation loss decreased (0.322459 --> 0.322158).  Saving model ...
	 Train_Loss: 0.3756 Train_Acc: 84.900 Val_Loss: 0.3222  BEST VAL Loss: 0.3222  Val_Acc: 87.263

Epoch 84: Validation loss decreased (0.322158 --> 0.321894).  Saving model ...
	 Train_Loss: 0.3753 Train_Acc: 85.039 Val_Loss: 0.3219  BEST VAL Loss: 0.3219  Val_Acc: 87.354

Epoch 85: Validation loss decreased (0.321894 --> 0.321604).  Saving model ...
	 Train_Loss: 0.3749 Train_Acc: 84.969 Val_Loss: 0.3216  BEST VAL Loss: 0.3216  Val_Acc: 87.259

Epoch 86: Validation loss decreased (0.321604 --> 0.321331).  Saving model ...
	 Train_Loss: 0.3746 Train_Acc: 84.896 Val_Loss: 0.3213  BEST VAL Loss: 0.3213  Val_Acc: 87.159

Epoch 87: Validation loss decreased (0.321331 --> 0.321065).  Saving model ...
	 Train_Loss: 0.3743 Train_Acc: 85.137 Val_Loss: 0.3211  BEST VAL Loss: 0.3211  Val_Acc: 87.294

Epoch 88: Validation loss decreased (0.321065 --> 0.320906).  Saving model ...
	 Train_Loss: 0.3740 Train_Acc: 84.915 Val_Loss: 0.3209  BEST VAL Loss: 0.3209  Val_Acc: 87.146

Epoch 89: Validation loss decreased (0.320906 --> 0.320703).  Saving model ...
	 Train_Loss: 0.3737 Train_Acc: 85.014 Val_Loss: 0.3207  BEST VAL Loss: 0.3207  Val_Acc: 86.920

Epoch 90: Validation loss decreased (0.320703 --> 0.320481).  Saving model ...
	 Train_Loss: 0.3734 Train_Acc: 85.018 Val_Loss: 0.3205  BEST VAL Loss: 0.3205  Val_Acc: 87.159

Epoch 91: Validation loss decreased (0.320481 --> 0.320318).  Saving model ...
	 Train_Loss: 0.3731 Train_Acc: 84.953 Val_Loss: 0.3203  BEST VAL Loss: 0.3203  Val_Acc: 86.955

Epoch 92: Validation loss decreased (0.320318 --> 0.320121).  Saving model ...
	 Train_Loss: 0.3728 Train_Acc: 84.962 Val_Loss: 0.3201  BEST VAL Loss: 0.3201  Val_Acc: 87.233

Epoch 93: Validation loss decreased (0.320121 --> 0.319971).  Saving model ...
	 Train_Loss: 0.3725 Train_Acc: 85.042 Val_Loss: 0.3200  BEST VAL Loss: 0.3200  Val_Acc: 86.937

Epoch 94: Validation loss decreased (0.319971 --> 0.319764).  Saving model ...
	 Train_Loss: 0.3722 Train_Acc: 85.178 Val_Loss: 0.3198  BEST VAL Loss: 0.3198  Val_Acc: 87.268

Epoch 95: Validation loss decreased (0.319764 --> 0.319673).  Saving model ...
	 Train_Loss: 0.3719 Train_Acc: 84.993 Val_Loss: 0.3197  BEST VAL Loss: 0.3197  Val_Acc: 86.824

Epoch 96: Validation loss decreased (0.319673 --> 0.319531).  Saving model ...
	 Train_Loss: 0.3716 Train_Acc: 85.045 Val_Loss: 0.3195  BEST VAL Loss: 0.3195  Val_Acc: 87.207

Epoch 97: Validation loss decreased (0.319531 --> 0.319351).  Saving model ...
	 Train_Loss: 0.3713 Train_Acc: 85.050 Val_Loss: 0.3194  BEST VAL Loss: 0.3194  Val_Acc: 86.989

Epoch 98: Validation loss decreased (0.319351 --> 0.319207).  Saving model ...
	 Train_Loss: 0.3711 Train_Acc: 85.015 Val_Loss: 0.3192  BEST VAL Loss: 0.3192  Val_Acc: 86.855

Epoch 99: Validation loss decreased (0.319207 --> 0.319020).  Saving model ...
	 Train_Loss: 0.3708 Train_Acc: 84.938 Val_Loss: 0.3190  BEST VAL Loss: 0.3190  Val_Acc: 87.085

Thapsigargin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.85      0.89     95989
           1       0.85      0.93      0.89     88099

    accuracy                           0.89    184088
   macro avg       0.89      0.89      0.89    184088
weighted avg       0.89      0.89      0.89    184088

Thapsigargin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.91      0.83      0.87     11999
           1       0.83      0.91      0.87     11013

    accuracy                           0.87     23012
   macro avg       0.87      0.87      0.87     23012
weighted avg       0.87      0.87      0.87     23012

Thapsigargin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.91      0.83      0.87     11999
           1       0.83      0.91      0.87     11012

    accuracy                           0.87     23011
   macro avg       0.87      0.87      0.87     23011
weighted avg       0.87      0.87      0.87     23011

              precision    recall  f1-score   support

           0       0.91      0.83      0.87     11999
           1       0.83      0.91      0.87     11012

    accuracy                           0.87     23011
   macro avg       0.87      0.87      0.87     23011
weighted avg       0.87      0.87      0.87     23011

Thapsigargin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.76      0.49      0.59     39448
           1       0.61      0.84      0.71     38332

    accuracy                           0.66     77780
   macro avg       0.69      0.66      0.65     77780
weighted avg       0.69      0.66      0.65     77780

              precision    recall  f1-score   support

           0       0.76      0.49      0.59     39448
           1       0.61      0.84      0.71     38332

    accuracy                           0.66     77780
   macro avg       0.69      0.66      0.65     77780
weighted avg       0.69      0.66      0.65     77780

completed
