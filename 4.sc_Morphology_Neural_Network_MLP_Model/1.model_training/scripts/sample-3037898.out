[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '7374e9f0'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '7a0059c4'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '11578788'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '1a1245d1'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_100.000_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_100.000_DMSO_0.025
TREATMENT_NAME: Flagellin_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_100.000_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (263982, 1270)
Number of total missing values across all columns: 564580
Data Subset Is Off
Wells held out for testing: ['J08' 'M10']
Wells to use for training, validation, and testing ['J02' 'J03' 'J09' 'M05' 'M11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.572573).  Saving model ...
	 Train_Loss: 0.6237 Train_Acc: 64.732 Val_Loss: 0.5726  BEST VAL Loss: 0.5726  Val_Acc: 72.555

Epoch 1: Validation loss decreased (0.572573 --> 0.560915).  Saving model ...
	 Train_Loss: 0.6014 Train_Acc: 68.948 Val_Loss: 0.5609  BEST VAL Loss: 0.5609  Val_Acc: 74.198

Epoch 2: Validation loss decreased (0.560915 --> 0.552164).  Saving model ...
	 Train_Loss: 0.5887 Train_Acc: 70.403 Val_Loss: 0.5522  BEST VAL Loss: 0.5522  Val_Acc: 75.482

Epoch 3: Validation loss decreased (0.552164 --> 0.545208).  Saving model ...
	 Train_Loss: 0.5800 Train_Acc: 71.119 Val_Loss: 0.5452  BEST VAL Loss: 0.5452  Val_Acc: 75.893

Epoch 4: Validation loss decreased (0.545208 --> 0.540217).  Saving model ...
	 Train_Loss: 0.5738 Train_Acc: 71.330 Val_Loss: 0.5402  BEST VAL Loss: 0.5402  Val_Acc: 76.335

Epoch 5: Validation loss decreased (0.540217 --> 0.536489).  Saving model ...
	 Train_Loss: 0.5687 Train_Acc: 71.711 Val_Loss: 0.5365  BEST VAL Loss: 0.5365  Val_Acc: 76.642

Epoch 6: Validation loss decreased (0.536489 --> 0.532553).  Saving model ...
	 Train_Loss: 0.5648 Train_Acc: 71.714 Val_Loss: 0.5326  BEST VAL Loss: 0.5326  Val_Acc: 76.709

Epoch 7: Validation loss decreased (0.532553 --> 0.529583).  Saving model ...
	 Train_Loss: 0.5614 Train_Acc: 71.995 Val_Loss: 0.5296  BEST VAL Loss: 0.5296  Val_Acc: 77.401

Epoch 8: Validation loss decreased (0.529583 --> 0.527339).  Saving model ...
	 Train_Loss: 0.5583 Train_Acc: 72.125 Val_Loss: 0.5273  BEST VAL Loss: 0.5273  Val_Acc: 76.517

Epoch 9: Validation loss decreased (0.527339 --> 0.524792).  Saving model ...
	 Train_Loss: 0.5558 Train_Acc: 72.031 Val_Loss: 0.5248  BEST VAL Loss: 0.5248  Val_Acc: 77.260

Epoch 10: Validation loss decreased (0.524792 --> 0.522990).  Saving model ...
	 Train_Loss: 0.5536 Train_Acc: 72.374 Val_Loss: 0.5230  BEST VAL Loss: 0.5230  Val_Acc: 77.323

Epoch 11: Validation loss decreased (0.522990 --> 0.521451).  Saving model ...
	 Train_Loss: 0.5514 Train_Acc: 72.346 Val_Loss: 0.5215  BEST VAL Loss: 0.5215  Val_Acc: 77.094

Epoch 12: Validation loss decreased (0.521451 --> 0.519587).  Saving model ...
	 Train_Loss: 0.5496 Train_Acc: 72.528 Val_Loss: 0.5196  BEST VAL Loss: 0.5196  Val_Acc: 77.172

Epoch 13: Validation loss decreased (0.519587 --> 0.518009).  Saving model ...
	 Train_Loss: 0.5480 Train_Acc: 72.422 Val_Loss: 0.5180  BEST VAL Loss: 0.5180  Val_Acc: 77.385

Epoch 14: Validation loss decreased (0.518009 --> 0.516371).  Saving model ...
	 Train_Loss: 0.5464 Train_Acc: 72.534 Val_Loss: 0.5164  BEST VAL Loss: 0.5164  Val_Acc: 77.411

Epoch 15: Validation loss decreased (0.516371 --> 0.515239).  Saving model ...
	 Train_Loss: 0.5450 Train_Acc: 72.587 Val_Loss: 0.5152  BEST VAL Loss: 0.5152  Val_Acc: 78.045

Epoch 16: Validation loss decreased (0.515239 --> 0.513664).  Saving model ...
	 Train_Loss: 0.5436 Train_Acc: 72.773 Val_Loss: 0.5137  BEST VAL Loss: 0.5137  Val_Acc: 78.009

Epoch 17: Validation loss decreased (0.513664 --> 0.512304).  Saving model ...
	 Train_Loss: 0.5423 Train_Acc: 72.818 Val_Loss: 0.5123  BEST VAL Loss: 0.5123  Val_Acc: 78.170

Epoch 18: Validation loss decreased (0.512304 --> 0.511047).  Saving model ...
	 Train_Loss: 0.5412 Train_Acc: 72.731 Val_Loss: 0.5110  BEST VAL Loss: 0.5110  Val_Acc: 78.113

Epoch 19: Validation loss decreased (0.511047 --> 0.509530).  Saving model ...
	 Train_Loss: 0.5400 Train_Acc: 72.849 Val_Loss: 0.5095  BEST VAL Loss: 0.5095  Val_Acc: 78.274

Epoch 20: Validation loss decreased (0.509530 --> 0.508263).  Saving model ...
	 Train_Loss: 0.5389 Train_Acc: 72.849 Val_Loss: 0.5083  BEST VAL Loss: 0.5083  Val_Acc: 78.446

Epoch 21: Validation loss decreased (0.508263 --> 0.506987).  Saving model ...
	 Train_Loss: 0.5379 Train_Acc: 73.009 Val_Loss: 0.5070  BEST VAL Loss: 0.5070  Val_Acc: 78.134

Epoch 22: Validation loss decreased (0.506987 --> 0.505841).  Saving model ...
	 Train_Loss: 0.5369 Train_Acc: 72.995 Val_Loss: 0.5058  BEST VAL Loss: 0.5058  Val_Acc: 78.404

Epoch 23: Validation loss decreased (0.505841 --> 0.505043).  Saving model ...
	 Train_Loss: 0.5359 Train_Acc: 73.020 Val_Loss: 0.5050  BEST VAL Loss: 0.5050  Val_Acc: 77.967

Epoch 24: Validation loss decreased (0.505043 --> 0.503951).  Saving model ...
	 Train_Loss: 0.5350 Train_Acc: 73.157 Val_Loss: 0.5040  BEST VAL Loss: 0.5040  Val_Acc: 78.440

Epoch 25: Validation loss decreased (0.503951 --> 0.502982).  Saving model ...
	 Train_Loss: 0.5341 Train_Acc: 73.175 Val_Loss: 0.5030  BEST VAL Loss: 0.5030  Val_Acc: 78.290

Epoch 26: Validation loss decreased (0.502982 --> 0.501937).  Saving model ...
	 Train_Loss: 0.5333 Train_Acc: 73.181 Val_Loss: 0.5019  BEST VAL Loss: 0.5019  Val_Acc: 78.331

Epoch 27: Validation loss decreased (0.501937 --> 0.501223).  Saving model ...
	 Train_Loss: 0.5325 Train_Acc: 73.233 Val_Loss: 0.5012  BEST VAL Loss: 0.5012  Val_Acc: 78.170

Epoch 28: Validation loss decreased (0.501223 --> 0.500487).  Saving model ...
	 Train_Loss: 0.5316 Train_Acc: 73.510 Val_Loss: 0.5005  BEST VAL Loss: 0.5005  Val_Acc: 78.539

Epoch 29: Validation loss decreased (0.500487 --> 0.499843).  Saving model ...
	 Train_Loss: 0.5309 Train_Acc: 73.705 Val_Loss: 0.4998  BEST VAL Loss: 0.4998  Val_Acc: 78.347

Epoch 30: Validation loss decreased (0.499843 --> 0.499108).  Saving model ...
	 Train_Loss: 0.5302 Train_Acc: 74.089 Val_Loss: 0.4991  BEST VAL Loss: 0.4991  Val_Acc: 78.196

Epoch 31: Validation loss decreased (0.499108 --> 0.498391).  Saving model ...
	 Train_Loss: 0.5295 Train_Acc: 74.803 Val_Loss: 0.4984  BEST VAL Loss: 0.4984  Val_Acc: 78.981

Epoch 32: Validation loss decreased (0.498391 --> 0.497536).  Saving model ...
	 Train_Loss: 0.5288 Train_Acc: 74.154 Val_Loss: 0.4975  BEST VAL Loss: 0.4975  Val_Acc: 78.602

Epoch 33: Validation loss decreased (0.497536 --> 0.496674).  Saving model ...
	 Train_Loss: 0.5282 Train_Acc: 74.078 Val_Loss: 0.4967  BEST VAL Loss: 0.4967  Val_Acc: 78.851

Epoch 34: Validation loss decreased (0.496674 --> 0.495882).  Saving model ...
	 Train_Loss: 0.5276 Train_Acc: 74.323 Val_Loss: 0.4959  BEST VAL Loss: 0.4959  Val_Acc: 78.737

Epoch 35: Validation loss decreased (0.495882 --> 0.495068).  Saving model ...
	 Train_Loss: 0.5270 Train_Acc: 73.822 Val_Loss: 0.4951  BEST VAL Loss: 0.4951  Val_Acc: 78.887

Epoch 36: Validation loss decreased (0.495068 --> 0.494379).  Saving model ...
	 Train_Loss: 0.5264 Train_Acc: 75.421 Val_Loss: 0.4944  BEST VAL Loss: 0.4944  Val_Acc: 79.075

Epoch 37: Validation loss decreased (0.494379 --> 0.493511).  Saving model ...
	 Train_Loss: 0.5258 Train_Acc: 76.114 Val_Loss: 0.4935  BEST VAL Loss: 0.4935  Val_Acc: 78.981

Epoch 38: Validation loss decreased (0.493511 --> 0.492974).  Saving model ...
	 Train_Loss: 0.5252 Train_Acc: 75.045 Val_Loss: 0.4930  BEST VAL Loss: 0.4930  Val_Acc: 78.752

Epoch 39: Validation loss decreased (0.492974 --> 0.492355).  Saving model ...
	 Train_Loss: 0.5246 Train_Acc: 74.011 Val_Loss: 0.4924  BEST VAL Loss: 0.4924  Val_Acc: 78.534

Epoch 40: Validation loss decreased (0.492355 --> 0.491726).  Saving model ...
	 Train_Loss: 0.5241 Train_Acc: 75.528 Val_Loss: 0.4917  BEST VAL Loss: 0.4917  Val_Acc: 79.043

Epoch 41: Validation loss decreased (0.491726 --> 0.491061).  Saving model ...
	 Train_Loss: 0.5236 Train_Acc: 73.759 Val_Loss: 0.4911  BEST VAL Loss: 0.4911  Val_Acc: 79.205

Epoch 42: Validation loss decreased (0.491061 --> 0.490409).  Saving model ...
	 Train_Loss: 0.5231 Train_Acc: 73.823 Val_Loss: 0.4904  BEST VAL Loss: 0.4904  Val_Acc: 79.168

Epoch 43: Validation loss decreased (0.490409 --> 0.489732).  Saving model ...
	 Train_Loss: 0.5226 Train_Acc: 73.773 Val_Loss: 0.4897  BEST VAL Loss: 0.4897  Val_Acc: 79.111

Epoch 44: Validation loss decreased (0.489732 --> 0.489172).  Saving model ...
	 Train_Loss: 0.5221 Train_Acc: 74.358 Val_Loss: 0.4892  BEST VAL Loss: 0.4892  Val_Acc: 79.319

Epoch 45: Validation loss decreased (0.489172 --> 0.488566).  Saving model ...
	 Train_Loss: 0.5216 Train_Acc: 75.724 Val_Loss: 0.4886  BEST VAL Loss: 0.4886  Val_Acc: 79.402

Epoch 46: Validation loss decreased (0.488566 --> 0.488038).  Saving model ...
	 Train_Loss: 0.5211 Train_Acc: 75.368 Val_Loss: 0.4880  BEST VAL Loss: 0.4880  Val_Acc: 79.288

Epoch 47: Validation loss decreased (0.488038 --> 0.487552).  Saving model ...
	 Train_Loss: 0.5207 Train_Acc: 76.155 Val_Loss: 0.4876  BEST VAL Loss: 0.4876  Val_Acc: 79.303

Epoch 48: Validation loss decreased (0.487552 --> 0.487048).  Saving model ...
	 Train_Loss: 0.5202 Train_Acc: 76.419 Val_Loss: 0.4870  BEST VAL Loss: 0.4870  Val_Acc: 79.517

Epoch 49: Validation loss decreased (0.487048 --> 0.486573).  Saving model ...
	 Train_Loss: 0.5198 Train_Acc: 76.372 Val_Loss: 0.4866  BEST VAL Loss: 0.4866  Val_Acc: 79.163

Epoch 50: Validation loss decreased (0.486573 --> 0.485989).  Saving model ...
	 Train_Loss: 0.5194 Train_Acc: 76.442 Val_Loss: 0.4860  BEST VAL Loss: 0.4860  Val_Acc: 79.387

Epoch 51: Validation loss decreased (0.485989 --> 0.485491).  Saving model ...
	 Train_Loss: 0.5189 Train_Acc: 76.433 Val_Loss: 0.4855  BEST VAL Loss: 0.4855  Val_Acc: 79.257

Epoch 52: Validation loss decreased (0.485491 --> 0.485018).  Saving model ...
	 Train_Loss: 0.5185 Train_Acc: 76.084 Val_Loss: 0.4850  BEST VAL Loss: 0.4850  Val_Acc: 79.184

Epoch 53: Validation loss decreased (0.485018 --> 0.484504).  Saving model ...
	 Train_Loss: 0.5181 Train_Acc: 75.706 Val_Loss: 0.4845  BEST VAL Loss: 0.4845  Val_Acc: 79.283

Epoch 54: Validation loss decreased (0.484504 --> 0.483989).  Saving model ...
	 Train_Loss: 0.5177 Train_Acc: 76.587 Val_Loss: 0.4840  BEST VAL Loss: 0.4840  Val_Acc: 79.350

Epoch 55: Validation loss decreased (0.483989 --> 0.483487).  Saving model ...
	 Train_Loss: 0.5173 Train_Acc: 76.183 Val_Loss: 0.4835  BEST VAL Loss: 0.4835  Val_Acc: 79.184

Epoch 56: Validation loss decreased (0.483487 --> 0.483075).  Saving model ...
	 Train_Loss: 0.5168 Train_Acc: 76.583 Val_Loss: 0.4831  BEST VAL Loss: 0.4831  Val_Acc: 78.825

Epoch 57: Validation loss decreased (0.483075 --> 0.482588).  Saving model ...
	 Train_Loss: 0.5164 Train_Acc: 76.552 Val_Loss: 0.4826  BEST VAL Loss: 0.4826  Val_Acc: 79.267

Epoch 58: Validation loss decreased (0.482588 --> 0.482071).  Saving model ...
	 Train_Loss: 0.5160 Train_Acc: 76.564 Val_Loss: 0.4821  BEST VAL Loss: 0.4821  Val_Acc: 79.808

Epoch 59: Validation loss decreased (0.482071 --> 0.481640).  Saving model ...
	 Train_Loss: 0.5157 Train_Acc: 76.719 Val_Loss: 0.4816  BEST VAL Loss: 0.4816  Val_Acc: 79.012

Epoch 60: Validation loss decreased (0.481640 --> 0.481299).  Saving model ...
	 Train_Loss: 0.5153 Train_Acc: 76.574 Val_Loss: 0.4813  BEST VAL Loss: 0.4813  Val_Acc: 79.501

Epoch 61: Validation loss decreased (0.481299 --> 0.480905).  Saving model ...
	 Train_Loss: 0.5149 Train_Acc: 76.326 Val_Loss: 0.4809  BEST VAL Loss: 0.4809  Val_Acc: 79.371

Epoch 62: Validation loss decreased (0.480905 --> 0.480543).  Saving model ...
	 Train_Loss: 0.5146 Train_Acc: 76.731 Val_Loss: 0.4805  BEST VAL Loss: 0.4805  Val_Acc: 79.568

Epoch 63: Validation loss decreased (0.480543 --> 0.480091).  Saving model ...
	 Train_Loss: 0.5142 Train_Acc: 76.892 Val_Loss: 0.4801  BEST VAL Loss: 0.4801  Val_Acc: 79.444

Epoch 64: Validation loss decreased (0.480091 --> 0.479708).  Saving model ...
	 Train_Loss: 0.5138 Train_Acc: 76.792 Val_Loss: 0.4797  BEST VAL Loss: 0.4797  Val_Acc: 79.584

Epoch 65: Validation loss decreased (0.479708 --> 0.479344).  Saving model ...
	 Train_Loss: 0.5135 Train_Acc: 76.894 Val_Loss: 0.4793  BEST VAL Loss: 0.4793  Val_Acc: 79.563

Epoch 66: Validation loss decreased (0.479344 --> 0.479021).  Saving model ...
	 Train_Loss: 0.5132 Train_Acc: 76.706 Val_Loss: 0.4790  BEST VAL Loss: 0.4790  Val_Acc: 79.324

Epoch 67: Validation loss decreased (0.479021 --> 0.478661).  Saving model ...
	 Train_Loss: 0.5128 Train_Acc: 76.794 Val_Loss: 0.4787  BEST VAL Loss: 0.4787  Val_Acc: 80.192

Epoch 68: Validation loss decreased (0.478661 --> 0.478354).  Saving model ...
	 Train_Loss: 0.5125 Train_Acc: 76.892 Val_Loss: 0.4784  BEST VAL Loss: 0.4784  Val_Acc: 78.945

Epoch 69: Validation loss decreased (0.478354 --> 0.478044).  Saving model ...
	 Train_Loss: 0.5122 Train_Acc: 76.836 Val_Loss: 0.4780  BEST VAL Loss: 0.4780  Val_Acc: 79.361

Epoch 70: Validation loss decreased (0.478044 --> 0.477710).  Saving model ...
	 Train_Loss: 0.5119 Train_Acc: 76.922 Val_Loss: 0.4777  BEST VAL Loss: 0.4777  Val_Acc: 79.808

Epoch 71: Validation loss decreased (0.477710 --> 0.477371).  Saving model ...
	 Train_Loss: 0.5116 Train_Acc: 76.827 Val_Loss: 0.4774  BEST VAL Loss: 0.4774  Val_Acc: 79.413

Epoch 72: Validation loss decreased (0.477371 --> 0.477063).  Saving model ...
	 Train_Loss: 0.5113 Train_Acc: 76.818 Val_Loss: 0.4771  BEST VAL Loss: 0.4771  Val_Acc: 79.730

Epoch 73: Validation loss decreased (0.477063 --> 0.476666).  Saving model ...
	 Train_Loss: 0.5110 Train_Acc: 76.845 Val_Loss: 0.4767  BEST VAL Loss: 0.4767  Val_Acc: 79.922

Epoch 74: Validation loss decreased (0.476666 --> 0.476337).  Saving model ...
	 Train_Loss: 0.5107 Train_Acc: 76.988 Val_Loss: 0.4763  BEST VAL Loss: 0.4763  Val_Acc: 79.730

Epoch 75: Validation loss decreased (0.476337 --> 0.475976).  Saving model ...
	 Train_Loss: 0.5104 Train_Acc: 76.956 Val_Loss: 0.4760  BEST VAL Loss: 0.4760  Val_Acc: 79.641

Epoch 76: Validation loss decreased (0.475976 --> 0.475672).  Saving model ...
	 Train_Loss: 0.5101 Train_Acc: 76.956 Val_Loss: 0.4757  BEST VAL Loss: 0.4757  Val_Acc: 79.449

Epoch 77: Validation loss decreased (0.475672 --> 0.475405).  Saving model ...
	 Train_Loss: 0.5098 Train_Acc: 76.962 Val_Loss: 0.4754  BEST VAL Loss: 0.4754  Val_Acc: 79.891

Epoch 78: Validation loss decreased (0.475405 --> 0.475121).  Saving model ...
	 Train_Loss: 0.5096 Train_Acc: 76.801 Val_Loss: 0.4751  BEST VAL Loss: 0.4751  Val_Acc: 79.922

Epoch 79: Validation loss decreased (0.475121 --> 0.474831).  Saving model ...
	 Train_Loss: 0.5093 Train_Acc: 77.023 Val_Loss: 0.4748  BEST VAL Loss: 0.4748  Val_Acc: 79.548

Epoch 80: Validation loss decreased (0.474831 --> 0.474516).  Saving model ...
	 Train_Loss: 0.5090 Train_Acc: 77.056 Val_Loss: 0.4745  BEST VAL Loss: 0.4745  Val_Acc: 79.828

Epoch 81: Validation loss decreased (0.474516 --> 0.474240).  Saving model ...
	 Train_Loss: 0.5088 Train_Acc: 77.024 Val_Loss: 0.4742  BEST VAL Loss: 0.4742  Val_Acc: 79.776

Epoch 82: Validation loss decreased (0.474240 --> 0.473897).  Saving model ...
	 Train_Loss: 0.5085 Train_Acc: 76.988 Val_Loss: 0.4739  BEST VAL Loss: 0.4739  Val_Acc: 79.984

Epoch 83: Validation loss decreased (0.473897 --> 0.473640).  Saving model ...
	 Train_Loss: 0.5082 Train_Acc: 77.107 Val_Loss: 0.4736  BEST VAL Loss: 0.4736  Val_Acc: 79.740

Epoch 84: Validation loss decreased (0.473640 --> 0.473387).  Saving model ...
	 Train_Loss: 0.5080 Train_Acc: 76.892 Val_Loss: 0.4734  BEST VAL Loss: 0.4734  Val_Acc: 79.605

Epoch 85: Validation loss decreased (0.473387 --> 0.473131).  Saving model ...
	 Train_Loss: 0.5077 Train_Acc: 76.886 Val_Loss: 0.4731  BEST VAL Loss: 0.4731  Val_Acc: 79.776

Epoch 86: Validation loss decreased (0.473131 --> 0.472866).  Saving model ...
	 Train_Loss: 0.5075 Train_Acc: 77.006 Val_Loss: 0.4729  BEST VAL Loss: 0.4729  Val_Acc: 79.730

Epoch 87: Validation loss decreased (0.472866 --> 0.472573).  Saving model ...
	 Train_Loss: 0.5072 Train_Acc: 77.198 Val_Loss: 0.4726  BEST VAL Loss: 0.4726  Val_Acc: 79.818

Epoch 88: Validation loss decreased (0.472573 --> 0.472296).  Saving model ...
	 Train_Loss: 0.5070 Train_Acc: 77.072 Val_Loss: 0.4723  BEST VAL Loss: 0.4723  Val_Acc: 78.965

Epoch 89: Validation loss decreased (0.472296 --> 0.472020).  Saving model ...
	 Train_Loss: 0.5067 Train_Acc: 77.018 Val_Loss: 0.4720  BEST VAL Loss: 0.4720  Val_Acc: 79.860

Epoch 90: Validation loss decreased (0.472020 --> 0.471717).  Saving model ...
	 Train_Loss: 0.5065 Train_Acc: 77.032 Val_Loss: 0.4717  BEST VAL Loss: 0.4717  Val_Acc: 80.369

Epoch 91: Validation loss decreased (0.471717 --> 0.471454).  Saving model ...
	 Train_Loss: 0.5063 Train_Acc: 77.184 Val_Loss: 0.4715  BEST VAL Loss: 0.4715  Val_Acc: 80.177

Epoch 92: Validation loss decreased (0.471454 --> 0.471137).  Saving model ...
	 Train_Loss: 0.5060 Train_Acc: 77.207 Val_Loss: 0.4711  BEST VAL Loss: 0.4711  Val_Acc: 80.166

Epoch 93: Validation loss decreased (0.471137 --> 0.470867).  Saving model ...
	 Train_Loss: 0.5058 Train_Acc: 77.103 Val_Loss: 0.4709  BEST VAL Loss: 0.4709  Val_Acc: 80.000

Epoch 94: Validation loss decreased (0.470867 --> 0.470607).  Saving model ...
	 Train_Loss: 0.5055 Train_Acc: 77.250 Val_Loss: 0.4706  BEST VAL Loss: 0.4706  Val_Acc: 79.101

Epoch 95: Validation loss decreased (0.470607 --> 0.470323).  Saving model ...
	 Train_Loss: 0.5053 Train_Acc: 77.100 Val_Loss: 0.4703  BEST VAL Loss: 0.4703  Val_Acc: 80.057

Epoch 96: Validation loss decreased (0.470323 --> 0.470050).  Saving model ...
	 Train_Loss: 0.5051 Train_Acc: 77.237 Val_Loss: 0.4700  BEST VAL Loss: 0.4700  Val_Acc: 80.042

Epoch 97: Validation loss decreased (0.470050 --> 0.469801).  Saving model ...
	 Train_Loss: 0.5049 Train_Acc: 77.161 Val_Loss: 0.4698  BEST VAL Loss: 0.4698  Val_Acc: 80.359

Epoch 98: Validation loss decreased (0.469801 --> 0.469589).  Saving model ...
	 Train_Loss: 0.5046 Train_Acc: 77.292 Val_Loss: 0.4696  BEST VAL Loss: 0.4696  Val_Acc: 80.052

Epoch 99: Validation loss decreased (0.469589 --> 0.469381).  Saving model ...
	 Train_Loss: 0.5044 Train_Acc: 77.232 Val_Loss: 0.4694  BEST VAL Loss: 0.4694  Val_Acc: 79.844

LPS_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.84      0.61      0.71     56122
           1       0.81      0.93      0.87     97753

    accuracy                           0.82    153875
   macro avg       0.82      0.77      0.79    153875
weighted avg       0.82      0.82      0.81    153875

LPS_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.82      0.58      0.68      7015
           1       0.79      0.93      0.85     12220

    accuracy                           0.80     19235
   macro avg       0.80      0.75      0.77     19235
weighted avg       0.80      0.80      0.79     19235

LPS_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.82      0.58      0.68      7016
           1       0.79      0.93      0.85     12219

    accuracy                           0.80     19235
   macro avg       0.81      0.75      0.77     19235
weighted avg       0.80      0.80      0.79     19235

              precision    recall  f1-score   support

           0       0.82      0.58      0.68      7016
           1       0.79      0.93      0.85     12219

    accuracy                           0.80     19235
   macro avg       0.81      0.75      0.77     19235
weighted avg       0.80      0.80      0.79     19235

LPS_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.80      0.23      0.35     34394
           1       0.57      0.95      0.71     37243

    accuracy                           0.60     71637
   macro avg       0.68      0.59      0.53     71637
weighted avg       0.68      0.60      0.54     71637

              precision    recall  f1-score   support

           0       0.80      0.23      0.35     34394
           1       0.57      0.95      0.71     37243

    accuracy                           0.60     71637
   macro avg       0.68      0.59      0.53     71637
weighted avg       0.68      0.60      0.54     71637

completed
