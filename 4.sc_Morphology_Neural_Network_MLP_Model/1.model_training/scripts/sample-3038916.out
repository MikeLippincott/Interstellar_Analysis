[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b56da867'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '9c18d2b0'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '5fa0516a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'd7e18516'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_0.100_DMSO_0.025 treatment_name: LPS_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_0.100_DMSO_0.025
TREATMENT_NAME: LPS_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_1.000_DMSO_0.025']
The dimensions of the data are: (33968, 1276)
Number of total missing values across all columns: 67936
Data Subset Is Off
Wells held out for testing: ['C20' 'D21']
Wells to use for training, validation, and testing ['C16' 'D16' 'C17' 'D17' 'D20' 'C21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.696515).  Saving model ...
	 Train_Loss: 0.7032 Train_Acc: 49.692 Val_Loss: 0.6965  BEST VAL Loss: 0.6965  Val_Acc: 50.234

Epoch 1: Validation loss decreased (0.696515 --> 0.693295).  Saving model ...
	 Train_Loss: 0.6989 Train_Acc: 51.548 Val_Loss: 0.6933  BEST VAL Loss: 0.6933  Val_Acc: 53.594

Epoch 2: Validation loss decreased (0.693295 --> 0.690607).  Saving model ...
	 Train_Loss: 0.6952 Train_Acc: 53.521 Val_Loss: 0.6906  BEST VAL Loss: 0.6906  Val_Acc: 55.703

Epoch 3: Validation loss decreased (0.690607 --> 0.688393).  Saving model ...
	 Train_Loss: 0.6926 Train_Acc: 54.043 Val_Loss: 0.6884  BEST VAL Loss: 0.6884  Val_Acc: 57.188

Epoch 4: Validation loss decreased (0.688393 --> 0.686412).  Saving model ...
	 Train_Loss: 0.6902 Train_Acc: 55.444 Val_Loss: 0.6864  BEST VAL Loss: 0.6864  Val_Acc: 58.359

Epoch 5: Validation loss decreased (0.686412 --> 0.684623).  Saving model ...
	 Train_Loss: 0.6876 Train_Acc: 56.968 Val_Loss: 0.6846  BEST VAL Loss: 0.6846  Val_Acc: 59.258

Epoch 6: Validation loss decreased (0.684623 --> 0.682945).  Saving model ...
	 Train_Loss: 0.6854 Train_Acc: 58.198 Val_Loss: 0.6829  BEST VAL Loss: 0.6829  Val_Acc: 60.234

Epoch 7: Validation loss decreased (0.682945 --> 0.681403).  Saving model ...
	 Train_Loss: 0.6836 Train_Acc: 58.872 Val_Loss: 0.6814  BEST VAL Loss: 0.6814  Val_Acc: 60.586

Epoch 8: Validation loss decreased (0.681403 --> 0.679893).  Saving model ...
	 Train_Loss: 0.6816 Train_Acc: 60.005 Val_Loss: 0.6799  BEST VAL Loss: 0.6799  Val_Acc: 61.133

Epoch 9: Validation loss decreased (0.679893 --> 0.678498).  Saving model ...
	 Train_Loss: 0.6799 Train_Acc: 59.751 Val_Loss: 0.6785  BEST VAL Loss: 0.6785  Val_Acc: 61.367

Epoch 10: Validation loss decreased (0.678498 --> 0.677199).  Saving model ...
	 Train_Loss: 0.6782 Train_Acc: 60.669 Val_Loss: 0.6772  BEST VAL Loss: 0.6772  Val_Acc: 61.758

Epoch 11: Validation loss decreased (0.677199 --> 0.675932).  Saving model ...
	 Train_Loss: 0.6763 Train_Acc: 61.484 Val_Loss: 0.6759  BEST VAL Loss: 0.6759  Val_Acc: 61.406

Epoch 12: Validation loss decreased (0.675932 --> 0.674738).  Saving model ...
	 Train_Loss: 0.6748 Train_Acc: 61.367 Val_Loss: 0.6747  BEST VAL Loss: 0.6747  Val_Acc: 62.031

Epoch 13: Validation loss decreased (0.674738 --> 0.673599).  Saving model ...
	 Train_Loss: 0.6733 Train_Acc: 61.885 Val_Loss: 0.6736  BEST VAL Loss: 0.6736  Val_Acc: 61.953

Epoch 14: Validation loss decreased (0.673599 --> 0.672530).  Saving model ...
	 Train_Loss: 0.6718 Train_Acc: 62.183 Val_Loss: 0.6725  BEST VAL Loss: 0.6725  Val_Acc: 61.992

Epoch 15: Validation loss decreased (0.672530 --> 0.671526).  Saving model ...
	 Train_Loss: 0.6703 Train_Acc: 62.456 Val_Loss: 0.6715  BEST VAL Loss: 0.6715  Val_Acc: 62.266

Epoch 16: Validation loss decreased (0.671526 --> 0.670567).  Saving model ...
	 Train_Loss: 0.6688 Train_Acc: 62.998 Val_Loss: 0.6706  BEST VAL Loss: 0.6706  Val_Acc: 62.461

Epoch 17: Validation loss decreased (0.670567 --> 0.669683).  Saving model ...
	 Train_Loss: 0.6673 Train_Acc: 63.428 Val_Loss: 0.6697  BEST VAL Loss: 0.6697  Val_Acc: 62.773

Epoch 18: Validation loss decreased (0.669683 --> 0.668829).  Saving model ...
	 Train_Loss: 0.6660 Train_Acc: 63.091 Val_Loss: 0.6688  BEST VAL Loss: 0.6688  Val_Acc: 62.734

Epoch 19: Validation loss decreased (0.668829 --> 0.668005).  Saving model ...
	 Train_Loss: 0.6646 Train_Acc: 63.135 Val_Loss: 0.6680  BEST VAL Loss: 0.6680  Val_Acc: 63.359

Epoch 20: Validation loss decreased (0.668005 --> 0.667222).  Saving model ...
	 Train_Loss: 0.6632 Train_Acc: 64.155 Val_Loss: 0.6672  BEST VAL Loss: 0.6672  Val_Acc: 63.477

Epoch 21: Validation loss decreased (0.667222 --> 0.666469).  Saving model ...
	 Train_Loss: 0.6619 Train_Acc: 64.390 Val_Loss: 0.6665  BEST VAL Loss: 0.6665  Val_Acc: 63.750

Epoch 22: Validation loss decreased (0.666469 --> 0.665744).  Saving model ...
	 Train_Loss: 0.6605 Train_Acc: 64.619 Val_Loss: 0.6657  BEST VAL Loss: 0.6657  Val_Acc: 63.984

Epoch 23: Validation loss decreased (0.665744 --> 0.665074).  Saving model ...
	 Train_Loss: 0.6592 Train_Acc: 64.331 Val_Loss: 0.6651  BEST VAL Loss: 0.6651  Val_Acc: 63.945

Epoch 24: Validation loss decreased (0.665074 --> 0.664441).  Saving model ...
	 Train_Loss: 0.6580 Train_Acc: 64.810 Val_Loss: 0.6644  BEST VAL Loss: 0.6644  Val_Acc: 63.711

Epoch 25: Validation loss decreased (0.664441 --> 0.663830).  Saving model ...
	 Train_Loss: 0.6568 Train_Acc: 64.927 Val_Loss: 0.6638  BEST VAL Loss: 0.6638  Val_Acc: 64.023

Epoch 26: Validation loss decreased (0.663830 --> 0.663269).  Saving model ...
	 Train_Loss: 0.6557 Train_Acc: 64.873 Val_Loss: 0.6633  BEST VAL Loss: 0.6633  Val_Acc: 64.023

Epoch 27: Validation loss decreased (0.663269 --> 0.662719).  Saving model ...
	 Train_Loss: 0.6545 Train_Acc: 64.888 Val_Loss: 0.6627  BEST VAL Loss: 0.6627  Val_Acc: 64.141

Epoch 28: Validation loss decreased (0.662719 --> 0.662203).  Saving model ...
	 Train_Loss: 0.6534 Train_Acc: 65.425 Val_Loss: 0.6622  BEST VAL Loss: 0.6622  Val_Acc: 64.062

Epoch 29: Validation loss decreased (0.662203 --> 0.661712).  Saving model ...
	 Train_Loss: 0.6522 Train_Acc: 65.796 Val_Loss: 0.6617  BEST VAL Loss: 0.6617  Val_Acc: 64.336

Epoch 30: Validation loss decreased (0.661712 --> 0.661229).  Saving model ...
	 Train_Loss: 0.6512 Train_Acc: 65.137 Val_Loss: 0.6612  BEST VAL Loss: 0.6612  Val_Acc: 64.414

Epoch 31: Validation loss decreased (0.661229 --> 0.660777).  Saving model ...
	 Train_Loss: 0.6502 Train_Acc: 65.586 Val_Loss: 0.6608  BEST VAL Loss: 0.6608  Val_Acc: 64.570

Epoch 32: Validation loss decreased (0.660777 --> 0.660329).  Saving model ...
	 Train_Loss: 0.6492 Train_Acc: 65.459 Val_Loss: 0.6603  BEST VAL Loss: 0.6603  Val_Acc: 64.648

Epoch 33: Validation loss decreased (0.660329 --> 0.659917).  Saving model ...
	 Train_Loss: 0.6482 Train_Acc: 65.796 Val_Loss: 0.6599  BEST VAL Loss: 0.6599  Val_Acc: 64.609

Epoch 34: Validation loss decreased (0.659917 --> 0.659512).  Saving model ...
	 Train_Loss: 0.6472 Train_Acc: 65.835 Val_Loss: 0.6595  BEST VAL Loss: 0.6595  Val_Acc: 64.883

Epoch 35: Validation loss decreased (0.659512 --> 0.659123).  Saving model ...
	 Train_Loss: 0.6463 Train_Acc: 65.757 Val_Loss: 0.6591  BEST VAL Loss: 0.6591  Val_Acc: 65.039

Epoch 36: Validation loss decreased (0.659123 --> 0.658734).  Saving model ...
	 Train_Loss: 0.6454 Train_Acc: 66.182 Val_Loss: 0.6587  BEST VAL Loss: 0.6587  Val_Acc: 64.922

Epoch 37: Validation loss decreased (0.658734 --> 0.658378).  Saving model ...
	 Train_Loss: 0.6445 Train_Acc: 66.030 Val_Loss: 0.6584  BEST VAL Loss: 0.6584  Val_Acc: 64.766

Epoch 38: Validation loss decreased (0.658378 --> 0.658037).  Saving model ...
	 Train_Loss: 0.6436 Train_Acc: 66.528 Val_Loss: 0.6580  BEST VAL Loss: 0.6580  Val_Acc: 65.078

Epoch 39: Validation loss decreased (0.658037 --> 0.657705).  Saving model ...
	 Train_Loss: 0.6426 Train_Acc: 66.372 Val_Loss: 0.6577  BEST VAL Loss: 0.6577  Val_Acc: 65.000

Epoch 40: Validation loss decreased (0.657705 --> 0.657383).  Saving model ...
	 Train_Loss: 0.6418 Train_Acc: 66.455 Val_Loss: 0.6574  BEST VAL Loss: 0.6574  Val_Acc: 65.195

Epoch 41: Validation loss decreased (0.657383 --> 0.657084).  Saving model ...
	 Train_Loss: 0.6409 Train_Acc: 66.416 Val_Loss: 0.6571  BEST VAL Loss: 0.6571  Val_Acc: 65.117

Epoch 42: Validation loss decreased (0.657084 --> 0.656796).  Saving model ...
	 Train_Loss: 0.6401 Train_Acc: 67.153 Val_Loss: 0.6568  BEST VAL Loss: 0.6568  Val_Acc: 65.195

Epoch 43: Validation loss decreased (0.656796 --> 0.656520).  Saving model ...
	 Train_Loss: 0.6393 Train_Acc: 66.772 Val_Loss: 0.6565  BEST VAL Loss: 0.6565  Val_Acc: 65.195

Epoch 44: Validation loss decreased (0.656520 --> 0.656256).  Saving model ...
	 Train_Loss: 0.6385 Train_Acc: 66.787 Val_Loss: 0.6563  BEST VAL Loss: 0.6563  Val_Acc: 65.117

Epoch 45: Validation loss decreased (0.656256 --> 0.656009).  Saving model ...
	 Train_Loss: 0.6377 Train_Acc: 67.217 Val_Loss: 0.6560  BEST VAL Loss: 0.6560  Val_Acc: 64.961

Epoch 46: Validation loss decreased (0.656009 --> 0.655759).  Saving model ...
	 Train_Loss: 0.6370 Train_Acc: 66.792 Val_Loss: 0.6558  BEST VAL Loss: 0.6558  Val_Acc: 64.883

Epoch 47: Validation loss decreased (0.655759 --> 0.655544).  Saving model ...
	 Train_Loss: 0.6362 Train_Acc: 67.026 Val_Loss: 0.6555  BEST VAL Loss: 0.6555  Val_Acc: 65.508

Epoch 48: Validation loss decreased (0.655544 --> 0.655346).  Saving model ...
	 Train_Loss: 0.6355 Train_Acc: 67.310 Val_Loss: 0.6553  BEST VAL Loss: 0.6553  Val_Acc: 65.586

Epoch 49: Validation loss decreased (0.655346 --> 0.655141).  Saving model ...
	 Train_Loss: 0.6347 Train_Acc: 67.778 Val_Loss: 0.6551  BEST VAL Loss: 0.6551  Val_Acc: 65.625

Epoch 50: Validation loss decreased (0.655141 --> 0.654960).  Saving model ...
	 Train_Loss: 0.6339 Train_Acc: 67.363 Val_Loss: 0.6550  BEST VAL Loss: 0.6550  Val_Acc: 65.547

Epoch 51: Validation loss decreased (0.654960 --> 0.654778).  Saving model ...
	 Train_Loss: 0.6332 Train_Acc: 67.827 Val_Loss: 0.6548  BEST VAL Loss: 0.6548  Val_Acc: 65.312

Epoch 52: Validation loss decreased (0.654778 --> 0.654601).  Saving model ...
	 Train_Loss: 0.6325 Train_Acc: 67.744 Val_Loss: 0.6546  BEST VAL Loss: 0.6546  Val_Acc: 65.742

Epoch 53: Validation loss decreased (0.654601 --> 0.654431).  Saving model ...
	 Train_Loss: 0.6318 Train_Acc: 67.583 Val_Loss: 0.6544  BEST VAL Loss: 0.6544  Val_Acc: 66.016

Epoch 54: Validation loss decreased (0.654431 --> 0.654261).  Saving model ...
	 Train_Loss: 0.6311 Train_Acc: 67.798 Val_Loss: 0.6543  BEST VAL Loss: 0.6543  Val_Acc: 65.703

Epoch 55: Validation loss decreased (0.654261 --> 0.654100).  Saving model ...
	 Train_Loss: 0.6304 Train_Acc: 68.086 Val_Loss: 0.6541  BEST VAL Loss: 0.6541  Val_Acc: 66.211

Epoch 56: Validation loss decreased (0.654100 --> 0.653949).  Saving model ...
	 Train_Loss: 0.6297 Train_Acc: 67.915 Val_Loss: 0.6539  BEST VAL Loss: 0.6539  Val_Acc: 66.133

Epoch 57: Validation loss decreased (0.653949 --> 0.653795).  Saving model ...
	 Train_Loss: 0.6290 Train_Acc: 67.998 Val_Loss: 0.6538  BEST VAL Loss: 0.6538  Val_Acc: 66.211

Epoch 58: Validation loss decreased (0.653795 --> 0.653657).  Saving model ...
	 Train_Loss: 0.6284 Train_Acc: 68.184 Val_Loss: 0.6537  BEST VAL Loss: 0.6537  Val_Acc: 66.523

Epoch 59: Validation loss decreased (0.653657 --> 0.653520).  Saving model ...
	 Train_Loss: 0.6277 Train_Acc: 68.027 Val_Loss: 0.6535  BEST VAL Loss: 0.6535  Val_Acc: 66.797

Epoch 60: Validation loss decreased (0.653520 --> 0.653391).  Saving model ...
	 Train_Loss: 0.6270 Train_Acc: 68.364 Val_Loss: 0.6534  BEST VAL Loss: 0.6534  Val_Acc: 66.328

Epoch 61: Validation loss decreased (0.653391 --> 0.653269).  Saving model ...
	 Train_Loss: 0.6264 Train_Acc: 68.359 Val_Loss: 0.6533  BEST VAL Loss: 0.6533  Val_Acc: 66.172

Epoch 62: Validation loss decreased (0.653269 --> 0.653163).  Saving model ...
	 Train_Loss: 0.6258 Train_Acc: 68.086 Val_Loss: 0.6532  BEST VAL Loss: 0.6532  Val_Acc: 66.445

Epoch 63: Validation loss decreased (0.653163 --> 0.653045).  Saving model ...
	 Train_Loss: 0.6252 Train_Acc: 68.105 Val_Loss: 0.6530  BEST VAL Loss: 0.6530  Val_Acc: 66.406

Epoch 64: Validation loss decreased (0.653045 --> 0.652942).  Saving model ...
	 Train_Loss: 0.6245 Train_Acc: 68.394 Val_Loss: 0.6529  BEST VAL Loss: 0.6529  Val_Acc: 66.602

Epoch 65: Validation loss decreased (0.652942 --> 0.652848).  Saving model ...
	 Train_Loss: 0.6240 Train_Acc: 68.535 Val_Loss: 0.6528  BEST VAL Loss: 0.6528  Val_Acc: 66.445

Epoch 66: Validation loss decreased (0.652848 --> 0.652758).  Saving model ...
	 Train_Loss: 0.6234 Train_Acc: 68.413 Val_Loss: 0.6528  BEST VAL Loss: 0.6528  Val_Acc: 66.797

Epoch 67: Validation loss decreased (0.652758 --> 0.652652).  Saving model ...
	 Train_Loss: 0.6228 Train_Acc: 68.345 Val_Loss: 0.6527  BEST VAL Loss: 0.6527  Val_Acc: 66.758

Epoch 68: Validation loss decreased (0.652652 --> 0.652550).  Saving model ...
	 Train_Loss: 0.6221 Train_Acc: 68.550 Val_Loss: 0.6525  BEST VAL Loss: 0.6525  Val_Acc: 66.562

Epoch 69: Validation loss decreased (0.652550 --> 0.652443).  Saving model ...
	 Train_Loss: 0.6216 Train_Acc: 68.516 Val_Loss: 0.6524  BEST VAL Loss: 0.6524  Val_Acc: 67.266

Epoch 70: Validation loss decreased (0.652443 --> 0.652353).  Saving model ...
	 Train_Loss: 0.6210 Train_Acc: 68.896 Val_Loss: 0.6524  BEST VAL Loss: 0.6524  Val_Acc: 67.148

Epoch 71: Validation loss decreased (0.652353 --> 0.652269).  Saving model ...
	 Train_Loss: 0.6204 Train_Acc: 68.711 Val_Loss: 0.6523  BEST VAL Loss: 0.6523  Val_Acc: 67.227

Epoch 72: Validation loss decreased (0.652269 --> 0.652189).  Saving model ...
	 Train_Loss: 0.6198 Train_Acc: 68.784 Val_Loss: 0.6522  BEST VAL Loss: 0.6522  Val_Acc: 67.070

Epoch 73: Validation loss decreased (0.652189 --> 0.652127).  Saving model ...
	 Train_Loss: 0.6193 Train_Acc: 68.784 Val_Loss: 0.6521  BEST VAL Loss: 0.6521  Val_Acc: 67.070

Epoch 74: Validation loss decreased (0.652127 --> 0.652048).  Saving model ...
	 Train_Loss: 0.6187 Train_Acc: 69.189 Val_Loss: 0.6520  BEST VAL Loss: 0.6520  Val_Acc: 67.188

Epoch 75: Validation loss decreased (0.652048 --> 0.651981).  Saving model ...
	 Train_Loss: 0.6181 Train_Acc: 69.287 Val_Loss: 0.6520  BEST VAL Loss: 0.6520  Val_Acc: 67.422

Epoch 76: Validation loss decreased (0.651981 --> 0.651916).  Saving model ...
	 Train_Loss: 0.6176 Train_Acc: 68.965 Val_Loss: 0.6519  BEST VAL Loss: 0.6519  Val_Acc: 67.422

Epoch 77: Validation loss decreased (0.651916 --> 0.651845).  Saving model ...
	 Train_Loss: 0.6170 Train_Acc: 69.712 Val_Loss: 0.6518  BEST VAL Loss: 0.6518  Val_Acc: 67.383

Epoch 78: Validation loss decreased (0.651845 --> 0.651764).  Saving model ...
	 Train_Loss: 0.6165 Train_Acc: 69.272 Val_Loss: 0.6518  BEST VAL Loss: 0.6518  Val_Acc: 67.539

Epoch 79: Validation loss decreased (0.651764 --> 0.651692).  Saving model ...
	 Train_Loss: 0.6159 Train_Acc: 69.346 Val_Loss: 0.6517  BEST VAL Loss: 0.6517  Val_Acc: 67.695

Epoch 80: Validation loss decreased (0.651692 --> 0.651644).  Saving model ...
	 Train_Loss: 0.6154 Train_Acc: 69.189 Val_Loss: 0.6516  BEST VAL Loss: 0.6516  Val_Acc: 67.617

Epoch 81: Validation loss decreased (0.651644 --> 0.651596).  Saving model ...
	 Train_Loss: 0.6149 Train_Acc: 69.473 Val_Loss: 0.6516  BEST VAL Loss: 0.6516  Val_Acc: 67.656

Epoch 82: Validation loss decreased (0.651596 --> 0.651544).  Saving model ...
	 Train_Loss: 0.6144 Train_Acc: 69.673 Val_Loss: 0.6515  BEST VAL Loss: 0.6515  Val_Acc: 67.656

Epoch 83: Validation loss decreased (0.651544 --> 0.651498).  Saving model ...
	 Train_Loss: 0.6139 Train_Acc: 69.429 Val_Loss: 0.6515  BEST VAL Loss: 0.6515  Val_Acc: 67.930

Epoch 84: Validation loss decreased (0.651498 --> 0.651457).  Saving model ...
	 Train_Loss: 0.6134 Train_Acc: 69.263 Val_Loss: 0.6515  BEST VAL Loss: 0.6515  Val_Acc: 67.969

Epoch 85: Validation loss decreased (0.651457 --> 0.651428).  Saving model ...
	 Train_Loss: 0.6128 Train_Acc: 69.810 Val_Loss: 0.6514  BEST VAL Loss: 0.6514  Val_Acc: 67.500

Epoch 86: Validation loss decreased (0.651428 --> 0.651390).  Saving model ...
	 Train_Loss: 0.6123 Train_Acc: 69.404 Val_Loss: 0.6514  BEST VAL Loss: 0.6514  Val_Acc: 68.047

Epoch 87: Validation loss decreased (0.651390 --> 0.651351).  Saving model ...
	 Train_Loss: 0.6118 Train_Acc: 69.565 Val_Loss: 0.6514  BEST VAL Loss: 0.6514  Val_Acc: 68.047

Epoch 88: Validation loss decreased (0.651351 --> 0.651322).  Saving model ...
	 Train_Loss: 0.6113 Train_Acc: 69.839 Val_Loss: 0.6513  BEST VAL Loss: 0.6513  Val_Acc: 67.500

Epoch 89: Validation loss decreased (0.651322 --> 0.651302).  Saving model ...
	 Train_Loss: 0.6108 Train_Acc: 69.580 Val_Loss: 0.6513  BEST VAL Loss: 0.6513  Val_Acc: 67.578

Epoch 90: Validation loss decreased (0.651302 --> 0.651276).  Saving model ...
	 Train_Loss: 0.6103 Train_Acc: 69.648 Val_Loss: 0.6513  BEST VAL Loss: 0.6513  Val_Acc: 68.125

Epoch 91: Validation loss decreased (0.651276 --> 0.651260).  Saving model ...
	 Train_Loss: 0.6098 Train_Acc: 70.083 Val_Loss: 0.6513  BEST VAL Loss: 0.6513  Val_Acc: 67.773

Epoch 92: Validation loss decreased (0.651260 --> 0.651236).  Saving model ...
	 Train_Loss: 0.6093 Train_Acc: 70.205 Val_Loss: 0.6512  BEST VAL Loss: 0.6512  Val_Acc: 67.695

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.6088 Train_Acc: 69.658 Val_Loss: 0.6512  BEST VAL Loss: 0.6512  Val_Acc: 67.812

Epoch 94: Validation loss decreased (0.651236 --> 0.651213).  Saving model ...
	 Train_Loss: 0.6083 Train_Acc: 69.951 Val_Loss: 0.6512  BEST VAL Loss: 0.6512  Val_Acc: 67.812

Epoch 95: Validation loss decreased (0.651213 --> 0.651200).  Saving model ...
	 Train_Loss: 0.6079 Train_Acc: 70.190 Val_Loss: 0.6512  BEST VAL Loss: 0.6512  Val_Acc: 67.812

Epoch 96: Validation loss decreased (0.651200 --> 0.651200).  Saving model ...
	 Train_Loss: 0.6074 Train_Acc: 70.239 Val_Loss: 0.6512  BEST VAL Loss: 0.6512  Val_Acc: 67.734

Epoch 97: Validation loss decreased (0.651200 --> 0.651188).  Saving model ...
	 Train_Loss: 0.6070 Train_Acc: 69.888 Val_Loss: 0.6512  BEST VAL Loss: 0.6512  Val_Acc: 68.047

Epoch 98: Validation loss decreased (0.651188 --> 0.651179).  Saving model ...
	 Train_Loss: 0.6065 Train_Acc: 69.956 Val_Loss: 0.6512  BEST VAL Loss: 0.6512  Val_Acc: 67.812

Epoch 99: Validation loss decreased (0.651179 --> 0.651150).  Saving model ...
	 Train_Loss: 0.6060 Train_Acc: 70.464 Val_Loss: 0.6511  BEST VAL Loss: 0.6511  Val_Acc: 67.773

LPS_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.75      0.79      0.77     10452
           1       0.77      0.72      0.74     10028

    accuracy                           0.76     20480
   macro avg       0.76      0.76      0.76     20480
weighted avg       0.76      0.76      0.76     20480

LPS_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.67      0.72      0.70      1307
           1       0.69      0.63      0.66      1253

    accuracy                           0.68      2560
   macro avg       0.68      0.68      0.68      2560
weighted avg       0.68      0.68      0.68      2560

LPS_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.67      0.72      0.69      1306
           1       0.68      0.63      0.66      1254

    accuracy                           0.68      2560
   macro avg       0.68      0.67      0.67      2560
weighted avg       0.68      0.68      0.67      2560

              precision    recall  f1-score   support

           0       0.67      0.72      0.69      1306
           1       0.68      0.63      0.66      1254

    accuracy                           0.68      2560
   macro avg       0.68      0.67      0.67      2560
weighted avg       0.68      0.68      0.67      2560

LPS_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.64      0.82      0.72      4445
           1       0.71      0.48      0.57      3923

    accuracy                           0.66      8368
   macro avg       0.68      0.65      0.65      8368
weighted avg       0.67      0.66      0.65      8368

              precision    recall  f1-score   support

           0       0.64      0.82      0.72      4445
           1       0.71      0.48      0.57      3923

    accuracy                           0.66      8368
   macro avg       0.68      0.65      0.65      8368
weighted avg       0.67      0.66      0.65      8368

completed
