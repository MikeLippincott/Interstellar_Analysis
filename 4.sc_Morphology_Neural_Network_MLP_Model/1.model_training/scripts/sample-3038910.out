[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '8901c2bb'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '60bce0f9'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '20bc641a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '37169d73'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_10.000_DMSO_0.025 treatment_name: LPS_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: LPS_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'LPS_10.000_DMSO_0.025']
The dimensions of the data are: (295923, 1270)
Number of total missing values across all columns: 591846
Data Subset Is Off
Wells held out for testing: ['D08' 'E08']
Wells to use for training, validation, and testing ['D02' 'E02' 'D03' 'E03' 'D09' 'E09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.541797).  Saving model ...
	 Train_Loss: 0.6177 Train_Acc: 65.674 Val_Loss: 0.5418  BEST VAL Loss: 0.5418  Val_Acc: 73.707

Epoch 1: Validation loss decreased (0.541797 --> 0.520322).  Saving model ...
	 Train_Loss: 0.5831 Train_Acc: 72.811 Val_Loss: 0.5203  BEST VAL Loss: 0.5203  Val_Acc: 76.335

Epoch 2: Validation loss decreased (0.520322 --> 0.509225).  Saving model ...
	 Train_Loss: 0.5630 Train_Acc: 74.445 Val_Loss: 0.5092  BEST VAL Loss: 0.5092  Val_Acc: 76.722

Epoch 3: Validation loss decreased (0.509225 --> 0.499333).  Saving model ...
	 Train_Loss: 0.5502 Train_Acc: 75.141 Val_Loss: 0.4993  BEST VAL Loss: 0.4993  Val_Acc: 77.765

Epoch 4: Validation loss decreased (0.499333 --> 0.493501).  Saving model ...
	 Train_Loss: 0.5413 Train_Acc: 75.613 Val_Loss: 0.4935  BEST VAL Loss: 0.4935  Val_Acc: 77.532

Epoch 5: Validation loss decreased (0.493501 --> 0.488054).  Saving model ...
	 Train_Loss: 0.5340 Train_Acc: 76.058 Val_Loss: 0.4881  BEST VAL Loss: 0.4881  Val_Acc: 78.264

Epoch 6: Validation loss decreased (0.488054 --> 0.483771).  Saving model ...
	 Train_Loss: 0.5283 Train_Acc: 76.335 Val_Loss: 0.4838  BEST VAL Loss: 0.4838  Val_Acc: 78.427

Epoch 7: Validation loss decreased (0.483771 --> 0.479636).  Saving model ...
	 Train_Loss: 0.5235 Train_Acc: 76.639 Val_Loss: 0.4796  BEST VAL Loss: 0.4796  Val_Acc: 79.042

Epoch 8: Validation loss decreased (0.479636 --> 0.476515).  Saving model ...
	 Train_Loss: 0.5194 Train_Acc: 76.823 Val_Loss: 0.4765  BEST VAL Loss: 0.4765  Val_Acc: 78.460

Epoch 9: Validation loss decreased (0.476515 --> 0.473371).  Saving model ...
	 Train_Loss: 0.5159 Train_Acc: 77.012 Val_Loss: 0.4734  BEST VAL Loss: 0.4734  Val_Acc: 79.023

Epoch 10: Validation loss decreased (0.473371 --> 0.470203).  Saving model ...
	 Train_Loss: 0.5127 Train_Acc: 77.034 Val_Loss: 0.4702  BEST VAL Loss: 0.4702  Val_Acc: 79.657

Epoch 11: Validation loss decreased (0.470203 --> 0.467920).  Saving model ...
	 Train_Loss: 0.5099 Train_Acc: 77.335 Val_Loss: 0.4679  BEST VAL Loss: 0.4679  Val_Acc: 79.242

Epoch 12: Validation loss decreased (0.467920 --> 0.465763).  Saving model ...
	 Train_Loss: 0.5073 Train_Acc: 77.543 Val_Loss: 0.4658  BEST VAL Loss: 0.4658  Val_Acc: 79.615

Epoch 13: Validation loss decreased (0.465763 --> 0.464041).  Saving model ...
	 Train_Loss: 0.5050 Train_Acc: 77.522 Val_Loss: 0.4640  BEST VAL Loss: 0.4640  Val_Acc: 79.396

Epoch 14: Validation loss decreased (0.464041 --> 0.462094).  Saving model ...
	 Train_Loss: 0.5028 Train_Acc: 77.772 Val_Loss: 0.4621  BEST VAL Loss: 0.4621  Val_Acc: 80.011

Epoch 15: Validation loss decreased (0.462094 --> 0.460361).  Saving model ...
	 Train_Loss: 0.5009 Train_Acc: 77.707 Val_Loss: 0.4604  BEST VAL Loss: 0.4604  Val_Acc: 79.890

Epoch 16: Validation loss decreased (0.460361 --> 0.458775).  Saving model ...
	 Train_Loss: 0.4990 Train_Acc: 77.872 Val_Loss: 0.4588  BEST VAL Loss: 0.4588  Val_Acc: 79.746

Epoch 17: Validation loss decreased (0.458775 --> 0.457533).  Saving model ...
	 Train_Loss: 0.4972 Train_Acc: 77.957 Val_Loss: 0.4575  BEST VAL Loss: 0.4575  Val_Acc: 79.559

Epoch 18: Validation loss decreased (0.457533 --> 0.456229).  Saving model ...
	 Train_Loss: 0.4955 Train_Acc: 78.091 Val_Loss: 0.4562  BEST VAL Loss: 0.4562  Val_Acc: 79.890

Epoch 19: Validation loss decreased (0.456229 --> 0.454776).  Saving model ...
	 Train_Loss: 0.4940 Train_Acc: 78.186 Val_Loss: 0.4548  BEST VAL Loss: 0.4548  Val_Acc: 80.286

Epoch 20: Validation loss decreased (0.454776 --> 0.453572).  Saving model ...
	 Train_Loss: 0.4924 Train_Acc: 78.342 Val_Loss: 0.4536  BEST VAL Loss: 0.4536  Val_Acc: 80.076

Epoch 21: Validation loss decreased (0.453572 --> 0.452307).  Saving model ...
	 Train_Loss: 0.4910 Train_Acc: 78.286 Val_Loss: 0.4523  BEST VAL Loss: 0.4523  Val_Acc: 80.277

Epoch 22: Validation loss decreased (0.452307 --> 0.451064).  Saving model ...
	 Train_Loss: 0.4897 Train_Acc: 78.459 Val_Loss: 0.4511  BEST VAL Loss: 0.4511  Val_Acc: 80.519

Epoch 23: Validation loss decreased (0.451064 --> 0.449914).  Saving model ...
	 Train_Loss: 0.4884 Train_Acc: 78.481 Val_Loss: 0.4499  BEST VAL Loss: 0.4499  Val_Acc: 80.417

Epoch 24: Validation loss decreased (0.449914 --> 0.448868).  Saving model ...
	 Train_Loss: 0.4872 Train_Acc: 78.566 Val_Loss: 0.4489  BEST VAL Loss: 0.4489  Val_Acc: 80.389

Epoch 25: Validation loss decreased (0.448868 --> 0.447893).  Saving model ...
	 Train_Loss: 0.4860 Train_Acc: 78.574 Val_Loss: 0.4479  BEST VAL Loss: 0.4479  Val_Acc: 80.431

Epoch 26: Validation loss decreased (0.447893 --> 0.447040).  Saving model ...
	 Train_Loss: 0.4849 Train_Acc: 78.670 Val_Loss: 0.4470  BEST VAL Loss: 0.4470  Val_Acc: 80.179

Epoch 27: Validation loss decreased (0.447040 --> 0.446187).  Saving model ...
	 Train_Loss: 0.4838 Train_Acc: 78.812 Val_Loss: 0.4462  BEST VAL Loss: 0.4462  Val_Acc: 80.351

Epoch 28: Validation loss decreased (0.446187 --> 0.445374).  Saving model ...
	 Train_Loss: 0.4828 Train_Acc: 78.726 Val_Loss: 0.4454  BEST VAL Loss: 0.4454  Val_Acc: 80.575

Epoch 29: Validation loss decreased (0.445374 --> 0.444511).  Saving model ...
	 Train_Loss: 0.4819 Train_Acc: 78.928 Val_Loss: 0.4445  BEST VAL Loss: 0.4445  Val_Acc: 80.724

Epoch 30: Validation loss decreased (0.444511 --> 0.443756).  Saving model ...
	 Train_Loss: 0.4809 Train_Acc: 79.030 Val_Loss: 0.4438  BEST VAL Loss: 0.4438  Val_Acc: 80.379

Epoch 31: Validation loss decreased (0.443756 --> 0.442961).  Saving model ...
	 Train_Loss: 0.4800 Train_Acc: 78.899 Val_Loss: 0.4430  BEST VAL Loss: 0.4430  Val_Acc: 80.766

Epoch 32: Validation loss decreased (0.442961 --> 0.442191).  Saving model ...
	 Train_Loss: 0.4791 Train_Acc: 79.027 Val_Loss: 0.4422  BEST VAL Loss: 0.4422  Val_Acc: 80.663

Epoch 33: Validation loss decreased (0.442191 --> 0.441481).  Saving model ...
	 Train_Loss: 0.4783 Train_Acc: 78.967 Val_Loss: 0.4415  BEST VAL Loss: 0.4415  Val_Acc: 80.794

Epoch 34: Validation loss decreased (0.441481 --> 0.440819).  Saving model ...
	 Train_Loss: 0.4774 Train_Acc: 78.993 Val_Loss: 0.4408  BEST VAL Loss: 0.4408  Val_Acc: 80.710

Epoch 35: Validation loss decreased (0.440819 --> 0.440259).  Saving model ...
	 Train_Loss: 0.4767 Train_Acc: 78.939 Val_Loss: 0.4403  BEST VAL Loss: 0.4403  Val_Acc: 80.645

Epoch 36: Validation loss decreased (0.440259 --> 0.439531).  Saving model ...
	 Train_Loss: 0.4759 Train_Acc: 79.198 Val_Loss: 0.4395  BEST VAL Loss: 0.4395  Val_Acc: 81.213

Epoch 37: Validation loss decreased (0.439531 --> 0.438945).  Saving model ...
	 Train_Loss: 0.4752 Train_Acc: 79.216 Val_Loss: 0.4389  BEST VAL Loss: 0.4389  Val_Acc: 80.757

Epoch 38: Validation loss decreased (0.438945 --> 0.438434).  Saving model ...
	 Train_Loss: 0.4745 Train_Acc: 79.102 Val_Loss: 0.4384  BEST VAL Loss: 0.4384  Val_Acc: 80.650

Epoch 39: Validation loss decreased (0.438434 --> 0.437746).  Saving model ...
	 Train_Loss: 0.4738 Train_Acc: 79.268 Val_Loss: 0.4377  BEST VAL Loss: 0.4377  Val_Acc: 81.153

Epoch 40: Validation loss decreased (0.437746 --> 0.437258).  Saving model ...
	 Train_Loss: 0.4731 Train_Acc: 79.271 Val_Loss: 0.4373  BEST VAL Loss: 0.4373  Val_Acc: 80.896

Epoch 41: Validation loss decreased (0.437258 --> 0.436653).  Saving model ...
	 Train_Loss: 0.4724 Train_Acc: 79.482 Val_Loss: 0.4367  BEST VAL Loss: 0.4367  Val_Acc: 81.227

Epoch 42: Validation loss decreased (0.436653 --> 0.436122).  Saving model ...
	 Train_Loss: 0.4718 Train_Acc: 79.369 Val_Loss: 0.4361  BEST VAL Loss: 0.4361  Val_Acc: 80.831

Epoch 43: Validation loss decreased (0.436122 --> 0.435631).  Saving model ...
	 Train_Loss: 0.4711 Train_Acc: 79.522 Val_Loss: 0.4356  BEST VAL Loss: 0.4356  Val_Acc: 80.985

Epoch 44: Validation loss decreased (0.435631 --> 0.435075).  Saving model ...
	 Train_Loss: 0.4705 Train_Acc: 79.412 Val_Loss: 0.4351  BEST VAL Loss: 0.4351  Val_Acc: 81.353

Epoch 45: Validation loss decreased (0.435075 --> 0.434529).  Saving model ...
	 Train_Loss: 0.4699 Train_Acc: 79.509 Val_Loss: 0.4345  BEST VAL Loss: 0.4345  Val_Acc: 81.637

Epoch 46: Validation loss decreased (0.434529 --> 0.434014).  Saving model ...
	 Train_Loss: 0.4693 Train_Acc: 79.498 Val_Loss: 0.4340  BEST VAL Loss: 0.4340  Val_Acc: 81.409

Epoch 47: Validation loss decreased (0.434014 --> 0.433493).  Saving model ...
	 Train_Loss: 0.4688 Train_Acc: 79.503 Val_Loss: 0.4335  BEST VAL Loss: 0.4335  Val_Acc: 81.362

Epoch 48: Validation loss decreased (0.433493 --> 0.433032).  Saving model ...
	 Train_Loss: 0.4682 Train_Acc: 79.526 Val_Loss: 0.4330  BEST VAL Loss: 0.4330  Val_Acc: 81.181

Epoch 49: Validation loss decreased (0.433032 --> 0.432568).  Saving model ...
	 Train_Loss: 0.4677 Train_Acc: 79.684 Val_Loss: 0.4326  BEST VAL Loss: 0.4326  Val_Acc: 81.139

Epoch 50: Validation loss decreased (0.432568 --> 0.432142).  Saving model ...
	 Train_Loss: 0.4672 Train_Acc: 79.494 Val_Loss: 0.4321  BEST VAL Loss: 0.4321  Val_Acc: 80.943

Epoch 51: Validation loss decreased (0.432142 --> 0.431723).  Saving model ...
	 Train_Loss: 0.4666 Train_Acc: 79.705 Val_Loss: 0.4317  BEST VAL Loss: 0.4317  Val_Acc: 81.334

Epoch 52: Validation loss decreased (0.431723 --> 0.431326).  Saving model ...
	 Train_Loss: 0.4662 Train_Acc: 79.462 Val_Loss: 0.4313  BEST VAL Loss: 0.4313  Val_Acc: 81.078

Epoch 53: Validation loss decreased (0.431326 --> 0.430832).  Saving model ...
	 Train_Loss: 0.4656 Train_Acc: 79.698 Val_Loss: 0.4308  BEST VAL Loss: 0.4308  Val_Acc: 81.553

Epoch 54: Validation loss decreased (0.430832 --> 0.430465).  Saving model ...
	 Train_Loss: 0.4651 Train_Acc: 79.765 Val_Loss: 0.4305  BEST VAL Loss: 0.4305  Val_Acc: 81.134

Epoch 55: Validation loss decreased (0.430465 --> 0.430086).  Saving model ...
	 Train_Loss: 0.4647 Train_Acc: 79.909 Val_Loss: 0.4301  BEST VAL Loss: 0.4301  Val_Acc: 81.404

Epoch 56: Validation loss decreased (0.430086 --> 0.429735).  Saving model ...
	 Train_Loss: 0.4642 Train_Acc: 79.718 Val_Loss: 0.4297  BEST VAL Loss: 0.4297  Val_Acc: 81.227

Epoch 57: Validation loss decreased (0.429735 --> 0.429366).  Saving model ...
	 Train_Loss: 0.4637 Train_Acc: 79.712 Val_Loss: 0.4294  BEST VAL Loss: 0.4294  Val_Acc: 81.553

Epoch 58: Validation loss decreased (0.429366 --> 0.429023).  Saving model ...
	 Train_Loss: 0.4633 Train_Acc: 79.815 Val_Loss: 0.4290  BEST VAL Loss: 0.4290  Val_Acc: 81.558

Epoch 59: Validation loss decreased (0.429023 --> 0.428653).  Saving model ...
	 Train_Loss: 0.4628 Train_Acc: 80.027 Val_Loss: 0.4287  BEST VAL Loss: 0.4287  Val_Acc: 81.516

Epoch 60: Validation loss decreased (0.428653 --> 0.428259).  Saving model ...
	 Train_Loss: 0.4624 Train_Acc: 79.925 Val_Loss: 0.4283  BEST VAL Loss: 0.4283  Val_Acc: 81.754

Epoch 61: Validation loss decreased (0.428259 --> 0.427896).  Saving model ...
	 Train_Loss: 0.4619 Train_Acc: 79.888 Val_Loss: 0.4279  BEST VAL Loss: 0.4279  Val_Acc: 81.539

Epoch 62: Validation loss decreased (0.427896 --> 0.427497).  Saving model ...
	 Train_Loss: 0.4615 Train_Acc: 80.010 Val_Loss: 0.4275  BEST VAL Loss: 0.4275  Val_Acc: 81.889

Epoch 63: Validation loss decreased (0.427497 --> 0.427147).  Saving model ...
	 Train_Loss: 0.4610 Train_Acc: 79.890 Val_Loss: 0.4271  BEST VAL Loss: 0.4271  Val_Acc: 81.512

Epoch 64: Validation loss decreased (0.427147 --> 0.426841).  Saving model ...
	 Train_Loss: 0.4607 Train_Acc: 79.904 Val_Loss: 0.4268  BEST VAL Loss: 0.4268  Val_Acc: 81.446

Epoch 65: Validation loss decreased (0.426841 --> 0.426539).  Saving model ...
	 Train_Loss: 0.4602 Train_Acc: 80.104 Val_Loss: 0.4265  BEST VAL Loss: 0.4265  Val_Acc: 81.418

Epoch 66: Validation loss decreased (0.426539 --> 0.426230).  Saving model ...
	 Train_Loss: 0.4599 Train_Acc: 80.015 Val_Loss: 0.4262  BEST VAL Loss: 0.4262  Val_Acc: 82.038

Epoch 67: Validation loss decreased (0.426230 --> 0.425892).  Saving model ...
	 Train_Loss: 0.4595 Train_Acc: 80.038 Val_Loss: 0.4259  BEST VAL Loss: 0.4259  Val_Acc: 82.001

Epoch 68: Validation loss decreased (0.425892 --> 0.425591).  Saving model ...
	 Train_Loss: 0.4590 Train_Acc: 80.105 Val_Loss: 0.4256  BEST VAL Loss: 0.4256  Val_Acc: 81.609

Epoch 69: Validation loss decreased (0.425591 --> 0.425274).  Saving model ...
	 Train_Loss: 0.4586 Train_Acc: 80.140 Val_Loss: 0.4253  BEST VAL Loss: 0.4253  Val_Acc: 81.880

Epoch 70: Validation loss decreased (0.425274 --> 0.424937).  Saving model ...
	 Train_Loss: 0.4583 Train_Acc: 80.080 Val_Loss: 0.4249  BEST VAL Loss: 0.4249  Val_Acc: 81.912

Epoch 71: Validation loss decreased (0.424937 --> 0.424643).  Saving model ...
	 Train_Loss: 0.4579 Train_Acc: 80.021 Val_Loss: 0.4246  BEST VAL Loss: 0.4246  Val_Acc: 81.605

Epoch 72: Validation loss decreased (0.424643 --> 0.424309).  Saving model ...
	 Train_Loss: 0.4576 Train_Acc: 80.221 Val_Loss: 0.4243  BEST VAL Loss: 0.4243  Val_Acc: 82.010

Epoch 73: Validation loss decreased (0.424309 --> 0.424015).  Saving model ...
	 Train_Loss: 0.4572 Train_Acc: 80.102 Val_Loss: 0.4240  BEST VAL Loss: 0.4240  Val_Acc: 81.828

Epoch 74: Validation loss decreased (0.424015 --> 0.423808).  Saving model ...
	 Train_Loss: 0.4568 Train_Acc: 80.226 Val_Loss: 0.4238  BEST VAL Loss: 0.4238  Val_Acc: 81.171

Epoch 75: Validation loss decreased (0.423808 --> 0.423515).  Saving model ...
	 Train_Loss: 0.4565 Train_Acc: 80.268 Val_Loss: 0.4235  BEST VAL Loss: 0.4235  Val_Acc: 82.117

Epoch 76: Validation loss decreased (0.423515 --> 0.423246).  Saving model ...
	 Train_Loss: 0.4561 Train_Acc: 80.377 Val_Loss: 0.4232  BEST VAL Loss: 0.4232  Val_Acc: 81.782

Epoch 77: Validation loss decreased (0.423246 --> 0.422933).  Saving model ...
	 Train_Loss: 0.4557 Train_Acc: 80.443 Val_Loss: 0.4229  BEST VAL Loss: 0.4229  Val_Acc: 82.005

Epoch 78: Validation loss decreased (0.422933 --> 0.422658).  Saving model ...
	 Train_Loss: 0.4553 Train_Acc: 80.442 Val_Loss: 0.4227  BEST VAL Loss: 0.4227  Val_Acc: 81.656

Epoch 79: Validation loss decreased (0.422658 --> 0.422383).  Saving model ...
	 Train_Loss: 0.4550 Train_Acc: 80.429 Val_Loss: 0.4224  BEST VAL Loss: 0.4224  Val_Acc: 81.968

Epoch 80: Validation loss decreased (0.422383 --> 0.422111).  Saving model ...
	 Train_Loss: 0.4546 Train_Acc: 80.499 Val_Loss: 0.4221  BEST VAL Loss: 0.4221  Val_Acc: 82.005

Epoch 81: Validation loss decreased (0.422111 --> 0.421838).  Saving model ...
	 Train_Loss: 0.4542 Train_Acc: 80.369 Val_Loss: 0.4218  BEST VAL Loss: 0.4218  Val_Acc: 82.127

Epoch 82: Validation loss decreased (0.421838 --> 0.421552).  Saving model ...
	 Train_Loss: 0.4539 Train_Acc: 80.415 Val_Loss: 0.4216  BEST VAL Loss: 0.4216  Val_Acc: 82.141

Epoch 83: Validation loss decreased (0.421552 --> 0.421292).  Saving model ...
	 Train_Loss: 0.4535 Train_Acc: 80.450 Val_Loss: 0.4213  BEST VAL Loss: 0.4213  Val_Acc: 82.089

Epoch 84: Validation loss decreased (0.421292 --> 0.421030).  Saving model ...
	 Train_Loss: 0.4532 Train_Acc: 80.630 Val_Loss: 0.4210  BEST VAL Loss: 0.4210  Val_Acc: 81.880

Epoch 85: Validation loss decreased (0.421030 --> 0.420765).  Saving model ...
	 Train_Loss: 0.4528 Train_Acc: 80.589 Val_Loss: 0.4208  BEST VAL Loss: 0.4208  Val_Acc: 81.912

Epoch 86: Validation loss decreased (0.420765 --> 0.420559).  Saving model ...
	 Train_Loss: 0.4525 Train_Acc: 80.458 Val_Loss: 0.4206  BEST VAL Loss: 0.4206  Val_Acc: 81.842

Epoch 87: Validation loss decreased (0.420559 --> 0.420313).  Saving model ...
	 Train_Loss: 0.4522 Train_Acc: 80.512 Val_Loss: 0.4203  BEST VAL Loss: 0.4203  Val_Acc: 82.201

Epoch 88: Validation loss decreased (0.420313 --> 0.420071).  Saving model ...
	 Train_Loss: 0.4519 Train_Acc: 80.515 Val_Loss: 0.4201  BEST VAL Loss: 0.4201  Val_Acc: 82.113

Epoch 89: Validation loss decreased (0.420071 --> 0.419787).  Saving model ...
	 Train_Loss: 0.4516 Train_Acc: 80.559 Val_Loss: 0.4198  BEST VAL Loss: 0.4198  Val_Acc: 82.453

Epoch 90: Validation loss decreased (0.419787 --> 0.419548).  Saving model ...
	 Train_Loss: 0.4512 Train_Acc: 80.684 Val_Loss: 0.4195  BEST VAL Loss: 0.4195  Val_Acc: 81.922

Epoch 91: Validation loss decreased (0.419548 --> 0.419328).  Saving model ...
	 Train_Loss: 0.4509 Train_Acc: 80.666 Val_Loss: 0.4193  BEST VAL Loss: 0.4193  Val_Acc: 81.894

Epoch 92: Validation loss decreased (0.419328 --> 0.419094).  Saving model ...
	 Train_Loss: 0.4506 Train_Acc: 80.673 Val_Loss: 0.4191  BEST VAL Loss: 0.4191  Val_Acc: 82.145

Epoch 93: Validation loss decreased (0.419094 --> 0.418904).  Saving model ...
	 Train_Loss: 0.4503 Train_Acc: 80.632 Val_Loss: 0.4189  BEST VAL Loss: 0.4189  Val_Acc: 82.117

Epoch 94: Validation loss decreased (0.418904 --> 0.418721).  Saving model ...
	 Train_Loss: 0.4500 Train_Acc: 80.579 Val_Loss: 0.4187  BEST VAL Loss: 0.4187  Val_Acc: 81.894

Epoch 95: Validation loss decreased (0.418721 --> 0.418486).  Saving model ...
	 Train_Loss: 0.4497 Train_Acc: 80.778 Val_Loss: 0.4185  BEST VAL Loss: 0.4185  Val_Acc: 82.168

Epoch 96: Validation loss decreased (0.418486 --> 0.418273).  Saving model ...
	 Train_Loss: 0.4494 Train_Acc: 80.686 Val_Loss: 0.4183  BEST VAL Loss: 0.4183  Val_Acc: 82.019

Epoch 97: Validation loss decreased (0.418273 --> 0.418090).  Saving model ...
	 Train_Loss: 0.4491 Train_Acc: 80.731 Val_Loss: 0.4181  BEST VAL Loss: 0.4181  Val_Acc: 82.113

Epoch 98: Validation loss decreased (0.418090 --> 0.417886).  Saving model ...
	 Train_Loss: 0.4488 Train_Acc: 80.759 Val_Loss: 0.4179  BEST VAL Loss: 0.4179  Val_Acc: 82.155

Epoch 99: Validation loss decreased (0.417886 --> 0.417692).  Saving model ...
	 Train_Loss: 0.4485 Train_Acc: 80.800 Val_Loss: 0.4177  BEST VAL Loss: 0.4177  Val_Acc: 82.397

LPS_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.91      0.75      0.82     79796
           1       0.81      0.93      0.87     91899

    accuracy                           0.85    171695
   macro avg       0.86      0.84      0.84    171695
weighted avg       0.85      0.85      0.84    171695

LPS_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.88      0.72      0.79      9975
           1       0.79      0.91      0.85     11487

    accuracy                           0.82     21462
   macro avg       0.83      0.82      0.82     21462
weighted avg       0.83      0.82      0.82     21462

LPS_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.86      0.72      0.78      9975
           1       0.79      0.90      0.84     11487

    accuracy                           0.82     21462
   macro avg       0.82      0.81      0.81     21462
weighted avg       0.82      0.82      0.81     21462

              precision    recall  f1-score   support

           0       0.86      0.72      0.78      9975
           1       0.79      0.90      0.84     11487

    accuracy                           0.82     21462
   macro avg       0.82      0.81      0.81     21462
weighted avg       0.82      0.82      0.81     21462

LPS_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.14      0.03      0.04     39687
           1       0.48      0.85      0.61     41617

    accuracy                           0.45     81304
   macro avg       0.31      0.44      0.33     81304
weighted avg       0.32      0.45      0.34     81304

              precision    recall  f1-score   support

           0       0.14      0.03      0.04     39687
           1       0.48      0.85      0.61     41617

    accuracy                           0.45     81304
   macro avg       0.31      0.44      0.33     81304
weighted avg       0.32      0.45      0.34     81304

completed
