[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '06aa3167'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'a783d731'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '897af416'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '65076cc8'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: DMSO_0.100_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: DMSO_0.100_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'LPS_0.010_DMSO_0.025']
The dimensions of the data are: (51502, 1276)
Number of total missing values across all columns: 103004
Data Subset Is Off
Wells held out for testing: ['B21' 'I14']
Wells to use for training, validation, and testing ['B14' 'C14' 'B15' 'C15' 'B16' 'B17' 'B20' 'J14' 'I15' 'J15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.571728).  Saving model ...
	 Train_Loss: 0.6087 Train_Acc: 70.927 Val_Loss: 0.5717  BEST VAL Loss: 0.5717  Val_Acc: 73.258

Epoch 1: Validation loss decreased (0.571728 --> 0.565811).  Saving model ...
	 Train_Loss: 0.5906 Train_Acc: 72.867 Val_Loss: 0.5658  BEST VAL Loss: 0.5658  Val_Acc: 73.565

Epoch 2: Validation loss decreased (0.565811 --> 0.557930).  Saving model ...
	 Train_Loss: 0.5782 Train_Acc: 73.744 Val_Loss: 0.5579  BEST VAL Loss: 0.5579  Val_Acc: 74.037

Epoch 3: Validation loss decreased (0.557930 --> 0.553403).  Saving model ...
	 Train_Loss: 0.5688 Train_Acc: 74.308 Val_Loss: 0.5534  BEST VAL Loss: 0.5534  Val_Acc: 74.888

Epoch 4: Validation loss decreased (0.553403 --> 0.547550).  Saving model ...
	 Train_Loss: 0.5611 Train_Acc: 74.931 Val_Loss: 0.5475  BEST VAL Loss: 0.5475  Val_Acc: 75.289

Epoch 5: Validation loss decreased (0.547550 --> 0.541791).  Saving model ...
	 Train_Loss: 0.5545 Train_Acc: 75.182 Val_Loss: 0.5418  BEST VAL Loss: 0.5418  Val_Acc: 75.762

Epoch 6: Validation loss decreased (0.541791 --> 0.537496).  Saving model ...
	 Train_Loss: 0.5488 Train_Acc: 75.259 Val_Loss: 0.5375  BEST VAL Loss: 0.5375  Val_Acc: 75.927

Epoch 7: Validation loss decreased (0.537496 --> 0.534020).  Saving model ...
	 Train_Loss: 0.5435 Train_Acc: 75.844 Val_Loss: 0.5340  BEST VAL Loss: 0.5340  Val_Acc: 75.762

Epoch 8: Validation loss decreased (0.534020 --> 0.531273).  Saving model ...
	 Train_Loss: 0.5387 Train_Acc: 76.355 Val_Loss: 0.5313  BEST VAL Loss: 0.5313  Val_Acc: 75.833

Epoch 9: Validation loss decreased (0.531273 --> 0.528631).  Saving model ...
	 Train_Loss: 0.5344 Train_Acc: 76.452 Val_Loss: 0.5286  BEST VAL Loss: 0.5286  Val_Acc: 76.140

Epoch 10: Validation loss decreased (0.528631 --> 0.525602).  Saving model ...
	 Train_Loss: 0.5304 Train_Acc: 76.470 Val_Loss: 0.5256  BEST VAL Loss: 0.5256  Val_Acc: 76.494

Epoch 11: Validation loss decreased (0.525602 --> 0.523171).  Saving model ...
	 Train_Loss: 0.5267 Train_Acc: 76.928 Val_Loss: 0.5232  BEST VAL Loss: 0.5232  Val_Acc: 76.494

Epoch 12: Validation loss decreased (0.523171 --> 0.520492).  Saving model ...
	 Train_Loss: 0.5233 Train_Acc: 76.951 Val_Loss: 0.5205  BEST VAL Loss: 0.5205  Val_Acc: 76.400

Epoch 13: Validation loss decreased (0.520492 --> 0.518841).  Saving model ...
	 Train_Loss: 0.5202 Train_Acc: 76.877 Val_Loss: 0.5188  BEST VAL Loss: 0.5188  Val_Acc: 76.565

Epoch 14: Validation loss decreased (0.518841 --> 0.516879).  Saving model ...
	 Train_Loss: 0.5172 Train_Acc: 77.391 Val_Loss: 0.5169  BEST VAL Loss: 0.5169  Val_Acc: 76.400

Epoch 15: Validation loss decreased (0.516879 --> 0.515040).  Saving model ...
	 Train_Loss: 0.5143 Train_Acc: 77.580 Val_Loss: 0.5150  BEST VAL Loss: 0.5150  Val_Acc: 76.825

Epoch 16: Validation loss decreased (0.515040 --> 0.513260).  Saving model ...
	 Train_Loss: 0.5117 Train_Acc: 77.690 Val_Loss: 0.5133  BEST VAL Loss: 0.5133  Val_Acc: 77.108

Epoch 17: Validation loss decreased (0.513260 --> 0.511553).  Saving model ...
	 Train_Loss: 0.5092 Train_Acc: 77.929 Val_Loss: 0.5116  BEST VAL Loss: 0.5116  Val_Acc: 76.896

Epoch 18: Validation loss decreased (0.511553 --> 0.509752).  Saving model ...
	 Train_Loss: 0.5068 Train_Acc: 77.879 Val_Loss: 0.5098  BEST VAL Loss: 0.5098  Val_Acc: 77.227

Epoch 19: Validation loss decreased (0.509752 --> 0.508222).  Saving model ...
	 Train_Loss: 0.5046 Train_Acc: 78.357 Val_Loss: 0.5082  BEST VAL Loss: 0.5082  Val_Acc: 76.872

Epoch 20: Validation loss decreased (0.508222 --> 0.507156).  Saving model ...
	 Train_Loss: 0.5023 Train_Acc: 78.508 Val_Loss: 0.5072  BEST VAL Loss: 0.5072  Val_Acc: 76.636

Epoch 21: Validation loss decreased (0.507156 --> 0.506170).  Saving model ...
	 Train_Loss: 0.5002 Train_Acc: 78.558 Val_Loss: 0.5062  BEST VAL Loss: 0.5062  Val_Acc: 76.565

Epoch 22: Validation loss decreased (0.506170 --> 0.505066).  Saving model ...
	 Train_Loss: 0.4982 Train_Acc: 78.572 Val_Loss: 0.5051  BEST VAL Loss: 0.5051  Val_Acc: 76.919

Epoch 23: Validation loss decreased (0.505066 --> 0.503840).  Saving model ...
	 Train_Loss: 0.4962 Train_Acc: 78.835 Val_Loss: 0.5038  BEST VAL Loss: 0.5038  Val_Acc: 77.014

Epoch 24: Validation loss decreased (0.503840 --> 0.502690).  Saving model ...
	 Train_Loss: 0.4943 Train_Acc: 78.865 Val_Loss: 0.5027  BEST VAL Loss: 0.5027  Val_Acc: 77.085

Epoch 25: Validation loss decreased (0.502690 --> 0.501563).  Saving model ...
	 Train_Loss: 0.4924 Train_Acc: 79.007 Val_Loss: 0.5016  BEST VAL Loss: 0.5016  Val_Acc: 77.274

Epoch 26: Validation loss decreased (0.501563 --> 0.500680).  Saving model ...
	 Train_Loss: 0.4906 Train_Acc: 79.207 Val_Loss: 0.5007  BEST VAL Loss: 0.5007  Val_Acc: 76.612

Epoch 27: Validation loss decreased (0.500680 --> 0.500173).  Saving model ...
	 Train_Loss: 0.4889 Train_Acc: 79.320 Val_Loss: 0.5002  BEST VAL Loss: 0.5002  Val_Acc: 77.038

Epoch 28: Validation loss decreased (0.500173 --> 0.499576).  Saving model ...
	 Train_Loss: 0.4872 Train_Acc: 79.314 Val_Loss: 0.4996  BEST VAL Loss: 0.4996  Val_Acc: 77.085

Epoch 29: Validation loss decreased (0.499576 --> 0.498901).  Saving model ...
	 Train_Loss: 0.4856 Train_Acc: 79.541 Val_Loss: 0.4989  BEST VAL Loss: 0.4989  Val_Acc: 77.061

Epoch 30: Validation loss decreased (0.498901 --> 0.498260).  Saving model ...
	 Train_Loss: 0.4840 Train_Acc: 79.582 Val_Loss: 0.4983  BEST VAL Loss: 0.4983  Val_Acc: 77.416

Epoch 31: Validation loss decreased (0.498260 --> 0.497965).  Saving model ...
	 Train_Loss: 0.4825 Train_Acc: 79.674 Val_Loss: 0.4980  BEST VAL Loss: 0.4980  Val_Acc: 77.108

Epoch 32: Validation loss decreased (0.497965 --> 0.497756).  Saving model ...
	 Train_Loss: 0.4810 Train_Acc: 79.801 Val_Loss: 0.4978  BEST VAL Loss: 0.4978  Val_Acc: 77.156

Epoch 33: Validation loss decreased (0.497756 --> 0.497150).  Saving model ...
	 Train_Loss: 0.4796 Train_Acc: 79.816 Val_Loss: 0.4971  BEST VAL Loss: 0.4971  Val_Acc: 77.179

Epoch 34: Validation loss decreased (0.497150 --> 0.496655).  Saving model ...
	 Train_Loss: 0.4781 Train_Acc: 80.093 Val_Loss: 0.4967  BEST VAL Loss: 0.4967  Val_Acc: 76.825

Epoch 35: Validation loss decreased (0.496655 --> 0.496417).  Saving model ...
	 Train_Loss: 0.4767 Train_Acc: 80.064 Val_Loss: 0.4964  BEST VAL Loss: 0.4964  Val_Acc: 77.345

Epoch 36: Validation loss decreased (0.496417 --> 0.495826).  Saving model ...
	 Train_Loss: 0.4753 Train_Acc: 80.250 Val_Loss: 0.4958  BEST VAL Loss: 0.4958  Val_Acc: 77.156

Epoch 37: Validation loss decreased (0.495826 --> 0.495397).  Saving model ...
	 Train_Loss: 0.4740 Train_Acc: 80.412 Val_Loss: 0.4954  BEST VAL Loss: 0.4954  Val_Acc: 77.605

Epoch 38: Validation loss decreased (0.495397 --> 0.495176).  Saving model ...
	 Train_Loss: 0.4727 Train_Acc: 80.524 Val_Loss: 0.4952  BEST VAL Loss: 0.4952  Val_Acc: 77.297

Epoch 39: Validation loss decreased (0.495176 --> 0.494946).  Saving model ...
	 Train_Loss: 0.4714 Train_Acc: 80.519 Val_Loss: 0.4949  BEST VAL Loss: 0.4949  Val_Acc: 77.463

Epoch 40: Validation loss decreased (0.494946 --> 0.494579).  Saving model ...
	 Train_Loss: 0.4701 Train_Acc: 80.477 Val_Loss: 0.4946  BEST VAL Loss: 0.4946  Val_Acc: 77.108

Epoch 41: Validation loss decreased (0.494579 --> 0.494282).  Saving model ...
	 Train_Loss: 0.4689 Train_Acc: 80.480 Val_Loss: 0.4943  BEST VAL Loss: 0.4943  Val_Acc: 77.227

Epoch 42: Validation loss decreased (0.494282 --> 0.493886).  Saving model ...
	 Train_Loss: 0.4677 Train_Acc: 80.663 Val_Loss: 0.4939  BEST VAL Loss: 0.4939  Val_Acc: 77.250

Epoch 43: Validation loss decreased (0.493886 --> 0.493430).  Saving model ...
	 Train_Loss: 0.4665 Train_Acc: 80.595 Val_Loss: 0.4934  BEST VAL Loss: 0.4934  Val_Acc: 77.085

Epoch 44: Validation loss decreased (0.493430 --> 0.493311).  Saving model ...
	 Train_Loss: 0.4654 Train_Acc: 80.601 Val_Loss: 0.4933  BEST VAL Loss: 0.4933  Val_Acc: 76.754

Epoch 45: Validation loss decreased (0.493311 --> 0.493065).  Saving model ...
	 Train_Loss: 0.4643 Train_Acc: 80.787 Val_Loss: 0.4931  BEST VAL Loss: 0.4931  Val_Acc: 77.038

Epoch 46: Validation loss decreased (0.493065 --> 0.492815).  Saving model ...
	 Train_Loss: 0.4632 Train_Acc: 80.985 Val_Loss: 0.4928  BEST VAL Loss: 0.4928  Val_Acc: 77.014

Epoch 47: Validation loss decreased (0.492815 --> 0.492474).  Saving model ...
	 Train_Loss: 0.4621 Train_Acc: 80.956 Val_Loss: 0.4925  BEST VAL Loss: 0.4925  Val_Acc: 77.274

Epoch 48: Validation loss decreased (0.492474 --> 0.492094).  Saving model ...
	 Train_Loss: 0.4611 Train_Acc: 81.044 Val_Loss: 0.4921  BEST VAL Loss: 0.4921  Val_Acc: 77.463

Epoch 49: Validation loss decreased (0.492094 --> 0.491911).  Saving model ...
	 Train_Loss: 0.4600 Train_Acc: 81.286 Val_Loss: 0.4919  BEST VAL Loss: 0.4919  Val_Acc: 77.274

Epoch 50: Validation loss decreased (0.491911 --> 0.491837).  Saving model ...
	 Train_Loss: 0.4590 Train_Acc: 81.345 Val_Loss: 0.4918  BEST VAL Loss: 0.4918  Val_Acc: 77.132

Epoch 51: Validation loss decreased (0.491837 --> 0.491579).  Saving model ...
	 Train_Loss: 0.4580 Train_Acc: 81.233 Val_Loss: 0.4916  BEST VAL Loss: 0.4916  Val_Acc: 77.274

Epoch 52: Validation loss decreased (0.491579 --> 0.491328).  Saving model ...
	 Train_Loss: 0.4570 Train_Acc: 81.325 Val_Loss: 0.4913  BEST VAL Loss: 0.4913  Val_Acc: 77.203

Epoch 53: Validation loss decreased (0.491328 --> 0.491114).  Saving model ...
	 Train_Loss: 0.4560 Train_Acc: 81.644 Val_Loss: 0.4911  BEST VAL Loss: 0.4911  Val_Acc: 77.534

Epoch 54: Validation loss decreased (0.491114 --> 0.490836).  Saving model ...
	 Train_Loss: 0.4550 Train_Acc: 81.478 Val_Loss: 0.4908  BEST VAL Loss: 0.4908  Val_Acc: 77.132

Epoch 55: Validation loss decreased (0.490836 --> 0.490558).  Saving model ...
	 Train_Loss: 0.4541 Train_Acc: 81.824 Val_Loss: 0.4906  BEST VAL Loss: 0.4906  Val_Acc: 77.416

Epoch 56: Validation loss decreased (0.490558 --> 0.490547).  Saving model ...
	 Train_Loss: 0.4531 Train_Acc: 81.732 Val_Loss: 0.4905  BEST VAL Loss: 0.4905  Val_Acc: 77.061

Epoch 57: Validation loss decreased (0.490547 --> 0.490280).  Saving model ...
	 Train_Loss: 0.4522 Train_Acc: 81.750 Val_Loss: 0.4903  BEST VAL Loss: 0.4903  Val_Acc: 77.321

Epoch 58: Validation loss decreased (0.490280 --> 0.490199).  Saving model ...
	 Train_Loss: 0.4513 Train_Acc: 82.025 Val_Loss: 0.4902  BEST VAL Loss: 0.4902  Val_Acc: 77.392

Epoch 59: Validation loss decreased (0.490199 --> 0.489967).  Saving model ...
	 Train_Loss: 0.4503 Train_Acc: 82.107 Val_Loss: 0.4900  BEST VAL Loss: 0.4900  Val_Acc: 77.628

Epoch 60: Validation loss decreased (0.489967 --> 0.489783).  Saving model ...
	 Train_Loss: 0.4494 Train_Acc: 82.119 Val_Loss: 0.4898  BEST VAL Loss: 0.4898  Val_Acc: 77.534

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.4485 Train_Acc: 81.960 Val_Loss: 0.4898  BEST VAL Loss: 0.4898  Val_Acc: 77.227

Epoch 62: Validation loss decreased (0.489783 --> 0.489637).  Saving model ...
	 Train_Loss: 0.4477 Train_Acc: 82.004 Val_Loss: 0.4896  BEST VAL Loss: 0.4896  Val_Acc: 77.746

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.4468 Train_Acc: 82.287 Val_Loss: 0.4897  BEST VAL Loss: 0.4896  Val_Acc: 77.085

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.4459 Train_Acc: 82.282 Val_Loss: 0.4898  BEST VAL Loss: 0.4896  Val_Acc: 76.541

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.4451 Train_Acc: 82.249 Val_Loss: 0.4898  BEST VAL Loss: 0.4896  Val_Acc: 77.439

Epoch 66: Validation loss decreased (0.489637 --> 0.489632).  Saving model ...
	 Train_Loss: 0.4443 Train_Acc: 82.261 Val_Loss: 0.4896  BEST VAL Loss: 0.4896  Val_Acc: 77.108

Epoch 67: Validation loss decreased (0.489632 --> 0.489448).  Saving model ...
	 Train_Loss: 0.4434 Train_Acc: 82.385 Val_Loss: 0.4894  BEST VAL Loss: 0.4894  Val_Acc: 76.825

Epoch 68: Validation loss decreased (0.489448 --> 0.489430).  Saving model ...
	 Train_Loss: 0.4426 Train_Acc: 82.382 Val_Loss: 0.4894  BEST VAL Loss: 0.4894  Val_Acc: 76.990

Epoch 69: Validation loss decreased (0.489430 --> 0.489221).  Saving model ...
	 Train_Loss: 0.4418 Train_Acc: 82.453 Val_Loss: 0.4892  BEST VAL Loss: 0.4892  Val_Acc: 76.636

Epoch 70: Validation loss decreased (0.489221 --> 0.489200).  Saving model ...
	 Train_Loss: 0.4411 Train_Acc: 82.462 Val_Loss: 0.4892  BEST VAL Loss: 0.4892  Val_Acc: 76.919

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.4403 Train_Acc: 82.559 Val_Loss: 0.4894  BEST VAL Loss: 0.4892  Val_Acc: 77.250

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.4396 Train_Acc: 82.633 Val_Loss: 0.4893  BEST VAL Loss: 0.4892  Val_Acc: 77.227

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.4388 Train_Acc: 82.766 Val_Loss: 0.4896  BEST VAL Loss: 0.4892  Val_Acc: 77.274

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.4381 Train_Acc: 82.866 Val_Loss: 0.4898  BEST VAL Loss: 0.4892  Val_Acc: 77.108

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.4373 Train_Acc: 82.660 Val_Loss: 0.4898  BEST VAL Loss: 0.4892  Val_Acc: 76.943

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.4366 Train_Acc: 82.648 Val_Loss: 0.4899  BEST VAL Loss: 0.4892  Val_Acc: 76.707

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.4359 Train_Acc: 83.011 Val_Loss: 0.4899  BEST VAL Loss: 0.4892  Val_Acc: 76.919

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.4352 Train_Acc: 82.967 Val_Loss: 0.4899  BEST VAL Loss: 0.4892  Val_Acc: 76.754

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.4344 Train_Acc: 83.070 Val_Loss: 0.4899  BEST VAL Loss: 0.4892  Val_Acc: 76.943

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.4337 Train_Acc: 82.931 Val_Loss: 0.4898  BEST VAL Loss: 0.4892  Val_Acc: 77.321

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.4330 Train_Acc: 83.040 Val_Loss: 0.4899  BEST VAL Loss: 0.4892  Val_Acc: 76.683

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.4323 Train_Acc: 83.020 Val_Loss: 0.4898  BEST VAL Loss: 0.4892  Val_Acc: 77.038

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.4316 Train_Acc: 83.156 Val_Loss: 0.4898  BEST VAL Loss: 0.4892  Val_Acc: 76.683

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.4310 Train_Acc: 82.973 Val_Loss: 0.4899  BEST VAL Loss: 0.4892  Val_Acc: 76.683

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.4304 Train_Acc: 83.324 Val_Loss: 0.4898  BEST VAL Loss: 0.4892  Val_Acc: 76.778

Epoch 86: Validation loss did not decrease
Early stopped at epoch : 86
DMSO_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.73      0.81      0.77     24644
           1       0.27      0.19      0.22      9219

    accuracy                           0.64     33863
   macro avg       0.50      0.50      0.50     33863
weighted avg       0.60      0.64      0.62     33863

DMSO_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.73      0.83      0.78      3081
           1       0.28      0.18      0.22      1152

    accuracy                           0.65      4233
   macro avg       0.50      0.50      0.50      4233
weighted avg       0.61      0.65      0.62      4233

DMSO_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.72      0.81      0.77      3081
           1       0.25      0.17      0.20      1152

    accuracy                           0.64      4233
   macro avg       0.49      0.49      0.48      4233
weighted avg       0.60      0.64      0.61      4233

              precision    recall  f1-score   support

           0       0.72      0.81      0.77      3081
           1       0.25      0.17      0.20      1152

    accuracy                           0.64      4233
   macro avg       0.49      0.49      0.48      4233
weighted avg       0.60      0.64      0.61      4233

DMSO_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.85      0.65      4837
           1       0.48      0.15      0.22      4336

    accuracy                           0.52      9173
   macro avg       0.50      0.50      0.44      9173
weighted avg       0.50      0.52      0.45      9173

              precision    recall  f1-score   support

           0       0.53      0.85      0.65      4837
           1       0.48      0.15      0.22      4336

    accuracy                           0.52      9173
   macro avg       0.50      0.50      0.44      9173
weighted avg       0.50      0.52      0.45      9173

completed
