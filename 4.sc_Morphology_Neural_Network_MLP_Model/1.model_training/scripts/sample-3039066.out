[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '03ca474c'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '0d0f09fa'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b6f83296'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e02c2199'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_100.000_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_100.000_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (33497, 1276)
Number of total missing values across all columns: 66994
Data Subset Is Off
Wells held out for testing: ['C20' 'J16']
Wells to use for training, validation, and testing ['C16' 'C17' 'C21' 'J17' 'J20' 'J21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.352406).  Saving model ...
	 Train_Loss: 0.5108 Train_Acc: 73.456 Val_Loss: 0.3524  BEST VAL Loss: 0.3524  Val_Acc: 84.088

Epoch 1: Validation loss decreased (0.352406 --> 0.305740).  Saving model ...
	 Train_Loss: 0.4367 Train_Acc: 82.765 Val_Loss: 0.3057  BEST VAL Loss: 0.3057  Val_Acc: 90.020

Epoch 2: Validation loss decreased (0.305740 --> 0.276036).  Saving model ...
	 Train_Loss: 0.3872 Train_Acc: 86.292 Val_Loss: 0.2760  BEST VAL Loss: 0.2760  Val_Acc: 92.224

Epoch 3: Validation loss decreased (0.276036 --> 0.254116).  Saving model ...
	 Train_Loss: 0.3539 Train_Acc: 87.008 Val_Loss: 0.2541  BEST VAL Loss: 0.2541  Val_Acc: 93.307

Epoch 4: Validation loss decreased (0.254116 --> 0.240579).  Saving model ...
	 Train_Loss: 0.3295 Train_Acc: 89.033 Val_Loss: 0.2406  BEST VAL Loss: 0.2406  Val_Acc: 91.543

Epoch 5: Validation loss decreased (0.240579 --> 0.227983).  Saving model ...
	 Train_Loss: 0.3101 Train_Acc: 90.270 Val_Loss: 0.2280  BEST VAL Loss: 0.2280  Val_Acc: 92.505

Epoch 6: Validation loss decreased (0.227983 --> 0.218882).  Saving model ...
	 Train_Loss: 0.2948 Train_Acc: 90.636 Val_Loss: 0.2189  BEST VAL Loss: 0.2189  Val_Acc: 92.505

Epoch 7: Validation loss decreased (0.218882 --> 0.210425).  Saving model ...
	 Train_Loss: 0.2824 Train_Acc: 90.871 Val_Loss: 0.2104  BEST VAL Loss: 0.2104  Val_Acc: 92.505

Epoch 8: Validation loss decreased (0.210425 --> 0.203134).  Saving model ...
	 Train_Loss: 0.2728 Train_Acc: 91.052 Val_Loss: 0.2031  BEST VAL Loss: 0.2031  Val_Acc: 92.505

Epoch 9: Validation loss decreased (0.203134 --> 0.197770).  Saving model ...
	 Train_Loss: 0.2647 Train_Acc: 90.987 Val_Loss: 0.1978  BEST VAL Loss: 0.1978  Val_Acc: 92.826

Epoch 10: Validation loss decreased (0.197770 --> 0.192857).  Saving model ...
	 Train_Loss: 0.2566 Train_Acc: 91.738 Val_Loss: 0.1929  BEST VAL Loss: 0.1929  Val_Acc: 92.986

Epoch 11: Validation loss decreased (0.192857 --> 0.189039).  Saving model ...
	 Train_Loss: 0.2500 Train_Acc: 91.728 Val_Loss: 0.1890  BEST VAL Loss: 0.1890  Val_Acc: 92.826

Epoch 12: Validation loss decreased (0.189039 --> 0.186754).  Saving model ...
	 Train_Loss: 0.2439 Train_Acc: 91.908 Val_Loss: 0.1868  BEST VAL Loss: 0.1868  Val_Acc: 92.826

Epoch 13: Validation loss decreased (0.186754 --> 0.183425).  Saving model ...
	 Train_Loss: 0.2393 Train_Acc: 91.803 Val_Loss: 0.1834  BEST VAL Loss: 0.1834  Val_Acc: 93.547

Epoch 14: Validation loss decreased (0.183425 --> 0.179928).  Saving model ...
	 Train_Loss: 0.2342 Train_Acc: 92.750 Val_Loss: 0.1799  BEST VAL Loss: 0.1799  Val_Acc: 94.269

Epoch 15: Validation loss decreased (0.179928 --> 0.178064).  Saving model ...
	 Train_Loss: 0.2290 Train_Acc: 92.961 Val_Loss: 0.1781  BEST VAL Loss: 0.1781  Val_Acc: 93.948

Epoch 16: Validation loss decreased (0.178064 --> 0.175653).  Saving model ...
	 Train_Loss: 0.2246 Train_Acc: 92.660 Val_Loss: 0.1757  BEST VAL Loss: 0.1757  Val_Acc: 94.028

Epoch 17: Validation loss decreased (0.175653 --> 0.175402).  Saving model ...
	 Train_Loss: 0.2200 Train_Acc: 93.472 Val_Loss: 0.1754  BEST VAL Loss: 0.1754  Val_Acc: 93.427

Epoch 18: Validation loss decreased (0.175402 --> 0.173149).  Saving model ...
	 Train_Loss: 0.2165 Train_Acc: 93.026 Val_Loss: 0.1731  BEST VAL Loss: 0.1731  Val_Acc: 94.148

Epoch 19: Validation loss decreased (0.173149 --> 0.171345).  Saving model ...
	 Train_Loss: 0.2133 Train_Acc: 93.041 Val_Loss: 0.1713  BEST VAL Loss: 0.1713  Val_Acc: 93.747

Epoch 20: Validation loss decreased (0.171345 --> 0.169836).  Saving model ...
	 Train_Loss: 0.2099 Train_Acc: 93.376 Val_Loss: 0.1698  BEST VAL Loss: 0.1698  Val_Acc: 93.948

Epoch 21: Validation loss decreased (0.169836 --> 0.169263).  Saving model ...
	 Train_Loss: 0.2068 Train_Acc: 93.281 Val_Loss: 0.1693  BEST VAL Loss: 0.1693  Val_Acc: 93.707

Epoch 22: Validation loss decreased (0.169263 --> 0.167668).  Saving model ...
	 Train_Loss: 0.2041 Train_Acc: 93.517 Val_Loss: 0.1677  BEST VAL Loss: 0.1677  Val_Acc: 94.028

Epoch 23: Validation loss decreased (0.167668 --> 0.166008).  Saving model ...
	 Train_Loss: 0.2012 Train_Acc: 93.742 Val_Loss: 0.1660  BEST VAL Loss: 0.1660  Val_Acc: 94.309

Epoch 24: Validation loss decreased (0.166008 --> 0.165449).  Saving model ...
	 Train_Loss: 0.1986 Train_Acc: 93.782 Val_Loss: 0.1654  BEST VAL Loss: 0.1654  Val_Acc: 93.747

Epoch 25: Validation loss decreased (0.165449 --> 0.165056).  Saving model ...
	 Train_Loss: 0.1962 Train_Acc: 93.732 Val_Loss: 0.1651  BEST VAL Loss: 0.1651  Val_Acc: 93.547

Epoch 26: Validation loss decreased (0.165056 --> 0.164276).  Saving model ...
	 Train_Loss: 0.1941 Train_Acc: 93.361 Val_Loss: 0.1643  BEST VAL Loss: 0.1643  Val_Acc: 94.349

Epoch 27: Validation loss decreased (0.164276 --> 0.164034).  Saving model ...
	 Train_Loss: 0.1920 Train_Acc: 93.958 Val_Loss: 0.1640  BEST VAL Loss: 0.1640  Val_Acc: 94.188

Epoch 28: Validation loss decreased (0.164034 --> 0.163386).  Saving model ...
	 Train_Loss: 0.1899 Train_Acc: 93.988 Val_Loss: 0.1634  BEST VAL Loss: 0.1634  Val_Acc: 94.148

Epoch 29: Validation loss decreased (0.163386 --> 0.162738).  Saving model ...
	 Train_Loss: 0.1880 Train_Acc: 93.872 Val_Loss: 0.1627  BEST VAL Loss: 0.1627  Val_Acc: 94.228

Epoch 30: Validation loss decreased (0.162738 --> 0.162051).  Saving model ...
	 Train_Loss: 0.1863 Train_Acc: 93.993 Val_Loss: 0.1621  BEST VAL Loss: 0.1621  Val_Acc: 94.108

Epoch 31: Validation loss decreased (0.162051 --> 0.161111).  Saving model ...
	 Train_Loss: 0.1846 Train_Acc: 94.083 Val_Loss: 0.1611  BEST VAL Loss: 0.1611  Val_Acc: 94.108

Epoch 32: Validation loss decreased (0.161111 --> 0.161059).  Saving model ...
	 Train_Loss: 0.1828 Train_Acc: 94.073 Val_Loss: 0.1611  BEST VAL Loss: 0.1611  Val_Acc: 94.228

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.1811 Train_Acc: 94.233 Val_Loss: 0.1615  BEST VAL Loss: 0.1611  Val_Acc: 93.788

Epoch 34: Validation loss did not decrease
	 Train_Loss: 0.1795 Train_Acc: 94.273 Val_Loss: 0.1620  BEST VAL Loss: 0.1611  Val_Acc: 94.148

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.1778 Train_Acc: 94.519 Val_Loss: 0.1627  BEST VAL Loss: 0.1611  Val_Acc: 93.788

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.1764 Train_Acc: 94.268 Val_Loss: 0.1623  BEST VAL Loss: 0.1611  Val_Acc: 94.269

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.1751 Train_Acc: 94.253 Val_Loss: 0.1621  BEST VAL Loss: 0.1611  Val_Acc: 93.868

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.1738 Train_Acc: 94.484 Val_Loss: 0.1628  BEST VAL Loss: 0.1611  Val_Acc: 94.429

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.1727 Train_Acc: 93.913 Val_Loss: 0.1629  BEST VAL Loss: 0.1611  Val_Acc: 93.948

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.1715 Train_Acc: 94.138 Val_Loss: 0.1631  BEST VAL Loss: 0.1611  Val_Acc: 94.509

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.1702 Train_Acc: 94.504 Val_Loss: 0.1635  BEST VAL Loss: 0.1611  Val_Acc: 93.948

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.1689 Train_Acc: 94.609 Val_Loss: 0.1629  BEST VAL Loss: 0.1611  Val_Acc: 94.349

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.1678 Train_Acc: 94.383 Val_Loss: 0.1631  BEST VAL Loss: 0.1611  Val_Acc: 93.868

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.1668 Train_Acc: 94.634 Val_Loss: 0.1623  BEST VAL Loss: 0.1611  Val_Acc: 94.349

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.1656 Train_Acc: 94.699 Val_Loss: 0.1621  BEST VAL Loss: 0.1611  Val_Acc: 94.349

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.1647 Train_Acc: 94.464 Val_Loss: 0.1616  BEST VAL Loss: 0.1611  Val_Acc: 94.589

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.1636 Train_Acc: 94.885 Val_Loss: 0.1615  BEST VAL Loss: 0.1611  Val_Acc: 94.790

Epoch 48: Validation loss did not decrease
Early stopped at epoch : 48
LPS_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      0.95      0.97     10451
           1       0.95      0.99      0.97      9508

    accuracy                           0.97     19959
   macro avg       0.97      0.97      0.97     19959
weighted avg       0.97      0.97      0.97     19959

LPS_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.92      0.94      1307
           1       0.92      0.97      0.94      1188

    accuracy                           0.94      2495
   macro avg       0.94      0.94      0.94      2495
weighted avg       0.94      0.94      0.94      2495

LPS_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.93      0.95      1307
           1       0.92      0.97      0.95      1188

    accuracy                           0.95      2495
   macro avg       0.95      0.95      0.95      2495
weighted avg       0.95      0.95      0.95      2495

              precision    recall  f1-score   support

           0       0.97      0.93      0.95      1307
           1       0.92      0.97      0.95      1188

    accuracy                           0.95      2495
   macro avg       0.95      0.95      0.95      2495
weighted avg       0.95      0.95      0.95      2495

LPS_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.69      0.81      4445
           1       0.75      0.97      0.84      4103

    accuracy                           0.83      8548
   macro avg       0.86      0.83      0.83      8548
weighted avg       0.86      0.83      0.83      8548

              precision    recall  f1-score   support

           0       0.97      0.69      0.81      4445
           1       0.75      0.97      0.84      4103

    accuracy                           0.83      8548
   macro avg       0.86      0.83      0.83      8548
weighted avg       0.86      0.83      0.83      8548

completed
