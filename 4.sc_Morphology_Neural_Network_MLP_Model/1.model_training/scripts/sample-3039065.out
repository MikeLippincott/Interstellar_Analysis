[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '6832e2bb'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '3a9377fe'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b865157e'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'd2866948'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_100.000_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_100.000_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (33497, 1276)
Number of total missing values across all columns: 66994
Data Subset Is Off
Wells held out for testing: ['C20' 'J16']
Wells to use for training, validation, and testing ['C16' 'C17' 'C21' 'J17' 'J20' 'J21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.423687).  Saving model ...
	 Train_Loss: 0.5745 Train_Acc: 70.164 Val_Loss: 0.4237  BEST VAL Loss: 0.4237  Val_Acc: 81.964

Epoch 1: Validation loss decreased (0.423687 --> 0.365805).  Saving model ...
	 Train_Loss: 0.4923 Train_Acc: 80.495 Val_Loss: 0.3658  BEST VAL Loss: 0.3658  Val_Acc: 86.854

Epoch 2: Validation loss decreased (0.365805 --> 0.326604).  Saving model ...
	 Train_Loss: 0.4401 Train_Acc: 85.029 Val_Loss: 0.3266  BEST VAL Loss: 0.3266  Val_Acc: 90.020

Epoch 3: Validation loss decreased (0.326604 --> 0.301266).  Saving model ...
	 Train_Loss: 0.3999 Train_Acc: 87.479 Val_Loss: 0.3013  BEST VAL Loss: 0.3013  Val_Acc: 91.583

Epoch 4: Validation loss decreased (0.301266 --> 0.278428).  Saving model ...
	 Train_Loss: 0.3690 Train_Acc: 88.962 Val_Loss: 0.2784  BEST VAL Loss: 0.2784  Val_Acc: 92.745

Epoch 5: Validation loss decreased (0.278428 --> 0.261575).  Saving model ...
	 Train_Loss: 0.3463 Train_Acc: 90.150 Val_Loss: 0.2616  BEST VAL Loss: 0.2616  Val_Acc: 93.106

Epoch 6: Validation loss decreased (0.261575 --> 0.249528).  Saving model ...
	 Train_Loss: 0.3281 Train_Acc: 90.746 Val_Loss: 0.2495  BEST VAL Loss: 0.2495  Val_Acc: 93.868

Epoch 7: Validation loss decreased (0.249528 --> 0.240381).  Saving model ...
	 Train_Loss: 0.3128 Train_Acc: 91.618 Val_Loss: 0.2404  BEST VAL Loss: 0.2404  Val_Acc: 93.988

Epoch 8: Validation loss decreased (0.240381 --> 0.230754).  Saving model ...
	 Train_Loss: 0.2999 Train_Acc: 92.159 Val_Loss: 0.2308  BEST VAL Loss: 0.2308  Val_Acc: 94.188

Epoch 9: Validation loss decreased (0.230754 --> 0.224027).  Saving model ...
	 Train_Loss: 0.2893 Train_Acc: 92.139 Val_Loss: 0.2240  BEST VAL Loss: 0.2240  Val_Acc: 93.747

Epoch 10: Validation loss decreased (0.224027 --> 0.217312).  Saving model ...
	 Train_Loss: 0.2803 Train_Acc: 91.918 Val_Loss: 0.2173  BEST VAL Loss: 0.2173  Val_Acc: 93.707

Epoch 11: Validation loss decreased (0.217312 --> 0.211545).  Saving model ...
	 Train_Loss: 0.2720 Train_Acc: 92.545 Val_Loss: 0.2115  BEST VAL Loss: 0.2115  Val_Acc: 93.908

Epoch 12: Validation loss decreased (0.211545 --> 0.206207).  Saving model ...
	 Train_Loss: 0.2644 Train_Acc: 92.750 Val_Loss: 0.2062  BEST VAL Loss: 0.2062  Val_Acc: 94.469

Epoch 13: Validation loss decreased (0.206207 --> 0.201401).  Saving model ...
	 Train_Loss: 0.2579 Train_Acc: 92.755 Val_Loss: 0.2014  BEST VAL Loss: 0.2014  Val_Acc: 94.870

Epoch 14: Validation loss decreased (0.201401 --> 0.197367).  Saving model ...
	 Train_Loss: 0.2520 Train_Acc: 93.051 Val_Loss: 0.1974  BEST VAL Loss: 0.1974  Val_Acc: 94.589

Epoch 15: Validation loss decreased (0.197367 --> 0.195314).  Saving model ...
	 Train_Loss: 0.2465 Train_Acc: 93.051 Val_Loss: 0.1953  BEST VAL Loss: 0.1953  Val_Acc: 94.269

Epoch 16: Validation loss decreased (0.195314 --> 0.192258).  Saving model ...
	 Train_Loss: 0.2417 Train_Acc: 93.381 Val_Loss: 0.1923  BEST VAL Loss: 0.1923  Val_Acc: 94.870

Epoch 17: Validation loss decreased (0.192258 --> 0.189959).  Saving model ...
	 Train_Loss: 0.2369 Train_Acc: 93.141 Val_Loss: 0.1900  BEST VAL Loss: 0.1900  Val_Acc: 94.389

Epoch 18: Validation loss decreased (0.189959 --> 0.187407).  Saving model ...
	 Train_Loss: 0.2327 Train_Acc: 93.226 Val_Loss: 0.1874  BEST VAL Loss: 0.1874  Val_Acc: 95.110

Epoch 19: Validation loss decreased (0.187407 --> 0.187154).  Saving model ...
	 Train_Loss: 0.2287 Train_Acc: 93.472 Val_Loss: 0.1872  BEST VAL Loss: 0.1872  Val_Acc: 93.868

Epoch 20: Validation loss decreased (0.187154 --> 0.185385).  Saving model ...
	 Train_Loss: 0.2254 Train_Acc: 93.251 Val_Loss: 0.1854  BEST VAL Loss: 0.1854  Val_Acc: 94.068

Epoch 21: Validation loss decreased (0.185385 --> 0.182905).  Saving model ...
	 Train_Loss: 0.2220 Train_Acc: 93.432 Val_Loss: 0.1829  BEST VAL Loss: 0.1829  Val_Acc: 95.230

Epoch 22: Validation loss decreased (0.182905 --> 0.181404).  Saving model ...
	 Train_Loss: 0.2186 Train_Acc: 93.692 Val_Loss: 0.1814  BEST VAL Loss: 0.1814  Val_Acc: 94.749

Epoch 23: Validation loss decreased (0.181404 --> 0.179711).  Saving model ...
	 Train_Loss: 0.2154 Train_Acc: 94.218 Val_Loss: 0.1797  BEST VAL Loss: 0.1797  Val_Acc: 94.990

Epoch 24: Validation loss decreased (0.179711 --> 0.178926).  Saving model ...
	 Train_Loss: 0.2127 Train_Acc: 93.657 Val_Loss: 0.1789  BEST VAL Loss: 0.1789  Val_Acc: 94.870

Epoch 25: Validation loss decreased (0.178926 --> 0.177339).  Saving model ...
	 Train_Loss: 0.2100 Train_Acc: 93.777 Val_Loss: 0.1773  BEST VAL Loss: 0.1773  Val_Acc: 94.790

Epoch 26: Validation loss decreased (0.177339 --> 0.176222).  Saving model ...
	 Train_Loss: 0.2074 Train_Acc: 94.023 Val_Loss: 0.1762  BEST VAL Loss: 0.1762  Val_Acc: 94.950

Epoch 27: Validation loss decreased (0.176222 --> 0.175087).  Saving model ...
	 Train_Loss: 0.2051 Train_Acc: 94.023 Val_Loss: 0.1751  BEST VAL Loss: 0.1751  Val_Acc: 94.870

Epoch 28: Validation loss decreased (0.175087 --> 0.173821).  Saving model ...
	 Train_Loss: 0.2026 Train_Acc: 94.238 Val_Loss: 0.1738  BEST VAL Loss: 0.1738  Val_Acc: 95.030

Epoch 29: Validation loss decreased (0.173821 --> 0.172954).  Saving model ...
	 Train_Loss: 0.2004 Train_Acc: 94.128 Val_Loss: 0.1730  BEST VAL Loss: 0.1730  Val_Acc: 95.030

Epoch 30: Validation loss decreased (0.172954 --> 0.172179).  Saving model ...
	 Train_Loss: 0.1981 Train_Acc: 94.153 Val_Loss: 0.1722  BEST VAL Loss: 0.1722  Val_Acc: 94.709

Epoch 31: Validation loss decreased (0.172179 --> 0.171122).  Saving model ...
	 Train_Loss: 0.1961 Train_Acc: 94.008 Val_Loss: 0.1711  BEST VAL Loss: 0.1711  Val_Acc: 95.311

Epoch 32: Validation loss decreased (0.171122 --> 0.170104).  Saving model ...
	 Train_Loss: 0.1942 Train_Acc: 94.424 Val_Loss: 0.1701  BEST VAL Loss: 0.1701  Val_Acc: 95.070

Epoch 33: Validation loss decreased (0.170104 --> 0.169165).  Saving model ...
	 Train_Loss: 0.1923 Train_Acc: 94.669 Val_Loss: 0.1692  BEST VAL Loss: 0.1692  Val_Acc: 95.230

Epoch 34: Validation loss decreased (0.169165 --> 0.168425).  Saving model ...
	 Train_Loss: 0.1906 Train_Acc: 94.118 Val_Loss: 0.1684  BEST VAL Loss: 0.1684  Val_Acc: 95.471

Epoch 35: Validation loss decreased (0.168425 --> 0.167645).  Saving model ...
	 Train_Loss: 0.1889 Train_Acc: 94.434 Val_Loss: 0.1676  BEST VAL Loss: 0.1676  Val_Acc: 95.230

Epoch 36: Validation loss decreased (0.167645 --> 0.167064).  Saving model ...
	 Train_Loss: 0.1873 Train_Acc: 94.373 Val_Loss: 0.1671  BEST VAL Loss: 0.1671  Val_Acc: 95.351

Epoch 37: Validation loss decreased (0.167064 --> 0.166350).  Saving model ...
	 Train_Loss: 0.1857 Train_Acc: 94.554 Val_Loss: 0.1663  BEST VAL Loss: 0.1663  Val_Acc: 95.351

Epoch 38: Validation loss decreased (0.166350 --> 0.165797).  Saving model ...
	 Train_Loss: 0.1844 Train_Acc: 94.248 Val_Loss: 0.1658  BEST VAL Loss: 0.1658  Val_Acc: 95.070

Epoch 39: Validation loss decreased (0.165797 --> 0.165423).  Saving model ...
	 Train_Loss: 0.1829 Train_Acc: 94.288 Val_Loss: 0.1654  BEST VAL Loss: 0.1654  Val_Acc: 95.271

Epoch 40: Validation loss decreased (0.165423 --> 0.164743).  Saving model ...
	 Train_Loss: 0.1816 Train_Acc: 94.118 Val_Loss: 0.1647  BEST VAL Loss: 0.1647  Val_Acc: 95.431

Epoch 41: Validation loss decreased (0.164743 --> 0.164185).  Saving model ...
	 Train_Loss: 0.1804 Train_Acc: 94.429 Val_Loss: 0.1642  BEST VAL Loss: 0.1642  Val_Acc: 94.910

Epoch 42: Validation loss decreased (0.164185 --> 0.163899).  Saving model ...
	 Train_Loss: 0.1791 Train_Acc: 94.158 Val_Loss: 0.1639  BEST VAL Loss: 0.1639  Val_Acc: 95.030

Epoch 43: Validation loss decreased (0.163899 --> 0.163350).  Saving model ...
	 Train_Loss: 0.1778 Train_Acc: 94.489 Val_Loss: 0.1634  BEST VAL Loss: 0.1634  Val_Acc: 94.950

Epoch 44: Validation loss decreased (0.163350 --> 0.162821).  Saving model ...
	 Train_Loss: 0.1766 Train_Acc: 94.429 Val_Loss: 0.1628  BEST VAL Loss: 0.1628  Val_Acc: 95.110

Epoch 45: Validation loss decreased (0.162821 --> 0.162171).  Saving model ...
	 Train_Loss: 0.1755 Train_Acc: 94.429 Val_Loss: 0.1622  BEST VAL Loss: 0.1622  Val_Acc: 95.150

Epoch 46: Validation loss decreased (0.162171 --> 0.162001).  Saving model ...
	 Train_Loss: 0.1745 Train_Acc: 94.158 Val_Loss: 0.1620  BEST VAL Loss: 0.1620  Val_Acc: 95.311

Epoch 47: Validation loss decreased (0.162001 --> 0.161136).  Saving model ...
	 Train_Loss: 0.1736 Train_Acc: 94.003 Val_Loss: 0.1611  BEST VAL Loss: 0.1611  Val_Acc: 95.711

Epoch 48: Validation loss decreased (0.161136 --> 0.160527).  Saving model ...
	 Train_Loss: 0.1727 Train_Acc: 94.449 Val_Loss: 0.1605  BEST VAL Loss: 0.1605  Val_Acc: 95.030

Epoch 49: Validation loss decreased (0.160527 --> 0.160307).  Saving model ...
	 Train_Loss: 0.1717 Train_Acc: 94.624 Val_Loss: 0.1603  BEST VAL Loss: 0.1603  Val_Acc: 95.832

Epoch 50: Validation loss decreased (0.160307 --> 0.160087).  Saving model ...
	 Train_Loss: 0.1706 Train_Acc: 95.035 Val_Loss: 0.1601  BEST VAL Loss: 0.1601  Val_Acc: 94.749

Epoch 51: Validation loss decreased (0.160087 --> 0.159853).  Saving model ...
	 Train_Loss: 0.1696 Train_Acc: 94.729 Val_Loss: 0.1599  BEST VAL Loss: 0.1599  Val_Acc: 95.230

Epoch 52: Validation loss decreased (0.159853 --> 0.159573).  Saving model ...
	 Train_Loss: 0.1688 Train_Acc: 93.913 Val_Loss: 0.1596  BEST VAL Loss: 0.1596  Val_Acc: 95.110

Epoch 53: Validation loss decreased (0.159573 --> 0.159197).  Saving model ...
	 Train_Loss: 0.1681 Train_Acc: 94.273 Val_Loss: 0.1592  BEST VAL Loss: 0.1592  Val_Acc: 94.709

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.1674 Train_Acc: 94.108 Val_Loss: 0.1593  BEST VAL Loss: 0.1592  Val_Acc: 95.150

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.1667 Train_Acc: 94.414 Val_Loss: 0.1594  BEST VAL Loss: 0.1592  Val_Acc: 95.230

Epoch 56: Validation loss decreased (0.159197 --> 0.158988).  Saving model ...
	 Train_Loss: 0.1660 Train_Acc: 94.474 Val_Loss: 0.1590  BEST VAL Loss: 0.1590  Val_Acc: 95.351

Epoch 57: Validation loss decreased (0.158988 --> 0.158720).  Saving model ...
	 Train_Loss: 0.1654 Train_Acc: 94.153 Val_Loss: 0.1587  BEST VAL Loss: 0.1587  Val_Acc: 94.910

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.1647 Train_Acc: 94.499 Val_Loss: 0.1588  BEST VAL Loss: 0.1587  Val_Acc: 95.110

Epoch 59: Validation loss decreased (0.158720 --> 0.158712).  Saving model ...
	 Train_Loss: 0.1641 Train_Acc: 94.218 Val_Loss: 0.1587  BEST VAL Loss: 0.1587  Val_Acc: 95.070

Epoch 60: Validation loss decreased (0.158712 --> 0.158564).  Saving model ...
	 Train_Loss: 0.1634 Train_Acc: 94.524 Val_Loss: 0.1586  BEST VAL Loss: 0.1586  Val_Acc: 95.551

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.1629 Train_Acc: 94.233 Val_Loss: 0.1586  BEST VAL Loss: 0.1586  Val_Acc: 95.351

Epoch 62: Validation loss decreased (0.158564 --> 0.158401).  Saving model ...
	 Train_Loss: 0.1622 Train_Acc: 94.248 Val_Loss: 0.1584  BEST VAL Loss: 0.1584  Val_Acc: 95.471

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.1615 Train_Acc: 94.694 Val_Loss: 0.1586  BEST VAL Loss: 0.1584  Val_Acc: 94.990

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.1610 Train_Acc: 94.574 Val_Loss: 0.1584  BEST VAL Loss: 0.1584  Val_Acc: 95.311

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.1603 Train_Acc: 94.509 Val_Loss: 0.1585  BEST VAL Loss: 0.1584  Val_Acc: 95.671

Epoch 66: Validation loss decreased (0.158401 --> 0.158207).  Saving model ...
	 Train_Loss: 0.1597 Train_Acc: 94.834 Val_Loss: 0.1582  BEST VAL Loss: 0.1582  Val_Acc: 95.631

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.1591 Train_Acc: 94.494 Val_Loss: 0.1584  BEST VAL Loss: 0.1582  Val_Acc: 95.671

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.1585 Train_Acc: 94.654 Val_Loss: 0.1586  BEST VAL Loss: 0.1582  Val_Acc: 95.511

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.1578 Train_Acc: 95.055 Val_Loss: 0.1584  BEST VAL Loss: 0.1582  Val_Acc: 95.511

Epoch 70: Validation loss decreased (0.158207 --> 0.158040).  Saving model ...
	 Train_Loss: 0.1572 Train_Acc: 94.779 Val_Loss: 0.1580  BEST VAL Loss: 0.1580  Val_Acc: 95.511

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.1566 Train_Acc: 94.900 Val_Loss: 0.1582  BEST VAL Loss: 0.1580  Val_Acc: 95.631

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.1560 Train_Acc: 94.539 Val_Loss: 0.1582  BEST VAL Loss: 0.1580  Val_Acc: 95.511

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.1554 Train_Acc: 94.940 Val_Loss: 0.1581  BEST VAL Loss: 0.1580  Val_Acc: 95.631

Epoch 74: Validation loss decreased (0.158040 --> 0.157835).  Saving model ...
	 Train_Loss: 0.1549 Train_Acc: 94.789 Val_Loss: 0.1578  BEST VAL Loss: 0.1578  Val_Acc: 95.752

Epoch 75: Validation loss decreased (0.157835 --> 0.157494).  Saving model ...
	 Train_Loss: 0.1544 Train_Acc: 94.684 Val_Loss: 0.1575  BEST VAL Loss: 0.1575  Val_Acc: 95.511

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.1539 Train_Acc: 94.744 Val_Loss: 0.1576  BEST VAL Loss: 0.1575  Val_Acc: 95.591

Epoch 77: Validation loss decreased (0.157494 --> 0.157356).  Saving model ...
	 Train_Loss: 0.1534 Train_Acc: 94.789 Val_Loss: 0.1574  BEST VAL Loss: 0.1574  Val_Acc: 95.992

Epoch 78: Validation loss decreased (0.157356 --> 0.156955).  Saving model ...
	 Train_Loss: 0.1528 Train_Acc: 95.125 Val_Loss: 0.1570  BEST VAL Loss: 0.1570  Val_Acc: 95.711

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.1523 Train_Acc: 94.869 Val_Loss: 0.1572  BEST VAL Loss: 0.1570  Val_Acc: 95.391

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.1517 Train_Acc: 95.035 Val_Loss: 0.1573  BEST VAL Loss: 0.1570  Val_Acc: 95.671

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.1512 Train_Acc: 94.834 Val_Loss: 0.1576  BEST VAL Loss: 0.1570  Val_Acc: 95.792

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.1506 Train_Acc: 95.355 Val_Loss: 0.1580  BEST VAL Loss: 0.1570  Val_Acc: 95.511

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.1501 Train_Acc: 95.050 Val_Loss: 0.1581  BEST VAL Loss: 0.1570  Val_Acc: 95.271

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.1497 Train_Acc: 94.624 Val_Loss: 0.1582  BEST VAL Loss: 0.1570  Val_Acc: 95.551

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.1492 Train_Acc: 95.280 Val_Loss: 0.1583  BEST VAL Loss: 0.1570  Val_Acc: 95.711

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.1487 Train_Acc: 95.360 Val_Loss: 0.1583  BEST VAL Loss: 0.1570  Val_Acc: 95.311

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.1482 Train_Acc: 95.310 Val_Loss: 0.1583  BEST VAL Loss: 0.1570  Val_Acc: 95.511

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.1477 Train_Acc: 95.035 Val_Loss: 0.1581  BEST VAL Loss: 0.1570  Val_Acc: 95.150

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.1473 Train_Acc: 95.015 Val_Loss: 0.1584  BEST VAL Loss: 0.1570  Val_Acc: 94.950

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.1468 Train_Acc: 95.000 Val_Loss: 0.1586  BEST VAL Loss: 0.1570  Val_Acc: 95.351

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.1464 Train_Acc: 94.769 Val_Loss: 0.1585  BEST VAL Loss: 0.1570  Val_Acc: 95.832

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.1460 Train_Acc: 95.466 Val_Loss: 0.1584  BEST VAL Loss: 0.1570  Val_Acc: 95.792

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.1456 Train_Acc: 94.970 Val_Loss: 0.1587  BEST VAL Loss: 0.1570  Val_Acc: 95.391

Epoch 94: Validation loss did not decrease
Early stopped at epoch : 94
LPS_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.51      0.52     10451
           1       0.47      0.48      0.48      9508

    accuracy                           0.50     19959
   macro avg       0.50      0.50      0.50     19959
weighted avg       0.50      0.50      0.50     19959

LPS_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.51      0.52      1307
           1       0.48      0.50      0.49      1188

    accuracy                           0.50      2495
   macro avg       0.50      0.50      0.50      2495
weighted avg       0.50      0.50      0.50      2495

LPS_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.53      0.53      1307
           1       0.49      0.49      0.49      1188

    accuracy                           0.51      2495
   macro avg       0.51      0.51      0.51      2495
weighted avg       0.51      0.51      0.51      2495

              precision    recall  f1-score   support

           0       0.53      0.53      0.53      1307
           1       0.49      0.49      0.49      1188

    accuracy                           0.51      2495
   macro avg       0.51      0.51      0.51      2495
weighted avg       0.51      0.51      0.51      2495

LPS_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.36      0.43      4445
           1       0.48      0.63      0.55      4103

    accuracy                           0.49      8548
   macro avg       0.50      0.50      0.49      8548
weighted avg       0.50      0.49      0.48      8548

              precision    recall  f1-score   support

           0       0.52      0.36      0.43      4445
           1       0.48      0.63      0.55      4103

    accuracy                           0.49      8548
   macro avg       0.50      0.50      0.49      8548
weighted avg       0.50      0.49      0.48      8548

completed
