[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '9e972b81'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e967634c'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '13c34fe2'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '965eef94'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_10.000_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (315925, 1270)
Number of total missing values across all columns: 631850
Data Subset Is Off
Wells held out for testing: ['E09' 'J08']
Wells to use for training, validation, and testing ['E02' 'E03' 'E08' 'J02' 'J03' 'J09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.611478).  Saving model ...
	 Train_Loss: 0.6844 Train_Acc: 58.825 Val_Loss: 0.6115  BEST VAL Loss: 0.6115  Val_Acc: 66.952

Epoch 1: Validation loss decreased (0.611478 --> 0.590731).  Saving model ...
	 Train_Loss: 0.6509 Train_Acc: 64.973 Val_Loss: 0.5907  BEST VAL Loss: 0.5907  Val_Acc: 69.753

Epoch 2: Validation loss decreased (0.590731 --> 0.579650).  Saving model ...
	 Train_Loss: 0.6330 Train_Acc: 66.502 Val_Loss: 0.5797  BEST VAL Loss: 0.5797  Val_Acc: 70.401

Epoch 3: Validation loss decreased (0.579650 --> 0.572208).  Saving model ...
	 Train_Loss: 0.6216 Train_Acc: 67.184 Val_Loss: 0.5722  BEST VAL Loss: 0.5722  Val_Acc: 70.620

Epoch 4: Validation loss decreased (0.572208 --> 0.565807).  Saving model ...
	 Train_Loss: 0.6124 Train_Acc: 68.161 Val_Loss: 0.5658  BEST VAL Loss: 0.5658  Val_Acc: 71.366

Epoch 5: Validation loss decreased (0.565807 --> 0.561364).  Saving model ...
	 Train_Loss: 0.6054 Train_Acc: 68.599 Val_Loss: 0.5614  BEST VAL Loss: 0.5614  Val_Acc: 71.728

Epoch 6: Validation loss decreased (0.561364 --> 0.557106).  Saving model ...
	 Train_Loss: 0.6001 Train_Acc: 68.724 Val_Loss: 0.5571  BEST VAL Loss: 0.5571  Val_Acc: 71.534

Epoch 7: Validation loss decreased (0.557106 --> 0.552933).  Saving model ...
	 Train_Loss: 0.5954 Train_Acc: 69.236 Val_Loss: 0.5529  BEST VAL Loss: 0.5529  Val_Acc: 72.507

Epoch 8: Validation loss decreased (0.552933 --> 0.549928).  Saving model ...
	 Train_Loss: 0.5912 Train_Acc: 69.547 Val_Loss: 0.5499  BEST VAL Loss: 0.5499  Val_Acc: 72.305

Epoch 9: Validation loss decreased (0.549928 --> 0.547112).  Saving model ...
	 Train_Loss: 0.5876 Train_Acc: 69.782 Val_Loss: 0.5471  BEST VAL Loss: 0.5471  Val_Acc: 72.815

Epoch 10: Validation loss decreased (0.547112 --> 0.544634).  Saving model ...
	 Train_Loss: 0.5846 Train_Acc: 69.845 Val_Loss: 0.5446  BEST VAL Loss: 0.5446  Val_Acc: 72.899

Epoch 11: Validation loss decreased (0.544634 --> 0.542662).  Saving model ...
	 Train_Loss: 0.5819 Train_Acc: 69.871 Val_Loss: 0.5427  BEST VAL Loss: 0.5427  Val_Acc: 73.341

Epoch 12: Validation loss decreased (0.542662 --> 0.540510).  Saving model ...
	 Train_Loss: 0.5795 Train_Acc: 70.147 Val_Loss: 0.5405  BEST VAL Loss: 0.5405  Val_Acc: 73.358

Epoch 13: Validation loss decreased (0.540510 --> 0.538921).  Saving model ...
	 Train_Loss: 0.5771 Train_Acc: 70.669 Val_Loss: 0.5389  BEST VAL Loss: 0.5389  Val_Acc: 73.354

Epoch 14: Validation loss decreased (0.538921 --> 0.537374).  Saving model ...
	 Train_Loss: 0.5749 Train_Acc: 70.672 Val_Loss: 0.5374  BEST VAL Loss: 0.5374  Val_Acc: 73.628

Epoch 15: Validation loss decreased (0.537374 --> 0.536124).  Saving model ...
	 Train_Loss: 0.5729 Train_Acc: 70.741 Val_Loss: 0.5361  BEST VAL Loss: 0.5361  Val_Acc: 72.718

Epoch 16: Validation loss decreased (0.536124 --> 0.534551).  Saving model ...
	 Train_Loss: 0.5711 Train_Acc: 71.017 Val_Loss: 0.5346  BEST VAL Loss: 0.5346  Val_Acc: 74.331

Epoch 17: Validation loss decreased (0.534551 --> 0.532949).  Saving model ...
	 Train_Loss: 0.5692 Train_Acc: 71.208 Val_Loss: 0.5329  BEST VAL Loss: 0.5329  Val_Acc: 74.491

Epoch 18: Validation loss decreased (0.532949 --> 0.532024).  Saving model ...
	 Train_Loss: 0.5676 Train_Acc: 71.130 Val_Loss: 0.5320  BEST VAL Loss: 0.5320  Val_Acc: 73.674

Epoch 19: Validation loss decreased (0.532024 --> 0.530481).  Saving model ...
	 Train_Loss: 0.5660 Train_Acc: 71.362 Val_Loss: 0.5305  BEST VAL Loss: 0.5305  Val_Acc: 75.001

Epoch 20: Validation loss decreased (0.530481 --> 0.529406).  Saving model ...
	 Train_Loss: 0.5646 Train_Acc: 71.526 Val_Loss: 0.5294  BEST VAL Loss: 0.5294  Val_Acc: 74.715

Epoch 21: Validation loss decreased (0.529406 --> 0.528299).  Saving model ...
	 Train_Loss: 0.5630 Train_Acc: 71.695 Val_Loss: 0.5283  BEST VAL Loss: 0.5283  Val_Acc: 75.254

Epoch 22: Validation loss decreased (0.528299 --> 0.527192).  Saving model ...
	 Train_Loss: 0.5615 Train_Acc: 72.040 Val_Loss: 0.5272  BEST VAL Loss: 0.5272  Val_Acc: 74.778

Epoch 23: Validation loss decreased (0.527192 --> 0.526297).  Saving model ...
	 Train_Loss: 0.5601 Train_Acc: 72.156 Val_Loss: 0.5263  BEST VAL Loss: 0.5263  Val_Acc: 74.011

Epoch 24: Validation loss decreased (0.526297 --> 0.525077).  Saving model ...
	 Train_Loss: 0.5588 Train_Acc: 72.229 Val_Loss: 0.5251  BEST VAL Loss: 0.5251  Val_Acc: 75.957

Epoch 25: Validation loss decreased (0.525077 --> 0.524623).  Saving model ...
	 Train_Loss: 0.5577 Train_Acc: 71.996 Val_Loss: 0.5246  BEST VAL Loss: 0.5246  Val_Acc: 75.064

Epoch 26: Validation loss decreased (0.524623 --> 0.523562).  Saving model ...
	 Train_Loss: 0.5566 Train_Acc: 72.188 Val_Loss: 0.5236  BEST VAL Loss: 0.5236  Val_Acc: 75.565

Epoch 27: Validation loss decreased (0.523562 --> 0.522661).  Saving model ...
	 Train_Loss: 0.5556 Train_Acc: 72.057 Val_Loss: 0.5227  BEST VAL Loss: 0.5227  Val_Acc: 75.123

Epoch 28: Validation loss decreased (0.522661 --> 0.521929).  Saving model ...
	 Train_Loss: 0.5544 Train_Acc: 72.539 Val_Loss: 0.5219  BEST VAL Loss: 0.5219  Val_Acc: 75.334

Epoch 29: Validation loss decreased (0.521929 --> 0.521176).  Saving model ...
	 Train_Loss: 0.5533 Train_Acc: 72.452 Val_Loss: 0.5212  BEST VAL Loss: 0.5212  Val_Acc: 75.368

Epoch 30: Validation loss decreased (0.521176 --> 0.520322).  Saving model ...
	 Train_Loss: 0.5524 Train_Acc: 72.380 Val_Loss: 0.5203  BEST VAL Loss: 0.5203  Val_Acc: 75.713

Epoch 31: Validation loss decreased (0.520322 --> 0.519608).  Saving model ...
	 Train_Loss: 0.5513 Train_Acc: 72.539 Val_Loss: 0.5196  BEST VAL Loss: 0.5196  Val_Acc: 75.730

Epoch 32: Validation loss decreased (0.519608 --> 0.518862).  Saving model ...
	 Train_Loss: 0.5504 Train_Acc: 72.754 Val_Loss: 0.5189  BEST VAL Loss: 0.5189  Val_Acc: 75.599

Epoch 33: Validation loss decreased (0.518862 --> 0.518240).  Saving model ...
	 Train_Loss: 0.5494 Train_Acc: 72.846 Val_Loss: 0.5182  BEST VAL Loss: 0.5182  Val_Acc: 76.155

Epoch 34: Validation loss decreased (0.518240 --> 0.517299).  Saving model ...
	 Train_Loss: 0.5486 Train_Acc: 72.572 Val_Loss: 0.5173  BEST VAL Loss: 0.5173  Val_Acc: 76.383

Epoch 35: Validation loss decreased (0.517299 --> 0.516372).  Saving model ...
	 Train_Loss: 0.5477 Train_Acc: 72.870 Val_Loss: 0.5164  BEST VAL Loss: 0.5164  Val_Acc: 76.513

Epoch 36: Validation loss decreased (0.516372 --> 0.515434).  Saving model ...
	 Train_Loss: 0.5468 Train_Acc: 72.886 Val_Loss: 0.5154  BEST VAL Loss: 0.5154  Val_Acc: 76.467

Epoch 37: Validation loss decreased (0.515434 --> 0.514703).  Saving model ...
	 Train_Loss: 0.5461 Train_Acc: 72.637 Val_Loss: 0.5147  BEST VAL Loss: 0.5147  Val_Acc: 76.572

Epoch 38: Validation loss decreased (0.514703 --> 0.513968).  Saving model ...
	 Train_Loss: 0.5453 Train_Acc: 72.883 Val_Loss: 0.5140  BEST VAL Loss: 0.5140  Val_Acc: 76.623

Epoch 39: Validation loss decreased (0.513968 --> 0.513618).  Saving model ...
	 Train_Loss: 0.5446 Train_Acc: 72.823 Val_Loss: 0.5136  BEST VAL Loss: 0.5136  Val_Acc: 74.875

Epoch 40: Validation loss decreased (0.513618 --> 0.513004).  Saving model ...
	 Train_Loss: 0.5438 Train_Acc: 73.021 Val_Loss: 0.5130  BEST VAL Loss: 0.5130  Val_Acc: 76.547

Epoch 41: Validation loss decreased (0.513004 --> 0.512252).  Saving model ...
	 Train_Loss: 0.5431 Train_Acc: 72.820 Val_Loss: 0.5123  BEST VAL Loss: 0.5123  Val_Acc: 76.661

Epoch 42: Validation loss decreased (0.512252 --> 0.511682).  Saving model ...
	 Train_Loss: 0.5424 Train_Acc: 73.013 Val_Loss: 0.5117  BEST VAL Loss: 0.5117  Val_Acc: 76.458

Epoch 43: Validation loss decreased (0.511682 --> 0.510937).  Saving model ...
	 Train_Loss: 0.5418 Train_Acc: 73.127 Val_Loss: 0.5109  BEST VAL Loss: 0.5109  Val_Acc: 76.610

Epoch 44: Validation loss decreased (0.510937 --> 0.510445).  Saving model ...
	 Train_Loss: 0.5411 Train_Acc: 73.155 Val_Loss: 0.5104  BEST VAL Loss: 0.5104  Val_Acc: 75.873

Epoch 45: Validation loss decreased (0.510445 --> 0.510024).  Saving model ...
	 Train_Loss: 0.5405 Train_Acc: 73.210 Val_Loss: 0.5100  BEST VAL Loss: 0.5100  Val_Acc: 75.587

Epoch 46: Validation loss decreased (0.510024 --> 0.509529).  Saving model ...
	 Train_Loss: 0.5398 Train_Acc: 73.211 Val_Loss: 0.5095  BEST VAL Loss: 0.5095  Val_Acc: 76.362

Epoch 47: Validation loss decreased (0.509529 --> 0.508997).  Saving model ...
	 Train_Loss: 0.5392 Train_Acc: 73.350 Val_Loss: 0.5090  BEST VAL Loss: 0.5090  Val_Acc: 76.374

Epoch 48: Validation loss decreased (0.508997 --> 0.508372).  Saving model ...
	 Train_Loss: 0.5387 Train_Acc: 72.930 Val_Loss: 0.5084  BEST VAL Loss: 0.5084  Val_Acc: 76.804

Epoch 49: Validation loss decreased (0.508372 --> 0.507872).  Saving model ...
	 Train_Loss: 0.5382 Train_Acc: 73.083 Val_Loss: 0.5079  BEST VAL Loss: 0.5079  Val_Acc: 76.437

Epoch 50: Validation loss decreased (0.507872 --> 0.507240).  Saving model ...
	 Train_Loss: 0.5377 Train_Acc: 73.075 Val_Loss: 0.5072  BEST VAL Loss: 0.5072  Val_Acc: 77.238

Epoch 51: Validation loss decreased (0.507240 --> 0.506688).  Saving model ...
	 Train_Loss: 0.5371 Train_Acc: 73.476 Val_Loss: 0.5067  BEST VAL Loss: 0.5067  Val_Acc: 76.825

Epoch 52: Validation loss decreased (0.506688 --> 0.506251).  Saving model ...
	 Train_Loss: 0.5366 Train_Acc: 73.286 Val_Loss: 0.5063  BEST VAL Loss: 0.5063  Val_Acc: 76.888

Epoch 53: Validation loss decreased (0.506251 --> 0.505745).  Saving model ...
	 Train_Loss: 0.5360 Train_Acc: 73.398 Val_Loss: 0.5057  BEST VAL Loss: 0.5057  Val_Acc: 77.162

Epoch 54: Validation loss decreased (0.505745 --> 0.505389).  Saving model ...
	 Train_Loss: 0.5355 Train_Acc: 73.290 Val_Loss: 0.5054  BEST VAL Loss: 0.5054  Val_Acc: 76.543

Epoch 55: Validation loss decreased (0.505389 --> 0.504881).  Saving model ...
	 Train_Loss: 0.5351 Train_Acc: 73.164 Val_Loss: 0.5049  BEST VAL Loss: 0.5049  Val_Acc: 76.728

Epoch 56: Validation loss decreased (0.504881 --> 0.504461).  Saving model ...
	 Train_Loss: 0.5347 Train_Acc: 72.871 Val_Loss: 0.5045  BEST VAL Loss: 0.5045  Val_Acc: 76.842

Epoch 57: Validation loss decreased (0.504461 --> 0.504070).  Saving model ...
	 Train_Loss: 0.5343 Train_Acc: 73.129 Val_Loss: 0.5041  BEST VAL Loss: 0.5041  Val_Acc: 76.905

Epoch 58: Validation loss decreased (0.504070 --> 0.503689).  Saving model ...
	 Train_Loss: 0.5338 Train_Acc: 73.323 Val_Loss: 0.5037  BEST VAL Loss: 0.5037  Val_Acc: 76.846

Epoch 59: Validation loss decreased (0.503689 --> 0.503201).  Saving model ...
	 Train_Loss: 0.5334 Train_Acc: 73.362 Val_Loss: 0.5032  BEST VAL Loss: 0.5032  Val_Acc: 77.006

Epoch 60: Validation loss decreased (0.503201 --> 0.502876).  Saving model ...
	 Train_Loss: 0.5330 Train_Acc: 73.357 Val_Loss: 0.5029  BEST VAL Loss: 0.5029  Val_Acc: 76.842

Epoch 61: Validation loss decreased (0.502876 --> 0.502520).  Saving model ...
	 Train_Loss: 0.5326 Train_Acc: 73.601 Val_Loss: 0.5025  BEST VAL Loss: 0.5025  Val_Acc: 76.854

Epoch 62: Validation loss decreased (0.502520 --> 0.502075).  Saving model ...
	 Train_Loss: 0.5321 Train_Acc: 73.597 Val_Loss: 0.5021  BEST VAL Loss: 0.5021  Val_Acc: 76.989

Epoch 63: Validation loss decreased (0.502075 --> 0.501763).  Saving model ...
	 Train_Loss: 0.5317 Train_Acc: 73.476 Val_Loss: 0.5018  BEST VAL Loss: 0.5018  Val_Acc: 76.467

Epoch 64: Validation loss decreased (0.501763 --> 0.501477).  Saving model ...
	 Train_Loss: 0.5313 Train_Acc: 73.421 Val_Loss: 0.5015  BEST VAL Loss: 0.5015  Val_Acc: 77.031

Epoch 65: Validation loss decreased (0.501477 --> 0.501084).  Saving model ...
	 Train_Loss: 0.5310 Train_Acc: 73.446 Val_Loss: 0.5011  BEST VAL Loss: 0.5011  Val_Acc: 77.347

Epoch 66: Validation loss decreased (0.501084 --> 0.500706).  Saving model ...
	 Train_Loss: 0.5306 Train_Acc: 73.559 Val_Loss: 0.5007  BEST VAL Loss: 0.5007  Val_Acc: 76.901

Epoch 67: Validation loss decreased (0.500706 --> 0.500306).  Saving model ...
	 Train_Loss: 0.5302 Train_Acc: 73.386 Val_Loss: 0.5003  BEST VAL Loss: 0.5003  Val_Acc: 77.103

Epoch 68: Validation loss decreased (0.500306 --> 0.500072).  Saving model ...
	 Train_Loss: 0.5298 Train_Acc: 73.784 Val_Loss: 0.5001  BEST VAL Loss: 0.5001  Val_Acc: 77.040

Epoch 69: Validation loss decreased (0.500072 --> 0.499768).  Saving model ...
	 Train_Loss: 0.5294 Train_Acc: 73.538 Val_Loss: 0.4998  BEST VAL Loss: 0.4998  Val_Acc: 77.103

Epoch 70: Validation loss decreased (0.499768 --> 0.499353).  Saving model ...
	 Train_Loss: 0.5291 Train_Acc: 73.688 Val_Loss: 0.4994  BEST VAL Loss: 0.4994  Val_Acc: 77.099

Epoch 71: Validation loss decreased (0.499353 --> 0.499056).  Saving model ...
	 Train_Loss: 0.5287 Train_Acc: 73.664 Val_Loss: 0.4991  BEST VAL Loss: 0.4991  Val_Acc: 76.656

Epoch 72: Validation loss decreased (0.499056 --> 0.498784).  Saving model ...
	 Train_Loss: 0.5284 Train_Acc: 73.599 Val_Loss: 0.4988  BEST VAL Loss: 0.4988  Val_Acc: 77.006

Epoch 73: Validation loss decreased (0.498784 --> 0.498439).  Saving model ...
	 Train_Loss: 0.5280 Train_Acc: 73.772 Val_Loss: 0.4984  BEST VAL Loss: 0.4984  Val_Acc: 76.854

Epoch 74: Validation loss decreased (0.498439 --> 0.498215).  Saving model ...
	 Train_Loss: 0.5277 Train_Acc: 73.446 Val_Loss: 0.4982  BEST VAL Loss: 0.4982  Val_Acc: 76.560

Epoch 75: Validation loss decreased (0.498215 --> 0.498093).  Saving model ...
	 Train_Loss: 0.5274 Train_Acc: 73.582 Val_Loss: 0.4981  BEST VAL Loss: 0.4981  Val_Acc: 75.675

Epoch 76: Validation loss decreased (0.498093 --> 0.497856).  Saving model ...
	 Train_Loss: 0.5271 Train_Acc: 73.620 Val_Loss: 0.4979  BEST VAL Loss: 0.4979  Val_Acc: 76.901

Epoch 77: Validation loss decreased (0.497856 --> 0.497679).  Saving model ...
	 Train_Loss: 0.5267 Train_Acc: 73.848 Val_Loss: 0.4977  BEST VAL Loss: 0.4977  Val_Acc: 76.597

Epoch 78: Validation loss decreased (0.497679 --> 0.497506).  Saving model ...
	 Train_Loss: 0.5263 Train_Acc: 73.907 Val_Loss: 0.4975  BEST VAL Loss: 0.4975  Val_Acc: 75.852

Epoch 79: Validation loss decreased (0.497506 --> 0.497392).  Saving model ...
	 Train_Loss: 0.5260 Train_Acc: 73.727 Val_Loss: 0.4974  BEST VAL Loss: 0.4974  Val_Acc: 76.795

Epoch 80: Validation loss decreased (0.497392 --> 0.497087).  Saving model ...
	 Train_Loss: 0.5257 Train_Acc: 73.790 Val_Loss: 0.4971  BEST VAL Loss: 0.4971  Val_Acc: 77.394

Epoch 81: Validation loss decreased (0.497087 --> 0.496934).  Saving model ...
	 Train_Loss: 0.5254 Train_Acc: 73.659 Val_Loss: 0.4969  BEST VAL Loss: 0.4969  Val_Acc: 76.808

Epoch 82: Validation loss decreased (0.496934 --> 0.496708).  Saving model ...
	 Train_Loss: 0.5251 Train_Acc: 73.796 Val_Loss: 0.4967  BEST VAL Loss: 0.4967  Val_Acc: 76.926

Epoch 83: Validation loss decreased (0.496708 --> 0.496578).  Saving model ...
	 Train_Loss: 0.5248 Train_Acc: 73.815 Val_Loss: 0.4966  BEST VAL Loss: 0.4966  Val_Acc: 76.597

Epoch 84: Validation loss decreased (0.496578 --> 0.496308).  Saving model ...
	 Train_Loss: 0.5246 Train_Acc: 73.578 Val_Loss: 0.4963  BEST VAL Loss: 0.4963  Val_Acc: 77.280

Epoch 85: Validation loss decreased (0.496308 --> 0.496022).  Saving model ...
	 Train_Loss: 0.5242 Train_Acc: 73.929 Val_Loss: 0.4960  BEST VAL Loss: 0.4960  Val_Acc: 77.486

Epoch 86: Validation loss decreased (0.496022 --> 0.495783).  Saving model ...
	 Train_Loss: 0.5240 Train_Acc: 73.737 Val_Loss: 0.4958  BEST VAL Loss: 0.4958  Val_Acc: 77.520

Epoch 87: Validation loss decreased (0.495783 --> 0.495591).  Saving model ...
	 Train_Loss: 0.5237 Train_Acc: 73.590 Val_Loss: 0.4956  BEST VAL Loss: 0.4956  Val_Acc: 77.541

Epoch 88: Validation loss decreased (0.495591 --> 0.495340).  Saving model ...
	 Train_Loss: 0.5235 Train_Acc: 73.737 Val_Loss: 0.4953  BEST VAL Loss: 0.4953  Val_Acc: 76.585

Epoch 89: Validation loss decreased (0.495340 --> 0.495174).  Saving model ...
	 Train_Loss: 0.5232 Train_Acc: 73.944 Val_Loss: 0.4952  BEST VAL Loss: 0.4952  Val_Acc: 77.183

Epoch 90: Validation loss decreased (0.495174 --> 0.495038).  Saving model ...
	 Train_Loss: 0.5229 Train_Acc: 73.996 Val_Loss: 0.4950  BEST VAL Loss: 0.4950  Val_Acc: 76.640

Epoch 91: Validation loss decreased (0.495038 --> 0.494860).  Saving model ...
	 Train_Loss: 0.5227 Train_Acc: 73.872 Val_Loss: 0.4949  BEST VAL Loss: 0.4949  Val_Acc: 77.457

Epoch 92: Validation loss decreased (0.494860 --> 0.494666).  Saving model ...
	 Train_Loss: 0.5224 Train_Acc: 73.828 Val_Loss: 0.4947  BEST VAL Loss: 0.4947  Val_Acc: 77.537

Epoch 93: Validation loss decreased (0.494666 --> 0.494477).  Saving model ...
	 Train_Loss: 0.5222 Train_Acc: 73.868 Val_Loss: 0.4945  BEST VAL Loss: 0.4945  Val_Acc: 77.554

Epoch 94: Validation loss decreased (0.494477 --> 0.494222).  Saving model ...
	 Train_Loss: 0.5219 Train_Acc: 74.194 Val_Loss: 0.4942  BEST VAL Loss: 0.4942  Val_Acc: 77.587

Epoch 95: Validation loss decreased (0.494222 --> 0.493971).  Saving model ...
	 Train_Loss: 0.5216 Train_Acc: 73.777 Val_Loss: 0.4940  BEST VAL Loss: 0.4940  Val_Acc: 77.149

Epoch 96: Validation loss decreased (0.493971 --> 0.493942).  Saving model ...
	 Train_Loss: 0.5214 Train_Acc: 73.805 Val_Loss: 0.4939  BEST VAL Loss: 0.4939  Val_Acc: 76.576

Epoch 97: Validation loss decreased (0.493942 --> 0.493750).  Saving model ...
	 Train_Loss: 0.5212 Train_Acc: 73.911 Val_Loss: 0.4938  BEST VAL Loss: 0.4938  Val_Acc: 77.436

Epoch 98: Validation loss decreased (0.493750 --> 0.493528).  Saving model ...
	 Train_Loss: 0.5209 Train_Acc: 74.006 Val_Loss: 0.4935  BEST VAL Loss: 0.4935  Val_Acc: 77.267

Epoch 99: Validation loss decreased (0.493528 --> 0.493436).  Saving model ...
	 Train_Loss: 0.5207 Train_Acc: 73.915 Val_Loss: 0.4934  BEST VAL Loss: 0.4934  Val_Acc: 77.516

LPS_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.75      0.87      0.80     92173
           1       0.85      0.73      0.79     97754

    accuracy                           0.80    189927
   macro avg       0.80      0.80      0.80    189927
weighted avg       0.80      0.80      0.80    189927

LPS_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.73      0.84      0.78     11522
           1       0.83      0.71      0.77     12219

    accuracy                           0.78     23741
   macro avg       0.78      0.78      0.77     23741
weighted avg       0.78      0.78      0.77     23741

LPS_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.74      0.84      0.79     11522
           1       0.83      0.72      0.77     12219

    accuracy                           0.78     23741
   macro avg       0.78      0.78      0.78     23741
weighted avg       0.78      0.78      0.78     23741

              precision    recall  f1-score   support

           0       0.74      0.84      0.79     11522
           1       0.83      0.72      0.77     12219

    accuracy                           0.78     23741
   macro avg       0.78      0.78      0.78     23741
weighted avg       0.78      0.78      0.78     23741

LPS_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.64      0.58      0.61     41273
           1       0.58      0.64      0.61     37243

    accuracy                           0.61     78516
   macro avg       0.61      0.61      0.61     78516
weighted avg       0.61      0.61      0.61     78516

              precision    recall  f1-score   support

           0       0.64      0.58      0.61     41273
           1       0.58      0.64      0.61     37243

    accuracy                           0.61     78516
   macro avg       0.61      0.61      0.61     78516
weighted avg       0.61      0.61      0.61     78516

completed
