[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '7ba1c120'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '0c49e125'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '17411ec2'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '51fcf098'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_0.100_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_0.100_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (33497, 1276)
Number of total missing values across all columns: 66994
Data Subset Is Off
Wells held out for testing: ['C20' 'J16']
Wells to use for training, validation, and testing ['C16' 'C17' 'C21' 'J17' 'J20' 'J21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.465817).  Saving model ...
	 Train_Loss: 0.5975 Train_Acc: 65.058 Val_Loss: 0.4658  BEST VAL Loss: 0.4658  Val_Acc: 79.559

Epoch 1: Validation loss decreased (0.465817 --> 0.421124).  Saving model ...
	 Train_Loss: 0.5403 Train_Acc: 75.795 Val_Loss: 0.4211  BEST VAL Loss: 0.4211  Val_Acc: 84.930

Epoch 2: Validation loss decreased (0.421124 --> 0.392874).  Saving model ...
	 Train_Loss: 0.5000 Train_Acc: 80.285 Val_Loss: 0.3929  BEST VAL Loss: 0.3929  Val_Acc: 86.453

Epoch 3: Validation loss decreased (0.392874 --> 0.372093).  Saving model ...
	 Train_Loss: 0.4681 Train_Acc: 84.578 Val_Loss: 0.3721  BEST VAL Loss: 0.3721  Val_Acc: 89.058

Epoch 4: Validation loss decreased (0.372093 --> 0.357016).  Saving model ...
	 Train_Loss: 0.4430 Train_Acc: 87.299 Val_Loss: 0.3570  BEST VAL Loss: 0.3570  Val_Acc: 89.138

Epoch 5: Validation loss decreased (0.357016 --> 0.344976).  Saving model ...
	 Train_Loss: 0.4243 Train_Acc: 88.051 Val_Loss: 0.3450  BEST VAL Loss: 0.3450  Val_Acc: 90.341

Epoch 6: Validation loss decreased (0.344976 --> 0.333890).  Saving model ...
	 Train_Loss: 0.4087 Train_Acc: 88.501 Val_Loss: 0.3339  BEST VAL Loss: 0.3339  Val_Acc: 90.661

Epoch 7: Validation loss decreased (0.333890 --> 0.325033).  Saving model ...
	 Train_Loss: 0.3960 Train_Acc: 88.296 Val_Loss: 0.3250  BEST VAL Loss: 0.3250  Val_Acc: 90.661

Epoch 8: Validation loss decreased (0.325033 --> 0.315784).  Saving model ...
	 Train_Loss: 0.3855 Train_Acc: 88.652 Val_Loss: 0.3158  BEST VAL Loss: 0.3158  Val_Acc: 92.425

Epoch 9: Validation loss decreased (0.315784 --> 0.308304).  Saving model ...
	 Train_Loss: 0.3767 Train_Acc: 88.832 Val_Loss: 0.3083  BEST VAL Loss: 0.3083  Val_Acc: 92.385

Epoch 10: Validation loss decreased (0.308304 --> 0.301713).  Saving model ...
	 Train_Loss: 0.3689 Train_Acc: 89.273 Val_Loss: 0.3017  BEST VAL Loss: 0.3017  Val_Acc: 91.984

Epoch 11: Validation loss decreased (0.301713 --> 0.296459).  Saving model ...
	 Train_Loss: 0.3620 Train_Acc: 89.363 Val_Loss: 0.2965  BEST VAL Loss: 0.2965  Val_Acc: 91.984

Epoch 12: Validation loss decreased (0.296459 --> 0.290663).  Saving model ...
	 Train_Loss: 0.3555 Train_Acc: 89.884 Val_Loss: 0.2907  BEST VAL Loss: 0.2907  Val_Acc: 92.745

Epoch 13: Validation loss decreased (0.290663 --> 0.284915).  Saving model ...
	 Train_Loss: 0.3497 Train_Acc: 89.859 Val_Loss: 0.2849  BEST VAL Loss: 0.2849  Val_Acc: 93.106

Epoch 14: Validation loss decreased (0.284915 --> 0.281534).  Saving model ...
	 Train_Loss: 0.3450 Train_Acc: 89.874 Val_Loss: 0.2815  BEST VAL Loss: 0.2815  Val_Acc: 92.144

Epoch 15: Validation loss decreased (0.281534 --> 0.278536).  Saving model ...
	 Train_Loss: 0.3410 Train_Acc: 89.799 Val_Loss: 0.2785  BEST VAL Loss: 0.2785  Val_Acc: 92.104

Epoch 16: Validation loss decreased (0.278536 --> 0.274974).  Saving model ...
	 Train_Loss: 0.3372 Train_Acc: 90.025 Val_Loss: 0.2750  BEST VAL Loss: 0.2750  Val_Acc: 93.106

Epoch 17: Validation loss decreased (0.274974 --> 0.271829).  Saving model ...
	 Train_Loss: 0.3334 Train_Acc: 90.355 Val_Loss: 0.2718  BEST VAL Loss: 0.2718  Val_Acc: 93.146

Epoch 18: Validation loss decreased (0.271829 --> 0.268867).  Saving model ...
	 Train_Loss: 0.3298 Train_Acc: 90.350 Val_Loss: 0.2689  BEST VAL Loss: 0.2689  Val_Acc: 92.745

Epoch 19: Validation loss decreased (0.268867 --> 0.265883).  Saving model ...
	 Train_Loss: 0.3265 Train_Acc: 90.501 Val_Loss: 0.2659  BEST VAL Loss: 0.2659  Val_Acc: 93.307

Epoch 20: Validation loss decreased (0.265883 --> 0.263396).  Saving model ...
	 Train_Loss: 0.3237 Train_Acc: 90.420 Val_Loss: 0.2634  BEST VAL Loss: 0.2634  Val_Acc: 93.627

Epoch 21: Validation loss decreased (0.263396 --> 0.260911).  Saving model ...
	 Train_Loss: 0.3209 Train_Acc: 90.706 Val_Loss: 0.2609  BEST VAL Loss: 0.2609  Val_Acc: 93.467

Epoch 22: Validation loss decreased (0.260911 --> 0.258920).  Saving model ...
	 Train_Loss: 0.3184 Train_Acc: 90.641 Val_Loss: 0.2589  BEST VAL Loss: 0.2589  Val_Acc: 93.026

Epoch 23: Validation loss decreased (0.258920 --> 0.257074).  Saving model ...
	 Train_Loss: 0.3161 Train_Acc: 90.781 Val_Loss: 0.2571  BEST VAL Loss: 0.2571  Val_Acc: 93.226

Epoch 24: Validation loss decreased (0.257074 --> 0.254840).  Saving model ...
	 Train_Loss: 0.3138 Train_Acc: 90.761 Val_Loss: 0.2548  BEST VAL Loss: 0.2548  Val_Acc: 93.948

Epoch 25: Validation loss decreased (0.254840 --> 0.253364).  Saving model ...
	 Train_Loss: 0.3114 Train_Acc: 90.926 Val_Loss: 0.2534  BEST VAL Loss: 0.2534  Val_Acc: 93.747

Epoch 26: Validation loss decreased (0.253364 --> 0.251855).  Saving model ...
	 Train_Loss: 0.3093 Train_Acc: 90.966 Val_Loss: 0.2519  BEST VAL Loss: 0.2519  Val_Acc: 93.547

Epoch 27: Validation loss decreased (0.251855 --> 0.250926).  Saving model ...
	 Train_Loss: 0.3075 Train_Acc: 90.876 Val_Loss: 0.2509  BEST VAL Loss: 0.2509  Val_Acc: 92.745

Epoch 28: Validation loss decreased (0.250926 --> 0.249294).  Saving model ...
	 Train_Loss: 0.3058 Train_Acc: 90.696 Val_Loss: 0.2493  BEST VAL Loss: 0.2493  Val_Acc: 93.587

Epoch 29: Validation loss decreased (0.249294 --> 0.247959).  Saving model ...
	 Train_Loss: 0.3039 Train_Acc: 91.132 Val_Loss: 0.2480  BEST VAL Loss: 0.2480  Val_Acc: 93.707

Epoch 30: Validation loss decreased (0.247959 --> 0.246971).  Saving model ...
	 Train_Loss: 0.3020 Train_Acc: 91.563 Val_Loss: 0.2470  BEST VAL Loss: 0.2470  Val_Acc: 93.146

Epoch 31: Validation loss decreased (0.246971 --> 0.245909).  Saving model ...
	 Train_Loss: 0.3002 Train_Acc: 91.312 Val_Loss: 0.2459  BEST VAL Loss: 0.2459  Val_Acc: 93.667

Epoch 32: Validation loss decreased (0.245909 --> 0.244821).  Saving model ...
	 Train_Loss: 0.2984 Train_Acc: 91.513 Val_Loss: 0.2448  BEST VAL Loss: 0.2448  Val_Acc: 93.747

Epoch 33: Validation loss decreased (0.244821 --> 0.244032).  Saving model ...
	 Train_Loss: 0.2971 Train_Acc: 91.077 Val_Loss: 0.2440  BEST VAL Loss: 0.2440  Val_Acc: 93.186

Epoch 34: Validation loss decreased (0.244032 --> 0.243020).  Saving model ...
	 Train_Loss: 0.2956 Train_Acc: 91.372 Val_Loss: 0.2430  BEST VAL Loss: 0.2430  Val_Acc: 92.946

Epoch 35: Validation loss decreased (0.243020 --> 0.241765).  Saving model ...
	 Train_Loss: 0.2944 Train_Acc: 91.222 Val_Loss: 0.2418  BEST VAL Loss: 0.2418  Val_Acc: 93.868

Epoch 36: Validation loss decreased (0.241765 --> 0.241010).  Saving model ...
	 Train_Loss: 0.2930 Train_Acc: 91.473 Val_Loss: 0.2410  BEST VAL Loss: 0.2410  Val_Acc: 93.347

Epoch 37: Validation loss decreased (0.241010 --> 0.239883).  Saving model ...
	 Train_Loss: 0.2919 Train_Acc: 91.117 Val_Loss: 0.2399  BEST VAL Loss: 0.2399  Val_Acc: 93.467

Epoch 38: Validation loss decreased (0.239883 --> 0.238853).  Saving model ...
	 Train_Loss: 0.2904 Train_Acc: 91.858 Val_Loss: 0.2389  BEST VAL Loss: 0.2389  Val_Acc: 93.667

Epoch 39: Validation loss decreased (0.238853 --> 0.237896).  Saving model ...
	 Train_Loss: 0.2890 Train_Acc: 92.009 Val_Loss: 0.2379  BEST VAL Loss: 0.2379  Val_Acc: 93.988

Epoch 40: Validation loss decreased (0.237896 --> 0.236990).  Saving model ...
	 Train_Loss: 0.2878 Train_Acc: 91.848 Val_Loss: 0.2370  BEST VAL Loss: 0.2370  Val_Acc: 94.108

Epoch 41: Validation loss decreased (0.236990 --> 0.236086).  Saving model ...
	 Train_Loss: 0.2867 Train_Acc: 91.447 Val_Loss: 0.2361  BEST VAL Loss: 0.2361  Val_Acc: 93.587

Epoch 42: Validation loss decreased (0.236086 --> 0.235365).  Saving model ...
	 Train_Loss: 0.2854 Train_Acc: 91.979 Val_Loss: 0.2354  BEST VAL Loss: 0.2354  Val_Acc: 93.828

Epoch 43: Validation loss decreased (0.235365 --> 0.234922).  Saving model ...
	 Train_Loss: 0.2840 Train_Acc: 92.259 Val_Loss: 0.2349  BEST VAL Loss: 0.2349  Val_Acc: 93.828

Epoch 44: Validation loss decreased (0.234922 --> 0.233996).  Saving model ...
	 Train_Loss: 0.2829 Train_Acc: 92.064 Val_Loss: 0.2340  BEST VAL Loss: 0.2340  Val_Acc: 93.988

Epoch 45: Validation loss decreased (0.233996 --> 0.232955).  Saving model ...
	 Train_Loss: 0.2816 Train_Acc: 92.159 Val_Loss: 0.2330  BEST VAL Loss: 0.2330  Val_Acc: 94.910

Epoch 46: Validation loss decreased (0.232955 --> 0.232113).  Saving model ...
	 Train_Loss: 0.2802 Train_Acc: 92.705 Val_Loss: 0.2321  BEST VAL Loss: 0.2321  Val_Acc: 94.389

Epoch 47: Validation loss decreased (0.232113 --> 0.231599).  Saving model ...
	 Train_Loss: 0.2790 Train_Acc: 92.495 Val_Loss: 0.2316  BEST VAL Loss: 0.2316  Val_Acc: 93.868

Epoch 48: Validation loss decreased (0.231599 --> 0.230882).  Saving model ...
	 Train_Loss: 0.2778 Train_Acc: 92.249 Val_Loss: 0.2309  BEST VAL Loss: 0.2309  Val_Acc: 93.908

Epoch 49: Validation loss decreased (0.230882 --> 0.230461).  Saving model ...
	 Train_Loss: 0.2767 Train_Acc: 92.389 Val_Loss: 0.2305  BEST VAL Loss: 0.2305  Val_Acc: 93.667

Epoch 50: Validation loss decreased (0.230461 --> 0.229868).  Saving model ...
	 Train_Loss: 0.2757 Train_Acc: 92.259 Val_Loss: 0.2299  BEST VAL Loss: 0.2299  Val_Acc: 93.788

Epoch 51: Validation loss decreased (0.229868 --> 0.229353).  Saving model ...
	 Train_Loss: 0.2748 Train_Acc: 92.169 Val_Loss: 0.2294  BEST VAL Loss: 0.2294  Val_Acc: 94.389

Epoch 52: Validation loss decreased (0.229353 --> 0.228653).  Saving model ...
	 Train_Loss: 0.2739 Train_Acc: 92.159 Val_Loss: 0.2287  BEST VAL Loss: 0.2287  Val_Acc: 94.349

Epoch 53: Validation loss decreased (0.228653 --> 0.227770).  Saving model ...
	 Train_Loss: 0.2728 Train_Acc: 92.505 Val_Loss: 0.2278  BEST VAL Loss: 0.2278  Val_Acc: 94.790

Epoch 54: Validation loss decreased (0.227770 --> 0.227104).  Saving model ...
	 Train_Loss: 0.2719 Train_Acc: 92.530 Val_Loss: 0.2271  BEST VAL Loss: 0.2271  Val_Acc: 94.469

Epoch 55: Validation loss decreased (0.227104 --> 0.226373).  Saving model ...
	 Train_Loss: 0.2709 Train_Acc: 92.339 Val_Loss: 0.2264  BEST VAL Loss: 0.2264  Val_Acc: 94.790

Epoch 56: Validation loss decreased (0.226373 --> 0.226257).  Saving model ...
	 Train_Loss: 0.2699 Train_Acc: 92.810 Val_Loss: 0.2263  BEST VAL Loss: 0.2263  Val_Acc: 94.669

Epoch 57: Validation loss decreased (0.226257 --> 0.225781).  Saving model ...
	 Train_Loss: 0.2693 Train_Acc: 92.064 Val_Loss: 0.2258  BEST VAL Loss: 0.2258  Val_Acc: 93.948

Epoch 58: Validation loss decreased (0.225781 --> 0.225196).  Saving model ...
	 Train_Loss: 0.2686 Train_Acc: 91.773 Val_Loss: 0.2252  BEST VAL Loss: 0.2252  Val_Acc: 93.427

Epoch 59: Validation loss decreased (0.225196 --> 0.224759).  Saving model ...
	 Train_Loss: 0.2681 Train_Acc: 91.798 Val_Loss: 0.2248  BEST VAL Loss: 0.2248  Val_Acc: 93.747

Epoch 60: Validation loss decreased (0.224759 --> 0.224177).  Saving model ...
	 Train_Loss: 0.2674 Train_Acc: 92.269 Val_Loss: 0.2242  BEST VAL Loss: 0.2242  Val_Acc: 94.309

Epoch 61: Validation loss decreased (0.224177 --> 0.223700).  Saving model ...
	 Train_Loss: 0.2667 Train_Acc: 92.289 Val_Loss: 0.2237  BEST VAL Loss: 0.2237  Val_Acc: 94.188

Epoch 62: Validation loss decreased (0.223700 --> 0.223223).  Saving model ...
	 Train_Loss: 0.2659 Train_Acc: 92.620 Val_Loss: 0.2232  BEST VAL Loss: 0.2232  Val_Acc: 94.188

Epoch 63: Validation loss decreased (0.223223 --> 0.222634).  Saving model ...
	 Train_Loss: 0.2650 Train_Acc: 92.785 Val_Loss: 0.2226  BEST VAL Loss: 0.2226  Val_Acc: 94.349

Epoch 64: Validation loss decreased (0.222634 --> 0.222288).  Saving model ...
	 Train_Loss: 0.2643 Train_Acc: 92.670 Val_Loss: 0.2223  BEST VAL Loss: 0.2223  Val_Acc: 94.228

Epoch 65: Validation loss decreased (0.222288 --> 0.221784).  Saving model ...
	 Train_Loss: 0.2636 Train_Acc: 92.700 Val_Loss: 0.2218  BEST VAL Loss: 0.2218  Val_Acc: 94.589

Epoch 66: Validation loss decreased (0.221784 --> 0.221424).  Saving model ...
	 Train_Loss: 0.2629 Train_Acc: 92.560 Val_Loss: 0.2214  BEST VAL Loss: 0.2214  Val_Acc: 93.667

Epoch 67: Validation loss decreased (0.221424 --> 0.220819).  Saving model ...
	 Train_Loss: 0.2622 Train_Acc: 92.800 Val_Loss: 0.2208  BEST VAL Loss: 0.2208  Val_Acc: 94.429

Epoch 68: Validation loss decreased (0.220819 --> 0.220109).  Saving model ...
	 Train_Loss: 0.2613 Train_Acc: 93.031 Val_Loss: 0.2201  BEST VAL Loss: 0.2201  Val_Acc: 94.990

Epoch 69: Validation loss decreased (0.220109 --> 0.219763).  Saving model ...
	 Train_Loss: 0.2605 Train_Acc: 93.181 Val_Loss: 0.2198  BEST VAL Loss: 0.2198  Val_Acc: 94.269

Epoch 70: Validation loss decreased (0.219763 --> 0.219466).  Saving model ...
	 Train_Loss: 0.2599 Train_Acc: 92.715 Val_Loss: 0.2195  BEST VAL Loss: 0.2195  Val_Acc: 94.188

Epoch 71: Validation loss decreased (0.219466 --> 0.219087).  Saving model ...
	 Train_Loss: 0.2592 Train_Acc: 92.870 Val_Loss: 0.2191  BEST VAL Loss: 0.2191  Val_Acc: 94.349

Epoch 72: Validation loss decreased (0.219087 --> 0.218803).  Saving model ...
	 Train_Loss: 0.2586 Train_Acc: 92.690 Val_Loss: 0.2188  BEST VAL Loss: 0.2188  Val_Acc: 94.549

Epoch 73: Validation loss decreased (0.218803 --> 0.218340).  Saving model ...
	 Train_Loss: 0.2582 Train_Acc: 92.384 Val_Loss: 0.2183  BEST VAL Loss: 0.2183  Val_Acc: 93.908

Epoch 74: Validation loss decreased (0.218340 --> 0.217854).  Saving model ...
	 Train_Loss: 0.2577 Train_Acc: 92.520 Val_Loss: 0.2179  BEST VAL Loss: 0.2179  Val_Acc: 94.429

Epoch 75: Validation loss decreased (0.217854 --> 0.217638).  Saving model ...
	 Train_Loss: 0.2571 Train_Acc: 92.605 Val_Loss: 0.2176  BEST VAL Loss: 0.2176  Val_Acc: 94.068

Epoch 76: Validation loss decreased (0.217638 --> 0.217327).  Saving model ...
	 Train_Loss: 0.2565 Train_Acc: 92.840 Val_Loss: 0.2173  BEST VAL Loss: 0.2173  Val_Acc: 94.389

Epoch 77: Validation loss decreased (0.217327 --> 0.216790).  Saving model ...
	 Train_Loss: 0.2560 Train_Acc: 92.655 Val_Loss: 0.2168  BEST VAL Loss: 0.2168  Val_Acc: 94.669

Epoch 78: Validation loss decreased (0.216790 --> 0.216531).  Saving model ...
	 Train_Loss: 0.2554 Train_Acc: 92.910 Val_Loss: 0.2165  BEST VAL Loss: 0.2165  Val_Acc: 94.148

Epoch 79: Validation loss decreased (0.216531 --> 0.216189).  Saving model ...
	 Train_Loss: 0.2549 Train_Acc: 92.830 Val_Loss: 0.2162  BEST VAL Loss: 0.2162  Val_Acc: 93.948

Epoch 80: Validation loss decreased (0.216189 --> 0.215728).  Saving model ...
	 Train_Loss: 0.2543 Train_Acc: 92.931 Val_Loss: 0.2157  BEST VAL Loss: 0.2157  Val_Acc: 94.108

Epoch 81: Validation loss decreased (0.215728 --> 0.215261).  Saving model ...
	 Train_Loss: 0.2537 Train_Acc: 92.946 Val_Loss: 0.2153  BEST VAL Loss: 0.2153  Val_Acc: 94.429

Epoch 82: Validation loss decreased (0.215261 --> 0.214989).  Saving model ...
	 Train_Loss: 0.2532 Train_Acc: 92.936 Val_Loss: 0.2150  BEST VAL Loss: 0.2150  Val_Acc: 94.549

Epoch 83: Validation loss decreased (0.214989 --> 0.214667).  Saving model ...
	 Train_Loss: 0.2528 Train_Acc: 92.445 Val_Loss: 0.2147  BEST VAL Loss: 0.2147  Val_Acc: 94.509

Epoch 84: Validation loss decreased (0.214667 --> 0.214402).  Saving model ...
	 Train_Loss: 0.2523 Train_Acc: 93.066 Val_Loss: 0.2144  BEST VAL Loss: 0.2144  Val_Acc: 94.509

Epoch 85: Validation loss decreased (0.214402 --> 0.214089).  Saving model ...
	 Train_Loss: 0.2517 Train_Acc: 93.101 Val_Loss: 0.2141  BEST VAL Loss: 0.2141  Val_Acc: 94.509

Epoch 86: Validation loss decreased (0.214089 --> 0.213685).  Saving model ...
	 Train_Loss: 0.2512 Train_Acc: 93.046 Val_Loss: 0.2137  BEST VAL Loss: 0.2137  Val_Acc: 94.790

Epoch 87: Validation loss decreased (0.213685 --> 0.213293).  Saving model ...
	 Train_Loss: 0.2507 Train_Acc: 93.256 Val_Loss: 0.2133  BEST VAL Loss: 0.2133  Val_Acc: 94.669

Epoch 88: Validation loss decreased (0.213293 --> 0.212750).  Saving model ...
	 Train_Loss: 0.2502 Train_Acc: 92.780 Val_Loss: 0.2128  BEST VAL Loss: 0.2128  Val_Acc: 94.830

Epoch 89: Validation loss decreased (0.212750 --> 0.212295).  Saving model ...
	 Train_Loss: 0.2498 Train_Acc: 92.850 Val_Loss: 0.2123  BEST VAL Loss: 0.2123  Val_Acc: 94.669

Epoch 90: Validation loss decreased (0.212295 --> 0.211991).  Saving model ...
	 Train_Loss: 0.2494 Train_Acc: 92.650 Val_Loss: 0.2120  BEST VAL Loss: 0.2120  Val_Acc: 94.709

Epoch 91: Validation loss decreased (0.211991 --> 0.211681).  Saving model ...
	 Train_Loss: 0.2490 Train_Acc: 92.665 Val_Loss: 0.2117  BEST VAL Loss: 0.2117  Val_Acc: 94.509

Epoch 92: Validation loss decreased (0.211681 --> 0.211392).  Saving model ...
	 Train_Loss: 0.2486 Train_Acc: 93.021 Val_Loss: 0.2114  BEST VAL Loss: 0.2114  Val_Acc: 94.509

Epoch 93: Validation loss decreased (0.211392 --> 0.211368).  Saving model ...
	 Train_Loss: 0.2481 Train_Acc: 93.356 Val_Loss: 0.2114  BEST VAL Loss: 0.2114  Val_Acc: 93.788

Epoch 94: Validation loss decreased (0.211368 --> 0.211062).  Saving model ...
	 Train_Loss: 0.2477 Train_Acc: 92.710 Val_Loss: 0.2111  BEST VAL Loss: 0.2111  Val_Acc: 94.549

Epoch 95: Validation loss decreased (0.211062 --> 0.210605).  Saving model ...
	 Train_Loss: 0.2472 Train_Acc: 93.336 Val_Loss: 0.2106  BEST VAL Loss: 0.2106  Val_Acc: 95.190

Epoch 96: Validation loss decreased (0.210605 --> 0.210395).  Saving model ...
	 Train_Loss: 0.2467 Train_Acc: 93.321 Val_Loss: 0.2104  BEST VAL Loss: 0.2104  Val_Acc: 94.068

Epoch 97: Validation loss decreased (0.210395 --> 0.210087).  Saving model ...
	 Train_Loss: 0.2462 Train_Acc: 93.176 Val_Loss: 0.2101  BEST VAL Loss: 0.2101  Val_Acc: 94.870

Epoch 98: Validation loss decreased (0.210087 --> 0.209755).  Saving model ...
	 Train_Loss: 0.2457 Train_Acc: 93.341 Val_Loss: 0.2098  BEST VAL Loss: 0.2098  Val_Acc: 94.669

Epoch 99: Validation loss decreased (0.209755 --> 0.209467).  Saving model ...
	 Train_Loss: 0.2454 Train_Acc: 92.840 Val_Loss: 0.2095  BEST VAL Loss: 0.2095  Val_Acc: 94.509

LPS_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.51      0.51     10451
           1       0.47      0.48      0.48      9508

    accuracy                           0.50     19959
   macro avg       0.50      0.50      0.50     19959
weighted avg       0.50      0.50      0.50     19959

LPS_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.53      0.54      1307
           1       0.50      0.51      0.51      1188

    accuracy                           0.52      2495
   macro avg       0.52      0.52      0.52      2495
weighted avg       0.52      0.52      0.52      2495

LPS_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.52      0.53      1307
           1       0.48      0.49      0.49      1188

    accuracy                           0.51      2495
   macro avg       0.51      0.51      0.51      2495
weighted avg       0.51      0.51      0.51      2495

              precision    recall  f1-score   support

           0       0.53      0.52      0.53      1307
           1       0.48      0.49      0.49      1188

    accuracy                           0.51      2495
   macro avg       0.51      0.51      0.51      2495
weighted avg       0.51      0.51      0.51      2495

LPS_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.37      0.43      4445
           1       0.48      0.62      0.54      4103

    accuracy                           0.49      8548
   macro avg       0.49      0.50      0.48      8548
weighted avg       0.50      0.49      0.48      8548

              precision    recall  f1-score   support

           0       0.51      0.37      0.43      4445
           1       0.48      0.62      0.54      4103

    accuracy                           0.49      8548
   macro avg       0.49      0.50      0.48      8548
weighted avg       0.50      0.49      0.48      8548

completed
