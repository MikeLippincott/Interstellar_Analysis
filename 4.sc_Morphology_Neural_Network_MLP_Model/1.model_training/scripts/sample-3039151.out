[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '07f6b69f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'd46d8923'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '8a2bb8e6'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'd6055ae2'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Thapsigargin_1.000_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Thapsigargin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'LPS_0.010_DMSO_0.025']
The dimensions of the data are: (29625, 1276)
Number of total missing values across all columns: 59250
Data Subset Is Off
Wells held out for testing: ['D14' 'B20']
Wells to use for training, validation, and testing ['D15' 'B16' 'B17' 'B21' 'K14' 'K15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.611646).  Saving model ...
	 Train_Loss: 0.6506 Train_Acc: 63.541 Val_Loss: 0.6116  BEST VAL Loss: 0.6116  Val_Acc: 71.858

Epoch 1: Validation loss decreased (0.611646 --> 0.574758).  Saving model ...
	 Train_Loss: 0.6151 Train_Acc: 73.902 Val_Loss: 0.5748  BEST VAL Loss: 0.5748  Val_Acc: 75.044

Epoch 2: Validation loss decreased (0.574758 --> 0.546041).  Saving model ...
	 Train_Loss: 0.5815 Train_Acc: 76.712 Val_Loss: 0.5460  BEST VAL Loss: 0.5460  Val_Acc: 79.027

Epoch 3: Validation loss decreased (0.546041 --> 0.519976).  Saving model ...
	 Train_Loss: 0.5530 Train_Acc: 78.792 Val_Loss: 0.5200  BEST VAL Loss: 0.5200  Val_Acc: 80.841

Epoch 4: Validation loss decreased (0.519976 --> 0.500878).  Saving model ...
	 Train_Loss: 0.5294 Train_Acc: 79.428 Val_Loss: 0.5009  BEST VAL Loss: 0.5009  Val_Acc: 80.929

Epoch 5: Validation loss decreased (0.500878 --> 0.483797).  Saving model ...
	 Train_Loss: 0.5109 Train_Acc: 78.543 Val_Loss: 0.4838  BEST VAL Loss: 0.4838  Val_Acc: 82.478

Epoch 6: Validation loss decreased (0.483797 --> 0.469766).  Saving model ...
	 Train_Loss: 0.4949 Train_Acc: 79.854 Val_Loss: 0.4698  BEST VAL Loss: 0.4698  Val_Acc: 83.230

Epoch 7: Validation loss decreased (0.469766 --> 0.458046).  Saving model ...
	 Train_Loss: 0.4815 Train_Acc: 80.695 Val_Loss: 0.4580  BEST VAL Loss: 0.4580  Val_Acc: 83.451

Epoch 8: Validation loss decreased (0.458046 --> 0.450357).  Saving model ...
	 Train_Loss: 0.4694 Train_Acc: 81.176 Val_Loss: 0.4504  BEST VAL Loss: 0.4504  Val_Acc: 81.726

Epoch 9: Validation loss decreased (0.450357 --> 0.440984).  Saving model ...
	 Train_Loss: 0.4586 Train_Acc: 81.231 Val_Loss: 0.4410  BEST VAL Loss: 0.4410  Val_Acc: 84.513

Epoch 10: Validation loss decreased (0.440984 --> 0.431765).  Saving model ...
	 Train_Loss: 0.4490 Train_Acc: 81.790 Val_Loss: 0.4318  BEST VAL Loss: 0.4318  Val_Acc: 85.442

Epoch 11: Validation loss decreased (0.431765 --> 0.423859).  Saving model ...
	 Train_Loss: 0.4403 Train_Acc: 82.398 Val_Loss: 0.4239  BEST VAL Loss: 0.4239  Val_Acc: 85.796

Epoch 12: Validation loss decreased (0.423859 --> 0.416007).  Saving model ...
	 Train_Loss: 0.4321 Train_Acc: 82.393 Val_Loss: 0.4160  BEST VAL Loss: 0.4160  Val_Acc: 85.796

Epoch 13: Validation loss decreased (0.416007 --> 0.409976).  Saving model ...
	 Train_Loss: 0.4251 Train_Acc: 82.758 Val_Loss: 0.4100  BEST VAL Loss: 0.4100  Val_Acc: 84.646

Epoch 14: Validation loss decreased (0.409976 --> 0.404240).  Saving model ...
	 Train_Loss: 0.4182 Train_Acc: 83.201 Val_Loss: 0.4042  BEST VAL Loss: 0.4042  Val_Acc: 86.283

Epoch 15: Validation loss decreased (0.404240 --> 0.398741).  Saving model ...
	 Train_Loss: 0.4118 Train_Acc: 83.776 Val_Loss: 0.3987  BEST VAL Loss: 0.3987  Val_Acc: 86.770

Epoch 16: Validation loss decreased (0.398741 --> 0.394189).  Saving model ...
	 Train_Loss: 0.4058 Train_Acc: 84.025 Val_Loss: 0.3942  BEST VAL Loss: 0.3942  Val_Acc: 86.504

Epoch 17: Validation loss decreased (0.394189 --> 0.389124).  Saving model ...
	 Train_Loss: 0.4005 Train_Acc: 85.551 Val_Loss: 0.3891  BEST VAL Loss: 0.3891  Val_Acc: 86.991

Epoch 18: Validation loss decreased (0.389124 --> 0.385102).  Saving model ...
	 Train_Loss: 0.3951 Train_Acc: 86.558 Val_Loss: 0.3851  BEST VAL Loss: 0.3851  Val_Acc: 86.814

Epoch 19: Validation loss decreased (0.385102 --> 0.381036).  Saving model ...
	 Train_Loss: 0.3904 Train_Acc: 86.746 Val_Loss: 0.3810  BEST VAL Loss: 0.3810  Val_Acc: 86.947

Epoch 20: Validation loss decreased (0.381036 --> 0.378164).  Saving model ...
	 Train_Loss: 0.3858 Train_Acc: 87.228 Val_Loss: 0.3782  BEST VAL Loss: 0.3782  Val_Acc: 86.903

Epoch 21: Validation loss decreased (0.378164 --> 0.374148).  Saving model ...
	 Train_Loss: 0.3812 Train_Acc: 87.344 Val_Loss: 0.3741  BEST VAL Loss: 0.3741  Val_Acc: 87.478

Epoch 22: Validation loss decreased (0.374148 --> 0.370851).  Saving model ...
	 Train_Loss: 0.3768 Train_Acc: 87.642 Val_Loss: 0.3709  BEST VAL Loss: 0.3709  Val_Acc: 87.257

Epoch 23: Validation loss decreased (0.370851 --> 0.367670).  Saving model ...
	 Train_Loss: 0.3727 Train_Acc: 87.947 Val_Loss: 0.3677  BEST VAL Loss: 0.3677  Val_Acc: 87.832

Epoch 24: Validation loss decreased (0.367670 --> 0.364478).  Saving model ...
	 Train_Loss: 0.3689 Train_Acc: 87.875 Val_Loss: 0.3645  BEST VAL Loss: 0.3645  Val_Acc: 87.345

Epoch 25: Validation loss decreased (0.364478 --> 0.361043).  Saving model ...
	 Train_Loss: 0.3651 Train_Acc: 88.223 Val_Loss: 0.3610  BEST VAL Loss: 0.3610  Val_Acc: 88.097

Epoch 26: Validation loss decreased (0.361043 --> 0.358531).  Saving model ...
	 Train_Loss: 0.3618 Train_Acc: 88.345 Val_Loss: 0.3585  BEST VAL Loss: 0.3585  Val_Acc: 87.743

Epoch 27: Validation loss decreased (0.358531 --> 0.356273).  Saving model ...
	 Train_Loss: 0.3583 Train_Acc: 88.688 Val_Loss: 0.3563  BEST VAL Loss: 0.3563  Val_Acc: 87.566

Epoch 28: Validation loss decreased (0.356273 --> 0.354213).  Saving model ...
	 Train_Loss: 0.3551 Train_Acc: 88.461 Val_Loss: 0.3542  BEST VAL Loss: 0.3542  Val_Acc: 87.212

Epoch 29: Validation loss decreased (0.354213 --> 0.353670).  Saving model ...
	 Train_Loss: 0.3520 Train_Acc: 88.776 Val_Loss: 0.3537  BEST VAL Loss: 0.3537  Val_Acc: 84.823

Epoch 30: Validation loss decreased (0.353670 --> 0.351810).  Saving model ...
	 Train_Loss: 0.3491 Train_Acc: 88.705 Val_Loss: 0.3518  BEST VAL Loss: 0.3518  Val_Acc: 88.097

Epoch 31: Validation loss decreased (0.351810 --> 0.350950).  Saving model ...
	 Train_Loss: 0.3461 Train_Acc: 88.998 Val_Loss: 0.3509  BEST VAL Loss: 0.3509  Val_Acc: 85.664

Epoch 32: Validation loss decreased (0.350950 --> 0.349398).  Saving model ...
	 Train_Loss: 0.3434 Train_Acc: 89.274 Val_Loss: 0.3494  BEST VAL Loss: 0.3494  Val_Acc: 87.522

Epoch 33: Validation loss decreased (0.349398 --> 0.347916).  Saving model ...
	 Train_Loss: 0.3407 Train_Acc: 89.153 Val_Loss: 0.3479  BEST VAL Loss: 0.3479  Val_Acc: 88.053

Epoch 34: Validation loss decreased (0.347916 --> 0.346311).  Saving model ...
	 Train_Loss: 0.3382 Train_Acc: 89.496 Val_Loss: 0.3463  BEST VAL Loss: 0.3463  Val_Acc: 88.230

Epoch 35: Validation loss decreased (0.346311 --> 0.344412).  Saving model ...
	 Train_Loss: 0.3356 Train_Acc: 89.440 Val_Loss: 0.3444  BEST VAL Loss: 0.3444  Val_Acc: 88.363

Epoch 36: Validation loss decreased (0.344412 --> 0.342694).  Saving model ...
	 Train_Loss: 0.3331 Train_Acc: 89.916 Val_Loss: 0.3427  BEST VAL Loss: 0.3427  Val_Acc: 88.628

Epoch 37: Validation loss decreased (0.342694 --> 0.340415).  Saving model ...
	 Train_Loss: 0.3308 Train_Acc: 89.861 Val_Loss: 0.3404  BEST VAL Loss: 0.3404  Val_Acc: 88.274

Epoch 38: Validation loss decreased (0.340415 --> 0.339028).  Saving model ...
	 Train_Loss: 0.3284 Train_Acc: 90.021 Val_Loss: 0.3390  BEST VAL Loss: 0.3390  Val_Acc: 88.363

Epoch 39: Validation loss decreased (0.339028 --> 0.338256).  Saving model ...
	 Train_Loss: 0.3262 Train_Acc: 90.121 Val_Loss: 0.3383  BEST VAL Loss: 0.3383  Val_Acc: 87.301

Epoch 40: Validation loss decreased (0.338256 --> 0.336299).  Saving model ...
	 Train_Loss: 0.3240 Train_Acc: 90.148 Val_Loss: 0.3363  BEST VAL Loss: 0.3363  Val_Acc: 88.053

Epoch 41: Validation loss decreased (0.336299 --> 0.334962).  Saving model ...
	 Train_Loss: 0.3219 Train_Acc: 90.397 Val_Loss: 0.3350  BEST VAL Loss: 0.3350  Val_Acc: 88.186

Epoch 42: Validation loss decreased (0.334962 --> 0.334353).  Saving model ...
	 Train_Loss: 0.3198 Train_Acc: 90.607 Val_Loss: 0.3344  BEST VAL Loss: 0.3344  Val_Acc: 87.566

Epoch 43: Validation loss decreased (0.334353 --> 0.332898).  Saving model ...
	 Train_Loss: 0.3177 Train_Acc: 90.447 Val_Loss: 0.3329  BEST VAL Loss: 0.3329  Val_Acc: 88.805

Epoch 44: Validation loss decreased (0.332898 --> 0.331714).  Saving model ...
	 Train_Loss: 0.3157 Train_Acc: 90.508 Val_Loss: 0.3317  BEST VAL Loss: 0.3317  Val_Acc: 88.540

Epoch 45: Validation loss decreased (0.331714 --> 0.330787).  Saving model ...
	 Train_Loss: 0.3137 Train_Acc: 90.884 Val_Loss: 0.3308  BEST VAL Loss: 0.3308  Val_Acc: 87.788

Epoch 46: Validation loss decreased (0.330787 --> 0.329623).  Saving model ...
	 Train_Loss: 0.3118 Train_Acc: 90.779 Val_Loss: 0.3296  BEST VAL Loss: 0.3296  Val_Acc: 88.628

Epoch 47: Validation loss decreased (0.329623 --> 0.328710).  Saving model ...
	 Train_Loss: 0.3099 Train_Acc: 91.105 Val_Loss: 0.3287  BEST VAL Loss: 0.3287  Val_Acc: 88.097

Epoch 48: Validation loss decreased (0.328710 --> 0.327696).  Saving model ...
	 Train_Loss: 0.3080 Train_Acc: 90.978 Val_Loss: 0.3277  BEST VAL Loss: 0.3277  Val_Acc: 88.407

Epoch 49: Validation loss decreased (0.327696 --> 0.326298).  Saving model ...
	 Train_Loss: 0.3063 Train_Acc: 90.950 Val_Loss: 0.3263  BEST VAL Loss: 0.3263  Val_Acc: 89.027

Epoch 50: Validation loss decreased (0.326298 --> 0.325815).  Saving model ...
	 Train_Loss: 0.3044 Train_Acc: 91.620 Val_Loss: 0.3258  BEST VAL Loss: 0.3258  Val_Acc: 88.142

Epoch 51: Validation loss decreased (0.325815 --> 0.324499).  Saving model ...
	 Train_Loss: 0.3027 Train_Acc: 91.432 Val_Loss: 0.3245  BEST VAL Loss: 0.3245  Val_Acc: 88.894

Epoch 52: Validation loss decreased (0.324499 --> 0.323465).  Saving model ...
	 Train_Loss: 0.3010 Train_Acc: 91.520 Val_Loss: 0.3235  BEST VAL Loss: 0.3235  Val_Acc: 88.363

Epoch 53: Validation loss decreased (0.323465 --> 0.322521).  Saving model ...
	 Train_Loss: 0.2994 Train_Acc: 91.304 Val_Loss: 0.3225  BEST VAL Loss: 0.3225  Val_Acc: 88.673

Epoch 54: Validation loss decreased (0.322521 --> 0.321529).  Saving model ...
	 Train_Loss: 0.2978 Train_Acc: 91.326 Val_Loss: 0.3215  BEST VAL Loss: 0.3215  Val_Acc: 89.159

Epoch 55: Validation loss decreased (0.321529 --> 0.320595).  Saving model ...
	 Train_Loss: 0.2962 Train_Acc: 91.775 Val_Loss: 0.3206  BEST VAL Loss: 0.3206  Val_Acc: 89.602

Epoch 56: Validation loss decreased (0.320595 --> 0.319753).  Saving model ...
	 Train_Loss: 0.2947 Train_Acc: 91.769 Val_Loss: 0.3198  BEST VAL Loss: 0.3198  Val_Acc: 87.611

Epoch 57: Validation loss decreased (0.319753 --> 0.319060).  Saving model ...
	 Train_Loss: 0.2932 Train_Acc: 91.725 Val_Loss: 0.3191  BEST VAL Loss: 0.3191  Val_Acc: 88.628

Epoch 58: Validation loss decreased (0.319060 --> 0.318232).  Saving model ...
	 Train_Loss: 0.2917 Train_Acc: 91.824 Val_Loss: 0.3182  BEST VAL Loss: 0.3182  Val_Acc: 89.071

Epoch 59: Validation loss decreased (0.318232 --> 0.317667).  Saving model ...
	 Train_Loss: 0.2902 Train_Acc: 92.068 Val_Loss: 0.3177  BEST VAL Loss: 0.3177  Val_Acc: 89.115

Epoch 60: Validation loss decreased (0.317667 --> 0.316994).  Saving model ...
	 Train_Loss: 0.2887 Train_Acc: 91.763 Val_Loss: 0.3170  BEST VAL Loss: 0.3170  Val_Acc: 88.982

Epoch 61: Validation loss decreased (0.316994 --> 0.316429).  Saving model ...
	 Train_Loss: 0.2873 Train_Acc: 91.913 Val_Loss: 0.3164  BEST VAL Loss: 0.3164  Val_Acc: 89.159

Epoch 62: Validation loss decreased (0.316429 --> 0.315605).  Saving model ...
	 Train_Loss: 0.2859 Train_Acc: 92.129 Val_Loss: 0.3156  BEST VAL Loss: 0.3156  Val_Acc: 89.027

Epoch 63: Validation loss decreased (0.315605 --> 0.314720).  Saving model ...
	 Train_Loss: 0.2845 Train_Acc: 92.217 Val_Loss: 0.3147  BEST VAL Loss: 0.3147  Val_Acc: 89.558

Epoch 64: Validation loss decreased (0.314720 --> 0.314126).  Saving model ...
	 Train_Loss: 0.2831 Train_Acc: 92.035 Val_Loss: 0.3141  BEST VAL Loss: 0.3141  Val_Acc: 89.381

Epoch 65: Validation loss decreased (0.314126 --> 0.313155).  Saving model ...
	 Train_Loss: 0.2818 Train_Acc: 92.377 Val_Loss: 0.3132  BEST VAL Loss: 0.3132  Val_Acc: 88.496

Epoch 66: Validation loss decreased (0.313155 --> 0.312716).  Saving model ...
	 Train_Loss: 0.2805 Train_Acc: 92.383 Val_Loss: 0.3127  BEST VAL Loss: 0.3127  Val_Acc: 88.938

Epoch 67: Validation loss decreased (0.312716 --> 0.311791).  Saving model ...
	 Train_Loss: 0.2792 Train_Acc: 92.422 Val_Loss: 0.3118  BEST VAL Loss: 0.3118  Val_Acc: 89.867

Epoch 68: Validation loss decreased (0.311791 --> 0.310953).  Saving model ...
	 Train_Loss: 0.2779 Train_Acc: 92.422 Val_Loss: 0.3110  BEST VAL Loss: 0.3110  Val_Acc: 90.044

Epoch 69: Validation loss decreased (0.310953 --> 0.310908).  Saving model ...
	 Train_Loss: 0.2766 Train_Acc: 92.615 Val_Loss: 0.3109  BEST VAL Loss: 0.3109  Val_Acc: 87.035

Epoch 70: Validation loss decreased (0.310908 --> 0.310221).  Saving model ...
	 Train_Loss: 0.2755 Train_Acc: 92.438 Val_Loss: 0.3102  BEST VAL Loss: 0.3102  Val_Acc: 89.779

Epoch 71: Validation loss decreased (0.310221 --> 0.309710).  Saving model ...
	 Train_Loss: 0.2742 Train_Acc: 92.826 Val_Loss: 0.3097  BEST VAL Loss: 0.3097  Val_Acc: 88.053

Epoch 72: Validation loss decreased (0.309710 --> 0.309187).  Saving model ...
	 Train_Loss: 0.2730 Train_Acc: 92.837 Val_Loss: 0.3092  BEST VAL Loss: 0.3092  Val_Acc: 89.204

Epoch 73: Validation loss decreased (0.309187 --> 0.308735).  Saving model ...
	 Train_Loss: 0.2719 Train_Acc: 92.859 Val_Loss: 0.3087  BEST VAL Loss: 0.3087  Val_Acc: 89.867

Epoch 74: Validation loss decreased (0.308735 --> 0.308063).  Saving model ...
	 Train_Loss: 0.2708 Train_Acc: 92.494 Val_Loss: 0.3081  BEST VAL Loss: 0.3081  Val_Acc: 89.602

Epoch 75: Validation loss decreased (0.308063 --> 0.307833).  Saving model ...
	 Train_Loss: 0.2697 Train_Acc: 92.743 Val_Loss: 0.3078  BEST VAL Loss: 0.3078  Val_Acc: 89.071

Epoch 76: Validation loss decreased (0.307833 --> 0.307495).  Saving model ...
	 Train_Loss: 0.2686 Train_Acc: 92.715 Val_Loss: 0.3075  BEST VAL Loss: 0.3075  Val_Acc: 89.381

Epoch 77: Validation loss decreased (0.307495 --> 0.307004).  Saving model ...
	 Train_Loss: 0.2675 Train_Acc: 93.014 Val_Loss: 0.3070  BEST VAL Loss: 0.3070  Val_Acc: 88.982

Epoch 78: Validation loss decreased (0.307004 --> 0.306476).  Saving model ...
	 Train_Loss: 0.2665 Train_Acc: 93.097 Val_Loss: 0.3065  BEST VAL Loss: 0.3065  Val_Acc: 88.805

Epoch 79: Validation loss decreased (0.306476 --> 0.306184).  Saving model ...
	 Train_Loss: 0.2654 Train_Acc: 92.942 Val_Loss: 0.3062  BEST VAL Loss: 0.3062  Val_Acc: 87.743

Epoch 80: Validation loss decreased (0.306184 --> 0.305843).  Saving model ...
	 Train_Loss: 0.2644 Train_Acc: 92.737 Val_Loss: 0.3058  BEST VAL Loss: 0.3058  Val_Acc: 89.336

Epoch 81: Validation loss decreased (0.305843 --> 0.305256).  Saving model ...
	 Train_Loss: 0.2633 Train_Acc: 93.014 Val_Loss: 0.3053  BEST VAL Loss: 0.3053  Val_Acc: 89.204

Epoch 82: Validation loss decreased (0.305256 --> 0.304590).  Saving model ...
	 Train_Loss: 0.2623 Train_Acc: 93.086 Val_Loss: 0.3046  BEST VAL Loss: 0.3046  Val_Acc: 89.646

Epoch 83: Validation loss decreased (0.304590 --> 0.304069).  Saving model ...
	 Train_Loss: 0.2613 Train_Acc: 93.180 Val_Loss: 0.3041  BEST VAL Loss: 0.3041  Val_Acc: 89.027

Epoch 84: Validation loss decreased (0.304069 --> 0.303517).  Saving model ...
	 Train_Loss: 0.2603 Train_Acc: 93.334 Val_Loss: 0.3035  BEST VAL Loss: 0.3035  Val_Acc: 89.735

Epoch 85: Validation loss decreased (0.303517 --> 0.303121).  Saving model ...
	 Train_Loss: 0.2592 Train_Acc: 93.423 Val_Loss: 0.3031  BEST VAL Loss: 0.3031  Val_Acc: 89.425

Epoch 86: Validation loss decreased (0.303121 --> 0.302709).  Saving model ...
	 Train_Loss: 0.2582 Train_Acc: 93.628 Val_Loss: 0.3027  BEST VAL Loss: 0.3027  Val_Acc: 89.336

Epoch 87: Validation loss decreased (0.302709 --> 0.302311).  Saving model ...
	 Train_Loss: 0.2572 Train_Acc: 93.268 Val_Loss: 0.3023  BEST VAL Loss: 0.3023  Val_Acc: 88.673

Epoch 88: Validation loss decreased (0.302311 --> 0.302105).  Saving model ...
	 Train_Loss: 0.2564 Train_Acc: 93.268 Val_Loss: 0.3021  BEST VAL Loss: 0.3021  Val_Acc: 89.159

Epoch 89: Validation loss decreased (0.302105 --> 0.301700).  Saving model ...
	 Train_Loss: 0.2554 Train_Acc: 93.434 Val_Loss: 0.3017  BEST VAL Loss: 0.3017  Val_Acc: 89.381

Epoch 90: Validation loss decreased (0.301700 --> 0.301384).  Saving model ...
	 Train_Loss: 0.2545 Train_Acc: 93.517 Val_Loss: 0.3014  BEST VAL Loss: 0.3014  Val_Acc: 89.602

Epoch 91: Validation loss decreased (0.301384 --> 0.300979).  Saving model ...
	 Train_Loss: 0.2535 Train_Acc: 93.705 Val_Loss: 0.3010  BEST VAL Loss: 0.3010  Val_Acc: 89.469

Epoch 92: Validation loss decreased (0.300979 --> 0.300430).  Saving model ...
	 Train_Loss: 0.2526 Train_Acc: 93.650 Val_Loss: 0.3004  BEST VAL Loss: 0.3004  Val_Acc: 88.805

Epoch 93: Validation loss decreased (0.300430 --> 0.300366).  Saving model ...
	 Train_Loss: 0.2518 Train_Acc: 93.760 Val_Loss: 0.3004  BEST VAL Loss: 0.3004  Val_Acc: 87.434

Epoch 94: Validation loss decreased (0.300366 --> 0.300194).  Saving model ...
	 Train_Loss: 0.2509 Train_Acc: 93.357 Val_Loss: 0.3002  BEST VAL Loss: 0.3002  Val_Acc: 89.381

Epoch 95: Validation loss decreased (0.300194 --> 0.299655).  Saving model ...
	 Train_Loss: 0.2500 Train_Acc: 93.749 Val_Loss: 0.2997  BEST VAL Loss: 0.2997  Val_Acc: 89.558

Epoch 96: Validation loss decreased (0.299655 --> 0.299232).  Saving model ...
	 Train_Loss: 0.2491 Train_Acc: 93.561 Val_Loss: 0.2992  BEST VAL Loss: 0.2992  Val_Acc: 89.558

Epoch 97: Validation loss decreased (0.299232 --> 0.299121).  Saving model ...
	 Train_Loss: 0.2482 Train_Acc: 93.744 Val_Loss: 0.2991  BEST VAL Loss: 0.2991  Val_Acc: 88.850

Epoch 98: Validation loss decreased (0.299121 --> 0.298813).  Saving model ...
	 Train_Loss: 0.2474 Train_Acc: 93.628 Val_Loss: 0.2988  BEST VAL Loss: 0.2988  Val_Acc: 89.159

Epoch 99: Validation loss decreased (0.298813 --> 0.298554).  Saving model ...
	 Train_Loss: 0.2465 Train_Acc: 93.688 Val_Loss: 0.2986  BEST VAL Loss: 0.2986  Val_Acc: 89.292

Thapsigargin_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.52      0.53      9707
           1       0.46      0.47      0.46      8371

    accuracy                           0.50     18078
   macro avg       0.50      0.50      0.50     18078
weighted avg       0.50      0.50      0.50     18078

Thapsigargin_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.53      0.53      1214
           1       0.46      0.46      0.46      1046

    accuracy                           0.50      2260
   macro avg       0.49      0.49      0.49      2260
weighted avg       0.50      0.50      0.50      2260

Thapsigargin_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.52      0.53      1214
           1       0.46      0.46      0.46      1046

    accuracy                           0.50      2260
   macro avg       0.49      0.49      0.49      2260
weighted avg       0.50      0.50      0.50      2260

              precision    recall  f1-score   support

           0       0.53      0.52      0.53      1214
           1       0.46      0.46      0.46      1046

    accuracy                           0.50      2260
   macro avg       0.49      0.49      0.49      2260
weighted avg       0.50      0.50      0.50      2260

Thapsigargin_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.53      0.53      3724
           1       0.47      0.47      0.47      3303

    accuracy                           0.50      7027
   macro avg       0.50      0.50      0.50      7027
weighted avg       0.50      0.50      0.50      7027

              precision    recall  f1-score   support

           0       0.53      0.53      0.53      3724
           1       0.47      0.47      0.47      3303

    accuracy                           0.50      7027
   macro avg       0.50      0.50      0.50      7027
weighted avg       0.50      0.50      0.50      7027

completed
