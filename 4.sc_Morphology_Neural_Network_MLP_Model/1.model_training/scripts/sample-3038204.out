[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '0f8a01f4'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '9d154d7a'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '19b5208c'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '5d224f2b'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Thapsigargin_10.000_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Thapsigargin_10.000_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (326419, 1270)
Number of total missing values across all columns: 652838
Data Subset Is Off
Wells held out for testing: ['J09' 'L06']
Wells to use for training, validation, and testing ['E06' 'E07' 'J02' 'J03' 'J08' 'L07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.365477).  Saving model ...
	 Train_Loss: 0.5089 Train_Acc: 75.910 Val_Loss: 0.3655  BEST VAL Loss: 0.3655  Val_Acc: 84.223

Epoch 1: Validation loss decreased (0.365477 --> 0.349833).  Saving model ...
	 Train_Loss: 0.4584 Train_Acc: 81.315 Val_Loss: 0.3498  BEST VAL Loss: 0.3498  Val_Acc: 85.863

Epoch 2: Validation loss decreased (0.349833 --> 0.335146).  Saving model ...
	 Train_Loss: 0.4329 Train_Acc: 82.893 Val_Loss: 0.3351  BEST VAL Loss: 0.3351  Val_Acc: 87.235

Epoch 3: Validation loss decreased (0.335146 --> 0.325429).  Saving model ...
	 Train_Loss: 0.4162 Train_Acc: 83.746 Val_Loss: 0.3254  BEST VAL Loss: 0.3254  Val_Acc: 87.974

Epoch 4: Validation loss decreased (0.325429 --> 0.318825).  Saving model ...
	 Train_Loss: 0.4041 Train_Acc: 84.302 Val_Loss: 0.3188  BEST VAL Loss: 0.3188  Val_Acc: 88.152

Epoch 5: Validation loss decreased (0.318825 --> 0.312211).  Saving model ...
	 Train_Loss: 0.3944 Train_Acc: 84.785 Val_Loss: 0.3122  BEST VAL Loss: 0.3122  Val_Acc: 88.408

Epoch 6: Validation loss decreased (0.312211 --> 0.307421).  Saving model ...
	 Train_Loss: 0.3868 Train_Acc: 84.995 Val_Loss: 0.3074  BEST VAL Loss: 0.3074  Val_Acc: 88.181

Epoch 7: Validation loss decreased (0.307421 --> 0.303027).  Saving model ...
	 Train_Loss: 0.3806 Train_Acc: 85.143 Val_Loss: 0.3030  BEST VAL Loss: 0.3030  Val_Acc: 88.949

Epoch 8: Validation loss decreased (0.303027 --> 0.299818).  Saving model ...
	 Train_Loss: 0.3751 Train_Acc: 85.387 Val_Loss: 0.2998  BEST VAL Loss: 0.2998  Val_Acc: 88.714

Epoch 9: Validation loss decreased (0.299818 --> 0.296230).  Saving model ...
	 Train_Loss: 0.3704 Train_Acc: 85.611 Val_Loss: 0.2962  BEST VAL Loss: 0.2962  Val_Acc: 88.895

Epoch 10: Validation loss decreased (0.296230 --> 0.293906).  Saving model ...
	 Train_Loss: 0.3663 Train_Acc: 85.692 Val_Loss: 0.2939  BEST VAL Loss: 0.2939  Val_Acc: 88.813

Epoch 11: Validation loss decreased (0.293906 --> 0.291224).  Saving model ...
	 Train_Loss: 0.3627 Train_Acc: 85.851 Val_Loss: 0.2912  BEST VAL Loss: 0.2912  Val_Acc: 89.226

Epoch 12: Validation loss decreased (0.291224 --> 0.289061).  Saving model ...
	 Train_Loss: 0.3596 Train_Acc: 85.912 Val_Loss: 0.2891  BEST VAL Loss: 0.2891  Val_Acc: 89.292

Epoch 13: Validation loss decreased (0.289061 --> 0.287102).  Saving model ...
	 Train_Loss: 0.3566 Train_Acc: 86.104 Val_Loss: 0.2871  BEST VAL Loss: 0.2871  Val_Acc: 89.375

Epoch 14: Validation loss decreased (0.287102 --> 0.285332).  Saving model ...
	 Train_Loss: 0.3540 Train_Acc: 86.214 Val_Loss: 0.2853  BEST VAL Loss: 0.2853  Val_Acc: 89.292

Epoch 15: Validation loss decreased (0.285332 --> 0.283677).  Saving model ...
	 Train_Loss: 0.3514 Train_Acc: 86.383 Val_Loss: 0.2837  BEST VAL Loss: 0.2837  Val_Acc: 89.193

Epoch 16: Validation loss decreased (0.283677 --> 0.282239).  Saving model ...
	 Train_Loss: 0.3492 Train_Acc: 86.295 Val_Loss: 0.2822  BEST VAL Loss: 0.2822  Val_Acc: 89.317

Epoch 17: Validation loss decreased (0.282239 --> 0.280472).  Saving model ...
	 Train_Loss: 0.3471 Train_Acc: 86.470 Val_Loss: 0.2805  BEST VAL Loss: 0.2805  Val_Acc: 89.705

Epoch 18: Validation loss decreased (0.280472 --> 0.279395).  Saving model ...
	 Train_Loss: 0.3452 Train_Acc: 86.393 Val_Loss: 0.2794  BEST VAL Loss: 0.2794  Val_Acc: 89.242

Epoch 19: Validation loss decreased (0.279395 --> 0.277969).  Saving model ...
	 Train_Loss: 0.3434 Train_Acc: 86.537 Val_Loss: 0.2780  BEST VAL Loss: 0.2780  Val_Acc: 89.668

Epoch 20: Validation loss decreased (0.277969 --> 0.276628).  Saving model ...
	 Train_Loss: 0.3418 Train_Acc: 86.634 Val_Loss: 0.2766  BEST VAL Loss: 0.2766  Val_Acc: 89.792

Epoch 21: Validation loss decreased (0.276628 --> 0.275552).  Saving model ...
	 Train_Loss: 0.3401 Train_Acc: 86.668 Val_Loss: 0.2756  BEST VAL Loss: 0.2756  Val_Acc: 89.651

Epoch 22: Validation loss decreased (0.275552 --> 0.274434).  Saving model ...
	 Train_Loss: 0.3387 Train_Acc: 86.640 Val_Loss: 0.2744  BEST VAL Loss: 0.2744  Val_Acc: 89.829

Epoch 23: Validation loss decreased (0.274434 --> 0.273382).  Saving model ...
	 Train_Loss: 0.3373 Train_Acc: 86.748 Val_Loss: 0.2734  BEST VAL Loss: 0.2734  Val_Acc: 89.759

Epoch 24: Validation loss decreased (0.273382 --> 0.272369).  Saving model ...
	 Train_Loss: 0.3360 Train_Acc: 86.790 Val_Loss: 0.2724  BEST VAL Loss: 0.2724  Val_Acc: 89.883

Epoch 25: Validation loss decreased (0.272369 --> 0.271342).  Saving model ...
	 Train_Loss: 0.3348 Train_Acc: 86.793 Val_Loss: 0.2713  BEST VAL Loss: 0.2713  Val_Acc: 90.126

Epoch 26: Validation loss decreased (0.271342 --> 0.270532).  Saving model ...
	 Train_Loss: 0.3336 Train_Acc: 86.782 Val_Loss: 0.2705  BEST VAL Loss: 0.2705  Val_Acc: 89.817

Epoch 27: Validation loss decreased (0.270532 --> 0.269756).  Saving model ...
	 Train_Loss: 0.3325 Train_Acc: 86.762 Val_Loss: 0.2698  BEST VAL Loss: 0.2698  Val_Acc: 89.887

Epoch 28: Validation loss decreased (0.269756 --> 0.269018).  Saving model ...
	 Train_Loss: 0.3314 Train_Acc: 86.908 Val_Loss: 0.2690  BEST VAL Loss: 0.2690  Val_Acc: 89.961

Epoch 29: Validation loss decreased (0.269018 --> 0.268370).  Saving model ...
	 Train_Loss: 0.3304 Train_Acc: 86.916 Val_Loss: 0.2684  BEST VAL Loss: 0.2684  Val_Acc: 89.949

Epoch 30: Validation loss decreased (0.268370 --> 0.267612).  Saving model ...
	 Train_Loss: 0.3295 Train_Acc: 86.969 Val_Loss: 0.2676  BEST VAL Loss: 0.2676  Val_Acc: 90.205

Epoch 31: Validation loss decreased (0.267612 --> 0.266850).  Saving model ...
	 Train_Loss: 0.3286 Train_Acc: 86.887 Val_Loss: 0.2669  BEST VAL Loss: 0.2669  Val_Acc: 90.238

Epoch 32: Validation loss decreased (0.266850 --> 0.266256).  Saving model ...
	 Train_Loss: 0.3277 Train_Acc: 86.936 Val_Loss: 0.2663  BEST VAL Loss: 0.2663  Val_Acc: 90.168

Epoch 33: Validation loss decreased (0.266256 --> 0.265665).  Saving model ...
	 Train_Loss: 0.3269 Train_Acc: 87.037 Val_Loss: 0.2657  BEST VAL Loss: 0.2657  Val_Acc: 89.941

Epoch 34: Validation loss decreased (0.265665 --> 0.265122).  Saving model ...
	 Train_Loss: 0.3260 Train_Acc: 87.075 Val_Loss: 0.2651  BEST VAL Loss: 0.2651  Val_Acc: 89.891

Epoch 35: Validation loss decreased (0.265122 --> 0.264605).  Saving model ...
	 Train_Loss: 0.3252 Train_Acc: 87.017 Val_Loss: 0.2646  BEST VAL Loss: 0.2646  Val_Acc: 90.069

Epoch 36: Validation loss decreased (0.264605 --> 0.264003).  Saving model ...
	 Train_Loss: 0.3245 Train_Acc: 87.077 Val_Loss: 0.2640  BEST VAL Loss: 0.2640  Val_Acc: 90.263

Epoch 37: Validation loss decreased (0.264003 --> 0.263468).  Saving model ...
	 Train_Loss: 0.3238 Train_Acc: 87.118 Val_Loss: 0.2635  BEST VAL Loss: 0.2635  Val_Acc: 90.114

Epoch 38: Validation loss decreased (0.263468 --> 0.263109).  Saving model ...
	 Train_Loss: 0.3231 Train_Acc: 87.148 Val_Loss: 0.2631  BEST VAL Loss: 0.2631  Val_Acc: 89.850

Epoch 39: Validation loss decreased (0.263109 --> 0.262735).  Saving model ...
	 Train_Loss: 0.3225 Train_Acc: 87.055 Val_Loss: 0.2627  BEST VAL Loss: 0.2627  Val_Acc: 90.168

Epoch 40: Validation loss decreased (0.262735 --> 0.262390).  Saving model ...
	 Train_Loss: 0.3218 Train_Acc: 87.211 Val_Loss: 0.2624  BEST VAL Loss: 0.2624  Val_Acc: 90.002

Epoch 41: Validation loss decreased (0.262390 --> 0.261979).  Saving model ...
	 Train_Loss: 0.3212 Train_Acc: 87.215 Val_Loss: 0.2620  BEST VAL Loss: 0.2620  Val_Acc: 90.217

Epoch 42: Validation loss decreased (0.261979 --> 0.261516).  Saving model ...
	 Train_Loss: 0.3206 Train_Acc: 87.322 Val_Loss: 0.2615  BEST VAL Loss: 0.2615  Val_Acc: 90.193

Epoch 43: Validation loss decreased (0.261516 --> 0.260980).  Saving model ...
	 Train_Loss: 0.3200 Train_Acc: 87.222 Val_Loss: 0.2610  BEST VAL Loss: 0.2610  Val_Acc: 90.366

Epoch 44: Validation loss decreased (0.260980 --> 0.260646).  Saving model ...
	 Train_Loss: 0.3194 Train_Acc: 87.159 Val_Loss: 0.2606  BEST VAL Loss: 0.2606  Val_Acc: 89.969

Epoch 45: Validation loss decreased (0.260646 --> 0.260267).  Saving model ...
	 Train_Loss: 0.3189 Train_Acc: 87.363 Val_Loss: 0.2603  BEST VAL Loss: 0.2603  Val_Acc: 90.106

Epoch 46: Validation loss decreased (0.260267 --> 0.259889).  Saving model ...
	 Train_Loss: 0.3183 Train_Acc: 87.295 Val_Loss: 0.2599  BEST VAL Loss: 0.2599  Val_Acc: 90.254

Epoch 47: Validation loss decreased (0.259889 --> 0.259434).  Saving model ...
	 Train_Loss: 0.3178 Train_Acc: 87.387 Val_Loss: 0.2594  BEST VAL Loss: 0.2594  Val_Acc: 90.350

Epoch 48: Validation loss decreased (0.259434 --> 0.259009).  Saving model ...
	 Train_Loss: 0.3172 Train_Acc: 87.320 Val_Loss: 0.2590  BEST VAL Loss: 0.2590  Val_Acc: 90.420

Epoch 49: Validation loss decreased (0.259009 --> 0.258659).  Saving model ...
	 Train_Loss: 0.3167 Train_Acc: 87.354 Val_Loss: 0.2587  BEST VAL Loss: 0.2587  Val_Acc: 90.172

Epoch 50: Validation loss decreased (0.258659 --> 0.258408).  Saving model ...
	 Train_Loss: 0.3163 Train_Acc: 87.291 Val_Loss: 0.2584  BEST VAL Loss: 0.2584  Val_Acc: 90.209

Epoch 51: Validation loss decreased (0.258408 --> 0.258136).  Saving model ...
	 Train_Loss: 0.3158 Train_Acc: 87.469 Val_Loss: 0.2581  BEST VAL Loss: 0.2581  Val_Acc: 90.325

Epoch 52: Validation loss decreased (0.258136 --> 0.257953).  Saving model ...
	 Train_Loss: 0.3154 Train_Acc: 87.457 Val_Loss: 0.2580  BEST VAL Loss: 0.2580  Val_Acc: 89.792

Epoch 53: Validation loss decreased (0.257953 --> 0.257681).  Saving model ...
	 Train_Loss: 0.3149 Train_Acc: 87.413 Val_Loss: 0.2577  BEST VAL Loss: 0.2577  Val_Acc: 90.250

Epoch 54: Validation loss decreased (0.257681 --> 0.257428).  Saving model ...
	 Train_Loss: 0.3145 Train_Acc: 87.416 Val_Loss: 0.2574  BEST VAL Loss: 0.2574  Val_Acc: 90.304

Epoch 55: Validation loss decreased (0.257428 --> 0.257128).  Saving model ...
	 Train_Loss: 0.3140 Train_Acc: 87.406 Val_Loss: 0.2571  BEST VAL Loss: 0.2571  Val_Acc: 90.106

Epoch 56: Validation loss decreased (0.257128 --> 0.256900).  Saving model ...
	 Train_Loss: 0.3136 Train_Acc: 87.444 Val_Loss: 0.2569  BEST VAL Loss: 0.2569  Val_Acc: 90.188

Epoch 57: Validation loss decreased (0.256900 --> 0.256616).  Saving model ...
	 Train_Loss: 0.3132 Train_Acc: 87.480 Val_Loss: 0.2566  BEST VAL Loss: 0.2566  Val_Acc: 90.304

Epoch 58: Validation loss decreased (0.256616 --> 0.256292).  Saving model ...
	 Train_Loss: 0.3128 Train_Acc: 87.517 Val_Loss: 0.2563  BEST VAL Loss: 0.2563  Val_Acc: 90.407

Epoch 59: Validation loss decreased (0.256292 --> 0.256068).  Saving model ...
	 Train_Loss: 0.3124 Train_Acc: 87.465 Val_Loss: 0.2561  BEST VAL Loss: 0.2561  Val_Acc: 90.333

Epoch 60: Validation loss decreased (0.256068 --> 0.255752).  Saving model ...
	 Train_Loss: 0.3121 Train_Acc: 87.518 Val_Loss: 0.2558  BEST VAL Loss: 0.2558  Val_Acc: 90.321

Epoch 61: Validation loss decreased (0.255752 --> 0.255497).  Saving model ...
	 Train_Loss: 0.3117 Train_Acc: 87.506 Val_Loss: 0.2555  BEST VAL Loss: 0.2555  Val_Acc: 90.403

Epoch 62: Validation loss decreased (0.255497 --> 0.255329).  Saving model ...
	 Train_Loss: 0.3113 Train_Acc: 87.593 Val_Loss: 0.2553  BEST VAL Loss: 0.2553  Val_Acc: 90.077

Epoch 63: Validation loss decreased (0.255329 --> 0.255066).  Saving model ...
	 Train_Loss: 0.3109 Train_Acc: 87.487 Val_Loss: 0.2551  BEST VAL Loss: 0.2551  Val_Acc: 90.449

Epoch 64: Validation loss decreased (0.255066 --> 0.254876).  Saving model ...
	 Train_Loss: 0.3106 Train_Acc: 87.535 Val_Loss: 0.2549  BEST VAL Loss: 0.2549  Val_Acc: 90.366

Epoch 65: Validation loss decreased (0.254876 --> 0.254631).  Saving model ...
	 Train_Loss: 0.3102 Train_Acc: 87.652 Val_Loss: 0.2546  BEST VAL Loss: 0.2546  Val_Acc: 90.341

Epoch 66: Validation loss decreased (0.254631 --> 0.254337).  Saving model ...
	 Train_Loss: 0.3099 Train_Acc: 87.576 Val_Loss: 0.2543  BEST VAL Loss: 0.2543  Val_Acc: 90.635

Epoch 67: Validation loss decreased (0.254337 --> 0.254178).  Saving model ...
	 Train_Loss: 0.3096 Train_Acc: 87.590 Val_Loss: 0.2542  BEST VAL Loss: 0.2542  Val_Acc: 90.383

Epoch 68: Validation loss decreased (0.254178 --> 0.253967).  Saving model ...
	 Train_Loss: 0.3093 Train_Acc: 87.696 Val_Loss: 0.2540  BEST VAL Loss: 0.2540  Val_Acc: 90.436

Epoch 69: Validation loss decreased (0.253967 --> 0.253782).  Saving model ...
	 Train_Loss: 0.3090 Train_Acc: 87.558 Val_Loss: 0.2538  BEST VAL Loss: 0.2538  Val_Acc: 90.288

Epoch 70: Validation loss decreased (0.253782 --> 0.253583).  Saving model ...
	 Train_Loss: 0.3087 Train_Acc: 87.609 Val_Loss: 0.2536  BEST VAL Loss: 0.2536  Val_Acc: 90.465

Epoch 71: Validation loss decreased (0.253583 --> 0.253366).  Saving model ...
	 Train_Loss: 0.3083 Train_Acc: 87.676 Val_Loss: 0.2534  BEST VAL Loss: 0.2534  Val_Acc: 90.461

Epoch 72: Validation loss decreased (0.253366 --> 0.253211).  Saving model ...
	 Train_Loss: 0.3080 Train_Acc: 87.703 Val_Loss: 0.2532  BEST VAL Loss: 0.2532  Val_Acc: 90.354

Epoch 73: Validation loss decreased (0.253211 --> 0.253021).  Saving model ...
	 Train_Loss: 0.3077 Train_Acc: 87.706 Val_Loss: 0.2530  BEST VAL Loss: 0.2530  Val_Acc: 90.445

Epoch 74: Validation loss decreased (0.253021 --> 0.252796).  Saving model ...
	 Train_Loss: 0.3074 Train_Acc: 87.680 Val_Loss: 0.2528  BEST VAL Loss: 0.2528  Val_Acc: 90.672

Epoch 75: Validation loss decreased (0.252796 --> 0.252552).  Saving model ...
	 Train_Loss: 0.3072 Train_Acc: 87.645 Val_Loss: 0.2526  BEST VAL Loss: 0.2526  Val_Acc: 90.734

Epoch 76: Validation loss decreased (0.252552 --> 0.252382).  Saving model ...
	 Train_Loss: 0.3069 Train_Acc: 87.764 Val_Loss: 0.2524  BEST VAL Loss: 0.2524  Val_Acc: 90.630

Epoch 77: Validation loss decreased (0.252382 --> 0.252156).  Saving model ...
	 Train_Loss: 0.3066 Train_Acc: 87.641 Val_Loss: 0.2522  BEST VAL Loss: 0.2522  Val_Acc: 90.527

Epoch 78: Validation loss decreased (0.252156 --> 0.251982).  Saving model ...
	 Train_Loss: 0.3063 Train_Acc: 87.639 Val_Loss: 0.2520  BEST VAL Loss: 0.2520  Val_Acc: 90.440

Epoch 79: Validation loss decreased (0.251982 --> 0.251800).  Saving model ...
	 Train_Loss: 0.3061 Train_Acc: 87.788 Val_Loss: 0.2518  BEST VAL Loss: 0.2518  Val_Acc: 90.593

Epoch 80: Validation loss decreased (0.251800 --> 0.251693).  Saving model ...
	 Train_Loss: 0.3058 Train_Acc: 87.632 Val_Loss: 0.2517  BEST VAL Loss: 0.2517  Val_Acc: 90.238

Epoch 81: Validation loss decreased (0.251693 --> 0.251481).  Saving model ...
	 Train_Loss: 0.3056 Train_Acc: 87.674 Val_Loss: 0.2515  BEST VAL Loss: 0.2515  Val_Acc: 90.560

Epoch 82: Validation loss decreased (0.251481 --> 0.251328).  Saving model ...
	 Train_Loss: 0.3053 Train_Acc: 87.814 Val_Loss: 0.2513  BEST VAL Loss: 0.2513  Val_Acc: 90.432

Epoch 83: Validation loss decreased (0.251328 --> 0.251211).  Saving model ...
	 Train_Loss: 0.3050 Train_Acc: 87.777 Val_Loss: 0.2512  BEST VAL Loss: 0.2512  Val_Acc: 90.275

Epoch 84: Validation loss decreased (0.251211 --> 0.251091).  Saving model ...
	 Train_Loss: 0.3048 Train_Acc: 87.680 Val_Loss: 0.2511  BEST VAL Loss: 0.2511  Val_Acc: 90.453

Epoch 85: Validation loss decreased (0.251091 --> 0.250909).  Saving model ...
	 Train_Loss: 0.3046 Train_Acc: 87.750 Val_Loss: 0.2509  BEST VAL Loss: 0.2509  Val_Acc: 90.482

Epoch 86: Validation loss decreased (0.250909 --> 0.250768).  Saving model ...
	 Train_Loss: 0.3043 Train_Acc: 87.748 Val_Loss: 0.2508  BEST VAL Loss: 0.2508  Val_Acc: 90.482

Epoch 87: Validation loss decreased (0.250768 --> 0.250637).  Saving model ...
	 Train_Loss: 0.3041 Train_Acc: 87.731 Val_Loss: 0.2506  BEST VAL Loss: 0.2506  Val_Acc: 90.440

Epoch 88: Validation loss decreased (0.250637 --> 0.250445).  Saving model ...
	 Train_Loss: 0.3039 Train_Acc: 87.810 Val_Loss: 0.2504  BEST VAL Loss: 0.2504  Val_Acc: 90.630

Epoch 89: Validation loss decreased (0.250445 --> 0.250331).  Saving model ...
	 Train_Loss: 0.3036 Train_Acc: 87.820 Val_Loss: 0.2503  BEST VAL Loss: 0.2503  Val_Acc: 90.684

Epoch 90: Validation loss decreased (0.250331 --> 0.250154).  Saving model ...
	 Train_Loss: 0.3034 Train_Acc: 87.764 Val_Loss: 0.2502  BEST VAL Loss: 0.2502  Val_Acc: 90.717

Epoch 91: Validation loss decreased (0.250154 --> 0.250029).  Saving model ...
	 Train_Loss: 0.3032 Train_Acc: 87.798 Val_Loss: 0.2500  BEST VAL Loss: 0.2500  Val_Acc: 90.494

Epoch 92: Validation loss decreased (0.250029 --> 0.249855).  Saving model ...
	 Train_Loss: 0.3030 Train_Acc: 87.788 Val_Loss: 0.2499  BEST VAL Loss: 0.2499  Val_Acc: 90.614

Epoch 93: Validation loss decreased (0.249855 --> 0.249708).  Saving model ...
	 Train_Loss: 0.3027 Train_Acc: 87.815 Val_Loss: 0.2497  BEST VAL Loss: 0.2497  Val_Acc: 90.684

Epoch 94: Validation loss decreased (0.249708 --> 0.249564).  Saving model ...
	 Train_Loss: 0.3025 Train_Acc: 87.787 Val_Loss: 0.2496  BEST VAL Loss: 0.2496  Val_Acc: 90.498

Epoch 95: Validation loss decreased (0.249564 --> 0.249479).  Saving model ...
	 Train_Loss: 0.3023 Train_Acc: 87.790 Val_Loss: 0.2495  BEST VAL Loss: 0.2495  Val_Acc: 90.453

Epoch 96: Validation loss decreased (0.249479 --> 0.249361).  Saving model ...
	 Train_Loss: 0.3021 Train_Acc: 87.834 Val_Loss: 0.2494  BEST VAL Loss: 0.2494  Val_Acc: 90.519

Epoch 97: Validation loss decreased (0.249361 --> 0.249235).  Saving model ...
	 Train_Loss: 0.3019 Train_Acc: 87.840 Val_Loss: 0.2492  BEST VAL Loss: 0.2492  Val_Acc: 90.428

Epoch 98: Validation loss decreased (0.249235 --> 0.249141).  Saving model ...
	 Train_Loss: 0.3017 Train_Acc: 87.746 Val_Loss: 0.2491  BEST VAL Loss: 0.2491  Val_Acc: 90.597

Epoch 99: Validation loss decreased (0.249141 --> 0.248998).  Saving model ...
	 Train_Loss: 0.3015 Train_Acc: 87.890 Val_Loss: 0.2490  BEST VAL Loss: 0.2490  Val_Acc: 90.742

Thapsigargin_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.90      0.91     95989
           1       0.91      0.93      0.92     97655

    accuracy                           0.92    193644
   macro avg       0.92      0.92      0.92    193644
weighted avg       0.92      0.92      0.92    193644

Thapsigargin_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.92      0.89      0.91     11999
           1       0.90      0.92      0.91     12207

    accuracy                           0.91     24206
   macro avg       0.91      0.91      0.91     24206
weighted avg       0.91      0.91      0.91     24206

Thapsigargin_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.91      0.89      0.90     11999
           1       0.90      0.91      0.91     12207

    accuracy                           0.90     24206
   macro avg       0.90      0.90      0.90     24206
weighted avg       0.90      0.90      0.90     24206

              precision    recall  f1-score   support

           0       0.91      0.89      0.90     11999
           1       0.90      0.91      0.91     12207

    accuracy                           0.90     24206
   macro avg       0.90      0.90      0.90     24206
weighted avg       0.90      0.90      0.90     24206

Thapsigargin_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.80      0.65      0.71     39448
           1       0.73      0.85      0.79     44915

    accuracy                           0.76     84363
   macro avg       0.77      0.75      0.75     84363
weighted avg       0.76      0.76      0.75     84363

              precision    recall  f1-score   support

           0       0.80      0.65      0.71     39448
           1       0.73      0.85      0.79     44915

    accuracy                           0.76     84363
   macro avg       0.77      0.75      0.75     84363
weighted avg       0.76      0.76      0.75     84363

completed
