[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '55d68ccf'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '6a289fe1'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '7a705914'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '4aeca20a'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_100.000_DMSO_0.025 treatment_name: DMSO_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_100.000_DMSO_0.025
TREATMENT_NAME: DMSO_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (374565, 1270)
Number of total missing values across all columns: 749130
Data Subset Is Off
Wells held out for testing: ['J06' 'J08']
Wells to use for training, validation, and testing ['B06' 'C06' 'B07' 'C07' 'I06' 'I07' 'J02' 'J03' 'J07' 'J09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.449272).  Saving model ...
	 Train_Loss: 0.5597 Train_Acc: 68.604 Val_Loss: 0.4493  BEST VAL Loss: 0.4493  Val_Acc: 78.805

Epoch 1: Validation loss decreased (0.449272 --> 0.427706).  Saving model ...
	 Train_Loss: 0.5268 Train_Acc: 74.505 Val_Loss: 0.4277  BEST VAL Loss: 0.4277  Val_Acc: 81.812

Epoch 2: Validation loss decreased (0.427706 --> 0.413776).  Saving model ...
	 Train_Loss: 0.5105 Train_Acc: 75.289 Val_Loss: 0.4138  BEST VAL Loss: 0.4138  Val_Acc: 83.082

Epoch 3: Validation loss decreased (0.413776 --> 0.404652).  Saving model ...
	 Train_Loss: 0.4998 Train_Acc: 75.812 Val_Loss: 0.4047  BEST VAL Loss: 0.4047  Val_Acc: 83.631

Epoch 4: Validation loss decreased (0.404652 --> 0.396447).  Saving model ...
	 Train_Loss: 0.4918 Train_Acc: 76.210 Val_Loss: 0.3964  BEST VAL Loss: 0.3964  Val_Acc: 83.999

Epoch 5: Validation loss decreased (0.396447 --> 0.391418).  Saving model ...
	 Train_Loss: 0.4854 Train_Acc: 76.416 Val_Loss: 0.3914  BEST VAL Loss: 0.3914  Val_Acc: 83.983

Epoch 6: Validation loss decreased (0.391418 --> 0.385421).  Saving model ...
	 Train_Loss: 0.4802 Train_Acc: 76.775 Val_Loss: 0.3854  BEST VAL Loss: 0.3854  Val_Acc: 84.694

Epoch 7: Validation loss decreased (0.385421 --> 0.379920).  Saving model ...
	 Train_Loss: 0.4758 Train_Acc: 76.953 Val_Loss: 0.3799  BEST VAL Loss: 0.3799  Val_Acc: 85.237

Epoch 8: Validation loss decreased (0.379920 --> 0.375936).  Saving model ...
	 Train_Loss: 0.4722 Train_Acc: 76.833 Val_Loss: 0.3759  BEST VAL Loss: 0.3759  Val_Acc: 85.136

Epoch 9: Validation loss decreased (0.375936 --> 0.372003).  Saving model ...
	 Train_Loss: 0.4690 Train_Acc: 77.065 Val_Loss: 0.3720  BEST VAL Loss: 0.3720  Val_Acc: 85.450

Epoch 10: Validation loss decreased (0.372003 --> 0.368305).  Saving model ...
	 Train_Loss: 0.4663 Train_Acc: 77.055 Val_Loss: 0.3683  BEST VAL Loss: 0.3683  Val_Acc: 85.586

Epoch 11: Validation loss decreased (0.368305 --> 0.365325).  Saving model ...
	 Train_Loss: 0.4638 Train_Acc: 77.109 Val_Loss: 0.3653  BEST VAL Loss: 0.3653  Val_Acc: 85.602

Epoch 12: Validation loss decreased (0.365325 --> 0.362320).  Saving model ...
	 Train_Loss: 0.4615 Train_Acc: 77.282 Val_Loss: 0.3623  BEST VAL Loss: 0.3623  Val_Acc: 85.666

Epoch 13: Validation loss decreased (0.362320 --> 0.359862).  Saving model ...
	 Train_Loss: 0.4596 Train_Acc: 77.397 Val_Loss: 0.3599  BEST VAL Loss: 0.3599  Val_Acc: 85.896

Epoch 14: Validation loss decreased (0.359862 --> 0.357473).  Saving model ...
	 Train_Loss: 0.4578 Train_Acc: 77.377 Val_Loss: 0.3575  BEST VAL Loss: 0.3575  Val_Acc: 85.792

Epoch 15: Validation loss decreased (0.357473 --> 0.355240).  Saving model ...
	 Train_Loss: 0.4561 Train_Acc: 77.462 Val_Loss: 0.3552  BEST VAL Loss: 0.3552  Val_Acc: 86.219

Epoch 16: Validation loss decreased (0.355240 --> 0.353067).  Saving model ...
	 Train_Loss: 0.4546 Train_Acc: 77.449 Val_Loss: 0.3531  BEST VAL Loss: 0.3531  Val_Acc: 86.257

Epoch 17: Validation loss decreased (0.353067 --> 0.351307).  Saving model ...
	 Train_Loss: 0.4532 Train_Acc: 77.553 Val_Loss: 0.3513  BEST VAL Loss: 0.3513  Val_Acc: 86.154

Epoch 18: Validation loss decreased (0.351307 --> 0.349685).  Saving model ...
	 Train_Loss: 0.4518 Train_Acc: 77.694 Val_Loss: 0.3497  BEST VAL Loss: 0.3497  Val_Acc: 86.109

Epoch 19: Validation loss decreased (0.349685 --> 0.348073).  Saving model ...
	 Train_Loss: 0.4505 Train_Acc: 77.689 Val_Loss: 0.3481  BEST VAL Loss: 0.3481  Val_Acc: 86.354

Epoch 20: Validation loss decreased (0.348073 --> 0.346506).  Saving model ...
	 Train_Loss: 0.4493 Train_Acc: 77.801 Val_Loss: 0.3465  BEST VAL Loss: 0.3465  Val_Acc: 86.180

Epoch 21: Validation loss decreased (0.346506 --> 0.344999).  Saving model ...
	 Train_Loss: 0.4482 Train_Acc: 77.724 Val_Loss: 0.3450  BEST VAL Loss: 0.3450  Val_Acc: 86.338

Epoch 22: Validation loss decreased (0.344999 --> 0.343541).  Saving model ...
	 Train_Loss: 0.4472 Train_Acc: 77.737 Val_Loss: 0.3435  BEST VAL Loss: 0.3435  Val_Acc: 86.516

Epoch 23: Validation loss decreased (0.343541 --> 0.342169).  Saving model ...
	 Train_Loss: 0.4462 Train_Acc: 77.829 Val_Loss: 0.3422  BEST VAL Loss: 0.3422  Val_Acc: 86.593

Epoch 24: Validation loss decreased (0.342169 --> 0.340971).  Saving model ...
	 Train_Loss: 0.4453 Train_Acc: 77.819 Val_Loss: 0.3410  BEST VAL Loss: 0.3410  Val_Acc: 86.516

Epoch 25: Validation loss decreased (0.340971 --> 0.339806).  Saving model ...
	 Train_Loss: 0.4444 Train_Acc: 77.896 Val_Loss: 0.3398  BEST VAL Loss: 0.3398  Val_Acc: 86.619

Epoch 26: Validation loss decreased (0.339806 --> 0.338625).  Saving model ...
	 Train_Loss: 0.4435 Train_Acc: 77.953 Val_Loss: 0.3386  BEST VAL Loss: 0.3386  Val_Acc: 86.745

Epoch 27: Validation loss decreased (0.338625 --> 0.337458).  Saving model ...
	 Train_Loss: 0.4426 Train_Acc: 78.096 Val_Loss: 0.3375  BEST VAL Loss: 0.3375  Val_Acc: 86.800

Epoch 28: Validation loss decreased (0.337458 --> 0.336491).  Saving model ...
	 Train_Loss: 0.4419 Train_Acc: 78.060 Val_Loss: 0.3365  BEST VAL Loss: 0.3365  Val_Acc: 86.868

Epoch 29: Validation loss decreased (0.336491 --> 0.335619).  Saving model ...
	 Train_Loss: 0.4411 Train_Acc: 78.235 Val_Loss: 0.3356  BEST VAL Loss: 0.3356  Val_Acc: 86.719

Epoch 30: Validation loss decreased (0.335619 --> 0.334710).  Saving model ...
	 Train_Loss: 0.4404 Train_Acc: 77.943 Val_Loss: 0.3347  BEST VAL Loss: 0.3347  Val_Acc: 86.690

Epoch 31: Validation loss decreased (0.334710 --> 0.333732).  Saving model ...
	 Train_Loss: 0.4396 Train_Acc: 78.273 Val_Loss: 0.3337  BEST VAL Loss: 0.3337  Val_Acc: 87.217

Epoch 32: Validation loss decreased (0.333732 --> 0.332904).  Saving model ...
	 Train_Loss: 0.4390 Train_Acc: 78.227 Val_Loss: 0.3329  BEST VAL Loss: 0.3329  Val_Acc: 86.829

Epoch 33: Validation loss decreased (0.332904 --> 0.332278).  Saving model ...
	 Train_Loss: 0.4383 Train_Acc: 78.322 Val_Loss: 0.3323  BEST VAL Loss: 0.3323  Val_Acc: 86.904

Epoch 34: Validation loss decreased (0.332278 --> 0.331444).  Saving model ...
	 Train_Loss: 0.4377 Train_Acc: 78.292 Val_Loss: 0.3314  BEST VAL Loss: 0.3314  Val_Acc: 87.078

Epoch 35: Validation loss decreased (0.331444 --> 0.330700).  Saving model ...
	 Train_Loss: 0.4371 Train_Acc: 78.284 Val_Loss: 0.3307  BEST VAL Loss: 0.3307  Val_Acc: 87.159

Epoch 36: Validation loss decreased (0.330700 --> 0.330056).  Saving model ...
	 Train_Loss: 0.4365 Train_Acc: 78.301 Val_Loss: 0.3301  BEST VAL Loss: 0.3301  Val_Acc: 87.030

Epoch 37: Validation loss decreased (0.330056 --> 0.329349).  Saving model ...
	 Train_Loss: 0.4359 Train_Acc: 78.257 Val_Loss: 0.3293  BEST VAL Loss: 0.3293  Val_Acc: 87.078

Epoch 38: Validation loss decreased (0.329349 --> 0.328631).  Saving model ...
	 Train_Loss: 0.4353 Train_Acc: 78.366 Val_Loss: 0.3286  BEST VAL Loss: 0.3286  Val_Acc: 87.194

Epoch 39: Validation loss decreased (0.328631 --> 0.327943).  Saving model ...
	 Train_Loss: 0.4348 Train_Acc: 78.429 Val_Loss: 0.3279  BEST VAL Loss: 0.3279  Val_Acc: 87.446

Epoch 40: Validation loss decreased (0.327943 --> 0.327223).  Saving model ...
	 Train_Loss: 0.4343 Train_Acc: 78.477 Val_Loss: 0.3272  BEST VAL Loss: 0.3272  Val_Acc: 87.556

Epoch 41: Validation loss decreased (0.327223 --> 0.326548).  Saving model ...
	 Train_Loss: 0.4337 Train_Acc: 78.526 Val_Loss: 0.3265  BEST VAL Loss: 0.3265  Val_Acc: 87.433

Epoch 42: Validation loss decreased (0.326548 --> 0.325901).  Saving model ...
	 Train_Loss: 0.4332 Train_Acc: 78.524 Val_Loss: 0.3259  BEST VAL Loss: 0.3259  Val_Acc: 87.420

Epoch 43: Validation loss decreased (0.325901 --> 0.325233).  Saving model ...
	 Train_Loss: 0.4327 Train_Acc: 78.478 Val_Loss: 0.3252  BEST VAL Loss: 0.3252  Val_Acc: 87.375

Epoch 44: Validation loss decreased (0.325233 --> 0.324684).  Saving model ...
	 Train_Loss: 0.4322 Train_Acc: 78.475 Val_Loss: 0.3247  BEST VAL Loss: 0.3247  Val_Acc: 87.107

Epoch 45: Validation loss decreased (0.324684 --> 0.324095).  Saving model ...
	 Train_Loss: 0.4318 Train_Acc: 78.641 Val_Loss: 0.3241  BEST VAL Loss: 0.3241  Val_Acc: 87.336

Epoch 46: Validation loss decreased (0.324095 --> 0.323512).  Saving model ...
	 Train_Loss: 0.4314 Train_Acc: 78.623 Val_Loss: 0.3235  BEST VAL Loss: 0.3235  Val_Acc: 87.265

Epoch 47: Validation loss decreased (0.323512 --> 0.323062).  Saving model ...
	 Train_Loss: 0.4309 Train_Acc: 78.544 Val_Loss: 0.3231  BEST VAL Loss: 0.3231  Val_Acc: 87.498

Epoch 48: Validation loss decreased (0.323062 --> 0.322521).  Saving model ...
	 Train_Loss: 0.4305 Train_Acc: 78.621 Val_Loss: 0.3225  BEST VAL Loss: 0.3225  Val_Acc: 87.718

Epoch 49: Validation loss decreased (0.322521 --> 0.322049).  Saving model ...
	 Train_Loss: 0.4301 Train_Acc: 78.620 Val_Loss: 0.3220  BEST VAL Loss: 0.3220  Val_Acc: 87.650

Epoch 50: Validation loss decreased (0.322049 --> 0.321561).  Saving model ...
	 Train_Loss: 0.4297 Train_Acc: 78.646 Val_Loss: 0.3216  BEST VAL Loss: 0.3216  Val_Acc: 87.514

Epoch 51: Validation loss decreased (0.321561 --> 0.321205).  Saving model ...
	 Train_Loss: 0.4293 Train_Acc: 78.658 Val_Loss: 0.3212  BEST VAL Loss: 0.3212  Val_Acc: 87.097

Epoch 52: Validation loss decreased (0.321205 --> 0.320803).  Saving model ...
	 Train_Loss: 0.4289 Train_Acc: 78.645 Val_Loss: 0.3208  BEST VAL Loss: 0.3208  Val_Acc: 87.501

Epoch 53: Validation loss decreased (0.320803 --> 0.320323).  Saving model ...
	 Train_Loss: 0.4285 Train_Acc: 78.714 Val_Loss: 0.3203  BEST VAL Loss: 0.3203  Val_Acc: 87.550

Epoch 54: Validation loss decreased (0.320323 --> 0.319968).  Saving model ...
	 Train_Loss: 0.4281 Train_Acc: 78.705 Val_Loss: 0.3200  BEST VAL Loss: 0.3200  Val_Acc: 87.398

Epoch 55: Validation loss decreased (0.319968 --> 0.319460).  Saving model ...
	 Train_Loss: 0.4278 Train_Acc: 78.782 Val_Loss: 0.3195  BEST VAL Loss: 0.3195  Val_Acc: 87.724

Epoch 56: Validation loss decreased (0.319460 --> 0.318910).  Saving model ...
	 Train_Loss: 0.4274 Train_Acc: 78.687 Val_Loss: 0.3189  BEST VAL Loss: 0.3189  Val_Acc: 87.789

Epoch 57: Validation loss decreased (0.318910 --> 0.318454).  Saving model ...
	 Train_Loss: 0.4271 Train_Acc: 78.761 Val_Loss: 0.3185  BEST VAL Loss: 0.3185  Val_Acc: 87.808

Epoch 58: Validation loss decreased (0.318454 --> 0.317937).  Saving model ...
	 Train_Loss: 0.4267 Train_Acc: 78.854 Val_Loss: 0.3179  BEST VAL Loss: 0.3179  Val_Acc: 87.740

Epoch 59: Validation loss decreased (0.317937 --> 0.317447).  Saving model ...
	 Train_Loss: 0.4263 Train_Acc: 78.814 Val_Loss: 0.3174  BEST VAL Loss: 0.3174  Val_Acc: 87.734

Epoch 60: Validation loss decreased (0.317447 --> 0.316939).  Saving model ...
	 Train_Loss: 0.4260 Train_Acc: 78.827 Val_Loss: 0.3169  BEST VAL Loss: 0.3169  Val_Acc: 88.076

Epoch 61: Validation loss decreased (0.316939 --> 0.316527).  Saving model ...
	 Train_Loss: 0.4257 Train_Acc: 78.936 Val_Loss: 0.3165  BEST VAL Loss: 0.3165  Val_Acc: 88.105

Epoch 62: Validation loss decreased (0.316527 --> 0.316033).  Saving model ...
	 Train_Loss: 0.4254 Train_Acc: 78.774 Val_Loss: 0.3160  BEST VAL Loss: 0.3160  Val_Acc: 87.966

Epoch 63: Validation loss decreased (0.316033 --> 0.315577).  Saving model ...
	 Train_Loss: 0.4251 Train_Acc: 78.722 Val_Loss: 0.3156  BEST VAL Loss: 0.3156  Val_Acc: 87.966

Epoch 64: Validation loss decreased (0.315577 --> 0.315178).  Saving model ...
	 Train_Loss: 0.4248 Train_Acc: 78.821 Val_Loss: 0.3152  BEST VAL Loss: 0.3152  Val_Acc: 87.889

Epoch 65: Validation loss decreased (0.315178 --> 0.314757).  Saving model ...
	 Train_Loss: 0.4245 Train_Acc: 78.828 Val_Loss: 0.3148  BEST VAL Loss: 0.3148  Val_Acc: 87.915

Epoch 66: Validation loss decreased (0.314757 --> 0.314362).  Saving model ...
	 Train_Loss: 0.4242 Train_Acc: 78.884 Val_Loss: 0.3144  BEST VAL Loss: 0.3144  Val_Acc: 87.908

Epoch 67: Validation loss decreased (0.314362 --> 0.314012).  Saving model ...
	 Train_Loss: 0.4239 Train_Acc: 78.963 Val_Loss: 0.3140  BEST VAL Loss: 0.3140  Val_Acc: 88.128

Epoch 68: Validation loss decreased (0.314012 --> 0.313652).  Saving model ...
	 Train_Loss: 0.4236 Train_Acc: 78.945 Val_Loss: 0.3137  BEST VAL Loss: 0.3137  Val_Acc: 87.827

Epoch 69: Validation loss decreased (0.313652 --> 0.313208).  Saving model ...
	 Train_Loss: 0.4233 Train_Acc: 78.847 Val_Loss: 0.3132  BEST VAL Loss: 0.3132  Val_Acc: 87.899

Epoch 70: Validation loss decreased (0.313208 --> 0.312849).  Saving model ...
	 Train_Loss: 0.4230 Train_Acc: 78.950 Val_Loss: 0.3128  BEST VAL Loss: 0.3128  Val_Acc: 88.037

Epoch 71: Validation loss decreased (0.312849 --> 0.312515).  Saving model ...
	 Train_Loss: 0.4227 Train_Acc: 79.050 Val_Loss: 0.3125  BEST VAL Loss: 0.3125  Val_Acc: 87.983

Epoch 72: Validation loss decreased (0.312515 --> 0.312184).  Saving model ...
	 Train_Loss: 0.4225 Train_Acc: 79.042 Val_Loss: 0.3122  BEST VAL Loss: 0.3122  Val_Acc: 88.199

Epoch 73: Validation loss decreased (0.312184 --> 0.311839).  Saving model ...
	 Train_Loss: 0.4222 Train_Acc: 79.057 Val_Loss: 0.3118  BEST VAL Loss: 0.3118  Val_Acc: 88.183

Epoch 74: Validation loss decreased (0.311839 --> 0.311433).  Saving model ...
	 Train_Loss: 0.4219 Train_Acc: 78.928 Val_Loss: 0.3114  BEST VAL Loss: 0.3114  Val_Acc: 88.280

Epoch 75: Validation loss decreased (0.311433 --> 0.311023).  Saving model ...
	 Train_Loss: 0.4217 Train_Acc: 79.060 Val_Loss: 0.3110  BEST VAL Loss: 0.3110  Val_Acc: 88.138

Epoch 76: Validation loss decreased (0.311023 --> 0.310748).  Saving model ...
	 Train_Loss: 0.4214 Train_Acc: 79.051 Val_Loss: 0.3107  BEST VAL Loss: 0.3107  Val_Acc: 88.254

Epoch 77: Validation loss decreased (0.310748 --> 0.310371).  Saving model ...
	 Train_Loss: 0.4211 Train_Acc: 79.059 Val_Loss: 0.3104  BEST VAL Loss: 0.3104  Val_Acc: 88.118

Epoch 78: Validation loss decreased (0.310371 --> 0.310022).  Saving model ...
	 Train_Loss: 0.4209 Train_Acc: 79.052 Val_Loss: 0.3100  BEST VAL Loss: 0.3100  Val_Acc: 88.302

Epoch 79: Validation loss decreased (0.310022 --> 0.309687).  Saving model ...
	 Train_Loss: 0.4207 Train_Acc: 79.177 Val_Loss: 0.3097  BEST VAL Loss: 0.3097  Val_Acc: 88.186

Epoch 80: Validation loss decreased (0.309687 --> 0.309343).  Saving model ...
	 Train_Loss: 0.4204 Train_Acc: 79.163 Val_Loss: 0.3093  BEST VAL Loss: 0.3093  Val_Acc: 88.151

Epoch 81: Validation loss decreased (0.309343 --> 0.308989).  Saving model ...
	 Train_Loss: 0.4202 Train_Acc: 79.038 Val_Loss: 0.3090  BEST VAL Loss: 0.3090  Val_Acc: 88.163

Epoch 82: Validation loss decreased (0.308989 --> 0.308676).  Saving model ...
	 Train_Loss: 0.4199 Train_Acc: 79.163 Val_Loss: 0.3087  BEST VAL Loss: 0.3087  Val_Acc: 88.154

Epoch 83: Validation loss decreased (0.308676 --> 0.308372).  Saving model ...
	 Train_Loss: 0.4197 Train_Acc: 79.077 Val_Loss: 0.3084  BEST VAL Loss: 0.3084  Val_Acc: 88.118

Epoch 84: Validation loss decreased (0.308372 --> 0.308169).  Saving model ...
	 Train_Loss: 0.4195 Train_Acc: 79.073 Val_Loss: 0.3082  BEST VAL Loss: 0.3082  Val_Acc: 87.928

Epoch 85: Validation loss decreased (0.308169 --> 0.307866).  Saving model ...
	 Train_Loss: 0.4193 Train_Acc: 79.081 Val_Loss: 0.3079  BEST VAL Loss: 0.3079  Val_Acc: 88.170

Epoch 86: Validation loss decreased (0.307866 --> 0.307616).  Saving model ...
	 Train_Loss: 0.4191 Train_Acc: 79.094 Val_Loss: 0.3076  BEST VAL Loss: 0.3076  Val_Acc: 88.280

Epoch 87: Validation loss decreased (0.307616 --> 0.307378).  Saving model ...
	 Train_Loss: 0.4189 Train_Acc: 79.227 Val_Loss: 0.3074  BEST VAL Loss: 0.3074  Val_Acc: 88.228

Epoch 88: Validation loss decreased (0.307378 --> 0.307080).  Saving model ...
	 Train_Loss: 0.4186 Train_Acc: 79.238 Val_Loss: 0.3071  BEST VAL Loss: 0.3071  Val_Acc: 88.451

Epoch 89: Validation loss decreased (0.307080 --> 0.306806).  Saving model ...
	 Train_Loss: 0.4184 Train_Acc: 79.173 Val_Loss: 0.3068  BEST VAL Loss: 0.3068  Val_Acc: 88.341

Epoch 90: Validation loss decreased (0.306806 --> 0.306539).  Saving model ...
	 Train_Loss: 0.4182 Train_Acc: 79.149 Val_Loss: 0.3065  BEST VAL Loss: 0.3065  Val_Acc: 88.131

Epoch 91: Validation loss decreased (0.306539 --> 0.306247).  Saving model ...
	 Train_Loss: 0.4180 Train_Acc: 79.265 Val_Loss: 0.3062  BEST VAL Loss: 0.3062  Val_Acc: 88.128

Epoch 92: Validation loss decreased (0.306247 --> 0.305950).  Saving model ...
	 Train_Loss: 0.4178 Train_Acc: 79.218 Val_Loss: 0.3059  BEST VAL Loss: 0.3059  Val_Acc: 88.202

Epoch 93: Validation loss decreased (0.305950 --> 0.305674).  Saving model ...
	 Train_Loss: 0.4176 Train_Acc: 79.344 Val_Loss: 0.3057  BEST VAL Loss: 0.3057  Val_Acc: 88.558

Epoch 94: Validation loss decreased (0.305674 --> 0.305369).  Saving model ...
	 Train_Loss: 0.4174 Train_Acc: 79.220 Val_Loss: 0.3054  BEST VAL Loss: 0.3054  Val_Acc: 88.651

Epoch 95: Validation loss decreased (0.305369 --> 0.305166).  Saving model ...
	 Train_Loss: 0.4172 Train_Acc: 79.220 Val_Loss: 0.3052  BEST VAL Loss: 0.3052  Val_Acc: 87.915

Epoch 96: Validation loss decreased (0.305166 --> 0.304908).  Saving model ...
	 Train_Loss: 0.4170 Train_Acc: 79.247 Val_Loss: 0.3049  BEST VAL Loss: 0.3049  Val_Acc: 88.302

Epoch 97: Validation loss decreased (0.304908 --> 0.304642).  Saving model ...
	 Train_Loss: 0.4168 Train_Acc: 79.319 Val_Loss: 0.3046  BEST VAL Loss: 0.3046  Val_Acc: 88.435

Epoch 98: Validation loss decreased (0.304642 --> 0.304419).  Saving model ...
	 Train_Loss: 0.4166 Train_Acc: 79.342 Val_Loss: 0.3044  BEST VAL Loss: 0.3044  Val_Acc: 88.390

Epoch 99: Validation loss decreased (0.304419 --> 0.304163).  Saving model ...
	 Train_Loss: 0.4164 Train_Acc: 79.319 Val_Loss: 0.3042  BEST VAL Loss: 0.3042  Val_Acc: 88.228

LPS_100.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.90      0.94      0.92    149884
           1       0.90      0.83      0.86     97754

    accuracy                           0.90    247638
   macro avg       0.90      0.88      0.89    247638
weighted avg       0.90      0.90      0.90    247638

LPS_100.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.89      0.93      0.90     18736
           1       0.88      0.82      0.85     12219

    accuracy                           0.88     30955
   macro avg       0.88      0.87      0.88     30955
weighted avg       0.88      0.88      0.88     30955

LPS_100.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.88      0.93      0.90     18736
           1       0.88      0.81      0.84     12219

    accuracy                           0.88     30955
   macro avg       0.88      0.87      0.87     30955
weighted avg       0.88      0.88      0.88     30955

              precision    recall  f1-score   support

           0       0.88      0.93      0.90     18736
           1       0.88      0.81      0.84     12219

    accuracy                           0.88     30955
   macro avg       0.88      0.87      0.87     30955
weighted avg       0.88      0.88      0.88     30955

LPS_100.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.60      0.90      0.72     27774
           1       0.88      0.56      0.69     37243

    accuracy                           0.71     65017
   macro avg       0.74      0.73      0.70     65017
weighted avg       0.76      0.71      0.70     65017

              precision    recall  f1-score   support

           0       0.60      0.90      0.72     27774
           1       0.88      0.56      0.69     37243

    accuracy                           0.71     65017
   macro avg       0.74      0.73      0.70     65017
weighted avg       0.76      0.71      0.70     65017

completed
