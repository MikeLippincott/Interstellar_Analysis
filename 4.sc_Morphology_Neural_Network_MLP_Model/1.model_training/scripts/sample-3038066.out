[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '0292ebf5'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '3146a867'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '0d99ca3c'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'f4e0fe54'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_0.100_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_0.100_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (312858, 1270)
Number of total missing values across all columns: 277194
Data Subset Is Off
Wells held out for testing: ['C09' 'L09']
Wells to use for training, validation, and testing ['C02' 'C03' 'C08' 'L02' 'L03' 'L08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.331607).  Saving model ...
	 Train_Loss: 0.5157 Train_Acc: 72.529 Val_Loss: 0.3316  BEST VAL Loss: 0.3316  Val_Acc: 87.651

Epoch 1: Validation loss decreased (0.331607 --> 0.296108).  Saving model ...
	 Train_Loss: 0.4223 Train_Acc: 87.595 Val_Loss: 0.2961  BEST VAL Loss: 0.2961  Val_Acc: 90.635

Epoch 2: Validation loss decreased (0.296108 --> 0.273155).  Saving model ...
	 Train_Loss: 0.3748 Train_Acc: 89.733 Val_Loss: 0.2732  BEST VAL Loss: 0.2732  Val_Acc: 91.602

Epoch 3: Validation loss decreased (0.273155 --> 0.256216).  Saving model ...
	 Train_Loss: 0.3447 Train_Acc: 90.670 Val_Loss: 0.2562  BEST VAL Loss: 0.2562  Val_Acc: 92.391

Epoch 4: Validation loss decreased (0.256216 --> 0.242423).  Saving model ...
	 Train_Loss: 0.3227 Train_Acc: 91.492 Val_Loss: 0.2424  BEST VAL Loss: 0.2424  Val_Acc: 92.961

Epoch 5: Validation loss decreased (0.242423 --> 0.232723).  Saving model ...
	 Train_Loss: 0.3062 Train_Acc: 91.817 Val_Loss: 0.2327  BEST VAL Loss: 0.2327  Val_Acc: 93.197

Epoch 6: Validation loss decreased (0.232723 --> 0.224812).  Saving model ...
	 Train_Loss: 0.2931 Train_Acc: 92.194 Val_Loss: 0.2248  BEST VAL Loss: 0.2248  Val_Acc: 93.416

Epoch 7: Validation loss decreased (0.224812 --> 0.217576).  Saving model ...
	 Train_Loss: 0.2824 Train_Acc: 92.441 Val_Loss: 0.2176  BEST VAL Loss: 0.2176  Val_Acc: 93.746

Epoch 8: Validation loss decreased (0.217576 --> 0.211764).  Saving model ...
	 Train_Loss: 0.2734 Train_Acc: 92.644 Val_Loss: 0.2118  BEST VAL Loss: 0.2118  Val_Acc: 93.779

Epoch 9: Validation loss decreased (0.211764 --> 0.207284).  Saving model ...
	 Train_Loss: 0.2657 Train_Acc: 92.826 Val_Loss: 0.2073  BEST VAL Loss: 0.2073  Val_Acc: 93.640

Epoch 10: Validation loss decreased (0.207284 --> 0.202482).  Saving model ...
	 Train_Loss: 0.2590 Train_Acc: 93.042 Val_Loss: 0.2025  BEST VAL Loss: 0.2025  Val_Acc: 94.159

Epoch 11: Validation loss decreased (0.202482 --> 0.198814).  Saving model ...
	 Train_Loss: 0.2530 Train_Acc: 93.134 Val_Loss: 0.1988  BEST VAL Loss: 0.1988  Val_Acc: 93.919

Epoch 12: Validation loss decreased (0.198814 --> 0.195210).  Saving model ...
	 Train_Loss: 0.2478 Train_Acc: 93.227 Val_Loss: 0.1952  BEST VAL Loss: 0.1952  Val_Acc: 94.269

Epoch 13: Validation loss decreased (0.195210 --> 0.192633).  Saving model ...
	 Train_Loss: 0.2432 Train_Acc: 93.326 Val_Loss: 0.1926  BEST VAL Loss: 0.1926  Val_Acc: 94.113

Epoch 14: Validation loss decreased (0.192633 --> 0.189803).  Saving model ...
	 Train_Loss: 0.2390 Train_Acc: 93.410 Val_Loss: 0.1898  BEST VAL Loss: 0.1898  Val_Acc: 94.345

Epoch 15: Validation loss decreased (0.189803 --> 0.187412).  Saving model ...
	 Train_Loss: 0.2352 Train_Acc: 93.500 Val_Loss: 0.1874  BEST VAL Loss: 0.1874  Val_Acc: 94.370

Epoch 16: Validation loss decreased (0.187412 --> 0.184820).  Saving model ...
	 Train_Loss: 0.2318 Train_Acc: 93.577 Val_Loss: 0.1848  BEST VAL Loss: 0.1848  Val_Acc: 94.699

Epoch 17: Validation loss decreased (0.184820 --> 0.182878).  Saving model ...
	 Train_Loss: 0.2285 Train_Acc: 93.619 Val_Loss: 0.1829  BEST VAL Loss: 0.1829  Val_Acc: 94.286

Epoch 18: Validation loss decreased (0.182878 --> 0.180934).  Saving model ...
	 Train_Loss: 0.2256 Train_Acc: 93.724 Val_Loss: 0.1809  BEST VAL Loss: 0.1809  Val_Acc: 94.442

Epoch 19: Validation loss decreased (0.180934 --> 0.179164).  Saving model ...
	 Train_Loss: 0.2228 Train_Acc: 93.719 Val_Loss: 0.1792  BEST VAL Loss: 0.1792  Val_Acc: 94.455

Epoch 20: Validation loss decreased (0.179164 --> 0.177295).  Saving model ...
	 Train_Loss: 0.2203 Train_Acc: 93.681 Val_Loss: 0.1773  BEST VAL Loss: 0.1773  Val_Acc: 94.682

Epoch 21: Validation loss decreased (0.177295 --> 0.175537).  Saving model ...
	 Train_Loss: 0.2179 Train_Acc: 93.794 Val_Loss: 0.1755  BEST VAL Loss: 0.1755  Val_Acc: 94.860

Epoch 22: Validation loss decreased (0.175537 --> 0.173780).  Saving model ...
	 Train_Loss: 0.2156 Train_Acc: 93.865 Val_Loss: 0.1738  BEST VAL Loss: 0.1738  Val_Acc: 94.872

Epoch 23: Validation loss decreased (0.173780 --> 0.172420).  Saving model ...
	 Train_Loss: 0.2134 Train_Acc: 93.897 Val_Loss: 0.1724  BEST VAL Loss: 0.1724  Val_Acc: 94.501

Epoch 24: Validation loss decreased (0.172420 --> 0.171213).  Saving model ...
	 Train_Loss: 0.2114 Train_Acc: 93.862 Val_Loss: 0.1712  BEST VAL Loss: 0.1712  Val_Acc: 94.670

Epoch 25: Validation loss decreased (0.171213 --> 0.170015).  Saving model ...
	 Train_Loss: 0.2095 Train_Acc: 93.975 Val_Loss: 0.1700  BEST VAL Loss: 0.1700  Val_Acc: 94.801

Epoch 26: Validation loss decreased (0.170015 --> 0.168792).  Saving model ...
	 Train_Loss: 0.2078 Train_Acc: 93.916 Val_Loss: 0.1688  BEST VAL Loss: 0.1688  Val_Acc: 94.822

Epoch 27: Validation loss decreased (0.168792 --> 0.167622).  Saving model ...
	 Train_Loss: 0.2061 Train_Acc: 94.001 Val_Loss: 0.1676  BEST VAL Loss: 0.1676  Val_Acc: 94.792

Epoch 28: Validation loss decreased (0.167622 --> 0.166941).  Saving model ...
	 Train_Loss: 0.2045 Train_Acc: 94.122 Val_Loss: 0.1669  BEST VAL Loss: 0.1669  Val_Acc: 94.708

Epoch 29: Validation loss decreased (0.166941 --> 0.165795).  Saving model ...
	 Train_Loss: 0.2030 Train_Acc: 94.008 Val_Loss: 0.1658  BEST VAL Loss: 0.1658  Val_Acc: 94.965

Epoch 30: Validation loss decreased (0.165795 --> 0.164775).  Saving model ...
	 Train_Loss: 0.2016 Train_Acc: 94.005 Val_Loss: 0.1648  BEST VAL Loss: 0.1648  Val_Acc: 94.822

Epoch 31: Validation loss decreased (0.164775 --> 0.163749).  Saving model ...
	 Train_Loss: 0.2002 Train_Acc: 94.059 Val_Loss: 0.1637  BEST VAL Loss: 0.1637  Val_Acc: 95.016

Epoch 32: Validation loss decreased (0.163749 --> 0.162779).  Saving model ...
	 Train_Loss: 0.1989 Train_Acc: 94.031 Val_Loss: 0.1628  BEST VAL Loss: 0.1628  Val_Acc: 95.045

Epoch 33: Validation loss decreased (0.162779 --> 0.161959).  Saving model ...
	 Train_Loss: 0.1977 Train_Acc: 94.046 Val_Loss: 0.1620  BEST VAL Loss: 0.1620  Val_Acc: 94.864

Epoch 34: Validation loss decreased (0.161959 --> 0.161145).  Saving model ...
	 Train_Loss: 0.1964 Train_Acc: 94.210 Val_Loss: 0.1611  BEST VAL Loss: 0.1611  Val_Acc: 94.792

Epoch 35: Validation loss decreased (0.161145 --> 0.160410).  Saving model ...
	 Train_Loss: 0.1952 Train_Acc: 94.076 Val_Loss: 0.1604  BEST VAL Loss: 0.1604  Val_Acc: 94.784

Epoch 36: Validation loss decreased (0.160410 --> 0.159702).  Saving model ...
	 Train_Loss: 0.1941 Train_Acc: 94.161 Val_Loss: 0.1597  BEST VAL Loss: 0.1597  Val_Acc: 94.712

Epoch 37: Validation loss decreased (0.159702 --> 0.158971).  Saving model ...
	 Train_Loss: 0.1931 Train_Acc: 94.137 Val_Loss: 0.1590  BEST VAL Loss: 0.1590  Val_Acc: 94.898

Epoch 38: Validation loss decreased (0.158971 --> 0.158345).  Saving model ...
	 Train_Loss: 0.1920 Train_Acc: 94.218 Val_Loss: 0.1583  BEST VAL Loss: 0.1583  Val_Acc: 94.839

Epoch 39: Validation loss decreased (0.158345 --> 0.157675).  Saving model ...
	 Train_Loss: 0.1910 Train_Acc: 94.240 Val_Loss: 0.1577  BEST VAL Loss: 0.1577  Val_Acc: 94.969

Epoch 40: Validation loss decreased (0.157675 --> 0.157033).  Saving model ...
	 Train_Loss: 0.1900 Train_Acc: 94.180 Val_Loss: 0.1570  BEST VAL Loss: 0.1570  Val_Acc: 94.893

Epoch 41: Validation loss decreased (0.157033 --> 0.156505).  Saving model ...
	 Train_Loss: 0.1891 Train_Acc: 94.212 Val_Loss: 0.1565  BEST VAL Loss: 0.1565  Val_Acc: 94.978

Epoch 42: Validation loss decreased (0.156505 --> 0.155865).  Saving model ...
	 Train_Loss: 0.1882 Train_Acc: 94.250 Val_Loss: 0.1559  BEST VAL Loss: 0.1559  Val_Acc: 94.982

Epoch 43: Validation loss decreased (0.155865 --> 0.155245).  Saving model ...
	 Train_Loss: 0.1873 Train_Acc: 94.277 Val_Loss: 0.1552  BEST VAL Loss: 0.1552  Val_Acc: 94.948

Epoch 44: Validation loss decreased (0.155245 --> 0.154643).  Saving model ...
	 Train_Loss: 0.1865 Train_Acc: 94.290 Val_Loss: 0.1546  BEST VAL Loss: 0.1546  Val_Acc: 95.020

Epoch 45: Validation loss decreased (0.154643 --> 0.154088).  Saving model ...
	 Train_Loss: 0.1856 Train_Acc: 94.419 Val_Loss: 0.1541  BEST VAL Loss: 0.1541  Val_Acc: 94.974

Epoch 46: Validation loss decreased (0.154088 --> 0.153540).  Saving model ...
	 Train_Loss: 0.1848 Train_Acc: 94.294 Val_Loss: 0.1535  BEST VAL Loss: 0.1535  Val_Acc: 95.096

Epoch 47: Validation loss decreased (0.153540 --> 0.153037).  Saving model ...
	 Train_Loss: 0.1841 Train_Acc: 94.366 Val_Loss: 0.1530  BEST VAL Loss: 0.1530  Val_Acc: 95.037

Epoch 48: Validation loss decreased (0.153037 --> 0.152509).  Saving model ...
	 Train_Loss: 0.1833 Train_Acc: 94.323 Val_Loss: 0.1525  BEST VAL Loss: 0.1525  Val_Acc: 95.151

Epoch 49: Validation loss decreased (0.152509 --> 0.152124).  Saving model ...
	 Train_Loss: 0.1826 Train_Acc: 94.361 Val_Loss: 0.1521  BEST VAL Loss: 0.1521  Val_Acc: 94.931

Epoch 50: Validation loss decreased (0.152124 --> 0.151648).  Saving model ...
	 Train_Loss: 0.1819 Train_Acc: 94.369 Val_Loss: 0.1516  BEST VAL Loss: 0.1516  Val_Acc: 95.134

Epoch 51: Validation loss decreased (0.151648 --> 0.151240).  Saving model ...
	 Train_Loss: 0.1812 Train_Acc: 94.354 Val_Loss: 0.1512  BEST VAL Loss: 0.1512  Val_Acc: 95.003

Epoch 52: Validation loss decreased (0.151240 --> 0.150774).  Saving model ...
	 Train_Loss: 0.1805 Train_Acc: 94.417 Val_Loss: 0.1508  BEST VAL Loss: 0.1508  Val_Acc: 95.126

Epoch 53: Validation loss decreased (0.150774 --> 0.150371).  Saving model ...
	 Train_Loss: 0.1799 Train_Acc: 94.380 Val_Loss: 0.1504  BEST VAL Loss: 0.1504  Val_Acc: 95.062

Epoch 54: Validation loss decreased (0.150371 --> 0.150025).  Saving model ...
	 Train_Loss: 0.1792 Train_Acc: 94.381 Val_Loss: 0.1500  BEST VAL Loss: 0.1500  Val_Acc: 95.062

Epoch 55: Validation loss decreased (0.150025 --> 0.149593).  Saving model ...
	 Train_Loss: 0.1786 Train_Acc: 94.375 Val_Loss: 0.1496  BEST VAL Loss: 0.1496  Val_Acc: 95.104

Epoch 56: Validation loss decreased (0.149593 --> 0.149171).  Saving model ...
	 Train_Loss: 0.1780 Train_Acc: 94.492 Val_Loss: 0.1492  BEST VAL Loss: 0.1492  Val_Acc: 95.151

Epoch 57: Validation loss decreased (0.149171 --> 0.148774).  Saving model ...
	 Train_Loss: 0.1774 Train_Acc: 94.468 Val_Loss: 0.1488  BEST VAL Loss: 0.1488  Val_Acc: 95.121

Epoch 58: Validation loss decreased (0.148774 --> 0.148439).  Saving model ...
	 Train_Loss: 0.1768 Train_Acc: 94.464 Val_Loss: 0.1484  BEST VAL Loss: 0.1484  Val_Acc: 94.898

Epoch 59: Validation loss decreased (0.148439 --> 0.148096).  Saving model ...
	 Train_Loss: 0.1762 Train_Acc: 94.477 Val_Loss: 0.1481  BEST VAL Loss: 0.1481  Val_Acc: 95.033

Epoch 60: Validation loss decreased (0.148096 --> 0.147785).  Saving model ...
	 Train_Loss: 0.1757 Train_Acc: 94.474 Val_Loss: 0.1478  BEST VAL Loss: 0.1478  Val_Acc: 95.012

Epoch 61: Validation loss decreased (0.147785 --> 0.147447).  Saving model ...
	 Train_Loss: 0.1751 Train_Acc: 94.545 Val_Loss: 0.1474  BEST VAL Loss: 0.1474  Val_Acc: 95.062

Epoch 62: Validation loss decreased (0.147447 --> 0.147119).  Saving model ...
	 Train_Loss: 0.1746 Train_Acc: 94.512 Val_Loss: 0.1471  BEST VAL Loss: 0.1471  Val_Acc: 95.138

Epoch 63: Validation loss decreased (0.147119 --> 0.146823).  Saving model ...
	 Train_Loss: 0.1741 Train_Acc: 94.528 Val_Loss: 0.1468  BEST VAL Loss: 0.1468  Val_Acc: 94.999

Epoch 64: Validation loss decreased (0.146823 --> 0.146538).  Saving model ...
	 Train_Loss: 0.1736 Train_Acc: 94.548 Val_Loss: 0.1465  BEST VAL Loss: 0.1465  Val_Acc: 95.121

Epoch 65: Validation loss decreased (0.146538 --> 0.146215).  Saving model ...
	 Train_Loss: 0.1731 Train_Acc: 94.519 Val_Loss: 0.1462  BEST VAL Loss: 0.1462  Val_Acc: 95.206

Epoch 66: Validation loss decreased (0.146215 --> 0.146039).  Saving model ...
	 Train_Loss: 0.1726 Train_Acc: 94.575 Val_Loss: 0.1460  BEST VAL Loss: 0.1460  Val_Acc: 95.045

Epoch 67: Validation loss decreased (0.146039 --> 0.145782).  Saving model ...
	 Train_Loss: 0.1721 Train_Acc: 94.590 Val_Loss: 0.1458  BEST VAL Loss: 0.1458  Val_Acc: 94.991

Epoch 68: Validation loss decreased (0.145782 --> 0.145462).  Saving model ...
	 Train_Loss: 0.1717 Train_Acc: 94.609 Val_Loss: 0.1455  BEST VAL Loss: 0.1455  Val_Acc: 95.113

Epoch 69: Validation loss decreased (0.145462 --> 0.145179).  Saving model ...
	 Train_Loss: 0.1712 Train_Acc: 94.572 Val_Loss: 0.1452  BEST VAL Loss: 0.1452  Val_Acc: 95.104

Epoch 70: Validation loss decreased (0.145179 --> 0.144893).  Saving model ...
	 Train_Loss: 0.1708 Train_Acc: 94.523 Val_Loss: 0.1449  BEST VAL Loss: 0.1449  Val_Acc: 95.096

Epoch 71: Validation loss decreased (0.144893 --> 0.144601).  Saving model ...
	 Train_Loss: 0.1703 Train_Acc: 94.601 Val_Loss: 0.1446  BEST VAL Loss: 0.1446  Val_Acc: 95.159

Epoch 72: Validation loss decreased (0.144601 --> 0.144355).  Saving model ...
	 Train_Loss: 0.1699 Train_Acc: 94.604 Val_Loss: 0.1444  BEST VAL Loss: 0.1444  Val_Acc: 95.147

Epoch 73: Validation loss decreased (0.144355 --> 0.144074).  Saving model ...
	 Train_Loss: 0.1695 Train_Acc: 94.549 Val_Loss: 0.1441  BEST VAL Loss: 0.1441  Val_Acc: 95.054

Epoch 74: Validation loss decreased (0.144074 --> 0.143804).  Saving model ...
	 Train_Loss: 0.1691 Train_Acc: 94.553 Val_Loss: 0.1438  BEST VAL Loss: 0.1438  Val_Acc: 95.138

Epoch 75: Validation loss decreased (0.143804 --> 0.143561).  Saving model ...
	 Train_Loss: 0.1687 Train_Acc: 94.601 Val_Loss: 0.1436  BEST VAL Loss: 0.1436  Val_Acc: 95.176

Epoch 76: Validation loss decreased (0.143561 --> 0.143287).  Saving model ...
	 Train_Loss: 0.1683 Train_Acc: 94.577 Val_Loss: 0.1433  BEST VAL Loss: 0.1433  Val_Acc: 95.218

Epoch 77: Validation loss decreased (0.143287 --> 0.143049).  Saving model ...
	 Train_Loss: 0.1679 Train_Acc: 94.566 Val_Loss: 0.1430  BEST VAL Loss: 0.1430  Val_Acc: 95.164

Epoch 78: Validation loss decreased (0.143049 --> 0.142829).  Saving model ...
	 Train_Loss: 0.1675 Train_Acc: 94.661 Val_Loss: 0.1428  BEST VAL Loss: 0.1428  Val_Acc: 94.995

Epoch 79: Validation loss decreased (0.142829 --> 0.142614).  Saving model ...
	 Train_Loss: 0.1671 Train_Acc: 94.614 Val_Loss: 0.1426  BEST VAL Loss: 0.1426  Val_Acc: 95.083

Epoch 80: Validation loss decreased (0.142614 --> 0.142399).  Saving model ...
	 Train_Loss: 0.1668 Train_Acc: 94.600 Val_Loss: 0.1424  BEST VAL Loss: 0.1424  Val_Acc: 95.256

Epoch 81: Validation loss decreased (0.142399 --> 0.142184).  Saving model ...
	 Train_Loss: 0.1664 Train_Acc: 94.638 Val_Loss: 0.1422  BEST VAL Loss: 0.1422  Val_Acc: 95.214

Epoch 82: Validation loss decreased (0.142184 --> 0.141975).  Saving model ...
	 Train_Loss: 0.1661 Train_Acc: 94.647 Val_Loss: 0.1420  BEST VAL Loss: 0.1420  Val_Acc: 95.147

Epoch 83: Validation loss decreased (0.141975 --> 0.141798).  Saving model ...
	 Train_Loss: 0.1657 Train_Acc: 94.588 Val_Loss: 0.1418  BEST VAL Loss: 0.1418  Val_Acc: 95.050

Epoch 84: Validation loss decreased (0.141798 --> 0.141597).  Saving model ...
	 Train_Loss: 0.1654 Train_Acc: 94.652 Val_Loss: 0.1416  BEST VAL Loss: 0.1416  Val_Acc: 95.096

Epoch 85: Validation loss decreased (0.141597 --> 0.141506).  Saving model ...
	 Train_Loss: 0.1651 Train_Acc: 94.642 Val_Loss: 0.1415  BEST VAL Loss: 0.1415  Val_Acc: 94.889

Epoch 86: Validation loss decreased (0.141506 --> 0.141260).  Saving model ...
	 Train_Loss: 0.1647 Train_Acc: 94.664 Val_Loss: 0.1413  BEST VAL Loss: 0.1413  Val_Acc: 95.345

Epoch 87: Validation loss decreased (0.141260 --> 0.141080).  Saving model ...
	 Train_Loss: 0.1644 Train_Acc: 94.625 Val_Loss: 0.1411  BEST VAL Loss: 0.1411  Val_Acc: 95.252

Epoch 88: Validation loss decreased (0.141080 --> 0.140868).  Saving model ...
	 Train_Loss: 0.1641 Train_Acc: 94.691 Val_Loss: 0.1409  BEST VAL Loss: 0.1409  Val_Acc: 95.265

Epoch 89: Validation loss decreased (0.140868 --> 0.140729).  Saving model ...
	 Train_Loss: 0.1638 Train_Acc: 94.703 Val_Loss: 0.1407  BEST VAL Loss: 0.1407  Val_Acc: 95.117

Epoch 90: Validation loss decreased (0.140729 --> 0.140557).  Saving model ...
	 Train_Loss: 0.1635 Train_Acc: 94.705 Val_Loss: 0.1406  BEST VAL Loss: 0.1406  Val_Acc: 95.218

Epoch 91: Validation loss decreased (0.140557 --> 0.140391).  Saving model ...
	 Train_Loss: 0.1632 Train_Acc: 94.748 Val_Loss: 0.1404  BEST VAL Loss: 0.1404  Val_Acc: 95.252

Epoch 92: Validation loss decreased (0.140391 --> 0.140237).  Saving model ...
	 Train_Loss: 0.1629 Train_Acc: 94.697 Val_Loss: 0.1402  BEST VAL Loss: 0.1402  Val_Acc: 95.172

Epoch 93: Validation loss decreased (0.140237 --> 0.140126).  Saving model ...
	 Train_Loss: 0.1626 Train_Acc: 94.699 Val_Loss: 0.1401  BEST VAL Loss: 0.1401  Val_Acc: 95.121

Epoch 94: Validation loss decreased (0.140126 --> 0.140000).  Saving model ...
	 Train_Loss: 0.1623 Train_Acc: 94.701 Val_Loss: 0.1400  BEST VAL Loss: 0.1400  Val_Acc: 95.172

Epoch 95: Validation loss decreased (0.140000 --> 0.139841).  Saving model ...
	 Train_Loss: 0.1620 Train_Acc: 94.757 Val_Loss: 0.1398  BEST VAL Loss: 0.1398  Val_Acc: 95.168

Epoch 96: Validation loss decreased (0.139841 --> 0.139691).  Saving model ...
	 Train_Loss: 0.1617 Train_Acc: 94.676 Val_Loss: 0.1397  BEST VAL Loss: 0.1397  Val_Acc: 95.235

Epoch 97: Validation loss decreased (0.139691 --> 0.139536).  Saving model ...
	 Train_Loss: 0.1614 Train_Acc: 94.711 Val_Loss: 0.1395  BEST VAL Loss: 0.1395  Val_Acc: 95.307

Epoch 98: Validation loss decreased (0.139536 --> 0.139367).  Saving model ...
	 Train_Loss: 0.1612 Train_Acc: 94.660 Val_Loss: 0.1394  BEST VAL Loss: 0.1394  Val_Acc: 95.311

Epoch 99: Validation loss decreased (0.139367 --> 0.139226).  Saving model ...
	 Train_Loss: 0.1609 Train_Acc: 94.711 Val_Loss: 0.1392  BEST VAL Loss: 0.1392  Val_Acc: 95.265

LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.42      0.43      0.43     80324
           1       0.58      0.57      0.57    109228

    accuracy                           0.51    189552
   macro avg       0.50      0.50      0.50    189552
weighted avg       0.51      0.51      0.51    189552

LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.43      0.44      0.43     10041
           1       0.58      0.57      0.57     13654

    accuracy                           0.51     23695
   macro avg       0.50      0.50      0.50     23695
weighted avg       0.51      0.51      0.51     23695

LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.43      0.44      0.44     10041
           1       0.58      0.57      0.58     13654

    accuracy                           0.52     23695
   macro avg       0.51      0.51      0.51     23695
weighted avg       0.52      0.52      0.52     23695

              precision    recall  f1-score   support

           0       0.43      0.44      0.44     10041
           1       0.58      0.57      0.58     13654

    accuracy                           0.52     23695
   macro avg       0.51      0.51      0.51     23695
weighted avg       0.52      0.52      0.52     23695

LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.48      0.49     38191
           1       0.50      0.52      0.51     37725

    accuracy                           0.50     75916
   macro avg       0.50      0.50      0.50     75916
weighted avg       0.50      0.50      0.50     75916

              precision    recall  f1-score   support

           0       0.50      0.48      0.49     38191
           1       0.50      0.52      0.51     37725

    accuracy                           0.50     75916
   macro avg       0.50      0.50      0.50     75916
weighted avg       0.50      0.50      0.50     75916

completed
