[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd307331a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'b546f200'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '256cfcfa'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e6222470'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_10.000_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_10.000_DMSO_0.025']
The dimensions of the data are: (299570, 1270)
Number of total missing values across all columns: 599140
Data Subset Is Off
Wells held out for testing: ['B08' 'E08']
Wells to use for training, validation, and testing ['B02' 'B03' 'B09' 'E02' 'E03' 'E09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.582756).  Saving model ...
	 Train_Loss: 0.6334 Train_Acc: 63.110 Val_Loss: 0.5828  BEST VAL Loss: 0.5828  Val_Acc: 68.389

Epoch 1: Validation loss decreased (0.582756 --> 0.554859).  Saving model ...
	 Train_Loss: 0.5963 Train_Acc: 70.485 Val_Loss: 0.5549  BEST VAL Loss: 0.5549  Val_Acc: 73.101

Epoch 2: Validation loss decreased (0.554859 --> 0.536897).  Saving model ...
	 Train_Loss: 0.5724 Train_Acc: 72.850 Val_Loss: 0.5369  BEST VAL Loss: 0.5369  Val_Acc: 74.973

Epoch 3: Validation loss decreased (0.536897 --> 0.523851).  Saving model ...
	 Train_Loss: 0.5565 Train_Acc: 73.897 Val_Loss: 0.5239  BEST VAL Loss: 0.5239  Val_Acc: 75.755

Epoch 4: Validation loss decreased (0.523851 --> 0.513481).  Saving model ...
	 Train_Loss: 0.5442 Train_Acc: 74.882 Val_Loss: 0.5135  BEST VAL Loss: 0.5135  Val_Acc: 76.908

Epoch 5: Validation loss decreased (0.513481 --> 0.505514).  Saving model ...
	 Train_Loss: 0.5345 Train_Acc: 75.396 Val_Loss: 0.5055  BEST VAL Loss: 0.5055  Val_Acc: 77.369

Epoch 6: Validation loss decreased (0.505514 --> 0.498283).  Saving model ...
	 Train_Loss: 0.5263 Train_Acc: 76.078 Val_Loss: 0.4983  BEST VAL Loss: 0.4983  Val_Acc: 78.143

Epoch 7: Validation loss decreased (0.498283 --> 0.492823).  Saving model ...
	 Train_Loss: 0.5195 Train_Acc: 76.389 Val_Loss: 0.4928  BEST VAL Loss: 0.4928  Val_Acc: 78.106

Epoch 8: Validation loss decreased (0.492823 --> 0.490634).  Saving model ...
	 Train_Loss: 0.5133 Train_Acc: 76.964 Val_Loss: 0.4906  BEST VAL Loss: 0.4906  Val_Acc: 76.384

Epoch 9: Validation loss decreased (0.490634 --> 0.486561).  Saving model ...
	 Train_Loss: 0.5081 Train_Acc: 77.222 Val_Loss: 0.4866  BEST VAL Loss: 0.4866  Val_Acc: 78.310

Epoch 10: Validation loss decreased (0.486561 --> 0.482414).  Saving model ...
	 Train_Loss: 0.5034 Train_Acc: 77.547 Val_Loss: 0.4824  BEST VAL Loss: 0.4824  Val_Acc: 78.938

Epoch 11: Validation loss decreased (0.482414 --> 0.478938).  Saving model ...
	 Train_Loss: 0.4990 Train_Acc: 77.859 Val_Loss: 0.4789  BEST VAL Loss: 0.4789  Val_Acc: 78.599

Epoch 12: Validation loss decreased (0.478938 --> 0.475572).  Saving model ...
	 Train_Loss: 0.4952 Train_Acc: 77.968 Val_Loss: 0.4756  BEST VAL Loss: 0.4756  Val_Acc: 79.115

Epoch 13: Validation loss decreased (0.475572 --> 0.473038).  Saving model ...
	 Train_Loss: 0.4914 Train_Acc: 78.521 Val_Loss: 0.4730  BEST VAL Loss: 0.4730  Val_Acc: 79.350

Epoch 14: Validation loss decreased (0.473038 --> 0.470032).  Saving model ...
	 Train_Loss: 0.4880 Train_Acc: 78.639 Val_Loss: 0.4700  BEST VAL Loss: 0.4700  Val_Acc: 79.870

Epoch 15: Validation loss decreased (0.470032 --> 0.467745).  Saving model ...
	 Train_Loss: 0.4848 Train_Acc: 78.838 Val_Loss: 0.4677  BEST VAL Loss: 0.4677  Val_Acc: 79.277

Epoch 16: Validation loss decreased (0.467745 --> 0.465325).  Saving model ...
	 Train_Loss: 0.4818 Train_Acc: 79.133 Val_Loss: 0.4653  BEST VAL Loss: 0.4653  Val_Acc: 79.779

Epoch 17: Validation loss decreased (0.465325 --> 0.463956).  Saving model ...
	 Train_Loss: 0.4789 Train_Acc: 79.339 Val_Loss: 0.4640  BEST VAL Loss: 0.4640  Val_Acc: 78.405

Epoch 18: Validation loss decreased (0.463956 --> 0.462124).  Saving model ...
	 Train_Loss: 0.4763 Train_Acc: 79.435 Val_Loss: 0.4621  BEST VAL Loss: 0.4621  Val_Acc: 79.436

Epoch 19: Validation loss decreased (0.462124 --> 0.460251).  Saving model ...
	 Train_Loss: 0.4738 Train_Acc: 79.525 Val_Loss: 0.4603  BEST VAL Loss: 0.4603  Val_Acc: 79.639

Epoch 20: Validation loss decreased (0.460251 --> 0.458014).  Saving model ...
	 Train_Loss: 0.4715 Train_Acc: 79.645 Val_Loss: 0.4580  BEST VAL Loss: 0.4580  Val_Acc: 80.381

Epoch 21: Validation loss decreased (0.458014 --> 0.455959).  Saving model ...
	 Train_Loss: 0.4692 Train_Acc: 79.735 Val_Loss: 0.4560  BEST VAL Loss: 0.4560  Val_Acc: 80.684

Epoch 22: Validation loss decreased (0.455959 --> 0.454766).  Saving model ...
	 Train_Loss: 0.4672 Train_Acc: 79.902 Val_Loss: 0.4548  BEST VAL Loss: 0.4548  Val_Acc: 79.002

Epoch 23: Validation loss decreased (0.454766 --> 0.453148).  Saving model ...
	 Train_Loss: 0.4652 Train_Acc: 80.051 Val_Loss: 0.4531  BEST VAL Loss: 0.4531  Val_Acc: 80.259

Epoch 24: Validation loss decreased (0.453148 --> 0.451591).  Saving model ...
	 Train_Loss: 0.4633 Train_Acc: 80.083 Val_Loss: 0.4516  BEST VAL Loss: 0.4516  Val_Acc: 80.336

Epoch 25: Validation loss decreased (0.451591 --> 0.450523).  Saving model ...
	 Train_Loss: 0.4614 Train_Acc: 80.199 Val_Loss: 0.4505  BEST VAL Loss: 0.4505  Val_Acc: 79.942

Epoch 26: Validation loss decreased (0.450523 --> 0.449065).  Saving model ...
	 Train_Loss: 0.4597 Train_Acc: 80.377 Val_Loss: 0.4491  BEST VAL Loss: 0.4491  Val_Acc: 80.580

Epoch 27: Validation loss decreased (0.449065 --> 0.447529).  Saving model ...
	 Train_Loss: 0.4580 Train_Acc: 80.436 Val_Loss: 0.4475  BEST VAL Loss: 0.4475  Val_Acc: 80.788

Epoch 28: Validation loss decreased (0.447529 --> 0.446113).  Saving model ...
	 Train_Loss: 0.4564 Train_Acc: 80.578 Val_Loss: 0.4461  BEST VAL Loss: 0.4461  Val_Acc: 80.928

Epoch 29: Validation loss decreased (0.446113 --> 0.444853).  Saving model ...
	 Train_Loss: 0.4548 Train_Acc: 80.646 Val_Loss: 0.4449  BEST VAL Loss: 0.4449  Val_Acc: 81.244

Epoch 30: Validation loss decreased (0.444853 --> 0.443481).  Saving model ...
	 Train_Loss: 0.4533 Train_Acc: 80.716 Val_Loss: 0.4435  BEST VAL Loss: 0.4435  Val_Acc: 81.163

Epoch 31: Validation loss decreased (0.443481 --> 0.442257).  Saving model ...
	 Train_Loss: 0.4518 Train_Acc: 80.766 Val_Loss: 0.4423  BEST VAL Loss: 0.4423  Val_Acc: 81.149

Epoch 32: Validation loss decreased (0.442257 --> 0.441032).  Saving model ...
	 Train_Loss: 0.4505 Train_Acc: 80.830 Val_Loss: 0.4410  BEST VAL Loss: 0.4410  Val_Acc: 81.380

Epoch 33: Validation loss decreased (0.441032 --> 0.439806).  Saving model ...
	 Train_Loss: 0.4492 Train_Acc: 80.859 Val_Loss: 0.4398  BEST VAL Loss: 0.4398  Val_Acc: 81.253

Epoch 34: Validation loss decreased (0.439806 --> 0.438495).  Saving model ...
	 Train_Loss: 0.4479 Train_Acc: 80.964 Val_Loss: 0.4385  BEST VAL Loss: 0.4385  Val_Acc: 81.593

Epoch 35: Validation loss decreased (0.438495 --> 0.437361).  Saving model ...
	 Train_Loss: 0.4466 Train_Acc: 81.071 Val_Loss: 0.4374  BEST VAL Loss: 0.4374  Val_Acc: 81.760

Epoch 36: Validation loss decreased (0.437361 --> 0.436341).  Saving model ...
	 Train_Loss: 0.4454 Train_Acc: 81.055 Val_Loss: 0.4363  BEST VAL Loss: 0.4363  Val_Acc: 81.561

Epoch 37: Validation loss decreased (0.436341 --> 0.435357).  Saving model ...
	 Train_Loss: 0.4442 Train_Acc: 81.264 Val_Loss: 0.4354  BEST VAL Loss: 0.4354  Val_Acc: 81.294

Epoch 38: Validation loss decreased (0.435357 --> 0.434348).  Saving model ...
	 Train_Loss: 0.4431 Train_Acc: 81.098 Val_Loss: 0.4343  BEST VAL Loss: 0.4343  Val_Acc: 81.303

Epoch 39: Validation loss decreased (0.434348 --> 0.433375).  Saving model ...
	 Train_Loss: 0.4420 Train_Acc: 81.350 Val_Loss: 0.4334  BEST VAL Loss: 0.4334  Val_Acc: 81.163

Epoch 40: Validation loss decreased (0.433375 --> 0.432410).  Saving model ...
	 Train_Loss: 0.4409 Train_Acc: 81.231 Val_Loss: 0.4324  BEST VAL Loss: 0.4324  Val_Acc: 81.561

Epoch 41: Validation loss decreased (0.432410 --> 0.432007).  Saving model ...
	 Train_Loss: 0.4398 Train_Acc: 81.330 Val_Loss: 0.4320  BEST VAL Loss: 0.4320  Val_Acc: 81.054

Epoch 42: Validation loss decreased (0.432007 --> 0.431296).  Saving model ...
	 Train_Loss: 0.4388 Train_Acc: 81.420 Val_Loss: 0.4313  BEST VAL Loss: 0.4313  Val_Acc: 80.937

Epoch 43: Validation loss decreased (0.431296 --> 0.430576).  Saving model ...
	 Train_Loss: 0.4378 Train_Acc: 81.407 Val_Loss: 0.4306  BEST VAL Loss: 0.4306  Val_Acc: 81.199

Epoch 44: Validation loss decreased (0.430576 --> 0.429775).  Saving model ...
	 Train_Loss: 0.4369 Train_Acc: 81.484 Val_Loss: 0.4298  BEST VAL Loss: 0.4298  Val_Acc: 81.534

Epoch 45: Validation loss decreased (0.429775 --> 0.429209).  Saving model ...
	 Train_Loss: 0.4359 Train_Acc: 81.521 Val_Loss: 0.4292  BEST VAL Loss: 0.4292  Val_Acc: 80.824

Epoch 46: Validation loss decreased (0.429209 --> 0.428430).  Saving model ...
	 Train_Loss: 0.4350 Train_Acc: 81.636 Val_Loss: 0.4284  BEST VAL Loss: 0.4284  Val_Acc: 81.710

Epoch 47: Validation loss decreased (0.428430 --> 0.427656).  Saving model ...
	 Train_Loss: 0.4341 Train_Acc: 81.646 Val_Loss: 0.4277  BEST VAL Loss: 0.4277  Val_Acc: 81.683

Epoch 48: Validation loss decreased (0.427656 --> 0.426879).  Saving model ...
	 Train_Loss: 0.4333 Train_Acc: 81.616 Val_Loss: 0.4269  BEST VAL Loss: 0.4269  Val_Acc: 81.891

Epoch 49: Validation loss decreased (0.426879 --> 0.426239).  Saving model ...
	 Train_Loss: 0.4324 Train_Acc: 81.604 Val_Loss: 0.4262  BEST VAL Loss: 0.4262  Val_Acc: 81.642

Epoch 50: Validation loss decreased (0.426239 --> 0.425501).  Saving model ...
	 Train_Loss: 0.4316 Train_Acc: 81.698 Val_Loss: 0.4255  BEST VAL Loss: 0.4255  Val_Acc: 82.049

Epoch 51: Validation loss decreased (0.425501 --> 0.424944).  Saving model ...
	 Train_Loss: 0.4308 Train_Acc: 81.616 Val_Loss: 0.4249  BEST VAL Loss: 0.4249  Val_Acc: 82.289

Epoch 52: Validation loss decreased (0.424944 --> 0.424290).  Saving model ...
	 Train_Loss: 0.4300 Train_Acc: 81.647 Val_Loss: 0.4243  BEST VAL Loss: 0.4243  Val_Acc: 81.706

Epoch 53: Validation loss decreased (0.424290 --> 0.423667).  Saving model ...
	 Train_Loss: 0.4293 Train_Acc: 81.722 Val_Loss: 0.4237  BEST VAL Loss: 0.4237  Val_Acc: 82.094

Epoch 54: Validation loss decreased (0.423667 --> 0.423053).  Saving model ...
	 Train_Loss: 0.4285 Train_Acc: 81.742 Val_Loss: 0.4231  BEST VAL Loss: 0.4231  Val_Acc: 81.810

Epoch 55: Validation loss decreased (0.423053 --> 0.422487).  Saving model ...
	 Train_Loss: 0.4278 Train_Acc: 81.871 Val_Loss: 0.4225  BEST VAL Loss: 0.4225  Val_Acc: 82.198

Epoch 56: Validation loss decreased (0.422487 --> 0.421904).  Saving model ...
	 Train_Loss: 0.4271 Train_Acc: 82.007 Val_Loss: 0.4219  BEST VAL Loss: 0.4219  Val_Acc: 82.018

Epoch 57: Validation loss decreased (0.421904 --> 0.421270).  Saving model ...
	 Train_Loss: 0.4264 Train_Acc: 81.838 Val_Loss: 0.4213  BEST VAL Loss: 0.4213  Val_Acc: 82.293

Epoch 58: Validation loss decreased (0.421270 --> 0.420747).  Saving model ...
	 Train_Loss: 0.4257 Train_Acc: 81.870 Val_Loss: 0.4207  BEST VAL Loss: 0.4207  Val_Acc: 82.085

Epoch 59: Validation loss decreased (0.420747 --> 0.420177).  Saving model ...
	 Train_Loss: 0.4250 Train_Acc: 81.949 Val_Loss: 0.4202  BEST VAL Loss: 0.4202  Val_Acc: 82.063

Epoch 60: Validation loss decreased (0.420177 --> 0.419662).  Saving model ...
	 Train_Loss: 0.4243 Train_Acc: 82.056 Val_Loss: 0.4197  BEST VAL Loss: 0.4197  Val_Acc: 82.076

Epoch 61: Validation loss decreased (0.419662 --> 0.419282).  Saving model ...
	 Train_Loss: 0.4237 Train_Acc: 82.056 Val_Loss: 0.4193  BEST VAL Loss: 0.4193  Val_Acc: 81.832

Epoch 62: Validation loss decreased (0.419282 --> 0.418798).  Saving model ...
	 Train_Loss: 0.4231 Train_Acc: 81.974 Val_Loss: 0.4188  BEST VAL Loss: 0.4188  Val_Acc: 82.216

Epoch 63: Validation loss decreased (0.418798 --> 0.418294).  Saving model ...
	 Train_Loss: 0.4224 Train_Acc: 82.113 Val_Loss: 0.4183  BEST VAL Loss: 0.4183  Val_Acc: 82.212

Epoch 64: Validation loss decreased (0.418294 --> 0.417777).  Saving model ...
	 Train_Loss: 0.4219 Train_Acc: 81.947 Val_Loss: 0.4178  BEST VAL Loss: 0.4178  Val_Acc: 82.370

Epoch 65: Validation loss decreased (0.417777 --> 0.417247).  Saving model ...
	 Train_Loss: 0.4213 Train_Acc: 82.027 Val_Loss: 0.4172  BEST VAL Loss: 0.4172  Val_Acc: 82.452

Epoch 66: Validation loss decreased (0.417247 --> 0.416766).  Saving model ...
	 Train_Loss: 0.4207 Train_Acc: 82.037 Val_Loss: 0.4168  BEST VAL Loss: 0.4168  Val_Acc: 82.330

Epoch 67: Validation loss decreased (0.416766 --> 0.416280).  Saving model ...
	 Train_Loss: 0.4201 Train_Acc: 82.096 Val_Loss: 0.4163  BEST VAL Loss: 0.4163  Val_Acc: 82.131

Epoch 68: Validation loss decreased (0.416280 --> 0.416139).  Saving model ...
	 Train_Loss: 0.4196 Train_Acc: 82.136 Val_Loss: 0.4161  BEST VAL Loss: 0.4161  Val_Acc: 81.023

Epoch 69: Validation loss decreased (0.416139 --> 0.415683).  Saving model ...
	 Train_Loss: 0.4190 Train_Acc: 82.105 Val_Loss: 0.4157  BEST VAL Loss: 0.4157  Val_Acc: 82.406

Epoch 70: Validation loss decreased (0.415683 --> 0.415268).  Saving model ...
	 Train_Loss: 0.4185 Train_Acc: 82.196 Val_Loss: 0.4153  BEST VAL Loss: 0.4153  Val_Acc: 82.158

Epoch 71: Validation loss decreased (0.415268 --> 0.414830).  Saving model ...
	 Train_Loss: 0.4180 Train_Acc: 82.210 Val_Loss: 0.4148  BEST VAL Loss: 0.4148  Val_Acc: 82.081

Epoch 72: Validation loss decreased (0.414830 --> 0.414436).  Saving model ...
	 Train_Loss: 0.4175 Train_Acc: 82.317 Val_Loss: 0.4144  BEST VAL Loss: 0.4144  Val_Acc: 82.515

Epoch 73: Validation loss decreased (0.414436 --> 0.414063).  Saving model ...
	 Train_Loss: 0.4170 Train_Acc: 82.300 Val_Loss: 0.4141  BEST VAL Loss: 0.4141  Val_Acc: 82.348

Epoch 74: Validation loss decreased (0.414063 --> 0.413581).  Saving model ...
	 Train_Loss: 0.4165 Train_Acc: 82.219 Val_Loss: 0.4136  BEST VAL Loss: 0.4136  Val_Acc: 82.506

Epoch 75: Validation loss decreased (0.413581 --> 0.413245).  Saving model ...
	 Train_Loss: 0.4160 Train_Acc: 82.386 Val_Loss: 0.4132  BEST VAL Loss: 0.4132  Val_Acc: 82.614

Epoch 76: Validation loss decreased (0.413245 --> 0.412843).  Saving model ...
	 Train_Loss: 0.4155 Train_Acc: 82.213 Val_Loss: 0.4128  BEST VAL Loss: 0.4128  Val_Acc: 82.402

Epoch 77: Validation loss decreased (0.412843 --> 0.412427).  Saving model ...
	 Train_Loss: 0.4150 Train_Acc: 82.279 Val_Loss: 0.4124  BEST VAL Loss: 0.4124  Val_Acc: 82.465

Epoch 78: Validation loss decreased (0.412427 --> 0.412021).  Saving model ...
	 Train_Loss: 0.4145 Train_Acc: 82.372 Val_Loss: 0.4120  BEST VAL Loss: 0.4120  Val_Acc: 82.614

Epoch 79: Validation loss decreased (0.412021 --> 0.411623).  Saving model ...
	 Train_Loss: 0.4141 Train_Acc: 82.299 Val_Loss: 0.4116  BEST VAL Loss: 0.4116  Val_Acc: 82.122

Epoch 80: Validation loss decreased (0.411623 --> 0.411203).  Saving model ...
	 Train_Loss: 0.4136 Train_Acc: 82.299 Val_Loss: 0.4112  BEST VAL Loss: 0.4112  Val_Acc: 82.782

Epoch 81: Validation loss decreased (0.411203 --> 0.410815).  Saving model ...
	 Train_Loss: 0.4132 Train_Acc: 82.432 Val_Loss: 0.4108  BEST VAL Loss: 0.4108  Val_Acc: 82.176

Epoch 82: Validation loss decreased (0.410815 --> 0.410409).  Saving model ...
	 Train_Loss: 0.4127 Train_Acc: 82.448 Val_Loss: 0.4104  BEST VAL Loss: 0.4104  Val_Acc: 82.868

Epoch 83: Validation loss decreased (0.410409 --> 0.410109).  Saving model ...
	 Train_Loss: 0.4123 Train_Acc: 82.392 Val_Loss: 0.4101  BEST VAL Loss: 0.4101  Val_Acc: 81.864

Epoch 84: Validation loss decreased (0.410109 --> 0.409795).  Saving model ...
	 Train_Loss: 0.4119 Train_Acc: 82.427 Val_Loss: 0.4098  BEST VAL Loss: 0.4098  Val_Acc: 82.144

Epoch 85: Validation loss decreased (0.409795 --> 0.409524).  Saving model ...
	 Train_Loss: 0.4115 Train_Acc: 82.294 Val_Loss: 0.4095  BEST VAL Loss: 0.4095  Val_Acc: 81.900

Epoch 86: Validation loss decreased (0.409524 --> 0.409160).  Saving model ...
	 Train_Loss: 0.4111 Train_Acc: 82.384 Val_Loss: 0.4092  BEST VAL Loss: 0.4092  Val_Acc: 82.646

Epoch 87: Validation loss decreased (0.409160 --> 0.408799).  Saving model ...
	 Train_Loss: 0.4107 Train_Acc: 82.465 Val_Loss: 0.4088  BEST VAL Loss: 0.4088  Val_Acc: 82.497

Epoch 88: Validation loss decreased (0.408799 --> 0.408504).  Saving model ...
	 Train_Loss: 0.4103 Train_Acc: 82.499 Val_Loss: 0.4085  BEST VAL Loss: 0.4085  Val_Acc: 82.461

Epoch 89: Validation loss decreased (0.408504 --> 0.408155).  Saving model ...
	 Train_Loss: 0.4099 Train_Acc: 82.446 Val_Loss: 0.4082  BEST VAL Loss: 0.4082  Val_Acc: 82.528

Epoch 90: Validation loss decreased (0.408155 --> 0.407877).  Saving model ...
	 Train_Loss: 0.4095 Train_Acc: 82.465 Val_Loss: 0.4079  BEST VAL Loss: 0.4079  Val_Acc: 82.420

Epoch 91: Validation loss decreased (0.407877 --> 0.407562).  Saving model ...
	 Train_Loss: 0.4091 Train_Acc: 82.468 Val_Loss: 0.4076  BEST VAL Loss: 0.4076  Val_Acc: 82.415

Epoch 92: Validation loss decreased (0.407562 --> 0.407270).  Saving model ...
	 Train_Loss: 0.4088 Train_Acc: 82.434 Val_Loss: 0.4073  BEST VAL Loss: 0.4073  Val_Acc: 82.709

Epoch 93: Validation loss decreased (0.407270 --> 0.407004).  Saving model ...
	 Train_Loss: 0.4084 Train_Acc: 82.472 Val_Loss: 0.4070  BEST VAL Loss: 0.4070  Val_Acc: 82.528

Epoch 94: Validation loss decreased (0.407004 --> 0.406638).  Saving model ...
	 Train_Loss: 0.4080 Train_Acc: 82.524 Val_Loss: 0.4066  BEST VAL Loss: 0.4066  Val_Acc: 82.673

Epoch 95: Validation loss decreased (0.406638 --> 0.406359).  Saving model ...
	 Train_Loss: 0.4077 Train_Acc: 82.485 Val_Loss: 0.4064  BEST VAL Loss: 0.4064  Val_Acc: 82.560

Epoch 96: Validation loss decreased (0.406359 --> 0.406125).  Saving model ...
	 Train_Loss: 0.4073 Train_Acc: 82.574 Val_Loss: 0.4061  BEST VAL Loss: 0.4061  Val_Acc: 82.474

Epoch 97: Validation loss decreased (0.406125 --> 0.405872).  Saving model ...
	 Train_Loss: 0.4070 Train_Acc: 82.522 Val_Loss: 0.4059  BEST VAL Loss: 0.4059  Val_Acc: 82.379

Epoch 98: Validation loss decreased (0.405872 --> 0.405560).  Saving model ...
	 Train_Loss: 0.4067 Train_Acc: 82.528 Val_Loss: 0.4056  BEST VAL Loss: 0.4056  Val_Acc: 82.623

Epoch 99: Validation loss decreased (0.405560 --> 0.405310).  Saving model ...
	 Train_Loss: 0.4063 Train_Acc: 82.684 Val_Loss: 0.4053  BEST VAL Loss: 0.4053  Val_Acc: 82.610

LPS_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.44      0.46     85026
           1       0.52      0.56      0.54     91898

    accuracy                           0.50    176924
   macro avg       0.50      0.50      0.50    176924
weighted avg       0.50      0.50      0.50    176924

LPS_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.45      0.46     10628
           1       0.52      0.56      0.54     11488

    accuracy                           0.50     22116
   macro avg       0.50      0.50      0.50     22116
weighted avg       0.50      0.50      0.50     22116

LPS_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.44      0.46     10629
           1       0.52      0.55      0.53     11487

    accuracy                           0.50     22116
   macro avg       0.50      0.50      0.50     22116
weighted avg       0.50      0.50      0.50     22116

              precision    recall  f1-score   support

           0       0.48      0.44      0.46     10629
           1       0.52      0.55      0.53     11487

    accuracy                           0.50     22116
   macro avg       0.50      0.50      0.50     22116
weighted avg       0.50      0.50      0.50     22116

LPS_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.33      0.39     36797
           1       0.53      0.66      0.59     41617

    accuracy                           0.51     78414
   macro avg       0.50      0.50      0.49     78414
weighted avg       0.50      0.51      0.49     78414

              precision    recall  f1-score   support

           0       0.46      0.33      0.39     36797
           1       0.53      0.66      0.59     41617

    accuracy                           0.51     78414
   macro avg       0.50      0.50      0.49     78414
weighted avg       0.50      0.51      0.49     78414

completed
