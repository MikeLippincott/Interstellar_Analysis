[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'f827e5bb'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '1da0fe53'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '2e06220c'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '624952d6'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_1.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_Nigericin_1.000_10.0_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (30211, 1276)
Number of total missing values across all columns: 31618
Data Subset Is Off
Wells held out for testing: ['M16' 'M22']
Wells to use for training, validation, and testing ['M17' 'M18' 'M19' 'M20' 'M21' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.462476).  Saving model ...
	 Train_Loss: 0.6309 Train_Acc: 60.252 Val_Loss: 0.4625  BEST VAL Loss: 0.4625  Val_Acc: 78.469

Epoch 1: Validation loss decreased (0.462476 --> 0.386900).  Saving model ...
	 Train_Loss: 0.5485 Train_Acc: 73.828 Val_Loss: 0.3869  BEST VAL Loss: 0.3869  Val_Acc: 87.645

Epoch 2: Validation loss decreased (0.386900 --> 0.339355).  Saving model ...
	 Train_Loss: 0.4939 Train_Acc: 79.250 Val_Loss: 0.3394  BEST VAL Loss: 0.3394  Val_Acc: 90.466

Epoch 3: Validation loss decreased (0.339355 --> 0.306218).  Saving model ...
	 Train_Loss: 0.4543 Train_Acc: 81.852 Val_Loss: 0.3062  BEST VAL Loss: 0.3062  Val_Acc: 92.122

Epoch 4: Validation loss decreased (0.306218 --> 0.282541).  Saving model ...
	 Train_Loss: 0.4257 Train_Acc: 82.703 Val_Loss: 0.2825  BEST VAL Loss: 0.2825  Val_Acc: 93.554

Epoch 5: Validation loss decreased (0.282541 --> 0.261405).  Saving model ...
	 Train_Loss: 0.4027 Train_Acc: 83.733 Val_Loss: 0.2614  BEST VAL Loss: 0.2614  Val_Acc: 93.912

Epoch 6: Validation loss decreased (0.261405 --> 0.248093).  Saving model ...
	 Train_Loss: 0.3844 Train_Acc: 84.454 Val_Loss: 0.2481  BEST VAL Loss: 0.2481  Val_Acc: 94.091

Epoch 7: Validation loss decreased (0.248093 --> 0.235294).  Saving model ...
	 Train_Loss: 0.3706 Train_Acc: 84.365 Val_Loss: 0.2353  BEST VAL Loss: 0.2353  Val_Acc: 94.405

Epoch 8: Validation loss decreased (0.235294 --> 0.225923).  Saving model ...
	 Train_Loss: 0.3586 Train_Acc: 84.773 Val_Loss: 0.2259  BEST VAL Loss: 0.2259  Val_Acc: 94.987

Epoch 9: Validation loss decreased (0.225923 --> 0.217540).  Saving model ...
	 Train_Loss: 0.3487 Train_Acc: 84.924 Val_Loss: 0.2175  BEST VAL Loss: 0.2175  Val_Acc: 94.808

Epoch 10: Validation loss decreased (0.217540 --> 0.208896).  Saving model ...
	 Train_Loss: 0.3403 Train_Acc: 84.617 Val_Loss: 0.2089  BEST VAL Loss: 0.2089  Val_Acc: 94.942

Epoch 11: Validation loss decreased (0.208896 --> 0.202293).  Saving model ...
	 Train_Loss: 0.3324 Train_Acc: 85.417 Val_Loss: 0.2023  BEST VAL Loss: 0.2023  Val_Acc: 95.031

Epoch 12: Validation loss decreased (0.202293 --> 0.196087).  Saving model ...
	 Train_Loss: 0.3255 Train_Acc: 85.428 Val_Loss: 0.1961  BEST VAL Loss: 0.1961  Val_Acc: 95.121

Epoch 13: Validation loss decreased (0.196087 --> 0.190565).  Saving model ...
	 Train_Loss: 0.3194 Train_Acc: 85.865 Val_Loss: 0.1906  BEST VAL Loss: 0.1906  Val_Acc: 94.942

Epoch 14: Validation loss decreased (0.190565 --> 0.185689).  Saving model ...
	 Train_Loss: 0.3137 Train_Acc: 86.128 Val_Loss: 0.1857  BEST VAL Loss: 0.1857  Val_Acc: 94.808

Epoch 15: Validation loss decreased (0.185689 --> 0.182222).  Saving model ...
	 Train_Loss: 0.3089 Train_Acc: 85.501 Val_Loss: 0.1822  BEST VAL Loss: 0.1822  Val_Acc: 95.031

Epoch 16: Validation loss decreased (0.182222 --> 0.178010).  Saving model ...
	 Train_Loss: 0.3048 Train_Acc: 85.579 Val_Loss: 0.1780  BEST VAL Loss: 0.1780  Val_Acc: 95.792

Epoch 17: Validation loss decreased (0.178010 --> 0.174857).  Saving model ...
	 Train_Loss: 0.3006 Train_Acc: 86.044 Val_Loss: 0.1749  BEST VAL Loss: 0.1749  Val_Acc: 95.971

Epoch 18: Validation loss decreased (0.174857 --> 0.172268).  Saving model ...
	 Train_Loss: 0.2970 Train_Acc: 85.098 Val_Loss: 0.1723  BEST VAL Loss: 0.1723  Val_Acc: 95.792

Epoch 19: Validation loss decreased (0.172268 --> 0.170334).  Saving model ...
	 Train_Loss: 0.2936 Train_Acc: 85.574 Val_Loss: 0.1703  BEST VAL Loss: 0.1703  Val_Acc: 95.434

Epoch 20: Validation loss decreased (0.170334 --> 0.168260).  Saving model ...
	 Train_Loss: 0.2899 Train_Acc: 86.732 Val_Loss: 0.1683  BEST VAL Loss: 0.1683  Val_Acc: 95.748

Epoch 21: Validation loss decreased (0.168260 --> 0.165186).  Saving model ...
	 Train_Loss: 0.2867 Train_Acc: 86.704 Val_Loss: 0.1652  BEST VAL Loss: 0.1652  Val_Acc: 95.255

Epoch 22: Validation loss decreased (0.165186 --> 0.163258).  Saving model ...
	 Train_Loss: 0.2837 Train_Acc: 86.301 Val_Loss: 0.1633  BEST VAL Loss: 0.1633  Val_Acc: 95.971

Epoch 23: Validation loss decreased (0.163258 --> 0.161412).  Saving model ...
	 Train_Loss: 0.2809 Train_Acc: 86.866 Val_Loss: 0.1614  BEST VAL Loss: 0.1614  Val_Acc: 95.703

Epoch 24: Validation loss decreased (0.161412 --> 0.159487).  Saving model ...
	 Train_Loss: 0.2785 Train_Acc: 86.447 Val_Loss: 0.1595  BEST VAL Loss: 0.1595  Val_Acc: 95.792

Epoch 25: Validation loss decreased (0.159487 --> 0.157627).  Saving model ...
	 Train_Loss: 0.2763 Train_Acc: 86.732 Val_Loss: 0.1576  BEST VAL Loss: 0.1576  Val_Acc: 96.150

Epoch 26: Validation loss decreased (0.157627 --> 0.155692).  Saving model ...
	 Train_Loss: 0.2742 Train_Acc: 86.407 Val_Loss: 0.1557  BEST VAL Loss: 0.1557  Val_Acc: 96.150

Epoch 27: Validation loss decreased (0.155692 --> 0.153773).  Saving model ...
	 Train_Loss: 0.2724 Train_Acc: 86.256 Val_Loss: 0.1538  BEST VAL Loss: 0.1538  Val_Acc: 96.150

Epoch 28: Validation loss decreased (0.153773 --> 0.152949).  Saving model ...
	 Train_Loss: 0.2706 Train_Acc: 86.245 Val_Loss: 0.1529  BEST VAL Loss: 0.1529  Val_Acc: 95.568

Epoch 29: Validation loss decreased (0.152949 --> 0.151496).  Saving model ...
	 Train_Loss: 0.2686 Train_Acc: 86.917 Val_Loss: 0.1515  BEST VAL Loss: 0.1515  Val_Acc: 96.106

Epoch 30: Validation loss decreased (0.151496 --> 0.150227).  Saving model ...
	 Train_Loss: 0.2668 Train_Acc: 86.721 Val_Loss: 0.1502  BEST VAL Loss: 0.1502  Val_Acc: 95.837

Epoch 31: Validation loss decreased (0.150227 --> 0.149293).  Saving model ...
	 Train_Loss: 0.2651 Train_Acc: 86.654 Val_Loss: 0.1493  BEST VAL Loss: 0.1493  Val_Acc: 96.598

Epoch 32: Validation loss decreased (0.149293 --> 0.148184).  Saving model ...
	 Train_Loss: 0.2636 Train_Acc: 86.626 Val_Loss: 0.1482  BEST VAL Loss: 0.1482  Val_Acc: 96.016

Epoch 33: Validation loss decreased (0.148184 --> 0.146820).  Saving model ...
	 Train_Loss: 0.2620 Train_Acc: 86.894 Val_Loss: 0.1468  BEST VAL Loss: 0.1468  Val_Acc: 96.285

Epoch 34: Validation loss decreased (0.146820 --> 0.146115).  Saving model ...
	 Train_Loss: 0.2605 Train_Acc: 86.922 Val_Loss: 0.1461  BEST VAL Loss: 0.1461  Val_Acc: 96.195

Epoch 35: Validation loss decreased (0.146115 --> 0.145321).  Saving model ...
	 Train_Loss: 0.2592 Train_Acc: 86.821 Val_Loss: 0.1453  BEST VAL Loss: 0.1453  Val_Acc: 96.509

Epoch 36: Validation loss decreased (0.145321 --> 0.144645).  Saving model ...
	 Train_Loss: 0.2579 Train_Acc: 86.598 Val_Loss: 0.1446  BEST VAL Loss: 0.1446  Val_Acc: 96.106

Epoch 37: Validation loss decreased (0.144645 --> 0.143935).  Saving model ...
	 Train_Loss: 0.2568 Train_Acc: 86.743 Val_Loss: 0.1439  BEST VAL Loss: 0.1439  Val_Acc: 96.061

Epoch 38: Validation loss decreased (0.143935 --> 0.143337).  Saving model ...
	 Train_Loss: 0.2558 Train_Acc: 86.805 Val_Loss: 0.1433  BEST VAL Loss: 0.1433  Val_Acc: 96.106

Epoch 39: Validation loss decreased (0.143337 --> 0.142486).  Saving model ...
	 Train_Loss: 0.2547 Train_Acc: 86.877 Val_Loss: 0.1425  BEST VAL Loss: 0.1425  Val_Acc: 96.195

Epoch 40: Validation loss decreased (0.142486 --> 0.141924).  Saving model ...
	 Train_Loss: 0.2535 Train_Acc: 86.911 Val_Loss: 0.1419  BEST VAL Loss: 0.1419  Val_Acc: 96.150

Epoch 41: Validation loss decreased (0.141924 --> 0.141736).  Saving model ...
	 Train_Loss: 0.2524 Train_Acc: 86.973 Val_Loss: 0.1417  BEST VAL Loss: 0.1417  Val_Acc: 95.927

Epoch 42: Validation loss decreased (0.141736 --> 0.141128).  Saving model ...
	 Train_Loss: 0.2512 Train_Acc: 87.605 Val_Loss: 0.1411  BEST VAL Loss: 0.1411  Val_Acc: 95.703

Epoch 43: Validation loss decreased (0.141128 --> 0.141118).  Saving model ...
	 Train_Loss: 0.2502 Train_Acc: 86.581 Val_Loss: 0.1411  BEST VAL Loss: 0.1411  Val_Acc: 96.061

Epoch 44: Validation loss decreased (0.141118 --> 0.140334).  Saving model ...
	 Train_Loss: 0.2493 Train_Acc: 87.096 Val_Loss: 0.1403  BEST VAL Loss: 0.1403  Val_Acc: 96.240

Epoch 45: Validation loss decreased (0.140334 --> 0.139581).  Saving model ...
	 Train_Loss: 0.2485 Train_Acc: 87.107 Val_Loss: 0.1396  BEST VAL Loss: 0.1396  Val_Acc: 96.285

Epoch 46: Validation loss decreased (0.139581 --> 0.138942).  Saving model ...
	 Train_Loss: 0.2476 Train_Acc: 87.073 Val_Loss: 0.1389  BEST VAL Loss: 0.1389  Val_Acc: 96.240

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.2466 Train_Acc: 87.331 Val_Loss: 0.1390  BEST VAL Loss: 0.1389  Val_Acc: 96.150

Epoch 48: Validation loss decreased (0.138942 --> 0.138362).  Saving model ...
	 Train_Loss: 0.2457 Train_Acc: 87.308 Val_Loss: 0.1384  BEST VAL Loss: 0.1384  Val_Acc: 95.882

Epoch 49: Validation loss decreased (0.138362 --> 0.137976).  Saving model ...
	 Train_Loss: 0.2449 Train_Acc: 87.073 Val_Loss: 0.1380  BEST VAL Loss: 0.1380  Val_Acc: 96.329

Epoch 50: Validation loss decreased (0.137976 --> 0.137427).  Saving model ...
	 Train_Loss: 0.2441 Train_Acc: 87.258 Val_Loss: 0.1374  BEST VAL Loss: 0.1374  Val_Acc: 96.329

Epoch 51: Validation loss decreased (0.137427 --> 0.137134).  Saving model ...
	 Train_Loss: 0.2435 Train_Acc: 87.084 Val_Loss: 0.1371  BEST VAL Loss: 0.1371  Val_Acc: 96.061

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.2427 Train_Acc: 87.269 Val_Loss: 0.1372  BEST VAL Loss: 0.1371  Val_Acc: 96.016

Epoch 53: Validation loss decreased (0.137134 --> 0.136629).  Saving model ...
	 Train_Loss: 0.2421 Train_Acc: 86.855 Val_Loss: 0.1366  BEST VAL Loss: 0.1366  Val_Acc: 96.598

Epoch 54: Validation loss decreased (0.136629 --> 0.136500).  Saving model ...
	 Train_Loss: 0.2413 Train_Acc: 87.241 Val_Loss: 0.1365  BEST VAL Loss: 0.1365  Val_Acc: 96.553

Epoch 55: Validation loss decreased (0.136500 --> 0.136052).  Saving model ...
	 Train_Loss: 0.2406 Train_Acc: 87.213 Val_Loss: 0.1361  BEST VAL Loss: 0.1361  Val_Acc: 96.553

Epoch 56: Validation loss decreased (0.136052 --> 0.135718).  Saving model ...
	 Train_Loss: 0.2399 Train_Acc: 87.292 Val_Loss: 0.1357  BEST VAL Loss: 0.1357  Val_Acc: 96.688

Epoch 57: Validation loss decreased (0.135718 --> 0.135554).  Saving model ...
	 Train_Loss: 0.2393 Train_Acc: 86.995 Val_Loss: 0.1356  BEST VAL Loss: 0.1356  Val_Acc: 96.240

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.2387 Train_Acc: 87.029 Val_Loss: 0.1358  BEST VAL Loss: 0.1356  Val_Acc: 96.016

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.2382 Train_Acc: 87.062 Val_Loss: 0.1358  BEST VAL Loss: 0.1356  Val_Acc: 96.329

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.2377 Train_Acc: 86.866 Val_Loss: 0.1356  BEST VAL Loss: 0.1356  Val_Acc: 95.971

Epoch 61: Validation loss decreased (0.135554 --> 0.134975).  Saving model ...
	 Train_Loss: 0.2372 Train_Acc: 87.543 Val_Loss: 0.1350  BEST VAL Loss: 0.1350  Val_Acc: 96.643

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.2366 Train_Acc: 87.292 Val_Loss: 0.1352  BEST VAL Loss: 0.1350  Val_Acc: 96.150

Epoch 63: Validation loss decreased (0.134975 --> 0.134731).  Saving model ...
	 Train_Loss: 0.2362 Train_Acc: 87.112 Val_Loss: 0.1347  BEST VAL Loss: 0.1347  Val_Acc: 96.329

Epoch 64: Validation loss decreased (0.134731 --> 0.134064).  Saving model ...
	 Train_Loss: 0.2357 Train_Acc: 87.045 Val_Loss: 0.1341  BEST VAL Loss: 0.1341  Val_Acc: 96.329

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.2352 Train_Acc: 87.236 Val_Loss: 0.1342  BEST VAL Loss: 0.1341  Val_Acc: 96.240

Epoch 66: Validation loss decreased (0.134064 --> 0.133971).  Saving model ...
	 Train_Loss: 0.2347 Train_Acc: 87.555 Val_Loss: 0.1340  BEST VAL Loss: 0.1340  Val_Acc: 96.464

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.2342 Train_Acc: 87.364 Val_Loss: 0.1347  BEST VAL Loss: 0.1340  Val_Acc: 96.285

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.2338 Train_Acc: 86.917 Val_Loss: 0.1344  BEST VAL Loss: 0.1340  Val_Acc: 96.285

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.2333 Train_Acc: 87.829 Val_Loss: 0.1344  BEST VAL Loss: 0.1340  Val_Acc: 96.240

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.2328 Train_Acc: 87.728 Val_Loss: 0.1344  BEST VAL Loss: 0.1340  Val_Acc: 96.285

Epoch 71: Validation loss decreased (0.133971 --> 0.133951).  Saving model ...
	 Train_Loss: 0.2324 Train_Acc: 87.264 Val_Loss: 0.1340  BEST VAL Loss: 0.1340  Val_Acc: 95.971

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.2319 Train_Acc: 87.174 Val_Loss: 0.1341  BEST VAL Loss: 0.1340  Val_Acc: 95.658

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.2315 Train_Acc: 87.163 Val_Loss: 0.1342  BEST VAL Loss: 0.1340  Val_Acc: 95.568

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.2311 Train_Acc: 87.297 Val_Loss: 0.1344  BEST VAL Loss: 0.1340  Val_Acc: 96.061

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.2307 Train_Acc: 87.532 Val_Loss: 0.1345  BEST VAL Loss: 0.1340  Val_Acc: 95.837

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.2304 Train_Acc: 87.163 Val_Loss: 0.1345  BEST VAL Loss: 0.1340  Val_Acc: 96.061

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.2300 Train_Acc: 87.191 Val_Loss: 0.1343  BEST VAL Loss: 0.1340  Val_Acc: 96.867

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.2297 Train_Acc: 87.152 Val_Loss: 0.1342  BEST VAL Loss: 0.1340  Val_Acc: 96.464

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.2293 Train_Acc: 86.710 Val_Loss: 0.1340  BEST VAL Loss: 0.1340  Val_Acc: 96.867

Epoch 80: Validation loss decreased (0.133951 --> 0.133521).  Saving model ...
	 Train_Loss: 0.2289 Train_Acc: 87.633 Val_Loss: 0.1335  BEST VAL Loss: 0.1335  Val_Acc: 96.643

Epoch 81: Validation loss decreased (0.133521 --> 0.133250).  Saving model ...
	 Train_Loss: 0.2286 Train_Acc: 86.984 Val_Loss: 0.1332  BEST VAL Loss: 0.1332  Val_Acc: 96.374

Epoch 82: Validation loss decreased (0.133250 --> 0.132994).  Saving model ...
	 Train_Loss: 0.2283 Train_Acc: 87.107 Val_Loss: 0.1330  BEST VAL Loss: 0.1330  Val_Acc: 96.329

Epoch 83: Validation loss decreased (0.132994 --> 0.132798).  Saving model ...
	 Train_Loss: 0.2280 Train_Acc: 87.359 Val_Loss: 0.1328  BEST VAL Loss: 0.1328  Val_Acc: 96.688

Epoch 84: Validation loss decreased (0.132798 --> 0.132577).  Saving model ...
	 Train_Loss: 0.2277 Train_Acc: 87.336 Val_Loss: 0.1326  BEST VAL Loss: 0.1326  Val_Acc: 96.240

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.2274 Train_Acc: 87.135 Val_Loss: 0.1326  BEST VAL Loss: 0.1326  Val_Acc: 96.150

Epoch 86: Validation loss decreased (0.132577 --> 0.132460).  Saving model ...
	 Train_Loss: 0.2270 Train_Acc: 87.415 Val_Loss: 0.1325  BEST VAL Loss: 0.1325  Val_Acc: 96.195

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.2267 Train_Acc: 86.973 Val_Loss: 0.1327  BEST VAL Loss: 0.1325  Val_Acc: 96.106

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.2264 Train_Acc: 87.420 Val_Loss: 0.1329  BEST VAL Loss: 0.1325  Val_Acc: 96.509

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.2261 Train_Acc: 87.364 Val_Loss: 0.1333  BEST VAL Loss: 0.1325  Val_Acc: 96.016

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.2257 Train_Acc: 87.555 Val_Loss: 0.1334  BEST VAL Loss: 0.1325  Val_Acc: 96.061

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.2255 Train_Acc: 87.208 Val_Loss: 0.1331  BEST VAL Loss: 0.1325  Val_Acc: 96.509

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.2252 Train_Acc: 87.409 Val_Loss: 0.1329  BEST VAL Loss: 0.1325  Val_Acc: 96.643

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.2248 Train_Acc: 87.639 Val_Loss: 0.1326  BEST VAL Loss: 0.1325  Val_Acc: 96.867

Epoch 94: Validation loss decreased (0.132460 --> 0.132361).  Saving model ...
	 Train_Loss: 0.2246 Train_Acc: 87.353 Val_Loss: 0.1324  BEST VAL Loss: 0.1324  Val_Acc: 96.464

Epoch 95: Validation loss decreased (0.132361 --> 0.132131).  Saving model ...
	 Train_Loss: 0.2243 Train_Acc: 87.532 Val_Loss: 0.1321  BEST VAL Loss: 0.1321  Val_Acc: 96.732

Epoch 96: Validation loss did not decrease
	 Train_Loss: 0.2240 Train_Acc: 87.868 Val_Loss: 0.1323  BEST VAL Loss: 0.1321  Val_Acc: 96.777

Epoch 97: Validation loss did not decrease
	 Train_Loss: 0.2237 Train_Acc: 87.711 Val_Loss: 0.1322  BEST VAL Loss: 0.1321  Val_Acc: 96.867

Epoch 98: Validation loss decreased (0.132131 --> 0.132029).  Saving model ...
	 Train_Loss: 0.2234 Train_Acc: 87.275 Val_Loss: 0.1320  BEST VAL Loss: 0.1320  Val_Acc: 97.404

Epoch 99: Validation loss did not decrease
	 Train_Loss: 0.2232 Train_Acc: 87.118 Val_Loss: 0.1328  BEST VAL Loss: 0.1320  Val_Acc: 96.688

Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.53      0.53      9434
           1       0.47      0.47      0.47      8436

    accuracy                           0.50     17870
   macro avg       0.50      0.50      0.50     17870
weighted avg       0.50      0.50      0.50     17870

Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.53      0.53      1179
           1       0.47      0.47      0.47      1055

    accuracy                           0.50      2234
   macro avg       0.50      0.50      0.50      2234
weighted avg       0.50      0.50      0.50      2234

Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.53      0.53      1179
           1       0.47      0.46      0.47      1055

    accuracy                           0.50      2234
   macro avg       0.50      0.50      0.50      2234
weighted avg       0.50      0.50      0.50      2234

              precision    recall  f1-score   support

           0       0.53      0.53      0.53      1179
           1       0.47      0.46      0.47      1055

    accuracy                           0.50      2234
   macro avg       0.50      0.50      0.50      2234
weighted avg       0.50      0.50      0.50      2234

Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.51      0.51      4017
           1       0.48      0.47      0.48      3856

    accuracy                           0.49      7873
   macro avg       0.49      0.49      0.49      7873
weighted avg       0.49      0.49      0.49      7873

              precision    recall  f1-score   support

           0       0.50      0.51      0.51      4017
           1       0.48      0.47      0.48      3856

    accuracy                           0.49      7873
   macro avg       0.49      0.49      0.49      7873
weighted avg       0.49      0.49      0.49      7873

completed
