[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'cbe5762f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '4fcd31ec'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '59478f5c'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'f770d2fe'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_0.100_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_0.100_DMSO_0.025
TREATMENT_NAME: Flagellin_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (33319, 1276)
Number of total missing values across all columns: 66638
Data Subset Is Off
Wells held out for testing: ['C21' 'M22']
Wells to use for training, validation, and testing ['C16' 'C17' 'C20' 'M18' 'M19' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.658044).  Saving model ...
	 Train_Loss: 0.6850 Train_Acc: 55.125 Val_Loss: 0.6580  BEST VAL Loss: 0.6580  Val_Acc: 61.290

Epoch 1: Validation loss decreased (0.658044 --> 0.642008).  Saving model ...
	 Train_Loss: 0.6701 Train_Acc: 60.011 Val_Loss: 0.6420  BEST VAL Loss: 0.6420  Val_Acc: 65.605

Epoch 2: Validation loss decreased (0.642008 --> 0.623766).  Saving model ...
	 Train_Loss: 0.6549 Train_Acc: 63.329 Val_Loss: 0.6238  BEST VAL Loss: 0.6238  Val_Acc: 70.161

Epoch 3: Validation loss decreased (0.623766 --> 0.610023).  Saving model ...
	 Train_Loss: 0.6405 Train_Acc: 65.512 Val_Loss: 0.6100  BEST VAL Loss: 0.6100  Val_Acc: 70.847

Epoch 4: Validation loss decreased (0.610023 --> 0.600925).  Saving model ...
	 Train_Loss: 0.6288 Train_Acc: 66.616 Val_Loss: 0.6009  BEST VAL Loss: 0.6009  Val_Acc: 71.774

Epoch 5: Validation loss decreased (0.600925 --> 0.593260).  Saving model ...
	 Train_Loss: 0.6182 Train_Acc: 68.003 Val_Loss: 0.5933  BEST VAL Loss: 0.5933  Val_Acc: 71.250

Epoch 6: Validation loss decreased (0.593260 --> 0.586360).  Saving model ...
	 Train_Loss: 0.6096 Train_Acc: 68.583 Val_Loss: 0.5864  BEST VAL Loss: 0.5864  Val_Acc: 72.379

Epoch 7: Validation loss decreased (0.586360 --> 0.580985).  Saving model ...
	 Train_Loss: 0.6017 Train_Acc: 69.702 Val_Loss: 0.5810  BEST VAL Loss: 0.5810  Val_Acc: 71.895

Epoch 8: Validation loss decreased (0.580985 --> 0.576076).  Saving model ...
	 Train_Loss: 0.5948 Train_Acc: 69.591 Val_Loss: 0.5761  BEST VAL Loss: 0.5761  Val_Acc: 73.145

Epoch 9: Validation loss decreased (0.576076 --> 0.571300).  Saving model ...
	 Train_Loss: 0.5886 Train_Acc: 70.524 Val_Loss: 0.5713  BEST VAL Loss: 0.5713  Val_Acc: 73.629

Epoch 10: Validation loss decreased (0.571300 --> 0.567515).  Saving model ...
	 Train_Loss: 0.5838 Train_Acc: 70.070 Val_Loss: 0.5675  BEST VAL Loss: 0.5675  Val_Acc: 73.508

Epoch 11: Validation loss decreased (0.567515 --> 0.564131).  Saving model ...
	 Train_Loss: 0.5786 Train_Acc: 71.215 Val_Loss: 0.5641  BEST VAL Loss: 0.5641  Val_Acc: 73.266

Epoch 12: Validation loss decreased (0.564131 --> 0.561678).  Saving model ...
	 Train_Loss: 0.5740 Train_Acc: 71.421 Val_Loss: 0.5617  BEST VAL Loss: 0.5617  Val_Acc: 73.710

Epoch 13: Validation loss decreased (0.561678 --> 0.558509).  Saving model ...
	 Train_Loss: 0.5699 Train_Acc: 71.361 Val_Loss: 0.5585  BEST VAL Loss: 0.5585  Val_Acc: 74.879

Epoch 14: Validation loss decreased (0.558509 --> 0.555287).  Saving model ...
	 Train_Loss: 0.5662 Train_Acc: 71.714 Val_Loss: 0.5553  BEST VAL Loss: 0.5553  Val_Acc: 74.718

Epoch 15: Validation loss decreased (0.555287 --> 0.553180).  Saving model ...
	 Train_Loss: 0.5624 Train_Acc: 71.749 Val_Loss: 0.5532  BEST VAL Loss: 0.5532  Val_Acc: 74.234

Epoch 16: Validation loss decreased (0.553180 --> 0.550782).  Saving model ...
	 Train_Loss: 0.5592 Train_Acc: 71.442 Val_Loss: 0.5508  BEST VAL Loss: 0.5508  Val_Acc: 74.597

Epoch 17: Validation loss decreased (0.550782 --> 0.549141).  Saving model ...
	 Train_Loss: 0.5562 Train_Acc: 72.021 Val_Loss: 0.5491  BEST VAL Loss: 0.5491  Val_Acc: 74.234

Epoch 18: Validation loss decreased (0.549141 --> 0.546999).  Saving model ...
	 Train_Loss: 0.5534 Train_Acc: 72.354 Val_Loss: 0.5470  BEST VAL Loss: 0.5470  Val_Acc: 74.234

Epoch 19: Validation loss decreased (0.546999 --> 0.545231).  Saving model ...
	 Train_Loss: 0.5508 Train_Acc: 72.364 Val_Loss: 0.5452  BEST VAL Loss: 0.5452  Val_Acc: 74.798

Epoch 20: Validation loss decreased (0.545231 --> 0.543530).  Saving model ...
	 Train_Loss: 0.5479 Train_Acc: 73.070 Val_Loss: 0.5435  BEST VAL Loss: 0.5435  Val_Acc: 74.355

Epoch 21: Validation loss decreased (0.543530 --> 0.542632).  Saving model ...
	 Train_Loss: 0.5454 Train_Acc: 73.363 Val_Loss: 0.5426  BEST VAL Loss: 0.5426  Val_Acc: 74.315

Epoch 22: Validation loss decreased (0.542632 --> 0.541416).  Saving model ...
	 Train_Loss: 0.5430 Train_Acc: 73.363 Val_Loss: 0.5414  BEST VAL Loss: 0.5414  Val_Acc: 73.710

Epoch 23: Validation loss decreased (0.541416 --> 0.540221).  Saving model ...
	 Train_Loss: 0.5408 Train_Acc: 73.171 Val_Loss: 0.5402  BEST VAL Loss: 0.5402  Val_Acc: 74.315

Epoch 24: Validation loss decreased (0.540221 --> 0.538772).  Saving model ...
	 Train_Loss: 0.5386 Train_Acc: 73.257 Val_Loss: 0.5388  BEST VAL Loss: 0.5388  Val_Acc: 74.879

Epoch 25: Validation loss decreased (0.538772 --> 0.537298).  Saving model ...
	 Train_Loss: 0.5364 Train_Acc: 73.826 Val_Loss: 0.5373  BEST VAL Loss: 0.5373  Val_Acc: 75.887

Epoch 26: Validation loss decreased (0.537298 --> 0.536247).  Saving model ...
	 Train_Loss: 0.5345 Train_Acc: 73.559 Val_Loss: 0.5362  BEST VAL Loss: 0.5362  Val_Acc: 74.234

Epoch 27: Validation loss decreased (0.536247 --> 0.535871).  Saving model ...
	 Train_Loss: 0.5324 Train_Acc: 73.867 Val_Loss: 0.5359  BEST VAL Loss: 0.5359  Val_Acc: 74.274

Epoch 28: Validation loss decreased (0.535871 --> 0.535174).  Saving model ...
	 Train_Loss: 0.5306 Train_Acc: 73.650 Val_Loss: 0.5352  BEST VAL Loss: 0.5352  Val_Acc: 75.040

Epoch 29: Validation loss decreased (0.535174 --> 0.534656).  Saving model ...
	 Train_Loss: 0.5289 Train_Acc: 74.013 Val_Loss: 0.5347  BEST VAL Loss: 0.5347  Val_Acc: 74.032

Epoch 30: Validation loss decreased (0.534656 --> 0.533669).  Saving model ...
	 Train_Loss: 0.5274 Train_Acc: 73.584 Val_Loss: 0.5337  BEST VAL Loss: 0.5337  Val_Acc: 75.081

Epoch 31: Validation loss decreased (0.533669 --> 0.533053).  Saving model ...
	 Train_Loss: 0.5257 Train_Acc: 74.416 Val_Loss: 0.5331  BEST VAL Loss: 0.5331  Val_Acc: 74.597

Epoch 32: Validation loss decreased (0.533053 --> 0.532332).  Saving model ...
	 Train_Loss: 0.5241 Train_Acc: 74.215 Val_Loss: 0.5323  BEST VAL Loss: 0.5323  Val_Acc: 76.210

Epoch 33: Validation loss decreased (0.532332 --> 0.531489).  Saving model ...
	 Train_Loss: 0.5226 Train_Acc: 74.487 Val_Loss: 0.5315  BEST VAL Loss: 0.5315  Val_Acc: 74.919

Epoch 34: Validation loss decreased (0.531489 --> 0.531144).  Saving model ...
	 Train_Loss: 0.5211 Train_Acc: 74.129 Val_Loss: 0.5311  BEST VAL Loss: 0.5311  Val_Acc: 74.879

Epoch 35: Validation loss decreased (0.531144 --> 0.530689).  Saving model ...
	 Train_Loss: 0.5196 Train_Acc: 74.936 Val_Loss: 0.5307  BEST VAL Loss: 0.5307  Val_Acc: 74.677

Epoch 36: Validation loss decreased (0.530689 --> 0.530100).  Saving model ...
	 Train_Loss: 0.5182 Train_Acc: 74.366 Val_Loss: 0.5301  BEST VAL Loss: 0.5301  Val_Acc: 75.484

Epoch 37: Validation loss decreased (0.530100 --> 0.529464).  Saving model ...
	 Train_Loss: 0.5169 Train_Acc: 74.512 Val_Loss: 0.5295  BEST VAL Loss: 0.5295  Val_Acc: 74.758

Epoch 38: Validation loss decreased (0.529464 --> 0.528951).  Saving model ...
	 Train_Loss: 0.5154 Train_Acc: 75.117 Val_Loss: 0.5290  BEST VAL Loss: 0.5290  Val_Acc: 75.524

Epoch 39: Validation loss decreased (0.528951 --> 0.528562).  Saving model ...
	 Train_Loss: 0.5140 Train_Acc: 75.218 Val_Loss: 0.5286  BEST VAL Loss: 0.5286  Val_Acc: 75.121

Epoch 40: Validation loss decreased (0.528562 --> 0.528038).  Saving model ...
	 Train_Loss: 0.5128 Train_Acc: 75.052 Val_Loss: 0.5280  BEST VAL Loss: 0.5280  Val_Acc: 74.194

Epoch 41: Validation loss decreased (0.528038 --> 0.527489).  Saving model ...
	 Train_Loss: 0.5115 Train_Acc: 74.547 Val_Loss: 0.5275  BEST VAL Loss: 0.5275  Val_Acc: 75.806

Epoch 42: Validation loss decreased (0.527489 --> 0.526918).  Saving model ...
	 Train_Loss: 0.5103 Train_Acc: 74.724 Val_Loss: 0.5269  BEST VAL Loss: 0.5269  Val_Acc: 75.444

Epoch 43: Validation loss decreased (0.526918 --> 0.526744).  Saving model ...
	 Train_Loss: 0.5091 Train_Acc: 75.153 Val_Loss: 0.5267  BEST VAL Loss: 0.5267  Val_Acc: 74.153

Epoch 44: Validation loss decreased (0.526744 --> 0.526510).  Saving model ...
	 Train_Loss: 0.5080 Train_Acc: 74.951 Val_Loss: 0.5265  BEST VAL Loss: 0.5265  Val_Acc: 74.758

Epoch 45: Validation loss decreased (0.526510 --> 0.526120).  Saving model ...
	 Train_Loss: 0.5070 Train_Acc: 75.284 Val_Loss: 0.5261  BEST VAL Loss: 0.5261  Val_Acc: 74.919

Epoch 46: Validation loss decreased (0.526120 --> 0.525856).  Saving model ...
	 Train_Loss: 0.5060 Train_Acc: 74.779 Val_Loss: 0.5259  BEST VAL Loss: 0.5259  Val_Acc: 73.750

Epoch 47: Validation loss decreased (0.525856 --> 0.525533).  Saving model ...
	 Train_Loss: 0.5049 Train_Acc: 75.127 Val_Loss: 0.5255  BEST VAL Loss: 0.5255  Val_Acc: 76.169

Epoch 48: Validation loss decreased (0.525533 --> 0.525429).  Saving model ...
	 Train_Loss: 0.5038 Train_Acc: 75.309 Val_Loss: 0.5254  BEST VAL Loss: 0.5254  Val_Acc: 74.960

Epoch 49: Validation loss decreased (0.525429 --> 0.525171).  Saving model ...
	 Train_Loss: 0.5028 Train_Acc: 75.203 Val_Loss: 0.5252  BEST VAL Loss: 0.5252  Val_Acc: 75.121

Epoch 50: Validation loss decreased (0.525171 --> 0.524818).  Saving model ...
	 Train_Loss: 0.5019 Train_Acc: 75.153 Val_Loss: 0.5248  BEST VAL Loss: 0.5248  Val_Acc: 75.323

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.5008 Train_Acc: 75.465 Val_Loss: 0.5249  BEST VAL Loss: 0.5248  Val_Acc: 75.161

Epoch 52: Validation loss decreased (0.524818 --> 0.524675).  Saving model ...
	 Train_Loss: 0.5000 Train_Acc: 75.490 Val_Loss: 0.5247  BEST VAL Loss: 0.5247  Val_Acc: 74.718

Epoch 53: Validation loss decreased (0.524675 --> 0.524389).  Saving model ...
	 Train_Loss: 0.4991 Train_Acc: 75.253 Val_Loss: 0.5244  BEST VAL Loss: 0.5244  Val_Acc: 74.718

Epoch 54: Validation loss decreased (0.524389 --> 0.524256).  Saving model ...
	 Train_Loss: 0.4982 Train_Acc: 75.354 Val_Loss: 0.5243  BEST VAL Loss: 0.5243  Val_Acc: 75.081

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.4974 Train_Acc: 75.455 Val_Loss: 0.5243  BEST VAL Loss: 0.5243  Val_Acc: 75.323

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.4966 Train_Acc: 75.319 Val_Loss: 0.5245  BEST VAL Loss: 0.5243  Val_Acc: 74.395

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.4958 Train_Acc: 75.379 Val_Loss: 0.5243  BEST VAL Loss: 0.5243  Val_Acc: 75.202

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.4951 Train_Acc: 75.581 Val_Loss: 0.5243  BEST VAL Loss: 0.5243  Val_Acc: 75.081

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.4943 Train_Acc: 75.591 Val_Loss: 0.5245  BEST VAL Loss: 0.5243  Val_Acc: 74.758

Epoch 60: Validation loss decreased (0.524256 --> 0.524238).  Saving model ...
	 Train_Loss: 0.4934 Train_Acc: 75.843 Val_Loss: 0.5242  BEST VAL Loss: 0.5242  Val_Acc: 75.484

Epoch 61: Validation loss decreased (0.524238 --> 0.524219).  Saving model ...
	 Train_Loss: 0.4927 Train_Acc: 75.667 Val_Loss: 0.5242  BEST VAL Loss: 0.5242  Val_Acc: 74.516

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.4918 Train_Acc: 76.337 Val_Loss: 0.5243  BEST VAL Loss: 0.5242  Val_Acc: 74.839

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.4910 Train_Acc: 75.853 Val_Loss: 0.5244  BEST VAL Loss: 0.5242  Val_Acc: 75.202

Epoch 64: Validation loss decreased (0.524219 --> 0.524206).  Saving model ...
	 Train_Loss: 0.4904 Train_Acc: 75.818 Val_Loss: 0.5242  BEST VAL Loss: 0.5242  Val_Acc: 76.250

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.4897 Train_Acc: 75.087 Val_Loss: 0.5242  BEST VAL Loss: 0.5242  Val_Acc: 75.323

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.4890 Train_Acc: 75.874 Val_Loss: 0.5244  BEST VAL Loss: 0.5242  Val_Acc: 75.524

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.4883 Train_Acc: 75.505 Val_Loss: 0.5246  BEST VAL Loss: 0.5242  Val_Acc: 75.202

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.4876 Train_Acc: 76.267 Val_Loss: 0.5247  BEST VAL Loss: 0.5242  Val_Acc: 75.363

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.4870 Train_Acc: 75.758 Val_Loss: 0.5246  BEST VAL Loss: 0.5242  Val_Acc: 74.919

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.4864 Train_Acc: 75.818 Val_Loss: 0.5245  BEST VAL Loss: 0.5242  Val_Acc: 75.081

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.4858 Train_Acc: 76.166 Val_Loss: 0.5245  BEST VAL Loss: 0.5242  Val_Acc: 75.040

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.4851 Train_Acc: 76.176 Val_Loss: 0.5246  BEST VAL Loss: 0.5242  Val_Acc: 75.363

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.4845 Train_Acc: 75.984 Val_Loss: 0.5246  BEST VAL Loss: 0.5242  Val_Acc: 74.798

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.4839 Train_Acc: 76.131 Val_Loss: 0.5247  BEST VAL Loss: 0.5242  Val_Acc: 74.597

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.4833 Train_Acc: 76.221 Val_Loss: 0.5249  BEST VAL Loss: 0.5242  Val_Acc: 75.040

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.4826 Train_Acc: 76.221 Val_Loss: 0.5251  BEST VAL Loss: 0.5242  Val_Acc: 75.040

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.4820 Train_Acc: 76.615 Val_Loss: 0.5254  BEST VAL Loss: 0.5242  Val_Acc: 75.121

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.4814 Train_Acc: 76.781 Val_Loss: 0.5254  BEST VAL Loss: 0.5242  Val_Acc: 75.565

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.4808 Train_Acc: 76.443 Val_Loss: 0.5256  BEST VAL Loss: 0.5242  Val_Acc: 74.960

Epoch 80: Validation loss did not decrease
Early stopped at epoch : 80
LPS_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.46      0.47      9433
           1       0.53      0.54      0.53     10400

    accuracy                           0.50     19833
   macro avg       0.50      0.50      0.50     19833
weighted avg       0.50      0.50      0.50     19833

LPS_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.45      0.46      1180
           1       0.51      0.52      0.52      1300

    accuracy                           0.49      2480
   macro avg       0.49      0.49      0.49      2480
weighted avg       0.49      0.49      0.49      2480

LPS_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.48      0.49      1179
           1       0.54      0.56      0.55      1301

    accuracy                           0.52      2480
   macro avg       0.52      0.52      0.52      2480
weighted avg       0.52      0.52      0.52      2480

              precision    recall  f1-score   support

           0       0.50      0.48      0.49      1179
           1       0.54      0.56      0.55      1301

    accuracy                           0.52      2480
   macro avg       0.52      0.52      0.52      2480
weighted avg       0.52      0.52      0.52      2480

LPS_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.46      0.47      4017
           1       0.53      0.54      0.54      4509

    accuracy                           0.51      8526
   macro avg       0.50      0.50      0.50      8526
weighted avg       0.51      0.51      0.51      8526

              precision    recall  f1-score   support

           0       0.48      0.46      0.47      4017
           1       0.53      0.54      0.54      4509

    accuracy                           0.51      8526
   macro avg       0.50      0.50      0.50      8526
weighted avg       0.51      0.51      0.51      8526

completed
