[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'fb0aea95'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '86c2fed9'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '88d9cd79'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '55f494ab'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Thapsigargin_10.000_DMSO_0.025 treatment_name: LPS_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Thapsigargin_10.000_DMSO_0.025
TREATMENT_NAME: LPS_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'Thapsigargin_10.000_DMSO_0.025']
The dimensions of the data are: (306417, 1270)
Number of total missing values across all columns: 612834
Data Subset Is Off
Wells held out for testing: ['D08' 'L06']
Wells to use for training, validation, and testing ['D02' 'D03' 'E06' 'E07' 'D09' 'L07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.444781).  Saving model ...
	 Train_Loss: 0.5609 Train_Acc: 71.125 Val_Loss: 0.4448  BEST VAL Loss: 0.4448  Val_Acc: 81.187

Epoch 1: Validation loss decreased (0.444781 --> 0.402503).  Saving model ...
	 Train_Loss: 0.4930 Train_Acc: 80.745 Val_Loss: 0.4025  BEST VAL Loss: 0.4025  Val_Acc: 85.128

Epoch 2: Validation loss decreased (0.402503 --> 0.376285).  Saving model ...
	 Train_Loss: 0.4539 Train_Acc: 83.118 Val_Loss: 0.3763  BEST VAL Loss: 0.3763  Val_Acc: 86.764

Epoch 3: Validation loss decreased (0.376285 --> 0.357631).  Saving model ...
	 Train_Loss: 0.4275 Train_Acc: 84.467 Val_Loss: 0.3576  BEST VAL Loss: 0.3576  Val_Acc: 87.697

Epoch 4: Validation loss decreased (0.357631 --> 0.343548).  Saving model ...
	 Train_Loss: 0.4082 Train_Acc: 85.502 Val_Loss: 0.3435  BEST VAL Loss: 0.3435  Val_Acc: 88.360

Epoch 5: Validation loss decreased (0.343548 --> 0.332284).  Saving model ...
	 Train_Loss: 0.3932 Train_Acc: 86.149 Val_Loss: 0.3323  BEST VAL Loss: 0.3323  Val_Acc: 88.721

Epoch 6: Validation loss decreased (0.332284 --> 0.322793).  Saving model ...
	 Train_Loss: 0.3812 Train_Acc: 86.664 Val_Loss: 0.3228  BEST VAL Loss: 0.3228  Val_Acc: 89.415

Epoch 7: Validation loss decreased (0.322793 --> 0.315139).  Saving model ...
	 Train_Loss: 0.3708 Train_Acc: 87.275 Val_Loss: 0.3151  BEST VAL Loss: 0.3151  Val_Acc: 89.316

Epoch 8: Validation loss decreased (0.315139 --> 0.308261).  Saving model ...
	 Train_Loss: 0.3619 Train_Acc: 87.692 Val_Loss: 0.3083  BEST VAL Loss: 0.3083  Val_Acc: 89.667

Epoch 9: Validation loss decreased (0.308261 --> 0.302222).  Saving model ...
	 Train_Loss: 0.3542 Train_Acc: 88.076 Val_Loss: 0.3022  BEST VAL Loss: 0.3022  Val_Acc: 90.073

Epoch 10: Validation loss decreased (0.302222 --> 0.296892).  Saving model ...
	 Train_Loss: 0.3473 Train_Acc: 88.272 Val_Loss: 0.2969  BEST VAL Loss: 0.2969  Val_Acc: 90.082

Epoch 11: Validation loss decreased (0.296892 --> 0.292147).  Saving model ...
	 Train_Loss: 0.3412 Train_Acc: 88.496 Val_Loss: 0.2921  BEST VAL Loss: 0.2921  Val_Acc: 90.235

Epoch 12: Validation loss decreased (0.292147 --> 0.287813).  Saving model ...
	 Train_Loss: 0.3358 Train_Acc: 88.665 Val_Loss: 0.2878  BEST VAL Loss: 0.2878  Val_Acc: 90.452

Epoch 13: Validation loss decreased (0.287813 --> 0.283915).  Saving model ...
	 Train_Loss: 0.3308 Train_Acc: 88.918 Val_Loss: 0.2839  BEST VAL Loss: 0.2839  Val_Acc: 90.569

Epoch 14: Validation loss decreased (0.283915 --> 0.280342).  Saving model ...
	 Train_Loss: 0.3264 Train_Acc: 88.914 Val_Loss: 0.2803  BEST VAL Loss: 0.2803  Val_Acc: 90.722

Epoch 15: Validation loss decreased (0.280342 --> 0.277099).  Saving model ...
	 Train_Loss: 0.3222 Train_Acc: 89.128 Val_Loss: 0.2771  BEST VAL Loss: 0.2771  Val_Acc: 90.736

Epoch 16: Validation loss decreased (0.277099 --> 0.274110).  Saving model ...
	 Train_Loss: 0.3184 Train_Acc: 89.257 Val_Loss: 0.2741  BEST VAL Loss: 0.2741  Val_Acc: 90.862

Epoch 17: Validation loss decreased (0.274110 --> 0.271395).  Saving model ...
	 Train_Loss: 0.3149 Train_Acc: 89.284 Val_Loss: 0.2714  BEST VAL Loss: 0.2714  Val_Acc: 90.966

Epoch 18: Validation loss decreased (0.271395 --> 0.268856).  Saving model ...
	 Train_Loss: 0.3117 Train_Acc: 89.440 Val_Loss: 0.2689  BEST VAL Loss: 0.2689  Val_Acc: 90.952

Epoch 19: Validation loss decreased (0.268856 --> 0.266546).  Saving model ...
	 Train_Loss: 0.3086 Train_Acc: 89.575 Val_Loss: 0.2665  BEST VAL Loss: 0.2665  Val_Acc: 91.002

Epoch 20: Validation loss decreased (0.266546 --> 0.264314).  Saving model ...
	 Train_Loss: 0.3058 Train_Acc: 89.613 Val_Loss: 0.2643  BEST VAL Loss: 0.2643  Val_Acc: 91.024

Epoch 21: Validation loss decreased (0.264314 --> 0.262196).  Saving model ...
	 Train_Loss: 0.3031 Train_Acc: 89.630 Val_Loss: 0.2622  BEST VAL Loss: 0.2622  Val_Acc: 91.268

Epoch 22: Validation loss decreased (0.262196 --> 0.260217).  Saving model ...
	 Train_Loss: 0.3006 Train_Acc: 89.767 Val_Loss: 0.2602  BEST VAL Loss: 0.2602  Val_Acc: 91.209

Epoch 23: Validation loss decreased (0.260217 --> 0.258409).  Saving model ...
	 Train_Loss: 0.2982 Train_Acc: 89.876 Val_Loss: 0.2584  BEST VAL Loss: 0.2584  Val_Acc: 91.214

Epoch 24: Validation loss decreased (0.258409 --> 0.256636).  Saving model ...
	 Train_Loss: 0.2960 Train_Acc: 89.863 Val_Loss: 0.2566  BEST VAL Loss: 0.2566  Val_Acc: 91.340

Epoch 25: Validation loss decreased (0.256636 --> 0.254965).  Saving model ...
	 Train_Loss: 0.2939 Train_Acc: 89.940 Val_Loss: 0.2550  BEST VAL Loss: 0.2550  Val_Acc: 91.353

Epoch 26: Validation loss decreased (0.254965 --> 0.253419).  Saving model ...
	 Train_Loss: 0.2918 Train_Acc: 90.050 Val_Loss: 0.2534  BEST VAL Loss: 0.2534  Val_Acc: 91.448

Epoch 27: Validation loss decreased (0.253419 --> 0.251903).  Saving model ...
	 Train_Loss: 0.2899 Train_Acc: 90.047 Val_Loss: 0.2519  BEST VAL Loss: 0.2519  Val_Acc: 91.335

Epoch 28: Validation loss decreased (0.251903 --> 0.250560).  Saving model ...
	 Train_Loss: 0.2880 Train_Acc: 90.163 Val_Loss: 0.2506  BEST VAL Loss: 0.2506  Val_Acc: 91.286

Epoch 29: Validation loss decreased (0.250560 --> 0.249231).  Saving model ...
	 Train_Loss: 0.2863 Train_Acc: 90.101 Val_Loss: 0.2492  BEST VAL Loss: 0.2492  Val_Acc: 91.398

Epoch 30: Validation loss decreased (0.249231 --> 0.247882).  Saving model ...
	 Train_Loss: 0.2846 Train_Acc: 90.268 Val_Loss: 0.2479  BEST VAL Loss: 0.2479  Val_Acc: 91.462

Epoch 31: Validation loss decreased (0.247882 --> 0.246621).  Saving model ...
	 Train_Loss: 0.2830 Train_Acc: 90.145 Val_Loss: 0.2466  BEST VAL Loss: 0.2466  Val_Acc: 91.489

Epoch 32: Validation loss decreased (0.246621 --> 0.245462).  Saving model ...
	 Train_Loss: 0.2815 Train_Acc: 90.295 Val_Loss: 0.2455  BEST VAL Loss: 0.2455  Val_Acc: 91.511

Epoch 33: Validation loss decreased (0.245462 --> 0.244348).  Saving model ...
	 Train_Loss: 0.2800 Train_Acc: 90.342 Val_Loss: 0.2443  BEST VAL Loss: 0.2443  Val_Acc: 91.543

Epoch 34: Validation loss decreased (0.244348 --> 0.243276).  Saving model ...
	 Train_Loss: 0.2785 Train_Acc: 90.349 Val_Loss: 0.2433  BEST VAL Loss: 0.2433  Val_Acc: 91.660

Epoch 35: Validation loss decreased (0.243276 --> 0.242264).  Saving model ...
	 Train_Loss: 0.2772 Train_Acc: 90.369 Val_Loss: 0.2423  BEST VAL Loss: 0.2423  Val_Acc: 91.520

Epoch 36: Validation loss decreased (0.242264 --> 0.241284).  Saving model ...
	 Train_Loss: 0.2758 Train_Acc: 90.403 Val_Loss: 0.2413  BEST VAL Loss: 0.2413  Val_Acc: 91.637

Epoch 37: Validation loss decreased (0.241284 --> 0.240301).  Saving model ...
	 Train_Loss: 0.2746 Train_Acc: 90.429 Val_Loss: 0.2403  BEST VAL Loss: 0.2403  Val_Acc: 91.768

Epoch 38: Validation loss decreased (0.240301 --> 0.239366).  Saving model ...
	 Train_Loss: 0.2733 Train_Acc: 90.524 Val_Loss: 0.2394  BEST VAL Loss: 0.2394  Val_Acc: 91.714

Epoch 39: Validation loss decreased (0.239366 --> 0.238436).  Saving model ...
	 Train_Loss: 0.2722 Train_Acc: 90.553 Val_Loss: 0.2384  BEST VAL Loss: 0.2384  Val_Acc: 91.885

Epoch 40: Validation loss decreased (0.238436 --> 0.237607).  Saving model ...
	 Train_Loss: 0.2710 Train_Acc: 90.595 Val_Loss: 0.2376  BEST VAL Loss: 0.2376  Val_Acc: 91.741

Epoch 41: Validation loss decreased (0.237607 --> 0.236775).  Saving model ...
	 Train_Loss: 0.2699 Train_Acc: 90.566 Val_Loss: 0.2368  BEST VAL Loss: 0.2368  Val_Acc: 91.813

Epoch 42: Validation loss decreased (0.236775 --> 0.235968).  Saving model ...
	 Train_Loss: 0.2689 Train_Acc: 90.548 Val_Loss: 0.2360  BEST VAL Loss: 0.2360  Val_Acc: 91.700

Epoch 43: Validation loss decreased (0.235968 --> 0.235149).  Saving model ...
	 Train_Loss: 0.2678 Train_Acc: 90.625 Val_Loss: 0.2351  BEST VAL Loss: 0.2351  Val_Acc: 91.809

Epoch 44: Validation loss decreased (0.235149 --> 0.234395).  Saving model ...
	 Train_Loss: 0.2668 Train_Acc: 90.566 Val_Loss: 0.2344  BEST VAL Loss: 0.2344  Val_Acc: 91.845

Epoch 45: Validation loss decreased (0.234395 --> 0.233631).  Saving model ...
	 Train_Loss: 0.2659 Train_Acc: 90.663 Val_Loss: 0.2336  BEST VAL Loss: 0.2336  Val_Acc: 91.984

Epoch 46: Validation loss decreased (0.233631 --> 0.232936).  Saving model ...
	 Train_Loss: 0.2649 Train_Acc: 90.703 Val_Loss: 0.2329  BEST VAL Loss: 0.2329  Val_Acc: 91.872

Epoch 47: Validation loss decreased (0.232936 --> 0.232271).  Saving model ...
	 Train_Loss: 0.2640 Train_Acc: 90.597 Val_Loss: 0.2323  BEST VAL Loss: 0.2323  Val_Acc: 91.800

Epoch 48: Validation loss decreased (0.232271 --> 0.231606).  Saving model ...
	 Train_Loss: 0.2631 Train_Acc: 90.743 Val_Loss: 0.2316  BEST VAL Loss: 0.2316  Val_Acc: 91.957

Epoch 49: Validation loss decreased (0.231606 --> 0.230950).  Saving model ...
	 Train_Loss: 0.2623 Train_Acc: 90.680 Val_Loss: 0.2309  BEST VAL Loss: 0.2309  Val_Acc: 92.021

Epoch 50: Validation loss decreased (0.230950 --> 0.230279).  Saving model ...
	 Train_Loss: 0.2615 Train_Acc: 90.659 Val_Loss: 0.2303  BEST VAL Loss: 0.2303  Val_Acc: 92.030

Epoch 51: Validation loss decreased (0.230279 --> 0.229712).  Saving model ...
	 Train_Loss: 0.2606 Train_Acc: 90.837 Val_Loss: 0.2297  BEST VAL Loss: 0.2297  Val_Acc: 91.912

Epoch 52: Validation loss decreased (0.229712 --> 0.229141).  Saving model ...
	 Train_Loss: 0.2598 Train_Acc: 90.875 Val_Loss: 0.2291  BEST VAL Loss: 0.2291  Val_Acc: 92.061

Epoch 53: Validation loss decreased (0.229141 --> 0.228617).  Saving model ...
	 Train_Loss: 0.2591 Train_Acc: 90.801 Val_Loss: 0.2286  BEST VAL Loss: 0.2286  Val_Acc: 91.809

Epoch 54: Validation loss decreased (0.228617 --> 0.228040).  Saving model ...
	 Train_Loss: 0.2583 Train_Acc: 90.881 Val_Loss: 0.2280  BEST VAL Loss: 0.2280  Val_Acc: 92.030

Epoch 55: Validation loss decreased (0.228040 --> 0.227485).  Saving model ...
	 Train_Loss: 0.2576 Train_Acc: 90.934 Val_Loss: 0.2275  BEST VAL Loss: 0.2275  Val_Acc: 92.061

Epoch 56: Validation loss decreased (0.227485 --> 0.226919).  Saving model ...
	 Train_Loss: 0.2568 Train_Acc: 90.949 Val_Loss: 0.2269  BEST VAL Loss: 0.2269  Val_Acc: 91.998

Epoch 57: Validation loss decreased (0.226919 --> 0.226395).  Saving model ...
	 Train_Loss: 0.2561 Train_Acc: 90.920 Val_Loss: 0.2264  BEST VAL Loss: 0.2264  Val_Acc: 91.989

Epoch 58: Validation loss decreased (0.226395 --> 0.225885).  Saving model ...
	 Train_Loss: 0.2554 Train_Acc: 90.906 Val_Loss: 0.2259  BEST VAL Loss: 0.2259  Val_Acc: 91.962

Epoch 59: Validation loss decreased (0.225885 --> 0.225371).  Saving model ...
	 Train_Loss: 0.2548 Train_Acc: 90.988 Val_Loss: 0.2254  BEST VAL Loss: 0.2254  Val_Acc: 92.156

Epoch 60: Validation loss decreased (0.225371 --> 0.224935).  Saving model ...
	 Train_Loss: 0.2541 Train_Acc: 90.916 Val_Loss: 0.2249  BEST VAL Loss: 0.2249  Val_Acc: 91.849

Epoch 61: Validation loss decreased (0.224935 --> 0.224464).  Saving model ...
	 Train_Loss: 0.2535 Train_Acc: 90.956 Val_Loss: 0.2245  BEST VAL Loss: 0.2245  Val_Acc: 92.061

Epoch 62: Validation loss decreased (0.224464 --> 0.224027).  Saving model ...
	 Train_Loss: 0.2528 Train_Acc: 90.968 Val_Loss: 0.2240  BEST VAL Loss: 0.2240  Val_Acc: 91.827

Epoch 63: Validation loss decreased (0.224027 --> 0.223582).  Saving model ...
	 Train_Loss: 0.2522 Train_Acc: 91.006 Val_Loss: 0.2236  BEST VAL Loss: 0.2236  Val_Acc: 91.984

Epoch 64: Validation loss decreased (0.223582 --> 0.223146).  Saving model ...
	 Train_Loss: 0.2517 Train_Acc: 90.952 Val_Loss: 0.2231  BEST VAL Loss: 0.2231  Val_Acc: 92.021

Epoch 65: Validation loss decreased (0.223146 --> 0.222708).  Saving model ...
	 Train_Loss: 0.2511 Train_Acc: 91.092 Val_Loss: 0.2227  BEST VAL Loss: 0.2227  Val_Acc: 92.111

Epoch 66: Validation loss decreased (0.222708 --> 0.222314).  Saving model ...
	 Train_Loss: 0.2505 Train_Acc: 91.023 Val_Loss: 0.2223  BEST VAL Loss: 0.2223  Val_Acc: 92.052

Epoch 67: Validation loss decreased (0.222314 --> 0.221916).  Saving model ...
	 Train_Loss: 0.2500 Train_Acc: 91.012 Val_Loss: 0.2219  BEST VAL Loss: 0.2219  Val_Acc: 92.039

Epoch 68: Validation loss decreased (0.221916 --> 0.221544).  Saving model ...
	 Train_Loss: 0.2494 Train_Acc: 90.986 Val_Loss: 0.2215  BEST VAL Loss: 0.2215  Val_Acc: 91.912

Epoch 69: Validation loss decreased (0.221544 --> 0.221216).  Saving model ...
	 Train_Loss: 0.2489 Train_Acc: 91.126 Val_Loss: 0.2212  BEST VAL Loss: 0.2212  Val_Acc: 91.948

Epoch 70: Validation loss decreased (0.221216 --> 0.220828).  Saving model ...
	 Train_Loss: 0.2483 Train_Acc: 91.163 Val_Loss: 0.2208  BEST VAL Loss: 0.2208  Val_Acc: 92.030

Epoch 71: Validation loss decreased (0.220828 --> 0.220475).  Saving model ...
	 Train_Loss: 0.2478 Train_Acc: 91.131 Val_Loss: 0.2205  BEST VAL Loss: 0.2205  Val_Acc: 92.034

Epoch 72: Validation loss decreased (0.220475 --> 0.220090).  Saving model ...
	 Train_Loss: 0.2473 Train_Acc: 91.076 Val_Loss: 0.2201  BEST VAL Loss: 0.2201  Val_Acc: 92.205

Epoch 73: Validation loss decreased (0.220090 --> 0.219726).  Saving model ...
	 Train_Loss: 0.2468 Train_Acc: 91.226 Val_Loss: 0.2197  BEST VAL Loss: 0.2197  Val_Acc: 92.093

Epoch 74: Validation loss decreased (0.219726 --> 0.219393).  Saving model ...
	 Train_Loss: 0.2463 Train_Acc: 91.066 Val_Loss: 0.2194  BEST VAL Loss: 0.2194  Val_Acc: 92.034

Epoch 75: Validation loss decreased (0.219393 --> 0.219067).  Saving model ...
	 Train_Loss: 0.2459 Train_Acc: 91.112 Val_Loss: 0.2191  BEST VAL Loss: 0.2191  Val_Acc: 92.039

Epoch 76: Validation loss decreased (0.219067 --> 0.218745).  Saving model ...
	 Train_Loss: 0.2454 Train_Acc: 91.177 Val_Loss: 0.2187  BEST VAL Loss: 0.2187  Val_Acc: 92.057

Epoch 77: Validation loss decreased (0.218745 --> 0.218416).  Saving model ...
	 Train_Loss: 0.2449 Train_Acc: 91.174 Val_Loss: 0.2184  BEST VAL Loss: 0.2184  Val_Acc: 92.106

Epoch 78: Validation loss decreased (0.218416 --> 0.218094).  Saving model ...
	 Train_Loss: 0.2445 Train_Acc: 91.212 Val_Loss: 0.2181  BEST VAL Loss: 0.2181  Val_Acc: 92.151

Epoch 79: Validation loss decreased (0.218094 --> 0.217802).  Saving model ...
	 Train_Loss: 0.2440 Train_Acc: 91.194 Val_Loss: 0.2178  BEST VAL Loss: 0.2178  Val_Acc: 92.043

Epoch 80: Validation loss decreased (0.217802 --> 0.217512).  Saving model ...
	 Train_Loss: 0.2436 Train_Acc: 91.188 Val_Loss: 0.2175  BEST VAL Loss: 0.2175  Val_Acc: 92.057

Epoch 81: Validation loss decreased (0.217512 --> 0.217225).  Saving model ...
	 Train_Loss: 0.2432 Train_Acc: 91.174 Val_Loss: 0.2172  BEST VAL Loss: 0.2172  Val_Acc: 91.948

Epoch 82: Validation loss decreased (0.217225 --> 0.216939).  Saving model ...
	 Train_Loss: 0.2428 Train_Acc: 91.137 Val_Loss: 0.2169  BEST VAL Loss: 0.2169  Val_Acc: 92.084

Epoch 83: Validation loss decreased (0.216939 --> 0.216655).  Saving model ...
	 Train_Loss: 0.2423 Train_Acc: 91.285 Val_Loss: 0.2167  BEST VAL Loss: 0.2167  Val_Acc: 92.075

Epoch 84: Validation loss decreased (0.216655 --> 0.216380).  Saving model ...
	 Train_Loss: 0.2419 Train_Acc: 91.254 Val_Loss: 0.2164  BEST VAL Loss: 0.2164  Val_Acc: 92.052

Epoch 85: Validation loss decreased (0.216380 --> 0.216098).  Saving model ...
	 Train_Loss: 0.2415 Train_Acc: 91.175 Val_Loss: 0.2161  BEST VAL Loss: 0.2161  Val_Acc: 92.142

Epoch 86: Validation loss decreased (0.216098 --> 0.215807).  Saving model ...
	 Train_Loss: 0.2411 Train_Acc: 91.212 Val_Loss: 0.2158  BEST VAL Loss: 0.2158  Val_Acc: 92.160

Epoch 87: Validation loss decreased (0.215807 --> 0.215526).  Saving model ...
	 Train_Loss: 0.2407 Train_Acc: 91.285 Val_Loss: 0.2155  BEST VAL Loss: 0.2155  Val_Acc: 92.084

Epoch 88: Validation loss decreased (0.215526 --> 0.215260).  Saving model ...
	 Train_Loss: 0.2404 Train_Acc: 91.236 Val_Loss: 0.2153  BEST VAL Loss: 0.2153  Val_Acc: 92.088

Epoch 89: Validation loss decreased (0.215260 --> 0.215005).  Saving model ...
	 Train_Loss: 0.2400 Train_Acc: 91.219 Val_Loss: 0.2150  BEST VAL Loss: 0.2150  Val_Acc: 92.120

Epoch 90: Validation loss decreased (0.215005 --> 0.214766).  Saving model ...
	 Train_Loss: 0.2396 Train_Acc: 91.269 Val_Loss: 0.2148  BEST VAL Loss: 0.2148  Val_Acc: 92.111

Epoch 91: Validation loss decreased (0.214766 --> 0.214516).  Saving model ...
	 Train_Loss: 0.2393 Train_Acc: 91.245 Val_Loss: 0.2145  BEST VAL Loss: 0.2145  Val_Acc: 92.129

Epoch 92: Validation loss decreased (0.214516 --> 0.214276).  Saving model ...
	 Train_Loss: 0.2389 Train_Acc: 91.249 Val_Loss: 0.2143  BEST VAL Loss: 0.2143  Val_Acc: 92.106

Epoch 93: Validation loss decreased (0.214276 --> 0.214011).  Saving model ...
	 Train_Loss: 0.2386 Train_Acc: 91.270 Val_Loss: 0.2140  BEST VAL Loss: 0.2140  Val_Acc: 92.300

Epoch 94: Validation loss decreased (0.214011 --> 0.213771).  Saving model ...
	 Train_Loss: 0.2382 Train_Acc: 91.256 Val_Loss: 0.2138  BEST VAL Loss: 0.2138  Val_Acc: 92.111

Epoch 95: Validation loss decreased (0.213771 --> 0.213527).  Saving model ...
	 Train_Loss: 0.2379 Train_Acc: 91.234 Val_Loss: 0.2135  BEST VAL Loss: 0.2135  Val_Acc: 92.214

Epoch 96: Validation loss decreased (0.213527 --> 0.213293).  Saving model ...
	 Train_Loss: 0.2376 Train_Acc: 91.256 Val_Loss: 0.2133  BEST VAL Loss: 0.2133  Val_Acc: 92.246

Epoch 97: Validation loss decreased (0.213293 --> 0.213057).  Saving model ...
	 Train_Loss: 0.2372 Train_Acc: 91.225 Val_Loss: 0.2131  BEST VAL Loss: 0.2131  Val_Acc: 92.102

Epoch 98: Validation loss decreased (0.213057 --> 0.212844).  Saving model ...
	 Train_Loss: 0.2369 Train_Acc: 91.361 Val_Loss: 0.2128  BEST VAL Loss: 0.2128  Val_Acc: 92.111

Epoch 99: Validation loss decreased (0.212844 --> 0.212610).  Saving model ...
	 Train_Loss: 0.2366 Train_Acc: 91.321 Val_Loss: 0.2126  BEST VAL Loss: 0.2126  Val_Acc: 92.156

Thapsigargin_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.94      0.92      0.93     79796
           1       0.93      0.96      0.94     97655

    accuracy                           0.94    177451
   macro avg       0.94      0.94      0.94    177451
weighted avg       0.94      0.94      0.94    177451

Thapsigargin_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.92      0.90      0.91      9975
           1       0.92      0.94      0.93     12207

    accuracy                           0.92     22182
   macro avg       0.92      0.92      0.92     22182
weighted avg       0.92      0.92      0.92     22182

Thapsigargin_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.90      0.91      9975
           1       0.92      0.94      0.93     12207

    accuracy                           0.92     22182
   macro avg       0.92      0.92      0.92     22182
weighted avg       0.92      0.92      0.92     22182

              precision    recall  f1-score   support

           0       0.93      0.90      0.91      9975
           1       0.92      0.94      0.93     12207

    accuracy                           0.92     22182
   macro avg       0.92      0.92      0.92     22182
weighted avg       0.92      0.92      0.92     22182

Thapsigargin_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.81      0.40      0.54     39687
           1       0.64      0.92      0.75     44915

    accuracy                           0.68     84602
   macro avg       0.73      0.66      0.65     84602
weighted avg       0.72      0.68      0.65     84602

              precision    recall  f1-score   support

           0       0.81      0.40      0.54     39687
           1       0.64      0.92      0.75     44915

    accuracy                           0.68     84602
   macro avg       0.73      0.66      0.65     84602
weighted avg       0.72      0.68      0.65     84602

completed
