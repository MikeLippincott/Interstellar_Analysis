[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '836aee4b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '0b2116d0'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'eec8d6a3'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '4d301bc2'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: H2O2_100.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['H2O2_100.000_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (421702, 1270)
Number of total missing values across all columns: 481072
Data Subset Is Off
Wells held out for testing: ['I10' 'M08']
Wells to use for training, validation, and testing ['H04' 'I04' 'H05' 'I05' 'H10' 'H11' 'I11' 'M02' 'M03' 'M09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.184184).  Saving model ...
	 Train_Loss: 0.3033 Train_Acc: 86.196 Val_Loss: 0.1842  BEST VAL Loss: 0.1842  Val_Acc: 93.053

Epoch 1: Validation loss decreased (0.184184 --> 0.166086).  Saving model ...
	 Train_Loss: 0.2469 Train_Acc: 92.120 Val_Loss: 0.1661  BEST VAL Loss: 0.1661  Val_Acc: 94.558

Epoch 2: Validation loss decreased (0.166086 --> 0.155019).  Saving model ...
	 Train_Loss: 0.2198 Train_Acc: 93.156 Val_Loss: 0.1550  BEST VAL Loss: 0.1550  Val_Acc: 95.074

Epoch 3: Validation loss decreased (0.155019 --> 0.147236).  Saving model ...
	 Train_Loss: 0.2037 Train_Acc: 93.906 Val_Loss: 0.1472  BEST VAL Loss: 0.1472  Val_Acc: 95.418

Epoch 4: Validation loss decreased (0.147236 --> 0.141348).  Saving model ...
	 Train_Loss: 0.1923 Train_Acc: 94.222 Val_Loss: 0.1413  BEST VAL Loss: 0.1413  Val_Acc: 95.681

Epoch 5: Validation loss decreased (0.141348 --> 0.137147).  Saving model ...
	 Train_Loss: 0.1838 Train_Acc: 94.480 Val_Loss: 0.1371  BEST VAL Loss: 0.1371  Val_Acc: 95.730

Epoch 6: Validation loss decreased (0.137147 --> 0.133596).  Saving model ...
	 Train_Loss: 0.1771 Train_Acc: 94.646 Val_Loss: 0.1336  BEST VAL Loss: 0.1336  Val_Acc: 95.916

Epoch 7: Validation loss decreased (0.133596 --> 0.130777).  Saving model ...
	 Train_Loss: 0.1717 Train_Acc: 94.773 Val_Loss: 0.1308  BEST VAL Loss: 0.1308  Val_Acc: 95.928

Epoch 8: Validation loss decreased (0.130777 --> 0.128286).  Saving model ...
	 Train_Loss: 0.1674 Train_Acc: 94.827 Val_Loss: 0.1283  BEST VAL Loss: 0.1283  Val_Acc: 96.157

Epoch 9: Validation loss decreased (0.128286 --> 0.126089).  Saving model ...
	 Train_Loss: 0.1636 Train_Acc: 94.891 Val_Loss: 0.1261  BEST VAL Loss: 0.1261  Val_Acc: 96.140

Epoch 10: Validation loss decreased (0.126089 --> 0.124356).  Saving model ...
	 Train_Loss: 0.1602 Train_Acc: 95.021 Val_Loss: 0.1244  BEST VAL Loss: 0.1244  Val_Acc: 96.103

Epoch 11: Validation loss decreased (0.124356 --> 0.122839).  Saving model ...
	 Train_Loss: 0.1573 Train_Acc: 95.046 Val_Loss: 0.1228  BEST VAL Loss: 0.1228  Val_Acc: 96.103

Epoch 12: Validation loss decreased (0.122839 --> 0.121402).  Saving model ...
	 Train_Loss: 0.1548 Train_Acc: 95.101 Val_Loss: 0.1214  BEST VAL Loss: 0.1214  Val_Acc: 96.240

Epoch 13: Validation loss decreased (0.121402 --> 0.120110).  Saving model ...
	 Train_Loss: 0.1526 Train_Acc: 95.174 Val_Loss: 0.1201  BEST VAL Loss: 0.1201  Val_Acc: 96.275

Epoch 14: Validation loss decreased (0.120110 --> 0.119121).  Saving model ...
	 Train_Loss: 0.1505 Train_Acc: 95.203 Val_Loss: 0.1191  BEST VAL Loss: 0.1191  Val_Acc: 96.237

Epoch 15: Validation loss decreased (0.119121 --> 0.118055).  Saving model ...
	 Train_Loss: 0.1487 Train_Acc: 95.260 Val_Loss: 0.1181  BEST VAL Loss: 0.1181  Val_Acc: 96.306

Epoch 16: Validation loss decreased (0.118055 --> 0.117112).  Saving model ...
	 Train_Loss: 0.1470 Train_Acc: 95.295 Val_Loss: 0.1171  BEST VAL Loss: 0.1171  Val_Acc: 96.375

Epoch 17: Validation loss decreased (0.117112 --> 0.116260).  Saving model ...
	 Train_Loss: 0.1454 Train_Acc: 95.316 Val_Loss: 0.1163  BEST VAL Loss: 0.1163  Val_Acc: 96.280

Epoch 18: Validation loss decreased (0.116260 --> 0.115469).  Saving model ...
	 Train_Loss: 0.1440 Train_Acc: 95.350 Val_Loss: 0.1155  BEST VAL Loss: 0.1155  Val_Acc: 96.254

Epoch 19: Validation loss decreased (0.115469 --> 0.114709).  Saving model ...
	 Train_Loss: 0.1427 Train_Acc: 95.364 Val_Loss: 0.1147  BEST VAL Loss: 0.1147  Val_Acc: 96.395

Epoch 20: Validation loss decreased (0.114709 --> 0.114029).  Saving model ...
	 Train_Loss: 0.1414 Train_Acc: 95.389 Val_Loss: 0.1140  BEST VAL Loss: 0.1140  Val_Acc: 96.392

Epoch 21: Validation loss decreased (0.114029 --> 0.113432).  Saving model ...
	 Train_Loss: 0.1403 Train_Acc: 95.432 Val_Loss: 0.1134  BEST VAL Loss: 0.1134  Val_Acc: 96.343

Epoch 22: Validation loss decreased (0.113432 --> 0.112783).  Saving model ...
	 Train_Loss: 0.1392 Train_Acc: 95.422 Val_Loss: 0.1128  BEST VAL Loss: 0.1128  Val_Acc: 96.472

Epoch 23: Validation loss decreased (0.112783 --> 0.112214).  Saving model ...
	 Train_Loss: 0.1382 Train_Acc: 95.419 Val_Loss: 0.1122  BEST VAL Loss: 0.1122  Val_Acc: 96.510

Epoch 24: Validation loss decreased (0.112214 --> 0.111700).  Saving model ...
	 Train_Loss: 0.1373 Train_Acc: 95.507 Val_Loss: 0.1117  BEST VAL Loss: 0.1117  Val_Acc: 96.472

Epoch 25: Validation loss decreased (0.111700 --> 0.111186).  Saving model ...
	 Train_Loss: 0.1364 Train_Acc: 95.517 Val_Loss: 0.1112  BEST VAL Loss: 0.1112  Val_Acc: 96.558

Epoch 26: Validation loss decreased (0.111186 --> 0.110887).  Saving model ...
	 Train_Loss: 0.1355 Train_Acc: 95.551 Val_Loss: 0.1109  BEST VAL Loss: 0.1109  Val_Acc: 96.297

Epoch 27: Validation loss decreased (0.110887 --> 0.110527).  Saving model ...
	 Train_Loss: 0.1348 Train_Acc: 95.509 Val_Loss: 0.1105  BEST VAL Loss: 0.1105  Val_Acc: 96.372

Epoch 28: Validation loss decreased (0.110527 --> 0.110093).  Saving model ...
	 Train_Loss: 0.1340 Train_Acc: 95.496 Val_Loss: 0.1101  BEST VAL Loss: 0.1101  Val_Acc: 96.484

Epoch 29: Validation loss decreased (0.110093 --> 0.109690).  Saving model ...
	 Train_Loss: 0.1332 Train_Acc: 95.529 Val_Loss: 0.1097  BEST VAL Loss: 0.1097  Val_Acc: 96.475

Epoch 30: Validation loss decreased (0.109690 --> 0.109405).  Saving model ...
	 Train_Loss: 0.1325 Train_Acc: 95.566 Val_Loss: 0.1094  BEST VAL Loss: 0.1094  Val_Acc: 96.415

Epoch 31: Validation loss decreased (0.109405 --> 0.109064).  Saving model ...
	 Train_Loss: 0.1319 Train_Acc: 95.530 Val_Loss: 0.1091  BEST VAL Loss: 0.1091  Val_Acc: 96.481

Epoch 32: Validation loss decreased (0.109064 --> 0.108730).  Saving model ...
	 Train_Loss: 0.1313 Train_Acc: 95.570 Val_Loss: 0.1087  BEST VAL Loss: 0.1087  Val_Acc: 96.467

Epoch 33: Validation loss decreased (0.108730 --> 0.108449).  Saving model ...
	 Train_Loss: 0.1306 Train_Acc: 95.623 Val_Loss: 0.1084  BEST VAL Loss: 0.1084  Val_Acc: 96.504

Epoch 34: Validation loss decreased (0.108449 --> 0.108179).  Saving model ...
	 Train_Loss: 0.1301 Train_Acc: 95.584 Val_Loss: 0.1082  BEST VAL Loss: 0.1082  Val_Acc: 96.501

Epoch 35: Validation loss decreased (0.108179 --> 0.107863).  Saving model ...
	 Train_Loss: 0.1295 Train_Acc: 95.630 Val_Loss: 0.1079  BEST VAL Loss: 0.1079  Val_Acc: 96.616

Epoch 36: Validation loss decreased (0.107863 --> 0.107572).  Saving model ...
	 Train_Loss: 0.1290 Train_Acc: 95.652 Val_Loss: 0.1076  BEST VAL Loss: 0.1076  Val_Acc: 96.590

Epoch 37: Validation loss decreased (0.107572 --> 0.107303).  Saving model ...
	 Train_Loss: 0.1285 Train_Acc: 95.654 Val_Loss: 0.1073  BEST VAL Loss: 0.1073  Val_Acc: 96.518

Epoch 38: Validation loss decreased (0.107303 --> 0.107051).  Saving model ...
	 Train_Loss: 0.1280 Train_Acc: 95.646 Val_Loss: 0.1071  BEST VAL Loss: 0.1071  Val_Acc: 96.441

Epoch 39: Validation loss decreased (0.107051 --> 0.106828).  Saving model ...
	 Train_Loss: 0.1275 Train_Acc: 95.656 Val_Loss: 0.1068  BEST VAL Loss: 0.1068  Val_Acc: 96.512

Epoch 40: Validation loss decreased (0.106828 --> 0.106580).  Saving model ...
	 Train_Loss: 0.1270 Train_Acc: 95.700 Val_Loss: 0.1066  BEST VAL Loss: 0.1066  Val_Acc: 96.555

Epoch 41: Validation loss decreased (0.106580 --> 0.106317).  Saving model ...
	 Train_Loss: 0.1266 Train_Acc: 95.700 Val_Loss: 0.1063  BEST VAL Loss: 0.1063  Val_Acc: 96.535

Epoch 42: Validation loss decreased (0.106317 --> 0.106100).  Saving model ...
	 Train_Loss: 0.1261 Train_Acc: 95.692 Val_Loss: 0.1061  BEST VAL Loss: 0.1061  Val_Acc: 96.555

Epoch 43: Validation loss decreased (0.106100 --> 0.105898).  Saving model ...
	 Train_Loss: 0.1257 Train_Acc: 95.673 Val_Loss: 0.1059  BEST VAL Loss: 0.1059  Val_Acc: 96.544

Epoch 44: Validation loss decreased (0.105898 --> 0.105685).  Saving model ...
	 Train_Loss: 0.1253 Train_Acc: 95.749 Val_Loss: 0.1057  BEST VAL Loss: 0.1057  Val_Acc: 96.561

Epoch 45: Validation loss decreased (0.105685 --> 0.105464).  Saving model ...
	 Train_Loss: 0.1249 Train_Acc: 95.707 Val_Loss: 0.1055  BEST VAL Loss: 0.1055  Val_Acc: 96.567

Epoch 46: Validation loss decreased (0.105464 --> 0.105307).  Saving model ...
	 Train_Loss: 0.1245 Train_Acc: 95.704 Val_Loss: 0.1053  BEST VAL Loss: 0.1053  Val_Acc: 96.587

Epoch 47: Validation loss decreased (0.105307 --> 0.105145).  Saving model ...
	 Train_Loss: 0.1242 Train_Acc: 95.741 Val_Loss: 0.1051  BEST VAL Loss: 0.1051  Val_Acc: 96.555

Epoch 48: Validation loss decreased (0.105145 --> 0.104968).  Saving model ...
	 Train_Loss: 0.1238 Train_Acc: 95.730 Val_Loss: 0.1050  BEST VAL Loss: 0.1050  Val_Acc: 96.610

Epoch 49: Validation loss decreased (0.104968 --> 0.104791).  Saving model ...
	 Train_Loss: 0.1235 Train_Acc: 95.653 Val_Loss: 0.1048  BEST VAL Loss: 0.1048  Val_Acc: 96.590

Epoch 50: Validation loss decreased (0.104791 --> 0.104638).  Saving model ...
	 Train_Loss: 0.1232 Train_Acc: 95.661 Val_Loss: 0.1046  BEST VAL Loss: 0.1046  Val_Acc: 96.590

Epoch 51: Validation loss decreased (0.104638 --> 0.104495).  Saving model ...
	 Train_Loss: 0.1228 Train_Acc: 95.733 Val_Loss: 0.1045  BEST VAL Loss: 0.1045  Val_Acc: 96.581

Epoch 52: Validation loss decreased (0.104495 --> 0.104365).  Saving model ...
	 Train_Loss: 0.1225 Train_Acc: 95.759 Val_Loss: 0.1044  BEST VAL Loss: 0.1044  Val_Acc: 96.604

Epoch 53: Validation loss decreased (0.104365 --> 0.104220).  Saving model ...
	 Train_Loss: 0.1222 Train_Acc: 95.719 Val_Loss: 0.1042  BEST VAL Loss: 0.1042  Val_Acc: 96.661

Epoch 54: Validation loss decreased (0.104220 --> 0.104075).  Saving model ...
	 Train_Loss: 0.1219 Train_Acc: 95.820 Val_Loss: 0.1041  BEST VAL Loss: 0.1041  Val_Acc: 96.558

Epoch 55: Validation loss decreased (0.104075 --> 0.103924).  Saving model ...
	 Train_Loss: 0.1216 Train_Acc: 95.787 Val_Loss: 0.1039  BEST VAL Loss: 0.1039  Val_Acc: 96.638

Epoch 56: Validation loss decreased (0.103924 --> 0.103832).  Saving model ...
	 Train_Loss: 0.1214 Train_Acc: 95.789 Val_Loss: 0.1038  BEST VAL Loss: 0.1038  Val_Acc: 96.570

Epoch 57: Validation loss decreased (0.103832 --> 0.103687).  Saving model ...
	 Train_Loss: 0.1211 Train_Acc: 95.788 Val_Loss: 0.1037  BEST VAL Loss: 0.1037  Val_Acc: 96.601

Epoch 58: Validation loss decreased (0.103687 --> 0.103569).  Saving model ...
	 Train_Loss: 0.1208 Train_Acc: 95.790 Val_Loss: 0.1036  BEST VAL Loss: 0.1036  Val_Acc: 96.673

Epoch 59: Validation loss decreased (0.103569 --> 0.103458).  Saving model ...
	 Train_Loss: 0.1205 Train_Acc: 95.771 Val_Loss: 0.1035  BEST VAL Loss: 0.1035  Val_Acc: 96.578

Epoch 60: Validation loss decreased (0.103458 --> 0.103332).  Saving model ...
	 Train_Loss: 0.1203 Train_Acc: 95.838 Val_Loss: 0.1033  BEST VAL Loss: 0.1033  Val_Acc: 96.664

Epoch 61: Validation loss decreased (0.103332 --> 0.103234).  Saving model ...
	 Train_Loss: 0.1200 Train_Acc: 95.804 Val_Loss: 0.1032  BEST VAL Loss: 0.1032  Val_Acc: 96.681

Epoch 62: Validation loss decreased (0.103234 --> 0.103140).  Saving model ...
	 Train_Loss: 0.1198 Train_Acc: 95.800 Val_Loss: 0.1031  BEST VAL Loss: 0.1031  Val_Acc: 96.567

Epoch 63: Validation loss decreased (0.103140 --> 0.103043).  Saving model ...
	 Train_Loss: 0.1195 Train_Acc: 95.812 Val_Loss: 0.1030  BEST VAL Loss: 0.1030  Val_Acc: 96.590

Epoch 64: Validation loss decreased (0.103043 --> 0.102940).  Saving model ...
	 Train_Loss: 0.1193 Train_Acc: 95.824 Val_Loss: 0.1029  BEST VAL Loss: 0.1029  Val_Acc: 96.641

Epoch 65: Validation loss decreased (0.102940 --> 0.102819).  Saving model ...
	 Train_Loss: 0.1191 Train_Acc: 95.820 Val_Loss: 0.1028  BEST VAL Loss: 0.1028  Val_Acc: 96.653

Epoch 66: Validation loss decreased (0.102819 --> 0.102742).  Saving model ...
	 Train_Loss: 0.1189 Train_Acc: 95.846 Val_Loss: 0.1027  BEST VAL Loss: 0.1027  Val_Acc: 96.584

Epoch 67: Validation loss decreased (0.102742 --> 0.102653).  Saving model ...
	 Train_Loss: 0.1186 Train_Acc: 95.856 Val_Loss: 0.1027  BEST VAL Loss: 0.1027  Val_Acc: 96.742

Epoch 68: Validation loss decreased (0.102653 --> 0.102558).  Saving model ...
	 Train_Loss: 0.1184 Train_Acc: 95.788 Val_Loss: 0.1026  BEST VAL Loss: 0.1026  Val_Acc: 96.670

Epoch 69: Validation loss decreased (0.102558 --> 0.102430).  Saving model ...
	 Train_Loss: 0.1182 Train_Acc: 95.810 Val_Loss: 0.1024  BEST VAL Loss: 0.1024  Val_Acc: 96.713

Epoch 70: Validation loss decreased (0.102430 --> 0.102355).  Saving model ...
	 Train_Loss: 0.1180 Train_Acc: 95.821 Val_Loss: 0.1024  BEST VAL Loss: 0.1024  Val_Acc: 96.656

Epoch 71: Validation loss decreased (0.102355 --> 0.102265).  Saving model ...
	 Train_Loss: 0.1178 Train_Acc: 95.863 Val_Loss: 0.1023  BEST VAL Loss: 0.1023  Val_Acc: 96.627

Epoch 72: Validation loss decreased (0.102265 --> 0.102181).  Saving model ...
	 Train_Loss: 0.1176 Train_Acc: 95.854 Val_Loss: 0.1022  BEST VAL Loss: 0.1022  Val_Acc: 96.581

Epoch 73: Validation loss decreased (0.102181 --> 0.102121).  Saving model ...
	 Train_Loss: 0.1174 Train_Acc: 95.768 Val_Loss: 0.1021  BEST VAL Loss: 0.1021  Val_Acc: 96.641

Epoch 74: Validation loss decreased (0.102121 --> 0.102032).  Saving model ...
	 Train_Loss: 0.1172 Train_Acc: 95.826 Val_Loss: 0.1020  BEST VAL Loss: 0.1020  Val_Acc: 96.618

Epoch 75: Validation loss decreased (0.102032 --> 0.101961).  Saving model ...
	 Train_Loss: 0.1170 Train_Acc: 95.822 Val_Loss: 0.1020  BEST VAL Loss: 0.1020  Val_Acc: 96.573

Epoch 76: Validation loss decreased (0.101961 --> 0.101891).  Saving model ...
	 Train_Loss: 0.1169 Train_Acc: 95.844 Val_Loss: 0.1019  BEST VAL Loss: 0.1019  Val_Acc: 96.733

Epoch 77: Validation loss decreased (0.101891 --> 0.101814).  Saving model ...
	 Train_Loss: 0.1167 Train_Acc: 95.885 Val_Loss: 0.1018  BEST VAL Loss: 0.1018  Val_Acc: 96.550

Epoch 78: Validation loss decreased (0.101814 --> 0.101725).  Saving model ...
	 Train_Loss: 0.1165 Train_Acc: 95.886 Val_Loss: 0.1017  BEST VAL Loss: 0.1017  Val_Acc: 96.702

Epoch 79: Validation loss decreased (0.101725 --> 0.101646).  Saving model ...
	 Train_Loss: 0.1163 Train_Acc: 95.892 Val_Loss: 0.1016  BEST VAL Loss: 0.1016  Val_Acc: 96.638

Epoch 80: Validation loss decreased (0.101646 --> 0.101574).  Saving model ...
	 Train_Loss: 0.1161 Train_Acc: 95.877 Val_Loss: 0.1016  BEST VAL Loss: 0.1016  Val_Acc: 96.693

Epoch 81: Validation loss decreased (0.101574 --> 0.101523).  Saving model ...
	 Train_Loss: 0.1160 Train_Acc: 95.923 Val_Loss: 0.1015  BEST VAL Loss: 0.1015  Val_Acc: 96.696

Epoch 82: Validation loss decreased (0.101523 --> 0.101458).  Saving model ...
	 Train_Loss: 0.1158 Train_Acc: 95.855 Val_Loss: 0.1015  BEST VAL Loss: 0.1015  Val_Acc: 96.673

Epoch 83: Validation loss decreased (0.101458 --> 0.101393).  Saving model ...
	 Train_Loss: 0.1156 Train_Acc: 95.881 Val_Loss: 0.1014  BEST VAL Loss: 0.1014  Val_Acc: 96.627

Epoch 84: Validation loss decreased (0.101393 --> 0.101323).  Saving model ...
	 Train_Loss: 0.1155 Train_Acc: 95.897 Val_Loss: 0.1013  BEST VAL Loss: 0.1013  Val_Acc: 96.647

Epoch 85: Validation loss decreased (0.101323 --> 0.101279).  Saving model ...
	 Train_Loss: 0.1153 Train_Acc: 95.889 Val_Loss: 0.1013  BEST VAL Loss: 0.1013  Val_Acc: 96.596

Epoch 86: Validation loss decreased (0.101279 --> 0.101225).  Saving model ...
	 Train_Loss: 0.1152 Train_Acc: 95.827 Val_Loss: 0.1012  BEST VAL Loss: 0.1012  Val_Acc: 96.636

Epoch 87: Validation loss decreased (0.101225 --> 0.101179).  Saving model ...
	 Train_Loss: 0.1150 Train_Acc: 95.906 Val_Loss: 0.1012  BEST VAL Loss: 0.1012  Val_Acc: 96.584

Epoch 88: Validation loss decreased (0.101179 --> 0.101134).  Saving model ...
	 Train_Loss: 0.1149 Train_Acc: 95.859 Val_Loss: 0.1011  BEST VAL Loss: 0.1011  Val_Acc: 96.601

Epoch 89: Validation loss decreased (0.101134 --> 0.101079).  Saving model ...
	 Train_Loss: 0.1147 Train_Acc: 95.918 Val_Loss: 0.1011  BEST VAL Loss: 0.1011  Val_Acc: 96.676

Epoch 90: Validation loss decreased (0.101079 --> 0.101031).  Saving model ...
	 Train_Loss: 0.1146 Train_Acc: 95.925 Val_Loss: 0.1010  BEST VAL Loss: 0.1010  Val_Acc: 96.719

Epoch 91: Validation loss decreased (0.101031 --> 0.100987).  Saving model ...
	 Train_Loss: 0.1144 Train_Acc: 95.916 Val_Loss: 0.1010  BEST VAL Loss: 0.1010  Val_Acc: 96.584

Epoch 92: Validation loss decreased (0.100987 --> 0.100941).  Saving model ...
	 Train_Loss: 0.1143 Train_Acc: 95.900 Val_Loss: 0.1009  BEST VAL Loss: 0.1009  Val_Acc: 96.584

Epoch 93: Validation loss decreased (0.100941 --> 0.100907).  Saving model ...
	 Train_Loss: 0.1141 Train_Acc: 95.930 Val_Loss: 0.1009  BEST VAL Loss: 0.1009  Val_Acc: 96.547

Epoch 94: Validation loss decreased (0.100907 --> 0.100889).  Saving model ...
	 Train_Loss: 0.1140 Train_Acc: 95.909 Val_Loss: 0.1009  BEST VAL Loss: 0.1009  Val_Acc: 96.487

Epoch 95: Validation loss decreased (0.100889 --> 0.100849).  Saving model ...
	 Train_Loss: 0.1139 Train_Acc: 95.911 Val_Loss: 0.1008  BEST VAL Loss: 0.1008  Val_Acc: 96.607

Epoch 96: Validation loss decreased (0.100849 --> 0.100802).  Saving model ...
	 Train_Loss: 0.1137 Train_Acc: 95.898 Val_Loss: 0.1008  BEST VAL Loss: 0.1008  Val_Acc: 96.656

Epoch 97: Validation loss decreased (0.100802 --> 0.100766).  Saving model ...
	 Train_Loss: 0.1136 Train_Acc: 95.892 Val_Loss: 0.1008  BEST VAL Loss: 0.1008  Val_Acc: 96.679

Epoch 98: Validation loss decreased (0.100766 --> 0.100722).  Saving model ...
	 Train_Loss: 0.1135 Train_Acc: 95.945 Val_Loss: 0.1007  BEST VAL Loss: 0.1007  Val_Acc: 96.719

Epoch 99: Validation loss decreased (0.100722 --> 0.100687).  Saving model ...
	 Train_Loss: 0.1133 Train_Acc: 95.922 Val_Loss: 0.1007  BEST VAL Loss: 0.1007  Val_Acc: 96.667

H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.61      0.61      0.61    169562
           1       0.39      0.39      0.39    109598

    accuracy                           0.52    279160
   macro avg       0.50      0.50      0.50    279160
weighted avg       0.52      0.52      0.52    279160

H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.61      0.61      0.61     21195
           1       0.39      0.39      0.39     13700

    accuracy                           0.52     34895
   macro avg       0.50      0.50      0.50     34895
weighted avg       0.52      0.52      0.52     34895

H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.61      0.61      0.61     21195
           1       0.39      0.39      0.39     13700

    accuracy                           0.53     34895
   macro avg       0.50      0.50      0.50     34895
weighted avg       0.52      0.53      0.53     34895

              precision    recall  f1-score   support

           0       0.61      0.61      0.61     21195
           1       0.39      0.39      0.39     13700

    accuracy                           0.53     34895
   macro avg       0.50      0.50      0.50     34895
weighted avg       0.52      0.53      0.53     34895

H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.39      0.46      0.42     28584
           1       0.61      0.54      0.57     44168

    accuracy                           0.51     72752
   macro avg       0.50      0.50      0.50     72752
weighted avg       0.52      0.51      0.51     72752

              precision    recall  f1-score   support

           0       0.39      0.46      0.42     28584
           1       0.61      0.54      0.57     44168

    accuracy                           0.51     72752
   macro avg       0.50      0.50      0.50     72752
weighted avg       0.52      0.51      0.51     72752

completed
