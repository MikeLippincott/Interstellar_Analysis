[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '89e571f6'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '115e9d38'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '111d81da'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '7918b5e4'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Thapsigargin_10.000_DMSO_0.025 treatment_name: H2O2_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Thapsigargin_10.000_DMSO_0.025
TREATMENT_NAME: H2O2_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (40112, 1276)
Number of total missing values across all columns: 80224
Data Subset Is Off
Wells held out for testing: ['E14' 'H22']
Wells to use for training, validation, and testing ['E15' 'H18' 'H19' 'H23' 'L14' 'L15' 'I18' 'I19' 'I22' 'I23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.432108).  Saving model ...
	 Train_Loss: 0.5561 Train_Acc: 69.586 Val_Loss: 0.4321  BEST VAL Loss: 0.4321  Val_Acc: 69.822

Epoch 1: Validation loss decreased (0.432108 --> 0.403105).  Saving model ...
	 Train_Loss: 0.4783 Train_Acc: 81.052 Val_Loss: 0.4031  BEST VAL Loss: 0.4031  Val_Acc: 86.693

Epoch 2: Validation loss decreased (0.403105 --> 0.373807).  Saving model ...
	 Train_Loss: 0.4396 Train_Acc: 84.272 Val_Loss: 0.3738  BEST VAL Loss: 0.3738  Val_Acc: 88.783

Epoch 3: Validation loss decreased (0.373807 --> 0.351825).  Saving model ...
	 Train_Loss: 0.4116 Train_Acc: 86.439 Val_Loss: 0.3518  BEST VAL Loss: 0.3518  Val_Acc: 88.691

Epoch 4: Validation loss decreased (0.351825 --> 0.344590).  Saving model ...
	 Train_Loss: 0.3955 Train_Acc: 85.978 Val_Loss: 0.3446  BEST VAL Loss: 0.3446  Val_Acc: 89.797

Epoch 5: Validation loss decreased (0.344590 --> 0.330619).  Saving model ...
	 Train_Loss: 0.3786 Train_Acc: 87.830 Val_Loss: 0.3306  BEST VAL Loss: 0.3306  Val_Acc: 89.859

Epoch 6: Validation loss decreased (0.330619 --> 0.320312).  Saving model ...
	 Train_Loss: 0.3654 Train_Acc: 88.464 Val_Loss: 0.3203  BEST VAL Loss: 0.3203  Val_Acc: 90.811

Epoch 7: Validation loss decreased (0.320312 --> 0.312665).  Saving model ...
	 Train_Loss: 0.3549 Train_Acc: 88.691 Val_Loss: 0.3127  BEST VAL Loss: 0.3127  Val_Acc: 90.934

Epoch 8: Validation loss decreased (0.312665 --> 0.305374).  Saving model ...
	 Train_Loss: 0.3450 Train_Acc: 89.341 Val_Loss: 0.3054  BEST VAL Loss: 0.3054  Val_Acc: 91.610

Epoch 9: Validation loss decreased (0.305374 --> 0.298862).  Saving model ...
	 Train_Loss: 0.3352 Train_Acc: 90.332 Val_Loss: 0.2989  BEST VAL Loss: 0.2989  Val_Acc: 92.440

Epoch 10: Validation loss decreased (0.298862 --> 0.292029).  Saving model ...
	 Train_Loss: 0.3263 Train_Acc: 91.043 Val_Loss: 0.2920  BEST VAL Loss: 0.2920  Val_Acc: 92.594

Epoch 11: Validation loss decreased (0.292029 --> 0.286800).  Saving model ...
	 Train_Loss: 0.3186 Train_Acc: 91.127 Val_Loss: 0.2868  BEST VAL Loss: 0.2868  Val_Acc: 92.532

Epoch 12: Validation loss decreased (0.286800 --> 0.281266).  Saving model ...
	 Train_Loss: 0.3121 Train_Acc: 91.181 Val_Loss: 0.2813  BEST VAL Loss: 0.2813  Val_Acc: 91.795

Epoch 13: Validation loss decreased (0.281266 --> 0.278393).  Saving model ...
	 Train_Loss: 0.3055 Train_Acc: 91.335 Val_Loss: 0.2784  BEST VAL Loss: 0.2784  Val_Acc: 93.116

Epoch 14: Validation loss decreased (0.278393 --> 0.274433).  Saving model ...
	 Train_Loss: 0.2992 Train_Acc: 92.284 Val_Loss: 0.2744  BEST VAL Loss: 0.2744  Val_Acc: 93.055

Epoch 15: Validation loss decreased (0.274433 --> 0.271738).  Saving model ...
	 Train_Loss: 0.2937 Train_Acc: 92.392 Val_Loss: 0.2717  BEST VAL Loss: 0.2717  Val_Acc: 91.149

Epoch 16: Validation loss decreased (0.271738 --> 0.269845).  Saving model ...
	 Train_Loss: 0.2924 Train_Acc: 89.594 Val_Loss: 0.2698  BEST VAL Loss: 0.2698  Val_Acc: 91.457

Epoch 17: Validation loss decreased (0.269845 --> 0.266471).  Saving model ...
	 Train_Loss: 0.2891 Train_Acc: 91.131 Val_Loss: 0.2665  BEST VAL Loss: 0.2665  Val_Acc: 92.778

Epoch 18: Validation loss decreased (0.266471 --> 0.264214).  Saving model ...
	 Train_Loss: 0.2858 Train_Acc: 91.354 Val_Loss: 0.2642  BEST VAL Loss: 0.2642  Val_Acc: 92.348

Epoch 19: Validation loss did not decrease
	 Train_Loss: 0.2849 Train_Acc: 90.086 Val_Loss: 0.2713  BEST VAL Loss: 0.2642  Val_Acc: 80.547

Epoch 20: Validation loss did not decrease
	 Train_Loss: 0.2874 Train_Acc: 88.968 Val_Loss: 0.2804  BEST VAL Loss: 0.2642  Val_Acc: 90.381

Epoch 21: Validation loss did not decrease
	 Train_Loss: 0.2876 Train_Acc: 90.086 Val_Loss: 0.2819  BEST VAL Loss: 0.2642  Val_Acc: 91.795

Epoch 22: Validation loss did not decrease
	 Train_Loss: 0.2862 Train_Acc: 90.455 Val_Loss: 0.2798  BEST VAL Loss: 0.2642  Val_Acc: 92.041

Epoch 23: Validation loss did not decrease
	 Train_Loss: 0.2839 Train_Acc: 90.905 Val_Loss: 0.2784  BEST VAL Loss: 0.2642  Val_Acc: 91.364

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.2807 Train_Acc: 92.146 Val_Loss: 0.2765  BEST VAL Loss: 0.2642  Val_Acc: 91.825

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.2776 Train_Acc: 92.380 Val_Loss: 0.2742  BEST VAL Loss: 0.2642  Val_Acc: 92.163

Epoch 26: Validation loss did not decrease
	 Train_Loss: 0.2744 Train_Acc: 92.991 Val_Loss: 0.2723  BEST VAL Loss: 0.2642  Val_Acc: 93.024

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.2712 Train_Acc: 93.030 Val_Loss: 0.2700  BEST VAL Loss: 0.2642  Val_Acc: 93.362

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.2685 Train_Acc: 92.807 Val_Loss: 0.2684  BEST VAL Loss: 0.2642  Val_Acc: 92.932

Epoch 29: Validation loss did not decrease
	 Train_Loss: 0.2662 Train_Acc: 92.987 Val_Loss: 0.2667  BEST VAL Loss: 0.2642  Val_Acc: 92.532

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.2635 Train_Acc: 93.483 Val_Loss: 0.2656  BEST VAL Loss: 0.2642  Val_Acc: 92.993

Epoch 31: Validation loss decreased (0.264214 --> 0.263935).  Saving model ...
	 Train_Loss: 0.2613 Train_Acc: 92.891 Val_Loss: 0.2639  BEST VAL Loss: 0.2639  Val_Acc: 93.055

Epoch 32: Validation loss decreased (0.263935 --> 0.262328).  Saving model ...
	 Train_Loss: 0.2589 Train_Acc: 93.445 Val_Loss: 0.2623  BEST VAL Loss: 0.2623  Val_Acc: 93.731

Epoch 33: Validation loss decreased (0.262328 --> 0.261151).  Saving model ...
	 Train_Loss: 0.2564 Train_Acc: 93.871 Val_Loss: 0.2612  BEST VAL Loss: 0.2612  Val_Acc: 93.024

Epoch 34: Validation loss decreased (0.261151 --> 0.259551).  Saving model ...
	 Train_Loss: 0.2537 Train_Acc: 94.171 Val_Loss: 0.2596  BEST VAL Loss: 0.2596  Val_Acc: 94.100

Epoch 35: Validation loss decreased (0.259551 --> 0.259077).  Saving model ...
	 Train_Loss: 0.2515 Train_Acc: 93.998 Val_Loss: 0.2591  BEST VAL Loss: 0.2591  Val_Acc: 93.270

Epoch 36: Validation loss decreased (0.259077 --> 0.258018).  Saving model ...
	 Train_Loss: 0.2499 Train_Acc: 93.003 Val_Loss: 0.2580  BEST VAL Loss: 0.2580  Val_Acc: 93.546

Epoch 37: Validation loss decreased (0.258018 --> 0.256855).  Saving model ...
	 Train_Loss: 0.2478 Train_Acc: 93.940 Val_Loss: 0.2569  BEST VAL Loss: 0.2569  Val_Acc: 94.069

Epoch 38: Validation loss decreased (0.256855 --> 0.255652).  Saving model ...
	 Train_Loss: 0.2454 Train_Acc: 94.417 Val_Loss: 0.2557  BEST VAL Loss: 0.2557  Val_Acc: 94.069

Epoch 39: Validation loss decreased (0.255652 --> 0.255062).  Saving model ...
	 Train_Loss: 0.2430 Train_Acc: 94.693 Val_Loss: 0.2551  BEST VAL Loss: 0.2551  Val_Acc: 93.884

Epoch 40: Validation loss decreased (0.255062 --> 0.254982).  Saving model ...
	 Train_Loss: 0.2407 Train_Acc: 94.970 Val_Loss: 0.2550  BEST VAL Loss: 0.2550  Val_Acc: 94.253

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.2417 Train_Acc: 91.984 Val_Loss: 0.2553  BEST VAL Loss: 0.2550  Val_Acc: 91.825

Epoch 42: Validation loss decreased (0.254982 --> 0.254753).  Saving model ...
	 Train_Loss: 0.2411 Train_Acc: 91.884 Val_Loss: 0.2548  BEST VAL Loss: 0.2548  Val_Acc: 91.703

Epoch 43: Validation loss decreased (0.254753 --> 0.253687).  Saving model ...
	 Train_Loss: 0.2398 Train_Acc: 93.287 Val_Loss: 0.2537  BEST VAL Loss: 0.2537  Val_Acc: 93.331

Epoch 44: Validation loss decreased (0.253687 --> 0.253457).  Saving model ...
	 Train_Loss: 0.2381 Train_Acc: 94.190 Val_Loss: 0.2535  BEST VAL Loss: 0.2535  Val_Acc: 93.977

Epoch 45: Validation loss decreased (0.253457 --> 0.253098).  Saving model ...
	 Train_Loss: 0.2365 Train_Acc: 94.355 Val_Loss: 0.2531  BEST VAL Loss: 0.2531  Val_Acc: 94.038

Epoch 46: Validation loss decreased (0.253098 --> 0.252695).  Saving model ...
	 Train_Loss: 0.2347 Train_Acc: 94.674 Val_Loss: 0.2527  BEST VAL Loss: 0.2527  Val_Acc: 94.222

Epoch 47: Validation loss decreased (0.252695 --> 0.251628).  Saving model ...
	 Train_Loss: 0.2331 Train_Acc: 94.947 Val_Loss: 0.2516  BEST VAL Loss: 0.2516  Val_Acc: 94.315

Epoch 48: Validation loss decreased (0.251628 --> 0.250576).  Saving model ...
	 Train_Loss: 0.2317 Train_Acc: 94.113 Val_Loss: 0.2506  BEST VAL Loss: 0.2506  Val_Acc: 93.762

Epoch 49: Validation loss decreased (0.250576 --> 0.249235).  Saving model ...
	 Train_Loss: 0.2303 Train_Acc: 94.494 Val_Loss: 0.2492  BEST VAL Loss: 0.2492  Val_Acc: 94.069

Epoch 50: Validation loss decreased (0.249235 --> 0.248789).  Saving model ...
	 Train_Loss: 0.2289 Train_Acc: 94.501 Val_Loss: 0.2488  BEST VAL Loss: 0.2488  Val_Acc: 94.192

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.2279 Train_Acc: 93.487 Val_Loss: 0.2500  BEST VAL Loss: 0.2488  Val_Acc: 93.516

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.2270 Train_Acc: 93.917 Val_Loss: 0.2503  BEST VAL Loss: 0.2488  Val_Acc: 93.915

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.2265 Train_Acc: 92.872 Val_Loss: 0.2503  BEST VAL Loss: 0.2488  Val_Acc: 93.423

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.2260 Train_Acc: 92.930 Val_Loss: 0.2501  BEST VAL Loss: 0.2488  Val_Acc: 93.577

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.2249 Train_Acc: 94.413 Val_Loss: 0.2493  BEST VAL Loss: 0.2488  Val_Acc: 93.669

Epoch 56: Validation loss decreased (0.248789 --> 0.248544).  Saving model ...
	 Train_Loss: 0.2239 Train_Acc: 94.251 Val_Loss: 0.2485  BEST VAL Loss: 0.2485  Val_Acc: 94.284

Epoch 57: Validation loss decreased (0.248544 --> 0.247937).  Saving model ...
	 Train_Loss: 0.2226 Train_Acc: 95.097 Val_Loss: 0.2479  BEST VAL Loss: 0.2479  Val_Acc: 94.561

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.2216 Train_Acc: 94.255 Val_Loss: 0.2480  BEST VAL Loss: 0.2479  Val_Acc: 94.315

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.2204 Train_Acc: 94.716 Val_Loss: 0.2480  BEST VAL Loss: 0.2479  Val_Acc: 94.653

Epoch 60: Validation loss decreased (0.247937 --> 0.247433).  Saving model ...
	 Train_Loss: 0.2192 Train_Acc: 94.943 Val_Loss: 0.2474  BEST VAL Loss: 0.2474  Val_Acc: 94.899

Epoch 61: Validation loss decreased (0.247433 --> 0.246802).  Saving model ...
	 Train_Loss: 0.2181 Train_Acc: 94.643 Val_Loss: 0.2468  BEST VAL Loss: 0.2468  Val_Acc: 94.407

Epoch 62: Validation loss decreased (0.246802 --> 0.246727).  Saving model ...
	 Train_Loss: 0.2170 Train_Acc: 95.047 Val_Loss: 0.2467  BEST VAL Loss: 0.2467  Val_Acc: 93.915

Epoch 63: Validation loss decreased (0.246727 --> 0.245914).  Saving model ...
	 Train_Loss: 0.2163 Train_Acc: 94.574 Val_Loss: 0.2459  BEST VAL Loss: 0.2459  Val_Acc: 94.530

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.2151 Train_Acc: 95.466 Val_Loss: 0.2463  BEST VAL Loss: 0.2459  Val_Acc: 94.192

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.2175 Train_Acc: 91.539 Val_Loss: 0.2520  BEST VAL Loss: 0.2459  Val_Acc: 90.043

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.2205 Train_Acc: 87.996 Val_Loss: 0.2594  BEST VAL Loss: 0.2459  Val_Acc: 89.551

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.2222 Train_Acc: 88.806 Val_Loss: 0.2619  BEST VAL Loss: 0.2459  Val_Acc: 91.149

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.2226 Train_Acc: 90.213 Val_Loss: 0.2628  BEST VAL Loss: 0.2459  Val_Acc: 91.948

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.2228 Train_Acc: 90.981 Val_Loss: 0.2645  BEST VAL Loss: 0.2459  Val_Acc: 91.641

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.2231 Train_Acc: 90.493 Val_Loss: 0.2672  BEST VAL Loss: 0.2459  Val_Acc: 92.624

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.2233 Train_Acc: 90.928 Val_Loss: 0.2683  BEST VAL Loss: 0.2459  Val_Acc: 92.563

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.2232 Train_Acc: 92.126 Val_Loss: 0.2705  BEST VAL Loss: 0.2459  Val_Acc: 92.870

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.2231 Train_Acc: 92.015 Val_Loss: 0.2717  BEST VAL Loss: 0.2459  Val_Acc: 92.901

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.2228 Train_Acc: 92.772 Val_Loss: 0.2727  BEST VAL Loss: 0.2459  Val_Acc: 92.963

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.2225 Train_Acc: 92.968 Val_Loss: 0.2740  BEST VAL Loss: 0.2459  Val_Acc: 93.208

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.2223 Train_Acc: 92.599 Val_Loss: 0.2760  BEST VAL Loss: 0.2459  Val_Acc: 93.178

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.2219 Train_Acc: 93.037 Val_Loss: 0.2771  BEST VAL Loss: 0.2459  Val_Acc: 93.331

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.2214 Train_Acc: 93.763 Val_Loss: 0.2789  BEST VAL Loss: 0.2459  Val_Acc: 93.669

Epoch 79: Validation loss did not decrease
Early stopped at epoch : 79
Thapsigargin_10.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_10.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.70      0.69      0.70     18174
           1       0.31      0.32      0.32      7850

    accuracy                           0.58     26024
   macro avg       0.51      0.51      0.51     26024
weighted avg       0.58      0.58      0.58     26024

Thapsigargin_10.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_10.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.70      0.69      0.70      2272
           1       0.31      0.32      0.31       982

    accuracy                           0.58      3254
   macro avg       0.50      0.50      0.50      3254
weighted avg       0.58      0.58      0.58      3254

Thapsigargin_10.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_10.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.70      0.70      0.70      2272
           1       0.31      0.32      0.32       982

    accuracy                           0.58      3254
   macro avg       0.51      0.51      0.51      3254
weighted avg       0.59      0.58      0.58      3254

              precision    recall  f1-score   support

           0       0.70      0.70      0.70      2272
           1       0.31      0.32      0.32       982

    accuracy                           0.58      3254
   macro avg       0.51      0.51      0.51      3254
weighted avg       0.59      0.58      0.58      3254

Thapsigargin_10.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_10.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.54      0.55      0.54      4182
           1       0.43      0.43      0.43      3398

    accuracy                           0.49      7580
   macro avg       0.49      0.49      0.49      7580
weighted avg       0.49      0.49      0.49      7580

              precision    recall  f1-score   support

           0       0.54      0.55      0.54      4182
           1       0.43      0.43      0.43      3398

    accuracy                           0.49      7580
   macro avg       0.49      0.49      0.49      7580
weighted avg       0.49      0.49      0.49      7580

completed
