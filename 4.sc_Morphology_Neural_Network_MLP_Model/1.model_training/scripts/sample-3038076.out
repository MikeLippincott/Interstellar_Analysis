[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'eb71f416'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '5c1130f3'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '33656f6c'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '26ca5cb9'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Thapsigargin_10.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Thapsigargin_10.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (341245, 1270)
Number of total missing values across all columns: 333968
Data Subset Is Off
Wells held out for testing: ['L06' 'L09']
Wells to use for training, validation, and testing ['E06' 'E07' 'L02' 'L03' 'L07' 'L08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.169143).  Saving model ...
	 Train_Loss: 0.3011 Train_Acc: 89.732 Val_Loss: 0.1691  BEST VAL Loss: 0.1691  Val_Acc: 94.617

Epoch 1: Validation loss decreased (0.169143 --> 0.149892).  Saving model ...
	 Train_Loss: 0.2454 Train_Acc: 93.867 Val_Loss: 0.1499  BEST VAL Loss: 0.1499  Val_Acc: 95.491

Epoch 2: Validation loss decreased (0.149892 --> 0.137879).  Saving model ...
	 Train_Loss: 0.2184 Train_Acc: 94.581 Val_Loss: 0.1379  BEST VAL Loss: 0.1379  Val_Acc: 95.955

Epoch 3: Validation loss decreased (0.137879 --> 0.129815).  Saving model ...
	 Train_Loss: 0.2017 Train_Acc: 95.035 Val_Loss: 0.1298  BEST VAL Loss: 0.1298  Val_Acc: 96.195

Epoch 4: Validation loss decreased (0.129815 --> 0.123502).  Saving model ...
	 Train_Loss: 0.1898 Train_Acc: 95.311 Val_Loss: 0.1235  BEST VAL Loss: 0.1235  Val_Acc: 96.470

Epoch 5: Validation loss decreased (0.123502 --> 0.118562).  Saving model ...
	 Train_Loss: 0.1808 Train_Acc: 95.545 Val_Loss: 0.1186  BEST VAL Loss: 0.1186  Val_Acc: 96.651

Epoch 6: Validation loss decreased (0.118562 --> 0.114620).  Saving model ...
	 Train_Loss: 0.1736 Train_Acc: 95.638 Val_Loss: 0.1146  BEST VAL Loss: 0.1146  Val_Acc: 96.736

Epoch 7: Validation loss decreased (0.114620 --> 0.111446).  Saving model ...
	 Train_Loss: 0.1678 Train_Acc: 95.731 Val_Loss: 0.1114  BEST VAL Loss: 0.1114  Val_Acc: 96.729

Epoch 8: Validation loss decreased (0.111446 --> 0.108760).  Saving model ...
	 Train_Loss: 0.1629 Train_Acc: 95.899 Val_Loss: 0.1088  BEST VAL Loss: 0.1088  Val_Acc: 96.860

Epoch 9: Validation loss decreased (0.108760 --> 0.106700).  Saving model ...
	 Train_Loss: 0.1588 Train_Acc: 95.937 Val_Loss: 0.1067  BEST VAL Loss: 0.1067  Val_Acc: 96.717

Epoch 10: Validation loss decreased (0.106700 --> 0.104721).  Saving model ...
	 Train_Loss: 0.1552 Train_Acc: 95.977 Val_Loss: 0.1047  BEST VAL Loss: 0.1047  Val_Acc: 96.937

Epoch 11: Validation loss decreased (0.104721 --> 0.102993).  Saving model ...
	 Train_Loss: 0.1521 Train_Acc: 96.026 Val_Loss: 0.1030  BEST VAL Loss: 0.1030  Val_Acc: 96.984

Epoch 12: Validation loss decreased (0.102993 --> 0.101354).  Saving model ...
	 Train_Loss: 0.1493 Train_Acc: 96.118 Val_Loss: 0.1014  BEST VAL Loss: 0.1014  Val_Acc: 97.096

Epoch 13: Validation loss decreased (0.101354 --> 0.099932).  Saving model ...
	 Train_Loss: 0.1469 Train_Acc: 96.089 Val_Loss: 0.0999  BEST VAL Loss: 0.0999  Val_Acc: 97.139

Epoch 14: Validation loss decreased (0.099932 --> 0.098707).  Saving model ...
	 Train_Loss: 0.1446 Train_Acc: 96.216 Val_Loss: 0.0987  BEST VAL Loss: 0.0987  Val_Acc: 97.077

Epoch 15: Validation loss decreased (0.098707 --> 0.097467).  Saving model ...
	 Train_Loss: 0.1426 Train_Acc: 96.207 Val_Loss: 0.0975  BEST VAL Loss: 0.0975  Val_Acc: 97.181

Epoch 16: Validation loss decreased (0.097467 --> 0.096344).  Saving model ...
	 Train_Loss: 0.1407 Train_Acc: 96.232 Val_Loss: 0.0963  BEST VAL Loss: 0.0963  Val_Acc: 97.216

Epoch 17: Validation loss decreased (0.096344 --> 0.095296).  Saving model ...
	 Train_Loss: 0.1391 Train_Acc: 96.269 Val_Loss: 0.0953  BEST VAL Loss: 0.0953  Val_Acc: 97.305

Epoch 18: Validation loss decreased (0.095296 --> 0.094411).  Saving model ...
	 Train_Loss: 0.1376 Train_Acc: 96.311 Val_Loss: 0.0944  BEST VAL Loss: 0.0944  Val_Acc: 97.262

Epoch 19: Validation loss decreased (0.094411 --> 0.093600).  Saving model ...
	 Train_Loss: 0.1361 Train_Acc: 96.321 Val_Loss: 0.0936  BEST VAL Loss: 0.0936  Val_Acc: 97.313

Epoch 20: Validation loss decreased (0.093600 --> 0.092871).  Saving model ...
	 Train_Loss: 0.1348 Train_Acc: 96.353 Val_Loss: 0.0929  BEST VAL Loss: 0.0929  Val_Acc: 97.200

Epoch 21: Validation loss decreased (0.092871 --> 0.092103).  Saving model ...
	 Train_Loss: 0.1336 Train_Acc: 96.370 Val_Loss: 0.0921  BEST VAL Loss: 0.0921  Val_Acc: 97.340

Epoch 22: Validation loss decreased (0.092103 --> 0.091351).  Saving model ...
	 Train_Loss: 0.1325 Train_Acc: 96.360 Val_Loss: 0.0914  BEST VAL Loss: 0.0914  Val_Acc: 97.429

Epoch 23: Validation loss decreased (0.091351 --> 0.090722).  Saving model ...
	 Train_Loss: 0.1314 Train_Acc: 96.401 Val_Loss: 0.0907  BEST VAL Loss: 0.0907  Val_Acc: 97.425

Epoch 24: Validation loss decreased (0.090722 --> 0.090064).  Saving model ...
	 Train_Loss: 0.1304 Train_Acc: 96.456 Val_Loss: 0.0901  BEST VAL Loss: 0.0901  Val_Acc: 97.463

Epoch 25: Validation loss decreased (0.090064 --> 0.089522).  Saving model ...
	 Train_Loss: 0.1294 Train_Acc: 96.427 Val_Loss: 0.0895  BEST VAL Loss: 0.0895  Val_Acc: 97.324

Epoch 26: Validation loss decreased (0.089522 --> 0.088885).  Saving model ...
	 Train_Loss: 0.1285 Train_Acc: 96.505 Val_Loss: 0.0889  BEST VAL Loss: 0.0889  Val_Acc: 97.537

Epoch 27: Validation loss decreased (0.088885 --> 0.088316).  Saving model ...
	 Train_Loss: 0.1276 Train_Acc: 96.527 Val_Loss: 0.0883  BEST VAL Loss: 0.0883  Val_Acc: 97.498

Epoch 28: Validation loss decreased (0.088316 --> 0.087772).  Saving model ...
	 Train_Loss: 0.1268 Train_Acc: 96.531 Val_Loss: 0.0878  BEST VAL Loss: 0.0878  Val_Acc: 97.494

Epoch 29: Validation loss decreased (0.087772 --> 0.087374).  Saving model ...
	 Train_Loss: 0.1260 Train_Acc: 96.486 Val_Loss: 0.0874  BEST VAL Loss: 0.0874  Val_Acc: 97.332

Epoch 30: Validation loss decreased (0.087374 --> 0.086941).  Saving model ...
	 Train_Loss: 0.1253 Train_Acc: 96.446 Val_Loss: 0.0869  BEST VAL Loss: 0.0869  Val_Acc: 97.448

Epoch 31: Validation loss decreased (0.086941 --> 0.086502).  Saving model ...
	 Train_Loss: 0.1247 Train_Acc: 96.536 Val_Loss: 0.0865  BEST VAL Loss: 0.0865  Val_Acc: 97.575

Epoch 32: Validation loss decreased (0.086502 --> 0.086075).  Saving model ...
	 Train_Loss: 0.1240 Train_Acc: 96.547 Val_Loss: 0.0861  BEST VAL Loss: 0.0861  Val_Acc: 97.517

Epoch 33: Validation loss decreased (0.086075 --> 0.085750).  Saving model ...
	 Train_Loss: 0.1233 Train_Acc: 96.618 Val_Loss: 0.0857  BEST VAL Loss: 0.0857  Val_Acc: 97.425

Epoch 34: Validation loss decreased (0.085750 --> 0.085394).  Saving model ...
	 Train_Loss: 0.1227 Train_Acc: 96.544 Val_Loss: 0.0854  BEST VAL Loss: 0.0854  Val_Acc: 97.510

Epoch 35: Validation loss decreased (0.085394 --> 0.085041).  Saving model ...
	 Train_Loss: 0.1222 Train_Acc: 96.559 Val_Loss: 0.0850  BEST VAL Loss: 0.0850  Val_Acc: 97.429

Epoch 36: Validation loss decreased (0.085041 --> 0.084640).  Saving model ...
	 Train_Loss: 0.1217 Train_Acc: 96.539 Val_Loss: 0.0846  BEST VAL Loss: 0.0846  Val_Acc: 97.634

Epoch 37: Validation loss decreased (0.084640 --> 0.084320).  Saving model ...
	 Train_Loss: 0.1211 Train_Acc: 96.655 Val_Loss: 0.0843  BEST VAL Loss: 0.0843  Val_Acc: 97.483

Epoch 38: Validation loss decreased (0.084320 --> 0.083958).  Saving model ...
	 Train_Loss: 0.1206 Train_Acc: 96.585 Val_Loss: 0.0840  BEST VAL Loss: 0.0840  Val_Acc: 97.595

Epoch 39: Validation loss decreased (0.083958 --> 0.083633).  Saving model ...
	 Train_Loss: 0.1201 Train_Acc: 96.660 Val_Loss: 0.0836  BEST VAL Loss: 0.0836  Val_Acc: 97.614

Epoch 40: Validation loss decreased (0.083633 --> 0.083342).  Saving model ...
	 Train_Loss: 0.1196 Train_Acc: 96.633 Val_Loss: 0.0833  BEST VAL Loss: 0.0833  Val_Acc: 97.510

Epoch 41: Validation loss decreased (0.083342 --> 0.083092).  Saving model ...
	 Train_Loss: 0.1192 Train_Acc: 96.593 Val_Loss: 0.0831  BEST VAL Loss: 0.0831  Val_Acc: 97.595

Epoch 42: Validation loss decreased (0.083092 --> 0.082873).  Saving model ...
	 Train_Loss: 0.1187 Train_Acc: 96.572 Val_Loss: 0.0829  BEST VAL Loss: 0.0829  Val_Acc: 97.490

Epoch 43: Validation loss decreased (0.082873 --> 0.082613).  Saving model ...
	 Train_Loss: 0.1183 Train_Acc: 96.658 Val_Loss: 0.0826  BEST VAL Loss: 0.0826  Val_Acc: 97.595

Epoch 44: Validation loss decreased (0.082613 --> 0.082341).  Saving model ...
	 Train_Loss: 0.1179 Train_Acc: 96.684 Val_Loss: 0.0823  BEST VAL Loss: 0.0823  Val_Acc: 97.645

Epoch 45: Validation loss decreased (0.082341 --> 0.082100).  Saving model ...
	 Train_Loss: 0.1174 Train_Acc: 96.728 Val_Loss: 0.0821  BEST VAL Loss: 0.0821  Val_Acc: 97.606

Epoch 46: Validation loss decreased (0.082100 --> 0.081848).  Saving model ...
	 Train_Loss: 0.1171 Train_Acc: 96.694 Val_Loss: 0.0818  BEST VAL Loss: 0.0818  Val_Acc: 97.626

Epoch 47: Validation loss decreased (0.081848 --> 0.081669).  Saving model ...
	 Train_Loss: 0.1167 Train_Acc: 96.673 Val_Loss: 0.0817  BEST VAL Loss: 0.0817  Val_Acc: 97.626

Epoch 48: Validation loss decreased (0.081669 --> 0.081475).  Saving model ...
	 Train_Loss: 0.1163 Train_Acc: 96.702 Val_Loss: 0.0815  BEST VAL Loss: 0.0815  Val_Acc: 97.552

Epoch 49: Validation loss decreased (0.081475 --> 0.081263).  Saving model ...
	 Train_Loss: 0.1159 Train_Acc: 96.732 Val_Loss: 0.0813  BEST VAL Loss: 0.0813  Val_Acc: 97.560

Epoch 50: Validation loss decreased (0.081263 --> 0.081056).  Saving model ...
	 Train_Loss: 0.1156 Train_Acc: 96.701 Val_Loss: 0.0811  BEST VAL Loss: 0.0811  Val_Acc: 97.556

Epoch 51: Validation loss decreased (0.081056 --> 0.080940).  Saving model ...
	 Train_Loss: 0.1153 Train_Acc: 96.710 Val_Loss: 0.0809  BEST VAL Loss: 0.0809  Val_Acc: 97.324

Epoch 52: Validation loss decreased (0.080940 --> 0.080747).  Saving model ...
	 Train_Loss: 0.1149 Train_Acc: 96.745 Val_Loss: 0.0807  BEST VAL Loss: 0.0807  Val_Acc: 97.614

Epoch 53: Validation loss decreased (0.080747 --> 0.080567).  Saving model ...
	 Train_Loss: 0.1146 Train_Acc: 96.760 Val_Loss: 0.0806  BEST VAL Loss: 0.0806  Val_Acc: 97.521

Epoch 54: Validation loss decreased (0.080567 --> 0.080364).  Saving model ...
	 Train_Loss: 0.1143 Train_Acc: 96.788 Val_Loss: 0.0804  BEST VAL Loss: 0.0804  Val_Acc: 97.676

Epoch 55: Validation loss decreased (0.080364 --> 0.080190).  Saving model ...
	 Train_Loss: 0.1140 Train_Acc: 96.738 Val_Loss: 0.0802  BEST VAL Loss: 0.0802  Val_Acc: 97.684

Epoch 56: Validation loss decreased (0.080190 --> 0.080029).  Saving model ...
	 Train_Loss: 0.1137 Train_Acc: 96.756 Val_Loss: 0.0800  BEST VAL Loss: 0.0800  Val_Acc: 97.676

Epoch 57: Validation loss decreased (0.080029 --> 0.079897).  Saving model ...
	 Train_Loss: 0.1134 Train_Acc: 96.772 Val_Loss: 0.0799  BEST VAL Loss: 0.0799  Val_Acc: 97.552

Epoch 58: Validation loss decreased (0.079897 --> 0.079713).  Saving model ...
	 Train_Loss: 0.1132 Train_Acc: 96.725 Val_Loss: 0.0797  BEST VAL Loss: 0.0797  Val_Acc: 97.661

Epoch 59: Validation loss decreased (0.079713 --> 0.079532).  Saving model ...
	 Train_Loss: 0.1129 Train_Acc: 96.787 Val_Loss: 0.0795  BEST VAL Loss: 0.0795  Val_Acc: 97.719

Epoch 60: Validation loss decreased (0.079532 --> 0.079360).  Saving model ...
	 Train_Loss: 0.1126 Train_Acc: 96.755 Val_Loss: 0.0794  BEST VAL Loss: 0.0794  Val_Acc: 97.692

Epoch 61: Validation loss decreased (0.079360 --> 0.079194).  Saving model ...
	 Train_Loss: 0.1124 Train_Acc: 96.750 Val_Loss: 0.0792  BEST VAL Loss: 0.0792  Val_Acc: 97.680

Epoch 62: Validation loss decreased (0.079194 --> 0.079034).  Saving model ...
	 Train_Loss: 0.1121 Train_Acc: 96.817 Val_Loss: 0.0790  BEST VAL Loss: 0.0790  Val_Acc: 97.680

Epoch 63: Validation loss decreased (0.079034 --> 0.078904).  Saving model ...
	 Train_Loss: 0.1119 Train_Acc: 96.813 Val_Loss: 0.0789  BEST VAL Loss: 0.0789  Val_Acc: 97.668

Epoch 64: Validation loss decreased (0.078904 --> 0.078755).  Saving model ...
	 Train_Loss: 0.1116 Train_Acc: 96.763 Val_Loss: 0.0788  BEST VAL Loss: 0.0788  Val_Acc: 97.676

Epoch 65: Validation loss decreased (0.078755 --> 0.078568).  Saving model ...
	 Train_Loss: 0.1114 Train_Acc: 96.739 Val_Loss: 0.0786  BEST VAL Loss: 0.0786  Val_Acc: 97.746

Epoch 66: Validation loss decreased (0.078568 --> 0.078438).  Saving model ...
	 Train_Loss: 0.1112 Train_Acc: 96.807 Val_Loss: 0.0784  BEST VAL Loss: 0.0784  Val_Acc: 97.707

Epoch 67: Validation loss decreased (0.078438 --> 0.078278).  Saving model ...
	 Train_Loss: 0.1109 Train_Acc: 96.806 Val_Loss: 0.0783  BEST VAL Loss: 0.0783  Val_Acc: 97.734

Epoch 68: Validation loss decreased (0.078278 --> 0.078186).  Saving model ...
	 Train_Loss: 0.1107 Train_Acc: 96.805 Val_Loss: 0.0782  BEST VAL Loss: 0.0782  Val_Acc: 97.556

Epoch 69: Validation loss decreased (0.078186 --> 0.078083).  Saving model ...
	 Train_Loss: 0.1105 Train_Acc: 96.784 Val_Loss: 0.0781  BEST VAL Loss: 0.0781  Val_Acc: 97.603

Epoch 70: Validation loss decreased (0.078083 --> 0.077945).  Saving model ...
	 Train_Loss: 0.1103 Train_Acc: 96.869 Val_Loss: 0.0779  BEST VAL Loss: 0.0779  Val_Acc: 97.769

Epoch 71: Validation loss decreased (0.077945 --> 0.077829).  Saving model ...
	 Train_Loss: 0.1101 Train_Acc: 96.769 Val_Loss: 0.0778  BEST VAL Loss: 0.0778  Val_Acc: 97.641

Epoch 72: Validation loss decreased (0.077829 --> 0.077711).  Saving model ...
	 Train_Loss: 0.1099 Train_Acc: 96.755 Val_Loss: 0.0777  BEST VAL Loss: 0.0777  Val_Acc: 97.692

Epoch 73: Validation loss decreased (0.077711 --> 0.077600).  Saving model ...
	 Train_Loss: 0.1097 Train_Acc: 96.769 Val_Loss: 0.0776  BEST VAL Loss: 0.0776  Val_Acc: 97.769

Epoch 74: Validation loss decreased (0.077600 --> 0.077483).  Saving model ...
	 Train_Loss: 0.1095 Train_Acc: 96.886 Val_Loss: 0.0775  BEST VAL Loss: 0.0775  Val_Acc: 97.765

Epoch 75: Validation loss decreased (0.077483 --> 0.077371).  Saving model ...
	 Train_Loss: 0.1093 Train_Acc: 96.818 Val_Loss: 0.0774  BEST VAL Loss: 0.0774  Val_Acc: 97.765

Epoch 76: Validation loss decreased (0.077371 --> 0.077271).  Saving model ...
	 Train_Loss: 0.1092 Train_Acc: 96.810 Val_Loss: 0.0773  BEST VAL Loss: 0.0773  Val_Acc: 97.707

Epoch 77: Validation loss decreased (0.077271 --> 0.077173).  Saving model ...
	 Train_Loss: 0.1090 Train_Acc: 96.798 Val_Loss: 0.0772  BEST VAL Loss: 0.0772  Val_Acc: 97.715

Epoch 78: Validation loss decreased (0.077173 --> 0.077099).  Saving model ...
	 Train_Loss: 0.1088 Train_Acc: 96.811 Val_Loss: 0.0771  BEST VAL Loss: 0.0771  Val_Acc: 97.622

Epoch 79: Validation loss decreased (0.077099 --> 0.076989).  Saving model ...
	 Train_Loss: 0.1086 Train_Acc: 96.852 Val_Loss: 0.0770  BEST VAL Loss: 0.0770  Val_Acc: 97.788

Epoch 80: Validation loss decreased (0.076989 --> 0.076925).  Saving model ...
	 Train_Loss: 0.1085 Train_Acc: 96.872 Val_Loss: 0.0769  BEST VAL Loss: 0.0769  Val_Acc: 97.618

Epoch 81: Validation loss decreased (0.076925 --> 0.076845).  Saving model ...
	 Train_Loss: 0.1083 Train_Acc: 96.881 Val_Loss: 0.0768  BEST VAL Loss: 0.0768  Val_Acc: 97.676

Epoch 82: Validation loss decreased (0.076845 --> 0.076742).  Saving model ...
	 Train_Loss: 0.1081 Train_Acc: 96.883 Val_Loss: 0.0767  BEST VAL Loss: 0.0767  Val_Acc: 97.800

Epoch 83: Validation loss decreased (0.076742 --> 0.076634).  Saving model ...
	 Train_Loss: 0.1079 Train_Acc: 96.848 Val_Loss: 0.0766  BEST VAL Loss: 0.0766  Val_Acc: 97.757

Epoch 84: Validation loss decreased (0.076634 --> 0.076531).  Saving model ...
	 Train_Loss: 0.1078 Train_Acc: 96.877 Val_Loss: 0.0765  BEST VAL Loss: 0.0765  Val_Acc: 97.761

Epoch 85: Validation loss decreased (0.076531 --> 0.076438).  Saving model ...
	 Train_Loss: 0.1076 Train_Acc: 96.883 Val_Loss: 0.0764  BEST VAL Loss: 0.0764  Val_Acc: 97.862

Epoch 86: Validation loss decreased (0.076438 --> 0.076340).  Saving model ...
	 Train_Loss: 0.1075 Train_Acc: 96.844 Val_Loss: 0.0763  BEST VAL Loss: 0.0763  Val_Acc: 97.823

Epoch 87: Validation loss decreased (0.076340 --> 0.076260).  Saving model ...
	 Train_Loss: 0.1073 Train_Acc: 96.822 Val_Loss: 0.0763  BEST VAL Loss: 0.0763  Val_Acc: 97.688

Epoch 88: Validation loss decreased (0.076260 --> 0.076208).  Saving model ...
	 Train_Loss: 0.1072 Train_Acc: 96.891 Val_Loss: 0.0762  BEST VAL Loss: 0.0762  Val_Acc: 97.583

Epoch 89: Validation loss decreased (0.076208 --> 0.076125).  Saving model ...
	 Train_Loss: 0.1070 Train_Acc: 96.871 Val_Loss: 0.0761  BEST VAL Loss: 0.0761  Val_Acc: 97.722

Epoch 90: Validation loss decreased (0.076125 --> 0.076045).  Saving model ...
	 Train_Loss: 0.1069 Train_Acc: 96.895 Val_Loss: 0.0760  BEST VAL Loss: 0.0760  Val_Acc: 97.711

Epoch 91: Validation loss decreased (0.076045 --> 0.075953).  Saving model ...
	 Train_Loss: 0.1067 Train_Acc: 96.879 Val_Loss: 0.0760  BEST VAL Loss: 0.0760  Val_Acc: 97.773

Epoch 92: Validation loss decreased (0.075953 --> 0.075884).  Saving model ...
	 Train_Loss: 0.1066 Train_Acc: 96.848 Val_Loss: 0.0759  BEST VAL Loss: 0.0759  Val_Acc: 97.719

Epoch 93: Validation loss decreased (0.075884 --> 0.075803).  Saving model ...
	 Train_Loss: 0.1065 Train_Acc: 96.839 Val_Loss: 0.0758  BEST VAL Loss: 0.0758  Val_Acc: 97.688

Epoch 94: Validation loss decreased (0.075803 --> 0.075716).  Saving model ...
	 Train_Loss: 0.1064 Train_Acc: 96.875 Val_Loss: 0.0757  BEST VAL Loss: 0.0757  Val_Acc: 97.707

Epoch 95: Validation loss decreased (0.075716 --> 0.075644).  Saving model ...
	 Train_Loss: 0.1062 Train_Acc: 96.891 Val_Loss: 0.0756  BEST VAL Loss: 0.0756  Val_Acc: 97.769

Epoch 96: Validation loss decreased (0.075644 --> 0.075559).  Saving model ...
	 Train_Loss: 0.1061 Train_Acc: 96.911 Val_Loss: 0.0756  BEST VAL Loss: 0.0756  Val_Acc: 97.815

Epoch 97: Validation loss decreased (0.075559 --> 0.075487).  Saving model ...
	 Train_Loss: 0.1060 Train_Acc: 96.894 Val_Loss: 0.0755  BEST VAL Loss: 0.0755  Val_Acc: 97.761

Epoch 98: Validation loss decreased (0.075487 --> 0.075400).  Saving model ...
	 Train_Loss: 0.1058 Train_Acc: 96.927 Val_Loss: 0.0754  BEST VAL Loss: 0.0754  Val_Acc: 97.738

Epoch 99: Validation loss decreased (0.075400 --> 0.075326).  Saving model ...
	 Train_Loss: 0.1057 Train_Acc: 96.860 Val_Loss: 0.0753  BEST VAL Loss: 0.0753  Val_Acc: 97.842

Thapsigargin_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.52      0.53    109228
           1       0.47      0.48      0.47     97655

    accuracy                           0.50    206883
   macro avg       0.50      0.50      0.50    206883
weighted avg       0.50      0.50      0.50    206883

Thapsigargin_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.52      0.52     13654
           1       0.47      0.47      0.47     12207

    accuracy                           0.50     25861
   macro avg       0.50      0.50      0.50     25861
weighted avg       0.50      0.50      0.50     25861

Thapsigargin_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.53      0.53     13654
           1       0.48      0.48      0.48     12207

    accuracy                           0.51     25861
   macro avg       0.51      0.51      0.50     25861
weighted avg       0.51      0.51      0.51     25861

              precision    recall  f1-score   support

           0       0.53      0.53      0.53     13654
           1       0.48      0.48      0.48     12207

    accuracy                           0.51     25861
   macro avg       0.51      0.51      0.50     25861
weighted avg       0.51      0.51      0.51     25861

Thapsigargin_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.47      0.47     37725
           1       0.54      0.53      0.54     44915

    accuracy                           0.50     82640
   macro avg       0.50      0.50      0.50     82640
weighted avg       0.50      0.50      0.50     82640

              precision    recall  f1-score   support

           0       0.46      0.47      0.47     37725
           1       0.54      0.53      0.54     44915

    accuracy                           0.50     82640
   macro avg       0.50      0.50      0.50     82640
weighted avg       0.50      0.50      0.50     82640

completed
