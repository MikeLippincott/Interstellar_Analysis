[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'fc304ca8'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '1bad9e88'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'db159d2f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'ed9e5a0d'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 treatment_name: H2O2_100.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
TREATMENT_NAME: H2O2_100.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['H2O2_100.000_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (43118, 1276)
Number of total missing values across all columns: 53800
Data Subset Is Off
Wells held out for testing: ['H22' 'K16']
Wells to use for training, validation, and testing ['H18' 'H19' 'H23' 'K17' 'I18' 'I19' 'K20' 'K21' 'I22' 'I23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.393772).  Saving model ...
	 Train_Loss: 0.5390 Train_Acc: 74.131 Val_Loss: 0.3938  BEST VAL Loss: 0.3938  Val_Acc: 85.488

Epoch 1: Validation loss decreased (0.393772 --> 0.348781).  Saving model ...
	 Train_Loss: 0.4755 Train_Acc: 80.733 Val_Loss: 0.3488  BEST VAL Loss: 0.3488  Val_Acc: 88.483

Epoch 2: Validation loss decreased (0.348781 --> 0.317203).  Saving model ...
	 Train_Loss: 0.4307 Train_Acc: 86.029 Val_Loss: 0.3172  BEST VAL Loss: 0.3172  Val_Acc: 90.210

Epoch 3: Validation loss decreased (0.317203 --> 0.295176).  Saving model ...
	 Train_Loss: 0.3973 Train_Acc: 88.185 Val_Loss: 0.2952  BEST VAL Loss: 0.2952  Val_Acc: 91.304

Epoch 4: Validation loss decreased (0.295176 --> 0.277220).  Saving model ...
	 Train_Loss: 0.3712 Train_Acc: 89.276 Val_Loss: 0.2772  BEST VAL Loss: 0.2772  Val_Acc: 91.823

Epoch 5: Validation loss decreased (0.277220 --> 0.262347).  Saving model ...
	 Train_Loss: 0.3505 Train_Acc: 90.622 Val_Loss: 0.2623  BEST VAL Loss: 0.2623  Val_Acc: 92.399

Epoch 6: Validation loss decreased (0.262347 --> 0.251514).  Saving model ...
	 Train_Loss: 0.3330 Train_Acc: 91.173 Val_Loss: 0.2515  BEST VAL Loss: 0.2515  Val_Acc: 92.370

Epoch 7: Validation loss decreased (0.251514 --> 0.242856).  Saving model ...
	 Train_Loss: 0.3190 Train_Acc: 91.702 Val_Loss: 0.2429  BEST VAL Loss: 0.2429  Val_Acc: 92.946

Epoch 8: Validation loss decreased (0.242856 --> 0.235971).  Saving model ...
	 Train_Loss: 0.3072 Train_Acc: 92.105 Val_Loss: 0.2360  BEST VAL Loss: 0.2360  Val_Acc: 92.485

Epoch 9: Validation loss decreased (0.235971 --> 0.230023).  Saving model ...
	 Train_Loss: 0.2966 Train_Acc: 92.674 Val_Loss: 0.2300  BEST VAL Loss: 0.2300  Val_Acc: 92.917

Epoch 10: Validation loss decreased (0.230023 --> 0.224843).  Saving model ...
	 Train_Loss: 0.2873 Train_Acc: 92.735 Val_Loss: 0.2248  BEST VAL Loss: 0.2248  Val_Acc: 93.205

Epoch 11: Validation loss decreased (0.224843 --> 0.220511).  Saving model ...
	 Train_Loss: 0.2797 Train_Acc: 92.757 Val_Loss: 0.2205  BEST VAL Loss: 0.2205  Val_Acc: 93.003

Epoch 12: Validation loss decreased (0.220511 --> 0.216933).  Saving model ...
	 Train_Loss: 0.2729 Train_Acc: 92.904 Val_Loss: 0.2169  BEST VAL Loss: 0.2169  Val_Acc: 93.061

Epoch 13: Validation loss decreased (0.216933 --> 0.214035).  Saving model ...
	 Train_Loss: 0.2666 Train_Acc: 93.214 Val_Loss: 0.2140  BEST VAL Loss: 0.2140  Val_Acc: 93.061

Epoch 14: Validation loss decreased (0.214035 --> 0.211613).  Saving model ...
	 Train_Loss: 0.2611 Train_Acc: 93.304 Val_Loss: 0.2116  BEST VAL Loss: 0.2116  Val_Acc: 93.118

Epoch 15: Validation loss decreased (0.211613 --> 0.208923).  Saving model ...
	 Train_Loss: 0.2556 Train_Acc: 93.574 Val_Loss: 0.2089  BEST VAL Loss: 0.2089  Val_Acc: 93.694

Epoch 16: Validation loss decreased (0.208923 --> 0.206844).  Saving model ...
	 Train_Loss: 0.2505 Train_Acc: 93.862 Val_Loss: 0.2068  BEST VAL Loss: 0.2068  Val_Acc: 93.349

Epoch 17: Validation loss decreased (0.206844 --> 0.204871).  Saving model ...
	 Train_Loss: 0.2459 Train_Acc: 93.747 Val_Loss: 0.2049  BEST VAL Loss: 0.2049  Val_Acc: 93.723

Epoch 18: Validation loss decreased (0.204871 --> 0.203580).  Saving model ...
	 Train_Loss: 0.2417 Train_Acc: 93.750 Val_Loss: 0.2036  BEST VAL Loss: 0.2036  Val_Acc: 93.406

Epoch 19: Validation loss decreased (0.203580 --> 0.202263).  Saving model ...
	 Train_Loss: 0.2378 Train_Acc: 93.740 Val_Loss: 0.2023  BEST VAL Loss: 0.2023  Val_Acc: 93.493

Epoch 20: Validation loss decreased (0.202263 --> 0.201159).  Saving model ...
	 Train_Loss: 0.2342 Train_Acc: 93.815 Val_Loss: 0.2012  BEST VAL Loss: 0.2012  Val_Acc: 93.406

Epoch 21: Validation loss decreased (0.201159 --> 0.200208).  Saving model ...
	 Train_Loss: 0.2307 Train_Acc: 94.161 Val_Loss: 0.2002  BEST VAL Loss: 0.2002  Val_Acc: 93.090

Epoch 22: Validation loss decreased (0.200208 --> 0.199385).  Saving model ...
	 Train_Loss: 0.2276 Train_Acc: 94.092 Val_Loss: 0.1994  BEST VAL Loss: 0.1994  Val_Acc: 93.291

Epoch 23: Validation loss decreased (0.199385 --> 0.198662).  Saving model ...
	 Train_Loss: 0.2247 Train_Acc: 93.819 Val_Loss: 0.1987  BEST VAL Loss: 0.1987  Val_Acc: 93.003

Epoch 24: Validation loss decreased (0.198662 --> 0.198243).  Saving model ...
	 Train_Loss: 0.2219 Train_Acc: 94.139 Val_Loss: 0.1982  BEST VAL Loss: 0.1982  Val_Acc: 93.003

Epoch 25: Validation loss decreased (0.198243 --> 0.198020).  Saving model ...
	 Train_Loss: 0.2193 Train_Acc: 94.272 Val_Loss: 0.1980  BEST VAL Loss: 0.1980  Val_Acc: 93.118

Epoch 26: Validation loss decreased (0.198020 --> 0.197585).  Saving model ...
	 Train_Loss: 0.2169 Train_Acc: 94.330 Val_Loss: 0.1976  BEST VAL Loss: 0.1976  Val_Acc: 93.090

Epoch 27: Validation loss decreased (0.197585 --> 0.197466).  Saving model ...
	 Train_Loss: 0.2144 Train_Acc: 94.546 Val_Loss: 0.1975  BEST VAL Loss: 0.1975  Val_Acc: 92.888

Epoch 28: Validation loss decreased (0.197466 --> 0.197212).  Saving model ...
	 Train_Loss: 0.2121 Train_Acc: 94.373 Val_Loss: 0.1972  BEST VAL Loss: 0.1972  Val_Acc: 93.349

Epoch 29: Validation loss decreased (0.197212 --> 0.197024).  Saving model ...
	 Train_Loss: 0.2100 Train_Acc: 94.370 Val_Loss: 0.1970  BEST VAL Loss: 0.1970  Val_Acc: 93.637

Epoch 30: Validation loss decreased (0.197024 --> 0.196412).  Saving model ...
	 Train_Loss: 0.2078 Train_Acc: 94.485 Val_Loss: 0.1964  BEST VAL Loss: 0.1964  Val_Acc: 93.579

Epoch 31: Validation loss decreased (0.196412 --> 0.196003).  Saving model ...
	 Train_Loss: 0.2058 Train_Acc: 94.686 Val_Loss: 0.1960  BEST VAL Loss: 0.1960  Val_Acc: 93.377

Epoch 32: Validation loss decreased (0.196003 --> 0.195807).  Saving model ...
	 Train_Loss: 0.2039 Train_Acc: 94.517 Val_Loss: 0.1958  BEST VAL Loss: 0.1958  Val_Acc: 93.579

Epoch 33: Validation loss decreased (0.195807 --> 0.195514).  Saving model ...
	 Train_Loss: 0.2020 Train_Acc: 94.632 Val_Loss: 0.1955  BEST VAL Loss: 0.1955  Val_Acc: 93.377

Epoch 34: Validation loss decreased (0.195514 --> 0.195023).  Saving model ...
	 Train_Loss: 0.2001 Train_Acc: 94.852 Val_Loss: 0.1950  BEST VAL Loss: 0.1950  Val_Acc: 93.752

Epoch 35: Validation loss decreased (0.195023 --> 0.194982).  Saving model ...
	 Train_Loss: 0.1984 Train_Acc: 94.838 Val_Loss: 0.1950  BEST VAL Loss: 0.1950  Val_Acc: 93.406

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.1967 Train_Acc: 94.694 Val_Loss: 0.1950  BEST VAL Loss: 0.1950  Val_Acc: 93.493

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.1950 Train_Acc: 94.895 Val_Loss: 0.1952  BEST VAL Loss: 0.1950  Val_Acc: 93.118

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.1935 Train_Acc: 94.802 Val_Loss: 0.1952  BEST VAL Loss: 0.1950  Val_Acc: 93.262

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.1919 Train_Acc: 95.093 Val_Loss: 0.1954  BEST VAL Loss: 0.1950  Val_Acc: 93.205

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.1906 Train_Acc: 94.946 Val_Loss: 0.1953  BEST VAL Loss: 0.1950  Val_Acc: 93.291

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.1891 Train_Acc: 94.802 Val_Loss: 0.1953  BEST VAL Loss: 0.1950  Val_Acc: 93.262

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.1878 Train_Acc: 94.866 Val_Loss: 0.1955  BEST VAL Loss: 0.1950  Val_Acc: 93.521

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.1865 Train_Acc: 94.935 Val_Loss: 0.1956  BEST VAL Loss: 0.1950  Val_Acc: 93.493

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.1851 Train_Acc: 95.147 Val_Loss: 0.1960  BEST VAL Loss: 0.1950  Val_Acc: 93.406

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.1839 Train_Acc: 94.895 Val_Loss: 0.1965  BEST VAL Loss: 0.1950  Val_Acc: 93.176

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.1827 Train_Acc: 95.115 Val_Loss: 0.1968  BEST VAL Loss: 0.1950  Val_Acc: 93.464

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.1815 Train_Acc: 95.212 Val_Loss: 0.1971  BEST VAL Loss: 0.1950  Val_Acc: 93.694

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.1803 Train_Acc: 95.169 Val_Loss: 0.1975  BEST VAL Loss: 0.1950  Val_Acc: 93.176

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.1792 Train_Acc: 95.140 Val_Loss: 0.1980  BEST VAL Loss: 0.1950  Val_Acc: 93.377

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.1781 Train_Acc: 95.003 Val_Loss: 0.1983  BEST VAL Loss: 0.1950  Val_Acc: 93.608

Epoch 51: Validation loss did not decrease
Early stopped at epoch : 51
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.99      0.98     18174
           1       0.98      0.94      0.96      9604

    accuracy                           0.97     27778
   macro avg       0.98      0.97      0.97     27778
weighted avg       0.97      0.97      0.97     27778

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.94      0.97      0.95      2272
           1       0.93      0.87      0.90      1201

    accuracy                           0.93      3473
   macro avg       0.93      0.92      0.93      3473
weighted avg       0.93      0.93      0.93      3473

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.94      0.96      0.95      2272
           1       0.92      0.88      0.90      1201

    accuracy                           0.93      3473
   macro avg       0.93      0.92      0.93      3473
weighted avg       0.93      0.93      0.93      3473

              precision    recall  f1-score   support

           0       0.94      0.96      0.95      2272
           1       0.92      0.88      0.90      1201

    accuracy                           0.93      3473
   macro avg       0.93      0.92      0.93      3473
weighted avg       0.93      0.93      0.93      3473

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.86      0.96      0.91      4182
           1       0.96      0.84      0.90      4212

    accuracy                           0.90      8394
   macro avg       0.91      0.90      0.90      8394
weighted avg       0.91      0.90      0.90      8394

              precision    recall  f1-score   support

           0       0.86      0.96      0.91      4182
           1       0.96      0.84      0.90      4212

    accuracy                           0.90      8394
   macro avg       0.91      0.90      0.90      8394
weighted avg       0.91      0.90      0.90      8394

completed
