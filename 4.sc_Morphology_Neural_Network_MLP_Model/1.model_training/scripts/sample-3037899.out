[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '2a14614a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'efd5f3a7'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '87bb6221'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '16f07ef9'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_10.000_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: Flagellin_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (32619, 1276)
Number of total missing values across all columns: 65238
Data Subset Is Off
Wells held out for testing: ['E21' 'M22']
Wells to use for training, validation, and testing ['E16' 'E17' 'E20' 'M18' 'M19' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.683543).  Saving model ...
	 Train_Loss: 0.6929 Train_Acc: 53.141 Val_Loss: 0.6835  BEST VAL Loss: 0.6835  Val_Acc: 56.997

Epoch 1: Validation loss decreased (0.683543 --> 0.680130).  Saving model ...
	 Train_Loss: 0.6876 Train_Acc: 54.917 Val_Loss: 0.6801  BEST VAL Loss: 0.6801  Val_Acc: 57.488

Epoch 2: Validation loss decreased (0.680130 --> 0.668126).  Saving model ...
	 Train_Loss: 0.6800 Train_Acc: 58.539 Val_Loss: 0.6681  BEST VAL Loss: 0.6681  Val_Acc: 62.111

Epoch 3: Validation loss decreased (0.668126 --> 0.659085).  Saving model ...
	 Train_Loss: 0.6715 Train_Acc: 60.611 Val_Loss: 0.6591  BEST VAL Loss: 0.6591  Val_Acc: 63.175

Epoch 4: Validation loss decreased (0.659085 --> 0.648440).  Saving model ...
	 Train_Loss: 0.6625 Train_Acc: 62.074 Val_Loss: 0.6484  BEST VAL Loss: 0.6484  Val_Acc: 64.648

Epoch 5: Validation loss decreased (0.648440 --> 0.639611).  Saving model ...
	 Train_Loss: 0.6548 Train_Acc: 63.563 Val_Loss: 0.6396  BEST VAL Loss: 0.6396  Val_Acc: 65.385

Epoch 6: Validation loss decreased (0.639611 --> 0.633054).  Saving model ...
	 Train_Loss: 0.6476 Train_Acc: 64.218 Val_Loss: 0.6331  BEST VAL Loss: 0.6331  Val_Acc: 66.653

Epoch 7: Validation loss decreased (0.633054 --> 0.626621).  Saving model ...
	 Train_Loss: 0.6404 Train_Acc: 65.717 Val_Loss: 0.6266  BEST VAL Loss: 0.6266  Val_Acc: 68.085

Epoch 8: Validation loss decreased (0.626621 --> 0.620033).  Saving model ...
	 Train_Loss: 0.6343 Train_Acc: 66.996 Val_Loss: 0.6200  BEST VAL Loss: 0.6200  Val_Acc: 70.213

Epoch 9: Validation loss decreased (0.620033 --> 0.616099).  Saving model ...
	 Train_Loss: 0.6279 Train_Acc: 67.999 Val_Loss: 0.6161  BEST VAL Loss: 0.6161  Val_Acc: 70.540

Epoch 10: Validation loss decreased (0.616099 --> 0.611576).  Saving model ...
	 Train_Loss: 0.6222 Train_Acc: 69.252 Val_Loss: 0.6116  BEST VAL Loss: 0.6116  Val_Acc: 71.236

Epoch 11: Validation loss decreased (0.611576 --> 0.606100).  Saving model ...
	 Train_Loss: 0.6170 Train_Acc: 69.600 Val_Loss: 0.6061  BEST VAL Loss: 0.6061  Val_Acc: 73.568

Epoch 12: Validation loss decreased (0.606100 --> 0.601715).  Saving model ...
	 Train_Loss: 0.6123 Train_Acc: 69.968 Val_Loss: 0.6017  BEST VAL Loss: 0.6017  Val_Acc: 72.218

Epoch 13: Validation loss decreased (0.601715 --> 0.597408).  Saving model ...
	 Train_Loss: 0.6079 Train_Acc: 70.142 Val_Loss: 0.5974  BEST VAL Loss: 0.5974  Val_Acc: 72.177

Epoch 14: Validation loss decreased (0.597408 --> 0.594643).  Saving model ...
	 Train_Loss: 0.6038 Train_Acc: 70.229 Val_Loss: 0.5946  BEST VAL Loss: 0.5946  Val_Acc: 71.972

Epoch 15: Validation loss decreased (0.594643 --> 0.590975).  Saving model ...
	 Train_Loss: 0.6000 Train_Acc: 70.649 Val_Loss: 0.5910  BEST VAL Loss: 0.5910  Val_Acc: 73.773

Epoch 16: Validation loss decreased (0.590975 --> 0.586429).  Saving model ...
	 Train_Loss: 0.5967 Train_Acc: 70.644 Val_Loss: 0.5864  BEST VAL Loss: 0.5864  Val_Acc: 75.082

Epoch 17: Validation loss decreased (0.586429 --> 0.582721).  Saving model ...
	 Train_Loss: 0.5940 Train_Acc: 70.976 Val_Loss: 0.5827  BEST VAL Loss: 0.5827  Val_Acc: 73.445

Epoch 18: Validation loss decreased (0.582721 --> 0.580404).  Saving model ...
	 Train_Loss: 0.5913 Train_Acc: 71.457 Val_Loss: 0.5804  BEST VAL Loss: 0.5804  Val_Acc: 73.445

Epoch 19: Validation loss decreased (0.580404 --> 0.577682).  Saving model ...
	 Train_Loss: 0.5884 Train_Acc: 71.866 Val_Loss: 0.5777  BEST VAL Loss: 0.5777  Val_Acc: 73.773

Epoch 20: Validation loss decreased (0.577682 --> 0.575533).  Saving model ...
	 Train_Loss: 0.5853 Train_Acc: 72.562 Val_Loss: 0.5755  BEST VAL Loss: 0.5755  Val_Acc: 73.773

Epoch 21: Validation loss decreased (0.575533 --> 0.574113).  Saving model ...
	 Train_Loss: 0.5825 Train_Acc: 73.069 Val_Loss: 0.5741  BEST VAL Loss: 0.5741  Val_Acc: 73.363

Epoch 22: Validation loss decreased (0.574113 --> 0.571505).  Saving model ...
	 Train_Loss: 0.5799 Train_Acc: 72.383 Val_Loss: 0.5715  BEST VAL Loss: 0.5715  Val_Acc: 75.327

Epoch 23: Validation loss decreased (0.571505 --> 0.569848).  Saving model ...
	 Train_Loss: 0.5774 Train_Acc: 73.058 Val_Loss: 0.5698  BEST VAL Loss: 0.5698  Val_Acc: 74.755

Epoch 24: Validation loss decreased (0.569848 --> 0.567487).  Saving model ...
	 Train_Loss: 0.5752 Train_Acc: 72.808 Val_Loss: 0.5675  BEST VAL Loss: 0.5675  Val_Acc: 74.182

Epoch 25: Validation loss decreased (0.567487 --> 0.565262).  Saving model ...
	 Train_Loss: 0.5731 Train_Acc: 72.736 Val_Loss: 0.5653  BEST VAL Loss: 0.5653  Val_Acc: 75.082

Epoch 26: Validation loss decreased (0.565262 --> 0.563001).  Saving model ...
	 Train_Loss: 0.5709 Train_Acc: 73.273 Val_Loss: 0.5630  BEST VAL Loss: 0.5630  Val_Acc: 75.696

Epoch 27: Validation loss decreased (0.563001 --> 0.560915).  Saving model ...
	 Train_Loss: 0.5688 Train_Acc: 73.683 Val_Loss: 0.5609  BEST VAL Loss: 0.5609  Val_Acc: 76.146

Epoch 28: Validation loss decreased (0.560915 --> 0.559135).  Saving model ...
	 Train_Loss: 0.5667 Train_Acc: 74.169 Val_Loss: 0.5591  BEST VAL Loss: 0.5591  Val_Acc: 74.591

Epoch 29: Validation loss decreased (0.559135 --> 0.557542).  Saving model ...
	 Train_Loss: 0.5645 Train_Acc: 75.084 Val_Loss: 0.5575  BEST VAL Loss: 0.5575  Val_Acc: 74.755

Epoch 30: Validation loss decreased (0.557542 --> 0.556211).  Saving model ...
	 Train_Loss: 0.5626 Train_Acc: 74.609 Val_Loss: 0.5562  BEST VAL Loss: 0.5562  Val_Acc: 74.795

Epoch 31: Validation loss decreased (0.556211 --> 0.554539).  Saving model ...
	 Train_Loss: 0.5607 Train_Acc: 74.614 Val_Loss: 0.5545  BEST VAL Loss: 0.5545  Val_Acc: 74.959

Epoch 32: Validation loss decreased (0.554539 --> 0.552795).  Saving model ...
	 Train_Loss: 0.5585 Train_Acc: 75.069 Val_Loss: 0.5528  BEST VAL Loss: 0.5528  Val_Acc: 76.187

Epoch 33: Validation loss decreased (0.552795 --> 0.551106).  Saving model ...
	 Train_Loss: 0.5567 Train_Acc: 74.511 Val_Loss: 0.5511  BEST VAL Loss: 0.5511  Val_Acc: 76.146

Epoch 34: Validation loss decreased (0.551106 --> 0.549518).  Saving model ...
	 Train_Loss: 0.5548 Train_Acc: 74.552 Val_Loss: 0.5495  BEST VAL Loss: 0.5495  Val_Acc: 76.064

Epoch 35: Validation loss decreased (0.549518 --> 0.548081).  Saving model ...
	 Train_Loss: 0.5530 Train_Acc: 75.448 Val_Loss: 0.5481  BEST VAL Loss: 0.5481  Val_Acc: 75.000

Epoch 36: Validation loss decreased (0.548081 --> 0.546453).  Saving model ...
	 Train_Loss: 0.5512 Train_Acc: 75.637 Val_Loss: 0.5465  BEST VAL Loss: 0.5465  Val_Acc: 75.000

Epoch 37: Validation loss decreased (0.546453 --> 0.545234).  Saving model ...
	 Train_Loss: 0.5495 Train_Acc: 76.302 Val_Loss: 0.5452  BEST VAL Loss: 0.5452  Val_Acc: 76.146

Epoch 38: Validation loss decreased (0.545234 --> 0.543613).  Saving model ...
	 Train_Loss: 0.5478 Train_Acc: 76.256 Val_Loss: 0.5436  BEST VAL Loss: 0.5436  Val_Acc: 76.637

Epoch 39: Validation loss decreased (0.543613 --> 0.542442).  Saving model ...
	 Train_Loss: 0.5462 Train_Acc: 75.862 Val_Loss: 0.5424  BEST VAL Loss: 0.5424  Val_Acc: 76.473

Epoch 40: Validation loss decreased (0.542442 --> 0.541054).  Saving model ...
	 Train_Loss: 0.5448 Train_Acc: 75.888 Val_Loss: 0.5411  BEST VAL Loss: 0.5411  Val_Acc: 75.696

Epoch 41: Validation loss decreased (0.541054 --> 0.540017).  Saving model ...
	 Train_Loss: 0.5432 Train_Acc: 76.138 Val_Loss: 0.5400  BEST VAL Loss: 0.5400  Val_Acc: 75.409

Epoch 42: Validation loss decreased (0.540017 --> 0.538926).  Saving model ...
	 Train_Loss: 0.5417 Train_Acc: 76.629 Val_Loss: 0.5389  BEST VAL Loss: 0.5389  Val_Acc: 75.368

Epoch 43: Validation loss decreased (0.538926 --> 0.537496).  Saving model ...
	 Train_Loss: 0.5401 Train_Acc: 76.537 Val_Loss: 0.5375  BEST VAL Loss: 0.5375  Val_Acc: 76.350

Epoch 44: Validation loss decreased (0.537496 --> 0.536416).  Saving model ...
	 Train_Loss: 0.5387 Train_Acc: 76.481 Val_Loss: 0.5364  BEST VAL Loss: 0.5364  Val_Acc: 76.678

Epoch 45: Validation loss decreased (0.536416 --> 0.534963).  Saving model ...
	 Train_Loss: 0.5371 Train_Acc: 76.660 Val_Loss: 0.5350  BEST VAL Loss: 0.5350  Val_Acc: 76.105

Epoch 46: Validation loss decreased (0.534963 --> 0.533892).  Saving model ...
	 Train_Loss: 0.5357 Train_Acc: 77.075 Val_Loss: 0.5339  BEST VAL Loss: 0.5339  Val_Acc: 75.614

Epoch 47: Validation loss decreased (0.533892 --> 0.533106).  Saving model ...
	 Train_Loss: 0.5342 Train_Acc: 77.141 Val_Loss: 0.5331  BEST VAL Loss: 0.5331  Val_Acc: 75.777

Epoch 48: Validation loss decreased (0.533106 --> 0.532392).  Saving model ...
	 Train_Loss: 0.5329 Train_Acc: 76.502 Val_Loss: 0.5324  BEST VAL Loss: 0.5324  Val_Acc: 76.187

Epoch 49: Validation loss decreased (0.532392 --> 0.531442).  Saving model ...
	 Train_Loss: 0.5317 Train_Acc: 76.461 Val_Loss: 0.5314  BEST VAL Loss: 0.5314  Val_Acc: 75.777

Epoch 50: Validation loss decreased (0.531442 --> 0.530711).  Saving model ...
	 Train_Loss: 0.5305 Train_Acc: 76.665 Val_Loss: 0.5307  BEST VAL Loss: 0.5307  Val_Acc: 76.555

Epoch 51: Validation loss decreased (0.530711 --> 0.529505).  Saving model ...
	 Train_Loss: 0.5293 Train_Acc: 76.476 Val_Loss: 0.5295  BEST VAL Loss: 0.5295  Val_Acc: 77.741

Epoch 52: Validation loss decreased (0.529505 --> 0.528591).  Saving model ...
	 Train_Loss: 0.5280 Train_Acc: 76.983 Val_Loss: 0.5286  BEST VAL Loss: 0.5286  Val_Acc: 76.473

Epoch 53: Validation loss decreased (0.528591 --> 0.527595).  Saving model ...
	 Train_Loss: 0.5267 Train_Acc: 76.655 Val_Loss: 0.5276  BEST VAL Loss: 0.5276  Val_Acc: 76.596

Epoch 54: Validation loss decreased (0.527595 --> 0.526657).  Saving model ...
	 Train_Loss: 0.5254 Train_Acc: 78.272 Val_Loss: 0.5267  BEST VAL Loss: 0.5267  Val_Acc: 77.005

Epoch 55: Validation loss decreased (0.526657 --> 0.525896).  Saving model ...
	 Train_Loss: 0.5242 Train_Acc: 77.816 Val_Loss: 0.5259  BEST VAL Loss: 0.5259  Val_Acc: 76.759

Epoch 56: Validation loss decreased (0.525896 --> 0.525008).  Saving model ...
	 Train_Loss: 0.5231 Train_Acc: 77.448 Val_Loss: 0.5250  BEST VAL Loss: 0.5250  Val_Acc: 76.555

Epoch 57: Validation loss decreased (0.525008 --> 0.524337).  Saving model ...
	 Train_Loss: 0.5219 Train_Acc: 77.929 Val_Loss: 0.5243  BEST VAL Loss: 0.5243  Val_Acc: 77.496

Epoch 58: Validation loss decreased (0.524337 --> 0.523646).  Saving model ...
	 Train_Loss: 0.5209 Train_Acc: 78.139 Val_Loss: 0.5236  BEST VAL Loss: 0.5236  Val_Acc: 77.700

Epoch 59: Validation loss decreased (0.523646 --> 0.523029).  Saving model ...
	 Train_Loss: 0.5199 Train_Acc: 78.144 Val_Loss: 0.5230  BEST VAL Loss: 0.5230  Val_Acc: 76.841

Epoch 60: Validation loss decreased (0.523029 --> 0.522242).  Saving model ...
	 Train_Loss: 0.5189 Train_Acc: 77.596 Val_Loss: 0.5222  BEST VAL Loss: 0.5222  Val_Acc: 77.209

Epoch 61: Validation loss decreased (0.522242 --> 0.521364).  Saving model ...
	 Train_Loss: 0.5178 Train_Acc: 78.343 Val_Loss: 0.5214  BEST VAL Loss: 0.5214  Val_Acc: 77.373

Epoch 62: Validation loss decreased (0.521364 --> 0.520750).  Saving model ...
	 Train_Loss: 0.5169 Train_Acc: 77.868 Val_Loss: 0.5207  BEST VAL Loss: 0.5207  Val_Acc: 76.678

Epoch 63: Validation loss decreased (0.520750 --> 0.520110).  Saving model ...
	 Train_Loss: 0.5160 Train_Acc: 77.827 Val_Loss: 0.5201  BEST VAL Loss: 0.5201  Val_Acc: 76.841

Epoch 64: Validation loss decreased (0.520110 --> 0.519374).  Saving model ...
	 Train_Loss: 0.5152 Train_Acc: 77.453 Val_Loss: 0.5194  BEST VAL Loss: 0.5194  Val_Acc: 77.005

Epoch 65: Validation loss decreased (0.519374 --> 0.518785).  Saving model ...
	 Train_Loss: 0.5144 Train_Acc: 77.376 Val_Loss: 0.5188  BEST VAL Loss: 0.5188  Val_Acc: 75.777

Epoch 66: Validation loss decreased (0.518785 --> 0.518108).  Saving model ...
	 Train_Loss: 0.5135 Train_Acc: 77.919 Val_Loss: 0.5181  BEST VAL Loss: 0.5181  Val_Acc: 77.005

Epoch 67: Validation loss decreased (0.518108 --> 0.517833).  Saving model ...
	 Train_Loss: 0.5128 Train_Acc: 77.586 Val_Loss: 0.5178  BEST VAL Loss: 0.5178  Val_Acc: 76.800

Epoch 68: Validation loss decreased (0.517833 --> 0.517250).  Saving model ...
	 Train_Loss: 0.5120 Train_Acc: 78.308 Val_Loss: 0.5172  BEST VAL Loss: 0.5172  Val_Acc: 76.391

Epoch 69: Validation loss decreased (0.517250 --> 0.516666).  Saving model ...
	 Train_Loss: 0.5111 Train_Acc: 77.934 Val_Loss: 0.5167  BEST VAL Loss: 0.5167  Val_Acc: 76.023

Epoch 70: Validation loss decreased (0.516666 --> 0.516086).  Saving model ...
	 Train_Loss: 0.5103 Train_Acc: 78.528 Val_Loss: 0.5161  BEST VAL Loss: 0.5161  Val_Acc: 76.800

Epoch 71: Validation loss decreased (0.516086 --> 0.515509).  Saving model ...
	 Train_Loss: 0.5094 Train_Acc: 78.794 Val_Loss: 0.5155  BEST VAL Loss: 0.5155  Val_Acc: 77.414

Epoch 72: Validation loss decreased (0.515509 --> 0.514906).  Saving model ...
	 Train_Loss: 0.5086 Train_Acc: 78.814 Val_Loss: 0.5149  BEST VAL Loss: 0.5149  Val_Acc: 77.291

Epoch 73: Validation loss decreased (0.514906 --> 0.514566).  Saving model ...
	 Train_Loss: 0.5077 Train_Acc: 78.922 Val_Loss: 0.5146  BEST VAL Loss: 0.5146  Val_Acc: 76.187

Epoch 74: Validation loss decreased (0.514566 --> 0.514141).  Saving model ...
	 Train_Loss: 0.5069 Train_Acc: 78.650 Val_Loss: 0.5141  BEST VAL Loss: 0.5141  Val_Acc: 76.596

Epoch 75: Validation loss decreased (0.514141 --> 0.513733).  Saving model ...
	 Train_Loss: 0.5061 Train_Acc: 78.717 Val_Loss: 0.5137  BEST VAL Loss: 0.5137  Val_Acc: 76.227

Epoch 76: Validation loss decreased (0.513733 --> 0.513386).  Saving model ...
	 Train_Loss: 0.5055 Train_Acc: 77.453 Val_Loss: 0.5134  BEST VAL Loss: 0.5134  Val_Acc: 75.450

Epoch 77: Validation loss decreased (0.513386 --> 0.512971).  Saving model ...
	 Train_Loss: 0.5048 Train_Acc: 77.944 Val_Loss: 0.5130  BEST VAL Loss: 0.5130  Val_Acc: 74.755

Epoch 78: Validation loss decreased (0.512971 --> 0.512734).  Saving model ...
	 Train_Loss: 0.5042 Train_Acc: 78.129 Val_Loss: 0.5127  BEST VAL Loss: 0.5127  Val_Acc: 76.555

Epoch 79: Validation loss decreased (0.512734 --> 0.512363).  Saving model ...
	 Train_Loss: 0.5035 Train_Acc: 78.369 Val_Loss: 0.5124  BEST VAL Loss: 0.5124  Val_Acc: 75.696

Epoch 80: Validation loss decreased (0.512363 --> 0.511895).  Saving model ...
	 Train_Loss: 0.5029 Train_Acc: 77.648 Val_Loss: 0.5119  BEST VAL Loss: 0.5119  Val_Acc: 76.678

Epoch 81: Validation loss decreased (0.511895 --> 0.511460).  Saving model ...
	 Train_Loss: 0.5023 Train_Acc: 76.619 Val_Loss: 0.5115  BEST VAL Loss: 0.5115  Val_Acc: 77.169

Epoch 82: Validation loss decreased (0.511460 --> 0.511113).  Saving model ...
	 Train_Loss: 0.5018 Train_Acc: 76.384 Val_Loss: 0.5111  BEST VAL Loss: 0.5111  Val_Acc: 76.718

Epoch 83: Validation loss decreased (0.511113 --> 0.510816).  Saving model ...
	 Train_Loss: 0.5012 Train_Acc: 77.975 Val_Loss: 0.5108  BEST VAL Loss: 0.5108  Val_Acc: 76.350

Epoch 84: Validation loss decreased (0.510816 --> 0.510526).  Saving model ...
	 Train_Loss: 0.5007 Train_Acc: 77.832 Val_Loss: 0.5105  BEST VAL Loss: 0.5105  Val_Acc: 75.777

Epoch 85: Validation loss decreased (0.510526 --> 0.510260).  Saving model ...
	 Train_Loss: 0.5002 Train_Acc: 77.591 Val_Loss: 0.5103  BEST VAL Loss: 0.5103  Val_Acc: 74.959

Epoch 86: Validation loss decreased (0.510260 --> 0.509940).  Saving model ...
	 Train_Loss: 0.4998 Train_Acc: 77.443 Val_Loss: 0.5099  BEST VAL Loss: 0.5099  Val_Acc: 76.391

Epoch 87: Validation loss decreased (0.509940 --> 0.509725).  Saving model ...
	 Train_Loss: 0.4992 Train_Acc: 78.292 Val_Loss: 0.5097  BEST VAL Loss: 0.5097  Val_Acc: 77.128

Epoch 88: Validation loss decreased (0.509725 --> 0.509362).  Saving model ...
	 Train_Loss: 0.4986 Train_Acc: 78.671 Val_Loss: 0.5094  BEST VAL Loss: 0.5094  Val_Acc: 76.555

Epoch 89: Validation loss decreased (0.509362 --> 0.509128).  Saving model ...
	 Train_Loss: 0.4981 Train_Acc: 78.103 Val_Loss: 0.5091  BEST VAL Loss: 0.5091  Val_Acc: 77.087

Epoch 90: Validation loss decreased (0.509128 --> 0.508753).  Saving model ...
	 Train_Loss: 0.4976 Train_Acc: 78.144 Val_Loss: 0.5088  BEST VAL Loss: 0.5088  Val_Acc: 75.859

Epoch 91: Validation loss decreased (0.508753 --> 0.508273).  Saving model ...
	 Train_Loss: 0.4971 Train_Acc: 78.262 Val_Loss: 0.5083  BEST VAL Loss: 0.5083  Val_Acc: 77.496

Epoch 92: Validation loss decreased (0.508273 --> 0.507988).  Saving model ...
	 Train_Loss: 0.4966 Train_Acc: 77.581 Val_Loss: 0.5080  BEST VAL Loss: 0.5080  Val_Acc: 76.882

Epoch 93: Validation loss decreased (0.507988 --> 0.507714).  Saving model ...
	 Train_Loss: 0.4960 Train_Acc: 77.929 Val_Loss: 0.5077  BEST VAL Loss: 0.5077  Val_Acc: 76.718

Epoch 94: Validation loss decreased (0.507714 --> 0.507591).  Saving model ...
	 Train_Loss: 0.4954 Train_Acc: 79.080 Val_Loss: 0.5076  BEST VAL Loss: 0.5076  Val_Acc: 76.637

Epoch 95: Validation loss decreased (0.507591 --> 0.507415).  Saving model ...
	 Train_Loss: 0.4949 Train_Acc: 78.635 Val_Loss: 0.5074  BEST VAL Loss: 0.5074  Val_Acc: 76.964

Epoch 96: Validation loss did not decrease
	 Train_Loss: 0.4944 Train_Acc: 78.466 Val_Loss: 0.5076  BEST VAL Loss: 0.5074  Val_Acc: 76.187

Epoch 97: Validation loss decreased (0.507415 --> 0.507363).  Saving model ...
	 Train_Loss: 0.4939 Train_Acc: 78.594 Val_Loss: 0.5074  BEST VAL Loss: 0.5074  Val_Acc: 76.964

Epoch 98: Validation loss decreased (0.507363 --> 0.507284).  Saving model ...
	 Train_Loss: 0.4934 Train_Acc: 78.563 Val_Loss: 0.5073  BEST VAL Loss: 0.5073  Val_Acc: 76.964

Epoch 99: Validation loss decreased (0.507284 --> 0.507053).  Saving model ...
	 Train_Loss: 0.4929 Train_Acc: 78.824 Val_Loss: 0.5071  BEST VAL Loss: 0.5071  Val_Acc: 77.128

LPS_10.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.46      0.47      9433
           1       0.52      0.54      0.53     10113

    accuracy                           0.50     19546
   macro avg       0.50      0.50      0.50     19546
weighted avg       0.50      0.50      0.50     19546

LPS_10.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.46      0.47      1179
           1       0.52      0.55      0.53      1265

    accuracy                           0.51      2444
   macro avg       0.50      0.50      0.50      2444
weighted avg       0.50      0.51      0.50      2444

LPS_10.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.46      0.47      1180
           1       0.51      0.54      0.53      1264

    accuracy                           0.50      2444
   macro avg       0.50      0.50      0.50      2444
weighted avg       0.50      0.50      0.50      2444

              precision    recall  f1-score   support

           0       0.48      0.46      0.47      1180
           1       0.51      0.54      0.53      1264

    accuracy                           0.50      2444
   macro avg       0.50      0.50      0.50      2444
weighted avg       0.50      0.50      0.50      2444

LPS_10.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.43      0.46      4017
           1       0.51      0.56      0.53      4168

    accuracy                           0.50      8185
   macro avg       0.50      0.50      0.49      8185
weighted avg       0.50      0.50      0.50      8185

              precision    recall  f1-score   support

           0       0.49      0.43      0.46      4017
           1       0.51      0.56      0.53      4168

    accuracy                           0.50      8185
   macro avg       0.50      0.50      0.49      8185
weighted avg       0.50      0.50      0.50      8185

completed
