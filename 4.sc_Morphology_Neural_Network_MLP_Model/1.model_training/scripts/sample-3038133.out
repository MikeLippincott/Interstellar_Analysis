[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '8917d66a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '0d34e2b9'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '73ae5a83'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '4a7286fe'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_0.100_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_0.100_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (31912, 1276)
Number of total missing values across all columns: 35020
Data Subset Is Off
Wells held out for testing: ['C20' 'M16']
Wells to use for training, validation, and testing ['C16' 'C17' 'C21' 'M17' 'M20' 'M21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.428284).  Saving model ...
	 Train_Loss: 0.6657 Train_Acc: 69.144 Val_Loss: 0.4283  BEST VAL Loss: 0.4283  Val_Acc: 87.045

Epoch 1: Validation loss decreased (0.428284 --> 0.403820).  Saving model ...
	 Train_Loss: 0.5994 Train_Acc: 74.587 Val_Loss: 0.4038  BEST VAL Loss: 0.4038  Val_Acc: 90.008

Epoch 2: Validation loss decreased (0.403820 --> 0.385112).  Saving model ...
	 Train_Loss: 0.5718 Train_Acc: 75.466 Val_Loss: 0.3851  BEST VAL Loss: 0.3851  Val_Acc: 91.660

Epoch 3: Validation loss decreased (0.385112 --> 0.373908).  Saving model ...
	 Train_Loss: 0.5539 Train_Acc: 76.652 Val_Loss: 0.3739  BEST VAL Loss: 0.3739  Val_Acc: 92.125

Epoch 4: Validation loss decreased (0.373908 --> 0.358930).  Saving model ...
	 Train_Loss: 0.5401 Train_Acc: 77.700 Val_Loss: 0.3589  BEST VAL Loss: 0.3589  Val_Acc: 92.972

Epoch 5: Validation loss decreased (0.358930 --> 0.350671).  Saving model ...
	 Train_Loss: 0.5301 Train_Acc: 78.002 Val_Loss: 0.3507  BEST VAL Loss: 0.3507  Val_Acc: 93.734

Epoch 6: Validation loss decreased (0.350671 --> 0.341678).  Saving model ...
	 Train_Loss: 0.5208 Train_Acc: 79.183 Val_Loss: 0.3417  BEST VAL Loss: 0.3417  Val_Acc: 94.539

Epoch 7: Validation loss decreased (0.341678 --> 0.331657).  Saving model ...
	 Train_Loss: 0.5114 Train_Acc: 80.294 Val_Loss: 0.3317  BEST VAL Loss: 0.3317  Val_Acc: 94.369

Epoch 8: Validation loss decreased (0.331657 --> 0.324009).  Saving model ...
	 Train_Loss: 0.5040 Train_Acc: 80.040 Val_Loss: 0.3240  BEST VAL Loss: 0.3240  Val_Acc: 94.962

Epoch 9: Validation loss decreased (0.324009 --> 0.316341).  Saving model ...
	 Train_Loss: 0.4980 Train_Acc: 80.252 Val_Loss: 0.3163  BEST VAL Loss: 0.3163  Val_Acc: 95.639

Epoch 10: Validation loss decreased (0.316341 --> 0.310849).  Saving model ...
	 Train_Loss: 0.4925 Train_Acc: 80.601 Val_Loss: 0.3108  BEST VAL Loss: 0.3108  Val_Acc: 95.047

Epoch 11: Validation loss decreased (0.310849 --> 0.305264).  Saving model ...
	 Train_Loss: 0.4882 Train_Acc: 80.469 Val_Loss: 0.3053  BEST VAL Loss: 0.3053  Val_Acc: 95.639

Epoch 12: Validation loss decreased (0.305264 --> 0.300280).  Saving model ...
	 Train_Loss: 0.4841 Train_Acc: 80.654 Val_Loss: 0.3003  BEST VAL Loss: 0.3003  Val_Acc: 95.428

Epoch 13: Validation loss decreased (0.300280 --> 0.296464).  Saving model ...
	 Train_Loss: 0.4810 Train_Acc: 80.469 Val_Loss: 0.2965  BEST VAL Loss: 0.2965  Val_Acc: 95.893

Epoch 14: Validation loss decreased (0.296464 --> 0.292744).  Saving model ...
	 Train_Loss: 0.4782 Train_Acc: 80.421 Val_Loss: 0.2927  BEST VAL Loss: 0.2927  Val_Acc: 96.147

Epoch 15: Validation loss decreased (0.292744 --> 0.289268).  Saving model ...
	 Train_Loss: 0.4755 Train_Acc: 80.797 Val_Loss: 0.2893  BEST VAL Loss: 0.2893  Val_Acc: 96.232

Epoch 16: Validation loss decreased (0.289268 --> 0.286449).  Saving model ...
	 Train_Loss: 0.4729 Train_Acc: 80.961 Val_Loss: 0.2864  BEST VAL Loss: 0.2864  Val_Acc: 96.105

Epoch 17: Validation loss decreased (0.286449 --> 0.283610).  Saving model ...
	 Train_Loss: 0.4701 Train_Acc: 81.427 Val_Loss: 0.2836  BEST VAL Loss: 0.2836  Val_Acc: 95.766

Epoch 18: Validation loss decreased (0.283610 --> 0.281096).  Saving model ...
	 Train_Loss: 0.4680 Train_Acc: 80.871 Val_Loss: 0.2811  BEST VAL Loss: 0.2811  Val_Acc: 96.274

Epoch 19: Validation loss decreased (0.281096 --> 0.278797).  Saving model ...
	 Train_Loss: 0.4659 Train_Acc: 81.364 Val_Loss: 0.2788  BEST VAL Loss: 0.2788  Val_Acc: 95.809

Epoch 20: Validation loss decreased (0.278797 --> 0.276584).  Saving model ...
	 Train_Loss: 0.4639 Train_Acc: 81.269 Val_Loss: 0.2766  BEST VAL Loss: 0.2766  Val_Acc: 96.105

Epoch 21: Validation loss decreased (0.276584 --> 0.275119).  Saving model ...
	 Train_Loss: 0.4623 Train_Acc: 81.083 Val_Loss: 0.2751  BEST VAL Loss: 0.2751  Val_Acc: 95.766

Epoch 22: Validation loss decreased (0.275119 --> 0.273359).  Saving model ...
	 Train_Loss: 0.4608 Train_Acc: 81.179 Val_Loss: 0.2734  BEST VAL Loss: 0.2734  Val_Acc: 96.274

Epoch 23: Validation loss decreased (0.273359 --> 0.271963).  Saving model ...
	 Train_Loss: 0.4593 Train_Acc: 81.226 Val_Loss: 0.2720  BEST VAL Loss: 0.2720  Val_Acc: 95.978

Epoch 24: Validation loss decreased (0.271963 --> 0.270185).  Saving model ...
	 Train_Loss: 0.4579 Train_Acc: 81.099 Val_Loss: 0.2702  BEST VAL Loss: 0.2702  Val_Acc: 96.613

Epoch 25: Validation loss decreased (0.270185 --> 0.268803).  Saving model ...
	 Train_Loss: 0.4568 Train_Acc: 81.369 Val_Loss: 0.2688  BEST VAL Loss: 0.2688  Val_Acc: 96.232

Epoch 26: Validation loss decreased (0.268803 --> 0.266982).  Saving model ...
	 Train_Loss: 0.4555 Train_Acc: 81.364 Val_Loss: 0.2670  BEST VAL Loss: 0.2670  Val_Acc: 96.359

Epoch 27: Validation loss decreased (0.266982 --> 0.265703).  Saving model ...
	 Train_Loss: 0.4544 Train_Acc: 81.194 Val_Loss: 0.2657  BEST VAL Loss: 0.2657  Val_Acc: 96.232

Epoch 28: Validation loss decreased (0.265703 --> 0.264791).  Saving model ...
	 Train_Loss: 0.4533 Train_Acc: 81.586 Val_Loss: 0.2648  BEST VAL Loss: 0.2648  Val_Acc: 95.978

Epoch 29: Validation loss decreased (0.264791 --> 0.263255).  Saving model ...
	 Train_Loss: 0.4524 Train_Acc: 81.157 Val_Loss: 0.2633  BEST VAL Loss: 0.2633  Val_Acc: 96.782

Epoch 30: Validation loss decreased (0.263255 --> 0.262235).  Saving model ...
	 Train_Loss: 0.4515 Train_Acc: 81.263 Val_Loss: 0.2622  BEST VAL Loss: 0.2622  Val_Acc: 96.359

Epoch 31: Validation loss decreased (0.262235 --> 0.261156).  Saving model ...
	 Train_Loss: 0.4505 Train_Acc: 81.687 Val_Loss: 0.2612  BEST VAL Loss: 0.2612  Val_Acc: 96.105

Epoch 32: Validation loss decreased (0.261156 --> 0.260157).  Saving model ...
	 Train_Loss: 0.4496 Train_Acc: 81.512 Val_Loss: 0.2602  BEST VAL Loss: 0.2602  Val_Acc: 96.401

Epoch 33: Validation loss decreased (0.260157 --> 0.259224).  Saving model ...
	 Train_Loss: 0.4488 Train_Acc: 81.327 Val_Loss: 0.2592  BEST VAL Loss: 0.2592  Val_Acc: 96.486

Epoch 34: Validation loss decreased (0.259224 --> 0.258356).  Saving model ...
	 Train_Loss: 0.4482 Train_Acc: 81.184 Val_Loss: 0.2584  BEST VAL Loss: 0.2584  Val_Acc: 96.147

Epoch 35: Validation loss decreased (0.258356 --> 0.257414).  Saving model ...
	 Train_Loss: 0.4475 Train_Acc: 81.332 Val_Loss: 0.2574  BEST VAL Loss: 0.2574  Val_Acc: 96.613

Epoch 36: Validation loss decreased (0.257414 --> 0.256673).  Saving model ...
	 Train_Loss: 0.4467 Train_Acc: 81.411 Val_Loss: 0.2567  BEST VAL Loss: 0.2567  Val_Acc: 96.317

Epoch 37: Validation loss decreased (0.256673 --> 0.255803).  Saving model ...
	 Train_Loss: 0.4459 Train_Acc: 81.893 Val_Loss: 0.2558  BEST VAL Loss: 0.2558  Val_Acc: 96.571

Epoch 38: Validation loss decreased (0.255803 --> 0.254891).  Saving model ...
	 Train_Loss: 0.4451 Train_Acc: 81.793 Val_Loss: 0.2549  BEST VAL Loss: 0.2549  Val_Acc: 96.063

Epoch 39: Validation loss decreased (0.254891 --> 0.254127).  Saving model ...
	 Train_Loss: 0.4444 Train_Acc: 81.655 Val_Loss: 0.2541  BEST VAL Loss: 0.2541  Val_Acc: 96.444

Epoch 40: Validation loss decreased (0.254127 --> 0.253419).  Saving model ...
	 Train_Loss: 0.4439 Train_Acc: 81.443 Val_Loss: 0.2534  BEST VAL Loss: 0.2534  Val_Acc: 96.232

Epoch 41: Validation loss decreased (0.253419 --> 0.252682).  Saving model ...
	 Train_Loss: 0.4432 Train_Acc: 81.771 Val_Loss: 0.2527  BEST VAL Loss: 0.2527  Val_Acc: 97.036

Epoch 42: Validation loss decreased (0.252682 --> 0.252131).  Saving model ...
	 Train_Loss: 0.4426 Train_Acc: 81.809 Val_Loss: 0.2521  BEST VAL Loss: 0.2521  Val_Acc: 97.079

Epoch 43: Validation loss decreased (0.252131 --> 0.251527).  Saving model ...
	 Train_Loss: 0.4420 Train_Acc: 81.771 Val_Loss: 0.2515  BEST VAL Loss: 0.2515  Val_Acc: 96.825

Epoch 44: Validation loss decreased (0.251527 --> 0.251081).  Saving model ...
	 Train_Loss: 0.4414 Train_Acc: 81.766 Val_Loss: 0.2511  BEST VAL Loss: 0.2511  Val_Acc: 96.655

Epoch 45: Validation loss decreased (0.251081 --> 0.250391).  Saving model ...
	 Train_Loss: 0.4407 Train_Acc: 82.063 Val_Loss: 0.2504  BEST VAL Loss: 0.2504  Val_Acc: 97.036

Epoch 46: Validation loss decreased (0.250391 --> 0.250029).  Saving model ...
	 Train_Loss: 0.4402 Train_Acc: 81.756 Val_Loss: 0.2500  BEST VAL Loss: 0.2500  Val_Acc: 96.867

Epoch 47: Validation loss decreased (0.250029 --> 0.249480).  Saving model ...
	 Train_Loss: 0.4397 Train_Acc: 81.809 Val_Loss: 0.2495  BEST VAL Loss: 0.2495  Val_Acc: 96.952

Epoch 48: Validation loss decreased (0.249480 --> 0.248913).  Saving model ...
	 Train_Loss: 0.4393 Train_Acc: 81.353 Val_Loss: 0.2489  BEST VAL Loss: 0.2489  Val_Acc: 96.571

Epoch 49: Validation loss decreased (0.248913 --> 0.248187).  Saving model ...
	 Train_Loss: 0.4388 Train_Acc: 81.893 Val_Loss: 0.2482  BEST VAL Loss: 0.2482  Val_Acc: 96.994

Epoch 50: Validation loss decreased (0.248187 --> 0.247796).  Saving model ...
	 Train_Loss: 0.4385 Train_Acc: 81.406 Val_Loss: 0.2478  BEST VAL Loss: 0.2478  Val_Acc: 96.655

Epoch 51: Validation loss decreased (0.247796 --> 0.247405).  Saving model ...
	 Train_Loss: 0.4381 Train_Acc: 81.539 Val_Loss: 0.2474  BEST VAL Loss: 0.2474  Val_Acc: 96.782

Epoch 52: Validation loss decreased (0.247405 --> 0.247036).  Saving model ...
	 Train_Loss: 0.4378 Train_Acc: 81.411 Val_Loss: 0.2470  BEST VAL Loss: 0.2470  Val_Acc: 96.613

Epoch 53: Validation loss decreased (0.247036 --> 0.246702).  Saving model ...
	 Train_Loss: 0.4374 Train_Acc: 81.771 Val_Loss: 0.2467  BEST VAL Loss: 0.2467  Val_Acc: 96.698

Epoch 54: Validation loss decreased (0.246702 --> 0.246175).  Saving model ...
	 Train_Loss: 0.4370 Train_Acc: 82.047 Val_Loss: 0.2462  BEST VAL Loss: 0.2462  Val_Acc: 96.698

Epoch 55: Validation loss decreased (0.246175 --> 0.245905).  Saving model ...
	 Train_Loss: 0.4365 Train_Acc: 82.163 Val_Loss: 0.2459  BEST VAL Loss: 0.2459  Val_Acc: 96.655

Epoch 56: Validation loss decreased (0.245905 --> 0.245565).  Saving model ...
	 Train_Loss: 0.4361 Train_Acc: 81.925 Val_Loss: 0.2456  BEST VAL Loss: 0.2456  Val_Acc: 96.994

Epoch 57: Validation loss decreased (0.245565 --> 0.245176).  Saving model ...
	 Train_Loss: 0.4357 Train_Acc: 81.904 Val_Loss: 0.2452  BEST VAL Loss: 0.2452  Val_Acc: 96.698

Epoch 58: Validation loss decreased (0.245176 --> 0.244879).  Saving model ...
	 Train_Loss: 0.4354 Train_Acc: 81.369 Val_Loss: 0.2449  BEST VAL Loss: 0.2449  Val_Acc: 95.978

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.4352 Train_Acc: 81.385 Val_Loss: 0.2450  BEST VAL Loss: 0.2449  Val_Acc: 96.105

Epoch 60: Validation loss decreased (0.244879 --> 0.244826).  Saving model ...
	 Train_Loss: 0.4349 Train_Acc: 81.824 Val_Loss: 0.2448  BEST VAL Loss: 0.2448  Val_Acc: 96.486

Epoch 61: Validation loss decreased (0.244826 --> 0.244596).  Saving model ...
	 Train_Loss: 0.4347 Train_Acc: 81.433 Val_Loss: 0.2446  BEST VAL Loss: 0.2446  Val_Acc: 96.359

Epoch 62: Validation loss decreased (0.244596 --> 0.244385).  Saving model ...
	 Train_Loss: 0.4345 Train_Acc: 81.433 Val_Loss: 0.2444  BEST VAL Loss: 0.2444  Val_Acc: 96.782

Epoch 63: Validation loss decreased (0.244385 --> 0.244075).  Saving model ...
	 Train_Loss: 0.4342 Train_Acc: 82.010 Val_Loss: 0.2441  BEST VAL Loss: 0.2441  Val_Acc: 96.401

Epoch 64: Validation loss decreased (0.244075 --> 0.243776).  Saving model ...
	 Train_Loss: 0.4339 Train_Acc: 81.750 Val_Loss: 0.2438  BEST VAL Loss: 0.2438  Val_Acc: 96.655

Epoch 65: Validation loss decreased (0.243776 --> 0.243559).  Saving model ...
	 Train_Loss: 0.4335 Train_Acc: 82.036 Val_Loss: 0.2436  BEST VAL Loss: 0.2436  Val_Acc: 96.698

Epoch 66: Validation loss decreased (0.243559 --> 0.243357).  Saving model ...
	 Train_Loss: 0.4332 Train_Acc: 82.153 Val_Loss: 0.2434  BEST VAL Loss: 0.2434  Val_Acc: 96.613

Epoch 67: Validation loss decreased (0.243357 --> 0.243131).  Saving model ...
	 Train_Loss: 0.4329 Train_Acc: 81.554 Val_Loss: 0.2431  BEST VAL Loss: 0.2431  Val_Acc: 96.571

Epoch 68: Validation loss decreased (0.243131 --> 0.242766).  Saving model ...
	 Train_Loss: 0.4328 Train_Acc: 81.411 Val_Loss: 0.2428  BEST VAL Loss: 0.2428  Val_Acc: 97.121

Epoch 69: Validation loss decreased (0.242766 --> 0.242468).  Saving model ...
	 Train_Loss: 0.4325 Train_Acc: 82.004 Val_Loss: 0.2425  BEST VAL Loss: 0.2425  Val_Acc: 97.248

Epoch 70: Validation loss decreased (0.242468 --> 0.242280).  Saving model ...
	 Train_Loss: 0.4322 Train_Acc: 81.793 Val_Loss: 0.2423  BEST VAL Loss: 0.2423  Val_Acc: 97.248

Epoch 71: Validation loss decreased (0.242280 --> 0.242032).  Saving model ...
	 Train_Loss: 0.4320 Train_Acc: 81.676 Val_Loss: 0.2420  BEST VAL Loss: 0.2420  Val_Acc: 97.333

Epoch 72: Validation loss decreased (0.242032 --> 0.241699).  Saving model ...
	 Train_Loss: 0.4318 Train_Acc: 81.581 Val_Loss: 0.2417  BEST VAL Loss: 0.2417  Val_Acc: 96.909

Epoch 73: Validation loss decreased (0.241699 --> 0.241554).  Saving model ...
	 Train_Loss: 0.4316 Train_Acc: 81.634 Val_Loss: 0.2416  BEST VAL Loss: 0.2416  Val_Acc: 96.909

Epoch 74: Validation loss decreased (0.241554 --> 0.241461).  Saving model ...
	 Train_Loss: 0.4314 Train_Acc: 81.835 Val_Loss: 0.2415  BEST VAL Loss: 0.2415  Val_Acc: 96.994

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.4312 Train_Acc: 81.756 Val_Loss: 0.2416  BEST VAL Loss: 0.2415  Val_Acc: 96.528

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.4310 Train_Acc: 81.703 Val_Loss: 0.2417  BEST VAL Loss: 0.2415  Val_Acc: 96.867

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.4309 Train_Acc: 81.443 Val_Loss: 0.2416  BEST VAL Loss: 0.2415  Val_Acc: 96.528

Epoch 78: Validation loss decreased (0.241461 --> 0.241373).  Saving model ...
	 Train_Loss: 0.4307 Train_Acc: 81.629 Val_Loss: 0.2414  BEST VAL Loss: 0.2414  Val_Acc: 96.655

Epoch 79: Validation loss decreased (0.241373 --> 0.241304).  Saving model ...
	 Train_Loss: 0.4305 Train_Acc: 81.824 Val_Loss: 0.2413  BEST VAL Loss: 0.2413  Val_Acc: 96.740

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.4304 Train_Acc: 81.586 Val_Loss: 0.2413  BEST VAL Loss: 0.2413  Val_Acc: 96.867

Epoch 81: Validation loss decreased (0.241304 --> 0.241074).  Saving model ...
	 Train_Loss: 0.4302 Train_Acc: 81.914 Val_Loss: 0.2411  BEST VAL Loss: 0.2411  Val_Acc: 97.036

Epoch 82: Validation loss decreased (0.241074 --> 0.240780).  Saving model ...
	 Train_Loss: 0.4300 Train_Acc: 81.893 Val_Loss: 0.2408  BEST VAL Loss: 0.2408  Val_Acc: 97.079

Epoch 83: Validation loss decreased (0.240780 --> 0.240690).  Saving model ...
	 Train_Loss: 0.4298 Train_Acc: 81.793 Val_Loss: 0.2407  BEST VAL Loss: 0.2407  Val_Acc: 96.867

Epoch 84: Validation loss decreased (0.240690 --> 0.240425).  Saving model ...
	 Train_Loss: 0.4295 Train_Acc: 82.147 Val_Loss: 0.2404  BEST VAL Loss: 0.2404  Val_Acc: 96.952

Epoch 85: Validation loss decreased (0.240425 --> 0.240248).  Saving model ...
	 Train_Loss: 0.4294 Train_Acc: 81.787 Val_Loss: 0.2402  BEST VAL Loss: 0.2402  Val_Acc: 97.206

Epoch 86: Validation loss decreased (0.240248 --> 0.240127).  Saving model ...
	 Train_Loss: 0.4292 Train_Acc: 81.952 Val_Loss: 0.2401  BEST VAL Loss: 0.2401  Val_Acc: 97.079

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.4290 Train_Acc: 81.454 Val_Loss: 0.2403  BEST VAL Loss: 0.2401  Val_Acc: 96.952

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.4289 Train_Acc: 81.777 Val_Loss: 0.2402  BEST VAL Loss: 0.2401  Val_Acc: 96.613

Epoch 89: Validation loss decreased (0.240127 --> 0.239923).  Saving model ...
	 Train_Loss: 0.4287 Train_Acc: 81.967 Val_Loss: 0.2399  BEST VAL Loss: 0.2399  Val_Acc: 96.782

Epoch 90: Validation loss decreased (0.239923 --> 0.239841).  Saving model ...
	 Train_Loss: 0.4285 Train_Acc: 82.079 Val_Loss: 0.2398  BEST VAL Loss: 0.2398  Val_Acc: 97.121

Epoch 91: Validation loss decreased (0.239841 --> 0.239711).  Saving model ...
	 Train_Loss: 0.4283 Train_Acc: 82.417 Val_Loss: 0.2397  BEST VAL Loss: 0.2397  Val_Acc: 97.036

Epoch 92: Validation loss decreased (0.239711 --> 0.239618).  Saving model ...
	 Train_Loss: 0.4281 Train_Acc: 81.660 Val_Loss: 0.2396  BEST VAL Loss: 0.2396  Val_Acc: 96.909

Epoch 93: Validation loss decreased (0.239618 --> 0.239423).  Saving model ...
	 Train_Loss: 0.4280 Train_Acc: 81.962 Val_Loss: 0.2394  BEST VAL Loss: 0.2394  Val_Acc: 97.163

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.4278 Train_Acc: 81.914 Val_Loss: 0.2394  BEST VAL Loss: 0.2394  Val_Acc: 96.909

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.4277 Train_Acc: 81.666 Val_Loss: 0.2394  BEST VAL Loss: 0.2394  Val_Acc: 96.952

Epoch 96: Validation loss decreased (0.239423 --> 0.239410).  Saving model ...
	 Train_Loss: 0.4275 Train_Acc: 82.306 Val_Loss: 0.2394  BEST VAL Loss: 0.2394  Val_Acc: 96.867

Epoch 97: Validation loss decreased (0.239410 --> 0.239334).  Saving model ...
	 Train_Loss: 0.4272 Train_Acc: 82.555 Val_Loss: 0.2393  BEST VAL Loss: 0.2393  Val_Acc: 96.613

Epoch 98: Validation loss decreased (0.239334 --> 0.239311).  Saving model ...
	 Train_Loss: 0.4271 Train_Acc: 81.777 Val_Loss: 0.2393  BEST VAL Loss: 0.2393  Val_Acc: 96.232

Epoch 99: Validation loss decreased (0.239311 --> 0.239206).  Saving model ...
	 Train_Loss: 0.4269 Train_Acc: 82.100 Val_Loss: 0.2392  BEST VAL Loss: 0.2392  Val_Acc: 96.444

LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      1.00      1.00     10452
           1       1.00      0.99      0.99      8436

    accuracy                           1.00     18888
   macro avg       1.00      1.00      1.00     18888
weighted avg       1.00      1.00      1.00     18888

LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.96      0.97      0.97      1307
           1       0.97      0.95      0.96      1055

    accuracy                           0.96      2362
   macro avg       0.96      0.96      0.96      2362
weighted avg       0.96      0.96      0.96      2362

LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.98      0.97      1306
           1       0.98      0.96      0.97      1055

    accuracy                           0.97      2361
   macro avg       0.97      0.97      0.97      2361
weighted avg       0.97      0.97      0.97      2361

              precision    recall  f1-score   support

           0       0.97      0.98      0.97      1306
           1       0.98      0.96      0.97      1055

    accuracy                           0.97      2361
   macro avg       0.97      0.97      0.97      2361
weighted avg       0.97      0.97      0.97      2361

LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.95      0.99      0.97      4445
           1       0.99      0.94      0.96      3856

    accuracy                           0.97      8301
   macro avg       0.97      0.97      0.97      8301
weighted avg       0.97      0.97      0.97      8301

              precision    recall  f1-score   support

           0       0.95      0.99      0.97      4445
           1       0.99      0.94      0.96      3856

    accuracy                           0.97      8301
   macro avg       0.97      0.97      0.97      8301
weighted avg       0.97      0.97      0.97      8301

completed
