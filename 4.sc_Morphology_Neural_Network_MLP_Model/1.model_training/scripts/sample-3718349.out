[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 18688 bytes to train_binary_model.py
[NbConvertApp] Converting notebook ../notebooks/train_multiclass_model.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: MissingIDFieldWarning: Code cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.
  validate(nb)
[NbConvertApp] Writing 31106 bytes to train_multiclass_model.py
[NbConvertApp] Converting notebook ../notebooks/train_regression_model.ipynb to script
[NbConvertApp] Writing 25120 bytes to train_regression_model.py
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:313: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels.drop_duplicates(inplace=True)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1015: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1016: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1015: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1016: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1036: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:577: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:651: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1219: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:879: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1219: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:1095: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
PBMC MultiClass_MLP True
[0.9436581681188537, 0.5245113046249099, 0.5318305272562364]
Data Subset Is Off
(1483474,) (370869,) (2207496,) (1536843,)
(1483474,) (370869,) (2207496,) (1536843,)
5598682
(95928,) (749319,) (638227,)
(23982,) (187329,) (159558,)
(119911,) (936644,) (1150941,)
(75619,) (788818,) (672406,)
(1483474, 1245) (370869, 1245) (2207496, 1245) (1536843, 1245)
(1483474,) (370869,) (2207496,) (1536843,)
Number of in features:  1245
Number of out features:  3
Multi_Class
Adam
Epoch 0: Validation loss decreased (inf --> 0.770437).  Saving model ...
	 Train_Loss: 0.8281 Train_Acc: 65.793 Val_Loss: 0.7704  BEST VAL Loss: 0.7704  Val_Acc: 68.258

Epoch 1: Validation loss decreased (0.770437 --> 0.760154).  Saving model ...
	 Train_Loss: 0.8147 Train_Acc: 67.490 Val_Loss: 0.7602  BEST VAL Loss: 0.7602  Val_Acc: 68.915

Epoch 2: Validation loss decreased (0.760154 --> 0.740454).  Saving model ...
	 Train_Loss: 0.8038 Train_Acc: 68.635 Val_Loss: 0.7405  BEST VAL Loss: 0.7405  Val_Acc: 71.614

Epoch 3: Validation loss decreased (0.740454 --> 0.733211).  Saving model ...
	 Train_Loss: 0.7919 Train_Acc: 69.546 Val_Loss: 0.7332  BEST VAL Loss: 0.7332  Val_Acc: 71.482

Epoch 4: Validation loss decreased (0.733211 --> 0.722077).  Saving model ...
	 Train_Loss: 0.7829 Train_Acc: 70.241 Val_Loss: 0.7221  BEST VAL Loss: 0.7221  Val_Acc: 73.079

Epoch 5: Validation loss decreased (0.722077 --> 0.711701).  Saving model ...
	 Train_Loss: 0.7760 Train_Acc: 70.567 Val_Loss: 0.7117  BEST VAL Loss: 0.7117  Val_Acc: 73.926

Epoch 6: Validation loss decreased (0.711701 --> 0.708637).  Saving model ...
	 Train_Loss: 0.7696 Train_Acc: 71.009 Val_Loss: 0.7086  BEST VAL Loss: 0.7086  Val_Acc: 72.083

Epoch 7: Validation loss decreased (0.708637 --> 0.705666).  Saving model ...
	 Train_Loss: 0.7643 Train_Acc: 71.335 Val_Loss: 0.7057  BEST VAL Loss: 0.7057  Val_Acc: 75.240

Epoch 8: Validation loss decreased (0.705666 --> 0.701952).  Saving model ...
	 Train_Loss: 0.7623 Train_Acc: 71.470 Val_Loss: 0.7020  BEST VAL Loss: 0.7020  Val_Acc: 75.168

Epoch 9: Validation loss decreased (0.701952 --> 0.700030).  Saving model ...
	 Train_Loss: 0.7604 Train_Acc: 71.635 Val_Loss: 0.7000  BEST VAL Loss: 0.7000  Val_Acc: 75.137

Epoch 10: Validation loss decreased (0.700030 --> 0.697102).  Saving model ...
	 Train_Loss: 0.7586 Train_Acc: 71.823 Val_Loss: 0.6971  BEST VAL Loss: 0.6971  Val_Acc: 75.575

Epoch 11: Validation loss decreased (0.697102 --> 0.695397).  Saving model ...
	 Train_Loss: 0.7569 Train_Acc: 71.891 Val_Loss: 0.6954  BEST VAL Loss: 0.6954  Val_Acc: 75.763

Epoch 12: Validation loss decreased (0.695397 --> 0.693302).  Saving model ...
	 Train_Loss: 0.7552 Train_Acc: 72.018 Val_Loss: 0.6933  BEST VAL Loss: 0.6933  Val_Acc: 75.753

Epoch 13: Validation loss decreased (0.693302 --> 0.691497).  Saving model ...
	 Train_Loss: 0.7536 Train_Acc: 72.107 Val_Loss: 0.6915  BEST VAL Loss: 0.6915  Val_Acc: 76.189

Epoch 14: Validation loss decreased (0.691497 --> 0.689639).  Saving model ...
	 Train_Loss: 0.7522 Train_Acc: 72.203 Val_Loss: 0.6896  BEST VAL Loss: 0.6896  Val_Acc: 75.630

Epoch 15: Validation loss decreased (0.689639 --> 0.687798).  Saving model ...
	 Train_Loss: 0.7508 Train_Acc: 72.254 Val_Loss: 0.6878  BEST VAL Loss: 0.6878  Val_Acc: 76.115

Epoch 16: Validation loss decreased (0.687798 --> 0.685956).  Saving model ...
	 Train_Loss: 0.7496 Train_Acc: 72.316 Val_Loss: 0.6860  BEST VAL Loss: 0.6860  Val_Acc: 76.293

Epoch 17: Validation loss decreased (0.685956 --> 0.685867).  Saving model ...
	 Train_Loss: 0.7483 Train_Acc: 72.347 Val_Loss: 0.6859  BEST VAL Loss: 0.6859  Val_Acc: 75.306

Epoch 18: Validation loss decreased (0.685867 --> 0.684146).  Saving model ...
	 Train_Loss: 0.7471 Train_Acc: 72.475 Val_Loss: 0.6841  BEST VAL Loss: 0.6841  Val_Acc: 76.429

Epoch 19: Validation loss decreased (0.684146 --> 0.682571).  Saving model ...
	 Train_Loss: 0.7460 Train_Acc: 72.560 Val_Loss: 0.6826  BEST VAL Loss: 0.6826  Val_Acc: 75.785

Epoch 20: Validation loss decreased (0.682571 --> 0.681303).  Saving model ...
	 Train_Loss: 0.7449 Train_Acc: 72.577 Val_Loss: 0.6813  BEST VAL Loss: 0.6813  Val_Acc: 76.251

Epoch 21: Validation loss decreased (0.681303 --> 0.680136).  Saving model ...
	 Train_Loss: 0.7439 Train_Acc: 72.650 Val_Loss: 0.6801  BEST VAL Loss: 0.6801  Val_Acc: 76.668

Epoch 22: Validation loss decreased (0.680136 --> 0.679465).  Saving model ...
	 Train_Loss: 0.7428 Train_Acc: 72.751 Val_Loss: 0.6795  BEST VAL Loss: 0.6795  Val_Acc: 74.389

Epoch 23: Validation loss decreased (0.679465 --> 0.677711).  Saving model ...
	 Train_Loss: 0.7419 Train_Acc: 72.738 Val_Loss: 0.6777  BEST VAL Loss: 0.6777  Val_Acc: 77.135

Epoch 24: Validation loss decreased (0.677711 --> 0.677100).  Saving model ...
	 Train_Loss: 0.7410 Train_Acc: 72.705 Val_Loss: 0.6771  BEST VAL Loss: 0.6771  Val_Acc: 76.151

Epoch 25: Validation loss decreased (0.677100 --> 0.675829).  Saving model ...
	 Train_Loss: 0.7402 Train_Acc: 72.830 Val_Loss: 0.6758  BEST VAL Loss: 0.6758  Val_Acc: 76.541

Epoch 26: Validation loss decreased (0.675829 --> 0.674657).  Saving model ...
	 Train_Loss: 0.7394 Train_Acc: 72.909 Val_Loss: 0.6747  BEST VAL Loss: 0.6747  Val_Acc: 77.074

Epoch 27: Validation loss decreased (0.674657 --> 0.673222).  Saving model ...
	 Train_Loss: 0.7385 Train_Acc: 72.926 Val_Loss: 0.6732  BEST VAL Loss: 0.6732  Val_Acc: 77.101

Epoch 28: Validation loss decreased (0.673222 --> 0.672011).  Saving model ...
	 Train_Loss: 0.7378 Train_Acc: 72.942 Val_Loss: 0.6720  BEST VAL Loss: 0.6720  Val_Acc: 77.185

Epoch 29: Validation loss decreased (0.672011 --> 0.671005).  Saving model ...
	 Train_Loss: 0.7371 Train_Acc: 72.972 Val_Loss: 0.6710  BEST VAL Loss: 0.6710  Val_Acc: 76.963

Epoch 30: Validation loss decreased (0.671005 --> 0.670002).  Saving model ...
	 Train_Loss: 0.7364 Train_Acc: 73.026 Val_Loss: 0.6700  BEST VAL Loss: 0.6700  Val_Acc: 77.177

Epoch 31: Validation loss decreased (0.670002 --> 0.669650).  Saving model ...
	 Train_Loss: 0.7356 Train_Acc: 73.068 Val_Loss: 0.6697  BEST VAL Loss: 0.6697  Val_Acc: 76.356

Epoch 32: Validation loss decreased (0.669650 --> 0.668990).  Saving model ...
	 Train_Loss: 0.7350 Train_Acc: 73.060 Val_Loss: 0.6690  BEST VAL Loss: 0.6690  Val_Acc: 75.089

Epoch 33: Validation loss decreased (0.668990 --> 0.668416).  Saving model ...
	 Train_Loss: 0.7343 Train_Acc: 73.140 Val_Loss: 0.6684  BEST VAL Loss: 0.6684  Val_Acc: 76.867

Epoch 34: Validation loss decreased (0.668416 --> 0.667183).  Saving model ...
	 Train_Loss: 0.7337 Train_Acc: 73.163 Val_Loss: 0.6672  BEST VAL Loss: 0.6672  Val_Acc: 77.633

Epoch 35: Validation loss decreased (0.667183 --> 0.667049).  Saving model ...
	 Train_Loss: 0.7331 Train_Acc: 73.082 Val_Loss: 0.6670  BEST VAL Loss: 0.6670  Val_Acc: 76.225

Epoch 36: Validation loss decreased (0.667049 --> 0.666643).  Saving model ...
	 Train_Loss: 0.7325 Train_Acc: 73.169 Val_Loss: 0.6666  BEST VAL Loss: 0.6666  Val_Acc: 76.133

Epoch 37: Validation loss decreased (0.666643 --> 0.666137).  Saving model ...
	 Train_Loss: 0.7320 Train_Acc: 73.219 Val_Loss: 0.6661  BEST VAL Loss: 0.6661  Val_Acc: 75.056

Epoch 38: Validation loss decreased (0.666137 --> 0.665399).  Saving model ...
	 Train_Loss: 0.7314 Train_Acc: 73.205 Val_Loss: 0.6654  BEST VAL Loss: 0.6654  Val_Acc: 76.236

Epoch 39: Validation loss decreased (0.665399 --> 0.665083).  Saving model ...
	 Train_Loss: 0.7309 Train_Acc: 73.217 Val_Loss: 0.6651  BEST VAL Loss: 0.6651  Val_Acc: 76.361

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.7304 Train_Acc: 73.273 Val_Loss: 0.6651  BEST VAL Loss: 0.6651  Val_Acc: 76.077

Epoch 41: Validation loss decreased (0.665083 --> 0.664712).  Saving model ...
	 Train_Loss: 0.7299 Train_Acc: 73.213 Val_Loss: 0.6647  BEST VAL Loss: 0.6647  Val_Acc: 76.840

Epoch 42: Validation loss decreased (0.664712 --> 0.663953).  Saving model ...
	 Train_Loss: 0.7294 Train_Acc: 73.235 Val_Loss: 0.6640  BEST VAL Loss: 0.6640  Val_Acc: 77.219

Epoch 43: Validation loss decreased (0.663953 --> 0.663275).  Saving model ...
	 Train_Loss: 0.7289 Train_Acc: 73.320 Val_Loss: 0.6633  BEST VAL Loss: 0.6633  Val_Acc: 77.249

Epoch 44: Validation loss decreased (0.663275 --> 0.662920).  Saving model ...
	 Train_Loss: 0.7285 Train_Acc: 73.261 Val_Loss: 0.6629  BEST VAL Loss: 0.6629  Val_Acc: 75.612

Epoch 45: Validation loss decreased (0.662920 --> 0.662558).  Saving model ...
	 Train_Loss: 0.7280 Train_Acc: 73.421 Val_Loss: 0.6626  BEST VAL Loss: 0.6626  Val_Acc: 75.103

Epoch 46: Validation loss decreased (0.662558 --> 0.662353).  Saving model ...
	 Train_Loss: 0.7276 Train_Acc: 73.308 Val_Loss: 0.6624  BEST VAL Loss: 0.6624  Val_Acc: 74.549

Epoch 47: Validation loss decreased (0.662353 --> 0.661808).  Saving model ...
	 Train_Loss: 0.7272 Train_Acc: 73.407 Val_Loss: 0.6618  BEST VAL Loss: 0.6618  Val_Acc: 77.327

Epoch 48: Validation loss decreased (0.661808 --> 0.661236).  Saving model ...
	 Train_Loss: 0.7268 Train_Acc: 73.364 Val_Loss: 0.6612  BEST VAL Loss: 0.6612  Val_Acc: 77.394

Epoch 49: Validation loss decreased (0.661236 --> 0.660827).  Saving model ...
	 Train_Loss: 0.7264 Train_Acc: 73.439 Val_Loss: 0.6608  BEST VAL Loss: 0.6608  Val_Acc: 74.646

Epoch 50: Validation loss decreased (0.660827 --> 0.660402).  Saving model ...
	 Train_Loss: 0.7260 Train_Acc: 73.375 Val_Loss: 0.6604  BEST VAL Loss: 0.6604  Val_Acc: 77.271

Epoch 51: Validation loss decreased (0.660402 --> 0.659660).  Saving model ...
	 Train_Loss: 0.7256 Train_Acc: 73.489 Val_Loss: 0.6597  BEST VAL Loss: 0.6597  Val_Acc: 77.372

Epoch 52: Validation loss decreased (0.659660 --> 0.659195).  Saving model ...
	 Train_Loss: 0.7252 Train_Acc: 73.423 Val_Loss: 0.6592  BEST VAL Loss: 0.6592  Val_Acc: 77.553

Epoch 53: Validation loss decreased (0.659195 --> 0.658501).  Saving model ...
	 Train_Loss: 0.7249 Train_Acc: 73.356 Val_Loss: 0.6585  BEST VAL Loss: 0.6585  Val_Acc: 77.930

Epoch 54: Validation loss decreased (0.658501 --> 0.658021).  Saving model ...
	 Train_Loss: 0.7245 Train_Acc: 73.451 Val_Loss: 0.6580  BEST VAL Loss: 0.6580  Val_Acc: 77.599

Epoch 55: Validation loss decreased (0.658021 --> 0.657499).  Saving model ...
	 Train_Loss: 0.7242 Train_Acc: 73.471 Val_Loss: 0.6575  BEST VAL Loss: 0.6575  Val_Acc: 77.475

Epoch 56: Validation loss decreased (0.657499 --> 0.657173).  Saving model ...
	 Train_Loss: 0.7239 Train_Acc: 73.463 Val_Loss: 0.6572  BEST VAL Loss: 0.6572  Val_Acc: 77.545

Epoch 57: Validation loss decreased (0.657173 --> 0.657100).  Saving model ...
	 Train_Loss: 0.7235 Train_Acc: 73.567 Val_Loss: 0.6571  BEST VAL Loss: 0.6571  Val_Acc: 76.283

Epoch 58: Validation loss decreased (0.657100 --> 0.656660).  Saving model ...
	 Train_Loss: 0.7232 Train_Acc: 73.579 Val_Loss: 0.6567  BEST VAL Loss: 0.6567  Val_Acc: 77.762

Epoch 59: Validation loss decreased (0.656660 --> 0.656213).  Saving model ...
	 Train_Loss: 0.7229 Train_Acc: 73.525 Val_Loss: 0.6562  BEST VAL Loss: 0.6562  Val_Acc: 77.956

Epoch 60: Validation loss decreased (0.656213 --> 0.655911).  Saving model ...
	 Train_Loss: 0.7225 Train_Acc: 73.611 Val_Loss: 0.6559  BEST VAL Loss: 0.6559  Val_Acc: 75.163

Epoch 61: Validation loss decreased (0.655911 --> 0.655483).  Saving model ...
	 Train_Loss: 0.7222 Train_Acc: 73.479 Val_Loss: 0.6555  BEST VAL Loss: 0.6555  Val_Acc: 77.802

Epoch 62: Validation loss decreased (0.655483 --> 0.654995).  Saving model ...
	 Train_Loss: 0.7220 Train_Acc: 73.558 Val_Loss: 0.6550  BEST VAL Loss: 0.6550  Val_Acc: 77.910

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.7217 Train_Acc: 73.596 Val_Loss: 0.6550  BEST VAL Loss: 0.6550  Val_Acc: 76.220

Epoch 64: Validation loss decreased (0.654995 --> 0.654725).  Saving model ...
	 Train_Loss: 0.7214 Train_Acc: 73.626 Val_Loss: 0.6547  BEST VAL Loss: 0.6547  Val_Acc: 77.497

Epoch 65: Validation loss decreased (0.654725 --> 0.654509).  Saving model ...
	 Train_Loss: 0.7211 Train_Acc: 73.646 Val_Loss: 0.6545  BEST VAL Loss: 0.6545  Val_Acc: 77.695

Epoch 66: Validation loss decreased (0.654509 --> 0.654174).  Saving model ...
	 Train_Loss: 0.7208 Train_Acc: 73.578 Val_Loss: 0.6542  BEST VAL Loss: 0.6542  Val_Acc: 77.915

Epoch 67: Validation loss decreased (0.654174 --> 0.654100).  Saving model ...
	 Train_Loss: 0.7205 Train_Acc: 73.660 Val_Loss: 0.6541  BEST VAL Loss: 0.6541  Val_Acc: 76.545

Epoch 68: Validation loss decreased (0.654100 --> 0.653762).  Saving model ...
	 Train_Loss: 0.7203 Train_Acc: 73.659 Val_Loss: 0.6538  BEST VAL Loss: 0.6538  Val_Acc: 78.035

Epoch 69: Validation loss decreased (0.653762 --> 0.653232).  Saving model ...
	 Train_Loss: 0.7200 Train_Acc: 73.707 Val_Loss: 0.6532  BEST VAL Loss: 0.6532  Val_Acc: 77.811

Epoch 70: Validation loss decreased (0.653232 --> 0.652880).  Saving model ...
	 Train_Loss: 0.7197 Train_Acc: 73.628 Val_Loss: 0.6529  BEST VAL Loss: 0.6529  Val_Acc: 77.483

Epoch 71: Validation loss decreased (0.652880 --> 0.652665).  Saving model ...
	 Train_Loss: 0.7194 Train_Acc: 73.670 Val_Loss: 0.6527  BEST VAL Loss: 0.6527  Val_Acc: 75.578

Epoch 72: Validation loss decreased (0.652665 --> 0.652358).  Saving model ...
	 Train_Loss: 0.7192 Train_Acc: 73.782 Val_Loss: 0.6524  BEST VAL Loss: 0.6524  Val_Acc: 77.722

Epoch 73: Validation loss decreased (0.652358 --> 0.651880).  Saving model ...
	 Train_Loss: 0.7189 Train_Acc: 73.708 Val_Loss: 0.6519  BEST VAL Loss: 0.6519  Val_Acc: 77.650

Epoch 74: Validation loss decreased (0.651880 --> 0.651597).  Saving model ...
	 Train_Loss: 0.7187 Train_Acc: 73.755 Val_Loss: 0.6516  BEST VAL Loss: 0.6516  Val_Acc: 77.832

Epoch 75: Validation loss decreased (0.651597 --> 0.651265).  Saving model ...
	 Train_Loss: 0.7184 Train_Acc: 73.765 Val_Loss: 0.6513  BEST VAL Loss: 0.6513  Val_Acc: 77.984

Epoch 76: Validation loss decreased (0.651265 --> 0.651035).  Saving model ...
	 Train_Loss: 0.7182 Train_Acc: 73.742 Val_Loss: 0.6510  BEST VAL Loss: 0.6510  Val_Acc: 77.871

Epoch 77: Validation loss decreased (0.651035 --> 0.650656).  Saving model ...
	 Train_Loss: 0.7180 Train_Acc: 73.721 Val_Loss: 0.6507  BEST VAL Loss: 0.6507  Val_Acc: 78.329

Epoch 78: Validation loss decreased (0.650656 --> 0.650419).  Saving model ...
	 Train_Loss: 0.7177 Train_Acc: 73.809 Val_Loss: 0.6504  BEST VAL Loss: 0.6504  Val_Acc: 77.718

Epoch 79: Validation loss decreased (0.650419 --> 0.650358).  Saving model ...
	 Train_Loss: 0.7175 Train_Acc: 73.743 Val_Loss: 0.6504  BEST VAL Loss: 0.6504  Val_Acc: 75.000

Epoch 80: Validation loss decreased (0.650358 --> 0.650142).  Saving model ...
	 Train_Loss: 0.7173 Train_Acc: 73.719 Val_Loss: 0.6501  BEST VAL Loss: 0.6501  Val_Acc: 75.145

Epoch 81: Validation loss decreased (0.650142 --> 0.649910).  Saving model ...
	 Train_Loss: 0.7171 Train_Acc: 73.729 Val_Loss: 0.6499  BEST VAL Loss: 0.6499  Val_Acc: 77.698

Epoch 82: Validation loss decreased (0.649910 --> 0.649616).  Saving model ...
	 Train_Loss: 0.7169 Train_Acc: 73.739 Val_Loss: 0.6496  BEST VAL Loss: 0.6496  Val_Acc: 75.385

Epoch 83: Validation loss decreased (0.649616 --> 0.649369).  Saving model ...
	 Train_Loss: 0.7167 Train_Acc: 73.743 Val_Loss: 0.6494  BEST VAL Loss: 0.6494  Val_Acc: 77.879

Epoch 84: Validation loss decreased (0.649369 --> 0.649163).  Saving model ...
	 Train_Loss: 0.7165 Train_Acc: 73.774 Val_Loss: 0.6492  BEST VAL Loss: 0.6492  Val_Acc: 77.415

Epoch 85: Validation loss decreased (0.649163 --> 0.648853).  Saving model ...
	 Train_Loss: 0.7163 Train_Acc: 73.824 Val_Loss: 0.6489  BEST VAL Loss: 0.6489  Val_Acc: 78.097

Epoch 86: Validation loss decreased (0.648853 --> 0.648652).  Saving model ...
	 Train_Loss: 0.7160 Train_Acc: 73.868 Val_Loss: 0.6487  BEST VAL Loss: 0.6487  Val_Acc: 77.921

Epoch 87: Validation loss decreased (0.648652 --> 0.648306).  Saving model ...
	 Train_Loss: 0.7158 Train_Acc: 73.793 Val_Loss: 0.6483  BEST VAL Loss: 0.6483  Val_Acc: 77.982

Epoch 88: Validation loss decreased (0.648306 --> 0.648018).  Saving model ...
	 Train_Loss: 0.7156 Train_Acc: 73.836 Val_Loss: 0.6480  BEST VAL Loss: 0.6480  Val_Acc: 77.645

Epoch 89: Validation loss decreased (0.648018 --> 0.647772).  Saving model ...
	 Train_Loss: 0.7155 Train_Acc: 73.815 Val_Loss: 0.6478  BEST VAL Loss: 0.6478  Val_Acc: 77.911

Epoch 90: Validation loss decreased (0.647772 --> 0.647711).  Saving model ...
	 Train_Loss: 0.7153 Train_Acc: 73.690 Val_Loss: 0.6477  BEST VAL Loss: 0.6477  Val_Acc: 77.247

Epoch 91: Validation loss decreased (0.647711 --> 0.647645).  Saving model ...
	 Train_Loss: 0.7151 Train_Acc: 73.820 Val_Loss: 0.6476  BEST VAL Loss: 0.6476  Val_Acc: 74.972

Epoch 92: Validation loss decreased (0.647645 --> 0.647335).  Saving model ...
	 Train_Loss: 0.7149 Train_Acc: 73.857 Val_Loss: 0.6473  BEST VAL Loss: 0.6473  Val_Acc: 78.232

Epoch 93: Validation loss decreased (0.647335 --> 0.647325).  Saving model ...
	 Train_Loss: 0.7148 Train_Acc: 73.820 Val_Loss: 0.6473  BEST VAL Loss: 0.6473  Val_Acc: 75.278

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.7146 Train_Acc: 73.859 Val_Loss: 0.6474  BEST VAL Loss: 0.6473  Val_Acc: 76.983

Epoch 95: Validation loss decreased (0.647325 --> 0.647170).  Saving model ...
	 Train_Loss: 0.7144 Train_Acc: 73.842 Val_Loss: 0.6472  BEST VAL Loss: 0.6472  Val_Acc: 77.754

Epoch 96: Validation loss decreased (0.647170 --> 0.646962).  Saving model ...
	 Train_Loss: 0.7142 Train_Acc: 73.864 Val_Loss: 0.6470  BEST VAL Loss: 0.6470  Val_Acc: 78.188

Epoch 97: Validation loss decreased (0.646962 --> 0.646809).  Saving model ...
	 Train_Loss: 0.7141 Train_Acc: 73.806 Val_Loss: 0.6468  BEST VAL Loss: 0.6468  Val_Acc: 77.789

Epoch 98: Validation loss decreased (0.646809 --> 0.646561).  Saving model ...
	 Train_Loss: 0.7139 Train_Acc: 73.886 Val_Loss: 0.6466  BEST VAL Loss: 0.6466  Val_Acc: 78.368

Epoch 99: Validation loss did not decrease
	 Train_Loss: 0.7137 Train_Acc: 73.824 Val_Loss: 0.6466  BEST VAL Loss: 0.6466  Val_Acc: 77.047

MultiClass_MLP_shuffle
              precision    recall  f1-score   support

           0       0.06      0.04      0.05     95928
           1       0.50      0.56      0.53    749319
           2       0.43      0.40      0.41    638227

    accuracy                           0.46   1483474
   macro avg       0.33      0.33      0.33   1483474
weighted avg       0.44      0.46      0.45   1483474

MultiClass_MLP_shuffle
              precision    recall  f1-score   support

           0       0.07      0.04      0.05     23982
           1       0.51      0.56      0.53    187329
           2       0.43      0.40      0.41    159558

    accuracy                           0.46    370869
   macro avg       0.33      0.33      0.33    370869
weighted avg       0.44      0.46      0.45    370869

MultiClass_MLP_shuffle
              precision    recall  f1-score   support

           0       0.06      0.04      0.05    119911
           1       0.42      0.51      0.46    936644
           2       0.52      0.45      0.49   1150941

    accuracy                           0.45   2207496
   macro avg       0.33      0.33      0.33   2207496
weighted avg       0.45      0.45      0.45   2207496

Precision for class 0: 0.055109375180558605
Recall for class 0: 0.039771163613012986
Precision for class 1: 0.4242908373982358
Recall for class 1: 0.5063994431181964
Precision for class 2: 0.5213597246813737
Recall for class 2: 0.45436994598333014
3
              precision    recall  f1-score   support

           0       0.06      0.04      0.05    119911
           1       0.42      0.51      0.46    936644
           2       0.52      0.45      0.49   1150941

    accuracy                           0.45   2207496
   macro avg       0.33      0.33      0.33   2207496
weighted avg       0.45      0.45      0.45   2207496

MultiClass_MLP_shuffle
              precision    recall  f1-score   support

           0       0.05      0.04      0.04     75619
           1       0.51      0.51      0.51    788818
           2       0.44      0.45      0.44    672406

    accuracy                           0.46   1536843
   macro avg       0.33      0.33      0.33   1536843
weighted avg       0.46      0.46      0.46   1536843

Precision for class 0: 0.04870642327751853
Recall for class 0: 0.03754347452359857
Precision for class 1: 0.5132041918552587
Recall for class 1: 0.5129231330928047
Precision for class 2: 0.437303037372006
Recall for class 2: 0.44885530468199275
3
              precision    recall  f1-score   support

           0       0.05      0.04      0.04     75619
           1       0.51      0.51      0.51    788818
           2       0.44      0.45      0.44    672406

    accuracy                           0.46   1536843
   macro avg       0.33      0.33      0.33   1536843
weighted avg       0.46      0.46      0.46   1536843

Done
