[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1ab40758'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '3bfde3fa'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'fca8afd1'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '0e11d156'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: H2O2_100.000_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (42759, 1276)
Number of total missing values across all columns: 85518
Data Subset Is Off
Wells held out for testing: ['B16' 'H22']
Wells to use for training, validation, and testing ['B17' 'H18' 'H19' 'B20' 'B21' 'H23' 'I18' 'I19' 'I22' 'I23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.559807).  Saving model ...
	 Train_Loss: 0.6066 Train_Acc: 63.731 Val_Loss: 0.5598  BEST VAL Loss: 0.5598  Val_Acc: 68.999

Epoch 1: Validation loss decreased (0.559807 --> 0.536960).  Saving model ...
	 Train_Loss: 0.5695 Train_Acc: 71.113 Val_Loss: 0.5370  BEST VAL Loss: 0.5370  Val_Acc: 72.036

Epoch 2: Validation loss decreased (0.536960 --> 0.521455).  Saving model ...
	 Train_Loss: 0.5440 Train_Acc: 74.095 Val_Loss: 0.5215  BEST VAL Loss: 0.5215  Val_Acc: 74.031

Epoch 3: Validation loss decreased (0.521455 --> 0.511043).  Saving model ...
	 Train_Loss: 0.5240 Train_Acc: 76.402 Val_Loss: 0.5110  BEST VAL Loss: 0.5110  Val_Acc: 74.957

Epoch 4: Validation loss decreased (0.511043 --> 0.502947).  Saving model ...
	 Train_Loss: 0.5076 Train_Acc: 77.674 Val_Loss: 0.5029  BEST VAL Loss: 0.5029  Val_Acc: 75.795

Epoch 5: Validation loss decreased (0.502947 --> 0.496195).  Saving model ...
	 Train_Loss: 0.4947 Train_Acc: 78.412 Val_Loss: 0.4962  BEST VAL Loss: 0.4962  Val_Acc: 77.270

Epoch 6: Validation loss decreased (0.496195 --> 0.489916).  Saving model ...
	 Train_Loss: 0.4836 Train_Acc: 79.196 Val_Loss: 0.4899  BEST VAL Loss: 0.4899  Val_Acc: 77.039

Epoch 7: Validation loss decreased (0.489916 --> 0.483426).  Saving model ...
	 Train_Loss: 0.4741 Train_Acc: 79.919 Val_Loss: 0.4834  BEST VAL Loss: 0.4834  Val_Acc: 77.993

Epoch 8: Validation loss decreased (0.483426 --> 0.480671).  Saving model ...
	 Train_Loss: 0.4654 Train_Acc: 80.660 Val_Loss: 0.4807  BEST VAL Loss: 0.4807  Val_Acc: 78.456

Epoch 9: Validation loss decreased (0.480671 --> 0.477312).  Saving model ...
	 Train_Loss: 0.4578 Train_Acc: 80.797 Val_Loss: 0.4773  BEST VAL Loss: 0.4773  Val_Acc: 78.514

Epoch 10: Validation loss decreased (0.477312 --> 0.475498).  Saving model ...
	 Train_Loss: 0.4512 Train_Acc: 80.953 Val_Loss: 0.4755  BEST VAL Loss: 0.4755  Val_Acc: 78.109

Epoch 11: Validation loss decreased (0.475498 --> 0.473936).  Saving model ...
	 Train_Loss: 0.4453 Train_Acc: 81.282 Val_Loss: 0.4739  BEST VAL Loss: 0.4739  Val_Acc: 78.109

Epoch 12: Validation loss decreased (0.473936 --> 0.472503).  Saving model ...
	 Train_Loss: 0.4400 Train_Acc: 81.459 Val_Loss: 0.4725  BEST VAL Loss: 0.4725  Val_Acc: 77.820

Epoch 13: Validation loss decreased (0.472503 --> 0.470956).  Saving model ...
	 Train_Loss: 0.4350 Train_Acc: 81.936 Val_Loss: 0.4710  BEST VAL Loss: 0.4710  Val_Acc: 78.803

Epoch 14: Validation loss decreased (0.470956 --> 0.469706).  Saving model ...
	 Train_Loss: 0.4304 Train_Acc: 81.951 Val_Loss: 0.4697  BEST VAL Loss: 0.4697  Val_Acc: 78.485

Epoch 15: Validation loss decreased (0.469706 --> 0.469309).  Saving model ...
	 Train_Loss: 0.4261 Train_Acc: 82.225 Val_Loss: 0.4693  BEST VAL Loss: 0.4693  Val_Acc: 78.138

Epoch 16: Validation loss did not decrease
	 Train_Loss: 0.4222 Train_Acc: 82.330 Val_Loss: 0.4694  BEST VAL Loss: 0.4693  Val_Acc: 77.964

Epoch 17: Validation loss decreased (0.469309 --> 0.468617).  Saving model ...
	 Train_Loss: 0.4185 Train_Acc: 82.786 Val_Loss: 0.4686  BEST VAL Loss: 0.4686  Val_Acc: 78.543

Epoch 18: Validation loss decreased (0.468617 --> 0.467996).  Saving model ...
	 Train_Loss: 0.4154 Train_Acc: 82.648 Val_Loss: 0.4680  BEST VAL Loss: 0.4680  Val_Acc: 78.080

Epoch 19: Validation loss decreased (0.467996 --> 0.467827).  Saving model ...
	 Train_Loss: 0.4118 Train_Acc: 83.169 Val_Loss: 0.4678  BEST VAL Loss: 0.4678  Val_Acc: 79.179

Epoch 20: Validation loss decreased (0.467827 --> 0.467586).  Saving model ...
	 Train_Loss: 0.4088 Train_Acc: 83.332 Val_Loss: 0.4676  BEST VAL Loss: 0.4676  Val_Acc: 77.993

Epoch 21: Validation loss did not decrease
	 Train_Loss: 0.4059 Train_Acc: 83.216 Val_Loss: 0.4677  BEST VAL Loss: 0.4676  Val_Acc: 78.282

Epoch 22: Validation loss decreased (0.467586 --> 0.467479).  Saving model ...
	 Train_Loss: 0.4031 Train_Acc: 83.418 Val_Loss: 0.4675  BEST VAL Loss: 0.4675  Val_Acc: 78.629

Epoch 23: Validation loss did not decrease
	 Train_Loss: 0.4004 Train_Acc: 83.480 Val_Loss: 0.4676  BEST VAL Loss: 0.4675  Val_Acc: 78.774

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.3977 Train_Acc: 83.939 Val_Loss: 0.4679  BEST VAL Loss: 0.4675  Val_Acc: 78.427

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.3953 Train_Acc: 83.823 Val_Loss: 0.4680  BEST VAL Loss: 0.4675  Val_Acc: 78.340

Epoch 26: Validation loss did not decrease
	 Train_Loss: 0.3930 Train_Acc: 83.566 Val_Loss: 0.4686  BEST VAL Loss: 0.4675  Val_Acc: 78.427

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.3909 Train_Acc: 83.845 Val_Loss: 0.4686  BEST VAL Loss: 0.4675  Val_Acc: 78.918

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.3886 Train_Acc: 84.409 Val_Loss: 0.4687  BEST VAL Loss: 0.4675  Val_Acc: 77.704

Epoch 29: Validation loss did not decrease
	 Train_Loss: 0.3866 Train_Acc: 84.214 Val_Loss: 0.4690  BEST VAL Loss: 0.4675  Val_Acc: 78.600

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.3846 Train_Acc: 84.239 Val_Loss: 0.4698  BEST VAL Loss: 0.4675  Val_Acc: 78.456

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.3824 Train_Acc: 84.618 Val_Loss: 0.4703  BEST VAL Loss: 0.4675  Val_Acc: 78.398

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.3806 Train_Acc: 84.409 Val_Loss: 0.4705  BEST VAL Loss: 0.4675  Val_Acc: 78.514

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.3788 Train_Acc: 84.738 Val_Loss: 0.4708  BEST VAL Loss: 0.4675  Val_Acc: 78.976

Epoch 34: Validation loss did not decrease
	 Train_Loss: 0.3771 Train_Acc: 84.242 Val_Loss: 0.4713  BEST VAL Loss: 0.4675  Val_Acc: 78.832

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.3754 Train_Acc: 84.637 Val_Loss: 0.4716  BEST VAL Loss: 0.4675  Val_Acc: 78.745

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.3737 Train_Acc: 84.828 Val_Loss: 0.4725  BEST VAL Loss: 0.4675  Val_Acc: 79.208

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.3722 Train_Acc: 84.676 Val_Loss: 0.4730  BEST VAL Loss: 0.4675  Val_Acc: 78.224

Epoch 38: Validation loss did not decrease
Early stopped at epoch : 38
H2O2_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.66      0.70      0.68     18174
           1       0.34      0.29      0.32      9489

    accuracy                           0.56     27663
   macro avg       0.50      0.50      0.50     27663
weighted avg       0.55      0.56      0.55     27663

H2O2_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.66      0.71      0.68      2272
           1       0.34      0.28      0.31      1186

    accuracy                           0.56      3458
   macro avg       0.50      0.50      0.50      3458
weighted avg       0.55      0.56      0.55      3458

H2O2_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.65      0.70      0.67      2272
           1       0.34      0.29      0.31      1187

    accuracy                           0.56      3459
   macro avg       0.50      0.50      0.49      3459
weighted avg       0.54      0.56      0.55      3459

              precision    recall  f1-score   support

           0       0.65      0.70      0.67      2272
           1       0.34      0.29      0.31      1187

    accuracy                           0.56      3459
   macro avg       0.50      0.50      0.49      3459
weighted avg       0.54      0.56      0.55      3459

H2O2_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.57      0.54      4182
           1       0.49      0.44      0.47      3997

    accuracy                           0.51      8179
   macro avg       0.50      0.50      0.50      8179
weighted avg       0.50      0.51      0.50      8179

              precision    recall  f1-score   support

           0       0.51      0.57      0.54      4182
           1       0.49      0.44      0.47      3997

    accuracy                           0.51      8179
   macro avg       0.50      0.50      0.50      8179
weighted avg       0.50      0.51      0.50      8179

completed
