[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'a6229804'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'daab2c55'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'c3d94a38'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '99e19ac5'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_100.000_DMSO_0.025 treatment_name: DMSO_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_100.000_DMSO_0.025
TREATMENT_NAME: DMSO_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (51630, 1276)
Number of total missing values across all columns: 103260
Data Subset Is Off
Wells held out for testing: ['I14' 'J21']
Wells to use for training, validation, and testing ['B14' 'C14' 'B15' 'C15' 'J14' 'I15' 'J15' 'J16' 'J17' 'J20']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.497252).  Saving model ...
	 Train_Loss: 0.5573 Train_Acc: 72.326 Val_Loss: 0.4973  BEST VAL Loss: 0.4973  Val_Acc: 72.744

Epoch 1: Validation loss decreased (0.497252 --> 0.442926).  Saving model ...
	 Train_Loss: 0.5083 Train_Acc: 78.598 Val_Loss: 0.4429  BEST VAL Loss: 0.4429  Val_Acc: 83.103

Epoch 2: Validation loss decreased (0.442926 --> 0.402577).  Saving model ...
	 Train_Loss: 0.4688 Train_Acc: 82.844 Val_Loss: 0.4026  BEST VAL Loss: 0.4026  Val_Acc: 88.962

Epoch 3: Validation loss decreased (0.402577 --> 0.372606).  Saving model ...
	 Train_Loss: 0.4398 Train_Acc: 83.989 Val_Loss: 0.3726  BEST VAL Loss: 0.3726  Val_Acc: 91.540

Epoch 4: Validation loss decreased (0.372606 --> 0.347411).  Saving model ...
	 Train_Loss: 0.4155 Train_Acc: 84.736 Val_Loss: 0.3474  BEST VAL Loss: 0.3474  Val_Acc: 92.594

Epoch 5: Validation loss decreased (0.347411 --> 0.327528).  Saving model ...
	 Train_Loss: 0.3962 Train_Acc: 85.217 Val_Loss: 0.3275  BEST VAL Loss: 0.3275  Val_Acc: 93.016

Epoch 6: Validation loss decreased (0.327528 --> 0.310640).  Saving model ...
	 Train_Loss: 0.3789 Train_Acc: 85.794 Val_Loss: 0.3106  BEST VAL Loss: 0.3106  Val_Acc: 94.000

Epoch 7: Validation loss decreased (0.310640 --> 0.296503).  Saving model ...
	 Train_Loss: 0.3639 Train_Acc: 85.914 Val_Loss: 0.2965  BEST VAL Loss: 0.2965  Val_Acc: 94.071

Epoch 8: Validation loss decreased (0.296503 --> 0.284051).  Saving model ...
	 Train_Loss: 0.3508 Train_Acc: 86.005 Val_Loss: 0.2841  BEST VAL Loss: 0.2841  Val_Acc: 94.493

Epoch 9: Validation loss decreased (0.284051 --> 0.273106).  Saving model ...
	 Train_Loss: 0.3386 Train_Acc: 86.096 Val_Loss: 0.2731  BEST VAL Loss: 0.2731  Val_Acc: 94.657

Epoch 10: Validation loss decreased (0.273106 --> 0.263158).  Saving model ...
	 Train_Loss: 0.3275 Train_Acc: 86.318 Val_Loss: 0.2632  BEST VAL Loss: 0.2632  Val_Acc: 94.868

Epoch 11: Validation loss decreased (0.263158 --> 0.254536).  Saving model ...
	 Train_Loss: 0.3175 Train_Acc: 86.172 Val_Loss: 0.2545  BEST VAL Loss: 0.2545  Val_Acc: 94.821

Epoch 12: Validation loss decreased (0.254536 --> 0.246742).  Saving model ...
	 Train_Loss: 0.3082 Train_Acc: 88.891 Val_Loss: 0.2467  BEST VAL Loss: 0.2467  Val_Acc: 94.891

Epoch 13: Validation loss decreased (0.246742 --> 0.239431).  Saving model ...
	 Train_Loss: 0.2994 Train_Acc: 93.007 Val_Loss: 0.2394  BEST VAL Loss: 0.2394  Val_Acc: 95.219

Epoch 14: Validation loss decreased (0.239431 --> 0.232545).  Saving model ...
	 Train_Loss: 0.2912 Train_Acc: 93.487 Val_Loss: 0.2325  BEST VAL Loss: 0.2325  Val_Acc: 95.172

Epoch 15: Validation loss decreased (0.232545 --> 0.226397).  Saving model ...
	 Train_Loss: 0.2836 Train_Acc: 93.719 Val_Loss: 0.2264  BEST VAL Loss: 0.2264  Val_Acc: 95.196

Epoch 16: Validation loss decreased (0.226397 --> 0.220644).  Saving model ...
	 Train_Loss: 0.2765 Train_Acc: 94.100 Val_Loss: 0.2206  BEST VAL Loss: 0.2206  Val_Acc: 95.407

Epoch 17: Validation loss decreased (0.220644 --> 0.215413).  Saving model ...
	 Train_Loss: 0.2699 Train_Acc: 94.592 Val_Loss: 0.2154  BEST VAL Loss: 0.2154  Val_Acc: 95.430

Epoch 18: Validation loss decreased (0.215413 --> 0.210836).  Saving model ...
	 Train_Loss: 0.2636 Train_Acc: 94.844 Val_Loss: 0.2108  BEST VAL Loss: 0.2108  Val_Acc: 95.266

Epoch 19: Validation loss decreased (0.210836 --> 0.206458).  Saving model ...
	 Train_Loss: 0.2579 Train_Acc: 94.785 Val_Loss: 0.2065  BEST VAL Loss: 0.2065  Val_Acc: 95.266

Epoch 20: Validation loss decreased (0.206458 --> 0.202198).  Saving model ...
	 Train_Loss: 0.2522 Train_Acc: 95.184 Val_Loss: 0.2022  BEST VAL Loss: 0.2022  Val_Acc: 95.758

Epoch 21: Validation loss decreased (0.202198 --> 0.199259).  Saving model ...
	 Train_Loss: 0.2470 Train_Acc: 95.263 Val_Loss: 0.1993  BEST VAL Loss: 0.1993  Val_Acc: 94.938

Epoch 22: Validation loss decreased (0.199259 --> 0.195521).  Saving model ...
	 Train_Loss: 0.2421 Train_Acc: 95.222 Val_Loss: 0.1955  BEST VAL Loss: 0.1955  Val_Acc: 95.735

Epoch 23: Validation loss decreased (0.195521 --> 0.192072).  Saving model ...
	 Train_Loss: 0.2374 Train_Acc: 95.573 Val_Loss: 0.1921  BEST VAL Loss: 0.1921  Val_Acc: 95.899

Epoch 24: Validation loss decreased (0.192072 --> 0.188831).  Saving model ...
	 Train_Loss: 0.2329 Train_Acc: 95.632 Val_Loss: 0.1888  BEST VAL Loss: 0.1888  Val_Acc: 95.993

Epoch 25: Validation loss decreased (0.188831 --> 0.185778).  Saving model ...
	 Train_Loss: 0.2287 Train_Acc: 95.764 Val_Loss: 0.1858  BEST VAL Loss: 0.1858  Val_Acc: 96.016

Epoch 26: Validation loss decreased (0.185778 --> 0.183155).  Saving model ...
	 Train_Loss: 0.2247 Train_Acc: 95.813 Val_Loss: 0.1832  BEST VAL Loss: 0.1832  Val_Acc: 95.852

Epoch 27: Validation loss decreased (0.183155 --> 0.180721).  Saving model ...
	 Train_Loss: 0.2208 Train_Acc: 96.089 Val_Loss: 0.1807  BEST VAL Loss: 0.1807  Val_Acc: 96.110

Epoch 28: Validation loss decreased (0.180721 --> 0.178964).  Saving model ...
	 Train_Loss: 0.2171 Train_Acc: 96.068 Val_Loss: 0.1790  BEST VAL Loss: 0.1790  Val_Acc: 95.500

Epoch 29: Validation loss decreased (0.178964 --> 0.176748).  Saving model ...
	 Train_Loss: 0.2137 Train_Acc: 96.019 Val_Loss: 0.1767  BEST VAL Loss: 0.1767  Val_Acc: 96.063

Epoch 30: Validation loss decreased (0.176748 --> 0.174569).  Saving model ...
	 Train_Loss: 0.2103 Train_Acc: 96.329 Val_Loss: 0.1746  BEST VAL Loss: 0.1746  Val_Acc: 96.110

Epoch 31: Validation loss decreased (0.174569 --> 0.172522).  Saving model ...
	 Train_Loss: 0.2070 Train_Acc: 96.347 Val_Loss: 0.1725  BEST VAL Loss: 0.1725  Val_Acc: 96.180

Epoch 32: Validation loss decreased (0.172522 --> 0.170546).  Saving model ...
	 Train_Loss: 0.2039 Train_Acc: 96.496 Val_Loss: 0.1705  BEST VAL Loss: 0.1705  Val_Acc: 96.367

Epoch 33: Validation loss decreased (0.170546 --> 0.168656).  Saving model ...
	 Train_Loss: 0.2009 Train_Acc: 96.625 Val_Loss: 0.1687  BEST VAL Loss: 0.1687  Val_Acc: 96.391

Epoch 34: Validation loss decreased (0.168656 --> 0.166986).  Saving model ...
	 Train_Loss: 0.1980 Train_Acc: 96.596 Val_Loss: 0.1670  BEST VAL Loss: 0.1670  Val_Acc: 96.250

Epoch 35: Validation loss decreased (0.166986 --> 0.165357).  Saving model ...
	 Train_Loss: 0.1952 Train_Acc: 96.678 Val_Loss: 0.1654  BEST VAL Loss: 0.1654  Val_Acc: 96.321

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.1925 Train_Acc: 96.739 Val_Loss: 0.1654  BEST VAL Loss: 0.1654  Val_Acc: 95.313

Epoch 37: Validation loss decreased (0.165357 --> 0.163872).  Saving model ...
	 Train_Loss: 0.1899 Train_Acc: 96.783 Val_Loss: 0.1639  BEST VAL Loss: 0.1639  Val_Acc: 96.227

Epoch 38: Validation loss decreased (0.163872 --> 0.162378).  Saving model ...
	 Train_Loss: 0.1873 Train_Acc: 96.959 Val_Loss: 0.1624  BEST VAL Loss: 0.1624  Val_Acc: 96.391

Epoch 39: Validation loss decreased (0.162378 --> 0.160958).  Saving model ...
	 Train_Loss: 0.1849 Train_Acc: 96.982 Val_Loss: 0.1610  BEST VAL Loss: 0.1610  Val_Acc: 96.438

Epoch 40: Validation loss decreased (0.160958 --> 0.159646).  Saving model ...
	 Train_Loss: 0.1825 Train_Acc: 97.047 Val_Loss: 0.1596  BEST VAL Loss: 0.1596  Val_Acc: 96.321

Epoch 41: Validation loss decreased (0.159646 --> 0.158469).  Saving model ...
	 Train_Loss: 0.1802 Train_Acc: 97.158 Val_Loss: 0.1585  BEST VAL Loss: 0.1585  Val_Acc: 96.391

Epoch 42: Validation loss decreased (0.158469 --> 0.157273).  Saving model ...
	 Train_Loss: 0.1780 Train_Acc: 97.141 Val_Loss: 0.1573  BEST VAL Loss: 0.1573  Val_Acc: 96.344

Epoch 43: Validation loss decreased (0.157273 --> 0.156202).  Saving model ...
	 Train_Loss: 0.1758 Train_Acc: 97.272 Val_Loss: 0.1562  BEST VAL Loss: 0.1562  Val_Acc: 96.180

Epoch 44: Validation loss decreased (0.156202 --> 0.155287).  Saving model ...
	 Train_Loss: 0.1738 Train_Acc: 97.132 Val_Loss: 0.1553  BEST VAL Loss: 0.1553  Val_Acc: 96.227

Epoch 45: Validation loss decreased (0.155287 --> 0.154341).  Saving model ...
	 Train_Loss: 0.1718 Train_Acc: 97.246 Val_Loss: 0.1543  BEST VAL Loss: 0.1543  Val_Acc: 96.274

Epoch 46: Validation loss decreased (0.154341 --> 0.153397).  Saving model ...
	 Train_Loss: 0.1699 Train_Acc: 97.337 Val_Loss: 0.1534  BEST VAL Loss: 0.1534  Val_Acc: 96.625

Epoch 47: Validation loss decreased (0.153397 --> 0.152747).  Saving model ...
	 Train_Loss: 0.1679 Train_Acc: 97.504 Val_Loss: 0.1527  BEST VAL Loss: 0.1527  Val_Acc: 96.133

Epoch 48: Validation loss decreased (0.152747 --> 0.152017).  Saving model ...
	 Train_Loss: 0.1660 Train_Acc: 97.469 Val_Loss: 0.1520  BEST VAL Loss: 0.1520  Val_Acc: 96.321

Epoch 49: Validation loss decreased (0.152017 --> 0.151397).  Saving model ...
	 Train_Loss: 0.1642 Train_Acc: 97.551 Val_Loss: 0.1514  BEST VAL Loss: 0.1514  Val_Acc: 96.227

Epoch 50: Validation loss decreased (0.151397 --> 0.150669).  Saving model ...
	 Train_Loss: 0.1625 Train_Acc: 97.469 Val_Loss: 0.1507  BEST VAL Loss: 0.1507  Val_Acc: 96.485

Epoch 51: Validation loss decreased (0.150669 --> 0.150094).  Saving model ...
	 Train_Loss: 0.1607 Train_Acc: 97.747 Val_Loss: 0.1501  BEST VAL Loss: 0.1501  Val_Acc: 96.297

Epoch 52: Validation loss decreased (0.150094 --> 0.149551).  Saving model ...
	 Train_Loss: 0.1591 Train_Acc: 97.480 Val_Loss: 0.1496  BEST VAL Loss: 0.1496  Val_Acc: 96.157

Epoch 53: Validation loss decreased (0.149551 --> 0.149051).  Saving model ...
	 Train_Loss: 0.1575 Train_Acc: 97.539 Val_Loss: 0.1491  BEST VAL Loss: 0.1491  Val_Acc: 96.297

Epoch 54: Validation loss decreased (0.149051 --> 0.148492).  Saving model ...
	 Train_Loss: 0.1560 Train_Acc: 97.615 Val_Loss: 0.1485  BEST VAL Loss: 0.1485  Val_Acc: 96.438

Epoch 55: Validation loss decreased (0.148492 --> 0.147860).  Saving model ...
	 Train_Loss: 0.1545 Train_Acc: 97.454 Val_Loss: 0.1479  BEST VAL Loss: 0.1479  Val_Acc: 96.649

Epoch 56: Validation loss decreased (0.147860 --> 0.147320).  Saving model ...
	 Train_Loss: 0.1530 Train_Acc: 97.560 Val_Loss: 0.1473  BEST VAL Loss: 0.1473  Val_Acc: 96.485

Epoch 57: Validation loss decreased (0.147320 --> 0.146832).  Saving model ...
	 Train_Loss: 0.1516 Train_Acc: 97.630 Val_Loss: 0.1468  BEST VAL Loss: 0.1468  Val_Acc: 96.461

Epoch 58: Validation loss decreased (0.146832 --> 0.146763).  Saving model ...
	 Train_Loss: 0.1502 Train_Acc: 97.765 Val_Loss: 0.1468  BEST VAL Loss: 0.1468  Val_Acc: 96.016

Epoch 59: Validation loss decreased (0.146763 --> 0.146311).  Saving model ...
	 Train_Loss: 0.1488 Train_Acc: 97.744 Val_Loss: 0.1463  BEST VAL Loss: 0.1463  Val_Acc: 96.461

Epoch 60: Validation loss decreased (0.146311 --> 0.145934).  Saving model ...
	 Train_Loss: 0.1474 Train_Acc: 97.835 Val_Loss: 0.1459  BEST VAL Loss: 0.1459  Val_Acc: 96.367

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.1461 Train_Acc: 97.858 Val_Loss: 0.1478  BEST VAL Loss: 0.1459  Val_Acc: 94.985

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.1449 Train_Acc: 97.773 Val_Loss: 0.1476  BEST VAL Loss: 0.1459  Val_Acc: 96.227

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.1436 Train_Acc: 97.952 Val_Loss: 0.1472  BEST VAL Loss: 0.1459  Val_Acc: 96.367

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.1424 Train_Acc: 97.996 Val_Loss: 0.1469  BEST VAL Loss: 0.1459  Val_Acc: 96.157

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.1412 Train_Acc: 97.976 Val_Loss: 0.1466  BEST VAL Loss: 0.1459  Val_Acc: 96.157

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.1400 Train_Acc: 97.943 Val_Loss: 0.1463  BEST VAL Loss: 0.1459  Val_Acc: 96.297

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.1388 Train_Acc: 98.078 Val_Loss: 0.1461  BEST VAL Loss: 0.1459  Val_Acc: 96.391

Epoch 68: Validation loss decreased (0.145934 --> 0.145888).  Saving model ...
	 Train_Loss: 0.1377 Train_Acc: 98.099 Val_Loss: 0.1459  BEST VAL Loss: 0.1459  Val_Acc: 96.227

Epoch 69: Validation loss decreased (0.145888 --> 0.145578).  Saving model ...
	 Train_Loss: 0.1366 Train_Acc: 98.031 Val_Loss: 0.1456  BEST VAL Loss: 0.1456  Val_Acc: 96.344

Epoch 70: Validation loss decreased (0.145578 --> 0.145363).  Saving model ...
	 Train_Loss: 0.1355 Train_Acc: 98.192 Val_Loss: 0.1454  BEST VAL Loss: 0.1454  Val_Acc: 96.414

Epoch 71: Validation loss decreased (0.145363 --> 0.145190).  Saving model ...
	 Train_Loss: 0.1344 Train_Acc: 98.046 Val_Loss: 0.1452  BEST VAL Loss: 0.1452  Val_Acc: 96.297

Epoch 72: Validation loss decreased (0.145190 --> 0.144974).  Saving model ...
	 Train_Loss: 0.1334 Train_Acc: 98.066 Val_Loss: 0.1450  BEST VAL Loss: 0.1450  Val_Acc: 96.250

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.1324 Train_Acc: 98.151 Val_Loss: 0.1450  BEST VAL Loss: 0.1450  Val_Acc: 95.946

Epoch 74: Validation loss decreased (0.144974 --> 0.144655).  Saving model ...
	 Train_Loss: 0.1314 Train_Acc: 98.172 Val_Loss: 0.1447  BEST VAL Loss: 0.1447  Val_Acc: 96.696

Epoch 75: Validation loss decreased (0.144655 --> 0.144621).  Saving model ...
	 Train_Loss: 0.1304 Train_Acc: 98.213 Val_Loss: 0.1446  BEST VAL Loss: 0.1446  Val_Acc: 96.414

Epoch 76: Validation loss decreased (0.144621 --> 0.144482).  Saving model ...
	 Train_Loss: 0.1295 Train_Acc: 98.058 Val_Loss: 0.1445  BEST VAL Loss: 0.1445  Val_Acc: 96.508

Epoch 77: Validation loss decreased (0.144482 --> 0.144425).  Saving model ...
	 Train_Loss: 0.1286 Train_Acc: 98.187 Val_Loss: 0.1444  BEST VAL Loss: 0.1444  Val_Acc: 96.203

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.1276 Train_Acc: 98.184 Val_Loss: 0.1451  BEST VAL Loss: 0.1444  Val_Acc: 95.524

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.1268 Train_Acc: 98.072 Val_Loss: 0.1449  BEST VAL Loss: 0.1444  Val_Acc: 96.367

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.1259 Train_Acc: 98.257 Val_Loss: 0.1448  BEST VAL Loss: 0.1444  Val_Acc: 96.461

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.1250 Train_Acc: 98.283 Val_Loss: 0.1459  BEST VAL Loss: 0.1444  Val_Acc: 95.125

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.1242 Train_Acc: 98.125 Val_Loss: 0.1458  BEST VAL Loss: 0.1444  Val_Acc: 96.391

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.1234 Train_Acc: 98.189 Val_Loss: 0.1456  BEST VAL Loss: 0.1444  Val_Acc: 96.438

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.1226 Train_Acc: 98.374 Val_Loss: 0.1456  BEST VAL Loss: 0.1444  Val_Acc: 96.438

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.1218 Train_Acc: 98.236 Val_Loss: 0.1455  BEST VAL Loss: 0.1444  Val_Acc: 96.391

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.1210 Train_Acc: 98.189 Val_Loss: 0.1453  BEST VAL Loss: 0.1444  Val_Acc: 96.532

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.1203 Train_Acc: 98.327 Val_Loss: 0.1452  BEST VAL Loss: 0.1444  Val_Acc: 96.414

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.1195 Train_Acc: 98.424 Val_Loss: 0.1453  BEST VAL Loss: 0.1444  Val_Acc: 96.297

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.1187 Train_Acc: 98.409 Val_Loss: 0.1452  BEST VAL Loss: 0.1444  Val_Acc: 96.461

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.1180 Train_Acc: 98.482 Val_Loss: 0.1453  BEST VAL Loss: 0.1444  Val_Acc: 96.321

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.1173 Train_Acc: 98.242 Val_Loss: 0.1452  BEST VAL Loss: 0.1444  Val_Acc: 96.274

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.1166 Train_Acc: 98.157 Val_Loss: 0.1454  BEST VAL Loss: 0.1444  Val_Acc: 96.250

Epoch 93: Validation loss did not decrease
Early stopped at epoch : 93
LPS_100.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     24644
           1       0.99      1.00      0.99      9489

    accuracy                           1.00     34133
   macro avg       1.00      1.00      1.00     34133
weighted avg       1.00      1.00      1.00     34133

LPS_100.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.98      0.97      3081
           1       0.95      0.91      0.93      1186

    accuracy                           0.96      4267
   macro avg       0.96      0.95      0.95      4267
weighted avg       0.96      0.96      0.96      4267

LPS_100.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.96      0.98      0.97      3081
           1       0.96      0.90      0.93      1186

    accuracy                           0.96      4267
   macro avg       0.96      0.94      0.95      4267
weighted avg       0.96      0.96      0.96      4267

              precision    recall  f1-score   support

           0       0.96      0.98      0.97      3081
           1       0.96      0.90      0.93      1186

    accuracy                           0.96      4267
   macro avg       0.96      0.94      0.95      4267
weighted avg       0.96      0.96      0.96      4267

LPS_100.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.87      1.00      0.93      4837
           1       1.00      0.83      0.90      4126

    accuracy                           0.92      8963
   macro avg       0.93      0.91      0.92      8963
weighted avg       0.93      0.92      0.92      8963

              precision    recall  f1-score   support

           0       0.87      1.00      0.93      4837
           1       1.00      0.83      0.90      4126

    accuracy                           0.92      8963
   macro avg       0.93      0.91      0.92      8963
weighted avg       0.93      0.92      0.92      8963

completed
