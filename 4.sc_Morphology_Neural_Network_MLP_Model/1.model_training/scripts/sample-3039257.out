[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'f44b567c'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '59da3a6f'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '00851ceb'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'dbc74c98'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_1.000_DMSO_0.025 treatment_name: Thapsigargin_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_1.000_DMSO_0.025
TREATMENT_NAME: Thapsigargin_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'Thapsigargin_1.000_DMSO_0.025']
The dimensions of the data are: (287889, 1270)
Number of total missing values across all columns: 575778
Data Subset Is Off
Wells held out for testing: ['D08' 'K06']
Wells to use for training, validation, and testing ['D02' 'D03' 'D06' 'D07' 'D09' 'K07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.539958).  Saving model ...
	 Train_Loss: 0.6007 Train_Acc: 68.175 Val_Loss: 0.5400  BEST VAL Loss: 0.5400  Val_Acc: 73.245

Epoch 1: Validation loss decreased (0.539958 --> 0.520563).  Saving model ...
	 Train_Loss: 0.5672 Train_Acc: 73.266 Val_Loss: 0.5206  BEST VAL Loss: 0.5206  Val_Acc: 75.432

Epoch 2: Validation loss decreased (0.520563 --> 0.506948).  Saving model ...
	 Train_Loss: 0.5473 Train_Acc: 74.780 Val_Loss: 0.5069  BEST VAL Loss: 0.5069  Val_Acc: 76.357

Epoch 3: Validation loss decreased (0.506948 --> 0.495746).  Saving model ...
	 Train_Loss: 0.5327 Train_Acc: 75.940 Val_Loss: 0.4957  BEST VAL Loss: 0.4957  Val_Acc: 77.677

Epoch 4: Validation loss decreased (0.495746 --> 0.486180).  Saving model ...
	 Train_Loss: 0.5213 Train_Acc: 76.770 Val_Loss: 0.4862  BEST VAL Loss: 0.4862  Val_Acc: 78.596

Epoch 5: Validation loss decreased (0.486180 --> 0.478180).  Saving model ...
	 Train_Loss: 0.5117 Train_Acc: 77.534 Val_Loss: 0.4782  BEST VAL Loss: 0.4782  Val_Acc: 79.330

Epoch 6: Validation loss decreased (0.478180 --> 0.470935).  Saving model ...
	 Train_Loss: 0.5038 Train_Acc: 77.913 Val_Loss: 0.4709  BEST VAL Loss: 0.4709  Val_Acc: 79.907

Epoch 7: Validation loss decreased (0.470935 --> 0.465047).  Saving model ...
	 Train_Loss: 0.4970 Train_Acc: 78.456 Val_Loss: 0.4650  BEST VAL Loss: 0.4650  Val_Acc: 80.240

Epoch 8: Validation loss decreased (0.465047 --> 0.459414).  Saving model ...
	 Train_Loss: 0.4910 Train_Acc: 78.749 Val_Loss: 0.4594  BEST VAL Loss: 0.4594  Val_Acc: 80.922

Epoch 9: Validation loss decreased (0.459414 --> 0.454587).  Saving model ...
	 Train_Loss: 0.4856 Train_Acc: 79.158 Val_Loss: 0.4546  BEST VAL Loss: 0.4546  Val_Acc: 81.084

Epoch 10: Validation loss decreased (0.454587 --> 0.449973).  Saving model ...
	 Train_Loss: 0.4809 Train_Acc: 79.230 Val_Loss: 0.4500  BEST VAL Loss: 0.4500  Val_Acc: 81.665

Epoch 11: Validation loss decreased (0.449973 --> 0.446400).  Saving model ...
	 Train_Loss: 0.4765 Train_Acc: 79.605 Val_Loss: 0.4464  BEST VAL Loss: 0.4464  Val_Acc: 81.041

Epoch 12: Validation loss decreased (0.446400 --> 0.443626).  Saving model ...
	 Train_Loss: 0.4724 Train_Acc: 79.870 Val_Loss: 0.4436  BEST VAL Loss: 0.4436  Val_Acc: 81.107

Epoch 13: Validation loss decreased (0.443626 --> 0.439848).  Saving model ...
	 Train_Loss: 0.4687 Train_Acc: 80.002 Val_Loss: 0.4398  BEST VAL Loss: 0.4398  Val_Acc: 82.418

Epoch 14: Validation loss decreased (0.439848 --> 0.436294).  Saving model ...
	 Train_Loss: 0.4652 Train_Acc: 80.278 Val_Loss: 0.4363  BEST VAL Loss: 0.4363  Val_Acc: 82.575

Epoch 15: Validation loss decreased (0.436294 --> 0.433144).  Saving model ...
	 Train_Loss: 0.4619 Train_Acc: 80.501 Val_Loss: 0.4331  BEST VAL Loss: 0.4331  Val_Acc: 82.618

Epoch 16: Validation loss decreased (0.433144 --> 0.430082).  Saving model ...
	 Train_Loss: 0.4588 Train_Acc: 80.755 Val_Loss: 0.4301  BEST VAL Loss: 0.4301  Val_Acc: 82.508

Epoch 17: Validation loss decreased (0.430082 --> 0.427069).  Saving model ...
	 Train_Loss: 0.4558 Train_Acc: 80.914 Val_Loss: 0.4271  BEST VAL Loss: 0.4271  Val_Acc: 82.923

Epoch 18: Validation loss decreased (0.427069 --> 0.424275).  Saving model ...
	 Train_Loss: 0.4528 Train_Acc: 81.133 Val_Loss: 0.4243  BEST VAL Loss: 0.4243  Val_Acc: 82.951

Epoch 19: Validation loss decreased (0.424275 --> 0.421668).  Saving model ...
	 Train_Loss: 0.4502 Train_Acc: 81.237 Val_Loss: 0.4217  BEST VAL Loss: 0.4217  Val_Acc: 83.399

Epoch 20: Validation loss decreased (0.421668 --> 0.419152).  Saving model ...
	 Train_Loss: 0.4476 Train_Acc: 81.512 Val_Loss: 0.4192  BEST VAL Loss: 0.4192  Val_Acc: 83.399

Epoch 21: Validation loss decreased (0.419152 --> 0.417002).  Saving model ...
	 Train_Loss: 0.4452 Train_Acc: 81.550 Val_Loss: 0.4170  BEST VAL Loss: 0.4170  Val_Acc: 83.213

Epoch 22: Validation loss decreased (0.417002 --> 0.414931).  Saving model ...
	 Train_Loss: 0.4428 Train_Acc: 81.714 Val_Loss: 0.4149  BEST VAL Loss: 0.4149  Val_Acc: 83.380

Epoch 23: Validation loss decreased (0.414931 --> 0.412649).  Saving model ...
	 Train_Loss: 0.4406 Train_Acc: 81.856 Val_Loss: 0.4126  BEST VAL Loss: 0.4126  Val_Acc: 84.009

Epoch 24: Validation loss decreased (0.412649 --> 0.411327).  Saving model ...
	 Train_Loss: 0.4384 Train_Acc: 81.920 Val_Loss: 0.4113  BEST VAL Loss: 0.4113  Val_Acc: 82.394

Epoch 25: Validation loss decreased (0.411327 --> 0.409230).  Saving model ...
	 Train_Loss: 0.4364 Train_Acc: 81.911 Val_Loss: 0.4092  BEST VAL Loss: 0.4092  Val_Acc: 84.062

Epoch 26: Validation loss decreased (0.409230 --> 0.407252).  Saving model ...
	 Train_Loss: 0.4344 Train_Acc: 82.173 Val_Loss: 0.4073  BEST VAL Loss: 0.4073  Val_Acc: 84.257

Epoch 27: Validation loss decreased (0.407252 --> 0.405747).  Saving model ...
	 Train_Loss: 0.4325 Train_Acc: 82.271 Val_Loss: 0.4057  BEST VAL Loss: 0.4057  Val_Acc: 83.533

Epoch 28: Validation loss decreased (0.405747 --> 0.403889).  Saving model ...
	 Train_Loss: 0.4307 Train_Acc: 82.343 Val_Loss: 0.4039  BEST VAL Loss: 0.4039  Val_Acc: 84.214

Epoch 29: Validation loss decreased (0.403889 --> 0.402257).  Saving model ...
	 Train_Loss: 0.4288 Train_Acc: 82.494 Val_Loss: 0.4023  BEST VAL Loss: 0.4023  Val_Acc: 84.171

Epoch 30: Validation loss decreased (0.402257 --> 0.400694).  Saving model ...
	 Train_Loss: 0.4271 Train_Acc: 82.545 Val_Loss: 0.4007  BEST VAL Loss: 0.4007  Val_Acc: 84.019

Epoch 31: Validation loss decreased (0.400694 --> 0.399067).  Saving model ...
	 Train_Loss: 0.4254 Train_Acc: 82.626 Val_Loss: 0.3991  BEST VAL Loss: 0.3991  Val_Acc: 84.400

Epoch 32: Validation loss decreased (0.399067 --> 0.397449).  Saving model ...
	 Train_Loss: 0.4239 Train_Acc: 82.596 Val_Loss: 0.3974  BEST VAL Loss: 0.3974  Val_Acc: 84.748

Epoch 33: Validation loss decreased (0.397449 --> 0.395907).  Saving model ...
	 Train_Loss: 0.4223 Train_Acc: 82.795 Val_Loss: 0.3959  BEST VAL Loss: 0.3959  Val_Acc: 84.505

Epoch 34: Validation loss decreased (0.395907 --> 0.394357).  Saving model ...
	 Train_Loss: 0.4208 Train_Acc: 82.837 Val_Loss: 0.3944  BEST VAL Loss: 0.3944  Val_Acc: 84.934

Epoch 35: Validation loss decreased (0.394357 --> 0.392994).  Saving model ...
	 Train_Loss: 0.4193 Train_Acc: 82.908 Val_Loss: 0.3930  BEST VAL Loss: 0.3930  Val_Acc: 84.819

Epoch 36: Validation loss decreased (0.392994 --> 0.391577).  Saving model ...
	 Train_Loss: 0.4179 Train_Acc: 83.129 Val_Loss: 0.3916  BEST VAL Loss: 0.3916  Val_Acc: 84.757

Epoch 37: Validation loss decreased (0.391577 --> 0.390190).  Saving model ...
	 Train_Loss: 0.4165 Train_Acc: 83.101 Val_Loss: 0.3902  BEST VAL Loss: 0.3902  Val_Acc: 84.686

Epoch 38: Validation loss decreased (0.390190 --> 0.389025).  Saving model ...
	 Train_Loss: 0.4151 Train_Acc: 83.337 Val_Loss: 0.3890  BEST VAL Loss: 0.3890  Val_Acc: 84.581

Epoch 39: Validation loss decreased (0.389025 --> 0.387767).  Saving model ...
	 Train_Loss: 0.4137 Train_Acc: 83.392 Val_Loss: 0.3878  BEST VAL Loss: 0.3878  Val_Acc: 84.943

Epoch 40: Validation loss decreased (0.387767 --> 0.386393).  Saving model ...
	 Train_Loss: 0.4124 Train_Acc: 83.373 Val_Loss: 0.3864  BEST VAL Loss: 0.3864  Val_Acc: 85.429

Epoch 41: Validation loss decreased (0.386393 --> 0.385101).  Saving model ...
	 Train_Loss: 0.4111 Train_Acc: 83.459 Val_Loss: 0.3851  BEST VAL Loss: 0.3851  Val_Acc: 85.405

Epoch 42: Validation loss decreased (0.385101 --> 0.383869).  Saving model ...
	 Train_Loss: 0.4098 Train_Acc: 83.564 Val_Loss: 0.3839  BEST VAL Loss: 0.3839  Val_Acc: 85.343

Epoch 43: Validation loss decreased (0.383869 --> 0.382698).  Saving model ...
	 Train_Loss: 0.4086 Train_Acc: 83.585 Val_Loss: 0.3827  BEST VAL Loss: 0.3827  Val_Acc: 85.353

Epoch 44: Validation loss decreased (0.382698 --> 0.381536).  Saving model ...
	 Train_Loss: 0.4074 Train_Acc: 83.697 Val_Loss: 0.3815  BEST VAL Loss: 0.3815  Val_Acc: 85.520

Epoch 45: Validation loss decreased (0.381536 --> 0.380416).  Saving model ...
	 Train_Loss: 0.4062 Train_Acc: 83.711 Val_Loss: 0.3804  BEST VAL Loss: 0.3804  Val_Acc: 85.353

Epoch 46: Validation loss decreased (0.380416 --> 0.379331).  Saving model ...
	 Train_Loss: 0.4051 Train_Acc: 83.808 Val_Loss: 0.3793  BEST VAL Loss: 0.3793  Val_Acc: 85.610

Epoch 47: Validation loss decreased (0.379331 --> 0.378284).  Saving model ...
	 Train_Loss: 0.4040 Train_Acc: 83.779 Val_Loss: 0.3783  BEST VAL Loss: 0.3783  Val_Acc: 85.496

Epoch 48: Validation loss decreased (0.378284 --> 0.377207).  Saving model ...
	 Train_Loss: 0.4029 Train_Acc: 83.908 Val_Loss: 0.3772  BEST VAL Loss: 0.3772  Val_Acc: 85.639

Epoch 49: Validation loss decreased (0.377207 --> 0.376228).  Saving model ...
	 Train_Loss: 0.4018 Train_Acc: 84.042 Val_Loss: 0.3762  BEST VAL Loss: 0.3762  Val_Acc: 85.648

Epoch 50: Validation loss decreased (0.376228 --> 0.375308).  Saving model ...
	 Train_Loss: 0.4008 Train_Acc: 83.916 Val_Loss: 0.3753  BEST VAL Loss: 0.3753  Val_Acc: 85.224

Epoch 51: Validation loss decreased (0.375308 --> 0.374386).  Saving model ...
	 Train_Loss: 0.3998 Train_Acc: 84.049 Val_Loss: 0.3744  BEST VAL Loss: 0.3744  Val_Acc: 85.629

Epoch 52: Validation loss decreased (0.374386 --> 0.373469).  Saving model ...
	 Train_Loss: 0.3988 Train_Acc: 83.890 Val_Loss: 0.3735  BEST VAL Loss: 0.3735  Val_Acc: 85.782

Epoch 53: Validation loss decreased (0.373469 --> 0.372569).  Saving model ...
	 Train_Loss: 0.3978 Train_Acc: 83.948 Val_Loss: 0.3726  BEST VAL Loss: 0.3726  Val_Acc: 85.829

Epoch 54: Validation loss decreased (0.372569 --> 0.371656).  Saving model ...
	 Train_Loss: 0.3969 Train_Acc: 84.026 Val_Loss: 0.3717  BEST VAL Loss: 0.3717  Val_Acc: 85.796

Epoch 55: Validation loss decreased (0.371656 --> 0.370925).  Saving model ...
	 Train_Loss: 0.3960 Train_Acc: 84.110 Val_Loss: 0.3709  BEST VAL Loss: 0.3709  Val_Acc: 85.353

Epoch 56: Validation loss decreased (0.370925 --> 0.370136).  Saving model ...
	 Train_Loss: 0.3951 Train_Acc: 84.172 Val_Loss: 0.3701  BEST VAL Loss: 0.3701  Val_Acc: 85.648

Epoch 57: Validation loss decreased (0.370136 --> 0.369281).  Saving model ...
	 Train_Loss: 0.3942 Train_Acc: 84.187 Val_Loss: 0.3693  BEST VAL Loss: 0.3693  Val_Acc: 86.115

Epoch 58: Validation loss decreased (0.369281 --> 0.368505).  Saving model ...
	 Train_Loss: 0.3933 Train_Acc: 84.184 Val_Loss: 0.3685  BEST VAL Loss: 0.3685  Val_Acc: 85.882

Epoch 59: Validation loss decreased (0.368505 --> 0.367673).  Saving model ...
	 Train_Loss: 0.3925 Train_Acc: 84.291 Val_Loss: 0.3677  BEST VAL Loss: 0.3677  Val_Acc: 85.791

Epoch 60: Validation loss decreased (0.367673 --> 0.366877).  Saving model ...
	 Train_Loss: 0.3917 Train_Acc: 84.353 Val_Loss: 0.3669  BEST VAL Loss: 0.3669  Val_Acc: 86.201

Epoch 61: Validation loss decreased (0.366877 --> 0.366204).  Saving model ...
	 Train_Loss: 0.3908 Train_Acc: 84.387 Val_Loss: 0.3662  BEST VAL Loss: 0.3662  Val_Acc: 85.858

Epoch 62: Validation loss decreased (0.366204 --> 0.365391).  Saving model ...
	 Train_Loss: 0.3901 Train_Acc: 84.329 Val_Loss: 0.3654  BEST VAL Loss: 0.3654  Val_Acc: 86.268

Epoch 63: Validation loss decreased (0.365391 --> 0.364663).  Saving model ...
	 Train_Loss: 0.3893 Train_Acc: 84.350 Val_Loss: 0.3647  BEST VAL Loss: 0.3647  Val_Acc: 86.139

Epoch 64: Validation loss decreased (0.364663 --> 0.363999).  Saving model ...
	 Train_Loss: 0.3885 Train_Acc: 84.362 Val_Loss: 0.3640  BEST VAL Loss: 0.3640  Val_Acc: 86.049

Epoch 65: Validation loss decreased (0.363999 --> 0.363264).  Saving model ...
	 Train_Loss: 0.3878 Train_Acc: 84.378 Val_Loss: 0.3633  BEST VAL Loss: 0.3633  Val_Acc: 86.187

Epoch 66: Validation loss decreased (0.363264 --> 0.362594).  Saving model ...
	 Train_Loss: 0.3871 Train_Acc: 84.303 Val_Loss: 0.3626  BEST VAL Loss: 0.3626  Val_Acc: 86.044

Epoch 67: Validation loss decreased (0.362594 --> 0.361854).  Saving model ...
	 Train_Loss: 0.3863 Train_Acc: 84.494 Val_Loss: 0.3619  BEST VAL Loss: 0.3619  Val_Acc: 86.496

Epoch 68: Validation loss decreased (0.361854 --> 0.361218).  Saving model ...
	 Train_Loss: 0.3856 Train_Acc: 84.361 Val_Loss: 0.3612  BEST VAL Loss: 0.3612  Val_Acc: 86.015

Epoch 69: Validation loss decreased (0.361218 --> 0.360648).  Saving model ...
	 Train_Loss: 0.3849 Train_Acc: 84.518 Val_Loss: 0.3606  BEST VAL Loss: 0.3606  Val_Acc: 86.072

Epoch 70: Validation loss decreased (0.360648 --> 0.360056).  Saving model ...
	 Train_Loss: 0.3843 Train_Acc: 84.501 Val_Loss: 0.3601  BEST VAL Loss: 0.3601  Val_Acc: 86.149

Epoch 71: Validation loss decreased (0.360056 --> 0.359426).  Saving model ...
	 Train_Loss: 0.3836 Train_Acc: 84.512 Val_Loss: 0.3594  BEST VAL Loss: 0.3594  Val_Acc: 86.263

Epoch 72: Validation loss decreased (0.359426 --> 0.358787).  Saving model ...
	 Train_Loss: 0.3829 Train_Acc: 84.524 Val_Loss: 0.3588  BEST VAL Loss: 0.3588  Val_Acc: 86.363

Epoch 73: Validation loss decreased (0.358787 --> 0.358162).  Saving model ...
	 Train_Loss: 0.3823 Train_Acc: 84.562 Val_Loss: 0.3582  BEST VAL Loss: 0.3582  Val_Acc: 86.558

Epoch 74: Validation loss decreased (0.358162 --> 0.357636).  Saving model ...
	 Train_Loss: 0.3817 Train_Acc: 84.568 Val_Loss: 0.3576  BEST VAL Loss: 0.3576  Val_Acc: 86.120

Epoch 75: Validation loss decreased (0.357636 --> 0.357067).  Saving model ...
	 Train_Loss: 0.3811 Train_Acc: 84.562 Val_Loss: 0.3571  BEST VAL Loss: 0.3571  Val_Acc: 86.191

Epoch 76: Validation loss decreased (0.357067 --> 0.356481).  Saving model ...
	 Train_Loss: 0.3805 Train_Acc: 84.596 Val_Loss: 0.3565  BEST VAL Loss: 0.3565  Val_Acc: 86.458

Epoch 77: Validation loss decreased (0.356481 --> 0.355988).  Saving model ...
	 Train_Loss: 0.3799 Train_Acc: 84.691 Val_Loss: 0.3560  BEST VAL Loss: 0.3560  Val_Acc: 86.130

Epoch 78: Validation loss decreased (0.355988 --> 0.355474).  Saving model ...
	 Train_Loss: 0.3793 Train_Acc: 84.641 Val_Loss: 0.3555  BEST VAL Loss: 0.3555  Val_Acc: 86.239

Epoch 79: Validation loss decreased (0.355474 --> 0.354925).  Saving model ...
	 Train_Loss: 0.3787 Train_Acc: 84.802 Val_Loss: 0.3549  BEST VAL Loss: 0.3549  Val_Acc: 86.377

Epoch 80: Validation loss decreased (0.354925 --> 0.354387).  Saving model ...
	 Train_Loss: 0.3781 Train_Acc: 84.572 Val_Loss: 0.3544  BEST VAL Loss: 0.3544  Val_Acc: 86.658

Epoch 81: Validation loss decreased (0.354387 --> 0.353874).  Saving model ...
	 Train_Loss: 0.3776 Train_Acc: 84.735 Val_Loss: 0.3539  BEST VAL Loss: 0.3539  Val_Acc: 86.334

Epoch 82: Validation loss decreased (0.353874 --> 0.353336).  Saving model ...
	 Train_Loss: 0.3770 Train_Acc: 84.716 Val_Loss: 0.3533  BEST VAL Loss: 0.3533  Val_Acc: 86.582

Epoch 83: Validation loss decreased (0.353336 --> 0.353018).  Saving model ...
	 Train_Loss: 0.3765 Train_Acc: 84.658 Val_Loss: 0.3530  BEST VAL Loss: 0.3530  Val_Acc: 85.410

Epoch 84: Validation loss decreased (0.353018 --> 0.352542).  Saving model ...
	 Train_Loss: 0.3760 Train_Acc: 84.774 Val_Loss: 0.3525  BEST VAL Loss: 0.3525  Val_Acc: 86.406

Epoch 85: Validation loss decreased (0.352542 --> 0.352127).  Saving model ...
	 Train_Loss: 0.3755 Train_Acc: 84.809 Val_Loss: 0.3521  BEST VAL Loss: 0.3521  Val_Acc: 86.206

Epoch 86: Validation loss decreased (0.352127 --> 0.351685).  Saving model ...
	 Train_Loss: 0.3749 Train_Acc: 84.743 Val_Loss: 0.3517  BEST VAL Loss: 0.3517  Val_Acc: 86.482

Epoch 87: Validation loss decreased (0.351685 --> 0.351203).  Saving model ...
	 Train_Loss: 0.3744 Train_Acc: 84.837 Val_Loss: 0.3512  BEST VAL Loss: 0.3512  Val_Acc: 86.692

Epoch 88: Validation loss decreased (0.351203 --> 0.350707).  Saving model ...
	 Train_Loss: 0.3739 Train_Acc: 84.787 Val_Loss: 0.3507  BEST VAL Loss: 0.3507  Val_Acc: 86.687

Epoch 89: Validation loss decreased (0.350707 --> 0.350288).  Saving model ...
	 Train_Loss: 0.3735 Train_Acc: 84.820 Val_Loss: 0.3503  BEST VAL Loss: 0.3503  Val_Acc: 86.501

Epoch 90: Validation loss decreased (0.350288 --> 0.349856).  Saving model ...
	 Train_Loss: 0.3730 Train_Acc: 84.870 Val_Loss: 0.3499  BEST VAL Loss: 0.3499  Val_Acc: 86.501

Epoch 91: Validation loss decreased (0.349856 --> 0.349386).  Saving model ...
	 Train_Loss: 0.3725 Train_Acc: 84.835 Val_Loss: 0.3494  BEST VAL Loss: 0.3494  Val_Acc: 86.782

Epoch 92: Validation loss decreased (0.349386 --> 0.348945).  Saving model ...
	 Train_Loss: 0.3720 Train_Acc: 84.907 Val_Loss: 0.3489  BEST VAL Loss: 0.3489  Val_Acc: 86.687

Epoch 93: Validation loss decreased (0.348945 --> 0.348498).  Saving model ...
	 Train_Loss: 0.3716 Train_Acc: 84.943 Val_Loss: 0.3485  BEST VAL Loss: 0.3485  Val_Acc: 86.863

Epoch 94: Validation loss decreased (0.348498 --> 0.348056).  Saving model ...
	 Train_Loss: 0.3711 Train_Acc: 84.894 Val_Loss: 0.3481  BEST VAL Loss: 0.3481  Val_Acc: 86.687

Epoch 95: Validation loss decreased (0.348056 --> 0.347651).  Saving model ...
	 Train_Loss: 0.3707 Train_Acc: 84.933 Val_Loss: 0.3477  BEST VAL Loss: 0.3477  Val_Acc: 86.849

Epoch 96: Validation loss decreased (0.347651 --> 0.347258).  Saving model ...
	 Train_Loss: 0.3702 Train_Acc: 84.993 Val_Loss: 0.3473  BEST VAL Loss: 0.3473  Val_Acc: 86.711

Epoch 97: Validation loss decreased (0.347258 --> 0.346883).  Saving model ...
	 Train_Loss: 0.3698 Train_Acc: 84.895 Val_Loss: 0.3469  BEST VAL Loss: 0.3469  Val_Acc: 86.506

Epoch 98: Validation loss decreased (0.346883 --> 0.346472).  Saving model ...
	 Train_Loss: 0.3694 Train_Acc: 84.941 Val_Loss: 0.3465  BEST VAL Loss: 0.3465  Val_Acc: 86.944

Epoch 99: Validation loss decreased (0.346472 --> 0.346047).  Saving model ...
	 Train_Loss: 0.3689 Train_Acc: 84.962 Val_Loss: 0.3460  BEST VAL Loss: 0.3460  Val_Acc: 87.021

LPS_1.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.47      0.47     79796
           1       0.53      0.53      0.53     88100

    accuracy                           0.50    167896
   macro avg       0.50      0.50      0.50    167896
weighted avg       0.50      0.50      0.50    167896

LPS_1.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.46      0.47      9975
           1       0.52      0.53      0.53     11012

    accuracy                           0.50     20987
   macro avg       0.50      0.50      0.50     20987
weighted avg       0.50      0.50      0.50     20987

LPS_1.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.47      0.48      9975
           1       0.53      0.54      0.54     11012

    accuracy                           0.51     20987
   macro avg       0.51      0.51      0.51     20987
weighted avg       0.51      0.51      0.51     20987

              precision    recall  f1-score   support

           0       0.48      0.47      0.48      9975
           1       0.53      0.54      0.54     11012

    accuracy                           0.51     20987
   macro avg       0.51      0.51      0.51     20987
weighted avg       0.51      0.51      0.51     20987

LPS_1.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.21      0.30     39687
           1       0.49      0.79      0.61     38332

    accuracy                           0.49     78019
   macro avg       0.50      0.50      0.45     78019
weighted avg       0.50      0.49      0.45     78019

              precision    recall  f1-score   support

           0       0.51      0.21      0.30     39687
           1       0.49      0.79      0.61     38332

    accuracy                           0.49     78019
   macro avg       0.50      0.50      0.45     78019
weighted avg       0.50      0.49      0.45     78019

completed
