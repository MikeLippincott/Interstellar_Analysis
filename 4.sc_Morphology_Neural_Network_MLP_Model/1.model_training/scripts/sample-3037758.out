[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ad564c6a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '9ef293e4'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '3b84dd90'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '6daf264b'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_10.000_DMSO_0.025 treatment_name: DMSO_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: DMSO_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'LPS_10.000_DMSO_0.025']
The dimensions of the data are: (371620, 1270)
Number of total missing values across all columns: 743240
Data Subset Is Off
Wells held out for testing: ['E09' 'J06']
Wells to use for training, validation, and testing ['B06' 'C06' 'B07' 'C07' 'E02' 'E03' 'E08' 'I06' 'I07' 'J07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.438257).  Saving model ...
	 Train_Loss: 0.5406 Train_Acc: 73.616 Val_Loss: 0.4383  BEST VAL Loss: 0.4383  Val_Acc: 80.848

Epoch 1: Validation loss decreased (0.438257 --> 0.407402).  Saving model ...
	 Train_Loss: 0.4887 Train_Acc: 80.112 Val_Loss: 0.4074  BEST VAL Loss: 0.4074  Val_Acc: 83.641

Epoch 2: Validation loss decreased (0.407402 --> 0.387400).  Saving model ...
	 Train_Loss: 0.4582 Train_Acc: 82.067 Val_Loss: 0.3874  BEST VAL Loss: 0.3874  Val_Acc: 85.072

Epoch 3: Validation loss decreased (0.387400 --> 0.372756).  Saving model ...
	 Train_Loss: 0.4367 Train_Acc: 83.332 Val_Loss: 0.3728  BEST VAL Loss: 0.3728  Val_Acc: 85.805

Epoch 4: Validation loss decreased (0.372756 --> 0.361260).  Saving model ...
	 Train_Loss: 0.4208 Train_Acc: 84.129 Val_Loss: 0.3613  BEST VAL Loss: 0.3613  Val_Acc: 86.427

Epoch 5: Validation loss decreased (0.361260 --> 0.352311).  Saving model ...
	 Train_Loss: 0.4082 Train_Acc: 84.621 Val_Loss: 0.3523  BEST VAL Loss: 0.3523  Val_Acc: 86.797

Epoch 6: Validation loss decreased (0.352311 --> 0.344356).  Saving model ...
	 Train_Loss: 0.3979 Train_Acc: 85.049 Val_Loss: 0.3444  BEST VAL Loss: 0.3444  Val_Acc: 87.174

Epoch 7: Validation loss decreased (0.344356 --> 0.337058).  Saving model ...
	 Train_Loss: 0.3890 Train_Acc: 85.403 Val_Loss: 0.3371  BEST VAL Loss: 0.3371  Val_Acc: 87.828

Epoch 8: Validation loss decreased (0.337058 --> 0.331603).  Saving model ...
	 Train_Loss: 0.3814 Train_Acc: 85.608 Val_Loss: 0.3316  BEST VAL Loss: 0.3316  Val_Acc: 87.626

Epoch 9: Validation loss decreased (0.331603 --> 0.326823).  Saving model ...
	 Train_Loss: 0.3747 Train_Acc: 85.776 Val_Loss: 0.3268  BEST VAL Loss: 0.3268  Val_Acc: 87.772

Epoch 10: Validation loss decreased (0.326823 --> 0.323235).  Saving model ...
	 Train_Loss: 0.3687 Train_Acc: 86.012 Val_Loss: 0.3232  BEST VAL Loss: 0.3232  Val_Acc: 87.438

Epoch 11: Validation loss decreased (0.323235 --> 0.318773).  Saving model ...
	 Train_Loss: 0.3634 Train_Acc: 86.194 Val_Loss: 0.3188  BEST VAL Loss: 0.3188  Val_Acc: 88.344

Epoch 12: Validation loss decreased (0.318773 --> 0.314744).  Saving model ...
	 Train_Loss: 0.3585 Train_Acc: 86.276 Val_Loss: 0.3147  BEST VAL Loss: 0.3147  Val_Acc: 88.277

Epoch 13: Validation loss decreased (0.314744 --> 0.310987).  Saving model ...
	 Train_Loss: 0.3542 Train_Acc: 86.376 Val_Loss: 0.3110  BEST VAL Loss: 0.3110  Val_Acc: 88.767

Epoch 14: Validation loss decreased (0.310987 --> 0.307265).  Saving model ...
	 Train_Loss: 0.3501 Train_Acc: 86.601 Val_Loss: 0.3073  BEST VAL Loss: 0.3073  Val_Acc: 88.978

Epoch 15: Validation loss decreased (0.307265 --> 0.304429).  Saving model ...
	 Train_Loss: 0.3464 Train_Acc: 86.862 Val_Loss: 0.3044  BEST VAL Loss: 0.3044  Val_Acc: 88.595

Epoch 16: Validation loss decreased (0.304429 --> 0.301373).  Saving model ...
	 Train_Loss: 0.3430 Train_Acc: 87.099 Val_Loss: 0.3014  BEST VAL Loss: 0.3014  Val_Acc: 89.173

Epoch 17: Validation loss decreased (0.301373 --> 0.299128).  Saving model ...
	 Train_Loss: 0.3397 Train_Acc: 87.246 Val_Loss: 0.2991  BEST VAL Loss: 0.2991  Val_Acc: 89.024

Epoch 18: Validation loss decreased (0.299128 --> 0.296781).  Saving model ...
	 Train_Loss: 0.3368 Train_Acc: 87.300 Val_Loss: 0.2968  BEST VAL Loss: 0.2968  Val_Acc: 88.985

Epoch 19: Validation loss decreased (0.296781 --> 0.294331).  Saving model ...
	 Train_Loss: 0.3340 Train_Acc: 87.396 Val_Loss: 0.2943  BEST VAL Loss: 0.2943  Val_Acc: 89.408

Epoch 20: Validation loss decreased (0.294331 --> 0.292193).  Saving model ...
	 Train_Loss: 0.3314 Train_Acc: 87.367 Val_Loss: 0.2922  BEST VAL Loss: 0.2922  Val_Acc: 89.487

Epoch 21: Validation loss decreased (0.292193 --> 0.290055).  Saving model ...
	 Train_Loss: 0.3288 Train_Acc: 87.644 Val_Loss: 0.2901  BEST VAL Loss: 0.2901  Val_Acc: 89.573

Epoch 22: Validation loss decreased (0.290055 --> 0.287991).  Saving model ...
	 Train_Loss: 0.3265 Train_Acc: 87.713 Val_Loss: 0.2880  BEST VAL Loss: 0.2880  Val_Acc: 89.560

Epoch 23: Validation loss decreased (0.287991 --> 0.285999).  Saving model ...
	 Train_Loss: 0.3243 Train_Acc: 87.687 Val_Loss: 0.2860  BEST VAL Loss: 0.2860  Val_Acc: 89.649

Epoch 24: Validation loss decreased (0.285999 --> 0.284159).  Saving model ...
	 Train_Loss: 0.3223 Train_Acc: 87.707 Val_Loss: 0.2842  BEST VAL Loss: 0.2842  Val_Acc: 89.755

Epoch 25: Validation loss decreased (0.284159 --> 0.282463).  Saving model ...
	 Train_Loss: 0.3203 Train_Acc: 87.864 Val_Loss: 0.2825  BEST VAL Loss: 0.2825  Val_Acc: 89.801

Epoch 26: Validation loss decreased (0.282463 --> 0.281031).  Saving model ...
	 Train_Loss: 0.3185 Train_Acc: 87.859 Val_Loss: 0.2810  BEST VAL Loss: 0.2810  Val_Acc: 89.844

Epoch 27: Validation loss decreased (0.281031 --> 0.279630).  Saving model ...
	 Train_Loss: 0.3167 Train_Acc: 87.950 Val_Loss: 0.2796  BEST VAL Loss: 0.2796  Val_Acc: 89.652

Epoch 28: Validation loss decreased (0.279630 --> 0.278173).  Saving model ...
	 Train_Loss: 0.3151 Train_Acc: 87.959 Val_Loss: 0.2782  BEST VAL Loss: 0.2782  Val_Acc: 89.930

Epoch 29: Validation loss decreased (0.278173 --> 0.276682).  Saving model ...
	 Train_Loss: 0.3135 Train_Acc: 88.118 Val_Loss: 0.2767  BEST VAL Loss: 0.2767  Val_Acc: 90.112

Epoch 30: Validation loss decreased (0.276682 --> 0.275274).  Saving model ...
	 Train_Loss: 0.3119 Train_Acc: 88.185 Val_Loss: 0.2753  BEST VAL Loss: 0.2753  Val_Acc: 90.174

Epoch 31: Validation loss decreased (0.275274 --> 0.273929).  Saving model ...
	 Train_Loss: 0.3105 Train_Acc: 88.159 Val_Loss: 0.2739  BEST VAL Loss: 0.2739  Val_Acc: 90.383

Epoch 32: Validation loss decreased (0.273929 --> 0.272680).  Saving model ...
	 Train_Loss: 0.3091 Train_Acc: 88.135 Val_Loss: 0.2727  BEST VAL Loss: 0.2727  Val_Acc: 90.231

Epoch 33: Validation loss decreased (0.272680 --> 0.271457).  Saving model ...
	 Train_Loss: 0.3077 Train_Acc: 88.183 Val_Loss: 0.2715  BEST VAL Loss: 0.2715  Val_Acc: 90.237

Epoch 34: Validation loss decreased (0.271457 --> 0.270257).  Saving model ...
	 Train_Loss: 0.3065 Train_Acc: 88.202 Val_Loss: 0.2703  BEST VAL Loss: 0.2703  Val_Acc: 90.231

Epoch 35: Validation loss decreased (0.270257 --> 0.269173).  Saving model ...
	 Train_Loss: 0.3052 Train_Acc: 88.291 Val_Loss: 0.2692  BEST VAL Loss: 0.2692  Val_Acc: 90.198

Epoch 36: Validation loss decreased (0.269173 --> 0.268087).  Saving model ...
	 Train_Loss: 0.3041 Train_Acc: 88.230 Val_Loss: 0.2681  BEST VAL Loss: 0.2681  Val_Acc: 90.356

Epoch 37: Validation loss decreased (0.268087 --> 0.267111).  Saving model ...
	 Train_Loss: 0.3029 Train_Acc: 88.305 Val_Loss: 0.2671  BEST VAL Loss: 0.2671  Val_Acc: 90.343

Epoch 38: Validation loss decreased (0.267111 --> 0.266086).  Saving model ...
	 Train_Loss: 0.3018 Train_Acc: 88.439 Val_Loss: 0.2661  BEST VAL Loss: 0.2661  Val_Acc: 90.376

Epoch 39: Validation loss decreased (0.266086 --> 0.265099).  Saving model ...
	 Train_Loss: 0.3008 Train_Acc: 88.307 Val_Loss: 0.2651  BEST VAL Loss: 0.2651  Val_Acc: 90.416

Epoch 40: Validation loss decreased (0.265099 --> 0.264161).  Saving model ...
	 Train_Loss: 0.2997 Train_Acc: 88.482 Val_Loss: 0.2642  BEST VAL Loss: 0.2642  Val_Acc: 90.505

Epoch 41: Validation loss decreased (0.264161 --> 0.263272).  Saving model ...
	 Train_Loss: 0.2988 Train_Acc: 88.380 Val_Loss: 0.2633  BEST VAL Loss: 0.2633  Val_Acc: 90.330

Epoch 42: Validation loss decreased (0.263272 --> 0.262409).  Saving model ...
	 Train_Loss: 0.2978 Train_Acc: 88.445 Val_Loss: 0.2624  BEST VAL Loss: 0.2624  Val_Acc: 90.495

Epoch 43: Validation loss decreased (0.262409 --> 0.261552).  Saving model ...
	 Train_Loss: 0.2970 Train_Acc: 88.359 Val_Loss: 0.2616  BEST VAL Loss: 0.2616  Val_Acc: 90.518

Epoch 44: Validation loss decreased (0.261552 --> 0.260877).  Saving model ...
	 Train_Loss: 0.2961 Train_Acc: 88.556 Val_Loss: 0.2609  BEST VAL Loss: 0.2609  Val_Acc: 90.260

Epoch 45: Validation loss decreased (0.260877 --> 0.260071).  Saving model ...
	 Train_Loss: 0.2952 Train_Acc: 88.518 Val_Loss: 0.2601  BEST VAL Loss: 0.2601  Val_Acc: 90.654

Epoch 46: Validation loss decreased (0.260071 --> 0.259331).  Saving model ...
	 Train_Loss: 0.2944 Train_Acc: 88.546 Val_Loss: 0.2593  BEST VAL Loss: 0.2593  Val_Acc: 90.508

Epoch 47: Validation loss decreased (0.259331 --> 0.258578).  Saving model ...
	 Train_Loss: 0.2936 Train_Acc: 88.518 Val_Loss: 0.2586  BEST VAL Loss: 0.2586  Val_Acc: 90.568

Epoch 48: Validation loss decreased (0.258578 --> 0.257893).  Saving model ...
	 Train_Loss: 0.2928 Train_Acc: 88.539 Val_Loss: 0.2579  BEST VAL Loss: 0.2579  Val_Acc: 90.522

Epoch 49: Validation loss decreased (0.257893 --> 0.257207).  Saving model ...
	 Train_Loss: 0.2920 Train_Acc: 88.608 Val_Loss: 0.2572  BEST VAL Loss: 0.2572  Val_Acc: 90.631

Epoch 50: Validation loss decreased (0.257207 --> 0.256555).  Saving model ...
	 Train_Loss: 0.2912 Train_Acc: 88.630 Val_Loss: 0.2566  BEST VAL Loss: 0.2566  Val_Acc: 90.604

Epoch 51: Validation loss decreased (0.256555 --> 0.255918).  Saving model ...
	 Train_Loss: 0.2905 Train_Acc: 88.548 Val_Loss: 0.2559  BEST VAL Loss: 0.2559  Val_Acc: 90.607

Epoch 52: Validation loss decreased (0.255918 --> 0.255301).  Saving model ...
	 Train_Loss: 0.2898 Train_Acc: 88.543 Val_Loss: 0.2553  BEST VAL Loss: 0.2553  Val_Acc: 90.667

Epoch 53: Validation loss decreased (0.255301 --> 0.254771).  Saving model ...
	 Train_Loss: 0.2892 Train_Acc: 88.608 Val_Loss: 0.2548  BEST VAL Loss: 0.2548  Val_Acc: 90.386

Epoch 54: Validation loss decreased (0.254771 --> 0.254204).  Saving model ...
	 Train_Loss: 0.2885 Train_Acc: 88.656 Val_Loss: 0.2542  BEST VAL Loss: 0.2542  Val_Acc: 90.650

Epoch 55: Validation loss decreased (0.254204 --> 0.253564).  Saving model ...
	 Train_Loss: 0.2879 Train_Acc: 88.611 Val_Loss: 0.2536  BEST VAL Loss: 0.2536  Val_Acc: 90.816

Epoch 56: Validation loss decreased (0.253564 --> 0.252996).  Saving model ...
	 Train_Loss: 0.2872 Train_Acc: 88.680 Val_Loss: 0.2530  BEST VAL Loss: 0.2530  Val_Acc: 90.756

Epoch 57: Validation loss decreased (0.252996 --> 0.252491).  Saving model ...
	 Train_Loss: 0.2866 Train_Acc: 88.749 Val_Loss: 0.2525  BEST VAL Loss: 0.2525  Val_Acc: 90.601

Epoch 58: Validation loss decreased (0.252491 --> 0.251955).  Saving model ...
	 Train_Loss: 0.2860 Train_Acc: 88.749 Val_Loss: 0.2520  BEST VAL Loss: 0.2520  Val_Acc: 90.743

Epoch 59: Validation loss decreased (0.251955 --> 0.251436).  Saving model ...
	 Train_Loss: 0.2854 Train_Acc: 88.713 Val_Loss: 0.2514  BEST VAL Loss: 0.2514  Val_Acc: 90.753

Epoch 60: Validation loss decreased (0.251436 --> 0.250929).  Saving model ...
	 Train_Loss: 0.2849 Train_Acc: 88.753 Val_Loss: 0.2509  BEST VAL Loss: 0.2509  Val_Acc: 90.697

Epoch 61: Validation loss decreased (0.250929 --> 0.250433).  Saving model ...
	 Train_Loss: 0.2843 Train_Acc: 88.714 Val_Loss: 0.2504  BEST VAL Loss: 0.2504  Val_Acc: 90.713

Epoch 62: Validation loss decreased (0.250433 --> 0.250010).  Saving model ...
	 Train_Loss: 0.2838 Train_Acc: 88.841 Val_Loss: 0.2500  BEST VAL Loss: 0.2500  Val_Acc: 90.604

Epoch 63: Validation loss decreased (0.250010 --> 0.249549).  Saving model ...
	 Train_Loss: 0.2832 Train_Acc: 88.753 Val_Loss: 0.2495  BEST VAL Loss: 0.2495  Val_Acc: 90.769

Epoch 64: Validation loss decreased (0.249549 --> 0.249099).  Saving model ...
	 Train_Loss: 0.2827 Train_Acc: 88.785 Val_Loss: 0.2491  BEST VAL Loss: 0.2491  Val_Acc: 90.875

Epoch 65: Validation loss decreased (0.249099 --> 0.248745).  Saving model ...
	 Train_Loss: 0.2822 Train_Acc: 88.787 Val_Loss: 0.2487  BEST VAL Loss: 0.2487  Val_Acc: 90.736

Epoch 66: Validation loss decreased (0.248745 --> 0.248390).  Saving model ...
	 Train_Loss: 0.2817 Train_Acc: 88.775 Val_Loss: 0.2484  BEST VAL Loss: 0.2484  Val_Acc: 90.707

Epoch 67: Validation loss decreased (0.248390 --> 0.247940).  Saving model ...
	 Train_Loss: 0.2812 Train_Acc: 88.770 Val_Loss: 0.2479  BEST VAL Loss: 0.2479  Val_Acc: 90.885

Epoch 68: Validation loss decreased (0.247940 --> 0.247539).  Saving model ...
	 Train_Loss: 0.2808 Train_Acc: 88.822 Val_Loss: 0.2475  BEST VAL Loss: 0.2475  Val_Acc: 90.687

Epoch 69: Validation loss decreased (0.247539 --> 0.247141).  Saving model ...
	 Train_Loss: 0.2803 Train_Acc: 88.835 Val_Loss: 0.2471  BEST VAL Loss: 0.2471  Val_Acc: 90.726

Epoch 70: Validation loss decreased (0.247141 --> 0.246698).  Saving model ...
	 Train_Loss: 0.2798 Train_Acc: 88.887 Val_Loss: 0.2467  BEST VAL Loss: 0.2467  Val_Acc: 90.869

Epoch 71: Validation loss decreased (0.246698 --> 0.246281).  Saving model ...
	 Train_Loss: 0.2794 Train_Acc: 88.903 Val_Loss: 0.2463  BEST VAL Loss: 0.2463  Val_Acc: 90.832

Epoch 72: Validation loss decreased (0.246281 --> 0.245870).  Saving model ...
	 Train_Loss: 0.2790 Train_Acc: 88.796 Val_Loss: 0.2459  BEST VAL Loss: 0.2459  Val_Acc: 90.954

Epoch 73: Validation loss decreased (0.245870 --> 0.245502).  Saving model ...
	 Train_Loss: 0.2785 Train_Acc: 88.833 Val_Loss: 0.2455  BEST VAL Loss: 0.2455  Val_Acc: 90.845

Epoch 74: Validation loss decreased (0.245502 --> 0.245103).  Saving model ...
	 Train_Loss: 0.2781 Train_Acc: 88.863 Val_Loss: 0.2451  BEST VAL Loss: 0.2451  Val_Acc: 90.951

Epoch 75: Validation loss decreased (0.245103 --> 0.244733).  Saving model ...
	 Train_Loss: 0.2777 Train_Acc: 88.840 Val_Loss: 0.2447  BEST VAL Loss: 0.2447  Val_Acc: 90.819

Epoch 76: Validation loss decreased (0.244733 --> 0.244364).  Saving model ...
	 Train_Loss: 0.2773 Train_Acc: 88.847 Val_Loss: 0.2444  BEST VAL Loss: 0.2444  Val_Acc: 90.968

Epoch 77: Validation loss decreased (0.244364 --> 0.244002).  Saving model ...
	 Train_Loss: 0.2769 Train_Acc: 88.844 Val_Loss: 0.2440  BEST VAL Loss: 0.2440  Val_Acc: 90.855

Epoch 78: Validation loss decreased (0.244002 --> 0.243673).  Saving model ...
	 Train_Loss: 0.2765 Train_Acc: 88.900 Val_Loss: 0.2437  BEST VAL Loss: 0.2437  Val_Acc: 90.862

Epoch 79: Validation loss decreased (0.243673 --> 0.243393).  Saving model ...
	 Train_Loss: 0.2762 Train_Acc: 88.892 Val_Loss: 0.2434  BEST VAL Loss: 0.2434  Val_Acc: 90.598

Epoch 80: Validation loss decreased (0.243393 --> 0.243049).  Saving model ...
	 Train_Loss: 0.2758 Train_Acc: 88.905 Val_Loss: 0.2430  BEST VAL Loss: 0.2430  Val_Acc: 91.126

Epoch 81: Validation loss decreased (0.243049 --> 0.242735).  Saving model ...
	 Train_Loss: 0.2754 Train_Acc: 88.872 Val_Loss: 0.2427  BEST VAL Loss: 0.2427  Val_Acc: 90.875

Epoch 82: Validation loss decreased (0.242735 --> 0.242445).  Saving model ...
	 Train_Loss: 0.2751 Train_Acc: 88.947 Val_Loss: 0.2424  BEST VAL Loss: 0.2424  Val_Acc: 90.852

Epoch 83: Validation loss decreased (0.242445 --> 0.242139).  Saving model ...
	 Train_Loss: 0.2747 Train_Acc: 88.942 Val_Loss: 0.2421  BEST VAL Loss: 0.2421  Val_Acc: 90.988

Epoch 84: Validation loss decreased (0.242139 --> 0.241818).  Saving model ...
	 Train_Loss: 0.2744 Train_Acc: 89.009 Val_Loss: 0.2418  BEST VAL Loss: 0.2418  Val_Acc: 90.954

Epoch 85: Validation loss decreased (0.241818 --> 0.241558).  Saving model ...
	 Train_Loss: 0.2740 Train_Acc: 88.915 Val_Loss: 0.2416  BEST VAL Loss: 0.2416  Val_Acc: 90.984

Epoch 86: Validation loss decreased (0.241558 --> 0.241248).  Saving model ...
	 Train_Loss: 0.2737 Train_Acc: 88.908 Val_Loss: 0.2412  BEST VAL Loss: 0.2412  Val_Acc: 91.087

Epoch 87: Validation loss decreased (0.241248 --> 0.240996).  Saving model ...
	 Train_Loss: 0.2734 Train_Acc: 88.982 Val_Loss: 0.2410  BEST VAL Loss: 0.2410  Val_Acc: 90.743

Epoch 88: Validation loss decreased (0.240996 --> 0.240718).  Saving model ...
	 Train_Loss: 0.2730 Train_Acc: 88.942 Val_Loss: 0.2407  BEST VAL Loss: 0.2407  Val_Acc: 91.077

Epoch 89: Validation loss decreased (0.240718 --> 0.240426).  Saving model ...
	 Train_Loss: 0.2727 Train_Acc: 88.994 Val_Loss: 0.2404  BEST VAL Loss: 0.2404  Val_Acc: 91.070

Epoch 90: Validation loss decreased (0.240426 --> 0.240146).  Saving model ...
	 Train_Loss: 0.2724 Train_Acc: 88.939 Val_Loss: 0.2401  BEST VAL Loss: 0.2401  Val_Acc: 91.116

Epoch 91: Validation loss decreased (0.240146 --> 0.239882).  Saving model ...
	 Train_Loss: 0.2721 Train_Acc: 89.005 Val_Loss: 0.2399  BEST VAL Loss: 0.2399  Val_Acc: 91.024

Epoch 92: Validation loss decreased (0.239882 --> 0.239624).  Saving model ...
	 Train_Loss: 0.2718 Train_Acc: 88.984 Val_Loss: 0.2396  BEST VAL Loss: 0.2396  Val_Acc: 91.014

Epoch 93: Validation loss decreased (0.239624 --> 0.239369).  Saving model ...
	 Train_Loss: 0.2715 Train_Acc: 88.986 Val_Loss: 0.2394  BEST VAL Loss: 0.2394  Val_Acc: 90.974

Epoch 94: Validation loss decreased (0.239369 --> 0.239106).  Saving model ...
	 Train_Loss: 0.2712 Train_Acc: 89.041 Val_Loss: 0.2391  BEST VAL Loss: 0.2391  Val_Acc: 91.083

Epoch 95: Validation loss decreased (0.239106 --> 0.238865).  Saving model ...
	 Train_Loss: 0.2709 Train_Acc: 88.987 Val_Loss: 0.2389  BEST VAL Loss: 0.2389  Val_Acc: 91.054

Epoch 96: Validation loss decreased (0.238865 --> 0.238771).  Saving model ...
	 Train_Loss: 0.2706 Train_Acc: 89.005 Val_Loss: 0.2388  BEST VAL Loss: 0.2388  Val_Acc: 90.984

Epoch 97: Validation loss decreased (0.238771 --> 0.238529).  Saving model ...
	 Train_Loss: 0.2704 Train_Acc: 88.994 Val_Loss: 0.2385  BEST VAL Loss: 0.2385  Val_Acc: 91.140

Epoch 98: Validation loss decreased (0.238529 --> 0.238337).  Saving model ...
	 Train_Loss: 0.2701 Train_Acc: 88.969 Val_Loss: 0.2383  BEST VAL Loss: 0.2383  Val_Acc: 90.740

Epoch 99: Validation loss decreased (0.238337 --> 0.238083).  Saving model ...
	 Train_Loss: 0.2698 Train_Acc: 89.115 Val_Loss: 0.2381  BEST VAL Loss: 0.2381  Val_Acc: 91.186

LPS_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.94      0.94      0.94    149884
           1       0.90      0.91      0.90     92173

    accuracy                           0.93    242057
   macro avg       0.92      0.92      0.92    242057
weighted avg       0.93      0.93      0.93    242057

LPS_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.93      0.93     18736
           1       0.88      0.89      0.88     11522

    accuracy                           0.91     30258
   macro avg       0.91      0.91      0.91     30258
weighted avg       0.91      0.91      0.91     30258

LPS_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.93      0.93     18736
           1       0.88      0.89      0.89     11522

    accuracy                           0.91     30258
   macro avg       0.91      0.91      0.91     30258
weighted avg       0.91      0.91      0.91     30258

              precision    recall  f1-score   support

           0       0.93      0.93      0.93     18736
           1       0.88      0.89      0.89     11522

    accuracy                           0.91     30258
   macro avg       0.91      0.91      0.91     30258
weighted avg       0.91      0.91      0.91     30258

LPS_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.65      0.86      0.74     27774
           1       0.88      0.69      0.77     41273

    accuracy                           0.75     69047
   macro avg       0.76      0.77      0.75     69047
weighted avg       0.78      0.75      0.76     69047

              precision    recall  f1-score   support

           0       0.65      0.86      0.74     27774
           1       0.88      0.69      0.77     41273

    accuracy                           0.75     69047
   macro avg       0.76      0.77      0.75     69047
weighted avg       0.78      0.75      0.76     69047

completed
