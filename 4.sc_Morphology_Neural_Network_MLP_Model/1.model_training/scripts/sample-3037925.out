[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '706bfef5'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '61733828'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'c5cbdd8c'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'aec4f0b6'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Thapsigargin_1.000_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Thapsigargin_1.000_DMSO_0.025
TREATMENT_NAME: Flagellin_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (253003, 1270)
Number of total missing values across all columns: 542622
Data Subset Is Off
Wells held out for testing: ['K07' 'M10']
Wells to use for training, validation, and testing ['D06' 'D07' 'K06' 'M05' 'M11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.581070).  Saving model ...
	 Train_Loss: 0.6414 Train_Acc: 61.043 Val_Loss: 0.5811  BEST VAL Loss: 0.5811  Val_Acc: 69.531

Epoch 1: Validation loss decreased (0.581070 --> 0.536933).  Saving model ...
	 Train_Loss: 0.5945 Train_Acc: 70.790 Val_Loss: 0.5369  BEST VAL Loss: 0.5369  Val_Acc: 76.719

Epoch 2: Validation loss decreased (0.536933 --> 0.512986).  Saving model ...
	 Train_Loss: 0.5598 Train_Acc: 75.157 Val_Loss: 0.5130  BEST VAL Loss: 0.5130  Val_Acc: 78.102

Epoch 3: Validation loss did not decrease
	 Train_Loss: 0.5373 Train_Acc: 76.556 Val_Loss: 0.5137  BEST VAL Loss: 0.5130  Val_Acc: 74.688

Epoch 4: Validation loss decreased (0.512986 --> 0.498707).  Saving model ...
	 Train_Loss: 0.5211 Train_Acc: 77.281 Val_Loss: 0.4987  BEST VAL Loss: 0.4987  Val_Acc: 79.151

Epoch 5: Validation loss decreased (0.498707 --> 0.488974).  Saving model ...
	 Train_Loss: 0.5085 Train_Acc: 77.799 Val_Loss: 0.4890  BEST VAL Loss: 0.4890  Val_Acc: 78.684

Epoch 6: Validation loss decreased (0.488974 --> 0.479037).  Saving model ...
	 Train_Loss: 0.4984 Train_Acc: 78.144 Val_Loss: 0.4790  BEST VAL Loss: 0.4790  Val_Acc: 80.666

Epoch 7: Validation loss decreased (0.479037 --> 0.470164).  Saving model ...
	 Train_Loss: 0.4898 Train_Acc: 78.654 Val_Loss: 0.4702  BEST VAL Loss: 0.4702  Val_Acc: 80.350

Epoch 8: Validation loss decreased (0.470164 --> 0.467890).  Saving model ...
	 Train_Loss: 0.4825 Train_Acc: 78.781 Val_Loss: 0.4679  BEST VAL Loss: 0.4679  Val_Acc: 78.651

Epoch 9: Validation loss decreased (0.467890 --> 0.463431).  Saving model ...
	 Train_Loss: 0.4762 Train_Acc: 79.036 Val_Loss: 0.4634  BEST VAL Loss: 0.4634  Val_Acc: 78.995

Epoch 10: Validation loss decreased (0.463431 --> 0.457589).  Saving model ...
	 Train_Loss: 0.4706 Train_Acc: 79.200 Val_Loss: 0.4576  BEST VAL Loss: 0.4576  Val_Acc: 82.115

Epoch 11: Validation loss decreased (0.457589 --> 0.451575).  Saving model ...
	 Train_Loss: 0.4653 Train_Acc: 79.492 Val_Loss: 0.4516  BEST VAL Loss: 0.4516  Val_Acc: 82.176

Epoch 12: Validation loss decreased (0.451575 --> 0.446131).  Saving model ...
	 Train_Loss: 0.4607 Train_Acc: 79.527 Val_Loss: 0.4461  BEST VAL Loss: 0.4461  Val_Acc: 81.343

Epoch 13: Validation loss decreased (0.446131 --> 0.440697).  Saving model ...
	 Train_Loss: 0.4564 Train_Acc: 79.788 Val_Loss: 0.4407  BEST VAL Loss: 0.4407  Val_Acc: 83.397

Epoch 14: Validation loss decreased (0.440697 --> 0.435724).  Saving model ...
	 Train_Loss: 0.4527 Train_Acc: 79.816 Val_Loss: 0.4357  BEST VAL Loss: 0.4357  Val_Acc: 83.397

Epoch 15: Validation loss decreased (0.435724 --> 0.432802).  Saving model ...
	 Train_Loss: 0.4491 Train_Acc: 80.070 Val_Loss: 0.4328  BEST VAL Loss: 0.4328  Val_Acc: 81.060

Epoch 16: Validation loss decreased (0.432802 --> 0.430088).  Saving model ...
	 Train_Loss: 0.4459 Train_Acc: 80.265 Val_Loss: 0.4301  BEST VAL Loss: 0.4301  Val_Acc: 83.081

Epoch 17: Validation loss did not decrease
	 Train_Loss: 0.4430 Train_Acc: 80.625 Val_Loss: 0.4301  BEST VAL Loss: 0.4301  Val_Acc: 80.211

Epoch 18: Validation loss decreased (0.430088 --> 0.429149).  Saving model ...
	 Train_Loss: 0.4402 Train_Acc: 80.950 Val_Loss: 0.4291  BEST VAL Loss: 0.4291  Val_Acc: 81.266

Epoch 19: Validation loss decreased (0.429149 --> 0.427879).  Saving model ...
	 Train_Loss: 0.4377 Train_Acc: 80.849 Val_Loss: 0.4279  BEST VAL Loss: 0.4279  Val_Acc: 81.060

Epoch 20: Validation loss decreased (0.427879 --> 0.425396).  Saving model ...
	 Train_Loss: 0.4352 Train_Acc: 81.008 Val_Loss: 0.4254  BEST VAL Loss: 0.4254  Val_Acc: 81.482

Epoch 21: Validation loss decreased (0.425396 --> 0.424468).  Saving model ...
	 Train_Loss: 0.4330 Train_Acc: 81.029 Val_Loss: 0.4245  BEST VAL Loss: 0.4245  Val_Acc: 82.043

Epoch 22: Validation loss decreased (0.424468 --> 0.422532).  Saving model ...
	 Train_Loss: 0.4309 Train_Acc: 81.133 Val_Loss: 0.4225  BEST VAL Loss: 0.4225  Val_Acc: 82.398

Epoch 23: Validation loss decreased (0.422532 --> 0.419844).  Saving model ...
	 Train_Loss: 0.4288 Train_Acc: 81.223 Val_Loss: 0.4198  BEST VAL Loss: 0.4198  Val_Acc: 83.075

Epoch 24: Validation loss decreased (0.419844 --> 0.418013).  Saving model ...
	 Train_Loss: 0.4270 Train_Acc: 81.311 Val_Loss: 0.4180  BEST VAL Loss: 0.4180  Val_Acc: 82.415

Epoch 25: Validation loss decreased (0.418013 --> 0.415889).  Saving model ...
	 Train_Loss: 0.4251 Train_Acc: 81.447 Val_Loss: 0.4159  BEST VAL Loss: 0.4159  Val_Acc: 83.086

Epoch 26: Validation loss decreased (0.415889 --> 0.413499).  Saving model ...
	 Train_Loss: 0.4234 Train_Acc: 81.431 Val_Loss: 0.4135  BEST VAL Loss: 0.4135  Val_Acc: 83.536

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.4218 Train_Acc: 81.480 Val_Loss: 0.4144  BEST VAL Loss: 0.4135  Val_Acc: 78.834

Epoch 28: Validation loss decreased (0.413499 --> 0.412834).  Saving model ...
	 Train_Loss: 0.4202 Train_Acc: 81.522 Val_Loss: 0.4128  BEST VAL Loss: 0.4128  Val_Acc: 82.442

Epoch 29: Validation loss decreased (0.412834 --> 0.411455).  Saving model ...
	 Train_Loss: 0.4188 Train_Acc: 81.586 Val_Loss: 0.4115  BEST VAL Loss: 0.4115  Val_Acc: 83.653

Epoch 30: Validation loss decreased (0.411455 --> 0.409828).  Saving model ...
	 Train_Loss: 0.4174 Train_Acc: 81.567 Val_Loss: 0.4098  BEST VAL Loss: 0.4098  Val_Acc: 82.637

Epoch 31: Validation loss decreased (0.409828 --> 0.408641).  Saving model ...
	 Train_Loss: 0.4160 Train_Acc: 81.800 Val_Loss: 0.4086  BEST VAL Loss: 0.4086  Val_Acc: 82.992

Epoch 32: Validation loss decreased (0.408641 --> 0.407666).  Saving model ...
	 Train_Loss: 0.4147 Train_Acc: 81.684 Val_Loss: 0.4077  BEST VAL Loss: 0.4077  Val_Acc: 82.687

Epoch 33: Validation loss decreased (0.407666 --> 0.405971).  Saving model ...
	 Train_Loss: 0.4135 Train_Acc: 81.846 Val_Loss: 0.4060  BEST VAL Loss: 0.4060  Val_Acc: 83.708

Epoch 34: Validation loss decreased (0.405971 --> 0.404842).  Saving model ...
	 Train_Loss: 0.4123 Train_Acc: 81.928 Val_Loss: 0.4048  BEST VAL Loss: 0.4048  Val_Acc: 82.925

Epoch 35: Validation loss decreased (0.404842 --> 0.403783).  Saving model ...
	 Train_Loss: 0.4111 Train_Acc: 81.964 Val_Loss: 0.4038  BEST VAL Loss: 0.4038  Val_Acc: 82.526

Epoch 36: Validation loss decreased (0.403783 --> 0.402460).  Saving model ...
	 Train_Loss: 0.4100 Train_Acc: 82.042 Val_Loss: 0.4025  BEST VAL Loss: 0.4025  Val_Acc: 83.175

Epoch 37: Validation loss decreased (0.402460 --> 0.401836).  Saving model ...
	 Train_Loss: 0.4090 Train_Acc: 82.261 Val_Loss: 0.4018  BEST VAL Loss: 0.4018  Val_Acc: 83.308

Epoch 38: Validation loss decreased (0.401836 --> 0.400152).  Saving model ...
	 Train_Loss: 0.4079 Train_Acc: 82.200 Val_Loss: 0.4002  BEST VAL Loss: 0.4002  Val_Acc: 83.875

Epoch 39: Validation loss decreased (0.400152 --> 0.398754).  Saving model ...
	 Train_Loss: 0.4069 Train_Acc: 82.368 Val_Loss: 0.3988  BEST VAL Loss: 0.3988  Val_Acc: 84.063

Epoch 40: Validation loss decreased (0.398754 --> 0.397852).  Saving model ...
	 Train_Loss: 0.4059 Train_Acc: 82.299 Val_Loss: 0.3979  BEST VAL Loss: 0.3979  Val_Acc: 83.114

Epoch 41: Validation loss decreased (0.397852 --> 0.396612).  Saving model ...
	 Train_Loss: 0.4051 Train_Acc: 82.272 Val_Loss: 0.3966  BEST VAL Loss: 0.3966  Val_Acc: 83.319

Epoch 42: Validation loss decreased (0.396612 --> 0.395793).  Saving model ...
	 Train_Loss: 0.4042 Train_Acc: 82.353 Val_Loss: 0.3958  BEST VAL Loss: 0.3958  Val_Acc: 83.319

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.4033 Train_Acc: 82.399 Val_Loss: 0.3969  BEST VAL Loss: 0.3958  Val_Acc: 79.700

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.4025 Train_Acc: 82.404 Val_Loss: 0.3960  BEST VAL Loss: 0.3958  Val_Acc: 84.296

Epoch 45: Validation loss decreased (0.395793 --> 0.394979).  Saving model ...
	 Train_Loss: 0.4016 Train_Acc: 82.524 Val_Loss: 0.3950  BEST VAL Loss: 0.3950  Val_Acc: 83.264

Epoch 46: Validation loss decreased (0.394979 --> 0.393909).  Saving model ...
	 Train_Loss: 0.4008 Train_Acc: 82.600 Val_Loss: 0.3939  BEST VAL Loss: 0.3939  Val_Acc: 84.252

Epoch 47: Validation loss decreased (0.393909 --> 0.393326).  Saving model ...
	 Train_Loss: 0.4000 Train_Acc: 82.603 Val_Loss: 0.3933  BEST VAL Loss: 0.3933  Val_Acc: 83.342

Epoch 48: Validation loss decreased (0.393326 --> 0.392731).  Saving model ...
	 Train_Loss: 0.3992 Train_Acc: 82.533 Val_Loss: 0.3927  BEST VAL Loss: 0.3927  Val_Acc: 82.648

Epoch 49: Validation loss decreased (0.392731 --> 0.391556).  Saving model ...
	 Train_Loss: 0.3985 Train_Acc: 82.655 Val_Loss: 0.3916  BEST VAL Loss: 0.3916  Val_Acc: 84.485

Epoch 50: Validation loss decreased (0.391556 --> 0.390622).  Saving model ...
	 Train_Loss: 0.3978 Train_Acc: 82.674 Val_Loss: 0.3906  BEST VAL Loss: 0.3906  Val_Acc: 83.797

Epoch 51: Validation loss decreased (0.390622 --> 0.389407).  Saving model ...
	 Train_Loss: 0.3971 Train_Acc: 82.649 Val_Loss: 0.3894  BEST VAL Loss: 0.3894  Val_Acc: 84.541

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.3965 Train_Acc: 82.601 Val_Loss: 0.3894  BEST VAL Loss: 0.3894  Val_Acc: 82.720

Epoch 53: Validation loss decreased (0.389407 --> 0.389375).  Saving model ...
	 Train_Loss: 0.3958 Train_Acc: 82.644 Val_Loss: 0.3894  BEST VAL Loss: 0.3894  Val_Acc: 82.004

Epoch 54: Validation loss decreased (0.389375 --> 0.388283).  Saving model ...
	 Train_Loss: 0.3952 Train_Acc: 82.763 Val_Loss: 0.3883  BEST VAL Loss: 0.3883  Val_Acc: 84.840

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.3945 Train_Acc: 82.745 Val_Loss: 0.3883  BEST VAL Loss: 0.3883  Val_Acc: 82.143

Epoch 56: Validation loss decreased (0.388283 --> 0.388217).  Saving model ...
	 Train_Loss: 0.3939 Train_Acc: 82.714 Val_Loss: 0.3882  BEST VAL Loss: 0.3882  Val_Acc: 82.798

Epoch 57: Validation loss decreased (0.388217 --> 0.387693).  Saving model ...
	 Train_Loss: 0.3933 Train_Acc: 82.695 Val_Loss: 0.3877  BEST VAL Loss: 0.3877  Val_Acc: 83.447

Epoch 58: Validation loss decreased (0.387693 --> 0.387122).  Saving model ...
	 Train_Loss: 0.3927 Train_Acc: 82.886 Val_Loss: 0.3871  BEST VAL Loss: 0.3871  Val_Acc: 83.813

Epoch 59: Validation loss decreased (0.387122 --> 0.386299).  Saving model ...
	 Train_Loss: 0.3922 Train_Acc: 82.833 Val_Loss: 0.3863  BEST VAL Loss: 0.3863  Val_Acc: 84.585

Epoch 60: Validation loss decreased (0.386299 --> 0.385716).  Saving model ...
	 Train_Loss: 0.3916 Train_Acc: 82.850 Val_Loss: 0.3857  BEST VAL Loss: 0.3857  Val_Acc: 84.507

Epoch 61: Validation loss decreased (0.385716 --> 0.385218).  Saving model ...
	 Train_Loss: 0.3910 Train_Acc: 82.864 Val_Loss: 0.3852  BEST VAL Loss: 0.3852  Val_Acc: 83.303

Epoch 62: Validation loss decreased (0.385218 --> 0.384733).  Saving model ...
	 Train_Loss: 0.3905 Train_Acc: 82.910 Val_Loss: 0.3847  BEST VAL Loss: 0.3847  Val_Acc: 83.752

Epoch 63: Validation loss decreased (0.384733 --> 0.384106).  Saving model ...
	 Train_Loss: 0.3900 Train_Acc: 83.035 Val_Loss: 0.3841  BEST VAL Loss: 0.3841  Val_Acc: 84.468

Epoch 64: Validation loss decreased (0.384106 --> 0.383465).  Saving model ...
	 Train_Loss: 0.3895 Train_Acc: 82.982 Val_Loss: 0.3835  BEST VAL Loss: 0.3835  Val_Acc: 85.201

Epoch 65: Validation loss decreased (0.383465 --> 0.382652).  Saving model ...
	 Train_Loss: 0.3890 Train_Acc: 83.019 Val_Loss: 0.3827  BEST VAL Loss: 0.3827  Val_Acc: 84.607

Epoch 66: Validation loss decreased (0.382652 --> 0.381927).  Saving model ...
	 Train_Loss: 0.3885 Train_Acc: 82.920 Val_Loss: 0.3819  BEST VAL Loss: 0.3819  Val_Acc: 84.652

Epoch 67: Validation loss decreased (0.381927 --> 0.381112).  Saving model ...
	 Train_Loss: 0.3880 Train_Acc: 82.921 Val_Loss: 0.3811  BEST VAL Loss: 0.3811  Val_Acc: 84.702

Epoch 68: Validation loss decreased (0.381112 --> 0.380900).  Saving model ...
	 Train_Loss: 0.3875 Train_Acc: 83.009 Val_Loss: 0.3809  BEST VAL Loss: 0.3809  Val_Acc: 82.759

Epoch 69: Validation loss decreased (0.380900 --> 0.380307).  Saving model ...
	 Train_Loss: 0.3871 Train_Acc: 83.143 Val_Loss: 0.3803  BEST VAL Loss: 0.3803  Val_Acc: 84.635

Epoch 70: Validation loss decreased (0.380307 --> 0.379753).  Saving model ...
	 Train_Loss: 0.3866 Train_Acc: 83.266 Val_Loss: 0.3798  BEST VAL Loss: 0.3798  Val_Acc: 85.012

Epoch 71: Validation loss decreased (0.379753 --> 0.379613).  Saving model ...
	 Train_Loss: 0.3861 Train_Acc: 83.050 Val_Loss: 0.3796  BEST VAL Loss: 0.3796  Val_Acc: 82.542

Epoch 72: Validation loss decreased (0.379613 --> 0.378925).  Saving model ...
	 Train_Loss: 0.3857 Train_Acc: 83.077 Val_Loss: 0.3789  BEST VAL Loss: 0.3789  Val_Acc: 84.446

Epoch 73: Validation loss decreased (0.378925 --> 0.378441).  Saving model ...
	 Train_Loss: 0.3853 Train_Acc: 83.042 Val_Loss: 0.3784  BEST VAL Loss: 0.3784  Val_Acc: 84.363

Epoch 74: Validation loss decreased (0.378441 --> 0.378158).  Saving model ...
	 Train_Loss: 0.3849 Train_Acc: 83.046 Val_Loss: 0.3782  BEST VAL Loss: 0.3782  Val_Acc: 83.847

Epoch 75: Validation loss decreased (0.378158 --> 0.377921).  Saving model ...
	 Train_Loss: 0.3845 Train_Acc: 82.900 Val_Loss: 0.3779  BEST VAL Loss: 0.3779  Val_Acc: 82.598

Epoch 76: Validation loss decreased (0.377921 --> 0.377529).  Saving model ...
	 Train_Loss: 0.3841 Train_Acc: 83.179 Val_Loss: 0.3775  BEST VAL Loss: 0.3775  Val_Acc: 84.580

Epoch 77: Validation loss decreased (0.377529 --> 0.377185).  Saving model ...
	 Train_Loss: 0.3837 Train_Acc: 83.204 Val_Loss: 0.3772  BEST VAL Loss: 0.3772  Val_Acc: 82.953

Epoch 78: Validation loss decreased (0.377185 --> 0.376644).  Saving model ...
	 Train_Loss: 0.3833 Train_Acc: 83.106 Val_Loss: 0.3766  BEST VAL Loss: 0.3766  Val_Acc: 84.324

Epoch 79: Validation loss decreased (0.376644 --> 0.376181).  Saving model ...
	 Train_Loss: 0.3829 Train_Acc: 83.155 Val_Loss: 0.3762  BEST VAL Loss: 0.3762  Val_Acc: 84.974

Epoch 80: Validation loss decreased (0.376181 --> 0.375519).  Saving model ...
	 Train_Loss: 0.3826 Train_Acc: 83.174 Val_Loss: 0.3755  BEST VAL Loss: 0.3755  Val_Acc: 84.996

Epoch 81: Validation loss decreased (0.375519 --> 0.374985).  Saving model ...
	 Train_Loss: 0.3822 Train_Acc: 83.154 Val_Loss: 0.3750  BEST VAL Loss: 0.3750  Val_Acc: 85.112

Epoch 82: Validation loss decreased (0.374985 --> 0.374548).  Saving model ...
	 Train_Loss: 0.3818 Train_Acc: 83.162 Val_Loss: 0.3745  BEST VAL Loss: 0.3745  Val_Acc: 84.829

Epoch 83: Validation loss decreased (0.374548 --> 0.374079).  Saving model ...
	 Train_Loss: 0.3815 Train_Acc: 83.165 Val_Loss: 0.3741  BEST VAL Loss: 0.3741  Val_Acc: 84.935

Epoch 84: Validation loss decreased (0.374079 --> 0.373589).  Saving model ...
	 Train_Loss: 0.3811 Train_Acc: 83.114 Val_Loss: 0.3736  BEST VAL Loss: 0.3736  Val_Acc: 85.218

Epoch 85: Validation loss decreased (0.373589 --> 0.373108).  Saving model ...
	 Train_Loss: 0.3808 Train_Acc: 83.131 Val_Loss: 0.3731  BEST VAL Loss: 0.3731  Val_Acc: 84.740

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.3805 Train_Acc: 83.144 Val_Loss: 0.3732  BEST VAL Loss: 0.3731  Val_Acc: 83.064

Epoch 87: Validation loss decreased (0.373108 --> 0.372916).  Saving model ...
	 Train_Loss: 0.3802 Train_Acc: 83.193 Val_Loss: 0.3729  BEST VAL Loss: 0.3729  Val_Acc: 84.213

Epoch 88: Validation loss decreased (0.372916 --> 0.372428).  Saving model ...
	 Train_Loss: 0.3798 Train_Acc: 83.190 Val_Loss: 0.3724  BEST VAL Loss: 0.3724  Val_Acc: 84.846

Epoch 89: Validation loss decreased (0.372428 --> 0.372239).  Saving model ...
	 Train_Loss: 0.3795 Train_Acc: 83.310 Val_Loss: 0.3722  BEST VAL Loss: 0.3722  Val_Acc: 83.625

Epoch 90: Validation loss decreased (0.372239 --> 0.371726).  Saving model ...
	 Train_Loss: 0.3792 Train_Acc: 83.011 Val_Loss: 0.3717  BEST VAL Loss: 0.3717  Val_Acc: 84.924

Epoch 91: Validation loss decreased (0.371726 --> 0.371195).  Saving model ...
	 Train_Loss: 0.3789 Train_Acc: 83.301 Val_Loss: 0.3712  BEST VAL Loss: 0.3712  Val_Acc: 85.201

Epoch 92: Validation loss decreased (0.371195 --> 0.370674).  Saving model ...
	 Train_Loss: 0.3786 Train_Acc: 83.279 Val_Loss: 0.3707  BEST VAL Loss: 0.3707  Val_Acc: 84.757

Epoch 93: Validation loss decreased (0.370674 --> 0.370188).  Saving model ...
	 Train_Loss: 0.3783 Train_Acc: 83.345 Val_Loss: 0.3702  BEST VAL Loss: 0.3702  Val_Acc: 84.946

Epoch 94: Validation loss decreased (0.370188 --> 0.369822).  Saving model ...
	 Train_Loss: 0.3780 Train_Acc: 83.508 Val_Loss: 0.3698  BEST VAL Loss: 0.3698  Val_Acc: 85.046

Epoch 95: Validation loss decreased (0.369822 --> 0.369417).  Saving model ...
	 Train_Loss: 0.3777 Train_Acc: 83.231 Val_Loss: 0.3694  BEST VAL Loss: 0.3694  Val_Acc: 84.013

Epoch 96: Validation loss decreased (0.369417 --> 0.369161).  Saving model ...
	 Train_Loss: 0.3774 Train_Acc: 83.436 Val_Loss: 0.3692  BEST VAL Loss: 0.3692  Val_Acc: 84.380

Epoch 97: Validation loss did not decrease
	 Train_Loss: 0.3771 Train_Acc: 83.409 Val_Loss: 0.3692  BEST VAL Loss: 0.3692  Val_Acc: 82.559

Epoch 98: Validation loss decreased (0.369161 --> 0.368721).  Saving model ...
	 Train_Loss: 0.3768 Train_Acc: 83.325 Val_Loss: 0.3687  BEST VAL Loss: 0.3687  Val_Acc: 85.162

Epoch 99: Validation loss decreased (0.368721 --> 0.368438).  Saving model ...
	 Train_Loss: 0.3766 Train_Acc: 83.415 Val_Loss: 0.3684  BEST VAL Loss: 0.3684  Val_Acc: 84.158

Thapsigargin_1.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.39      0.37      0.38     56122
           1       0.61      0.63      0.62     87992

    accuracy                           0.53    144114
   macro avg       0.50      0.50      0.50    144114
weighted avg       0.52      0.53      0.53    144114

Thapsigargin_1.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.40      0.38      0.39      7016
           1       0.62      0.63      0.62     10999

    accuracy                           0.53     18015
   macro avg       0.51      0.51      0.51     18015
weighted avg       0.53      0.53      0.53     18015

Thapsigargin_1.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.39      0.37      0.38      7015
           1       0.61      0.63      0.62     11000

    accuracy                           0.53     18015
   macro avg       0.50      0.50      0.50     18015
weighted avg       0.52      0.53      0.53     18015

              precision    recall  f1-score   support

           0       0.39      0.37      0.38      7015
           1       0.61      0.63      0.62     11000

    accuracy                           0.53     18015
   macro avg       0.50      0.50      0.50     18015
weighted avg       0.52      0.53      0.53     18015

Thapsigargin_1.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_1.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.55      0.51     34394
           1       0.53      0.45      0.49     38465

    accuracy                           0.50     72859
   macro avg       0.50      0.50      0.50     72859
weighted avg       0.50      0.50      0.50     72859

              precision    recall  f1-score   support

           0       0.47      0.55      0.51     34394
           1       0.53      0.45      0.49     38465

    accuracy                           0.50     72859
   macro avg       0.50      0.50      0.50     72859
weighted avg       0.50      0.50      0.50     72859

completed
