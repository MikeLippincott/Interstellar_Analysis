[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '89540132'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'c2649406'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd7c111ef'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '6679cc9f'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: DMSO_0.100_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: DMSO_0.100_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (50571, 1276)
Number of total missing values across all columns: 101142
Data Subset Is Off
Wells held out for testing: ['I14' 'L23']
Wells to use for training, validation, and testing ['B14' 'C14' 'B15' 'C15' 'J14' 'I15' 'J15' 'L18' 'L19' 'L22']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.534656).  Saving model ...
	 Train_Loss: 0.5984 Train_Acc: 69.346 Val_Loss: 0.5347  BEST VAL Loss: 0.5347  Val_Acc: 73.385

Epoch 1: Validation loss decreased (0.534656 --> 0.520653).  Saving model ...
	 Train_Loss: 0.5631 Train_Acc: 73.948 Val_Loss: 0.5207  BEST VAL Loss: 0.5207  Val_Acc: 74.560

Epoch 2: Validation loss decreased (0.520653 --> 0.512131).  Saving model ...
	 Train_Loss: 0.5456 Train_Acc: 74.720 Val_Loss: 0.5121  BEST VAL Loss: 0.5121  Val_Acc: 76.204

Epoch 3: Validation loss decreased (0.512131 --> 0.506116).  Saving model ...
	 Train_Loss: 0.5329 Train_Acc: 75.598 Val_Loss: 0.5061  BEST VAL Loss: 0.5061  Val_Acc: 76.744

Epoch 4: Validation loss decreased (0.506116 --> 0.501266).  Saving model ...
	 Train_Loss: 0.5240 Train_Acc: 75.924 Val_Loss: 0.5013  BEST VAL Loss: 0.5013  Val_Acc: 77.331

Epoch 5: Validation loss decreased (0.501266 --> 0.497903).  Saving model ...
	 Train_Loss: 0.5174 Train_Acc: 76.183 Val_Loss: 0.4979  BEST VAL Loss: 0.4979  Val_Acc: 76.979

Epoch 6: Validation loss decreased (0.497903 --> 0.495072).  Saving model ...
	 Train_Loss: 0.5113 Train_Acc: 76.679 Val_Loss: 0.4951  BEST VAL Loss: 0.4951  Val_Acc: 77.284

Epoch 7: Validation loss decreased (0.495072 --> 0.491845).  Saving model ...
	 Train_Loss: 0.5053 Train_Acc: 77.152 Val_Loss: 0.4918  BEST VAL Loss: 0.4918  Val_Acc: 77.543

Epoch 8: Validation loss decreased (0.491845 --> 0.489713).  Saving model ...
	 Train_Loss: 0.5004 Train_Acc: 77.023 Val_Loss: 0.4897  BEST VAL Loss: 0.4897  Val_Acc: 77.731

Epoch 9: Validation loss decreased (0.489713 --> 0.487544).  Saving model ...
	 Train_Loss: 0.4959 Train_Acc: 77.299 Val_Loss: 0.4875  BEST VAL Loss: 0.4875  Val_Acc: 77.966

Epoch 10: Validation loss decreased (0.487544 --> 0.485980).  Saving model ...
	 Train_Loss: 0.4914 Train_Acc: 77.936 Val_Loss: 0.4860  BEST VAL Loss: 0.4860  Val_Acc: 77.613

Epoch 11: Validation loss decreased (0.485980 --> 0.485232).  Saving model ...
	 Train_Loss: 0.4878 Train_Acc: 77.739 Val_Loss: 0.4852  BEST VAL Loss: 0.4852  Val_Acc: 77.566

Epoch 12: Validation loss decreased (0.485232 --> 0.484160).  Saving model ...
	 Train_Loss: 0.4848 Train_Acc: 77.402 Val_Loss: 0.4842  BEST VAL Loss: 0.4842  Val_Acc: 77.848

Epoch 13: Validation loss decreased (0.484160 --> 0.483552).  Saving model ...
	 Train_Loss: 0.4815 Train_Acc: 78.018 Val_Loss: 0.4836  BEST VAL Loss: 0.4836  Val_Acc: 78.130

Epoch 14: Validation loss decreased (0.483552 --> 0.482853).  Saving model ...
	 Train_Loss: 0.4785 Train_Acc: 78.162 Val_Loss: 0.4829  BEST VAL Loss: 0.4829  Val_Acc: 77.966

Epoch 15: Validation loss did not decrease
	 Train_Loss: 0.4759 Train_Acc: 77.971 Val_Loss: 0.4829  BEST VAL Loss: 0.4829  Val_Acc: 78.764

Epoch 16: Validation loss did not decrease
	 Train_Loss: 0.4734 Train_Acc: 78.145 Val_Loss: 0.4830  BEST VAL Loss: 0.4829  Val_Acc: 77.754

Epoch 17: Validation loss did not decrease
	 Train_Loss: 0.4712 Train_Acc: 78.274 Val_Loss: 0.4830  BEST VAL Loss: 0.4829  Val_Acc: 78.036

Epoch 18: Validation loss did not decrease
	 Train_Loss: 0.4691 Train_Acc: 78.121 Val_Loss: 0.4837  BEST VAL Loss: 0.4829  Val_Acc: 78.130

Epoch 19: Validation loss did not decrease
	 Train_Loss: 0.4670 Train_Acc: 78.459 Val_Loss: 0.4839  BEST VAL Loss: 0.4829  Val_Acc: 77.942

Epoch 20: Validation loss did not decrease
	 Train_Loss: 0.4651 Train_Acc: 78.476 Val_Loss: 0.4841  BEST VAL Loss: 0.4829  Val_Acc: 78.389

Epoch 21: Validation loss did not decrease
	 Train_Loss: 0.4634 Train_Acc: 78.371 Val_Loss: 0.4838  BEST VAL Loss: 0.4829  Val_Acc: 78.600

Epoch 22: Validation loss did not decrease
	 Train_Loss: 0.4614 Train_Acc: 78.870 Val_Loss: 0.4841  BEST VAL Loss: 0.4829  Val_Acc: 78.436

Epoch 23: Validation loss did not decrease
	 Train_Loss: 0.4595 Train_Acc: 79.020 Val_Loss: 0.4842  BEST VAL Loss: 0.4829  Val_Acc: 78.600

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.4580 Train_Acc: 78.726 Val_Loss: 0.4850  BEST VAL Loss: 0.4829  Val_Acc: 78.083

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.4566 Train_Acc: 78.779 Val_Loss: 0.4846  BEST VAL Loss: 0.4829  Val_Acc: 78.365

Epoch 26: Validation loss did not decrease
	 Train_Loss: 0.4551 Train_Acc: 79.034 Val_Loss: 0.4844  BEST VAL Loss: 0.4829  Val_Acc: 79.164

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.4536 Train_Acc: 79.120 Val_Loss: 0.4842  BEST VAL Loss: 0.4829  Val_Acc: 78.482

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.4522 Train_Acc: 78.973 Val_Loss: 0.4841  BEST VAL Loss: 0.4829  Val_Acc: 78.929

Epoch 29: Validation loss did not decrease
	 Train_Loss: 0.4509 Train_Acc: 79.175 Val_Loss: 0.4836  BEST VAL Loss: 0.4829  Val_Acc: 78.882

Epoch 30: Validation loss did not decrease
Early stopped at epoch : 30
DMSO_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.83      0.92      0.88     24644
           1       0.72      0.51      0.60      9407

    accuracy                           0.81     34051
   macro avg       0.78      0.72      0.74     34051
weighted avg       0.80      0.81      0.80     34051

DMSO_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.81      0.91      0.86      3081
           1       0.65      0.45      0.53      1176

    accuracy                           0.78      4257
   macro avg       0.73      0.68      0.69      4257
weighted avg       0.77      0.78      0.77      4257

DMSO_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.81      0.91      0.86      3081
           1       0.65      0.46      0.54      1176

    accuracy                           0.78      4257
   macro avg       0.73      0.68      0.70      4257
weighted avg       0.77      0.78      0.77      4257

              precision    recall  f1-score   support

           0       0.81      0.91      0.86      3081
           1       0.65      0.46      0.54      1176

    accuracy                           0.78      4257
   macro avg       0.73      0.68      0.70      4257
weighted avg       0.77      0.78      0.77      4257

DMSO_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.71      0.88      0.79      4837
           1       0.72      0.46      0.56      3169

    accuracy                           0.71      8006
   macro avg       0.72      0.67      0.68      8006
weighted avg       0.71      0.71      0.70      8006

              precision    recall  f1-score   support

           0       0.71      0.88      0.79      4837
           1       0.72      0.46      0.56      3169

    accuracy                           0.71      8006
   macro avg       0.72      0.67      0.68      8006
weighted avg       0.71      0.71      0.70      8006

completed
