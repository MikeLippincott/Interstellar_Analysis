[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '26777b59'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '356a7615'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '051a6a0f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '5def6f43'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_0.100_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_0.100_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (298032, 1270)
Number of total missing values across all columns: 596064
Data Subset Is Off
Wells held out for testing: ['C08' 'J08']
Wells to use for training, validation, and testing ['C02' 'C03' 'C09' 'J02' 'J03' 'J09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.685995).  Saving model ...
	 Train_Loss: 0.6929 Train_Acc: 51.630 Val_Loss: 0.6860  BEST VAL Loss: 0.6860  Val_Acc: 54.269

Epoch 1: Validation loss decreased (0.685995 --> 0.684318).  Saving model ...
	 Train_Loss: 0.6890 Train_Acc: 54.551 Val_Loss: 0.6843  BEST VAL Loss: 0.6843  Val_Acc: 55.124

Epoch 2: Validation loss decreased (0.684318 --> 0.682529).  Saving model ...
	 Train_Loss: 0.6867 Train_Acc: 55.359 Val_Loss: 0.6825  BEST VAL Loss: 0.6825  Val_Acc: 56.288

Epoch 3: Validation loss decreased (0.682529 --> 0.680650).  Saving model ...
	 Train_Loss: 0.6847 Train_Acc: 56.223 Val_Loss: 0.6806  BEST VAL Loss: 0.6806  Val_Acc: 57.696

Epoch 4: Validation loss decreased (0.680650 --> 0.678655).  Saving model ...
	 Train_Loss: 0.6828 Train_Acc: 56.890 Val_Loss: 0.6787  BEST VAL Loss: 0.6787  Val_Acc: 58.563

Epoch 5: Validation loss decreased (0.678655 --> 0.676766).  Saving model ...
	 Train_Loss: 0.6810 Train_Acc: 57.476 Val_Loss: 0.6768  BEST VAL Loss: 0.6768  Val_Acc: 59.267

Epoch 6: Validation loss decreased (0.676766 --> 0.675036).  Saving model ...
	 Train_Loss: 0.6792 Train_Acc: 58.073 Val_Loss: 0.6750  BEST VAL Loss: 0.6750  Val_Acc: 59.701

Epoch 7: Validation loss decreased (0.675036 --> 0.673441).  Saving model ...
	 Train_Loss: 0.6776 Train_Acc: 58.420 Val_Loss: 0.6734  BEST VAL Loss: 0.6734  Val_Acc: 60.272

Epoch 8: Validation loss decreased (0.673441 --> 0.671965).  Saving model ...
	 Train_Loss: 0.6761 Train_Acc: 58.904 Val_Loss: 0.6720  BEST VAL Loss: 0.6720  Val_Acc: 60.630

Epoch 9: Validation loss decreased (0.671965 --> 0.670545).  Saving model ...
	 Train_Loss: 0.6747 Train_Acc: 59.320 Val_Loss: 0.6705  BEST VAL Loss: 0.6705  Val_Acc: 61.157

Epoch 10: Validation loss decreased (0.670545 --> 0.669281).  Saving model ...
	 Train_Loss: 0.6734 Train_Acc: 59.731 Val_Loss: 0.6693  BEST VAL Loss: 0.6693  Val_Acc: 61.401

Epoch 11: Validation loss decreased (0.669281 --> 0.668046).  Saving model ...
	 Train_Loss: 0.6721 Train_Acc: 59.874 Val_Loss: 0.6680  BEST VAL Loss: 0.6680  Val_Acc: 61.640

Epoch 12: Validation loss decreased (0.668046 --> 0.666833).  Saving model ...
	 Train_Loss: 0.6709 Train_Acc: 60.430 Val_Loss: 0.6668  BEST VAL Loss: 0.6668  Val_Acc: 61.901

Epoch 13: Validation loss decreased (0.666833 --> 0.665716).  Saving model ...
	 Train_Loss: 0.6697 Train_Acc: 60.621 Val_Loss: 0.6657  BEST VAL Loss: 0.6657  Val_Acc: 62.144

Epoch 14: Validation loss decreased (0.665716 --> 0.664625).  Saving model ...
	 Train_Loss: 0.6686 Train_Acc: 61.053 Val_Loss: 0.6646  BEST VAL Loss: 0.6646  Val_Acc: 62.304

Epoch 15: Validation loss decreased (0.664625 --> 0.663610).  Saving model ...
	 Train_Loss: 0.6675 Train_Acc: 61.315 Val_Loss: 0.6636  BEST VAL Loss: 0.6636  Val_Acc: 62.423

Epoch 16: Validation loss decreased (0.663610 --> 0.662604).  Saving model ...
	 Train_Loss: 0.6664 Train_Acc: 61.633 Val_Loss: 0.6626  BEST VAL Loss: 0.6626  Val_Acc: 62.839

Epoch 17: Validation loss decreased (0.662604 --> 0.661525).  Saving model ...
	 Train_Loss: 0.6652 Train_Acc: 61.948 Val_Loss: 0.6615  BEST VAL Loss: 0.6615  Val_Acc: 63.105

Epoch 18: Validation loss decreased (0.661525 --> 0.660536).  Saving model ...
	 Train_Loss: 0.6642 Train_Acc: 62.321 Val_Loss: 0.6605  BEST VAL Loss: 0.6605  Val_Acc: 63.207

Epoch 19: Validation loss decreased (0.660536 --> 0.659605).  Saving model ...
	 Train_Loss: 0.6632 Train_Acc: 62.371 Val_Loss: 0.6596  BEST VAL Loss: 0.6596  Val_Acc: 63.034

Epoch 20: Validation loss decreased (0.659605 --> 0.658713).  Saving model ...
	 Train_Loss: 0.6622 Train_Acc: 62.730 Val_Loss: 0.6587  BEST VAL Loss: 0.6587  Val_Acc: 63.716

Epoch 21: Validation loss decreased (0.658713 --> 0.657808).  Saving model ...
	 Train_Loss: 0.6612 Train_Acc: 62.958 Val_Loss: 0.6578  BEST VAL Loss: 0.6578  Val_Acc: 63.769

Epoch 22: Validation loss decreased (0.657808 --> 0.656871).  Saving model ...
	 Train_Loss: 0.6603 Train_Acc: 63.040 Val_Loss: 0.6569  BEST VAL Loss: 0.6569  Val_Acc: 64.163

Epoch 23: Validation loss decreased (0.656871 --> 0.655975).  Saving model ...
	 Train_Loss: 0.6593 Train_Acc: 63.156 Val_Loss: 0.6560  BEST VAL Loss: 0.6560  Val_Acc: 63.915

Epoch 24: Validation loss decreased (0.655975 --> 0.655077).  Saving model ...
	 Train_Loss: 0.6584 Train_Acc: 63.433 Val_Loss: 0.6551  BEST VAL Loss: 0.6551  Val_Acc: 64.393

Epoch 25: Validation loss decreased (0.655077 --> 0.654246).  Saving model ...
	 Train_Loss: 0.6574 Train_Acc: 63.603 Val_Loss: 0.6542  BEST VAL Loss: 0.6542  Val_Acc: 64.433

Epoch 26: Validation loss decreased (0.654246 --> 0.653427).  Saving model ...
	 Train_Loss: 0.6566 Train_Acc: 63.735 Val_Loss: 0.6534  BEST VAL Loss: 0.6534  Val_Acc: 64.623

Epoch 27: Validation loss decreased (0.653427 --> 0.652616).  Saving model ...
	 Train_Loss: 0.6557 Train_Acc: 63.857 Val_Loss: 0.6526  BEST VAL Loss: 0.6526  Val_Acc: 64.915

Epoch 28: Validation loss decreased (0.652616 --> 0.651767).  Saving model ...
	 Train_Loss: 0.6549 Train_Acc: 64.061 Val_Loss: 0.6518  BEST VAL Loss: 0.6518  Val_Acc: 65.353

Epoch 29: Validation loss decreased (0.651767 --> 0.650955).  Saving model ...
	 Train_Loss: 0.6540 Train_Acc: 64.156 Val_Loss: 0.6510  BEST VAL Loss: 0.6510  Val_Acc: 64.973

Epoch 30: Validation loss decreased (0.650955 --> 0.650084).  Saving model ...
	 Train_Loss: 0.6532 Train_Acc: 64.236 Val_Loss: 0.6501  BEST VAL Loss: 0.6501  Val_Acc: 65.371

Epoch 31: Validation loss decreased (0.650084 --> 0.649229).  Saving model ...
	 Train_Loss: 0.6524 Train_Acc: 64.279 Val_Loss: 0.6492  BEST VAL Loss: 0.6492  Val_Acc: 65.446

Epoch 32: Validation loss decreased (0.649229 --> 0.648407).  Saving model ...
	 Train_Loss: 0.6517 Train_Acc: 64.285 Val_Loss: 0.6484  BEST VAL Loss: 0.6484  Val_Acc: 65.230

Epoch 33: Validation loss decreased (0.648407 --> 0.647644).  Saving model ...
	 Train_Loss: 0.6509 Train_Acc: 64.647 Val_Loss: 0.6476  BEST VAL Loss: 0.6476  Val_Acc: 65.849

Epoch 34: Validation loss decreased (0.647644 --> 0.646909).  Saving model ...
	 Train_Loss: 0.6502 Train_Acc: 64.659 Val_Loss: 0.6469  BEST VAL Loss: 0.6469  Val_Acc: 65.893

Epoch 35: Validation loss decreased (0.646909 --> 0.646171).  Saving model ...
	 Train_Loss: 0.6494 Train_Acc: 64.770 Val_Loss: 0.6462  BEST VAL Loss: 0.6462  Val_Acc: 65.907

Epoch 36: Validation loss decreased (0.646171 --> 0.645401).  Saving model ...
	 Train_Loss: 0.6487 Train_Acc: 64.842 Val_Loss: 0.6454  BEST VAL Loss: 0.6454  Val_Acc: 66.279

Epoch 37: Validation loss decreased (0.645401 --> 0.644637).  Saving model ...
	 Train_Loss: 0.6480 Train_Acc: 64.898 Val_Loss: 0.6446  BEST VAL Loss: 0.6446  Val_Acc: 66.420

Epoch 38: Validation loss decreased (0.644637 --> 0.643923).  Saving model ...
	 Train_Loss: 0.6473 Train_Acc: 64.983 Val_Loss: 0.6439  BEST VAL Loss: 0.6439  Val_Acc: 66.168

Epoch 39: Validation loss decreased (0.643923 --> 0.643161).  Saving model ...
	 Train_Loss: 0.6466 Train_Acc: 64.930 Val_Loss: 0.6432  BEST VAL Loss: 0.6432  Val_Acc: 66.318

Epoch 40: Validation loss decreased (0.643161 --> 0.642425).  Saving model ...
	 Train_Loss: 0.6460 Train_Acc: 65.042 Val_Loss: 0.6424  BEST VAL Loss: 0.6424  Val_Acc: 66.606

Epoch 41: Validation loss decreased (0.642425 --> 0.641732).  Saving model ...
	 Train_Loss: 0.6453 Train_Acc: 65.007 Val_Loss: 0.6417  BEST VAL Loss: 0.6417  Val_Acc: 66.681

Epoch 42: Validation loss decreased (0.641732 --> 0.640981).  Saving model ...
	 Train_Loss: 0.6447 Train_Acc: 65.183 Val_Loss: 0.6410  BEST VAL Loss: 0.6410  Val_Acc: 66.885

Epoch 43: Validation loss decreased (0.640981 --> 0.640413).  Saving model ...
	 Train_Loss: 0.6441 Train_Acc: 65.209 Val_Loss: 0.6404  BEST VAL Loss: 0.6404  Val_Acc: 66.708

Epoch 44: Validation loss decreased (0.640413 --> 0.639699).  Saving model ...
	 Train_Loss: 0.6435 Train_Acc: 65.226 Val_Loss: 0.6397  BEST VAL Loss: 0.6397  Val_Acc: 66.810

Epoch 45: Validation loss decreased (0.639699 --> 0.639134).  Saving model ...
	 Train_Loss: 0.6429 Train_Acc: 65.279 Val_Loss: 0.6391  BEST VAL Loss: 0.6391  Val_Acc: 66.673

Epoch 46: Validation loss decreased (0.639134 --> 0.638515).  Saving model ...
	 Train_Loss: 0.6423 Train_Acc: 65.330 Val_Loss: 0.6385  BEST VAL Loss: 0.6385  Val_Acc: 66.885

Epoch 47: Validation loss decreased (0.638515 --> 0.637951).  Saving model ...
	 Train_Loss: 0.6418 Train_Acc: 65.385 Val_Loss: 0.6380  BEST VAL Loss: 0.6380  Val_Acc: 66.863

Epoch 48: Validation loss decreased (0.637951 --> 0.637351).  Saving model ...
	 Train_Loss: 0.6412 Train_Acc: 65.371 Val_Loss: 0.6374  BEST VAL Loss: 0.6374  Val_Acc: 67.106

Epoch 49: Validation loss decreased (0.637351 --> 0.636701).  Saving model ...
	 Train_Loss: 0.6407 Train_Acc: 65.470 Val_Loss: 0.6367  BEST VAL Loss: 0.6367  Val_Acc: 67.407

Epoch 50: Validation loss decreased (0.636701 --> 0.636080).  Saving model ...
	 Train_Loss: 0.6401 Train_Acc: 65.545 Val_Loss: 0.6361  BEST VAL Loss: 0.6361  Val_Acc: 67.372

Epoch 51: Validation loss decreased (0.636080 --> 0.635480).  Saving model ...
	 Train_Loss: 0.6396 Train_Acc: 65.640 Val_Loss: 0.6355  BEST VAL Loss: 0.6355  Val_Acc: 67.518

Epoch 52: Validation loss decreased (0.635480 --> 0.634901).  Saving model ...
	 Train_Loss: 0.6391 Train_Acc: 65.538 Val_Loss: 0.6349  BEST VAL Loss: 0.6349  Val_Acc: 67.394

Epoch 53: Validation loss decreased (0.634901 --> 0.634314).  Saving model ...
	 Train_Loss: 0.6386 Train_Acc: 65.678 Val_Loss: 0.6343  BEST VAL Loss: 0.6343  Val_Acc: 67.571

Epoch 54: Validation loss decreased (0.634314 --> 0.633748).  Saving model ...
	 Train_Loss: 0.6381 Train_Acc: 65.661 Val_Loss: 0.6337  BEST VAL Loss: 0.6337  Val_Acc: 67.514

Epoch 55: Validation loss decreased (0.633748 --> 0.633190).  Saving model ...
	 Train_Loss: 0.6376 Train_Acc: 65.733 Val_Loss: 0.6332  BEST VAL Loss: 0.6332  Val_Acc: 67.912

Epoch 56: Validation loss decreased (0.633190 --> 0.632613).  Saving model ...
	 Train_Loss: 0.6371 Train_Acc: 65.756 Val_Loss: 0.6326  BEST VAL Loss: 0.6326  Val_Acc: 67.673

Epoch 57: Validation loss decreased (0.632613 --> 0.632124).  Saving model ...
	 Train_Loss: 0.6366 Train_Acc: 65.847 Val_Loss: 0.6321  BEST VAL Loss: 0.6321  Val_Acc: 67.655

Epoch 58: Validation loss decreased (0.632124 --> 0.631615).  Saving model ...
	 Train_Loss: 0.6362 Train_Acc: 65.709 Val_Loss: 0.6316  BEST VAL Loss: 0.6316  Val_Acc: 67.571

Epoch 59: Validation loss decreased (0.631615 --> 0.631157).  Saving model ...
	 Train_Loss: 0.6357 Train_Acc: 65.942 Val_Loss: 0.6312  BEST VAL Loss: 0.6312  Val_Acc: 67.580

Epoch 60: Validation loss decreased (0.631157 --> 0.630657).  Saving model ...
	 Train_Loss: 0.6353 Train_Acc: 65.824 Val_Loss: 0.6307  BEST VAL Loss: 0.6307  Val_Acc: 67.770

Epoch 61: Validation loss decreased (0.630657 --> 0.630168).  Saving model ...
	 Train_Loss: 0.6348 Train_Acc: 66.015 Val_Loss: 0.6302  BEST VAL Loss: 0.6302  Val_Acc: 67.784

Epoch 62: Validation loss decreased (0.630168 --> 0.629686).  Saving model ...
	 Train_Loss: 0.6344 Train_Acc: 65.888 Val_Loss: 0.6297  BEST VAL Loss: 0.6297  Val_Acc: 67.642

Epoch 63: Validation loss decreased (0.629686 --> 0.629244).  Saving model ...
	 Train_Loss: 0.6340 Train_Acc: 65.798 Val_Loss: 0.6292  BEST VAL Loss: 0.6292  Val_Acc: 67.797

Epoch 64: Validation loss decreased (0.629244 --> 0.628774).  Saving model ...
	 Train_Loss: 0.6336 Train_Acc: 65.904 Val_Loss: 0.6288  BEST VAL Loss: 0.6288  Val_Acc: 67.854

Epoch 65: Validation loss decreased (0.628774 --> 0.628322).  Saving model ...
	 Train_Loss: 0.6332 Train_Acc: 66.064 Val_Loss: 0.6283  BEST VAL Loss: 0.6283  Val_Acc: 68.111

Epoch 66: Validation loss decreased (0.628322 --> 0.627833).  Saving model ...
	 Train_Loss: 0.6328 Train_Acc: 66.148 Val_Loss: 0.6278  BEST VAL Loss: 0.6278  Val_Acc: 68.368

Epoch 67: Validation loss decreased (0.627833 --> 0.627358).  Saving model ...
	 Train_Loss: 0.6324 Train_Acc: 66.007 Val_Loss: 0.6274  BEST VAL Loss: 0.6274  Val_Acc: 68.155

Epoch 68: Validation loss decreased (0.627358 --> 0.626918).  Saving model ...
	 Train_Loss: 0.6320 Train_Acc: 66.016 Val_Loss: 0.6269  BEST VAL Loss: 0.6269  Val_Acc: 67.970

Epoch 69: Validation loss decreased (0.626918 --> 0.626455).  Saving model ...
	 Train_Loss: 0.6316 Train_Acc: 66.049 Val_Loss: 0.6265  BEST VAL Loss: 0.6265  Val_Acc: 68.492

Epoch 70: Validation loss decreased (0.626455 --> 0.626051).  Saving model ...
	 Train_Loss: 0.6312 Train_Acc: 66.225 Val_Loss: 0.6261  BEST VAL Loss: 0.6261  Val_Acc: 67.925

Epoch 71: Validation loss decreased (0.626051 --> 0.625615).  Saving model ...
	 Train_Loss: 0.6308 Train_Acc: 66.170 Val_Loss: 0.6256  BEST VAL Loss: 0.6256  Val_Acc: 68.204

Epoch 72: Validation loss decreased (0.625615 --> 0.625220).  Saving model ...
	 Train_Loss: 0.6305 Train_Acc: 66.106 Val_Loss: 0.6252  BEST VAL Loss: 0.6252  Val_Acc: 68.271

Epoch 73: Validation loss decreased (0.625220 --> 0.624810).  Saving model ...
	 Train_Loss: 0.6301 Train_Acc: 66.333 Val_Loss: 0.6248  BEST VAL Loss: 0.6248  Val_Acc: 68.319

Epoch 74: Validation loss decreased (0.624810 --> 0.624400).  Saving model ...
	 Train_Loss: 0.6298 Train_Acc: 66.176 Val_Loss: 0.6244  BEST VAL Loss: 0.6244  Val_Acc: 68.514

Epoch 75: Validation loss decreased (0.624400 --> 0.624011).  Saving model ...
	 Train_Loss: 0.6294 Train_Acc: 66.217 Val_Loss: 0.6240  BEST VAL Loss: 0.6240  Val_Acc: 68.372

Epoch 76: Validation loss decreased (0.624011 --> 0.623601).  Saving model ...
	 Train_Loss: 0.6291 Train_Acc: 66.269 Val_Loss: 0.6236  BEST VAL Loss: 0.6236  Val_Acc: 68.620

Epoch 77: Validation loss decreased (0.623601 --> 0.623198).  Saving model ...
	 Train_Loss: 0.6288 Train_Acc: 66.225 Val_Loss: 0.6232  BEST VAL Loss: 0.6232  Val_Acc: 68.386

Epoch 78: Validation loss decreased (0.623198 --> 0.622803).  Saving model ...
	 Train_Loss: 0.6284 Train_Acc: 66.312 Val_Loss: 0.6228  BEST VAL Loss: 0.6228  Val_Acc: 68.377

Epoch 79: Validation loss decreased (0.622803 --> 0.622417).  Saving model ...
	 Train_Loss: 0.6281 Train_Acc: 66.289 Val_Loss: 0.6224  BEST VAL Loss: 0.6224  Val_Acc: 68.501

Epoch 80: Validation loss decreased (0.622417 --> 0.621987).  Saving model ...
	 Train_Loss: 0.6278 Train_Acc: 66.252 Val_Loss: 0.6220  BEST VAL Loss: 0.6220  Val_Acc: 68.992

Epoch 81: Validation loss decreased (0.621987 --> 0.621636).  Saving model ...
	 Train_Loss: 0.6275 Train_Acc: 66.360 Val_Loss: 0.6216  BEST VAL Loss: 0.6216  Val_Acc: 68.461

Epoch 82: Validation loss decreased (0.621636 --> 0.621278).  Saving model ...
	 Train_Loss: 0.6272 Train_Acc: 66.486 Val_Loss: 0.6213  BEST VAL Loss: 0.6213  Val_Acc: 68.443

Epoch 83: Validation loss decreased (0.621278 --> 0.620961).  Saving model ...
	 Train_Loss: 0.6269 Train_Acc: 66.135 Val_Loss: 0.6210  BEST VAL Loss: 0.6210  Val_Acc: 68.018

Epoch 84: Validation loss decreased (0.620961 --> 0.620622).  Saving model ...
	 Train_Loss: 0.6266 Train_Acc: 66.402 Val_Loss: 0.6206  BEST VAL Loss: 0.6206  Val_Acc: 68.412

Epoch 85: Validation loss decreased (0.620622 --> 0.620241).  Saving model ...
	 Train_Loss: 0.6263 Train_Acc: 66.434 Val_Loss: 0.6202  BEST VAL Loss: 0.6202  Val_Acc: 68.634

Epoch 86: Validation loss decreased (0.620241 --> 0.619908).  Saving model ...
	 Train_Loss: 0.6260 Train_Acc: 66.315 Val_Loss: 0.6199  BEST VAL Loss: 0.6199  Val_Acc: 68.443

Epoch 87: Validation loss decreased (0.619908 --> 0.619595).  Saving model ...
	 Train_Loss: 0.6257 Train_Acc: 66.456 Val_Loss: 0.6196  BEST VAL Loss: 0.6196  Val_Acc: 68.580

Epoch 88: Validation loss decreased (0.619595 --> 0.619258).  Saving model ...
	 Train_Loss: 0.6254 Train_Acc: 66.511 Val_Loss: 0.6193  BEST VAL Loss: 0.6193  Val_Acc: 68.549

Epoch 89: Validation loss decreased (0.619258 --> 0.618924).  Saving model ...
	 Train_Loss: 0.6251 Train_Acc: 66.407 Val_Loss: 0.6189  BEST VAL Loss: 0.6189  Val_Acc: 68.536

Epoch 90: Validation loss decreased (0.618924 --> 0.618592).  Saving model ...
	 Train_Loss: 0.6248 Train_Acc: 66.485 Val_Loss: 0.6186  BEST VAL Loss: 0.6186  Val_Acc: 68.554

Epoch 91: Validation loss decreased (0.618592 --> 0.618251).  Saving model ...
	 Train_Loss: 0.6246 Train_Acc: 66.407 Val_Loss: 0.6183  BEST VAL Loss: 0.6183  Val_Acc: 68.943

Epoch 92: Validation loss decreased (0.618251 --> 0.617929).  Saving model ...
	 Train_Loss: 0.6243 Train_Acc: 66.619 Val_Loss: 0.6179  BEST VAL Loss: 0.6179  Val_Acc: 68.806

Epoch 93: Validation loss decreased (0.617929 --> 0.617636).  Saving model ...
	 Train_Loss: 0.6240 Train_Acc: 66.487 Val_Loss: 0.6176  BEST VAL Loss: 0.6176  Val_Acc: 68.682

Epoch 94: Validation loss decreased (0.617636 --> 0.617316).  Saving model ...
	 Train_Loss: 0.6238 Train_Acc: 66.474 Val_Loss: 0.6173  BEST VAL Loss: 0.6173  Val_Acc: 68.957

Epoch 95: Validation loss decreased (0.617316 --> 0.617007).  Saving model ...
	 Train_Loss: 0.6235 Train_Acc: 66.451 Val_Loss: 0.6170  BEST VAL Loss: 0.6170  Val_Acc: 68.669

Epoch 96: Validation loss decreased (0.617007 --> 0.616709).  Saving model ...
	 Train_Loss: 0.6233 Train_Acc: 66.477 Val_Loss: 0.6167  BEST VAL Loss: 0.6167  Val_Acc: 68.656

Epoch 97: Validation loss decreased (0.616709 --> 0.616392).  Saving model ...
	 Train_Loss: 0.6230 Train_Acc: 66.570 Val_Loss: 0.6164  BEST VAL Loss: 0.6164  Val_Acc: 68.917

Epoch 98: Validation loss decreased (0.616392 --> 0.616086).  Saving model ...
	 Train_Loss: 0.6228 Train_Acc: 66.498 Val_Loss: 0.6161  BEST VAL Loss: 0.6161  Val_Acc: 68.917

Epoch 99: Validation loss decreased (0.616086 --> 0.615766).  Saving model ...
	 Train_Loss: 0.6225 Train_Acc: 66.462 Val_Loss: 0.6158  BEST VAL Loss: 0.6158  Val_Acc: 69.182

LPS_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.72      0.66      0.69     82968
           1       0.73      0.79      0.76     97752

    accuracy                           0.73    180720
   macro avg       0.73      0.72      0.72    180720
weighted avg       0.73      0.73      0.73    180720

LPS_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.68      0.61      0.65     10371
           1       0.70      0.76      0.73     12220

    accuracy                           0.69     22591
   macro avg       0.69      0.69      0.69     22591
weighted avg       0.69      0.69      0.69     22591

LPS_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.68      0.62      0.65     10371
           1       0.70      0.75      0.73     12220

    accuracy                           0.69     22591
   macro avg       0.69      0.69      0.69     22591
weighted avg       0.69      0.69      0.69     22591

              precision    recall  f1-score   support

           0       0.68      0.62      0.65     10371
           1       0.70      0.75      0.73     12220

    accuracy                           0.69     22591
   macro avg       0.69      0.69      0.69     22591
weighted avg       0.69      0.69      0.69     22591

LPS_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.60      0.69      0.64     34887
           1       0.66      0.57      0.61     37243

    accuracy                           0.63     72130
   macro avg       0.63      0.63      0.63     72130
weighted avg       0.63      0.63      0.63     72130

              precision    recall  f1-score   support

           0       0.60      0.69      0.64     34887
           1       0.66      0.57      0.61     37243

    accuracy                           0.63     72130
   macro avg       0.63      0.63      0.63     72130
weighted avg       0.63      0.63      0.63     72130

completed
