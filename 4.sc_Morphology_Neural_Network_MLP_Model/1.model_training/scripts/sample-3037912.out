[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '98703b13'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'd318ea33'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '915e28d9'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '73ffa082'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_0.100_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_0.100_DMSO_0.025
TREATMENT_NAME: Flagellin_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (243144, 1270)
Number of total missing values across all columns: 522904
Data Subset Is Off
Wells held out for testing: ['C09' 'M10']
Wells to use for training, validation, and testing ['C02' 'C03' 'C08' 'M05' 'M11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.662004).  Saving model ...
	 Train_Loss: 0.6743 Train_Acc: 58.536 Val_Loss: 0.6620  BEST VAL Loss: 0.6620  Val_Acc: 58.871

Epoch 1: Validation loss decreased (0.662004 --> 0.652423).  Saving model ...
	 Train_Loss: 0.6654 Train_Acc: 58.868 Val_Loss: 0.6524  BEST VAL Loss: 0.6524  Val_Acc: 58.871

Epoch 2: Validation loss decreased (0.652423 --> 0.643012).  Saving model ...
	 Train_Loss: 0.6575 Train_Acc: 61.243 Val_Loss: 0.6430  BEST VAL Loss: 0.6430  Val_Acc: 65.959

Epoch 3: Validation loss decreased (0.643012 --> 0.634190).  Saving model ...
	 Train_Loss: 0.6498 Train_Acc: 65.978 Val_Loss: 0.6342  BEST VAL Loss: 0.6342  Val_Acc: 69.037

Epoch 4: Validation loss decreased (0.634190 --> 0.626245).  Saving model ...
	 Train_Loss: 0.6427 Train_Acc: 67.342 Val_Loss: 0.6262  BEST VAL Loss: 0.6262  Val_Acc: 69.594

Epoch 5: Validation loss decreased (0.626245 --> 0.619169).  Saving model ...
	 Train_Loss: 0.6362 Train_Acc: 68.154 Val_Loss: 0.6192  BEST VAL Loss: 0.6192  Val_Acc: 70.579

Epoch 6: Validation loss decreased (0.619169 --> 0.612628).  Saving model ...
	 Train_Loss: 0.6302 Train_Acc: 68.841 Val_Loss: 0.6126  BEST VAL Loss: 0.6126  Val_Acc: 71.435

Epoch 7: Validation loss decreased (0.612628 --> 0.606549).  Saving model ...
	 Train_Loss: 0.6247 Train_Acc: 69.703 Val_Loss: 0.6065  BEST VAL Loss: 0.6065  Val_Acc: 72.403

Epoch 8: Validation loss decreased (0.606549 --> 0.600510).  Saving model ...
	 Train_Loss: 0.6193 Train_Acc: 70.302 Val_Loss: 0.6005  BEST VAL Loss: 0.6005  Val_Acc: 73.030

Epoch 9: Validation loss decreased (0.600510 --> 0.594916).  Saving model ...
	 Train_Loss: 0.6144 Train_Acc: 70.747 Val_Loss: 0.5949  BEST VAL Loss: 0.5949  Val_Acc: 73.440

Epoch 10: Validation loss decreased (0.594916 --> 0.589818).  Saving model ...
	 Train_Loss: 0.6098 Train_Acc: 71.121 Val_Loss: 0.5898  BEST VAL Loss: 0.5898  Val_Acc: 74.156

Epoch 11: Validation loss decreased (0.589818 --> 0.585156).  Saving model ...
	 Train_Loss: 0.6056 Train_Acc: 71.237 Val_Loss: 0.5852  BEST VAL Loss: 0.5852  Val_Acc: 74.027

Epoch 12: Validation loss decreased (0.585156 --> 0.580746).  Saving model ...
	 Train_Loss: 0.6017 Train_Acc: 71.645 Val_Loss: 0.5807  BEST VAL Loss: 0.5807  Val_Acc: 74.414

Epoch 13: Validation loss decreased (0.580746 --> 0.576854).  Saving model ...
	 Train_Loss: 0.5980 Train_Acc: 71.926 Val_Loss: 0.5769  BEST VAL Loss: 0.5769  Val_Acc: 74.408

Epoch 14: Validation loss decreased (0.576854 --> 0.573253).  Saving model ...
	 Train_Loss: 0.5945 Train_Acc: 72.312 Val_Loss: 0.5733  BEST VAL Loss: 0.5733  Val_Acc: 74.707

Epoch 15: Validation loss decreased (0.573253 --> 0.569856).  Saving model ...
	 Train_Loss: 0.5913 Train_Acc: 72.559 Val_Loss: 0.5699  BEST VAL Loss: 0.5699  Val_Acc: 75.023

Epoch 16: Validation loss decreased (0.569856 --> 0.566618).  Saving model ...
	 Train_Loss: 0.5883 Train_Acc: 72.543 Val_Loss: 0.5666  BEST VAL Loss: 0.5666  Val_Acc: 75.229

Epoch 17: Validation loss decreased (0.566618 --> 0.564427).  Saving model ...
	 Train_Loss: 0.5854 Train_Acc: 72.870 Val_Loss: 0.5644  BEST VAL Loss: 0.5644  Val_Acc: 74.056

Epoch 18: Validation loss decreased (0.564427 --> 0.561644).  Saving model ...
	 Train_Loss: 0.5828 Train_Acc: 73.095 Val_Loss: 0.5616  BEST VAL Loss: 0.5616  Val_Acc: 75.299

Epoch 19: Validation loss decreased (0.561644 --> 0.558863).  Saving model ...
	 Train_Loss: 0.5802 Train_Acc: 73.215 Val_Loss: 0.5589  BEST VAL Loss: 0.5589  Val_Acc: 75.604

Epoch 20: Validation loss decreased (0.558863 --> 0.556543).  Saving model ...
	 Train_Loss: 0.5777 Train_Acc: 73.582 Val_Loss: 0.5565  BEST VAL Loss: 0.5565  Val_Acc: 75.147

Epoch 21: Validation loss decreased (0.556543 --> 0.554107).  Saving model ...
	 Train_Loss: 0.5753 Train_Acc: 73.879 Val_Loss: 0.5541  BEST VAL Loss: 0.5541  Val_Acc: 75.463

Epoch 22: Validation loss decreased (0.554107 --> 0.551730).  Saving model ...
	 Train_Loss: 0.5730 Train_Acc: 73.993 Val_Loss: 0.5517  BEST VAL Loss: 0.5517  Val_Acc: 75.909

Epoch 23: Validation loss decreased (0.551730 --> 0.549387).  Saving model ...
	 Train_Loss: 0.5709 Train_Acc: 74.150 Val_Loss: 0.5494  BEST VAL Loss: 0.5494  Val_Acc: 76.196

Epoch 24: Validation loss decreased (0.549387 --> 0.547299).  Saving model ...
	 Train_Loss: 0.5688 Train_Acc: 74.205 Val_Loss: 0.5473  BEST VAL Loss: 0.5473  Val_Acc: 75.862

Epoch 25: Validation loss decreased (0.547299 --> 0.545353).  Saving model ...
	 Train_Loss: 0.5669 Train_Acc: 74.369 Val_Loss: 0.5454  BEST VAL Loss: 0.5454  Val_Acc: 75.721

Epoch 26: Validation loss decreased (0.545353 --> 0.543330).  Saving model ...
	 Train_Loss: 0.5650 Train_Acc: 74.493 Val_Loss: 0.5433  BEST VAL Loss: 0.5433  Val_Acc: 76.466

Epoch 27: Validation loss decreased (0.543330 --> 0.541358).  Saving model ...
	 Train_Loss: 0.5632 Train_Acc: 74.549 Val_Loss: 0.5414  BEST VAL Loss: 0.5414  Val_Acc: 76.577

Epoch 28: Validation loss decreased (0.541358 --> 0.539623).  Saving model ...
	 Train_Loss: 0.5614 Train_Acc: 74.792 Val_Loss: 0.5396  BEST VAL Loss: 0.5396  Val_Acc: 76.225

Epoch 29: Validation loss decreased (0.539623 --> 0.537841).  Saving model ...
	 Train_Loss: 0.5597 Train_Acc: 74.845 Val_Loss: 0.5378  BEST VAL Loss: 0.5378  Val_Acc: 76.601

Epoch 30: Validation loss decreased (0.537841 --> 0.536097).  Saving model ...
	 Train_Loss: 0.5581 Train_Acc: 74.805 Val_Loss: 0.5361  BEST VAL Loss: 0.5361  Val_Acc: 76.788

Epoch 31: Validation loss decreased (0.536097 --> 0.534507).  Saving model ...
	 Train_Loss: 0.5566 Train_Acc: 74.892 Val_Loss: 0.5345  BEST VAL Loss: 0.5345  Val_Acc: 76.648

Epoch 32: Validation loss decreased (0.534507 --> 0.533017).  Saving model ...
	 Train_Loss: 0.5551 Train_Acc: 75.056 Val_Loss: 0.5330  BEST VAL Loss: 0.5330  Val_Acc: 76.536

Epoch 33: Validation loss decreased (0.533017 --> 0.531557).  Saving model ...
	 Train_Loss: 0.5536 Train_Acc: 75.156 Val_Loss: 0.5316  BEST VAL Loss: 0.5316  Val_Acc: 76.671

Epoch 34: Validation loss decreased (0.531557 --> 0.530142).  Saving model ...
	 Train_Loss: 0.5522 Train_Acc: 75.070 Val_Loss: 0.5301  BEST VAL Loss: 0.5301  Val_Acc: 76.788

Epoch 35: Validation loss decreased (0.530142 --> 0.528744).  Saving model ...
	 Train_Loss: 0.5508 Train_Acc: 75.316 Val_Loss: 0.5287  BEST VAL Loss: 0.5287  Val_Acc: 76.952

Epoch 36: Validation loss decreased (0.528744 --> 0.527456).  Saving model ...
	 Train_Loss: 0.5494 Train_Acc: 75.290 Val_Loss: 0.5275  BEST VAL Loss: 0.5275  Val_Acc: 76.513

Epoch 37: Validation loss decreased (0.527456 --> 0.526193).  Saving model ...
	 Train_Loss: 0.5481 Train_Acc: 75.237 Val_Loss: 0.5262  BEST VAL Loss: 0.5262  Val_Acc: 76.730

Epoch 38: Validation loss decreased (0.526193 --> 0.524946).  Saving model ...
	 Train_Loss: 0.5468 Train_Acc: 75.452 Val_Loss: 0.5249  BEST VAL Loss: 0.5249  Val_Acc: 76.800

Epoch 39: Validation loss decreased (0.524946 --> 0.523798).  Saving model ...
	 Train_Loss: 0.5456 Train_Acc: 75.478 Val_Loss: 0.5238  BEST VAL Loss: 0.5238  Val_Acc: 76.864

Epoch 40: Validation loss decreased (0.523798 --> 0.522635).  Saving model ...
	 Train_Loss: 0.5444 Train_Acc: 75.323 Val_Loss: 0.5226  BEST VAL Loss: 0.5226  Val_Acc: 76.917

Epoch 41: Validation loss decreased (0.522635 --> 0.521514).  Saving model ...
	 Train_Loss: 0.5433 Train_Acc: 75.475 Val_Loss: 0.5215  BEST VAL Loss: 0.5215  Val_Acc: 77.152

Epoch 42: Validation loss decreased (0.521514 --> 0.520366).  Saving model ...
	 Train_Loss: 0.5421 Train_Acc: 75.495 Val_Loss: 0.5204  BEST VAL Loss: 0.5204  Val_Acc: 77.246

Epoch 43: Validation loss decreased (0.520366 --> 0.519267).  Saving model ...
	 Train_Loss: 0.5410 Train_Acc: 75.534 Val_Loss: 0.5193  BEST VAL Loss: 0.5193  Val_Acc: 77.310

Epoch 44: Validation loss decreased (0.519267 --> 0.518233).  Saving model ...
	 Train_Loss: 0.5400 Train_Acc: 75.621 Val_Loss: 0.5182  BEST VAL Loss: 0.5182  Val_Acc: 77.187

Epoch 45: Validation loss decreased (0.518233 --> 0.517331).  Saving model ...
	 Train_Loss: 0.5389 Train_Acc: 75.487 Val_Loss: 0.5173  BEST VAL Loss: 0.5173  Val_Acc: 76.841

Epoch 46: Validation loss decreased (0.517331 --> 0.516339).  Saving model ...
	 Train_Loss: 0.5379 Train_Acc: 75.796 Val_Loss: 0.5163  BEST VAL Loss: 0.5163  Val_Acc: 77.304

Epoch 47: Validation loss decreased (0.516339 --> 0.515372).  Saving model ...
	 Train_Loss: 0.5369 Train_Acc: 75.687 Val_Loss: 0.5154  BEST VAL Loss: 0.5154  Val_Acc: 77.146

Epoch 48: Validation loss decreased (0.515372 --> 0.514409).  Saving model ...
	 Train_Loss: 0.5359 Train_Acc: 75.801 Val_Loss: 0.5144  BEST VAL Loss: 0.5144  Val_Acc: 77.492

Epoch 49: Validation loss decreased (0.514409 --> 0.513461).  Saving model ...
	 Train_Loss: 0.5350 Train_Acc: 75.634 Val_Loss: 0.5135  BEST VAL Loss: 0.5135  Val_Acc: 77.515

Epoch 50: Validation loss decreased (0.513461 --> 0.512551).  Saving model ...
	 Train_Loss: 0.5340 Train_Acc: 75.720 Val_Loss: 0.5126  BEST VAL Loss: 0.5126  Val_Acc: 77.416

Epoch 51: Validation loss decreased (0.512551 --> 0.511731).  Saving model ...
	 Train_Loss: 0.5331 Train_Acc: 75.773 Val_Loss: 0.5117  BEST VAL Loss: 0.5117  Val_Acc: 77.163

Epoch 52: Validation loss decreased (0.511731 --> 0.510846).  Saving model ...
	 Train_Loss: 0.5323 Train_Acc: 75.717 Val_Loss: 0.5108  BEST VAL Loss: 0.5108  Val_Acc: 77.410

Epoch 53: Validation loss decreased (0.510846 --> 0.509977).  Saving model ...
	 Train_Loss: 0.5314 Train_Acc: 75.769 Val_Loss: 0.5100  BEST VAL Loss: 0.5100  Val_Acc: 77.199

Epoch 54: Validation loss decreased (0.509977 --> 0.509199).  Saving model ...
	 Train_Loss: 0.5305 Train_Acc: 75.817 Val_Loss: 0.5092  BEST VAL Loss: 0.5092  Val_Acc: 77.445

Epoch 55: Validation loss decreased (0.509199 --> 0.508354).  Saving model ...
	 Train_Loss: 0.5297 Train_Acc: 75.816 Val_Loss: 0.5084  BEST VAL Loss: 0.5084  Val_Acc: 77.292

Epoch 56: Validation loss decreased (0.508354 --> 0.507529).  Saving model ...
	 Train_Loss: 0.5289 Train_Acc: 75.789 Val_Loss: 0.5075  BEST VAL Loss: 0.5075  Val_Acc: 77.638

Epoch 57: Validation loss decreased (0.507529 --> 0.506688).  Saving model ...
	 Train_Loss: 0.5281 Train_Acc: 75.892 Val_Loss: 0.5067  BEST VAL Loss: 0.5067  Val_Acc: 77.791

Epoch 58: Validation loss decreased (0.506688 --> 0.505882).  Saving model ...
	 Train_Loss: 0.5273 Train_Acc: 75.877 Val_Loss: 0.5059  BEST VAL Loss: 0.5059  Val_Acc: 77.539

Epoch 59: Validation loss decreased (0.505882 --> 0.505172).  Saving model ...
	 Train_Loss: 0.5266 Train_Acc: 75.958 Val_Loss: 0.5052  BEST VAL Loss: 0.5052  Val_Acc: 77.656

Epoch 60: Validation loss decreased (0.505172 --> 0.504456).  Saving model ...
	 Train_Loss: 0.5258 Train_Acc: 75.840 Val_Loss: 0.5045  BEST VAL Loss: 0.5045  Val_Acc: 77.462

Epoch 61: Validation loss decreased (0.504456 --> 0.503777).  Saving model ...
	 Train_Loss: 0.5251 Train_Acc: 75.968 Val_Loss: 0.5038  BEST VAL Loss: 0.5038  Val_Acc: 77.333

Epoch 62: Validation loss decreased (0.503777 --> 0.503067).  Saving model ...
	 Train_Loss: 0.5244 Train_Acc: 75.914 Val_Loss: 0.5031  BEST VAL Loss: 0.5031  Val_Acc: 77.627

Epoch 63: Validation loss decreased (0.503067 --> 0.502374).  Saving model ...
	 Train_Loss: 0.5237 Train_Acc: 76.002 Val_Loss: 0.5024  BEST VAL Loss: 0.5024  Val_Acc: 77.744

Epoch 64: Validation loss decreased (0.502374 --> 0.501696).  Saving model ...
	 Train_Loss: 0.5230 Train_Acc: 75.912 Val_Loss: 0.5017  BEST VAL Loss: 0.5017  Val_Acc: 77.562

Epoch 65: Validation loss decreased (0.501696 --> 0.500985).  Saving model ...
	 Train_Loss: 0.5223 Train_Acc: 76.031 Val_Loss: 0.5010  BEST VAL Loss: 0.5010  Val_Acc: 77.668

Epoch 66: Validation loss decreased (0.500985 --> 0.500365).  Saving model ...
	 Train_Loss: 0.5216 Train_Acc: 76.054 Val_Loss: 0.5004  BEST VAL Loss: 0.5004  Val_Acc: 77.521

Epoch 67: Validation loss decreased (0.500365 --> 0.499682).  Saving model ...
	 Train_Loss: 0.5210 Train_Acc: 75.999 Val_Loss: 0.4997  BEST VAL Loss: 0.4997  Val_Acc: 77.867

Epoch 68: Validation loss decreased (0.499682 --> 0.499082).  Saving model ...
	 Train_Loss: 0.5203 Train_Acc: 76.078 Val_Loss: 0.4991  BEST VAL Loss: 0.4991  Val_Acc: 77.662

Epoch 69: Validation loss decreased (0.499082 --> 0.498443).  Saving model ...
	 Train_Loss: 0.5197 Train_Acc: 76.101 Val_Loss: 0.4984  BEST VAL Loss: 0.4984  Val_Acc: 77.504

Epoch 70: Validation loss decreased (0.498443 --> 0.497922).  Saving model ...
	 Train_Loss: 0.5190 Train_Acc: 76.242 Val_Loss: 0.4979  BEST VAL Loss: 0.4979  Val_Acc: 77.550

Epoch 71: Validation loss decreased (0.497922 --> 0.497292).  Saving model ...
	 Train_Loss: 0.5184 Train_Acc: 76.089 Val_Loss: 0.4973  BEST VAL Loss: 0.4973  Val_Acc: 77.914

Epoch 72: Validation loss decreased (0.497292 --> 0.496715).  Saving model ...
	 Train_Loss: 0.5178 Train_Acc: 76.196 Val_Loss: 0.4967  BEST VAL Loss: 0.4967  Val_Acc: 77.820

Epoch 73: Validation loss decreased (0.496715 --> 0.496138).  Saving model ...
	 Train_Loss: 0.5172 Train_Acc: 76.178 Val_Loss: 0.4961  BEST VAL Loss: 0.4961  Val_Acc: 77.943

Epoch 74: Validation loss decreased (0.496138 --> 0.495526).  Saving model ...
	 Train_Loss: 0.5166 Train_Acc: 76.214 Val_Loss: 0.4955  BEST VAL Loss: 0.4955  Val_Acc: 77.797

Epoch 75: Validation loss decreased (0.495526 --> 0.494941).  Saving model ...
	 Train_Loss: 0.5161 Train_Acc: 76.255 Val_Loss: 0.4949  BEST VAL Loss: 0.4949  Val_Acc: 78.125

Epoch 76: Validation loss decreased (0.494941 --> 0.494371).  Saving model ...
	 Train_Loss: 0.5155 Train_Acc: 76.325 Val_Loss: 0.4944  BEST VAL Loss: 0.4944  Val_Acc: 77.990

Epoch 77: Validation loss decreased (0.494371 --> 0.493812).  Saving model ...
	 Train_Loss: 0.5149 Train_Acc: 76.137 Val_Loss: 0.4938  BEST VAL Loss: 0.4938  Val_Acc: 78.008

Epoch 78: Validation loss decreased (0.493812 --> 0.493300).  Saving model ...
	 Train_Loss: 0.5144 Train_Acc: 76.262 Val_Loss: 0.4933  BEST VAL Loss: 0.4933  Val_Acc: 77.744

Epoch 79: Validation loss decreased (0.493300 --> 0.492757).  Saving model ...
	 Train_Loss: 0.5139 Train_Acc: 76.260 Val_Loss: 0.4928  BEST VAL Loss: 0.4928  Val_Acc: 78.383

Epoch 80: Validation loss decreased (0.492757 --> 0.492296).  Saving model ...
	 Train_Loss: 0.5133 Train_Acc: 76.145 Val_Loss: 0.4923  BEST VAL Loss: 0.4923  Val_Acc: 77.849

Epoch 81: Validation loss decreased (0.492296 --> 0.491830).  Saving model ...
	 Train_Loss: 0.5128 Train_Acc: 76.262 Val_Loss: 0.4918  BEST VAL Loss: 0.4918  Val_Acc: 77.779

Epoch 82: Validation loss decreased (0.491830 --> 0.491293).  Saving model ...
	 Train_Loss: 0.5123 Train_Acc: 76.405 Val_Loss: 0.4913  BEST VAL Loss: 0.4913  Val_Acc: 78.090

Epoch 83: Validation loss decreased (0.491293 --> 0.490770).  Saving model ...
	 Train_Loss: 0.5118 Train_Acc: 76.282 Val_Loss: 0.4908  BEST VAL Loss: 0.4908  Val_Acc: 78.172

Epoch 84: Validation loss decreased (0.490770 --> 0.490224).  Saving model ...
	 Train_Loss: 0.5113 Train_Acc: 76.231 Val_Loss: 0.4902  BEST VAL Loss: 0.4902  Val_Acc: 78.084

Epoch 85: Validation loss decreased (0.490224 --> 0.489725).  Saving model ...
	 Train_Loss: 0.5108 Train_Acc: 76.280 Val_Loss: 0.4897  BEST VAL Loss: 0.4897  Val_Acc: 78.295

Epoch 86: Validation loss decreased (0.489725 --> 0.489227).  Saving model ...
	 Train_Loss: 0.5103 Train_Acc: 76.286 Val_Loss: 0.4892  BEST VAL Loss: 0.4892  Val_Acc: 78.401

Epoch 87: Validation loss decreased (0.489227 --> 0.488779).  Saving model ...
	 Train_Loss: 0.5098 Train_Acc: 76.292 Val_Loss: 0.4888  BEST VAL Loss: 0.4888  Val_Acc: 77.920

Epoch 88: Validation loss decreased (0.488779 --> 0.488312).  Saving model ...
	 Train_Loss: 0.5093 Train_Acc: 76.348 Val_Loss: 0.4883  BEST VAL Loss: 0.4883  Val_Acc: 78.043

Epoch 89: Validation loss decreased (0.488312 --> 0.487866).  Saving model ...
	 Train_Loss: 0.5089 Train_Acc: 76.329 Val_Loss: 0.4879  BEST VAL Loss: 0.4879  Val_Acc: 78.002

Epoch 90: Validation loss decreased (0.487866 --> 0.487387).  Saving model ...
	 Train_Loss: 0.5084 Train_Acc: 76.403 Val_Loss: 0.4874  BEST VAL Loss: 0.4874  Val_Acc: 78.084

Epoch 91: Validation loss decreased (0.487387 --> 0.486941).  Saving model ...
	 Train_Loss: 0.5080 Train_Acc: 76.316 Val_Loss: 0.4869  BEST VAL Loss: 0.4869  Val_Acc: 77.908

Epoch 92: Validation loss decreased (0.486941 --> 0.486515).  Saving model ...
	 Train_Loss: 0.5075 Train_Acc: 76.361 Val_Loss: 0.4865  BEST VAL Loss: 0.4865  Val_Acc: 78.125

Epoch 93: Validation loss decreased (0.486515 --> 0.486083).  Saving model ...
	 Train_Loss: 0.5071 Train_Acc: 76.589 Val_Loss: 0.4861  BEST VAL Loss: 0.4861  Val_Acc: 78.037

Epoch 94: Validation loss decreased (0.486083 --> 0.485668).  Saving model ...
	 Train_Loss: 0.5066 Train_Acc: 76.510 Val_Loss: 0.4857  BEST VAL Loss: 0.4857  Val_Acc: 77.885

Epoch 95: Validation loss decreased (0.485668 --> 0.485260).  Saving model ...
	 Train_Loss: 0.5062 Train_Acc: 76.441 Val_Loss: 0.4853  BEST VAL Loss: 0.4853  Val_Acc: 78.254

Epoch 96: Validation loss decreased (0.485260 --> 0.484828).  Saving model ...
	 Train_Loss: 0.5058 Train_Acc: 76.578 Val_Loss: 0.4848  BEST VAL Loss: 0.4848  Val_Acc: 77.973

Epoch 97: Validation loss decreased (0.484828 --> 0.484431).  Saving model ...
	 Train_Loss: 0.5053 Train_Acc: 76.529 Val_Loss: 0.4844  BEST VAL Loss: 0.4844  Val_Acc: 78.225

Epoch 98: Validation loss decreased (0.484431 --> 0.484059).  Saving model ...
	 Train_Loss: 0.5049 Train_Acc: 76.632 Val_Loss: 0.4841  BEST VAL Loss: 0.4841  Val_Acc: 78.189

Epoch 99: Validation loss decreased (0.484059 --> 0.483705).  Saving model ...
	 Train_Loss: 0.5045 Train_Acc: 76.469 Val_Loss: 0.4837  BEST VAL Loss: 0.4837  Val_Acc: 77.990

LPS_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.83      0.65      0.73     56123
           1       0.79      0.91      0.84     80324

    accuracy                           0.80    136447
   macro avg       0.81      0.78      0.79    136447
weighted avg       0.81      0.80      0.80    136447

LPS_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.80      0.62      0.70      7015
           1       0.77      0.89      0.83     10041

    accuracy                           0.78     17056
   macro avg       0.79      0.76      0.76     17056
weighted avg       0.78      0.78      0.77     17056

LPS_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.81      0.63      0.71      7015
           1       0.78      0.90      0.83     10041

    accuracy                           0.79     17056
   macro avg       0.79      0.76      0.77     17056
weighted avg       0.79      0.79      0.78     17056

              precision    recall  f1-score   support

           0       0.81      0.63      0.71      7015
           1       0.78      0.90      0.83     10041

    accuracy                           0.79     17056
   macro avg       0.79      0.76      0.77     17056
weighted avg       0.79      0.79      0.78     17056

LPS_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.59      0.35      0.44     34394
           1       0.57      0.78      0.66     38191

    accuracy                           0.58     72585
   macro avg       0.58      0.57      0.55     72585
weighted avg       0.58      0.58      0.56     72585

              precision    recall  f1-score   support

           0       0.59      0.35      0.44     34394
           1       0.57      0.78      0.66     38191

    accuracy                           0.58     72585
   macro avg       0.58      0.57      0.55     72585
weighted avg       0.58      0.58      0.56     72585

completed
