[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '0f5b71a3'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '8455f855'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '230f0645'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'c4d3b48f'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Flagellin_0.100_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (238995, 1270)
Number of total missing values across all columns: 477990
Data Subset Is Off
Wells held out for testing: ['B09' 'L10']
Wells to use for training, validation, and testing ['B02' 'B03' 'B08' 'L05' 'L11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.499417).  Saving model ...
	 Train_Loss: 0.5989 Train_Acc: 68.528 Val_Loss: 0.4994  BEST VAL Loss: 0.4994  Val_Acc: 75.458

Epoch 1: Validation loss decreased (0.499417 --> 0.479763).  Saving model ...
	 Train_Loss: 0.5558 Train_Acc: 74.099 Val_Loss: 0.4798  BEST VAL Loss: 0.4798  Val_Acc: 77.779

Epoch 2: Validation loss decreased (0.479763 --> 0.469836).  Saving model ...
	 Train_Loss: 0.5326 Train_Acc: 76.020 Val_Loss: 0.4698  BEST VAL Loss: 0.4698  Val_Acc: 78.380

Epoch 3: Validation loss decreased (0.469836 --> 0.460946).  Saving model ...
	 Train_Loss: 0.5166 Train_Acc: 77.112 Val_Loss: 0.4609  BEST VAL Loss: 0.4609  Val_Acc: 79.599

Epoch 4: Validation loss decreased (0.460946 --> 0.451768).  Saving model ...
	 Train_Loss: 0.5063 Train_Acc: 77.575 Val_Loss: 0.4518  BEST VAL Loss: 0.4518  Val_Acc: 80.530

Epoch 5: Validation loss decreased (0.451768 --> 0.446869).  Saving model ...
	 Train_Loss: 0.4969 Train_Acc: 78.318 Val_Loss: 0.4469  BEST VAL Loss: 0.4469  Val_Acc: 80.183

Epoch 6: Validation loss decreased (0.446869 --> 0.442421).  Saving model ...
	 Train_Loss: 0.4890 Train_Acc: 78.959 Val_Loss: 0.4424  BEST VAL Loss: 0.4424  Val_Acc: 80.990

Epoch 7: Validation loss decreased (0.442421 --> 0.437840).  Saving model ...
	 Train_Loss: 0.4826 Train_Acc: 79.087 Val_Loss: 0.4378  BEST VAL Loss: 0.4378  Val_Acc: 81.096

Epoch 8: Validation loss decreased (0.437840 --> 0.434539).  Saving model ...
	 Train_Loss: 0.4769 Train_Acc: 79.435 Val_Loss: 0.4345  BEST VAL Loss: 0.4345  Val_Acc: 81.060

Epoch 9: Validation loss decreased (0.434539 --> 0.430429).  Saving model ...
	 Train_Loss: 0.4721 Train_Acc: 79.449 Val_Loss: 0.4304  BEST VAL Loss: 0.4304  Val_Acc: 82.068

Epoch 10: Validation loss decreased (0.430429 --> 0.426410).  Saving model ...
	 Train_Loss: 0.4674 Train_Acc: 80.014 Val_Loss: 0.4264  BEST VAL Loss: 0.4264  Val_Acc: 81.738

Epoch 11: Validation loss decreased (0.426410 --> 0.423429).  Saving model ...
	 Train_Loss: 0.4634 Train_Acc: 80.098 Val_Loss: 0.4234  BEST VAL Loss: 0.4234  Val_Acc: 81.803

Epoch 12: Validation loss decreased (0.423429 --> 0.420996).  Saving model ...
	 Train_Loss: 0.4599 Train_Acc: 80.072 Val_Loss: 0.4210  BEST VAL Loss: 0.4210  Val_Acc: 81.968

Epoch 13: Validation loss decreased (0.420996 --> 0.418323).  Saving model ...
	 Train_Loss: 0.4565 Train_Acc: 80.286 Val_Loss: 0.4183  BEST VAL Loss: 0.4183  Val_Acc: 82.062

Epoch 14: Validation loss decreased (0.418323 --> 0.415644).  Saving model ...
	 Train_Loss: 0.4535 Train_Acc: 80.378 Val_Loss: 0.4156  BEST VAL Loss: 0.4156  Val_Acc: 82.333

Epoch 15: Validation loss decreased (0.415644 --> 0.413549).  Saving model ...
	 Train_Loss: 0.4507 Train_Acc: 80.508 Val_Loss: 0.4135  BEST VAL Loss: 0.4135  Val_Acc: 82.121

Epoch 16: Validation loss decreased (0.413549 --> 0.411234).  Saving model ...
	 Train_Loss: 0.4482 Train_Acc: 80.488 Val_Loss: 0.4112  BEST VAL Loss: 0.4112  Val_Acc: 82.698

Epoch 17: Validation loss decreased (0.411234 --> 0.409169).  Saving model ...
	 Train_Loss: 0.4458 Train_Acc: 80.595 Val_Loss: 0.4092  BEST VAL Loss: 0.4092  Val_Acc: 82.775

Epoch 18: Validation loss decreased (0.409169 --> 0.407324).  Saving model ...
	 Train_Loss: 0.4435 Train_Acc: 80.846 Val_Loss: 0.4073  BEST VAL Loss: 0.4073  Val_Acc: 82.321

Epoch 19: Validation loss decreased (0.407324 --> 0.405703).  Saving model ...
	 Train_Loss: 0.4415 Train_Acc: 80.734 Val_Loss: 0.4057  BEST VAL Loss: 0.4057  Val_Acc: 82.244

Epoch 20: Validation loss decreased (0.405703 --> 0.404482).  Saving model ...
	 Train_Loss: 0.4397 Train_Acc: 80.802 Val_Loss: 0.4045  BEST VAL Loss: 0.4045  Val_Acc: 82.138

Epoch 21: Validation loss decreased (0.404482 --> 0.403109).  Saving model ...
	 Train_Loss: 0.4379 Train_Acc: 80.771 Val_Loss: 0.4031  BEST VAL Loss: 0.4031  Val_Acc: 82.680

Epoch 22: Validation loss decreased (0.403109 --> 0.401657).  Saving model ...
	 Train_Loss: 0.4362 Train_Acc: 80.865 Val_Loss: 0.4017  BEST VAL Loss: 0.4017  Val_Acc: 82.657

Epoch 23: Validation loss decreased (0.401657 --> 0.400987).  Saving model ...
	 Train_Loss: 0.4346 Train_Acc: 81.181 Val_Loss: 0.4010  BEST VAL Loss: 0.4010  Val_Acc: 81.879

Epoch 24: Validation loss decreased (0.400987 --> 0.399723).  Saving model ...
	 Train_Loss: 0.4330 Train_Acc: 81.084 Val_Loss: 0.3997  BEST VAL Loss: 0.3997  Val_Acc: 82.498

Epoch 25: Validation loss decreased (0.399723 --> 0.398594).  Saving model ...
	 Train_Loss: 0.4317 Train_Acc: 81.007 Val_Loss: 0.3986  BEST VAL Loss: 0.3986  Val_Acc: 82.474

Epoch 26: Validation loss decreased (0.398594 --> 0.397492).  Saving model ...
	 Train_Loss: 0.4302 Train_Acc: 81.112 Val_Loss: 0.3975  BEST VAL Loss: 0.3975  Val_Acc: 82.822

Epoch 27: Validation loss decreased (0.397492 --> 0.396810).  Saving model ...
	 Train_Loss: 0.4289 Train_Acc: 81.170 Val_Loss: 0.3968  BEST VAL Loss: 0.3968  Val_Acc: 82.303

Epoch 28: Validation loss decreased (0.396810 --> 0.396180).  Saving model ...
	 Train_Loss: 0.4277 Train_Acc: 81.245 Val_Loss: 0.3962  BEST VAL Loss: 0.3962  Val_Acc: 82.362

Epoch 29: Validation loss decreased (0.396180 --> 0.395187).  Saving model ...
	 Train_Loss: 0.4265 Train_Acc: 81.154 Val_Loss: 0.3952  BEST VAL Loss: 0.3952  Val_Acc: 83.152

Epoch 30: Validation loss decreased (0.395187 --> 0.394114).  Saving model ...
	 Train_Loss: 0.4254 Train_Acc: 81.169 Val_Loss: 0.3941  BEST VAL Loss: 0.3941  Val_Acc: 83.299

Epoch 31: Validation loss decreased (0.394114 --> 0.393121).  Saving model ...
	 Train_Loss: 0.4243 Train_Acc: 81.302 Val_Loss: 0.3931  BEST VAL Loss: 0.3931  Val_Acc: 83.181

Epoch 32: Validation loss decreased (0.393121 --> 0.392214).  Saving model ...
	 Train_Loss: 0.4232 Train_Acc: 81.385 Val_Loss: 0.3922  BEST VAL Loss: 0.3922  Val_Acc: 83.063

Epoch 33: Validation loss decreased (0.392214 --> 0.391500).  Saving model ...
	 Train_Loss: 0.4221 Train_Acc: 81.312 Val_Loss: 0.3915  BEST VAL Loss: 0.3915  Val_Acc: 82.751

Epoch 34: Validation loss decreased (0.391500 --> 0.390724).  Saving model ...
	 Train_Loss: 0.4212 Train_Acc: 81.339 Val_Loss: 0.3907  BEST VAL Loss: 0.3907  Val_Acc: 83.664

Epoch 35: Validation loss decreased (0.390724 --> 0.389932).  Saving model ...
	 Train_Loss: 0.4202 Train_Acc: 81.378 Val_Loss: 0.3899  BEST VAL Loss: 0.3899  Val_Acc: 82.898

Epoch 36: Validation loss decreased (0.389932 --> 0.389615).  Saving model ...
	 Train_Loss: 0.4193 Train_Acc: 81.271 Val_Loss: 0.3896  BEST VAL Loss: 0.3896  Val_Acc: 82.380

Epoch 37: Validation loss decreased (0.389615 --> 0.389081).  Saving model ...
	 Train_Loss: 0.4184 Train_Acc: 81.488 Val_Loss: 0.3891  BEST VAL Loss: 0.3891  Val_Acc: 82.663

Epoch 38: Validation loss decreased (0.389081 --> 0.388275).  Saving model ...
	 Train_Loss: 0.4176 Train_Acc: 81.588 Val_Loss: 0.3883  BEST VAL Loss: 0.3883  Val_Acc: 83.576

Epoch 39: Validation loss decreased (0.388275 --> 0.387871).  Saving model ...
	 Train_Loss: 0.4167 Train_Acc: 81.515 Val_Loss: 0.3879  BEST VAL Loss: 0.3879  Val_Acc: 83.287

Epoch 40: Validation loss decreased (0.387871 --> 0.387288).  Saving model ...
	 Train_Loss: 0.4160 Train_Acc: 81.384 Val_Loss: 0.3873  BEST VAL Loss: 0.3873  Val_Acc: 82.845

Epoch 41: Validation loss decreased (0.387288 --> 0.386609).  Saving model ...
	 Train_Loss: 0.4152 Train_Acc: 81.588 Val_Loss: 0.3866  BEST VAL Loss: 0.3866  Val_Acc: 83.476

Epoch 42: Validation loss decreased (0.386609 --> 0.386042).  Saving model ...
	 Train_Loss: 0.4144 Train_Acc: 81.700 Val_Loss: 0.3860  BEST VAL Loss: 0.3860  Val_Acc: 83.010

Epoch 43: Validation loss decreased (0.386042 --> 0.385645).  Saving model ...
	 Train_Loss: 0.4137 Train_Acc: 81.500 Val_Loss: 0.3856  BEST VAL Loss: 0.3856  Val_Acc: 83.199

Epoch 44: Validation loss decreased (0.385645 --> 0.385021).  Saving model ...
	 Train_Loss: 0.4130 Train_Acc: 81.604 Val_Loss: 0.3850  BEST VAL Loss: 0.3850  Val_Acc: 83.381

Epoch 45: Validation loss decreased (0.385021 --> 0.384644).  Saving model ...
	 Train_Loss: 0.4123 Train_Acc: 81.605 Val_Loss: 0.3846  BEST VAL Loss: 0.3846  Val_Acc: 83.081

Epoch 46: Validation loss decreased (0.384644 --> 0.384331).  Saving model ...
	 Train_Loss: 0.4117 Train_Acc: 81.444 Val_Loss: 0.3843  BEST VAL Loss: 0.3843  Val_Acc: 82.527

Epoch 47: Validation loss decreased (0.384331 --> 0.383849).  Saving model ...
	 Train_Loss: 0.4110 Train_Acc: 81.537 Val_Loss: 0.3838  BEST VAL Loss: 0.3838  Val_Acc: 82.792

Epoch 48: Validation loss decreased (0.383849 --> 0.383508).  Saving model ...
	 Train_Loss: 0.4105 Train_Acc: 81.573 Val_Loss: 0.3835  BEST VAL Loss: 0.3835  Val_Acc: 83.122

Epoch 49: Validation loss decreased (0.383508 --> 0.382930).  Saving model ...
	 Train_Loss: 0.4099 Train_Acc: 81.623 Val_Loss: 0.3829  BEST VAL Loss: 0.3829  Val_Acc: 83.735

Epoch 50: Validation loss decreased (0.382930 --> 0.382526).  Saving model ...
	 Train_Loss: 0.4093 Train_Acc: 81.778 Val_Loss: 0.3825  BEST VAL Loss: 0.3825  Val_Acc: 83.281

Epoch 51: Validation loss decreased (0.382526 --> 0.381984).  Saving model ...
	 Train_Loss: 0.4087 Train_Acc: 81.639 Val_Loss: 0.3820  BEST VAL Loss: 0.3820  Val_Acc: 83.393

Epoch 52: Validation loss decreased (0.381984 --> 0.381490).  Saving model ...
	 Train_Loss: 0.4081 Train_Acc: 81.726 Val_Loss: 0.3815  BEST VAL Loss: 0.3815  Val_Acc: 83.317

Epoch 53: Validation loss decreased (0.381490 --> 0.381175).  Saving model ...
	 Train_Loss: 0.4075 Train_Acc: 81.830 Val_Loss: 0.3812  BEST VAL Loss: 0.3812  Val_Acc: 83.287

Epoch 54: Validation loss decreased (0.381175 --> 0.380729).  Saving model ...
	 Train_Loss: 0.4070 Train_Acc: 81.799 Val_Loss: 0.3807  BEST VAL Loss: 0.3807  Val_Acc: 82.999

Epoch 55: Validation loss decreased (0.380729 --> 0.380195).  Saving model ...
	 Train_Loss: 0.4064 Train_Acc: 81.877 Val_Loss: 0.3802  BEST VAL Loss: 0.3802  Val_Acc: 83.782

Epoch 56: Validation loss decreased (0.380195 --> 0.379868).  Saving model ...
	 Train_Loss: 0.4059 Train_Acc: 81.708 Val_Loss: 0.3799  BEST VAL Loss: 0.3799  Val_Acc: 83.399

Epoch 57: Validation loss decreased (0.379868 --> 0.379506).  Saving model ...
	 Train_Loss: 0.4054 Train_Acc: 81.782 Val_Loss: 0.3795  BEST VAL Loss: 0.3795  Val_Acc: 83.293

Epoch 58: Validation loss decreased (0.379506 --> 0.379038).  Saving model ...
	 Train_Loss: 0.4050 Train_Acc: 81.724 Val_Loss: 0.3790  BEST VAL Loss: 0.3790  Val_Acc: 83.381

Epoch 59: Validation loss decreased (0.379038 --> 0.378667).  Saving model ...
	 Train_Loss: 0.4045 Train_Acc: 81.785 Val_Loss: 0.3787  BEST VAL Loss: 0.3787  Val_Acc: 83.470

Epoch 60: Validation loss decreased (0.378667 --> 0.378381).  Saving model ...
	 Train_Loss: 0.4041 Train_Acc: 81.687 Val_Loss: 0.3784  BEST VAL Loss: 0.3784  Val_Acc: 83.110

Epoch 61: Validation loss decreased (0.378381 --> 0.377978).  Saving model ...
	 Train_Loss: 0.4036 Train_Acc: 81.830 Val_Loss: 0.3780  BEST VAL Loss: 0.3780  Val_Acc: 83.499

Epoch 62: Validation loss decreased (0.377978 --> 0.377598).  Saving model ...
	 Train_Loss: 0.4032 Train_Acc: 81.910 Val_Loss: 0.3776  BEST VAL Loss: 0.3776  Val_Acc: 83.711

Epoch 63: Validation loss decreased (0.377598 --> 0.377125).  Saving model ...
	 Train_Loss: 0.4027 Train_Acc: 81.922 Val_Loss: 0.3771  BEST VAL Loss: 0.3771  Val_Acc: 83.753

Epoch 64: Validation loss decreased (0.377125 --> 0.376864).  Saving model ...
	 Train_Loss: 0.4023 Train_Acc: 81.985 Val_Loss: 0.3769  BEST VAL Loss: 0.3769  Val_Acc: 83.010

Epoch 65: Validation loss decreased (0.376864 --> 0.376572).  Saving model ...
	 Train_Loss: 0.4019 Train_Acc: 81.881 Val_Loss: 0.3766  BEST VAL Loss: 0.3766  Val_Acc: 83.175

Epoch 66: Validation loss decreased (0.376572 --> 0.376219).  Saving model ...
	 Train_Loss: 0.4015 Train_Acc: 81.992 Val_Loss: 0.3762  BEST VAL Loss: 0.3762  Val_Acc: 83.764

Epoch 67: Validation loss decreased (0.376219 --> 0.375870).  Saving model ...
	 Train_Loss: 0.4010 Train_Acc: 81.969 Val_Loss: 0.3759  BEST VAL Loss: 0.3759  Val_Acc: 83.364

Epoch 68: Validation loss decreased (0.375870 --> 0.375539).  Saving model ...
	 Train_Loss: 0.4006 Train_Acc: 82.081 Val_Loss: 0.3755  BEST VAL Loss: 0.3755  Val_Acc: 83.859

Epoch 69: Validation loss decreased (0.375539 --> 0.375360).  Saving model ...
	 Train_Loss: 0.4002 Train_Acc: 82.017 Val_Loss: 0.3754  BEST VAL Loss: 0.3754  Val_Acc: 83.052

Epoch 70: Validation loss decreased (0.375360 --> 0.375063).  Saving model ...
	 Train_Loss: 0.3999 Train_Acc: 81.939 Val_Loss: 0.3751  BEST VAL Loss: 0.3751  Val_Acc: 83.264

Epoch 71: Validation loss decreased (0.375063 --> 0.374641).  Saving model ...
	 Train_Loss: 0.3995 Train_Acc: 81.996 Val_Loss: 0.3746  BEST VAL Loss: 0.3746  Val_Acc: 83.788

Epoch 72: Validation loss decreased (0.374641 --> 0.374321).  Saving model ...
	 Train_Loss: 0.3991 Train_Acc: 81.874 Val_Loss: 0.3743  BEST VAL Loss: 0.3743  Val_Acc: 83.299

Epoch 73: Validation loss decreased (0.374321 --> 0.374170).  Saving model ...
	 Train_Loss: 0.3987 Train_Acc: 82.071 Val_Loss: 0.3742  BEST VAL Loss: 0.3742  Val_Acc: 83.075

Epoch 74: Validation loss decreased (0.374170 --> 0.373962).  Saving model ...
	 Train_Loss: 0.3983 Train_Acc: 82.134 Val_Loss: 0.3740  BEST VAL Loss: 0.3740  Val_Acc: 83.452

Epoch 75: Validation loss decreased (0.373962 --> 0.373592).  Saving model ...
	 Train_Loss: 0.3980 Train_Acc: 82.151 Val_Loss: 0.3736  BEST VAL Loss: 0.3736  Val_Acc: 83.912

Epoch 76: Validation loss decreased (0.373592 --> 0.373407).  Saving model ...
	 Train_Loss: 0.3977 Train_Acc: 81.995 Val_Loss: 0.3734  BEST VAL Loss: 0.3734  Val_Acc: 83.688

Epoch 77: Validation loss decreased (0.373407 --> 0.373139).  Saving model ...
	 Train_Loss: 0.3973 Train_Acc: 82.089 Val_Loss: 0.3731  BEST VAL Loss: 0.3731  Val_Acc: 83.594

Epoch 78: Validation loss decreased (0.373139 --> 0.372959).  Saving model ...
	 Train_Loss: 0.3970 Train_Acc: 82.204 Val_Loss: 0.3730  BEST VAL Loss: 0.3730  Val_Acc: 83.458

Epoch 79: Validation loss decreased (0.372959 --> 0.372720).  Saving model ...
	 Train_Loss: 0.3966 Train_Acc: 81.979 Val_Loss: 0.3727  BEST VAL Loss: 0.3727  Val_Acc: 83.511

Epoch 80: Validation loss decreased (0.372720 --> 0.372486).  Saving model ...
	 Train_Loss: 0.3963 Train_Acc: 82.137 Val_Loss: 0.3725  BEST VAL Loss: 0.3725  Val_Acc: 83.317

Epoch 81: Validation loss decreased (0.372486 --> 0.372226).  Saving model ...
	 Train_Loss: 0.3960 Train_Acc: 82.199 Val_Loss: 0.3722  BEST VAL Loss: 0.3722  Val_Acc: 83.570

Epoch 82: Validation loss decreased (0.372226 --> 0.372001).  Saving model ...
	 Train_Loss: 0.3957 Train_Acc: 82.062 Val_Loss: 0.3720  BEST VAL Loss: 0.3720  Val_Acc: 83.564

Epoch 83: Validation loss decreased (0.372001 --> 0.371693).  Saving model ...
	 Train_Loss: 0.3954 Train_Acc: 82.288 Val_Loss: 0.3717  BEST VAL Loss: 0.3717  Val_Acc: 83.994

Epoch 84: Validation loss decreased (0.371693 --> 0.371543).  Saving model ...
	 Train_Loss: 0.3951 Train_Acc: 82.046 Val_Loss: 0.3715  BEST VAL Loss: 0.3715  Val_Acc: 83.523

Epoch 85: Validation loss decreased (0.371543 --> 0.371334).  Saving model ...
	 Train_Loss: 0.3948 Train_Acc: 82.070 Val_Loss: 0.3713  BEST VAL Loss: 0.3713  Val_Acc: 83.694

Epoch 86: Validation loss decreased (0.371334 --> 0.371047).  Saving model ...
	 Train_Loss: 0.3945 Train_Acc: 82.052 Val_Loss: 0.3710  BEST VAL Loss: 0.3710  Val_Acc: 83.847

Epoch 87: Validation loss decreased (0.371047 --> 0.370729).  Saving model ...
	 Train_Loss: 0.3942 Train_Acc: 82.310 Val_Loss: 0.3707  BEST VAL Loss: 0.3707  Val_Acc: 84.271

Epoch 88: Validation loss decreased (0.370729 --> 0.370511).  Saving model ...
	 Train_Loss: 0.3939 Train_Acc: 82.214 Val_Loss: 0.3705  BEST VAL Loss: 0.3705  Val_Acc: 83.947

Epoch 89: Validation loss decreased (0.370511 --> 0.370210).  Saving model ...
	 Train_Loss: 0.3936 Train_Acc: 82.333 Val_Loss: 0.3702  BEST VAL Loss: 0.3702  Val_Acc: 83.941

Epoch 90: Validation loss decreased (0.370210 --> 0.369998).  Saving model ...
	 Train_Loss: 0.3933 Train_Acc: 82.344 Val_Loss: 0.3700  BEST VAL Loss: 0.3700  Val_Acc: 84.118

Epoch 91: Validation loss decreased (0.369998 --> 0.369844).  Saving model ...
	 Train_Loss: 0.3930 Train_Acc: 82.232 Val_Loss: 0.3698  BEST VAL Loss: 0.3698  Val_Acc: 83.711

Epoch 92: Validation loss decreased (0.369844 --> 0.369623).  Saving model ...
	 Train_Loss: 0.3927 Train_Acc: 82.350 Val_Loss: 0.3696  BEST VAL Loss: 0.3696  Val_Acc: 83.705

Epoch 93: Validation loss decreased (0.369623 --> 0.369477).  Saving model ...
	 Train_Loss: 0.3925 Train_Acc: 82.232 Val_Loss: 0.3695  BEST VAL Loss: 0.3695  Val_Acc: 83.652

Epoch 94: Validation loss decreased (0.369477 --> 0.369302).  Saving model ...
	 Train_Loss: 0.3922 Train_Acc: 82.310 Val_Loss: 0.3693  BEST VAL Loss: 0.3693  Val_Acc: 83.499

Epoch 95: Validation loss decreased (0.369302 --> 0.369157).  Saving model ...
	 Train_Loss: 0.3919 Train_Acc: 82.323 Val_Loss: 0.3692  BEST VAL Loss: 0.3692  Val_Acc: 83.965

Epoch 96: Validation loss decreased (0.369157 --> 0.368967).  Saving model ...
	 Train_Loss: 0.3917 Train_Acc: 82.363 Val_Loss: 0.3690  BEST VAL Loss: 0.3690  Val_Acc: 84.029

Epoch 97: Validation loss decreased (0.368967 --> 0.368899).  Saving model ...
	 Train_Loss: 0.3914 Train_Acc: 82.305 Val_Loss: 0.3689  BEST VAL Loss: 0.3689  Val_Acc: 83.270

Epoch 98: Validation loss decreased (0.368899 --> 0.368719).  Saving model ...
	 Train_Loss: 0.3911 Train_Acc: 82.353 Val_Loss: 0.3687  BEST VAL Loss: 0.3687  Val_Acc: 83.552

Epoch 99: Validation loss decreased (0.368719 --> 0.368514).  Saving model ...
	 Train_Loss: 0.3909 Train_Acc: 82.332 Val_Loss: 0.3685  BEST VAL Loss: 0.3685  Val_Acc: 84.012

Flagellin_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.37      0.31      0.34     50422
           1       0.63      0.69      0.66     85370

    accuracy                           0.55    135792
   macro avg       0.50      0.50      0.50    135792
weighted avg       0.53      0.55      0.54    135792

Flagellin_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.38      0.31      0.34      6303
           1       0.63      0.69      0.66     10672

    accuracy                           0.55     16975
   macro avg       0.50      0.50      0.50     16975
weighted avg       0.54      0.55      0.54     16975

Flagellin_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.37      0.31      0.33      6303
           1       0.63      0.69      0.66     10672

    accuracy                           0.55     16975
   macro avg       0.50      0.50      0.50     16975
weighted avg       0.53      0.55      0.54     16975

              precision    recall  f1-score   support

           0       0.37      0.31      0.33      6303
           1       0.63      0.69      0.66     10672

    accuracy                           0.55     16975
   macro avg       0.50      0.50      0.50     16975
weighted avg       0.53      0.55      0.54     16975

Flagellin_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.50      0.49     32887
           1       0.52      0.50      0.51     36366

    accuracy                           0.50     69253
   macro avg       0.50      0.50      0.50     69253
weighted avg       0.50      0.50      0.50     69253

              precision    recall  f1-score   support

           0       0.47      0.50      0.49     32887
           1       0.52      0.50      0.51     36366

    accuracy                           0.50     69253
   macro avg       0.50      0.50      0.50     69253
weighted avg       0.50      0.50      0.50     69253

completed
