[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'becb8907'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'bbe3b939'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b0cb85e5'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '1969de77'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: H2O2_100.000_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['H2O2_100.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (41828, 1276)
Number of total missing values across all columns: 83656
Data Subset Is Off
Wells held out for testing: ['I22' 'L22']
Wells to use for training, validation, and testing ['H18' 'H19' 'H22' 'H23' 'I18' 'L18' 'I19' 'L19' 'I23' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.572913).  Saving model ...
	 Train_Loss: 0.6063 Train_Acc: 68.929 Val_Loss: 0.5729  BEST VAL Loss: 0.5729  Val_Acc: 68.969

Epoch 1: Validation loss decreased (0.572913 --> 0.562285).  Saving model ...
	 Train_Loss: 0.5902 Train_Acc: 70.426 Val_Loss: 0.5623  BEST VAL Loss: 0.5623  Val_Acc: 70.725

Epoch 2: Validation loss decreased (0.562285 --> 0.557755).  Saving model ...
	 Train_Loss: 0.5809 Train_Acc: 70.951 Val_Loss: 0.5578  BEST VAL Loss: 0.5578  Val_Acc: 71.359

Epoch 3: Validation loss decreased (0.557755 --> 0.553265).  Saving model ...
	 Train_Loss: 0.5740 Train_Acc: 71.250 Val_Loss: 0.5533  BEST VAL Loss: 0.5533  Val_Acc: 71.531

Epoch 4: Validation loss decreased (0.553265 --> 0.549613).  Saving model ...
	 Train_Loss: 0.5684 Train_Acc: 71.592 Val_Loss: 0.5496  BEST VAL Loss: 0.5496  Val_Acc: 72.050

Epoch 5: Validation loss decreased (0.549613 --> 0.546113).  Saving model ...
	 Train_Loss: 0.5637 Train_Acc: 72.175 Val_Loss: 0.5461  BEST VAL Loss: 0.5461  Val_Acc: 72.395

Epoch 6: Validation loss decreased (0.546113 --> 0.543382).  Saving model ...
	 Train_Loss: 0.5598 Train_Acc: 72.438 Val_Loss: 0.5434  BEST VAL Loss: 0.5434  Val_Acc: 72.453

Epoch 7: Validation loss decreased (0.543382 --> 0.540908).  Saving model ...
	 Train_Loss: 0.5564 Train_Acc: 72.614 Val_Loss: 0.5409  BEST VAL Loss: 0.5409  Val_Acc: 72.568

Epoch 8: Validation loss decreased (0.540908 --> 0.538568).  Saving model ...
	 Train_Loss: 0.5536 Train_Acc: 72.650 Val_Loss: 0.5386  BEST VAL Loss: 0.5386  Val_Acc: 72.251

Epoch 9: Validation loss decreased (0.538568 --> 0.536803).  Saving model ...
	 Train_Loss: 0.5510 Train_Acc: 72.837 Val_Loss: 0.5368  BEST VAL Loss: 0.5368  Val_Acc: 72.453

Epoch 10: Validation loss decreased (0.536803 --> 0.535483).  Saving model ...
	 Train_Loss: 0.5489 Train_Acc: 72.744 Val_Loss: 0.5355  BEST VAL Loss: 0.5355  Val_Acc: 72.222

Epoch 11: Validation loss decreased (0.535483 --> 0.534042).  Saving model ...
	 Train_Loss: 0.5465 Train_Acc: 72.931 Val_Loss: 0.5340  BEST VAL Loss: 0.5340  Val_Acc: 72.337

Epoch 12: Validation loss decreased (0.534042 --> 0.533495).  Saving model ...
	 Train_Loss: 0.5444 Train_Acc: 73.021 Val_Loss: 0.5335  BEST VAL Loss: 0.5335  Val_Acc: 72.251

Epoch 13: Validation loss decreased (0.533495 --> 0.533001).  Saving model ...
	 Train_Loss: 0.5427 Train_Acc: 73.157 Val_Loss: 0.5330  BEST VAL Loss: 0.5330  Val_Acc: 71.675

Epoch 14: Validation loss decreased (0.533001 --> 0.532497).  Saving model ...
	 Train_Loss: 0.5411 Train_Acc: 73.291 Val_Loss: 0.5325  BEST VAL Loss: 0.5325  Val_Acc: 72.510

Epoch 15: Validation loss decreased (0.532497 --> 0.531824).  Saving model ...
	 Train_Loss: 0.5395 Train_Acc: 73.107 Val_Loss: 0.5318  BEST VAL Loss: 0.5318  Val_Acc: 72.481

Epoch 16: Validation loss decreased (0.531824 --> 0.531144).  Saving model ...
	 Train_Loss: 0.5382 Train_Acc: 73.327 Val_Loss: 0.5311  BEST VAL Loss: 0.5311  Val_Acc: 73.230

Epoch 17: Validation loss decreased (0.531144 --> 0.530581).  Saving model ...
	 Train_Loss: 0.5368 Train_Acc: 73.395 Val_Loss: 0.5306  BEST VAL Loss: 0.5306  Val_Acc: 72.740

Epoch 18: Validation loss decreased (0.530581 --> 0.530359).  Saving model ...
	 Train_Loss: 0.5356 Train_Acc: 73.467 Val_Loss: 0.5304  BEST VAL Loss: 0.5304  Val_Acc: 72.424

Epoch 19: Validation loss decreased (0.530359 --> 0.530122).  Saving model ...
	 Train_Loss: 0.5345 Train_Acc: 73.575 Val_Loss: 0.5301  BEST VAL Loss: 0.5301  Val_Acc: 72.539

Epoch 20: Validation loss decreased (0.530122 --> 0.529441).  Saving model ...
	 Train_Loss: 0.5332 Train_Acc: 73.766 Val_Loss: 0.5294  BEST VAL Loss: 0.5294  Val_Acc: 72.769

Epoch 21: Validation loss decreased (0.529441 --> 0.529050).  Saving model ...
	 Train_Loss: 0.5321 Train_Acc: 74.010 Val_Loss: 0.5291  BEST VAL Loss: 0.5291  Val_Acc: 72.625

Epoch 22: Validation loss decreased (0.529050 --> 0.528392).  Saving model ...
	 Train_Loss: 0.5310 Train_Acc: 73.650 Val_Loss: 0.5284  BEST VAL Loss: 0.5284  Val_Acc: 73.086

Epoch 23: Validation loss decreased (0.528392 --> 0.527913).  Saving model ...
	 Train_Loss: 0.5299 Train_Acc: 73.701 Val_Loss: 0.5279  BEST VAL Loss: 0.5279  Val_Acc: 73.201

Epoch 24: Validation loss decreased (0.527913 --> 0.527569).  Saving model ...
	 Train_Loss: 0.5290 Train_Acc: 73.665 Val_Loss: 0.5276  BEST VAL Loss: 0.5276  Val_Acc: 73.201

Epoch 25: Validation loss decreased (0.527569 --> 0.527217).  Saving model ...
	 Train_Loss: 0.5280 Train_Acc: 74.233 Val_Loss: 0.5272  BEST VAL Loss: 0.5272  Val_Acc: 73.057

Epoch 26: Validation loss decreased (0.527217 --> 0.527013).  Saving model ...
	 Train_Loss: 0.5271 Train_Acc: 73.845 Val_Loss: 0.5270  BEST VAL Loss: 0.5270  Val_Acc: 73.402

Epoch 27: Validation loss decreased (0.527013 --> 0.526804).  Saving model ...
	 Train_Loss: 0.5263 Train_Acc: 74.003 Val_Loss: 0.5268  BEST VAL Loss: 0.5268  Val_Acc: 73.028

Epoch 28: Validation loss decreased (0.526804 --> 0.526501).  Saving model ...
	 Train_Loss: 0.5255 Train_Acc: 73.971 Val_Loss: 0.5265  BEST VAL Loss: 0.5265  Val_Acc: 73.057

Epoch 29: Validation loss decreased (0.526501 --> 0.526105).  Saving model ...
	 Train_Loss: 0.5247 Train_Acc: 74.284 Val_Loss: 0.5261  BEST VAL Loss: 0.5261  Val_Acc: 73.604

Epoch 30: Validation loss decreased (0.526105 --> 0.525824).  Saving model ...
	 Train_Loss: 0.5239 Train_Acc: 73.946 Val_Loss: 0.5258  BEST VAL Loss: 0.5258  Val_Acc: 73.057

Epoch 31: Validation loss decreased (0.525824 --> 0.525432).  Saving model ...
	 Train_Loss: 0.5231 Train_Acc: 74.410 Val_Loss: 0.5254  BEST VAL Loss: 0.5254  Val_Acc: 73.518

Epoch 32: Validation loss decreased (0.525432 --> 0.525052).  Saving model ...
	 Train_Loss: 0.5224 Train_Acc: 74.172 Val_Loss: 0.5251  BEST VAL Loss: 0.5251  Val_Acc: 73.258

Epoch 33: Validation loss decreased (0.525052 --> 0.524796).  Saving model ...
	 Train_Loss: 0.5216 Train_Acc: 74.521 Val_Loss: 0.5248  BEST VAL Loss: 0.5248  Val_Acc: 73.086

Epoch 34: Validation loss decreased (0.524796 --> 0.524698).  Saving model ...
	 Train_Loss: 0.5210 Train_Acc: 74.248 Val_Loss: 0.5247  BEST VAL Loss: 0.5247  Val_Acc: 72.740

Epoch 35: Validation loss decreased (0.524698 --> 0.524406).  Saving model ...
	 Train_Loss: 0.5204 Train_Acc: 74.140 Val_Loss: 0.5244  BEST VAL Loss: 0.5244  Val_Acc: 73.546

Epoch 36: Validation loss decreased (0.524406 --> 0.524255).  Saving model ...
	 Train_Loss: 0.5197 Train_Acc: 74.280 Val_Loss: 0.5243  BEST VAL Loss: 0.5243  Val_Acc: 73.345

Epoch 37: Validation loss decreased (0.524255 --> 0.524104).  Saving model ...
	 Train_Loss: 0.5191 Train_Acc: 74.345 Val_Loss: 0.5241  BEST VAL Loss: 0.5241  Val_Acc: 73.431

Epoch 38: Validation loss decreased (0.524104 --> 0.523980).  Saving model ...
	 Train_Loss: 0.5185 Train_Acc: 74.190 Val_Loss: 0.5240  BEST VAL Loss: 0.5240  Val_Acc: 73.172

Epoch 39: Validation loss decreased (0.523980 --> 0.523808).  Saving model ...
	 Train_Loss: 0.5179 Train_Acc: 74.316 Val_Loss: 0.5238  BEST VAL Loss: 0.5238  Val_Acc: 73.258

Epoch 40: Validation loss decreased (0.523808 --> 0.523669).  Saving model ...
	 Train_Loss: 0.5174 Train_Acc: 74.305 Val_Loss: 0.5237  BEST VAL Loss: 0.5237  Val_Acc: 73.230

Epoch 41: Validation loss decreased (0.523669 --> 0.523425).  Saving model ...
	 Train_Loss: 0.5168 Train_Acc: 74.269 Val_Loss: 0.5234  BEST VAL Loss: 0.5234  Val_Acc: 73.143

Epoch 42: Validation loss decreased (0.523425 --> 0.523194).  Saving model ...
	 Train_Loss: 0.5163 Train_Acc: 74.183 Val_Loss: 0.5232  BEST VAL Loss: 0.5232  Val_Acc: 73.316

Epoch 43: Validation loss decreased (0.523194 --> 0.522958).  Saving model ...
	 Train_Loss: 0.5158 Train_Acc: 74.467 Val_Loss: 0.5230  BEST VAL Loss: 0.5230  Val_Acc: 73.719

Epoch 44: Validation loss decreased (0.522958 --> 0.522855).  Saving model ...
	 Train_Loss: 0.5153 Train_Acc: 74.284 Val_Loss: 0.5229  BEST VAL Loss: 0.5229  Val_Acc: 73.661

Epoch 45: Validation loss decreased (0.522855 --> 0.522692).  Saving model ...
	 Train_Loss: 0.5148 Train_Acc: 74.363 Val_Loss: 0.5227  BEST VAL Loss: 0.5227  Val_Acc: 72.999

Epoch 46: Validation loss decreased (0.522692 --> 0.522548).  Saving model ...
	 Train_Loss: 0.5143 Train_Acc: 74.424 Val_Loss: 0.5225  BEST VAL Loss: 0.5225  Val_Acc: 72.971

Epoch 47: Validation loss decreased (0.522548 --> 0.522424).  Saving model ...
	 Train_Loss: 0.5138 Train_Acc: 74.266 Val_Loss: 0.5224  BEST VAL Loss: 0.5224  Val_Acc: 73.402

Epoch 48: Validation loss decreased (0.522424 --> 0.522344).  Saving model ...
	 Train_Loss: 0.5134 Train_Acc: 74.356 Val_Loss: 0.5223  BEST VAL Loss: 0.5223  Val_Acc: 73.575

Epoch 49: Validation loss decreased (0.522344 --> 0.522205).  Saving model ...
	 Train_Loss: 0.5129 Train_Acc: 74.460 Val_Loss: 0.5222  BEST VAL Loss: 0.5222  Val_Acc: 73.518

Epoch 50: Validation loss decreased (0.522205 --> 0.522200).  Saving model ...
	 Train_Loss: 0.5125 Train_Acc: 74.547 Val_Loss: 0.5222  BEST VAL Loss: 0.5222  Val_Acc: 73.604

Epoch 51: Validation loss decreased (0.522200 --> 0.522108).  Saving model ...
	 Train_Loss: 0.5120 Train_Acc: 74.489 Val_Loss: 0.5221  BEST VAL Loss: 0.5221  Val_Acc: 74.151

Epoch 52: Validation loss decreased (0.522108 --> 0.522005).  Saving model ...
	 Train_Loss: 0.5116 Train_Acc: 74.349 Val_Loss: 0.5220  BEST VAL Loss: 0.5220  Val_Acc: 73.661

Epoch 53: Validation loss decreased (0.522005 --> 0.521976).  Saving model ...
	 Train_Loss: 0.5112 Train_Acc: 74.543 Val_Loss: 0.5220  BEST VAL Loss: 0.5220  Val_Acc: 73.460

Epoch 54: Validation loss decreased (0.521976 --> 0.521913).  Saving model ...
	 Train_Loss: 0.5108 Train_Acc: 74.313 Val_Loss: 0.5219  BEST VAL Loss: 0.5219  Val_Acc: 73.431

Epoch 55: Validation loss decreased (0.521913 --> 0.521815).  Saving model ...
	 Train_Loss: 0.5104 Train_Acc: 74.547 Val_Loss: 0.5218  BEST VAL Loss: 0.5218  Val_Acc: 73.633

Epoch 56: Validation loss decreased (0.521815 --> 0.521762).  Saving model ...
	 Train_Loss: 0.5100 Train_Acc: 74.579 Val_Loss: 0.5218  BEST VAL Loss: 0.5218  Val_Acc: 73.172

Epoch 57: Validation loss decreased (0.521762 --> 0.521715).  Saving model ...
	 Train_Loss: 0.5096 Train_Acc: 74.921 Val_Loss: 0.5217  BEST VAL Loss: 0.5217  Val_Acc: 73.086

Epoch 58: Validation loss decreased (0.521715 --> 0.521714).  Saving model ...
	 Train_Loss: 0.5092 Train_Acc: 74.755 Val_Loss: 0.5217  BEST VAL Loss: 0.5217  Val_Acc: 72.913

Epoch 59: Validation loss decreased (0.521714 --> 0.521615).  Saving model ...
	 Train_Loss: 0.5088 Train_Acc: 74.601 Val_Loss: 0.5216  BEST VAL Loss: 0.5216  Val_Acc: 73.115

Epoch 60: Validation loss decreased (0.521615 --> 0.521541).  Saving model ...
	 Train_Loss: 0.5084 Train_Acc: 75.140 Val_Loss: 0.5215  BEST VAL Loss: 0.5215  Val_Acc: 73.805

Epoch 61: Validation loss decreased (0.521541 --> 0.521520).  Saving model ...
	 Train_Loss: 0.5080 Train_Acc: 74.593 Val_Loss: 0.5215  BEST VAL Loss: 0.5215  Val_Acc: 72.855

Epoch 62: Validation loss decreased (0.521520 --> 0.521466).  Saving model ...
	 Train_Loss: 0.5076 Train_Acc: 74.755 Val_Loss: 0.5215  BEST VAL Loss: 0.5215  Val_Acc: 73.863

Epoch 63: Validation loss decreased (0.521466 --> 0.521456).  Saving model ...
	 Train_Loss: 0.5073 Train_Acc: 74.798 Val_Loss: 0.5215  BEST VAL Loss: 0.5215  Val_Acc: 73.604

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.5069 Train_Acc: 74.626 Val_Loss: 0.5215  BEST VAL Loss: 0.5215  Val_Acc: 73.518

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.5066 Train_Acc: 74.615 Val_Loss: 0.5215  BEST VAL Loss: 0.5215  Val_Acc: 73.748

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.5063 Train_Acc: 74.723 Val_Loss: 0.5215  BEST VAL Loss: 0.5215  Val_Acc: 73.690

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.5060 Train_Acc: 74.593 Val_Loss: 0.5215  BEST VAL Loss: 0.5215  Val_Acc: 73.489

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.5057 Train_Acc: 74.716 Val_Loss: 0.5216  BEST VAL Loss: 0.5215  Val_Acc: 73.892

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.5054 Train_Acc: 74.680 Val_Loss: 0.5216  BEST VAL Loss: 0.5215  Val_Acc: 73.172

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.5051 Train_Acc: 74.561 Val_Loss: 0.5216  BEST VAL Loss: 0.5215  Val_Acc: 72.971

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.5048 Train_Acc: 74.611 Val_Loss: 0.5217  BEST VAL Loss: 0.5215  Val_Acc: 73.489

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.5045 Train_Acc: 74.838 Val_Loss: 0.5217  BEST VAL Loss: 0.5215  Val_Acc: 73.374

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.5042 Train_Acc: 74.529 Val_Loss: 0.5218  BEST VAL Loss: 0.5215  Val_Acc: 73.863

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.5039 Train_Acc: 74.899 Val_Loss: 0.5218  BEST VAL Loss: 0.5215  Val_Acc: 73.287

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.5036 Train_Acc: 74.694 Val_Loss: 0.5218  BEST VAL Loss: 0.5215  Val_Acc: 73.431

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.5033 Train_Acc: 74.385 Val_Loss: 0.5219  BEST VAL Loss: 0.5215  Val_Acc: 73.143

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.5031 Train_Acc: 74.676 Val_Loss: 0.5220  BEST VAL Loss: 0.5215  Val_Acc: 73.172

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.5028 Train_Acc: 74.734 Val_Loss: 0.5221  BEST VAL Loss: 0.5215  Val_Acc: 73.460

Epoch 79: Validation loss did not decrease
Early stopped at epoch : 79
H2O2_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.81      0.37      0.51      8635
           1       0.77      0.96      0.86     19153

    accuracy                           0.78     27788
   macro avg       0.79      0.66      0.68     27788
weighted avg       0.78      0.78      0.75     27788

H2O2_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.67      0.29      0.41      1079
           1       0.75      0.93      0.83      2395

    accuracy                           0.74      3474
   macro avg       0.71      0.61      0.62      3474
weighted avg       0.72      0.74      0.70      3474

H2O2_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.69      0.31      0.43      1079
           1       0.75      0.94      0.83      2395

    accuracy                           0.74      3474
   macro avg       0.72      0.62      0.63      3474
weighted avg       0.73      0.74      0.71      3474

              precision    recall  f1-score   support

           0       0.69      0.31      0.43      1079
           1       0.75      0.94      0.83      2395

    accuracy                           0.74      3474
   macro avg       0.72      0.62      0.63      3474
weighted avg       0.73      0.74      0.71      3474

H2O2_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.96      0.24      0.39      4135
           1       0.48      0.98      0.65      2957

    accuracy                           0.55      7092
   macro avg       0.72      0.61      0.52      7092
weighted avg       0.76      0.55      0.50      7092

              precision    recall  f1-score   support

           0       0.96      0.24      0.39      4135
           1       0.48      0.98      0.65      2957

    accuracy                           0.55      7092
   macro avg       0.72      0.61      0.52      7092
weighted avg       0.76      0.55      0.50      7092

completed
