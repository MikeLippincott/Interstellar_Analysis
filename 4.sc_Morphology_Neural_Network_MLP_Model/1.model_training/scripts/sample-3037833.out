[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b83ca546'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '8fdb471b'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '83615a8c'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'a032043c'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_1.000_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_1.000_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (31386, 1276)
Number of total missing values across all columns: 62772
Data Subset Is Off
Wells held out for testing: ['D21' 'L22']
Wells to use for training, validation, and testing ['D16' 'D17' 'D20' 'L18' 'L19' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.663914).  Saving model ...
	 Train_Loss: 0.6798 Train_Acc: 56.210 Val_Loss: 0.6639  BEST VAL Loss: 0.6639  Val_Acc: 60.309

Epoch 1: Validation loss decreased (0.663914 --> 0.651902).  Saving model ...
	 Train_Loss: 0.6666 Train_Acc: 61.355 Val_Loss: 0.6519  BEST VAL Loss: 0.6519  Val_Acc: 65.152

Epoch 2: Validation loss decreased (0.651902 --> 0.636814).  Saving model ...
	 Train_Loss: 0.6539 Train_Acc: 64.334 Val_Loss: 0.6368  BEST VAL Loss: 0.6368  Val_Acc: 66.695

Epoch 3: Validation loss decreased (0.636814 --> 0.624758).  Saving model ...
	 Train_Loss: 0.6403 Train_Acc: 67.581 Val_Loss: 0.6248  BEST VAL Loss: 0.6248  Val_Acc: 69.396

Epoch 4: Validation loss decreased (0.624758 --> 0.613610).  Saving model ...
	 Train_Loss: 0.6277 Train_Acc: 69.382 Val_Loss: 0.6136  BEST VAL Loss: 0.6136  Val_Acc: 69.396

Epoch 5: Validation loss decreased (0.613610 --> 0.604851).  Saving model ...
	 Train_Loss: 0.6173 Train_Acc: 70.405 Val_Loss: 0.6049  BEST VAL Loss: 0.6049  Val_Acc: 70.767

Epoch 6: Validation loss decreased (0.604851 --> 0.596158).  Saving model ...
	 Train_Loss: 0.6076 Train_Acc: 72.200 Val_Loss: 0.5962  BEST VAL Loss: 0.5962  Val_Acc: 72.225

Epoch 7: Validation loss decreased (0.596158 --> 0.589057).  Saving model ...
	 Train_Loss: 0.5992 Train_Acc: 72.988 Val_Loss: 0.5891  BEST VAL Loss: 0.5891  Val_Acc: 72.996

Epoch 8: Validation loss decreased (0.589057 --> 0.583770).  Saving model ...
	 Train_Loss: 0.5913 Train_Acc: 73.754 Val_Loss: 0.5838  BEST VAL Loss: 0.5838  Val_Acc: 72.653

Epoch 9: Validation loss decreased (0.583770 --> 0.578460).  Saving model ...
	 Train_Loss: 0.5838 Train_Acc: 74.488 Val_Loss: 0.5785  BEST VAL Loss: 0.5785  Val_Acc: 73.639

Epoch 10: Validation loss decreased (0.578460 --> 0.573914).  Saving model ...
	 Train_Loss: 0.5770 Train_Acc: 75.083 Val_Loss: 0.5739  BEST VAL Loss: 0.5739  Val_Acc: 73.382

Epoch 11: Validation loss decreased (0.573914 --> 0.569923).  Saving model ...
	 Train_Loss: 0.5707 Train_Acc: 75.753 Val_Loss: 0.5699  BEST VAL Loss: 0.5699  Val_Acc: 73.596

Epoch 12: Validation loss decreased (0.569923 --> 0.566006).  Saving model ...
	 Train_Loss: 0.5650 Train_Acc: 75.919 Val_Loss: 0.5660  BEST VAL Loss: 0.5660  Val_Acc: 74.153

Epoch 13: Validation loss decreased (0.566006 --> 0.562942).  Saving model ...
	 Train_Loss: 0.5597 Train_Acc: 76.005 Val_Loss: 0.5629  BEST VAL Loss: 0.5629  Val_Acc: 74.668

Epoch 14: Validation loss decreased (0.562942 --> 0.560262).  Saving model ...
	 Train_Loss: 0.5544 Train_Acc: 77.253 Val_Loss: 0.5603  BEST VAL Loss: 0.5603  Val_Acc: 74.239

Epoch 15: Validation loss decreased (0.560262 --> 0.557697).  Saving model ...
	 Train_Loss: 0.5493 Train_Acc: 77.371 Val_Loss: 0.5577  BEST VAL Loss: 0.5577  Val_Acc: 73.553

Epoch 16: Validation loss decreased (0.557697 --> 0.555691).  Saving model ...
	 Train_Loss: 0.5443 Train_Acc: 77.843 Val_Loss: 0.5557  BEST VAL Loss: 0.5557  Val_Acc: 73.468

Epoch 17: Validation loss decreased (0.555691 --> 0.554141).  Saving model ...
	 Train_Loss: 0.5400 Train_Acc: 77.907 Val_Loss: 0.5541  BEST VAL Loss: 0.5541  Val_Acc: 73.468

Epoch 18: Validation loss decreased (0.554141 --> 0.552482).  Saving model ...
	 Train_Loss: 0.5359 Train_Acc: 78.255 Val_Loss: 0.5525  BEST VAL Loss: 0.5525  Val_Acc: 74.539

Epoch 19: Validation loss decreased (0.552482 --> 0.550826).  Saving model ...
	 Train_Loss: 0.5319 Train_Acc: 78.496 Val_Loss: 0.5508  BEST VAL Loss: 0.5508  Val_Acc: 74.282

Epoch 20: Validation loss decreased (0.550826 --> 0.550435).  Saving model ...
	 Train_Loss: 0.5279 Train_Acc: 79.241 Val_Loss: 0.5504  BEST VAL Loss: 0.5504  Val_Acc: 74.368

Epoch 21: Validation loss decreased (0.550435 --> 0.549718).  Saving model ...
	 Train_Loss: 0.5242 Train_Acc: 79.182 Val_Loss: 0.5497  BEST VAL Loss: 0.5497  Val_Acc: 73.596

Epoch 22: Validation loss decreased (0.549718 --> 0.548540).  Saving model ...
	 Train_Loss: 0.5210 Train_Acc: 78.738 Val_Loss: 0.5485  BEST VAL Loss: 0.5485  Val_Acc: 75.096

Epoch 23: Validation loss decreased (0.548540 --> 0.547676).  Saving model ...
	 Train_Loss: 0.5178 Train_Acc: 79.188 Val_Loss: 0.5477  BEST VAL Loss: 0.5477  Val_Acc: 74.582

Epoch 24: Validation loss decreased (0.547676 --> 0.546726).  Saving model ...
	 Train_Loss: 0.5148 Train_Acc: 78.989 Val_Loss: 0.5467  BEST VAL Loss: 0.5467  Val_Acc: 74.711

Epoch 25: Validation loss decreased (0.546726 --> 0.546251).  Saving model ...
	 Train_Loss: 0.5119 Train_Acc: 79.740 Val_Loss: 0.5463  BEST VAL Loss: 0.5463  Val_Acc: 74.839

Epoch 26: Validation loss decreased (0.546251 --> 0.545552).  Saving model ...
	 Train_Loss: 0.5091 Train_Acc: 79.279 Val_Loss: 0.5456  BEST VAL Loss: 0.5456  Val_Acc: 75.782

Epoch 27: Validation loss decreased (0.545552 --> 0.545130).  Saving model ...
	 Train_Loss: 0.5063 Train_Acc: 79.799 Val_Loss: 0.5451  BEST VAL Loss: 0.5451  Val_Acc: 75.482

Epoch 28: Validation loss decreased (0.545130 --> 0.544763).  Saving model ...
	 Train_Loss: 0.5036 Train_Acc: 79.965 Val_Loss: 0.5448  BEST VAL Loss: 0.5448  Val_Acc: 75.011

Epoch 29: Validation loss decreased (0.544763 --> 0.544263).  Saving model ...
	 Train_Loss: 0.5012 Train_Acc: 79.841 Val_Loss: 0.5443  BEST VAL Loss: 0.5443  Val_Acc: 75.054

Epoch 30: Validation loss decreased (0.544263 --> 0.544232).  Saving model ...
	 Train_Loss: 0.4987 Train_Acc: 80.318 Val_Loss: 0.5442  BEST VAL Loss: 0.5442  Val_Acc: 74.025

Epoch 31: Validation loss decreased (0.544232 --> 0.543479).  Saving model ...
	 Train_Loss: 0.4967 Train_Acc: 79.482 Val_Loss: 0.5435  BEST VAL Loss: 0.5435  Val_Acc: 75.139

Epoch 32: Validation loss decreased (0.543479 --> 0.543437).  Saving model ...
	 Train_Loss: 0.4945 Train_Acc: 79.852 Val_Loss: 0.5434  BEST VAL Loss: 0.5434  Val_Acc: 74.239

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.4922 Train_Acc: 80.586 Val_Loss: 0.5438  BEST VAL Loss: 0.5434  Val_Acc: 73.682

Epoch 34: Validation loss decreased (0.543437 --> 0.543253).  Saving model ...
	 Train_Loss: 0.4901 Train_Acc: 80.715 Val_Loss: 0.5433  BEST VAL Loss: 0.5433  Val_Acc: 75.354

Epoch 35: Validation loss decreased (0.543253 --> 0.543069).  Saving model ...
	 Train_Loss: 0.4880 Train_Acc: 80.908 Val_Loss: 0.5431  BEST VAL Loss: 0.5431  Val_Acc: 74.368

Epoch 36: Validation loss decreased (0.543069 --> 0.543017).  Saving model ...
	 Train_Loss: 0.4857 Train_Acc: 81.422 Val_Loss: 0.5430  BEST VAL Loss: 0.5430  Val_Acc: 74.625

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.4838 Train_Acc: 80.972 Val_Loss: 0.5431  BEST VAL Loss: 0.5430  Val_Acc: 74.282

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.4818 Train_Acc: 80.977 Val_Loss: 0.5431  BEST VAL Loss: 0.5430  Val_Acc: 74.925

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.4799 Train_Acc: 81.036 Val_Loss: 0.5430  BEST VAL Loss: 0.5430  Val_Acc: 75.139

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.4781 Train_Acc: 81.042 Val_Loss: 0.5436  BEST VAL Loss: 0.5430  Val_Acc: 74.539

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.4762 Train_Acc: 81.352 Val_Loss: 0.5441  BEST VAL Loss: 0.5430  Val_Acc: 73.768

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.4745 Train_Acc: 81.395 Val_Loss: 0.5444  BEST VAL Loss: 0.5430  Val_Acc: 73.596

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.4727 Train_Acc: 81.379 Val_Loss: 0.5446  BEST VAL Loss: 0.5430  Val_Acc: 74.239

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.4709 Train_Acc: 81.878 Val_Loss: 0.5452  BEST VAL Loss: 0.5430  Val_Acc: 73.811

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.4693 Train_Acc: 81.974 Val_Loss: 0.5457  BEST VAL Loss: 0.5430  Val_Acc: 74.111

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.4676 Train_Acc: 81.749 Val_Loss: 0.5460  BEST VAL Loss: 0.5430  Val_Acc: 73.768

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.4659 Train_Acc: 81.979 Val_Loss: 0.5463  BEST VAL Loss: 0.5430  Val_Acc: 74.325

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.4643 Train_Acc: 82.146 Val_Loss: 0.5470  BEST VAL Loss: 0.5430  Val_Acc: 74.282

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.4629 Train_Acc: 82.178 Val_Loss: 0.5475  BEST VAL Loss: 0.5430  Val_Acc: 73.853

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.4614 Train_Acc: 82.505 Val_Loss: 0.5481  BEST VAL Loss: 0.5430  Val_Acc: 73.853

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.4599 Train_Acc: 82.178 Val_Loss: 0.5487  BEST VAL Loss: 0.5430  Val_Acc: 73.682

Epoch 52: Validation loss did not decrease
Early stopped at epoch : 52
LPS_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.82      0.88      0.85      8635
           1       0.89      0.84      0.86     10027

    accuracy                           0.86     18662
   macro avg       0.86      0.86      0.86     18662
weighted avg       0.86      0.86      0.86     18662

LPS_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.72      0.74      0.73      1079
           1       0.77      0.75      0.76      1254

    accuracy                           0.75      2333
   macro avg       0.75      0.75      0.75      2333
weighted avg       0.75      0.75      0.75      2333

LPS_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.69      0.74      0.72      1079
           1       0.76      0.72      0.74      1254

    accuracy                           0.73      2333
   macro avg       0.73      0.73      0.73      2333
weighted avg       0.73      0.73      0.73      2333

              precision    recall  f1-score   support

           0       0.69      0.74      0.72      1079
           1       0.76      0.72      0.74      1254

    accuracy                           0.73      2333
   macro avg       0.73      0.73      0.73      2333
weighted avg       0.73      0.73      0.73      2333

LPS_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.43      0.50      0.46      4135
           1       0.36      0.30      0.33      3923

    accuracy                           0.40      8058
   macro avg       0.40      0.40      0.39      8058
weighted avg       0.40      0.40      0.40      8058

              precision    recall  f1-score   support

           0       0.43      0.50      0.46      4135
           1       0.36      0.30      0.33      3923

    accuracy                           0.40      8058
   macro avg       0.40      0.40      0.39      8058
weighted avg       0.40      0.40      0.40      8058

completed
