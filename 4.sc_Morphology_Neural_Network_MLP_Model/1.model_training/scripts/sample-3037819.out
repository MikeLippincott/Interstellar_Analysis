[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '5edfe0e0'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '3e6c3558'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '150e0c47'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '0127cef9'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_Nigericin_1.000_10.0_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (29330, 1276)
Number of total missing values across all columns: 29856
Data Subset Is Off
Wells held out for testing: ['M16' 'L22']
Wells to use for training, validation, and testing ['M17' 'L18' 'L19' 'M20' 'M21' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.276921).  Saving model ...
	 Train_Loss: 0.4938 Train_Acc: 73.077 Val_Loss: 0.2769  BEST VAL Loss: 0.2769  Val_Acc: 88.800

Epoch 1: Validation loss decreased (0.276921 --> 0.238040).  Saving model ...
	 Train_Loss: 0.4238 Train_Acc: 83.287 Val_Loss: 0.2380  BEST VAL Loss: 0.2380  Val_Acc: 91.659

Epoch 2: Validation loss decreased (0.238040 --> 0.219704).  Saving model ...
	 Train_Loss: 0.3825 Train_Acc: 85.754 Val_Loss: 0.2197  BEST VAL Loss: 0.2197  Val_Acc: 92.549

Epoch 3: Validation loss decreased (0.219704 --> 0.206794).  Saving model ...
	 Train_Loss: 0.3551 Train_Acc: 86.896 Val_Loss: 0.2068  BEST VAL Loss: 0.2068  Val_Acc: 93.393

Epoch 4: Validation loss decreased (0.206794 --> 0.196249).  Saving model ...
	 Train_Loss: 0.3395 Train_Acc: 87.007 Val_Loss: 0.1962  BEST VAL Loss: 0.1962  Val_Acc: 93.627

Epoch 5: Validation loss decreased (0.196249 --> 0.189875).  Saving model ...
	 Train_Loss: 0.3264 Train_Acc: 87.218 Val_Loss: 0.1899  BEST VAL Loss: 0.1899  Val_Acc: 93.533

Epoch 6: Validation loss decreased (0.189875 --> 0.184570).  Saving model ...
	 Train_Loss: 0.3151 Train_Acc: 87.517 Val_Loss: 0.1846  BEST VAL Loss: 0.1846  Val_Acc: 93.346

Epoch 7: Validation loss decreased (0.184570 --> 0.183283).  Saving model ...
	 Train_Loss: 0.3057 Train_Acc: 88.050 Val_Loss: 0.1833  BEST VAL Loss: 0.1833  Val_Acc: 94.096

Epoch 8: Validation loss decreased (0.183283 --> 0.180243).  Saving model ...
	 Train_Loss: 0.2980 Train_Acc: 88.202 Val_Loss: 0.1802  BEST VAL Loss: 0.1802  Val_Acc: 94.658

Epoch 9: Validation loss decreased (0.180243 --> 0.178407).  Saving model ...
	 Train_Loss: 0.2914 Train_Acc: 88.384 Val_Loss: 0.1784  BEST VAL Loss: 0.1784  Val_Acc: 93.768

Epoch 10: Validation loss decreased (0.178407 --> 0.176075).  Saving model ...
	 Train_Loss: 0.2860 Train_Acc: 88.144 Val_Loss: 0.1761  BEST VAL Loss: 0.1761  Val_Acc: 94.752

Epoch 11: Validation loss did not decrease
	 Train_Loss: 0.2807 Train_Acc: 88.899 Val_Loss: 0.1781  BEST VAL Loss: 0.1761  Val_Acc: 95.314

Epoch 12: Validation loss did not decrease
	 Train_Loss: 0.2759 Train_Acc: 88.911 Val_Loss: 0.1769  BEST VAL Loss: 0.1761  Val_Acc: 94.049

Epoch 13: Validation loss decreased (0.176075 --> 0.175443).  Saving model ...
	 Train_Loss: 0.2720 Train_Acc: 88.595 Val_Loss: 0.1754  BEST VAL Loss: 0.1754  Val_Acc: 94.799

Epoch 14: Validation loss decreased (0.175443 --> 0.171805).  Saving model ...
	 Train_Loss: 0.2675 Train_Acc: 89.139 Val_Loss: 0.1718  BEST VAL Loss: 0.1718  Val_Acc: 95.220

Epoch 15: Validation loss decreased (0.171805 --> 0.169379).  Saving model ...
	 Train_Loss: 0.2633 Train_Acc: 89.637 Val_Loss: 0.1694  BEST VAL Loss: 0.1694  Val_Acc: 95.173

Epoch 16: Validation loss decreased (0.169379 --> 0.168582).  Saving model ...
	 Train_Loss: 0.2600 Train_Acc: 89.315 Val_Loss: 0.1686  BEST VAL Loss: 0.1686  Val_Acc: 94.799

Epoch 17: Validation loss decreased (0.168582 --> 0.166158).  Saving model ...
	 Train_Loss: 0.2569 Train_Acc: 89.122 Val_Loss: 0.1662  BEST VAL Loss: 0.1662  Val_Acc: 95.408

Epoch 18: Validation loss decreased (0.166158 --> 0.163939).  Saving model ...
	 Train_Loss: 0.2542 Train_Acc: 89.151 Val_Loss: 0.1639  BEST VAL Loss: 0.1639  Val_Acc: 94.799

Epoch 19: Validation loss decreased (0.163939 --> 0.162344).  Saving model ...
	 Train_Loss: 0.2514 Train_Acc: 89.673 Val_Loss: 0.1623  BEST VAL Loss: 0.1623  Val_Acc: 94.939

Epoch 20: Validation loss did not decrease
	 Train_Loss: 0.2501 Train_Acc: 88.325 Val_Loss: 0.1630  BEST VAL Loss: 0.1623  Val_Acc: 95.689

Epoch 21: Validation loss decreased (0.162344 --> 0.161607).  Saving model ...
	 Train_Loss: 0.2484 Train_Acc: 89.110 Val_Loss: 0.1616  BEST VAL Loss: 0.1616  Val_Acc: 95.408

Epoch 22: Validation loss decreased (0.161607 --> 0.159708).  Saving model ...
	 Train_Loss: 0.2466 Train_Acc: 88.964 Val_Loss: 0.1597  BEST VAL Loss: 0.1597  Val_Acc: 95.501

Epoch 23: Validation loss decreased (0.159708 --> 0.158345).  Saving model ...
	 Train_Loss: 0.2444 Train_Acc: 89.602 Val_Loss: 0.1583  BEST VAL Loss: 0.1583  Val_Acc: 95.642

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.2424 Train_Acc: 89.620 Val_Loss: 0.1589  BEST VAL Loss: 0.1583  Val_Acc: 95.455

Epoch 25: Validation loss decreased (0.158345 --> 0.156380).  Saving model ...
	 Train_Loss: 0.2407 Train_Acc: 89.813 Val_Loss: 0.1564  BEST VAL Loss: 0.1564  Val_Acc: 95.783

Epoch 26: Validation loss did not decrease
	 Train_Loss: 0.2391 Train_Acc: 89.333 Val_Loss: 0.1574  BEST VAL Loss: 0.1564  Val_Acc: 95.501

Epoch 27: Validation loss decreased (0.156380 --> 0.155610).  Saving model ...
	 Train_Loss: 0.2378 Train_Acc: 89.901 Val_Loss: 0.1556  BEST VAL Loss: 0.1556  Val_Acc: 95.736

Epoch 28: Validation loss decreased (0.155610 --> 0.153956).  Saving model ...
	 Train_Loss: 0.2370 Train_Acc: 88.724 Val_Loss: 0.1540  BEST VAL Loss: 0.1540  Val_Acc: 95.267

Epoch 29: Validation loss decreased (0.153956 --> 0.152566).  Saving model ...
	 Train_Loss: 0.2357 Train_Acc: 89.760 Val_Loss: 0.1526  BEST VAL Loss: 0.1526  Val_Acc: 95.876

Epoch 30: Validation loss decreased (0.152566 --> 0.151388).  Saving model ...
	 Train_Loss: 0.2347 Train_Acc: 89.579 Val_Loss: 0.1514  BEST VAL Loss: 0.1514  Val_Acc: 95.314

Epoch 31: Validation loss decreased (0.151388 --> 0.150728).  Saving model ...
	 Train_Loss: 0.2335 Train_Acc: 89.579 Val_Loss: 0.1507  BEST VAL Loss: 0.1507  Val_Acc: 95.080

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.2323 Train_Acc: 89.848 Val_Loss: 0.1511  BEST VAL Loss: 0.1507  Val_Acc: 95.127

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.2315 Train_Acc: 89.661 Val_Loss: 0.1512  BEST VAL Loss: 0.1507  Val_Acc: 94.939

Epoch 34: Validation loss decreased (0.150728 --> 0.149889).  Saving model ...
	 Train_Loss: 0.2310 Train_Acc: 89.743 Val_Loss: 0.1499  BEST VAL Loss: 0.1499  Val_Acc: 95.689

Epoch 35: Validation loss decreased (0.149889 --> 0.148947).  Saving model ...
	 Train_Loss: 0.2309 Train_Acc: 89.134 Val_Loss: 0.1489  BEST VAL Loss: 0.1489  Val_Acc: 96.064

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.2313 Train_Acc: 88.097 Val_Loss: 0.1496  BEST VAL Loss: 0.1489  Val_Acc: 95.080

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.2317 Train_Acc: 88.630 Val_Loss: 0.1502  BEST VAL Loss: 0.1489  Val_Acc: 94.517

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.2321 Train_Acc: 88.243 Val_Loss: 0.1501  BEST VAL Loss: 0.1489  Val_Acc: 94.892

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.2320 Train_Acc: 88.952 Val_Loss: 0.1496  BEST VAL Loss: 0.1489  Val_Acc: 93.955

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.2321 Train_Acc: 88.472 Val_Loss: 0.1504  BEST VAL Loss: 0.1489  Val_Acc: 95.361

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.2318 Train_Acc: 89.561 Val_Loss: 0.1498  BEST VAL Loss: 0.1489  Val_Acc: 93.674

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.2314 Train_Acc: 89.450 Val_Loss: 0.1503  BEST VAL Loss: 0.1489  Val_Acc: 94.986

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.2311 Train_Acc: 89.637 Val_Loss: 0.1495  BEST VAL Loss: 0.1489  Val_Acc: 94.845

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.2306 Train_Acc: 90.135 Val_Loss: 0.1491  BEST VAL Loss: 0.1489  Val_Acc: 94.002

Epoch 45: Validation loss decreased (0.148947 --> 0.148354).  Saving model ...
	 Train_Loss: 0.2301 Train_Acc: 90.112 Val_Loss: 0.1484  BEST VAL Loss: 0.1484  Val_Acc: 93.908

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.2297 Train_Acc: 89.245 Val_Loss: 0.1491  BEST VAL Loss: 0.1484  Val_Acc: 94.845

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.2294 Train_Acc: 89.667 Val_Loss: 0.1485  BEST VAL Loss: 0.1484  Val_Acc: 94.470

Epoch 48: Validation loss decreased (0.148354 --> 0.148165).  Saving model ...
	 Train_Loss: 0.2289 Train_Acc: 90.053 Val_Loss: 0.1482  BEST VAL Loss: 0.1482  Val_Acc: 95.173

Epoch 49: Validation loss decreased (0.148165 --> 0.147827).  Saving model ...
	 Train_Loss: 0.2284 Train_Acc: 90.065 Val_Loss: 0.1478  BEST VAL Loss: 0.1478  Val_Acc: 94.892

Epoch 50: Validation loss decreased (0.147827 --> 0.147489).  Saving model ...
	 Train_Loss: 0.2277 Train_Acc: 90.165 Val_Loss: 0.1475  BEST VAL Loss: 0.1475  Val_Acc: 95.548

Epoch 51: Validation loss decreased (0.147489 --> 0.147442).  Saving model ...
	 Train_Loss: 0.2271 Train_Acc: 89.919 Val_Loss: 0.1474  BEST VAL Loss: 0.1474  Val_Acc: 94.845

Epoch 52: Validation loss decreased (0.147442 --> 0.147281).  Saving model ...
	 Train_Loss: 0.2265 Train_Acc: 90.071 Val_Loss: 0.1473  BEST VAL Loss: 0.1473  Val_Acc: 95.127

Epoch 53: Validation loss decreased (0.147281 --> 0.146993).  Saving model ...
	 Train_Loss: 0.2261 Train_Acc: 90.153 Val_Loss: 0.1470  BEST VAL Loss: 0.1470  Val_Acc: 94.845

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.2261 Train_Acc: 88.835 Val_Loss: 0.1470  BEST VAL Loss: 0.1470  Val_Acc: 94.424

Epoch 55: Validation loss decreased (0.146993 --> 0.146525).  Saving model ...
	 Train_Loss: 0.2265 Train_Acc: 88.155 Val_Loss: 0.1465  BEST VAL Loss: 0.1465  Val_Acc: 95.033

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.2264 Train_Acc: 89.362 Val_Loss: 0.1467  BEST VAL Loss: 0.1465  Val_Acc: 93.908

Epoch 57: Validation loss decreased (0.146525 --> 0.146524).  Saving model ...
	 Train_Loss: 0.2261 Train_Acc: 89.280 Val_Loss: 0.1465  BEST VAL Loss: 0.1465  Val_Acc: 94.799

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.2257 Train_Acc: 89.960 Val_Loss: 0.1468  BEST VAL Loss: 0.1465  Val_Acc: 94.939

Epoch 59: Validation loss decreased (0.146524 --> 0.146226).  Saving model ...
	 Train_Loss: 0.2252 Train_Acc: 90.065 Val_Loss: 0.1462  BEST VAL Loss: 0.1462  Val_Acc: 95.127

Epoch 60: Validation loss decreased (0.146226 --> 0.145813).  Saving model ...
	 Train_Loss: 0.2250 Train_Acc: 89.555 Val_Loss: 0.1458  BEST VAL Loss: 0.1458  Val_Acc: 94.892

Epoch 61: Validation loss decreased (0.145813 --> 0.145642).  Saving model ...
	 Train_Loss: 0.2252 Train_Acc: 88.858 Val_Loss: 0.1456  BEST VAL Loss: 0.1456  Val_Acc: 94.564

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.2254 Train_Acc: 88.149 Val_Loss: 0.1459  BEST VAL Loss: 0.1456  Val_Acc: 94.611

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.2257 Train_Acc: 88.548 Val_Loss: 0.1460  BEST VAL Loss: 0.1456  Val_Acc: 93.580

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.2261 Train_Acc: 87.599 Val_Loss: 0.1459  BEST VAL Loss: 0.1456  Val_Acc: 94.283

Epoch 65: Validation loss decreased (0.145642 --> 0.145614).  Saving model ...
	 Train_Loss: 0.2261 Train_Acc: 89.257 Val_Loss: 0.1456  BEST VAL Loss: 0.1456  Val_Acc: 94.939

Epoch 66: Validation loss decreased (0.145614 --> 0.145398).  Saving model ...
	 Train_Loss: 0.2258 Train_Acc: 89.626 Val_Loss: 0.1454  BEST VAL Loss: 0.1454  Val_Acc: 94.752

Epoch 67: Validation loss decreased (0.145398 --> 0.145375).  Saving model ...
	 Train_Loss: 0.2256 Train_Acc: 89.339 Val_Loss: 0.1454  BEST VAL Loss: 0.1454  Val_Acc: 94.611

Epoch 68: Validation loss decreased (0.145375 --> 0.145271).  Saving model ...
	 Train_Loss: 0.2258 Train_Acc: 87.892 Val_Loss: 0.1453  BEST VAL Loss: 0.1453  Val_Acc: 94.142

Epoch 69: Validation loss decreased (0.145271 --> 0.144853).  Saving model ...
	 Train_Loss: 0.2261 Train_Acc: 87.739 Val_Loss: 0.1449  BEST VAL Loss: 0.1449  Val_Acc: 94.517

Epoch 70: Validation loss decreased (0.144853 --> 0.144700).  Saving model ...
	 Train_Loss: 0.2262 Train_Acc: 88.308 Val_Loss: 0.1447  BEST VAL Loss: 0.1447  Val_Acc: 95.127

Epoch 71: Validation loss decreased (0.144700 --> 0.144410).  Saving model ...
	 Train_Loss: 0.2262 Train_Acc: 88.870 Val_Loss: 0.1444  BEST VAL Loss: 0.1444  Val_Acc: 94.892

Epoch 72: Validation loss decreased (0.144410 --> 0.144143).  Saving model ...
	 Train_Loss: 0.2262 Train_Acc: 89.309 Val_Loss: 0.1441  BEST VAL Loss: 0.1441  Val_Acc: 95.689

Epoch 73: Validation loss decreased (0.144143 --> 0.143790).  Saving model ...
	 Train_Loss: 0.2260 Train_Acc: 89.356 Val_Loss: 0.1438  BEST VAL Loss: 0.1438  Val_Acc: 94.658

Epoch 74: Validation loss decreased (0.143790 --> 0.143640).  Saving model ...
	 Train_Loss: 0.2259 Train_Acc: 89.087 Val_Loss: 0.1436  BEST VAL Loss: 0.1436  Val_Acc: 95.220

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.2258 Train_Acc: 89.386 Val_Loss: 0.1437  BEST VAL Loss: 0.1436  Val_Acc: 95.455

Epoch 76: Validation loss decreased (0.143640 --> 0.143243).  Saving model ...
	 Train_Loss: 0.2257 Train_Acc: 89.391 Val_Loss: 0.1432  BEST VAL Loss: 0.1432  Val_Acc: 95.173

Epoch 77: Validation loss decreased (0.143243 --> 0.142782).  Saving model ...
	 Train_Loss: 0.2257 Train_Acc: 88.606 Val_Loss: 0.1428  BEST VAL Loss: 0.1428  Val_Acc: 95.361

Epoch 78: Validation loss decreased (0.142782 --> 0.142287).  Saving model ...
	 Train_Loss: 0.2256 Train_Acc: 88.788 Val_Loss: 0.1423  BEST VAL Loss: 0.1423  Val_Acc: 95.642

Epoch 79: Validation loss decreased (0.142287 --> 0.142146).  Saving model ...
	 Train_Loss: 0.2257 Train_Acc: 88.190 Val_Loss: 0.1421  BEST VAL Loss: 0.1421  Val_Acc: 95.080

Epoch 80: Validation loss decreased (0.142146 --> 0.141651).  Saving model ...
	 Train_Loss: 0.2256 Train_Acc: 88.970 Val_Loss: 0.1417  BEST VAL Loss: 0.1417  Val_Acc: 95.127

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.2255 Train_Acc: 88.952 Val_Loss: 0.1420  BEST VAL Loss: 0.1417  Val_Acc: 95.829

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.2254 Train_Acc: 89.075 Val_Loss: 0.1418  BEST VAL Loss: 0.1417  Val_Acc: 95.127

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.2254 Train_Acc: 88.776 Val_Loss: 0.1417  BEST VAL Loss: 0.1417  Val_Acc: 94.799

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.2257 Train_Acc: 87.880 Val_Loss: 0.1418  BEST VAL Loss: 0.1417  Val_Acc: 96.017

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.2260 Train_Acc: 88.425 Val_Loss: 0.1424  BEST VAL Loss: 0.1417  Val_Acc: 94.096

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.2267 Train_Acc: 86.890 Val_Loss: 0.1431  BEST VAL Loss: 0.1417  Val_Acc: 89.550

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.2277 Train_Acc: 85.765 Val_Loss: 0.1434  BEST VAL Loss: 0.1417  Val_Acc: 93.346

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.2287 Train_Acc: 85.941 Val_Loss: 0.1444  BEST VAL Loss: 0.1417  Val_Acc: 89.363

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.2300 Train_Acc: 83.844 Val_Loss: 0.1462  BEST VAL Loss: 0.1417  Val_Acc: 90.675

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.2308 Train_Acc: 84.623 Val_Loss: 0.1468  BEST VAL Loss: 0.1417  Val_Acc: 92.362

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.2313 Train_Acc: 86.667 Val_Loss: 0.1469  BEST VAL Loss: 0.1417  Val_Acc: 92.455

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.2319 Train_Acc: 86.503 Val_Loss: 0.1474  BEST VAL Loss: 0.1417  Val_Acc: 93.627

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.2323 Train_Acc: 87.253 Val_Loss: 0.1475  BEST VAL Loss: 0.1417  Val_Acc: 94.377

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.2327 Train_Acc: 87.447 Val_Loss: 0.1475  BEST VAL Loss: 0.1417  Val_Acc: 93.533

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.2329 Train_Acc: 87.435 Val_Loss: 0.1477  BEST VAL Loss: 0.1417  Val_Acc: 94.377

Epoch 96: Validation loss did not decrease
Early stopped at epoch : 96
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.53      0.52      8635
           1       0.50      0.49      0.50      8436

    accuracy                           0.51     17071
   macro avg       0.51      0.51      0.51     17071
weighted avg       0.51      0.51      0.51     17071

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.52      0.51      1079
           1       0.48      0.46      0.47      1055

    accuracy                           0.49      2134
   macro avg       0.49      0.49      0.49      2134
weighted avg       0.49      0.49      0.49      2134

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.51      0.50      1079
           1       0.49      0.48      0.48      1055

    accuracy                           0.49      2134
   macro avg       0.49      0.49      0.49      2134
weighted avg       0.49      0.49      0.49      2134

              precision    recall  f1-score   support

           0       0.50      0.51      0.50      1079
           1       0.49      0.48      0.48      1055

    accuracy                           0.49      2134
   macro avg       0.49      0.49      0.49      2134
weighted avg       0.49      0.49      0.49      2134

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.53      0.52      4135
           1       0.47      0.46      0.47      3856

    accuracy                           0.49      7991
   macro avg       0.49      0.49      0.49      7991
weighted avg       0.49      0.49      0.49      7991

              precision    recall  f1-score   support

           0       0.51      0.53      0.52      4135
           1       0.47      0.46      0.47      3856

    accuracy                           0.49      7991
   macro avg       0.49      0.49      0.49      7991
weighted avg       0.49      0.49      0.49      7991

completed
