[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '0fd5bf2a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '84093f1e'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '92473a6b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '91ce8585'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_0.010_DMSO_0.025 treatment_name: LPS_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_0.010_DMSO_0.025
TREATMENT_NAME: LPS_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_1.000_DMSO_0.025']
The dimensions of the data are: (282513, 1270)
Number of total missing values across all columns: 565026
Data Subset Is Off
Wells held out for testing: ['B08' 'D08']
Wells to use for training, validation, and testing ['B02' 'B03' 'B09' 'D02' 'D03' 'D09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.593241).  Saving model ...
	 Train_Loss: 0.6329 Train_Acc: 61.437 Val_Loss: 0.5932  BEST VAL Loss: 0.5932  Val_Acc: 64.670

Epoch 1: Validation loss decreased (0.593241 --> 0.586242).  Saving model ...
	 Train_Loss: 0.6111 Train_Acc: 64.506 Val_Loss: 0.5862  BEST VAL Loss: 0.5862  Val_Acc: 66.558

Epoch 2: Validation loss decreased (0.586242 --> 0.575019).  Saving model ...
	 Train_Loss: 0.5971 Train_Acc: 66.875 Val_Loss: 0.5750  BEST VAL Loss: 0.5750  Val_Acc: 69.655

Epoch 3: Validation loss decreased (0.575019 --> 0.564182).  Saving model ...
	 Train_Loss: 0.5855 Train_Acc: 68.711 Val_Loss: 0.5642  BEST VAL Loss: 0.5642  Val_Acc: 71.072

Epoch 4: Validation loss decreased (0.564182 --> 0.557307).  Saving model ...
	 Train_Loss: 0.5758 Train_Acc: 69.842 Val_Loss: 0.5573  BEST VAL Loss: 0.5573  Val_Acc: 71.703

Epoch 5: Validation loss decreased (0.557307 --> 0.550354).  Saving model ...
	 Train_Loss: 0.5675 Train_Acc: 70.744 Val_Loss: 0.5504  BEST VAL Loss: 0.5504  Val_Acc: 72.266

Epoch 6: Validation loss decreased (0.550354 --> 0.545193).  Saving model ...
	 Train_Loss: 0.5608 Train_Acc: 71.349 Val_Loss: 0.5452  BEST VAL Loss: 0.5452  Val_Acc: 72.917

Epoch 7: Validation loss decreased (0.545193 --> 0.540014).  Saving model ...
	 Train_Loss: 0.5547 Train_Acc: 71.940 Val_Loss: 0.5400  BEST VAL Loss: 0.5400  Val_Acc: 73.276

Epoch 8: Validation loss decreased (0.540014 --> 0.535712).  Saving model ...
	 Train_Loss: 0.5493 Train_Acc: 72.258 Val_Loss: 0.5357  BEST VAL Loss: 0.5357  Val_Acc: 73.567

Epoch 9: Validation loss decreased (0.535712 --> 0.532316).  Saving model ...
	 Train_Loss: 0.5446 Train_Acc: 72.319 Val_Loss: 0.5323  BEST VAL Loss: 0.5323  Val_Acc: 73.960

Epoch 10: Validation loss decreased (0.532316 --> 0.528264).  Saving model ...
	 Train_Loss: 0.5404 Train_Acc: 72.489 Val_Loss: 0.5283  BEST VAL Loss: 0.5283  Val_Acc: 74.387

Epoch 11: Validation loss decreased (0.528264 --> 0.524772).  Saving model ...
	 Train_Loss: 0.5366 Train_Acc: 72.935 Val_Loss: 0.5248  BEST VAL Loss: 0.5248  Val_Acc: 74.708

Epoch 12: Validation loss decreased (0.524772 --> 0.521846).  Saving model ...
	 Train_Loss: 0.5329 Train_Acc: 73.276 Val_Loss: 0.5218  BEST VAL Loss: 0.5218  Val_Acc: 75.120

Epoch 13: Validation loss decreased (0.521846 --> 0.519525).  Saving model ...
	 Train_Loss: 0.5296 Train_Acc: 73.276 Val_Loss: 0.5195  BEST VAL Loss: 0.5195  Val_Acc: 75.154

Epoch 14: Validation loss decreased (0.519525 --> 0.517049).  Saving model ...
	 Train_Loss: 0.5264 Train_Acc: 73.596 Val_Loss: 0.5170  BEST VAL Loss: 0.5170  Val_Acc: 75.605

Epoch 15: Validation loss decreased (0.517049 --> 0.514560).  Saving model ...
	 Train_Loss: 0.5235 Train_Acc: 73.666 Val_Loss: 0.5146  BEST VAL Loss: 0.5146  Val_Acc: 75.586

Epoch 16: Validation loss decreased (0.514560 --> 0.512577).  Saving model ...
	 Train_Loss: 0.5209 Train_Acc: 73.681 Val_Loss: 0.5126  BEST VAL Loss: 0.5126  Val_Acc: 75.411

Epoch 17: Validation loss decreased (0.512577 --> 0.510670).  Saving model ...
	 Train_Loss: 0.5184 Train_Acc: 73.870 Val_Loss: 0.5107  BEST VAL Loss: 0.5107  Val_Acc: 76.008

Epoch 18: Validation loss decreased (0.510670 --> 0.509107).  Saving model ...
	 Train_Loss: 0.5161 Train_Acc: 73.934 Val_Loss: 0.5091  BEST VAL Loss: 0.5091  Val_Acc: 75.649

Epoch 19: Validation loss decreased (0.509107 --> 0.507364).  Saving model ...
	 Train_Loss: 0.5139 Train_Acc: 74.011 Val_Loss: 0.5074  BEST VAL Loss: 0.5074  Val_Acc: 75.601

Epoch 20: Validation loss decreased (0.507364 --> 0.505699).  Saving model ...
	 Train_Loss: 0.5119 Train_Acc: 74.198 Val_Loss: 0.5057  BEST VAL Loss: 0.5057  Val_Acc: 75.664

Epoch 21: Validation loss decreased (0.505699 --> 0.503999).  Saving model ...
	 Train_Loss: 0.5100 Train_Acc: 74.130 Val_Loss: 0.5040  BEST VAL Loss: 0.5040  Val_Acc: 76.295

Epoch 22: Validation loss decreased (0.503999 --> 0.502293).  Saving model ...
	 Train_Loss: 0.5081 Train_Acc: 74.215 Val_Loss: 0.5023  BEST VAL Loss: 0.5023  Val_Acc: 76.280

Epoch 23: Validation loss decreased (0.502293 --> 0.500958).  Saving model ...
	 Train_Loss: 0.5063 Train_Acc: 74.389 Val_Loss: 0.5010  BEST VAL Loss: 0.5010  Val_Acc: 76.047

Epoch 24: Validation loss decreased (0.500958 --> 0.499502).  Saving model ...
	 Train_Loss: 0.5047 Train_Acc: 74.327 Val_Loss: 0.4995  BEST VAL Loss: 0.4995  Val_Acc: 76.542

Epoch 25: Validation loss decreased (0.499502 --> 0.498322).  Saving model ...
	 Train_Loss: 0.5032 Train_Acc: 74.357 Val_Loss: 0.4983  BEST VAL Loss: 0.4983  Val_Acc: 76.358

Epoch 26: Validation loss decreased (0.498322 --> 0.497084).  Saving model ...
	 Train_Loss: 0.5017 Train_Acc: 74.553 Val_Loss: 0.4971  BEST VAL Loss: 0.4971  Val_Acc: 76.562

Epoch 27: Validation loss decreased (0.497084 --> 0.495892).  Saving model ...
	 Train_Loss: 0.5002 Train_Acc: 74.462 Val_Loss: 0.4959  BEST VAL Loss: 0.4959  Val_Acc: 76.528

Epoch 28: Validation loss decreased (0.495892 --> 0.494770).  Saving model ...
	 Train_Loss: 0.4989 Train_Acc: 74.672 Val_Loss: 0.4948  BEST VAL Loss: 0.4948  Val_Acc: 76.615

Epoch 29: Validation loss decreased (0.494770 --> 0.493737).  Saving model ...
	 Train_Loss: 0.4975 Train_Acc: 74.849 Val_Loss: 0.4937  BEST VAL Loss: 0.4937  Val_Acc: 76.547

Epoch 30: Validation loss decreased (0.493737 --> 0.492747).  Saving model ...
	 Train_Loss: 0.4962 Train_Acc: 74.786 Val_Loss: 0.4927  BEST VAL Loss: 0.4927  Val_Acc: 76.426

Epoch 31: Validation loss decreased (0.492747 --> 0.491689).  Saving model ...
	 Train_Loss: 0.4949 Train_Acc: 74.814 Val_Loss: 0.4917  BEST VAL Loss: 0.4917  Val_Acc: 76.372

Epoch 32: Validation loss decreased (0.491689 --> 0.490862).  Saving model ...
	 Train_Loss: 0.4937 Train_Acc: 74.818 Val_Loss: 0.4909  BEST VAL Loss: 0.4909  Val_Acc: 76.435

Epoch 33: Validation loss decreased (0.490862 --> 0.490291).  Saving model ...
	 Train_Loss: 0.4926 Train_Acc: 74.928 Val_Loss: 0.4903  BEST VAL Loss: 0.4903  Val_Acc: 76.785

Epoch 34: Validation loss decreased (0.490291 --> 0.489703).  Saving model ...
	 Train_Loss: 0.4915 Train_Acc: 74.821 Val_Loss: 0.4897  BEST VAL Loss: 0.4897  Val_Acc: 76.644

Epoch 35: Validation loss decreased (0.489703 --> 0.488884).  Saving model ...
	 Train_Loss: 0.4904 Train_Acc: 74.909 Val_Loss: 0.4889  BEST VAL Loss: 0.4889  Val_Acc: 76.853

Epoch 36: Validation loss decreased (0.488884 --> 0.488094).  Saving model ...
	 Train_Loss: 0.4893 Train_Acc: 75.059 Val_Loss: 0.4881  BEST VAL Loss: 0.4881  Val_Acc: 76.790

Epoch 37: Validation loss decreased (0.488094 --> 0.487523).  Saving model ...
	 Train_Loss: 0.4883 Train_Acc: 75.107 Val_Loss: 0.4875  BEST VAL Loss: 0.4875  Val_Acc: 76.814

Epoch 38: Validation loss decreased (0.487523 --> 0.486934).  Saving model ...
	 Train_Loss: 0.4874 Train_Acc: 74.917 Val_Loss: 0.4869  BEST VAL Loss: 0.4869  Val_Acc: 76.906

Epoch 39: Validation loss decreased (0.486934 --> 0.486439).  Saving model ...
	 Train_Loss: 0.4864 Train_Acc: 75.124 Val_Loss: 0.4864  BEST VAL Loss: 0.4864  Val_Acc: 76.804

Epoch 40: Validation loss decreased (0.486439 --> 0.485803).  Saving model ...
	 Train_Loss: 0.4855 Train_Acc: 75.343 Val_Loss: 0.4858  BEST VAL Loss: 0.4858  Val_Acc: 77.032

Epoch 41: Validation loss decreased (0.485803 --> 0.485244).  Saving model ...
	 Train_Loss: 0.4846 Train_Acc: 75.207 Val_Loss: 0.4852  BEST VAL Loss: 0.4852  Val_Acc: 77.047

Epoch 42: Validation loss decreased (0.485244 --> 0.484637).  Saving model ...
	 Train_Loss: 0.4837 Train_Acc: 75.214 Val_Loss: 0.4846  BEST VAL Loss: 0.4846  Val_Acc: 76.790

Epoch 43: Validation loss decreased (0.484637 --> 0.484096).  Saving model ...
	 Train_Loss: 0.4828 Train_Acc: 75.304 Val_Loss: 0.4841  BEST VAL Loss: 0.4841  Val_Acc: 77.115

Epoch 44: Validation loss decreased (0.484096 --> 0.483578).  Saving model ...
	 Train_Loss: 0.4820 Train_Acc: 75.313 Val_Loss: 0.4836  BEST VAL Loss: 0.4836  Val_Acc: 77.120

Epoch 45: Validation loss decreased (0.483578 --> 0.483140).  Saving model ...
	 Train_Loss: 0.4812 Train_Acc: 75.212 Val_Loss: 0.4831  BEST VAL Loss: 0.4831  Val_Acc: 76.974

Epoch 46: Validation loss decreased (0.483140 --> 0.482705).  Saving model ...
	 Train_Loss: 0.4805 Train_Acc: 75.028 Val_Loss: 0.4827  BEST VAL Loss: 0.4827  Val_Acc: 77.091

Epoch 47: Validation loss decreased (0.482705 --> 0.482255).  Saving model ...
	 Train_Loss: 0.4798 Train_Acc: 75.190 Val_Loss: 0.4823  BEST VAL Loss: 0.4823  Val_Acc: 76.940

Epoch 48: Validation loss decreased (0.482255 --> 0.481812).  Saving model ...
	 Train_Loss: 0.4791 Train_Acc: 75.228 Val_Loss: 0.4818  BEST VAL Loss: 0.4818  Val_Acc: 77.100

Epoch 49: Validation loss decreased (0.481812 --> 0.481516).  Saving model ...
	 Train_Loss: 0.4784 Train_Acc: 75.213 Val_Loss: 0.4815  BEST VAL Loss: 0.4815  Val_Acc: 76.455

Epoch 50: Validation loss decreased (0.481516 --> 0.481254).  Saving model ...
	 Train_Loss: 0.4777 Train_Acc: 75.441 Val_Loss: 0.4813  BEST VAL Loss: 0.4813  Val_Acc: 77.047

Epoch 51: Validation loss decreased (0.481254 --> 0.480922).  Saving model ...
	 Train_Loss: 0.4771 Train_Acc: 75.273 Val_Loss: 0.4809  BEST VAL Loss: 0.4809  Val_Acc: 76.887

Epoch 52: Validation loss decreased (0.480922 --> 0.480736).  Saving model ...
	 Train_Loss: 0.4764 Train_Acc: 75.489 Val_Loss: 0.4807  BEST VAL Loss: 0.4807  Val_Acc: 77.285

Epoch 53: Validation loss decreased (0.480736 --> 0.480609).  Saving model ...
	 Train_Loss: 0.4757 Train_Acc: 75.495 Val_Loss: 0.4806  BEST VAL Loss: 0.4806  Val_Acc: 76.950

Epoch 54: Validation loss decreased (0.480609 --> 0.480197).  Saving model ...
	 Train_Loss: 0.4751 Train_Acc: 75.331 Val_Loss: 0.4802  BEST VAL Loss: 0.4802  Val_Acc: 77.013

Epoch 55: Validation loss decreased (0.480197 --> 0.479841).  Saving model ...
	 Train_Loss: 0.4745 Train_Acc: 75.446 Val_Loss: 0.4798  BEST VAL Loss: 0.4798  Val_Acc: 76.780

Epoch 56: Validation loss decreased (0.479841 --> 0.479514).  Saving model ...
	 Train_Loss: 0.4739 Train_Acc: 75.561 Val_Loss: 0.4795  BEST VAL Loss: 0.4795  Val_Acc: 76.979

Epoch 57: Validation loss decreased (0.479514 --> 0.479258).  Saving model ...
	 Train_Loss: 0.4732 Train_Acc: 75.558 Val_Loss: 0.4793  BEST VAL Loss: 0.4793  Val_Acc: 76.785

Epoch 58: Validation loss decreased (0.479258 --> 0.479243).  Saving model ...
	 Train_Loss: 0.4726 Train_Acc: 75.613 Val_Loss: 0.4792  BEST VAL Loss: 0.4792  Val_Acc: 76.921

Epoch 59: Validation loss decreased (0.479243 --> 0.479154).  Saving model ...
	 Train_Loss: 0.4721 Train_Acc: 75.584 Val_Loss: 0.4792  BEST VAL Loss: 0.4792  Val_Acc: 76.858

Epoch 60: Validation loss decreased (0.479154 --> 0.478884).  Saving model ...
	 Train_Loss: 0.4715 Train_Acc: 75.596 Val_Loss: 0.4789  BEST VAL Loss: 0.4789  Val_Acc: 77.028

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.4709 Train_Acc: 75.508 Val_Loss: 0.4789  BEST VAL Loss: 0.4789  Val_Acc: 76.882

Epoch 62: Validation loss decreased (0.478884 --> 0.478741).  Saving model ...
	 Train_Loss: 0.4704 Train_Acc: 75.571 Val_Loss: 0.4787  BEST VAL Loss: 0.4787  Val_Acc: 76.984

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.4698 Train_Acc: 75.707 Val_Loss: 0.4788  BEST VAL Loss: 0.4787  Val_Acc: 77.013

Epoch 64: Validation loss decreased (0.478741 --> 0.478735).  Saving model ...
	 Train_Loss: 0.4693 Train_Acc: 75.845 Val_Loss: 0.4787  BEST VAL Loss: 0.4787  Val_Acc: 77.256

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.4688 Train_Acc: 75.510 Val_Loss: 0.4789  BEST VAL Loss: 0.4787  Val_Acc: 76.833

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.4682 Train_Acc: 75.647 Val_Loss: 0.4790  BEST VAL Loss: 0.4787  Val_Acc: 77.066

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.4678 Train_Acc: 75.429 Val_Loss: 0.4793  BEST VAL Loss: 0.4787  Val_Acc: 77.236

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.4673 Train_Acc: 75.711 Val_Loss: 0.4795  BEST VAL Loss: 0.4787  Val_Acc: 76.877

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.4668 Train_Acc: 75.801 Val_Loss: 0.4794  BEST VAL Loss: 0.4787  Val_Acc: 77.120

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.4663 Train_Acc: 75.720 Val_Loss: 0.4792  BEST VAL Loss: 0.4787  Val_Acc: 77.261

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.4659 Train_Acc: 75.745 Val_Loss: 0.4791  BEST VAL Loss: 0.4787  Val_Acc: 77.125

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.4654 Train_Acc: 75.591 Val_Loss: 0.4790  BEST VAL Loss: 0.4787  Val_Acc: 77.202

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.4650 Train_Acc: 75.724 Val_Loss: 0.4788  BEST VAL Loss: 0.4787  Val_Acc: 76.911

Epoch 74: Validation loss decreased (0.478735 --> 0.478713).  Saving model ...
	 Train_Loss: 0.4645 Train_Acc: 75.808 Val_Loss: 0.4787  BEST VAL Loss: 0.4787  Val_Acc: 77.246

Epoch 75: Validation loss decreased (0.478713 --> 0.478505).  Saving model ...
	 Train_Loss: 0.4641 Train_Acc: 75.732 Val_Loss: 0.4785  BEST VAL Loss: 0.4785  Val_Acc: 77.202

Epoch 76: Validation loss decreased (0.478505 --> 0.478371).  Saving model ...
	 Train_Loss: 0.4637 Train_Acc: 75.860 Val_Loss: 0.4784  BEST VAL Loss: 0.4784  Val_Acc: 77.392

Epoch 77: Validation loss decreased (0.478371 --> 0.478305).  Saving model ...
	 Train_Loss: 0.4633 Train_Acc: 75.840 Val_Loss: 0.4783  BEST VAL Loss: 0.4783  Val_Acc: 77.023

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.4629 Train_Acc: 75.807 Val_Loss: 0.4783  BEST VAL Loss: 0.4783  Val_Acc: 76.955

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.4625 Train_Acc: 75.842 Val_Loss: 0.4785  BEST VAL Loss: 0.4783  Val_Acc: 77.081

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.4621 Train_Acc: 75.946 Val_Loss: 0.4785  BEST VAL Loss: 0.4783  Val_Acc: 77.066

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.4617 Train_Acc: 75.874 Val_Loss: 0.4784  BEST VAL Loss: 0.4783  Val_Acc: 77.139

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.4612 Train_Acc: 75.944 Val_Loss: 0.4785  BEST VAL Loss: 0.4783  Val_Acc: 77.120

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.4608 Train_Acc: 75.943 Val_Loss: 0.4783  BEST VAL Loss: 0.4783  Val_Acc: 77.202

Epoch 84: Validation loss decreased (0.478305 --> 0.478234).  Saving model ...
	 Train_Loss: 0.4605 Train_Acc: 75.861 Val_Loss: 0.4782  BEST VAL Loss: 0.4782  Val_Acc: 77.261

Epoch 85: Validation loss decreased (0.478234 --> 0.478086).  Saving model ...
	 Train_Loss: 0.4601 Train_Acc: 75.978 Val_Loss: 0.4781  BEST VAL Loss: 0.4781  Val_Acc: 77.382

Epoch 86: Validation loss decreased (0.478086 --> 0.477954).  Saving model ...
	 Train_Loss: 0.4597 Train_Acc: 75.961 Val_Loss: 0.4780  BEST VAL Loss: 0.4780  Val_Acc: 77.028

Epoch 87: Validation loss decreased (0.477954 --> 0.477748).  Saving model ...
	 Train_Loss: 0.4593 Train_Acc: 75.907 Val_Loss: 0.4777  BEST VAL Loss: 0.4777  Val_Acc: 76.921

Epoch 88: Validation loss decreased (0.477748 --> 0.477643).  Saving model ...
	 Train_Loss: 0.4590 Train_Acc: 75.974 Val_Loss: 0.4776  BEST VAL Loss: 0.4776  Val_Acc: 76.921

Epoch 89: Validation loss decreased (0.477643 --> 0.477506).  Saving model ...
	 Train_Loss: 0.4586 Train_Acc: 76.009 Val_Loss: 0.4775  BEST VAL Loss: 0.4775  Val_Acc: 77.299

Epoch 90: Validation loss decreased (0.477506 --> 0.477390).  Saving model ...
	 Train_Loss: 0.4583 Train_Acc: 75.820 Val_Loss: 0.4774  BEST VAL Loss: 0.4774  Val_Acc: 77.401

Epoch 91: Validation loss decreased (0.477390 --> 0.477275).  Saving model ...
	 Train_Loss: 0.4579 Train_Acc: 75.928 Val_Loss: 0.4773  BEST VAL Loss: 0.4773  Val_Acc: 77.270

Epoch 92: Validation loss decreased (0.477275 --> 0.477202).  Saving model ...
	 Train_Loss: 0.4576 Train_Acc: 75.976 Val_Loss: 0.4772  BEST VAL Loss: 0.4772  Val_Acc: 77.353

Epoch 93: Validation loss decreased (0.477202 --> 0.477128).  Saving model ...
	 Train_Loss: 0.4572 Train_Acc: 76.070 Val_Loss: 0.4771  BEST VAL Loss: 0.4771  Val_Acc: 77.265

Epoch 94: Validation loss decreased (0.477128 --> 0.477072).  Saving model ...
	 Train_Loss: 0.4569 Train_Acc: 75.941 Val_Loss: 0.4771  BEST VAL Loss: 0.4771  Val_Acc: 76.998

Epoch 95: Validation loss decreased (0.477072 --> 0.476940).  Saving model ...
	 Train_Loss: 0.4566 Train_Acc: 75.937 Val_Loss: 0.4769  BEST VAL Loss: 0.4769  Val_Acc: 77.110

Epoch 96: Validation loss decreased (0.476940 --> 0.476746).  Saving model ...
	 Train_Loss: 0.4563 Train_Acc: 75.923 Val_Loss: 0.4767  BEST VAL Loss: 0.4767  Val_Acc: 77.023

Epoch 97: Validation loss decreased (0.476746 --> 0.476595).  Saving model ...
	 Train_Loss: 0.4559 Train_Acc: 76.128 Val_Loss: 0.4766  BEST VAL Loss: 0.4766  Val_Acc: 77.202

Epoch 98: Validation loss decreased (0.476595 --> 0.476497).  Saving model ...
	 Train_Loss: 0.4556 Train_Acc: 76.035 Val_Loss: 0.4765  BEST VAL Loss: 0.4765  Val_Acc: 77.333

Epoch 99: Validation loss decreased (0.476497 --> 0.476393).  Saving model ...
	 Train_Loss: 0.4553 Train_Acc: 75.937 Val_Loss: 0.4764  BEST VAL Loss: 0.4764  Val_Acc: 77.290

LPS_0.010_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.76      0.91      0.83     85027
           1       0.88      0.69      0.77     79796

    accuracy                           0.80    164823
   macro avg       0.82      0.80      0.80    164823
weighted avg       0.82      0.80      0.80    164823

LPS_0.010_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.73      0.88      0.80     10628
           1       0.84      0.66      0.74      9975

    accuracy                           0.77     20603
   macro avg       0.78      0.77      0.77     20603
weighted avg       0.78      0.77      0.77     20603

LPS_0.010_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.74      0.88      0.80     10628
           1       0.84      0.66      0.74      9975

    accuracy                           0.78     20603
   macro avg       0.79      0.77      0.77     20603
weighted avg       0.79      0.78      0.77     20603

              precision    recall  f1-score   support

           0       0.74      0.88      0.80     10628
           1       0.84      0.66      0.74      9975

    accuracy                           0.78     20603
   macro avg       0.79      0.77      0.77     20603
weighted avg       0.79      0.78      0.77     20603

LPS_0.010_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.43      0.68      0.52     36797
           1       0.35      0.16      0.22     39687

    accuracy                           0.41     76484
   macro avg       0.39      0.42      0.37     76484
weighted avg       0.39      0.41      0.37     76484

              precision    recall  f1-score   support

           0       0.43      0.68      0.52     36797
           1       0.35      0.16      0.22     39687

    accuracy                           0.41     76484
   macro avg       0.39      0.42      0.37     76484
weighted avg       0.39      0.41      0.37     76484

completed
