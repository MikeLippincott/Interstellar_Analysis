[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '3a584e87'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e8ff863f'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '0d161bd0'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '883b9c79'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 treatment_name: LPS_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
TREATMENT_NAME: LPS_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (32676, 1276)
Number of total missing values across all columns: 32916
Data Subset Is Off
Wells held out for testing: ['D20' 'K16']
Wells to use for training, validation, and testing ['D16' 'D17' 'D21' 'K17' 'K20' 'K21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.504554).  Saving model ...
	 Train_Loss: 0.6078 Train_Acc: 58.700 Val_Loss: 0.5046  BEST VAL Loss: 0.5046  Val_Acc: 81.152

Epoch 1: Validation loss decreased (0.504554 --> 0.473581).  Saving model ...
	 Train_Loss: 0.5562 Train_Acc: 78.576 Val_Loss: 0.4736  BEST VAL Loss: 0.4736  Val_Acc: 83.621

Epoch 2: Validation loss decreased (0.473581 --> 0.450052).  Saving model ...
	 Train_Loss: 0.5204 Train_Acc: 81.370 Val_Loss: 0.4501  BEST VAL Loss: 0.4501  Val_Acc: 86.132

Epoch 3: Validation loss decreased (0.450052 --> 0.432150).  Saving model ...
	 Train_Loss: 0.4944 Train_Acc: 83.381 Val_Loss: 0.4322  BEST VAL Loss: 0.4322  Val_Acc: 86.955

Epoch 4: Validation loss decreased (0.432150 --> 0.418594).  Saving model ...
	 Train_Loss: 0.4754 Train_Acc: 83.767 Val_Loss: 0.4186  BEST VAL Loss: 0.4186  Val_Acc: 87.243

Epoch 5: Validation loss decreased (0.418594 --> 0.402741).  Saving model ...
	 Train_Loss: 0.4578 Train_Acc: 85.378 Val_Loss: 0.4027  BEST VAL Loss: 0.4027  Val_Acc: 88.807

Epoch 6: Validation loss decreased (0.402741 --> 0.391326).  Saving model ...
	 Train_Loss: 0.4446 Train_Acc: 85.517 Val_Loss: 0.3913  BEST VAL Loss: 0.3913  Val_Acc: 88.848

Epoch 7: Validation loss decreased (0.391326 --> 0.380985).  Saving model ...
	 Train_Loss: 0.4322 Train_Acc: 86.350 Val_Loss: 0.3810  BEST VAL Loss: 0.3810  Val_Acc: 89.342

Epoch 8: Validation loss decreased (0.380985 --> 0.372259).  Saving model ...
	 Train_Loss: 0.4215 Train_Acc: 86.726 Val_Loss: 0.3723  BEST VAL Loss: 0.3723  Val_Acc: 89.177

Epoch 9: Validation loss decreased (0.372259 --> 0.365499).  Saving model ...
	 Train_Loss: 0.4122 Train_Acc: 87.225 Val_Loss: 0.3655  BEST VAL Loss: 0.3655  Val_Acc: 89.959

Epoch 10: Validation loss decreased (0.365499 --> 0.360746).  Saving model ...
	 Train_Loss: 0.4042 Train_Acc: 87.441 Val_Loss: 0.3607  BEST VAL Loss: 0.3607  Val_Acc: 88.930

Epoch 11: Validation loss decreased (0.360746 --> 0.353539).  Saving model ...
	 Train_Loss: 0.3968 Train_Acc: 88.110 Val_Loss: 0.3535  BEST VAL Loss: 0.3535  Val_Acc: 91.029

Epoch 12: Validation loss decreased (0.353539 --> 0.349398).  Saving model ...
	 Train_Loss: 0.3903 Train_Acc: 88.207 Val_Loss: 0.3494  BEST VAL Loss: 0.3494  Val_Acc: 89.547

Epoch 13: Validation loss decreased (0.349398 --> 0.344246).  Saving model ...
	 Train_Loss: 0.3842 Train_Acc: 88.403 Val_Loss: 0.3442  BEST VAL Loss: 0.3442  Val_Acc: 90.412

Epoch 14: Validation loss decreased (0.344246 --> 0.340004).  Saving model ...
	 Train_Loss: 0.3784 Train_Acc: 89.005 Val_Loss: 0.3400  BEST VAL Loss: 0.3400  Val_Acc: 90.165

Epoch 15: Validation loss decreased (0.340004 --> 0.335955).  Saving model ...
	 Train_Loss: 0.3731 Train_Acc: 88.928 Val_Loss: 0.3360  BEST VAL Loss: 0.3360  Val_Acc: 91.358

Epoch 16: Validation loss decreased (0.335955 --> 0.331682).  Saving model ...
	 Train_Loss: 0.3689 Train_Acc: 88.629 Val_Loss: 0.3317  BEST VAL Loss: 0.3317  Val_Acc: 91.111

Epoch 17: Validation loss decreased (0.331682 --> 0.328177).  Saving model ...
	 Train_Loss: 0.3646 Train_Acc: 89.103 Val_Loss: 0.3282  BEST VAL Loss: 0.3282  Val_Acc: 91.070

Epoch 18: Validation loss decreased (0.328177 --> 0.324387).  Saving model ...
	 Train_Loss: 0.3602 Train_Acc: 89.694 Val_Loss: 0.3244  BEST VAL Loss: 0.3244  Val_Acc: 91.564

Epoch 19: Validation loss decreased (0.324387 --> 0.321693).  Saving model ...
	 Train_Loss: 0.3562 Train_Acc: 89.689 Val_Loss: 0.3217  BEST VAL Loss: 0.3217  Val_Acc: 91.317

Epoch 20: Validation loss decreased (0.321693 --> 0.320231).  Saving model ...
	 Train_Loss: 0.3527 Train_Acc: 89.715 Val_Loss: 0.3202  BEST VAL Loss: 0.3202  Val_Acc: 90.412

Epoch 21: Validation loss decreased (0.320231 --> 0.317467).  Saving model ...
	 Train_Loss: 0.3495 Train_Acc: 89.566 Val_Loss: 0.3175  BEST VAL Loss: 0.3175  Val_Acc: 92.058

Epoch 22: Validation loss decreased (0.317467 --> 0.314225).  Saving model ...
	 Train_Loss: 0.3462 Train_Acc: 90.008 Val_Loss: 0.3142  BEST VAL Loss: 0.3142  Val_Acc: 92.428

Epoch 23: Validation loss decreased (0.314225 --> 0.311142).  Saving model ...
	 Train_Loss: 0.3429 Train_Acc: 90.507 Val_Loss: 0.3111  BEST VAL Loss: 0.3111  Val_Acc: 92.016

Epoch 24: Validation loss decreased (0.311142 --> 0.308874).  Saving model ...
	 Train_Loss: 0.3401 Train_Acc: 90.137 Val_Loss: 0.3089  BEST VAL Loss: 0.3089  Val_Acc: 92.469

Epoch 25: Validation loss decreased (0.308874 --> 0.308294).  Saving model ...
	 Train_Loss: 0.3374 Train_Acc: 90.312 Val_Loss: 0.3083  BEST VAL Loss: 0.3083  Val_Acc: 90.782

Epoch 26: Validation loss decreased (0.308294 --> 0.305696).  Saving model ...
	 Train_Loss: 0.3348 Train_Acc: 90.240 Val_Loss: 0.3057  BEST VAL Loss: 0.3057  Val_Acc: 93.045

Epoch 27: Validation loss decreased (0.305696 --> 0.304316).  Saving model ...
	 Train_Loss: 0.3321 Train_Acc: 90.574 Val_Loss: 0.3043  BEST VAL Loss: 0.3043  Val_Acc: 91.235

Epoch 28: Validation loss decreased (0.304316 --> 0.302019).  Saving model ...
	 Train_Loss: 0.3298 Train_Acc: 90.554 Val_Loss: 0.3020  BEST VAL Loss: 0.3020  Val_Acc: 92.016

Epoch 29: Validation loss decreased (0.302019 --> 0.299732).  Saving model ...
	 Train_Loss: 0.3276 Train_Acc: 90.466 Val_Loss: 0.2997  BEST VAL Loss: 0.2997  Val_Acc: 93.128

Epoch 30: Validation loss decreased (0.299732 --> 0.299265).  Saving model ...
	 Train_Loss: 0.3255 Train_Acc: 90.765 Val_Loss: 0.2993  BEST VAL Loss: 0.2993  Val_Acc: 92.181

Epoch 31: Validation loss decreased (0.299265 --> 0.298119).  Saving model ...
	 Train_Loss: 0.3237 Train_Acc: 90.497 Val_Loss: 0.2981  BEST VAL Loss: 0.2981  Val_Acc: 91.070

Epoch 32: Validation loss decreased (0.298119 --> 0.296073).  Saving model ...
	 Train_Loss: 0.3217 Train_Acc: 90.780 Val_Loss: 0.2961  BEST VAL Loss: 0.2961  Val_Acc: 92.963

Epoch 33: Validation loss decreased (0.296073 --> 0.294378).  Saving model ...
	 Train_Loss: 0.3197 Train_Acc: 90.929 Val_Loss: 0.2944  BEST VAL Loss: 0.2944  Val_Acc: 93.045

Epoch 34: Validation loss decreased (0.294378 --> 0.293151).  Saving model ...
	 Train_Loss: 0.3179 Train_Acc: 91.042 Val_Loss: 0.2932  BEST VAL Loss: 0.2932  Val_Acc: 92.675

Epoch 35: Validation loss decreased (0.293151 --> 0.290991).  Saving model ...
	 Train_Loss: 0.3159 Train_Acc: 91.140 Val_Loss: 0.2910  BEST VAL Loss: 0.2910  Val_Acc: 93.292

Epoch 36: Validation loss decreased (0.290991 --> 0.290196).  Saving model ...
	 Train_Loss: 0.3142 Train_Acc: 91.099 Val_Loss: 0.2902  BEST VAL Loss: 0.2902  Val_Acc: 92.016

Epoch 37: Validation loss decreased (0.290196 --> 0.288631).  Saving model ...
	 Train_Loss: 0.3128 Train_Acc: 90.878 Val_Loss: 0.2886  BEST VAL Loss: 0.2886  Val_Acc: 93.333

Epoch 38: Validation loss decreased (0.288631 --> 0.287398).  Saving model ...
	 Train_Loss: 0.3112 Train_Acc: 91.341 Val_Loss: 0.2874  BEST VAL Loss: 0.2874  Val_Acc: 93.128

Epoch 39: Validation loss decreased (0.287398 --> 0.286141).  Saving model ...
	 Train_Loss: 0.3095 Train_Acc: 91.428 Val_Loss: 0.2861  BEST VAL Loss: 0.2861  Val_Acc: 93.498

Epoch 40: Validation loss decreased (0.286141 --> 0.285386).  Saving model ...
	 Train_Loss: 0.3081 Train_Acc: 91.078 Val_Loss: 0.2854  BEST VAL Loss: 0.2854  Val_Acc: 92.922

Epoch 41: Validation loss decreased (0.285386 --> 0.283743).  Saving model ...
	 Train_Loss: 0.3066 Train_Acc: 91.305 Val_Loss: 0.2837  BEST VAL Loss: 0.2837  Val_Acc: 93.333

Epoch 42: Validation loss decreased (0.283743 --> 0.282997).  Saving model ...
	 Train_Loss: 0.3051 Train_Acc: 91.722 Val_Loss: 0.2830  BEST VAL Loss: 0.2830  Val_Acc: 93.539

Epoch 43: Validation loss decreased (0.282997 --> 0.282058).  Saving model ...
	 Train_Loss: 0.3037 Train_Acc: 91.536 Val_Loss: 0.2821  BEST VAL Loss: 0.2821  Val_Acc: 93.169

Epoch 44: Validation loss decreased (0.282058 --> 0.280563).  Saving model ...
	 Train_Loss: 0.3023 Train_Acc: 91.588 Val_Loss: 0.2806  BEST VAL Loss: 0.2806  Val_Acc: 93.374

Epoch 45: Validation loss decreased (0.280563 --> 0.280101).  Saving model ...
	 Train_Loss: 0.3011 Train_Acc: 91.485 Val_Loss: 0.2801  BEST VAL Loss: 0.2801  Val_Acc: 93.580

Epoch 46: Validation loss decreased (0.280101 --> 0.278817).  Saving model ...
	 Train_Loss: 0.3000 Train_Acc: 91.289 Val_Loss: 0.2788  BEST VAL Loss: 0.2788  Val_Acc: 93.539

Epoch 47: Validation loss decreased (0.278817 --> 0.277908).  Saving model ...
	 Train_Loss: 0.2986 Train_Acc: 91.932 Val_Loss: 0.2779  BEST VAL Loss: 0.2779  Val_Acc: 93.374

Epoch 48: Validation loss decreased (0.277908 --> 0.276891).  Saving model ...
	 Train_Loss: 0.2974 Train_Acc: 91.634 Val_Loss: 0.2769  BEST VAL Loss: 0.2769  Val_Acc: 93.704

Epoch 49: Validation loss decreased (0.276891 --> 0.275642).  Saving model ...
	 Train_Loss: 0.2963 Train_Acc: 91.593 Val_Loss: 0.2756  BEST VAL Loss: 0.2756  Val_Acc: 94.074

Epoch 50: Validation loss decreased (0.275642 --> 0.274481).  Saving model ...
	 Train_Loss: 0.2953 Train_Acc: 91.454 Val_Loss: 0.2745  BEST VAL Loss: 0.2745  Val_Acc: 94.115

Epoch 51: Validation loss decreased (0.274481 --> 0.273209).  Saving model ...
	 Train_Loss: 0.2943 Train_Acc: 91.804 Val_Loss: 0.2732  BEST VAL Loss: 0.2732  Val_Acc: 93.909

Epoch 52: Validation loss decreased (0.273209 --> 0.272056).  Saving model ...
	 Train_Loss: 0.2931 Train_Acc: 91.999 Val_Loss: 0.2721  BEST VAL Loss: 0.2721  Val_Acc: 94.403

Epoch 53: Validation loss decreased (0.272056 --> 0.271330).  Saving model ...
	 Train_Loss: 0.2920 Train_Acc: 91.886 Val_Loss: 0.2713  BEST VAL Loss: 0.2713  Val_Acc: 93.704

Epoch 54: Validation loss decreased (0.271330 --> 0.270317).  Saving model ...
	 Train_Loss: 0.2910 Train_Acc: 91.999 Val_Loss: 0.2703  BEST VAL Loss: 0.2703  Val_Acc: 93.745

Epoch 55: Validation loss decreased (0.270317 --> 0.270163).  Saving model ...
	 Train_Loss: 0.2901 Train_Acc: 91.644 Val_Loss: 0.2702  BEST VAL Loss: 0.2702  Val_Acc: 92.634

Epoch 56: Validation loss decreased (0.270163 --> 0.269363).  Saving model ...
	 Train_Loss: 0.2892 Train_Acc: 91.830 Val_Loss: 0.2694  BEST VAL Loss: 0.2694  Val_Acc: 93.292

Epoch 57: Validation loss decreased (0.269363 --> 0.268554).  Saving model ...
	 Train_Loss: 0.2883 Train_Acc: 92.005 Val_Loss: 0.2686  BEST VAL Loss: 0.2686  Val_Acc: 93.868

Epoch 58: Validation loss decreased (0.268554 --> 0.268325).  Saving model ...
	 Train_Loss: 0.2874 Train_Acc: 91.871 Val_Loss: 0.2683  BEST VAL Loss: 0.2683  Val_Acc: 93.045

Epoch 59: Validation loss decreased (0.268325 --> 0.267275).  Saving model ...
	 Train_Loss: 0.2866 Train_Acc: 91.686 Val_Loss: 0.2673  BEST VAL Loss: 0.2673  Val_Acc: 94.280

Epoch 60: Validation loss decreased (0.267275 --> 0.266656).  Saving model ...
	 Train_Loss: 0.2857 Train_Acc: 92.241 Val_Loss: 0.2667  BEST VAL Loss: 0.2667  Val_Acc: 94.115

Epoch 61: Validation loss decreased (0.266656 --> 0.266147).  Saving model ...
	 Train_Loss: 0.2848 Train_Acc: 92.143 Val_Loss: 0.2661  BEST VAL Loss: 0.2661  Val_Acc: 93.786

Epoch 62: Validation loss decreased (0.266147 --> 0.265596).  Saving model ...
	 Train_Loss: 0.2839 Train_Acc: 92.061 Val_Loss: 0.2656  BEST VAL Loss: 0.2656  Val_Acc: 93.909

Epoch 63: Validation loss decreased (0.265596 --> 0.264854).  Saving model ...
	 Train_Loss: 0.2830 Train_Acc: 92.241 Val_Loss: 0.2649  BEST VAL Loss: 0.2649  Val_Acc: 93.951

Epoch 64: Validation loss decreased (0.264854 --> 0.264847).  Saving model ...
	 Train_Loss: 0.2823 Train_Acc: 92.149 Val_Loss: 0.2648  BEST VAL Loss: 0.2648  Val_Acc: 92.798

Epoch 65: Validation loss decreased (0.264847 --> 0.264162).  Saving model ...
	 Train_Loss: 0.2815 Train_Acc: 91.994 Val_Loss: 0.2642  BEST VAL Loss: 0.2642  Val_Acc: 93.580

Epoch 66: Validation loss decreased (0.264162 --> 0.263677).  Saving model ...
	 Train_Loss: 0.2807 Train_Acc: 92.354 Val_Loss: 0.2637  BEST VAL Loss: 0.2637  Val_Acc: 93.539

Epoch 67: Validation loss decreased (0.263677 --> 0.263086).  Saving model ...
	 Train_Loss: 0.2799 Train_Acc: 92.334 Val_Loss: 0.2631  BEST VAL Loss: 0.2631  Val_Acc: 93.704

Epoch 68: Validation loss decreased (0.263086 --> 0.262262).  Saving model ...
	 Train_Loss: 0.2791 Train_Acc: 92.349 Val_Loss: 0.2623  BEST VAL Loss: 0.2623  Val_Acc: 94.650

Epoch 69: Validation loss decreased (0.262262 --> 0.261736).  Saving model ...
	 Train_Loss: 0.2785 Train_Acc: 92.123 Val_Loss: 0.2617  BEST VAL Loss: 0.2617  Val_Acc: 93.909

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.2777 Train_Acc: 92.231 Val_Loss: 0.2618  BEST VAL Loss: 0.2617  Val_Acc: 92.593

Epoch 71: Validation loss decreased (0.261736 --> 0.260988).  Saving model ...
	 Train_Loss: 0.2771 Train_Acc: 91.938 Val_Loss: 0.2610  BEST VAL Loss: 0.2610  Val_Acc: 94.650

Epoch 72: Validation loss decreased (0.260988 --> 0.260351).  Saving model ...
	 Train_Loss: 0.2763 Train_Acc: 92.715 Val_Loss: 0.2604  BEST VAL Loss: 0.2604  Val_Acc: 94.115

Epoch 73: Validation loss decreased (0.260351 --> 0.259901).  Saving model ...
	 Train_Loss: 0.2756 Train_Acc: 92.349 Val_Loss: 0.2599  BEST VAL Loss: 0.2599  Val_Acc: 93.704

Epoch 74: Validation loss decreased (0.259901 --> 0.259558).  Saving model ...
	 Train_Loss: 0.2749 Train_Acc: 92.262 Val_Loss: 0.2596  BEST VAL Loss: 0.2596  Val_Acc: 93.539

Epoch 75: Validation loss decreased (0.259558 --> 0.259152).  Saving model ...
	 Train_Loss: 0.2743 Train_Acc: 92.282 Val_Loss: 0.2592  BEST VAL Loss: 0.2592  Val_Acc: 93.663

Epoch 76: Validation loss decreased (0.259152 --> 0.259104).  Saving model ...
	 Train_Loss: 0.2738 Train_Acc: 92.149 Val_Loss: 0.2591  BEST VAL Loss: 0.2591  Val_Acc: 93.498

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.2732 Train_Acc: 92.318 Val_Loss: 0.2592  BEST VAL Loss: 0.2591  Val_Acc: 93.416

Epoch 78: Validation loss decreased (0.259104 --> 0.258460).  Saving model ...
	 Train_Loss: 0.2726 Train_Acc: 92.324 Val_Loss: 0.2585  BEST VAL Loss: 0.2585  Val_Acc: 94.856

Epoch 79: Validation loss decreased (0.258460 --> 0.258138).  Saving model ...
	 Train_Loss: 0.2719 Train_Acc: 92.570 Val_Loss: 0.2581  BEST VAL Loss: 0.2581  Val_Acc: 94.074

Epoch 80: Validation loss decreased (0.258138 --> 0.257652).  Saving model ...
	 Train_Loss: 0.2713 Train_Acc: 92.560 Val_Loss: 0.2577  BEST VAL Loss: 0.2577  Val_Acc: 93.786

Epoch 81: Validation loss decreased (0.257652 --> 0.256941).  Saving model ...
	 Train_Loss: 0.2706 Train_Acc: 92.684 Val_Loss: 0.2569  BEST VAL Loss: 0.2569  Val_Acc: 94.691

Epoch 82: Validation loss decreased (0.256941 --> 0.256673).  Saving model ...
	 Train_Loss: 0.2700 Train_Acc: 92.581 Val_Loss: 0.2567  BEST VAL Loss: 0.2567  Val_Acc: 93.663

Epoch 83: Validation loss decreased (0.256673 --> 0.256051).  Saving model ...
	 Train_Loss: 0.2694 Train_Acc: 92.709 Val_Loss: 0.2561  BEST VAL Loss: 0.2561  Val_Acc: 94.444

Epoch 84: Validation loss decreased (0.256051 --> 0.255622).  Saving model ...
	 Train_Loss: 0.2689 Train_Acc: 92.663 Val_Loss: 0.2556  BEST VAL Loss: 0.2556  Val_Acc: 93.951

Epoch 85: Validation loss decreased (0.255622 --> 0.255275).  Saving model ...
	 Train_Loss: 0.2683 Train_Acc: 92.483 Val_Loss: 0.2553  BEST VAL Loss: 0.2553  Val_Acc: 94.156

Epoch 86: Validation loss decreased (0.255275 --> 0.254668).  Saving model ...
	 Train_Loss: 0.2678 Train_Acc: 92.396 Val_Loss: 0.2547  BEST VAL Loss: 0.2547  Val_Acc: 94.815

Epoch 87: Validation loss decreased (0.254668 --> 0.254342).  Saving model ...
	 Train_Loss: 0.2673 Train_Acc: 92.792 Val_Loss: 0.2543  BEST VAL Loss: 0.2543  Val_Acc: 94.403

Epoch 88: Validation loss decreased (0.254342 --> 0.253917).  Saving model ...
	 Train_Loss: 0.2668 Train_Acc: 92.483 Val_Loss: 0.2539  BEST VAL Loss: 0.2539  Val_Acc: 94.198

Epoch 89: Validation loss decreased (0.253917 --> 0.253555).  Saving model ...
	 Train_Loss: 0.2662 Train_Acc: 92.560 Val_Loss: 0.2536  BEST VAL Loss: 0.2536  Val_Acc: 94.115

Epoch 90: Validation loss decreased (0.253555 --> 0.253153).  Saving model ...
	 Train_Loss: 0.2657 Train_Acc: 92.576 Val_Loss: 0.2532  BEST VAL Loss: 0.2532  Val_Acc: 94.239

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.2652 Train_Acc: 92.925 Val_Loss: 0.2532  BEST VAL Loss: 0.2532  Val_Acc: 93.539

Epoch 92: Validation loss decreased (0.253153 --> 0.252751).  Saving model ...
	 Train_Loss: 0.2648 Train_Acc: 92.288 Val_Loss: 0.2528  BEST VAL Loss: 0.2528  Val_Acc: 94.280

Epoch 93: Validation loss decreased (0.252751 --> 0.252263).  Saving model ...
	 Train_Loss: 0.2643 Train_Acc: 92.771 Val_Loss: 0.2523  BEST VAL Loss: 0.2523  Val_Acc: 94.198

Epoch 94: Validation loss decreased (0.252263 --> 0.252085).  Saving model ...
	 Train_Loss: 0.2638 Train_Acc: 92.370 Val_Loss: 0.2521  BEST VAL Loss: 0.2521  Val_Acc: 94.321

Epoch 95: Validation loss decreased (0.252085 --> 0.251810).  Saving model ...
	 Train_Loss: 0.2634 Train_Acc: 92.668 Val_Loss: 0.2518  BEST VAL Loss: 0.2518  Val_Acc: 93.580

Epoch 96: Validation loss decreased (0.251810 --> 0.251623).  Saving model ...
	 Train_Loss: 0.2628 Train_Acc: 93.126 Val_Loss: 0.2516  BEST VAL Loss: 0.2516  Val_Acc: 93.951

Epoch 97: Validation loss decreased (0.251623 --> 0.251228).  Saving model ...
	 Train_Loss: 0.2623 Train_Acc: 92.807 Val_Loss: 0.2512  BEST VAL Loss: 0.2512  Val_Acc: 94.362

Epoch 98: Validation loss decreased (0.251228 --> 0.250744).  Saving model ...
	 Train_Loss: 0.2619 Train_Acc: 92.761 Val_Loss: 0.2507  BEST VAL Loss: 0.2507  Val_Acc: 94.362

Epoch 99: Validation loss did not decrease
	 Train_Loss: 0.2614 Train_Acc: 92.766 Val_Loss: 0.2508  BEST VAL Loss: 0.2507  Val_Acc: 93.745

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.49      0.50      9832
           1       0.50      0.52      0.51      9604

    accuracy                           0.51     19436
   macro avg       0.51      0.51      0.51     19436
weighted avg       0.51      0.51      0.51     19436

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.47      0.48      1229
           1       0.48      0.50      0.49      1201

    accuracy                           0.48      2430
   macro avg       0.48      0.48      0.48      2430
weighted avg       0.48      0.48      0.48      2430

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.50      0.51      1229
           1       0.51      0.52      0.51      1201

    accuracy                           0.51      2430
   macro avg       0.51      0.51      0.51      2430
weighted avg       0.51      0.51      0.51      2430

              precision    recall  f1-score   support

           0       0.52      0.50      0.51      1229
           1       0.51      0.52      0.51      1201

    accuracy                           0.51      2430
   macro avg       0.51      0.51      0.51      2430
weighted avg       0.51      0.51      0.51      2430

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.49      0.50      4168
           1       0.51      0.52      0.51      4212

    accuracy                           0.51      8380
   macro avg       0.50      0.50      0.50      8380
weighted avg       0.50      0.51      0.50      8380

              precision    recall  f1-score   support

           0       0.50      0.49      0.50      4168
           1       0.51      0.52      0.51      4212

    accuracy                           0.51      8380
   macro avg       0.50      0.50      0.50      8380
weighted avg       0.50      0.51      0.50      8380

completed
