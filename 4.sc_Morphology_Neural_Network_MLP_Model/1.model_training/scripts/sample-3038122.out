[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '70161672'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'adfc739b'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '87c0b1c2'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '7f145b97'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_100.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_100.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_100.000_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (340601, 1270)
Number of total missing values across all columns: 318870
Data Subset Is Off
Wells held out for testing: ['J08' 'M09']
Wells to use for training, validation, and testing ['J02' 'J03' 'J09' 'M02' 'M03' 'M08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.357544).  Saving model ...
	 Train_Loss: 0.5079 Train_Acc: 73.594 Val_Loss: 0.3575  BEST VAL Loss: 0.3575  Val_Acc: 85.714

Epoch 1: Validation loss decreased (0.357544 --> 0.318502).  Saving model ...
	 Train_Loss: 0.4465 Train_Acc: 83.500 Val_Loss: 0.3185  BEST VAL Loss: 0.3185  Val_Acc: 89.202

Epoch 2: Validation loss decreased (0.318502 --> 0.294802).  Saving model ...
	 Train_Loss: 0.4061 Train_Acc: 86.862 Val_Loss: 0.2948  BEST VAL Loss: 0.2948  Val_Acc: 90.562

Epoch 3: Validation loss decreased (0.294802 --> 0.279290).  Saving model ...
	 Train_Loss: 0.3793 Train_Acc: 87.959 Val_Loss: 0.2793  BEST VAL Loss: 0.2793  Val_Acc: 91.172

Epoch 4: Validation loss decreased (0.279290 --> 0.267527).  Saving model ...
	 Train_Loss: 0.3603 Train_Acc: 88.519 Val_Loss: 0.2675  BEST VAL Loss: 0.2675  Val_Acc: 91.614

Epoch 5: Validation loss decreased (0.267527 --> 0.258635).  Saving model ...
	 Train_Loss: 0.3457 Train_Acc: 88.991 Val_Loss: 0.2586  BEST VAL Loss: 0.2586  Val_Acc: 91.913

Epoch 6: Validation loss decreased (0.258635 --> 0.251453).  Saving model ...
	 Train_Loss: 0.3341 Train_Acc: 89.456 Val_Loss: 0.2515  BEST VAL Loss: 0.2515  Val_Acc: 92.146

Epoch 7: Validation loss decreased (0.251453 --> 0.245680).  Saving model ...
	 Train_Loss: 0.3244 Train_Acc: 89.781 Val_Loss: 0.2457  BEST VAL Loss: 0.2457  Val_Acc: 92.327

Epoch 8: Validation loss decreased (0.245680 --> 0.240760).  Saving model ...
	 Train_Loss: 0.3159 Train_Acc: 90.230 Val_Loss: 0.2408  BEST VAL Loss: 0.2408  Val_Acc: 92.394

Epoch 9: Validation loss decreased (0.240760 --> 0.236264).  Saving model ...
	 Train_Loss: 0.3085 Train_Acc: 90.633 Val_Loss: 0.2363  BEST VAL Loss: 0.2363  Val_Acc: 92.682

Epoch 10: Validation loss decreased (0.236264 --> 0.232450).  Saving model ...
	 Train_Loss: 0.3020 Train_Acc: 90.905 Val_Loss: 0.2324  BEST VAL Loss: 0.2324  Val_Acc: 92.634

Epoch 11: Validation loss decreased (0.232450 --> 0.228900).  Saving model ...
	 Train_Loss: 0.2962 Train_Acc: 91.182 Val_Loss: 0.2289  BEST VAL Loss: 0.2289  Val_Acc: 92.808

Epoch 12: Validation loss decreased (0.228900 --> 0.225511).  Saving model ...
	 Train_Loss: 0.2908 Train_Acc: 91.533 Val_Loss: 0.2255  BEST VAL Loss: 0.2255  Val_Acc: 92.954

Epoch 13: Validation loss decreased (0.225511 --> 0.222696).  Saving model ...
	 Train_Loss: 0.2858 Train_Acc: 91.693 Val_Loss: 0.2227  BEST VAL Loss: 0.2227  Val_Acc: 92.891

Epoch 14: Validation loss decreased (0.222696 --> 0.219893).  Saving model ...
	 Train_Loss: 0.2813 Train_Acc: 91.868 Val_Loss: 0.2199  BEST VAL Loss: 0.2199  Val_Acc: 93.076

Epoch 15: Validation loss decreased (0.219893 --> 0.217263).  Saving model ...
	 Train_Loss: 0.2771 Train_Acc: 92.003 Val_Loss: 0.2173  BEST VAL Loss: 0.2173  Val_Acc: 93.210

Epoch 16: Validation loss decreased (0.217263 --> 0.214909).  Saving model ...
	 Train_Loss: 0.2732 Train_Acc: 92.164 Val_Loss: 0.2149  BEST VAL Loss: 0.2149  Val_Acc: 93.202

Epoch 17: Validation loss decreased (0.214909 --> 0.212664).  Saving model ...
	 Train_Loss: 0.2697 Train_Acc: 92.135 Val_Loss: 0.2127  BEST VAL Loss: 0.2127  Val_Acc: 93.332

Epoch 18: Validation loss decreased (0.212664 --> 0.210491).  Saving model ...
	 Train_Loss: 0.2665 Train_Acc: 92.278 Val_Loss: 0.2105  BEST VAL Loss: 0.2105  Val_Acc: 93.379

Epoch 19: Validation loss decreased (0.210491 --> 0.208581).  Saving model ...
	 Train_Loss: 0.2634 Train_Acc: 92.346 Val_Loss: 0.2086  BEST VAL Loss: 0.2086  Val_Acc: 93.423

Epoch 20: Validation loss decreased (0.208581 --> 0.206707).  Saving model ...
	 Train_Loss: 0.2605 Train_Acc: 92.425 Val_Loss: 0.2067  BEST VAL Loss: 0.2067  Val_Acc: 93.568

Epoch 21: Validation loss decreased (0.206707 --> 0.204940).  Saving model ...
	 Train_Loss: 0.2578 Train_Acc: 92.556 Val_Loss: 0.2049  BEST VAL Loss: 0.2049  Val_Acc: 93.572

Epoch 22: Validation loss decreased (0.204940 --> 0.203297).  Saving model ...
	 Train_Loss: 0.2553 Train_Acc: 92.509 Val_Loss: 0.2033  BEST VAL Loss: 0.2033  Val_Acc: 93.754

Epoch 23: Validation loss decreased (0.203297 --> 0.201700).  Saving model ...
	 Train_Loss: 0.2529 Train_Acc: 92.604 Val_Loss: 0.2017  BEST VAL Loss: 0.2017  Val_Acc: 93.734

Epoch 24: Validation loss decreased (0.201700 --> 0.200277).  Saving model ...
	 Train_Loss: 0.2507 Train_Acc: 92.687 Val_Loss: 0.2003  BEST VAL Loss: 0.2003  Val_Acc: 93.679

Epoch 25: Validation loss decreased (0.200277 --> 0.198867).  Saving model ...
	 Train_Loss: 0.2486 Train_Acc: 92.759 Val_Loss: 0.1989  BEST VAL Loss: 0.1989  Val_Acc: 93.769

Epoch 26: Validation loss decreased (0.198867 --> 0.197578).  Saving model ...
	 Train_Loss: 0.2466 Train_Acc: 92.770 Val_Loss: 0.1976  BEST VAL Loss: 0.1976  Val_Acc: 93.892

Epoch 27: Validation loss decreased (0.197578 --> 0.196251).  Saving model ...
	 Train_Loss: 0.2447 Train_Acc: 92.899 Val_Loss: 0.1963  BEST VAL Loss: 0.1963  Val_Acc: 93.947

Epoch 28: Validation loss decreased (0.196251 --> 0.195040).  Saving model ...
	 Train_Loss: 0.2429 Train_Acc: 92.821 Val_Loss: 0.1950  BEST VAL Loss: 0.1950  Val_Acc: 93.947

Epoch 29: Validation loss decreased (0.195040 --> 0.193985).  Saving model ...
	 Train_Loss: 0.2412 Train_Acc: 92.908 Val_Loss: 0.1940  BEST VAL Loss: 0.1940  Val_Acc: 93.884

Epoch 30: Validation loss decreased (0.193985 --> 0.192879).  Saving model ...
	 Train_Loss: 0.2395 Train_Acc: 92.963 Val_Loss: 0.1929  BEST VAL Loss: 0.1929  Val_Acc: 93.931

Epoch 31: Validation loss decreased (0.192879 --> 0.191774).  Saving model ...
	 Train_Loss: 0.2380 Train_Acc: 92.946 Val_Loss: 0.1918  BEST VAL Loss: 0.1918  Val_Acc: 94.100

Epoch 32: Validation loss decreased (0.191774 --> 0.190735).  Saving model ...
	 Train_Loss: 0.2365 Train_Acc: 93.027 Val_Loss: 0.1907  BEST VAL Loss: 0.1907  Val_Acc: 94.002

Epoch 33: Validation loss decreased (0.190735 --> 0.189730).  Saving model ...
	 Train_Loss: 0.2350 Train_Acc: 93.046 Val_Loss: 0.1897  BEST VAL Loss: 0.1897  Val_Acc: 94.093

Epoch 34: Validation loss decreased (0.189730 --> 0.188805).  Saving model ...
	 Train_Loss: 0.2336 Train_Acc: 93.146 Val_Loss: 0.1888  BEST VAL Loss: 0.1888  Val_Acc: 94.156

Epoch 35: Validation loss decreased (0.188805 --> 0.187913).  Saving model ...
	 Train_Loss: 0.2322 Train_Acc: 93.107 Val_Loss: 0.1879  BEST VAL Loss: 0.1879  Val_Acc: 94.089

Epoch 36: Validation loss decreased (0.187913 --> 0.187079).  Saving model ...
	 Train_Loss: 0.2309 Train_Acc: 93.212 Val_Loss: 0.1871  BEST VAL Loss: 0.1871  Val_Acc: 94.203

Epoch 37: Validation loss decreased (0.187079 --> 0.186231).  Saving model ...
	 Train_Loss: 0.2296 Train_Acc: 93.223 Val_Loss: 0.1862  BEST VAL Loss: 0.1862  Val_Acc: 94.266

Epoch 38: Validation loss decreased (0.186231 --> 0.185455).  Saving model ...
	 Train_Loss: 0.2284 Train_Acc: 93.253 Val_Loss: 0.1855  BEST VAL Loss: 0.1855  Val_Acc: 94.160

Epoch 39: Validation loss decreased (0.185455 --> 0.184882).  Saving model ...
	 Train_Loss: 0.2273 Train_Acc: 93.217 Val_Loss: 0.1849  BEST VAL Loss: 0.1849  Val_Acc: 93.860

Epoch 40: Validation loss decreased (0.184882 --> 0.184164).  Saving model ...
	 Train_Loss: 0.2262 Train_Acc: 93.256 Val_Loss: 0.1842  BEST VAL Loss: 0.1842  Val_Acc: 94.152

Epoch 41: Validation loss decreased (0.184164 --> 0.183413).  Saving model ...
	 Train_Loss: 0.2251 Train_Acc: 93.228 Val_Loss: 0.1834  BEST VAL Loss: 0.1834  Val_Acc: 94.333

Epoch 42: Validation loss decreased (0.183413 --> 0.182694).  Saving model ...
	 Train_Loss: 0.2240 Train_Acc: 93.317 Val_Loss: 0.1827  BEST VAL Loss: 0.1827  Val_Acc: 94.317

Epoch 43: Validation loss decreased (0.182694 --> 0.181970).  Saving model ...
	 Train_Loss: 0.2230 Train_Acc: 93.391 Val_Loss: 0.1820  BEST VAL Loss: 0.1820  Val_Acc: 94.361

Epoch 44: Validation loss decreased (0.181970 --> 0.181346).  Saving model ...
	 Train_Loss: 0.2220 Train_Acc: 93.391 Val_Loss: 0.1813  BEST VAL Loss: 0.1813  Val_Acc: 94.274

Epoch 45: Validation loss decreased (0.181346 --> 0.180693).  Saving model ...
	 Train_Loss: 0.2211 Train_Acc: 93.323 Val_Loss: 0.1807  BEST VAL Loss: 0.1807  Val_Acc: 94.380

Epoch 46: Validation loss decreased (0.180693 --> 0.180159).  Saving model ...
	 Train_Loss: 0.2202 Train_Acc: 93.382 Val_Loss: 0.1802  BEST VAL Loss: 0.1802  Val_Acc: 94.207

Epoch 47: Validation loss decreased (0.180159 --> 0.179531).  Saving model ...
	 Train_Loss: 0.2193 Train_Acc: 93.454 Val_Loss: 0.1795  BEST VAL Loss: 0.1795  Val_Acc: 94.428

Epoch 48: Validation loss decreased (0.179531 --> 0.178955).  Saving model ...
	 Train_Loss: 0.2184 Train_Acc: 93.502 Val_Loss: 0.1790  BEST VAL Loss: 0.1790  Val_Acc: 94.412

Epoch 49: Validation loss decreased (0.178955 --> 0.178415).  Saving model ...
	 Train_Loss: 0.2175 Train_Acc: 93.463 Val_Loss: 0.1784  BEST VAL Loss: 0.1784  Val_Acc: 94.357

Epoch 50: Validation loss decreased (0.178415 --> 0.177870).  Saving model ...
	 Train_Loss: 0.2167 Train_Acc: 93.508 Val_Loss: 0.1779  BEST VAL Loss: 0.1779  Val_Acc: 94.491

Epoch 51: Validation loss decreased (0.177870 --> 0.177411).  Saving model ...
	 Train_Loss: 0.2159 Train_Acc: 93.592 Val_Loss: 0.1774  BEST VAL Loss: 0.1774  Val_Acc: 94.183

Epoch 52: Validation loss decreased (0.177411 --> 0.176922).  Saving model ...
	 Train_Loss: 0.2151 Train_Acc: 93.513 Val_Loss: 0.1769  BEST VAL Loss: 0.1769  Val_Acc: 94.357

Epoch 53: Validation loss decreased (0.176922 --> 0.176443).  Saving model ...
	 Train_Loss: 0.2143 Train_Acc: 93.584 Val_Loss: 0.1764  BEST VAL Loss: 0.1764  Val_Acc: 94.408

Epoch 54: Validation loss decreased (0.176443 --> 0.175987).  Saving model ...
	 Train_Loss: 0.2136 Train_Acc: 93.573 Val_Loss: 0.1760  BEST VAL Loss: 0.1760  Val_Acc: 94.372

Epoch 55: Validation loss decreased (0.175987 --> 0.175505).  Saving model ...
	 Train_Loss: 0.2128 Train_Acc: 93.602 Val_Loss: 0.1755  BEST VAL Loss: 0.1755  Val_Acc: 94.502

Epoch 56: Validation loss decreased (0.175505 --> 0.175056).  Saving model ...
	 Train_Loss: 0.2121 Train_Acc: 93.618 Val_Loss: 0.1751  BEST VAL Loss: 0.1751  Val_Acc: 94.357

Epoch 57: Validation loss decreased (0.175056 --> 0.174611).  Saving model ...
	 Train_Loss: 0.2115 Train_Acc: 93.654 Val_Loss: 0.1746  BEST VAL Loss: 0.1746  Val_Acc: 94.424

Epoch 58: Validation loss decreased (0.174611 --> 0.174233).  Saving model ...
	 Train_Loss: 0.2108 Train_Acc: 93.763 Val_Loss: 0.1742  BEST VAL Loss: 0.1742  Val_Acc: 94.223

Epoch 59: Validation loss decreased (0.174233 --> 0.173794).  Saving model ...
	 Train_Loss: 0.2101 Train_Acc: 93.698 Val_Loss: 0.1738  BEST VAL Loss: 0.1738  Val_Acc: 94.491

Epoch 60: Validation loss decreased (0.173794 --> 0.173381).  Saving model ...
	 Train_Loss: 0.2095 Train_Acc: 93.715 Val_Loss: 0.1734  BEST VAL Loss: 0.1734  Val_Acc: 94.447

Epoch 61: Validation loss decreased (0.173381 --> 0.172996).  Saving model ...
	 Train_Loss: 0.2088 Train_Acc: 93.736 Val_Loss: 0.1730  BEST VAL Loss: 0.1730  Val_Acc: 94.534

Epoch 62: Validation loss decreased (0.172996 --> 0.172618).  Saving model ...
	 Train_Loss: 0.2082 Train_Acc: 93.755 Val_Loss: 0.1726  BEST VAL Loss: 0.1726  Val_Acc: 94.380

Epoch 63: Validation loss decreased (0.172618 --> 0.172218).  Saving model ...
	 Train_Loss: 0.2076 Train_Acc: 93.764 Val_Loss: 0.1722  BEST VAL Loss: 0.1722  Val_Acc: 94.451

Epoch 64: Validation loss decreased (0.172218 --> 0.171825).  Saving model ...
	 Train_Loss: 0.2070 Train_Acc: 93.670 Val_Loss: 0.1718  BEST VAL Loss: 0.1718  Val_Acc: 94.566

Epoch 65: Validation loss decreased (0.171825 --> 0.171419).  Saving model ...
	 Train_Loss: 0.2064 Train_Acc: 93.775 Val_Loss: 0.1714  BEST VAL Loss: 0.1714  Val_Acc: 94.640

Epoch 66: Validation loss decreased (0.171419 --> 0.171037).  Saving model ...
	 Train_Loss: 0.2059 Train_Acc: 93.750 Val_Loss: 0.1710  BEST VAL Loss: 0.1710  Val_Acc: 94.601

Epoch 67: Validation loss decreased (0.171037 --> 0.170682).  Saving model ...
	 Train_Loss: 0.2053 Train_Acc: 93.800 Val_Loss: 0.1707  BEST VAL Loss: 0.1707  Val_Acc: 94.483

Epoch 68: Validation loss decreased (0.170682 --> 0.170357).  Saving model ...
	 Train_Loss: 0.2048 Train_Acc: 93.751 Val_Loss: 0.1704  BEST VAL Loss: 0.1704  Val_Acc: 94.530

Epoch 69: Validation loss decreased (0.170357 --> 0.169983).  Saving model ...
	 Train_Loss: 0.2043 Train_Acc: 93.724 Val_Loss: 0.1700  BEST VAL Loss: 0.1700  Val_Acc: 94.625

Epoch 70: Validation loss decreased (0.169983 --> 0.169647).  Saving model ...
	 Train_Loss: 0.2038 Train_Acc: 93.817 Val_Loss: 0.1696  BEST VAL Loss: 0.1696  Val_Acc: 94.660

Epoch 71: Validation loss decreased (0.169647 --> 0.169308).  Saving model ...
	 Train_Loss: 0.2032 Train_Acc: 93.810 Val_Loss: 0.1693  BEST VAL Loss: 0.1693  Val_Acc: 94.703

Epoch 72: Validation loss decreased (0.169308 --> 0.168974).  Saving model ...
	 Train_Loss: 0.2028 Train_Acc: 93.870 Val_Loss: 0.1690  BEST VAL Loss: 0.1690  Val_Acc: 94.692

Epoch 73: Validation loss decreased (0.168974 --> 0.168661).  Saving model ...
	 Train_Loss: 0.2023 Train_Acc: 93.832 Val_Loss: 0.1687  BEST VAL Loss: 0.1687  Val_Acc: 94.585

Epoch 74: Validation loss decreased (0.168661 --> 0.168350).  Saving model ...
	 Train_Loss: 0.2018 Train_Acc: 93.901 Val_Loss: 0.1683  BEST VAL Loss: 0.1683  Val_Acc: 94.597

Epoch 75: Validation loss decreased (0.168350 --> 0.168075).  Saving model ...
	 Train_Loss: 0.2013 Train_Acc: 93.937 Val_Loss: 0.1681  BEST VAL Loss: 0.1681  Val_Acc: 94.542

Epoch 76: Validation loss decreased (0.168075 --> 0.167810).  Saving model ...
	 Train_Loss: 0.2008 Train_Acc: 93.866 Val_Loss: 0.1678  BEST VAL Loss: 0.1678  Val_Acc: 94.562

Epoch 77: Validation loss decreased (0.167810 --> 0.167518).  Saving model ...
	 Train_Loss: 0.2004 Train_Acc: 93.934 Val_Loss: 0.1675  BEST VAL Loss: 0.1675  Val_Acc: 94.566

Epoch 78: Validation loss decreased (0.167518 --> 0.167204).  Saving model ...
	 Train_Loss: 0.1999 Train_Acc: 93.877 Val_Loss: 0.1672  BEST VAL Loss: 0.1672  Val_Acc: 94.727

Epoch 79: Validation loss decreased (0.167204 --> 0.166921).  Saving model ...
	 Train_Loss: 0.1995 Train_Acc: 93.893 Val_Loss: 0.1669  BEST VAL Loss: 0.1669  Val_Acc: 94.581

Epoch 80: Validation loss decreased (0.166921 --> 0.166640).  Saving model ...
	 Train_Loss: 0.1990 Train_Acc: 93.942 Val_Loss: 0.1666  BEST VAL Loss: 0.1666  Val_Acc: 94.676

Epoch 81: Validation loss decreased (0.166640 --> 0.166381).  Saving model ...
	 Train_Loss: 0.1986 Train_Acc: 93.934 Val_Loss: 0.1664  BEST VAL Loss: 0.1664  Val_Acc: 94.696

Epoch 82: Validation loss decreased (0.166381 --> 0.166099).  Saving model ...
	 Train_Loss: 0.1982 Train_Acc: 93.911 Val_Loss: 0.1661  BEST VAL Loss: 0.1661  Val_Acc: 94.759

Epoch 83: Validation loss decreased (0.166099 --> 0.165808).  Saving model ...
	 Train_Loss: 0.1978 Train_Acc: 93.927 Val_Loss: 0.1658  BEST VAL Loss: 0.1658  Val_Acc: 94.755

Epoch 84: Validation loss decreased (0.165808 --> 0.165536).  Saving model ...
	 Train_Loss: 0.1974 Train_Acc: 93.968 Val_Loss: 0.1655  BEST VAL Loss: 0.1655  Val_Acc: 94.613

Epoch 85: Validation loss decreased (0.165536 --> 0.165302).  Saving model ...
	 Train_Loss: 0.1970 Train_Acc: 93.993 Val_Loss: 0.1653  BEST VAL Loss: 0.1653  Val_Acc: 94.696

Epoch 86: Validation loss decreased (0.165302 --> 0.165054).  Saving model ...
	 Train_Loss: 0.1966 Train_Acc: 94.025 Val_Loss: 0.1651  BEST VAL Loss: 0.1651  Val_Acc: 94.621

Epoch 87: Validation loss decreased (0.165054 --> 0.164823).  Saving model ...
	 Train_Loss: 0.1962 Train_Acc: 93.984 Val_Loss: 0.1648  BEST VAL Loss: 0.1648  Val_Acc: 94.518

Epoch 88: Validation loss decreased (0.164823 --> 0.164598).  Saving model ...
	 Train_Loss: 0.1959 Train_Acc: 93.985 Val_Loss: 0.1646  BEST VAL Loss: 0.1646  Val_Acc: 94.609

Epoch 89: Validation loss decreased (0.164598 --> 0.164360).  Saving model ...
	 Train_Loss: 0.1955 Train_Acc: 93.979 Val_Loss: 0.1644  BEST VAL Loss: 0.1644  Val_Acc: 94.711

Epoch 90: Validation loss decreased (0.164360 --> 0.164113).  Saving model ...
	 Train_Loss: 0.1951 Train_Acc: 93.979 Val_Loss: 0.1641  BEST VAL Loss: 0.1641  Val_Acc: 94.755

Epoch 91: Validation loss decreased (0.164113 --> 0.163873).  Saving model ...
	 Train_Loss: 0.1948 Train_Acc: 94.002 Val_Loss: 0.1639  BEST VAL Loss: 0.1639  Val_Acc: 94.837

Epoch 92: Validation loss decreased (0.163873 --> 0.163693).  Saving model ...
	 Train_Loss: 0.1944 Train_Acc: 94.036 Val_Loss: 0.1637  BEST VAL Loss: 0.1637  Val_Acc: 94.633

Epoch 93: Validation loss decreased (0.163693 --> 0.163474).  Saving model ...
	 Train_Loss: 0.1941 Train_Acc: 93.980 Val_Loss: 0.1635  BEST VAL Loss: 0.1635  Val_Acc: 94.652

Epoch 94: Validation loss decreased (0.163474 --> 0.163276).  Saving model ...
	 Train_Loss: 0.1937 Train_Acc: 94.027 Val_Loss: 0.1633  BEST VAL Loss: 0.1633  Val_Acc: 94.636

Epoch 95: Validation loss decreased (0.163276 --> 0.163070).  Saving model ...
	 Train_Loss: 0.1934 Train_Acc: 94.058 Val_Loss: 0.1631  BEST VAL Loss: 0.1631  Val_Acc: 94.770

Epoch 96: Validation loss decreased (0.163070 --> 0.162848).  Saving model ...
	 Train_Loss: 0.1931 Train_Acc: 94.052 Val_Loss: 0.1628  BEST VAL Loss: 0.1628  Val_Acc: 94.857

Epoch 97: Validation loss decreased (0.162848 --> 0.162648).  Saving model ...
	 Train_Loss: 0.1927 Train_Acc: 94.076 Val_Loss: 0.1626  BEST VAL Loss: 0.1626  Val_Acc: 94.778

Epoch 98: Validation loss decreased (0.162648 --> 0.162452).  Saving model ...
	 Train_Loss: 0.1924 Train_Acc: 94.086 Val_Loss: 0.1625  BEST VAL Loss: 0.1625  Val_Acc: 94.711

Epoch 99: Validation loss decreased (0.162452 --> 0.162263).  Saving model ...
	 Train_Loss: 0.1921 Train_Acc: 94.065 Val_Loss: 0.1623  BEST VAL Loss: 0.1623  Val_Acc: 94.719

LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.94      0.97      0.96     97753
           1       0.97      0.95      0.96    105241

    accuracy                           0.96    202994
   macro avg       0.96      0.96      0.96    202994
weighted avg       0.96      0.96      0.96    202994

LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.96      0.95     12219
           1       0.96      0.94      0.95     13156

    accuracy                           0.95     25375
   macro avg       0.95      0.95      0.95     25375
weighted avg       0.95      0.95      0.95     25375

LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.96      0.95     12220
           1       0.96      0.93      0.95     13155

    accuracy                           0.95     25375
   macro avg       0.95      0.95      0.95     25375
weighted avg       0.95      0.95      0.95     25375

              precision    recall  f1-score   support

           0       0.93      0.96      0.95     12220
           1       0.96      0.93      0.95     13155

    accuracy                           0.95     25375
   macro avg       0.95      0.95      0.95     25375
weighted avg       0.95      0.95      0.95     25375

LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.83      0.90     37243
           1       0.89      0.99      0.93     49614

    accuracy                           0.92     86857
   macro avg       0.93      0.91      0.92     86857
weighted avg       0.93      0.92      0.92     86857

              precision    recall  f1-score   support

           0       0.98      0.83      0.90     37243
           1       0.89      0.99      0.93     49614

    accuracy                           0.92     86857
   macro avg       0.93      0.91      0.92     86857
weighted avg       0.93      0.92      0.92     86857

completed
