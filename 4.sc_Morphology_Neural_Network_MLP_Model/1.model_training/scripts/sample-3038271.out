[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'f1ef7c0d'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '8ea02a14'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '62ba4527'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'a83454dd'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: H2O2_100.000_DMSO_0.025 treatment_name: LPS_10.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: LPS_10.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (397026, 1270)
Number of total missing values across all columns: 794052
Data Subset Is Off
Wells held out for testing: ['E09' 'I10']
Wells to use for training, validation, and testing ['E02' 'E03' 'E08' 'H04' 'I04' 'H05' 'I05' 'H10' 'H11' 'I11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.356226).  Saving model ...
	 Train_Loss: 0.4828 Train_Acc: 76.595 Val_Loss: 0.3562  BEST VAL Loss: 0.3562  Val_Acc: 84.317

Epoch 1: Validation loss decreased (0.356226 --> 0.338854).  Saving model ...
	 Train_Loss: 0.4400 Train_Acc: 81.252 Val_Loss: 0.3389  BEST VAL Loss: 0.3389  Val_Acc: 85.570

Epoch 2: Validation loss decreased (0.338854 --> 0.325889).  Saving model ...
	 Train_Loss: 0.4167 Train_Acc: 82.566 Val_Loss: 0.3259  BEST VAL Loss: 0.3259  Val_Acc: 86.933

Epoch 3: Validation loss decreased (0.325889 --> 0.319140).  Saving model ...
	 Train_Loss: 0.4018 Train_Acc: 83.988 Val_Loss: 0.3191  BEST VAL Loss: 0.3191  Val_Acc: 87.227

Epoch 4: Validation loss decreased (0.319140 --> 0.312991).  Saving model ...
	 Train_Loss: 0.3915 Train_Acc: 84.813 Val_Loss: 0.3130  BEST VAL Loss: 0.3130  Val_Acc: 87.328

Epoch 5: Validation loss decreased (0.312991 --> 0.306898).  Saving model ...
	 Train_Loss: 0.3827 Train_Acc: 85.510 Val_Loss: 0.3069  BEST VAL Loss: 0.3069  Val_Acc: 88.138

Epoch 6: Validation loss decreased (0.306898 --> 0.301968).  Saving model ...
	 Train_Loss: 0.3760 Train_Acc: 85.717 Val_Loss: 0.3020  BEST VAL Loss: 0.3020  Val_Acc: 88.297

Epoch 7: Validation loss decreased (0.301968 --> 0.297390).  Saving model ...
	 Train_Loss: 0.3702 Train_Acc: 86.053 Val_Loss: 0.2974  BEST VAL Loss: 0.2974  Val_Acc: 88.550

Epoch 8: Validation loss decreased (0.297390 --> 0.294179).  Saving model ...
	 Train_Loss: 0.3654 Train_Acc: 86.167 Val_Loss: 0.2942  BEST VAL Loss: 0.2942  Val_Acc: 88.666

Epoch 9: Validation loss decreased (0.294179 --> 0.292336).  Saving model ...
	 Train_Loss: 0.3613 Train_Acc: 86.188 Val_Loss: 0.2923  BEST VAL Loss: 0.2923  Val_Acc: 88.275

Epoch 10: Validation loss decreased (0.292336 --> 0.290172).  Saving model ...
	 Train_Loss: 0.3577 Train_Acc: 86.525 Val_Loss: 0.2902  BEST VAL Loss: 0.2902  Val_Acc: 88.877

Epoch 11: Validation loss decreased (0.290172 --> 0.288084).  Saving model ...
	 Train_Loss: 0.3546 Train_Acc: 86.489 Val_Loss: 0.2881  BEST VAL Loss: 0.2881  Val_Acc: 88.783

Epoch 12: Validation loss decreased (0.288084 --> 0.286184).  Saving model ...
	 Train_Loss: 0.3517 Train_Acc: 86.656 Val_Loss: 0.2862  BEST VAL Loss: 0.2862  Val_Acc: 88.883

Epoch 13: Validation loss decreased (0.286184 --> 0.284326).  Saving model ...
	 Train_Loss: 0.3492 Train_Acc: 86.722 Val_Loss: 0.2843  BEST VAL Loss: 0.2843  Val_Acc: 88.905

Epoch 14: Validation loss decreased (0.284326 --> 0.282801).  Saving model ...
	 Train_Loss: 0.3470 Train_Acc: 86.750 Val_Loss: 0.2828  BEST VAL Loss: 0.2828  Val_Acc: 88.954

Epoch 15: Validation loss decreased (0.282801 --> 0.281591).  Saving model ...
	 Train_Loss: 0.3449 Train_Acc: 86.970 Val_Loss: 0.2816  BEST VAL Loss: 0.2816  Val_Acc: 88.997

Epoch 16: Validation loss decreased (0.281591 --> 0.280693).  Saving model ...
	 Train_Loss: 0.3430 Train_Acc: 87.039 Val_Loss: 0.2807  BEST VAL Loss: 0.2807  Val_Acc: 88.926

Epoch 17: Validation loss decreased (0.280693 --> 0.279689).  Saving model ...
	 Train_Loss: 0.3413 Train_Acc: 87.032 Val_Loss: 0.2797  BEST VAL Loss: 0.2797  Val_Acc: 88.981

Epoch 18: Validation loss decreased (0.279689 --> 0.278776).  Saving model ...
	 Train_Loss: 0.3399 Train_Acc: 86.842 Val_Loss: 0.2788  BEST VAL Loss: 0.2788  Val_Acc: 88.911

Epoch 19: Validation loss decreased (0.278776 --> 0.277584).  Saving model ...
	 Train_Loss: 0.3385 Train_Acc: 86.973 Val_Loss: 0.2776  BEST VAL Loss: 0.2776  Val_Acc: 89.296

Epoch 20: Validation loss decreased (0.277584 --> 0.276988).  Saving model ...
	 Train_Loss: 0.3372 Train_Acc: 87.100 Val_Loss: 0.2770  BEST VAL Loss: 0.2770  Val_Acc: 89.125

Epoch 21: Validation loss decreased (0.276988 --> 0.275936).  Saving model ...
	 Train_Loss: 0.3359 Train_Acc: 87.045 Val_Loss: 0.2759  BEST VAL Loss: 0.2759  Val_Acc: 89.165

Epoch 22: Validation loss decreased (0.275936 --> 0.275163).  Saving model ...
	 Train_Loss: 0.3349 Train_Acc: 87.063 Val_Loss: 0.2752  BEST VAL Loss: 0.2752  Val_Acc: 88.773

Epoch 23: Validation loss decreased (0.275163 --> 0.274533).  Saving model ...
	 Train_Loss: 0.3339 Train_Acc: 87.121 Val_Loss: 0.2745  BEST VAL Loss: 0.2745  Val_Acc: 88.972

Epoch 24: Validation loss decreased (0.274533 --> 0.273748).  Saving model ...
	 Train_Loss: 0.3328 Train_Acc: 87.114 Val_Loss: 0.2737  BEST VAL Loss: 0.2737  Val_Acc: 89.192

Epoch 25: Validation loss decreased (0.273748 --> 0.273578).  Saving model ...
	 Train_Loss: 0.3317 Train_Acc: 87.341 Val_Loss: 0.2736  BEST VAL Loss: 0.2736  Val_Acc: 89.278

Epoch 26: Validation loss decreased (0.273578 --> 0.273200).  Saving model ...
	 Train_Loss: 0.3308 Train_Acc: 87.179 Val_Loss: 0.2732  BEST VAL Loss: 0.2732  Val_Acc: 89.113

Epoch 27: Validation loss decreased (0.273200 --> 0.272832).  Saving model ...
	 Train_Loss: 0.3299 Train_Acc: 87.325 Val_Loss: 0.2728  BEST VAL Loss: 0.2728  Val_Acc: 89.018

Epoch 28: Validation loss decreased (0.272832 --> 0.272554).  Saving model ...
	 Train_Loss: 0.3292 Train_Acc: 87.210 Val_Loss: 0.2726  BEST VAL Loss: 0.2726  Val_Acc: 89.360

Epoch 29: Validation loss decreased (0.272554 --> 0.272254).  Saving model ...
	 Train_Loss: 0.3285 Train_Acc: 87.087 Val_Loss: 0.2723  BEST VAL Loss: 0.2723  Val_Acc: 88.709

Epoch 30: Validation loss decreased (0.272254 --> 0.272233).  Saving model ...
	 Train_Loss: 0.3277 Train_Acc: 87.367 Val_Loss: 0.2722  BEST VAL Loss: 0.2722  Val_Acc: 89.000

Epoch 31: Validation loss decreased (0.272233 --> 0.271935).  Saving model ...
	 Train_Loss: 0.3270 Train_Acc: 87.364 Val_Loss: 0.2719  BEST VAL Loss: 0.2719  Val_Acc: 88.948

Epoch 32: Validation loss decreased (0.271935 --> 0.271301).  Saving model ...
	 Train_Loss: 0.3263 Train_Acc: 87.387 Val_Loss: 0.2713  BEST VAL Loss: 0.2713  Val_Acc: 89.583

Epoch 33: Validation loss decreased (0.271301 --> 0.270998).  Saving model ...
	 Train_Loss: 0.3257 Train_Acc: 87.329 Val_Loss: 0.2710  BEST VAL Loss: 0.2710  Val_Acc: 89.379

Epoch 34: Validation loss decreased (0.270998 --> 0.270624).  Saving model ...
	 Train_Loss: 0.3251 Train_Acc: 87.452 Val_Loss: 0.2706  BEST VAL Loss: 0.2706  Val_Acc: 89.379

Epoch 35: Validation loss decreased (0.270624 --> 0.270193).  Saving model ...
	 Train_Loss: 0.3246 Train_Acc: 87.276 Val_Loss: 0.2702  BEST VAL Loss: 0.2702  Val_Acc: 89.036

Epoch 36: Validation loss decreased (0.270193 --> 0.269829).  Saving model ...
	 Train_Loss: 0.3241 Train_Acc: 87.270 Val_Loss: 0.2698  BEST VAL Loss: 0.2698  Val_Acc: 89.128

Epoch 37: Validation loss decreased (0.269829 --> 0.269355).  Saving model ...
	 Train_Loss: 0.3236 Train_Acc: 87.355 Val_Loss: 0.2694  BEST VAL Loss: 0.2694  Val_Acc: 89.247

Epoch 38: Validation loss decreased (0.269355 --> 0.268880).  Saving model ...
	 Train_Loss: 0.3230 Train_Acc: 87.544 Val_Loss: 0.2689  BEST VAL Loss: 0.2689  Val_Acc: 89.586

Epoch 39: Validation loss decreased (0.268880 --> 0.268559).  Saving model ...
	 Train_Loss: 0.3225 Train_Acc: 87.655 Val_Loss: 0.2686  BEST VAL Loss: 0.2686  Val_Acc: 89.317

Epoch 40: Validation loss decreased (0.268559 --> 0.268048).  Saving model ...
	 Train_Loss: 0.3220 Train_Acc: 87.504 Val_Loss: 0.2680  BEST VAL Loss: 0.2680  Val_Acc: 89.648

Epoch 41: Validation loss decreased (0.268048 --> 0.267908).  Saving model ...
	 Train_Loss: 0.3215 Train_Acc: 87.504 Val_Loss: 0.2679  BEST VAL Loss: 0.2679  Val_Acc: 89.226

Epoch 42: Validation loss decreased (0.267908 --> 0.267561).  Saving model ...
	 Train_Loss: 0.3211 Train_Acc: 87.298 Val_Loss: 0.2676  BEST VAL Loss: 0.2676  Val_Acc: 89.602

Epoch 43: Validation loss decreased (0.267561 --> 0.267275).  Saving model ...
	 Train_Loss: 0.3206 Train_Acc: 87.661 Val_Loss: 0.2673  BEST VAL Loss: 0.2673  Val_Acc: 88.816

Epoch 44: Validation loss decreased (0.267275 --> 0.266929).  Saving model ...
	 Train_Loss: 0.3202 Train_Acc: 87.515 Val_Loss: 0.2669  BEST VAL Loss: 0.2669  Val_Acc: 89.596

Epoch 45: Validation loss decreased (0.266929 --> 0.266574).  Saving model ...
	 Train_Loss: 0.3198 Train_Acc: 87.610 Val_Loss: 0.2666  BEST VAL Loss: 0.2666  Val_Acc: 89.455

Epoch 46: Validation loss decreased (0.266574 --> 0.266403).  Saving model ...
	 Train_Loss: 0.3194 Train_Acc: 87.566 Val_Loss: 0.2664  BEST VAL Loss: 0.2664  Val_Acc: 89.700

Epoch 47: Validation loss decreased (0.266403 --> 0.266110).  Saving model ...
	 Train_Loss: 0.3190 Train_Acc: 87.634 Val_Loss: 0.2661  BEST VAL Loss: 0.2661  Val_Acc: 89.580

Epoch 48: Validation loss decreased (0.266110 --> 0.265897).  Saving model ...
	 Train_Loss: 0.3186 Train_Acc: 87.648 Val_Loss: 0.2659  BEST VAL Loss: 0.2659  Val_Acc: 89.275

Epoch 49: Validation loss decreased (0.265897 --> 0.265713).  Saving model ...
	 Train_Loss: 0.3182 Train_Acc: 87.542 Val_Loss: 0.2657  BEST VAL Loss: 0.2657  Val_Acc: 89.513

Epoch 50: Validation loss decreased (0.265713 --> 0.265528).  Saving model ...
	 Train_Loss: 0.3179 Train_Acc: 87.524 Val_Loss: 0.2655  BEST VAL Loss: 0.2655  Val_Acc: 88.899

Epoch 51: Validation loss decreased (0.265528 --> 0.265259).  Saving model ...
	 Train_Loss: 0.3175 Train_Acc: 87.734 Val_Loss: 0.2653  BEST VAL Loss: 0.2653  Val_Acc: 89.449

Epoch 52: Validation loss decreased (0.265259 --> 0.265012).  Saving model ...
	 Train_Loss: 0.3172 Train_Acc: 87.720 Val_Loss: 0.2650  BEST VAL Loss: 0.2650  Val_Acc: 89.562

Epoch 53: Validation loss decreased (0.265012 --> 0.264846).  Saving model ...
	 Train_Loss: 0.3169 Train_Acc: 87.651 Val_Loss: 0.2648  BEST VAL Loss: 0.2648  Val_Acc: 89.351

Epoch 54: Validation loss decreased (0.264846 --> 0.264619).  Saving model ...
	 Train_Loss: 0.3166 Train_Acc: 87.424 Val_Loss: 0.2646  BEST VAL Loss: 0.2646  Val_Acc: 89.495

Epoch 55: Validation loss decreased (0.264619 --> 0.264407).  Saving model ...
	 Train_Loss: 0.3163 Train_Acc: 87.698 Val_Loss: 0.2644  BEST VAL Loss: 0.2644  Val_Acc: 89.354

Epoch 56: Validation loss decreased (0.264407 --> 0.264086).  Saving model ...
	 Train_Loss: 0.3159 Train_Acc: 87.851 Val_Loss: 0.2641  BEST VAL Loss: 0.2641  Val_Acc: 89.715

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.3157 Train_Acc: 87.445 Val_Loss: 0.2642  BEST VAL Loss: 0.2641  Val_Acc: 89.275

Epoch 58: Validation loss decreased (0.264086 --> 0.264010).  Saving model ...
	 Train_Loss: 0.3154 Train_Acc: 87.639 Val_Loss: 0.2640  BEST VAL Loss: 0.2640  Val_Acc: 89.620

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.3151 Train_Acc: 87.752 Val_Loss: 0.2641  BEST VAL Loss: 0.2640  Val_Acc: 89.645

Epoch 60: Validation loss decreased (0.264010 --> 0.263867).  Saving model ...
	 Train_Loss: 0.3148 Train_Acc: 87.730 Val_Loss: 0.2639  BEST VAL Loss: 0.2639  Val_Acc: 89.623

Epoch 61: Validation loss decreased (0.263867 --> 0.263587).  Saving model ...
	 Train_Loss: 0.3146 Train_Acc: 87.771 Val_Loss: 0.2636  BEST VAL Loss: 0.2636  Val_Acc: 89.562

Epoch 62: Validation loss decreased (0.263587 --> 0.263382).  Saving model ...
	 Train_Loss: 0.3143 Train_Acc: 87.798 Val_Loss: 0.2634  BEST VAL Loss: 0.2634  Val_Acc: 89.556

Epoch 63: Validation loss decreased (0.263382 --> 0.263104).  Saving model ...
	 Train_Loss: 0.3140 Train_Acc: 87.751 Val_Loss: 0.2631  BEST VAL Loss: 0.2631  Val_Acc: 89.504

Epoch 64: Validation loss decreased (0.263104 --> 0.262769).  Saving model ...
	 Train_Loss: 0.3138 Train_Acc: 87.789 Val_Loss: 0.2628  BEST VAL Loss: 0.2628  Val_Acc: 89.742

Epoch 65: Validation loss decreased (0.262769 --> 0.262692).  Saving model ...
	 Train_Loss: 0.3135 Train_Acc: 87.800 Val_Loss: 0.2627  BEST VAL Loss: 0.2627  Val_Acc: 89.690

Epoch 66: Validation loss decreased (0.262692 --> 0.262417).  Saving model ...
	 Train_Loss: 0.3133 Train_Acc: 87.387 Val_Loss: 0.2624  BEST VAL Loss: 0.2624  Val_Acc: 89.904

Epoch 67: Validation loss decreased (0.262417 --> 0.262287).  Saving model ...
	 Train_Loss: 0.3131 Train_Acc: 87.574 Val_Loss: 0.2623  BEST VAL Loss: 0.2623  Val_Acc: 89.486

Epoch 68: Validation loss decreased (0.262287 --> 0.262131).  Saving model ...
	 Train_Loss: 0.3129 Train_Acc: 87.822 Val_Loss: 0.2621  BEST VAL Loss: 0.2621  Val_Acc: 89.171

Epoch 69: Validation loss decreased (0.262131 --> 0.261834).  Saving model ...
	 Train_Loss: 0.3126 Train_Acc: 87.838 Val_Loss: 0.2618  BEST VAL Loss: 0.2618  Val_Acc: 89.926

Epoch 70: Validation loss decreased (0.261834 --> 0.261566).  Saving model ...
	 Train_Loss: 0.3124 Train_Acc: 87.775 Val_Loss: 0.2616  BEST VAL Loss: 0.2616  Val_Acc: 89.803

Epoch 71: Validation loss decreased (0.261566 --> 0.261421).  Saving model ...
	 Train_Loss: 0.3122 Train_Acc: 87.799 Val_Loss: 0.2614  BEST VAL Loss: 0.2614  Val_Acc: 89.330

Epoch 72: Validation loss decreased (0.261421 --> 0.261232).  Saving model ...
	 Train_Loss: 0.3119 Train_Acc: 87.956 Val_Loss: 0.2612  BEST VAL Loss: 0.2612  Val_Acc: 89.874

Epoch 73: Validation loss decreased (0.261232 --> 0.261085).  Saving model ...
	 Train_Loss: 0.3117 Train_Acc: 87.836 Val_Loss: 0.2611  BEST VAL Loss: 0.2611  Val_Acc: 89.513

Epoch 74: Validation loss decreased (0.261085 --> 0.260868).  Saving model ...
	 Train_Loss: 0.3115 Train_Acc: 87.879 Val_Loss: 0.2609  BEST VAL Loss: 0.2609  Val_Acc: 89.565

Epoch 75: Validation loss decreased (0.260868 --> 0.260761).  Saving model ...
	 Train_Loss: 0.3113 Train_Acc: 87.762 Val_Loss: 0.2608  BEST VAL Loss: 0.2608  Val_Acc: 89.886

Epoch 76: Validation loss decreased (0.260761 --> 0.260727).  Saving model ...
	 Train_Loss: 0.3111 Train_Acc: 87.782 Val_Loss: 0.2607  BEST VAL Loss: 0.2607  Val_Acc: 89.687

Epoch 77: Validation loss decreased (0.260727 --> 0.260592).  Saving model ...
	 Train_Loss: 0.3109 Train_Acc: 87.792 Val_Loss: 0.2606  BEST VAL Loss: 0.2606  Val_Acc: 89.412

Epoch 78: Validation loss decreased (0.260592 --> 0.260419).  Saving model ...
	 Train_Loss: 0.3107 Train_Acc: 87.697 Val_Loss: 0.2604  BEST VAL Loss: 0.2604  Val_Acc: 89.742

Epoch 79: Validation loss decreased (0.260419 --> 0.260175).  Saving model ...
	 Train_Loss: 0.3105 Train_Acc: 87.938 Val_Loss: 0.2602  BEST VAL Loss: 0.2602  Val_Acc: 89.779

Epoch 80: Validation loss decreased (0.260175 --> 0.260068).  Saving model ...
	 Train_Loss: 0.3104 Train_Acc: 87.987 Val_Loss: 0.2601  BEST VAL Loss: 0.2601  Val_Acc: 89.837

Epoch 81: Validation loss decreased (0.260068 --> 0.260019).  Saving model ...
	 Train_Loss: 0.3102 Train_Acc: 87.851 Val_Loss: 0.2600  BEST VAL Loss: 0.2600  Val_Acc: 89.623

Epoch 82: Validation loss decreased (0.260019 --> 0.259830).  Saving model ...
	 Train_Loss: 0.3100 Train_Acc: 87.796 Val_Loss: 0.2598  BEST VAL Loss: 0.2598  Val_Acc: 89.752

Epoch 83: Validation loss decreased (0.259830 --> 0.259701).  Saving model ...
	 Train_Loss: 0.3098 Train_Acc: 87.866 Val_Loss: 0.2597  BEST VAL Loss: 0.2597  Val_Acc: 89.871

Epoch 84: Validation loss decreased (0.259701 --> 0.259554).  Saving model ...
	 Train_Loss: 0.3097 Train_Acc: 87.850 Val_Loss: 0.2596  BEST VAL Loss: 0.2596  Val_Acc: 89.580

Epoch 85: Validation loss decreased (0.259554 --> 0.259361).  Saving model ...
	 Train_Loss: 0.3095 Train_Acc: 87.820 Val_Loss: 0.2594  BEST VAL Loss: 0.2594  Val_Acc: 89.657

Epoch 86: Validation loss decreased (0.259361 --> 0.259211).  Saving model ...
	 Train_Loss: 0.3093 Train_Acc: 87.971 Val_Loss: 0.2592  BEST VAL Loss: 0.2592  Val_Acc: 89.623

Epoch 87: Validation loss decreased (0.259211 --> 0.259034).  Saving model ...
	 Train_Loss: 0.3092 Train_Acc: 87.845 Val_Loss: 0.2590  BEST VAL Loss: 0.2590  Val_Acc: 89.816

Epoch 88: Validation loss decreased (0.259034 --> 0.258874).  Saving model ...
	 Train_Loss: 0.3090 Train_Acc: 87.746 Val_Loss: 0.2589  BEST VAL Loss: 0.2589  Val_Acc: 89.898

Epoch 89: Validation loss decreased (0.258874 --> 0.258786).  Saving model ...
	 Train_Loss: 0.3089 Train_Acc: 87.887 Val_Loss: 0.2588  BEST VAL Loss: 0.2588  Val_Acc: 89.281

Epoch 90: Validation loss decreased (0.258786 --> 0.258687).  Saving model ...
	 Train_Loss: 0.3087 Train_Acc: 87.699 Val_Loss: 0.2587  BEST VAL Loss: 0.2587  Val_Acc: 89.739

Epoch 91: Validation loss decreased (0.258687 --> 0.258549).  Saving model ...
	 Train_Loss: 0.3086 Train_Acc: 87.798 Val_Loss: 0.2585  BEST VAL Loss: 0.2585  Val_Acc: 89.522

Epoch 92: Validation loss decreased (0.258549 --> 0.258441).  Saving model ...
	 Train_Loss: 0.3084 Train_Acc: 87.804 Val_Loss: 0.2584  BEST VAL Loss: 0.2584  Val_Acc: 89.489

Epoch 93: Validation loss decreased (0.258441 --> 0.258325).  Saving model ...
	 Train_Loss: 0.3082 Train_Acc: 87.965 Val_Loss: 0.2583  BEST VAL Loss: 0.2583  Val_Acc: 89.479

Epoch 94: Validation loss decreased (0.258325 --> 0.258265).  Saving model ...
	 Train_Loss: 0.3081 Train_Acc: 87.926 Val_Loss: 0.2583  BEST VAL Loss: 0.2583  Val_Acc: 89.901

Epoch 95: Validation loss decreased (0.258265 --> 0.258138).  Saving model ...
	 Train_Loss: 0.3079 Train_Acc: 87.992 Val_Loss: 0.2581  BEST VAL Loss: 0.2581  Val_Acc: 89.868

Epoch 96: Validation loss decreased (0.258138 --> 0.258118).  Saving model ...
	 Train_Loss: 0.3078 Train_Acc: 87.961 Val_Loss: 0.2581  BEST VAL Loss: 0.2581  Val_Acc: 89.519

Epoch 97: Validation loss decreased (0.258118 --> 0.258008).  Saving model ...
	 Train_Loss: 0.3076 Train_Acc: 87.933 Val_Loss: 0.2580  BEST VAL Loss: 0.2580  Val_Acc: 89.675

Epoch 98: Validation loss decreased (0.258008 --> 0.257902).  Saving model ...
	 Train_Loss: 0.3075 Train_Acc: 87.635 Val_Loss: 0.2579  BEST VAL Loss: 0.2579  Val_Acc: 89.489

Epoch 99: Validation loss decreased (0.257902 --> 0.257828).  Saving model ...
	 Train_Loss: 0.3074 Train_Acc: 87.749 Val_Loss: 0.2578  BEST VAL Loss: 0.2578  Val_Acc: 89.275

H2O2_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.91      0.92    169562
           1       0.85      0.88      0.86     92173

    accuracy                           0.90    261735
   macro avg       0.89      0.90      0.89    261735
weighted avg       0.90      0.90      0.90    261735

H2O2_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.92      0.91      0.92     21195
           1       0.84      0.86      0.85     11522

    accuracy                           0.89     32717
   macro avg       0.88      0.89      0.88     32717
weighted avg       0.89      0.89      0.89     32717

H2O2_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.91      0.92     21195
           1       0.84      0.87      0.86     11522

    accuracy                           0.90     32717
   macro avg       0.88      0.89      0.89     32717
weighted avg       0.90      0.90      0.90     32717

              precision    recall  f1-score   support

           0       0.93      0.91      0.92     21195
           1       0.84      0.87      0.86     11522

    accuracy                           0.90     32717
   macro avg       0.88      0.89      0.89     32717
weighted avg       0.90      0.90      0.90     32717

H2O2_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.59      0.77      0.67     28584
           1       0.80      0.63      0.70     41273

    accuracy                           0.69     69857
   macro avg       0.70      0.70      0.69     69857
weighted avg       0.71      0.69      0.69     69857

              precision    recall  f1-score   support

           0       0.59      0.77      0.67     28584
           1       0.80      0.63      0.70     41273

    accuracy                           0.69     69857
   macro avg       0.70      0.70      0.69     69857
weighted avg       0.71      0.69      0.69     69857

completed
