[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 18688 bytes to train_binary_model.py
[NbConvertApp] Converting notebook ../notebooks/train_multiclass_model.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: MissingIDFieldWarning: Code cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.
  validate(nb)
[NbConvertApp] Writing 31106 bytes to train_multiclass_model.py
[NbConvertApp] Converting notebook ../notebooks/train_regression_model.ipynb to script
[NbConvertApp] Writing 25120 bytes to train_regression_model.py
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:313: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels.drop_duplicates(inplace=True)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1015: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1016: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1015: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1016: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1036: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:577: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:651: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1219: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:879: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1219: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:1095: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
PBMC MultiClass_MLP True
[0.9436581681188537, 0.5245113046249099, 0.5318305272562364]
Data Subset Is Off
(1483474,) (370869,) (2207496,) (1536843,)
(1483474,) (370869,) (2207496,) (1536843,)
5598682
(95928,) (749319,) (638227,)
(23982,) (187329,) (159558,)
(119911,) (936644,) (1150941,)
(75619,) (788818,) (672406,)
(1483474, 1245) (370869, 1245) (2207496, 1245) (1536843, 1245)
(1483474,) (370869,) (2207496,) (1536843,)
Number of in features:  1245
Number of out features:  3
Multi_Class
Adam
Epoch 0: Validation loss decreased (inf --> 0.791172).  Saving model ...
	 Train_Loss: 0.8268 Train_Acc: 65.822 Val_Loss: 0.7912  BEST VAL Loss: 0.7912  Val_Acc: 67.536

Epoch 1: Validation loss decreased (0.791172 --> 0.767466).  Saving model ...
	 Train_Loss: 0.8193 Train_Acc: 65.441 Val_Loss: 0.7675  BEST VAL Loss: 0.7675  Val_Acc: 69.607

Epoch 2: Validation loss decreased (0.767466 --> 0.749339).  Saving model ...
	 Train_Loss: 0.8085 Train_Acc: 66.695 Val_Loss: 0.7493  BEST VAL Loss: 0.7493  Val_Acc: 70.235

Epoch 3: Validation loss decreased (0.749339 --> 0.738495).  Saving model ...
	 Train_Loss: 0.7999 Train_Acc: 67.272 Val_Loss: 0.7385  BEST VAL Loss: 0.7385  Val_Acc: 70.426

Epoch 4: Validation loss decreased (0.738495 --> 0.735338).  Saving model ...
	 Train_Loss: 0.7936 Train_Acc: 67.716 Val_Loss: 0.7353  BEST VAL Loss: 0.7353  Val_Acc: 70.926

Epoch 5: Validation loss decreased (0.735338 --> 0.728109).  Saving model ...
	 Train_Loss: 0.7902 Train_Acc: 68.031 Val_Loss: 0.7281  BEST VAL Loss: 0.7281  Val_Acc: 71.578

Epoch 6: Validation loss decreased (0.728109 --> 0.723741).  Saving model ...
	 Train_Loss: 0.7872 Train_Acc: 68.402 Val_Loss: 0.7237  BEST VAL Loss: 0.7237  Val_Acc: 72.597

Epoch 7: Validation loss decreased (0.723741 --> 0.717978).  Saving model ...
	 Train_Loss: 0.7846 Train_Acc: 68.757 Val_Loss: 0.7180  BEST VAL Loss: 0.7180  Val_Acc: 72.981

Epoch 8: Validation loss decreased (0.717978 --> 0.713704).  Saving model ...
	 Train_Loss: 0.7821 Train_Acc: 68.810 Val_Loss: 0.7137  BEST VAL Loss: 0.7137  Val_Acc: 73.167

Epoch 9: Validation loss decreased (0.713704 --> 0.708727).  Saving model ...
	 Train_Loss: 0.7798 Train_Acc: 69.018 Val_Loss: 0.7087  BEST VAL Loss: 0.7087  Val_Acc: 72.536

Epoch 10: Validation loss decreased (0.708727 --> 0.705306).  Saving model ...
	 Train_Loss: 0.7776 Train_Acc: 69.171 Val_Loss: 0.7053  BEST VAL Loss: 0.7053  Val_Acc: 73.953

Epoch 11: Validation loss decreased (0.705306 --> 0.702488).  Saving model ...
	 Train_Loss: 0.7757 Train_Acc: 69.336 Val_Loss: 0.7025  BEST VAL Loss: 0.7025  Val_Acc: 73.553

Epoch 12: Validation loss decreased (0.702488 --> 0.699767).  Saving model ...
	 Train_Loss: 0.7738 Train_Acc: 69.395 Val_Loss: 0.6998  BEST VAL Loss: 0.6998  Val_Acc: 73.422

Epoch 13: Validation loss decreased (0.699767 --> 0.697820).  Saving model ...
	 Train_Loss: 0.7729 Train_Acc: 70.425 Val_Loss: 0.6978  BEST VAL Loss: 0.6978  Val_Acc: 75.818

Epoch 14: Validation loss decreased (0.697820 --> 0.695336).  Saving model ...
	 Train_Loss: 0.7715 Train_Acc: 71.140 Val_Loss: 0.6953  BEST VAL Loss: 0.6953  Val_Acc: 75.720

Epoch 15: Validation loss decreased (0.695336 --> 0.694191).  Saving model ...
	 Train_Loss: 0.7701 Train_Acc: 71.353 Val_Loss: 0.6942  BEST VAL Loss: 0.6942  Val_Acc: 75.482

Epoch 16: Validation loss decreased (0.694191 --> 0.693865).  Saving model ...
	 Train_Loss: 0.7688 Train_Acc: 71.434 Val_Loss: 0.6939  BEST VAL Loss: 0.6939  Val_Acc: 75.394

Epoch 17: Validation loss decreased (0.693865 --> 0.693154).  Saving model ...
	 Train_Loss: 0.7675 Train_Acc: 71.521 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 75.344

Epoch 18: Validation loss decreased (0.693154 --> 0.691878).  Saving model ...
	 Train_Loss: 0.7663 Train_Acc: 71.595 Val_Loss: 0.6919  BEST VAL Loss: 0.6919  Val_Acc: 75.649

Epoch 19: Validation loss decreased (0.691878 --> 0.690066).  Saving model ...
	 Train_Loss: 0.7651 Train_Acc: 71.716 Val_Loss: 0.6901  BEST VAL Loss: 0.6901  Val_Acc: 76.744

Epoch 20: Validation loss decreased (0.690066 --> 0.688687).  Saving model ...
	 Train_Loss: 0.7640 Train_Acc: 71.713 Val_Loss: 0.6887  BEST VAL Loss: 0.6887  Val_Acc: 76.191

Epoch 21: Validation loss decreased (0.688687 --> 0.687720).  Saving model ...
	 Train_Loss: 0.7630 Train_Acc: 71.796 Val_Loss: 0.6877  BEST VAL Loss: 0.6877  Val_Acc: 76.048

Epoch 22: Validation loss decreased (0.687720 --> 0.686732).  Saving model ...
	 Train_Loss: 0.7619 Train_Acc: 71.894 Val_Loss: 0.6867  BEST VAL Loss: 0.6867  Val_Acc: 76.082

Epoch 23: Validation loss decreased (0.686732 --> 0.685584).  Saving model ...
	 Train_Loss: 0.7609 Train_Acc: 71.901 Val_Loss: 0.6856  BEST VAL Loss: 0.6856  Val_Acc: 76.381

Epoch 24: Validation loss decreased (0.685584 --> 0.684716).  Saving model ...
	 Train_Loss: 0.7599 Train_Acc: 72.007 Val_Loss: 0.6847  BEST VAL Loss: 0.6847  Val_Acc: 75.281

Epoch 25: Validation loss decreased (0.684716 --> 0.683388).  Saving model ...
	 Train_Loss: 0.7590 Train_Acc: 72.005 Val_Loss: 0.6834  BEST VAL Loss: 0.6834  Val_Acc: 76.888

Epoch 26: Validation loss decreased (0.683388 --> 0.682194).  Saving model ...
	 Train_Loss: 0.7581 Train_Acc: 72.119 Val_Loss: 0.6822  BEST VAL Loss: 0.6822  Val_Acc: 77.117

Epoch 27: Validation loss decreased (0.682194 --> 0.680856).  Saving model ...
	 Train_Loss: 0.7573 Train_Acc: 72.146 Val_Loss: 0.6809  BEST VAL Loss: 0.6809  Val_Acc: 76.968

Epoch 28: Validation loss decreased (0.680856 --> 0.680413).  Saving model ...
	 Train_Loss: 0.7565 Train_Acc: 72.102 Val_Loss: 0.6804  BEST VAL Loss: 0.6804  Val_Acc: 76.206

Epoch 29: Validation loss decreased (0.680413 --> 0.679278).  Saving model ...
	 Train_Loss: 0.7558 Train_Acc: 72.140 Val_Loss: 0.6793  BEST VAL Loss: 0.6793  Val_Acc: 76.865

Epoch 30: Validation loss decreased (0.679278 --> 0.678185).  Saving model ...
	 Train_Loss: 0.7550 Train_Acc: 72.208 Val_Loss: 0.6782  BEST VAL Loss: 0.6782  Val_Acc: 76.174

Epoch 31: Validation loss decreased (0.678185 --> 0.677571).  Saving model ...
	 Train_Loss: 0.7543 Train_Acc: 72.175 Val_Loss: 0.6776  BEST VAL Loss: 0.6776  Val_Acc: 76.459

Epoch 32: Validation loss decreased (0.677571 --> 0.676288).  Saving model ...
	 Train_Loss: 0.7536 Train_Acc: 72.272 Val_Loss: 0.6763  BEST VAL Loss: 0.6763  Val_Acc: 77.428

Epoch 33: Validation loss decreased (0.676288 --> 0.675427).  Saving model ...
	 Train_Loss: 0.7530 Train_Acc: 72.245 Val_Loss: 0.6754  BEST VAL Loss: 0.6754  Val_Acc: 76.344

Epoch 34: Validation loss decreased (0.675427 --> 0.674576).  Saving model ...
	 Train_Loss: 0.7523 Train_Acc: 72.320 Val_Loss: 0.6746  BEST VAL Loss: 0.6746  Val_Acc: 77.008

Epoch 35: Validation loss decreased (0.674576 --> 0.674335).  Saving model ...
	 Train_Loss: 0.7518 Train_Acc: 72.314 Val_Loss: 0.6743  BEST VAL Loss: 0.6743  Val_Acc: 75.486

Epoch 36: Validation loss decreased (0.674335 --> 0.673241).  Saving model ...
	 Train_Loss: 0.7512 Train_Acc: 72.296 Val_Loss: 0.6732  BEST VAL Loss: 0.6732  Val_Acc: 77.521

Epoch 37: Validation loss decreased (0.673241 --> 0.672361).  Saving model ...
	 Train_Loss: 0.7506 Train_Acc: 72.456 Val_Loss: 0.6724  BEST VAL Loss: 0.6724  Val_Acc: 77.473

Epoch 38: Validation loss decreased (0.672361 --> 0.671723).  Saving model ...
	 Train_Loss: 0.7501 Train_Acc: 72.365 Val_Loss: 0.6717  BEST VAL Loss: 0.6717  Val_Acc: 77.143

Epoch 39: Validation loss decreased (0.671723 --> 0.670870).  Saving model ...
	 Train_Loss: 0.7496 Train_Acc: 72.482 Val_Loss: 0.6709  BEST VAL Loss: 0.6709  Val_Acc: 77.645

Epoch 40: Validation loss decreased (0.670870 --> 0.670474).  Saving model ...
	 Train_Loss: 0.7491 Train_Acc: 72.449 Val_Loss: 0.6705  BEST VAL Loss: 0.6705  Val_Acc: 76.704

Epoch 41: Validation loss decreased (0.670474 --> 0.669608).  Saving model ...
	 Train_Loss: 0.7486 Train_Acc: 72.417 Val_Loss: 0.6696  BEST VAL Loss: 0.6696  Val_Acc: 77.544

Epoch 42: Validation loss decreased (0.669608 --> 0.668835).  Saving model ...
	 Train_Loss: 0.7481 Train_Acc: 72.483 Val_Loss: 0.6688  BEST VAL Loss: 0.6688  Val_Acc: 77.353

Epoch 43: Validation loss decreased (0.668835 --> 0.668033).  Saving model ...
	 Train_Loss: 0.7476 Train_Acc: 72.545 Val_Loss: 0.6680  BEST VAL Loss: 0.6680  Val_Acc: 77.651

Epoch 44: Validation loss decreased (0.668033 --> 0.667330).  Saving model ...
	 Train_Loss: 0.7471 Train_Acc: 72.518 Val_Loss: 0.6673  BEST VAL Loss: 0.6673  Val_Acc: 76.695

Epoch 45: Validation loss decreased (0.667330 --> 0.666689).  Saving model ...
	 Train_Loss: 0.7467 Train_Acc: 72.551 Val_Loss: 0.6667  BEST VAL Loss: 0.6667  Val_Acc: 77.877

Epoch 46: Validation loss decreased (0.666689 --> 0.666350).  Saving model ...
	 Train_Loss: 0.7463 Train_Acc: 72.539 Val_Loss: 0.6663  BEST VAL Loss: 0.6663  Val_Acc: 77.063

Epoch 47: Validation loss decreased (0.666350 --> 0.666080).  Saving model ...
	 Train_Loss: 0.7458 Train_Acc: 72.612 Val_Loss: 0.6661  BEST VAL Loss: 0.6661  Val_Acc: 75.276

Epoch 48: Validation loss decreased (0.666080 --> 0.665654).  Saving model ...
	 Train_Loss: 0.7454 Train_Acc: 72.637 Val_Loss: 0.6657  BEST VAL Loss: 0.6657  Val_Acc: 75.862

Epoch 49: Validation loss decreased (0.665654 --> 0.665484).  Saving model ...
	 Train_Loss: 0.7450 Train_Acc: 72.644 Val_Loss: 0.6655  BEST VAL Loss: 0.6655  Val_Acc: 76.546

Epoch 50: Validation loss decreased (0.665484 --> 0.664863).  Saving model ...
	 Train_Loss: 0.7447 Train_Acc: 72.627 Val_Loss: 0.6649  BEST VAL Loss: 0.6649  Val_Acc: 77.710

Epoch 51: Validation loss decreased (0.664863 --> 0.664306).  Saving model ...
	 Train_Loss: 0.7443 Train_Acc: 72.633 Val_Loss: 0.6643  BEST VAL Loss: 0.6643  Val_Acc: 76.435

Epoch 52: Validation loss decreased (0.664306 --> 0.664198).  Saving model ...
	 Train_Loss: 0.7439 Train_Acc: 72.729 Val_Loss: 0.6642  BEST VAL Loss: 0.6642  Val_Acc: 75.508

Epoch 53: Validation loss decreased (0.664198 --> 0.663805).  Saving model ...
	 Train_Loss: 0.7435 Train_Acc: 72.743 Val_Loss: 0.6638  BEST VAL Loss: 0.6638  Val_Acc: 77.071

Epoch 54: Validation loss decreased (0.663805 --> 0.663690).  Saving model ...
	 Train_Loss: 0.7432 Train_Acc: 72.700 Val_Loss: 0.6637  BEST VAL Loss: 0.6637  Val_Acc: 76.286

Epoch 55: Validation loss decreased (0.663690 --> 0.663084).  Saving model ...
	 Train_Loss: 0.7428 Train_Acc: 72.737 Val_Loss: 0.6631  BEST VAL Loss: 0.6631  Val_Acc: 77.960

Epoch 56: Validation loss decreased (0.663084 --> 0.662461).  Saving model ...
	 Train_Loss: 0.7425 Train_Acc: 72.717 Val_Loss: 0.6625  BEST VAL Loss: 0.6625  Val_Acc: 78.059

Epoch 57: Validation loss decreased (0.662461 --> 0.661893).  Saving model ...
	 Train_Loss: 0.7422 Train_Acc: 72.711 Val_Loss: 0.6619  BEST VAL Loss: 0.6619  Val_Acc: 77.602

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.7418 Train_Acc: 72.762 Val_Loss: 0.6619  BEST VAL Loss: 0.6619  Val_Acc: 76.613

Epoch 59: Validation loss decreased (0.661893 --> 0.661667).  Saving model ...
	 Train_Loss: 0.7415 Train_Acc: 72.797 Val_Loss: 0.6617  BEST VAL Loss: 0.6617  Val_Acc: 77.807

Epoch 60: Validation loss decreased (0.661667 --> 0.661242).  Saving model ...
	 Train_Loss: 0.7412 Train_Acc: 72.753 Val_Loss: 0.6612  BEST VAL Loss: 0.6612  Val_Acc: 76.395

Epoch 61: Validation loss decreased (0.661242 --> 0.660989).  Saving model ...
	 Train_Loss: 0.7409 Train_Acc: 72.785 Val_Loss: 0.6610  BEST VAL Loss: 0.6610  Val_Acc: 77.553

Epoch 62: Validation loss decreased (0.660989 --> 0.660759).  Saving model ...
	 Train_Loss: 0.7406 Train_Acc: 72.812 Val_Loss: 0.6608  BEST VAL Loss: 0.6608  Val_Acc: 77.092

Epoch 63: Validation loss decreased (0.660759 --> 0.660304).  Saving model ...
	 Train_Loss: 0.7403 Train_Acc: 72.831 Val_Loss: 0.6603  BEST VAL Loss: 0.6603  Val_Acc: 77.793

Epoch 64: Validation loss decreased (0.660304 --> 0.659835).  Saving model ...
	 Train_Loss: 0.7400 Train_Acc: 72.830 Val_Loss: 0.6598  BEST VAL Loss: 0.6598  Val_Acc: 78.157

Epoch 65: Validation loss decreased (0.659835 --> 0.659743).  Saving model ...
	 Train_Loss: 0.7397 Train_Acc: 72.819 Val_Loss: 0.6597  BEST VAL Loss: 0.6597  Val_Acc: 76.965

Epoch 66: Validation loss decreased (0.659743 --> 0.659463).  Saving model ...
	 Train_Loss: 0.7395 Train_Acc: 72.879 Val_Loss: 0.6595  BEST VAL Loss: 0.6595  Val_Acc: 77.842

Epoch 67: Validation loss decreased (0.659463 --> 0.659067).  Saving model ...
	 Train_Loss: 0.7392 Train_Acc: 72.906 Val_Loss: 0.6591  BEST VAL Loss: 0.6591  Val_Acc: 77.743

Epoch 68: Validation loss decreased (0.659067 --> 0.658704).  Saving model ...
	 Train_Loss: 0.7389 Train_Acc: 72.880 Val_Loss: 0.6587  BEST VAL Loss: 0.6587  Val_Acc: 77.813

Epoch 69: Validation loss decreased (0.658704 --> 0.658414).  Saving model ...
	 Train_Loss: 0.7387 Train_Acc: 72.881 Val_Loss: 0.6584  BEST VAL Loss: 0.6584  Val_Acc: 77.935

Epoch 70: Validation loss decreased (0.658414 --> 0.658200).  Saving model ...
	 Train_Loss: 0.7385 Train_Acc: 72.860 Val_Loss: 0.6582  BEST VAL Loss: 0.6582  Val_Acc: 76.194

Epoch 71: Validation loss decreased (0.658200 --> 0.657779).  Saving model ...
	 Train_Loss: 0.7382 Train_Acc: 72.903 Val_Loss: 0.6578  BEST VAL Loss: 0.6578  Val_Acc: 77.212

Epoch 72: Validation loss decreased (0.657779 --> 0.657591).  Saving model ...
	 Train_Loss: 0.7380 Train_Acc: 72.921 Val_Loss: 0.6576  BEST VAL Loss: 0.6576  Val_Acc: 77.250

Epoch 73: Validation loss decreased (0.657591 --> 0.657390).  Saving model ...
	 Train_Loss: 0.7377 Train_Acc: 72.881 Val_Loss: 0.6574  BEST VAL Loss: 0.6574  Val_Acc: 77.113

Epoch 74: Validation loss decreased (0.657390 --> 0.657186).  Saving model ...
	 Train_Loss: 0.7375 Train_Acc: 72.894 Val_Loss: 0.6572  BEST VAL Loss: 0.6572  Val_Acc: 77.679

Epoch 75: Validation loss decreased (0.657186 --> 0.656711).  Saving model ...
	 Train_Loss: 0.7373 Train_Acc: 72.900 Val_Loss: 0.6567  BEST VAL Loss: 0.6567  Val_Acc: 78.212

Epoch 76: Validation loss decreased (0.656711 --> 0.656395).  Saving model ...
	 Train_Loss: 0.7371 Train_Acc: 72.880 Val_Loss: 0.6564  BEST VAL Loss: 0.6564  Val_Acc: 78.168

Epoch 77: Validation loss decreased (0.656395 --> 0.656054).  Saving model ...
	 Train_Loss: 0.7368 Train_Acc: 72.975 Val_Loss: 0.6561  BEST VAL Loss: 0.6561  Val_Acc: 78.281

Epoch 78: Validation loss decreased (0.656054 --> 0.655700).  Saving model ...
	 Train_Loss: 0.7366 Train_Acc: 72.969 Val_Loss: 0.6557  BEST VAL Loss: 0.6557  Val_Acc: 77.772

Epoch 79: Validation loss decreased (0.655700 --> 0.655514).  Saving model ...
	 Train_Loss: 0.7364 Train_Acc: 72.956 Val_Loss: 0.6555  BEST VAL Loss: 0.6555  Val_Acc: 77.422

Epoch 80: Validation loss decreased (0.655514 --> 0.655340).  Saving model ...
	 Train_Loss: 0.7362 Train_Acc: 72.970 Val_Loss: 0.6553  BEST VAL Loss: 0.6553  Val_Acc: 77.940

Epoch 81: Validation loss decreased (0.655340 --> 0.655157).  Saving model ...
	 Train_Loss: 0.7360 Train_Acc: 73.009 Val_Loss: 0.6552  BEST VAL Loss: 0.6552  Val_Acc: 77.553

Epoch 82: Validation loss decreased (0.655157 --> 0.654910).  Saving model ...
	 Train_Loss: 0.7358 Train_Acc: 72.993 Val_Loss: 0.6549  BEST VAL Loss: 0.6549  Val_Acc: 78.140

Epoch 83: Validation loss decreased (0.654910 --> 0.654628).  Saving model ...
	 Train_Loss: 0.7356 Train_Acc: 72.934 Val_Loss: 0.6546  BEST VAL Loss: 0.6546  Val_Acc: 76.953

Epoch 84: Validation loss decreased (0.654628 --> 0.654352).  Saving model ...
	 Train_Loss: 0.7354 Train_Acc: 72.965 Val_Loss: 0.6544  BEST VAL Loss: 0.6544  Val_Acc: 78.060

Epoch 85: Validation loss decreased (0.654352 --> 0.654339).  Saving model ...
	 Train_Loss: 0.7352 Train_Acc: 73.030 Val_Loss: 0.6543  BEST VAL Loss: 0.6543  Val_Acc: 75.378

Epoch 86: Validation loss decreased (0.654339 --> 0.654113).  Saving model ...
	 Train_Loss: 0.7350 Train_Acc: 73.019 Val_Loss: 0.6541  BEST VAL Loss: 0.6541  Val_Acc: 78.032

Epoch 87: Validation loss decreased (0.654113 --> 0.653949).  Saving model ...
	 Train_Loss: 0.7348 Train_Acc: 73.027 Val_Loss: 0.6539  BEST VAL Loss: 0.6539  Val_Acc: 77.970

Epoch 88: Validation loss decreased (0.653949 --> 0.653866).  Saving model ...
	 Train_Loss: 0.7347 Train_Acc: 72.981 Val_Loss: 0.6539  BEST VAL Loss: 0.6539  Val_Acc: 77.039

Epoch 89: Validation loss decreased (0.653866 --> 0.653716).  Saving model ...
	 Train_Loss: 0.7345 Train_Acc: 72.978 Val_Loss: 0.6537  BEST VAL Loss: 0.6537  Val_Acc: 77.741

Epoch 90: Validation loss decreased (0.653716 --> 0.653510).  Saving model ...
	 Train_Loss: 0.7343 Train_Acc: 72.971 Val_Loss: 0.6535  BEST VAL Loss: 0.6535  Val_Acc: 76.533

Epoch 91: Validation loss decreased (0.653510 --> 0.653395).  Saving model ...
	 Train_Loss: 0.7341 Train_Acc: 73.014 Val_Loss: 0.6534  BEST VAL Loss: 0.6534  Val_Acc: 77.644

Epoch 92: Validation loss decreased (0.653395 --> 0.653204).  Saving model ...
	 Train_Loss: 0.7340 Train_Acc: 73.016 Val_Loss: 0.6532  BEST VAL Loss: 0.6532  Val_Acc: 77.784

Epoch 93: Validation loss decreased (0.653204 --> 0.652990).  Saving model ...
	 Train_Loss: 0.7338 Train_Acc: 72.994 Val_Loss: 0.6530  BEST VAL Loss: 0.6530  Val_Acc: 76.886

Epoch 94: Validation loss decreased (0.652990 --> 0.652826).  Saving model ...
	 Train_Loss: 0.7336 Train_Acc: 73.047 Val_Loss: 0.6528  BEST VAL Loss: 0.6528  Val_Acc: 77.786

Epoch 95: Validation loss decreased (0.652826 --> 0.652525).  Saving model ...
	 Train_Loss: 0.7335 Train_Acc: 73.100 Val_Loss: 0.6525  BEST VAL Loss: 0.6525  Val_Acc: 78.144

Epoch 96: Validation loss decreased (0.652525 --> 0.652357).  Saving model ...
	 Train_Loss: 0.7333 Train_Acc: 73.067 Val_Loss: 0.6524  BEST VAL Loss: 0.6524  Val_Acc: 75.305

Epoch 97: Validation loss decreased (0.652357 --> 0.652241).  Saving model ...
	 Train_Loss: 0.7331 Train_Acc: 72.978 Val_Loss: 0.6522  BEST VAL Loss: 0.6522  Val_Acc: 77.603

Epoch 98: Validation loss decreased (0.652241 --> 0.652023).  Saving model ...
	 Train_Loss: 0.7330 Train_Acc: 73.080 Val_Loss: 0.6520  BEST VAL Loss: 0.6520  Val_Acc: 78.097

Epoch 99: Validation loss decreased (0.652023 --> 0.651833).  Saving model ...
	 Train_Loss: 0.7328 Train_Acc: 73.025 Val_Loss: 0.6518  BEST VAL Loss: 0.6518  Val_Acc: 78.143

MultiClass_MLP_shuffle
              precision    recall  f1-score   support

           0       0.06      0.03      0.04     95928
           1       0.51      0.58      0.54    749319
           2       0.43      0.39      0.41    638227

    accuracy                           0.46   1483474
   macro avg       0.33      0.33      0.33   1483474
weighted avg       0.44      0.46      0.45   1483474

MultiClass_MLP_shuffle
              precision    recall  f1-score   support

           0       0.07      0.03      0.04     23982
           1       0.51      0.49      0.50    187329
           2       0.43      0.48      0.46    159558

    accuracy                           0.46    370869
   macro avg       0.34      0.33      0.33    370869
weighted avg       0.45      0.46      0.45    370869

MultiClass_MLP_shuffle
              precision    recall  f1-score   support

           0       0.05      0.03      0.03    119911
           1       0.42      0.43      0.43    936644
           2       0.52      0.54      0.53   1150941

    accuracy                           0.47   2207496
   macro avg       0.33      0.33      0.33   2207496
weighted avg       0.45      0.47      0.46   2207496

Precision for class 0: 0.052995864237618345
Recall for class 0: 0.025860846794706075
Precision for class 1: 0.4240017067510329
Recall for class 1: 0.4349774300588057
Precision for class 2: 0.5211389353686415
Recall for class 2: 0.5379606773935415
3
              precision    recall  f1-score   support

           0       0.05      0.03      0.03    119911
           1       0.42      0.43      0.43    936644
           2       0.52      0.54      0.53   1150941

    accuracy                           0.47   2207496
   macro avg       0.33      0.33      0.33   2207496
weighted avg       0.45      0.47      0.46   2207496

MultiClass_MLP_shuffle
              precision    recall  f1-score   support

           0       0.04      0.00      0.01     75619
           1       0.51      0.42      0.46    788818
           2       0.44      0.58      0.50    672406

    accuracy                           0.47   1536843
   macro avg       0.33      0.33      0.32   1536843
weighted avg       0.46      0.47      0.45   1536843

Precision for class 0: 0.04284510771452642
Recall for class 0: 0.00470781152884857
Precision for class 1: 0.5138111235535647
Recall for class 1: 0.4188038305413923
Precision for class 2: 0.4377002938207309
Recall for class 2: 0.5764612451405847
3
              precision    recall  f1-score   support

           0       0.04      0.00      0.01     75619
           1       0.51      0.42      0.46    788818
           2       0.44      0.58      0.50    672406

    accuracy                           0.47   1536843
   macro avg       0.33      0.33      0.32   1536843
weighted avg       0.46      0.47      0.45   1536843

Done
