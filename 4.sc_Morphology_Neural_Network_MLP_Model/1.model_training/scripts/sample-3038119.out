[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '88bc7cd9'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'c1c9c56b'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '3da31e03'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '2a7a932f'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_100.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_100.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_100.000_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (30389, 1276)
Number of total missing values across all columns: 31974
Data Subset Is Off
Wells held out for testing: ['M16' 'J20']
Wells to use for training, validation, and testing ['J16' 'J17' 'M17' 'M20' 'J21' 'M21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.199762).  Saving model ...
	 Train_Loss: 0.4161 Train_Acc: 78.934 Val_Loss: 0.1998  BEST VAL Loss: 0.1998  Val_Acc: 91.405

Epoch 1: Validation loss decreased (0.199762 --> 0.153790).  Saving model ...
	 Train_Loss: 0.3013 Train_Acc: 92.492 Val_Loss: 0.1538  BEST VAL Loss: 0.1538  Val_Acc: 95.288

Epoch 2: Validation loss decreased (0.153790 --> 0.135103).  Saving model ...
	 Train_Loss: 0.2427 Train_Acc: 95.089 Val_Loss: 0.1351  BEST VAL Loss: 0.1351  Val_Acc: 96.335

Epoch 3: Validation loss decreased (0.135103 --> 0.125086).  Saving model ...
	 Train_Loss: 0.2065 Train_Acc: 96.372 Val_Loss: 0.1251  BEST VAL Loss: 0.1251  Val_Acc: 96.422

Epoch 4: Validation loss decreased (0.125086 --> 0.119632).  Saving model ...
	 Train_Loss: 0.1822 Train_Acc: 96.895 Val_Loss: 0.1196  BEST VAL Loss: 0.1196  Val_Acc: 96.684

Epoch 5: Validation loss decreased (0.119632 --> 0.115001).  Saving model ...
	 Train_Loss: 0.1648 Train_Acc: 97.032 Val_Loss: 0.1150  BEST VAL Loss: 0.1150  Val_Acc: 96.990

Epoch 6: Validation loss decreased (0.115001 --> 0.114085).  Saving model ...
	 Train_Loss: 0.1516 Train_Acc: 97.316 Val_Loss: 0.1141  BEST VAL Loss: 0.1141  Val_Acc: 96.859

Epoch 7: Validation loss decreased (0.114085 --> 0.110305).  Saving model ...
	 Train_Loss: 0.1418 Train_Acc: 97.136 Val_Loss: 0.1103  BEST VAL Loss: 0.1103  Val_Acc: 96.728

Epoch 8: Validation loss decreased (0.110305 --> 0.106780).  Saving model ...
	 Train_Loss: 0.1333 Train_Acc: 97.452 Val_Loss: 0.1068  BEST VAL Loss: 0.1068  Val_Acc: 97.077

Epoch 9: Validation loss decreased (0.106780 --> 0.103924).  Saving model ...
	 Train_Loss: 0.1264 Train_Acc: 97.708 Val_Loss: 0.1039  BEST VAL Loss: 0.1039  Val_Acc: 97.208

Epoch 10: Validation loss decreased (0.103924 --> 0.102275).  Saving model ...
	 Train_Loss: 0.1203 Train_Acc: 97.899 Val_Loss: 0.1023  BEST VAL Loss: 0.1023  Val_Acc: 96.815

Epoch 11: Validation loss decreased (0.102275 --> 0.102151).  Saving model ...
	 Train_Loss: 0.1153 Train_Acc: 97.763 Val_Loss: 0.1022  BEST VAL Loss: 0.1022  Val_Acc: 97.033

Epoch 12: Validation loss did not decrease
	 Train_Loss: 0.1109 Train_Acc: 97.992 Val_Loss: 0.1022  BEST VAL Loss: 0.1022  Val_Acc: 97.077

Epoch 13: Validation loss decreased (0.102151 --> 0.101707).  Saving model ...
	 Train_Loss: 0.1065 Train_Acc: 98.363 Val_Loss: 0.1017  BEST VAL Loss: 0.1017  Val_Acc: 97.906

Epoch 14: Validation loss decreased (0.101707 --> 0.101397).  Saving model ...
	 Train_Loss: 0.1026 Train_Acc: 98.243 Val_Loss: 0.1014  BEST VAL Loss: 0.1014  Val_Acc: 97.469

Epoch 15: Validation loss did not decrease
	 Train_Loss: 0.0990 Train_Acc: 98.434 Val_Loss: 0.1026  BEST VAL Loss: 0.1014  Val_Acc: 97.295

Epoch 16: Validation loss did not decrease
	 Train_Loss: 0.0961 Train_Acc: 98.254 Val_Loss: 0.1031  BEST VAL Loss: 0.1014  Val_Acc: 97.164

Epoch 17: Validation loss did not decrease
	 Train_Loss: 0.0934 Train_Acc: 98.238 Val_Loss: 0.1027  BEST VAL Loss: 0.1014  Val_Acc: 97.251

Epoch 18: Validation loss did not decrease
	 Train_Loss: 0.0909 Train_Acc: 98.352 Val_Loss: 0.1026  BEST VAL Loss: 0.1014  Val_Acc: 97.513

Epoch 19: Validation loss did not decrease
	 Train_Loss: 0.0885 Train_Acc: 98.418 Val_Loss: 0.1024  BEST VAL Loss: 0.1014  Val_Acc: 97.513

Epoch 20: Validation loss did not decrease
	 Train_Loss: 0.0865 Train_Acc: 98.500 Val_Loss: 0.1019  BEST VAL Loss: 0.1014  Val_Acc: 97.731

Epoch 21: Validation loss decreased (0.101397 --> 0.100958).  Saving model ...
	 Train_Loss: 0.0845 Train_Acc: 98.500 Val_Loss: 0.1010  BEST VAL Loss: 0.1010  Val_Acc: 98.037

Epoch 22: Validation loss decreased (0.100958 --> 0.100548).  Saving model ...
	 Train_Loss: 0.0824 Train_Acc: 98.734 Val_Loss: 0.1005  BEST VAL Loss: 0.1005  Val_Acc: 97.775

Epoch 23: Validation loss decreased (0.100548 --> 0.099926).  Saving model ...
	 Train_Loss: 0.0805 Train_Acc: 98.680 Val_Loss: 0.0999  BEST VAL Loss: 0.0999  Val_Acc: 97.731

Epoch 24: Validation loss decreased (0.099926 --> 0.098840).  Saving model ...
	 Train_Loss: 0.0788 Train_Acc: 98.712 Val_Loss: 0.0988  BEST VAL Loss: 0.0988  Val_Acc: 97.688

Epoch 25: Validation loss decreased (0.098840 --> 0.098029).  Saving model ...
	 Train_Loss: 0.0772 Train_Acc: 98.669 Val_Loss: 0.0980  BEST VAL Loss: 0.0980  Val_Acc: 97.862

Epoch 26: Validation loss decreased (0.098029 --> 0.097992).  Saving model ...
	 Train_Loss: 0.0757 Train_Acc: 98.832 Val_Loss: 0.0980  BEST VAL Loss: 0.0980  Val_Acc: 97.688

Epoch 27: Validation loss decreased (0.097992 --> 0.097759).  Saving model ...
	 Train_Loss: 0.0743 Train_Acc: 98.734 Val_Loss: 0.0978  BEST VAL Loss: 0.0978  Val_Acc: 97.775

Epoch 28: Validation loss decreased (0.097759 --> 0.097689).  Saving model ...
	 Train_Loss: 0.0729 Train_Acc: 98.931 Val_Loss: 0.0977  BEST VAL Loss: 0.0977  Val_Acc: 97.600

Epoch 29: Validation loss did not decrease
	 Train_Loss: 0.0714 Train_Acc: 99.083 Val_Loss: 0.0982  BEST VAL Loss: 0.0977  Val_Acc: 97.557

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.0701 Train_Acc: 99.045 Val_Loss: 0.0984  BEST VAL Loss: 0.0977  Val_Acc: 97.818

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.0690 Train_Acc: 98.898 Val_Loss: 0.0984  BEST VAL Loss: 0.0977  Val_Acc: 97.862

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.0680 Train_Acc: 98.865 Val_Loss: 0.0987  BEST VAL Loss: 0.0977  Val_Acc: 97.644

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.0670 Train_Acc: 98.789 Val_Loss: 0.0983  BEST VAL Loss: 0.0977  Val_Acc: 97.775

Epoch 34: Validation loss did not decrease
	 Train_Loss: 0.0660 Train_Acc: 98.991 Val_Loss: 0.0981  BEST VAL Loss: 0.0977  Val_Acc: 97.818

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.0650 Train_Acc: 99.062 Val_Loss: 0.0977  BEST VAL Loss: 0.0977  Val_Acc: 98.080

Epoch 36: Validation loss decreased (0.097689 --> 0.097655).  Saving model ...
	 Train_Loss: 0.0641 Train_Acc: 99.007 Val_Loss: 0.0977  BEST VAL Loss: 0.0977  Val_Acc: 97.775

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.0631 Train_Acc: 99.116 Val_Loss: 0.0977  BEST VAL Loss: 0.0977  Val_Acc: 97.949

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.0620 Train_Acc: 99.345 Val_Loss: 0.0979  BEST VAL Loss: 0.0977  Val_Acc: 97.949

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.0610 Train_Acc: 99.334 Val_Loss: 0.0981  BEST VAL Loss: 0.0977  Val_Acc: 97.862

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.0601 Train_Acc: 99.296 Val_Loss: 0.0983  BEST VAL Loss: 0.0977  Val_Acc: 98.473

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.0592 Train_Acc: 99.378 Val_Loss: 0.0986  BEST VAL Loss: 0.0977  Val_Acc: 98.124

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.0584 Train_Acc: 99.302 Val_Loss: 0.0988  BEST VAL Loss: 0.0977  Val_Acc: 97.993

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.0575 Train_Acc: 99.367 Val_Loss: 0.0990  BEST VAL Loss: 0.0977  Val_Acc: 98.298

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.0567 Train_Acc: 99.285 Val_Loss: 0.0992  BEST VAL Loss: 0.0977  Val_Acc: 97.818

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.0561 Train_Acc: 99.122 Val_Loss: 0.0996  BEST VAL Loss: 0.0977  Val_Acc: 97.775

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.0555 Train_Acc: 99.138 Val_Loss: 0.0995  BEST VAL Loss: 0.0977  Val_Acc: 98.124

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.0549 Train_Acc: 99.160 Val_Loss: 0.0997  BEST VAL Loss: 0.0977  Val_Acc: 97.818

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.0543 Train_Acc: 99.182 Val_Loss: 0.0996  BEST VAL Loss: 0.0977  Val_Acc: 98.124

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.0536 Train_Acc: 99.280 Val_Loss: 0.0998  BEST VAL Loss: 0.0977  Val_Acc: 98.080

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.0531 Train_Acc: 99.138 Val_Loss: 0.0999  BEST VAL Loss: 0.0977  Val_Acc: 98.080

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.0526 Train_Acc: 99.154 Val_Loss: 0.0999  BEST VAL Loss: 0.0977  Val_Acc: 98.037

Epoch 52: Validation loss did not decrease
Early stopped at epoch : 52
LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       1.00      0.99      1.00      9892
           1       0.99      1.00      1.00      8436

    accuracy                           1.00     18328
   macro avg       1.00      1.00      1.00     18328
weighted avg       1.00      1.00      1.00     18328

LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.98      0.98      1237
           1       0.97      0.98      0.98      1055

    accuracy                           0.98      2292
   macro avg       0.98      0.98      0.98      2292
weighted avg       0.98      0.98      0.98      2292

LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.98      0.98      1236
           1       0.98      0.98      0.98      1055

    accuracy                           0.98      2291
   macro avg       0.98      0.98      0.98      2291
weighted avg       0.98      0.98      0.98      2291

              precision    recall  f1-score   support

           0       0.98      0.98      0.98      1236
           1       0.98      0.98      0.98      1055

    accuracy                           0.98      2291
   macro avg       0.98      0.98      0.98      2291
weighted avg       0.98      0.98      0.98      2291

LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.96      0.93      0.94      3622
           1       0.94      0.96      0.95      3856

    accuracy                           0.95      7478
   macro avg       0.95      0.95      0.95      7478
weighted avg       0.95      0.95      0.95      7478

              precision    recall  f1-score   support

           0       0.96      0.93      0.94      3622
           1       0.94      0.96      0.95      3856

    accuracy                           0.95      7478
   macro avg       0.95      0.95      0.95      7478
weighted avg       0.95      0.95      0.95      7478

completed
