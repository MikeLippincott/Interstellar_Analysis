[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '37e7a688'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '3b70950a'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '6d702722'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '3923c768'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Flagellin_1.000_DMSO_0.025 treatment_name: Thapsigargin_10.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Flagellin_1.000_DMSO_0.025
TREATMENT_NAME: Thapsigargin_10.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (271531, 1270)
Number of total missing values across all columns: 579678
Data Subset Is Off
Wells held out for testing: ['L06' 'M10']
Wells to use for training, validation, and testing ['E06' 'E07' 'M05' 'L07' 'M11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.637027).  Saving model ...
	 Train_Loss: 0.6519 Train_Acc: 63.698 Val_Loss: 0.6370  BEST VAL Loss: 0.6370  Val_Acc: 64.438

Epoch 1: Validation loss decreased (0.637027 --> 0.578527).  Saving model ...
	 Train_Loss: 0.6271 Train_Acc: 69.165 Val_Loss: 0.5785  BEST VAL Loss: 0.5785  Val_Acc: 78.515

Epoch 2: Validation loss decreased (0.578527 --> 0.526435).  Saving model ...
	 Train_Loss: 0.5883 Train_Acc: 77.107 Val_Loss: 0.5264  BEST VAL Loss: 0.5264  Val_Acc: 83.853

Epoch 3: Validation loss decreased (0.526435 --> 0.490522).  Saving model ...
	 Train_Loss: 0.5572 Train_Acc: 80.001 Val_Loss: 0.4905  BEST VAL Loss: 0.4905  Val_Acc: 85.190

Epoch 4: Validation loss decreased (0.490522 --> 0.468629).  Saving model ...
	 Train_Loss: 0.5334 Train_Acc: 81.629 Val_Loss: 0.4686  BEST VAL Loss: 0.4686  Val_Acc: 84.971

Epoch 5: Validation loss decreased (0.468629 --> 0.446908).  Saving model ...
	 Train_Loss: 0.5140 Train_Acc: 82.800 Val_Loss: 0.4469  BEST VAL Loss: 0.4469  Val_Acc: 87.172

Epoch 6: Validation loss decreased (0.446908 --> 0.431335).  Saving model ...
	 Train_Loss: 0.4984 Train_Acc: 83.306 Val_Loss: 0.4313  BEST VAL Loss: 0.4313  Val_Acc: 87.036

Epoch 7: Validation loss decreased (0.431335 --> 0.422171).  Saving model ...
	 Train_Loss: 0.4850 Train_Acc: 84.044 Val_Loss: 0.4222  BEST VAL Loss: 0.4222  Val_Acc: 85.465

Epoch 8: Validation loss decreased (0.422171 --> 0.410427).  Saving model ...
	 Train_Loss: 0.4737 Train_Acc: 84.413 Val_Loss: 0.4104  BEST VAL Loss: 0.4104  Val_Acc: 87.775

Epoch 9: Validation loss decreased (0.410427 --> 0.400514).  Saving model ...
	 Train_Loss: 0.4639 Train_Acc: 84.717 Val_Loss: 0.4005  BEST VAL Loss: 0.4005  Val_Acc: 87.994

Epoch 10: Validation loss decreased (0.400514 --> 0.391002).  Saving model ...
	 Train_Loss: 0.4551 Train_Acc: 85.160 Val_Loss: 0.3910  BEST VAL Loss: 0.3910  Val_Acc: 88.706

Epoch 11: Validation loss decreased (0.391002 --> 0.384032).  Saving model ...
	 Train_Loss: 0.4474 Train_Acc: 85.446 Val_Loss: 0.3840  BEST VAL Loss: 0.3840  Val_Acc: 87.895

Epoch 12: Validation loss decreased (0.384032 --> 0.376613).  Saving model ...
	 Train_Loss: 0.4402 Train_Acc: 85.811 Val_Loss: 0.3766  BEST VAL Loss: 0.3766  Val_Acc: 89.055

Epoch 13: Validation loss decreased (0.376613 --> 0.369262).  Saving model ...
	 Train_Loss: 0.4337 Train_Acc: 86.178 Val_Loss: 0.3693  BEST VAL Loss: 0.3693  Val_Acc: 89.674

Epoch 14: Validation loss decreased (0.369262 --> 0.363008).  Saving model ...
	 Train_Loss: 0.4276 Train_Acc: 86.439 Val_Loss: 0.3630  BEST VAL Loss: 0.3630  Val_Acc: 89.643

Epoch 15: Validation loss decreased (0.363008 --> 0.357361).  Saving model ...
	 Train_Loss: 0.4222 Train_Acc: 86.603 Val_Loss: 0.3574  BEST VAL Loss: 0.3574  Val_Acc: 89.580

Epoch 16: Validation loss decreased (0.357361 --> 0.352165).  Saving model ...
	 Train_Loss: 0.4172 Train_Acc: 86.720 Val_Loss: 0.3522  BEST VAL Loss: 0.3522  Val_Acc: 89.877

Epoch 17: Validation loss decreased (0.352165 --> 0.347951).  Saving model ...
	 Train_Loss: 0.4125 Train_Acc: 86.916 Val_Loss: 0.3480  BEST VAL Loss: 0.3480  Val_Acc: 89.320

Epoch 18: Validation loss decreased (0.347951 --> 0.343380).  Saving model ...
	 Train_Loss: 0.4082 Train_Acc: 87.064 Val_Loss: 0.3434  BEST VAL Loss: 0.3434  Val_Acc: 90.080

Epoch 19: Validation loss decreased (0.343380 --> 0.339247).  Saving model ...
	 Train_Loss: 0.4041 Train_Acc: 87.319 Val_Loss: 0.3392  BEST VAL Loss: 0.3392  Val_Acc: 90.074

Epoch 20: Validation loss decreased (0.339247 --> 0.335589).  Saving model ...
	 Train_Loss: 0.4003 Train_Acc: 87.288 Val_Loss: 0.3356  BEST VAL Loss: 0.3356  Val_Acc: 89.939

Epoch 21: Validation loss decreased (0.335589 --> 0.332192).  Saving model ...
	 Train_Loss: 0.3968 Train_Acc: 87.339 Val_Loss: 0.3322  BEST VAL Loss: 0.3322  Val_Acc: 90.350

Epoch 22: Validation loss decreased (0.332192 --> 0.329410).  Saving model ...
	 Train_Loss: 0.3934 Train_Acc: 87.518 Val_Loss: 0.3294  BEST VAL Loss: 0.3294  Val_Acc: 89.955

Epoch 23: Validation loss decreased (0.329410 --> 0.326354).  Saving model ...
	 Train_Loss: 0.3903 Train_Acc: 87.680 Val_Loss: 0.3264  BEST VAL Loss: 0.3264  Val_Acc: 90.225

Epoch 24: Validation loss decreased (0.326354 --> 0.323621).  Saving model ...
	 Train_Loss: 0.3873 Train_Acc: 87.651 Val_Loss: 0.3236  BEST VAL Loss: 0.3236  Val_Acc: 90.288

Epoch 25: Validation loss decreased (0.323621 --> 0.320976).  Saving model ...
	 Train_Loss: 0.3845 Train_Acc: 87.875 Val_Loss: 0.3210  BEST VAL Loss: 0.3210  Val_Acc: 90.340

Epoch 26: Validation loss decreased (0.320976 --> 0.318615).  Saving model ...
	 Train_Loss: 0.3817 Train_Acc: 88.046 Val_Loss: 0.3186  BEST VAL Loss: 0.3186  Val_Acc: 90.194

Epoch 27: Validation loss decreased (0.318615 --> 0.316276).  Saving model ...
	 Train_Loss: 0.3791 Train_Acc: 88.018 Val_Loss: 0.3163  BEST VAL Loss: 0.3163  Val_Acc: 90.230

Epoch 28: Validation loss decreased (0.316276 --> 0.313888).  Saving model ...
	 Train_Loss: 0.3766 Train_Acc: 88.068 Val_Loss: 0.3139  BEST VAL Loss: 0.3139  Val_Acc: 90.563

Epoch 29: Validation loss decreased (0.313888 --> 0.311744).  Saving model ...
	 Train_Loss: 0.3743 Train_Acc: 88.081 Val_Loss: 0.3117  BEST VAL Loss: 0.3117  Val_Acc: 90.761

Epoch 30: Validation loss decreased (0.311744 --> 0.309773).  Saving model ...
	 Train_Loss: 0.3720 Train_Acc: 88.181 Val_Loss: 0.3098  BEST VAL Loss: 0.3098  Val_Acc: 90.850

Epoch 31: Validation loss decreased (0.309773 --> 0.307746).  Saving model ...
	 Train_Loss: 0.3698 Train_Acc: 88.291 Val_Loss: 0.3077  BEST VAL Loss: 0.3077  Val_Acc: 90.771

Epoch 32: Validation loss decreased (0.307746 --> 0.306046).  Saving model ...
	 Train_Loss: 0.3677 Train_Acc: 88.448 Val_Loss: 0.3060  BEST VAL Loss: 0.3060  Val_Acc: 90.262

Epoch 33: Validation loss decreased (0.306046 --> 0.304334).  Saving model ...
	 Train_Loss: 0.3657 Train_Acc: 88.304 Val_Loss: 0.3043  BEST VAL Loss: 0.3043  Val_Acc: 90.600

Epoch 34: Validation loss decreased (0.304334 --> 0.302747).  Saving model ...
	 Train_Loss: 0.3638 Train_Acc: 88.470 Val_Loss: 0.3027  BEST VAL Loss: 0.3027  Val_Acc: 90.584

Epoch 35: Validation loss decreased (0.302747 --> 0.301153).  Saving model ...
	 Train_Loss: 0.3619 Train_Acc: 88.641 Val_Loss: 0.3012  BEST VAL Loss: 0.3012  Val_Acc: 90.766

Epoch 36: Validation loss decreased (0.301153 --> 0.299683).  Saving model ...
	 Train_Loss: 0.3601 Train_Acc: 88.550 Val_Loss: 0.2997  BEST VAL Loss: 0.2997  Val_Acc: 90.735

Epoch 37: Validation loss decreased (0.299683 --> 0.298371).  Saving model ...
	 Train_Loss: 0.3584 Train_Acc: 88.503 Val_Loss: 0.2984  BEST VAL Loss: 0.2984  Val_Acc: 90.891

Epoch 38: Validation loss decreased (0.298371 --> 0.296991).  Saving model ...
	 Train_Loss: 0.3568 Train_Acc: 88.684 Val_Loss: 0.2970  BEST VAL Loss: 0.2970  Val_Acc: 90.839

Epoch 39: Validation loss decreased (0.296991 --> 0.295620).  Saving model ...
	 Train_Loss: 0.3552 Train_Acc: 88.722 Val_Loss: 0.2956  BEST VAL Loss: 0.2956  Val_Acc: 90.818

Epoch 40: Validation loss decreased (0.295620 --> 0.294308).  Saving model ...
	 Train_Loss: 0.3537 Train_Acc: 88.645 Val_Loss: 0.2943  BEST VAL Loss: 0.2943  Val_Acc: 90.980

Epoch 41: Validation loss decreased (0.294308 --> 0.293010).  Saving model ...
	 Train_Loss: 0.3522 Train_Acc: 88.787 Val_Loss: 0.2930  BEST VAL Loss: 0.2930  Val_Acc: 91.011

Epoch 42: Validation loss decreased (0.293010 --> 0.291762).  Saving model ...
	 Train_Loss: 0.3507 Train_Acc: 88.886 Val_Loss: 0.2918  BEST VAL Loss: 0.2918  Val_Acc: 91.141

Epoch 43: Validation loss decreased (0.291762 --> 0.290772).  Saving model ...
	 Train_Loss: 0.3493 Train_Acc: 88.818 Val_Loss: 0.2908  BEST VAL Loss: 0.2908  Val_Acc: 90.855

Epoch 44: Validation loss decreased (0.290772 --> 0.289736).  Saving model ...
	 Train_Loss: 0.3480 Train_Acc: 88.836 Val_Loss: 0.2897  BEST VAL Loss: 0.2897  Val_Acc: 90.891

Epoch 45: Validation loss decreased (0.289736 --> 0.288618).  Saving model ...
	 Train_Loss: 0.3467 Train_Acc: 88.794 Val_Loss: 0.2886  BEST VAL Loss: 0.2886  Val_Acc: 91.058

Epoch 46: Validation loss decreased (0.288618 --> 0.287487).  Saving model ...
	 Train_Loss: 0.3454 Train_Acc: 88.956 Val_Loss: 0.2875  BEST VAL Loss: 0.2875  Val_Acc: 91.094

Epoch 47: Validation loss decreased (0.287487 --> 0.286473).  Saving model ...
	 Train_Loss: 0.3442 Train_Acc: 89.029 Val_Loss: 0.2865  BEST VAL Loss: 0.2865  Val_Acc: 90.969

Epoch 48: Validation loss decreased (0.286473 --> 0.285487).  Saving model ...
	 Train_Loss: 0.3430 Train_Acc: 89.011 Val_Loss: 0.2855  BEST VAL Loss: 0.2855  Val_Acc: 91.260

Epoch 49: Validation loss decreased (0.285487 --> 0.284587).  Saving model ...
	 Train_Loss: 0.3418 Train_Acc: 89.189 Val_Loss: 0.2846  BEST VAL Loss: 0.2846  Val_Acc: 91.146

Epoch 50: Validation loss decreased (0.284587 --> 0.283703).  Saving model ...
	 Train_Loss: 0.3406 Train_Acc: 89.080 Val_Loss: 0.2837  BEST VAL Loss: 0.2837  Val_Acc: 91.234

Epoch 51: Validation loss decreased (0.283703 --> 0.282838).  Saving model ...
	 Train_Loss: 0.3395 Train_Acc: 89.154 Val_Loss: 0.2828  BEST VAL Loss: 0.2828  Val_Acc: 91.078

Epoch 52: Validation loss decreased (0.282838 --> 0.282018).  Saving model ...
	 Train_Loss: 0.3384 Train_Acc: 89.070 Val_Loss: 0.2820  BEST VAL Loss: 0.2820  Val_Acc: 91.084

Epoch 53: Validation loss decreased (0.282018 --> 0.281207).  Saving model ...
	 Train_Loss: 0.3373 Train_Acc: 89.329 Val_Loss: 0.2812  BEST VAL Loss: 0.2812  Val_Acc: 91.078

Epoch 54: Validation loss decreased (0.281207 --> 0.280428).  Saving model ...
	 Train_Loss: 0.3363 Train_Acc: 89.202 Val_Loss: 0.2804  BEST VAL Loss: 0.2804  Val_Acc: 91.182

Epoch 55: Validation loss decreased (0.280428 --> 0.279705).  Saving model ...
	 Train_Loss: 0.3353 Train_Acc: 89.188 Val_Loss: 0.2797  BEST VAL Loss: 0.2797  Val_Acc: 91.047

Epoch 56: Validation loss decreased (0.279705 --> 0.279010).  Saving model ...
	 Train_Loss: 0.3343 Train_Acc: 89.197 Val_Loss: 0.2790  BEST VAL Loss: 0.2790  Val_Acc: 91.380

Epoch 57: Validation loss decreased (0.279010 --> 0.278340).  Saving model ...
	 Train_Loss: 0.3333 Train_Acc: 89.347 Val_Loss: 0.2783  BEST VAL Loss: 0.2783  Val_Acc: 91.032

Epoch 58: Validation loss decreased (0.278340 --> 0.277720).  Saving model ...
	 Train_Loss: 0.3324 Train_Acc: 89.302 Val_Loss: 0.2777  BEST VAL Loss: 0.2777  Val_Acc: 91.120

Epoch 59: Validation loss decreased (0.277720 --> 0.277025).  Saving model ...
	 Train_Loss: 0.3314 Train_Acc: 89.379 Val_Loss: 0.2770  BEST VAL Loss: 0.2770  Val_Acc: 91.182

Epoch 60: Validation loss decreased (0.277025 --> 0.276450).  Saving model ...
	 Train_Loss: 0.3305 Train_Acc: 89.408 Val_Loss: 0.2764  BEST VAL Loss: 0.2764  Val_Acc: 91.172

Epoch 61: Validation loss decreased (0.276450 --> 0.275866).  Saving model ...
	 Train_Loss: 0.3296 Train_Acc: 89.327 Val_Loss: 0.2759  BEST VAL Loss: 0.2759  Val_Acc: 91.250

Epoch 62: Validation loss decreased (0.275866 --> 0.275378).  Saving model ...
	 Train_Loss: 0.3288 Train_Acc: 89.395 Val_Loss: 0.2754  BEST VAL Loss: 0.2754  Val_Acc: 90.756

Epoch 63: Validation loss decreased (0.275378 --> 0.274790).  Saving model ...
	 Train_Loss: 0.3279 Train_Acc: 89.513 Val_Loss: 0.2748  BEST VAL Loss: 0.2748  Val_Acc: 91.198

Epoch 64: Validation loss decreased (0.274790 --> 0.274209).  Saving model ...
	 Train_Loss: 0.3271 Train_Acc: 89.417 Val_Loss: 0.2742  BEST VAL Loss: 0.2742  Val_Acc: 91.099

Epoch 65: Validation loss decreased (0.274209 --> 0.273644).  Saving model ...
	 Train_Loss: 0.3263 Train_Acc: 89.493 Val_Loss: 0.2736  BEST VAL Loss: 0.2736  Val_Acc: 91.541

Epoch 66: Validation loss decreased (0.273644 --> 0.273082).  Saving model ...
	 Train_Loss: 0.3255 Train_Acc: 89.532 Val_Loss: 0.2731  BEST VAL Loss: 0.2731  Val_Acc: 91.333

Epoch 67: Validation loss decreased (0.273082 --> 0.272728).  Saving model ...
	 Train_Loss: 0.3247 Train_Acc: 89.550 Val_Loss: 0.2727  BEST VAL Loss: 0.2727  Val_Acc: 90.974

Epoch 68: Validation loss decreased (0.272728 --> 0.272223).  Saving model ...
	 Train_Loss: 0.3239 Train_Acc: 89.637 Val_Loss: 0.2722  BEST VAL Loss: 0.2722  Val_Acc: 91.245

Epoch 69: Validation loss decreased (0.272223 --> 0.271708).  Saving model ...
	 Train_Loss: 0.3232 Train_Acc: 89.467 Val_Loss: 0.2717  BEST VAL Loss: 0.2717  Val_Acc: 91.401

Epoch 70: Validation loss decreased (0.271708 --> 0.271182).  Saving model ...
	 Train_Loss: 0.3225 Train_Acc: 89.522 Val_Loss: 0.2712  BEST VAL Loss: 0.2712  Val_Acc: 91.312

Epoch 71: Validation loss decreased (0.271182 --> 0.270706).  Saving model ...
	 Train_Loss: 0.3217 Train_Acc: 89.543 Val_Loss: 0.2707  BEST VAL Loss: 0.2707  Val_Acc: 91.323

Epoch 72: Validation loss decreased (0.270706 --> 0.270242).  Saving model ...
	 Train_Loss: 0.3210 Train_Acc: 89.512 Val_Loss: 0.2702  BEST VAL Loss: 0.2702  Val_Acc: 91.281

Epoch 73: Validation loss decreased (0.270242 --> 0.269802).  Saving model ...
	 Train_Loss: 0.3204 Train_Acc: 89.645 Val_Loss: 0.2698  BEST VAL Loss: 0.2698  Val_Acc: 91.302

Epoch 74: Validation loss decreased (0.269802 --> 0.269317).  Saving model ...
	 Train_Loss: 0.3197 Train_Acc: 89.489 Val_Loss: 0.2693  BEST VAL Loss: 0.2693  Val_Acc: 91.521

Epoch 75: Validation loss decreased (0.269317 --> 0.268945).  Saving model ...
	 Train_Loss: 0.3190 Train_Acc: 89.628 Val_Loss: 0.2689  BEST VAL Loss: 0.2689  Val_Acc: 91.151

Epoch 76: Validation loss decreased (0.268945 --> 0.268519).  Saving model ...
	 Train_Loss: 0.3184 Train_Acc: 89.621 Val_Loss: 0.2685  BEST VAL Loss: 0.2685  Val_Acc: 91.422

Epoch 77: Validation loss decreased (0.268519 --> 0.268130).  Saving model ...
	 Train_Loss: 0.3177 Train_Acc: 89.788 Val_Loss: 0.2681  BEST VAL Loss: 0.2681  Val_Acc: 91.281

Epoch 78: Validation loss decreased (0.268130 --> 0.267744).  Saving model ...
	 Train_Loss: 0.3171 Train_Acc: 89.729 Val_Loss: 0.2677  BEST VAL Loss: 0.2677  Val_Acc: 91.354

Epoch 79: Validation loss decreased (0.267744 --> 0.267383).  Saving model ...
	 Train_Loss: 0.3164 Train_Acc: 89.674 Val_Loss: 0.2674  BEST VAL Loss: 0.2674  Val_Acc: 91.193

Epoch 80: Validation loss decreased (0.267383 --> 0.267060).  Saving model ...
	 Train_Loss: 0.3158 Train_Acc: 89.637 Val_Loss: 0.2671  BEST VAL Loss: 0.2671  Val_Acc: 91.214

Epoch 81: Validation loss decreased (0.267060 --> 0.266682).  Saving model ...
	 Train_Loss: 0.3152 Train_Acc: 89.621 Val_Loss: 0.2667  BEST VAL Loss: 0.2667  Val_Acc: 91.286

Epoch 82: Validation loss decreased (0.266682 --> 0.266321).  Saving model ...
	 Train_Loss: 0.3147 Train_Acc: 89.794 Val_Loss: 0.2663  BEST VAL Loss: 0.2663  Val_Acc: 91.401

Epoch 83: Validation loss decreased (0.266321 --> 0.266028).  Saving model ...
	 Train_Loss: 0.3141 Train_Acc: 89.839 Val_Loss: 0.2660  BEST VAL Loss: 0.2660  Val_Acc: 91.391

Epoch 84: Validation loss decreased (0.266028 --> 0.265689).  Saving model ...
	 Train_Loss: 0.3135 Train_Acc: 89.822 Val_Loss: 0.2657  BEST VAL Loss: 0.2657  Val_Acc: 91.391

Epoch 85: Validation loss decreased (0.265689 --> 0.265419).  Saving model ...
	 Train_Loss: 0.3129 Train_Acc: 89.753 Val_Loss: 0.2654  BEST VAL Loss: 0.2654  Val_Acc: 91.099

Epoch 86: Validation loss decreased (0.265419 --> 0.265303).  Saving model ...
	 Train_Loss: 0.3124 Train_Acc: 89.783 Val_Loss: 0.2653  BEST VAL Loss: 0.2653  Val_Acc: 91.042

Epoch 87: Validation loss decreased (0.265303 --> 0.265014).  Saving model ...
	 Train_Loss: 0.3118 Train_Acc: 89.796 Val_Loss: 0.2650  BEST VAL Loss: 0.2650  Val_Acc: 91.432

Epoch 88: Validation loss decreased (0.265014 --> 0.264832).  Saving model ...
	 Train_Loss: 0.3113 Train_Acc: 89.721 Val_Loss: 0.2648  BEST VAL Loss: 0.2648  Val_Acc: 91.047

Epoch 89: Validation loss decreased (0.264832 --> 0.264502).  Saving model ...
	 Train_Loss: 0.3108 Train_Acc: 89.654 Val_Loss: 0.2645  BEST VAL Loss: 0.2645  Val_Acc: 91.354

Epoch 90: Validation loss decreased (0.264502 --> 0.264148).  Saving model ...
	 Train_Loss: 0.3103 Train_Acc: 89.899 Val_Loss: 0.2641  BEST VAL Loss: 0.2641  Val_Acc: 91.437

Epoch 91: Validation loss decreased (0.264148 --> 0.263876).  Saving model ...
	 Train_Loss: 0.3098 Train_Acc: 89.852 Val_Loss: 0.2639  BEST VAL Loss: 0.2639  Val_Acc: 91.411

Epoch 92: Validation loss decreased (0.263876 --> 0.263624).  Saving model ...
	 Train_Loss: 0.3093 Train_Acc: 89.872 Val_Loss: 0.2636  BEST VAL Loss: 0.2636  Val_Acc: 91.432

Epoch 93: Validation loss decreased (0.263624 --> 0.263406).  Saving model ...
	 Train_Loss: 0.3088 Train_Acc: 89.880 Val_Loss: 0.2634  BEST VAL Loss: 0.2634  Val_Acc: 91.453

Epoch 94: Validation loss decreased (0.263406 --> 0.263187).  Saving model ...
	 Train_Loss: 0.3083 Train_Acc: 89.882 Val_Loss: 0.2632  BEST VAL Loss: 0.2632  Val_Acc: 91.417

Epoch 95: Validation loss decreased (0.263187 --> 0.262938).  Saving model ...
	 Train_Loss: 0.3078 Train_Acc: 89.747 Val_Loss: 0.2629  BEST VAL Loss: 0.2629  Val_Acc: 91.521

Epoch 96: Validation loss decreased (0.262938 --> 0.262674).  Saving model ...
	 Train_Loss: 0.3073 Train_Acc: 89.948 Val_Loss: 0.2627  BEST VAL Loss: 0.2627  Val_Acc: 91.552

Epoch 97: Validation loss decreased (0.262674 --> 0.262517).  Saving model ...
	 Train_Loss: 0.3069 Train_Acc: 89.903 Val_Loss: 0.2625  BEST VAL Loss: 0.2625  Val_Acc: 91.411

Epoch 98: Validation loss decreased (0.262517 --> 0.262296).  Saving model ...
	 Train_Loss: 0.3064 Train_Acc: 89.883 Val_Loss: 0.2623  BEST VAL Loss: 0.2623  Val_Acc: 91.562

Epoch 99: Validation loss decreased (0.262296 --> 0.262061).  Saving model ...
	 Train_Loss: 0.3060 Train_Acc: 89.974 Val_Loss: 0.2621  BEST VAL Loss: 0.2621  Val_Acc: 91.484

Flagellin_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.96      0.87      0.91     56121
           1       0.93      0.98      0.95     97655

    accuracy                           0.94    153776
   macro avg       0.94      0.92      0.93    153776
weighted avg       0.94      0.94      0.94    153776

Flagellin_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.83      0.88      7016
           1       0.91      0.96      0.93     12207

    accuracy                           0.91     19223
   macro avg       0.92      0.90      0.91     19223
weighted avg       0.92      0.91      0.91     19223

Flagellin_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.92      0.85      0.88      7016
           1       0.92      0.96      0.94     12207

    accuracy                           0.92     19223
   macro avg       0.92      0.90      0.91     19223
weighted avg       0.92      0.92      0.92     19223

              precision    recall  f1-score   support

           0       0.92      0.85      0.88      7016
           1       0.92      0.96      0.94     12207

    accuracy                           0.92     19223
   macro avg       0.92      0.90      0.91     19223
weighted avg       0.92      0.92      0.92     19223

Flagellin_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.86      0.69      0.76     34394
           1       0.79      0.92      0.85     44915

    accuracy                           0.82     79309
   macro avg       0.83      0.80      0.81     79309
weighted avg       0.82      0.82      0.81     79309

              precision    recall  f1-score   support

           0       0.86      0.69      0.76     34394
           1       0.79      0.92      0.85     44915

    accuracy                           0.82     79309
   macro avg       0.83      0.80      0.81     79309
weighted avg       0.82      0.82      0.81     79309

completed
