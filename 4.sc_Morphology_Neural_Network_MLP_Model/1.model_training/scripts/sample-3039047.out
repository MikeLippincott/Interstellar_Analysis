[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '9ba173c3'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '2c81e506'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '5977e142'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'bdc70314'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_1.000_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (33319, 1276)
Number of total missing values across all columns: 66638
Data Subset Is Off
Wells held out for testing: ['C21' 'M22']
Wells to use for training, validation, and testing ['C16' 'C17' 'C20' 'M18' 'M19' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.686488).  Saving model ...
	 Train_Loss: 0.6974 Train_Acc: 52.443 Val_Loss: 0.6865  BEST VAL Loss: 0.6865  Val_Acc: 52.460

Epoch 1: Validation loss decreased (0.686488 --> 0.682533).  Saving model ...
	 Train_Loss: 0.6911 Train_Acc: 53.098 Val_Loss: 0.6825  BEST VAL Loss: 0.6825  Val_Acc: 53.387

Epoch 2: Validation loss decreased (0.682533 --> 0.678085).  Saving model ...
	 Train_Loss: 0.6861 Train_Acc: 55.700 Val_Loss: 0.6781  BEST VAL Loss: 0.6781  Val_Acc: 57.984

Epoch 3: Validation loss decreased (0.678085 --> 0.674671).  Saving model ...
	 Train_Loss: 0.6818 Train_Acc: 57.556 Val_Loss: 0.6747  BEST VAL Loss: 0.6747  Val_Acc: 60.685

Epoch 4: Validation loss decreased (0.674671 --> 0.670334).  Saving model ...
	 Train_Loss: 0.6774 Train_Acc: 58.937 Val_Loss: 0.6703  BEST VAL Loss: 0.6703  Val_Acc: 62.056

Epoch 5: Validation loss decreased (0.670334 --> 0.665861).  Saving model ...
	 Train_Loss: 0.6731 Train_Acc: 59.825 Val_Loss: 0.6659  BEST VAL Loss: 0.6659  Val_Acc: 63.427

Epoch 6: Validation loss decreased (0.665861 --> 0.661680).  Saving model ...
	 Train_Loss: 0.6686 Train_Acc: 60.964 Val_Loss: 0.6617  BEST VAL Loss: 0.6617  Val_Acc: 64.435

Epoch 7: Validation loss decreased (0.661680 --> 0.657031).  Saving model ...
	 Train_Loss: 0.6640 Train_Acc: 63.238 Val_Loss: 0.6570  BEST VAL Loss: 0.6570  Val_Acc: 66.734

Epoch 8: Validation loss decreased (0.657031 --> 0.652064).  Saving model ...
	 Train_Loss: 0.6589 Train_Acc: 65.799 Val_Loss: 0.6521  BEST VAL Loss: 0.6521  Val_Acc: 67.258

Epoch 9: Validation loss decreased (0.652064 --> 0.647625).  Saving model ...
	 Train_Loss: 0.6538 Train_Acc: 66.778 Val_Loss: 0.6476  BEST VAL Loss: 0.6476  Val_Acc: 67.661

Epoch 10: Validation loss decreased (0.647625 --> 0.642980).  Saving model ...
	 Train_Loss: 0.6488 Train_Acc: 67.771 Val_Loss: 0.6430  BEST VAL Loss: 0.6430  Val_Acc: 68.790

Epoch 11: Validation loss decreased (0.642980 --> 0.638705).  Saving model ...
	 Train_Loss: 0.6438 Train_Acc: 68.522 Val_Loss: 0.6387  BEST VAL Loss: 0.6387  Val_Acc: 69.758

Epoch 12: Validation loss decreased (0.638705 --> 0.634333).  Saving model ...
	 Train_Loss: 0.6388 Train_Acc: 69.112 Val_Loss: 0.6343  BEST VAL Loss: 0.6343  Val_Acc: 69.315

Epoch 13: Validation loss decreased (0.634333 --> 0.630276).  Saving model ...
	 Train_Loss: 0.6339 Train_Acc: 70.045 Val_Loss: 0.6303  BEST VAL Loss: 0.6303  Val_Acc: 69.879

Epoch 14: Validation loss decreased (0.630276 --> 0.626497).  Saving model ...
	 Train_Loss: 0.6295 Train_Acc: 70.115 Val_Loss: 0.6265  BEST VAL Loss: 0.6265  Val_Acc: 70.242

Epoch 15: Validation loss decreased (0.626497 --> 0.622808).  Saving model ...
	 Train_Loss: 0.6251 Train_Acc: 70.655 Val_Loss: 0.6228  BEST VAL Loss: 0.6228  Val_Acc: 70.403

Epoch 16: Validation loss decreased (0.622808 --> 0.619280).  Saving model ...
	 Train_Loss: 0.6209 Train_Acc: 71.396 Val_Loss: 0.6193  BEST VAL Loss: 0.6193  Val_Acc: 71.129

Epoch 17: Validation loss decreased (0.619280 --> 0.615747).  Saving model ...
	 Train_Loss: 0.6169 Train_Acc: 71.815 Val_Loss: 0.6157  BEST VAL Loss: 0.6157  Val_Acc: 71.532

Epoch 18: Validation loss decreased (0.615747 --> 0.612546).  Saving model ...
	 Train_Loss: 0.6128 Train_Acc: 72.218 Val_Loss: 0.6125  BEST VAL Loss: 0.6125  Val_Acc: 71.694

Epoch 19: Validation loss decreased (0.612546 --> 0.609903).  Saving model ...
	 Train_Loss: 0.6092 Train_Acc: 72.329 Val_Loss: 0.6099  BEST VAL Loss: 0.6099  Val_Acc: 70.806

Epoch 20: Validation loss decreased (0.609903 --> 0.607202).  Saving model ...
	 Train_Loss: 0.6056 Train_Acc: 72.667 Val_Loss: 0.6072  BEST VAL Loss: 0.6072  Val_Acc: 71.331

Epoch 21: Validation loss decreased (0.607202 --> 0.605275).  Saving model ...
	 Train_Loss: 0.6023 Train_Acc: 72.763 Val_Loss: 0.6053  BEST VAL Loss: 0.6053  Val_Acc: 71.048

Epoch 22: Validation loss decreased (0.605275 --> 0.602966).  Saving model ...
	 Train_Loss: 0.5991 Train_Acc: 72.949 Val_Loss: 0.6030  BEST VAL Loss: 0.6030  Val_Acc: 71.089

Epoch 23: Validation loss decreased (0.602966 --> 0.600821).  Saving model ...
	 Train_Loss: 0.5961 Train_Acc: 73.272 Val_Loss: 0.6008  BEST VAL Loss: 0.6008  Val_Acc: 71.532

Epoch 24: Validation loss decreased (0.600821 --> 0.598949).  Saving model ...
	 Train_Loss: 0.5932 Train_Acc: 73.786 Val_Loss: 0.5989  BEST VAL Loss: 0.5989  Val_Acc: 71.774

Epoch 25: Validation loss decreased (0.598949 --> 0.597035).  Saving model ...
	 Train_Loss: 0.5902 Train_Acc: 74.089 Val_Loss: 0.5970  BEST VAL Loss: 0.5970  Val_Acc: 71.371

Epoch 26: Validation loss decreased (0.597035 --> 0.595198).  Saving model ...
	 Train_Loss: 0.5874 Train_Acc: 73.983 Val_Loss: 0.5952  BEST VAL Loss: 0.5952  Val_Acc: 72.621

Epoch 27: Validation loss decreased (0.595198 --> 0.593162).  Saving model ...
	 Train_Loss: 0.5847 Train_Acc: 74.492 Val_Loss: 0.5932  BEST VAL Loss: 0.5932  Val_Acc: 72.621

Epoch 28: Validation loss decreased (0.593162 --> 0.591496).  Saving model ...
	 Train_Loss: 0.5820 Train_Acc: 74.568 Val_Loss: 0.5915  BEST VAL Loss: 0.5915  Val_Acc: 72.581

Epoch 29: Validation loss decreased (0.591496 --> 0.589886).  Saving model ...
	 Train_Loss: 0.5794 Train_Acc: 75.021 Val_Loss: 0.5899  BEST VAL Loss: 0.5899  Val_Acc: 72.661

Epoch 30: Validation loss decreased (0.589886 --> 0.588251).  Saving model ...
	 Train_Loss: 0.5769 Train_Acc: 74.996 Val_Loss: 0.5883  BEST VAL Loss: 0.5883  Val_Acc: 71.935

Epoch 31: Validation loss decreased (0.588251 --> 0.587008).  Saving model ...
	 Train_Loss: 0.5746 Train_Acc: 75.208 Val_Loss: 0.5870  BEST VAL Loss: 0.5870  Val_Acc: 72.782

Epoch 32: Validation loss decreased (0.587008 --> 0.585708).  Saving model ...
	 Train_Loss: 0.5724 Train_Acc: 75.208 Val_Loss: 0.5857  BEST VAL Loss: 0.5857  Val_Acc: 72.742

Epoch 33: Validation loss decreased (0.585708 --> 0.584418).  Saving model ...
	 Train_Loss: 0.5701 Train_Acc: 75.450 Val_Loss: 0.5844  BEST VAL Loss: 0.5844  Val_Acc: 72.339

Epoch 34: Validation loss decreased (0.584418 --> 0.583091).  Saving model ...
	 Train_Loss: 0.5681 Train_Acc: 75.400 Val_Loss: 0.5831  BEST VAL Loss: 0.5831  Val_Acc: 72.581

Epoch 35: Validation loss decreased (0.583091 --> 0.581851).  Saving model ...
	 Train_Loss: 0.5660 Train_Acc: 75.798 Val_Loss: 0.5819  BEST VAL Loss: 0.5819  Val_Acc: 72.298

Epoch 36: Validation loss decreased (0.581851 --> 0.580600).  Saving model ...
	 Train_Loss: 0.5639 Train_Acc: 75.990 Val_Loss: 0.5806  BEST VAL Loss: 0.5806  Val_Acc: 72.218

Epoch 37: Validation loss decreased (0.580600 --> 0.579344).  Saving model ...
	 Train_Loss: 0.5618 Train_Acc: 76.640 Val_Loss: 0.5793  BEST VAL Loss: 0.5793  Val_Acc: 72.379

Epoch 38: Validation loss decreased (0.579344 --> 0.578324).  Saving model ...
	 Train_Loss: 0.5599 Train_Acc: 76.065 Val_Loss: 0.5783  BEST VAL Loss: 0.5783  Val_Acc: 72.339

Epoch 39: Validation loss decreased (0.578324 --> 0.577543).  Saving model ...
	 Train_Loss: 0.5581 Train_Acc: 75.858 Val_Loss: 0.5775  BEST VAL Loss: 0.5775  Val_Acc: 72.137

Epoch 40: Validation loss decreased (0.577543 --> 0.576621).  Saving model ...
	 Train_Loss: 0.5563 Train_Acc: 76.040 Val_Loss: 0.5766  BEST VAL Loss: 0.5766  Val_Acc: 72.540

Epoch 41: Validation loss decreased (0.576621 --> 0.575446).  Saving model ...
	 Train_Loss: 0.5545 Train_Acc: 76.595 Val_Loss: 0.5754  BEST VAL Loss: 0.5754  Val_Acc: 72.460

Epoch 42: Validation loss decreased (0.575446 --> 0.574494).  Saving model ...
	 Train_Loss: 0.5528 Train_Acc: 76.907 Val_Loss: 0.5745  BEST VAL Loss: 0.5745  Val_Acc: 72.863

Epoch 43: Validation loss decreased (0.574494 --> 0.573616).  Saving model ...
	 Train_Loss: 0.5511 Train_Acc: 76.953 Val_Loss: 0.5736  BEST VAL Loss: 0.5736  Val_Acc: 72.419

Epoch 44: Validation loss decreased (0.573616 --> 0.572726).  Saving model ...
	 Train_Loss: 0.5493 Train_Acc: 76.963 Val_Loss: 0.5727  BEST VAL Loss: 0.5727  Val_Acc: 72.621

Epoch 45: Validation loss decreased (0.572726 --> 0.572008).  Saving model ...
	 Train_Loss: 0.5477 Train_Acc: 77.013 Val_Loss: 0.5720  BEST VAL Loss: 0.5720  Val_Acc: 72.984

Epoch 46: Validation loss decreased (0.572008 --> 0.571407).  Saving model ...
	 Train_Loss: 0.5461 Train_Acc: 77.109 Val_Loss: 0.5714  BEST VAL Loss: 0.5714  Val_Acc: 72.581

Epoch 47: Validation loss decreased (0.571407 --> 0.570855).  Saving model ...
	 Train_Loss: 0.5445 Train_Acc: 77.331 Val_Loss: 0.5709  BEST VAL Loss: 0.5709  Val_Acc: 71.935

Epoch 48: Validation loss decreased (0.570855 --> 0.570216).  Saving model ...
	 Train_Loss: 0.5429 Train_Acc: 77.583 Val_Loss: 0.5702  BEST VAL Loss: 0.5702  Val_Acc: 72.742

Epoch 49: Validation loss decreased (0.570216 --> 0.569657).  Saving model ...
	 Train_Loss: 0.5414 Train_Acc: 77.497 Val_Loss: 0.5697  BEST VAL Loss: 0.5697  Val_Acc: 71.935

Epoch 50: Validation loss decreased (0.569657 --> 0.568859).  Saving model ...
	 Train_Loss: 0.5398 Train_Acc: 77.860 Val_Loss: 0.5689  BEST VAL Loss: 0.5689  Val_Acc: 72.339

Epoch 51: Validation loss decreased (0.568859 --> 0.568218).  Saving model ...
	 Train_Loss: 0.5383 Train_Acc: 77.785 Val_Loss: 0.5682  BEST VAL Loss: 0.5682  Val_Acc: 72.621

Epoch 52: Validation loss decreased (0.568218 --> 0.567558).  Saving model ...
	 Train_Loss: 0.5368 Train_Acc: 77.714 Val_Loss: 0.5676  BEST VAL Loss: 0.5676  Val_Acc: 72.661

Epoch 53: Validation loss decreased (0.567558 --> 0.567057).  Saving model ...
	 Train_Loss: 0.5354 Train_Acc: 77.855 Val_Loss: 0.5671  BEST VAL Loss: 0.5671  Val_Acc: 72.742

Epoch 54: Validation loss decreased (0.567057 --> 0.566614).  Saving model ...
	 Train_Loss: 0.5340 Train_Acc: 78.011 Val_Loss: 0.5666  BEST VAL Loss: 0.5666  Val_Acc: 72.218

Epoch 55: Validation loss decreased (0.566614 --> 0.566221).  Saving model ...
	 Train_Loss: 0.5327 Train_Acc: 78.016 Val_Loss: 0.5662  BEST VAL Loss: 0.5662  Val_Acc: 71.855

Epoch 56: Validation loss decreased (0.566221 --> 0.565815).  Saving model ...
	 Train_Loss: 0.5315 Train_Acc: 77.648 Val_Loss: 0.5658  BEST VAL Loss: 0.5658  Val_Acc: 72.944

Epoch 57: Validation loss decreased (0.565815 --> 0.565452).  Saving model ...
	 Train_Loss: 0.5302 Train_Acc: 77.699 Val_Loss: 0.5655  BEST VAL Loss: 0.5655  Val_Acc: 72.500

Epoch 58: Validation loss decreased (0.565452 --> 0.564881).  Saving model ...
	 Train_Loss: 0.5289 Train_Acc: 78.047 Val_Loss: 0.5649  BEST VAL Loss: 0.5649  Val_Acc: 72.702

Epoch 59: Validation loss decreased (0.564881 --> 0.564409).  Saving model ...
	 Train_Loss: 0.5277 Train_Acc: 78.203 Val_Loss: 0.5644  BEST VAL Loss: 0.5644  Val_Acc: 72.500

Epoch 60: Validation loss decreased (0.564409 --> 0.563982).  Saving model ...
	 Train_Loss: 0.5264 Train_Acc: 78.611 Val_Loss: 0.5640  BEST VAL Loss: 0.5640  Val_Acc: 72.782

Epoch 61: Validation loss decreased (0.563982 --> 0.563686).  Saving model ...
	 Train_Loss: 0.5252 Train_Acc: 78.153 Val_Loss: 0.5637  BEST VAL Loss: 0.5637  Val_Acc: 72.500

Epoch 62: Validation loss decreased (0.563686 --> 0.563173).  Saving model ...
	 Train_Loss: 0.5240 Train_Acc: 78.914 Val_Loss: 0.5632  BEST VAL Loss: 0.5632  Val_Acc: 72.702

Epoch 63: Validation loss decreased (0.563173 --> 0.562798).  Saving model ...
	 Train_Loss: 0.5227 Train_Acc: 78.959 Val_Loss: 0.5628  BEST VAL Loss: 0.5628  Val_Acc: 72.984

Epoch 64: Validation loss decreased (0.562798 --> 0.562570).  Saving model ...
	 Train_Loss: 0.5216 Train_Acc: 78.798 Val_Loss: 0.5626  BEST VAL Loss: 0.5626  Val_Acc: 72.218

Epoch 65: Validation loss decreased (0.562570 --> 0.562255).  Saving model ...
	 Train_Loss: 0.5204 Train_Acc: 78.843 Val_Loss: 0.5623  BEST VAL Loss: 0.5623  Val_Acc: 73.306

Epoch 66: Validation loss decreased (0.562255 --> 0.561951).  Saving model ...
	 Train_Loss: 0.5193 Train_Acc: 79.111 Val_Loss: 0.5620  BEST VAL Loss: 0.5620  Val_Acc: 72.258

Epoch 67: Validation loss decreased (0.561951 --> 0.561657).  Saving model ...
	 Train_Loss: 0.5182 Train_Acc: 78.949 Val_Loss: 0.5617  BEST VAL Loss: 0.5617  Val_Acc: 72.581

Epoch 68: Validation loss decreased (0.561657 --> 0.561250).  Saving model ...
	 Train_Loss: 0.5171 Train_Acc: 78.813 Val_Loss: 0.5613  BEST VAL Loss: 0.5613  Val_Acc: 72.823

Epoch 69: Validation loss decreased (0.561250 --> 0.561031).  Saving model ...
	 Train_Loss: 0.5160 Train_Acc: 79.252 Val_Loss: 0.5610  BEST VAL Loss: 0.5610  Val_Acc: 72.581

Epoch 70: Validation loss decreased (0.561031 --> 0.560948).  Saving model ...
	 Train_Loss: 0.5149 Train_Acc: 79.388 Val_Loss: 0.5609  BEST VAL Loss: 0.5609  Val_Acc: 72.137

Epoch 71: Validation loss decreased (0.560948 --> 0.560694).  Saving model ...
	 Train_Loss: 0.5138 Train_Acc: 79.287 Val_Loss: 0.5607  BEST VAL Loss: 0.5607  Val_Acc: 72.903

Epoch 72: Validation loss decreased (0.560694 --> 0.560535).  Saving model ...
	 Train_Loss: 0.5127 Train_Acc: 79.474 Val_Loss: 0.5605  BEST VAL Loss: 0.5605  Val_Acc: 72.661

Epoch 73: Validation loss decreased (0.560535 --> 0.560286).  Saving model ...
	 Train_Loss: 0.5117 Train_Acc: 79.393 Val_Loss: 0.5603  BEST VAL Loss: 0.5603  Val_Acc: 72.782

Epoch 74: Validation loss decreased (0.560286 --> 0.560089).  Saving model ...
	 Train_Loss: 0.5106 Train_Acc: 79.670 Val_Loss: 0.5601  BEST VAL Loss: 0.5601  Val_Acc: 72.984

Epoch 75: Validation loss decreased (0.560089 --> 0.559938).  Saving model ...
	 Train_Loss: 0.5096 Train_Acc: 79.539 Val_Loss: 0.5599  BEST VAL Loss: 0.5599  Val_Acc: 72.661

Epoch 76: Validation loss decreased (0.559938 --> 0.559658).  Saving model ...
	 Train_Loss: 0.5087 Train_Acc: 79.297 Val_Loss: 0.5597  BEST VAL Loss: 0.5597  Val_Acc: 72.782

Epoch 77: Validation loss decreased (0.559658 --> 0.559617).  Saving model ...
	 Train_Loss: 0.5077 Train_Acc: 79.514 Val_Loss: 0.5596  BEST VAL Loss: 0.5596  Val_Acc: 73.105

Epoch 78: Validation loss decreased (0.559617 --> 0.559517).  Saving model ...
	 Train_Loss: 0.5068 Train_Acc: 79.161 Val_Loss: 0.5595  BEST VAL Loss: 0.5595  Val_Acc: 72.903

Epoch 79: Validation loss decreased (0.559517 --> 0.559182).  Saving model ...
	 Train_Loss: 0.5058 Train_Acc: 80.134 Val_Loss: 0.5592  BEST VAL Loss: 0.5592  Val_Acc: 73.185

Epoch 80: Validation loss decreased (0.559182 --> 0.559092).  Saving model ...
	 Train_Loss: 0.5048 Train_Acc: 79.867 Val_Loss: 0.5591  BEST VAL Loss: 0.5591  Val_Acc: 72.863

Epoch 81: Validation loss decreased (0.559092 --> 0.558958).  Saving model ...
	 Train_Loss: 0.5039 Train_Acc: 79.907 Val_Loss: 0.5590  BEST VAL Loss: 0.5590  Val_Acc: 72.823

Epoch 82: Validation loss decreased (0.558958 --> 0.558850).  Saving model ...
	 Train_Loss: 0.5029 Train_Acc: 80.290 Val_Loss: 0.5588  BEST VAL Loss: 0.5588  Val_Acc: 72.903

Epoch 83: Validation loss decreased (0.558850 --> 0.558707).  Saving model ...
	 Train_Loss: 0.5020 Train_Acc: 79.968 Val_Loss: 0.5587  BEST VAL Loss: 0.5587  Val_Acc: 72.460

Epoch 84: Validation loss decreased (0.558707 --> 0.558560).  Saving model ...
	 Train_Loss: 0.5013 Train_Acc: 79.196 Val_Loss: 0.5586  BEST VAL Loss: 0.5586  Val_Acc: 73.185

Epoch 85: Validation loss decreased (0.558560 --> 0.558549).  Saving model ...
	 Train_Loss: 0.5004 Train_Acc: 80.149 Val_Loss: 0.5585  BEST VAL Loss: 0.5585  Val_Acc: 72.298

Epoch 86: Validation loss decreased (0.558549 --> 0.558364).  Saving model ...
	 Train_Loss: 0.4996 Train_Acc: 80.190 Val_Loss: 0.5584  BEST VAL Loss: 0.5584  Val_Acc: 72.863

Epoch 87: Validation loss decreased (0.558364 --> 0.558312).  Saving model ...
	 Train_Loss: 0.4987 Train_Acc: 79.993 Val_Loss: 0.5583  BEST VAL Loss: 0.5583  Val_Acc: 72.460

Epoch 88: Validation loss decreased (0.558312 --> 0.558297).  Saving model ...
	 Train_Loss: 0.4979 Train_Acc: 80.114 Val_Loss: 0.5583  BEST VAL Loss: 0.5583  Val_Acc: 71.855

Epoch 89: Validation loss decreased (0.558297 --> 0.558290).  Saving model ...
	 Train_Loss: 0.4971 Train_Acc: 80.422 Val_Loss: 0.5583  BEST VAL Loss: 0.5583  Val_Acc: 72.782

Epoch 90: Validation loss decreased (0.558290 --> 0.558146).  Saving model ...
	 Train_Loss: 0.4962 Train_Acc: 79.968 Val_Loss: 0.5581  BEST VAL Loss: 0.5581  Val_Acc: 73.105

Epoch 91: Validation loss decreased (0.558146 --> 0.558072).  Saving model ...
	 Train_Loss: 0.4954 Train_Acc: 80.169 Val_Loss: 0.5581  BEST VAL Loss: 0.5581  Val_Acc: 72.621

Epoch 92: Validation loss decreased (0.558072 --> 0.557971).  Saving model ...
	 Train_Loss: 0.4946 Train_Acc: 79.932 Val_Loss: 0.5580  BEST VAL Loss: 0.5580  Val_Acc: 72.782

Epoch 93: Validation loss decreased (0.557971 --> 0.557912).  Saving model ...
	 Train_Loss: 0.4938 Train_Acc: 80.401 Val_Loss: 0.5579  BEST VAL Loss: 0.5579  Val_Acc: 72.823

Epoch 94: Validation loss decreased (0.557912 --> 0.557884).  Saving model ...
	 Train_Loss: 0.4930 Train_Acc: 80.719 Val_Loss: 0.5579  BEST VAL Loss: 0.5579  Val_Acc: 73.387

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.4922 Train_Acc: 80.976 Val_Loss: 0.5579  BEST VAL Loss: 0.5579  Val_Acc: 72.782

Epoch 96: Validation loss decreased (0.557884 --> 0.557871).  Saving model ...
	 Train_Loss: 0.4914 Train_Acc: 80.588 Val_Loss: 0.5579  BEST VAL Loss: 0.5579  Val_Acc: 72.339

Epoch 97: Validation loss did not decrease
	 Train_Loss: 0.4906 Train_Acc: 80.825 Val_Loss: 0.5579  BEST VAL Loss: 0.5579  Val_Acc: 72.540

Epoch 98: Validation loss did not decrease
	 Train_Loss: 0.4898 Train_Acc: 80.911 Val_Loss: 0.5579  BEST VAL Loss: 0.5579  Val_Acc: 72.742

Epoch 99: Validation loss did not decrease
	 Train_Loss: 0.4891 Train_Acc: 80.437 Val_Loss: 0.5579  BEST VAL Loss: 0.5579  Val_Acc: 72.581

Flagellin_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.49      0.48      9433
           1       0.52      0.50      0.51     10400

    accuracy                           0.50     19833
   macro avg       0.50      0.50      0.50     19833
weighted avg       0.50      0.50      0.50     19833

Flagellin_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.50      0.49      1180
           1       0.53      0.51      0.52      1300

    accuracy                           0.50      2480
   macro avg       0.50      0.50      0.50      2480
weighted avg       0.51      0.50      0.51      2480

Flagellin_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.47      0.47      1179
           1       0.52      0.51      0.52      1301

    accuracy                           0.49      2480
   macro avg       0.49      0.49      0.49      2480
weighted avg       0.49      0.49      0.49      2480

              precision    recall  f1-score   support

           0       0.47      0.47      0.47      1179
           1       0.52      0.51      0.52      1301

    accuracy                           0.49      2480
   macro avg       0.49      0.49      0.49      2480
weighted avg       0.49      0.49      0.49      2480

Flagellin_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.50      0.49      4017
           1       0.53      0.51      0.52      4509

    accuracy                           0.50      8526
   macro avg       0.50      0.50      0.50      8526
weighted avg       0.51      0.50      0.51      8526

              precision    recall  f1-score   support

           0       0.48      0.50      0.49      4017
           1       0.53      0.51      0.52      4509

    accuracy                           0.50      8526
   macro avg       0.50      0.50      0.50      8526
weighted avg       0.51      0.50      0.51      8526

completed
