[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b3ccb1a0'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '250e6989'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ba13f3f6'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '74197eb3'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_10.000_DMSO_0.025 treatment_name: DMSO_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: DMSO_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'LPS_10.000_DMSO_0.025']
The dimensions of the data are: (52453, 1276)
Number of total missing values across all columns: 104906
Data Subset Is Off
Wells held out for testing: ['E20' 'I14']
Wells to use for training, validation, and testing ['B14' 'C14' 'B15' 'C15' 'E16' 'E17' 'E21' 'J14' 'I15' 'J15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.528420).  Saving model ...
	 Train_Loss: 0.5831 Train_Acc: 69.728 Val_Loss: 0.5284  BEST VAL Loss: 0.5284  Val_Acc: 70.909

Epoch 1: Validation loss decreased (0.528420 --> 0.520834).  Saving model ...
	 Train_Loss: 0.5622 Train_Acc: 70.902 Val_Loss: 0.5208  BEST VAL Loss: 0.5208  Val_Acc: 70.909

Epoch 2: Validation loss decreased (0.520834 --> 0.515458).  Saving model ...
	 Train_Loss: 0.5493 Train_Acc: 70.902 Val_Loss: 0.5155  BEST VAL Loss: 0.5155  Val_Acc: 70.909

Epoch 3: Validation loss decreased (0.515458 --> 0.511004).  Saving model ...
	 Train_Loss: 0.5397 Train_Acc: 70.902 Val_Loss: 0.5110  BEST VAL Loss: 0.5110  Val_Acc: 70.909

Epoch 4: Validation loss decreased (0.511004 --> 0.507553).  Saving model ...
	 Train_Loss: 0.5323 Train_Acc: 72.608 Val_Loss: 0.5076  BEST VAL Loss: 0.5076  Val_Acc: 70.909

Epoch 5: Validation loss decreased (0.507553 --> 0.504309).  Saving model ...
	 Train_Loss: 0.5267 Train_Acc: 73.787 Val_Loss: 0.5043  BEST VAL Loss: 0.5043  Val_Acc: 76.249

Epoch 6: Validation loss decreased (0.504309 --> 0.502039).  Saving model ...
	 Train_Loss: 0.5218 Train_Acc: 73.994 Val_Loss: 0.5020  BEST VAL Loss: 0.5020  Val_Acc: 76.341

Epoch 7: Validation loss decreased (0.502039 --> 0.499885).  Saving model ...
	 Train_Loss: 0.5176 Train_Acc: 74.179 Val_Loss: 0.4999  BEST VAL Loss: 0.4999  Val_Acc: 76.433

Epoch 8: Validation loss decreased (0.499885 --> 0.497836).  Saving model ...
	 Train_Loss: 0.5137 Train_Acc: 74.590 Val_Loss: 0.4978  BEST VAL Loss: 0.4978  Val_Acc: 76.133

Epoch 9: Validation loss decreased (0.497836 --> 0.496204).  Saving model ...
	 Train_Loss: 0.5104 Train_Acc: 74.423 Val_Loss: 0.4962  BEST VAL Loss: 0.4962  Val_Acc: 76.525

Epoch 10: Validation loss decreased (0.496204 --> 0.494822).  Saving model ...
	 Train_Loss: 0.5074 Train_Acc: 74.682 Val_Loss: 0.4948  BEST VAL Loss: 0.4948  Val_Acc: 76.640

Epoch 11: Validation loss decreased (0.494822 --> 0.493815).  Saving model ...
	 Train_Loss: 0.5046 Train_Acc: 74.878 Val_Loss: 0.4938  BEST VAL Loss: 0.4938  Val_Acc: 75.811

Epoch 12: Validation loss decreased (0.493815 --> 0.492812).  Saving model ...
	 Train_Loss: 0.5023 Train_Acc: 74.789 Val_Loss: 0.4928  BEST VAL Loss: 0.4928  Val_Acc: 76.594

Epoch 13: Validation loss decreased (0.492812 --> 0.491702).  Saving model ...
	 Train_Loss: 0.4999 Train_Acc: 75.344 Val_Loss: 0.4917  BEST VAL Loss: 0.4917  Val_Acc: 77.077

Epoch 14: Validation loss decreased (0.491702 --> 0.490922).  Saving model ...
	 Train_Loss: 0.4978 Train_Acc: 75.796 Val_Loss: 0.4909  BEST VAL Loss: 0.4909  Val_Acc: 76.548

Epoch 15: Validation loss decreased (0.490922 --> 0.490334).  Saving model ...
	 Train_Loss: 0.4957 Train_Acc: 75.749 Val_Loss: 0.4903  BEST VAL Loss: 0.4903  Val_Acc: 76.617

Epoch 16: Validation loss decreased (0.490334 --> 0.489562).  Saving model ...
	 Train_Loss: 0.4939 Train_Acc: 75.675 Val_Loss: 0.4896  BEST VAL Loss: 0.4896  Val_Acc: 77.353

Epoch 17: Validation loss decreased (0.489562 --> 0.488870).  Saving model ...
	 Train_Loss: 0.4922 Train_Acc: 75.666 Val_Loss: 0.4889  BEST VAL Loss: 0.4889  Val_Acc: 76.870

Epoch 18: Validation loss decreased (0.488870 --> 0.488185).  Saving model ...
	 Train_Loss: 0.4905 Train_Acc: 75.888 Val_Loss: 0.4882  BEST VAL Loss: 0.4882  Val_Acc: 77.146

Epoch 19: Validation loss decreased (0.488185 --> 0.487542).  Saving model ...
	 Train_Loss: 0.4889 Train_Acc: 76.244 Val_Loss: 0.4875  BEST VAL Loss: 0.4875  Val_Acc: 76.617

Epoch 20: Validation loss decreased (0.487542 --> 0.487103).  Saving model ...
	 Train_Loss: 0.4875 Train_Acc: 76.144 Val_Loss: 0.4871  BEST VAL Loss: 0.4871  Val_Acc: 76.732

Epoch 21: Validation loss decreased (0.487103 --> 0.486717).  Saving model ...
	 Train_Loss: 0.4861 Train_Acc: 76.069 Val_Loss: 0.4867  BEST VAL Loss: 0.4867  Val_Acc: 76.893

Epoch 22: Validation loss decreased (0.486717 --> 0.486424).  Saving model ...
	 Train_Loss: 0.4848 Train_Acc: 75.965 Val_Loss: 0.4864  BEST VAL Loss: 0.4864  Val_Acc: 76.916

Epoch 23: Validation loss decreased (0.486424 --> 0.486156).  Saving model ...
	 Train_Loss: 0.4836 Train_Acc: 76.270 Val_Loss: 0.4862  BEST VAL Loss: 0.4862  Val_Acc: 76.985

Epoch 24: Validation loss decreased (0.486156 --> 0.485703).  Saving model ...
	 Train_Loss: 0.4824 Train_Acc: 76.241 Val_Loss: 0.4857  BEST VAL Loss: 0.4857  Val_Acc: 77.031

Epoch 25: Validation loss decreased (0.485703 --> 0.485294).  Saving model ...
	 Train_Loss: 0.4812 Train_Acc: 76.650 Val_Loss: 0.4853  BEST VAL Loss: 0.4853  Val_Acc: 77.054

Epoch 26: Validation loss decreased (0.485294 --> 0.485013).  Saving model ...
	 Train_Loss: 0.4801 Train_Acc: 76.279 Val_Loss: 0.4850  BEST VAL Loss: 0.4850  Val_Acc: 76.939

Epoch 27: Validation loss decreased (0.485013 --> 0.484955).  Saving model ...
	 Train_Loss: 0.4790 Train_Acc: 76.299 Val_Loss: 0.4850  BEST VAL Loss: 0.4850  Val_Acc: 76.824

Epoch 28: Validation loss decreased (0.484955 --> 0.484682).  Saving model ...
	 Train_Loss: 0.4780 Train_Acc: 77.332 Val_Loss: 0.4847  BEST VAL Loss: 0.4847  Val_Acc: 77.031

Epoch 29: Validation loss decreased (0.484682 --> 0.484587).  Saving model ...
	 Train_Loss: 0.4770 Train_Acc: 79.216 Val_Loss: 0.4846  BEST VAL Loss: 0.4846  Val_Acc: 76.985

Epoch 30: Validation loss decreased (0.484587 --> 0.484509).  Saving model ...
	 Train_Loss: 0.4761 Train_Acc: 79.067 Val_Loss: 0.4845  BEST VAL Loss: 0.4845  Val_Acc: 76.985

Epoch 31: Validation loss decreased (0.484509 --> 0.484436).  Saving model ...
	 Train_Loss: 0.4752 Train_Acc: 79.268 Val_Loss: 0.4844  BEST VAL Loss: 0.4844  Val_Acc: 77.054

Epoch 32: Validation loss decreased (0.484436 --> 0.484419).  Saving model ...
	 Train_Loss: 0.4744 Train_Acc: 79.190 Val_Loss: 0.4844  BEST VAL Loss: 0.4844  Val_Acc: 77.031

Epoch 33: Validation loss decreased (0.484419 --> 0.484406).  Saving model ...
	 Train_Loss: 0.4735 Train_Acc: 79.639 Val_Loss: 0.4844  BEST VAL Loss: 0.4844  Val_Acc: 77.031

Epoch 34: Validation loss did not decrease
	 Train_Loss: 0.4727 Train_Acc: 79.478 Val_Loss: 0.4845  BEST VAL Loss: 0.4844  Val_Acc: 76.778

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.4719 Train_Acc: 79.567 Val_Loss: 0.4844  BEST VAL Loss: 0.4844  Val_Acc: 77.054

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.4712 Train_Acc: 79.254 Val_Loss: 0.4845  BEST VAL Loss: 0.4844  Val_Acc: 77.123

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.4703 Train_Acc: 79.786 Val_Loss: 0.4846  BEST VAL Loss: 0.4844  Val_Acc: 77.100

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.4697 Train_Acc: 79.501 Val_Loss: 0.4845  BEST VAL Loss: 0.4844  Val_Acc: 77.077

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.4690 Train_Acc: 79.608 Val_Loss: 0.4845  BEST VAL Loss: 0.4844  Val_Acc: 76.985

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.4683 Train_Acc: 79.861 Val_Loss: 0.4847  BEST VAL Loss: 0.4844  Val_Acc: 76.870

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.4677 Train_Acc: 79.507 Val_Loss: 0.4847  BEST VAL Loss: 0.4844  Val_Acc: 76.985

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.4671 Train_Acc: 79.855 Val_Loss: 0.4849  BEST VAL Loss: 0.4844  Val_Acc: 76.962

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.4665 Train_Acc: 79.841 Val_Loss: 0.4851  BEST VAL Loss: 0.4844  Val_Acc: 76.732

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.4659 Train_Acc: 79.982 Val_Loss: 0.4852  BEST VAL Loss: 0.4844  Val_Acc: 76.709

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.4653 Train_Acc: 79.921 Val_Loss: 0.4854  BEST VAL Loss: 0.4844  Val_Acc: 76.387

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.4646 Train_Acc: 80.111 Val_Loss: 0.4855  BEST VAL Loss: 0.4844  Val_Acc: 76.502

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.4640 Train_Acc: 80.140 Val_Loss: 0.4855  BEST VAL Loss: 0.4844  Val_Acc: 76.778

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.4635 Train_Acc: 80.171 Val_Loss: 0.4856  BEST VAL Loss: 0.4844  Val_Acc: 76.962

Epoch 49: Validation loss did not decrease
Early stopped at epoch : 49
LPS_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.85      0.92      0.88     24644
           1       0.75      0.61      0.67     10114

    accuracy                           0.83     34758
   macro avg       0.80      0.76      0.78     34758
weighted avg       0.82      0.83      0.82     34758

LPS_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.81      0.88      0.84      3081
           1       0.63      0.52      0.57      1264

    accuracy                           0.77      4345
   macro avg       0.72      0.70      0.70      4345
weighted avg       0.76      0.77      0.76      4345

LPS_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.81      0.88      0.84      3081
           1       0.62      0.49      0.55      1264

    accuracy                           0.76      4345
   macro avg       0.71      0.68      0.69      4345
weighted avg       0.75      0.76      0.75      4345

              precision    recall  f1-score   support

           0       0.81      0.88      0.84      3081
           1       0.62      0.49      0.55      1264

    accuracy                           0.76      4345
   macro avg       0.71      0.68      0.69      4345
weighted avg       0.75      0.76      0.75      4345

LPS_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.63      0.84      0.72      4837
           1       0.70      0.44      0.54      4168

    accuracy                           0.65      9005
   macro avg       0.67      0.64      0.63      9005
weighted avg       0.66      0.65      0.64      9005

              precision    recall  f1-score   support

           0       0.63      0.84      0.72      4837
           1       0.70      0.44      0.54      4168

    accuracy                           0.65      9005
   macro avg       0.67      0.64      0.63      9005
weighted avg       0.66      0.65      0.64      9005

completed
