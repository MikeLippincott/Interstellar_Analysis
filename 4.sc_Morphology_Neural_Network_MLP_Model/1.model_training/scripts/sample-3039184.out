[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'a68d7bb6'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '2193c068'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ab337d91'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'babe8d0a'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_100.000_DMSO_0.025 treatment_name: Thapsigargin_10.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_100.000_DMSO_0.025
TREATMENT_NAME: Thapsigargin_10.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (29199, 1276)
Number of total missing values across all columns: 58398
Data Subset Is Off
Wells held out for testing: ['E14' 'J20']
Wells to use for training, validation, and testing ['E15' 'L14' 'L15' 'J16' 'J17' 'J21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.145115).  Saving model ...
	 Train_Loss: 0.2741 Train_Acc: 87.291 Val_Loss: 0.1451  BEST VAL Loss: 0.1451  Val_Acc: 94.635

Epoch 1: Validation loss decreased (0.145115 --> 0.116109).  Saving model ...
	 Train_Loss: 0.2049 Train_Acc: 94.268 Val_Loss: 0.1161  BEST VAL Loss: 0.1161  Val_Acc: 96.573

Epoch 2: Validation loss decreased (0.116109 --> 0.101233).  Saving model ...
	 Train_Loss: 0.1694 Train_Acc: 95.587 Val_Loss: 0.1012  BEST VAL Loss: 0.1012  Val_Acc: 97.385

Epoch 3: Validation loss decreased (0.101233 --> 0.094161).  Saving model ...
	 Train_Loss: 0.1468 Train_Acc: 96.432 Val_Loss: 0.0942  BEST VAL Loss: 0.0942  Val_Acc: 97.610

Epoch 4: Validation loss decreased (0.094161 --> 0.091993).  Saving model ...
	 Train_Loss: 0.1309 Train_Acc: 96.889 Val_Loss: 0.0920  BEST VAL Loss: 0.0920  Val_Acc: 97.971

Epoch 5: Validation loss decreased (0.091993 --> 0.086703).  Saving model ...
	 Train_Loss: 0.1196 Train_Acc: 97.176 Val_Loss: 0.0867  BEST VAL Loss: 0.0867  Val_Acc: 98.287

Epoch 6: Validation loss did not decrease
	 Train_Loss: 0.1103 Train_Acc: 97.560 Val_Loss: 0.0887  BEST VAL Loss: 0.0867  Val_Acc: 97.836

Epoch 7: Validation loss did not decrease
	 Train_Loss: 0.1023 Train_Acc: 97.678 Val_Loss: 0.0925  BEST VAL Loss: 0.0867  Val_Acc: 97.791

Epoch 8: Validation loss did not decrease
	 Train_Loss: 0.0965 Train_Acc: 97.802 Val_Loss: 0.0923  BEST VAL Loss: 0.0867  Val_Acc: 97.746

Epoch 9: Validation loss did not decrease
	 Train_Loss: 0.0920 Train_Acc: 97.779 Val_Loss: 0.0900  BEST VAL Loss: 0.0867  Val_Acc: 97.926

Epoch 10: Validation loss did not decrease
	 Train_Loss: 0.0874 Train_Acc: 97.988 Val_Loss: 0.0919  BEST VAL Loss: 0.0867  Val_Acc: 98.242

Epoch 11: Validation loss did not decrease
	 Train_Loss: 0.0834 Train_Acc: 98.157 Val_Loss: 0.0927  BEST VAL Loss: 0.0867  Val_Acc: 98.332

Epoch 12: Validation loss did not decrease
	 Train_Loss: 0.0799 Train_Acc: 98.270 Val_Loss: 0.0916  BEST VAL Loss: 0.0867  Val_Acc: 98.242

Epoch 13: Validation loss did not decrease
	 Train_Loss: 0.0770 Train_Acc: 98.388 Val_Loss: 0.0893  BEST VAL Loss: 0.0867  Val_Acc: 98.557

Epoch 14: Validation loss did not decrease
	 Train_Loss: 0.0743 Train_Acc: 98.337 Val_Loss: 0.0879  BEST VAL Loss: 0.0867  Val_Acc: 98.061

Epoch 15: Validation loss did not decrease
	 Train_Loss: 0.0719 Train_Acc: 98.535 Val_Loss: 0.0875  BEST VAL Loss: 0.0867  Val_Acc: 98.061

Epoch 16: Validation loss decreased (0.086703 --> 0.086408).  Saving model ...
	 Train_Loss: 0.0701 Train_Acc: 98.134 Val_Loss: 0.0864  BEST VAL Loss: 0.0864  Val_Acc: 98.151

Epoch 17: Validation loss decreased (0.086408 --> 0.085478).  Saving model ...
	 Train_Loss: 0.0680 Train_Acc: 98.490 Val_Loss: 0.0855  BEST VAL Loss: 0.0855  Val_Acc: 98.061

Epoch 18: Validation loss decreased (0.085478 --> 0.083516).  Saving model ...
	 Train_Loss: 0.0665 Train_Acc: 98.247 Val_Loss: 0.0835  BEST VAL Loss: 0.0835  Val_Acc: 98.242

Epoch 19: Validation loss decreased (0.083516 --> 0.082765).  Saving model ...
	 Train_Loss: 0.0650 Train_Acc: 98.371 Val_Loss: 0.0828  BEST VAL Loss: 0.0828  Val_Acc: 98.197

Epoch 20: Validation loss decreased (0.082765 --> 0.082154).  Saving model ...
	 Train_Loss: 0.0635 Train_Acc: 98.439 Val_Loss: 0.0822  BEST VAL Loss: 0.0822  Val_Acc: 98.061

Epoch 21: Validation loss decreased (0.082154 --> 0.081845).  Saving model ...
	 Train_Loss: 0.0620 Train_Acc: 98.546 Val_Loss: 0.0818  BEST VAL Loss: 0.0818  Val_Acc: 98.106

Epoch 22: Validation loss decreased (0.081845 --> 0.081342).  Saving model ...
	 Train_Loss: 0.0608 Train_Acc: 98.535 Val_Loss: 0.0813  BEST VAL Loss: 0.0813  Val_Acc: 98.242

Epoch 23: Validation loss decreased (0.081342 --> 0.080224).  Saving model ...
	 Train_Loss: 0.0595 Train_Acc: 98.681 Val_Loss: 0.0802  BEST VAL Loss: 0.0802  Val_Acc: 98.287

Epoch 24: Validation loss decreased (0.080224 --> 0.080208).  Saving model ...
	 Train_Loss: 0.0583 Train_Acc: 98.568 Val_Loss: 0.0802  BEST VAL Loss: 0.0802  Val_Acc: 98.918

Epoch 25: Validation loss decreased (0.080208 --> 0.079944).  Saving model ...
	 Train_Loss: 0.0572 Train_Acc: 98.692 Val_Loss: 0.0799  BEST VAL Loss: 0.0799  Val_Acc: 98.332

Epoch 26: Validation loss decreased (0.079944 --> 0.079598).  Saving model ...
	 Train_Loss: 0.0562 Train_Acc: 98.591 Val_Loss: 0.0796  BEST VAL Loss: 0.0796  Val_Acc: 98.602

Epoch 27: Validation loss decreased (0.079598 --> 0.079427).  Saving model ...
	 Train_Loss: 0.0552 Train_Acc: 98.738 Val_Loss: 0.0794  BEST VAL Loss: 0.0794  Val_Acc: 98.377

Epoch 28: Validation loss decreased (0.079427 --> 0.079313).  Saving model ...
	 Train_Loss: 0.0543 Train_Acc: 98.726 Val_Loss: 0.0793  BEST VAL Loss: 0.0793  Val_Acc: 98.422

Epoch 29: Validation loss decreased (0.079313 --> 0.078929).  Saving model ...
	 Train_Loss: 0.0533 Train_Acc: 98.783 Val_Loss: 0.0789  BEST VAL Loss: 0.0789  Val_Acc: 98.512

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.0524 Train_Acc: 98.980 Val_Loss: 0.0793  BEST VAL Loss: 0.0789  Val_Acc: 98.377

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.0515 Train_Acc: 98.884 Val_Loss: 0.0796  BEST VAL Loss: 0.0789  Val_Acc: 98.557

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.0508 Train_Acc: 98.811 Val_Loss: 0.0805  BEST VAL Loss: 0.0789  Val_Acc: 98.151

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.0502 Train_Acc: 98.715 Val_Loss: 0.0799  BEST VAL Loss: 0.0789  Val_Acc: 98.693

Epoch 34: Validation loss did not decrease
	 Train_Loss: 0.0495 Train_Acc: 98.878 Val_Loss: 0.0792  BEST VAL Loss: 0.0789  Val_Acc: 98.783

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.0487 Train_Acc: 99.008 Val_Loss: 0.0799  BEST VAL Loss: 0.0789  Val_Acc: 98.738

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.0480 Train_Acc: 99.025 Val_Loss: 0.0793  BEST VAL Loss: 0.0789  Val_Acc: 98.602

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.0474 Train_Acc: 98.839 Val_Loss: 0.0808  BEST VAL Loss: 0.0789  Val_Acc: 98.242

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.0469 Train_Acc: 98.845 Val_Loss: 0.0812  BEST VAL Loss: 0.0789  Val_Acc: 98.647

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.0463 Train_Acc: 99.025 Val_Loss: 0.0815  BEST VAL Loss: 0.0789  Val_Acc: 98.738

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.0458 Train_Acc: 98.963 Val_Loss: 0.0813  BEST VAL Loss: 0.0789  Val_Acc: 98.738

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.0452 Train_Acc: 99.053 Val_Loss: 0.0814  BEST VAL Loss: 0.0789  Val_Acc: 98.512

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.0448 Train_Acc: 98.929 Val_Loss: 0.0816  BEST VAL Loss: 0.0789  Val_Acc: 98.693

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.0443 Train_Acc: 99.014 Val_Loss: 0.0810  BEST VAL Loss: 0.0789  Val_Acc: 98.557

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.0438 Train_Acc: 99.110 Val_Loss: 0.0806  BEST VAL Loss: 0.0789  Val_Acc: 98.557

Epoch 45: Validation loss did not decrease
Early stopped at epoch : 45
LPS_100.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.56      0.57      0.56      9891
           1       0.45      0.44      0.44      7852

    accuracy                           0.51     17743
   macro avg       0.50      0.50      0.50     17743
weighted avg       0.51      0.51      0.51     17743

LPS_100.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.56      0.56      1237
           1       0.44      0.43      0.43       981

    accuracy                           0.50      2218
   macro avg       0.49      0.49      0.49      2218
weighted avg       0.50      0.50      0.50      2218

LPS_100.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.56      0.57      0.56      1237
           1       0.45      0.44      0.44       981

    accuracy                           0.51      2218
   macro avg       0.50      0.50      0.50      2218
weighted avg       0.51      0.51      0.51      2218

              precision    recall  f1-score   support

           0       0.56      0.57      0.56      1237
           1       0.45      0.44      0.44       981

    accuracy                           0.51      2218
   macro avg       0.50      0.50      0.50      2218
weighted avg       0.51      0.51      0.51      2218

LPS_100.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.50      0.51      3622
           1       0.48      0.50      0.49      3398

    accuracy                           0.50      7020
   macro avg       0.50      0.50      0.50      7020
weighted avg       0.50      0.50      0.50      7020

              precision    recall  f1-score   support

           0       0.52      0.50      0.51      3622
           1       0.48      0.50      0.49      3398

    accuracy                           0.50      7020
   macro avg       0.50      0.50      0.50      7020
weighted avg       0.50      0.50      0.50      7020

completed
