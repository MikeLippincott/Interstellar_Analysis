[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ef588861'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'a4902be2'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '50490838'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '3b34c3fa'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (33728, 1276)
Number of total missing values across all columns: 35020
Data Subset Is Off
Wells held out for testing: ['C20' 'K16']
Wells to use for training, validation, and testing ['C16' 'C17' 'C21' 'K17' 'K20' 'K21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.466726).  Saving model ...
	 Train_Loss: 0.5678 Train_Acc: 70.054 Val_Loss: 0.4667  BEST VAL Loss: 0.4667  Val_Acc: 82.815

Epoch 1: Validation loss decreased (0.466726 --> 0.436235).  Saving model ...
	 Train_Loss: 0.5199 Train_Acc: 77.957 Val_Loss: 0.4362  BEST VAL Loss: 0.4362  Val_Acc: 84.091

Epoch 2: Validation loss decreased (0.436235 --> 0.405070).  Saving model ...
	 Train_Loss: 0.4850 Train_Acc: 80.908 Val_Loss: 0.4051  BEST VAL Loss: 0.4051  Val_Acc: 88.078

Epoch 3: Validation loss decreased (0.405070 --> 0.380031).  Saving model ...
	 Train_Loss: 0.4564 Train_Acc: 83.252 Val_Loss: 0.3800  BEST VAL Loss: 0.3800  Val_Acc: 89.633

Epoch 4: Validation loss decreased (0.380031 --> 0.360059).  Saving model ...
	 Train_Loss: 0.4349 Train_Acc: 84.015 Val_Loss: 0.3601  BEST VAL Loss: 0.3601  Val_Acc: 90.351

Epoch 5: Validation loss decreased (0.360059 --> 0.343279).  Saving model ...
	 Train_Loss: 0.4163 Train_Acc: 85.491 Val_Loss: 0.3433  BEST VAL Loss: 0.3433  Val_Acc: 91.268

Epoch 6: Validation loss decreased (0.343279 --> 0.328528).  Saving model ...
	 Train_Loss: 0.4001 Train_Acc: 86.378 Val_Loss: 0.3285  BEST VAL Loss: 0.3285  Val_Acc: 91.826

Epoch 7: Validation loss decreased (0.328528 --> 0.317248).  Saving model ...
	 Train_Loss: 0.3864 Train_Acc: 86.852 Val_Loss: 0.3172  BEST VAL Loss: 0.3172  Val_Acc: 92.185

Epoch 8: Validation loss decreased (0.317248 --> 0.305973).  Saving model ...
	 Train_Loss: 0.3742 Train_Acc: 87.495 Val_Loss: 0.3060  BEST VAL Loss: 0.3060  Val_Acc: 93.062

Epoch 9: Validation loss decreased (0.305973 --> 0.295786).  Saving model ...
	 Train_Loss: 0.3631 Train_Acc: 87.829 Val_Loss: 0.2958  BEST VAL Loss: 0.2958  Val_Acc: 92.982

Epoch 10: Validation loss decreased (0.295786 --> 0.287031).  Saving model ...
	 Train_Loss: 0.3532 Train_Acc: 88.722 Val_Loss: 0.2870  BEST VAL Loss: 0.2870  Val_Acc: 92.982

Epoch 11: Validation loss decreased (0.287031 --> 0.279046).  Saving model ...
	 Train_Loss: 0.3446 Train_Acc: 88.647 Val_Loss: 0.2790  BEST VAL Loss: 0.2790  Val_Acc: 93.660

Epoch 12: Validation loss decreased (0.279046 --> 0.271602).  Saving model ...
	 Train_Loss: 0.3368 Train_Acc: 89.205 Val_Loss: 0.2716  BEST VAL Loss: 0.2716  Val_Acc: 93.979

Epoch 13: Validation loss decreased (0.271602 --> 0.264900).  Saving model ...
	 Train_Loss: 0.3293 Train_Acc: 89.789 Val_Loss: 0.2649  BEST VAL Loss: 0.2649  Val_Acc: 94.418

Epoch 14: Validation loss decreased (0.264900 --> 0.258643).  Saving model ...
	 Train_Loss: 0.3226 Train_Acc: 89.769 Val_Loss: 0.2586  BEST VAL Loss: 0.2586  Val_Acc: 94.298

Epoch 15: Validation loss decreased (0.258643 --> 0.252850).  Saving model ...
	 Train_Loss: 0.3164 Train_Acc: 90.043 Val_Loss: 0.2528  BEST VAL Loss: 0.2528  Val_Acc: 94.418

Epoch 16: Validation loss decreased (0.252850 --> 0.247666).  Saving model ...
	 Train_Loss: 0.3106 Train_Acc: 90.143 Val_Loss: 0.2477  BEST VAL Loss: 0.2477  Val_Acc: 94.338

Epoch 17: Validation loss decreased (0.247666 --> 0.242806).  Saving model ...
	 Train_Loss: 0.3048 Train_Acc: 90.691 Val_Loss: 0.2428  BEST VAL Loss: 0.2428  Val_Acc: 94.577

Epoch 18: Validation loss decreased (0.242806 --> 0.238456).  Saving model ...
	 Train_Loss: 0.2998 Train_Acc: 90.302 Val_Loss: 0.2385  BEST VAL Loss: 0.2385  Val_Acc: 94.338

Epoch 19: Validation loss decreased (0.238456 --> 0.234199).  Saving model ...
	 Train_Loss: 0.2951 Train_Acc: 90.551 Val_Loss: 0.2342  BEST VAL Loss: 0.2342  Val_Acc: 95.056

Epoch 20: Validation loss decreased (0.234199 --> 0.230123).  Saving model ...
	 Train_Loss: 0.2903 Train_Acc: 90.861 Val_Loss: 0.2301  BEST VAL Loss: 0.2301  Val_Acc: 95.215

Epoch 21: Validation loss decreased (0.230123 --> 0.226402).  Saving model ...
	 Train_Loss: 0.2859 Train_Acc: 91.070 Val_Loss: 0.2264  BEST VAL Loss: 0.2264  Val_Acc: 95.016

Epoch 22: Validation loss decreased (0.226402 --> 0.222968).  Saving model ...
	 Train_Loss: 0.2819 Train_Acc: 91.035 Val_Loss: 0.2230  BEST VAL Loss: 0.2230  Val_Acc: 94.896

Epoch 23: Validation loss decreased (0.222968 --> 0.219602).  Saving model ...
	 Train_Loss: 0.2778 Train_Acc: 91.454 Val_Loss: 0.2196  BEST VAL Loss: 0.2196  Val_Acc: 95.255

Epoch 24: Validation loss decreased (0.219602 --> 0.216518).  Saving model ...
	 Train_Loss: 0.2742 Train_Acc: 91.459 Val_Loss: 0.2165  BEST VAL Loss: 0.2165  Val_Acc: 95.654

Epoch 25: Validation loss decreased (0.216518 --> 0.213650).  Saving model ...
	 Train_Loss: 0.2706 Train_Acc: 91.703 Val_Loss: 0.2136  BEST VAL Loss: 0.2136  Val_Acc: 95.175

Epoch 26: Validation loss decreased (0.213650 --> 0.211001).  Saving model ...
	 Train_Loss: 0.2674 Train_Acc: 91.524 Val_Loss: 0.2110  BEST VAL Loss: 0.2110  Val_Acc: 95.215

Epoch 27: Validation loss decreased (0.211001 --> 0.208360).  Saving model ...
	 Train_Loss: 0.2644 Train_Acc: 91.264 Val_Loss: 0.2084  BEST VAL Loss: 0.2084  Val_Acc: 95.694

Epoch 28: Validation loss decreased (0.208360 --> 0.205835).  Saving model ...
	 Train_Loss: 0.2613 Train_Acc: 91.813 Val_Loss: 0.2058  BEST VAL Loss: 0.2058  Val_Acc: 95.694

Epoch 29: Validation loss decreased (0.205835 --> 0.203538).  Saving model ...
	 Train_Loss: 0.2583 Train_Acc: 91.838 Val_Loss: 0.2035  BEST VAL Loss: 0.2035  Val_Acc: 95.455

Epoch 30: Validation loss decreased (0.203538 --> 0.201354).  Saving model ...
	 Train_Loss: 0.2556 Train_Acc: 91.534 Val_Loss: 0.2014  BEST VAL Loss: 0.2014  Val_Acc: 95.455

Epoch 31: Validation loss decreased (0.201354 --> 0.199227).  Saving model ...
	 Train_Loss: 0.2529 Train_Acc: 91.903 Val_Loss: 0.1992  BEST VAL Loss: 0.1992  Val_Acc: 95.654

Epoch 32: Validation loss decreased (0.199227 --> 0.197156).  Saving model ...
	 Train_Loss: 0.2503 Train_Acc: 91.977 Val_Loss: 0.1972  BEST VAL Loss: 0.1972  Val_Acc: 95.734

Epoch 33: Validation loss decreased (0.197156 --> 0.195167).  Saving model ...
	 Train_Loss: 0.2479 Train_Acc: 91.828 Val_Loss: 0.1952  BEST VAL Loss: 0.1952  Val_Acc: 95.853

Epoch 34: Validation loss decreased (0.195167 --> 0.193413).  Saving model ...
	 Train_Loss: 0.2456 Train_Acc: 92.217 Val_Loss: 0.1934  BEST VAL Loss: 0.1934  Val_Acc: 95.455

Epoch 35: Validation loss decreased (0.193413 --> 0.191603).  Saving model ...
	 Train_Loss: 0.2435 Train_Acc: 91.858 Val_Loss: 0.1916  BEST VAL Loss: 0.1916  Val_Acc: 96.292

Epoch 36: Validation loss decreased (0.191603 --> 0.189829).  Saving model ...
	 Train_Loss: 0.2412 Train_Acc: 92.336 Val_Loss: 0.1898  BEST VAL Loss: 0.1898  Val_Acc: 96.053

Epoch 37: Validation loss decreased (0.189829 --> 0.188199).  Saving model ...
	 Train_Loss: 0.2390 Train_Acc: 92.536 Val_Loss: 0.1882  BEST VAL Loss: 0.1882  Val_Acc: 96.053

Epoch 38: Validation loss decreased (0.188199 --> 0.186601).  Saving model ...
	 Train_Loss: 0.2369 Train_Acc: 92.576 Val_Loss: 0.1866  BEST VAL Loss: 0.1866  Val_Acc: 95.973

Epoch 39: Validation loss decreased (0.186601 --> 0.185037).  Saving model ...
	 Train_Loss: 0.2350 Train_Acc: 92.312 Val_Loss: 0.1850  BEST VAL Loss: 0.1850  Val_Acc: 96.212

Epoch 40: Validation loss decreased (0.185037 --> 0.183582).  Saving model ...
	 Train_Loss: 0.2331 Train_Acc: 92.202 Val_Loss: 0.1836  BEST VAL Loss: 0.1836  Val_Acc: 96.013

Epoch 41: Validation loss decreased (0.183582 --> 0.182183).  Saving model ...
	 Train_Loss: 0.2312 Train_Acc: 92.671 Val_Loss: 0.1822  BEST VAL Loss: 0.1822  Val_Acc: 96.093

Epoch 42: Validation loss decreased (0.182183 --> 0.180813).  Saving model ...
	 Train_Loss: 0.2293 Train_Acc: 92.386 Val_Loss: 0.1808  BEST VAL Loss: 0.1808  Val_Acc: 95.813

Epoch 43: Validation loss decreased (0.180813 --> 0.179469).  Saving model ...
	 Train_Loss: 0.2276 Train_Acc: 92.481 Val_Loss: 0.1795  BEST VAL Loss: 0.1795  Val_Acc: 96.292

Epoch 44: Validation loss decreased (0.179469 --> 0.178211).  Saving model ...
	 Train_Loss: 0.2259 Train_Acc: 92.566 Val_Loss: 0.1782  BEST VAL Loss: 0.1782  Val_Acc: 96.172

Epoch 45: Validation loss decreased (0.178211 --> 0.177003).  Saving model ...
	 Train_Loss: 0.2243 Train_Acc: 92.571 Val_Loss: 0.1770  BEST VAL Loss: 0.1770  Val_Acc: 96.172

Epoch 46: Validation loss decreased (0.177003 --> 0.175848).  Saving model ...
	 Train_Loss: 0.2226 Train_Acc: 92.820 Val_Loss: 0.1758  BEST VAL Loss: 0.1758  Val_Acc: 96.132

Epoch 47: Validation loss decreased (0.175848 --> 0.174786).  Saving model ...
	 Train_Loss: 0.2211 Train_Acc: 92.596 Val_Loss: 0.1748  BEST VAL Loss: 0.1748  Val_Acc: 96.013

Epoch 48: Validation loss decreased (0.174786 --> 0.173735).  Saving model ...
	 Train_Loss: 0.2196 Train_Acc: 92.715 Val_Loss: 0.1737  BEST VAL Loss: 0.1737  Val_Acc: 95.933

Epoch 49: Validation loss decreased (0.173735 --> 0.172693).  Saving model ...
	 Train_Loss: 0.2181 Train_Acc: 92.720 Val_Loss: 0.1727  BEST VAL Loss: 0.1727  Val_Acc: 95.973

Epoch 50: Validation loss decreased (0.172693 --> 0.171720).  Saving model ...
	 Train_Loss: 0.2166 Train_Acc: 92.695 Val_Loss: 0.1717  BEST VAL Loss: 0.1717  Val_Acc: 96.132

Epoch 51: Validation loss decreased (0.171720 --> 0.170756).  Saving model ...
	 Train_Loss: 0.2152 Train_Acc: 92.940 Val_Loss: 0.1708  BEST VAL Loss: 0.1708  Val_Acc: 96.332

Epoch 52: Validation loss decreased (0.170756 --> 0.169813).  Saving model ...
	 Train_Loss: 0.2138 Train_Acc: 92.885 Val_Loss: 0.1698  BEST VAL Loss: 0.1698  Val_Acc: 96.451

Epoch 53: Validation loss decreased (0.169813 --> 0.168980).  Saving model ...
	 Train_Loss: 0.2125 Train_Acc: 92.646 Val_Loss: 0.1690  BEST VAL Loss: 0.1690  Val_Acc: 96.332

Epoch 54: Validation loss decreased (0.168980 --> 0.168064).  Saving model ...
	 Train_Loss: 0.2112 Train_Acc: 92.636 Val_Loss: 0.1681  BEST VAL Loss: 0.1681  Val_Acc: 96.212

Epoch 55: Validation loss decreased (0.168064 --> 0.167454).  Saving model ...
	 Train_Loss: 0.2100 Train_Acc: 92.676 Val_Loss: 0.1675  BEST VAL Loss: 0.1675  Val_Acc: 95.893

Epoch 56: Validation loss decreased (0.167454 --> 0.166652).  Saving model ...
	 Train_Loss: 0.2087 Train_Acc: 92.960 Val_Loss: 0.1667  BEST VAL Loss: 0.1667  Val_Acc: 96.093

Epoch 57: Validation loss decreased (0.166652 --> 0.165899).  Saving model ...
	 Train_Loss: 0.2075 Train_Acc: 92.875 Val_Loss: 0.1659  BEST VAL Loss: 0.1659  Val_Acc: 96.053

Epoch 58: Validation loss decreased (0.165899 --> 0.165100).  Saving model ...
	 Train_Loss: 0.2064 Train_Acc: 92.825 Val_Loss: 0.1651  BEST VAL Loss: 0.1651  Val_Acc: 96.332

Epoch 59: Validation loss decreased (0.165100 --> 0.164305).  Saving model ...
	 Train_Loss: 0.2052 Train_Acc: 92.935 Val_Loss: 0.1643  BEST VAL Loss: 0.1643  Val_Acc: 96.013

Epoch 60: Validation loss decreased (0.164305 --> 0.163637).  Saving model ...
	 Train_Loss: 0.2040 Train_Acc: 92.980 Val_Loss: 0.1636  BEST VAL Loss: 0.1636  Val_Acc: 96.332

Epoch 61: Validation loss decreased (0.163637 --> 0.162909).  Saving model ...
	 Train_Loss: 0.2029 Train_Acc: 92.830 Val_Loss: 0.1629  BEST VAL Loss: 0.1629  Val_Acc: 96.172

Epoch 62: Validation loss decreased (0.162909 --> 0.162218).  Saving model ...
	 Train_Loss: 0.2018 Train_Acc: 93.244 Val_Loss: 0.1622  BEST VAL Loss: 0.1622  Val_Acc: 96.292

Epoch 63: Validation loss decreased (0.162218 --> 0.161500).  Saving model ...
	 Train_Loss: 0.2007 Train_Acc: 92.945 Val_Loss: 0.1615  BEST VAL Loss: 0.1615  Val_Acc: 96.172

Epoch 64: Validation loss decreased (0.161500 --> 0.160799).  Saving model ...
	 Train_Loss: 0.1997 Train_Acc: 93.219 Val_Loss: 0.1608  BEST VAL Loss: 0.1608  Val_Acc: 96.252

Epoch 65: Validation loss decreased (0.160799 --> 0.160160).  Saving model ...
	 Train_Loss: 0.1987 Train_Acc: 93.079 Val_Loss: 0.1602  BEST VAL Loss: 0.1602  Val_Acc: 96.252

Epoch 66: Validation loss decreased (0.160160 --> 0.159497).  Saving model ...
	 Train_Loss: 0.1977 Train_Acc: 93.224 Val_Loss: 0.1595  BEST VAL Loss: 0.1595  Val_Acc: 96.332

Epoch 67: Validation loss decreased (0.159497 --> 0.158856).  Saving model ...
	 Train_Loss: 0.1966 Train_Acc: 93.344 Val_Loss: 0.1589  BEST VAL Loss: 0.1589  Val_Acc: 96.411

Epoch 68: Validation loss decreased (0.158856 --> 0.158255).  Saving model ...
	 Train_Loss: 0.1957 Train_Acc: 93.179 Val_Loss: 0.1583  BEST VAL Loss: 0.1583  Val_Acc: 96.252

Epoch 69: Validation loss decreased (0.158255 --> 0.157698).  Saving model ...
	 Train_Loss: 0.1947 Train_Acc: 93.289 Val_Loss: 0.1577  BEST VAL Loss: 0.1577  Val_Acc: 96.252

Epoch 70: Validation loss decreased (0.157698 --> 0.157116).  Saving model ...
	 Train_Loss: 0.1937 Train_Acc: 93.189 Val_Loss: 0.1571  BEST VAL Loss: 0.1571  Val_Acc: 96.252

Epoch 71: Validation loss decreased (0.157116 --> 0.156552).  Saving model ...
	 Train_Loss: 0.1928 Train_Acc: 93.184 Val_Loss: 0.1566  BEST VAL Loss: 0.1566  Val_Acc: 95.973

Epoch 72: Validation loss decreased (0.156552 --> 0.156014).  Saving model ...
	 Train_Loss: 0.1919 Train_Acc: 93.164 Val_Loss: 0.1560  BEST VAL Loss: 0.1560  Val_Acc: 96.252

Epoch 73: Validation loss decreased (0.156014 --> 0.155507).  Saving model ...
	 Train_Loss: 0.1910 Train_Acc: 93.124 Val_Loss: 0.1555  BEST VAL Loss: 0.1555  Val_Acc: 96.451

Epoch 74: Validation loss decreased (0.155507 --> 0.154986).  Saving model ...
	 Train_Loss: 0.1901 Train_Acc: 93.239 Val_Loss: 0.1550  BEST VAL Loss: 0.1550  Val_Acc: 96.292

Epoch 75: Validation loss decreased (0.154986 --> 0.154446).  Saving model ...
	 Train_Loss: 0.1892 Train_Acc: 93.374 Val_Loss: 0.1544  BEST VAL Loss: 0.1544  Val_Acc: 96.451

Epoch 76: Validation loss decreased (0.154446 --> 0.154084).  Saving model ...
	 Train_Loss: 0.1884 Train_Acc: 93.229 Val_Loss: 0.1541  BEST VAL Loss: 0.1541  Val_Acc: 96.093

Epoch 77: Validation loss decreased (0.154084 --> 0.153603).  Saving model ...
	 Train_Loss: 0.1877 Train_Acc: 92.720 Val_Loss: 0.1536  BEST VAL Loss: 0.1536  Val_Acc: 96.332

Epoch 78: Validation loss decreased (0.153603 --> 0.153128).  Saving model ...
	 Train_Loss: 0.1869 Train_Acc: 92.875 Val_Loss: 0.1531  BEST VAL Loss: 0.1531  Val_Acc: 96.093

Epoch 79: Validation loss decreased (0.153128 --> 0.152668).  Saving model ...
	 Train_Loss: 0.1861 Train_Acc: 93.239 Val_Loss: 0.1527  BEST VAL Loss: 0.1527  Val_Acc: 96.372

Epoch 80: Validation loss decreased (0.152668 --> 0.152183).  Saving model ...
	 Train_Loss: 0.1852 Train_Acc: 93.259 Val_Loss: 0.1522  BEST VAL Loss: 0.1522  Val_Acc: 96.491

Epoch 81: Validation loss decreased (0.152183 --> 0.151734).  Saving model ...
	 Train_Loss: 0.1845 Train_Acc: 93.015 Val_Loss: 0.1517  BEST VAL Loss: 0.1517  Val_Acc: 96.172

Epoch 82: Validation loss decreased (0.151734 --> 0.151317).  Saving model ...
	 Train_Loss: 0.1837 Train_Acc: 93.339 Val_Loss: 0.1513  BEST VAL Loss: 0.1513  Val_Acc: 96.212

Epoch 83: Validation loss decreased (0.151317 --> 0.150888).  Saving model ...
	 Train_Loss: 0.1829 Train_Acc: 93.264 Val_Loss: 0.1509  BEST VAL Loss: 0.1509  Val_Acc: 96.491

Epoch 84: Validation loss decreased (0.150888 --> 0.150523).  Saving model ...
	 Train_Loss: 0.1822 Train_Acc: 93.209 Val_Loss: 0.1505  BEST VAL Loss: 0.1505  Val_Acc: 96.252

Epoch 85: Validation loss decreased (0.150523 --> 0.150096).  Saving model ...
	 Train_Loss: 0.1815 Train_Acc: 93.114 Val_Loss: 0.1501  BEST VAL Loss: 0.1501  Val_Acc: 96.332

Epoch 86: Validation loss decreased (0.150096 --> 0.149659).  Saving model ...
	 Train_Loss: 0.1808 Train_Acc: 93.209 Val_Loss: 0.1497  BEST VAL Loss: 0.1497  Val_Acc: 96.332

Epoch 87: Validation loss decreased (0.149659 --> 0.149257).  Saving model ...
	 Train_Loss: 0.1801 Train_Acc: 93.025 Val_Loss: 0.1493  BEST VAL Loss: 0.1493  Val_Acc: 96.292

Epoch 88: Validation loss decreased (0.149257 --> 0.149040).  Saving model ...
	 Train_Loss: 0.1794 Train_Acc: 93.264 Val_Loss: 0.1490  BEST VAL Loss: 0.1490  Val_Acc: 96.252

Epoch 89: Validation loss decreased (0.149040 --> 0.148631).  Saving model ...
	 Train_Loss: 0.1787 Train_Acc: 93.199 Val_Loss: 0.1486  BEST VAL Loss: 0.1486  Val_Acc: 96.332

Epoch 90: Validation loss decreased (0.148631 --> 0.148228).  Saving model ...
	 Train_Loss: 0.1780 Train_Acc: 93.369 Val_Loss: 0.1482  BEST VAL Loss: 0.1482  Val_Acc: 96.212

Epoch 91: Validation loss decreased (0.148228 --> 0.147867).  Saving model ...
	 Train_Loss: 0.1773 Train_Acc: 93.668 Val_Loss: 0.1479  BEST VAL Loss: 0.1479  Val_Acc: 96.372

Epoch 92: Validation loss decreased (0.147867 --> 0.147535).  Saving model ...
	 Train_Loss: 0.1767 Train_Acc: 93.384 Val_Loss: 0.1475  BEST VAL Loss: 0.1475  Val_Acc: 96.332

Epoch 93: Validation loss decreased (0.147535 --> 0.147189).  Saving model ...
	 Train_Loss: 0.1760 Train_Acc: 93.229 Val_Loss: 0.1472  BEST VAL Loss: 0.1472  Val_Acc: 96.372

Epoch 94: Validation loss decreased (0.147189 --> 0.146817).  Saving model ...
	 Train_Loss: 0.1753 Train_Acc: 93.837 Val_Loss: 0.1468  BEST VAL Loss: 0.1468  Val_Acc: 96.292

Epoch 95: Validation loss decreased (0.146817 --> 0.146441).  Saving model ...
	 Train_Loss: 0.1746 Train_Acc: 93.369 Val_Loss: 0.1464  BEST VAL Loss: 0.1464  Val_Acc: 96.332

Epoch 96: Validation loss decreased (0.146441 --> 0.146096).  Saving model ...
	 Train_Loss: 0.1740 Train_Acc: 93.389 Val_Loss: 0.1461  BEST VAL Loss: 0.1461  Val_Acc: 96.491

Epoch 97: Validation loss decreased (0.146096 --> 0.145795).  Saving model ...
	 Train_Loss: 0.1734 Train_Acc: 93.443 Val_Loss: 0.1458  BEST VAL Loss: 0.1458  Val_Acc: 96.372

Epoch 98: Validation loss decreased (0.145795 --> 0.145434).  Saving model ...
	 Train_Loss: 0.1728 Train_Acc: 93.309 Val_Loss: 0.1454  BEST VAL Loss: 0.1454  Val_Acc: 96.531

Epoch 99: Validation loss decreased (0.145434 --> 0.145134).  Saving model ...
	 Train_Loss: 0.1722 Train_Acc: 93.548 Val_Loss: 0.1451  BEST VAL Loss: 0.1451  Val_Acc: 96.332

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      0.98      0.98     10452
           1       0.98      0.99      0.98      9604

    accuracy                           0.98     20056
   macro avg       0.98      0.98      0.98     20056
weighted avg       0.98      0.98      0.98     20056

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.96      0.96      1307
           1       0.95      0.97      0.96      1201

    accuracy                           0.96      2508
   macro avg       0.96      0.96      0.96      2508
weighted avg       0.96      0.96      0.96      2508

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.96      0.96      1306
           1       0.95      0.97      0.96      1201

    accuracy                           0.96      2507
   macro avg       0.96      0.96      0.96      2507
weighted avg       0.96      0.96      0.96      2507

              precision    recall  f1-score   support

           0       0.97      0.96      0.96      1306
           1       0.95      0.97      0.96      1201

    accuracy                           0.96      2507
   macro avg       0.96      0.96      0.96      2507
weighted avg       0.96      0.96      0.96      2507

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.97      0.97      4445
           1       0.97      0.97      0.97      4212

    accuracy                           0.97      8657
   macro avg       0.97      0.97      0.97      8657
weighted avg       0.97      0.97      0.97      8657

              precision    recall  f1-score   support

           0       0.97      0.97      0.97      4445
           1       0.97      0.97      0.97      4212

    accuracy                           0.97      8657
   macro avg       0.97      0.97      0.97      8657
weighted avg       0.97      0.97      0.97      8657

completed
