[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '94097eab'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'aa6cd090'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '25098a1c'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'a3e355fc'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: H2O2_100.000_DMSO_0.025 treatment_name: LPS_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: LPS_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (43358, 1276)
Number of total missing values across all columns: 86716
Data Subset Is Off
Wells held out for testing: ['D21' 'H22']
Wells to use for training, validation, and testing ['D16' 'D17' 'H18' 'H19' 'D20' 'H23' 'I18' 'I19' 'I22' 'I23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.608691).  Saving model ...
	 Train_Loss: 0.7263 Train_Acc: 65.994 Val_Loss: 0.6087  BEST VAL Loss: 0.6087  Val_Acc: 73.001

Epoch 1: Validation loss decreased (0.608691 --> 0.580487).  Saving model ...
	 Train_Loss: 0.6539 Train_Acc: 74.292 Val_Loss: 0.5805  BEST VAL Loss: 0.5805  Val_Acc: 76.574

Epoch 2: Validation loss decreased (0.580487 --> 0.560928).  Saving model ...
	 Train_Loss: 0.6172 Train_Acc: 76.171 Val_Loss: 0.5609  BEST VAL Loss: 0.5609  Val_Acc: 77.028

Epoch 3: Validation loss decreased (0.560928 --> 0.547283).  Saving model ...
	 Train_Loss: 0.5940 Train_Acc: 76.767 Val_Loss: 0.5473  BEST VAL Loss: 0.5473  Val_Acc: 78.219

Epoch 4: Validation loss decreased (0.547283 --> 0.538389).  Saving model ...
	 Train_Loss: 0.5778 Train_Acc: 77.203 Val_Loss: 0.5384  BEST VAL Loss: 0.5384  Val_Acc: 77.822

Epoch 5: Validation loss decreased (0.538389 --> 0.531352).  Saving model ...
	 Train_Loss: 0.5654 Train_Acc: 77.586 Val_Loss: 0.5314  BEST VAL Loss: 0.5314  Val_Acc: 77.708

Epoch 6: Validation loss decreased (0.531352 --> 0.523569).  Saving model ...
	 Train_Loss: 0.5563 Train_Acc: 77.667 Val_Loss: 0.5236  BEST VAL Loss: 0.5236  Val_Acc: 78.673

Epoch 7: Validation loss decreased (0.523569 --> 0.517357).  Saving model ...
	 Train_Loss: 0.5482 Train_Acc: 78.026 Val_Loss: 0.5174  BEST VAL Loss: 0.5174  Val_Acc: 78.446

Epoch 8: Validation loss decreased (0.517357 --> 0.512455).  Saving model ...
	 Train_Loss: 0.5414 Train_Acc: 78.646 Val_Loss: 0.5125  BEST VAL Loss: 0.5125  Val_Acc: 79.013

Epoch 9: Validation loss decreased (0.512455 --> 0.508472).  Saving model ...
	 Train_Loss: 0.5358 Train_Acc: 78.728 Val_Loss: 0.5085  BEST VAL Loss: 0.5085  Val_Acc: 78.928

Epoch 10: Validation loss decreased (0.508472 --> 0.505272).  Saving model ...
	 Train_Loss: 0.5306 Train_Acc: 79.089 Val_Loss: 0.5053  BEST VAL Loss: 0.5053  Val_Acc: 78.815

Epoch 11: Validation loss decreased (0.505272 --> 0.501877).  Saving model ...
	 Train_Loss: 0.5262 Train_Acc: 79.288 Val_Loss: 0.5019  BEST VAL Loss: 0.5019  Val_Acc: 79.552

Epoch 12: Validation loss decreased (0.501877 --> 0.498730).  Saving model ...
	 Train_Loss: 0.5221 Train_Acc: 79.501 Val_Loss: 0.4987  BEST VAL Loss: 0.4987  Val_Acc: 79.807

Epoch 13: Validation loss decreased (0.498730 --> 0.495835).  Saving model ...
	 Train_Loss: 0.5190 Train_Acc: 79.242 Val_Loss: 0.4958  BEST VAL Loss: 0.4958  Val_Acc: 79.949

Epoch 14: Validation loss decreased (0.495835 --> 0.493359).  Saving model ...
	 Train_Loss: 0.5161 Train_Acc: 79.221 Val_Loss: 0.4934  BEST VAL Loss: 0.4934  Val_Acc: 79.495

Epoch 15: Validation loss decreased (0.493359 --> 0.490777).  Saving model ...
	 Train_Loss: 0.5130 Train_Acc: 79.671 Val_Loss: 0.4908  BEST VAL Loss: 0.4908  Val_Acc: 79.864

Epoch 16: Validation loss decreased (0.490777 --> 0.488714).  Saving model ...
	 Train_Loss: 0.5102 Train_Acc: 79.990 Val_Loss: 0.4887  BEST VAL Loss: 0.4887  Val_Acc: 79.750

Epoch 17: Validation loss decreased (0.488714 --> 0.486729).  Saving model ...
	 Train_Loss: 0.5078 Train_Acc: 79.586 Val_Loss: 0.4867  BEST VAL Loss: 0.4867  Val_Acc: 79.410

Epoch 18: Validation loss decreased (0.486729 --> 0.484975).  Saving model ...
	 Train_Loss: 0.5056 Train_Acc: 79.884 Val_Loss: 0.4850  BEST VAL Loss: 0.4850  Val_Acc: 80.488

Epoch 19: Validation loss decreased (0.484975 --> 0.483012).  Saving model ...
	 Train_Loss: 0.5036 Train_Acc: 80.185 Val_Loss: 0.4830  BEST VAL Loss: 0.4830  Val_Acc: 79.977

Epoch 20: Validation loss decreased (0.483012 --> 0.481359).  Saving model ...
	 Train_Loss: 0.5015 Train_Acc: 80.263 Val_Loss: 0.4814  BEST VAL Loss: 0.4814  Val_Acc: 79.836

Epoch 21: Validation loss decreased (0.481359 --> 0.480002).  Saving model ...
	 Train_Loss: 0.4996 Train_Acc: 80.160 Val_Loss: 0.4800  BEST VAL Loss: 0.4800  Val_Acc: 80.091

Epoch 22: Validation loss decreased (0.480002 --> 0.478578).  Saving model ...
	 Train_Loss: 0.4977 Train_Acc: 80.504 Val_Loss: 0.4786  BEST VAL Loss: 0.4786  Val_Acc: 80.800

Epoch 23: Validation loss decreased (0.478578 --> 0.477365).  Saving model ...
	 Train_Loss: 0.4959 Train_Acc: 80.713 Val_Loss: 0.4774  BEST VAL Loss: 0.4774  Val_Acc: 80.119

Epoch 24: Validation loss decreased (0.477365 --> 0.476334).  Saving model ...
	 Train_Loss: 0.4945 Train_Acc: 80.174 Val_Loss: 0.4763  BEST VAL Loss: 0.4763  Val_Acc: 80.318

Epoch 25: Validation loss decreased (0.476334 --> 0.475199).  Saving model ...
	 Train_Loss: 0.4930 Train_Acc: 80.742 Val_Loss: 0.4752  BEST VAL Loss: 0.4752  Val_Acc: 80.715

Epoch 26: Validation loss decreased (0.475199 --> 0.474066).  Saving model ...
	 Train_Loss: 0.4914 Train_Acc: 80.625 Val_Loss: 0.4741  BEST VAL Loss: 0.4741  Val_Acc: 80.459

Epoch 27: Validation loss decreased (0.474066 --> 0.473216).  Saving model ...
	 Train_Loss: 0.4901 Train_Acc: 80.880 Val_Loss: 0.4732  BEST VAL Loss: 0.4732  Val_Acc: 80.545

Epoch 28: Validation loss decreased (0.473216 --> 0.472174).  Saving model ...
	 Train_Loss: 0.4888 Train_Acc: 80.916 Val_Loss: 0.4722  BEST VAL Loss: 0.4722  Val_Acc: 80.459

Epoch 29: Validation loss decreased (0.472174 --> 0.470907).  Saving model ...
	 Train_Loss: 0.4875 Train_Acc: 80.628 Val_Loss: 0.4709  BEST VAL Loss: 0.4709  Val_Acc: 81.027

Epoch 30: Validation loss decreased (0.470907 --> 0.469914).  Saving model ...
	 Train_Loss: 0.4863 Train_Acc: 80.916 Val_Loss: 0.4699  BEST VAL Loss: 0.4699  Val_Acc: 80.771

Epoch 31: Validation loss decreased (0.469914 --> 0.469025).  Saving model ...
	 Train_Loss: 0.4852 Train_Acc: 81.011 Val_Loss: 0.4690  BEST VAL Loss: 0.4690  Val_Acc: 80.800

Epoch 32: Validation loss decreased (0.469025 --> 0.468134).  Saving model ...
	 Train_Loss: 0.4842 Train_Acc: 80.855 Val_Loss: 0.4681  BEST VAL Loss: 0.4681  Val_Acc: 81.197

Epoch 33: Validation loss decreased (0.468134 --> 0.467320).  Saving model ...
	 Train_Loss: 0.4832 Train_Acc: 81.015 Val_Loss: 0.4673  BEST VAL Loss: 0.4673  Val_Acc: 81.140

Epoch 34: Validation loss decreased (0.467320 --> 0.466579).  Saving model ...
	 Train_Loss: 0.4820 Train_Acc: 81.171 Val_Loss: 0.4666  BEST VAL Loss: 0.4666  Val_Acc: 80.856

Epoch 35: Validation loss decreased (0.466579 --> 0.465922).  Saving model ...
	 Train_Loss: 0.4810 Train_Acc: 81.004 Val_Loss: 0.4659  BEST VAL Loss: 0.4659  Val_Acc: 81.282

Epoch 36: Validation loss decreased (0.465922 --> 0.465416).  Saving model ...
	 Train_Loss: 0.4800 Train_Acc: 81.430 Val_Loss: 0.4654  BEST VAL Loss: 0.4654  Val_Acc: 80.913

Epoch 37: Validation loss decreased (0.465416 --> 0.464933).  Saving model ...
	 Train_Loss: 0.4791 Train_Acc: 81.611 Val_Loss: 0.4649  BEST VAL Loss: 0.4649  Val_Acc: 80.459

Epoch 38: Validation loss decreased (0.464933 --> 0.464390).  Saving model ...
	 Train_Loss: 0.4784 Train_Acc: 80.713 Val_Loss: 0.4644  BEST VAL Loss: 0.4644  Val_Acc: 81.168

Epoch 39: Validation loss decreased (0.464390 --> 0.463861).  Saving model ...
	 Train_Loss: 0.4775 Train_Acc: 81.171 Val_Loss: 0.4639  BEST VAL Loss: 0.4639  Val_Acc: 80.800

Epoch 40: Validation loss decreased (0.463861 --> 0.463349).  Saving model ...
	 Train_Loss: 0.4767 Train_Acc: 81.419 Val_Loss: 0.4633  BEST VAL Loss: 0.4633  Val_Acc: 81.509

Epoch 41: Validation loss decreased (0.463349 --> 0.462946).  Saving model ...
	 Train_Loss: 0.4759 Train_Acc: 81.472 Val_Loss: 0.4629  BEST VAL Loss: 0.4629  Val_Acc: 81.197

Epoch 42: Validation loss decreased (0.462946 --> 0.462390).  Saving model ...
	 Train_Loss: 0.4751 Train_Acc: 81.423 Val_Loss: 0.4624  BEST VAL Loss: 0.4624  Val_Acc: 81.027

Epoch 43: Validation loss decreased (0.462390 --> 0.461691).  Saving model ...
	 Train_Loss: 0.4743 Train_Acc: 81.614 Val_Loss: 0.4617  BEST VAL Loss: 0.4617  Val_Acc: 81.310

Epoch 44: Validation loss decreased (0.461691 --> 0.461202).  Saving model ...
	 Train_Loss: 0.4736 Train_Acc: 81.522 Val_Loss: 0.4612  BEST VAL Loss: 0.4612  Val_Acc: 81.424

Epoch 45: Validation loss decreased (0.461202 --> 0.460815).  Saving model ...
	 Train_Loss: 0.4729 Train_Acc: 81.426 Val_Loss: 0.4608  BEST VAL Loss: 0.4608  Val_Acc: 81.395

Epoch 46: Validation loss decreased (0.460815 --> 0.460388).  Saving model ...
	 Train_Loss: 0.4722 Train_Acc: 81.724 Val_Loss: 0.4604  BEST VAL Loss: 0.4604  Val_Acc: 81.764

Epoch 47: Validation loss decreased (0.460388 --> 0.460023).  Saving model ...
	 Train_Loss: 0.4716 Train_Acc: 81.625 Val_Loss: 0.4600  BEST VAL Loss: 0.4600  Val_Acc: 81.055

Epoch 48: Validation loss decreased (0.460023 --> 0.459512).  Saving model ...
	 Train_Loss: 0.4710 Train_Acc: 81.628 Val_Loss: 0.4595  BEST VAL Loss: 0.4595  Val_Acc: 81.055

Epoch 49: Validation loss decreased (0.459512 --> 0.459296).  Saving model ...
	 Train_Loss: 0.4703 Train_Acc: 81.557 Val_Loss: 0.4593  BEST VAL Loss: 0.4593  Val_Acc: 81.339

Epoch 50: Validation loss decreased (0.459296 --> 0.458934).  Saving model ...
	 Train_Loss: 0.4696 Train_Acc: 81.738 Val_Loss: 0.4589  BEST VAL Loss: 0.4589  Val_Acc: 81.339

Epoch 51: Validation loss decreased (0.458934 --> 0.458707).  Saving model ...
	 Train_Loss: 0.4690 Train_Acc: 82.100 Val_Loss: 0.4587  BEST VAL Loss: 0.4587  Val_Acc: 80.885

Epoch 52: Validation loss decreased (0.458707 --> 0.458525).  Saving model ...
	 Train_Loss: 0.4684 Train_Acc: 81.926 Val_Loss: 0.4585  BEST VAL Loss: 0.4585  Val_Acc: 81.055

Epoch 53: Validation loss decreased (0.458525 --> 0.458113).  Saving model ...
	 Train_Loss: 0.4678 Train_Acc: 81.830 Val_Loss: 0.4581  BEST VAL Loss: 0.4581  Val_Acc: 80.743

Epoch 54: Validation loss decreased (0.458113 --> 0.457881).  Saving model ...
	 Train_Loss: 0.4673 Train_Acc: 81.767 Val_Loss: 0.4579  BEST VAL Loss: 0.4579  Val_Acc: 81.339

Epoch 55: Validation loss decreased (0.457881 --> 0.457635).  Saving model ...
	 Train_Loss: 0.4667 Train_Acc: 81.589 Val_Loss: 0.4576  BEST VAL Loss: 0.4576  Val_Acc: 81.509

Epoch 56: Validation loss decreased (0.457635 --> 0.457356).  Saving model ...
	 Train_Loss: 0.4662 Train_Acc: 81.813 Val_Loss: 0.4574  BEST VAL Loss: 0.4574  Val_Acc: 81.225

Epoch 57: Validation loss decreased (0.457356 --> 0.457042).  Saving model ...
	 Train_Loss: 0.4656 Train_Acc: 82.029 Val_Loss: 0.4570  BEST VAL Loss: 0.4570  Val_Acc: 81.452

Epoch 58: Validation loss decreased (0.457042 --> 0.457024).  Saving model ...
	 Train_Loss: 0.4651 Train_Acc: 82.330 Val_Loss: 0.4570  BEST VAL Loss: 0.4570  Val_Acc: 80.942

Epoch 59: Validation loss decreased (0.457024 --> 0.456759).  Saving model ...
	 Train_Loss: 0.4646 Train_Acc: 81.706 Val_Loss: 0.4568  BEST VAL Loss: 0.4568  Val_Acc: 81.452

Epoch 60: Validation loss decreased (0.456759 --> 0.456486).  Saving model ...
	 Train_Loss: 0.4641 Train_Acc: 81.972 Val_Loss: 0.4565  BEST VAL Loss: 0.4565  Val_Acc: 81.339

Epoch 61: Validation loss decreased (0.456486 --> 0.456240).  Saving model ...
	 Train_Loss: 0.4636 Train_Acc: 81.940 Val_Loss: 0.4562  BEST VAL Loss: 0.4562  Val_Acc: 81.566

Epoch 62: Validation loss decreased (0.456240 --> 0.456035).  Saving model ...
	 Train_Loss: 0.4631 Train_Acc: 81.788 Val_Loss: 0.4560  BEST VAL Loss: 0.4560  Val_Acc: 81.282

Epoch 63: Validation loss decreased (0.456035 --> 0.455913).  Saving model ...
	 Train_Loss: 0.4627 Train_Acc: 81.979 Val_Loss: 0.4559  BEST VAL Loss: 0.4559  Val_Acc: 81.225

Epoch 64: Validation loss decreased (0.455913 --> 0.455685).  Saving model ...
	 Train_Loss: 0.4622 Train_Acc: 82.291 Val_Loss: 0.4557  BEST VAL Loss: 0.4557  Val_Acc: 81.197

Epoch 65: Validation loss decreased (0.455685 --> 0.455458).  Saving model ...
	 Train_Loss: 0.4617 Train_Acc: 82.306 Val_Loss: 0.4555  BEST VAL Loss: 0.4555  Val_Acc: 81.537

Epoch 66: Validation loss decreased (0.455458 --> 0.455405).  Saving model ...
	 Train_Loss: 0.4612 Train_Acc: 82.238 Val_Loss: 0.4554  BEST VAL Loss: 0.4554  Val_Acc: 81.367

Epoch 67: Validation loss decreased (0.455405 --> 0.455186).  Saving model ...
	 Train_Loss: 0.4608 Train_Acc: 82.029 Val_Loss: 0.4552  BEST VAL Loss: 0.4552  Val_Acc: 81.821

Epoch 68: Validation loss decreased (0.455186 --> 0.455044).  Saving model ...
	 Train_Loss: 0.4605 Train_Acc: 82.022 Val_Loss: 0.4550  BEST VAL Loss: 0.4550  Val_Acc: 81.679

Epoch 69: Validation loss decreased (0.455044 --> 0.454959).  Saving model ...
	 Train_Loss: 0.4601 Train_Acc: 81.930 Val_Loss: 0.4550  BEST VAL Loss: 0.4550  Val_Acc: 80.545

Epoch 70: Validation loss decreased (0.454959 --> 0.454705).  Saving model ...
	 Train_Loss: 0.4597 Train_Acc: 82.125 Val_Loss: 0.4547  BEST VAL Loss: 0.4547  Val_Acc: 82.218

Epoch 71: Validation loss decreased (0.454705 --> 0.454433).  Saving model ...
	 Train_Loss: 0.4593 Train_Acc: 82.387 Val_Loss: 0.4544  BEST VAL Loss: 0.4544  Val_Acc: 81.225

Epoch 72: Validation loss decreased (0.454433 --> 0.454188).  Saving model ...
	 Train_Loss: 0.4589 Train_Acc: 82.387 Val_Loss: 0.4542  BEST VAL Loss: 0.4542  Val_Acc: 81.509

Epoch 73: Validation loss decreased (0.454188 --> 0.453935).  Saving model ...
	 Train_Loss: 0.4585 Train_Acc: 82.171 Val_Loss: 0.4539  BEST VAL Loss: 0.4539  Val_Acc: 81.736

Epoch 74: Validation loss decreased (0.453935 --> 0.453767).  Saving model ...
	 Train_Loss: 0.4581 Train_Acc: 82.494 Val_Loss: 0.4538  BEST VAL Loss: 0.4538  Val_Acc: 81.651

Epoch 75: Validation loss decreased (0.453767 --> 0.453519).  Saving model ...
	 Train_Loss: 0.4578 Train_Acc: 82.167 Val_Loss: 0.4535  BEST VAL Loss: 0.4535  Val_Acc: 81.594

Epoch 76: Validation loss decreased (0.453519 --> 0.453307).  Saving model ...
	 Train_Loss: 0.4574 Train_Acc: 82.132 Val_Loss: 0.4533  BEST VAL Loss: 0.4533  Val_Acc: 81.877

Epoch 77: Validation loss decreased (0.453307 --> 0.453227).  Saving model ...
	 Train_Loss: 0.4571 Train_Acc: 82.490 Val_Loss: 0.4532  BEST VAL Loss: 0.4532  Val_Acc: 81.764

Epoch 78: Validation loss decreased (0.453227 --> 0.453194).  Saving model ...
	 Train_Loss: 0.4567 Train_Acc: 82.359 Val_Loss: 0.4532  BEST VAL Loss: 0.4532  Val_Acc: 81.849

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.4563 Train_Acc: 82.557 Val_Loss: 0.4533  BEST VAL Loss: 0.4532  Val_Acc: 81.877

Epoch 80: Validation loss decreased (0.453194 --> 0.453118).  Saving model ...
	 Train_Loss: 0.4560 Train_Acc: 82.373 Val_Loss: 0.4531  BEST VAL Loss: 0.4531  Val_Acc: 81.339

Epoch 81: Validation loss decreased (0.453118 --> 0.452971).  Saving model ...
	 Train_Loss: 0.4557 Train_Acc: 82.352 Val_Loss: 0.4530  BEST VAL Loss: 0.4530  Val_Acc: 81.480

Epoch 82: Validation loss decreased (0.452971 --> 0.452860).  Saving model ...
	 Train_Loss: 0.4553 Train_Acc: 82.522 Val_Loss: 0.4529  BEST VAL Loss: 0.4529  Val_Acc: 81.339

Epoch 83: Validation loss decreased (0.452860 --> 0.452799).  Saving model ...
	 Train_Loss: 0.4550 Train_Acc: 82.437 Val_Loss: 0.4528  BEST VAL Loss: 0.4528  Val_Acc: 81.736

Epoch 84: Validation loss decreased (0.452799 --> 0.452782).  Saving model ...
	 Train_Loss: 0.4547 Train_Acc: 82.522 Val_Loss: 0.4528  BEST VAL Loss: 0.4528  Val_Acc: 81.112

Epoch 85: Validation loss decreased (0.452782 --> 0.452654).  Saving model ...
	 Train_Loss: 0.4544 Train_Acc: 82.373 Val_Loss: 0.4527  BEST VAL Loss: 0.4527  Val_Acc: 81.736

Epoch 86: Validation loss decreased (0.452654 --> 0.452524).  Saving model ...
	 Train_Loss: 0.4540 Train_Acc: 82.362 Val_Loss: 0.4525  BEST VAL Loss: 0.4525  Val_Acc: 81.197

Epoch 87: Validation loss decreased (0.452524 --> 0.452390).  Saving model ...
	 Train_Loss: 0.4537 Train_Acc: 82.533 Val_Loss: 0.4524  BEST VAL Loss: 0.4524  Val_Acc: 81.792

Epoch 88: Validation loss decreased (0.452390 --> 0.452313).  Saving model ...
	 Train_Loss: 0.4534 Train_Acc: 82.511 Val_Loss: 0.4523  BEST VAL Loss: 0.4523  Val_Acc: 81.452

Epoch 89: Validation loss decreased (0.452313 --> 0.452186).  Saving model ...
	 Train_Loss: 0.4531 Train_Acc: 82.366 Val_Loss: 0.4522  BEST VAL Loss: 0.4522  Val_Acc: 81.083

Epoch 90: Validation loss decreased (0.452186 --> 0.452058).  Saving model ...
	 Train_Loss: 0.4529 Train_Acc: 82.075 Val_Loss: 0.4521  BEST VAL Loss: 0.4521  Val_Acc: 81.877

Epoch 91: Validation loss decreased (0.452058 --> 0.451993).  Saving model ...
	 Train_Loss: 0.4526 Train_Acc: 82.582 Val_Loss: 0.4520  BEST VAL Loss: 0.4520  Val_Acc: 81.537

Epoch 92: Validation loss decreased (0.451993 --> 0.451904).  Saving model ...
	 Train_Loss: 0.4523 Train_Acc: 82.646 Val_Loss: 0.4519  BEST VAL Loss: 0.4519  Val_Acc: 81.651

Epoch 93: Validation loss decreased (0.451904 --> 0.451848).  Saving model ...
	 Train_Loss: 0.4521 Train_Acc: 82.323 Val_Loss: 0.4518  BEST VAL Loss: 0.4518  Val_Acc: 81.849

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.4518 Train_Acc: 82.444 Val_Loss: 0.4519  BEST VAL Loss: 0.4518  Val_Acc: 82.388

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.4515 Train_Acc: 82.533 Val_Loss: 0.4519  BEST VAL Loss: 0.4518  Val_Acc: 81.310

Epoch 96: Validation loss did not decrease
	 Train_Loss: 0.4512 Train_Acc: 82.891 Val_Loss: 0.4519  BEST VAL Loss: 0.4518  Val_Acc: 81.225

Epoch 97: Validation loss did not decrease
	 Train_Loss: 0.4509 Train_Acc: 82.841 Val_Loss: 0.4519  BEST VAL Loss: 0.4518  Val_Acc: 81.480

Epoch 98: Validation loss did not decrease
	 Train_Loss: 0.4507 Train_Acc: 82.802 Val_Loss: 0.4519  BEST VAL Loss: 0.4518  Val_Acc: 81.651

Epoch 99: Validation loss did not decrease
	 Train_Loss: 0.4504 Train_Acc: 82.781 Val_Loss: 0.4519  BEST VAL Loss: 0.4518  Val_Acc: 81.849

H2O2_100.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.64      0.72      0.68     18174
           1       0.35      0.28      0.31     10027

    accuracy                           0.56     28201
   macro avg       0.50      0.50      0.50     28201
weighted avg       0.54      0.56      0.55     28201

H2O2_100.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.65      0.72      0.68      2272
           1       0.36      0.29      0.32      1254

    accuracy                           0.56      3526
   macro avg       0.50      0.50      0.50      3526
weighted avg       0.54      0.56      0.55      3526

H2O2_100.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.64      0.72      0.68      2272
           1       0.35      0.27      0.30      1254

    accuracy                           0.56      3526
   macro avg       0.49      0.49      0.49      3526
weighted avg       0.54      0.56      0.54      3526

              precision    recall  f1-score   support

           0       0.64      0.72      0.68      2272
           1       0.35      0.27      0.30      1254

    accuracy                           0.56      3526
   macro avg       0.49      0.49      0.49      3526
weighted avg       0.54      0.56      0.54      3526

H2O2_100.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.81      0.63      4182
           1       0.49      0.19      0.27      3923

    accuracy                           0.51      8105
   macro avg       0.50      0.50      0.45      8105
weighted avg       0.50      0.51      0.46      8105

              precision    recall  f1-score   support

           0       0.52      0.81      0.63      4182
           1       0.49      0.19      0.27      3923

    accuracy                           0.51      8105
   macro avg       0.50      0.50      0.45      8105
weighted avg       0.50      0.51      0.46      8105

completed
