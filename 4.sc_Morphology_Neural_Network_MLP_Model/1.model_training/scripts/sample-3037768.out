[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'a971da36'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '84c4c9e5'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd3591141'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '147edd69'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_0.010_DMSO_0.025 treatment_name: DMSO_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_0.010_DMSO_0.025
TREATMENT_NAME: DMSO_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'LPS_0.010_DMSO_0.025']
The dimensions of the data are: (51502, 1276)
Number of total missing values across all columns: 103004
Data Subset Is Off
Wells held out for testing: ['B21' 'I14']
Wells to use for training, validation, and testing ['B14' 'C14' 'B15' 'C15' 'B16' 'B17' 'B20' 'J14' 'I15' 'J15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.562482).  Saving model ...
	 Train_Loss: 0.5931 Train_Acc: 72.593 Val_Loss: 0.5625  BEST VAL Loss: 0.5625  Val_Acc: 72.785

Epoch 1: Validation loss decreased (0.562482 --> 0.556769).  Saving model ...
	 Train_Loss: 0.5827 Train_Acc: 72.725 Val_Loss: 0.5568  BEST VAL Loss: 0.5568  Val_Acc: 72.762

Epoch 2: Validation loss decreased (0.556769 --> 0.552507).  Saving model ...
	 Train_Loss: 0.5758 Train_Acc: 72.782 Val_Loss: 0.5525  BEST VAL Loss: 0.5525  Val_Acc: 72.762

Epoch 3: Validation loss decreased (0.552507 --> 0.549012).  Saving model ...
	 Train_Loss: 0.5710 Train_Acc: 72.867 Val_Loss: 0.5490  BEST VAL Loss: 0.5490  Val_Acc: 72.762

Epoch 4: Validation loss decreased (0.549012 --> 0.545788).  Saving model ...
	 Train_Loss: 0.5668 Train_Acc: 73.171 Val_Loss: 0.5458  BEST VAL Loss: 0.5458  Val_Acc: 72.762

Epoch 5: Validation loss decreased (0.545788 --> 0.542886).  Saving model ...
	 Train_Loss: 0.5630 Train_Acc: 73.239 Val_Loss: 0.5429  BEST VAL Loss: 0.5429  Val_Acc: 72.785

Epoch 6: Validation loss decreased (0.542886 --> 0.540201).  Saving model ...
	 Train_Loss: 0.5596 Train_Acc: 73.673 Val_Loss: 0.5402  BEST VAL Loss: 0.5402  Val_Acc: 72.903

Epoch 7: Validation loss decreased (0.540201 --> 0.537639).  Saving model ...
	 Train_Loss: 0.5564 Train_Acc: 73.821 Val_Loss: 0.5376  BEST VAL Loss: 0.5376  Val_Acc: 73.021

Epoch 8: Validation loss decreased (0.537639 --> 0.535195).  Saving model ...
	 Train_Loss: 0.5534 Train_Acc: 74.004 Val_Loss: 0.5352  BEST VAL Loss: 0.5352  Val_Acc: 73.258

Epoch 9: Validation loss decreased (0.535195 --> 0.532920).  Saving model ...
	 Train_Loss: 0.5506 Train_Acc: 74.326 Val_Loss: 0.5329  BEST VAL Loss: 0.5329  Val_Acc: 73.565

Epoch 10: Validation loss decreased (0.532920 --> 0.530713).  Saving model ...
	 Train_Loss: 0.5480 Train_Acc: 74.571 Val_Loss: 0.5307  BEST VAL Loss: 0.5307  Val_Acc: 73.825

Epoch 11: Validation loss decreased (0.530713 --> 0.528697).  Saving model ...
	 Train_Loss: 0.5455 Train_Acc: 74.633 Val_Loss: 0.5287  BEST VAL Loss: 0.5287  Val_Acc: 74.297

Epoch 12: Validation loss decreased (0.528697 --> 0.526782).  Saving model ...
	 Train_Loss: 0.5433 Train_Acc: 74.731 Val_Loss: 0.5268  BEST VAL Loss: 0.5268  Val_Acc: 74.250

Epoch 13: Validation loss decreased (0.526782 --> 0.525014).  Saving model ...
	 Train_Loss: 0.5410 Train_Acc: 75.138 Val_Loss: 0.5250  BEST VAL Loss: 0.5250  Val_Acc: 74.533

Epoch 14: Validation loss decreased (0.525014 --> 0.523302).  Saving model ...
	 Train_Loss: 0.5389 Train_Acc: 75.303 Val_Loss: 0.5233  BEST VAL Loss: 0.5233  Val_Acc: 74.959

Epoch 15: Validation loss decreased (0.523302 --> 0.521711).  Saving model ...
	 Train_Loss: 0.5368 Train_Acc: 75.162 Val_Loss: 0.5217  BEST VAL Loss: 0.5217  Val_Acc: 74.911

Epoch 16: Validation loss decreased (0.521711 --> 0.520170).  Saving model ...
	 Train_Loss: 0.5349 Train_Acc: 75.300 Val_Loss: 0.5202  BEST VAL Loss: 0.5202  Val_Acc: 74.959

Epoch 17: Validation loss decreased (0.520170 --> 0.518630).  Saving model ...
	 Train_Loss: 0.5330 Train_Acc: 75.368 Val_Loss: 0.5186  BEST VAL Loss: 0.5186  Val_Acc: 75.455

Epoch 18: Validation loss decreased (0.518630 --> 0.517262).  Saving model ...
	 Train_Loss: 0.5313 Train_Acc: 75.466 Val_Loss: 0.5173  BEST VAL Loss: 0.5173  Val_Acc: 75.242

Epoch 19: Validation loss decreased (0.517262 --> 0.515909).  Saving model ...
	 Train_Loss: 0.5295 Train_Acc: 75.723 Val_Loss: 0.5159  BEST VAL Loss: 0.5159  Val_Acc: 75.644

Epoch 20: Validation loss decreased (0.515909 --> 0.514543).  Saving model ...
	 Train_Loss: 0.5278 Train_Acc: 75.947 Val_Loss: 0.5145  BEST VAL Loss: 0.5145  Val_Acc: 75.691

Epoch 21: Validation loss decreased (0.514543 --> 0.513266).  Saving model ...
	 Train_Loss: 0.5262 Train_Acc: 75.826 Val_Loss: 0.5133  BEST VAL Loss: 0.5133  Val_Acc: 75.715

Epoch 22: Validation loss decreased (0.513266 --> 0.512091).  Saving model ...
	 Train_Loss: 0.5248 Train_Acc: 75.755 Val_Loss: 0.5121  BEST VAL Loss: 0.5121  Val_Acc: 75.691

Epoch 23: Validation loss decreased (0.512091 --> 0.510979).  Saving model ...
	 Train_Loss: 0.5233 Train_Acc: 75.732 Val_Loss: 0.5110  BEST VAL Loss: 0.5110  Val_Acc: 75.880

Epoch 24: Validation loss decreased (0.510979 --> 0.509856).  Saving model ...
	 Train_Loss: 0.5219 Train_Acc: 75.808 Val_Loss: 0.5099  BEST VAL Loss: 0.5099  Val_Acc: 76.093

Epoch 25: Validation loss decreased (0.509856 --> 0.508822).  Saving model ...
	 Train_Loss: 0.5205 Train_Acc: 76.166 Val_Loss: 0.5088  BEST VAL Loss: 0.5088  Val_Acc: 75.974

Epoch 26: Validation loss decreased (0.508822 --> 0.507827).  Saving model ...
	 Train_Loss: 0.5192 Train_Acc: 75.968 Val_Loss: 0.5078  BEST VAL Loss: 0.5078  Val_Acc: 76.282

Epoch 27: Validation loss decreased (0.507827 --> 0.506823).  Saving model ...
	 Train_Loss: 0.5179 Train_Acc: 76.310 Val_Loss: 0.5068  BEST VAL Loss: 0.5068  Val_Acc: 76.211

Epoch 28: Validation loss decreased (0.506823 --> 0.505892).  Saving model ...
	 Train_Loss: 0.5167 Train_Acc: 76.039 Val_Loss: 0.5059  BEST VAL Loss: 0.5059  Val_Acc: 76.187

Epoch 29: Validation loss decreased (0.505892 --> 0.505038).  Saving model ...
	 Train_Loss: 0.5155 Train_Acc: 76.151 Val_Loss: 0.5050  BEST VAL Loss: 0.5050  Val_Acc: 76.022

Epoch 30: Validation loss decreased (0.505038 --> 0.504188).  Saving model ...
	 Train_Loss: 0.5143 Train_Acc: 76.186 Val_Loss: 0.5042  BEST VAL Loss: 0.5042  Val_Acc: 76.140

Epoch 31: Validation loss decreased (0.504188 --> 0.503358).  Saving model ...
	 Train_Loss: 0.5132 Train_Acc: 76.325 Val_Loss: 0.5034  BEST VAL Loss: 0.5034  Val_Acc: 76.329

Epoch 32: Validation loss decreased (0.503358 --> 0.502558).  Saving model ...
	 Train_Loss: 0.5121 Train_Acc: 76.369 Val_Loss: 0.5026  BEST VAL Loss: 0.5026  Val_Acc: 76.305

Epoch 33: Validation loss decreased (0.502558 --> 0.501832).  Saving model ...
	 Train_Loss: 0.5110 Train_Acc: 76.508 Val_Loss: 0.5018  BEST VAL Loss: 0.5018  Val_Acc: 76.282

Epoch 34: Validation loss decreased (0.501832 --> 0.501113).  Saving model ...
	 Train_Loss: 0.5099 Train_Acc: 76.420 Val_Loss: 0.5011  BEST VAL Loss: 0.5011  Val_Acc: 76.305

Epoch 35: Validation loss decreased (0.501113 --> 0.500407).  Saving model ...
	 Train_Loss: 0.5089 Train_Acc: 76.556 Val_Loss: 0.5004  BEST VAL Loss: 0.5004  Val_Acc: 76.163

Epoch 36: Validation loss decreased (0.500407 --> 0.499740).  Saving model ...
	 Train_Loss: 0.5079 Train_Acc: 76.251 Val_Loss: 0.4997  BEST VAL Loss: 0.4997  Val_Acc: 76.045

Epoch 37: Validation loss decreased (0.499740 --> 0.499087).  Saving model ...
	 Train_Loss: 0.5069 Train_Acc: 76.600 Val_Loss: 0.4991  BEST VAL Loss: 0.4991  Val_Acc: 76.140

Epoch 38: Validation loss decreased (0.499087 --> 0.498446).  Saving model ...
	 Train_Loss: 0.5060 Train_Acc: 76.420 Val_Loss: 0.4984  BEST VAL Loss: 0.4984  Val_Acc: 76.447

Epoch 39: Validation loss decreased (0.498446 --> 0.497815).  Saving model ...
	 Train_Loss: 0.5050 Train_Acc: 76.730 Val_Loss: 0.4978  BEST VAL Loss: 0.4978  Val_Acc: 76.707

Epoch 40: Validation loss decreased (0.497815 --> 0.497176).  Saving model ...
	 Train_Loss: 0.5041 Train_Acc: 76.848 Val_Loss: 0.4972  BEST VAL Loss: 0.4972  Val_Acc: 76.919

Epoch 41: Validation loss decreased (0.497176 --> 0.496617).  Saving model ...
	 Train_Loss: 0.5032 Train_Acc: 76.561 Val_Loss: 0.4966  BEST VAL Loss: 0.4966  Val_Acc: 76.352

Epoch 42: Validation loss decreased (0.496617 --> 0.496073).  Saving model ...
	 Train_Loss: 0.5023 Train_Acc: 76.815 Val_Loss: 0.4961  BEST VAL Loss: 0.4961  Val_Acc: 76.423

Epoch 43: Validation loss decreased (0.496073 --> 0.495554).  Saving model ...
	 Train_Loss: 0.5015 Train_Acc: 76.815 Val_Loss: 0.4956  BEST VAL Loss: 0.4956  Val_Acc: 76.471

Epoch 44: Validation loss decreased (0.495554 --> 0.495064).  Saving model ...
	 Train_Loss: 0.5006 Train_Acc: 76.857 Val_Loss: 0.4951  BEST VAL Loss: 0.4951  Val_Acc: 76.518

Epoch 45: Validation loss decreased (0.495064 --> 0.494555).  Saving model ...
	 Train_Loss: 0.4997 Train_Acc: 76.638 Val_Loss: 0.4946  BEST VAL Loss: 0.4946  Val_Acc: 76.187

Epoch 46: Validation loss decreased (0.494555 --> 0.494054).  Saving model ...
	 Train_Loss: 0.4989 Train_Acc: 76.807 Val_Loss: 0.4941  BEST VAL Loss: 0.4941  Val_Acc: 76.471

Epoch 47: Validation loss decreased (0.494054 --> 0.493578).  Saving model ...
	 Train_Loss: 0.4981 Train_Acc: 76.954 Val_Loss: 0.4936  BEST VAL Loss: 0.4936  Val_Acc: 76.660

Epoch 48: Validation loss decreased (0.493578 --> 0.493112).  Saving model ...
	 Train_Loss: 0.4973 Train_Acc: 76.804 Val_Loss: 0.4931  BEST VAL Loss: 0.4931  Val_Acc: 76.187

Epoch 49: Validation loss decreased (0.493112 --> 0.492666).  Saving model ...
	 Train_Loss: 0.4965 Train_Acc: 76.821 Val_Loss: 0.4927  BEST VAL Loss: 0.4927  Val_Acc: 76.494

Epoch 50: Validation loss decreased (0.492666 --> 0.492213).  Saving model ...
	 Train_Loss: 0.4958 Train_Acc: 76.907 Val_Loss: 0.4922  BEST VAL Loss: 0.4922  Val_Acc: 76.683

Epoch 51: Validation loss decreased (0.492213 --> 0.491781).  Saving model ...
	 Train_Loss: 0.4950 Train_Acc: 77.016 Val_Loss: 0.4918  BEST VAL Loss: 0.4918  Val_Acc: 76.754

Epoch 52: Validation loss decreased (0.491781 --> 0.491350).  Saving model ...
	 Train_Loss: 0.4943 Train_Acc: 76.963 Val_Loss: 0.4914  BEST VAL Loss: 0.4914  Val_Acc: 76.471

Epoch 53: Validation loss decreased (0.491350 --> 0.490926).  Saving model ...
	 Train_Loss: 0.4936 Train_Acc: 76.987 Val_Loss: 0.4909  BEST VAL Loss: 0.4909  Val_Acc: 76.400

Epoch 54: Validation loss decreased (0.490926 --> 0.490536).  Saving model ...
	 Train_Loss: 0.4929 Train_Acc: 77.164 Val_Loss: 0.4905  BEST VAL Loss: 0.4905  Val_Acc: 76.471

Epoch 55: Validation loss decreased (0.490536 --> 0.490160).  Saving model ...
	 Train_Loss: 0.4922 Train_Acc: 77.312 Val_Loss: 0.4902  BEST VAL Loss: 0.4902  Val_Acc: 76.636

Epoch 56: Validation loss decreased (0.490160 --> 0.489774).  Saving model ...
	 Train_Loss: 0.4915 Train_Acc: 77.022 Val_Loss: 0.4898  BEST VAL Loss: 0.4898  Val_Acc: 76.636

Epoch 57: Validation loss decreased (0.489774 --> 0.489374).  Saving model ...
	 Train_Loss: 0.4908 Train_Acc: 76.869 Val_Loss: 0.4894  BEST VAL Loss: 0.4894  Val_Acc: 76.707

Epoch 58: Validation loss decreased (0.489374 --> 0.489027).  Saving model ...
	 Train_Loss: 0.4901 Train_Acc: 77.128 Val_Loss: 0.4890  BEST VAL Loss: 0.4890  Val_Acc: 76.518

Epoch 59: Validation loss decreased (0.489027 --> 0.488687).  Saving model ...
	 Train_Loss: 0.4895 Train_Acc: 77.081 Val_Loss: 0.4887  BEST VAL Loss: 0.4887  Val_Acc: 76.636

Epoch 60: Validation loss decreased (0.488687 --> 0.488373).  Saving model ...
	 Train_Loss: 0.4889 Train_Acc: 77.158 Val_Loss: 0.4884  BEST VAL Loss: 0.4884  Val_Acc: 76.849

Epoch 61: Validation loss decreased (0.488373 --> 0.488052).  Saving model ...
	 Train_Loss: 0.4882 Train_Acc: 77.066 Val_Loss: 0.4881  BEST VAL Loss: 0.4881  Val_Acc: 76.636

Epoch 62: Validation loss decreased (0.488052 --> 0.487723).  Saving model ...
	 Train_Loss: 0.4876 Train_Acc: 77.176 Val_Loss: 0.4877  BEST VAL Loss: 0.4877  Val_Acc: 76.778

Epoch 63: Validation loss decreased (0.487723 --> 0.487394).  Saving model ...
	 Train_Loss: 0.4869 Train_Acc: 77.096 Val_Loss: 0.4874  BEST VAL Loss: 0.4874  Val_Acc: 76.919

Epoch 64: Validation loss decreased (0.487394 --> 0.487103).  Saving model ...
	 Train_Loss: 0.4863 Train_Acc: 77.362 Val_Loss: 0.4871  BEST VAL Loss: 0.4871  Val_Acc: 77.250

Epoch 65: Validation loss decreased (0.487103 --> 0.486831).  Saving model ...
	 Train_Loss: 0.4857 Train_Acc: 77.285 Val_Loss: 0.4868  BEST VAL Loss: 0.4868  Val_Acc: 76.967

Epoch 66: Validation loss decreased (0.486831 --> 0.486538).  Saving model ...
	 Train_Loss: 0.4851 Train_Acc: 77.199 Val_Loss: 0.4865  BEST VAL Loss: 0.4865  Val_Acc: 76.683

Epoch 67: Validation loss decreased (0.486538 --> 0.486272).  Saving model ...
	 Train_Loss: 0.4845 Train_Acc: 77.385 Val_Loss: 0.4863  BEST VAL Loss: 0.4863  Val_Acc: 76.801

Epoch 68: Validation loss decreased (0.486272 --> 0.485988).  Saving model ...
	 Train_Loss: 0.4839 Train_Acc: 77.427 Val_Loss: 0.4860  BEST VAL Loss: 0.4860  Val_Acc: 77.321

Epoch 69: Validation loss decreased (0.485988 --> 0.485718).  Saving model ...
	 Train_Loss: 0.4833 Train_Acc: 77.223 Val_Loss: 0.4857  BEST VAL Loss: 0.4857  Val_Acc: 77.038

Epoch 70: Validation loss decreased (0.485718 --> 0.485428).  Saving model ...
	 Train_Loss: 0.4827 Train_Acc: 77.542 Val_Loss: 0.4854  BEST VAL Loss: 0.4854  Val_Acc: 77.368

Epoch 71: Validation loss decreased (0.485428 --> 0.485163).  Saving model ...
	 Train_Loss: 0.4822 Train_Acc: 77.220 Val_Loss: 0.4852  BEST VAL Loss: 0.4852  Val_Acc: 77.038

Epoch 72: Validation loss decreased (0.485163 --> 0.484927).  Saving model ...
	 Train_Loss: 0.4816 Train_Acc: 77.288 Val_Loss: 0.4849  BEST VAL Loss: 0.4849  Val_Acc: 77.014

Epoch 73: Validation loss decreased (0.484927 --> 0.484690).  Saving model ...
	 Train_Loss: 0.4810 Train_Acc: 77.459 Val_Loss: 0.4847  BEST VAL Loss: 0.4847  Val_Acc: 77.392

Epoch 74: Validation loss decreased (0.484690 --> 0.484465).  Saving model ...
	 Train_Loss: 0.4805 Train_Acc: 77.376 Val_Loss: 0.4845  BEST VAL Loss: 0.4845  Val_Acc: 76.636

Epoch 75: Validation loss decreased (0.484465 --> 0.484260).  Saving model ...
	 Train_Loss: 0.4799 Train_Acc: 77.374 Val_Loss: 0.4843  BEST VAL Loss: 0.4843  Val_Acc: 76.943

Epoch 76: Validation loss decreased (0.484260 --> 0.484046).  Saving model ...
	 Train_Loss: 0.4794 Train_Acc: 77.577 Val_Loss: 0.4840  BEST VAL Loss: 0.4840  Val_Acc: 77.061

Epoch 77: Validation loss decreased (0.484046 --> 0.483851).  Saving model ...
	 Train_Loss: 0.4789 Train_Acc: 77.427 Val_Loss: 0.4839  BEST VAL Loss: 0.4839  Val_Acc: 77.132

Epoch 78: Validation loss decreased (0.483851 --> 0.483654).  Saving model ...
	 Train_Loss: 0.4783 Train_Acc: 77.518 Val_Loss: 0.4837  BEST VAL Loss: 0.4837  Val_Acc: 77.061

Epoch 79: Validation loss decreased (0.483654 --> 0.483478).  Saving model ...
	 Train_Loss: 0.4778 Train_Acc: 77.244 Val_Loss: 0.4835  BEST VAL Loss: 0.4835  Val_Acc: 76.943

Epoch 80: Validation loss decreased (0.483478 --> 0.483297).  Saving model ...
	 Train_Loss: 0.4773 Train_Acc: 77.229 Val_Loss: 0.4833  BEST VAL Loss: 0.4833  Val_Acc: 77.038

Epoch 81: Validation loss decreased (0.483297 --> 0.483113).  Saving model ...
	 Train_Loss: 0.4768 Train_Acc: 77.595 Val_Loss: 0.4831  BEST VAL Loss: 0.4831  Val_Acc: 77.061

Epoch 82: Validation loss decreased (0.483113 --> 0.482957).  Saving model ...
	 Train_Loss: 0.4763 Train_Acc: 77.506 Val_Loss: 0.4830  BEST VAL Loss: 0.4830  Val_Acc: 77.061

Epoch 83: Validation loss decreased (0.482957 --> 0.482792).  Saving model ...
	 Train_Loss: 0.4758 Train_Acc: 77.285 Val_Loss: 0.4828  BEST VAL Loss: 0.4828  Val_Acc: 77.345

Epoch 84: Validation loss decreased (0.482792 --> 0.482630).  Saving model ...
	 Train_Loss: 0.4753 Train_Acc: 77.619 Val_Loss: 0.4826  BEST VAL Loss: 0.4826  Val_Acc: 77.061

Epoch 85: Validation loss decreased (0.482630 --> 0.482447).  Saving model ...
	 Train_Loss: 0.4748 Train_Acc: 77.465 Val_Loss: 0.4824  BEST VAL Loss: 0.4824  Val_Acc: 77.203

Epoch 86: Validation loss decreased (0.482447 --> 0.482278).  Saving model ...
	 Train_Loss: 0.4744 Train_Acc: 77.450 Val_Loss: 0.4823  BEST VAL Loss: 0.4823  Val_Acc: 76.683

Epoch 87: Validation loss decreased (0.482278 --> 0.482087).  Saving model ...
	 Train_Loss: 0.4739 Train_Acc: 77.568 Val_Loss: 0.4821  BEST VAL Loss: 0.4821  Val_Acc: 77.274

Epoch 88: Validation loss decreased (0.482087 --> 0.481916).  Saving model ...
	 Train_Loss: 0.4734 Train_Acc: 77.752 Val_Loss: 0.4819  BEST VAL Loss: 0.4819  Val_Acc: 77.392

Epoch 89: Validation loss decreased (0.481916 --> 0.481766).  Saving model ...
	 Train_Loss: 0.4729 Train_Acc: 77.589 Val_Loss: 0.4818  BEST VAL Loss: 0.4818  Val_Acc: 76.801

Epoch 90: Validation loss decreased (0.481766 --> 0.481611).  Saving model ...
	 Train_Loss: 0.4725 Train_Acc: 77.574 Val_Loss: 0.4816  BEST VAL Loss: 0.4816  Val_Acc: 77.038

Epoch 91: Validation loss decreased (0.481611 --> 0.481452).  Saving model ...
	 Train_Loss: 0.4720 Train_Acc: 77.335 Val_Loss: 0.4815  BEST VAL Loss: 0.4815  Val_Acc: 76.967

Epoch 92: Validation loss decreased (0.481452 --> 0.481312).  Saving model ...
	 Train_Loss: 0.4715 Train_Acc: 77.524 Val_Loss: 0.4813  BEST VAL Loss: 0.4813  Val_Acc: 77.297

Epoch 93: Validation loss decreased (0.481312 --> 0.481162).  Saving model ...
	 Train_Loss: 0.4711 Train_Acc: 77.489 Val_Loss: 0.4812  BEST VAL Loss: 0.4812  Val_Acc: 77.014

Epoch 94: Validation loss decreased (0.481162 --> 0.481020).  Saving model ...
	 Train_Loss: 0.4706 Train_Acc: 77.837 Val_Loss: 0.4810  BEST VAL Loss: 0.4810  Val_Acc: 77.108

Epoch 95: Validation loss decreased (0.481020 --> 0.480892).  Saving model ...
	 Train_Loss: 0.4702 Train_Acc: 77.654 Val_Loss: 0.4809  BEST VAL Loss: 0.4809  Val_Acc: 77.179

Epoch 96: Validation loss decreased (0.480892 --> 0.480775).  Saving model ...
	 Train_Loss: 0.4697 Train_Acc: 77.639 Val_Loss: 0.4808  BEST VAL Loss: 0.4808  Val_Acc: 76.967

Epoch 97: Validation loss decreased (0.480775 --> 0.480644).  Saving model ...
	 Train_Loss: 0.4693 Train_Acc: 77.619 Val_Loss: 0.4806  BEST VAL Loss: 0.4806  Val_Acc: 77.179

Epoch 98: Validation loss decreased (0.480644 --> 0.480497).  Saving model ...
	 Train_Loss: 0.4689 Train_Acc: 77.805 Val_Loss: 0.4805  BEST VAL Loss: 0.4805  Val_Acc: 77.203

Epoch 99: Validation loss decreased (0.480497 --> 0.480342).  Saving model ...
	 Train_Loss: 0.4685 Train_Acc: 77.610 Val_Loss: 0.4803  BEST VAL Loss: 0.4803  Val_Acc: 77.439

LPS_0.010_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.81      0.96      0.88     24644
           1       0.80      0.40      0.54      9219

    accuracy                           0.81     33863
   macro avg       0.81      0.68      0.71     33863
weighted avg       0.81      0.81      0.79     33863

LPS_0.010_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.79      0.94      0.86      3081
           1       0.68      0.33      0.44      1152

    accuracy                           0.77      4233
   macro avg       0.73      0.63      0.65      4233
weighted avg       0.76      0.77      0.75      4233

LPS_0.010_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.78      0.94      0.85      3081
           1       0.63      0.30      0.40      1152

    accuracy                           0.76      4233
   macro avg       0.71      0.62      0.63      4233
weighted avg       0.74      0.76      0.73      4233

              precision    recall  f1-score   support

           0       0.78      0.94      0.85      3081
           1       0.63      0.30      0.40      1152

    accuracy                           0.76      4233
   macro avg       0.71      0.62      0.63      4233
weighted avg       0.74      0.76      0.73      4233

LPS_0.010_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.54      0.92      0.68      4837
           1       0.58      0.12      0.19      4336

    accuracy                           0.54      9173
   macro avg       0.56      0.52      0.44      9173
weighted avg       0.56      0.54      0.45      9173

              precision    recall  f1-score   support

           0       0.54      0.92      0.68      4837
           1       0.58      0.12      0.19      4336

    accuracy                           0.54      9173
   macro avg       0.56      0.52      0.44      9173
weighted avg       0.56      0.54      0.45      9173

completed
