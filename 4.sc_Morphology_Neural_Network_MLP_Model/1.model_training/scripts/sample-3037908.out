[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '7cfdaa7e'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '108d8cf4'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'fbb393b7'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '28c04be7'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_1.000_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_1.000_DMSO_0.025
TREATMENT_NAME: Flagellin_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (243980, 1270)
Number of total missing values across all columns: 524576
Data Subset Is Off
Wells held out for testing: ['D09' 'M10']
Wells to use for training, validation, and testing ['D02' 'D03' 'D08' 'M05' 'M11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.584664).  Saving model ...
	 Train_Loss: 0.6299 Train_Acc: 64.413 Val_Loss: 0.5847  BEST VAL Loss: 0.5847  Val_Acc: 68.604

Epoch 1: Validation loss decreased (0.584664 --> 0.570323).  Saving model ...
	 Train_Loss: 0.6051 Train_Acc: 68.605 Val_Loss: 0.5703  BEST VAL Loss: 0.5703  Val_Acc: 71.746

Epoch 2: Validation loss decreased (0.570323 --> 0.554561).  Saving model ...
	 Train_Loss: 0.5871 Train_Acc: 71.604 Val_Loss: 0.5546  BEST VAL Loss: 0.5546  Val_Acc: 74.911

Epoch 3: Validation loss decreased (0.554561 --> 0.542019).  Saving model ...
	 Train_Loss: 0.5717 Train_Acc: 73.867 Val_Loss: 0.5420  BEST VAL Loss: 0.5420  Val_Acc: 76.257

Epoch 4: Validation loss decreased (0.542019 --> 0.532524).  Saving model ...
	 Train_Loss: 0.5594 Train_Acc: 74.913 Val_Loss: 0.5325  BEST VAL Loss: 0.5325  Val_Acc: 76.683

Epoch 5: Validation loss decreased (0.532524 --> 0.526302).  Saving model ...
	 Train_Loss: 0.5498 Train_Acc: 75.577 Val_Loss: 0.5263  BEST VAL Loss: 0.5263  Val_Acc: 76.654

Epoch 6: Validation loss decreased (0.526302 --> 0.520967).  Saving model ...
	 Train_Loss: 0.5423 Train_Acc: 75.941 Val_Loss: 0.5210  BEST VAL Loss: 0.5210  Val_Acc: 77.385

Epoch 7: Validation loss decreased (0.520967 --> 0.516443).  Saving model ...
	 Train_Loss: 0.5359 Train_Acc: 76.131 Val_Loss: 0.5164  BEST VAL Loss: 0.5164  Val_Acc: 77.362

Epoch 8: Validation loss decreased (0.516443 --> 0.512719).  Saving model ...
	 Train_Loss: 0.5306 Train_Acc: 76.519 Val_Loss: 0.5127  BEST VAL Loss: 0.5127  Val_Acc: 77.696

Epoch 9: Validation loss decreased (0.512719 --> 0.509253).  Saving model ...
	 Train_Loss: 0.5258 Train_Acc: 76.772 Val_Loss: 0.5093  BEST VAL Loss: 0.5093  Val_Acc: 78.047

Epoch 10: Validation loss decreased (0.509253 --> 0.506333).  Saving model ...
	 Train_Loss: 0.5218 Train_Acc: 76.801 Val_Loss: 0.5063  BEST VAL Loss: 0.5063  Val_Acc: 78.041

Epoch 11: Validation loss decreased (0.506333 --> 0.504194).  Saving model ...
	 Train_Loss: 0.5181 Train_Acc: 77.085 Val_Loss: 0.5042  BEST VAL Loss: 0.5042  Val_Acc: 78.064

Epoch 12: Validation loss decreased (0.504194 --> 0.502008).  Saving model ...
	 Train_Loss: 0.5148 Train_Acc: 77.235 Val_Loss: 0.5020  BEST VAL Loss: 0.5020  Val_Acc: 78.283

Epoch 13: Validation loss decreased (0.502008 --> 0.500084).  Saving model ...
	 Train_Loss: 0.5117 Train_Acc: 77.417 Val_Loss: 0.5001  BEST VAL Loss: 0.5001  Val_Acc: 78.490

Epoch 14: Validation loss decreased (0.500084 --> 0.498420).  Saving model ...
	 Train_Loss: 0.5090 Train_Acc: 77.462 Val_Loss: 0.4984  BEST VAL Loss: 0.4984  Val_Acc: 78.386

Epoch 15: Validation loss decreased (0.498420 --> 0.497003).  Saving model ...
	 Train_Loss: 0.5064 Train_Acc: 77.585 Val_Loss: 0.4970  BEST VAL Loss: 0.4970  Val_Acc: 78.502

Epoch 16: Validation loss decreased (0.497003 --> 0.495635).  Saving model ...
	 Train_Loss: 0.5042 Train_Acc: 77.589 Val_Loss: 0.4956  BEST VAL Loss: 0.4956  Val_Acc: 78.565

Epoch 17: Validation loss decreased (0.495635 --> 0.494314).  Saving model ...
	 Train_Loss: 0.5020 Train_Acc: 77.680 Val_Loss: 0.4943  BEST VAL Loss: 0.4943  Val_Acc: 78.536

Epoch 18: Validation loss decreased (0.494314 --> 0.493172).  Saving model ...
	 Train_Loss: 0.5000 Train_Acc: 77.813 Val_Loss: 0.4932  BEST VAL Loss: 0.4932  Val_Acc: 78.651

Epoch 19: Validation loss decreased (0.493172 --> 0.492180).  Saving model ...
	 Train_Loss: 0.4982 Train_Acc: 77.852 Val_Loss: 0.4922  BEST VAL Loss: 0.4922  Val_Acc: 78.697

Epoch 20: Validation loss decreased (0.492180 --> 0.491341).  Saving model ...
	 Train_Loss: 0.4964 Train_Acc: 77.987 Val_Loss: 0.4913  BEST VAL Loss: 0.4913  Val_Acc: 78.473

Epoch 21: Validation loss decreased (0.491341 --> 0.490386).  Saving model ...
	 Train_Loss: 0.4947 Train_Acc: 78.020 Val_Loss: 0.4904  BEST VAL Loss: 0.4904  Val_Acc: 78.691

Epoch 22: Validation loss decreased (0.490386 --> 0.489718).  Saving model ...
	 Train_Loss: 0.4932 Train_Acc: 78.212 Val_Loss: 0.4897  BEST VAL Loss: 0.4897  Val_Acc: 78.703

Epoch 23: Validation loss decreased (0.489718 --> 0.488987).  Saving model ...
	 Train_Loss: 0.4917 Train_Acc: 78.140 Val_Loss: 0.4890  BEST VAL Loss: 0.4890  Val_Acc: 78.755

Epoch 24: Validation loss decreased (0.488987 --> 0.488275).  Saving model ...
	 Train_Loss: 0.4903 Train_Acc: 78.322 Val_Loss: 0.4883  BEST VAL Loss: 0.4883  Val_Acc: 78.847

Epoch 25: Validation loss decreased (0.488275 --> 0.487858).  Saving model ...
	 Train_Loss: 0.4889 Train_Acc: 78.332 Val_Loss: 0.4879  BEST VAL Loss: 0.4879  Val_Acc: 78.323

Epoch 26: Validation loss decreased (0.487858 --> 0.487313).  Saving model ...
	 Train_Loss: 0.4876 Train_Acc: 78.314 Val_Loss: 0.4873  BEST VAL Loss: 0.4873  Val_Acc: 78.599

Epoch 27: Validation loss decreased (0.487313 --> 0.486850).  Saving model ...
	 Train_Loss: 0.4864 Train_Acc: 78.443 Val_Loss: 0.4868  BEST VAL Loss: 0.4868  Val_Acc: 78.381

Epoch 28: Validation loss decreased (0.486850 --> 0.486306).  Saving model ...
	 Train_Loss: 0.4853 Train_Acc: 78.374 Val_Loss: 0.4863  BEST VAL Loss: 0.4863  Val_Acc: 78.709

Epoch 29: Validation loss decreased (0.486306 --> 0.485699).  Saving model ...
	 Train_Loss: 0.4842 Train_Acc: 78.525 Val_Loss: 0.4857  BEST VAL Loss: 0.4857  Val_Acc: 78.645

Epoch 30: Validation loss decreased (0.485699 --> 0.485147).  Saving model ...
	 Train_Loss: 0.4831 Train_Acc: 78.416 Val_Loss: 0.4851  BEST VAL Loss: 0.4851  Val_Acc: 78.841

Epoch 31: Validation loss decreased (0.485147 --> 0.484639).  Saving model ...
	 Train_Loss: 0.4820 Train_Acc: 78.577 Val_Loss: 0.4846  BEST VAL Loss: 0.4846  Val_Acc: 78.571

Epoch 32: Validation loss decreased (0.484639 --> 0.484166).  Saving model ...
	 Train_Loss: 0.4811 Train_Acc: 78.550 Val_Loss: 0.4842  BEST VAL Loss: 0.4842  Val_Acc: 78.548

Epoch 33: Validation loss decreased (0.484166 --> 0.483728).  Saving model ...
	 Train_Loss: 0.4801 Train_Acc: 78.543 Val_Loss: 0.4837  BEST VAL Loss: 0.4837  Val_Acc: 78.680

Epoch 34: Validation loss decreased (0.483728 --> 0.483425).  Saving model ...
	 Train_Loss: 0.4792 Train_Acc: 78.630 Val_Loss: 0.4834  BEST VAL Loss: 0.4834  Val_Acc: 78.680

Epoch 35: Validation loss decreased (0.483425 --> 0.483066).  Saving model ...
	 Train_Loss: 0.4783 Train_Acc: 78.690 Val_Loss: 0.4831  BEST VAL Loss: 0.4831  Val_Acc: 78.818

Epoch 36: Validation loss decreased (0.483066 --> 0.482649).  Saving model ...
	 Train_Loss: 0.4775 Train_Acc: 78.730 Val_Loss: 0.4826  BEST VAL Loss: 0.4826  Val_Acc: 78.985

Epoch 37: Validation loss decreased (0.482649 --> 0.482315).  Saving model ...
	 Train_Loss: 0.4766 Train_Acc: 78.817 Val_Loss: 0.4823  BEST VAL Loss: 0.4823  Val_Acc: 78.726

Epoch 38: Validation loss decreased (0.482315 --> 0.481905).  Saving model ...
	 Train_Loss: 0.4758 Train_Acc: 78.739 Val_Loss: 0.4819  BEST VAL Loss: 0.4819  Val_Acc: 79.089

Epoch 39: Validation loss decreased (0.481905 --> 0.481592).  Saving model ...
	 Train_Loss: 0.4750 Train_Acc: 78.795 Val_Loss: 0.4816  BEST VAL Loss: 0.4816  Val_Acc: 78.755

Epoch 40: Validation loss decreased (0.481592 --> 0.481266).  Saving model ...
	 Train_Loss: 0.4742 Train_Acc: 78.901 Val_Loss: 0.4813  BEST VAL Loss: 0.4813  Val_Acc: 78.807

Epoch 41: Validation loss decreased (0.481266 --> 0.480953).  Saving model ...
	 Train_Loss: 0.4734 Train_Acc: 79.016 Val_Loss: 0.4810  BEST VAL Loss: 0.4810  Val_Acc: 78.812

Epoch 42: Validation loss decreased (0.480953 --> 0.480734).  Saving model ...
	 Train_Loss: 0.4727 Train_Acc: 78.981 Val_Loss: 0.4807  BEST VAL Loss: 0.4807  Val_Acc: 78.617

Epoch 43: Validation loss decreased (0.480734 --> 0.480500).  Saving model ...
	 Train_Loss: 0.4720 Train_Acc: 78.932 Val_Loss: 0.4805  BEST VAL Loss: 0.4805  Val_Acc: 78.737

Epoch 44: Validation loss decreased (0.480500 --> 0.480189).  Saving model ...
	 Train_Loss: 0.4713 Train_Acc: 78.906 Val_Loss: 0.4802  BEST VAL Loss: 0.4802  Val_Acc: 78.864

Epoch 45: Validation loss decreased (0.480189 --> 0.479957).  Saving model ...
	 Train_Loss: 0.4706 Train_Acc: 78.995 Val_Loss: 0.4800  BEST VAL Loss: 0.4800  Val_Acc: 78.801

Epoch 46: Validation loss decreased (0.479957 --> 0.479685).  Saving model ...
	 Train_Loss: 0.4700 Train_Acc: 79.088 Val_Loss: 0.4797  BEST VAL Loss: 0.4797  Val_Acc: 78.927

Epoch 47: Validation loss decreased (0.479685 --> 0.479500).  Saving model ...
	 Train_Loss: 0.4693 Train_Acc: 79.121 Val_Loss: 0.4795  BEST VAL Loss: 0.4795  Val_Acc: 78.801

Epoch 48: Validation loss decreased (0.479500 --> 0.479306).  Saving model ...
	 Train_Loss: 0.4687 Train_Acc: 79.063 Val_Loss: 0.4793  BEST VAL Loss: 0.4793  Val_Acc: 78.939

Epoch 49: Validation loss decreased (0.479306 --> 0.479073).  Saving model ...
	 Train_Loss: 0.4681 Train_Acc: 79.078 Val_Loss: 0.4791  BEST VAL Loss: 0.4791  Val_Acc: 79.042

Epoch 50: Validation loss decreased (0.479073 --> 0.478893).  Saving model ...
	 Train_Loss: 0.4675 Train_Acc: 79.150 Val_Loss: 0.4789  BEST VAL Loss: 0.4789  Val_Acc: 78.847

Epoch 51: Validation loss decreased (0.478893 --> 0.478732).  Saving model ...
	 Train_Loss: 0.4669 Train_Acc: 79.000 Val_Loss: 0.4787  BEST VAL Loss: 0.4787  Val_Acc: 78.887

Epoch 52: Validation loss decreased (0.478732 --> 0.478543).  Saving model ...
	 Train_Loss: 0.4663 Train_Acc: 79.204 Val_Loss: 0.4785  BEST VAL Loss: 0.4785  Val_Acc: 78.939

Epoch 53: Validation loss decreased (0.478543 --> 0.478357).  Saving model ...
	 Train_Loss: 0.4658 Train_Acc: 79.266 Val_Loss: 0.4784  BEST VAL Loss: 0.4784  Val_Acc: 78.979

Epoch 54: Validation loss decreased (0.478357 --> 0.478227).  Saving model ...
	 Train_Loss: 0.4652 Train_Acc: 79.312 Val_Loss: 0.4782  BEST VAL Loss: 0.4782  Val_Acc: 78.893

Epoch 55: Validation loss decreased (0.478227 --> 0.478141).  Saving model ...
	 Train_Loss: 0.4647 Train_Acc: 79.127 Val_Loss: 0.4781  BEST VAL Loss: 0.4781  Val_Acc: 78.801

Epoch 56: Validation loss decreased (0.478141 --> 0.478035).  Saving model ...
	 Train_Loss: 0.4641 Train_Acc: 79.334 Val_Loss: 0.4780  BEST VAL Loss: 0.4780  Val_Acc: 78.709

Epoch 57: Validation loss decreased (0.478035 --> 0.477856).  Saving model ...
	 Train_Loss: 0.4636 Train_Acc: 79.332 Val_Loss: 0.4779  BEST VAL Loss: 0.4779  Val_Acc: 78.881

Epoch 58: Validation loss decreased (0.477856 --> 0.477691).  Saving model ...
	 Train_Loss: 0.4631 Train_Acc: 79.333 Val_Loss: 0.4777  BEST VAL Loss: 0.4777  Val_Acc: 79.094

Epoch 59: Validation loss decreased (0.477691 --> 0.477502).  Saving model ...
	 Train_Loss: 0.4626 Train_Acc: 79.371 Val_Loss: 0.4775  BEST VAL Loss: 0.4775  Val_Acc: 78.973

Epoch 60: Validation loss decreased (0.477502 --> 0.477381).  Saving model ...
	 Train_Loss: 0.4621 Train_Acc: 79.509 Val_Loss: 0.4774  BEST VAL Loss: 0.4774  Val_Acc: 78.847

Epoch 61: Validation loss decreased (0.477381 --> 0.477253).  Saving model ...
	 Train_Loss: 0.4616 Train_Acc: 79.473 Val_Loss: 0.4773  BEST VAL Loss: 0.4773  Val_Acc: 78.807

Epoch 62: Validation loss decreased (0.477253 --> 0.477134).  Saving model ...
	 Train_Loss: 0.4611 Train_Acc: 79.301 Val_Loss: 0.4771  BEST VAL Loss: 0.4771  Val_Acc: 78.881

Epoch 63: Validation loss decreased (0.477134 --> 0.477029).  Saving model ...
	 Train_Loss: 0.4607 Train_Acc: 79.441 Val_Loss: 0.4770  BEST VAL Loss: 0.4770  Val_Acc: 78.784

Epoch 64: Validation loss decreased (0.477029 --> 0.476879).  Saving model ...
	 Train_Loss: 0.4602 Train_Acc: 79.345 Val_Loss: 0.4769  BEST VAL Loss: 0.4769  Val_Acc: 79.019

Epoch 65: Validation loss decreased (0.476879 --> 0.476747).  Saving model ...
	 Train_Loss: 0.4598 Train_Acc: 79.359 Val_Loss: 0.4767  BEST VAL Loss: 0.4767  Val_Acc: 78.985

Epoch 66: Validation loss decreased (0.476747 --> 0.476549).  Saving model ...
	 Train_Loss: 0.4593 Train_Acc: 79.283 Val_Loss: 0.4765  BEST VAL Loss: 0.4765  Val_Acc: 79.204

Epoch 67: Validation loss decreased (0.476549 --> 0.476345).  Saving model ...
	 Train_Loss: 0.4589 Train_Acc: 79.485 Val_Loss: 0.4763  BEST VAL Loss: 0.4763  Val_Acc: 79.065

Epoch 68: Validation loss decreased (0.476345 --> 0.476235).  Saving model ...
	 Train_Loss: 0.4585 Train_Acc: 79.345 Val_Loss: 0.4762  BEST VAL Loss: 0.4762  Val_Acc: 79.175

Epoch 69: Validation loss decreased (0.476235 --> 0.476080).  Saving model ...
	 Train_Loss: 0.4581 Train_Acc: 79.483 Val_Loss: 0.4761  BEST VAL Loss: 0.4761  Val_Acc: 79.163

Epoch 70: Validation loss decreased (0.476080 --> 0.475953).  Saving model ...
	 Train_Loss: 0.4577 Train_Acc: 79.492 Val_Loss: 0.4760  BEST VAL Loss: 0.4760  Val_Acc: 79.014

Epoch 71: Validation loss decreased (0.475953 --> 0.475828).  Saving model ...
	 Train_Loss: 0.4573 Train_Acc: 79.496 Val_Loss: 0.4758  BEST VAL Loss: 0.4758  Val_Acc: 79.008

Epoch 72: Validation loss decreased (0.475828 --> 0.475751).  Saving model ...
	 Train_Loss: 0.4569 Train_Acc: 79.431 Val_Loss: 0.4758  BEST VAL Loss: 0.4758  Val_Acc: 78.973

Epoch 73: Validation loss decreased (0.475751 --> 0.475641).  Saving model ...
	 Train_Loss: 0.4565 Train_Acc: 79.545 Val_Loss: 0.4756  BEST VAL Loss: 0.4756  Val_Acc: 79.158

Epoch 74: Validation loss decreased (0.475641 --> 0.475536).  Saving model ...
	 Train_Loss: 0.4561 Train_Acc: 79.538 Val_Loss: 0.4755  BEST VAL Loss: 0.4755  Val_Acc: 78.973

Epoch 75: Validation loss decreased (0.475536 --> 0.475428).  Saving model ...
	 Train_Loss: 0.4557 Train_Acc: 79.570 Val_Loss: 0.4754  BEST VAL Loss: 0.4754  Val_Acc: 79.031

Epoch 76: Validation loss decreased (0.475428 --> 0.475272).  Saving model ...
	 Train_Loss: 0.4554 Train_Acc: 79.622 Val_Loss: 0.4753  BEST VAL Loss: 0.4753  Val_Acc: 79.129

Epoch 77: Validation loss decreased (0.475272 --> 0.475199).  Saving model ...
	 Train_Loss: 0.4550 Train_Acc: 79.501 Val_Loss: 0.4752  BEST VAL Loss: 0.4752  Val_Acc: 79.060

Epoch 78: Validation loss decreased (0.475199 --> 0.475066).  Saving model ...
	 Train_Loss: 0.4546 Train_Acc: 79.547 Val_Loss: 0.4751  BEST VAL Loss: 0.4751  Val_Acc: 79.250

Epoch 79: Validation loss decreased (0.475066 --> 0.474968).  Saving model ...
	 Train_Loss: 0.4543 Train_Acc: 79.525 Val_Loss: 0.4750  BEST VAL Loss: 0.4750  Val_Acc: 78.996

Epoch 80: Validation loss decreased (0.474968 --> 0.474815).  Saving model ...
	 Train_Loss: 0.4540 Train_Acc: 79.527 Val_Loss: 0.4748  BEST VAL Loss: 0.4748  Val_Acc: 79.359

Epoch 81: Validation loss decreased (0.474815 --> 0.474721).  Saving model ...
	 Train_Loss: 0.4536 Train_Acc: 79.672 Val_Loss: 0.4747  BEST VAL Loss: 0.4747  Val_Acc: 79.008

Epoch 82: Validation loss decreased (0.474721 --> 0.474649).  Saving model ...
	 Train_Loss: 0.4533 Train_Acc: 79.596 Val_Loss: 0.4746  BEST VAL Loss: 0.4746  Val_Acc: 78.939

Epoch 83: Validation loss decreased (0.474649 --> 0.474530).  Saving model ...
	 Train_Loss: 0.4530 Train_Acc: 79.563 Val_Loss: 0.4745  BEST VAL Loss: 0.4745  Val_Acc: 79.204

Epoch 84: Validation loss decreased (0.474530 --> 0.474451).  Saving model ...
	 Train_Loss: 0.4527 Train_Acc: 79.532 Val_Loss: 0.4745  BEST VAL Loss: 0.4745  Val_Acc: 78.881

Epoch 85: Validation loss decreased (0.474451 --> 0.474377).  Saving model ...
	 Train_Loss: 0.4523 Train_Acc: 79.730 Val_Loss: 0.4744  BEST VAL Loss: 0.4744  Val_Acc: 79.117

Epoch 86: Validation loss decreased (0.474377 --> 0.474236).  Saving model ...
	 Train_Loss: 0.4520 Train_Acc: 79.711 Val_Loss: 0.4742  BEST VAL Loss: 0.4742  Val_Acc: 79.163

Epoch 87: Validation loss decreased (0.474236 --> 0.474066).  Saving model ...
	 Train_Loss: 0.4517 Train_Acc: 79.706 Val_Loss: 0.4741  BEST VAL Loss: 0.4741  Val_Acc: 79.526

Epoch 88: Validation loss decreased (0.474066 --> 0.474008).  Saving model ...
	 Train_Loss: 0.4514 Train_Acc: 79.674 Val_Loss: 0.4740  BEST VAL Loss: 0.4740  Val_Acc: 79.140

Epoch 89: Validation loss decreased (0.474008 --> 0.473882).  Saving model ...
	 Train_Loss: 0.4511 Train_Acc: 79.575 Val_Loss: 0.4739  BEST VAL Loss: 0.4739  Val_Acc: 79.382

Epoch 90: Validation loss decreased (0.473882 --> 0.473775).  Saving model ...
	 Train_Loss: 0.4508 Train_Acc: 79.736 Val_Loss: 0.4738  BEST VAL Loss: 0.4738  Val_Acc: 79.140

Epoch 91: Validation loss decreased (0.473775 --> 0.473678).  Saving model ...
	 Train_Loss: 0.4505 Train_Acc: 79.870 Val_Loss: 0.4737  BEST VAL Loss: 0.4737  Val_Acc: 79.313

Epoch 92: Validation loss decreased (0.473678 --> 0.473600).  Saving model ...
	 Train_Loss: 0.4502 Train_Acc: 79.563 Val_Loss: 0.4736  BEST VAL Loss: 0.4736  Val_Acc: 79.100

Epoch 93: Validation loss decreased (0.473600 --> 0.473508).  Saving model ...
	 Train_Loss: 0.4499 Train_Acc: 79.668 Val_Loss: 0.4735  BEST VAL Loss: 0.4735  Val_Acc: 79.244

Epoch 94: Validation loss decreased (0.473508 --> 0.473417).  Saving model ...
	 Train_Loss: 0.4496 Train_Acc: 79.837 Val_Loss: 0.4734  BEST VAL Loss: 0.4734  Val_Acc: 79.244

Epoch 95: Validation loss decreased (0.473417 --> 0.473346).  Saving model ...
	 Train_Loss: 0.4493 Train_Acc: 79.716 Val_Loss: 0.4733  BEST VAL Loss: 0.4733  Val_Acc: 79.152

Epoch 96: Validation loss decreased (0.473346 --> 0.473248).  Saving model ...
	 Train_Loss: 0.4491 Train_Acc: 79.645 Val_Loss: 0.4732  BEST VAL Loss: 0.4732  Val_Acc: 79.284

Epoch 97: Validation loss decreased (0.473248 --> 0.473168).  Saving model ...
	 Train_Loss: 0.4488 Train_Acc: 79.743 Val_Loss: 0.4732  BEST VAL Loss: 0.4732  Val_Acc: 79.238

Epoch 98: Validation loss decreased (0.473168 --> 0.473076).  Saving model ...
	 Train_Loss: 0.4486 Train_Acc: 79.798 Val_Loss: 0.4731  BEST VAL Loss: 0.4731  Val_Acc: 79.215

Epoch 99: Validation loss decreased (0.473076 --> 0.473010).  Saving model ...
	 Train_Loss: 0.4483 Train_Acc: 79.836 Val_Loss: 0.4730  BEST VAL Loss: 0.4730  Val_Acc: 79.215

LPS_1.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.83      0.71      0.77     56122
           1       0.82      0.90      0.86     82897

    accuracy                           0.82    139019
   macro avg       0.82      0.81      0.81    139019
weighted avg       0.82      0.82      0.82    139019

LPS_1.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.78      0.67      0.72      7016
           1       0.80      0.87      0.83     10362

    accuracy                           0.79     17378
   macro avg       0.79      0.77      0.78     17378
weighted avg       0.79      0.79      0.79     17378

LPS_1.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.78      0.67      0.72      7015
           1       0.80      0.88      0.83     10363

    accuracy                           0.79     17378
   macro avg       0.79      0.77      0.78     17378
weighted avg       0.79      0.79      0.79     17378

              precision    recall  f1-score   support

           0       0.78      0.67      0.72      7015
           1       0.80      0.88      0.83     10363

    accuracy                           0.79     17378
   macro avg       0.79      0.77      0.78     17378
weighted avg       0.79      0.79      0.79     17378

LPS_1.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.46      0.63     34394
           1       0.66      0.99      0.79     35811

    accuracy                           0.73     70205
   macro avg       0.81      0.72      0.71     70205
weighted avg       0.81      0.73      0.71     70205

              precision    recall  f1-score   support

           0       0.97      0.46      0.63     34394
           1       0.66      0.99      0.79     35811

    accuracy                           0.73     70205
   macro avg       0.81      0.72      0.71     70205
weighted avg       0.81      0.73      0.71     70205

completed
