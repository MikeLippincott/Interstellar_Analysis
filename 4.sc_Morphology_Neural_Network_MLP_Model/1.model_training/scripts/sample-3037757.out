[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '16ff064e'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'd2d31f0f'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '32d26bd5'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '747ea683'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_10.000_DMSO_0.025 treatment_name: DMSO_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: DMSO_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'LPS_10.000_DMSO_0.025']
The dimensions of the data are: (371620, 1270)
Number of total missing values across all columns: 743240
Data Subset Is Off
Wells held out for testing: ['E09' 'J06']
Wells to use for training, validation, and testing ['B06' 'C06' 'B07' 'C07' 'E02' 'E03' 'E08' 'I06' 'I07' 'J07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.445697).  Saving model ...
	 Train_Loss: 0.5437 Train_Acc: 71.998 Val_Loss: 0.4457  BEST VAL Loss: 0.4457  Val_Acc: 80.828

Epoch 1: Validation loss decreased (0.445697 --> 0.422031).  Saving model ...
	 Train_Loss: 0.4888 Train_Acc: 80.223 Val_Loss: 0.4220  BEST VAL Loss: 0.4220  Val_Acc: 81.608

Epoch 2: Validation loss decreased (0.422031 --> 0.400173).  Saving model ...
	 Train_Loss: 0.4568 Train_Acc: 82.301 Val_Loss: 0.4002  BEST VAL Loss: 0.4002  Val_Acc: 84.351

Epoch 3: Validation loss decreased (0.400173 --> 0.397100).  Saving model ...
	 Train_Loss: 0.4351 Train_Acc: 83.381 Val_Loss: 0.3971  BEST VAL Loss: 0.3971  Val_Acc: 82.124

Epoch 4: Validation loss decreased (0.397100 --> 0.384422).  Saving model ...
	 Train_Loss: 0.4186 Train_Acc: 84.225 Val_Loss: 0.3844  BEST VAL Loss: 0.3844  Val_Acc: 85.511

Epoch 5: Validation loss decreased (0.384422 --> 0.371670).  Saving model ...
	 Train_Loss: 0.4057 Train_Acc: 84.698 Val_Loss: 0.3717  BEST VAL Loss: 0.3717  Val_Acc: 86.645

Epoch 6: Validation loss decreased (0.371670 --> 0.361825).  Saving model ...
	 Train_Loss: 0.3950 Train_Acc: 85.169 Val_Loss: 0.3618  BEST VAL Loss: 0.3618  Val_Acc: 86.513

Epoch 7: Validation loss decreased (0.361825 --> 0.355486).  Saving model ...
	 Train_Loss: 0.3859 Train_Acc: 85.479 Val_Loss: 0.3555  BEST VAL Loss: 0.3555  Val_Acc: 85.614

Epoch 8: Validation loss decreased (0.355486 --> 0.349199).  Saving model ...
	 Train_Loss: 0.3780 Train_Acc: 85.776 Val_Loss: 0.3492  BEST VAL Loss: 0.3492  Val_Acc: 87.022

Epoch 9: Validation loss decreased (0.349199 --> 0.342366).  Saving model ...
	 Train_Loss: 0.3712 Train_Acc: 85.988 Val_Loss: 0.3424  BEST VAL Loss: 0.3424  Val_Acc: 87.600

Epoch 10: Validation loss decreased (0.342366 --> 0.338845).  Saving model ...
	 Train_Loss: 0.3650 Train_Acc: 86.224 Val_Loss: 0.3388  BEST VAL Loss: 0.3388  Val_Acc: 86.764

Epoch 11: Validation loss did not decrease
	 Train_Loss: 0.3596 Train_Acc: 86.520 Val_Loss: 0.3389  BEST VAL Loss: 0.3388  Val_Acc: 84.698

Epoch 12: Validation loss decreased (0.338845 --> 0.334338).  Saving model ...
	 Train_Loss: 0.3547 Train_Acc: 86.677 Val_Loss: 0.3343  BEST VAL Loss: 0.3343  Val_Acc: 87.831

Epoch 13: Validation loss decreased (0.334338 --> 0.329150).  Saving model ...
	 Train_Loss: 0.3502 Train_Acc: 86.973 Val_Loss: 0.3291  BEST VAL Loss: 0.3291  Val_Acc: 88.598

Epoch 14: Validation loss decreased (0.329150 --> 0.324599).  Saving model ...
	 Train_Loss: 0.3461 Train_Acc: 87.146 Val_Loss: 0.3246  BEST VAL Loss: 0.3246  Val_Acc: 88.648

Epoch 15: Validation loss decreased (0.324599 --> 0.322371).  Saving model ...
	 Train_Loss: 0.3424 Train_Acc: 87.226 Val_Loss: 0.3224  BEST VAL Loss: 0.3224  Val_Acc: 87.111

Epoch 16: Validation loss did not decrease
	 Train_Loss: 0.3390 Train_Acc: 87.361 Val_Loss: 0.3230  BEST VAL Loss: 0.3224  Val_Acc: 85.647

Epoch 17: Validation loss did not decrease
	 Train_Loss: 0.3358 Train_Acc: 87.389 Val_Loss: 0.3275  BEST VAL Loss: 0.3224  Val_Acc: 83.492

Epoch 18: Validation loss did not decrease
	 Train_Loss: 0.3329 Train_Acc: 87.398 Val_Loss: 0.3261  BEST VAL Loss: 0.3224  Val_Acc: 86.876

Epoch 19: Validation loss did not decrease
	 Train_Loss: 0.3302 Train_Acc: 87.575 Val_Loss: 0.3237  BEST VAL Loss: 0.3224  Val_Acc: 87.669

Epoch 20: Validation loss decreased (0.322371 --> 0.320027).  Saving model ...
	 Train_Loss: 0.3276 Train_Acc: 87.662 Val_Loss: 0.3200  BEST VAL Loss: 0.3200  Val_Acc: 89.556

Epoch 21: Validation loss decreased (0.320027 --> 0.316892).  Saving model ...
	 Train_Loss: 0.3252 Train_Acc: 87.679 Val_Loss: 0.3169  BEST VAL Loss: 0.3169  Val_Acc: 89.150

Epoch 22: Validation loss decreased (0.316892 --> 0.314659).  Saving model ...
	 Train_Loss: 0.3229 Train_Acc: 87.795 Val_Loss: 0.3147  BEST VAL Loss: 0.3147  Val_Acc: 88.066

Epoch 23: Validation loss decreased (0.314659 --> 0.312766).  Saving model ...
	 Train_Loss: 0.3208 Train_Acc: 87.798 Val_Loss: 0.3128  BEST VAL Loss: 0.3128  Val_Acc: 88.218

Epoch 24: Validation loss decreased (0.312766 --> 0.310104).  Saving model ...
	 Train_Loss: 0.3188 Train_Acc: 87.911 Val_Loss: 0.3101  BEST VAL Loss: 0.3101  Val_Acc: 89.395

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.3169 Train_Acc: 87.913 Val_Loss: 0.3120  BEST VAL Loss: 0.3101  Val_Acc: 84.857

Epoch 26: Validation loss decreased (0.310104 --> 0.309903).  Saving model ...
	 Train_Loss: 0.3151 Train_Acc: 87.909 Val_Loss: 0.3099  BEST VAL Loss: 0.3099  Val_Acc: 89.054

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.3135 Train_Acc: 88.061 Val_Loss: 0.3102  BEST VAL Loss: 0.3099  Val_Acc: 86.784

Epoch 28: Validation loss decreased (0.309903 --> 0.308034).  Saving model ...
	 Train_Loss: 0.3119 Train_Acc: 88.038 Val_Loss: 0.3080  BEST VAL Loss: 0.3080  Val_Acc: 89.226

Epoch 29: Validation loss decreased (0.308034 --> 0.305644).  Saving model ...
	 Train_Loss: 0.3103 Train_Acc: 88.137 Val_Loss: 0.3056  BEST VAL Loss: 0.3056  Val_Acc: 89.765

Epoch 30: Validation loss decreased (0.305644 --> 0.304041).  Saving model ...
	 Train_Loss: 0.3089 Train_Acc: 88.085 Val_Loss: 0.3040  BEST VAL Loss: 0.3040  Val_Acc: 89.219

Epoch 31: Validation loss decreased (0.304041 --> 0.301963).  Saving model ...
	 Train_Loss: 0.3074 Train_Acc: 88.192 Val_Loss: 0.3020  BEST VAL Loss: 0.3020  Val_Acc: 89.887

Epoch 32: Validation loss decreased (0.301963 --> 0.300938).  Saving model ...
	 Train_Loss: 0.3061 Train_Acc: 88.330 Val_Loss: 0.3009  BEST VAL Loss: 0.3009  Val_Acc: 89.160

Epoch 33: Validation loss decreased (0.300938 --> 0.298871).  Saving model ...
	 Train_Loss: 0.3048 Train_Acc: 88.234 Val_Loss: 0.2989  BEST VAL Loss: 0.2989  Val_Acc: 90.161

Epoch 34: Validation loss decreased (0.298871 --> 0.297093).  Saving model ...
	 Train_Loss: 0.3036 Train_Acc: 88.377 Val_Loss: 0.2971  BEST VAL Loss: 0.2971  Val_Acc: 89.768

Epoch 35: Validation loss decreased (0.297093 --> 0.295936).  Saving model ...
	 Train_Loss: 0.3024 Train_Acc: 88.379 Val_Loss: 0.2959  BEST VAL Loss: 0.2959  Val_Acc: 88.707

Epoch 36: Validation loss decreased (0.295936 --> 0.294878).  Saving model ...
	 Train_Loss: 0.3012 Train_Acc: 88.251 Val_Loss: 0.2949  BEST VAL Loss: 0.2949  Val_Acc: 89.239

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.3002 Train_Acc: 88.313 Val_Loss: 0.2954  BEST VAL Loss: 0.2949  Val_Acc: 86.721

Epoch 38: Validation loss decreased (0.294878 --> 0.294113).  Saving model ...
	 Train_Loss: 0.2992 Train_Acc: 88.247 Val_Loss: 0.2941  BEST VAL Loss: 0.2941  Val_Acc: 89.728

Epoch 39: Validation loss decreased (0.294113 --> 0.293243).  Saving model ...
	 Train_Loss: 0.2982 Train_Acc: 88.363 Val_Loss: 0.2932  BEST VAL Loss: 0.2932  Val_Acc: 88.872

Epoch 40: Validation loss decreased (0.293243 --> 0.291615).  Saving model ...
	 Train_Loss: 0.2972 Train_Acc: 88.427 Val_Loss: 0.2916  BEST VAL Loss: 0.2916  Val_Acc: 90.568

Epoch 41: Validation loss decreased (0.291615 --> 0.290307).  Saving model ...
	 Train_Loss: 0.2962 Train_Acc: 88.535 Val_Loss: 0.2903  BEST VAL Loss: 0.2903  Val_Acc: 90.244

Epoch 42: Validation loss decreased (0.290307 --> 0.289018).  Saving model ...
	 Train_Loss: 0.2954 Train_Acc: 88.413 Val_Loss: 0.2890  BEST VAL Loss: 0.2890  Val_Acc: 90.046

Epoch 43: Validation loss decreased (0.289018 --> 0.287896).  Saving model ...
	 Train_Loss: 0.2945 Train_Acc: 88.459 Val_Loss: 0.2879  BEST VAL Loss: 0.2879  Val_Acc: 89.785

Epoch 44: Validation loss decreased (0.287896 --> 0.287155).  Saving model ...
	 Train_Loss: 0.2936 Train_Acc: 88.543 Val_Loss: 0.2872  BEST VAL Loss: 0.2872  Val_Acc: 88.925

Epoch 45: Validation loss decreased (0.287155 --> 0.286603).  Saving model ...
	 Train_Loss: 0.2928 Train_Acc: 88.397 Val_Loss: 0.2866  BEST VAL Loss: 0.2866  Val_Acc: 88.836

Epoch 46: Validation loss decreased (0.286603 --> 0.285334).  Saving model ...
	 Train_Loss: 0.2920 Train_Acc: 88.489 Val_Loss: 0.2853  BEST VAL Loss: 0.2853  Val_Acc: 90.538

Epoch 47: Validation loss decreased (0.285334 --> 0.285185).  Saving model ...
	 Train_Loss: 0.2912 Train_Acc: 88.601 Val_Loss: 0.2852  BEST VAL Loss: 0.2852  Val_Acc: 88.350

Epoch 48: Validation loss decreased (0.285185 --> 0.284180).  Saving model ...
	 Train_Loss: 0.2905 Train_Acc: 88.570 Val_Loss: 0.2842  BEST VAL Loss: 0.2842  Val_Acc: 89.966

Epoch 49: Validation loss decreased (0.284180 --> 0.283152).  Saving model ...
	 Train_Loss: 0.2898 Train_Acc: 88.591 Val_Loss: 0.2832  BEST VAL Loss: 0.2832  Val_Acc: 90.221

Epoch 50: Validation loss decreased (0.283152 --> 0.282447).  Saving model ...
	 Train_Loss: 0.2891 Train_Acc: 88.554 Val_Loss: 0.2824  BEST VAL Loss: 0.2824  Val_Acc: 89.378

Epoch 51: Validation loss decreased (0.282447 --> 0.281434).  Saving model ...
	 Train_Loss: 0.2884 Train_Acc: 88.643 Val_Loss: 0.2814  BEST VAL Loss: 0.2814  Val_Acc: 90.303

Epoch 52: Validation loss decreased (0.281434 --> 0.281095).  Saving model ...
	 Train_Loss: 0.2877 Train_Acc: 88.668 Val_Loss: 0.2811  BEST VAL Loss: 0.2811  Val_Acc: 88.925

Epoch 53: Validation loss decreased (0.281095 --> 0.280220).  Saving model ...
	 Train_Loss: 0.2871 Train_Acc: 88.621 Val_Loss: 0.2802  BEST VAL Loss: 0.2802  Val_Acc: 89.897

Epoch 54: Validation loss decreased (0.280220 --> 0.279320).  Saving model ...
	 Train_Loss: 0.2864 Train_Acc: 88.663 Val_Loss: 0.2793  BEST VAL Loss: 0.2793  Val_Acc: 90.151

Epoch 55: Validation loss decreased (0.279320 --> 0.278785).  Saving model ...
	 Train_Loss: 0.2858 Train_Acc: 88.601 Val_Loss: 0.2788  BEST VAL Loss: 0.2788  Val_Acc: 88.905

Epoch 56: Validation loss decreased (0.278785 --> 0.277893).  Saving model ...
	 Train_Loss: 0.2852 Train_Acc: 88.682 Val_Loss: 0.2779  BEST VAL Loss: 0.2779  Val_Acc: 90.287

Epoch 57: Validation loss decreased (0.277893 --> 0.276976).  Saving model ...
	 Train_Loss: 0.2846 Train_Acc: 88.669 Val_Loss: 0.2770  BEST VAL Loss: 0.2770  Val_Acc: 90.426

Epoch 58: Validation loss decreased (0.276976 --> 0.276142).  Saving model ...
	 Train_Loss: 0.2841 Train_Acc: 88.710 Val_Loss: 0.2761  BEST VAL Loss: 0.2761  Val_Acc: 90.409

Epoch 59: Validation loss decreased (0.276142 --> 0.275526).  Saving model ...
	 Train_Loss: 0.2835 Train_Acc: 88.701 Val_Loss: 0.2755  BEST VAL Loss: 0.2755  Val_Acc: 89.745

Epoch 60: Validation loss decreased (0.275526 --> 0.275065).  Saving model ...
	 Train_Loss: 0.2830 Train_Acc: 88.719 Val_Loss: 0.2751  BEST VAL Loss: 0.2751  Val_Acc: 89.560

Epoch 61: Validation loss decreased (0.275065 --> 0.274252).  Saving model ...
	 Train_Loss: 0.2824 Train_Acc: 88.722 Val_Loss: 0.2743  BEST VAL Loss: 0.2743  Val_Acc: 90.479

Epoch 62: Validation loss decreased (0.274252 --> 0.273567).  Saving model ...
	 Train_Loss: 0.2819 Train_Acc: 88.732 Val_Loss: 0.2736  BEST VAL Loss: 0.2736  Val_Acc: 90.181

Epoch 63: Validation loss decreased (0.273567 --> 0.272882).  Saving model ...
	 Train_Loss: 0.2814 Train_Acc: 88.664 Val_Loss: 0.2729  BEST VAL Loss: 0.2729  Val_Acc: 90.141

Epoch 64: Validation loss decreased (0.272882 --> 0.272123).  Saving model ...
	 Train_Loss: 0.2809 Train_Acc: 88.767 Val_Loss: 0.2721  BEST VAL Loss: 0.2721  Val_Acc: 90.730

Epoch 65: Validation loss decreased (0.272123 --> 0.271495).  Saving model ...
	 Train_Loss: 0.2805 Train_Acc: 88.807 Val_Loss: 0.2715  BEST VAL Loss: 0.2715  Val_Acc: 90.231

Epoch 66: Validation loss decreased (0.271495 --> 0.270764).  Saving model ...
	 Train_Loss: 0.2800 Train_Acc: 88.817 Val_Loss: 0.2708  BEST VAL Loss: 0.2708  Val_Acc: 90.561

Epoch 67: Validation loss decreased (0.270764 --> 0.270372).  Saving model ...
	 Train_Loss: 0.2795 Train_Acc: 88.813 Val_Loss: 0.2704  BEST VAL Loss: 0.2704  Val_Acc: 89.695

Epoch 68: Validation loss decreased (0.270372 --> 0.270216).  Saving model ...
	 Train_Loss: 0.2791 Train_Acc: 88.752 Val_Loss: 0.2702  BEST VAL Loss: 0.2702  Val_Acc: 89.325

Epoch 69: Validation loss decreased (0.270216 --> 0.269509).  Saving model ...
	 Train_Loss: 0.2787 Train_Acc: 88.799 Val_Loss: 0.2695  BEST VAL Loss: 0.2695  Val_Acc: 90.677

Epoch 70: Validation loss decreased (0.269509 --> 0.268891).  Saving model ...
	 Train_Loss: 0.2782 Train_Acc: 88.818 Val_Loss: 0.2689  BEST VAL Loss: 0.2689  Val_Acc: 90.594

Epoch 71: Validation loss decreased (0.268891 --> 0.268696).  Saving model ...
	 Train_Loss: 0.2778 Train_Acc: 88.865 Val_Loss: 0.2687  BEST VAL Loss: 0.2687  Val_Acc: 90.178

Epoch 72: Validation loss decreased (0.268696 --> 0.268070).  Saving model ...
	 Train_Loss: 0.2774 Train_Acc: 88.744 Val_Loss: 0.2681  BEST VAL Loss: 0.2681  Val_Acc: 91.011

Epoch 73: Validation loss decreased (0.268070 --> 0.267465).  Saving model ...
	 Train_Loss: 0.2770 Train_Acc: 88.883 Val_Loss: 0.2675  BEST VAL Loss: 0.2675  Val_Acc: 90.799

Epoch 74: Validation loss decreased (0.267465 --> 0.267079).  Saving model ...
	 Train_Loss: 0.2766 Train_Acc: 88.816 Val_Loss: 0.2671  BEST VAL Loss: 0.2671  Val_Acc: 89.903

Epoch 75: Validation loss decreased (0.267079 --> 0.266631).  Saving model ...
	 Train_Loss: 0.2762 Train_Acc: 88.837 Val_Loss: 0.2666  BEST VAL Loss: 0.2666  Val_Acc: 89.966

Epoch 76: Validation loss decreased (0.266631 --> 0.266147).  Saving model ...
	 Train_Loss: 0.2758 Train_Acc: 88.831 Val_Loss: 0.2661  BEST VAL Loss: 0.2661  Val_Acc: 90.763

Epoch 77: Validation loss decreased (0.266147 --> 0.265593).  Saving model ...
	 Train_Loss: 0.2755 Train_Acc: 88.824 Val_Loss: 0.2656  BEST VAL Loss: 0.2656  Val_Acc: 90.707

Epoch 78: Validation loss decreased (0.265593 --> 0.265217).  Saving model ...
	 Train_Loss: 0.2751 Train_Acc: 88.915 Val_Loss: 0.2652  BEST VAL Loss: 0.2652  Val_Acc: 89.983

Epoch 79: Validation loss decreased (0.265217 --> 0.264961).  Saving model ...
	 Train_Loss: 0.2747 Train_Acc: 88.850 Val_Loss: 0.2650  BEST VAL Loss: 0.2650  Val_Acc: 89.930

Epoch 80: Validation loss decreased (0.264961 --> 0.264572).  Saving model ...
	 Train_Loss: 0.2744 Train_Acc: 88.954 Val_Loss: 0.2646  BEST VAL Loss: 0.2646  Val_Acc: 90.327

Epoch 81: Validation loss decreased (0.264572 --> 0.264054).  Saving model ...
	 Train_Loss: 0.2741 Train_Acc: 88.832 Val_Loss: 0.2641  BEST VAL Loss: 0.2641  Val_Acc: 90.802

Epoch 82: Validation loss decreased (0.264054 --> 0.263781).  Saving model ...
	 Train_Loss: 0.2737 Train_Acc: 88.903 Val_Loss: 0.2638  BEST VAL Loss: 0.2638  Val_Acc: 89.831

Epoch 83: Validation loss decreased (0.263781 --> 0.263296).  Saving model ...
	 Train_Loss: 0.2734 Train_Acc: 88.903 Val_Loss: 0.2633  BEST VAL Loss: 0.2633  Val_Acc: 90.654

Epoch 84: Validation loss decreased (0.263296 --> 0.262894).  Saving model ...
	 Train_Loss: 0.2730 Train_Acc: 88.979 Val_Loss: 0.2629  BEST VAL Loss: 0.2629  Val_Acc: 90.601

Epoch 85: Validation loss decreased (0.262894 --> 0.262416).  Saving model ...
	 Train_Loss: 0.2727 Train_Acc: 89.067 Val_Loss: 0.2624  BEST VAL Loss: 0.2624  Val_Acc: 90.674

Epoch 86: Validation loss decreased (0.262416 --> 0.261960).  Saving model ...
	 Train_Loss: 0.2724 Train_Acc: 88.909 Val_Loss: 0.2620  BEST VAL Loss: 0.2620  Val_Acc: 90.796

Epoch 87: Validation loss decreased (0.261960 --> 0.261504).  Saving model ...
	 Train_Loss: 0.2721 Train_Acc: 88.890 Val_Loss: 0.2615  BEST VAL Loss: 0.2615  Val_Acc: 90.254

Epoch 88: Validation loss decreased (0.261504 --> 0.261013).  Saving model ...
	 Train_Loss: 0.2718 Train_Acc: 88.918 Val_Loss: 0.2610  BEST VAL Loss: 0.2610  Val_Acc: 90.783

Epoch 89: Validation loss decreased (0.261013 --> 0.260766).  Saving model ...
	 Train_Loss: 0.2715 Train_Acc: 88.954 Val_Loss: 0.2608  BEST VAL Loss: 0.2608  Val_Acc: 89.920

Epoch 90: Validation loss decreased (0.260766 --> 0.260451).  Saving model ...
	 Train_Loss: 0.2712 Train_Acc: 88.997 Val_Loss: 0.2605  BEST VAL Loss: 0.2605  Val_Acc: 90.621

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.2709 Train_Acc: 88.944 Val_Loss: 0.2606  BEST VAL Loss: 0.2605  Val_Acc: 88.767

Epoch 92: Validation loss decreased (0.260451 --> 0.260195).  Saving model ...
	 Train_Loss: 0.2706 Train_Acc: 88.910 Val_Loss: 0.2602  BEST VAL Loss: 0.2602  Val_Acc: 90.726

Epoch 93: Validation loss decreased (0.260195 --> 0.259728).  Saving model ...
	 Train_Loss: 0.2703 Train_Acc: 88.866 Val_Loss: 0.2597  BEST VAL Loss: 0.2597  Val_Acc: 91.070

Epoch 94: Validation loss decreased (0.259728 --> 0.259669).  Saving model ...
	 Train_Loss: 0.2700 Train_Acc: 88.964 Val_Loss: 0.2597  BEST VAL Loss: 0.2597  Val_Acc: 88.710

Epoch 95: Validation loss decreased (0.259669 --> 0.259265).  Saving model ...
	 Train_Loss: 0.2698 Train_Acc: 88.938 Val_Loss: 0.2593  BEST VAL Loss: 0.2593  Val_Acc: 90.826

Epoch 96: Validation loss decreased (0.259265 --> 0.259205).  Saving model ...
	 Train_Loss: 0.2695 Train_Acc: 89.004 Val_Loss: 0.2592  BEST VAL Loss: 0.2592  Val_Acc: 89.646

Epoch 97: Validation loss decreased (0.259205 --> 0.258831).  Saving model ...
	 Train_Loss: 0.2693 Train_Acc: 88.988 Val_Loss: 0.2588  BEST VAL Loss: 0.2588  Val_Acc: 90.799

Epoch 98: Validation loss decreased (0.258831 --> 0.258615).  Saving model ...
	 Train_Loss: 0.2690 Train_Acc: 88.967 Val_Loss: 0.2586  BEST VAL Loss: 0.2586  Val_Acc: 89.923

Epoch 99: Validation loss decreased (0.258615 --> 0.258308).  Saving model ...
	 Train_Loss: 0.2687 Train_Acc: 89.042 Val_Loss: 0.2583  BEST VAL Loss: 0.2583  Val_Acc: 90.697

LPS_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.62      0.62      0.62    149884
           1       0.38      0.38      0.38     92173

    accuracy                           0.53    242057
   macro avg       0.50      0.50      0.50    242057
weighted avg       0.53      0.53      0.53    242057

LPS_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.62      0.62      0.62     18736
           1       0.38      0.37      0.38     11522

    accuracy                           0.53     30258
   macro avg       0.50      0.50      0.50     30258
weighted avg       0.53      0.53      0.53     30258

LPS_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.62      0.62      0.62     18736
           1       0.38      0.38      0.38     11522

    accuracy                           0.53     30258
   macro avg       0.50      0.50      0.50     30258
weighted avg       0.53      0.53      0.53     30258

              precision    recall  f1-score   support

           0       0.62      0.62      0.62     18736
           1       0.38      0.38      0.38     11522

    accuracy                           0.53     30258
   macro avg       0.50      0.50      0.50     30258
weighted avg       0.53      0.53      0.53     30258

LPS_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.40      0.54      0.46     27774
           1       0.60      0.46      0.52     41273

    accuracy                           0.49     69047
   macro avg       0.50      0.50      0.49     69047
weighted avg       0.52      0.49      0.50     69047

              precision    recall  f1-score   support

           0       0.40      0.54      0.46     27774
           1       0.60      0.46      0.52     41273

    accuracy                           0.49     69047
   macro avg       0.50      0.50      0.49     69047
weighted avg       0.52      0.49      0.50     69047

completed
