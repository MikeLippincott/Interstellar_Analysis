[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '0df3c214'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'd2d7be94'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '4645c992'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'a37a340b'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_0.100_DMSO_0.025 treatment_name: Thapsigargin_10.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_0.100_DMSO_0.025
TREATMENT_NAME: Thapsigargin_10.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'LPS_0.100_DMSO_0.025']
The dimensions of the data are: (30722, 1276)
Number of total missing values across all columns: 61444
Data Subset Is Off
Wells held out for testing: ['E14' 'C20']
Wells to use for training, validation, and testing ['E15' 'C16' 'C17' 'C21' 'L14' 'L15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.580469).  Saving model ...
	 Train_Loss: 0.6374 Train_Acc: 63.940 Val_Loss: 0.5805  BEST VAL Loss: 0.5805  Val_Acc: 73.645

Epoch 1: Validation loss decreased (0.580469 --> 0.544449).  Saving model ...
	 Train_Loss: 0.5887 Train_Acc: 77.228 Val_Loss: 0.5444  BEST VAL Loss: 0.5444  Val_Acc: 80.769

Epoch 2: Validation loss decreased (0.544449 --> 0.513549).  Saving model ...
	 Train_Loss: 0.5527 Train_Acc: 81.265 Val_Loss: 0.5135  BEST VAL Loss: 0.5135  Val_Acc: 83.654

Epoch 3: Validation loss decreased (0.513549 --> 0.490924).  Saving model ...
	 Train_Loss: 0.5250 Train_Acc: 83.374 Val_Loss: 0.4909  BEST VAL Loss: 0.4909  Val_Acc: 85.052

Epoch 4: Validation loss decreased (0.490924 --> 0.470035).  Saving model ...
	 Train_Loss: 0.5027 Train_Acc: 84.724 Val_Loss: 0.4700  BEST VAL Loss: 0.4700  Val_Acc: 85.621

Epoch 5: Validation loss decreased (0.470035 --> 0.454958).  Saving model ...
	 Train_Loss: 0.4839 Train_Acc: 86.248 Val_Loss: 0.4550  BEST VAL Loss: 0.4550  Val_Acc: 86.538

Epoch 6: Validation loss decreased (0.454958 --> 0.440846).  Saving model ...
	 Train_Loss: 0.4678 Train_Acc: 86.920 Val_Loss: 0.4408  BEST VAL Loss: 0.4408  Val_Acc: 87.456

Epoch 7: Validation loss decreased (0.440846 --> 0.428302).  Saving model ...
	 Train_Loss: 0.4534 Train_Acc: 87.434 Val_Loss: 0.4283  BEST VAL Loss: 0.4283  Val_Acc: 88.418

Epoch 8: Validation loss decreased (0.428302 --> 0.417682).  Saving model ...
	 Train_Loss: 0.4404 Train_Acc: 88.062 Val_Loss: 0.4177  BEST VAL Loss: 0.4177  Val_Acc: 88.505

Epoch 9: Validation loss decreased (0.417682 --> 0.406744).  Saving model ...
	 Train_Loss: 0.4287 Train_Acc: 88.510 Val_Loss: 0.4067  BEST VAL Loss: 0.4067  Val_Acc: 89.117

Epoch 10: Validation loss decreased (0.406744 --> 0.397567).  Saving model ...
	 Train_Loss: 0.4181 Train_Acc: 89.182 Val_Loss: 0.3976  BEST VAL Loss: 0.3976  Val_Acc: 89.554

Epoch 11: Validation loss decreased (0.397567 --> 0.388683).  Saving model ...
	 Train_Loss: 0.4084 Train_Acc: 89.166 Val_Loss: 0.3887  BEST VAL Loss: 0.3887  Val_Acc: 90.079

Epoch 12: Validation loss decreased (0.388683 --> 0.380910).  Saving model ...
	 Train_Loss: 0.3994 Train_Acc: 90.056 Val_Loss: 0.3809  BEST VAL Loss: 0.3809  Val_Acc: 90.079

Epoch 13: Validation loss decreased (0.380910 --> 0.373229).  Saving model ...
	 Train_Loss: 0.3908 Train_Acc: 90.166 Val_Loss: 0.3732  BEST VAL Loss: 0.3732  Val_Acc: 90.385

Epoch 14: Validation loss decreased (0.373229 --> 0.365756).  Saving model ...
	 Train_Loss: 0.3832 Train_Acc: 90.231 Val_Loss: 0.3658  BEST VAL Loss: 0.3658  Val_Acc: 90.603

Epoch 15: Validation loss decreased (0.365756 --> 0.359339).  Saving model ...
	 Train_Loss: 0.3761 Train_Acc: 90.493 Val_Loss: 0.3593  BEST VAL Loss: 0.3593  Val_Acc: 90.865

Epoch 16: Validation loss decreased (0.359339 --> 0.353392).  Saving model ...
	 Train_Loss: 0.3695 Train_Acc: 90.641 Val_Loss: 0.3534  BEST VAL Loss: 0.3534  Val_Acc: 90.997

Epoch 17: Validation loss decreased (0.353392 --> 0.348132).  Saving model ...
	 Train_Loss: 0.3629 Train_Acc: 91.280 Val_Loss: 0.3481  BEST VAL Loss: 0.3481  Val_Acc: 90.953

Epoch 18: Validation loss decreased (0.348132 --> 0.342214).  Saving model ...
	 Train_Loss: 0.3570 Train_Acc: 91.313 Val_Loss: 0.3422  BEST VAL Loss: 0.3422  Val_Acc: 91.215

Epoch 19: Validation loss decreased (0.342214 --> 0.337389).  Saving model ...
	 Train_Loss: 0.3510 Train_Acc: 91.564 Val_Loss: 0.3374  BEST VAL Loss: 0.3374  Val_Acc: 91.477

Epoch 20: Validation loss decreased (0.337389 --> 0.332227).  Saving model ...
	 Train_Loss: 0.3456 Train_Acc: 91.799 Val_Loss: 0.3322  BEST VAL Loss: 0.3322  Val_Acc: 91.871

Epoch 21: Validation loss decreased (0.332227 --> 0.327407).  Saving model ...
	 Train_Loss: 0.3404 Train_Acc: 92.067 Val_Loss: 0.3274  BEST VAL Loss: 0.3274  Val_Acc: 91.565

Epoch 22: Validation loss decreased (0.327407 --> 0.322958).  Saving model ...
	 Train_Loss: 0.3354 Train_Acc: 92.050 Val_Loss: 0.3230  BEST VAL Loss: 0.3230  Val_Acc: 91.914

Epoch 23: Validation loss decreased (0.322958 --> 0.319039).  Saving model ...
	 Train_Loss: 0.3306 Train_Acc: 92.395 Val_Loss: 0.3190  BEST VAL Loss: 0.3190  Val_Acc: 92.002

Epoch 24: Validation loss decreased (0.319039 --> 0.315194).  Saving model ...
	 Train_Loss: 0.3260 Train_Acc: 92.411 Val_Loss: 0.3152  BEST VAL Loss: 0.3152  Val_Acc: 92.133

Epoch 25: Validation loss decreased (0.315194 --> 0.310944).  Saving model ...
	 Train_Loss: 0.3218 Train_Acc: 92.564 Val_Loss: 0.3109  BEST VAL Loss: 0.3109  Val_Acc: 92.308

Epoch 26: Validation loss decreased (0.310944 --> 0.307172).  Saving model ...
	 Train_Loss: 0.3176 Train_Acc: 92.635 Val_Loss: 0.3072  BEST VAL Loss: 0.3072  Val_Acc: 92.264

Epoch 27: Validation loss decreased (0.307172 --> 0.303713).  Saving model ...
	 Train_Loss: 0.3136 Train_Acc: 93.023 Val_Loss: 0.3037  BEST VAL Loss: 0.3037  Val_Acc: 92.570

Epoch 28: Validation loss decreased (0.303713 --> 0.300653).  Saving model ...
	 Train_Loss: 0.3098 Train_Acc: 92.914 Val_Loss: 0.3007  BEST VAL Loss: 0.3007  Val_Acc: 92.657

Epoch 29: Validation loss decreased (0.300653 --> 0.297335).  Saving model ...
	 Train_Loss: 0.3061 Train_Acc: 93.176 Val_Loss: 0.2973  BEST VAL Loss: 0.2973  Val_Acc: 92.657

Epoch 30: Validation loss decreased (0.297335 --> 0.294578).  Saving model ...
	 Train_Loss: 0.3025 Train_Acc: 93.318 Val_Loss: 0.2946  BEST VAL Loss: 0.2946  Val_Acc: 92.920

Epoch 31: Validation loss decreased (0.294578 --> 0.291514).  Saving model ...
	 Train_Loss: 0.2991 Train_Acc: 93.367 Val_Loss: 0.2915  BEST VAL Loss: 0.2915  Val_Acc: 92.832

Epoch 32: Validation loss decreased (0.291514 --> 0.288677).  Saving model ...
	 Train_Loss: 0.2958 Train_Acc: 93.493 Val_Loss: 0.2887  BEST VAL Loss: 0.2887  Val_Acc: 92.701

Epoch 33: Validation loss decreased (0.288677 --> 0.285866).  Saving model ...
	 Train_Loss: 0.2925 Train_Acc: 93.673 Val_Loss: 0.2859  BEST VAL Loss: 0.2859  Val_Acc: 92.876

Epoch 34: Validation loss decreased (0.285866 --> 0.283244).  Saving model ...
	 Train_Loss: 0.2895 Train_Acc: 93.569 Val_Loss: 0.2832  BEST VAL Loss: 0.2832  Val_Acc: 93.051

Epoch 35: Validation loss decreased (0.283244 --> 0.280812).  Saving model ...
	 Train_Loss: 0.2863 Train_Acc: 93.985 Val_Loss: 0.2808  BEST VAL Loss: 0.2808  Val_Acc: 93.007

Epoch 36: Validation loss decreased (0.280812 --> 0.278165).  Saving model ...
	 Train_Loss: 0.2834 Train_Acc: 93.853 Val_Loss: 0.2782  BEST VAL Loss: 0.2782  Val_Acc: 93.226

Epoch 37: Validation loss decreased (0.278165 --> 0.275779).  Saving model ...
	 Train_Loss: 0.2806 Train_Acc: 94.067 Val_Loss: 0.2758  BEST VAL Loss: 0.2758  Val_Acc: 93.313

Epoch 38: Validation loss decreased (0.275779 --> 0.273191).  Saving model ...
	 Train_Loss: 0.2777 Train_Acc: 94.034 Val_Loss: 0.2732  BEST VAL Loss: 0.2732  Val_Acc: 93.269

Epoch 39: Validation loss decreased (0.273191 --> 0.270808).  Saving model ...
	 Train_Loss: 0.2750 Train_Acc: 93.924 Val_Loss: 0.2708  BEST VAL Loss: 0.2708  Val_Acc: 93.313

Epoch 40: Validation loss decreased (0.270808 --> 0.268289).  Saving model ...
	 Train_Loss: 0.2725 Train_Acc: 94.362 Val_Loss: 0.2683  BEST VAL Loss: 0.2683  Val_Acc: 93.357

Epoch 41: Validation loss decreased (0.268289 --> 0.266123).  Saving model ...
	 Train_Loss: 0.2699 Train_Acc: 94.214 Val_Loss: 0.2661  BEST VAL Loss: 0.2661  Val_Acc: 93.400

Epoch 42: Validation loss decreased (0.266123 --> 0.264296).  Saving model ...
	 Train_Loss: 0.2674 Train_Acc: 94.356 Val_Loss: 0.2643  BEST VAL Loss: 0.2643  Val_Acc: 93.357

Epoch 43: Validation loss decreased (0.264296 --> 0.262131).  Saving model ...
	 Train_Loss: 0.2650 Train_Acc: 94.454 Val_Loss: 0.2621  BEST VAL Loss: 0.2621  Val_Acc: 93.357

Epoch 44: Validation loss decreased (0.262131 --> 0.260204).  Saving model ...
	 Train_Loss: 0.2627 Train_Acc: 94.471 Val_Loss: 0.2602  BEST VAL Loss: 0.2602  Val_Acc: 93.400

Epoch 45: Validation loss decreased (0.260204 --> 0.258204).  Saving model ...
	 Train_Loss: 0.2604 Train_Acc: 94.465 Val_Loss: 0.2582  BEST VAL Loss: 0.2582  Val_Acc: 93.488

Epoch 46: Validation loss decreased (0.258204 --> 0.256278).  Saving model ...
	 Train_Loss: 0.2582 Train_Acc: 94.684 Val_Loss: 0.2563  BEST VAL Loss: 0.2563  Val_Acc: 93.488

Epoch 47: Validation loss decreased (0.256278 --> 0.254680).  Saving model ...
	 Train_Loss: 0.2560 Train_Acc: 94.597 Val_Loss: 0.2547  BEST VAL Loss: 0.2547  Val_Acc: 93.619

Epoch 48: Validation loss decreased (0.254680 --> 0.252908).  Saving model ...
	 Train_Loss: 0.2539 Train_Acc: 94.629 Val_Loss: 0.2529  BEST VAL Loss: 0.2529  Val_Acc: 93.706

Epoch 49: Validation loss decreased (0.252908 --> 0.251180).  Saving model ...
	 Train_Loss: 0.2519 Train_Acc: 94.886 Val_Loss: 0.2512  BEST VAL Loss: 0.2512  Val_Acc: 93.575

Epoch 50: Validation loss decreased (0.251180 --> 0.249584).  Saving model ...
	 Train_Loss: 0.2498 Train_Acc: 94.881 Val_Loss: 0.2496  BEST VAL Loss: 0.2496  Val_Acc: 93.663

Epoch 51: Validation loss decreased (0.249584 --> 0.247833).  Saving model ...
	 Train_Loss: 0.2479 Train_Acc: 94.930 Val_Loss: 0.2478  BEST VAL Loss: 0.2478  Val_Acc: 93.925

Epoch 52: Validation loss decreased (0.247833 --> 0.246551).  Saving model ...
	 Train_Loss: 0.2459 Train_Acc: 95.110 Val_Loss: 0.2466  BEST VAL Loss: 0.2466  Val_Acc: 93.663

Epoch 53: Validation loss decreased (0.246551 --> 0.245021).  Saving model ...
	 Train_Loss: 0.2440 Train_Acc: 95.159 Val_Loss: 0.2450  BEST VAL Loss: 0.2450  Val_Acc: 93.969

Epoch 54: Validation loss decreased (0.245021 --> 0.243442).  Saving model ...
	 Train_Loss: 0.2422 Train_Acc: 95.066 Val_Loss: 0.2434  BEST VAL Loss: 0.2434  Val_Acc: 93.925

Epoch 55: Validation loss decreased (0.243442 --> 0.241862).  Saving model ...
	 Train_Loss: 0.2404 Train_Acc: 95.312 Val_Loss: 0.2419  BEST VAL Loss: 0.2419  Val_Acc: 94.143

Epoch 56: Validation loss decreased (0.241862 --> 0.240458).  Saving model ...
	 Train_Loss: 0.2386 Train_Acc: 95.225 Val_Loss: 0.2405  BEST VAL Loss: 0.2405  Val_Acc: 94.143

Epoch 57: Validation loss decreased (0.240458 --> 0.239025).  Saving model ...
	 Train_Loss: 0.2368 Train_Acc: 95.214 Val_Loss: 0.2390  BEST VAL Loss: 0.2390  Val_Acc: 94.056

Epoch 58: Validation loss decreased (0.239025 --> 0.237656).  Saving model ...
	 Train_Loss: 0.2351 Train_Acc: 95.443 Val_Loss: 0.2377  BEST VAL Loss: 0.2377  Val_Acc: 94.231

Epoch 59: Validation loss decreased (0.237656 --> 0.236360).  Saving model ...
	 Train_Loss: 0.2335 Train_Acc: 95.252 Val_Loss: 0.2364  BEST VAL Loss: 0.2364  Val_Acc: 94.012

Epoch 60: Validation loss decreased (0.236360 --> 0.235098).  Saving model ...
	 Train_Loss: 0.2319 Train_Acc: 95.236 Val_Loss: 0.2351  BEST VAL Loss: 0.2351  Val_Acc: 94.274

Epoch 61: Validation loss decreased (0.235098 --> 0.233779).  Saving model ...
	 Train_Loss: 0.2303 Train_Acc: 95.225 Val_Loss: 0.2338  BEST VAL Loss: 0.2338  Val_Acc: 94.493

Epoch 62: Validation loss decreased (0.233779 --> 0.232544).  Saving model ...
	 Train_Loss: 0.2287 Train_Acc: 95.372 Val_Loss: 0.2325  BEST VAL Loss: 0.2325  Val_Acc: 94.231

Epoch 63: Validation loss decreased (0.232544 --> 0.231194).  Saving model ...
	 Train_Loss: 0.2272 Train_Acc: 95.482 Val_Loss: 0.2312  BEST VAL Loss: 0.2312  Val_Acc: 94.012

Epoch 64: Validation loss decreased (0.231194 --> 0.229809).  Saving model ...
	 Train_Loss: 0.2257 Train_Acc: 95.580 Val_Loss: 0.2298  BEST VAL Loss: 0.2298  Val_Acc: 94.362

Epoch 65: Validation loss decreased (0.229809 --> 0.228578).  Saving model ...
	 Train_Loss: 0.2242 Train_Acc: 95.542 Val_Loss: 0.2286  BEST VAL Loss: 0.2286  Val_Acc: 94.362

Epoch 66: Validation loss decreased (0.228578 --> 0.227240).  Saving model ...
	 Train_Loss: 0.2228 Train_Acc: 95.400 Val_Loss: 0.2272  BEST VAL Loss: 0.2272  Val_Acc: 94.231

Epoch 67: Validation loss decreased (0.227240 --> 0.226007).  Saving model ...
	 Train_Loss: 0.2214 Train_Acc: 95.646 Val_Loss: 0.2260  BEST VAL Loss: 0.2260  Val_Acc: 94.056

Epoch 68: Validation loss decreased (0.226007 --> 0.224844).  Saving model ...
	 Train_Loss: 0.2200 Train_Acc: 95.487 Val_Loss: 0.2248  BEST VAL Loss: 0.2248  Val_Acc: 94.143

Epoch 69: Validation loss decreased (0.224844 --> 0.223706).  Saving model ...
	 Train_Loss: 0.2187 Train_Acc: 95.564 Val_Loss: 0.2237  BEST VAL Loss: 0.2237  Val_Acc: 94.493

Epoch 70: Validation loss decreased (0.223706 --> 0.222546).  Saving model ...
	 Train_Loss: 0.2173 Train_Acc: 95.613 Val_Loss: 0.2225  BEST VAL Loss: 0.2225  Val_Acc: 94.362

Epoch 71: Validation loss decreased (0.222546 --> 0.221581).  Saving model ...
	 Train_Loss: 0.2160 Train_Acc: 95.678 Val_Loss: 0.2216  BEST VAL Loss: 0.2216  Val_Acc: 94.449

Epoch 72: Validation loss decreased (0.221581 --> 0.220596).  Saving model ...
	 Train_Loss: 0.2147 Train_Acc: 95.809 Val_Loss: 0.2206  BEST VAL Loss: 0.2206  Val_Acc: 94.318

Epoch 73: Validation loss decreased (0.220596 --> 0.219526).  Saving model ...
	 Train_Loss: 0.2135 Train_Acc: 95.777 Val_Loss: 0.2195  BEST VAL Loss: 0.2195  Val_Acc: 94.493

Epoch 74: Validation loss decreased (0.219526 --> 0.218699).  Saving model ...
	 Train_Loss: 0.2122 Train_Acc: 95.717 Val_Loss: 0.2187  BEST VAL Loss: 0.2187  Val_Acc: 94.187

Epoch 75: Validation loss decreased (0.218699 --> 0.217738).  Saving model ...
	 Train_Loss: 0.2110 Train_Acc: 95.711 Val_Loss: 0.2177  BEST VAL Loss: 0.2177  Val_Acc: 94.187

Epoch 76: Validation loss decreased (0.217738 --> 0.216826).  Saving model ...
	 Train_Loss: 0.2098 Train_Acc: 95.673 Val_Loss: 0.2168  BEST VAL Loss: 0.2168  Val_Acc: 94.537

Epoch 77: Validation loss decreased (0.216826 --> 0.215853).  Saving model ...
	 Train_Loss: 0.2086 Train_Acc: 95.946 Val_Loss: 0.2159  BEST VAL Loss: 0.2159  Val_Acc: 94.100

Epoch 78: Validation loss decreased (0.215853 --> 0.215035).  Saving model ...
	 Train_Loss: 0.2074 Train_Acc: 95.990 Val_Loss: 0.2150  BEST VAL Loss: 0.2150  Val_Acc: 94.056

Epoch 79: Validation loss decreased (0.215035 --> 0.214231).  Saving model ...
	 Train_Loss: 0.2063 Train_Acc: 96.039 Val_Loss: 0.2142  BEST VAL Loss: 0.2142  Val_Acc: 94.799

Epoch 80: Validation loss decreased (0.214231 --> 0.213192).  Saving model ...
	 Train_Loss: 0.2052 Train_Acc: 95.957 Val_Loss: 0.2132  BEST VAL Loss: 0.2132  Val_Acc: 94.668

Epoch 81: Validation loss decreased (0.213192 --> 0.212547).  Saving model ...
	 Train_Loss: 0.2041 Train_Acc: 96.055 Val_Loss: 0.2125  BEST VAL Loss: 0.2125  Val_Acc: 93.400

Epoch 82: Validation loss decreased (0.212547 --> 0.211650).  Saving model ...
	 Train_Loss: 0.2030 Train_Acc: 96.088 Val_Loss: 0.2117  BEST VAL Loss: 0.2117  Val_Acc: 94.755

Epoch 83: Validation loss decreased (0.211650 --> 0.210739).  Saving model ...
	 Train_Loss: 0.2019 Train_Acc: 96.186 Val_Loss: 0.2107  BEST VAL Loss: 0.2107  Val_Acc: 94.799

Epoch 84: Validation loss decreased (0.210739 --> 0.209981).  Saving model ...
	 Train_Loss: 0.2008 Train_Acc: 96.033 Val_Loss: 0.2100  BEST VAL Loss: 0.2100  Val_Acc: 94.624

Epoch 85: Validation loss decreased (0.209981 --> 0.209092).  Saving model ...
	 Train_Loss: 0.1998 Train_Acc: 96.083 Val_Loss: 0.2091  BEST VAL Loss: 0.2091  Val_Acc: 94.755

Epoch 86: Validation loss decreased (0.209092 --> 0.208223).  Saving model ...
	 Train_Loss: 0.1988 Train_Acc: 96.274 Val_Loss: 0.2082  BEST VAL Loss: 0.2082  Val_Acc: 94.668

Epoch 87: Validation loss decreased (0.208223 --> 0.207468).  Saving model ...
	 Train_Loss: 0.1978 Train_Acc: 96.236 Val_Loss: 0.2075  BEST VAL Loss: 0.2075  Val_Acc: 94.580

Epoch 88: Validation loss decreased (0.207468 --> 0.206726).  Saving model ...
	 Train_Loss: 0.1968 Train_Acc: 96.247 Val_Loss: 0.2067  BEST VAL Loss: 0.2067  Val_Acc: 94.930

Epoch 89: Validation loss decreased (0.206726 --> 0.205979).  Saving model ...
	 Train_Loss: 0.1958 Train_Acc: 96.290 Val_Loss: 0.2060  BEST VAL Loss: 0.2060  Val_Acc: 94.930

Epoch 90: Validation loss decreased (0.205979 --> 0.205320).  Saving model ...
	 Train_Loss: 0.1948 Train_Acc: 96.247 Val_Loss: 0.2053  BEST VAL Loss: 0.2053  Val_Acc: 94.493

Epoch 91: Validation loss decreased (0.205320 --> 0.204590).  Saving model ...
	 Train_Loss: 0.1939 Train_Acc: 96.416 Val_Loss: 0.2046  BEST VAL Loss: 0.2046  Val_Acc: 94.755

Epoch 92: Validation loss decreased (0.204590 --> 0.203768).  Saving model ...
	 Train_Loss: 0.1929 Train_Acc: 96.312 Val_Loss: 0.2038  BEST VAL Loss: 0.2038  Val_Acc: 94.843

Epoch 93: Validation loss decreased (0.203768 --> 0.203057).  Saving model ...
	 Train_Loss: 0.1920 Train_Acc: 96.449 Val_Loss: 0.2031  BEST VAL Loss: 0.2031  Val_Acc: 94.799

Epoch 94: Validation loss decreased (0.203057 --> 0.202290).  Saving model ...
	 Train_Loss: 0.1911 Train_Acc: 96.383 Val_Loss: 0.2023  BEST VAL Loss: 0.2023  Val_Acc: 94.886

Epoch 95: Validation loss decreased (0.202290 --> 0.201599).  Saving model ...
	 Train_Loss: 0.1902 Train_Acc: 96.443 Val_Loss: 0.2016  BEST VAL Loss: 0.2016  Val_Acc: 94.100

Epoch 96: Validation loss decreased (0.201599 --> 0.201018).  Saving model ...
	 Train_Loss: 0.1893 Train_Acc: 96.487 Val_Loss: 0.2010  BEST VAL Loss: 0.2010  Val_Acc: 94.886

Epoch 97: Validation loss decreased (0.201018 --> 0.200411).  Saving model ...
	 Train_Loss: 0.1884 Train_Acc: 96.421 Val_Loss: 0.2004  BEST VAL Loss: 0.2004  Val_Acc: 94.537

Epoch 98: Validation loss decreased (0.200411 --> 0.199757).  Saving model ...
	 Train_Loss: 0.1875 Train_Acc: 96.563 Val_Loss: 0.1998  BEST VAL Loss: 0.1998  Val_Acc: 94.799

Epoch 99: Validation loss decreased (0.199757 --> 0.199115).  Saving model ...
	 Train_Loss: 0.1867 Train_Acc: 96.552 Val_Loss: 0.1991  BEST VAL Loss: 0.1991  Val_Acc: 94.668

LPS_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.57      0.58      0.57     10451
           1       0.43      0.42      0.43      7852

    accuracy                           0.51     18303
   macro avg       0.50      0.50      0.50     18303
weighted avg       0.51      0.51      0.51     18303

LPS_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.57      0.57      0.57      1307
           1       0.42      0.42      0.42       981

    accuracy                           0.50      2288
   macro avg       0.49      0.49      0.49      2288
weighted avg       0.50      0.50      0.50      2288

LPS_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.57      0.57      0.57      1307
           1       0.42      0.42      0.42       981

    accuracy                           0.51      2288
   macro avg       0.50      0.50      0.50      2288
weighted avg       0.51      0.51      0.51      2288

              precision    recall  f1-score   support

           0       0.57      0.57      0.57      1307
           1       0.42      0.42      0.42       981

    accuracy                           0.51      2288
   macro avg       0.50      0.50      0.50      2288
weighted avg       0.51      0.51      0.51      2288

LPS_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.56      0.57      0.57      4445
           1       0.43      0.42      0.43      3398

    accuracy                           0.51      7843
   macro avg       0.50      0.50      0.50      7843
weighted avg       0.51      0.51      0.51      7843

              precision    recall  f1-score   support

           0       0.56      0.57      0.57      4445
           1       0.43      0.42      0.43      3398

    accuracy                           0.51      7843
   macro avg       0.50      0.50      0.50      7843
weighted avg       0.51      0.51      0.51      7843

completed
