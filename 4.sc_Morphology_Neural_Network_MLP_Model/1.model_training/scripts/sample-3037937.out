[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '49cf15aa'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '3518d543'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '416c3212'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '0a70795d'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Flagellin_0.100_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_Nigericin_1.000_1.0_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (261928, 1270)
Number of total missing values across all columns: 191830
Data Subset Is Off
Wells held out for testing: ['K08' 'L10']
Wells to use for training, validation, and testing ['K02' 'K03' 'K09' 'L05' 'L11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.266489).  Saving model ...
	 Train_Loss: 0.3816 Train_Acc: 83.887 Val_Loss: 0.2665  BEST VAL Loss: 0.2665  Val_Acc: 89.796

Epoch 1: Validation loss decreased (0.266489 --> 0.234854).  Saving model ...
	 Train_Loss: 0.3151 Train_Acc: 90.533 Val_Loss: 0.2349  BEST VAL Loss: 0.2349  Val_Acc: 92.295

Epoch 2: Validation loss decreased (0.234854 --> 0.214440).  Saving model ...
	 Train_Loss: 0.2790 Train_Acc: 92.162 Val_Loss: 0.2144  BEST VAL Loss: 0.2144  Val_Acc: 93.473

Epoch 3: Validation loss decreased (0.214440 --> 0.199587).  Saving model ...
	 Train_Loss: 0.2552 Train_Acc: 93.077 Val_Loss: 0.1996  BEST VAL Loss: 0.1996  Val_Acc: 94.253

Epoch 4: Validation loss decreased (0.199587 --> 0.188624).  Saving model ...
	 Train_Loss: 0.2383 Train_Acc: 93.511 Val_Loss: 0.1886  BEST VAL Loss: 0.1886  Val_Acc: 94.524

Epoch 5: Validation loss decreased (0.188624 --> 0.180616).  Saving model ...
	 Train_Loss: 0.2253 Train_Acc: 93.881 Val_Loss: 0.1806  BEST VAL Loss: 0.1806  Val_Acc: 94.535

Epoch 6: Validation loss decreased (0.180616 --> 0.173638).  Saving model ...
	 Train_Loss: 0.2152 Train_Acc: 94.034 Val_Loss: 0.1736  BEST VAL Loss: 0.1736  Val_Acc: 95.044

Epoch 7: Validation loss decreased (0.173638 --> 0.167773).  Saving model ...
	 Train_Loss: 0.2067 Train_Acc: 94.260 Val_Loss: 0.1678  BEST VAL Loss: 0.1678  Val_Acc: 95.124

Epoch 8: Validation loss decreased (0.167773 --> 0.162720).  Saving model ...
	 Train_Loss: 0.1997 Train_Acc: 94.424 Val_Loss: 0.1627  BEST VAL Loss: 0.1627  Val_Acc: 95.230

Epoch 9: Validation loss decreased (0.162720 --> 0.158356).  Saving model ...
	 Train_Loss: 0.1935 Train_Acc: 94.580 Val_Loss: 0.1584  BEST VAL Loss: 0.1584  Val_Acc: 95.437

Epoch 10: Validation loss decreased (0.158356 --> 0.154390).  Saving model ...
	 Train_Loss: 0.1881 Train_Acc: 94.680 Val_Loss: 0.1544  BEST VAL Loss: 0.1544  Val_Acc: 95.564

Epoch 11: Validation loss decreased (0.154390 --> 0.151020).  Saving model ...
	 Train_Loss: 0.1835 Train_Acc: 94.770 Val_Loss: 0.1510  BEST VAL Loss: 0.1510  Val_Acc: 95.660

Epoch 12: Validation loss decreased (0.151020 --> 0.148479).  Saving model ...
	 Train_Loss: 0.1793 Train_Acc: 94.809 Val_Loss: 0.1485  BEST VAL Loss: 0.1485  Val_Acc: 95.495

Epoch 13: Validation loss decreased (0.148479 --> 0.145600).  Saving model ...
	 Train_Loss: 0.1755 Train_Acc: 95.004 Val_Loss: 0.1456  BEST VAL Loss: 0.1456  Val_Acc: 95.920

Epoch 14: Validation loss decreased (0.145600 --> 0.143151).  Saving model ...
	 Train_Loss: 0.1720 Train_Acc: 95.045 Val_Loss: 0.1432  BEST VAL Loss: 0.1432  Val_Acc: 95.803

Epoch 15: Validation loss decreased (0.143151 --> 0.140756).  Saving model ...
	 Train_Loss: 0.1689 Train_Acc: 95.112 Val_Loss: 0.1408  BEST VAL Loss: 0.1408  Val_Acc: 96.079

Epoch 16: Validation loss decreased (0.140756 --> 0.138510).  Saving model ...
	 Train_Loss: 0.1660 Train_Acc: 95.176 Val_Loss: 0.1385  BEST VAL Loss: 0.1385  Val_Acc: 95.989

Epoch 17: Validation loss decreased (0.138510 --> 0.136311).  Saving model ...
	 Train_Loss: 0.1632 Train_Acc: 95.279 Val_Loss: 0.1363  BEST VAL Loss: 0.1363  Val_Acc: 96.243

Epoch 18: Validation loss decreased (0.136311 --> 0.134346).  Saving model ...
	 Train_Loss: 0.1607 Train_Acc: 95.342 Val_Loss: 0.1343  BEST VAL Loss: 0.1343  Val_Acc: 96.323

Epoch 19: Validation loss decreased (0.134346 --> 0.132520).  Saving model ...
	 Train_Loss: 0.1584 Train_Acc: 95.386 Val_Loss: 0.1325  BEST VAL Loss: 0.1325  Val_Acc: 96.180

Epoch 20: Validation loss decreased (0.132520 --> 0.130787).  Saving model ...
	 Train_Loss: 0.1562 Train_Acc: 95.461 Val_Loss: 0.1308  BEST VAL Loss: 0.1308  Val_Acc: 96.296

Epoch 21: Validation loss decreased (0.130787 --> 0.129093).  Saving model ...
	 Train_Loss: 0.1541 Train_Acc: 95.531 Val_Loss: 0.1291  BEST VAL Loss: 0.1291  Val_Acc: 96.455

Epoch 22: Validation loss decreased (0.129093 --> 0.127509).  Saving model ...
	 Train_Loss: 0.1521 Train_Acc: 95.533 Val_Loss: 0.1275  BEST VAL Loss: 0.1275  Val_Acc: 96.471

Epoch 23: Validation loss decreased (0.127509 --> 0.126048).  Saving model ...
	 Train_Loss: 0.1503 Train_Acc: 95.522 Val_Loss: 0.1260  BEST VAL Loss: 0.1260  Val_Acc: 96.461

Epoch 24: Validation loss decreased (0.126048 --> 0.124772).  Saving model ...
	 Train_Loss: 0.1486 Train_Acc: 95.651 Val_Loss: 0.1248  BEST VAL Loss: 0.1248  Val_Acc: 96.413

Epoch 25: Validation loss decreased (0.124772 --> 0.123429).  Saving model ...
	 Train_Loss: 0.1469 Train_Acc: 95.663 Val_Loss: 0.1234  BEST VAL Loss: 0.1234  Val_Acc: 96.519

Epoch 26: Validation loss decreased (0.123429 --> 0.122125).  Saving model ...
	 Train_Loss: 0.1454 Train_Acc: 95.651 Val_Loss: 0.1221  BEST VAL Loss: 0.1221  Val_Acc: 96.615

Epoch 27: Validation loss decreased (0.122125 --> 0.120916).  Saving model ...
	 Train_Loss: 0.1439 Train_Acc: 95.781 Val_Loss: 0.1209  BEST VAL Loss: 0.1209  Val_Acc: 96.567

Epoch 28: Validation loss decreased (0.120916 --> 0.119814).  Saving model ...
	 Train_Loss: 0.1425 Train_Acc: 95.761 Val_Loss: 0.1198  BEST VAL Loss: 0.1198  Val_Acc: 96.700

Epoch 29: Validation loss decreased (0.119814 --> 0.119030).  Saving model ...
	 Train_Loss: 0.1412 Train_Acc: 95.744 Val_Loss: 0.1190  BEST VAL Loss: 0.1190  Val_Acc: 96.323

Epoch 30: Validation loss decreased (0.119030 --> 0.118036).  Saving model ...
	 Train_Loss: 0.1399 Train_Acc: 95.825 Val_Loss: 0.1180  BEST VAL Loss: 0.1180  Val_Acc: 96.737

Epoch 31: Validation loss decreased (0.118036 --> 0.117038).  Saving model ...
	 Train_Loss: 0.1387 Train_Acc: 95.849 Val_Loss: 0.1170  BEST VAL Loss: 0.1170  Val_Acc: 96.715

Epoch 32: Validation loss decreased (0.117038 --> 0.116061).  Saving model ...
	 Train_Loss: 0.1375 Train_Acc: 95.933 Val_Loss: 0.1161  BEST VAL Loss: 0.1161  Val_Acc: 96.731

Epoch 33: Validation loss decreased (0.116061 --> 0.115107).  Saving model ...
	 Train_Loss: 0.1364 Train_Acc: 95.868 Val_Loss: 0.1151  BEST VAL Loss: 0.1151  Val_Acc: 96.827

Epoch 34: Validation loss decreased (0.115107 --> 0.114352).  Saving model ...
	 Train_Loss: 0.1353 Train_Acc: 95.945 Val_Loss: 0.1144  BEST VAL Loss: 0.1144  Val_Acc: 96.604

Epoch 35: Validation loss decreased (0.114352 --> 0.113608).  Saving model ...
	 Train_Loss: 0.1343 Train_Acc: 96.052 Val_Loss: 0.1136  BEST VAL Loss: 0.1136  Val_Acc: 96.684

Epoch 36: Validation loss decreased (0.113608 --> 0.112839).  Saving model ...
	 Train_Loss: 0.1333 Train_Acc: 95.968 Val_Loss: 0.1128  BEST VAL Loss: 0.1128  Val_Acc: 96.763

Epoch 37: Validation loss decreased (0.112839 --> 0.112064).  Saving model ...
	 Train_Loss: 0.1323 Train_Acc: 96.050 Val_Loss: 0.1121  BEST VAL Loss: 0.1121  Val_Acc: 96.721

Epoch 38: Validation loss decreased (0.112064 --> 0.111304).  Saving model ...
	 Train_Loss: 0.1313 Train_Acc: 96.036 Val_Loss: 0.1113  BEST VAL Loss: 0.1113  Val_Acc: 96.933

Epoch 39: Validation loss decreased (0.111304 --> 0.110611).  Saving model ...
	 Train_Loss: 0.1305 Train_Acc: 96.096 Val_Loss: 0.1106  BEST VAL Loss: 0.1106  Val_Acc: 96.790

Epoch 40: Validation loss decreased (0.110611 --> 0.109959).  Saving model ...
	 Train_Loss: 0.1296 Train_Acc: 96.090 Val_Loss: 0.1100  BEST VAL Loss: 0.1100  Val_Acc: 96.779

Epoch 41: Validation loss decreased (0.109959 --> 0.109272).  Saving model ...
	 Train_Loss: 0.1287 Train_Acc: 96.108 Val_Loss: 0.1093  BEST VAL Loss: 0.1093  Val_Acc: 96.907

Epoch 42: Validation loss decreased (0.109272 --> 0.108653).  Saving model ...
	 Train_Loss: 0.1279 Train_Acc: 96.104 Val_Loss: 0.1087  BEST VAL Loss: 0.1087  Val_Acc: 96.933

Epoch 43: Validation loss decreased (0.108653 --> 0.108011).  Saving model ...
	 Train_Loss: 0.1271 Train_Acc: 96.177 Val_Loss: 0.1080  BEST VAL Loss: 0.1080  Val_Acc: 96.917

Epoch 44: Validation loss decreased (0.108011 --> 0.107470).  Saving model ...
	 Train_Loss: 0.1264 Train_Acc: 96.190 Val_Loss: 0.1075  BEST VAL Loss: 0.1075  Val_Acc: 96.891

Epoch 45: Validation loss decreased (0.107470 --> 0.106890).  Saving model ...
	 Train_Loss: 0.1256 Train_Acc: 96.179 Val_Loss: 0.1069  BEST VAL Loss: 0.1069  Val_Acc: 96.912

Epoch 46: Validation loss decreased (0.106890 --> 0.106403).  Saving model ...
	 Train_Loss: 0.1249 Train_Acc: 96.169 Val_Loss: 0.1064  BEST VAL Loss: 0.1064  Val_Acc: 96.960

Epoch 47: Validation loss decreased (0.106403 --> 0.105893).  Saving model ...
	 Train_Loss: 0.1242 Train_Acc: 96.217 Val_Loss: 0.1059  BEST VAL Loss: 0.1059  Val_Acc: 96.970

Epoch 48: Validation loss decreased (0.105893 --> 0.105443).  Saving model ...
	 Train_Loss: 0.1235 Train_Acc: 96.258 Val_Loss: 0.1054  BEST VAL Loss: 0.1054  Val_Acc: 96.853

Epoch 49: Validation loss decreased (0.105443 --> 0.104990).  Saving model ...
	 Train_Loss: 0.1229 Train_Acc: 96.242 Val_Loss: 0.1050  BEST VAL Loss: 0.1050  Val_Acc: 96.758

Epoch 50: Validation loss decreased (0.104990 --> 0.104542).  Saving model ...
	 Train_Loss: 0.1222 Train_Acc: 96.282 Val_Loss: 0.1045  BEST VAL Loss: 0.1045  Val_Acc: 97.013

Epoch 51: Validation loss decreased (0.104542 --> 0.104123).  Saving model ...
	 Train_Loss: 0.1216 Train_Acc: 96.205 Val_Loss: 0.1041  BEST VAL Loss: 0.1041  Val_Acc: 96.912

Epoch 52: Validation loss decreased (0.104123 --> 0.103685).  Saving model ...
	 Train_Loss: 0.1210 Train_Acc: 96.289 Val_Loss: 0.1037  BEST VAL Loss: 0.1037  Val_Acc: 97.018

Epoch 53: Validation loss decreased (0.103685 --> 0.103235).  Saving model ...
	 Train_Loss: 0.1205 Train_Acc: 96.327 Val_Loss: 0.1032  BEST VAL Loss: 0.1032  Val_Acc: 97.007

Epoch 54: Validation loss decreased (0.103235 --> 0.102839).  Saving model ...
	 Train_Loss: 0.1199 Train_Acc: 96.270 Val_Loss: 0.1028  BEST VAL Loss: 0.1028  Val_Acc: 96.965

Epoch 55: Validation loss decreased (0.102839 --> 0.102449).  Saving model ...
	 Train_Loss: 0.1193 Train_Acc: 96.363 Val_Loss: 0.1024  BEST VAL Loss: 0.1024  Val_Acc: 97.108

Epoch 56: Validation loss decreased (0.102449 --> 0.102075).  Saving model ...
	 Train_Loss: 0.1188 Train_Acc: 96.367 Val_Loss: 0.1021  BEST VAL Loss: 0.1021  Val_Acc: 97.050

Epoch 57: Validation loss decreased (0.102075 --> 0.101702).  Saving model ...
	 Train_Loss: 0.1183 Train_Acc: 96.305 Val_Loss: 0.1017  BEST VAL Loss: 0.1017  Val_Acc: 97.007

Epoch 58: Validation loss decreased (0.101702 --> 0.101346).  Saving model ...
	 Train_Loss: 0.1178 Train_Acc: 96.311 Val_Loss: 0.1013  BEST VAL Loss: 0.1013  Val_Acc: 96.965

Epoch 59: Validation loss decreased (0.101346 --> 0.101080).  Saving model ...
	 Train_Loss: 0.1173 Train_Acc: 96.319 Val_Loss: 0.1011  BEST VAL Loss: 0.1011  Val_Acc: 96.827

Epoch 60: Validation loss decreased (0.101080 --> 0.100751).  Saving model ...
	 Train_Loss: 0.1168 Train_Acc: 96.349 Val_Loss: 0.1008  BEST VAL Loss: 0.1008  Val_Acc: 96.991

Epoch 61: Validation loss decreased (0.100751 --> 0.100437).  Saving model ...
	 Train_Loss: 0.1163 Train_Acc: 96.396 Val_Loss: 0.1004  BEST VAL Loss: 0.1004  Val_Acc: 96.981

Epoch 62: Validation loss decreased (0.100437 --> 0.100136).  Saving model ...
	 Train_Loss: 0.1159 Train_Acc: 96.365 Val_Loss: 0.1001  BEST VAL Loss: 0.1001  Val_Acc: 97.034

Epoch 63: Validation loss decreased (0.100136 --> 0.099816).  Saving model ...
	 Train_Loss: 0.1154 Train_Acc: 96.396 Val_Loss: 0.0998  BEST VAL Loss: 0.0998  Val_Acc: 97.113

Epoch 64: Validation loss decreased (0.099816 --> 0.099517).  Saving model ...
	 Train_Loss: 0.1150 Train_Acc: 96.394 Val_Loss: 0.0995  BEST VAL Loss: 0.0995  Val_Acc: 96.986

Epoch 65: Validation loss decreased (0.099517 --> 0.099211).  Saving model ...
	 Train_Loss: 0.1145 Train_Acc: 96.480 Val_Loss: 0.0992  BEST VAL Loss: 0.0992  Val_Acc: 97.177

Epoch 66: Validation loss decreased (0.099211 --> 0.098950).  Saving model ...
	 Train_Loss: 0.1141 Train_Acc: 96.384 Val_Loss: 0.0990  BEST VAL Loss: 0.0990  Val_Acc: 96.975

Epoch 67: Validation loss decreased (0.098950 --> 0.098702).  Saving model ...
	 Train_Loss: 0.1137 Train_Acc: 96.406 Val_Loss: 0.0987  BEST VAL Loss: 0.0987  Val_Acc: 97.082

Epoch 68: Validation loss decreased (0.098702 --> 0.098426).  Saving model ...
	 Train_Loss: 0.1133 Train_Acc: 96.443 Val_Loss: 0.0984  BEST VAL Loss: 0.0984  Val_Acc: 97.113

Epoch 69: Validation loss decreased (0.098426 --> 0.098189).  Saving model ...
	 Train_Loss: 0.1129 Train_Acc: 96.438 Val_Loss: 0.0982  BEST VAL Loss: 0.0982  Val_Acc: 97.039

Epoch 70: Validation loss decreased (0.098189 --> 0.098003).  Saving model ...
	 Train_Loss: 0.1125 Train_Acc: 96.491 Val_Loss: 0.0980  BEST VAL Loss: 0.0980  Val_Acc: 96.907

Epoch 71: Validation loss decreased (0.098003 --> 0.097738).  Saving model ...
	 Train_Loss: 0.1121 Train_Acc: 96.466 Val_Loss: 0.0977  BEST VAL Loss: 0.0977  Val_Acc: 97.055

Epoch 72: Validation loss decreased (0.097738 --> 0.097463).  Saving model ...
	 Train_Loss: 0.1118 Train_Acc: 96.451 Val_Loss: 0.0975  BEST VAL Loss: 0.0975  Val_Acc: 97.029

Epoch 73: Validation loss decreased (0.097463 --> 0.097328).  Saving model ...
	 Train_Loss: 0.1114 Train_Acc: 96.437 Val_Loss: 0.0973  BEST VAL Loss: 0.0973  Val_Acc: 96.848

Epoch 74: Validation loss decreased (0.097328 --> 0.097105).  Saving model ...
	 Train_Loss: 0.1110 Train_Acc: 96.443 Val_Loss: 0.0971  BEST VAL Loss: 0.0971  Val_Acc: 97.082

Epoch 75: Validation loss decreased (0.097105 --> 0.096859).  Saving model ...
	 Train_Loss: 0.1107 Train_Acc: 96.457 Val_Loss: 0.0969  BEST VAL Loss: 0.0969  Val_Acc: 97.113

Epoch 76: Validation loss decreased (0.096859 --> 0.096644).  Saving model ...
	 Train_Loss: 0.1103 Train_Acc: 96.522 Val_Loss: 0.0966  BEST VAL Loss: 0.0966  Val_Acc: 97.023

Epoch 77: Validation loss decreased (0.096644 --> 0.096449).  Saving model ...
	 Train_Loss: 0.1100 Train_Acc: 96.504 Val_Loss: 0.0964  BEST VAL Loss: 0.0964  Val_Acc: 97.055

Epoch 78: Validation loss decreased (0.096449 --> 0.096242).  Saving model ...
	 Train_Loss: 0.1097 Train_Acc: 96.565 Val_Loss: 0.0962  BEST VAL Loss: 0.0962  Val_Acc: 97.039

Epoch 79: Validation loss decreased (0.096242 --> 0.096069).  Saving model ...
	 Train_Loss: 0.1093 Train_Acc: 96.542 Val_Loss: 0.0961  BEST VAL Loss: 0.0961  Val_Acc: 97.193

Epoch 80: Validation loss decreased (0.096069 --> 0.095891).  Saving model ...
	 Train_Loss: 0.1090 Train_Acc: 96.528 Val_Loss: 0.0959  BEST VAL Loss: 0.0959  Val_Acc: 96.922

Epoch 81: Validation loss decreased (0.095891 --> 0.095696).  Saving model ...
	 Train_Loss: 0.1087 Train_Acc: 96.556 Val_Loss: 0.0957  BEST VAL Loss: 0.0957  Val_Acc: 96.949

Epoch 82: Validation loss decreased (0.095696 --> 0.095480).  Saving model ...
	 Train_Loss: 0.1084 Train_Acc: 96.553 Val_Loss: 0.0955  BEST VAL Loss: 0.0955  Val_Acc: 97.119

Epoch 83: Validation loss decreased (0.095480 --> 0.095281).  Saving model ...
	 Train_Loss: 0.1080 Train_Acc: 96.571 Val_Loss: 0.0953  BEST VAL Loss: 0.0953  Val_Acc: 97.050

Epoch 84: Validation loss decreased (0.095281 --> 0.095133).  Saving model ...
	 Train_Loss: 0.1078 Train_Acc: 96.579 Val_Loss: 0.0951  BEST VAL Loss: 0.0951  Val_Acc: 97.023

Epoch 85: Validation loss decreased (0.095133 --> 0.094975).  Saving model ...
	 Train_Loss: 0.1075 Train_Acc: 96.510 Val_Loss: 0.0950  BEST VAL Loss: 0.0950  Val_Acc: 97.060

Epoch 86: Validation loss decreased (0.094975 --> 0.094812).  Saving model ...
	 Train_Loss: 0.1072 Train_Acc: 96.557 Val_Loss: 0.0948  BEST VAL Loss: 0.0948  Val_Acc: 96.885

Epoch 87: Validation loss decreased (0.094812 --> 0.094642).  Saving model ...
	 Train_Loss: 0.1069 Train_Acc: 96.566 Val_Loss: 0.0946  BEST VAL Loss: 0.0946  Val_Acc: 97.034

Epoch 88: Validation loss decreased (0.094642 --> 0.094505).  Saving model ...
	 Train_Loss: 0.1066 Train_Acc: 96.583 Val_Loss: 0.0945  BEST VAL Loss: 0.0945  Val_Acc: 97.055

Epoch 89: Validation loss decreased (0.094505 --> 0.094345).  Saving model ...
	 Train_Loss: 0.1063 Train_Acc: 96.601 Val_Loss: 0.0943  BEST VAL Loss: 0.0943  Val_Acc: 97.066

Epoch 90: Validation loss decreased (0.094345 --> 0.094174).  Saving model ...
	 Train_Loss: 0.1061 Train_Acc: 96.547 Val_Loss: 0.0942  BEST VAL Loss: 0.0942  Val_Acc: 97.188

Epoch 91: Validation loss decreased (0.094174 --> 0.094039).  Saving model ...
	 Train_Loss: 0.1058 Train_Acc: 96.637 Val_Loss: 0.0940  BEST VAL Loss: 0.0940  Val_Acc: 97.029

Epoch 92: Validation loss decreased (0.094039 --> 0.093878).  Saving model ...
	 Train_Loss: 0.1055 Train_Acc: 96.577 Val_Loss: 0.0939  BEST VAL Loss: 0.0939  Val_Acc: 97.188

Epoch 93: Validation loss decreased (0.093878 --> 0.093769).  Saving model ...
	 Train_Loss: 0.1053 Train_Acc: 96.607 Val_Loss: 0.0938  BEST VAL Loss: 0.0938  Val_Acc: 97.044

Epoch 94: Validation loss decreased (0.093769 --> 0.093638).  Saving model ...
	 Train_Loss: 0.1050 Train_Acc: 96.571 Val_Loss: 0.0936  BEST VAL Loss: 0.0936  Val_Acc: 96.991

Epoch 95: Validation loss decreased (0.093638 --> 0.093495).  Saving model ...
	 Train_Loss: 0.1048 Train_Acc: 96.624 Val_Loss: 0.0935  BEST VAL Loss: 0.0935  Val_Acc: 97.198

Epoch 96: Validation loss decreased (0.093495 --> 0.093405).  Saving model ...
	 Train_Loss: 0.1045 Train_Acc: 96.661 Val_Loss: 0.0934  BEST VAL Loss: 0.0934  Val_Acc: 96.970

Epoch 97: Validation loss decreased (0.093405 --> 0.093290).  Saving model ...
	 Train_Loss: 0.1043 Train_Acc: 96.672 Val_Loss: 0.0933  BEST VAL Loss: 0.0933  Val_Acc: 97.108

Epoch 98: Validation loss decreased (0.093290 --> 0.093151).  Saving model ...
	 Train_Loss: 0.1040 Train_Acc: 96.650 Val_Loss: 0.0932  BEST VAL Loss: 0.0932  Val_Acc: 97.188

Epoch 99: Validation loss decreased (0.093151 --> 0.093046).  Saving model ...
	 Train_Loss: 0.1038 Train_Acc: 96.698 Val_Loss: 0.0930  BEST VAL Loss: 0.0930  Val_Acc: 97.071

Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.33      0.33      0.33     50422
           1       0.66      0.67      0.67    100339

    accuracy                           0.55    150761
   macro avg       0.50      0.50      0.50    150761
weighted avg       0.55      0.55      0.55    150761

Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.33      0.32      0.32      6303
           1       0.66      0.67      0.66     12543

    accuracy                           0.55     18846
   macro avg       0.49      0.49      0.49     18846
weighted avg       0.55      0.55      0.55     18846

Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.33      0.32      0.33      6303
           1       0.66      0.67      0.66     12543

    accuracy                           0.55     18846
   macro avg       0.49      0.49      0.49     18846
weighted avg       0.55      0.55      0.55     18846

              precision    recall  f1-score   support

           0       0.33      0.32      0.33      6303
           1       0.66      0.67      0.66     12543

    accuracy                           0.55     18846
   macro avg       0.49      0.49      0.49     18846
weighted avg       0.55      0.55      0.55     18846

Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.45      0.43      0.44     32887
           1       0.55      0.57      0.56     40588

    accuracy                           0.51     73475
   macro avg       0.50      0.50      0.50     73475
weighted avg       0.51      0.51      0.51     73475

              precision    recall  f1-score   support

           0       0.45      0.43      0.44     32887
           1       0.55      0.57      0.56     40588

    accuracy                           0.51     73475
   macro avg       0.50      0.50      0.50     73475
weighted avg       0.51      0.51      0.51     73475

completed
