[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '876f1dd3'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '2ad8072e'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '180eb84f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'f2c9d55d'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_10.000_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (31738, 1276)
Number of total missing values across all columns: 63476
Data Subset Is Off
Wells held out for testing: ['E21' 'L22']
Wells to use for training, validation, and testing ['E16' 'E17' 'E20' 'L18' 'L19' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.682523).  Saving model ...
	 Train_Loss: 0.6903 Train_Acc: 55.091 Val_Loss: 0.6825  BEST VAL Loss: 0.6825  Val_Acc: 55.333

Epoch 1: Validation loss decreased (0.682523 --> 0.679137).  Saving model ...
	 Train_Loss: 0.6844 Train_Acc: 56.745 Val_Loss: 0.6791  BEST VAL Loss: 0.6791  Val_Acc: 56.570

Epoch 2: Validation loss decreased (0.679137 --> 0.675962).  Saving model ...
	 Train_Loss: 0.6804 Train_Acc: 58.047 Val_Loss: 0.6760  BEST VAL Loss: 0.6760  Val_Acc: 57.807

Epoch 3: Validation loss decreased (0.675962 --> 0.672770).  Saving model ...
	 Train_Loss: 0.6766 Train_Acc: 59.444 Val_Loss: 0.6728  BEST VAL Loss: 0.6728  Val_Acc: 59.428

Epoch 4: Validation loss decreased (0.672770 --> 0.669605).  Saving model ...
	 Train_Loss: 0.6728 Train_Acc: 60.895 Val_Loss: 0.6696  BEST VAL Loss: 0.6696  Val_Acc: 60.794

Epoch 5: Validation loss decreased (0.669605 --> 0.666462).  Saving model ...
	 Train_Loss: 0.6691 Train_Acc: 62.202 Val_Loss: 0.6665  BEST VAL Loss: 0.6665  Val_Acc: 62.500

Epoch 6: Validation loss decreased (0.666462 --> 0.663293).  Saving model ...
	 Train_Loss: 0.6653 Train_Acc: 63.274 Val_Loss: 0.6633  BEST VAL Loss: 0.6633  Val_Acc: 63.055

Epoch 7: Validation loss decreased (0.663293 --> 0.660174).  Saving model ...
	 Train_Loss: 0.6616 Train_Acc: 64.202 Val_Loss: 0.6602  BEST VAL Loss: 0.6602  Val_Acc: 63.908

Epoch 8: Validation loss decreased (0.660174 --> 0.657035).  Saving model ...
	 Train_Loss: 0.6577 Train_Acc: 65.061 Val_Loss: 0.6570  BEST VAL Loss: 0.6570  Val_Acc: 65.060

Epoch 9: Validation loss decreased (0.657035 --> 0.653920).  Saving model ...
	 Train_Loss: 0.6539 Train_Acc: 65.675 Val_Loss: 0.6539  BEST VAL Loss: 0.6539  Val_Acc: 65.444

Epoch 10: Validation loss decreased (0.653920 --> 0.650811).  Saving model ...
	 Train_Loss: 0.6500 Train_Acc: 66.704 Val_Loss: 0.6508  BEST VAL Loss: 0.6508  Val_Acc: 65.828

Epoch 11: Validation loss decreased (0.650811 --> 0.647732).  Saving model ...
	 Train_Loss: 0.6461 Train_Acc: 67.301 Val_Loss: 0.6477  BEST VAL Loss: 0.6477  Val_Acc: 66.382

Epoch 12: Validation loss decreased (0.647732 --> 0.644677).  Saving model ...
	 Train_Loss: 0.6421 Train_Acc: 68.064 Val_Loss: 0.6447  BEST VAL Loss: 0.6447  Val_Acc: 66.766

Epoch 13: Validation loss decreased (0.644677 --> 0.641688).  Saving model ...
	 Train_Loss: 0.6383 Train_Acc: 68.555 Val_Loss: 0.6417  BEST VAL Loss: 0.6417  Val_Acc: 67.363

Epoch 14: Validation loss decreased (0.641688 --> 0.638660).  Saving model ...
	 Train_Loss: 0.6345 Train_Acc: 69.355 Val_Loss: 0.6387  BEST VAL Loss: 0.6387  Val_Acc: 67.534

Epoch 15: Validation loss decreased (0.638660 --> 0.635742).  Saving model ...
	 Train_Loss: 0.6307 Train_Acc: 69.921 Val_Loss: 0.6357  BEST VAL Loss: 0.6357  Val_Acc: 68.473

Epoch 16: Validation loss decreased (0.635742 --> 0.632859).  Saving model ...
	 Train_Loss: 0.6272 Train_Acc: 69.857 Val_Loss: 0.6329  BEST VAL Loss: 0.6329  Val_Acc: 68.899

Epoch 17: Validation loss decreased (0.632859 --> 0.630019).  Saving model ...
	 Train_Loss: 0.6235 Train_Acc: 71.025 Val_Loss: 0.6300  BEST VAL Loss: 0.6300  Val_Acc: 69.369

Epoch 18: Validation loss decreased (0.630019 --> 0.627151).  Saving model ...
	 Train_Loss: 0.6198 Train_Acc: 71.531 Val_Loss: 0.6272  BEST VAL Loss: 0.6272  Val_Acc: 69.838

Epoch 19: Validation loss decreased (0.627151 --> 0.624304).  Saving model ...
	 Train_Loss: 0.6162 Train_Acc: 72.145 Val_Loss: 0.6243  BEST VAL Loss: 0.6243  Val_Acc: 70.776

Epoch 20: Validation loss decreased (0.624304 --> 0.621482).  Saving model ...
	 Train_Loss: 0.6127 Train_Acc: 72.988 Val_Loss: 0.6215  BEST VAL Loss: 0.6215  Val_Acc: 71.203

Epoch 21: Validation loss decreased (0.621482 --> 0.618682).  Saving model ...
	 Train_Loss: 0.6091 Train_Acc: 73.190 Val_Loss: 0.6187  BEST VAL Loss: 0.6187  Val_Acc: 71.758

Epoch 22: Validation loss decreased (0.618682 --> 0.615907).  Saving model ...
	 Train_Loss: 0.6056 Train_Acc: 73.612 Val_Loss: 0.6159  BEST VAL Loss: 0.6159  Val_Acc: 72.312

Epoch 23: Validation loss decreased (0.615907 --> 0.613163).  Saving model ...
	 Train_Loss: 0.6021 Train_Acc: 73.798 Val_Loss: 0.6132  BEST VAL Loss: 0.6132  Val_Acc: 72.611

Epoch 24: Validation loss decreased (0.613163 --> 0.610404).  Saving model ...
	 Train_Loss: 0.5986 Train_Acc: 74.556 Val_Loss: 0.6104  BEST VAL Loss: 0.6104  Val_Acc: 72.824

Epoch 25: Validation loss decreased (0.610404 --> 0.607791).  Saving model ...
	 Train_Loss: 0.5952 Train_Acc: 74.567 Val_Loss: 0.6078  BEST VAL Loss: 0.6078  Val_Acc: 72.995

Epoch 26: Validation loss decreased (0.607791 --> 0.605142).  Saving model ...
	 Train_Loss: 0.5918 Train_Acc: 75.047 Val_Loss: 0.6051  BEST VAL Loss: 0.6051  Val_Acc: 73.677

Epoch 27: Validation loss decreased (0.605142 --> 0.602554).  Saving model ...
	 Train_Loss: 0.5884 Train_Acc: 75.217 Val_Loss: 0.6026  BEST VAL Loss: 0.6026  Val_Acc: 74.232

Epoch 28: Validation loss decreased (0.602554 --> 0.600016).  Saving model ...
	 Train_Loss: 0.5852 Train_Acc: 75.601 Val_Loss: 0.6000  BEST VAL Loss: 0.6000  Val_Acc: 74.445

Epoch 29: Validation loss decreased (0.600016 --> 0.597566).  Saving model ...
	 Train_Loss: 0.5819 Train_Acc: 75.916 Val_Loss: 0.5976  BEST VAL Loss: 0.5976  Val_Acc: 74.829

Epoch 30: Validation loss decreased (0.597566 --> 0.595187).  Saving model ...
	 Train_Loss: 0.5789 Train_Acc: 76.114 Val_Loss: 0.5952  BEST VAL Loss: 0.5952  Val_Acc: 74.872

Epoch 31: Validation loss decreased (0.595187 --> 0.592872).  Saving model ...
	 Train_Loss: 0.5758 Train_Acc: 76.375 Val_Loss: 0.5929  BEST VAL Loss: 0.5929  Val_Acc: 75.256

Epoch 32: Validation loss decreased (0.592872 --> 0.590659).  Saving model ...
	 Train_Loss: 0.5727 Train_Acc: 76.695 Val_Loss: 0.5907  BEST VAL Loss: 0.5907  Val_Acc: 75.128

Epoch 33: Validation loss decreased (0.590659 --> 0.588489).  Saving model ...
	 Train_Loss: 0.5696 Train_Acc: 77.223 Val_Loss: 0.5885  BEST VAL Loss: 0.5885  Val_Acc: 75.597

Epoch 34: Validation loss decreased (0.588489 --> 0.586379).  Saving model ...
	 Train_Loss: 0.5666 Train_Acc: 77.468 Val_Loss: 0.5864  BEST VAL Loss: 0.5864  Val_Acc: 75.384

Epoch 35: Validation loss decreased (0.586379 --> 0.584360).  Saving model ...
	 Train_Loss: 0.5637 Train_Acc: 77.906 Val_Loss: 0.5844  BEST VAL Loss: 0.5844  Val_Acc: 75.939

Epoch 36: Validation loss decreased (0.584360 --> 0.582415).  Saving model ...
	 Train_Loss: 0.5609 Train_Acc: 77.436 Val_Loss: 0.5824  BEST VAL Loss: 0.5824  Val_Acc: 75.811

Epoch 37: Validation loss decreased (0.582415 --> 0.580548).  Saving model ...
	 Train_Loss: 0.5582 Train_Acc: 78.189 Val_Loss: 0.5805  BEST VAL Loss: 0.5805  Val_Acc: 75.555

Epoch 38: Validation loss decreased (0.580548 --> 0.578772).  Saving model ...
	 Train_Loss: 0.5554 Train_Acc: 78.578 Val_Loss: 0.5788  BEST VAL Loss: 0.5788  Val_Acc: 75.981

Epoch 39: Validation loss decreased (0.578772 --> 0.577017).  Saving model ...
	 Train_Loss: 0.5527 Train_Acc: 78.594 Val_Loss: 0.5770  BEST VAL Loss: 0.5770  Val_Acc: 76.109

Epoch 40: Validation loss decreased (0.577017 --> 0.575299).  Saving model ...
	 Train_Loss: 0.5502 Train_Acc: 78.615 Val_Loss: 0.5753  BEST VAL Loss: 0.5753  Val_Acc: 75.896

Epoch 41: Validation loss decreased (0.575299 --> 0.573630).  Saving model ...
	 Train_Loss: 0.5476 Train_Acc: 78.727 Val_Loss: 0.5736  BEST VAL Loss: 0.5736  Val_Acc: 76.280

Epoch 42: Validation loss decreased (0.573630 --> 0.571982).  Saving model ...
	 Train_Loss: 0.5451 Train_Acc: 78.989 Val_Loss: 0.5720  BEST VAL Loss: 0.5720  Val_Acc: 76.408

Epoch 43: Validation loss decreased (0.571982 --> 0.570418).  Saving model ...
	 Train_Loss: 0.5427 Train_Acc: 79.282 Val_Loss: 0.5704  BEST VAL Loss: 0.5704  Val_Acc: 76.195

Epoch 44: Validation loss decreased (0.570418 --> 0.568903).  Saving model ...
	 Train_Loss: 0.5402 Train_Acc: 79.501 Val_Loss: 0.5689  BEST VAL Loss: 0.5689  Val_Acc: 75.981

Epoch 45: Validation loss decreased (0.568903 --> 0.567386).  Saving model ...
	 Train_Loss: 0.5379 Train_Acc: 79.266 Val_Loss: 0.5674  BEST VAL Loss: 0.5674  Val_Acc: 76.323

Epoch 46: Validation loss decreased (0.567386 --> 0.565943).  Saving model ...
	 Train_Loss: 0.5357 Train_Acc: 79.154 Val_Loss: 0.5659  BEST VAL Loss: 0.5659  Val_Acc: 76.280

Epoch 47: Validation loss decreased (0.565943 --> 0.564566).  Saving model ...
	 Train_Loss: 0.5334 Train_Acc: 79.837 Val_Loss: 0.5646  BEST VAL Loss: 0.5646  Val_Acc: 75.939

Epoch 48: Validation loss decreased (0.564566 --> 0.563208).  Saving model ...
	 Train_Loss: 0.5312 Train_Acc: 79.735 Val_Loss: 0.5632  BEST VAL Loss: 0.5632  Val_Acc: 76.493

Epoch 49: Validation loss decreased (0.563208 --> 0.561853).  Saving model ...
	 Train_Loss: 0.5289 Train_Acc: 80.445 Val_Loss: 0.5619  BEST VAL Loss: 0.5619  Val_Acc: 76.962

Epoch 50: Validation loss decreased (0.561853 --> 0.560611).  Saving model ...
	 Train_Loss: 0.5268 Train_Acc: 80.296 Val_Loss: 0.5606  BEST VAL Loss: 0.5606  Val_Acc: 76.877

Epoch 51: Validation loss decreased (0.560611 --> 0.559429).  Saving model ...
	 Train_Loss: 0.5247 Train_Acc: 80.674 Val_Loss: 0.5594  BEST VAL Loss: 0.5594  Val_Acc: 76.834

Epoch 52: Validation loss decreased (0.559429 --> 0.558231).  Saving model ...
	 Train_Loss: 0.5226 Train_Acc: 80.600 Val_Loss: 0.5582  BEST VAL Loss: 0.5582  Val_Acc: 76.578

Epoch 53: Validation loss decreased (0.558231 --> 0.557041).  Saving model ...
	 Train_Loss: 0.5205 Train_Acc: 80.536 Val_Loss: 0.5570  BEST VAL Loss: 0.5570  Val_Acc: 76.323

Epoch 54: Validation loss decreased (0.557041 --> 0.555899).  Saving model ...
	 Train_Loss: 0.5185 Train_Acc: 80.744 Val_Loss: 0.5559  BEST VAL Loss: 0.5559  Val_Acc: 76.451

Epoch 55: Validation loss decreased (0.555899 --> 0.554837).  Saving model ...
	 Train_Loss: 0.5165 Train_Acc: 80.936 Val_Loss: 0.5548  BEST VAL Loss: 0.5548  Val_Acc: 76.621

Epoch 56: Validation loss decreased (0.554837 --> 0.553762).  Saving model ...
	 Train_Loss: 0.5146 Train_Acc: 81.165 Val_Loss: 0.5538  BEST VAL Loss: 0.5538  Val_Acc: 76.749

Epoch 57: Validation loss decreased (0.553762 --> 0.552733).  Saving model ...
	 Train_Loss: 0.5127 Train_Acc: 80.792 Val_Loss: 0.5527  BEST VAL Loss: 0.5527  Val_Acc: 76.877

Epoch 58: Validation loss decreased (0.552733 --> 0.551774).  Saving model ...
	 Train_Loss: 0.5109 Train_Acc: 80.968 Val_Loss: 0.5518  BEST VAL Loss: 0.5518  Val_Acc: 76.920

Epoch 59: Validation loss decreased (0.551774 --> 0.550847).  Saving model ...
	 Train_Loss: 0.5090 Train_Acc: 81.437 Val_Loss: 0.5508  BEST VAL Loss: 0.5508  Val_Acc: 76.451

Epoch 60: Validation loss decreased (0.550847 --> 0.549959).  Saving model ...
	 Train_Loss: 0.5071 Train_Acc: 81.752 Val_Loss: 0.5500  BEST VAL Loss: 0.5500  Val_Acc: 76.408

Epoch 61: Validation loss decreased (0.549959 --> 0.549086).  Saving model ...
	 Train_Loss: 0.5054 Train_Acc: 81.650 Val_Loss: 0.5491  BEST VAL Loss: 0.5491  Val_Acc: 76.109

Epoch 62: Validation loss decreased (0.549086 --> 0.548273).  Saving model ...
	 Train_Loss: 0.5036 Train_Acc: 81.784 Val_Loss: 0.5483  BEST VAL Loss: 0.5483  Val_Acc: 76.451

Epoch 63: Validation loss decreased (0.548273 --> 0.547413).  Saving model ...
	 Train_Loss: 0.5018 Train_Acc: 81.890 Val_Loss: 0.5474  BEST VAL Loss: 0.5474  Val_Acc: 76.664

Epoch 64: Validation loss decreased (0.547413 --> 0.546637).  Saving model ...
	 Train_Loss: 0.5001 Train_Acc: 82.114 Val_Loss: 0.5466  BEST VAL Loss: 0.5466  Val_Acc: 76.706

Epoch 65: Validation loss decreased (0.546637 --> 0.545922).  Saving model ...
	 Train_Loss: 0.4984 Train_Acc: 82.173 Val_Loss: 0.5459  BEST VAL Loss: 0.5459  Val_Acc: 76.280

Epoch 66: Validation loss decreased (0.545922 --> 0.545195).  Saving model ...
	 Train_Loss: 0.4968 Train_Acc: 81.954 Val_Loss: 0.5452  BEST VAL Loss: 0.5452  Val_Acc: 76.621

Epoch 67: Validation loss decreased (0.545195 --> 0.544442).  Saving model ...
	 Train_Loss: 0.4952 Train_Acc: 82.253 Val_Loss: 0.5444  BEST VAL Loss: 0.5444  Val_Acc: 76.536

Epoch 68: Validation loss decreased (0.544442 --> 0.543684).  Saving model ...
	 Train_Loss: 0.4935 Train_Acc: 82.221 Val_Loss: 0.5437  BEST VAL Loss: 0.5437  Val_Acc: 77.133

Epoch 69: Validation loss decreased (0.543684 --> 0.543040).  Saving model ...
	 Train_Loss: 0.4920 Train_Acc: 82.408 Val_Loss: 0.5430  BEST VAL Loss: 0.5430  Val_Acc: 76.280

Epoch 70: Validation loss decreased (0.543040 --> 0.542396).  Saving model ...
	 Train_Loss: 0.4904 Train_Acc: 82.589 Val_Loss: 0.5424  BEST VAL Loss: 0.5424  Val_Acc: 76.749

Epoch 71: Validation loss decreased (0.542396 --> 0.541831).  Saving model ...
	 Train_Loss: 0.4888 Train_Acc: 82.616 Val_Loss: 0.5418  BEST VAL Loss: 0.5418  Val_Acc: 76.664

Epoch 72: Validation loss decreased (0.541831 --> 0.541209).  Saving model ...
	 Train_Loss: 0.4874 Train_Acc: 82.600 Val_Loss: 0.5412  BEST VAL Loss: 0.5412  Val_Acc: 76.451

Epoch 73: Validation loss decreased (0.541209 --> 0.540572).  Saving model ...
	 Train_Loss: 0.4858 Train_Acc: 83.176 Val_Loss: 0.5406  BEST VAL Loss: 0.5406  Val_Acc: 76.877

Epoch 74: Validation loss decreased (0.540572 --> 0.539970).  Saving model ...
	 Train_Loss: 0.4844 Train_Acc: 82.696 Val_Loss: 0.5400  BEST VAL Loss: 0.5400  Val_Acc: 76.877

Epoch 75: Validation loss decreased (0.539970 --> 0.539380).  Saving model ...
	 Train_Loss: 0.4829 Train_Acc: 83.160 Val_Loss: 0.5394  BEST VAL Loss: 0.5394  Val_Acc: 77.005

Epoch 76: Validation loss decreased (0.539380 --> 0.538820).  Saving model ...
	 Train_Loss: 0.4815 Train_Acc: 82.840 Val_Loss: 0.5388  BEST VAL Loss: 0.5388  Val_Acc: 77.048

Epoch 77: Validation loss decreased (0.538820 --> 0.538244).  Saving model ...
	 Train_Loss: 0.4800 Train_Acc: 83.587 Val_Loss: 0.5382  BEST VAL Loss: 0.5382  Val_Acc: 77.602

Epoch 78: Validation loss decreased (0.538244 --> 0.537725).  Saving model ...
	 Train_Loss: 0.4786 Train_Acc: 83.165 Val_Loss: 0.5377  BEST VAL Loss: 0.5377  Val_Acc: 77.176

Epoch 79: Validation loss decreased (0.537725 --> 0.537236).  Saving model ...
	 Train_Loss: 0.4773 Train_Acc: 83.448 Val_Loss: 0.5372  BEST VAL Loss: 0.5372  Val_Acc: 77.133

Epoch 80: Validation loss decreased (0.537236 --> 0.536717).  Saving model ...
	 Train_Loss: 0.4758 Train_Acc: 83.949 Val_Loss: 0.5367  BEST VAL Loss: 0.5367  Val_Acc: 77.389

Epoch 81: Validation loss decreased (0.536717 --> 0.536280).  Saving model ...
	 Train_Loss: 0.4744 Train_Acc: 83.693 Val_Loss: 0.5363  BEST VAL Loss: 0.5363  Val_Acc: 77.133

Epoch 82: Validation loss decreased (0.536280 --> 0.535773).  Saving model ...
	 Train_Loss: 0.4731 Train_Acc: 83.555 Val_Loss: 0.5358  BEST VAL Loss: 0.5358  Val_Acc: 77.090

Epoch 83: Validation loss decreased (0.535773 --> 0.535367).  Saving model ...
	 Train_Loss: 0.4717 Train_Acc: 83.901 Val_Loss: 0.5354  BEST VAL Loss: 0.5354  Val_Acc: 76.493

Epoch 84: Validation loss decreased (0.535367 --> 0.534869).  Saving model ...
	 Train_Loss: 0.4704 Train_Acc: 83.811 Val_Loss: 0.5349  BEST VAL Loss: 0.5349  Val_Acc: 76.749

Epoch 85: Validation loss decreased (0.534869 --> 0.534421).  Saving model ...
	 Train_Loss: 0.4691 Train_Acc: 84.088 Val_Loss: 0.5344  BEST VAL Loss: 0.5344  Val_Acc: 76.834

Epoch 86: Validation loss decreased (0.534421 --> 0.533988).  Saving model ...
	 Train_Loss: 0.4678 Train_Acc: 83.848 Val_Loss: 0.5340  BEST VAL Loss: 0.5340  Val_Acc: 76.920

Epoch 87: Validation loss decreased (0.533988 --> 0.533657).  Saving model ...
	 Train_Loss: 0.4665 Train_Acc: 84.398 Val_Loss: 0.5337  BEST VAL Loss: 0.5337  Val_Acc: 76.792

Epoch 88: Validation loss decreased (0.533657 --> 0.533295).  Saving model ...
	 Train_Loss: 0.4653 Train_Acc: 84.195 Val_Loss: 0.5333  BEST VAL Loss: 0.5333  Val_Acc: 76.664

Epoch 89: Validation loss decreased (0.533295 --> 0.532966).  Saving model ...
	 Train_Loss: 0.4640 Train_Acc: 84.211 Val_Loss: 0.5330  BEST VAL Loss: 0.5330  Val_Acc: 76.365

Epoch 90: Validation loss decreased (0.532966 --> 0.532577).  Saving model ...
	 Train_Loss: 0.4628 Train_Acc: 84.253 Val_Loss: 0.5326  BEST VAL Loss: 0.5326  Val_Acc: 76.920

Epoch 91: Validation loss decreased (0.532577 --> 0.532204).  Saving model ...
	 Train_Loss: 0.4616 Train_Acc: 84.536 Val_Loss: 0.5322  BEST VAL Loss: 0.5322  Val_Acc: 77.133

Epoch 92: Validation loss decreased (0.532204 --> 0.531866).  Saving model ...
	 Train_Loss: 0.4604 Train_Acc: 84.414 Val_Loss: 0.5319  BEST VAL Loss: 0.5319  Val_Acc: 76.536

Epoch 93: Validation loss decreased (0.531866 --> 0.531527).  Saving model ...
	 Train_Loss: 0.4593 Train_Acc: 84.531 Val_Loss: 0.5315  BEST VAL Loss: 0.5315  Val_Acc: 77.176

Epoch 94: Validation loss decreased (0.531527 --> 0.531226).  Saving model ...
	 Train_Loss: 0.4581 Train_Acc: 84.888 Val_Loss: 0.5312  BEST VAL Loss: 0.5312  Val_Acc: 76.834

Epoch 95: Validation loss decreased (0.531226 --> 0.531033).  Saving model ...
	 Train_Loss: 0.4569 Train_Acc: 84.355 Val_Loss: 0.5310  BEST VAL Loss: 0.5310  Val_Acc: 76.621

Epoch 96: Validation loss decreased (0.531033 --> 0.530757).  Saving model ...
	 Train_Loss: 0.4558 Train_Acc: 84.739 Val_Loss: 0.5308  BEST VAL Loss: 0.5308  Val_Acc: 76.493

Epoch 97: Validation loss decreased (0.530757 --> 0.530468).  Saving model ...
	 Train_Loss: 0.4546 Train_Acc: 85.171 Val_Loss: 0.5305  BEST VAL Loss: 0.5305  Val_Acc: 77.048

Epoch 98: Validation loss decreased (0.530468 --> 0.530213).  Saving model ...
	 Train_Loss: 0.4535 Train_Acc: 84.792 Val_Loss: 0.5302  BEST VAL Loss: 0.5302  Val_Acc: 76.792

Epoch 99: Validation loss decreased (0.530213 --> 0.530012).  Saving model ...
	 Train_Loss: 0.4523 Train_Acc: 85.080 Val_Loss: 0.5300  BEST VAL Loss: 0.5300  Val_Acc: 76.493

LPS_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.91      0.85      0.88      8634
           1       0.88      0.93      0.90     10113

    accuracy                           0.89     18747
   macro avg       0.89      0.89      0.89     18747
weighted avg       0.89      0.89      0.89     18747

LPS_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.76      0.71      0.73      1080
           1       0.77      0.81      0.79      1264

    accuracy                           0.76      2344
   macro avg       0.76      0.76      0.76      2344
weighted avg       0.76      0.76      0.76      2344

LPS_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.78      0.73      0.75      1079
           1       0.78      0.82      0.80      1265

    accuracy                           0.78      2344
   macro avg       0.78      0.78      0.78      2344
weighted avg       0.78      0.78      0.78      2344

              precision    recall  f1-score   support

           0       0.78      0.73      0.75      1079
           1       0.78      0.82      0.80      1265

    accuracy                           0.78      2344
   macro avg       0.78      0.78      0.78      2344
weighted avg       0.78      0.78      0.78      2344

LPS_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.61      0.41      0.49      4135
           1       0.56      0.74      0.64      4168

    accuracy                           0.58      8303
   macro avg       0.59      0.58      0.57      8303
weighted avg       0.59      0.58      0.57      8303

              precision    recall  f1-score   support

           0       0.61      0.41      0.49      4135
           1       0.56      0.74      0.64      4168

    accuracy                           0.58      8303
   macro avg       0.59      0.58      0.57      8303
weighted avg       0.59      0.58      0.57      8303

completed
