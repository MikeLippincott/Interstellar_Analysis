[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '7c36ec86'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'ecc1aa21'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'c2ff4f5f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'cffe7a53'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Flagellin_1.000_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Flagellin_1.000_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['Flagellin_0.100_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (200462, 1270)
Number of total missing values across all columns: 437540
Data Subset Is Off
Wells held out for testing: ['L10' 'M10']
Wells to use for training, validation, and testing ['L05' 'M05' 'L11' 'M11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.679234).  Saving model ...
	 Train_Loss: 0.6990 Train_Acc: 53.240 Val_Loss: 0.6792  BEST VAL Loss: 0.6792  Val_Acc: 60.598

Epoch 1: Validation loss decreased (0.679234 --> 0.669162).  Saving model ...
	 Train_Loss: 0.6834 Train_Acc: 59.023 Val_Loss: 0.6692  BEST VAL Loss: 0.6692  Val_Acc: 64.457

Epoch 2: Validation loss decreased (0.669162 --> 0.657619).  Saving model ...
	 Train_Loss: 0.6703 Train_Acc: 63.251 Val_Loss: 0.6576  BEST VAL Loss: 0.6576  Val_Acc: 67.040

Epoch 3: Validation loss decreased (0.657619 --> 0.646023).  Saving model ...
	 Train_Loss: 0.6592 Train_Acc: 65.404 Val_Loss: 0.6460  BEST VAL Loss: 0.6460  Val_Acc: 69.795

Epoch 4: Validation loss decreased (0.646023 --> 0.638090).  Saving model ...
	 Train_Loss: 0.6502 Train_Acc: 66.823 Val_Loss: 0.6381  BEST VAL Loss: 0.6381  Val_Acc: 69.878

Epoch 5: Validation loss decreased (0.638090 --> 0.630956).  Saving model ...
	 Train_Loss: 0.6420 Train_Acc: 68.321 Val_Loss: 0.6310  BEST VAL Loss: 0.6310  Val_Acc: 70.621

Epoch 6: Validation loss decreased (0.630956 --> 0.626973).  Saving model ...
	 Train_Loss: 0.6351 Train_Acc: 69.097 Val_Loss: 0.6270  BEST VAL Loss: 0.6270  Val_Acc: 68.706

Epoch 7: Validation loss decreased (0.626973 --> 0.619517).  Saving model ...
	 Train_Loss: 0.6294 Train_Acc: 69.342 Val_Loss: 0.6195  BEST VAL Loss: 0.6195  Val_Acc: 73.106

Epoch 8: Validation loss decreased (0.619517 --> 0.615306).  Saving model ...
	 Train_Loss: 0.6241 Train_Acc: 70.268 Val_Loss: 0.6153  BEST VAL Loss: 0.6153  Val_Acc: 70.966

Epoch 9: Validation loss decreased (0.615306 --> 0.610758).  Saving model ...
	 Train_Loss: 0.6193 Train_Acc: 70.783 Val_Loss: 0.6108  BEST VAL Loss: 0.6108  Val_Acc: 71.890

Epoch 10: Validation loss decreased (0.610758 --> 0.608930).  Saving model ...
	 Train_Loss: 0.6152 Train_Acc: 71.026 Val_Loss: 0.6089  BEST VAL Loss: 0.6089  Val_Acc: 69.044

Epoch 11: Validation loss decreased (0.608930 --> 0.604376).  Saving model ...
	 Train_Loss: 0.6114 Train_Acc: 71.367 Val_Loss: 0.6044  BEST VAL Loss: 0.6044  Val_Acc: 72.903

Epoch 12: Validation loss decreased (0.604376 --> 0.600966).  Saving model ...
	 Train_Loss: 0.6080 Train_Acc: 71.588 Val_Loss: 0.6010  BEST VAL Loss: 0.6010  Val_Acc: 72.498

Epoch 13: Validation loss decreased (0.600966 --> 0.596972).  Saving model ...
	 Train_Loss: 0.6047 Train_Acc: 72.039 Val_Loss: 0.5970  BEST VAL Loss: 0.5970  Val_Acc: 74.082

Epoch 14: Validation loss decreased (0.596972 --> 0.593240).  Saving model ...
	 Train_Loss: 0.6016 Train_Acc: 72.274 Val_Loss: 0.5932  BEST VAL Loss: 0.5932  Val_Acc: 74.578

Epoch 15: Validation loss decreased (0.593240 --> 0.588960).  Saving model ...
	 Train_Loss: 0.5987 Train_Acc: 72.483 Val_Loss: 0.5890  BEST VAL Loss: 0.5890  Val_Acc: 75.756

Epoch 16: Validation loss decreased (0.588960 --> 0.586194).  Saving model ...
	 Train_Loss: 0.5960 Train_Acc: 72.727 Val_Loss: 0.5862  BEST VAL Loss: 0.5862  Val_Acc: 74.690

Epoch 17: Validation loss decreased (0.586194 --> 0.583244).  Saving model ...
	 Train_Loss: 0.5936 Train_Acc: 72.906 Val_Loss: 0.5832  BEST VAL Loss: 0.5832  Val_Acc: 74.780

Epoch 18: Validation loss decreased (0.583244 --> 0.580273).  Saving model ...
	 Train_Loss: 0.5912 Train_Acc: 73.209 Val_Loss: 0.5803  BEST VAL Loss: 0.5803  Val_Acc: 75.171

Epoch 19: Validation loss decreased (0.580273 --> 0.578268).  Saving model ...
	 Train_Loss: 0.5890 Train_Acc: 73.162 Val_Loss: 0.5783  BEST VAL Loss: 0.5783  Val_Acc: 74.555

Epoch 20: Validation loss decreased (0.578268 --> 0.576119).  Saving model ...
	 Train_Loss: 0.5870 Train_Acc: 73.376 Val_Loss: 0.5761  BEST VAL Loss: 0.5761  Val_Acc: 74.938

Epoch 21: Validation loss decreased (0.576119 --> 0.573553).  Saving model ...
	 Train_Loss: 0.5849 Train_Acc: 73.639 Val_Loss: 0.5736  BEST VAL Loss: 0.5736  Val_Acc: 76.252

Epoch 22: Validation loss decreased (0.573553 --> 0.570945).  Saving model ...
	 Train_Loss: 0.5830 Train_Acc: 73.750 Val_Loss: 0.5709  BEST VAL Loss: 0.5709  Val_Acc: 76.620

Epoch 23: Validation loss decreased (0.570945 --> 0.569482).  Saving model ...
	 Train_Loss: 0.5813 Train_Acc: 73.788 Val_Loss: 0.5695  BEST VAL Loss: 0.5695  Val_Acc: 74.473

Epoch 24: Validation loss decreased (0.569482 --> 0.567312).  Saving model ...
	 Train_Loss: 0.5795 Train_Acc: 74.027 Val_Loss: 0.5673  BEST VAL Loss: 0.5673  Val_Acc: 76.034

Epoch 25: Validation loss decreased (0.567312 --> 0.566843).  Saving model ...
	 Train_Loss: 0.5779 Train_Acc: 74.110 Val_Loss: 0.5668  BEST VAL Loss: 0.5668  Val_Acc: 72.798

Epoch 26: Validation loss decreased (0.566843 --> 0.564984).  Saving model ...
	 Train_Loss: 0.5764 Train_Acc: 74.108 Val_Loss: 0.5650  BEST VAL Loss: 0.5650  Val_Acc: 76.605

Epoch 27: Validation loss decreased (0.564984 --> 0.563124).  Saving model ...
	 Train_Loss: 0.5748 Train_Acc: 74.358 Val_Loss: 0.5631  BEST VAL Loss: 0.5631  Val_Acc: 76.154

Epoch 28: Validation loss decreased (0.563124 --> 0.562570).  Saving model ...
	 Train_Loss: 0.5733 Train_Acc: 74.469 Val_Loss: 0.5626  BEST VAL Loss: 0.5626  Val_Acc: 73.376

Epoch 29: Validation loss decreased (0.562570 --> 0.560695).  Saving model ...
	 Train_Loss: 0.5719 Train_Acc: 74.604 Val_Loss: 0.5607  BEST VAL Loss: 0.5607  Val_Acc: 76.785

Epoch 30: Validation loss decreased (0.560695 --> 0.559071).  Saving model ...
	 Train_Loss: 0.5705 Train_Acc: 74.663 Val_Loss: 0.5591  BEST VAL Loss: 0.5591  Val_Acc: 76.440

Epoch 31: Validation loss decreased (0.559071 --> 0.558052).  Saving model ...
	 Train_Loss: 0.5691 Train_Acc: 74.755 Val_Loss: 0.5581  BEST VAL Loss: 0.5581  Val_Acc: 75.193

Epoch 32: Validation loss decreased (0.558052 --> 0.556978).  Saving model ...
	 Train_Loss: 0.5679 Train_Acc: 74.781 Val_Loss: 0.5570  BEST VAL Loss: 0.5570  Val_Acc: 75.178

Epoch 33: Validation loss decreased (0.556978 --> 0.555831).  Saving model ...
	 Train_Loss: 0.5666 Train_Acc: 75.067 Val_Loss: 0.5558  BEST VAL Loss: 0.5558  Val_Acc: 75.809

Epoch 34: Validation loss decreased (0.555831 --> 0.554427).  Saving model ...
	 Train_Loss: 0.5655 Train_Acc: 74.977 Val_Loss: 0.5544  BEST VAL Loss: 0.5544  Val_Acc: 76.770

Epoch 35: Validation loss decreased (0.554427 --> 0.553230).  Saving model ...
	 Train_Loss: 0.5643 Train_Acc: 74.946 Val_Loss: 0.5532  BEST VAL Loss: 0.5532  Val_Acc: 76.290

Epoch 36: Validation loss decreased (0.553230 --> 0.552001).  Saving model ...
	 Train_Loss: 0.5632 Train_Acc: 75.102 Val_Loss: 0.5520  BEST VAL Loss: 0.5520  Val_Acc: 76.312

Epoch 37: Validation loss decreased (0.552001 --> 0.550766).  Saving model ...
	 Train_Loss: 0.5621 Train_Acc: 75.196 Val_Loss: 0.5508  BEST VAL Loss: 0.5508  Val_Acc: 76.770

Epoch 38: Validation loss decreased (0.550766 --> 0.549766).  Saving model ...
	 Train_Loss: 0.5610 Train_Acc: 75.448 Val_Loss: 0.5498  BEST VAL Loss: 0.5498  Val_Acc: 76.305

Epoch 39: Validation loss decreased (0.549766 --> 0.548757).  Saving model ...
	 Train_Loss: 0.5600 Train_Acc: 75.345 Val_Loss: 0.5488  BEST VAL Loss: 0.5488  Val_Acc: 76.515

Epoch 40: Validation loss decreased (0.548757 --> 0.547764).  Saving model ...
	 Train_Loss: 0.5590 Train_Acc: 75.527 Val_Loss: 0.5478  BEST VAL Loss: 0.5478  Val_Acc: 76.672

Epoch 41: Validation loss decreased (0.547764 --> 0.546743).  Saving model ...
	 Train_Loss: 0.5580 Train_Acc: 75.433 Val_Loss: 0.5467  BEST VAL Loss: 0.5467  Val_Acc: 77.010

Epoch 42: Validation loss decreased (0.546743 --> 0.546075).  Saving model ...
	 Train_Loss: 0.5570 Train_Acc: 75.542 Val_Loss: 0.5461  BEST VAL Loss: 0.5461  Val_Acc: 75.974

Epoch 43: Validation loss decreased (0.546075 --> 0.545193).  Saving model ...
	 Train_Loss: 0.5561 Train_Acc: 75.538 Val_Loss: 0.5452  BEST VAL Loss: 0.5452  Val_Acc: 76.725

Epoch 44: Validation loss decreased (0.545193 --> 0.544352).  Saving model ...
	 Train_Loss: 0.5552 Train_Acc: 75.657 Val_Loss: 0.5444  BEST VAL Loss: 0.5444  Val_Acc: 76.455

Epoch 45: Validation loss decreased (0.544352 --> 0.543920).  Saving model ...
	 Train_Loss: 0.5544 Train_Acc: 75.700 Val_Loss: 0.5439  BEST VAL Loss: 0.5439  Val_Acc: 75.246

Epoch 46: Validation loss decreased (0.543920 --> 0.543737).  Saving model ...
	 Train_Loss: 0.5535 Train_Acc: 75.890 Val_Loss: 0.5437  BEST VAL Loss: 0.5437  Val_Acc: 74.090

Epoch 47: Validation loss decreased (0.543737 --> 0.543380).  Saving model ...
	 Train_Loss: 0.5526 Train_Acc: 75.857 Val_Loss: 0.5434  BEST VAL Loss: 0.5434  Val_Acc: 75.066

Epoch 48: Validation loss decreased (0.543380 --> 0.542343).  Saving model ...
	 Train_Loss: 0.5518 Train_Acc: 75.839 Val_Loss: 0.5423  BEST VAL Loss: 0.5423  Val_Acc: 77.160

Epoch 49: Validation loss decreased (0.542343 --> 0.541697).  Saving model ...
	 Train_Loss: 0.5510 Train_Acc: 76.061 Val_Loss: 0.5417  BEST VAL Loss: 0.5417  Val_Acc: 76.267

Epoch 50: Validation loss decreased (0.541697 --> 0.540955).  Saving model ...
	 Train_Loss: 0.5502 Train_Acc: 75.929 Val_Loss: 0.5410  BEST VAL Loss: 0.5410  Val_Acc: 76.845

Epoch 51: Validation loss decreased (0.540955 --> 0.540254).  Saving model ...
	 Train_Loss: 0.5494 Train_Acc: 76.252 Val_Loss: 0.5403  BEST VAL Loss: 0.5403  Val_Acc: 76.717

Epoch 52: Validation loss decreased (0.540254 --> 0.539067).  Saving model ...
	 Train_Loss: 0.5487 Train_Acc: 76.082 Val_Loss: 0.5391  BEST VAL Loss: 0.5391  Val_Acc: 78.189

Epoch 53: Validation loss decreased (0.539067 --> 0.538161).  Saving model ...
	 Train_Loss: 0.5479 Train_Acc: 76.278 Val_Loss: 0.5382  BEST VAL Loss: 0.5382  Val_Acc: 77.461

Epoch 54: Validation loss decreased (0.538161 --> 0.537156).  Saving model ...
	 Train_Loss: 0.5471 Train_Acc: 76.240 Val_Loss: 0.5372  BEST VAL Loss: 0.5372  Val_Acc: 78.219

Epoch 55: Validation loss decreased (0.537156 --> 0.536217).  Saving model ...
	 Train_Loss: 0.5465 Train_Acc: 76.322 Val_Loss: 0.5362  BEST VAL Loss: 0.5362  Val_Acc: 78.152

Epoch 56: Validation loss decreased (0.536217 --> 0.535761).  Saving model ...
	 Train_Loss: 0.5458 Train_Acc: 76.151 Val_Loss: 0.5358  BEST VAL Loss: 0.5358  Val_Acc: 76.042

Epoch 57: Validation loss decreased (0.535761 --> 0.535353).  Saving model ...
	 Train_Loss: 0.5451 Train_Acc: 76.361 Val_Loss: 0.5354  BEST VAL Loss: 0.5354  Val_Acc: 75.516

Epoch 58: Validation loss decreased (0.535353 --> 0.534758).  Saving model ...
	 Train_Loss: 0.5444 Train_Acc: 76.397 Val_Loss: 0.5348  BEST VAL Loss: 0.5348  Val_Acc: 76.905

Epoch 59: Validation loss decreased (0.534758 --> 0.534227).  Saving model ...
	 Train_Loss: 0.5438 Train_Acc: 76.440 Val_Loss: 0.5342  BEST VAL Loss: 0.5342  Val_Acc: 76.470

Epoch 60: Validation loss decreased (0.534227 --> 0.533491).  Saving model ...
	 Train_Loss: 0.5431 Train_Acc: 76.598 Val_Loss: 0.5335  BEST VAL Loss: 0.5335  Val_Acc: 77.483

Epoch 61: Validation loss decreased (0.533491 --> 0.532918).  Saving model ...
	 Train_Loss: 0.5424 Train_Acc: 76.492 Val_Loss: 0.5329  BEST VAL Loss: 0.5329  Val_Acc: 77.160

Epoch 62: Validation loss decreased (0.532918 --> 0.532196).  Saving model ...
	 Train_Loss: 0.5418 Train_Acc: 76.691 Val_Loss: 0.5322  BEST VAL Loss: 0.5322  Val_Acc: 77.483

Epoch 63: Validation loss decreased (0.532196 --> 0.531268).  Saving model ...
	 Train_Loss: 0.5412 Train_Acc: 76.571 Val_Loss: 0.5313  BEST VAL Loss: 0.5313  Val_Acc: 78.910

Epoch 64: Validation loss decreased (0.531268 --> 0.530371).  Saving model ...
	 Train_Loss: 0.5406 Train_Acc: 76.709 Val_Loss: 0.5304  BEST VAL Loss: 0.5304  Val_Acc: 78.985

Epoch 65: Validation loss decreased (0.530371 --> 0.529945).  Saving model ...
	 Train_Loss: 0.5400 Train_Acc: 76.622 Val_Loss: 0.5299  BEST VAL Loss: 0.5299  Val_Acc: 76.410

Epoch 66: Validation loss decreased (0.529945 --> 0.529188).  Saving model ...
	 Train_Loss: 0.5394 Train_Acc: 76.704 Val_Loss: 0.5292  BEST VAL Loss: 0.5292  Val_Acc: 78.054

Epoch 67: Validation loss decreased (0.529188 --> 0.528880).  Saving model ...
	 Train_Loss: 0.5389 Train_Acc: 76.751 Val_Loss: 0.5289  BEST VAL Loss: 0.5289  Val_Acc: 76.124

Epoch 68: Validation loss decreased (0.528880 --> 0.528288).  Saving model ...
	 Train_Loss: 0.5383 Train_Acc: 76.754 Val_Loss: 0.5283  BEST VAL Loss: 0.5283  Val_Acc: 77.558

Epoch 69: Validation loss decreased (0.528288 --> 0.527558).  Saving model ...
	 Train_Loss: 0.5377 Train_Acc: 76.716 Val_Loss: 0.5276  BEST VAL Loss: 0.5276  Val_Acc: 78.775

Epoch 70: Validation loss decreased (0.527558 --> 0.526927).  Saving model ...
	 Train_Loss: 0.5372 Train_Acc: 76.897 Val_Loss: 0.5269  BEST VAL Loss: 0.5269  Val_Acc: 78.099

Epoch 71: Validation loss decreased (0.526927 --> 0.526732).  Saving model ...
	 Train_Loss: 0.5366 Train_Acc: 76.886 Val_Loss: 0.5267  BEST VAL Loss: 0.5267  Val_Acc: 75.531

Epoch 72: Validation loss decreased (0.526732 --> 0.526338).  Saving model ...
	 Train_Loss: 0.5361 Train_Acc: 77.225 Val_Loss: 0.5263  BEST VAL Loss: 0.5263  Val_Acc: 76.860

Epoch 73: Validation loss decreased (0.526338 --> 0.525762).  Saving model ...
	 Train_Loss: 0.5356 Train_Acc: 77.070 Val_Loss: 0.5258  BEST VAL Loss: 0.5258  Val_Acc: 78.114

Epoch 74: Validation loss decreased (0.525762 --> 0.525131).  Saving model ...
	 Train_Loss: 0.5351 Train_Acc: 76.757 Val_Loss: 0.5251  BEST VAL Loss: 0.5251  Val_Acc: 78.422

Epoch 75: Validation loss decreased (0.525131 --> 0.524445).  Saving model ...
	 Train_Loss: 0.5346 Train_Acc: 77.176 Val_Loss: 0.5244  BEST VAL Loss: 0.5244  Val_Acc: 78.610

Epoch 76: Validation loss decreased (0.524445 --> 0.523982).  Saving model ...
	 Train_Loss: 0.5341 Train_Acc: 76.991 Val_Loss: 0.5240  BEST VAL Loss: 0.5240  Val_Acc: 77.483

Epoch 77: Validation loss decreased (0.523982 --> 0.523636).  Saving model ...
	 Train_Loss: 0.5336 Train_Acc: 77.119 Val_Loss: 0.5236  BEST VAL Loss: 0.5236  Val_Acc: 76.853

Epoch 78: Validation loss decreased (0.523636 --> 0.523185).  Saving model ...
	 Train_Loss: 0.5331 Train_Acc: 77.072 Val_Loss: 0.5232  BEST VAL Loss: 0.5232  Val_Acc: 77.175

Epoch 79: Validation loss decreased (0.523185 --> 0.522833).  Saving model ...
	 Train_Loss: 0.5326 Train_Acc: 77.177 Val_Loss: 0.5228  BEST VAL Loss: 0.5228  Val_Acc: 77.221

Epoch 80: Validation loss decreased (0.522833 --> 0.522462).  Saving model ...
	 Train_Loss: 0.5321 Train_Acc: 77.128 Val_Loss: 0.5225  BEST VAL Loss: 0.5225  Val_Acc: 76.702

Epoch 81: Validation loss decreased (0.522462 --> 0.522010).  Saving model ...
	 Train_Loss: 0.5317 Train_Acc: 77.295 Val_Loss: 0.5220  BEST VAL Loss: 0.5220  Val_Acc: 77.769

Epoch 82: Validation loss decreased (0.522010 --> 0.521733).  Saving model ...
	 Train_Loss: 0.5312 Train_Acc: 77.276 Val_Loss: 0.5217  BEST VAL Loss: 0.5217  Val_Acc: 76.763

Epoch 83: Validation loss decreased (0.521733 --> 0.521530).  Saving model ...
	 Train_Loss: 0.5308 Train_Acc: 77.228 Val_Loss: 0.5215  BEST VAL Loss: 0.5215  Val_Acc: 76.094

Epoch 84: Validation loss decreased (0.521530 --> 0.521131).  Saving model ...
	 Train_Loss: 0.5303 Train_Acc: 77.394 Val_Loss: 0.5211  BEST VAL Loss: 0.5211  Val_Acc: 77.498

Epoch 85: Validation loss decreased (0.521131 --> 0.520739).  Saving model ...
	 Train_Loss: 0.5299 Train_Acc: 77.257 Val_Loss: 0.5207  BEST VAL Loss: 0.5207  Val_Acc: 77.603

Epoch 86: Validation loss decreased (0.520739 --> 0.520263).  Saving model ...
	 Train_Loss: 0.5295 Train_Acc: 77.214 Val_Loss: 0.5203  BEST VAL Loss: 0.5203  Val_Acc: 78.076

Epoch 87: Validation loss decreased (0.520263 --> 0.519672).  Saving model ...
	 Train_Loss: 0.5291 Train_Acc: 77.327 Val_Loss: 0.5197  BEST VAL Loss: 0.5197  Val_Acc: 78.790

Epoch 88: Validation loss decreased (0.519672 --> 0.519174).  Saving model ...
	 Train_Loss: 0.5287 Train_Acc: 77.228 Val_Loss: 0.5192  BEST VAL Loss: 0.5192  Val_Acc: 78.294

Epoch 89: Validation loss decreased (0.519174 --> 0.518625).  Saving model ...
	 Train_Loss: 0.5282 Train_Acc: 77.315 Val_Loss: 0.5186  BEST VAL Loss: 0.5186  Val_Acc: 78.625

Epoch 90: Validation loss decreased (0.518625 --> 0.518355).  Saving model ...
	 Train_Loss: 0.5278 Train_Acc: 77.586 Val_Loss: 0.5184  BEST VAL Loss: 0.5184  Val_Acc: 77.048

Epoch 91: Validation loss decreased (0.518355 --> 0.517859).  Saving model ...
	 Train_Loss: 0.5275 Train_Acc: 77.293 Val_Loss: 0.5179  BEST VAL Loss: 0.5179  Val_Acc: 78.579

Epoch 92: Validation loss decreased (0.517859 --> 0.517696).  Saving model ...
	 Train_Loss: 0.5271 Train_Acc: 77.373 Val_Loss: 0.5177  BEST VAL Loss: 0.5177  Val_Acc: 76.425

Epoch 93: Validation loss decreased (0.517696 --> 0.517220).  Saving model ...
	 Train_Loss: 0.5267 Train_Acc: 77.498 Val_Loss: 0.5172  BEST VAL Loss: 0.5172  Val_Acc: 78.377

Epoch 94: Validation loss decreased (0.517220 --> 0.516747).  Saving model ...
	 Train_Loss: 0.5263 Train_Acc: 77.535 Val_Loss: 0.5167  BEST VAL Loss: 0.5167  Val_Acc: 78.662

Epoch 95: Validation loss decreased (0.516747 --> 0.516374).  Saving model ...
	 Train_Loss: 0.5259 Train_Acc: 77.694 Val_Loss: 0.5164  BEST VAL Loss: 0.5164  Val_Acc: 77.679

Epoch 96: Validation loss decreased (0.516374 --> 0.515813).  Saving model ...
	 Train_Loss: 0.5255 Train_Acc: 77.606 Val_Loss: 0.5158  BEST VAL Loss: 0.5158  Val_Acc: 79.383

Epoch 97: Validation loss decreased (0.515813 --> 0.515400).  Saving model ...
	 Train_Loss: 0.5251 Train_Acc: 77.558 Val_Loss: 0.5154  BEST VAL Loss: 0.5154  Val_Acc: 78.459

Epoch 98: Validation loss decreased (0.515400 --> 0.515128).  Saving model ...
	 Train_Loss: 0.5247 Train_Acc: 77.650 Val_Loss: 0.5151  BEST VAL Loss: 0.5151  Val_Acc: 77.198

Epoch 99: Validation loss decreased (0.515128 --> 0.514730).  Saving model ...
	 Train_Loss: 0.5244 Train_Acc: 77.337 Val_Loss: 0.5147  BEST VAL Loss: 0.5147  Val_Acc: 78.121

Flagellin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.76      0.92      0.83     50422
           1       0.91      0.73      0.81     56121

    accuracy                           0.82    106543
   macro avg       0.83      0.82      0.82    106543
weighted avg       0.84      0.82      0.82    106543

Flagellin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.72      0.88      0.79      6303
           1       0.86      0.69      0.77      7016

    accuracy                           0.78     13319
   macro avg       0.79      0.79      0.78     13319
weighted avg       0.80      0.78      0.78     13319

Flagellin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.73      0.88      0.80      6303
           1       0.87      0.71      0.78      7016

    accuracy                           0.79     13319
   macro avg       0.80      0.80      0.79     13319
weighted avg       0.80      0.79      0.79     13319

              precision    recall  f1-score   support

           0       0.73      0.88      0.80      6303
           1       0.87      0.71      0.78      7016

    accuracy                           0.79     13319
   macro avg       0.80      0.80      0.79     13319
weighted avg       0.80      0.79      0.79     13319

Flagellin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.57      0.79      0.66     32887
           1       0.68      0.44      0.53     34394

    accuracy                           0.61     67281
   macro avg       0.63      0.61      0.60     67281
weighted avg       0.63      0.61      0.60     67281

              precision    recall  f1-score   support

           0       0.57      0.79      0.66     32887
           1       0.68      0.44      0.53     34394

    accuracy                           0.61     67281
   macro avg       0.63      0.61      0.60     67281
weighted avg       0.63      0.61      0.60     67281

completed
