[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ceeb7c40'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'da712b1c'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'a3e45525'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '0337a78a'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Flagellin_1.000_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Flagellin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (243144, 1270)
Number of total missing values across all columns: 522904
Data Subset Is Off
Wells held out for testing: ['C09' 'M10']
Wells to use for training, validation, and testing ['C02' 'C03' 'C08' 'M05' 'M11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.592754).  Saving model ...
	 Train_Loss: 0.6433 Train_Acc: 62.712 Val_Loss: 0.5928  BEST VAL Loss: 0.5928  Val_Acc: 68.557

Epoch 1: Validation loss decreased (0.592754 --> 0.580674).  Saving model ...
	 Train_Loss: 0.6201 Train_Acc: 68.144 Val_Loss: 0.5807  BEST VAL Loss: 0.5807  Val_Acc: 71.271

Epoch 2: Validation loss decreased (0.580674 --> 0.570200).  Saving model ...
	 Train_Loss: 0.6064 Train_Acc: 69.731 Val_Loss: 0.5702  BEST VAL Loss: 0.5702  Val_Acc: 72.285

Epoch 3: Validation loss decreased (0.570200 --> 0.563199).  Saving model ...
	 Train_Loss: 0.5965 Train_Acc: 70.666 Val_Loss: 0.5632  BEST VAL Loss: 0.5632  Val_Acc: 72.866

Epoch 4: Validation loss decreased (0.563199 --> 0.557080).  Saving model ...
	 Train_Loss: 0.5891 Train_Acc: 71.170 Val_Loss: 0.5571  BEST VAL Loss: 0.5571  Val_Acc: 73.499

Epoch 5: Validation loss decreased (0.557080 --> 0.551647).  Saving model ...
	 Train_Loss: 0.5829 Train_Acc: 71.587 Val_Loss: 0.5516  BEST VAL Loss: 0.5516  Val_Acc: 74.167

Epoch 6: Validation loss decreased (0.551647 --> 0.548115).  Saving model ...
	 Train_Loss: 0.5776 Train_Acc: 72.069 Val_Loss: 0.5481  BEST VAL Loss: 0.5481  Val_Acc: 73.816

Epoch 7: Validation loss decreased (0.548115 --> 0.544156).  Saving model ...
	 Train_Loss: 0.5731 Train_Acc: 72.412 Val_Loss: 0.5442  BEST VAL Loss: 0.5442  Val_Acc: 74.490

Epoch 8: Validation loss decreased (0.544156 --> 0.540955).  Saving model ...
	 Train_Loss: 0.5690 Train_Acc: 72.662 Val_Loss: 0.5410  BEST VAL Loss: 0.5410  Val_Acc: 74.595

Epoch 9: Validation loss decreased (0.540955 --> 0.537666).  Saving model ...
	 Train_Loss: 0.5653 Train_Acc: 72.781 Val_Loss: 0.5377  BEST VAL Loss: 0.5377  Val_Acc: 74.678

Epoch 10: Validation loss decreased (0.537666 --> 0.535550).  Saving model ...
	 Train_Loss: 0.5622 Train_Acc: 72.962 Val_Loss: 0.5356  BEST VAL Loss: 0.5356  Val_Acc: 74.508

Epoch 11: Validation loss decreased (0.535550 --> 0.533471).  Saving model ...
	 Train_Loss: 0.5593 Train_Acc: 73.209 Val_Loss: 0.5335  BEST VAL Loss: 0.5335  Val_Acc: 74.842

Epoch 12: Validation loss decreased (0.533471 --> 0.531431).  Saving model ...
	 Train_Loss: 0.5567 Train_Acc: 73.333 Val_Loss: 0.5314  BEST VAL Loss: 0.5314  Val_Acc: 75.229

Epoch 13: Validation loss decreased (0.531431 --> 0.529225).  Saving model ...
	 Train_Loss: 0.5542 Train_Acc: 73.447 Val_Loss: 0.5292  BEST VAL Loss: 0.5292  Val_Acc: 75.311

Epoch 14: Validation loss decreased (0.529225 --> 0.527561).  Saving model ...
	 Train_Loss: 0.5520 Train_Acc: 73.465 Val_Loss: 0.5276  BEST VAL Loss: 0.5276  Val_Acc: 75.504

Epoch 15: Validation loss decreased (0.527561 --> 0.525418).  Saving model ...
	 Train_Loss: 0.5499 Train_Acc: 73.733 Val_Loss: 0.5254  BEST VAL Loss: 0.5254  Val_Acc: 75.674

Epoch 16: Validation loss decreased (0.525418 --> 0.523895).  Saving model ...
	 Train_Loss: 0.5479 Train_Acc: 73.709 Val_Loss: 0.5239  BEST VAL Loss: 0.5239  Val_Acc: 75.545

Epoch 17: Validation loss decreased (0.523895 --> 0.522231).  Saving model ...
	 Train_Loss: 0.5461 Train_Acc: 73.777 Val_Loss: 0.5222  BEST VAL Loss: 0.5222  Val_Acc: 75.756

Epoch 18: Validation loss decreased (0.522231 --> 0.520547).  Saving model ...
	 Train_Loss: 0.5444 Train_Acc: 73.886 Val_Loss: 0.5205  BEST VAL Loss: 0.5205  Val_Acc: 75.709

Epoch 19: Validation loss decreased (0.520547 --> 0.519151).  Saving model ...
	 Train_Loss: 0.5427 Train_Acc: 73.964 Val_Loss: 0.5192  BEST VAL Loss: 0.5192  Val_Acc: 75.827

Epoch 20: Validation loss decreased (0.519151 --> 0.517594).  Saving model ...
	 Train_Loss: 0.5412 Train_Acc: 74.065 Val_Loss: 0.5176  BEST VAL Loss: 0.5176  Val_Acc: 76.360

Epoch 21: Validation loss decreased (0.517594 --> 0.516197).  Saving model ...
	 Train_Loss: 0.5397 Train_Acc: 74.110 Val_Loss: 0.5162  BEST VAL Loss: 0.5162  Val_Acc: 76.096

Epoch 22: Validation loss decreased (0.516197 --> 0.514870).  Saving model ...
	 Train_Loss: 0.5383 Train_Acc: 74.296 Val_Loss: 0.5149  BEST VAL Loss: 0.5149  Val_Acc: 76.173

Epoch 23: Validation loss decreased (0.514870 --> 0.513571).  Saving model ...
	 Train_Loss: 0.5369 Train_Acc: 74.271 Val_Loss: 0.5136  BEST VAL Loss: 0.5136  Val_Acc: 75.967

Epoch 24: Validation loss decreased (0.513571 --> 0.512162).  Saving model ...
	 Train_Loss: 0.5356 Train_Acc: 74.304 Val_Loss: 0.5122  BEST VAL Loss: 0.5122  Val_Acc: 76.431

Epoch 25: Validation loss decreased (0.512162 --> 0.510945).  Saving model ...
	 Train_Loss: 0.5344 Train_Acc: 74.348 Val_Loss: 0.5109  BEST VAL Loss: 0.5109  Val_Acc: 76.565

Epoch 26: Validation loss decreased (0.510945 --> 0.509878).  Saving model ...
	 Train_Loss: 0.5332 Train_Acc: 74.370 Val_Loss: 0.5099  BEST VAL Loss: 0.5099  Val_Acc: 76.266

Epoch 27: Validation loss decreased (0.509878 --> 0.508865).  Saving model ...
	 Train_Loss: 0.5321 Train_Acc: 74.361 Val_Loss: 0.5089  BEST VAL Loss: 0.5089  Val_Acc: 76.524

Epoch 28: Validation loss decreased (0.508865 --> 0.507730).  Saving model ...
	 Train_Loss: 0.5310 Train_Acc: 74.559 Val_Loss: 0.5077  BEST VAL Loss: 0.5077  Val_Acc: 77.011

Epoch 29: Validation loss decreased (0.507730 --> 0.506761).  Saving model ...
	 Train_Loss: 0.5300 Train_Acc: 74.590 Val_Loss: 0.5068  BEST VAL Loss: 0.5068  Val_Acc: 76.788

Epoch 30: Validation loss decreased (0.506761 --> 0.505818).  Saving model ...
	 Train_Loss: 0.5289 Train_Acc: 74.620 Val_Loss: 0.5058  BEST VAL Loss: 0.5058  Val_Acc: 76.319

Epoch 31: Validation loss decreased (0.505818 --> 0.505027).  Saving model ...
	 Train_Loss: 0.5280 Train_Acc: 74.657 Val_Loss: 0.5050  BEST VAL Loss: 0.5050  Val_Acc: 76.331

Epoch 32: Validation loss decreased (0.505027 --> 0.504088).  Saving model ...
	 Train_Loss: 0.5271 Train_Acc: 74.647 Val_Loss: 0.5041  BEST VAL Loss: 0.5041  Val_Acc: 77.070

Epoch 33: Validation loss decreased (0.504088 --> 0.503190).  Saving model ...
	 Train_Loss: 0.5262 Train_Acc: 74.642 Val_Loss: 0.5032  BEST VAL Loss: 0.5032  Val_Acc: 76.601

Epoch 34: Validation loss decreased (0.503190 --> 0.502612).  Saving model ...
	 Train_Loss: 0.5254 Train_Acc: 74.559 Val_Loss: 0.5026  BEST VAL Loss: 0.5026  Val_Acc: 75.920

Epoch 35: Validation loss decreased (0.502612 --> 0.501804).  Saving model ...
	 Train_Loss: 0.5246 Train_Acc: 74.635 Val_Loss: 0.5018  BEST VAL Loss: 0.5018  Val_Acc: 76.964

Epoch 36: Validation loss decreased (0.501804 --> 0.501109).  Saving model ...
	 Train_Loss: 0.5239 Train_Acc: 74.480 Val_Loss: 0.5011  BEST VAL Loss: 0.5011  Val_Acc: 76.782

Epoch 37: Validation loss decreased (0.501109 --> 0.500307).  Saving model ...
	 Train_Loss: 0.5231 Train_Acc: 74.795 Val_Loss: 0.5003  BEST VAL Loss: 0.5003  Val_Acc: 77.029

Epoch 38: Validation loss decreased (0.500307 --> 0.499550).  Saving model ...
	 Train_Loss: 0.5223 Train_Acc: 75.058 Val_Loss: 0.4995  BEST VAL Loss: 0.4995  Val_Acc: 76.964

Epoch 39: Validation loss decreased (0.499550 --> 0.498807).  Saving model ...
	 Train_Loss: 0.5215 Train_Acc: 74.997 Val_Loss: 0.4988  BEST VAL Loss: 0.4988  Val_Acc: 77.023

Epoch 40: Validation loss decreased (0.498807 --> 0.497974).  Saving model ...
	 Train_Loss: 0.5208 Train_Acc: 74.852 Val_Loss: 0.4980  BEST VAL Loss: 0.4980  Val_Acc: 77.105

Epoch 41: Validation loss decreased (0.497974 --> 0.497298).  Saving model ...
	 Train_Loss: 0.5202 Train_Acc: 74.980 Val_Loss: 0.4973  BEST VAL Loss: 0.4973  Val_Acc: 76.530

Epoch 42: Validation loss decreased (0.497298 --> 0.496638).  Saving model ...
	 Train_Loss: 0.5195 Train_Acc: 74.809 Val_Loss: 0.4966  BEST VAL Loss: 0.4966  Val_Acc: 76.958

Epoch 43: Validation loss decreased (0.496638 --> 0.495861).  Saving model ...
	 Train_Loss: 0.5188 Train_Acc: 74.921 Val_Loss: 0.4959  BEST VAL Loss: 0.4959  Val_Acc: 77.216

Epoch 44: Validation loss decreased (0.495861 --> 0.495155).  Saving model ...
	 Train_Loss: 0.5182 Train_Acc: 74.900 Val_Loss: 0.4952  BEST VAL Loss: 0.4952  Val_Acc: 77.081

Epoch 45: Validation loss decreased (0.495155 --> 0.494510).  Saving model ...
	 Train_Loss: 0.5176 Train_Acc: 75.095 Val_Loss: 0.4945  BEST VAL Loss: 0.4945  Val_Acc: 77.034

Epoch 46: Validation loss decreased (0.494510 --> 0.493906).  Saving model ...
	 Train_Loss: 0.5170 Train_Acc: 74.943 Val_Loss: 0.4939  BEST VAL Loss: 0.4939  Val_Acc: 77.122

Epoch 47: Validation loss decreased (0.493906 --> 0.493280).  Saving model ...
	 Train_Loss: 0.5164 Train_Acc: 74.938 Val_Loss: 0.4933  BEST VAL Loss: 0.4933  Val_Acc: 77.287

Epoch 48: Validation loss decreased (0.493280 --> 0.492725).  Saving model ...
	 Train_Loss: 0.5159 Train_Acc: 75.028 Val_Loss: 0.4927  BEST VAL Loss: 0.4927  Val_Acc: 76.941

Epoch 49: Validation loss decreased (0.492725 --> 0.492030).  Saving model ...
	 Train_Loss: 0.5153 Train_Acc: 75.063 Val_Loss: 0.4920  BEST VAL Loss: 0.4920  Val_Acc: 77.550

Epoch 50: Validation loss decreased (0.492030 --> 0.491445).  Saving model ...
	 Train_Loss: 0.5148 Train_Acc: 74.962 Val_Loss: 0.4914  BEST VAL Loss: 0.4914  Val_Acc: 77.099

Epoch 51: Validation loss decreased (0.491445 --> 0.490852).  Saving model ...
	 Train_Loss: 0.5142 Train_Acc: 75.049 Val_Loss: 0.4909  BEST VAL Loss: 0.4909  Val_Acc: 77.234

Epoch 52: Validation loss decreased (0.490852 --> 0.490358).  Saving model ...
	 Train_Loss: 0.5137 Train_Acc: 75.176 Val_Loss: 0.4904  BEST VAL Loss: 0.4904  Val_Acc: 76.923

Epoch 53: Validation loss decreased (0.490358 --> 0.489917).  Saving model ...
	 Train_Loss: 0.5132 Train_Acc: 74.865 Val_Loss: 0.4899  BEST VAL Loss: 0.4899  Val_Acc: 76.823

Epoch 54: Validation loss decreased (0.489917 --> 0.489358).  Saving model ...
	 Train_Loss: 0.5127 Train_Acc: 75.068 Val_Loss: 0.4894  BEST VAL Loss: 0.4894  Val_Acc: 77.416

Epoch 55: Validation loss decreased (0.489358 --> 0.488898).  Saving model ...
	 Train_Loss: 0.5122 Train_Acc: 75.116 Val_Loss: 0.4889  BEST VAL Loss: 0.4889  Val_Acc: 77.011

Epoch 56: Validation loss decreased (0.488898 --> 0.488429).  Saving model ...
	 Train_Loss: 0.5118 Train_Acc: 75.004 Val_Loss: 0.4884  BEST VAL Loss: 0.4884  Val_Acc: 77.234

Epoch 57: Validation loss decreased (0.488429 --> 0.487870).  Saving model ...
	 Train_Loss: 0.5113 Train_Acc: 75.209 Val_Loss: 0.4879  BEST VAL Loss: 0.4879  Val_Acc: 77.662

Epoch 58: Validation loss decreased (0.487870 --> 0.487344).  Saving model ...
	 Train_Loss: 0.5108 Train_Acc: 75.271 Val_Loss: 0.4873  BEST VAL Loss: 0.4873  Val_Acc: 77.205

Epoch 59: Validation loss decreased (0.487344 --> 0.486835).  Saving model ...
	 Train_Loss: 0.5104 Train_Acc: 75.116 Val_Loss: 0.4868  BEST VAL Loss: 0.4868  Val_Acc: 77.205

Epoch 60: Validation loss decreased (0.486835 --> 0.486378).  Saving model ...
	 Train_Loss: 0.5099 Train_Acc: 75.253 Val_Loss: 0.4864  BEST VAL Loss: 0.4864  Val_Acc: 77.339

Epoch 61: Validation loss decreased (0.486378 --> 0.485931).  Saving model ...
	 Train_Loss: 0.5095 Train_Acc: 75.168 Val_Loss: 0.4859  BEST VAL Loss: 0.4859  Val_Acc: 76.923

Epoch 62: Validation loss decreased (0.485931 --> 0.485466).  Saving model ...
	 Train_Loss: 0.5090 Train_Acc: 75.333 Val_Loss: 0.4855  BEST VAL Loss: 0.4855  Val_Acc: 77.111

Epoch 63: Validation loss decreased (0.485466 --> 0.485051).  Saving model ...
	 Train_Loss: 0.5086 Train_Acc: 75.289 Val_Loss: 0.4851  BEST VAL Loss: 0.4851  Val_Acc: 77.492

Epoch 64: Validation loss decreased (0.485051 --> 0.484563).  Saving model ...
	 Train_Loss: 0.5082 Train_Acc: 75.216 Val_Loss: 0.4846  BEST VAL Loss: 0.4846  Val_Acc: 77.445

Epoch 65: Validation loss decreased (0.484563 --> 0.484168).  Saving model ...
	 Train_Loss: 0.5078 Train_Acc: 75.280 Val_Loss: 0.4842  BEST VAL Loss: 0.4842  Val_Acc: 77.246

Epoch 66: Validation loss decreased (0.484168 --> 0.483736).  Saving model ...
	 Train_Loss: 0.5074 Train_Acc: 75.259 Val_Loss: 0.4837  BEST VAL Loss: 0.4837  Val_Acc: 77.158

Epoch 67: Validation loss decreased (0.483736 --> 0.483339).  Saving model ...
	 Train_Loss: 0.5070 Train_Acc: 75.238 Val_Loss: 0.4833  BEST VAL Loss: 0.4833  Val_Acc: 77.169

Epoch 68: Validation loss decreased (0.483339 --> 0.483042).  Saving model ...
	 Train_Loss: 0.5067 Train_Acc: 75.322 Val_Loss: 0.4830  BEST VAL Loss: 0.4830  Val_Acc: 77.128

Epoch 69: Validation loss decreased (0.483042 --> 0.482677).  Saving model ...
	 Train_Loss: 0.5063 Train_Acc: 75.245 Val_Loss: 0.4827  BEST VAL Loss: 0.4827  Val_Acc: 76.970

Epoch 70: Validation loss decreased (0.482677 --> 0.482271).  Saving model ...
	 Train_Loss: 0.5059 Train_Acc: 75.362 Val_Loss: 0.4823  BEST VAL Loss: 0.4823  Val_Acc: 77.328

Epoch 71: Validation loss decreased (0.482271 --> 0.481879).  Saving model ...
	 Train_Loss: 0.5056 Train_Acc: 75.319 Val_Loss: 0.4819  BEST VAL Loss: 0.4819  Val_Acc: 77.263

Epoch 72: Validation loss decreased (0.481879 --> 0.481535).  Saving model ...
	 Train_Loss: 0.5052 Train_Acc: 75.475 Val_Loss: 0.4815  BEST VAL Loss: 0.4815  Val_Acc: 77.281

Epoch 73: Validation loss decreased (0.481535 --> 0.481155).  Saving model ...
	 Train_Loss: 0.5048 Train_Acc: 75.557 Val_Loss: 0.4812  BEST VAL Loss: 0.4812  Val_Acc: 77.486

Epoch 74: Validation loss decreased (0.481155 --> 0.480860).  Saving model ...
	 Train_Loss: 0.5045 Train_Acc: 75.357 Val_Loss: 0.4809  BEST VAL Loss: 0.4809  Val_Acc: 77.234

Epoch 75: Validation loss decreased (0.480860 --> 0.480554).  Saving model ...
	 Train_Loss: 0.5041 Train_Acc: 75.440 Val_Loss: 0.4806  BEST VAL Loss: 0.4806  Val_Acc: 77.175

Epoch 76: Validation loss decreased (0.480554 --> 0.480216).  Saving model ...
	 Train_Loss: 0.5038 Train_Acc: 75.306 Val_Loss: 0.4802  BEST VAL Loss: 0.4802  Val_Acc: 77.175

Epoch 77: Validation loss decreased (0.480216 --> 0.479924).  Saving model ...
	 Train_Loss: 0.5035 Train_Acc: 75.374 Val_Loss: 0.4799  BEST VAL Loss: 0.4799  Val_Acc: 77.187

Epoch 78: Validation loss decreased (0.479924 --> 0.479586).  Saving model ...
	 Train_Loss: 0.5031 Train_Acc: 75.471 Val_Loss: 0.4796  BEST VAL Loss: 0.4796  Val_Acc: 77.316

Epoch 79: Validation loss decreased (0.479586 --> 0.479273).  Saving model ...
	 Train_Loss: 0.5028 Train_Acc: 75.278 Val_Loss: 0.4793  BEST VAL Loss: 0.4793  Val_Acc: 77.316

Epoch 80: Validation loss decreased (0.479273 --> 0.478963).  Saving model ...
	 Train_Loss: 0.5025 Train_Acc: 75.393 Val_Loss: 0.4790  BEST VAL Loss: 0.4790  Val_Acc: 77.468

Epoch 81: Validation loss decreased (0.478963 --> 0.478616).  Saving model ...
	 Train_Loss: 0.5022 Train_Acc: 75.473 Val_Loss: 0.4786  BEST VAL Loss: 0.4786  Val_Acc: 77.685

Epoch 82: Validation loss decreased (0.478616 --> 0.478363).  Saving model ...
	 Train_Loss: 0.5019 Train_Acc: 75.482 Val_Loss: 0.4784  BEST VAL Loss: 0.4784  Val_Acc: 77.122

Epoch 83: Validation loss decreased (0.478363 --> 0.478074).  Saving model ...
	 Train_Loss: 0.5016 Train_Acc: 75.477 Val_Loss: 0.4781  BEST VAL Loss: 0.4781  Val_Acc: 77.445

Epoch 84: Validation loss decreased (0.478074 --> 0.477772).  Saving model ...
	 Train_Loss: 0.5013 Train_Acc: 75.445 Val_Loss: 0.4778  BEST VAL Loss: 0.4778  Val_Acc: 77.451

Epoch 85: Validation loss decreased (0.477772 --> 0.477456).  Saving model ...
	 Train_Loss: 0.5010 Train_Acc: 75.547 Val_Loss: 0.4775  BEST VAL Loss: 0.4775  Val_Acc: 77.779

Epoch 86: Validation loss decreased (0.477456 --> 0.477133).  Saving model ...
	 Train_Loss: 0.5008 Train_Acc: 75.494 Val_Loss: 0.4771  BEST VAL Loss: 0.4771  Val_Acc: 77.591

Epoch 87: Validation loss decreased (0.477133 --> 0.476859).  Saving model ...
	 Train_Loss: 0.5005 Train_Acc: 75.470 Val_Loss: 0.4769  BEST VAL Loss: 0.4769  Val_Acc: 77.474

Epoch 88: Validation loss decreased (0.476859 --> 0.476562).  Saving model ...
	 Train_Loss: 0.5002 Train_Acc: 75.409 Val_Loss: 0.4766  BEST VAL Loss: 0.4766  Val_Acc: 77.539

Epoch 89: Validation loss decreased (0.476562 --> 0.476274).  Saving model ...
	 Train_Loss: 0.5000 Train_Acc: 75.511 Val_Loss: 0.4763  BEST VAL Loss: 0.4763  Val_Acc: 77.627

Epoch 90: Validation loss decreased (0.476274 --> 0.476061).  Saving model ...
	 Train_Loss: 0.4997 Train_Acc: 75.561 Val_Loss: 0.4761  BEST VAL Loss: 0.4761  Val_Acc: 77.222

Epoch 91: Validation loss decreased (0.476061 --> 0.475770).  Saving model ...
	 Train_Loss: 0.4994 Train_Acc: 75.399 Val_Loss: 0.4758  BEST VAL Loss: 0.4758  Val_Acc: 77.615

Epoch 92: Validation loss decreased (0.475770 --> 0.475500).  Saving model ...
	 Train_Loss: 0.4992 Train_Acc: 75.574 Val_Loss: 0.4755  BEST VAL Loss: 0.4755  Val_Acc: 77.844

Epoch 93: Validation loss decreased (0.475500 --> 0.475230).  Saving model ...
	 Train_Loss: 0.4989 Train_Acc: 75.426 Val_Loss: 0.4752  BEST VAL Loss: 0.4752  Val_Acc: 77.685

Epoch 94: Validation loss decreased (0.475230 --> 0.474930).  Saving model ...
	 Train_Loss: 0.4986 Train_Acc: 75.577 Val_Loss: 0.4749  BEST VAL Loss: 0.4749  Val_Acc: 77.656

Epoch 95: Validation loss decreased (0.474930 --> 0.474683).  Saving model ...
	 Train_Loss: 0.4984 Train_Acc: 75.692 Val_Loss: 0.4747  BEST VAL Loss: 0.4747  Val_Acc: 77.240

Epoch 96: Validation loss decreased (0.474683 --> 0.474431).  Saving model ...
	 Train_Loss: 0.4981 Train_Acc: 75.510 Val_Loss: 0.4744  BEST VAL Loss: 0.4744  Val_Acc: 77.416

Epoch 97: Validation loss decreased (0.474431 --> 0.474200).  Saving model ...
	 Train_Loss: 0.4979 Train_Acc: 75.465 Val_Loss: 0.4742  BEST VAL Loss: 0.4742  Val_Acc: 77.457

Epoch 98: Validation loss decreased (0.474200 --> 0.473945).  Saving model ...
	 Train_Loss: 0.4977 Train_Acc: 75.508 Val_Loss: 0.4739  BEST VAL Loss: 0.4739  Val_Acc: 77.363

Epoch 99: Validation loss decreased (0.473945 --> 0.473712).  Saving model ...
	 Train_Loss: 0.4974 Train_Acc: 75.578 Val_Loss: 0.4737  BEST VAL Loss: 0.4737  Val_Acc: 77.586

Flagellin_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.88      0.59      0.71     56123
           1       0.77      0.94      0.85     80324

    accuracy                           0.80    136447
   macro avg       0.82      0.77      0.78    136447
weighted avg       0.81      0.80      0.79    136447

Flagellin_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.84      0.56      0.67      7015
           1       0.75      0.93      0.83     10041

    accuracy                           0.78     17056
   macro avg       0.80      0.74      0.75     17056
weighted avg       0.79      0.78      0.76     17056

Flagellin_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.84      0.57      0.68      7015
           1       0.76      0.93      0.83     10041

    accuracy                           0.78     17056
   macro avg       0.80      0.75      0.76     17056
weighted avg       0.79      0.78      0.77     17056

              precision    recall  f1-score   support

           0       0.84      0.57      0.68      7015
           1       0.76      0.93      0.83     10041

    accuracy                           0.78     17056
   macro avg       0.80      0.75      0.76     17056
weighted avg       0.79      0.78      0.77     17056

Flagellin_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.63      0.30      0.41     34394
           1       0.57      0.84      0.68     38191

    accuracy                           0.58     72585
   macro avg       0.60      0.57      0.54     72585
weighted avg       0.60      0.58      0.55     72585

              precision    recall  f1-score   support

           0       0.63      0.30      0.41     34394
           1       0.57      0.84      0.68     38191

    accuracy                           0.58     72585
   macro avg       0.60      0.57      0.54     72585
weighted avg       0.60      0.58      0.55     72585

completed
