[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '89637e36'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '092a4a7f'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'c4a8d7df'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '07cb181d'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_0.010_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_0.010_DMSO_0.025
TREATMENT_NAME: Flagellin_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (247627, 1270)
Number of total missing values across all columns: 531870
Data Subset Is Off
Wells held out for testing: ['B09' 'M10']
Wells to use for training, validation, and testing ['B02' 'B03' 'B08' 'M05' 'M11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.628838).  Saving model ...
	 Train_Loss: 0.6567 Train_Acc: 59.206 Val_Loss: 0.6288  BEST VAL Loss: 0.6288  Val_Acc: 64.375

Epoch 1: Validation loss decreased (0.628838 --> 0.613478).  Saving model ...
	 Train_Loss: 0.6358 Train_Acc: 66.338 Val_Loss: 0.6135  BEST VAL Loss: 0.6135  Val_Acc: 69.136

Epoch 2: Validation loss decreased (0.613478 --> 0.599946).  Saving model ...
	 Train_Loss: 0.6199 Train_Acc: 69.701 Val_Loss: 0.5999  BEST VAL Loss: 0.5999  Val_Acc: 71.651

Epoch 3: Validation loss decreased (0.599946 --> 0.588270).  Saving model ...
	 Train_Loss: 0.6064 Train_Acc: 71.565 Val_Loss: 0.5883  BEST VAL Loss: 0.5883  Val_Acc: 72.952

Epoch 4: Validation loss decreased (0.588270 --> 0.577962).  Saving model ...
	 Train_Loss: 0.5946 Train_Acc: 72.805 Val_Loss: 0.5780  BEST VAL Loss: 0.5780  Val_Acc: 74.235

Epoch 5: Validation loss decreased (0.577962 --> 0.568908).  Saving model ...
	 Train_Loss: 0.5845 Train_Acc: 73.577 Val_Loss: 0.5689  BEST VAL Loss: 0.5689  Val_Acc: 75.140

Epoch 6: Validation loss decreased (0.568908 --> 0.560729).  Saving model ...
	 Train_Loss: 0.5754 Train_Acc: 74.407 Val_Loss: 0.5607  BEST VAL Loss: 0.5607  Val_Acc: 75.869

Epoch 7: Validation loss decreased (0.560729 --> 0.553543).  Saving model ...
	 Train_Loss: 0.5673 Train_Acc: 75.190 Val_Loss: 0.5535  BEST VAL Loss: 0.5535  Val_Acc: 76.231

Epoch 8: Validation loss decreased (0.553543 --> 0.547055).  Saving model ...
	 Train_Loss: 0.5600 Train_Acc: 75.728 Val_Loss: 0.5471  BEST VAL Loss: 0.5471  Val_Acc: 76.638

Epoch 9: Validation loss decreased (0.547055 --> 0.541307).  Saving model ...
	 Train_Loss: 0.5535 Train_Acc: 76.072 Val_Loss: 0.5413  BEST VAL Loss: 0.5413  Val_Acc: 77.006

Epoch 10: Validation loss decreased (0.541307 --> 0.536265).  Saving model ...
	 Train_Loss: 0.5477 Train_Acc: 76.430 Val_Loss: 0.5363  BEST VAL Loss: 0.5363  Val_Acc: 77.153

Epoch 11: Validation loss decreased (0.536265 --> 0.531635).  Saving model ...
	 Train_Loss: 0.5424 Train_Acc: 76.790 Val_Loss: 0.5316  BEST VAL Loss: 0.5316  Val_Acc: 77.407

Epoch 12: Validation loss decreased (0.531635 --> 0.527236).  Saving model ...
	 Train_Loss: 0.5376 Train_Acc: 76.984 Val_Loss: 0.5272  BEST VAL Loss: 0.5272  Val_Acc: 77.826

Epoch 13: Validation loss decreased (0.527236 --> 0.523229).  Saving model ...
	 Train_Loss: 0.5332 Train_Acc: 77.367 Val_Loss: 0.5232  BEST VAL Loss: 0.5232  Val_Acc: 78.006

Epoch 14: Validation loss decreased (0.523229 --> 0.519551).  Saving model ...
	 Train_Loss: 0.5290 Train_Acc: 77.645 Val_Loss: 0.5196  BEST VAL Loss: 0.5196  Val_Acc: 78.136

Epoch 15: Validation loss decreased (0.519551 --> 0.516341).  Saving model ...
	 Train_Loss: 0.5253 Train_Acc: 77.802 Val_Loss: 0.5163  BEST VAL Loss: 0.5163  Val_Acc: 78.040

Epoch 16: Validation loss decreased (0.516341 --> 0.513074).  Saving model ...
	 Train_Loss: 0.5218 Train_Acc: 77.918 Val_Loss: 0.5131  BEST VAL Loss: 0.5131  Val_Acc: 78.713

Epoch 17: Validation loss decreased (0.513074 --> 0.510035).  Saving model ...
	 Train_Loss: 0.5186 Train_Acc: 77.964 Val_Loss: 0.5100  BEST VAL Loss: 0.5100  Val_Acc: 78.855

Epoch 18: Validation loss decreased (0.510035 --> 0.507248).  Saving model ...
	 Train_Loss: 0.5154 Train_Acc: 78.312 Val_Loss: 0.5072  BEST VAL Loss: 0.5072  Val_Acc: 78.628

Epoch 19: Validation loss decreased (0.507248 --> 0.504553).  Saving model ...
	 Train_Loss: 0.5125 Train_Acc: 78.594 Val_Loss: 0.5046  BEST VAL Loss: 0.5046  Val_Acc: 79.030

Epoch 20: Validation loss decreased (0.504553 --> 0.501986).  Saving model ...
	 Train_Loss: 0.5096 Train_Acc: 78.700 Val_Loss: 0.5020  BEST VAL Loss: 0.5020  Val_Acc: 79.024

Epoch 21: Validation loss decreased (0.501986 --> 0.499505).  Saving model ...
	 Train_Loss: 0.5070 Train_Acc: 78.736 Val_Loss: 0.4995  BEST VAL Loss: 0.4995  Val_Acc: 79.284

Epoch 22: Validation loss decreased (0.499505 --> 0.497153).  Saving model ...
	 Train_Loss: 0.5044 Train_Acc: 79.035 Val_Loss: 0.4972  BEST VAL Loss: 0.4972  Val_Acc: 79.499

Epoch 23: Validation loss decreased (0.497153 --> 0.494932).  Saving model ...
	 Train_Loss: 0.5020 Train_Acc: 79.024 Val_Loss: 0.4949  BEST VAL Loss: 0.4949  Val_Acc: 79.686

Epoch 24: Validation loss decreased (0.494932 --> 0.492733).  Saving model ...
	 Train_Loss: 0.4996 Train_Acc: 79.249 Val_Loss: 0.4927  BEST VAL Loss: 0.4927  Val_Acc: 79.821

Epoch 25: Validation loss decreased (0.492733 --> 0.490625).  Saving model ...
	 Train_Loss: 0.4974 Train_Acc: 79.352 Val_Loss: 0.4906  BEST VAL Loss: 0.4906  Val_Acc: 79.929

Epoch 26: Validation loss decreased (0.490625 --> 0.488638).  Saving model ...
	 Train_Loss: 0.4953 Train_Acc: 79.374 Val_Loss: 0.4886  BEST VAL Loss: 0.4886  Val_Acc: 79.974

Epoch 27: Validation loss decreased (0.488638 --> 0.486751).  Saving model ...
	 Train_Loss: 0.4933 Train_Acc: 79.470 Val_Loss: 0.4868  BEST VAL Loss: 0.4868  Val_Acc: 80.104

Epoch 28: Validation loss decreased (0.486751 --> 0.484974).  Saving model ...
	 Train_Loss: 0.4913 Train_Acc: 79.619 Val_Loss: 0.4850  BEST VAL Loss: 0.4850  Val_Acc: 80.070

Epoch 29: Validation loss decreased (0.484974 --> 0.483236).  Saving model ...
	 Train_Loss: 0.4894 Train_Acc: 79.744 Val_Loss: 0.4832  BEST VAL Loss: 0.4832  Val_Acc: 80.211

Epoch 30: Validation loss decreased (0.483236 --> 0.481658).  Saving model ...
	 Train_Loss: 0.4876 Train_Acc: 79.809 Val_Loss: 0.4817  BEST VAL Loss: 0.4817  Val_Acc: 80.110

Epoch 31: Validation loss decreased (0.481658 --> 0.480069).  Saving model ...
	 Train_Loss: 0.4858 Train_Acc: 79.781 Val_Loss: 0.4801  BEST VAL Loss: 0.4801  Val_Acc: 80.330

Epoch 32: Validation loss decreased (0.480069 --> 0.478528).  Saving model ...
	 Train_Loss: 0.4842 Train_Acc: 79.899 Val_Loss: 0.4785  BEST VAL Loss: 0.4785  Val_Acc: 80.528

Epoch 33: Validation loss decreased (0.478528 --> 0.477111).  Saving model ...
	 Train_Loss: 0.4826 Train_Acc: 80.059 Val_Loss: 0.4771  BEST VAL Loss: 0.4771  Val_Acc: 80.364

Epoch 34: Validation loss decreased (0.477111 --> 0.475701).  Saving model ...
	 Train_Loss: 0.4810 Train_Acc: 80.186 Val_Loss: 0.4757  BEST VAL Loss: 0.4757  Val_Acc: 80.635

Epoch 35: Validation loss decreased (0.475701 --> 0.474368).  Saving model ...
	 Train_Loss: 0.4795 Train_Acc: 80.128 Val_Loss: 0.4744  BEST VAL Loss: 0.4744  Val_Acc: 80.477

Epoch 36: Validation loss decreased (0.474368 --> 0.473103).  Saving model ...
	 Train_Loss: 0.4781 Train_Acc: 80.156 Val_Loss: 0.4731  BEST VAL Loss: 0.4731  Val_Acc: 80.409

Epoch 37: Validation loss decreased (0.473103 --> 0.471877).  Saving model ...
	 Train_Loss: 0.4767 Train_Acc: 80.284 Val_Loss: 0.4719  BEST VAL Loss: 0.4719  Val_Acc: 80.630

Epoch 38: Validation loss decreased (0.471877 --> 0.470737).  Saving model ...
	 Train_Loss: 0.4753 Train_Acc: 80.304 Val_Loss: 0.4707  BEST VAL Loss: 0.4707  Val_Acc: 80.613

Epoch 39: Validation loss decreased (0.470737 --> 0.469569).  Saving model ...
	 Train_Loss: 0.4740 Train_Acc: 80.386 Val_Loss: 0.4696  BEST VAL Loss: 0.4696  Val_Acc: 80.760

Epoch 40: Validation loss decreased (0.469569 --> 0.468472).  Saving model ...
	 Train_Loss: 0.4727 Train_Acc: 80.407 Val_Loss: 0.4685  BEST VAL Loss: 0.4685  Val_Acc: 80.811

Epoch 41: Validation loss decreased (0.468472 --> 0.467426).  Saving model ...
	 Train_Loss: 0.4715 Train_Acc: 80.364 Val_Loss: 0.4674  BEST VAL Loss: 0.4674  Val_Acc: 80.771

Epoch 42: Validation loss decreased (0.467426 --> 0.466406).  Saving model ...
	 Train_Loss: 0.4703 Train_Acc: 80.514 Val_Loss: 0.4664  BEST VAL Loss: 0.4664  Val_Acc: 80.913

Epoch 43: Validation loss decreased (0.466406 --> 0.465411).  Saving model ...
	 Train_Loss: 0.4691 Train_Acc: 80.564 Val_Loss: 0.4654  BEST VAL Loss: 0.4654  Val_Acc: 80.839

Epoch 44: Validation loss decreased (0.465411 --> 0.464452).  Saving model ...
	 Train_Loss: 0.4680 Train_Acc: 80.573 Val_Loss: 0.4645  BEST VAL Loss: 0.4645  Val_Acc: 81.043

Epoch 45: Validation loss decreased (0.464452 --> 0.463534).  Saving model ...
	 Train_Loss: 0.4669 Train_Acc: 80.567 Val_Loss: 0.4635  BEST VAL Loss: 0.4635  Val_Acc: 80.924

Epoch 46: Validation loss decreased (0.463534 --> 0.462648).  Saving model ...
	 Train_Loss: 0.4659 Train_Acc: 80.646 Val_Loss: 0.4626  BEST VAL Loss: 0.4626  Val_Acc: 80.929

Epoch 47: Validation loss decreased (0.462648 --> 0.461770).  Saving model ...
	 Train_Loss: 0.4649 Train_Acc: 80.669 Val_Loss: 0.4618  BEST VAL Loss: 0.4618  Val_Acc: 80.929

Epoch 48: Validation loss decreased (0.461770 --> 0.460972).  Saving model ...
	 Train_Loss: 0.4639 Train_Acc: 80.745 Val_Loss: 0.4610  BEST VAL Loss: 0.4610  Val_Acc: 80.879

Epoch 49: Validation loss decreased (0.460972 --> 0.460199).  Saving model ...
	 Train_Loss: 0.4629 Train_Acc: 80.767 Val_Loss: 0.4602  BEST VAL Loss: 0.4602  Val_Acc: 80.794

Epoch 50: Validation loss decreased (0.460199 --> 0.459464).  Saving model ...
	 Train_Loss: 0.4619 Train_Acc: 80.791 Val_Loss: 0.4595  BEST VAL Loss: 0.4595  Val_Acc: 80.850

Epoch 51: Validation loss decreased (0.459464 --> 0.458693).  Saving model ...
	 Train_Loss: 0.4610 Train_Acc: 80.843 Val_Loss: 0.4587  BEST VAL Loss: 0.4587  Val_Acc: 81.014

Epoch 52: Validation loss decreased (0.458693 --> 0.457989).  Saving model ...
	 Train_Loss: 0.4601 Train_Acc: 80.951 Val_Loss: 0.4580  BEST VAL Loss: 0.4580  Val_Acc: 80.890

Epoch 53: Validation loss decreased (0.457989 --> 0.457256).  Saving model ...
	 Train_Loss: 0.4592 Train_Acc: 80.876 Val_Loss: 0.4573  BEST VAL Loss: 0.4573  Val_Acc: 81.116

Epoch 54: Validation loss decreased (0.457256 --> 0.456511).  Saving model ...
	 Train_Loss: 0.4584 Train_Acc: 80.918 Val_Loss: 0.4565  BEST VAL Loss: 0.4565  Val_Acc: 81.167

Epoch 55: Validation loss decreased (0.456511 --> 0.455807).  Saving model ...
	 Train_Loss: 0.4575 Train_Acc: 81.027 Val_Loss: 0.4558  BEST VAL Loss: 0.4558  Val_Acc: 81.116

Epoch 56: Validation loss decreased (0.455807 --> 0.455121).  Saving model ...
	 Train_Loss: 0.4567 Train_Acc: 80.895 Val_Loss: 0.4551  BEST VAL Loss: 0.4551  Val_Acc: 81.325

Epoch 57: Validation loss decreased (0.455121 --> 0.454458).  Saving model ...
	 Train_Loss: 0.4559 Train_Acc: 81.034 Val_Loss: 0.4545  BEST VAL Loss: 0.4545  Val_Acc: 81.263

Epoch 58: Validation loss decreased (0.454458 --> 0.453863).  Saving model ...
	 Train_Loss: 0.4551 Train_Acc: 81.052 Val_Loss: 0.4539  BEST VAL Loss: 0.4539  Val_Acc: 80.884

Epoch 59: Validation loss decreased (0.453863 --> 0.453258).  Saving model ...
	 Train_Loss: 0.4544 Train_Acc: 81.076 Val_Loss: 0.4533  BEST VAL Loss: 0.4533  Val_Acc: 81.082

Epoch 60: Validation loss decreased (0.453258 --> 0.452691).  Saving model ...
	 Train_Loss: 0.4536 Train_Acc: 80.984 Val_Loss: 0.4527  BEST VAL Loss: 0.4527  Val_Acc: 81.071

Epoch 61: Validation loss decreased (0.452691 --> 0.452130).  Saving model ...
	 Train_Loss: 0.4529 Train_Acc: 81.113 Val_Loss: 0.4521  BEST VAL Loss: 0.4521  Val_Acc: 81.156

Epoch 62: Validation loss decreased (0.452130 --> 0.451510).  Saving model ...
	 Train_Loss: 0.4521 Train_Acc: 81.167 Val_Loss: 0.4515  BEST VAL Loss: 0.4515  Val_Acc: 81.365

Epoch 63: Validation loss decreased (0.451510 --> 0.451000).  Saving model ...
	 Train_Loss: 0.4514 Train_Acc: 81.119 Val_Loss: 0.4510  BEST VAL Loss: 0.4510  Val_Acc: 80.997

Epoch 64: Validation loss decreased (0.451000 --> 0.450506).  Saving model ...
	 Train_Loss: 0.4507 Train_Acc: 81.157 Val_Loss: 0.4505  BEST VAL Loss: 0.4505  Val_Acc: 81.116

Epoch 65: Validation loss decreased (0.450506 --> 0.449994).  Saving model ...
	 Train_Loss: 0.4501 Train_Acc: 81.266 Val_Loss: 0.4500  BEST VAL Loss: 0.4500  Val_Acc: 81.297

Epoch 66: Validation loss decreased (0.449994 --> 0.449511).  Saving model ...
	 Train_Loss: 0.4494 Train_Acc: 81.254 Val_Loss: 0.4495  BEST VAL Loss: 0.4495  Val_Acc: 81.076

Epoch 67: Validation loss decreased (0.449511 --> 0.448989).  Saving model ...
	 Train_Loss: 0.4487 Train_Acc: 81.228 Val_Loss: 0.4490  BEST VAL Loss: 0.4490  Val_Acc: 81.387

Epoch 68: Validation loss decreased (0.448989 --> 0.448500).  Saving model ...
	 Train_Loss: 0.4481 Train_Acc: 81.192 Val_Loss: 0.4485  BEST VAL Loss: 0.4485  Val_Acc: 81.207

Epoch 69: Validation loss decreased (0.448500 --> 0.448013).  Saving model ...
	 Train_Loss: 0.4475 Train_Acc: 81.201 Val_Loss: 0.4480  BEST VAL Loss: 0.4480  Val_Acc: 81.252

Epoch 70: Validation loss decreased (0.448013 --> 0.447527).  Saving model ...
	 Train_Loss: 0.4468 Train_Acc: 81.360 Val_Loss: 0.4475  BEST VAL Loss: 0.4475  Val_Acc: 81.297

Epoch 71: Validation loss decreased (0.447527 --> 0.447038).  Saving model ...
	 Train_Loss: 0.4462 Train_Acc: 81.373 Val_Loss: 0.4470  BEST VAL Loss: 0.4470  Val_Acc: 81.376

Epoch 72: Validation loss decreased (0.447038 --> 0.446603).  Saving model ...
	 Train_Loss: 0.4456 Train_Acc: 81.316 Val_Loss: 0.4466  BEST VAL Loss: 0.4466  Val_Acc: 81.229

Epoch 73: Validation loss decreased (0.446603 --> 0.446187).  Saving model ...
	 Train_Loss: 0.4451 Train_Acc: 81.314 Val_Loss: 0.4462  BEST VAL Loss: 0.4462  Val_Acc: 81.280

Epoch 74: Validation loss decreased (0.446187 --> 0.445789).  Saving model ...
	 Train_Loss: 0.4445 Train_Acc: 81.380 Val_Loss: 0.4458  BEST VAL Loss: 0.4458  Val_Acc: 81.263

Epoch 75: Validation loss decreased (0.445789 --> 0.445353).  Saving model ...
	 Train_Loss: 0.4439 Train_Acc: 81.369 Val_Loss: 0.4454  BEST VAL Loss: 0.4454  Val_Acc: 81.314

Epoch 76: Validation loss decreased (0.445353 --> 0.444939).  Saving model ...
	 Train_Loss: 0.4434 Train_Acc: 81.386 Val_Loss: 0.4449  BEST VAL Loss: 0.4449  Val_Acc: 81.308

Epoch 77: Validation loss decreased (0.444939 --> 0.444525).  Saving model ...
	 Train_Loss: 0.4428 Train_Acc: 81.273 Val_Loss: 0.4445  BEST VAL Loss: 0.4445  Val_Acc: 81.308

Epoch 78: Validation loss decreased (0.444525 --> 0.444147).  Saving model ...
	 Train_Loss: 0.4423 Train_Acc: 81.306 Val_Loss: 0.4441  BEST VAL Loss: 0.4441  Val_Acc: 81.303

Epoch 79: Validation loss decreased (0.444147 --> 0.443720).  Saving model ...
	 Train_Loss: 0.4418 Train_Acc: 81.441 Val_Loss: 0.4437  BEST VAL Loss: 0.4437  Val_Acc: 81.393

Epoch 80: Validation loss decreased (0.443720 --> 0.443356).  Saving model ...
	 Train_Loss: 0.4412 Train_Acc: 81.433 Val_Loss: 0.4434  BEST VAL Loss: 0.4434  Val_Acc: 81.184

Epoch 81: Validation loss decreased (0.443356 --> 0.443026).  Saving model ...
	 Train_Loss: 0.4407 Train_Acc: 81.388 Val_Loss: 0.4430  BEST VAL Loss: 0.4430  Val_Acc: 81.274

Epoch 82: Validation loss decreased (0.443026 --> 0.442647).  Saving model ...
	 Train_Loss: 0.4402 Train_Acc: 81.373 Val_Loss: 0.4426  BEST VAL Loss: 0.4426  Val_Acc: 81.365

Epoch 83: Validation loss decreased (0.442647 --> 0.442308).  Saving model ...
	 Train_Loss: 0.4398 Train_Acc: 81.460 Val_Loss: 0.4423  BEST VAL Loss: 0.4423  Val_Acc: 81.382

Epoch 84: Validation loss decreased (0.442308 --> 0.441980).  Saving model ...
	 Train_Loss: 0.4393 Train_Acc: 81.486 Val_Loss: 0.4420  BEST VAL Loss: 0.4420  Val_Acc: 81.331

Epoch 85: Validation loss decreased (0.441980 --> 0.441655).  Saving model ...
	 Train_Loss: 0.4388 Train_Acc: 81.439 Val_Loss: 0.4417  BEST VAL Loss: 0.4417  Val_Acc: 81.252

Epoch 86: Validation loss decreased (0.441655 --> 0.441298).  Saving model ...
	 Train_Loss: 0.4383 Train_Acc: 81.463 Val_Loss: 0.4413  BEST VAL Loss: 0.4413  Val_Acc: 81.314

Epoch 87: Validation loss decreased (0.441298 --> 0.440968).  Saving model ...
	 Train_Loss: 0.4379 Train_Acc: 81.558 Val_Loss: 0.4410  BEST VAL Loss: 0.4410  Val_Acc: 81.444

Epoch 88: Validation loss decreased (0.440968 --> 0.440592).  Saving model ...
	 Train_Loss: 0.4374 Train_Acc: 81.475 Val_Loss: 0.4406  BEST VAL Loss: 0.4406  Val_Acc: 81.631

Epoch 89: Validation loss decreased (0.440592 --> 0.440262).  Saving model ...
	 Train_Loss: 0.4370 Train_Acc: 81.529 Val_Loss: 0.4403  BEST VAL Loss: 0.4403  Val_Acc: 81.461

Epoch 90: Validation loss decreased (0.440262 --> 0.439943).  Saving model ...
	 Train_Loss: 0.4365 Train_Acc: 81.516 Val_Loss: 0.4399  BEST VAL Loss: 0.4399  Val_Acc: 81.387

Epoch 91: Validation loss decreased (0.439943 --> 0.439622).  Saving model ...
	 Train_Loss: 0.4361 Train_Acc: 81.627 Val_Loss: 0.4396  BEST VAL Loss: 0.4396  Val_Acc: 81.438

Epoch 92: Validation loss decreased (0.439622 --> 0.439329).  Saving model ...
	 Train_Loss: 0.4356 Train_Acc: 81.619 Val_Loss: 0.4393  BEST VAL Loss: 0.4393  Val_Acc: 81.354

Epoch 93: Validation loss decreased (0.439329 --> 0.439007).  Saving model ...
	 Train_Loss: 0.4352 Train_Acc: 81.535 Val_Loss: 0.4390  BEST VAL Loss: 0.4390  Val_Acc: 81.608

Epoch 94: Validation loss decreased (0.439007 --> 0.438678).  Saving model ...
	 Train_Loss: 0.4348 Train_Acc: 81.592 Val_Loss: 0.4387  BEST VAL Loss: 0.4387  Val_Acc: 81.659

Epoch 95: Validation loss decreased (0.438678 --> 0.438379).  Saving model ...
	 Train_Loss: 0.4344 Train_Acc: 81.696 Val_Loss: 0.4384  BEST VAL Loss: 0.4384  Val_Acc: 81.314

Epoch 96: Validation loss decreased (0.438379 --> 0.438078).  Saving model ...
	 Train_Loss: 0.4339 Train_Acc: 81.646 Val_Loss: 0.4381  BEST VAL Loss: 0.4381  Val_Acc: 81.399

Epoch 97: Validation loss decreased (0.438078 --> 0.437785).  Saving model ...
	 Train_Loss: 0.4335 Train_Acc: 81.586 Val_Loss: 0.4378  BEST VAL Loss: 0.4378  Val_Acc: 81.376

Epoch 98: Validation loss decreased (0.437785 --> 0.437533).  Saving model ...
	 Train_Loss: 0.4332 Train_Acc: 81.534 Val_Loss: 0.4375  BEST VAL Loss: 0.4375  Val_Acc: 81.161

Epoch 99: Validation loss decreased (0.437533 --> 0.437275).  Saving model ...
	 Train_Loss: 0.4328 Train_Acc: 81.631 Val_Loss: 0.4373  BEST VAL Loss: 0.4373  Val_Acc: 81.314

LPS_0.010_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.84      0.73      0.78     56123
           1       0.84      0.91      0.87     85370

    accuracy                           0.84    141493
   macro avg       0.84      0.82      0.83    141493
weighted avg       0.84      0.84      0.83    141493

LPS_0.010_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.80      0.70      0.75      7015
           1       0.82      0.89      0.85     10672

    accuracy                           0.81     17687
   macro avg       0.81      0.79      0.80     17687
weighted avg       0.81      0.81      0.81     17687

LPS_0.010_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.81      0.70      0.75      7015
           1       0.82      0.89      0.86     10672

    accuracy                           0.82     17687
   macro avg       0.82      0.80      0.81     17687
weighted avg       0.82      0.82      0.82     17687

              precision    recall  f1-score   support

           0       0.81      0.70      0.75      7015
           1       0.82      0.89      0.86     10672

    accuracy                           0.82     17687
   macro avg       0.82      0.80      0.81     17687
weighted avg       0.82      0.82      0.82     17687

LPS_0.010_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.67      0.30      0.42     34394
           1       0.56      0.86      0.68     36366

    accuracy                           0.59     70760
   macro avg       0.62      0.58      0.55     70760
weighted avg       0.61      0.59      0.55     70760

              precision    recall  f1-score   support

           0       0.67      0.30      0.42     34394
           1       0.56      0.86      0.68     36366

    accuracy                           0.59     70760
   macro avg       0.62      0.58      0.55     70760
weighted avg       0.61      0.59      0.55     70760

completed
