[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '7f0d07b0'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'a4ec2435'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '6c3f2abe'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '8cd6d571'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 treatment_name: Thapsigargin_10.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
TREATMENT_NAME: Thapsigargin_10.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (29430, 1276)
Number of total missing values across all columns: 26424
Data Subset Is Off
Wells held out for testing: ['E14' 'K20']
Wells to use for training, validation, and testing ['E15' 'L14' 'L15' 'K16' 'K17' 'K21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.165271).  Saving model ...
	 Train_Loss: 0.3200 Train_Acc: 83.095 Val_Loss: 0.1653  BEST VAL Loss: 0.1653  Val_Acc: 93.512

Epoch 1: Validation loss decreased (0.165271 --> 0.145170).  Saving model ...
	 Train_Loss: 0.2536 Train_Acc: 92.750 Val_Loss: 0.1452  BEST VAL Loss: 0.1452  Val_Acc: 95.236

Epoch 2: Validation loss decreased (0.145170 --> 0.127316).  Saving model ...
	 Train_Loss: 0.2165 Train_Acc: 94.185 Val_Loss: 0.1273  BEST VAL Loss: 0.1273  Val_Acc: 95.871

Epoch 3: Validation loss decreased (0.127316 --> 0.120368).  Saving model ...
	 Train_Loss: 0.1915 Train_Acc: 95.218 Val_Loss: 0.1204  BEST VAL Loss: 0.1204  Val_Acc: 96.915

Epoch 4: Validation loss decreased (0.120368 --> 0.115308).  Saving model ...
	 Train_Loss: 0.1740 Train_Acc: 95.927 Val_Loss: 0.1153  BEST VAL Loss: 0.1153  Val_Acc: 96.642

Epoch 5: Validation loss decreased (0.115308 --> 0.113897).  Saving model ...
	 Train_Loss: 0.1613 Train_Acc: 95.865 Val_Loss: 0.1139  BEST VAL Loss: 0.1139  Val_Acc: 96.869

Epoch 6: Validation loss decreased (0.113897 --> 0.108828).  Saving model ...
	 Train_Loss: 0.1506 Train_Acc: 96.460 Val_Loss: 0.1088  BEST VAL Loss: 0.1088  Val_Acc: 97.459

Epoch 7: Validation loss decreased (0.108828 --> 0.105785).  Saving model ...
	 Train_Loss: 0.1426 Train_Acc: 96.500 Val_Loss: 0.1058  BEST VAL Loss: 0.1058  Val_Acc: 97.142

Epoch 8: Validation loss decreased (0.105785 --> 0.104731).  Saving model ...
	 Train_Loss: 0.1358 Train_Acc: 96.835 Val_Loss: 0.1047  BEST VAL Loss: 0.1047  Val_Acc: 96.960

Epoch 9: Validation loss decreased (0.104731 --> 0.103041).  Saving model ...
	 Train_Loss: 0.1304 Train_Acc: 96.721 Val_Loss: 0.1030  BEST VAL Loss: 0.1030  Val_Acc: 97.505

Epoch 10: Validation loss decreased (0.103041 --> 0.101505).  Saving model ...
	 Train_Loss: 0.1261 Train_Acc: 96.710 Val_Loss: 0.1015  BEST VAL Loss: 0.1015  Val_Acc: 97.232

Epoch 11: Validation loss decreased (0.101505 --> 0.101332).  Saving model ...
	 Train_Loss: 0.1215 Train_Acc: 97.300 Val_Loss: 0.1013  BEST VAL Loss: 0.1013  Val_Acc: 97.278

Epoch 12: Validation loss decreased (0.101332 --> 0.100271).  Saving model ...
	 Train_Loss: 0.1178 Train_Acc: 97.141 Val_Loss: 0.1003  BEST VAL Loss: 0.1003  Val_Acc: 97.459

Epoch 13: Validation loss decreased (0.100271 --> 0.099049).  Saving model ...
	 Train_Loss: 0.1147 Train_Acc: 97.135 Val_Loss: 0.0990  BEST VAL Loss: 0.0990  Val_Acc: 97.051

Epoch 14: Validation loss did not decrease
	 Train_Loss: 0.1117 Train_Acc: 97.288 Val_Loss: 0.0993  BEST VAL Loss: 0.0990  Val_Acc: 97.187

Epoch 15: Validation loss did not decrease
	 Train_Loss: 0.1089 Train_Acc: 97.464 Val_Loss: 0.0997  BEST VAL Loss: 0.0990  Val_Acc: 97.505

Epoch 16: Validation loss did not decrease
	 Train_Loss: 0.1064 Train_Acc: 97.510 Val_Loss: 0.1004  BEST VAL Loss: 0.0990  Val_Acc: 97.278

Epoch 17: Validation loss did not decrease
	 Train_Loss: 0.1040 Train_Acc: 97.578 Val_Loss: 0.0999  BEST VAL Loss: 0.0990  Val_Acc: 97.414

Epoch 18: Validation loss did not decrease
	 Train_Loss: 0.1018 Train_Acc: 97.737 Val_Loss: 0.1029  BEST VAL Loss: 0.0990  Val_Acc: 97.278

Epoch 19: Validation loss did not decrease
	 Train_Loss: 0.0999 Train_Acc: 97.657 Val_Loss: 0.1067  BEST VAL Loss: 0.0990  Val_Acc: 97.142

Epoch 20: Validation loss did not decrease
	 Train_Loss: 0.0985 Train_Acc: 97.249 Val_Loss: 0.1064  BEST VAL Loss: 0.0990  Val_Acc: 97.323

Epoch 21: Validation loss did not decrease
	 Train_Loss: 0.0970 Train_Acc: 97.606 Val_Loss: 0.1068  BEST VAL Loss: 0.0990  Val_Acc: 97.323

Epoch 22: Validation loss did not decrease
	 Train_Loss: 0.0956 Train_Acc: 97.549 Val_Loss: 0.1080  BEST VAL Loss: 0.0990  Val_Acc: 97.368

Epoch 23: Validation loss did not decrease
	 Train_Loss: 0.0941 Train_Acc: 97.754 Val_Loss: 0.1082  BEST VAL Loss: 0.0990  Val_Acc: 97.777

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.0925 Train_Acc: 98.015 Val_Loss: 0.1086  BEST VAL Loss: 0.0990  Val_Acc: 97.595

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.0910 Train_Acc: 98.020 Val_Loss: 0.1084  BEST VAL Loss: 0.0990  Val_Acc: 97.505

Epoch 26: Validation loss did not decrease
	 Train_Loss: 0.0896 Train_Acc: 98.009 Val_Loss: 0.1082  BEST VAL Loss: 0.0990  Val_Acc: 98.004

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.0887 Train_Acc: 97.612 Val_Loss: 0.1083  BEST VAL Loss: 0.0990  Val_Acc: 97.414

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.0877 Train_Acc: 97.617 Val_Loss: 0.1090  BEST VAL Loss: 0.0990  Val_Acc: 97.459

Epoch 29: Validation loss did not decrease
Early stopped at epoch : 29
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.56      0.55      0.55      9778
           1       0.45      0.45      0.45      7850

    accuracy                           0.51     17628
   macro avg       0.50      0.50      0.50     17628
weighted avg       0.51      0.51      0.51     17628

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.55      0.55      1222
           1       0.44      0.45      0.45       982

    accuracy                           0.50      2204
   macro avg       0.50      0.50      0.50      2204
weighted avg       0.51      0.50      0.51      2204

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.56      0.56      0.56      1222
           1       0.46      0.46      0.46       982

    accuracy                           0.51      2204
   macro avg       0.51      0.51      0.51      2204
weighted avg       0.52      0.51      0.51      2204

              precision    recall  f1-score   support

           0       0.56      0.56      0.56      1222
           1       0.46      0.46      0.46       982

    accuracy                           0.51      2204
   macro avg       0.51      0.51      0.51      2204
weighted avg       0.52      0.51      0.51      2204

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.53      0.53      3996
           1       0.45      0.45      0.45      3398

    accuracy                           0.49      7394
   macro avg       0.49      0.49      0.49      7394
weighted avg       0.49      0.49      0.49      7394

              precision    recall  f1-score   support

           0       0.53      0.53      0.53      3996
           1       0.45      0.45      0.45      3398

    accuracy                           0.49      7394
   macro avg       0.49      0.49      0.49      7394
weighted avg       0.49      0.49      0.49      7394

completed
