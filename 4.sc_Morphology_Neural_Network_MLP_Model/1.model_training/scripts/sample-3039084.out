[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '78d127a5'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '59ac53a7'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1a01e8eb'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '528c0c6a'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_0.010_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_0.010_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_0.100_DMSO_0.025']
The dimensions of the data are: (281677, 1270)
Number of total missing values across all columns: 563354
Data Subset Is Off
Wells held out for testing: ['B08' 'C08']
Wells to use for training, validation, and testing ['B02' 'C02' 'B03' 'C03' 'B09' 'C09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.683531).  Saving model ...
	 Train_Loss: 0.6891 Train_Acc: 53.093 Val_Loss: 0.6835  BEST VAL Loss: 0.6835  Val_Acc: 54.771

Epoch 1: Validation loss decreased (0.683531 --> 0.681663).  Saving model ...
	 Train_Loss: 0.6854 Train_Acc: 54.959 Val_Loss: 0.6817  BEST VAL Loss: 0.6817  Val_Acc: 56.038

Epoch 2: Validation loss decreased (0.681663 --> 0.679600).  Saving model ...
	 Train_Loss: 0.6826 Train_Acc: 56.094 Val_Loss: 0.6796  BEST VAL Loss: 0.6796  Val_Acc: 57.024

Epoch 3: Validation loss decreased (0.679600 --> 0.677438).  Saving model ...
	 Train_Loss: 0.6800 Train_Acc: 56.988 Val_Loss: 0.6774  BEST VAL Loss: 0.6774  Val_Acc: 57.886

Epoch 4: Validation loss decreased (0.677438 --> 0.675082).  Saving model ...
	 Train_Loss: 0.6775 Train_Acc: 57.712 Val_Loss: 0.6751  BEST VAL Loss: 0.6751  Val_Acc: 58.571

Epoch 5: Validation loss decreased (0.675082 --> 0.672759).  Saving model ...
	 Train_Loss: 0.6749 Train_Acc: 58.491 Val_Loss: 0.6728  BEST VAL Loss: 0.6728  Val_Acc: 59.324

Epoch 6: Validation loss decreased (0.672759 --> 0.670496).  Saving model ...
	 Train_Loss: 0.6724 Train_Acc: 59.019 Val_Loss: 0.6705  BEST VAL Loss: 0.6705  Val_Acc: 59.910

Epoch 7: Validation loss decreased (0.670496 --> 0.668317).  Saving model ...
	 Train_Loss: 0.6701 Train_Acc: 59.616 Val_Loss: 0.6683  BEST VAL Loss: 0.6683  Val_Acc: 60.524

Epoch 8: Validation loss decreased (0.668317 --> 0.666257).  Saving model ...
	 Train_Loss: 0.6679 Train_Acc: 60.001 Val_Loss: 0.6663  BEST VAL Loss: 0.6663  Val_Acc: 60.819

Epoch 9: Validation loss decreased (0.666257 --> 0.664313).  Saving model ...
	 Train_Loss: 0.6658 Train_Acc: 60.294 Val_Loss: 0.6643  BEST VAL Loss: 0.6643  Val_Acc: 61.033

Epoch 10: Validation loss decreased (0.664313 --> 0.662503).  Saving model ...
	 Train_Loss: 0.6639 Train_Acc: 60.591 Val_Loss: 0.6625  BEST VAL Loss: 0.6625  Val_Acc: 61.357

Epoch 11: Validation loss decreased (0.662503 --> 0.660877).  Saving model ...
	 Train_Loss: 0.6622 Train_Acc: 60.835 Val_Loss: 0.6609  BEST VAL Loss: 0.6609  Val_Acc: 61.338

Epoch 12: Validation loss decreased (0.660877 --> 0.659351).  Saving model ...
	 Train_Loss: 0.6605 Train_Acc: 61.125 Val_Loss: 0.6594  BEST VAL Loss: 0.6594  Val_Acc: 61.305

Epoch 13: Validation loss decreased (0.659351 --> 0.657809).  Saving model ...
	 Train_Loss: 0.6589 Train_Acc: 61.289 Val_Loss: 0.6578  BEST VAL Loss: 0.6578  Val_Acc: 61.619

Epoch 14: Validation loss decreased (0.657809 --> 0.656327).  Saving model ...
	 Train_Loss: 0.6574 Train_Acc: 61.372 Val_Loss: 0.6563  BEST VAL Loss: 0.6563  Val_Acc: 61.805

Epoch 15: Validation loss decreased (0.656327 --> 0.654939).  Saving model ...
	 Train_Loss: 0.6560 Train_Acc: 61.784 Val_Loss: 0.6549  BEST VAL Loss: 0.6549  Val_Acc: 62.381

Epoch 16: Validation loss decreased (0.654939 --> 0.653639).  Saving model ...
	 Train_Loss: 0.6546 Train_Acc: 62.007 Val_Loss: 0.6536  BEST VAL Loss: 0.6536  Val_Acc: 62.700

Epoch 17: Validation loss decreased (0.653639 --> 0.652521).  Saving model ...
	 Train_Loss: 0.6533 Train_Acc: 62.095 Val_Loss: 0.6525  BEST VAL Loss: 0.6525  Val_Acc: 62.481

Epoch 18: Validation loss decreased (0.652521 --> 0.651264).  Saving model ...
	 Train_Loss: 0.6520 Train_Acc: 62.232 Val_Loss: 0.6513  BEST VAL Loss: 0.6513  Val_Acc: 62.914

Epoch 19: Validation loss decreased (0.651264 --> 0.650119).  Saving model ...
	 Train_Loss: 0.6508 Train_Acc: 62.385 Val_Loss: 0.6501  BEST VAL Loss: 0.6501  Val_Acc: 62.914

Epoch 20: Validation loss decreased (0.650119 --> 0.649032).  Saving model ...
	 Train_Loss: 0.6496 Train_Acc: 62.648 Val_Loss: 0.6490  BEST VAL Loss: 0.6490  Val_Acc: 63.190

Epoch 21: Validation loss decreased (0.649032 --> 0.647973).  Saving model ...
	 Train_Loss: 0.6485 Train_Acc: 62.709 Val_Loss: 0.6480  BEST VAL Loss: 0.6480  Val_Acc: 63.171

Epoch 22: Validation loss decreased (0.647973 --> 0.646933).  Saving model ...
	 Train_Loss: 0.6474 Train_Acc: 62.871 Val_Loss: 0.6469  BEST VAL Loss: 0.6469  Val_Acc: 63.433

Epoch 23: Validation loss decreased (0.646933 --> 0.646020).  Saving model ...
	 Train_Loss: 0.6464 Train_Acc: 63.197 Val_Loss: 0.6460  BEST VAL Loss: 0.6460  Val_Acc: 63.286

Epoch 24: Validation loss decreased (0.646020 --> 0.645113).  Saving model ...
	 Train_Loss: 0.6454 Train_Acc: 63.166 Val_Loss: 0.6451  BEST VAL Loss: 0.6451  Val_Acc: 63.300

Epoch 25: Validation loss decreased (0.645113 --> 0.644207).  Saving model ...
	 Train_Loss: 0.6444 Train_Acc: 63.337 Val_Loss: 0.6442  BEST VAL Loss: 0.6442  Val_Acc: 63.700

Epoch 26: Validation loss decreased (0.644207 --> 0.643325).  Saving model ...
	 Train_Loss: 0.6434 Train_Acc: 63.403 Val_Loss: 0.6433  BEST VAL Loss: 0.6433  Val_Acc: 64.019

Epoch 27: Validation loss decreased (0.643325 --> 0.642485).  Saving model ...
	 Train_Loss: 0.6424 Train_Acc: 63.611 Val_Loss: 0.6425  BEST VAL Loss: 0.6425  Val_Acc: 63.905

Epoch 28: Validation loss decreased (0.642485 --> 0.641631).  Saving model ...
	 Train_Loss: 0.6415 Train_Acc: 63.601 Val_Loss: 0.6416  BEST VAL Loss: 0.6416  Val_Acc: 64.067

Epoch 29: Validation loss decreased (0.641631 --> 0.640805).  Saving model ...
	 Train_Loss: 0.6407 Train_Acc: 63.739 Val_Loss: 0.6408  BEST VAL Loss: 0.6408  Val_Acc: 64.195

Epoch 30: Validation loss decreased (0.640805 --> 0.640019).  Saving model ...
	 Train_Loss: 0.6398 Train_Acc: 63.947 Val_Loss: 0.6400  BEST VAL Loss: 0.6400  Val_Acc: 64.238

Epoch 31: Validation loss decreased (0.640019 --> 0.639248).  Saving model ...
	 Train_Loss: 0.6389 Train_Acc: 63.930 Val_Loss: 0.6392  BEST VAL Loss: 0.6392  Val_Acc: 64.343

Epoch 32: Validation loss decreased (0.639248 --> 0.638483).  Saving model ...
	 Train_Loss: 0.6381 Train_Acc: 64.088 Val_Loss: 0.6385  BEST VAL Loss: 0.6385  Val_Acc: 64.600

Epoch 33: Validation loss decreased (0.638483 --> 0.637744).  Saving model ...
	 Train_Loss: 0.6373 Train_Acc: 64.043 Val_Loss: 0.6377  BEST VAL Loss: 0.6377  Val_Acc: 64.490

Epoch 34: Validation loss decreased (0.637744 --> 0.637008).  Saving model ...
	 Train_Loss: 0.6365 Train_Acc: 64.108 Val_Loss: 0.6370  BEST VAL Loss: 0.6370  Val_Acc: 64.495

Epoch 35: Validation loss decreased (0.637008 --> 0.636299).  Saving model ...
	 Train_Loss: 0.6357 Train_Acc: 64.248 Val_Loss: 0.6363  BEST VAL Loss: 0.6363  Val_Acc: 64.819

Epoch 36: Validation loss decreased (0.636299 --> 0.635619).  Saving model ...
	 Train_Loss: 0.6349 Train_Acc: 64.288 Val_Loss: 0.6356  BEST VAL Loss: 0.6356  Val_Acc: 64.795

Epoch 37: Validation loss decreased (0.635619 --> 0.634939).  Saving model ...
	 Train_Loss: 0.6342 Train_Acc: 64.385 Val_Loss: 0.6349  BEST VAL Loss: 0.6349  Val_Acc: 64.652

Epoch 38: Validation loss decreased (0.634939 --> 0.634304).  Saving model ...
	 Train_Loss: 0.6334 Train_Acc: 64.438 Val_Loss: 0.6343  BEST VAL Loss: 0.6343  Val_Acc: 64.919

Epoch 39: Validation loss decreased (0.634304 --> 0.633692).  Saving model ...
	 Train_Loss: 0.6327 Train_Acc: 64.343 Val_Loss: 0.6337  BEST VAL Loss: 0.6337  Val_Acc: 64.910

Epoch 40: Validation loss decreased (0.633692 --> 0.633081).  Saving model ...
	 Train_Loss: 0.6320 Train_Acc: 64.428 Val_Loss: 0.6331  BEST VAL Loss: 0.6331  Val_Acc: 64.933

Epoch 41: Validation loss decreased (0.633081 --> 0.632486).  Saving model ...
	 Train_Loss: 0.6313 Train_Acc: 64.484 Val_Loss: 0.6325  BEST VAL Loss: 0.6325  Val_Acc: 64.952

Epoch 42: Validation loss decreased (0.632486 --> 0.631960).  Saving model ...
	 Train_Loss: 0.6306 Train_Acc: 64.667 Val_Loss: 0.6320  BEST VAL Loss: 0.6320  Val_Acc: 64.700

Epoch 43: Validation loss decreased (0.631960 --> 0.631417).  Saving model ...
	 Train_Loss: 0.6300 Train_Acc: 64.554 Val_Loss: 0.6314  BEST VAL Loss: 0.6314  Val_Acc: 65.090

Epoch 44: Validation loss decreased (0.631417 --> 0.630858).  Saving model ...
	 Train_Loss: 0.6293 Train_Acc: 64.652 Val_Loss: 0.6309  BEST VAL Loss: 0.6309  Val_Acc: 65.024

Epoch 45: Validation loss decreased (0.630858 --> 0.630327).  Saving model ...
	 Train_Loss: 0.6287 Train_Acc: 64.671 Val_Loss: 0.6303  BEST VAL Loss: 0.6303  Val_Acc: 65.229

Epoch 46: Validation loss decreased (0.630327 --> 0.629806).  Saving model ...
	 Train_Loss: 0.6281 Train_Acc: 64.712 Val_Loss: 0.6298  BEST VAL Loss: 0.6298  Val_Acc: 65.076

Epoch 47: Validation loss decreased (0.629806 --> 0.629331).  Saving model ...
	 Train_Loss: 0.6275 Train_Acc: 64.799 Val_Loss: 0.6293  BEST VAL Loss: 0.6293  Val_Acc: 65.300

Epoch 48: Validation loss decreased (0.629331 --> 0.628877).  Saving model ...
	 Train_Loss: 0.6269 Train_Acc: 64.766 Val_Loss: 0.6289  BEST VAL Loss: 0.6289  Val_Acc: 65.124

Epoch 49: Validation loss decreased (0.628877 --> 0.628424).  Saving model ...
	 Train_Loss: 0.6263 Train_Acc: 64.835 Val_Loss: 0.6284  BEST VAL Loss: 0.6284  Val_Acc: 65.048

Epoch 50: Validation loss decreased (0.628424 --> 0.628008).  Saving model ...
	 Train_Loss: 0.6257 Train_Acc: 64.848 Val_Loss: 0.6280  BEST VAL Loss: 0.6280  Val_Acc: 64.919

Epoch 51: Validation loss decreased (0.628008 --> 0.627580).  Saving model ...
	 Train_Loss: 0.6251 Train_Acc: 64.854 Val_Loss: 0.6276  BEST VAL Loss: 0.6276  Val_Acc: 65.138

Epoch 52: Validation loss decreased (0.627580 --> 0.627172).  Saving model ...
	 Train_Loss: 0.6245 Train_Acc: 64.852 Val_Loss: 0.6272  BEST VAL Loss: 0.6272  Val_Acc: 65.262

Epoch 53: Validation loss decreased (0.627172 --> 0.626719).  Saving model ...
	 Train_Loss: 0.6240 Train_Acc: 64.962 Val_Loss: 0.6267  BEST VAL Loss: 0.6267  Val_Acc: 65.357

Epoch 54: Validation loss decreased (0.626719 --> 0.626329).  Saving model ...
	 Train_Loss: 0.6235 Train_Acc: 64.915 Val_Loss: 0.6263  BEST VAL Loss: 0.6263  Val_Acc: 65.014

Epoch 55: Validation loss decreased (0.626329 --> 0.625923).  Saving model ...
	 Train_Loss: 0.6229 Train_Acc: 64.956 Val_Loss: 0.6259  BEST VAL Loss: 0.6259  Val_Acc: 65.348

Epoch 56: Validation loss decreased (0.625923 --> 0.625520).  Saving model ...
	 Train_Loss: 0.6224 Train_Acc: 64.891 Val_Loss: 0.6255  BEST VAL Loss: 0.6255  Val_Acc: 65.305

Epoch 57: Validation loss decreased (0.625520 --> 0.625122).  Saving model ...
	 Train_Loss: 0.6219 Train_Acc: 64.869 Val_Loss: 0.6251  BEST VAL Loss: 0.6251  Val_Acc: 64.995

Epoch 58: Validation loss decreased (0.625122 --> 0.624738).  Saving model ...
	 Train_Loss: 0.6214 Train_Acc: 65.029 Val_Loss: 0.6247  BEST VAL Loss: 0.6247  Val_Acc: 65.176

Epoch 59: Validation loss decreased (0.624738 --> 0.624343).  Saving model ...
	 Train_Loss: 0.6209 Train_Acc: 64.921 Val_Loss: 0.6243  BEST VAL Loss: 0.6243  Val_Acc: 65.467

Epoch 60: Validation loss decreased (0.624343 --> 0.623976).  Saving model ...
	 Train_Loss: 0.6205 Train_Acc: 65.012 Val_Loss: 0.6240  BEST VAL Loss: 0.6240  Val_Acc: 64.990

Epoch 61: Validation loss decreased (0.623976 --> 0.623591).  Saving model ...
	 Train_Loss: 0.6200 Train_Acc: 65.024 Val_Loss: 0.6236  BEST VAL Loss: 0.6236  Val_Acc: 65.038

Epoch 62: Validation loss decreased (0.623591 --> 0.623216).  Saving model ...
	 Train_Loss: 0.6195 Train_Acc: 65.047 Val_Loss: 0.6232  BEST VAL Loss: 0.6232  Val_Acc: 65.438

Epoch 63: Validation loss decreased (0.623216 --> 0.622843).  Saving model ...
	 Train_Loss: 0.6191 Train_Acc: 65.229 Val_Loss: 0.6228  BEST VAL Loss: 0.6228  Val_Acc: 66.224

Epoch 64: Validation loss decreased (0.622843 --> 0.622481).  Saving model ...
	 Train_Loss: 0.6186 Train_Acc: 65.310 Val_Loss: 0.6225  BEST VAL Loss: 0.6225  Val_Acc: 66.390

Epoch 65: Validation loss decreased (0.622481 --> 0.622131).  Saving model ...
	 Train_Loss: 0.6182 Train_Acc: 65.193 Val_Loss: 0.6221  BEST VAL Loss: 0.6221  Val_Acc: 66.524

Epoch 66: Validation loss decreased (0.622131 --> 0.621769).  Saving model ...
	 Train_Loss: 0.6177 Train_Acc: 65.297 Val_Loss: 0.6218  BEST VAL Loss: 0.6218  Val_Acc: 66.462

Epoch 67: Validation loss decreased (0.621769 --> 0.621389).  Saving model ...
	 Train_Loss: 0.6173 Train_Acc: 65.466 Val_Loss: 0.6214  BEST VAL Loss: 0.6214  Val_Acc: 66.352

Epoch 68: Validation loss decreased (0.621389 --> 0.621059).  Saving model ...
	 Train_Loss: 0.6169 Train_Acc: 65.403 Val_Loss: 0.6211  BEST VAL Loss: 0.6211  Val_Acc: 66.390

Epoch 69: Validation loss decreased (0.621059 --> 0.620749).  Saving model ...
	 Train_Loss: 0.6165 Train_Acc: 65.484 Val_Loss: 0.6207  BEST VAL Loss: 0.6207  Val_Acc: 66.424

Epoch 70: Validation loss decreased (0.620749 --> 0.620449).  Saving model ...
	 Train_Loss: 0.6161 Train_Acc: 65.407 Val_Loss: 0.6204  BEST VAL Loss: 0.6204  Val_Acc: 66.467

Epoch 71: Validation loss decreased (0.620449 --> 0.620142).  Saving model ...
	 Train_Loss: 0.6157 Train_Acc: 65.410 Val_Loss: 0.6201  BEST VAL Loss: 0.6201  Val_Acc: 66.719

Epoch 72: Validation loss decreased (0.620142 --> 0.619856).  Saving model ...
	 Train_Loss: 0.6153 Train_Acc: 65.528 Val_Loss: 0.6199  BEST VAL Loss: 0.6199  Val_Acc: 66.933

Epoch 73: Validation loss decreased (0.619856 --> 0.619570).  Saving model ...
	 Train_Loss: 0.6149 Train_Acc: 65.489 Val_Loss: 0.6196  BEST VAL Loss: 0.6196  Val_Acc: 66.767

Epoch 74: Validation loss decreased (0.619570 --> 0.619318).  Saving model ...
	 Train_Loss: 0.6146 Train_Acc: 65.472 Val_Loss: 0.6193  BEST VAL Loss: 0.6193  Val_Acc: 66.667

Epoch 75: Validation loss decreased (0.619318 --> 0.619051).  Saving model ...
	 Train_Loss: 0.6142 Train_Acc: 65.681 Val_Loss: 0.6191  BEST VAL Loss: 0.6191  Val_Acc: 66.881

Epoch 76: Validation loss decreased (0.619051 --> 0.618770).  Saving model ...
	 Train_Loss: 0.6138 Train_Acc: 65.748 Val_Loss: 0.6188  BEST VAL Loss: 0.6188  Val_Acc: 66.638

Epoch 77: Validation loss decreased (0.618770 --> 0.618499).  Saving model ...
	 Train_Loss: 0.6135 Train_Acc: 65.609 Val_Loss: 0.6185  BEST VAL Loss: 0.6185  Val_Acc: 67.033

Epoch 78: Validation loss decreased (0.618499 --> 0.618210).  Saving model ...
	 Train_Loss: 0.6131 Train_Acc: 65.645 Val_Loss: 0.6182  BEST VAL Loss: 0.6182  Val_Acc: 67.105

Epoch 79: Validation loss decreased (0.618210 --> 0.617935).  Saving model ...
	 Train_Loss: 0.6128 Train_Acc: 65.793 Val_Loss: 0.6179  BEST VAL Loss: 0.6179  Val_Acc: 67.062

Epoch 80: Validation loss decreased (0.617935 --> 0.617677).  Saving model ...
	 Train_Loss: 0.6124 Train_Acc: 65.647 Val_Loss: 0.6177  BEST VAL Loss: 0.6177  Val_Acc: 66.995

Epoch 81: Validation loss decreased (0.617677 --> 0.617425).  Saving model ...
	 Train_Loss: 0.6121 Train_Acc: 65.746 Val_Loss: 0.6174  BEST VAL Loss: 0.6174  Val_Acc: 67.300

Epoch 82: Validation loss decreased (0.617425 --> 0.617151).  Saving model ...
	 Train_Loss: 0.6117 Train_Acc: 66.020 Val_Loss: 0.6172  BEST VAL Loss: 0.6172  Val_Acc: 67.014

Epoch 83: Validation loss decreased (0.617151 --> 0.616908).  Saving model ...
	 Train_Loss: 0.6114 Train_Acc: 65.856 Val_Loss: 0.6169  BEST VAL Loss: 0.6169  Val_Acc: 67.024

Epoch 84: Validation loss decreased (0.616908 --> 0.616662).  Saving model ...
	 Train_Loss: 0.6111 Train_Acc: 65.838 Val_Loss: 0.6167  BEST VAL Loss: 0.6167  Val_Acc: 66.871

Epoch 85: Validation loss decreased (0.616662 --> 0.616402).  Saving model ...
	 Train_Loss: 0.6108 Train_Acc: 65.953 Val_Loss: 0.6164  BEST VAL Loss: 0.6164  Val_Acc: 67.057

Epoch 86: Validation loss decreased (0.616402 --> 0.616150).  Saving model ...
	 Train_Loss: 0.6104 Train_Acc: 65.983 Val_Loss: 0.6162  BEST VAL Loss: 0.6162  Val_Acc: 67.386

Epoch 87: Validation loss decreased (0.616150 --> 0.615924).  Saving model ...
	 Train_Loss: 0.6101 Train_Acc: 65.903 Val_Loss: 0.6159  BEST VAL Loss: 0.6159  Val_Acc: 67.200

Epoch 88: Validation loss decreased (0.615924 --> 0.615693).  Saving model ...
	 Train_Loss: 0.6098 Train_Acc: 66.050 Val_Loss: 0.6157  BEST VAL Loss: 0.6157  Val_Acc: 67.229

Epoch 89: Validation loss decreased (0.615693 --> 0.615484).  Saving model ...
	 Train_Loss: 0.6095 Train_Acc: 65.912 Val_Loss: 0.6155  BEST VAL Loss: 0.6155  Val_Acc: 67.362

Epoch 90: Validation loss decreased (0.615484 --> 0.615269).  Saving model ...
	 Train_Loss: 0.6092 Train_Acc: 65.902 Val_Loss: 0.6153  BEST VAL Loss: 0.6153  Val_Acc: 67.429

Epoch 91: Validation loss decreased (0.615269 --> 0.615058).  Saving model ...
	 Train_Loss: 0.6089 Train_Acc: 66.139 Val_Loss: 0.6151  BEST VAL Loss: 0.6151  Val_Acc: 67.376

Epoch 92: Validation loss decreased (0.615058 --> 0.614845).  Saving model ...
	 Train_Loss: 0.6086 Train_Acc: 66.073 Val_Loss: 0.6148  BEST VAL Loss: 0.6148  Val_Acc: 67.467

Epoch 93: Validation loss decreased (0.614845 --> 0.614649).  Saving model ...
	 Train_Loss: 0.6084 Train_Acc: 65.956 Val_Loss: 0.6146  BEST VAL Loss: 0.6146  Val_Acc: 67.224

Epoch 94: Validation loss decreased (0.614649 --> 0.614439).  Saving model ...
	 Train_Loss: 0.6081 Train_Acc: 65.938 Val_Loss: 0.6144  BEST VAL Loss: 0.6144  Val_Acc: 67.229

Epoch 95: Validation loss decreased (0.614439 --> 0.614237).  Saving model ...
	 Train_Loss: 0.6078 Train_Acc: 66.020 Val_Loss: 0.6142  BEST VAL Loss: 0.6142  Val_Acc: 67.305

Epoch 96: Validation loss decreased (0.614237 --> 0.614037).  Saving model ...
	 Train_Loss: 0.6075 Train_Acc: 66.166 Val_Loss: 0.6140  BEST VAL Loss: 0.6140  Val_Acc: 67.500

Epoch 97: Validation loss decreased (0.614037 --> 0.613839).  Saving model ...
	 Train_Loss: 0.6072 Train_Acc: 66.146 Val_Loss: 0.6138  BEST VAL Loss: 0.6138  Val_Acc: 67.395

Epoch 98: Validation loss decreased (0.613839 --> 0.613640).  Saving model ...
	 Train_Loss: 0.6070 Train_Acc: 66.063 Val_Loss: 0.6136  BEST VAL Loss: 0.6136  Val_Acc: 67.200

Epoch 99: Validation loss decreased (0.613640 --> 0.613425).  Saving model ...
	 Train_Loss: 0.6067 Train_Acc: 66.202 Val_Loss: 0.6134  BEST VAL Loss: 0.6134  Val_Acc: 67.376

LPS_0.010_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.72      0.66      0.69     85025
           1       0.68      0.74      0.71     82968

    accuracy                           0.70    167993
   macro avg       0.70      0.70      0.70    167993
weighted avg       0.70      0.70      0.70    167993

LPS_0.010_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.70      0.63      0.66     10629
           1       0.65      0.72      0.69     10371

    accuracy                           0.67     21000
   macro avg       0.68      0.67      0.67     21000
weighted avg       0.68      0.67      0.67     21000

LPS_0.010_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.70      0.64      0.67     10629
           1       0.66      0.72      0.69     10371

    accuracy                           0.68     21000
   macro avg       0.68      0.68      0.68     21000
weighted avg       0.68      0.68      0.68     21000

              precision    recall  f1-score   support

           0       0.70      0.64      0.67     10629
           1       0.66      0.72      0.69     10371

    accuracy                           0.68     21000
   macro avg       0.68      0.68      0.68     21000
weighted avg       0.68      0.68      0.68     21000

LPS_0.010_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.58      0.31      0.40     36797
           1       0.51      0.76      0.61     34887

    accuracy                           0.53     71684
   macro avg       0.54      0.53      0.51     71684
weighted avg       0.54      0.53      0.50     71684

              precision    recall  f1-score   support

           0       0.58      0.31      0.40     36797
           1       0.51      0.76      0.61     34887

    accuracy                           0.53     71684
   macro avg       0.54      0.53      0.51     71684
weighted avg       0.54      0.53      0.50     71684

completed
