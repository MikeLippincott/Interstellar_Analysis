[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '87fce789'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '368b95b9'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '714970f4'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e71e6ea5'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_0.100_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_0.100_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (32438, 1276)
Number of total missing values across all columns: 64876
Data Subset Is Off
Wells held out for testing: ['C21' 'L22']
Wells to use for training, validation, and testing ['C16' 'C17' 'C20' 'L18' 'L19' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.626376).  Saving model ...
	 Train_Loss: 0.6707 Train_Acc: 59.336 Val_Loss: 0.6264  BEST VAL Loss: 0.6264  Val_Acc: 67.437

Epoch 1: Validation loss decreased (0.626376 --> 0.619699).  Saving model ...
	 Train_Loss: 0.6528 Train_Acc: 64.432 Val_Loss: 0.6197  BEST VAL Loss: 0.6197  Val_Acc: 68.193

Epoch 2: Validation loss decreased (0.619699 --> 0.611113).  Saving model ...
	 Train_Loss: 0.6405 Train_Acc: 66.796 Val_Loss: 0.6111  BEST VAL Loss: 0.6111  Val_Acc: 68.782

Epoch 3: Validation loss decreased (0.611113 --> 0.605079).  Saving model ...
	 Train_Loss: 0.6308 Train_Acc: 67.033 Val_Loss: 0.6051  BEST VAL Loss: 0.6051  Val_Acc: 69.664

Epoch 4: Validation loss decreased (0.605079 --> 0.600764).  Saving model ...
	 Train_Loss: 0.6256 Train_Acc: 67.169 Val_Loss: 0.6008  BEST VAL Loss: 0.6008  Val_Acc: 69.202

Epoch 5: Validation loss decreased (0.600764 --> 0.596755).  Saving model ...
	 Train_Loss: 0.6204 Train_Acc: 67.905 Val_Loss: 0.5968  BEST VAL Loss: 0.5968  Val_Acc: 71.134

Epoch 6: Validation loss decreased (0.596755 --> 0.592588).  Saving model ...
	 Train_Loss: 0.6136 Train_Acc: 68.998 Val_Loss: 0.5926  BEST VAL Loss: 0.5926  Val_Acc: 69.958

Epoch 7: Validation loss decreased (0.592588 --> 0.587709).  Saving model ...
	 Train_Loss: 0.6095 Train_Acc: 69.549 Val_Loss: 0.5877  BEST VAL Loss: 0.5877  Val_Acc: 70.756

Epoch 8: Validation loss decreased (0.587709 --> 0.583863).  Saving model ...
	 Train_Loss: 0.6054 Train_Acc: 69.392 Val_Loss: 0.5839  BEST VAL Loss: 0.5839  Val_Acc: 71.597

Epoch 9: Validation loss decreased (0.583863 --> 0.580502).  Saving model ...
	 Train_Loss: 0.6021 Train_Acc: 69.686 Val_Loss: 0.5805  BEST VAL Loss: 0.5805  Val_Acc: 70.840

Epoch 10: Validation loss decreased (0.580502 --> 0.576973).  Saving model ...
	 Train_Loss: 0.5988 Train_Acc: 70.195 Val_Loss: 0.5770  BEST VAL Loss: 0.5770  Val_Acc: 71.261

Epoch 11: Validation loss decreased (0.576973 --> 0.574929).  Saving model ...
	 Train_Loss: 0.5961 Train_Acc: 70.689 Val_Loss: 0.5749  BEST VAL Loss: 0.5749  Val_Acc: 71.807

Epoch 12: Validation loss decreased (0.574929 --> 0.572741).  Saving model ...
	 Train_Loss: 0.5927 Train_Acc: 70.815 Val_Loss: 0.5727  BEST VAL Loss: 0.5727  Val_Acc: 72.563

Epoch 13: Validation loss decreased (0.572741 --> 0.570879).  Saving model ...
	 Train_Loss: 0.5900 Train_Acc: 70.558 Val_Loss: 0.5709  BEST VAL Loss: 0.5709  Val_Acc: 72.521

Epoch 14: Validation loss decreased (0.570879 --> 0.568266).  Saving model ...
	 Train_Loss: 0.5876 Train_Acc: 70.962 Val_Loss: 0.5683  BEST VAL Loss: 0.5683  Val_Acc: 73.319

Epoch 15: Validation loss decreased (0.568266 --> 0.566545).  Saving model ...
	 Train_Loss: 0.5850 Train_Acc: 71.682 Val_Loss: 0.5665  BEST VAL Loss: 0.5665  Val_Acc: 72.269

Epoch 16: Validation loss decreased (0.566545 --> 0.564811).  Saving model ...
	 Train_Loss: 0.5833 Train_Acc: 71.120 Val_Loss: 0.5648  BEST VAL Loss: 0.5648  Val_Acc: 73.193

Epoch 17: Validation loss decreased (0.564811 --> 0.563417).  Saving model ...
	 Train_Loss: 0.5820 Train_Acc: 70.248 Val_Loss: 0.5634  BEST VAL Loss: 0.5634  Val_Acc: 72.185

Epoch 18: Validation loss decreased (0.563417 --> 0.560983).  Saving model ...
	 Train_Loss: 0.5798 Train_Acc: 71.425 Val_Loss: 0.5610  BEST VAL Loss: 0.5610  Val_Acc: 74.496

Epoch 19: Validation loss decreased (0.560983 --> 0.559027).  Saving model ...
	 Train_Loss: 0.5780 Train_Acc: 72.192 Val_Loss: 0.5590  BEST VAL Loss: 0.5590  Val_Acc: 73.613

Epoch 20: Validation loss decreased (0.559027 --> 0.557939).  Saving model ...
	 Train_Loss: 0.5760 Train_Acc: 72.082 Val_Loss: 0.5579  BEST VAL Loss: 0.5579  Val_Acc: 72.815

Epoch 21: Validation loss decreased (0.557939 --> 0.556089).  Saving model ...
	 Train_Loss: 0.5744 Train_Acc: 72.076 Val_Loss: 0.5561  BEST VAL Loss: 0.5561  Val_Acc: 73.613

Epoch 22: Validation loss decreased (0.556089 --> 0.554706).  Saving model ...
	 Train_Loss: 0.5725 Train_Acc: 72.181 Val_Loss: 0.5547  BEST VAL Loss: 0.5547  Val_Acc: 73.908

Epoch 23: Validation loss decreased (0.554706 --> 0.553317).  Saving model ...
	 Train_Loss: 0.5712 Train_Acc: 71.619 Val_Loss: 0.5533  BEST VAL Loss: 0.5533  Val_Acc: 73.697

Epoch 24: Validation loss decreased (0.553317 --> 0.552075).  Saving model ...
	 Train_Loss: 0.5697 Train_Acc: 72.124 Val_Loss: 0.5521  BEST VAL Loss: 0.5521  Val_Acc: 74.664

Epoch 25: Validation loss decreased (0.552075 --> 0.550771).  Saving model ...
	 Train_Loss: 0.5680 Train_Acc: 72.581 Val_Loss: 0.5508  BEST VAL Loss: 0.5508  Val_Acc: 73.613

Epoch 26: Validation loss decreased (0.550771 --> 0.549538).  Saving model ...
	 Train_Loss: 0.5669 Train_Acc: 72.202 Val_Loss: 0.5495  BEST VAL Loss: 0.5495  Val_Acc: 74.412

Epoch 27: Validation loss decreased (0.549538 --> 0.548816).  Saving model ...
	 Train_Loss: 0.5659 Train_Acc: 72.197 Val_Loss: 0.5488  BEST VAL Loss: 0.5488  Val_Acc: 73.992

Epoch 28: Validation loss decreased (0.548816 --> 0.547848).  Saving model ...
	 Train_Loss: 0.5646 Train_Acc: 72.318 Val_Loss: 0.5478  BEST VAL Loss: 0.5478  Val_Acc: 73.824

Epoch 29: Validation loss decreased (0.547848 --> 0.546860).  Saving model ...
	 Train_Loss: 0.5634 Train_Acc: 72.796 Val_Loss: 0.5469  BEST VAL Loss: 0.5469  Val_Acc: 74.286

Epoch 30: Validation loss decreased (0.546860 --> 0.545466).  Saving model ...
	 Train_Loss: 0.5619 Train_Acc: 72.980 Val_Loss: 0.5455  BEST VAL Loss: 0.5455  Val_Acc: 74.034

Epoch 31: Validation loss decreased (0.545466 --> 0.544396).  Saving model ...
	 Train_Loss: 0.5606 Train_Acc: 72.775 Val_Loss: 0.5444  BEST VAL Loss: 0.5444  Val_Acc: 74.160

Epoch 32: Validation loss decreased (0.544396 --> 0.543545).  Saving model ...
	 Train_Loss: 0.5593 Train_Acc: 73.248 Val_Loss: 0.5435  BEST VAL Loss: 0.5435  Val_Acc: 74.580

Epoch 33: Validation loss decreased (0.543545 --> 0.543103).  Saving model ...
	 Train_Loss: 0.5579 Train_Acc: 73.138 Val_Loss: 0.5431  BEST VAL Loss: 0.5431  Val_Acc: 74.034

Epoch 34: Validation loss decreased (0.543103 --> 0.542200).  Saving model ...
	 Train_Loss: 0.5570 Train_Acc: 72.628 Val_Loss: 0.5422  BEST VAL Loss: 0.5422  Val_Acc: 74.286

Epoch 35: Validation loss decreased (0.542200 --> 0.541511).  Saving model ...
	 Train_Loss: 0.5560 Train_Acc: 72.560 Val_Loss: 0.5415  BEST VAL Loss: 0.5415  Val_Acc: 74.286

Epoch 36: Validation loss decreased (0.541511 --> 0.540532).  Saving model ...
	 Train_Loss: 0.5550 Train_Acc: 73.127 Val_Loss: 0.5405  BEST VAL Loss: 0.5405  Val_Acc: 74.790

Epoch 37: Validation loss decreased (0.540532 --> 0.539761).  Saving model ...
	 Train_Loss: 0.5542 Train_Acc: 72.523 Val_Loss: 0.5398  BEST VAL Loss: 0.5398  Val_Acc: 74.034

Epoch 38: Validation loss decreased (0.539761 --> 0.538942).  Saving model ...
	 Train_Loss: 0.5533 Train_Acc: 73.069 Val_Loss: 0.5389  BEST VAL Loss: 0.5389  Val_Acc: 74.328

Epoch 39: Validation loss decreased (0.538942 --> 0.538392).  Saving model ...
	 Train_Loss: 0.5526 Train_Acc: 73.122 Val_Loss: 0.5384  BEST VAL Loss: 0.5384  Val_Acc: 74.034

Epoch 40: Validation loss decreased (0.538392 --> 0.537667).  Saving model ...
	 Train_Loss: 0.5517 Train_Acc: 73.237 Val_Loss: 0.5377  BEST VAL Loss: 0.5377  Val_Acc: 74.160

Epoch 41: Validation loss decreased (0.537667 --> 0.536972).  Saving model ...
	 Train_Loss: 0.5511 Train_Acc: 72.497 Val_Loss: 0.5370  BEST VAL Loss: 0.5370  Val_Acc: 74.538

Epoch 42: Validation loss decreased (0.536972 --> 0.536209).  Saving model ...
	 Train_Loss: 0.5500 Train_Acc: 73.532 Val_Loss: 0.5362  BEST VAL Loss: 0.5362  Val_Acc: 75.000

Epoch 43: Validation loss decreased (0.536209 --> 0.535768).  Saving model ...
	 Train_Loss: 0.5490 Train_Acc: 73.868 Val_Loss: 0.5358  BEST VAL Loss: 0.5358  Val_Acc: 75.168

Epoch 44: Validation loss decreased (0.535768 --> 0.535122).  Saving model ...
	 Train_Loss: 0.5480 Train_Acc: 73.495 Val_Loss: 0.5351  BEST VAL Loss: 0.5351  Val_Acc: 75.126

Epoch 45: Validation loss decreased (0.535122 --> 0.534430).  Saving model ...
	 Train_Loss: 0.5472 Train_Acc: 73.311 Val_Loss: 0.5344  BEST VAL Loss: 0.5344  Val_Acc: 74.832

Epoch 46: Validation loss decreased (0.534430 --> 0.533899).  Saving model ...
	 Train_Loss: 0.5463 Train_Acc: 73.742 Val_Loss: 0.5339  BEST VAL Loss: 0.5339  Val_Acc: 74.958

Epoch 47: Validation loss decreased (0.533899 --> 0.533444).  Saving model ...
	 Train_Loss: 0.5458 Train_Acc: 73.085 Val_Loss: 0.5334  BEST VAL Loss: 0.5334  Val_Acc: 74.832

Epoch 48: Validation loss decreased (0.533444 --> 0.532928).  Saving model ...
	 Train_Loss: 0.5454 Train_Acc: 73.074 Val_Loss: 0.5329  BEST VAL Loss: 0.5329  Val_Acc: 74.328

Epoch 49: Validation loss decreased (0.532928 --> 0.532293).  Saving model ...
	 Train_Loss: 0.5448 Train_Acc: 72.602 Val_Loss: 0.5323  BEST VAL Loss: 0.5323  Val_Acc: 74.202

Epoch 50: Validation loss decreased (0.532293 --> 0.531765).  Saving model ...
	 Train_Loss: 0.5441 Train_Acc: 73.216 Val_Loss: 0.5318  BEST VAL Loss: 0.5318  Val_Acc: 75.168

Epoch 51: Validation loss decreased (0.531765 --> 0.531198).  Saving model ...
	 Train_Loss: 0.5435 Train_Acc: 73.920 Val_Loss: 0.5312  BEST VAL Loss: 0.5312  Val_Acc: 75.084

Epoch 52: Validation loss decreased (0.531198 --> 0.530783).  Saving model ...
	 Train_Loss: 0.5428 Train_Acc: 73.311 Val_Loss: 0.5308  BEST VAL Loss: 0.5308  Val_Acc: 74.370

Epoch 53: Validation loss decreased (0.530783 --> 0.530269).  Saving model ...
	 Train_Loss: 0.5422 Train_Acc: 73.626 Val_Loss: 0.5303  BEST VAL Loss: 0.5303  Val_Acc: 75.126

Epoch 54: Validation loss decreased (0.530269 --> 0.529738).  Saving model ...
	 Train_Loss: 0.5416 Train_Acc: 73.390 Val_Loss: 0.5297  BEST VAL Loss: 0.5297  Val_Acc: 74.958

Epoch 55: Validation loss decreased (0.529738 --> 0.529580).  Saving model ...
	 Train_Loss: 0.5412 Train_Acc: 72.901 Val_Loss: 0.5296  BEST VAL Loss: 0.5296  Val_Acc: 73.529

Epoch 56: Validation loss decreased (0.529580 --> 0.529002).  Saving model ...
	 Train_Loss: 0.5406 Train_Acc: 73.227 Val_Loss: 0.5290  BEST VAL Loss: 0.5290  Val_Acc: 75.042

Epoch 57: Validation loss decreased (0.529002 --> 0.528409).  Saving model ...
	 Train_Loss: 0.5399 Train_Acc: 73.857 Val_Loss: 0.5284  BEST VAL Loss: 0.5284  Val_Acc: 74.916

Epoch 58: Validation loss decreased (0.528409 --> 0.527906).  Saving model ...
	 Train_Loss: 0.5395 Train_Acc: 74.041 Val_Loss: 0.5279  BEST VAL Loss: 0.5279  Val_Acc: 74.496

Epoch 59: Validation loss decreased (0.527906 --> 0.527419).  Saving model ...
	 Train_Loss: 0.5392 Train_Acc: 72.134 Val_Loss: 0.5274  BEST VAL Loss: 0.5274  Val_Acc: 75.126

Epoch 60: Validation loss decreased (0.527419 --> 0.527010).  Saving model ...
	 Train_Loss: 0.5389 Train_Acc: 72.833 Val_Loss: 0.5270  BEST VAL Loss: 0.5270  Val_Acc: 74.874

Epoch 61: Validation loss decreased (0.527010 --> 0.526593).  Saving model ...
	 Train_Loss: 0.5386 Train_Acc: 72.765 Val_Loss: 0.5266  BEST VAL Loss: 0.5266  Val_Acc: 75.630

Epoch 62: Validation loss decreased (0.526593 --> 0.526314).  Saving model ...
	 Train_Loss: 0.5382 Train_Acc: 73.432 Val_Loss: 0.5263  BEST VAL Loss: 0.5263  Val_Acc: 74.748

Epoch 63: Validation loss decreased (0.526314 --> 0.525913).  Saving model ...
	 Train_Loss: 0.5377 Train_Acc: 73.631 Val_Loss: 0.5259  BEST VAL Loss: 0.5259  Val_Acc: 75.252

Epoch 64: Validation loss decreased (0.525913 --> 0.525502).  Saving model ...
	 Train_Loss: 0.5373 Train_Acc: 74.057 Val_Loss: 0.5255  BEST VAL Loss: 0.5255  Val_Acc: 75.042

Epoch 65: Validation loss decreased (0.525502 --> 0.525116).  Saving model ...
	 Train_Loss: 0.5367 Train_Acc: 74.330 Val_Loss: 0.5251  BEST VAL Loss: 0.5251  Val_Acc: 75.042

Epoch 66: Validation loss decreased (0.525116 --> 0.524899).  Saving model ...
	 Train_Loss: 0.5361 Train_Acc: 73.852 Val_Loss: 0.5249  BEST VAL Loss: 0.5249  Val_Acc: 74.790

Epoch 67: Validation loss decreased (0.524899 --> 0.524591).  Saving model ...
	 Train_Loss: 0.5356 Train_Acc: 73.962 Val_Loss: 0.5246  BEST VAL Loss: 0.5246  Val_Acc: 76.008

Epoch 68: Validation loss decreased (0.524591 --> 0.524313).  Saving model ...
	 Train_Loss: 0.5350 Train_Acc: 74.257 Val_Loss: 0.5243  BEST VAL Loss: 0.5243  Val_Acc: 75.546

Epoch 69: Validation loss decreased (0.524313 --> 0.524040).  Saving model ...
	 Train_Loss: 0.5345 Train_Acc: 74.057 Val_Loss: 0.5240  BEST VAL Loss: 0.5240  Val_Acc: 75.672

Epoch 70: Validation loss decreased (0.524040 --> 0.523616).  Saving model ...
	 Train_Loss: 0.5339 Train_Acc: 74.146 Val_Loss: 0.5236  BEST VAL Loss: 0.5236  Val_Acc: 75.378

Epoch 71: Validation loss decreased (0.523616 --> 0.523260).  Saving model ...
	 Train_Loss: 0.5334 Train_Acc: 74.372 Val_Loss: 0.5233  BEST VAL Loss: 0.5233  Val_Acc: 75.504

Epoch 72: Validation loss decreased (0.523260 --> 0.522709).  Saving model ...
	 Train_Loss: 0.5327 Train_Acc: 74.504 Val_Loss: 0.5227  BEST VAL Loss: 0.5227  Val_Acc: 75.672

Epoch 73: Validation loss decreased (0.522709 --> 0.522478).  Saving model ...
	 Train_Loss: 0.5323 Train_Acc: 74.561 Val_Loss: 0.5225  BEST VAL Loss: 0.5225  Val_Acc: 74.118

Epoch 74: Validation loss decreased (0.522478 --> 0.522019).  Saving model ...
	 Train_Loss: 0.5318 Train_Acc: 73.589 Val_Loss: 0.5220  BEST VAL Loss: 0.5220  Val_Acc: 75.252

Epoch 75: Validation loss decreased (0.522019 --> 0.521767).  Saving model ...
	 Train_Loss: 0.5314 Train_Acc: 73.878 Val_Loss: 0.5218  BEST VAL Loss: 0.5218  Val_Acc: 74.706

Epoch 76: Validation loss decreased (0.521767 --> 0.521489).  Saving model ...
	 Train_Loss: 0.5309 Train_Acc: 74.241 Val_Loss: 0.5215  BEST VAL Loss: 0.5215  Val_Acc: 74.748

Epoch 77: Validation loss decreased (0.521489 --> 0.521147).  Saving model ...
	 Train_Loss: 0.5305 Train_Acc: 74.088 Val_Loss: 0.5211  BEST VAL Loss: 0.5211  Val_Acc: 75.336

Epoch 78: Validation loss decreased (0.521147 --> 0.520897).  Saving model ...
	 Train_Loss: 0.5301 Train_Acc: 74.414 Val_Loss: 0.5209  BEST VAL Loss: 0.5209  Val_Acc: 75.378

Epoch 79: Validation loss decreased (0.520897 --> 0.520746).  Saving model ...
	 Train_Loss: 0.5297 Train_Acc: 74.031 Val_Loss: 0.5207  BEST VAL Loss: 0.5207  Val_Acc: 74.412

Epoch 80: Validation loss decreased (0.520746 --> 0.520519).  Saving model ...
	 Train_Loss: 0.5293 Train_Acc: 73.694 Val_Loss: 0.5205  BEST VAL Loss: 0.5205  Val_Acc: 74.286

Epoch 81: Validation loss decreased (0.520519 --> 0.520129).  Saving model ...
	 Train_Loss: 0.5289 Train_Acc: 74.293 Val_Loss: 0.5201  BEST VAL Loss: 0.5201  Val_Acc: 75.546

Epoch 82: Validation loss decreased (0.520129 --> 0.519954).  Saving model ...
	 Train_Loss: 0.5286 Train_Acc: 74.651 Val_Loss: 0.5200  BEST VAL Loss: 0.5200  Val_Acc: 74.664

Epoch 83: Validation loss decreased (0.519954 --> 0.519803).  Saving model ...
	 Train_Loss: 0.5284 Train_Acc: 73.269 Val_Loss: 0.5198  BEST VAL Loss: 0.5198  Val_Acc: 74.286

Epoch 84: Validation loss decreased (0.519803 --> 0.519698).  Saving model ...
	 Train_Loss: 0.5282 Train_Acc: 73.442 Val_Loss: 0.5197  BEST VAL Loss: 0.5197  Val_Acc: 75.126

Epoch 85: Validation loss decreased (0.519698 --> 0.519472).  Saving model ...
	 Train_Loss: 0.5277 Train_Acc: 74.461 Val_Loss: 0.5195  BEST VAL Loss: 0.5195  Val_Acc: 75.294

Epoch 86: Validation loss decreased (0.519472 --> 0.519185).  Saving model ...
	 Train_Loss: 0.5273 Train_Acc: 74.115 Val_Loss: 0.5192  BEST VAL Loss: 0.5192  Val_Acc: 75.462

Epoch 87: Validation loss decreased (0.519185 --> 0.518974).  Saving model ...
	 Train_Loss: 0.5269 Train_Acc: 73.715 Val_Loss: 0.5190  BEST VAL Loss: 0.5190  Val_Acc: 75.336

Epoch 88: Validation loss decreased (0.518974 --> 0.518602).  Saving model ...
	 Train_Loss: 0.5267 Train_Acc: 73.905 Val_Loss: 0.5186  BEST VAL Loss: 0.5186  Val_Acc: 75.714

Epoch 89: Validation loss decreased (0.518602 --> 0.518218).  Saving model ...
	 Train_Loss: 0.5264 Train_Acc: 73.852 Val_Loss: 0.5182  BEST VAL Loss: 0.5182  Val_Acc: 75.756

Epoch 90: Validation loss decreased (0.518218 --> 0.518050).  Saving model ...
	 Train_Loss: 0.5262 Train_Acc: 73.652 Val_Loss: 0.5181  BEST VAL Loss: 0.5181  Val_Acc: 74.832

Epoch 91: Validation loss decreased (0.518050 --> 0.517831).  Saving model ...
	 Train_Loss: 0.5259 Train_Acc: 74.440 Val_Loss: 0.5178  BEST VAL Loss: 0.5178  Val_Acc: 75.168

Epoch 92: Validation loss decreased (0.517831 --> 0.517583).  Saving model ...
	 Train_Loss: 0.5257 Train_Acc: 73.589 Val_Loss: 0.5176  BEST VAL Loss: 0.5176  Val_Acc: 74.286

Epoch 93: Validation loss decreased (0.517583 --> 0.517380).  Saving model ...
	 Train_Loss: 0.5254 Train_Acc: 74.283 Val_Loss: 0.5174  BEST VAL Loss: 0.5174  Val_Acc: 74.664

Epoch 94: Validation loss decreased (0.517380 --> 0.517148).  Saving model ...
	 Train_Loss: 0.5250 Train_Acc: 73.863 Val_Loss: 0.5171  BEST VAL Loss: 0.5171  Val_Acc: 74.790

Epoch 95: Validation loss decreased (0.517148 --> 0.516945).  Saving model ...
	 Train_Loss: 0.5247 Train_Acc: 74.493 Val_Loss: 0.5169  BEST VAL Loss: 0.5169  Val_Acc: 75.672

Epoch 96: Validation loss decreased (0.516945 --> 0.516749).  Saving model ...
	 Train_Loss: 0.5242 Train_Acc: 74.472 Val_Loss: 0.5167  BEST VAL Loss: 0.5167  Val_Acc: 74.832

Epoch 97: Validation loss decreased (0.516749 --> 0.516551).  Saving model ...
	 Train_Loss: 0.5240 Train_Acc: 74.829 Val_Loss: 0.5166  BEST VAL Loss: 0.5166  Val_Acc: 74.664

Epoch 98: Validation loss decreased (0.516551 --> 0.516536).  Saving model ...
	 Train_Loss: 0.5239 Train_Acc: 72.665 Val_Loss: 0.5165  BEST VAL Loss: 0.5165  Val_Acc: 74.832

Epoch 99: Validation loss decreased (0.516536 --> 0.516360).  Saving model ...
	 Train_Loss: 0.5237 Train_Acc: 74.004 Val_Loss: 0.5164  BEST VAL Loss: 0.5164  Val_Acc: 74.202

LPS_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.45      0.34      0.39      8633
           1       0.55      0.66      0.60     10401

    accuracy                           0.51     19034
   macro avg       0.50      0.50      0.49     19034
weighted avg       0.50      0.51      0.50     19034

LPS_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.34      0.39      1080
           1       0.55      0.67      0.60      1300

    accuracy                           0.52      2380
   macro avg       0.50      0.50      0.50      2380
weighted avg       0.51      0.52      0.51      2380

LPS_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.34      0.39      1080
           1       0.55      0.67      0.60      1300

    accuracy                           0.52      2380
   macro avg       0.51      0.50      0.50      2380
weighted avg       0.51      0.52      0.51      2380

              precision    recall  f1-score   support

           0       0.46      0.34      0.39      1080
           1       0.55      0.67      0.60      1300

    accuracy                           0.52      2380
   macro avg       0.51      0.50      0.50      2380
weighted avg       0.51      0.52      0.51      2380

LPS_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.20      0.29      4135
           1       0.52      0.80      0.63      4509

    accuracy                           0.52      8644
   macro avg       0.50      0.50      0.46      8644
weighted avg       0.50      0.52      0.47      8644

              precision    recall  f1-score   support

           0       0.48      0.20      0.29      4135
           1       0.52      0.80      0.63      4509

    accuracy                           0.52      8644
   macro avg       0.50      0.50      0.46      8644
weighted avg       0.50      0.52      0.47      8644

completed
