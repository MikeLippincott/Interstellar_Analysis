[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '710d1ecf'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'a787076e'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'fa160308'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '7e9f41e6'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_0.100_DMSO_0.025 treatment_name: Thapsigargin_10.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_0.100_DMSO_0.025
TREATMENT_NAME: Thapsigargin_10.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'Thapsigargin_10.000_DMSO_0.025']
The dimensions of the data are: (305581, 1270)
Number of total missing values across all columns: 611162
Data Subset Is Off
Wells held out for testing: ['C08' 'L06']
Wells to use for training, validation, and testing ['C02' 'C03' 'C09' 'E06' 'E07' 'L07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.681110).  Saving model ...
	 Train_Loss: 0.6899 Train_Acc: 52.904 Val_Loss: 0.6811  BEST VAL Loss: 0.6811  Val_Acc: 54.066

Epoch 1: Validation loss decreased (0.681110 --> 0.651475).  Saving model ...
	 Train_Loss: 0.6786 Train_Acc: 56.809 Val_Loss: 0.6515  BEST VAL Loss: 0.6515  Val_Acc: 71.844

Epoch 2: Validation loss decreased (0.651475 --> 0.608990).  Saving model ...
	 Train_Loss: 0.6544 Train_Acc: 68.951 Val_Loss: 0.6090  BEST VAL Loss: 0.6090  Val_Acc: 77.048

Epoch 3: Validation loss decreased (0.608990 --> 0.581926).  Saving model ...
	 Train_Loss: 0.6298 Train_Acc: 73.302 Val_Loss: 0.5819  BEST VAL Loss: 0.5819  Val_Acc: 76.805

Epoch 4: Validation loss decreased (0.581926 --> 0.552320).  Saving model ...
	 Train_Loss: 0.6081 Train_Acc: 75.630 Val_Loss: 0.5523  BEST VAL Loss: 0.5523  Val_Acc: 82.275

Epoch 5: Validation loss decreased (0.552320 --> 0.526897).  Saving model ...
	 Train_Loss: 0.5889 Train_Acc: 77.518 Val_Loss: 0.5269  BEST VAL Loss: 0.5269  Val_Acc: 82.815

Epoch 6: Validation loss decreased (0.526897 --> 0.506189).  Saving model ...
	 Train_Loss: 0.5722 Train_Acc: 79.005 Val_Loss: 0.5062  BEST VAL Loss: 0.5062  Val_Acc: 83.803

Epoch 7: Validation loss decreased (0.506189 --> 0.487607).  Saving model ...
	 Train_Loss: 0.5576 Train_Acc: 79.982 Val_Loss: 0.4876  BEST VAL Loss: 0.4876  Val_Acc: 85.446

Epoch 8: Validation loss decreased (0.487607 --> 0.473177).  Saving model ...
	 Train_Loss: 0.5453 Train_Acc: 80.333 Val_Loss: 0.4732  BEST VAL Loss: 0.4732  Val_Acc: 85.473

Epoch 9: Validation loss decreased (0.473177 --> 0.460322).  Saving model ...
	 Train_Loss: 0.5341 Train_Acc: 81.181 Val_Loss: 0.4603  BEST VAL Loss: 0.4603  Val_Acc: 85.614

Epoch 10: Validation loss decreased (0.460322 --> 0.449372).  Saving model ...
	 Train_Loss: 0.5243 Train_Acc: 81.641 Val_Loss: 0.4494  BEST VAL Loss: 0.4494  Val_Acc: 86.088

Epoch 11: Validation loss decreased (0.449372 --> 0.439429).  Saving model ...
	 Train_Loss: 0.5153 Train_Acc: 82.224 Val_Loss: 0.4394  BEST VAL Loss: 0.4394  Val_Acc: 86.819

Epoch 12: Validation loss decreased (0.439429 --> 0.430347).  Saving model ...
	 Train_Loss: 0.5071 Train_Acc: 82.752 Val_Loss: 0.4303  BEST VAL Loss: 0.4303  Val_Acc: 86.792

Epoch 13: Validation loss decreased (0.430347 --> 0.422298).  Saving model ...
	 Train_Loss: 0.4997 Train_Acc: 83.120 Val_Loss: 0.4223  BEST VAL Loss: 0.4223  Val_Acc: 86.885

Epoch 14: Validation loss decreased (0.422298 --> 0.416090).  Saving model ...
	 Train_Loss: 0.4927 Train_Acc: 83.546 Val_Loss: 0.4161  BEST VAL Loss: 0.4161  Val_Acc: 86.717

Epoch 15: Validation loss decreased (0.416090 --> 0.410328).  Saving model ...
	 Train_Loss: 0.4863 Train_Acc: 83.684 Val_Loss: 0.4103  BEST VAL Loss: 0.4103  Val_Acc: 86.106

Epoch 16: Validation loss decreased (0.410328 --> 0.407761).  Saving model ...
	 Train_Loss: 0.4804 Train_Acc: 83.961 Val_Loss: 0.4078  BEST VAL Loss: 0.4078  Val_Acc: 84.153

Epoch 17: Validation loss decreased (0.407761 --> 0.402615).  Saving model ...
	 Train_Loss: 0.4750 Train_Acc: 84.140 Val_Loss: 0.4026  BEST VAL Loss: 0.4026  Val_Acc: 87.001

Epoch 18: Validation loss decreased (0.402615 --> 0.398047).  Saving model ...
	 Train_Loss: 0.4699 Train_Acc: 84.503 Val_Loss: 0.3980  BEST VAL Loss: 0.3980  Val_Acc: 87.169

Epoch 19: Validation loss decreased (0.398047 --> 0.394402).  Saving model ...
	 Train_Loss: 0.4652 Train_Acc: 84.442 Val_Loss: 0.3944  BEST VAL Loss: 0.3944  Val_Acc: 86.779

Epoch 20: Validation loss decreased (0.394402 --> 0.390195).  Saving model ...
	 Train_Loss: 0.4607 Train_Acc: 84.666 Val_Loss: 0.3902  BEST VAL Loss: 0.3902  Val_Acc: 87.001

Epoch 21: Validation loss decreased (0.390195 --> 0.386301).  Saving model ...
	 Train_Loss: 0.4566 Train_Acc: 84.696 Val_Loss: 0.3863  BEST VAL Loss: 0.3863  Val_Acc: 87.160

Epoch 22: Validation loss decreased (0.386301 --> 0.382343).  Saving model ...
	 Train_Loss: 0.4528 Train_Acc: 84.741 Val_Loss: 0.3823  BEST VAL Loss: 0.3823  Val_Acc: 87.705

Epoch 23: Validation loss decreased (0.382343 --> 0.378827).  Saving model ...
	 Train_Loss: 0.4492 Train_Acc: 84.876 Val_Loss: 0.3788  BEST VAL Loss: 0.3788  Val_Acc: 87.855

Epoch 24: Validation loss decreased (0.378827 --> 0.375616).  Saving model ...
	 Train_Loss: 0.4457 Train_Acc: 84.994 Val_Loss: 0.3756  BEST VAL Loss: 0.3756  Val_Acc: 87.514

Epoch 25: Validation loss decreased (0.375616 --> 0.372261).  Saving model ...
	 Train_Loss: 0.4424 Train_Acc: 85.316 Val_Loss: 0.3723  BEST VAL Loss: 0.3723  Val_Acc: 87.948

Epoch 26: Validation loss decreased (0.372261 --> 0.369238).  Saving model ...
	 Train_Loss: 0.4394 Train_Acc: 85.139 Val_Loss: 0.3692  BEST VAL Loss: 0.3692  Val_Acc: 87.767

Epoch 27: Validation loss decreased (0.369238 --> 0.366192).  Saving model ...
	 Train_Loss: 0.4363 Train_Acc: 85.403 Val_Loss: 0.3662  BEST VAL Loss: 0.3662  Val_Acc: 88.223

Epoch 28: Validation loss decreased (0.366192 --> 0.363432).  Saving model ...
	 Train_Loss: 0.4336 Train_Acc: 85.302 Val_Loss: 0.3634  BEST VAL Loss: 0.3634  Val_Acc: 88.179

Epoch 29: Validation loss decreased (0.363432 --> 0.360820).  Saving model ...
	 Train_Loss: 0.4309 Train_Acc: 85.527 Val_Loss: 0.3608  BEST VAL Loss: 0.3608  Val_Acc: 88.316

Epoch 30: Validation loss decreased (0.360820 --> 0.358365).  Saving model ...
	 Train_Loss: 0.4283 Train_Acc: 85.677 Val_Loss: 0.3584  BEST VAL Loss: 0.3584  Val_Acc: 87.878

Epoch 31: Validation loss decreased (0.358365 --> 0.356099).  Saving model ...
	 Train_Loss: 0.4258 Train_Acc: 85.685 Val_Loss: 0.3561  BEST VAL Loss: 0.3561  Val_Acc: 88.440

Epoch 32: Validation loss decreased (0.356099 --> 0.353806).  Saving model ...
	 Train_Loss: 0.4235 Train_Acc: 85.770 Val_Loss: 0.3538  BEST VAL Loss: 0.3538  Val_Acc: 88.170

Epoch 33: Validation loss decreased (0.353806 --> 0.351783).  Saving model ...
	 Train_Loss: 0.4212 Train_Acc: 85.865 Val_Loss: 0.3518  BEST VAL Loss: 0.3518  Val_Acc: 88.055

Epoch 34: Validation loss decreased (0.351783 --> 0.349818).  Saving model ...
	 Train_Loss: 0.4191 Train_Acc: 85.696 Val_Loss: 0.3498  BEST VAL Loss: 0.3498  Val_Acc: 88.033

Epoch 35: Validation loss decreased (0.349818 --> 0.347834).  Saving model ...
	 Train_Loss: 0.4170 Train_Acc: 85.833 Val_Loss: 0.3478  BEST VAL Loss: 0.3478  Val_Acc: 88.374

Epoch 36: Validation loss decreased (0.347834 --> 0.345887).  Saving model ...
	 Train_Loss: 0.4150 Train_Acc: 85.830 Val_Loss: 0.3459  BEST VAL Loss: 0.3459  Val_Acc: 88.391

Epoch 37: Validation loss decreased (0.345887 --> 0.344174).  Saving model ...
	 Train_Loss: 0.4132 Train_Acc: 85.862 Val_Loss: 0.3442  BEST VAL Loss: 0.3442  Val_Acc: 88.343

Epoch 38: Validation loss decreased (0.344174 --> 0.342563).  Saving model ...
	 Train_Loss: 0.4113 Train_Acc: 86.012 Val_Loss: 0.3426  BEST VAL Loss: 0.3426  Val_Acc: 88.267

Epoch 39: Validation loss decreased (0.342563 --> 0.340816).  Saving model ...
	 Train_Loss: 0.4095 Train_Acc: 86.086 Val_Loss: 0.3408  BEST VAL Loss: 0.3408  Val_Acc: 88.635

Epoch 40: Validation loss decreased (0.340816 --> 0.339276).  Saving model ...
	 Train_Loss: 0.4079 Train_Acc: 86.093 Val_Loss: 0.3393  BEST VAL Loss: 0.3393  Val_Acc: 88.582

Epoch 41: Validation loss decreased (0.339276 --> 0.337625).  Saving model ...
	 Train_Loss: 0.4062 Train_Acc: 86.220 Val_Loss: 0.3376  BEST VAL Loss: 0.3376  Val_Acc: 88.719

Epoch 42: Validation loss decreased (0.337625 --> 0.336155).  Saving model ...
	 Train_Loss: 0.4047 Train_Acc: 86.169 Val_Loss: 0.3362  BEST VAL Loss: 0.3362  Val_Acc: 88.577

Epoch 43: Validation loss decreased (0.336155 --> 0.334761).  Saving model ...
	 Train_Loss: 0.4032 Train_Acc: 86.130 Val_Loss: 0.3348  BEST VAL Loss: 0.3348  Val_Acc: 88.458

Epoch 44: Validation loss decreased (0.334761 --> 0.333337).  Saving model ...
	 Train_Loss: 0.4017 Train_Acc: 86.258 Val_Loss: 0.3333  BEST VAL Loss: 0.3333  Val_Acc: 88.697

Epoch 45: Validation loss decreased (0.333337 --> 0.331936).  Saving model ...
	 Train_Loss: 0.4002 Train_Acc: 86.386 Val_Loss: 0.3319  BEST VAL Loss: 0.3319  Val_Acc: 88.768

Epoch 46: Validation loss decreased (0.331936 --> 0.330690).  Saving model ...
	 Train_Loss: 0.3989 Train_Acc: 86.181 Val_Loss: 0.3307  BEST VAL Loss: 0.3307  Val_Acc: 88.320

Epoch 47: Validation loss decreased (0.330690 --> 0.329474).  Saving model ...
	 Train_Loss: 0.3975 Train_Acc: 86.216 Val_Loss: 0.3295  BEST VAL Loss: 0.3295  Val_Acc: 88.794

Epoch 48: Validation loss decreased (0.329474 --> 0.328205).  Saving model ...
	 Train_Loss: 0.3962 Train_Acc: 86.341 Val_Loss: 0.3282  BEST VAL Loss: 0.3282  Val_Acc: 88.936

Epoch 49: Validation loss decreased (0.328205 --> 0.327048).  Saving model ...
	 Train_Loss: 0.3950 Train_Acc: 86.450 Val_Loss: 0.3270  BEST VAL Loss: 0.3270  Val_Acc: 88.662

Epoch 50: Validation loss decreased (0.327048 --> 0.325800).  Saving model ...
	 Train_Loss: 0.3937 Train_Acc: 86.468 Val_Loss: 0.3258  BEST VAL Loss: 0.3258  Val_Acc: 89.038

Epoch 51: Validation loss decreased (0.325800 --> 0.324567).  Saving model ...
	 Train_Loss: 0.3925 Train_Acc: 86.424 Val_Loss: 0.3246  BEST VAL Loss: 0.3246  Val_Acc: 89.162

Epoch 52: Validation loss decreased (0.324567 --> 0.323494).  Saving model ...
	 Train_Loss: 0.3914 Train_Acc: 86.471 Val_Loss: 0.3235  BEST VAL Loss: 0.3235  Val_Acc: 88.972

Epoch 53: Validation loss decreased (0.323494 --> 0.322426).  Saving model ...
	 Train_Loss: 0.3902 Train_Acc: 86.579 Val_Loss: 0.3224  BEST VAL Loss: 0.3224  Val_Acc: 88.945

Epoch 54: Validation loss decreased (0.322426 --> 0.321420).  Saving model ...
	 Train_Loss: 0.3891 Train_Acc: 86.606 Val_Loss: 0.3214  BEST VAL Loss: 0.3214  Val_Acc: 88.887

Epoch 55: Validation loss decreased (0.321420 --> 0.320395).  Saving model ...
	 Train_Loss: 0.3880 Train_Acc: 86.520 Val_Loss: 0.3204  BEST VAL Loss: 0.3204  Val_Acc: 88.763

Epoch 56: Validation loss decreased (0.320395 --> 0.319421).  Saving model ...
	 Train_Loss: 0.3869 Train_Acc: 86.549 Val_Loss: 0.3194  BEST VAL Loss: 0.3194  Val_Acc: 88.980

Epoch 57: Validation loss decreased (0.319421 --> 0.318553).  Saving model ...
	 Train_Loss: 0.3859 Train_Acc: 86.514 Val_Loss: 0.3186  BEST VAL Loss: 0.3186  Val_Acc: 89.104

Epoch 58: Validation loss decreased (0.318553 --> 0.317585).  Saving model ...
	 Train_Loss: 0.3849 Train_Acc: 86.594 Val_Loss: 0.3176  BEST VAL Loss: 0.3176  Val_Acc: 88.985

Epoch 59: Validation loss decreased (0.317585 --> 0.316699).  Saving model ...
	 Train_Loss: 0.3840 Train_Acc: 86.585 Val_Loss: 0.3167  BEST VAL Loss: 0.3167  Val_Acc: 88.901

Epoch 60: Validation loss decreased (0.316699 --> 0.315978).  Saving model ...
	 Train_Loss: 0.3830 Train_Acc: 86.591 Val_Loss: 0.3160  BEST VAL Loss: 0.3160  Val_Acc: 88.542

Epoch 61: Validation loss decreased (0.315978 --> 0.315328).  Saving model ...
	 Train_Loss: 0.3821 Train_Acc: 86.728 Val_Loss: 0.3153  BEST VAL Loss: 0.3153  Val_Acc: 88.573

Epoch 62: Validation loss decreased (0.315328 --> 0.314534).  Saving model ...
	 Train_Loss: 0.3812 Train_Acc: 86.600 Val_Loss: 0.3145  BEST VAL Loss: 0.3145  Val_Acc: 88.998

Epoch 63: Validation loss decreased (0.314534 --> 0.313751).  Saving model ...
	 Train_Loss: 0.3804 Train_Acc: 86.570 Val_Loss: 0.3138  BEST VAL Loss: 0.3138  Val_Acc: 89.020

Epoch 64: Validation loss decreased (0.313751 --> 0.313098).  Saving model ...
	 Train_Loss: 0.3795 Train_Acc: 86.724 Val_Loss: 0.3131  BEST VAL Loss: 0.3131  Val_Acc: 88.746

Epoch 65: Validation loss decreased (0.313098 --> 0.312298).  Saving model ...
	 Train_Loss: 0.3787 Train_Acc: 86.593 Val_Loss: 0.3123  BEST VAL Loss: 0.3123  Val_Acc: 89.344

Epoch 66: Validation loss decreased (0.312298 --> 0.311559).  Saving model ...
	 Train_Loss: 0.3778 Train_Acc: 86.812 Val_Loss: 0.3116  BEST VAL Loss: 0.3116  Val_Acc: 89.051

Epoch 67: Validation loss decreased (0.311559 --> 0.310797).  Saving model ...
	 Train_Loss: 0.3770 Train_Acc: 86.789 Val_Loss: 0.3108  BEST VAL Loss: 0.3108  Val_Acc: 89.180

Epoch 68: Validation loss decreased (0.310797 --> 0.310141).  Saving model ...
	 Train_Loss: 0.3762 Train_Acc: 86.896 Val_Loss: 0.3101  BEST VAL Loss: 0.3101  Val_Acc: 89.100

Epoch 69: Validation loss decreased (0.310141 --> 0.309363).  Saving model ...
	 Train_Loss: 0.3755 Train_Acc: 86.804 Val_Loss: 0.3094  BEST VAL Loss: 0.3094  Val_Acc: 89.255

Epoch 70: Validation loss decreased (0.309363 --> 0.308730).  Saving model ...
	 Train_Loss: 0.3747 Train_Acc: 86.678 Val_Loss: 0.3087  BEST VAL Loss: 0.3087  Val_Acc: 88.892

Epoch 71: Validation loss decreased (0.308730 --> 0.308108).  Saving model ...
	 Train_Loss: 0.3740 Train_Acc: 86.774 Val_Loss: 0.3081  BEST VAL Loss: 0.3081  Val_Acc: 88.901

Epoch 72: Validation loss decreased (0.308108 --> 0.307456).  Saving model ...
	 Train_Loss: 0.3732 Train_Acc: 86.858 Val_Loss: 0.3075  BEST VAL Loss: 0.3075  Val_Acc: 89.286

Epoch 73: Validation loss decreased (0.307456 --> 0.306824).  Saving model ...
	 Train_Loss: 0.3725 Train_Acc: 86.953 Val_Loss: 0.3068  BEST VAL Loss: 0.3068  Val_Acc: 89.259

Epoch 74: Validation loss decreased (0.306824 --> 0.306231).  Saving model ...
	 Train_Loss: 0.3718 Train_Acc: 86.786 Val_Loss: 0.3062  BEST VAL Loss: 0.3062  Val_Acc: 89.011

Epoch 75: Validation loss decreased (0.306231 --> 0.305597).  Saving model ...
	 Train_Loss: 0.3711 Train_Acc: 87.042 Val_Loss: 0.3056  BEST VAL Loss: 0.3056  Val_Acc: 89.242

Epoch 76: Validation loss decreased (0.305597 --> 0.305057).  Saving model ...
	 Train_Loss: 0.3704 Train_Acc: 86.932 Val_Loss: 0.3051  BEST VAL Loss: 0.3051  Val_Acc: 89.034

Epoch 77: Validation loss decreased (0.305057 --> 0.304561).  Saving model ...
	 Train_Loss: 0.3697 Train_Acc: 87.106 Val_Loss: 0.3046  BEST VAL Loss: 0.3046  Val_Acc: 89.065

Epoch 78: Validation loss decreased (0.304561 --> 0.303971).  Saving model ...
	 Train_Loss: 0.3690 Train_Acc: 86.967 Val_Loss: 0.3040  BEST VAL Loss: 0.3040  Val_Acc: 89.206

Epoch 79: Validation loss decreased (0.303971 --> 0.303637).  Saving model ...
	 Train_Loss: 0.3684 Train_Acc: 86.983 Val_Loss: 0.3036  BEST VAL Loss: 0.3036  Val_Acc: 88.405

Epoch 80: Validation loss decreased (0.303637 --> 0.303109).  Saving model ...
	 Train_Loss: 0.3677 Train_Acc: 86.973 Val_Loss: 0.3031  BEST VAL Loss: 0.3031  Val_Acc: 89.175

Epoch 81: Validation loss decreased (0.303109 --> 0.302565).  Saving model ...
	 Train_Loss: 0.3671 Train_Acc: 87.090 Val_Loss: 0.3026  BEST VAL Loss: 0.3026  Val_Acc: 89.251

Epoch 82: Validation loss decreased (0.302565 --> 0.302030).  Saving model ...
	 Train_Loss: 0.3664 Train_Acc: 87.200 Val_Loss: 0.3020  BEST VAL Loss: 0.3020  Val_Acc: 89.202

Epoch 83: Validation loss decreased (0.302030 --> 0.301495).  Saving model ...
	 Train_Loss: 0.3658 Train_Acc: 87.085 Val_Loss: 0.3015  BEST VAL Loss: 0.3015  Val_Acc: 89.251

Epoch 84: Validation loss decreased (0.301495 --> 0.300977).  Saving model ...
	 Train_Loss: 0.3652 Train_Acc: 87.040 Val_Loss: 0.3010  BEST VAL Loss: 0.3010  Val_Acc: 89.193

Epoch 85: Validation loss decreased (0.300977 --> 0.300476).  Saving model ...
	 Train_Loss: 0.3647 Train_Acc: 87.011 Val_Loss: 0.3005  BEST VAL Loss: 0.3005  Val_Acc: 89.361

Epoch 86: Validation loss decreased (0.300476 --> 0.299998).  Saving model ...
	 Train_Loss: 0.3641 Train_Acc: 87.100 Val_Loss: 0.3000  BEST VAL Loss: 0.3000  Val_Acc: 89.233

Epoch 87: Validation loss decreased (0.299998 --> 0.299501).  Saving model ...
	 Train_Loss: 0.3635 Train_Acc: 86.968 Val_Loss: 0.2995  BEST VAL Loss: 0.2995  Val_Acc: 89.388

Epoch 88: Validation loss decreased (0.299501 --> 0.298976).  Saving model ...
	 Train_Loss: 0.3629 Train_Acc: 87.086 Val_Loss: 0.2990  BEST VAL Loss: 0.2990  Val_Acc: 89.441

Epoch 89: Validation loss decreased (0.298976 --> 0.298470).  Saving model ...
	 Train_Loss: 0.3624 Train_Acc: 87.141 Val_Loss: 0.2985  BEST VAL Loss: 0.2985  Val_Acc: 89.375

Epoch 90: Validation loss decreased (0.298470 --> 0.298019).  Saving model ...
	 Train_Loss: 0.3618 Train_Acc: 87.012 Val_Loss: 0.2980  BEST VAL Loss: 0.2980  Val_Acc: 89.166

Epoch 91: Validation loss decreased (0.298019 --> 0.297539).  Saving model ...
	 Train_Loss: 0.3613 Train_Acc: 87.091 Val_Loss: 0.2975  BEST VAL Loss: 0.2975  Val_Acc: 89.605

Epoch 92: Validation loss decreased (0.297539 --> 0.297143).  Saving model ...
	 Train_Loss: 0.3608 Train_Acc: 87.122 Val_Loss: 0.2971  BEST VAL Loss: 0.2971  Val_Acc: 89.251

Epoch 93: Validation loss decreased (0.297143 --> 0.296668).  Saving model ...
	 Train_Loss: 0.3602 Train_Acc: 87.228 Val_Loss: 0.2967  BEST VAL Loss: 0.2967  Val_Acc: 89.459

Epoch 94: Validation loss decreased (0.296668 --> 0.296310).  Saving model ...
	 Train_Loss: 0.3597 Train_Acc: 87.100 Val_Loss: 0.2963  BEST VAL Loss: 0.2963  Val_Acc: 89.459

Epoch 95: Validation loss decreased (0.296310 --> 0.295860).  Saving model ...
	 Train_Loss: 0.3592 Train_Acc: 87.082 Val_Loss: 0.2959  BEST VAL Loss: 0.2959  Val_Acc: 89.663

Epoch 96: Validation loss decreased (0.295860 --> 0.295465).  Saving model ...
	 Train_Loss: 0.3587 Train_Acc: 87.252 Val_Loss: 0.2955  BEST VAL Loss: 0.2955  Val_Acc: 89.321

Epoch 97: Validation loss decreased (0.295465 --> 0.295131).  Saving model ...
	 Train_Loss: 0.3582 Train_Acc: 87.230 Val_Loss: 0.2951  BEST VAL Loss: 0.2951  Val_Acc: 89.025

Epoch 98: Validation loss decreased (0.295131 --> 0.294753).  Saving model ...
	 Train_Loss: 0.3578 Train_Acc: 87.224 Val_Loss: 0.2948  BEST VAL Loss: 0.2948  Val_Acc: 89.361

Epoch 99: Validation loss decreased (0.294753 --> 0.294353).  Saving model ...
	 Train_Loss: 0.3573 Train_Acc: 87.186 Val_Loss: 0.2944  BEST VAL Loss: 0.2944  Val_Acc: 89.445

LPS_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.46      0.46     82968
           1       0.54      0.54      0.54     97655

    accuracy                           0.50    180623
   macro avg       0.50      0.50      0.50    180623
weighted avg       0.50      0.50      0.50    180623

LPS_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.46      0.46     10371
           1       0.54      0.54      0.54     12207

    accuracy                           0.50     22578
   macro avg       0.50      0.50      0.50     22578
weighted avg       0.50      0.50      0.50     22578

LPS_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.46      0.46     10371
           1       0.54      0.54      0.54     12207

    accuracy                           0.50     22578
   macro avg       0.50      0.50      0.50     22578
weighted avg       0.50      0.50      0.50     22578

              precision    recall  f1-score   support

           0       0.46      0.46      0.46     10371
           1       0.54      0.54      0.54     12207

    accuracy                           0.50     22578
   macro avg       0.50      0.50      0.50     22578
weighted avg       0.50      0.50      0.50     22578

LPS_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.44      0.44      0.44     34887
           1       0.56      0.56      0.56     44915

    accuracy                           0.51     79802
   macro avg       0.50      0.50      0.50     79802
weighted avg       0.51      0.51      0.51     79802

              precision    recall  f1-score   support

           0       0.44      0.44      0.44     34887
           1       0.56      0.56      0.56     44915

    accuracy                           0.51     79802
   macro avg       0.50      0.50      0.50     79802
weighted avg       0.51      0.51      0.51     79802

completed
