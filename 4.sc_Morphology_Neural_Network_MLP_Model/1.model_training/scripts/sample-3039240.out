[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '2e072022'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '53d6422e'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'f2067d6d'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '8d022299'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: Thapsigargin_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: Thapsigargin_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (322717, 1270)
Number of total missing values across all columns: 296912
Data Subset Is Off
Wells held out for testing: ['K06' 'L09']
Wells to use for training, validation, and testing ['D06' 'D07' 'K07' 'L02' 'L03' 'L08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.170389).  Saving model ...
	 Train_Loss: 0.2759 Train_Acc: 87.633 Val_Loss: 0.1704  BEST VAL Loss: 0.1704  Val_Acc: 93.084

Epoch 1: Validation loss decreased (0.170389 --> 0.161304).  Saving model ...
	 Train_Loss: 0.2342 Train_Acc: 92.596 Val_Loss: 0.1613  BEST VAL Loss: 0.1613  Val_Acc: 93.748

Epoch 2: Validation loss decreased (0.161304 --> 0.155243).  Saving model ...
	 Train_Loss: 0.2160 Train_Acc: 93.243 Val_Loss: 0.1552  BEST VAL Loss: 0.1552  Val_Acc: 94.405

Epoch 3: Validation loss decreased (0.155243 --> 0.150779).  Saving model ...
	 Train_Loss: 0.2043 Train_Acc: 93.575 Val_Loss: 0.1508  BEST VAL Loss: 0.1508  Val_Acc: 94.580

Epoch 4: Validation loss decreased (0.150779 --> 0.147011).  Saving model ...
	 Train_Loss: 0.1965 Train_Acc: 93.753 Val_Loss: 0.1470  BEST VAL Loss: 0.1470  Val_Acc: 95.013

Epoch 5: Validation loss decreased (0.147011 --> 0.144028).  Saving model ...
	 Train_Loss: 0.1906 Train_Acc: 93.898 Val_Loss: 0.1440  BEST VAL Loss: 0.1440  Val_Acc: 94.993

Epoch 6: Validation loss decreased (0.144028 --> 0.141147).  Saving model ...
	 Train_Loss: 0.1857 Train_Acc: 94.047 Val_Loss: 0.1411  BEST VAL Loss: 0.1411  Val_Acc: 95.184

Epoch 7: Validation loss decreased (0.141147 --> 0.139505).  Saving model ...
	 Train_Loss: 0.1818 Train_Acc: 94.132 Val_Loss: 0.1395  BEST VAL Loss: 0.1395  Val_Acc: 95.078

Epoch 8: Validation loss decreased (0.139505 --> 0.137481).  Saving model ...
	 Train_Loss: 0.1785 Train_Acc: 94.223 Val_Loss: 0.1375  BEST VAL Loss: 0.1375  Val_Acc: 95.342

Epoch 9: Validation loss decreased (0.137481 --> 0.136006).  Saving model ...
	 Train_Loss: 0.1759 Train_Acc: 94.170 Val_Loss: 0.1360  BEST VAL Loss: 0.1360  Val_Acc: 95.171

Epoch 10: Validation loss decreased (0.136006 --> 0.134629).  Saving model ...
	 Train_Loss: 0.1735 Train_Acc: 94.318 Val_Loss: 0.1346  BEST VAL Loss: 0.1346  Val_Acc: 95.358

Epoch 11: Validation loss decreased (0.134629 --> 0.133794).  Saving model ...
	 Train_Loss: 0.1714 Train_Acc: 94.362 Val_Loss: 0.1338  BEST VAL Loss: 0.1338  Val_Acc: 95.086

Epoch 12: Validation loss decreased (0.133794 --> 0.132500).  Saving model ...
	 Train_Loss: 0.1695 Train_Acc: 94.418 Val_Loss: 0.1325  BEST VAL Loss: 0.1325  Val_Acc: 95.435

Epoch 13: Validation loss decreased (0.132500 --> 0.131899).  Saving model ...
	 Train_Loss: 0.1676 Train_Acc: 94.480 Val_Loss: 0.1319  BEST VAL Loss: 0.1319  Val_Acc: 95.338

Epoch 14: Validation loss decreased (0.131899 --> 0.130978).  Saving model ...
	 Train_Loss: 0.1662 Train_Acc: 94.398 Val_Loss: 0.1310  BEST VAL Loss: 0.1310  Val_Acc: 95.301

Epoch 15: Validation loss decreased (0.130978 --> 0.130174).  Saving model ...
	 Train_Loss: 0.1648 Train_Acc: 94.523 Val_Loss: 0.1302  BEST VAL Loss: 0.1302  Val_Acc: 95.334

Epoch 16: Validation loss decreased (0.130174 --> 0.129394).  Saving model ...
	 Train_Loss: 0.1635 Train_Acc: 94.509 Val_Loss: 0.1294  BEST VAL Loss: 0.1294  Val_Acc: 95.516

Epoch 17: Validation loss decreased (0.129394 --> 0.128786).  Saving model ...
	 Train_Loss: 0.1623 Train_Acc: 94.681 Val_Loss: 0.1288  BEST VAL Loss: 0.1288  Val_Acc: 95.459

Epoch 18: Validation loss decreased (0.128786 --> 0.128423).  Saving model ...
	 Train_Loss: 0.1611 Train_Acc: 94.671 Val_Loss: 0.1284  BEST VAL Loss: 0.1284  Val_Acc: 95.196

Epoch 19: Validation loss decreased (0.128423 --> 0.127866).  Saving model ...
	 Train_Loss: 0.1600 Train_Acc: 94.671 Val_Loss: 0.1279  BEST VAL Loss: 0.1279  Val_Acc: 95.492

Epoch 20: Validation loss decreased (0.127866 --> 0.127395).  Saving model ...
	 Train_Loss: 0.1590 Train_Acc: 94.718 Val_Loss: 0.1274  BEST VAL Loss: 0.1274  Val_Acc: 95.439

Epoch 21: Validation loss decreased (0.127395 --> 0.126897).  Saving model ...
	 Train_Loss: 0.1580 Train_Acc: 94.816 Val_Loss: 0.1269  BEST VAL Loss: 0.1269  Val_Acc: 95.678

Epoch 22: Validation loss decreased (0.126897 --> 0.126444).  Saving model ...
	 Train_Loss: 0.1572 Train_Acc: 94.766 Val_Loss: 0.1264  BEST VAL Loss: 0.1264  Val_Acc: 95.589

Epoch 23: Validation loss decreased (0.126444 --> 0.125933).  Saving model ...
	 Train_Loss: 0.1562 Train_Acc: 94.828 Val_Loss: 0.1259  BEST VAL Loss: 0.1259  Val_Acc: 95.646

Epoch 24: Validation loss decreased (0.125933 --> 0.125428).  Saving model ...
	 Train_Loss: 0.1554 Train_Acc: 94.867 Val_Loss: 0.1254  BEST VAL Loss: 0.1254  Val_Acc: 95.528

Epoch 25: Validation loss decreased (0.125428 --> 0.125102).  Saving model ...
	 Train_Loss: 0.1546 Train_Acc: 94.757 Val_Loss: 0.1251  BEST VAL Loss: 0.1251  Val_Acc: 95.492

Epoch 26: Validation loss decreased (0.125102 --> 0.124598).  Saving model ...
	 Train_Loss: 0.1538 Train_Acc: 94.821 Val_Loss: 0.1246  BEST VAL Loss: 0.1246  Val_Acc: 95.686

Epoch 27: Validation loss decreased (0.124598 --> 0.124135).  Saving model ...
	 Train_Loss: 0.1531 Train_Acc: 94.943 Val_Loss: 0.1241  BEST VAL Loss: 0.1241  Val_Acc: 95.800

Epoch 28: Validation loss decreased (0.124135 --> 0.123954).  Saving model ...
	 Train_Loss: 0.1524 Train_Acc: 94.987 Val_Loss: 0.1240  BEST VAL Loss: 0.1240  Val_Acc: 95.638

Epoch 29: Validation loss decreased (0.123954 --> 0.123464).  Saving model ...
	 Train_Loss: 0.1517 Train_Acc: 95.037 Val_Loss: 0.1235  BEST VAL Loss: 0.1235  Val_Acc: 95.946

Epoch 30: Validation loss decreased (0.123464 --> 0.123044).  Saving model ...
	 Train_Loss: 0.1510 Train_Acc: 94.976 Val_Loss: 0.1230  BEST VAL Loss: 0.1230  Val_Acc: 95.820

Epoch 31: Validation loss decreased (0.123044 --> 0.122630).  Saving model ...
	 Train_Loss: 0.1505 Train_Acc: 94.825 Val_Loss: 0.1226  BEST VAL Loss: 0.1226  Val_Acc: 95.772

Epoch 32: Validation loss decreased (0.122630 --> 0.122231).  Saving model ...
	 Train_Loss: 0.1499 Train_Acc: 94.998 Val_Loss: 0.1222  BEST VAL Loss: 0.1222  Val_Acc: 95.727

Epoch 33: Validation loss decreased (0.122231 --> 0.121773).  Saving model ...
	 Train_Loss: 0.1493 Train_Acc: 95.047 Val_Loss: 0.1218  BEST VAL Loss: 0.1218  Val_Acc: 95.865

Epoch 34: Validation loss decreased (0.121773 --> 0.121434).  Saving model ...
	 Train_Loss: 0.1488 Train_Acc: 94.977 Val_Loss: 0.1214  BEST VAL Loss: 0.1214  Val_Acc: 95.885

Epoch 35: Validation loss decreased (0.121434 --> 0.121184).  Saving model ...
	 Train_Loss: 0.1483 Train_Acc: 94.958 Val_Loss: 0.1212  BEST VAL Loss: 0.1212  Val_Acc: 95.711

Epoch 36: Validation loss decreased (0.121184 --> 0.120901).  Saving model ...
	 Train_Loss: 0.1479 Train_Acc: 94.893 Val_Loss: 0.1209  BEST VAL Loss: 0.1209  Val_Acc: 95.857

Epoch 37: Validation loss decreased (0.120901 --> 0.120619).  Saving model ...
	 Train_Loss: 0.1474 Train_Acc: 95.025 Val_Loss: 0.1206  BEST VAL Loss: 0.1206  Val_Acc: 95.950

Epoch 38: Validation loss decreased (0.120619 --> 0.120255).  Saving model ...
	 Train_Loss: 0.1469 Train_Acc: 94.980 Val_Loss: 0.1203  BEST VAL Loss: 0.1203  Val_Acc: 95.930

Epoch 39: Validation loss decreased (0.120255 --> 0.119922).  Saving model ...
	 Train_Loss: 0.1465 Train_Acc: 94.996 Val_Loss: 0.1199  BEST VAL Loss: 0.1199  Val_Acc: 95.934

Epoch 40: Validation loss decreased (0.119922 --> 0.119710).  Saving model ...
	 Train_Loss: 0.1461 Train_Acc: 94.865 Val_Loss: 0.1197  BEST VAL Loss: 0.1197  Val_Acc: 95.800

Epoch 41: Validation loss decreased (0.119710 --> 0.119432).  Saving model ...
	 Train_Loss: 0.1457 Train_Acc: 95.024 Val_Loss: 0.1194  BEST VAL Loss: 0.1194  Val_Acc: 95.844

Epoch 42: Validation loss decreased (0.119432 --> 0.119418).  Saving model ...
	 Train_Loss: 0.1454 Train_Acc: 94.899 Val_Loss: 0.1194  BEST VAL Loss: 0.1194  Val_Acc: 95.601

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.1451 Train_Acc: 94.854 Val_Loss: 0.1194  BEST VAL Loss: 0.1194  Val_Acc: 95.869

Epoch 44: Validation loss decreased (0.119418 --> 0.119265).  Saving model ...
	 Train_Loss: 0.1448 Train_Acc: 94.960 Val_Loss: 0.1193  BEST VAL Loss: 0.1193  Val_Acc: 95.707

Epoch 45: Validation loss decreased (0.119265 --> 0.119062).  Saving model ...
	 Train_Loss: 0.1445 Train_Acc: 94.885 Val_Loss: 0.1191  BEST VAL Loss: 0.1191  Val_Acc: 95.901

Epoch 46: Validation loss decreased (0.119062 --> 0.118965).  Saving model ...
	 Train_Loss: 0.1442 Train_Acc: 94.952 Val_Loss: 0.1190  BEST VAL Loss: 0.1190  Val_Acc: 95.735

Epoch 47: Validation loss decreased (0.118965 --> 0.118685).  Saving model ...
	 Train_Loss: 0.1438 Train_Acc: 95.148 Val_Loss: 0.1187  BEST VAL Loss: 0.1187  Val_Acc: 95.986

Epoch 48: Validation loss decreased (0.118685 --> 0.118483).  Saving model ...
	 Train_Loss: 0.1435 Train_Acc: 95.134 Val_Loss: 0.1185  BEST VAL Loss: 0.1185  Val_Acc: 95.958

Epoch 49: Validation loss decreased (0.118483 --> 0.118243).  Saving model ...
	 Train_Loss: 0.1431 Train_Acc: 95.102 Val_Loss: 0.1182  BEST VAL Loss: 0.1182  Val_Acc: 95.950

Epoch 50: Validation loss decreased (0.118243 --> 0.118051).  Saving model ...
	 Train_Loss: 0.1428 Train_Acc: 95.056 Val_Loss: 0.1181  BEST VAL Loss: 0.1181  Val_Acc: 95.861

Epoch 51: Validation loss decreased (0.118051 --> 0.117879).  Saving model ...
	 Train_Loss: 0.1425 Train_Acc: 95.138 Val_Loss: 0.1179  BEST VAL Loss: 0.1179  Val_Acc: 95.755

Epoch 52: Validation loss decreased (0.117879 --> 0.117630).  Saving model ...
	 Train_Loss: 0.1422 Train_Acc: 95.035 Val_Loss: 0.1176  BEST VAL Loss: 0.1176  Val_Acc: 96.120

Epoch 53: Validation loss decreased (0.117630 --> 0.117451).  Saving model ...
	 Train_Loss: 0.1419 Train_Acc: 94.999 Val_Loss: 0.1175  BEST VAL Loss: 0.1175  Val_Acc: 96.019

Epoch 54: Validation loss decreased (0.117451 --> 0.117350).  Saving model ...
	 Train_Loss: 0.1417 Train_Acc: 94.997 Val_Loss: 0.1174  BEST VAL Loss: 0.1174  Val_Acc: 95.938

Epoch 55: Validation loss decreased (0.117350 --> 0.117197).  Saving model ...
	 Train_Loss: 0.1414 Train_Acc: 95.038 Val_Loss: 0.1172  BEST VAL Loss: 0.1172  Val_Acc: 95.958

Epoch 56: Validation loss decreased (0.117197 --> 0.117000).  Saving model ...
	 Train_Loss: 0.1411 Train_Acc: 95.252 Val_Loss: 0.1170  BEST VAL Loss: 0.1170  Val_Acc: 96.157

Epoch 57: Validation loss decreased (0.117000 --> 0.116869).  Saving model ...
	 Train_Loss: 0.1408 Train_Acc: 95.191 Val_Loss: 0.1169  BEST VAL Loss: 0.1169  Val_Acc: 95.926

Epoch 58: Validation loss decreased (0.116869 --> 0.116690).  Saving model ...
	 Train_Loss: 0.1406 Train_Acc: 95.059 Val_Loss: 0.1167  BEST VAL Loss: 0.1167  Val_Acc: 96.144

Epoch 59: Validation loss decreased (0.116690 --> 0.116632).  Saving model ...
	 Train_Loss: 0.1402 Train_Acc: 95.305 Val_Loss: 0.1166  BEST VAL Loss: 0.1166  Val_Acc: 95.865

Epoch 60: Validation loss decreased (0.116632 --> 0.116465).  Saving model ...
	 Train_Loss: 0.1400 Train_Acc: 95.168 Val_Loss: 0.1165  BEST VAL Loss: 0.1165  Val_Acc: 95.990

Epoch 61: Validation loss decreased (0.116465 --> 0.116261).  Saving model ...
	 Train_Loss: 0.1398 Train_Acc: 95.127 Val_Loss: 0.1163  BEST VAL Loss: 0.1163  Val_Acc: 96.031

Epoch 62: Validation loss decreased (0.116261 --> 0.116112).  Saving model ...
	 Train_Loss: 0.1395 Train_Acc: 95.220 Val_Loss: 0.1161  BEST VAL Loss: 0.1161  Val_Acc: 95.970

Epoch 63: Validation loss decreased (0.116112 --> 0.116054).  Saving model ...
	 Train_Loss: 0.1392 Train_Acc: 95.220 Val_Loss: 0.1161  BEST VAL Loss: 0.1161  Val_Acc: 95.881

Epoch 64: Validation loss decreased (0.116054 --> 0.115853).  Saving model ...
	 Train_Loss: 0.1390 Train_Acc: 95.230 Val_Loss: 0.1159  BEST VAL Loss: 0.1159  Val_Acc: 96.149

Epoch 65: Validation loss decreased (0.115853 --> 0.115737).  Saving model ...
	 Train_Loss: 0.1387 Train_Acc: 95.266 Val_Loss: 0.1157  BEST VAL Loss: 0.1157  Val_Acc: 95.828

Epoch 66: Validation loss decreased (0.115737 --> 0.115570).  Saving model ...
	 Train_Loss: 0.1385 Train_Acc: 95.257 Val_Loss: 0.1156  BEST VAL Loss: 0.1156  Val_Acc: 96.201

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.1383 Train_Acc: 95.219 Val_Loss: 0.1156  BEST VAL Loss: 0.1156  Val_Acc: 95.638

Epoch 68: Validation loss decreased (0.115570 --> 0.115441).  Saving model ...
	 Train_Loss: 0.1380 Train_Acc: 95.241 Val_Loss: 0.1154  BEST VAL Loss: 0.1154  Val_Acc: 96.059

Epoch 69: Validation loss decreased (0.115441 --> 0.115290).  Saving model ...
	 Train_Loss: 0.1378 Train_Acc: 95.261 Val_Loss: 0.1153  BEST VAL Loss: 0.1153  Val_Acc: 96.116

Epoch 70: Validation loss decreased (0.115290 --> 0.115200).  Saving model ...
	 Train_Loss: 0.1376 Train_Acc: 95.232 Val_Loss: 0.1152  BEST VAL Loss: 0.1152  Val_Acc: 95.849

Epoch 71: Validation loss decreased (0.115200 --> 0.115168).  Saving model ...
	 Train_Loss: 0.1374 Train_Acc: 95.235 Val_Loss: 0.1152  BEST VAL Loss: 0.1152  Val_Acc: 95.942

Epoch 72: Validation loss decreased (0.115168 --> 0.115027).  Saving model ...
	 Train_Loss: 0.1372 Train_Acc: 95.210 Val_Loss: 0.1150  BEST VAL Loss: 0.1150  Val_Acc: 95.893

Epoch 73: Validation loss decreased (0.115027 --> 0.114924).  Saving model ...
	 Train_Loss: 0.1370 Train_Acc: 95.113 Val_Loss: 0.1149  BEST VAL Loss: 0.1149  Val_Acc: 95.922

Epoch 74: Validation loss decreased (0.114924 --> 0.114800).  Saving model ...
	 Train_Loss: 0.1369 Train_Acc: 95.270 Val_Loss: 0.1148  BEST VAL Loss: 0.1148  Val_Acc: 96.007

Epoch 75: Validation loss decreased (0.114800 --> 0.114747).  Saving model ...
	 Train_Loss: 0.1367 Train_Acc: 95.195 Val_Loss: 0.1147  BEST VAL Loss: 0.1147  Val_Acc: 95.711

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.1365 Train_Acc: 95.110 Val_Loss: 0.1148  BEST VAL Loss: 0.1147  Val_Acc: 95.772

Epoch 77: Validation loss decreased (0.114747 --> 0.114601).  Saving model ...
	 Train_Loss: 0.1364 Train_Acc: 95.162 Val_Loss: 0.1146  BEST VAL Loss: 0.1146  Val_Acc: 96.242

Epoch 78: Validation loss decreased (0.114601 --> 0.114506).  Saving model ...
	 Train_Loss: 0.1362 Train_Acc: 95.150 Val_Loss: 0.1145  BEST VAL Loss: 0.1145  Val_Acc: 95.772

Epoch 79: Validation loss decreased (0.114506 --> 0.114428).  Saving model ...
	 Train_Loss: 0.1361 Train_Acc: 95.253 Val_Loss: 0.1144  BEST VAL Loss: 0.1144  Val_Acc: 95.922

Epoch 80: Validation loss decreased (0.114428 --> 0.114287).  Saving model ...
	 Train_Loss: 0.1359 Train_Acc: 95.209 Val_Loss: 0.1143  BEST VAL Loss: 0.1143  Val_Acc: 95.978

Epoch 81: Validation loss decreased (0.114287 --> 0.114196).  Saving model ...
	 Train_Loss: 0.1357 Train_Acc: 95.306 Val_Loss: 0.1142  BEST VAL Loss: 0.1142  Val_Acc: 95.982

Epoch 82: Validation loss decreased (0.114196 --> 0.114110).  Saving model ...
	 Train_Loss: 0.1355 Train_Acc: 95.238 Val_Loss: 0.1141  BEST VAL Loss: 0.1141  Val_Acc: 96.027

Epoch 83: Validation loss decreased (0.114110 --> 0.114052).  Saving model ...
	 Train_Loss: 0.1354 Train_Acc: 95.216 Val_Loss: 0.1141  BEST VAL Loss: 0.1141  Val_Acc: 95.958

Epoch 84: Validation loss decreased (0.114052 --> 0.113968).  Saving model ...
	 Train_Loss: 0.1352 Train_Acc: 95.245 Val_Loss: 0.1140  BEST VAL Loss: 0.1140  Val_Acc: 96.047

Epoch 85: Validation loss decreased (0.113968 --> 0.113834).  Saving model ...
	 Train_Loss: 0.1350 Train_Acc: 95.203 Val_Loss: 0.1138  BEST VAL Loss: 0.1138  Val_Acc: 96.323

Epoch 86: Validation loss decreased (0.113834 --> 0.113723).  Saving model ...
	 Train_Loss: 0.1349 Train_Acc: 95.280 Val_Loss: 0.1137  BEST VAL Loss: 0.1137  Val_Acc: 96.169

Epoch 87: Validation loss decreased (0.113723 --> 0.113592).  Saving model ...
	 Train_Loss: 0.1347 Train_Acc: 95.392 Val_Loss: 0.1136  BEST VAL Loss: 0.1136  Val_Acc: 96.149

Epoch 88: Validation loss decreased (0.113592 --> 0.113462).  Saving model ...
	 Train_Loss: 0.1345 Train_Acc: 95.423 Val_Loss: 0.1135  BEST VAL Loss: 0.1135  Val_Acc: 96.108

Epoch 89: Validation loss decreased (0.113462 --> 0.113447).  Saving model ...
	 Train_Loss: 0.1343 Train_Acc: 95.367 Val_Loss: 0.1134  BEST VAL Loss: 0.1134  Val_Acc: 95.982

Epoch 90: Validation loss decreased (0.113447 --> 0.113415).  Saving model ...
	 Train_Loss: 0.1342 Train_Acc: 95.302 Val_Loss: 0.1134  BEST VAL Loss: 0.1134  Val_Acc: 95.703

Epoch 91: Validation loss decreased (0.113415 --> 0.113339).  Saving model ...
	 Train_Loss: 0.1340 Train_Acc: 95.228 Val_Loss: 0.1133  BEST VAL Loss: 0.1133  Val_Acc: 96.031

Epoch 92: Validation loss decreased (0.113339 --> 0.113247).  Saving model ...
	 Train_Loss: 0.1339 Train_Acc: 95.370 Val_Loss: 0.1132  BEST VAL Loss: 0.1132  Val_Acc: 96.161

Epoch 93: Validation loss decreased (0.113247 --> 0.113197).  Saving model ...
	 Train_Loss: 0.1337 Train_Acc: 95.295 Val_Loss: 0.1132  BEST VAL Loss: 0.1132  Val_Acc: 95.897

Epoch 94: Validation loss decreased (0.113197 --> 0.113119).  Saving model ...
	 Train_Loss: 0.1336 Train_Acc: 95.267 Val_Loss: 0.1131  BEST VAL Loss: 0.1131  Val_Acc: 96.088

Epoch 95: Validation loss decreased (0.113119 --> 0.113065).  Saving model ...
	 Train_Loss: 0.1335 Train_Acc: 95.298 Val_Loss: 0.1131  BEST VAL Loss: 0.1131  Val_Acc: 95.966

Epoch 96: Validation loss decreased (0.113065 --> 0.112987).  Saving model ...
	 Train_Loss: 0.1334 Train_Acc: 95.050 Val_Loss: 0.1130  BEST VAL Loss: 0.1130  Val_Acc: 95.946

Epoch 97: Validation loss decreased (0.112987 --> 0.112937).  Saving model ...
	 Train_Loss: 0.1333 Train_Acc: 95.261 Val_Loss: 0.1129  BEST VAL Loss: 0.1129  Val_Acc: 95.950

Epoch 98: Validation loss decreased (0.112937 --> 0.112857).  Saving model ...
	 Train_Loss: 0.1332 Train_Acc: 95.314 Val_Loss: 0.1129  BEST VAL Loss: 0.1129  Val_Acc: 96.108

Epoch 99: Validation loss decreased (0.112857 --> 0.112744).  Saving model ...
	 Train_Loss: 0.1330 Train_Acc: 95.238 Val_Loss: 0.1127  BEST VAL Loss: 0.1127  Val_Acc: 96.076

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.55      0.55    109228
           1       0.45      0.45      0.45     88100

    accuracy                           0.50    197328
   macro avg       0.50      0.50      0.50    197328
weighted avg       0.50      0.50      0.50    197328

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.56      0.56      0.56     13654
           1       0.46      0.46      0.46     11012

    accuracy                           0.51     24666
   macro avg       0.51      0.51      0.51     24666
weighted avg       0.51      0.51      0.51     24666

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.55      0.55     13654
           1       0.44      0.44      0.44     11012

    accuracy                           0.50     24666
   macro avg       0.49      0.49      0.49     24666
weighted avg       0.50      0.50      0.50     24666

              precision    recall  f1-score   support

           0       0.55      0.55      0.55     13654
           1       0.44      0.44      0.44     11012

    accuracy                           0.50     24666
   macro avg       0.49      0.49      0.49     24666
weighted avg       0.50      0.50      0.50     24666

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.49      0.49     37725
           1       0.50      0.51      0.50     38332

    accuracy                           0.50     76057
   macro avg       0.50      0.50      0.50     76057
weighted avg       0.50      0.50      0.50     76057

              precision    recall  f1-score   support

           0       0.50      0.49      0.49     37725
           1       0.50      0.51      0.50     38332

    accuracy                           0.50     76057
   macro avg       0.50      0.50      0.50     76057
weighted avg       0.50      0.50      0.50     76057

completed
