[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'a684f16b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'eb228205'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '67b874fb'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '0ed3211d'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Thapsigargin_1.000_DMSO_0.025 treatment_name: DMSO_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Thapsigargin_1.000_DMSO_0.025
TREATMENT_NAME: DMSO_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'Thapsigargin_1.000_DMSO_0.025']
The dimensions of the data are: (49409, 1276)
Number of total missing values across all columns: 98818
Data Subset Is Off
Wells held out for testing: ['I14' 'K14']
Wells to use for training, validation, and testing ['B14' 'C14' 'D14' 'B15' 'C15' 'D15' 'J14' 'I15' 'J15' 'K15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.367008).  Saving model ...
	 Train_Loss: 0.5474 Train_Acc: 77.009 Val_Loss: 0.3670  BEST VAL Loss: 0.3670  Val_Acc: 84.957

Epoch 1: Validation loss decreased (0.367008 --> 0.337199).  Saving model ...
	 Train_Loss: 0.4829 Train_Acc: 80.879 Val_Loss: 0.3372  BEST VAL Loss: 0.3372  Val_Acc: 88.262

Epoch 2: Validation loss decreased (0.337199 --> 0.317127).  Saving model ...
	 Train_Loss: 0.4481 Train_Acc: 82.696 Val_Loss: 0.3171  BEST VAL Loss: 0.3171  Val_Acc: 88.894

Epoch 3: Validation loss decreased (0.317127 --> 0.299946).  Saving model ...
	 Train_Loss: 0.4265 Train_Acc: 82.796 Val_Loss: 0.2999  BEST VAL Loss: 0.2999  Val_Acc: 90.061

Epoch 4: Validation loss decreased (0.299946 --> 0.287985).  Saving model ...
	 Train_Loss: 0.4104 Train_Acc: 84.011 Val_Loss: 0.2880  BEST VAL Loss: 0.2880  Val_Acc: 90.425

Epoch 5: Validation loss decreased (0.287985 --> 0.279849).  Saving model ...
	 Train_Loss: 0.3980 Train_Acc: 85.391 Val_Loss: 0.2798  BEST VAL Loss: 0.2798  Val_Acc: 90.255

Epoch 6: Validation loss decreased (0.279849 --> 0.271758).  Saving model ...
	 Train_Loss: 0.3879 Train_Acc: 85.925 Val_Loss: 0.2718  BEST VAL Loss: 0.2718  Val_Acc: 90.522

Epoch 7: Validation loss decreased (0.271758 --> 0.267259).  Saving model ...
	 Train_Loss: 0.3799 Train_Acc: 86.138 Val_Loss: 0.2673  BEST VAL Loss: 0.2673  Val_Acc: 90.522

Epoch 8: Validation loss decreased (0.267259 --> 0.262414).  Saving model ...
	 Train_Loss: 0.3725 Train_Acc: 86.284 Val_Loss: 0.2624  BEST VAL Loss: 0.2624  Val_Acc: 90.960

Epoch 9: Validation loss decreased (0.262414 --> 0.258784).  Saving model ...
	 Train_Loss: 0.3664 Train_Acc: 86.712 Val_Loss: 0.2588  BEST VAL Loss: 0.2588  Val_Acc: 91.227

Epoch 10: Validation loss decreased (0.258784 --> 0.253747).  Saving model ...
	 Train_Loss: 0.3603 Train_Acc: 87.304 Val_Loss: 0.2537  BEST VAL Loss: 0.2537  Val_Acc: 91.470

Epoch 11: Validation loss decreased (0.253747 --> 0.250805).  Saving model ...
	 Train_Loss: 0.3557 Train_Acc: 86.894 Val_Loss: 0.2508  BEST VAL Loss: 0.2508  Val_Acc: 91.495

Epoch 12: Validation loss decreased (0.250805 --> 0.247752).  Saving model ...
	 Train_Loss: 0.3512 Train_Acc: 87.383 Val_Loss: 0.2478  BEST VAL Loss: 0.2478  Val_Acc: 91.203

Epoch 13: Validation loss decreased (0.247752 --> 0.246370).  Saving model ...
	 Train_Loss: 0.3472 Train_Acc: 87.304 Val_Loss: 0.2464  BEST VAL Loss: 0.2464  Val_Acc: 91.592

Epoch 14: Validation loss decreased (0.246370 --> 0.243583).  Saving model ...
	 Train_Loss: 0.3436 Train_Acc: 87.432 Val_Loss: 0.2436  BEST VAL Loss: 0.2436  Val_Acc: 92.029

Epoch 15: Validation loss decreased (0.243583 --> 0.241817).  Saving model ...
	 Train_Loss: 0.3405 Train_Acc: 87.450 Val_Loss: 0.2418  BEST VAL Loss: 0.2418  Val_Acc: 91.203

Epoch 16: Validation loss decreased (0.241817 --> 0.240065).  Saving model ...
	 Train_Loss: 0.3372 Train_Acc: 87.851 Val_Loss: 0.2401  BEST VAL Loss: 0.2401  Val_Acc: 91.908

Epoch 17: Validation loss decreased (0.240065 --> 0.237747).  Saving model ...
	 Train_Loss: 0.3344 Train_Acc: 87.851 Val_Loss: 0.2377  BEST VAL Loss: 0.2377  Val_Acc: 91.567

Epoch 18: Validation loss decreased (0.237747 --> 0.236814).  Saving model ...
	 Train_Loss: 0.3316 Train_Acc: 88.109 Val_Loss: 0.2368  BEST VAL Loss: 0.2368  Val_Acc: 91.519

Epoch 19: Validation loss decreased (0.236814 --> 0.235521).  Saving model ...
	 Train_Loss: 0.3292 Train_Acc: 87.791 Val_Loss: 0.2355  BEST VAL Loss: 0.2355  Val_Acc: 91.689

Epoch 20: Validation loss decreased (0.235521 --> 0.233776).  Saving model ...
	 Train_Loss: 0.3269 Train_Acc: 88.216 Val_Loss: 0.2338  BEST VAL Loss: 0.2338  Val_Acc: 91.859

Epoch 21: Validation loss decreased (0.233776 --> 0.232341).  Saving model ...
	 Train_Loss: 0.3247 Train_Acc: 88.119 Val_Loss: 0.2323  BEST VAL Loss: 0.2323  Val_Acc: 91.883

Epoch 22: Validation loss decreased (0.232341 --> 0.230700).  Saving model ...
	 Train_Loss: 0.3226 Train_Acc: 88.468 Val_Loss: 0.2307  BEST VAL Loss: 0.2307  Val_Acc: 91.908

Epoch 23: Validation loss decreased (0.230700 --> 0.229432).  Saving model ...
	 Train_Loss: 0.3205 Train_Acc: 88.432 Val_Loss: 0.2294  BEST VAL Loss: 0.2294  Val_Acc: 91.762

Epoch 24: Validation loss decreased (0.229432 --> 0.228186).  Saving model ...
	 Train_Loss: 0.3185 Train_Acc: 88.650 Val_Loss: 0.2282  BEST VAL Loss: 0.2282  Val_Acc: 91.665

Epoch 25: Validation loss decreased (0.228186 --> 0.226765).  Saving model ...
	 Train_Loss: 0.3167 Train_Acc: 88.632 Val_Loss: 0.2268  BEST VAL Loss: 0.2268  Val_Acc: 92.296

Epoch 26: Validation loss decreased (0.226765 --> 0.225743).  Saving model ...
	 Train_Loss: 0.3150 Train_Acc: 88.322 Val_Loss: 0.2257  BEST VAL Loss: 0.2257  Val_Acc: 92.442

Epoch 27: Validation loss decreased (0.225743 --> 0.224176).  Saving model ...
	 Train_Loss: 0.3135 Train_Acc: 88.471 Val_Loss: 0.2242  BEST VAL Loss: 0.2242  Val_Acc: 92.491

Epoch 28: Validation loss decreased (0.224176 --> 0.223184).  Saving model ...
	 Train_Loss: 0.3119 Train_Acc: 88.675 Val_Loss: 0.2232  BEST VAL Loss: 0.2232  Val_Acc: 92.224

Epoch 29: Validation loss decreased (0.223184 --> 0.222362).  Saving model ...
	 Train_Loss: 0.3104 Train_Acc: 88.638 Val_Loss: 0.2224  BEST VAL Loss: 0.2224  Val_Acc: 92.418

Epoch 30: Validation loss decreased (0.222362 --> 0.221774).  Saving model ...
	 Train_Loss: 0.3090 Train_Acc: 88.480 Val_Loss: 0.2218  BEST VAL Loss: 0.2218  Val_Acc: 92.005

Epoch 31: Validation loss decreased (0.221774 --> 0.221051).  Saving model ...
	 Train_Loss: 0.3076 Train_Acc: 88.723 Val_Loss: 0.2211  BEST VAL Loss: 0.2211  Val_Acc: 92.151

Epoch 32: Validation loss decreased (0.221051 --> 0.220220).  Saving model ...
	 Train_Loss: 0.3062 Train_Acc: 89.021 Val_Loss: 0.2202  BEST VAL Loss: 0.2202  Val_Acc: 92.588

Epoch 33: Validation loss decreased (0.220220 --> 0.219261).  Saving model ...
	 Train_Loss: 0.3049 Train_Acc: 88.860 Val_Loss: 0.2193  BEST VAL Loss: 0.2193  Val_Acc: 92.272

Epoch 34: Validation loss decreased (0.219261 --> 0.218748).  Saving model ...
	 Train_Loss: 0.3037 Train_Acc: 88.690 Val_Loss: 0.2187  BEST VAL Loss: 0.2187  Val_Acc: 92.078

Epoch 35: Validation loss decreased (0.218748 --> 0.217723).  Saving model ...
	 Train_Loss: 0.3025 Train_Acc: 89.085 Val_Loss: 0.2177  BEST VAL Loss: 0.2177  Val_Acc: 92.175

Epoch 36: Validation loss decreased (0.217723 --> 0.217008).  Saving model ...
	 Train_Loss: 0.3013 Train_Acc: 88.915 Val_Loss: 0.2170  BEST VAL Loss: 0.2170  Val_Acc: 91.908

Epoch 37: Validation loss decreased (0.217008 --> 0.216495).  Saving model ...
	 Train_Loss: 0.3003 Train_Acc: 88.854 Val_Loss: 0.2165  BEST VAL Loss: 0.2165  Val_Acc: 92.369

Epoch 38: Validation loss decreased (0.216495 --> 0.216236).  Saving model ...
	 Train_Loss: 0.2993 Train_Acc: 88.905 Val_Loss: 0.2162  BEST VAL Loss: 0.2162  Val_Acc: 91.956

Epoch 39: Validation loss decreased (0.216236 --> 0.215430).  Saving model ...
	 Train_Loss: 0.2983 Train_Acc: 88.975 Val_Loss: 0.2154  BEST VAL Loss: 0.2154  Val_Acc: 92.151

Epoch 40: Validation loss decreased (0.215430 --> 0.214973).  Saving model ...
	 Train_Loss: 0.2973 Train_Acc: 88.990 Val_Loss: 0.2150  BEST VAL Loss: 0.2150  Val_Acc: 92.151

Epoch 41: Validation loss decreased (0.214973 --> 0.214693).  Saving model ...
	 Train_Loss: 0.2963 Train_Acc: 89.185 Val_Loss: 0.2147  BEST VAL Loss: 0.2147  Val_Acc: 92.151

Epoch 42: Validation loss decreased (0.214693 --> 0.213990).  Saving model ...
	 Train_Loss: 0.2954 Train_Acc: 89.133 Val_Loss: 0.2140  BEST VAL Loss: 0.2140  Val_Acc: 92.272

Epoch 43: Validation loss decreased (0.213990 --> 0.213609).  Saving model ...
	 Train_Loss: 0.2944 Train_Acc: 89.194 Val_Loss: 0.2136  BEST VAL Loss: 0.2136  Val_Acc: 92.296

Epoch 44: Validation loss decreased (0.213609 --> 0.212898).  Saving model ...
	 Train_Loss: 0.2936 Train_Acc: 89.076 Val_Loss: 0.2129  BEST VAL Loss: 0.2129  Val_Acc: 92.491

Epoch 45: Validation loss decreased (0.212898 --> 0.212114).  Saving model ...
	 Train_Loss: 0.2928 Train_Acc: 89.173 Val_Loss: 0.2121  BEST VAL Loss: 0.2121  Val_Acc: 92.612

Epoch 46: Validation loss decreased (0.212114 --> 0.211444).  Saving model ...
	 Train_Loss: 0.2919 Train_Acc: 89.158 Val_Loss: 0.2114  BEST VAL Loss: 0.2114  Val_Acc: 92.685

Epoch 47: Validation loss decreased (0.211444 --> 0.211103).  Saving model ...
	 Train_Loss: 0.2911 Train_Acc: 89.179 Val_Loss: 0.2111  BEST VAL Loss: 0.2111  Val_Acc: 92.661

Epoch 48: Validation loss decreased (0.211103 --> 0.210966).  Saving model ...
	 Train_Loss: 0.2903 Train_Acc: 89.492 Val_Loss: 0.2110  BEST VAL Loss: 0.2110  Val_Acc: 92.442

Epoch 49: Validation loss decreased (0.210966 --> 0.210682).  Saving model ...
	 Train_Loss: 0.2895 Train_Acc: 89.325 Val_Loss: 0.2107  BEST VAL Loss: 0.2107  Val_Acc: 92.199

Epoch 50: Validation loss decreased (0.210682 --> 0.210389).  Saving model ...
	 Train_Loss: 0.2886 Train_Acc: 89.680 Val_Loss: 0.2104  BEST VAL Loss: 0.2104  Val_Acc: 92.321

Epoch 51: Validation loss decreased (0.210389 --> 0.209808).  Saving model ...
	 Train_Loss: 0.2878 Train_Acc: 89.501 Val_Loss: 0.2098  BEST VAL Loss: 0.2098  Val_Acc: 92.418

Epoch 52: Validation loss decreased (0.209808 --> 0.209290).  Saving model ...
	 Train_Loss: 0.2871 Train_Acc: 89.595 Val_Loss: 0.2093  BEST VAL Loss: 0.2093  Val_Acc: 92.880

Epoch 53: Validation loss decreased (0.209290 --> 0.209137).  Saving model ...
	 Train_Loss: 0.2863 Train_Acc: 89.455 Val_Loss: 0.2091  BEST VAL Loss: 0.2091  Val_Acc: 92.394

Epoch 54: Validation loss decreased (0.209137 --> 0.208899).  Saving model ...
	 Train_Loss: 0.2856 Train_Acc: 89.619 Val_Loss: 0.2089  BEST VAL Loss: 0.2089  Val_Acc: 92.369

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.2850 Train_Acc: 89.300 Val_Loss: 0.2090  BEST VAL Loss: 0.2089  Val_Acc: 92.345

Epoch 56: Validation loss decreased (0.208899 --> 0.208844).  Saving model ...
	 Train_Loss: 0.2843 Train_Acc: 89.498 Val_Loss: 0.2088  BEST VAL Loss: 0.2088  Val_Acc: 92.296

Epoch 57: Validation loss decreased (0.208844 --> 0.208685).  Saving model ...
	 Train_Loss: 0.2836 Train_Acc: 89.659 Val_Loss: 0.2087  BEST VAL Loss: 0.2087  Val_Acc: 92.515

Epoch 58: Validation loss decreased (0.208685 --> 0.208657).  Saving model ...
	 Train_Loss: 0.2830 Train_Acc: 89.641 Val_Loss: 0.2087  BEST VAL Loss: 0.2087  Val_Acc: 92.126

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.2823 Train_Acc: 89.865 Val_Loss: 0.2087  BEST VAL Loss: 0.2087  Val_Acc: 92.734

Epoch 60: Validation loss decreased (0.208657 --> 0.208564).  Saving model ...
	 Train_Loss: 0.2817 Train_Acc: 89.553 Val_Loss: 0.2086  BEST VAL Loss: 0.2086  Val_Acc: 92.102

Epoch 61: Validation loss decreased (0.208564 --> 0.208311).  Saving model ...
	 Train_Loss: 0.2811 Train_Acc: 89.549 Val_Loss: 0.2083  BEST VAL Loss: 0.2083  Val_Acc: 91.810

Epoch 62: Validation loss decreased (0.208311 --> 0.208013).  Saving model ...
	 Train_Loss: 0.2805 Train_Acc: 89.686 Val_Loss: 0.2080  BEST VAL Loss: 0.2080  Val_Acc: 92.321

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.2798 Train_Acc: 89.868 Val_Loss: 0.2082  BEST VAL Loss: 0.2080  Val_Acc: 92.248

Epoch 64: Validation loss decreased (0.208013 --> 0.207901).  Saving model ...
	 Train_Loss: 0.2793 Train_Acc: 89.950 Val_Loss: 0.2079  BEST VAL Loss: 0.2079  Val_Acc: 91.835

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.2787 Train_Acc: 89.899 Val_Loss: 0.2080  BEST VAL Loss: 0.2079  Val_Acc: 91.981

Epoch 66: Validation loss decreased (0.207901 --> 0.207858).  Saving model ...
	 Train_Loss: 0.2782 Train_Acc: 89.613 Val_Loss: 0.2079  BEST VAL Loss: 0.2079  Val_Acc: 92.394

Epoch 67: Validation loss decreased (0.207858 --> 0.207604).  Saving model ...
	 Train_Loss: 0.2776 Train_Acc: 89.856 Val_Loss: 0.2076  BEST VAL Loss: 0.2076  Val_Acc: 92.272

Epoch 68: Validation loss decreased (0.207604 --> 0.207374).  Saving model ...
	 Train_Loss: 0.2771 Train_Acc: 89.662 Val_Loss: 0.2074  BEST VAL Loss: 0.2074  Val_Acc: 92.126

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.2765 Train_Acc: 90.111 Val_Loss: 0.2075  BEST VAL Loss: 0.2074  Val_Acc: 92.126

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.2760 Train_Acc: 89.847 Val_Loss: 0.2076  BEST VAL Loss: 0.2074  Val_Acc: 91.981

Epoch 71: Validation loss decreased (0.207374 --> 0.207286).  Saving model ...
	 Train_Loss: 0.2754 Train_Acc: 89.947 Val_Loss: 0.2073  BEST VAL Loss: 0.2073  Val_Acc: 92.345

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.2749 Train_Acc: 89.972 Val_Loss: 0.2075  BEST VAL Loss: 0.2073  Val_Acc: 92.224

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.2744 Train_Acc: 89.783 Val_Loss: 0.2076  BEST VAL Loss: 0.2073  Val_Acc: 92.321

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.2739 Train_Acc: 90.039 Val_Loss: 0.2075  BEST VAL Loss: 0.2073  Val_Acc: 92.394

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.2734 Train_Acc: 90.203 Val_Loss: 0.2076  BEST VAL Loss: 0.2073  Val_Acc: 92.199

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.2729 Train_Acc: 89.789 Val_Loss: 0.2076  BEST VAL Loss: 0.2073  Val_Acc: 92.564

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.2725 Train_Acc: 89.859 Val_Loss: 0.2074  BEST VAL Loss: 0.2073  Val_Acc: 92.442

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.2720 Train_Acc: 90.321 Val_Loss: 0.2077  BEST VAL Loss: 0.2073  Val_Acc: 92.102

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.2715 Train_Acc: 90.279 Val_Loss: 0.2076  BEST VAL Loss: 0.2073  Val_Acc: 92.248

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.2710 Train_Acc: 90.054 Val_Loss: 0.2074  BEST VAL Loss: 0.2073  Val_Acc: 92.394

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.2706 Train_Acc: 90.072 Val_Loss: 0.2076  BEST VAL Loss: 0.2073  Val_Acc: 92.272

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.2701 Train_Acc: 89.963 Val_Loss: 0.2079  BEST VAL Loss: 0.2073  Val_Acc: 92.248

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.2697 Train_Acc: 89.938 Val_Loss: 0.2081  BEST VAL Loss: 0.2073  Val_Acc: 92.272

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.2693 Train_Acc: 90.069 Val_Loss: 0.2082  BEST VAL Loss: 0.2073  Val_Acc: 92.151

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.2689 Train_Acc: 89.932 Val_Loss: 0.2081  BEST VAL Loss: 0.2073  Val_Acc: 92.248

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.2685 Train_Acc: 90.090 Val_Loss: 0.2080  BEST VAL Loss: 0.2073  Val_Acc: 92.296

Epoch 87: Validation loss did not decrease
Early stopped at epoch : 87
Thapsigargin_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.75      0.76      0.75     24644
           1       0.24      0.23      0.24      8273

    accuracy                           0.63     32917
   macro avg       0.50      0.50      0.50     32917
weighted avg       0.62      0.63      0.62     32917

Thapsigargin_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.75      0.78      0.76      3081
           1       0.24      0.21      0.22      1034

    accuracy                           0.63      4115
   macro avg       0.49      0.49      0.49      4115
weighted avg       0.62      0.63      0.63      4115

Thapsigargin_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.74      0.77      0.76      3081
           1       0.23      0.21      0.22      1034

    accuracy                           0.63      4115
   macro avg       0.49      0.49      0.49      4115
weighted avg       0.62      0.63      0.62      4115

              precision    recall  f1-score   support

           0       0.74      0.77      0.76      3081
           1       0.23      0.21      0.22      1034

    accuracy                           0.63      4115
   macro avg       0.49      0.49      0.49      4115
weighted avg       0.62      0.63      0.62      4115

Thapsigargin_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.59      0.67      0.63      4837
           1       0.42      0.34      0.37      3425

    accuracy                           0.53      8262
   macro avg       0.51      0.51      0.50      8262
weighted avg       0.52      0.53      0.52      8262

              precision    recall  f1-score   support

           0       0.59      0.67      0.63      4837
           1       0.42      0.34      0.37      3425

    accuracy                           0.53      8262
   macro avg       0.51      0.51      0.50      8262
weighted avg       0.52      0.53      0.52      8262

completed
