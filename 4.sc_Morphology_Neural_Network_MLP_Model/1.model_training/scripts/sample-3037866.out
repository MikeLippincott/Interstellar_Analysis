[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'db6156f2'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '9c5e22f2'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '2f219cb4'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '5e9afa6a'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Flagellin_0.100_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: Flagellin_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Flagellin_0.100_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (200462, 1270)
Number of total missing values across all columns: 437540
Data Subset Is Off
Wells held out for testing: ['L10' 'M10']
Wells to use for training, validation, and testing ['L05' 'M05' 'L11' 'M11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.675531).  Saving model ...
	 Train_Loss: 1.1316 Train_Acc: 55.254 Val_Loss: 0.6755  BEST VAL Loss: 0.6755  Val_Acc: 59.134

Epoch 1: Validation loss decreased (0.675531 --> 0.667075).  Saving model ...
	 Train_Loss: 0.9027 Train_Acc: 59.735 Val_Loss: 0.6671  BEST VAL Loss: 0.6671  Val_Acc: 61.626

Epoch 2: Validation loss decreased (0.667075 --> 0.664671).  Saving model ...
	 Train_Loss: 0.8826 Train_Acc: 60.650 Val_Loss: 0.6647  BEST VAL Loss: 0.6647  Val_Acc: 61.716

Epoch 3: Validation loss decreased (0.664671 --> 0.655216).  Saving model ...
	 Train_Loss: 0.8241 Train_Acc: 62.792 Val_Loss: 0.6552  BEST VAL Loss: 0.6552  Val_Acc: 64.622

Epoch 4: Validation loss decreased (0.655216 --> 0.647074).  Saving model ...
	 Train_Loss: 0.8011 Train_Acc: 64.025 Val_Loss: 0.6471  BEST VAL Loss: 0.6471  Val_Acc: 67.603

Epoch 5: Validation loss decreased (0.647074 --> 0.644951).  Saving model ...
	 Train_Loss: 0.7897 Train_Acc: 64.973 Val_Loss: 0.6450  BEST VAL Loss: 0.6450  Val_Acc: 64.479

Epoch 6: Validation loss decreased (0.644951 --> 0.635788).  Saving model ...
	 Train_Loss: 0.7641 Train_Acc: 67.238 Val_Loss: 0.6358  BEST VAL Loss: 0.6358  Val_Acc: 70.073

Epoch 7: Validation loss decreased (0.635788 --> 0.627176).  Saving model ...
	 Train_Loss: 0.7441 Train_Acc: 67.840 Val_Loss: 0.6272  BEST VAL Loss: 0.6272  Val_Acc: 70.246

Epoch 8: Validation loss decreased (0.627176 --> 0.621486).  Saving model ...
	 Train_Loss: 0.7383 Train_Acc: 66.684 Val_Loss: 0.6215  BEST VAL Loss: 0.6215  Val_Acc: 69.239

Epoch 9: Validation loss decreased (0.621486 --> 0.616539).  Saving model ...
	 Train_Loss: 0.7231 Train_Acc: 69.533 Val_Loss: 0.6165  BEST VAL Loss: 0.6165  Val_Acc: 69.968

Epoch 10: Validation loss did not decrease
	 Train_Loss: 0.7196 Train_Acc: 67.875 Val_Loss: 0.6253  BEST VAL Loss: 0.6165  Val_Acc: 64.224

Epoch 11: Validation loss did not decrease
	 Train_Loss: 0.7068 Train_Acc: 70.831 Val_Loss: 0.6192  BEST VAL Loss: 0.6165  Val_Acc: 72.535

Epoch 12: Validation loss decreased (0.616539 --> 0.614526).  Saving model ...
	 Train_Loss: 0.6982 Train_Acc: 69.797 Val_Loss: 0.6145  BEST VAL Loss: 0.6145  Val_Acc: 71.507

Epoch 13: Validation loss decreased (0.614526 --> 0.610568).  Saving model ...
	 Train_Loss: 0.6883 Train_Acc: 71.427 Val_Loss: 0.6106  BEST VAL Loss: 0.6106  Val_Acc: 70.471

Epoch 14: Validation loss decreased (0.610568 --> 0.605240).  Saving model ...
	 Train_Loss: 0.6853 Train_Acc: 69.819 Val_Loss: 0.6052  BEST VAL Loss: 0.6052  Val_Acc: 72.731

Epoch 15: Validation loss decreased (0.605240 --> 0.600791).  Saving model ...
	 Train_Loss: 0.6784 Train_Acc: 70.849 Val_Loss: 0.6008  BEST VAL Loss: 0.6008  Val_Acc: 72.160

Epoch 16: Validation loss decreased (0.600791 --> 0.599590).  Saving model ...
	 Train_Loss: 0.6716 Train_Acc: 71.158 Val_Loss: 0.5996  BEST VAL Loss: 0.5996  Val_Acc: 73.039

Epoch 17: Validation loss decreased (0.599590 --> 0.596501).  Saving model ...
	 Train_Loss: 0.6660 Train_Acc: 71.781 Val_Loss: 0.5965  BEST VAL Loss: 0.5965  Val_Acc: 72.265

Epoch 18: Validation loss decreased (0.596501 --> 0.592367).  Saving model ...
	 Train_Loss: 0.6600 Train_Acc: 71.926 Val_Loss: 0.5924  BEST VAL Loss: 0.5924  Val_Acc: 75.231

Epoch 19: Validation loss decreased (0.592367 --> 0.589744).  Saving model ...
	 Train_Loss: 0.6547 Train_Acc: 72.034 Val_Loss: 0.5897  BEST VAL Loss: 0.5897  Val_Acc: 73.316

Epoch 20: Validation loss decreased (0.589744 --> 0.586464).  Saving model ...
	 Train_Loss: 0.6495 Train_Acc: 72.410 Val_Loss: 0.5865  BEST VAL Loss: 0.5865  Val_Acc: 74.630

Epoch 21: Validation loss decreased (0.586464 --> 0.582207).  Saving model ...
	 Train_Loss: 0.6475 Train_Acc: 71.000 Val_Loss: 0.5822  BEST VAL Loss: 0.5822  Val_Acc: 75.967

Epoch 22: Validation loss decreased (0.582207 --> 0.580424).  Saving model ...
	 Train_Loss: 0.6420 Train_Acc: 73.877 Val_Loss: 0.5804  BEST VAL Loss: 0.5804  Val_Acc: 73.474

Epoch 23: Validation loss decreased (0.580424 --> 0.579809).  Saving model ...
	 Train_Loss: 0.6378 Train_Acc: 72.936 Val_Loss: 0.5798  BEST VAL Loss: 0.5798  Val_Acc: 71.477

Epoch 24: Validation loss decreased (0.579809 --> 0.578998).  Saving model ...
	 Train_Loss: 0.6340 Train_Acc: 72.521 Val_Loss: 0.5790  BEST VAL Loss: 0.5790  Val_Acc: 75.066

Epoch 25: Validation loss decreased (0.578998 --> 0.576319).  Saving model ...
	 Train_Loss: 0.6313 Train_Acc: 72.007 Val_Loss: 0.5763  BEST VAL Loss: 0.5763  Val_Acc: 74.848

Epoch 26: Validation loss decreased (0.576319 --> 0.573741).  Saving model ...
	 Train_Loss: 0.6272 Train_Acc: 73.782 Val_Loss: 0.5737  BEST VAL Loss: 0.5737  Val_Acc: 75.419

Epoch 27: Validation loss decreased (0.573741 --> 0.572230).  Saving model ...
	 Train_Loss: 0.6264 Train_Acc: 71.563 Val_Loss: 0.5722  BEST VAL Loss: 0.5722  Val_Acc: 73.264

Epoch 28: Validation loss decreased (0.572230 --> 0.571477).  Saving model ...
	 Train_Loss: 0.6221 Train_Acc: 74.481 Val_Loss: 0.5715  BEST VAL Loss: 0.5715  Val_Acc: 73.084

Epoch 29: Validation loss decreased (0.571477 --> 0.569207).  Saving model ...
	 Train_Loss: 0.6198 Train_Acc: 73.399 Val_Loss: 0.5692  BEST VAL Loss: 0.5692  Val_Acc: 75.674

Epoch 30: Validation loss decreased (0.569207 --> 0.567848).  Saving model ...
	 Train_Loss: 0.6160 Train_Acc: 74.619 Val_Loss: 0.5678  BEST VAL Loss: 0.5678  Val_Acc: 75.404

Epoch 31: Validation loss decreased (0.567848 --> 0.567724).  Saving model ...
	 Train_Loss: 0.6139 Train_Acc: 72.925 Val_Loss: 0.5677  BEST VAL Loss: 0.5677  Val_Acc: 72.250

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.6104 Train_Acc: 74.788 Val_Loss: 0.5686  BEST VAL Loss: 0.5677  Val_Acc: 69.878

Epoch 33: Validation loss decreased (0.567724 --> 0.566792).  Saving model ...
	 Train_Loss: 0.6075 Train_Acc: 74.137 Val_Loss: 0.5668  BEST VAL Loss: 0.5668  Val_Acc: 76.169

Epoch 34: Validation loss decreased (0.566792 --> 0.564808).  Saving model ...
	 Train_Loss: 0.6073 Train_Acc: 73.328 Val_Loss: 0.5648  BEST VAL Loss: 0.5648  Val_Acc: 75.832

Epoch 35: Validation loss decreased (0.564808 --> 0.564074).  Saving model ...
	 Train_Loss: 0.6039 Train_Acc: 75.677 Val_Loss: 0.5641  BEST VAL Loss: 0.5641  Val_Acc: 74.097

Epoch 36: Validation loss decreased (0.564074 --> 0.563382).  Saving model ...
	 Train_Loss: 0.6011 Train_Acc: 74.830 Val_Loss: 0.5634  BEST VAL Loss: 0.5634  Val_Acc: 75.351

Epoch 37: Validation loss decreased (0.563382 --> 0.562398).  Saving model ...
	 Train_Loss: 0.5987 Train_Acc: 74.593 Val_Loss: 0.5624  BEST VAL Loss: 0.5624  Val_Acc: 76.477

Epoch 38: Validation loss decreased (0.562398 --> 0.560512).  Saving model ...
	 Train_Loss: 0.5964 Train_Acc: 74.452 Val_Loss: 0.5605  BEST VAL Loss: 0.5605  Val_Acc: 75.824

Epoch 39: Validation loss decreased (0.560512 --> 0.559320).  Saving model ...
	 Train_Loss: 0.5941 Train_Acc: 74.530 Val_Loss: 0.5593  BEST VAL Loss: 0.5593  Val_Acc: 76.320

Epoch 40: Validation loss decreased (0.559320 --> 0.557917).  Saving model ...
	 Train_Loss: 0.5921 Train_Acc: 74.134 Val_Loss: 0.5579  BEST VAL Loss: 0.5579  Val_Acc: 76.702

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.5901 Train_Acc: 74.518 Val_Loss: 0.5598  BEST VAL Loss: 0.5579  Val_Acc: 63.691

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.5884 Train_Acc: 74.686 Val_Loss: 0.5590  BEST VAL Loss: 0.5579  Val_Acc: 75.877

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.5863 Train_Acc: 74.887 Val_Loss: 0.5580  BEST VAL Loss: 0.5579  Val_Acc: 72.701

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.5849 Train_Acc: 74.015 Val_Loss: 0.5607  BEST VAL Loss: 0.5579  Val_Acc: 72.468

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.5828 Train_Acc: 75.252 Val_Loss: 0.5601  BEST VAL Loss: 0.5579  Val_Acc: 74.743

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.5810 Train_Acc: 74.844 Val_Loss: 0.5599  BEST VAL Loss: 0.5579  Val_Acc: 70.058

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.5791 Train_Acc: 75.474 Val_Loss: 0.5602  BEST VAL Loss: 0.5579  Val_Acc: 71.177

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.5786 Train_Acc: 73.940 Val_Loss: 0.5585  BEST VAL Loss: 0.5579  Val_Acc: 77.371

Epoch 49: Validation loss decreased (0.557917 --> 0.557294).  Saving model ...
	 Train_Loss: 0.5764 Train_Acc: 76.321 Val_Loss: 0.5573  BEST VAL Loss: 0.5573  Val_Acc: 76.612

Epoch 50: Validation loss decreased (0.557294 --> 0.556089).  Saving model ...
	 Train_Loss: 0.5747 Train_Acc: 75.483 Val_Loss: 0.5561  BEST VAL Loss: 0.5561  Val_Acc: 75.449

Epoch 51: Validation loss decreased (0.556089 --> 0.554804).  Saving model ...
	 Train_Loss: 0.5731 Train_Acc: 75.294 Val_Loss: 0.5548  BEST VAL Loss: 0.5548  Val_Acc: 74.953

Epoch 52: Validation loss decreased (0.554804 --> 0.553599).  Saving model ...
	 Train_Loss: 0.5715 Train_Acc: 75.348 Val_Loss: 0.5536  BEST VAL Loss: 0.5536  Val_Acc: 77.266

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.5700 Train_Acc: 75.443 Val_Loss: 0.5541  BEST VAL Loss: 0.5536  Val_Acc: 75.847

Epoch 54: Validation loss decreased (0.553599 --> 0.552969).  Saving model ...
	 Train_Loss: 0.5686 Train_Acc: 75.076 Val_Loss: 0.5530  BEST VAL Loss: 0.5530  Val_Acc: 77.558

Epoch 55: Validation loss decreased (0.552969 --> 0.552864).  Saving model ...
	 Train_Loss: 0.5674 Train_Acc: 75.065 Val_Loss: 0.5529  BEST VAL Loss: 0.5529  Val_Acc: 72.701

Epoch 56: Validation loss decreased (0.552864 --> 0.552090).  Saving model ...
	 Train_Loss: 0.5660 Train_Acc: 75.585 Val_Loss: 0.5521  BEST VAL Loss: 0.5521  Val_Acc: 74.503

Epoch 57: Validation loss decreased (0.552090 --> 0.551281).  Saving model ...
	 Train_Loss: 0.5645 Train_Acc: 75.777 Val_Loss: 0.5513  BEST VAL Loss: 0.5513  Val_Acc: 76.995

Epoch 58: Validation loss decreased (0.551281 --> 0.549866).  Saving model ...
	 Train_Loss: 0.5632 Train_Acc: 75.433 Val_Loss: 0.5499  BEST VAL Loss: 0.5499  Val_Acc: 76.650

Epoch 59: Validation loss decreased (0.549866 --> 0.549146).  Saving model ...
	 Train_Loss: 0.5618 Train_Acc: 75.787 Val_Loss: 0.5491  BEST VAL Loss: 0.5491  Val_Acc: 76.898

Epoch 60: Validation loss decreased (0.549146 --> 0.549121).  Saving model ...
	 Train_Loss: 0.5605 Train_Acc: 75.718 Val_Loss: 0.5491  BEST VAL Loss: 0.5491  Val_Acc: 75.569

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.5593 Train_Acc: 75.468 Val_Loss: 0.5494  BEST VAL Loss: 0.5491  Val_Acc: 74.120

Epoch 62: Validation loss decreased (0.549121 --> 0.548803).  Saving model ...
	 Train_Loss: 0.5580 Train_Acc: 75.614 Val_Loss: 0.5488  BEST VAL Loss: 0.5488  Val_Acc: 75.899

Epoch 63: Validation loss decreased (0.548803 --> 0.547603).  Saving model ...
	 Train_Loss: 0.5569 Train_Acc: 75.631 Val_Loss: 0.5476  BEST VAL Loss: 0.5476  Val_Acc: 77.243

Epoch 64: Validation loss decreased (0.547603 --> 0.546301).  Saving model ...
	 Train_Loss: 0.5557 Train_Acc: 75.799 Val_Loss: 0.5463  BEST VAL Loss: 0.5463  Val_Acc: 77.821

Epoch 65: Validation loss decreased (0.546301 --> 0.545935).  Saving model ...
	 Train_Loss: 0.5546 Train_Acc: 75.718 Val_Loss: 0.5459  BEST VAL Loss: 0.5459  Val_Acc: 76.274

Epoch 66: Validation loss decreased (0.545935 --> 0.545565).  Saving model ...
	 Train_Loss: 0.5535 Train_Acc: 75.623 Val_Loss: 0.5456  BEST VAL Loss: 0.5456  Val_Acc: 77.025

Epoch 67: Validation loss decreased (0.545565 --> 0.544580).  Saving model ...
	 Train_Loss: 0.5523 Train_Acc: 75.968 Val_Loss: 0.5446  BEST VAL Loss: 0.5446  Val_Acc: 76.515

Epoch 68: Validation loss decreased (0.544580 --> 0.544320).  Saving model ...
	 Train_Loss: 0.5512 Train_Acc: 76.034 Val_Loss: 0.5443  BEST VAL Loss: 0.5443  Val_Acc: 74.397

Epoch 69: Validation loss decreased (0.544320 --> 0.543548).  Saving model ...
	 Train_Loss: 0.5502 Train_Acc: 75.840 Val_Loss: 0.5435  BEST VAL Loss: 0.5435  Val_Acc: 76.477

Epoch 70: Validation loss decreased (0.543548 --> 0.543458).  Saving model ...
	 Train_Loss: 0.5493 Train_Acc: 75.668 Val_Loss: 0.5435  BEST VAL Loss: 0.5435  Val_Acc: 76.965

Epoch 71: Validation loss decreased (0.543458 --> 0.542535).  Saving model ...
	 Train_Loss: 0.5482 Train_Acc: 76.213 Val_Loss: 0.5425  BEST VAL Loss: 0.5425  Val_Acc: 77.836

Epoch 72: Validation loss decreased (0.542535 --> 0.541735).  Saving model ...
	 Train_Loss: 0.5472 Train_Acc: 76.042 Val_Loss: 0.5417  BEST VAL Loss: 0.5417  Val_Acc: 78.369

Epoch 73: Validation loss decreased (0.541735 --> 0.540849).  Saving model ...
	 Train_Loss: 0.5462 Train_Acc: 76.103 Val_Loss: 0.5408  BEST VAL Loss: 0.5408  Val_Acc: 76.147

Epoch 74: Validation loss decreased (0.540849 --> 0.539967).  Saving model ...
	 Train_Loss: 0.5454 Train_Acc: 75.925 Val_Loss: 0.5400  BEST VAL Loss: 0.5400  Val_Acc: 76.665

Epoch 75: Validation loss decreased (0.539967 --> 0.539818).  Saving model ...
	 Train_Loss: 0.5446 Train_Acc: 75.587 Val_Loss: 0.5398  BEST VAL Loss: 0.5398  Val_Acc: 76.237

Epoch 76: Validation loss decreased (0.539818 --> 0.539376).  Saving model ...
	 Train_Loss: 0.5436 Train_Acc: 76.172 Val_Loss: 0.5394  BEST VAL Loss: 0.5394  Val_Acc: 77.491

Epoch 77: Validation loss decreased (0.539376 --> 0.538727).  Saving model ...
	 Train_Loss: 0.5427 Train_Acc: 76.231 Val_Loss: 0.5387  BEST VAL Loss: 0.5387  Val_Acc: 77.679

Epoch 78: Validation loss decreased (0.538727 --> 0.537983).  Saving model ...
	 Train_Loss: 0.5419 Train_Acc: 76.015 Val_Loss: 0.5380  BEST VAL Loss: 0.5380  Val_Acc: 76.259

Epoch 79: Validation loss decreased (0.537983 --> 0.537460).  Saving model ...
	 Train_Loss: 0.5409 Train_Acc: 76.598 Val_Loss: 0.5375  BEST VAL Loss: 0.5375  Val_Acc: 76.064

Epoch 80: Validation loss decreased (0.537460 --> 0.537364).  Saving model ...
	 Train_Loss: 0.5401 Train_Acc: 76.150 Val_Loss: 0.5374  BEST VAL Loss: 0.5374  Val_Acc: 74.067

Epoch 81: Validation loss decreased (0.537364 --> 0.536657).  Saving model ...
	 Train_Loss: 0.5395 Train_Acc: 75.695 Val_Loss: 0.5367  BEST VAL Loss: 0.5367  Val_Acc: 76.965

Epoch 82: Validation loss decreased (0.536657 --> 0.536191).  Saving model ...
	 Train_Loss: 0.5385 Train_Acc: 77.298 Val_Loss: 0.5362  BEST VAL Loss: 0.5362  Val_Acc: 77.776

Epoch 83: Validation loss decreased (0.536191 --> 0.535552).  Saving model ...
	 Train_Loss: 0.5376 Train_Acc: 76.720 Val_Loss: 0.5356  BEST VAL Loss: 0.5356  Val_Acc: 77.175

Epoch 84: Validation loss decreased (0.535552 --> 0.535136).  Saving model ...
	 Train_Loss: 0.5367 Train_Acc: 76.547 Val_Loss: 0.5351  BEST VAL Loss: 0.5351  Val_Acc: 75.088

Epoch 85: Validation loss decreased (0.535136 --> 0.534481).  Saving model ...
	 Train_Loss: 0.5359 Train_Acc: 76.310 Val_Loss: 0.5345  BEST VAL Loss: 0.5345  Val_Acc: 77.829

Epoch 86: Validation loss decreased (0.534481 --> 0.533657).  Saving model ...
	 Train_Loss: 0.5353 Train_Acc: 75.933 Val_Loss: 0.5337  BEST VAL Loss: 0.5337  Val_Acc: 77.528

Epoch 87: Validation loss decreased (0.533657 --> 0.533226).  Saving model ...
	 Train_Loss: 0.5344 Train_Acc: 76.905 Val_Loss: 0.5332  BEST VAL Loss: 0.5332  Val_Acc: 73.391

Epoch 88: Validation loss decreased (0.533226 --> 0.532626).  Saving model ...
	 Train_Loss: 0.5336 Train_Acc: 76.758 Val_Loss: 0.5326  BEST VAL Loss: 0.5326  Val_Acc: 76.830

Epoch 89: Validation loss decreased (0.532626 --> 0.532137).  Saving model ...
	 Train_Loss: 0.5330 Train_Acc: 75.495 Val_Loss: 0.5321  BEST VAL Loss: 0.5321  Val_Acc: 77.025

Epoch 90: Validation loss decreased (0.532137 --> 0.531903).  Saving model ...
	 Train_Loss: 0.5322 Train_Acc: 76.768 Val_Loss: 0.5319  BEST VAL Loss: 0.5319  Val_Acc: 76.274

Epoch 91: Validation loss decreased (0.531903 --> 0.531411).  Saving model ...
	 Train_Loss: 0.5314 Train_Acc: 76.850 Val_Loss: 0.5314  BEST VAL Loss: 0.5314  Val_Acc: 77.063

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.5307 Train_Acc: 76.792 Val_Loss: 0.5319  BEST VAL Loss: 0.5314  Val_Acc: 71.875

Epoch 93: Validation loss decreased (0.531411 --> 0.531277).  Saving model ...
	 Train_Loss: 0.5301 Train_Acc: 75.980 Val_Loss: 0.5313  BEST VAL Loss: 0.5313  Val_Acc: 76.868

Epoch 94: Validation loss decreased (0.531277 --> 0.531032).  Saving model ...
	 Train_Loss: 0.5293 Train_Acc: 76.870 Val_Loss: 0.5310  BEST VAL Loss: 0.5310  Val_Acc: 77.251

Epoch 95: Validation loss decreased (0.531032 --> 0.530650).  Saving model ...
	 Train_Loss: 0.5286 Train_Acc: 76.390 Val_Loss: 0.5307  BEST VAL Loss: 0.5307  Val_Acc: 73.106

Epoch 96: Validation loss decreased (0.530650 --> 0.530261).  Saving model ...
	 Train_Loss: 0.5279 Train_Acc: 76.669 Val_Loss: 0.5303  BEST VAL Loss: 0.5303  Val_Acc: 77.296

Epoch 97: Validation loss decreased (0.530261 --> 0.529819).  Saving model ...
	 Train_Loss: 0.5272 Train_Acc: 76.534 Val_Loss: 0.5298  BEST VAL Loss: 0.5298  Val_Acc: 76.650

Epoch 98: Validation loss decreased (0.529819 --> 0.529402).  Saving model ...
	 Train_Loss: 0.5266 Train_Acc: 76.074 Val_Loss: 0.5294  BEST VAL Loss: 0.5294  Val_Acc: 76.845

Epoch 99: Validation loss did not decrease
	 Train_Loss: 0.5262 Train_Acc: 75.896 Val_Loss: 0.5296  BEST VAL Loss: 0.5294  Val_Acc: 77.273

Flagellin_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.36      0.41     50422
           1       0.53      0.64      0.58     56121

    accuracy                           0.51    106543
   macro avg       0.50      0.50      0.49    106543
weighted avg       0.50      0.51      0.50    106543

Flagellin_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.35      0.40      6303
           1       0.52      0.64      0.58      7016

    accuracy                           0.50     13319
   macro avg       0.50      0.50      0.49     13319
weighted avg       0.50      0.50      0.49     13319

Flagellin_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.35      0.40      6303
           1       0.52      0.64      0.57      7016

    accuracy                           0.50     13319
   macro avg       0.49      0.49      0.49     13319
weighted avg       0.49      0.50      0.49     13319

              precision    recall  f1-score   support

           0       0.46      0.35      0.40      6303
           1       0.52      0.64      0.57      7016

    accuracy                           0.50     13319
   macro avg       0.49      0.49      0.49     13319
weighted avg       0.49      0.50      0.49     13319

Flagellin_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.49      0.49     32887
           1       0.51      0.51      0.51     34394

    accuracy                           0.50     67281
   macro avg       0.50      0.50      0.50     67281
weighted avg       0.50      0.50      0.50     67281

              precision    recall  f1-score   support

           0       0.49      0.49      0.49     32887
           1       0.51      0.51      0.51     34394

    accuracy                           0.50     67281
   macro avg       0.50      0.50      0.50     67281
weighted avg       0.50      0.50      0.50     67281

completed
