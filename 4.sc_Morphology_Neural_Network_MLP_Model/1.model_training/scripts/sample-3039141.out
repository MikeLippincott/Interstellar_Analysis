[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '608f8779'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'ca208b6e'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'e7736607'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '35e8b564'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_0.100_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_0.100_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_0.100_DMSO_0.025']
The dimensions of the data are: (281677, 1270)
Number of total missing values across all columns: 563354
Data Subset Is Off
Wells held out for testing: ['B08' 'C08']
Wells to use for training, validation, and testing ['B02' 'C02' 'B03' 'C03' 'B09' 'C09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.684616).  Saving model ...
	 Train_Loss: 0.6915 Train_Acc: 52.488 Val_Loss: 0.6846  BEST VAL Loss: 0.6846  Val_Acc: 54.314

Epoch 1: Validation loss decreased (0.684616 --> 0.682078).  Saving model ...
	 Train_Loss: 0.6870 Train_Acc: 54.744 Val_Loss: 0.6821  BEST VAL Loss: 0.6821  Val_Acc: 55.624

Epoch 2: Validation loss decreased (0.682078 --> 0.679501).  Saving model ...
	 Train_Loss: 0.6839 Train_Acc: 55.955 Val_Loss: 0.6795  BEST VAL Loss: 0.6795  Val_Acc: 56.900

Epoch 3: Validation loss decreased (0.679501 --> 0.677174).  Saving model ...
	 Train_Loss: 0.6809 Train_Acc: 56.853 Val_Loss: 0.6772  BEST VAL Loss: 0.6772  Val_Acc: 57.329

Epoch 4: Validation loss decreased (0.677174 --> 0.674802).  Saving model ...
	 Train_Loss: 0.6783 Train_Acc: 57.470 Val_Loss: 0.6748  BEST VAL Loss: 0.6748  Val_Acc: 58.319

Epoch 5: Validation loss decreased (0.674802 --> 0.672646).  Saving model ...
	 Train_Loss: 0.6760 Train_Acc: 57.998 Val_Loss: 0.6726  BEST VAL Loss: 0.6726  Val_Acc: 59.443

Epoch 6: Validation loss decreased (0.672646 --> 0.670655).  Saving model ...
	 Train_Loss: 0.6738 Train_Acc: 58.598 Val_Loss: 0.6707  BEST VAL Loss: 0.6707  Val_Acc: 59.619

Epoch 7: Validation loss decreased (0.670655 --> 0.668783).  Saving model ...
	 Train_Loss: 0.6719 Train_Acc: 58.736 Val_Loss: 0.6688  BEST VAL Loss: 0.6688  Val_Acc: 60.000

Epoch 8: Validation loss decreased (0.668783 --> 0.666987).  Saving model ...
	 Train_Loss: 0.6702 Train_Acc: 59.142 Val_Loss: 0.6670  BEST VAL Loss: 0.6670  Val_Acc: 60.500

Epoch 9: Validation loss decreased (0.666987 --> 0.665428).  Saving model ...
	 Train_Loss: 0.6686 Train_Acc: 59.397 Val_Loss: 0.6654  BEST VAL Loss: 0.6654  Val_Acc: 60.805

Epoch 10: Validation loss decreased (0.665428 --> 0.663998).  Saving model ...
	 Train_Loss: 0.6671 Train_Acc: 59.732 Val_Loss: 0.6640  BEST VAL Loss: 0.6640  Val_Acc: 60.967

Epoch 11: Validation loss decreased (0.663998 --> 0.662794).  Saving model ...
	 Train_Loss: 0.6657 Train_Acc: 59.756 Val_Loss: 0.6628  BEST VAL Loss: 0.6628  Val_Acc: 60.705

Epoch 12: Validation loss decreased (0.662794 --> 0.661534).  Saving model ...
	 Train_Loss: 0.6644 Train_Acc: 59.990 Val_Loss: 0.6615  BEST VAL Loss: 0.6615  Val_Acc: 61.200

Epoch 13: Validation loss decreased (0.661534 --> 0.660366).  Saving model ...
	 Train_Loss: 0.6632 Train_Acc: 60.307 Val_Loss: 0.6604  BEST VAL Loss: 0.6604  Val_Acc: 61.586

Epoch 14: Validation loss decreased (0.660366 --> 0.659230).  Saving model ...
	 Train_Loss: 0.6620 Train_Acc: 60.358 Val_Loss: 0.6592  BEST VAL Loss: 0.6592  Val_Acc: 61.190

Epoch 15: Validation loss decreased (0.659230 --> 0.658024).  Saving model ...
	 Train_Loss: 0.6609 Train_Acc: 60.431 Val_Loss: 0.6580  BEST VAL Loss: 0.6580  Val_Acc: 61.600

Epoch 16: Validation loss decreased (0.658024 --> 0.656979).  Saving model ...
	 Train_Loss: 0.6599 Train_Acc: 60.423 Val_Loss: 0.6570  BEST VAL Loss: 0.6570  Val_Acc: 61.662

Epoch 17: Validation loss decreased (0.656979 --> 0.656054).  Saving model ...
	 Train_Loss: 0.6588 Train_Acc: 60.892 Val_Loss: 0.6561  BEST VAL Loss: 0.6561  Val_Acc: 61.871

Epoch 18: Validation loss decreased (0.656054 --> 0.655120).  Saving model ...
	 Train_Loss: 0.6579 Train_Acc: 60.725 Val_Loss: 0.6551  BEST VAL Loss: 0.6551  Val_Acc: 62.124

Epoch 19: Validation loss decreased (0.655120 --> 0.654035).  Saving model ...
	 Train_Loss: 0.6569 Train_Acc: 61.264 Val_Loss: 0.6540  BEST VAL Loss: 0.6540  Val_Acc: 62.195

Epoch 20: Validation loss decreased (0.654035 --> 0.653151).  Saving model ...
	 Train_Loss: 0.6560 Train_Acc: 61.251 Val_Loss: 0.6532  BEST VAL Loss: 0.6532  Val_Acc: 62.514

Epoch 21: Validation loss decreased (0.653151 --> 0.652221).  Saving model ...
	 Train_Loss: 0.6551 Train_Acc: 61.360 Val_Loss: 0.6522  BEST VAL Loss: 0.6522  Val_Acc: 62.690

Epoch 22: Validation loss decreased (0.652221 --> 0.651301).  Saving model ...
	 Train_Loss: 0.6542 Train_Acc: 61.604 Val_Loss: 0.6513  BEST VAL Loss: 0.6513  Val_Acc: 63.043

Epoch 23: Validation loss decreased (0.651301 --> 0.650487).  Saving model ...
	 Train_Loss: 0.6533 Train_Acc: 61.778 Val_Loss: 0.6505  BEST VAL Loss: 0.6505  Val_Acc: 62.881

Epoch 24: Validation loss decreased (0.650487 --> 0.649568).  Saving model ...
	 Train_Loss: 0.6524 Train_Acc: 61.956 Val_Loss: 0.6496  BEST VAL Loss: 0.6496  Val_Acc: 63.381

Epoch 25: Validation loss decreased (0.649568 --> 0.648671).  Saving model ...
	 Train_Loss: 0.6516 Train_Acc: 62.101 Val_Loss: 0.6487  BEST VAL Loss: 0.6487  Val_Acc: 63.557

Epoch 26: Validation loss decreased (0.648671 --> 0.647906).  Saving model ...
	 Train_Loss: 0.6507 Train_Acc: 62.369 Val_Loss: 0.6479  BEST VAL Loss: 0.6479  Val_Acc: 63.190

Epoch 27: Validation loss decreased (0.647906 --> 0.647038).  Saving model ...
	 Train_Loss: 0.6499 Train_Acc: 62.431 Val_Loss: 0.6470  BEST VAL Loss: 0.6470  Val_Acc: 63.629

Epoch 28: Validation loss decreased (0.647038 --> 0.646177).  Saving model ...
	 Train_Loss: 0.6491 Train_Acc: 62.382 Val_Loss: 0.6462  BEST VAL Loss: 0.6462  Val_Acc: 64.100

Epoch 29: Validation loss decreased (0.646177 --> 0.645367).  Saving model ...
	 Train_Loss: 0.6483 Train_Acc: 62.888 Val_Loss: 0.6454  BEST VAL Loss: 0.6454  Val_Acc: 64.071

Epoch 30: Validation loss decreased (0.645367 --> 0.644525).  Saving model ...
	 Train_Loss: 0.6475 Train_Acc: 62.978 Val_Loss: 0.6445  BEST VAL Loss: 0.6445  Val_Acc: 64.586

Epoch 31: Validation loss decreased (0.644525 --> 0.643714).  Saving model ...
	 Train_Loss: 0.6467 Train_Acc: 63.023 Val_Loss: 0.6437  BEST VAL Loss: 0.6437  Val_Acc: 64.405

Epoch 32: Validation loss decreased (0.643714 --> 0.642886).  Saving model ...
	 Train_Loss: 0.6458 Train_Acc: 63.230 Val_Loss: 0.6429  BEST VAL Loss: 0.6429  Val_Acc: 64.681

Epoch 33: Validation loss decreased (0.642886 --> 0.642057).  Saving model ...
	 Train_Loss: 0.6450 Train_Acc: 63.428 Val_Loss: 0.6421  BEST VAL Loss: 0.6421  Val_Acc: 64.814

Epoch 34: Validation loss decreased (0.642057 --> 0.641229).  Saving model ...
	 Train_Loss: 0.6442 Train_Acc: 63.432 Val_Loss: 0.6412  BEST VAL Loss: 0.6412  Val_Acc: 64.752

Epoch 35: Validation loss decreased (0.641229 --> 0.640392).  Saving model ...
	 Train_Loss: 0.6434 Train_Acc: 63.421 Val_Loss: 0.6404  BEST VAL Loss: 0.6404  Val_Acc: 65.338

Epoch 36: Validation loss decreased (0.640392 --> 0.639558).  Saving model ...
	 Train_Loss: 0.6427 Train_Acc: 63.394 Val_Loss: 0.6396  BEST VAL Loss: 0.6396  Val_Acc: 65.581

Epoch 37: Validation loss decreased (0.639558 --> 0.638774).  Saving model ...
	 Train_Loss: 0.6419 Train_Acc: 63.663 Val_Loss: 0.6388  BEST VAL Loss: 0.6388  Val_Acc: 65.638

Epoch 38: Validation loss decreased (0.638774 --> 0.637938).  Saving model ...
	 Train_Loss: 0.6411 Train_Acc: 63.690 Val_Loss: 0.6379  BEST VAL Loss: 0.6379  Val_Acc: 66.038

Epoch 39: Validation loss decreased (0.637938 --> 0.637217).  Saving model ...
	 Train_Loss: 0.6404 Train_Acc: 63.933 Val_Loss: 0.6372  BEST VAL Loss: 0.6372  Val_Acc: 65.719

Epoch 40: Validation loss decreased (0.637217 --> 0.636404).  Saving model ...
	 Train_Loss: 0.6396 Train_Acc: 64.027 Val_Loss: 0.6364  BEST VAL Loss: 0.6364  Val_Acc: 66.248

Epoch 41: Validation loss decreased (0.636404 --> 0.635654).  Saving model ...
	 Train_Loss: 0.6388 Train_Acc: 64.192 Val_Loss: 0.6357  BEST VAL Loss: 0.6357  Val_Acc: 66.290

Epoch 42: Validation loss decreased (0.635654 --> 0.634896).  Saving model ...
	 Train_Loss: 0.6381 Train_Acc: 64.105 Val_Loss: 0.6349  BEST VAL Loss: 0.6349  Val_Acc: 66.348

Epoch 43: Validation loss decreased (0.634896 --> 0.634181).  Saving model ...
	 Train_Loss: 0.6374 Train_Acc: 64.244 Val_Loss: 0.6342  BEST VAL Loss: 0.6342  Val_Acc: 65.852

Epoch 44: Validation loss decreased (0.634181 --> 0.633430).  Saving model ...
	 Train_Loss: 0.6367 Train_Acc: 64.126 Val_Loss: 0.6334  BEST VAL Loss: 0.6334  Val_Acc: 66.695

Epoch 45: Validation loss decreased (0.633430 --> 0.632774).  Saving model ...
	 Train_Loss: 0.6360 Train_Acc: 64.209 Val_Loss: 0.6328  BEST VAL Loss: 0.6328  Val_Acc: 66.410

Epoch 46: Validation loss decreased (0.632774 --> 0.632021).  Saving model ...
	 Train_Loss: 0.6353 Train_Acc: 64.387 Val_Loss: 0.6320  BEST VAL Loss: 0.6320  Val_Acc: 66.457

Epoch 47: Validation loss decreased (0.632021 --> 0.631370).  Saving model ...
	 Train_Loss: 0.6346 Train_Acc: 64.456 Val_Loss: 0.6314  BEST VAL Loss: 0.6314  Val_Acc: 66.119

Epoch 48: Validation loss decreased (0.631370 --> 0.630643).  Saving model ...
	 Train_Loss: 0.6339 Train_Acc: 64.448 Val_Loss: 0.6306  BEST VAL Loss: 0.6306  Val_Acc: 66.843

Epoch 49: Validation loss decreased (0.630643 --> 0.629954).  Saving model ...
	 Train_Loss: 0.6333 Train_Acc: 64.374 Val_Loss: 0.6300  BEST VAL Loss: 0.6300  Val_Acc: 66.795

Epoch 50: Validation loss decreased (0.629954 --> 0.629227).  Saving model ...
	 Train_Loss: 0.6326 Train_Acc: 64.598 Val_Loss: 0.6292  BEST VAL Loss: 0.6292  Val_Acc: 66.776

Epoch 51: Validation loss decreased (0.629227 --> 0.628549).  Saving model ...
	 Train_Loss: 0.6319 Train_Acc: 64.412 Val_Loss: 0.6285  BEST VAL Loss: 0.6285  Val_Acc: 67.376

Epoch 52: Validation loss decreased (0.628549 --> 0.627821).  Saving model ...
	 Train_Loss: 0.6313 Train_Acc: 64.746 Val_Loss: 0.6278  BEST VAL Loss: 0.6278  Val_Acc: 67.481

Epoch 53: Validation loss decreased (0.627821 --> 0.627221).  Saving model ...
	 Train_Loss: 0.6307 Train_Acc: 64.583 Val_Loss: 0.6272  BEST VAL Loss: 0.6272  Val_Acc: 66.700

Epoch 54: Validation loss decreased (0.627221 --> 0.626549).  Saving model ...
	 Train_Loss: 0.6301 Train_Acc: 64.615 Val_Loss: 0.6265  BEST VAL Loss: 0.6265  Val_Acc: 67.114

Epoch 55: Validation loss decreased (0.626549 --> 0.625991).  Saving model ...
	 Train_Loss: 0.6294 Train_Acc: 64.485 Val_Loss: 0.6260  BEST VAL Loss: 0.6260  Val_Acc: 66.767

Epoch 56: Validation loss decreased (0.625991 --> 0.625332).  Saving model ...
	 Train_Loss: 0.6288 Train_Acc: 64.702 Val_Loss: 0.6253  BEST VAL Loss: 0.6253  Val_Acc: 67.114

Epoch 57: Validation loss decreased (0.625332 --> 0.624715).  Saving model ...
	 Train_Loss: 0.6282 Train_Acc: 64.706 Val_Loss: 0.6247  BEST VAL Loss: 0.6247  Val_Acc: 67.119

Epoch 58: Validation loss decreased (0.624715 --> 0.624071).  Saving model ...
	 Train_Loss: 0.6276 Train_Acc: 64.662 Val_Loss: 0.6241  BEST VAL Loss: 0.6241  Val_Acc: 67.457

Epoch 59: Validation loss decreased (0.624071 --> 0.623479).  Saving model ...
	 Train_Loss: 0.6270 Train_Acc: 64.782 Val_Loss: 0.6235  BEST VAL Loss: 0.6235  Val_Acc: 66.810

Epoch 60: Validation loss decreased (0.623479 --> 0.622885).  Saving model ...
	 Train_Loss: 0.6265 Train_Acc: 64.721 Val_Loss: 0.6229  BEST VAL Loss: 0.6229  Val_Acc: 66.876

Epoch 61: Validation loss decreased (0.622885 --> 0.622277).  Saving model ...
	 Train_Loss: 0.6259 Train_Acc: 64.769 Val_Loss: 0.6223  BEST VAL Loss: 0.6223  Val_Acc: 67.529

Epoch 62: Validation loss decreased (0.622277 --> 0.621728).  Saving model ...
	 Train_Loss: 0.6253 Train_Acc: 64.791 Val_Loss: 0.6217  BEST VAL Loss: 0.6217  Val_Acc: 67.729

Epoch 63: Validation loss decreased (0.621728 --> 0.621133).  Saving model ...
	 Train_Loss: 0.6247 Train_Acc: 64.802 Val_Loss: 0.6211  BEST VAL Loss: 0.6211  Val_Acc: 68.005

Epoch 64: Validation loss decreased (0.621133 --> 0.620549).  Saving model ...
	 Train_Loss: 0.6242 Train_Acc: 64.831 Val_Loss: 0.6205  BEST VAL Loss: 0.6205  Val_Acc: 67.648

Epoch 65: Validation loss decreased (0.620549 --> 0.619983).  Saving model ...
	 Train_Loss: 0.6236 Train_Acc: 64.777 Val_Loss: 0.6200  BEST VAL Loss: 0.6200  Val_Acc: 67.562

Epoch 66: Validation loss decreased (0.619983 --> 0.619422).  Saving model ...
	 Train_Loss: 0.6231 Train_Acc: 64.818 Val_Loss: 0.6194  BEST VAL Loss: 0.6194  Val_Acc: 67.524

Epoch 67: Validation loss decreased (0.619422 --> 0.618849).  Saving model ...
	 Train_Loss: 0.6226 Train_Acc: 64.830 Val_Loss: 0.6188  BEST VAL Loss: 0.6188  Val_Acc: 68.024

Epoch 68: Validation loss decreased (0.618849 --> 0.618331).  Saving model ...
	 Train_Loss: 0.6221 Train_Acc: 64.859 Val_Loss: 0.6183  BEST VAL Loss: 0.6183  Val_Acc: 67.514

Epoch 69: Validation loss decreased (0.618331 --> 0.617788).  Saving model ...
	 Train_Loss: 0.6216 Train_Acc: 64.916 Val_Loss: 0.6178  BEST VAL Loss: 0.6178  Val_Acc: 67.624

Epoch 70: Validation loss decreased (0.617788 --> 0.617216).  Saving model ...
	 Train_Loss: 0.6210 Train_Acc: 65.070 Val_Loss: 0.6172  BEST VAL Loss: 0.6172  Val_Acc: 68.024

Epoch 71: Validation loss decreased (0.617216 --> 0.616643).  Saving model ...
	 Train_Loss: 0.6205 Train_Acc: 65.035 Val_Loss: 0.6166  BEST VAL Loss: 0.6166  Val_Acc: 67.976

Epoch 72: Validation loss decreased (0.616643 --> 0.616157).  Saving model ...
	 Train_Loss: 0.6200 Train_Acc: 65.041 Val_Loss: 0.6162  BEST VAL Loss: 0.6162  Val_Acc: 67.781

Epoch 73: Validation loss decreased (0.616157 --> 0.615614).  Saving model ...
	 Train_Loss: 0.6196 Train_Acc: 65.167 Val_Loss: 0.6156  BEST VAL Loss: 0.6156  Val_Acc: 68.152

Epoch 74: Validation loss decreased (0.615614 --> 0.615084).  Saving model ...
	 Train_Loss: 0.6191 Train_Acc: 65.214 Val_Loss: 0.6151  BEST VAL Loss: 0.6151  Val_Acc: 68.086

Epoch 75: Validation loss decreased (0.615084 --> 0.614595).  Saving model ...
	 Train_Loss: 0.6186 Train_Acc: 65.378 Val_Loss: 0.6146  BEST VAL Loss: 0.6146  Val_Acc: 68.167

Epoch 76: Validation loss decreased (0.614595 --> 0.614116).  Saving model ...
	 Train_Loss: 0.6181 Train_Acc: 65.256 Val_Loss: 0.6141  BEST VAL Loss: 0.6141  Val_Acc: 68.162

Epoch 77: Validation loss decreased (0.614116 --> 0.613663).  Saving model ...
	 Train_Loss: 0.6177 Train_Acc: 65.425 Val_Loss: 0.6137  BEST VAL Loss: 0.6137  Val_Acc: 68.748

Epoch 78: Validation loss decreased (0.613663 --> 0.613190).  Saving model ...
	 Train_Loss: 0.6172 Train_Acc: 65.405 Val_Loss: 0.6132  BEST VAL Loss: 0.6132  Val_Acc: 68.448

Epoch 79: Validation loss decreased (0.613190 --> 0.612761).  Saving model ...
	 Train_Loss: 0.6168 Train_Acc: 65.399 Val_Loss: 0.6128  BEST VAL Loss: 0.6128  Val_Acc: 68.476

Epoch 80: Validation loss decreased (0.612761 --> 0.612295).  Saving model ...
	 Train_Loss: 0.6164 Train_Acc: 65.409 Val_Loss: 0.6123  BEST VAL Loss: 0.6123  Val_Acc: 68.590

Epoch 81: Validation loss decreased (0.612295 --> 0.611823).  Saving model ...
	 Train_Loss: 0.6159 Train_Acc: 65.394 Val_Loss: 0.6118  BEST VAL Loss: 0.6118  Val_Acc: 67.952

Epoch 82: Validation loss decreased (0.611823 --> 0.611358).  Saving model ...
	 Train_Loss: 0.6155 Train_Acc: 65.473 Val_Loss: 0.6114  BEST VAL Loss: 0.6114  Val_Acc: 68.481

Epoch 83: Validation loss decreased (0.611358 --> 0.610922).  Saving model ...
	 Train_Loss: 0.6151 Train_Acc: 65.721 Val_Loss: 0.6109  BEST VAL Loss: 0.6109  Val_Acc: 68.224

Epoch 84: Validation loss decreased (0.610922 --> 0.610514).  Saving model ...
	 Train_Loss: 0.6147 Train_Acc: 65.534 Val_Loss: 0.6105  BEST VAL Loss: 0.6105  Val_Acc: 68.376

Epoch 85: Validation loss decreased (0.610514 --> 0.610081).  Saving model ...
	 Train_Loss: 0.6143 Train_Acc: 65.484 Val_Loss: 0.6101  BEST VAL Loss: 0.6101  Val_Acc: 68.533

Epoch 86: Validation loss decreased (0.610081 --> 0.609701).  Saving model ...
	 Train_Loss: 0.6139 Train_Acc: 65.582 Val_Loss: 0.6097  BEST VAL Loss: 0.6097  Val_Acc: 68.671

Epoch 87: Validation loss decreased (0.609701 --> 0.609310).  Saving model ...
	 Train_Loss: 0.6135 Train_Acc: 65.646 Val_Loss: 0.6093  BEST VAL Loss: 0.6093  Val_Acc: 68.733

Epoch 88: Validation loss decreased (0.609310 --> 0.608903).  Saving model ...
	 Train_Loss: 0.6131 Train_Acc: 65.751 Val_Loss: 0.6089  BEST VAL Loss: 0.6089  Val_Acc: 68.424

Epoch 89: Validation loss decreased (0.608903 --> 0.608509).  Saving model ...
	 Train_Loss: 0.6127 Train_Acc: 65.646 Val_Loss: 0.6085  BEST VAL Loss: 0.6085  Val_Acc: 68.433

Epoch 90: Validation loss decreased (0.608509 --> 0.608122).  Saving model ...
	 Train_Loss: 0.6123 Train_Acc: 65.637 Val_Loss: 0.6081  BEST VAL Loss: 0.6081  Val_Acc: 68.352

Epoch 91: Validation loss decreased (0.608122 --> 0.607711).  Saving model ...
	 Train_Loss: 0.6119 Train_Acc: 65.856 Val_Loss: 0.6077  BEST VAL Loss: 0.6077  Val_Acc: 68.414

Epoch 92: Validation loss decreased (0.607711 --> 0.607352).  Saving model ...
	 Train_Loss: 0.6115 Train_Acc: 65.722 Val_Loss: 0.6074  BEST VAL Loss: 0.6074  Val_Acc: 68.533

Epoch 93: Validation loss decreased (0.607352 --> 0.606959).  Saving model ...
	 Train_Loss: 0.6111 Train_Acc: 65.823 Val_Loss: 0.6070  BEST VAL Loss: 0.6070  Val_Acc: 68.567

Epoch 94: Validation loss decreased (0.606959 --> 0.606593).  Saving model ...
	 Train_Loss: 0.6108 Train_Acc: 65.772 Val_Loss: 0.6066  BEST VAL Loss: 0.6066  Val_Acc: 69.029

Epoch 95: Validation loss decreased (0.606593 --> 0.606236).  Saving model ...
	 Train_Loss: 0.6104 Train_Acc: 65.680 Val_Loss: 0.6062  BEST VAL Loss: 0.6062  Val_Acc: 68.624

Epoch 96: Validation loss decreased (0.606236 --> 0.605877).  Saving model ...
	 Train_Loss: 0.6100 Train_Acc: 65.775 Val_Loss: 0.6059  BEST VAL Loss: 0.6059  Val_Acc: 68.552

Epoch 97: Validation loss decreased (0.605877 --> 0.605528).  Saving model ...
	 Train_Loss: 0.6097 Train_Acc: 65.906 Val_Loss: 0.6055  BEST VAL Loss: 0.6055  Val_Acc: 68.762

Epoch 98: Validation loss decreased (0.605528 --> 0.605174).  Saving model ...
	 Train_Loss: 0.6093 Train_Acc: 65.958 Val_Loss: 0.6052  BEST VAL Loss: 0.6052  Val_Acc: 68.519

Epoch 99: Validation loss decreased (0.605174 --> 0.604846).  Saving model ...
	 Train_Loss: 0.6090 Train_Acc: 65.681 Val_Loss: 0.6048  BEST VAL Loss: 0.6048  Val_Acc: 68.705

LPS_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.45      0.48     85025
           1       0.49      0.55      0.52     82968

    accuracy                           0.50    167993
   macro avg       0.50      0.50      0.50    167993
weighted avg       0.50      0.50      0.50    167993

LPS_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.44      0.47     10629
           1       0.49      0.55      0.52     10371

    accuracy                           0.50     21000
   macro avg       0.50      0.50      0.49     21000
weighted avg       0.50      0.50      0.49     21000

LPS_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.46      0.48     10629
           1       0.50      0.55      0.52     10371

    accuracy                           0.50     21000
   macro avg       0.51      0.50      0.50     21000
weighted avg       0.51      0.50      0.50     21000

              precision    recall  f1-score   support

           0       0.51      0.46      0.48     10629
           1       0.50      0.55      0.52     10371

    accuracy                           0.50     21000
   macro avg       0.51      0.50      0.50     21000
weighted avg       0.51      0.50      0.50     21000

LPS_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.28      0.36     36797
           1       0.49      0.72      0.58     34887

    accuracy                           0.49     71684
   macro avg       0.50      0.50      0.47     71684
weighted avg       0.50      0.49      0.47     71684

              precision    recall  f1-score   support

           0       0.51      0.28      0.36     36797
           1       0.49      0.72      0.58     34887

    accuracy                           0.49     71684
   macro avg       0.50      0.50      0.47     71684
weighted avg       0.50      0.49      0.47     71684

completed
