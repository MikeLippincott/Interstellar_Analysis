[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '337924db'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'c69ab3d8'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '9b983c4f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e8101a3d'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (30261, 1276)
Number of total missing values across all columns: 31718
Data Subset Is Off
Wells held out for testing: ['B20' 'M16']
Wells to use for training, validation, and testing ['B16' 'B17' 'B21' 'M17' 'M20' 'M21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.200279).  Saving model ...
	 Train_Loss: 0.3691 Train_Acc: 82.661 Val_Loss: 0.2003  BEST VAL Loss: 0.2003  Val_Acc: 91.714

Epoch 1: Validation loss decreased (0.200279 --> 0.168441).  Saving model ...
	 Train_Loss: 0.3017 Train_Acc: 89.638 Val_Loss: 0.1684  BEST VAL Loss: 0.1684  Val_Acc: 94.447

Epoch 2: Validation loss decreased (0.168441 --> 0.152096).  Saving model ...
	 Train_Loss: 0.2627 Train_Acc: 91.953 Val_Loss: 0.1521  BEST VAL Loss: 0.1521  Val_Acc: 95.681

Epoch 3: Validation loss decreased (0.152096 --> 0.141398).  Saving model ...
	 Train_Loss: 0.2368 Train_Acc: 92.984 Val_Loss: 0.1414  BEST VAL Loss: 0.1414  Val_Acc: 96.210

Epoch 4: Validation loss decreased (0.141398 --> 0.133600).  Saving model ...
	 Train_Loss: 0.2184 Train_Acc: 93.700 Val_Loss: 0.1336  BEST VAL Loss: 0.1336  Val_Acc: 96.827

Epoch 5: Validation loss decreased (0.133600 --> 0.130198).  Saving model ...
	 Train_Loss: 0.2050 Train_Acc: 93.695 Val_Loss: 0.1302  BEST VAL Loss: 0.1302  Val_Acc: 96.739

Epoch 6: Validation loss decreased (0.130198 --> 0.125175).  Saving model ...
	 Train_Loss: 0.1936 Train_Acc: 94.406 Val_Loss: 0.1252  BEST VAL Loss: 0.1252  Val_Acc: 97.047

Epoch 7: Validation loss decreased (0.125175 --> 0.121060).  Saving model ...
	 Train_Loss: 0.1847 Train_Acc: 94.422 Val_Loss: 0.1211  BEST VAL Loss: 0.1211  Val_Acc: 97.091

Epoch 8: Validation loss decreased (0.121060 --> 0.116988).  Saving model ...
	 Train_Loss: 0.1771 Train_Acc: 94.654 Val_Loss: 0.1170  BEST VAL Loss: 0.1170  Val_Acc: 97.135

Epoch 9: Validation loss decreased (0.116988 --> 0.113695).  Saving model ...
	 Train_Loss: 0.1705 Train_Acc: 94.996 Val_Loss: 0.1137  BEST VAL Loss: 0.1137  Val_Acc: 97.003

Epoch 10: Validation loss decreased (0.113695 --> 0.110645).  Saving model ...
	 Train_Loss: 0.1650 Train_Acc: 94.858 Val_Loss: 0.1106  BEST VAL Loss: 0.1106  Val_Acc: 97.003

Epoch 11: Validation loss decreased (0.110645 --> 0.109542).  Saving model ...
	 Train_Loss: 0.1597 Train_Acc: 95.144 Val_Loss: 0.1095  BEST VAL Loss: 0.1095  Val_Acc: 97.135

Epoch 12: Validation loss decreased (0.109542 --> 0.107439).  Saving model ...
	 Train_Loss: 0.1550 Train_Acc: 95.211 Val_Loss: 0.1074  BEST VAL Loss: 0.1074  Val_Acc: 97.444

Epoch 13: Validation loss decreased (0.107439 --> 0.106215).  Saving model ...
	 Train_Loss: 0.1509 Train_Acc: 95.183 Val_Loss: 0.1062  BEST VAL Loss: 0.1062  Val_Acc: 97.356

Epoch 14: Validation loss decreased (0.106215 --> 0.103735).  Saving model ...
	 Train_Loss: 0.1472 Train_Acc: 95.448 Val_Loss: 0.1037  BEST VAL Loss: 0.1037  Val_Acc: 97.400

Epoch 15: Validation loss did not decrease
	 Train_Loss: 0.1440 Train_Acc: 95.503 Val_Loss: 0.1040  BEST VAL Loss: 0.1037  Val_Acc: 97.444

Epoch 16: Validation loss decreased (0.103735 --> 0.102557).  Saving model ...
	 Train_Loss: 0.1410 Train_Acc: 95.541 Val_Loss: 0.1026  BEST VAL Loss: 0.1026  Val_Acc: 97.223

Epoch 17: Validation loss decreased (0.102557 --> 0.102398).  Saving model ...
	 Train_Loss: 0.1377 Train_Acc: 95.927 Val_Loss: 0.1024  BEST VAL Loss: 0.1024  Val_Acc: 97.488

Epoch 18: Validation loss decreased (0.102398 --> 0.102329).  Saving model ...
	 Train_Loss: 0.1349 Train_Acc: 95.784 Val_Loss: 0.1023  BEST VAL Loss: 0.1023  Val_Acc: 97.179

Epoch 19: Validation loss decreased (0.102329 --> 0.101743).  Saving model ...
	 Train_Loss: 0.1329 Train_Acc: 95.547 Val_Loss: 0.1017  BEST VAL Loss: 0.1017  Val_Acc: 97.752

Epoch 20: Validation loss did not decrease
	 Train_Loss: 0.1308 Train_Acc: 95.613 Val_Loss: 0.1018  BEST VAL Loss: 0.1017  Val_Acc: 97.356

Epoch 21: Validation loss decreased (0.101743 --> 0.100563).  Saving model ...
	 Train_Loss: 0.1287 Train_Acc: 95.762 Val_Loss: 0.1006  BEST VAL Loss: 0.1006  Val_Acc: 97.400

Epoch 22: Validation loss decreased (0.100563 --> 0.100102).  Saving model ...
	 Train_Loss: 0.1266 Train_Acc: 95.993 Val_Loss: 0.1001  BEST VAL Loss: 0.1001  Val_Acc: 97.356

Epoch 23: Validation loss decreased (0.100102 --> 0.098418).  Saving model ...
	 Train_Loss: 0.1245 Train_Acc: 96.021 Val_Loss: 0.0984  BEST VAL Loss: 0.0984  Val_Acc: 97.752

Epoch 24: Validation loss decreased (0.098418 --> 0.097672).  Saving model ...
	 Train_Loss: 0.1227 Train_Acc: 95.988 Val_Loss: 0.0977  BEST VAL Loss: 0.0977  Val_Acc: 97.973

Epoch 25: Validation loss decreased (0.097672 --> 0.096740).  Saving model ...
	 Train_Loss: 0.1211 Train_Acc: 95.784 Val_Loss: 0.0967  BEST VAL Loss: 0.0967  Val_Acc: 97.312

Epoch 26: Validation loss decreased (0.096740 --> 0.095952).  Saving model ...
	 Train_Loss: 0.1196 Train_Acc: 95.701 Val_Loss: 0.0960  BEST VAL Loss: 0.0960  Val_Acc: 97.620

Epoch 27: Validation loss decreased (0.095952 --> 0.095158).  Saving model ...
	 Train_Loss: 0.1181 Train_Acc: 96.065 Val_Loss: 0.0952  BEST VAL Loss: 0.0952  Val_Acc: 97.444

Epoch 28: Validation loss decreased (0.095158 --> 0.094560).  Saving model ...
	 Train_Loss: 0.1165 Train_Acc: 96.098 Val_Loss: 0.0946  BEST VAL Loss: 0.0946  Val_Acc: 97.444

Epoch 29: Validation loss decreased (0.094560 --> 0.094161).  Saving model ...
	 Train_Loss: 0.1150 Train_Acc: 96.302 Val_Loss: 0.0942  BEST VAL Loss: 0.0942  Val_Acc: 97.400

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.1135 Train_Acc: 96.484 Val_Loss: 0.0949  BEST VAL Loss: 0.0942  Val_Acc: 97.885

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.1123 Train_Acc: 95.883 Val_Loss: 0.0946  BEST VAL Loss: 0.0942  Val_Acc: 97.664

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.1113 Train_Acc: 95.762 Val_Loss: 0.0944  BEST VAL Loss: 0.0942  Val_Acc: 97.973

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.1101 Train_Acc: 96.059 Val_Loss: 0.0942  BEST VAL Loss: 0.0942  Val_Acc: 97.576

Epoch 34: Validation loss decreased (0.094161 --> 0.093574).  Saving model ...
	 Train_Loss: 0.1091 Train_Acc: 96.247 Val_Loss: 0.0936  BEST VAL Loss: 0.0936  Val_Acc: 97.576

Epoch 35: Validation loss decreased (0.093574 --> 0.093467).  Saving model ...
	 Train_Loss: 0.1081 Train_Acc: 95.922 Val_Loss: 0.0935  BEST VAL Loss: 0.0935  Val_Acc: 97.268

Epoch 36: Validation loss decreased (0.093467 --> 0.093207).  Saving model ...
	 Train_Loss: 0.1071 Train_Acc: 96.638 Val_Loss: 0.0932  BEST VAL Loss: 0.0932  Val_Acc: 97.576

Epoch 37: Validation loss decreased (0.093207 --> 0.092759).  Saving model ...
	 Train_Loss: 0.1063 Train_Acc: 95.839 Val_Loss: 0.0928  BEST VAL Loss: 0.0928  Val_Acc: 97.488

Epoch 38: Validation loss decreased (0.092759 --> 0.092567).  Saving model ...
	 Train_Loss: 0.1054 Train_Acc: 95.916 Val_Loss: 0.0926  BEST VAL Loss: 0.0926  Val_Acc: 97.444

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.1044 Train_Acc: 96.522 Val_Loss: 0.0929  BEST VAL Loss: 0.0926  Val_Acc: 97.929

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.1034 Train_Acc: 96.489 Val_Loss: 0.0929  BEST VAL Loss: 0.0926  Val_Acc: 97.796

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.1024 Train_Acc: 96.318 Val_Loss: 0.0928  BEST VAL Loss: 0.0926  Val_Acc: 97.532

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.1016 Train_Acc: 96.004 Val_Loss: 0.0930  BEST VAL Loss: 0.0926  Val_Acc: 97.488

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.1008 Train_Acc: 96.142 Val_Loss: 0.0927  BEST VAL Loss: 0.0926  Val_Acc: 97.312

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.1001 Train_Acc: 96.318 Val_Loss: 0.0928  BEST VAL Loss: 0.0926  Val_Acc: 97.885

Epoch 45: Validation loss decreased (0.092567 --> 0.092494).  Saving model ...
	 Train_Loss: 0.0993 Train_Acc: 96.302 Val_Loss: 0.0925  BEST VAL Loss: 0.0925  Val_Acc: 97.929

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.0986 Train_Acc: 96.401 Val_Loss: 0.0926  BEST VAL Loss: 0.0925  Val_Acc: 97.708

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.0979 Train_Acc: 96.291 Val_Loss: 0.0930  BEST VAL Loss: 0.0925  Val_Acc: 97.444

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.0972 Train_Acc: 96.500 Val_Loss: 0.0930  BEST VAL Loss: 0.0925  Val_Acc: 97.620

Epoch 49: Validation loss decreased (0.092494 --> 0.092397).  Saving model ...
	 Train_Loss: 0.0966 Train_Acc: 96.429 Val_Loss: 0.0924  BEST VAL Loss: 0.0924  Val_Acc: 98.237

Epoch 50: Validation loss decreased (0.092397 --> 0.092199).  Saving model ...
	 Train_Loss: 0.0961 Train_Acc: 96.136 Val_Loss: 0.0922  BEST VAL Loss: 0.0922  Val_Acc: 98.061

Epoch 51: Validation loss decreased (0.092199 --> 0.091780).  Saving model ...
	 Train_Loss: 0.0955 Train_Acc: 96.478 Val_Loss: 0.0918  BEST VAL Loss: 0.0918  Val_Acc: 98.061

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.0949 Train_Acc: 96.324 Val_Loss: 0.0918  BEST VAL Loss: 0.0918  Val_Acc: 98.149

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.0944 Train_Acc: 96.318 Val_Loss: 0.0919  BEST VAL Loss: 0.0918  Val_Acc: 97.444

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.0937 Train_Acc: 96.533 Val_Loss: 0.0918  BEST VAL Loss: 0.0918  Val_Acc: 97.885

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.0931 Train_Acc: 96.517 Val_Loss: 0.0920  BEST VAL Loss: 0.0918  Val_Acc: 97.885

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.0925 Train_Acc: 96.710 Val_Loss: 0.0921  BEST VAL Loss: 0.0918  Val_Acc: 97.664

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.0919 Train_Acc: 96.688 Val_Loss: 0.0931  BEST VAL Loss: 0.0918  Val_Acc: 97.708

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.0913 Train_Acc: 96.572 Val_Loss: 0.0933  BEST VAL Loss: 0.0918  Val_Acc: 97.532

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.0908 Train_Acc: 96.396 Val_Loss: 0.0935  BEST VAL Loss: 0.0918  Val_Acc: 97.752

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.0902 Train_Acc: 96.947 Val_Loss: 0.0936  BEST VAL Loss: 0.0918  Val_Acc: 97.840

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.0896 Train_Acc: 96.627 Val_Loss: 0.0937  BEST VAL Loss: 0.0918  Val_Acc: 97.929

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.0891 Train_Acc: 96.748 Val_Loss: 0.0940  BEST VAL Loss: 0.0918  Val_Acc: 97.796

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.0886 Train_Acc: 96.919 Val_Loss: 0.0938  BEST VAL Loss: 0.0918  Val_Acc: 98.017

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.0881 Train_Acc: 96.550 Val_Loss: 0.0935  BEST VAL Loss: 0.0918  Val_Acc: 98.369

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.0877 Train_Acc: 96.814 Val_Loss: 0.0933  BEST VAL Loss: 0.0918  Val_Acc: 98.105

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.0873 Train_Acc: 96.627 Val_Loss: 0.0931  BEST VAL Loss: 0.0918  Val_Acc: 98.105

Epoch 67: Validation loss did not decrease
Early stopped at epoch : 67
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.54      0.54      0.54      9708
           1       0.47      0.47      0.47      8436

    accuracy                           0.51     18144
   macro avg       0.50      0.50      0.50     18144
weighted avg       0.51      0.51      0.51     18144

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.54      0.55      1214
           1       0.48      0.48      0.48      1055

    accuracy                           0.52      2269
   macro avg       0.51      0.51      0.51      2269
weighted avg       0.52      0.52      0.52      2269

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.54      0.54      0.54      1213
           1       0.47      0.47      0.47      1055

    accuracy                           0.51      2268
   macro avg       0.50      0.50      0.50      2268
weighted avg       0.51      0.51      0.51      2268

              precision    recall  f1-score   support

           0       0.54      0.54      0.54      1213
           1       0.47      0.47      0.47      1055

    accuracy                           0.51      2268
   macro avg       0.50      0.50      0.50      2268
weighted avg       0.51      0.51      0.51      2268

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.50      0.50      3724
           1       0.51      0.51      0.51      3856

    accuracy                           0.50      7580
   macro avg       0.50      0.50      0.50      7580
weighted avg       0.50      0.50      0.50      7580

              precision    recall  f1-score   support

           0       0.49      0.50      0.50      3724
           1       0.51      0.51      0.51      3856

    accuracy                           0.50      7580
   macro avg       0.50      0.50      0.50      7580
weighted avg       0.50      0.50      0.50      7580

completed
