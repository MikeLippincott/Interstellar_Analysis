[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '00e1eb7f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '486bbee1'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '794339c9'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '5885ed8c'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_0.100_DMSO_0.025 treatment_name: LPS_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_0.100_DMSO_0.025
TREATMENT_NAME: LPS_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_1.000_DMSO_0.025']
The dimensions of the data are: (33968, 1276)
Number of total missing values across all columns: 67936
Data Subset Is Off
Wells held out for testing: ['C20' 'D21']
Wells to use for training, validation, and testing ['C16' 'D16' 'C17' 'D17' 'D20' 'C21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.694076).  Saving model ...
	 Train_Loss: 0.6975 Train_Acc: 51.372 Val_Loss: 0.6941  BEST VAL Loss: 0.6941  Val_Acc: 52.422

Epoch 1: Validation loss decreased (0.694076 --> 0.691648).  Saving model ...
	 Train_Loss: 0.6941 Train_Acc: 53.101 Val_Loss: 0.6916  BEST VAL Loss: 0.6916  Val_Acc: 54.453

Epoch 2: Validation loss decreased (0.691648 --> 0.689951).  Saving model ...
	 Train_Loss: 0.6913 Train_Acc: 54.653 Val_Loss: 0.6900  BEST VAL Loss: 0.6900  Val_Acc: 55.547

Epoch 3: Validation loss decreased (0.689951 --> 0.688363).  Saving model ...
	 Train_Loss: 0.6885 Train_Acc: 56.523 Val_Loss: 0.6884  BEST VAL Loss: 0.6884  Val_Acc: 56.992

Epoch 4: Validation loss decreased (0.688363 --> 0.687007).  Saving model ...
	 Train_Loss: 0.6862 Train_Acc: 57.212 Val_Loss: 0.6870  BEST VAL Loss: 0.6870  Val_Acc: 58.008

Epoch 5: Validation loss decreased (0.687007 --> 0.685791).  Saving model ...
	 Train_Loss: 0.6840 Train_Acc: 58.018 Val_Loss: 0.6858  BEST VAL Loss: 0.6858  Val_Acc: 58.789

Epoch 6: Validation loss decreased (0.685791 --> 0.684459).  Saving model ...
	 Train_Loss: 0.6821 Train_Acc: 59.033 Val_Loss: 0.6845  BEST VAL Loss: 0.6845  Val_Acc: 59.531

Epoch 7: Validation loss decreased (0.684459 --> 0.683534).  Saving model ...
	 Train_Loss: 0.6804 Train_Acc: 59.268 Val_Loss: 0.6835  BEST VAL Loss: 0.6835  Val_Acc: 59.180

Epoch 8: Validation loss decreased (0.683534 --> 0.682687).  Saving model ...
	 Train_Loss: 0.6786 Train_Acc: 60.122 Val_Loss: 0.6827  BEST VAL Loss: 0.6827  Val_Acc: 59.609

Epoch 9: Validation loss decreased (0.682687 --> 0.681716).  Saving model ...
	 Train_Loss: 0.6771 Train_Acc: 60.322 Val_Loss: 0.6817  BEST VAL Loss: 0.6817  Val_Acc: 59.883

Epoch 10: Validation loss decreased (0.681716 --> 0.680705).  Saving model ...
	 Train_Loss: 0.6755 Train_Acc: 61.138 Val_Loss: 0.6807  BEST VAL Loss: 0.6807  Val_Acc: 60.234

Epoch 11: Validation loss decreased (0.680705 --> 0.680563).  Saving model ...
	 Train_Loss: 0.6740 Train_Acc: 61.265 Val_Loss: 0.6806  BEST VAL Loss: 0.6806  Val_Acc: 60.273

Epoch 12: Validation loss decreased (0.680563 --> 0.679847).  Saving model ...
	 Train_Loss: 0.6725 Train_Acc: 61.172 Val_Loss: 0.6798  BEST VAL Loss: 0.6798  Val_Acc: 60.703

Epoch 13: Validation loss decreased (0.679847 --> 0.679120).  Saving model ...
	 Train_Loss: 0.6711 Train_Acc: 61.943 Val_Loss: 0.6791  BEST VAL Loss: 0.6791  Val_Acc: 60.898

Epoch 14: Validation loss decreased (0.679120 --> 0.678968).  Saving model ...
	 Train_Loss: 0.6698 Train_Acc: 62.314 Val_Loss: 0.6790  BEST VAL Loss: 0.6790  Val_Acc: 61.367

Epoch 15: Validation loss decreased (0.678968 --> 0.678187).  Saving model ...
	 Train_Loss: 0.6684 Train_Acc: 62.520 Val_Loss: 0.6782  BEST VAL Loss: 0.6782  Val_Acc: 62.344

Epoch 16: Validation loss decreased (0.678187 --> 0.677570).  Saving model ...
	 Train_Loss: 0.6670 Train_Acc: 62.930 Val_Loss: 0.6776  BEST VAL Loss: 0.6776  Val_Acc: 62.617

Epoch 17: Validation loss decreased (0.677570 --> 0.677483).  Saving model ...
	 Train_Loss: 0.6657 Train_Acc: 62.695 Val_Loss: 0.6775  BEST VAL Loss: 0.6775  Val_Acc: 63.008

Epoch 18: Validation loss did not decrease
	 Train_Loss: 0.6644 Train_Acc: 63.071 Val_Loss: 0.6775  BEST VAL Loss: 0.6775  Val_Acc: 62.773

Epoch 19: Validation loss decreased (0.677483 --> 0.676748).  Saving model ...
	 Train_Loss: 0.6631 Train_Acc: 63.604 Val_Loss: 0.6767  BEST VAL Loss: 0.6767  Val_Acc: 62.773

Epoch 20: Validation loss decreased (0.676748 --> 0.676132).  Saving model ...
	 Train_Loss: 0.6618 Train_Acc: 63.960 Val_Loss: 0.6761  BEST VAL Loss: 0.6761  Val_Acc: 62.930

Epoch 21: Validation loss decreased (0.676132 --> 0.675635).  Saving model ...
	 Train_Loss: 0.6606 Train_Acc: 63.896 Val_Loss: 0.6756  BEST VAL Loss: 0.6756  Val_Acc: 63.125

Epoch 22: Validation loss decreased (0.675635 --> 0.675034).  Saving model ...
	 Train_Loss: 0.6594 Train_Acc: 64.312 Val_Loss: 0.6750  BEST VAL Loss: 0.6750  Val_Acc: 63.516

Epoch 23: Validation loss decreased (0.675034 --> 0.674489).  Saving model ...
	 Train_Loss: 0.6582 Train_Acc: 64.702 Val_Loss: 0.6745  BEST VAL Loss: 0.6745  Val_Acc: 63.438

Epoch 24: Validation loss decreased (0.674489 --> 0.674019).  Saving model ...
	 Train_Loss: 0.6570 Train_Acc: 64.805 Val_Loss: 0.6740  BEST VAL Loss: 0.6740  Val_Acc: 63.125

Epoch 25: Validation loss decreased (0.674019 --> 0.673598).  Saving model ...
	 Train_Loss: 0.6558 Train_Acc: 64.702 Val_Loss: 0.6736  BEST VAL Loss: 0.6736  Val_Acc: 63.750

Epoch 26: Validation loss decreased (0.673598 --> 0.673085).  Saving model ...
	 Train_Loss: 0.6547 Train_Acc: 64.780 Val_Loss: 0.6731  BEST VAL Loss: 0.6731  Val_Acc: 63.242

Epoch 27: Validation loss decreased (0.673085 --> 0.672752).  Saving model ...
	 Train_Loss: 0.6537 Train_Acc: 64.634 Val_Loss: 0.6728  BEST VAL Loss: 0.6728  Val_Acc: 63.867

Epoch 28: Validation loss decreased (0.672752 --> 0.672350).  Saving model ...
	 Train_Loss: 0.6527 Train_Acc: 65.073 Val_Loss: 0.6724  BEST VAL Loss: 0.6724  Val_Acc: 63.711

Epoch 29: Validation loss decreased (0.672350 --> 0.672020).  Saving model ...
	 Train_Loss: 0.6516 Train_Acc: 65.449 Val_Loss: 0.6720  BEST VAL Loss: 0.6720  Val_Acc: 64.219

Epoch 30: Validation loss decreased (0.672020 --> 0.671741).  Saving model ...
	 Train_Loss: 0.6505 Train_Acc: 65.811 Val_Loss: 0.6717  BEST VAL Loss: 0.6717  Val_Acc: 63.945

Epoch 31: Validation loss decreased (0.671741 --> 0.671503).  Saving model ...
	 Train_Loss: 0.6495 Train_Acc: 65.610 Val_Loss: 0.6715  BEST VAL Loss: 0.6715  Val_Acc: 64.062

Epoch 32: Validation loss decreased (0.671503 --> 0.671222).  Saving model ...
	 Train_Loss: 0.6485 Train_Acc: 66.045 Val_Loss: 0.6712  BEST VAL Loss: 0.6712  Val_Acc: 64.141

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.6475 Train_Acc: 65.972 Val_Loss: 0.6717  BEST VAL Loss: 0.6712  Val_Acc: 64.258

Epoch 34: Validation loss did not decrease
	 Train_Loss: 0.6466 Train_Acc: 65.850 Val_Loss: 0.6715  BEST VAL Loss: 0.6712  Val_Acc: 64.141

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.6456 Train_Acc: 66.440 Val_Loss: 0.6713  BEST VAL Loss: 0.6712  Val_Acc: 64.414

Epoch 36: Validation loss decreased (0.671222 --> 0.671135).  Saving model ...
	 Train_Loss: 0.6447 Train_Acc: 65.972 Val_Loss: 0.6711  BEST VAL Loss: 0.6711  Val_Acc: 64.297

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.6438 Train_Acc: 66.147 Val_Loss: 0.6716  BEST VAL Loss: 0.6711  Val_Acc: 64.844

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.6429 Train_Acc: 66.704 Val_Loss: 0.6714  BEST VAL Loss: 0.6711  Val_Acc: 64.688

Epoch 39: Validation loss decreased (0.671135 --> 0.671095).  Saving model ...
	 Train_Loss: 0.6420 Train_Acc: 66.982 Val_Loss: 0.6711  BEST VAL Loss: 0.6711  Val_Acc: 64.844

Epoch 40: Validation loss decreased (0.671095 --> 0.670961).  Saving model ...
	 Train_Loss: 0.6411 Train_Acc: 66.611 Val_Loss: 0.6710  BEST VAL Loss: 0.6710  Val_Acc: 64.883

Epoch 41: Validation loss decreased (0.670961 --> 0.670795).  Saving model ...
	 Train_Loss: 0.6403 Train_Acc: 66.748 Val_Loss: 0.6708  BEST VAL Loss: 0.6708  Val_Acc: 64.688

Epoch 42: Validation loss decreased (0.670795 --> 0.670626).  Saving model ...
	 Train_Loss: 0.6394 Train_Acc: 67.236 Val_Loss: 0.6706  BEST VAL Loss: 0.6706  Val_Acc: 65.273

Epoch 43: Validation loss decreased (0.670626 --> 0.670453).  Saving model ...
	 Train_Loss: 0.6386 Train_Acc: 66.812 Val_Loss: 0.6705  BEST VAL Loss: 0.6705  Val_Acc: 65.039

Epoch 44: Validation loss decreased (0.670453 --> 0.670327).  Saving model ...
	 Train_Loss: 0.6378 Train_Acc: 67.358 Val_Loss: 0.6703  BEST VAL Loss: 0.6703  Val_Acc: 64.922

Epoch 45: Validation loss decreased (0.670327 --> 0.670201).  Saving model ...
	 Train_Loss: 0.6370 Train_Acc: 67.100 Val_Loss: 0.6702  BEST VAL Loss: 0.6702  Val_Acc: 65.039

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.6362 Train_Acc: 67.422 Val_Loss: 0.6707  BEST VAL Loss: 0.6702  Val_Acc: 65.039

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.6355 Train_Acc: 66.899 Val_Loss: 0.6705  BEST VAL Loss: 0.6702  Val_Acc: 65.000

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.6347 Train_Acc: 67.285 Val_Loss: 0.6704  BEST VAL Loss: 0.6702  Val_Acc: 65.000

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.6340 Train_Acc: 67.500 Val_Loss: 0.6703  BEST VAL Loss: 0.6702  Val_Acc: 64.922

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.6332 Train_Acc: 67.490 Val_Loss: 0.6703  BEST VAL Loss: 0.6702  Val_Acc: 64.883

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.6325 Train_Acc: 67.832 Val_Loss: 0.6708  BEST VAL Loss: 0.6702  Val_Acc: 65.117

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.6318 Train_Acc: 67.754 Val_Loss: 0.6707  BEST VAL Loss: 0.6702  Val_Acc: 64.727

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.6310 Train_Acc: 68.037 Val_Loss: 0.6707  BEST VAL Loss: 0.6702  Val_Acc: 64.844

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.6303 Train_Acc: 68.022 Val_Loss: 0.6706  BEST VAL Loss: 0.6702  Val_Acc: 65.391

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.6297 Train_Acc: 67.910 Val_Loss: 0.6705  BEST VAL Loss: 0.6702  Val_Acc: 65.391

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.6289 Train_Acc: 68.379 Val_Loss: 0.6705  BEST VAL Loss: 0.6702  Val_Acc: 65.234

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.6282 Train_Acc: 68.555 Val_Loss: 0.6705  BEST VAL Loss: 0.6702  Val_Acc: 65.430

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.6275 Train_Acc: 68.613 Val_Loss: 0.6704  BEST VAL Loss: 0.6702  Val_Acc: 65.781

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.6268 Train_Acc: 68.906 Val_Loss: 0.6703  BEST VAL Loss: 0.6702  Val_Acc: 65.430

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.6262 Train_Acc: 68.286 Val_Loss: 0.6703  BEST VAL Loss: 0.6702  Val_Acc: 64.883

Epoch 61: Validation loss did not decrease
Early stopped at epoch : 61
LPS_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.52      0.51     10452
           1       0.49      0.48      0.48     10028

    accuracy                           0.50     20480
   macro avg       0.50      0.50      0.50     20480
weighted avg       0.50      0.50      0.50     20480

LPS_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.54      0.53      1307
           1       0.50      0.47      0.48      1253

    accuracy                           0.51      2560
   macro avg       0.51      0.51      0.51      2560
weighted avg       0.51      0.51      0.51      2560

LPS_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.52      0.51      1306
           1       0.49      0.47      0.48      1254

    accuracy                           0.50      2560
   macro avg       0.50      0.50      0.50      2560
weighted avg       0.50      0.50      0.50      2560

              precision    recall  f1-score   support

           0       0.51      0.52      0.51      1306
           1       0.49      0.47      0.48      1254

    accuracy                           0.50      2560
   macro avg       0.50      0.50      0.50      2560
weighted avg       0.50      0.50      0.50      2560

LPS_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.63      0.57      4445
           1       0.46      0.36      0.41      3923

    accuracy                           0.50      8368
   macro avg       0.50      0.50      0.49      8368
weighted avg       0.50      0.50      0.50      8368

              precision    recall  f1-score   support

           0       0.53      0.63      0.57      4445
           1       0.46      0.36      0.41      3923

    accuracy                           0.50      8368
   macro avg       0.50      0.50      0.49      8368
weighted avg       0.50      0.50      0.50      8368

completed
