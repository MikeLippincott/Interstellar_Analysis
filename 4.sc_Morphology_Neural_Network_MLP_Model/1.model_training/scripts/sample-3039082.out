[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'bcaf4811'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'f4f61f34'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '523acde0'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'c1d54284'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_0.010_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_0.010_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_0.100_DMSO_0.025']
The dimensions of the data are: (33369, 1276)
Number of total missing values across all columns: 66738
Data Subset Is Off
Wells held out for testing: ['B20' 'C21']
Wells to use for training, validation, and testing ['B16' 'C16' 'B17' 'C17' 'C20' 'B21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.677004).  Saving model ...
	 Train_Loss: 0.6883 Train_Acc: 53.168 Val_Loss: 0.6770  BEST VAL Loss: 0.6770  Val_Acc: 58.910

Epoch 1: Validation loss decreased (0.677004 --> 0.669347).  Saving model ...
	 Train_Loss: 0.6832 Train_Acc: 54.993 Val_Loss: 0.6693  BEST VAL Loss: 0.6693  Val_Acc: 61.774

Epoch 2: Validation loss decreased (0.669347 --> 0.664438).  Saving model ...
	 Train_Loss: 0.6783 Train_Acc: 58.405 Val_Loss: 0.6644  BEST VAL Loss: 0.6644  Val_Acc: 65.076

Epoch 3: Validation loss decreased (0.664438 --> 0.655340).  Saving model ...
	 Train_Loss: 0.6717 Train_Acc: 60.493 Val_Loss: 0.6553  BEST VAL Loss: 0.6553  Val_Acc: 66.587

Epoch 4: Validation loss decreased (0.655340 --> 0.648263).  Saving model ...
	 Train_Loss: 0.6654 Train_Acc: 62.766 Val_Loss: 0.6483  BEST VAL Loss: 0.6483  Val_Acc: 67.422

Epoch 5: Validation loss decreased (0.648263 --> 0.642839).  Saving model ...
	 Train_Loss: 0.6602 Train_Acc: 63.736 Val_Loss: 0.6428  BEST VAL Loss: 0.6428  Val_Acc: 66.985

Epoch 6: Validation loss decreased (0.642839 --> 0.637099).  Saving model ...
	 Train_Loss: 0.6551 Train_Acc: 64.084 Val_Loss: 0.6371  BEST VAL Loss: 0.6371  Val_Acc: 68.496

Epoch 7: Validation loss decreased (0.637099 --> 0.632825).  Saving model ...
	 Train_Loss: 0.6504 Train_Acc: 65.437 Val_Loss: 0.6328  BEST VAL Loss: 0.6328  Val_Acc: 67.820

Epoch 8: Validation loss decreased (0.632825 --> 0.627904).  Saving model ...
	 Train_Loss: 0.6454 Train_Acc: 66.924 Val_Loss: 0.6279  BEST VAL Loss: 0.6279  Val_Acc: 69.053

Epoch 9: Validation loss decreased (0.627904 --> 0.623538).  Saving model ...
	 Train_Loss: 0.6411 Train_Acc: 66.690 Val_Loss: 0.6235  BEST VAL Loss: 0.6235  Val_Acc: 68.775

Epoch 10: Validation loss decreased (0.623538 --> 0.620208).  Saving model ...
	 Train_Loss: 0.6366 Train_Acc: 68.023 Val_Loss: 0.6202  BEST VAL Loss: 0.6202  Val_Acc: 67.860

Epoch 11: Validation loss decreased (0.620208 --> 0.616897).  Saving model ...
	 Train_Loss: 0.6333 Train_Acc: 67.779 Val_Loss: 0.6169  BEST VAL Loss: 0.6169  Val_Acc: 68.815

Epoch 12: Validation loss decreased (0.616897 --> 0.613867).  Saving model ...
	 Train_Loss: 0.6294 Train_Acc: 68.639 Val_Loss: 0.6139  BEST VAL Loss: 0.6139  Val_Acc: 69.610

Epoch 13: Validation loss decreased (0.613867 --> 0.611215).  Saving model ...
	 Train_Loss: 0.6258 Train_Acc: 69.057 Val_Loss: 0.6112  BEST VAL Loss: 0.6112  Val_Acc: 68.974

Epoch 14: Validation loss decreased (0.611215 --> 0.609028).  Saving model ...
	 Train_Loss: 0.6233 Train_Acc: 68.545 Val_Loss: 0.6090  BEST VAL Loss: 0.6090  Val_Acc: 69.570

Epoch 15: Validation loss decreased (0.609028 --> 0.606608).  Saving model ...
	 Train_Loss: 0.6206 Train_Acc: 68.674 Val_Loss: 0.6066  BEST VAL Loss: 0.6066  Val_Acc: 69.451

Epoch 16: Validation loss decreased (0.606608 --> 0.604485).  Saving model ...
	 Train_Loss: 0.6181 Train_Acc: 69.226 Val_Loss: 0.6045  BEST VAL Loss: 0.6045  Val_Acc: 69.173

Epoch 17: Validation loss decreased (0.604485 --> 0.602355).  Saving model ...
	 Train_Loss: 0.6159 Train_Acc: 69.544 Val_Loss: 0.6024  BEST VAL Loss: 0.6024  Val_Acc: 69.889

Epoch 18: Validation loss decreased (0.602355 --> 0.600461).  Saving model ...
	 Train_Loss: 0.6134 Train_Acc: 70.062 Val_Loss: 0.6005  BEST VAL Loss: 0.6005  Val_Acc: 69.769

Epoch 19: Validation loss decreased (0.600461 --> 0.598463).  Saving model ...
	 Train_Loss: 0.6110 Train_Acc: 70.206 Val_Loss: 0.5985  BEST VAL Loss: 0.5985  Val_Acc: 70.804

Epoch 20: Validation loss decreased (0.598463 --> 0.596755).  Saving model ...
	 Train_Loss: 0.6086 Train_Acc: 70.783 Val_Loss: 0.5968  BEST VAL Loss: 0.5968  Val_Acc: 70.088

Epoch 21: Validation loss decreased (0.596755 --> 0.595308).  Saving model ...
	 Train_Loss: 0.6063 Train_Acc: 70.002 Val_Loss: 0.5953  BEST VAL Loss: 0.5953  Val_Acc: 71.241

Epoch 22: Validation loss decreased (0.595308 --> 0.593975).  Saving model ...
	 Train_Loss: 0.6043 Train_Acc: 70.828 Val_Loss: 0.5940  BEST VAL Loss: 0.5940  Val_Acc: 69.769

Epoch 23: Validation loss decreased (0.593975 --> 0.592617).  Saving model ...
	 Train_Loss: 0.6023 Train_Acc: 70.514 Val_Loss: 0.5926  BEST VAL Loss: 0.5926  Val_Acc: 70.764

Epoch 24: Validation loss decreased (0.592617 --> 0.591473).  Saving model ...
	 Train_Loss: 0.6006 Train_Acc: 70.340 Val_Loss: 0.5915  BEST VAL Loss: 0.5915  Val_Acc: 70.366

Epoch 25: Validation loss decreased (0.591473 --> 0.590325).  Saving model ...
	 Train_Loss: 0.5989 Train_Acc: 70.753 Val_Loss: 0.5903  BEST VAL Loss: 0.5903  Val_Acc: 70.883

Epoch 26: Validation loss decreased (0.590325 --> 0.589091).  Saving model ...
	 Train_Loss: 0.5972 Train_Acc: 71.116 Val_Loss: 0.5891  BEST VAL Loss: 0.5891  Val_Acc: 70.843

Epoch 27: Validation loss decreased (0.589091 --> 0.587995).  Saving model ...
	 Train_Loss: 0.5954 Train_Acc: 71.176 Val_Loss: 0.5880  BEST VAL Loss: 0.5880  Val_Acc: 70.883

Epoch 28: Validation loss decreased (0.587995 --> 0.586678).  Saving model ...
	 Train_Loss: 0.5938 Train_Acc: 70.842 Val_Loss: 0.5867  BEST VAL Loss: 0.5867  Val_Acc: 72.196

Epoch 29: Validation loss decreased (0.586678 --> 0.585768).  Saving model ...
	 Train_Loss: 0.5922 Train_Acc: 71.002 Val_Loss: 0.5858  BEST VAL Loss: 0.5858  Val_Acc: 71.241

Epoch 30: Validation loss decreased (0.585768 --> 0.584793).  Saving model ...
	 Train_Loss: 0.5908 Train_Acc: 71.056 Val_Loss: 0.5848  BEST VAL Loss: 0.5848  Val_Acc: 71.002

Epoch 31: Validation loss decreased (0.584793 --> 0.583954).  Saving model ...
	 Train_Loss: 0.5893 Train_Acc: 71.424 Val_Loss: 0.5840  BEST VAL Loss: 0.5840  Val_Acc: 70.247

Epoch 32: Validation loss decreased (0.583954 --> 0.583124).  Saving model ...
	 Train_Loss: 0.5880 Train_Acc: 71.394 Val_Loss: 0.5831  BEST VAL Loss: 0.5831  Val_Acc: 70.724

Epoch 33: Validation loss decreased (0.583124 --> 0.582288).  Saving model ...
	 Train_Loss: 0.5867 Train_Acc: 72.444 Val_Loss: 0.5823  BEST VAL Loss: 0.5823  Val_Acc: 71.281

Epoch 34: Validation loss decreased (0.582288 --> 0.581585).  Saving model ...
	 Train_Loss: 0.5855 Train_Acc: 71.718 Val_Loss: 0.5816  BEST VAL Loss: 0.5816  Val_Acc: 71.161

Epoch 35: Validation loss decreased (0.581585 --> 0.580932).  Saving model ...
	 Train_Loss: 0.5843 Train_Acc: 71.872 Val_Loss: 0.5809  BEST VAL Loss: 0.5809  Val_Acc: 70.684

Epoch 36: Validation loss decreased (0.580932 --> 0.580174).  Saving model ...
	 Train_Loss: 0.5831 Train_Acc: 72.011 Val_Loss: 0.5802  BEST VAL Loss: 0.5802  Val_Acc: 71.360

Epoch 37: Validation loss decreased (0.580174 --> 0.579548).  Saving model ...
	 Train_Loss: 0.5818 Train_Acc: 72.618 Val_Loss: 0.5795  BEST VAL Loss: 0.5795  Val_Acc: 70.565

Epoch 38: Validation loss decreased (0.579548 --> 0.578847).  Saving model ...
	 Train_Loss: 0.5806 Train_Acc: 71.956 Val_Loss: 0.5788  BEST VAL Loss: 0.5788  Val_Acc: 71.440

Epoch 39: Validation loss decreased (0.578847 --> 0.578348).  Saving model ...
	 Train_Loss: 0.5794 Train_Acc: 71.872 Val_Loss: 0.5783  BEST VAL Loss: 0.5783  Val_Acc: 71.201

Epoch 40: Validation loss decreased (0.578348 --> 0.577737).  Saving model ...
	 Train_Loss: 0.5784 Train_Acc: 71.648 Val_Loss: 0.5777  BEST VAL Loss: 0.5777  Val_Acc: 70.883

Epoch 41: Validation loss decreased (0.577737 --> 0.577090).  Saving model ...
	 Train_Loss: 0.5773 Train_Acc: 71.902 Val_Loss: 0.5771  BEST VAL Loss: 0.5771  Val_Acc: 71.042

Epoch 42: Validation loss decreased (0.577090 --> 0.576496).  Saving model ...
	 Train_Loss: 0.5762 Train_Acc: 71.758 Val_Loss: 0.5765  BEST VAL Loss: 0.5765  Val_Acc: 71.559

Epoch 43: Validation loss decreased (0.576496 --> 0.575897).  Saving model ...
	 Train_Loss: 0.5751 Train_Acc: 71.922 Val_Loss: 0.5759  BEST VAL Loss: 0.5759  Val_Acc: 71.201

Epoch 44: Validation loss decreased (0.575897 --> 0.575332).  Saving model ...
	 Train_Loss: 0.5741 Train_Acc: 72.076 Val_Loss: 0.5753  BEST VAL Loss: 0.5753  Val_Acc: 71.997

Epoch 45: Validation loss decreased (0.575332 --> 0.574990).  Saving model ...
	 Train_Loss: 0.5733 Train_Acc: 71.161 Val_Loss: 0.5750  BEST VAL Loss: 0.5750  Val_Acc: 71.082

Epoch 46: Validation loss decreased (0.574990 --> 0.574648).  Saving model ...
	 Train_Loss: 0.5724 Train_Acc: 71.663 Val_Loss: 0.5746  BEST VAL Loss: 0.5746  Val_Acc: 70.286

Epoch 47: Validation loss decreased (0.574648 --> 0.574165).  Saving model ...
	 Train_Loss: 0.5716 Train_Acc: 71.564 Val_Loss: 0.5742  BEST VAL Loss: 0.5742  Val_Acc: 70.764

Epoch 48: Validation loss decreased (0.574165 --> 0.573863).  Saving model ...
	 Train_Loss: 0.5707 Train_Acc: 72.280 Val_Loss: 0.5739  BEST VAL Loss: 0.5739  Val_Acc: 71.400

Epoch 49: Validation loss decreased (0.573863 --> 0.573470).  Saving model ...
	 Train_Loss: 0.5698 Train_Acc: 71.832 Val_Loss: 0.5735  BEST VAL Loss: 0.5735  Val_Acc: 71.679

Epoch 50: Validation loss decreased (0.573470 --> 0.573064).  Saving model ...
	 Train_Loss: 0.5691 Train_Acc: 71.942 Val_Loss: 0.5731  BEST VAL Loss: 0.5731  Val_Acc: 70.684

Epoch 51: Validation loss decreased (0.573064 --> 0.572672).  Saving model ...
	 Train_Loss: 0.5682 Train_Acc: 72.086 Val_Loss: 0.5727  BEST VAL Loss: 0.5727  Val_Acc: 71.639

Epoch 52: Validation loss decreased (0.572672 --> 0.572353).  Saving model ...
	 Train_Loss: 0.5675 Train_Acc: 71.230 Val_Loss: 0.5724  BEST VAL Loss: 0.5724  Val_Acc: 71.360

Epoch 53: Validation loss decreased (0.572353 --> 0.572041).  Saving model ...
	 Train_Loss: 0.5667 Train_Acc: 71.733 Val_Loss: 0.5720  BEST VAL Loss: 0.5720  Val_Acc: 71.679

Epoch 54: Validation loss decreased (0.572041 --> 0.571728).  Saving model ...
	 Train_Loss: 0.5659 Train_Acc: 72.145 Val_Loss: 0.5717  BEST VAL Loss: 0.5717  Val_Acc: 71.639

Epoch 55: Validation loss decreased (0.571728 --> 0.571405).  Saving model ...
	 Train_Loss: 0.5651 Train_Acc: 72.459 Val_Loss: 0.5714  BEST VAL Loss: 0.5714  Val_Acc: 71.281

Epoch 56: Validation loss decreased (0.571405 --> 0.571203).  Saving model ...
	 Train_Loss: 0.5643 Train_Acc: 72.111 Val_Loss: 0.5712  BEST VAL Loss: 0.5712  Val_Acc: 71.877

Epoch 57: Validation loss decreased (0.571203 --> 0.571022).  Saving model ...
	 Train_Loss: 0.5634 Train_Acc: 72.946 Val_Loss: 0.5710  BEST VAL Loss: 0.5710  Val_Acc: 70.485

Epoch 58: Validation loss decreased (0.571022 --> 0.570807).  Saving model ...
	 Train_Loss: 0.5628 Train_Acc: 72.503 Val_Loss: 0.5708  BEST VAL Loss: 0.5708  Val_Acc: 70.883

Epoch 59: Validation loss decreased (0.570807 --> 0.570595).  Saving model ...
	 Train_Loss: 0.5620 Train_Acc: 72.533 Val_Loss: 0.5706  BEST VAL Loss: 0.5706  Val_Acc: 71.400

Epoch 60: Validation loss decreased (0.570595 --> 0.570393).  Saving model ...
	 Train_Loss: 0.5613 Train_Acc: 72.225 Val_Loss: 0.5704  BEST VAL Loss: 0.5704  Val_Acc: 72.116

Epoch 61: Validation loss decreased (0.570393 --> 0.570251).  Saving model ...
	 Train_Loss: 0.5607 Train_Acc: 72.210 Val_Loss: 0.5703  BEST VAL Loss: 0.5703  Val_Acc: 71.798

Epoch 62: Validation loss decreased (0.570251 --> 0.570071).  Saving model ...
	 Train_Loss: 0.5600 Train_Acc: 72.409 Val_Loss: 0.5701  BEST VAL Loss: 0.5701  Val_Acc: 71.519

Epoch 63: Validation loss decreased (0.570071 --> 0.569921).  Saving model ...
	 Train_Loss: 0.5594 Train_Acc: 72.036 Val_Loss: 0.5699  BEST VAL Loss: 0.5699  Val_Acc: 71.997

Epoch 64: Validation loss decreased (0.569921 --> 0.569812).  Saving model ...
	 Train_Loss: 0.5588 Train_Acc: 71.996 Val_Loss: 0.5698  BEST VAL Loss: 0.5698  Val_Acc: 71.002

Epoch 65: Validation loss decreased (0.569812 --> 0.569735).  Saving model ...
	 Train_Loss: 0.5582 Train_Acc: 71.966 Val_Loss: 0.5697  BEST VAL Loss: 0.5697  Val_Acc: 72.156

Epoch 66: Validation loss decreased (0.569735 --> 0.569717).  Saving model ...
	 Train_Loss: 0.5576 Train_Acc: 72.424 Val_Loss: 0.5697  BEST VAL Loss: 0.5697  Val_Acc: 71.519

Epoch 67: Validation loss decreased (0.569717 --> 0.569616).  Saving model ...
	 Train_Loss: 0.5570 Train_Acc: 72.832 Val_Loss: 0.5696  BEST VAL Loss: 0.5696  Val_Acc: 70.485

Epoch 68: Validation loss decreased (0.569616 --> 0.569462).  Saving model ...
	 Train_Loss: 0.5564 Train_Acc: 72.235 Val_Loss: 0.5695  BEST VAL Loss: 0.5695  Val_Acc: 71.360

Epoch 69: Validation loss decreased (0.569462 --> 0.569366).  Saving model ...
	 Train_Loss: 0.5558 Train_Acc: 72.593 Val_Loss: 0.5694  BEST VAL Loss: 0.5694  Val_Acc: 71.002

Epoch 70: Validation loss decreased (0.569366 --> 0.569340).  Saving model ...
	 Train_Loss: 0.5552 Train_Acc: 72.603 Val_Loss: 0.5693  BEST VAL Loss: 0.5693  Val_Acc: 70.485

Epoch 71: Validation loss decreased (0.569340 --> 0.569217).  Saving model ...
	 Train_Loss: 0.5545 Train_Acc: 72.787 Val_Loss: 0.5692  BEST VAL Loss: 0.5692  Val_Acc: 71.002

Epoch 72: Validation loss decreased (0.569217 --> 0.569108).  Saving model ...
	 Train_Loss: 0.5540 Train_Acc: 72.573 Val_Loss: 0.5691  BEST VAL Loss: 0.5691  Val_Acc: 71.122

Epoch 73: Validation loss decreased (0.569108 --> 0.568963).  Saving model ...
	 Train_Loss: 0.5534 Train_Acc: 72.648 Val_Loss: 0.5690  BEST VAL Loss: 0.5690  Val_Acc: 71.122

Epoch 74: Validation loss decreased (0.568963 --> 0.568848).  Saving model ...
	 Train_Loss: 0.5528 Train_Acc: 72.747 Val_Loss: 0.5688  BEST VAL Loss: 0.5688  Val_Acc: 71.241

Epoch 75: Validation loss decreased (0.568848 --> 0.568824).  Saving model ...
	 Train_Loss: 0.5523 Train_Acc: 72.727 Val_Loss: 0.5688  BEST VAL Loss: 0.5688  Val_Acc: 71.718

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.5516 Train_Acc: 72.936 Val_Loss: 0.5688  BEST VAL Loss: 0.5688  Val_Acc: 70.684

Epoch 77: Validation loss decreased (0.568824 --> 0.568806).  Saving model ...
	 Train_Loss: 0.5512 Train_Acc: 72.394 Val_Loss: 0.5688  BEST VAL Loss: 0.5688  Val_Acc: 71.360

Epoch 78: Validation loss decreased (0.568806 --> 0.568699).  Saving model ...
	 Train_Loss: 0.5508 Train_Acc: 72.071 Val_Loss: 0.5687  BEST VAL Loss: 0.5687  Val_Acc: 71.201

Epoch 79: Validation loss decreased (0.568699 --> 0.568609).  Saving model ...
	 Train_Loss: 0.5503 Train_Acc: 72.618 Val_Loss: 0.5686  BEST VAL Loss: 0.5686  Val_Acc: 72.156

Epoch 80: Validation loss decreased (0.568609 --> 0.568534).  Saving model ...
	 Train_Loss: 0.5497 Train_Acc: 72.548 Val_Loss: 0.5685  BEST VAL Loss: 0.5685  Val_Acc: 71.042

Epoch 81: Validation loss decreased (0.568534 --> 0.568420).  Saving model ...
	 Train_Loss: 0.5492 Train_Acc: 72.787 Val_Loss: 0.5684  BEST VAL Loss: 0.5684  Val_Acc: 70.366

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.5487 Train_Acc: 73.070 Val_Loss: 0.5685  BEST VAL Loss: 0.5684  Val_Acc: 71.002

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.5482 Train_Acc: 73.031 Val_Loss: 0.5684  BEST VAL Loss: 0.5684  Val_Acc: 71.639

Epoch 84: Validation loss decreased (0.568420 --> 0.568340).  Saving model ...
	 Train_Loss: 0.5477 Train_Acc: 72.871 Val_Loss: 0.5683  BEST VAL Loss: 0.5683  Val_Acc: 71.559

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.5472 Train_Acc: 72.832 Val_Loss: 0.5684  BEST VAL Loss: 0.5683  Val_Acc: 70.565

Epoch 86: Validation loss decreased (0.568340 --> 0.568319).  Saving model ...
	 Train_Loss: 0.5467 Train_Acc: 72.732 Val_Loss: 0.5683  BEST VAL Loss: 0.5683  Val_Acc: 71.798

Epoch 87: Validation loss decreased (0.568319 --> 0.568262).  Saving model ...
	 Train_Loss: 0.5462 Train_Acc: 72.588 Val_Loss: 0.5683  BEST VAL Loss: 0.5683  Val_Acc: 70.883

Epoch 88: Validation loss decreased (0.568262 --> 0.568249).  Saving model ...
	 Train_Loss: 0.5458 Train_Acc: 72.852 Val_Loss: 0.5682  BEST VAL Loss: 0.5682  Val_Acc: 71.281

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.5453 Train_Acc: 72.762 Val_Loss: 0.5683  BEST VAL Loss: 0.5682  Val_Acc: 71.838

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.5448 Train_Acc: 72.742 Val_Loss: 0.5683  BEST VAL Loss: 0.5682  Val_Acc: 70.804

Epoch 91: Validation loss decreased (0.568249 --> 0.568210).  Saving model ...
	 Train_Loss: 0.5444 Train_Acc: 72.558 Val_Loss: 0.5682  BEST VAL Loss: 0.5682  Val_Acc: 71.718

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.5439 Train_Acc: 73.448 Val_Loss: 0.5683  BEST VAL Loss: 0.5682  Val_Acc: 70.724

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.5435 Train_Acc: 73.065 Val_Loss: 0.5683  BEST VAL Loss: 0.5682  Val_Acc: 70.644

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.5431 Train_Acc: 72.871 Val_Loss: 0.5683  BEST VAL Loss: 0.5682  Val_Acc: 70.684

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.5427 Train_Acc: 72.896 Val_Loss: 0.5683  BEST VAL Loss: 0.5682  Val_Acc: 71.281

Epoch 96: Validation loss did not decrease
	 Train_Loss: 0.5423 Train_Acc: 73.080 Val_Loss: 0.5683  BEST VAL Loss: 0.5682  Val_Acc: 69.849

Epoch 97: Validation loss decreased (0.568210 --> 0.568166).  Saving model ...
	 Train_Loss: 0.5419 Train_Acc: 72.966 Val_Loss: 0.5682  BEST VAL Loss: 0.5682  Val_Acc: 71.519

Epoch 98: Validation loss decreased (0.568166 --> 0.568039).  Saving model ...
	 Train_Loss: 0.5415 Train_Acc: 72.911 Val_Loss: 0.5680  BEST VAL Loss: 0.5680  Val_Acc: 71.997

Epoch 99: Validation loss decreased (0.568039 --> 0.568025).  Saving model ...
	 Train_Loss: 0.5410 Train_Acc: 72.837 Val_Loss: 0.5680  BEST VAL Loss: 0.5680  Val_Acc: 71.002

LPS_0.010_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.81      0.79      0.80      9707
           1       0.81      0.82      0.82     10401

    accuracy                           0.81     20108
   macro avg       0.81      0.81      0.81     20108
weighted avg       0.81      0.81      0.81     20108

LPS_0.010_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.70      0.70      0.70      1214
           1       0.72      0.72      0.72      1300

    accuracy                           0.71      2514
   macro avg       0.71      0.71      0.71      2514
weighted avg       0.71      0.71      0.71      2514

LPS_0.010_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.72      0.71      0.71      1214
           1       0.73      0.74      0.74      1300

    accuracy                           0.72      2514
   macro avg       0.72      0.72      0.72      2514
weighted avg       0.72      0.72      0.72      2514

              precision    recall  f1-score   support

           0       0.72      0.71      0.71      1214
           1       0.73      0.74      0.74      1300

    accuracy                           0.72      2514
   macro avg       0.72      0.72      0.72      2514
weighted avg       0.72      0.72      0.72      2514

LPS_0.010_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.62      0.72      0.66      3724
           1       0.73      0.63      0.68      4509

    accuracy                           0.67      8233
   macro avg       0.67      0.67      0.67      8233
weighted avg       0.68      0.67      0.67      8233

              precision    recall  f1-score   support

           0       0.62      0.72      0.66      3724
           1       0.73      0.63      0.68      4509

    accuracy                           0.67      8233
   macro avg       0.67      0.67      0.67      8233
weighted avg       0.68      0.67      0.67      8233

completed
