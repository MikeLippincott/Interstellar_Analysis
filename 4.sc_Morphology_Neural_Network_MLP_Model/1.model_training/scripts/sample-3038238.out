[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'c5e84b53'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '33a3caa2'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'aa285079'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'afe29e64'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_100.000_DMSO_0.025 treatment_name: LPS_10.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_100.000_DMSO_0.025
TREATMENT_NAME: LPS_10.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (32797, 1276)
Number of total missing values across all columns: 65594
Data Subset Is Off
Wells held out for testing: ['E20' 'J16']
Wells to use for training, validation, and testing ['E16' 'E17' 'E21' 'J17' 'J20' 'J21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.393275).  Saving model ...
	 Train_Loss: 0.5807 Train_Acc: 70.688 Val_Loss: 0.3933  BEST VAL Loss: 0.3933  Val_Acc: 81.818

Epoch 1: Validation loss decreased (0.393275 --> 0.329810).  Saving model ...
	 Train_Loss: 0.4798 Train_Acc: 81.927 Val_Loss: 0.3298  BEST VAL Loss: 0.3298  Val_Acc: 89.808

Epoch 2: Validation loss decreased (0.329810 --> 0.290301).  Saving model ...
	 Train_Loss: 0.4190 Train_Acc: 86.177 Val_Loss: 0.2903  BEST VAL Loss: 0.2903  Val_Acc: 91.398

Epoch 3: Validation loss decreased (0.290301 --> 0.260677).  Saving model ...
	 Train_Loss: 0.3773 Train_Acc: 89.016 Val_Loss: 0.2607  BEST VAL Loss: 0.2607  Val_Acc: 92.825

Epoch 4: Validation loss decreased (0.260677 --> 0.241677).  Saving model ...
	 Train_Loss: 0.3489 Train_Acc: 89.455 Val_Loss: 0.2417  BEST VAL Loss: 0.2417  Val_Acc: 93.070

Epoch 5: Validation loss decreased (0.241677 --> 0.230238).  Saving model ...
	 Train_Loss: 0.3277 Train_Acc: 90.036 Val_Loss: 0.2302  BEST VAL Loss: 0.2302  Val_Acc: 93.070

Epoch 6: Validation loss decreased (0.230238 --> 0.219039).  Saving model ...
	 Train_Loss: 0.3114 Train_Acc: 90.637 Val_Loss: 0.2190  BEST VAL Loss: 0.2190  Val_Acc: 94.089

Epoch 7: Validation loss decreased (0.219039 --> 0.210439).  Saving model ...
	 Train_Loss: 0.2986 Train_Acc: 90.627 Val_Loss: 0.2104  BEST VAL Loss: 0.2104  Val_Acc: 93.477

Epoch 8: Validation loss decreased (0.210439 --> 0.203401).  Saving model ...
	 Train_Loss: 0.2873 Train_Acc: 91.055 Val_Loss: 0.2034  BEST VAL Loss: 0.2034  Val_Acc: 94.293

Epoch 9: Validation loss decreased (0.203401 --> 0.196930).  Saving model ...
	 Train_Loss: 0.2779 Train_Acc: 91.182 Val_Loss: 0.1969  BEST VAL Loss: 0.1969  Val_Acc: 94.293

Epoch 10: Validation loss decreased (0.196930 --> 0.193516).  Saving model ...
	 Train_Loss: 0.2697 Train_Acc: 91.667 Val_Loss: 0.1935  BEST VAL Loss: 0.1935  Val_Acc: 93.763

Epoch 11: Validation loss decreased (0.193516 --> 0.189537).  Saving model ...
	 Train_Loss: 0.2628 Train_Acc: 91.346 Val_Loss: 0.1895  BEST VAL Loss: 0.1895  Val_Acc: 94.660

Epoch 12: Validation loss decreased (0.189537 --> 0.186015).  Saving model ...
	 Train_Loss: 0.2568 Train_Acc: 91.427 Val_Loss: 0.1860  BEST VAL Loss: 0.1860  Val_Acc: 94.782

Epoch 13: Validation loss decreased (0.186015 --> 0.183318).  Saving model ...
	 Train_Loss: 0.2513 Train_Acc: 91.707 Val_Loss: 0.1833  BEST VAL Loss: 0.1833  Val_Acc: 93.926

Epoch 14: Validation loss decreased (0.183318 --> 0.180736).  Saving model ...
	 Train_Loss: 0.2464 Train_Acc: 91.799 Val_Loss: 0.1807  BEST VAL Loss: 0.1807  Val_Acc: 94.415

Epoch 15: Validation loss decreased (0.180736 --> 0.178199).  Saving model ...
	 Train_Loss: 0.2418 Train_Acc: 92.176 Val_Loss: 0.1782  BEST VAL Loss: 0.1782  Val_Acc: 94.741

Epoch 16: Validation loss decreased (0.178199 --> 0.175537).  Saving model ...
	 Train_Loss: 0.2372 Train_Acc: 92.467 Val_Loss: 0.1755  BEST VAL Loss: 0.1755  Val_Acc: 94.660

Epoch 17: Validation loss decreased (0.175537 --> 0.173432).  Saving model ...
	 Train_Loss: 0.2332 Train_Acc: 92.278 Val_Loss: 0.1734  BEST VAL Loss: 0.1734  Val_Acc: 95.149

Epoch 18: Validation loss decreased (0.173432 --> 0.171586).  Saving model ...
	 Train_Loss: 0.2296 Train_Acc: 92.238 Val_Loss: 0.1716  BEST VAL Loss: 0.1716  Val_Acc: 94.741

Epoch 19: Validation loss decreased (0.171586 --> 0.170172).  Saving model ...
	 Train_Loss: 0.2261 Train_Acc: 92.666 Val_Loss: 0.1702  BEST VAL Loss: 0.1702  Val_Acc: 94.415

Epoch 20: Validation loss decreased (0.170172 --> 0.168524).  Saving model ...
	 Train_Loss: 0.2229 Train_Acc: 92.615 Val_Loss: 0.1685  BEST VAL Loss: 0.1685  Val_Acc: 94.456

Epoch 21: Validation loss decreased (0.168524 --> 0.166675).  Saving model ...
	 Train_Loss: 0.2199 Train_Acc: 92.462 Val_Loss: 0.1667  BEST VAL Loss: 0.1667  Val_Acc: 94.945

Epoch 22: Validation loss decreased (0.166675 --> 0.165320).  Saving model ...
	 Train_Loss: 0.2169 Train_Acc: 92.920 Val_Loss: 0.1653  BEST VAL Loss: 0.1653  Val_Acc: 94.863

Epoch 23: Validation loss decreased (0.165320 --> 0.164528).  Saving model ...
	 Train_Loss: 0.2143 Train_Acc: 92.615 Val_Loss: 0.1645  BEST VAL Loss: 0.1645  Val_Acc: 94.374

Epoch 24: Validation loss decreased (0.164528 --> 0.163508).  Saving model ...
	 Train_Loss: 0.2117 Train_Acc: 92.900 Val_Loss: 0.1635  BEST VAL Loss: 0.1635  Val_Acc: 95.067

Epoch 25: Validation loss decreased (0.163508 --> 0.162936).  Saving model ...
	 Train_Loss: 0.2090 Train_Acc: 93.338 Val_Loss: 0.1629  BEST VAL Loss: 0.1629  Val_Acc: 94.945

Epoch 26: Validation loss decreased (0.162936 --> 0.161715).  Saving model ...
	 Train_Loss: 0.2068 Train_Acc: 93.028 Val_Loss: 0.1617  BEST VAL Loss: 0.1617  Val_Acc: 95.026

Epoch 27: Validation loss decreased (0.161715 --> 0.160784).  Saving model ...
	 Train_Loss: 0.2048 Train_Acc: 92.788 Val_Loss: 0.1608  BEST VAL Loss: 0.1608  Val_Acc: 94.619

Epoch 28: Validation loss decreased (0.160784 --> 0.160051).  Saving model ...
	 Train_Loss: 0.2028 Train_Acc: 92.941 Val_Loss: 0.1601  BEST VAL Loss: 0.1601  Val_Acc: 95.108

Epoch 29: Validation loss decreased (0.160051 --> 0.159229).  Saving model ...
	 Train_Loss: 0.2009 Train_Acc: 92.977 Val_Loss: 0.1592  BEST VAL Loss: 0.1592  Val_Acc: 94.823

Epoch 30: Validation loss decreased (0.159229 --> 0.159187).  Saving model ...
	 Train_Loss: 0.1991 Train_Acc: 93.318 Val_Loss: 0.1592  BEST VAL Loss: 0.1592  Val_Acc: 95.271

Epoch 31: Validation loss decreased (0.159187 --> 0.158401).  Saving model ...
	 Train_Loss: 0.1972 Train_Acc: 93.313 Val_Loss: 0.1584  BEST VAL Loss: 0.1584  Val_Acc: 95.190

Epoch 32: Validation loss decreased (0.158401 --> 0.157486).  Saving model ...
	 Train_Loss: 0.1955 Train_Acc: 93.364 Val_Loss: 0.1575  BEST VAL Loss: 0.1575  Val_Acc: 95.475

Epoch 33: Validation loss decreased (0.157486 --> 0.156946).  Saving model ...
	 Train_Loss: 0.1938 Train_Acc: 93.344 Val_Loss: 0.1569  BEST VAL Loss: 0.1569  Val_Acc: 95.067

Epoch 34: Validation loss decreased (0.156946 --> 0.156474).  Saving model ...
	 Train_Loss: 0.1921 Train_Acc: 93.593 Val_Loss: 0.1565  BEST VAL Loss: 0.1565  Val_Acc: 95.067

Epoch 35: Validation loss decreased (0.156474 --> 0.156423).  Saving model ...
	 Train_Loss: 0.1906 Train_Acc: 93.496 Val_Loss: 0.1564  BEST VAL Loss: 0.1564  Val_Acc: 94.782

Epoch 36: Validation loss decreased (0.156423 --> 0.156077).  Saving model ...
	 Train_Loss: 0.1890 Train_Acc: 93.507 Val_Loss: 0.1561  BEST VAL Loss: 0.1561  Val_Acc: 95.312

Epoch 37: Validation loss decreased (0.156077 --> 0.156019).  Saving model ...
	 Train_Loss: 0.1875 Train_Acc: 93.522 Val_Loss: 0.1560  BEST VAL Loss: 0.1560  Val_Acc: 95.516

Epoch 38: Validation loss decreased (0.156019 --> 0.155698).  Saving model ...
	 Train_Loss: 0.1862 Train_Acc: 93.573 Val_Loss: 0.1557  BEST VAL Loss: 0.1557  Val_Acc: 95.190

Epoch 39: Validation loss decreased (0.155698 --> 0.155210).  Saving model ...
	 Train_Loss: 0.1850 Train_Acc: 93.196 Val_Loss: 0.1552  BEST VAL Loss: 0.1552  Val_Acc: 95.556

Epoch 40: Validation loss decreased (0.155210 --> 0.154832).  Saving model ...
	 Train_Loss: 0.1836 Train_Acc: 93.644 Val_Loss: 0.1548  BEST VAL Loss: 0.1548  Val_Acc: 95.760

Epoch 41: Validation loss decreased (0.154832 --> 0.154304).  Saving model ...
	 Train_Loss: 0.1824 Train_Acc: 93.670 Val_Loss: 0.1543  BEST VAL Loss: 0.1543  Val_Acc: 95.353

Epoch 42: Validation loss decreased (0.154304 --> 0.153938).  Saving model ...
	 Train_Loss: 0.1811 Train_Acc: 93.955 Val_Loss: 0.1539  BEST VAL Loss: 0.1539  Val_Acc: 95.271

Epoch 43: Validation loss decreased (0.153938 --> 0.153553).  Saving model ...
	 Train_Loss: 0.1798 Train_Acc: 93.950 Val_Loss: 0.1536  BEST VAL Loss: 0.1536  Val_Acc: 95.720

Epoch 44: Validation loss decreased (0.153553 --> 0.153232).  Saving model ...
	 Train_Loss: 0.1787 Train_Acc: 93.675 Val_Loss: 0.1532  BEST VAL Loss: 0.1532  Val_Acc: 95.434

Epoch 45: Validation loss decreased (0.153232 --> 0.152920).  Saving model ...
	 Train_Loss: 0.1775 Train_Acc: 94.006 Val_Loss: 0.1529  BEST VAL Loss: 0.1529  Val_Acc: 95.108

Epoch 46: Validation loss decreased (0.152920 --> 0.152564).  Saving model ...
	 Train_Loss: 0.1764 Train_Acc: 93.552 Val_Loss: 0.1526  BEST VAL Loss: 0.1526  Val_Acc: 95.720

Epoch 47: Validation loss decreased (0.152564 --> 0.152431).  Saving model ...
	 Train_Loss: 0.1754 Train_Acc: 93.777 Val_Loss: 0.1524  BEST VAL Loss: 0.1524  Val_Acc: 95.434

Epoch 48: Validation loss decreased (0.152431 --> 0.152061).  Saving model ...
	 Train_Loss: 0.1744 Train_Acc: 93.624 Val_Loss: 0.1521  BEST VAL Loss: 0.1521  Val_Acc: 95.638

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.1735 Train_Acc: 93.843 Val_Loss: 0.1521  BEST VAL Loss: 0.1521  Val_Acc: 95.679

Epoch 50: Validation loss decreased (0.152061 --> 0.151837).  Saving model ...
	 Train_Loss: 0.1726 Train_Acc: 93.741 Val_Loss: 0.1518  BEST VAL Loss: 0.1518  Val_Acc: 95.597

Epoch 51: Validation loss decreased (0.151837 --> 0.151616).  Saving model ...
	 Train_Loss: 0.1717 Train_Acc: 93.537 Val_Loss: 0.1516  BEST VAL Loss: 0.1516  Val_Acc: 95.597

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.1707 Train_Acc: 94.042 Val_Loss: 0.1517  BEST VAL Loss: 0.1516  Val_Acc: 95.353

Epoch 53: Validation loss decreased (0.151616 --> 0.151356).  Saving model ...
	 Train_Loss: 0.1697 Train_Acc: 94.343 Val_Loss: 0.1514  BEST VAL Loss: 0.1514  Val_Acc: 95.556

Epoch 54: Validation loss decreased (0.151356 --> 0.151301).  Saving model ...
	 Train_Loss: 0.1687 Train_Acc: 94.286 Val_Loss: 0.1513  BEST VAL Loss: 0.1513  Val_Acc: 95.883

Epoch 55: Validation loss decreased (0.151301 --> 0.151010).  Saving model ...
	 Train_Loss: 0.1678 Train_Acc: 93.976 Val_Loss: 0.1510  BEST VAL Loss: 0.1510  Val_Acc: 95.556

Epoch 56: Validation loss decreased (0.151010 --> 0.150802).  Saving model ...
	 Train_Loss: 0.1670 Train_Acc: 94.088 Val_Loss: 0.1508  BEST VAL Loss: 0.1508  Val_Acc: 95.679

Epoch 57: Validation loss decreased (0.150802 --> 0.150696).  Saving model ...
	 Train_Loss: 0.1661 Train_Acc: 94.266 Val_Loss: 0.1507  BEST VAL Loss: 0.1507  Val_Acc: 95.679

Epoch 58: Validation loss decreased (0.150696 --> 0.150615).  Saving model ...
	 Train_Loss: 0.1653 Train_Acc: 94.027 Val_Loss: 0.1506  BEST VAL Loss: 0.1506  Val_Acc: 95.760

Epoch 59: Validation loss decreased (0.150615 --> 0.150290).  Saving model ...
	 Train_Loss: 0.1646 Train_Acc: 93.874 Val_Loss: 0.1503  BEST VAL Loss: 0.1503  Val_Acc: 95.923

Epoch 60: Validation loss decreased (0.150290 --> 0.150215).  Saving model ...
	 Train_Loss: 0.1638 Train_Acc: 94.057 Val_Loss: 0.1502  BEST VAL Loss: 0.1502  Val_Acc: 95.556

Epoch 61: Validation loss decreased (0.150215 --> 0.150214).  Saving model ...
	 Train_Loss: 0.1631 Train_Acc: 93.843 Val_Loss: 0.1502  BEST VAL Loss: 0.1502  Val_Acc: 95.475

Epoch 62: Validation loss decreased (0.150214 --> 0.150098).  Saving model ...
	 Train_Loss: 0.1623 Train_Acc: 94.337 Val_Loss: 0.1501  BEST VAL Loss: 0.1501  Val_Acc: 95.475

Epoch 63: Validation loss decreased (0.150098 --> 0.150083).  Saving model ...
	 Train_Loss: 0.1616 Train_Acc: 94.164 Val_Loss: 0.1501  BEST VAL Loss: 0.1501  Val_Acc: 95.923

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.1609 Train_Acc: 94.164 Val_Loss: 0.1504  BEST VAL Loss: 0.1501  Val_Acc: 95.475

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.1602 Train_Acc: 94.368 Val_Loss: 0.1504  BEST VAL Loss: 0.1501  Val_Acc: 95.638

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.1595 Train_Acc: 93.914 Val_Loss: 0.1502  BEST VAL Loss: 0.1501  Val_Acc: 95.760

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.1588 Train_Acc: 94.450 Val_Loss: 0.1503  BEST VAL Loss: 0.1501  Val_Acc: 95.760

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.1581 Train_Acc: 94.327 Val_Loss: 0.1504  BEST VAL Loss: 0.1501  Val_Acc: 95.556

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.1575 Train_Acc: 94.393 Val_Loss: 0.1506  BEST VAL Loss: 0.1501  Val_Acc: 95.638

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.1569 Train_Acc: 94.123 Val_Loss: 0.1507  BEST VAL Loss: 0.1501  Val_Acc: 95.638

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.1563 Train_Acc: 94.021 Val_Loss: 0.1505  BEST VAL Loss: 0.1501  Val_Acc: 95.556

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.1557 Train_Acc: 94.139 Val_Loss: 0.1505  BEST VAL Loss: 0.1501  Val_Acc: 95.556

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.1551 Train_Acc: 94.286 Val_Loss: 0.1506  BEST VAL Loss: 0.1501  Val_Acc: 96.249

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.1546 Train_Acc: 94.032 Val_Loss: 0.1504  BEST VAL Loss: 0.1501  Val_Acc: 95.720

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.1540 Train_Acc: 94.083 Val_Loss: 0.1503  BEST VAL Loss: 0.1501  Val_Acc: 95.597

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.1535 Train_Acc: 94.062 Val_Loss: 0.1503  BEST VAL Loss: 0.1501  Val_Acc: 95.801

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.1530 Train_Acc: 94.200 Val_Loss: 0.1503  BEST VAL Loss: 0.1501  Val_Acc: 95.516

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.1525 Train_Acc: 94.021 Val_Loss: 0.1504  BEST VAL Loss: 0.1501  Val_Acc: 95.556

Epoch 79: Validation loss did not decrease
Early stopped at epoch : 79
LPS_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.52      0.51     10114
           1       0.48      0.48      0.48      9506

    accuracy                           0.50     19620
   macro avg       0.50      0.50      0.50     19620
weighted avg       0.50      0.50      0.50     19620

LPS_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.51      0.51      1264
           1       0.47      0.47      0.47      1189

    accuracy                           0.49      2453
   macro avg       0.49      0.49      0.49      2453
weighted avg       0.49      0.49      0.49      2453

LPS_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.51      0.50      1264
           1       0.47      0.47      0.47      1189

    accuracy                           0.49      2453
   macro avg       0.49      0.49      0.49      2453
weighted avg       0.49      0.49      0.49      2453

              precision    recall  f1-score   support

           0       0.50      0.51      0.50      1264
           1       0.47      0.47      0.47      1189

    accuracy                           0.49      2453
   macro avg       0.49      0.49      0.49      2453
weighted avg       0.49      0.49      0.49      2453

LPS_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.45      0.48      4168
           1       0.50      0.55      0.52      4103

    accuracy                           0.50      8271
   macro avg       0.50      0.50      0.50      8271
weighted avg       0.50      0.50      0.50      8271

              precision    recall  f1-score   support

           0       0.51      0.45      0.48      4168
           1       0.50      0.55      0.52      4103

    accuracy                           0.50      8271
   macro avg       0.50      0.50      0.50      8271
weighted avg       0.50      0.50      0.50      8271

completed
