[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '2107e6ab'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '9d76fc44'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '06b97d4f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'b4d6c871'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: DMSO_0.100_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: DMSO_0.100_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (50045, 1276)
Number of total missing values across all columns: 71286
Data Subset Is Off
Wells held out for testing: ['I14' 'M21']
Wells to use for training, validation, and testing ['B14' 'C14' 'B15' 'C15' 'J14' 'I15' 'J15' 'M16' 'M17' 'M20']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.123553).  Saving model ...
	 Train_Loss: 0.2677 Train_Acc: 87.591 Val_Loss: 0.1236  BEST VAL Loss: 0.1236  Val_Acc: 94.944

Epoch 1: Validation loss decreased (0.123553 --> 0.111339).  Saving model ...
	 Train_Loss: 0.2157 Train_Acc: 92.001 Val_Loss: 0.1113  BEST VAL Loss: 0.1113  Val_Acc: 95.016

Epoch 2: Validation loss decreased (0.111339 --> 0.101634).  Saving model ...
	 Train_Loss: 0.1893 Train_Acc: 94.269 Val_Loss: 0.1016  BEST VAL Loss: 0.1016  Val_Acc: 96.621

Epoch 3: Validation loss decreased (0.101634 --> 0.095838).  Saving model ...
	 Train_Loss: 0.1734 Train_Acc: 94.694 Val_Loss: 0.0958  BEST VAL Loss: 0.0958  Val_Acc: 96.429

Epoch 4: Validation loss decreased (0.095838 --> 0.091030).  Saving model ...
	 Train_Loss: 0.1624 Train_Acc: 95.114 Val_Loss: 0.0910  BEST VAL Loss: 0.0910  Val_Acc: 97.100

Epoch 5: Validation loss decreased (0.091030 --> 0.089170).  Saving model ...
	 Train_Loss: 0.1549 Train_Acc: 95.176 Val_Loss: 0.0892  BEST VAL Loss: 0.0892  Val_Acc: 96.549

Epoch 6: Validation loss decreased (0.089170 --> 0.086662).  Saving model ...
	 Train_Loss: 0.1479 Train_Acc: 95.563 Val_Loss: 0.0867  BEST VAL Loss: 0.0867  Val_Acc: 97.029

Epoch 7: Validation loss decreased (0.086662 --> 0.084533).  Saving model ...
	 Train_Loss: 0.1428 Train_Acc: 95.563 Val_Loss: 0.0845  BEST VAL Loss: 0.0845  Val_Acc: 97.268

Epoch 8: Validation loss decreased (0.084533 --> 0.082697).  Saving model ...
	 Train_Loss: 0.1384 Train_Acc: 95.563 Val_Loss: 0.0827  BEST VAL Loss: 0.0827  Val_Acc: 97.196

Epoch 9: Validation loss decreased (0.082697 --> 0.080690).  Saving model ...
	 Train_Loss: 0.1342 Train_Acc: 95.803 Val_Loss: 0.0807  BEST VAL Loss: 0.0807  Val_Acc: 97.652

Epoch 10: Validation loss decreased (0.080690 --> 0.079406).  Saving model ...
	 Train_Loss: 0.1307 Train_Acc: 96.027 Val_Loss: 0.0794  BEST VAL Loss: 0.0794  Val_Acc: 97.100

Epoch 11: Validation loss decreased (0.079406 --> 0.077785).  Saving model ...
	 Train_Loss: 0.1276 Train_Acc: 95.973 Val_Loss: 0.0778  BEST VAL Loss: 0.0778  Val_Acc: 97.532

Epoch 12: Validation loss decreased (0.077785 --> 0.076366).  Saving model ...
	 Train_Loss: 0.1252 Train_Acc: 95.776 Val_Loss: 0.0764  BEST VAL Loss: 0.0764  Val_Acc: 97.795

Epoch 13: Validation loss did not decrease
	 Train_Loss: 0.1233 Train_Acc: 95.839 Val_Loss: 0.0767  BEST VAL Loss: 0.0764  Val_Acc: 97.580

Epoch 14: Validation loss decreased (0.076366 --> 0.076082).  Saving model ...
	 Train_Loss: 0.1213 Train_Acc: 96.153 Val_Loss: 0.0761  BEST VAL Loss: 0.0761  Val_Acc: 97.556

Epoch 15: Validation loss decreased (0.076082 --> 0.075186).  Saving model ...
	 Train_Loss: 0.1191 Train_Acc: 96.360 Val_Loss: 0.0752  BEST VAL Loss: 0.0752  Val_Acc: 97.580

Epoch 16: Validation loss decreased (0.075186 --> 0.074422).  Saving model ...
	 Train_Loss: 0.1173 Train_Acc: 96.249 Val_Loss: 0.0744  BEST VAL Loss: 0.0744  Val_Acc: 97.987

Epoch 17: Validation loss decreased (0.074422 --> 0.073251).  Saving model ...
	 Train_Loss: 0.1155 Train_Acc: 96.453 Val_Loss: 0.0733  BEST VAL Loss: 0.0733  Val_Acc: 97.891

Epoch 18: Validation loss decreased (0.073251 --> 0.072365).  Saving model ...
	 Train_Loss: 0.1140 Train_Acc: 96.354 Val_Loss: 0.0724  BEST VAL Loss: 0.0724  Val_Acc: 97.843

Epoch 19: Validation loss did not decrease
	 Train_Loss: 0.1125 Train_Acc: 96.531 Val_Loss: 0.0724  BEST VAL Loss: 0.0724  Val_Acc: 97.891

Epoch 20: Validation loss decreased (0.072365 --> 0.071868).  Saving model ...
	 Train_Loss: 0.1109 Train_Acc: 96.588 Val_Loss: 0.0719  BEST VAL Loss: 0.0719  Val_Acc: 97.987

Epoch 21: Validation loss decreased (0.071868 --> 0.071644).  Saving model ...
	 Train_Loss: 0.1093 Train_Acc: 96.764 Val_Loss: 0.0716  BEST VAL Loss: 0.0716  Val_Acc: 97.867

Epoch 22: Validation loss decreased (0.071644 --> 0.070922).  Saving model ...
	 Train_Loss: 0.1077 Train_Acc: 96.929 Val_Loss: 0.0709  BEST VAL Loss: 0.0709  Val_Acc: 98.083

Epoch 23: Validation loss decreased (0.070922 --> 0.070116).  Saving model ...
	 Train_Loss: 0.1065 Train_Acc: 96.644 Val_Loss: 0.0701  BEST VAL Loss: 0.0701  Val_Acc: 98.155

Epoch 24: Validation loss decreased (0.070116 --> 0.069497).  Saving model ...
	 Train_Loss: 0.1053 Train_Acc: 96.576 Val_Loss: 0.0695  BEST VAL Loss: 0.0695  Val_Acc: 98.011

Epoch 25: Validation loss decreased (0.069497 --> 0.069159).  Saving model ...
	 Train_Loss: 0.1042 Train_Acc: 96.656 Val_Loss: 0.0692  BEST VAL Loss: 0.0692  Val_Acc: 97.580

Epoch 26: Validation loss decreased (0.069159 --> 0.068694).  Saving model ...
	 Train_Loss: 0.1030 Train_Acc: 96.977 Val_Loss: 0.0687  BEST VAL Loss: 0.0687  Val_Acc: 98.083

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.1019 Train_Acc: 96.770 Val_Loss: 0.0690  BEST VAL Loss: 0.0687  Val_Acc: 97.771

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.1012 Train_Acc: 96.459 Val_Loss: 0.0690  BEST VAL Loss: 0.0687  Val_Acc: 97.388

Epoch 29: Validation loss did not decrease
	 Train_Loss: 0.1006 Train_Acc: 96.609 Val_Loss: 0.0696  BEST VAL Loss: 0.0687  Val_Acc: 97.556

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.1000 Train_Acc: 96.636 Val_Loss: 0.0693  BEST VAL Loss: 0.0687  Val_Acc: 97.867

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.0992 Train_Acc: 96.639 Val_Loss: 0.0691  BEST VAL Loss: 0.0687  Val_Acc: 97.508

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.0985 Train_Acc: 96.902 Val_Loss: 0.0689  BEST VAL Loss: 0.0687  Val_Acc: 97.867

Epoch 33: Validation loss decreased (0.068694 --> 0.068370).  Saving model ...
	 Train_Loss: 0.0977 Train_Acc: 96.884 Val_Loss: 0.0684  BEST VAL Loss: 0.0684  Val_Acc: 98.035

Epoch 34: Validation loss decreased (0.068370 --> 0.068040).  Saving model ...
	 Train_Loss: 0.0969 Train_Acc: 96.959 Val_Loss: 0.0680  BEST VAL Loss: 0.0680  Val_Acc: 97.771

Epoch 35: Validation loss decreased (0.068040 --> 0.067531).  Saving model ...
	 Train_Loss: 0.0961 Train_Acc: 97.031 Val_Loss: 0.0675  BEST VAL Loss: 0.0675  Val_Acc: 98.179

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.0953 Train_Acc: 97.028 Val_Loss: 0.0676  BEST VAL Loss: 0.0675  Val_Acc: 98.251

Epoch 37: Validation loss decreased (0.067531 --> 0.067282).  Saving model ...
	 Train_Loss: 0.0947 Train_Acc: 97.037 Val_Loss: 0.0673  BEST VAL Loss: 0.0673  Val_Acc: 97.939

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.0941 Train_Acc: 96.875 Val_Loss: 0.0673  BEST VAL Loss: 0.0673  Val_Acc: 97.819

Epoch 39: Validation loss decreased (0.067282 --> 0.066968).  Saving model ...
	 Train_Loss: 0.0935 Train_Acc: 96.845 Val_Loss: 0.0670  BEST VAL Loss: 0.0670  Val_Acc: 97.987

Epoch 40: Validation loss decreased (0.066968 --> 0.066483).  Saving model ...
	 Train_Loss: 0.0929 Train_Acc: 97.073 Val_Loss: 0.0665  BEST VAL Loss: 0.0665  Val_Acc: 97.939

Epoch 41: Validation loss decreased (0.066483 --> 0.065947).  Saving model ...
	 Train_Loss: 0.0924 Train_Acc: 96.935 Val_Loss: 0.0659  BEST VAL Loss: 0.0659  Val_Acc: 98.275

Epoch 42: Validation loss decreased (0.065947 --> 0.065463).  Saving model ...
	 Train_Loss: 0.0917 Train_Acc: 97.085 Val_Loss: 0.0655  BEST VAL Loss: 0.0655  Val_Acc: 98.131

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.0913 Train_Acc: 96.941 Val_Loss: 0.0655  BEST VAL Loss: 0.0655  Val_Acc: 98.083

Epoch 44: Validation loss decreased (0.065463 --> 0.065095).  Saving model ...
	 Train_Loss: 0.0907 Train_Acc: 97.265 Val_Loss: 0.0651  BEST VAL Loss: 0.0651  Val_Acc: 98.083

Epoch 45: Validation loss decreased (0.065095 --> 0.064957).  Saving model ...
	 Train_Loss: 0.0902 Train_Acc: 96.995 Val_Loss: 0.0650  BEST VAL Loss: 0.0650  Val_Acc: 98.011

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.0897 Train_Acc: 97.118 Val_Loss: 0.0651  BEST VAL Loss: 0.0650  Val_Acc: 98.107

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.0893 Train_Acc: 96.977 Val_Loss: 0.0650  BEST VAL Loss: 0.0650  Val_Acc: 98.083

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.0890 Train_Acc: 96.923 Val_Loss: 0.0651  BEST VAL Loss: 0.0650  Val_Acc: 98.179

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.0888 Train_Acc: 96.704 Val_Loss: 0.0650  BEST VAL Loss: 0.0650  Val_Acc: 97.819

Epoch 50: Validation loss decreased (0.064957 --> 0.064647).  Saving model ...
	 Train_Loss: 0.0884 Train_Acc: 96.962 Val_Loss: 0.0646  BEST VAL Loss: 0.0646  Val_Acc: 98.179

Epoch 51: Validation loss decreased (0.064647 --> 0.064600).  Saving model ...
	 Train_Loss: 0.0879 Train_Acc: 97.103 Val_Loss: 0.0646  BEST VAL Loss: 0.0646  Val_Acc: 97.891

Epoch 52: Validation loss decreased (0.064600 --> 0.064539).  Saving model ...
	 Train_Loss: 0.0875 Train_Acc: 97.202 Val_Loss: 0.0645  BEST VAL Loss: 0.0645  Val_Acc: 97.508

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.0871 Train_Acc: 96.791 Val_Loss: 0.0647  BEST VAL Loss: 0.0645  Val_Acc: 97.987

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.0867 Train_Acc: 97.367 Val_Loss: 0.0647  BEST VAL Loss: 0.0645  Val_Acc: 98.227

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.0862 Train_Acc: 97.241 Val_Loss: 0.0647  BEST VAL Loss: 0.0645  Val_Acc: 97.963

Epoch 56: Validation loss decreased (0.064539 --> 0.064510).  Saving model ...
	 Train_Loss: 0.0859 Train_Acc: 97.169 Val_Loss: 0.0645  BEST VAL Loss: 0.0645  Val_Acc: 97.867

Epoch 57: Validation loss decreased (0.064510 --> 0.064480).  Saving model ...
	 Train_Loss: 0.0854 Train_Acc: 97.277 Val_Loss: 0.0645  BEST VAL Loss: 0.0645  Val_Acc: 97.819

Epoch 58: Validation loss decreased (0.064480 --> 0.064329).  Saving model ...
	 Train_Loss: 0.0849 Train_Acc: 97.534 Val_Loss: 0.0643  BEST VAL Loss: 0.0643  Val_Acc: 98.155

Epoch 59: Validation loss decreased (0.064329 --> 0.064272).  Saving model ...
	 Train_Loss: 0.0845 Train_Acc: 97.618 Val_Loss: 0.0643  BEST VAL Loss: 0.0643  Val_Acc: 97.915

Epoch 60: Validation loss decreased (0.064272 --> 0.064237).  Saving model ...
	 Train_Loss: 0.0842 Train_Acc: 97.202 Val_Loss: 0.0642  BEST VAL Loss: 0.0642  Val_Acc: 98.299

Epoch 61: Validation loss decreased (0.064237 --> 0.064185).  Saving model ...
	 Train_Loss: 0.0839 Train_Acc: 97.178 Val_Loss: 0.0642  BEST VAL Loss: 0.0642  Val_Acc: 98.203

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.0835 Train_Acc: 97.241 Val_Loss: 0.0642  BEST VAL Loss: 0.0642  Val_Acc: 97.987

Epoch 63: Validation loss decreased (0.064185 --> 0.064082).  Saving model ...
	 Train_Loss: 0.0832 Train_Acc: 97.399 Val_Loss: 0.0641  BEST VAL Loss: 0.0641  Val_Acc: 97.915

Epoch 64: Validation loss decreased (0.064082 --> 0.063918).  Saving model ...
	 Train_Loss: 0.0827 Train_Acc: 97.358 Val_Loss: 0.0639  BEST VAL Loss: 0.0639  Val_Acc: 98.011

Epoch 65: Validation loss decreased (0.063918 --> 0.063803).  Saving model ...
	 Train_Loss: 0.0825 Train_Acc: 97.181 Val_Loss: 0.0638  BEST VAL Loss: 0.0638  Val_Acc: 97.867

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.0823 Train_Acc: 97.187 Val_Loss: 0.0640  BEST VAL Loss: 0.0638  Val_Acc: 98.035

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.0821 Train_Acc: 97.190 Val_Loss: 0.0640  BEST VAL Loss: 0.0638  Val_Acc: 98.083

Epoch 68: Validation loss decreased (0.063803 --> 0.063799).  Saving model ...
	 Train_Loss: 0.0819 Train_Acc: 97.193 Val_Loss: 0.0638  BEST VAL Loss: 0.0638  Val_Acc: 98.035

Epoch 69: Validation loss decreased (0.063799 --> 0.063613).  Saving model ...
	 Train_Loss: 0.0816 Train_Acc: 97.199 Val_Loss: 0.0636  BEST VAL Loss: 0.0636  Val_Acc: 98.251

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.0816 Train_Acc: 97.100 Val_Loss: 0.0645  BEST VAL Loss: 0.0636  Val_Acc: 97.220

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.0825 Train_Acc: 96.036 Val_Loss: 0.0650  BEST VAL Loss: 0.0636  Val_Acc: 96.765

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.0842 Train_Acc: 91.431 Val_Loss: 0.0658  BEST VAL Loss: 0.0636  Val_Acc: 94.464

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.0858 Train_Acc: 91.683 Val_Loss: 0.0669  BEST VAL Loss: 0.0636  Val_Acc: 94.153

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.0874 Train_Acc: 92.142 Val_Loss: 0.0672  BEST VAL Loss: 0.0636  Val_Acc: 96.334

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.0886 Train_Acc: 92.753 Val_Loss: 0.0674  BEST VAL Loss: 0.0636  Val_Acc: 95.878

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.0894 Train_Acc: 93.268 Val_Loss: 0.0676  BEST VAL Loss: 0.0636  Val_Acc: 95.639

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.0902 Train_Acc: 93.547 Val_Loss: 0.0677  BEST VAL Loss: 0.0636  Val_Acc: 95.998

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.0910 Train_Acc: 93.394 Val_Loss: 0.0678  BEST VAL Loss: 0.0636  Val_Acc: 96.142

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.0917 Train_Acc: 93.756 Val_Loss: 0.0676  BEST VAL Loss: 0.0636  Val_Acc: 97.795

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.0922 Train_Acc: 94.230 Val_Loss: 0.0676  BEST VAL Loss: 0.0636  Val_Acc: 96.837

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.0928 Train_Acc: 94.194 Val_Loss: 0.0678  BEST VAL Loss: 0.0636  Val_Acc: 96.429

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.0933 Train_Acc: 94.020 Val_Loss: 0.0678  BEST VAL Loss: 0.0636  Val_Acc: 96.693

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.0938 Train_Acc: 94.272 Val_Loss: 0.0678  BEST VAL Loss: 0.0636  Val_Acc: 97.340

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.0943 Train_Acc: 94.254 Val_Loss: 0.0676  BEST VAL Loss: 0.0636  Val_Acc: 97.628

Epoch 85: Validation loss did not decrease
Early stopped at epoch : 85
DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      1.00      1.00     24644
           1       0.99      0.99      0.99      8734

    accuracy                           0.99     33378
   macro avg       0.99      0.99      0.99     33378
weighted avg       0.99      0.99      0.99     33378

DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      0.99      0.99      3081
           1       0.97      0.97      0.97      1092

    accuracy                           0.98      4173
   macro avg       0.98      0.98      0.98      4173
weighted avg       0.98      0.98      0.98      4173

DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      0.99      0.99      3081
           1       0.96      0.96      0.96      1092

    accuracy                           0.98      4173
   macro avg       0.97      0.97      0.97      4173
weighted avg       0.98      0.98      0.98      4173

              precision    recall  f1-score   support

           0       0.99      0.99      0.99      3081
           1       0.96      0.96      0.96      1092

    accuracy                           0.98      4173
   macro avg       0.97      0.97      0.97      4173
weighted avg       0.98      0.98      0.98      4173

DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.99      0.98      4837
           1       0.99      0.96      0.97      3484

    accuracy                           0.98      8321
   macro avg       0.98      0.98      0.98      8321
weighted avg       0.98      0.98      0.98      8321

              precision    recall  f1-score   support

           0       0.97      0.99      0.98      4837
           1       0.99      0.96      0.97      3484

    accuracy                           0.98      8321
   macro avg       0.98      0.98      0.98      8321
weighted avg       0.98      0.98      0.98      8321

completed
