[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '95a74864'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'f8c04096'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'bfb28ce2'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'd3487b5d'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_1.000_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_1.000_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (32445, 1276)
Number of total missing values across all columns: 64890
Data Subset Is Off
Wells held out for testing: ['D20' 'J16']
Wells to use for training, validation, and testing ['D16' 'D17' 'D21' 'J17' 'J20' 'J21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.440333).  Saving model ...
	 Train_Loss: 0.6477 Train_Acc: 66.630 Val_Loss: 0.4403  BEST VAL Loss: 0.4403  Val_Acc: 78.825

Epoch 1: Validation loss decreased (0.440333 --> 0.411876).  Saving model ...
	 Train_Loss: 0.5451 Train_Acc: 77.190 Val_Loss: 0.4119  BEST VAL Loss: 0.4119  Val_Acc: 82.299

Epoch 2: Validation loss decreased (0.411876 --> 0.371691).  Saving model ...
	 Train_Loss: 0.4857 Train_Acc: 79.745 Val_Loss: 0.3717  BEST VAL Loss: 0.3717  Val_Acc: 88.213

Epoch 3: Validation loss decreased (0.371691 --> 0.347816).  Saving model ...
	 Train_Loss: 0.4444 Train_Acc: 83.980 Val_Loss: 0.3478  BEST VAL Loss: 0.3478  Val_Acc: 87.262

Epoch 4: Validation loss decreased (0.347816 --> 0.330067).  Saving model ...
	 Train_Loss: 0.4133 Train_Acc: 86.090 Val_Loss: 0.3301  BEST VAL Loss: 0.3301  Val_Acc: 87.758

Epoch 5: Validation loss decreased (0.330067 --> 0.318128).  Saving model ...
	 Train_Loss: 0.3898 Train_Acc: 86.901 Val_Loss: 0.3181  BEST VAL Loss: 0.3181  Val_Acc: 88.255

Epoch 6: Validation loss decreased (0.318128 --> 0.310570).  Saving model ...
	 Train_Loss: 0.3709 Train_Acc: 87.775 Val_Loss: 0.3106  BEST VAL Loss: 0.3106  Val_Acc: 89.537

Epoch 7: Validation loss decreased (0.310570 --> 0.301904).  Saving model ...
	 Train_Loss: 0.3543 Train_Acc: 88.603 Val_Loss: 0.3019  BEST VAL Loss: 0.3019  Val_Acc: 90.488

Epoch 8: Validation loss decreased (0.301904 --> 0.293641).  Saving model ...
	 Train_Loss: 0.3403 Train_Acc: 89.120 Val_Loss: 0.2936  BEST VAL Loss: 0.2936  Val_Acc: 91.356

Epoch 9: Validation loss decreased (0.293641 --> 0.286096).  Saving model ...
	 Train_Loss: 0.3289 Train_Acc: 89.497 Val_Loss: 0.2861  BEST VAL Loss: 0.2861  Val_Acc: 91.481

Epoch 10: Validation loss decreased (0.286096 --> 0.281700).  Saving model ...
	 Train_Loss: 0.3184 Train_Acc: 89.859 Val_Loss: 0.2817  BEST VAL Loss: 0.2817  Val_Acc: 91.315

Epoch 11: Validation loss decreased (0.281700 --> 0.277293).  Saving model ...
	 Train_Loss: 0.3086 Train_Acc: 90.340 Val_Loss: 0.2773  BEST VAL Loss: 0.2773  Val_Acc: 92.060

Epoch 12: Validation loss decreased (0.277293 --> 0.273126).  Saving model ...
	 Train_Loss: 0.3004 Train_Acc: 90.258 Val_Loss: 0.2731  BEST VAL Loss: 0.2731  Val_Acc: 92.101

Epoch 13: Validation loss decreased (0.273126 --> 0.268959).  Saving model ...
	 Train_Loss: 0.2934 Train_Acc: 90.097 Val_Loss: 0.2690  BEST VAL Loss: 0.2690  Val_Acc: 91.522

Epoch 14: Validation loss decreased (0.268959 --> 0.264155).  Saving model ...
	 Train_Loss: 0.2868 Train_Acc: 90.470 Val_Loss: 0.2642  BEST VAL Loss: 0.2642  Val_Acc: 92.266

Epoch 15: Validation loss decreased (0.264155 --> 0.260177).  Saving model ...
	 Train_Loss: 0.2808 Train_Acc: 90.392 Val_Loss: 0.2602  BEST VAL Loss: 0.2602  Val_Acc: 92.225

Epoch 16: Validation loss decreased (0.260177 --> 0.258169).  Saving model ...
	 Train_Loss: 0.2752 Train_Acc: 91.152 Val_Loss: 0.2582  BEST VAL Loss: 0.2582  Val_Acc: 92.101

Epoch 17: Validation loss did not decrease
	 Train_Loss: 0.2701 Train_Acc: 91.214 Val_Loss: 0.2590  BEST VAL Loss: 0.2582  Val_Acc: 92.639

Epoch 18: Validation loss decreased (0.258169 --> 0.257453).  Saving model ...
	 Train_Loss: 0.2654 Train_Acc: 91.131 Val_Loss: 0.2575  BEST VAL Loss: 0.2575  Val_Acc: 92.184

Epoch 19: Validation loss did not decrease
	 Train_Loss: 0.2607 Train_Acc: 91.602 Val_Loss: 0.2579  BEST VAL Loss: 0.2575  Val_Acc: 92.349

Epoch 20: Validation loss did not decrease
	 Train_Loss: 0.2566 Train_Acc: 91.137 Val_Loss: 0.2577  BEST VAL Loss: 0.2575  Val_Acc: 92.556

Epoch 21: Validation loss did not decrease
	 Train_Loss: 0.2529 Train_Acc: 91.499 Val_Loss: 0.2601  BEST VAL Loss: 0.2575  Val_Acc: 92.308

Epoch 22: Validation loss did not decrease
	 Train_Loss: 0.2496 Train_Acc: 91.338 Val_Loss: 0.2586  BEST VAL Loss: 0.2575  Val_Acc: 92.514

Epoch 23: Validation loss did not decrease
	 Train_Loss: 0.2461 Train_Acc: 91.768 Val_Loss: 0.2578  BEST VAL Loss: 0.2575  Val_Acc: 93.135

Epoch 24: Validation loss decreased (0.257453 --> 0.256713).  Saving model ...
	 Train_Loss: 0.2430 Train_Acc: 91.680 Val_Loss: 0.2567  BEST VAL Loss: 0.2567  Val_Acc: 92.887

Epoch 25: Validation loss decreased (0.256713 --> 0.256256).  Saving model ...
	 Train_Loss: 0.2402 Train_Acc: 91.266 Val_Loss: 0.2563  BEST VAL Loss: 0.2563  Val_Acc: 92.060

Epoch 26: Validation loss decreased (0.256256 --> 0.255557).  Saving model ...
	 Train_Loss: 0.2378 Train_Acc: 91.256 Val_Loss: 0.2556  BEST VAL Loss: 0.2556  Val_Acc: 92.225

Epoch 27: Validation loss decreased (0.255557 --> 0.254910).  Saving model ...
	 Train_Loss: 0.2355 Train_Acc: 91.442 Val_Loss: 0.2549  BEST VAL Loss: 0.2549  Val_Acc: 92.887

Epoch 28: Validation loss decreased (0.254910 --> 0.254793).  Saving model ...
	 Train_Loss: 0.2331 Train_Acc: 91.866 Val_Loss: 0.2548  BEST VAL Loss: 0.2548  Val_Acc: 92.432

Epoch 29: Validation loss decreased (0.254793 --> 0.254558).  Saving model ...
	 Train_Loss: 0.2306 Train_Acc: 92.119 Val_Loss: 0.2546  BEST VAL Loss: 0.2546  Val_Acc: 92.887

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.2283 Train_Acc: 92.109 Val_Loss: 0.2554  BEST VAL Loss: 0.2546  Val_Acc: 93.093

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.2259 Train_Acc: 92.290 Val_Loss: 0.2551  BEST VAL Loss: 0.2546  Val_Acc: 92.514

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.2237 Train_Acc: 92.357 Val_Loss: 0.2550  BEST VAL Loss: 0.2546  Val_Acc: 92.597

Epoch 33: Validation loss decreased (0.254558 --> 0.254211).  Saving model ...
	 Train_Loss: 0.2218 Train_Acc: 92.093 Val_Loss: 0.2542  BEST VAL Loss: 0.2542  Val_Acc: 92.556

Epoch 34: Validation loss did not decrease
	 Train_Loss: 0.2201 Train_Acc: 91.773 Val_Loss: 0.2557  BEST VAL Loss: 0.2542  Val_Acc: 92.514

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.2187 Train_Acc: 91.731 Val_Loss: 0.2555  BEST VAL Loss: 0.2542  Val_Acc: 92.308

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.2171 Train_Acc: 91.881 Val_Loss: 0.2560  BEST VAL Loss: 0.2542  Val_Acc: 92.060

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.2152 Train_Acc: 92.419 Val_Loss: 0.2565  BEST VAL Loss: 0.2542  Val_Acc: 92.763

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.2134 Train_Acc: 92.667 Val_Loss: 0.2560  BEST VAL Loss: 0.2542  Val_Acc: 92.473

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.2118 Train_Acc: 92.383 Val_Loss: 0.2567  BEST VAL Loss: 0.2542  Val_Acc: 92.060

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.2106 Train_Acc: 91.814 Val_Loss: 0.2568  BEST VAL Loss: 0.2542  Val_Acc: 91.894

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.2093 Train_Acc: 92.212 Val_Loss: 0.2562  BEST VAL Loss: 0.2542  Val_Acc: 91.150

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.2079 Train_Acc: 92.062 Val_Loss: 0.2559  BEST VAL Loss: 0.2542  Val_Acc: 92.928

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.2065 Train_Acc: 92.476 Val_Loss: 0.2558  BEST VAL Loss: 0.2542  Val_Acc: 92.969

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.2051 Train_Acc: 92.414 Val_Loss: 0.2565  BEST VAL Loss: 0.2542  Val_Acc: 92.556

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.2037 Train_Acc: 92.688 Val_Loss: 0.2564  BEST VAL Loss: 0.2542  Val_Acc: 92.680

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.2026 Train_Acc: 92.419 Val_Loss: 0.2560  BEST VAL Loss: 0.2542  Val_Acc: 92.473

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.2015 Train_Acc: 92.466 Val_Loss: 0.2568  BEST VAL Loss: 0.2542  Val_Acc: 91.935

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.2002 Train_Acc: 92.440 Val_Loss: 0.2578  BEST VAL Loss: 0.2542  Val_Acc: 91.356

Epoch 49: Validation loss did not decrease
Early stopped at epoch : 49
LPS_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.50      0.50      9832
           1       0.48      0.49      0.49      9506

    accuracy                           0.49     19338
   macro avg       0.49      0.49      0.49     19338
weighted avg       0.49      0.49      0.49     19338

LPS_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.50      0.50      1229
           1       0.48      0.48      0.48      1189

    accuracy                           0.49      2418
   macro avg       0.49      0.49      0.49      2418
weighted avg       0.49      0.49      0.49      2418

LPS_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.51      0.51      1229
           1       0.50      0.51      0.50      1189

    accuracy                           0.51      2418
   macro avg       0.51      0.51      0.51      2418
weighted avg       0.51      0.51      0.51      2418

              precision    recall  f1-score   support

           0       0.52      0.51      0.51      1229
           1       0.50      0.51      0.50      1189

    accuracy                           0.51      2418
   macro avg       0.51      0.51      0.51      2418
weighted avg       0.51      0.51      0.51      2418

LPS_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.51      0.51      4168
           1       0.50      0.49      0.49      4103

    accuracy                           0.50      8271
   macro avg       0.50      0.50      0.50      8271
weighted avg       0.50      0.50      0.50      8271

              precision    recall  f1-score   support

           0       0.50      0.51      0.51      4168
           1       0.50      0.49      0.49      4103

    accuracy                           0.50      8271
   macro avg       0.50      0.50      0.50      8271
weighted avg       0.50      0.50      0.50      8271

completed
