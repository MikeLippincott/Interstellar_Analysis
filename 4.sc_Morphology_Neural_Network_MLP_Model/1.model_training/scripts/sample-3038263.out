[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '88624311'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '1e650438'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '943e4dfa'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'fe2327b1'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Thapsigargin_10.000_DMSO_0.025 treatment_name: LPS_10.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Thapsigargin_10.000_DMSO_0.025
TREATMENT_NAME: LPS_10.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'Thapsigargin_10.000_DMSO_0.025']
The dimensions of the data are: (323474, 1270)
Number of total missing values across all columns: 646948
Data Subset Is Off
Wells held out for testing: ['E09' 'L06']
Wells to use for training, validation, and testing ['E02' 'E03' 'E06' 'E07' 'E08' 'L07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.343041).  Saving model ...
	 Train_Loss: 0.4914 Train_Acc: 76.112 Val_Loss: 0.3430  BEST VAL Loss: 0.3430  Val_Acc: 84.820

Epoch 1: Validation loss decreased (0.343041 --> 0.326559).  Saving model ...
	 Train_Loss: 0.4256 Train_Acc: 83.663 Val_Loss: 0.3266  BEST VAL Loss: 0.3266  Val_Acc: 86.337

Epoch 2: Validation loss decreased (0.326559 --> 0.311420).  Saving model ...
	 Train_Loss: 0.3931 Train_Acc: 85.456 Val_Loss: 0.3114  BEST VAL Loss: 0.3114  Val_Acc: 87.863

Epoch 3: Validation loss decreased (0.311420 --> 0.301408).  Saving model ...
	 Train_Loss: 0.3732 Train_Acc: 86.272 Val_Loss: 0.3014  BEST VAL Loss: 0.3014  Val_Acc: 88.276

Epoch 4: Validation loss decreased (0.301408 --> 0.294932).  Saving model ...
	 Train_Loss: 0.3591 Train_Acc: 86.819 Val_Loss: 0.2949  BEST VAL Loss: 0.2949  Val_Acc: 88.508

Epoch 5: Validation loss decreased (0.294932 --> 0.287862).  Saving model ...
	 Train_Loss: 0.3485 Train_Acc: 87.115 Val_Loss: 0.2879  BEST VAL Loss: 0.2879  Val_Acc: 89.165

Epoch 6: Validation loss decreased (0.287862 --> 0.283175).  Saving model ...
	 Train_Loss: 0.3400 Train_Acc: 87.398 Val_Loss: 0.2832  BEST VAL Loss: 0.2832  Val_Acc: 88.988

Epoch 7: Validation loss decreased (0.283175 --> 0.278982).  Saving model ...
	 Train_Loss: 0.3332 Train_Acc: 87.655 Val_Loss: 0.2790  BEST VAL Loss: 0.2790  Val_Acc: 89.342

Epoch 8: Validation loss decreased (0.278982 --> 0.275564).  Saving model ...
	 Train_Loss: 0.3276 Train_Acc: 87.700 Val_Loss: 0.2756  BEST VAL Loss: 0.2756  Val_Acc: 89.532

Epoch 9: Validation loss decreased (0.275564 --> 0.272523).  Saving model ...
	 Train_Loss: 0.3228 Train_Acc: 87.909 Val_Loss: 0.2725  BEST VAL Loss: 0.2725  Val_Acc: 89.776

Epoch 10: Validation loss decreased (0.272523 --> 0.270226).  Saving model ...
	 Train_Loss: 0.3186 Train_Acc: 88.013 Val_Loss: 0.2702  BEST VAL Loss: 0.2702  Val_Acc: 89.637

Epoch 11: Validation loss decreased (0.270226 --> 0.267925).  Saving model ...
	 Train_Loss: 0.3148 Train_Acc: 88.219 Val_Loss: 0.2679  BEST VAL Loss: 0.2679  Val_Acc: 89.802

Epoch 12: Validation loss decreased (0.267925 --> 0.266320).  Saving model ...
	 Train_Loss: 0.3114 Train_Acc: 88.277 Val_Loss: 0.2663  BEST VAL Loss: 0.2663  Val_Acc: 89.591

Epoch 13: Validation loss decreased (0.266320 --> 0.264244).  Saving model ...
	 Train_Loss: 0.3084 Train_Acc: 88.351 Val_Loss: 0.2642  BEST VAL Loss: 0.2642  Val_Acc: 90.181

Epoch 14: Validation loss decreased (0.264244 --> 0.262576).  Saving model ...
	 Train_Loss: 0.3057 Train_Acc: 88.462 Val_Loss: 0.2626  BEST VAL Loss: 0.2626  Val_Acc: 89.983

Epoch 15: Validation loss decreased (0.262576 --> 0.261565).  Saving model ...
	 Train_Loss: 0.3032 Train_Acc: 88.528 Val_Loss: 0.2616  BEST VAL Loss: 0.2616  Val_Acc: 89.679

Epoch 16: Validation loss decreased (0.261565 --> 0.260252).  Saving model ...
	 Train_Loss: 0.3009 Train_Acc: 88.625 Val_Loss: 0.2603  BEST VAL Loss: 0.2603  Val_Acc: 90.067

Epoch 17: Validation loss decreased (0.260252 --> 0.259802).  Saving model ...
	 Train_Loss: 0.2990 Train_Acc: 88.444 Val_Loss: 0.2598  BEST VAL Loss: 0.2598  Val_Acc: 89.426

Epoch 18: Validation loss decreased (0.259802 --> 0.258368).  Saving model ...
	 Train_Loss: 0.2970 Train_Acc: 88.619 Val_Loss: 0.2584  BEST VAL Loss: 0.2584  Val_Acc: 90.467

Epoch 19: Validation loss decreased (0.258368 --> 0.257256).  Saving model ...
	 Train_Loss: 0.2951 Train_Acc: 88.798 Val_Loss: 0.2573  BEST VAL Loss: 0.2573  Val_Acc: 90.033

Epoch 20: Validation loss decreased (0.257256 --> 0.256472).  Saving model ...
	 Train_Loss: 0.2935 Train_Acc: 88.735 Val_Loss: 0.2565  BEST VAL Loss: 0.2565  Val_Acc: 89.886

Epoch 21: Validation loss decreased (0.256472 --> 0.255373).  Saving model ...
	 Train_Loss: 0.2919 Train_Acc: 88.758 Val_Loss: 0.2554  BEST VAL Loss: 0.2554  Val_Acc: 90.282

Epoch 22: Validation loss decreased (0.255373 --> 0.254607).  Saving model ...
	 Train_Loss: 0.2903 Train_Acc: 88.913 Val_Loss: 0.2546  BEST VAL Loss: 0.2546  Val_Acc: 90.122

Epoch 23: Validation loss decreased (0.254607 --> 0.254128).  Saving model ...
	 Train_Loss: 0.2889 Train_Acc: 88.916 Val_Loss: 0.2541  BEST VAL Loss: 0.2541  Val_Acc: 89.987

Epoch 24: Validation loss decreased (0.254128 --> 0.253441).  Saving model ...
	 Train_Loss: 0.2876 Train_Acc: 88.777 Val_Loss: 0.2534  BEST VAL Loss: 0.2534  Val_Acc: 90.092

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.2864 Train_Acc: 88.844 Val_Loss: 0.2535  BEST VAL Loss: 0.2534  Val_Acc: 89.376

Epoch 26: Validation loss decreased (0.253441 --> 0.253185).  Saving model ...
	 Train_Loss: 0.2852 Train_Acc: 88.973 Val_Loss: 0.2532  BEST VAL Loss: 0.2532  Val_Acc: 89.780

Epoch 27: Validation loss decreased (0.253185 --> 0.252537).  Saving model ...
	 Train_Loss: 0.2839 Train_Acc: 89.072 Val_Loss: 0.2525  BEST VAL Loss: 0.2525  Val_Acc: 90.000

Epoch 28: Validation loss decreased (0.252537 --> 0.252013).  Saving model ...
	 Train_Loss: 0.2828 Train_Acc: 89.082 Val_Loss: 0.2520  BEST VAL Loss: 0.2520  Val_Acc: 89.966

Epoch 29: Validation loss decreased (0.252013 --> 0.251551).  Saving model ...
	 Train_Loss: 0.2817 Train_Acc: 89.084 Val_Loss: 0.2516  BEST VAL Loss: 0.2516  Val_Acc: 90.016

Epoch 30: Validation loss decreased (0.251551 --> 0.251103).  Saving model ...
	 Train_Loss: 0.2808 Train_Acc: 89.086 Val_Loss: 0.2511  BEST VAL Loss: 0.2511  Val_Acc: 89.987

Epoch 31: Validation loss decreased (0.251103 --> 0.250469).  Saving model ...
	 Train_Loss: 0.2798 Train_Acc: 89.126 Val_Loss: 0.2505  BEST VAL Loss: 0.2505  Val_Acc: 90.341

Epoch 32: Validation loss decreased (0.250469 --> 0.250410).  Saving model ...
	 Train_Loss: 0.2788 Train_Acc: 89.247 Val_Loss: 0.2504  BEST VAL Loss: 0.2504  Val_Acc: 89.945

Epoch 33: Validation loss decreased (0.250410 --> 0.250090).  Saving model ...
	 Train_Loss: 0.2780 Train_Acc: 89.028 Val_Loss: 0.2501  BEST VAL Loss: 0.2501  Val_Acc: 90.042

Epoch 34: Validation loss decreased (0.250090 --> 0.249886).  Saving model ...
	 Train_Loss: 0.2770 Train_Acc: 89.251 Val_Loss: 0.2499  BEST VAL Loss: 0.2499  Val_Acc: 89.924

Epoch 35: Validation loss decreased (0.249886 --> 0.249670).  Saving model ...
	 Train_Loss: 0.2762 Train_Acc: 89.267 Val_Loss: 0.2497  BEST VAL Loss: 0.2497  Val_Acc: 89.536

Epoch 36: Validation loss decreased (0.249670 --> 0.249266).  Saving model ...
	 Train_Loss: 0.2754 Train_Acc: 89.198 Val_Loss: 0.2493  BEST VAL Loss: 0.2493  Val_Acc: 90.396

Epoch 37: Validation loss decreased (0.249266 --> 0.248891).  Saving model ...
	 Train_Loss: 0.2746 Train_Acc: 89.231 Val_Loss: 0.2489  BEST VAL Loss: 0.2489  Val_Acc: 90.156

Epoch 38: Validation loss decreased (0.248891 --> 0.248503).  Saving model ...
	 Train_Loss: 0.2738 Train_Acc: 89.339 Val_Loss: 0.2485  BEST VAL Loss: 0.2485  Val_Acc: 90.219

Epoch 39: Validation loss decreased (0.248503 --> 0.248475).  Saving model ...
	 Train_Loss: 0.2730 Train_Acc: 89.387 Val_Loss: 0.2485  BEST VAL Loss: 0.2485  Val_Acc: 89.751

Epoch 40: Validation loss decreased (0.248475 --> 0.248469).  Saving model ...
	 Train_Loss: 0.2723 Train_Acc: 89.237 Val_Loss: 0.2485  BEST VAL Loss: 0.2485  Val_Acc: 89.898

Epoch 41: Validation loss decreased (0.248469 --> 0.248060).  Saving model ...
	 Train_Loss: 0.2717 Train_Acc: 89.224 Val_Loss: 0.2481  BEST VAL Loss: 0.2481  Val_Acc: 90.628

Epoch 42: Validation loss decreased (0.248060 --> 0.247616).  Saving model ...
	 Train_Loss: 0.2711 Train_Acc: 89.349 Val_Loss: 0.2476  BEST VAL Loss: 0.2476  Val_Acc: 90.278

Epoch 43: Validation loss decreased (0.247616 --> 0.247294).  Saving model ...
	 Train_Loss: 0.2705 Train_Acc: 89.272 Val_Loss: 0.2473  BEST VAL Loss: 0.2473  Val_Acc: 90.231

Epoch 44: Validation loss decreased (0.247294 --> 0.246980).  Saving model ...
	 Train_Loss: 0.2699 Train_Acc: 89.288 Val_Loss: 0.2470  BEST VAL Loss: 0.2470  Val_Acc: 90.105

Epoch 45: Validation loss decreased (0.246980 --> 0.246528).  Saving model ...
	 Train_Loss: 0.2694 Train_Acc: 89.358 Val_Loss: 0.2465  BEST VAL Loss: 0.2465  Val_Acc: 90.345

Epoch 46: Validation loss decreased (0.246528 --> 0.246305).  Saving model ...
	 Train_Loss: 0.2688 Train_Acc: 89.463 Val_Loss: 0.2463  BEST VAL Loss: 0.2463  Val_Acc: 90.316

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.2682 Train_Acc: 89.398 Val_Loss: 0.2464  BEST VAL Loss: 0.2463  Val_Acc: 89.848

Epoch 48: Validation loss decreased (0.246305 --> 0.246115).  Saving model ...
	 Train_Loss: 0.2676 Train_Acc: 89.398 Val_Loss: 0.2461  BEST VAL Loss: 0.2461  Val_Acc: 90.413

Epoch 49: Validation loss decreased (0.246115 --> 0.245724).  Saving model ...
	 Train_Loss: 0.2672 Train_Acc: 89.334 Val_Loss: 0.2457  BEST VAL Loss: 0.2457  Val_Acc: 90.425

Epoch 50: Validation loss decreased (0.245724 --> 0.245437).  Saving model ...
	 Train_Loss: 0.2667 Train_Acc: 89.480 Val_Loss: 0.2454  BEST VAL Loss: 0.2454  Val_Acc: 90.067

Epoch 51: Validation loss decreased (0.245437 --> 0.245198).  Saving model ...
	 Train_Loss: 0.2661 Train_Acc: 89.442 Val_Loss: 0.2452  BEST VAL Loss: 0.2452  Val_Acc: 90.118

Epoch 52: Validation loss decreased (0.245198 --> 0.244955).  Saving model ...
	 Train_Loss: 0.2657 Train_Acc: 89.485 Val_Loss: 0.2450  BEST VAL Loss: 0.2450  Val_Acc: 90.016

Epoch 53: Validation loss decreased (0.244955 --> 0.244826).  Saving model ...
	 Train_Loss: 0.2652 Train_Acc: 89.461 Val_Loss: 0.2448  BEST VAL Loss: 0.2448  Val_Acc: 90.303

Epoch 54: Validation loss decreased (0.244826 --> 0.244422).  Saving model ...
	 Train_Loss: 0.2647 Train_Acc: 89.470 Val_Loss: 0.2444  BEST VAL Loss: 0.2444  Val_Acc: 90.754

Epoch 55: Validation loss decreased (0.244422 --> 0.244181).  Saving model ...
	 Train_Loss: 0.2643 Train_Acc: 89.456 Val_Loss: 0.2442  BEST VAL Loss: 0.2442  Val_Acc: 90.480

Epoch 56: Validation loss decreased (0.244181 --> 0.243882).  Saving model ...
	 Train_Loss: 0.2638 Train_Acc: 89.428 Val_Loss: 0.2439  BEST VAL Loss: 0.2439  Val_Acc: 90.678

Epoch 57: Validation loss decreased (0.243882 --> 0.243688).  Saving model ...
	 Train_Loss: 0.2634 Train_Acc: 89.564 Val_Loss: 0.2437  BEST VAL Loss: 0.2437  Val_Acc: 90.404

Epoch 58: Validation loss decreased (0.243688 --> 0.243573).  Saving model ...
	 Train_Loss: 0.2629 Train_Acc: 89.470 Val_Loss: 0.2436  BEST VAL Loss: 0.2436  Val_Acc: 90.172

Epoch 59: Validation loss decreased (0.243573 --> 0.243344).  Saving model ...
	 Train_Loss: 0.2625 Train_Acc: 89.517 Val_Loss: 0.2433  BEST VAL Loss: 0.2433  Val_Acc: 90.526

Epoch 60: Validation loss decreased (0.243344 --> 0.243122).  Saving model ...
	 Train_Loss: 0.2621 Train_Acc: 89.567 Val_Loss: 0.2431  BEST VAL Loss: 0.2431  Val_Acc: 90.408

Epoch 61: Validation loss decreased (0.243122 --> 0.242826).  Saving model ...
	 Train_Loss: 0.2617 Train_Acc: 89.477 Val_Loss: 0.2428  BEST VAL Loss: 0.2428  Val_Acc: 90.712

Epoch 62: Validation loss decreased (0.242826 --> 0.242541).  Saving model ...
	 Train_Loss: 0.2612 Train_Acc: 89.590 Val_Loss: 0.2425  BEST VAL Loss: 0.2425  Val_Acc: 90.800

Epoch 63: Validation loss decreased (0.242541 --> 0.242362).  Saving model ...
	 Train_Loss: 0.2608 Train_Acc: 89.616 Val_Loss: 0.2424  BEST VAL Loss: 0.2424  Val_Acc: 90.476

Epoch 64: Validation loss decreased (0.242362 --> 0.242206).  Saving model ...
	 Train_Loss: 0.2604 Train_Acc: 89.575 Val_Loss: 0.2422  BEST VAL Loss: 0.2422  Val_Acc: 90.366

Epoch 65: Validation loss decreased (0.242206 --> 0.241949).  Saving model ...
	 Train_Loss: 0.2600 Train_Acc: 89.573 Val_Loss: 0.2419  BEST VAL Loss: 0.2419  Val_Acc: 90.703

Epoch 66: Validation loss decreased (0.241949 --> 0.241688).  Saving model ...
	 Train_Loss: 0.2597 Train_Acc: 89.487 Val_Loss: 0.2417  BEST VAL Loss: 0.2417  Val_Acc: 90.459

Epoch 67: Validation loss decreased (0.241688 --> 0.241539).  Saving model ...
	 Train_Loss: 0.2593 Train_Acc: 89.626 Val_Loss: 0.2415  BEST VAL Loss: 0.2415  Val_Acc: 90.257

Epoch 68: Validation loss decreased (0.241539 --> 0.241381).  Saving model ...
	 Train_Loss: 0.2590 Train_Acc: 89.618 Val_Loss: 0.2414  BEST VAL Loss: 0.2414  Val_Acc: 90.290

Epoch 69: Validation loss decreased (0.241381 --> 0.241369).  Saving model ...
	 Train_Loss: 0.2587 Train_Acc: 89.452 Val_Loss: 0.2414  BEST VAL Loss: 0.2414  Val_Acc: 90.059

Epoch 70: Validation loss decreased (0.241369 --> 0.241152).  Saving model ...
	 Train_Loss: 0.2583 Train_Acc: 89.629 Val_Loss: 0.2412  BEST VAL Loss: 0.2412  Val_Acc: 90.687

Epoch 71: Validation loss decreased (0.241152 --> 0.240974).  Saving model ...
	 Train_Loss: 0.2580 Train_Acc: 89.630 Val_Loss: 0.2410  BEST VAL Loss: 0.2410  Val_Acc: 90.248

Epoch 72: Validation loss decreased (0.240974 --> 0.240701).  Saving model ...
	 Train_Loss: 0.2577 Train_Acc: 89.467 Val_Loss: 0.2407  BEST VAL Loss: 0.2407  Val_Acc: 90.636

Epoch 73: Validation loss decreased (0.240701 --> 0.240461).  Saving model ...
	 Train_Loss: 0.2574 Train_Acc: 89.552 Val_Loss: 0.2405  BEST VAL Loss: 0.2405  Val_Acc: 90.623

Epoch 74: Validation loss decreased (0.240461 --> 0.240303).  Saving model ...
	 Train_Loss: 0.2570 Train_Acc: 89.560 Val_Loss: 0.2403  BEST VAL Loss: 0.2403  Val_Acc: 90.404

Epoch 75: Validation loss decreased (0.240303 --> 0.240170).  Saving model ...
	 Train_Loss: 0.2568 Train_Acc: 89.526 Val_Loss: 0.2402  BEST VAL Loss: 0.2402  Val_Acc: 90.438

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.2565 Train_Acc: 89.310 Val_Loss: 0.2404  BEST VAL Loss: 0.2402  Val_Acc: 89.793

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.2563 Train_Acc: 89.481 Val_Loss: 0.2402  BEST VAL Loss: 0.2402  Val_Acc: 90.767

Epoch 78: Validation loss decreased (0.240170 --> 0.240119).  Saving model ...
	 Train_Loss: 0.2560 Train_Acc: 89.582 Val_Loss: 0.2401  BEST VAL Loss: 0.2401  Val_Acc: 90.775

Epoch 79: Validation loss decreased (0.240119 --> 0.239929).  Saving model ...
	 Train_Loss: 0.2557 Train_Acc: 89.543 Val_Loss: 0.2399  BEST VAL Loss: 0.2399  Val_Acc: 90.682

Epoch 80: Validation loss decreased (0.239929 --> 0.239753).  Saving model ...
	 Train_Loss: 0.2554 Train_Acc: 89.658 Val_Loss: 0.2398  BEST VAL Loss: 0.2398  Val_Acc: 90.560

Epoch 81: Validation loss decreased (0.239753 --> 0.239581).  Saving model ...
	 Train_Loss: 0.2551 Train_Acc: 89.626 Val_Loss: 0.2396  BEST VAL Loss: 0.2396  Val_Acc: 90.682

Epoch 82: Validation loss decreased (0.239581 --> 0.239330).  Saving model ...
	 Train_Loss: 0.2548 Train_Acc: 89.569 Val_Loss: 0.2393  BEST VAL Loss: 0.2393  Val_Acc: 90.813

Epoch 83: Validation loss decreased (0.239330 --> 0.239174).  Saving model ...
	 Train_Loss: 0.2546 Train_Acc: 89.715 Val_Loss: 0.2392  BEST VAL Loss: 0.2392  Val_Acc: 90.611

Epoch 84: Validation loss decreased (0.239174 --> 0.239069).  Saving model ...
	 Train_Loss: 0.2543 Train_Acc: 89.619 Val_Loss: 0.2391  BEST VAL Loss: 0.2391  Val_Acc: 90.695

Epoch 85: Validation loss decreased (0.239069 --> 0.238986).  Saving model ...
	 Train_Loss: 0.2540 Train_Acc: 89.630 Val_Loss: 0.2390  BEST VAL Loss: 0.2390  Val_Acc: 90.628

Epoch 86: Validation loss decreased (0.238986 --> 0.238806).  Saving model ...
	 Train_Loss: 0.2538 Train_Acc: 89.662 Val_Loss: 0.2388  BEST VAL Loss: 0.2388  Val_Acc: 90.556

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.2535 Train_Acc: 89.676 Val_Loss: 0.2388  BEST VAL Loss: 0.2388  Val_Acc: 90.122

Epoch 88: Validation loss decreased (0.238806 --> 0.238614).  Saving model ...
	 Train_Loss: 0.2532 Train_Acc: 89.717 Val_Loss: 0.2386  BEST VAL Loss: 0.2386  Val_Acc: 90.720

Epoch 89: Validation loss decreased (0.238614 --> 0.238476).  Saving model ...
	 Train_Loss: 0.2529 Train_Acc: 89.797 Val_Loss: 0.2385  BEST VAL Loss: 0.2385  Val_Acc: 90.682

Epoch 90: Validation loss decreased (0.238476 --> 0.238434).  Saving model ...
	 Train_Loss: 0.2527 Train_Acc: 89.702 Val_Loss: 0.2384  BEST VAL Loss: 0.2384  Val_Acc: 90.160

Epoch 91: Validation loss decreased (0.238434 --> 0.238249).  Saving model ...
	 Train_Loss: 0.2524 Train_Acc: 89.753 Val_Loss: 0.2382  BEST VAL Loss: 0.2382  Val_Acc: 90.598

Epoch 92: Validation loss decreased (0.238249 --> 0.238056).  Saving model ...
	 Train_Loss: 0.2522 Train_Acc: 89.685 Val_Loss: 0.2381  BEST VAL Loss: 0.2381  Val_Acc: 90.674

Epoch 93: Validation loss decreased (0.238056 --> 0.237918).  Saving model ...
	 Train_Loss: 0.2519 Train_Acc: 89.892 Val_Loss: 0.2379  BEST VAL Loss: 0.2379  Val_Acc: 90.594

Epoch 94: Validation loss decreased (0.237918 --> 0.237737).  Saving model ...
	 Train_Loss: 0.2517 Train_Acc: 89.765 Val_Loss: 0.2377  BEST VAL Loss: 0.2377  Val_Acc: 90.758

Epoch 95: Validation loss decreased (0.237737 --> 0.237638).  Saving model ...
	 Train_Loss: 0.2514 Train_Acc: 89.724 Val_Loss: 0.2376  BEST VAL Loss: 0.2376  Val_Acc: 90.606

Epoch 96: Validation loss decreased (0.237638 --> 0.237546).  Saving model ...
	 Train_Loss: 0.2512 Train_Acc: 89.802 Val_Loss: 0.2375  BEST VAL Loss: 0.2375  Val_Acc: 90.893

Epoch 97: Validation loss decreased (0.237546 --> 0.237392).  Saving model ...
	 Train_Loss: 0.2510 Train_Acc: 89.714 Val_Loss: 0.2374  BEST VAL Loss: 0.2374  Val_Acc: 90.788

Epoch 98: Validation loss decreased (0.237392 --> 0.237235).  Saving model ...
	 Train_Loss: 0.2507 Train_Acc: 89.669 Val_Loss: 0.2372  BEST VAL Loss: 0.2372  Val_Acc: 90.771

Epoch 99: Validation loss did not decrease
	 Train_Loss: 0.2505 Train_Acc: 89.792 Val_Loss: 0.2372  BEST VAL Loss: 0.2372  Val_Acc: 90.257

Thapsigargin_10.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.95      0.88      0.91     92173
           1       0.89      0.96      0.92     97655

    accuracy                           0.92    189828
   macro avg       0.92      0.92      0.92    189828
weighted avg       0.92      0.92      0.92    189828

Thapsigargin_10.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.94      0.86      0.90     11522
           1       0.88      0.95      0.91     12207

    accuracy                           0.91     23729
   macro avg       0.91      0.91      0.91     23729
weighted avg       0.91      0.91      0.91     23729

Thapsigargin_10.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.94      0.87      0.90     11522
           1       0.88      0.94      0.91     12207

    accuracy                           0.91     23729
   macro avg       0.91      0.91      0.91     23729
weighted avg       0.91      0.91      0.91     23729

              precision    recall  f1-score   support

           0       0.94      0.87      0.90     11522
           1       0.88      0.94      0.91     12207

    accuracy                           0.91     23729
   macro avg       0.91      0.91      0.91     23729
weighted avg       0.91      0.91      0.91     23729

Thapsigargin_10.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.90      0.69      0.78     41273
           1       0.77      0.93      0.84     44915

    accuracy                           0.81     86188
   macro avg       0.83      0.81      0.81     86188
weighted avg       0.83      0.81      0.81     86188

              precision    recall  f1-score   support

           0       0.90      0.69      0.78     41273
           1       0.77      0.93      0.84     44915

    accuracy                           0.81     86188
   macro avg       0.83      0.81      0.81     86188
weighted avg       0.83      0.81      0.81     86188

completed
