[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '0acebcb8'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '4eae91ee'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd7f3129e'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'f891862c'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 treatment_name: LPS_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
TREATMENT_NAME: LPS_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (305446, 1270)
Number of total missing values across all columns: 278866
Data Subset Is Off
Wells held out for testing: ['D08' 'K08']
Wells to use for training, validation, and testing ['D02' 'D03' 'D09' 'K02' 'K03' 'K09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.355751).  Saving model ...
	 Train_Loss: 0.4702 Train_Acc: 77.128 Val_Loss: 0.3558  BEST VAL Loss: 0.3558  Val_Acc: 84.222

Epoch 1: Validation loss decreased (0.355751 --> 0.334820).  Saving model ...
	 Train_Loss: 0.4169 Train_Acc: 83.381 Val_Loss: 0.3348  BEST VAL Loss: 0.3348  Val_Acc: 86.553

Epoch 2: Validation loss decreased (0.334820 --> 0.324370).  Saving model ...
	 Train_Loss: 0.3899 Train_Acc: 84.781 Val_Loss: 0.3244  BEST VAL Loss: 0.3244  Val_Acc: 86.948

Epoch 3: Validation loss decreased (0.324370 --> 0.321579).  Saving model ...
	 Train_Loss: 0.3718 Train_Acc: 85.754 Val_Loss: 0.3216  BEST VAL Loss: 0.3216  Val_Acc: 86.553

Epoch 4: Validation loss decreased (0.321579 --> 0.311175).  Saving model ...
	 Train_Loss: 0.3590 Train_Acc: 86.269 Val_Loss: 0.3112  BEST VAL Loss: 0.3112  Val_Acc: 88.161

Epoch 5: Validation loss decreased (0.311175 --> 0.305003).  Saving model ...
	 Train_Loss: 0.3494 Train_Acc: 86.660 Val_Loss: 0.3050  BEST VAL Loss: 0.3050  Val_Acc: 88.431

Epoch 6: Validation loss decreased (0.305003 --> 0.300480).  Saving model ...
	 Train_Loss: 0.3415 Train_Acc: 87.057 Val_Loss: 0.3005  BEST VAL Loss: 0.3005  Val_Acc: 88.778

Epoch 7: Validation loss decreased (0.300480 --> 0.296268).  Saving model ...
	 Train_Loss: 0.3351 Train_Acc: 87.155 Val_Loss: 0.2963  BEST VAL Loss: 0.2963  Val_Acc: 88.787

Epoch 8: Validation loss decreased (0.296268 --> 0.291604).  Saving model ...
	 Train_Loss: 0.3293 Train_Acc: 87.457 Val_Loss: 0.2916  BEST VAL Loss: 0.2916  Val_Acc: 89.053

Epoch 9: Validation loss decreased (0.291604 --> 0.289991).  Saving model ...
	 Train_Loss: 0.3244 Train_Acc: 87.713 Val_Loss: 0.2900  BEST VAL Loss: 0.2900  Val_Acc: 88.693

Epoch 10: Validation loss decreased (0.289991 --> 0.286779).  Saving model ...
	 Train_Loss: 0.3203 Train_Acc: 87.713 Val_Loss: 0.2868  BEST VAL Loss: 0.2868  Val_Acc: 89.173

Epoch 11: Validation loss decreased (0.286779 --> 0.284018).  Saving model ...
	 Train_Loss: 0.3165 Train_Acc: 87.819 Val_Loss: 0.2840  BEST VAL Loss: 0.2840  Val_Acc: 89.413

Epoch 12: Validation loss decreased (0.284018 --> 0.281298).  Saving model ...
	 Train_Loss: 0.3130 Train_Acc: 88.045 Val_Loss: 0.2813  BEST VAL Loss: 0.2813  Val_Acc: 89.697

Epoch 13: Validation loss decreased (0.281298 --> 0.280102).  Saving model ...
	 Train_Loss: 0.3101 Train_Acc: 87.996 Val_Loss: 0.2801  BEST VAL Loss: 0.2801  Val_Acc: 89.035

Epoch 14: Validation loss decreased (0.280102 --> 0.278625).  Saving model ...
	 Train_Loss: 0.3072 Train_Acc: 88.231 Val_Loss: 0.2786  BEST VAL Loss: 0.2786  Val_Acc: 89.204

Epoch 15: Validation loss decreased (0.278625 --> 0.276512).  Saving model ...
	 Train_Loss: 0.3048 Train_Acc: 88.287 Val_Loss: 0.2765  BEST VAL Loss: 0.2765  Val_Acc: 89.764

Epoch 16: Validation loss decreased (0.276512 --> 0.275027).  Saving model ...
	 Train_Loss: 0.3026 Train_Acc: 88.313 Val_Loss: 0.2750  BEST VAL Loss: 0.2750  Val_Acc: 89.568

Epoch 17: Validation loss decreased (0.275027 --> 0.273470).  Saving model ...
	 Train_Loss: 0.3002 Train_Acc: 88.624 Val_Loss: 0.2735  BEST VAL Loss: 0.2735  Val_Acc: 89.746

Epoch 18: Validation loss decreased (0.273470 --> 0.271924).  Saving model ...
	 Train_Loss: 0.2981 Train_Acc: 88.568 Val_Loss: 0.2719  BEST VAL Loss: 0.2719  Val_Acc: 89.910

Epoch 19: Validation loss decreased (0.271924 --> 0.270760).  Saving model ...
	 Train_Loss: 0.2961 Train_Acc: 88.586 Val_Loss: 0.2708  BEST VAL Loss: 0.2708  Val_Acc: 89.746

Epoch 20: Validation loss decreased (0.270760 --> 0.269673).  Saving model ...
	 Train_Loss: 0.2943 Train_Acc: 88.540 Val_Loss: 0.2697  BEST VAL Loss: 0.2697  Val_Acc: 89.604

Epoch 21: Validation loss decreased (0.269673 --> 0.268538).  Saving model ...
	 Train_Loss: 0.2926 Train_Acc: 88.686 Val_Loss: 0.2685  BEST VAL Loss: 0.2685  Val_Acc: 90.137

Epoch 22: Validation loss decreased (0.268538 --> 0.267285).  Saving model ...
	 Train_Loss: 0.2910 Train_Acc: 88.731 Val_Loss: 0.2673  BEST VAL Loss: 0.2673  Val_Acc: 90.128

Epoch 23: Validation loss decreased (0.267285 --> 0.266374).  Saving model ...
	 Train_Loss: 0.2894 Train_Acc: 88.907 Val_Loss: 0.2664  BEST VAL Loss: 0.2664  Val_Acc: 90.030

Epoch 24: Validation loss decreased (0.266374 --> 0.265470).  Saving model ...
	 Train_Loss: 0.2880 Train_Acc: 88.696 Val_Loss: 0.2655  BEST VAL Loss: 0.2655  Val_Acc: 89.941

Epoch 25: Validation loss decreased (0.265470 --> 0.265022).  Saving model ...
	 Train_Loss: 0.2867 Train_Acc: 88.822 Val_Loss: 0.2650  BEST VAL Loss: 0.2650  Val_Acc: 89.506

Epoch 26: Validation loss decreased (0.265022 --> 0.264254).  Saving model ...
	 Train_Loss: 0.2854 Train_Acc: 88.811 Val_Loss: 0.2643  BEST VAL Loss: 0.2643  Val_Acc: 90.030

Epoch 27: Validation loss decreased (0.264254 --> 0.264046).  Saving model ...
	 Train_Loss: 0.2842 Train_Acc: 89.057 Val_Loss: 0.2640  BEST VAL Loss: 0.2640  Val_Acc: 89.413

Epoch 28: Validation loss decreased (0.264046 --> 0.263410).  Saving model ...
	 Train_Loss: 0.2830 Train_Acc: 89.014 Val_Loss: 0.2634  BEST VAL Loss: 0.2634  Val_Acc: 90.092

Epoch 29: Validation loss decreased (0.263410 --> 0.262764).  Saving model ...
	 Train_Loss: 0.2820 Train_Acc: 88.825 Val_Loss: 0.2628  BEST VAL Loss: 0.2628  Val_Acc: 89.884

Epoch 30: Validation loss decreased (0.262764 --> 0.262142).  Saving model ...
	 Train_Loss: 0.2809 Train_Acc: 89.047 Val_Loss: 0.2621  BEST VAL Loss: 0.2621  Val_Acc: 89.972

Epoch 31: Validation loss decreased (0.262142 --> 0.261559).  Saving model ...
	 Train_Loss: 0.2799 Train_Acc: 89.008 Val_Loss: 0.2616  BEST VAL Loss: 0.2616  Val_Acc: 90.141

Epoch 32: Validation loss decreased (0.261559 --> 0.260873).  Saving model ...
	 Train_Loss: 0.2789 Train_Acc: 89.182 Val_Loss: 0.2609  BEST VAL Loss: 0.2609  Val_Acc: 90.115

Epoch 33: Validation loss decreased (0.260873 --> 0.260435).  Saving model ...
	 Train_Loss: 0.2779 Train_Acc: 89.127 Val_Loss: 0.2604  BEST VAL Loss: 0.2604  Val_Acc: 90.106

Epoch 34: Validation loss decreased (0.260435 --> 0.260106).  Saving model ...
	 Train_Loss: 0.2771 Train_Acc: 89.079 Val_Loss: 0.2601  BEST VAL Loss: 0.2601  Val_Acc: 90.083

Epoch 35: Validation loss decreased (0.260106 --> 0.259681).  Saving model ...
	 Train_Loss: 0.2763 Train_Acc: 89.093 Val_Loss: 0.2597  BEST VAL Loss: 0.2597  Val_Acc: 90.079

Epoch 36: Validation loss decreased (0.259681 --> 0.259554).  Saving model ...
	 Train_Loss: 0.2754 Train_Acc: 89.211 Val_Loss: 0.2596  BEST VAL Loss: 0.2596  Val_Acc: 89.764

Epoch 37: Validation loss decreased (0.259554 --> 0.259166).  Saving model ...
	 Train_Loss: 0.2746 Train_Acc: 89.203 Val_Loss: 0.2592  BEST VAL Loss: 0.2592  Val_Acc: 90.079

Epoch 38: Validation loss decreased (0.259166 --> 0.258702).  Saving model ...
	 Train_Loss: 0.2738 Train_Acc: 89.317 Val_Loss: 0.2587  BEST VAL Loss: 0.2587  Val_Acc: 90.310

Epoch 39: Validation loss decreased (0.258702 --> 0.258371).  Saving model ...
	 Train_Loss: 0.2731 Train_Acc: 89.266 Val_Loss: 0.2584  BEST VAL Loss: 0.2584  Val_Acc: 90.110

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.2723 Train_Acc: 89.343 Val_Loss: 0.2586  BEST VAL Loss: 0.2584  Val_Acc: 89.706

Epoch 41: Validation loss decreased (0.258371 --> 0.258027).  Saving model ...
	 Train_Loss: 0.2715 Train_Acc: 89.363 Val_Loss: 0.2580  BEST VAL Loss: 0.2580  Val_Acc: 90.421

Epoch 42: Validation loss decreased (0.258027 --> 0.257762).  Saving model ...
	 Train_Loss: 0.2708 Train_Acc: 89.402 Val_Loss: 0.2578  BEST VAL Loss: 0.2578  Val_Acc: 89.932

Epoch 43: Validation loss decreased (0.257762 --> 0.257247).  Saving model ...
	 Train_Loss: 0.2702 Train_Acc: 89.321 Val_Loss: 0.2572  BEST VAL Loss: 0.2572  Val_Acc: 90.217

Epoch 44: Validation loss decreased (0.257247 --> 0.256964).  Saving model ...
	 Train_Loss: 0.2695 Train_Acc: 89.315 Val_Loss: 0.2570  BEST VAL Loss: 0.2570  Val_Acc: 89.910

Epoch 45: Validation loss decreased (0.256964 --> 0.256562).  Saving model ...
	 Train_Loss: 0.2689 Train_Acc: 89.403 Val_Loss: 0.2566  BEST VAL Loss: 0.2566  Val_Acc: 90.243

Epoch 46: Validation loss decreased (0.256562 --> 0.256138).  Saving model ...
	 Train_Loss: 0.2682 Train_Acc: 89.429 Val_Loss: 0.2561  BEST VAL Loss: 0.2561  Val_Acc: 90.266

Epoch 47: Validation loss decreased (0.256138 --> 0.255802).  Saving model ...
	 Train_Loss: 0.2676 Train_Acc: 89.501 Val_Loss: 0.2558  BEST VAL Loss: 0.2558  Val_Acc: 90.226

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.2670 Train_Acc: 89.435 Val_Loss: 0.2558  BEST VAL Loss: 0.2558  Val_Acc: 89.813

Epoch 49: Validation loss decreased (0.255802 --> 0.255568).  Saving model ...
	 Train_Loss: 0.2664 Train_Acc: 89.450 Val_Loss: 0.2556  BEST VAL Loss: 0.2556  Val_Acc: 89.990

Epoch 50: Validation loss decreased (0.255568 --> 0.255199).  Saving model ...
	 Train_Loss: 0.2660 Train_Acc: 89.318 Val_Loss: 0.2552  BEST VAL Loss: 0.2552  Val_Acc: 90.319

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.2654 Train_Acc: 89.481 Val_Loss: 0.2553  BEST VAL Loss: 0.2552  Val_Acc: 89.577

Epoch 52: Validation loss decreased (0.255199 --> 0.255038).  Saving model ...
	 Train_Loss: 0.2649 Train_Acc: 89.468 Val_Loss: 0.2550  BEST VAL Loss: 0.2550  Val_Acc: 90.301

Epoch 53: Validation loss decreased (0.255038 --> 0.254844).  Saving model ...
	 Train_Loss: 0.2644 Train_Acc: 89.380 Val_Loss: 0.2548  BEST VAL Loss: 0.2548  Val_Acc: 90.177

Epoch 54: Validation loss decreased (0.254844 --> 0.254723).  Saving model ...
	 Train_Loss: 0.2639 Train_Acc: 89.527 Val_Loss: 0.2547  BEST VAL Loss: 0.2547  Val_Acc: 90.177

Epoch 55: Validation loss decreased (0.254723 --> 0.254544).  Saving model ...
	 Train_Loss: 0.2634 Train_Acc: 89.577 Val_Loss: 0.2545  BEST VAL Loss: 0.2545  Val_Acc: 90.132

Epoch 56: Validation loss decreased (0.254544 --> 0.254416).  Saving model ...
	 Train_Loss: 0.2630 Train_Acc: 89.503 Val_Loss: 0.2544  BEST VAL Loss: 0.2544  Val_Acc: 90.070

Epoch 57: Validation loss decreased (0.254416 --> 0.254164).  Saving model ...
	 Train_Loss: 0.2625 Train_Acc: 89.454 Val_Loss: 0.2542  BEST VAL Loss: 0.2542  Val_Acc: 90.283

Epoch 58: Validation loss decreased (0.254164 --> 0.254012).  Saving model ...
	 Train_Loss: 0.2621 Train_Acc: 89.590 Val_Loss: 0.2540  BEST VAL Loss: 0.2540  Val_Acc: 90.061

Epoch 59: Validation loss decreased (0.254012 --> 0.253782).  Saving model ...
	 Train_Loss: 0.2616 Train_Acc: 89.519 Val_Loss: 0.2538  BEST VAL Loss: 0.2538  Val_Acc: 90.168

Epoch 60: Validation loss decreased (0.253782 --> 0.253701).  Saving model ...
	 Train_Loss: 0.2612 Train_Acc: 89.612 Val_Loss: 0.2537  BEST VAL Loss: 0.2537  Val_Acc: 90.217

Epoch 61: Validation loss decreased (0.253701 --> 0.253542).  Saving model ...
	 Train_Loss: 0.2608 Train_Acc: 89.651 Val_Loss: 0.2535  BEST VAL Loss: 0.2535  Val_Acc: 90.257

Epoch 62: Validation loss decreased (0.253542 --> 0.253350).  Saving model ...
	 Train_Loss: 0.2604 Train_Acc: 89.570 Val_Loss: 0.2533  BEST VAL Loss: 0.2533  Val_Acc: 90.208

Epoch 63: Validation loss decreased (0.253350 --> 0.253349).  Saving model ...
	 Train_Loss: 0.2600 Train_Acc: 89.596 Val_Loss: 0.2533  BEST VAL Loss: 0.2533  Val_Acc: 90.314

Epoch 64: Validation loss decreased (0.253349 --> 0.253217).  Saving model ...
	 Train_Loss: 0.2596 Train_Acc: 89.681 Val_Loss: 0.2532  BEST VAL Loss: 0.2532  Val_Acc: 90.341

Epoch 65: Validation loss decreased (0.253217 --> 0.252995).  Saving model ...
	 Train_Loss: 0.2592 Train_Acc: 89.634 Val_Loss: 0.2530  BEST VAL Loss: 0.2530  Val_Acc: 90.381

Epoch 66: Validation loss decreased (0.252995 --> 0.252930).  Saving model ...
	 Train_Loss: 0.2588 Train_Acc: 89.732 Val_Loss: 0.2529  BEST VAL Loss: 0.2529  Val_Acc: 90.070

Epoch 67: Validation loss decreased (0.252930 --> 0.252784).  Saving model ...
	 Train_Loss: 0.2584 Train_Acc: 89.639 Val_Loss: 0.2528  BEST VAL Loss: 0.2528  Val_Acc: 90.155

Epoch 68: Validation loss decreased (0.252784 --> 0.252545).  Saving model ...
	 Train_Loss: 0.2580 Train_Acc: 89.655 Val_Loss: 0.2525  BEST VAL Loss: 0.2525  Val_Acc: 90.545

Epoch 69: Validation loss decreased (0.252545 --> 0.252427).  Saving model ...
	 Train_Loss: 0.2577 Train_Acc: 89.706 Val_Loss: 0.2524  BEST VAL Loss: 0.2524  Val_Acc: 90.248

Epoch 70: Validation loss decreased (0.252427 --> 0.252281).  Saving model ...
	 Train_Loss: 0.2573 Train_Acc: 89.793 Val_Loss: 0.2523  BEST VAL Loss: 0.2523  Val_Acc: 90.004

Epoch 71: Validation loss decreased (0.252281 --> 0.252215).  Saving model ...
	 Train_Loss: 0.2569 Train_Acc: 89.777 Val_Loss: 0.2522  BEST VAL Loss: 0.2522  Val_Acc: 90.190

Epoch 72: Validation loss decreased (0.252215 --> 0.252046).  Saving model ...
	 Train_Loss: 0.2566 Train_Acc: 89.672 Val_Loss: 0.2520  BEST VAL Loss: 0.2520  Val_Acc: 90.377

Epoch 73: Validation loss decreased (0.252046 --> 0.251931).  Saving model ...
	 Train_Loss: 0.2562 Train_Acc: 89.713 Val_Loss: 0.2519  BEST VAL Loss: 0.2519  Val_Acc: 90.119

Epoch 74: Validation loss decreased (0.251931 --> 0.251793).  Saving model ...
	 Train_Loss: 0.2560 Train_Acc: 89.615 Val_Loss: 0.2518  BEST VAL Loss: 0.2518  Val_Acc: 90.283

Epoch 75: Validation loss decreased (0.251793 --> 0.251686).  Saving model ...
	 Train_Loss: 0.2556 Train_Acc: 89.719 Val_Loss: 0.2517  BEST VAL Loss: 0.2517  Val_Acc: 90.243

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.2553 Train_Acc: 89.744 Val_Loss: 0.2518  BEST VAL Loss: 0.2517  Val_Acc: 89.910

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.2550 Train_Acc: 89.799 Val_Loss: 0.2518  BEST VAL Loss: 0.2517  Val_Acc: 89.839

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.2546 Train_Acc: 89.852 Val_Loss: 0.2517  BEST VAL Loss: 0.2517  Val_Acc: 90.212

Epoch 79: Validation loss decreased (0.251686 --> 0.251514).  Saving model ...
	 Train_Loss: 0.2544 Train_Acc: 89.715 Val_Loss: 0.2515  BEST VAL Loss: 0.2515  Val_Acc: 90.616

Epoch 80: Validation loss decreased (0.251514 --> 0.251415).  Saving model ...
	 Train_Loss: 0.2541 Train_Acc: 89.805 Val_Loss: 0.2514  BEST VAL Loss: 0.2514  Val_Acc: 90.501

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.2538 Train_Acc: 89.783 Val_Loss: 0.2514  BEST VAL Loss: 0.2514  Val_Acc: 90.172

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.2535 Train_Acc: 89.890 Val_Loss: 0.2517  BEST VAL Loss: 0.2514  Val_Acc: 89.999

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.2532 Train_Acc: 89.822 Val_Loss: 0.2516  BEST VAL Loss: 0.2514  Val_Acc: 90.559

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.2529 Train_Acc: 89.808 Val_Loss: 0.2515  BEST VAL Loss: 0.2514  Val_Acc: 90.439

Epoch 85: Validation loss decreased (0.251415 --> 0.251385).  Saving model ...
	 Train_Loss: 0.2526 Train_Acc: 89.870 Val_Loss: 0.2514  BEST VAL Loss: 0.2514  Val_Acc: 90.266

Epoch 86: Validation loss decreased (0.251385 --> 0.251352).  Saving model ...
	 Train_Loss: 0.2524 Train_Acc: 89.785 Val_Loss: 0.2514  BEST VAL Loss: 0.2514  Val_Acc: 90.248

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.2521 Train_Acc: 89.741 Val_Loss: 0.2514  BEST VAL Loss: 0.2514  Val_Acc: 90.110

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.2519 Train_Acc: 89.774 Val_Loss: 0.2514  BEST VAL Loss: 0.2514  Val_Acc: 90.341

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.2516 Train_Acc: 89.866 Val_Loss: 0.2516  BEST VAL Loss: 0.2514  Val_Acc: 90.004

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.2513 Train_Acc: 89.822 Val_Loss: 0.2517  BEST VAL Loss: 0.2514  Val_Acc: 89.764

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.2511 Train_Acc: 89.891 Val_Loss: 0.2516  BEST VAL Loss: 0.2514  Val_Acc: 90.092

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.2508 Train_Acc: 89.858 Val_Loss: 0.2515  BEST VAL Loss: 0.2514  Val_Acc: 90.150

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.2506 Train_Acc: 89.919 Val_Loss: 0.2514  BEST VAL Loss: 0.2514  Val_Acc: 90.212

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.2503 Train_Acc: 90.060 Val_Loss: 0.2514  BEST VAL Loss: 0.2514  Val_Acc: 90.319

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.2501 Train_Acc: 89.948 Val_Loss: 0.2514  BEST VAL Loss: 0.2514  Val_Acc: 90.363

Epoch 96: Validation loss did not decrease
	 Train_Loss: 0.2498 Train_Acc: 89.900 Val_Loss: 0.2515  BEST VAL Loss: 0.2514  Val_Acc: 89.821

Epoch 97: Validation loss did not decrease
	 Train_Loss: 0.2496 Train_Acc: 89.709 Val_Loss: 0.2516  BEST VAL Loss: 0.2514  Val_Acc: 90.146

Epoch 98: Validation loss did not decrease
	 Train_Loss: 0.2494 Train_Acc: 89.933 Val_Loss: 0.2516  BEST VAL Loss: 0.2514  Val_Acc: 90.390

Epoch 99: Validation loss did not decrease
	 Train_Loss: 0.2491 Train_Acc: 89.997 Val_Loss: 0.2515  BEST VAL Loss: 0.2514  Val_Acc: 90.132

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.44      0.43      0.44     79796
           1       0.56      0.57      0.56    100340

    accuracy                           0.51    180136
   macro avg       0.50      0.50      0.50    180136
weighted avg       0.51      0.51      0.51    180136

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.44      0.43      0.44      9975
           1       0.56      0.56      0.56     12543

    accuracy                           0.51     22518
   macro avg       0.50      0.50      0.50     22518
weighted avg       0.51      0.51      0.51     22518

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.44      0.43      0.44      9975
           1       0.55      0.56      0.56     12542

    accuracy                           0.50     22517
   macro avg       0.50      0.50      0.50     22517
weighted avg       0.50      0.50      0.50     22517

              precision    recall  f1-score   support

           0       0.44      0.43      0.44      9975
           1       0.55      0.56      0.56     12542

    accuracy                           0.50     22517
   macro avg       0.50      0.50      0.50     22517
weighted avg       0.50      0.50      0.50     22517

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.55      0.52     39687
           1       0.50      0.45      0.47     40588

    accuracy                           0.50     80275
   macro avg       0.50      0.50      0.50     80275
weighted avg       0.50      0.50      0.50     80275

              precision    recall  f1-score   support

           0       0.49      0.55      0.52     39687
           1       0.50      0.45      0.47     40588

    accuracy                           0.50     80275
   macro avg       0.50      0.50      0.50     80275
weighted avg       0.50      0.50      0.50     80275

completed
