[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'f8231018'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'c738e9e1'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'dfcb3627'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '17e9de3a'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_0.100_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_0.100_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (31162, 1276)
Number of total missing values across all columns: 35020
Data Subset Is Off
Wells held out for testing: ['C20' 'L16']
Wells to use for training, validation, and testing ['C16' 'C17' 'C21' 'L17' 'L20' 'L21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.175055).  Saving model ...
	 Train_Loss: 0.3834 Train_Acc: 85.269 Val_Loss: 0.1751  BEST VAL Loss: 0.1751  Val_Acc: 94.258

Epoch 1: Validation loss decreased (0.175055 --> 0.158024).  Saving model ...
	 Train_Loss: 0.2895 Train_Acc: 92.224 Val_Loss: 0.1580  BEST VAL Loss: 0.1580  Val_Acc: 95.085

Epoch 2: Validation loss decreased (0.158024 --> 0.142226).  Saving model ...
	 Train_Loss: 0.2420 Train_Acc: 94.116 Val_Loss: 0.1422  BEST VAL Loss: 0.1422  Val_Acc: 96.129

Epoch 3: Validation loss decreased (0.142226 --> 0.133653).  Saving model ...
	 Train_Loss: 0.2130 Train_Acc: 94.943 Val_Loss: 0.1337  BEST VAL Loss: 0.1337  Val_Acc: 95.824

Epoch 4: Validation loss decreased (0.133653 --> 0.125681).  Saving model ...
	 Train_Loss: 0.1920 Train_Acc: 95.563 Val_Loss: 0.1257  BEST VAL Loss: 0.1257  Val_Acc: 96.694

Epoch 5: Validation loss decreased (0.125681 --> 0.119701).  Saving model ...
	 Train_Loss: 0.1764 Train_Acc: 96.090 Val_Loss: 0.1197  BEST VAL Loss: 0.1197  Val_Acc: 96.477

Epoch 6: Validation loss decreased (0.119701 --> 0.114370).  Saving model ...
	 Train_Loss: 0.1640 Train_Acc: 96.444 Val_Loss: 0.1144  BEST VAL Loss: 0.1144  Val_Acc: 96.738

Epoch 7: Validation loss decreased (0.114370 --> 0.110838).  Saving model ...
	 Train_Loss: 0.1540 Train_Acc: 96.498 Val_Loss: 0.1108  BEST VAL Loss: 0.1108  Val_Acc: 96.259

Epoch 8: Validation loss decreased (0.110838 --> 0.107745).  Saving model ...
	 Train_Loss: 0.1456 Train_Acc: 96.726 Val_Loss: 0.1077  BEST VAL Loss: 0.1077  Val_Acc: 96.955

Epoch 9: Validation loss decreased (0.107745 --> 0.105327).  Saving model ...
	 Train_Loss: 0.1386 Train_Acc: 96.699 Val_Loss: 0.1053  BEST VAL Loss: 0.1053  Val_Acc: 96.955

Epoch 10: Validation loss decreased (0.105327 --> 0.103442).  Saving model ...
	 Train_Loss: 0.1327 Train_Acc: 96.748 Val_Loss: 0.1034  BEST VAL Loss: 0.1034  Val_Acc: 97.260

Epoch 11: Validation loss decreased (0.103442 --> 0.101760).  Saving model ...
	 Train_Loss: 0.1277 Train_Acc: 96.841 Val_Loss: 0.1018  BEST VAL Loss: 0.1018  Val_Acc: 97.129

Epoch 12: Validation loss decreased (0.101760 --> 0.100969).  Saving model ...
	 Train_Loss: 0.1233 Train_Acc: 96.884 Val_Loss: 0.1010  BEST VAL Loss: 0.1010  Val_Acc: 96.651

Epoch 13: Validation loss decreased (0.100969 --> 0.100234).  Saving model ...
	 Train_Loss: 0.1196 Train_Acc: 96.982 Val_Loss: 0.1002  BEST VAL Loss: 0.1002  Val_Acc: 97.042

Epoch 14: Validation loss decreased (0.100234 --> 0.098707).  Saving model ...
	 Train_Loss: 0.1164 Train_Acc: 97.004 Val_Loss: 0.0987  BEST VAL Loss: 0.0987  Val_Acc: 96.781

Epoch 15: Validation loss decreased (0.098707 --> 0.098212).  Saving model ...
	 Train_Loss: 0.1134 Train_Acc: 97.080 Val_Loss: 0.0982  BEST VAL Loss: 0.0982  Val_Acc: 97.347

Epoch 16: Validation loss decreased (0.098212 --> 0.098073).  Saving model ...
	 Train_Loss: 0.1104 Train_Acc: 97.113 Val_Loss: 0.0981  BEST VAL Loss: 0.0981  Val_Acc: 97.564

Epoch 17: Validation loss decreased (0.098073 --> 0.097490).  Saving model ...
	 Train_Loss: 0.1077 Train_Acc: 97.194 Val_Loss: 0.0975  BEST VAL Loss: 0.0975  Val_Acc: 97.347

Epoch 18: Validation loss decreased (0.097490 --> 0.097122).  Saving model ...
	 Train_Loss: 0.1053 Train_Acc: 97.254 Val_Loss: 0.0971  BEST VAL Loss: 0.0971  Val_Acc: 97.347

Epoch 19: Validation loss decreased (0.097122 --> 0.096965).  Saving model ...
	 Train_Loss: 0.1029 Train_Acc: 97.308 Val_Loss: 0.0970  BEST VAL Loss: 0.0970  Val_Acc: 97.216

Epoch 20: Validation loss decreased (0.096965 --> 0.096668).  Saving model ...
	 Train_Loss: 0.1008 Train_Acc: 97.292 Val_Loss: 0.0967  BEST VAL Loss: 0.0967  Val_Acc: 97.477

Epoch 21: Validation loss decreased (0.096668 --> 0.096652).  Saving model ...
	 Train_Loss: 0.0989 Train_Acc: 97.167 Val_Loss: 0.0967  BEST VAL Loss: 0.0967  Val_Acc: 97.216

Epoch 22: Validation loss decreased (0.096652 --> 0.096233).  Saving model ...
	 Train_Loss: 0.0971 Train_Acc: 97.221 Val_Loss: 0.0962  BEST VAL Loss: 0.0962  Val_Acc: 97.216

Epoch 23: Validation loss decreased (0.096233 --> 0.096225).  Saving model ...
	 Train_Loss: 0.0954 Train_Acc: 97.249 Val_Loss: 0.0962  BEST VAL Loss: 0.0962  Val_Acc: 97.260

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.0939 Train_Acc: 97.210 Val_Loss: 0.0969  BEST VAL Loss: 0.0962  Val_Acc: 97.347

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.0924 Train_Acc: 97.428 Val_Loss: 0.0971  BEST VAL Loss: 0.0962  Val_Acc: 97.260

Epoch 26: Validation loss did not decrease
	 Train_Loss: 0.0911 Train_Acc: 97.401 Val_Loss: 0.0966  BEST VAL Loss: 0.0962  Val_Acc: 97.608

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.0897 Train_Acc: 97.292 Val_Loss: 0.0969  BEST VAL Loss: 0.0962  Val_Acc: 97.129

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.0883 Train_Acc: 97.689 Val_Loss: 0.0971  BEST VAL Loss: 0.0962  Val_Acc: 97.042

Epoch 29: Validation loss did not decrease
	 Train_Loss: 0.0870 Train_Acc: 97.542 Val_Loss: 0.0973  BEST VAL Loss: 0.0962  Val_Acc: 96.781

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.0859 Train_Acc: 97.406 Val_Loss: 0.0980  BEST VAL Loss: 0.0962  Val_Acc: 97.129

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.0848 Train_Acc: 97.477 Val_Loss: 0.0981  BEST VAL Loss: 0.0962  Val_Acc: 96.825

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.0837 Train_Acc: 97.656 Val_Loss: 0.0982  BEST VAL Loss: 0.0962  Val_Acc: 97.129

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.0829 Train_Acc: 97.162 Val_Loss: 0.0977  BEST VAL Loss: 0.0962  Val_Acc: 97.303

Epoch 34: Validation loss did not decrease
	 Train_Loss: 0.0820 Train_Acc: 97.450 Val_Loss: 0.0974  BEST VAL Loss: 0.0962  Val_Acc: 97.173

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.0810 Train_Acc: 97.591 Val_Loss: 0.0977  BEST VAL Loss: 0.0962  Val_Acc: 97.129

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.0801 Train_Acc: 97.504 Val_Loss: 0.0973  BEST VAL Loss: 0.0962  Val_Acc: 97.216

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.0793 Train_Acc: 97.558 Val_Loss: 0.0966  BEST VAL Loss: 0.0962  Val_Acc: 97.521

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.0784 Train_Acc: 97.689 Val_Loss: 0.0966  BEST VAL Loss: 0.0962  Val_Acc: 97.738

Epoch 39: Validation loss did not decrease
Early stopped at epoch : 39
LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      1.00      0.99     10451
           1       1.00      0.99      0.99      7939

    accuracy                           0.99     18390
   macro avg       0.99      0.99      0.99     18390
weighted avg       0.99      0.99      0.99     18390

LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.97      0.98      1307
           1       0.96      0.97      0.97       992

    accuracy                           0.97      2299
   macro avg       0.97      0.97      0.97      2299
weighted avg       0.97      0.97      0.97      2299

LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.98      0.97      1307
           1       0.97      0.97      0.97       992

    accuracy                           0.97      2299
   macro avg       0.97      0.97      0.97      2299
weighted avg       0.97      0.97      0.97      2299

              precision    recall  f1-score   support

           0       0.97      0.98      0.97      1307
           1       0.97      0.97      0.97       992

    accuracy                           0.97      2299
   macro avg       0.97      0.97      0.97      2299
weighted avg       0.97      0.97      0.97      2299

LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.94      0.98      0.96      4445
           1       0.98      0.93      0.95      3729

    accuracy                           0.96      8174
   macro avg       0.96      0.95      0.96      8174
weighted avg       0.96      0.96      0.96      8174

              precision    recall  f1-score   support

           0       0.94      0.98      0.96      4445
           1       0.98      0.93      0.95      3729

    accuracy                           0.96      8174
   macro avg       0.96      0.95      0.96      8174
weighted avg       0.96      0.96      0.96      8174

completed
