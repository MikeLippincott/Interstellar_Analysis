[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '28667f7c'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'acb5a771'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b42bbcfe'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '4f913c4d'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_10.000_DMSO_0.025 treatment_name: Thapsigargin_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: Thapsigargin_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'Thapsigargin_1.000_DMSO_0.025']
The dimensions of the data are: (304946, 1270)
Number of total missing values across all columns: 609892
Data Subset Is Off
Wells held out for testing: ['E09' 'K06']
Wells to use for training, validation, and testing ['E02' 'E03' 'D06' 'D07' 'E08' 'K07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.563585).  Saving model ...
	 Train_Loss: 0.6196 Train_Acc: 65.424 Val_Loss: 0.5636  BEST VAL Loss: 0.5636  Val_Acc: 71.937

Epoch 1: Validation loss decreased (0.563585 --> 0.540591).  Saving model ...
	 Train_Loss: 0.5854 Train_Acc: 71.844 Val_Loss: 0.5406  BEST VAL Loss: 0.5406  Val_Acc: 74.435

Epoch 2: Validation loss decreased (0.540591 --> 0.525107).  Saving model ...
	 Train_Loss: 0.5640 Train_Acc: 73.774 Val_Loss: 0.5251  BEST VAL Loss: 0.5251  Val_Acc: 75.607

Epoch 3: Validation loss decreased (0.525107 --> 0.513791).  Saving model ...
	 Train_Loss: 0.5490 Train_Acc: 74.877 Val_Loss: 0.5138  BEST VAL Loss: 0.5138  Val_Acc: 76.472

Epoch 4: Validation loss decreased (0.513791 --> 0.505144).  Saving model ...
	 Train_Loss: 0.5378 Train_Acc: 75.570 Val_Loss: 0.5051  BEST VAL Loss: 0.5051  Val_Acc: 76.916

Epoch 5: Validation loss decreased (0.505144 --> 0.498117).  Saving model ...
	 Train_Loss: 0.5288 Train_Acc: 76.102 Val_Loss: 0.4981  BEST VAL Loss: 0.4981  Val_Acc: 77.284

Epoch 6: Validation loss decreased (0.498117 --> 0.492097).  Saving model ...
	 Train_Loss: 0.5214 Train_Acc: 76.517 Val_Loss: 0.4921  BEST VAL Loss: 0.4921  Val_Acc: 77.746

Epoch 7: Validation loss decreased (0.492097 --> 0.486954).  Saving model ...
	 Train_Loss: 0.5151 Train_Acc: 76.906 Val_Loss: 0.4870  BEST VAL Loss: 0.4870  Val_Acc: 77.981

Epoch 8: Validation loss decreased (0.486954 --> 0.482351).  Saving model ...
	 Train_Loss: 0.5095 Train_Acc: 77.217 Val_Loss: 0.4824  BEST VAL Loss: 0.4824  Val_Acc: 78.323

Epoch 9: Validation loss decreased (0.482351 --> 0.478332).  Saving model ...
	 Train_Loss: 0.5045 Train_Acc: 77.522 Val_Loss: 0.4783  BEST VAL Loss: 0.4783  Val_Acc: 78.398

Epoch 10: Validation loss decreased (0.478332 --> 0.474638).  Saving model ...
	 Train_Loss: 0.5000 Train_Acc: 77.824 Val_Loss: 0.4746  BEST VAL Loss: 0.4746  Val_Acc: 78.615

Epoch 11: Validation loss decreased (0.474638 --> 0.471236).  Saving model ...
	 Train_Loss: 0.4959 Train_Acc: 77.977 Val_Loss: 0.4712  BEST VAL Loss: 0.4712  Val_Acc: 79.175

Epoch 12: Validation loss decreased (0.471236 --> 0.468080).  Saving model ...
	 Train_Loss: 0.4921 Train_Acc: 78.298 Val_Loss: 0.4681  BEST VAL Loss: 0.4681  Val_Acc: 79.334

Epoch 13: Validation loss decreased (0.468080 --> 0.465111).  Saving model ...
	 Train_Loss: 0.4886 Train_Acc: 78.548 Val_Loss: 0.4651  BEST VAL Loss: 0.4651  Val_Acc: 79.592

Epoch 14: Validation loss decreased (0.465111 --> 0.462370).  Saving model ...
	 Train_Loss: 0.4853 Train_Acc: 78.643 Val_Loss: 0.4624  BEST VAL Loss: 0.4624  Val_Acc: 79.769

Epoch 15: Validation loss decreased (0.462370 --> 0.459754).  Saving model ...
	 Train_Loss: 0.4822 Train_Acc: 78.987 Val_Loss: 0.4598  BEST VAL Loss: 0.4598  Val_Acc: 80.040

Epoch 16: Validation loss decreased (0.459754 --> 0.457300).  Saving model ...
	 Train_Loss: 0.4793 Train_Acc: 79.203 Val_Loss: 0.4573  BEST VAL Loss: 0.4573  Val_Acc: 80.138

Epoch 17: Validation loss decreased (0.457300 --> 0.454936).  Saving model ...
	 Train_Loss: 0.4765 Train_Acc: 79.327 Val_Loss: 0.4549  BEST VAL Loss: 0.4549  Val_Acc: 80.288

Epoch 18: Validation loss decreased (0.454936 --> 0.452694).  Saving model ...
	 Train_Loss: 0.4739 Train_Acc: 79.463 Val_Loss: 0.4527  BEST VAL Loss: 0.4527  Val_Acc: 80.444

Epoch 19: Validation loss decreased (0.452694 --> 0.450531).  Saving model ...
	 Train_Loss: 0.4714 Train_Acc: 79.653 Val_Loss: 0.4505  BEST VAL Loss: 0.4505  Val_Acc: 80.697

Epoch 20: Validation loss decreased (0.450531 --> 0.448489).  Saving model ...
	 Train_Loss: 0.4690 Train_Acc: 79.873 Val_Loss: 0.4485  BEST VAL Loss: 0.4485  Val_Acc: 80.728

Epoch 21: Validation loss decreased (0.448489 --> 0.446521).  Saving model ...
	 Train_Loss: 0.4668 Train_Acc: 80.050 Val_Loss: 0.4465  BEST VAL Loss: 0.4465  Val_Acc: 80.888

Epoch 22: Validation loss decreased (0.446521 --> 0.444633).  Saving model ...
	 Train_Loss: 0.4645 Train_Acc: 80.187 Val_Loss: 0.4446  BEST VAL Loss: 0.4446  Val_Acc: 81.047

Epoch 23: Validation loss decreased (0.444633 --> 0.442829).  Saving model ...
	 Train_Loss: 0.4625 Train_Acc: 80.272 Val_Loss: 0.4428  BEST VAL Loss: 0.4428  Val_Acc: 81.069

Epoch 24: Validation loss decreased (0.442829 --> 0.441074).  Saving model ...
	 Train_Loss: 0.4604 Train_Acc: 80.443 Val_Loss: 0.4411  BEST VAL Loss: 0.4411  Val_Acc: 81.211

Epoch 25: Validation loss decreased (0.441074 --> 0.439414).  Saving model ...
	 Train_Loss: 0.4585 Train_Acc: 80.567 Val_Loss: 0.4394  BEST VAL Loss: 0.4394  Val_Acc: 81.291

Epoch 26: Validation loss decreased (0.439414 --> 0.437815).  Saving model ...
	 Train_Loss: 0.4566 Train_Acc: 80.749 Val_Loss: 0.4378  BEST VAL Loss: 0.4378  Val_Acc: 81.469

Epoch 27: Validation loss decreased (0.437815 --> 0.436270).  Saving model ...
	 Train_Loss: 0.4548 Train_Acc: 80.828 Val_Loss: 0.4363  BEST VAL Loss: 0.4363  Val_Acc: 81.513

Epoch 28: Validation loss decreased (0.436270 --> 0.434749).  Saving model ...
	 Train_Loss: 0.4531 Train_Acc: 80.859 Val_Loss: 0.4347  BEST VAL Loss: 0.4347  Val_Acc: 81.682

Epoch 29: Validation loss decreased (0.434749 --> 0.433279).  Saving model ...
	 Train_Loss: 0.4514 Train_Acc: 80.992 Val_Loss: 0.4333  BEST VAL Loss: 0.4333  Val_Acc: 81.775

Epoch 30: Validation loss decreased (0.433279 --> 0.431875).  Saving model ...
	 Train_Loss: 0.4497 Train_Acc: 81.048 Val_Loss: 0.4319  BEST VAL Loss: 0.4319  Val_Acc: 81.793

Epoch 31: Validation loss decreased (0.431875 --> 0.430533).  Saving model ...
	 Train_Loss: 0.4481 Train_Acc: 81.165 Val_Loss: 0.4305  BEST VAL Loss: 0.4305  Val_Acc: 82.050

Epoch 32: Validation loss decreased (0.430533 --> 0.429197).  Saving model ...
	 Train_Loss: 0.4466 Train_Acc: 81.349 Val_Loss: 0.4292  BEST VAL Loss: 0.4292  Val_Acc: 82.134

Epoch 33: Validation loss decreased (0.429197 --> 0.427900).  Saving model ...
	 Train_Loss: 0.4451 Train_Acc: 81.385 Val_Loss: 0.4279  BEST VAL Loss: 0.4279  Val_Acc: 82.179

Epoch 34: Validation loss decreased (0.427900 --> 0.426631).  Saving model ...
	 Train_Loss: 0.4437 Train_Acc: 81.389 Val_Loss: 0.4266  BEST VAL Loss: 0.4266  Val_Acc: 82.276

Epoch 35: Validation loss decreased (0.426631 --> 0.425400).  Saving model ...
	 Train_Loss: 0.4422 Train_Acc: 81.597 Val_Loss: 0.4254  BEST VAL Loss: 0.4254  Val_Acc: 82.312

Epoch 36: Validation loss decreased (0.425400 --> 0.424207).  Saving model ...
	 Train_Loss: 0.4409 Train_Acc: 81.580 Val_Loss: 0.4242  BEST VAL Loss: 0.4242  Val_Acc: 82.387

Epoch 37: Validation loss decreased (0.424207 --> 0.423043).  Saving model ...
	 Train_Loss: 0.4396 Train_Acc: 81.810 Val_Loss: 0.4230  BEST VAL Loss: 0.4230  Val_Acc: 82.498

Epoch 38: Validation loss decreased (0.423043 --> 0.421904).  Saving model ...
	 Train_Loss: 0.4383 Train_Acc: 81.730 Val_Loss: 0.4219  BEST VAL Loss: 0.4219  Val_Acc: 82.565

Epoch 39: Validation loss decreased (0.421904 --> 0.420806).  Saving model ...
	 Train_Loss: 0.4370 Train_Acc: 81.878 Val_Loss: 0.4208  BEST VAL Loss: 0.4208  Val_Acc: 82.667

Epoch 40: Validation loss decreased (0.420806 --> 0.419713).  Saving model ...
	 Train_Loss: 0.4358 Train_Acc: 81.880 Val_Loss: 0.4197  BEST VAL Loss: 0.4197  Val_Acc: 82.698

Epoch 41: Validation loss decreased (0.419713 --> 0.418656).  Saving model ...
	 Train_Loss: 0.4346 Train_Acc: 81.941 Val_Loss: 0.4187  BEST VAL Loss: 0.4187  Val_Acc: 82.849

Epoch 42: Validation loss decreased (0.418656 --> 0.417627).  Saving model ...
	 Train_Loss: 0.4334 Train_Acc: 82.064 Val_Loss: 0.4176  BEST VAL Loss: 0.4176  Val_Acc: 82.876

Epoch 43: Validation loss decreased (0.417627 --> 0.416603).  Saving model ...
	 Train_Loss: 0.4322 Train_Acc: 82.217 Val_Loss: 0.4166  BEST VAL Loss: 0.4166  Val_Acc: 82.955

Epoch 44: Validation loss decreased (0.416603 --> 0.415605).  Saving model ...
	 Train_Loss: 0.4311 Train_Acc: 82.160 Val_Loss: 0.4156  BEST VAL Loss: 0.4156  Val_Acc: 82.991

Epoch 45: Validation loss decreased (0.415605 --> 0.414638).  Saving model ...
	 Train_Loss: 0.4300 Train_Acc: 82.250 Val_Loss: 0.4146  BEST VAL Loss: 0.4146  Val_Acc: 83.084

Epoch 46: Validation loss decreased (0.414638 --> 0.413671).  Saving model ...
	 Train_Loss: 0.4289 Train_Acc: 82.360 Val_Loss: 0.4137  BEST VAL Loss: 0.4137  Val_Acc: 83.080

Epoch 47: Validation loss decreased (0.413671 --> 0.412730).  Saving model ...
	 Train_Loss: 0.4278 Train_Acc: 82.423 Val_Loss: 0.4127  BEST VAL Loss: 0.4127  Val_Acc: 83.253

Epoch 48: Validation loss decreased (0.412730 --> 0.411820).  Saving model ...
	 Train_Loss: 0.4268 Train_Acc: 82.478 Val_Loss: 0.4118  BEST VAL Loss: 0.4118  Val_Acc: 83.253

Epoch 49: Validation loss decreased (0.411820 --> 0.410927).  Saving model ...
	 Train_Loss: 0.4258 Train_Acc: 82.496 Val_Loss: 0.4109  BEST VAL Loss: 0.4109  Val_Acc: 83.355

Epoch 50: Validation loss decreased (0.410927 --> 0.410038).  Saving model ...
	 Train_Loss: 0.4248 Train_Acc: 82.668 Val_Loss: 0.4100  BEST VAL Loss: 0.4100  Val_Acc: 83.426

Epoch 51: Validation loss decreased (0.410038 --> 0.409174).  Saving model ...
	 Train_Loss: 0.4238 Train_Acc: 82.750 Val_Loss: 0.4092  BEST VAL Loss: 0.4092  Val_Acc: 83.461

Epoch 52: Validation loss decreased (0.409174 --> 0.408313).  Saving model ...
	 Train_Loss: 0.4228 Train_Acc: 82.740 Val_Loss: 0.4083  BEST VAL Loss: 0.4083  Val_Acc: 83.346

Epoch 53: Validation loss decreased (0.408313 --> 0.407478).  Saving model ...
	 Train_Loss: 0.4219 Train_Acc: 82.772 Val_Loss: 0.4075  BEST VAL Loss: 0.4075  Val_Acc: 83.448

Epoch 54: Validation loss decreased (0.407478 --> 0.406661).  Saving model ...
	 Train_Loss: 0.4210 Train_Acc: 82.725 Val_Loss: 0.4067  BEST VAL Loss: 0.4067  Val_Acc: 83.519

Epoch 55: Validation loss decreased (0.406661 --> 0.405861).  Saving model ...
	 Train_Loss: 0.4201 Train_Acc: 82.819 Val_Loss: 0.4059  BEST VAL Loss: 0.4059  Val_Acc: 83.599

Epoch 56: Validation loss decreased (0.405861 --> 0.405077).  Saving model ...
	 Train_Loss: 0.4192 Train_Acc: 83.006 Val_Loss: 0.4051  BEST VAL Loss: 0.4051  Val_Acc: 83.665

Epoch 57: Validation loss decreased (0.405077 --> 0.404297).  Saving model ...
	 Train_Loss: 0.4183 Train_Acc: 82.983 Val_Loss: 0.4043  BEST VAL Loss: 0.4043  Val_Acc: 83.754

Epoch 58: Validation loss decreased (0.404297 --> 0.403532).  Saving model ...
	 Train_Loss: 0.4175 Train_Acc: 83.061 Val_Loss: 0.4035  BEST VAL Loss: 0.4035  Val_Acc: 83.648

Epoch 59: Validation loss decreased (0.403532 --> 0.402776).  Saving model ...
	 Train_Loss: 0.4166 Train_Acc: 83.007 Val_Loss: 0.4028  BEST VAL Loss: 0.4028  Val_Acc: 83.745

Epoch 60: Validation loss decreased (0.402776 --> 0.402027).  Saving model ...
	 Train_Loss: 0.4158 Train_Acc: 83.105 Val_Loss: 0.4020  BEST VAL Loss: 0.4020  Val_Acc: 83.909

Epoch 61: Validation loss decreased (0.402027 --> 0.401316).  Saving model ...
	 Train_Loss: 0.4150 Train_Acc: 83.183 Val_Loss: 0.4013  BEST VAL Loss: 0.4013  Val_Acc: 83.896

Epoch 62: Validation loss decreased (0.401316 --> 0.400602).  Saving model ...
	 Train_Loss: 0.4142 Train_Acc: 83.217 Val_Loss: 0.4006  BEST VAL Loss: 0.4006  Val_Acc: 83.980

Epoch 63: Validation loss decreased (0.400602 --> 0.399897).  Saving model ...
	 Train_Loss: 0.4134 Train_Acc: 83.293 Val_Loss: 0.3999  BEST VAL Loss: 0.3999  Val_Acc: 84.074

Epoch 64: Validation loss decreased (0.399897 --> 0.399197).  Saving model ...
	 Train_Loss: 0.4126 Train_Acc: 83.306 Val_Loss: 0.3992  BEST VAL Loss: 0.3992  Val_Acc: 84.096

Epoch 65: Validation loss decreased (0.399197 --> 0.398527).  Saving model ...
	 Train_Loss: 0.4118 Train_Acc: 83.412 Val_Loss: 0.3985  BEST VAL Loss: 0.3985  Val_Acc: 84.020

Epoch 66: Validation loss decreased (0.398527 --> 0.397872).  Saving model ...
	 Train_Loss: 0.4110 Train_Acc: 83.492 Val_Loss: 0.3979  BEST VAL Loss: 0.3979  Val_Acc: 84.114

Epoch 67: Validation loss decreased (0.397872 --> 0.397211).  Saving model ...
	 Train_Loss: 0.4103 Train_Acc: 83.422 Val_Loss: 0.3972  BEST VAL Loss: 0.3972  Val_Acc: 84.402

Epoch 68: Validation loss decreased (0.397211 --> 0.396567).  Saving model ...
	 Train_Loss: 0.4095 Train_Acc: 83.479 Val_Loss: 0.3966  BEST VAL Loss: 0.3966  Val_Acc: 84.225

Epoch 69: Validation loss decreased (0.396567 --> 0.395924).  Saving model ...
	 Train_Loss: 0.4088 Train_Acc: 83.604 Val_Loss: 0.3959  BEST VAL Loss: 0.3959  Val_Acc: 84.220

Epoch 70: Validation loss decreased (0.395924 --> 0.395303).  Saving model ...
	 Train_Loss: 0.4081 Train_Acc: 83.543 Val_Loss: 0.3953  BEST VAL Loss: 0.3953  Val_Acc: 84.318

Epoch 71: Validation loss decreased (0.395303 --> 0.394688).  Saving model ...
	 Train_Loss: 0.4074 Train_Acc: 83.579 Val_Loss: 0.3947  BEST VAL Loss: 0.3947  Val_Acc: 84.340

Epoch 72: Validation loss decreased (0.394688 --> 0.394077).  Saving model ...
	 Train_Loss: 0.4067 Train_Acc: 83.730 Val_Loss: 0.3941  BEST VAL Loss: 0.3941  Val_Acc: 84.389

Epoch 73: Validation loss decreased (0.394077 --> 0.393466).  Saving model ...
	 Train_Loss: 0.4060 Train_Acc: 83.748 Val_Loss: 0.3935  BEST VAL Loss: 0.3935  Val_Acc: 84.220

Epoch 74: Validation loss decreased (0.393466 --> 0.392866).  Saving model ...
	 Train_Loss: 0.4053 Train_Acc: 83.771 Val_Loss: 0.3929  BEST VAL Loss: 0.3929  Val_Acc: 84.344

Epoch 75: Validation loss decreased (0.392866 --> 0.392286).  Saving model ...
	 Train_Loss: 0.4046 Train_Acc: 83.813 Val_Loss: 0.3923  BEST VAL Loss: 0.3923  Val_Acc: 84.548

Epoch 76: Validation loss decreased (0.392286 --> 0.391707).  Saving model ...
	 Train_Loss: 0.4039 Train_Acc: 83.828 Val_Loss: 0.3917  BEST VAL Loss: 0.3917  Val_Acc: 84.420

Epoch 77: Validation loss decreased (0.391707 --> 0.391126).  Saving model ...
	 Train_Loss: 0.4033 Train_Acc: 83.836 Val_Loss: 0.3911  BEST VAL Loss: 0.3911  Val_Acc: 84.646

Epoch 78: Validation loss decreased (0.391126 --> 0.390561).  Saving model ...
	 Train_Loss: 0.4026 Train_Acc: 83.797 Val_Loss: 0.3906  BEST VAL Loss: 0.3906  Val_Acc: 84.593

Epoch 79: Validation loss decreased (0.390561 --> 0.389998).  Saving model ...
	 Train_Loss: 0.4020 Train_Acc: 83.928 Val_Loss: 0.3900  BEST VAL Loss: 0.3900  Val_Acc: 84.588

Epoch 80: Validation loss decreased (0.389998 --> 0.389452).  Saving model ...
	 Train_Loss: 0.4014 Train_Acc: 83.887 Val_Loss: 0.3895  BEST VAL Loss: 0.3895  Val_Acc: 84.744

Epoch 81: Validation loss decreased (0.389452 --> 0.388902).  Saving model ...
	 Train_Loss: 0.4007 Train_Acc: 84.048 Val_Loss: 0.3889  BEST VAL Loss: 0.3889  Val_Acc: 84.651

Epoch 82: Validation loss decreased (0.388902 --> 0.388365).  Saving model ...
	 Train_Loss: 0.4001 Train_Acc: 84.057 Val_Loss: 0.3884  BEST VAL Loss: 0.3884  Val_Acc: 84.855

Epoch 83: Validation loss decreased (0.388365 --> 0.387838).  Saving model ...
	 Train_Loss: 0.3995 Train_Acc: 84.080 Val_Loss: 0.3878  BEST VAL Loss: 0.3878  Val_Acc: 84.806

Epoch 84: Validation loss decreased (0.387838 --> 0.387317).  Saving model ...
	 Train_Loss: 0.3989 Train_Acc: 84.128 Val_Loss: 0.3873  BEST VAL Loss: 0.3873  Val_Acc: 84.726

Epoch 85: Validation loss decreased (0.387317 --> 0.386803).  Saving model ...
	 Train_Loss: 0.3983 Train_Acc: 84.071 Val_Loss: 0.3868  BEST VAL Loss: 0.3868  Val_Acc: 84.943

Epoch 86: Validation loss decreased (0.386803 --> 0.386287).  Saving model ...
	 Train_Loss: 0.3977 Train_Acc: 84.140 Val_Loss: 0.3863  BEST VAL Loss: 0.3863  Val_Acc: 84.828

Epoch 87: Validation loss decreased (0.386287 --> 0.385772).  Saving model ...
	 Train_Loss: 0.3971 Train_Acc: 84.181 Val_Loss: 0.3858  BEST VAL Loss: 0.3858  Val_Acc: 84.983

Epoch 88: Validation loss decreased (0.385772 --> 0.385287).  Saving model ...
	 Train_Loss: 0.3965 Train_Acc: 84.309 Val_Loss: 0.3853  BEST VAL Loss: 0.3853  Val_Acc: 84.957

Epoch 89: Validation loss decreased (0.385287 --> 0.384798).  Saving model ...
	 Train_Loss: 0.3960 Train_Acc: 84.171 Val_Loss: 0.3848  BEST VAL Loss: 0.3848  Val_Acc: 84.806

Epoch 90: Validation loss decreased (0.384798 --> 0.384318).  Saving model ...
	 Train_Loss: 0.3954 Train_Acc: 84.287 Val_Loss: 0.3843  BEST VAL Loss: 0.3843  Val_Acc: 84.806

Epoch 91: Validation loss decreased (0.384318 --> 0.383839).  Saving model ...
	 Train_Loss: 0.3948 Train_Acc: 84.309 Val_Loss: 0.3838  BEST VAL Loss: 0.3838  Val_Acc: 85.019

Epoch 92: Validation loss decreased (0.383839 --> 0.383347).  Saving model ...
	 Train_Loss: 0.3943 Train_Acc: 84.319 Val_Loss: 0.3833  BEST VAL Loss: 0.3833  Val_Acc: 85.156

Epoch 93: Validation loss decreased (0.383347 --> 0.382869).  Saving model ...
	 Train_Loss: 0.3937 Train_Acc: 84.385 Val_Loss: 0.3829  BEST VAL Loss: 0.3829  Val_Acc: 85.099

Epoch 94: Validation loss decreased (0.382869 --> 0.382396).  Saving model ...
	 Train_Loss: 0.3932 Train_Acc: 84.458 Val_Loss: 0.3824  BEST VAL Loss: 0.3824  Val_Acc: 85.152

Epoch 95: Validation loss decreased (0.382396 --> 0.381947).  Saving model ...
	 Train_Loss: 0.3926 Train_Acc: 84.486 Val_Loss: 0.3819  BEST VAL Loss: 0.3819  Val_Acc: 85.094

Epoch 96: Validation loss decreased (0.381947 --> 0.381505).  Saving model ...
	 Train_Loss: 0.3921 Train_Acc: 84.471 Val_Loss: 0.3815  BEST VAL Loss: 0.3815  Val_Acc: 85.121

Epoch 97: Validation loss decreased (0.381505 --> 0.381046).  Saving model ...
	 Train_Loss: 0.3916 Train_Acc: 84.506 Val_Loss: 0.3810  BEST VAL Loss: 0.3810  Val_Acc: 85.192

Epoch 98: Validation loss decreased (0.381046 --> 0.380600).  Saving model ...
	 Train_Loss: 0.3911 Train_Acc: 84.526 Val_Loss: 0.3806  BEST VAL Loss: 0.3806  Val_Acc: 85.254

Epoch 99: Validation loss decreased (0.380600 --> 0.380154).  Saving model ...
	 Train_Loss: 0.3905 Train_Acc: 84.589 Val_Loss: 0.3802  BEST VAL Loss: 0.3802  Val_Acc: 85.334

LPS_10.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.86      0.90      0.88     92173
           1       0.89      0.84      0.86     88099

    accuracy                           0.87    180272
   macro avg       0.87      0.87      0.87    180272
weighted avg       0.87      0.87      0.87    180272

LPS_10.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.84      0.88      0.86     11522
           1       0.86      0.83      0.85     11013

    accuracy                           0.85     22535
   macro avg       0.85      0.85      0.85     22535
weighted avg       0.85      0.85      0.85     22535

LPS_10.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.84      0.87      0.86     11522
           1       0.86      0.83      0.84     11012

    accuracy                           0.85     22534
   macro avg       0.85      0.85      0.85     22534
weighted avg       0.85      0.85      0.85     22534

              precision    recall  f1-score   support

           0       0.84      0.87      0.86     11522
           1       0.86      0.83      0.84     11012

    accuracy                           0.85     22534
   macro avg       0.85      0.85      0.85     22534
weighted avg       0.85      0.85      0.85     22534

LPS_10.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.73      0.64      0.68     41273
           1       0.66      0.74      0.70     38332

    accuracy                           0.69     79605
   macro avg       0.69      0.69      0.69     79605
weighted avg       0.69      0.69      0.69     79605

              precision    recall  f1-score   support

           0       0.73      0.64      0.68     41273
           1       0.66      0.74      0.70     38332

    accuracy                           0.69     79605
   macro avg       0.69      0.69      0.69     79605
weighted avg       0.69      0.69      0.69     79605

completed
