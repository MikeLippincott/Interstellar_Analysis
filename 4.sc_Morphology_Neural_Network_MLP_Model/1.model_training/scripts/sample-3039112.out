[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '0ac67304'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'b4e792d9'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '34c1eabc'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '020215a1'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (32077, 1276)
Number of total missing values across all columns: 31718
Data Subset Is Off
Wells held out for testing: ['B20' 'K16']
Wells to use for training, validation, and testing ['B16' 'B17' 'B21' 'K17' 'K20' 'K21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.693154).  Saving model ...
	 Train_Loss: 0.7012 Train_Acc: 50.233 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 1: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6972 Train_Acc: 50.072 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 2: Validation loss did not decrease
	 Train_Loss: 0.6959 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 3: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6952 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 4: Validation loss did not decrease
	 Train_Loss: 0.6948 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 5: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6946 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 6: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6944 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 7: Validation loss did not decrease
	 Train_Loss: 0.6942 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 8: Validation loss did not decrease
	 Train_Loss: 0.6941 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 9: Validation loss did not decrease
	 Train_Loss: 0.6940 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 10: Validation loss did not decrease
	 Train_Loss: 0.6940 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 11: Validation loss did not decrease
	 Train_Loss: 0.6939 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 12: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6939 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 13: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6938 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 14: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6938 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 15: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6937 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 16: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6937 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 17: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6937 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 18: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6937 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 19: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6936 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 20: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6936 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 21: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6936 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 22: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6936 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 23: Validation loss did not decrease
	 Train_Loss: 0.6936 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 24: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6936 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.6935 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 26: Validation loss did not decrease
	 Train_Loss: 0.6935 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 27: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6935 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 28: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6935 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 29: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6935 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 30: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6935 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 31: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6935 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 32: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6935 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 33: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6935 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 34: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6935 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 35: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6935 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 36: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6935 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 37: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6934 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 38: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6934 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 39: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6934 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 40: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6934 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 41: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6934 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 42: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6934 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 43: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6934 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 44: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6934 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 45: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6934 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 46: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6934 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 47: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6934 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 48: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6934 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 49: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6934 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 50: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6934 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 51: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6934 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 52: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6934 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 53: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6934 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 54: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6934 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 55: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6934 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 56: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6934 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 57: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6934 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 58: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6934 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 59: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6934 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 60: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6934 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 61: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6934 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 62: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6934 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 63: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6934 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 64: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6934 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 65: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6934 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 66: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6934 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 67: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6934 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 68: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6934 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 69: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6933 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 70: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6933 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 71: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6933 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 72: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6933 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 73: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6933 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 74: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6933 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 75: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6933 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 76: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6933 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 77: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6933 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 78: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6933 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 79: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6933 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 80: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6933 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 81: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6933 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 82: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6933 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 83: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6933 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 84: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6933 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 85: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6933 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 86: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6933 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 87: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6933 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 88: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6933 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 89: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6933 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 90: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6933 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 91: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6933 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 92: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6933 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 93: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6933 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 94: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6933 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 95: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6933 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 96: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6933 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 97: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6933 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 98: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6933 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

Epoch 99: Validation loss decreased (0.693154 --> 0.693154).  Saving model ...
	 Train_Loss: 0.6933 Train_Acc: 50.021 Val_Loss: 0.6932  BEST VAL Loss: 0.6932  Val_Acc: 49.731

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.00      0.00      0.00      9708
           1       0.50      1.00      0.66      9604

    accuracy                           0.50     19312
   macro avg       0.25      0.50      0.33     19312
weighted avg       0.25      0.50      0.33     19312

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.00      0.00      0.00      1214
           1       0.50      1.00      0.66      1201

    accuracy                           0.50      2415
   macro avg       0.25      0.50      0.33      2415
weighted avg       0.25      0.50      0.33      2415

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.00      0.00      0.00      1213
           1       0.50      1.00      0.66      1201

    accuracy                           0.50      2414
   macro avg       0.25      0.50      0.33      2414
weighted avg       0.25      0.50      0.33      2414

              precision    recall  f1-score   support

           0       0.00      0.00      0.00      1213
           1       0.50      1.00      0.66      1201

    accuracy                           0.50      2414
   macro avg       0.25      0.50      0.33      2414
weighted avg       0.25      0.50      0.33      2414

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.00      0.00      0.00      3724
           1       0.53      1.00      0.69      4212

    accuracy                           0.53      7936
   macro avg       0.27      0.50      0.35      7936
weighted avg       0.28      0.53      0.37      7936

              precision    recall  f1-score   support

           0       0.00      0.00      0.00      3724
           1       0.53      1.00      0.69      4212

    accuracy                           0.53      7936
   macro avg       0.27      0.50      0.35      7936
weighted avg       0.28      0.53      0.37      7936

completed
