[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ca681be5'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'da870ddc'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '0e8383c2'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'fc67a5da'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (304610, 1270)
Number of total missing values across all columns: 277194
Data Subset Is Off
Wells held out for testing: ['C08' 'K08']
Wells to use for training, validation, and testing ['C02' 'C03' 'C09' 'K02' 'K03' 'K09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.337452).  Saving model ...
	 Train_Loss: 0.4738 Train_Acc: 77.571 Val_Loss: 0.3375  BEST VAL Loss: 0.3375  Val_Acc: 85.712

Epoch 1: Validation loss decreased (0.337452 --> 0.319380).  Saving model ...
	 Train_Loss: 0.4210 Train_Acc: 83.365 Val_Loss: 0.3194  BEST VAL Loss: 0.3194  Val_Acc: 87.519

Epoch 2: Validation loss decreased (0.319380 --> 0.307626).  Saving model ...
	 Train_Loss: 0.3966 Train_Acc: 84.467 Val_Loss: 0.3076  BEST VAL Loss: 0.3076  Val_Acc: 88.278

Epoch 3: Validation loss decreased (0.307626 --> 0.300083).  Saving model ...
	 Train_Loss: 0.3812 Train_Acc: 85.057 Val_Loss: 0.3001  BEST VAL Loss: 0.3001  Val_Acc: 88.322

Epoch 4: Validation loss decreased (0.300083 --> 0.294841).  Saving model ...
	 Train_Loss: 0.3706 Train_Acc: 85.394 Val_Loss: 0.2948  BEST VAL Loss: 0.2948  Val_Acc: 88.562

Epoch 5: Validation loss decreased (0.294841 --> 0.289918).  Saving model ...
	 Train_Loss: 0.3621 Train_Acc: 85.767 Val_Loss: 0.2899  BEST VAL Loss: 0.2899  Val_Acc: 89.072

Epoch 6: Validation loss decreased (0.289918 --> 0.284749).  Saving model ...
	 Train_Loss: 0.3553 Train_Acc: 85.975 Val_Loss: 0.2847  BEST VAL Loss: 0.2847  Val_Acc: 89.578

Epoch 7: Validation loss decreased (0.284749 --> 0.281446).  Saving model ...
	 Train_Loss: 0.3498 Train_Acc: 86.064 Val_Loss: 0.2814  BEST VAL Loss: 0.2814  Val_Acc: 89.334

Epoch 8: Validation loss decreased (0.281446 --> 0.279238).  Saving model ...
	 Train_Loss: 0.3450 Train_Acc: 86.379 Val_Loss: 0.2792  BEST VAL Loss: 0.2792  Val_Acc: 89.303

Epoch 9: Validation loss decreased (0.279238 --> 0.276750).  Saving model ...
	 Train_Loss: 0.3411 Train_Acc: 86.356 Val_Loss: 0.2768  BEST VAL Loss: 0.2768  Val_Acc: 89.714

Epoch 10: Validation loss decreased (0.276750 --> 0.274739).  Saving model ...
	 Train_Loss: 0.3376 Train_Acc: 86.416 Val_Loss: 0.2747  BEST VAL Loss: 0.2747  Val_Acc: 89.906

Epoch 11: Validation loss decreased (0.274739 --> 0.272989).  Saving model ...
	 Train_Loss: 0.3347 Train_Acc: 86.458 Val_Loss: 0.2730  BEST VAL Loss: 0.2730  Val_Acc: 89.875

Epoch 12: Validation loss decreased (0.272989 --> 0.270789).  Saving model ...
	 Train_Loss: 0.3318 Train_Acc: 86.639 Val_Loss: 0.2708  BEST VAL Loss: 0.2708  Val_Acc: 89.901

Epoch 13: Validation loss decreased (0.270789 --> 0.268606).  Saving model ...
	 Train_Loss: 0.3292 Train_Acc: 86.720 Val_Loss: 0.2686  BEST VAL Loss: 0.2686  Val_Acc: 90.211

Epoch 14: Validation loss decreased (0.268606 --> 0.266941).  Saving model ...
	 Train_Loss: 0.3268 Train_Acc: 86.749 Val_Loss: 0.2669  BEST VAL Loss: 0.2669  Val_Acc: 90.211

Epoch 15: Validation loss decreased (0.266941 --> 0.265498).  Saving model ...
	 Train_Loss: 0.3247 Train_Acc: 86.879 Val_Loss: 0.2655  BEST VAL Loss: 0.2655  Val_Acc: 90.189

Epoch 16: Validation loss decreased (0.265498 --> 0.264383).  Saving model ...
	 Train_Loss: 0.3228 Train_Acc: 86.897 Val_Loss: 0.2644  BEST VAL Loss: 0.2644  Val_Acc: 90.128

Epoch 17: Validation loss decreased (0.264383 --> 0.263362).  Saving model ...
	 Train_Loss: 0.3211 Train_Acc: 86.921 Val_Loss: 0.2634  BEST VAL Loss: 0.2634  Val_Acc: 90.229

Epoch 18: Validation loss decreased (0.263362 --> 0.262020).  Saving model ...
	 Train_Loss: 0.3195 Train_Acc: 86.921 Val_Loss: 0.2620  BEST VAL Loss: 0.2620  Val_Acc: 90.408

Epoch 19: Validation loss decreased (0.262020 --> 0.260702).  Saving model ...
	 Train_Loss: 0.3179 Train_Acc: 87.059 Val_Loss: 0.2607  BEST VAL Loss: 0.2607  Val_Acc: 90.456

Epoch 20: Validation loss decreased (0.260702 --> 0.259841).  Saving model ...
	 Train_Loss: 0.3165 Train_Acc: 86.909 Val_Loss: 0.2598  BEST VAL Loss: 0.2598  Val_Acc: 90.264

Epoch 21: Validation loss decreased (0.259841 --> 0.258637).  Saving model ...
	 Train_Loss: 0.3150 Train_Acc: 87.097 Val_Loss: 0.2586  BEST VAL Loss: 0.2586  Val_Acc: 90.552

Epoch 22: Validation loss decreased (0.258637 --> 0.257602).  Saving model ...
	 Train_Loss: 0.3139 Train_Acc: 87.074 Val_Loss: 0.2576  BEST VAL Loss: 0.2576  Val_Acc: 90.530

Epoch 23: Validation loss decreased (0.257602 --> 0.256653).  Saving model ...
	 Train_Loss: 0.3127 Train_Acc: 87.189 Val_Loss: 0.2567  BEST VAL Loss: 0.2567  Val_Acc: 90.543

Epoch 24: Validation loss decreased (0.256653 --> 0.256122).  Saving model ...
	 Train_Loss: 0.3115 Train_Acc: 87.213 Val_Loss: 0.2561  BEST VAL Loss: 0.2561  Val_Acc: 90.242

Epoch 25: Validation loss decreased (0.256122 --> 0.255451).  Saving model ...
	 Train_Loss: 0.3105 Train_Acc: 87.195 Val_Loss: 0.2555  BEST VAL Loss: 0.2555  Val_Acc: 90.229

Epoch 26: Validation loss decreased (0.255451 --> 0.254796).  Saving model ...
	 Train_Loss: 0.3094 Train_Acc: 87.226 Val_Loss: 0.2548  BEST VAL Loss: 0.2548  Val_Acc: 90.329

Epoch 27: Validation loss decreased (0.254796 --> 0.253963).  Saving model ...
	 Train_Loss: 0.3084 Train_Acc: 87.175 Val_Loss: 0.2540  BEST VAL Loss: 0.2540  Val_Acc: 90.429

Epoch 28: Validation loss decreased (0.253963 --> 0.253282).  Saving model ...
	 Train_Loss: 0.3074 Train_Acc: 87.255 Val_Loss: 0.2533  BEST VAL Loss: 0.2533  Val_Acc: 90.757

Epoch 29: Validation loss decreased (0.253282 --> 0.252592).  Saving model ...
	 Train_Loss: 0.3065 Train_Acc: 87.175 Val_Loss: 0.2526  BEST VAL Loss: 0.2526  Val_Acc: 90.779

Epoch 30: Validation loss decreased (0.252592 --> 0.252283).  Saving model ...
	 Train_Loss: 0.3058 Train_Acc: 87.177 Val_Loss: 0.2523  BEST VAL Loss: 0.2523  Val_Acc: 90.268

Epoch 31: Validation loss decreased (0.252283 --> 0.251781).  Saving model ...
	 Train_Loss: 0.3050 Train_Acc: 87.208 Val_Loss: 0.2518  BEST VAL Loss: 0.2518  Val_Acc: 90.621

Epoch 32: Validation loss decreased (0.251781 --> 0.251112).  Saving model ...
	 Train_Loss: 0.3042 Train_Acc: 87.302 Val_Loss: 0.2511  BEST VAL Loss: 0.2511  Val_Acc: 91.049

Epoch 33: Validation loss decreased (0.251112 --> 0.250637).  Saving model ...
	 Train_Loss: 0.3035 Train_Acc: 87.337 Val_Loss: 0.2506  BEST VAL Loss: 0.2506  Val_Acc: 90.512

Epoch 34: Validation loss decreased (0.250637 --> 0.250252).  Saving model ...
	 Train_Loss: 0.3028 Train_Acc: 87.259 Val_Loss: 0.2503  BEST VAL Loss: 0.2503  Val_Acc: 90.656

Epoch 35: Validation loss decreased (0.250252 --> 0.249574).  Saving model ...
	 Train_Loss: 0.3021 Train_Acc: 87.377 Val_Loss: 0.2496  BEST VAL Loss: 0.2496  Val_Acc: 90.966

Epoch 36: Validation loss decreased (0.249574 --> 0.249087).  Saving model ...
	 Train_Loss: 0.3015 Train_Acc: 87.249 Val_Loss: 0.2491  BEST VAL Loss: 0.2491  Val_Acc: 90.892

Epoch 37: Validation loss decreased (0.249087 --> 0.248789).  Saving model ...
	 Train_Loss: 0.3009 Train_Acc: 87.345 Val_Loss: 0.2488  BEST VAL Loss: 0.2488  Val_Acc: 90.355

Epoch 38: Validation loss decreased (0.248789 --> 0.248320).  Saving model ...
	 Train_Loss: 0.3003 Train_Acc: 87.418 Val_Loss: 0.2483  BEST VAL Loss: 0.2483  Val_Acc: 91.005

Epoch 39: Validation loss decreased (0.248320 --> 0.248108).  Saving model ...
	 Train_Loss: 0.2996 Train_Acc: 87.445 Val_Loss: 0.2481  BEST VAL Loss: 0.2481  Val_Acc: 90.621

Epoch 40: Validation loss decreased (0.248108 --> 0.247820).  Saving model ...
	 Train_Loss: 0.2990 Train_Acc: 87.425 Val_Loss: 0.2478  BEST VAL Loss: 0.2478  Val_Acc: 90.861

Epoch 41: Validation loss decreased (0.247820 --> 0.247664).  Saving model ...
	 Train_Loss: 0.2985 Train_Acc: 87.523 Val_Loss: 0.2477  BEST VAL Loss: 0.2477  Val_Acc: 90.277

Epoch 42: Validation loss decreased (0.247664 --> 0.247420).  Saving model ...
	 Train_Loss: 0.2979 Train_Acc: 87.537 Val_Loss: 0.2474  BEST VAL Loss: 0.2474  Val_Acc: 90.691

Epoch 43: Validation loss decreased (0.247420 --> 0.247190).  Saving model ...
	 Train_Loss: 0.2973 Train_Acc: 87.427 Val_Loss: 0.2472  BEST VAL Loss: 0.2472  Val_Acc: 90.604

Epoch 44: Validation loss decreased (0.247190 --> 0.246870).  Saving model ...
	 Train_Loss: 0.2968 Train_Acc: 87.533 Val_Loss: 0.2469  BEST VAL Loss: 0.2469  Val_Acc: 90.717

Epoch 45: Validation loss decreased (0.246870 --> 0.246577).  Saving model ...
	 Train_Loss: 0.2963 Train_Acc: 87.471 Val_Loss: 0.2466  BEST VAL Loss: 0.2466  Val_Acc: 90.713

Epoch 46: Validation loss decreased (0.246577 --> 0.246232).  Saving model ...
	 Train_Loss: 0.2958 Train_Acc: 87.493 Val_Loss: 0.2462  BEST VAL Loss: 0.2462  Val_Acc: 90.700

Epoch 47: Validation loss decreased (0.246232 --> 0.245821).  Saving model ...
	 Train_Loss: 0.2953 Train_Acc: 87.595 Val_Loss: 0.2458  BEST VAL Loss: 0.2458  Val_Acc: 91.115

Epoch 48: Validation loss decreased (0.245821 --> 0.245619).  Saving model ...
	 Train_Loss: 0.2948 Train_Acc: 87.524 Val_Loss: 0.2456  BEST VAL Loss: 0.2456  Val_Acc: 91.054

Epoch 49: Validation loss decreased (0.245619 --> 0.245399).  Saving model ...
	 Train_Loss: 0.2943 Train_Acc: 87.600 Val_Loss: 0.2454  BEST VAL Loss: 0.2454  Val_Acc: 90.783

Epoch 50: Validation loss decreased (0.245399 --> 0.245093).  Saving model ...
	 Train_Loss: 0.2939 Train_Acc: 87.611 Val_Loss: 0.2451  BEST VAL Loss: 0.2451  Val_Acc: 90.848

Epoch 51: Validation loss decreased (0.245093 --> 0.244826).  Saving model ...
	 Train_Loss: 0.2934 Train_Acc: 87.545 Val_Loss: 0.2448  BEST VAL Loss: 0.2448  Val_Acc: 90.896

Epoch 52: Validation loss decreased (0.244826 --> 0.244613).  Saving model ...
	 Train_Loss: 0.2930 Train_Acc: 87.563 Val_Loss: 0.2446  BEST VAL Loss: 0.2446  Val_Acc: 90.861

Epoch 53: Validation loss decreased (0.244613 --> 0.244244).  Saving model ...
	 Train_Loss: 0.2925 Train_Acc: 87.622 Val_Loss: 0.2442  BEST VAL Loss: 0.2442  Val_Acc: 90.966

Epoch 54: Validation loss decreased (0.244244 --> 0.244006).  Saving model ...
	 Train_Loss: 0.2921 Train_Acc: 87.655 Val_Loss: 0.2440  BEST VAL Loss: 0.2440  Val_Acc: 90.613

Epoch 55: Validation loss decreased (0.244006 --> 0.243825).  Saving model ...
	 Train_Loss: 0.2917 Train_Acc: 87.529 Val_Loss: 0.2438  BEST VAL Loss: 0.2438  Val_Acc: 90.792

Epoch 56: Validation loss decreased (0.243825 --> 0.243514).  Saving model ...
	 Train_Loss: 0.2913 Train_Acc: 87.653 Val_Loss: 0.2435  BEST VAL Loss: 0.2435  Val_Acc: 90.822

Epoch 57: Validation loss decreased (0.243514 --> 0.243257).  Saving model ...
	 Train_Loss: 0.2909 Train_Acc: 87.683 Val_Loss: 0.2433  BEST VAL Loss: 0.2433  Val_Acc: 90.905

Epoch 58: Validation loss decreased (0.243257 --> 0.243031).  Saving model ...
	 Train_Loss: 0.2905 Train_Acc: 87.635 Val_Loss: 0.2430  BEST VAL Loss: 0.2430  Val_Acc: 91.032

Epoch 59: Validation loss decreased (0.243031 --> 0.242857).  Saving model ...
	 Train_Loss: 0.2901 Train_Acc: 87.714 Val_Loss: 0.2429  BEST VAL Loss: 0.2429  Val_Acc: 91.097

Epoch 60: Validation loss decreased (0.242857 --> 0.242637).  Saving model ...
	 Train_Loss: 0.2898 Train_Acc: 87.532 Val_Loss: 0.2426  BEST VAL Loss: 0.2426  Val_Acc: 90.674

Epoch 61: Validation loss decreased (0.242637 --> 0.242381).  Saving model ...
	 Train_Loss: 0.2895 Train_Acc: 87.671 Val_Loss: 0.2424  BEST VAL Loss: 0.2424  Val_Acc: 90.944

Epoch 62: Validation loss decreased (0.242381 --> 0.242066).  Saving model ...
	 Train_Loss: 0.2891 Train_Acc: 87.620 Val_Loss: 0.2421  BEST VAL Loss: 0.2421  Val_Acc: 90.923

Epoch 63: Validation loss decreased (0.242066 --> 0.241754).  Saving model ...
	 Train_Loss: 0.2888 Train_Acc: 87.759 Val_Loss: 0.2418  BEST VAL Loss: 0.2418  Val_Acc: 91.333

Epoch 64: Validation loss decreased (0.241754 --> 0.241585).  Saving model ...
	 Train_Loss: 0.2884 Train_Acc: 87.736 Val_Loss: 0.2416  BEST VAL Loss: 0.2416  Val_Acc: 90.429

Epoch 65: Validation loss decreased (0.241585 --> 0.241314).  Saving model ...
	 Train_Loss: 0.2881 Train_Acc: 87.709 Val_Loss: 0.2413  BEST VAL Loss: 0.2413  Val_Acc: 91.093

Epoch 66: Validation loss decreased (0.241314 --> 0.241090).  Saving model ...
	 Train_Loss: 0.2878 Train_Acc: 87.602 Val_Loss: 0.2411  BEST VAL Loss: 0.2411  Val_Acc: 91.263

Epoch 67: Validation loss decreased (0.241090 --> 0.241022).  Saving model ...
	 Train_Loss: 0.2875 Train_Acc: 87.676 Val_Loss: 0.2410  BEST VAL Loss: 0.2410  Val_Acc: 91.010

Epoch 68: Validation loss decreased (0.241022 --> 0.240802).  Saving model ...
	 Train_Loss: 0.2872 Train_Acc: 87.631 Val_Loss: 0.2408  BEST VAL Loss: 0.2408  Val_Acc: 90.848

Epoch 69: Validation loss decreased (0.240802 --> 0.240564).  Saving model ...
	 Train_Loss: 0.2869 Train_Acc: 87.781 Val_Loss: 0.2406  BEST VAL Loss: 0.2406  Val_Acc: 90.888

Epoch 70: Validation loss decreased (0.240564 --> 0.240499).  Saving model ...
	 Train_Loss: 0.2866 Train_Acc: 87.666 Val_Loss: 0.2405  BEST VAL Loss: 0.2405  Val_Acc: 90.748

Epoch 71: Validation loss decreased (0.240499 --> 0.240358).  Saving model ...
	 Train_Loss: 0.2863 Train_Acc: 87.705 Val_Loss: 0.2404  BEST VAL Loss: 0.2404  Val_Acc: 90.722

Epoch 72: Validation loss decreased (0.240358 --> 0.240167).  Saving model ...
	 Train_Loss: 0.2860 Train_Acc: 87.749 Val_Loss: 0.2402  BEST VAL Loss: 0.2402  Val_Acc: 91.032

Epoch 73: Validation loss decreased (0.240167 --> 0.240030).  Saving model ...
	 Train_Loss: 0.2858 Train_Acc: 87.561 Val_Loss: 0.2400  BEST VAL Loss: 0.2400  Val_Acc: 90.944

Epoch 74: Validation loss decreased (0.240030 --> 0.239859).  Saving model ...
	 Train_Loss: 0.2855 Train_Acc: 87.764 Val_Loss: 0.2399  BEST VAL Loss: 0.2399  Val_Acc: 91.154

Epoch 75: Validation loss decreased (0.239859 --> 0.239715).  Saving model ...
	 Train_Loss: 0.2852 Train_Acc: 87.725 Val_Loss: 0.2397  BEST VAL Loss: 0.2397  Val_Acc: 90.857

Epoch 76: Validation loss decreased (0.239715 --> 0.239484).  Saving model ...
	 Train_Loss: 0.2850 Train_Acc: 87.665 Val_Loss: 0.2395  BEST VAL Loss: 0.2395  Val_Acc: 91.084

Epoch 77: Validation loss decreased (0.239484 --> 0.239316).  Saving model ...
	 Train_Loss: 0.2847 Train_Acc: 87.628 Val_Loss: 0.2393  BEST VAL Loss: 0.2393  Val_Acc: 90.923

Epoch 78: Validation loss decreased (0.239316 --> 0.239111).  Saving model ...
	 Train_Loss: 0.2845 Train_Acc: 87.734 Val_Loss: 0.2391  BEST VAL Loss: 0.2391  Val_Acc: 91.145

Epoch 79: Validation loss decreased (0.239111 --> 0.238909).  Saving model ...
	 Train_Loss: 0.2842 Train_Acc: 87.798 Val_Loss: 0.2389  BEST VAL Loss: 0.2389  Val_Acc: 91.027

Epoch 80: Validation loss decreased (0.238909 --> 0.238702).  Saving model ...
	 Train_Loss: 0.2839 Train_Acc: 87.886 Val_Loss: 0.2387  BEST VAL Loss: 0.2387  Val_Acc: 91.202

Epoch 81: Validation loss decreased (0.238702 --> 0.238636).  Saving model ...
	 Train_Loss: 0.2837 Train_Acc: 87.754 Val_Loss: 0.2386  BEST VAL Loss: 0.2386  Val_Acc: 90.822

Epoch 82: Validation loss decreased (0.238636 --> 0.238482).  Saving model ...
	 Train_Loss: 0.2834 Train_Acc: 87.881 Val_Loss: 0.2385  BEST VAL Loss: 0.2385  Val_Acc: 91.237

Epoch 83: Validation loss decreased (0.238482 --> 0.238300).  Saving model ...
	 Train_Loss: 0.2832 Train_Acc: 87.780 Val_Loss: 0.2383  BEST VAL Loss: 0.2383  Val_Acc: 91.333

Epoch 84: Validation loss decreased (0.238300 --> 0.238159).  Saving model ...
	 Train_Loss: 0.2830 Train_Acc: 87.772 Val_Loss: 0.2382  BEST VAL Loss: 0.2382  Val_Acc: 90.761

Epoch 85: Validation loss decreased (0.238159 --> 0.237964).  Saving model ...
	 Train_Loss: 0.2828 Train_Acc: 87.678 Val_Loss: 0.2380  BEST VAL Loss: 0.2380  Val_Acc: 91.202

Epoch 86: Validation loss decreased (0.237964 --> 0.237816).  Saving model ...
	 Train_Loss: 0.2825 Train_Acc: 87.889 Val_Loss: 0.2378  BEST VAL Loss: 0.2378  Val_Acc: 91.211

Epoch 87: Validation loss decreased (0.237816 --> 0.237775).  Saving model ...
	 Train_Loss: 0.2823 Train_Acc: 87.804 Val_Loss: 0.2378  BEST VAL Loss: 0.2378  Val_Acc: 91.219

Epoch 88: Validation loss decreased (0.237775 --> 0.237600).  Saving model ...
	 Train_Loss: 0.2821 Train_Acc: 87.853 Val_Loss: 0.2376  BEST VAL Loss: 0.2376  Val_Acc: 91.246

Epoch 89: Validation loss decreased (0.237600 --> 0.237561).  Saving model ...
	 Train_Loss: 0.2818 Train_Acc: 87.878 Val_Loss: 0.2376  BEST VAL Loss: 0.2376  Val_Acc: 90.783

Epoch 90: Validation loss decreased (0.237561 --> 0.237447).  Saving model ...
	 Train_Loss: 0.2817 Train_Acc: 87.764 Val_Loss: 0.2374  BEST VAL Loss: 0.2374  Val_Acc: 91.228

Epoch 91: Validation loss decreased (0.237447 --> 0.237298).  Saving model ...
	 Train_Loss: 0.2814 Train_Acc: 87.811 Val_Loss: 0.2373  BEST VAL Loss: 0.2373  Val_Acc: 91.145

Epoch 92: Validation loss decreased (0.237298 --> 0.237147).  Saving model ...
	 Train_Loss: 0.2812 Train_Acc: 87.816 Val_Loss: 0.2371  BEST VAL Loss: 0.2371  Val_Acc: 91.128

Epoch 93: Validation loss decreased (0.237147 --> 0.237019).  Saving model ...
	 Train_Loss: 0.2810 Train_Acc: 87.790 Val_Loss: 0.2370  BEST VAL Loss: 0.2370  Val_Acc: 91.250

Epoch 94: Validation loss decreased (0.237019 --> 0.236887).  Saving model ...
	 Train_Loss: 0.2808 Train_Acc: 87.834 Val_Loss: 0.2369  BEST VAL Loss: 0.2369  Val_Acc: 91.198

Epoch 95: Validation loss decreased (0.236887 --> 0.236750).  Saving model ...
	 Train_Loss: 0.2806 Train_Acc: 87.858 Val_Loss: 0.2367  BEST VAL Loss: 0.2367  Val_Acc: 91.045

Epoch 96: Validation loss decreased (0.236750 --> 0.236598).  Saving model ...
	 Train_Loss: 0.2804 Train_Acc: 87.911 Val_Loss: 0.2366  BEST VAL Loss: 0.2366  Val_Acc: 91.080

Epoch 97: Validation loss decreased (0.236598 --> 0.236447).  Saving model ...
	 Train_Loss: 0.2802 Train_Acc: 87.907 Val_Loss: 0.2364  BEST VAL Loss: 0.2364  Val_Acc: 91.150

Epoch 98: Validation loss decreased (0.236447 --> 0.236416).  Saving model ...
	 Train_Loss: 0.2801 Train_Acc: 87.740 Val_Loss: 0.2364  BEST VAL Loss: 0.2364  Val_Acc: 90.787

Epoch 99: Validation loss decreased (0.236416 --> 0.236278).  Saving model ...
	 Train_Loss: 0.2799 Train_Acc: 87.882 Val_Loss: 0.2363  BEST VAL Loss: 0.2363  Val_Acc: 91.198

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.45      0.45      0.45     82968
           1       0.55      0.54      0.54    100339

    accuracy                           0.50    183307
   macro avg       0.50      0.50      0.50    183307
weighted avg       0.50      0.50      0.50    183307

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.45      0.45      0.45     10371
           1       0.55      0.54      0.54     12543

    accuracy                           0.50     22914
   macro avg       0.50      0.50      0.50     22914
weighted avg       0.50      0.50      0.50     22914

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.45      0.46      0.46     10371
           1       0.55      0.54      0.55     12543

    accuracy                           0.51     22914
   macro avg       0.50      0.50      0.50     22914
weighted avg       0.51      0.51      0.51     22914

              precision    recall  f1-score   support

           0       0.45      0.46      0.46     10371
           1       0.55      0.54      0.55     12543

    accuracy                           0.51     22914
   macro avg       0.50      0.50      0.50     22914
weighted avg       0.51      0.51      0.51     22914

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.50      0.48     34887
           1       0.54      0.50      0.52     40588

    accuracy                           0.50     75475
   macro avg       0.50      0.50      0.50     75475
weighted avg       0.50      0.50      0.50     75475

              precision    recall  f1-score   support

           0       0.46      0.50      0.48     34887
           1       0.54      0.50      0.52     40588

    accuracy                           0.50     75475
   macro avg       0.50      0.50      0.50     75475
weighted avg       0.50      0.50      0.50     75475

completed
