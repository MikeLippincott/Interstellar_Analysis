[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'be44c736'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'f4ecca4d'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd9d3e3de'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'a61c48de'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
TREATMENT_NAME: Flagellin_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_Nigericin_1.000_10.0_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (285713, 1270)
Number of total missing values across all columns: 245710
Data Subset Is Off
Wells held out for testing: ['M08' 'M10']
Wells to use for training, validation, and testing ['M02' 'M03' 'M05' 'M09' 'M11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.124357).  Saving model ...
	 Train_Loss: 0.2254 Train_Acc: 91.483 Val_Loss: 0.1244  BEST VAL Loss: 0.1244  Val_Acc: 95.656

Epoch 1: Validation loss decreased (0.124357 --> 0.111553).  Saving model ...
	 Train_Loss: 0.1894 Train_Acc: 94.649 Val_Loss: 0.1116  BEST VAL Loss: 0.1116  Val_Acc: 96.587

Epoch 2: Validation loss decreased (0.111553 --> 0.106502).  Saving model ...
	 Train_Loss: 0.1718 Train_Acc: 95.164 Val_Loss: 0.1065  BEST VAL Loss: 0.1065  Val_Acc: 96.578

Epoch 3: Validation loss decreased (0.106502 --> 0.101963).  Saving model ...
	 Train_Loss: 0.1611 Train_Acc: 95.483 Val_Loss: 0.1020  BEST VAL Loss: 0.1020  Val_Acc: 96.973

Epoch 4: Validation loss decreased (0.101963 --> 0.099264).  Saving model ...
	 Train_Loss: 0.1535 Train_Acc: 95.654 Val_Loss: 0.0993  BEST VAL Loss: 0.0993  Val_Acc: 96.993

Epoch 5: Validation loss decreased (0.099264 --> 0.097092).  Saving model ...
	 Train_Loss: 0.1477 Train_Acc: 95.867 Val_Loss: 0.0971  BEST VAL Loss: 0.0971  Val_Acc: 97.060

Epoch 6: Validation loss decreased (0.097092 --> 0.095845).  Saving model ...
	 Train_Loss: 0.1436 Train_Acc: 95.807 Val_Loss: 0.0958  BEST VAL Loss: 0.0958  Val_Acc: 97.089

Epoch 7: Validation loss decreased (0.095845 --> 0.094690).  Saving model ...
	 Train_Loss: 0.1399 Train_Acc: 95.929 Val_Loss: 0.0947  BEST VAL Loss: 0.0947  Val_Acc: 97.147

Epoch 8: Validation loss decreased (0.094690 --> 0.093289).  Saving model ...
	 Train_Loss: 0.1368 Train_Acc: 96.065 Val_Loss: 0.0933  BEST VAL Loss: 0.0933  Val_Acc: 97.133

Epoch 9: Validation loss decreased (0.093289 --> 0.091947).  Saving model ...
	 Train_Loss: 0.1342 Train_Acc: 96.085 Val_Loss: 0.0919  BEST VAL Loss: 0.0919  Val_Acc: 97.360

Epoch 10: Validation loss decreased (0.091947 --> 0.091300).  Saving model ...
	 Train_Loss: 0.1319 Train_Acc: 96.099 Val_Loss: 0.0913  BEST VAL Loss: 0.0913  Val_Acc: 97.282

Epoch 11: Validation loss decreased (0.091300 --> 0.090705).  Saving model ...
	 Train_Loss: 0.1299 Train_Acc: 96.243 Val_Loss: 0.0907  BEST VAL Loss: 0.0907  Val_Acc: 97.253

Epoch 12: Validation loss decreased (0.090705 --> 0.090026).  Saving model ...
	 Train_Loss: 0.1281 Train_Acc: 96.308 Val_Loss: 0.0900  BEST VAL Loss: 0.0900  Val_Acc: 97.263

Epoch 13: Validation loss decreased (0.090026 --> 0.089336).  Saving model ...
	 Train_Loss: 0.1264 Train_Acc: 96.336 Val_Loss: 0.0893  BEST VAL Loss: 0.0893  Val_Acc: 97.258

Epoch 14: Validation loss decreased (0.089336 --> 0.088634).  Saving model ...
	 Train_Loss: 0.1249 Train_Acc: 96.308 Val_Loss: 0.0886  BEST VAL Loss: 0.0886  Val_Acc: 97.374

Epoch 15: Validation loss decreased (0.088634 --> 0.088167).  Saving model ...
	 Train_Loss: 0.1235 Train_Acc: 96.347 Val_Loss: 0.0882  BEST VAL Loss: 0.0882  Val_Acc: 97.374

Epoch 16: Validation loss decreased (0.088167 --> 0.087414).  Saving model ...
	 Train_Loss: 0.1224 Train_Acc: 96.285 Val_Loss: 0.0874  BEST VAL Loss: 0.0874  Val_Acc: 97.466

Epoch 17: Validation loss decreased (0.087414 --> 0.086763).  Saving model ...
	 Train_Loss: 0.1212 Train_Acc: 96.460 Val_Loss: 0.0868  BEST VAL Loss: 0.0868  Val_Acc: 97.413

Epoch 18: Validation loss decreased (0.086763 --> 0.086439).  Saving model ...
	 Train_Loss: 0.1202 Train_Acc: 96.430 Val_Loss: 0.0864  BEST VAL Loss: 0.0864  Val_Acc: 97.306

Epoch 19: Validation loss decreased (0.086439 --> 0.085940).  Saving model ...
	 Train_Loss: 0.1193 Train_Acc: 96.416 Val_Loss: 0.0859  BEST VAL Loss: 0.0859  Val_Acc: 97.442

Epoch 20: Validation loss decreased (0.085940 --> 0.085477).  Saving model ...
	 Train_Loss: 0.1183 Train_Acc: 96.512 Val_Loss: 0.0855  BEST VAL Loss: 0.0855  Val_Acc: 97.403

Epoch 21: Validation loss decreased (0.085477 --> 0.084968).  Saving model ...
	 Train_Loss: 0.1175 Train_Acc: 96.556 Val_Loss: 0.0850  BEST VAL Loss: 0.0850  Val_Acc: 97.553

Epoch 22: Validation loss decreased (0.084968 --> 0.084713).  Saving model ...
	 Train_Loss: 0.1166 Train_Acc: 96.499 Val_Loss: 0.0847  BEST VAL Loss: 0.0847  Val_Acc: 97.364

Epoch 23: Validation loss decreased (0.084713 --> 0.084350).  Saving model ...
	 Train_Loss: 0.1159 Train_Acc: 96.540 Val_Loss: 0.0843  BEST VAL Loss: 0.0843  Val_Acc: 97.504

Epoch 24: Validation loss decreased (0.084350 --> 0.083991).  Saving model ...
	 Train_Loss: 0.1151 Train_Acc: 96.583 Val_Loss: 0.0840  BEST VAL Loss: 0.0840  Val_Acc: 97.514

Epoch 25: Validation loss decreased (0.083991 --> 0.083617).  Saving model ...
	 Train_Loss: 0.1144 Train_Acc: 96.593 Val_Loss: 0.0836  BEST VAL Loss: 0.0836  Val_Acc: 97.519

Epoch 26: Validation loss decreased (0.083617 --> 0.083283).  Saving model ...
	 Train_Loss: 0.1138 Train_Acc: 96.577 Val_Loss: 0.0833  BEST VAL Loss: 0.0833  Val_Acc: 97.364

Epoch 27: Validation loss decreased (0.083283 --> 0.083034).  Saving model ...
	 Train_Loss: 0.1131 Train_Acc: 96.612 Val_Loss: 0.0830  BEST VAL Loss: 0.0830  Val_Acc: 97.442

Epoch 28: Validation loss decreased (0.083034 --> 0.082736).  Saving model ...
	 Train_Loss: 0.1126 Train_Acc: 96.605 Val_Loss: 0.0827  BEST VAL Loss: 0.0827  Val_Acc: 97.543

Epoch 29: Validation loss decreased (0.082736 --> 0.082458).  Saving model ...
	 Train_Loss: 0.1120 Train_Acc: 96.675 Val_Loss: 0.0825  BEST VAL Loss: 0.0825  Val_Acc: 97.606

Epoch 30: Validation loss decreased (0.082458 --> 0.082318).  Saving model ...
	 Train_Loss: 0.1114 Train_Acc: 96.649 Val_Loss: 0.0823  BEST VAL Loss: 0.0823  Val_Acc: 97.413

Epoch 31: Validation loss decreased (0.082318 --> 0.082081).  Saving model ...
	 Train_Loss: 0.1110 Train_Acc: 96.613 Val_Loss: 0.0821  BEST VAL Loss: 0.0821  Val_Acc: 97.495

Epoch 32: Validation loss decreased (0.082081 --> 0.081943).  Saving model ...
	 Train_Loss: 0.1105 Train_Acc: 96.697 Val_Loss: 0.0819  BEST VAL Loss: 0.0819  Val_Acc: 97.437

Epoch 33: Validation loss decreased (0.081943 --> 0.081658).  Saving model ...
	 Train_Loss: 0.1100 Train_Acc: 96.664 Val_Loss: 0.0817  BEST VAL Loss: 0.0817  Val_Acc: 97.514

Epoch 34: Validation loss decreased (0.081658 --> 0.081437).  Saving model ...
	 Train_Loss: 0.1096 Train_Acc: 96.672 Val_Loss: 0.0814  BEST VAL Loss: 0.0814  Val_Acc: 97.485

Epoch 35: Validation loss decreased (0.081437 --> 0.081307).  Saving model ...
	 Train_Loss: 0.1091 Train_Acc: 96.772 Val_Loss: 0.0813  BEST VAL Loss: 0.0813  Val_Acc: 97.567

Epoch 36: Validation loss decreased (0.081307 --> 0.081080).  Saving model ...
	 Train_Loss: 0.1087 Train_Acc: 96.710 Val_Loss: 0.0811  BEST VAL Loss: 0.0811  Val_Acc: 97.495

Epoch 37: Validation loss decreased (0.081080 --> 0.080841).  Saving model ...
	 Train_Loss: 0.1084 Train_Acc: 96.711 Val_Loss: 0.0808  BEST VAL Loss: 0.0808  Val_Acc: 97.673

Epoch 38: Validation loss decreased (0.080841 --> 0.080641).  Saving model ...
	 Train_Loss: 0.1080 Train_Acc: 96.735 Val_Loss: 0.0806  BEST VAL Loss: 0.0806  Val_Acc: 97.538

Epoch 39: Validation loss decreased (0.080641 --> 0.080496).  Saving model ...
	 Train_Loss: 0.1076 Train_Acc: 96.780 Val_Loss: 0.0805  BEST VAL Loss: 0.0805  Val_Acc: 97.451

Epoch 40: Validation loss decreased (0.080496 --> 0.080306).  Saving model ...
	 Train_Loss: 0.1072 Train_Acc: 96.781 Val_Loss: 0.0803  BEST VAL Loss: 0.0803  Val_Acc: 97.557

Epoch 41: Validation loss decreased (0.080306 --> 0.080152).  Saving model ...
	 Train_Loss: 0.1068 Train_Acc: 96.828 Val_Loss: 0.0802  BEST VAL Loss: 0.0802  Val_Acc: 97.615

Epoch 42: Validation loss decreased (0.080152 --> 0.079953).  Saving model ...
	 Train_Loss: 0.1065 Train_Acc: 96.796 Val_Loss: 0.0800  BEST VAL Loss: 0.0800  Val_Acc: 97.606

Epoch 43: Validation loss decreased (0.079953 --> 0.079806).  Saving model ...
	 Train_Loss: 0.1061 Train_Acc: 96.773 Val_Loss: 0.0798  BEST VAL Loss: 0.0798  Val_Acc: 97.668

Epoch 44: Validation loss decreased (0.079806 --> 0.079652).  Saving model ...
	 Train_Loss: 0.1058 Train_Acc: 96.811 Val_Loss: 0.0797  BEST VAL Loss: 0.0797  Val_Acc: 97.625

Epoch 45: Validation loss decreased (0.079652 --> 0.079382).  Saving model ...
	 Train_Loss: 0.1055 Train_Acc: 96.845 Val_Loss: 0.0794  BEST VAL Loss: 0.0794  Val_Acc: 97.736

Epoch 46: Validation loss decreased (0.079382 --> 0.079232).  Saving model ...
	 Train_Loss: 0.1052 Train_Acc: 96.790 Val_Loss: 0.0792  BEST VAL Loss: 0.0792  Val_Acc: 97.601

Epoch 47: Validation loss decreased (0.079232 --> 0.079128).  Saving model ...
	 Train_Loss: 0.1049 Train_Acc: 96.808 Val_Loss: 0.0791  BEST VAL Loss: 0.0791  Val_Acc: 97.615

Epoch 48: Validation loss decreased (0.079128 --> 0.078954).  Saving model ...
	 Train_Loss: 0.1046 Train_Acc: 96.812 Val_Loss: 0.0790  BEST VAL Loss: 0.0790  Val_Acc: 97.582

Epoch 49: Validation loss decreased (0.078954 --> 0.078797).  Saving model ...
	 Train_Loss: 0.1043 Train_Acc: 96.822 Val_Loss: 0.0788  BEST VAL Loss: 0.0788  Val_Acc: 97.557

Epoch 50: Validation loss decreased (0.078797 --> 0.078764).  Saving model ...
	 Train_Loss: 0.1040 Train_Acc: 96.853 Val_Loss: 0.0788  BEST VAL Loss: 0.0788  Val_Acc: 97.649

Epoch 51: Validation loss decreased (0.078764 --> 0.078664).  Saving model ...
	 Train_Loss: 0.1037 Train_Acc: 96.924 Val_Loss: 0.0787  BEST VAL Loss: 0.0787  Val_Acc: 97.577

Epoch 52: Validation loss decreased (0.078664 --> 0.078545).  Saving model ...
	 Train_Loss: 0.1034 Train_Acc: 96.899 Val_Loss: 0.0785  BEST VAL Loss: 0.0785  Val_Acc: 97.635

Epoch 53: Validation loss decreased (0.078545 --> 0.078402).  Saving model ...
	 Train_Loss: 0.1031 Train_Acc: 96.938 Val_Loss: 0.0784  BEST VAL Loss: 0.0784  Val_Acc: 97.596

Epoch 54: Validation loss decreased (0.078402 --> 0.078249).  Saving model ...
	 Train_Loss: 0.1029 Train_Acc: 96.836 Val_Loss: 0.0782  BEST VAL Loss: 0.0782  Val_Acc: 97.683

Epoch 55: Validation loss decreased (0.078249 --> 0.078093).  Saving model ...
	 Train_Loss: 0.1026 Train_Acc: 96.947 Val_Loss: 0.0781  BEST VAL Loss: 0.0781  Val_Acc: 97.741

Epoch 56: Validation loss decreased (0.078093 --> 0.077980).  Saving model ...
	 Train_Loss: 0.1024 Train_Acc: 96.858 Val_Loss: 0.0780  BEST VAL Loss: 0.0780  Val_Acc: 97.668

Epoch 57: Validation loss decreased (0.077980 --> 0.077818).  Saving model ...
	 Train_Loss: 0.1021 Train_Acc: 96.926 Val_Loss: 0.0778  BEST VAL Loss: 0.0778  Val_Acc: 97.640

Epoch 58: Validation loss decreased (0.077818 --> 0.077679).  Saving model ...
	 Train_Loss: 0.1019 Train_Acc: 96.916 Val_Loss: 0.0777  BEST VAL Loss: 0.0777  Val_Acc: 97.746

Epoch 59: Validation loss decreased (0.077679 --> 0.077575).  Saving model ...
	 Train_Loss: 0.1016 Train_Acc: 96.942 Val_Loss: 0.0776  BEST VAL Loss: 0.0776  Val_Acc: 97.644

Epoch 60: Validation loss decreased (0.077575 --> 0.077492).  Saving model ...
	 Train_Loss: 0.1014 Train_Acc: 96.929 Val_Loss: 0.0775  BEST VAL Loss: 0.0775  Val_Acc: 97.615

Epoch 61: Validation loss decreased (0.077492 --> 0.077394).  Saving model ...
	 Train_Loss: 0.1012 Train_Acc: 96.953 Val_Loss: 0.0774  BEST VAL Loss: 0.0774  Val_Acc: 97.601

Epoch 62: Validation loss decreased (0.077394 --> 0.077281).  Saving model ...
	 Train_Loss: 0.1010 Train_Acc: 96.953 Val_Loss: 0.0773  BEST VAL Loss: 0.0773  Val_Acc: 97.659

Epoch 63: Validation loss decreased (0.077281 --> 0.077158).  Saving model ...
	 Train_Loss: 0.1008 Train_Acc: 96.959 Val_Loss: 0.0772  BEST VAL Loss: 0.0772  Val_Acc: 97.712

Epoch 64: Validation loss decreased (0.077158 --> 0.077018).  Saving model ...
	 Train_Loss: 0.1005 Train_Acc: 96.985 Val_Loss: 0.0770  BEST VAL Loss: 0.0770  Val_Acc: 97.736

Epoch 65: Validation loss decreased (0.077018 --> 0.076887).  Saving model ...
	 Train_Loss: 0.1003 Train_Acc: 96.950 Val_Loss: 0.0769  BEST VAL Loss: 0.0769  Val_Acc: 97.775

Epoch 66: Validation loss decreased (0.076887 --> 0.076767).  Saving model ...
	 Train_Loss: 0.1001 Train_Acc: 96.918 Val_Loss: 0.0768  BEST VAL Loss: 0.0768  Val_Acc: 97.673

Epoch 67: Validation loss decreased (0.076767 --> 0.076655).  Saving model ...
	 Train_Loss: 0.0999 Train_Acc: 97.023 Val_Loss: 0.0767  BEST VAL Loss: 0.0767  Val_Acc: 97.731

Epoch 68: Validation loss decreased (0.076655 --> 0.076556).  Saving model ...
	 Train_Loss: 0.0997 Train_Acc: 96.980 Val_Loss: 0.0766  BEST VAL Loss: 0.0766  Val_Acc: 97.707

Epoch 69: Validation loss decreased (0.076556 --> 0.076483).  Saving model ...
	 Train_Loss: 0.0995 Train_Acc: 96.912 Val_Loss: 0.0765  BEST VAL Loss: 0.0765  Val_Acc: 97.693

Epoch 70: Validation loss decreased (0.076483 --> 0.076354).  Saving model ...
	 Train_Loss: 0.0993 Train_Acc: 97.009 Val_Loss: 0.0764  BEST VAL Loss: 0.0764  Val_Acc: 97.755

Epoch 71: Validation loss decreased (0.076354 --> 0.076258).  Saving model ...
	 Train_Loss: 0.0992 Train_Acc: 96.980 Val_Loss: 0.0763  BEST VAL Loss: 0.0763  Val_Acc: 97.654

Epoch 72: Validation loss decreased (0.076258 --> 0.076167).  Saving model ...
	 Train_Loss: 0.0990 Train_Acc: 96.988 Val_Loss: 0.0762  BEST VAL Loss: 0.0762  Val_Acc: 97.712

Epoch 73: Validation loss decreased (0.076167 --> 0.076077).  Saving model ...
	 Train_Loss: 0.0988 Train_Acc: 96.970 Val_Loss: 0.0761  BEST VAL Loss: 0.0761  Val_Acc: 97.577

Epoch 74: Validation loss decreased (0.076077 --> 0.076030).  Saving model ...
	 Train_Loss: 0.0986 Train_Acc: 96.988 Val_Loss: 0.0760  BEST VAL Loss: 0.0760  Val_Acc: 97.746

Epoch 75: Validation loss decreased (0.076030 --> 0.076020).  Saving model ...
	 Train_Loss: 0.0984 Train_Acc: 97.061 Val_Loss: 0.0760  BEST VAL Loss: 0.0760  Val_Acc: 97.693

Epoch 76: Validation loss decreased (0.076020 --> 0.075969).  Saving model ...
	 Train_Loss: 0.0983 Train_Acc: 97.001 Val_Loss: 0.0760  BEST VAL Loss: 0.0760  Val_Acc: 97.726

Epoch 77: Validation loss decreased (0.075969 --> 0.075922).  Saving model ...
	 Train_Loss: 0.0981 Train_Acc: 96.974 Val_Loss: 0.0759  BEST VAL Loss: 0.0759  Val_Acc: 97.683

Epoch 78: Validation loss decreased (0.075922 --> 0.075862).  Saving model ...
	 Train_Loss: 0.0979 Train_Acc: 97.051 Val_Loss: 0.0759  BEST VAL Loss: 0.0759  Val_Acc: 97.731

Epoch 79: Validation loss decreased (0.075862 --> 0.075836).  Saving model ...
	 Train_Loss: 0.0978 Train_Acc: 97.033 Val_Loss: 0.0758  BEST VAL Loss: 0.0758  Val_Acc: 97.697

Epoch 80: Validation loss decreased (0.075836 --> 0.075790).  Saving model ...
	 Train_Loss: 0.0976 Train_Acc: 97.018 Val_Loss: 0.0758  BEST VAL Loss: 0.0758  Val_Acc: 97.673

Epoch 81: Validation loss decreased (0.075790 --> 0.075752).  Saving model ...
	 Train_Loss: 0.0975 Train_Acc: 97.044 Val_Loss: 0.0758  BEST VAL Loss: 0.0758  Val_Acc: 97.664

Epoch 82: Validation loss decreased (0.075752 --> 0.075713).  Saving model ...
	 Train_Loss: 0.0973 Train_Acc: 97.105 Val_Loss: 0.0757  BEST VAL Loss: 0.0757  Val_Acc: 97.789

Epoch 83: Validation loss decreased (0.075713 --> 0.075687).  Saving model ...
	 Train_Loss: 0.0971 Train_Acc: 97.090 Val_Loss: 0.0757  BEST VAL Loss: 0.0757  Val_Acc: 97.770

Epoch 84: Validation loss decreased (0.075687 --> 0.075641).  Saving model ...
	 Train_Loss: 0.0970 Train_Acc: 97.084 Val_Loss: 0.0756  BEST VAL Loss: 0.0756  Val_Acc: 97.746

Epoch 85: Validation loss decreased (0.075641 --> 0.075592).  Saving model ...
	 Train_Loss: 0.0968 Train_Acc: 97.024 Val_Loss: 0.0756  BEST VAL Loss: 0.0756  Val_Acc: 97.712

Epoch 86: Validation loss decreased (0.075592 --> 0.075543).  Saving model ...
	 Train_Loss: 0.0967 Train_Acc: 97.061 Val_Loss: 0.0755  BEST VAL Loss: 0.0755  Val_Acc: 97.678

Epoch 87: Validation loss decreased (0.075543 --> 0.075499).  Saving model ...
	 Train_Loss: 0.0966 Train_Acc: 97.056 Val_Loss: 0.0755  BEST VAL Loss: 0.0755  Val_Acc: 97.635

Epoch 88: Validation loss decreased (0.075499 --> 0.075468).  Saving model ...
	 Train_Loss: 0.0964 Train_Acc: 97.069 Val_Loss: 0.0755  BEST VAL Loss: 0.0755  Val_Acc: 97.668

Epoch 89: Validation loss decreased (0.075468 --> 0.075386).  Saving model ...
	 Train_Loss: 0.0963 Train_Acc: 97.090 Val_Loss: 0.0754  BEST VAL Loss: 0.0754  Val_Acc: 97.731

Epoch 90: Validation loss decreased (0.075386 --> 0.075318).  Saving model ...
	 Train_Loss: 0.0961 Train_Acc: 97.091 Val_Loss: 0.0753  BEST VAL Loss: 0.0753  Val_Acc: 97.635

Epoch 91: Validation loss decreased (0.075318 --> 0.075253).  Saving model ...
	 Train_Loss: 0.0960 Train_Acc: 97.020 Val_Loss: 0.0753  BEST VAL Loss: 0.0753  Val_Acc: 97.591

Epoch 92: Validation loss decreased (0.075253 --> 0.075208).  Saving model ...
	 Train_Loss: 0.0959 Train_Acc: 97.166 Val_Loss: 0.0752  BEST VAL Loss: 0.0752  Val_Acc: 97.649

Epoch 93: Validation loss decreased (0.075208 --> 0.075164).  Saving model ...
	 Train_Loss: 0.0957 Train_Acc: 97.102 Val_Loss: 0.0752  BEST VAL Loss: 0.0752  Val_Acc: 97.693

Epoch 94: Validation loss decreased (0.075164 --> 0.075090).  Saving model ...
	 Train_Loss: 0.0956 Train_Acc: 97.075 Val_Loss: 0.0751  BEST VAL Loss: 0.0751  Val_Acc: 97.736

Epoch 95: Validation loss decreased (0.075090 --> 0.075045).  Saving model ...
	 Train_Loss: 0.0955 Train_Acc: 97.090 Val_Loss: 0.0750  BEST VAL Loss: 0.0750  Val_Acc: 97.736

Epoch 96: Validation loss decreased (0.075045 --> 0.074976).  Saving model ...
	 Train_Loss: 0.0953 Train_Acc: 97.151 Val_Loss: 0.0750  BEST VAL Loss: 0.0750  Val_Acc: 97.755

Epoch 97: Validation loss decreased (0.074976 --> 0.074975).  Saving model ...
	 Train_Loss: 0.0952 Train_Acc: 97.119 Val_Loss: 0.0750  BEST VAL Loss: 0.0750  Val_Acc: 97.712

Epoch 98: Validation loss decreased (0.074975 --> 0.074930).  Saving model ...
	 Train_Loss: 0.0951 Train_Acc: 97.080 Val_Loss: 0.0749  BEST VAL Loss: 0.0749  Val_Acc: 97.789

Epoch 99: Validation loss did not decrease
	 Train_Loss: 0.0950 Train_Acc: 97.131 Val_Loss: 0.0749  BEST VAL Loss: 0.0749  Val_Acc: 97.644

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.98      0.98     56122
           1       0.99      0.99      0.99    109598

    accuracy                           0.99    165720
   macro avg       0.99      0.99      0.99    165720
weighted avg       0.99      0.99      0.99    165720

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.97      0.97      7016
           1       0.98      0.98      0.98     13700

    accuracy                           0.98     20716
   macro avg       0.98      0.97      0.98     20716
weighted avg       0.98      0.98      0.98     20716

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.97      0.97      7015
           1       0.98      0.98      0.98     13700

    accuracy                           0.98     20715
   macro avg       0.98      0.98      0.98     20715
weighted avg       0.98      0.98      0.98     20715

              precision    recall  f1-score   support

           0       0.97      0.97      0.97      7015
           1       0.98      0.98      0.98     13700

    accuracy                           0.98     20715
   macro avg       0.98      0.98      0.98     20715
weighted avg       0.98      0.98      0.98     20715

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.95      0.85      0.90     34394
           1       0.89      0.96      0.93     44168

    accuracy                           0.92     78562
   macro avg       0.92      0.91      0.91     78562
weighted avg       0.92      0.92      0.91     78562

              precision    recall  f1-score   support

           0       0.95      0.85      0.90     34394
           1       0.89      0.96      0.93     44168

    accuracy                           0.92     78562
   macro avg       0.92      0.91      0.91     78562
weighted avg       0.92      0.92      0.91     78562

completed
