[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '65e80362'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '61cee714'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '0ccc6920'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '513d1a44'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_1.000_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_100.000_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (31796, 1276)
Number of total missing values across all columns: 63592
Data Subset Is Off
Wells held out for testing: ['J16' 'M22']
Wells to use for training, validation, and testing ['J17' 'M18' 'M19' 'J20' 'J21' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.555239).  Saving model ...
	 Train_Loss: 0.7123 Train_Acc: 59.192 Val_Loss: 0.5552  BEST VAL Loss: 0.5552  Val_Acc: 78.505

Epoch 1: Validation loss decreased (0.555239 --> 0.491678).  Saving model ...
	 Train_Loss: 0.6374 Train_Acc: 73.326 Val_Loss: 0.4917  BEST VAL Loss: 0.4917  Val_Acc: 83.953

Epoch 2: Validation loss decreased (0.491678 --> 0.444459).  Saving model ...
	 Train_Loss: 0.5941 Train_Acc: 78.083 Val_Loss: 0.4445  BEST VAL Loss: 0.4445  Val_Acc: 87.753

Epoch 3: Validation loss decreased (0.444459 --> 0.409096).  Saving model ...
	 Train_Loss: 0.5538 Train_Acc: 82.714 Val_Loss: 0.4091  BEST VAL Loss: 0.4091  Val_Acc: 88.218

Epoch 4: Validation loss decreased (0.409096 --> 0.386419).  Saving model ...
	 Train_Loss: 0.5196 Train_Acc: 85.686 Val_Loss: 0.3864  BEST VAL Loss: 0.3864  Val_Acc: 89.231

Epoch 5: Validation loss decreased (0.386419 --> 0.363492).  Saving model ...
	 Train_Loss: 0.4926 Train_Acc: 87.059 Val_Loss: 0.3635  BEST VAL Loss: 0.3635  Val_Acc: 90.160

Epoch 6: Validation loss decreased (0.363492 --> 0.346765).  Saving model ...
	 Train_Loss: 0.4708 Train_Acc: 87.376 Val_Loss: 0.3468  BEST VAL Loss: 0.3468  Val_Acc: 89.696

Epoch 7: Validation loss decreased (0.346765 --> 0.330916).  Saving model ...
	 Train_Loss: 0.4536 Train_Acc: 88.089 Val_Loss: 0.3309  BEST VAL Loss: 0.3309  Val_Acc: 92.145

Epoch 8: Validation loss decreased (0.330916 --> 0.319725).  Saving model ...
	 Train_Loss: 0.4386 Train_Acc: 88.643 Val_Loss: 0.3197  BEST VAL Loss: 0.3197  Val_Acc: 91.681

Epoch 9: Validation loss decreased (0.319725 --> 0.310861).  Saving model ...
	 Train_Loss: 0.4258 Train_Acc: 88.823 Val_Loss: 0.3109  BEST VAL Loss: 0.3109  Val_Acc: 91.554

Epoch 10: Validation loss decreased (0.310861 --> 0.302774).  Saving model ...
	 Train_Loss: 0.4152 Train_Acc: 88.976 Val_Loss: 0.3028  BEST VAL Loss: 0.3028  Val_Acc: 92.188

Epoch 11: Validation loss decreased (0.302774 --> 0.296492).  Saving model ...
	 Train_Loss: 0.4056 Train_Acc: 89.435 Val_Loss: 0.2965  BEST VAL Loss: 0.2965  Val_Acc: 91.258

Epoch 12: Validation loss decreased (0.296492 --> 0.289833).  Saving model ...
	 Train_Loss: 0.3967 Train_Acc: 89.921 Val_Loss: 0.2898  BEST VAL Loss: 0.2898  Val_Acc: 91.892

Epoch 13: Validation loss decreased (0.289833 --> 0.284142).  Saving model ...
	 Train_Loss: 0.3892 Train_Acc: 89.789 Val_Loss: 0.2841  BEST VAL Loss: 0.2841  Val_Acc: 92.103

Epoch 14: Validation loss decreased (0.284142 --> 0.278625).  Saving model ...
	 Train_Loss: 0.3831 Train_Acc: 89.366 Val_Loss: 0.2786  BEST VAL Loss: 0.2786  Val_Acc: 92.694

Epoch 15: Validation loss decreased (0.278625 --> 0.274202).  Saving model ...
	 Train_Loss: 0.3770 Train_Acc: 89.974 Val_Loss: 0.2742  BEST VAL Loss: 0.2742  Val_Acc: 92.568

Epoch 16: Validation loss decreased (0.274202 --> 0.270476).  Saving model ...
	 Train_Loss: 0.3709 Train_Acc: 90.597 Val_Loss: 0.2705  BEST VAL Loss: 0.2705  Val_Acc: 92.990

Epoch 17: Validation loss decreased (0.270476 --> 0.266985).  Saving model ...
	 Train_Loss: 0.3653 Train_Acc: 90.607 Val_Loss: 0.2670  BEST VAL Loss: 0.2670  Val_Acc: 92.483

Epoch 18: Validation loss decreased (0.266985 --> 0.263519).  Saving model ...
	 Train_Loss: 0.3606 Train_Acc: 90.380 Val_Loss: 0.2635  BEST VAL Loss: 0.2635  Val_Acc: 92.948

Epoch 19: Validation loss decreased (0.263519 --> 0.260758).  Saving model ...
	 Train_Loss: 0.3563 Train_Acc: 90.375 Val_Loss: 0.2608  BEST VAL Loss: 0.2608  Val_Acc: 92.525

Epoch 20: Validation loss decreased (0.260758 --> 0.257778).  Saving model ...
	 Train_Loss: 0.3515 Train_Acc: 90.956 Val_Loss: 0.2578  BEST VAL Loss: 0.2578  Val_Acc: 93.074

Epoch 21: Validation loss decreased (0.257778 --> 0.256660).  Saving model ...
	 Train_Loss: 0.3477 Train_Acc: 90.718 Val_Loss: 0.2567  BEST VAL Loss: 0.2567  Val_Acc: 92.272

Epoch 22: Validation loss decreased (0.256660 --> 0.254053).  Saving model ...
	 Train_Loss: 0.3443 Train_Acc: 90.465 Val_Loss: 0.2541  BEST VAL Loss: 0.2541  Val_Acc: 93.074

Epoch 23: Validation loss decreased (0.254053 --> 0.251916).  Saving model ...
	 Train_Loss: 0.3407 Train_Acc: 91.283 Val_Loss: 0.2519  BEST VAL Loss: 0.2519  Val_Acc: 92.525

Epoch 24: Validation loss decreased (0.251916 --> 0.249970).  Saving model ...
	 Train_Loss: 0.3374 Train_Acc: 90.998 Val_Loss: 0.2500  BEST VAL Loss: 0.2500  Val_Acc: 92.399

Epoch 25: Validation loss decreased (0.249970 --> 0.248366).  Saving model ...
	 Train_Loss: 0.3345 Train_Acc: 90.919 Val_Loss: 0.2484  BEST VAL Loss: 0.2484  Val_Acc: 92.272

Epoch 26: Validation loss decreased (0.248366 --> 0.247557).  Saving model ...
	 Train_Loss: 0.3316 Train_Acc: 90.977 Val_Loss: 0.2476  BEST VAL Loss: 0.2476  Val_Acc: 92.483

Epoch 27: Validation loss decreased (0.247557 --> 0.245869).  Saving model ...
	 Train_Loss: 0.3292 Train_Acc: 90.676 Val_Loss: 0.2459  BEST VAL Loss: 0.2459  Val_Acc: 92.399

Epoch 28: Validation loss decreased (0.245869 --> 0.244321).  Saving model ...
	 Train_Loss: 0.3269 Train_Acc: 90.829 Val_Loss: 0.2443  BEST VAL Loss: 0.2443  Val_Acc: 92.821

Epoch 29: Validation loss decreased (0.244321 --> 0.243144).  Saving model ...
	 Train_Loss: 0.3243 Train_Acc: 91.600 Val_Loss: 0.2431  BEST VAL Loss: 0.2431  Val_Acc: 92.736

Epoch 30: Validation loss decreased (0.243144 --> 0.241869).  Saving model ...
	 Train_Loss: 0.3218 Train_Acc: 91.452 Val_Loss: 0.2419  BEST VAL Loss: 0.2419  Val_Acc: 92.399

Epoch 31: Validation loss decreased (0.241869 --> 0.241000).  Saving model ...
	 Train_Loss: 0.3197 Train_Acc: 91.399 Val_Loss: 0.2410  BEST VAL Loss: 0.2410  Val_Acc: 91.850

Epoch 32: Validation loss decreased (0.241000 --> 0.239681).  Saving model ...
	 Train_Loss: 0.3175 Train_Acc: 91.447 Val_Loss: 0.2397  BEST VAL Loss: 0.2397  Val_Acc: 91.427

Epoch 33: Validation loss decreased (0.239681 --> 0.238788).  Saving model ...
	 Train_Loss: 0.3153 Train_Acc: 91.790 Val_Loss: 0.2388  BEST VAL Loss: 0.2388  Val_Acc: 92.568

Epoch 34: Validation loss decreased (0.238788 --> 0.237916).  Saving model ...
	 Train_Loss: 0.3133 Train_Acc: 91.610 Val_Loss: 0.2379  BEST VAL Loss: 0.2379  Val_Acc: 92.441

Epoch 35: Validation loss decreased (0.237916 --> 0.237110).  Saving model ...
	 Train_Loss: 0.3113 Train_Acc: 91.647 Val_Loss: 0.2371  BEST VAL Loss: 0.2371  Val_Acc: 92.568

Epoch 36: Validation loss decreased (0.237110 --> 0.236293).  Saving model ...
	 Train_Loss: 0.3095 Train_Acc: 91.711 Val_Loss: 0.2363  BEST VAL Loss: 0.2363  Val_Acc: 92.399

Epoch 37: Validation loss decreased (0.236293 --> 0.235612).  Saving model ...
	 Train_Loss: 0.3075 Train_Acc: 92.064 Val_Loss: 0.2356  BEST VAL Loss: 0.2356  Val_Acc: 92.483

Epoch 38: Validation loss decreased (0.235612 --> 0.235154).  Saving model ...
	 Train_Loss: 0.3057 Train_Acc: 91.832 Val_Loss: 0.2352  BEST VAL Loss: 0.2352  Val_Acc: 91.470

Epoch 39: Validation loss decreased (0.235154 --> 0.234657).  Saving model ...
	 Train_Loss: 0.3038 Train_Acc: 92.080 Val_Loss: 0.2347  BEST VAL Loss: 0.2347  Val_Acc: 92.230

Epoch 40: Validation loss decreased (0.234657 --> 0.234167).  Saving model ...
	 Train_Loss: 0.3020 Train_Acc: 92.122 Val_Loss: 0.2342  BEST VAL Loss: 0.2342  Val_Acc: 91.807

Epoch 41: Validation loss decreased (0.234167 --> 0.233401).  Saving model ...
	 Train_Loss: 0.3005 Train_Acc: 91.711 Val_Loss: 0.2334  BEST VAL Loss: 0.2334  Val_Acc: 92.525

Epoch 42: Validation loss decreased (0.233401 --> 0.232656).  Saving model ...
	 Train_Loss: 0.2989 Train_Acc: 92.091 Val_Loss: 0.2327  BEST VAL Loss: 0.2327  Val_Acc: 91.934

Epoch 43: Validation loss decreased (0.232656 --> 0.231923).  Saving model ...
	 Train_Loss: 0.2978 Train_Acc: 91.510 Val_Loss: 0.2319  BEST VAL Loss: 0.2319  Val_Acc: 93.243

Epoch 44: Validation loss decreased (0.231923 --> 0.230917).  Saving model ...
	 Train_Loss: 0.2963 Train_Acc: 92.091 Val_Loss: 0.2309  BEST VAL Loss: 0.2309  Val_Acc: 93.074

Epoch 45: Validation loss decreased (0.230917 --> 0.230585).  Saving model ...
	 Train_Loss: 0.2948 Train_Acc: 92.218 Val_Loss: 0.2306  BEST VAL Loss: 0.2306  Val_Acc: 93.285

Epoch 46: Validation loss decreased (0.230585 --> 0.230353).  Saving model ...
	 Train_Loss: 0.2933 Train_Acc: 92.392 Val_Loss: 0.2304  BEST VAL Loss: 0.2304  Val_Acc: 92.736

Epoch 47: Validation loss decreased (0.230353 --> 0.230011).  Saving model ...
	 Train_Loss: 0.2920 Train_Acc: 92.228 Val_Loss: 0.2300  BEST VAL Loss: 0.2300  Val_Acc: 92.694

Epoch 48: Validation loss decreased (0.230011 --> 0.229530).  Saving model ...
	 Train_Loss: 0.2906 Train_Acc: 92.117 Val_Loss: 0.2295  BEST VAL Loss: 0.2295  Val_Acc: 92.694

Epoch 49: Validation loss decreased (0.229530 --> 0.229125).  Saving model ...
	 Train_Loss: 0.2893 Train_Acc: 92.286 Val_Loss: 0.2291  BEST VAL Loss: 0.2291  Val_Acc: 93.074

Epoch 50: Validation loss decreased (0.229125 --> 0.228778).  Saving model ...
	 Train_Loss: 0.2881 Train_Acc: 92.281 Val_Loss: 0.2288  BEST VAL Loss: 0.2288  Val_Acc: 92.736

Epoch 51: Validation loss decreased (0.228778 --> 0.228250).  Saving model ...
	 Train_Loss: 0.2869 Train_Acc: 92.439 Val_Loss: 0.2283  BEST VAL Loss: 0.2283  Val_Acc: 92.779

Epoch 52: Validation loss decreased (0.228250 --> 0.227946).  Saving model ...
	 Train_Loss: 0.2857 Train_Acc: 92.365 Val_Loss: 0.2279  BEST VAL Loss: 0.2279  Val_Acc: 92.736

Epoch 53: Validation loss decreased (0.227946 --> 0.227779).  Saving model ...
	 Train_Loss: 0.2846 Train_Acc: 92.249 Val_Loss: 0.2278  BEST VAL Loss: 0.2278  Val_Acc: 92.863

Epoch 54: Validation loss decreased (0.227779 --> 0.227655).  Saving model ...
	 Train_Loss: 0.2835 Train_Acc: 92.059 Val_Loss: 0.2277  BEST VAL Loss: 0.2277  Val_Acc: 93.243

Epoch 55: Validation loss decreased (0.227655 --> 0.227223).  Saving model ...
	 Train_Loss: 0.2825 Train_Acc: 92.049 Val_Loss: 0.2272  BEST VAL Loss: 0.2272  Val_Acc: 93.412

Epoch 56: Validation loss decreased (0.227223 --> 0.226867).  Saving model ...
	 Train_Loss: 0.2815 Train_Acc: 92.445 Val_Loss: 0.2269  BEST VAL Loss: 0.2269  Val_Acc: 92.610

Epoch 57: Validation loss decreased (0.226867 --> 0.226793).  Saving model ...
	 Train_Loss: 0.2804 Train_Acc: 92.640 Val_Loss: 0.2268  BEST VAL Loss: 0.2268  Val_Acc: 92.652

Epoch 58: Validation loss decreased (0.226793 --> 0.226719).  Saving model ...
	 Train_Loss: 0.2795 Train_Acc: 92.270 Val_Loss: 0.2267  BEST VAL Loss: 0.2267  Val_Acc: 92.568

Epoch 59: Validation loss decreased (0.226719 --> 0.226642).  Saving model ...
	 Train_Loss: 0.2786 Train_Acc: 92.181 Val_Loss: 0.2266  BEST VAL Loss: 0.2266  Val_Acc: 92.356

Epoch 60: Validation loss decreased (0.226642 --> 0.226458).  Saving model ...
	 Train_Loss: 0.2776 Train_Acc: 92.614 Val_Loss: 0.2265  BEST VAL Loss: 0.2265  Val_Acc: 92.736

Epoch 61: Validation loss decreased (0.226458 --> 0.226235).  Saving model ...
	 Train_Loss: 0.2768 Train_Acc: 92.376 Val_Loss: 0.2262  BEST VAL Loss: 0.2262  Val_Acc: 92.905

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.2760 Train_Acc: 92.476 Val_Loss: 0.2263  BEST VAL Loss: 0.2262  Val_Acc: 92.736

Epoch 63: Validation loss decreased (0.226235 --> 0.226102).  Saving model ...
	 Train_Loss: 0.2750 Train_Acc: 92.893 Val_Loss: 0.2261  BEST VAL Loss: 0.2261  Val_Acc: 93.032

Epoch 64: Validation loss decreased (0.226102 --> 0.225984).  Saving model ...
	 Train_Loss: 0.2741 Train_Acc: 92.677 Val_Loss: 0.2260  BEST VAL Loss: 0.2260  Val_Acc: 92.188

Epoch 65: Validation loss decreased (0.225984 --> 0.225707).  Saving model ...
	 Train_Loss: 0.2733 Train_Acc: 92.577 Val_Loss: 0.2257  BEST VAL Loss: 0.2257  Val_Acc: 92.863

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.2725 Train_Acc: 92.202 Val_Loss: 0.2259  BEST VAL Loss: 0.2257  Val_Acc: 93.243

Epoch 67: Validation loss decreased (0.225707 --> 0.225654).  Saving model ...
	 Train_Loss: 0.2718 Train_Acc: 92.582 Val_Loss: 0.2257  BEST VAL Loss: 0.2257  Val_Acc: 92.610

Epoch 68: Validation loss decreased (0.225654 --> 0.225459).  Saving model ...
	 Train_Loss: 0.2710 Train_Acc: 92.714 Val_Loss: 0.2255  BEST VAL Loss: 0.2255  Val_Acc: 93.074

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.2702 Train_Acc: 92.962 Val_Loss: 0.2256  BEST VAL Loss: 0.2255  Val_Acc: 93.285

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.2695 Train_Acc: 92.788 Val_Loss: 0.2259  BEST VAL Loss: 0.2255  Val_Acc: 91.470

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.2687 Train_Acc: 92.941 Val_Loss: 0.2257  BEST VAL Loss: 0.2255  Val_Acc: 92.399

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.2679 Train_Acc: 92.914 Val_Loss: 0.2259  BEST VAL Loss: 0.2255  Val_Acc: 92.905

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.2672 Train_Acc: 92.951 Val_Loss: 0.2256  BEST VAL Loss: 0.2255  Val_Acc: 92.779

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.2665 Train_Acc: 92.709 Val_Loss: 0.2256  BEST VAL Loss: 0.2255  Val_Acc: 92.399

Epoch 75: Validation loss decreased (0.225459 --> 0.225249).  Saving model ...
	 Train_Loss: 0.2659 Train_Acc: 92.603 Val_Loss: 0.2252  BEST VAL Loss: 0.2252  Val_Acc: 93.117

Epoch 76: Validation loss decreased (0.225249 --> 0.225213).  Saving model ...
	 Train_Loss: 0.2652 Train_Acc: 92.846 Val_Loss: 0.2252  BEST VAL Loss: 0.2252  Val_Acc: 92.441

Epoch 77: Validation loss decreased (0.225213 --> 0.225039).  Saving model ...
	 Train_Loss: 0.2645 Train_Acc: 93.221 Val_Loss: 0.2250  BEST VAL Loss: 0.2250  Val_Acc: 92.863

Epoch 78: Validation loss decreased (0.225039 --> 0.224984).  Saving model ...
	 Train_Loss: 0.2637 Train_Acc: 92.988 Val_Loss: 0.2250  BEST VAL Loss: 0.2250  Val_Acc: 91.850

Epoch 79: Validation loss decreased (0.224984 --> 0.224969).  Saving model ...
	 Train_Loss: 0.2631 Train_Acc: 92.999 Val_Loss: 0.2250  BEST VAL Loss: 0.2250  Val_Acc: 92.652

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.2624 Train_Acc: 93.120 Val_Loss: 0.2251  BEST VAL Loss: 0.2250  Val_Acc: 91.512

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.2617 Train_Acc: 92.735 Val_Loss: 0.2250  BEST VAL Loss: 0.2250  Val_Acc: 92.441

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.2611 Train_Acc: 93.194 Val_Loss: 0.2250  BEST VAL Loss: 0.2250  Val_Acc: 92.652

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.2604 Train_Acc: 93.200 Val_Loss: 0.2251  BEST VAL Loss: 0.2250  Val_Acc: 92.441

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.2599 Train_Acc: 93.141 Val_Loss: 0.2250  BEST VAL Loss: 0.2250  Val_Acc: 92.230

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.2593 Train_Acc: 93.010 Val_Loss: 0.2250  BEST VAL Loss: 0.2250  Val_Acc: 92.568

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.2587 Train_Acc: 93.178 Val_Loss: 0.2250  BEST VAL Loss: 0.2250  Val_Acc: 92.736

Epoch 87: Validation loss decreased (0.224969 --> 0.224854).  Saving model ...
	 Train_Loss: 0.2582 Train_Acc: 92.772 Val_Loss: 0.2249  BEST VAL Loss: 0.2249  Val_Acc: 93.074

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.2577 Train_Acc: 92.999 Val_Loss: 0.2249  BEST VAL Loss: 0.2249  Val_Acc: 93.074

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.2571 Train_Acc: 92.941 Val_Loss: 0.2250  BEST VAL Loss: 0.2249  Val_Acc: 92.948

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.2566 Train_Acc: 92.936 Val_Loss: 0.2249  BEST VAL Loss: 0.2249  Val_Acc: 93.032

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.2562 Train_Acc: 92.603 Val_Loss: 0.2250  BEST VAL Loss: 0.2249  Val_Acc: 92.948

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.2557 Train_Acc: 92.746 Val_Loss: 0.2249  BEST VAL Loss: 0.2249  Val_Acc: 93.285

Epoch 93: Validation loss decreased (0.224854 --> 0.224567).  Saving model ...
	 Train_Loss: 0.2553 Train_Acc: 92.973 Val_Loss: 0.2246  BEST VAL Loss: 0.2246  Val_Acc: 93.201

Epoch 94: Validation loss decreased (0.224567 --> 0.224415).  Saving model ...
	 Train_Loss: 0.2549 Train_Acc: 92.793 Val_Loss: 0.2244  BEST VAL Loss: 0.2244  Val_Acc: 92.610

Epoch 95: Validation loss decreased (0.224415 --> 0.224353).  Saving model ...
	 Train_Loss: 0.2544 Train_Acc: 93.046 Val_Loss: 0.2244  BEST VAL Loss: 0.2244  Val_Acc: 92.694

Epoch 96: Validation loss decreased (0.224353 --> 0.224177).  Saving model ...
	 Train_Loss: 0.2539 Train_Acc: 92.851 Val_Loss: 0.2242  BEST VAL Loss: 0.2242  Val_Acc: 93.159

Epoch 97: Validation loss decreased (0.224177 --> 0.224160).  Saving model ...
	 Train_Loss: 0.2535 Train_Acc: 92.909 Val_Loss: 0.2242  BEST VAL Loss: 0.2242  Val_Acc: 92.905

Epoch 98: Validation loss decreased (0.224160 --> 0.224026).  Saving model ...
	 Train_Loss: 0.2529 Train_Acc: 93.532 Val_Loss: 0.2240  BEST VAL Loss: 0.2240  Val_Acc: 92.061

Epoch 99: Validation loss decreased (0.224026 --> 0.223944).  Saving model ...
	 Train_Loss: 0.2525 Train_Acc: 92.793 Val_Loss: 0.2239  BEST VAL Loss: 0.2239  Val_Acc: 92.948

Flagellin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.51      0.50      9434
           1       0.50      0.49      0.50      9506

    accuracy                           0.50     18940
   macro avg       0.50      0.50      0.50     18940
weighted avg       0.50      0.50      0.50     18940

Flagellin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.53      0.52      1179
           1       0.51      0.49      0.50      1189

    accuracy                           0.51      2368
   macro avg       0.51      0.51      0.51      2368
weighted avg       0.51      0.51      0.51      2368

Flagellin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.50      0.49      1179
           1       0.49      0.48      0.49      1189

    accuracy                           0.49      2368
   macro avg       0.49      0.49      0.49      2368
weighted avg       0.49      0.49      0.49      2368

              precision    recall  f1-score   support

           0       0.49      0.50      0.49      1179
           1       0.49      0.48      0.49      1189

    accuracy                           0.49      2368
   macro avg       0.49      0.49      0.49      2368
weighted avg       0.49      0.49      0.49      2368

Flagellin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.51      0.50      4017
           1       0.50      0.49      0.49      4103

    accuracy                           0.50      8120
   macro avg       0.50      0.50      0.50      8120
weighted avg       0.50      0.50      0.50      8120

              precision    recall  f1-score   support

           0       0.49      0.51      0.50      4017
           1       0.50      0.49      0.49      4103

    accuracy                           0.50      8120
   macro avg       0.50      0.50      0.50      8120
weighted avg       0.50      0.50      0.50      8120

completed
