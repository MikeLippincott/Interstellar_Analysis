[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'aa06f3a4'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '3ab7b7a7'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '72c73904'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '728ee6df'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_0.010_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_0.010_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (238995, 1270)
Number of total missing values across all columns: 477990
Data Subset Is Off
Wells held out for testing: ['B09' 'L10']
Wells to use for training, validation, and testing ['B02' 'B03' 'B08' 'L05' 'L11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.506336).  Saving model ...
	 Train_Loss: 0.5985 Train_Acc: 64.873 Val_Loss: 0.5063  BEST VAL Loss: 0.5063  Val_Acc: 75.417

Epoch 1: Validation loss decreased (0.506336 --> 0.483543).  Saving model ...
	 Train_Loss: 0.5544 Train_Acc: 75.087 Val_Loss: 0.4835  BEST VAL Loss: 0.4835  Val_Acc: 78.138

Epoch 2: Validation loss decreased (0.483543 --> 0.468550).  Saving model ...
	 Train_Loss: 0.5291 Train_Acc: 77.186 Val_Loss: 0.4686  BEST VAL Loss: 0.4686  Val_Acc: 79.163

Epoch 3: Validation loss decreased (0.468550 --> 0.457049).  Saving model ...
	 Train_Loss: 0.5115 Train_Acc: 78.289 Val_Loss: 0.4570  BEST VAL Loss: 0.4570  Val_Acc: 80.141

Epoch 4: Validation loss decreased (0.457049 --> 0.449772).  Saving model ...
	 Train_Loss: 0.4987 Train_Acc: 78.938 Val_Loss: 0.4498  BEST VAL Loss: 0.4498  Val_Acc: 80.483

Epoch 5: Validation loss decreased (0.449772 --> 0.442904).  Saving model ...
	 Train_Loss: 0.4890 Train_Acc: 79.433 Val_Loss: 0.4429  BEST VAL Loss: 0.4429  Val_Acc: 80.972

Epoch 6: Validation loss decreased (0.442904 --> 0.437158).  Saving model ...
	 Train_Loss: 0.4808 Train_Acc: 79.834 Val_Loss: 0.4372  BEST VAL Loss: 0.4372  Val_Acc: 81.449

Epoch 7: Validation loss decreased (0.437158 --> 0.432601).  Saving model ...
	 Train_Loss: 0.4740 Train_Acc: 80.105 Val_Loss: 0.4326  BEST VAL Loss: 0.4326  Val_Acc: 81.390

Epoch 8: Validation loss decreased (0.432601 --> 0.428741).  Saving model ...
	 Train_Loss: 0.4680 Train_Acc: 80.564 Val_Loss: 0.4287  BEST VAL Loss: 0.4287  Val_Acc: 81.626

Epoch 9: Validation loss decreased (0.428741 --> 0.424823).  Saving model ...
	 Train_Loss: 0.4629 Train_Acc: 80.523 Val_Loss: 0.4248  BEST VAL Loss: 0.4248  Val_Acc: 81.797

Epoch 10: Validation loss decreased (0.424823 --> 0.421568).  Saving model ...
	 Train_Loss: 0.4585 Train_Acc: 80.799 Val_Loss: 0.4216  BEST VAL Loss: 0.4216  Val_Acc: 81.820

Epoch 11: Validation loss decreased (0.421568 --> 0.418895).  Saving model ...
	 Train_Loss: 0.4545 Train_Acc: 80.914 Val_Loss: 0.4189  BEST VAL Loss: 0.4189  Val_Acc: 82.044

Epoch 12: Validation loss decreased (0.418895 --> 0.416134).  Saving model ...
	 Train_Loss: 0.4510 Train_Acc: 80.992 Val_Loss: 0.4161  BEST VAL Loss: 0.4161  Val_Acc: 82.080

Epoch 13: Validation loss decreased (0.416134 --> 0.413781).  Saving model ...
	 Train_Loss: 0.4478 Train_Acc: 81.209 Val_Loss: 0.4138  BEST VAL Loss: 0.4138  Val_Acc: 82.115

Epoch 14: Validation loss decreased (0.413781 --> 0.411954).  Saving model ...
	 Train_Loss: 0.4449 Train_Acc: 81.368 Val_Loss: 0.4120  BEST VAL Loss: 0.4120  Val_Acc: 82.032

Epoch 15: Validation loss decreased (0.411954 --> 0.410053).  Saving model ...
	 Train_Loss: 0.4422 Train_Acc: 81.426 Val_Loss: 0.4101  BEST VAL Loss: 0.4101  Val_Acc: 82.362

Epoch 16: Validation loss decreased (0.410053 --> 0.408220).  Saving model ...
	 Train_Loss: 0.4397 Train_Acc: 81.572 Val_Loss: 0.4082  BEST VAL Loss: 0.4082  Val_Acc: 82.380

Epoch 17: Validation loss decreased (0.408220 --> 0.406634).  Saving model ...
	 Train_Loss: 0.4373 Train_Acc: 81.720 Val_Loss: 0.4066  BEST VAL Loss: 0.4066  Val_Acc: 82.421

Epoch 18: Validation loss decreased (0.406634 --> 0.405115).  Saving model ...
	 Train_Loss: 0.4351 Train_Acc: 81.768 Val_Loss: 0.4051  BEST VAL Loss: 0.4051  Val_Acc: 82.297

Epoch 19: Validation loss decreased (0.405115 --> 0.403648).  Saving model ...
	 Train_Loss: 0.4331 Train_Acc: 81.797 Val_Loss: 0.4036  BEST VAL Loss: 0.4036  Val_Acc: 82.557

Epoch 20: Validation loss decreased (0.403648 --> 0.402125).  Saving model ...
	 Train_Loss: 0.4312 Train_Acc: 81.814 Val_Loss: 0.4021  BEST VAL Loss: 0.4021  Val_Acc: 82.651

Epoch 21: Validation loss decreased (0.402125 --> 0.400811).  Saving model ...
	 Train_Loss: 0.4294 Train_Acc: 81.903 Val_Loss: 0.4008  BEST VAL Loss: 0.4008  Val_Acc: 82.680

Epoch 22: Validation loss decreased (0.400811 --> 0.399508).  Saving model ...
	 Train_Loss: 0.4278 Train_Acc: 81.954 Val_Loss: 0.3995  BEST VAL Loss: 0.3995  Val_Acc: 82.993

Epoch 23: Validation loss decreased (0.399508 --> 0.398464).  Saving model ...
	 Train_Loss: 0.4262 Train_Acc: 82.048 Val_Loss: 0.3985  BEST VAL Loss: 0.3985  Val_Acc: 82.686

Epoch 24: Validation loss decreased (0.398464 --> 0.397314).  Saving model ...
	 Train_Loss: 0.4247 Train_Acc: 82.056 Val_Loss: 0.3973  BEST VAL Loss: 0.3973  Val_Acc: 82.892

Epoch 25: Validation loss decreased (0.397314 --> 0.396264).  Saving model ...
	 Train_Loss: 0.4233 Train_Acc: 82.060 Val_Loss: 0.3963  BEST VAL Loss: 0.3963  Val_Acc: 82.769

Epoch 26: Validation loss decreased (0.396264 --> 0.395312).  Saving model ...
	 Train_Loss: 0.4220 Train_Acc: 82.173 Val_Loss: 0.3953  BEST VAL Loss: 0.3953  Val_Acc: 82.716

Epoch 27: Validation loss decreased (0.395312 --> 0.394479).  Saving model ...
	 Train_Loss: 0.4207 Train_Acc: 82.254 Val_Loss: 0.3945  BEST VAL Loss: 0.3945  Val_Acc: 82.663

Epoch 28: Validation loss decreased (0.394479 --> 0.393581).  Saving model ...
	 Train_Loss: 0.4194 Train_Acc: 82.285 Val_Loss: 0.3936  BEST VAL Loss: 0.3936  Val_Acc: 82.863

Epoch 29: Validation loss decreased (0.393581 --> 0.392847).  Saving model ...
	 Train_Loss: 0.4183 Train_Acc: 82.277 Val_Loss: 0.3928  BEST VAL Loss: 0.3928  Val_Acc: 82.845

Epoch 30: Validation loss decreased (0.392847 --> 0.392094).  Saving model ...
	 Train_Loss: 0.4171 Train_Acc: 82.329 Val_Loss: 0.3921  BEST VAL Loss: 0.3921  Val_Acc: 83.128

Epoch 31: Validation loss decreased (0.392094 --> 0.391428).  Saving model ...
	 Train_Loss: 0.4161 Train_Acc: 82.315 Val_Loss: 0.3914  BEST VAL Loss: 0.3914  Val_Acc: 82.798

Epoch 32: Validation loss decreased (0.391428 --> 0.390720).  Saving model ...
	 Train_Loss: 0.4151 Train_Acc: 82.425 Val_Loss: 0.3907  BEST VAL Loss: 0.3907  Val_Acc: 82.875

Epoch 33: Validation loss decreased (0.390720 --> 0.390096).  Saving model ...
	 Train_Loss: 0.4141 Train_Acc: 82.462 Val_Loss: 0.3901  BEST VAL Loss: 0.3901  Val_Acc: 82.680

Epoch 34: Validation loss decreased (0.390096 --> 0.389511).  Saving model ...
	 Train_Loss: 0.4131 Train_Acc: 82.565 Val_Loss: 0.3895  BEST VAL Loss: 0.3895  Val_Acc: 82.804

Epoch 35: Validation loss decreased (0.389511 --> 0.389010).  Saving model ...
	 Train_Loss: 0.4122 Train_Acc: 82.414 Val_Loss: 0.3890  BEST VAL Loss: 0.3890  Val_Acc: 83.040

Epoch 36: Validation loss decreased (0.389010 --> 0.388391).  Saving model ...
	 Train_Loss: 0.4113 Train_Acc: 82.537 Val_Loss: 0.3884  BEST VAL Loss: 0.3884  Val_Acc: 83.128

Epoch 37: Validation loss decreased (0.388391 --> 0.387885).  Saving model ...
	 Train_Loss: 0.4105 Train_Acc: 82.612 Val_Loss: 0.3879  BEST VAL Loss: 0.3879  Val_Acc: 82.763

Epoch 38: Validation loss decreased (0.387885 --> 0.387196).  Saving model ...
	 Train_Loss: 0.4097 Train_Acc: 82.635 Val_Loss: 0.3872  BEST VAL Loss: 0.3872  Val_Acc: 83.046

Epoch 39: Validation loss decreased (0.387196 --> 0.386711).  Saving model ...
	 Train_Loss: 0.4089 Train_Acc: 82.579 Val_Loss: 0.3867  BEST VAL Loss: 0.3867  Val_Acc: 82.999

Epoch 40: Validation loss decreased (0.386711 --> 0.386186).  Saving model ...
	 Train_Loss: 0.4081 Train_Acc: 82.598 Val_Loss: 0.3862  BEST VAL Loss: 0.3862  Val_Acc: 82.975

Epoch 41: Validation loss decreased (0.386186 --> 0.385667).  Saving model ...
	 Train_Loss: 0.4073 Train_Acc: 82.744 Val_Loss: 0.3857  BEST VAL Loss: 0.3857  Val_Acc: 83.128

Epoch 42: Validation loss decreased (0.385667 --> 0.385171).  Saving model ...
	 Train_Loss: 0.4066 Train_Acc: 82.707 Val_Loss: 0.3852  BEST VAL Loss: 0.3852  Val_Acc: 83.081

Epoch 43: Validation loss decreased (0.385171 --> 0.384650).  Saving model ...
	 Train_Loss: 0.4059 Train_Acc: 82.598 Val_Loss: 0.3847  BEST VAL Loss: 0.3847  Val_Acc: 83.387

Epoch 44: Validation loss decreased (0.384650 --> 0.384118).  Saving model ...
	 Train_Loss: 0.4053 Train_Acc: 82.654 Val_Loss: 0.3841  BEST VAL Loss: 0.3841  Val_Acc: 83.275

Epoch 45: Validation loss decreased (0.384118 --> 0.383583).  Saving model ...
	 Train_Loss: 0.4046 Train_Acc: 82.756 Val_Loss: 0.3836  BEST VAL Loss: 0.3836  Val_Acc: 83.311

Epoch 46: Validation loss decreased (0.383583 --> 0.383146).  Saving model ...
	 Train_Loss: 0.4040 Train_Acc: 82.760 Val_Loss: 0.3831  BEST VAL Loss: 0.3831  Val_Acc: 83.270

Epoch 47: Validation loss decreased (0.383146 --> 0.382680).  Saving model ...
	 Train_Loss: 0.4034 Train_Acc: 82.769 Val_Loss: 0.3827  BEST VAL Loss: 0.3827  Val_Acc: 83.393

Epoch 48: Validation loss decreased (0.382680 --> 0.382215).  Saving model ...
	 Train_Loss: 0.4027 Train_Acc: 82.945 Val_Loss: 0.3822  BEST VAL Loss: 0.3822  Val_Acc: 83.270

Epoch 49: Validation loss decreased (0.382215 --> 0.381702).  Saving model ...
	 Train_Loss: 0.4022 Train_Acc: 82.727 Val_Loss: 0.3817  BEST VAL Loss: 0.3817  Val_Acc: 83.287

Epoch 50: Validation loss decreased (0.381702 --> 0.381289).  Saving model ...
	 Train_Loss: 0.4016 Train_Acc: 82.894 Val_Loss: 0.3813  BEST VAL Loss: 0.3813  Val_Acc: 83.222

Epoch 51: Validation loss decreased (0.381289 --> 0.380850).  Saving model ...
	 Train_Loss: 0.4010 Train_Acc: 83.074 Val_Loss: 0.3808  BEST VAL Loss: 0.3808  Val_Acc: 83.487

Epoch 52: Validation loss decreased (0.380850 --> 0.380457).  Saving model ...
	 Train_Loss: 0.4005 Train_Acc: 82.877 Val_Loss: 0.3805  BEST VAL Loss: 0.3805  Val_Acc: 83.364

Epoch 53: Validation loss decreased (0.380457 --> 0.380027).  Saving model ...
	 Train_Loss: 0.3999 Train_Acc: 82.998 Val_Loss: 0.3800  BEST VAL Loss: 0.3800  Val_Acc: 83.328

Epoch 54: Validation loss decreased (0.380027 --> 0.379626).  Saving model ...
	 Train_Loss: 0.3994 Train_Acc: 82.939 Val_Loss: 0.3796  BEST VAL Loss: 0.3796  Val_Acc: 83.287

Epoch 55: Validation loss decreased (0.379626 --> 0.379251).  Saving model ...
	 Train_Loss: 0.3989 Train_Acc: 82.911 Val_Loss: 0.3793  BEST VAL Loss: 0.3793  Val_Acc: 83.364

Epoch 56: Validation loss decreased (0.379251 --> 0.378941).  Saving model ...
	 Train_Loss: 0.3984 Train_Acc: 83.006 Val_Loss: 0.3789  BEST VAL Loss: 0.3789  Val_Acc: 83.187

Epoch 57: Validation loss decreased (0.378941 --> 0.378602).  Saving model ...
	 Train_Loss: 0.3980 Train_Acc: 82.989 Val_Loss: 0.3786  BEST VAL Loss: 0.3786  Val_Acc: 83.423

Epoch 58: Validation loss decreased (0.378602 --> 0.378251).  Saving model ...
	 Train_Loss: 0.3975 Train_Acc: 82.979 Val_Loss: 0.3783  BEST VAL Loss: 0.3783  Val_Acc: 83.281

Epoch 59: Validation loss decreased (0.378251 --> 0.377957).  Saving model ...
	 Train_Loss: 0.3970 Train_Acc: 82.984 Val_Loss: 0.3780  BEST VAL Loss: 0.3780  Val_Acc: 83.305

Epoch 60: Validation loss decreased (0.377957 --> 0.377713).  Saving model ...
	 Train_Loss: 0.3966 Train_Acc: 83.066 Val_Loss: 0.3777  BEST VAL Loss: 0.3777  Val_Acc: 83.264

Epoch 61: Validation loss decreased (0.377713 --> 0.377322).  Saving model ...
	 Train_Loss: 0.3961 Train_Acc: 83.043 Val_Loss: 0.3773  BEST VAL Loss: 0.3773  Val_Acc: 83.758

Epoch 62: Validation loss decreased (0.377322 --> 0.376952).  Saving model ...
	 Train_Loss: 0.3957 Train_Acc: 83.082 Val_Loss: 0.3770  BEST VAL Loss: 0.3770  Val_Acc: 83.576

Epoch 63: Validation loss decreased (0.376952 --> 0.376626).  Saving model ...
	 Train_Loss: 0.3953 Train_Acc: 83.087 Val_Loss: 0.3766  BEST VAL Loss: 0.3766  Val_Acc: 83.476

Epoch 64: Validation loss decreased (0.376626 --> 0.376305).  Saving model ...
	 Train_Loss: 0.3948 Train_Acc: 83.129 Val_Loss: 0.3763  BEST VAL Loss: 0.3763  Val_Acc: 83.452

Epoch 65: Validation loss decreased (0.376305 --> 0.375958).  Saving model ...
	 Train_Loss: 0.3944 Train_Acc: 83.137 Val_Loss: 0.3760  BEST VAL Loss: 0.3760  Val_Acc: 83.505

Epoch 66: Validation loss decreased (0.375958 --> 0.375640).  Saving model ...
	 Train_Loss: 0.3940 Train_Acc: 83.117 Val_Loss: 0.3756  BEST VAL Loss: 0.3756  Val_Acc: 83.753

Epoch 67: Validation loss decreased (0.375640 --> 0.375364).  Saving model ...
	 Train_Loss: 0.3936 Train_Acc: 83.212 Val_Loss: 0.3754  BEST VAL Loss: 0.3754  Val_Acc: 83.499

Epoch 68: Validation loss decreased (0.375364 --> 0.375076).  Saving model ...
	 Train_Loss: 0.3932 Train_Acc: 83.111 Val_Loss: 0.3751  BEST VAL Loss: 0.3751  Val_Acc: 83.676

Epoch 69: Validation loss decreased (0.375076 --> 0.374762).  Saving model ...
	 Train_Loss: 0.3928 Train_Acc: 83.316 Val_Loss: 0.3748  BEST VAL Loss: 0.3748  Val_Acc: 83.794

Epoch 70: Validation loss decreased (0.374762 --> 0.374493).  Saving model ...
	 Train_Loss: 0.3924 Train_Acc: 83.329 Val_Loss: 0.3745  BEST VAL Loss: 0.3745  Val_Acc: 83.676

Epoch 71: Validation loss decreased (0.374493 --> 0.374183).  Saving model ...
	 Train_Loss: 0.3921 Train_Acc: 83.184 Val_Loss: 0.3742  BEST VAL Loss: 0.3742  Val_Acc: 83.806

Epoch 72: Validation loss decreased (0.374183 --> 0.373885).  Saving model ...
	 Train_Loss: 0.3917 Train_Acc: 83.264 Val_Loss: 0.3739  BEST VAL Loss: 0.3739  Val_Acc: 84.053

Epoch 73: Validation loss decreased (0.373885 --> 0.373567).  Saving model ...
	 Train_Loss: 0.3913 Train_Acc: 83.291 Val_Loss: 0.3736  BEST VAL Loss: 0.3736  Val_Acc: 84.024

Epoch 74: Validation loss decreased (0.373567 --> 0.373325).  Saving model ...
	 Train_Loss: 0.3909 Train_Acc: 83.322 Val_Loss: 0.3733  BEST VAL Loss: 0.3733  Val_Acc: 83.700

Epoch 75: Validation loss decreased (0.373325 --> 0.373114).  Saving model ...
	 Train_Loss: 0.3906 Train_Acc: 83.228 Val_Loss: 0.3731  BEST VAL Loss: 0.3731  Val_Acc: 83.700

Epoch 76: Validation loss decreased (0.373114 --> 0.372860).  Saving model ...
	 Train_Loss: 0.3903 Train_Acc: 83.237 Val_Loss: 0.3729  BEST VAL Loss: 0.3729  Val_Acc: 83.882

Epoch 77: Validation loss decreased (0.372860 --> 0.372557).  Saving model ...
	 Train_Loss: 0.3899 Train_Acc: 83.277 Val_Loss: 0.3726  BEST VAL Loss: 0.3726  Val_Acc: 83.723

Epoch 78: Validation loss decreased (0.372557 --> 0.372292).  Saving model ...
	 Train_Loss: 0.3896 Train_Acc: 83.356 Val_Loss: 0.3723  BEST VAL Loss: 0.3723  Val_Acc: 83.888

Epoch 79: Validation loss decreased (0.372292 --> 0.372046).  Saving model ...
	 Train_Loss: 0.3893 Train_Acc: 83.252 Val_Loss: 0.3720  BEST VAL Loss: 0.3720  Val_Acc: 83.705

Epoch 80: Validation loss decreased (0.372046 --> 0.371793).  Saving model ...
	 Train_Loss: 0.3890 Train_Acc: 83.302 Val_Loss: 0.3718  BEST VAL Loss: 0.3718  Val_Acc: 83.912

Epoch 81: Validation loss decreased (0.371793 --> 0.371546).  Saving model ...
	 Train_Loss: 0.3887 Train_Acc: 83.396 Val_Loss: 0.3715  BEST VAL Loss: 0.3715  Val_Acc: 84.012

Epoch 82: Validation loss decreased (0.371546 --> 0.371304).  Saving model ...
	 Train_Loss: 0.3884 Train_Acc: 83.311 Val_Loss: 0.3713  BEST VAL Loss: 0.3713  Val_Acc: 83.976

Epoch 83: Validation loss decreased (0.371304 --> 0.371094).  Saving model ...
	 Train_Loss: 0.3881 Train_Acc: 83.342 Val_Loss: 0.3711  BEST VAL Loss: 0.3711  Val_Acc: 83.811

Epoch 84: Validation loss decreased (0.371094 --> 0.370869).  Saving model ...
	 Train_Loss: 0.3877 Train_Acc: 83.507 Val_Loss: 0.3709  BEST VAL Loss: 0.3709  Val_Acc: 83.976

Epoch 85: Validation loss decreased (0.370869 --> 0.370649).  Saving model ...
	 Train_Loss: 0.3874 Train_Acc: 83.397 Val_Loss: 0.3706  BEST VAL Loss: 0.3706  Val_Acc: 83.929

Epoch 86: Validation loss decreased (0.370649 --> 0.370427).  Saving model ...
	 Train_Loss: 0.3871 Train_Acc: 83.407 Val_Loss: 0.3704  BEST VAL Loss: 0.3704  Val_Acc: 84.100

Epoch 87: Validation loss decreased (0.370427 --> 0.370227).  Saving model ...
	 Train_Loss: 0.3869 Train_Acc: 83.409 Val_Loss: 0.3702  BEST VAL Loss: 0.3702  Val_Acc: 83.853

Epoch 88: Validation loss decreased (0.370227 --> 0.369985).  Saving model ...
	 Train_Loss: 0.3866 Train_Acc: 83.410 Val_Loss: 0.3700  BEST VAL Loss: 0.3700  Val_Acc: 84.012

Epoch 89: Validation loss decreased (0.369985 --> 0.369784).  Saving model ...
	 Train_Loss: 0.3863 Train_Acc: 83.548 Val_Loss: 0.3698  BEST VAL Loss: 0.3698  Val_Acc: 83.888

Epoch 90: Validation loss decreased (0.369784 --> 0.369582).  Saving model ...
	 Train_Loss: 0.3860 Train_Acc: 83.449 Val_Loss: 0.3696  BEST VAL Loss: 0.3696  Val_Acc: 84.053

Epoch 91: Validation loss decreased (0.369582 --> 0.369394).  Saving model ...
	 Train_Loss: 0.3857 Train_Acc: 83.455 Val_Loss: 0.3694  BEST VAL Loss: 0.3694  Val_Acc: 83.876

Epoch 92: Validation loss decreased (0.369394 --> 0.369166).  Saving model ...
	 Train_Loss: 0.3855 Train_Acc: 83.554 Val_Loss: 0.3692  BEST VAL Loss: 0.3692  Val_Acc: 84.230

Epoch 93: Validation loss decreased (0.369166 --> 0.368974).  Saving model ...
	 Train_Loss: 0.3852 Train_Acc: 83.474 Val_Loss: 0.3690  BEST VAL Loss: 0.3690  Val_Acc: 84.112

Epoch 94: Validation loss decreased (0.368974 --> 0.368782).  Saving model ...
	 Train_Loss: 0.3850 Train_Acc: 83.450 Val_Loss: 0.3688  BEST VAL Loss: 0.3688  Val_Acc: 84.141

Epoch 95: Validation loss decreased (0.368782 --> 0.368575).  Saving model ...
	 Train_Loss: 0.3847 Train_Acc: 83.522 Val_Loss: 0.3686  BEST VAL Loss: 0.3686  Val_Acc: 84.206

Epoch 96: Validation loss decreased (0.368575 --> 0.368347).  Saving model ...
	 Train_Loss: 0.3845 Train_Acc: 83.407 Val_Loss: 0.3683  BEST VAL Loss: 0.3683  Val_Acc: 84.206

Epoch 97: Validation loss decreased (0.368347 --> 0.368155).  Saving model ...
	 Train_Loss: 0.3842 Train_Acc: 83.556 Val_Loss: 0.3682  BEST VAL Loss: 0.3682  Val_Acc: 84.124

Epoch 98: Validation loss decreased (0.368155 --> 0.367942).  Saving model ...
	 Train_Loss: 0.3840 Train_Acc: 83.411 Val_Loss: 0.3679  BEST VAL Loss: 0.3679  Val_Acc: 84.265

Epoch 99: Validation loss decreased (0.367942 --> 0.367742).  Saving model ...
	 Train_Loss: 0.3837 Train_Acc: 83.582 Val_Loss: 0.3677  BEST VAL Loss: 0.3677  Val_Acc: 84.277

LPS_0.010_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.89      0.74      0.80     50422
           1       0.86      0.95      0.90     85370

    accuracy                           0.87    135792
   macro avg       0.87      0.84      0.85    135792
weighted avg       0.87      0.87      0.86    135792

LPS_0.010_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.85      0.70      0.77      6303
           1       0.84      0.93      0.88     10672

    accuracy                           0.84     16975
   macro avg       0.85      0.81      0.82     16975
weighted avg       0.84      0.84      0.84     16975

LPS_0.010_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.85      0.71      0.77      6303
           1       0.84      0.92      0.88     10672

    accuracy                           0.84     16975
   macro avg       0.84      0.82      0.83     16975
weighted avg       0.84      0.84      0.84     16975

              precision    recall  f1-score   support

           0       0.85      0.71      0.77      6303
           1       0.84      0.92      0.88     10672

    accuracy                           0.84     16975
   macro avg       0.84      0.82      0.83     16975
weighted avg       0.84      0.84      0.84     16975

LPS_0.010_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.59      0.57      0.58     32887
           1       0.62      0.64      0.63     36366

    accuracy                           0.61     69253
   macro avg       0.61      0.61      0.61     69253
weighted avg       0.61      0.61      0.61     69253

              precision    recall  f1-score   support

           0       0.59      0.57      0.58     32887
           1       0.62      0.64      0.63     36366

    accuracy                           0.61     69253
   macro avg       0.61      0.61      0.61     69253
weighted avg       0.61      0.61      0.61     69253

completed
