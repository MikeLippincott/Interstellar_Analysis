[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '3aa8e694'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '0f36889c'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'df41b3fa'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '91142937'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Thapsigargin_10.000_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Thapsigargin_10.000_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (28140, 1276)
Number of total missing values across all columns: 56280
Data Subset Is Off
Wells held out for testing: ['E14' 'L22']
Wells to use for training, validation, and testing ['E15' 'L14' 'L15' 'L18' 'L19' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.382168).  Saving model ...
	 Train_Loss: 0.4973 Train_Acc: 73.976 Val_Loss: 0.3822  BEST VAL Loss: 0.3822  Val_Acc: 82.533

Epoch 1: Validation loss decreased (0.382168 --> 0.328893).  Saving model ...
	 Train_Loss: 0.4179 Train_Acc: 83.840 Val_Loss: 0.3289  BEST VAL Loss: 0.3289  Val_Acc: 87.336

Epoch 2: Validation loss decreased (0.328893 --> 0.304882).  Saving model ...
	 Train_Loss: 0.3720 Train_Acc: 87.285 Val_Loss: 0.3049  BEST VAL Loss: 0.3049  Val_Acc: 88.695

Epoch 3: Validation loss decreased (0.304882 --> 0.287527).  Saving model ...
	 Train_Loss: 0.3395 Train_Acc: 89.609 Val_Loss: 0.2875  BEST VAL Loss: 0.2875  Val_Acc: 89.859

Epoch 4: Validation loss decreased (0.287527 --> 0.272926).  Saving model ...
	 Train_Loss: 0.3153 Train_Acc: 90.689 Val_Loss: 0.2729  BEST VAL Loss: 0.2729  Val_Acc: 90.636

Epoch 5: Validation loss decreased (0.272926 --> 0.264651).  Saving model ...
	 Train_Loss: 0.2948 Train_Acc: 91.914 Val_Loss: 0.2647  BEST VAL Loss: 0.2647  Val_Acc: 91.752

Epoch 6: Validation loss decreased (0.264651 --> 0.251875).  Saving model ...
	 Train_Loss: 0.2780 Train_Acc: 92.260 Val_Loss: 0.2519  BEST VAL Loss: 0.2519  Val_Acc: 91.752

Epoch 7: Validation loss decreased (0.251875 --> 0.244528).  Saving model ...
	 Train_Loss: 0.2640 Train_Acc: 92.715 Val_Loss: 0.2445  BEST VAL Loss: 0.2445  Val_Acc: 92.285

Epoch 8: Validation loss decreased (0.244528 --> 0.238951).  Saving model ...
	 Train_Loss: 0.2517 Train_Acc: 93.248 Val_Loss: 0.2390  BEST VAL Loss: 0.2390  Val_Acc: 91.849

Epoch 9: Validation loss decreased (0.238951 --> 0.233705).  Saving model ...
	 Train_Loss: 0.2410 Train_Acc: 93.819 Val_Loss: 0.2337  BEST VAL Loss: 0.2337  Val_Acc: 92.528

Epoch 10: Validation loss decreased (0.233705 --> 0.229619).  Saving model ...
	 Train_Loss: 0.2313 Train_Acc: 94.213 Val_Loss: 0.2296  BEST VAL Loss: 0.2296  Val_Acc: 92.091

Epoch 11: Validation loss decreased (0.229619 --> 0.223732).  Saving model ...
	 Train_Loss: 0.2228 Train_Acc: 94.213 Val_Loss: 0.2237  BEST VAL Loss: 0.2237  Val_Acc: 92.188

Epoch 12: Validation loss decreased (0.223732 --> 0.218316).  Saving model ...
	 Train_Loss: 0.2147 Train_Acc: 94.959 Val_Loss: 0.2183  BEST VAL Loss: 0.2183  Val_Acc: 92.770

Epoch 13: Validation loss decreased (0.218316 --> 0.216701).  Saving model ...
	 Train_Loss: 0.2078 Train_Acc: 94.729 Val_Loss: 0.2167  BEST VAL Loss: 0.2167  Val_Acc: 92.479

Epoch 14: Validation loss decreased (0.216701 --> 0.214319).  Saving model ...
	 Train_Loss: 0.2014 Train_Acc: 95.050 Val_Loss: 0.2143  BEST VAL Loss: 0.2143  Val_Acc: 92.382

Epoch 15: Validation loss did not decrease
	 Train_Loss: 0.1954 Train_Acc: 95.456 Val_Loss: 0.2145  BEST VAL Loss: 0.2143  Val_Acc: 92.625

Epoch 16: Validation loss decreased (0.214319 --> 0.213528).  Saving model ...
	 Train_Loss: 0.1902 Train_Acc: 95.147 Val_Loss: 0.2135  BEST VAL Loss: 0.2135  Val_Acc: 92.431

Epoch 17: Validation loss decreased (0.213528 --> 0.210775).  Saving model ...
	 Train_Loss: 0.1852 Train_Acc: 95.408 Val_Loss: 0.2108  BEST VAL Loss: 0.2108  Val_Acc: 92.673

Epoch 18: Validation loss decreased (0.210775 --> 0.209675).  Saving model ...
	 Train_Loss: 0.1805 Train_Acc: 95.602 Val_Loss: 0.2097  BEST VAL Loss: 0.2097  Val_Acc: 92.868

Epoch 19: Validation loss did not decrease
	 Train_Loss: 0.1760 Train_Acc: 95.736 Val_Loss: 0.2124  BEST VAL Loss: 0.2097  Val_Acc: 92.382

Epoch 20: Validation loss did not decrease
	 Train_Loss: 0.1720 Train_Acc: 95.802 Val_Loss: 0.2133  BEST VAL Loss: 0.2097  Val_Acc: 92.819

Epoch 21: Validation loss did not decrease
	 Train_Loss: 0.1681 Train_Acc: 96.087 Val_Loss: 0.2123  BEST VAL Loss: 0.2097  Val_Acc: 92.916

Epoch 22: Validation loss did not decrease
	 Train_Loss: 0.1645 Train_Acc: 95.893 Val_Loss: 0.2106  BEST VAL Loss: 0.2097  Val_Acc: 92.770

Epoch 23: Validation loss decreased (0.209675 --> 0.209345).  Saving model ...
	 Train_Loss: 0.1611 Train_Acc: 96.160 Val_Loss: 0.2093  BEST VAL Loss: 0.2093  Val_Acc: 92.382

Epoch 24: Validation loss decreased (0.209345 --> 0.209291).  Saving model ...
	 Train_Loss: 0.1579 Train_Acc: 96.245 Val_Loss: 0.2093  BEST VAL Loss: 0.2093  Val_Acc: 92.673

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.1548 Train_Acc: 96.306 Val_Loss: 0.2119  BEST VAL Loss: 0.2093  Val_Acc: 92.528

Epoch 26: Validation loss did not decrease
	 Train_Loss: 0.1518 Train_Acc: 96.445 Val_Loss: 0.2162  BEST VAL Loss: 0.2093  Val_Acc: 92.916

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.1492 Train_Acc: 96.354 Val_Loss: 0.2149  BEST VAL Loss: 0.2093  Val_Acc: 92.528

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.1466 Train_Acc: 96.312 Val_Loss: 0.2154  BEST VAL Loss: 0.2093  Val_Acc: 92.673

Epoch 29: Validation loss did not decrease
	 Train_Loss: 0.1442 Train_Acc: 96.482 Val_Loss: 0.2143  BEST VAL Loss: 0.2093  Val_Acc: 92.916

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.1419 Train_Acc: 96.597 Val_Loss: 0.2140  BEST VAL Loss: 0.2093  Val_Acc: 92.868

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.1396 Train_Acc: 96.561 Val_Loss: 0.2129  BEST VAL Loss: 0.2093  Val_Acc: 93.110

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.1375 Train_Acc: 96.688 Val_Loss: 0.2151  BEST VAL Loss: 0.2093  Val_Acc: 92.868

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.1354 Train_Acc: 96.506 Val_Loss: 0.2143  BEST VAL Loss: 0.2093  Val_Acc: 92.868

Epoch 34: Validation loss did not decrease
	 Train_Loss: 0.1335 Train_Acc: 96.627 Val_Loss: 0.2147  BEST VAL Loss: 0.2093  Val_Acc: 93.062

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.1317 Train_Acc: 96.761 Val_Loss: 0.2147  BEST VAL Loss: 0.2093  Val_Acc: 92.819

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.1299 Train_Acc: 96.761 Val_Loss: 0.2140  BEST VAL Loss: 0.2093  Val_Acc: 93.256

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.1282 Train_Acc: 96.603 Val_Loss: 0.2148  BEST VAL Loss: 0.2093  Val_Acc: 92.965

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.1264 Train_Acc: 96.876 Val_Loss: 0.2147  BEST VAL Loss: 0.2093  Val_Acc: 92.770

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.1248 Train_Acc: 96.943 Val_Loss: 0.2171  BEST VAL Loss: 0.2093  Val_Acc: 92.285

Epoch 40: Validation loss did not decrease
Early stopped at epoch : 40
Thapsigargin_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.53      0.53      8634
           1       0.48      0.47      0.48      7851

    accuracy                           0.50     16485
   macro avg       0.50      0.50      0.50     16485
weighted avg       0.50      0.50      0.50     16485

Thapsigargin_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.51      0.50      1079
           1       0.45      0.43      0.44       982

    accuracy                           0.47      2061
   macro avg       0.47      0.47      0.47      2061
weighted avg       0.47      0.47      0.47      2061

Thapsigargin_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.53      0.52      1080
           1       0.47      0.47      0.47       981

    accuracy                           0.50      2061
   macro avg       0.50      0.50      0.50      2061
weighted avg       0.50      0.50      0.50      2061

              precision    recall  f1-score   support

           0       0.52      0.53      0.52      1080
           1       0.47      0.47      0.47       981

    accuracy                           0.50      2061
   macro avg       0.50      0.50      0.50      2061
weighted avg       0.50      0.50      0.50      2061

Thapsigargin_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.55      0.55      4135
           1       0.46      0.46      0.46      3398

    accuracy                           0.51      7533
   macro avg       0.51      0.51      0.51      7533
weighted avg       0.51      0.51      0.51      7533

              precision    recall  f1-score   support

           0       0.55      0.55      0.55      4135
           1       0.46      0.46      0.46      3398

    accuracy                           0.51      7533
   macro avg       0.51      0.51      0.51      7533
weighted avg       0.51      0.51      0.51      7533

completed
