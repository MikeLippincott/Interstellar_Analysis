[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '7c2718e1'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '1bcd3b00'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '30c9f6a3'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '8c781ed1'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_10.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (31212, 1276)
Number of total missing values across all columns: 33620
Data Subset Is Off
Wells held out for testing: ['E20' 'M16']
Wells to use for training, validation, and testing ['E16' 'E17' 'E21' 'M17' 'M20' 'M21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.454162).  Saving model ...
	 Train_Loss: 0.6130 Train_Acc: 63.450 Val_Loss: 0.4542  BEST VAL Loss: 0.4542  Val_Acc: 86.805

Epoch 1: Validation loss decreased (0.454162 --> 0.418853).  Saving model ...
	 Train_Loss: 0.5618 Train_Acc: 72.857 Val_Loss: 0.4189  BEST VAL Loss: 0.4189  Val_Acc: 88.271

Epoch 2: Validation loss decreased (0.418853 --> 0.391585).  Saving model ...
	 Train_Loss: 0.5275 Train_Acc: 77.790 Val_Loss: 0.3916  BEST VAL Loss: 0.3916  Val_Acc: 90.168

Epoch 3: Validation loss decreased (0.391585 --> 0.371767).  Saving model ...
	 Train_Loss: 0.5063 Train_Acc: 78.555 Val_Loss: 0.3718  BEST VAL Loss: 0.3718  Val_Acc: 90.513

Epoch 4: Validation loss decreased (0.371767 --> 0.354984).  Saving model ...
	 Train_Loss: 0.4906 Train_Acc: 79.364 Val_Loss: 0.3550  BEST VAL Loss: 0.3550  Val_Acc: 91.591

Epoch 5: Validation loss decreased (0.354984 --> 0.341241).  Saving model ...
	 Train_Loss: 0.4780 Train_Acc: 80.167 Val_Loss: 0.3412  BEST VAL Loss: 0.3412  Val_Acc: 92.712

Epoch 6: Validation loss decreased (0.341241 --> 0.332464).  Saving model ...
	 Train_Loss: 0.4673 Train_Acc: 80.965 Val_Loss: 0.3325  BEST VAL Loss: 0.3325  Val_Acc: 92.712

Epoch 7: Validation loss decreased (0.332464 --> 0.324286).  Saving model ...
	 Train_Loss: 0.4587 Train_Acc: 81.261 Val_Loss: 0.3243  BEST VAL Loss: 0.3243  Val_Acc: 93.445

Epoch 8: Validation loss decreased (0.324286 --> 0.316779).  Saving model ...
	 Train_Loss: 0.4515 Train_Acc: 81.515 Val_Loss: 0.3168  BEST VAL Loss: 0.3168  Val_Acc: 93.618

Epoch 9: Validation loss decreased (0.316779 --> 0.311029).  Saving model ...
	 Train_Loss: 0.4452 Train_Acc: 81.849 Val_Loss: 0.3110  BEST VAL Loss: 0.3110  Val_Acc: 93.920

Epoch 10: Validation loss decreased (0.311029 --> 0.305172).  Saving model ...
	 Train_Loss: 0.4398 Train_Acc: 81.919 Val_Loss: 0.3052  BEST VAL Loss: 0.3052  Val_Acc: 94.308

Epoch 11: Validation loss decreased (0.305172 --> 0.301910).  Saving model ...
	 Train_Loss: 0.4355 Train_Acc: 81.849 Val_Loss: 0.3019  BEST VAL Loss: 0.3019  Val_Acc: 93.747

Epoch 12: Validation loss decreased (0.301910 --> 0.297446).  Saving model ...
	 Train_Loss: 0.4314 Train_Acc: 82.318 Val_Loss: 0.2974  BEST VAL Loss: 0.2974  Val_Acc: 94.351

Epoch 13: Validation loss decreased (0.297446 --> 0.294201).  Saving model ...
	 Train_Loss: 0.4281 Train_Acc: 82.167 Val_Loss: 0.2942  BEST VAL Loss: 0.2942  Val_Acc: 94.049

Epoch 14: Validation loss decreased (0.294201 --> 0.290678).  Saving model ...
	 Train_Loss: 0.4248 Train_Acc: 82.571 Val_Loss: 0.2907  BEST VAL Loss: 0.2907  Val_Acc: 94.351

Epoch 15: Validation loss decreased (0.290678 --> 0.287692).  Saving model ...
	 Train_Loss: 0.4222 Train_Acc: 82.372 Val_Loss: 0.2877  BEST VAL Loss: 0.2877  Val_Acc: 94.610

Epoch 16: Validation loss decreased (0.287692 --> 0.285122).  Saving model ...
	 Train_Loss: 0.4200 Train_Acc: 81.984 Val_Loss: 0.2851  BEST VAL Loss: 0.2851  Val_Acc: 93.963

Epoch 17: Validation loss decreased (0.285122 --> 0.283300).  Saving model ...
	 Train_Loss: 0.4174 Train_Acc: 82.863 Val_Loss: 0.2833  BEST VAL Loss: 0.2833  Val_Acc: 94.696

Epoch 18: Validation loss decreased (0.283300 --> 0.280430).  Saving model ...
	 Train_Loss: 0.4150 Train_Acc: 82.895 Val_Loss: 0.2804  BEST VAL Loss: 0.2804  Val_Acc: 94.610

Epoch 19: Validation loss decreased (0.280430 --> 0.278327).  Saving model ...
	 Train_Loss: 0.4126 Train_Acc: 83.164 Val_Loss: 0.2783  BEST VAL Loss: 0.2783  Val_Acc: 94.567

Epoch 20: Validation loss decreased (0.278327 --> 0.276679).  Saving model ...
	 Train_Loss: 0.4105 Train_Acc: 83.423 Val_Loss: 0.2767  BEST VAL Loss: 0.2767  Val_Acc: 94.782

Epoch 21: Validation loss decreased (0.276679 --> 0.274440).  Saving model ...
	 Train_Loss: 0.4089 Train_Acc: 82.755 Val_Loss: 0.2744  BEST VAL Loss: 0.2744  Val_Acc: 94.912

Epoch 22: Validation loss decreased (0.274440 --> 0.271958).  Saving model ...
	 Train_Loss: 0.4075 Train_Acc: 82.609 Val_Loss: 0.2720  BEST VAL Loss: 0.2720  Val_Acc: 94.998

Epoch 23: Validation loss decreased (0.271958 --> 0.270063).  Saving model ...
	 Train_Loss: 0.4055 Train_Acc: 83.811 Val_Loss: 0.2701  BEST VAL Loss: 0.2701  Val_Acc: 95.127

Epoch 24: Validation loss decreased (0.270063 --> 0.267952).  Saving model ...
	 Train_Loss: 0.4038 Train_Acc: 83.590 Val_Loss: 0.2680  BEST VAL Loss: 0.2680  Val_Acc: 95.041

Epoch 25: Validation loss decreased (0.267952 --> 0.265969).  Saving model ...
	 Train_Loss: 0.4024 Train_Acc: 83.035 Val_Loss: 0.2660  BEST VAL Loss: 0.2660  Val_Acc: 94.955

Epoch 26: Validation loss decreased (0.265969 --> 0.265042).  Saving model ...
	 Train_Loss: 0.4011 Train_Acc: 83.111 Val_Loss: 0.2650  BEST VAL Loss: 0.2650  Val_Acc: 94.912

Epoch 27: Validation loss decreased (0.265042 --> 0.263969).  Saving model ...
	 Train_Loss: 0.4000 Train_Acc: 83.159 Val_Loss: 0.2640  BEST VAL Loss: 0.2640  Val_Acc: 95.213

Epoch 28: Validation loss decreased (0.263969 --> 0.262723).  Saving model ...
	 Train_Loss: 0.3987 Train_Acc: 83.407 Val_Loss: 0.2627  BEST VAL Loss: 0.2627  Val_Acc: 95.602

Epoch 29: Validation loss decreased (0.262723 --> 0.262064).  Saving model ...
	 Train_Loss: 0.3973 Train_Acc: 83.844 Val_Loss: 0.2621  BEST VAL Loss: 0.2621  Val_Acc: 95.386

Epoch 30: Validation loss decreased (0.262064 --> 0.261568).  Saving model ...
	 Train_Loss: 0.3962 Train_Acc: 83.590 Val_Loss: 0.2616  BEST VAL Loss: 0.2616  Val_Acc: 94.912

Epoch 31: Validation loss decreased (0.261568 --> 0.260789).  Saving model ...
	 Train_Loss: 0.3950 Train_Acc: 83.752 Val_Loss: 0.2608  BEST VAL Loss: 0.2608  Val_Acc: 95.300

Epoch 32: Validation loss decreased (0.260789 --> 0.260035).  Saving model ...
	 Train_Loss: 0.3941 Train_Acc: 83.569 Val_Loss: 0.2600  BEST VAL Loss: 0.2600  Val_Acc: 94.912

Epoch 33: Validation loss decreased (0.260035 --> 0.259551).  Saving model ...
	 Train_Loss: 0.3930 Train_Acc: 83.741 Val_Loss: 0.2596  BEST VAL Loss: 0.2596  Val_Acc: 94.955

Epoch 34: Validation loss decreased (0.259551 --> 0.259132).  Saving model ...
	 Train_Loss: 0.3922 Train_Acc: 83.358 Val_Loss: 0.2591  BEST VAL Loss: 0.2591  Val_Acc: 95.602

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.3912 Train_Acc: 83.774 Val_Loss: 0.2592  BEST VAL Loss: 0.2591  Val_Acc: 95.602

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.3902 Train_Acc: 84.092 Val_Loss: 0.2592  BEST VAL Loss: 0.2591  Val_Acc: 94.825

Epoch 37: Validation loss decreased (0.259132 --> 0.258760).  Saving model ...
	 Train_Loss: 0.3895 Train_Acc: 83.833 Val_Loss: 0.2588  BEST VAL Loss: 0.2588  Val_Acc: 95.170

Epoch 38: Validation loss decreased (0.258760 --> 0.257781).  Saving model ...
	 Train_Loss: 0.3890 Train_Acc: 83.218 Val_Loss: 0.2578  BEST VAL Loss: 0.2578  Val_Acc: 94.998

Epoch 39: Validation loss decreased (0.257781 --> 0.257179).  Saving model ...
	 Train_Loss: 0.3883 Train_Acc: 83.504 Val_Loss: 0.2572  BEST VAL Loss: 0.2572  Val_Acc: 95.558

Epoch 40: Validation loss decreased (0.257179 --> 0.256362).  Saving model ...
	 Train_Loss: 0.3877 Train_Acc: 83.358 Val_Loss: 0.2564  BEST VAL Loss: 0.2564  Val_Acc: 95.300

Epoch 41: Validation loss decreased (0.256362 --> 0.255535).  Saving model ...
	 Train_Loss: 0.3871 Train_Acc: 83.515 Val_Loss: 0.2555  BEST VAL Loss: 0.2555  Val_Acc: 95.343

Epoch 42: Validation loss decreased (0.255535 --> 0.254880).  Saving model ...
	 Train_Loss: 0.3865 Train_Acc: 83.687 Val_Loss: 0.2549  BEST VAL Loss: 0.2549  Val_Acc: 95.558

Epoch 43: Validation loss decreased (0.254880 --> 0.254354).  Saving model ...
	 Train_Loss: 0.3858 Train_Acc: 83.968 Val_Loss: 0.2544  BEST VAL Loss: 0.2544  Val_Acc: 95.300

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.3851 Train_Acc: 84.135 Val_Loss: 0.2545  BEST VAL Loss: 0.2544  Val_Acc: 95.257

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.3845 Train_Acc: 83.806 Val_Loss: 0.2545  BEST VAL Loss: 0.2544  Val_Acc: 95.084

Epoch 46: Validation loss decreased (0.254354 --> 0.254258).  Saving model ...
	 Train_Loss: 0.3839 Train_Acc: 83.973 Val_Loss: 0.2543  BEST VAL Loss: 0.2543  Val_Acc: 95.300

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.3833 Train_Acc: 83.849 Val_Loss: 0.2544  BEST VAL Loss: 0.2543  Val_Acc: 95.774

Epoch 48: Validation loss decreased (0.254258 --> 0.254165).  Saving model ...
	 Train_Loss: 0.3828 Train_Acc: 83.644 Val_Loss: 0.2542  BEST VAL Loss: 0.2542  Val_Acc: 95.257

Epoch 49: Validation loss decreased (0.254165 --> 0.253599).  Saving model ...
	 Train_Loss: 0.3823 Train_Acc: 83.946 Val_Loss: 0.2536  BEST VAL Loss: 0.2536  Val_Acc: 95.947

Epoch 50: Validation loss decreased (0.253599 --> 0.252867).  Saving model ...
	 Train_Loss: 0.3818 Train_Acc: 83.854 Val_Loss: 0.2529  BEST VAL Loss: 0.2529  Val_Acc: 95.731

Epoch 51: Validation loss decreased (0.252867 --> 0.252430).  Saving model ...
	 Train_Loss: 0.3811 Train_Acc: 84.383 Val_Loss: 0.2524  BEST VAL Loss: 0.2524  Val_Acc: 95.645

Epoch 52: Validation loss decreased (0.252430 --> 0.252046).  Saving model ...
	 Train_Loss: 0.3806 Train_Acc: 84.345 Val_Loss: 0.2520  BEST VAL Loss: 0.2520  Val_Acc: 95.990

Epoch 53: Validation loss decreased (0.252046 --> 0.251832).  Saving model ...
	 Train_Loss: 0.3800 Train_Acc: 84.216 Val_Loss: 0.2518  BEST VAL Loss: 0.2518  Val_Acc: 96.076

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.3796 Train_Acc: 83.774 Val_Loss: 0.2519  BEST VAL Loss: 0.2518  Val_Acc: 96.335

Epoch 55: Validation loss decreased (0.251832 --> 0.251737).  Saving model ...
	 Train_Loss: 0.3792 Train_Acc: 83.865 Val_Loss: 0.2517  BEST VAL Loss: 0.2517  Val_Acc: 96.205

Epoch 56: Validation loss decreased (0.251737 --> 0.251171).  Saving model ...
	 Train_Loss: 0.3789 Train_Acc: 83.682 Val_Loss: 0.2512  BEST VAL Loss: 0.2512  Val_Acc: 96.205

Epoch 57: Validation loss decreased (0.251171 --> 0.250826).  Saving model ...
	 Train_Loss: 0.3784 Train_Acc: 84.156 Val_Loss: 0.2508  BEST VAL Loss: 0.2508  Val_Acc: 96.076

Epoch 58: Validation loss decreased (0.250826 --> 0.250531).  Saving model ...
	 Train_Loss: 0.3780 Train_Acc: 84.259 Val_Loss: 0.2505  BEST VAL Loss: 0.2505  Val_Acc: 96.162

Epoch 59: Validation loss decreased (0.250531 --> 0.250436).  Saving model ...
	 Train_Loss: 0.3775 Train_Acc: 84.216 Val_Loss: 0.2504  BEST VAL Loss: 0.2504  Val_Acc: 96.119

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.3771 Train_Acc: 84.221 Val_Loss: 0.2509  BEST VAL Loss: 0.2504  Val_Acc: 96.162

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.3767 Train_Acc: 83.989 Val_Loss: 0.2510  BEST VAL Loss: 0.2504  Val_Acc: 95.990

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.3763 Train_Acc: 84.361 Val_Loss: 0.2511  BEST VAL Loss: 0.2504  Val_Acc: 95.774

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.3759 Train_Acc: 84.205 Val_Loss: 0.2514  BEST VAL Loss: 0.2504  Val_Acc: 95.947

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.3756 Train_Acc: 84.221 Val_Loss: 0.2513  BEST VAL Loss: 0.2504  Val_Acc: 95.817

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.3752 Train_Acc: 84.011 Val_Loss: 0.2509  BEST VAL Loss: 0.2504  Val_Acc: 96.248

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.3748 Train_Acc: 84.501 Val_Loss: 0.2505  BEST VAL Loss: 0.2504  Val_Acc: 95.817

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.3746 Train_Acc: 83.860 Val_Loss: 0.2507  BEST VAL Loss: 0.2504  Val_Acc: 95.645

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.3742 Train_Acc: 84.350 Val_Loss: 0.2506  BEST VAL Loss: 0.2504  Val_Acc: 95.774

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.3739 Train_Acc: 84.394 Val_Loss: 0.2509  BEST VAL Loss: 0.2504  Val_Acc: 95.903

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.3735 Train_Acc: 84.270 Val_Loss: 0.2513  BEST VAL Loss: 0.2504  Val_Acc: 96.033

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.3732 Train_Acc: 84.135 Val_Loss: 0.2510  BEST VAL Loss: 0.2504  Val_Acc: 95.731

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.3730 Train_Acc: 84.156 Val_Loss: 0.2514  BEST VAL Loss: 0.2504  Val_Acc: 95.947

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.3727 Train_Acc: 83.849 Val_Loss: 0.2515  BEST VAL Loss: 0.2504  Val_Acc: 96.033

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.3724 Train_Acc: 84.577 Val_Loss: 0.2518  BEST VAL Loss: 0.2504  Val_Acc: 95.774

Epoch 75: Validation loss did not decrease
Early stopped at epoch : 75
LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.54      0.54     10114
           1       0.46      0.47      0.47      8436

    accuracy                           0.51     18550
   macro avg       0.50      0.50      0.50     18550
weighted avg       0.51      0.51      0.51     18550

LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.56      0.56      0.56      1264
           1       0.47      0.48      0.48      1055

    accuracy                           0.52      2319
   macro avg       0.52      0.52      0.52      2319
weighted avg       0.52      0.52      0.52      2319

LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.55      0.55      1264
           1       0.46      0.46      0.46      1055

    accuracy                           0.51      2319
   macro avg       0.50      0.50      0.50      2319
weighted avg       0.51      0.51      0.51      2319

              precision    recall  f1-score   support

           0       0.55      0.55      0.55      1264
           1       0.46      0.46      0.46      1055

    accuracy                           0.51      2319
   macro avg       0.50      0.50      0.50      2319
weighted avg       0.51      0.51      0.51      2319

LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.52      0.52      4168
           1       0.48      0.47      0.47      3856

    accuracy                           0.50      8024
   macro avg       0.50      0.50      0.50      8024
weighted avg       0.50      0.50      0.50      8024

              precision    recall  f1-score   support

           0       0.52      0.52      0.52      4168
           1       0.48      0.47      0.47      3856

    accuracy                           0.50      8024
   macro avg       0.50      0.50      0.50      8024
weighted avg       0.50      0.50      0.50      8024

completed
