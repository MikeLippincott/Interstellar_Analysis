[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '627108e3'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '2cd2e871'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '4bf552ef'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '2c0fc4a6'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Thapsigargin_1.000_DMSO_0.025 treatment_name: LPS_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Thapsigargin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'LPS_1.000_DMSO_0.025']
The dimensions of the data are: (30224, 1276)
Number of total missing values across all columns: 60448
Data Subset Is Off
Wells held out for testing: ['D14' 'D20']
Wells to use for training, validation, and testing ['D15' 'D16' 'D17' 'D21' 'K14' 'K15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.573260).  Saving model ...
	 Train_Loss: 0.6349 Train_Acc: 65.892 Val_Loss: 0.5733  BEST VAL Loss: 0.5733  Val_Acc: 74.165

Epoch 1: Validation loss decreased (0.573260 --> 0.542402).  Saving model ...
	 Train_Loss: 0.5923 Train_Acc: 74.490 Val_Loss: 0.5424  BEST VAL Loss: 0.5424  Val_Acc: 76.582

Epoch 2: Validation loss decreased (0.542402 --> 0.517630).  Saving model ...
	 Train_Loss: 0.5624 Train_Acc: 77.358 Val_Loss: 0.5176  BEST VAL Loss: 0.5176  Val_Acc: 78.998

Epoch 3: Validation loss decreased (0.517630 --> 0.496137).  Saving model ...
	 Train_Loss: 0.5390 Train_Acc: 79.062 Val_Loss: 0.4961  BEST VAL Loss: 0.4961  Val_Acc: 80.053

Epoch 4: Validation loss decreased (0.496137 --> 0.481978).  Saving model ...
	 Train_Loss: 0.5203 Train_Acc: 80.831 Val_Loss: 0.4820  BEST VAL Loss: 0.4820  Val_Acc: 81.591

Epoch 5: Validation loss decreased (0.481978 --> 0.469765).  Saving model ...
	 Train_Loss: 0.5044 Train_Acc: 81.567 Val_Loss: 0.4698  BEST VAL Loss: 0.4698  Val_Acc: 82.469

Epoch 6: Validation loss decreased (0.469765 --> 0.457802).  Saving model ...
	 Train_Loss: 0.4908 Train_Acc: 82.754 Val_Loss: 0.4578  BEST VAL Loss: 0.4578  Val_Acc: 83.524

Epoch 7: Validation loss decreased (0.457802 --> 0.447953).  Saving model ...
	 Train_Loss: 0.4788 Train_Acc: 83.353 Val_Loss: 0.4480  BEST VAL Loss: 0.4480  Val_Acc: 83.084

Epoch 8: Validation loss decreased (0.447953 --> 0.438372).  Saving model ...
	 Train_Loss: 0.4681 Train_Acc: 83.462 Val_Loss: 0.4384  BEST VAL Loss: 0.4384  Val_Acc: 84.139

Epoch 9: Validation loss decreased (0.438372 --> 0.430657).  Saving model ...
	 Train_Loss: 0.4579 Train_Acc: 84.682 Val_Loss: 0.4307  BEST VAL Loss: 0.4307  Val_Acc: 84.095

Epoch 10: Validation loss decreased (0.430657 --> 0.423298).  Saving model ...
	 Train_Loss: 0.4494 Train_Acc: 84.627 Val_Loss: 0.4233  BEST VAL Loss: 0.4233  Val_Acc: 85.018

Epoch 11: Validation loss decreased (0.423298 --> 0.416286).  Saving model ...
	 Train_Loss: 0.4411 Train_Acc: 85.380 Val_Loss: 0.4163  BEST VAL Loss: 0.4163  Val_Acc: 85.193

Epoch 12: Validation loss decreased (0.416286 --> 0.409706).  Saving model ...
	 Train_Loss: 0.4335 Train_Acc: 85.885 Val_Loss: 0.4097  BEST VAL Loss: 0.4097  Val_Acc: 85.808

Epoch 13: Validation loss decreased (0.409706 --> 0.403506).  Saving model ...
	 Train_Loss: 0.4263 Train_Acc: 86.001 Val_Loss: 0.4035  BEST VAL Loss: 0.4035  Val_Acc: 86.248

Epoch 14: Validation loss decreased (0.403506 --> 0.398279).  Saving model ...
	 Train_Loss: 0.4198 Train_Acc: 86.237 Val_Loss: 0.3983  BEST VAL Loss: 0.3983  Val_Acc: 87.127

Epoch 15: Validation loss decreased (0.398279 --> 0.393719).  Saving model ...
	 Train_Loss: 0.4135 Train_Acc: 86.935 Val_Loss: 0.3937  BEST VAL Loss: 0.3937  Val_Acc: 86.116

Epoch 16: Validation loss decreased (0.393719 --> 0.389009).  Saving model ...
	 Train_Loss: 0.4075 Train_Acc: 87.231 Val_Loss: 0.3890  BEST VAL Loss: 0.3890  Val_Acc: 86.555

Epoch 17: Validation loss decreased (0.389009 --> 0.384873).  Saving model ...
	 Train_Loss: 0.4020 Train_Acc: 87.100 Val_Loss: 0.3849  BEST VAL Loss: 0.3849  Val_Acc: 85.896

Epoch 18: Validation loss decreased (0.384873 --> 0.380678).  Saving model ...
	 Train_Loss: 0.3967 Train_Acc: 87.836 Val_Loss: 0.3807  BEST VAL Loss: 0.3807  Val_Acc: 87.390

Epoch 19: Validation loss decreased (0.380678 --> 0.377059).  Saving model ...
	 Train_Loss: 0.3916 Train_Acc: 87.825 Val_Loss: 0.3771  BEST VAL Loss: 0.3771  Val_Acc: 86.643

Epoch 20: Validation loss decreased (0.377059 --> 0.373083).  Saving model ...
	 Train_Loss: 0.3867 Train_Acc: 88.292 Val_Loss: 0.3731  BEST VAL Loss: 0.3731  Val_Acc: 87.039

Epoch 21: Validation loss decreased (0.373083 --> 0.369577).  Saving model ...
	 Train_Loss: 0.3823 Train_Acc: 88.286 Val_Loss: 0.3696  BEST VAL Loss: 0.3696  Val_Acc: 87.258

Epoch 22: Validation loss decreased (0.369577 --> 0.365928).  Saving model ...
	 Train_Loss: 0.3781 Train_Acc: 88.424 Val_Loss: 0.3659  BEST VAL Loss: 0.3659  Val_Acc: 87.083

Epoch 23: Validation loss decreased (0.365928 --> 0.362714).  Saving model ...
	 Train_Loss: 0.3740 Train_Acc: 88.726 Val_Loss: 0.3627  BEST VAL Loss: 0.3627  Val_Acc: 87.522

Epoch 24: Validation loss decreased (0.362714 --> 0.359440).  Saving model ...
	 Train_Loss: 0.3700 Train_Acc: 88.693 Val_Loss: 0.3594  BEST VAL Loss: 0.3594  Val_Acc: 88.181

Epoch 25: Validation loss decreased (0.359440 --> 0.356458).  Saving model ...
	 Train_Loss: 0.3663 Train_Acc: 88.830 Val_Loss: 0.3565  BEST VAL Loss: 0.3565  Val_Acc: 87.522

Epoch 26: Validation loss decreased (0.356458 --> 0.353033).  Saving model ...
	 Train_Loss: 0.3628 Train_Acc: 89.072 Val_Loss: 0.3530  BEST VAL Loss: 0.3530  Val_Acc: 88.093

Epoch 27: Validation loss decreased (0.353033 --> 0.350279).  Saving model ...
	 Train_Loss: 0.3593 Train_Acc: 89.528 Val_Loss: 0.3503  BEST VAL Loss: 0.3503  Val_Acc: 88.049

Epoch 28: Validation loss decreased (0.350279 --> 0.347887).  Saving model ...
	 Train_Loss: 0.3561 Train_Acc: 89.550 Val_Loss: 0.3479  BEST VAL Loss: 0.3479  Val_Acc: 87.478

Epoch 29: Validation loss decreased (0.347887 --> 0.345883).  Saving model ...
	 Train_Loss: 0.3528 Train_Acc: 89.610 Val_Loss: 0.3459  BEST VAL Loss: 0.3459  Val_Acc: 87.170

Epoch 30: Validation loss decreased (0.345883 --> 0.343510).  Saving model ...
	 Train_Loss: 0.3497 Train_Acc: 89.314 Val_Loss: 0.3435  BEST VAL Loss: 0.3435  Val_Acc: 88.225

Epoch 31: Validation loss decreased (0.343510 --> 0.341219).  Saving model ...
	 Train_Loss: 0.3467 Train_Acc: 89.781 Val_Loss: 0.3412  BEST VAL Loss: 0.3412  Val_Acc: 87.786

Epoch 32: Validation loss decreased (0.341219 --> 0.338630).  Saving model ...
	 Train_Loss: 0.3437 Train_Acc: 90.099 Val_Loss: 0.3386  BEST VAL Loss: 0.3386  Val_Acc: 88.708

Epoch 33: Validation loss decreased (0.338630 --> 0.336860).  Saving model ...
	 Train_Loss: 0.3410 Train_Acc: 90.034 Val_Loss: 0.3369  BEST VAL Loss: 0.3369  Val_Acc: 88.225

Epoch 34: Validation loss decreased (0.336860 --> 0.334790).  Saving model ...
	 Train_Loss: 0.3382 Train_Acc: 90.418 Val_Loss: 0.3348  BEST VAL Loss: 0.3348  Val_Acc: 87.961

Epoch 35: Validation loss decreased (0.334790 --> 0.333465).  Saving model ...
	 Train_Loss: 0.3357 Train_Acc: 90.149 Val_Loss: 0.3335  BEST VAL Loss: 0.3335  Val_Acc: 88.533

Epoch 36: Validation loss decreased (0.333465 --> 0.331498).  Saving model ...
	 Train_Loss: 0.3331 Train_Acc: 90.512 Val_Loss: 0.3315  BEST VAL Loss: 0.3315  Val_Acc: 88.181

Epoch 37: Validation loss decreased (0.331498 --> 0.329772).  Saving model ...
	 Train_Loss: 0.3307 Train_Acc: 90.715 Val_Loss: 0.3298  BEST VAL Loss: 0.3298  Val_Acc: 88.576

Epoch 38: Validation loss decreased (0.329772 --> 0.328370).  Saving model ...
	 Train_Loss: 0.3282 Train_Acc: 90.407 Val_Loss: 0.3284  BEST VAL Loss: 0.3284  Val_Acc: 88.884

Epoch 39: Validation loss decreased (0.328370 --> 0.326807).  Saving model ...
	 Train_Loss: 0.3259 Train_Acc: 90.770 Val_Loss: 0.3268  BEST VAL Loss: 0.3268  Val_Acc: 88.884

Epoch 40: Validation loss decreased (0.326807 --> 0.325710).  Saving model ...
	 Train_Loss: 0.3237 Train_Acc: 90.858 Val_Loss: 0.3257  BEST VAL Loss: 0.3257  Val_Acc: 87.961

Epoch 41: Validation loss decreased (0.325710 --> 0.324400).  Saving model ...
	 Train_Loss: 0.3216 Train_Acc: 91.132 Val_Loss: 0.3244  BEST VAL Loss: 0.3244  Val_Acc: 88.752

Epoch 42: Validation loss decreased (0.324400 --> 0.322756).  Saving model ...
	 Train_Loss: 0.3194 Train_Acc: 91.325 Val_Loss: 0.3228  BEST VAL Loss: 0.3228  Val_Acc: 89.543

Epoch 43: Validation loss decreased (0.322756 --> 0.321505).  Saving model ...
	 Train_Loss: 0.3173 Train_Acc: 91.105 Val_Loss: 0.3215  BEST VAL Loss: 0.3215  Val_Acc: 88.664

Epoch 44: Validation loss decreased (0.321505 --> 0.320200).  Saving model ...
	 Train_Loss: 0.3153 Train_Acc: 91.077 Val_Loss: 0.3202  BEST VAL Loss: 0.3202  Val_Acc: 89.148

Epoch 45: Validation loss decreased (0.320200 --> 0.318681).  Saving model ...
	 Train_Loss: 0.3132 Train_Acc: 91.237 Val_Loss: 0.3187  BEST VAL Loss: 0.3187  Val_Acc: 89.807

Epoch 46: Validation loss decreased (0.318681 --> 0.317200).  Saving model ...
	 Train_Loss: 0.3114 Train_Acc: 91.226 Val_Loss: 0.3172  BEST VAL Loss: 0.3172  Val_Acc: 88.928

Epoch 47: Validation loss decreased (0.317200 --> 0.316016).  Saving model ...
	 Train_Loss: 0.3094 Train_Acc: 91.462 Val_Loss: 0.3160  BEST VAL Loss: 0.3160  Val_Acc: 88.972

Epoch 48: Validation loss decreased (0.316016 --> 0.314884).  Saving model ...
	 Train_Loss: 0.3076 Train_Acc: 91.528 Val_Loss: 0.3149  BEST VAL Loss: 0.3149  Val_Acc: 89.104

Epoch 49: Validation loss decreased (0.314884 --> 0.313859).  Saving model ...
	 Train_Loss: 0.3058 Train_Acc: 91.402 Val_Loss: 0.3139  BEST VAL Loss: 0.3139  Val_Acc: 88.313

Epoch 50: Validation loss decreased (0.313859 --> 0.312881).  Saving model ...
	 Train_Loss: 0.3040 Train_Acc: 91.693 Val_Loss: 0.3129  BEST VAL Loss: 0.3129  Val_Acc: 89.631

Epoch 51: Validation loss decreased (0.312881 --> 0.311798).  Saving model ...
	 Train_Loss: 0.3023 Train_Acc: 91.731 Val_Loss: 0.3118  BEST VAL Loss: 0.3118  Val_Acc: 89.192

Epoch 52: Validation loss decreased (0.311798 --> 0.310588).  Saving model ...
	 Train_Loss: 0.3006 Train_Acc: 91.726 Val_Loss: 0.3106  BEST VAL Loss: 0.3106  Val_Acc: 88.972

Epoch 53: Validation loss decreased (0.310588 --> 0.309573).  Saving model ...
	 Train_Loss: 0.2990 Train_Acc: 91.781 Val_Loss: 0.3096  BEST VAL Loss: 0.3096  Val_Acc: 89.675

Epoch 54: Validation loss decreased (0.309573 --> 0.308712).  Saving model ...
	 Train_Loss: 0.2973 Train_Acc: 91.814 Val_Loss: 0.3087  BEST VAL Loss: 0.3087  Val_Acc: 88.796

Epoch 55: Validation loss decreased (0.308712 --> 0.307971).  Saving model ...
	 Train_Loss: 0.2957 Train_Acc: 91.896 Val_Loss: 0.3080  BEST VAL Loss: 0.3080  Val_Acc: 88.752

Epoch 56: Validation loss decreased (0.307971 --> 0.307169).  Saving model ...
	 Train_Loss: 0.2940 Train_Acc: 92.110 Val_Loss: 0.3072  BEST VAL Loss: 0.3072  Val_Acc: 88.796

Epoch 57: Validation loss decreased (0.307169 --> 0.306314).  Saving model ...
	 Train_Loss: 0.2925 Train_Acc: 91.704 Val_Loss: 0.3063  BEST VAL Loss: 0.3063  Val_Acc: 89.323

Epoch 58: Validation loss decreased (0.306314 --> 0.305362).  Saving model ...
	 Train_Loss: 0.2911 Train_Acc: 92.193 Val_Loss: 0.3054  BEST VAL Loss: 0.3054  Val_Acc: 89.323

Epoch 59: Validation loss decreased (0.305362 --> 0.304270).  Saving model ...
	 Train_Loss: 0.2897 Train_Acc: 92.011 Val_Loss: 0.3043  BEST VAL Loss: 0.3043  Val_Acc: 89.279

Epoch 60: Validation loss decreased (0.304270 --> 0.303216).  Saving model ...
	 Train_Loss: 0.2882 Train_Acc: 92.215 Val_Loss: 0.3032  BEST VAL Loss: 0.3032  Val_Acc: 89.192

Epoch 61: Validation loss decreased (0.303216 --> 0.302380).  Saving model ...
	 Train_Loss: 0.2868 Train_Acc: 92.231 Val_Loss: 0.3024  BEST VAL Loss: 0.3024  Val_Acc: 89.543

Epoch 62: Validation loss decreased (0.302380 --> 0.301330).  Saving model ...
	 Train_Loss: 0.2853 Train_Acc: 92.495 Val_Loss: 0.3013  BEST VAL Loss: 0.3013  Val_Acc: 89.455

Epoch 63: Validation loss decreased (0.301330 --> 0.300452).  Saving model ...
	 Train_Loss: 0.2840 Train_Acc: 92.303 Val_Loss: 0.3005  BEST VAL Loss: 0.3005  Val_Acc: 89.587

Epoch 64: Validation loss decreased (0.300452 --> 0.299611).  Saving model ...
	 Train_Loss: 0.2826 Train_Acc: 92.325 Val_Loss: 0.2996  BEST VAL Loss: 0.2996  Val_Acc: 88.708

Epoch 65: Validation loss decreased (0.299611 --> 0.298762).  Saving model ...
	 Train_Loss: 0.2813 Train_Acc: 92.391 Val_Loss: 0.2988  BEST VAL Loss: 0.2988  Val_Acc: 89.411

Epoch 66: Validation loss decreased (0.298762 --> 0.298057).  Saving model ...
	 Train_Loss: 0.2800 Train_Acc: 92.385 Val_Loss: 0.2981  BEST VAL Loss: 0.2981  Val_Acc: 89.455

Epoch 67: Validation loss decreased (0.298057 --> 0.297224).  Saving model ...
	 Train_Loss: 0.2787 Train_Acc: 92.402 Val_Loss: 0.2972  BEST VAL Loss: 0.2972  Val_Acc: 89.895

Epoch 68: Validation loss decreased (0.297224 --> 0.296576).  Saving model ...
	 Train_Loss: 0.2775 Train_Acc: 92.621 Val_Loss: 0.2966  BEST VAL Loss: 0.2966  Val_Acc: 89.279

Epoch 69: Validation loss decreased (0.296576 --> 0.296048).  Saving model ...
	 Train_Loss: 0.2762 Train_Acc: 92.605 Val_Loss: 0.2960  BEST VAL Loss: 0.2960  Val_Acc: 89.631

Epoch 70: Validation loss decreased (0.296048 --> 0.295384).  Saving model ...
	 Train_Loss: 0.2750 Train_Acc: 92.489 Val_Loss: 0.2954  BEST VAL Loss: 0.2954  Val_Acc: 89.543

Epoch 71: Validation loss decreased (0.295384 --> 0.294654).  Saving model ...
	 Train_Loss: 0.2737 Train_Acc: 92.825 Val_Loss: 0.2947  BEST VAL Loss: 0.2947  Val_Acc: 89.499

Epoch 72: Validation loss decreased (0.294654 --> 0.294129).  Saving model ...
	 Train_Loss: 0.2726 Train_Acc: 92.682 Val_Loss: 0.2941  BEST VAL Loss: 0.2941  Val_Acc: 89.851

Epoch 73: Validation loss decreased (0.294129 --> 0.293485).  Saving model ...
	 Train_Loss: 0.2713 Train_Acc: 92.951 Val_Loss: 0.2935  BEST VAL Loss: 0.2935  Val_Acc: 89.148

Epoch 74: Validation loss decreased (0.293485 --> 0.292887).  Saving model ...
	 Train_Loss: 0.2702 Train_Acc: 92.901 Val_Loss: 0.2929  BEST VAL Loss: 0.2929  Val_Acc: 89.411

Epoch 75: Validation loss decreased (0.292887 --> 0.292337).  Saving model ...
	 Train_Loss: 0.2691 Train_Acc: 92.687 Val_Loss: 0.2923  BEST VAL Loss: 0.2923  Val_Acc: 89.719

Epoch 76: Validation loss decreased (0.292337 --> 0.291660).  Saving model ...
	 Train_Loss: 0.2680 Train_Acc: 92.907 Val_Loss: 0.2917  BEST VAL Loss: 0.2917  Val_Acc: 89.455

Epoch 77: Validation loss decreased (0.291660 --> 0.290964).  Saving model ...
	 Train_Loss: 0.2669 Train_Acc: 92.945 Val_Loss: 0.2910  BEST VAL Loss: 0.2910  Val_Acc: 89.982

Epoch 78: Validation loss decreased (0.290964 --> 0.290383).  Saving model ...
	 Train_Loss: 0.2658 Train_Acc: 92.912 Val_Loss: 0.2904  BEST VAL Loss: 0.2904  Val_Acc: 89.323

Epoch 79: Validation loss decreased (0.290383 --> 0.289773).  Saving model ...
	 Train_Loss: 0.2647 Train_Acc: 93.105 Val_Loss: 0.2898  BEST VAL Loss: 0.2898  Val_Acc: 89.982

Epoch 80: Validation loss decreased (0.289773 --> 0.289214).  Saving model ...
	 Train_Loss: 0.2636 Train_Acc: 93.275 Val_Loss: 0.2892  BEST VAL Loss: 0.2892  Val_Acc: 89.982

Epoch 81: Validation loss decreased (0.289214 --> 0.288668).  Saving model ...
	 Train_Loss: 0.2626 Train_Acc: 92.967 Val_Loss: 0.2887  BEST VAL Loss: 0.2887  Val_Acc: 89.851

Epoch 82: Validation loss decreased (0.288668 --> 0.288146).  Saving model ...
	 Train_Loss: 0.2616 Train_Acc: 92.995 Val_Loss: 0.2881  BEST VAL Loss: 0.2881  Val_Acc: 89.675

Epoch 83: Validation loss decreased (0.288146 --> 0.287645).  Saving model ...
	 Train_Loss: 0.2606 Train_Acc: 93.066 Val_Loss: 0.2876  BEST VAL Loss: 0.2876  Val_Acc: 88.752

Epoch 84: Validation loss decreased (0.287645 --> 0.286971).  Saving model ...
	 Train_Loss: 0.2596 Train_Acc: 93.423 Val_Loss: 0.2870  BEST VAL Loss: 0.2870  Val_Acc: 89.587

Epoch 85: Validation loss decreased (0.286971 --> 0.286442).  Saving model ...
	 Train_Loss: 0.2585 Train_Acc: 93.259 Val_Loss: 0.2864  BEST VAL Loss: 0.2864  Val_Acc: 89.411

Epoch 86: Validation loss decreased (0.286442 --> 0.285904).  Saving model ...
	 Train_Loss: 0.2576 Train_Acc: 93.226 Val_Loss: 0.2859  BEST VAL Loss: 0.2859  Val_Acc: 89.323

Epoch 87: Validation loss decreased (0.285904 --> 0.285464).  Saving model ...
	 Train_Loss: 0.2566 Train_Acc: 93.407 Val_Loss: 0.2855  BEST VAL Loss: 0.2855  Val_Acc: 90.070

Epoch 88: Validation loss decreased (0.285464 --> 0.284913).  Saving model ...
	 Train_Loss: 0.2556 Train_Acc: 93.314 Val_Loss: 0.2849  BEST VAL Loss: 0.2849  Val_Acc: 89.938

Epoch 89: Validation loss decreased (0.284913 --> 0.284365).  Saving model ...
	 Train_Loss: 0.2547 Train_Acc: 93.588 Val_Loss: 0.2844  BEST VAL Loss: 0.2844  Val_Acc: 89.499

Epoch 90: Validation loss decreased (0.284365 --> 0.283688).  Saving model ...
	 Train_Loss: 0.2538 Train_Acc: 93.572 Val_Loss: 0.2837  BEST VAL Loss: 0.2837  Val_Acc: 89.851

Epoch 91: Validation loss decreased (0.283688 --> 0.283194).  Saving model ...
	 Train_Loss: 0.2529 Train_Acc: 93.484 Val_Loss: 0.2832  BEST VAL Loss: 0.2832  Val_Acc: 89.148

Epoch 92: Validation loss decreased (0.283194 --> 0.282771).  Saving model ...
	 Train_Loss: 0.2520 Train_Acc: 93.418 Val_Loss: 0.2828  BEST VAL Loss: 0.2828  Val_Acc: 89.631

Epoch 93: Validation loss decreased (0.282771 --> 0.282701).  Saving model ...
	 Train_Loss: 0.2511 Train_Acc: 93.478 Val_Loss: 0.2827  BEST VAL Loss: 0.2827  Val_Acc: 88.664

Epoch 94: Validation loss decreased (0.282701 --> 0.282153).  Saving model ...
	 Train_Loss: 0.2502 Train_Acc: 93.440 Val_Loss: 0.2822  BEST VAL Loss: 0.2822  Val_Acc: 89.851

Epoch 95: Validation loss decreased (0.282153 --> 0.281645).  Saving model ...
	 Train_Loss: 0.2493 Train_Acc: 93.550 Val_Loss: 0.2816  BEST VAL Loss: 0.2816  Val_Acc: 89.499

Epoch 96: Validation loss decreased (0.281645 --> 0.281226).  Saving model ...
	 Train_Loss: 0.2485 Train_Acc: 93.868 Val_Loss: 0.2812  BEST VAL Loss: 0.2812  Val_Acc: 89.455

Epoch 97: Validation loss decreased (0.281226 --> 0.280864).  Saving model ...
	 Train_Loss: 0.2476 Train_Acc: 93.775 Val_Loss: 0.2809  BEST VAL Loss: 0.2809  Val_Acc: 89.236

Epoch 98: Validation loss decreased (0.280864 --> 0.280442).  Saving model ...
	 Train_Loss: 0.2467 Train_Acc: 93.687 Val_Loss: 0.2804  BEST VAL Loss: 0.2804  Val_Acc: 89.982

Epoch 99: Validation loss decreased (0.280442 --> 0.280054).  Saving model ...
	 Train_Loss: 0.2459 Train_Acc: 93.654 Val_Loss: 0.2801  BEST VAL Loss: 0.2801  Val_Acc: 89.587

Thapsigargin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.54      0.54      0.54      9832
           1       0.46      0.46      0.46      8369

    accuracy                           0.51     18201
   macro avg       0.50      0.50      0.50     18201
weighted avg       0.51      0.51      0.51     18201

Thapsigargin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.53      0.53      1229
           1       0.45      0.45      0.45      1047

    accuracy                           0.49      2276
   macro avg       0.49      0.49      0.49      2276
weighted avg       0.49      0.49      0.49      2276

Thapsigargin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.54      0.54      0.54      1229
           1       0.46      0.47      0.47      1047

    accuracy                           0.51      2276
   macro avg       0.50      0.50      0.50      2276
weighted avg       0.51      0.51      0.51      2276

              precision    recall  f1-score   support

           0       0.54      0.54      0.54      1229
           1       0.46      0.47      0.47      1047

    accuracy                           0.51      2276
   macro avg       0.50      0.50      0.50      2276
weighted avg       0.51      0.51      0.51      2276

Thapsigargin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.56      0.55      0.56      4168
           1       0.45      0.45      0.45      3303

    accuracy                           0.51      7471
   macro avg       0.50      0.50      0.50      7471
weighted avg       0.51      0.51      0.51      7471

              precision    recall  f1-score   support

           0       0.56      0.55      0.56      4168
           1       0.45      0.45      0.45      3303

    accuracy                           0.51      7471
   macro avg       0.50      0.50      0.50      7471
weighted avg       0.51      0.51      0.51      7471

completed
