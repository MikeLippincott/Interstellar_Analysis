[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '48d841d7'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'be93653b'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'acd9fa75'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '6070fafb'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (31162, 1276)
Number of total missing values across all columns: 35020
Data Subset Is Off
Wells held out for testing: ['C20' 'L16']
Wells to use for training, validation, and testing ['C16' 'C17' 'C21' 'L17' 'L20' 'L21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.169662).  Saving model ...
	 Train_Loss: 0.3975 Train_Acc: 86.335 Val_Loss: 0.1697  BEST VAL Loss: 0.1697  Val_Acc: 92.562

Epoch 1: Validation loss decreased (0.169662 --> 0.152849).  Saving model ...
	 Train_Loss: 0.2843 Train_Acc: 93.132 Val_Loss: 0.1528  BEST VAL Loss: 0.1528  Val_Acc: 94.258

Epoch 2: Validation loss decreased (0.152849 --> 0.141397).  Saving model ...
	 Train_Loss: 0.2352 Train_Acc: 94.611 Val_Loss: 0.1414  BEST VAL Loss: 0.1414  Val_Acc: 95.476

Epoch 3: Validation loss decreased (0.141397 --> 0.132140).  Saving model ...
	 Train_Loss: 0.2040 Train_Acc: 95.476 Val_Loss: 0.1321  BEST VAL Loss: 0.1321  Val_Acc: 95.998

Epoch 4: Validation loss decreased (0.132140 --> 0.126576).  Saving model ...
	 Train_Loss: 0.1827 Train_Acc: 96.025 Val_Loss: 0.1266  BEST VAL Loss: 0.1266  Val_Acc: 95.520

Epoch 5: Validation loss decreased (0.126576 --> 0.121282).  Saving model ...
	 Train_Loss: 0.1672 Train_Acc: 96.395 Val_Loss: 0.1213  BEST VAL Loss: 0.1213  Val_Acc: 96.129

Epoch 6: Validation loss decreased (0.121282 --> 0.115646).  Saving model ...
	 Train_Loss: 0.1554 Train_Acc: 96.585 Val_Loss: 0.1156  BEST VAL Loss: 0.1156  Val_Acc: 96.781

Epoch 7: Validation loss decreased (0.115646 --> 0.112504).  Saving model ...
	 Train_Loss: 0.1447 Train_Acc: 97.031 Val_Loss: 0.1125  BEST VAL Loss: 0.1125  Val_Acc: 96.477

Epoch 8: Validation loss decreased (0.112504 --> 0.112204).  Saving model ...
	 Train_Loss: 0.1364 Train_Acc: 97.151 Val_Loss: 0.1122  BEST VAL Loss: 0.1122  Val_Acc: 95.955

Epoch 9: Validation loss decreased (0.112204 --> 0.109937).  Saving model ...
	 Train_Loss: 0.1288 Train_Acc: 97.694 Val_Loss: 0.1099  BEST VAL Loss: 0.1099  Val_Acc: 96.868

Epoch 10: Validation loss decreased (0.109937 --> 0.107667).  Saving model ...
	 Train_Loss: 0.1226 Train_Acc: 97.450 Val_Loss: 0.1077  BEST VAL Loss: 0.1077  Val_Acc: 96.912

Epoch 11: Validation loss decreased (0.107667 --> 0.106240).  Saving model ...
	 Train_Loss: 0.1172 Train_Acc: 97.803 Val_Loss: 0.1062  BEST VAL Loss: 0.1062  Val_Acc: 96.651

Epoch 12: Validation loss decreased (0.106240 --> 0.105752).  Saving model ...
	 Train_Loss: 0.1125 Train_Acc: 97.879 Val_Loss: 0.1058  BEST VAL Loss: 0.1058  Val_Acc: 96.651

Epoch 13: Validation loss decreased (0.105752 --> 0.105293).  Saving model ...
	 Train_Loss: 0.1084 Train_Acc: 97.885 Val_Loss: 0.1053  BEST VAL Loss: 0.1053  Val_Acc: 97.129

Epoch 14: Validation loss decreased (0.105293 --> 0.104299).  Saving model ...
	 Train_Loss: 0.1045 Train_Acc: 98.053 Val_Loss: 0.1043  BEST VAL Loss: 0.1043  Val_Acc: 97.303

Epoch 15: Validation loss decreased (0.104299 --> 0.103234).  Saving model ...
	 Train_Loss: 0.1007 Train_Acc: 98.227 Val_Loss: 0.1032  BEST VAL Loss: 0.1032  Val_Acc: 97.129

Epoch 16: Validation loss decreased (0.103234 --> 0.102884).  Saving model ...
	 Train_Loss: 0.0980 Train_Acc: 98.015 Val_Loss: 0.1029  BEST VAL Loss: 0.1029  Val_Acc: 96.999

Epoch 17: Validation loss did not decrease
	 Train_Loss: 0.0951 Train_Acc: 98.157 Val_Loss: 0.1032  BEST VAL Loss: 0.1029  Val_Acc: 97.434

Epoch 18: Validation loss decreased (0.102884 --> 0.102860).  Saving model ...
	 Train_Loss: 0.0930 Train_Acc: 97.754 Val_Loss: 0.1029  BEST VAL Loss: 0.1029  Val_Acc: 96.999

Epoch 19: Validation loss decreased (0.102860 --> 0.102189).  Saving model ...
	 Train_Loss: 0.0907 Train_Acc: 98.010 Val_Loss: 0.1022  BEST VAL Loss: 0.1022  Val_Acc: 97.347

Epoch 20: Validation loss decreased (0.102189 --> 0.101661).  Saving model ...
	 Train_Loss: 0.0887 Train_Acc: 98.140 Val_Loss: 0.1017  BEST VAL Loss: 0.1017  Val_Acc: 97.086

Epoch 21: Validation loss decreased (0.101661 --> 0.100461).  Saving model ...
	 Train_Loss: 0.0866 Train_Acc: 98.380 Val_Loss: 0.1005  BEST VAL Loss: 0.1005  Val_Acc: 97.651

Epoch 22: Validation loss decreased (0.100461 --> 0.099439).  Saving model ...
	 Train_Loss: 0.0846 Train_Acc: 98.434 Val_Loss: 0.0994  BEST VAL Loss: 0.0994  Val_Acc: 97.608

Epoch 23: Validation loss decreased (0.099439 --> 0.098627).  Saving model ...
	 Train_Loss: 0.0829 Train_Acc: 98.341 Val_Loss: 0.0986  BEST VAL Loss: 0.0986  Val_Acc: 97.738

Epoch 24: Validation loss decreased (0.098627 --> 0.098170).  Saving model ...
	 Train_Loss: 0.0810 Train_Acc: 98.624 Val_Loss: 0.0982  BEST VAL Loss: 0.0982  Val_Acc: 97.173

Epoch 25: Validation loss decreased (0.098170 --> 0.097538).  Saving model ...
	 Train_Loss: 0.0796 Train_Acc: 98.216 Val_Loss: 0.0975  BEST VAL Loss: 0.0975  Val_Acc: 97.434

Epoch 26: Validation loss decreased (0.097538 --> 0.097221).  Saving model ...
	 Train_Loss: 0.0783 Train_Acc: 98.260 Val_Loss: 0.0972  BEST VAL Loss: 0.0972  Val_Acc: 97.564

Epoch 27: Validation loss decreased (0.097221 --> 0.096893).  Saving model ...
	 Train_Loss: 0.0770 Train_Acc: 98.374 Val_Loss: 0.0969  BEST VAL Loss: 0.0969  Val_Acc: 97.651

Epoch 28: Validation loss decreased (0.096893 --> 0.096438).  Saving model ...
	 Train_Loss: 0.0755 Train_Acc: 98.706 Val_Loss: 0.0964  BEST VAL Loss: 0.0964  Val_Acc: 97.695

Epoch 29: Validation loss decreased (0.096438 --> 0.095973).  Saving model ...
	 Train_Loss: 0.0742 Train_Acc: 98.586 Val_Loss: 0.0960  BEST VAL Loss: 0.0960  Val_Acc: 97.912

Epoch 30: Validation loss decreased (0.095973 --> 0.095497).  Saving model ...
	 Train_Loss: 0.0729 Train_Acc: 98.510 Val_Loss: 0.0955  BEST VAL Loss: 0.0955  Val_Acc: 97.695

Epoch 31: Validation loss decreased (0.095497 --> 0.095261).  Saving model ...
	 Train_Loss: 0.0719 Train_Acc: 98.592 Val_Loss: 0.0953  BEST VAL Loss: 0.0953  Val_Acc: 97.477

Epoch 32: Validation loss decreased (0.095261 --> 0.094990).  Saving model ...
	 Train_Loss: 0.0707 Train_Acc: 98.646 Val_Loss: 0.0950  BEST VAL Loss: 0.0950  Val_Acc: 97.564

Epoch 33: Validation loss decreased (0.094990 --> 0.094266).  Saving model ...
	 Train_Loss: 0.0696 Train_Acc: 98.526 Val_Loss: 0.0943  BEST VAL Loss: 0.0943  Val_Acc: 97.695

Epoch 34: Validation loss did not decrease
	 Train_Loss: 0.0688 Train_Acc: 98.336 Val_Loss: 0.0945  BEST VAL Loss: 0.0943  Val_Acc: 97.303

Epoch 35: Validation loss decreased (0.094266 --> 0.094099).  Saving model ...
	 Train_Loss: 0.0684 Train_Acc: 98.314 Val_Loss: 0.0941  BEST VAL Loss: 0.0941  Val_Acc: 97.999

Epoch 36: Validation loss decreased (0.094099 --> 0.093216).  Saving model ...
	 Train_Loss: 0.0674 Train_Acc: 98.679 Val_Loss: 0.0932  BEST VAL Loss: 0.0932  Val_Acc: 98.130

Epoch 37: Validation loss decreased (0.093216 --> 0.092845).  Saving model ...
	 Train_Loss: 0.0664 Train_Acc: 98.907 Val_Loss: 0.0928  BEST VAL Loss: 0.0928  Val_Acc: 97.695

Epoch 38: Validation loss decreased (0.092845 --> 0.092696).  Saving model ...
	 Train_Loss: 0.0655 Train_Acc: 98.836 Val_Loss: 0.0927  BEST VAL Loss: 0.0927  Val_Acc: 97.782

Epoch 39: Validation loss decreased (0.092696 --> 0.092378).  Saving model ...
	 Train_Loss: 0.0645 Train_Acc: 98.951 Val_Loss: 0.0924  BEST VAL Loss: 0.0924  Val_Acc: 97.738

Epoch 40: Validation loss decreased (0.092378 --> 0.091885).  Saving model ...
	 Train_Loss: 0.0636 Train_Acc: 99.032 Val_Loss: 0.0919  BEST VAL Loss: 0.0919  Val_Acc: 97.695

Epoch 41: Validation loss decreased (0.091885 --> 0.091405).  Saving model ...
	 Train_Loss: 0.0628 Train_Acc: 98.755 Val_Loss: 0.0914  BEST VAL Loss: 0.0914  Val_Acc: 97.825

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.0621 Train_Acc: 98.738 Val_Loss: 0.0915  BEST VAL Loss: 0.0914  Val_Acc: 97.564

Epoch 43: Validation loss decreased (0.091405 --> 0.091030).  Saving model ...
	 Train_Loss: 0.0614 Train_Acc: 98.630 Val_Loss: 0.0910  BEST VAL Loss: 0.0910  Val_Acc: 97.912

Epoch 44: Validation loss decreased (0.091030 --> 0.091021).  Saving model ...
	 Train_Loss: 0.0608 Train_Acc: 98.777 Val_Loss: 0.0910  BEST VAL Loss: 0.0910  Val_Acc: 97.695

Epoch 45: Validation loss decreased (0.091021 --> 0.090846).  Saving model ...
	 Train_Loss: 0.0602 Train_Acc: 98.782 Val_Loss: 0.0908  BEST VAL Loss: 0.0908  Val_Acc: 97.956

Epoch 46: Validation loss decreased (0.090846 --> 0.090698).  Saving model ...
	 Train_Loss: 0.0596 Train_Acc: 98.738 Val_Loss: 0.0907  BEST VAL Loss: 0.0907  Val_Acc: 97.869

Epoch 47: Validation loss decreased (0.090698 --> 0.090636).  Saving model ...
	 Train_Loss: 0.0589 Train_Acc: 98.815 Val_Loss: 0.0906  BEST VAL Loss: 0.0906  Val_Acc: 97.521

Epoch 48: Validation loss decreased (0.090636 --> 0.090156).  Saving model ...
	 Train_Loss: 0.0585 Train_Acc: 98.613 Val_Loss: 0.0902  BEST VAL Loss: 0.0902  Val_Acc: 97.956

Epoch 49: Validation loss decreased (0.090156 --> 0.089904).  Saving model ...
	 Train_Loss: 0.0579 Train_Acc: 98.858 Val_Loss: 0.0899  BEST VAL Loss: 0.0899  Val_Acc: 97.782

Epoch 50: Validation loss decreased (0.089904 --> 0.089866).  Saving model ...
	 Train_Loss: 0.0573 Train_Acc: 98.923 Val_Loss: 0.0899  BEST VAL Loss: 0.0899  Val_Acc: 97.825

Epoch 51: Validation loss decreased (0.089866 --> 0.089442).  Saving model ...
	 Train_Loss: 0.0569 Train_Acc: 98.760 Val_Loss: 0.0894  BEST VAL Loss: 0.0894  Val_Acc: 98.173

Epoch 52: Validation loss decreased (0.089442 --> 0.089314).  Saving model ...
	 Train_Loss: 0.0563 Train_Acc: 98.972 Val_Loss: 0.0893  BEST VAL Loss: 0.0893  Val_Acc: 98.260

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.0558 Train_Acc: 98.902 Val_Loss: 0.0895  BEST VAL Loss: 0.0893  Val_Acc: 98.086

Epoch 54: Validation loss decreased (0.089314 --> 0.089029).  Saving model ...
	 Train_Loss: 0.0553 Train_Acc: 98.836 Val_Loss: 0.0890  BEST VAL Loss: 0.0890  Val_Acc: 98.086

Epoch 55: Validation loss decreased (0.089029 --> 0.088777).  Saving model ...
	 Train_Loss: 0.0549 Train_Acc: 98.912 Val_Loss: 0.0888  BEST VAL Loss: 0.0888  Val_Acc: 98.043

Epoch 56: Validation loss decreased (0.088777 --> 0.088757).  Saving model ...
	 Train_Loss: 0.0543 Train_Acc: 98.983 Val_Loss: 0.0888  BEST VAL Loss: 0.0888  Val_Acc: 97.869

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.0538 Train_Acc: 99.010 Val_Loss: 0.0888  BEST VAL Loss: 0.0888  Val_Acc: 97.608

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.0535 Train_Acc: 98.619 Val_Loss: 0.0888  BEST VAL Loss: 0.0888  Val_Acc: 97.608

Epoch 59: Validation loss decreased (0.088757 --> 0.088543).  Saving model ...
	 Train_Loss: 0.0531 Train_Acc: 98.885 Val_Loss: 0.0885  BEST VAL Loss: 0.0885  Val_Acc: 97.825

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.0527 Train_Acc: 99.027 Val_Loss: 0.0886  BEST VAL Loss: 0.0885  Val_Acc: 97.825

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.0523 Train_Acc: 98.940 Val_Loss: 0.0887  BEST VAL Loss: 0.0885  Val_Acc: 97.912

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.0520 Train_Acc: 98.738 Val_Loss: 0.0887  BEST VAL Loss: 0.0885  Val_Acc: 97.869

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.0516 Train_Acc: 98.874 Val_Loss: 0.0889  BEST VAL Loss: 0.0885  Val_Acc: 97.912

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.0512 Train_Acc: 98.918 Val_Loss: 0.0887  BEST VAL Loss: 0.0885  Val_Acc: 97.956

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.0508 Train_Acc: 98.972 Val_Loss: 0.0887  BEST VAL Loss: 0.0885  Val_Acc: 97.869

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.0504 Train_Acc: 99.059 Val_Loss: 0.0890  BEST VAL Loss: 0.0885  Val_Acc: 97.608

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.0500 Train_Acc: 98.929 Val_Loss: 0.0890  BEST VAL Loss: 0.0885  Val_Acc: 98.086

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.0496 Train_Acc: 99.032 Val_Loss: 0.0891  BEST VAL Loss: 0.0885  Val_Acc: 98.130

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.0493 Train_Acc: 99.005 Val_Loss: 0.0890  BEST VAL Loss: 0.0885  Val_Acc: 97.869

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.0489 Train_Acc: 98.999 Val_Loss: 0.0891  BEST VAL Loss: 0.0885  Val_Acc: 97.956

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.0486 Train_Acc: 98.864 Val_Loss: 0.0893  BEST VAL Loss: 0.0885  Val_Acc: 97.521

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.0483 Train_Acc: 99.027 Val_Loss: 0.0893  BEST VAL Loss: 0.0885  Val_Acc: 97.912

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.0480 Train_Acc: 98.934 Val_Loss: 0.0892  BEST VAL Loss: 0.0885  Val_Acc: 98.086

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.0476 Train_Acc: 99.070 Val_Loss: 0.0891  BEST VAL Loss: 0.0885  Val_Acc: 98.043

Epoch 75: Validation loss did not decrease
Early stopped at epoch : 75
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     10451
           1       1.00      1.00      1.00      7939

    accuracy                           1.00     18390
   macro avg       1.00      1.00      1.00     18390
weighted avg       1.00      1.00      1.00     18390

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      0.98      0.98      1307
           1       0.97      0.98      0.97       992

    accuracy                           0.98      2299
   macro avg       0.98      0.98      0.98      2299
weighted avg       0.98      0.98      0.98      2299

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      0.98      0.98      1307
           1       0.98      0.98      0.98       992

    accuracy                           0.98      2299
   macro avg       0.98      0.98      0.98      2299
weighted avg       0.98      0.98      0.98      2299

              precision    recall  f1-score   support

           0       0.99      0.98      0.98      1307
           1       0.98      0.98      0.98       992

    accuracy                           0.98      2299
   macro avg       0.98      0.98      0.98      2299
weighted avg       0.98      0.98      0.98      2299

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.95      0.99      0.97      4445
           1       0.98      0.94      0.96      3729

    accuracy                           0.96      8174
   macro avg       0.97      0.96      0.96      8174
weighted avg       0.97      0.96      0.96      8174

              precision    recall  f1-score   support

           0       0.95      0.99      0.97      4445
           1       0.98      0.94      0.96      3729

    accuracy                           0.96      8174
   macro avg       0.97      0.96      0.96      8174
weighted avg       0.97      0.96      0.96      8174

completed
