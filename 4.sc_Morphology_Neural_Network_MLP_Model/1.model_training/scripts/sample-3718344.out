[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 18688 bytes to train_binary_model.py
[NbConvertApp] Converting notebook ../notebooks/train_multiclass_model.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: MissingIDFieldWarning: Code cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.
  validate(nb)
[NbConvertApp] Writing 31106 bytes to train_multiclass_model.py
[NbConvertApp] Converting notebook ../notebooks/train_regression_model.ipynb to script
[NbConvertApp] Writing 25120 bytes to train_regression_model.py
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:313: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels.drop_duplicates(inplace=True)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1015: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1016: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1015: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1016: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1036: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:577: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:651: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1219: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:879: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1219: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:1095: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
SHSY5Y MultiClass_MLP_h202_remove True
[0.954878893196544, 0.4803479499984947, 0.5647731568049614]
Data Subset Is Off
(156754,) (39189,) (230445,) (144614,)
(156754,) (39189,) (230445,) (144614,)
571002
(7972,) (85003,) (63779,)
(1993,) (21251,) (15945,)
(9965,) (106254,) (114226,)
(7048,) (71293,) (66273,)
(156754, 1251) (39189, 1251) (230445, 1251) (144614, 1251)
(156754,) (39189,) (230445,) (144614,)
Number of in features:  1251
Number of out features:  3
Multi_Class
SGD
Epoch 0: Validation loss decreased (inf --> 0.618106).  Saving model ...
	 Train_Loss: 0.6844 Train_Acc: 68.197 Val_Loss: 0.6181  BEST VAL Loss: 0.6181  Val_Acc: 70.096

Epoch 1: Validation loss decreased (0.618106 --> 0.608744).  Saving model ...
	 Train_Loss: 0.6584 Train_Acc: 70.199 Val_Loss: 0.6087  BEST VAL Loss: 0.6087  Val_Acc: 71.992

Epoch 2: Validation loss decreased (0.608744 --> 0.600666).  Saving model ...
	 Train_Loss: 0.6440 Train_Acc: 70.771 Val_Loss: 0.6007  BEST VAL Loss: 0.6007  Val_Acc: 72.480

Epoch 3: Validation loss decreased (0.600666 --> 0.594096).  Saving model ...
	 Train_Loss: 0.6341 Train_Acc: 71.397 Val_Loss: 0.5941  BEST VAL Loss: 0.5941  Val_Acc: 72.480

Epoch 4: Validation loss decreased (0.594096 --> 0.588717).  Saving model ...
	 Train_Loss: 0.6259 Train_Acc: 71.832 Val_Loss: 0.5887  BEST VAL Loss: 0.5887  Val_Acc: 72.615

Epoch 5: Validation loss decreased (0.588717 --> 0.584869).  Saving model ...
	 Train_Loss: 0.6191 Train_Acc: 72.249 Val_Loss: 0.5849  BEST VAL Loss: 0.5849  Val_Acc: 73.873

Epoch 6: Validation loss decreased (0.584869 --> 0.581501).  Saving model ...
	 Train_Loss: 0.6135 Train_Acc: 72.308 Val_Loss: 0.5815  BEST VAL Loss: 0.5815  Val_Acc: 73.891

Epoch 7: Validation loss decreased (0.581501 --> 0.578438).  Saving model ...
	 Train_Loss: 0.6088 Train_Acc: 72.521 Val_Loss: 0.5784  BEST VAL Loss: 0.5784  Val_Acc: 73.717

Epoch 8: Validation loss decreased (0.578438 --> 0.577096).  Saving model ...
	 Train_Loss: 0.6045 Train_Acc: 72.789 Val_Loss: 0.5771  BEST VAL Loss: 0.5771  Val_Acc: 72.975

Epoch 9: Validation loss decreased (0.577096 --> 0.575273).  Saving model ...
	 Train_Loss: 0.6007 Train_Acc: 72.932 Val_Loss: 0.5753  BEST VAL Loss: 0.5753  Val_Acc: 73.010

Epoch 10: Validation loss decreased (0.575273 --> 0.573466).  Saving model ...
	 Train_Loss: 0.5974 Train_Acc: 72.962 Val_Loss: 0.5735  BEST VAL Loss: 0.5735  Val_Acc: 73.965

Epoch 11: Validation loss decreased (0.573466 --> 0.572023).  Saving model ...
	 Train_Loss: 0.5945 Train_Acc: 73.115 Val_Loss: 0.5720  BEST VAL Loss: 0.5720  Val_Acc: 74.120

Epoch 12: Validation loss decreased (0.572023 --> 0.570532).  Saving model ...
	 Train_Loss: 0.5915 Train_Acc: 73.283 Val_Loss: 0.5705  BEST VAL Loss: 0.5705  Val_Acc: 74.554

Epoch 13: Validation loss decreased (0.570532 --> 0.569471).  Saving model ...
	 Train_Loss: 0.5890 Train_Acc: 73.321 Val_Loss: 0.5695  BEST VAL Loss: 0.5695  Val_Acc: 73.865

Epoch 14: Validation loss decreased (0.569471 --> 0.568241).  Saving model ...
	 Train_Loss: 0.5866 Train_Acc: 73.407 Val_Loss: 0.5682  BEST VAL Loss: 0.5682  Val_Acc: 74.478

Epoch 15: Validation loss decreased (0.568241 --> 0.566919).  Saving model ...
	 Train_Loss: 0.5844 Train_Acc: 73.559 Val_Loss: 0.5669  BEST VAL Loss: 0.5669  Val_Acc: 73.712

Epoch 16: Validation loss decreased (0.566919 --> 0.566179).  Saving model ...
	 Train_Loss: 0.5823 Train_Acc: 73.616 Val_Loss: 0.5662  BEST VAL Loss: 0.5662  Val_Acc: 74.358

Epoch 17: Validation loss decreased (0.566179 --> 0.565213).  Saving model ...
	 Train_Loss: 0.5803 Train_Acc: 73.731 Val_Loss: 0.5652  BEST VAL Loss: 0.5652  Val_Acc: 74.771

Epoch 18: Validation loss decreased (0.565213 --> 0.564729).  Saving model ...
	 Train_Loss: 0.5785 Train_Acc: 73.684 Val_Loss: 0.5647  BEST VAL Loss: 0.5647  Val_Acc: 73.179

Epoch 19: Validation loss decreased (0.564729 --> 0.563899).  Saving model ...
	 Train_Loss: 0.5768 Train_Acc: 73.784 Val_Loss: 0.5639  BEST VAL Loss: 0.5639  Val_Acc: 74.587

Epoch 20: Validation loss decreased (0.563899 --> 0.563348).  Saving model ...
	 Train_Loss: 0.5751 Train_Acc: 73.890 Val_Loss: 0.5633  BEST VAL Loss: 0.5633  Val_Acc: 74.774

Epoch 21: Validation loss decreased (0.563348 --> 0.562695).  Saving model ...
	 Train_Loss: 0.5735 Train_Acc: 74.049 Val_Loss: 0.5627  BEST VAL Loss: 0.5627  Val_Acc: 73.855

Epoch 22: Validation loss decreased (0.562695 --> 0.562213).  Saving model ...
	 Train_Loss: 0.5719 Train_Acc: 74.093 Val_Loss: 0.5622  BEST VAL Loss: 0.5622  Val_Acc: 74.049

Epoch 23: Validation loss decreased (0.562213 --> 0.561400).  Saving model ...
	 Train_Loss: 0.5705 Train_Acc: 74.207 Val_Loss: 0.5614  BEST VAL Loss: 0.5614  Val_Acc: 74.495

Epoch 24: Validation loss decreased (0.561400 --> 0.560866).  Saving model ...
	 Train_Loss: 0.5690 Train_Acc: 74.190 Val_Loss: 0.5609  BEST VAL Loss: 0.5609  Val_Acc: 73.832

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.5677 Train_Acc: 74.159 Val_Loss: 0.5610  BEST VAL Loss: 0.5609  Val_Acc: 72.408

Epoch 26: Validation loss decreased (0.560866 --> 0.560672).  Saving model ...
	 Train_Loss: 0.5664 Train_Acc: 74.346 Val_Loss: 0.5607  BEST VAL Loss: 0.5607  Val_Acc: 73.153

Epoch 27: Validation loss decreased (0.560672 --> 0.560355).  Saving model ...
	 Train_Loss: 0.5652 Train_Acc: 74.456 Val_Loss: 0.5604  BEST VAL Loss: 0.5604  Val_Acc: 74.250

Epoch 28: Validation loss decreased (0.560355 --> 0.560297).  Saving model ...
	 Train_Loss: 0.5640 Train_Acc: 74.389 Val_Loss: 0.5603  BEST VAL Loss: 0.5603  Val_Acc: 74.955

Epoch 29: Validation loss decreased (0.560297 --> 0.559936).  Saving model ...
	 Train_Loss: 0.5629 Train_Acc: 74.379 Val_Loss: 0.5599  BEST VAL Loss: 0.5599  Val_Acc: 74.437

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.5618 Train_Acc: 74.422 Val_Loss: 0.5601  BEST VAL Loss: 0.5599  Val_Acc: 72.444

Epoch 31: Validation loss decreased (0.559936 --> 0.559758).  Saving model ...
	 Train_Loss: 0.5607 Train_Acc: 74.480 Val_Loss: 0.5598  BEST VAL Loss: 0.5598  Val_Acc: 75.230

Epoch 32: Validation loss decreased (0.559758 --> 0.559163).  Saving model ...
	 Train_Loss: 0.5598 Train_Acc: 74.537 Val_Loss: 0.5592  BEST VAL Loss: 0.5592  Val_Acc: 75.077

Epoch 33: Validation loss decreased (0.559163 --> 0.559055).  Saving model ...
	 Train_Loss: 0.5587 Train_Acc: 74.579 Val_Loss: 0.5591  BEST VAL Loss: 0.5591  Val_Acc: 74.845

Epoch 34: Validation loss decreased (0.559055 --> 0.558880).  Saving model ...
	 Train_Loss: 0.5578 Train_Acc: 74.635 Val_Loss: 0.5589  BEST VAL Loss: 0.5589  Val_Acc: 73.592

Epoch 35: Validation loss decreased (0.558880 --> 0.558611).  Saving model ...
	 Train_Loss: 0.5568 Train_Acc: 74.618 Val_Loss: 0.5586  BEST VAL Loss: 0.5586  Val_Acc: 74.840

Epoch 36: Validation loss decreased (0.558611 --> 0.558272).  Saving model ...
	 Train_Loss: 0.5559 Train_Acc: 74.836 Val_Loss: 0.5583  BEST VAL Loss: 0.5583  Val_Acc: 75.105

Epoch 37: Validation loss decreased (0.558272 --> 0.557995).  Saving model ...
	 Train_Loss: 0.5550 Train_Acc: 74.739 Val_Loss: 0.5580  BEST VAL Loss: 0.5580  Val_Acc: 75.266

Epoch 38: Validation loss decreased (0.557995 --> 0.557951).  Saving model ...
	 Train_Loss: 0.5542 Train_Acc: 74.847 Val_Loss: 0.5580  BEST VAL Loss: 0.5580  Val_Acc: 75.029

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.5534 Train_Acc: 74.797 Val_Loss: 0.5580  BEST VAL Loss: 0.5580  Val_Acc: 74.314

Epoch 40: Validation loss decreased (0.557951 --> 0.557931).  Saving model ...
	 Train_Loss: 0.5526 Train_Acc: 74.825 Val_Loss: 0.5579  BEST VAL Loss: 0.5579  Val_Acc: 74.911

Epoch 41: Validation loss decreased (0.557931 --> 0.557673).  Saving model ...
	 Train_Loss: 0.5518 Train_Acc: 74.868 Val_Loss: 0.5577  BEST VAL Loss: 0.5577  Val_Acc: 75.077

Epoch 42: Validation loss decreased (0.557673 --> 0.557482).  Saving model ...
	 Train_Loss: 0.5510 Train_Acc: 74.931 Val_Loss: 0.5575  BEST VAL Loss: 0.5575  Val_Acc: 75.212

Epoch 43: Validation loss decreased (0.557482 --> 0.557412).  Saving model ...
	 Train_Loss: 0.5503 Train_Acc: 75.073 Val_Loss: 0.5574  BEST VAL Loss: 0.5574  Val_Acc: 74.740

Epoch 44: Validation loss decreased (0.557412 --> 0.557311).  Saving model ...
	 Train_Loss: 0.5496 Train_Acc: 74.994 Val_Loss: 0.5573  BEST VAL Loss: 0.5573  Val_Acc: 75.154

Epoch 45: Validation loss decreased (0.557311 --> 0.557249).  Saving model ...
	 Train_Loss: 0.5489 Train_Acc: 74.970 Val_Loss: 0.5572  BEST VAL Loss: 0.5572  Val_Acc: 75.059

Epoch 46: Validation loss decreased (0.557249 --> 0.557210).  Saving model ...
	 Train_Loss: 0.5482 Train_Acc: 74.952 Val_Loss: 0.5572  BEST VAL Loss: 0.5572  Val_Acc: 75.103

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.5475 Train_Acc: 74.937 Val_Loss: 0.5572  BEST VAL Loss: 0.5572  Val_Acc: 75.215

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.5469 Train_Acc: 75.026 Val_Loss: 0.5575  BEST VAL Loss: 0.5572  Val_Acc: 74.809

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.5462 Train_Acc: 74.999 Val_Loss: 0.5575  BEST VAL Loss: 0.5572  Val_Acc: 74.794

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.5456 Train_Acc: 75.140 Val_Loss: 0.5574  BEST VAL Loss: 0.5572  Val_Acc: 75.253

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.5450 Train_Acc: 75.264 Val_Loss: 0.5573  BEST VAL Loss: 0.5572  Val_Acc: 75.409

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.5444 Train_Acc: 75.213 Val_Loss: 0.5573  BEST VAL Loss: 0.5572  Val_Acc: 75.644

Epoch 53: Validation loss decreased (0.557210 --> 0.557202).  Saving model ...
	 Train_Loss: 0.5438 Train_Acc: 75.120 Val_Loss: 0.5572  BEST VAL Loss: 0.5572  Val_Acc: 74.929

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.5432 Train_Acc: 75.095 Val_Loss: 0.5574  BEST VAL Loss: 0.5572  Val_Acc: 72.444

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.5427 Train_Acc: 75.125 Val_Loss: 0.5574  BEST VAL Loss: 0.5572  Val_Acc: 74.802

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.5421 Train_Acc: 75.340 Val_Loss: 0.5574  BEST VAL Loss: 0.5572  Val_Acc: 75.506

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.5416 Train_Acc: 75.221 Val_Loss: 0.5573  BEST VAL Loss: 0.5572  Val_Acc: 75.271

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.5411 Train_Acc: 75.203 Val_Loss: 0.5572  BEST VAL Loss: 0.5572  Val_Acc: 74.776

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.5406 Train_Acc: 75.196 Val_Loss: 0.5573  BEST VAL Loss: 0.5572  Val_Acc: 75.529

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.5400 Train_Acc: 75.323 Val_Loss: 0.5573  BEST VAL Loss: 0.5572  Val_Acc: 75.026

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.5395 Train_Acc: 75.381 Val_Loss: 0.5572  BEST VAL Loss: 0.5572  Val_Acc: 75.062

Epoch 62: Validation loss decreased (0.557202 --> 0.557117).  Saving model ...
	 Train_Loss: 0.5390 Train_Acc: 75.294 Val_Loss: 0.5571  BEST VAL Loss: 0.5571  Val_Acc: 74.643

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.5385 Train_Acc: 75.328 Val_Loss: 0.5571  BEST VAL Loss: 0.5571  Val_Acc: 75.376

Epoch 64: Validation loss decreased (0.557117 --> 0.557037).  Saving model ...
	 Train_Loss: 0.5381 Train_Acc: 75.338 Val_Loss: 0.5570  BEST VAL Loss: 0.5570  Val_Acc: 75.491

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.5376 Train_Acc: 75.395 Val_Loss: 0.5571  BEST VAL Loss: 0.5570  Val_Acc: 75.292

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.5372 Train_Acc: 75.428 Val_Loss: 0.5572  BEST VAL Loss: 0.5570  Val_Acc: 74.937

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.5367 Train_Acc: 75.347 Val_Loss: 0.5572  BEST VAL Loss: 0.5570  Val_Acc: 75.485

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.5363 Train_Acc: 75.363 Val_Loss: 0.5571  BEST VAL Loss: 0.5570  Val_Acc: 75.330

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.5359 Train_Acc: 75.370 Val_Loss: 0.5572  BEST VAL Loss: 0.5570  Val_Acc: 75.771

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.5354 Train_Acc: 75.458 Val_Loss: 0.5574  BEST VAL Loss: 0.5570  Val_Acc: 74.289

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.5350 Train_Acc: 75.377 Val_Loss: 0.5574  BEST VAL Loss: 0.5570  Val_Acc: 75.238

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.5346 Train_Acc: 75.492 Val_Loss: 0.5575  BEST VAL Loss: 0.5570  Val_Acc: 74.189

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.5342 Train_Acc: 75.481 Val_Loss: 0.5576  BEST VAL Loss: 0.5570  Val_Acc: 75.376

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.5338 Train_Acc: 75.578 Val_Loss: 0.5575  BEST VAL Loss: 0.5570  Val_Acc: 75.090

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.5335 Train_Acc: 75.437 Val_Loss: 0.5574  BEST VAL Loss: 0.5570  Val_Acc: 75.205

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.5331 Train_Acc: 75.631 Val_Loss: 0.5574  BEST VAL Loss: 0.5570  Val_Acc: 74.837

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.5327 Train_Acc: 75.630 Val_Loss: 0.5576  BEST VAL Loss: 0.5570  Val_Acc: 74.592

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.5323 Train_Acc: 75.589 Val_Loss: 0.5577  BEST VAL Loss: 0.5570  Val_Acc: 74.990

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.5319 Train_Acc: 75.496 Val_Loss: 0.5577  BEST VAL Loss: 0.5570  Val_Acc: 75.215

Epoch 80: Validation loss did not decrease
Early stopped at epoch : 80
MultiClass_MLP_h202_remove_shuffle
              precision    recall  f1-score   support

           0       0.05      0.05      0.05      7972
           1       0.54      0.59      0.56     85003
           2       0.41      0.36      0.38     63779

    accuracy                           0.47    156754
   macro avg       0.33      0.33      0.33    156754
weighted avg       0.46      0.47      0.46    156754

MultiClass_MLP_h202_remove_shuffle
              precision    recall  f1-score   support

           0       0.05      0.05      0.05      1993
           1       0.54      0.59      0.56     21251
           2       0.41      0.36      0.38     15945

    accuracy                           0.47     39189
   macro avg       0.33      0.33      0.33     39189
weighted avg       0.46      0.47      0.46     39189

MultiClass_MLP_h202_remove_shuffle
              precision    recall  f1-score   support

           0       0.04      0.04      0.04      9965
           1       0.46      0.56      0.51    106254
           2       0.50      0.39      0.44    114226

    accuracy                           0.46    230445
   macro avg       0.33      0.33      0.33    230445
weighted avg       0.46      0.46      0.45    230445

Precision for class 0: 0.043495730788548466
Recall for class 0: 0.04345208228800803
Precision for class 1: 0.4614733797898688
Recall for class 1: 0.5646658008169104
Precision for class 2: 0.4972589415977718
Recall for class 2: 0.39386829618475655
3
              precision    recall  f1-score   support

           0       0.04      0.04      0.04      9965
           1       0.46      0.56      0.51    106254
           2       0.50      0.39      0.44    114226

    accuracy                           0.46    230445
   macro avg       0.33      0.33      0.33    230445
weighted avg       0.46      0.46      0.45    230445

MultiClass_MLP_h202_remove_shuffle
              precision    recall  f1-score   support

           0       0.05      0.05      0.05      7048
           1       0.49      0.57      0.53     71293
           2       0.46      0.38      0.42     66273

    accuracy                           0.46    144614
   macro avg       0.33      0.33      0.33    144614
weighted avg       0.46      0.46      0.46    144614

Precision for class 0: 0.04867389993972272
Recall for class 0: 0.045828603859250854
Precision for class 1: 0.4938947063299394
Recall for class 1: 0.5735906751013423
Precision for class 2: 0.4589623239883293
Recall for class 2: 0.3821465755284958
3
              precision    recall  f1-score   support

           0       0.05      0.05      0.05      7048
           1       0.49      0.57      0.53     71293
           2       0.46      0.38      0.42     66273

    accuracy                           0.46    144614
   macro avg       0.33      0.33      0.33    144614
weighted avg       0.46      0.46      0.46    144614

Done
