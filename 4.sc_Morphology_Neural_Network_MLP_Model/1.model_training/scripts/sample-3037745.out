[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '3e392b99'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '46780331'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '7c969999'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e89b9867'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 treatment_name: DMSO_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
TREATMENT_NAME: DMSO_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (50045, 1276)
Number of total missing values across all columns: 71286
Data Subset Is Off
Wells held out for testing: ['I14' 'M21']
Wells to use for training, validation, and testing ['B14' 'C14' 'B15' 'C15' 'J14' 'I15' 'J15' 'M16' 'M17' 'M20']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.188258).  Saving model ...
	 Train_Loss: 0.3435 Train_Acc: 83.160 Val_Loss: 0.1883  BEST VAL Loss: 0.1883  Val_Acc: 93.506

Epoch 1: Validation loss decreased (0.188258 --> 0.152987).  Saving model ...
	 Train_Loss: 0.2764 Train_Acc: 89.247 Val_Loss: 0.1530  BEST VAL Loss: 0.1530  Val_Acc: 96.022

Epoch 2: Validation loss decreased (0.152987 --> 0.135524).  Saving model ...
	 Train_Loss: 0.2400 Train_Acc: 91.294 Val_Loss: 0.1355  BEST VAL Loss: 0.1355  Val_Acc: 96.214

Epoch 3: Validation loss decreased (0.135524 --> 0.125152).  Saving model ...
	 Train_Loss: 0.2164 Train_Acc: 94.314 Val_Loss: 0.1252  BEST VAL Loss: 0.1252  Val_Acc: 96.981

Epoch 4: Validation loss decreased (0.125152 --> 0.116936).  Saving model ...
	 Train_Loss: 0.2024 Train_Acc: 94.472 Val_Loss: 0.1169  BEST VAL Loss: 0.1169  Val_Acc: 97.268

Epoch 5: Validation loss decreased (0.116936 --> 0.112517).  Saving model ...
	 Train_Loss: 0.1896 Train_Acc: 95.227 Val_Loss: 0.1125  BEST VAL Loss: 0.1125  Val_Acc: 97.316

Epoch 6: Validation loss decreased (0.112517 --> 0.106449).  Saving model ...
	 Train_Loss: 0.1792 Train_Acc: 95.659 Val_Loss: 0.1064  BEST VAL Loss: 0.1064  Val_Acc: 97.556

Epoch 7: Validation loss decreased (0.106449 --> 0.102541).  Saving model ...
	 Train_Loss: 0.1701 Train_Acc: 95.815 Val_Loss: 0.1025  BEST VAL Loss: 0.1025  Val_Acc: 97.604

Epoch 8: Validation loss decreased (0.102541 --> 0.098954).  Saving model ...
	 Train_Loss: 0.1629 Train_Acc: 96.048 Val_Loss: 0.0990  BEST VAL Loss: 0.0990  Val_Acc: 97.556

Epoch 9: Validation loss decreased (0.098954 --> 0.096400).  Saving model ...
	 Train_Loss: 0.1564 Train_Acc: 96.111 Val_Loss: 0.0964  BEST VAL Loss: 0.0964  Val_Acc: 97.723

Epoch 10: Validation loss decreased (0.096400 --> 0.093420).  Saving model ...
	 Train_Loss: 0.1511 Train_Acc: 95.833 Val_Loss: 0.0934  BEST VAL Loss: 0.0934  Val_Acc: 97.915

Epoch 11: Validation loss decreased (0.093420 --> 0.090748).  Saving model ...
	 Train_Loss: 0.1470 Train_Acc: 95.928 Val_Loss: 0.0907  BEST VAL Loss: 0.0907  Val_Acc: 97.795

Epoch 12: Validation loss decreased (0.090748 --> 0.089808).  Saving model ...
	 Train_Loss: 0.1428 Train_Acc: 96.420 Val_Loss: 0.0898  BEST VAL Loss: 0.0898  Val_Acc: 97.364

Epoch 13: Validation loss decreased (0.089808 --> 0.087808).  Saving model ...
	 Train_Loss: 0.1391 Train_Acc: 96.201 Val_Loss: 0.0878  BEST VAL Loss: 0.0878  Val_Acc: 97.843

Epoch 14: Validation loss decreased (0.087808 --> 0.085950).  Saving model ...
	 Train_Loss: 0.1356 Train_Acc: 96.558 Val_Loss: 0.0860  BEST VAL Loss: 0.0860  Val_Acc: 98.059

Epoch 15: Validation loss decreased (0.085950 --> 0.084966).  Saving model ...
	 Train_Loss: 0.1324 Train_Acc: 96.501 Val_Loss: 0.0850  BEST VAL Loss: 0.0850  Val_Acc: 97.628

Epoch 16: Validation loss decreased (0.084966 --> 0.084083).  Saving model ...
	 Train_Loss: 0.1303 Train_Acc: 96.129 Val_Loss: 0.0841  BEST VAL Loss: 0.0841  Val_Acc: 97.723

Epoch 17: Validation loss decreased (0.084083 --> 0.083059).  Saving model ...
	 Train_Loss: 0.1280 Train_Acc: 96.435 Val_Loss: 0.0831  BEST VAL Loss: 0.0831  Val_Acc: 97.364

Epoch 18: Validation loss decreased (0.083059 --> 0.081914).  Saving model ...
	 Train_Loss: 0.1257 Train_Acc: 96.591 Val_Loss: 0.0819  BEST VAL Loss: 0.0819  Val_Acc: 97.891

Epoch 19: Validation loss decreased (0.081914 --> 0.081488).  Saving model ...
	 Train_Loss: 0.1240 Train_Acc: 96.222 Val_Loss: 0.0815  BEST VAL Loss: 0.0815  Val_Acc: 97.604

Epoch 20: Validation loss decreased (0.081488 --> 0.080687).  Saving model ...
	 Train_Loss: 0.1228 Train_Acc: 96.096 Val_Loss: 0.0807  BEST VAL Loss: 0.0807  Val_Acc: 97.987

Epoch 21: Validation loss decreased (0.080687 --> 0.079962).  Saving model ...
	 Train_Loss: 0.1213 Train_Acc: 96.378 Val_Loss: 0.0800  BEST VAL Loss: 0.0800  Val_Acc: 97.795

Epoch 22: Validation loss decreased (0.079962 --> 0.079439).  Saving model ...
	 Train_Loss: 0.1197 Train_Acc: 96.603 Val_Loss: 0.0794  BEST VAL Loss: 0.0794  Val_Acc: 97.843

Epoch 23: Validation loss decreased (0.079439 --> 0.078739).  Saving model ...
	 Train_Loss: 0.1185 Train_Acc: 96.207 Val_Loss: 0.0787  BEST VAL Loss: 0.0787  Val_Acc: 98.059

Epoch 24: Validation loss decreased (0.078739 --> 0.078576).  Saving model ...
	 Train_Loss: 0.1178 Train_Acc: 95.635 Val_Loss: 0.0786  BEST VAL Loss: 0.0786  Val_Acc: 97.580

Epoch 25: Validation loss decreased (0.078576 --> 0.078144).  Saving model ...
	 Train_Loss: 0.1170 Train_Acc: 96.180 Val_Loss: 0.0781  BEST VAL Loss: 0.0781  Val_Acc: 97.556

Epoch 26: Validation loss decreased (0.078144 --> 0.077671).  Saving model ...
	 Train_Loss: 0.1163 Train_Acc: 96.258 Val_Loss: 0.0777  BEST VAL Loss: 0.0777  Val_Acc: 97.891

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.1155 Train_Acc: 96.453 Val_Loss: 0.0780  BEST VAL Loss: 0.0777  Val_Acc: 97.556

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.1157 Train_Acc: 94.350 Val_Loss: 0.0782  BEST VAL Loss: 0.0777  Val_Acc: 97.268

Epoch 29: Validation loss did not decrease
	 Train_Loss: 0.1152 Train_Acc: 95.659 Val_Loss: 0.0778  BEST VAL Loss: 0.0777  Val_Acc: 97.532

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.1148 Train_Acc: 95.973 Val_Loss: 0.0783  BEST VAL Loss: 0.0777  Val_Acc: 96.909

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.1154 Train_Acc: 95.057 Val_Loss: 0.0784  BEST VAL Loss: 0.0777  Val_Acc: 96.909

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.1164 Train_Acc: 94.790 Val_Loss: 0.0781  BEST VAL Loss: 0.0777  Val_Acc: 97.412

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.1180 Train_Acc: 93.990 Val_Loss: 0.0797  BEST VAL Loss: 0.0777  Val_Acc: 96.597

Epoch 34: Validation loss did not decrease
	 Train_Loss: 0.1214 Train_Acc: 91.572 Val_Loss: 0.0818  BEST VAL Loss: 0.0777  Val_Acc: 94.249

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.1250 Train_Acc: 90.221 Val_Loss: 0.0837  BEST VAL Loss: 0.0777  Val_Acc: 94.057

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.1299 Train_Acc: 87.441 Val_Loss: 0.0870  BEST VAL Loss: 0.0777  Val_Acc: 94.393

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.1347 Train_Acc: 88.163 Val_Loss: 0.0901  BEST VAL Loss: 0.0777  Val_Acc: 94.416

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.1396 Train_Acc: 87.249 Val_Loss: 0.0940  BEST VAL Loss: 0.0777  Val_Acc: 94.081

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.1452 Train_Acc: 87.174 Val_Loss: 0.0983  BEST VAL Loss: 0.0777  Val_Acc: 90.367

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.1498 Train_Acc: 84.840 Val_Loss: 0.1013  BEST VAL Loss: 0.0777  Val_Acc: 92.667

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.1536 Train_Acc: 86.617 Val_Loss: 0.1041  BEST VAL Loss: 0.0777  Val_Acc: 93.458

Epoch 42: Validation loss did not decrease
Early stopped at epoch : 42
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      0.99      0.99     24644
           1       0.98      0.97      0.98      8734

    accuracy                           0.99     33378
   macro avg       0.98      0.98      0.98     33378
weighted avg       0.99      0.99      0.99     33378

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      0.99      0.99      3081
           1       0.96      0.96      0.96      1092

    accuracy                           0.98      4173
   macro avg       0.97      0.97      0.97      4173
weighted avg       0.98      0.98      0.98      4173

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.99      0.98      3081
           1       0.96      0.95      0.96      1092

    accuracy                           0.98      4173
   macro avg       0.97      0.97      0.97      4173
weighted avg       0.98      0.98      0.98      4173

              precision    recall  f1-score   support

           0       0.98      0.99      0.98      3081
           1       0.96      0.95      0.96      1092

    accuracy                           0.98      4173
   macro avg       0.97      0.97      0.97      4173
weighted avg       0.98      0.98      0.98      4173

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.96      0.99      0.98      4837
           1       0.98      0.95      0.97      3484

    accuracy                           0.97      8321
   macro avg       0.97      0.97      0.97      8321
weighted avg       0.97      0.97      0.97      8321

              precision    recall  f1-score   support

           0       0.96      0.99      0.98      4837
           1       0.98      0.95      0.97      3484

    accuracy                           0.97      8321
   macro avg       0.97      0.97      0.97      8321
weighted avg       0.97      0.97      0.97      8321

completed
