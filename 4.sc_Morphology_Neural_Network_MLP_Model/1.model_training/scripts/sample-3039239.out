[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ef5f33e5'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'b4cb9f66'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '6295f59f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'ec0e7830'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: Thapsigargin_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: Thapsigargin_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (27418, 1276)
Number of total missing values across all columns: 27532
Data Subset Is Off
Wells held out for testing: ['D14' 'L20']
Wells to use for training, validation, and testing ['D15' 'K14' 'K15' 'L16' 'L17' 'L21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.297685).  Saving model ...
	 Train_Loss: 0.4055 Train_Acc: 83.694 Val_Loss: 0.2977  BEST VAL Loss: 0.2977  Val_Acc: 92.522

Epoch 1: Validation loss decreased (0.297685 --> 0.263967).  Saving model ...
	 Train_Loss: 0.3266 Train_Acc: 92.470 Val_Loss: 0.2640  BEST VAL Loss: 0.2640  Val_Acc: 94.056

Epoch 2: Validation loss decreased (0.263967 --> 0.242075).  Saving model ...
	 Train_Loss: 0.2830 Train_Acc: 93.981 Val_Loss: 0.2421  BEST VAL Loss: 0.2421  Val_Acc: 94.535

Epoch 3: Validation loss decreased (0.242075 --> 0.225228).  Saving model ...
	 Train_Loss: 0.2541 Train_Acc: 94.515 Val_Loss: 0.2252  BEST VAL Loss: 0.2252  Val_Acc: 95.110

Epoch 4: Validation loss decreased (0.225228 --> 0.211537).  Saving model ...
	 Train_Loss: 0.2331 Train_Acc: 95.036 Val_Loss: 0.2115  BEST VAL Loss: 0.2115  Val_Acc: 95.398

Epoch 5: Validation loss decreased (0.211537 --> 0.200030).  Saving model ...
	 Train_Loss: 0.2167 Train_Acc: 95.396 Val_Loss: 0.2000  BEST VAL Loss: 0.2000  Val_Acc: 95.733

Epoch 6: Validation loss decreased (0.200030 --> 0.190380).  Saving model ...
	 Train_Loss: 0.2035 Train_Acc: 95.798 Val_Loss: 0.1904  BEST VAL Loss: 0.1904  Val_Acc: 96.069

Epoch 7: Validation loss decreased (0.190380 --> 0.182114).  Saving model ...
	 Train_Loss: 0.1923 Train_Acc: 96.205 Val_Loss: 0.1821  BEST VAL Loss: 0.1821  Val_Acc: 96.405

Epoch 8: Validation loss decreased (0.182114 --> 0.174951).  Saving model ...
	 Train_Loss: 0.1828 Train_Acc: 96.415 Val_Loss: 0.1750  BEST VAL Loss: 0.1750  Val_Acc: 96.453

Epoch 9: Validation loss decreased (0.174951 --> 0.168696).  Saving model ...
	 Train_Loss: 0.1746 Train_Acc: 96.667 Val_Loss: 0.1687  BEST VAL Loss: 0.1687  Val_Acc: 96.644

Epoch 10: Validation loss decreased (0.168696 --> 0.163234).  Saving model ...
	 Train_Loss: 0.1672 Train_Acc: 96.769 Val_Loss: 0.1632  BEST VAL Loss: 0.1632  Val_Acc: 96.788

Epoch 11: Validation loss decreased (0.163234 --> 0.158355).  Saving model ...
	 Train_Loss: 0.1607 Train_Acc: 97.033 Val_Loss: 0.1584  BEST VAL Loss: 0.1584  Val_Acc: 96.932

Epoch 12: Validation loss decreased (0.158355 --> 0.154011).  Saving model ...
	 Train_Loss: 0.1549 Train_Acc: 97.104 Val_Loss: 0.1540  BEST VAL Loss: 0.1540  Val_Acc: 97.172

Epoch 13: Validation loss decreased (0.154011 --> 0.150076).  Saving model ...
	 Train_Loss: 0.1498 Train_Acc: 97.158 Val_Loss: 0.1501  BEST VAL Loss: 0.1501  Val_Acc: 97.220

Epoch 14: Validation loss decreased (0.150076 --> 0.146444).  Saving model ...
	 Train_Loss: 0.1451 Train_Acc: 97.362 Val_Loss: 0.1464  BEST VAL Loss: 0.1464  Val_Acc: 97.220

Epoch 15: Validation loss decreased (0.146444 --> 0.143155).  Saving model ...
	 Train_Loss: 0.1407 Train_Acc: 97.506 Val_Loss: 0.1432  BEST VAL Loss: 0.1432  Val_Acc: 97.411

Epoch 16: Validation loss decreased (0.143155 --> 0.140089).  Saving model ...
	 Train_Loss: 0.1367 Train_Acc: 97.662 Val_Loss: 0.1401  BEST VAL Loss: 0.1401  Val_Acc: 97.411

Epoch 17: Validation loss decreased (0.140089 --> 0.137278).  Saving model ...
	 Train_Loss: 0.1330 Train_Acc: 97.716 Val_Loss: 0.1373  BEST VAL Loss: 0.1373  Val_Acc: 97.507

Epoch 18: Validation loss decreased (0.137278 --> 0.134701).  Saving model ...
	 Train_Loss: 0.1295 Train_Acc: 97.854 Val_Loss: 0.1347  BEST VAL Loss: 0.1347  Val_Acc: 97.363

Epoch 19: Validation loss decreased (0.134701 --> 0.132347).  Saving model ...
	 Train_Loss: 0.1264 Train_Acc: 97.842 Val_Loss: 0.1323  BEST VAL Loss: 0.1323  Val_Acc: 97.411

Epoch 20: Validation loss decreased (0.132347 --> 0.130128).  Saving model ...
	 Train_Loss: 0.1233 Train_Acc: 98.028 Val_Loss: 0.1301  BEST VAL Loss: 0.1301  Val_Acc: 97.507

Epoch 21: Validation loss decreased (0.130128 --> 0.128024).  Saving model ...
	 Train_Loss: 0.1204 Train_Acc: 97.992 Val_Loss: 0.1280  BEST VAL Loss: 0.1280  Val_Acc: 97.315

Epoch 22: Validation loss decreased (0.128024 --> 0.126054).  Saving model ...
	 Train_Loss: 0.1178 Train_Acc: 98.094 Val_Loss: 0.1261  BEST VAL Loss: 0.1261  Val_Acc: 97.507

Epoch 23: Validation loss decreased (0.126054 --> 0.124185).  Saving model ...
	 Train_Loss: 0.1153 Train_Acc: 98.130 Val_Loss: 0.1242  BEST VAL Loss: 0.1242  Val_Acc: 97.507

Epoch 24: Validation loss decreased (0.124185 --> 0.122422).  Saving model ...
	 Train_Loss: 0.1130 Train_Acc: 98.112 Val_Loss: 0.1224  BEST VAL Loss: 0.1224  Val_Acc: 97.699

Epoch 25: Validation loss decreased (0.122422 --> 0.120757).  Saving model ...
	 Train_Loss: 0.1107 Train_Acc: 98.267 Val_Loss: 0.1208  BEST VAL Loss: 0.1208  Val_Acc: 97.507

Epoch 26: Validation loss decreased (0.120757 --> 0.119183).  Saving model ...
	 Train_Loss: 0.1086 Train_Acc: 98.315 Val_Loss: 0.1192  BEST VAL Loss: 0.1192  Val_Acc: 97.555

Epoch 27: Validation loss decreased (0.119183 --> 0.117727).  Saving model ...
	 Train_Loss: 0.1066 Train_Acc: 98.357 Val_Loss: 0.1177  BEST VAL Loss: 0.1177  Val_Acc: 97.459

Epoch 28: Validation loss decreased (0.117727 --> 0.116332).  Saving model ...
	 Train_Loss: 0.1046 Train_Acc: 98.483 Val_Loss: 0.1163  BEST VAL Loss: 0.1163  Val_Acc: 97.651

Epoch 29: Validation loss decreased (0.116332 --> 0.114970).  Saving model ...
	 Train_Loss: 0.1028 Train_Acc: 98.345 Val_Loss: 0.1150  BEST VAL Loss: 0.1150  Val_Acc: 97.699

Epoch 30: Validation loss decreased (0.114970 --> 0.113696).  Saving model ...
	 Train_Loss: 0.1010 Train_Acc: 98.585 Val_Loss: 0.1137  BEST VAL Loss: 0.1137  Val_Acc: 97.651

Epoch 31: Validation loss decreased (0.113696 --> 0.112483).  Saving model ...
	 Train_Loss: 0.0993 Train_Acc: 98.513 Val_Loss: 0.1125  BEST VAL Loss: 0.1125  Val_Acc: 97.699

Epoch 32: Validation loss decreased (0.112483 --> 0.111351).  Saving model ...
	 Train_Loss: 0.0977 Train_Acc: 98.621 Val_Loss: 0.1114  BEST VAL Loss: 0.1114  Val_Acc: 97.603

Epoch 33: Validation loss decreased (0.111351 --> 0.110241).  Saving model ...
	 Train_Loss: 0.0961 Train_Acc: 98.627 Val_Loss: 0.1102  BEST VAL Loss: 0.1102  Val_Acc: 97.603

Epoch 34: Validation loss decreased (0.110241 --> 0.109202).  Saving model ...
	 Train_Loss: 0.0946 Train_Acc: 98.639 Val_Loss: 0.1092  BEST VAL Loss: 0.1092  Val_Acc: 97.795

Epoch 35: Validation loss decreased (0.109202 --> 0.108182).  Saving model ...
	 Train_Loss: 0.0932 Train_Acc: 98.549 Val_Loss: 0.1082  BEST VAL Loss: 0.1082  Val_Acc: 97.747

Epoch 36: Validation loss decreased (0.108182 --> 0.107195).  Saving model ...
	 Train_Loss: 0.0918 Train_Acc: 98.729 Val_Loss: 0.1072  BEST VAL Loss: 0.1072  Val_Acc: 97.843

Epoch 37: Validation loss decreased (0.107195 --> 0.106237).  Saving model ...
	 Train_Loss: 0.0905 Train_Acc: 98.645 Val_Loss: 0.1062  BEST VAL Loss: 0.1062  Val_Acc: 97.891

Epoch 38: Validation loss decreased (0.106237 --> 0.105322).  Saving model ...
	 Train_Loss: 0.0893 Train_Acc: 98.687 Val_Loss: 0.1053  BEST VAL Loss: 0.1053  Val_Acc: 97.795

Epoch 39: Validation loss decreased (0.105322 --> 0.104424).  Saving model ...
	 Train_Loss: 0.0880 Train_Acc: 98.717 Val_Loss: 0.1044  BEST VAL Loss: 0.1044  Val_Acc: 97.843

Epoch 40: Validation loss decreased (0.104424 --> 0.103563).  Saving model ...
	 Train_Loss: 0.0868 Train_Acc: 98.795 Val_Loss: 0.1036  BEST VAL Loss: 0.1036  Val_Acc: 97.891

Epoch 41: Validation loss decreased (0.103563 --> 0.102744).  Saving model ...
	 Train_Loss: 0.0857 Train_Acc: 98.831 Val_Loss: 0.1027  BEST VAL Loss: 0.1027  Val_Acc: 97.843

Epoch 42: Validation loss decreased (0.102744 --> 0.101953).  Saving model ...
	 Train_Loss: 0.0845 Train_Acc: 98.861 Val_Loss: 0.1020  BEST VAL Loss: 0.1020  Val_Acc: 97.843

Epoch 43: Validation loss decreased (0.101953 --> 0.101170).  Saving model ...
	 Train_Loss: 0.0834 Train_Acc: 98.897 Val_Loss: 0.1012  BEST VAL Loss: 0.1012  Val_Acc: 97.843

Epoch 44: Validation loss decreased (0.101170 --> 0.100412).  Saving model ...
	 Train_Loss: 0.0824 Train_Acc: 98.885 Val_Loss: 0.1004  BEST VAL Loss: 0.1004  Val_Acc: 97.843

Epoch 45: Validation loss decreased (0.100412 --> 0.099681).  Saving model ...
	 Train_Loss: 0.0814 Train_Acc: 98.855 Val_Loss: 0.0997  BEST VAL Loss: 0.0997  Val_Acc: 97.891

Epoch 46: Validation loss decreased (0.099681 --> 0.098948).  Saving model ...
	 Train_Loss: 0.0804 Train_Acc: 98.891 Val_Loss: 0.0989  BEST VAL Loss: 0.0989  Val_Acc: 97.891

Epoch 47: Validation loss decreased (0.098948 --> 0.098281).  Saving model ...
	 Train_Loss: 0.0794 Train_Acc: 98.999 Val_Loss: 0.0983  BEST VAL Loss: 0.0983  Val_Acc: 97.843

Epoch 48: Validation loss decreased (0.098281 --> 0.097608).  Saving model ...
	 Train_Loss: 0.0785 Train_Acc: 98.927 Val_Loss: 0.0976  BEST VAL Loss: 0.0976  Val_Acc: 97.843

Epoch 49: Validation loss decreased (0.097608 --> 0.096970).  Saving model ...
	 Train_Loss: 0.0776 Train_Acc: 98.993 Val_Loss: 0.0970  BEST VAL Loss: 0.0970  Val_Acc: 97.795

Epoch 50: Validation loss decreased (0.096970 --> 0.096348).  Saving model ...
	 Train_Loss: 0.0767 Train_Acc: 99.041 Val_Loss: 0.0963  BEST VAL Loss: 0.0963  Val_Acc: 97.843

Epoch 51: Validation loss decreased (0.096348 --> 0.095753).  Saving model ...
	 Train_Loss: 0.0759 Train_Acc: 99.113 Val_Loss: 0.0958  BEST VAL Loss: 0.0958  Val_Acc: 97.795

Epoch 52: Validation loss decreased (0.095753 --> 0.095151).  Saving model ...
	 Train_Loss: 0.0750 Train_Acc: 98.975 Val_Loss: 0.0952  BEST VAL Loss: 0.0952  Val_Acc: 97.939

Epoch 53: Validation loss decreased (0.095151 --> 0.094563).  Saving model ...
	 Train_Loss: 0.0742 Train_Acc: 99.119 Val_Loss: 0.0946  BEST VAL Loss: 0.0946  Val_Acc: 97.939

Epoch 54: Validation loss decreased (0.094563 --> 0.093998).  Saving model ...
	 Train_Loss: 0.0734 Train_Acc: 99.173 Val_Loss: 0.0940  BEST VAL Loss: 0.0940  Val_Acc: 97.939

Epoch 55: Validation loss decreased (0.093998 --> 0.093458).  Saving model ...
	 Train_Loss: 0.0727 Train_Acc: 99.107 Val_Loss: 0.0935  BEST VAL Loss: 0.0935  Val_Acc: 97.939

Epoch 56: Validation loss decreased (0.093458 --> 0.092907).  Saving model ...
	 Train_Loss: 0.0719 Train_Acc: 99.095 Val_Loss: 0.0929  BEST VAL Loss: 0.0929  Val_Acc: 97.939

Epoch 57: Validation loss decreased (0.092907 --> 0.092382).  Saving model ...
	 Train_Loss: 0.0712 Train_Acc: 99.173 Val_Loss: 0.0924  BEST VAL Loss: 0.0924  Val_Acc: 97.843

Epoch 58: Validation loss decreased (0.092382 --> 0.091871).  Saving model ...
	 Train_Loss: 0.0705 Train_Acc: 99.197 Val_Loss: 0.0919  BEST VAL Loss: 0.0919  Val_Acc: 97.987

Epoch 59: Validation loss decreased (0.091871 --> 0.091361).  Saving model ...
	 Train_Loss: 0.0698 Train_Acc: 99.173 Val_Loss: 0.0914  BEST VAL Loss: 0.0914  Val_Acc: 98.035

Epoch 60: Validation loss decreased (0.091361 --> 0.090855).  Saving model ...
	 Train_Loss: 0.0691 Train_Acc: 99.155 Val_Loss: 0.0909  BEST VAL Loss: 0.0909  Val_Acc: 97.987

Epoch 61: Validation loss decreased (0.090855 --> 0.090374).  Saving model ...
	 Train_Loss: 0.0684 Train_Acc: 99.173 Val_Loss: 0.0904  BEST VAL Loss: 0.0904  Val_Acc: 97.987

Epoch 62: Validation loss decreased (0.090374 --> 0.089922).  Saving model ...
	 Train_Loss: 0.0678 Train_Acc: 99.245 Val_Loss: 0.0899  BEST VAL Loss: 0.0899  Val_Acc: 97.939

Epoch 63: Validation loss decreased (0.089922 --> 0.089507).  Saving model ...
	 Train_Loss: 0.0671 Train_Acc: 99.251 Val_Loss: 0.0895  BEST VAL Loss: 0.0895  Val_Acc: 97.891

Epoch 64: Validation loss decreased (0.089507 --> 0.089071).  Saving model ...
	 Train_Loss: 0.0665 Train_Acc: 99.113 Val_Loss: 0.0891  BEST VAL Loss: 0.0891  Val_Acc: 97.939

Epoch 65: Validation loss decreased (0.089071 --> 0.088647).  Saving model ...
	 Train_Loss: 0.0659 Train_Acc: 99.287 Val_Loss: 0.0886  BEST VAL Loss: 0.0886  Val_Acc: 97.939

Epoch 66: Validation loss decreased (0.088647 --> 0.088235).  Saving model ...
	 Train_Loss: 0.0653 Train_Acc: 99.317 Val_Loss: 0.0882  BEST VAL Loss: 0.0882  Val_Acc: 98.035

Epoch 67: Validation loss decreased (0.088235 --> 0.087840).  Saving model ...
	 Train_Loss: 0.0647 Train_Acc: 99.281 Val_Loss: 0.0878  BEST VAL Loss: 0.0878  Val_Acc: 97.939

Epoch 68: Validation loss decreased (0.087840 --> 0.087460).  Saving model ...
	 Train_Loss: 0.0641 Train_Acc: 99.335 Val_Loss: 0.0875  BEST VAL Loss: 0.0875  Val_Acc: 97.891

Epoch 69: Validation loss decreased (0.087460 --> 0.087067).  Saving model ...
	 Train_Loss: 0.0635 Train_Acc: 99.287 Val_Loss: 0.0871  BEST VAL Loss: 0.0871  Val_Acc: 97.987

Epoch 70: Validation loss decreased (0.087067 --> 0.086682).  Saving model ...
	 Train_Loss: 0.0630 Train_Acc: 99.353 Val_Loss: 0.0867  BEST VAL Loss: 0.0867  Val_Acc: 97.891

Epoch 71: Validation loss decreased (0.086682 --> 0.086323).  Saving model ...
	 Train_Loss: 0.0624 Train_Acc: 99.365 Val_Loss: 0.0863  BEST VAL Loss: 0.0863  Val_Acc: 97.843

Epoch 72: Validation loss decreased (0.086323 --> 0.085955).  Saving model ...
	 Train_Loss: 0.0619 Train_Acc: 99.365 Val_Loss: 0.0860  BEST VAL Loss: 0.0860  Val_Acc: 97.939

Epoch 73: Validation loss decreased (0.085955 --> 0.085600).  Saving model ...
	 Train_Loss: 0.0614 Train_Acc: 99.287 Val_Loss: 0.0856  BEST VAL Loss: 0.0856  Val_Acc: 97.939

Epoch 74: Validation loss decreased (0.085600 --> 0.085245).  Saving model ...
	 Train_Loss: 0.0609 Train_Acc: 99.365 Val_Loss: 0.0852  BEST VAL Loss: 0.0852  Val_Acc: 97.939

Epoch 75: Validation loss decreased (0.085245 --> 0.084896).  Saving model ...
	 Train_Loss: 0.0604 Train_Acc: 99.407 Val_Loss: 0.0849  BEST VAL Loss: 0.0849  Val_Acc: 97.987

Epoch 76: Validation loss decreased (0.084896 --> 0.084554).  Saving model ...
	 Train_Loss: 0.0599 Train_Acc: 99.353 Val_Loss: 0.0846  BEST VAL Loss: 0.0846  Val_Acc: 97.987

Epoch 77: Validation loss decreased (0.084554 --> 0.084237).  Saving model ...
	 Train_Loss: 0.0594 Train_Acc: 99.424 Val_Loss: 0.0842  BEST VAL Loss: 0.0842  Val_Acc: 97.891

Epoch 78: Validation loss decreased (0.084237 --> 0.083911).  Saving model ...
	 Train_Loss: 0.0590 Train_Acc: 99.436 Val_Loss: 0.0839  BEST VAL Loss: 0.0839  Val_Acc: 97.843

Epoch 79: Validation loss decreased (0.083911 --> 0.083588).  Saving model ...
	 Train_Loss: 0.0585 Train_Acc: 99.401 Val_Loss: 0.0836  BEST VAL Loss: 0.0836  Val_Acc: 98.035

Epoch 80: Validation loss decreased (0.083588 --> 0.083274).  Saving model ...
	 Train_Loss: 0.0580 Train_Acc: 99.430 Val_Loss: 0.0833  BEST VAL Loss: 0.0833  Val_Acc: 98.035

Epoch 81: Validation loss decreased (0.083274 --> 0.082966).  Saving model ...
	 Train_Loss: 0.0576 Train_Acc: 99.413 Val_Loss: 0.0830  BEST VAL Loss: 0.0830  Val_Acc: 98.035

Epoch 82: Validation loss decreased (0.082966 --> 0.082676).  Saving model ...
	 Train_Loss: 0.0572 Train_Acc: 99.407 Val_Loss: 0.0827  BEST VAL Loss: 0.0827  Val_Acc: 97.939

Epoch 83: Validation loss decreased (0.082676 --> 0.082394).  Saving model ...
	 Train_Loss: 0.0568 Train_Acc: 99.478 Val_Loss: 0.0824  BEST VAL Loss: 0.0824  Val_Acc: 97.987

Epoch 84: Validation loss decreased (0.082394 --> 0.082121).  Saving model ...
	 Train_Loss: 0.0563 Train_Acc: 99.401 Val_Loss: 0.0821  BEST VAL Loss: 0.0821  Val_Acc: 98.082

Epoch 85: Validation loss decreased (0.082121 --> 0.081860).  Saving model ...
	 Train_Loss: 0.0559 Train_Acc: 99.526 Val_Loss: 0.0819  BEST VAL Loss: 0.0819  Val_Acc: 97.987

Epoch 86: Validation loss decreased (0.081860 --> 0.081600).  Saving model ...
	 Train_Loss: 0.0555 Train_Acc: 99.430 Val_Loss: 0.0816  BEST VAL Loss: 0.0816  Val_Acc: 97.939

Epoch 87: Validation loss decreased (0.081600 --> 0.081334).  Saving model ...
	 Train_Loss: 0.0551 Train_Acc: 99.442 Val_Loss: 0.0813  BEST VAL Loss: 0.0813  Val_Acc: 98.082

Epoch 88: Validation loss decreased (0.081334 --> 0.081076).  Saving model ...
	 Train_Loss: 0.0547 Train_Acc: 99.520 Val_Loss: 0.0811  BEST VAL Loss: 0.0811  Val_Acc: 97.987

Epoch 89: Validation loss decreased (0.081076 --> 0.080823).  Saving model ...
	 Train_Loss: 0.0543 Train_Acc: 99.454 Val_Loss: 0.0808  BEST VAL Loss: 0.0808  Val_Acc: 97.939

Epoch 90: Validation loss decreased (0.080823 --> 0.080578).  Saving model ...
	 Train_Loss: 0.0540 Train_Acc: 99.424 Val_Loss: 0.0806  BEST VAL Loss: 0.0806  Val_Acc: 98.035

Epoch 91: Validation loss decreased (0.080578 --> 0.080324).  Saving model ...
	 Train_Loss: 0.0536 Train_Acc: 99.526 Val_Loss: 0.0803  BEST VAL Loss: 0.0803  Val_Acc: 98.130

Epoch 92: Validation loss decreased (0.080324 --> 0.080100).  Saving model ...
	 Train_Loss: 0.0532 Train_Acc: 99.436 Val_Loss: 0.0801  BEST VAL Loss: 0.0801  Val_Acc: 98.035

Epoch 93: Validation loss decreased (0.080100 --> 0.079871).  Saving model ...
	 Train_Loss: 0.0529 Train_Acc: 99.472 Val_Loss: 0.0799  BEST VAL Loss: 0.0799  Val_Acc: 98.130

Epoch 94: Validation loss decreased (0.079871 --> 0.079638).  Saving model ...
	 Train_Loss: 0.0525 Train_Acc: 99.472 Val_Loss: 0.0796  BEST VAL Loss: 0.0796  Val_Acc: 98.130

Epoch 95: Validation loss decreased (0.079638 --> 0.079408).  Saving model ...
	 Train_Loss: 0.0522 Train_Acc: 99.502 Val_Loss: 0.0794  BEST VAL Loss: 0.0794  Val_Acc: 98.130

Epoch 96: Validation loss decreased (0.079408 --> 0.079169).  Saving model ...
	 Train_Loss: 0.0518 Train_Acc: 99.574 Val_Loss: 0.0792  BEST VAL Loss: 0.0792  Val_Acc: 98.178

Epoch 97: Validation loss decreased (0.079169 --> 0.078934).  Saving model ...
	 Train_Loss: 0.0515 Train_Acc: 99.514 Val_Loss: 0.0789  BEST VAL Loss: 0.0789  Val_Acc: 98.130

Epoch 98: Validation loss decreased (0.078934 --> 0.078730).  Saving model ...
	 Train_Loss: 0.0511 Train_Acc: 99.550 Val_Loss: 0.0787  BEST VAL Loss: 0.0787  Val_Acc: 98.178

Epoch 99: Validation loss decreased (0.078730 --> 0.078533).  Saving model ...
	 Train_Loss: 0.0508 Train_Acc: 99.526 Val_Loss: 0.0785  BEST VAL Loss: 0.0785  Val_Acc: 98.178

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      8312
           1       1.00      1.00      1.00      8369

    accuracy                           1.00     16681
   macro avg       1.00      1.00      1.00     16681
weighted avg       1.00      1.00      1.00     16681

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.99      0.98      1039
           1       0.99      0.98      0.98      1047

    accuracy                           0.98      2086
   macro avg       0.98      0.98      0.98      2086
weighted avg       0.98      0.98      0.98      2086

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.98      0.98      1039
           1       0.98      0.98      0.98      1047

    accuracy                           0.98      2086
   macro avg       0.98      0.98      0.98      2086
weighted avg       0.98      0.98      0.98      2086

              precision    recall  f1-score   support

           0       0.98      0.98      0.98      1039
           1       0.98      0.98      0.98      1047

    accuracy                           0.98      2086
   macro avg       0.98      0.98      0.98      2086
weighted avg       0.98      0.98      0.98      2086

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.99      0.99      3262
           1       0.99      0.98      0.99      3303

    accuracy                           0.99      6565
   macro avg       0.99      0.99      0.99      6565
weighted avg       0.99      0.99      0.99      6565

              precision    recall  f1-score   support

           0       0.98      0.99      0.99      3262
           1       0.99      0.98      0.99      3303

    accuracy                           0.99      6565
   macro avg       0.99      0.99      0.99      6565
weighted avg       0.99      0.99      0.99      6565

completed
