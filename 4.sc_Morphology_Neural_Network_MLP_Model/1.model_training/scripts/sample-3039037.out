[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '148864bd'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'ca1eb3b1'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'c759a6e8'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '4e1a5e62'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: H2O2_100.000_DMSO_0.025 treatment_name: LPS_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: LPS_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (379969, 1270)
Number of total missing values across all columns: 759938
Data Subset Is Off
Wells held out for testing: ['D09' 'I10']
Wells to use for training, validation, and testing ['D02' 'D03' 'D08' 'H04' 'I04' 'H05' 'I05' 'H10' 'H11' 'I11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.342500).  Saving model ...
	 Train_Loss: 0.4517 Train_Acc: 78.629 Val_Loss: 0.3425  BEST VAL Loss: 0.3425  Val_Acc: 85.085

Epoch 1: Validation loss decreased (0.342500 --> 0.329098).  Saving model ...
	 Train_Loss: 0.4085 Train_Acc: 83.610 Val_Loss: 0.3291  BEST VAL Loss: 0.3291  Val_Acc: 86.114

Epoch 2: Validation loss decreased (0.329098 --> 0.318793).  Saving model ...
	 Train_Loss: 0.3867 Train_Acc: 84.780 Val_Loss: 0.3188  BEST VAL Loss: 0.3188  Val_Acc: 87.138

Epoch 3: Validation loss decreased (0.318793 --> 0.311154).  Saving model ...
	 Train_Loss: 0.3734 Train_Acc: 85.199 Val_Loss: 0.3112  BEST VAL Loss: 0.3112  Val_Acc: 87.410

Epoch 4: Validation loss decreased (0.311154 --> 0.304784).  Saving model ...
	 Train_Loss: 0.3637 Train_Acc: 85.687 Val_Loss: 0.3048  BEST VAL Loss: 0.3048  Val_Acc: 88.070

Epoch 5: Validation loss decreased (0.304784 --> 0.299984).  Saving model ...
	 Train_Loss: 0.3561 Train_Acc: 85.936 Val_Loss: 0.3000  BEST VAL Loss: 0.3000  Val_Acc: 88.203

Epoch 6: Validation loss decreased (0.299984 --> 0.296488).  Saving model ...
	 Train_Loss: 0.3500 Train_Acc: 86.204 Val_Loss: 0.2965  BEST VAL Loss: 0.2965  Val_Acc: 88.301

Epoch 7: Validation loss decreased (0.296488 --> 0.293467).  Saving model ...
	 Train_Loss: 0.3450 Train_Acc: 86.383 Val_Loss: 0.2935  BEST VAL Loss: 0.2935  Val_Acc: 88.383

Epoch 8: Validation loss decreased (0.293467 --> 0.290457).  Saving model ...
	 Train_Loss: 0.3406 Train_Acc: 86.544 Val_Loss: 0.2905  BEST VAL Loss: 0.2905  Val_Acc: 88.792

Epoch 9: Validation loss decreased (0.290457 --> 0.288010).  Saving model ...
	 Train_Loss: 0.3370 Train_Acc: 86.633 Val_Loss: 0.2880  BEST VAL Loss: 0.2880  Val_Acc: 88.707

Epoch 10: Validation loss decreased (0.288010 --> 0.286009).  Saving model ...
	 Train_Loss: 0.3340 Train_Acc: 86.579 Val_Loss: 0.2860  BEST VAL Loss: 0.2860  Val_Acc: 88.792

Epoch 11: Validation loss decreased (0.286009 --> 0.283944).  Saving model ...
	 Train_Loss: 0.3312 Train_Acc: 86.860 Val_Loss: 0.2839  BEST VAL Loss: 0.2839  Val_Acc: 89.049

Epoch 12: Validation loss decreased (0.283944 --> 0.282211).  Saving model ...
	 Train_Loss: 0.3287 Train_Acc: 86.872 Val_Loss: 0.2822  BEST VAL Loss: 0.2822  Val_Acc: 89.068

Epoch 13: Validation loss decreased (0.282211 --> 0.280719).  Saving model ...
	 Train_Loss: 0.3265 Train_Acc: 86.949 Val_Loss: 0.2807  BEST VAL Loss: 0.2807  Val_Acc: 89.004

Epoch 14: Validation loss decreased (0.280719 --> 0.279210).  Saving model ...
	 Train_Loss: 0.3243 Train_Acc: 87.116 Val_Loss: 0.2792  BEST VAL Loss: 0.2792  Val_Acc: 88.985

Epoch 15: Validation loss decreased (0.279210 --> 0.278062).  Saving model ...
	 Train_Loss: 0.3225 Train_Acc: 86.991 Val_Loss: 0.2781  BEST VAL Loss: 0.2781  Val_Acc: 89.055

Epoch 16: Validation loss decreased (0.278062 --> 0.276811).  Saving model ...
	 Train_Loss: 0.3207 Train_Acc: 87.169 Val_Loss: 0.2768  BEST VAL Loss: 0.2768  Val_Acc: 89.179

Epoch 17: Validation loss decreased (0.276811 --> 0.275610).  Saving model ...
	 Train_Loss: 0.3191 Train_Acc: 87.144 Val_Loss: 0.2756  BEST VAL Loss: 0.2756  Val_Acc: 89.419

Epoch 18: Validation loss decreased (0.275610 --> 0.274789).  Saving model ...
	 Train_Loss: 0.3176 Train_Acc: 87.249 Val_Loss: 0.2748  BEST VAL Loss: 0.2748  Val_Acc: 89.004

Epoch 19: Validation loss decreased (0.274789 --> 0.273759).  Saving model ...
	 Train_Loss: 0.3162 Train_Acc: 87.298 Val_Loss: 0.2738  BEST VAL Loss: 0.2738  Val_Acc: 89.204

Epoch 20: Validation loss decreased (0.273759 --> 0.272659).  Saving model ...
	 Train_Loss: 0.3149 Train_Acc: 87.356 Val_Loss: 0.2727  BEST VAL Loss: 0.2727  Val_Acc: 89.419

Epoch 21: Validation loss decreased (0.272659 --> 0.271739).  Saving model ...
	 Train_Loss: 0.3137 Train_Acc: 87.270 Val_Loss: 0.2717  BEST VAL Loss: 0.2717  Val_Acc: 89.407

Epoch 22: Validation loss decreased (0.271739 --> 0.270743).  Saving model ...
	 Train_Loss: 0.3125 Train_Acc: 87.400 Val_Loss: 0.2707  BEST VAL Loss: 0.2707  Val_Acc: 89.591

Epoch 23: Validation loss decreased (0.270743 --> 0.269880).  Saving model ...
	 Train_Loss: 0.3115 Train_Acc: 87.350 Val_Loss: 0.2699  BEST VAL Loss: 0.2699  Val_Acc: 89.578

Epoch 24: Validation loss decreased (0.269880 --> 0.269117).  Saving model ...
	 Train_Loss: 0.3104 Train_Acc: 87.470 Val_Loss: 0.2691  BEST VAL Loss: 0.2691  Val_Acc: 89.622

Epoch 25: Validation loss decreased (0.269117 --> 0.268501).  Saving model ...
	 Train_Loss: 0.3095 Train_Acc: 87.383 Val_Loss: 0.2685  BEST VAL Loss: 0.2685  Val_Acc: 89.369

Epoch 26: Validation loss decreased (0.268501 --> 0.268074).  Saving model ...
	 Train_Loss: 0.3086 Train_Acc: 87.516 Val_Loss: 0.2681  BEST VAL Loss: 0.2681  Val_Acc: 89.153

Epoch 27: Validation loss decreased (0.268074 --> 0.267336).  Saving model ...
	 Train_Loss: 0.3077 Train_Acc: 87.504 Val_Loss: 0.2673  BEST VAL Loss: 0.2673  Val_Acc: 89.562

Epoch 28: Validation loss decreased (0.267336 --> 0.266842).  Saving model ...
	 Train_Loss: 0.3068 Train_Acc: 87.557 Val_Loss: 0.2668  BEST VAL Loss: 0.2668  Val_Acc: 89.543

Epoch 29: Validation loss decreased (0.266842 --> 0.266230).  Saving model ...
	 Train_Loss: 0.3060 Train_Acc: 87.571 Val_Loss: 0.2662  BEST VAL Loss: 0.2662  Val_Acc: 89.562

Epoch 30: Validation loss decreased (0.266230 --> 0.265583).  Saving model ...
	 Train_Loss: 0.3053 Train_Acc: 87.580 Val_Loss: 0.2656  BEST VAL Loss: 0.2656  Val_Acc: 89.619

Epoch 31: Validation loss decreased (0.265583 --> 0.265043).  Saving model ...
	 Train_Loss: 0.3045 Train_Acc: 87.563 Val_Loss: 0.2650  BEST VAL Loss: 0.2650  Val_Acc: 89.768

Epoch 32: Validation loss decreased (0.265043 --> 0.264595).  Saving model ...
	 Train_Loss: 0.3038 Train_Acc: 87.752 Val_Loss: 0.2646  BEST VAL Loss: 0.2646  Val_Acc: 89.530

Epoch 33: Validation loss decreased (0.264595 --> 0.264079).  Saving model ...
	 Train_Loss: 0.3031 Train_Acc: 87.709 Val_Loss: 0.2641  BEST VAL Loss: 0.2641  Val_Acc: 89.692

Epoch 34: Validation loss decreased (0.264079 --> 0.263487).  Saving model ...
	 Train_Loss: 0.3024 Train_Acc: 87.640 Val_Loss: 0.2635  BEST VAL Loss: 0.2635  Val_Acc: 89.774

Epoch 35: Validation loss decreased (0.263487 --> 0.262962).  Saving model ...
	 Train_Loss: 0.3017 Train_Acc: 87.714 Val_Loss: 0.2630  BEST VAL Loss: 0.2630  Val_Acc: 89.670

Epoch 36: Validation loss decreased (0.262962 --> 0.262561).  Saving model ...
	 Train_Loss: 0.3011 Train_Acc: 87.757 Val_Loss: 0.2626  BEST VAL Loss: 0.2626  Val_Acc: 89.686

Epoch 37: Validation loss decreased (0.262561 --> 0.262112).  Saving model ...
	 Train_Loss: 0.3005 Train_Acc: 87.809 Val_Loss: 0.2621  BEST VAL Loss: 0.2621  Val_Acc: 89.863

Epoch 38: Validation loss decreased (0.262112 --> 0.261649).  Saving model ...
	 Train_Loss: 0.2999 Train_Acc: 87.836 Val_Loss: 0.2616  BEST VAL Loss: 0.2616  Val_Acc: 89.803

Epoch 39: Validation loss decreased (0.261649 --> 0.261252).  Saving model ...
	 Train_Loss: 0.2993 Train_Acc: 87.695 Val_Loss: 0.2613  BEST VAL Loss: 0.2613  Val_Acc: 89.597

Epoch 40: Validation loss decreased (0.261252 --> 0.260845).  Saving model ...
	 Train_Loss: 0.2988 Train_Acc: 87.850 Val_Loss: 0.2608  BEST VAL Loss: 0.2608  Val_Acc: 89.682

Epoch 41: Validation loss decreased (0.260845 --> 0.260451).  Saving model ...
	 Train_Loss: 0.2982 Train_Acc: 87.819 Val_Loss: 0.2605  BEST VAL Loss: 0.2605  Val_Acc: 89.803

Epoch 42: Validation loss decreased (0.260451 --> 0.260079).  Saving model ...
	 Train_Loss: 0.2977 Train_Acc: 87.762 Val_Loss: 0.2601  BEST VAL Loss: 0.2601  Val_Acc: 89.692

Epoch 43: Validation loss decreased (0.260079 --> 0.259746).  Saving model ...
	 Train_Loss: 0.2972 Train_Acc: 87.863 Val_Loss: 0.2597  BEST VAL Loss: 0.2597  Val_Acc: 89.692

Epoch 44: Validation loss decreased (0.259746 --> 0.259425).  Saving model ...
	 Train_Loss: 0.2967 Train_Acc: 87.865 Val_Loss: 0.2594  BEST VAL Loss: 0.2594  Val_Acc: 89.660

Epoch 45: Validation loss decreased (0.259425 --> 0.259070).  Saving model ...
	 Train_Loss: 0.2963 Train_Acc: 87.851 Val_Loss: 0.2591  BEST VAL Loss: 0.2591  Val_Acc: 89.971

Epoch 46: Validation loss decreased (0.259070 --> 0.258687).  Saving model ...
	 Train_Loss: 0.2958 Train_Acc: 87.865 Val_Loss: 0.2587  BEST VAL Loss: 0.2587  Val_Acc: 90.047

Epoch 47: Validation loss decreased (0.258687 --> 0.258412).  Saving model ...
	 Train_Loss: 0.2954 Train_Acc: 87.920 Val_Loss: 0.2584  BEST VAL Loss: 0.2584  Val_Acc: 89.844

Epoch 48: Validation loss decreased (0.258412 --> 0.258078).  Saving model ...
	 Train_Loss: 0.2949 Train_Acc: 87.874 Val_Loss: 0.2581  BEST VAL Loss: 0.2581  Val_Acc: 89.904

Epoch 49: Validation loss decreased (0.258078 --> 0.257799).  Saving model ...
	 Train_Loss: 0.2945 Train_Acc: 87.896 Val_Loss: 0.2578  BEST VAL Loss: 0.2578  Val_Acc: 89.793

Epoch 50: Validation loss decreased (0.257799 --> 0.257461).  Saving model ...
	 Train_Loss: 0.2941 Train_Acc: 87.917 Val_Loss: 0.2575  BEST VAL Loss: 0.2575  Val_Acc: 90.079

Epoch 51: Validation loss decreased (0.257461 --> 0.257095).  Saving model ...
	 Train_Loss: 0.2937 Train_Acc: 87.900 Val_Loss: 0.2571  BEST VAL Loss: 0.2571  Val_Acc: 90.104

Epoch 52: Validation loss decreased (0.257095 --> 0.256771).  Saving model ...
	 Train_Loss: 0.2933 Train_Acc: 87.903 Val_Loss: 0.2568  BEST VAL Loss: 0.2568  Val_Acc: 90.031

Epoch 53: Validation loss decreased (0.256771 --> 0.256535).  Saving model ...
	 Train_Loss: 0.2929 Train_Acc: 87.957 Val_Loss: 0.2565  BEST VAL Loss: 0.2565  Val_Acc: 89.841

Epoch 54: Validation loss decreased (0.256535 --> 0.256233).  Saving model ...
	 Train_Loss: 0.2926 Train_Acc: 88.023 Val_Loss: 0.2562  BEST VAL Loss: 0.2562  Val_Acc: 90.088

Epoch 55: Validation loss decreased (0.256233 --> 0.255926).  Saving model ...
	 Train_Loss: 0.2922 Train_Acc: 87.996 Val_Loss: 0.2559  BEST VAL Loss: 0.2559  Val_Acc: 89.930

Epoch 56: Validation loss decreased (0.255926 --> 0.255646).  Saving model ...
	 Train_Loss: 0.2918 Train_Acc: 88.001 Val_Loss: 0.2556  BEST VAL Loss: 0.2556  Val_Acc: 89.958

Epoch 57: Validation loss decreased (0.255646 --> 0.255366).  Saving model ...
	 Train_Loss: 0.2915 Train_Acc: 88.022 Val_Loss: 0.2554  BEST VAL Loss: 0.2554  Val_Acc: 90.025

Epoch 58: Validation loss decreased (0.255366 --> 0.255112).  Saving model ...
	 Train_Loss: 0.2911 Train_Acc: 87.984 Val_Loss: 0.2551  BEST VAL Loss: 0.2551  Val_Acc: 89.955

Epoch 59: Validation loss decreased (0.255112 --> 0.254882).  Saving model ...
	 Train_Loss: 0.2908 Train_Acc: 88.046 Val_Loss: 0.2549  BEST VAL Loss: 0.2549  Val_Acc: 90.009

Epoch 60: Validation loss decreased (0.254882 --> 0.254629).  Saving model ...
	 Train_Loss: 0.2905 Train_Acc: 88.019 Val_Loss: 0.2546  BEST VAL Loss: 0.2546  Val_Acc: 89.869

Epoch 61: Validation loss decreased (0.254629 --> 0.254380).  Saving model ...
	 Train_Loss: 0.2902 Train_Acc: 88.011 Val_Loss: 0.2544  BEST VAL Loss: 0.2544  Val_Acc: 90.015

Epoch 62: Validation loss decreased (0.254380 --> 0.254089).  Saving model ...
	 Train_Loss: 0.2899 Train_Acc: 88.032 Val_Loss: 0.2541  BEST VAL Loss: 0.2541  Val_Acc: 90.082

Epoch 63: Validation loss decreased (0.254089 --> 0.253822).  Saving model ...
	 Train_Loss: 0.2896 Train_Acc: 87.995 Val_Loss: 0.2538  BEST VAL Loss: 0.2538  Val_Acc: 90.047

Epoch 64: Validation loss decreased (0.253822 --> 0.253589).  Saving model ...
	 Train_Loss: 0.2893 Train_Acc: 88.017 Val_Loss: 0.2536  BEST VAL Loss: 0.2536  Val_Acc: 90.098

Epoch 65: Validation loss decreased (0.253589 --> 0.253358).  Saving model ...
	 Train_Loss: 0.2890 Train_Acc: 88.032 Val_Loss: 0.2534  BEST VAL Loss: 0.2534  Val_Acc: 90.075

Epoch 66: Validation loss decreased (0.253358 --> 0.253111).  Saving model ...
	 Train_Loss: 0.2887 Train_Acc: 88.030 Val_Loss: 0.2531  BEST VAL Loss: 0.2531  Val_Acc: 90.022

Epoch 67: Validation loss decreased (0.253111 --> 0.252902).  Saving model ...
	 Train_Loss: 0.2884 Train_Acc: 88.029 Val_Loss: 0.2529  BEST VAL Loss: 0.2529  Val_Acc: 90.075

Epoch 68: Validation loss decreased (0.252902 --> 0.252707).  Saving model ...
	 Train_Loss: 0.2882 Train_Acc: 88.074 Val_Loss: 0.2527  BEST VAL Loss: 0.2527  Val_Acc: 89.996

Epoch 69: Validation loss decreased (0.252707 --> 0.252503).  Saving model ...
	 Train_Loss: 0.2879 Train_Acc: 88.111 Val_Loss: 0.2525  BEST VAL Loss: 0.2525  Val_Acc: 90.088

Epoch 70: Validation loss decreased (0.252503 --> 0.252299).  Saving model ...
	 Train_Loss: 0.2876 Train_Acc: 88.114 Val_Loss: 0.2523  BEST VAL Loss: 0.2523  Val_Acc: 90.259

Epoch 71: Validation loss decreased (0.252299 --> 0.252074).  Saving model ...
	 Train_Loss: 0.2874 Train_Acc: 88.045 Val_Loss: 0.2521  BEST VAL Loss: 0.2521  Val_Acc: 90.218

Epoch 72: Validation loss decreased (0.252074 --> 0.251887).  Saving model ...
	 Train_Loss: 0.2871 Train_Acc: 88.147 Val_Loss: 0.2519  BEST VAL Loss: 0.2519  Val_Acc: 89.936

Epoch 73: Validation loss decreased (0.251887 --> 0.251707).  Saving model ...
	 Train_Loss: 0.2868 Train_Acc: 88.202 Val_Loss: 0.2517  BEST VAL Loss: 0.2517  Val_Acc: 89.923

Epoch 74: Validation loss decreased (0.251707 --> 0.251491).  Saving model ...
	 Train_Loss: 0.2866 Train_Acc: 88.211 Val_Loss: 0.2515  BEST VAL Loss: 0.2515  Val_Acc: 90.212

Epoch 75: Validation loss decreased (0.251491 --> 0.251289).  Saving model ...
	 Train_Loss: 0.2863 Train_Acc: 88.206 Val_Loss: 0.2513  BEST VAL Loss: 0.2513  Val_Acc: 90.044

Epoch 76: Validation loss decreased (0.251289 --> 0.251075).  Saving model ...
	 Train_Loss: 0.2861 Train_Acc: 88.160 Val_Loss: 0.2511  BEST VAL Loss: 0.2511  Val_Acc: 90.025

Epoch 77: Validation loss decreased (0.251075 --> 0.250964).  Saving model ...
	 Train_Loss: 0.2858 Train_Acc: 88.145 Val_Loss: 0.2510  BEST VAL Loss: 0.2510  Val_Acc: 89.977

Epoch 78: Validation loss decreased (0.250964 --> 0.250797).  Saving model ...
	 Train_Loss: 0.2856 Train_Acc: 88.198 Val_Loss: 0.2508  BEST VAL Loss: 0.2508  Val_Acc: 89.990

Epoch 79: Validation loss decreased (0.250797 --> 0.250604).  Saving model ...
	 Train_Loss: 0.2854 Train_Acc: 88.199 Val_Loss: 0.2506  BEST VAL Loss: 0.2506  Val_Acc: 90.155

Epoch 80: Validation loss decreased (0.250604 --> 0.250405).  Saving model ...
	 Train_Loss: 0.2851 Train_Acc: 88.175 Val_Loss: 0.2504  BEST VAL Loss: 0.2504  Val_Acc: 90.310

Epoch 81: Validation loss decreased (0.250405 --> 0.250247).  Saving model ...
	 Train_Loss: 0.2849 Train_Acc: 88.270 Val_Loss: 0.2502  BEST VAL Loss: 0.2502  Val_Acc: 90.139

Epoch 82: Validation loss decreased (0.250247 --> 0.250086).  Saving model ...
	 Train_Loss: 0.2847 Train_Acc: 88.227 Val_Loss: 0.2501  BEST VAL Loss: 0.2501  Val_Acc: 89.898

Epoch 83: Validation loss decreased (0.250086 --> 0.249925).  Saving model ...
	 Train_Loss: 0.2845 Train_Acc: 88.188 Val_Loss: 0.2499  BEST VAL Loss: 0.2499  Val_Acc: 90.129

Epoch 84: Validation loss decreased (0.249925 --> 0.249779).  Saving model ...
	 Train_Loss: 0.2842 Train_Acc: 88.228 Val_Loss: 0.2498  BEST VAL Loss: 0.2498  Val_Acc: 90.098

Epoch 85: Validation loss decreased (0.249779 --> 0.249610).  Saving model ...
	 Train_Loss: 0.2840 Train_Acc: 88.226 Val_Loss: 0.2496  BEST VAL Loss: 0.2496  Val_Acc: 90.202

Epoch 86: Validation loss decreased (0.249610 --> 0.249441).  Saving model ...
	 Train_Loss: 0.2838 Train_Acc: 88.198 Val_Loss: 0.2494  BEST VAL Loss: 0.2494  Val_Acc: 90.205

Epoch 87: Validation loss decreased (0.249441 --> 0.249301).  Saving model ...
	 Train_Loss: 0.2836 Train_Acc: 88.202 Val_Loss: 0.2493  BEST VAL Loss: 0.2493  Val_Acc: 90.170

Epoch 88: Validation loss decreased (0.249301 --> 0.249132).  Saving model ...
	 Train_Loss: 0.2834 Train_Acc: 88.213 Val_Loss: 0.2491  BEST VAL Loss: 0.2491  Val_Acc: 90.300

Epoch 89: Validation loss decreased (0.249132 --> 0.248972).  Saving model ...
	 Train_Loss: 0.2832 Train_Acc: 88.154 Val_Loss: 0.2490  BEST VAL Loss: 0.2490  Val_Acc: 90.028

Epoch 90: Validation loss decreased (0.248972 --> 0.248821).  Saving model ...
	 Train_Loss: 0.2830 Train_Acc: 88.297 Val_Loss: 0.2488  BEST VAL Loss: 0.2488  Val_Acc: 90.234

Epoch 91: Validation loss decreased (0.248821 --> 0.248669).  Saving model ...
	 Train_Loss: 0.2828 Train_Acc: 88.231 Val_Loss: 0.2487  BEST VAL Loss: 0.2487  Val_Acc: 90.006

Epoch 92: Validation loss decreased (0.248669 --> 0.248523).  Saving model ...
	 Train_Loss: 0.2826 Train_Acc: 88.254 Val_Loss: 0.2485  BEST VAL Loss: 0.2485  Val_Acc: 90.117

Epoch 93: Validation loss decreased (0.248523 --> 0.248366).  Saving model ...
	 Train_Loss: 0.2824 Train_Acc: 88.265 Val_Loss: 0.2484  BEST VAL Loss: 0.2484  Val_Acc: 90.259

Epoch 94: Validation loss decreased (0.248366 --> 0.248198).  Saving model ...
	 Train_Loss: 0.2823 Train_Acc: 88.202 Val_Loss: 0.2482  BEST VAL Loss: 0.2482  Val_Acc: 90.405

Epoch 95: Validation loss decreased (0.248198 --> 0.248027).  Saving model ...
	 Train_Loss: 0.2821 Train_Acc: 88.219 Val_Loss: 0.2480  BEST VAL Loss: 0.2480  Val_Acc: 90.300

Epoch 96: Validation loss decreased (0.248027 --> 0.247861).  Saving model ...
	 Train_Loss: 0.2819 Train_Acc: 88.251 Val_Loss: 0.2479  BEST VAL Loss: 0.2479  Val_Acc: 90.294

Epoch 97: Validation loss decreased (0.247861 --> 0.247708).  Saving model ...
	 Train_Loss: 0.2817 Train_Acc: 88.274 Val_Loss: 0.2477  BEST VAL Loss: 0.2477  Val_Acc: 90.453

Epoch 98: Validation loss decreased (0.247708 --> 0.247554).  Saving model ...
	 Train_Loss: 0.2815 Train_Acc: 88.294 Val_Loss: 0.2476  BEST VAL Loss: 0.2476  Val_Acc: 90.418

Epoch 99: Validation loss decreased (0.247554 --> 0.247388).  Saving model ...
	 Train_Loss: 0.2814 Train_Acc: 88.333 Val_Loss: 0.2474  BEST VAL Loss: 0.2474  Val_Acc: 90.326

H2O2_100.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.67      0.69      0.68    169560
           1       0.33      0.31      0.32     82898

    accuracy                           0.57    252458
   macro avg       0.50      0.50      0.50    252458
weighted avg       0.56      0.57      0.56    252458

H2O2_100.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.67      0.69      0.68     21196
           1       0.32      0.30      0.31     10362

    accuracy                           0.56     31558
   macro avg       0.49      0.49      0.49     31558
weighted avg       0.55      0.56      0.56     31558

H2O2_100.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.67      0.69      0.68     21196
           1       0.33      0.31      0.32     10362

    accuracy                           0.57     31558
   macro avg       0.50      0.50      0.50     31558
weighted avg       0.56      0.57      0.56     31558

              precision    recall  f1-score   support

           0       0.67      0.69      0.68     21196
           1       0.33      0.31      0.32     10362

    accuracy                           0.57     31558
   macro avg       0.50      0.50      0.50     31558
weighted avg       0.56      0.57      0.56     31558

H2O2_100.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.44      0.82      0.58     28584
           1       0.56      0.18      0.27     35811

    accuracy                           0.46     64395
   macro avg       0.50      0.50      0.42     64395
weighted avg       0.51      0.46      0.41     64395

              precision    recall  f1-score   support

           0       0.44      0.82      0.58     28584
           1       0.56      0.18      0.27     35811

    accuracy                           0.46     64395
   macro avg       0.50      0.50      0.42     64395
weighted avg       0.51      0.46      0.41     64395

completed
