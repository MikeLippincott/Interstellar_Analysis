[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'a01583ff'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '3f42d874'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1ce690e9'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '7e51807f'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_Nigericin_1.000_3.0_DMSO_0.025'
 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (28054, 1276)
Number of total missing values across all columns: 0
Data Subset Is Off
Wells held out for testing: ['L16' 'M20']
Wells to use for training, validation, and testing ['M16' 'L17' 'M17' 'L20' 'L21' 'M21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.681478).  Saving model ...
	 Train_Loss: 0.7044 Train_Acc: 50.329 Val_Loss: 0.6815  BEST VAL Loss: 0.6815  Val_Acc: 53.197

Epoch 1: Validation loss decreased (0.681478 --> 0.674576).  Saving model ...
	 Train_Loss: 0.6961 Train_Acc: 53.868 Val_Loss: 0.6746  BEST VAL Loss: 0.6746  Val_Acc: 57.345

Epoch 2: Validation loss decreased (0.674576 --> 0.668661).  Saving model ...
	 Train_Loss: 0.6885 Train_Acc: 57.345 Val_Loss: 0.6687  BEST VAL Loss: 0.6687  Val_Acc: 60.957

Epoch 3: Validation loss decreased (0.668661 --> 0.663716).  Saving model ...
	 Train_Loss: 0.6818 Train_Acc: 59.145 Val_Loss: 0.6637  BEST VAL Loss: 0.6637  Val_Acc: 63.202

Epoch 4: Validation loss decreased (0.663716 --> 0.659284).  Saving model ...
	 Train_Loss: 0.6766 Train_Acc: 60.426 Val_Loss: 0.6593  BEST VAL Loss: 0.6593  Val_Acc: 63.934

Epoch 5: Validation loss decreased (0.659284 --> 0.654873).  Saving model ...
	 Train_Loss: 0.6714 Train_Acc: 61.652 Val_Loss: 0.6549  BEST VAL Loss: 0.6549  Val_Acc: 64.861

Epoch 6: Validation loss decreased (0.654873 --> 0.650963).  Saving model ...
	 Train_Loss: 0.6665 Train_Acc: 63.439 Val_Loss: 0.6510  BEST VAL Loss: 0.6510  Val_Acc: 65.642

Epoch 7: Validation loss decreased (0.650963 --> 0.647376).  Saving model ...
	 Train_Loss: 0.6620 Train_Acc: 64.635 Val_Loss: 0.6474  BEST VAL Loss: 0.6474  Val_Acc: 66.227

Epoch 8: Validation loss decreased (0.647376 --> 0.643928).  Saving model ...
	 Train_Loss: 0.6579 Train_Acc: 64.666 Val_Loss: 0.6439  BEST VAL Loss: 0.6439  Val_Acc: 66.520

Epoch 9: Validation loss decreased (0.643928 --> 0.640674).  Saving model ...
	 Train_Loss: 0.6541 Train_Acc: 65.367 Val_Loss: 0.6407  BEST VAL Loss: 0.6407  Val_Acc: 67.106

Epoch 10: Validation loss decreased (0.640674 --> 0.637597).  Saving model ...
	 Train_Loss: 0.6504 Train_Acc: 66.301 Val_Loss: 0.6376  BEST VAL Loss: 0.6376  Val_Acc: 67.301

Epoch 11: Validation loss decreased (0.637597 --> 0.634822).  Saving model ...
	 Train_Loss: 0.6468 Train_Acc: 66.770 Val_Loss: 0.6348  BEST VAL Loss: 0.6348  Val_Acc: 68.082

Epoch 12: Validation loss decreased (0.634822 --> 0.632104).  Saving model ...
	 Train_Loss: 0.6435 Train_Acc: 67.088 Val_Loss: 0.6321  BEST VAL Loss: 0.6321  Val_Acc: 68.131

Epoch 13: Validation loss decreased (0.632104 --> 0.629574).  Saving model ...
	 Train_Loss: 0.6404 Train_Acc: 67.740 Val_Loss: 0.6296  BEST VAL Loss: 0.6296  Val_Acc: 68.228

Epoch 14: Validation loss decreased (0.629574 --> 0.627113).  Saving model ...
	 Train_Loss: 0.6373 Train_Acc: 67.637 Val_Loss: 0.6271  BEST VAL Loss: 0.6271  Val_Acc: 68.424

Epoch 15: Validation loss decreased (0.627113 --> 0.624699).  Saving model ...
	 Train_Loss: 0.6344 Train_Acc: 68.320 Val_Loss: 0.6247  BEST VAL Loss: 0.6247  Val_Acc: 68.668

Epoch 16: Validation loss decreased (0.624699 --> 0.622414).  Saving model ...
	 Train_Loss: 0.6315 Train_Acc: 68.637 Val_Loss: 0.6224  BEST VAL Loss: 0.6224  Val_Acc: 68.716

Epoch 17: Validation loss decreased (0.622414 --> 0.620147).  Saving model ...
	 Train_Loss: 0.6287 Train_Acc: 69.082 Val_Loss: 0.6201  BEST VAL Loss: 0.6201  Val_Acc: 68.863

Epoch 18: Validation loss decreased (0.620147 --> 0.618016).  Saving model ...
	 Train_Loss: 0.6262 Train_Acc: 68.832 Val_Loss: 0.6180  BEST VAL Loss: 0.6180  Val_Acc: 69.058

Epoch 19: Validation loss decreased (0.618016 --> 0.616006).  Saving model ...
	 Train_Loss: 0.6237 Train_Acc: 69.143 Val_Loss: 0.6160  BEST VAL Loss: 0.6160  Val_Acc: 69.546

Epoch 20: Validation loss decreased (0.616006 --> 0.613999).  Saving model ...
	 Train_Loss: 0.6211 Train_Acc: 70.004 Val_Loss: 0.6140  BEST VAL Loss: 0.6140  Val_Acc: 69.644

Epoch 21: Validation loss decreased (0.613999 --> 0.612122).  Saving model ...
	 Train_Loss: 0.6187 Train_Acc: 70.168 Val_Loss: 0.6121  BEST VAL Loss: 0.6121  Val_Acc: 69.400

Epoch 22: Validation loss decreased (0.612122 --> 0.610306).  Saving model ...
	 Train_Loss: 0.6164 Train_Acc: 70.144 Val_Loss: 0.6103  BEST VAL Loss: 0.6103  Val_Acc: 69.839

Epoch 23: Validation loss decreased (0.610306 --> 0.608445).  Saving model ...
	 Train_Loss: 0.6142 Train_Acc: 70.510 Val_Loss: 0.6084  BEST VAL Loss: 0.6084  Val_Acc: 70.083

Epoch 24: Validation loss decreased (0.608445 --> 0.606707).  Saving model ...
	 Train_Loss: 0.6120 Train_Acc: 70.516 Val_Loss: 0.6067  BEST VAL Loss: 0.6067  Val_Acc: 70.229

Epoch 25: Validation loss decreased (0.606707 --> 0.605017).  Saving model ...
	 Train_Loss: 0.6098 Train_Acc: 71.236 Val_Loss: 0.6050  BEST VAL Loss: 0.6050  Val_Acc: 70.229

Epoch 26: Validation loss decreased (0.605017 --> 0.603311).  Saving model ...
	 Train_Loss: 0.6079 Train_Acc: 70.846 Val_Loss: 0.6033  BEST VAL Loss: 0.6033  Val_Acc: 70.425

Epoch 27: Validation loss decreased (0.603311 --> 0.601602).  Saving model ...
	 Train_Loss: 0.6059 Train_Acc: 71.230 Val_Loss: 0.6016  BEST VAL Loss: 0.6016  Val_Acc: 70.425

Epoch 28: Validation loss decreased (0.601602 --> 0.599970).  Saving model ...
	 Train_Loss: 0.6040 Train_Acc: 71.486 Val_Loss: 0.6000  BEST VAL Loss: 0.6000  Val_Acc: 70.571

Epoch 29: Validation loss decreased (0.599970 --> 0.598423).  Saving model ...
	 Train_Loss: 0.6019 Train_Acc: 72.102 Val_Loss: 0.5984  BEST VAL Loss: 0.5984  Val_Acc: 71.010

Epoch 30: Validation loss decreased (0.598423 --> 0.596918).  Saving model ...
	 Train_Loss: 0.6001 Train_Acc: 72.053 Val_Loss: 0.5969  BEST VAL Loss: 0.5969  Val_Acc: 71.157

Epoch 31: Validation loss decreased (0.596918 --> 0.595454).  Saving model ...
	 Train_Loss: 0.5982 Train_Acc: 72.395 Val_Loss: 0.5955  BEST VAL Loss: 0.5955  Val_Acc: 71.352

Epoch 32: Validation loss decreased (0.595454 --> 0.594002).  Saving model ...
	 Train_Loss: 0.5965 Train_Acc: 72.407 Val_Loss: 0.5940  BEST VAL Loss: 0.5940  Val_Acc: 71.157

Epoch 33: Validation loss decreased (0.594002 --> 0.592632).  Saving model ...
	 Train_Loss: 0.5947 Train_Acc: 72.328 Val_Loss: 0.5926  BEST VAL Loss: 0.5926  Val_Acc: 71.352

Epoch 34: Validation loss decreased (0.592632 --> 0.591296).  Saving model ...
	 Train_Loss: 0.5930 Train_Acc: 72.883 Val_Loss: 0.5913  BEST VAL Loss: 0.5913  Val_Acc: 71.157

Epoch 35: Validation loss decreased (0.591296 --> 0.590129).  Saving model ...
	 Train_Loss: 0.5913 Train_Acc: 72.755 Val_Loss: 0.5901  BEST VAL Loss: 0.5901  Val_Acc: 71.303

Epoch 36: Validation loss decreased (0.590129 --> 0.588946).  Saving model ...
	 Train_Loss: 0.5897 Train_Acc: 72.804 Val_Loss: 0.5889  BEST VAL Loss: 0.5889  Val_Acc: 71.498

Epoch 37: Validation loss decreased (0.588946 --> 0.587722).  Saving model ...
	 Train_Loss: 0.5881 Train_Acc: 73.084 Val_Loss: 0.5877  BEST VAL Loss: 0.5877  Val_Acc: 71.303

Epoch 38: Validation loss decreased (0.587722 --> 0.586616).  Saving model ...
	 Train_Loss: 0.5865 Train_Acc: 72.956 Val_Loss: 0.5866  BEST VAL Loss: 0.5866  Val_Acc: 71.059

Epoch 39: Validation loss decreased (0.586616 --> 0.585496).  Saving model ...
	 Train_Loss: 0.5849 Train_Acc: 73.255 Val_Loss: 0.5855  BEST VAL Loss: 0.5855  Val_Acc: 71.547

Epoch 40: Validation loss decreased (0.585496 --> 0.584322).  Saving model ...
	 Train_Loss: 0.5834 Train_Acc: 73.591 Val_Loss: 0.5843  BEST VAL Loss: 0.5843  Val_Acc: 71.303

Epoch 41: Validation loss decreased (0.584322 --> 0.583231).  Saving model ...
	 Train_Loss: 0.5820 Train_Acc: 73.371 Val_Loss: 0.5832  BEST VAL Loss: 0.5832  Val_Acc: 71.547

Epoch 42: Validation loss decreased (0.583231 --> 0.582165).  Saving model ...
	 Train_Loss: 0.5806 Train_Acc: 73.572 Val_Loss: 0.5822  BEST VAL Loss: 0.5822  Val_Acc: 71.596

Epoch 43: Validation loss decreased (0.582165 --> 0.581081).  Saving model ...
	 Train_Loss: 0.5792 Train_Acc: 73.810 Val_Loss: 0.5811  BEST VAL Loss: 0.5811  Val_Acc: 71.791

Epoch 44: Validation loss decreased (0.581081 --> 0.580069).  Saving model ...
	 Train_Loss: 0.5777 Train_Acc: 74.158 Val_Loss: 0.5801  BEST VAL Loss: 0.5801  Val_Acc: 71.645

Epoch 45: Validation loss decreased (0.580069 --> 0.579113).  Saving model ...
	 Train_Loss: 0.5764 Train_Acc: 73.939 Val_Loss: 0.5791  BEST VAL Loss: 0.5791  Val_Acc: 71.742

Epoch 46: Validation loss decreased (0.579113 --> 0.578130).  Saving model ...
	 Train_Loss: 0.5750 Train_Acc: 74.384 Val_Loss: 0.5781  BEST VAL Loss: 0.5781  Val_Acc: 71.938

Epoch 47: Validation loss decreased (0.578130 --> 0.577150).  Saving model ...
	 Train_Loss: 0.5737 Train_Acc: 74.054 Val_Loss: 0.5771  BEST VAL Loss: 0.5771  Val_Acc: 71.986

Epoch 48: Validation loss decreased (0.577150 --> 0.576243).  Saving model ...
	 Train_Loss: 0.5724 Train_Acc: 74.298 Val_Loss: 0.5762  BEST VAL Loss: 0.5762  Val_Acc: 71.938

Epoch 49: Validation loss decreased (0.576243 --> 0.575334).  Saving model ...
	 Train_Loss: 0.5711 Train_Acc: 74.536 Val_Loss: 0.5753  BEST VAL Loss: 0.5753  Val_Acc: 71.986

Epoch 50: Validation loss decreased (0.575334 --> 0.574471).  Saving model ...
	 Train_Loss: 0.5699 Train_Acc: 74.353 Val_Loss: 0.5745  BEST VAL Loss: 0.5745  Val_Acc: 71.938

Epoch 51: Validation loss decreased (0.574471 --> 0.573652).  Saving model ...
	 Train_Loss: 0.5687 Train_Acc: 74.286 Val_Loss: 0.5737  BEST VAL Loss: 0.5737  Val_Acc: 72.084

Epoch 52: Validation loss decreased (0.573652 --> 0.572804).  Saving model ...
	 Train_Loss: 0.5674 Train_Acc: 74.780 Val_Loss: 0.5728  BEST VAL Loss: 0.5728  Val_Acc: 72.328

Epoch 53: Validation loss decreased (0.572804 --> 0.572030).  Saving model ...
	 Train_Loss: 0.5662 Train_Acc: 75.104 Val_Loss: 0.5720  BEST VAL Loss: 0.5720  Val_Acc: 72.084

Epoch 54: Validation loss decreased (0.572030 --> 0.571238).  Saving model ...
	 Train_Loss: 0.5650 Train_Acc: 75.067 Val_Loss: 0.5712  BEST VAL Loss: 0.5712  Val_Acc: 71.889

Epoch 55: Validation loss decreased (0.571238 --> 0.570484).  Saving model ...
	 Train_Loss: 0.5639 Train_Acc: 74.969 Val_Loss: 0.5705  BEST VAL Loss: 0.5705  Val_Acc: 72.328

Epoch 56: Validation loss decreased (0.570484 --> 0.569763).  Saving model ...
	 Train_Loss: 0.5627 Train_Acc: 75.128 Val_Loss: 0.5698  BEST VAL Loss: 0.5698  Val_Acc: 71.889

Epoch 57: Validation loss decreased (0.569763 --> 0.569031).  Saving model ...
	 Train_Loss: 0.5615 Train_Acc: 74.982 Val_Loss: 0.5690  BEST VAL Loss: 0.5690  Val_Acc: 72.670

Epoch 58: Validation loss decreased (0.569031 --> 0.568308).  Saving model ...
	 Train_Loss: 0.5604 Train_Acc: 75.183 Val_Loss: 0.5683  BEST VAL Loss: 0.5683  Val_Acc: 72.084

Epoch 59: Validation loss decreased (0.568308 --> 0.567632).  Saving model ...
	 Train_Loss: 0.5593 Train_Acc: 75.189 Val_Loss: 0.5676  BEST VAL Loss: 0.5676  Val_Acc: 72.328

Epoch 60: Validation loss decreased (0.567632 --> 0.567051).  Saving model ...
	 Train_Loss: 0.5583 Train_Acc: 75.488 Val_Loss: 0.5671  BEST VAL Loss: 0.5671  Val_Acc: 72.133

Epoch 61: Validation loss decreased (0.567051 --> 0.566364).  Saving model ...
	 Train_Loss: 0.5572 Train_Acc: 75.427 Val_Loss: 0.5664  BEST VAL Loss: 0.5664  Val_Acc: 72.035

Epoch 62: Validation loss decreased (0.566364 --> 0.565757).  Saving model ...
	 Train_Loss: 0.5562 Train_Acc: 75.573 Val_Loss: 0.5658  BEST VAL Loss: 0.5658  Val_Acc: 71.889

Epoch 63: Validation loss decreased (0.565757 --> 0.565221).  Saving model ...
	 Train_Loss: 0.5552 Train_Acc: 75.610 Val_Loss: 0.5652  BEST VAL Loss: 0.5652  Val_Acc: 72.182

Epoch 64: Validation loss decreased (0.565221 --> 0.564680).  Saving model ...
	 Train_Loss: 0.5541 Train_Acc: 75.549 Val_Loss: 0.5647  BEST VAL Loss: 0.5647  Val_Acc: 71.742

Epoch 65: Validation loss decreased (0.564680 --> 0.564079).  Saving model ...
	 Train_Loss: 0.5532 Train_Acc: 75.695 Val_Loss: 0.5641  BEST VAL Loss: 0.5641  Val_Acc: 72.914

Epoch 66: Validation loss decreased (0.564079 --> 0.563517).  Saving model ...
	 Train_Loss: 0.5522 Train_Acc: 75.714 Val_Loss: 0.5635  BEST VAL Loss: 0.5635  Val_Acc: 73.060

Epoch 67: Validation loss decreased (0.563517 --> 0.562979).  Saving model ...
	 Train_Loss: 0.5512 Train_Acc: 75.805 Val_Loss: 0.5630  BEST VAL Loss: 0.5630  Val_Acc: 72.670

Epoch 68: Validation loss decreased (0.562979 --> 0.562427).  Saving model ...
	 Train_Loss: 0.5502 Train_Acc: 75.781 Val_Loss: 0.5624  BEST VAL Loss: 0.5624  Val_Acc: 72.084

Epoch 69: Validation loss decreased (0.562427 --> 0.561915).  Saving model ...
	 Train_Loss: 0.5493 Train_Acc: 76.007 Val_Loss: 0.5619  BEST VAL Loss: 0.5619  Val_Acc: 72.621

Epoch 70: Validation loss decreased (0.561915 --> 0.561422).  Saving model ...
	 Train_Loss: 0.5484 Train_Acc: 76.080 Val_Loss: 0.5614  BEST VAL Loss: 0.5614  Val_Acc: 72.230

Epoch 71: Validation loss decreased (0.561422 --> 0.560913).  Saving model ...
	 Train_Loss: 0.5475 Train_Acc: 75.964 Val_Loss: 0.5609  BEST VAL Loss: 0.5609  Val_Acc: 72.572

Epoch 72: Validation loss decreased (0.560913 --> 0.560478).  Saving model ...
	 Train_Loss: 0.5466 Train_Acc: 76.440 Val_Loss: 0.5605  BEST VAL Loss: 0.5605  Val_Acc: 72.426

Epoch 73: Validation loss decreased (0.560478 --> 0.560010).  Saving model ...
	 Train_Loss: 0.5457 Train_Acc: 75.994 Val_Loss: 0.5600  BEST VAL Loss: 0.5600  Val_Acc: 72.767

Epoch 74: Validation loss decreased (0.560010 --> 0.559568).  Saving model ...
	 Train_Loss: 0.5448 Train_Acc: 76.489 Val_Loss: 0.5596  BEST VAL Loss: 0.5596  Val_Acc: 72.084

Epoch 75: Validation loss decreased (0.559568 --> 0.559148).  Saving model ...
	 Train_Loss: 0.5439 Train_Acc: 76.074 Val_Loss: 0.5591  BEST VAL Loss: 0.5591  Val_Acc: 72.767

Epoch 76: Validation loss decreased (0.559148 --> 0.558679).  Saving model ...
	 Train_Loss: 0.5431 Train_Acc: 76.269 Val_Loss: 0.5587  BEST VAL Loss: 0.5587  Val_Acc: 72.767

Epoch 77: Validation loss decreased (0.558679 --> 0.558304).  Saving model ...
	 Train_Loss: 0.5422 Train_Acc: 76.452 Val_Loss: 0.5583  BEST VAL Loss: 0.5583  Val_Acc: 72.718

Epoch 78: Validation loss decreased (0.558304 --> 0.557856).  Saving model ...
	 Train_Loss: 0.5413 Train_Acc: 76.867 Val_Loss: 0.5579  BEST VAL Loss: 0.5579  Val_Acc: 72.718

Epoch 79: Validation loss decreased (0.557856 --> 0.557418).  Saving model ...
	 Train_Loss: 0.5405 Train_Acc: 76.556 Val_Loss: 0.5574  BEST VAL Loss: 0.5574  Val_Acc: 73.011

Epoch 80: Validation loss decreased (0.557418 --> 0.557007).  Saving model ...
	 Train_Loss: 0.5397 Train_Acc: 76.330 Val_Loss: 0.5570  BEST VAL Loss: 0.5570  Val_Acc: 73.060

Epoch 81: Validation loss decreased (0.557007 --> 0.556681).  Saving model ...
	 Train_Loss: 0.5389 Train_Acc: 76.531 Val_Loss: 0.5567  BEST VAL Loss: 0.5567  Val_Acc: 72.328

Epoch 82: Validation loss decreased (0.556681 --> 0.556320).  Saving model ...
	 Train_Loss: 0.5381 Train_Acc: 76.324 Val_Loss: 0.5563  BEST VAL Loss: 0.5563  Val_Acc: 72.865

Epoch 83: Validation loss decreased (0.556320 --> 0.555960).  Saving model ...
	 Train_Loss: 0.5373 Train_Acc: 76.641 Val_Loss: 0.5560  BEST VAL Loss: 0.5560  Val_Acc: 72.523

Epoch 84: Validation loss decreased (0.555960 --> 0.555656).  Saving model ...
	 Train_Loss: 0.5366 Train_Acc: 76.611 Val_Loss: 0.5557  BEST VAL Loss: 0.5557  Val_Acc: 72.279

Epoch 85: Validation loss decreased (0.555656 --> 0.555367).  Saving model ...
	 Train_Loss: 0.5358 Train_Acc: 76.812 Val_Loss: 0.5554  BEST VAL Loss: 0.5554  Val_Acc: 71.498

Epoch 86: Validation loss decreased (0.555367 --> 0.555010).  Saving model ...
	 Train_Loss: 0.5350 Train_Acc: 77.056 Val_Loss: 0.5550  BEST VAL Loss: 0.5550  Val_Acc: 72.377

Epoch 87: Validation loss decreased (0.555010 --> 0.554678).  Saving model ...
	 Train_Loss: 0.5343 Train_Acc: 76.934 Val_Loss: 0.5547  BEST VAL Loss: 0.5547  Val_Acc: 72.572

Epoch 88: Validation loss decreased (0.554678 --> 0.554362).  Saving model ...
	 Train_Loss: 0.5335 Train_Acc: 77.111 Val_Loss: 0.5544  BEST VAL Loss: 0.5544  Val_Acc: 72.914

Epoch 89: Validation loss decreased (0.554362 --> 0.553997).  Saving model ...
	 Train_Loss: 0.5328 Train_Acc: 76.873 Val_Loss: 0.5540  BEST VAL Loss: 0.5540  Val_Acc: 73.109

Epoch 90: Validation loss decreased (0.553997 --> 0.553691).  Saving model ...
	 Train_Loss: 0.5321 Train_Acc: 76.836 Val_Loss: 0.5537  BEST VAL Loss: 0.5537  Val_Acc: 72.962

Epoch 91: Validation loss decreased (0.553691 --> 0.553347).  Saving model ...
	 Train_Loss: 0.5314 Train_Acc: 76.787 Val_Loss: 0.5533  BEST VAL Loss: 0.5533  Val_Acc: 72.621

Epoch 92: Validation loss decreased (0.553347 --> 0.553045).  Saving model ...
	 Train_Loss: 0.5307 Train_Acc: 77.080 Val_Loss: 0.5530  BEST VAL Loss: 0.5530  Val_Acc: 73.206

Epoch 93: Validation loss decreased (0.553045 --> 0.552772).  Saving model ...
	 Train_Loss: 0.5300 Train_Acc: 76.867 Val_Loss: 0.5528  BEST VAL Loss: 0.5528  Val_Acc: 72.182

Epoch 94: Validation loss decreased (0.552772 --> 0.552460).  Saving model ...
	 Train_Loss: 0.5293 Train_Acc: 77.300 Val_Loss: 0.5525  BEST VAL Loss: 0.5525  Val_Acc: 72.816

Epoch 95: Validation loss decreased (0.552460 --> 0.552207).  Saving model ...
	 Train_Loss: 0.5286 Train_Acc: 77.452 Val_Loss: 0.5522  BEST VAL Loss: 0.5522  Val_Acc: 72.962

Epoch 96: Validation loss decreased (0.552207 --> 0.551936).  Saving model ...
	 Train_Loss: 0.5279 Train_Acc: 77.282 Val_Loss: 0.5519  BEST VAL Loss: 0.5519  Val_Acc: 73.109

Epoch 97: Validation loss decreased (0.551936 --> 0.551667).  Saving model ...
	 Train_Loss: 0.5272 Train_Acc: 77.269 Val_Loss: 0.5517  BEST VAL Loss: 0.5517  Val_Acc: 72.279

Epoch 98: Validation loss decreased (0.551667 --> 0.551409).  Saving model ...
	 Train_Loss: 0.5266 Train_Acc: 77.178 Val_Loss: 0.5514  BEST VAL Loss: 0.5514  Val_Acc: 72.621

Epoch 99: Validation loss decreased (0.551409 --> 0.551200).  Saving model ...
	 Train_Loss: 0.5259 Train_Acc: 77.410 Val_Loss: 0.5512  BEST VAL Loss: 0.5512  Val_Acc: 72.328

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.80      0.81      0.80      8453
           1       0.79      0.79      0.79      7939

    accuracy                           0.80     16392
   macro avg       0.80      0.80      0.80     16392
weighted avg       0.80      0.80      0.80     16392

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.73      0.73      0.73      1057
           1       0.71      0.71      0.71       992

    accuracy                           0.72      2049
   macro avg       0.72      0.72      0.72      2049
weighted avg       0.72      0.72      0.72      2049

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.75      0.74      0.75      1057
           1       0.73      0.74      0.73       992

    accuracy                           0.74      2049
   macro avg       0.74      0.74      0.74      2049
weighted avg       0.74      0.74      0.74      2049

              precision    recall  f1-score   support

           0       0.75      0.74      0.75      1057
           1       0.73      0.74      0.73       992

    accuracy                           0.74      2049
   macro avg       0.74      0.74      0.74      2049
weighted avg       0.74      0.74      0.74      2049

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.64      0.41      0.50      3835
           1       0.56      0.77      0.65      3729

    accuracy                           0.59      7564
   macro avg       0.60      0.59      0.57      7564
weighted avg       0.60      0.59      0.57      7564

              precision    recall  f1-score   support

           0       0.64      0.41      0.50      3835
           1       0.56      0.77      0.65      3729

    accuracy                           0.59      7564
   macro avg       0.60      0.59      0.57      7564
weighted avg       0.60      0.59      0.57      7564

completed
