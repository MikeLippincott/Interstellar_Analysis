[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '86e03a10'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '80078dd5'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '9442988f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '32b2baa0'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_1.000_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_1.000_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (235348, 1270)
Number of total missing values across all columns: 470696
Data Subset Is Off
Wells held out for testing: ['D09' 'L10']
Wells to use for training, validation, and testing ['D02' 'D03' 'D08' 'L05' 'L11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.574611).  Saving model ...
	 Train_Loss: 0.6844 Train_Acc: 63.762 Val_Loss: 0.5746  BEST VAL Loss: 0.5746  Val_Acc: 69.655

Epoch 1: Validation loss decreased (0.574611 --> 0.556525).  Saving model ...
	 Train_Loss: 0.6275 Train_Acc: 70.837 Val_Loss: 0.5565  BEST VAL Loss: 0.5565  Val_Acc: 73.579

Epoch 2: Validation loss decreased (0.556525 --> 0.552695).  Saving model ...
	 Train_Loss: 0.5992 Train_Acc: 73.089 Val_Loss: 0.5527  BEST VAL Loss: 0.5527  Val_Acc: 74.959

Epoch 3: Validation loss decreased (0.552695 --> 0.539074).  Saving model ...
	 Train_Loss: 0.5816 Train_Acc: 74.230 Val_Loss: 0.5391  BEST VAL Loss: 0.5391  Val_Acc: 76.490

Epoch 4: Validation loss decreased (0.539074 --> 0.529455).  Saving model ...
	 Train_Loss: 0.5685 Train_Acc: 75.249 Val_Loss: 0.5295  BEST VAL Loss: 0.5295  Val_Acc: 76.778

Epoch 5: Validation loss decreased (0.529455 --> 0.525479).  Saving model ...
	 Train_Loss: 0.5602 Train_Acc: 75.380 Val_Loss: 0.5255  BEST VAL Loss: 0.5255  Val_Acc: 75.914

Epoch 6: Validation loss decreased (0.525479 --> 0.519874).  Saving model ...
	 Train_Loss: 0.5524 Train_Acc: 75.848 Val_Loss: 0.5199  BEST VAL Loss: 0.5199  Val_Acc: 77.114

Epoch 7: Validation loss decreased (0.519874 --> 0.515051).  Saving model ...
	 Train_Loss: 0.5457 Train_Acc: 76.330 Val_Loss: 0.5151  BEST VAL Loss: 0.5151  Val_Acc: 77.714

Epoch 8: Validation loss decreased (0.515051 --> 0.510514).  Saving model ...
	 Train_Loss: 0.5400 Train_Acc: 76.781 Val_Loss: 0.5105  BEST VAL Loss: 0.5105  Val_Acc: 78.014

Epoch 9: Validation loss decreased (0.510514 --> 0.506199).  Saving model ...
	 Train_Loss: 0.5350 Train_Acc: 77.124 Val_Loss: 0.5062  BEST VAL Loss: 0.5062  Val_Acc: 78.566

Epoch 10: Validation loss decreased (0.506199 --> 0.501992).  Saving model ...
	 Train_Loss: 0.5302 Train_Acc: 77.493 Val_Loss: 0.5020  BEST VAL Loss: 0.5020  Val_Acc: 78.584

Epoch 11: Validation loss decreased (0.501992 --> 0.499472).  Saving model ...
	 Train_Loss: 0.5263 Train_Acc: 77.439 Val_Loss: 0.4995  BEST VAL Loss: 0.4995  Val_Acc: 78.830

Epoch 12: Validation loss decreased (0.499472 --> 0.497177).  Saving model ...
	 Train_Loss: 0.5230 Train_Acc: 77.369 Val_Loss: 0.4972  BEST VAL Loss: 0.4972  Val_Acc: 79.052

Epoch 13: Validation loss did not decrease
	 Train_Loss: 0.5217 Train_Acc: 77.059 Val_Loss: 0.5013  BEST VAL Loss: 0.4972  Val_Acc: 75.962

Epoch 14: Validation loss did not decrease
	 Train_Loss: 0.5197 Train_Acc: 76.996 Val_Loss: 0.4991  BEST VAL Loss: 0.4972  Val_Acc: 79.160

Epoch 15: Validation loss decreased (0.497177 --> 0.496928).  Saving model ...
	 Train_Loss: 0.5170 Train_Acc: 77.731 Val_Loss: 0.4969  BEST VAL Loss: 0.4969  Val_Acc: 79.226

Epoch 16: Validation loss decreased (0.496928 --> 0.494389).  Saving model ...
	 Train_Loss: 0.5143 Train_Acc: 77.968 Val_Loss: 0.4944  BEST VAL Loss: 0.4944  Val_Acc: 79.814

Epoch 17: Validation loss decreased (0.494389 --> 0.492454).  Saving model ...
	 Train_Loss: 0.5118 Train_Acc: 78.161 Val_Loss: 0.4925  BEST VAL Loss: 0.4925  Val_Acc: 79.406

Epoch 18: Validation loss decreased (0.492454 --> 0.490378).  Saving model ...
	 Train_Loss: 0.5095 Train_Acc: 78.103 Val_Loss: 0.4904  BEST VAL Loss: 0.4904  Val_Acc: 79.598

Epoch 19: Validation loss decreased (0.490378 --> 0.488223).  Saving model ...
	 Train_Loss: 0.5072 Train_Acc: 78.597 Val_Loss: 0.4882  BEST VAL Loss: 0.4882  Val_Acc: 79.646

Epoch 20: Validation loss decreased (0.488223 --> 0.486533).  Saving model ...
	 Train_Loss: 0.5054 Train_Acc: 78.180 Val_Loss: 0.4865  BEST VAL Loss: 0.4865  Val_Acc: 79.490

Epoch 21: Validation loss decreased (0.486533 --> 0.484694).  Saving model ...
	 Train_Loss: 0.5035 Train_Acc: 78.432 Val_Loss: 0.4847  BEST VAL Loss: 0.4847  Val_Acc: 80.096

Epoch 22: Validation loss decreased (0.484694 --> 0.482886).  Saving model ...
	 Train_Loss: 0.5018 Train_Acc: 78.485 Val_Loss: 0.4829  BEST VAL Loss: 0.4829  Val_Acc: 80.240

Epoch 23: Validation loss decreased (0.482886 --> 0.481016).  Saving model ...
	 Train_Loss: 0.5000 Train_Acc: 78.637 Val_Loss: 0.4810  BEST VAL Loss: 0.4810  Val_Acc: 80.264

Epoch 24: Validation loss decreased (0.481016 --> 0.479780).  Saving model ...
	 Train_Loss: 0.4983 Train_Acc: 78.606 Val_Loss: 0.4798  BEST VAL Loss: 0.4798  Val_Acc: 80.366

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.4968 Train_Acc: 78.663 Val_Loss: 0.4813  BEST VAL Loss: 0.4798  Val_Acc: 79.508

Epoch 26: Validation loss did not decrease
	 Train_Loss: 0.4961 Train_Acc: 78.111 Val_Loss: 0.4801  BEST VAL Loss: 0.4798  Val_Acc: 79.952

Epoch 27: Validation loss decreased (0.479780 --> 0.479457).  Saving model ...
	 Train_Loss: 0.4946 Train_Acc: 78.906 Val_Loss: 0.4795  BEST VAL Loss: 0.4795  Val_Acc: 79.910

Epoch 28: Validation loss decreased (0.479457 --> 0.478535).  Saving model ...
	 Train_Loss: 0.4933 Train_Acc: 78.987 Val_Loss: 0.4785  BEST VAL Loss: 0.4785  Val_Acc: 80.024

Epoch 29: Validation loss decreased (0.478535 --> 0.477058).  Saving model ...
	 Train_Loss: 0.4918 Train_Acc: 79.182 Val_Loss: 0.4771  BEST VAL Loss: 0.4771  Val_Acc: 80.960

Epoch 30: Validation loss decreased (0.477058 --> 0.475608).  Saving model ...
	 Train_Loss: 0.4904 Train_Acc: 79.186 Val_Loss: 0.4756  BEST VAL Loss: 0.4756  Val_Acc: 80.954

Epoch 31: Validation loss decreased (0.475608 --> 0.474170).  Saving model ...
	 Train_Loss: 0.4890 Train_Acc: 79.353 Val_Loss: 0.4742  BEST VAL Loss: 0.4742  Val_Acc: 80.486

Epoch 32: Validation loss decreased (0.474170 --> 0.472765).  Saving model ...
	 Train_Loss: 0.4879 Train_Acc: 79.120 Val_Loss: 0.4728  BEST VAL Loss: 0.4728  Val_Acc: 80.888

Epoch 33: Validation loss decreased (0.472765 --> 0.471694).  Saving model ...
	 Train_Loss: 0.4867 Train_Acc: 79.258 Val_Loss: 0.4717  BEST VAL Loss: 0.4717  Val_Acc: 80.696

Epoch 34: Validation loss decreased (0.471694 --> 0.470551).  Saving model ...
	 Train_Loss: 0.4856 Train_Acc: 79.314 Val_Loss: 0.4706  BEST VAL Loss: 0.4706  Val_Acc: 80.792

Epoch 35: Validation loss decreased (0.470551 --> 0.469802).  Saving model ...
	 Train_Loss: 0.4846 Train_Acc: 79.172 Val_Loss: 0.4698  BEST VAL Loss: 0.4698  Val_Acc: 80.480

Epoch 36: Validation loss decreased (0.469802 --> 0.469430).  Saving model ...
	 Train_Loss: 0.4835 Train_Acc: 79.405 Val_Loss: 0.4694  BEST VAL Loss: 0.4694  Val_Acc: 80.240

Epoch 37: Validation loss decreased (0.469430 --> 0.468494).  Saving model ...
	 Train_Loss: 0.4825 Train_Acc: 79.493 Val_Loss: 0.4685  BEST VAL Loss: 0.4685  Val_Acc: 80.450

Epoch 38: Validation loss decreased (0.468494 --> 0.467628).  Saving model ...
	 Train_Loss: 0.4816 Train_Acc: 79.324 Val_Loss: 0.4676  BEST VAL Loss: 0.4676  Val_Acc: 80.822

Epoch 39: Validation loss decreased (0.467628 --> 0.467050).  Saving model ...
	 Train_Loss: 0.4806 Train_Acc: 79.423 Val_Loss: 0.4670  BEST VAL Loss: 0.4670  Val_Acc: 80.324

Epoch 40: Validation loss decreased (0.467050 --> 0.466107).  Saving model ...
	 Train_Loss: 0.4799 Train_Acc: 79.214 Val_Loss: 0.4661  BEST VAL Loss: 0.4661  Val_Acc: 80.996

Epoch 41: Validation loss decreased (0.466107 --> 0.465313).  Saving model ...
	 Train_Loss: 0.4789 Train_Acc: 79.589 Val_Loss: 0.4653  BEST VAL Loss: 0.4653  Val_Acc: 80.654

Epoch 42: Validation loss decreased (0.465313 --> 0.464373).  Saving model ...
	 Train_Loss: 0.4781 Train_Acc: 79.540 Val_Loss: 0.4644  BEST VAL Loss: 0.4644  Val_Acc: 80.612

Epoch 43: Validation loss decreased (0.464373 --> 0.463824).  Saving model ...
	 Train_Loss: 0.4772 Train_Acc: 79.581 Val_Loss: 0.4638  BEST VAL Loss: 0.4638  Val_Acc: 80.870

Epoch 44: Validation loss decreased (0.463824 --> 0.462823).  Saving model ...
	 Train_Loss: 0.4763 Train_Acc: 79.908 Val_Loss: 0.4628  BEST VAL Loss: 0.4628  Val_Acc: 80.840

Epoch 45: Validation loss decreased (0.462823 --> 0.461895).  Saving model ...
	 Train_Loss: 0.4755 Train_Acc: 79.634 Val_Loss: 0.4619  BEST VAL Loss: 0.4619  Val_Acc: 81.344

Epoch 46: Validation loss decreased (0.461895 --> 0.461061).  Saving model ...
	 Train_Loss: 0.4748 Train_Acc: 79.546 Val_Loss: 0.4611  BEST VAL Loss: 0.4611  Val_Acc: 81.170

Epoch 47: Validation loss decreased (0.461061 --> 0.460561).  Saving model ...
	 Train_Loss: 0.4741 Train_Acc: 79.530 Val_Loss: 0.4606  BEST VAL Loss: 0.4606  Val_Acc: 81.248

Epoch 48: Validation loss decreased (0.460561 --> 0.460099).  Saving model ...
	 Train_Loss: 0.4734 Train_Acc: 79.751 Val_Loss: 0.4601  BEST VAL Loss: 0.4601  Val_Acc: 81.122

Epoch 49: Validation loss decreased (0.460099 --> 0.459618).  Saving model ...
	 Train_Loss: 0.4726 Train_Acc: 79.869 Val_Loss: 0.4596  BEST VAL Loss: 0.4596  Val_Acc: 80.600

Epoch 50: Validation loss decreased (0.459618 --> 0.459241).  Saving model ...
	 Train_Loss: 0.4719 Train_Acc: 79.761 Val_Loss: 0.4592  BEST VAL Loss: 0.4592  Val_Acc: 80.162

Epoch 51: Validation loss decreased (0.459241 --> 0.458741).  Saving model ...
	 Train_Loss: 0.4712 Train_Acc: 79.897 Val_Loss: 0.4587  BEST VAL Loss: 0.4587  Val_Acc: 81.098

Epoch 52: Validation loss decreased (0.458741 --> 0.458246).  Saving model ...
	 Train_Loss: 0.4706 Train_Acc: 79.837 Val_Loss: 0.4582  BEST VAL Loss: 0.4582  Val_Acc: 81.314

Epoch 53: Validation loss decreased (0.458246 --> 0.457862).  Saving model ...
	 Train_Loss: 0.4699 Train_Acc: 79.812 Val_Loss: 0.4579  BEST VAL Loss: 0.4579  Val_Acc: 80.948

Epoch 54: Validation loss decreased (0.457862 --> 0.457250).  Saving model ...
	 Train_Loss: 0.4693 Train_Acc: 79.677 Val_Loss: 0.4573  BEST VAL Loss: 0.4573  Val_Acc: 81.428

Epoch 55: Validation loss decreased (0.457250 --> 0.456801).  Saving model ...
	 Train_Loss: 0.4687 Train_Acc: 79.940 Val_Loss: 0.4568  BEST VAL Loss: 0.4568  Val_Acc: 81.158

Epoch 56: Validation loss decreased (0.456801 --> 0.456206).  Saving model ...
	 Train_Loss: 0.4681 Train_Acc: 79.821 Val_Loss: 0.4562  BEST VAL Loss: 0.4562  Val_Acc: 81.422

Epoch 57: Validation loss decreased (0.456206 --> 0.455758).  Saving model ...
	 Train_Loss: 0.4676 Train_Acc: 79.707 Val_Loss: 0.4558  BEST VAL Loss: 0.4558  Val_Acc: 80.966

Epoch 58: Validation loss decreased (0.455758 --> 0.455468).  Saving model ...
	 Train_Loss: 0.4671 Train_Acc: 79.807 Val_Loss: 0.4555  BEST VAL Loss: 0.4555  Val_Acc: 81.098

Epoch 59: Validation loss decreased (0.455468 --> 0.454896).  Saving model ...
	 Train_Loss: 0.4665 Train_Acc: 79.968 Val_Loss: 0.4549  BEST VAL Loss: 0.4549  Val_Acc: 81.806

Epoch 60: Validation loss decreased (0.454896 --> 0.454454).  Saving model ...
	 Train_Loss: 0.4659 Train_Acc: 79.952 Val_Loss: 0.4545  BEST VAL Loss: 0.4545  Val_Acc: 81.392

Epoch 61: Validation loss decreased (0.454454 --> 0.453850).  Saving model ...
	 Train_Loss: 0.4653 Train_Acc: 80.083 Val_Loss: 0.4539  BEST VAL Loss: 0.4539  Val_Acc: 81.470

Epoch 62: Validation loss decreased (0.453850 --> 0.453512).  Saving model ...
	 Train_Loss: 0.4647 Train_Acc: 80.095 Val_Loss: 0.4535  BEST VAL Loss: 0.4535  Val_Acc: 81.404

Epoch 63: Validation loss decreased (0.453512 --> 0.453183).  Saving model ...
	 Train_Loss: 0.4642 Train_Acc: 80.010 Val_Loss: 0.4532  BEST VAL Loss: 0.4532  Val_Acc: 81.656

Epoch 64: Validation loss decreased (0.453183 --> 0.452783).  Saving model ...
	 Train_Loss: 0.4636 Train_Acc: 80.182 Val_Loss: 0.4528  BEST VAL Loss: 0.4528  Val_Acc: 81.494

Epoch 65: Validation loss decreased (0.452783 --> 0.452588).  Saving model ...
	 Train_Loss: 0.4630 Train_Acc: 80.074 Val_Loss: 0.4526  BEST VAL Loss: 0.4526  Val_Acc: 81.218

Epoch 66: Validation loss decreased (0.452588 --> 0.452165).  Saving model ...
	 Train_Loss: 0.4625 Train_Acc: 80.248 Val_Loss: 0.4522  BEST VAL Loss: 0.4522  Val_Acc: 81.632

Epoch 67: Validation loss decreased (0.452165 --> 0.451970).  Saving model ...
	 Train_Loss: 0.4621 Train_Acc: 80.098 Val_Loss: 0.4520  BEST VAL Loss: 0.4520  Val_Acc: 80.516

Epoch 68: Validation loss decreased (0.451970 --> 0.451940).  Saving model ...
	 Train_Loss: 0.4617 Train_Acc: 80.053 Val_Loss: 0.4519  BEST VAL Loss: 0.4519  Val_Acc: 80.108

Epoch 69: Validation loss decreased (0.451940 --> 0.451590).  Saving model ...
	 Train_Loss: 0.4612 Train_Acc: 80.088 Val_Loss: 0.4516  BEST VAL Loss: 0.4516  Val_Acc: 81.392

Epoch 70: Validation loss decreased (0.451590 --> 0.451415).  Saving model ...
	 Train_Loss: 0.4607 Train_Acc: 80.422 Val_Loss: 0.4514  BEST VAL Loss: 0.4514  Val_Acc: 81.404

Epoch 71: Validation loss decreased (0.451415 --> 0.451365).  Saving model ...
	 Train_Loss: 0.4602 Train_Acc: 80.386 Val_Loss: 0.4514  BEST VAL Loss: 0.4514  Val_Acc: 81.290

Epoch 72: Validation loss decreased (0.451365 --> 0.451012).  Saving model ...
	 Train_Loss: 0.4597 Train_Acc: 80.299 Val_Loss: 0.4510  BEST VAL Loss: 0.4510  Val_Acc: 81.386

Epoch 73: Validation loss decreased (0.451012 --> 0.450698).  Saving model ...
	 Train_Loss: 0.4592 Train_Acc: 80.482 Val_Loss: 0.4507  BEST VAL Loss: 0.4507  Val_Acc: 81.722

Epoch 74: Validation loss decreased (0.450698 --> 0.450364).  Saving model ...
	 Train_Loss: 0.4588 Train_Acc: 80.224 Val_Loss: 0.4504  BEST VAL Loss: 0.4504  Val_Acc: 81.674

Epoch 75: Validation loss decreased (0.450364 --> 0.450102).  Saving model ...
	 Train_Loss: 0.4583 Train_Acc: 80.550 Val_Loss: 0.4501  BEST VAL Loss: 0.4501  Val_Acc: 81.728

Epoch 76: Validation loss decreased (0.450102 --> 0.449765).  Saving model ...
	 Train_Loss: 0.4578 Train_Acc: 80.383 Val_Loss: 0.4498  BEST VAL Loss: 0.4498  Val_Acc: 81.734

Epoch 77: Validation loss decreased (0.449765 --> 0.449512).  Saving model ...
	 Train_Loss: 0.4574 Train_Acc: 80.516 Val_Loss: 0.4495  BEST VAL Loss: 0.4495  Val_Acc: 81.428

Epoch 78: Validation loss decreased (0.449512 --> 0.449461).  Saving model ...
	 Train_Loss: 0.4570 Train_Acc: 80.421 Val_Loss: 0.4495  BEST VAL Loss: 0.4495  Val_Acc: 81.170

Epoch 79: Validation loss decreased (0.449461 --> 0.449032).  Saving model ...
	 Train_Loss: 0.4565 Train_Acc: 80.556 Val_Loss: 0.4490  BEST VAL Loss: 0.4490  Val_Acc: 82.034

Epoch 80: Validation loss decreased (0.449032 --> 0.449028).  Saving model ...
	 Train_Loss: 0.4561 Train_Acc: 80.508 Val_Loss: 0.4490  BEST VAL Loss: 0.4490  Val_Acc: 80.924

Epoch 81: Validation loss decreased (0.449028 --> 0.448788).  Saving model ...
	 Train_Loss: 0.4557 Train_Acc: 80.390 Val_Loss: 0.4488  BEST VAL Loss: 0.4488  Val_Acc: 81.626

Epoch 82: Validation loss decreased (0.448788 --> 0.448556).  Saving model ...
	 Train_Loss: 0.4553 Train_Acc: 80.662 Val_Loss: 0.4486  BEST VAL Loss: 0.4486  Val_Acc: 81.866

Epoch 83: Validation loss decreased (0.448556 --> 0.448391).  Saving model ...
	 Train_Loss: 0.4549 Train_Acc: 80.533 Val_Loss: 0.4484  BEST VAL Loss: 0.4484  Val_Acc: 81.194

Epoch 84: Validation loss decreased (0.448391 --> 0.448152).  Saving model ...
	 Train_Loss: 0.4545 Train_Acc: 80.634 Val_Loss: 0.4482  BEST VAL Loss: 0.4482  Val_Acc: 81.626

Epoch 85: Validation loss decreased (0.448152 --> 0.447822).  Saving model ...
	 Train_Loss: 0.4541 Train_Acc: 80.626 Val_Loss: 0.4478  BEST VAL Loss: 0.4478  Val_Acc: 81.680

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.4540 Train_Acc: 79.885 Val_Loss: 0.4490  BEST VAL Loss: 0.4478  Val_Acc: 78.572

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.4539 Train_Acc: 79.741 Val_Loss: 0.4487  BEST VAL Loss: 0.4478  Val_Acc: 81.776

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.4536 Train_Acc: 80.418 Val_Loss: 0.4484  BEST VAL Loss: 0.4478  Val_Acc: 81.914

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.4533 Train_Acc: 80.507 Val_Loss: 0.4480  BEST VAL Loss: 0.4478  Val_Acc: 81.896

Epoch 90: Validation loss decreased (0.447822 --> 0.447783).  Saving model ...
	 Train_Loss: 0.4530 Train_Acc: 80.668 Val_Loss: 0.4478  BEST VAL Loss: 0.4478  Val_Acc: 81.848

Epoch 91: Validation loss decreased (0.447783 --> 0.447547).  Saving model ...
	 Train_Loss: 0.4527 Train_Acc: 80.591 Val_Loss: 0.4475  BEST VAL Loss: 0.4475  Val_Acc: 81.854

Epoch 92: Validation loss decreased (0.447547 --> 0.447222).  Saving model ...
	 Train_Loss: 0.4523 Train_Acc: 80.579 Val_Loss: 0.4472  BEST VAL Loss: 0.4472  Val_Acc: 81.992

Epoch 93: Validation loss decreased (0.447222 --> 0.446854).  Saving model ...
	 Train_Loss: 0.4519 Train_Acc: 80.863 Val_Loss: 0.4469  BEST VAL Loss: 0.4469  Val_Acc: 82.040

Epoch 94: Validation loss decreased (0.446854 --> 0.446654).  Saving model ...
	 Train_Loss: 0.4515 Train_Acc: 81.015 Val_Loss: 0.4467  BEST VAL Loss: 0.4467  Val_Acc: 81.860

Epoch 95: Validation loss decreased (0.446654 --> 0.446389).  Saving model ...
	 Train_Loss: 0.4511 Train_Acc: 80.930 Val_Loss: 0.4464  BEST VAL Loss: 0.4464  Val_Acc: 82.040

Epoch 96: Validation loss decreased (0.446389 --> 0.446307).  Saving model ...
	 Train_Loss: 0.4507 Train_Acc: 80.758 Val_Loss: 0.4463  BEST VAL Loss: 0.4463  Val_Acc: 81.302

Epoch 97: Validation loss decreased (0.446307 --> 0.446041).  Saving model ...
	 Train_Loss: 0.4504 Train_Acc: 80.614 Val_Loss: 0.4460  BEST VAL Loss: 0.4460  Val_Acc: 81.998

Epoch 98: Validation loss decreased (0.446041 --> 0.445848).  Saving model ...
	 Train_Loss: 0.4500 Train_Acc: 81.028 Val_Loss: 0.4458  BEST VAL Loss: 0.4458  Val_Acc: 81.710

Epoch 99: Validation loss decreased (0.445848 --> 0.445757).  Saving model ...
	 Train_Loss: 0.4497 Train_Acc: 80.772 Val_Loss: 0.4458  BEST VAL Loss: 0.4458  Val_Acc: 81.722

LPS_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.84      0.72      0.78     50422
           1       0.84      0.92      0.88     82898

    accuracy                           0.84    133320
   macro avg       0.84      0.82      0.83    133320
weighted avg       0.84      0.84      0.84    133320

LPS_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.80      0.69      0.74      6303
           1       0.82      0.90      0.86     10362

    accuracy                           0.82     16665
   macro avg       0.81      0.79      0.80     16665
weighted avg       0.82      0.82      0.81     16665

LPS_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.79      0.69      0.74      6303
           1       0.82      0.89      0.86     10362

    accuracy                           0.81     16665
   macro avg       0.81      0.79      0.80     16665
weighted avg       0.81      0.81      0.81     16665

              precision    recall  f1-score   support

           0       0.79      0.69      0.74      6303
           1       0.82      0.89      0.86     10362

    accuracy                           0.81     16665
   macro avg       0.81      0.79      0.80     16665
weighted avg       0.81      0.81      0.81     16665

LPS_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.78      0.54      0.64     32887
           1       0.67      0.86      0.76     35811

    accuracy                           0.71     68698
   macro avg       0.73      0.70      0.70     68698
weighted avg       0.72      0.71      0.70     68698

              precision    recall  f1-score   support

           0       0.78      0.54      0.64     32887
           1       0.67      0.86      0.76     35811

    accuracy                           0.71     68698
   macro avg       0.73      0.70      0.70     68698
weighted avg       0.72      0.71      0.70     68698

completed
