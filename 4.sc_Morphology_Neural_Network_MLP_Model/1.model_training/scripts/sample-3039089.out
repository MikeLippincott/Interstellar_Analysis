[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1cea2ac7'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'ddca8ae2'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '5b8903e0'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '5677bfd7'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Thapsigargin_1.000_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Thapsigargin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'LPS_0.100_DMSO_0.025']
The dimensions of the data are: (31276, 1276)
Number of total missing values across all columns: 62552
Data Subset Is Off
Wells held out for testing: ['D14' 'C20']
Wells to use for training, validation, and testing ['D15' 'C16' 'C17' 'C21' 'K14' 'K15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.564669).  Saving model ...
	 Train_Loss: 0.7505 Train_Acc: 61.263 Val_Loss: 0.5647  BEST VAL Loss: 0.5647  Val_Acc: 71.441

Epoch 1: Validation loss decreased (0.564669 --> 0.553190).  Saving model ...
	 Train_Loss: 0.6504 Train_Acc: 71.746 Val_Loss: 0.5532  BEST VAL Loss: 0.5532  Val_Acc: 71.441

Epoch 2: Validation loss decreased (0.553190 --> 0.536617).  Saving model ...
	 Train_Loss: 0.6036 Train_Acc: 74.424 Val_Loss: 0.5366  BEST VAL Loss: 0.5366  Val_Acc: 76.158

Epoch 3: Validation loss decreased (0.536617 --> 0.523350).  Saving model ...
	 Train_Loss: 0.5742 Train_Acc: 76.272 Val_Loss: 0.5234  BEST VAL Loss: 0.5234  Val_Acc: 77.688

Epoch 4: Validation loss decreased (0.523350 --> 0.513422).  Saving model ...
	 Train_Loss: 0.5525 Train_Acc: 77.728 Val_Loss: 0.5134  BEST VAL Loss: 0.5134  Val_Acc: 79.218

Epoch 5: Validation loss decreased (0.513422 --> 0.503697).  Saving model ...
	 Train_Loss: 0.5350 Train_Acc: 79.285 Val_Loss: 0.5037  BEST VAL Loss: 0.5037  Val_Acc: 80.025

Epoch 6: Validation loss decreased (0.503697 --> 0.493630).  Saving model ...
	 Train_Loss: 0.5197 Train_Acc: 80.549 Val_Loss: 0.4936  BEST VAL Loss: 0.4936  Val_Acc: 80.663

Epoch 7: Validation loss decreased (0.493630 --> 0.484909).  Saving model ...
	 Train_Loss: 0.5070 Train_Acc: 81.155 Val_Loss: 0.4849  BEST VAL Loss: 0.4849  Val_Acc: 81.088

Epoch 8: Validation loss decreased (0.484909 --> 0.476755).  Saving model ...
	 Train_Loss: 0.4960 Train_Acc: 81.782 Val_Loss: 0.4768  BEST VAL Loss: 0.4768  Val_Acc: 83.043

Epoch 9: Validation loss decreased (0.476755 --> 0.469603).  Saving model ...
	 Train_Loss: 0.4858 Train_Acc: 82.866 Val_Loss: 0.4696  BEST VAL Loss: 0.4696  Val_Acc: 82.830

Epoch 10: Validation loss decreased (0.469603 --> 0.464263).  Saving model ...
	 Train_Loss: 0.4766 Train_Acc: 83.201 Val_Loss: 0.4643  BEST VAL Loss: 0.4643  Val_Acc: 82.745

Epoch 11: Validation loss decreased (0.464263 --> 0.457224).  Saving model ...
	 Train_Loss: 0.4682 Train_Acc: 83.982 Val_Loss: 0.4572  BEST VAL Loss: 0.4572  Val_Acc: 84.573

Epoch 12: Validation loss decreased (0.457224 --> 0.451142).  Saving model ...
	 Train_Loss: 0.4608 Train_Acc: 84.029 Val_Loss: 0.4511  BEST VAL Loss: 0.4511  Val_Acc: 84.275

Epoch 13: Validation loss decreased (0.451142 --> 0.447240).  Saving model ...
	 Train_Loss: 0.4540 Train_Acc: 84.582 Val_Loss: 0.4472  BEST VAL Loss: 0.4472  Val_Acc: 84.870

Epoch 14: Validation loss decreased (0.447240 --> 0.442071).  Saving model ...
	 Train_Loss: 0.4476 Train_Acc: 85.033 Val_Loss: 0.4421  BEST VAL Loss: 0.4421  Val_Acc: 85.805

Epoch 15: Validation loss decreased (0.442071 --> 0.438019).  Saving model ...
	 Train_Loss: 0.4418 Train_Acc: 85.352 Val_Loss: 0.4380  BEST VAL Loss: 0.4380  Val_Acc: 85.550

Epoch 16: Validation loss decreased (0.438019 --> 0.435036).  Saving model ...
	 Train_Loss: 0.4362 Train_Acc: 85.602 Val_Loss: 0.4350  BEST VAL Loss: 0.4350  Val_Acc: 83.978

Epoch 17: Validation loss decreased (0.435036 --> 0.430545).  Saving model ...
	 Train_Loss: 0.4312 Train_Acc: 85.623 Val_Loss: 0.4305  BEST VAL Loss: 0.4305  Val_Acc: 85.975

Epoch 18: Validation loss decreased (0.430545 --> 0.426774).  Saving model ...
	 Train_Loss: 0.4263 Train_Acc: 86.224 Val_Loss: 0.4268  BEST VAL Loss: 0.4268  Val_Acc: 85.678

Epoch 19: Validation loss decreased (0.426774 --> 0.423014).  Saving model ...
	 Train_Loss: 0.4218 Train_Acc: 86.277 Val_Loss: 0.4230  BEST VAL Loss: 0.4230  Val_Acc: 85.975

Epoch 20: Validation loss decreased (0.423014 --> 0.421111).  Saving model ...
	 Train_Loss: 0.4174 Train_Acc: 86.553 Val_Loss: 0.4211  BEST VAL Loss: 0.4211  Val_Acc: 86.698

Epoch 21: Validation loss decreased (0.421111 --> 0.418783).  Saving model ...
	 Train_Loss: 0.4137 Train_Acc: 86.218 Val_Loss: 0.4188  BEST VAL Loss: 0.4188  Val_Acc: 86.655

Epoch 22: Validation loss decreased (0.418783 --> 0.416682).  Saving model ...
	 Train_Loss: 0.4103 Train_Acc: 86.378 Val_Loss: 0.4167  BEST VAL Loss: 0.4167  Val_Acc: 85.593

Epoch 23: Validation loss decreased (0.416682 --> 0.414088).  Saving model ...
	 Train_Loss: 0.4070 Train_Acc: 86.686 Val_Loss: 0.4141  BEST VAL Loss: 0.4141  Val_Acc: 86.230

Epoch 24: Validation loss decreased (0.414088 --> 0.412333).  Saving model ...
	 Train_Loss: 0.4039 Train_Acc: 86.622 Val_Loss: 0.4123  BEST VAL Loss: 0.4123  Val_Acc: 86.570

Epoch 25: Validation loss decreased (0.412333 --> 0.410065).  Saving model ...
	 Train_Loss: 0.4005 Train_Acc: 87.408 Val_Loss: 0.4101  BEST VAL Loss: 0.4101  Val_Acc: 86.273

Epoch 26: Validation loss decreased (0.410065 --> 0.407503).  Saving model ...
	 Train_Loss: 0.3973 Train_Acc: 87.504 Val_Loss: 0.4075  BEST VAL Loss: 0.4075  Val_Acc: 87.208

Epoch 27: Validation loss decreased (0.407503 --> 0.405465).  Saving model ...
	 Train_Loss: 0.3943 Train_Acc: 87.461 Val_Loss: 0.4055  BEST VAL Loss: 0.4055  Val_Acc: 87.293

Epoch 28: Validation loss decreased (0.405465 --> 0.403430).  Saving model ...
	 Train_Loss: 0.3916 Train_Acc: 87.244 Val_Loss: 0.4034  BEST VAL Loss: 0.4034  Val_Acc: 87.038

Epoch 29: Validation loss decreased (0.403430 --> 0.401737).  Saving model ...
	 Train_Loss: 0.3888 Train_Acc: 88.035 Val_Loss: 0.4017  BEST VAL Loss: 0.4017  Val_Acc: 87.293

Epoch 30: Validation loss decreased (0.401737 --> 0.399997).  Saving model ...
	 Train_Loss: 0.3862 Train_Acc: 87.977 Val_Loss: 0.4000  BEST VAL Loss: 0.4000  Val_Acc: 86.995

Epoch 31: Validation loss decreased (0.399997 --> 0.398363).  Saving model ...
	 Train_Loss: 0.3837 Train_Acc: 88.009 Val_Loss: 0.3984  BEST VAL Loss: 0.3984  Val_Acc: 86.868

Epoch 32: Validation loss decreased (0.398363 --> 0.396877).  Saving model ...
	 Train_Loss: 0.3812 Train_Acc: 88.423 Val_Loss: 0.3969  BEST VAL Loss: 0.3969  Val_Acc: 87.335

Epoch 33: Validation loss decreased (0.396877 --> 0.394977).  Saving model ...
	 Train_Loss: 0.3790 Train_Acc: 87.897 Val_Loss: 0.3950  BEST VAL Loss: 0.3950  Val_Acc: 87.675

Epoch 34: Validation loss decreased (0.394977 --> 0.393626).  Saving model ...
	 Train_Loss: 0.3766 Train_Acc: 88.694 Val_Loss: 0.3936  BEST VAL Loss: 0.3936  Val_Acc: 87.293

Epoch 35: Validation loss decreased (0.393626 --> 0.392427).  Saving model ...
	 Train_Loss: 0.3743 Train_Acc: 88.636 Val_Loss: 0.3924  BEST VAL Loss: 0.3924  Val_Acc: 86.698

Epoch 36: Validation loss decreased (0.392427 --> 0.391111).  Saving model ...
	 Train_Loss: 0.3722 Train_Acc: 88.354 Val_Loss: 0.3911  BEST VAL Loss: 0.3911  Val_Acc: 87.973

Epoch 37: Validation loss decreased (0.391111 --> 0.389200).  Saving model ...
	 Train_Loss: 0.3703 Train_Acc: 88.620 Val_Loss: 0.3892  BEST VAL Loss: 0.3892  Val_Acc: 88.015

Epoch 38: Validation loss decreased (0.389200 --> 0.387506).  Saving model ...
	 Train_Loss: 0.3681 Train_Acc: 89.008 Val_Loss: 0.3875  BEST VAL Loss: 0.3875  Val_Acc: 87.718

Epoch 39: Validation loss decreased (0.387506 --> 0.386076).  Saving model ...
	 Train_Loss: 0.3662 Train_Acc: 88.811 Val_Loss: 0.3861  BEST VAL Loss: 0.3861  Val_Acc: 88.143

Epoch 40: Validation loss decreased (0.386076 --> 0.384931).  Saving model ...
	 Train_Loss: 0.3642 Train_Acc: 89.002 Val_Loss: 0.3849  BEST VAL Loss: 0.3849  Val_Acc: 87.803

Epoch 41: Validation loss decreased (0.384931 --> 0.384168).  Saving model ...
	 Train_Loss: 0.3624 Train_Acc: 88.938 Val_Loss: 0.3842  BEST VAL Loss: 0.3842  Val_Acc: 87.548

Epoch 42: Validation loss decreased (0.384168 --> 0.383028).  Saving model ...
	 Train_Loss: 0.3605 Train_Acc: 89.289 Val_Loss: 0.3830  BEST VAL Loss: 0.3830  Val_Acc: 87.718

Epoch 43: Validation loss decreased (0.383028 --> 0.381792).  Saving model ...
	 Train_Loss: 0.3587 Train_Acc: 89.353 Val_Loss: 0.3818  BEST VAL Loss: 0.3818  Val_Acc: 87.293

Epoch 44: Validation loss decreased (0.381792 --> 0.381027).  Saving model ...
	 Train_Loss: 0.3571 Train_Acc: 89.236 Val_Loss: 0.3810  BEST VAL Loss: 0.3810  Val_Acc: 87.123

Epoch 45: Validation loss decreased (0.381027 --> 0.380300).  Saving model ...
	 Train_Loss: 0.3553 Train_Acc: 89.491 Val_Loss: 0.3803  BEST VAL Loss: 0.3803  Val_Acc: 88.143

Epoch 46: Validation loss decreased (0.380300 --> 0.379124).  Saving model ...
	 Train_Loss: 0.3537 Train_Acc: 89.555 Val_Loss: 0.3791  BEST VAL Loss: 0.3791  Val_Acc: 88.270

Epoch 47: Validation loss decreased (0.379124 --> 0.378273).  Saving model ...
	 Train_Loss: 0.3520 Train_Acc: 89.613 Val_Loss: 0.3783  BEST VAL Loss: 0.3783  Val_Acc: 87.675

Epoch 48: Validation loss decreased (0.378273 --> 0.377065).  Saving model ...
	 Train_Loss: 0.3506 Train_Acc: 89.305 Val_Loss: 0.3771  BEST VAL Loss: 0.3771  Val_Acc: 88.143

Epoch 49: Validation loss decreased (0.377065 --> 0.376011).  Saving model ...
	 Train_Loss: 0.3491 Train_Acc: 89.762 Val_Loss: 0.3760  BEST VAL Loss: 0.3760  Val_Acc: 87.930

Epoch 50: Validation loss decreased (0.376011 --> 0.374738).  Saving model ...
	 Train_Loss: 0.3478 Train_Acc: 89.225 Val_Loss: 0.3747  BEST VAL Loss: 0.3747  Val_Acc: 88.270

Epoch 51: Validation loss decreased (0.374738 --> 0.373580).  Saving model ...
	 Train_Loss: 0.3464 Train_Acc: 89.719 Val_Loss: 0.3736  BEST VAL Loss: 0.3736  Val_Acc: 88.823

Epoch 52: Validation loss decreased (0.373580 --> 0.372631).  Saving model ...
	 Train_Loss: 0.3450 Train_Acc: 89.900 Val_Loss: 0.3726  BEST VAL Loss: 0.3726  Val_Acc: 87.973

Epoch 53: Validation loss decreased (0.372631 --> 0.371811).  Saving model ...
	 Train_Loss: 0.3437 Train_Acc: 89.321 Val_Loss: 0.3718  BEST VAL Loss: 0.3718  Val_Acc: 88.270

Epoch 54: Validation loss decreased (0.371811 --> 0.371043).  Saving model ...
	 Train_Loss: 0.3425 Train_Acc: 89.672 Val_Loss: 0.3710  BEST VAL Loss: 0.3710  Val_Acc: 88.610

Epoch 55: Validation loss decreased (0.371043 --> 0.370285).  Saving model ...
	 Train_Loss: 0.3413 Train_Acc: 89.406 Val_Loss: 0.3703  BEST VAL Loss: 0.3703  Val_Acc: 88.398

Epoch 56: Validation loss decreased (0.370285 --> 0.369091).  Saving model ...
	 Train_Loss: 0.3402 Train_Acc: 89.560 Val_Loss: 0.3691  BEST VAL Loss: 0.3691  Val_Acc: 88.610

Epoch 57: Validation loss decreased (0.369091 --> 0.368390).  Saving model ...
	 Train_Loss: 0.3390 Train_Acc: 90.214 Val_Loss: 0.3684  BEST VAL Loss: 0.3684  Val_Acc: 88.185

Epoch 58: Validation loss decreased (0.368390 --> 0.367803).  Saving model ...
	 Train_Loss: 0.3377 Train_Acc: 90.182 Val_Loss: 0.3678  BEST VAL Loss: 0.3678  Val_Acc: 88.313

Epoch 59: Validation loss decreased (0.367803 --> 0.367050).  Saving model ...
	 Train_Loss: 0.3365 Train_Acc: 90.129 Val_Loss: 0.3671  BEST VAL Loss: 0.3671  Val_Acc: 88.270

Epoch 60: Validation loss decreased (0.367050 --> 0.366037).  Saving model ...
	 Train_Loss: 0.3353 Train_Acc: 90.421 Val_Loss: 0.3660  BEST VAL Loss: 0.3660  Val_Acc: 88.908

Epoch 61: Validation loss decreased (0.366037 --> 0.364993).  Saving model ...
	 Train_Loss: 0.3341 Train_Acc: 90.214 Val_Loss: 0.3650  BEST VAL Loss: 0.3650  Val_Acc: 88.738

Epoch 62: Validation loss decreased (0.364993 --> 0.364110).  Saving model ...
	 Train_Loss: 0.3330 Train_Acc: 90.421 Val_Loss: 0.3641  BEST VAL Loss: 0.3641  Val_Acc: 89.248

Epoch 63: Validation loss decreased (0.364110 --> 0.363585).  Saving model ...
	 Train_Loss: 0.3319 Train_Acc: 90.224 Val_Loss: 0.3636  BEST VAL Loss: 0.3636  Val_Acc: 88.228

Epoch 64: Validation loss decreased (0.363585 --> 0.363353).  Saving model ...
	 Train_Loss: 0.3308 Train_Acc: 90.442 Val_Loss: 0.3634  BEST VAL Loss: 0.3634  Val_Acc: 88.865

Epoch 65: Validation loss decreased (0.363353 --> 0.362587).  Saving model ...
	 Train_Loss: 0.3298 Train_Acc: 90.261 Val_Loss: 0.3626  BEST VAL Loss: 0.3626  Val_Acc: 88.780

Epoch 66: Validation loss decreased (0.362587 --> 0.362054).  Saving model ...
	 Train_Loss: 0.3288 Train_Acc: 90.346 Val_Loss: 0.3621  BEST VAL Loss: 0.3621  Val_Acc: 88.610

Epoch 67: Validation loss decreased (0.362054 --> 0.361356).  Saving model ...
	 Train_Loss: 0.3277 Train_Acc: 90.973 Val_Loss: 0.3614  BEST VAL Loss: 0.3614  Val_Acc: 88.058

Epoch 68: Validation loss decreased (0.361356 --> 0.360590).  Saving model ...
	 Train_Loss: 0.3267 Train_Acc: 90.272 Val_Loss: 0.3606  BEST VAL Loss: 0.3606  Val_Acc: 88.695

Epoch 69: Validation loss decreased (0.360590 --> 0.359838).  Saving model ...
	 Train_Loss: 0.3258 Train_Acc: 90.570 Val_Loss: 0.3598  BEST VAL Loss: 0.3598  Val_Acc: 88.865

Epoch 70: Validation loss decreased (0.359838 --> 0.359061).  Saving model ...
	 Train_Loss: 0.3249 Train_Acc: 90.267 Val_Loss: 0.3591  BEST VAL Loss: 0.3591  Val_Acc: 88.738

Epoch 71: Validation loss decreased (0.359061 --> 0.358331).  Saving model ...
	 Train_Loss: 0.3239 Train_Acc: 90.777 Val_Loss: 0.3583  BEST VAL Loss: 0.3583  Val_Acc: 89.163

Epoch 72: Validation loss decreased (0.358331 --> 0.357694).  Saving model ...
	 Train_Loss: 0.3230 Train_Acc: 90.644 Val_Loss: 0.3577  BEST VAL Loss: 0.3577  Val_Acc: 88.185

Epoch 73: Validation loss decreased (0.357694 --> 0.357089).  Saving model ...
	 Train_Loss: 0.3222 Train_Acc: 90.261 Val_Loss: 0.3571  BEST VAL Loss: 0.3571  Val_Acc: 89.545

Epoch 74: Validation loss decreased (0.357089 --> 0.356727).  Saving model ...
	 Train_Loss: 0.3213 Train_Acc: 90.660 Val_Loss: 0.3567  BEST VAL Loss: 0.3567  Val_Acc: 89.290

Epoch 75: Validation loss decreased (0.356727 --> 0.356037).  Saving model ...
	 Train_Loss: 0.3206 Train_Acc: 90.357 Val_Loss: 0.3560  BEST VAL Loss: 0.3560  Val_Acc: 88.780

Epoch 76: Validation loss decreased (0.356037 --> 0.355238).  Saving model ...
	 Train_Loss: 0.3198 Train_Acc: 90.182 Val_Loss: 0.3552  BEST VAL Loss: 0.3552  Val_Acc: 88.695

Epoch 77: Validation loss decreased (0.355238 --> 0.354879).  Saving model ...
	 Train_Loss: 0.3191 Train_Acc: 90.596 Val_Loss: 0.3549  BEST VAL Loss: 0.3549  Val_Acc: 88.568

Epoch 78: Validation loss decreased (0.354879 --> 0.354146).  Saving model ...
	 Train_Loss: 0.3182 Train_Acc: 90.920 Val_Loss: 0.3541  BEST VAL Loss: 0.3541  Val_Acc: 88.568

Epoch 79: Validation loss decreased (0.354146 --> 0.353747).  Saving model ...
	 Train_Loss: 0.3175 Train_Acc: 90.516 Val_Loss: 0.3537  BEST VAL Loss: 0.3537  Val_Acc: 88.610

Epoch 80: Validation loss decreased (0.353747 --> 0.353322).  Saving model ...
	 Train_Loss: 0.3168 Train_Acc: 90.516 Val_Loss: 0.3533  BEST VAL Loss: 0.3533  Val_Acc: 88.823

Epoch 81: Validation loss decreased (0.353322 --> 0.353009).  Saving model ...
	 Train_Loss: 0.3160 Train_Acc: 90.697 Val_Loss: 0.3530  BEST VAL Loss: 0.3530  Val_Acc: 88.823

Epoch 82: Validation loss decreased (0.353009 --> 0.352342).  Saving model ...
	 Train_Loss: 0.3152 Train_Acc: 90.957 Val_Loss: 0.3523  BEST VAL Loss: 0.3523  Val_Acc: 89.418

Epoch 83: Validation loss decreased (0.352342 --> 0.351784).  Saving model ...
	 Train_Loss: 0.3144 Train_Acc: 91.048 Val_Loss: 0.3518  BEST VAL Loss: 0.3518  Val_Acc: 88.568

Epoch 84: Validation loss decreased (0.351784 --> 0.351369).  Saving model ...
	 Train_Loss: 0.3136 Train_Acc: 91.111 Val_Loss: 0.3514  BEST VAL Loss: 0.3514  Val_Acc: 88.823

Epoch 85: Validation loss decreased (0.351369 --> 0.350906).  Saving model ...
	 Train_Loss: 0.3129 Train_Acc: 90.564 Val_Loss: 0.3509  BEST VAL Loss: 0.3509  Val_Acc: 89.163

Epoch 86: Validation loss decreased (0.350906 --> 0.350506).  Saving model ...
	 Train_Loss: 0.3122 Train_Acc: 91.143 Val_Loss: 0.3505  BEST VAL Loss: 0.3505  Val_Acc: 88.823

Epoch 87: Validation loss decreased (0.350506 --> 0.350095).  Saving model ...
	 Train_Loss: 0.3115 Train_Acc: 90.915 Val_Loss: 0.3501  BEST VAL Loss: 0.3501  Val_Acc: 88.100

Epoch 88: Validation loss decreased (0.350095 --> 0.349661).  Saving model ...
	 Train_Loss: 0.3108 Train_Acc: 91.011 Val_Loss: 0.3497  BEST VAL Loss: 0.3497  Val_Acc: 88.695

Epoch 89: Validation loss decreased (0.349661 --> 0.349485).  Saving model ...
	 Train_Loss: 0.3101 Train_Acc: 91.234 Val_Loss: 0.3495  BEST VAL Loss: 0.3495  Val_Acc: 89.163

Epoch 90: Validation loss decreased (0.349485 --> 0.348890).  Saving model ...
	 Train_Loss: 0.3094 Train_Acc: 90.793 Val_Loss: 0.3489  BEST VAL Loss: 0.3489  Val_Acc: 88.738

Epoch 91: Validation loss decreased (0.348890 --> 0.348504).  Saving model ...
	 Train_Loss: 0.3088 Train_Acc: 90.984 Val_Loss: 0.3485  BEST VAL Loss: 0.3485  Val_Acc: 89.035

Epoch 92: Validation loss decreased (0.348504 --> 0.347917).  Saving model ...
	 Train_Loss: 0.3081 Train_Acc: 91.080 Val_Loss: 0.3479  BEST VAL Loss: 0.3479  Val_Acc: 89.205

Epoch 93: Validation loss decreased (0.347917 --> 0.347637).  Saving model ...
	 Train_Loss: 0.3074 Train_Acc: 91.106 Val_Loss: 0.3476  BEST VAL Loss: 0.3476  Val_Acc: 89.205

Epoch 94: Validation loss decreased (0.347637 --> 0.347357).  Saving model ...
	 Train_Loss: 0.3067 Train_Acc: 91.510 Val_Loss: 0.3474  BEST VAL Loss: 0.3474  Val_Acc: 89.418

Epoch 95: Validation loss decreased (0.347357 --> 0.347120).  Saving model ...
	 Train_Loss: 0.3060 Train_Acc: 91.616 Val_Loss: 0.3471  BEST VAL Loss: 0.3471  Val_Acc: 88.865

Epoch 96: Validation loss decreased (0.347120 --> 0.346818).  Saving model ...
	 Train_Loss: 0.3054 Train_Acc: 91.404 Val_Loss: 0.3468  BEST VAL Loss: 0.3468  Val_Acc: 89.248

Epoch 97: Validation loss decreased (0.346818 --> 0.346468).  Saving model ...
	 Train_Loss: 0.3047 Train_Acc: 91.175 Val_Loss: 0.3465  BEST VAL Loss: 0.3465  Val_Acc: 88.440

Epoch 98: Validation loss decreased (0.346468 --> 0.346459).  Saving model ...
	 Train_Loss: 0.3040 Train_Acc: 91.754 Val_Loss: 0.3465  BEST VAL Loss: 0.3465  Val_Acc: 88.780

Epoch 99: Validation loss decreased (0.346459 --> 0.345940).  Saving model ...
	 Train_Loss: 0.3034 Train_Acc: 91.196 Val_Loss: 0.3459  BEST VAL Loss: 0.3459  Val_Acc: 89.035

Thapsigargin_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.56      0.53      0.54     10451
           1       0.45      0.47      0.46      8371

    accuracy                           0.50     18822
   macro avg       0.50      0.50      0.50     18822
weighted avg       0.51      0.50      0.51     18822

Thapsigargin_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.56      0.52      0.54      1307
           1       0.45      0.49      0.47      1046

    accuracy                           0.51      2353
   macro avg       0.51      0.51      0.51      2353
weighted avg       0.51      0.51      0.51      2353

Thapsigargin_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.54      0.52      0.53      1307
           1       0.43      0.45      0.44      1046

    accuracy                           0.49      2353
   macro avg       0.49      0.49      0.49      2353
weighted avg       0.49      0.49      0.49      2353

              precision    recall  f1-score   support

           0       0.54      0.52      0.53      1307
           1       0.43      0.45      0.44      1046

    accuracy                           0.49      2353
   macro avg       0.49      0.49      0.49      2353
weighted avg       0.49      0.49      0.49      2353

Thapsigargin_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.58      0.54      0.56      4445
           1       0.43      0.46      0.45      3303

    accuracy                           0.51      7748
   macro avg       0.50      0.50      0.50      7748
weighted avg       0.51      0.51      0.51      7748

              precision    recall  f1-score   support

           0       0.58      0.54      0.56      4445
           1       0.43      0.46      0.45      3303

    accuracy                           0.51      7748
   macro avg       0.50      0.50      0.50      7748
weighted avg       0.51      0.51      0.51      7748

completed
