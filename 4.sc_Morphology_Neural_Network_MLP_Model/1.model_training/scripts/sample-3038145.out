[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '4065c2b2'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'aa0575b6'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '2402a72d'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'bd23b4a3'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Thapsigargin_1.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Thapsigargin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (28168, 1276)
Number of total missing values across all columns: 27532
Data Subset Is Off
Wells held out for testing: ['D14' 'M20']
Wells to use for training, validation, and testing ['D15' 'K14' 'K15' 'M16' 'M17' 'M21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.259653).  Saving model ...
	 Train_Loss: 0.4202 Train_Acc: 84.356 Val_Loss: 0.2597  BEST VAL Loss: 0.2597  Val_Acc: 92.487

Epoch 1: Validation loss decreased (0.259653 --> 0.219746).  Saving model ...
	 Train_Loss: 0.3332 Train_Acc: 92.279 Val_Loss: 0.2197  BEST VAL Loss: 0.2197  Val_Acc: 94.294

Epoch 2: Validation loss decreased (0.219746 --> 0.192965).  Saving model ...
	 Train_Loss: 0.2854 Train_Acc: 93.741 Val_Loss: 0.1930  BEST VAL Loss: 0.1930  Val_Acc: 94.960

Epoch 3: Validation loss decreased (0.192965 --> 0.173462).  Saving model ...
	 Train_Loss: 0.2534 Train_Acc: 94.864 Val_Loss: 0.1735  BEST VAL Loss: 0.1735  Val_Acc: 95.625

Epoch 4: Validation loss decreased (0.173462 --> 0.158695).  Saving model ...
	 Train_Loss: 0.2305 Train_Acc: 95.275 Val_Loss: 0.1587  BEST VAL Loss: 0.1587  Val_Acc: 96.053

Epoch 5: Validation loss decreased (0.158695 --> 0.146905).  Saving model ...
	 Train_Loss: 0.2127 Train_Acc: 95.869 Val_Loss: 0.1469  BEST VAL Loss: 0.1469  Val_Acc: 96.671

Epoch 6: Validation loss decreased (0.146905 --> 0.137095).  Saving model ...
	 Train_Loss: 0.1980 Train_Acc: 96.249 Val_Loss: 0.1371  BEST VAL Loss: 0.1371  Val_Acc: 97.147

Epoch 7: Validation loss decreased (0.137095 --> 0.128920).  Saving model ...
	 Train_Loss: 0.1858 Train_Acc: 96.713 Val_Loss: 0.1289  BEST VAL Loss: 0.1289  Val_Acc: 97.290

Epoch 8: Validation loss decreased (0.128920 --> 0.121993).  Saving model ...
	 Train_Loss: 0.1756 Train_Acc: 96.796 Val_Loss: 0.1220  BEST VAL Loss: 0.1220  Val_Acc: 97.432

Epoch 9: Validation loss decreased (0.121993 --> 0.116033).  Saving model ...
	 Train_Loss: 0.1667 Train_Acc: 97.105 Val_Loss: 0.1160  BEST VAL Loss: 0.1160  Val_Acc: 97.622

Epoch 10: Validation loss decreased (0.116033 --> 0.110834).  Saving model ...
	 Train_Loss: 0.1593 Train_Acc: 96.992 Val_Loss: 0.1108  BEST VAL Loss: 0.1108  Val_Acc: 97.622

Epoch 11: Validation loss decreased (0.110834 --> 0.106238).  Saving model ...
	 Train_Loss: 0.1526 Train_Acc: 97.284 Val_Loss: 0.1062  BEST VAL Loss: 0.1062  Val_Acc: 97.718

Epoch 12: Validation loss decreased (0.106238 --> 0.102141).  Saving model ...
	 Train_Loss: 0.1466 Train_Acc: 97.450 Val_Loss: 0.1021  BEST VAL Loss: 0.1021  Val_Acc: 97.955

Epoch 13: Validation loss decreased (0.102141 --> 0.098493).  Saving model ...
	 Train_Loss: 0.1413 Train_Acc: 97.462 Val_Loss: 0.0985  BEST VAL Loss: 0.0985  Val_Acc: 98.003

Epoch 14: Validation loss decreased (0.098493 --> 0.095190).  Saving model ...
	 Train_Loss: 0.1364 Train_Acc: 97.569 Val_Loss: 0.0952  BEST VAL Loss: 0.0952  Val_Acc: 98.003

Epoch 15: Validation loss decreased (0.095190 --> 0.092212).  Saving model ...
	 Train_Loss: 0.1320 Train_Acc: 97.712 Val_Loss: 0.0922  BEST VAL Loss: 0.0922  Val_Acc: 98.050

Epoch 16: Validation loss decreased (0.092212 --> 0.089494).  Saving model ...
	 Train_Loss: 0.1280 Train_Acc: 97.765 Val_Loss: 0.0895  BEST VAL Loss: 0.0895  Val_Acc: 98.193

Epoch 17: Validation loss decreased (0.089494 --> 0.087011).  Saving model ...
	 Train_Loss: 0.1242 Train_Acc: 98.009 Val_Loss: 0.0870  BEST VAL Loss: 0.0870  Val_Acc: 98.146

Epoch 18: Validation loss decreased (0.087011 --> 0.084738).  Saving model ...
	 Train_Loss: 0.1206 Train_Acc: 98.044 Val_Loss: 0.0847  BEST VAL Loss: 0.0847  Val_Acc: 98.193

Epoch 19: Validation loss decreased (0.084738 --> 0.082640).  Saving model ...
	 Train_Loss: 0.1175 Train_Acc: 97.866 Val_Loss: 0.0826  BEST VAL Loss: 0.0826  Val_Acc: 98.193

Epoch 20: Validation loss decreased (0.082640 --> 0.080679).  Saving model ...
	 Train_Loss: 0.1144 Train_Acc: 98.104 Val_Loss: 0.0807  BEST VAL Loss: 0.0807  Val_Acc: 98.241

Epoch 21: Validation loss decreased (0.080679 --> 0.078874).  Saving model ...
	 Train_Loss: 0.1116 Train_Acc: 98.229 Val_Loss: 0.0789  BEST VAL Loss: 0.0789  Val_Acc: 98.193

Epoch 22: Validation loss decreased (0.078874 --> 0.077194).  Saving model ...
	 Train_Loss: 0.1090 Train_Acc: 98.193 Val_Loss: 0.0772  BEST VAL Loss: 0.0772  Val_Acc: 98.241

Epoch 23: Validation loss decreased (0.077194 --> 0.075623).  Saving model ...
	 Train_Loss: 0.1065 Train_Acc: 98.354 Val_Loss: 0.0756  BEST VAL Loss: 0.0756  Val_Acc: 98.288

Epoch 24: Validation loss decreased (0.075623 --> 0.074154).  Saving model ...
	 Train_Loss: 0.1041 Train_Acc: 98.241 Val_Loss: 0.0742  BEST VAL Loss: 0.0742  Val_Acc: 98.288

Epoch 25: Validation loss decreased (0.074154 --> 0.072779).  Saving model ...
	 Train_Loss: 0.1020 Train_Acc: 98.193 Val_Loss: 0.0728  BEST VAL Loss: 0.0728  Val_Acc: 98.193

Epoch 26: Validation loss decreased (0.072779 --> 0.071511).  Saving model ...
	 Train_Loss: 0.0999 Train_Acc: 98.407 Val_Loss: 0.0715  BEST VAL Loss: 0.0715  Val_Acc: 98.193

Epoch 27: Validation loss decreased (0.071511 --> 0.070315).  Saving model ...
	 Train_Loss: 0.0980 Train_Acc: 98.318 Val_Loss: 0.0703  BEST VAL Loss: 0.0703  Val_Acc: 98.288

Epoch 28: Validation loss decreased (0.070315 --> 0.069199).  Saving model ...
	 Train_Loss: 0.0961 Train_Acc: 98.466 Val_Loss: 0.0692  BEST VAL Loss: 0.0692  Val_Acc: 98.241

Epoch 29: Validation loss decreased (0.069199 --> 0.068119).  Saving model ...
	 Train_Loss: 0.0943 Train_Acc: 98.419 Val_Loss: 0.0681  BEST VAL Loss: 0.0681  Val_Acc: 98.288

Epoch 30: Validation loss decreased (0.068119 --> 0.067109).  Saving model ...
	 Train_Loss: 0.0926 Train_Acc: 98.532 Val_Loss: 0.0671  BEST VAL Loss: 0.0671  Val_Acc: 98.241

Epoch 31: Validation loss decreased (0.067109 --> 0.066152).  Saving model ...
	 Train_Loss: 0.0910 Train_Acc: 98.461 Val_Loss: 0.0662  BEST VAL Loss: 0.0662  Val_Acc: 98.288

Epoch 32: Validation loss decreased (0.066152 --> 0.065249).  Saving model ...
	 Train_Loss: 0.0894 Train_Acc: 98.639 Val_Loss: 0.0652  BEST VAL Loss: 0.0652  Val_Acc: 98.383

Epoch 33: Validation loss decreased (0.065249 --> 0.064373).  Saving model ...
	 Train_Loss: 0.0879 Train_Acc: 98.651 Val_Loss: 0.0644  BEST VAL Loss: 0.0644  Val_Acc: 98.336

Epoch 34: Validation loss decreased (0.064373 --> 0.063529).  Saving model ...
	 Train_Loss: 0.0865 Train_Acc: 98.645 Val_Loss: 0.0635  BEST VAL Loss: 0.0635  Val_Acc: 98.431

Epoch 35: Validation loss decreased (0.063529 --> 0.062751).  Saving model ...
	 Train_Loss: 0.0851 Train_Acc: 98.597 Val_Loss: 0.0628  BEST VAL Loss: 0.0628  Val_Acc: 98.478

Epoch 36: Validation loss decreased (0.062751 --> 0.061993).  Saving model ...
	 Train_Loss: 0.0838 Train_Acc: 98.663 Val_Loss: 0.0620  BEST VAL Loss: 0.0620  Val_Acc: 98.478

Epoch 37: Validation loss decreased (0.061993 --> 0.061290).  Saving model ...
	 Train_Loss: 0.0825 Train_Acc: 98.758 Val_Loss: 0.0613  BEST VAL Loss: 0.0613  Val_Acc: 98.431

Epoch 38: Validation loss decreased (0.061290 --> 0.060610).  Saving model ...
	 Train_Loss: 0.0813 Train_Acc: 98.663 Val_Loss: 0.0606  BEST VAL Loss: 0.0606  Val_Acc: 98.431

Epoch 39: Validation loss decreased (0.060610 --> 0.059955).  Saving model ...
	 Train_Loss: 0.0802 Train_Acc: 98.728 Val_Loss: 0.0600  BEST VAL Loss: 0.0600  Val_Acc: 98.431

Epoch 40: Validation loss decreased (0.059955 --> 0.059320).  Saving model ...
	 Train_Loss: 0.0790 Train_Acc: 98.811 Val_Loss: 0.0593  BEST VAL Loss: 0.0593  Val_Acc: 98.478

Epoch 41: Validation loss decreased (0.059320 --> 0.058712).  Saving model ...
	 Train_Loss: 0.0779 Train_Acc: 98.782 Val_Loss: 0.0587  BEST VAL Loss: 0.0587  Val_Acc: 98.478

Epoch 42: Validation loss decreased (0.058712 --> 0.058131).  Saving model ...
	 Train_Loss: 0.0769 Train_Acc: 98.847 Val_Loss: 0.0581  BEST VAL Loss: 0.0581  Val_Acc: 98.478

Epoch 43: Validation loss decreased (0.058131 --> 0.057579).  Saving model ...
	 Train_Loss: 0.0759 Train_Acc: 98.764 Val_Loss: 0.0576  BEST VAL Loss: 0.0576  Val_Acc: 98.478

Epoch 44: Validation loss decreased (0.057579 --> 0.057040).  Saving model ...
	 Train_Loss: 0.0749 Train_Acc: 98.912 Val_Loss: 0.0570  BEST VAL Loss: 0.0570  Val_Acc: 98.478

Epoch 45: Validation loss decreased (0.057040 --> 0.056528).  Saving model ...
	 Train_Loss: 0.0740 Train_Acc: 98.787 Val_Loss: 0.0565  BEST VAL Loss: 0.0565  Val_Acc: 98.431

Epoch 46: Validation loss decreased (0.056528 --> 0.056039).  Saving model ...
	 Train_Loss: 0.0730 Train_Acc: 98.978 Val_Loss: 0.0560  BEST VAL Loss: 0.0560  Val_Acc: 98.478

Epoch 47: Validation loss decreased (0.056039 --> 0.055571).  Saving model ...
	 Train_Loss: 0.0721 Train_Acc: 98.853 Val_Loss: 0.0556  BEST VAL Loss: 0.0556  Val_Acc: 98.431

Epoch 48: Validation loss decreased (0.055571 --> 0.055119).  Saving model ...
	 Train_Loss: 0.0712 Train_Acc: 98.918 Val_Loss: 0.0551  BEST VAL Loss: 0.0551  Val_Acc: 98.383

Epoch 49: Validation loss decreased (0.055119 --> 0.054683).  Saving model ...
	 Train_Loss: 0.0704 Train_Acc: 98.871 Val_Loss: 0.0547  BEST VAL Loss: 0.0547  Val_Acc: 98.526

Epoch 50: Validation loss decreased (0.054683 --> 0.054265).  Saving model ...
	 Train_Loss: 0.0696 Train_Acc: 98.883 Val_Loss: 0.0543  BEST VAL Loss: 0.0543  Val_Acc: 98.478

Epoch 51: Validation loss decreased (0.054265 --> 0.053859).  Saving model ...
	 Train_Loss: 0.0688 Train_Acc: 98.817 Val_Loss: 0.0539  BEST VAL Loss: 0.0539  Val_Acc: 98.478

Epoch 52: Validation loss decreased (0.053859 --> 0.053478).  Saving model ...
	 Train_Loss: 0.0680 Train_Acc: 98.930 Val_Loss: 0.0535  BEST VAL Loss: 0.0535  Val_Acc: 98.383

Epoch 53: Validation loss decreased (0.053478 --> 0.053093).  Saving model ...
	 Train_Loss: 0.0673 Train_Acc: 98.942 Val_Loss: 0.0531  BEST VAL Loss: 0.0531  Val_Acc: 98.478

Epoch 54: Validation loss decreased (0.053093 --> 0.052721).  Saving model ...
	 Train_Loss: 0.0665 Train_Acc: 98.954 Val_Loss: 0.0527  BEST VAL Loss: 0.0527  Val_Acc: 98.478

Epoch 55: Validation loss decreased (0.052721 --> 0.052361).  Saving model ...
	 Train_Loss: 0.0658 Train_Acc: 99.073 Val_Loss: 0.0524  BEST VAL Loss: 0.0524  Val_Acc: 98.431

Epoch 56: Validation loss decreased (0.052361 --> 0.052019).  Saving model ...
	 Train_Loss: 0.0651 Train_Acc: 98.978 Val_Loss: 0.0520  BEST VAL Loss: 0.0520  Val_Acc: 98.431

Epoch 57: Validation loss decreased (0.052019 --> 0.051681).  Saving model ...
	 Train_Loss: 0.0645 Train_Acc: 99.001 Val_Loss: 0.0517  BEST VAL Loss: 0.0517  Val_Acc: 98.526

Epoch 58: Validation loss decreased (0.051681 --> 0.051363).  Saving model ...
	 Train_Loss: 0.0638 Train_Acc: 99.079 Val_Loss: 0.0514  BEST VAL Loss: 0.0514  Val_Acc: 98.478

Epoch 59: Validation loss decreased (0.051363 --> 0.051045).  Saving model ...
	 Train_Loss: 0.0631 Train_Acc: 99.085 Val_Loss: 0.0510  BEST VAL Loss: 0.0510  Val_Acc: 98.573

Epoch 60: Validation loss decreased (0.051045 --> 0.050741).  Saving model ...
	 Train_Loss: 0.0625 Train_Acc: 99.091 Val_Loss: 0.0507  BEST VAL Loss: 0.0507  Val_Acc: 98.526

Epoch 61: Validation loss decreased (0.050741 --> 0.050443).  Saving model ...
	 Train_Loss: 0.0619 Train_Acc: 99.019 Val_Loss: 0.0504  BEST VAL Loss: 0.0504  Val_Acc: 98.478

Epoch 62: Validation loss decreased (0.050443 --> 0.050156).  Saving model ...
	 Train_Loss: 0.0613 Train_Acc: 99.097 Val_Loss: 0.0502  BEST VAL Loss: 0.0502  Val_Acc: 98.478

Epoch 63: Validation loss decreased (0.050156 --> 0.049887).  Saving model ...
	 Train_Loss: 0.0607 Train_Acc: 99.233 Val_Loss: 0.0499  BEST VAL Loss: 0.0499  Val_Acc: 98.621

Epoch 64: Validation loss decreased (0.049887 --> 0.049623).  Saving model ...
	 Train_Loss: 0.0601 Train_Acc: 99.174 Val_Loss: 0.0496  BEST VAL Loss: 0.0496  Val_Acc: 98.526

Epoch 65: Validation loss decreased (0.049623 --> 0.049371).  Saving model ...
	 Train_Loss: 0.0595 Train_Acc: 99.198 Val_Loss: 0.0494  BEST VAL Loss: 0.0494  Val_Acc: 98.573

Epoch 66: Validation loss decreased (0.049371 --> 0.049129).  Saving model ...
	 Train_Loss: 0.0590 Train_Acc: 99.245 Val_Loss: 0.0491  BEST VAL Loss: 0.0491  Val_Acc: 98.526

Epoch 67: Validation loss decreased (0.049129 --> 0.048886).  Saving model ...
	 Train_Loss: 0.0584 Train_Acc: 99.251 Val_Loss: 0.0489  BEST VAL Loss: 0.0489  Val_Acc: 98.621

Epoch 68: Validation loss decreased (0.048886 --> 0.048649).  Saving model ...
	 Train_Loss: 0.0579 Train_Acc: 99.162 Val_Loss: 0.0486  BEST VAL Loss: 0.0486  Val_Acc: 98.526

Epoch 69: Validation loss decreased (0.048649 --> 0.048422).  Saving model ...
	 Train_Loss: 0.0574 Train_Acc: 99.322 Val_Loss: 0.0484  BEST VAL Loss: 0.0484  Val_Acc: 98.526

Epoch 70: Validation loss decreased (0.048422 --> 0.048198).  Saving model ...
	 Train_Loss: 0.0569 Train_Acc: 99.305 Val_Loss: 0.0482  BEST VAL Loss: 0.0482  Val_Acc: 98.573

Epoch 71: Validation loss decreased (0.048198 --> 0.047980).  Saving model ...
	 Train_Loss: 0.0564 Train_Acc: 99.334 Val_Loss: 0.0480  BEST VAL Loss: 0.0480  Val_Acc: 98.526

Epoch 72: Validation loss decreased (0.047980 --> 0.047769).  Saving model ...
	 Train_Loss: 0.0559 Train_Acc: 99.311 Val_Loss: 0.0478  BEST VAL Loss: 0.0478  Val_Acc: 98.573

Epoch 73: Validation loss decreased (0.047769 --> 0.047564).  Saving model ...
	 Train_Loss: 0.0554 Train_Acc: 99.239 Val_Loss: 0.0476  BEST VAL Loss: 0.0476  Val_Acc: 98.621

Epoch 74: Validation loss decreased (0.047564 --> 0.047360).  Saving model ...
	 Train_Loss: 0.0550 Train_Acc: 99.239 Val_Loss: 0.0474  BEST VAL Loss: 0.0474  Val_Acc: 98.621

Epoch 75: Validation loss decreased (0.047360 --> 0.047166).  Saving model ...
	 Train_Loss: 0.0545 Train_Acc: 99.275 Val_Loss: 0.0472  BEST VAL Loss: 0.0472  Val_Acc: 98.621

Epoch 76: Validation loss decreased (0.047166 --> 0.046977).  Saving model ...
	 Train_Loss: 0.0541 Train_Acc: 99.346 Val_Loss: 0.0470  BEST VAL Loss: 0.0470  Val_Acc: 98.621

Epoch 77: Validation loss decreased (0.046977 --> 0.046787).  Saving model ...
	 Train_Loss: 0.0536 Train_Acc: 99.346 Val_Loss: 0.0468  BEST VAL Loss: 0.0468  Val_Acc: 98.621

Epoch 78: Validation loss decreased (0.046787 --> 0.046605).  Saving model ...
	 Train_Loss: 0.0532 Train_Acc: 99.423 Val_Loss: 0.0466  BEST VAL Loss: 0.0466  Val_Acc: 98.621

Epoch 79: Validation loss decreased (0.046605 --> 0.046431).  Saving model ...
	 Train_Loss: 0.0528 Train_Acc: 99.340 Val_Loss: 0.0464  BEST VAL Loss: 0.0464  Val_Acc: 98.621

Epoch 80: Validation loss decreased (0.046431 --> 0.046267).  Saving model ...
	 Train_Loss: 0.0524 Train_Acc: 99.382 Val_Loss: 0.0463  BEST VAL Loss: 0.0463  Val_Acc: 98.621

Epoch 81: Validation loss decreased (0.046267 --> 0.046101).  Saving model ...
	 Train_Loss: 0.0520 Train_Acc: 99.423 Val_Loss: 0.0461  BEST VAL Loss: 0.0461  Val_Acc: 98.669

Epoch 82: Validation loss decreased (0.046101 --> 0.045940).  Saving model ...
	 Train_Loss: 0.0516 Train_Acc: 99.412 Val_Loss: 0.0459  BEST VAL Loss: 0.0459  Val_Acc: 98.669

Epoch 83: Validation loss decreased (0.045940 --> 0.045781).  Saving model ...
	 Train_Loss: 0.0512 Train_Acc: 99.394 Val_Loss: 0.0458  BEST VAL Loss: 0.0458  Val_Acc: 98.621

Epoch 84: Validation loss decreased (0.045781 --> 0.045632).  Saving model ...
	 Train_Loss: 0.0508 Train_Acc: 99.471 Val_Loss: 0.0456  BEST VAL Loss: 0.0456  Val_Acc: 98.621

Epoch 85: Validation loss decreased (0.045632 --> 0.045489).  Saving model ...
	 Train_Loss: 0.0504 Train_Acc: 99.507 Val_Loss: 0.0455  BEST VAL Loss: 0.0455  Val_Acc: 98.621

Epoch 86: Validation loss decreased (0.045489 --> 0.045346).  Saving model ...
	 Train_Loss: 0.0500 Train_Acc: 99.394 Val_Loss: 0.0453  BEST VAL Loss: 0.0453  Val_Acc: 98.621

Epoch 87: Validation loss decreased (0.045346 --> 0.045206).  Saving model ...
	 Train_Loss: 0.0496 Train_Acc: 99.465 Val_Loss: 0.0452  BEST VAL Loss: 0.0452  Val_Acc: 98.573

Epoch 88: Validation loss decreased (0.045206 --> 0.045069).  Saving model ...
	 Train_Loss: 0.0493 Train_Acc: 99.429 Val_Loss: 0.0451  BEST VAL Loss: 0.0451  Val_Acc: 98.669

Epoch 89: Validation loss decreased (0.045069 --> 0.044935).  Saving model ...
	 Train_Loss: 0.0489 Train_Acc: 99.471 Val_Loss: 0.0449  BEST VAL Loss: 0.0449  Val_Acc: 98.621

Epoch 90: Validation loss decreased (0.044935 --> 0.044805).  Saving model ...
	 Train_Loss: 0.0486 Train_Acc: 99.459 Val_Loss: 0.0448  BEST VAL Loss: 0.0448  Val_Acc: 98.573

Epoch 91: Validation loss decreased (0.044805 --> 0.044679).  Saving model ...
	 Train_Loss: 0.0482 Train_Acc: 99.524 Val_Loss: 0.0447  BEST VAL Loss: 0.0447  Val_Acc: 98.669

Epoch 92: Validation loss decreased (0.044679 --> 0.044556).  Saving model ...
	 Train_Loss: 0.0479 Train_Acc: 99.358 Val_Loss: 0.0446  BEST VAL Loss: 0.0446  Val_Acc: 98.526

Epoch 93: Validation loss decreased (0.044556 --> 0.044437).  Saving model ...
	 Train_Loss: 0.0476 Train_Acc: 99.429 Val_Loss: 0.0444  BEST VAL Loss: 0.0444  Val_Acc: 98.716

Epoch 94: Validation loss decreased (0.044437 --> 0.044320).  Saving model ...
	 Train_Loss: 0.0472 Train_Acc: 99.524 Val_Loss: 0.0443  BEST VAL Loss: 0.0443  Val_Acc: 98.669

Epoch 95: Validation loss decreased (0.044320 --> 0.044203).  Saving model ...
	 Train_Loss: 0.0469 Train_Acc: 99.483 Val_Loss: 0.0442  BEST VAL Loss: 0.0442  Val_Acc: 98.621

Epoch 96: Validation loss decreased (0.044203 --> 0.044092).  Saving model ...
	 Train_Loss: 0.0466 Train_Acc: 99.388 Val_Loss: 0.0441  BEST VAL Loss: 0.0441  Val_Acc: 98.669

Epoch 97: Validation loss decreased (0.044092 --> 0.043982).  Saving model ...
	 Train_Loss: 0.0463 Train_Acc: 99.507 Val_Loss: 0.0440  BEST VAL Loss: 0.0440  Val_Acc: 98.669

Epoch 98: Validation loss decreased (0.043982 --> 0.043874).  Saving model ...
	 Train_Loss: 0.0460 Train_Acc: 99.465 Val_Loss: 0.0439  BEST VAL Loss: 0.0439  Val_Acc: 98.669

Epoch 99: Validation loss decreased (0.043874 --> 0.043767).  Saving model ...
	 Train_Loss: 0.0457 Train_Acc: 99.536 Val_Loss: 0.0438  BEST VAL Loss: 0.0438  Val_Acc: 98.716

Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      8453
           1       1.00      1.00      1.00      8371

    accuracy                           1.00     16824
   macro avg       1.00      1.00      1.00     16824
weighted avg       1.00      1.00      1.00     16824

Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.99      0.99      1057
           1       0.99      0.98      0.99      1046

    accuracy                           0.99      2103
   macro avg       0.99      0.99      0.99      2103
weighted avg       0.99      0.99      0.99      2103

Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.99      0.99      1057
           1       0.99      0.98      0.99      1046

    accuracy                           0.99      2103
   macro avg       0.99      0.99      0.99      2103
weighted avg       0.99      0.99      0.99      2103

              precision    recall  f1-score   support

           0       0.98      0.99      0.99      1057
           1       0.99      0.98      0.99      1046

    accuracy                           0.99      2103
   macro avg       0.99      0.99      0.99      2103
weighted avg       0.99      0.99      0.99      2103

Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      0.99      0.99      3835
           1       0.99      0.98      0.99      3303

    accuracy                           0.99      7138
   macro avg       0.99      0.99      0.99      7138
weighted avg       0.99      0.99      0.99      7138

              precision    recall  f1-score   support

           0       0.99      0.99      0.99      3835
           1       0.99      0.98      0.99      3303

    accuracy                           0.99      7138
   macro avg       0.99      0.99      0.99      7138
weighted avg       0.99      0.99      0.99      7138

completed
