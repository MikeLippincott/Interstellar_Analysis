[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ab1eb0a1'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '32b32f00'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd42962ea'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '7c617404'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_100.000_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (29639, 1276)
Number of total missing values across all columns: 31974
Data Subset Is Off
Wells held out for testing: ['L16' 'J20']
Wells to use for training, validation, and testing ['J16' 'J17' 'L17' 'L20' 'J21' 'L21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.331328).  Saving model ...
	 Train_Loss: 0.5752 Train_Acc: 64.582 Val_Loss: 0.3313  BEST VAL Loss: 0.3313  Val_Acc: 88.515

Epoch 1: Validation loss decreased (0.331328 --> 0.255908).  Saving model ...
	 Train_Loss: 0.4712 Train_Acc: 80.538 Val_Loss: 0.2559  BEST VAL Loss: 0.2559  Val_Acc: 93.405

Epoch 2: Validation loss decreased (0.255908 --> 0.210633).  Saving model ...
	 Train_Loss: 0.4011 Train_Acc: 87.134 Val_Loss: 0.2106  BEST VAL Loss: 0.2106  Val_Acc: 95.514

Epoch 3: Validation loss decreased (0.210633 --> 0.185999).  Saving model ...
	 Train_Loss: 0.3560 Train_Acc: 88.957 Val_Loss: 0.1860  BEST VAL Loss: 0.1860  Val_Acc: 95.917

Epoch 4: Validation loss decreased (0.185999 --> 0.167252).  Saving model ...
	 Train_Loss: 0.3229 Train_Acc: 89.809 Val_Loss: 0.1673  BEST VAL Loss: 0.1673  Val_Acc: 96.501

Epoch 5: Validation loss decreased (0.167252 --> 0.155151).  Saving model ...
	 Train_Loss: 0.2967 Train_Acc: 92.176 Val_Loss: 0.1552  BEST VAL Loss: 0.1552  Val_Acc: 96.546

Epoch 6: Validation loss decreased (0.155151 --> 0.145665).  Saving model ...
	 Train_Loss: 0.2757 Train_Acc: 93.735 Val_Loss: 0.1457  BEST VAL Loss: 0.1457  Val_Acc: 96.725

Epoch 7: Validation loss decreased (0.145665 --> 0.137354).  Saving model ...
	 Train_Loss: 0.2584 Train_Acc: 94.386 Val_Loss: 0.1374  BEST VAL Loss: 0.1374  Val_Acc: 97.622

Epoch 8: Validation loss decreased (0.137354 --> 0.129972).  Saving model ...
	 Train_Loss: 0.2434 Train_Acc: 94.554 Val_Loss: 0.1300  BEST VAL Loss: 0.1300  Val_Acc: 97.757

Epoch 9: Validation loss decreased (0.129972 --> 0.124616).  Saving model ...
	 Train_Loss: 0.2305 Train_Acc: 94.936 Val_Loss: 0.1246  BEST VAL Loss: 0.1246  Val_Acc: 97.757

Epoch 10: Validation loss decreased (0.124616 --> 0.119901).  Saving model ...
	 Train_Loss: 0.2196 Train_Acc: 94.638 Val_Loss: 0.1199  BEST VAL Loss: 0.1199  Val_Acc: 98.026

Epoch 11: Validation loss decreased (0.119901 --> 0.116490).  Saving model ...
	 Train_Loss: 0.2101 Train_Acc: 95.233 Val_Loss: 0.1165  BEST VAL Loss: 0.1165  Val_Acc: 97.891

Epoch 12: Validation loss decreased (0.116490 --> 0.112777).  Saving model ...
	 Train_Loss: 0.2025 Train_Acc: 95.143 Val_Loss: 0.1128  BEST VAL Loss: 0.1128  Val_Acc: 98.205

Epoch 13: Validation loss decreased (0.112777 --> 0.109240).  Saving model ...
	 Train_Loss: 0.1958 Train_Acc: 95.283 Val_Loss: 0.1092  BEST VAL Loss: 0.1092  Val_Acc: 97.712

Epoch 14: Validation loss decreased (0.109240 --> 0.105671).  Saving model ...
	 Train_Loss: 0.1897 Train_Acc: 95.519 Val_Loss: 0.1057  BEST VAL Loss: 0.1057  Val_Acc: 98.385

Epoch 15: Validation loss decreased (0.105671 --> 0.103901).  Saving model ...
	 Train_Loss: 0.1843 Train_Acc: 95.311 Val_Loss: 0.1039  BEST VAL Loss: 0.1039  Val_Acc: 97.936

Epoch 16: Validation loss decreased (0.103901 --> 0.102432).  Saving model ...
	 Train_Loss: 0.1791 Train_Acc: 95.659 Val_Loss: 0.1024  BEST VAL Loss: 0.1024  Val_Acc: 97.802

Epoch 17: Validation loss decreased (0.102432 --> 0.101595).  Saving model ...
	 Train_Loss: 0.1747 Train_Acc: 95.580 Val_Loss: 0.1016  BEST VAL Loss: 0.1016  Val_Acc: 98.205

Epoch 18: Validation loss decreased (0.101595 --> 0.100170).  Saving model ...
	 Train_Loss: 0.1705 Train_Acc: 95.900 Val_Loss: 0.1002  BEST VAL Loss: 0.1002  Val_Acc: 97.981

Epoch 19: Validation loss decreased (0.100170 --> 0.099094).  Saving model ...
	 Train_Loss: 0.1666 Train_Acc: 96.063 Val_Loss: 0.0991  BEST VAL Loss: 0.0991  Val_Acc: 97.936

Epoch 20: Validation loss decreased (0.099094 --> 0.098063).  Saving model ...
	 Train_Loss: 0.1630 Train_Acc: 96.102 Val_Loss: 0.0981  BEST VAL Loss: 0.0981  Val_Acc: 98.071

Epoch 21: Validation loss decreased (0.098063 --> 0.097399).  Saving model ...
	 Train_Loss: 0.1600 Train_Acc: 95.833 Val_Loss: 0.0974  BEST VAL Loss: 0.0974  Val_Acc: 97.802

Epoch 22: Validation loss decreased (0.097399 --> 0.097074).  Saving model ...
	 Train_Loss: 0.1569 Train_Acc: 96.315 Val_Loss: 0.0971  BEST VAL Loss: 0.0971  Val_Acc: 97.847

Epoch 23: Validation loss decreased (0.097074 --> 0.096132).  Saving model ...
	 Train_Loss: 0.1540 Train_Acc: 96.231 Val_Loss: 0.0961  BEST VAL Loss: 0.0961  Val_Acc: 97.847

Epoch 24: Validation loss decreased (0.096132 --> 0.095208).  Saving model ...
	 Train_Loss: 0.1513 Train_Acc: 95.945 Val_Loss: 0.0952  BEST VAL Loss: 0.0952  Val_Acc: 97.936

Epoch 25: Validation loss decreased (0.095208 --> 0.094333).  Saving model ...
	 Train_Loss: 0.1488 Train_Acc: 96.175 Val_Loss: 0.0943  BEST VAL Loss: 0.0943  Val_Acc: 98.116

Epoch 26: Validation loss decreased (0.094333 --> 0.093813).  Saving model ...
	 Train_Loss: 0.1464 Train_Acc: 96.259 Val_Loss: 0.0938  BEST VAL Loss: 0.0938  Val_Acc: 98.295

Epoch 27: Validation loss decreased (0.093813 --> 0.093613).  Saving model ...
	 Train_Loss: 0.1444 Train_Acc: 96.080 Val_Loss: 0.0936  BEST VAL Loss: 0.0936  Val_Acc: 97.891

Epoch 28: Validation loss decreased (0.093613 --> 0.093072).  Saving model ...
	 Train_Loss: 0.1423 Train_Acc: 96.321 Val_Loss: 0.0931  BEST VAL Loss: 0.0931  Val_Acc: 98.475

Epoch 29: Validation loss decreased (0.093072 --> 0.092997).  Saving model ...
	 Train_Loss: 0.1401 Train_Acc: 96.590 Val_Loss: 0.0930  BEST VAL Loss: 0.0930  Val_Acc: 98.205

Epoch 30: Validation loss decreased (0.092997 --> 0.092853).  Saving model ...
	 Train_Loss: 0.1381 Train_Acc: 96.534 Val_Loss: 0.0929  BEST VAL Loss: 0.0929  Val_Acc: 98.205

Epoch 31: Validation loss decreased (0.092853 --> 0.092641).  Saving model ...
	 Train_Loss: 0.1363 Train_Acc: 96.607 Val_Loss: 0.0926  BEST VAL Loss: 0.0926  Val_Acc: 98.161

Epoch 32: Validation loss decreased (0.092641 --> 0.092332).  Saving model ...
	 Train_Loss: 0.1346 Train_Acc: 96.624 Val_Loss: 0.0923  BEST VAL Loss: 0.0923  Val_Acc: 98.430

Epoch 33: Validation loss decreased (0.092332 --> 0.091932).  Saving model ...
	 Train_Loss: 0.1330 Train_Acc: 96.584 Val_Loss: 0.0919  BEST VAL Loss: 0.0919  Val_Acc: 98.340

Epoch 34: Validation loss decreased (0.091932 --> 0.091320).  Saving model ...
	 Train_Loss: 0.1316 Train_Acc: 96.304 Val_Loss: 0.0913  BEST VAL Loss: 0.0913  Val_Acc: 97.891

Epoch 35: Validation loss decreased (0.091320 --> 0.090939).  Saving model ...
	 Train_Loss: 0.1301 Train_Acc: 96.579 Val_Loss: 0.0909  BEST VAL Loss: 0.0909  Val_Acc: 98.340

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.1286 Train_Acc: 96.769 Val_Loss: 0.0910  BEST VAL Loss: 0.0909  Val_Acc: 98.385

Epoch 37: Validation loss decreased (0.090939 --> 0.090693).  Saving model ...
	 Train_Loss: 0.1272 Train_Acc: 96.955 Val_Loss: 0.0907  BEST VAL Loss: 0.0907  Val_Acc: 98.385

Epoch 38: Validation loss decreased (0.090693 --> 0.090333).  Saving model ...
	 Train_Loss: 0.1258 Train_Acc: 96.747 Val_Loss: 0.0903  BEST VAL Loss: 0.0903  Val_Acc: 98.295

Epoch 39: Validation loss decreased (0.090333 --> 0.089910).  Saving model ...
	 Train_Loss: 0.1246 Train_Acc: 96.680 Val_Loss: 0.0899  BEST VAL Loss: 0.0899  Val_Acc: 98.205

Epoch 40: Validation loss decreased (0.089910 --> 0.089461).  Saving model ...
	 Train_Loss: 0.1235 Train_Acc: 96.685 Val_Loss: 0.0895  BEST VAL Loss: 0.0895  Val_Acc: 98.340

Epoch 41: Validation loss decreased (0.089461 --> 0.089117).  Saving model ...
	 Train_Loss: 0.1222 Train_Acc: 97.235 Val_Loss: 0.0891  BEST VAL Loss: 0.0891  Val_Acc: 98.205

Epoch 42: Validation loss decreased (0.089117 --> 0.088730).  Saving model ...
	 Train_Loss: 0.1210 Train_Acc: 96.893 Val_Loss: 0.0887  BEST VAL Loss: 0.0887  Val_Acc: 98.250

Epoch 43: Validation loss decreased (0.088730 --> 0.088562).  Saving model ...
	 Train_Loss: 0.1199 Train_Acc: 96.977 Val_Loss: 0.0886  BEST VAL Loss: 0.0886  Val_Acc: 98.430

Epoch 44: Validation loss decreased (0.088562 --> 0.088053).  Saving model ...
	 Train_Loss: 0.1189 Train_Acc: 96.769 Val_Loss: 0.0881  BEST VAL Loss: 0.0881  Val_Acc: 97.981

Epoch 45: Validation loss decreased (0.088053 --> 0.087665).  Saving model ...
	 Train_Loss: 0.1179 Train_Acc: 96.999 Val_Loss: 0.0877  BEST VAL Loss: 0.0877  Val_Acc: 98.430

Epoch 46: Validation loss decreased (0.087665 --> 0.087216).  Saving model ...
	 Train_Loss: 0.1170 Train_Acc: 96.859 Val_Loss: 0.0872  BEST VAL Loss: 0.0872  Val_Acc: 98.116

Epoch 47: Validation loss decreased (0.087216 --> 0.086881).  Saving model ...
	 Train_Loss: 0.1160 Train_Acc: 96.803 Val_Loss: 0.0869  BEST VAL Loss: 0.0869  Val_Acc: 98.475

Epoch 48: Validation loss decreased (0.086881 --> 0.086678).  Saving model ...
	 Train_Loss: 0.1152 Train_Acc: 96.747 Val_Loss: 0.0867  BEST VAL Loss: 0.0867  Val_Acc: 98.385

Epoch 49: Validation loss decreased (0.086678 --> 0.086445).  Saving model ...
	 Train_Loss: 0.1143 Train_Acc: 97.033 Val_Loss: 0.0864  BEST VAL Loss: 0.0864  Val_Acc: 98.340

Epoch 50: Validation loss decreased (0.086445 --> 0.086100).  Saving model ...
	 Train_Loss: 0.1135 Train_Acc: 96.669 Val_Loss: 0.0861  BEST VAL Loss: 0.0861  Val_Acc: 98.340

Epoch 51: Validation loss decreased (0.086100 --> 0.085827).  Saving model ...
	 Train_Loss: 0.1127 Train_Acc: 96.893 Val_Loss: 0.0858  BEST VAL Loss: 0.0858  Val_Acc: 98.250

Epoch 52: Validation loss decreased (0.085827 --> 0.085684).  Saving model ...
	 Train_Loss: 0.1120 Train_Acc: 96.859 Val_Loss: 0.0857  BEST VAL Loss: 0.0857  Val_Acc: 98.116

Epoch 53: Validation loss decreased (0.085684 --> 0.085407).  Saving model ...
	 Train_Loss: 0.1112 Train_Acc: 96.831 Val_Loss: 0.0854  BEST VAL Loss: 0.0854  Val_Acc: 98.430

Epoch 54: Validation loss decreased (0.085407 --> 0.085232).  Saving model ...
	 Train_Loss: 0.1105 Train_Acc: 96.854 Val_Loss: 0.0852  BEST VAL Loss: 0.0852  Val_Acc: 98.430

Epoch 55: Validation loss decreased (0.085232 --> 0.084939).  Saving model ...
	 Train_Loss: 0.1098 Train_Acc: 96.893 Val_Loss: 0.0849  BEST VAL Loss: 0.0849  Val_Acc: 98.609

Epoch 56: Validation loss decreased (0.084939 --> 0.084658).  Saving model ...
	 Train_Loss: 0.1090 Train_Acc: 97.252 Val_Loss: 0.0847  BEST VAL Loss: 0.0847  Val_Acc: 98.340

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.1082 Train_Acc: 97.684 Val_Loss: 0.0847  BEST VAL Loss: 0.0847  Val_Acc: 98.520

Epoch 58: Validation loss decreased (0.084658 --> 0.084536).  Saving model ...
	 Train_Loss: 0.1075 Train_Acc: 97.510 Val_Loss: 0.0845  BEST VAL Loss: 0.0845  Val_Acc: 98.385

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.1068 Train_Acc: 97.459 Val_Loss: 0.0847  BEST VAL Loss: 0.0845  Val_Acc: 98.520

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.1061 Train_Acc: 97.583 Val_Loss: 0.0850  BEST VAL Loss: 0.0845  Val_Acc: 98.250

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.1054 Train_Acc: 97.330 Val_Loss: 0.0847  BEST VAL Loss: 0.0845  Val_Acc: 98.250

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.1048 Train_Acc: 97.314 Val_Loss: 0.0847  BEST VAL Loss: 0.0845  Val_Acc: 98.340

Epoch 63: Validation loss decreased (0.084536 --> 0.084478).  Saving model ...
	 Train_Loss: 0.1042 Train_Acc: 97.583 Val_Loss: 0.0845  BEST VAL Loss: 0.0845  Val_Acc: 98.385

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.1036 Train_Acc: 97.392 Val_Loss: 0.0846  BEST VAL Loss: 0.0845  Val_Acc: 98.385

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.1030 Train_Acc: 97.487 Val_Loss: 0.0845  BEST VAL Loss: 0.0845  Val_Acc: 98.385

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.1024 Train_Acc: 97.543 Val_Loss: 0.0847  BEST VAL Loss: 0.0845  Val_Acc: 98.475

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.1019 Train_Acc: 97.566 Val_Loss: 0.0845  BEST VAL Loss: 0.0845  Val_Acc: 98.250

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.1014 Train_Acc: 97.257 Val_Loss: 0.0845  BEST VAL Loss: 0.0845  Val_Acc: 98.026

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.1009 Train_Acc: 97.504 Val_Loss: 0.0845  BEST VAL Loss: 0.0845  Val_Acc: 98.475

Epoch 70: Validation loss decreased (0.084478 --> 0.084298).  Saving model ...
	 Train_Loss: 0.1004 Train_Acc: 97.644 Val_Loss: 0.0843  BEST VAL Loss: 0.0843  Val_Acc: 98.430

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.0999 Train_Acc: 97.695 Val_Loss: 0.0843  BEST VAL Loss: 0.0843  Val_Acc: 98.520

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.0994 Train_Acc: 97.504 Val_Loss: 0.0845  BEST VAL Loss: 0.0843  Val_Acc: 98.475

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.0989 Train_Acc: 97.398 Val_Loss: 0.0846  BEST VAL Loss: 0.0843  Val_Acc: 98.205

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.0984 Train_Acc: 97.667 Val_Loss: 0.0848  BEST VAL Loss: 0.0843  Val_Acc: 98.340

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.0980 Train_Acc: 97.510 Val_Loss: 0.0847  BEST VAL Loss: 0.0843  Val_Acc: 98.475

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.0975 Train_Acc: 97.684 Val_Loss: 0.0846  BEST VAL Loss: 0.0843  Val_Acc: 98.475

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.0970 Train_Acc: 97.431 Val_Loss: 0.0845  BEST VAL Loss: 0.0843  Val_Acc: 98.475

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.0965 Train_Acc: 97.527 Val_Loss: 0.0845  BEST VAL Loss: 0.0843  Val_Acc: 98.385

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.0961 Train_Acc: 97.555 Val_Loss: 0.0844  BEST VAL Loss: 0.0843  Val_Acc: 98.609

Epoch 80: Validation loss decreased (0.084298 --> 0.084255).  Saving model ...
	 Train_Loss: 0.0957 Train_Acc: 97.420 Val_Loss: 0.0843  BEST VAL Loss: 0.0843  Val_Acc: 98.430

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.0953 Train_Acc: 97.353 Val_Loss: 0.0844  BEST VAL Loss: 0.0843  Val_Acc: 98.475

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.0948 Train_Acc: 97.684 Val_Loss: 0.0843  BEST VAL Loss: 0.0843  Val_Acc: 98.609

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.0944 Train_Acc: 97.538 Val_Loss: 0.0845  BEST VAL Loss: 0.0843  Val_Acc: 98.564

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.0939 Train_Acc: 97.482 Val_Loss: 0.0844  BEST VAL Loss: 0.0843  Val_Acc: 98.340

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.0936 Train_Acc: 97.588 Val_Loss: 0.0844  BEST VAL Loss: 0.0843  Val_Acc: 98.475

Epoch 86: Validation loss decreased (0.084255 --> 0.084213).  Saving model ...
	 Train_Loss: 0.0932 Train_Acc: 97.465 Val_Loss: 0.0842  BEST VAL Loss: 0.0842  Val_Acc: 98.430

Epoch 87: Validation loss decreased (0.084213 --> 0.084013).  Saving model ...
	 Train_Loss: 0.0928 Train_Acc: 97.566 Val_Loss: 0.0840  BEST VAL Loss: 0.0840  Val_Acc: 98.430

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.0924 Train_Acc: 97.504 Val_Loss: 0.0841  BEST VAL Loss: 0.0840  Val_Acc: 98.430

Epoch 89: Validation loss decreased (0.084013 --> 0.083890).  Saving model ...
	 Train_Loss: 0.0920 Train_Acc: 97.667 Val_Loss: 0.0839  BEST VAL Loss: 0.0839  Val_Acc: 98.520

Epoch 90: Validation loss decreased (0.083890 --> 0.083786).  Saving model ...
	 Train_Loss: 0.0917 Train_Acc: 97.482 Val_Loss: 0.0838  BEST VAL Loss: 0.0838  Val_Acc: 98.385

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.0913 Train_Acc: 97.583 Val_Loss: 0.0839  BEST VAL Loss: 0.0838  Val_Acc: 98.026

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.0910 Train_Acc: 97.656 Val_Loss: 0.0839  BEST VAL Loss: 0.0838  Val_Acc: 98.520

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.0906 Train_Acc: 97.487 Val_Loss: 0.0838  BEST VAL Loss: 0.0838  Val_Acc: 98.475

Epoch 94: Validation loss decreased (0.083786 --> 0.083778).  Saving model ...
	 Train_Loss: 0.0902 Train_Acc: 97.807 Val_Loss: 0.0838  BEST VAL Loss: 0.0838  Val_Acc: 98.295

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.0898 Train_Acc: 97.869 Val_Loss: 0.0839  BEST VAL Loss: 0.0838  Val_Acc: 98.250

Epoch 96: Validation loss did not decrease
	 Train_Loss: 0.0895 Train_Acc: 98.020 Val_Loss: 0.0840  BEST VAL Loss: 0.0838  Val_Acc: 98.385

Epoch 97: Validation loss did not decrease
	 Train_Loss: 0.0891 Train_Acc: 97.902 Val_Loss: 0.0845  BEST VAL Loss: 0.0838  Val_Acc: 98.340

Epoch 98: Validation loss did not decrease
	 Train_Loss: 0.0888 Train_Acc: 97.622 Val_Loss: 0.0844  BEST VAL Loss: 0.0838  Val_Acc: 98.340

Epoch 99: Validation loss did not decrease
	 Train_Loss: 0.0884 Train_Acc: 97.734 Val_Loss: 0.0845  BEST VAL Loss: 0.0838  Val_Acc: 98.520

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      9891
           1       1.00      1.00      1.00      7939

    accuracy                           1.00     17830
   macro avg       1.00      1.00      1.00     17830
weighted avg       1.00      1.00      1.00     17830

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.99      0.98      1237
           1       0.98      0.98      0.98       992

    accuracy                           0.98      2229
   macro avg       0.98      0.98      0.98      2229
weighted avg       0.98      0.98      0.98      2229

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.99      0.98      1237
           1       0.98      0.97      0.98       992

    accuracy                           0.98      2229
   macro avg       0.98      0.98      0.98      2229
weighted avg       0.98      0.98      0.98      2229

              precision    recall  f1-score   support

           0       0.98      0.99      0.98      1237
           1       0.98      0.97      0.98       992

    accuracy                           0.98      2229
   macro avg       0.98      0.98      0.98      2229
weighted avg       0.98      0.98      0.98      2229

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.88      0.96      0.92      3622
           1       0.96      0.87      0.91      3729

    accuracy                           0.92      7351
   macro avg       0.92      0.92      0.92      7351
weighted avg       0.92      0.92      0.92      7351

              precision    recall  f1-score   support

           0       0.88      0.96      0.92      3622
           1       0.96      0.87      0.91      3729

    accuracy                           0.92      7351
   macro avg       0.92      0.92      0.92      7351
weighted avg       0.92      0.92      0.92      7351

completed
