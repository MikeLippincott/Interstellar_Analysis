[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1a09214a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '9bd22fc7'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'f681280f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '4627211a'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: Thapsigargin_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: Thapsigargin_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (27418, 1276)
Number of total missing values across all columns: 27532
Data Subset Is Off
Wells held out for testing: ['D14' 'L20']
Wells to use for training, validation, and testing ['D15' 'K14' 'K15' 'L16' 'L17' 'L21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.264914).  Saving model ...
	 Train_Loss: 0.4233 Train_Acc: 85.600 Val_Loss: 0.2649  BEST VAL Loss: 0.2649  Val_Acc: 92.474

Epoch 1: Validation loss decreased (0.264914 --> 0.220705).  Saving model ...
	 Train_Loss: 0.3402 Train_Acc: 92.806 Val_Loss: 0.2207  BEST VAL Loss: 0.2207  Val_Acc: 93.960

Epoch 2: Validation loss decreased (0.220705 --> 0.200475).  Saving model ...
	 Train_Loss: 0.2944 Train_Acc: 94.017 Val_Loss: 0.2005  BEST VAL Loss: 0.2005  Val_Acc: 94.775

Epoch 3: Validation loss decreased (0.200475 --> 0.183399).  Saving model ...
	 Train_Loss: 0.2639 Train_Acc: 94.713 Val_Loss: 0.1834  BEST VAL Loss: 0.1834  Val_Acc: 95.062

Epoch 4: Validation loss decreased (0.183399 --> 0.173063).  Saving model ...
	 Train_Loss: 0.2412 Train_Acc: 95.270 Val_Loss: 0.1731  BEST VAL Loss: 0.1731  Val_Acc: 95.398

Epoch 5: Validation loss decreased (0.173063 --> 0.163223).  Saving model ...
	 Train_Loss: 0.2236 Train_Acc: 95.636 Val_Loss: 0.1632  BEST VAL Loss: 0.1632  Val_Acc: 95.686

Epoch 6: Validation loss decreased (0.163223 --> 0.154981).  Saving model ...
	 Train_Loss: 0.2093 Train_Acc: 95.965 Val_Loss: 0.1550  BEST VAL Loss: 0.1550  Val_Acc: 96.021

Epoch 7: Validation loss decreased (0.154981 --> 0.146952).  Saving model ...
	 Train_Loss: 0.1975 Train_Acc: 96.307 Val_Loss: 0.1470  BEST VAL Loss: 0.1470  Val_Acc: 96.165

Epoch 8: Validation loss decreased (0.146952 --> 0.140884).  Saving model ...
	 Train_Loss: 0.1878 Train_Acc: 96.499 Val_Loss: 0.1409  BEST VAL Loss: 0.1409  Val_Acc: 96.500

Epoch 9: Validation loss decreased (0.140884 --> 0.136076).  Saving model ...
	 Train_Loss: 0.1791 Train_Acc: 96.811 Val_Loss: 0.1361  BEST VAL Loss: 0.1361  Val_Acc: 96.596

Epoch 10: Validation loss decreased (0.136076 --> 0.131697).  Saving model ...
	 Train_Loss: 0.1715 Train_Acc: 96.847 Val_Loss: 0.1317  BEST VAL Loss: 0.1317  Val_Acc: 96.836

Epoch 11: Validation loss decreased (0.131697 --> 0.127808).  Saving model ...
	 Train_Loss: 0.1648 Train_Acc: 97.039 Val_Loss: 0.1278  BEST VAL Loss: 0.1278  Val_Acc: 97.028

Epoch 12: Validation loss decreased (0.127808 --> 0.125402).  Saving model ...
	 Train_Loss: 0.1587 Train_Acc: 97.116 Val_Loss: 0.1254  BEST VAL Loss: 0.1254  Val_Acc: 97.363

Epoch 13: Validation loss decreased (0.125402 --> 0.124240).  Saving model ...
	 Train_Loss: 0.1534 Train_Acc: 97.218 Val_Loss: 0.1242  BEST VAL Loss: 0.1242  Val_Acc: 97.315

Epoch 14: Validation loss decreased (0.124240 --> 0.120046).  Saving model ...
	 Train_Loss: 0.1484 Train_Acc: 97.506 Val_Loss: 0.1200  BEST VAL Loss: 0.1200  Val_Acc: 97.267

Epoch 15: Validation loss decreased (0.120046 --> 0.116973).  Saving model ...
	 Train_Loss: 0.1439 Train_Acc: 97.548 Val_Loss: 0.1170  BEST VAL Loss: 0.1170  Val_Acc: 97.363

Epoch 16: Validation loss decreased (0.116973 --> 0.115065).  Saving model ...
	 Train_Loss: 0.1397 Train_Acc: 97.788 Val_Loss: 0.1151  BEST VAL Loss: 0.1151  Val_Acc: 97.507

Epoch 17: Validation loss decreased (0.115065 --> 0.113633).  Saving model ...
	 Train_Loss: 0.1358 Train_Acc: 97.890 Val_Loss: 0.1136  BEST VAL Loss: 0.1136  Val_Acc: 97.411

Epoch 18: Validation loss decreased (0.113633 --> 0.112139).  Saving model ...
	 Train_Loss: 0.1322 Train_Acc: 97.770 Val_Loss: 0.1121  BEST VAL Loss: 0.1121  Val_Acc: 97.459

Epoch 19: Validation loss decreased (0.112139 --> 0.109658).  Saving model ...
	 Train_Loss: 0.1289 Train_Acc: 98.064 Val_Loss: 0.1097  BEST VAL Loss: 0.1097  Val_Acc: 97.411

Epoch 20: Validation loss decreased (0.109658 --> 0.107645).  Saving model ...
	 Train_Loss: 0.1258 Train_Acc: 97.908 Val_Loss: 0.1076  BEST VAL Loss: 0.1076  Val_Acc: 97.363

Epoch 21: Validation loss decreased (0.107645 --> 0.105467).  Saving model ...
	 Train_Loss: 0.1229 Train_Acc: 98.052 Val_Loss: 0.1055  BEST VAL Loss: 0.1055  Val_Acc: 97.411

Epoch 22: Validation loss decreased (0.105467 --> 0.103335).  Saving model ...
	 Train_Loss: 0.1201 Train_Acc: 98.100 Val_Loss: 0.1033  BEST VAL Loss: 0.1033  Val_Acc: 97.507

Epoch 23: Validation loss decreased (0.103335 --> 0.101626).  Saving model ...
	 Train_Loss: 0.1175 Train_Acc: 98.196 Val_Loss: 0.1016  BEST VAL Loss: 0.1016  Val_Acc: 97.459

Epoch 24: Validation loss decreased (0.101626 --> 0.099666).  Saving model ...
	 Train_Loss: 0.1150 Train_Acc: 98.238 Val_Loss: 0.0997  BEST VAL Loss: 0.0997  Val_Acc: 97.507

Epoch 25: Validation loss decreased (0.099666 --> 0.098592).  Saving model ...
	 Train_Loss: 0.1128 Train_Acc: 98.196 Val_Loss: 0.0986  BEST VAL Loss: 0.0986  Val_Acc: 97.555

Epoch 26: Validation loss decreased (0.098592 --> 0.097114).  Saving model ...
	 Train_Loss: 0.1106 Train_Acc: 98.291 Val_Loss: 0.0971  BEST VAL Loss: 0.0971  Val_Acc: 97.651

Epoch 27: Validation loss decreased (0.097114 --> 0.096680).  Saving model ...
	 Train_Loss: 0.1085 Train_Acc: 98.297 Val_Loss: 0.0967  BEST VAL Loss: 0.0967  Val_Acc: 97.651

Epoch 28: Validation loss decreased (0.096680 --> 0.095987).  Saving model ...
	 Train_Loss: 0.1066 Train_Acc: 98.285 Val_Loss: 0.0960  BEST VAL Loss: 0.0960  Val_Acc: 97.795

Epoch 29: Validation loss decreased (0.095987 --> 0.095431).  Saving model ...
	 Train_Loss: 0.1047 Train_Acc: 98.489 Val_Loss: 0.0954  BEST VAL Loss: 0.0954  Val_Acc: 97.699

Epoch 30: Validation loss decreased (0.095431 --> 0.093887).  Saving model ...
	 Train_Loss: 0.1028 Train_Acc: 98.609 Val_Loss: 0.0939  BEST VAL Loss: 0.0939  Val_Acc: 97.795

Epoch 31: Validation loss decreased (0.093887 --> 0.093354).  Saving model ...
	 Train_Loss: 0.1011 Train_Acc: 98.525 Val_Loss: 0.0934  BEST VAL Loss: 0.0934  Val_Acc: 97.747

Epoch 32: Validation loss decreased (0.093354 --> 0.091963).  Saving model ...
	 Train_Loss: 0.0994 Train_Acc: 98.471 Val_Loss: 0.0920  BEST VAL Loss: 0.0920  Val_Acc: 97.795

Epoch 33: Validation loss decreased (0.091963 --> 0.091366).  Saving model ...
	 Train_Loss: 0.0978 Train_Acc: 98.651 Val_Loss: 0.0914  BEST VAL Loss: 0.0914  Val_Acc: 97.747

Epoch 34: Validation loss decreased (0.091366 --> 0.090299).  Saving model ...
	 Train_Loss: 0.0963 Train_Acc: 98.705 Val_Loss: 0.0903  BEST VAL Loss: 0.0903  Val_Acc: 97.843

Epoch 35: Validation loss decreased (0.090299 --> 0.089140).  Saving model ...
	 Train_Loss: 0.0948 Train_Acc: 98.561 Val_Loss: 0.0891  BEST VAL Loss: 0.0891  Val_Acc: 97.699

Epoch 36: Validation loss decreased (0.089140 --> 0.088049).  Saving model ...
	 Train_Loss: 0.0934 Train_Acc: 98.687 Val_Loss: 0.0880  BEST VAL Loss: 0.0880  Val_Acc: 97.747

Epoch 37: Validation loss decreased (0.088049 --> 0.087592).  Saving model ...
	 Train_Loss: 0.0920 Train_Acc: 98.693 Val_Loss: 0.0876  BEST VAL Loss: 0.0876  Val_Acc: 97.843

Epoch 38: Validation loss decreased (0.087592 --> 0.086793).  Saving model ...
	 Train_Loss: 0.0907 Train_Acc: 98.735 Val_Loss: 0.0868  BEST VAL Loss: 0.0868  Val_Acc: 97.843

Epoch 39: Validation loss decreased (0.086793 --> 0.085845).  Saving model ...
	 Train_Loss: 0.0894 Train_Acc: 98.747 Val_Loss: 0.0858  BEST VAL Loss: 0.0858  Val_Acc: 97.939

Epoch 40: Validation loss decreased (0.085845 --> 0.085241).  Saving model ...
	 Train_Loss: 0.0882 Train_Acc: 98.783 Val_Loss: 0.0852  BEST VAL Loss: 0.0852  Val_Acc: 98.035

Epoch 41: Validation loss decreased (0.085241 --> 0.084589).  Saving model ...
	 Train_Loss: 0.0870 Train_Acc: 98.861 Val_Loss: 0.0846  BEST VAL Loss: 0.0846  Val_Acc: 97.891

Epoch 42: Validation loss decreased (0.084589 --> 0.083785).  Saving model ...
	 Train_Loss: 0.0859 Train_Acc: 98.897 Val_Loss: 0.0838  BEST VAL Loss: 0.0838  Val_Acc: 97.939

Epoch 43: Validation loss decreased (0.083785 --> 0.083120).  Saving model ...
	 Train_Loss: 0.0848 Train_Acc: 98.939 Val_Loss: 0.0831  BEST VAL Loss: 0.0831  Val_Acc: 97.987

Epoch 44: Validation loss decreased (0.083120 --> 0.082350).  Saving model ...
	 Train_Loss: 0.0837 Train_Acc: 98.891 Val_Loss: 0.0823  BEST VAL Loss: 0.0823  Val_Acc: 98.035

Epoch 45: Validation loss decreased (0.082350 --> 0.081875).  Saving model ...
	 Train_Loss: 0.0826 Train_Acc: 99.065 Val_Loss: 0.0819  BEST VAL Loss: 0.0819  Val_Acc: 97.891

Epoch 46: Validation loss decreased (0.081875 --> 0.081511).  Saving model ...
	 Train_Loss: 0.0816 Train_Acc: 99.041 Val_Loss: 0.0815  BEST VAL Loss: 0.0815  Val_Acc: 98.035

Epoch 47: Validation loss decreased (0.081511 --> 0.080718).  Saving model ...
	 Train_Loss: 0.0806 Train_Acc: 98.933 Val_Loss: 0.0807  BEST VAL Loss: 0.0807  Val_Acc: 97.987

Epoch 48: Validation loss decreased (0.080718 --> 0.080194).  Saving model ...
	 Train_Loss: 0.0797 Train_Acc: 99.011 Val_Loss: 0.0802  BEST VAL Loss: 0.0802  Val_Acc: 97.987

Epoch 49: Validation loss decreased (0.080194 --> 0.079604).  Saving model ...
	 Train_Loss: 0.0788 Train_Acc: 99.053 Val_Loss: 0.0796  BEST VAL Loss: 0.0796  Val_Acc: 97.939

Epoch 50: Validation loss decreased (0.079604 --> 0.079015).  Saving model ...
	 Train_Loss: 0.0779 Train_Acc: 99.005 Val_Loss: 0.0790  BEST VAL Loss: 0.0790  Val_Acc: 97.939

Epoch 51: Validation loss decreased (0.079015 --> 0.078459).  Saving model ...
	 Train_Loss: 0.0770 Train_Acc: 99.017 Val_Loss: 0.0785  BEST VAL Loss: 0.0785  Val_Acc: 97.987

Epoch 52: Validation loss decreased (0.078459 --> 0.078347).  Saving model ...
	 Train_Loss: 0.0761 Train_Acc: 99.149 Val_Loss: 0.0783  BEST VAL Loss: 0.0783  Val_Acc: 98.035

Epoch 53: Validation loss decreased (0.078347 --> 0.077621).  Saving model ...
	 Train_Loss: 0.0753 Train_Acc: 99.017 Val_Loss: 0.0776  BEST VAL Loss: 0.0776  Val_Acc: 98.035

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.0745 Train_Acc: 99.101 Val_Loss: 0.0776  BEST VAL Loss: 0.0776  Val_Acc: 97.939

Epoch 55: Validation loss decreased (0.077621 --> 0.077047).  Saving model ...
	 Train_Loss: 0.0737 Train_Acc: 99.095 Val_Loss: 0.0770  BEST VAL Loss: 0.0770  Val_Acc: 97.987

Epoch 56: Validation loss decreased (0.077047 --> 0.077021).  Saving model ...
	 Train_Loss: 0.0730 Train_Acc: 99.125 Val_Loss: 0.0770  BEST VAL Loss: 0.0770  Val_Acc: 97.987

Epoch 57: Validation loss decreased (0.077021 --> 0.076644).  Saving model ...
	 Train_Loss: 0.0722 Train_Acc: 99.161 Val_Loss: 0.0766  BEST VAL Loss: 0.0766  Val_Acc: 97.987

Epoch 58: Validation loss decreased (0.076644 --> 0.076232).  Saving model ...
	 Train_Loss: 0.0715 Train_Acc: 99.089 Val_Loss: 0.0762  BEST VAL Loss: 0.0762  Val_Acc: 98.035

Epoch 59: Validation loss decreased (0.076232 --> 0.075921).  Saving model ...
	 Train_Loss: 0.0708 Train_Acc: 99.269 Val_Loss: 0.0759  BEST VAL Loss: 0.0759  Val_Acc: 97.987

Epoch 60: Validation loss decreased (0.075921 --> 0.075469).  Saving model ...
	 Train_Loss: 0.0701 Train_Acc: 99.203 Val_Loss: 0.0755  BEST VAL Loss: 0.0755  Val_Acc: 98.035

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.0694 Train_Acc: 99.269 Val_Loss: 0.0755  BEST VAL Loss: 0.0755  Val_Acc: 98.130

Epoch 62: Validation loss decreased (0.075469 --> 0.075157).  Saving model ...
	 Train_Loss: 0.0687 Train_Acc: 99.209 Val_Loss: 0.0752  BEST VAL Loss: 0.0752  Val_Acc: 98.226

Epoch 63: Validation loss decreased (0.075157 --> 0.074918).  Saving model ...
	 Train_Loss: 0.0681 Train_Acc: 99.287 Val_Loss: 0.0749  BEST VAL Loss: 0.0749  Val_Acc: 98.082

Epoch 64: Validation loss decreased (0.074918 --> 0.074672).  Saving model ...
	 Train_Loss: 0.0674 Train_Acc: 99.227 Val_Loss: 0.0747  BEST VAL Loss: 0.0747  Val_Acc: 98.178

Epoch 65: Validation loss decreased (0.074672 --> 0.074182).  Saving model ...
	 Train_Loss: 0.0668 Train_Acc: 99.311 Val_Loss: 0.0742  BEST VAL Loss: 0.0742  Val_Acc: 98.274

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.0662 Train_Acc: 99.365 Val_Loss: 0.0743  BEST VAL Loss: 0.0742  Val_Acc: 98.130

Epoch 67: Validation loss decreased (0.074182 --> 0.074051).  Saving model ...
	 Train_Loss: 0.0656 Train_Acc: 99.377 Val_Loss: 0.0741  BEST VAL Loss: 0.0741  Val_Acc: 98.178

Epoch 68: Validation loss decreased (0.074051 --> 0.073637).  Saving model ...
	 Train_Loss: 0.0650 Train_Acc: 99.383 Val_Loss: 0.0736  BEST VAL Loss: 0.0736  Val_Acc: 98.178

Epoch 69: Validation loss decreased (0.073637 --> 0.073229).  Saving model ...
	 Train_Loss: 0.0645 Train_Acc: 99.299 Val_Loss: 0.0732  BEST VAL Loss: 0.0732  Val_Acc: 98.130

Epoch 70: Validation loss decreased (0.073229 --> 0.072944).  Saving model ...
	 Train_Loss: 0.0639 Train_Acc: 99.383 Val_Loss: 0.0729  BEST VAL Loss: 0.0729  Val_Acc: 98.178

Epoch 71: Validation loss decreased (0.072944 --> 0.072855).  Saving model ...
	 Train_Loss: 0.0633 Train_Acc: 99.377 Val_Loss: 0.0729  BEST VAL Loss: 0.0729  Val_Acc: 98.130

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.0628 Train_Acc: 99.233 Val_Loss: 0.0729  BEST VAL Loss: 0.0729  Val_Acc: 98.130

Epoch 73: Validation loss decreased (0.072855 --> 0.072518).  Saving model ...
	 Train_Loss: 0.0623 Train_Acc: 99.419 Val_Loss: 0.0725  BEST VAL Loss: 0.0725  Val_Acc: 98.178

Epoch 74: Validation loss decreased (0.072518 --> 0.072237).  Saving model ...
	 Train_Loss: 0.0618 Train_Acc: 99.377 Val_Loss: 0.0722  BEST VAL Loss: 0.0722  Val_Acc: 98.082

Epoch 75: Validation loss decreased (0.072237 --> 0.071949).  Saving model ...
	 Train_Loss: 0.0613 Train_Acc: 99.508 Val_Loss: 0.0719  BEST VAL Loss: 0.0719  Val_Acc: 98.082

Epoch 76: Validation loss decreased (0.071949 --> 0.071925).  Saving model ...
	 Train_Loss: 0.0608 Train_Acc: 99.401 Val_Loss: 0.0719  BEST VAL Loss: 0.0719  Val_Acc: 98.178

Epoch 77: Validation loss decreased (0.071925 --> 0.071805).  Saving model ...
	 Train_Loss: 0.0603 Train_Acc: 99.460 Val_Loss: 0.0718  BEST VAL Loss: 0.0718  Val_Acc: 98.130

Epoch 78: Validation loss decreased (0.071805 --> 0.071604).  Saving model ...
	 Train_Loss: 0.0598 Train_Acc: 99.448 Val_Loss: 0.0716  BEST VAL Loss: 0.0716  Val_Acc: 98.226

Epoch 79: Validation loss decreased (0.071604 --> 0.071308).  Saving model ...
	 Train_Loss: 0.0593 Train_Acc: 99.466 Val_Loss: 0.0713  BEST VAL Loss: 0.0713  Val_Acc: 98.178

Epoch 80: Validation loss decreased (0.071308 --> 0.071301).  Saving model ...
	 Train_Loss: 0.0589 Train_Acc: 99.436 Val_Loss: 0.0713  BEST VAL Loss: 0.0713  Val_Acc: 98.130

Epoch 81: Validation loss decreased (0.071301 --> 0.071129).  Saving model ...
	 Train_Loss: 0.0584 Train_Acc: 99.329 Val_Loss: 0.0711  BEST VAL Loss: 0.0711  Val_Acc: 98.226

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.0580 Train_Acc: 99.538 Val_Loss: 0.0712  BEST VAL Loss: 0.0711  Val_Acc: 98.274

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.0575 Train_Acc: 99.395 Val_Loss: 0.0712  BEST VAL Loss: 0.0711  Val_Acc: 98.226

Epoch 84: Validation loss decreased (0.071129 --> 0.070836).  Saving model ...
	 Train_Loss: 0.0571 Train_Acc: 99.466 Val_Loss: 0.0708  BEST VAL Loss: 0.0708  Val_Acc: 98.178

Epoch 85: Validation loss decreased (0.070836 --> 0.070765).  Saving model ...
	 Train_Loss: 0.0567 Train_Acc: 99.466 Val_Loss: 0.0708  BEST VAL Loss: 0.0708  Val_Acc: 98.178

Epoch 86: Validation loss decreased (0.070765 --> 0.070749).  Saving model ...
	 Train_Loss: 0.0563 Train_Acc: 99.562 Val_Loss: 0.0707  BEST VAL Loss: 0.0707  Val_Acc: 98.178

Epoch 87: Validation loss decreased (0.070749 --> 0.070622).  Saving model ...
	 Train_Loss: 0.0559 Train_Acc: 99.472 Val_Loss: 0.0706  BEST VAL Loss: 0.0706  Val_Acc: 98.274

Epoch 88: Validation loss decreased (0.070622 --> 0.070581).  Saving model ...
	 Train_Loss: 0.0555 Train_Acc: 99.424 Val_Loss: 0.0706  BEST VAL Loss: 0.0706  Val_Acc: 98.226

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.0551 Train_Acc: 99.496 Val_Loss: 0.0707  BEST VAL Loss: 0.0706  Val_Acc: 98.178

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.0547 Train_Acc: 99.520 Val_Loss: 0.0706  BEST VAL Loss: 0.0706  Val_Acc: 98.178

Epoch 91: Validation loss decreased (0.070581 --> 0.070282).  Saving model ...
	 Train_Loss: 0.0543 Train_Acc: 99.634 Val_Loss: 0.0703  BEST VAL Loss: 0.0703  Val_Acc: 98.274

Epoch 92: Validation loss decreased (0.070282 --> 0.069937).  Saving model ...
	 Train_Loss: 0.0539 Train_Acc: 99.514 Val_Loss: 0.0699  BEST VAL Loss: 0.0699  Val_Acc: 98.226

Epoch 93: Validation loss decreased (0.069937 --> 0.069755).  Saving model ...
	 Train_Loss: 0.0535 Train_Acc: 99.562 Val_Loss: 0.0698  BEST VAL Loss: 0.0698  Val_Acc: 98.274

Epoch 94: Validation loss decreased (0.069755 --> 0.069428).  Saving model ...
	 Train_Loss: 0.0532 Train_Acc: 99.538 Val_Loss: 0.0694  BEST VAL Loss: 0.0694  Val_Acc: 98.226

Epoch 95: Validation loss decreased (0.069428 --> 0.069265).  Saving model ...
	 Train_Loss: 0.0528 Train_Acc: 99.556 Val_Loss: 0.0693  BEST VAL Loss: 0.0693  Val_Acc: 98.178

Epoch 96: Validation loss decreased (0.069265 --> 0.069093).  Saving model ...
	 Train_Loss: 0.0525 Train_Acc: 99.556 Val_Loss: 0.0691  BEST VAL Loss: 0.0691  Val_Acc: 98.130

Epoch 97: Validation loss decreased (0.069093 --> 0.068856).  Saving model ...
	 Train_Loss: 0.0521 Train_Acc: 99.580 Val_Loss: 0.0689  BEST VAL Loss: 0.0689  Val_Acc: 98.226

Epoch 98: Validation loss decreased (0.068856 --> 0.068597).  Saving model ...
	 Train_Loss: 0.0518 Train_Acc: 99.580 Val_Loss: 0.0686  BEST VAL Loss: 0.0686  Val_Acc: 98.178

Epoch 99: Validation loss decreased (0.068597 --> 0.068314).  Saving model ...
	 Train_Loss: 0.0514 Train_Acc: 99.550 Val_Loss: 0.0683  BEST VAL Loss: 0.0683  Val_Acc: 98.178

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.50      0.50      8312
           1       0.50      0.50      0.50      8369

    accuracy                           0.50     16681
   macro avg       0.50      0.50      0.50     16681
weighted avg       0.50      0.50      0.50     16681

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.50      0.49      1039
           1       0.49      0.49      0.49      1047

    accuracy                           0.49      2086
   macro avg       0.49      0.49      0.49      2086
weighted avg       0.49      0.49      0.49      2086

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.48      0.48      1039
           1       0.48      0.48      0.48      1047

    accuracy                           0.48      2086
   macro avg       0.48      0.48      0.48      2086
weighted avg       0.48      0.48      0.48      2086

              precision    recall  f1-score   support

           0       0.48      0.48      0.48      1039
           1       0.48      0.48      0.48      1047

    accuracy                           0.48      2086
   macro avg       0.48      0.48      0.48      2086
weighted avg       0.48      0.48      0.48      2086

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.50      0.49      3262
           1       0.50      0.49      0.49      3303

    accuracy                           0.49      6565
   macro avg       0.49      0.49      0.49      6565
weighted avg       0.49      0.49      0.49      6565

              precision    recall  f1-score   support

           0       0.49      0.50      0.49      3262
           1       0.50      0.49      0.49      3303

    accuracy                           0.49      6565
   macro avg       0.49      0.49      0.49      6565
weighted avg       0.49      0.49      0.49      6565

completed
