[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '21f86224'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '1ee7ef38'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'e854b974'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '10d25ecc'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: DMSO_0.100_DMSO_0.025 treatment_name: Thapsigargin_10.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: DMSO_0.100_DMSO_0.025
TREATMENT_NAME: Thapsigargin_10.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'Thapsigargin_10.000_DMSO_0.025']
The dimensions of the data are: (382114, 1270)
Number of total missing values across all columns: 764228
Data Subset Is Off
Wells held out for testing: ['J06' 'L06']
Wells to use for training, validation, and testing ['B06' 'C06' 'B07' 'C07' 'E06' 'E07' 'I06' 'I07' 'J07' 'L07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.239269).  Saving model ...
	 Train_Loss: 0.4250 Train_Acc: 80.402 Val_Loss: 0.2393  BEST VAL Loss: 0.2393  Val_Acc: 90.240

Epoch 1: Validation loss decreased (0.239269 --> 0.220132).  Saving model ...
	 Train_Loss: 0.3583 Train_Acc: 87.880 Val_Loss: 0.2201  BEST VAL Loss: 0.2201  Val_Acc: 91.736

Epoch 2: Validation loss decreased (0.220132 --> 0.210304).  Saving model ...
	 Train_Loss: 0.3253 Train_Acc: 89.469 Val_Loss: 0.2103  BEST VAL Loss: 0.2103  Val_Acc: 92.163

Epoch 3: Validation loss decreased (0.210304 --> 0.201113).  Saving model ...
	 Train_Loss: 0.3045 Train_Acc: 90.212 Val_Loss: 0.2011  BEST VAL Loss: 0.2011  Val_Acc: 92.767

Epoch 4: Validation loss decreased (0.201113 --> 0.195695).  Saving model ...
	 Train_Loss: 0.2903 Train_Acc: 90.614 Val_Loss: 0.1957  BEST VAL Loss: 0.1957  Val_Acc: 92.780

Epoch 5: Validation loss decreased (0.195695 --> 0.190423).  Saving model ...
	 Train_Loss: 0.2799 Train_Acc: 90.793 Val_Loss: 0.1904  BEST VAL Loss: 0.1904  Val_Acc: 93.356

Epoch 6: Validation loss decreased (0.190423 --> 0.185977).  Saving model ...
	 Train_Loss: 0.2713 Train_Acc: 91.103 Val_Loss: 0.1860  BEST VAL Loss: 0.1860  Val_Acc: 93.695

Epoch 7: Validation loss decreased (0.185977 --> 0.183312).  Saving model ...
	 Train_Loss: 0.2644 Train_Acc: 91.223 Val_Loss: 0.1833  BEST VAL Loss: 0.1833  Val_Acc: 93.314

Epoch 8: Validation loss decreased (0.183312 --> 0.180361).  Saving model ...
	 Train_Loss: 0.2586 Train_Acc: 91.404 Val_Loss: 0.1804  BEST VAL Loss: 0.1804  Val_Acc: 93.740

Epoch 9: Validation loss decreased (0.180361 --> 0.179210).  Saving model ...
	 Train_Loss: 0.2537 Train_Acc: 91.506 Val_Loss: 0.1792  BEST VAL Loss: 0.1792  Val_Acc: 93.194

Epoch 10: Validation loss decreased (0.179210 --> 0.178026).  Saving model ...
	 Train_Loss: 0.2496 Train_Acc: 91.561 Val_Loss: 0.1780  BEST VAL Loss: 0.1780  Val_Acc: 93.252

Epoch 11: Validation loss decreased (0.178026 --> 0.175654).  Saving model ...
	 Train_Loss: 0.2460 Train_Acc: 91.637 Val_Loss: 0.1757  BEST VAL Loss: 0.1757  Val_Acc: 94.024

Epoch 12: Validation loss decreased (0.175654 --> 0.174016).  Saving model ...
	 Train_Loss: 0.2427 Train_Acc: 91.693 Val_Loss: 0.1740  BEST VAL Loss: 0.1740  Val_Acc: 93.940

Epoch 13: Validation loss decreased (0.174016 --> 0.172631).  Saving model ...
	 Train_Loss: 0.2398 Train_Acc: 91.840 Val_Loss: 0.1726  BEST VAL Loss: 0.1726  Val_Acc: 93.869

Epoch 14: Validation loss decreased (0.172631 --> 0.171397).  Saving model ...
	 Train_Loss: 0.2371 Train_Acc: 91.922 Val_Loss: 0.1714  BEST VAL Loss: 0.1714  Val_Acc: 93.737

Epoch 15: Validation loss decreased (0.171397 --> 0.170203).  Saving model ...
	 Train_Loss: 0.2347 Train_Acc: 91.901 Val_Loss: 0.1702  BEST VAL Loss: 0.1702  Val_Acc: 93.717

Epoch 16: Validation loss decreased (0.170203 --> 0.168962).  Saving model ...
	 Train_Loss: 0.2325 Train_Acc: 91.938 Val_Loss: 0.1690  BEST VAL Loss: 0.1690  Val_Acc: 94.325

Epoch 17: Validation loss decreased (0.168962 --> 0.167877).  Saving model ...
	 Train_Loss: 0.2304 Train_Acc: 91.981 Val_Loss: 0.1679  BEST VAL Loss: 0.1679  Val_Acc: 94.083

Epoch 18: Validation loss decreased (0.167877 --> 0.166529).  Saving model ...
	 Train_Loss: 0.2285 Train_Acc: 92.107 Val_Loss: 0.1665  BEST VAL Loss: 0.1665  Val_Acc: 94.328

Epoch 19: Validation loss decreased (0.166529 --> 0.165325).  Saving model ...
	 Train_Loss: 0.2267 Train_Acc: 92.072 Val_Loss: 0.1653  BEST VAL Loss: 0.1653  Val_Acc: 94.264

Epoch 20: Validation loss decreased (0.165325 --> 0.164481).  Saving model ...
	 Train_Loss: 0.2250 Train_Acc: 92.064 Val_Loss: 0.1645  BEST VAL Loss: 0.1645  Val_Acc: 94.273

Epoch 21: Validation loss decreased (0.164481 --> 0.163746).  Saving model ...
	 Train_Loss: 0.2235 Train_Acc: 92.179 Val_Loss: 0.1637  BEST VAL Loss: 0.1637  Val_Acc: 94.273

Epoch 22: Validation loss decreased (0.163746 --> 0.162706).  Saving model ...
	 Train_Loss: 0.2220 Train_Acc: 92.199 Val_Loss: 0.1627  BEST VAL Loss: 0.1627  Val_Acc: 94.470

Epoch 23: Validation loss decreased (0.162706 --> 0.161804).  Saving model ...
	 Train_Loss: 0.2207 Train_Acc: 92.119 Val_Loss: 0.1618  BEST VAL Loss: 0.1618  Val_Acc: 94.487

Epoch 24: Validation loss decreased (0.161804 --> 0.160891).  Saving model ...
	 Train_Loss: 0.2195 Train_Acc: 92.172 Val_Loss: 0.1609  BEST VAL Loss: 0.1609  Val_Acc: 94.509

Epoch 25: Validation loss decreased (0.160891 --> 0.160053).  Saving model ...
	 Train_Loss: 0.2182 Train_Acc: 92.216 Val_Loss: 0.1601  BEST VAL Loss: 0.1601  Val_Acc: 94.370

Epoch 26: Validation loss decreased (0.160053 --> 0.159513).  Saving model ...
	 Train_Loss: 0.2171 Train_Acc: 92.224 Val_Loss: 0.1595  BEST VAL Loss: 0.1595  Val_Acc: 94.328

Epoch 27: Validation loss decreased (0.159513 --> 0.158825).  Saving model ...
	 Train_Loss: 0.2160 Train_Acc: 92.230 Val_Loss: 0.1588  BEST VAL Loss: 0.1588  Val_Acc: 94.461

Epoch 28: Validation loss decreased (0.158825 --> 0.158511).  Saving model ...
	 Train_Loss: 0.2150 Train_Acc: 92.295 Val_Loss: 0.1585  BEST VAL Loss: 0.1585  Val_Acc: 94.189

Epoch 29: Validation loss decreased (0.158511 --> 0.157893).  Saving model ...
	 Train_Loss: 0.2141 Train_Acc: 92.320 Val_Loss: 0.1579  BEST VAL Loss: 0.1579  Val_Acc: 94.474

Epoch 30: Validation loss decreased (0.157893 --> 0.157353).  Saving model ...
	 Train_Loss: 0.2131 Train_Acc: 92.393 Val_Loss: 0.1574  BEST VAL Loss: 0.1574  Val_Acc: 94.277

Epoch 31: Validation loss decreased (0.157353 --> 0.156946).  Saving model ...
	 Train_Loss: 0.2122 Train_Acc: 92.322 Val_Loss: 0.1569  BEST VAL Loss: 0.1569  Val_Acc: 94.409

Epoch 32: Validation loss decreased (0.156946 --> 0.156573).  Saving model ...
	 Train_Loss: 0.2114 Train_Acc: 92.359 Val_Loss: 0.1566  BEST VAL Loss: 0.1566  Val_Acc: 94.506

Epoch 33: Validation loss decreased (0.156573 --> 0.156141).  Saving model ...
	 Train_Loss: 0.2105 Train_Acc: 92.467 Val_Loss: 0.1561  BEST VAL Loss: 0.1561  Val_Acc: 94.367

Epoch 34: Validation loss decreased (0.156141 --> 0.155616).  Saving model ...
	 Train_Loss: 0.2097 Train_Acc: 92.358 Val_Loss: 0.1556  BEST VAL Loss: 0.1556  Val_Acc: 94.593

Epoch 35: Validation loss decreased (0.155616 --> 0.155204).  Saving model ...
	 Train_Loss: 0.2090 Train_Acc: 92.408 Val_Loss: 0.1552  BEST VAL Loss: 0.1552  Val_Acc: 94.458

Epoch 36: Validation loss decreased (0.155204 --> 0.154843).  Saving model ...
	 Train_Loss: 0.2082 Train_Acc: 92.407 Val_Loss: 0.1548  BEST VAL Loss: 0.1548  Val_Acc: 94.474

Epoch 37: Validation loss decreased (0.154843 --> 0.154413).  Saving model ...
	 Train_Loss: 0.2075 Train_Acc: 92.540 Val_Loss: 0.1544  BEST VAL Loss: 0.1544  Val_Acc: 94.571

Epoch 38: Validation loss decreased (0.154413 --> 0.153996).  Saving model ...
	 Train_Loss: 0.2068 Train_Acc: 92.494 Val_Loss: 0.1540  BEST VAL Loss: 0.1540  Val_Acc: 94.480

Epoch 39: Validation loss decreased (0.153996 --> 0.153709).  Saving model ...
	 Train_Loss: 0.2062 Train_Acc: 92.501 Val_Loss: 0.1537  BEST VAL Loss: 0.1537  Val_Acc: 94.493

Epoch 40: Validation loss decreased (0.153709 --> 0.153257).  Saving model ...
	 Train_Loss: 0.2056 Train_Acc: 92.476 Val_Loss: 0.1533  BEST VAL Loss: 0.1533  Val_Acc: 94.771

Epoch 41: Validation loss decreased (0.153257 --> 0.152871).  Saving model ...
	 Train_Loss: 0.2050 Train_Acc: 92.515 Val_Loss: 0.1529  BEST VAL Loss: 0.1529  Val_Acc: 94.710

Epoch 42: Validation loss decreased (0.152871 --> 0.152461).  Saving model ...
	 Train_Loss: 0.2044 Train_Acc: 92.514 Val_Loss: 0.1525  BEST VAL Loss: 0.1525  Val_Acc: 94.619

Epoch 43: Validation loss decreased (0.152461 --> 0.152111).  Saving model ...
	 Train_Loss: 0.2038 Train_Acc: 92.668 Val_Loss: 0.1521  BEST VAL Loss: 0.1521  Val_Acc: 94.632

Epoch 44: Validation loss decreased (0.152111 --> 0.151763).  Saving model ...
	 Train_Loss: 0.2032 Train_Acc: 92.559 Val_Loss: 0.1518  BEST VAL Loss: 0.1518  Val_Acc: 94.687

Epoch 45: Validation loss decreased (0.151763 --> 0.151358).  Saving model ...
	 Train_Loss: 0.2027 Train_Acc: 92.522 Val_Loss: 0.1514  BEST VAL Loss: 0.1514  Val_Acc: 94.852

Epoch 46: Validation loss decreased (0.151358 --> 0.151151).  Saving model ...
	 Train_Loss: 0.2022 Train_Acc: 92.507 Val_Loss: 0.1512  BEST VAL Loss: 0.1512  Val_Acc: 94.260

Epoch 47: Validation loss decreased (0.151151 --> 0.150809).  Saving model ...
	 Train_Loss: 0.2017 Train_Acc: 92.537 Val_Loss: 0.1508  BEST VAL Loss: 0.1508  Val_Acc: 94.774

Epoch 48: Validation loss decreased (0.150809 --> 0.150399).  Saving model ...
	 Train_Loss: 0.2012 Train_Acc: 92.510 Val_Loss: 0.1504  BEST VAL Loss: 0.1504  Val_Acc: 94.836

Epoch 49: Validation loss decreased (0.150399 --> 0.149979).  Saving model ...
	 Train_Loss: 0.2008 Train_Acc: 92.514 Val_Loss: 0.1500  BEST VAL Loss: 0.1500  Val_Acc: 94.920

Epoch 50: Validation loss decreased (0.149979 --> 0.149624).  Saving model ...
	 Train_Loss: 0.2003 Train_Acc: 92.601 Val_Loss: 0.1496  BEST VAL Loss: 0.1496  Val_Acc: 94.823

Epoch 51: Validation loss decreased (0.149624 --> 0.149494).  Saving model ...
	 Train_Loss: 0.1999 Train_Acc: 92.548 Val_Loss: 0.1495  BEST VAL Loss: 0.1495  Val_Acc: 94.477

Epoch 52: Validation loss decreased (0.149494 --> 0.149212).  Saving model ...
	 Train_Loss: 0.1994 Train_Acc: 92.720 Val_Loss: 0.1492  BEST VAL Loss: 0.1492  Val_Acc: 94.739

Epoch 53: Validation loss decreased (0.149212 --> 0.149086).  Saving model ...
	 Train_Loss: 0.1990 Train_Acc: 92.570 Val_Loss: 0.1491  BEST VAL Loss: 0.1491  Val_Acc: 94.587

Epoch 54: Validation loss decreased (0.149086 --> 0.148767).  Saving model ...
	 Train_Loss: 0.1986 Train_Acc: 92.558 Val_Loss: 0.1488  BEST VAL Loss: 0.1488  Val_Acc: 94.836

Epoch 55: Validation loss decreased (0.148767 --> 0.148572).  Saving model ...
	 Train_Loss: 0.1982 Train_Acc: 92.634 Val_Loss: 0.1486  BEST VAL Loss: 0.1486  Val_Acc: 94.483

Epoch 56: Validation loss decreased (0.148572 --> 0.148279).  Saving model ...
	 Train_Loss: 0.1978 Train_Acc: 92.641 Val_Loss: 0.1483  BEST VAL Loss: 0.1483  Val_Acc: 94.923

Epoch 57: Validation loss decreased (0.148279 --> 0.147960).  Saving model ...
	 Train_Loss: 0.1974 Train_Acc: 92.673 Val_Loss: 0.1480  BEST VAL Loss: 0.1480  Val_Acc: 94.946

Epoch 58: Validation loss decreased (0.147960 --> 0.147768).  Saving model ...
	 Train_Loss: 0.1970 Train_Acc: 92.640 Val_Loss: 0.1478  BEST VAL Loss: 0.1478  Val_Acc: 94.710

Epoch 59: Validation loss decreased (0.147768 --> 0.147509).  Saving model ...
	 Train_Loss: 0.1967 Train_Acc: 92.705 Val_Loss: 0.1475  BEST VAL Loss: 0.1475  Val_Acc: 94.926

Epoch 60: Validation loss decreased (0.147509 --> 0.147382).  Saving model ...
	 Train_Loss: 0.1963 Train_Acc: 92.554 Val_Loss: 0.1474  BEST VAL Loss: 0.1474  Val_Acc: 94.548

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.1960 Train_Acc: 92.639 Val_Loss: 0.1474  BEST VAL Loss: 0.1474  Val_Acc: 93.931

Epoch 62: Validation loss decreased (0.147382 --> 0.147187).  Saving model ...
	 Train_Loss: 0.1957 Train_Acc: 92.692 Val_Loss: 0.1472  BEST VAL Loss: 0.1472  Val_Acc: 94.839

Epoch 63: Validation loss decreased (0.147187 --> 0.147017).  Saving model ...
	 Train_Loss: 0.1953 Train_Acc: 92.667 Val_Loss: 0.1470  BEST VAL Loss: 0.1470  Val_Acc: 94.787

Epoch 64: Validation loss decreased (0.147017 --> 0.146828).  Saving model ...
	 Train_Loss: 0.1950 Train_Acc: 92.646 Val_Loss: 0.1468  BEST VAL Loss: 0.1468  Val_Acc: 94.784

Epoch 65: Validation loss decreased (0.146828 --> 0.146740).  Saving model ...
	 Train_Loss: 0.1947 Train_Acc: 92.691 Val_Loss: 0.1467  BEST VAL Loss: 0.1467  Val_Acc: 94.613

Epoch 66: Validation loss decreased (0.146740 --> 0.146472).  Saving model ...
	 Train_Loss: 0.1944 Train_Acc: 92.826 Val_Loss: 0.1465  BEST VAL Loss: 0.1465  Val_Acc: 95.078

Epoch 67: Validation loss decreased (0.146472 --> 0.146236).  Saving model ...
	 Train_Loss: 0.1941 Train_Acc: 92.655 Val_Loss: 0.1462  BEST VAL Loss: 0.1462  Val_Acc: 94.926

Epoch 68: Validation loss decreased (0.146236 --> 0.146022).  Saving model ...
	 Train_Loss: 0.1938 Train_Acc: 92.633 Val_Loss: 0.1460  BEST VAL Loss: 0.1460  Val_Acc: 94.742

Epoch 69: Validation loss decreased (0.146022 --> 0.145798).  Saving model ...
	 Train_Loss: 0.1935 Train_Acc: 92.821 Val_Loss: 0.1458  BEST VAL Loss: 0.1458  Val_Acc: 94.836

Epoch 70: Validation loss decreased (0.145798 --> 0.145603).  Saving model ...
	 Train_Loss: 0.1932 Train_Acc: 92.708 Val_Loss: 0.1456  BEST VAL Loss: 0.1456  Val_Acc: 94.862

Epoch 71: Validation loss decreased (0.145603 --> 0.145455).  Saving model ...
	 Train_Loss: 0.1930 Train_Acc: 92.600 Val_Loss: 0.1455  BEST VAL Loss: 0.1455  Val_Acc: 94.729

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.1927 Train_Acc: 92.711 Val_Loss: 0.1456  BEST VAL Loss: 0.1455  Val_Acc: 93.973

Epoch 73: Validation loss decreased (0.145455 --> 0.145357).  Saving model ...
	 Train_Loss: 0.1924 Train_Acc: 92.735 Val_Loss: 0.1454  BEST VAL Loss: 0.1454  Val_Acc: 94.816

Epoch 74: Validation loss decreased (0.145357 --> 0.145255).  Saving model ...
	 Train_Loss: 0.1922 Train_Acc: 92.762 Val_Loss: 0.1453  BEST VAL Loss: 0.1453  Val_Acc: 94.561

Epoch 75: Validation loss decreased (0.145255 --> 0.145142).  Saving model ...
	 Train_Loss: 0.1919 Train_Acc: 92.707 Val_Loss: 0.1451  BEST VAL Loss: 0.1451  Val_Acc: 94.771

Epoch 76: Validation loss decreased (0.145142 --> 0.144942).  Saving model ...
	 Train_Loss: 0.1917 Train_Acc: 92.755 Val_Loss: 0.1449  BEST VAL Loss: 0.1449  Val_Acc: 94.978

Epoch 77: Validation loss decreased (0.144942 --> 0.144800).  Saving model ...
	 Train_Loss: 0.1914 Train_Acc: 92.695 Val_Loss: 0.1448  BEST VAL Loss: 0.1448  Val_Acc: 94.748

Epoch 78: Validation loss decreased (0.144800 --> 0.144594).  Saving model ...
	 Train_Loss: 0.1912 Train_Acc: 92.762 Val_Loss: 0.1446  BEST VAL Loss: 0.1446  Val_Acc: 94.807

Epoch 79: Validation loss decreased (0.144594 --> 0.144404).  Saving model ...
	 Train_Loss: 0.1909 Train_Acc: 92.870 Val_Loss: 0.1444  BEST VAL Loss: 0.1444  Val_Acc: 94.949

Epoch 80: Validation loss decreased (0.144404 --> 0.144229).  Saving model ...
	 Train_Loss: 0.1907 Train_Acc: 92.775 Val_Loss: 0.1442  BEST VAL Loss: 0.1442  Val_Acc: 94.887

Epoch 81: Validation loss decreased (0.144229 --> 0.144067).  Saving model ...
	 Train_Loss: 0.1905 Train_Acc: 92.823 Val_Loss: 0.1441  BEST VAL Loss: 0.1441  Val_Acc: 94.949

Epoch 82: Validation loss decreased (0.144067 --> 0.143897).  Saving model ...
	 Train_Loss: 0.1902 Train_Acc: 92.752 Val_Loss: 0.1439  BEST VAL Loss: 0.1439  Val_Acc: 95.000

Epoch 83: Validation loss decreased (0.143897 --> 0.143753).  Saving model ...
	 Train_Loss: 0.1900 Train_Acc: 92.884 Val_Loss: 0.1438  BEST VAL Loss: 0.1438  Val_Acc: 94.858

Epoch 84: Validation loss decreased (0.143753 --> 0.143680).  Saving model ...
	 Train_Loss: 0.1898 Train_Acc: 92.797 Val_Loss: 0.1437  BEST VAL Loss: 0.1437  Val_Acc: 94.500

Epoch 85: Validation loss decreased (0.143680 --> 0.143587).  Saving model ...
	 Train_Loss: 0.1896 Train_Acc: 92.839 Val_Loss: 0.1436  BEST VAL Loss: 0.1436  Val_Acc: 94.748

Epoch 86: Validation loss decreased (0.143587 --> 0.143385).  Saving model ...
	 Train_Loss: 0.1893 Train_Acc: 92.857 Val_Loss: 0.1434  BEST VAL Loss: 0.1434  Val_Acc: 95.010

Epoch 87: Validation loss decreased (0.143385 --> 0.143205).  Saving model ...
	 Train_Loss: 0.1891 Train_Acc: 92.862 Val_Loss: 0.1432  BEST VAL Loss: 0.1432  Val_Acc: 95.075

Epoch 88: Validation loss decreased (0.143205 --> 0.142990).  Saving model ...
	 Train_Loss: 0.1889 Train_Acc: 92.854 Val_Loss: 0.1430  BEST VAL Loss: 0.1430  Val_Acc: 95.130

Epoch 89: Validation loss decreased (0.142990 --> 0.142910).  Saving model ...
	 Train_Loss: 0.1887 Train_Acc: 92.789 Val_Loss: 0.1429  BEST VAL Loss: 0.1429  Val_Acc: 94.765

Epoch 90: Validation loss decreased (0.142910 --> 0.142768).  Saving model ...
	 Train_Loss: 0.1885 Train_Acc: 92.835 Val_Loss: 0.1428  BEST VAL Loss: 0.1428  Val_Acc: 94.781

Epoch 91: Validation loss decreased (0.142768 --> 0.142618).  Saving model ...
	 Train_Loss: 0.1883 Train_Acc: 92.854 Val_Loss: 0.1426  BEST VAL Loss: 0.1426  Val_Acc: 94.978

Epoch 92: Validation loss decreased (0.142618 --> 0.142530).  Saving model ...
	 Train_Loss: 0.1881 Train_Acc: 92.872 Val_Loss: 0.1425  BEST VAL Loss: 0.1425  Val_Acc: 94.758

Epoch 93: Validation loss decreased (0.142530 --> 0.142419).  Saving model ...
	 Train_Loss: 0.1880 Train_Acc: 92.793 Val_Loss: 0.1424  BEST VAL Loss: 0.1424  Val_Acc: 94.845

Epoch 94: Validation loss decreased (0.142419 --> 0.142262).  Saving model ...
	 Train_Loss: 0.1878 Train_Acc: 92.765 Val_Loss: 0.1423  BEST VAL Loss: 0.1423  Val_Acc: 94.984

Epoch 95: Validation loss decreased (0.142262 --> 0.142173).  Saving model ...
	 Train_Loss: 0.1876 Train_Acc: 92.899 Val_Loss: 0.1422  BEST VAL Loss: 0.1422  Val_Acc: 94.635

Epoch 96: Validation loss decreased (0.142173 --> 0.142092).  Saving model ...
	 Train_Loss: 0.1874 Train_Acc: 92.824 Val_Loss: 0.1421  BEST VAL Loss: 0.1421  Val_Acc: 94.790

Epoch 97: Validation loss decreased (0.142092 --> 0.142014).  Saving model ...
	 Train_Loss: 0.1873 Train_Acc: 92.884 Val_Loss: 0.1420  BEST VAL Loss: 0.1420  Val_Acc: 94.913

Epoch 98: Validation loss decreased (0.142014 --> 0.141863).  Saving model ...
	 Train_Loss: 0.1871 Train_Acc: 92.932 Val_Loss: 0.1419  BEST VAL Loss: 0.1419  Val_Acc: 95.097

Epoch 99: Validation loss decreased (0.141863 --> 0.141760).  Saving model ...
	 Train_Loss: 0.1869 Train_Acc: 92.846 Val_Loss: 0.1418  BEST VAL Loss: 0.1418  Val_Acc: 94.881

DMSO_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.60      0.62      0.61    149884
           1       0.39      0.38      0.39     97655

    accuracy                           0.52    247539
   macro avg       0.50      0.50      0.50    247539
weighted avg       0.52      0.52      0.52    247539

DMSO_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.60      0.61      0.61     18736
           1       0.39      0.38      0.38     12207

    accuracy                           0.52     30943
   macro avg       0.50      0.50      0.50     30943
weighted avg       0.52      0.52      0.52     30943

DMSO_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.60      0.62      0.61     18736
           1       0.39      0.38      0.39     12207

    accuracy                           0.52     30943
   macro avg       0.50      0.50      0.50     30943
weighted avg       0.52      0.52      0.52     30943

              precision    recall  f1-score   support

           0       0.60      0.62      0.61     18736
           1       0.39      0.38      0.39     12207

    accuracy                           0.52     30943
   macro avg       0.50      0.50      0.50     30943
weighted avg       0.52      0.52      0.52     30943

DMSO_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.38      0.44      0.41     27774
           1       0.62      0.56      0.59     44915

    accuracy                           0.51     72689
   macro avg       0.50      0.50      0.50     72689
weighted avg       0.53      0.51      0.52     72689

              precision    recall  f1-score   support

           0       0.38      0.44      0.41     27774
           1       0.62      0.56      0.59     44915

    accuracy                           0.51     72689
   macro avg       0.50      0.50      0.50     72689
weighted avg       0.53      0.51      0.52     72689

completed
