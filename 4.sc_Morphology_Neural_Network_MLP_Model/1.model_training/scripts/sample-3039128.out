[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '754eb13f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '86f6a92d'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'c2feb000'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'bd63eef2'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_100.000_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_100.000_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (302515, 1270)
Number of total missing values across all columns: 605030
Data Subset Is Off
Wells held out for testing: ['B08' 'J08']
Wells to use for training, validation, and testing ['B02' 'B03' 'B09' 'J02' 'J03' 'J09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.668595).  Saving model ...
	 Train_Loss: 0.6801 Train_Acc: 56.500 Val_Loss: 0.6686  BEST VAL Loss: 0.6686  Val_Acc: 58.937

Epoch 1: Validation loss decreased (0.668595 --> 0.661974).  Saving model ...
	 Train_Loss: 0.6718 Train_Acc: 59.458 Val_Loss: 0.6620  BEST VAL Loss: 0.6620  Val_Acc: 61.244

Epoch 2: Validation loss decreased (0.661974 --> 0.655896).  Saving model ...
	 Train_Loss: 0.6653 Train_Acc: 61.192 Val_Loss: 0.6559  BEST VAL Loss: 0.6559  Val_Acc: 62.745

Epoch 3: Validation loss decreased (0.655896 --> 0.650755).  Saving model ...
	 Train_Loss: 0.6598 Train_Acc: 62.421 Val_Loss: 0.6508  BEST VAL Loss: 0.6508  Val_Acc: 64.124

Epoch 4: Validation loss decreased (0.650755 --> 0.646418).  Saving model ...
	 Train_Loss: 0.6551 Train_Acc: 63.286 Val_Loss: 0.6464  BEST VAL Loss: 0.6464  Val_Acc: 64.544

Epoch 5: Validation loss decreased (0.646418 --> 0.643020).  Saving model ...
	 Train_Loss: 0.6511 Train_Acc: 63.911 Val_Loss: 0.6430  BEST VAL Loss: 0.6430  Val_Acc: 64.894

Epoch 6: Validation loss decreased (0.643020 --> 0.639667).  Saving model ...
	 Train_Loss: 0.6476 Train_Acc: 64.363 Val_Loss: 0.6397  BEST VAL Loss: 0.6397  Val_Acc: 65.638

Epoch 7: Validation loss decreased (0.639667 --> 0.636779).  Saving model ...
	 Train_Loss: 0.6446 Train_Acc: 64.566 Val_Loss: 0.6368  BEST VAL Loss: 0.6368  Val_Acc: 66.194

Epoch 8: Validation loss decreased (0.636779 --> 0.634349).  Saving model ...
	 Train_Loss: 0.6420 Train_Acc: 64.758 Val_Loss: 0.6343  BEST VAL Loss: 0.6343  Val_Acc: 66.391

Epoch 9: Validation loss decreased (0.634349 --> 0.632176).  Saving model ...
	 Train_Loss: 0.6397 Train_Acc: 64.949 Val_Loss: 0.6322  BEST VAL Loss: 0.6322  Val_Acc: 66.430

Epoch 10: Validation loss decreased (0.632176 --> 0.630308).  Saving model ...
	 Train_Loss: 0.6376 Train_Acc: 65.223 Val_Loss: 0.6303  BEST VAL Loss: 0.6303  Val_Acc: 66.785

Epoch 11: Validation loss decreased (0.630308 --> 0.628501).  Saving model ...
	 Train_Loss: 0.6356 Train_Acc: 65.407 Val_Loss: 0.6285  BEST VAL Loss: 0.6285  Val_Acc: 67.100

Epoch 12: Validation loss decreased (0.628501 --> 0.626969).  Saving model ...
	 Train_Loss: 0.6339 Train_Acc: 65.491 Val_Loss: 0.6270  BEST VAL Loss: 0.6270  Val_Acc: 66.833

Epoch 13: Validation loss decreased (0.626969 --> 0.625385).  Saving model ...
	 Train_Loss: 0.6323 Train_Acc: 65.616 Val_Loss: 0.6254  BEST VAL Loss: 0.6254  Val_Acc: 67.166

Epoch 14: Validation loss decreased (0.625385 --> 0.623903).  Saving model ...
	 Train_Loss: 0.6309 Train_Acc: 66.016 Val_Loss: 0.6239  BEST VAL Loss: 0.6239  Val_Acc: 67.511

Epoch 15: Validation loss decreased (0.623903 --> 0.622724).  Saving model ...
	 Train_Loss: 0.6295 Train_Acc: 66.147 Val_Loss: 0.6227  BEST VAL Loss: 0.6227  Val_Acc: 67.117

Epoch 16: Validation loss decreased (0.622724 --> 0.621403).  Saving model ...
	 Train_Loss: 0.6282 Train_Acc: 66.234 Val_Loss: 0.6214  BEST VAL Loss: 0.6214  Val_Acc: 67.770

Epoch 17: Validation loss decreased (0.621403 --> 0.620160).  Saving model ...
	 Train_Loss: 0.6269 Train_Acc: 66.189 Val_Loss: 0.6202  BEST VAL Loss: 0.6202  Val_Acc: 68.072

Epoch 18: Validation loss decreased (0.620160 --> 0.619040).  Saving model ...
	 Train_Loss: 0.6258 Train_Acc: 66.353 Val_Loss: 0.6190  BEST VAL Loss: 0.6190  Val_Acc: 67.800

Epoch 19: Validation loss decreased (0.619040 --> 0.617891).  Saving model ...
	 Train_Loss: 0.6247 Train_Acc: 66.450 Val_Loss: 0.6179  BEST VAL Loss: 0.6179  Val_Acc: 67.853

Epoch 20: Validation loss decreased (0.617891 --> 0.616809).  Saving model ...
	 Train_Loss: 0.6237 Train_Acc: 66.520 Val_Loss: 0.6168  BEST VAL Loss: 0.6168  Val_Acc: 68.334

Epoch 21: Validation loss decreased (0.616809 --> 0.615759).  Saving model ...
	 Train_Loss: 0.6227 Train_Acc: 66.511 Val_Loss: 0.6158  BEST VAL Loss: 0.6158  Val_Acc: 68.181

Epoch 22: Validation loss decreased (0.615759 --> 0.614731).  Saving model ...
	 Train_Loss: 0.6218 Train_Acc: 66.803 Val_Loss: 0.6147  BEST VAL Loss: 0.6147  Val_Acc: 68.290

Epoch 23: Validation loss decreased (0.614731 --> 0.613761).  Saving model ...
	 Train_Loss: 0.6209 Train_Acc: 66.632 Val_Loss: 0.6138  BEST VAL Loss: 0.6138  Val_Acc: 68.501

Epoch 24: Validation loss decreased (0.613761 --> 0.612775).  Saving model ...
	 Train_Loss: 0.6200 Train_Acc: 66.796 Val_Loss: 0.6128  BEST VAL Loss: 0.6128  Val_Acc: 68.457

Epoch 25: Validation loss decreased (0.612775 --> 0.611769).  Saving model ...
	 Train_Loss: 0.6191 Train_Acc: 66.953 Val_Loss: 0.6118  BEST VAL Loss: 0.6118  Val_Acc: 68.439

Epoch 26: Validation loss decreased (0.611769 --> 0.610820).  Saving model ...
	 Train_Loss: 0.6183 Train_Acc: 66.928 Val_Loss: 0.6108  BEST VAL Loss: 0.6108  Val_Acc: 68.671

Epoch 27: Validation loss decreased (0.610820 --> 0.609974).  Saving model ...
	 Train_Loss: 0.6174 Train_Acc: 67.100 Val_Loss: 0.6100  BEST VAL Loss: 0.6100  Val_Acc: 68.671

Epoch 28: Validation loss decreased (0.609974 --> 0.609142).  Saving model ...
	 Train_Loss: 0.6166 Train_Acc: 67.041 Val_Loss: 0.6091  BEST VAL Loss: 0.6091  Val_Acc: 68.588

Epoch 29: Validation loss decreased (0.609142 --> 0.608372).  Saving model ...
	 Train_Loss: 0.6159 Train_Acc: 67.080 Val_Loss: 0.6084  BEST VAL Loss: 0.6084  Val_Acc: 68.846

Epoch 30: Validation loss decreased (0.608372 --> 0.607555).  Saving model ...
	 Train_Loss: 0.6151 Train_Acc: 67.076 Val_Loss: 0.6076  BEST VAL Loss: 0.6076  Val_Acc: 68.868

Epoch 31: Validation loss decreased (0.607555 --> 0.606748).  Saving model ...
	 Train_Loss: 0.6144 Train_Acc: 67.376 Val_Loss: 0.6067  BEST VAL Loss: 0.6067  Val_Acc: 68.768

Epoch 32: Validation loss decreased (0.606748 --> 0.605955).  Saving model ...
	 Train_Loss: 0.6137 Train_Acc: 67.198 Val_Loss: 0.6060  BEST VAL Loss: 0.6060  Val_Acc: 68.824

Epoch 33: Validation loss decreased (0.605955 --> 0.605237).  Saving model ...
	 Train_Loss: 0.6129 Train_Acc: 67.423 Val_Loss: 0.6052  BEST VAL Loss: 0.6052  Val_Acc: 68.641

Epoch 34: Validation loss decreased (0.605237 --> 0.604502).  Saving model ...
	 Train_Loss: 0.6123 Train_Acc: 67.354 Val_Loss: 0.6045  BEST VAL Loss: 0.6045  Val_Acc: 68.702

Epoch 35: Validation loss decreased (0.604502 --> 0.603762).  Saving model ...
	 Train_Loss: 0.6116 Train_Acc: 67.374 Val_Loss: 0.6038  BEST VAL Loss: 0.6038  Val_Acc: 69.030

Epoch 36: Validation loss decreased (0.603762 --> 0.603026).  Saving model ...
	 Train_Loss: 0.6109 Train_Acc: 67.340 Val_Loss: 0.6030  BEST VAL Loss: 0.6030  Val_Acc: 68.982

Epoch 37: Validation loss decreased (0.603026 --> 0.602296).  Saving model ...
	 Train_Loss: 0.6103 Train_Acc: 67.551 Val_Loss: 0.6023  BEST VAL Loss: 0.6023  Val_Acc: 69.087

Epoch 38: Validation loss decreased (0.602296 --> 0.601604).  Saving model ...
	 Train_Loss: 0.6097 Train_Acc: 67.332 Val_Loss: 0.6016  BEST VAL Loss: 0.6016  Val_Acc: 69.223

Epoch 39: Validation loss decreased (0.601604 --> 0.600904).  Saving model ...
	 Train_Loss: 0.6090 Train_Acc: 67.664 Val_Loss: 0.6009  BEST VAL Loss: 0.6009  Val_Acc: 69.201

Epoch 40: Validation loss decreased (0.600904 --> 0.600211).  Saving model ...
	 Train_Loss: 0.6084 Train_Acc: 67.638 Val_Loss: 0.6002  BEST VAL Loss: 0.6002  Val_Acc: 69.271

Epoch 41: Validation loss decreased (0.600211 --> 0.599558).  Saving model ...
	 Train_Loss: 0.6077 Train_Acc: 67.707 Val_Loss: 0.5996  BEST VAL Loss: 0.5996  Val_Acc: 69.153

Epoch 42: Validation loss decreased (0.599558 --> 0.598884).  Saving model ...
	 Train_Loss: 0.6071 Train_Acc: 67.722 Val_Loss: 0.5989  BEST VAL Loss: 0.5989  Val_Acc: 69.345

Epoch 43: Validation loss decreased (0.598884 --> 0.598269).  Saving model ...
	 Train_Loss: 0.6065 Train_Acc: 67.705 Val_Loss: 0.5983  BEST VAL Loss: 0.5983  Val_Acc: 69.437

Epoch 44: Validation loss decreased (0.598269 --> 0.597635).  Saving model ...
	 Train_Loss: 0.6059 Train_Acc: 67.767 Val_Loss: 0.5976  BEST VAL Loss: 0.5976  Val_Acc: 69.175

Epoch 45: Validation loss decreased (0.597635 --> 0.596990).  Saving model ...
	 Train_Loss: 0.6054 Train_Acc: 67.838 Val_Loss: 0.5970  BEST VAL Loss: 0.5970  Val_Acc: 69.704

Epoch 46: Validation loss decreased (0.596990 --> 0.596353).  Saving model ...
	 Train_Loss: 0.6048 Train_Acc: 67.874 Val_Loss: 0.5964  BEST VAL Loss: 0.5964  Val_Acc: 69.498

Epoch 47: Validation loss decreased (0.596353 --> 0.595713).  Saving model ...
	 Train_Loss: 0.6042 Train_Acc: 67.831 Val_Loss: 0.5957  BEST VAL Loss: 0.5957  Val_Acc: 69.783

Epoch 48: Validation loss decreased (0.595713 --> 0.595092).  Saving model ...
	 Train_Loss: 0.6037 Train_Acc: 67.916 Val_Loss: 0.5951  BEST VAL Loss: 0.5951  Val_Acc: 69.603

Epoch 49: Validation loss decreased (0.595092 --> 0.594482).  Saving model ...
	 Train_Loss: 0.6031 Train_Acc: 67.992 Val_Loss: 0.5945  BEST VAL Loss: 0.5945  Val_Acc: 69.748

Epoch 50: Validation loss decreased (0.594482 --> 0.593899).  Saving model ...
	 Train_Loss: 0.6026 Train_Acc: 68.038 Val_Loss: 0.5939  BEST VAL Loss: 0.5939  Val_Acc: 69.555

Epoch 51: Validation loss decreased (0.593899 --> 0.593346).  Saving model ...
	 Train_Loss: 0.6021 Train_Acc: 68.045 Val_Loss: 0.5933  BEST VAL Loss: 0.5933  Val_Acc: 69.910

Epoch 52: Validation loss decreased (0.593346 --> 0.592773).  Saving model ...
	 Train_Loss: 0.6016 Train_Acc: 67.976 Val_Loss: 0.5928  BEST VAL Loss: 0.5928  Val_Acc: 69.713

Epoch 53: Validation loss decreased (0.592773 --> 0.592221).  Saving model ...
	 Train_Loss: 0.6010 Train_Acc: 68.048 Val_Loss: 0.5922  BEST VAL Loss: 0.5922  Val_Acc: 69.849

Epoch 54: Validation loss decreased (0.592221 --> 0.591647).  Saving model ...
	 Train_Loss: 0.6005 Train_Acc: 68.148 Val_Loss: 0.5916  BEST VAL Loss: 0.5916  Val_Acc: 70.024

Epoch 55: Validation loss decreased (0.591647 --> 0.591124).  Saving model ...
	 Train_Loss: 0.6001 Train_Acc: 68.086 Val_Loss: 0.5911  BEST VAL Loss: 0.5911  Val_Acc: 69.892

Epoch 56: Validation loss decreased (0.591124 --> 0.590575).  Saving model ...
	 Train_Loss: 0.5996 Train_Acc: 68.131 Val_Loss: 0.5906  BEST VAL Loss: 0.5906  Val_Acc: 70.015

Epoch 57: Validation loss decreased (0.590575 --> 0.590065).  Saving model ...
	 Train_Loss: 0.5991 Train_Acc: 68.118 Val_Loss: 0.5901  BEST VAL Loss: 0.5901  Val_Acc: 70.067

Epoch 58: Validation loss decreased (0.590065 --> 0.589574).  Saving model ...
	 Train_Loss: 0.5986 Train_Acc: 68.095 Val_Loss: 0.5896  BEST VAL Loss: 0.5896  Val_Acc: 69.897

Epoch 59: Validation loss decreased (0.589574 --> 0.589055).  Saving model ...
	 Train_Loss: 0.5981 Train_Acc: 68.271 Val_Loss: 0.5891  BEST VAL Loss: 0.5891  Val_Acc: 70.225

Epoch 60: Validation loss decreased (0.589055 --> 0.588558).  Saving model ...
	 Train_Loss: 0.5977 Train_Acc: 68.261 Val_Loss: 0.5886  BEST VAL Loss: 0.5886  Val_Acc: 70.063

Epoch 61: Validation loss decreased (0.588558 --> 0.588080).  Saving model ...
	 Train_Loss: 0.5972 Train_Acc: 68.266 Val_Loss: 0.5881  BEST VAL Loss: 0.5881  Val_Acc: 70.304

Epoch 62: Validation loss decreased (0.588080 --> 0.587607).  Saving model ...
	 Train_Loss: 0.5968 Train_Acc: 68.287 Val_Loss: 0.5876  BEST VAL Loss: 0.5876  Val_Acc: 70.006

Epoch 63: Validation loss decreased (0.587607 --> 0.587144).  Saving model ...
	 Train_Loss: 0.5963 Train_Acc: 68.208 Val_Loss: 0.5871  BEST VAL Loss: 0.5871  Val_Acc: 69.971

Epoch 64: Validation loss decreased (0.587144 --> 0.586711).  Saving model ...
	 Train_Loss: 0.5959 Train_Acc: 68.072 Val_Loss: 0.5867  BEST VAL Loss: 0.5867  Val_Acc: 69.914

Epoch 65: Validation loss decreased (0.586711 --> 0.586291).  Saving model ...
	 Train_Loss: 0.5955 Train_Acc: 68.198 Val_Loss: 0.5863  BEST VAL Loss: 0.5863  Val_Acc: 70.041

Epoch 66: Validation loss decreased (0.586291 --> 0.585823).  Saving model ...
	 Train_Loss: 0.5951 Train_Acc: 68.367 Val_Loss: 0.5858  BEST VAL Loss: 0.5858  Val_Acc: 70.129

Epoch 67: Validation loss decreased (0.585823 --> 0.585388).  Saving model ...
	 Train_Loss: 0.5948 Train_Acc: 68.251 Val_Loss: 0.5854  BEST VAL Loss: 0.5854  Val_Acc: 70.137

Epoch 68: Validation loss decreased (0.585388 --> 0.584971).  Saving model ...
	 Train_Loss: 0.5944 Train_Acc: 68.291 Val_Loss: 0.5850  BEST VAL Loss: 0.5850  Val_Acc: 70.348

Epoch 69: Validation loss decreased (0.584971 --> 0.584566).  Saving model ...
	 Train_Loss: 0.5940 Train_Acc: 68.248 Val_Loss: 0.5846  BEST VAL Loss: 0.5846  Val_Acc: 70.186

Epoch 70: Validation loss decreased (0.584566 --> 0.584153).  Saving model ...
	 Train_Loss: 0.5936 Train_Acc: 68.385 Val_Loss: 0.5842  BEST VAL Loss: 0.5842  Val_Acc: 70.488

Epoch 71: Validation loss decreased (0.584153 --> 0.583763).  Saving model ...
	 Train_Loss: 0.5932 Train_Acc: 68.477 Val_Loss: 0.5838  BEST VAL Loss: 0.5838  Val_Acc: 70.216

Epoch 72: Validation loss decreased (0.583763 --> 0.583364).  Saving model ...
	 Train_Loss: 0.5928 Train_Acc: 68.296 Val_Loss: 0.5834  BEST VAL Loss: 0.5834  Val_Acc: 70.321

Epoch 73: Validation loss decreased (0.583364 --> 0.583000).  Saving model ...
	 Train_Loss: 0.5925 Train_Acc: 68.326 Val_Loss: 0.5830  BEST VAL Loss: 0.5830  Val_Acc: 70.216

Epoch 74: Validation loss decreased (0.583000 --> 0.582609).  Saving model ...
	 Train_Loss: 0.5921 Train_Acc: 68.385 Val_Loss: 0.5826  BEST VAL Loss: 0.5826  Val_Acc: 70.479

Epoch 75: Validation loss decreased (0.582609 --> 0.582238).  Saving model ...
	 Train_Loss: 0.5918 Train_Acc: 68.542 Val_Loss: 0.5822  BEST VAL Loss: 0.5822  Val_Acc: 70.312

Epoch 76: Validation loss decreased (0.582238 --> 0.581909).  Saving model ...
	 Train_Loss: 0.5914 Train_Acc: 68.400 Val_Loss: 0.5819  BEST VAL Loss: 0.5819  Val_Acc: 69.940

Epoch 77: Validation loss decreased (0.581909 --> 0.581539).  Saving model ...
	 Train_Loss: 0.5911 Train_Acc: 68.592 Val_Loss: 0.5815  BEST VAL Loss: 0.5815  Val_Acc: 70.470

Epoch 78: Validation loss decreased (0.581539 --> 0.581183).  Saving model ...
	 Train_Loss: 0.5907 Train_Acc: 68.478 Val_Loss: 0.5812  BEST VAL Loss: 0.5812  Val_Acc: 70.439

Epoch 79: Validation loss decreased (0.581183 --> 0.580833).  Saving model ...
	 Train_Loss: 0.5904 Train_Acc: 68.381 Val_Loss: 0.5808  BEST VAL Loss: 0.5808  Val_Acc: 70.536

Epoch 80: Validation loss decreased (0.580833 --> 0.580480).  Saving model ...
	 Train_Loss: 0.5901 Train_Acc: 68.648 Val_Loss: 0.5805  BEST VAL Loss: 0.5805  Val_Acc: 70.702

Epoch 81: Validation loss decreased (0.580480 --> 0.580137).  Saving model ...
	 Train_Loss: 0.5898 Train_Acc: 68.449 Val_Loss: 0.5801  BEST VAL Loss: 0.5801  Val_Acc: 70.628

Epoch 82: Validation loss decreased (0.580137 --> 0.579801).  Saving model ...
	 Train_Loss: 0.5895 Train_Acc: 68.255 Val_Loss: 0.5798  BEST VAL Loss: 0.5798  Val_Acc: 70.496

Epoch 83: Validation loss decreased (0.579801 --> 0.579463).  Saving model ...
	 Train_Loss: 0.5892 Train_Acc: 68.554 Val_Loss: 0.5795  BEST VAL Loss: 0.5795  Val_Acc: 70.820

Epoch 84: Validation loss decreased (0.579463 --> 0.579149).  Saving model ...
	 Train_Loss: 0.5889 Train_Acc: 68.526 Val_Loss: 0.5791  BEST VAL Loss: 0.5791  Val_Acc: 70.776

Epoch 85: Validation loss decreased (0.579149 --> 0.578844).  Saving model ...
	 Train_Loss: 0.5886 Train_Acc: 68.554 Val_Loss: 0.5788  BEST VAL Loss: 0.5788  Val_Acc: 70.750

Epoch 86: Validation loss decreased (0.578844 --> 0.578543).  Saving model ...
	 Train_Loss: 0.5883 Train_Acc: 68.623 Val_Loss: 0.5785  BEST VAL Loss: 0.5785  Val_Acc: 70.593

Epoch 87: Validation loss decreased (0.578543 --> 0.578230).  Saving model ...
	 Train_Loss: 0.5880 Train_Acc: 68.618 Val_Loss: 0.5782  BEST VAL Loss: 0.5782  Val_Acc: 70.562

Epoch 88: Validation loss decreased (0.578230 --> 0.577911).  Saving model ...
	 Train_Loss: 0.5877 Train_Acc: 68.634 Val_Loss: 0.5779  BEST VAL Loss: 0.5779  Val_Acc: 70.724

Epoch 89: Validation loss decreased (0.577911 --> 0.577601).  Saving model ...
	 Train_Loss: 0.5874 Train_Acc: 68.406 Val_Loss: 0.5776  BEST VAL Loss: 0.5776  Val_Acc: 70.711

Epoch 90: Validation loss decreased (0.577601 --> 0.577336).  Saving model ...
	 Train_Loss: 0.5871 Train_Acc: 68.562 Val_Loss: 0.5773  BEST VAL Loss: 0.5773  Val_Acc: 70.676

Epoch 91: Validation loss decreased (0.577336 --> 0.577044).  Saving model ...
	 Train_Loss: 0.5869 Train_Acc: 68.544 Val_Loss: 0.5770  BEST VAL Loss: 0.5770  Val_Acc: 70.846

Epoch 92: Validation loss decreased (0.577044 --> 0.576765).  Saving model ...
	 Train_Loss: 0.5866 Train_Acc: 68.537 Val_Loss: 0.5768  BEST VAL Loss: 0.5768  Val_Acc: 70.846

Epoch 93: Validation loss decreased (0.576765 --> 0.576493).  Saving model ...
	 Train_Loss: 0.5863 Train_Acc: 68.619 Val_Loss: 0.5765  BEST VAL Loss: 0.5765  Val_Acc: 70.698

Epoch 94: Validation loss decreased (0.576493 --> 0.576209).  Saving model ...
	 Train_Loss: 0.5861 Train_Acc: 68.617 Val_Loss: 0.5762  BEST VAL Loss: 0.5762  Val_Acc: 70.825

Epoch 95: Validation loss decreased (0.576209 --> 0.575942).  Saving model ...
	 Train_Loss: 0.5858 Train_Acc: 68.810 Val_Loss: 0.5759  BEST VAL Loss: 0.5759  Val_Acc: 70.790

Epoch 96: Validation loss decreased (0.575942 --> 0.575666).  Saving model ...
	 Train_Loss: 0.5856 Train_Acc: 68.628 Val_Loss: 0.5757  BEST VAL Loss: 0.5757  Val_Acc: 70.663

Epoch 97: Validation loss decreased (0.575666 --> 0.575391).  Saving model ...
	 Train_Loss: 0.5853 Train_Acc: 68.656 Val_Loss: 0.5754  BEST VAL Loss: 0.5754  Val_Acc: 70.912

Epoch 98: Validation loss decreased (0.575391 --> 0.575120).  Saving model ...
	 Train_Loss: 0.5851 Train_Acc: 68.714 Val_Loss: 0.5751  BEST VAL Loss: 0.5751  Val_Acc: 70.903

Epoch 99: Validation loss decreased (0.575120 --> 0.574861).  Saving model ...
	 Train_Loss: 0.5848 Train_Acc: 68.611 Val_Loss: 0.5749  BEST VAL Loss: 0.5749  Val_Acc: 70.724

LPS_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.72      0.70      0.71     85026
           1       0.75      0.77      0.76     97753

    accuracy                           0.74    182779
   macro avg       0.74      0.73      0.74    182779
weighted avg       0.74      0.74      0.74    182779

LPS_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.69      0.67      0.68     10629
           1       0.72      0.74      0.73     12219

    accuracy                           0.71     22848
   macro avg       0.71      0.70      0.70     22848
weighted avg       0.71      0.71      0.71     22848

LPS_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.70      0.68      0.69     10628
           1       0.73      0.75      0.74     12220

    accuracy                           0.72     22848
   macro avg       0.71      0.71      0.71     22848
weighted avg       0.71      0.72      0.71     22848

              precision    recall  f1-score   support

           0       0.70      0.68      0.69     10628
           1       0.73      0.75      0.74     12220

    accuracy                           0.72     22848
   macro avg       0.71      0.71      0.71     22848
weighted avg       0.71      0.72      0.71     22848

LPS_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.51      0.54      0.53     36797
           1       0.52      0.50      0.51     37243

    accuracy                           0.52     74040
   macro avg       0.52      0.52      0.52     74040
weighted avg       0.52      0.52      0.52     74040

              precision    recall  f1-score   support

           0       0.51      0.54      0.53     36797
           1       0.52      0.50      0.51     37243

    accuracy                           0.52     74040
   macro avg       0.52      0.52      0.52     74040
weighted avg       0.52      0.52      0.52     74040

completed
