[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'e2530245'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'af1f61ed'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '9b791e51'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '3d074a93'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (317341, 1270)
Number of total missing values across all columns: 286160
Data Subset Is Off
Wells held out for testing: ['B09' 'L09']
Wells to use for training, validation, and testing ['B02' 'B03' 'B08' 'L02' 'L03' 'L08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.263099).  Saving model ...
	 Train_Loss: 0.3803 Train_Acc: 82.961 Val_Loss: 0.2631  BEST VAL Loss: 0.2631  Val_Acc: 89.961

Epoch 1: Validation loss decreased (0.263099 --> 0.236134).  Saving model ...
	 Train_Loss: 0.3265 Train_Acc: 89.574 Val_Loss: 0.2361  BEST VAL Loss: 0.2361  Val_Acc: 91.934

Epoch 2: Validation loss decreased (0.236134 --> 0.218992).  Saving model ...
	 Train_Loss: 0.2961 Train_Acc: 91.082 Val_Loss: 0.2190  BEST VAL Loss: 0.2190  Val_Acc: 92.909

Epoch 3: Validation loss decreased (0.218992 --> 0.206700).  Saving model ...
	 Train_Loss: 0.2763 Train_Acc: 91.773 Val_Loss: 0.2067  BEST VAL Loss: 0.2067  Val_Acc: 93.521

Epoch 4: Validation loss decreased (0.206700 --> 0.197470).  Saving model ...
	 Train_Loss: 0.2621 Train_Acc: 92.228 Val_Loss: 0.1975  BEST VAL Loss: 0.1975  Val_Acc: 93.899

Epoch 5: Validation loss decreased (0.197470 --> 0.190442).  Saving model ...
	 Train_Loss: 0.2511 Train_Acc: 92.509 Val_Loss: 0.1904  BEST VAL Loss: 0.1904  Val_Acc: 94.092

Epoch 6: Validation loss decreased (0.190442 --> 0.184615).  Saving model ...
	 Train_Loss: 0.2424 Train_Acc: 92.780 Val_Loss: 0.1846  BEST VAL Loss: 0.1846  Val_Acc: 94.191

Epoch 7: Validation loss decreased (0.184615 --> 0.179850).  Saving model ...
	 Train_Loss: 0.2353 Train_Acc: 92.954 Val_Loss: 0.1799  BEST VAL Loss: 0.1799  Val_Acc: 94.376

Epoch 8: Validation loss decreased (0.179850 --> 0.175937).  Saving model ...
	 Train_Loss: 0.2293 Train_Acc: 93.170 Val_Loss: 0.1759  BEST VAL Loss: 0.1759  Val_Acc: 94.413

Epoch 9: Validation loss decreased (0.175937 --> 0.172484).  Saving model ...
	 Train_Loss: 0.2242 Train_Acc: 93.241 Val_Loss: 0.1725  BEST VAL Loss: 0.1725  Val_Acc: 94.421

Epoch 10: Validation loss decreased (0.172484 --> 0.169655).  Saving model ...
	 Train_Loss: 0.2199 Train_Acc: 93.315 Val_Loss: 0.1697  BEST VAL Loss: 0.1697  Val_Acc: 94.462

Epoch 11: Validation loss decreased (0.169655 --> 0.167007).  Saving model ...
	 Train_Loss: 0.2161 Train_Acc: 93.458 Val_Loss: 0.1670  BEST VAL Loss: 0.1670  Val_Acc: 94.623

Epoch 12: Validation loss decreased (0.167007 --> 0.164656).  Saving model ...
	 Train_Loss: 0.2127 Train_Acc: 93.495 Val_Loss: 0.1647  BEST VAL Loss: 0.1647  Val_Acc: 94.672

Epoch 13: Validation loss decreased (0.164656 --> 0.162531).  Saving model ...
	 Train_Loss: 0.2096 Train_Acc: 93.557 Val_Loss: 0.1625  BEST VAL Loss: 0.1625  Val_Acc: 94.758

Epoch 14: Validation loss decreased (0.162531 --> 0.160696).  Saving model ...
	 Train_Loss: 0.2067 Train_Acc: 93.651 Val_Loss: 0.1607  BEST VAL Loss: 0.1607  Val_Acc: 94.767

Epoch 15: Validation loss decreased (0.160696 --> 0.158821).  Saving model ...
	 Train_Loss: 0.2041 Train_Acc: 93.754 Val_Loss: 0.1588  BEST VAL Loss: 0.1588  Val_Acc: 94.960

Epoch 16: Validation loss decreased (0.158821 --> 0.157291).  Saving model ...
	 Train_Loss: 0.2017 Train_Acc: 93.801 Val_Loss: 0.1573  BEST VAL Loss: 0.1573  Val_Acc: 94.935

Epoch 17: Validation loss decreased (0.157291 --> 0.156226).  Saving model ...
	 Train_Loss: 0.1997 Train_Acc: 93.803 Val_Loss: 0.1562  BEST VAL Loss: 0.1562  Val_Acc: 94.771

Epoch 18: Validation loss decreased (0.156226 --> 0.154849).  Saving model ...
	 Train_Loss: 0.1977 Train_Acc: 93.848 Val_Loss: 0.1548  BEST VAL Loss: 0.1548  Val_Acc: 95.133

Epoch 19: Validation loss decreased (0.154849 --> 0.153613).  Saving model ...
	 Train_Loss: 0.1958 Train_Acc: 93.862 Val_Loss: 0.1536  BEST VAL Loss: 0.1536  Val_Acc: 95.017

Epoch 20: Validation loss decreased (0.153613 --> 0.152463).  Saving model ...
	 Train_Loss: 0.1941 Train_Acc: 93.947 Val_Loss: 0.1525  BEST VAL Loss: 0.1525  Val_Acc: 95.079

Epoch 21: Validation loss decreased (0.152463 --> 0.151330).  Saving model ...
	 Train_Loss: 0.1925 Train_Acc: 94.021 Val_Loss: 0.1513  BEST VAL Loss: 0.1513  Val_Acc: 95.071

Epoch 22: Validation loss decreased (0.151330 --> 0.150331).  Saving model ...
	 Train_Loss: 0.1909 Train_Acc: 94.026 Val_Loss: 0.1503  BEST VAL Loss: 0.1503  Val_Acc: 94.952

Epoch 23: Validation loss decreased (0.150331 --> 0.149296).  Saving model ...
	 Train_Loss: 0.1895 Train_Acc: 93.987 Val_Loss: 0.1493  BEST VAL Loss: 0.1493  Val_Acc: 95.194

Epoch 24: Validation loss decreased (0.149296 --> 0.148618).  Saving model ...
	 Train_Loss: 0.1882 Train_Acc: 94.056 Val_Loss: 0.1486  BEST VAL Loss: 0.1486  Val_Acc: 95.013

Epoch 25: Validation loss decreased (0.148618 --> 0.147734).  Saving model ...
	 Train_Loss: 0.1869 Train_Acc: 94.133 Val_Loss: 0.1477  BEST VAL Loss: 0.1477  Val_Acc: 95.207

Epoch 26: Validation loss decreased (0.147734 --> 0.146844).  Saving model ...
	 Train_Loss: 0.1857 Train_Acc: 94.124 Val_Loss: 0.1468  BEST VAL Loss: 0.1468  Val_Acc: 95.433

Epoch 27: Validation loss decreased (0.146844 --> 0.145994).  Saving model ...
	 Train_Loss: 0.1845 Train_Acc: 94.168 Val_Loss: 0.1460  BEST VAL Loss: 0.1460  Val_Acc: 95.379

Epoch 28: Validation loss decreased (0.145994 --> 0.145271).  Saving model ...
	 Train_Loss: 0.1834 Train_Acc: 94.197 Val_Loss: 0.1453  BEST VAL Loss: 0.1453  Val_Acc: 95.128

Epoch 29: Validation loss decreased (0.145271 --> 0.144626).  Saving model ...
	 Train_Loss: 0.1824 Train_Acc: 94.196 Val_Loss: 0.1446  BEST VAL Loss: 0.1446  Val_Acc: 95.244

Epoch 30: Validation loss decreased (0.144626 --> 0.143983).  Saving model ...
	 Train_Loss: 0.1814 Train_Acc: 94.268 Val_Loss: 0.1440  BEST VAL Loss: 0.1440  Val_Acc: 95.400

Epoch 31: Validation loss decreased (0.143983 --> 0.143265).  Saving model ...
	 Train_Loss: 0.1804 Train_Acc: 94.245 Val_Loss: 0.1433  BEST VAL Loss: 0.1433  Val_Acc: 95.375

Epoch 32: Validation loss decreased (0.143265 --> 0.142632).  Saving model ...
	 Train_Loss: 0.1795 Train_Acc: 94.244 Val_Loss: 0.1426  BEST VAL Loss: 0.1426  Val_Acc: 95.490

Epoch 33: Validation loss decreased (0.142632 --> 0.142146).  Saving model ...
	 Train_Loss: 0.1786 Train_Acc: 94.297 Val_Loss: 0.1421  BEST VAL Loss: 0.1421  Val_Acc: 95.244

Epoch 34: Validation loss decreased (0.142146 --> 0.141640).  Saving model ...
	 Train_Loss: 0.1778 Train_Acc: 94.344 Val_Loss: 0.1416  BEST VAL Loss: 0.1416  Val_Acc: 95.507

Epoch 35: Validation loss decreased (0.141640 --> 0.141175).  Saving model ...
	 Train_Loss: 0.1769 Train_Acc: 94.283 Val_Loss: 0.1412  BEST VAL Loss: 0.1412  Val_Acc: 95.309

Epoch 36: Validation loss decreased (0.141175 --> 0.140654).  Saving model ...
	 Train_Loss: 0.1761 Train_Acc: 94.385 Val_Loss: 0.1407  BEST VAL Loss: 0.1407  Val_Acc: 95.363

Epoch 37: Validation loss decreased (0.140654 --> 0.140097).  Saving model ...
	 Train_Loss: 0.1754 Train_Acc: 94.365 Val_Loss: 0.1401  BEST VAL Loss: 0.1401  Val_Acc: 95.498

Epoch 38: Validation loss decreased (0.140097 --> 0.139629).  Saving model ...
	 Train_Loss: 0.1746 Train_Acc: 94.340 Val_Loss: 0.1396  BEST VAL Loss: 0.1396  Val_Acc: 95.605

Epoch 39: Validation loss decreased (0.139629 --> 0.139180).  Saving model ...
	 Train_Loss: 0.1739 Train_Acc: 94.381 Val_Loss: 0.1392  BEST VAL Loss: 0.1392  Val_Acc: 95.445

Epoch 40: Validation loss decreased (0.139180 --> 0.138726).  Saving model ...
	 Train_Loss: 0.1733 Train_Acc: 94.410 Val_Loss: 0.1387  BEST VAL Loss: 0.1387  Val_Acc: 95.400

Epoch 41: Validation loss decreased (0.138726 --> 0.138264).  Saving model ...
	 Train_Loss: 0.1726 Train_Acc: 94.437 Val_Loss: 0.1383  BEST VAL Loss: 0.1383  Val_Acc: 95.560

Epoch 42: Validation loss decreased (0.138264 --> 0.137915).  Saving model ...
	 Train_Loss: 0.1719 Train_Acc: 94.438 Val_Loss: 0.1379  BEST VAL Loss: 0.1379  Val_Acc: 95.326

Epoch 43: Validation loss decreased (0.137915 --> 0.137511).  Saving model ...
	 Train_Loss: 0.1713 Train_Acc: 94.441 Val_Loss: 0.1375  BEST VAL Loss: 0.1375  Val_Acc: 95.568

Epoch 44: Validation loss decreased (0.137511 --> 0.137146).  Saving model ...
	 Train_Loss: 0.1707 Train_Acc: 94.465 Val_Loss: 0.1371  BEST VAL Loss: 0.1371  Val_Acc: 95.540

Epoch 45: Validation loss decreased (0.137146 --> 0.136810).  Saving model ...
	 Train_Loss: 0.1701 Train_Acc: 94.477 Val_Loss: 0.1368  BEST VAL Loss: 0.1368  Val_Acc: 95.527

Epoch 46: Validation loss decreased (0.136810 --> 0.136364).  Saving model ...
	 Train_Loss: 0.1695 Train_Acc: 94.532 Val_Loss: 0.1364  BEST VAL Loss: 0.1364  Val_Acc: 95.540

Epoch 47: Validation loss decreased (0.136364 --> 0.136037).  Saving model ...
	 Train_Loss: 0.1690 Train_Acc: 94.546 Val_Loss: 0.1360  BEST VAL Loss: 0.1360  Val_Acc: 95.655

Epoch 48: Validation loss decreased (0.136037 --> 0.135648).  Saving model ...
	 Train_Loss: 0.1684 Train_Acc: 94.534 Val_Loss: 0.1356  BEST VAL Loss: 0.1356  Val_Acc: 95.688

Epoch 49: Validation loss decreased (0.135648 --> 0.135313).  Saving model ...
	 Train_Loss: 0.1679 Train_Acc: 94.493 Val_Loss: 0.1353  BEST VAL Loss: 0.1353  Val_Acc: 95.692

Epoch 50: Validation loss decreased (0.135313 --> 0.134919).  Saving model ...
	 Train_Loss: 0.1674 Train_Acc: 94.557 Val_Loss: 0.1349  BEST VAL Loss: 0.1349  Val_Acc: 95.675

Epoch 51: Validation loss decreased (0.134919 --> 0.134521).  Saving model ...
	 Train_Loss: 0.1669 Train_Acc: 94.516 Val_Loss: 0.1345  BEST VAL Loss: 0.1345  Val_Acc: 95.679

Epoch 52: Validation loss decreased (0.134521 --> 0.134171).  Saving model ...
	 Train_Loss: 0.1664 Train_Acc: 94.601 Val_Loss: 0.1342  BEST VAL Loss: 0.1342  Val_Acc: 95.663

Epoch 53: Validation loss decreased (0.134171 --> 0.133811).  Saving model ...
	 Train_Loss: 0.1659 Train_Acc: 94.613 Val_Loss: 0.1338  BEST VAL Loss: 0.1338  Val_Acc: 95.638

Epoch 54: Validation loss decreased (0.133811 --> 0.133479).  Saving model ...
	 Train_Loss: 0.1654 Train_Acc: 94.566 Val_Loss: 0.1335  BEST VAL Loss: 0.1335  Val_Acc: 95.762

Epoch 55: Validation loss decreased (0.133479 --> 0.133156).  Saving model ...
	 Train_Loss: 0.1650 Train_Acc: 94.605 Val_Loss: 0.1332  BEST VAL Loss: 0.1332  Val_Acc: 95.725

Epoch 56: Validation loss decreased (0.133156 --> 0.132852).  Saving model ...
	 Train_Loss: 0.1645 Train_Acc: 94.581 Val_Loss: 0.1329  BEST VAL Loss: 0.1329  Val_Acc: 95.667

Epoch 57: Validation loss decreased (0.132852 --> 0.132514).  Saving model ...
	 Train_Loss: 0.1641 Train_Acc: 94.643 Val_Loss: 0.1325  BEST VAL Loss: 0.1325  Val_Acc: 95.823

Epoch 58: Validation loss decreased (0.132514 --> 0.132213).  Saving model ...
	 Train_Loss: 0.1637 Train_Acc: 94.638 Val_Loss: 0.1322  BEST VAL Loss: 0.1322  Val_Acc: 95.774

Epoch 59: Validation loss decreased (0.132213 --> 0.131934).  Saving model ...
	 Train_Loss: 0.1632 Train_Acc: 94.639 Val_Loss: 0.1319  BEST VAL Loss: 0.1319  Val_Acc: 95.815

Epoch 60: Validation loss decreased (0.131934 --> 0.131662).  Saving model ...
	 Train_Loss: 0.1628 Train_Acc: 94.711 Val_Loss: 0.1317  BEST VAL Loss: 0.1317  Val_Acc: 95.704

Epoch 61: Validation loss decreased (0.131662 --> 0.131528).  Saving model ...
	 Train_Loss: 0.1624 Train_Acc: 94.708 Val_Loss: 0.1315  BEST VAL Loss: 0.1315  Val_Acc: 95.387

Epoch 62: Validation loss decreased (0.131528 --> 0.131364).  Saving model ...
	 Train_Loss: 0.1620 Train_Acc: 94.678 Val_Loss: 0.1314  BEST VAL Loss: 0.1314  Val_Acc: 95.490

Epoch 63: Validation loss decreased (0.131364 --> 0.131188).  Saving model ...
	 Train_Loss: 0.1616 Train_Acc: 94.664 Val_Loss: 0.1312  BEST VAL Loss: 0.1312  Val_Acc: 95.799

Epoch 64: Validation loss decreased (0.131188 --> 0.130969).  Saving model ...
	 Train_Loss: 0.1613 Train_Acc: 94.634 Val_Loss: 0.1310  BEST VAL Loss: 0.1310  Val_Acc: 95.840

Epoch 65: Validation loss decreased (0.130969 --> 0.130766).  Saving model ...
	 Train_Loss: 0.1609 Train_Acc: 94.688 Val_Loss: 0.1308  BEST VAL Loss: 0.1308  Val_Acc: 95.914

Epoch 66: Validation loss decreased (0.130766 --> 0.130553).  Saving model ...
	 Train_Loss: 0.1605 Train_Acc: 94.646 Val_Loss: 0.1306  BEST VAL Loss: 0.1306  Val_Acc: 95.844

Epoch 67: Validation loss decreased (0.130553 --> 0.130303).  Saving model ...
	 Train_Loss: 0.1602 Train_Acc: 94.678 Val_Loss: 0.1303  BEST VAL Loss: 0.1303  Val_Acc: 95.794

Epoch 68: Validation loss decreased (0.130303 --> 0.130074).  Saving model ...
	 Train_Loss: 0.1598 Train_Acc: 94.695 Val_Loss: 0.1301  BEST VAL Loss: 0.1301  Val_Acc: 95.786

Epoch 69: Validation loss decreased (0.130074 --> 0.129830).  Saving model ...
	 Train_Loss: 0.1595 Train_Acc: 94.714 Val_Loss: 0.1298  BEST VAL Loss: 0.1298  Val_Acc: 95.827

Epoch 70: Validation loss decreased (0.129830 --> 0.129644).  Saving model ...
	 Train_Loss: 0.1592 Train_Acc: 94.758 Val_Loss: 0.1296  BEST VAL Loss: 0.1296  Val_Acc: 95.844

Epoch 71: Validation loss decreased (0.129644 --> 0.129444).  Saving model ...
	 Train_Loss: 0.1588 Train_Acc: 94.777 Val_Loss: 0.1294  BEST VAL Loss: 0.1294  Val_Acc: 95.864

Epoch 72: Validation loss decreased (0.129444 --> 0.129203).  Saving model ...
	 Train_Loss: 0.1585 Train_Acc: 94.751 Val_Loss: 0.1292  BEST VAL Loss: 0.1292  Val_Acc: 95.967

Epoch 73: Validation loss decreased (0.129203 --> 0.129003).  Saving model ...
	 Train_Loss: 0.1582 Train_Acc: 94.718 Val_Loss: 0.1290  BEST VAL Loss: 0.1290  Val_Acc: 95.996

Epoch 74: Validation loss decreased (0.129003 --> 0.128789).  Saving model ...
	 Train_Loss: 0.1579 Train_Acc: 94.704 Val_Loss: 0.1288  BEST VAL Loss: 0.1288  Val_Acc: 95.934

Epoch 75: Validation loss decreased (0.128789 --> 0.128583).  Saving model ...
	 Train_Loss: 0.1576 Train_Acc: 94.766 Val_Loss: 0.1286  BEST VAL Loss: 0.1286  Val_Acc: 95.930

Epoch 76: Validation loss decreased (0.128583 --> 0.128370).  Saving model ...
	 Train_Loss: 0.1573 Train_Acc: 94.710 Val_Loss: 0.1284  BEST VAL Loss: 0.1284  Val_Acc: 95.914

Epoch 77: Validation loss decreased (0.128370 --> 0.128151).  Saving model ...
	 Train_Loss: 0.1570 Train_Acc: 94.838 Val_Loss: 0.1282  BEST VAL Loss: 0.1282  Val_Acc: 95.881

Epoch 78: Validation loss decreased (0.128151 --> 0.127939).  Saving model ...
	 Train_Loss: 0.1567 Train_Acc: 94.816 Val_Loss: 0.1279  BEST VAL Loss: 0.1279  Val_Acc: 95.893

Epoch 79: Validation loss decreased (0.127939 --> 0.127744).  Saving model ...
	 Train_Loss: 0.1564 Train_Acc: 94.845 Val_Loss: 0.1277  BEST VAL Loss: 0.1277  Val_Acc: 95.955

Epoch 80: Validation loss decreased (0.127744 --> 0.127545).  Saving model ...
	 Train_Loss: 0.1561 Train_Acc: 94.827 Val_Loss: 0.1275  BEST VAL Loss: 0.1275  Val_Acc: 95.881

Epoch 81: Validation loss decreased (0.127545 --> 0.127358).  Saving model ...
	 Train_Loss: 0.1558 Train_Acc: 94.803 Val_Loss: 0.1274  BEST VAL Loss: 0.1274  Val_Acc: 95.959

Epoch 82: Validation loss decreased (0.127358 --> 0.127177).  Saving model ...
	 Train_Loss: 0.1556 Train_Acc: 94.812 Val_Loss: 0.1272  BEST VAL Loss: 0.1272  Val_Acc: 95.799

Epoch 83: Validation loss decreased (0.127177 --> 0.126990).  Saving model ...
	 Train_Loss: 0.1553 Train_Acc: 94.788 Val_Loss: 0.1270  BEST VAL Loss: 0.1270  Val_Acc: 95.959

Epoch 84: Validation loss decreased (0.126990 --> 0.126820).  Saving model ...
	 Train_Loss: 0.1550 Train_Acc: 94.818 Val_Loss: 0.1268  BEST VAL Loss: 0.1268  Val_Acc: 95.873

Epoch 85: Validation loss decreased (0.126820 --> 0.126663).  Saving model ...
	 Train_Loss: 0.1548 Train_Acc: 94.808 Val_Loss: 0.1267  BEST VAL Loss: 0.1267  Val_Acc: 96.004

Epoch 86: Validation loss decreased (0.126663 --> 0.126518).  Saving model ...
	 Train_Loss: 0.1545 Train_Acc: 94.805 Val_Loss: 0.1265  BEST VAL Loss: 0.1265  Val_Acc: 95.868

Epoch 87: Validation loss decreased (0.126518 --> 0.126380).  Saving model ...
	 Train_Loss: 0.1543 Train_Acc: 94.794 Val_Loss: 0.1264  BEST VAL Loss: 0.1264  Val_Acc: 95.918

Epoch 88: Validation loss decreased (0.126380 --> 0.126195).  Saving model ...
	 Train_Loss: 0.1540 Train_Acc: 94.913 Val_Loss: 0.1262  BEST VAL Loss: 0.1262  Val_Acc: 96.004

Epoch 89: Validation loss decreased (0.126195 --> 0.126071).  Saving model ...
	 Train_Loss: 0.1538 Train_Acc: 94.893 Val_Loss: 0.1261  BEST VAL Loss: 0.1261  Val_Acc: 95.860

Epoch 90: Validation loss decreased (0.126071 --> 0.125914).  Saving model ...
	 Train_Loss: 0.1535 Train_Acc: 94.890 Val_Loss: 0.1259  BEST VAL Loss: 0.1259  Val_Acc: 95.778

Epoch 91: Validation loss decreased (0.125914 --> 0.125759).  Saving model ...
	 Train_Loss: 0.1533 Train_Acc: 94.897 Val_Loss: 0.1258  BEST VAL Loss: 0.1258  Val_Acc: 95.971

Epoch 92: Validation loss decreased (0.125759 --> 0.125651).  Saving model ...
	 Train_Loss: 0.1531 Train_Acc: 94.847 Val_Loss: 0.1257  BEST VAL Loss: 0.1257  Val_Acc: 95.930

Epoch 93: Validation loss decreased (0.125651 --> 0.125483).  Saving model ...
	 Train_Loss: 0.1528 Train_Acc: 94.833 Val_Loss: 0.1255  BEST VAL Loss: 0.1255  Val_Acc: 95.856

Epoch 94: Validation loss decreased (0.125483 --> 0.125369).  Saving model ...
	 Train_Loss: 0.1526 Train_Acc: 94.846 Val_Loss: 0.1254  BEST VAL Loss: 0.1254  Val_Acc: 95.864

Epoch 95: Validation loss decreased (0.125369 --> 0.125240).  Saving model ...
	 Train_Loss: 0.1524 Train_Acc: 94.893 Val_Loss: 0.1252  BEST VAL Loss: 0.1252  Val_Acc: 95.905

Epoch 96: Validation loss decreased (0.125240 --> 0.125108).  Saving model ...
	 Train_Loss: 0.1522 Train_Acc: 94.918 Val_Loss: 0.1251  BEST VAL Loss: 0.1251  Val_Acc: 95.901

Epoch 97: Validation loss decreased (0.125108 --> 0.124964).  Saving model ...
	 Train_Loss: 0.1519 Train_Acc: 94.896 Val_Loss: 0.1250  BEST VAL Loss: 0.1250  Val_Acc: 95.942

Epoch 98: Validation loss decreased (0.124964 --> 0.124814).  Saving model ...
	 Train_Loss: 0.1517 Train_Acc: 94.898 Val_Loss: 0.1248  BEST VAL Loss: 0.1248  Val_Acc: 96.049

Epoch 99: Validation loss decreased (0.124814 --> 0.124701).  Saving model ...
	 Train_Loss: 0.1515 Train_Acc: 94.952 Val_Loss: 0.1247  BEST VAL Loss: 0.1247  Val_Acc: 96.012

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.44      0.45      0.44     85372
           1       0.56      0.55      0.56    109228

    accuracy                           0.51    194600
   macro avg       0.50      0.50      0.50    194600
weighted avg       0.51      0.51      0.51    194600

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.44      0.45      0.44     10671
           1       0.56      0.55      0.56     13654

    accuracy                           0.51     24325
   macro avg       0.50      0.50      0.50     24325
weighted avg       0.51      0.51      0.51     24325

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.43      0.44      0.44     10671
           1       0.56      0.55      0.55     13654

    accuracy                           0.50     24325
   macro avg       0.50      0.50      0.50     24325
weighted avg       0.50      0.50      0.50     24325

              precision    recall  f1-score   support

           0       0.43      0.44      0.44     10671
           1       0.56      0.55      0.55     13654

    accuracy                           0.50     24325
   macro avg       0.50      0.50      0.50     24325
weighted avg       0.50      0.50      0.50     24325

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.41      0.45     36366
           1       0.51      0.59      0.55     37725

    accuracy                           0.50     74091
   macro avg       0.50      0.50      0.50     74091
weighted avg       0.50      0.50      0.50     74091

              precision    recall  f1-score   support

           0       0.49      0.41      0.45     36366
           1       0.51      0.59      0.55     37725

    accuracy                           0.50     74091
   macro avg       0.50      0.50      0.50     74091
weighted avg       0.50      0.50      0.50     74091

completed
