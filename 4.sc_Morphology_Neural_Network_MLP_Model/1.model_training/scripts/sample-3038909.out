[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b381defc'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '83e574f8'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '24d34430'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '55ba2580'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_10.000_DMSO_0.025 treatment_name: LPS_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: LPS_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'LPS_10.000_DMSO_0.025']
The dimensions of the data are: (295923, 1270)
Number of total missing values across all columns: 591846
Data Subset Is Off
Wells held out for testing: ['D08' 'E08']
Wells to use for training, validation, and testing ['D02' 'E02' 'D03' 'E03' 'D09' 'E09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.503704).  Saving model ...
	 Train_Loss: 0.5845 Train_Acc: 69.007 Val_Loss: 0.5037  BEST VAL Loss: 0.5037  Val_Acc: 75.356

Epoch 1: Validation loss decreased (0.503704 --> 0.489244).  Saving model ...
	 Train_Loss: 0.5547 Train_Acc: 73.471 Val_Loss: 0.4892  BEST VAL Loss: 0.4892  Val_Acc: 76.708

Epoch 2: Validation loss decreased (0.489244 --> 0.480509).  Saving model ...
	 Train_Loss: 0.5382 Train_Acc: 74.563 Val_Loss: 0.4805  BEST VAL Loss: 0.4805  Val_Acc: 77.719

Epoch 3: Validation loss decreased (0.480509 --> 0.471484).  Saving model ...
	 Train_Loss: 0.5275 Train_Acc: 75.351 Val_Loss: 0.4715  BEST VAL Loss: 0.4715  Val_Acc: 78.436

Epoch 4: Validation loss decreased (0.471484 --> 0.464849).  Saving model ...
	 Train_Loss: 0.5196 Train_Acc: 75.936 Val_Loss: 0.4648  BEST VAL Loss: 0.4648  Val_Acc: 79.019

Epoch 5: Validation loss decreased (0.464849 --> 0.460488).  Saving model ...
	 Train_Loss: 0.5130 Train_Acc: 76.334 Val_Loss: 0.4605  BEST VAL Loss: 0.4605  Val_Acc: 78.758

Epoch 6: Validation loss decreased (0.460488 --> 0.457287).  Saving model ...
	 Train_Loss: 0.5078 Train_Acc: 76.609 Val_Loss: 0.4573  BEST VAL Loss: 0.4573  Val_Acc: 78.311

Epoch 7: Validation loss decreased (0.457287 --> 0.452857).  Saving model ...
	 Train_Loss: 0.5034 Train_Acc: 76.949 Val_Loss: 0.4529  BEST VAL Loss: 0.4529  Val_Acc: 79.788

Epoch 8: Validation loss decreased (0.452857 --> 0.450018).  Saving model ...
	 Train_Loss: 0.4994 Train_Acc: 77.179 Val_Loss: 0.4500  BEST VAL Loss: 0.4500  Val_Acc: 79.047

Epoch 9: Validation loss decreased (0.450018 --> 0.446893).  Saving model ...
	 Train_Loss: 0.4959 Train_Acc: 77.464 Val_Loss: 0.4469  BEST VAL Loss: 0.4469  Val_Acc: 80.114

Epoch 10: Validation loss decreased (0.446893 --> 0.445073).  Saving model ...
	 Train_Loss: 0.4930 Train_Acc: 77.532 Val_Loss: 0.4451  BEST VAL Loss: 0.4451  Val_Acc: 79.862

Epoch 11: Validation loss decreased (0.445073 --> 0.442557).  Saving model ...
	 Train_Loss: 0.4904 Train_Acc: 77.646 Val_Loss: 0.4426  BEST VAL Loss: 0.4426  Val_Acc: 80.514

Epoch 12: Validation loss decreased (0.442557 --> 0.440318).  Saving model ...
	 Train_Loss: 0.4880 Train_Acc: 77.688 Val_Loss: 0.4403  BEST VAL Loss: 0.4403  Val_Acc: 80.612

Epoch 13: Validation loss decreased (0.440318 --> 0.438308).  Saving model ...
	 Train_Loss: 0.4857 Train_Acc: 77.945 Val_Loss: 0.4383  BEST VAL Loss: 0.4383  Val_Acc: 80.696

Epoch 14: Validation loss decreased (0.438308 --> 0.436758).  Saving model ...
	 Train_Loss: 0.4836 Train_Acc: 78.130 Val_Loss: 0.4368  BEST VAL Loss: 0.4368  Val_Acc: 80.048

Epoch 15: Validation loss decreased (0.436758 --> 0.435246).  Saving model ...
	 Train_Loss: 0.4818 Train_Acc: 78.069 Val_Loss: 0.4352  BEST VAL Loss: 0.4352  Val_Acc: 81.018

Epoch 16: Validation loss decreased (0.435246 --> 0.433528).  Saving model ...
	 Train_Loss: 0.4800 Train_Acc: 78.224 Val_Loss: 0.4335  BEST VAL Loss: 0.4335  Val_Acc: 80.803

Epoch 17: Validation loss decreased (0.433528 --> 0.431949).  Saving model ...
	 Train_Loss: 0.4784 Train_Acc: 78.199 Val_Loss: 0.4319  BEST VAL Loss: 0.4319  Val_Acc: 81.111

Epoch 18: Validation loss decreased (0.431949 --> 0.430760).  Saving model ...
	 Train_Loss: 0.4769 Train_Acc: 78.260 Val_Loss: 0.4308  BEST VAL Loss: 0.4308  Val_Acc: 80.403

Epoch 19: Validation loss decreased (0.430760 --> 0.429316).  Saving model ...
	 Train_Loss: 0.4754 Train_Acc: 78.411 Val_Loss: 0.4293  BEST VAL Loss: 0.4293  Val_Acc: 81.157

Epoch 20: Validation loss decreased (0.429316 --> 0.427886).  Saving model ...
	 Train_Loss: 0.4741 Train_Acc: 78.406 Val_Loss: 0.4279  BEST VAL Loss: 0.4279  Val_Acc: 81.386

Epoch 21: Validation loss decreased (0.427886 --> 0.426590).  Saving model ...
	 Train_Loss: 0.4727 Train_Acc: 78.522 Val_Loss: 0.4266  BEST VAL Loss: 0.4266  Val_Acc: 81.293

Epoch 22: Validation loss decreased (0.426590 --> 0.425349).  Saving model ...
	 Train_Loss: 0.4715 Train_Acc: 78.644 Val_Loss: 0.4253  BEST VAL Loss: 0.4253  Val_Acc: 81.348

Epoch 23: Validation loss decreased (0.425349 --> 0.424060).  Saving model ...
	 Train_Loss: 0.4703 Train_Acc: 78.796 Val_Loss: 0.4241  BEST VAL Loss: 0.4241  Val_Acc: 81.595

Epoch 24: Validation loss decreased (0.424060 --> 0.422941).  Saving model ...
	 Train_Loss: 0.4691 Train_Acc: 78.726 Val_Loss: 0.4229  BEST VAL Loss: 0.4229  Val_Acc: 81.633

Epoch 25: Validation loss decreased (0.422941 --> 0.421892).  Saving model ...
	 Train_Loss: 0.4680 Train_Acc: 78.765 Val_Loss: 0.4219  BEST VAL Loss: 0.4219  Val_Acc: 81.390

Epoch 26: Validation loss decreased (0.421892 --> 0.420955).  Saving model ...
	 Train_Loss: 0.4669 Train_Acc: 78.878 Val_Loss: 0.4210  BEST VAL Loss: 0.4210  Val_Acc: 81.758

Epoch 27: Validation loss decreased (0.420955 --> 0.420181).  Saving model ...
	 Train_Loss: 0.4659 Train_Acc: 78.826 Val_Loss: 0.4202  BEST VAL Loss: 0.4202  Val_Acc: 81.866

Epoch 28: Validation loss decreased (0.420181 --> 0.419081).  Saving model ...
	 Train_Loss: 0.4649 Train_Acc: 78.953 Val_Loss: 0.4191  BEST VAL Loss: 0.4191  Val_Acc: 82.029

Epoch 29: Validation loss decreased (0.419081 --> 0.418222).  Saving model ...
	 Train_Loss: 0.4640 Train_Acc: 78.938 Val_Loss: 0.4182  BEST VAL Loss: 0.4182  Val_Acc: 81.432

Epoch 30: Validation loss decreased (0.418222 --> 0.417263).  Saving model ...
	 Train_Loss: 0.4631 Train_Acc: 79.157 Val_Loss: 0.4173  BEST VAL Loss: 0.4173  Val_Acc: 81.726

Epoch 31: Validation loss decreased (0.417263 --> 0.416425).  Saving model ...
	 Train_Loss: 0.4622 Train_Acc: 79.079 Val_Loss: 0.4164  BEST VAL Loss: 0.4164  Val_Acc: 81.665

Epoch 32: Validation loss decreased (0.416425 --> 0.415543).  Saving model ...
	 Train_Loss: 0.4614 Train_Acc: 79.058 Val_Loss: 0.4155  BEST VAL Loss: 0.4155  Val_Acc: 82.089

Epoch 33: Validation loss decreased (0.415543 --> 0.414761).  Saving model ...
	 Train_Loss: 0.4605 Train_Acc: 79.071 Val_Loss: 0.4148  BEST VAL Loss: 0.4148  Val_Acc: 82.332

Epoch 34: Validation loss decreased (0.414761 --> 0.414054).  Saving model ...
	 Train_Loss: 0.4597 Train_Acc: 79.206 Val_Loss: 0.4141  BEST VAL Loss: 0.4141  Val_Acc: 81.675

Epoch 35: Validation loss decreased (0.414054 --> 0.413388).  Saving model ...
	 Train_Loss: 0.4589 Train_Acc: 79.281 Val_Loss: 0.4134  BEST VAL Loss: 0.4134  Val_Acc: 81.446

Epoch 36: Validation loss decreased (0.413388 --> 0.412624).  Saving model ...
	 Train_Loss: 0.4581 Train_Acc: 79.298 Val_Loss: 0.4126  BEST VAL Loss: 0.4126  Val_Acc: 82.355

Epoch 37: Validation loss decreased (0.412624 --> 0.411908).  Saving model ...
	 Train_Loss: 0.4574 Train_Acc: 79.398 Val_Loss: 0.4119  BEST VAL Loss: 0.4119  Val_Acc: 82.201

Epoch 38: Validation loss decreased (0.411908 --> 0.411275).  Saving model ...
	 Train_Loss: 0.4567 Train_Acc: 79.178 Val_Loss: 0.4113  BEST VAL Loss: 0.4113  Val_Acc: 81.842

Epoch 39: Validation loss decreased (0.411275 --> 0.410654).  Saving model ...
	 Train_Loss: 0.4560 Train_Acc: 79.405 Val_Loss: 0.4107  BEST VAL Loss: 0.4107  Val_Acc: 81.996

Epoch 40: Validation loss decreased (0.410654 --> 0.410023).  Saving model ...
	 Train_Loss: 0.4553 Train_Acc: 79.457 Val_Loss: 0.4100  BEST VAL Loss: 0.4100  Val_Acc: 81.884

Epoch 41: Validation loss decreased (0.410023 --> 0.409362).  Saving model ...
	 Train_Loss: 0.4547 Train_Acc: 79.344 Val_Loss: 0.4094  BEST VAL Loss: 0.4094  Val_Acc: 82.266

Epoch 42: Validation loss decreased (0.409362 --> 0.408674).  Saving model ...
	 Train_Loss: 0.4540 Train_Acc: 79.600 Val_Loss: 0.4087  BEST VAL Loss: 0.4087  Val_Acc: 82.555

Epoch 43: Validation loss decreased (0.408674 --> 0.408074).  Saving model ...
	 Train_Loss: 0.4534 Train_Acc: 79.524 Val_Loss: 0.4081  BEST VAL Loss: 0.4081  Val_Acc: 82.336

Epoch 44: Validation loss decreased (0.408074 --> 0.407519).  Saving model ...
	 Train_Loss: 0.4529 Train_Acc: 79.356 Val_Loss: 0.4075  BEST VAL Loss: 0.4075  Val_Acc: 82.131

Epoch 45: Validation loss decreased (0.407519 --> 0.407140).  Saving model ...
	 Train_Loss: 0.4523 Train_Acc: 79.581 Val_Loss: 0.4071  BEST VAL Loss: 0.4071  Val_Acc: 81.684

Epoch 46: Validation loss decreased (0.407140 --> 0.406676).  Saving model ...
	 Train_Loss: 0.4517 Train_Acc: 79.539 Val_Loss: 0.4067  BEST VAL Loss: 0.4067  Val_Acc: 81.936

Epoch 47: Validation loss decreased (0.406676 --> 0.406217).  Saving model ...
	 Train_Loss: 0.4512 Train_Acc: 79.610 Val_Loss: 0.4062  BEST VAL Loss: 0.4062  Val_Acc: 81.982

Epoch 48: Validation loss decreased (0.406217 --> 0.405633).  Saving model ...
	 Train_Loss: 0.4506 Train_Acc: 79.782 Val_Loss: 0.4056  BEST VAL Loss: 0.4056  Val_Acc: 82.392

Epoch 49: Validation loss decreased (0.405633 --> 0.405073).  Saving model ...
	 Train_Loss: 0.4501 Train_Acc: 79.694 Val_Loss: 0.4051  BEST VAL Loss: 0.4051  Val_Acc: 82.429

Epoch 50: Validation loss decreased (0.405073 --> 0.404692).  Saving model ...
	 Train_Loss: 0.4495 Train_Acc: 79.667 Val_Loss: 0.4047  BEST VAL Loss: 0.4047  Val_Acc: 82.266

Epoch 51: Validation loss decreased (0.404692 --> 0.404271).  Saving model ...
	 Train_Loss: 0.4490 Train_Acc: 79.634 Val_Loss: 0.4043  BEST VAL Loss: 0.4043  Val_Acc: 82.136

Epoch 52: Validation loss decreased (0.404271 --> 0.403839).  Saving model ...
	 Train_Loss: 0.4485 Train_Acc: 79.750 Val_Loss: 0.4038  BEST VAL Loss: 0.4038  Val_Acc: 81.949

Epoch 53: Validation loss decreased (0.403839 --> 0.403367).  Saving model ...
	 Train_Loss: 0.4481 Train_Acc: 79.691 Val_Loss: 0.4034  BEST VAL Loss: 0.4034  Val_Acc: 81.959

Epoch 54: Validation loss decreased (0.403367 --> 0.402924).  Saving model ...
	 Train_Loss: 0.4476 Train_Acc: 79.648 Val_Loss: 0.4029  BEST VAL Loss: 0.4029  Val_Acc: 82.551

Epoch 55: Validation loss decreased (0.402924 --> 0.402437).  Saving model ...
	 Train_Loss: 0.4471 Train_Acc: 79.759 Val_Loss: 0.4024  BEST VAL Loss: 0.4024  Val_Acc: 82.509

Epoch 56: Validation loss decreased (0.402437 --> 0.401910).  Saving model ...
	 Train_Loss: 0.4467 Train_Acc: 79.759 Val_Loss: 0.4019  BEST VAL Loss: 0.4019  Val_Acc: 82.830

Epoch 57: Validation loss decreased (0.401910 --> 0.401455).  Saving model ...
	 Train_Loss: 0.4462 Train_Acc: 79.885 Val_Loss: 0.4015  BEST VAL Loss: 0.4015  Val_Acc: 82.425

Epoch 58: Validation loss decreased (0.401455 --> 0.401011).  Saving model ...
	 Train_Loss: 0.4458 Train_Acc: 79.940 Val_Loss: 0.4010  BEST VAL Loss: 0.4010  Val_Acc: 82.602

Epoch 59: Validation loss decreased (0.401011 --> 0.400624).  Saving model ...
	 Train_Loss: 0.4453 Train_Acc: 79.881 Val_Loss: 0.4006  BEST VAL Loss: 0.4006  Val_Acc: 82.569

Epoch 60: Validation loss decreased (0.400624 --> 0.400217).  Saving model ...
	 Train_Loss: 0.4449 Train_Acc: 79.826 Val_Loss: 0.4002  BEST VAL Loss: 0.4002  Val_Acc: 82.499

Epoch 61: Validation loss decreased (0.400217 --> 0.399733).  Saving model ...
	 Train_Loss: 0.4445 Train_Acc: 79.847 Val_Loss: 0.3997  BEST VAL Loss: 0.3997  Val_Acc: 82.886

Epoch 62: Validation loss decreased (0.399733 --> 0.399354).  Saving model ...
	 Train_Loss: 0.4441 Train_Acc: 80.005 Val_Loss: 0.3994  BEST VAL Loss: 0.3994  Val_Acc: 82.425

Epoch 63: Validation loss decreased (0.399354 --> 0.399016).  Saving model ...
	 Train_Loss: 0.4437 Train_Acc: 79.895 Val_Loss: 0.3990  BEST VAL Loss: 0.3990  Val_Acc: 82.499

Epoch 64: Validation loss decreased (0.399016 --> 0.398636).  Saving model ...
	 Train_Loss: 0.4433 Train_Acc: 79.973 Val_Loss: 0.3986  BEST VAL Loss: 0.3986  Val_Acc: 82.439

Epoch 65: Validation loss decreased (0.398636 --> 0.398281).  Saving model ...
	 Train_Loss: 0.4430 Train_Acc: 79.892 Val_Loss: 0.3983  BEST VAL Loss: 0.3983  Val_Acc: 82.565

Epoch 66: Validation loss decreased (0.398281 --> 0.397894).  Saving model ...
	 Train_Loss: 0.4426 Train_Acc: 79.925 Val_Loss: 0.3979  BEST VAL Loss: 0.3979  Val_Acc: 82.895

Epoch 67: Validation loss decreased (0.397894 --> 0.397553).  Saving model ...
	 Train_Loss: 0.4422 Train_Acc: 80.012 Val_Loss: 0.3976  BEST VAL Loss: 0.3976  Val_Acc: 82.816

Epoch 68: Validation loss decreased (0.397553 --> 0.397172).  Saving model ...
	 Train_Loss: 0.4419 Train_Acc: 79.977 Val_Loss: 0.3972  BEST VAL Loss: 0.3972  Val_Acc: 82.802

Epoch 69: Validation loss decreased (0.397172 --> 0.396827).  Saving model ...
	 Train_Loss: 0.4415 Train_Acc: 80.005 Val_Loss: 0.3968  BEST VAL Loss: 0.3968  Val_Acc: 82.784

Epoch 70: Validation loss decreased (0.396827 --> 0.396523).  Saving model ...
	 Train_Loss: 0.4411 Train_Acc: 79.974 Val_Loss: 0.3965  BEST VAL Loss: 0.3965  Val_Acc: 82.546

Epoch 71: Validation loss decreased (0.396523 --> 0.396190).  Saving model ...
	 Train_Loss: 0.4408 Train_Acc: 80.079 Val_Loss: 0.3962  BEST VAL Loss: 0.3962  Val_Acc: 82.742

Epoch 72: Validation loss decreased (0.396190 --> 0.395856).  Saving model ...
	 Train_Loss: 0.4405 Train_Acc: 79.962 Val_Loss: 0.3959  BEST VAL Loss: 0.3959  Val_Acc: 82.532

Epoch 73: Validation loss decreased (0.395856 --> 0.395578).  Saving model ...
	 Train_Loss: 0.4402 Train_Acc: 79.958 Val_Loss: 0.3956  BEST VAL Loss: 0.3956  Val_Acc: 82.341

Epoch 74: Validation loss decreased (0.395578 --> 0.395289).  Saving model ...
	 Train_Loss: 0.4398 Train_Acc: 80.154 Val_Loss: 0.3953  BEST VAL Loss: 0.3953  Val_Acc: 82.397

Epoch 75: Validation loss decreased (0.395289 --> 0.395053).  Saving model ...
	 Train_Loss: 0.4395 Train_Acc: 80.058 Val_Loss: 0.3951  BEST VAL Loss: 0.3951  Val_Acc: 82.541

Epoch 76: Validation loss decreased (0.395053 --> 0.394794).  Saving model ...
	 Train_Loss: 0.4392 Train_Acc: 80.137 Val_Loss: 0.3948  BEST VAL Loss: 0.3948  Val_Acc: 82.490

Epoch 77: Validation loss decreased (0.394794 --> 0.394522).  Saving model ...
	 Train_Loss: 0.4388 Train_Acc: 80.174 Val_Loss: 0.3945  BEST VAL Loss: 0.3945  Val_Acc: 82.756

Epoch 78: Validation loss decreased (0.394522 --> 0.394208).  Saving model ...
	 Train_Loss: 0.4385 Train_Acc: 80.199 Val_Loss: 0.3942  BEST VAL Loss: 0.3942  Val_Acc: 82.965

Epoch 79: Validation loss decreased (0.394208 --> 0.393876).  Saving model ...
	 Train_Loss: 0.4382 Train_Acc: 80.090 Val_Loss: 0.3939  BEST VAL Loss: 0.3939  Val_Acc: 82.676

Epoch 80: Validation loss decreased (0.393876 --> 0.393668).  Saving model ...
	 Train_Loss: 0.4379 Train_Acc: 80.065 Val_Loss: 0.3937  BEST VAL Loss: 0.3937  Val_Acc: 82.858

Epoch 81: Validation loss decreased (0.393668 --> 0.393379).  Saving model ...
	 Train_Loss: 0.4376 Train_Acc: 80.362 Val_Loss: 0.3934  BEST VAL Loss: 0.3934  Val_Acc: 82.606

Epoch 82: Validation loss decreased (0.393379 --> 0.393069).  Saving model ...
	 Train_Loss: 0.4373 Train_Acc: 80.271 Val_Loss: 0.3931  BEST VAL Loss: 0.3931  Val_Acc: 82.989

Epoch 83: Validation loss decreased (0.393069 --> 0.392832).  Saving model ...
	 Train_Loss: 0.4371 Train_Acc: 80.112 Val_Loss: 0.3928  BEST VAL Loss: 0.3928  Val_Acc: 82.551

Epoch 84: Validation loss decreased (0.392832 --> 0.392587).  Saving model ...
	 Train_Loss: 0.4368 Train_Acc: 80.235 Val_Loss: 0.3926  BEST VAL Loss: 0.3926  Val_Acc: 83.021

Epoch 85: Validation loss decreased (0.392587 --> 0.392315).  Saving model ...
	 Train_Loss: 0.4365 Train_Acc: 80.244 Val_Loss: 0.3923  BEST VAL Loss: 0.3923  Val_Acc: 82.900

Epoch 86: Validation loss decreased (0.392315 --> 0.392070).  Saving model ...
	 Train_Loss: 0.4362 Train_Acc: 80.355 Val_Loss: 0.3921  BEST VAL Loss: 0.3921  Val_Acc: 83.007

Epoch 87: Validation loss decreased (0.392070 --> 0.391787).  Saving model ...
	 Train_Loss: 0.4359 Train_Acc: 80.259 Val_Loss: 0.3918  BEST VAL Loss: 0.3918  Val_Acc: 82.877

Epoch 88: Validation loss decreased (0.391787 --> 0.391561).  Saving model ...
	 Train_Loss: 0.4357 Train_Acc: 80.248 Val_Loss: 0.3916  BEST VAL Loss: 0.3916  Val_Acc: 82.728

Epoch 89: Validation loss decreased (0.391561 --> 0.391322).  Saving model ...
	 Train_Loss: 0.4354 Train_Acc: 80.366 Val_Loss: 0.3913  BEST VAL Loss: 0.3913  Val_Acc: 82.784

Epoch 90: Validation loss decreased (0.391322 --> 0.391070).  Saving model ...
	 Train_Loss: 0.4352 Train_Acc: 80.188 Val_Loss: 0.3911  BEST VAL Loss: 0.3911  Val_Acc: 82.970

Epoch 91: Validation loss decreased (0.391070 --> 0.390829).  Saving model ...
	 Train_Loss: 0.4349 Train_Acc: 80.208 Val_Loss: 0.3908  BEST VAL Loss: 0.3908  Val_Acc: 83.016

Epoch 92: Validation loss decreased (0.390829 --> 0.390641).  Saving model ...
	 Train_Loss: 0.4347 Train_Acc: 80.424 Val_Loss: 0.3906  BEST VAL Loss: 0.3906  Val_Acc: 82.467

Epoch 93: Validation loss decreased (0.390641 --> 0.390454).  Saving model ...
	 Train_Loss: 0.4344 Train_Acc: 80.380 Val_Loss: 0.3905  BEST VAL Loss: 0.3905  Val_Acc: 82.942

Epoch 94: Validation loss decreased (0.390454 --> 0.390193).  Saving model ...
	 Train_Loss: 0.4342 Train_Acc: 80.246 Val_Loss: 0.3902  BEST VAL Loss: 0.3902  Val_Acc: 83.166

Epoch 95: Validation loss decreased (0.390193 --> 0.389994).  Saving model ...
	 Train_Loss: 0.4340 Train_Acc: 80.268 Val_Loss: 0.3900  BEST VAL Loss: 0.3900  Val_Acc: 82.979

Epoch 96: Validation loss decreased (0.389994 --> 0.389802).  Saving model ...
	 Train_Loss: 0.4337 Train_Acc: 80.371 Val_Loss: 0.3898  BEST VAL Loss: 0.3898  Val_Acc: 82.807

Epoch 97: Validation loss decreased (0.389802 --> 0.389529).  Saving model ...
	 Train_Loss: 0.4335 Train_Acc: 80.335 Val_Loss: 0.3895  BEST VAL Loss: 0.3895  Val_Acc: 83.273

Epoch 98: Validation loss decreased (0.389529 --> 0.389318).  Saving model ...
	 Train_Loss: 0.4333 Train_Acc: 80.267 Val_Loss: 0.3893  BEST VAL Loss: 0.3893  Val_Acc: 82.821

Epoch 99: Validation loss decreased (0.389318 --> 0.389146).  Saving model ...
	 Train_Loss: 0.4330 Train_Acc: 80.452 Val_Loss: 0.3891  BEST VAL Loss: 0.3891  Val_Acc: 82.695

LPS_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.41      0.44     79796
           1       0.53      0.59      0.56     91899

    accuracy                           0.51    171695
   macro avg       0.50      0.50      0.50    171695
weighted avg       0.50      0.51      0.50    171695

LPS_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.41      0.44      9975
           1       0.54      0.59      0.56     11487

    accuracy                           0.51     21462
   macro avg       0.50      0.50      0.50     21462
weighted avg       0.50      0.51      0.50     21462

LPS_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.42      0.44      9975
           1       0.54      0.59      0.56     11487

    accuracy                           0.51     21462
   macro avg       0.50      0.50      0.50     21462
weighted avg       0.50      0.51      0.50     21462

              precision    recall  f1-score   support

           0       0.47      0.42      0.44      9975
           1       0.54      0.59      0.56     11487

    accuracy                           0.51     21462
   macro avg       0.50      0.50      0.50     21462
weighted avg       0.50      0.51      0.50     21462

LPS_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.11      0.18     39687
           1       0.51      0.89      0.65     41617

    accuracy                           0.51     81304
   macro avg       0.50      0.50      0.41     81304
weighted avg       0.50      0.51      0.42     81304

              precision    recall  f1-score   support

           0       0.48      0.11      0.18     39687
           1       0.51      0.89      0.65     41617

    accuracy                           0.51     81304
   macro avg       0.50      0.50      0.41     81304
weighted avg       0.50      0.51      0.42     81304

completed
