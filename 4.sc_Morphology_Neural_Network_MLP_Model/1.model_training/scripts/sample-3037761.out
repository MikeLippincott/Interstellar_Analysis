[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'e2e5308d'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '58a1f254'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'eae065ae'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '9d963c6f'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_1.000_DMSO_0.025 treatment_name: DMSO_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_1.000_DMSO_0.025
TREATMENT_NAME: DMSO_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'LPS_1.000_DMSO_0.025']
The dimensions of the data are: (354563, 1270)
Number of total missing values across all columns: 709126
Data Subset Is Off
Wells held out for testing: ['D09' 'J06']
Wells to use for training, validation, and testing ['B06' 'C06' 'B07' 'C07' 'D02' 'D03' 'D08' 'I06' 'I07' 'J07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.396339).  Saving model ...
	 Train_Loss: 0.5203 Train_Acc: 73.714 Val_Loss: 0.3963  BEST VAL Loss: 0.3963  Val_Acc: 83.026

Epoch 1: Validation loss decreased (0.396339 --> 0.378299).  Saving model ...
	 Train_Loss: 0.4749 Train_Acc: 80.627 Val_Loss: 0.3783  BEST VAL Loss: 0.3783  Val_Acc: 84.662

Epoch 2: Validation loss decreased (0.378299 --> 0.364702).  Saving model ...
	 Train_Loss: 0.4522 Train_Acc: 81.957 Val_Loss: 0.3647  BEST VAL Loss: 0.3647  Val_Acc: 86.301

Epoch 3: Validation loss decreased (0.364702 --> 0.356222).  Saving model ...
	 Train_Loss: 0.4372 Train_Acc: 82.844 Val_Loss: 0.3562  BEST VAL Loss: 0.3562  Val_Acc: 86.456

Epoch 4: Validation loss decreased (0.356222 --> 0.349177).  Saving model ...
	 Train_Loss: 0.4265 Train_Acc: 83.405 Val_Loss: 0.3492  BEST VAL Loss: 0.3492  Val_Acc: 87.003

Epoch 5: Validation loss decreased (0.349177 --> 0.345997).  Saving model ...
	 Train_Loss: 0.4184 Train_Acc: 83.756 Val_Loss: 0.3460  BEST VAL Loss: 0.3460  Val_Acc: 86.769

Epoch 6: Validation loss decreased (0.345997 --> 0.342132).  Saving model ...
	 Train_Loss: 0.4119 Train_Acc: 84.018 Val_Loss: 0.3421  BEST VAL Loss: 0.3421  Val_Acc: 87.147

Epoch 7: Validation loss decreased (0.342132 --> 0.338242).  Saving model ...
	 Train_Loss: 0.4064 Train_Acc: 84.251 Val_Loss: 0.3382  BEST VAL Loss: 0.3382  Val_Acc: 87.631

Epoch 8: Validation loss decreased (0.338242 --> 0.335306).  Saving model ...
	 Train_Loss: 0.4016 Train_Acc: 84.470 Val_Loss: 0.3353  BEST VAL Loss: 0.3353  Val_Acc: 87.704

Epoch 9: Validation loss decreased (0.335306 --> 0.333059).  Saving model ...
	 Train_Loss: 0.3979 Train_Acc: 84.551 Val_Loss: 0.3331  BEST VAL Loss: 0.3331  Val_Acc: 88.185

Epoch 10: Validation loss decreased (0.333059 --> 0.330466).  Saving model ...
	 Train_Loss: 0.3945 Train_Acc: 84.775 Val_Loss: 0.3305  BEST VAL Loss: 0.3305  Val_Acc: 88.044

Epoch 11: Validation loss decreased (0.330466 --> 0.328512).  Saving model ...
	 Train_Loss: 0.3915 Train_Acc: 84.827 Val_Loss: 0.3285  BEST VAL Loss: 0.3285  Val_Acc: 88.164

Epoch 12: Validation loss decreased (0.328512 --> 0.326706).  Saving model ...
	 Train_Loss: 0.3887 Train_Acc: 85.024 Val_Loss: 0.3267  BEST VAL Loss: 0.3267  Val_Acc: 88.209

Epoch 13: Validation loss decreased (0.326706 --> 0.325345).  Saving model ...
	 Train_Loss: 0.3863 Train_Acc: 85.065 Val_Loss: 0.3253  BEST VAL Loss: 0.3253  Val_Acc: 88.144

Epoch 14: Validation loss decreased (0.325345 --> 0.323433).  Saving model ...
	 Train_Loss: 0.3840 Train_Acc: 85.171 Val_Loss: 0.3234  BEST VAL Loss: 0.3234  Val_Acc: 88.453

Epoch 15: Validation loss decreased (0.323433 --> 0.322318).  Saving model ...
	 Train_Loss: 0.3820 Train_Acc: 85.128 Val_Loss: 0.3223  BEST VAL Loss: 0.3223  Val_Acc: 88.477

Epoch 16: Validation loss decreased (0.322318 --> 0.320805).  Saving model ...
	 Train_Loss: 0.3800 Train_Acc: 85.400 Val_Loss: 0.3208  BEST VAL Loss: 0.3208  Val_Acc: 88.652

Epoch 17: Validation loss decreased (0.320805 --> 0.320042).  Saving model ...
	 Train_Loss: 0.3783 Train_Acc: 85.369 Val_Loss: 0.3200  BEST VAL Loss: 0.3200  Val_Acc: 88.326

Epoch 18: Validation loss decreased (0.320042 --> 0.318885).  Saving model ...
	 Train_Loss: 0.3765 Train_Acc: 85.480 Val_Loss: 0.3189  BEST VAL Loss: 0.3189  Val_Acc: 88.271

Epoch 19: Validation loss decreased (0.318885 --> 0.317871).  Saving model ...
	 Train_Loss: 0.3750 Train_Acc: 85.429 Val_Loss: 0.3179  BEST VAL Loss: 0.3179  Val_Acc: 88.515

Epoch 20: Validation loss decreased (0.317871 --> 0.317202).  Saving model ...
	 Train_Loss: 0.3736 Train_Acc: 85.596 Val_Loss: 0.3172  BEST VAL Loss: 0.3172  Val_Acc: 88.401

Epoch 21: Validation loss decreased (0.317202 --> 0.316105).  Saving model ...
	 Train_Loss: 0.3722 Train_Acc: 85.582 Val_Loss: 0.3161  BEST VAL Loss: 0.3161  Val_Acc: 88.937

Epoch 22: Validation loss decreased (0.316105 --> 0.315503).  Saving model ...
	 Train_Loss: 0.3710 Train_Acc: 85.653 Val_Loss: 0.3155  BEST VAL Loss: 0.3155  Val_Acc: 88.539

Epoch 23: Validation loss decreased (0.315503 --> 0.314681).  Saving model ...
	 Train_Loss: 0.3698 Train_Acc: 85.625 Val_Loss: 0.3147  BEST VAL Loss: 0.3147  Val_Acc: 88.288

Epoch 24: Validation loss decreased (0.314681 --> 0.313790).  Saving model ...
	 Train_Loss: 0.3687 Train_Acc: 85.746 Val_Loss: 0.3138  BEST VAL Loss: 0.3138  Val_Acc: 88.669

Epoch 25: Validation loss decreased (0.313790 --> 0.313057).  Saving model ...
	 Train_Loss: 0.3676 Train_Acc: 85.813 Val_Loss: 0.3131  BEST VAL Loss: 0.3131  Val_Acc: 88.738

Epoch 26: Validation loss decreased (0.313057 --> 0.312620).  Saving model ...
	 Train_Loss: 0.3666 Train_Acc: 85.834 Val_Loss: 0.3126  BEST VAL Loss: 0.3126  Val_Acc: 88.666

Epoch 27: Validation loss decreased (0.312620 --> 0.312127).  Saving model ...
	 Train_Loss: 0.3657 Train_Acc: 85.727 Val_Loss: 0.3121  BEST VAL Loss: 0.3121  Val_Acc: 88.446

Epoch 28: Validation loss decreased (0.312127 --> 0.311221).  Saving model ...
	 Train_Loss: 0.3647 Train_Acc: 85.898 Val_Loss: 0.3112  BEST VAL Loss: 0.3112  Val_Acc: 89.016

Epoch 29: Validation loss decreased (0.311221 --> 0.310440).  Saving model ...
	 Train_Loss: 0.3638 Train_Acc: 85.875 Val_Loss: 0.3104  BEST VAL Loss: 0.3104  Val_Acc: 88.824

Epoch 30: Validation loss decreased (0.310440 --> 0.309919).  Saving model ...
	 Train_Loss: 0.3630 Train_Acc: 85.947 Val_Loss: 0.3099  BEST VAL Loss: 0.3099  Val_Acc: 88.590

Epoch 31: Validation loss decreased (0.309919 --> 0.309333).  Saving model ...
	 Train_Loss: 0.3622 Train_Acc: 85.937 Val_Loss: 0.3093  BEST VAL Loss: 0.3093  Val_Acc: 88.989

Epoch 32: Validation loss decreased (0.309333 --> 0.308963).  Saving model ...
	 Train_Loss: 0.3614 Train_Acc: 85.949 Val_Loss: 0.3090  BEST VAL Loss: 0.3090  Val_Acc: 88.223

Epoch 33: Validation loss decreased (0.308963 --> 0.308555).  Saving model ...
	 Train_Loss: 0.3606 Train_Acc: 85.979 Val_Loss: 0.3086  BEST VAL Loss: 0.3086  Val_Acc: 88.972

Epoch 34: Validation loss decreased (0.308555 --> 0.308174).  Saving model ...
	 Train_Loss: 0.3598 Train_Acc: 86.239 Val_Loss: 0.3082  BEST VAL Loss: 0.3082  Val_Acc: 88.876

Epoch 35: Validation loss decreased (0.308174 --> 0.307564).  Saving model ...
	 Train_Loss: 0.3591 Train_Acc: 86.043 Val_Loss: 0.3076  BEST VAL Loss: 0.3076  Val_Acc: 89.205

Epoch 36: Validation loss decreased (0.307564 --> 0.307225).  Saving model ...
	 Train_Loss: 0.3585 Train_Acc: 86.029 Val_Loss: 0.3072  BEST VAL Loss: 0.3072  Val_Acc: 88.961

Epoch 37: Validation loss decreased (0.307225 --> 0.306811).  Saving model ...
	 Train_Loss: 0.3579 Train_Acc: 86.180 Val_Loss: 0.3068  BEST VAL Loss: 0.3068  Val_Acc: 89.209

Epoch 38: Validation loss decreased (0.306811 --> 0.306395).  Saving model ...
	 Train_Loss: 0.3572 Train_Acc: 86.202 Val_Loss: 0.3064  BEST VAL Loss: 0.3064  Val_Acc: 89.247

Epoch 39: Validation loss decreased (0.306395 --> 0.305923).  Saving model ...
	 Train_Loss: 0.3566 Train_Acc: 86.212 Val_Loss: 0.3059  BEST VAL Loss: 0.3059  Val_Acc: 89.226

Epoch 40: Validation loss decreased (0.305923 --> 0.305855).  Saving model ...
	 Train_Loss: 0.3560 Train_Acc: 86.359 Val_Loss: 0.3059  BEST VAL Loss: 0.3059  Val_Acc: 87.714

Epoch 41: Validation loss decreased (0.305855 --> 0.305409).  Saving model ...
	 Train_Loss: 0.3554 Train_Acc: 86.238 Val_Loss: 0.3054  BEST VAL Loss: 0.3054  Val_Acc: 89.010

Epoch 42: Validation loss decreased (0.305409 --> 0.305079).  Saving model ...
	 Train_Loss: 0.3549 Train_Acc: 86.304 Val_Loss: 0.3051  BEST VAL Loss: 0.3051  Val_Acc: 88.408

Epoch 43: Validation loss decreased (0.305079 --> 0.304681).  Saving model ...
	 Train_Loss: 0.3543 Train_Acc: 86.282 Val_Loss: 0.3047  BEST VAL Loss: 0.3047  Val_Acc: 88.869

Epoch 44: Validation loss decreased (0.304681 --> 0.304216).  Saving model ...
	 Train_Loss: 0.3538 Train_Acc: 86.347 Val_Loss: 0.3042  BEST VAL Loss: 0.3042  Val_Acc: 89.071

Epoch 45: Validation loss decreased (0.304216 --> 0.304046).  Saving model ...
	 Train_Loss: 0.3533 Train_Acc: 86.336 Val_Loss: 0.3040  BEST VAL Loss: 0.3040  Val_Acc: 88.322

Epoch 46: Validation loss decreased (0.304046 --> 0.303943).  Saving model ...
	 Train_Loss: 0.3528 Train_Acc: 86.280 Val_Loss: 0.3039  BEST VAL Loss: 0.3039  Val_Acc: 89.157

Epoch 47: Validation loss decreased (0.303943 --> 0.303507).  Saving model ...
	 Train_Loss: 0.3524 Train_Acc: 86.279 Val_Loss: 0.3035  BEST VAL Loss: 0.3035  Val_Acc: 89.284

Epoch 48: Validation loss decreased (0.303507 --> 0.303056).  Saving model ...
	 Train_Loss: 0.3519 Train_Acc: 86.430 Val_Loss: 0.3031  BEST VAL Loss: 0.3031  Val_Acc: 89.171

Epoch 49: Validation loss decreased (0.303056 --> 0.302742).  Saving model ...
	 Train_Loss: 0.3515 Train_Acc: 86.378 Val_Loss: 0.3027  BEST VAL Loss: 0.3027  Val_Acc: 89.089

Epoch 50: Validation loss decreased (0.302742 --> 0.302313).  Saving model ...
	 Train_Loss: 0.3510 Train_Acc: 86.459 Val_Loss: 0.3023  BEST VAL Loss: 0.3023  Val_Acc: 89.360

Epoch 51: Validation loss decreased (0.302313 --> 0.302205).  Saving model ...
	 Train_Loss: 0.3505 Train_Acc: 86.499 Val_Loss: 0.3022  BEST VAL Loss: 0.3022  Val_Acc: 88.697

Epoch 52: Validation loss decreased (0.302205 --> 0.301862).  Saving model ...
	 Train_Loss: 0.3501 Train_Acc: 86.450 Val_Loss: 0.3019  BEST VAL Loss: 0.3019  Val_Acc: 89.401

Epoch 53: Validation loss decreased (0.301862 --> 0.301554).  Saving model ...
	 Train_Loss: 0.3497 Train_Acc: 86.501 Val_Loss: 0.3016  BEST VAL Loss: 0.3016  Val_Acc: 89.346

Epoch 54: Validation loss decreased (0.301554 --> 0.301230).  Saving model ...
	 Train_Loss: 0.3493 Train_Acc: 86.468 Val_Loss: 0.3012  BEST VAL Loss: 0.3012  Val_Acc: 89.006

Epoch 55: Validation loss decreased (0.301230 --> 0.300912).  Saving model ...
	 Train_Loss: 0.3489 Train_Acc: 86.398 Val_Loss: 0.3009  BEST VAL Loss: 0.3009  Val_Acc: 89.185

Epoch 56: Validation loss decreased (0.300912 --> 0.300625).  Saving model ...
	 Train_Loss: 0.3486 Train_Acc: 86.435 Val_Loss: 0.3006  BEST VAL Loss: 0.3006  Val_Acc: 89.250

Epoch 57: Validation loss decreased (0.300625 --> 0.300404).  Saving model ...
	 Train_Loss: 0.3482 Train_Acc: 86.580 Val_Loss: 0.3004  BEST VAL Loss: 0.3004  Val_Acc: 88.848

Epoch 58: Validation loss decreased (0.300404 --> 0.300122).  Saving model ...
	 Train_Loss: 0.3478 Train_Acc: 86.497 Val_Loss: 0.3001  BEST VAL Loss: 0.3001  Val_Acc: 89.635

Epoch 59: Validation loss decreased (0.300122 --> 0.299887).  Saving model ...
	 Train_Loss: 0.3474 Train_Acc: 86.411 Val_Loss: 0.2999  BEST VAL Loss: 0.2999  Val_Acc: 89.003

Epoch 60: Validation loss decreased (0.299887 --> 0.299612).  Saving model ...
	 Train_Loss: 0.3471 Train_Acc: 86.461 Val_Loss: 0.2996  BEST VAL Loss: 0.2996  Val_Acc: 89.480

Epoch 61: Validation loss decreased (0.299612 --> 0.299566).  Saving model ...
	 Train_Loss: 0.3468 Train_Acc: 86.568 Val_Loss: 0.2996  BEST VAL Loss: 0.2996  Val_Acc: 89.047

Epoch 62: Validation loss decreased (0.299566 --> 0.299347).  Saving model ...
	 Train_Loss: 0.3465 Train_Acc: 86.538 Val_Loss: 0.2993  BEST VAL Loss: 0.2993  Val_Acc: 89.587

Epoch 63: Validation loss decreased (0.299347 --> 0.299057).  Saving model ...
	 Train_Loss: 0.3461 Train_Acc: 86.621 Val_Loss: 0.2991  BEST VAL Loss: 0.2991  Val_Acc: 89.278

Epoch 64: Validation loss decreased (0.299057 --> 0.298847).  Saving model ...
	 Train_Loss: 0.3458 Train_Acc: 86.534 Val_Loss: 0.2988  BEST VAL Loss: 0.2988  Val_Acc: 89.233

Epoch 65: Validation loss decreased (0.298847 --> 0.298625).  Saving model ...
	 Train_Loss: 0.3455 Train_Acc: 86.559 Val_Loss: 0.2986  BEST VAL Loss: 0.2986  Val_Acc: 89.329

Epoch 66: Validation loss decreased (0.298625 --> 0.298425).  Saving model ...
	 Train_Loss: 0.3452 Train_Acc: 86.713 Val_Loss: 0.2984  BEST VAL Loss: 0.2984  Val_Acc: 89.226

Epoch 67: Validation loss decreased (0.298425 --> 0.298146).  Saving model ...
	 Train_Loss: 0.3448 Train_Acc: 86.638 Val_Loss: 0.2981  BEST VAL Loss: 0.2981  Val_Acc: 89.484

Epoch 68: Validation loss decreased (0.298146 --> 0.297968).  Saving model ...
	 Train_Loss: 0.3445 Train_Acc: 86.664 Val_Loss: 0.2980  BEST VAL Loss: 0.2980  Val_Acc: 89.271

Epoch 69: Validation loss decreased (0.297968 --> 0.297772).  Saving model ...
	 Train_Loss: 0.3442 Train_Acc: 86.737 Val_Loss: 0.2978  BEST VAL Loss: 0.2978  Val_Acc: 89.498

Epoch 70: Validation loss decreased (0.297772 --> 0.297612).  Saving model ...
	 Train_Loss: 0.3439 Train_Acc: 86.638 Val_Loss: 0.2976  BEST VAL Loss: 0.2976  Val_Acc: 89.611

Epoch 71: Validation loss decreased (0.297612 --> 0.297507).  Saving model ...
	 Train_Loss: 0.3436 Train_Acc: 86.712 Val_Loss: 0.2975  BEST VAL Loss: 0.2975  Val_Acc: 89.446

Epoch 72: Validation loss decreased (0.297507 --> 0.297373).  Saving model ...
	 Train_Loss: 0.3433 Train_Acc: 86.719 Val_Loss: 0.2974  BEST VAL Loss: 0.2974  Val_Acc: 89.477

Epoch 73: Validation loss decreased (0.297373 --> 0.297310).  Saving model ...
	 Train_Loss: 0.3431 Train_Acc: 86.661 Val_Loss: 0.2973  BEST VAL Loss: 0.2973  Val_Acc: 88.559

Epoch 74: Validation loss decreased (0.297310 --> 0.297083).  Saving model ...
	 Train_Loss: 0.3428 Train_Acc: 86.692 Val_Loss: 0.2971  BEST VAL Loss: 0.2971  Val_Acc: 89.638

Epoch 75: Validation loss decreased (0.297083 --> 0.296863).  Saving model ...
	 Train_Loss: 0.3425 Train_Acc: 86.760 Val_Loss: 0.2969  BEST VAL Loss: 0.2969  Val_Acc: 89.233

Epoch 76: Validation loss decreased (0.296863 --> 0.296690).  Saving model ...
	 Train_Loss: 0.3423 Train_Acc: 86.654 Val_Loss: 0.2967  BEST VAL Loss: 0.2967  Val_Acc: 89.449

Epoch 77: Validation loss decreased (0.296690 --> 0.296553).  Saving model ...
	 Train_Loss: 0.3420 Train_Acc: 86.779 Val_Loss: 0.2966  BEST VAL Loss: 0.2966  Val_Acc: 89.487

Epoch 78: Validation loss decreased (0.296553 --> 0.296454).  Saving model ...
	 Train_Loss: 0.3418 Train_Acc: 86.744 Val_Loss: 0.2965  BEST VAL Loss: 0.2965  Val_Acc: 89.614

Epoch 79: Validation loss decreased (0.296454 --> 0.296239).  Saving model ...
	 Train_Loss: 0.3415 Train_Acc: 86.933 Val_Loss: 0.2962  BEST VAL Loss: 0.2962  Val_Acc: 89.350

Epoch 80: Validation loss decreased (0.296239 --> 0.296046).  Saving model ...
	 Train_Loss: 0.3412 Train_Acc: 86.825 Val_Loss: 0.2960  BEST VAL Loss: 0.2960  Val_Acc: 89.449

Epoch 81: Validation loss decreased (0.296046 --> 0.295884).  Saving model ...
	 Train_Loss: 0.3410 Train_Acc: 86.774 Val_Loss: 0.2959  BEST VAL Loss: 0.2959  Val_Acc: 89.178

Epoch 82: Validation loss decreased (0.295884 --> 0.295717).  Saving model ...
	 Train_Loss: 0.3408 Train_Acc: 86.734 Val_Loss: 0.2957  BEST VAL Loss: 0.2957  Val_Acc: 89.336

Epoch 83: Validation loss decreased (0.295717 --> 0.295516).  Saving model ...
	 Train_Loss: 0.3405 Train_Acc: 86.816 Val_Loss: 0.2955  BEST VAL Loss: 0.2955  Val_Acc: 89.470

Epoch 84: Validation loss decreased (0.295516 --> 0.295395).  Saving model ...
	 Train_Loss: 0.3403 Train_Acc: 86.910 Val_Loss: 0.2954  BEST VAL Loss: 0.2954  Val_Acc: 89.439

Epoch 85: Validation loss decreased (0.295395 --> 0.295276).  Saving model ...
	 Train_Loss: 0.3401 Train_Acc: 86.829 Val_Loss: 0.2953  BEST VAL Loss: 0.2953  Val_Acc: 89.460

Epoch 86: Validation loss decreased (0.295276 --> 0.295095).  Saving model ...
	 Train_Loss: 0.3398 Train_Acc: 86.799 Val_Loss: 0.2951  BEST VAL Loss: 0.2951  Val_Acc: 89.278

Epoch 87: Validation loss decreased (0.295095 --> 0.295000).  Saving model ...
	 Train_Loss: 0.3396 Train_Acc: 86.870 Val_Loss: 0.2950  BEST VAL Loss: 0.2950  Val_Acc: 89.553

Epoch 88: Validation loss decreased (0.295000 --> 0.294885).  Saving model ...
	 Train_Loss: 0.3394 Train_Acc: 86.839 Val_Loss: 0.2949  BEST VAL Loss: 0.2949  Val_Acc: 89.305

Epoch 89: Validation loss decreased (0.294885 --> 0.294770).  Saving model ...
	 Train_Loss: 0.3392 Train_Acc: 86.711 Val_Loss: 0.2948  BEST VAL Loss: 0.2948  Val_Acc: 88.927

Epoch 90: Validation loss decreased (0.294770 --> 0.294613).  Saving model ...
	 Train_Loss: 0.3390 Train_Acc: 86.817 Val_Loss: 0.2946  BEST VAL Loss: 0.2946  Val_Acc: 89.480

Epoch 91: Validation loss decreased (0.294613 --> 0.294572).  Saving model ...
	 Train_Loss: 0.3388 Train_Acc: 86.838 Val_Loss: 0.2946  BEST VAL Loss: 0.2946  Val_Acc: 89.250

Epoch 92: Validation loss decreased (0.294572 --> 0.294412).  Saving model ...
	 Train_Loss: 0.3386 Train_Acc: 86.846 Val_Loss: 0.2944  BEST VAL Loss: 0.2944  Val_Acc: 89.322

Epoch 93: Validation loss decreased (0.294412 --> 0.294317).  Saving model ...
	 Train_Loss: 0.3384 Train_Acc: 86.831 Val_Loss: 0.2943  BEST VAL Loss: 0.2943  Val_Acc: 89.429

Epoch 94: Validation loss decreased (0.294317 --> 0.294217).  Saving model ...
	 Train_Loss: 0.3382 Train_Acc: 86.903 Val_Loss: 0.2942  BEST VAL Loss: 0.2942  Val_Acc: 89.539

Epoch 95: Validation loss decreased (0.294217 --> 0.294099).  Saving model ...
	 Train_Loss: 0.3380 Train_Acc: 86.867 Val_Loss: 0.2941  BEST VAL Loss: 0.2941  Val_Acc: 89.161

Epoch 96: Validation loss decreased (0.294099 --> 0.293933).  Saving model ...
	 Train_Loss: 0.3378 Train_Acc: 86.953 Val_Loss: 0.2939  BEST VAL Loss: 0.2939  Val_Acc: 89.580

Epoch 97: Validation loss decreased (0.293933 --> 0.293739).  Saving model ...
	 Train_Loss: 0.3376 Train_Acc: 86.880 Val_Loss: 0.2937  BEST VAL Loss: 0.2937  Val_Acc: 89.460

Epoch 98: Validation loss decreased (0.293739 --> 0.293707).  Saving model ...
	 Train_Loss: 0.3374 Train_Acc: 86.945 Val_Loss: 0.2937  BEST VAL Loss: 0.2937  Val_Acc: 89.429

Epoch 99: Validation loss decreased (0.293707 --> 0.293641).  Saving model ...
	 Train_Loss: 0.3373 Train_Acc: 86.912 Val_Loss: 0.2936  BEST VAL Loss: 0.2936  Val_Acc: 89.415

LPS_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.64      0.63      0.64    149884
           1       0.35      0.37      0.36     82898

    accuracy                           0.54    232782
   macro avg       0.50      0.50      0.50    232782
weighted avg       0.54      0.54      0.54    232782

LPS_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.65      0.63      0.64     18736
           1       0.36      0.37      0.36     10362

    accuracy                           0.54     29098
   macro avg       0.50      0.50      0.50     29098
weighted avg       0.54      0.54      0.54     29098

LPS_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.64      0.63      0.64     18736
           1       0.36      0.37      0.36     10362

    accuracy                           0.54     29098
   macro avg       0.50      0.50      0.50     29098
weighted avg       0.54      0.54      0.54     29098

              precision    recall  f1-score   support

           0       0.64      0.63      0.64     18736
           1       0.36      0.37      0.36     10362

    accuracy                           0.54     29098
   macro avg       0.50      0.50      0.50     29098
weighted avg       0.54      0.54      0.54     29098

LPS_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.44      0.79      0.56     27774
           1       0.56      0.21      0.31     35811

    accuracy                           0.46     63585
   macro avg       0.50      0.50      0.43     63585
weighted avg       0.51      0.46      0.42     63585

              precision    recall  f1-score   support

           0       0.44      0.79      0.56     27774
           1       0.56      0.21      0.31     35811

    accuracy                           0.46     63585
   macro avg       0.50      0.50      0.43     63585
weighted avg       0.51      0.46      0.42     63585

completed
