[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b56dfed9'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '7eb206f9'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'a649f606'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '7935589f'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Thapsigargin_1.000_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Thapsigargin_1.000_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (28694, 1276)
Number of total missing values across all columns: 57388
Data Subset Is Off
Wells held out for testing: ['D14' 'L22']
Wells to use for training, validation, and testing ['D15' 'K14' 'K15' 'L18' 'L19' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.662037).  Saving model ...
	 Train_Loss: 0.6371 Train_Acc: 66.243 Val_Loss: 0.6620  BEST VAL Loss: 0.6620  Val_Acc: 61.524

Epoch 1: Validation loss decreased (0.662037 --> 0.597890).  Saving model ...
	 Train_Loss: 0.6117 Train_Acc: 69.813 Val_Loss: 0.5979  BEST VAL Loss: 0.5979  Val_Acc: 74.036

Epoch 2: Validation loss decreased (0.597890 --> 0.561880).  Saving model ...
	 Train_Loss: 0.5852 Train_Acc: 74.659 Val_Loss: 0.5619  BEST VAL Loss: 0.5619  Val_Acc: 77.846

Epoch 3: Validation loss decreased (0.561880 --> 0.532094).  Saving model ...
	 Train_Loss: 0.5601 Train_Acc: 76.217 Val_Loss: 0.5321  BEST VAL Loss: 0.5321  Val_Acc: 78.598

Epoch 4: Validation loss decreased (0.532094 --> 0.512980).  Saving model ...
	 Train_Loss: 0.5425 Train_Acc: 77.582 Val_Loss: 0.5130  BEST VAL Loss: 0.5130  Val_Acc: 78.975

Epoch 5: Validation loss decreased (0.512980 --> 0.500506).  Saving model ...
	 Train_Loss: 0.5275 Train_Acc: 78.711 Val_Loss: 0.5005  BEST VAL Loss: 0.5005  Val_Acc: 79.210

Epoch 6: Validation loss did not decrease
	 Train_Loss: 0.5121 Train_Acc: 79.628 Val_Loss: 0.5030  BEST VAL Loss: 0.5005  Val_Acc: 74.412

Epoch 7: Validation loss decreased (0.500506 --> 0.493537).  Saving model ...
	 Train_Loss: 0.5043 Train_Acc: 78.364 Val_Loss: 0.4935  BEST VAL Loss: 0.4935  Val_Acc: 81.750

Epoch 8: Validation loss decreased (0.493537 --> 0.483534).  Saving model ...
	 Train_Loss: 0.4959 Train_Acc: 79.640 Val_Loss: 0.4835  BEST VAL Loss: 0.4835  Val_Acc: 81.750

Epoch 9: Validation loss decreased (0.483534 --> 0.475130).  Saving model ...
	 Train_Loss: 0.4887 Train_Acc: 81.122 Val_Loss: 0.4751  BEST VAL Loss: 0.4751  Val_Acc: 81.515

Epoch 10: Validation loss decreased (0.475130 --> 0.464638).  Saving model ...
	 Train_Loss: 0.4812 Train_Acc: 80.369 Val_Loss: 0.4646  BEST VAL Loss: 0.4646  Val_Acc: 81.985

Epoch 11: Validation loss decreased (0.464638 --> 0.456555).  Saving model ...
	 Train_Loss: 0.4726 Train_Acc: 82.081 Val_Loss: 0.4566  BEST VAL Loss: 0.4566  Val_Acc: 83.208

Epoch 12: Validation loss decreased (0.456555 --> 0.447999).  Saving model ...
	 Train_Loss: 0.4643 Train_Acc: 82.892 Val_Loss: 0.4480  BEST VAL Loss: 0.4480  Val_Acc: 84.337

Epoch 13: Validation loss decreased (0.447999 --> 0.445714).  Saving model ...
	 Train_Loss: 0.4591 Train_Acc: 83.669 Val_Loss: 0.4457  BEST VAL Loss: 0.4457  Val_Acc: 80.997

Epoch 14: Validation loss decreased (0.445714 --> 0.438948).  Saving model ...
	 Train_Loss: 0.4551 Train_Acc: 81.381 Val_Loss: 0.4389  BEST VAL Loss: 0.4389  Val_Acc: 84.572

Epoch 15: Validation loss decreased (0.438948 --> 0.438727).  Saving model ...
	 Train_Loss: 0.4539 Train_Acc: 83.504 Val_Loss: 0.4387  BEST VAL Loss: 0.4387  Val_Acc: 79.163

Epoch 16: Validation loss decreased (0.438727 --> 0.433594).  Saving model ...
	 Train_Loss: 0.4503 Train_Acc: 81.063 Val_Loss: 0.4336  BEST VAL Loss: 0.4336  Val_Acc: 84.149

Epoch 17: Validation loss decreased (0.433594 --> 0.428380).  Saving model ...
	 Train_Loss: 0.4457 Train_Acc: 83.474 Val_Loss: 0.4284  BEST VAL Loss: 0.4284  Val_Acc: 84.666

Epoch 18: Validation loss decreased (0.428380 --> 0.423233).  Saving model ...
	 Train_Loss: 0.4411 Train_Acc: 84.016 Val_Loss: 0.4232  BEST VAL Loss: 0.4232  Val_Acc: 85.230

Epoch 19: Validation loss decreased (0.423233 --> 0.418092).  Saving model ...
	 Train_Loss: 0.4366 Train_Acc: 84.486 Val_Loss: 0.4181  BEST VAL Loss: 0.4181  Val_Acc: 85.325

Epoch 20: Validation loss decreased (0.418092 --> 0.414168).  Saving model ...
	 Train_Loss: 0.4319 Train_Acc: 84.886 Val_Loss: 0.4142  BEST VAL Loss: 0.4142  Val_Acc: 85.042

Epoch 21: Validation loss decreased (0.414168 --> 0.410149).  Saving model ...
	 Train_Loss: 0.4281 Train_Acc: 85.127 Val_Loss: 0.4101  BEST VAL Loss: 0.4101  Val_Acc: 85.042

Epoch 22: Validation loss did not decrease
	 Train_Loss: 0.4252 Train_Acc: 84.939 Val_Loss: 0.4111  BEST VAL Loss: 0.4101  Val_Acc: 80.056

Epoch 23: Validation loss decreased (0.410149 --> 0.407611).  Saving model ...
	 Train_Loss: 0.4228 Train_Acc: 83.075 Val_Loss: 0.4076  BEST VAL Loss: 0.4076  Val_Acc: 85.701

Epoch 24: Validation loss decreased (0.407611 --> 0.404786).  Saving model ...
	 Train_Loss: 0.4189 Train_Acc: 85.268 Val_Loss: 0.4048  BEST VAL Loss: 0.4048  Val_Acc: 86.171

Epoch 25: Validation loss decreased (0.404786 --> 0.403957).  Saving model ...
	 Train_Loss: 0.4153 Train_Acc: 85.639 Val_Loss: 0.4040  BEST VAL Loss: 0.4040  Val_Acc: 85.654

Epoch 26: Validation loss decreased (0.403957 --> 0.401409).  Saving model ...
	 Train_Loss: 0.4118 Train_Acc: 85.997 Val_Loss: 0.4014  BEST VAL Loss: 0.4014  Val_Acc: 85.983

Epoch 27: Validation loss decreased (0.401409 --> 0.398894).  Saving model ...
	 Train_Loss: 0.4084 Train_Acc: 85.862 Val_Loss: 0.3989  BEST VAL Loss: 0.3989  Val_Acc: 86.030

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.4054 Train_Acc: 86.227 Val_Loss: 0.4015  BEST VAL Loss: 0.3989  Val_Acc: 80.621

Epoch 29: Validation loss did not decrease
	 Train_Loss: 0.4048 Train_Acc: 85.127 Val_Loss: 0.4032  BEST VAL Loss: 0.3989  Val_Acc: 77.940

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.4040 Train_Acc: 81.751 Val_Loss: 0.4013  BEST VAL Loss: 0.3989  Val_Acc: 85.230

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.4026 Train_Acc: 84.227 Val_Loss: 0.3991  BEST VAL Loss: 0.3989  Val_Acc: 84.431

Epoch 32: Validation loss decreased (0.398894 --> 0.395779).  Saving model ...
	 Train_Loss: 0.4002 Train_Acc: 84.898 Val_Loss: 0.3958  BEST VAL Loss: 0.3958  Val_Acc: 86.548

Epoch 33: Validation loss decreased (0.395779 --> 0.393771).  Saving model ...
	 Train_Loss: 0.3984 Train_Acc: 86.039 Val_Loss: 0.3938  BEST VAL Loss: 0.3938  Val_Acc: 85.889

Epoch 34: Validation loss decreased (0.393771 --> 0.391643).  Saving model ...
	 Train_Loss: 0.3968 Train_Acc: 85.533 Val_Loss: 0.3916  BEST VAL Loss: 0.3916  Val_Acc: 85.466

Epoch 35: Validation loss decreased (0.391643 --> 0.388903).  Saving model ...
	 Train_Loss: 0.3946 Train_Acc: 85.686 Val_Loss: 0.3889  BEST VAL Loss: 0.3889  Val_Acc: 86.548

Epoch 36: Validation loss decreased (0.388903 --> 0.386724).  Saving model ...
	 Train_Loss: 0.3923 Train_Acc: 86.121 Val_Loss: 0.3867  BEST VAL Loss: 0.3867  Val_Acc: 86.971

Epoch 37: Validation loss decreased (0.386724 --> 0.385409).  Saving model ...
	 Train_Loss: 0.3903 Train_Acc: 86.480 Val_Loss: 0.3854  BEST VAL Loss: 0.3854  Val_Acc: 85.278

Epoch 38: Validation loss decreased (0.385409 --> 0.383691).  Saving model ...
	 Train_Loss: 0.3880 Train_Acc: 86.386 Val_Loss: 0.3837  BEST VAL Loss: 0.3837  Val_Acc: 86.689

Epoch 39: Validation loss decreased (0.383691 --> 0.382236).  Saving model ...
	 Train_Loss: 0.3856 Train_Acc: 86.744 Val_Loss: 0.3822  BEST VAL Loss: 0.3822  Val_Acc: 86.548

Epoch 40: Validation loss decreased (0.382236 --> 0.380076).  Saving model ...
	 Train_Loss: 0.3836 Train_Acc: 86.868 Val_Loss: 0.3801  BEST VAL Loss: 0.3801  Val_Acc: 87.065

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.3819 Train_Acc: 87.197 Val_Loss: 0.3841  BEST VAL Loss: 0.3801  Val_Acc: 78.222

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.3819 Train_Acc: 84.080 Val_Loss: 0.3826  BEST VAL Loss: 0.3801  Val_Acc: 85.842

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.3807 Train_Acc: 86.497 Val_Loss: 0.3807  BEST VAL Loss: 0.3801  Val_Acc: 86.453

Epoch 44: Validation loss decreased (0.380076 --> 0.378880).  Saving model ...
	 Train_Loss: 0.3792 Train_Acc: 87.015 Val_Loss: 0.3789  BEST VAL Loss: 0.3789  Val_Acc: 86.924

Epoch 45: Validation loss decreased (0.378880 --> 0.378464).  Saving model ...
	 Train_Loss: 0.3785 Train_Acc: 87.244 Val_Loss: 0.3785  BEST VAL Loss: 0.3785  Val_Acc: 82.973

Epoch 46: Validation loss decreased (0.378464 --> 0.376661).  Saving model ...
	 Train_Loss: 0.3779 Train_Acc: 84.574 Val_Loss: 0.3767  BEST VAL Loss: 0.3767  Val_Acc: 86.595

Epoch 47: Validation loss decreased (0.376661 --> 0.375209).  Saving model ...
	 Train_Loss: 0.3763 Train_Acc: 86.156 Val_Loss: 0.3752  BEST VAL Loss: 0.3752  Val_Acc: 86.736

Epoch 48: Validation loss decreased (0.375209 --> 0.373821).  Saving model ...
	 Train_Loss: 0.3750 Train_Acc: 86.833 Val_Loss: 0.3738  BEST VAL Loss: 0.3738  Val_Acc: 87.018

Epoch 49: Validation loss decreased (0.373821 --> 0.372825).  Saving model ...
	 Train_Loss: 0.3732 Train_Acc: 87.626 Val_Loss: 0.3728  BEST VAL Loss: 0.3728  Val_Acc: 86.406

Epoch 50: Validation loss decreased (0.372825 --> 0.371874).  Saving model ...
	 Train_Loss: 0.3713 Train_Acc: 87.362 Val_Loss: 0.3719  BEST VAL Loss: 0.3719  Val_Acc: 87.159

Epoch 51: Validation loss decreased (0.371874 --> 0.370791).  Saving model ...
	 Train_Loss: 0.3699 Train_Acc: 88.062 Val_Loss: 0.3708  BEST VAL Loss: 0.3708  Val_Acc: 86.736

Epoch 52: Validation loss decreased (0.370791 --> 0.369484).  Saving model ...
	 Train_Loss: 0.3683 Train_Acc: 87.421 Val_Loss: 0.3695  BEST VAL Loss: 0.3695  Val_Acc: 86.406

Epoch 53: Validation loss decreased (0.369484 --> 0.367845).  Saving model ...
	 Train_Loss: 0.3667 Train_Acc: 87.626 Val_Loss: 0.3678  BEST VAL Loss: 0.3678  Val_Acc: 87.065

Epoch 54: Validation loss decreased (0.367845 --> 0.366456).  Saving model ...
	 Train_Loss: 0.3651 Train_Acc: 88.550 Val_Loss: 0.3665  BEST VAL Loss: 0.3665  Val_Acc: 86.924

Epoch 55: Validation loss decreased (0.366456 --> 0.364804).  Saving model ...
	 Train_Loss: 0.3633 Train_Acc: 88.132 Val_Loss: 0.3648  BEST VAL Loss: 0.3648  Val_Acc: 87.535

Epoch 56: Validation loss decreased (0.364804 --> 0.364495).  Saving model ...
	 Train_Loss: 0.3617 Train_Acc: 88.579 Val_Loss: 0.3645  BEST VAL Loss: 0.3645  Val_Acc: 85.607

Epoch 57: Validation loss decreased (0.364495 --> 0.362977).  Saving model ...
	 Train_Loss: 0.3602 Train_Acc: 88.273 Val_Loss: 0.3630  BEST VAL Loss: 0.3630  Val_Acc: 87.159

Epoch 58: Validation loss decreased (0.362977 --> 0.362597).  Saving model ...
	 Train_Loss: 0.3587 Train_Acc: 88.173 Val_Loss: 0.3626  BEST VAL Loss: 0.3626  Val_Acc: 86.500

Epoch 59: Validation loss decreased (0.362597 --> 0.361509).  Saving model ...
	 Train_Loss: 0.3575 Train_Acc: 88.226 Val_Loss: 0.3615  BEST VAL Loss: 0.3615  Val_Acc: 85.701

Epoch 60: Validation loss decreased (0.361509 --> 0.360604).  Saving model ...
	 Train_Loss: 0.3563 Train_Acc: 87.885 Val_Loss: 0.3606  BEST VAL Loss: 0.3606  Val_Acc: 86.453

Epoch 61: Validation loss decreased (0.360604 --> 0.359745).  Saving model ...
	 Train_Loss: 0.3554 Train_Acc: 87.944 Val_Loss: 0.3597  BEST VAL Loss: 0.3597  Val_Acc: 86.595

Epoch 62: Validation loss decreased (0.359745 --> 0.358681).  Saving model ...
	 Train_Loss: 0.3540 Train_Acc: 87.938 Val_Loss: 0.3587  BEST VAL Loss: 0.3587  Val_Acc: 87.441

Epoch 63: Validation loss decreased (0.358681 --> 0.357470).  Saving model ...
	 Train_Loss: 0.3526 Train_Acc: 88.385 Val_Loss: 0.3575  BEST VAL Loss: 0.3575  Val_Acc: 87.159

Epoch 64: Validation loss decreased (0.357470 --> 0.356662).  Saving model ...
	 Train_Loss: 0.3514 Train_Acc: 88.491 Val_Loss: 0.3567  BEST VAL Loss: 0.3567  Val_Acc: 86.877

Epoch 65: Validation loss decreased (0.356662 --> 0.356022).  Saving model ...
	 Train_Loss: 0.3501 Train_Acc: 87.909 Val_Loss: 0.3560  BEST VAL Loss: 0.3560  Val_Acc: 86.124

Epoch 66: Validation loss decreased (0.356022 --> 0.354786).  Saving model ...
	 Train_Loss: 0.3488 Train_Acc: 88.338 Val_Loss: 0.3548  BEST VAL Loss: 0.3548  Val_Acc: 87.865

Epoch 67: Validation loss decreased (0.354786 --> 0.354025).  Saving model ...
	 Train_Loss: 0.3474 Train_Acc: 88.914 Val_Loss: 0.3540  BEST VAL Loss: 0.3540  Val_Acc: 87.959

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.3463 Train_Acc: 89.120 Val_Loss: 0.3542  BEST VAL Loss: 0.3540  Val_Acc: 85.795

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.3455 Train_Acc: 87.532 Val_Loss: 0.3553  BEST VAL Loss: 0.3540  Val_Acc: 83.678

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.3446 Train_Acc: 87.891 Val_Loss: 0.3542  BEST VAL Loss: 0.3540  Val_Acc: 88.241

Epoch 71: Validation loss decreased (0.354025 --> 0.353438).  Saving model ...
	 Train_Loss: 0.3434 Train_Acc: 88.620 Val_Loss: 0.3534  BEST VAL Loss: 0.3534  Val_Acc: 87.676

Epoch 72: Validation loss decreased (0.353438 --> 0.352588).  Saving model ...
	 Train_Loss: 0.3421 Train_Acc: 88.820 Val_Loss: 0.3526  BEST VAL Loss: 0.3526  Val_Acc: 88.476

Epoch 73: Validation loss decreased (0.352588 --> 0.351681).  Saving model ...
	 Train_Loss: 0.3409 Train_Acc: 89.479 Val_Loss: 0.3517  BEST VAL Loss: 0.3517  Val_Acc: 87.676

Epoch 74: Validation loss decreased (0.351681 --> 0.350635).  Saving model ...
	 Train_Loss: 0.3396 Train_Acc: 89.250 Val_Loss: 0.3506  BEST VAL Loss: 0.3506  Val_Acc: 88.006

Epoch 75: Validation loss decreased (0.350635 --> 0.349706).  Saving model ...
	 Train_Loss: 0.3385 Train_Acc: 89.544 Val_Loss: 0.3497  BEST VAL Loss: 0.3497  Val_Acc: 88.664

Epoch 76: Validation loss decreased (0.349706 --> 0.348430).  Saving model ...
	 Train_Loss: 0.3372 Train_Acc: 89.720 Val_Loss: 0.3484  BEST VAL Loss: 0.3484  Val_Acc: 88.476

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.3360 Train_Acc: 89.979 Val_Loss: 0.3486  BEST VAL Loss: 0.3484  Val_Acc: 83.208

Epoch 78: Validation loss decreased (0.348430 --> 0.347934).  Saving model ...
	 Train_Loss: 0.3352 Train_Acc: 88.991 Val_Loss: 0.3479  BEST VAL Loss: 0.3479  Val_Acc: 87.488

Epoch 79: Validation loss decreased (0.347934 --> 0.346597).  Saving model ...
	 Train_Loss: 0.3341 Train_Acc: 89.020 Val_Loss: 0.3466  BEST VAL Loss: 0.3466  Val_Acc: 88.758

Epoch 80: Validation loss decreased (0.346597 --> 0.345679).  Saving model ...
	 Train_Loss: 0.3328 Train_Acc: 89.597 Val_Loss: 0.3457  BEST VAL Loss: 0.3457  Val_Acc: 88.241

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.3320 Train_Acc: 89.908 Val_Loss: 0.3459  BEST VAL Loss: 0.3457  Val_Acc: 86.265

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.3314 Train_Acc: 89.073 Val_Loss: 0.3461  BEST VAL Loss: 0.3457  Val_Acc: 83.725

Epoch 83: Validation loss decreased (0.345679 --> 0.345433).  Saving model ...
	 Train_Loss: 0.3308 Train_Acc: 87.509 Val_Loss: 0.3454  BEST VAL Loss: 0.3454  Val_Acc: 88.006

Epoch 84: Validation loss decreased (0.345433 --> 0.344637).  Saving model ...
	 Train_Loss: 0.3299 Train_Acc: 88.856 Val_Loss: 0.3446  BEST VAL Loss: 0.3446  Val_Acc: 88.617

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.3292 Train_Acc: 89.508 Val_Loss: 0.3472  BEST VAL Loss: 0.3446  Val_Acc: 82.738

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.3289 Train_Acc: 86.191 Val_Loss: 0.3468  BEST VAL Loss: 0.3446  Val_Acc: 88.100

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.3283 Train_Acc: 88.250 Val_Loss: 0.3457  BEST VAL Loss: 0.3446  Val_Acc: 89.229

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.3275 Train_Acc: 89.126 Val_Loss: 0.3449  BEST VAL Loss: 0.3446  Val_Acc: 86.453

Epoch 89: Validation loss decreased (0.344637 --> 0.344367).  Saving model ...
	 Train_Loss: 0.3268 Train_Acc: 88.144 Val_Loss: 0.3444  BEST VAL Loss: 0.3444  Val_Acc: 87.959

Epoch 90: Validation loss decreased (0.344367 --> 0.343544).  Saving model ...
	 Train_Loss: 0.3260 Train_Acc: 89.544 Val_Loss: 0.3435  BEST VAL Loss: 0.3435  Val_Acc: 88.335

Epoch 91: Validation loss decreased (0.343544 --> 0.342947).  Saving model ...
	 Train_Loss: 0.3250 Train_Acc: 89.679 Val_Loss: 0.3429  BEST VAL Loss: 0.3429  Val_Acc: 88.429

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.3241 Train_Acc: 90.114 Val_Loss: 0.3435  BEST VAL Loss: 0.3429  Val_Acc: 84.008

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.3238 Train_Acc: 86.985 Val_Loss: 0.3432  BEST VAL Loss: 0.3429  Val_Acc: 87.912

Epoch 94: Validation loss decreased (0.342947 --> 0.342532).  Saving model ...
	 Train_Loss: 0.3231 Train_Acc: 88.367 Val_Loss: 0.3425  BEST VAL Loss: 0.3425  Val_Acc: 89.040

Epoch 95: Validation loss decreased (0.342532 --> 0.342108).  Saving model ...
	 Train_Loss: 0.3223 Train_Acc: 89.091 Val_Loss: 0.3421  BEST VAL Loss: 0.3421  Val_Acc: 87.206

Epoch 96: Validation loss decreased (0.342108 --> 0.341685).  Saving model ...
	 Train_Loss: 0.3215 Train_Acc: 89.161 Val_Loss: 0.3417  BEST VAL Loss: 0.3417  Val_Acc: 89.229

Epoch 97: Validation loss decreased (0.341685 --> 0.340771).  Saving model ...
	 Train_Loss: 0.3206 Train_Acc: 89.755 Val_Loss: 0.3408  BEST VAL Loss: 0.3408  Val_Acc: 88.805

Epoch 98: Validation loss decreased (0.340771 --> 0.339852).  Saving model ...
	 Train_Loss: 0.3196 Train_Acc: 90.073 Val_Loss: 0.3399  BEST VAL Loss: 0.3399  Val_Acc: 88.664

Epoch 99: Validation loss decreased (0.339852 --> 0.338932).  Saving model ...
	 Train_Loss: 0.3186 Train_Acc: 90.155 Val_Loss: 0.3389  BEST VAL Loss: 0.3389  Val_Acc: 88.805

Thapsigargin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.52      0.51      8634
           1       0.50      0.50      0.50      8370

    accuracy                           0.51     17004
   macro avg       0.51      0.51      0.51     17004
weighted avg       0.51      0.51      0.51     17004

Thapsigargin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.51      0.51      1080
           1       0.49      0.49      0.49      1046

    accuracy                           0.50      2126
   macro avg       0.50      0.50      0.50      2126
weighted avg       0.50      0.50      0.50      2126

Thapsigargin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.50      0.49      1079
           1       0.48      0.47      0.47      1047

    accuracy                           0.48      2126
   macro avg       0.48      0.48      0.48      2126
weighted avg       0.48      0.48      0.48      2126

              precision    recall  f1-score   support

           0       0.49      0.50      0.49      1079
           1       0.48      0.47      0.47      1047

    accuracy                           0.48      2126
   macro avg       0.48      0.48      0.48      2126
weighted avg       0.48      0.48      0.48      2126

Thapsigargin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.56      0.54      0.55      4135
           1       0.44      0.46      0.45      3303

    accuracy                           0.50      7438
   macro avg       0.50      0.50      0.50      7438
weighted avg       0.51      0.50      0.51      7438

              precision    recall  f1-score   support

           0       0.56      0.54      0.55      4135
           1       0.44      0.46      0.45      3303

    accuracy                           0.50      7438
   macro avg       0.50      0.50      0.50      7438
weighted avg       0.51      0.50      0.51      7438

completed
