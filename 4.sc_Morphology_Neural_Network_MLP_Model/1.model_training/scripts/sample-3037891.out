[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'f4bba024'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '58bc422d'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '23e364b0'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '509d7330'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
TREATMENT_NAME: Flagellin_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_Nigericin_1.000_10.0_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (30211, 1276)
Number of total missing values across all columns: 31618
Data Subset Is Off
Wells held out for testing: ['M16' 'M22']
Wells to use for training, validation, and testing ['M17' 'M18' 'M19' 'M20' 'M21' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.396792).  Saving model ...
	 Train_Loss: 0.5891 Train_Acc: 68.657 Val_Loss: 0.3968  BEST VAL Loss: 0.3968  Val_Acc: 87.825

Epoch 1: Validation loss decreased (0.396792 --> 0.333557).  Saving model ...
	 Train_Loss: 0.5041 Train_Acc: 81.455 Val_Loss: 0.3336  BEST VAL Loss: 0.3336  Val_Acc: 90.645

Epoch 2: Validation loss decreased (0.333557 --> 0.323573).  Saving model ...
	 Train_Loss: 0.4543 Train_Acc: 85.154 Val_Loss: 0.3236  BEST VAL Loss: 0.3236  Val_Acc: 91.137

Epoch 3: Validation loss decreased (0.323573 --> 0.293885).  Saving model ...
	 Train_Loss: 0.4194 Train_Acc: 87.364 Val_Loss: 0.2939  BEST VAL Loss: 0.2939  Val_Acc: 92.346

Epoch 4: Validation loss decreased (0.293885 --> 0.277338).  Saving model ...
	 Train_Loss: 0.3938 Train_Acc: 88.383 Val_Loss: 0.2773  BEST VAL Loss: 0.2773  Val_Acc: 92.838

Epoch 5: Validation loss decreased (0.277338 --> 0.258186).  Saving model ...
	 Train_Loss: 0.3736 Train_Acc: 89.261 Val_Loss: 0.2582  BEST VAL Loss: 0.2582  Val_Acc: 94.181

Epoch 6: Validation loss decreased (0.258186 --> 0.245972).  Saving model ...
	 Train_Loss: 0.3573 Train_Acc: 89.922 Val_Loss: 0.2460  BEST VAL Loss: 0.2460  Val_Acc: 94.449

Epoch 7: Validation loss decreased (0.245972 --> 0.231948).  Saving model ...
	 Train_Loss: 0.3442 Train_Acc: 90.056 Val_Loss: 0.2319  BEST VAL Loss: 0.2319  Val_Acc: 95.210

Epoch 8: Validation loss decreased (0.231948 --> 0.224979).  Saving model ...
	 Train_Loss: 0.3335 Train_Acc: 90.123 Val_Loss: 0.2250  BEST VAL Loss: 0.2250  Val_Acc: 93.688

Epoch 9: Validation loss decreased (0.224979 --> 0.217043).  Saving model ...
	 Train_Loss: 0.3242 Train_Acc: 90.616 Val_Loss: 0.2170  BEST VAL Loss: 0.2170  Val_Acc: 95.792

Epoch 10: Validation loss decreased (0.217043 --> 0.212077).  Saving model ...
	 Train_Loss: 0.3165 Train_Acc: 90.616 Val_Loss: 0.2121  BEST VAL Loss: 0.2121  Val_Acc: 93.733

Epoch 11: Validation loss decreased (0.212077 --> 0.206853).  Saving model ...
	 Train_Loss: 0.3110 Train_Acc: 90.436 Val_Loss: 0.2069  BEST VAL Loss: 0.2069  Val_Acc: 95.389

Epoch 12: Validation loss decreased (0.206853 --> 0.201002).  Saving model ...
	 Train_Loss: 0.3049 Train_Acc: 90.996 Val_Loss: 0.2010  BEST VAL Loss: 0.2010  Val_Acc: 95.389

Epoch 13: Validation loss decreased (0.201002 --> 0.196709).  Saving model ...
	 Train_Loss: 0.2991 Train_Acc: 91.119 Val_Loss: 0.1967  BEST VAL Loss: 0.1967  Val_Acc: 94.763

Epoch 14: Validation loss decreased (0.196709 --> 0.192693).  Saving model ...
	 Train_Loss: 0.2936 Train_Acc: 91.522 Val_Loss: 0.1927  BEST VAL Loss: 0.1927  Val_Acc: 94.718

Epoch 15: Validation loss decreased (0.192693 --> 0.189891).  Saving model ...
	 Train_Loss: 0.2886 Train_Acc: 91.343 Val_Loss: 0.1899  BEST VAL Loss: 0.1899  Val_Acc: 94.360

Epoch 16: Validation loss decreased (0.189891 --> 0.186653).  Saving model ...
	 Train_Loss: 0.2845 Train_Acc: 91.349 Val_Loss: 0.1867  BEST VAL Loss: 0.1867  Val_Acc: 95.613

Epoch 17: Validation loss decreased (0.186653 --> 0.183609).  Saving model ...
	 Train_Loss: 0.2807 Train_Acc: 91.382 Val_Loss: 0.1836  BEST VAL Loss: 0.1836  Val_Acc: 95.658

Epoch 18: Validation loss decreased (0.183609 --> 0.180547).  Saving model ...
	 Train_Loss: 0.2770 Train_Acc: 91.427 Val_Loss: 0.1805  BEST VAL Loss: 0.1805  Val_Acc: 95.210

Epoch 19: Validation loss decreased (0.180547 --> 0.177507).  Saving model ...
	 Train_Loss: 0.2736 Train_Acc: 91.656 Val_Loss: 0.1775  BEST VAL Loss: 0.1775  Val_Acc: 95.524

Epoch 20: Validation loss decreased (0.177507 --> 0.174842).  Saving model ...
	 Train_Loss: 0.2702 Train_Acc: 91.757 Val_Loss: 0.1748  BEST VAL Loss: 0.1748  Val_Acc: 95.703

Epoch 21: Validation loss decreased (0.174842 --> 0.172270).  Saving model ...
	 Train_Loss: 0.2671 Train_Acc: 91.964 Val_Loss: 0.1723  BEST VAL Loss: 0.1723  Val_Acc: 95.434

Epoch 22: Validation loss decreased (0.172270 --> 0.170669).  Saving model ...
	 Train_Loss: 0.2641 Train_Acc: 91.987 Val_Loss: 0.1707  BEST VAL Loss: 0.1707  Val_Acc: 94.449

Epoch 23: Validation loss decreased (0.170669 --> 0.169041).  Saving model ...
	 Train_Loss: 0.2614 Train_Acc: 91.791 Val_Loss: 0.1690  BEST VAL Loss: 0.1690  Val_Acc: 94.897

Epoch 24: Validation loss decreased (0.169041 --> 0.167355).  Saving model ...
	 Train_Loss: 0.2588 Train_Acc: 91.936 Val_Loss: 0.1674  BEST VAL Loss: 0.1674  Val_Acc: 95.389

Epoch 25: Validation loss decreased (0.167355 --> 0.165859).  Saving model ...
	 Train_Loss: 0.2567 Train_Acc: 91.802 Val_Loss: 0.1659  BEST VAL Loss: 0.1659  Val_Acc: 94.584

Epoch 26: Validation loss decreased (0.165859 --> 0.164205).  Saving model ...
	 Train_Loss: 0.2549 Train_Acc: 91.561 Val_Loss: 0.1642  BEST VAL Loss: 0.1642  Val_Acc: 95.345

Epoch 27: Validation loss decreased (0.164205 --> 0.163450).  Saving model ...
	 Train_Loss: 0.2528 Train_Acc: 91.942 Val_Loss: 0.1635  BEST VAL Loss: 0.1635  Val_Acc: 95.613

Epoch 28: Validation loss decreased (0.163450 --> 0.162035).  Saving model ...
	 Train_Loss: 0.2509 Train_Acc: 92.238 Val_Loss: 0.1620  BEST VAL Loss: 0.1620  Val_Acc: 96.195

Epoch 29: Validation loss decreased (0.162035 --> 0.160980).  Saving model ...
	 Train_Loss: 0.2490 Train_Acc: 92.071 Val_Loss: 0.1610  BEST VAL Loss: 0.1610  Val_Acc: 95.703

Epoch 30: Validation loss decreased (0.160980 --> 0.159865).  Saving model ...
	 Train_Loss: 0.2472 Train_Acc: 92.613 Val_Loss: 0.1599  BEST VAL Loss: 0.1599  Val_Acc: 96.106

Epoch 31: Validation loss decreased (0.159865 --> 0.159172).  Saving model ...
	 Train_Loss: 0.2452 Train_Acc: 92.804 Val_Loss: 0.1592  BEST VAL Loss: 0.1592  Val_Acc: 95.389

Epoch 32: Validation loss decreased (0.159172 --> 0.157902).  Saving model ...
	 Train_Loss: 0.2434 Train_Acc: 92.423 Val_Loss: 0.1579  BEST VAL Loss: 0.1579  Val_Acc: 95.434

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.2419 Train_Acc: 92.535 Val_Loss: 0.1580  BEST VAL Loss: 0.1579  Val_Acc: 95.121

Epoch 34: Validation loss decreased (0.157902 --> 0.157085).  Saving model ...
	 Train_Loss: 0.2406 Train_Acc: 92.132 Val_Loss: 0.1571  BEST VAL Loss: 0.1571  Val_Acc: 95.837

Epoch 35: Validation loss decreased (0.157085 --> 0.156493).  Saving model ...
	 Train_Loss: 0.2392 Train_Acc: 92.485 Val_Loss: 0.1565  BEST VAL Loss: 0.1565  Val_Acc: 96.061

Epoch 36: Validation loss decreased (0.156493 --> 0.156392).  Saving model ...
	 Train_Loss: 0.2376 Train_Acc: 92.675 Val_Loss: 0.1564  BEST VAL Loss: 0.1564  Val_Acc: 96.195

Epoch 37: Validation loss decreased (0.156392 --> 0.155187).  Saving model ...
	 Train_Loss: 0.2360 Train_Acc: 93.246 Val_Loss: 0.1552  BEST VAL Loss: 0.1552  Val_Acc: 96.195

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.2343 Train_Acc: 93.173 Val_Loss: 0.1554  BEST VAL Loss: 0.1552  Val_Acc: 95.210

Epoch 39: Validation loss decreased (0.155187 --> 0.154854).  Saving model ...
	 Train_Loss: 0.2329 Train_Acc: 92.647 Val_Loss: 0.1549  BEST VAL Loss: 0.1549  Val_Acc: 95.837

Epoch 40: Validation loss decreased (0.154854 --> 0.154209).  Saving model ...
	 Train_Loss: 0.2314 Train_Acc: 92.927 Val_Loss: 0.1542  BEST VAL Loss: 0.1542  Val_Acc: 96.240

Epoch 41: Validation loss decreased (0.154209 --> 0.154182).  Saving model ...
	 Train_Loss: 0.2302 Train_Acc: 92.557 Val_Loss: 0.1542  BEST VAL Loss: 0.1542  Val_Acc: 95.613

Epoch 42: Validation loss decreased (0.154182 --> 0.153328).  Saving model ...
	 Train_Loss: 0.2290 Train_Acc: 92.669 Val_Loss: 0.1533  BEST VAL Loss: 0.1533  Val_Acc: 95.166

Epoch 43: Validation loss decreased (0.153328 --> 0.152749).  Saving model ...
	 Train_Loss: 0.2278 Train_Acc: 93.229 Val_Loss: 0.1527  BEST VAL Loss: 0.1527  Val_Acc: 95.792

Epoch 44: Validation loss decreased (0.152749 --> 0.152018).  Saving model ...
	 Train_Loss: 0.2265 Train_Acc: 93.162 Val_Loss: 0.1520  BEST VAL Loss: 0.1520  Val_Acc: 95.434

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.2254 Train_Acc: 92.798 Val_Loss: 0.1520  BEST VAL Loss: 0.1520  Val_Acc: 96.061

Epoch 46: Validation loss decreased (0.152018 --> 0.151467).  Saving model ...
	 Train_Loss: 0.2242 Train_Acc: 92.988 Val_Loss: 0.1515  BEST VAL Loss: 0.1515  Val_Acc: 95.613

Epoch 47: Validation loss decreased (0.151467 --> 0.151107).  Saving model ...
	 Train_Loss: 0.2231 Train_Acc: 92.955 Val_Loss: 0.1511  BEST VAL Loss: 0.1511  Val_Acc: 96.016

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.2220 Train_Acc: 93.330 Val_Loss: 0.1512  BEST VAL Loss: 0.1511  Val_Acc: 96.061

Epoch 49: Validation loss decreased (0.151107 --> 0.150923).  Saving model ...
	 Train_Loss: 0.2212 Train_Acc: 92.977 Val_Loss: 0.1509  BEST VAL Loss: 0.1509  Val_Acc: 95.613

Epoch 50: Validation loss decreased (0.150923 --> 0.150708).  Saving model ...
	 Train_Loss: 0.2206 Train_Acc: 92.899 Val_Loss: 0.1507  BEST VAL Loss: 0.1507  Val_Acc: 95.389

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.2198 Train_Acc: 93.106 Val_Loss: 0.1508  BEST VAL Loss: 0.1507  Val_Acc: 96.419

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.2191 Train_Acc: 92.569 Val_Loss: 0.1510  BEST VAL Loss: 0.1507  Val_Acc: 93.688

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.2185 Train_Acc: 92.222 Val_Loss: 0.1513  BEST VAL Loss: 0.1507  Val_Acc: 96.195

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.2175 Train_Acc: 93.324 Val_Loss: 0.1520  BEST VAL Loss: 0.1507  Val_Acc: 95.792

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.2167 Train_Acc: 93.039 Val_Loss: 0.1525  BEST VAL Loss: 0.1507  Val_Acc: 95.210

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.2160 Train_Acc: 92.910 Val_Loss: 0.1519  BEST VAL Loss: 0.1507  Val_Acc: 96.106

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.2151 Train_Acc: 93.167 Val_Loss: 0.1519  BEST VAL Loss: 0.1507  Val_Acc: 96.106

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.2141 Train_Acc: 93.643 Val_Loss: 0.1520  BEST VAL Loss: 0.1507  Val_Acc: 96.598

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.2133 Train_Acc: 93.453 Val_Loss: 0.1514  BEST VAL Loss: 0.1507  Val_Acc: 95.837

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.2124 Train_Acc: 93.425 Val_Loss: 0.1508  BEST VAL Loss: 0.1507  Val_Acc: 96.553

Epoch 61: Validation loss decreased (0.150708 --> 0.150547).  Saving model ...
	 Train_Loss: 0.2116 Train_Acc: 93.447 Val_Loss: 0.1505  BEST VAL Loss: 0.1505  Val_Acc: 96.106

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.2107 Train_Acc: 93.481 Val_Loss: 0.1507  BEST VAL Loss: 0.1505  Val_Acc: 95.971

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.2100 Train_Acc: 93.268 Val_Loss: 0.1506  BEST VAL Loss: 0.1505  Val_Acc: 96.195

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.2093 Train_Acc: 93.212 Val_Loss: 0.1506  BEST VAL Loss: 0.1505  Val_Acc: 95.837

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.2086 Train_Acc: 93.128 Val_Loss: 0.1511  BEST VAL Loss: 0.1505  Val_Acc: 95.971

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.2079 Train_Acc: 93.766 Val_Loss: 0.1509  BEST VAL Loss: 0.1505  Val_Acc: 96.195

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.2072 Train_Acc: 93.374 Val_Loss: 0.1518  BEST VAL Loss: 0.1505  Val_Acc: 96.240

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.2066 Train_Acc: 93.139 Val_Loss: 0.1518  BEST VAL Loss: 0.1505  Val_Acc: 96.106

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.2061 Train_Acc: 92.798 Val_Loss: 0.1527  BEST VAL Loss: 0.1505  Val_Acc: 96.329

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.2057 Train_Acc: 92.664 Val_Loss: 0.1526  BEST VAL Loss: 0.1505  Val_Acc: 96.240

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.2052 Train_Acc: 93.313 Val_Loss: 0.1521  BEST VAL Loss: 0.1505  Val_Acc: 96.867

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.2045 Train_Acc: 93.302 Val_Loss: 0.1519  BEST VAL Loss: 0.1505  Val_Acc: 96.240

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.2039 Train_Acc: 93.419 Val_Loss: 0.1516  BEST VAL Loss: 0.1505  Val_Acc: 95.882

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.2032 Train_Acc: 93.621 Val_Loss: 0.1524  BEST VAL Loss: 0.1505  Val_Acc: 96.329

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.2025 Train_Acc: 93.699 Val_Loss: 0.1525  BEST VAL Loss: 0.1505  Val_Acc: 96.285

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.2018 Train_Acc: 93.503 Val_Loss: 0.1521  BEST VAL Loss: 0.1505  Val_Acc: 96.374

Epoch 77: Validation loss did not decrease
Early stopped at epoch : 77
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.54      0.53      9434
           1       0.47      0.46      0.46      8436

    accuracy                           0.50     17870
   macro avg       0.50      0.50      0.50     17870
weighted avg       0.50      0.50      0.50     17870

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.54      0.53      1179
           1       0.46      0.45      0.46      1055

    accuracy                           0.49      2234
   macro avg       0.49      0.49      0.49      2234
weighted avg       0.49      0.49      0.49      2234

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.57      0.56      1179
           1       0.50      0.48      0.49      1055

    accuracy                           0.52      2234
   macro avg       0.52      0.52      0.52      2234
weighted avg       0.52      0.52      0.52      2234

              precision    recall  f1-score   support

           0       0.55      0.57      0.56      1179
           1       0.50      0.48      0.49      1055

    accuracy                           0.52      2234
   macro avg       0.52      0.52      0.52      2234
weighted avg       0.52      0.52      0.52      2234

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.51      0.51      4017
           1       0.48      0.47      0.48      3856

    accuracy                           0.49      7873
   macro avg       0.49      0.49      0.49      7873
weighted avg       0.49      0.49      0.49      7873

              precision    recall  f1-score   support

           0       0.50      0.51      0.51      4017
           1       0.48      0.47      0.48      3856

    accuracy                           0.49      7873
   macro avg       0.49      0.49      0.49      7873
weighted avg       0.49      0.49      0.49      7873

completed
