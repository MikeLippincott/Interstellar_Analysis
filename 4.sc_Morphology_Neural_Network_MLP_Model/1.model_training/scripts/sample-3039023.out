[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '2a6aaccb'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '04c67b8d'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '5730ac99'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '380d6446'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_0.010_DMSO_0.025 treatment_name: LPS_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_0.010_DMSO_0.025
TREATMENT_NAME: LPS_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_1.000_DMSO_0.025']
The dimensions of the data are: (32317, 1276)
Number of total missing values across all columns: 64634
Data Subset Is Off
Wells held out for testing: ['B20' 'D21']
Wells to use for training, validation, and testing ['B16' 'D16' 'B17' 'D17' 'D20' 'B21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.617823).  Saving model ...
	 Train_Loss: 0.6735 Train_Acc: 60.139 Val_Loss: 0.6178  BEST VAL Loss: 0.6178  Val_Acc: 67.369

Epoch 1: Validation loss decreased (0.617823 --> 0.604203).  Saving model ...
	 Train_Loss: 0.6415 Train_Acc: 66.072 Val_Loss: 0.6042  BEST VAL Loss: 0.6042  Val_Acc: 68.423

Epoch 2: Validation loss decreased (0.604203 --> 0.598185).  Saving model ...
	 Train_Loss: 0.6233 Train_Acc: 68.438 Val_Loss: 0.5982  BEST VAL Loss: 0.5982  Val_Acc: 69.882

Epoch 3: Validation loss decreased (0.598185 --> 0.590995).  Saving model ...
	 Train_Loss: 0.6097 Train_Acc: 69.264 Val_Loss: 0.5910  BEST VAL Loss: 0.5910  Val_Acc: 70.734

Epoch 4: Validation loss decreased (0.590995 --> 0.585461).  Saving model ...
	 Train_Loss: 0.5994 Train_Acc: 70.566 Val_Loss: 0.5855  BEST VAL Loss: 0.5855  Val_Acc: 71.261

Epoch 5: Validation loss decreased (0.585461 --> 0.579841).  Saving model ...
	 Train_Loss: 0.5907 Train_Acc: 71.823 Val_Loss: 0.5798  BEST VAL Loss: 0.5798  Val_Acc: 72.477

Epoch 6: Validation loss decreased (0.579841 --> 0.576130).  Saving model ...
	 Train_Loss: 0.5824 Train_Acc: 72.826 Val_Loss: 0.5761  BEST VAL Loss: 0.5761  Val_Acc: 72.071

Epoch 7: Validation loss decreased (0.576130 --> 0.573089).  Saving model ...
	 Train_Loss: 0.5752 Train_Acc: 73.642 Val_Loss: 0.5731  BEST VAL Loss: 0.5731  Val_Acc: 71.828

Epoch 8: Validation loss decreased (0.573089 --> 0.570376).  Saving model ...
	 Train_Loss: 0.5689 Train_Acc: 73.926 Val_Loss: 0.5704  BEST VAL Loss: 0.5704  Val_Acc: 72.639

Epoch 9: Validation loss decreased (0.570376 --> 0.567605).  Saving model ...
	 Train_Loss: 0.5631 Train_Acc: 74.569 Val_Loss: 0.5676  BEST VAL Loss: 0.5676  Val_Acc: 72.679

Epoch 10: Validation loss decreased (0.567605 --> 0.564901).  Saving model ...
	 Train_Loss: 0.5577 Train_Acc: 75.081 Val_Loss: 0.5649  BEST VAL Loss: 0.5649  Val_Acc: 73.044

Epoch 11: Validation loss decreased (0.564901 --> 0.562702).  Saving model ...
	 Train_Loss: 0.5528 Train_Acc: 75.350 Val_Loss: 0.5627  BEST VAL Loss: 0.5627  Val_Acc: 74.139

Epoch 12: Validation loss decreased (0.562702 --> 0.559692).  Saving model ...
	 Train_Loss: 0.5481 Train_Acc: 76.049 Val_Loss: 0.5597  BEST VAL Loss: 0.5597  Val_Acc: 74.868

Epoch 13: Validation loss decreased (0.559692 --> 0.557625).  Saving model ...
	 Train_Loss: 0.5437 Train_Acc: 76.186 Val_Loss: 0.5576  BEST VAL Loss: 0.5576  Val_Acc: 74.260

Epoch 14: Validation loss decreased (0.557625 --> 0.556487).  Saving model ...
	 Train_Loss: 0.5393 Train_Acc: 76.378 Val_Loss: 0.5565  BEST VAL Loss: 0.5565  Val_Acc: 73.450

Epoch 15: Validation loss decreased (0.556487 --> 0.554787).  Saving model ...
	 Train_Loss: 0.5352 Train_Acc: 77.133 Val_Loss: 0.5548  BEST VAL Loss: 0.5548  Val_Acc: 75.193

Epoch 16: Validation loss decreased (0.554787 --> 0.553713).  Saving model ...
	 Train_Loss: 0.5315 Train_Acc: 76.824 Val_Loss: 0.5537  BEST VAL Loss: 0.5537  Val_Acc: 73.733

Epoch 17: Validation loss decreased (0.553713 --> 0.552620).  Saving model ...
	 Train_Loss: 0.5279 Train_Acc: 77.234 Val_Loss: 0.5526  BEST VAL Loss: 0.5526  Val_Acc: 73.774

Epoch 18: Validation loss decreased (0.552620 --> 0.550828).  Saving model ...
	 Train_Loss: 0.5246 Train_Acc: 77.468 Val_Loss: 0.5508  BEST VAL Loss: 0.5508  Val_Acc: 75.233

Epoch 19: Validation loss decreased (0.550828 --> 0.549731).  Saving model ...
	 Train_Loss: 0.5213 Train_Acc: 77.787 Val_Loss: 0.5497  BEST VAL Loss: 0.5497  Val_Acc: 74.747

Epoch 20: Validation loss decreased (0.549731 --> 0.548996).  Saving model ...
	 Train_Loss: 0.5183 Train_Acc: 77.822 Val_Loss: 0.5490  BEST VAL Loss: 0.5490  Val_Acc: 74.706

Epoch 21: Validation loss decreased (0.548996 --> 0.547786).  Saving model ...
	 Train_Loss: 0.5157 Train_Acc: 77.848 Val_Loss: 0.5478  BEST VAL Loss: 0.5478  Val_Acc: 74.098

Epoch 22: Validation loss decreased (0.547786 --> 0.547072).  Saving model ...
	 Train_Loss: 0.5130 Train_Acc: 77.974 Val_Loss: 0.5471  BEST VAL Loss: 0.5471  Val_Acc: 74.463

Epoch 23: Validation loss decreased (0.547072 --> 0.546401).  Saving model ...
	 Train_Loss: 0.5103 Train_Acc: 78.486 Val_Loss: 0.5464  BEST VAL Loss: 0.5464  Val_Acc: 74.787

Epoch 24: Validation loss decreased (0.546401 --> 0.546208).  Saving model ...
	 Train_Loss: 0.5075 Train_Acc: 78.841 Val_Loss: 0.5462  BEST VAL Loss: 0.5462  Val_Acc: 75.030

Epoch 25: Validation loss decreased (0.546208 --> 0.545619).  Saving model ...
	 Train_Loss: 0.5051 Train_Acc: 78.988 Val_Loss: 0.5456  BEST VAL Loss: 0.5456  Val_Acc: 75.679

Epoch 26: Validation loss decreased (0.545619 --> 0.545396).  Saving model ...
	 Train_Loss: 0.5026 Train_Acc: 79.312 Val_Loss: 0.5454  BEST VAL Loss: 0.5454  Val_Acc: 74.382

Epoch 27: Validation loss decreased (0.545396 --> 0.544371).  Saving model ...
	 Train_Loss: 0.5002 Train_Acc: 79.236 Val_Loss: 0.5444  BEST VAL Loss: 0.5444  Val_Acc: 75.355

Epoch 28: Validation loss decreased (0.544371 --> 0.543693).  Saving model ...
	 Train_Loss: 0.4979 Train_Acc: 79.545 Val_Loss: 0.5437  BEST VAL Loss: 0.5437  Val_Acc: 75.557

Epoch 29: Validation loss decreased (0.543693 --> 0.543242).  Saving model ...
	 Train_Loss: 0.4955 Train_Acc: 79.560 Val_Loss: 0.5432  BEST VAL Loss: 0.5432  Val_Acc: 75.193

Epoch 30: Validation loss decreased (0.543242 --> 0.542730).  Saving model ...
	 Train_Loss: 0.4932 Train_Acc: 79.773 Val_Loss: 0.5427  BEST VAL Loss: 0.5427  Val_Acc: 75.193

Epoch 31: Validation loss decreased (0.542730 --> 0.542045).  Saving model ...
	 Train_Loss: 0.4910 Train_Acc: 79.651 Val_Loss: 0.5420  BEST VAL Loss: 0.5420  Val_Acc: 76.084

Epoch 32: Validation loss decreased (0.542045 --> 0.541562).  Saving model ...
	 Train_Loss: 0.4888 Train_Acc: 80.371 Val_Loss: 0.5416  BEST VAL Loss: 0.5416  Val_Acc: 76.165

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.4864 Train_Acc: 80.427 Val_Loss: 0.5417  BEST VAL Loss: 0.5416  Val_Acc: 75.071

Epoch 34: Validation loss decreased (0.541562 --> 0.541496).  Saving model ...
	 Train_Loss: 0.4844 Train_Acc: 80.178 Val_Loss: 0.5415  BEST VAL Loss: 0.5415  Val_Acc: 75.152

Epoch 35: Validation loss decreased (0.541496 --> 0.541109).  Saving model ...
	 Train_Loss: 0.4824 Train_Acc: 80.259 Val_Loss: 0.5411  BEST VAL Loss: 0.5411  Val_Acc: 75.233

Epoch 36: Validation loss decreased (0.541109 --> 0.540844).  Saving model ...
	 Train_Loss: 0.4804 Train_Acc: 80.619 Val_Loss: 0.5408  BEST VAL Loss: 0.5408  Val_Acc: 75.193

Epoch 37: Validation loss decreased (0.540844 --> 0.540715).  Saving model ...
	 Train_Loss: 0.4785 Train_Acc: 80.817 Val_Loss: 0.5407  BEST VAL Loss: 0.5407  Val_Acc: 75.111

Epoch 38: Validation loss decreased (0.540715 --> 0.540661).  Saving model ...
	 Train_Loss: 0.4765 Train_Acc: 80.741 Val_Loss: 0.5407  BEST VAL Loss: 0.5407  Val_Acc: 75.638

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.4745 Train_Acc: 80.949 Val_Loss: 0.5410  BEST VAL Loss: 0.5407  Val_Acc: 75.719

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.4727 Train_Acc: 81.101 Val_Loss: 0.5410  BEST VAL Loss: 0.5407  Val_Acc: 74.868

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.4706 Train_Acc: 81.926 Val_Loss: 0.5410  BEST VAL Loss: 0.5407  Val_Acc: 75.841

Epoch 42: Validation loss decreased (0.540661 --> 0.540619).  Saving model ...
	 Train_Loss: 0.4689 Train_Acc: 81.009 Val_Loss: 0.5406  BEST VAL Loss: 0.5406  Val_Acc: 75.152

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.4672 Train_Acc: 81.470 Val_Loss: 0.5408  BEST VAL Loss: 0.5406  Val_Acc: 75.030

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.4655 Train_Acc: 81.572 Val_Loss: 0.5408  BEST VAL Loss: 0.5406  Val_Acc: 75.476

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.4638 Train_Acc: 81.638 Val_Loss: 0.5409  BEST VAL Loss: 0.5406  Val_Acc: 75.071

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.4623 Train_Acc: 81.278 Val_Loss: 0.5409  BEST VAL Loss: 0.5406  Val_Acc: 75.841

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.4607 Train_Acc: 81.703 Val_Loss: 0.5413  BEST VAL Loss: 0.5406  Val_Acc: 75.679

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.4592 Train_Acc: 81.815 Val_Loss: 0.5415  BEST VAL Loss: 0.5406  Val_Acc: 75.638

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.4578 Train_Acc: 81.308 Val_Loss: 0.5418  BEST VAL Loss: 0.5406  Val_Acc: 74.747

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.4562 Train_Acc: 81.987 Val_Loss: 0.5419  BEST VAL Loss: 0.5406  Val_Acc: 75.882

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.4549 Train_Acc: 81.364 Val_Loss: 0.5420  BEST VAL Loss: 0.5406  Val_Acc: 75.355

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.4535 Train_Acc: 82.007 Val_Loss: 0.5422  BEST VAL Loss: 0.5406  Val_Acc: 75.517

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.4521 Train_Acc: 82.190 Val_Loss: 0.5424  BEST VAL Loss: 0.5406  Val_Acc: 75.801

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.4507 Train_Acc: 82.139 Val_Loss: 0.5425  BEST VAL Loss: 0.5406  Val_Acc: 75.922

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.4494 Train_Acc: 82.185 Val_Loss: 0.5426  BEST VAL Loss: 0.5406  Val_Acc: 75.517

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.4480 Train_Acc: 82.448 Val_Loss: 0.5429  BEST VAL Loss: 0.5406  Val_Acc: 75.030

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.4468 Train_Acc: 81.805 Val_Loss: 0.5430  BEST VAL Loss: 0.5406  Val_Acc: 75.395

Epoch 58: Validation loss did not decrease
Early stopped at epoch : 58
LPS_0.010_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.89      0.85      0.87      9708
           1       0.86      0.90      0.88     10028

    accuracy                           0.87     19736
   macro avg       0.87      0.87      0.87     19736
weighted avg       0.87      0.87      0.87     19736

LPS_0.010_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.75      0.74      0.75      1213
           1       0.75      0.76      0.76      1254

    accuracy                           0.75      2467
   macro avg       0.75      0.75      0.75      2467
weighted avg       0.75      0.75      0.75      2467

LPS_0.010_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.76      0.72      0.74      1214
           1       0.74      0.78      0.76      1253

    accuracy                           0.75      2467
   macro avg       0.75      0.75      0.75      2467
weighted avg       0.75      0.75      0.75      2467

              precision    recall  f1-score   support

           0       0.76      0.72      0.74      1214
           1       0.74      0.78      0.76      1253

    accuracy                           0.75      2467
   macro avg       0.75      0.75      0.75      2467
weighted avg       0.75      0.75      0.75      2467

LPS_0.010_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.56      0.69      0.62      3724
           1       0.62      0.48      0.55      3923

    accuracy                           0.59      7647
   macro avg       0.59      0.59      0.58      7647
weighted avg       0.59      0.59      0.58      7647

              precision    recall  f1-score   support

           0       0.56      0.69      0.62      3724
           1       0.62      0.48      0.55      3923

    accuracy                           0.59      7647
   macro avg       0.59      0.59      0.58      7647
weighted avg       0.59      0.59      0.58      7647

completed
