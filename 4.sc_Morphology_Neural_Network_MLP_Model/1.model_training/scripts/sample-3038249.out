[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '34c8d467'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'a011967f'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '2bbccb41'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'd196e26f'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_1.000_DMSO_0.025 treatment_name: LPS_10.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_1.000_DMSO_0.025
TREATMENT_NAME: LPS_10.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'LPS_10.000_DMSO_0.025']
The dimensions of the data are: (295923, 1270)
Number of total missing values across all columns: 591846
Data Subset Is Off
Wells held out for testing: ['D08' 'E08']
Wells to use for training, validation, and testing ['D02' 'E02' 'D03' 'E03' 'D09' 'E09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.616168).  Saving model ...
	 Train_Loss: 0.6639 Train_Acc: 59.117 Val_Loss: 0.6162  BEST VAL Loss: 0.6162  Val_Acc: 67.170

Epoch 1: Validation loss decreased (0.616168 --> 0.576178).  Saving model ...
	 Train_Loss: 0.6291 Train_Acc: 67.792 Val_Loss: 0.5762  BEST VAL Loss: 0.5762  Val_Acc: 73.399

Epoch 2: Validation loss decreased (0.576178 --> 0.554143).  Saving model ...
	 Train_Loss: 0.6013 Train_Acc: 71.579 Val_Loss: 0.5541  BEST VAL Loss: 0.5541  Val_Acc: 74.690

Epoch 3: Validation loss decreased (0.554143 --> 0.537558).  Saving model ...
	 Train_Loss: 0.5822 Train_Acc: 73.251 Val_Loss: 0.5376  BEST VAL Loss: 0.5376  Val_Acc: 76.358

Epoch 4: Validation loss decreased (0.537558 --> 0.526603).  Saving model ...
	 Train_Loss: 0.5684 Train_Acc: 74.113 Val_Loss: 0.5266  BEST VAL Loss: 0.5266  Val_Acc: 76.372

Epoch 5: Validation loss decreased (0.526603 --> 0.519007).  Saving model ...
	 Train_Loss: 0.5569 Train_Acc: 75.010 Val_Loss: 0.5190  BEST VAL Loss: 0.5190  Val_Acc: 76.093

Epoch 6: Validation loss decreased (0.519007 --> 0.510766).  Saving model ...
	 Train_Loss: 0.5481 Train_Acc: 75.301 Val_Loss: 0.5108  BEST VAL Loss: 0.5108  Val_Acc: 77.607

Epoch 7: Validation loss decreased (0.510766 --> 0.503727).  Saving model ...
	 Train_Loss: 0.5405 Train_Acc: 75.807 Val_Loss: 0.5037  BEST VAL Loss: 0.5037  Val_Acc: 78.068

Epoch 8: Validation loss decreased (0.503727 --> 0.501740).  Saving model ...
	 Train_Loss: 0.5339 Train_Acc: 76.038 Val_Loss: 0.5017  BEST VAL Loss: 0.5017  Val_Acc: 76.060

Epoch 9: Validation loss decreased (0.501740 --> 0.496090).  Saving model ...
	 Train_Loss: 0.5278 Train_Acc: 76.515 Val_Loss: 0.4961  BEST VAL Loss: 0.4961  Val_Acc: 78.557

Epoch 10: Validation loss decreased (0.496090 --> 0.491183).  Saving model ...
	 Train_Loss: 0.5225 Train_Acc: 76.914 Val_Loss: 0.4912  BEST VAL Loss: 0.4912  Val_Acc: 79.056

Epoch 11: Validation loss decreased (0.491183 --> 0.486843).  Saving model ...
	 Train_Loss: 0.5177 Train_Acc: 77.236 Val_Loss: 0.4868  BEST VAL Loss: 0.4868  Val_Acc: 79.019

Epoch 12: Validation loss decreased (0.486843 --> 0.482652).  Saving model ...
	 Train_Loss: 0.5134 Train_Acc: 77.374 Val_Loss: 0.4827  BEST VAL Loss: 0.4827  Val_Acc: 79.317

Epoch 13: Validation loss decreased (0.482652 --> 0.478893).  Saving model ...
	 Train_Loss: 0.5095 Train_Acc: 77.685 Val_Loss: 0.4789  BEST VAL Loss: 0.4789  Val_Acc: 79.275

Epoch 14: Validation loss decreased (0.478893 --> 0.476027).  Saving model ...
	 Train_Loss: 0.5060 Train_Acc: 77.727 Val_Loss: 0.4760  BEST VAL Loss: 0.4760  Val_Acc: 79.424

Epoch 15: Validation loss decreased (0.476027 --> 0.473332).  Saving model ...
	 Train_Loss: 0.5026 Train_Acc: 78.024 Val_Loss: 0.4733  BEST VAL Loss: 0.4733  Val_Acc: 79.135

Epoch 16: Validation loss decreased (0.473332 --> 0.470319).  Saving model ...
	 Train_Loss: 0.4994 Train_Acc: 78.215 Val_Loss: 0.4703  BEST VAL Loss: 0.4703  Val_Acc: 80.034

Epoch 17: Validation loss decreased (0.470319 --> 0.468499).  Saving model ...
	 Train_Loss: 0.4964 Train_Acc: 78.300 Val_Loss: 0.4685  BEST VAL Loss: 0.4685  Val_Acc: 78.912

Epoch 18: Validation loss decreased (0.468499 --> 0.466279).  Saving model ...
	 Train_Loss: 0.4936 Train_Acc: 78.519 Val_Loss: 0.4663  BEST VAL Loss: 0.4663  Val_Acc: 79.419

Epoch 19: Validation loss decreased (0.466279 --> 0.465058).  Saving model ...
	 Train_Loss: 0.4911 Train_Acc: 78.389 Val_Loss: 0.4651  BEST VAL Loss: 0.4651  Val_Acc: 78.660

Epoch 20: Validation loss decreased (0.465058 --> 0.463209).  Saving model ...
	 Train_Loss: 0.4887 Train_Acc: 78.525 Val_Loss: 0.4632  BEST VAL Loss: 0.4632  Val_Acc: 79.699

Epoch 21: Validation loss decreased (0.463209 --> 0.461633).  Saving model ...
	 Train_Loss: 0.4864 Train_Acc: 78.768 Val_Loss: 0.4616  BEST VAL Loss: 0.4616  Val_Acc: 79.056

Epoch 22: Validation loss decreased (0.461633 --> 0.459709).  Saving model ...
	 Train_Loss: 0.4843 Train_Acc: 78.752 Val_Loss: 0.4597  BEST VAL Loss: 0.4597  Val_Acc: 80.300

Epoch 23: Validation loss decreased (0.459709 --> 0.457919).  Saving model ...
	 Train_Loss: 0.4822 Train_Acc: 78.857 Val_Loss: 0.4579  BEST VAL Loss: 0.4579  Val_Acc: 80.305

Epoch 24: Validation loss decreased (0.457919 --> 0.456297).  Saving model ...
	 Train_Loss: 0.4803 Train_Acc: 78.784 Val_Loss: 0.4563  BEST VAL Loss: 0.4563  Val_Acc: 80.230

Epoch 25: Validation loss decreased (0.456297 --> 0.454626).  Saving model ...
	 Train_Loss: 0.4785 Train_Acc: 78.999 Val_Loss: 0.4546  BEST VAL Loss: 0.4546  Val_Acc: 80.696

Epoch 26: Validation loss decreased (0.454626 --> 0.453055).  Saving model ...
	 Train_Loss: 0.4767 Train_Acc: 79.215 Val_Loss: 0.4531  BEST VAL Loss: 0.4531  Val_Acc: 80.524

Epoch 27: Validation loss decreased (0.453055 --> 0.451536).  Saving model ...
	 Train_Loss: 0.4750 Train_Acc: 79.022 Val_Loss: 0.4515  BEST VAL Loss: 0.4515  Val_Acc: 80.468

Epoch 28: Validation loss decreased (0.451536 --> 0.450239).  Saving model ...
	 Train_Loss: 0.4734 Train_Acc: 79.082 Val_Loss: 0.4502  BEST VAL Loss: 0.4502  Val_Acc: 80.398

Epoch 29: Validation loss decreased (0.450239 --> 0.448820).  Saving model ...
	 Train_Loss: 0.4719 Train_Acc: 79.264 Val_Loss: 0.4488  BEST VAL Loss: 0.4488  Val_Acc: 80.631

Epoch 30: Validation loss decreased (0.448820 --> 0.447480).  Saving model ...
	 Train_Loss: 0.4704 Train_Acc: 79.276 Val_Loss: 0.4475  BEST VAL Loss: 0.4475  Val_Acc: 80.752

Epoch 31: Validation loss decreased (0.447480 --> 0.446301).  Saving model ...
	 Train_Loss: 0.4690 Train_Acc: 79.465 Val_Loss: 0.4463  BEST VAL Loss: 0.4463  Val_Acc: 80.505

Epoch 32: Validation loss decreased (0.446301 --> 0.445122).  Saving model ...
	 Train_Loss: 0.4676 Train_Acc: 79.390 Val_Loss: 0.4451  BEST VAL Loss: 0.4451  Val_Acc: 80.896

Epoch 33: Validation loss decreased (0.445122 --> 0.443975).  Saving model ...
	 Train_Loss: 0.4663 Train_Acc: 79.377 Val_Loss: 0.4440  BEST VAL Loss: 0.4440  Val_Acc: 80.962

Epoch 34: Validation loss decreased (0.443975 --> 0.442783).  Saving model ...
	 Train_Loss: 0.4650 Train_Acc: 79.437 Val_Loss: 0.4428  BEST VAL Loss: 0.4428  Val_Acc: 80.873

Epoch 35: Validation loss decreased (0.442783 --> 0.441603).  Saving model ...
	 Train_Loss: 0.4638 Train_Acc: 79.432 Val_Loss: 0.4416  BEST VAL Loss: 0.4416  Val_Acc: 81.092

Epoch 36: Validation loss decreased (0.441603 --> 0.440514).  Saving model ...
	 Train_Loss: 0.4626 Train_Acc: 79.511 Val_Loss: 0.4405  BEST VAL Loss: 0.4405  Val_Acc: 80.906

Epoch 37: Validation loss decreased (0.440514 --> 0.439511).  Saving model ...
	 Train_Loss: 0.4615 Train_Acc: 79.691 Val_Loss: 0.4395  BEST VAL Loss: 0.4395  Val_Acc: 80.659

Epoch 38: Validation loss decreased (0.439511 --> 0.438484).  Saving model ...
	 Train_Loss: 0.4604 Train_Acc: 79.545 Val_Loss: 0.4385  BEST VAL Loss: 0.4385  Val_Acc: 81.195

Epoch 39: Validation loss decreased (0.438484 --> 0.437636).  Saving model ...
	 Train_Loss: 0.4593 Train_Acc: 79.591 Val_Loss: 0.4376  BEST VAL Loss: 0.4376  Val_Acc: 81.237

Epoch 40: Validation loss decreased (0.437636 --> 0.436800).  Saving model ...
	 Train_Loss: 0.4583 Train_Acc: 79.734 Val_Loss: 0.4368  BEST VAL Loss: 0.4368  Val_Acc: 80.589

Epoch 41: Validation loss decreased (0.436800 --> 0.435964).  Saving model ...
	 Train_Loss: 0.4573 Train_Acc: 79.620 Val_Loss: 0.4360  BEST VAL Loss: 0.4360  Val_Acc: 80.813

Epoch 42: Validation loss decreased (0.435964 --> 0.435141).  Saving model ...
	 Train_Loss: 0.4564 Train_Acc: 79.640 Val_Loss: 0.4351  BEST VAL Loss: 0.4351  Val_Acc: 81.106

Epoch 43: Validation loss decreased (0.435141 --> 0.434273).  Saving model ...
	 Train_Loss: 0.4554 Train_Acc: 79.746 Val_Loss: 0.4343  BEST VAL Loss: 0.4343  Val_Acc: 81.157

Epoch 44: Validation loss decreased (0.434273 --> 0.433552).  Saving model ...
	 Train_Loss: 0.4545 Train_Acc: 79.765 Val_Loss: 0.4336  BEST VAL Loss: 0.4336  Val_Acc: 81.428

Epoch 45: Validation loss decreased (0.433552 --> 0.432955).  Saving model ...
	 Train_Loss: 0.4536 Train_Acc: 79.738 Val_Loss: 0.4330  BEST VAL Loss: 0.4330  Val_Acc: 80.449

Epoch 46: Validation loss decreased (0.432955 --> 0.432218).  Saving model ...
	 Train_Loss: 0.4527 Train_Acc: 79.835 Val_Loss: 0.4322  BEST VAL Loss: 0.4322  Val_Acc: 81.176

Epoch 47: Validation loss decreased (0.432218 --> 0.431433).  Saving model ...
	 Train_Loss: 0.4519 Train_Acc: 79.808 Val_Loss: 0.4314  BEST VAL Loss: 0.4314  Val_Acc: 81.437

Epoch 48: Validation loss decreased (0.431433 --> 0.430679).  Saving model ...
	 Train_Loss: 0.4511 Train_Acc: 79.876 Val_Loss: 0.4307  BEST VAL Loss: 0.4307  Val_Acc: 81.302

Epoch 49: Validation loss decreased (0.430679 --> 0.430034).  Saving model ...
	 Train_Loss: 0.4503 Train_Acc: 79.903 Val_Loss: 0.4300  BEST VAL Loss: 0.4300  Val_Acc: 81.409

Epoch 50: Validation loss decreased (0.430034 --> 0.429356).  Saving model ...
	 Train_Loss: 0.4495 Train_Acc: 79.873 Val_Loss: 0.4294  BEST VAL Loss: 0.4294  Val_Acc: 81.525

Epoch 51: Validation loss decreased (0.429356 --> 0.428702).  Saving model ...
	 Train_Loss: 0.4488 Train_Acc: 79.941 Val_Loss: 0.4287  BEST VAL Loss: 0.4287  Val_Acc: 81.232

Epoch 52: Validation loss decreased (0.428702 --> 0.428228).  Saving model ...
	 Train_Loss: 0.4480 Train_Acc: 79.995 Val_Loss: 0.4282  BEST VAL Loss: 0.4282  Val_Acc: 80.654

Epoch 53: Validation loss decreased (0.428228 --> 0.427693).  Saving model ...
	 Train_Loss: 0.4473 Train_Acc: 79.895 Val_Loss: 0.4277  BEST VAL Loss: 0.4277  Val_Acc: 80.976

Epoch 54: Validation loss decreased (0.427693 --> 0.427094).  Saving model ...
	 Train_Loss: 0.4466 Train_Acc: 79.932 Val_Loss: 0.4271  BEST VAL Loss: 0.4271  Val_Acc: 81.339

Epoch 55: Validation loss decreased (0.427094 --> 0.426563).  Saving model ...
	 Train_Loss: 0.4460 Train_Acc: 79.984 Val_Loss: 0.4266  BEST VAL Loss: 0.4266  Val_Acc: 81.428

Epoch 56: Validation loss decreased (0.426563 --> 0.426175).  Saving model ...
	 Train_Loss: 0.4453 Train_Acc: 79.961 Val_Loss: 0.4262  BEST VAL Loss: 0.4262  Val_Acc: 80.598

Epoch 57: Validation loss decreased (0.426175 --> 0.425609).  Saving model ...
	 Train_Loss: 0.4446 Train_Acc: 79.911 Val_Loss: 0.4256  BEST VAL Loss: 0.4256  Val_Acc: 81.362

Epoch 58: Validation loss decreased (0.425609 --> 0.425152).  Saving model ...
	 Train_Loss: 0.4440 Train_Acc: 80.029 Val_Loss: 0.4252  BEST VAL Loss: 0.4252  Val_Acc: 81.437

Epoch 59: Validation loss decreased (0.425152 --> 0.424730).  Saving model ...
	 Train_Loss: 0.4434 Train_Acc: 80.046 Val_Loss: 0.4247  BEST VAL Loss: 0.4247  Val_Acc: 80.677

Epoch 60: Validation loss decreased (0.424730 --> 0.424269).  Saving model ...
	 Train_Loss: 0.4428 Train_Acc: 80.082 Val_Loss: 0.4243  BEST VAL Loss: 0.4243  Val_Acc: 81.330

Epoch 61: Validation loss decreased (0.424269 --> 0.423795).  Saving model ...
	 Train_Loss: 0.4422 Train_Acc: 80.098 Val_Loss: 0.4238  BEST VAL Loss: 0.4238  Val_Acc: 81.493

Epoch 62: Validation loss decreased (0.423795 --> 0.423306).  Saving model ...
	 Train_Loss: 0.4416 Train_Acc: 80.154 Val_Loss: 0.4233  BEST VAL Loss: 0.4233  Val_Acc: 81.423

Epoch 63: Validation loss decreased (0.423306 --> 0.422844).  Saving model ...
	 Train_Loss: 0.4411 Train_Acc: 80.159 Val_Loss: 0.4228  BEST VAL Loss: 0.4228  Val_Acc: 81.516

Epoch 64: Validation loss decreased (0.422844 --> 0.422360).  Saving model ...
	 Train_Loss: 0.4405 Train_Acc: 80.116 Val_Loss: 0.4224  BEST VAL Loss: 0.4224  Val_Acc: 81.609

Epoch 65: Validation loss decreased (0.422360 --> 0.422234).  Saving model ...
	 Train_Loss: 0.4400 Train_Acc: 80.089 Val_Loss: 0.4222  BEST VAL Loss: 0.4222  Val_Acc: 80.272

Epoch 66: Validation loss decreased (0.422234 --> 0.421736).  Saving model ...
	 Train_Loss: 0.4394 Train_Acc: 80.149 Val_Loss: 0.4217  BEST VAL Loss: 0.4217  Val_Acc: 81.633

Epoch 67: Validation loss decreased (0.421736 --> 0.421333).  Saving model ...
	 Train_Loss: 0.4389 Train_Acc: 80.228 Val_Loss: 0.4213  BEST VAL Loss: 0.4213  Val_Acc: 81.237

Epoch 68: Validation loss decreased (0.421333 --> 0.420837).  Saving model ...
	 Train_Loss: 0.4384 Train_Acc: 80.209 Val_Loss: 0.4208  BEST VAL Loss: 0.4208  Val_Acc: 81.908

Epoch 69: Validation loss decreased (0.420837 --> 0.420403).  Saving model ...
	 Train_Loss: 0.4379 Train_Acc: 80.279 Val_Loss: 0.4204  BEST VAL Loss: 0.4204  Val_Acc: 81.274

Epoch 70: Validation loss decreased (0.420403 --> 0.419949).  Saving model ...
	 Train_Loss: 0.4374 Train_Acc: 80.407 Val_Loss: 0.4199  BEST VAL Loss: 0.4199  Val_Acc: 81.595

Epoch 71: Validation loss decreased (0.419949 --> 0.419497).  Saving model ...
	 Train_Loss: 0.4369 Train_Acc: 80.348 Val_Loss: 0.4195  BEST VAL Loss: 0.4195  Val_Acc: 81.875

Epoch 72: Validation loss decreased (0.419497 --> 0.419096).  Saving model ...
	 Train_Loss: 0.4365 Train_Acc: 80.352 Val_Loss: 0.4191  BEST VAL Loss: 0.4191  Val_Acc: 81.376

Epoch 73: Validation loss decreased (0.419096 --> 0.418749).  Saving model ...
	 Train_Loss: 0.4360 Train_Acc: 80.350 Val_Loss: 0.4187  BEST VAL Loss: 0.4187  Val_Acc: 81.749

Epoch 74: Validation loss decreased (0.418749 --> 0.418383).  Saving model ...
	 Train_Loss: 0.4356 Train_Acc: 80.362 Val_Loss: 0.4184  BEST VAL Loss: 0.4184  Val_Acc: 81.689

Epoch 75: Validation loss decreased (0.418383 --> 0.418058).  Saving model ...
	 Train_Loss: 0.4351 Train_Acc: 80.433 Val_Loss: 0.4181  BEST VAL Loss: 0.4181  Val_Acc: 81.260

Epoch 76: Validation loss decreased (0.418058 --> 0.417650).  Saving model ...
	 Train_Loss: 0.4347 Train_Acc: 80.313 Val_Loss: 0.4176  BEST VAL Loss: 0.4176  Val_Acc: 81.973

Epoch 77: Validation loss decreased (0.417650 --> 0.417262).  Saving model ...
	 Train_Loss: 0.4343 Train_Acc: 80.315 Val_Loss: 0.4173  BEST VAL Loss: 0.4173  Val_Acc: 81.642

Epoch 78: Validation loss decreased (0.417262 --> 0.416879).  Saving model ...
	 Train_Loss: 0.4339 Train_Acc: 80.351 Val_Loss: 0.4169  BEST VAL Loss: 0.4169  Val_Acc: 81.479

Epoch 79: Validation loss decreased (0.416879 --> 0.416517).  Saving model ...
	 Train_Loss: 0.4334 Train_Acc: 80.427 Val_Loss: 0.4165  BEST VAL Loss: 0.4165  Val_Acc: 81.814

Epoch 80: Validation loss decreased (0.416517 --> 0.416190).  Saving model ...
	 Train_Loss: 0.4330 Train_Acc: 80.437 Val_Loss: 0.4162  BEST VAL Loss: 0.4162  Val_Acc: 81.512

Epoch 81: Validation loss decreased (0.416190 --> 0.415873).  Saving model ...
	 Train_Loss: 0.4326 Train_Acc: 80.312 Val_Loss: 0.4159  BEST VAL Loss: 0.4159  Val_Acc: 81.367

Epoch 82: Validation loss decreased (0.415873 --> 0.415586).  Saving model ...
	 Train_Loss: 0.4322 Train_Acc: 80.444 Val_Loss: 0.4156  BEST VAL Loss: 0.4156  Val_Acc: 81.395

Epoch 83: Validation loss decreased (0.415586 --> 0.415292).  Saving model ...
	 Train_Loss: 0.4318 Train_Acc: 80.395 Val_Loss: 0.4153  BEST VAL Loss: 0.4153  Val_Acc: 81.605

Epoch 84: Validation loss decreased (0.415292 --> 0.414959).  Saving model ...
	 Train_Loss: 0.4314 Train_Acc: 80.527 Val_Loss: 0.4150  BEST VAL Loss: 0.4150  Val_Acc: 81.940

Epoch 85: Validation loss decreased (0.414959 --> 0.414617).  Saving model ...
	 Train_Loss: 0.4311 Train_Acc: 80.499 Val_Loss: 0.4146  BEST VAL Loss: 0.4146  Val_Acc: 81.973

Epoch 86: Validation loss decreased (0.414617 --> 0.414321).  Saving model ...
	 Train_Loss: 0.4307 Train_Acc: 80.384 Val_Loss: 0.4143  BEST VAL Loss: 0.4143  Val_Acc: 81.824

Epoch 87: Validation loss decreased (0.414321 --> 0.414243).  Saving model ...
	 Train_Loss: 0.4303 Train_Acc: 80.655 Val_Loss: 0.4142  BEST VAL Loss: 0.4142  Val_Acc: 80.463

Epoch 88: Validation loss decreased (0.414243 --> 0.413962).  Saving model ...
	 Train_Loss: 0.4299 Train_Acc: 80.562 Val_Loss: 0.4140  BEST VAL Loss: 0.4140  Val_Acc: 81.558

Epoch 89: Validation loss decreased (0.413962 --> 0.413698).  Saving model ...
	 Train_Loss: 0.4296 Train_Acc: 80.613 Val_Loss: 0.4137  BEST VAL Loss: 0.4137  Val_Acc: 81.693

Epoch 90: Validation loss decreased (0.413698 --> 0.413409).  Saving model ...
	 Train_Loss: 0.4292 Train_Acc: 80.535 Val_Loss: 0.4134  BEST VAL Loss: 0.4134  Val_Acc: 81.633

Epoch 91: Validation loss decreased (0.413409 --> 0.413137).  Saving model ...
	 Train_Loss: 0.4289 Train_Acc: 80.515 Val_Loss: 0.4131  BEST VAL Loss: 0.4131  Val_Acc: 82.150

Epoch 92: Validation loss decreased (0.413137 --> 0.412902).  Saving model ...
	 Train_Loss: 0.4286 Train_Acc: 80.625 Val_Loss: 0.4129  BEST VAL Loss: 0.4129  Val_Acc: 81.647

Epoch 93: Validation loss decreased (0.412902 --> 0.412607).  Saving model ...
	 Train_Loss: 0.4282 Train_Acc: 80.702 Val_Loss: 0.4126  BEST VAL Loss: 0.4126  Val_Acc: 81.870

Epoch 94: Validation loss decreased (0.412607 --> 0.412326).  Saving model ...
	 Train_Loss: 0.4279 Train_Acc: 80.580 Val_Loss: 0.4123  BEST VAL Loss: 0.4123  Val_Acc: 81.502

Epoch 95: Validation loss decreased (0.412326 --> 0.412042).  Saving model ...
	 Train_Loss: 0.4276 Train_Acc: 80.558 Val_Loss: 0.4120  BEST VAL Loss: 0.4120  Val_Acc: 81.423

Epoch 96: Validation loss decreased (0.412042 --> 0.411844).  Saving model ...
	 Train_Loss: 0.4273 Train_Acc: 80.663 Val_Loss: 0.4118  BEST VAL Loss: 0.4118  Val_Acc: 81.316

Epoch 97: Validation loss decreased (0.411844 --> 0.411548).  Saving model ...
	 Train_Loss: 0.4269 Train_Acc: 80.571 Val_Loss: 0.4115  BEST VAL Loss: 0.4115  Val_Acc: 81.977

Epoch 98: Validation loss decreased (0.411548 --> 0.411311).  Saving model ...
	 Train_Loss: 0.4266 Train_Acc: 80.624 Val_Loss: 0.4113  BEST VAL Loss: 0.4113  Val_Acc: 81.498

Epoch 99: Validation loss decreased (0.411311 --> 0.411035).  Saving model ...
	 Train_Loss: 0.4263 Train_Acc: 80.593 Val_Loss: 0.4110  BEST VAL Loss: 0.4110  Val_Acc: 81.963

LPS_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.41      0.44     79796
           1       0.54      0.59      0.56     91899

    accuracy                           0.51    171695
   macro avg       0.50      0.50      0.50    171695
weighted avg       0.50      0.51      0.50    171695

LPS_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.40      0.43      9975
           1       0.53      0.58      0.55     11487

    accuracy                           0.50     21462
   macro avg       0.49      0.49      0.49     21462
weighted avg       0.49      0.50      0.50     21462

LPS_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.42      0.44      9975
           1       0.54      0.59      0.56     11487

    accuracy                           0.51     21462
   macro avg       0.50      0.50      0.50     21462
weighted avg       0.51      0.51      0.51     21462

              precision    recall  f1-score   support

           0       0.47      0.42      0.44      9975
           1       0.54      0.59      0.56     11487

    accuracy                           0.51     21462
   macro avg       0.50      0.50      0.50     21462
weighted avg       0.51      0.51      0.51     21462

LPS_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.11      0.18     39687
           1       0.51      0.89      0.65     41617

    accuracy                           0.51     81304
   macro avg       0.50      0.50      0.42     81304
weighted avg       0.50      0.51      0.42     81304

              precision    recall  f1-score   support

           0       0.48      0.11      0.18     39687
           1       0.51      0.89      0.65     41617

    accuracy                           0.51     81304
   macro avg       0.50      0.50      0.42     81304
weighted avg       0.50      0.51      0.42     81304

completed
