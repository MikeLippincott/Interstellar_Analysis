[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'bea09886'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '5b88f841'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '31e85ea3'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '7526308d'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_0.100_DMSO_0.025 treatment_name: Thapsigargin_10.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_0.100_DMSO_0.025
TREATMENT_NAME: Thapsigargin_10.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'Thapsigargin_10.000_DMSO_0.025']
The dimensions of the data are: (305581, 1270)
Number of total missing values across all columns: 611162
Data Subset Is Off
Wells held out for testing: ['C08' 'L06']
Wells to use for training, validation, and testing ['C02' 'C03' 'C09' 'E06' 'E07' 'L07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.674450).  Saving model ...
	 Train_Loss: 0.6887 Train_Acc: 53.614 Val_Loss: 0.6745  BEST VAL Loss: 0.6745  Val_Acc: 59.031

Epoch 1: Validation loss decreased (0.674450 --> 0.622273).  Saving model ...
	 Train_Loss: 0.6719 Train_Acc: 60.537 Val_Loss: 0.6223  BEST VAL Loss: 0.6223  Val_Acc: 75.844

Epoch 2: Validation loss decreased (0.622273 --> 0.571151).  Saving model ...
	 Train_Loss: 0.6408 Train_Acc: 67.122 Val_Loss: 0.5712  BEST VAL Loss: 0.5712  Val_Acc: 80.206

Epoch 3: Validation loss decreased (0.571151 --> 0.533675).  Saving model ...
	 Train_Loss: 0.6118 Train_Acc: 74.247 Val_Loss: 0.5337  BEST VAL Loss: 0.5337  Val_Acc: 82.412

Epoch 4: Validation loss decreased (0.533675 --> 0.506502).  Saving model ...
	 Train_Loss: 0.5873 Train_Acc: 78.091 Val_Loss: 0.5065  BEST VAL Loss: 0.5065  Val_Acc: 82.682

Epoch 5: Validation loss decreased (0.506502 --> 0.487911).  Saving model ...
	 Train_Loss: 0.5675 Train_Acc: 79.697 Val_Loss: 0.4879  BEST VAL Loss: 0.4879  Val_Acc: 82.541

Epoch 6: Validation loss decreased (0.487911 --> 0.468853).  Saving model ...
	 Train_Loss: 0.5508 Train_Acc: 80.804 Val_Loss: 0.4689  BEST VAL Loss: 0.4689  Val_Acc: 85.047

Epoch 7: Validation loss decreased (0.468853 --> 0.456102).  Saving model ...
	 Train_Loss: 0.5366 Train_Acc: 81.583 Val_Loss: 0.4561  BEST VAL Loss: 0.4561  Val_Acc: 83.989

Epoch 8: Validation loss decreased (0.456102 --> 0.442262).  Saving model ...
	 Train_Loss: 0.5242 Train_Acc: 82.142 Val_Loss: 0.4423  BEST VAL Loss: 0.4423  Val_Acc: 86.075

Epoch 9: Validation loss decreased (0.442262 --> 0.431116).  Saving model ...
	 Train_Loss: 0.5133 Train_Acc: 82.648 Val_Loss: 0.4311  BEST VAL Loss: 0.4311  Val_Acc: 85.769

Epoch 10: Validation loss decreased (0.431116 --> 0.421921).  Saving model ...
	 Train_Loss: 0.5037 Train_Acc: 83.034 Val_Loss: 0.4219  BEST VAL Loss: 0.4219  Val_Acc: 85.960

Epoch 11: Validation loss decreased (0.421921 --> 0.413611).  Saving model ...
	 Train_Loss: 0.4951 Train_Acc: 83.345 Val_Loss: 0.4136  BEST VAL Loss: 0.4136  Val_Acc: 86.146

Epoch 12: Validation loss decreased (0.413611 --> 0.405781).  Saving model ...
	 Train_Loss: 0.4871 Train_Acc: 83.829 Val_Loss: 0.4058  BEST VAL Loss: 0.4058  Val_Acc: 86.819

Epoch 13: Validation loss decreased (0.405781 --> 0.399183).  Saving model ...
	 Train_Loss: 0.4799 Train_Acc: 84.194 Val_Loss: 0.3992  BEST VAL Loss: 0.3992  Val_Acc: 86.509

Epoch 14: Validation loss decreased (0.399183 --> 0.392777).  Saving model ...
	 Train_Loss: 0.4734 Train_Acc: 84.456 Val_Loss: 0.3928  BEST VAL Loss: 0.3928  Val_Acc: 87.364

Epoch 15: Validation loss decreased (0.392777 --> 0.386998).  Saving model ...
	 Train_Loss: 0.4672 Train_Acc: 84.862 Val_Loss: 0.3870  BEST VAL Loss: 0.3870  Val_Acc: 87.306

Epoch 16: Validation loss decreased (0.386998 --> 0.381783).  Saving model ...
	 Train_Loss: 0.4618 Train_Acc: 84.946 Val_Loss: 0.3818  BEST VAL Loss: 0.3818  Val_Acc: 87.568

Epoch 17: Validation loss decreased (0.381783 --> 0.376989).  Saving model ...
	 Train_Loss: 0.4567 Train_Acc: 85.138 Val_Loss: 0.3770  BEST VAL Loss: 0.3770  Val_Acc: 87.550

Epoch 18: Validation loss decreased (0.376989 --> 0.373180).  Saving model ...
	 Train_Loss: 0.4519 Train_Acc: 85.418 Val_Loss: 0.3732  BEST VAL Loss: 0.3732  Val_Acc: 87.080

Epoch 19: Validation loss decreased (0.373180 --> 0.370031).  Saving model ...
	 Train_Loss: 0.4474 Train_Acc: 85.487 Val_Loss: 0.3700  BEST VAL Loss: 0.3700  Val_Acc: 86.660

Epoch 20: Validation loss decreased (0.370031 --> 0.366024).  Saving model ...
	 Train_Loss: 0.4431 Train_Acc: 85.727 Val_Loss: 0.3660  BEST VAL Loss: 0.3660  Val_Acc: 88.046

Epoch 21: Validation loss decreased (0.366024 --> 0.362666).  Saving model ...
	 Train_Loss: 0.4391 Train_Acc: 85.904 Val_Loss: 0.3627  BEST VAL Loss: 0.3627  Val_Acc: 87.612

Epoch 22: Validation loss decreased (0.362666 --> 0.359465).  Saving model ...
	 Train_Loss: 0.4354 Train_Acc: 85.882 Val_Loss: 0.3595  BEST VAL Loss: 0.3595  Val_Acc: 87.816

Epoch 23: Validation loss decreased (0.359465 --> 0.356462).  Saving model ...
	 Train_Loss: 0.4320 Train_Acc: 85.976 Val_Loss: 0.3565  BEST VAL Loss: 0.3565  Val_Acc: 87.895

Epoch 24: Validation loss decreased (0.356462 --> 0.353593).  Saving model ...
	 Train_Loss: 0.4287 Train_Acc: 86.059 Val_Loss: 0.3536  BEST VAL Loss: 0.3536  Val_Acc: 88.095

Epoch 25: Validation loss decreased (0.353593 --> 0.351046).  Saving model ...
	 Train_Loss: 0.4255 Train_Acc: 86.210 Val_Loss: 0.3510  BEST VAL Loss: 0.3510  Val_Acc: 87.665

Epoch 26: Validation loss decreased (0.351046 --> 0.348400).  Saving model ...
	 Train_Loss: 0.4226 Train_Acc: 86.269 Val_Loss: 0.3484  BEST VAL Loss: 0.3484  Val_Acc: 88.183

Epoch 27: Validation loss decreased (0.348400 --> 0.346035).  Saving model ...
	 Train_Loss: 0.4198 Train_Acc: 86.311 Val_Loss: 0.3460  BEST VAL Loss: 0.3460  Val_Acc: 88.055

Epoch 28: Validation loss decreased (0.346035 --> 0.343814).  Saving model ...
	 Train_Loss: 0.4172 Train_Acc: 86.296 Val_Loss: 0.3438  BEST VAL Loss: 0.3438  Val_Acc: 88.161

Epoch 29: Validation loss decreased (0.343814 --> 0.341775).  Saving model ...
	 Train_Loss: 0.4147 Train_Acc: 86.144 Val_Loss: 0.3418  BEST VAL Loss: 0.3418  Val_Acc: 88.152

Epoch 30: Validation loss decreased (0.341775 --> 0.339668).  Saving model ...
	 Train_Loss: 0.4123 Train_Acc: 86.286 Val_Loss: 0.3397  BEST VAL Loss: 0.3397  Val_Acc: 88.303

Epoch 31: Validation loss decreased (0.339668 --> 0.337751).  Saving model ...
	 Train_Loss: 0.4099 Train_Acc: 86.363 Val_Loss: 0.3378  BEST VAL Loss: 0.3378  Val_Acc: 88.294

Epoch 32: Validation loss decreased (0.337751 --> 0.335892).  Saving model ...
	 Train_Loss: 0.4077 Train_Acc: 86.396 Val_Loss: 0.3359  BEST VAL Loss: 0.3359  Val_Acc: 88.347

Epoch 33: Validation loss decreased (0.335892 --> 0.334003).  Saving model ...
	 Train_Loss: 0.4056 Train_Acc: 86.481 Val_Loss: 0.3340  BEST VAL Loss: 0.3340  Val_Acc: 88.476

Epoch 34: Validation loss decreased (0.334003 --> 0.332312).  Saving model ...
	 Train_Loss: 0.4035 Train_Acc: 86.578 Val_Loss: 0.3323  BEST VAL Loss: 0.3323  Val_Acc: 88.418

Epoch 35: Validation loss decreased (0.332312 --> 0.330628).  Saving model ...
	 Train_Loss: 0.4015 Train_Acc: 86.705 Val_Loss: 0.3306  BEST VAL Loss: 0.3306  Val_Acc: 88.515

Epoch 36: Validation loss decreased (0.330628 --> 0.329152).  Saving model ...
	 Train_Loss: 0.3996 Train_Acc: 86.655 Val_Loss: 0.3292  BEST VAL Loss: 0.3292  Val_Acc: 88.294

Epoch 37: Validation loss decreased (0.329152 --> 0.327641).  Saving model ...
	 Train_Loss: 0.3977 Train_Acc: 86.864 Val_Loss: 0.3276  BEST VAL Loss: 0.3276  Val_Acc: 88.484

Epoch 38: Validation loss decreased (0.327641 --> 0.326167).  Saving model ...
	 Train_Loss: 0.3959 Train_Acc: 86.809 Val_Loss: 0.3262  BEST VAL Loss: 0.3262  Val_Acc: 88.582

Epoch 39: Validation loss decreased (0.326167 --> 0.324746).  Saving model ...
	 Train_Loss: 0.3942 Train_Acc: 86.972 Val_Loss: 0.3247  BEST VAL Loss: 0.3247  Val_Acc: 88.697

Epoch 40: Validation loss decreased (0.324746 --> 0.323532).  Saving model ...
	 Train_Loss: 0.3925 Train_Acc: 86.859 Val_Loss: 0.3235  BEST VAL Loss: 0.3235  Val_Acc: 88.489

Epoch 41: Validation loss decreased (0.323532 --> 0.322198).  Saving model ...
	 Train_Loss: 0.3909 Train_Acc: 87.030 Val_Loss: 0.3222  BEST VAL Loss: 0.3222  Val_Acc: 88.657

Epoch 42: Validation loss decreased (0.322198 --> 0.320894).  Saving model ...
	 Train_Loss: 0.3893 Train_Acc: 87.041 Val_Loss: 0.3209  BEST VAL Loss: 0.3209  Val_Acc: 88.569

Epoch 43: Validation loss decreased (0.320894 --> 0.319688).  Saving model ...
	 Train_Loss: 0.3878 Train_Acc: 87.036 Val_Loss: 0.3197  BEST VAL Loss: 0.3197  Val_Acc: 88.706

Epoch 44: Validation loss decreased (0.319688 --> 0.318448).  Saving model ...
	 Train_Loss: 0.3863 Train_Acc: 87.159 Val_Loss: 0.3184  BEST VAL Loss: 0.3184  Val_Acc: 88.861

Epoch 45: Validation loss decreased (0.318448 --> 0.317359).  Saving model ...
	 Train_Loss: 0.3849 Train_Acc: 87.184 Val_Loss: 0.3174  BEST VAL Loss: 0.3174  Val_Acc: 88.697

Epoch 46: Validation loss decreased (0.317359 --> 0.316188).  Saving model ...
	 Train_Loss: 0.3835 Train_Acc: 87.164 Val_Loss: 0.3162  BEST VAL Loss: 0.3162  Val_Acc: 88.923

Epoch 47: Validation loss decreased (0.316188 --> 0.315221).  Saving model ...
	 Train_Loss: 0.3821 Train_Acc: 87.186 Val_Loss: 0.3152  BEST VAL Loss: 0.3152  Val_Acc: 88.480

Epoch 48: Validation loss decreased (0.315221 --> 0.314195).  Saving model ...
	 Train_Loss: 0.3809 Train_Acc: 87.105 Val_Loss: 0.3142  BEST VAL Loss: 0.3142  Val_Acc: 88.839

Epoch 49: Validation loss decreased (0.314195 --> 0.313133).  Saving model ...
	 Train_Loss: 0.3797 Train_Acc: 87.197 Val_Loss: 0.3131  BEST VAL Loss: 0.3131  Val_Acc: 89.082

Epoch 50: Validation loss decreased (0.313133 --> 0.312123).  Saving model ...
	 Train_Loss: 0.3785 Train_Acc: 87.184 Val_Loss: 0.3121  BEST VAL Loss: 0.3121  Val_Acc: 89.065

Epoch 51: Validation loss decreased (0.312123 --> 0.311172).  Saving model ...
	 Train_Loss: 0.3773 Train_Acc: 87.244 Val_Loss: 0.3112  BEST VAL Loss: 0.3112  Val_Acc: 88.732

Epoch 52: Validation loss decreased (0.311172 --> 0.310226).  Saving model ...
	 Train_Loss: 0.3761 Train_Acc: 87.247 Val_Loss: 0.3102  BEST VAL Loss: 0.3102  Val_Acc: 88.856

Epoch 53: Validation loss decreased (0.310226 --> 0.309313).  Saving model ...
	 Train_Loss: 0.3750 Train_Acc: 87.328 Val_Loss: 0.3093  BEST VAL Loss: 0.3093  Val_Acc: 89.016

Epoch 54: Validation loss decreased (0.309313 --> 0.308385).  Saving model ...
	 Train_Loss: 0.3740 Train_Acc: 87.298 Val_Loss: 0.3084  BEST VAL Loss: 0.3084  Val_Acc: 89.078

Epoch 55: Validation loss decreased (0.308385 --> 0.307591).  Saving model ...
	 Train_Loss: 0.3729 Train_Acc: 87.429 Val_Loss: 0.3076  BEST VAL Loss: 0.3076  Val_Acc: 88.710

Epoch 56: Validation loss decreased (0.307591 --> 0.306771).  Saving model ...
	 Train_Loss: 0.3719 Train_Acc: 87.360 Val_Loss: 0.3068  BEST VAL Loss: 0.3068  Val_Acc: 89.166

Epoch 57: Validation loss decreased (0.306771 --> 0.305917).  Saving model ...
	 Train_Loss: 0.3709 Train_Acc: 87.505 Val_Loss: 0.3059  BEST VAL Loss: 0.3059  Val_Acc: 89.158

Epoch 58: Validation loss decreased (0.305917 --> 0.305143).  Saving model ...
	 Train_Loss: 0.3699 Train_Acc: 87.412 Val_Loss: 0.3051  BEST VAL Loss: 0.3051  Val_Acc: 88.896

Epoch 59: Validation loss decreased (0.305143 --> 0.304437).  Saving model ...
	 Train_Loss: 0.3690 Train_Acc: 87.468 Val_Loss: 0.3044  BEST VAL Loss: 0.3044  Val_Acc: 88.701

Epoch 60: Validation loss decreased (0.304437 --> 0.303735).  Saving model ...
	 Train_Loss: 0.3681 Train_Acc: 87.424 Val_Loss: 0.3037  BEST VAL Loss: 0.3037  Val_Acc: 89.162

Epoch 61: Validation loss decreased (0.303735 --> 0.303126).  Saving model ...
	 Train_Loss: 0.3672 Train_Acc: 87.510 Val_Loss: 0.3031  BEST VAL Loss: 0.3031  Val_Acc: 88.458

Epoch 62: Validation loss decreased (0.303126 --> 0.302416).  Saving model ...
	 Train_Loss: 0.3663 Train_Acc: 87.481 Val_Loss: 0.3024  BEST VAL Loss: 0.3024  Val_Acc: 89.228

Epoch 63: Validation loss decreased (0.302416 --> 0.301724).  Saving model ...
	 Train_Loss: 0.3654 Train_Acc: 87.586 Val_Loss: 0.3017  BEST VAL Loss: 0.3017  Val_Acc: 88.874

Epoch 64: Validation loss decreased (0.301724 --> 0.301083).  Saving model ...
	 Train_Loss: 0.3646 Train_Acc: 87.471 Val_Loss: 0.3011  BEST VAL Loss: 0.3011  Val_Acc: 88.786

Epoch 65: Validation loss decreased (0.301083 --> 0.300395).  Saving model ...
	 Train_Loss: 0.3638 Train_Acc: 87.620 Val_Loss: 0.3004  BEST VAL Loss: 0.3004  Val_Acc: 89.268

Epoch 66: Validation loss decreased (0.300395 --> 0.299708).  Saving model ...
	 Train_Loss: 0.3630 Train_Acc: 87.627 Val_Loss: 0.2997  BEST VAL Loss: 0.2997  Val_Acc: 89.104

Epoch 67: Validation loss decreased (0.299708 --> 0.299025).  Saving model ...
	 Train_Loss: 0.3622 Train_Acc: 87.539 Val_Loss: 0.2990  BEST VAL Loss: 0.2990  Val_Acc: 89.437

Epoch 68: Validation loss decreased (0.299025 --> 0.298410).  Saving model ...
	 Train_Loss: 0.3615 Train_Acc: 87.571 Val_Loss: 0.2984  BEST VAL Loss: 0.2984  Val_Acc: 89.113

Epoch 69: Validation loss decreased (0.298410 --> 0.297855).  Saving model ...
	 Train_Loss: 0.3607 Train_Acc: 87.647 Val_Loss: 0.2979  BEST VAL Loss: 0.2979  Val_Acc: 88.573

Epoch 70: Validation loss decreased (0.297855 --> 0.297209).  Saving model ...
	 Train_Loss: 0.3600 Train_Acc: 87.725 Val_Loss: 0.2972  BEST VAL Loss: 0.2972  Val_Acc: 89.472

Epoch 71: Validation loss decreased (0.297209 --> 0.296667).  Saving model ...
	 Train_Loss: 0.3592 Train_Acc: 87.772 Val_Loss: 0.2967  BEST VAL Loss: 0.2967  Val_Acc: 88.905

Epoch 72: Validation loss decreased (0.296667 --> 0.296074).  Saving model ...
	 Train_Loss: 0.3585 Train_Acc: 87.722 Val_Loss: 0.2961  BEST VAL Loss: 0.2961  Val_Acc: 89.211

Epoch 73: Validation loss decreased (0.296074 --> 0.295540).  Saving model ...
	 Train_Loss: 0.3578 Train_Acc: 87.745 Val_Loss: 0.2955  BEST VAL Loss: 0.2955  Val_Acc: 89.348

Epoch 74: Validation loss decreased (0.295540 --> 0.294999).  Saving model ...
	 Train_Loss: 0.3572 Train_Acc: 87.637 Val_Loss: 0.2950  BEST VAL Loss: 0.2950  Val_Acc: 88.949

Epoch 75: Validation loss decreased (0.294999 --> 0.294454).  Saving model ...
	 Train_Loss: 0.3565 Train_Acc: 87.726 Val_Loss: 0.2945  BEST VAL Loss: 0.2945  Val_Acc: 89.348

Epoch 76: Validation loss decreased (0.294454 --> 0.293903).  Saving model ...
	 Train_Loss: 0.3559 Train_Acc: 87.705 Val_Loss: 0.2939  BEST VAL Loss: 0.2939  Val_Acc: 89.153

Epoch 77: Validation loss decreased (0.293903 --> 0.293371).  Saving model ...
	 Train_Loss: 0.3552 Train_Acc: 87.905 Val_Loss: 0.2934  BEST VAL Loss: 0.2934  Val_Acc: 89.162

Epoch 78: Validation loss decreased (0.293371 --> 0.292886).  Saving model ...
	 Train_Loss: 0.3546 Train_Acc: 87.827 Val_Loss: 0.2929  BEST VAL Loss: 0.2929  Val_Acc: 89.189

Epoch 79: Validation loss decreased (0.292886 --> 0.292453).  Saving model ...
	 Train_Loss: 0.3540 Train_Acc: 87.817 Val_Loss: 0.2925  BEST VAL Loss: 0.2925  Val_Acc: 88.954

Epoch 80: Validation loss decreased (0.292453 --> 0.292003).  Saving model ...
	 Train_Loss: 0.3534 Train_Acc: 87.802 Val_Loss: 0.2920  BEST VAL Loss: 0.2920  Val_Acc: 89.220

Epoch 81: Validation loss decreased (0.292003 --> 0.291544).  Saving model ...
	 Train_Loss: 0.3528 Train_Acc: 87.994 Val_Loss: 0.2915  BEST VAL Loss: 0.2915  Val_Acc: 89.087

Epoch 82: Validation loss decreased (0.291544 --> 0.291037).  Saving model ...
	 Train_Loss: 0.3522 Train_Acc: 87.904 Val_Loss: 0.2910  BEST VAL Loss: 0.2910  Val_Acc: 89.383

Epoch 83: Validation loss decreased (0.291037 --> 0.290612).  Saving model ...
	 Train_Loss: 0.3516 Train_Acc: 87.949 Val_Loss: 0.2906  BEST VAL Loss: 0.2906  Val_Acc: 88.954

Epoch 84: Validation loss decreased (0.290612 --> 0.290142).  Saving model ...
	 Train_Loss: 0.3510 Train_Acc: 87.902 Val_Loss: 0.2901  BEST VAL Loss: 0.2901  Val_Acc: 89.330

Epoch 85: Validation loss decreased (0.290142 --> 0.289719).  Saving model ...
	 Train_Loss: 0.3505 Train_Acc: 87.936 Val_Loss: 0.2897  BEST VAL Loss: 0.2897  Val_Acc: 89.162

Epoch 86: Validation loss decreased (0.289719 --> 0.289273).  Saving model ...
	 Train_Loss: 0.3499 Train_Acc: 87.988 Val_Loss: 0.2893  BEST VAL Loss: 0.2893  Val_Acc: 89.100

Epoch 87: Validation loss decreased (0.289273 --> 0.288864).  Saving model ...
	 Train_Loss: 0.3494 Train_Acc: 88.027 Val_Loss: 0.2889  BEST VAL Loss: 0.2889  Val_Acc: 89.228

Epoch 88: Validation loss decreased (0.288864 --> 0.288466).  Saving model ...
	 Train_Loss: 0.3489 Train_Acc: 88.018 Val_Loss: 0.2885  BEST VAL Loss: 0.2885  Val_Acc: 89.370

Epoch 89: Validation loss decreased (0.288466 --> 0.288089).  Saving model ...
	 Train_Loss: 0.3483 Train_Acc: 88.191 Val_Loss: 0.2881  BEST VAL Loss: 0.2881  Val_Acc: 89.175

Epoch 90: Validation loss decreased (0.288089 --> 0.287671).  Saving model ...
	 Train_Loss: 0.3478 Train_Acc: 88.207 Val_Loss: 0.2877  BEST VAL Loss: 0.2877  Val_Acc: 89.313

Epoch 91: Validation loss decreased (0.287671 --> 0.287283).  Saving model ...
	 Train_Loss: 0.3473 Train_Acc: 88.177 Val_Loss: 0.2873  BEST VAL Loss: 0.2873  Val_Acc: 89.459

Epoch 92: Validation loss decreased (0.287283 --> 0.286902).  Saving model ...
	 Train_Loss: 0.3468 Train_Acc: 88.292 Val_Loss: 0.2869  BEST VAL Loss: 0.2869  Val_Acc: 89.406

Epoch 93: Validation loss decreased (0.286902 --> 0.286515).  Saving model ...
	 Train_Loss: 0.3463 Train_Acc: 88.248 Val_Loss: 0.2865  BEST VAL Loss: 0.2865  Val_Acc: 89.406

Epoch 94: Validation loss decreased (0.286515 --> 0.286149).  Saving model ...
	 Train_Loss: 0.3458 Train_Acc: 88.345 Val_Loss: 0.2861  BEST VAL Loss: 0.2861  Val_Acc: 89.357

Epoch 95: Validation loss decreased (0.286149 --> 0.285778).  Saving model ...
	 Train_Loss: 0.3453 Train_Acc: 88.343 Val_Loss: 0.2858  BEST VAL Loss: 0.2858  Val_Acc: 89.499

Epoch 96: Validation loss decreased (0.285778 --> 0.285461).  Saving model ...
	 Train_Loss: 0.3448 Train_Acc: 88.459 Val_Loss: 0.2855  BEST VAL Loss: 0.2855  Val_Acc: 89.264

Epoch 97: Validation loss decreased (0.285461 --> 0.285096).  Saving model ...
	 Train_Loss: 0.3443 Train_Acc: 88.413 Val_Loss: 0.2851  BEST VAL Loss: 0.2851  Val_Acc: 89.587

Epoch 98: Validation loss decreased (0.285096 --> 0.284743).  Saving model ...
	 Train_Loss: 0.3438 Train_Acc: 88.374 Val_Loss: 0.2847  BEST VAL Loss: 0.2847  Val_Acc: 89.530

Epoch 99: Validation loss decreased (0.284743 --> 0.284385).  Saving model ...
	 Train_Loss: 0.3434 Train_Acc: 88.344 Val_Loss: 0.2844  BEST VAL Loss: 0.2844  Val_Acc: 89.277

LPS_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.89      0.93      0.91     82968
           1       0.94      0.90      0.92     97655

    accuracy                           0.91    180623
   macro avg       0.91      0.91      0.91    180623
weighted avg       0.91      0.91      0.91    180623

LPS_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.86      0.91      0.89     10371
           1       0.92      0.88      0.90     12207

    accuracy                           0.89     22578
   macro avg       0.89      0.89      0.89     22578
weighted avg       0.89      0.89      0.89     22578

LPS_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.86      0.91      0.89     10371
           1       0.92      0.87      0.90     12207

    accuracy                           0.89     22578
   macro avg       0.89      0.89      0.89     22578
weighted avg       0.89      0.89      0.89     22578

              precision    recall  f1-score   support

           0       0.86      0.91      0.89     10371
           1       0.92      0.87      0.90     12207

    accuracy                           0.89     22578
   macro avg       0.89      0.89      0.89     22578
weighted avg       0.89      0.89      0.89     22578

LPS_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.78      0.84      0.81     34887
           1       0.86      0.82      0.84     44915

    accuracy                           0.82     79802
   macro avg       0.82      0.83      0.82     79802
weighted avg       0.83      0.82      0.82     79802

              precision    recall  f1-score   support

           0       0.78      0.84      0.81     34887
           1       0.86      0.82      0.84     44915

    accuracy                           0.82     79802
   macro avg       0.82      0.83      0.82     79802
weighted avg       0.83      0.82      0.82     79802

completed
