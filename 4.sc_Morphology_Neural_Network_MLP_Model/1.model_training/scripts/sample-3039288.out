[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '89179946'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '638bada6'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'f75154f3'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '50f10b82'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_1.000_DMSO_0.025 treatment_name: H2O2_100.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_1.000_DMSO_0.025
TREATMENT_NAME: H2O2_100.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['H2O2_100.000_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (42709, 1276)
Number of total missing values across all columns: 85418
Data Subset Is Off
Wells held out for testing: ['I22' 'M22']
Wells to use for training, validation, and testing ['H18' 'H19' 'H22' 'H23' 'I18' 'M18' 'I19' 'M19' 'I23' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.619031).  Saving model ...
	 Train_Loss: 0.6969 Train_Acc: 46.203 Val_Loss: 0.6190  BEST VAL Loss: 0.6190  Val_Acc: 66.872

Epoch 1: Validation loss decreased (0.619031 --> 0.589599).  Saving model ...
	 Train_Loss: 0.6490 Train_Acc: 69.458 Val_Loss: 0.5896  BEST VAL Loss: 0.5896  Val_Acc: 72.468

Epoch 2: Validation loss decreased (0.589599 --> 0.570058).  Saving model ...
	 Train_Loss: 0.6200 Train_Acc: 71.718 Val_Loss: 0.5701  BEST VAL Loss: 0.5701  Val_Acc: 73.475

Epoch 3: Validation loss decreased (0.570058 --> 0.554839).  Saving model ...
	 Train_Loss: 0.5990 Train_Acc: 72.564 Val_Loss: 0.5548  BEST VAL Loss: 0.5548  Val_Acc: 74.203

Epoch 4: Validation loss decreased (0.554839 --> 0.542499).  Saving model ...
	 Train_Loss: 0.5829 Train_Acc: 73.596 Val_Loss: 0.5425  BEST VAL Loss: 0.5425  Val_Acc: 75.350

Epoch 5: Validation loss decreased (0.542499 --> 0.531894).  Saving model ...
	 Train_Loss: 0.5695 Train_Acc: 74.058 Val_Loss: 0.5319  BEST VAL Loss: 0.5319  Val_Acc: 76.273

Epoch 6: Validation loss decreased (0.531894 --> 0.522921).  Saving model ...
	 Train_Loss: 0.5585 Train_Acc: 74.621 Val_Loss: 0.5229  BEST VAL Loss: 0.5229  Val_Acc: 76.637

Epoch 7: Validation loss decreased (0.522921 --> 0.514825).  Saving model ...
	 Train_Loss: 0.5489 Train_Acc: 74.957 Val_Loss: 0.5148  BEST VAL Loss: 0.5148  Val_Acc: 77.336

Epoch 8: Validation loss decreased (0.514825 --> 0.507661).  Saving model ...
	 Train_Loss: 0.5405 Train_Acc: 75.601 Val_Loss: 0.5077  BEST VAL Loss: 0.5077  Val_Acc: 77.980

Epoch 9: Validation loss decreased (0.507661 --> 0.501113).  Saving model ...
	 Train_Loss: 0.5328 Train_Acc: 76.279 Val_Loss: 0.5011  BEST VAL Loss: 0.5011  Val_Acc: 78.260

Epoch 10: Validation loss decreased (0.501113 --> 0.495280).  Saving model ...
	 Train_Loss: 0.5260 Train_Acc: 76.426 Val_Loss: 0.4953  BEST VAL Loss: 0.4953  Val_Acc: 78.707

Epoch 11: Validation loss decreased (0.495280 --> 0.490095).  Saving model ...
	 Train_Loss: 0.5197 Train_Acc: 76.661 Val_Loss: 0.4901  BEST VAL Loss: 0.4901  Val_Acc: 79.239

Epoch 12: Validation loss decreased (0.490095 --> 0.485111).  Saving model ...
	 Train_Loss: 0.5139 Train_Acc: 76.983 Val_Loss: 0.4851  BEST VAL Loss: 0.4851  Val_Acc: 79.827

Epoch 13: Validation loss decreased (0.485111 --> 0.480537).  Saving model ...
	 Train_Loss: 0.5086 Train_Acc: 76.972 Val_Loss: 0.4805  BEST VAL Loss: 0.4805  Val_Acc: 80.106

Epoch 14: Validation loss decreased (0.480537 --> 0.476317).  Saving model ...
	 Train_Loss: 0.5037 Train_Acc: 77.122 Val_Loss: 0.4763  BEST VAL Loss: 0.4763  Val_Acc: 80.162

Epoch 15: Validation loss decreased (0.476317 --> 0.472379).  Saving model ...
	 Train_Loss: 0.4993 Train_Acc: 77.539 Val_Loss: 0.4724  BEST VAL Loss: 0.4724  Val_Acc: 80.498

Epoch 16: Validation loss decreased (0.472379 --> 0.468624).  Saving model ...
	 Train_Loss: 0.4950 Train_Acc: 77.616 Val_Loss: 0.4686  BEST VAL Loss: 0.4686  Val_Acc: 80.414

Epoch 17: Validation loss decreased (0.468624 --> 0.465305).  Saving model ...
	 Train_Loss: 0.4912 Train_Acc: 77.262 Val_Loss: 0.4653  BEST VAL Loss: 0.4653  Val_Acc: 80.666

Epoch 18: Validation loss decreased (0.465305 --> 0.462147).  Saving model ...
	 Train_Loss: 0.4875 Train_Acc: 77.714 Val_Loss: 0.4621  BEST VAL Loss: 0.4621  Val_Acc: 81.058

Epoch 19: Validation loss decreased (0.462147 --> 0.459171).  Saving model ...
	 Train_Loss: 0.4840 Train_Acc: 77.710 Val_Loss: 0.4592  BEST VAL Loss: 0.4592  Val_Acc: 80.722

Epoch 20: Validation loss decreased (0.459171 --> 0.456360).  Saving model ...
	 Train_Loss: 0.4805 Train_Acc: 78.210 Val_Loss: 0.4564  BEST VAL Loss: 0.4564  Val_Acc: 81.114

Epoch 21: Validation loss decreased (0.456360 --> 0.453679).  Saving model ...
	 Train_Loss: 0.4774 Train_Acc: 77.899 Val_Loss: 0.4537  BEST VAL Loss: 0.4537  Val_Acc: 81.701

Epoch 22: Validation loss decreased (0.453679 --> 0.451250).  Saving model ...
	 Train_Loss: 0.4743 Train_Acc: 78.333 Val_Loss: 0.4512  BEST VAL Loss: 0.4512  Val_Acc: 81.253

Epoch 23: Validation loss decreased (0.451250 --> 0.448978).  Saving model ...
	 Train_Loss: 0.4717 Train_Acc: 78.172 Val_Loss: 0.4490  BEST VAL Loss: 0.4490  Val_Acc: 81.925

Epoch 24: Validation loss decreased (0.448978 --> 0.446904).  Saving model ...
	 Train_Loss: 0.4689 Train_Acc: 78.385 Val_Loss: 0.4469  BEST VAL Loss: 0.4469  Val_Acc: 81.673

Epoch 25: Validation loss decreased (0.446904 --> 0.444761).  Saving model ...
	 Train_Loss: 0.4663 Train_Acc: 78.476 Val_Loss: 0.4448  BEST VAL Loss: 0.4448  Val_Acc: 82.373

Epoch 26: Validation loss decreased (0.444761 --> 0.442787).  Saving model ...
	 Train_Loss: 0.4639 Train_Acc: 78.438 Val_Loss: 0.4428  BEST VAL Loss: 0.4428  Val_Acc: 82.513

Epoch 27: Validation loss decreased (0.442787 --> 0.440866).  Saving model ...
	 Train_Loss: 0.4616 Train_Acc: 78.592 Val_Loss: 0.4409  BEST VAL Loss: 0.4409  Val_Acc: 81.673

Epoch 28: Validation loss decreased (0.440866 --> 0.439086).  Saving model ...
	 Train_Loss: 0.4593 Train_Acc: 78.882 Val_Loss: 0.4391  BEST VAL Loss: 0.4391  Val_Acc: 81.925

Epoch 29: Validation loss decreased (0.439086 --> 0.437334).  Saving model ...
	 Train_Loss: 0.4571 Train_Acc: 78.665 Val_Loss: 0.4373  BEST VAL Loss: 0.4373  Val_Acc: 82.541

Epoch 30: Validation loss decreased (0.437334 --> 0.435718).  Saving model ...
	 Train_Loss: 0.4551 Train_Acc: 78.613 Val_Loss: 0.4357  BEST VAL Loss: 0.4357  Val_Acc: 82.121

Epoch 31: Validation loss decreased (0.435718 --> 0.434082).  Saving model ...
	 Train_Loss: 0.4531 Train_Acc: 78.469 Val_Loss: 0.4341  BEST VAL Loss: 0.4341  Val_Acc: 82.625

Epoch 32: Validation loss decreased (0.434082 --> 0.432562).  Saving model ...
	 Train_Loss: 0.4512 Train_Acc: 78.571 Val_Loss: 0.4326  BEST VAL Loss: 0.4326  Val_Acc: 82.597

Epoch 33: Validation loss decreased (0.432562 --> 0.431136).  Saving model ...
	 Train_Loss: 0.4494 Train_Acc: 78.798 Val_Loss: 0.4311  BEST VAL Loss: 0.4311  Val_Acc: 82.373

Epoch 34: Validation loss decreased (0.431136 --> 0.429719).  Saving model ...
	 Train_Loss: 0.4477 Train_Acc: 78.903 Val_Loss: 0.4297  BEST VAL Loss: 0.4297  Val_Acc: 82.736

Epoch 35: Validation loss decreased (0.429719 --> 0.428402).  Saving model ...
	 Train_Loss: 0.4459 Train_Acc: 78.840 Val_Loss: 0.4284  BEST VAL Loss: 0.4284  Val_Acc: 82.820

Epoch 36: Validation loss decreased (0.428402 --> 0.427139).  Saving model ...
	 Train_Loss: 0.4443 Train_Acc: 78.861 Val_Loss: 0.4271  BEST VAL Loss: 0.4271  Val_Acc: 82.820

Epoch 37: Validation loss decreased (0.427139 --> 0.425817).  Saving model ...
	 Train_Loss: 0.4427 Train_Acc: 78.952 Val_Loss: 0.4258  BEST VAL Loss: 0.4258  Val_Acc: 83.128

Epoch 38: Validation loss decreased (0.425817 --> 0.424613).  Saving model ...
	 Train_Loss: 0.4412 Train_Acc: 80.043 Val_Loss: 0.4246  BEST VAL Loss: 0.4246  Val_Acc: 83.212

Epoch 39: Validation loss decreased (0.424613 --> 0.423444).  Saving model ...
	 Train_Loss: 0.4398 Train_Acc: 80.795 Val_Loss: 0.4234  BEST VAL Loss: 0.4234  Val_Acc: 82.792

Epoch 40: Validation loss decreased (0.423444 --> 0.422369).  Saving model ...
	 Train_Loss: 0.4383 Train_Acc: 81.086 Val_Loss: 0.4224  BEST VAL Loss: 0.4224  Val_Acc: 82.680

Epoch 41: Validation loss decreased (0.422369 --> 0.421389).  Saving model ...
	 Train_Loss: 0.4368 Train_Acc: 81.345 Val_Loss: 0.4214  BEST VAL Loss: 0.4214  Val_Acc: 82.792

Epoch 42: Validation loss decreased (0.421389 --> 0.420423).  Saving model ...
	 Train_Loss: 0.4355 Train_Acc: 81.019 Val_Loss: 0.4204  BEST VAL Loss: 0.4204  Val_Acc: 82.960

Epoch 43: Validation loss decreased (0.420423 --> 0.419432).  Saving model ...
	 Train_Loss: 0.4342 Train_Acc: 80.981 Val_Loss: 0.4194  BEST VAL Loss: 0.4194  Val_Acc: 82.820

Epoch 44: Validation loss decreased (0.419432 --> 0.418533).  Saving model ...
	 Train_Loss: 0.4329 Train_Acc: 81.016 Val_Loss: 0.4185  BEST VAL Loss: 0.4185  Val_Acc: 82.848

Epoch 45: Validation loss decreased (0.418533 --> 0.417644).  Saving model ...
	 Train_Loss: 0.4317 Train_Acc: 81.037 Val_Loss: 0.4176  BEST VAL Loss: 0.4176  Val_Acc: 83.128

Epoch 46: Validation loss decreased (0.417644 --> 0.416781).  Saving model ...
	 Train_Loss: 0.4305 Train_Acc: 80.981 Val_Loss: 0.4168  BEST VAL Loss: 0.4168  Val_Acc: 83.464

Epoch 47: Validation loss decreased (0.416781 --> 0.416024).  Saving model ...
	 Train_Loss: 0.4293 Train_Acc: 81.016 Val_Loss: 0.4160  BEST VAL Loss: 0.4160  Val_Acc: 83.492

Epoch 48: Validation loss decreased (0.416024 --> 0.415235).  Saving model ...
	 Train_Loss: 0.4282 Train_Acc: 81.282 Val_Loss: 0.4152  BEST VAL Loss: 0.4152  Val_Acc: 83.044

Epoch 49: Validation loss decreased (0.415235 --> 0.414437).  Saving model ...
	 Train_Loss: 0.4270 Train_Acc: 81.205 Val_Loss: 0.4144  BEST VAL Loss: 0.4144  Val_Acc: 83.296

Epoch 50: Validation loss decreased (0.414437 --> 0.413663).  Saving model ...
	 Train_Loss: 0.4259 Train_Acc: 81.380 Val_Loss: 0.4137  BEST VAL Loss: 0.4137  Val_Acc: 83.212

Epoch 51: Validation loss decreased (0.413663 --> 0.412904).  Saving model ...
	 Train_Loss: 0.4249 Train_Acc: 81.296 Val_Loss: 0.4129  BEST VAL Loss: 0.4129  Val_Acc: 83.184

Epoch 52: Validation loss decreased (0.412904 --> 0.412165).  Saving model ...
	 Train_Loss: 0.4238 Train_Acc: 81.586 Val_Loss: 0.4122  BEST VAL Loss: 0.4122  Val_Acc: 83.492

Epoch 53: Validation loss decreased (0.412165 --> 0.411478).  Saving model ...
	 Train_Loss: 0.4228 Train_Acc: 81.320 Val_Loss: 0.4115  BEST VAL Loss: 0.4115  Val_Acc: 83.380

Epoch 54: Validation loss decreased (0.411478 --> 0.410831).  Saving model ...
	 Train_Loss: 0.4218 Train_Acc: 81.621 Val_Loss: 0.4108  BEST VAL Loss: 0.4108  Val_Acc: 83.828

Epoch 55: Validation loss decreased (0.410831 --> 0.410186).  Saving model ...
	 Train_Loss: 0.4208 Train_Acc: 81.457 Val_Loss: 0.4102  BEST VAL Loss: 0.4102  Val_Acc: 83.716

Epoch 56: Validation loss decreased (0.410186 --> 0.409585).  Saving model ...
	 Train_Loss: 0.4198 Train_Acc: 81.820 Val_Loss: 0.4096  BEST VAL Loss: 0.4096  Val_Acc: 83.212

Epoch 57: Validation loss decreased (0.409585 --> 0.408959).  Saving model ...
	 Train_Loss: 0.4189 Train_Acc: 81.708 Val_Loss: 0.4090  BEST VAL Loss: 0.4090  Val_Acc: 83.184

Epoch 58: Validation loss decreased (0.408959 --> 0.408358).  Saving model ...
	 Train_Loss: 0.4180 Train_Acc: 81.485 Val_Loss: 0.4084  BEST VAL Loss: 0.4084  Val_Acc: 83.464

Epoch 59: Validation loss decreased (0.408358 --> 0.407807).  Saving model ...
	 Train_Loss: 0.4171 Train_Acc: 81.590 Val_Loss: 0.4078  BEST VAL Loss: 0.4078  Val_Acc: 83.380

Epoch 60: Validation loss decreased (0.407807 --> 0.407222).  Saving model ...
	 Train_Loss: 0.4163 Train_Acc: 81.971 Val_Loss: 0.4072  BEST VAL Loss: 0.4072  Val_Acc: 83.772

Epoch 61: Validation loss decreased (0.407222 --> 0.406737).  Saving model ...
	 Train_Loss: 0.4154 Train_Acc: 81.621 Val_Loss: 0.4067  BEST VAL Loss: 0.4067  Val_Acc: 83.352

Epoch 62: Validation loss decreased (0.406737 --> 0.406214).  Saving model ...
	 Train_Loss: 0.4146 Train_Acc: 81.883 Val_Loss: 0.4062  BEST VAL Loss: 0.4062  Val_Acc: 83.968

Epoch 63: Validation loss decreased (0.406214 --> 0.405764).  Saving model ...
	 Train_Loss: 0.4138 Train_Acc: 81.810 Val_Loss: 0.4058  BEST VAL Loss: 0.4058  Val_Acc: 83.324

Epoch 64: Validation loss decreased (0.405764 --> 0.405294).  Saving model ...
	 Train_Loss: 0.4129 Train_Acc: 82.076 Val_Loss: 0.4053  BEST VAL Loss: 0.4053  Val_Acc: 83.464

Epoch 65: Validation loss decreased (0.405294 --> 0.404850).  Saving model ...
	 Train_Loss: 0.4121 Train_Acc: 82.083 Val_Loss: 0.4048  BEST VAL Loss: 0.4048  Val_Acc: 83.296

Epoch 66: Validation loss decreased (0.404850 --> 0.404345).  Saving model ...
	 Train_Loss: 0.4114 Train_Acc: 81.866 Val_Loss: 0.4043  BEST VAL Loss: 0.4043  Val_Acc: 84.135

Epoch 67: Validation loss decreased (0.404345 --> 0.403888).  Saving model ...
	 Train_Loss: 0.4106 Train_Acc: 82.184 Val_Loss: 0.4039  BEST VAL Loss: 0.4039  Val_Acc: 83.884

Epoch 68: Validation loss decreased (0.403888 --> 0.403466).  Saving model ...
	 Train_Loss: 0.4099 Train_Acc: 82.013 Val_Loss: 0.4035  BEST VAL Loss: 0.4035  Val_Acc: 83.576

Epoch 69: Validation loss decreased (0.403466 --> 0.403094).  Saving model ...
	 Train_Loss: 0.4091 Train_Acc: 82.174 Val_Loss: 0.4031  BEST VAL Loss: 0.4031  Val_Acc: 83.968

Epoch 70: Validation loss decreased (0.403094 --> 0.402676).  Saving model ...
	 Train_Loss: 0.4084 Train_Acc: 82.058 Val_Loss: 0.4027  BEST VAL Loss: 0.4027  Val_Acc: 83.772

Epoch 71: Validation loss decreased (0.402676 --> 0.402243).  Saving model ...
	 Train_Loss: 0.4077 Train_Acc: 82.282 Val_Loss: 0.4022  BEST VAL Loss: 0.4022  Val_Acc: 83.996

Epoch 72: Validation loss decreased (0.402243 --> 0.401862).  Saving model ...
	 Train_Loss: 0.4071 Train_Acc: 81.729 Val_Loss: 0.4019  BEST VAL Loss: 0.4019  Val_Acc: 83.352

Epoch 73: Validation loss decreased (0.401862 --> 0.401511).  Saving model ...
	 Train_Loss: 0.4064 Train_Acc: 82.079 Val_Loss: 0.4015  BEST VAL Loss: 0.4015  Val_Acc: 83.772

Epoch 74: Validation loss decreased (0.401511 --> 0.401156).  Saving model ...
	 Train_Loss: 0.4057 Train_Acc: 82.356 Val_Loss: 0.4012  BEST VAL Loss: 0.4012  Val_Acc: 83.744

Epoch 75: Validation loss decreased (0.401156 --> 0.400859).  Saving model ...
	 Train_Loss: 0.4051 Train_Acc: 82.209 Val_Loss: 0.4009  BEST VAL Loss: 0.4009  Val_Acc: 83.632

Epoch 76: Validation loss decreased (0.400859 --> 0.400517).  Saving model ...
	 Train_Loss: 0.4044 Train_Acc: 82.321 Val_Loss: 0.4005  BEST VAL Loss: 0.4005  Val_Acc: 84.024

Epoch 77: Validation loss decreased (0.400517 --> 0.400182).  Saving model ...
	 Train_Loss: 0.4038 Train_Acc: 82.247 Val_Loss: 0.4002  BEST VAL Loss: 0.4002  Val_Acc: 83.856

Epoch 78: Validation loss decreased (0.400182 --> 0.399856).  Saving model ...
	 Train_Loss: 0.4032 Train_Acc: 82.475 Val_Loss: 0.3999  BEST VAL Loss: 0.3999  Val_Acc: 83.632

Epoch 79: Validation loss decreased (0.399856 --> 0.399556).  Saving model ...
	 Train_Loss: 0.4025 Train_Acc: 82.660 Val_Loss: 0.3996  BEST VAL Loss: 0.3996  Val_Acc: 83.884

Epoch 80: Validation loss decreased (0.399556 --> 0.399294).  Saving model ...
	 Train_Loss: 0.4019 Train_Acc: 82.174 Val_Loss: 0.3993  BEST VAL Loss: 0.3993  Val_Acc: 82.764

Epoch 81: Validation loss decreased (0.399294 --> 0.398948).  Saving model ...
	 Train_Loss: 0.4013 Train_Acc: 82.093 Val_Loss: 0.3989  BEST VAL Loss: 0.3989  Val_Acc: 83.912

Epoch 82: Validation loss decreased (0.398948 --> 0.398685).  Saving model ...
	 Train_Loss: 0.4008 Train_Acc: 82.258 Val_Loss: 0.3987  BEST VAL Loss: 0.3987  Val_Acc: 83.772

Epoch 83: Validation loss decreased (0.398685 --> 0.398394).  Saving model ...
	 Train_Loss: 0.4002 Train_Acc: 82.121 Val_Loss: 0.3984  BEST VAL Loss: 0.3984  Val_Acc: 83.184

Epoch 84: Validation loss decreased (0.398394 --> 0.398101).  Saving model ...
	 Train_Loss: 0.3996 Train_Acc: 82.349 Val_Loss: 0.3981  BEST VAL Loss: 0.3981  Val_Acc: 83.604

Epoch 85: Validation loss decreased (0.398101 --> 0.397824).  Saving model ...
	 Train_Loss: 0.3991 Train_Acc: 82.265 Val_Loss: 0.3978  BEST VAL Loss: 0.3978  Val_Acc: 83.464

Epoch 86: Validation loss decreased (0.397824 --> 0.397570).  Saving model ...
	 Train_Loss: 0.3985 Train_Acc: 82.216 Val_Loss: 0.3976  BEST VAL Loss: 0.3976  Val_Acc: 83.044

Epoch 87: Validation loss decreased (0.397570 --> 0.397278).  Saving model ...
	 Train_Loss: 0.3980 Train_Acc: 82.443 Val_Loss: 0.3973  BEST VAL Loss: 0.3973  Val_Acc: 83.688

Epoch 88: Validation loss decreased (0.397278 --> 0.397069).  Saving model ...
	 Train_Loss: 0.3974 Train_Acc: 82.359 Val_Loss: 0.3971  BEST VAL Loss: 0.3971  Val_Acc: 82.960

Epoch 89: Validation loss decreased (0.397069 --> 0.396818).  Saving model ...
	 Train_Loss: 0.3969 Train_Acc: 82.471 Val_Loss: 0.3968  BEST VAL Loss: 0.3968  Val_Acc: 84.079

Epoch 90: Validation loss decreased (0.396818 --> 0.396603).  Saving model ...
	 Train_Loss: 0.3964 Train_Acc: 82.289 Val_Loss: 0.3966  BEST VAL Loss: 0.3966  Val_Acc: 83.548

Epoch 91: Validation loss decreased (0.396603 --> 0.396365).  Saving model ...
	 Train_Loss: 0.3958 Train_Acc: 82.552 Val_Loss: 0.3964  BEST VAL Loss: 0.3964  Val_Acc: 83.380

Epoch 92: Validation loss decreased (0.396365 --> 0.396160).  Saving model ...
	 Train_Loss: 0.3953 Train_Acc: 82.663 Val_Loss: 0.3962  BEST VAL Loss: 0.3962  Val_Acc: 83.492

Epoch 93: Validation loss decreased (0.396160 --> 0.395918).  Saving model ...
	 Train_Loss: 0.3948 Train_Acc: 82.457 Val_Loss: 0.3959  BEST VAL Loss: 0.3959  Val_Acc: 83.660

Epoch 94: Validation loss decreased (0.395918 --> 0.395693).  Saving model ...
	 Train_Loss: 0.3943 Train_Acc: 82.663 Val_Loss: 0.3957  BEST VAL Loss: 0.3957  Val_Acc: 83.660

Epoch 95: Validation loss decreased (0.395693 --> 0.395503).  Saving model ...
	 Train_Loss: 0.3938 Train_Acc: 82.506 Val_Loss: 0.3955  BEST VAL Loss: 0.3955  Val_Acc: 83.772

Epoch 96: Validation loss decreased (0.395503 --> 0.395313).  Saving model ...
	 Train_Loss: 0.3933 Train_Acc: 82.912 Val_Loss: 0.3953  BEST VAL Loss: 0.3953  Val_Acc: 83.632

Epoch 97: Validation loss decreased (0.395313 --> 0.395103).  Saving model ...
	 Train_Loss: 0.3928 Train_Acc: 82.359 Val_Loss: 0.3951  BEST VAL Loss: 0.3951  Val_Acc: 83.520

Epoch 98: Validation loss decreased (0.395103 --> 0.394888).  Saving model ...
	 Train_Loss: 0.3924 Train_Acc: 82.485 Val_Loss: 0.3949  BEST VAL Loss: 0.3949  Val_Acc: 83.772

Epoch 99: Validation loss decreased (0.394888 --> 0.394707).  Saving model ...
	 Train_Loss: 0.3919 Train_Acc: 82.450 Val_Loss: 0.3947  BEST VAL Loss: 0.3947  Val_Acc: 83.324

Flagellin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.79      0.82      0.81      9434
           1       0.91      0.90      0.90     19153

    accuracy                           0.87     28587
   macro avg       0.85      0.86      0.86     28587
weighted avg       0.87      0.87      0.87     28587

Flagellin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.73      0.77      0.75      1179
           1       0.89      0.86      0.87      2395

    accuracy                           0.83      3574
   macro avg       0.81      0.82      0.81      3574
weighted avg       0.84      0.83      0.83      3574

Flagellin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.72      0.74      0.73      1179
           1       0.87      0.86      0.86      2395

    accuracy                           0.82      3574
   macro avg       0.80      0.80      0.80      3574
weighted avg       0.82      0.82      0.82      3574

              precision    recall  f1-score   support

           0       0.72      0.74      0.73      1179
           1       0.87      0.86      0.86      2395

    accuracy                           0.82      3574
   macro avg       0.80      0.80      0.80      3574
weighted avg       0.82      0.82      0.82      3574

Flagellin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.40      0.56      4017
           1       0.54      0.96      0.69      2957

    accuracy                           0.64      6974
   macro avg       0.74      0.68      0.63      6974
weighted avg       0.77      0.64      0.62      6974

              precision    recall  f1-score   support

           0       0.93      0.40      0.56      4017
           1       0.54      0.96      0.69      2957

    accuracy                           0.64      6974
   macro avg       0.74      0.68      0.63      6974
weighted avg       0.77      0.64      0.62      6974

completed
