[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd4bce22b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '3034a517'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd8dc723a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'b8238a7d'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_1.000_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_1.000_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_1.000_DMSO_0.025']
The dimensions of the data are: (33968, 1276)
Number of total missing values across all columns: 67936
Data Subset Is Off
Wells held out for testing: ['C20' 'D21']
Wells to use for training, validation, and testing ['C16' 'D16' 'C17' 'D17' 'D20' 'C21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.684067).  Saving model ...
	 Train_Loss: 0.6945 Train_Acc: 52.192 Val_Loss: 0.6841  BEST VAL Loss: 0.6841  Val_Acc: 58.594

Epoch 1: Validation loss decreased (0.684067 --> 0.680260).  Saving model ...
	 Train_Loss: 0.6884 Train_Acc: 55.688 Val_Loss: 0.6803  BEST VAL Loss: 0.6803  Val_Acc: 59.883

Epoch 2: Validation loss decreased (0.680260 --> 0.679410).  Saving model ...
	 Train_Loss: 0.6813 Train_Acc: 59.746 Val_Loss: 0.6794  BEST VAL Loss: 0.6794  Val_Acc: 60.352

Epoch 3: Validation loss did not decrease
	 Train_Loss: 0.6753 Train_Acc: 61.646 Val_Loss: 0.6799  BEST VAL Loss: 0.6794  Val_Acc: 62.695

Epoch 4: Validation loss did not decrease
	 Train_Loss: 0.6695 Train_Acc: 63.198 Val_Loss: 0.6811  BEST VAL Loss: 0.6794  Val_Acc: 62.188

Epoch 5: Validation loss did not decrease
	 Train_Loss: 0.6646 Train_Acc: 64.062 Val_Loss: 0.6812  BEST VAL Loss: 0.6794  Val_Acc: 62.656

Epoch 6: Validation loss did not decrease
	 Train_Loss: 0.6602 Train_Acc: 65.015 Val_Loss: 0.6817  BEST VAL Loss: 0.6794  Val_Acc: 62.734

Epoch 7: Validation loss did not decrease
	 Train_Loss: 0.6565 Train_Acc: 65.405 Val_Loss: 0.6811  BEST VAL Loss: 0.6794  Val_Acc: 63.555

Epoch 8: Validation loss did not decrease
	 Train_Loss: 0.6529 Train_Acc: 65.884 Val_Loss: 0.6815  BEST VAL Loss: 0.6794  Val_Acc: 64.531

Epoch 9: Validation loss did not decrease
	 Train_Loss: 0.6492 Train_Acc: 66.211 Val_Loss: 0.6819  BEST VAL Loss: 0.6794  Val_Acc: 62.695

Epoch 10: Validation loss did not decrease
	 Train_Loss: 0.6461 Train_Acc: 66.797 Val_Loss: 0.6824  BEST VAL Loss: 0.6794  Val_Acc: 63.086

Epoch 11: Validation loss did not decrease
	 Train_Loss: 0.6432 Train_Acc: 66.904 Val_Loss: 0.6825  BEST VAL Loss: 0.6794  Val_Acc: 64.805

Epoch 12: Validation loss did not decrease
	 Train_Loss: 0.6403 Train_Acc: 67.129 Val_Loss: 0.6827  BEST VAL Loss: 0.6794  Val_Acc: 65.156

Epoch 13: Validation loss did not decrease
	 Train_Loss: 0.6377 Train_Acc: 67.524 Val_Loss: 0.6824  BEST VAL Loss: 0.6794  Val_Acc: 65.039

Epoch 14: Validation loss did not decrease
	 Train_Loss: 0.6351 Train_Acc: 67.925 Val_Loss: 0.6820  BEST VAL Loss: 0.6794  Val_Acc: 65.625

Epoch 15: Validation loss did not decrease
	 Train_Loss: 0.6323 Train_Acc: 68.335 Val_Loss: 0.6816  BEST VAL Loss: 0.6794  Val_Acc: 65.703

Epoch 16: Validation loss did not decrease
	 Train_Loss: 0.6298 Train_Acc: 68.779 Val_Loss: 0.6814  BEST VAL Loss: 0.6794  Val_Acc: 63.867

Epoch 17: Validation loss did not decrease
	 Train_Loss: 0.6274 Train_Acc: 69.233 Val_Loss: 0.6801  BEST VAL Loss: 0.6794  Val_Acc: 67.812

Epoch 18: Validation loss decreased (0.679410 --> 0.679098).  Saving model ...
	 Train_Loss: 0.6251 Train_Acc: 68.882 Val_Loss: 0.6791  BEST VAL Loss: 0.6791  Val_Acc: 66.836

Epoch 19: Validation loss decreased (0.679098 --> 0.678488).  Saving model ...
	 Train_Loss: 0.6228 Train_Acc: 69.482 Val_Loss: 0.6785  BEST VAL Loss: 0.6785  Val_Acc: 66.562

Epoch 20: Validation loss decreased (0.678488 --> 0.678194).  Saving model ...
	 Train_Loss: 0.6208 Train_Acc: 69.287 Val_Loss: 0.6782  BEST VAL Loss: 0.6782  Val_Acc: 66.797

Epoch 21: Validation loss decreased (0.678194 --> 0.677689).  Saving model ...
	 Train_Loss: 0.6188 Train_Acc: 69.351 Val_Loss: 0.6777  BEST VAL Loss: 0.6777  Val_Acc: 66.953

Epoch 22: Validation loss decreased (0.677689 --> 0.676980).  Saving model ...
	 Train_Loss: 0.6168 Train_Acc: 70.000 Val_Loss: 0.6770  BEST VAL Loss: 0.6770  Val_Acc: 67.422

Epoch 23: Validation loss decreased (0.676980 --> 0.676566).  Saving model ...
	 Train_Loss: 0.6149 Train_Acc: 70.415 Val_Loss: 0.6766  BEST VAL Loss: 0.6766  Val_Acc: 67.852

Epoch 24: Validation loss decreased (0.676566 --> 0.676198).  Saving model ...
	 Train_Loss: 0.6130 Train_Acc: 70.151 Val_Loss: 0.6762  BEST VAL Loss: 0.6762  Val_Acc: 67.148

Epoch 25: Validation loss decreased (0.676198 --> 0.675503).  Saving model ...
	 Train_Loss: 0.6112 Train_Acc: 70.659 Val_Loss: 0.6755  BEST VAL Loss: 0.6755  Val_Acc: 67.812

Epoch 26: Validation loss decreased (0.675503 --> 0.675454).  Saving model ...
	 Train_Loss: 0.6092 Train_Acc: 70.757 Val_Loss: 0.6755  BEST VAL Loss: 0.6755  Val_Acc: 67.695

Epoch 27: Validation loss decreased (0.675454 --> 0.675323).  Saving model ...
	 Train_Loss: 0.6074 Train_Acc: 71.016 Val_Loss: 0.6753  BEST VAL Loss: 0.6753  Val_Acc: 68.047

Epoch 28: Validation loss decreased (0.675323 --> 0.674913).  Saving model ...
	 Train_Loss: 0.6057 Train_Acc: 70.874 Val_Loss: 0.6749  BEST VAL Loss: 0.6749  Val_Acc: 68.203

Epoch 29: Validation loss decreased (0.674913 --> 0.674669).  Saving model ...
	 Train_Loss: 0.6041 Train_Acc: 71.245 Val_Loss: 0.6747  BEST VAL Loss: 0.6747  Val_Acc: 67.695

Epoch 30: Validation loss decreased (0.674669 --> 0.674576).  Saving model ...
	 Train_Loss: 0.6023 Train_Acc: 71.660 Val_Loss: 0.6746  BEST VAL Loss: 0.6746  Val_Acc: 68.281

Epoch 31: Validation loss decreased (0.674576 --> 0.674184).  Saving model ...
	 Train_Loss: 0.6008 Train_Acc: 71.509 Val_Loss: 0.6742  BEST VAL Loss: 0.6742  Val_Acc: 68.203

Epoch 32: Validation loss decreased (0.674184 --> 0.673974).  Saving model ...
	 Train_Loss: 0.5993 Train_Acc: 71.553 Val_Loss: 0.6740  BEST VAL Loss: 0.6740  Val_Acc: 68.047

Epoch 33: Validation loss decreased (0.673974 --> 0.673904).  Saving model ...
	 Train_Loss: 0.5979 Train_Acc: 71.553 Val_Loss: 0.6739  BEST VAL Loss: 0.6739  Val_Acc: 68.359

Epoch 34: Validation loss decreased (0.673904 --> 0.673693).  Saving model ...
	 Train_Loss: 0.5964 Train_Acc: 72.246 Val_Loss: 0.6737  BEST VAL Loss: 0.6737  Val_Acc: 68.984

Epoch 35: Validation loss decreased (0.673693 --> 0.673553).  Saving model ...
	 Train_Loss: 0.5949 Train_Acc: 72.500 Val_Loss: 0.6736  BEST VAL Loss: 0.6736  Val_Acc: 68.359

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.5934 Train_Acc: 72.759 Val_Loss: 0.6737  BEST VAL Loss: 0.6736  Val_Acc: 68.281

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.5921 Train_Acc: 72.310 Val_Loss: 0.6738  BEST VAL Loss: 0.6736  Val_Acc: 68.398

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.5908 Train_Acc: 71.655 Val_Loss: 0.6737  BEST VAL Loss: 0.6736  Val_Acc: 69.180

Epoch 39: Validation loss decreased (0.673553 --> 0.673553).  Saving model ...
	 Train_Loss: 0.5896 Train_Acc: 72.725 Val_Loss: 0.6736  BEST VAL Loss: 0.6736  Val_Acc: 68.359

Epoch 40: Validation loss decreased (0.673553 --> 0.673485).  Saving model ...
	 Train_Loss: 0.5884 Train_Acc: 72.451 Val_Loss: 0.6735  BEST VAL Loss: 0.6735  Val_Acc: 68.750

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.5873 Train_Acc: 72.153 Val_Loss: 0.6736  BEST VAL Loss: 0.6735  Val_Acc: 68.672

Epoch 42: Validation loss decreased (0.673485 --> 0.673479).  Saving model ...
	 Train_Loss: 0.5861 Train_Acc: 72.290 Val_Loss: 0.6735  BEST VAL Loss: 0.6735  Val_Acc: 68.008

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.5850 Train_Acc: 72.212 Val_Loss: 0.6736  BEST VAL Loss: 0.6735  Val_Acc: 68.359

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.5840 Train_Acc: 72.749 Val_Loss: 0.6740  BEST VAL Loss: 0.6735  Val_Acc: 67.773

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.5828 Train_Acc: 72.837 Val_Loss: 0.6745  BEST VAL Loss: 0.6735  Val_Acc: 68.633

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.5817 Train_Acc: 73.188 Val_Loss: 0.6748  BEST VAL Loss: 0.6735  Val_Acc: 68.164

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.5806 Train_Acc: 72.769 Val_Loss: 0.6750  BEST VAL Loss: 0.6735  Val_Acc: 68.359

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.5796 Train_Acc: 73.105 Val_Loss: 0.6749  BEST VAL Loss: 0.6735  Val_Acc: 68.242

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.5786 Train_Acc: 72.646 Val_Loss: 0.6752  BEST VAL Loss: 0.6735  Val_Acc: 68.281

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.5777 Train_Acc: 72.949 Val_Loss: 0.6755  BEST VAL Loss: 0.6735  Val_Acc: 68.906

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.5768 Train_Acc: 72.471 Val_Loss: 0.6760  BEST VAL Loss: 0.6735  Val_Acc: 68.008

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.5758 Train_Acc: 73.110 Val_Loss: 0.6762  BEST VAL Loss: 0.6735  Val_Acc: 68.906

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.5749 Train_Acc: 73.091 Val_Loss: 0.6765  BEST VAL Loss: 0.6735  Val_Acc: 68.242

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.5740 Train_Acc: 73.232 Val_Loss: 0.6768  BEST VAL Loss: 0.6735  Val_Acc: 68.984

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.5731 Train_Acc: 73.252 Val_Loss: 0.6775  BEST VAL Loss: 0.6735  Val_Acc: 68.594

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.5723 Train_Acc: 73.066 Val_Loss: 0.6777  BEST VAL Loss: 0.6735  Val_Acc: 68.555

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.5714 Train_Acc: 73.364 Val_Loss: 0.6780  BEST VAL Loss: 0.6735  Val_Acc: 69.141

Epoch 58: Validation loss did not decrease
Early stopped at epoch : 58
LPS_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.76      0.81      0.78     10452
           1       0.79      0.73      0.76     10028

    accuracy                           0.77     20480
   macro avg       0.77      0.77      0.77     20480
weighted avg       0.77      0.77      0.77     20480

LPS_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.68      0.72      0.70      1307
           1       0.68      0.64      0.66      1253

    accuracy                           0.68      2560
   macro avg       0.68      0.68      0.68      2560
weighted avg       0.68      0.68      0.68      2560

LPS_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.67      0.71      0.69      1306
           1       0.68      0.64      0.66      1254

    accuracy                           0.67      2560
   macro avg       0.67      0.67      0.67      2560
weighted avg       0.67      0.67      0.67      2560

              precision    recall  f1-score   support

           0       0.67      0.71      0.69      1306
           1       0.68      0.64      0.66      1254

    accuracy                           0.67      2560
   macro avg       0.67      0.67      0.67      2560
weighted avg       0.67      0.67      0.67      2560

LPS_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.64      0.79      0.70      4445
           1       0.67      0.49      0.57      3923

    accuracy                           0.65      8368
   macro avg       0.65      0.64      0.64      8368
weighted avg       0.65      0.65      0.64      8368

              precision    recall  f1-score   support

           0       0.64      0.79      0.70      4445
           1       0.67      0.49      0.57      3923

    accuracy                           0.65      8368
   macro avg       0.65      0.64      0.64      8368
weighted avg       0.65      0.65      0.64      8368

completed
