[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '713d39b6'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '9f600017'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd0fe6026'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'ff84c58c'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_0.100_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_100.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (30915, 1276)
Number of total missing values across all columns: 61830
Data Subset Is Off
Wells held out for testing: ['J16' 'L22']
Wells to use for training, validation, and testing ['J17' 'L18' 'L19' 'J20' 'J21' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.546918).  Saving model ...
	 Train_Loss: 0.6529 Train_Acc: 58.646 Val_Loss: 0.5469  BEST VAL Loss: 0.5469  Val_Acc: 80.203

Epoch 1: Validation loss decreased (0.546918 --> 0.466194).  Saving model ...
	 Train_Loss: 0.5973 Train_Acc: 70.608 Val_Loss: 0.4662  BEST VAL Loss: 0.4662  Val_Acc: 85.891

Epoch 2: Validation loss decreased (0.466194 --> 0.397296).  Saving model ...
	 Train_Loss: 0.5367 Train_Acc: 80.161 Val_Loss: 0.3973  BEST VAL Loss: 0.3973  Val_Acc: 90.256

Epoch 3: Validation loss decreased (0.397296 --> 0.349554).  Saving model ...
	 Train_Loss: 0.4889 Train_Acc: 84.703 Val_Loss: 0.3496  BEST VAL Loss: 0.3496  Val_Acc: 91.667

Epoch 4: Validation loss decreased (0.349554 --> 0.316698).  Saving model ...
	 Train_Loss: 0.4530 Train_Acc: 86.462 Val_Loss: 0.3167  BEST VAL Loss: 0.3167  Val_Acc: 93.078

Epoch 5: Validation loss decreased (0.316698 --> 0.295319).  Saving model ...
	 Train_Loss: 0.4266 Train_Acc: 86.925 Val_Loss: 0.2953  BEST VAL Loss: 0.2953  Val_Acc: 93.871

Epoch 6: Validation loss decreased (0.295319 --> 0.277806).  Saving model ...
	 Train_Loss: 0.4046 Train_Acc: 88.121 Val_Loss: 0.2778  BEST VAL Loss: 0.2778  Val_Acc: 93.342

Epoch 7: Validation loss decreased (0.277806 --> 0.263765).  Saving model ...
	 Train_Loss: 0.3868 Train_Acc: 88.771 Val_Loss: 0.2638  BEST VAL Loss: 0.2638  Val_Acc: 93.430

Epoch 8: Validation loss decreased (0.263765 --> 0.251865).  Saving model ...
	 Train_Loss: 0.3719 Train_Acc: 89.262 Val_Loss: 0.2519  BEST VAL Loss: 0.2519  Val_Acc: 94.268

Epoch 9: Validation loss decreased (0.251865 --> 0.242095).  Saving model ...
	 Train_Loss: 0.3593 Train_Acc: 89.615 Val_Loss: 0.2421  BEST VAL Loss: 0.2421  Val_Acc: 94.048

Epoch 10: Validation loss decreased (0.242095 --> 0.235680).  Saving model ...
	 Train_Loss: 0.3486 Train_Acc: 89.212 Val_Loss: 0.2357  BEST VAL Loss: 0.2357  Val_Acc: 94.092

Epoch 11: Validation loss decreased (0.235680 --> 0.229058).  Saving model ...
	 Train_Loss: 0.3396 Train_Acc: 89.775 Val_Loss: 0.2291  BEST VAL Loss: 0.2291  Val_Acc: 94.312

Epoch 12: Validation loss decreased (0.229058 --> 0.222535).  Saving model ...
	 Train_Loss: 0.3317 Train_Acc: 89.835 Val_Loss: 0.2225  BEST VAL Loss: 0.2225  Val_Acc: 94.533

Epoch 13: Validation loss decreased (0.222535 --> 0.217676).  Saving model ...
	 Train_Loss: 0.3241 Train_Acc: 90.386 Val_Loss: 0.2177  BEST VAL Loss: 0.2177  Val_Acc: 94.136

Epoch 14: Validation loss decreased (0.217676 --> 0.213128).  Saving model ...
	 Train_Loss: 0.3175 Train_Acc: 90.221 Val_Loss: 0.2131  BEST VAL Loss: 0.2131  Val_Acc: 94.489

Epoch 15: Validation loss decreased (0.213128 --> 0.209704).  Saving model ...
	 Train_Loss: 0.3121 Train_Acc: 89.356 Val_Loss: 0.2097  BEST VAL Loss: 0.2097  Val_Acc: 94.136

Epoch 16: Validation loss decreased (0.209704 --> 0.206281).  Saving model ...
	 Train_Loss: 0.3067 Train_Acc: 89.626 Val_Loss: 0.2063  BEST VAL Loss: 0.2063  Val_Acc: 94.400

Epoch 17: Validation loss decreased (0.206281 --> 0.202725).  Saving model ...
	 Train_Loss: 0.3013 Train_Acc: 90.111 Val_Loss: 0.2027  BEST VAL Loss: 0.2027  Val_Acc: 95.459

Epoch 18: Validation loss decreased (0.202725 --> 0.199394).  Saving model ...
	 Train_Loss: 0.2964 Train_Acc: 90.100 Val_Loss: 0.1994  BEST VAL Loss: 0.1994  Val_Acc: 94.753

Epoch 19: Validation loss decreased (0.199394 --> 0.196962).  Saving model ...
	 Train_Loss: 0.2918 Train_Acc: 90.381 Val_Loss: 0.1970  BEST VAL Loss: 0.1970  Val_Acc: 94.489

Epoch 20: Validation loss decreased (0.196962 --> 0.195186).  Saving model ...
	 Train_Loss: 0.2877 Train_Acc: 90.177 Val_Loss: 0.1952  BEST VAL Loss: 0.1952  Val_Acc: 94.444

Epoch 21: Validation loss decreased (0.195186 --> 0.193734).  Saving model ...
	 Train_Loss: 0.2841 Train_Acc: 90.050 Val_Loss: 0.1937  BEST VAL Loss: 0.1937  Val_Acc: 94.665

Epoch 22: Validation loss decreased (0.193734 --> 0.192505).  Saving model ...
	 Train_Loss: 0.2808 Train_Acc: 89.786 Val_Loss: 0.1925  BEST VAL Loss: 0.1925  Val_Acc: 94.444

Epoch 23: Validation loss decreased (0.192505 --> 0.190948).  Saving model ...
	 Train_Loss: 0.2776 Train_Acc: 90.045 Val_Loss: 0.1909  BEST VAL Loss: 0.1909  Val_Acc: 94.621

Epoch 24: Validation loss decreased (0.190948 --> 0.189820).  Saving model ...
	 Train_Loss: 0.2743 Train_Acc: 90.866 Val_Loss: 0.1898  BEST VAL Loss: 0.1898  Val_Acc: 94.929

Epoch 25: Validation loss decreased (0.189820 --> 0.188964).  Saving model ...
	 Train_Loss: 0.2716 Train_Acc: 90.827 Val_Loss: 0.1890  BEST VAL Loss: 0.1890  Val_Acc: 94.533

Epoch 26: Validation loss decreased (0.188964 --> 0.187977).  Saving model ...
	 Train_Loss: 0.2691 Train_Acc: 90.177 Val_Loss: 0.1880  BEST VAL Loss: 0.1880  Val_Acc: 95.106

Epoch 27: Validation loss decreased (0.187977 --> 0.186829).  Saving model ...
	 Train_Loss: 0.2664 Train_Acc: 90.486 Val_Loss: 0.1868  BEST VAL Loss: 0.1868  Val_Acc: 94.885

Epoch 28: Validation loss decreased (0.186829 --> 0.185870).  Saving model ...
	 Train_Loss: 0.2641 Train_Acc: 90.673 Val_Loss: 0.1859  BEST VAL Loss: 0.1859  Val_Acc: 94.621

Epoch 29: Validation loss decreased (0.185870 --> 0.185410).  Saving model ...
	 Train_Loss: 0.2621 Train_Acc: 90.050 Val_Loss: 0.1854  BEST VAL Loss: 0.1854  Val_Acc: 94.489

Epoch 30: Validation loss decreased (0.185410 --> 0.184964).  Saving model ...
	 Train_Loss: 0.2601 Train_Acc: 90.568 Val_Loss: 0.1850  BEST VAL Loss: 0.1850  Val_Acc: 94.753

Epoch 31: Validation loss decreased (0.184964 --> 0.184642).  Saving model ...
	 Train_Loss: 0.2580 Train_Acc: 91.219 Val_Loss: 0.1846  BEST VAL Loss: 0.1846  Val_Acc: 95.018

Epoch 32: Validation loss decreased (0.184642 --> 0.183659).  Saving model ...
	 Train_Loss: 0.2561 Train_Acc: 90.629 Val_Loss: 0.1837  BEST VAL Loss: 0.1837  Val_Acc: 94.709

Epoch 33: Validation loss decreased (0.183659 --> 0.182910).  Saving model ...
	 Train_Loss: 0.2545 Train_Acc: 90.199 Val_Loss: 0.1829  BEST VAL Loss: 0.1829  Val_Acc: 94.797

Epoch 34: Validation loss decreased (0.182910 --> 0.182071).  Saving model ...
	 Train_Loss: 0.2527 Train_Acc: 90.265 Val_Loss: 0.1821  BEST VAL Loss: 0.1821  Val_Acc: 95.238

Epoch 35: Validation loss decreased (0.182071 --> 0.181240).  Saving model ...
	 Train_Loss: 0.2510 Train_Acc: 90.557 Val_Loss: 0.1812  BEST VAL Loss: 0.1812  Val_Acc: 94.929

Epoch 36: Validation loss decreased (0.181240 --> 0.180340).  Saving model ...
	 Train_Loss: 0.2496 Train_Acc: 90.772 Val_Loss: 0.1803  BEST VAL Loss: 0.1803  Val_Acc: 95.106

Epoch 37: Validation loss decreased (0.180340 --> 0.179641).  Saving model ...
	 Train_Loss: 0.2479 Train_Acc: 90.778 Val_Loss: 0.1796  BEST VAL Loss: 0.1796  Val_Acc: 95.150

Epoch 38: Validation loss decreased (0.179641 --> 0.179033).  Saving model ...
	 Train_Loss: 0.2461 Train_Acc: 91.042 Val_Loss: 0.1790  BEST VAL Loss: 0.1790  Val_Acc: 95.018

Epoch 39: Validation loss decreased (0.179033 --> 0.178244).  Saving model ...
	 Train_Loss: 0.2446 Train_Acc: 90.750 Val_Loss: 0.1782  BEST VAL Loss: 0.1782  Val_Acc: 94.665

Epoch 40: Validation loss decreased (0.178244 --> 0.177831).  Saving model ...
	 Train_Loss: 0.2433 Train_Acc: 90.767 Val_Loss: 0.1778  BEST VAL Loss: 0.1778  Val_Acc: 94.709

Epoch 41: Validation loss decreased (0.177831 --> 0.177454).  Saving model ...
	 Train_Loss: 0.2420 Train_Acc: 90.359 Val_Loss: 0.1775  BEST VAL Loss: 0.1775  Val_Acc: 94.533

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.2406 Train_Acc: 90.767 Val_Loss: 0.1775  BEST VAL Loss: 0.1775  Val_Acc: 94.621

Epoch 43: Validation loss decreased (0.177454 --> 0.177224).  Saving model ...
	 Train_Loss: 0.2395 Train_Acc: 90.282 Val_Loss: 0.1772  BEST VAL Loss: 0.1772  Val_Acc: 95.106

Epoch 44: Validation loss decreased (0.177224 --> 0.177011).  Saving model ...
	 Train_Loss: 0.2385 Train_Acc: 90.166 Val_Loss: 0.1770  BEST VAL Loss: 0.1770  Val_Acc: 94.797

Epoch 45: Validation loss decreased (0.177011 --> 0.176523).  Saving model ...
	 Train_Loss: 0.2373 Train_Acc: 90.563 Val_Loss: 0.1765  BEST VAL Loss: 0.1765  Val_Acc: 95.238

Epoch 46: Validation loss decreased (0.176523 --> 0.176246).  Saving model ...
	 Train_Loss: 0.2362 Train_Acc: 90.408 Val_Loss: 0.1762  BEST VAL Loss: 0.1762  Val_Acc: 95.370

Epoch 47: Validation loss decreased (0.176246 --> 0.175897).  Saving model ...
	 Train_Loss: 0.2350 Train_Acc: 91.285 Val_Loss: 0.1759  BEST VAL Loss: 0.1759  Val_Acc: 95.194

Epoch 48: Validation loss decreased (0.175897 --> 0.175883).  Saving model ...
	 Train_Loss: 0.2339 Train_Acc: 91.296 Val_Loss: 0.1759  BEST VAL Loss: 0.1759  Val_Acc: 94.533

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.2330 Train_Acc: 90.932 Val_Loss: 0.1760  BEST VAL Loss: 0.1759  Val_Acc: 94.841

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.2322 Train_Acc: 90.271 Val_Loss: 0.1762  BEST VAL Loss: 0.1759  Val_Acc: 95.018

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.2314 Train_Acc: 90.238 Val_Loss: 0.1765  BEST VAL Loss: 0.1759  Val_Acc: 95.326

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.2305 Train_Acc: 90.502 Val_Loss: 0.1766  BEST VAL Loss: 0.1759  Val_Acc: 94.929

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.2297 Train_Acc: 90.530 Val_Loss: 0.1769  BEST VAL Loss: 0.1759  Val_Acc: 95.062

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.2288 Train_Acc: 90.684 Val_Loss: 0.1771  BEST VAL Loss: 0.1759  Val_Acc: 94.621

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.2279 Train_Acc: 91.009 Val_Loss: 0.1773  BEST VAL Loss: 0.1759  Val_Acc: 94.665

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.2272 Train_Acc: 91.114 Val_Loss: 0.1773  BEST VAL Loss: 0.1759  Val_Acc: 94.577

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.2264 Train_Acc: 90.552 Val_Loss: 0.1769  BEST VAL Loss: 0.1759  Val_Acc: 94.929

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.2257 Train_Acc: 91.191 Val_Loss: 0.1767  BEST VAL Loss: 0.1759  Val_Acc: 95.062

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.2249 Train_Acc: 90.894 Val_Loss: 0.1765  BEST VAL Loss: 0.1759  Val_Acc: 95.018

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.2242 Train_Acc: 91.566 Val_Loss: 0.1762  BEST VAL Loss: 0.1759  Val_Acc: 95.150

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.2235 Train_Acc: 91.125 Val_Loss: 0.1762  BEST VAL Loss: 0.1759  Val_Acc: 94.665

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.2227 Train_Acc: 91.009 Val_Loss: 0.1763  BEST VAL Loss: 0.1759  Val_Acc: 95.106

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.2220 Train_Acc: 91.346 Val_Loss: 0.1763  BEST VAL Loss: 0.1759  Val_Acc: 94.665

Epoch 64: Validation loss did not decrease
Early stopped at epoch : 64
Flagellin_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.99      0.98      8635
           1       0.99      0.97      0.98      9506

    accuracy                           0.98     18141
   macro avg       0.98      0.98      0.98     18141
weighted avg       0.98      0.98      0.98     18141

Flagellin_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.96      0.94      1079
           1       0.96      0.93      0.95      1189

    accuracy                           0.95      2268
   macro avg       0.95      0.95      0.95      2268
weighted avg       0.95      0.95      0.95      2268

Flagellin_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.96      0.95      1079
           1       0.96      0.94      0.95      1189

    accuracy                           0.95      2268
   macro avg       0.95      0.95      0.95      2268
weighted avg       0.95      0.95      0.95      2268

              precision    recall  f1-score   support

           0       0.93      0.96      0.95      1079
           1       0.96      0.94      0.95      1189

    accuracy                           0.95      2268
   macro avg       0.95      0.95      0.95      2268
weighted avg       0.95      0.95      0.95      2268

Flagellin_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.95      0.92      0.93      4135
           1       0.92      0.95      0.93      4103

    accuracy                           0.93      8238
   macro avg       0.93      0.93      0.93      8238
weighted avg       0.93      0.93      0.93      8238

              precision    recall  f1-score   support

           0       0.95      0.92      0.93      4135
           1       0.92      0.95      0.93      4103

    accuracy                           0.93      8238
   macro avg       0.93      0.93      0.93      8238
weighted avg       0.93      0.93      0.93      8238

completed
