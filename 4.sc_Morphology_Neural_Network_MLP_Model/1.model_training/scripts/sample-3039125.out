[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '800853f7'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '09207331'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'f0ca844b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '985b489e'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_100.000_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_100.000_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (31846, 1276)
Number of total missing values across all columns: 63692
Data Subset Is Off
Wells held out for testing: ['B20' 'J16']
Wells to use for training, validation, and testing ['B16' 'B17' 'B21' 'J17' 'J20' 'J21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.290192).  Saving model ...
	 Train_Loss: 0.4188 Train_Acc: 79.428 Val_Loss: 0.2902  BEST VAL Loss: 0.2902  Val_Acc: 89.134

Epoch 1: Validation loss decreased (0.290192 --> 0.259783).  Saving model ...
	 Train_Loss: 0.3481 Train_Acc: 88.493 Val_Loss: 0.2598  BEST VAL Loss: 0.2598  Val_Acc: 91.216

Epoch 2: Validation loss decreased (0.259783 --> 0.235633).  Saving model ...
	 Train_Loss: 0.3061 Train_Acc: 91.007 Val_Loss: 0.2356  BEST VAL Loss: 0.2356  Val_Acc: 92.631

Epoch 3: Validation loss decreased (0.235633 --> 0.215265).  Saving model ...
	 Train_Loss: 0.2778 Train_Acc: 91.887 Val_Loss: 0.2153  BEST VAL Loss: 0.2153  Val_Acc: 94.088

Epoch 4: Validation loss decreased (0.215265 --> 0.200528).  Saving model ...
	 Train_Loss: 0.2565 Train_Acc: 93.094 Val_Loss: 0.2005  BEST VAL Loss: 0.2005  Val_Acc: 94.380

Epoch 5: Validation loss decreased (0.200528 --> 0.188719).  Saving model ...
	 Train_Loss: 0.2401 Train_Acc: 93.609 Val_Loss: 0.1887  BEST VAL Loss: 0.1887  Val_Acc: 95.087

Epoch 6: Validation loss decreased (0.188719 --> 0.180640).  Saving model ...
	 Train_Loss: 0.2267 Train_Acc: 94.182 Val_Loss: 0.1806  BEST VAL Loss: 0.1806  Val_Acc: 94.754

Epoch 7: Validation loss decreased (0.180640 --> 0.172414).  Saving model ...
	 Train_Loss: 0.2154 Train_Acc: 94.317 Val_Loss: 0.1724  BEST VAL Loss: 0.1724  Val_Acc: 95.545

Epoch 8: Validation loss decreased (0.172414 --> 0.165904).  Saving model ...
	 Train_Loss: 0.2054 Train_Acc: 94.733 Val_Loss: 0.1659  BEST VAL Loss: 0.1659  Val_Acc: 95.379

Epoch 9: Validation loss decreased (0.165904 --> 0.160181).  Saving model ...
	 Train_Loss: 0.1970 Train_Acc: 94.988 Val_Loss: 0.1602  BEST VAL Loss: 0.1602  Val_Acc: 95.962

Epoch 10: Validation loss decreased (0.160181 --> 0.155029).  Saving model ...
	 Train_Loss: 0.1898 Train_Acc: 95.170 Val_Loss: 0.1550  BEST VAL Loss: 0.1550  Val_Acc: 95.837

Epoch 11: Validation loss decreased (0.155029 --> 0.150866).  Saving model ...
	 Train_Loss: 0.1830 Train_Acc: 95.321 Val_Loss: 0.1509  BEST VAL Loss: 0.1509  Val_Acc: 96.045

Epoch 12: Validation loss decreased (0.150866 --> 0.146773).  Saving model ...
	 Train_Loss: 0.1771 Train_Acc: 95.722 Val_Loss: 0.1468  BEST VAL Loss: 0.1468  Val_Acc: 95.962

Epoch 13: Validation loss decreased (0.146773 --> 0.143160).  Saving model ...
	 Train_Loss: 0.1719 Train_Acc: 95.571 Val_Loss: 0.1432  BEST VAL Loss: 0.1432  Val_Acc: 96.378

Epoch 14: Validation loss decreased (0.143160 --> 0.139948).  Saving model ...
	 Train_Loss: 0.1671 Train_Acc: 95.868 Val_Loss: 0.1399  BEST VAL Loss: 0.1399  Val_Acc: 96.211

Epoch 15: Validation loss decreased (0.139948 --> 0.137226).  Saving model ...
	 Train_Loss: 0.1627 Train_Acc: 95.899 Val_Loss: 0.1372  BEST VAL Loss: 0.1372  Val_Acc: 96.211

Epoch 16: Validation loss decreased (0.137226 --> 0.134834).  Saving model ...
	 Train_Loss: 0.1585 Train_Acc: 96.185 Val_Loss: 0.1348  BEST VAL Loss: 0.1348  Val_Acc: 96.503

Epoch 17: Validation loss decreased (0.134834 --> 0.132574).  Saving model ...
	 Train_Loss: 0.1547 Train_Acc: 96.232 Val_Loss: 0.1326  BEST VAL Loss: 0.1326  Val_Acc: 96.586

Epoch 18: Validation loss decreased (0.132574 --> 0.130459).  Saving model ...
	 Train_Loss: 0.1511 Train_Acc: 96.487 Val_Loss: 0.1305  BEST VAL Loss: 0.1305  Val_Acc: 96.586

Epoch 19: Validation loss decreased (0.130459 --> 0.128868).  Saving model ...
	 Train_Loss: 0.1478 Train_Acc: 96.451 Val_Loss: 0.1289  BEST VAL Loss: 0.1289  Val_Acc: 96.253

Epoch 20: Validation loss decreased (0.128868 --> 0.127215).  Saving model ...
	 Train_Loss: 0.1447 Train_Acc: 96.565 Val_Loss: 0.1272  BEST VAL Loss: 0.1272  Val_Acc: 96.461

Epoch 21: Validation loss decreased (0.127215 --> 0.125613).  Saving model ...
	 Train_Loss: 0.1417 Train_Acc: 96.648 Val_Loss: 0.1256  BEST VAL Loss: 0.1256  Val_Acc: 96.794

Epoch 22: Validation loss decreased (0.125613 --> 0.124404).  Saving model ...
	 Train_Loss: 0.1390 Train_Acc: 96.581 Val_Loss: 0.1244  BEST VAL Loss: 0.1244  Val_Acc: 96.586

Epoch 23: Validation loss decreased (0.124404 --> 0.123213).  Saving model ...
	 Train_Loss: 0.1363 Train_Acc: 96.888 Val_Loss: 0.1232  BEST VAL Loss: 0.1232  Val_Acc: 96.586

Epoch 24: Validation loss decreased (0.123213 --> 0.121904).  Saving model ...
	 Train_Loss: 0.1338 Train_Acc: 96.805 Val_Loss: 0.1219  BEST VAL Loss: 0.1219  Val_Acc: 96.628

Epoch 25: Validation loss decreased (0.121904 --> 0.120908).  Saving model ...
	 Train_Loss: 0.1313 Train_Acc: 96.935 Val_Loss: 0.1209  BEST VAL Loss: 0.1209  Val_Acc: 96.628

Epoch 26: Validation loss decreased (0.120908 --> 0.119968).  Saving model ...
	 Train_Loss: 0.1290 Train_Acc: 97.060 Val_Loss: 0.1200  BEST VAL Loss: 0.1200  Val_Acc: 96.461

Epoch 27: Validation loss decreased (0.119968 --> 0.118855).  Saving model ...
	 Train_Loss: 0.1270 Train_Acc: 96.867 Val_Loss: 0.1189  BEST VAL Loss: 0.1189  Val_Acc: 96.794

Epoch 28: Validation loss decreased (0.118855 --> 0.117976).  Saving model ...
	 Train_Loss: 0.1248 Train_Acc: 97.002 Val_Loss: 0.1180  BEST VAL Loss: 0.1180  Val_Acc: 96.545

Epoch 29: Validation loss decreased (0.117976 --> 0.117292).  Saving model ...
	 Train_Loss: 0.1229 Train_Acc: 97.148 Val_Loss: 0.1173  BEST VAL Loss: 0.1173  Val_Acc: 96.919

Epoch 30: Validation loss decreased (0.117292 --> 0.116576).  Saving model ...
	 Train_Loss: 0.1211 Train_Acc: 96.950 Val_Loss: 0.1166  BEST VAL Loss: 0.1166  Val_Acc: 96.836

Epoch 31: Validation loss decreased (0.116576 --> 0.115972).  Saving model ...
	 Train_Loss: 0.1193 Train_Acc: 97.320 Val_Loss: 0.1160  BEST VAL Loss: 0.1160  Val_Acc: 96.878

Epoch 32: Validation loss decreased (0.115972 --> 0.115586).  Saving model ...
	 Train_Loss: 0.1176 Train_Acc: 97.268 Val_Loss: 0.1156  BEST VAL Loss: 0.1156  Val_Acc: 96.128

Epoch 33: Validation loss decreased (0.115586 --> 0.114968).  Saving model ...
	 Train_Loss: 0.1160 Train_Acc: 96.971 Val_Loss: 0.1150  BEST VAL Loss: 0.1150  Val_Acc: 96.503

Epoch 34: Validation loss decreased (0.114968 --> 0.114334).  Saving model ...
	 Train_Loss: 0.1144 Train_Acc: 97.434 Val_Loss: 0.1143  BEST VAL Loss: 0.1143  Val_Acc: 96.836

Epoch 35: Validation loss decreased (0.114334 --> 0.113716).  Saving model ...
	 Train_Loss: 0.1129 Train_Acc: 97.247 Val_Loss: 0.1137  BEST VAL Loss: 0.1137  Val_Acc: 96.919

Epoch 36: Validation loss decreased (0.113716 --> 0.113165).  Saving model ...
	 Train_Loss: 0.1114 Train_Acc: 97.351 Val_Loss: 0.1132  BEST VAL Loss: 0.1132  Val_Acc: 96.628

Epoch 37: Validation loss decreased (0.113165 --> 0.113045).  Saving model ...
	 Train_Loss: 0.1099 Train_Acc: 97.398 Val_Loss: 0.1130  BEST VAL Loss: 0.1130  Val_Acc: 96.128

Epoch 38: Validation loss decreased (0.113045 --> 0.112628).  Saving model ...
	 Train_Loss: 0.1085 Train_Acc: 97.450 Val_Loss: 0.1126  BEST VAL Loss: 0.1126  Val_Acc: 96.711

Epoch 39: Validation loss decreased (0.112628 --> 0.112094).  Saving model ...
	 Train_Loss: 0.1072 Train_Acc: 97.273 Val_Loss: 0.1121  BEST VAL Loss: 0.1121  Val_Acc: 96.919

Epoch 40: Validation loss decreased (0.112094 --> 0.111881).  Saving model ...
	 Train_Loss: 0.1060 Train_Acc: 97.320 Val_Loss: 0.1119  BEST VAL Loss: 0.1119  Val_Acc: 96.669

Epoch 41: Validation loss decreased (0.111881 --> 0.111621).  Saving model ...
	 Train_Loss: 0.1049 Train_Acc: 97.283 Val_Loss: 0.1116  BEST VAL Loss: 0.1116  Val_Acc: 96.420

Epoch 42: Validation loss decreased (0.111621 --> 0.111404).  Saving model ...
	 Train_Loss: 0.1037 Train_Acc: 97.429 Val_Loss: 0.1114  BEST VAL Loss: 0.1114  Val_Acc: 96.461

Epoch 43: Validation loss decreased (0.111404 --> 0.111241).  Saving model ...
	 Train_Loss: 0.1025 Train_Acc: 97.440 Val_Loss: 0.1112  BEST VAL Loss: 0.1112  Val_Acc: 96.378

Epoch 44: Validation loss decreased (0.111241 --> 0.111006).  Saving model ...
	 Train_Loss: 0.1014 Train_Acc: 97.315 Val_Loss: 0.1110  BEST VAL Loss: 0.1110  Val_Acc: 96.253

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.1003 Train_Acc: 97.512 Val_Loss: 0.1110  BEST VAL Loss: 0.1110  Val_Acc: 96.420

Epoch 46: Validation loss decreased (0.111006 --> 0.110752).  Saving model ...
	 Train_Loss: 0.0992 Train_Acc: 97.575 Val_Loss: 0.1108  BEST VAL Loss: 0.1108  Val_Acc: 96.253

Epoch 47: Validation loss decreased (0.110752 --> 0.110723).  Saving model ...
	 Train_Loss: 0.0983 Train_Acc: 97.460 Val_Loss: 0.1107  BEST VAL Loss: 0.1107  Val_Acc: 96.461

Epoch 48: Validation loss decreased (0.110723 --> 0.110540).  Saving model ...
	 Train_Loss: 0.0972 Train_Acc: 97.731 Val_Loss: 0.1105  BEST VAL Loss: 0.1105  Val_Acc: 96.378

Epoch 49: Validation loss decreased (0.110540 --> 0.110482).  Saving model ...
	 Train_Loss: 0.0963 Train_Acc: 97.512 Val_Loss: 0.1105  BEST VAL Loss: 0.1105  Val_Acc: 96.295

Epoch 50: Validation loss decreased (0.110482 --> 0.110425).  Saving model ...
	 Train_Loss: 0.0953 Train_Acc: 97.585 Val_Loss: 0.1104  BEST VAL Loss: 0.1104  Val_Acc: 96.378

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.0944 Train_Acc: 97.721 Val_Loss: 0.1104  BEST VAL Loss: 0.1104  Val_Acc: 96.461

Epoch 52: Validation loss decreased (0.110425 --> 0.110417).  Saving model ...
	 Train_Loss: 0.0935 Train_Acc: 97.679 Val_Loss: 0.1104  BEST VAL Loss: 0.1104  Val_Acc: 96.336

Epoch 53: Validation loss decreased (0.110417 --> 0.110197).  Saving model ...
	 Train_Loss: 0.0927 Train_Acc: 97.486 Val_Loss: 0.1102  BEST VAL Loss: 0.1102  Val_Acc: 96.545

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.0919 Train_Acc: 97.564 Val_Loss: 0.1102  BEST VAL Loss: 0.1102  Val_Acc: 96.378

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.0911 Train_Acc: 97.377 Val_Loss: 0.1102  BEST VAL Loss: 0.1102  Val_Acc: 96.336

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.0903 Train_Acc: 97.642 Val_Loss: 0.1102  BEST VAL Loss: 0.1102  Val_Acc: 96.545

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.0896 Train_Acc: 97.700 Val_Loss: 0.1103  BEST VAL Loss: 0.1102  Val_Acc: 96.503

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.0888 Train_Acc: 97.840 Val_Loss: 0.1104  BEST VAL Loss: 0.1102  Val_Acc: 96.378

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.0881 Train_Acc: 97.668 Val_Loss: 0.1106  BEST VAL Loss: 0.1102  Val_Acc: 96.586

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.0874 Train_Acc: 97.668 Val_Loss: 0.1107  BEST VAL Loss: 0.1102  Val_Acc: 96.087

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.0867 Train_Acc: 97.882 Val_Loss: 0.1106  BEST VAL Loss: 0.1102  Val_Acc: 96.420

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.0860 Train_Acc: 97.668 Val_Loss: 0.1106  BEST VAL Loss: 0.1102  Val_Acc: 96.295

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.0854 Train_Acc: 97.721 Val_Loss: 0.1107  BEST VAL Loss: 0.1102  Val_Acc: 96.461

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.0847 Train_Acc: 97.616 Val_Loss: 0.1106  BEST VAL Loss: 0.1102  Val_Acc: 96.420

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.0841 Train_Acc: 97.747 Val_Loss: 0.1107  BEST VAL Loss: 0.1102  Val_Acc: 96.295

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.0835 Train_Acc: 97.903 Val_Loss: 0.1106  BEST VAL Loss: 0.1102  Val_Acc: 96.545

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.0829 Train_Acc: 97.747 Val_Loss: 0.1108  BEST VAL Loss: 0.1102  Val_Acc: 96.420

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.0823 Train_Acc: 97.700 Val_Loss: 0.1111  BEST VAL Loss: 0.1102  Val_Acc: 96.253

Epoch 69: Validation loss did not decrease
Early stopped at epoch : 69
LPS_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       1.00      0.98      0.99      9707
           1       0.98      1.00      0.99      9508

    accuracy                           0.99     19215
   macro avg       0.99      0.99      0.99     19215
weighted avg       0.99      0.99      0.99     19215

LPS_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.96      0.97      1214
           1       0.96      0.97      0.97      1188

    accuracy                           0.97      2402
   macro avg       0.97      0.97      0.97      2402
weighted avg       0.97      0.97      0.97      2402

LPS_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.97      0.97      1214
           1       0.97      0.98      0.97      1188

    accuracy                           0.97      2402
   macro avg       0.97      0.97      0.97      2402
weighted avg       0.97      0.97      0.97      2402

              precision    recall  f1-score   support

           0       0.98      0.97      0.97      1214
           1       0.97      0.98      0.97      1188

    accuracy                           0.97      2402
   macro avg       0.97      0.97      0.97      2402
weighted avg       0.97      0.97      0.97      2402

LPS_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.96      0.96      0.96      3724
           1       0.97      0.96      0.97      4103

    accuracy                           0.96      7827
   macro avg       0.96      0.96      0.96      7827
weighted avg       0.96      0.96      0.96      7827

              precision    recall  f1-score   support

           0       0.96      0.96      0.96      3724
           1       0.97      0.96      0.97      4103

    accuracy                           0.96      7827
   macro avg       0.96      0.96      0.96      7827
weighted avg       0.96      0.96      0.96      7827

completed
