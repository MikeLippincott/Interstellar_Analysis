[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '27661750'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '2a72f796'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'a973142b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'b0b5aa58'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_100.000_DMSO_0.025 treatment_name: LPS_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_100.000_DMSO_0.025
TREATMENT_NAME: LPS_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (32445, 1276)
Number of total missing values across all columns: 64890
Data Subset Is Off
Wells held out for testing: ['D20' 'J16']
Wells to use for training, validation, and testing ['D16' 'D17' 'D21' 'J17' 'J20' 'J21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.689037).  Saving model ...
	 Train_Loss: 0.6929 Train_Acc: 51.288 Val_Loss: 0.6890  BEST VAL Loss: 0.6890  Val_Acc: 54.177

Epoch 1: Validation loss decreased (0.689037 --> 0.682533).  Saving model ...
	 Train_Loss: 0.6889 Train_Acc: 57.679 Val_Loss: 0.6825  BEST VAL Loss: 0.6825  Val_Acc: 63.193

Epoch 2: Validation loss decreased (0.682533 --> 0.671836).  Saving model ...
	 Train_Loss: 0.6814 Train_Acc: 62.354 Val_Loss: 0.6718  BEST VAL Loss: 0.6718  Val_Acc: 66.625

Epoch 3: Validation loss decreased (0.671836 --> 0.661230).  Saving model ...
	 Train_Loss: 0.6717 Train_Acc: 67.303 Val_Loss: 0.6612  BEST VAL Loss: 0.6612  Val_Acc: 68.693

Epoch 4: Validation loss decreased (0.661230 --> 0.647768).  Saving model ...
	 Train_Loss: 0.6612 Train_Acc: 70.090 Val_Loss: 0.6478  BEST VAL Loss: 0.6478  Val_Acc: 71.464

Epoch 5: Validation loss decreased (0.647768 --> 0.633499).  Saving model ...
	 Train_Loss: 0.6493 Train_Acc: 72.401 Val_Loss: 0.6335  BEST VAL Loss: 0.6335  Val_Acc: 73.863

Epoch 6: Validation loss decreased (0.633499 --> 0.617840).  Saving model ...
	 Train_Loss: 0.6367 Train_Acc: 74.801 Val_Loss: 0.6178  BEST VAL Loss: 0.6178  Val_Acc: 76.634

Epoch 7: Validation loss decreased (0.617840 --> 0.600884).  Saving model ...
	 Train_Loss: 0.6227 Train_Acc: 76.776 Val_Loss: 0.6009  BEST VAL Loss: 0.6009  Val_Acc: 80.108

Epoch 8: Validation loss decreased (0.600884 --> 0.583261).  Saving model ...
	 Train_Loss: 0.6076 Train_Acc: 78.622 Val_Loss: 0.5833  BEST VAL Loss: 0.5833  Val_Acc: 81.679

Epoch 9: Validation loss decreased (0.583261 --> 0.565059).  Saving model ...
	 Train_Loss: 0.5920 Train_Acc: 80.696 Val_Loss: 0.5651  BEST VAL Loss: 0.5651  Val_Acc: 83.706

Epoch 10: Validation loss decreased (0.565059 --> 0.547149).  Saving model ...
	 Train_Loss: 0.5768 Train_Acc: 82.144 Val_Loss: 0.5471  BEST VAL Loss: 0.5471  Val_Acc: 85.608

Epoch 11: Validation loss decreased (0.547149 --> 0.529402).  Saving model ...
	 Train_Loss: 0.5620 Train_Acc: 83.732 Val_Loss: 0.5294  BEST VAL Loss: 0.5294  Val_Acc: 87.676

Epoch 12: Validation loss decreased (0.529402 --> 0.512798).  Saving model ...
	 Train_Loss: 0.5481 Train_Acc: 84.440 Val_Loss: 0.5128  BEST VAL Loss: 0.5128  Val_Acc: 88.337

Epoch 13: Validation loss decreased (0.512798 --> 0.497487).  Saving model ...
	 Train_Loss: 0.5350 Train_Acc: 85.903 Val_Loss: 0.4975  BEST VAL Loss: 0.4975  Val_Acc: 89.123

Epoch 14: Validation loss decreased (0.497487 --> 0.482874).  Saving model ...
	 Train_Loss: 0.5225 Train_Acc: 86.534 Val_Loss: 0.4829  BEST VAL Loss: 0.4829  Val_Acc: 90.281

Epoch 15: Validation loss decreased (0.482874 --> 0.469511).  Saving model ...
	 Train_Loss: 0.5110 Train_Acc: 87.124 Val_Loss: 0.4695  BEST VAL Loss: 0.4695  Val_Acc: 90.612

Epoch 16: Validation loss decreased (0.469511 --> 0.457252).  Saving model ...
	 Train_Loss: 0.5001 Train_Acc: 87.496 Val_Loss: 0.4573  BEST VAL Loss: 0.4573  Val_Acc: 91.191

Epoch 17: Validation loss decreased (0.457252 --> 0.445810).  Saving model ...
	 Train_Loss: 0.4898 Train_Acc: 88.220 Val_Loss: 0.4458  BEST VAL Loss: 0.4458  Val_Acc: 91.522

Epoch 18: Validation loss decreased (0.445810 --> 0.435128).  Saving model ...
	 Train_Loss: 0.4802 Train_Acc: 88.536 Val_Loss: 0.4351  BEST VAL Loss: 0.4351  Val_Acc: 91.853

Epoch 19: Validation loss decreased (0.435128 --> 0.425196).  Saving model ...
	 Train_Loss: 0.4712 Train_Acc: 88.913 Val_Loss: 0.4252  BEST VAL Loss: 0.4252  Val_Acc: 91.687

Epoch 20: Validation loss decreased (0.425196 --> 0.415888).  Saving model ...
	 Train_Loss: 0.4628 Train_Acc: 89.032 Val_Loss: 0.4159  BEST VAL Loss: 0.4159  Val_Acc: 91.853

Epoch 21: Validation loss decreased (0.415888 --> 0.407423).  Saving model ...
	 Train_Loss: 0.4548 Train_Acc: 89.534 Val_Loss: 0.4074  BEST VAL Loss: 0.4074  Val_Acc: 91.646

Epoch 22: Validation loss decreased (0.407423 --> 0.399601).  Saving model ...
	 Train_Loss: 0.4472 Train_Acc: 89.606 Val_Loss: 0.3996  BEST VAL Loss: 0.3996  Val_Acc: 91.563

Epoch 23: Validation loss decreased (0.399601 --> 0.391964).  Saving model ...
	 Train_Loss: 0.4400 Train_Acc: 89.823 Val_Loss: 0.3920  BEST VAL Loss: 0.3920  Val_Acc: 91.605

Epoch 24: Validation loss decreased (0.391964 --> 0.384984).  Saving model ...
	 Train_Loss: 0.4332 Train_Acc: 89.865 Val_Loss: 0.3850  BEST VAL Loss: 0.3850  Val_Acc: 91.522

Epoch 25: Validation loss decreased (0.384984 --> 0.378050).  Saving model ...
	 Train_Loss: 0.4269 Train_Acc: 89.663 Val_Loss: 0.3780  BEST VAL Loss: 0.3780  Val_Acc: 92.225

Epoch 26: Validation loss decreased (0.378050 --> 0.371917).  Saving model ...
	 Train_Loss: 0.4208 Train_Acc: 90.387 Val_Loss: 0.3719  BEST VAL Loss: 0.3719  Val_Acc: 91.935

Epoch 27: Validation loss decreased (0.371917 --> 0.366258).  Saving model ...
	 Train_Loss: 0.4148 Train_Acc: 90.904 Val_Loss: 0.3663  BEST VAL Loss: 0.3663  Val_Acc: 92.308

Epoch 28: Validation loss decreased (0.366258 --> 0.360561).  Saving model ...
	 Train_Loss: 0.4093 Train_Acc: 90.490 Val_Loss: 0.3606  BEST VAL Loss: 0.3606  Val_Acc: 92.514

Epoch 29: Validation loss decreased (0.360561 --> 0.355550).  Saving model ...
	 Train_Loss: 0.4039 Train_Acc: 90.764 Val_Loss: 0.3556  BEST VAL Loss: 0.3556  Val_Acc: 91.977

Epoch 30: Validation loss decreased (0.355550 --> 0.350609).  Saving model ...
	 Train_Loss: 0.3988 Train_Acc: 90.940 Val_Loss: 0.3506  BEST VAL Loss: 0.3506  Val_Acc: 92.225

Epoch 31: Validation loss decreased (0.350609 --> 0.346059).  Saving model ...
	 Train_Loss: 0.3939 Train_Acc: 91.080 Val_Loss: 0.3461  BEST VAL Loss: 0.3461  Val_Acc: 92.142

Epoch 32: Validation loss decreased (0.346059 --> 0.341732).  Saving model ...
	 Train_Loss: 0.3892 Train_Acc: 91.044 Val_Loss: 0.3417  BEST VAL Loss: 0.3417  Val_Acc: 92.225

Epoch 33: Validation loss decreased (0.341732 --> 0.337250).  Saving model ...
	 Train_Loss: 0.3847 Train_Acc: 91.395 Val_Loss: 0.3372  BEST VAL Loss: 0.3372  Val_Acc: 92.556

Epoch 34: Validation loss decreased (0.337250 --> 0.333162).  Saving model ...
	 Train_Loss: 0.3804 Train_Acc: 91.333 Val_Loss: 0.3332  BEST VAL Loss: 0.3332  Val_Acc: 92.680

Epoch 35: Validation loss decreased (0.333162 --> 0.329586).  Saving model ...
	 Train_Loss: 0.3762 Train_Acc: 91.354 Val_Loss: 0.3296  BEST VAL Loss: 0.3296  Val_Acc: 92.804

Epoch 36: Validation loss decreased (0.329586 --> 0.326183).  Saving model ...
	 Train_Loss: 0.3721 Train_Acc: 91.902 Val_Loss: 0.3262  BEST VAL Loss: 0.3262  Val_Acc: 92.639

Epoch 37: Validation loss decreased (0.326183 --> 0.322640).  Saving model ...
	 Train_Loss: 0.3682 Train_Acc: 91.618 Val_Loss: 0.3226  BEST VAL Loss: 0.3226  Val_Acc: 92.763

Epoch 38: Validation loss decreased (0.322640 --> 0.319410).  Saving model ...
	 Train_Loss: 0.3644 Train_Acc: 91.736 Val_Loss: 0.3194  BEST VAL Loss: 0.3194  Val_Acc: 92.845

Epoch 39: Validation loss decreased (0.319410 --> 0.316377).  Saving model ...
	 Train_Loss: 0.3607 Train_Acc: 91.705 Val_Loss: 0.3164  BEST VAL Loss: 0.3164  Val_Acc: 92.514

Epoch 40: Validation loss decreased (0.316377 --> 0.313270).  Saving model ...
	 Train_Loss: 0.3573 Train_Acc: 92.042 Val_Loss: 0.3133  BEST VAL Loss: 0.3133  Val_Acc: 93.176

Epoch 41: Validation loss decreased (0.313270 --> 0.310275).  Saving model ...
	 Train_Loss: 0.3540 Train_Acc: 91.938 Val_Loss: 0.3103  BEST VAL Loss: 0.3103  Val_Acc: 92.804

Epoch 42: Validation loss decreased (0.310275 --> 0.307452).  Saving model ...
	 Train_Loss: 0.3507 Train_Acc: 92.192 Val_Loss: 0.3075  BEST VAL Loss: 0.3075  Val_Acc: 92.887

Epoch 43: Validation loss decreased (0.307452 --> 0.304797).  Saving model ...
	 Train_Loss: 0.3475 Train_Acc: 92.109 Val_Loss: 0.3048  BEST VAL Loss: 0.3048  Val_Acc: 92.969

Epoch 44: Validation loss decreased (0.304797 --> 0.302422).  Saving model ...
	 Train_Loss: 0.3445 Train_Acc: 92.347 Val_Loss: 0.3024  BEST VAL Loss: 0.3024  Val_Acc: 93.011

Epoch 45: Validation loss decreased (0.302422 --> 0.299948).  Saving model ...
	 Train_Loss: 0.3415 Train_Acc: 92.362 Val_Loss: 0.2999  BEST VAL Loss: 0.2999  Val_Acc: 92.639

Epoch 46: Validation loss decreased (0.299948 --> 0.297580).  Saving model ...
	 Train_Loss: 0.3386 Train_Acc: 92.398 Val_Loss: 0.2976  BEST VAL Loss: 0.2976  Val_Acc: 92.969

Epoch 47: Validation loss decreased (0.297580 --> 0.295729).  Saving model ...
	 Train_Loss: 0.3358 Train_Acc: 92.331 Val_Loss: 0.2957  BEST VAL Loss: 0.2957  Val_Acc: 92.639

Epoch 48: Validation loss decreased (0.295729 --> 0.293683).  Saving model ...
	 Train_Loss: 0.3331 Train_Acc: 92.543 Val_Loss: 0.2937  BEST VAL Loss: 0.2937  Val_Acc: 92.845

Epoch 49: Validation loss decreased (0.293683 --> 0.292068).  Saving model ...
	 Train_Loss: 0.3305 Train_Acc: 92.367 Val_Loss: 0.2921  BEST VAL Loss: 0.2921  Val_Acc: 92.804

Epoch 50: Validation loss decreased (0.292068 --> 0.290259).  Saving model ...
	 Train_Loss: 0.3279 Train_Acc: 92.678 Val_Loss: 0.2903  BEST VAL Loss: 0.2903  Val_Acc: 92.928

Epoch 51: Validation loss decreased (0.290259 --> 0.288407).  Saving model ...
	 Train_Loss: 0.3254 Train_Acc: 92.574 Val_Loss: 0.2884  BEST VAL Loss: 0.2884  Val_Acc: 93.218

Epoch 52: Validation loss decreased (0.288407 --> 0.286713).  Saving model ...
	 Train_Loss: 0.3230 Train_Acc: 92.900 Val_Loss: 0.2867  BEST VAL Loss: 0.2867  Val_Acc: 93.011

Epoch 53: Validation loss decreased (0.286713 --> 0.284799).  Saving model ...
	 Train_Loss: 0.3205 Train_Acc: 92.993 Val_Loss: 0.2848  BEST VAL Loss: 0.2848  Val_Acc: 93.011

Epoch 54: Validation loss decreased (0.284799 --> 0.283177).  Saving model ...
	 Train_Loss: 0.3182 Train_Acc: 92.859 Val_Loss: 0.2832  BEST VAL Loss: 0.2832  Val_Acc: 93.218

Epoch 55: Validation loss decreased (0.283177 --> 0.281603).  Saving model ...
	 Train_Loss: 0.3160 Train_Acc: 92.590 Val_Loss: 0.2816  BEST VAL Loss: 0.2816  Val_Acc: 92.845

Epoch 56: Validation loss decreased (0.281603 --> 0.279986).  Saving model ...
	 Train_Loss: 0.3137 Train_Acc: 93.159 Val_Loss: 0.2800  BEST VAL Loss: 0.2800  Val_Acc: 92.928

Epoch 57: Validation loss decreased (0.279986 --> 0.278366).  Saving model ...
	 Train_Loss: 0.3116 Train_Acc: 93.184 Val_Loss: 0.2784  BEST VAL Loss: 0.2784  Val_Acc: 92.887

Epoch 58: Validation loss decreased (0.278366 --> 0.276711).  Saving model ...
	 Train_Loss: 0.3095 Train_Acc: 93.231 Val_Loss: 0.2767  BEST VAL Loss: 0.2767  Val_Acc: 93.259

Epoch 59: Validation loss decreased (0.276711 --> 0.275450).  Saving model ...
	 Train_Loss: 0.3074 Train_Acc: 92.998 Val_Loss: 0.2755  BEST VAL Loss: 0.2755  Val_Acc: 92.804

Epoch 60: Validation loss decreased (0.275450 --> 0.274179).  Saving model ...
	 Train_Loss: 0.3054 Train_Acc: 93.205 Val_Loss: 0.2742  BEST VAL Loss: 0.2742  Val_Acc: 92.845

Epoch 61: Validation loss decreased (0.274179 --> 0.273154).  Saving model ...
	 Train_Loss: 0.3035 Train_Acc: 93.159 Val_Loss: 0.2732  BEST VAL Loss: 0.2732  Val_Acc: 92.928

Epoch 62: Validation loss decreased (0.273154 --> 0.271864).  Saving model ...
	 Train_Loss: 0.3015 Train_Acc: 93.521 Val_Loss: 0.2719  BEST VAL Loss: 0.2719  Val_Acc: 92.763

Epoch 63: Validation loss decreased (0.271864 --> 0.270447).  Saving model ...
	 Train_Loss: 0.2996 Train_Acc: 93.262 Val_Loss: 0.2704  BEST VAL Loss: 0.2704  Val_Acc: 93.300

Epoch 64: Validation loss decreased (0.270447 --> 0.269199).  Saving model ...
	 Train_Loss: 0.2977 Train_Acc: 93.433 Val_Loss: 0.2692  BEST VAL Loss: 0.2692  Val_Acc: 93.093

Epoch 65: Validation loss decreased (0.269199 --> 0.268032).  Saving model ...
	 Train_Loss: 0.2959 Train_Acc: 93.712 Val_Loss: 0.2680  BEST VAL Loss: 0.2680  Val_Acc: 92.804

Epoch 66: Validation loss decreased (0.268032 --> 0.266907).  Saving model ...
	 Train_Loss: 0.2941 Train_Acc: 93.531 Val_Loss: 0.2669  BEST VAL Loss: 0.2669  Val_Acc: 92.928

Epoch 67: Validation loss decreased (0.266907 --> 0.265751).  Saving model ...
	 Train_Loss: 0.2923 Train_Acc: 93.707 Val_Loss: 0.2658  BEST VAL Loss: 0.2658  Val_Acc: 93.135

Epoch 68: Validation loss decreased (0.265751 --> 0.264774).  Saving model ...
	 Train_Loss: 0.2906 Train_Acc: 93.634 Val_Loss: 0.2648  BEST VAL Loss: 0.2648  Val_Acc: 92.928

Epoch 69: Validation loss decreased (0.264774 --> 0.263761).  Saving model ...
	 Train_Loss: 0.2889 Train_Acc: 93.733 Val_Loss: 0.2638  BEST VAL Loss: 0.2638  Val_Acc: 92.887

Epoch 70: Validation loss decreased (0.263761 --> 0.262803).  Saving model ...
	 Train_Loss: 0.2873 Train_Acc: 93.639 Val_Loss: 0.2628  BEST VAL Loss: 0.2628  Val_Acc: 93.383

Epoch 71: Validation loss decreased (0.262803 --> 0.261761).  Saving model ...
	 Train_Loss: 0.2857 Train_Acc: 93.686 Val_Loss: 0.2618  BEST VAL Loss: 0.2618  Val_Acc: 92.804

Epoch 72: Validation loss decreased (0.261761 --> 0.260733).  Saving model ...
	 Train_Loss: 0.2841 Train_Acc: 93.753 Val_Loss: 0.2607  BEST VAL Loss: 0.2607  Val_Acc: 93.218

Epoch 73: Validation loss decreased (0.260733 --> 0.259772).  Saving model ...
	 Train_Loss: 0.2825 Train_Acc: 93.815 Val_Loss: 0.2598  BEST VAL Loss: 0.2598  Val_Acc: 93.259

Epoch 74: Validation loss decreased (0.259772 --> 0.258801).  Saving model ...
	 Train_Loss: 0.2809 Train_Acc: 94.007 Val_Loss: 0.2588  BEST VAL Loss: 0.2588  Val_Acc: 93.218

Epoch 75: Validation loss decreased (0.258801 --> 0.257920).  Saving model ...
	 Train_Loss: 0.2794 Train_Acc: 93.831 Val_Loss: 0.2579  BEST VAL Loss: 0.2579  Val_Acc: 93.300

Epoch 76: Validation loss decreased (0.257920 --> 0.256937).  Saving model ...
	 Train_Loss: 0.2779 Train_Acc: 94.032 Val_Loss: 0.2569  BEST VAL Loss: 0.2569  Val_Acc: 93.093

Epoch 77: Validation loss decreased (0.256937 --> 0.256094).  Saving model ...
	 Train_Loss: 0.2764 Train_Acc: 94.188 Val_Loss: 0.2561  BEST VAL Loss: 0.2561  Val_Acc: 92.887

Epoch 78: Validation loss decreased (0.256094 --> 0.255341).  Saving model ...
	 Train_Loss: 0.2750 Train_Acc: 93.862 Val_Loss: 0.2553  BEST VAL Loss: 0.2553  Val_Acc: 93.135

Epoch 79: Validation loss decreased (0.255341 --> 0.254548).  Saving model ...
	 Train_Loss: 0.2736 Train_Acc: 93.960 Val_Loss: 0.2545  BEST VAL Loss: 0.2545  Val_Acc: 92.721

Epoch 80: Validation loss decreased (0.254548 --> 0.253800).  Saving model ...
	 Train_Loss: 0.2722 Train_Acc: 94.296 Val_Loss: 0.2538  BEST VAL Loss: 0.2538  Val_Acc: 92.928

Epoch 81: Validation loss decreased (0.253800 --> 0.253151).  Saving model ...
	 Train_Loss: 0.2709 Train_Acc: 94.058 Val_Loss: 0.2532  BEST VAL Loss: 0.2532  Val_Acc: 92.969

Epoch 82: Validation loss decreased (0.253151 --> 0.252390).  Saving model ...
	 Train_Loss: 0.2696 Train_Acc: 94.058 Val_Loss: 0.2524  BEST VAL Loss: 0.2524  Val_Acc: 93.383

Epoch 83: Validation loss decreased (0.252390 --> 0.251691).  Saving model ...
	 Train_Loss: 0.2683 Train_Acc: 94.182 Val_Loss: 0.2517  BEST VAL Loss: 0.2517  Val_Acc: 93.176

Epoch 84: Validation loss decreased (0.251691 --> 0.250925).  Saving model ...
	 Train_Loss: 0.2670 Train_Acc: 94.348 Val_Loss: 0.2509  BEST VAL Loss: 0.2509  Val_Acc: 93.259

Epoch 85: Validation loss decreased (0.250925 --> 0.250285).  Saving model ...
	 Train_Loss: 0.2657 Train_Acc: 94.301 Val_Loss: 0.2503  BEST VAL Loss: 0.2503  Val_Acc: 93.424

Epoch 86: Validation loss decreased (0.250285 --> 0.249584).  Saving model ...
	 Train_Loss: 0.2644 Train_Acc: 94.513 Val_Loss: 0.2496  BEST VAL Loss: 0.2496  Val_Acc: 93.093

Epoch 87: Validation loss decreased (0.249584 --> 0.248946).  Saving model ...
	 Train_Loss: 0.2632 Train_Acc: 94.312 Val_Loss: 0.2489  BEST VAL Loss: 0.2489  Val_Acc: 93.383

Epoch 88: Validation loss decreased (0.248946 --> 0.248427).  Saving model ...
	 Train_Loss: 0.2620 Train_Acc: 94.307 Val_Loss: 0.2484  BEST VAL Loss: 0.2484  Val_Acc: 92.969

Epoch 89: Validation loss decreased (0.248427 --> 0.247995).  Saving model ...
	 Train_Loss: 0.2608 Train_Acc: 94.379 Val_Loss: 0.2480  BEST VAL Loss: 0.2480  Val_Acc: 93.176

Epoch 90: Validation loss decreased (0.247995 --> 0.247514).  Saving model ...
	 Train_Loss: 0.2596 Train_Acc: 94.317 Val_Loss: 0.2475  BEST VAL Loss: 0.2475  Val_Acc: 93.507

Epoch 91: Validation loss decreased (0.247514 --> 0.246986).  Saving model ...
	 Train_Loss: 0.2584 Train_Acc: 94.658 Val_Loss: 0.2470  BEST VAL Loss: 0.2470  Val_Acc: 93.383

Epoch 92: Validation loss decreased (0.246986 --> 0.246621).  Saving model ...
	 Train_Loss: 0.2572 Train_Acc: 94.798 Val_Loss: 0.2466  BEST VAL Loss: 0.2466  Val_Acc: 93.093

Epoch 93: Validation loss decreased (0.246621 --> 0.245982).  Saving model ...
	 Train_Loss: 0.2561 Train_Acc: 94.596 Val_Loss: 0.2460  BEST VAL Loss: 0.2460  Val_Acc: 92.969

Epoch 94: Validation loss decreased (0.245982 --> 0.245561).  Saving model ...
	 Train_Loss: 0.2550 Train_Acc: 94.524 Val_Loss: 0.2456  BEST VAL Loss: 0.2456  Val_Acc: 93.011

Epoch 95: Validation loss decreased (0.245561 --> 0.245124).  Saving model ...
	 Train_Loss: 0.2540 Train_Acc: 94.105 Val_Loss: 0.2451  BEST VAL Loss: 0.2451  Val_Acc: 93.176

Epoch 96: Validation loss decreased (0.245124 --> 0.244755).  Saving model ...
	 Train_Loss: 0.2529 Train_Acc: 94.436 Val_Loss: 0.2448  BEST VAL Loss: 0.2448  Val_Acc: 93.052

Epoch 97: Validation loss decreased (0.244755 --> 0.244387).  Saving model ...
	 Train_Loss: 0.2518 Train_Acc: 94.818 Val_Loss: 0.2444  BEST VAL Loss: 0.2444  Val_Acc: 93.466

Epoch 98: Validation loss decreased (0.244387 --> 0.244086).  Saving model ...
	 Train_Loss: 0.2508 Train_Acc: 94.829 Val_Loss: 0.2441  BEST VAL Loss: 0.2441  Val_Acc: 93.176

Epoch 99: Validation loss decreased (0.244086 --> 0.243632).  Saving model ...
	 Train_Loss: 0.2497 Train_Acc: 94.865 Val_Loss: 0.2436  BEST VAL Loss: 0.2436  Val_Acc: 93.342

LPS_100.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.50      0.51      9832
           1       0.49      0.50      0.50      9506

    accuracy                           0.50     19338
   macro avg       0.50      0.50      0.50     19338
weighted avg       0.50      0.50      0.50     19338

LPS_100.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.51      0.51      1229
           1       0.49      0.50      0.50      1189

    accuracy                           0.50      2418
   macro avg       0.50      0.50      0.50      2418
weighted avg       0.50      0.50      0.50      2418

LPS_100.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.51      0.51      1229
           1       0.49      0.49      0.49      1189

    accuracy                           0.50      2418
   macro avg       0.50      0.50      0.50      2418
weighted avg       0.50      0.50      0.50      2418

              precision    recall  f1-score   support

           0       0.51      0.51      0.51      1229
           1       0.49      0.49      0.49      1189

    accuracy                           0.50      2418
   macro avg       0.50      0.50      0.50      2418
weighted avg       0.50      0.50      0.50      2418

LPS_100.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.50      0.50      4168
           1       0.49      0.49      0.49      4103

    accuracy                           0.49      8271
   macro avg       0.49      0.49      0.49      8271
weighted avg       0.49      0.49      0.49      8271

              precision    recall  f1-score   support

           0       0.50      0.50      0.50      4168
           1       0.49      0.49      0.49      4103

    accuracy                           0.49      8271
   macro avg       0.49      0.49      0.49      8271
weighted avg       0.49      0.49      0.49      8271

completed
