[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '47ed566f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e28b6a9a'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '4e84b59d'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e9292041'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: H2O2_100.000_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['H2O2_100.000_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (399971, 1270)
Number of total missing values across all columns: 799942
Data Subset Is Off
Wells held out for testing: ['I10' 'J08']
Wells to use for training, validation, and testing ['H04' 'I04' 'H05' 'I05' 'H10' 'H11' 'I11' 'J02' 'J03' 'J09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.387667).  Saving model ...
	 Train_Loss: 0.4742 Train_Acc: 76.869 Val_Loss: 0.3877  BEST VAL Loss: 0.3877  Val_Acc: 82.140

Epoch 1: Validation loss decreased (0.387667 --> 0.373768).  Saving model ...
	 Train_Loss: 0.4342 Train_Acc: 81.686 Val_Loss: 0.3738  BEST VAL Loss: 0.3738  Val_Acc: 83.780

Epoch 2: Validation loss decreased (0.373768 --> 0.364794).  Saving model ...
	 Train_Loss: 0.4139 Train_Acc: 82.769 Val_Loss: 0.3648  BEST VAL Loss: 0.3648  Val_Acc: 84.459

Epoch 3: Validation loss decreased (0.364794 --> 0.359649).  Saving model ...
	 Train_Loss: 0.4009 Train_Acc: 83.243 Val_Loss: 0.3596  BEST VAL Loss: 0.3596  Val_Acc: 84.603

Epoch 4: Validation loss decreased (0.359649 --> 0.354771).  Saving model ...
	 Train_Loss: 0.3919 Train_Acc: 83.578 Val_Loss: 0.3548  BEST VAL Loss: 0.3548  Val_Acc: 84.896

Epoch 5: Validation loss decreased (0.354771 --> 0.350368).  Saving model ...
	 Train_Loss: 0.3846 Train_Acc: 84.014 Val_Loss: 0.3504  BEST VAL Loss: 0.3504  Val_Acc: 85.357

Epoch 6: Validation loss decreased (0.350368 --> 0.347017).  Saving model ...
	 Train_Loss: 0.3786 Train_Acc: 84.224 Val_Loss: 0.3470  BEST VAL Loss: 0.3470  Val_Acc: 85.333

Epoch 7: Validation loss decreased (0.347017 --> 0.343771).  Saving model ...
	 Train_Loss: 0.3737 Train_Acc: 84.502 Val_Loss: 0.3438  BEST VAL Loss: 0.3438  Val_Acc: 85.671

Epoch 8: Validation loss decreased (0.343771 --> 0.341460).  Saving model ...
	 Train_Loss: 0.3695 Train_Acc: 84.610 Val_Loss: 0.3415  BEST VAL Loss: 0.3415  Val_Acc: 85.548

Epoch 9: Validation loss decreased (0.341460 --> 0.339121).  Saving model ...
	 Train_Loss: 0.3658 Train_Acc: 84.701 Val_Loss: 0.3391  BEST VAL Loss: 0.3391  Val_Acc: 85.919

Epoch 10: Validation loss decreased (0.339121 --> 0.337210).  Saving model ...
	 Train_Loss: 0.3628 Train_Acc: 84.725 Val_Loss: 0.3372  BEST VAL Loss: 0.3372  Val_Acc: 85.905

Epoch 11: Validation loss decreased (0.337210 --> 0.335543).  Saving model ...
	 Train_Loss: 0.3600 Train_Acc: 84.866 Val_Loss: 0.3355  BEST VAL Loss: 0.3355  Val_Acc: 85.979

Epoch 12: Validation loss decreased (0.335543 --> 0.333714).  Saving model ...
	 Train_Loss: 0.3575 Train_Acc: 84.953 Val_Loss: 0.3337  BEST VAL Loss: 0.3337  Val_Acc: 86.186

Epoch 13: Validation loss decreased (0.333714 --> 0.332324).  Saving model ...
	 Train_Loss: 0.3552 Train_Acc: 85.035 Val_Loss: 0.3323  BEST VAL Loss: 0.3323  Val_Acc: 86.303

Epoch 14: Validation loss decreased (0.332324 --> 0.330983).  Saving model ...
	 Train_Loss: 0.3532 Train_Acc: 85.148 Val_Loss: 0.3310  BEST VAL Loss: 0.3310  Val_Acc: 86.000

Epoch 15: Validation loss decreased (0.330983 --> 0.329665).  Saving model ...
	 Train_Loss: 0.3513 Train_Acc: 85.208 Val_Loss: 0.3297  BEST VAL Loss: 0.3297  Val_Acc: 86.350

Epoch 16: Validation loss decreased (0.329665 --> 0.328336).  Saving model ...
	 Train_Loss: 0.3495 Train_Acc: 85.298 Val_Loss: 0.3283  BEST VAL Loss: 0.3283  Val_Acc: 86.557

Epoch 17: Validation loss decreased (0.328336 --> 0.327081).  Saving model ...
	 Train_Loss: 0.3479 Train_Acc: 85.370 Val_Loss: 0.3271  BEST VAL Loss: 0.3271  Val_Acc: 86.440

Epoch 18: Validation loss decreased (0.327081 --> 0.325707).  Saving model ...
	 Train_Loss: 0.3464 Train_Acc: 85.310 Val_Loss: 0.3257  BEST VAL Loss: 0.3257  Val_Acc: 86.739

Epoch 19: Validation loss decreased (0.325707 --> 0.324607).  Saving model ...
	 Train_Loss: 0.3450 Train_Acc: 85.429 Val_Loss: 0.3246  BEST VAL Loss: 0.3246  Val_Acc: 86.476

Epoch 20: Validation loss decreased (0.324607 --> 0.323722).  Saving model ...
	 Train_Loss: 0.3437 Train_Acc: 85.419 Val_Loss: 0.3237  BEST VAL Loss: 0.3237  Val_Acc: 86.494

Epoch 21: Validation loss decreased (0.323722 --> 0.322710).  Saving model ...
	 Train_Loss: 0.3425 Train_Acc: 85.385 Val_Loss: 0.3227  BEST VAL Loss: 0.3227  Val_Acc: 86.748

Epoch 22: Validation loss decreased (0.322710 --> 0.321930).  Saving model ...
	 Train_Loss: 0.3414 Train_Acc: 85.456 Val_Loss: 0.3219  BEST VAL Loss: 0.3219  Val_Acc: 86.285

Epoch 23: Validation loss decreased (0.321930 --> 0.321371).  Saving model ...
	 Train_Loss: 0.3402 Train_Acc: 85.505 Val_Loss: 0.3214  BEST VAL Loss: 0.3214  Val_Acc: 86.509

Epoch 24: Validation loss decreased (0.321371 --> 0.320672).  Saving model ...
	 Train_Loss: 0.3391 Train_Acc: 85.603 Val_Loss: 0.3207  BEST VAL Loss: 0.3207  Val_Acc: 86.874

Epoch 25: Validation loss decreased (0.320672 --> 0.319794).  Saving model ...
	 Train_Loss: 0.3382 Train_Acc: 85.494 Val_Loss: 0.3198  BEST VAL Loss: 0.3198  Val_Acc: 86.832

Epoch 26: Validation loss decreased (0.319794 --> 0.319226).  Saving model ...
	 Train_Loss: 0.3373 Train_Acc: 85.550 Val_Loss: 0.3192  BEST VAL Loss: 0.3192  Val_Acc: 86.659

Epoch 27: Validation loss decreased (0.319226 --> 0.318482).  Saving model ...
	 Train_Loss: 0.3364 Train_Acc: 85.503 Val_Loss: 0.3185  BEST VAL Loss: 0.3185  Val_Acc: 86.617

Epoch 28: Validation loss decreased (0.318482 --> 0.317843).  Saving model ...
	 Train_Loss: 0.3356 Train_Acc: 85.545 Val_Loss: 0.3178  BEST VAL Loss: 0.3178  Val_Acc: 86.841

Epoch 29: Validation loss decreased (0.317843 --> 0.317211).  Saving model ...
	 Train_Loss: 0.3347 Train_Acc: 85.601 Val_Loss: 0.3172  BEST VAL Loss: 0.3172  Val_Acc: 86.584

Epoch 30: Validation loss decreased (0.317211 --> 0.316793).  Saving model ...
	 Train_Loss: 0.3340 Train_Acc: 85.504 Val_Loss: 0.3168  BEST VAL Loss: 0.3168  Val_Acc: 86.228

Epoch 31: Validation loss decreased (0.316793 --> 0.316252).  Saving model ...
	 Train_Loss: 0.3332 Train_Acc: 85.636 Val_Loss: 0.3163  BEST VAL Loss: 0.3163  Val_Acc: 86.988

Epoch 32: Validation loss decreased (0.316252 --> 0.315831).  Saving model ...
	 Train_Loss: 0.3325 Train_Acc: 85.680 Val_Loss: 0.3158  BEST VAL Loss: 0.3158  Val_Acc: 86.757

Epoch 33: Validation loss decreased (0.315831 --> 0.315435).  Saving model ...
	 Train_Loss: 0.3318 Train_Acc: 85.710 Val_Loss: 0.3154  BEST VAL Loss: 0.3154  Val_Acc: 86.641

Epoch 34: Validation loss decreased (0.315435 --> 0.314901).  Saving model ...
	 Train_Loss: 0.3311 Train_Acc: 85.758 Val_Loss: 0.3149  BEST VAL Loss: 0.3149  Val_Acc: 86.904

Epoch 35: Validation loss decreased (0.314901 --> 0.314420).  Saving model ...
	 Train_Loss: 0.3305 Train_Acc: 85.791 Val_Loss: 0.3144  BEST VAL Loss: 0.3144  Val_Acc: 87.021

Epoch 36: Validation loss decreased (0.314420 --> 0.314114).  Saving model ...
	 Train_Loss: 0.3299 Train_Acc: 85.758 Val_Loss: 0.3141  BEST VAL Loss: 0.3141  Val_Acc: 86.701

Epoch 37: Validation loss decreased (0.314114 --> 0.313669).  Saving model ...
	 Train_Loss: 0.3293 Train_Acc: 85.767 Val_Loss: 0.3137  BEST VAL Loss: 0.3137  Val_Acc: 86.641

Epoch 38: Validation loss decreased (0.313669 --> 0.313177).  Saving model ...
	 Train_Loss: 0.3287 Train_Acc: 85.773 Val_Loss: 0.3132  BEST VAL Loss: 0.3132  Val_Acc: 87.218

Epoch 39: Validation loss decreased (0.313177 --> 0.312686).  Saving model ...
	 Train_Loss: 0.3282 Train_Acc: 85.869 Val_Loss: 0.3127  BEST VAL Loss: 0.3127  Val_Acc: 87.048

Epoch 40: Validation loss decreased (0.312686 --> 0.312335).  Saving model ...
	 Train_Loss: 0.3276 Train_Acc: 85.851 Val_Loss: 0.3123  BEST VAL Loss: 0.3123  Val_Acc: 86.952

Epoch 41: Validation loss decreased (0.312335 --> 0.311897).  Saving model ...
	 Train_Loss: 0.3270 Train_Acc: 85.866 Val_Loss: 0.3119  BEST VAL Loss: 0.3119  Val_Acc: 87.078

Epoch 42: Validation loss decreased (0.311897 --> 0.311657).  Saving model ...
	 Train_Loss: 0.3265 Train_Acc: 85.886 Val_Loss: 0.3117  BEST VAL Loss: 0.3117  Val_Acc: 86.808

Epoch 43: Validation loss decreased (0.311657 --> 0.311376).  Saving model ...
	 Train_Loss: 0.3260 Train_Acc: 85.873 Val_Loss: 0.3114  BEST VAL Loss: 0.3114  Val_Acc: 86.952

Epoch 44: Validation loss decreased (0.311376 --> 0.311069).  Saving model ...
	 Train_Loss: 0.3256 Train_Acc: 85.832 Val_Loss: 0.3111  BEST VAL Loss: 0.3111  Val_Acc: 86.692

Epoch 45: Validation loss decreased (0.311069 --> 0.310824).  Saving model ...
	 Train_Loss: 0.3251 Train_Acc: 85.914 Val_Loss: 0.3108  BEST VAL Loss: 0.3108  Val_Acc: 86.826

Epoch 46: Validation loss decreased (0.310824 --> 0.310407).  Saving model ...
	 Train_Loss: 0.3246 Train_Acc: 85.867 Val_Loss: 0.3104  BEST VAL Loss: 0.3104  Val_Acc: 87.248

Epoch 47: Validation loss decreased (0.310407 --> 0.310116).  Saving model ...
	 Train_Loss: 0.3242 Train_Acc: 85.910 Val_Loss: 0.3101  BEST VAL Loss: 0.3101  Val_Acc: 87.167

Epoch 48: Validation loss decreased (0.310116 --> 0.309772).  Saving model ...
	 Train_Loss: 0.3238 Train_Acc: 85.836 Val_Loss: 0.3098  BEST VAL Loss: 0.3098  Val_Acc: 87.102

Epoch 49: Validation loss decreased (0.309772 --> 0.309610).  Saving model ...
	 Train_Loss: 0.3234 Train_Acc: 85.922 Val_Loss: 0.3096  BEST VAL Loss: 0.3096  Val_Acc: 86.925

Epoch 50: Validation loss decreased (0.309610 --> 0.309331).  Saving model ...
	 Train_Loss: 0.3230 Train_Acc: 85.987 Val_Loss: 0.3093  BEST VAL Loss: 0.3093  Val_Acc: 86.871

Epoch 51: Validation loss decreased (0.309331 --> 0.308951).  Saving model ...
	 Train_Loss: 0.3226 Train_Acc: 85.880 Val_Loss: 0.3090  BEST VAL Loss: 0.3090  Val_Acc: 87.120

Epoch 52: Validation loss decreased (0.308951 --> 0.308695).  Saving model ...
	 Train_Loss: 0.3222 Train_Acc: 86.076 Val_Loss: 0.3087  BEST VAL Loss: 0.3087  Val_Acc: 86.988

Epoch 53: Validation loss decreased (0.308695 --> 0.308359).  Saving model ...
	 Train_Loss: 0.3218 Train_Acc: 85.984 Val_Loss: 0.3084  BEST VAL Loss: 0.3084  Val_Acc: 87.224

Epoch 54: Validation loss decreased (0.308359 --> 0.308097).  Saving model ...
	 Train_Loss: 0.3214 Train_Acc: 85.972 Val_Loss: 0.3081  BEST VAL Loss: 0.3081  Val_Acc: 87.176

Epoch 55: Validation loss decreased (0.308097 --> 0.307857).  Saving model ...
	 Train_Loss: 0.3211 Train_Acc: 85.969 Val_Loss: 0.3079  BEST VAL Loss: 0.3079  Val_Acc: 87.132

Epoch 56: Validation loss decreased (0.307857 --> 0.307808).  Saving model ...
	 Train_Loss: 0.3207 Train_Acc: 86.048 Val_Loss: 0.3078  BEST VAL Loss: 0.3078  Val_Acc: 86.653

Epoch 57: Validation loss decreased (0.307808 --> 0.307489).  Saving model ...
	 Train_Loss: 0.3203 Train_Acc: 86.072 Val_Loss: 0.3075  BEST VAL Loss: 0.3075  Val_Acc: 87.383

Epoch 58: Validation loss decreased (0.307489 --> 0.307243).  Saving model ...
	 Train_Loss: 0.3200 Train_Acc: 85.940 Val_Loss: 0.3072  BEST VAL Loss: 0.3072  Val_Acc: 87.006

Epoch 59: Validation loss decreased (0.307243 --> 0.307099).  Saving model ...
	 Train_Loss: 0.3196 Train_Acc: 86.060 Val_Loss: 0.3071  BEST VAL Loss: 0.3071  Val_Acc: 86.781

Epoch 60: Validation loss decreased (0.307099 --> 0.306817).  Saving model ...
	 Train_Loss: 0.3193 Train_Acc: 86.065 Val_Loss: 0.3068  BEST VAL Loss: 0.3068  Val_Acc: 87.263

Epoch 61: Validation loss decreased (0.306817 --> 0.306652).  Saving model ...
	 Train_Loss: 0.3190 Train_Acc: 85.986 Val_Loss: 0.3067  BEST VAL Loss: 0.3067  Val_Acc: 87.081

Epoch 62: Validation loss decreased (0.306652 --> 0.306539).  Saving model ...
	 Train_Loss: 0.3187 Train_Acc: 86.029 Val_Loss: 0.3065  BEST VAL Loss: 0.3065  Val_Acc: 86.994

Epoch 63: Validation loss decreased (0.306539 --> 0.306264).  Saving model ...
	 Train_Loss: 0.3184 Train_Acc: 86.109 Val_Loss: 0.3063  BEST VAL Loss: 0.3063  Val_Acc: 87.066

Epoch 64: Validation loss decreased (0.306264 --> 0.306072).  Saving model ...
	 Train_Loss: 0.3181 Train_Acc: 86.115 Val_Loss: 0.3061  BEST VAL Loss: 0.3061  Val_Acc: 87.173

Epoch 65: Validation loss decreased (0.306072 --> 0.305839).  Saving model ...
	 Train_Loss: 0.3178 Train_Acc: 86.132 Val_Loss: 0.3058  BEST VAL Loss: 0.3058  Val_Acc: 86.940

Epoch 66: Validation loss decreased (0.305839 --> 0.305652).  Saving model ...
	 Train_Loss: 0.3175 Train_Acc: 86.096 Val_Loss: 0.3057  BEST VAL Loss: 0.3057  Val_Acc: 86.955

Epoch 67: Validation loss decreased (0.305652 --> 0.305445).  Saving model ...
	 Train_Loss: 0.3172 Train_Acc: 86.021 Val_Loss: 0.3054  BEST VAL Loss: 0.3054  Val_Acc: 87.215

Epoch 68: Validation loss decreased (0.305445 --> 0.305270).  Saving model ...
	 Train_Loss: 0.3169 Train_Acc: 86.110 Val_Loss: 0.3053  BEST VAL Loss: 0.3053  Val_Acc: 87.215

Epoch 69: Validation loss decreased (0.305270 --> 0.305127).  Saving model ...
	 Train_Loss: 0.3167 Train_Acc: 86.162 Val_Loss: 0.3051  BEST VAL Loss: 0.3051  Val_Acc: 87.069

Epoch 70: Validation loss decreased (0.305127 --> 0.304949).  Saving model ...
	 Train_Loss: 0.3164 Train_Acc: 86.138 Val_Loss: 0.3049  BEST VAL Loss: 0.3049  Val_Acc: 87.033

Epoch 71: Validation loss decreased (0.304949 --> 0.304741).  Saving model ...
	 Train_Loss: 0.3161 Train_Acc: 86.114 Val_Loss: 0.3047  BEST VAL Loss: 0.3047  Val_Acc: 87.123

Epoch 72: Validation loss decreased (0.304741 --> 0.304575).  Saving model ...
	 Train_Loss: 0.3159 Train_Acc: 86.116 Val_Loss: 0.3046  BEST VAL Loss: 0.3046  Val_Acc: 87.167

Epoch 73: Validation loss decreased (0.304575 --> 0.304348).  Saving model ...
	 Train_Loss: 0.3156 Train_Acc: 86.249 Val_Loss: 0.3043  BEST VAL Loss: 0.3043  Val_Acc: 87.057

Epoch 74: Validation loss decreased (0.304348 --> 0.304185).  Saving model ...
	 Train_Loss: 0.3153 Train_Acc: 86.194 Val_Loss: 0.3042  BEST VAL Loss: 0.3042  Val_Acc: 87.143

Epoch 75: Validation loss decreased (0.304185 --> 0.304079).  Saving model ...
	 Train_Loss: 0.3151 Train_Acc: 86.101 Val_Loss: 0.3041  BEST VAL Loss: 0.3041  Val_Acc: 86.907

Epoch 76: Validation loss decreased (0.304079 --> 0.303925).  Saving model ...
	 Train_Loss: 0.3148 Train_Acc: 86.238 Val_Loss: 0.3039  BEST VAL Loss: 0.3039  Val_Acc: 87.386

Epoch 77: Validation loss decreased (0.303925 --> 0.303799).  Saving model ...
	 Train_Loss: 0.3146 Train_Acc: 86.179 Val_Loss: 0.3038  BEST VAL Loss: 0.3038  Val_Acc: 86.943

Epoch 78: Validation loss decreased (0.303799 --> 0.303701).  Saving model ...
	 Train_Loss: 0.3144 Train_Acc: 86.185 Val_Loss: 0.3037  BEST VAL Loss: 0.3037  Val_Acc: 87.120

Epoch 79: Validation loss decreased (0.303701 --> 0.303519).  Saving model ...
	 Train_Loss: 0.3141 Train_Acc: 86.249 Val_Loss: 0.3035  BEST VAL Loss: 0.3035  Val_Acc: 87.051

Epoch 80: Validation loss decreased (0.303519 --> 0.303369).  Saving model ...
	 Train_Loss: 0.3139 Train_Acc: 86.082 Val_Loss: 0.3034  BEST VAL Loss: 0.3034  Val_Acc: 87.206

Epoch 81: Validation loss decreased (0.303369 --> 0.303157).  Saving model ...
	 Train_Loss: 0.3137 Train_Acc: 86.197 Val_Loss: 0.3032  BEST VAL Loss: 0.3032  Val_Acc: 87.353

Epoch 82: Validation loss decreased (0.303157 --> 0.303019).  Saving model ...
	 Train_Loss: 0.3135 Train_Acc: 86.188 Val_Loss: 0.3030  BEST VAL Loss: 0.3030  Val_Acc: 87.066

Epoch 83: Validation loss decreased (0.303019 --> 0.302916).  Saving model ...
	 Train_Loss: 0.3133 Train_Acc: 86.216 Val_Loss: 0.3029  BEST VAL Loss: 0.3029  Val_Acc: 87.099

Epoch 84: Validation loss decreased (0.302916 --> 0.302778).  Saving model ...
	 Train_Loss: 0.3131 Train_Acc: 86.208 Val_Loss: 0.3028  BEST VAL Loss: 0.3028  Val_Acc: 87.263

Epoch 85: Validation loss decreased (0.302778 --> 0.302725).  Saving model ...
	 Train_Loss: 0.3129 Train_Acc: 86.269 Val_Loss: 0.3027  BEST VAL Loss: 0.3027  Val_Acc: 87.146

Epoch 86: Validation loss decreased (0.302725 --> 0.302652).  Saving model ...
	 Train_Loss: 0.3127 Train_Acc: 86.228 Val_Loss: 0.3027  BEST VAL Loss: 0.3027  Val_Acc: 87.188

Epoch 87: Validation loss decreased (0.302652 --> 0.302515).  Saving model ...
	 Train_Loss: 0.3125 Train_Acc: 86.187 Val_Loss: 0.3025  BEST VAL Loss: 0.3025  Val_Acc: 87.096

Epoch 88: Validation loss decreased (0.302515 --> 0.302432).  Saving model ...
	 Train_Loss: 0.3123 Train_Acc: 86.200 Val_Loss: 0.3024  BEST VAL Loss: 0.3024  Val_Acc: 86.799

Epoch 89: Validation loss decreased (0.302432 --> 0.302324).  Saving model ...
	 Train_Loss: 0.3121 Train_Acc: 86.224 Val_Loss: 0.3023  BEST VAL Loss: 0.3023  Val_Acc: 87.164

Epoch 90: Validation loss decreased (0.302324 --> 0.302180).  Saving model ...
	 Train_Loss: 0.3119 Train_Acc: 86.195 Val_Loss: 0.3022  BEST VAL Loss: 0.3022  Val_Acc: 87.320

Epoch 91: Validation loss decreased (0.302180 --> 0.302038).  Saving model ...
	 Train_Loss: 0.3117 Train_Acc: 86.257 Val_Loss: 0.3020  BEST VAL Loss: 0.3020  Val_Acc: 87.194

Epoch 92: Validation loss decreased (0.302038 --> 0.301883).  Saving model ...
	 Train_Loss: 0.3115 Train_Acc: 86.262 Val_Loss: 0.3019  BEST VAL Loss: 0.3019  Val_Acc: 87.398

Epoch 93: Validation loss decreased (0.301883 --> 0.301742).  Saving model ...
	 Train_Loss: 0.3113 Train_Acc: 86.297 Val_Loss: 0.3017  BEST VAL Loss: 0.3017  Val_Acc: 87.281

Epoch 94: Validation loss decreased (0.301742 --> 0.301581).  Saving model ...
	 Train_Loss: 0.3111 Train_Acc: 86.195 Val_Loss: 0.3016  BEST VAL Loss: 0.3016  Val_Acc: 87.191

Epoch 95: Validation loss decreased (0.301581 --> 0.301443).  Saving model ...
	 Train_Loss: 0.3109 Train_Acc: 86.303 Val_Loss: 0.3014  BEST VAL Loss: 0.3014  Val_Acc: 87.015

Epoch 96: Validation loss decreased (0.301443 --> 0.301293).  Saving model ...
	 Train_Loss: 0.3108 Train_Acc: 86.266 Val_Loss: 0.3013  BEST VAL Loss: 0.3013  Val_Acc: 87.081

Epoch 97: Validation loss decreased (0.301293 --> 0.301144).  Saving model ...
	 Train_Loss: 0.3106 Train_Acc: 86.291 Val_Loss: 0.3011  BEST VAL Loss: 0.3011  Val_Acc: 87.332

Epoch 98: Validation loss decreased (0.301144 --> 0.301078).  Saving model ...
	 Train_Loss: 0.3104 Train_Acc: 86.207 Val_Loss: 0.3011  BEST VAL Loss: 0.3011  Val_Acc: 87.072

Epoch 99: Validation loss decreased (0.301078 --> 0.300947).  Saving model ...
	 Train_Loss: 0.3102 Train_Acc: 86.311 Val_Loss: 0.3009  BEST VAL Loss: 0.3009  Val_Acc: 87.167

H2O2_100.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.63      0.63      0.63    169560
           1       0.37      0.37      0.37     97754

    accuracy                           0.53    267314
   macro avg       0.50      0.50      0.50    267314
weighted avg       0.54      0.53      0.54    267314

H2O2_100.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.63      0.63      0.63     21196
           1       0.36      0.37      0.36     12219

    accuracy                           0.53     33415
   macro avg       0.50      0.50      0.50     33415
weighted avg       0.53      0.53      0.53     33415

H2O2_100.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.64      0.64      0.64     21196
           1       0.38      0.38      0.38     12219

    accuracy                           0.54     33415
   macro avg       0.51      0.51      0.51     33415
weighted avg       0.54      0.54      0.54     33415

              precision    recall  f1-score   support

           0       0.64      0.64      0.64     21196
           1       0.38      0.38      0.38     12219

    accuracy                           0.54     33415
   macro avg       0.51      0.51      0.51     33415
weighted avg       0.54      0.54      0.54     33415

H2O2_100.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.44      0.58      0.50     28584
           1       0.57      0.42      0.48     37243

    accuracy                           0.49     65827
   macro avg       0.50      0.50      0.49     65827
weighted avg       0.51      0.49      0.49     65827

              precision    recall  f1-score   support

           0       0.44      0.58      0.50     28584
           1       0.57      0.42      0.48     37243

    accuracy                           0.49     65827
   macro avg       0.50      0.50      0.49     65827
weighted avg       0.51      0.49      0.49     65827

completed
