[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1ef5e480'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'd21f1431'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'c2b5a20c'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'eeea4766'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: DMSO_0.100_DMSO_0.025 treatment_name: LPS_10.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: DMSO_0.100_DMSO_0.025
TREATMENT_NAME: LPS_10.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'LPS_10.000_DMSO_0.025']
The dimensions of the data are: (371620, 1270)
Number of total missing values across all columns: 743240
Data Subset Is Off
Wells held out for testing: ['E09' 'J06']
Wells to use for training, validation, and testing ['B06' 'C06' 'B07' 'C07' 'E02' 'E03' 'E08' 'I06' 'I07' 'J07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.384052).  Saving model ...
	 Train_Loss: 0.5161 Train_Acc: 74.439 Val_Loss: 0.3841  BEST VAL Loss: 0.3841  Val_Acc: 84.556

Epoch 1: Validation loss decreased (0.384052 --> 0.361464).  Saving model ...
	 Train_Loss: 0.4744 Train_Acc: 80.612 Val_Loss: 0.3615  BEST VAL Loss: 0.3615  Val_Acc: 86.764

Epoch 2: Validation loss decreased (0.361464 --> 0.349875).  Saving model ...
	 Train_Loss: 0.4528 Train_Acc: 81.995 Val_Loss: 0.3499  BEST VAL Loss: 0.3499  Val_Acc: 87.038

Epoch 3: Validation loss decreased (0.349875 --> 0.340678).  Saving model ...
	 Train_Loss: 0.4392 Train_Acc: 82.589 Val_Loss: 0.3407  BEST VAL Loss: 0.3407  Val_Acc: 87.610

Epoch 4: Validation loss decreased (0.340678 --> 0.334875).  Saving model ...
	 Train_Loss: 0.4297 Train_Acc: 82.871 Val_Loss: 0.3349  BEST VAL Loss: 0.3349  Val_Acc: 87.997

Epoch 5: Validation loss decreased (0.334875 --> 0.331486).  Saving model ...
	 Train_Loss: 0.4227 Train_Acc: 83.244 Val_Loss: 0.3315  BEST VAL Loss: 0.3315  Val_Acc: 87.534

Epoch 6: Validation loss decreased (0.331486 --> 0.327175).  Saving model ...
	 Train_Loss: 0.4172 Train_Acc: 83.291 Val_Loss: 0.3272  BEST VAL Loss: 0.3272  Val_Acc: 88.284

Epoch 7: Validation loss decreased (0.327175 --> 0.324421).  Saving model ...
	 Train_Loss: 0.4125 Train_Acc: 83.620 Val_Loss: 0.3244  BEST VAL Loss: 0.3244  Val_Acc: 88.132

Epoch 8: Validation loss decreased (0.324421 --> 0.321994).  Saving model ...
	 Train_Loss: 0.4084 Train_Acc: 83.740 Val_Loss: 0.3220  BEST VAL Loss: 0.3220  Val_Acc: 88.383

Epoch 9: Validation loss decreased (0.321994 --> 0.319473).  Saving model ...
	 Train_Loss: 0.4050 Train_Acc: 83.795 Val_Loss: 0.3195  BEST VAL Loss: 0.3195  Val_Acc: 88.466

Epoch 10: Validation loss decreased (0.319473 --> 0.317218).  Saving model ...
	 Train_Loss: 0.4020 Train_Acc: 84.005 Val_Loss: 0.3172  BEST VAL Loss: 0.3172  Val_Acc: 88.472

Epoch 11: Validation loss decreased (0.317218 --> 0.315237).  Saving model ...
	 Train_Loss: 0.3994 Train_Acc: 84.013 Val_Loss: 0.3152  BEST VAL Loss: 0.3152  Val_Acc: 88.568

Epoch 12: Validation loss decreased (0.315237 --> 0.313203).  Saving model ...
	 Train_Loss: 0.3972 Train_Acc: 83.949 Val_Loss: 0.3132  BEST VAL Loss: 0.3132  Val_Acc: 88.859

Epoch 13: Validation loss decreased (0.313203 --> 0.311960).  Saving model ...
	 Train_Loss: 0.3951 Train_Acc: 84.129 Val_Loss: 0.3120  BEST VAL Loss: 0.3120  Val_Acc: 88.486

Epoch 14: Validation loss decreased (0.311960 --> 0.310230).  Saving model ...
	 Train_Loss: 0.3931 Train_Acc: 84.378 Val_Loss: 0.3102  BEST VAL Loss: 0.3102  Val_Acc: 89.081

Epoch 15: Validation loss decreased (0.310230 --> 0.309002).  Saving model ...
	 Train_Loss: 0.3913 Train_Acc: 84.317 Val_Loss: 0.3090  BEST VAL Loss: 0.3090  Val_Acc: 88.823

Epoch 16: Validation loss decreased (0.309002 --> 0.307646).  Saving model ...
	 Train_Loss: 0.3897 Train_Acc: 84.474 Val_Loss: 0.3076  BEST VAL Loss: 0.3076  Val_Acc: 88.823

Epoch 17: Validation loss decreased (0.307646 --> 0.306521).  Saving model ...
	 Train_Loss: 0.3882 Train_Acc: 84.443 Val_Loss: 0.3065  BEST VAL Loss: 0.3065  Val_Acc: 88.542

Epoch 18: Validation loss decreased (0.306521 --> 0.305271).  Saving model ...
	 Train_Loss: 0.3868 Train_Acc: 84.485 Val_Loss: 0.3053  BEST VAL Loss: 0.3053  Val_Acc: 89.312

Epoch 19: Validation loss decreased (0.305271 --> 0.304193).  Saving model ...
	 Train_Loss: 0.3855 Train_Acc: 84.582 Val_Loss: 0.3042  BEST VAL Loss: 0.3042  Val_Acc: 88.889

Epoch 20: Validation loss decreased (0.304193 --> 0.303007).  Saving model ...
	 Train_Loss: 0.3844 Train_Acc: 84.610 Val_Loss: 0.3030  BEST VAL Loss: 0.3030  Val_Acc: 89.206

Epoch 21: Validation loss decreased (0.303007 --> 0.301868).  Saving model ...
	 Train_Loss: 0.3832 Train_Acc: 84.704 Val_Loss: 0.3019  BEST VAL Loss: 0.3019  Val_Acc: 89.540

Epoch 22: Validation loss decreased (0.301868 --> 0.300918).  Saving model ...
	 Train_Loss: 0.3821 Train_Acc: 84.742 Val_Loss: 0.3009  BEST VAL Loss: 0.3009  Val_Acc: 89.325

Epoch 23: Validation loss decreased (0.300918 --> 0.299991).  Saving model ...
	 Train_Loss: 0.3811 Train_Acc: 84.724 Val_Loss: 0.3000  BEST VAL Loss: 0.3000  Val_Acc: 89.385

Epoch 24: Validation loss decreased (0.299991 --> 0.299202).  Saving model ...
	 Train_Loss: 0.3802 Train_Acc: 84.779 Val_Loss: 0.2992  BEST VAL Loss: 0.2992  Val_Acc: 89.408

Epoch 25: Validation loss decreased (0.299202 --> 0.298389).  Saving model ...
	 Train_Loss: 0.3793 Train_Acc: 84.736 Val_Loss: 0.2984  BEST VAL Loss: 0.2984  Val_Acc: 89.467

Epoch 26: Validation loss decreased (0.298389 --> 0.297585).  Saving model ...
	 Train_Loss: 0.3784 Train_Acc: 84.809 Val_Loss: 0.2976  BEST VAL Loss: 0.2976  Val_Acc: 89.474

Epoch 27: Validation loss decreased (0.297585 --> 0.296988).  Saving model ...
	 Train_Loss: 0.3776 Train_Acc: 84.828 Val_Loss: 0.2970  BEST VAL Loss: 0.2970  Val_Acc: 89.352

Epoch 28: Validation loss decreased (0.296988 --> 0.296302).  Saving model ...
	 Train_Loss: 0.3768 Train_Acc: 84.924 Val_Loss: 0.2963  BEST VAL Loss: 0.2963  Val_Acc: 89.781

Epoch 29: Validation loss decreased (0.296302 --> 0.295608).  Saving model ...
	 Train_Loss: 0.3760 Train_Acc: 85.013 Val_Loss: 0.2956  BEST VAL Loss: 0.2956  Val_Acc: 89.778

Epoch 30: Validation loss decreased (0.295608 --> 0.294939).  Saving model ...
	 Train_Loss: 0.3753 Train_Acc: 84.913 Val_Loss: 0.2949  BEST VAL Loss: 0.2949  Val_Acc: 89.613

Epoch 31: Validation loss decreased (0.294939 --> 0.294357).  Saving model ...
	 Train_Loss: 0.3746 Train_Acc: 84.899 Val_Loss: 0.2944  BEST VAL Loss: 0.2944  Val_Acc: 89.728

Epoch 32: Validation loss decreased (0.294357 --> 0.293859).  Saving model ...
	 Train_Loss: 0.3740 Train_Acc: 84.953 Val_Loss: 0.2939  BEST VAL Loss: 0.2939  Val_Acc: 89.695

Epoch 33: Validation loss decreased (0.293859 --> 0.293233).  Saving model ...
	 Train_Loss: 0.3734 Train_Acc: 84.966 Val_Loss: 0.2932  BEST VAL Loss: 0.2932  Val_Acc: 90.089

Epoch 34: Validation loss decreased (0.293233 --> 0.292634).  Saving model ...
	 Train_Loss: 0.3727 Train_Acc: 85.064 Val_Loss: 0.2926  BEST VAL Loss: 0.2926  Val_Acc: 89.847

Epoch 35: Validation loss decreased (0.292634 --> 0.292135).  Saving model ...
	 Train_Loss: 0.3721 Train_Acc: 85.097 Val_Loss: 0.2921  BEST VAL Loss: 0.2921  Val_Acc: 89.824

Epoch 36: Validation loss decreased (0.292135 --> 0.291636).  Saving model ...
	 Train_Loss: 0.3716 Train_Acc: 85.054 Val_Loss: 0.2916  BEST VAL Loss: 0.2916  Val_Acc: 89.940

Epoch 37: Validation loss decreased (0.291636 --> 0.291200).  Saving model ...
	 Train_Loss: 0.3710 Train_Acc: 85.098 Val_Loss: 0.2912  BEST VAL Loss: 0.2912  Val_Acc: 89.960

Epoch 38: Validation loss decreased (0.291200 --> 0.290764).  Saving model ...
	 Train_Loss: 0.3705 Train_Acc: 85.080 Val_Loss: 0.2908  BEST VAL Loss: 0.2908  Val_Acc: 89.834

Epoch 39: Validation loss decreased (0.290764 --> 0.290269).  Saving model ...
	 Train_Loss: 0.3699 Train_Acc: 85.331 Val_Loss: 0.2903  BEST VAL Loss: 0.2903  Val_Acc: 89.785

Epoch 40: Validation loss decreased (0.290269 --> 0.289798).  Saving model ...
	 Train_Loss: 0.3694 Train_Acc: 85.232 Val_Loss: 0.2898  BEST VAL Loss: 0.2898  Val_Acc: 89.847

Epoch 41: Validation loss decreased (0.289798 --> 0.289345).  Saving model ...
	 Train_Loss: 0.3689 Train_Acc: 85.241 Val_Loss: 0.2893  BEST VAL Loss: 0.2893  Val_Acc: 90.095

Epoch 42: Validation loss decreased (0.289345 --> 0.289132).  Saving model ...
	 Train_Loss: 0.3684 Train_Acc: 85.247 Val_Loss: 0.2891  BEST VAL Loss: 0.2891  Val_Acc: 89.213

Epoch 43: Validation loss decreased (0.289132 --> 0.288774).  Saving model ...
	 Train_Loss: 0.3680 Train_Acc: 85.122 Val_Loss: 0.2888  BEST VAL Loss: 0.2888  Val_Acc: 89.639

Epoch 44: Validation loss decreased (0.288774 --> 0.288316).  Saving model ...
	 Train_Loss: 0.3675 Train_Acc: 85.254 Val_Loss: 0.2883  BEST VAL Loss: 0.2883  Val_Acc: 90.052

Epoch 45: Validation loss decreased (0.288316 --> 0.287866).  Saving model ...
	 Train_Loss: 0.3671 Train_Acc: 85.367 Val_Loss: 0.2879  BEST VAL Loss: 0.2879  Val_Acc: 90.135

Epoch 46: Validation loss decreased (0.287866 --> 0.287457).  Saving model ...
	 Train_Loss: 0.3666 Train_Acc: 85.332 Val_Loss: 0.2875  BEST VAL Loss: 0.2875  Val_Acc: 90.241

Epoch 47: Validation loss decreased (0.287457 --> 0.287111).  Saving model ...
	 Train_Loss: 0.3662 Train_Acc: 85.377 Val_Loss: 0.2871  BEST VAL Loss: 0.2871  Val_Acc: 89.603

Epoch 48: Validation loss decreased (0.287111 --> 0.286693).  Saving model ...
	 Train_Loss: 0.3659 Train_Acc: 85.177 Val_Loss: 0.2867  BEST VAL Loss: 0.2867  Val_Acc: 89.980

Epoch 49: Validation loss decreased (0.286693 --> 0.286354).  Saving model ...
	 Train_Loss: 0.3654 Train_Acc: 85.510 Val_Loss: 0.2864  BEST VAL Loss: 0.2864  Val_Acc: 89.619

Epoch 50: Validation loss decreased (0.286354 --> 0.286006).  Saving model ...
	 Train_Loss: 0.3651 Train_Acc: 85.271 Val_Loss: 0.2860  BEST VAL Loss: 0.2860  Val_Acc: 90.171

Epoch 51: Validation loss decreased (0.286006 --> 0.285641).  Saving model ...
	 Train_Loss: 0.3647 Train_Acc: 85.405 Val_Loss: 0.2856  BEST VAL Loss: 0.2856  Val_Acc: 90.204

Epoch 52: Validation loss decreased (0.285641 --> 0.285278).  Saving model ...
	 Train_Loss: 0.3644 Train_Acc: 85.396 Val_Loss: 0.2853  BEST VAL Loss: 0.2853  Val_Acc: 90.052

Epoch 53: Validation loss decreased (0.285278 --> 0.284952).  Saving model ...
	 Train_Loss: 0.3640 Train_Acc: 85.429 Val_Loss: 0.2850  BEST VAL Loss: 0.2850  Val_Acc: 89.841

Epoch 54: Validation loss decreased (0.284952 --> 0.284642).  Saving model ...
	 Train_Loss: 0.3637 Train_Acc: 85.296 Val_Loss: 0.2846  BEST VAL Loss: 0.2846  Val_Acc: 90.165

Epoch 55: Validation loss decreased (0.284642 --> 0.284362).  Saving model ...
	 Train_Loss: 0.3633 Train_Acc: 85.520 Val_Loss: 0.2844  BEST VAL Loss: 0.2844  Val_Acc: 89.874

Epoch 56: Validation loss decreased (0.284362 --> 0.284027).  Saving model ...
	 Train_Loss: 0.3630 Train_Acc: 85.512 Val_Loss: 0.2840  BEST VAL Loss: 0.2840  Val_Acc: 90.386

Epoch 57: Validation loss decreased (0.284027 --> 0.283781).  Saving model ...
	 Train_Loss: 0.3627 Train_Acc: 85.480 Val_Loss: 0.2838  BEST VAL Loss: 0.2838  Val_Acc: 90.346

Epoch 58: Validation loss decreased (0.283781 --> 0.283510).  Saving model ...
	 Train_Loss: 0.3623 Train_Acc: 85.619 Val_Loss: 0.2835  BEST VAL Loss: 0.2835  Val_Acc: 89.827

Epoch 59: Validation loss decreased (0.283510 --> 0.283207).  Saving model ...
	 Train_Loss: 0.3620 Train_Acc: 85.648 Val_Loss: 0.2832  BEST VAL Loss: 0.2832  Val_Acc: 90.284

Epoch 60: Validation loss decreased (0.283207 --> 0.282917).  Saving model ...
	 Train_Loss: 0.3617 Train_Acc: 85.551 Val_Loss: 0.2829  BEST VAL Loss: 0.2829  Val_Acc: 90.174

Epoch 61: Validation loss decreased (0.282917 --> 0.282708).  Saving model ...
	 Train_Loss: 0.3614 Train_Acc: 85.465 Val_Loss: 0.2827  BEST VAL Loss: 0.2827  Val_Acc: 89.788

Epoch 62: Validation loss decreased (0.282708 --> 0.282476).  Saving model ...
	 Train_Loss: 0.3611 Train_Acc: 85.582 Val_Loss: 0.2825  BEST VAL Loss: 0.2825  Val_Acc: 89.980

Epoch 63: Validation loss decreased (0.282476 --> 0.282284).  Saving model ...
	 Train_Loss: 0.3608 Train_Acc: 85.559 Val_Loss: 0.2823  BEST VAL Loss: 0.2823  Val_Acc: 89.778

Epoch 64: Validation loss decreased (0.282284 --> 0.282096).  Saving model ...
	 Train_Loss: 0.3605 Train_Acc: 85.519 Val_Loss: 0.2821  BEST VAL Loss: 0.2821  Val_Acc: 89.861

Epoch 65: Validation loss decreased (0.282096 --> 0.281876).  Saving model ...
	 Train_Loss: 0.3603 Train_Acc: 85.511 Val_Loss: 0.2819  BEST VAL Loss: 0.2819  Val_Acc: 90.065

Epoch 66: Validation loss decreased (0.281876 --> 0.281612).  Saving model ...
	 Train_Loss: 0.3600 Train_Acc: 85.572 Val_Loss: 0.2816  BEST VAL Loss: 0.2816  Val_Acc: 90.333

Epoch 67: Validation loss decreased (0.281612 --> 0.281452).  Saving model ...
	 Train_Loss: 0.3597 Train_Acc: 85.641 Val_Loss: 0.2815  BEST VAL Loss: 0.2815  Val_Acc: 89.728

Epoch 68: Validation loss decreased (0.281452 --> 0.281238).  Saving model ...
	 Train_Loss: 0.3594 Train_Acc: 85.633 Val_Loss: 0.2812  BEST VAL Loss: 0.2812  Val_Acc: 89.953

Epoch 69: Validation loss decreased (0.281238 --> 0.280969).  Saving model ...
	 Train_Loss: 0.3592 Train_Acc: 85.612 Val_Loss: 0.2810  BEST VAL Loss: 0.2810  Val_Acc: 90.178

Epoch 70: Validation loss decreased (0.280969 --> 0.280740).  Saving model ...
	 Train_Loss: 0.3589 Train_Acc: 85.618 Val_Loss: 0.2807  BEST VAL Loss: 0.2807  Val_Acc: 90.446

Epoch 71: Validation loss decreased (0.280740 --> 0.280493).  Saving model ...
	 Train_Loss: 0.3587 Train_Acc: 85.547 Val_Loss: 0.2805  BEST VAL Loss: 0.2805  Val_Acc: 90.386

Epoch 72: Validation loss decreased (0.280493 --> 0.280290).  Saving model ...
	 Train_Loss: 0.3585 Train_Acc: 85.746 Val_Loss: 0.2803  BEST VAL Loss: 0.2803  Val_Acc: 90.426

Epoch 73: Validation loss decreased (0.280290 --> 0.280072).  Saving model ...
	 Train_Loss: 0.3582 Train_Acc: 85.631 Val_Loss: 0.2801  BEST VAL Loss: 0.2801  Val_Acc: 90.022

Epoch 74: Validation loss decreased (0.280072 --> 0.279895).  Saving model ...
	 Train_Loss: 0.3580 Train_Acc: 85.693 Val_Loss: 0.2799  BEST VAL Loss: 0.2799  Val_Acc: 90.251

Epoch 75: Validation loss decreased (0.279895 --> 0.279691).  Saving model ...
	 Train_Loss: 0.3577 Train_Acc: 85.691 Val_Loss: 0.2797  BEST VAL Loss: 0.2797  Val_Acc: 90.274

Epoch 76: Validation loss decreased (0.279691 --> 0.279558).  Saving model ...
	 Train_Loss: 0.3575 Train_Acc: 85.693 Val_Loss: 0.2796  BEST VAL Loss: 0.2796  Val_Acc: 90.333

Epoch 77: Validation loss decreased (0.279558 --> 0.279369).  Saving model ...
	 Train_Loss: 0.3573 Train_Acc: 85.718 Val_Loss: 0.2794  BEST VAL Loss: 0.2794  Val_Acc: 89.999

Epoch 78: Validation loss decreased (0.279369 --> 0.279143).  Saving model ...
	 Train_Loss: 0.3570 Train_Acc: 85.709 Val_Loss: 0.2791  BEST VAL Loss: 0.2791  Val_Acc: 90.178

Epoch 79: Validation loss decreased (0.279143 --> 0.278957).  Saving model ...
	 Train_Loss: 0.3568 Train_Acc: 85.840 Val_Loss: 0.2790  BEST VAL Loss: 0.2790  Val_Acc: 89.943

Epoch 80: Validation loss decreased (0.278957 --> 0.278716).  Saving model ...
	 Train_Loss: 0.3566 Train_Acc: 85.788 Val_Loss: 0.2787  BEST VAL Loss: 0.2787  Val_Acc: 90.221

Epoch 81: Validation loss decreased (0.278716 --> 0.278510).  Saving model ...
	 Train_Loss: 0.3564 Train_Acc: 85.800 Val_Loss: 0.2785  BEST VAL Loss: 0.2785  Val_Acc: 90.313

Epoch 82: Validation loss decreased (0.278510 --> 0.278357).  Saving model ...
	 Train_Loss: 0.3562 Train_Acc: 85.785 Val_Loss: 0.2784  BEST VAL Loss: 0.2784  Val_Acc: 90.079

Epoch 83: Validation loss decreased (0.278357 --> 0.278199).  Saving model ...
	 Train_Loss: 0.3560 Train_Acc: 85.725 Val_Loss: 0.2782  BEST VAL Loss: 0.2782  Val_Acc: 90.158

Epoch 84: Validation loss decreased (0.278199 --> 0.277998).  Saving model ...
	 Train_Loss: 0.3558 Train_Acc: 85.799 Val_Loss: 0.2780  BEST VAL Loss: 0.2780  Val_Acc: 90.310

Epoch 85: Validation loss decreased (0.277998 --> 0.277836).  Saving model ...
	 Train_Loss: 0.3556 Train_Acc: 85.743 Val_Loss: 0.2778  BEST VAL Loss: 0.2778  Val_Acc: 90.518

Epoch 86: Validation loss decreased (0.277836 --> 0.277692).  Saving model ...
	 Train_Loss: 0.3554 Train_Acc: 85.720 Val_Loss: 0.2777  BEST VAL Loss: 0.2777  Val_Acc: 90.320

Epoch 87: Validation loss decreased (0.277692 --> 0.277517).  Saving model ...
	 Train_Loss: 0.3552 Train_Acc: 85.715 Val_Loss: 0.2775  BEST VAL Loss: 0.2775  Val_Acc: 90.373

Epoch 88: Validation loss decreased (0.277517 --> 0.277338).  Saving model ...
	 Train_Loss: 0.3550 Train_Acc: 85.806 Val_Loss: 0.2773  BEST VAL Loss: 0.2773  Val_Acc: 90.082

Epoch 89: Validation loss decreased (0.277338 --> 0.277201).  Saving model ...
	 Train_Loss: 0.3549 Train_Acc: 85.799 Val_Loss: 0.2772  BEST VAL Loss: 0.2772  Val_Acc: 90.412

Epoch 90: Validation loss decreased (0.277201 --> 0.277104).  Saving model ...
	 Train_Loss: 0.3547 Train_Acc: 85.752 Val_Loss: 0.2771  BEST VAL Loss: 0.2771  Val_Acc: 90.138

Epoch 91: Validation loss decreased (0.277104 --> 0.276909).  Saving model ...
	 Train_Loss: 0.3545 Train_Acc: 85.754 Val_Loss: 0.2769  BEST VAL Loss: 0.2769  Val_Acc: 90.512

Epoch 92: Validation loss decreased (0.276909 --> 0.276730).  Saving model ...
	 Train_Loss: 0.3543 Train_Acc: 85.817 Val_Loss: 0.2767  BEST VAL Loss: 0.2767  Val_Acc: 90.452

Epoch 93: Validation loss decreased (0.276730 --> 0.276573).  Saving model ...
	 Train_Loss: 0.3542 Train_Acc: 85.803 Val_Loss: 0.2766  BEST VAL Loss: 0.2766  Val_Acc: 90.591

Epoch 94: Validation loss decreased (0.276573 --> 0.276406).  Saving model ...
	 Train_Loss: 0.3540 Train_Acc: 85.770 Val_Loss: 0.2764  BEST VAL Loss: 0.2764  Val_Acc: 90.551

Epoch 95: Validation loss decreased (0.276406 --> 0.276247).  Saving model ...
	 Train_Loss: 0.3538 Train_Acc: 85.928 Val_Loss: 0.2762  BEST VAL Loss: 0.2762  Val_Acc: 90.383

Epoch 96: Validation loss decreased (0.276247 --> 0.276125).  Saving model ...
	 Train_Loss: 0.3536 Train_Acc: 85.782 Val_Loss: 0.2761  BEST VAL Loss: 0.2761  Val_Acc: 90.446

Epoch 97: Validation loss decreased (0.276125 --> 0.276017).  Saving model ...
	 Train_Loss: 0.3535 Train_Acc: 85.829 Val_Loss: 0.2760  BEST VAL Loss: 0.2760  Val_Acc: 90.482

Epoch 98: Validation loss decreased (0.276017 --> 0.275843).  Saving model ...
	 Train_Loss: 0.3533 Train_Acc: 85.845 Val_Loss: 0.2758  BEST VAL Loss: 0.2758  Val_Acc: 90.257

Epoch 99: Validation loss decreased (0.275843 --> 0.275687).  Saving model ...
	 Train_Loss: 0.3531 Train_Acc: 85.881 Val_Loss: 0.2757  BEST VAL Loss: 0.2757  Val_Acc: 90.336

DMSO_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.62      0.60      0.61    149884
           1       0.38      0.40      0.39     92173

    accuracy                           0.52    242057
   macro avg       0.50      0.50      0.50    242057
weighted avg       0.53      0.52      0.53    242057

DMSO_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.62      0.60      0.61     18736
           1       0.38      0.40      0.39     11522

    accuracy                           0.53     30258
   macro avg       0.50      0.50      0.50     30258
weighted avg       0.53      0.53      0.53     30258

DMSO_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.62      0.60      0.61     18736
           1       0.38      0.39      0.38     11522

    accuracy                           0.52     30258
   macro avg       0.50      0.50      0.50     30258
weighted avg       0.52      0.52      0.52     30258

              precision    recall  f1-score   support

           0       0.62      0.60      0.61     18736
           1       0.38      0.39      0.38     11522

    accuracy                           0.52     30258
   macro avg       0.50      0.50      0.50     30258
weighted avg       0.52      0.52      0.52     30258

DMSO_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.40      0.51      0.45     27774
           1       0.60      0.49      0.54     41273

    accuracy                           0.50     69047
   macro avg       0.50      0.50      0.49     69047
weighted avg       0.52      0.50      0.50     69047

              precision    recall  f1-score   support

           0       0.40      0.51      0.45     27774
           1       0.60      0.49      0.54     41273

    accuracy                           0.50     69047
   macro avg       0.50      0.50      0.49     69047
weighted avg       0.52      0.50      0.50     69047

completed
