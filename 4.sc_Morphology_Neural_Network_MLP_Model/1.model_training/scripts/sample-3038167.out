[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '377910be'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '75344350'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '821cfb6e'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'b14b9d19'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_100.000_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (325448, 1270)
Number of total missing values across all columns: 318870
Data Subset Is Off
Wells held out for testing: ['K08' 'J09']
Wells to use for training, validation, and testing ['J02' 'K02' 'J03' 'K03' 'J08' 'K09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.468181).  Saving model ...
	 Train_Loss: 0.5446 Train_Acc: 72.948 Val_Loss: 0.4682  BEST VAL Loss: 0.4682  Val_Acc: 78.408

Epoch 1: Validation loss decreased (0.468181 --> 0.435576).  Saving model ...
	 Train_Loss: 0.5001 Train_Acc: 78.687 Val_Loss: 0.4356  BEST VAL Loss: 0.4356  Val_Acc: 82.006

Epoch 2: Validation loss decreased (0.435576 --> 0.412312).  Saving model ...
	 Train_Loss: 0.4705 Train_Acc: 81.177 Val_Loss: 0.4123  BEST VAL Loss: 0.4123  Val_Acc: 83.909

Epoch 3: Validation loss decreased (0.412312 --> 0.397889).  Saving model ...
	 Train_Loss: 0.4506 Train_Acc: 82.328 Val_Loss: 0.3979  BEST VAL Loss: 0.3979  Val_Acc: 84.561

Epoch 4: Validation loss decreased (0.397889 --> 0.386765).  Saving model ...
	 Train_Loss: 0.4359 Train_Acc: 82.967 Val_Loss: 0.3868  BEST VAL Loss: 0.3868  Val_Acc: 85.087

Epoch 5: Validation loss decreased (0.386765 --> 0.382061).  Saving model ...
	 Train_Loss: 0.4246 Train_Acc: 83.504 Val_Loss: 0.3821  BEST VAL Loss: 0.3821  Val_Acc: 83.820

Epoch 6: Validation loss decreased (0.382061 --> 0.374030).  Saving model ...
	 Train_Loss: 0.4153 Train_Acc: 83.910 Val_Loss: 0.3740  BEST VAL Loss: 0.3740  Val_Acc: 85.955

Epoch 7: Validation loss decreased (0.374030 --> 0.367181).  Saving model ...
	 Train_Loss: 0.4075 Train_Acc: 84.249 Val_Loss: 0.3672  BEST VAL Loss: 0.3672  Val_Acc: 86.403

Epoch 8: Validation loss decreased (0.367181 --> 0.361075).  Saving model ...
	 Train_Loss: 0.4009 Train_Acc: 84.631 Val_Loss: 0.3611  BEST VAL Loss: 0.3611  Val_Acc: 86.794

Epoch 9: Validation loss decreased (0.361075 --> 0.355785).  Saving model ...
	 Train_Loss: 0.3950 Train_Acc: 85.031 Val_Loss: 0.3558  BEST VAL Loss: 0.3558  Val_Acc: 87.022

Epoch 10: Validation loss decreased (0.355785 --> 0.351423).  Saving model ...
	 Train_Loss: 0.3899 Train_Acc: 85.176 Val_Loss: 0.3514  BEST VAL Loss: 0.3514  Val_Acc: 86.933

Epoch 11: Validation loss decreased (0.351423 --> 0.348168).  Saving model ...
	 Train_Loss: 0.3852 Train_Acc: 85.390 Val_Loss: 0.3482  BEST VAL Loss: 0.3482  Val_Acc: 86.900

Epoch 12: Validation loss decreased (0.348168 --> 0.344327).  Saving model ...
	 Train_Loss: 0.3809 Train_Acc: 85.689 Val_Loss: 0.3443  BEST VAL Loss: 0.3443  Val_Acc: 87.613

Epoch 13: Validation loss decreased (0.344327 --> 0.341831).  Saving model ...
	 Train_Loss: 0.3771 Train_Acc: 85.794 Val_Loss: 0.3418  BEST VAL Loss: 0.3418  Val_Acc: 86.823

Epoch 14: Validation loss decreased (0.341831 --> 0.339962).  Saving model ...
	 Train_Loss: 0.3735 Train_Acc: 85.942 Val_Loss: 0.3400  BEST VAL Loss: 0.3400  Val_Acc: 86.855

Epoch 15: Validation loss decreased (0.339962 --> 0.337191).  Saving model ...
	 Train_Loss: 0.3703 Train_Acc: 86.021 Val_Loss: 0.3372  BEST VAL Loss: 0.3372  Val_Acc: 87.796

Epoch 16: Validation loss decreased (0.337191 --> 0.334551).  Saving model ...
	 Train_Loss: 0.3673 Train_Acc: 86.211 Val_Loss: 0.3346  BEST VAL Loss: 0.3346  Val_Acc: 87.690

Epoch 17: Validation loss decreased (0.334551 --> 0.331926).  Saving model ...
	 Train_Loss: 0.3644 Train_Acc: 86.349 Val_Loss: 0.3319  BEST VAL Loss: 0.3319  Val_Acc: 88.000

Epoch 18: Validation loss decreased (0.331926 --> 0.329496).  Saving model ...
	 Train_Loss: 0.3619 Train_Acc: 86.278 Val_Loss: 0.3295  BEST VAL Loss: 0.3295  Val_Acc: 88.037

Epoch 19: Validation loss decreased (0.329496 --> 0.327169).  Saving model ...
	 Train_Loss: 0.3593 Train_Acc: 86.478 Val_Loss: 0.3272  BEST VAL Loss: 0.3272  Val_Acc: 88.196

Epoch 20: Validation loss decreased (0.327169 --> 0.324960).  Saving model ...
	 Train_Loss: 0.3570 Train_Acc: 86.572 Val_Loss: 0.3250  BEST VAL Loss: 0.3250  Val_Acc: 88.420

Epoch 21: Validation loss decreased (0.324960 --> 0.323044).  Saving model ...
	 Train_Loss: 0.3549 Train_Acc: 86.667 Val_Loss: 0.3230  BEST VAL Loss: 0.3230  Val_Acc: 87.972

Epoch 22: Validation loss decreased (0.323044 --> 0.321097).  Saving model ...
	 Train_Loss: 0.3528 Train_Acc: 86.735 Val_Loss: 0.3211  BEST VAL Loss: 0.3211  Val_Acc: 88.489

Epoch 23: Validation loss decreased (0.321097 --> 0.320160).  Saving model ...
	 Train_Loss: 0.3508 Train_Acc: 86.835 Val_Loss: 0.3202  BEST VAL Loss: 0.3202  Val_Acc: 87.397

Epoch 24: Validation loss decreased (0.320160 --> 0.318804).  Saving model ...
	 Train_Loss: 0.3489 Train_Acc: 86.857 Val_Loss: 0.3188  BEST VAL Loss: 0.3188  Val_Acc: 88.045

Epoch 25: Validation loss decreased (0.318804 --> 0.317119).  Saving model ...
	 Train_Loss: 0.3472 Train_Acc: 86.971 Val_Loss: 0.3171  BEST VAL Loss: 0.3171  Val_Acc: 88.738

Epoch 26: Validation loss decreased (0.317119 --> 0.315580).  Saving model ...
	 Train_Loss: 0.3455 Train_Acc: 86.893 Val_Loss: 0.3156  BEST VAL Loss: 0.3156  Val_Acc: 88.440

Epoch 27: Validation loss decreased (0.315580 --> 0.314428).  Saving model ...
	 Train_Loss: 0.3439 Train_Acc: 86.915 Val_Loss: 0.3144  BEST VAL Loss: 0.3144  Val_Acc: 88.184

Epoch 28: Validation loss decreased (0.314428 --> 0.312871).  Saving model ...
	 Train_Loss: 0.3424 Train_Acc: 87.087 Val_Loss: 0.3129  BEST VAL Loss: 0.3129  Val_Acc: 88.872

Epoch 29: Validation loss decreased (0.312871 --> 0.311679).  Saving model ...
	 Train_Loss: 0.3410 Train_Acc: 87.004 Val_Loss: 0.3117  BEST VAL Loss: 0.3117  Val_Acc: 88.701

Epoch 30: Validation loss decreased (0.311679 --> 0.310403).  Saving model ...
	 Train_Loss: 0.3396 Train_Acc: 87.130 Val_Loss: 0.3104  BEST VAL Loss: 0.3104  Val_Acc: 88.725

Epoch 31: Validation loss decreased (0.310403 --> 0.309275).  Saving model ...
	 Train_Loss: 0.3383 Train_Acc: 87.178 Val_Loss: 0.3093  BEST VAL Loss: 0.3093  Val_Acc: 88.738

Epoch 32: Validation loss decreased (0.309275 --> 0.308224).  Saving model ...
	 Train_Loss: 0.3370 Train_Acc: 87.231 Val_Loss: 0.3082  BEST VAL Loss: 0.3082  Val_Acc: 88.795

Epoch 33: Validation loss decreased (0.308224 --> 0.306995).  Saving model ...
	 Train_Loss: 0.3357 Train_Acc: 87.232 Val_Loss: 0.3070  BEST VAL Loss: 0.3070  Val_Acc: 89.064

Epoch 34: Validation loss decreased (0.306995 --> 0.305949).  Saving model ...
	 Train_Loss: 0.3345 Train_Acc: 87.405 Val_Loss: 0.3059  BEST VAL Loss: 0.3059  Val_Acc: 88.787

Epoch 35: Validation loss decreased (0.305949 --> 0.304841).  Saving model ...
	 Train_Loss: 0.3334 Train_Acc: 87.394 Val_Loss: 0.3048  BEST VAL Loss: 0.3048  Val_Acc: 89.223

Epoch 36: Validation loss decreased (0.304841 --> 0.303762).  Saving model ...
	 Train_Loss: 0.3323 Train_Acc: 87.307 Val_Loss: 0.3038  BEST VAL Loss: 0.3038  Val_Acc: 89.149

Epoch 37: Validation loss decreased (0.303762 --> 0.302929).  Saving model ...
	 Train_Loss: 0.3313 Train_Acc: 87.358 Val_Loss: 0.3029  BEST VAL Loss: 0.3029  Val_Acc: 88.782

Epoch 38: Validation loss decreased (0.302929 --> 0.302093).  Saving model ...
	 Train_Loss: 0.3302 Train_Acc: 87.445 Val_Loss: 0.3021  BEST VAL Loss: 0.3021  Val_Acc: 89.007

Epoch 39: Validation loss decreased (0.302093 --> 0.301289).  Saving model ...
	 Train_Loss: 0.3292 Train_Acc: 87.468 Val_Loss: 0.3013  BEST VAL Loss: 0.3013  Val_Acc: 88.717

Epoch 40: Validation loss decreased (0.301289 --> 0.300547).  Saving model ...
	 Train_Loss: 0.3283 Train_Acc: 87.443 Val_Loss: 0.3005  BEST VAL Loss: 0.3005  Val_Acc: 88.905

Epoch 41: Validation loss decreased (0.300547 --> 0.299687).  Saving model ...
	 Train_Loss: 0.3274 Train_Acc: 87.529 Val_Loss: 0.2997  BEST VAL Loss: 0.2997  Val_Acc: 89.227

Epoch 42: Validation loss decreased (0.299687 --> 0.298809).  Saving model ...
	 Train_Loss: 0.3265 Train_Acc: 87.512 Val_Loss: 0.2988  BEST VAL Loss: 0.2988  Val_Acc: 89.223

Epoch 43: Validation loss decreased (0.298809 --> 0.297967).  Saving model ...
	 Train_Loss: 0.3256 Train_Acc: 87.609 Val_Loss: 0.2980  BEST VAL Loss: 0.2980  Val_Acc: 89.276

Epoch 44: Validation loss decreased (0.297967 --> 0.297857).  Saving model ...
	 Train_Loss: 0.3248 Train_Acc: 87.619 Val_Loss: 0.2979  BEST VAL Loss: 0.2979  Val_Acc: 87.837

Epoch 45: Validation loss decreased (0.297857 --> 0.297068).  Saving model ...
	 Train_Loss: 0.3239 Train_Acc: 87.623 Val_Loss: 0.2971  BEST VAL Loss: 0.2971  Val_Acc: 89.170

Epoch 46: Validation loss decreased (0.297068 --> 0.296464).  Saving model ...
	 Train_Loss: 0.3232 Train_Acc: 87.583 Val_Loss: 0.2965  BEST VAL Loss: 0.2965  Val_Acc: 88.897

Epoch 47: Validation loss decreased (0.296464 --> 0.295685).  Saving model ...
	 Train_Loss: 0.3224 Train_Acc: 87.722 Val_Loss: 0.2957  BEST VAL Loss: 0.2957  Val_Acc: 89.324

Epoch 48: Validation loss decreased (0.295685 --> 0.295058).  Saving model ...
	 Train_Loss: 0.3216 Train_Acc: 87.730 Val_Loss: 0.2951  BEST VAL Loss: 0.2951  Val_Acc: 89.007

Epoch 49: Validation loss decreased (0.295058 --> 0.294392).  Saving model ...
	 Train_Loss: 0.3209 Train_Acc: 87.632 Val_Loss: 0.2944  BEST VAL Loss: 0.2944  Val_Acc: 89.357

Epoch 50: Validation loss decreased (0.294392 --> 0.293768).  Saving model ...
	 Train_Loss: 0.3202 Train_Acc: 87.761 Val_Loss: 0.2938  BEST VAL Loss: 0.2938  Val_Acc: 89.198

Epoch 51: Validation loss decreased (0.293768 --> 0.293198).  Saving model ...
	 Train_Loss: 0.3195 Train_Acc: 87.768 Val_Loss: 0.2932  BEST VAL Loss: 0.2932  Val_Acc: 89.117

Epoch 52: Validation loss decreased (0.293198 --> 0.292621).  Saving model ...
	 Train_Loss: 0.3188 Train_Acc: 87.695 Val_Loss: 0.2926  BEST VAL Loss: 0.2926  Val_Acc: 89.251

Epoch 53: Validation loss decreased (0.292621 --> 0.292132).  Saving model ...
	 Train_Loss: 0.3182 Train_Acc: 87.809 Val_Loss: 0.2921  BEST VAL Loss: 0.2921  Val_Acc: 89.096

Epoch 54: Validation loss decreased (0.292132 --> 0.291473).  Saving model ...
	 Train_Loss: 0.3175 Train_Acc: 87.814 Val_Loss: 0.2915  BEST VAL Loss: 0.2915  Val_Acc: 89.434

Epoch 55: Validation loss decreased (0.291473 --> 0.290886).  Saving model ...
	 Train_Loss: 0.3169 Train_Acc: 87.680 Val_Loss: 0.2909  BEST VAL Loss: 0.2909  Val_Acc: 89.239

Epoch 56: Validation loss decreased (0.290886 --> 0.290336).  Saving model ...
	 Train_Loss: 0.3163 Train_Acc: 87.830 Val_Loss: 0.2903  BEST VAL Loss: 0.2903  Val_Acc: 89.418

Epoch 57: Validation loss decreased (0.290336 --> 0.289908).  Saving model ...
	 Train_Loss: 0.3157 Train_Acc: 87.911 Val_Loss: 0.2899  BEST VAL Loss: 0.2899  Val_Acc: 89.284

Epoch 58: Validation loss decreased (0.289908 --> 0.289415).  Saving model ...
	 Train_Loss: 0.3151 Train_Acc: 87.904 Val_Loss: 0.2894  BEST VAL Loss: 0.2894  Val_Acc: 89.402

Epoch 59: Validation loss decreased (0.289415 --> 0.288916).  Saving model ...
	 Train_Loss: 0.3146 Train_Acc: 87.881 Val_Loss: 0.2889  BEST VAL Loss: 0.2889  Val_Acc: 89.377

Epoch 60: Validation loss decreased (0.288916 --> 0.288340).  Saving model ...
	 Train_Loss: 0.3140 Train_Acc: 87.956 Val_Loss: 0.2883  BEST VAL Loss: 0.2883  Val_Acc: 89.659

Epoch 61: Validation loss decreased (0.288340 --> 0.287788).  Saving model ...
	 Train_Loss: 0.3134 Train_Acc: 87.865 Val_Loss: 0.2878  BEST VAL Loss: 0.2878  Val_Acc: 89.646

Epoch 62: Validation loss decreased (0.287788 --> 0.287386).  Saving model ...
	 Train_Loss: 0.3129 Train_Acc: 87.901 Val_Loss: 0.2874  BEST VAL Loss: 0.2874  Val_Acc: 89.092

Epoch 63: Validation loss decreased (0.287386 --> 0.287014).  Saving model ...
	 Train_Loss: 0.3124 Train_Acc: 87.941 Val_Loss: 0.2870  BEST VAL Loss: 0.2870  Val_Acc: 89.284

Epoch 64: Validation loss decreased (0.287014 --> 0.286591).  Saving model ...
	 Train_Loss: 0.3119 Train_Acc: 88.067 Val_Loss: 0.2866  BEST VAL Loss: 0.2866  Val_Acc: 89.316

Epoch 65: Validation loss decreased (0.286591 --> 0.286151).  Saving model ...
	 Train_Loss: 0.3114 Train_Acc: 87.966 Val_Loss: 0.2862  BEST VAL Loss: 0.2862  Val_Acc: 89.414

Epoch 66: Validation loss decreased (0.286151 --> 0.285691).  Saving model ...
	 Train_Loss: 0.3109 Train_Acc: 88.091 Val_Loss: 0.2857  BEST VAL Loss: 0.2857  Val_Acc: 89.667

Epoch 67: Validation loss decreased (0.285691 --> 0.285316).  Saving model ...
	 Train_Loss: 0.3104 Train_Acc: 87.972 Val_Loss: 0.2853  BEST VAL Loss: 0.2853  Val_Acc: 89.451

Epoch 68: Validation loss decreased (0.285316 --> 0.284968).  Saving model ...
	 Train_Loss: 0.3099 Train_Acc: 88.052 Val_Loss: 0.2850  BEST VAL Loss: 0.2850  Val_Acc: 89.406

Epoch 69: Validation loss decreased (0.284968 --> 0.284698).  Saving model ...
	 Train_Loss: 0.3094 Train_Acc: 88.070 Val_Loss: 0.2847  BEST VAL Loss: 0.2847  Val_Acc: 88.994

Epoch 70: Validation loss decreased (0.284698 --> 0.284290).  Saving model ...
	 Train_Loss: 0.3090 Train_Acc: 88.064 Val_Loss: 0.2843  BEST VAL Loss: 0.2843  Val_Acc: 89.589

Epoch 71: Validation loss decreased (0.284290 --> 0.283864).  Saving model ...
	 Train_Loss: 0.3085 Train_Acc: 88.015 Val_Loss: 0.2839  BEST VAL Loss: 0.2839  Val_Acc: 89.544

Epoch 72: Validation loss decreased (0.283864 --> 0.283523).  Saving model ...
	 Train_Loss: 0.3081 Train_Acc: 88.107 Val_Loss: 0.2835  BEST VAL Loss: 0.2835  Val_Acc: 89.569

Epoch 73: Validation loss decreased (0.283523 --> 0.283139).  Saving model ...
	 Train_Loss: 0.3077 Train_Acc: 88.054 Val_Loss: 0.2831  BEST VAL Loss: 0.2831  Val_Acc: 89.601

Epoch 74: Validation loss decreased (0.283139 --> 0.282809).  Saving model ...
	 Train_Loss: 0.3073 Train_Acc: 88.130 Val_Loss: 0.2828  BEST VAL Loss: 0.2828  Val_Acc: 89.381

Epoch 75: Validation loss decreased (0.282809 --> 0.282632).  Saving model ...
	 Train_Loss: 0.3069 Train_Acc: 88.074 Val_Loss: 0.2826  BEST VAL Loss: 0.2826  Val_Acc: 88.990

Epoch 76: Validation loss decreased (0.282632 --> 0.282239).  Saving model ...
	 Train_Loss: 0.3065 Train_Acc: 88.106 Val_Loss: 0.2822  BEST VAL Loss: 0.2822  Val_Acc: 89.830

Epoch 77: Validation loss decreased (0.282239 --> 0.281921).  Saving model ...
	 Train_Loss: 0.3061 Train_Acc: 88.097 Val_Loss: 0.2819  BEST VAL Loss: 0.2819  Val_Acc: 89.487

Epoch 78: Validation loss decreased (0.281921 --> 0.281641).  Saving model ...
	 Train_Loss: 0.3057 Train_Acc: 88.185 Val_Loss: 0.2816  BEST VAL Loss: 0.2816  Val_Acc: 89.475

Epoch 79: Validation loss decreased (0.281641 --> 0.281285).  Saving model ...
	 Train_Loss: 0.3053 Train_Acc: 88.098 Val_Loss: 0.2813  BEST VAL Loss: 0.2813  Val_Acc: 89.699

Epoch 80: Validation loss decreased (0.281285 --> 0.281017).  Saving model ...
	 Train_Loss: 0.3050 Train_Acc: 88.091 Val_Loss: 0.2810  BEST VAL Loss: 0.2810  Val_Acc: 89.141

Epoch 81: Validation loss decreased (0.281017 --> 0.280723).  Saving model ...
	 Train_Loss: 0.3046 Train_Acc: 88.114 Val_Loss: 0.2807  BEST VAL Loss: 0.2807  Val_Acc: 89.634

Epoch 82: Validation loss decreased (0.280723 --> 0.280432).  Saving model ...
	 Train_Loss: 0.3042 Train_Acc: 88.278 Val_Loss: 0.2804  BEST VAL Loss: 0.2804  Val_Acc: 89.732

Epoch 83: Validation loss decreased (0.280432 --> 0.280114).  Saving model ...
	 Train_Loss: 0.3039 Train_Acc: 88.208 Val_Loss: 0.2801  BEST VAL Loss: 0.2801  Val_Acc: 89.471

Epoch 84: Validation loss decreased (0.280114 --> 0.279761).  Saving model ...
	 Train_Loss: 0.3035 Train_Acc: 88.142 Val_Loss: 0.2798  BEST VAL Loss: 0.2798  Val_Acc: 89.671

Epoch 85: Validation loss decreased (0.279761 --> 0.279446).  Saving model ...
	 Train_Loss: 0.3032 Train_Acc: 88.281 Val_Loss: 0.2794  BEST VAL Loss: 0.2794  Val_Acc: 89.585

Epoch 86: Validation loss decreased (0.279446 --> 0.279088).  Saving model ...
	 Train_Loss: 0.3028 Train_Acc: 88.206 Val_Loss: 0.2791  BEST VAL Loss: 0.2791  Val_Acc: 89.716

Epoch 87: Validation loss decreased (0.279088 --> 0.278814).  Saving model ...
	 Train_Loss: 0.3025 Train_Acc: 88.182 Val_Loss: 0.2788  BEST VAL Loss: 0.2788  Val_Acc: 89.683

Epoch 88: Validation loss decreased (0.278814 --> 0.278588).  Saving model ...
	 Train_Loss: 0.3022 Train_Acc: 88.164 Val_Loss: 0.2786  BEST VAL Loss: 0.2786  Val_Acc: 89.247

Epoch 89: Validation loss decreased (0.278588 --> 0.278283).  Saving model ...
	 Train_Loss: 0.3018 Train_Acc: 88.192 Val_Loss: 0.2783  BEST VAL Loss: 0.2783  Val_Acc: 89.838

Epoch 90: Validation loss decreased (0.278283 --> 0.277974).  Saving model ...
	 Train_Loss: 0.3015 Train_Acc: 88.223 Val_Loss: 0.2780  BEST VAL Loss: 0.2780  Val_Acc: 89.585

Epoch 91: Validation loss decreased (0.277974 --> 0.277646).  Saving model ...
	 Train_Loss: 0.3012 Train_Acc: 88.200 Val_Loss: 0.2776  BEST VAL Loss: 0.2776  Val_Acc: 89.809

Epoch 92: Validation loss decreased (0.277646 --> 0.277352).  Saving model ...
	 Train_Loss: 0.3009 Train_Acc: 88.322 Val_Loss: 0.2774  BEST VAL Loss: 0.2774  Val_Acc: 89.817

Epoch 93: Validation loss decreased (0.277352 --> 0.277206).  Saving model ...
	 Train_Loss: 0.3006 Train_Acc: 88.253 Val_Loss: 0.2772  BEST VAL Loss: 0.2772  Val_Acc: 89.051

Epoch 94: Validation loss decreased (0.277206 --> 0.276920).  Saving model ...
	 Train_Loss: 0.3003 Train_Acc: 88.230 Val_Loss: 0.2769  BEST VAL Loss: 0.2769  Val_Acc: 89.850

Epoch 95: Validation loss decreased (0.276920 --> 0.276699).  Saving model ...
	 Train_Loss: 0.3000 Train_Acc: 88.282 Val_Loss: 0.2767  BEST VAL Loss: 0.2767  Val_Acc: 89.561

Epoch 96: Validation loss decreased (0.276699 --> 0.276434).  Saving model ...
	 Train_Loss: 0.2997 Train_Acc: 88.291 Val_Loss: 0.2764  BEST VAL Loss: 0.2764  Val_Acc: 89.862

Epoch 97: Validation loss decreased (0.276434 --> 0.276314).  Saving model ...
	 Train_Loss: 0.2994 Train_Acc: 88.261 Val_Loss: 0.2763  BEST VAL Loss: 0.2763  Val_Acc: 88.913

Epoch 98: Validation loss decreased (0.276314 --> 0.276062).  Saving model ...
	 Train_Loss: 0.2991 Train_Acc: 88.303 Val_Loss: 0.2761  BEST VAL Loss: 0.2761  Val_Acc: 89.834

Epoch 99: Validation loss decreased (0.276062 --> 0.275822).  Saving model ...
	 Train_Loss: 0.2988 Train_Acc: 88.441 Val_Loss: 0.2758  BEST VAL Loss: 0.2758  Val_Acc: 89.553

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.49      0.49     95989
           1       0.51      0.51      0.51    100339

    accuracy                           0.50    196328
   macro avg       0.50      0.50      0.50    196328
weighted avg       0.50      0.50      0.50    196328

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.50      0.50     11999
           1       0.52      0.51      0.51     12543

    accuracy                           0.50     24542
   macro avg       0.50      0.50      0.50     24542
weighted avg       0.51      0.50      0.50     24542

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.49      0.48     11999
           1       0.50      0.50      0.50     12543

    accuracy                           0.49     24542
   macro avg       0.49      0.49      0.49     24542
weighted avg       0.49      0.49      0.49     24542

              precision    recall  f1-score   support

           0       0.48      0.49      0.48     11999
           1       0.50      0.50      0.50     12543

    accuracy                           0.49     24542
   macro avg       0.49      0.49      0.49     24542
weighted avg       0.49      0.49      0.49     24542

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.50      0.49     39448
           1       0.51      0.50      0.50     40588

    accuracy                           0.50     80036
   macro avg       0.50      0.50      0.50     80036
weighted avg       0.50      0.50      0.50     80036

              precision    recall  f1-score   support

           0       0.49      0.50      0.49     39448
           1       0.51      0.50      0.50     40588

    accuracy                           0.50     80036
   macro avg       0.50      0.50      0.50     80036
weighted avg       0.50      0.50      0.50     80036

completed
