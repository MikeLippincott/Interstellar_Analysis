[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ad22a939'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'eaffc5ef'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '6ad31b7a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'c5b59d75'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_1.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_Nigericin_1.000_1.0_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (32027, 1276)
Number of total missing values across all columns: 31618
Data Subset Is Off
Wells held out for testing: ['K16' 'M22']
Wells to use for training, validation, and testing ['K17' 'M18' 'M19' 'K20' 'K21' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.389763).  Saving model ...
	 Train_Loss: 0.5354 Train_Acc: 70.065 Val_Loss: 0.3898  BEST VAL Loss: 0.3898  Val_Acc: 82.269

Epoch 1: Validation loss decreased (0.389763 --> 0.344777).  Saving model ...
	 Train_Loss: 0.4544 Train_Acc: 81.022 Val_Loss: 0.3448  BEST VAL Loss: 0.3448  Val_Acc: 87.017

Epoch 2: Validation loss decreased (0.344777 --> 0.311129).  Saving model ...
	 Train_Loss: 0.4081 Train_Acc: 84.615 Val_Loss: 0.3111  BEST VAL Loss: 0.3111  Val_Acc: 89.538

Epoch 3: Validation loss decreased (0.311129 --> 0.288559).  Saving model ...
	 Train_Loss: 0.3739 Train_Acc: 86.217 Val_Loss: 0.2886  BEST VAL Loss: 0.2886  Val_Acc: 91.050

Epoch 4: Validation loss decreased (0.288559 --> 0.273636).  Saving model ...
	 Train_Loss: 0.3479 Train_Acc: 87.740 Val_Loss: 0.2736  BEST VAL Loss: 0.2736  Val_Acc: 91.429

Epoch 5: Validation loss decreased (0.273636 --> 0.258124).  Saving model ...
	 Train_Loss: 0.3256 Train_Acc: 89.148 Val_Loss: 0.2581  BEST VAL Loss: 0.2581  Val_Acc: 92.227

Epoch 6: Validation loss decreased (0.258124 --> 0.245516).  Saving model ...
	 Train_Loss: 0.3085 Train_Acc: 90.104 Val_Loss: 0.2455  BEST VAL Loss: 0.2455  Val_Acc: 93.235

Epoch 7: Validation loss decreased (0.245516 --> 0.235078).  Saving model ...
	 Train_Loss: 0.2936 Train_Acc: 92.384 Val_Loss: 0.2351  BEST VAL Loss: 0.2351  Val_Acc: 94.076

Epoch 8: Validation loss decreased (0.235078 --> 0.226365).  Saving model ...
	 Train_Loss: 0.2810 Train_Acc: 92.846 Val_Loss: 0.2264  BEST VAL Loss: 0.2264  Val_Acc: 93.950

Epoch 9: Validation loss decreased (0.226365 --> 0.218195).  Saving model ...
	 Train_Loss: 0.2703 Train_Acc: 93.014 Val_Loss: 0.2182  BEST VAL Loss: 0.2182  Val_Acc: 93.824

Epoch 10: Validation loss decreased (0.218195 --> 0.211609).  Saving model ...
	 Train_Loss: 0.2602 Train_Acc: 93.728 Val_Loss: 0.2116  BEST VAL Loss: 0.2116  Val_Acc: 93.782

Epoch 11: Validation loss decreased (0.211609 --> 0.205417).  Saving model ...
	 Train_Loss: 0.2513 Train_Acc: 93.791 Val_Loss: 0.2054  BEST VAL Loss: 0.2054  Val_Acc: 94.790

Epoch 12: Validation loss decreased (0.205417 --> 0.199824).  Saving model ...
	 Train_Loss: 0.2431 Train_Acc: 94.259 Val_Loss: 0.1998  BEST VAL Loss: 0.1998  Val_Acc: 94.958

Epoch 13: Validation loss decreased (0.199824 --> 0.195248).  Saving model ...
	 Train_Loss: 0.2359 Train_Acc: 94.548 Val_Loss: 0.1952  BEST VAL Loss: 0.1952  Val_Acc: 94.874

Epoch 14: Validation loss decreased (0.195248 --> 0.190872).  Saving model ...
	 Train_Loss: 0.2294 Train_Acc: 94.185 Val_Loss: 0.1909  BEST VAL Loss: 0.1909  Val_Acc: 94.748

Epoch 15: Validation loss decreased (0.190872 --> 0.187477).  Saving model ...
	 Train_Loss: 0.2234 Train_Acc: 94.774 Val_Loss: 0.1875  BEST VAL Loss: 0.1875  Val_Acc: 95.168

Epoch 16: Validation loss decreased (0.187477 --> 0.184446).  Saving model ...
	 Train_Loss: 0.2176 Train_Acc: 95.341 Val_Loss: 0.1844  BEST VAL Loss: 0.1844  Val_Acc: 94.790

Epoch 17: Validation loss decreased (0.184446 --> 0.181127).  Saving model ...
	 Train_Loss: 0.2124 Train_Acc: 95.099 Val_Loss: 0.1811  BEST VAL Loss: 0.1811  Val_Acc: 95.336

Epoch 18: Validation loss decreased (0.181127 --> 0.177896).  Saving model ...
	 Train_Loss: 0.2074 Train_Acc: 95.803 Val_Loss: 0.1779  BEST VAL Loss: 0.1779  Val_Acc: 95.546

Epoch 19: Validation loss decreased (0.177896 --> 0.175304).  Saving model ...
	 Train_Loss: 0.2037 Train_Acc: 94.910 Val_Loss: 0.1753  BEST VAL Loss: 0.1753  Val_Acc: 95.042

Epoch 20: Validation loss decreased (0.175304 --> 0.172404).  Saving model ...
	 Train_Loss: 0.2001 Train_Acc: 94.889 Val_Loss: 0.1724  BEST VAL Loss: 0.1724  Val_Acc: 95.546

Epoch 21: Validation loss decreased (0.172404 --> 0.170509).  Saving model ...
	 Train_Loss: 0.1971 Train_Acc: 95.015 Val_Loss: 0.1705  BEST VAL Loss: 0.1705  Val_Acc: 95.336

Epoch 22: Validation loss decreased (0.170509 --> 0.169254).  Saving model ...
	 Train_Loss: 0.1946 Train_Acc: 94.642 Val_Loss: 0.1693  BEST VAL Loss: 0.1693  Val_Acc: 95.294

Epoch 23: Validation loss decreased (0.169254 --> 0.168178).  Saving model ...
	 Train_Loss: 0.1918 Train_Acc: 95.183 Val_Loss: 0.1682  BEST VAL Loss: 0.1682  Val_Acc: 95.084

Epoch 24: Validation loss decreased (0.168178 --> 0.166750).  Saving model ...
	 Train_Loss: 0.1893 Train_Acc: 95.131 Val_Loss: 0.1668  BEST VAL Loss: 0.1668  Val_Acc: 94.958

Epoch 25: Validation loss decreased (0.166750 --> 0.165806).  Saving model ...
	 Train_Loss: 0.1870 Train_Acc: 94.642 Val_Loss: 0.1658  BEST VAL Loss: 0.1658  Val_Acc: 94.832

Epoch 26: Validation loss decreased (0.165806 --> 0.164442).  Saving model ...
	 Train_Loss: 0.1844 Train_Acc: 95.304 Val_Loss: 0.1644  BEST VAL Loss: 0.1644  Val_Acc: 95.210

Epoch 27: Validation loss decreased (0.164442 --> 0.162707).  Saving model ...
	 Train_Loss: 0.1815 Train_Acc: 95.777 Val_Loss: 0.1627  BEST VAL Loss: 0.1627  Val_Acc: 95.462

Epoch 28: Validation loss decreased (0.162707 --> 0.161351).  Saving model ...
	 Train_Loss: 0.1787 Train_Acc: 96.066 Val_Loss: 0.1614  BEST VAL Loss: 0.1614  Val_Acc: 95.546

Epoch 29: Validation loss decreased (0.161351 --> 0.159919).  Saving model ...
	 Train_Loss: 0.1762 Train_Acc: 95.924 Val_Loss: 0.1599  BEST VAL Loss: 0.1599  Val_Acc: 95.588

Epoch 30: Validation loss decreased (0.159919 --> 0.158819).  Saving model ...
	 Train_Loss: 0.1739 Train_Acc: 96.229 Val_Loss: 0.1588  BEST VAL Loss: 0.1588  Val_Acc: 95.798

Epoch 31: Validation loss decreased (0.158819 --> 0.157517).  Saving model ...
	 Train_Loss: 0.1721 Train_Acc: 95.845 Val_Loss: 0.1575  BEST VAL Loss: 0.1575  Val_Acc: 95.714

Epoch 32: Validation loss decreased (0.157517 --> 0.156499).  Saving model ...
	 Train_Loss: 0.1700 Train_Acc: 96.181 Val_Loss: 0.1565  BEST VAL Loss: 0.1565  Val_Acc: 95.714

Epoch 33: Validation loss decreased (0.156499 --> 0.154980).  Saving model ...
	 Train_Loss: 0.1680 Train_Acc: 96.239 Val_Loss: 0.1550  BEST VAL Loss: 0.1550  Val_Acc: 96.218

Epoch 34: Validation loss decreased (0.154980 --> 0.154080).  Saving model ...
	 Train_Loss: 0.1662 Train_Acc: 95.798 Val_Loss: 0.1541  BEST VAL Loss: 0.1541  Val_Acc: 95.630

Epoch 35: Validation loss decreased (0.154080 --> 0.152982).  Saving model ...
	 Train_Loss: 0.1644 Train_Acc: 96.260 Val_Loss: 0.1530  BEST VAL Loss: 0.1530  Val_Acc: 96.261

Epoch 36: Validation loss decreased (0.152982 --> 0.151954).  Saving model ...
	 Train_Loss: 0.1625 Train_Acc: 96.113 Val_Loss: 0.1520  BEST VAL Loss: 0.1520  Val_Acc: 95.672

Epoch 37: Validation loss decreased (0.151954 --> 0.151508).  Saving model ...
	 Train_Loss: 0.1606 Train_Acc: 96.565 Val_Loss: 0.1515  BEST VAL Loss: 0.1515  Val_Acc: 95.252

Epoch 38: Validation loss decreased (0.151508 --> 0.151030).  Saving model ...
	 Train_Loss: 0.1587 Train_Acc: 96.560 Val_Loss: 0.1510  BEST VAL Loss: 0.1510  Val_Acc: 95.420

Epoch 39: Validation loss decreased (0.151030 --> 0.150719).  Saving model ...
	 Train_Loss: 0.1568 Train_Acc: 96.848 Val_Loss: 0.1507  BEST VAL Loss: 0.1507  Val_Acc: 95.756

Epoch 40: Validation loss decreased (0.150719 --> 0.149711).  Saving model ...
	 Train_Loss: 0.1550 Train_Acc: 96.612 Val_Loss: 0.1497  BEST VAL Loss: 0.1497  Val_Acc: 95.966

Epoch 41: Validation loss decreased (0.149711 --> 0.148788).  Saving model ...
	 Train_Loss: 0.1531 Train_Acc: 96.911 Val_Loss: 0.1488  BEST VAL Loss: 0.1488  Val_Acc: 96.218

Epoch 42: Validation loss decreased (0.148788 --> 0.148224).  Saving model ...
	 Train_Loss: 0.1516 Train_Acc: 96.659 Val_Loss: 0.1482  BEST VAL Loss: 0.1482  Val_Acc: 95.798

Epoch 43: Validation loss decreased (0.148224 --> 0.147709).  Saving model ...
	 Train_Loss: 0.1503 Train_Acc: 96.160 Val_Loss: 0.1477  BEST VAL Loss: 0.1477  Val_Acc: 95.840

Epoch 44: Validation loss decreased (0.147709 --> 0.147004).  Saving model ...
	 Train_Loss: 0.1489 Train_Acc: 96.439 Val_Loss: 0.1470  BEST VAL Loss: 0.1470  Val_Acc: 95.924

Epoch 45: Validation loss decreased (0.147004 --> 0.146420).  Saving model ...
	 Train_Loss: 0.1473 Train_Acc: 96.880 Val_Loss: 0.1464  BEST VAL Loss: 0.1464  Val_Acc: 95.882

Epoch 46: Validation loss decreased (0.146420 --> 0.145972).  Saving model ...
	 Train_Loss: 0.1458 Train_Acc: 97.122 Val_Loss: 0.1460  BEST VAL Loss: 0.1460  Val_Acc: 96.092

Epoch 47: Validation loss decreased (0.145972 --> 0.145697).  Saving model ...
	 Train_Loss: 0.1443 Train_Acc: 97.253 Val_Loss: 0.1457  BEST VAL Loss: 0.1457  Val_Acc: 96.134

Epoch 48: Validation loss decreased (0.145697 --> 0.145368).  Saving model ...
	 Train_Loss: 0.1430 Train_Acc: 96.554 Val_Loss: 0.1454  BEST VAL Loss: 0.1454  Val_Acc: 95.672

Epoch 49: Validation loss decreased (0.145368 --> 0.144951).  Saving model ...
	 Train_Loss: 0.1419 Train_Acc: 96.602 Val_Loss: 0.1450  BEST VAL Loss: 0.1450  Val_Acc: 95.798

Epoch 50: Validation loss decreased (0.144951 --> 0.144606).  Saving model ...
	 Train_Loss: 0.1405 Train_Acc: 97.137 Val_Loss: 0.1446  BEST VAL Loss: 0.1446  Val_Acc: 96.092

Epoch 51: Validation loss decreased (0.144606 --> 0.144225).  Saving model ...
	 Train_Loss: 0.1392 Train_Acc: 96.901 Val_Loss: 0.1442  BEST VAL Loss: 0.1442  Val_Acc: 96.134

Epoch 52: Validation loss decreased (0.144225 --> 0.143927).  Saving model ...
	 Train_Loss: 0.1379 Train_Acc: 97.263 Val_Loss: 0.1439  BEST VAL Loss: 0.1439  Val_Acc: 96.176

Epoch 53: Validation loss decreased (0.143927 --> 0.143752).  Saving model ...
	 Train_Loss: 0.1367 Train_Acc: 97.242 Val_Loss: 0.1438  BEST VAL Loss: 0.1438  Val_Acc: 96.261

Epoch 54: Validation loss decreased (0.143752 --> 0.143426).  Saving model ...
	 Train_Loss: 0.1357 Train_Acc: 96.591 Val_Loss: 0.1434  BEST VAL Loss: 0.1434  Val_Acc: 96.092

Epoch 55: Validation loss decreased (0.143426 --> 0.143092).  Saving model ...
	 Train_Loss: 0.1345 Train_Acc: 96.985 Val_Loss: 0.1431  BEST VAL Loss: 0.1431  Val_Acc: 96.050

Epoch 56: Validation loss decreased (0.143092 --> 0.142734).  Saving model ...
	 Train_Loss: 0.1333 Train_Acc: 97.253 Val_Loss: 0.1427  BEST VAL Loss: 0.1427  Val_Acc: 96.008

Epoch 57: Validation loss decreased (0.142734 --> 0.142501).  Saving model ...
	 Train_Loss: 0.1322 Train_Acc: 97.321 Val_Loss: 0.1425  BEST VAL Loss: 0.1425  Val_Acc: 96.345

Epoch 58: Validation loss decreased (0.142501 --> 0.142332).  Saving model ...
	 Train_Loss: 0.1312 Train_Acc: 97.321 Val_Loss: 0.1423  BEST VAL Loss: 0.1423  Val_Acc: 95.924

Epoch 59: Validation loss decreased (0.142332 --> 0.142323).  Saving model ...
	 Train_Loss: 0.1302 Train_Acc: 97.095 Val_Loss: 0.1423  BEST VAL Loss: 0.1423  Val_Acc: 96.134

Epoch 60: Validation loss decreased (0.142323 --> 0.142224).  Saving model ...
	 Train_Loss: 0.1293 Train_Acc: 96.581 Val_Loss: 0.1422  BEST VAL Loss: 0.1422  Val_Acc: 95.840

Epoch 61: Validation loss decreased (0.142224 --> 0.141921).  Saving model ...
	 Train_Loss: 0.1284 Train_Acc: 97.069 Val_Loss: 0.1419  BEST VAL Loss: 0.1419  Val_Acc: 96.008

Epoch 62: Validation loss decreased (0.141921 --> 0.141623).  Saving model ...
	 Train_Loss: 0.1275 Train_Acc: 97.342 Val_Loss: 0.1416  BEST VAL Loss: 0.1416  Val_Acc: 96.261

Epoch 63: Validation loss decreased (0.141623 --> 0.141334).  Saving model ...
	 Train_Loss: 0.1267 Train_Acc: 96.917 Val_Loss: 0.1413  BEST VAL Loss: 0.1413  Val_Acc: 96.176

Epoch 64: Validation loss decreased (0.141334 --> 0.141070).  Saving model ...
	 Train_Loss: 0.1258 Train_Acc: 97.211 Val_Loss: 0.1411  BEST VAL Loss: 0.1411  Val_Acc: 96.092

Epoch 65: Validation loss decreased (0.141070 --> 0.141038).  Saving model ...
	 Train_Loss: 0.1249 Train_Acc: 97.200 Val_Loss: 0.1410  BEST VAL Loss: 0.1410  Val_Acc: 96.092

Epoch 66: Validation loss decreased (0.141038 --> 0.141024).  Saving model ...
	 Train_Loss: 0.1242 Train_Acc: 96.901 Val_Loss: 0.1410  BEST VAL Loss: 0.1410  Val_Acc: 96.050

Epoch 67: Validation loss decreased (0.141024 --> 0.140932).  Saving model ...
	 Train_Loss: 0.1233 Train_Acc: 97.174 Val_Loss: 0.1409  BEST VAL Loss: 0.1409  Val_Acc: 95.672

Epoch 68: Validation loss decreased (0.140932 --> 0.140822).  Saving model ...
	 Train_Loss: 0.1225 Train_Acc: 97.489 Val_Loss: 0.1408  BEST VAL Loss: 0.1408  Val_Acc: 96.050

Epoch 69: Validation loss decreased (0.140822 --> 0.140776).  Saving model ...
	 Train_Loss: 0.1217 Train_Acc: 97.195 Val_Loss: 0.1408  BEST VAL Loss: 0.1408  Val_Acc: 95.756

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.1209 Train_Acc: 97.589 Val_Loss: 0.1408  BEST VAL Loss: 0.1408  Val_Acc: 95.378

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.1204 Train_Acc: 96.791 Val_Loss: 0.1409  BEST VAL Loss: 0.1408  Val_Acc: 95.336

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.1197 Train_Acc: 97.242 Val_Loss: 0.1408  BEST VAL Loss: 0.1408  Val_Acc: 95.336

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.1191 Train_Acc: 97.090 Val_Loss: 0.1409  BEST VAL Loss: 0.1408  Val_Acc: 95.966

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.1187 Train_Acc: 96.475 Val_Loss: 0.1409  BEST VAL Loss: 0.1408  Val_Acc: 95.924

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.1181 Train_Acc: 96.985 Val_Loss: 0.1410  BEST VAL Loss: 0.1408  Val_Acc: 96.008

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.1174 Train_Acc: 97.300 Val_Loss: 0.1408  BEST VAL Loss: 0.1408  Val_Acc: 96.050

Epoch 77: Validation loss decreased (0.140776 --> 0.140640).  Saving model ...
	 Train_Loss: 0.1167 Train_Acc: 97.337 Val_Loss: 0.1406  BEST VAL Loss: 0.1406  Val_Acc: 95.966

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.1160 Train_Acc: 97.500 Val_Loss: 0.1409  BEST VAL Loss: 0.1406  Val_Acc: 96.218

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.1154 Train_Acc: 97.584 Val_Loss: 0.1408  BEST VAL Loss: 0.1406  Val_Acc: 96.345

Epoch 80: Validation loss decreased (0.140640 --> 0.140548).  Saving model ...
	 Train_Loss: 0.1148 Train_Acc: 97.368 Val_Loss: 0.1405  BEST VAL Loss: 0.1405  Val_Acc: 96.218

Epoch 81: Validation loss decreased (0.140548 --> 0.140324).  Saving model ...
	 Train_Loss: 0.1142 Train_Acc: 97.447 Val_Loss: 0.1403  BEST VAL Loss: 0.1403  Val_Acc: 96.513

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.1138 Train_Acc: 96.654 Val_Loss: 0.1404  BEST VAL Loss: 0.1403  Val_Acc: 95.840

Epoch 83: Validation loss decreased (0.140324 --> 0.140321).  Saving model ...
	 Train_Loss: 0.1133 Train_Acc: 96.974 Val_Loss: 0.1403  BEST VAL Loss: 0.1403  Val_Acc: 96.429

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.1128 Train_Acc: 97.290 Val_Loss: 0.1407  BEST VAL Loss: 0.1403  Val_Acc: 96.513

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.1122 Train_Acc: 97.326 Val_Loss: 0.1406  BEST VAL Loss: 0.1403  Val_Acc: 96.176

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.1117 Train_Acc: 97.563 Val_Loss: 0.1407  BEST VAL Loss: 0.1403  Val_Acc: 96.261

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.1111 Train_Acc: 97.431 Val_Loss: 0.1408  BEST VAL Loss: 0.1403  Val_Acc: 96.387

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.1106 Train_Acc: 97.484 Val_Loss: 0.1410  BEST VAL Loss: 0.1403  Val_Acc: 96.218

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.1101 Train_Acc: 97.473 Val_Loss: 0.1410  BEST VAL Loss: 0.1403  Val_Acc: 95.798

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.1098 Train_Acc: 97.405 Val_Loss: 0.1411  BEST VAL Loss: 0.1403  Val_Acc: 96.261

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.1094 Train_Acc: 96.728 Val_Loss: 0.1415  BEST VAL Loss: 0.1403  Val_Acc: 95.546

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.1090 Train_Acc: 97.080 Val_Loss: 0.1417  BEST VAL Loss: 0.1403  Val_Acc: 96.008

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.1086 Train_Acc: 97.153 Val_Loss: 0.1420  BEST VAL Loss: 0.1403  Val_Acc: 95.924

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.1082 Train_Acc: 97.647 Val_Loss: 0.1423  BEST VAL Loss: 0.1403  Val_Acc: 95.798

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.1086 Train_Acc: 95.041 Val_Loss: 0.1426  BEST VAL Loss: 0.1403  Val_Acc: 94.748

Epoch 96: Validation loss did not decrease
	 Train_Loss: 0.1086 Train_Acc: 95.824 Val_Loss: 0.1427  BEST VAL Loss: 0.1403  Val_Acc: 95.756

Epoch 97: Validation loss did not decrease
	 Train_Loss: 0.1084 Train_Acc: 96.213 Val_Loss: 0.1427  BEST VAL Loss: 0.1403  Val_Acc: 95.798

Epoch 98: Validation loss did not decrease
	 Train_Loss: 0.1081 Train_Acc: 96.927 Val_Loss: 0.1427  BEST VAL Loss: 0.1403  Val_Acc: 96.387

Epoch 99: Validation loss did not decrease
Early stopped at epoch : 99
Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.50      0.50      9434
           1       0.51      0.50      0.51      9604

    accuracy                           0.50     19038
   macro avg       0.50      0.50      0.50     19038
weighted avg       0.50      0.50      0.50     19038

Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.50      0.50      1179
           1       0.50      0.49      0.50      1201

    accuracy                           0.50      2380
   macro avg       0.50      0.50      0.50      2380
weighted avg       0.50      0.50      0.50      2380

Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.49      0.49      1179
           1       0.49      0.48      0.49      1201

    accuracy                           0.49      2380
   macro avg       0.49      0.49      0.49      2380
weighted avg       0.49      0.49      0.49      2380

              precision    recall  f1-score   support

           0       0.48      0.49      0.49      1179
           1       0.49      0.48      0.49      1201

    accuracy                           0.49      2380
   macro avg       0.49      0.49      0.49      2380
weighted avg       0.49      0.49      0.49      2380

Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.47      0.47      4017
           1       0.51      0.52      0.51      4212

    accuracy                           0.50      8229
   macro avg       0.49      0.49      0.49      8229
weighted avg       0.50      0.50      0.50      8229

              precision    recall  f1-score   support

           0       0.48      0.47      0.47      4017
           1       0.51      0.52      0.51      4212

    accuracy                           0.50      8229
   macro avg       0.49      0.49      0.49      8229
weighted avg       0.50      0.50      0.50      8229

completed
