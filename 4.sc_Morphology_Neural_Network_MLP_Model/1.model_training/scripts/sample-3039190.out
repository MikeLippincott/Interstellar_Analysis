[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'aeae9e67'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '047cd8c4'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '2bf68ff0'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'bf895329'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_10.000_DMSO_0.025 treatment_name: Thapsigargin_10.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: Thapsigargin_10.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'Thapsigargin_10.000_DMSO_0.025']
The dimensions of the data are: (323474, 1270)
Number of total missing values across all columns: 646948
Data Subset Is Off
Wells held out for testing: ['E09' 'L06']
Wells to use for training, validation, and testing ['E02' 'E03' 'E06' 'E07' 'E08' 'L07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.459285).  Saving model ...
	 Train_Loss: 0.5674 Train_Acc: 69.506 Val_Loss: 0.4593  BEST VAL Loss: 0.4593  Val_Acc: 78.503

Epoch 1: Validation loss decreased (0.459285 --> 0.426646).  Saving model ...
	 Train_Loss: 0.5077 Train_Acc: 78.024 Val_Loss: 0.4266  BEST VAL Loss: 0.4266  Val_Acc: 82.250

Epoch 2: Validation loss decreased (0.426646 --> 0.403780).  Saving model ...
	 Train_Loss: 0.4739 Train_Acc: 81.428 Val_Loss: 0.4038  BEST VAL Loss: 0.4038  Val_Acc: 84.706

Epoch 3: Validation loss decreased (0.403780 --> 0.387214).  Saving model ...
	 Train_Loss: 0.4503 Train_Acc: 82.970 Val_Loss: 0.3872  BEST VAL Loss: 0.3872  Val_Acc: 85.667

Epoch 4: Validation loss decreased (0.387214 --> 0.374120).  Saving model ...
	 Train_Loss: 0.4326 Train_Acc: 83.904 Val_Loss: 0.3741  BEST VAL Loss: 0.3741  Val_Acc: 86.388

Epoch 5: Validation loss decreased (0.374120 --> 0.363284).  Saving model ...
	 Train_Loss: 0.4185 Train_Acc: 84.551 Val_Loss: 0.3633  BEST VAL Loss: 0.3633  Val_Acc: 86.860

Epoch 6: Validation loss decreased (0.363284 --> 0.354416).  Saving model ...
	 Train_Loss: 0.4072 Train_Acc: 84.977 Val_Loss: 0.3544  BEST VAL Loss: 0.3544  Val_Acc: 87.374

Epoch 7: Validation loss decreased (0.354416 --> 0.347012).  Saving model ...
	 Train_Loss: 0.3977 Train_Acc: 85.457 Val_Loss: 0.3470  BEST VAL Loss: 0.3470  Val_Acc: 87.635

Epoch 8: Validation loss decreased (0.347012 --> 0.340331).  Saving model ...
	 Train_Loss: 0.3896 Train_Acc: 85.805 Val_Loss: 0.3403  BEST VAL Loss: 0.3403  Val_Acc: 88.145

Epoch 9: Validation loss decreased (0.340331 --> 0.334606).  Saving model ...
	 Train_Loss: 0.3825 Train_Acc: 86.016 Val_Loss: 0.3346  BEST VAL Loss: 0.3346  Val_Acc: 88.293

Epoch 10: Validation loss decreased (0.334606 --> 0.329507).  Saving model ...
	 Train_Loss: 0.3763 Train_Acc: 86.366 Val_Loss: 0.3295  BEST VAL Loss: 0.3295  Val_Acc: 88.390

Epoch 11: Validation loss decreased (0.329507 --> 0.324845).  Saving model ...
	 Train_Loss: 0.3707 Train_Acc: 86.680 Val_Loss: 0.3248  BEST VAL Loss: 0.3248  Val_Acc: 88.592

Epoch 12: Validation loss decreased (0.324845 --> 0.320733).  Saving model ...
	 Train_Loss: 0.3657 Train_Acc: 86.874 Val_Loss: 0.3207  BEST VAL Loss: 0.3207  Val_Acc: 88.723

Epoch 13: Validation loss decreased (0.320733 --> 0.316783).  Saving model ...
	 Train_Loss: 0.3612 Train_Acc: 86.961 Val_Loss: 0.3168  BEST VAL Loss: 0.3168  Val_Acc: 89.026

Epoch 14: Validation loss decreased (0.316783 --> 0.313248).  Saving model ...
	 Train_Loss: 0.3570 Train_Acc: 87.111 Val_Loss: 0.3132  BEST VAL Loss: 0.3132  Val_Acc: 89.186

Epoch 15: Validation loss decreased (0.313248 --> 0.309973).  Saving model ...
	 Train_Loss: 0.3532 Train_Acc: 87.385 Val_Loss: 0.3100  BEST VAL Loss: 0.3100  Val_Acc: 89.144

Epoch 16: Validation loss decreased (0.309973 --> 0.306791).  Saving model ...
	 Train_Loss: 0.3496 Train_Acc: 87.504 Val_Loss: 0.3068  BEST VAL Loss: 0.3068  Val_Acc: 89.498

Epoch 17: Validation loss decreased (0.306791 --> 0.303939).  Saving model ...
	 Train_Loss: 0.3463 Train_Acc: 87.678 Val_Loss: 0.3039  BEST VAL Loss: 0.3039  Val_Acc: 89.389

Epoch 18: Validation loss decreased (0.303939 --> 0.301300).  Saving model ...
	 Train_Loss: 0.3432 Train_Acc: 87.745 Val_Loss: 0.3013  BEST VAL Loss: 0.3013  Val_Acc: 89.389

Epoch 19: Validation loss decreased (0.301300 --> 0.298740).  Saving model ...
	 Train_Loss: 0.3403 Train_Acc: 87.934 Val_Loss: 0.2987  BEST VAL Loss: 0.2987  Val_Acc: 89.595

Epoch 20: Validation loss decreased (0.298740 --> 0.296392).  Saving model ...
	 Train_Loss: 0.3375 Train_Acc: 87.959 Val_Loss: 0.2964  BEST VAL Loss: 0.2964  Val_Acc: 89.443

Epoch 21: Validation loss decreased (0.296392 --> 0.294384).  Saving model ...
	 Train_Loss: 0.3349 Train_Acc: 88.113 Val_Loss: 0.2944  BEST VAL Loss: 0.2944  Val_Acc: 89.595

Epoch 22: Validation loss decreased (0.294384 --> 0.292388).  Saving model ...
	 Train_Loss: 0.3325 Train_Acc: 88.196 Val_Loss: 0.2924  BEST VAL Loss: 0.2924  Val_Acc: 89.700

Epoch 23: Validation loss decreased (0.292388 --> 0.290404).  Saving model ...
	 Train_Loss: 0.3302 Train_Acc: 88.253 Val_Loss: 0.2904  BEST VAL Loss: 0.2904  Val_Acc: 89.726

Epoch 24: Validation loss decreased (0.290404 --> 0.288669).  Saving model ...
	 Train_Loss: 0.3280 Train_Acc: 88.386 Val_Loss: 0.2887  BEST VAL Loss: 0.2887  Val_Acc: 89.705

Epoch 25: Validation loss decreased (0.288669 --> 0.286882).  Saving model ...
	 Train_Loss: 0.3259 Train_Acc: 88.397 Val_Loss: 0.2869  BEST VAL Loss: 0.2869  Val_Acc: 90.113

Epoch 26: Validation loss decreased (0.286882 --> 0.285143).  Saving model ...
	 Train_Loss: 0.3239 Train_Acc: 88.521 Val_Loss: 0.2851  BEST VAL Loss: 0.2851  Val_Acc: 89.932

Epoch 27: Validation loss decreased (0.285143 --> 0.283570).  Saving model ...
	 Train_Loss: 0.3220 Train_Acc: 88.621 Val_Loss: 0.2836  BEST VAL Loss: 0.2836  Val_Acc: 89.957

Epoch 28: Validation loss decreased (0.283570 --> 0.282065).  Saving model ...
	 Train_Loss: 0.3202 Train_Acc: 88.597 Val_Loss: 0.2821  BEST VAL Loss: 0.2821  Val_Acc: 90.109

Epoch 29: Validation loss decreased (0.282065 --> 0.280608).  Saving model ...
	 Train_Loss: 0.3184 Train_Acc: 88.749 Val_Loss: 0.2806  BEST VAL Loss: 0.2806  Val_Acc: 90.101

Epoch 30: Validation loss decreased (0.280608 --> 0.279128).  Saving model ...
	 Train_Loss: 0.3167 Train_Acc: 88.850 Val_Loss: 0.2791  BEST VAL Loss: 0.2791  Val_Acc: 90.324

Epoch 31: Validation loss decreased (0.279128 --> 0.277772).  Saving model ...
	 Train_Loss: 0.3151 Train_Acc: 88.790 Val_Loss: 0.2778  BEST VAL Loss: 0.2778  Val_Acc: 90.408

Epoch 32: Validation loss decreased (0.277772 --> 0.276559).  Saving model ...
	 Train_Loss: 0.3136 Train_Acc: 88.867 Val_Loss: 0.2766  BEST VAL Loss: 0.2766  Val_Acc: 90.248

Epoch 33: Validation loss decreased (0.276559 --> 0.275380).  Saving model ...
	 Train_Loss: 0.3121 Train_Acc: 88.851 Val_Loss: 0.2754  BEST VAL Loss: 0.2754  Val_Acc: 90.303

Epoch 34: Validation loss decreased (0.275380 --> 0.274226).  Saving model ...
	 Train_Loss: 0.3107 Train_Acc: 89.045 Val_Loss: 0.2742  BEST VAL Loss: 0.2742  Val_Acc: 90.429

Epoch 35: Validation loss decreased (0.274226 --> 0.273027).  Saving model ...
	 Train_Loss: 0.3093 Train_Acc: 89.108 Val_Loss: 0.2730  BEST VAL Loss: 0.2730  Val_Acc: 90.552

Epoch 36: Validation loss decreased (0.273027 --> 0.271905).  Saving model ...
	 Train_Loss: 0.3080 Train_Acc: 89.104 Val_Loss: 0.2719  BEST VAL Loss: 0.2719  Val_Acc: 90.455

Epoch 37: Validation loss decreased (0.271905 --> 0.270774).  Saving model ...
	 Train_Loss: 0.3066 Train_Acc: 89.188 Val_Loss: 0.2708  BEST VAL Loss: 0.2708  Val_Acc: 90.611

Epoch 38: Validation loss decreased (0.270774 --> 0.269689).  Saving model ...
	 Train_Loss: 0.3054 Train_Acc: 89.271 Val_Loss: 0.2697  BEST VAL Loss: 0.2697  Val_Acc: 90.497

Epoch 39: Validation loss decreased (0.269689 --> 0.268689).  Saving model ...
	 Train_Loss: 0.3041 Train_Acc: 89.186 Val_Loss: 0.2687  BEST VAL Loss: 0.2687  Val_Acc: 90.644

Epoch 40: Validation loss decreased (0.268689 --> 0.267702).  Saving model ...
	 Train_Loss: 0.3030 Train_Acc: 89.272 Val_Loss: 0.2677  BEST VAL Loss: 0.2677  Val_Acc: 90.703

Epoch 41: Validation loss decreased (0.267702 --> 0.266754).  Saving model ...
	 Train_Loss: 0.3019 Train_Acc: 89.263 Val_Loss: 0.2668  BEST VAL Loss: 0.2668  Val_Acc: 90.636

Epoch 42: Validation loss decreased (0.266754 --> 0.265801).  Saving model ...
	 Train_Loss: 0.3008 Train_Acc: 89.318 Val_Loss: 0.2658  BEST VAL Loss: 0.2658  Val_Acc: 90.868

Epoch 43: Validation loss decreased (0.265801 --> 0.265146).  Saving model ...
	 Train_Loss: 0.2997 Train_Acc: 89.313 Val_Loss: 0.2651  BEST VAL Loss: 0.2651  Val_Acc: 90.257

Epoch 44: Validation loss decreased (0.265146 --> 0.264271).  Saving model ...
	 Train_Loss: 0.2987 Train_Acc: 89.418 Val_Loss: 0.2643  BEST VAL Loss: 0.2643  Val_Acc: 90.775

Epoch 45: Validation loss decreased (0.264271 --> 0.263621).  Saving model ...
	 Train_Loss: 0.2977 Train_Acc: 89.386 Val_Loss: 0.2636  BEST VAL Loss: 0.2636  Val_Acc: 90.438

Epoch 46: Validation loss decreased (0.263621 --> 0.262817).  Saving model ...
	 Train_Loss: 0.2968 Train_Acc: 89.436 Val_Loss: 0.2628  BEST VAL Loss: 0.2628  Val_Acc: 90.821

Epoch 47: Validation loss decreased (0.262817 --> 0.262028).  Saving model ...
	 Train_Loss: 0.2959 Train_Acc: 89.461 Val_Loss: 0.2620  BEST VAL Loss: 0.2620  Val_Acc: 90.864

Epoch 48: Validation loss decreased (0.262028 --> 0.261319).  Saving model ...
	 Train_Loss: 0.2950 Train_Acc: 89.542 Val_Loss: 0.2613  BEST VAL Loss: 0.2613  Val_Acc: 90.767

Epoch 49: Validation loss decreased (0.261319 --> 0.260574).  Saving model ...
	 Train_Loss: 0.2941 Train_Acc: 89.539 Val_Loss: 0.2606  BEST VAL Loss: 0.2606  Val_Acc: 90.754

Epoch 50: Validation loss decreased (0.260574 --> 0.259882).  Saving model ...
	 Train_Loss: 0.2932 Train_Acc: 89.550 Val_Loss: 0.2599  BEST VAL Loss: 0.2599  Val_Acc: 90.653

Epoch 51: Validation loss decreased (0.259882 --> 0.259149).  Saving model ...
	 Train_Loss: 0.2923 Train_Acc: 89.609 Val_Loss: 0.2591  BEST VAL Loss: 0.2591  Val_Acc: 90.969

Epoch 52: Validation loss decreased (0.259149 --> 0.258471).  Saving model ...
	 Train_Loss: 0.2915 Train_Acc: 89.635 Val_Loss: 0.2585  BEST VAL Loss: 0.2585  Val_Acc: 90.897

Epoch 53: Validation loss decreased (0.258471 --> 0.257826).  Saving model ...
	 Train_Loss: 0.2907 Train_Acc: 89.696 Val_Loss: 0.2578  BEST VAL Loss: 0.2578  Val_Acc: 90.699

Epoch 54: Validation loss decreased (0.257826 --> 0.257208).  Saving model ...
	 Train_Loss: 0.2899 Train_Acc: 89.653 Val_Loss: 0.2572  BEST VAL Loss: 0.2572  Val_Acc: 90.783

Epoch 55: Validation loss decreased (0.257208 --> 0.256557).  Saving model ...
	 Train_Loss: 0.2891 Train_Acc: 89.773 Val_Loss: 0.2566  BEST VAL Loss: 0.2566  Val_Acc: 90.859

Epoch 56: Validation loss decreased (0.256557 --> 0.255929).  Saving model ...
	 Train_Loss: 0.2883 Train_Acc: 89.772 Val_Loss: 0.2559  BEST VAL Loss: 0.2559  Val_Acc: 91.019

Epoch 57: Validation loss decreased (0.255929 --> 0.255342).  Saving model ...
	 Train_Loss: 0.2876 Train_Acc: 89.798 Val_Loss: 0.2553  BEST VAL Loss: 0.2553  Val_Acc: 90.805

Epoch 58: Validation loss decreased (0.255342 --> 0.254945).  Saving model ...
	 Train_Loss: 0.2868 Train_Acc: 89.859 Val_Loss: 0.2549  BEST VAL Loss: 0.2549  Val_Acc: 90.442

Epoch 59: Validation loss decreased (0.254945 --> 0.254356).  Saving model ...
	 Train_Loss: 0.2862 Train_Acc: 89.818 Val_Loss: 0.2544  BEST VAL Loss: 0.2544  Val_Acc: 90.868

Epoch 60: Validation loss decreased (0.254356 --> 0.253775).  Saving model ...
	 Train_Loss: 0.2855 Train_Acc: 89.712 Val_Loss: 0.2538  BEST VAL Loss: 0.2538  Val_Acc: 91.007

Epoch 61: Validation loss decreased (0.253775 --> 0.253441).  Saving model ...
	 Train_Loss: 0.2848 Train_Acc: 89.905 Val_Loss: 0.2534  BEST VAL Loss: 0.2534  Val_Acc: 90.421

Epoch 62: Validation loss decreased (0.253441 --> 0.252925).  Saving model ...
	 Train_Loss: 0.2842 Train_Acc: 89.889 Val_Loss: 0.2529  BEST VAL Loss: 0.2529  Val_Acc: 90.990

Epoch 63: Validation loss decreased (0.252925 --> 0.252441).  Saving model ...
	 Train_Loss: 0.2835 Train_Acc: 89.920 Val_Loss: 0.2524  BEST VAL Loss: 0.2524  Val_Acc: 90.830

Epoch 64: Validation loss decreased (0.252441 --> 0.251914).  Saving model ...
	 Train_Loss: 0.2829 Train_Acc: 89.924 Val_Loss: 0.2519  BEST VAL Loss: 0.2519  Val_Acc: 91.121

Epoch 65: Validation loss decreased (0.251914 --> 0.251408).  Saving model ...
	 Train_Loss: 0.2823 Train_Acc: 89.927 Val_Loss: 0.2514  BEST VAL Loss: 0.2514  Val_Acc: 91.040

Epoch 66: Validation loss decreased (0.251408 --> 0.251041).  Saving model ...
	 Train_Loss: 0.2817 Train_Acc: 90.037 Val_Loss: 0.2510  BEST VAL Loss: 0.2510  Val_Acc: 90.547

Epoch 67: Validation loss decreased (0.251041 --> 0.250540).  Saving model ...
	 Train_Loss: 0.2811 Train_Acc: 89.979 Val_Loss: 0.2505  BEST VAL Loss: 0.2505  Val_Acc: 91.234

Epoch 68: Validation loss decreased (0.250540 --> 0.250074).  Saving model ...
	 Train_Loss: 0.2805 Train_Acc: 89.978 Val_Loss: 0.2501  BEST VAL Loss: 0.2501  Val_Acc: 91.011

Epoch 69: Validation loss decreased (0.250074 --> 0.249598).  Saving model ...
	 Train_Loss: 0.2799 Train_Acc: 90.020 Val_Loss: 0.2496  BEST VAL Loss: 0.2496  Val_Acc: 91.112

Epoch 70: Validation loss decreased (0.249598 --> 0.249139).  Saving model ...
	 Train_Loss: 0.2794 Train_Acc: 90.040 Val_Loss: 0.2491  BEST VAL Loss: 0.2491  Val_Acc: 91.251

Epoch 71: Validation loss decreased (0.249139 --> 0.248692).  Saving model ...
	 Train_Loss: 0.2788 Train_Acc: 89.985 Val_Loss: 0.2487  BEST VAL Loss: 0.2487  Val_Acc: 90.990

Epoch 72: Validation loss decreased (0.248692 --> 0.248246).  Saving model ...
	 Train_Loss: 0.2783 Train_Acc: 90.047 Val_Loss: 0.2482  BEST VAL Loss: 0.2482  Val_Acc: 91.192

Epoch 73: Validation loss decreased (0.248246 --> 0.247802).  Saving model ...
	 Train_Loss: 0.2777 Train_Acc: 90.090 Val_Loss: 0.2478  BEST VAL Loss: 0.2478  Val_Acc: 91.196

Epoch 74: Validation loss decreased (0.247802 --> 0.247375).  Saving model ...
	 Train_Loss: 0.2772 Train_Acc: 90.153 Val_Loss: 0.2474  BEST VAL Loss: 0.2474  Val_Acc: 91.276

Epoch 75: Validation loss decreased (0.247375 --> 0.246954).  Saving model ...
	 Train_Loss: 0.2767 Train_Acc: 90.105 Val_Loss: 0.2470  BEST VAL Loss: 0.2470  Val_Acc: 91.234

Epoch 76: Validation loss decreased (0.246954 --> 0.246538).  Saving model ...
	 Train_Loss: 0.2762 Train_Acc: 90.164 Val_Loss: 0.2465  BEST VAL Loss: 0.2465  Val_Acc: 91.213

Epoch 77: Validation loss decreased (0.246538 --> 0.246147).  Saving model ...
	 Train_Loss: 0.2757 Train_Acc: 90.192 Val_Loss: 0.2461  BEST VAL Loss: 0.2461  Val_Acc: 91.024

Epoch 78: Validation loss decreased (0.246147 --> 0.245808).  Saving model ...
	 Train_Loss: 0.2752 Train_Acc: 90.178 Val_Loss: 0.2458  BEST VAL Loss: 0.2458  Val_Acc: 90.716

Epoch 79: Validation loss decreased (0.245808 --> 0.245476).  Saving model ...
	 Train_Loss: 0.2747 Train_Acc: 90.256 Val_Loss: 0.2455  BEST VAL Loss: 0.2455  Val_Acc: 91.112

Epoch 80: Validation loss decreased (0.245476 --> 0.245106).  Saving model ...
	 Train_Loss: 0.2742 Train_Acc: 90.183 Val_Loss: 0.2451  BEST VAL Loss: 0.2451  Val_Acc: 91.137

Epoch 81: Validation loss decreased (0.245106 --> 0.244732).  Saving model ...
	 Train_Loss: 0.2738 Train_Acc: 90.133 Val_Loss: 0.2447  BEST VAL Loss: 0.2447  Val_Acc: 91.180

Epoch 82: Validation loss decreased (0.244732 --> 0.244369).  Saving model ...
	 Train_Loss: 0.2733 Train_Acc: 90.185 Val_Loss: 0.2444  BEST VAL Loss: 0.2444  Val_Acc: 91.268

Epoch 83: Validation loss decreased (0.244369 --> 0.244016).  Saving model ...
	 Train_Loss: 0.2729 Train_Acc: 90.254 Val_Loss: 0.2440  BEST VAL Loss: 0.2440  Val_Acc: 91.209

Epoch 84: Validation loss decreased (0.244016 --> 0.243680).  Saving model ...
	 Train_Loss: 0.2725 Train_Acc: 90.210 Val_Loss: 0.2437  BEST VAL Loss: 0.2437  Val_Acc: 91.209

Epoch 85: Validation loss decreased (0.243680 --> 0.243370).  Saving model ...
	 Train_Loss: 0.2720 Train_Acc: 90.253 Val_Loss: 0.2434  BEST VAL Loss: 0.2434  Val_Acc: 91.104

Epoch 86: Validation loss decreased (0.243370 --> 0.243038).  Saving model ...
	 Train_Loss: 0.2716 Train_Acc: 90.314 Val_Loss: 0.2430  BEST VAL Loss: 0.2430  Val_Acc: 91.310

Epoch 87: Validation loss decreased (0.243038 --> 0.242715).  Saving model ...
	 Train_Loss: 0.2712 Train_Acc: 90.270 Val_Loss: 0.2427  BEST VAL Loss: 0.2427  Val_Acc: 91.407

Epoch 88: Validation loss decreased (0.242715 --> 0.242392).  Saving model ...
	 Train_Loss: 0.2708 Train_Acc: 90.282 Val_Loss: 0.2424  BEST VAL Loss: 0.2424  Val_Acc: 91.281

Epoch 89: Validation loss decreased (0.242392 --> 0.242048).  Saving model ...
	 Train_Loss: 0.2703 Train_Acc: 90.340 Val_Loss: 0.2420  BEST VAL Loss: 0.2420  Val_Acc: 91.251

Epoch 90: Validation loss decreased (0.242048 --> 0.241715).  Saving model ...
	 Train_Loss: 0.2699 Train_Acc: 90.390 Val_Loss: 0.2417  BEST VAL Loss: 0.2417  Val_Acc: 91.255

Epoch 91: Validation loss decreased (0.241715 --> 0.241404).  Saving model ...
	 Train_Loss: 0.2695 Train_Acc: 90.421 Val_Loss: 0.2414  BEST VAL Loss: 0.2414  Val_Acc: 91.394

Epoch 92: Validation loss decreased (0.241404 --> 0.241116).  Saving model ...
	 Train_Loss: 0.2691 Train_Acc: 90.367 Val_Loss: 0.2411  BEST VAL Loss: 0.2411  Val_Acc: 91.137

Epoch 93: Validation loss decreased (0.241116 --> 0.240790).  Saving model ...
	 Train_Loss: 0.2688 Train_Acc: 90.347 Val_Loss: 0.2408  BEST VAL Loss: 0.2408  Val_Acc: 91.416

Epoch 94: Validation loss decreased (0.240790 --> 0.240550).  Saving model ...
	 Train_Loss: 0.2684 Train_Acc: 90.367 Val_Loss: 0.2405  BEST VAL Loss: 0.2405  Val_Acc: 91.024

Epoch 95: Validation loss decreased (0.240550 --> 0.240276).  Saving model ...
	 Train_Loss: 0.2680 Train_Acc: 90.382 Val_Loss: 0.2403  BEST VAL Loss: 0.2403  Val_Acc: 91.255

Epoch 96: Validation loss decreased (0.240276 --> 0.239990).  Saving model ...
	 Train_Loss: 0.2677 Train_Acc: 90.338 Val_Loss: 0.2400  BEST VAL Loss: 0.2400  Val_Acc: 91.281

Epoch 97: Validation loss decreased (0.239990 --> 0.239718).  Saving model ...
	 Train_Loss: 0.2673 Train_Acc: 90.355 Val_Loss: 0.2397  BEST VAL Loss: 0.2397  Val_Acc: 91.382

Epoch 98: Validation loss decreased (0.239718 --> 0.239488).  Saving model ...
	 Train_Loss: 0.2669 Train_Acc: 90.452 Val_Loss: 0.2395  BEST VAL Loss: 0.2395  Val_Acc: 90.944

Epoch 99: Validation loss decreased (0.239488 --> 0.239214).  Saving model ...
	 Train_Loss: 0.2666 Train_Acc: 90.377 Val_Loss: 0.2392  BEST VAL Loss: 0.2392  Val_Acc: 91.538

LPS_10.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.49      0.49     92173
           1       0.52      0.51      0.51     97655

    accuracy                           0.50    189828
   macro avg       0.50      0.50      0.50    189828
weighted avg       0.50      0.50      0.50    189828

LPS_10.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.49      0.49     11522
           1       0.52      0.51      0.51     12207

    accuracy                           0.50     23729
   macro avg       0.50      0.50      0.50     23729
weighted avg       0.50      0.50      0.50     23729

LPS_10.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.49      0.49     11522
           1       0.52      0.51      0.51     12207

    accuracy                           0.50     23729
   macro avg       0.50      0.50      0.50     23729
weighted avg       0.50      0.50      0.50     23729

              precision    recall  f1-score   support

           0       0.49      0.49      0.49     11522
           1       0.52      0.51      0.51     12207

    accuracy                           0.50     23729
   macro avg       0.50      0.50      0.50     23729
weighted avg       0.50      0.50      0.50     23729

LPS_10.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.42      0.45     41273
           1       0.52      0.58      0.55     44915

    accuracy                           0.50     86188
   macro avg       0.50      0.50      0.50     86188
weighted avg       0.50      0.50      0.50     86188

              precision    recall  f1-score   support

           0       0.48      0.42      0.45     41273
           1       0.52      0.58      0.55     44915

    accuracy                           0.50     86188
   macro avg       0.50      0.50      0.50     86188
weighted avg       0.50      0.50      0.50     86188

completed
