[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'da1b8be2'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '80a18b9f'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '8d02b036'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'ce5ff84c'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: DMSO_0.100_DMSO_0.025 treatment_name: LPS_10.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: DMSO_0.100_DMSO_0.025
TREATMENT_NAME: LPS_10.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'LPS_10.000_DMSO_0.025']
The dimensions of the data are: (52453, 1276)
Number of total missing values across all columns: 104906
Data Subset Is Off
Wells held out for testing: ['E20' 'I14']
Wells to use for training, validation, and testing ['B14' 'C14' 'B15' 'C15' 'E16' 'E17' 'E21' 'J14' 'I15' 'J15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.591476).  Saving model ...
	 Train_Loss: 0.6072 Train_Acc: 70.905 Val_Loss: 0.5915  BEST VAL Loss: 0.5915  Val_Acc: 70.909

Epoch 1: Validation loss decreased (0.591476 --> 0.582642).  Saving model ...
	 Train_Loss: 0.5969 Train_Acc: 70.902 Val_Loss: 0.5826  BEST VAL Loss: 0.5826  Val_Acc: 70.909

Epoch 2: Validation loss decreased (0.582642 --> 0.574797).  Saving model ...
	 Train_Loss: 0.5894 Train_Acc: 70.905 Val_Loss: 0.5748  BEST VAL Loss: 0.5748  Val_Acc: 70.909

Epoch 3: Validation loss decreased (0.574797 --> 0.567524).  Saving model ...
	 Train_Loss: 0.5836 Train_Acc: 70.971 Val_Loss: 0.5675  BEST VAL Loss: 0.5675  Val_Acc: 70.955

Epoch 4: Validation loss decreased (0.567524 --> 0.561723).  Saving model ...
	 Train_Loss: 0.5778 Train_Acc: 71.581 Val_Loss: 0.5617  BEST VAL Loss: 0.5617  Val_Acc: 71.231

Epoch 5: Validation loss decreased (0.561723 --> 0.556117).  Saving model ...
	 Train_Loss: 0.5725 Train_Acc: 72.343 Val_Loss: 0.5561  BEST VAL Loss: 0.5561  Val_Acc: 72.750

Epoch 6: Validation loss decreased (0.556117 --> 0.550880).  Saving model ...
	 Train_Loss: 0.5673 Train_Acc: 73.169 Val_Loss: 0.5509  BEST VAL Loss: 0.5509  Val_Acc: 74.039

Epoch 7: Validation loss decreased (0.550880 --> 0.545192).  Saving model ...
	 Train_Loss: 0.5626 Train_Acc: 73.304 Val_Loss: 0.5452  BEST VAL Loss: 0.5452  Val_Acc: 74.868

Epoch 8: Validation loss decreased (0.545192 --> 0.540337).  Saving model ...
	 Train_Loss: 0.5582 Train_Acc: 73.914 Val_Loss: 0.5403  BEST VAL Loss: 0.5403  Val_Acc: 75.650

Epoch 9: Validation loss decreased (0.540337 --> 0.535906).  Saving model ...
	 Train_Loss: 0.5542 Train_Acc: 73.859 Val_Loss: 0.5359  BEST VAL Loss: 0.5359  Val_Acc: 75.995

Epoch 10: Validation loss decreased (0.535906 --> 0.531672).  Saving model ...
	 Train_Loss: 0.5505 Train_Acc: 74.653 Val_Loss: 0.5317  BEST VAL Loss: 0.5317  Val_Acc: 76.272

Epoch 11: Validation loss decreased (0.531672 --> 0.527694).  Saving model ...
	 Train_Loss: 0.5470 Train_Acc: 74.835 Val_Loss: 0.5277  BEST VAL Loss: 0.5277  Val_Acc: 76.824

Epoch 12: Validation loss decreased (0.527694 --> 0.524302).  Saving model ...
	 Train_Loss: 0.5437 Train_Acc: 75.286 Val_Loss: 0.5243  BEST VAL Loss: 0.5243  Val_Acc: 77.031

Epoch 13: Validation loss decreased (0.524302 --> 0.521529).  Saving model ...
	 Train_Loss: 0.5406 Train_Acc: 75.301 Val_Loss: 0.5215  BEST VAL Loss: 0.5215  Val_Acc: 77.307

Epoch 14: Validation loss decreased (0.521529 --> 0.518538).  Saving model ...
	 Train_Loss: 0.5377 Train_Acc: 75.706 Val_Loss: 0.5185  BEST VAL Loss: 0.5185  Val_Acc: 77.192

Epoch 15: Validation loss decreased (0.518538 --> 0.516051).  Saving model ...
	 Train_Loss: 0.5350 Train_Acc: 75.934 Val_Loss: 0.5161  BEST VAL Loss: 0.5161  Val_Acc: 77.353

Epoch 16: Validation loss decreased (0.516051 --> 0.513483).  Saving model ...
	 Train_Loss: 0.5323 Train_Acc: 76.135 Val_Loss: 0.5135  BEST VAL Loss: 0.5135  Val_Acc: 77.652

Epoch 17: Validation loss decreased (0.513483 --> 0.511232).  Saving model ...
	 Train_Loss: 0.5298 Train_Acc: 76.296 Val_Loss: 0.5112  BEST VAL Loss: 0.5112  Val_Acc: 77.837

Epoch 18: Validation loss decreased (0.511232 --> 0.509360).  Saving model ...
	 Train_Loss: 0.5274 Train_Acc: 76.428 Val_Loss: 0.5094  BEST VAL Loss: 0.5094  Val_Acc: 77.491

Epoch 19: Validation loss decreased (0.509360 --> 0.507390).  Saving model ...
	 Train_Loss: 0.5252 Train_Acc: 76.733 Val_Loss: 0.5074  BEST VAL Loss: 0.5074  Val_Acc: 77.284

Epoch 20: Validation loss decreased (0.507390 --> 0.505934).  Saving model ...
	 Train_Loss: 0.5232 Train_Acc: 76.331 Val_Loss: 0.5059  BEST VAL Loss: 0.5059  Val_Acc: 77.284

Epoch 21: Validation loss decreased (0.505934 --> 0.504236).  Saving model ...
	 Train_Loss: 0.5211 Train_Acc: 76.915 Val_Loss: 0.5042  BEST VAL Loss: 0.5042  Val_Acc: 78.136

Epoch 22: Validation loss decreased (0.504236 --> 0.502566).  Saving model ...
	 Train_Loss: 0.5192 Train_Acc: 77.208 Val_Loss: 0.5026  BEST VAL Loss: 0.5026  Val_Acc: 77.722

Epoch 23: Validation loss decreased (0.502566 --> 0.500832).  Saving model ...
	 Train_Loss: 0.5173 Train_Acc: 77.151 Val_Loss: 0.5008  BEST VAL Loss: 0.5008  Val_Acc: 78.044

Epoch 24: Validation loss decreased (0.500832 --> 0.499498).  Saving model ...
	 Train_Loss: 0.5155 Train_Acc: 77.199 Val_Loss: 0.4995  BEST VAL Loss: 0.4995  Val_Acc: 77.745

Epoch 25: Validation loss decreased (0.499498 --> 0.498211).  Saving model ...
	 Train_Loss: 0.5138 Train_Acc: 77.294 Val_Loss: 0.4982  BEST VAL Loss: 0.4982  Val_Acc: 77.998

Epoch 26: Validation loss decreased (0.498211 --> 0.496926).  Saving model ...
	 Train_Loss: 0.5122 Train_Acc: 77.473 Val_Loss: 0.4969  BEST VAL Loss: 0.4969  Val_Acc: 78.090

Epoch 27: Validation loss decreased (0.496926 --> 0.495921).  Saving model ...
	 Train_Loss: 0.5106 Train_Acc: 77.625 Val_Loss: 0.4959  BEST VAL Loss: 0.4959  Val_Acc: 78.596

Epoch 28: Validation loss decreased (0.495921 --> 0.494844).  Saving model ...
	 Train_Loss: 0.5091 Train_Acc: 77.568 Val_Loss: 0.4948  BEST VAL Loss: 0.4948  Val_Acc: 78.435

Epoch 29: Validation loss decreased (0.494844 --> 0.493787).  Saving model ...
	 Train_Loss: 0.5076 Train_Acc: 77.729 Val_Loss: 0.4938  BEST VAL Loss: 0.4938  Val_Acc: 78.182

Epoch 30: Validation loss decreased (0.493787 --> 0.492636).  Saving model ...
	 Train_Loss: 0.5061 Train_Acc: 77.654 Val_Loss: 0.4926  BEST VAL Loss: 0.4926  Val_Acc: 78.228

Epoch 31: Validation loss decreased (0.492636 --> 0.491611).  Saving model ...
	 Train_Loss: 0.5048 Train_Acc: 78.054 Val_Loss: 0.4916  BEST VAL Loss: 0.4916  Val_Acc: 78.412

Epoch 32: Validation loss decreased (0.491611 --> 0.490815).  Saving model ...
	 Train_Loss: 0.5035 Train_Acc: 78.045 Val_Loss: 0.4908  BEST VAL Loss: 0.4908  Val_Acc: 77.906

Epoch 33: Validation loss decreased (0.490815 --> 0.490102).  Saving model ...
	 Train_Loss: 0.5022 Train_Acc: 77.930 Val_Loss: 0.4901  BEST VAL Loss: 0.4901  Val_Acc: 78.297

Epoch 34: Validation loss decreased (0.490102 --> 0.489241).  Saving model ...
	 Train_Loss: 0.5010 Train_Acc: 78.172 Val_Loss: 0.4892  BEST VAL Loss: 0.4892  Val_Acc: 78.067

Epoch 35: Validation loss decreased (0.489241 --> 0.488560).  Saving model ...
	 Train_Loss: 0.4998 Train_Acc: 78.514 Val_Loss: 0.4886  BEST VAL Loss: 0.4886  Val_Acc: 78.573

Epoch 36: Validation loss decreased (0.488560 --> 0.487836).  Saving model ...
	 Train_Loss: 0.4986 Train_Acc: 78.293 Val_Loss: 0.4878  BEST VAL Loss: 0.4878  Val_Acc: 78.481

Epoch 37: Validation loss decreased (0.487836 --> 0.487051).  Saving model ...
	 Train_Loss: 0.4975 Train_Acc: 78.534 Val_Loss: 0.4871  BEST VAL Loss: 0.4871  Val_Acc: 78.113

Epoch 38: Validation loss decreased (0.487051 --> 0.486308).  Saving model ...
	 Train_Loss: 0.4963 Train_Acc: 78.690 Val_Loss: 0.4863  BEST VAL Loss: 0.4863  Val_Acc: 78.504

Epoch 39: Validation loss decreased (0.486308 --> 0.485696).  Saving model ...
	 Train_Loss: 0.4953 Train_Acc: 78.756 Val_Loss: 0.4857  BEST VAL Loss: 0.4857  Val_Acc: 78.711

Epoch 40: Validation loss decreased (0.485696 --> 0.485175).  Saving model ...
	 Train_Loss: 0.4942 Train_Acc: 78.414 Val_Loss: 0.4852  BEST VAL Loss: 0.4852  Val_Acc: 78.412

Epoch 41: Validation loss decreased (0.485175 --> 0.484525).  Saving model ...
	 Train_Loss: 0.4932 Train_Acc: 78.790 Val_Loss: 0.4845  BEST VAL Loss: 0.4845  Val_Acc: 78.412

Epoch 42: Validation loss decreased (0.484525 --> 0.484003).  Saving model ...
	 Train_Loss: 0.4922 Train_Acc: 78.903 Val_Loss: 0.4840  BEST VAL Loss: 0.4840  Val_Acc: 78.228

Epoch 43: Validation loss decreased (0.484003 --> 0.483307).  Saving model ...
	 Train_Loss: 0.4911 Train_Acc: 78.949 Val_Loss: 0.4833  BEST VAL Loss: 0.4833  Val_Acc: 79.079

Epoch 44: Validation loss decreased (0.483307 --> 0.482728).  Saving model ...
	 Train_Loss: 0.4902 Train_Acc: 78.808 Val_Loss: 0.4827  BEST VAL Loss: 0.4827  Val_Acc: 78.481

Epoch 45: Validation loss decreased (0.482728 --> 0.482218).  Saving model ...
	 Train_Loss: 0.4892 Train_Acc: 79.061 Val_Loss: 0.4822  BEST VAL Loss: 0.4822  Val_Acc: 78.573

Epoch 46: Validation loss decreased (0.482218 --> 0.481608).  Saving model ...
	 Train_Loss: 0.4883 Train_Acc: 79.032 Val_Loss: 0.4816  BEST VAL Loss: 0.4816  Val_Acc: 78.987

Epoch 47: Validation loss decreased (0.481608 --> 0.481054).  Saving model ...
	 Train_Loss: 0.4875 Train_Acc: 78.862 Val_Loss: 0.4811  BEST VAL Loss: 0.4811  Val_Acc: 78.780

Epoch 48: Validation loss decreased (0.481054 --> 0.480620).  Saving model ...
	 Train_Loss: 0.4866 Train_Acc: 79.104 Val_Loss: 0.4806  BEST VAL Loss: 0.4806  Val_Acc: 78.366

Epoch 49: Validation loss decreased (0.480620 --> 0.480271).  Saving model ...
	 Train_Loss: 0.4859 Train_Acc: 78.963 Val_Loss: 0.4803  BEST VAL Loss: 0.4803  Val_Acc: 78.527

Epoch 50: Validation loss decreased (0.480271 --> 0.479973).  Saving model ...
	 Train_Loss: 0.4851 Train_Acc: 79.139 Val_Loss: 0.4800  BEST VAL Loss: 0.4800  Val_Acc: 78.872

Epoch 51: Validation loss decreased (0.479973 --> 0.479743).  Saving model ...
	 Train_Loss: 0.4843 Train_Acc: 79.513 Val_Loss: 0.4797  BEST VAL Loss: 0.4797  Val_Acc: 78.389

Epoch 52: Validation loss decreased (0.479743 --> 0.479426).  Saving model ...
	 Train_Loss: 0.4835 Train_Acc: 79.130 Val_Loss: 0.4794  BEST VAL Loss: 0.4794  Val_Acc: 78.941

Epoch 53: Validation loss decreased (0.479426 --> 0.479131).  Saving model ...
	 Train_Loss: 0.4827 Train_Acc: 79.239 Val_Loss: 0.4791  BEST VAL Loss: 0.4791  Val_Acc: 78.642

Epoch 54: Validation loss decreased (0.479131 --> 0.478908).  Saving model ...
	 Train_Loss: 0.4820 Train_Acc: 79.107 Val_Loss: 0.4789  BEST VAL Loss: 0.4789  Val_Acc: 78.251

Epoch 55: Validation loss decreased (0.478908 --> 0.478632).  Saving model ...
	 Train_Loss: 0.4813 Train_Acc: 79.248 Val_Loss: 0.4786  BEST VAL Loss: 0.4786  Val_Acc: 78.734

Epoch 56: Validation loss decreased (0.478632 --> 0.478411).  Saving model ...
	 Train_Loss: 0.4805 Train_Acc: 79.530 Val_Loss: 0.4784  BEST VAL Loss: 0.4784  Val_Acc: 78.780

Epoch 57: Validation loss decreased (0.478411 --> 0.478038).  Saving model ...
	 Train_Loss: 0.4798 Train_Acc: 79.363 Val_Loss: 0.4780  BEST VAL Loss: 0.4780  Val_Acc: 79.102

Epoch 58: Validation loss decreased (0.478038 --> 0.477911).  Saving model ...
	 Train_Loss: 0.4791 Train_Acc: 79.490 Val_Loss: 0.4779  BEST VAL Loss: 0.4779  Val_Acc: 78.343

Epoch 59: Validation loss decreased (0.477911 --> 0.477496).  Saving model ...
	 Train_Loss: 0.4784 Train_Acc: 79.421 Val_Loss: 0.4775  BEST VAL Loss: 0.4775  Val_Acc: 79.010

Epoch 60: Validation loss decreased (0.477496 --> 0.477129).  Saving model ...
	 Train_Loss: 0.4778 Train_Acc: 79.377 Val_Loss: 0.4771  BEST VAL Loss: 0.4771  Val_Acc: 78.711

Epoch 61: Validation loss decreased (0.477129 --> 0.476958).  Saving model ...
	 Train_Loss: 0.4771 Train_Acc: 79.636 Val_Loss: 0.4770  BEST VAL Loss: 0.4770  Val_Acc: 78.550

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.4765 Train_Acc: 79.452 Val_Loss: 0.4770  BEST VAL Loss: 0.4770  Val_Acc: 78.389

Epoch 63: Validation loss decreased (0.476958 --> 0.476678).  Saving model ...
	 Train_Loss: 0.4758 Train_Acc: 79.472 Val_Loss: 0.4767  BEST VAL Loss: 0.4767  Val_Acc: 78.964

Epoch 64: Validation loss decreased (0.476678 --> 0.476356).  Saving model ...
	 Train_Loss: 0.4752 Train_Acc: 79.449 Val_Loss: 0.4764  BEST VAL Loss: 0.4764  Val_Acc: 79.033

Epoch 65: Validation loss decreased (0.476356 --> 0.476115).  Saving model ...
	 Train_Loss: 0.4746 Train_Acc: 79.815 Val_Loss: 0.4761  BEST VAL Loss: 0.4761  Val_Acc: 78.642

Epoch 66: Validation loss decreased (0.476115 --> 0.475856).  Saving model ...
	 Train_Loss: 0.4741 Train_Acc: 79.582 Val_Loss: 0.4759  BEST VAL Loss: 0.4759  Val_Acc: 78.734

Epoch 67: Validation loss decreased (0.475856 --> 0.475565).  Saving model ...
	 Train_Loss: 0.4735 Train_Acc: 79.547 Val_Loss: 0.4756  BEST VAL Loss: 0.4756  Val_Acc: 78.780

Epoch 68: Validation loss decreased (0.475565 --> 0.475271).  Saving model ...
	 Train_Loss: 0.4729 Train_Acc: 79.924 Val_Loss: 0.4753  BEST VAL Loss: 0.4753  Val_Acc: 78.458

Epoch 69: Validation loss decreased (0.475271 --> 0.475092).  Saving model ...
	 Train_Loss: 0.4723 Train_Acc: 79.826 Val_Loss: 0.4751  BEST VAL Loss: 0.4751  Val_Acc: 78.619

Epoch 70: Validation loss decreased (0.475092 --> 0.474982).  Saving model ...
	 Train_Loss: 0.4717 Train_Acc: 80.117 Val_Loss: 0.4750  BEST VAL Loss: 0.4750  Val_Acc: 78.320

Epoch 71: Validation loss decreased (0.474982 --> 0.474706).  Saving model ...
	 Train_Loss: 0.4712 Train_Acc: 80.051 Val_Loss: 0.4747  BEST VAL Loss: 0.4747  Val_Acc: 78.136

Epoch 72: Validation loss decreased (0.474706 --> 0.474530).  Saving model ...
	 Train_Loss: 0.4706 Train_Acc: 79.970 Val_Loss: 0.4745  BEST VAL Loss: 0.4745  Val_Acc: 78.688

Epoch 73: Validation loss decreased (0.474530 --> 0.474323).  Saving model ...
	 Train_Loss: 0.4701 Train_Acc: 79.927 Val_Loss: 0.4743  BEST VAL Loss: 0.4743  Val_Acc: 78.688

Epoch 74: Validation loss decreased (0.474323 --> 0.474208).  Saving model ...
	 Train_Loss: 0.4696 Train_Acc: 79.593 Val_Loss: 0.4742  BEST VAL Loss: 0.4742  Val_Acc: 78.941

Epoch 75: Validation loss decreased (0.474208 --> 0.473962).  Saving model ...
	 Train_Loss: 0.4691 Train_Acc: 79.927 Val_Loss: 0.4740  BEST VAL Loss: 0.4740  Val_Acc: 78.343

Epoch 76: Validation loss decreased (0.473962 --> 0.473896).  Saving model ...
	 Train_Loss: 0.4686 Train_Acc: 79.999 Val_Loss: 0.4739  BEST VAL Loss: 0.4739  Val_Acc: 78.573

Epoch 77: Validation loss decreased (0.473896 --> 0.473674).  Saving model ...
	 Train_Loss: 0.4681 Train_Acc: 79.933 Val_Loss: 0.4737  BEST VAL Loss: 0.4737  Val_Acc: 78.136

Epoch 78: Validation loss decreased (0.473674 --> 0.473671).  Saving model ...
	 Train_Loss: 0.4675 Train_Acc: 80.120 Val_Loss: 0.4737  BEST VAL Loss: 0.4737  Val_Acc: 77.883

Epoch 79: Validation loss decreased (0.473671 --> 0.473522).  Saving model ...
	 Train_Loss: 0.4670 Train_Acc: 79.967 Val_Loss: 0.4735  BEST VAL Loss: 0.4735  Val_Acc: 78.504

Epoch 80: Validation loss decreased (0.473522 --> 0.473437).  Saving model ...
	 Train_Loss: 0.4666 Train_Acc: 79.990 Val_Loss: 0.4734  BEST VAL Loss: 0.4734  Val_Acc: 78.481

Epoch 81: Validation loss decreased (0.473437 --> 0.473351).  Saving model ...
	 Train_Loss: 0.4661 Train_Acc: 80.028 Val_Loss: 0.4734  BEST VAL Loss: 0.4734  Val_Acc: 78.780

Epoch 82: Validation loss decreased (0.473351 --> 0.473262).  Saving model ...
	 Train_Loss: 0.4657 Train_Acc: 80.148 Val_Loss: 0.4733  BEST VAL Loss: 0.4733  Val_Acc: 78.527

Epoch 83: Validation loss decreased (0.473262 --> 0.473081).  Saving model ...
	 Train_Loss: 0.4652 Train_Acc: 80.209 Val_Loss: 0.4731  BEST VAL Loss: 0.4731  Val_Acc: 78.803

Epoch 84: Validation loss decreased (0.473081 --> 0.472973).  Saving model ...
	 Train_Loss: 0.4648 Train_Acc: 80.114 Val_Loss: 0.4730  BEST VAL Loss: 0.4730  Val_Acc: 78.711

Epoch 85: Validation loss decreased (0.472973 --> 0.472885).  Saving model ...
	 Train_Loss: 0.4643 Train_Acc: 80.218 Val_Loss: 0.4729  BEST VAL Loss: 0.4729  Val_Acc: 78.780

Epoch 86: Validation loss decreased (0.472885 --> 0.472788).  Saving model ...
	 Train_Loss: 0.4638 Train_Acc: 80.252 Val_Loss: 0.4728  BEST VAL Loss: 0.4728  Val_Acc: 78.205

Epoch 87: Validation loss decreased (0.472788 --> 0.472648).  Saving model ...
	 Train_Loss: 0.4634 Train_Acc: 80.241 Val_Loss: 0.4726  BEST VAL Loss: 0.4726  Val_Acc: 78.918

Epoch 88: Validation loss decreased (0.472648 --> 0.472583).  Saving model ...
	 Train_Loss: 0.4630 Train_Acc: 80.344 Val_Loss: 0.4726  BEST VAL Loss: 0.4726  Val_Acc: 78.941

Epoch 89: Validation loss decreased (0.472583 --> 0.472463).  Saving model ...
	 Train_Loss: 0.4625 Train_Acc: 80.226 Val_Loss: 0.4725  BEST VAL Loss: 0.4725  Val_Acc: 79.056

Epoch 90: Validation loss decreased (0.472463 --> 0.472344).  Saving model ...
	 Train_Loss: 0.4621 Train_Acc: 80.442 Val_Loss: 0.4723  BEST VAL Loss: 0.4723  Val_Acc: 78.481

Epoch 91: Validation loss decreased (0.472344 --> 0.472323).  Saving model ...
	 Train_Loss: 0.4617 Train_Acc: 80.425 Val_Loss: 0.4723  BEST VAL Loss: 0.4723  Val_Acc: 78.964

Epoch 92: Validation loss decreased (0.472323 --> 0.472205).  Saving model ...
	 Train_Loss: 0.4613 Train_Acc: 80.497 Val_Loss: 0.4722  BEST VAL Loss: 0.4722  Val_Acc: 78.619

Epoch 93: Validation loss decreased (0.472205 --> 0.472167).  Saving model ...
	 Train_Loss: 0.4608 Train_Acc: 80.609 Val_Loss: 0.4722  BEST VAL Loss: 0.4722  Val_Acc: 78.895

Epoch 94: Validation loss decreased (0.472167 --> 0.471988).  Saving model ...
	 Train_Loss: 0.4604 Train_Acc: 80.393 Val_Loss: 0.4720  BEST VAL Loss: 0.4720  Val_Acc: 79.102

Epoch 95: Validation loss decreased (0.471988 --> 0.471855).  Saving model ...
	 Train_Loss: 0.4600 Train_Acc: 80.566 Val_Loss: 0.4719  BEST VAL Loss: 0.4719  Val_Acc: 78.849

Epoch 96: Validation loss decreased (0.471855 --> 0.471769).  Saving model ...
	 Train_Loss: 0.4596 Train_Acc: 80.640 Val_Loss: 0.4718  BEST VAL Loss: 0.4718  Val_Acc: 78.826

Epoch 97: Validation loss decreased (0.471769 --> 0.471680).  Saving model ...
	 Train_Loss: 0.4592 Train_Acc: 80.439 Val_Loss: 0.4717  BEST VAL Loss: 0.4717  Val_Acc: 78.320

Epoch 98: Validation loss decreased (0.471680 --> 0.471613).  Saving model ...
	 Train_Loss: 0.4588 Train_Acc: 80.773 Val_Loss: 0.4716  BEST VAL Loss: 0.4716  Val_Acc: 78.596

Epoch 99: Validation loss decreased (0.471613 --> 0.471540).  Saving model ...
	 Train_Loss: 0.4584 Train_Acc: 80.661 Val_Loss: 0.4715  BEST VAL Loss: 0.4715  Val_Acc: 78.895

DMSO_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.71      0.78      0.74     24644
           1       0.29      0.22      0.25     10114

    accuracy                           0.61     34758
   macro avg       0.50      0.50      0.49     34758
weighted avg       0.58      0.61      0.60     34758

DMSO_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.71      0.79      0.75      3081
           1       0.30      0.22      0.26      1264

    accuracy                           0.62      4345
   macro avg       0.51      0.50      0.50      4345
weighted avg       0.59      0.62      0.60      4345

DMSO_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.71      0.78      0.74      3081
           1       0.29      0.22      0.25      1264

    accuracy                           0.61      4345
   macro avg       0.50      0.50      0.49      4345
weighted avg       0.59      0.61      0.60      4345

              precision    recall  f1-score   support

           0       0.71      0.78      0.74      3081
           1       0.29      0.22      0.25      1264

    accuracy                           0.61      4345
   macro avg       0.50      0.50      0.49      4345
weighted avg       0.59      0.61      0.60      4345

DMSO_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.68      0.60      4837
           1       0.45      0.30      0.36      4168

    accuracy                           0.51      9005
   macro avg       0.49      0.49      0.48      9005
weighted avg       0.49      0.51      0.49      9005

              precision    recall  f1-score   support

           0       0.53      0.68      0.60      4837
           1       0.45      0.30      0.36      4168

    accuracy                           0.51      9005
   macro avg       0.49      0.49      0.48      9005
weighted avg       0.49      0.51      0.49      9005

completed
