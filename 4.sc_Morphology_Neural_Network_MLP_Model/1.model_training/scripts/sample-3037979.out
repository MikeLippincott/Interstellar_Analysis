[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ed238b80'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '7b2c2e31'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ff156cfe'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'cbc8af81'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_0.010_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_0.010_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (309093, 1270)
Number of total missing values across all columns: 286160
Data Subset Is Off
Wells held out for testing: ['B08' 'K08']
Wells to use for training, validation, and testing ['B02' 'B03' 'B09' 'K02' 'K03' 'K09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.305617).  Saving model ...
	 Train_Loss: 0.4135 Train_Acc: 80.774 Val_Loss: 0.3056  BEST VAL Loss: 0.3056  Val_Acc: 86.837

Epoch 1: Validation loss decreased (0.305617 --> 0.287146).  Saving model ...
	 Train_Loss: 0.3622 Train_Acc: 86.245 Val_Loss: 0.2871  BEST VAL Loss: 0.2871  Val_Acc: 88.628

Epoch 2: Validation loss decreased (0.287146 --> 0.277368).  Saving model ...
	 Train_Loss: 0.3374 Train_Acc: 87.493 Val_Loss: 0.2774  BEST VAL Loss: 0.2774  Val_Acc: 89.228

Epoch 3: Validation loss decreased (0.277368 --> 0.268980).  Saving model ...
	 Train_Loss: 0.3216 Train_Acc: 88.177 Val_Loss: 0.2690  BEST VAL Loss: 0.2690  Val_Acc: 89.910

Epoch 4: Validation loss decreased (0.268980 --> 0.263818).  Saving model ...
	 Train_Loss: 0.3106 Train_Acc: 88.486 Val_Loss: 0.2638  BEST VAL Loss: 0.2638  Val_Acc: 89.953

Epoch 5: Validation loss decreased (0.263818 --> 0.259392).  Saving model ...
	 Train_Loss: 0.3022 Train_Acc: 88.815 Val_Loss: 0.2594  BEST VAL Loss: 0.2594  Val_Acc: 90.432

Epoch 6: Validation loss decreased (0.259392 --> 0.255784).  Saving model ...
	 Train_Loss: 0.2954 Train_Acc: 89.079 Val_Loss: 0.2558  BEST VAL Loss: 0.2558  Val_Acc: 90.687

Epoch 7: Validation loss decreased (0.255784 --> 0.252892).  Saving model ...
	 Train_Loss: 0.2896 Train_Acc: 89.354 Val_Loss: 0.2529  BEST VAL Loss: 0.2529  Val_Acc: 90.730

Epoch 8: Validation loss decreased (0.252892 --> 0.250472).  Saving model ...
	 Train_Loss: 0.2848 Train_Acc: 89.476 Val_Loss: 0.2505  BEST VAL Loss: 0.2505  Val_Acc: 90.704

Epoch 9: Validation loss decreased (0.250472 --> 0.247889).  Saving model ...
	 Train_Loss: 0.2805 Train_Acc: 89.621 Val_Loss: 0.2479  BEST VAL Loss: 0.2479  Val_Acc: 90.941

Epoch 10: Validation loss decreased (0.247889 --> 0.245611).  Saving model ...
	 Train_Loss: 0.2767 Train_Acc: 89.812 Val_Loss: 0.2456  BEST VAL Loss: 0.2456  Val_Acc: 91.066

Epoch 11: Validation loss decreased (0.245611 --> 0.243529).  Saving model ...
	 Train_Loss: 0.2734 Train_Acc: 89.878 Val_Loss: 0.2435  BEST VAL Loss: 0.2435  Val_Acc: 91.088

Epoch 12: Validation loss decreased (0.243529 --> 0.241716).  Saving model ...
	 Train_Loss: 0.2703 Train_Acc: 90.046 Val_Loss: 0.2417  BEST VAL Loss: 0.2417  Val_Acc: 91.187

Epoch 13: Validation loss decreased (0.241716 --> 0.240036).  Saving model ...
	 Train_Loss: 0.2675 Train_Acc: 90.142 Val_Loss: 0.2400  BEST VAL Loss: 0.2400  Val_Acc: 91.269

Epoch 14: Validation loss decreased (0.240036 --> 0.238414).  Saving model ...
	 Train_Loss: 0.2650 Train_Acc: 90.157 Val_Loss: 0.2384  BEST VAL Loss: 0.2384  Val_Acc: 91.278

Epoch 15: Validation loss decreased (0.238414 --> 0.237043).  Saving model ...
	 Train_Loss: 0.2627 Train_Acc: 90.290 Val_Loss: 0.2370  BEST VAL Loss: 0.2370  Val_Acc: 91.205

Epoch 16: Validation loss decreased (0.237043 --> 0.235810).  Saving model ...
	 Train_Loss: 0.2605 Train_Acc: 90.364 Val_Loss: 0.2358  BEST VAL Loss: 0.2358  Val_Acc: 91.261

Epoch 17: Validation loss decreased (0.235810 --> 0.234687).  Saving model ...
	 Train_Loss: 0.2584 Train_Acc: 90.475 Val_Loss: 0.2347  BEST VAL Loss: 0.2347  Val_Acc: 91.390

Epoch 18: Validation loss decreased (0.234687 --> 0.233565).  Saving model ...
	 Train_Loss: 0.2566 Train_Acc: 90.459 Val_Loss: 0.2336  BEST VAL Loss: 0.2336  Val_Acc: 91.511

Epoch 19: Validation loss decreased (0.233565 --> 0.232545).  Saving model ...
	 Train_Loss: 0.2548 Train_Acc: 90.596 Val_Loss: 0.2325  BEST VAL Loss: 0.2325  Val_Acc: 91.515

Epoch 20: Validation loss decreased (0.232545 --> 0.231587).  Saving model ...
	 Train_Loss: 0.2531 Train_Acc: 90.616 Val_Loss: 0.2316  BEST VAL Loss: 0.2316  Val_Acc: 91.481

Epoch 21: Validation loss decreased (0.231587 --> 0.230748).  Saving model ...
	 Train_Loss: 0.2515 Train_Acc: 90.682 Val_Loss: 0.2307  BEST VAL Loss: 0.2307  Val_Acc: 91.524

Epoch 22: Validation loss decreased (0.230748 --> 0.229811).  Saving model ...
	 Train_Loss: 0.2500 Train_Acc: 90.729 Val_Loss: 0.2298  BEST VAL Loss: 0.2298  Val_Acc: 91.610

Epoch 23: Validation loss decreased (0.229811 --> 0.228940).  Saving model ...
	 Train_Loss: 0.2486 Train_Acc: 90.873 Val_Loss: 0.2289  BEST VAL Loss: 0.2289  Val_Acc: 91.869

Epoch 24: Validation loss decreased (0.228940 --> 0.228398).  Saving model ...
	 Train_Loss: 0.2473 Train_Acc: 90.838 Val_Loss: 0.2284  BEST VAL Loss: 0.2284  Val_Acc: 91.580

Epoch 25: Validation loss decreased (0.228398 --> 0.227828).  Saving model ...
	 Train_Loss: 0.2460 Train_Acc: 90.845 Val_Loss: 0.2278  BEST VAL Loss: 0.2278  Val_Acc: 91.528

Epoch 26: Validation loss decreased (0.227828 --> 0.227091).  Saving model ...
	 Train_Loss: 0.2448 Train_Acc: 90.884 Val_Loss: 0.2271  BEST VAL Loss: 0.2271  Val_Acc: 91.869

Epoch 27: Validation loss decreased (0.227091 --> 0.226418).  Saving model ...
	 Train_Loss: 0.2436 Train_Acc: 90.976 Val_Loss: 0.2264  BEST VAL Loss: 0.2264  Val_Acc: 91.779

Epoch 28: Validation loss decreased (0.226418 --> 0.225861).  Saving model ...
	 Train_Loss: 0.2425 Train_Acc: 91.013 Val_Loss: 0.2259  BEST VAL Loss: 0.2259  Val_Acc: 91.722

Epoch 29: Validation loss decreased (0.225861 --> 0.225348).  Saving model ...
	 Train_Loss: 0.2415 Train_Acc: 91.081 Val_Loss: 0.2253  BEST VAL Loss: 0.2253  Val_Acc: 91.705

Epoch 30: Validation loss decreased (0.225348 --> 0.224838).  Saving model ...
	 Train_Loss: 0.2405 Train_Acc: 91.112 Val_Loss: 0.2248  BEST VAL Loss: 0.2248  Val_Acc: 91.679

Epoch 31: Validation loss decreased (0.224838 --> 0.224436).  Saving model ...
	 Train_Loss: 0.2395 Train_Acc: 91.150 Val_Loss: 0.2244  BEST VAL Loss: 0.2244  Val_Acc: 91.662

Epoch 32: Validation loss decreased (0.224436 --> 0.223883).  Saving model ...
	 Train_Loss: 0.2385 Train_Acc: 91.127 Val_Loss: 0.2239  BEST VAL Loss: 0.2239  Val_Acc: 91.865

Epoch 33: Validation loss decreased (0.223883 --> 0.223468).  Saving model ...
	 Train_Loss: 0.2376 Train_Acc: 91.150 Val_Loss: 0.2235  BEST VAL Loss: 0.2235  Val_Acc: 91.813

Epoch 34: Validation loss decreased (0.223468 --> 0.223168).  Saving model ...
	 Train_Loss: 0.2367 Train_Acc: 91.235 Val_Loss: 0.2232  BEST VAL Loss: 0.2232  Val_Acc: 91.800

Epoch 35: Validation loss decreased (0.223168 --> 0.222862).  Saving model ...
	 Train_Loss: 0.2359 Train_Acc: 91.198 Val_Loss: 0.2229  BEST VAL Loss: 0.2229  Val_Acc: 91.783

Epoch 36: Validation loss decreased (0.222862 --> 0.222658).  Saving model ...
	 Train_Loss: 0.2351 Train_Acc: 91.319 Val_Loss: 0.2227  BEST VAL Loss: 0.2227  Val_Acc: 91.809

Epoch 37: Validation loss decreased (0.222658 --> 0.222459).  Saving model ...
	 Train_Loss: 0.2343 Train_Acc: 91.262 Val_Loss: 0.2225  BEST VAL Loss: 0.2225  Val_Acc: 91.645

Epoch 38: Validation loss decreased (0.222459 --> 0.222130).  Saving model ...
	 Train_Loss: 0.2336 Train_Acc: 91.242 Val_Loss: 0.2221  BEST VAL Loss: 0.2221  Val_Acc: 91.826

Epoch 39: Validation loss decreased (0.222130 --> 0.221897).  Saving model ...
	 Train_Loss: 0.2328 Train_Acc: 91.355 Val_Loss: 0.2219  BEST VAL Loss: 0.2219  Val_Acc: 91.688

Epoch 40: Validation loss decreased (0.221897 --> 0.221466).  Saving model ...
	 Train_Loss: 0.2321 Train_Acc: 91.418 Val_Loss: 0.2215  BEST VAL Loss: 0.2215  Val_Acc: 91.804

Epoch 41: Validation loss decreased (0.221466 --> 0.221139).  Saving model ...
	 Train_Loss: 0.2314 Train_Acc: 91.414 Val_Loss: 0.2211  BEST VAL Loss: 0.2211  Val_Acc: 91.761

Epoch 42: Validation loss decreased (0.221139 --> 0.220926).  Saving model ...
	 Train_Loss: 0.2308 Train_Acc: 91.444 Val_Loss: 0.2209  BEST VAL Loss: 0.2209  Val_Acc: 91.735

Epoch 43: Validation loss decreased (0.220926 --> 0.220699).  Saving model ...
	 Train_Loss: 0.2301 Train_Acc: 91.478 Val_Loss: 0.2207  BEST VAL Loss: 0.2207  Val_Acc: 91.783

Epoch 44: Validation loss decreased (0.220699 --> 0.220400).  Saving model ...
	 Train_Loss: 0.2295 Train_Acc: 91.408 Val_Loss: 0.2204  BEST VAL Loss: 0.2204  Val_Acc: 91.891

Epoch 45: Validation loss decreased (0.220400 --> 0.220257).  Saving model ...
	 Train_Loss: 0.2289 Train_Acc: 91.455 Val_Loss: 0.2203  BEST VAL Loss: 0.2203  Val_Acc: 91.705

Epoch 46: Validation loss decreased (0.220257 --> 0.220055).  Saving model ...
	 Train_Loss: 0.2283 Train_Acc: 91.425 Val_Loss: 0.2201  BEST VAL Loss: 0.2201  Val_Acc: 91.917

Epoch 47: Validation loss decreased (0.220055 --> 0.219939).  Saving model ...
	 Train_Loss: 0.2277 Train_Acc: 91.520 Val_Loss: 0.2199  BEST VAL Loss: 0.2199  Val_Acc: 91.943

Epoch 48: Validation loss decreased (0.219939 --> 0.219826).  Saving model ...
	 Train_Loss: 0.2271 Train_Acc: 91.528 Val_Loss: 0.2198  BEST VAL Loss: 0.2198  Val_Acc: 91.912

Epoch 49: Validation loss decreased (0.219826 --> 0.219639).  Saving model ...
	 Train_Loss: 0.2266 Train_Acc: 91.500 Val_Loss: 0.2196  BEST VAL Loss: 0.2196  Val_Acc: 91.839

Epoch 50: Validation loss decreased (0.219639 --> 0.219515).  Saving model ...
	 Train_Loss: 0.2260 Train_Acc: 91.620 Val_Loss: 0.2195  BEST VAL Loss: 0.2195  Val_Acc: 91.986

Epoch 51: Validation loss decreased (0.219515 --> 0.219388).  Saving model ...
	 Train_Loss: 0.2255 Train_Acc: 91.564 Val_Loss: 0.2194  BEST VAL Loss: 0.2194  Val_Acc: 92.063

Epoch 52: Validation loss decreased (0.219388 --> 0.219230).  Saving model ...
	 Train_Loss: 0.2250 Train_Acc: 91.657 Val_Loss: 0.2192  BEST VAL Loss: 0.2192  Val_Acc: 91.943

Epoch 53: Validation loss decreased (0.219230 --> 0.219140).  Saving model ...
	 Train_Loss: 0.2245 Train_Acc: 91.585 Val_Loss: 0.2191  BEST VAL Loss: 0.2191  Val_Acc: 91.856

Epoch 54: Validation loss decreased (0.219140 --> 0.218975).  Saving model ...
	 Train_Loss: 0.2240 Train_Acc: 91.585 Val_Loss: 0.2190  BEST VAL Loss: 0.2190  Val_Acc: 91.938

Epoch 55: Validation loss decreased (0.218975 --> 0.218729).  Saving model ...
	 Train_Loss: 0.2236 Train_Acc: 91.644 Val_Loss: 0.2187  BEST VAL Loss: 0.2187  Val_Acc: 92.046

Epoch 56: Validation loss decreased (0.218729 --> 0.218557).  Saving model ...
	 Train_Loss: 0.2231 Train_Acc: 91.558 Val_Loss: 0.2186  BEST VAL Loss: 0.2186  Val_Acc: 92.033

Epoch 57: Validation loss decreased (0.218557 --> 0.218444).  Saving model ...
	 Train_Loss: 0.2227 Train_Acc: 91.625 Val_Loss: 0.2184  BEST VAL Loss: 0.2184  Val_Acc: 91.999

Epoch 58: Validation loss decreased (0.218444 --> 0.218352).  Saving model ...
	 Train_Loss: 0.2222 Train_Acc: 91.834 Val_Loss: 0.2184  BEST VAL Loss: 0.2184  Val_Acc: 92.016

Epoch 59: Validation loss decreased (0.218352 --> 0.218248).  Saving model ...
	 Train_Loss: 0.2218 Train_Acc: 91.672 Val_Loss: 0.2182  BEST VAL Loss: 0.2182  Val_Acc: 91.822

Epoch 60: Validation loss decreased (0.218248 --> 0.218151).  Saving model ...
	 Train_Loss: 0.2213 Train_Acc: 91.701 Val_Loss: 0.2182  BEST VAL Loss: 0.2182  Val_Acc: 91.835

Epoch 61: Validation loss decreased (0.218151 --> 0.218107).  Saving model ...
	 Train_Loss: 0.2209 Train_Acc: 91.774 Val_Loss: 0.2181  BEST VAL Loss: 0.2181  Val_Acc: 91.930

Epoch 62: Validation loss decreased (0.218107 --> 0.217974).  Saving model ...
	 Train_Loss: 0.2205 Train_Acc: 91.686 Val_Loss: 0.2180  BEST VAL Loss: 0.2180  Val_Acc: 91.804

Epoch 63: Validation loss decreased (0.217974 --> 0.217847).  Saving model ...
	 Train_Loss: 0.2201 Train_Acc: 91.717 Val_Loss: 0.2178  BEST VAL Loss: 0.2178  Val_Acc: 91.994

Epoch 64: Validation loss decreased (0.217847 --> 0.217650).  Saving model ...
	 Train_Loss: 0.2197 Train_Acc: 91.722 Val_Loss: 0.2177  BEST VAL Loss: 0.2177  Val_Acc: 92.007

Epoch 65: Validation loss decreased (0.217650 --> 0.217489).  Saving model ...
	 Train_Loss: 0.2193 Train_Acc: 91.818 Val_Loss: 0.2175  BEST VAL Loss: 0.2175  Val_Acc: 92.007

Epoch 66: Validation loss decreased (0.217489 --> 0.217374).  Saving model ...
	 Train_Loss: 0.2189 Train_Acc: 91.811 Val_Loss: 0.2174  BEST VAL Loss: 0.2174  Val_Acc: 92.063

Epoch 67: Validation loss decreased (0.217374 --> 0.217187).  Saving model ...
	 Train_Loss: 0.2185 Train_Acc: 91.893 Val_Loss: 0.2172  BEST VAL Loss: 0.2172  Val_Acc: 91.861

Epoch 68: Validation loss decreased (0.217187 --> 0.216994).  Saving model ...
	 Train_Loss: 0.2182 Train_Acc: 91.829 Val_Loss: 0.2170  BEST VAL Loss: 0.2170  Val_Acc: 91.968

Epoch 69: Validation loss decreased (0.216994 --> 0.216846).  Saving model ...
	 Train_Loss: 0.2178 Train_Acc: 91.839 Val_Loss: 0.2168  BEST VAL Loss: 0.2168  Val_Acc: 91.848

Epoch 70: Validation loss decreased (0.216846 --> 0.216707).  Saving model ...
	 Train_Loss: 0.2174 Train_Acc: 91.797 Val_Loss: 0.2167  BEST VAL Loss: 0.2167  Val_Acc: 91.731

Epoch 71: Validation loss decreased (0.216707 --> 0.216529).  Saving model ...
	 Train_Loss: 0.2171 Train_Acc: 91.835 Val_Loss: 0.2165  BEST VAL Loss: 0.2165  Val_Acc: 92.025

Epoch 72: Validation loss decreased (0.216529 --> 0.216360).  Saving model ...
	 Train_Loss: 0.2167 Train_Acc: 91.885 Val_Loss: 0.2164  BEST VAL Loss: 0.2164  Val_Acc: 92.107

Epoch 73: Validation loss decreased (0.216360 --> 0.216185).  Saving model ...
	 Train_Loss: 0.2164 Train_Acc: 91.870 Val_Loss: 0.2162  BEST VAL Loss: 0.2162  Val_Acc: 92.016

Epoch 74: Validation loss decreased (0.216185 --> 0.216032).  Saving model ...
	 Train_Loss: 0.2161 Train_Acc: 91.977 Val_Loss: 0.2160  BEST VAL Loss: 0.2160  Val_Acc: 91.943

Epoch 75: Validation loss decreased (0.216032 --> 0.215873).  Saving model ...
	 Train_Loss: 0.2157 Train_Acc: 91.851 Val_Loss: 0.2159  BEST VAL Loss: 0.2159  Val_Acc: 91.809

Epoch 76: Validation loss decreased (0.215873 --> 0.215754).  Saving model ...
	 Train_Loss: 0.2154 Train_Acc: 91.985 Val_Loss: 0.2158  BEST VAL Loss: 0.2158  Val_Acc: 92.046

Epoch 77: Validation loss decreased (0.215754 --> 0.215604).  Saving model ...
	 Train_Loss: 0.2151 Train_Acc: 91.905 Val_Loss: 0.2156  BEST VAL Loss: 0.2156  Val_Acc: 92.020

Epoch 78: Validation loss decreased (0.215604 --> 0.215401).  Saving model ...
	 Train_Loss: 0.2148 Train_Acc: 91.975 Val_Loss: 0.2154  BEST VAL Loss: 0.2154  Val_Acc: 92.012

Epoch 79: Validation loss decreased (0.215401 --> 0.215240).  Saving model ...
	 Train_Loss: 0.2145 Train_Acc: 91.983 Val_Loss: 0.2152  BEST VAL Loss: 0.2152  Val_Acc: 92.003

Epoch 80: Validation loss decreased (0.215240 --> 0.215147).  Saving model ...
	 Train_Loss: 0.2142 Train_Acc: 91.940 Val_Loss: 0.2151  BEST VAL Loss: 0.2151  Val_Acc: 91.804

Epoch 81: Validation loss decreased (0.215147 --> 0.215007).  Saving model ...
	 Train_Loss: 0.2139 Train_Acc: 91.973 Val_Loss: 0.2150  BEST VAL Loss: 0.2150  Val_Acc: 92.098

Epoch 82: Validation loss decreased (0.215007 --> 0.214876).  Saving model ...
	 Train_Loss: 0.2136 Train_Acc: 92.001 Val_Loss: 0.2149  BEST VAL Loss: 0.2149  Val_Acc: 92.076

Epoch 83: Validation loss decreased (0.214876 --> 0.214796).  Saving model ...
	 Train_Loss: 0.2133 Train_Acc: 91.975 Val_Loss: 0.2148  BEST VAL Loss: 0.2148  Val_Acc: 91.955

Epoch 84: Validation loss decreased (0.214796 --> 0.214682).  Saving model ...
	 Train_Loss: 0.2130 Train_Acc: 91.970 Val_Loss: 0.2147  BEST VAL Loss: 0.2147  Val_Acc: 92.025

Epoch 85: Validation loss decreased (0.214682 --> 0.214560).  Saving model ...
	 Train_Loss: 0.2127 Train_Acc: 91.943 Val_Loss: 0.2146  BEST VAL Loss: 0.2146  Val_Acc: 92.102

Epoch 86: Validation loss decreased (0.214560 --> 0.214423).  Saving model ...
	 Train_Loss: 0.2124 Train_Acc: 92.029 Val_Loss: 0.2144  BEST VAL Loss: 0.2144  Val_Acc: 92.107

Epoch 87: Validation loss decreased (0.214423 --> 0.214315).  Saving model ...
	 Train_Loss: 0.2122 Train_Acc: 92.021 Val_Loss: 0.2143  BEST VAL Loss: 0.2143  Val_Acc: 92.124

Epoch 88: Validation loss decreased (0.214315 --> 0.214212).  Saving model ...
	 Train_Loss: 0.2119 Train_Acc: 92.086 Val_Loss: 0.2142  BEST VAL Loss: 0.2142  Val_Acc: 92.115

Epoch 89: Validation loss decreased (0.214212 --> 0.214135).  Saving model ...
	 Train_Loss: 0.2116 Train_Acc: 92.062 Val_Loss: 0.2141  BEST VAL Loss: 0.2141  Val_Acc: 91.986

Epoch 90: Validation loss decreased (0.214135 --> 0.214029).  Saving model ...
	 Train_Loss: 0.2113 Train_Acc: 92.091 Val_Loss: 0.2140  BEST VAL Loss: 0.2140  Val_Acc: 91.981

Epoch 91: Validation loss decreased (0.214029 --> 0.213961).  Saving model ...
	 Train_Loss: 0.2111 Train_Acc: 92.105 Val_Loss: 0.2140  BEST VAL Loss: 0.2140  Val_Acc: 92.085

Epoch 92: Validation loss decreased (0.213961 --> 0.213877).  Saving model ...
	 Train_Loss: 0.2108 Train_Acc: 92.010 Val_Loss: 0.2139  BEST VAL Loss: 0.2139  Val_Acc: 92.020

Epoch 93: Validation loss decreased (0.213877 --> 0.213822).  Saving model ...
	 Train_Loss: 0.2106 Train_Acc: 92.027 Val_Loss: 0.2138  BEST VAL Loss: 0.2138  Val_Acc: 91.925

Epoch 94: Validation loss decreased (0.213822 --> 0.213776).  Saving model ...
	 Train_Loss: 0.2103 Train_Acc: 92.130 Val_Loss: 0.2138  BEST VAL Loss: 0.2138  Val_Acc: 91.938

Epoch 95: Validation loss decreased (0.213776 --> 0.213708).  Saving model ...
	 Train_Loss: 0.2101 Train_Acc: 92.042 Val_Loss: 0.2137  BEST VAL Loss: 0.2137  Val_Acc: 92.158

Epoch 96: Validation loss decreased (0.213708 --> 0.213641).  Saving model ...
	 Train_Loss: 0.2099 Train_Acc: 92.038 Val_Loss: 0.2136  BEST VAL Loss: 0.2136  Val_Acc: 91.917

Epoch 97: Validation loss decreased (0.213641 --> 0.213575).  Saving model ...
	 Train_Loss: 0.2096 Train_Acc: 92.038 Val_Loss: 0.2136  BEST VAL Loss: 0.2136  Val_Acc: 92.081

Epoch 98: Validation loss decreased (0.213575 --> 0.213509).  Saving model ...
	 Train_Loss: 0.2094 Train_Acc: 92.068 Val_Loss: 0.2135  BEST VAL Loss: 0.2135  Val_Acc: 92.003

Epoch 99: Validation loss decreased (0.213509 --> 0.213431).  Saving model ...
	 Train_Loss: 0.2092 Train_Acc: 92.089 Val_Loss: 0.2134  BEST VAL Loss: 0.2134  Val_Acc: 91.934

LPS_0.010_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.94      0.93      0.93     85027
           1       0.94      0.95      0.94    100339

    accuracy                           0.94    185366
   macro avg       0.94      0.94      0.94    185366
weighted avg       0.94      0.94      0.94    185366

LPS_0.010_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.92      0.90      0.91     10628
           1       0.92      0.93      0.93     12543

    accuracy                           0.92     23171
   macro avg       0.92      0.92      0.92     23171
weighted avg       0.92      0.92      0.92     23171

LPS_0.010_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.92      0.90      0.91     10628
           1       0.92      0.93      0.93     12543

    accuracy                           0.92     23171
   macro avg       0.92      0.92      0.92     23171
weighted avg       0.92      0.92      0.92     23171

              precision    recall  f1-score   support

           0       0.92      0.90      0.91     10628
           1       0.92      0.93      0.93     12543

    accuracy                           0.92     23171
   macro avg       0.92      0.92      0.92     23171
weighted avg       0.92      0.92      0.92     23171

LPS_0.010_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.94      0.97      0.95     36797
           1       0.97      0.94      0.95     40588

    accuracy                           0.95     77385
   macro avg       0.95      0.95      0.95     77385
weighted avg       0.95      0.95      0.95     77385

              precision    recall  f1-score   support

           0       0.94      0.97      0.95     36797
           1       0.97      0.94      0.95     40588

    accuracy                           0.95     77385
   macro avg       0.95      0.95      0.95     77385
weighted avg       0.95      0.95      0.95     77385

completed
