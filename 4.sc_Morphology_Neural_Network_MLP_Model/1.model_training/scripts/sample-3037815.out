[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '01b9856d'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '36e29559'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '2755e9fe'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '2d38e00b'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_Nigericin_1.000_3.0_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (28580, 1276)
Number of total missing values across all columns: 29856
Data Subset Is Off
Wells held out for testing: ['L16' 'L22']
Wells to use for training, validation, and testing ['L17' 'L18' 'L19' 'L20' 'L21' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.216694).  Saving model ...
	 Train_Loss: 0.4432 Train_Acc: 80.093 Val_Loss: 0.2167  BEST VAL Loss: 0.2167  Val_Acc: 92.181

Epoch 1: Validation loss decreased (0.216694 --> 0.200360).  Saving model ...
	 Train_Loss: 0.3612 Train_Acc: 89.947 Val_Loss: 0.2004  BEST VAL Loss: 0.2004  Val_Acc: 92.326

Epoch 2: Validation loss decreased (0.200360 --> 0.192295).  Saving model ...
	 Train_Loss: 0.3222 Train_Acc: 91.401 Val_Loss: 0.1923  BEST VAL Loss: 0.1923  Val_Acc: 93.292

Epoch 3: Validation loss did not decrease
	 Train_Loss: 0.2972 Train_Acc: 92.403 Val_Loss: 0.1934  BEST VAL Loss: 0.1923  Val_Acc: 93.629

Epoch 4: Validation loss decreased (0.192295 --> 0.183643).  Saving model ...
	 Train_Loss: 0.2789 Train_Acc: 93.049 Val_Loss: 0.1836  BEST VAL Loss: 0.1836  Val_Acc: 94.208

Epoch 5: Validation loss decreased (0.183643 --> 0.177864).  Saving model ...
	 Train_Loss: 0.2669 Train_Acc: 92.578 Val_Loss: 0.1779  BEST VAL Loss: 0.1779  Val_Acc: 93.533

Epoch 6: Validation loss decreased (0.177864 --> 0.171054).  Saving model ...
	 Train_Loss: 0.2557 Train_Acc: 93.658 Val_Loss: 0.1711  BEST VAL Loss: 0.1711  Val_Acc: 94.160

Epoch 7: Validation loss did not decrease
	 Train_Loss: 0.2455 Train_Acc: 94.376 Val_Loss: 0.1832  BEST VAL Loss: 0.1711  Val_Acc: 93.967

Epoch 8: Validation loss did not decrease
	 Train_Loss: 0.2388 Train_Acc: 93.700 Val_Loss: 0.1810  BEST VAL Loss: 0.1711  Val_Acc: 95.029

Epoch 9: Validation loss did not decrease
	 Train_Loss: 0.2327 Train_Acc: 94.105 Val_Loss: 0.1803  BEST VAL Loss: 0.1711  Val_Acc: 94.981

Epoch 10: Validation loss did not decrease
	 Train_Loss: 0.2282 Train_Acc: 94.008 Val_Loss: 0.1787  BEST VAL Loss: 0.1711  Val_Acc: 94.015

Epoch 11: Validation loss did not decrease
	 Train_Loss: 0.2250 Train_Acc: 93.755 Val_Loss: 0.1790  BEST VAL Loss: 0.1711  Val_Acc: 94.450

Epoch 12: Validation loss did not decrease
	 Train_Loss: 0.2215 Train_Acc: 93.881 Val_Loss: 0.1797  BEST VAL Loss: 0.1711  Val_Acc: 94.595

Epoch 13: Validation loss did not decrease
	 Train_Loss: 0.2181 Train_Acc: 94.533 Val_Loss: 0.1798  BEST VAL Loss: 0.1711  Val_Acc: 94.498

Epoch 14: Validation loss did not decrease
	 Train_Loss: 0.2147 Train_Acc: 94.461 Val_Loss: 0.1788  BEST VAL Loss: 0.1711  Val_Acc: 94.643

Epoch 15: Validation loss did not decrease
	 Train_Loss: 0.2113 Train_Acc: 94.871 Val_Loss: 0.1765  BEST VAL Loss: 0.1711  Val_Acc: 94.450

Epoch 16: Validation loss did not decrease
	 Train_Loss: 0.2079 Train_Acc: 95.106 Val_Loss: 0.1742  BEST VAL Loss: 0.1711  Val_Acc: 95.029

Epoch 17: Validation loss did not decrease
	 Train_Loss: 0.2046 Train_Acc: 95.124 Val_Loss: 0.1723  BEST VAL Loss: 0.1711  Val_Acc: 94.595

Epoch 18: Validation loss did not decrease
	 Train_Loss: 0.2022 Train_Acc: 94.871 Val_Loss: 0.1747  BEST VAL Loss: 0.1711  Val_Acc: 94.739

Epoch 19: Validation loss did not decrease
	 Train_Loss: 0.1999 Train_Acc: 95.070 Val_Loss: 0.1759  BEST VAL Loss: 0.1711  Val_Acc: 94.208

Epoch 20: Validation loss did not decrease
	 Train_Loss: 0.1979 Train_Acc: 94.979 Val_Loss: 0.1738  BEST VAL Loss: 0.1711  Val_Acc: 94.595

Epoch 21: Validation loss did not decrease
	 Train_Loss: 0.1956 Train_Acc: 95.348 Val_Loss: 0.1729  BEST VAL Loss: 0.1711  Val_Acc: 95.174

Epoch 22: Validation loss did not decrease
Early stopped at epoch : 22
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.52      0.52      8634
           1       0.49      0.50      0.49      7938

    accuracy                           0.51     16572
   macro avg       0.51      0.51      0.51     16572
weighted avg       0.51      0.51      0.51     16572

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.51      0.52      1080
           1       0.48      0.50      0.49       992

    accuracy                           0.51      2072
   macro avg       0.51      0.51      0.50      2072
weighted avg       0.51      0.51      0.51      2072

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.50      0.51      1079
           1       0.48      0.50      0.49       993

    accuracy                           0.50      2072
   macro avg       0.50      0.50      0.50      2072
weighted avg       0.50      0.50      0.50      2072

              precision    recall  f1-score   support

           0       0.52      0.50      0.51      1079
           1       0.48      0.50      0.49       993

    accuracy                           0.50      2072
   macro avg       0.50      0.50      0.50      2072
weighted avg       0.50      0.50      0.50      2072

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.49      0.50      4135
           1       0.46      0.49      0.47      3729

    accuracy                           0.49      7864
   macro avg       0.49      0.49      0.49      7864
weighted avg       0.49      0.49      0.49      7864

              precision    recall  f1-score   support

           0       0.51      0.49      0.50      4135
           1       0.46      0.49      0.47      3729

    accuracy                           0.49      7864
   macro avg       0.49      0.49      0.49      7864
weighted avg       0.49      0.49      0.49      7864

completed
