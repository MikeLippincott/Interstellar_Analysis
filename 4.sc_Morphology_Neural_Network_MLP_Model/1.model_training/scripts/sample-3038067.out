[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ad413c88'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '75d4fef5'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '6661b2c1'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '62725f27'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_0.100_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_0.100_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (312858, 1270)
Number of total missing values across all columns: 277194
Data Subset Is Off
Wells held out for testing: ['C09' 'L09']
Wells to use for training, validation, and testing ['C02' 'C03' 'C08' 'L02' 'L03' 'L08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.386367).  Saving model ...
	 Train_Loss: 0.5509 Train_Acc: 69.389 Val_Loss: 0.3864  BEST VAL Loss: 0.3864  Val_Acc: 87.305

Epoch 1: Validation loss decreased (0.386367 --> 0.332510).  Saving model ...
	 Train_Loss: 0.4634 Train_Acc: 85.368 Val_Loss: 0.3325  BEST VAL Loss: 0.3325  Val_Acc: 90.542

Epoch 2: Validation loss decreased (0.332510 --> 0.299282).  Saving model ...
	 Train_Loss: 0.4134 Train_Acc: 87.789 Val_Loss: 0.2993  BEST VAL Loss: 0.2993  Val_Acc: 91.623

Epoch 3: Validation loss decreased (0.299282 --> 0.275885).  Saving model ...
	 Train_Loss: 0.3796 Train_Acc: 89.052 Val_Loss: 0.2759  BEST VAL Loss: 0.2759  Val_Acc: 92.053

Epoch 4: Validation loss decreased (0.275885 --> 0.259660).  Saving model ...
	 Train_Loss: 0.3551 Train_Acc: 90.254 Val_Loss: 0.2597  BEST VAL Loss: 0.2597  Val_Acc: 92.598

Epoch 5: Validation loss decreased (0.259660 --> 0.247492).  Saving model ...
	 Train_Loss: 0.3365 Train_Acc: 91.005 Val_Loss: 0.2475  BEST VAL Loss: 0.2475  Val_Acc: 92.927

Epoch 6: Validation loss decreased (0.247492 --> 0.237914).  Saving model ...
	 Train_Loss: 0.3213 Train_Acc: 91.544 Val_Loss: 0.2379  BEST VAL Loss: 0.2379  Val_Acc: 92.986

Epoch 7: Validation loss decreased (0.237914 --> 0.230277).  Saving model ...
	 Train_Loss: 0.3090 Train_Acc: 91.826 Val_Loss: 0.2303  BEST VAL Loss: 0.2303  Val_Acc: 93.184

Epoch 8: Validation loss decreased (0.230277 --> 0.223825).  Saving model ...
	 Train_Loss: 0.2986 Train_Acc: 92.156 Val_Loss: 0.2238  BEST VAL Loss: 0.2238  Val_Acc: 93.399

Epoch 9: Validation loss decreased (0.223825 --> 0.218542).  Saving model ...
	 Train_Loss: 0.2895 Train_Acc: 92.475 Val_Loss: 0.2185  BEST VAL Loss: 0.2185  Val_Acc: 93.526

Epoch 10: Validation loss decreased (0.218542 --> 0.213561).  Saving model ...
	 Train_Loss: 0.2816 Train_Acc: 92.634 Val_Loss: 0.2136  BEST VAL Loss: 0.2136  Val_Acc: 93.897

Epoch 11: Validation loss decreased (0.213561 --> 0.209288).  Saving model ...
	 Train_Loss: 0.2746 Train_Acc: 92.888 Val_Loss: 0.2093  BEST VAL Loss: 0.2093  Val_Acc: 93.902

Epoch 12: Validation loss decreased (0.209288 --> 0.205078).  Saving model ...
	 Train_Loss: 0.2682 Train_Acc: 93.048 Val_Loss: 0.2051  BEST VAL Loss: 0.2051  Val_Acc: 94.210

Epoch 13: Validation loss decreased (0.205078 --> 0.201336).  Saving model ...
	 Train_Loss: 0.2625 Train_Acc: 93.183 Val_Loss: 0.2013  BEST VAL Loss: 0.2013  Val_Acc: 94.345

Epoch 14: Validation loss decreased (0.201336 --> 0.198101).  Saving model ...
	 Train_Loss: 0.2574 Train_Acc: 93.366 Val_Loss: 0.1981  BEST VAL Loss: 0.1981  Val_Acc: 94.315

Epoch 15: Validation loss decreased (0.198101 --> 0.195112).  Saving model ...
	 Train_Loss: 0.2526 Train_Acc: 93.511 Val_Loss: 0.1951  BEST VAL Loss: 0.1951  Val_Acc: 94.387

Epoch 16: Validation loss decreased (0.195112 --> 0.192593).  Saving model ...
	 Train_Loss: 0.2483 Train_Acc: 93.620 Val_Loss: 0.1926  BEST VAL Loss: 0.1926  Val_Acc: 94.197

Epoch 17: Validation loss decreased (0.192593 --> 0.189999).  Saving model ...
	 Train_Loss: 0.2442 Train_Acc: 93.724 Val_Loss: 0.1900  BEST VAL Loss: 0.1900  Val_Acc: 94.514

Epoch 18: Validation loss decreased (0.189999 --> 0.187567).  Saving model ...
	 Train_Loss: 0.2404 Train_Acc: 93.841 Val_Loss: 0.1876  BEST VAL Loss: 0.1876  Val_Acc: 94.547

Epoch 19: Validation loss decreased (0.187567 --> 0.185405).  Saving model ...
	 Train_Loss: 0.2369 Train_Acc: 93.950 Val_Loss: 0.1854  BEST VAL Loss: 0.1854  Val_Acc: 94.581

Epoch 20: Validation loss decreased (0.185405 --> 0.183425).  Saving model ...
	 Train_Loss: 0.2337 Train_Acc: 93.973 Val_Loss: 0.1834  BEST VAL Loss: 0.1834  Val_Acc: 94.514

Epoch 21: Validation loss decreased (0.183425 --> 0.181564).  Saving model ...
	 Train_Loss: 0.2307 Train_Acc: 94.093 Val_Loss: 0.1816  BEST VAL Loss: 0.1816  Val_Acc: 94.619

Epoch 22: Validation loss decreased (0.181564 --> 0.179795).  Saving model ...
	 Train_Loss: 0.2278 Train_Acc: 94.105 Val_Loss: 0.1798  BEST VAL Loss: 0.1798  Val_Acc: 94.623

Epoch 23: Validation loss decreased (0.179795 --> 0.178063).  Saving model ...
	 Train_Loss: 0.2252 Train_Acc: 94.184 Val_Loss: 0.1781  BEST VAL Loss: 0.1781  Val_Acc: 94.716

Epoch 24: Validation loss decreased (0.178063 --> 0.176477).  Saving model ...
	 Train_Loss: 0.2226 Train_Acc: 94.215 Val_Loss: 0.1765  BEST VAL Loss: 0.1765  Val_Acc: 94.733

Epoch 25: Validation loss decreased (0.176477 --> 0.174949).  Saving model ...
	 Train_Loss: 0.2203 Train_Acc: 94.270 Val_Loss: 0.1749  BEST VAL Loss: 0.1749  Val_Acc: 94.813

Epoch 26: Validation loss decreased (0.174949 --> 0.173633).  Saving model ...
	 Train_Loss: 0.2180 Train_Acc: 94.349 Val_Loss: 0.1736  BEST VAL Loss: 0.1736  Val_Acc: 94.767

Epoch 27: Validation loss decreased (0.173633 --> 0.172448).  Saving model ...
	 Train_Loss: 0.2159 Train_Acc: 94.343 Val_Loss: 0.1724  BEST VAL Loss: 0.1724  Val_Acc: 94.729

Epoch 28: Validation loss decreased (0.172448 --> 0.171172).  Saving model ...
	 Train_Loss: 0.2139 Train_Acc: 94.387 Val_Loss: 0.1712  BEST VAL Loss: 0.1712  Val_Acc: 94.801

Epoch 29: Validation loss decreased (0.171172 --> 0.170168).  Saving model ...
	 Train_Loss: 0.2120 Train_Acc: 94.437 Val_Loss: 0.1702  BEST VAL Loss: 0.1702  Val_Acc: 94.632

Epoch 30: Validation loss decreased (0.170168 --> 0.169061).  Saving model ...
	 Train_Loss: 0.2101 Train_Acc: 94.455 Val_Loss: 0.1691  BEST VAL Loss: 0.1691  Val_Acc: 94.910

Epoch 31: Validation loss decreased (0.169061 --> 0.168070).  Saving model ...
	 Train_Loss: 0.2084 Train_Acc: 94.500 Val_Loss: 0.1681  BEST VAL Loss: 0.1681  Val_Acc: 94.763

Epoch 32: Validation loss decreased (0.168070 --> 0.167052).  Saving model ...
	 Train_Loss: 0.2067 Train_Acc: 94.611 Val_Loss: 0.1671  BEST VAL Loss: 0.1671  Val_Acc: 94.864

Epoch 33: Validation loss decreased (0.167052 --> 0.166112).  Saving model ...
	 Train_Loss: 0.2051 Train_Acc: 94.607 Val_Loss: 0.1661  BEST VAL Loss: 0.1661  Val_Acc: 94.855

Epoch 34: Validation loss decreased (0.166112 --> 0.165153).  Saving model ...
	 Train_Loss: 0.2036 Train_Acc: 94.574 Val_Loss: 0.1652  BEST VAL Loss: 0.1652  Val_Acc: 94.936

Epoch 35: Validation loss decreased (0.165153 --> 0.164216).  Saving model ...
	 Train_Loss: 0.2021 Train_Acc: 94.630 Val_Loss: 0.1642  BEST VAL Loss: 0.1642  Val_Acc: 94.872

Epoch 36: Validation loss decreased (0.164216 --> 0.163342).  Saving model ...
	 Train_Loss: 0.2007 Train_Acc: 94.714 Val_Loss: 0.1633  BEST VAL Loss: 0.1633  Val_Acc: 94.995

Epoch 37: Validation loss decreased (0.163342 --> 0.162527).  Saving model ...
	 Train_Loss: 0.1993 Train_Acc: 94.767 Val_Loss: 0.1625  BEST VAL Loss: 0.1625  Val_Acc: 95.016

Epoch 38: Validation loss decreased (0.162527 --> 0.161780).  Saving model ...
	 Train_Loss: 0.1981 Train_Acc: 94.663 Val_Loss: 0.1618  BEST VAL Loss: 0.1618  Val_Acc: 94.944

Epoch 39: Validation loss decreased (0.161780 --> 0.161078).  Saving model ...
	 Train_Loss: 0.1968 Train_Acc: 94.694 Val_Loss: 0.1611  BEST VAL Loss: 0.1611  Val_Acc: 94.974

Epoch 40: Validation loss decreased (0.161078 --> 0.160357).  Saving model ...
	 Train_Loss: 0.1956 Train_Acc: 94.713 Val_Loss: 0.1604  BEST VAL Loss: 0.1604  Val_Acc: 94.978

Epoch 41: Validation loss decreased (0.160357 --> 0.159642).  Saving model ...
	 Train_Loss: 0.1945 Train_Acc: 94.662 Val_Loss: 0.1596  BEST VAL Loss: 0.1596  Val_Acc: 95.033

Epoch 42: Validation loss decreased (0.159642 --> 0.158986).  Saving model ...
	 Train_Loss: 0.1933 Train_Acc: 94.828 Val_Loss: 0.1590  BEST VAL Loss: 0.1590  Val_Acc: 95.066

Epoch 43: Validation loss decreased (0.158986 --> 0.158386).  Saving model ...
	 Train_Loss: 0.1923 Train_Acc: 94.782 Val_Loss: 0.1584  BEST VAL Loss: 0.1584  Val_Acc: 94.940

Epoch 44: Validation loss decreased (0.158386 --> 0.157806).  Saving model ...
	 Train_Loss: 0.1913 Train_Acc: 94.788 Val_Loss: 0.1578  BEST VAL Loss: 0.1578  Val_Acc: 95.050

Epoch 45: Validation loss decreased (0.157806 --> 0.157273).  Saving model ...
	 Train_Loss: 0.1903 Train_Acc: 94.842 Val_Loss: 0.1573  BEST VAL Loss: 0.1573  Val_Acc: 94.910

Epoch 46: Validation loss decreased (0.157273 --> 0.156704).  Saving model ...
	 Train_Loss: 0.1893 Train_Acc: 94.795 Val_Loss: 0.1567  BEST VAL Loss: 0.1567  Val_Acc: 95.037

Epoch 47: Validation loss decreased (0.156704 --> 0.156158).  Saving model ...
	 Train_Loss: 0.1884 Train_Acc: 94.872 Val_Loss: 0.1562  BEST VAL Loss: 0.1562  Val_Acc: 95.079

Epoch 48: Validation loss decreased (0.156158 --> 0.155615).  Saving model ...
	 Train_Loss: 0.1875 Train_Acc: 94.862 Val_Loss: 0.1556  BEST VAL Loss: 0.1556  Val_Acc: 94.957

Epoch 49: Validation loss decreased (0.155615 --> 0.155067).  Saving model ...
	 Train_Loss: 0.1866 Train_Acc: 94.859 Val_Loss: 0.1551  BEST VAL Loss: 0.1551  Val_Acc: 95.092

Epoch 50: Validation loss decreased (0.155067 --> 0.154587).  Saving model ...
	 Train_Loss: 0.1857 Train_Acc: 94.829 Val_Loss: 0.1546  BEST VAL Loss: 0.1546  Val_Acc: 95.113

Epoch 51: Validation loss decreased (0.154587 --> 0.154130).  Saving model ...
	 Train_Loss: 0.1849 Train_Acc: 94.843 Val_Loss: 0.1541  BEST VAL Loss: 0.1541  Val_Acc: 95.028

Epoch 52: Validation loss decreased (0.154130 --> 0.153694).  Saving model ...
	 Train_Loss: 0.1841 Train_Acc: 94.863 Val_Loss: 0.1537  BEST VAL Loss: 0.1537  Val_Acc: 95.007

Epoch 53: Validation loss decreased (0.153694 --> 0.153231).  Saving model ...
	 Train_Loss: 0.1833 Train_Acc: 94.967 Val_Loss: 0.1532  BEST VAL Loss: 0.1532  Val_Acc: 95.134

Epoch 54: Validation loss decreased (0.153231 --> 0.152806).  Saving model ...
	 Train_Loss: 0.1826 Train_Acc: 94.905 Val_Loss: 0.1528  BEST VAL Loss: 0.1528  Val_Acc: 95.134

Epoch 55: Validation loss decreased (0.152806 --> 0.152407).  Saving model ...
	 Train_Loss: 0.1819 Train_Acc: 94.922 Val_Loss: 0.1524  BEST VAL Loss: 0.1524  Val_Acc: 95.126

Epoch 56: Validation loss decreased (0.152407 --> 0.151961).  Saving model ...
	 Train_Loss: 0.1811 Train_Acc: 94.941 Val_Loss: 0.1520  BEST VAL Loss: 0.1520  Val_Acc: 95.121

Epoch 57: Validation loss decreased (0.151961 --> 0.151548).  Saving model ...
	 Train_Loss: 0.1805 Train_Acc: 94.913 Val_Loss: 0.1515  BEST VAL Loss: 0.1515  Val_Acc: 95.088

Epoch 58: Validation loss decreased (0.151548 --> 0.151124).  Saving model ...
	 Train_Loss: 0.1798 Train_Acc: 94.955 Val_Loss: 0.1511  BEST VAL Loss: 0.1511  Val_Acc: 95.130

Epoch 59: Validation loss decreased (0.151124 --> 0.150727).  Saving model ...
	 Train_Loss: 0.1791 Train_Acc: 94.960 Val_Loss: 0.1507  BEST VAL Loss: 0.1507  Val_Acc: 95.138

Epoch 60: Validation loss decreased (0.150727 --> 0.150348).  Saving model ...
	 Train_Loss: 0.1785 Train_Acc: 95.040 Val_Loss: 0.1503  BEST VAL Loss: 0.1503  Val_Acc: 95.206

Epoch 61: Validation loss decreased (0.150348 --> 0.149983).  Saving model ...
	 Train_Loss: 0.1779 Train_Acc: 94.968 Val_Loss: 0.1500  BEST VAL Loss: 0.1500  Val_Acc: 95.185

Epoch 62: Validation loss decreased (0.149983 --> 0.149704).  Saving model ...
	 Train_Loss: 0.1772 Train_Acc: 95.066 Val_Loss: 0.1497  BEST VAL Loss: 0.1497  Val_Acc: 95.096

Epoch 63: Validation loss decreased (0.149704 --> 0.149354).  Saving model ...
	 Train_Loss: 0.1766 Train_Acc: 95.040 Val_Loss: 0.1494  BEST VAL Loss: 0.1494  Val_Acc: 95.113

Epoch 64: Validation loss decreased (0.149354 --> 0.149051).  Saving model ...
	 Train_Loss: 0.1760 Train_Acc: 95.029 Val_Loss: 0.1491  BEST VAL Loss: 0.1491  Val_Acc: 95.172

Epoch 65: Validation loss decreased (0.149051 --> 0.148789).  Saving model ...
	 Train_Loss: 0.1754 Train_Acc: 95.077 Val_Loss: 0.1488  BEST VAL Loss: 0.1488  Val_Acc: 94.995

Epoch 66: Validation loss decreased (0.148789 --> 0.148493).  Saving model ...
	 Train_Loss: 0.1749 Train_Acc: 95.051 Val_Loss: 0.1485  BEST VAL Loss: 0.1485  Val_Acc: 95.037

Epoch 67: Validation loss decreased (0.148493 --> 0.148196).  Saving model ...
	 Train_Loss: 0.1743 Train_Acc: 95.130 Val_Loss: 0.1482  BEST VAL Loss: 0.1482  Val_Acc: 95.126

Epoch 68: Validation loss decreased (0.148196 --> 0.147929).  Saving model ...
	 Train_Loss: 0.1738 Train_Acc: 95.086 Val_Loss: 0.1479  BEST VAL Loss: 0.1479  Val_Acc: 95.096

Epoch 69: Validation loss decreased (0.147929 --> 0.147668).  Saving model ...
	 Train_Loss: 0.1732 Train_Acc: 95.051 Val_Loss: 0.1477  BEST VAL Loss: 0.1477  Val_Acc: 95.092

Epoch 70: Validation loss decreased (0.147668 --> 0.147426).  Saving model ...
	 Train_Loss: 0.1727 Train_Acc: 95.140 Val_Loss: 0.1474  BEST VAL Loss: 0.1474  Val_Acc: 95.041

Epoch 71: Validation loss decreased (0.147426 --> 0.147195).  Saving model ...
	 Train_Loss: 0.1722 Train_Acc: 95.050 Val_Loss: 0.1472  BEST VAL Loss: 0.1472  Val_Acc: 95.045

Epoch 72: Validation loss decreased (0.147195 --> 0.146976).  Saving model ...
	 Train_Loss: 0.1717 Train_Acc: 95.164 Val_Loss: 0.1470  BEST VAL Loss: 0.1470  Val_Acc: 95.109

Epoch 73: Validation loss decreased (0.146976 --> 0.146765).  Saving model ...
	 Train_Loss: 0.1712 Train_Acc: 95.167 Val_Loss: 0.1468  BEST VAL Loss: 0.1468  Val_Acc: 95.164

Epoch 74: Validation loss decreased (0.146765 --> 0.146517).  Saving model ...
	 Train_Loss: 0.1708 Train_Acc: 95.136 Val_Loss: 0.1465  BEST VAL Loss: 0.1465  Val_Acc: 95.142

Epoch 75: Validation loss decreased (0.146517 --> 0.146293).  Saving model ...
	 Train_Loss: 0.1703 Train_Acc: 95.159 Val_Loss: 0.1463  BEST VAL Loss: 0.1463  Val_Acc: 95.134

Epoch 76: Validation loss decreased (0.146293 --> 0.146061).  Saving model ...
	 Train_Loss: 0.1698 Train_Acc: 95.143 Val_Loss: 0.1461  BEST VAL Loss: 0.1461  Val_Acc: 95.164

Epoch 77: Validation loss decreased (0.146061 --> 0.145825).  Saving model ...
	 Train_Loss: 0.1694 Train_Acc: 95.219 Val_Loss: 0.1458  BEST VAL Loss: 0.1458  Val_Acc: 95.244

Epoch 78: Validation loss decreased (0.145825 --> 0.145606).  Saving model ...
	 Train_Loss: 0.1689 Train_Acc: 95.226 Val_Loss: 0.1456  BEST VAL Loss: 0.1456  Val_Acc: 95.109

Epoch 79: Validation loss decreased (0.145606 --> 0.145381).  Saving model ...
	 Train_Loss: 0.1685 Train_Acc: 95.225 Val_Loss: 0.1454  BEST VAL Loss: 0.1454  Val_Acc: 95.176

Epoch 80: Validation loss decreased (0.145381 --> 0.145149).  Saving model ...
	 Train_Loss: 0.1681 Train_Acc: 95.137 Val_Loss: 0.1451  BEST VAL Loss: 0.1451  Val_Acc: 95.328

Epoch 81: Validation loss decreased (0.145149 --> 0.144950).  Saving model ...
	 Train_Loss: 0.1677 Train_Acc: 95.274 Val_Loss: 0.1450  BEST VAL Loss: 0.1450  Val_Acc: 95.155

Epoch 82: Validation loss decreased (0.144950 --> 0.144757).  Saving model ...
	 Train_Loss: 0.1672 Train_Acc: 95.228 Val_Loss: 0.1448  BEST VAL Loss: 0.1448  Val_Acc: 95.075

Epoch 83: Validation loss decreased (0.144757 --> 0.144580).  Saving model ...
	 Train_Loss: 0.1668 Train_Acc: 95.219 Val_Loss: 0.1446  BEST VAL Loss: 0.1446  Val_Acc: 95.066

Epoch 84: Validation loss decreased (0.144580 --> 0.144372).  Saving model ...
	 Train_Loss: 0.1664 Train_Acc: 95.200 Val_Loss: 0.1444  BEST VAL Loss: 0.1444  Val_Acc: 95.223

Epoch 85: Validation loss decreased (0.144372 --> 0.144189).  Saving model ...
	 Train_Loss: 0.1661 Train_Acc: 95.241 Val_Loss: 0.1442  BEST VAL Loss: 0.1442  Val_Acc: 95.134

Epoch 86: Validation loss decreased (0.144189 --> 0.144026).  Saving model ...
	 Train_Loss: 0.1657 Train_Acc: 95.238 Val_Loss: 0.1440  BEST VAL Loss: 0.1440  Val_Acc: 95.020

Epoch 87: Validation loss decreased (0.144026 --> 0.143845).  Saving model ...
	 Train_Loss: 0.1653 Train_Acc: 95.179 Val_Loss: 0.1438  BEST VAL Loss: 0.1438  Val_Acc: 95.210

Epoch 88: Validation loss decreased (0.143845 --> 0.143668).  Saving model ...
	 Train_Loss: 0.1649 Train_Acc: 95.249 Val_Loss: 0.1437  BEST VAL Loss: 0.1437  Val_Acc: 95.109

Epoch 89: Validation loss decreased (0.143668 --> 0.143500).  Saving model ...
	 Train_Loss: 0.1646 Train_Acc: 95.316 Val_Loss: 0.1435  BEST VAL Loss: 0.1435  Val_Acc: 95.054

Epoch 90: Validation loss decreased (0.143500 --> 0.143351).  Saving model ...
	 Train_Loss: 0.1642 Train_Acc: 95.226 Val_Loss: 0.1434  BEST VAL Loss: 0.1434  Val_Acc: 95.007

Epoch 91: Validation loss decreased (0.143351 --> 0.143189).  Saving model ...
	 Train_Loss: 0.1639 Train_Acc: 95.281 Val_Loss: 0.1432  BEST VAL Loss: 0.1432  Val_Acc: 95.083

Epoch 92: Validation loss decreased (0.143189 --> 0.143018).  Saving model ...
	 Train_Loss: 0.1635 Train_Acc: 95.260 Val_Loss: 0.1430  BEST VAL Loss: 0.1430  Val_Acc: 95.096

Epoch 93: Validation loss decreased (0.143018 --> 0.142857).  Saving model ...
	 Train_Loss: 0.1632 Train_Acc: 95.277 Val_Loss: 0.1429  BEST VAL Loss: 0.1429  Val_Acc: 94.995

Epoch 94: Validation loss decreased (0.142857 --> 0.142699).  Saving model ...
	 Train_Loss: 0.1629 Train_Acc: 95.309 Val_Loss: 0.1427  BEST VAL Loss: 0.1427  Val_Acc: 95.016

Epoch 95: Validation loss decreased (0.142699 --> 0.142568).  Saving model ...
	 Train_Loss: 0.1626 Train_Acc: 95.207 Val_Loss: 0.1426  BEST VAL Loss: 0.1426  Val_Acc: 95.024

Epoch 96: Validation loss decreased (0.142568 --> 0.142462).  Saving model ...
	 Train_Loss: 0.1622 Train_Acc: 95.315 Val_Loss: 0.1425  BEST VAL Loss: 0.1425  Val_Acc: 95.054

Epoch 97: Validation loss decreased (0.142462 --> 0.142314).  Saving model ...
	 Train_Loss: 0.1619 Train_Acc: 95.231 Val_Loss: 0.1423  BEST VAL Loss: 0.1423  Val_Acc: 95.155

Epoch 98: Validation loss decreased (0.142314 --> 0.142209).  Saving model ...
	 Train_Loss: 0.1616 Train_Acc: 95.282 Val_Loss: 0.1422  BEST VAL Loss: 0.1422  Val_Acc: 94.948

Epoch 99: Validation loss decreased (0.142209 --> 0.142079).  Saving model ...
	 Train_Loss: 0.1613 Train_Acc: 95.236 Val_Loss: 0.1421  BEST VAL Loss: 0.1421  Val_Acc: 95.088

LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.95      0.97      0.96     80324
           1       0.98      0.96      0.97    109228

    accuracy                           0.97    189552
   macro avg       0.96      0.97      0.97    189552
weighted avg       0.97      0.97      0.97    189552

LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.95      0.94     10041
           1       0.97      0.95      0.96     13654

    accuracy                           0.95     23695
   macro avg       0.95      0.95      0.95     23695
weighted avg       0.95      0.95      0.95     23695

LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.95      0.94     10041
           1       0.97      0.95      0.96     13654

    accuracy                           0.95     23695
   macro avg       0.95      0.95      0.95     23695
weighted avg       0.95      0.95      0.95     23695

              precision    recall  f1-score   support

           0       0.93      0.95      0.94     10041
           1       0.97      0.95      0.96     13654

    accuracy                           0.95     23695
   macro avg       0.95      0.95      0.95     23695
weighted avg       0.95      0.95      0.95     23695

LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      0.94      0.97     38191
           1       0.94      0.99      0.97     37725

    accuracy                           0.97     75916
   macro avg       0.97      0.97      0.97     75916
weighted avg       0.97      0.97      0.97     75916

              precision    recall  f1-score   support

           0       0.99      0.94      0.97     38191
           1       0.94      0.99      0.97     37725

    accuracy                           0.97     75916
   macro avg       0.97      0.97      0.97     75916
weighted avg       0.97      0.97      0.97     75916

completed
