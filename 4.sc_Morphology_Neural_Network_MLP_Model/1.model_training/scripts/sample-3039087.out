[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '48d3e0ea'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'c2729383'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '9fec4349'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '9799d243'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Thapsigargin_10.000_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Thapsigargin_10.000_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'Thapsigargin_10.000_DMSO_0.025']
The dimensions of the data are: (305581, 1270)
Number of total missing values across all columns: 611162
Data Subset Is Off
Wells held out for testing: ['C08' 'L06']
Wells to use for training, validation, and testing ['C02' 'C03' 'C09' 'E06' 'E07' 'L07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.480807).  Saving model ...
	 Train_Loss: 0.5820 Train_Acc: 67.241 Val_Loss: 0.4808  BEST VAL Loss: 0.4808  Val_Acc: 76.933

Epoch 1: Validation loss decreased (0.480807 --> 0.456108).  Saving model ...
	 Train_Loss: 0.5342 Train_Acc: 76.096 Val_Loss: 0.4561  BEST VAL Loss: 0.4561  Val_Acc: 80.198

Epoch 2: Validation loss decreased (0.456108 --> 0.439956).  Saving model ...
	 Train_Loss: 0.5081 Train_Acc: 78.074 Val_Loss: 0.4400  BEST VAL Loss: 0.4400  Val_Acc: 81.070

Epoch 3: Validation loss decreased (0.439956 --> 0.427906).  Saving model ...
	 Train_Loss: 0.4902 Train_Acc: 79.123 Val_Loss: 0.4279  BEST VAL Loss: 0.4279  Val_Acc: 82.859

Epoch 4: Validation loss decreased (0.427906 --> 0.416986).  Saving model ...
	 Train_Loss: 0.4774 Train_Acc: 79.547 Val_Loss: 0.4170  BEST VAL Loss: 0.4170  Val_Acc: 83.546

Epoch 5: Validation loss decreased (0.416986 --> 0.410086).  Saving model ...
	 Train_Loss: 0.4668 Train_Acc: 80.142 Val_Loss: 0.4101  BEST VAL Loss: 0.4101  Val_Acc: 83.807

Epoch 6: Validation loss decreased (0.410086 --> 0.402066).  Saving model ...
	 Train_Loss: 0.4583 Train_Acc: 80.557 Val_Loss: 0.4021  BEST VAL Loss: 0.4021  Val_Acc: 84.737

Epoch 7: Validation loss decreased (0.402066 --> 0.395640).  Saving model ...
	 Train_Loss: 0.4509 Train_Acc: 80.787 Val_Loss: 0.3956  BEST VAL Loss: 0.3956  Val_Acc: 84.777

Epoch 8: Validation loss decreased (0.395640 --> 0.389760).  Saving model ...
	 Train_Loss: 0.4449 Train_Acc: 80.845 Val_Loss: 0.3898  BEST VAL Loss: 0.3898  Val_Acc: 85.096

Epoch 9: Validation loss decreased (0.389760 --> 0.384560).  Saving model ...
	 Train_Loss: 0.4396 Train_Acc: 81.146 Val_Loss: 0.3846  BEST VAL Loss: 0.3846  Val_Acc: 85.734

Epoch 10: Validation loss decreased (0.384560 --> 0.380472).  Saving model ...
	 Train_Loss: 0.4346 Train_Acc: 81.386 Val_Loss: 0.3805  BEST VAL Loss: 0.3805  Val_Acc: 85.318

Epoch 11: Validation loss decreased (0.380472 --> 0.376018).  Saving model ...
	 Train_Loss: 0.4302 Train_Acc: 81.589 Val_Loss: 0.3760  BEST VAL Loss: 0.3760  Val_Acc: 85.862

Epoch 12: Validation loss decreased (0.376018 --> 0.372272).  Saving model ...
	 Train_Loss: 0.4264 Train_Acc: 81.590 Val_Loss: 0.3723  BEST VAL Loss: 0.3723  Val_Acc: 85.889

Epoch 13: Validation loss decreased (0.372272 --> 0.369368).  Saving model ...
	 Train_Loss: 0.4230 Train_Acc: 81.753 Val_Loss: 0.3694  BEST VAL Loss: 0.3694  Val_Acc: 86.062

Epoch 14: Validation loss decreased (0.369368 --> 0.366190).  Saving model ...
	 Train_Loss: 0.4197 Train_Acc: 81.930 Val_Loss: 0.3662  BEST VAL Loss: 0.3662  Val_Acc: 86.155

Epoch 15: Validation loss decreased (0.366190 --> 0.363302).  Saving model ...
	 Train_Loss: 0.4167 Train_Acc: 82.018 Val_Loss: 0.3633  BEST VAL Loss: 0.3633  Val_Acc: 86.155

Epoch 16: Validation loss decreased (0.363302 --> 0.360815).  Saving model ...
	 Train_Loss: 0.4139 Train_Acc: 82.014 Val_Loss: 0.3608  BEST VAL Loss: 0.3608  Val_Acc: 86.234

Epoch 17: Validation loss decreased (0.360815 --> 0.358428).  Saving model ...
	 Train_Loss: 0.4114 Train_Acc: 82.093 Val_Loss: 0.3584  BEST VAL Loss: 0.3584  Val_Acc: 86.239

Epoch 18: Validation loss decreased (0.358428 --> 0.355975).  Saving model ...
	 Train_Loss: 0.4091 Train_Acc: 82.213 Val_Loss: 0.3560  BEST VAL Loss: 0.3560  Val_Acc: 86.761

Epoch 19: Validation loss decreased (0.355975 --> 0.354001).  Saving model ...
	 Train_Loss: 0.4069 Train_Acc: 82.243 Val_Loss: 0.3540  BEST VAL Loss: 0.3540  Val_Acc: 86.606

Epoch 20: Validation loss decreased (0.354001 --> 0.352390).  Saving model ...
	 Train_Loss: 0.4049 Train_Acc: 82.368 Val_Loss: 0.3524  BEST VAL Loss: 0.3524  Val_Acc: 86.310

Epoch 21: Validation loss decreased (0.352390 --> 0.350208).  Saving model ...
	 Train_Loss: 0.4030 Train_Acc: 82.246 Val_Loss: 0.3502  BEST VAL Loss: 0.3502  Val_Acc: 86.713

Epoch 22: Validation loss decreased (0.350208 --> 0.348054).  Saving model ...
	 Train_Loss: 0.4012 Train_Acc: 82.327 Val_Loss: 0.3481  BEST VAL Loss: 0.3481  Val_Acc: 86.978

Epoch 23: Validation loss decreased (0.348054 --> 0.346511).  Saving model ...
	 Train_Loss: 0.3996 Train_Acc: 82.271 Val_Loss: 0.3465  BEST VAL Loss: 0.3465  Val_Acc: 86.704

Epoch 24: Validation loss decreased (0.346511 --> 0.344815).  Saving model ...
	 Train_Loss: 0.3980 Train_Acc: 82.351 Val_Loss: 0.3448  BEST VAL Loss: 0.3448  Val_Acc: 86.730

Epoch 25: Validation loss decreased (0.344815 --> 0.343267).  Saving model ...
	 Train_Loss: 0.3965 Train_Acc: 82.440 Val_Loss: 0.3433  BEST VAL Loss: 0.3433  Val_Acc: 86.841

Epoch 26: Validation loss decreased (0.343267 --> 0.341675).  Saving model ...
	 Train_Loss: 0.3949 Train_Acc: 82.657 Val_Loss: 0.3417  BEST VAL Loss: 0.3417  Val_Acc: 86.863

Epoch 27: Validation loss decreased (0.341675 --> 0.340322).  Saving model ...
	 Train_Loss: 0.3936 Train_Acc: 82.409 Val_Loss: 0.3403  BEST VAL Loss: 0.3403  Val_Acc: 86.699

Epoch 28: Validation loss decreased (0.340322 --> 0.339045).  Saving model ...
	 Train_Loss: 0.3924 Train_Acc: 82.398 Val_Loss: 0.3390  BEST VAL Loss: 0.3390  Val_Acc: 87.098

Epoch 29: Validation loss decreased (0.339045 --> 0.338058).  Saving model ...
	 Train_Loss: 0.3912 Train_Acc: 82.428 Val_Loss: 0.3381  BEST VAL Loss: 0.3381  Val_Acc: 86.673

Epoch 30: Validation loss decreased (0.338058 --> 0.336686).  Saving model ...
	 Train_Loss: 0.3900 Train_Acc: 82.607 Val_Loss: 0.3367  BEST VAL Loss: 0.3367  Val_Acc: 87.351

Epoch 31: Validation loss decreased (0.336686 --> 0.335523).  Saving model ...
	 Train_Loss: 0.3889 Train_Acc: 82.544 Val_Loss: 0.3355  BEST VAL Loss: 0.3355  Val_Acc: 87.142

Epoch 32: Validation loss decreased (0.335523 --> 0.334491).  Saving model ...
	 Train_Loss: 0.3878 Train_Acc: 82.643 Val_Loss: 0.3345  BEST VAL Loss: 0.3345  Val_Acc: 86.996

Epoch 33: Validation loss decreased (0.334491 --> 0.333422).  Saving model ...
	 Train_Loss: 0.3868 Train_Acc: 82.544 Val_Loss: 0.3334  BEST VAL Loss: 0.3334  Val_Acc: 87.098

Epoch 34: Validation loss decreased (0.333422 --> 0.332411).  Saving model ...
	 Train_Loss: 0.3857 Train_Acc: 82.731 Val_Loss: 0.3324  BEST VAL Loss: 0.3324  Val_Acc: 87.107

Epoch 35: Validation loss decreased (0.332411 --> 0.331375).  Saving model ...
	 Train_Loss: 0.3848 Train_Acc: 82.593 Val_Loss: 0.3314  BEST VAL Loss: 0.3314  Val_Acc: 87.107

Epoch 36: Validation loss decreased (0.331375 --> 0.330948).  Saving model ...
	 Train_Loss: 0.3838 Train_Acc: 82.620 Val_Loss: 0.3309  BEST VAL Loss: 0.3309  Val_Acc: 86.358

Epoch 37: Validation loss decreased (0.330948 --> 0.330009).  Saving model ...
	 Train_Loss: 0.3829 Train_Acc: 82.805 Val_Loss: 0.3300  BEST VAL Loss: 0.3300  Val_Acc: 87.333

Epoch 38: Validation loss decreased (0.330009 --> 0.329234).  Saving model ...
	 Train_Loss: 0.3821 Train_Acc: 82.766 Val_Loss: 0.3292  BEST VAL Loss: 0.3292  Val_Acc: 86.841

Epoch 39: Validation loss decreased (0.329234 --> 0.328375).  Saving model ...
	 Train_Loss: 0.3812 Train_Acc: 82.850 Val_Loss: 0.3284  BEST VAL Loss: 0.3284  Val_Acc: 87.258

Epoch 40: Validation loss decreased (0.328375 --> 0.328115).  Saving model ...
	 Train_Loss: 0.3804 Train_Acc: 82.764 Val_Loss: 0.3281  BEST VAL Loss: 0.3281  Val_Acc: 86.443

Epoch 41: Validation loss decreased (0.328115 --> 0.327205).  Saving model ...
	 Train_Loss: 0.3797 Train_Acc: 82.864 Val_Loss: 0.3272  BEST VAL Loss: 0.3272  Val_Acc: 87.554

Epoch 42: Validation loss decreased (0.327205 --> 0.326622).  Saving model ...
	 Train_Loss: 0.3789 Train_Acc: 82.741 Val_Loss: 0.3266  BEST VAL Loss: 0.3266  Val_Acc: 87.045

Epoch 43: Validation loss decreased (0.326622 --> 0.326059).  Saving model ...
	 Train_Loss: 0.3782 Train_Acc: 82.876 Val_Loss: 0.3261  BEST VAL Loss: 0.3261  Val_Acc: 86.810

Epoch 44: Validation loss decreased (0.326059 --> 0.325327).  Saving model ...
	 Train_Loss: 0.3775 Train_Acc: 82.910 Val_Loss: 0.3253  BEST VAL Loss: 0.3253  Val_Acc: 87.435

Epoch 45: Validation loss decreased (0.325327 --> 0.324785).  Saving model ...
	 Train_Loss: 0.3768 Train_Acc: 82.861 Val_Loss: 0.3248  BEST VAL Loss: 0.3248  Val_Acc: 87.085

Epoch 46: Validation loss decreased (0.324785 --> 0.324188).  Saving model ...
	 Train_Loss: 0.3761 Train_Acc: 82.915 Val_Loss: 0.3242  BEST VAL Loss: 0.3242  Val_Acc: 87.196

Epoch 47: Validation loss decreased (0.324188 --> 0.323547).  Saving model ...
	 Train_Loss: 0.3755 Train_Acc: 82.896 Val_Loss: 0.3235  BEST VAL Loss: 0.3235  Val_Acc: 87.320

Epoch 48: Validation loss decreased (0.323547 --> 0.322968).  Saving model ...
	 Train_Loss: 0.3749 Train_Acc: 82.950 Val_Loss: 0.3230  BEST VAL Loss: 0.3230  Val_Acc: 87.284

Epoch 49: Validation loss decreased (0.322968 --> 0.322329).  Saving model ...
	 Train_Loss: 0.3742 Train_Acc: 82.972 Val_Loss: 0.3223  BEST VAL Loss: 0.3223  Val_Acc: 87.377

Epoch 50: Validation loss decreased (0.322329 --> 0.321632).  Saving model ...
	 Train_Loss: 0.3736 Train_Acc: 82.991 Val_Loss: 0.3216  BEST VAL Loss: 0.3216  Val_Acc: 87.519

Epoch 51: Validation loss decreased (0.321632 --> 0.321142).  Saving model ...
	 Train_Loss: 0.3731 Train_Acc: 82.904 Val_Loss: 0.3211  BEST VAL Loss: 0.3211  Val_Acc: 87.297

Epoch 52: Validation loss decreased (0.321142 --> 0.320787).  Saving model ...
	 Train_Loss: 0.3725 Train_Acc: 82.985 Val_Loss: 0.3208  BEST VAL Loss: 0.3208  Val_Acc: 86.846

Epoch 53: Validation loss decreased (0.320787 --> 0.320262).  Saving model ...
	 Train_Loss: 0.3719 Train_Acc: 82.952 Val_Loss: 0.3203  BEST VAL Loss: 0.3203  Val_Acc: 87.235

Epoch 54: Validation loss decreased (0.320262 --> 0.319818).  Saving model ...
	 Train_Loss: 0.3714 Train_Acc: 83.053 Val_Loss: 0.3198  BEST VAL Loss: 0.3198  Val_Acc: 87.027

Epoch 55: Validation loss decreased (0.319818 --> 0.319347).  Saving model ...
	 Train_Loss: 0.3709 Train_Acc: 83.028 Val_Loss: 0.3193  BEST VAL Loss: 0.3193  Val_Acc: 86.970

Epoch 56: Validation loss decreased (0.319347 --> 0.319334).  Saving model ...
	 Train_Loss: 0.3703 Train_Acc: 83.089 Val_Loss: 0.3193  BEST VAL Loss: 0.3193  Val_Acc: 86.075

Epoch 57: Validation loss decreased (0.319334 --> 0.318874).  Saving model ...
	 Train_Loss: 0.3699 Train_Acc: 83.147 Val_Loss: 0.3189  BEST VAL Loss: 0.3189  Val_Acc: 87.492

Epoch 58: Validation loss decreased (0.318874 --> 0.318371).  Saving model ...
	 Train_Loss: 0.3694 Train_Acc: 83.023 Val_Loss: 0.3184  BEST VAL Loss: 0.3184  Val_Acc: 87.638

Epoch 59: Validation loss decreased (0.318371 --> 0.317793).  Saving model ...
	 Train_Loss: 0.3689 Train_Acc: 82.990 Val_Loss: 0.3178  BEST VAL Loss: 0.3178  Val_Acc: 87.625

Epoch 60: Validation loss decreased (0.317793 --> 0.317424).  Saving model ...
	 Train_Loss: 0.3685 Train_Acc: 83.125 Val_Loss: 0.3174  BEST VAL Loss: 0.3174  Val_Acc: 87.129

Epoch 61: Validation loss decreased (0.317424 --> 0.316880).  Saving model ...
	 Train_Loss: 0.3680 Train_Acc: 82.948 Val_Loss: 0.3169  BEST VAL Loss: 0.3169  Val_Acc: 87.382

Epoch 62: Validation loss decreased (0.316880 --> 0.316603).  Saving model ...
	 Train_Loss: 0.3676 Train_Acc: 82.945 Val_Loss: 0.3166  BEST VAL Loss: 0.3166  Val_Acc: 87.120

Epoch 63: Validation loss decreased (0.316603 --> 0.316221).  Saving model ...
	 Train_Loss: 0.3672 Train_Acc: 83.232 Val_Loss: 0.3162  BEST VAL Loss: 0.3162  Val_Acc: 87.293

Epoch 64: Validation loss decreased (0.316221 --> 0.315829).  Saving model ...
	 Train_Loss: 0.3667 Train_Acc: 83.196 Val_Loss: 0.3158  BEST VAL Loss: 0.3158  Val_Acc: 87.563

Epoch 65: Validation loss decreased (0.315829 --> 0.315674).  Saving model ...
	 Train_Loss: 0.3663 Train_Acc: 83.056 Val_Loss: 0.3157  BEST VAL Loss: 0.3157  Val_Acc: 86.673

Epoch 66: Validation loss decreased (0.315674 --> 0.315220).  Saving model ...
	 Train_Loss: 0.3659 Train_Acc: 83.100 Val_Loss: 0.3152  BEST VAL Loss: 0.3152  Val_Acc: 87.550

Epoch 67: Validation loss decreased (0.315220 --> 0.314835).  Saving model ...
	 Train_Loss: 0.3655 Train_Acc: 83.108 Val_Loss: 0.3148  BEST VAL Loss: 0.3148  Val_Acc: 87.218

Epoch 68: Validation loss decreased (0.314835 --> 0.314432).  Saving model ...
	 Train_Loss: 0.3651 Train_Acc: 83.257 Val_Loss: 0.3144  BEST VAL Loss: 0.3144  Val_Acc: 87.541

Epoch 69: Validation loss decreased (0.314432 --> 0.314191).  Saving model ...
	 Train_Loss: 0.3647 Train_Acc: 83.209 Val_Loss: 0.3142  BEST VAL Loss: 0.3142  Val_Acc: 86.965

Epoch 70: Validation loss decreased (0.314191 --> 0.313803).  Saving model ...
	 Train_Loss: 0.3643 Train_Acc: 83.132 Val_Loss: 0.3138  BEST VAL Loss: 0.3138  Val_Acc: 87.320

Epoch 71: Validation loss decreased (0.313803 --> 0.313500).  Saving model ...
	 Train_Loss: 0.3640 Train_Acc: 83.103 Val_Loss: 0.3135  BEST VAL Loss: 0.3135  Val_Acc: 87.541

Epoch 72: Validation loss decreased (0.313500 --> 0.313087).  Saving model ...
	 Train_Loss: 0.3636 Train_Acc: 83.112 Val_Loss: 0.3131  BEST VAL Loss: 0.3131  Val_Acc: 87.634

Epoch 73: Validation loss decreased (0.313087 --> 0.312662).  Saving model ...
	 Train_Loss: 0.3633 Train_Acc: 83.253 Val_Loss: 0.3127  BEST VAL Loss: 0.3127  Val_Acc: 87.740

Epoch 74: Validation loss decreased (0.312662 --> 0.312262).  Saving model ...
	 Train_Loss: 0.3629 Train_Acc: 83.288 Val_Loss: 0.3123  BEST VAL Loss: 0.3123  Val_Acc: 87.749

Epoch 75: Validation loss decreased (0.312262 --> 0.311885).  Saving model ...
	 Train_Loss: 0.3626 Train_Acc: 83.251 Val_Loss: 0.3119  BEST VAL Loss: 0.3119  Val_Acc: 87.479

Epoch 76: Validation loss decreased (0.311885 --> 0.311517).  Saving model ...
	 Train_Loss: 0.3623 Train_Acc: 83.158 Val_Loss: 0.3115  BEST VAL Loss: 0.3115  Val_Acc: 87.501

Epoch 77: Validation loss decreased (0.311517 --> 0.311208).  Saving model ...
	 Train_Loss: 0.3620 Train_Acc: 83.205 Val_Loss: 0.3112  BEST VAL Loss: 0.3112  Val_Acc: 87.501

Epoch 78: Validation loss decreased (0.311208 --> 0.311135).  Saving model ...
	 Train_Loss: 0.3616 Train_Acc: 83.275 Val_Loss: 0.3111  BEST VAL Loss: 0.3111  Val_Acc: 86.482

Epoch 79: Validation loss decreased (0.311135 --> 0.310873).  Saving model ...
	 Train_Loss: 0.3613 Train_Acc: 83.131 Val_Loss: 0.3109  BEST VAL Loss: 0.3109  Val_Acc: 87.395

Epoch 80: Validation loss decreased (0.310873 --> 0.310546).  Saving model ...
	 Train_Loss: 0.3610 Train_Acc: 83.121 Val_Loss: 0.3105  BEST VAL Loss: 0.3105  Val_Acc: 87.475

Epoch 81: Validation loss decreased (0.310546 --> 0.310195).  Saving model ...
	 Train_Loss: 0.3607 Train_Acc: 83.131 Val_Loss: 0.3102  BEST VAL Loss: 0.3102  Val_Acc: 87.838

Epoch 82: Validation loss decreased (0.310195 --> 0.309861).  Saving model ...
	 Train_Loss: 0.3604 Train_Acc: 83.189 Val_Loss: 0.3099  BEST VAL Loss: 0.3099  Val_Acc: 87.590

Epoch 83: Validation loss decreased (0.309861 --> 0.309569).  Saving model ...
	 Train_Loss: 0.3601 Train_Acc: 83.327 Val_Loss: 0.3096  BEST VAL Loss: 0.3096  Val_Acc: 87.386

Epoch 84: Validation loss decreased (0.309569 --> 0.309303).  Saving model ...
	 Train_Loss: 0.3598 Train_Acc: 83.314 Val_Loss: 0.3093  BEST VAL Loss: 0.3093  Val_Acc: 87.457

Epoch 85: Validation loss decreased (0.309303 --> 0.309023).  Saving model ...
	 Train_Loss: 0.3595 Train_Acc: 83.277 Val_Loss: 0.3090  BEST VAL Loss: 0.3090  Val_Acc: 87.408

Epoch 86: Validation loss decreased (0.309023 --> 0.308862).  Saving model ...
	 Train_Loss: 0.3593 Train_Acc: 83.330 Val_Loss: 0.3089  BEST VAL Loss: 0.3089  Val_Acc: 87.085

Epoch 87: Validation loss decreased (0.308862 --> 0.308613).  Saving model ...
	 Train_Loss: 0.3590 Train_Acc: 83.255 Val_Loss: 0.3086  BEST VAL Loss: 0.3086  Val_Acc: 87.240

Epoch 88: Validation loss decreased (0.308613 --> 0.308363).  Saving model ...
	 Train_Loss: 0.3587 Train_Acc: 83.297 Val_Loss: 0.3084  BEST VAL Loss: 0.3084  Val_Acc: 87.576

Epoch 89: Validation loss decreased (0.308363 --> 0.308125).  Saving model ...
	 Train_Loss: 0.3584 Train_Acc: 83.303 Val_Loss: 0.3081  BEST VAL Loss: 0.3081  Val_Acc: 87.461

Epoch 90: Validation loss decreased (0.308125 --> 0.307866).  Saving model ...
	 Train_Loss: 0.3582 Train_Acc: 83.353 Val_Loss: 0.3079  BEST VAL Loss: 0.3079  Val_Acc: 87.572

Epoch 91: Validation loss decreased (0.307866 --> 0.307606).  Saving model ...
	 Train_Loss: 0.3579 Train_Acc: 83.370 Val_Loss: 0.3076  BEST VAL Loss: 0.3076  Val_Acc: 87.723

Epoch 92: Validation loss decreased (0.307606 --> 0.307380).  Saving model ...
	 Train_Loss: 0.3577 Train_Acc: 83.206 Val_Loss: 0.3074  BEST VAL Loss: 0.3074  Val_Acc: 87.386

Epoch 93: Validation loss decreased (0.307380 --> 0.307108).  Saving model ...
	 Train_Loss: 0.3574 Train_Acc: 83.355 Val_Loss: 0.3071  BEST VAL Loss: 0.3071  Val_Acc: 87.855

Epoch 94: Validation loss decreased (0.307108 --> 0.306858).  Saving model ...
	 Train_Loss: 0.3572 Train_Acc: 83.361 Val_Loss: 0.3069  BEST VAL Loss: 0.3069  Val_Acc: 87.683

Epoch 95: Validation loss decreased (0.306858 --> 0.306713).  Saving model ...
	 Train_Loss: 0.3569 Train_Acc: 83.268 Val_Loss: 0.3067  BEST VAL Loss: 0.3067  Val_Acc: 87.244

Epoch 96: Validation loss decreased (0.306713 --> 0.306511).  Saving model ...
	 Train_Loss: 0.3567 Train_Acc: 83.375 Val_Loss: 0.3065  BEST VAL Loss: 0.3065  Val_Acc: 87.466

Epoch 97: Validation loss decreased (0.306511 --> 0.306249).  Saving model ...
	 Train_Loss: 0.3565 Train_Acc: 83.342 Val_Loss: 0.3062  BEST VAL Loss: 0.3062  Val_Acc: 87.723

Epoch 98: Validation loss decreased (0.306249 --> 0.306003).  Saving model ...
	 Train_Loss: 0.3562 Train_Acc: 83.387 Val_Loss: 0.3060  BEST VAL Loss: 0.3060  Val_Acc: 87.847

Epoch 99: Validation loss decreased (0.306003 --> 0.305761).  Saving model ...
	 Train_Loss: 0.3560 Train_Acc: 83.397 Val_Loss: 0.3058  BEST VAL Loss: 0.3058  Val_Acc: 87.847

Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.43      0.45     82968
           1       0.54      0.57      0.55     97655

    accuracy                           0.50    180623
   macro avg       0.50      0.50      0.50    180623
weighted avg       0.50      0.50      0.50    180623

Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.43      0.45     10371
           1       0.54      0.57      0.55     12207

    accuracy                           0.51     22578
   macro avg       0.50      0.50      0.50     22578
weighted avg       0.50      0.51      0.50     22578

Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.43      0.44     10371
           1       0.54      0.56      0.55     12207

    accuracy                           0.50     22578
   macro avg       0.50      0.50      0.50     22578
weighted avg       0.50      0.50      0.50     22578

              precision    recall  f1-score   support

           0       0.46      0.43      0.44     10371
           1       0.54      0.56      0.55     12207

    accuracy                           0.50     22578
   macro avg       0.50      0.50      0.50     22578
weighted avg       0.50      0.50      0.50     22578

Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.43      0.41      0.42     34887
           1       0.56      0.59      0.57     44915

    accuracy                           0.51     79802
   macro avg       0.50      0.50      0.50     79802
weighted avg       0.50      0.51      0.51     79802

              precision    recall  f1-score   support

           0       0.43      0.41      0.42     34887
           1       0.56      0.59      0.57     44915

    accuracy                           0.51     79802
   macro avg       0.50      0.50      0.50     79802
weighted avg       0.50      0.51      0.51     79802

completed
