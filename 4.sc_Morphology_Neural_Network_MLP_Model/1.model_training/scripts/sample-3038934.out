[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '76f9251e'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'b89139ab'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '16b9900f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '04f9a85f'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_0.100_DMSO_0.025 treatment_name: LPS_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_0.100_DMSO_0.025
TREATMENT_NAME: LPS_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_1.000_DMSO_0.025']
The dimensions of the data are: (278030, 1270)
Number of total missing values across all columns: 556060
Data Subset Is Off
Wells held out for testing: ['C08' 'D08']
Wells to use for training, validation, and testing ['C02' 'C03' 'C09' 'D02' 'D03' 'D09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.653838).  Saving model ...
	 Train_Loss: 0.7218 Train_Acc: 54.674 Val_Loss: 0.6538  BEST VAL Loss: 0.6538  Val_Acc: 61.029

Epoch 1: Validation loss decreased (0.653838 --> 0.643525).  Saving model ...
	 Train_Loss: 0.6866 Train_Acc: 59.857 Val_Loss: 0.6435  BEST VAL Loss: 0.6435  Val_Acc: 62.951

Epoch 2: Validation loss decreased (0.643525 --> 0.638417).  Saving model ...
	 Train_Loss: 0.6708 Train_Acc: 61.246 Val_Loss: 0.6384  BEST VAL Loss: 0.6384  Val_Acc: 62.194

Epoch 3: Validation loss decreased (0.638417 --> 0.632083).  Saving model ...
	 Train_Loss: 0.6604 Train_Acc: 61.764 Val_Loss: 0.6321  BEST VAL Loss: 0.6321  Val_Acc: 64.086

Epoch 4: Validation loss decreased (0.632083 --> 0.627525).  Saving model ...
	 Train_Loss: 0.6529 Train_Acc: 62.143 Val_Loss: 0.6275  BEST VAL Loss: 0.6275  Val_Acc: 64.278

Epoch 5: Validation loss decreased (0.627525 --> 0.624262).  Saving model ...
	 Train_Loss: 0.6468 Train_Acc: 62.630 Val_Loss: 0.6243  BEST VAL Loss: 0.6243  Val_Acc: 64.204

Epoch 6: Validation loss decreased (0.624262 --> 0.620592).  Saving model ...
	 Train_Loss: 0.6421 Train_Acc: 62.551 Val_Loss: 0.6206  BEST VAL Loss: 0.6206  Val_Acc: 63.865

Epoch 7: Validation loss decreased (0.620592 --> 0.615879).  Saving model ...
	 Train_Loss: 0.6374 Train_Acc: 63.294 Val_Loss: 0.6159  BEST VAL Loss: 0.6159  Val_Acc: 65.507

Epoch 8: Validation loss decreased (0.615879 --> 0.612897).  Saving model ...
	 Train_Loss: 0.6334 Train_Acc: 63.531 Val_Loss: 0.6129  BEST VAL Loss: 0.6129  Val_Acc: 65.241

Epoch 9: Validation loss decreased (0.612897 --> 0.609336).  Saving model ...
	 Train_Loss: 0.6302 Train_Acc: 63.523 Val_Loss: 0.6093  BEST VAL Loss: 0.6093  Val_Acc: 66.151

Epoch 10: Validation loss decreased (0.609336 --> 0.606182).  Saving model ...
	 Train_Loss: 0.6270 Train_Acc: 63.959 Val_Loss: 0.6062  BEST VAL Loss: 0.6062  Val_Acc: 65.689

Epoch 11: Validation loss decreased (0.606182 --> 0.603630).  Saving model ...
	 Train_Loss: 0.6244 Train_Acc: 63.741 Val_Loss: 0.6036  BEST VAL Loss: 0.6036  Val_Acc: 65.782

Epoch 12: Validation loss decreased (0.603630 --> 0.601020).  Saving model ...
	 Train_Loss: 0.6221 Train_Acc: 63.759 Val_Loss: 0.6010  BEST VAL Loss: 0.6010  Val_Acc: 65.620

Epoch 13: Validation loss decreased (0.601020 --> 0.598759).  Saving model ...
	 Train_Loss: 0.6198 Train_Acc: 63.969 Val_Loss: 0.5988  BEST VAL Loss: 0.5988  Val_Acc: 65.767

Epoch 14: Validation loss decreased (0.598759 --> 0.596554).  Saving model ...
	 Train_Loss: 0.6176 Train_Acc: 64.069 Val_Loss: 0.5966  BEST VAL Loss: 0.5966  Val_Acc: 66.858

Epoch 15: Validation loss decreased (0.596554 --> 0.594823).  Saving model ...
	 Train_Loss: 0.6156 Train_Acc: 64.135 Val_Loss: 0.5948  BEST VAL Loss: 0.5948  Val_Acc: 65.831

Epoch 16: Validation loss decreased (0.594823 --> 0.592710).  Saving model ...
	 Train_Loss: 0.6138 Train_Acc: 64.187 Val_Loss: 0.5927  BEST VAL Loss: 0.5927  Val_Acc: 66.932

Epoch 17: Validation loss decreased (0.592710 --> 0.591049).  Saving model ...
	 Train_Loss: 0.6121 Train_Acc: 64.292 Val_Loss: 0.5910  BEST VAL Loss: 0.5910  Val_Acc: 67.021

Epoch 18: Validation loss decreased (0.591049 --> 0.589699).  Saving model ...
	 Train_Loss: 0.6106 Train_Acc: 64.080 Val_Loss: 0.5897  BEST VAL Loss: 0.5897  Val_Acc: 66.023

Epoch 19: Validation loss decreased (0.589699 --> 0.588063).  Saving model ...
	 Train_Loss: 0.6092 Train_Acc: 64.218 Val_Loss: 0.5881  BEST VAL Loss: 0.5881  Val_Acc: 66.765

Epoch 20: Validation loss decreased (0.588063 --> 0.586618).  Saving model ...
	 Train_Loss: 0.6078 Train_Acc: 64.358 Val_Loss: 0.5866  BEST VAL Loss: 0.5866  Val_Acc: 67.109

Epoch 21: Validation loss decreased (0.586618 --> 0.585115).  Saving model ...
	 Train_Loss: 0.6066 Train_Acc: 64.497 Val_Loss: 0.5851  BEST VAL Loss: 0.5851  Val_Acc: 67.197

Epoch 22: Validation loss decreased (0.585115 --> 0.583952).  Saving model ...
	 Train_Loss: 0.6053 Train_Acc: 64.172 Val_Loss: 0.5840  BEST VAL Loss: 0.5840  Val_Acc: 67.207

Epoch 23: Validation loss decreased (0.583952 --> 0.582597).  Saving model ...
	 Train_Loss: 0.6042 Train_Acc: 64.201 Val_Loss: 0.5826  BEST VAL Loss: 0.5826  Val_Acc: 67.424

Epoch 24: Validation loss decreased (0.582597 --> 0.581409).  Saving model ...
	 Train_Loss: 0.6031 Train_Acc: 64.242 Val_Loss: 0.5814  BEST VAL Loss: 0.5814  Val_Acc: 66.809

Epoch 25: Validation loss decreased (0.581409 --> 0.580288).  Saving model ...
	 Train_Loss: 0.6021 Train_Acc: 64.581 Val_Loss: 0.5803  BEST VAL Loss: 0.5803  Val_Acc: 68.146

Epoch 26: Validation loss decreased (0.580288 --> 0.579179).  Saving model ...
	 Train_Loss: 0.6010 Train_Acc: 64.616 Val_Loss: 0.5792  BEST VAL Loss: 0.5792  Val_Acc: 67.340

Epoch 27: Validation loss decreased (0.579179 --> 0.578022).  Saving model ...
	 Train_Loss: 0.6002 Train_Acc: 64.294 Val_Loss: 0.5780  BEST VAL Loss: 0.5780  Val_Acc: 67.517

Epoch 28: Validation loss decreased (0.578022 --> 0.577095).  Saving model ...
	 Train_Loss: 0.5992 Train_Acc: 64.578 Val_Loss: 0.5771  BEST VAL Loss: 0.5771  Val_Acc: 66.996

Epoch 29: Validation loss decreased (0.577095 --> 0.576576).  Saving model ...
	 Train_Loss: 0.5985 Train_Acc: 64.229 Val_Loss: 0.5766  BEST VAL Loss: 0.5766  Val_Acc: 66.082

Epoch 30: Validation loss decreased (0.576576 --> 0.575650).  Saving model ...
	 Train_Loss: 0.5977 Train_Acc: 64.418 Val_Loss: 0.5756  BEST VAL Loss: 0.5756  Val_Acc: 67.659

Epoch 31: Validation loss decreased (0.575650 --> 0.574837).  Saving model ...
	 Train_Loss: 0.5968 Train_Acc: 64.557 Val_Loss: 0.5748  BEST VAL Loss: 0.5748  Val_Acc: 67.040

Epoch 32: Validation loss decreased (0.574837 --> 0.573967).  Saving model ...
	 Train_Loss: 0.5960 Train_Acc: 64.706 Val_Loss: 0.5740  BEST VAL Loss: 0.5740  Val_Acc: 67.601

Epoch 33: Validation loss decreased (0.573967 --> 0.573353).  Saving model ...
	 Train_Loss: 0.5954 Train_Acc: 64.429 Val_Loss: 0.5734  BEST VAL Loss: 0.5734  Val_Acc: 66.544

Epoch 34: Validation loss decreased (0.573353 --> 0.572413).  Saving model ...
	 Train_Loss: 0.5947 Train_Acc: 64.194 Val_Loss: 0.5724  BEST VAL Loss: 0.5724  Val_Acc: 67.822

Epoch 35: Validation loss decreased (0.572413 --> 0.571586).  Saving model ...
	 Train_Loss: 0.5939 Train_Acc: 64.454 Val_Loss: 0.5716  BEST VAL Loss: 0.5716  Val_Acc: 67.345

Epoch 36: Validation loss decreased (0.571586 --> 0.570865).  Saving model ...
	 Train_Loss: 0.5932 Train_Acc: 64.668 Val_Loss: 0.5709  BEST VAL Loss: 0.5709  Val_Acc: 66.775

Epoch 37: Validation loss decreased (0.570865 --> 0.570216).  Saving model ...
	 Train_Loss: 0.5925 Train_Acc: 64.673 Val_Loss: 0.5702  BEST VAL Loss: 0.5702  Val_Acc: 67.787

Epoch 38: Validation loss decreased (0.570216 --> 0.569568).  Saving model ...
	 Train_Loss: 0.5919 Train_Acc: 64.687 Val_Loss: 0.5696  BEST VAL Loss: 0.5696  Val_Acc: 67.866

Epoch 39: Validation loss decreased (0.569568 --> 0.568938).  Saving model ...
	 Train_Loss: 0.5912 Train_Acc: 64.777 Val_Loss: 0.5689  BEST VAL Loss: 0.5689  Val_Acc: 67.827

Epoch 40: Validation loss decreased (0.568938 --> 0.568292).  Saving model ...
	 Train_Loss: 0.5905 Train_Acc: 64.597 Val_Loss: 0.5683  BEST VAL Loss: 0.5683  Val_Acc: 67.866

Epoch 41: Validation loss decreased (0.568292 --> 0.567723).  Saving model ...
	 Train_Loss: 0.5899 Train_Acc: 64.832 Val_Loss: 0.5677  BEST VAL Loss: 0.5677  Val_Acc: 67.699

Epoch 42: Validation loss decreased (0.567723 --> 0.567137).  Saving model ...
	 Train_Loss: 0.5893 Train_Acc: 64.828 Val_Loss: 0.5671  BEST VAL Loss: 0.5671  Val_Acc: 67.222

Epoch 43: Validation loss decreased (0.567137 --> 0.566506).  Saving model ...
	 Train_Loss: 0.5887 Train_Acc: 64.592 Val_Loss: 0.5665  BEST VAL Loss: 0.5665  Val_Acc: 68.033

Epoch 44: Validation loss decreased (0.566506 --> 0.565830).  Saving model ...
	 Train_Loss: 0.5882 Train_Acc: 64.579 Val_Loss: 0.5658  BEST VAL Loss: 0.5658  Val_Acc: 67.895

Epoch 45: Validation loss decreased (0.565830 --> 0.565375).  Saving model ...
	 Train_Loss: 0.5876 Train_Acc: 64.533 Val_Loss: 0.5654  BEST VAL Loss: 0.5654  Val_Acc: 67.792

Epoch 46: Validation loss decreased (0.565375 --> 0.564839).  Saving model ...
	 Train_Loss: 0.5871 Train_Acc: 64.701 Val_Loss: 0.5648  BEST VAL Loss: 0.5648  Val_Acc: 68.318

Epoch 47: Validation loss decreased (0.564839 --> 0.564240).  Saving model ...
	 Train_Loss: 0.5865 Train_Acc: 64.923 Val_Loss: 0.5642  BEST VAL Loss: 0.5642  Val_Acc: 68.387

Epoch 48: Validation loss decreased (0.564240 --> 0.563977).  Saving model ...
	 Train_Loss: 0.5860 Train_Acc: 64.711 Val_Loss: 0.5640  BEST VAL Loss: 0.5640  Val_Acc: 67.178

Epoch 49: Validation loss decreased (0.563977 --> 0.563410).  Saving model ...
	 Train_Loss: 0.5855 Train_Acc: 64.269 Val_Loss: 0.5634  BEST VAL Loss: 0.5634  Val_Acc: 68.790

Epoch 50: Validation loss decreased (0.563410 --> 0.562829).  Saving model ...
	 Train_Loss: 0.5850 Train_Acc: 64.347 Val_Loss: 0.5628  BEST VAL Loss: 0.5628  Val_Acc: 68.613

Epoch 51: Validation loss decreased (0.562829 --> 0.562276).  Saving model ...
	 Train_Loss: 0.5845 Train_Acc: 64.751 Val_Loss: 0.5623  BEST VAL Loss: 0.5623  Val_Acc: 68.662

Epoch 52: Validation loss decreased (0.562276 --> 0.561639).  Saving model ...
	 Train_Loss: 0.5840 Train_Acc: 64.755 Val_Loss: 0.5616  BEST VAL Loss: 0.5616  Val_Acc: 68.421

Epoch 53: Validation loss decreased (0.561639 --> 0.561042).  Saving model ...
	 Train_Loss: 0.5834 Train_Acc: 64.829 Val_Loss: 0.5610  BEST VAL Loss: 0.5610  Val_Acc: 68.962

Epoch 54: Validation loss decreased (0.561042 --> 0.560571).  Saving model ...
	 Train_Loss: 0.5830 Train_Acc: 64.510 Val_Loss: 0.5606  BEST VAL Loss: 0.5606  Val_Acc: 66.740

Epoch 55: Validation loss decreased (0.560571 --> 0.560088).  Saving model ...
	 Train_Loss: 0.5826 Train_Acc: 64.587 Val_Loss: 0.5601  BEST VAL Loss: 0.5601  Val_Acc: 68.638

Epoch 56: Validation loss decreased (0.560088 --> 0.559561).  Saving model ...
	 Train_Loss: 0.5821 Train_Acc: 64.549 Val_Loss: 0.5596  BEST VAL Loss: 0.5596  Val_Acc: 68.313

Epoch 57: Validation loss decreased (0.559561 --> 0.558961).  Saving model ...
	 Train_Loss: 0.5816 Train_Acc: 64.488 Val_Loss: 0.5590  BEST VAL Loss: 0.5590  Val_Acc: 68.878

Epoch 58: Validation loss decreased (0.558961 --> 0.558466).  Saving model ...
	 Train_Loss: 0.5812 Train_Acc: 64.320 Val_Loss: 0.5585  BEST VAL Loss: 0.5585  Val_Acc: 68.544

Epoch 59: Validation loss decreased (0.558466 --> 0.557929).  Saving model ...
	 Train_Loss: 0.5808 Train_Acc: 64.391 Val_Loss: 0.5579  BEST VAL Loss: 0.5579  Val_Acc: 68.864

Epoch 60: Validation loss decreased (0.557929 --> 0.557445).  Saving model ...
	 Train_Loss: 0.5803 Train_Acc: 64.372 Val_Loss: 0.5574  BEST VAL Loss: 0.5574  Val_Acc: 66.834

Epoch 61: Validation loss decreased (0.557445 --> 0.556926).  Saving model ...
	 Train_Loss: 0.5799 Train_Acc: 64.736 Val_Loss: 0.5569  BEST VAL Loss: 0.5569  Val_Acc: 68.741

Epoch 62: Validation loss decreased (0.556926 --> 0.556403).  Saving model ...
	 Train_Loss: 0.5795 Train_Acc: 64.431 Val_Loss: 0.5564  BEST VAL Loss: 0.5564  Val_Acc: 68.815

Epoch 63: Validation loss decreased (0.556403 --> 0.556036).  Saving model ...
	 Train_Loss: 0.5790 Train_Acc: 64.488 Val_Loss: 0.5560  BEST VAL Loss: 0.5560  Val_Acc: 68.485

Epoch 64: Validation loss decreased (0.556036 --> 0.555587).  Saving model ...
	 Train_Loss: 0.5787 Train_Acc: 64.436 Val_Loss: 0.5556  BEST VAL Loss: 0.5556  Val_Acc: 68.549

Epoch 65: Validation loss decreased (0.555587 --> 0.555092).  Saving model ...
	 Train_Loss: 0.5783 Train_Acc: 64.409 Val_Loss: 0.5551  BEST VAL Loss: 0.5551  Val_Acc: 68.765

Epoch 66: Validation loss decreased (0.555092 --> 0.554697).  Saving model ...
	 Train_Loss: 0.5780 Train_Acc: 64.544 Val_Loss: 0.5547  BEST VAL Loss: 0.5547  Val_Acc: 68.991

Epoch 67: Validation loss decreased (0.554697 --> 0.554190).  Saving model ...
	 Train_Loss: 0.5776 Train_Acc: 64.678 Val_Loss: 0.5542  BEST VAL Loss: 0.5542  Val_Acc: 69.316

Epoch 68: Validation loss decreased (0.554190 --> 0.553795).  Saving model ...
	 Train_Loss: 0.5772 Train_Acc: 64.820 Val_Loss: 0.5538  BEST VAL Loss: 0.5538  Val_Acc: 69.109

Epoch 69: Validation loss decreased (0.553795 --> 0.553359).  Saving model ...
	 Train_Loss: 0.5768 Train_Acc: 64.732 Val_Loss: 0.5534  BEST VAL Loss: 0.5534  Val_Acc: 68.682

Epoch 70: Validation loss decreased (0.553359 --> 0.552930).  Saving model ...
	 Train_Loss: 0.5765 Train_Acc: 64.525 Val_Loss: 0.5529  BEST VAL Loss: 0.5529  Val_Acc: 67.379

Epoch 71: Validation loss decreased (0.552930 --> 0.552537).  Saving model ...
	 Train_Loss: 0.5761 Train_Acc: 64.448 Val_Loss: 0.5525  BEST VAL Loss: 0.5525  Val_Acc: 69.050

Epoch 72: Validation loss decreased (0.552537 --> 0.552101).  Saving model ...
	 Train_Loss: 0.5758 Train_Acc: 64.414 Val_Loss: 0.5521  BEST VAL Loss: 0.5521  Val_Acc: 68.908

Epoch 73: Validation loss decreased (0.552101 --> 0.551743).  Saving model ...
	 Train_Loss: 0.5755 Train_Acc: 64.283 Val_Loss: 0.5517  BEST VAL Loss: 0.5517  Val_Acc: 67.217

Epoch 74: Validation loss decreased (0.551743 --> 0.551377).  Saving model ...
	 Train_Loss: 0.5752 Train_Acc: 64.403 Val_Loss: 0.5514  BEST VAL Loss: 0.5514  Val_Acc: 68.662

Epoch 75: Validation loss decreased (0.551377 --> 0.550996).  Saving model ...
	 Train_Loss: 0.5748 Train_Acc: 64.399 Val_Loss: 0.5510  BEST VAL Loss: 0.5510  Val_Acc: 67.374

Epoch 76: Validation loss decreased (0.550996 --> 0.550702).  Saving model ...
	 Train_Loss: 0.5745 Train_Acc: 64.451 Val_Loss: 0.5507  BEST VAL Loss: 0.5507  Val_Acc: 68.854

Epoch 77: Validation loss decreased (0.550702 --> 0.550300).  Saving model ...
	 Train_Loss: 0.5742 Train_Acc: 64.614 Val_Loss: 0.5503  BEST VAL Loss: 0.5503  Val_Acc: 68.878

Epoch 78: Validation loss decreased (0.550300 --> 0.549923).  Saving model ...
	 Train_Loss: 0.5739 Train_Acc: 64.334 Val_Loss: 0.5499  BEST VAL Loss: 0.5499  Val_Acc: 68.824

Epoch 79: Validation loss decreased (0.549923 --> 0.549537).  Saving model ...
	 Train_Loss: 0.5736 Train_Acc: 64.359 Val_Loss: 0.5495  BEST VAL Loss: 0.5495  Val_Acc: 67.350

Epoch 80: Validation loss decreased (0.549537 --> 0.549237).  Saving model ...
	 Train_Loss: 0.5733 Train_Acc: 64.650 Val_Loss: 0.5492  BEST VAL Loss: 0.5492  Val_Acc: 68.849

Epoch 81: Validation loss decreased (0.549237 --> 0.548881).  Saving model ...
	 Train_Loss: 0.5730 Train_Acc: 64.278 Val_Loss: 0.5489  BEST VAL Loss: 0.5489  Val_Acc: 68.180

Epoch 82: Validation loss decreased (0.548881 --> 0.548586).  Saving model ...
	 Train_Loss: 0.5727 Train_Acc: 64.482 Val_Loss: 0.5486  BEST VAL Loss: 0.5486  Val_Acc: 68.834

Epoch 83: Validation loss decreased (0.548586 --> 0.548361).  Saving model ...
	 Train_Loss: 0.5725 Train_Acc: 64.350 Val_Loss: 0.5484  BEST VAL Loss: 0.5484  Val_Acc: 68.446

Epoch 84: Validation loss decreased (0.548361 --> 0.548084).  Saving model ...
	 Train_Loss: 0.5722 Train_Acc: 64.380 Val_Loss: 0.5481  BEST VAL Loss: 0.5481  Val_Acc: 69.163

Epoch 85: Validation loss decreased (0.548084 --> 0.547748).  Saving model ...
	 Train_Loss: 0.5719 Train_Acc: 64.589 Val_Loss: 0.5477  BEST VAL Loss: 0.5477  Val_Acc: 68.977

Epoch 86: Validation loss decreased (0.547748 --> 0.547457).  Saving model ...
	 Train_Loss: 0.5717 Train_Acc: 64.637 Val_Loss: 0.5475  BEST VAL Loss: 0.5475  Val_Acc: 67.286

Epoch 87: Validation loss decreased (0.547457 --> 0.547191).  Saving model ...
	 Train_Loss: 0.5714 Train_Acc: 64.383 Val_Loss: 0.5472  BEST VAL Loss: 0.5472  Val_Acc: 68.957

Epoch 88: Validation loss decreased (0.547191 --> 0.546912).  Saving model ...
	 Train_Loss: 0.5711 Train_Acc: 64.455 Val_Loss: 0.5469  BEST VAL Loss: 0.5469  Val_Acc: 69.203

Epoch 89: Validation loss decreased (0.546912 --> 0.546699).  Saving model ...
	 Train_Loss: 0.5709 Train_Acc: 64.342 Val_Loss: 0.5467  BEST VAL Loss: 0.5467  Val_Acc: 69.036

Epoch 90: Validation loss decreased (0.546699 --> 0.546528).  Saving model ...
	 Train_Loss: 0.5706 Train_Acc: 64.465 Val_Loss: 0.5465  BEST VAL Loss: 0.5465  Val_Acc: 68.701

Epoch 91: Validation loss decreased (0.546528 --> 0.546293).  Saving model ...
	 Train_Loss: 0.5704 Train_Acc: 64.586 Val_Loss: 0.5463  BEST VAL Loss: 0.5463  Val_Acc: 66.726

Epoch 92: Validation loss decreased (0.546293 --> 0.546119).  Saving model ...
	 Train_Loss: 0.5701 Train_Acc: 64.213 Val_Loss: 0.5461  BEST VAL Loss: 0.5461  Val_Acc: 66.868

Epoch 93: Validation loss decreased (0.546119 --> 0.545861).  Saving model ...
	 Train_Loss: 0.5699 Train_Acc: 64.474 Val_Loss: 0.5459  BEST VAL Loss: 0.5459  Val_Acc: 68.539

Epoch 94: Validation loss decreased (0.545861 --> 0.545652).  Saving model ...
	 Train_Loss: 0.5696 Train_Acc: 64.312 Val_Loss: 0.5457  BEST VAL Loss: 0.5457  Val_Acc: 67.045

Epoch 95: Validation loss decreased (0.545652 --> 0.545417).  Saving model ...
	 Train_Loss: 0.5694 Train_Acc: 64.388 Val_Loss: 0.5454  BEST VAL Loss: 0.5454  Val_Acc: 67.227

Epoch 96: Validation loss decreased (0.545417 --> 0.545177).  Saving model ...
	 Train_Loss: 0.5692 Train_Acc: 64.297 Val_Loss: 0.5452  BEST VAL Loss: 0.5452  Val_Acc: 67.222

Epoch 97: Validation loss decreased (0.545177 --> 0.544965).  Saving model ...
	 Train_Loss: 0.5689 Train_Acc: 64.592 Val_Loss: 0.5450  BEST VAL Loss: 0.5450  Val_Acc: 66.819

Epoch 98: Validation loss decreased (0.544965 --> 0.544709).  Saving model ...
	 Train_Loss: 0.5687 Train_Acc: 64.317 Val_Loss: 0.5447  BEST VAL Loss: 0.5447  Val_Acc: 67.365

Epoch 99: Validation loss decreased (0.544709 --> 0.544510).  Saving model ...
	 Train_Loss: 0.5685 Train_Acc: 64.408 Val_Loss: 0.5445  BEST VAL Loss: 0.5445  Val_Acc: 66.726

LPS_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.62      0.97      0.75     82968
           1       0.92      0.37      0.53     79796

    accuracy                           0.68    162764
   macro avg       0.77      0.67      0.64    162764
weighted avg       0.76      0.68      0.64    162764

LPS_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.61      0.96      0.75     10371
           1       0.90      0.36      0.52      9975

    accuracy                           0.67     20346
   macro avg       0.75      0.66      0.63     20346
weighted avg       0.75      0.67      0.63     20346

LPS_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.61      0.96      0.75     10371
           1       0.90      0.37      0.52      9975

    accuracy                           0.67     20346
   macro avg       0.75      0.66      0.63     20346
weighted avg       0.75      0.67      0.64     20346

              precision    recall  f1-score   support

           0       0.61      0.96      0.75     10371
           1       0.90      0.37      0.52      9975

    accuracy                           0.67     20346
   macro avg       0.75      0.66      0.63     20346
weighted avg       0.75      0.67      0.64     20346

LPS_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.46      0.95      0.62     34887
           1       0.43      0.03      0.06     39687

    accuracy                           0.46     74574
   macro avg       0.45      0.49      0.34     74574
weighted avg       0.44      0.46      0.32     74574

              precision    recall  f1-score   support

           0       0.46      0.95      0.62     34887
           1       0.43      0.03      0.06     39687

    accuracy                           0.46     74574
   macro avg       0.45      0.49      0.34     74574
weighted avg       0.44      0.46      0.32     74574

completed
