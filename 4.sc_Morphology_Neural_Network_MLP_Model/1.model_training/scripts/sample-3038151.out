[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b7333929'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '56e4cdcd'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '0bf5cc6b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'fe3c5372'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: H2O2_100.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['H2O2_100.000_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (421702, 1270)
Number of total missing values across all columns: 481072
Data Subset Is Off
Wells held out for testing: ['I10' 'M08']
Wells to use for training, validation, and testing ['H04' 'I04' 'H05' 'I05' 'H10' 'H11' 'I11' 'M02' 'M03' 'M09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.196234).  Saving model ...
	 Train_Loss: 0.3077 Train_Acc: 86.359 Val_Loss: 0.1962  BEST VAL Loss: 0.1962  Val_Acc: 92.363

Epoch 1: Validation loss decreased (0.196234 --> 0.178195).  Saving model ...
	 Train_Loss: 0.2563 Train_Acc: 91.803 Val_Loss: 0.1782  BEST VAL Loss: 0.1782  Val_Acc: 93.776

Epoch 2: Validation loss decreased (0.178195 --> 0.166760).  Saving model ...
	 Train_Loss: 0.2301 Train_Acc: 93.056 Val_Loss: 0.1668  BEST VAL Loss: 0.1668  Val_Acc: 94.495

Epoch 3: Validation loss decreased (0.166760 --> 0.158629).  Saving model ...
	 Train_Loss: 0.2136 Train_Acc: 93.668 Val_Loss: 0.1586  BEST VAL Loss: 0.1586  Val_Acc: 94.968

Epoch 4: Validation loss decreased (0.158629 --> 0.152516).  Saving model ...
	 Train_Loss: 0.2019 Train_Acc: 94.024 Val_Loss: 0.1525  BEST VAL Loss: 0.1525  Val_Acc: 95.272

Epoch 5: Validation loss decreased (0.152516 --> 0.147415).  Saving model ...
	 Train_Loss: 0.1933 Train_Acc: 94.224 Val_Loss: 0.1474  BEST VAL Loss: 0.1474  Val_Acc: 95.564

Epoch 6: Validation loss decreased (0.147415 --> 0.143364).  Saving model ...
	 Train_Loss: 0.1864 Train_Acc: 94.473 Val_Loss: 0.1434  BEST VAL Loss: 0.1434  Val_Acc: 95.690

Epoch 7: Validation loss decreased (0.143364 --> 0.140126).  Saving model ...
	 Train_Loss: 0.1808 Train_Acc: 94.615 Val_Loss: 0.1401  BEST VAL Loss: 0.1401  Val_Acc: 95.716

Epoch 8: Validation loss decreased (0.140126 --> 0.137369).  Saving model ...
	 Train_Loss: 0.1762 Train_Acc: 94.699 Val_Loss: 0.1374  BEST VAL Loss: 0.1374  Val_Acc: 95.873

Epoch 9: Validation loss decreased (0.137369 --> 0.134842).  Saving model ...
	 Train_Loss: 0.1722 Train_Acc: 94.768 Val_Loss: 0.1348  BEST VAL Loss: 0.1348  Val_Acc: 95.988

Epoch 10: Validation loss decreased (0.134842 --> 0.132496).  Saving model ...
	 Train_Loss: 0.1687 Train_Acc: 94.919 Val_Loss: 0.1325  BEST VAL Loss: 0.1325  Val_Acc: 96.163

Epoch 11: Validation loss decreased (0.132496 --> 0.130530).  Saving model ...
	 Train_Loss: 0.1656 Train_Acc: 94.952 Val_Loss: 0.1305  BEST VAL Loss: 0.1305  Val_Acc: 96.048

Epoch 12: Validation loss decreased (0.130530 --> 0.128936).  Saving model ...
	 Train_Loss: 0.1629 Train_Acc: 95.014 Val_Loss: 0.1289  BEST VAL Loss: 0.1289  Val_Acc: 96.085

Epoch 13: Validation loss decreased (0.128936 --> 0.127431).  Saving model ...
	 Train_Loss: 0.1604 Train_Acc: 95.108 Val_Loss: 0.1274  BEST VAL Loss: 0.1274  Val_Acc: 96.140

Epoch 14: Validation loss decreased (0.127431 --> 0.126029).  Saving model ...
	 Train_Loss: 0.1582 Train_Acc: 95.170 Val_Loss: 0.1260  BEST VAL Loss: 0.1260  Val_Acc: 96.211

Epoch 15: Validation loss decreased (0.126029 --> 0.124757).  Saving model ...
	 Train_Loss: 0.1561 Train_Acc: 95.220 Val_Loss: 0.1248  BEST VAL Loss: 0.1248  Val_Acc: 96.174

Epoch 16: Validation loss decreased (0.124757 --> 0.123611).  Saving model ...
	 Train_Loss: 0.1543 Train_Acc: 95.201 Val_Loss: 0.1236  BEST VAL Loss: 0.1236  Val_Acc: 96.226

Epoch 17: Validation loss decreased (0.123611 --> 0.122666).  Saving model ...
	 Train_Loss: 0.1526 Train_Acc: 95.259 Val_Loss: 0.1227  BEST VAL Loss: 0.1227  Val_Acc: 96.186

Epoch 18: Validation loss decreased (0.122666 --> 0.121732).  Saving model ...
	 Train_Loss: 0.1510 Train_Acc: 95.288 Val_Loss: 0.1217  BEST VAL Loss: 0.1217  Val_Acc: 96.340

Epoch 19: Validation loss decreased (0.121732 --> 0.120939).  Saving model ...
	 Train_Loss: 0.1495 Train_Acc: 95.277 Val_Loss: 0.1209  BEST VAL Loss: 0.1209  Val_Acc: 96.214

Epoch 20: Validation loss decreased (0.120939 --> 0.120163).  Saving model ...
	 Train_Loss: 0.1482 Train_Acc: 95.331 Val_Loss: 0.1202  BEST VAL Loss: 0.1202  Val_Acc: 96.283

Epoch 21: Validation loss decreased (0.120163 --> 0.119474).  Saving model ...
	 Train_Loss: 0.1470 Train_Acc: 95.340 Val_Loss: 0.1195  BEST VAL Loss: 0.1195  Val_Acc: 96.254

Epoch 22: Validation loss decreased (0.119474 --> 0.118800).  Saving model ...
	 Train_Loss: 0.1458 Train_Acc: 95.419 Val_Loss: 0.1188  BEST VAL Loss: 0.1188  Val_Acc: 96.283

Epoch 23: Validation loss decreased (0.118800 --> 0.118131).  Saving model ...
	 Train_Loss: 0.1447 Train_Acc: 95.407 Val_Loss: 0.1181  BEST VAL Loss: 0.1181  Val_Acc: 96.257

Epoch 24: Validation loss decreased (0.118131 --> 0.117492).  Saving model ...
	 Train_Loss: 0.1437 Train_Acc: 95.442 Val_Loss: 0.1175  BEST VAL Loss: 0.1175  Val_Acc: 96.303

Epoch 25: Validation loss decreased (0.117492 --> 0.116914).  Saving model ...
	 Train_Loss: 0.1427 Train_Acc: 95.484 Val_Loss: 0.1169  BEST VAL Loss: 0.1169  Val_Acc: 96.303

Epoch 26: Validation loss decreased (0.116914 --> 0.116382).  Saving model ...
	 Train_Loss: 0.1418 Train_Acc: 95.479 Val_Loss: 0.1164  BEST VAL Loss: 0.1164  Val_Acc: 96.295

Epoch 27: Validation loss decreased (0.116382 --> 0.115847).  Saving model ...
	 Train_Loss: 0.1409 Train_Acc: 95.517 Val_Loss: 0.1158  BEST VAL Loss: 0.1158  Val_Acc: 96.392

Epoch 28: Validation loss decreased (0.115847 --> 0.115378).  Saving model ...
	 Train_Loss: 0.1400 Train_Acc: 95.524 Val_Loss: 0.1154  BEST VAL Loss: 0.1154  Val_Acc: 96.329

Epoch 29: Validation loss decreased (0.115378 --> 0.114877).  Saving model ...
	 Train_Loss: 0.1392 Train_Acc: 95.564 Val_Loss: 0.1149  BEST VAL Loss: 0.1149  Val_Acc: 96.401

Epoch 30: Validation loss decreased (0.114877 --> 0.114404).  Saving model ...
	 Train_Loss: 0.1385 Train_Acc: 95.554 Val_Loss: 0.1144  BEST VAL Loss: 0.1144  Val_Acc: 96.472

Epoch 31: Validation loss decreased (0.114404 --> 0.113939).  Saving model ...
	 Train_Loss: 0.1378 Train_Acc: 95.604 Val_Loss: 0.1139  BEST VAL Loss: 0.1139  Val_Acc: 96.446

Epoch 32: Validation loss decreased (0.113939 --> 0.113577).  Saving model ...
	 Train_Loss: 0.1371 Train_Acc: 95.595 Val_Loss: 0.1136  BEST VAL Loss: 0.1136  Val_Acc: 96.372

Epoch 33: Validation loss decreased (0.113577 --> 0.113185).  Saving model ...
	 Train_Loss: 0.1364 Train_Acc: 95.595 Val_Loss: 0.1132  BEST VAL Loss: 0.1132  Val_Acc: 96.361

Epoch 34: Validation loss decreased (0.113185 --> 0.112840).  Saving model ...
	 Train_Loss: 0.1358 Train_Acc: 95.635 Val_Loss: 0.1128  BEST VAL Loss: 0.1128  Val_Acc: 96.401

Epoch 35: Validation loss decreased (0.112840 --> 0.112539).  Saving model ...
	 Train_Loss: 0.1352 Train_Acc: 95.634 Val_Loss: 0.1125  BEST VAL Loss: 0.1125  Val_Acc: 96.295

Epoch 36: Validation loss decreased (0.112539 --> 0.112189).  Saving model ...
	 Train_Loss: 0.1346 Train_Acc: 95.620 Val_Loss: 0.1122  BEST VAL Loss: 0.1122  Val_Acc: 96.507

Epoch 37: Validation loss decreased (0.112189 --> 0.111888).  Saving model ...
	 Train_Loss: 0.1340 Train_Acc: 95.614 Val_Loss: 0.1119  BEST VAL Loss: 0.1119  Val_Acc: 96.449

Epoch 38: Validation loss decreased (0.111888 --> 0.111563).  Saving model ...
	 Train_Loss: 0.1335 Train_Acc: 95.626 Val_Loss: 0.1116  BEST VAL Loss: 0.1116  Val_Acc: 96.461

Epoch 39: Validation loss decreased (0.111563 --> 0.111268).  Saving model ...
	 Train_Loss: 0.1330 Train_Acc: 95.655 Val_Loss: 0.1113  BEST VAL Loss: 0.1113  Val_Acc: 96.478

Epoch 40: Validation loss decreased (0.111268 --> 0.110983).  Saving model ...
	 Train_Loss: 0.1325 Train_Acc: 95.703 Val_Loss: 0.1110  BEST VAL Loss: 0.1110  Val_Acc: 96.361

Epoch 41: Validation loss decreased (0.110983 --> 0.110689).  Saving model ...
	 Train_Loss: 0.1320 Train_Acc: 95.668 Val_Loss: 0.1107  BEST VAL Loss: 0.1107  Val_Acc: 96.429

Epoch 42: Validation loss decreased (0.110689 --> 0.110430).  Saving model ...
	 Train_Loss: 0.1315 Train_Acc: 95.710 Val_Loss: 0.1104  BEST VAL Loss: 0.1104  Val_Acc: 96.467

Epoch 43: Validation loss decreased (0.110430 --> 0.110210).  Saving model ...
	 Train_Loss: 0.1311 Train_Acc: 95.715 Val_Loss: 0.1102  BEST VAL Loss: 0.1102  Val_Acc: 96.409

Epoch 44: Validation loss decreased (0.110210 --> 0.109977).  Saving model ...
	 Train_Loss: 0.1306 Train_Acc: 95.715 Val_Loss: 0.1100  BEST VAL Loss: 0.1100  Val_Acc: 96.398

Epoch 45: Validation loss decreased (0.109977 --> 0.109778).  Saving model ...
	 Train_Loss: 0.1302 Train_Acc: 95.706 Val_Loss: 0.1098  BEST VAL Loss: 0.1098  Val_Acc: 96.381

Epoch 46: Validation loss decreased (0.109778 --> 0.109545).  Saving model ...
	 Train_Loss: 0.1298 Train_Acc: 95.731 Val_Loss: 0.1095  BEST VAL Loss: 0.1095  Val_Acc: 96.444

Epoch 47: Validation loss decreased (0.109545 --> 0.109364).  Saving model ...
	 Train_Loss: 0.1294 Train_Acc: 95.779 Val_Loss: 0.1094  BEST VAL Loss: 0.1094  Val_Acc: 96.504

Epoch 48: Validation loss decreased (0.109364 --> 0.109187).  Saving model ...
	 Train_Loss: 0.1290 Train_Acc: 95.688 Val_Loss: 0.1092  BEST VAL Loss: 0.1092  Val_Acc: 96.449

Epoch 49: Validation loss decreased (0.109187 --> 0.108986).  Saving model ...
	 Train_Loss: 0.1287 Train_Acc: 95.796 Val_Loss: 0.1090  BEST VAL Loss: 0.1090  Val_Acc: 96.467

Epoch 50: Validation loss decreased (0.108986 --> 0.108781).  Saving model ...
	 Train_Loss: 0.1283 Train_Acc: 95.849 Val_Loss: 0.1088  BEST VAL Loss: 0.1088  Val_Acc: 96.587

Epoch 51: Validation loss decreased (0.108781 --> 0.108605).  Saving model ...
	 Train_Loss: 0.1279 Train_Acc: 95.736 Val_Loss: 0.1086  BEST VAL Loss: 0.1086  Val_Acc: 96.561

Epoch 52: Validation loss decreased (0.108605 --> 0.108403).  Saving model ...
	 Train_Loss: 0.1276 Train_Acc: 95.798 Val_Loss: 0.1084  BEST VAL Loss: 0.1084  Val_Acc: 96.547

Epoch 53: Validation loss decreased (0.108403 --> 0.108218).  Saving model ...
	 Train_Loss: 0.1272 Train_Acc: 95.840 Val_Loss: 0.1082  BEST VAL Loss: 0.1082  Val_Acc: 96.555

Epoch 54: Validation loss decreased (0.108218 --> 0.108058).  Saving model ...
	 Train_Loss: 0.1269 Train_Acc: 95.797 Val_Loss: 0.1081  BEST VAL Loss: 0.1081  Val_Acc: 96.498

Epoch 55: Validation loss decreased (0.108058 --> 0.107918).  Saving model ...
	 Train_Loss: 0.1266 Train_Acc: 95.731 Val_Loss: 0.1079  BEST VAL Loss: 0.1079  Val_Acc: 96.521

Epoch 56: Validation loss decreased (0.107918 --> 0.107760).  Saving model ...
	 Train_Loss: 0.1263 Train_Acc: 95.805 Val_Loss: 0.1078  BEST VAL Loss: 0.1078  Val_Acc: 96.544

Epoch 57: Validation loss decreased (0.107760 --> 0.107596).  Saving model ...
	 Train_Loss: 0.1260 Train_Acc: 95.820 Val_Loss: 0.1076  BEST VAL Loss: 0.1076  Val_Acc: 96.561

Epoch 58: Validation loss decreased (0.107596 --> 0.107461).  Saving model ...
	 Train_Loss: 0.1257 Train_Acc: 95.808 Val_Loss: 0.1075  BEST VAL Loss: 0.1075  Val_Acc: 96.441

Epoch 59: Validation loss decreased (0.107461 --> 0.107311).  Saving model ...
	 Train_Loss: 0.1254 Train_Acc: 95.794 Val_Loss: 0.1073  BEST VAL Loss: 0.1073  Val_Acc: 96.521

Epoch 60: Validation loss decreased (0.107311 --> 0.107191).  Saving model ...
	 Train_Loss: 0.1251 Train_Acc: 95.835 Val_Loss: 0.1072  BEST VAL Loss: 0.1072  Val_Acc: 96.475

Epoch 61: Validation loss decreased (0.107191 --> 0.107078).  Saving model ...
	 Train_Loss: 0.1249 Train_Acc: 95.868 Val_Loss: 0.1071  BEST VAL Loss: 0.1071  Val_Acc: 96.527

Epoch 62: Validation loss decreased (0.107078 --> 0.106939).  Saving model ...
	 Train_Loss: 0.1246 Train_Acc: 95.835 Val_Loss: 0.1069  BEST VAL Loss: 0.1069  Val_Acc: 96.530

Epoch 63: Validation loss decreased (0.106939 --> 0.106803).  Saving model ...
	 Train_Loss: 0.1243 Train_Acc: 95.831 Val_Loss: 0.1068  BEST VAL Loss: 0.1068  Val_Acc: 96.581

Epoch 64: Validation loss decreased (0.106803 --> 0.106664).  Saving model ...
	 Train_Loss: 0.1241 Train_Acc: 95.916 Val_Loss: 0.1067  BEST VAL Loss: 0.1067  Val_Acc: 96.587

Epoch 65: Validation loss decreased (0.106664 --> 0.106530).  Saving model ...
	 Train_Loss: 0.1238 Train_Acc: 95.886 Val_Loss: 0.1065  BEST VAL Loss: 0.1065  Val_Acc: 96.601

Epoch 66: Validation loss decreased (0.106530 --> 0.106419).  Saving model ...
	 Train_Loss: 0.1236 Train_Acc: 95.882 Val_Loss: 0.1064  BEST VAL Loss: 0.1064  Val_Acc: 96.538

Epoch 67: Validation loss decreased (0.106419 --> 0.106299).  Saving model ...
	 Train_Loss: 0.1233 Train_Acc: 95.943 Val_Loss: 0.1063  BEST VAL Loss: 0.1063  Val_Acc: 96.570

Epoch 68: Validation loss decreased (0.106299 --> 0.106181).  Saving model ...
	 Train_Loss: 0.1231 Train_Acc: 95.916 Val_Loss: 0.1062  BEST VAL Loss: 0.1062  Val_Acc: 96.587

Epoch 69: Validation loss decreased (0.106181 --> 0.106068).  Saving model ...
	 Train_Loss: 0.1229 Train_Acc: 95.946 Val_Loss: 0.1061  BEST VAL Loss: 0.1061  Val_Acc: 96.578

Epoch 70: Validation loss decreased (0.106068 --> 0.105960).  Saving model ...
	 Train_Loss: 0.1226 Train_Acc: 95.936 Val_Loss: 0.1060  BEST VAL Loss: 0.1060  Val_Acc: 96.553

Epoch 71: Validation loss decreased (0.105960 --> 0.105860).  Saving model ...
	 Train_Loss: 0.1224 Train_Acc: 95.889 Val_Loss: 0.1059  BEST VAL Loss: 0.1059  Val_Acc: 96.578

Epoch 72: Validation loss decreased (0.105860 --> 0.105757).  Saving model ...
	 Train_Loss: 0.1222 Train_Acc: 95.936 Val_Loss: 0.1058  BEST VAL Loss: 0.1058  Val_Acc: 96.532

Epoch 73: Validation loss decreased (0.105757 --> 0.105664).  Saving model ...
	 Train_Loss: 0.1220 Train_Acc: 95.908 Val_Loss: 0.1057  BEST VAL Loss: 0.1057  Val_Acc: 96.535

Epoch 74: Validation loss decreased (0.105664 --> 0.105565).  Saving model ...
	 Train_Loss: 0.1218 Train_Acc: 95.899 Val_Loss: 0.1056  BEST VAL Loss: 0.1056  Val_Acc: 96.590

Epoch 75: Validation loss decreased (0.105565 --> 0.105463).  Saving model ...
	 Train_Loss: 0.1216 Train_Acc: 95.897 Val_Loss: 0.1055  BEST VAL Loss: 0.1055  Val_Acc: 96.633

Epoch 76: Validation loss decreased (0.105463 --> 0.105377).  Saving model ...
	 Train_Loss: 0.1214 Train_Acc: 95.937 Val_Loss: 0.1054  BEST VAL Loss: 0.1054  Val_Acc: 96.561

Epoch 77: Validation loss decreased (0.105377 --> 0.105302).  Saving model ...
	 Train_Loss: 0.1212 Train_Acc: 95.909 Val_Loss: 0.1053  BEST VAL Loss: 0.1053  Val_Acc: 96.512

Epoch 78: Validation loss decreased (0.105302 --> 0.105217).  Saving model ...
	 Train_Loss: 0.1210 Train_Acc: 95.880 Val_Loss: 0.1052  BEST VAL Loss: 0.1052  Val_Acc: 96.495

Epoch 79: Validation loss decreased (0.105217 --> 0.105129).  Saving model ...
	 Train_Loss: 0.1208 Train_Acc: 95.891 Val_Loss: 0.1051  BEST VAL Loss: 0.1051  Val_Acc: 96.544

Epoch 80: Validation loss decreased (0.105129 --> 0.105061).  Saving model ...
	 Train_Loss: 0.1206 Train_Acc: 95.949 Val_Loss: 0.1051  BEST VAL Loss: 0.1051  Val_Acc: 96.504

Epoch 81: Validation loss decreased (0.105061 --> 0.105000).  Saving model ...
	 Train_Loss: 0.1204 Train_Acc: 95.932 Val_Loss: 0.1050  BEST VAL Loss: 0.1050  Val_Acc: 96.510

Epoch 82: Validation loss decreased (0.105000 --> 0.104924).  Saving model ...
	 Train_Loss: 0.1202 Train_Acc: 95.883 Val_Loss: 0.1049  BEST VAL Loss: 0.1049  Val_Acc: 96.553

Epoch 83: Validation loss decreased (0.104924 --> 0.104834).  Saving model ...
	 Train_Loss: 0.1201 Train_Acc: 95.922 Val_Loss: 0.1048  BEST VAL Loss: 0.1048  Val_Acc: 96.492

Epoch 84: Validation loss decreased (0.104834 --> 0.104765).  Saving model ...
	 Train_Loss: 0.1199 Train_Acc: 95.935 Val_Loss: 0.1048  BEST VAL Loss: 0.1048  Val_Acc: 96.481

Epoch 85: Validation loss decreased (0.104765 --> 0.104693).  Saving model ...
	 Train_Loss: 0.1197 Train_Acc: 95.950 Val_Loss: 0.1047  BEST VAL Loss: 0.1047  Val_Acc: 96.538

Epoch 86: Validation loss decreased (0.104693 --> 0.104598).  Saving model ...
	 Train_Loss: 0.1196 Train_Acc: 95.897 Val_Loss: 0.1046  BEST VAL Loss: 0.1046  Val_Acc: 96.598

Epoch 87: Validation loss decreased (0.104598 --> 0.104528).  Saving model ...
	 Train_Loss: 0.1194 Train_Acc: 95.993 Val_Loss: 0.1045  BEST VAL Loss: 0.1045  Val_Acc: 96.558

Epoch 88: Validation loss decreased (0.104528 --> 0.104463).  Saving model ...
	 Train_Loss: 0.1193 Train_Acc: 95.979 Val_Loss: 0.1045  BEST VAL Loss: 0.1045  Val_Acc: 96.544

Epoch 89: Validation loss decreased (0.104463 --> 0.104391).  Saving model ...
	 Train_Loss: 0.1191 Train_Acc: 95.985 Val_Loss: 0.1044  BEST VAL Loss: 0.1044  Val_Acc: 96.541

Epoch 90: Validation loss decreased (0.104391 --> 0.104318).  Saving model ...
	 Train_Loss: 0.1189 Train_Acc: 95.951 Val_Loss: 0.1043  BEST VAL Loss: 0.1043  Val_Acc: 96.664

Epoch 91: Validation loss decreased (0.104318 --> 0.104250).  Saving model ...
	 Train_Loss: 0.1188 Train_Acc: 95.951 Val_Loss: 0.1043  BEST VAL Loss: 0.1043  Val_Acc: 96.532

Epoch 92: Validation loss decreased (0.104250 --> 0.104189).  Saving model ...
	 Train_Loss: 0.1186 Train_Acc: 95.977 Val_Loss: 0.1042  BEST VAL Loss: 0.1042  Val_Acc: 96.561

Epoch 93: Validation loss decreased (0.104189 --> 0.104121).  Saving model ...
	 Train_Loss: 0.1185 Train_Acc: 95.988 Val_Loss: 0.1041  BEST VAL Loss: 0.1041  Val_Acc: 96.564

Epoch 94: Validation loss decreased (0.104121 --> 0.104071).  Saving model ...
	 Train_Loss: 0.1183 Train_Acc: 95.999 Val_Loss: 0.1041  BEST VAL Loss: 0.1041  Val_Acc: 96.573

Epoch 95: Validation loss decreased (0.104071 --> 0.104027).  Saving model ...
	 Train_Loss: 0.1182 Train_Acc: 96.000 Val_Loss: 0.1040  BEST VAL Loss: 0.1040  Val_Acc: 96.561

Epoch 96: Validation loss decreased (0.104027 --> 0.103969).  Saving model ...
	 Train_Loss: 0.1180 Train_Acc: 95.936 Val_Loss: 0.1040  BEST VAL Loss: 0.1040  Val_Acc: 96.584

Epoch 97: Validation loss decreased (0.103969 --> 0.103924).  Saving model ...
	 Train_Loss: 0.1179 Train_Acc: 95.965 Val_Loss: 0.1039  BEST VAL Loss: 0.1039  Val_Acc: 96.567

Epoch 98: Validation loss decreased (0.103924 --> 0.103882).  Saving model ...
	 Train_Loss: 0.1178 Train_Acc: 96.006 Val_Loss: 0.1039  BEST VAL Loss: 0.1039  Val_Acc: 96.547

Epoch 99: Validation loss decreased (0.103882 --> 0.103828).  Saving model ...
	 Train_Loss: 0.1176 Train_Acc: 95.935 Val_Loss: 0.1038  BEST VAL Loss: 0.1038  Val_Acc: 96.627

H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.98      0.98    169562
           1       0.97      0.97      0.97    109598

    accuracy                           0.98    279160
   macro avg       0.97      0.97      0.97    279160
weighted avg       0.98      0.98      0.98    279160

H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.97      0.97     21195
           1       0.96      0.96      0.96     13700

    accuracy                           0.97     34895
   macro avg       0.96      0.96      0.96     34895
weighted avg       0.97      0.97      0.97     34895

H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.97      0.97     21195
           1       0.96      0.95      0.96     13700

    accuracy                           0.96     34895
   macro avg       0.96      0.96      0.96     34895
weighted avg       0.96      0.96      0.96     34895

              precision    recall  f1-score   support

           0       0.97      0.97      0.97     21195
           1       0.96      0.95      0.96     13700

    accuracy                           0.96     34895
   macro avg       0.96      0.96      0.96     34895
weighted avg       0.96      0.96      0.96     34895

H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.87      1.00      0.93     28584
           1       1.00      0.90      0.95     44168

    accuracy                           0.94     72752
   macro avg       0.93      0.95      0.94     72752
weighted avg       0.95      0.94      0.94     72752

              precision    recall  f1-score   support

           0       0.87      1.00      0.93     28584
           1       1.00      0.90      0.95     44168

    accuracy                           0.94     72752
   macro avg       0.93      0.95      0.94     72752
weighted avg       0.95      0.94      0.94     72752

completed
