[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd3b5d7f6'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '35013bac'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'adeee900'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'cf31fa78'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_1.000_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_1.000_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (32445, 1276)
Number of total missing values across all columns: 64890
Data Subset Is Off
Wells held out for testing: ['D20' 'J16']
Wells to use for training, validation, and testing ['D16' 'D17' 'D21' 'J17' 'J20' 'J21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.393478).  Saving model ...
	 Train_Loss: 0.5196 Train_Acc: 73.188 Val_Loss: 0.3935  BEST VAL Loss: 0.3935  Val_Acc: 82.299

Epoch 1: Validation loss decreased (0.393478 --> 0.347278).  Saving model ...
	 Train_Loss: 0.4451 Train_Acc: 82.506 Val_Loss: 0.3473  BEST VAL Loss: 0.3473  Val_Acc: 87.593

Epoch 2: Validation loss decreased (0.347278 --> 0.313629).  Saving model ...
	 Train_Loss: 0.3988 Train_Acc: 86.012 Val_Loss: 0.3136  BEST VAL Loss: 0.3136  Val_Acc: 89.661

Epoch 3: Validation loss decreased (0.313629 --> 0.291293).  Saving model ...
	 Train_Loss: 0.3644 Train_Acc: 88.044 Val_Loss: 0.2913  BEST VAL Loss: 0.2913  Val_Acc: 90.447

Epoch 4: Validation loss decreased (0.291293 --> 0.277436).  Saving model ...
	 Train_Loss: 0.3410 Train_Acc: 88.804 Val_Loss: 0.2774  BEST VAL Loss: 0.2774  Val_Acc: 91.026

Epoch 5: Validation loss decreased (0.277436 --> 0.266978).  Saving model ...
	 Train_Loss: 0.3233 Train_Acc: 88.768 Val_Loss: 0.2670  BEST VAL Loss: 0.2670  Val_Acc: 91.646

Epoch 6: Validation loss decreased (0.266978 --> 0.260176).  Saving model ...
	 Train_Loss: 0.3091 Train_Acc: 89.642 Val_Loss: 0.2602  BEST VAL Loss: 0.2602  Val_Acc: 91.356

Epoch 7: Validation loss decreased (0.260176 --> 0.253568).  Saving model ...
	 Train_Loss: 0.2977 Train_Acc: 89.916 Val_Loss: 0.2536  BEST VAL Loss: 0.2536  Val_Acc: 91.811

Epoch 8: Validation loss decreased (0.253568 --> 0.251195).  Saving model ...
	 Train_Loss: 0.2882 Train_Acc: 89.937 Val_Loss: 0.2512  BEST VAL Loss: 0.2512  Val_Acc: 91.274

Epoch 9: Validation loss decreased (0.251195 --> 0.249431).  Saving model ...
	 Train_Loss: 0.2800 Train_Acc: 89.813 Val_Loss: 0.2494  BEST VAL Loss: 0.2494  Val_Acc: 91.977

Epoch 10: Validation loss decreased (0.249431 --> 0.247276).  Saving model ...
	 Train_Loss: 0.2733 Train_Acc: 90.009 Val_Loss: 0.2473  BEST VAL Loss: 0.2473  Val_Acc: 92.184

Epoch 11: Validation loss decreased (0.247276 --> 0.244362).  Saving model ...
	 Train_Loss: 0.2670 Train_Acc: 90.759 Val_Loss: 0.2444  BEST VAL Loss: 0.2444  Val_Acc: 92.101

Epoch 12: Validation loss decreased (0.244362 --> 0.242613).  Saving model ...
	 Train_Loss: 0.2611 Train_Acc: 90.759 Val_Loss: 0.2426  BEST VAL Loss: 0.2426  Val_Acc: 92.018

Epoch 13: Validation loss decreased (0.242613 --> 0.242550).  Saving model ...
	 Train_Loss: 0.2558 Train_Acc: 90.888 Val_Loss: 0.2426  BEST VAL Loss: 0.2426  Val_Acc: 91.853

Epoch 14: Validation loss decreased (0.242550 --> 0.242296).  Saving model ...
	 Train_Loss: 0.2510 Train_Acc: 90.961 Val_Loss: 0.2423  BEST VAL Loss: 0.2423  Val_Acc: 91.605

Epoch 15: Validation loss decreased (0.242296 --> 0.242063).  Saving model ...
	 Train_Loss: 0.2471 Train_Acc: 90.707 Val_Loss: 0.2421  BEST VAL Loss: 0.2421  Val_Acc: 91.729

Epoch 16: Validation loss decreased (0.242063 --> 0.240594).  Saving model ...
	 Train_Loss: 0.2432 Train_Acc: 91.126 Val_Loss: 0.2406  BEST VAL Loss: 0.2406  Val_Acc: 92.266

Epoch 17: Validation loss decreased (0.240594 --> 0.240422).  Saving model ...
	 Train_Loss: 0.2396 Train_Acc: 91.421 Val_Loss: 0.2404  BEST VAL Loss: 0.2404  Val_Acc: 92.225

Epoch 18: Validation loss did not decrease
	 Train_Loss: 0.2364 Train_Acc: 91.049 Val_Loss: 0.2409  BEST VAL Loss: 0.2404  Val_Acc: 91.315

Epoch 19: Validation loss decreased (0.240422 --> 0.240362).  Saving model ...
	 Train_Loss: 0.2338 Train_Acc: 91.188 Val_Loss: 0.2404  BEST VAL Loss: 0.2404  Val_Acc: 91.398

Epoch 20: Validation loss decreased (0.240362 --> 0.239329).  Saving model ...
	 Train_Loss: 0.2311 Train_Acc: 91.204 Val_Loss: 0.2393  BEST VAL Loss: 0.2393  Val_Acc: 92.018

Epoch 21: Validation loss did not decrease
	 Train_Loss: 0.2283 Train_Acc: 91.437 Val_Loss: 0.2398  BEST VAL Loss: 0.2393  Val_Acc: 92.225

Epoch 22: Validation loss decreased (0.239329 --> 0.238625).  Saving model ...
	 Train_Loss: 0.2257 Train_Acc: 91.690 Val_Loss: 0.2386  BEST VAL Loss: 0.2386  Val_Acc: 92.060

Epoch 23: Validation loss decreased (0.238625 --> 0.238443).  Saving model ...
	 Train_Loss: 0.2231 Train_Acc: 91.695 Val_Loss: 0.2384  BEST VAL Loss: 0.2384  Val_Acc: 92.184

Epoch 24: Validation loss decreased (0.238443 --> 0.238394).  Saving model ...
	 Train_Loss: 0.2206 Train_Acc: 91.747 Val_Loss: 0.2384  BEST VAL Loss: 0.2384  Val_Acc: 92.018

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.2183 Train_Acc: 91.861 Val_Loss: 0.2385  BEST VAL Loss: 0.2384  Val_Acc: 92.308

Epoch 26: Validation loss decreased (0.238394 --> 0.238313).  Saving model ...
	 Train_Loss: 0.2159 Train_Acc: 91.902 Val_Loss: 0.2383  BEST VAL Loss: 0.2383  Val_Acc: 92.018

Epoch 27: Validation loss decreased (0.238313 --> 0.237522).  Saving model ...
	 Train_Loss: 0.2138 Train_Acc: 92.021 Val_Loss: 0.2375  BEST VAL Loss: 0.2375  Val_Acc: 92.887

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.2119 Train_Acc: 92.155 Val_Loss: 0.2375  BEST VAL Loss: 0.2375  Val_Acc: 92.887

Epoch 29: Validation loss decreased (0.237522 --> 0.237403).  Saving model ...
	 Train_Loss: 0.2101 Train_Acc: 92.114 Val_Loss: 0.2374  BEST VAL Loss: 0.2374  Val_Acc: 91.853

Epoch 30: Validation loss decreased (0.237403 --> 0.237254).  Saving model ...
	 Train_Loss: 0.2086 Train_Acc: 91.716 Val_Loss: 0.2373  BEST VAL Loss: 0.2373  Val_Acc: 92.018

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.2070 Train_Acc: 91.757 Val_Loss: 0.2379  BEST VAL Loss: 0.2373  Val_Acc: 92.266

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.2055 Train_Acc: 92.093 Val_Loss: 0.2384  BEST VAL Loss: 0.2373  Val_Acc: 92.390

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.2038 Train_Acc: 92.404 Val_Loss: 0.2394  BEST VAL Loss: 0.2373  Val_Acc: 91.977

Epoch 34: Validation loss did not decrease
	 Train_Loss: 0.2021 Train_Acc: 92.621 Val_Loss: 0.2400  BEST VAL Loss: 0.2373  Val_Acc: 92.060

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.2007 Train_Acc: 91.990 Val_Loss: 0.2404  BEST VAL Loss: 0.2373  Val_Acc: 92.184

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.1995 Train_Acc: 92.052 Val_Loss: 0.2404  BEST VAL Loss: 0.2373  Val_Acc: 91.853

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.1982 Train_Acc: 92.373 Val_Loss: 0.2401  BEST VAL Loss: 0.2373  Val_Acc: 92.804

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.1968 Train_Acc: 92.326 Val_Loss: 0.2413  BEST VAL Loss: 0.2373  Val_Acc: 92.763

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.1956 Train_Acc: 92.342 Val_Loss: 0.2416  BEST VAL Loss: 0.2373  Val_Acc: 92.556

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.1945 Train_Acc: 91.954 Val_Loss: 0.2428  BEST VAL Loss: 0.2373  Val_Acc: 92.349

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.1934 Train_Acc: 92.052 Val_Loss: 0.2427  BEST VAL Loss: 0.2373  Val_Acc: 92.845

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.1924 Train_Acc: 92.186 Val_Loss: 0.2436  BEST VAL Loss: 0.2373  Val_Acc: 92.473

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.1915 Train_Acc: 91.768 Val_Loss: 0.2444  BEST VAL Loss: 0.2373  Val_Acc: 92.390

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.1905 Train_Acc: 91.886 Val_Loss: 0.2449  BEST VAL Loss: 0.2373  Val_Acc: 92.721

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.1895 Train_Acc: 92.124 Val_Loss: 0.2460  BEST VAL Loss: 0.2373  Val_Acc: 93.093

Epoch 46: Validation loss did not decrease
Early stopped at epoch : 46
LPS_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.96      0.96      0.96      9832
           1       0.96      0.96      0.96      9506

    accuracy                           0.96     19338
   macro avg       0.96      0.96      0.96     19338
weighted avg       0.96      0.96      0.96     19338

LPS_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.92      0.93      0.92      1229
           1       0.92      0.91      0.92      1189

    accuracy                           0.92      2418
   macro avg       0.92      0.92      0.92      2418
weighted avg       0.92      0.92      0.92      2418

LPS_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.92      0.93      0.93      1229
           1       0.93      0.92      0.92      1189

    accuracy                           0.93      2418
   macro avg       0.93      0.93      0.93      2418
weighted avg       0.93      0.93      0.93      2418

              precision    recall  f1-score   support

           0       0.92      0.93      0.93      1229
           1       0.93      0.92      0.92      1189

    accuracy                           0.93      2418
   macro avg       0.93      0.93      0.93      2418
weighted avg       0.93      0.93      0.93      2418

LPS_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.98      0.97      4168
           1       0.98      0.97      0.97      4103

    accuracy                           0.97      8271
   macro avg       0.97      0.97      0.97      8271
weighted avg       0.97      0.97      0.97      8271

              precision    recall  f1-score   support

           0       0.97      0.98      0.97      4168
           1       0.98      0.97      0.97      4103

    accuracy                           0.97      8271
   macro avg       0.97      0.97      0.97      8271
weighted avg       0.97      0.97      0.97      8271

completed
