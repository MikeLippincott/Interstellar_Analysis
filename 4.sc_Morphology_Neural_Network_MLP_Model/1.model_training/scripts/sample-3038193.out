[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'fd8899a8'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'a7bbe27b'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'fb3c9d5d'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '2c706ddf'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_0.100_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_0.100_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (298032, 1270)
Number of total missing values across all columns: 596064
Data Subset Is Off
Wells held out for testing: ['C08' 'J08']
Wells to use for training, validation, and testing ['C02' 'C03' 'C09' 'J02' 'J03' 'J09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.687390).  Saving model ...
	 Train_Loss: 0.6900 Train_Acc: 53.679 Val_Loss: 0.6874  BEST VAL Loss: 0.6874  Val_Acc: 54.420

Epoch 1: Validation loss decreased (0.687390 --> 0.686019).  Saving model ...
	 Train_Loss: 0.6882 Train_Acc: 55.102 Val_Loss: 0.6860  BEST VAL Loss: 0.6860  Val_Acc: 55.465

Epoch 2: Validation loss decreased (0.686019 --> 0.684356).  Saving model ...
	 Train_Loss: 0.6866 Train_Acc: 56.124 Val_Loss: 0.6844  BEST VAL Loss: 0.6844  Val_Acc: 56.669

Epoch 3: Validation loss decreased (0.684356 --> 0.682521).  Saving model ...
	 Train_Loss: 0.6851 Train_Acc: 56.970 Val_Loss: 0.6825  BEST VAL Loss: 0.6825  Val_Acc: 57.514

Epoch 4: Validation loss decreased (0.682521 --> 0.680341).  Saving model ...
	 Train_Loss: 0.6834 Train_Acc: 57.800 Val_Loss: 0.6803  BEST VAL Loss: 0.6803  Val_Acc: 58.855

Epoch 5: Validation loss decreased (0.680341 --> 0.678138).  Saving model ...
	 Train_Loss: 0.6817 Train_Acc: 58.346 Val_Loss: 0.6781  BEST VAL Loss: 0.6781  Val_Acc: 59.453

Epoch 6: Validation loss decreased (0.678138 --> 0.676113).  Saving model ...
	 Train_Loss: 0.6800 Train_Acc: 58.961 Val_Loss: 0.6761  BEST VAL Loss: 0.6761  Val_Acc: 59.838

Epoch 7: Validation loss decreased (0.676113 --> 0.674206).  Saving model ...
	 Train_Loss: 0.6783 Train_Acc: 59.525 Val_Loss: 0.6742  BEST VAL Loss: 0.6742  Val_Acc: 60.604

Epoch 8: Validation loss decreased (0.674206 --> 0.672336).  Saving model ...
	 Train_Loss: 0.6767 Train_Acc: 59.940 Val_Loss: 0.6723  BEST VAL Loss: 0.6723  Val_Acc: 61.299

Epoch 9: Validation loss decreased (0.672336 --> 0.670643).  Saving model ...
	 Train_Loss: 0.6751 Train_Acc: 60.437 Val_Loss: 0.6706  BEST VAL Loss: 0.6706  Val_Acc: 61.529

Epoch 10: Validation loss decreased (0.670643 --> 0.669106).  Saving model ...
	 Train_Loss: 0.6737 Train_Acc: 60.729 Val_Loss: 0.6691  BEST VAL Loss: 0.6691  Val_Acc: 61.724

Epoch 11: Validation loss decreased (0.669106 --> 0.667584).  Saving model ...
	 Train_Loss: 0.6723 Train_Acc: 61.104 Val_Loss: 0.6676  BEST VAL Loss: 0.6676  Val_Acc: 61.976

Epoch 12: Validation loss decreased (0.667584 --> 0.666138).  Saving model ...
	 Train_Loss: 0.6710 Train_Acc: 61.278 Val_Loss: 0.6661  BEST VAL Loss: 0.6661  Val_Acc: 62.397

Epoch 13: Validation loss decreased (0.666138 --> 0.664877).  Saving model ...
	 Train_Loss: 0.6697 Train_Acc: 61.648 Val_Loss: 0.6649  BEST VAL Loss: 0.6649  Val_Acc: 62.104

Epoch 14: Validation loss decreased (0.664877 --> 0.663522).  Saving model ...
	 Train_Loss: 0.6685 Train_Acc: 61.831 Val_Loss: 0.6635  BEST VAL Loss: 0.6635  Val_Acc: 62.976

Epoch 15: Validation loss decreased (0.663522 --> 0.662417).  Saving model ...
	 Train_Loss: 0.6674 Train_Acc: 61.892 Val_Loss: 0.6624  BEST VAL Loss: 0.6624  Val_Acc: 62.414

Epoch 16: Validation loss decreased (0.662417 --> 0.661228).  Saving model ...
	 Train_Loss: 0.6663 Train_Acc: 62.324 Val_Loss: 0.6612  BEST VAL Loss: 0.6612  Val_Acc: 62.879

Epoch 17: Validation loss decreased (0.661228 --> 0.660156).  Saving model ...
	 Train_Loss: 0.6652 Train_Acc: 62.497 Val_Loss: 0.6602  BEST VAL Loss: 0.6602  Val_Acc: 63.162

Epoch 18: Validation loss decreased (0.660156 --> 0.659080).  Saving model ...
	 Train_Loss: 0.6642 Train_Acc: 62.681 Val_Loss: 0.6591  BEST VAL Loss: 0.6591  Val_Acc: 63.503

Epoch 19: Validation loss decreased (0.659080 --> 0.658075).  Saving model ...
	 Train_Loss: 0.6632 Train_Acc: 63.047 Val_Loss: 0.6581  BEST VAL Loss: 0.6581  Val_Acc: 63.122

Epoch 20: Validation loss decreased (0.658075 --> 0.657068).  Saving model ...
	 Train_Loss: 0.6623 Train_Acc: 63.142 Val_Loss: 0.6571  BEST VAL Loss: 0.6571  Val_Acc: 63.822

Epoch 21: Validation loss decreased (0.657068 --> 0.656103).  Saving model ...
	 Train_Loss: 0.6613 Train_Acc: 63.266 Val_Loss: 0.6561  BEST VAL Loss: 0.6561  Val_Acc: 63.844

Epoch 22: Validation loss decreased (0.656103 --> 0.655152).  Saving model ...
	 Train_Loss: 0.6605 Train_Acc: 63.337 Val_Loss: 0.6552  BEST VAL Loss: 0.6552  Val_Acc: 64.504

Epoch 23: Validation loss decreased (0.655152 --> 0.654274).  Saving model ...
	 Train_Loss: 0.6596 Train_Acc: 63.565 Val_Loss: 0.6543  BEST VAL Loss: 0.6543  Val_Acc: 64.539

Epoch 24: Validation loss decreased (0.654274 --> 0.653307).  Saving model ...
	 Train_Loss: 0.6588 Train_Acc: 63.794 Val_Loss: 0.6533  BEST VAL Loss: 0.6533  Val_Acc: 65.008

Epoch 25: Validation loss decreased (0.653307 --> 0.652427).  Saving model ...
	 Train_Loss: 0.6579 Train_Acc: 63.788 Val_Loss: 0.6524  BEST VAL Loss: 0.6524  Val_Acc: 64.725

Epoch 26: Validation loss decreased (0.652427 --> 0.651581).  Saving model ...
	 Train_Loss: 0.6571 Train_Acc: 64.090 Val_Loss: 0.6516  BEST VAL Loss: 0.6516  Val_Acc: 64.309

Epoch 27: Validation loss decreased (0.651581 --> 0.650748).  Saving model ...
	 Train_Loss: 0.6563 Train_Acc: 64.137 Val_Loss: 0.6507  BEST VAL Loss: 0.6507  Val_Acc: 64.787

Epoch 28: Validation loss decreased (0.650748 --> 0.649961).  Saving model ...
	 Train_Loss: 0.6556 Train_Acc: 64.285 Val_Loss: 0.6500  BEST VAL Loss: 0.6500  Val_Acc: 65.088

Epoch 29: Validation loss decreased (0.649961 --> 0.649151).  Saving model ...
	 Train_Loss: 0.6548 Train_Acc: 64.330 Val_Loss: 0.6492  BEST VAL Loss: 0.6492  Val_Acc: 65.283

Epoch 30: Validation loss decreased (0.649151 --> 0.648426).  Saving model ...
	 Train_Loss: 0.6541 Train_Acc: 64.524 Val_Loss: 0.6484  BEST VAL Loss: 0.6484  Val_Acc: 65.283

Epoch 31: Validation loss decreased (0.648426 --> 0.647633).  Saving model ...
	 Train_Loss: 0.6534 Train_Acc: 64.597 Val_Loss: 0.6476  BEST VAL Loss: 0.6476  Val_Acc: 65.566

Epoch 32: Validation loss decreased (0.647633 --> 0.646880).  Saving model ...
	 Train_Loss: 0.6527 Train_Acc: 64.713 Val_Loss: 0.6469  BEST VAL Loss: 0.6469  Val_Acc: 65.486

Epoch 33: Validation loss decreased (0.646880 --> 0.646194).  Saving model ...
	 Train_Loss: 0.6521 Train_Acc: 64.698 Val_Loss: 0.6462  BEST VAL Loss: 0.6462  Val_Acc: 65.486

Epoch 34: Validation loss decreased (0.646194 --> 0.645502).  Saving model ...
	 Train_Loss: 0.6514 Train_Acc: 64.863 Val_Loss: 0.6455  BEST VAL Loss: 0.6455  Val_Acc: 65.969

Epoch 35: Validation loss decreased (0.645502 --> 0.644806).  Saving model ...
	 Train_Loss: 0.6508 Train_Acc: 65.143 Val_Loss: 0.6448  BEST VAL Loss: 0.6448  Val_Acc: 65.792

Epoch 36: Validation loss decreased (0.644806 --> 0.644156).  Saving model ...
	 Train_Loss: 0.6501 Train_Acc: 65.137 Val_Loss: 0.6442  BEST VAL Loss: 0.6442  Val_Acc: 65.818

Epoch 37: Validation loss decreased (0.644156 --> 0.643486).  Saving model ...
	 Train_Loss: 0.6495 Train_Acc: 65.153 Val_Loss: 0.6435  BEST VAL Loss: 0.6435  Val_Acc: 65.703

Epoch 38: Validation loss decreased (0.643486 --> 0.642842).  Saving model ...
	 Train_Loss: 0.6489 Train_Acc: 65.235 Val_Loss: 0.6428  BEST VAL Loss: 0.6428  Val_Acc: 65.995

Epoch 39: Validation loss decreased (0.642842 --> 0.642222).  Saving model ...
	 Train_Loss: 0.6483 Train_Acc: 65.379 Val_Loss: 0.6422  BEST VAL Loss: 0.6422  Val_Acc: 66.195

Epoch 40: Validation loss decreased (0.642222 --> 0.641604).  Saving model ...
	 Train_Loss: 0.6477 Train_Acc: 65.520 Val_Loss: 0.6416  BEST VAL Loss: 0.6416  Val_Acc: 66.287

Epoch 41: Validation loss decreased (0.641604 --> 0.641018).  Saving model ...
	 Train_Loss: 0.6472 Train_Acc: 65.557 Val_Loss: 0.6410  BEST VAL Loss: 0.6410  Val_Acc: 65.685

Epoch 42: Validation loss decreased (0.641018 --> 0.640412).  Saving model ...
	 Train_Loss: 0.6466 Train_Acc: 65.605 Val_Loss: 0.6404  BEST VAL Loss: 0.6404  Val_Acc: 65.898

Epoch 43: Validation loss decreased (0.640412 --> 0.639858).  Saving model ...
	 Train_Loss: 0.6460 Train_Acc: 65.476 Val_Loss: 0.6399  BEST VAL Loss: 0.6399  Val_Acc: 65.876

Epoch 44: Validation loss decreased (0.639858 --> 0.639331).  Saving model ...
	 Train_Loss: 0.6455 Train_Acc: 65.461 Val_Loss: 0.6393  BEST VAL Loss: 0.6393  Val_Acc: 65.761

Epoch 45: Validation loss decreased (0.639331 --> 0.638748).  Saving model ...
	 Train_Loss: 0.6450 Train_Acc: 65.475 Val_Loss: 0.6387  BEST VAL Loss: 0.6387  Val_Acc: 66.602

Epoch 46: Validation loss decreased (0.638748 --> 0.638213).  Saving model ...
	 Train_Loss: 0.6445 Train_Acc: 65.696 Val_Loss: 0.6382  BEST VAL Loss: 0.6382  Val_Acc: 66.341

Epoch 47: Validation loss decreased (0.638213 --> 0.637642).  Saving model ...
	 Train_Loss: 0.6440 Train_Acc: 65.917 Val_Loss: 0.6376  BEST VAL Loss: 0.6376  Val_Acc: 66.752

Epoch 48: Validation loss decreased (0.637642 --> 0.637099).  Saving model ...
	 Train_Loss: 0.6435 Train_Acc: 65.880 Val_Loss: 0.6371  BEST VAL Loss: 0.6371  Val_Acc: 66.819

Epoch 49: Validation loss decreased (0.637099 --> 0.636582).  Saving model ...
	 Train_Loss: 0.6430 Train_Acc: 65.936 Val_Loss: 0.6366  BEST VAL Loss: 0.6366  Val_Acc: 66.509

Epoch 50: Validation loss decreased (0.636582 --> 0.636086).  Saving model ...
	 Train_Loss: 0.6425 Train_Acc: 65.901 Val_Loss: 0.6361  BEST VAL Loss: 0.6361  Val_Acc: 66.584

Epoch 51: Validation loss decreased (0.636086 --> 0.635574).  Saving model ...
	 Train_Loss: 0.6420 Train_Acc: 66.118 Val_Loss: 0.6356  BEST VAL Loss: 0.6356  Val_Acc: 67.022

Epoch 52: Validation loss decreased (0.635574 --> 0.635094).  Saving model ...
	 Train_Loss: 0.6416 Train_Acc: 65.967 Val_Loss: 0.6351  BEST VAL Loss: 0.6351  Val_Acc: 66.562

Epoch 53: Validation loss decreased (0.635094 --> 0.634583).  Saving model ...
	 Train_Loss: 0.6411 Train_Acc: 66.198 Val_Loss: 0.6346  BEST VAL Loss: 0.6346  Val_Acc: 67.049

Epoch 54: Validation loss decreased (0.634583 --> 0.634144).  Saving model ...
	 Train_Loss: 0.6407 Train_Acc: 66.210 Val_Loss: 0.6341  BEST VAL Loss: 0.6341  Val_Acc: 66.739

Epoch 55: Validation loss decreased (0.634144 --> 0.633672).  Saving model ...
	 Train_Loss: 0.6402 Train_Acc: 66.252 Val_Loss: 0.6337  BEST VAL Loss: 0.6337  Val_Acc: 66.929

Epoch 56: Validation loss decreased (0.633672 --> 0.633206).  Saving model ...
	 Train_Loss: 0.6398 Train_Acc: 66.336 Val_Loss: 0.6332  BEST VAL Loss: 0.6332  Val_Acc: 66.916

Epoch 57: Validation loss decreased (0.633206 --> 0.632722).  Saving model ...
	 Train_Loss: 0.6393 Train_Acc: 66.292 Val_Loss: 0.6327  BEST VAL Loss: 0.6327  Val_Acc: 66.969

Epoch 58: Validation loss decreased (0.632722 --> 0.632320).  Saving model ...
	 Train_Loss: 0.6389 Train_Acc: 66.315 Val_Loss: 0.6323  BEST VAL Loss: 0.6323  Val_Acc: 66.677

Epoch 59: Validation loss decreased (0.632320 --> 0.631884).  Saving model ...
	 Train_Loss: 0.6385 Train_Acc: 66.481 Val_Loss: 0.6319  BEST VAL Loss: 0.6319  Val_Acc: 66.965

Epoch 60: Validation loss decreased (0.631884 --> 0.631448).  Saving model ...
	 Train_Loss: 0.6381 Train_Acc: 66.516 Val_Loss: 0.6314  BEST VAL Loss: 0.6314  Val_Acc: 66.889

Epoch 61: Validation loss decreased (0.631448 --> 0.631021).  Saving model ...
	 Train_Loss: 0.6377 Train_Acc: 66.414 Val_Loss: 0.6310  BEST VAL Loss: 0.6310  Val_Acc: 66.965

Epoch 62: Validation loss decreased (0.631021 --> 0.630619).  Saving model ...
	 Train_Loss: 0.6373 Train_Acc: 66.405 Val_Loss: 0.6306  BEST VAL Loss: 0.6306  Val_Acc: 67.208

Epoch 63: Validation loss decreased (0.630619 --> 0.630241).  Saving model ...
	 Train_Loss: 0.6369 Train_Acc: 66.596 Val_Loss: 0.6302  BEST VAL Loss: 0.6302  Val_Acc: 67.159

Epoch 64: Validation loss decreased (0.630241 --> 0.629850).  Saving model ...
	 Train_Loss: 0.6365 Train_Acc: 66.431 Val_Loss: 0.6298  BEST VAL Loss: 0.6298  Val_Acc: 67.443

Epoch 65: Validation loss decreased (0.629850 --> 0.629472).  Saving model ...
	 Train_Loss: 0.6361 Train_Acc: 66.540 Val_Loss: 0.6295  BEST VAL Loss: 0.6295  Val_Acc: 67.173

Epoch 66: Validation loss decreased (0.629472 --> 0.629066).  Saving model ...
	 Train_Loss: 0.6358 Train_Acc: 66.698 Val_Loss: 0.6291  BEST VAL Loss: 0.6291  Val_Acc: 67.208

Epoch 67: Validation loss decreased (0.629066 --> 0.628678).  Saving model ...
	 Train_Loss: 0.6354 Train_Acc: 66.662 Val_Loss: 0.6287  BEST VAL Loss: 0.6287  Val_Acc: 67.620

Epoch 68: Validation loss decreased (0.628678 --> 0.628307).  Saving model ...
	 Train_Loss: 0.6350 Train_Acc: 66.682 Val_Loss: 0.6283  BEST VAL Loss: 0.6283  Val_Acc: 67.306

Epoch 69: Validation loss decreased (0.628307 --> 0.627927).  Saving model ...
	 Train_Loss: 0.6347 Train_Acc: 66.830 Val_Loss: 0.6279  BEST VAL Loss: 0.6279  Val_Acc: 67.279

Epoch 70: Validation loss decreased (0.627927 --> 0.627559).  Saving model ...
	 Train_Loss: 0.6343 Train_Acc: 66.793 Val_Loss: 0.6276  BEST VAL Loss: 0.6276  Val_Acc: 67.239

Epoch 71: Validation loss decreased (0.627559 --> 0.627187).  Saving model ...
	 Train_Loss: 0.6340 Train_Acc: 66.739 Val_Loss: 0.6272  BEST VAL Loss: 0.6272  Val_Acc: 67.297

Epoch 72: Validation loss decreased (0.627187 --> 0.626822).  Saving model ...
	 Train_Loss: 0.6336 Train_Acc: 66.626 Val_Loss: 0.6268  BEST VAL Loss: 0.6268  Val_Acc: 67.474

Epoch 73: Validation loss decreased (0.626822 --> 0.626442).  Saving model ...
	 Train_Loss: 0.6333 Train_Acc: 66.814 Val_Loss: 0.6264  BEST VAL Loss: 0.6264  Val_Acc: 67.235

Epoch 74: Validation loss decreased (0.626442 --> 0.626075).  Saving model ...
	 Train_Loss: 0.6330 Train_Acc: 66.898 Val_Loss: 0.6261  BEST VAL Loss: 0.6261  Val_Acc: 67.682

Epoch 75: Validation loss decreased (0.626075 --> 0.625716).  Saving model ...
	 Train_Loss: 0.6326 Train_Acc: 66.934 Val_Loss: 0.6257  BEST VAL Loss: 0.6257  Val_Acc: 67.704

Epoch 76: Validation loss decreased (0.625716 --> 0.625367).  Saving model ...
	 Train_Loss: 0.6323 Train_Acc: 66.958 Val_Loss: 0.6254  BEST VAL Loss: 0.6254  Val_Acc: 67.775

Epoch 77: Validation loss decreased (0.625367 --> 0.625038).  Saving model ...
	 Train_Loss: 0.6320 Train_Acc: 66.990 Val_Loss: 0.6250  BEST VAL Loss: 0.6250  Val_Acc: 67.713

Epoch 78: Validation loss decreased (0.625038 --> 0.624717).  Saving model ...
	 Train_Loss: 0.6317 Train_Acc: 66.752 Val_Loss: 0.6247  BEST VAL Loss: 0.6247  Val_Acc: 67.761

Epoch 79: Validation loss decreased (0.624717 --> 0.624470).  Saving model ...
	 Train_Loss: 0.6314 Train_Acc: 66.891 Val_Loss: 0.6245  BEST VAL Loss: 0.6245  Val_Acc: 66.735

Epoch 80: Validation loss decreased (0.624470 --> 0.624182).  Saving model ...
	 Train_Loss: 0.6311 Train_Acc: 67.067 Val_Loss: 0.6242  BEST VAL Loss: 0.6242  Val_Acc: 67.469

Epoch 81: Validation loss decreased (0.624182 --> 0.623844).  Saving model ...
	 Train_Loss: 0.6308 Train_Acc: 67.060 Val_Loss: 0.6238  BEST VAL Loss: 0.6238  Val_Acc: 67.850

Epoch 82: Validation loss decreased (0.623844 --> 0.623519).  Saving model ...
	 Train_Loss: 0.6305 Train_Acc: 66.886 Val_Loss: 0.6235  BEST VAL Loss: 0.6235  Val_Acc: 67.615

Epoch 83: Validation loss decreased (0.623519 --> 0.623229).  Saving model ...
	 Train_Loss: 0.6302 Train_Acc: 67.037 Val_Loss: 0.6232  BEST VAL Loss: 0.6232  Val_Acc: 67.593

Epoch 84: Validation loss decreased (0.623229 --> 0.622913).  Saving model ...
	 Train_Loss: 0.6299 Train_Acc: 66.999 Val_Loss: 0.6229  BEST VAL Loss: 0.6229  Val_Acc: 67.872

Epoch 85: Validation loss decreased (0.622913 --> 0.622601).  Saving model ...
	 Train_Loss: 0.6296 Train_Acc: 67.078 Val_Loss: 0.6226  BEST VAL Loss: 0.6226  Val_Acc: 67.881

Epoch 86: Validation loss decreased (0.622601 --> 0.622286).  Saving model ...
	 Train_Loss: 0.6294 Train_Acc: 67.243 Val_Loss: 0.6223  BEST VAL Loss: 0.6223  Val_Acc: 67.788

Epoch 87: Validation loss decreased (0.622286 --> 0.621993).  Saving model ...
	 Train_Loss: 0.6291 Train_Acc: 67.129 Val_Loss: 0.6220  BEST VAL Loss: 0.6220  Val_Acc: 67.797

Epoch 88: Validation loss decreased (0.621993 --> 0.621689).  Saving model ...
	 Train_Loss: 0.6288 Train_Acc: 67.129 Val_Loss: 0.6217  BEST VAL Loss: 0.6217  Val_Acc: 68.173

Epoch 89: Validation loss decreased (0.621689 --> 0.621388).  Saving model ...
	 Train_Loss: 0.6285 Train_Acc: 67.220 Val_Loss: 0.6214  BEST VAL Loss: 0.6214  Val_Acc: 67.961

Epoch 90: Validation loss decreased (0.621388 --> 0.621119).  Saving model ...
	 Train_Loss: 0.6283 Train_Acc: 67.004 Val_Loss: 0.6211  BEST VAL Loss: 0.6211  Val_Acc: 68.018

Epoch 91: Validation loss decreased (0.621119 --> 0.620840).  Saving model ...
	 Train_Loss: 0.6280 Train_Acc: 67.083 Val_Loss: 0.6208  BEST VAL Loss: 0.6208  Val_Acc: 67.894

Epoch 92: Validation loss decreased (0.620840 --> 0.620555).  Saving model ...
	 Train_Loss: 0.6278 Train_Acc: 67.185 Val_Loss: 0.6206  BEST VAL Loss: 0.6206  Val_Acc: 67.708

Epoch 93: Validation loss decreased (0.620555 --> 0.620258).  Saving model ...
	 Train_Loss: 0.6275 Train_Acc: 67.323 Val_Loss: 0.6203  BEST VAL Loss: 0.6203  Val_Acc: 68.085

Epoch 94: Validation loss decreased (0.620258 --> 0.619980).  Saving model ...
	 Train_Loss: 0.6272 Train_Acc: 67.177 Val_Loss: 0.6200  BEST VAL Loss: 0.6200  Val_Acc: 67.784

Epoch 95: Validation loss decreased (0.619980 --> 0.619736).  Saving model ...
	 Train_Loss: 0.6270 Train_Acc: 67.328 Val_Loss: 0.6197  BEST VAL Loss: 0.6197  Val_Acc: 67.190

Epoch 96: Validation loss decreased (0.619736 --> 0.619486).  Saving model ...
	 Train_Loss: 0.6267 Train_Acc: 67.375 Val_Loss: 0.6195  BEST VAL Loss: 0.6195  Val_Acc: 67.797

Epoch 97: Validation loss decreased (0.619486 --> 0.619256).  Saving model ...
	 Train_Loss: 0.6265 Train_Acc: 67.308 Val_Loss: 0.6193  BEST VAL Loss: 0.6193  Val_Acc: 67.651

Epoch 98: Validation loss decreased (0.619256 --> 0.618970).  Saving model ...
	 Train_Loss: 0.6262 Train_Acc: 67.384 Val_Loss: 0.6190  BEST VAL Loss: 0.6190  Val_Acc: 68.381

Epoch 99: Validation loss decreased (0.618970 --> 0.618709).  Saving model ...
	 Train_Loss: 0.6260 Train_Acc: 67.380 Val_Loss: 0.6187  BEST VAL Loss: 0.6187  Val_Acc: 67.801

LPS_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.33      0.38     82968
           1       0.54      0.67      0.60     97752

    accuracy                           0.51    180720
   macro avg       0.50      0.50      0.49    180720
weighted avg       0.50      0.51      0.50    180720

LPS_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.32      0.38     10371
           1       0.54      0.67      0.60     12220

    accuracy                           0.51     22591
   macro avg       0.50      0.50      0.49     22591
weighted avg       0.50      0.51      0.50     22591

LPS_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.33      0.38     10371
           1       0.54      0.67      0.60     12220

    accuracy                           0.51     22591
   macro avg       0.50      0.50      0.49     22591
weighted avg       0.50      0.51      0.50     22591

              precision    recall  f1-score   support

           0       0.46      0.33      0.38     10371
           1       0.54      0.67      0.60     12220

    accuracy                           0.51     22591
   macro avg       0.50      0.50      0.49     22591
weighted avg       0.50      0.51      0.50     22591

LPS_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.43      0.46     34887
           1       0.52      0.58      0.55     37243

    accuracy                           0.51     72130
   macro avg       0.50      0.50      0.50     72130
weighted avg       0.51      0.51      0.50     72130

              precision    recall  f1-score   support

           0       0.49      0.43      0.46     34887
           1       0.52      0.58      0.55     37243

    accuracy                           0.51     72130
   macro avg       0.50      0.50      0.50     72130
weighted avg       0.51      0.51      0.50     72130

completed
