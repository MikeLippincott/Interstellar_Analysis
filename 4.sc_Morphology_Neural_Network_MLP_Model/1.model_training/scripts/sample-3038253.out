[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b20d96a5'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'c06fc049'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ae6bee71'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'c2e6fb11'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_0.100_DMSO_0.025 treatment_name: LPS_10.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_0.100_DMSO_0.025
TREATMENT_NAME: LPS_10.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_10.000_DMSO_0.025']
The dimensions of the data are: (295087, 1270)
Number of total missing values across all columns: 590174
Data Subset Is Off
Wells held out for testing: ['C08' 'E08']
Wells to use for training, validation, and testing ['C02' 'C03' 'C09' 'E02' 'E03' 'E09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.691370).  Saving model ...
	 Train_Loss: 0.6971 Train_Acc: 49.744 Val_Loss: 0.6914  BEST VAL Loss: 0.6914  Val_Acc: 52.669

Epoch 1: Validation loss decreased (0.691370 --> 0.690473).  Saving model ...
	 Train_Loss: 0.6939 Train_Acc: 53.232 Val_Loss: 0.6905  BEST VAL Loss: 0.6905  Val_Acc: 53.200

Epoch 2: Validation loss decreased (0.690473 --> 0.689087).  Saving model ...
	 Train_Loss: 0.6921 Train_Acc: 54.560 Val_Loss: 0.6891  BEST VAL Loss: 0.6891  Val_Acc: 55.433

Epoch 3: Validation loss decreased (0.689087 --> 0.686860).  Saving model ...
	 Train_Loss: 0.6902 Train_Acc: 56.341 Val_Loss: 0.6869  BEST VAL Loss: 0.6869  Val_Acc: 57.981

Epoch 4: Validation loss decreased (0.686860 --> 0.683636).  Saving model ...
	 Train_Loss: 0.6878 Train_Acc: 57.999 Val_Loss: 0.6836  BEST VAL Loss: 0.6836  Val_Acc: 60.350

Epoch 5: Validation loss decreased (0.683636 --> 0.679739).  Saving model ...
	 Train_Loss: 0.6848 Train_Acc: 59.693 Val_Loss: 0.6797  BEST VAL Loss: 0.6797  Val_Acc: 61.654

Epoch 6: Validation loss decreased (0.679739 --> 0.675478).  Saving model ...
	 Train_Loss: 0.6813 Train_Acc: 61.085 Val_Loss: 0.6755  BEST VAL Loss: 0.6755  Val_Acc: 62.940

Epoch 7: Validation loss decreased (0.675478 --> 0.670971).  Saving model ...
	 Train_Loss: 0.6777 Train_Acc: 62.242 Val_Loss: 0.6710  BEST VAL Loss: 0.6710  Val_Acc: 64.079

Epoch 8: Validation loss decreased (0.670971 --> 0.666293).  Saving model ...
	 Train_Loss: 0.6740 Train_Acc: 63.177 Val_Loss: 0.6663  BEST VAL Loss: 0.6663  Val_Acc: 65.122

Epoch 9: Validation loss decreased (0.666293 --> 0.661748).  Saving model ...
	 Train_Loss: 0.6703 Train_Acc: 63.973 Val_Loss: 0.6617  BEST VAL Loss: 0.6617  Val_Acc: 65.849

Epoch 10: Validation loss decreased (0.661748 --> 0.657399).  Saving model ...
	 Train_Loss: 0.6666 Train_Acc: 64.767 Val_Loss: 0.6574  BEST VAL Loss: 0.6574  Val_Acc: 66.801

Epoch 11: Validation loss decreased (0.657399 --> 0.653116).  Saving model ...
	 Train_Loss: 0.6630 Train_Acc: 65.457 Val_Loss: 0.6531  BEST VAL Loss: 0.6531  Val_Acc: 67.135

Epoch 12: Validation loss decreased (0.653116 --> 0.649151).  Saving model ...
	 Train_Loss: 0.6596 Train_Acc: 65.995 Val_Loss: 0.6492  BEST VAL Loss: 0.6492  Val_Acc: 67.542

Epoch 13: Validation loss decreased (0.649151 --> 0.645520).  Saving model ...
	 Train_Loss: 0.6564 Train_Acc: 66.593 Val_Loss: 0.6455  BEST VAL Loss: 0.6455  Val_Acc: 67.629

Epoch 14: Validation loss decreased (0.645520 --> 0.641981).  Saving model ...
	 Train_Loss: 0.6532 Train_Acc: 67.042 Val_Loss: 0.6420  BEST VAL Loss: 0.6420  Val_Acc: 68.315

Epoch 15: Validation loss decreased (0.641981 --> 0.638709).  Saving model ...
	 Train_Loss: 0.6501 Train_Acc: 67.467 Val_Loss: 0.6387  BEST VAL Loss: 0.6387  Val_Acc: 68.384

Epoch 16: Validation loss decreased (0.638709 --> 0.635511).  Saving model ...
	 Train_Loss: 0.6473 Train_Acc: 67.763 Val_Loss: 0.6355  BEST VAL Loss: 0.6355  Val_Acc: 68.910

Epoch 17: Validation loss decreased (0.635511 --> 0.632556).  Saving model ...
	 Train_Loss: 0.6444 Train_Acc: 68.359 Val_Loss: 0.6326  BEST VAL Loss: 0.6326  Val_Acc: 69.042

Epoch 18: Validation loss decreased (0.632556 --> 0.629727).  Saving model ...
	 Train_Loss: 0.6417 Train_Acc: 68.554 Val_Loss: 0.6297  BEST VAL Loss: 0.6297  Val_Acc: 69.349

Epoch 19: Validation loss decreased (0.629727 --> 0.627088).  Saving model ...
	 Train_Loss: 0.6392 Train_Acc: 68.751 Val_Loss: 0.6271  BEST VAL Loss: 0.6271  Val_Acc: 69.436

Epoch 20: Validation loss decreased (0.627088 --> 0.624539).  Saving model ...
	 Train_Loss: 0.6367 Train_Acc: 69.108 Val_Loss: 0.6245  BEST VAL Loss: 0.6245  Val_Acc: 69.427

Epoch 21: Validation loss decreased (0.624539 --> 0.622053).  Saving model ...
	 Train_Loss: 0.6343 Train_Acc: 69.252 Val_Loss: 0.6221  BEST VAL Loss: 0.6221  Val_Acc: 69.564

Epoch 22: Validation loss decreased (0.622053 --> 0.619757).  Saving model ...
	 Train_Loss: 0.6320 Train_Acc: 69.443 Val_Loss: 0.6198  BEST VAL Loss: 0.6198  Val_Acc: 69.669

Epoch 23: Validation loss decreased (0.619757 --> 0.617470).  Saving model ...
	 Train_Loss: 0.6298 Train_Acc: 69.649 Val_Loss: 0.6175  BEST VAL Loss: 0.6175  Val_Acc: 69.939

Epoch 24: Validation loss decreased (0.617470 --> 0.615444).  Saving model ...
	 Train_Loss: 0.6277 Train_Acc: 69.729 Val_Loss: 0.6154  BEST VAL Loss: 0.6154  Val_Acc: 69.390

Epoch 25: Validation loss decreased (0.615444 --> 0.613380).  Saving model ...
	 Train_Loss: 0.6256 Train_Acc: 69.988 Val_Loss: 0.6134  BEST VAL Loss: 0.6134  Val_Acc: 70.122

Epoch 26: Validation loss decreased (0.613380 --> 0.611635).  Saving model ...
	 Train_Loss: 0.6236 Train_Acc: 70.097 Val_Loss: 0.6116  BEST VAL Loss: 0.6116  Val_Acc: 69.450

Epoch 27: Validation loss decreased (0.611635 --> 0.609621).  Saving model ...
	 Train_Loss: 0.6217 Train_Acc: 70.374 Val_Loss: 0.6096  BEST VAL Loss: 0.6096  Val_Acc: 70.882

Epoch 28: Validation loss decreased (0.609621 --> 0.607767).  Saving model ...
	 Train_Loss: 0.6198 Train_Acc: 70.423 Val_Loss: 0.6078  BEST VAL Loss: 0.6078  Val_Acc: 70.680

Epoch 29: Validation loss decreased (0.607767 --> 0.605882).  Saving model ...
	 Train_Loss: 0.6180 Train_Acc: 70.657 Val_Loss: 0.6059  BEST VAL Loss: 0.6059  Val_Acc: 71.010

Epoch 30: Validation loss decreased (0.605882 --> 0.604059).  Saving model ...
	 Train_Loss: 0.6162 Train_Acc: 70.665 Val_Loss: 0.6041  BEST VAL Loss: 0.6041  Val_Acc: 71.065

Epoch 31: Validation loss decreased (0.604059 --> 0.602282).  Saving model ...
	 Train_Loss: 0.6145 Train_Acc: 70.882 Val_Loss: 0.6023  BEST VAL Loss: 0.6023  Val_Acc: 71.010

Epoch 32: Validation loss decreased (0.602282 --> 0.600618).  Saving model ...
	 Train_Loss: 0.6129 Train_Acc: 71.021 Val_Loss: 0.6006  BEST VAL Loss: 0.6006  Val_Acc: 71.161

Epoch 33: Validation loss decreased (0.600618 --> 0.599003).  Saving model ...
	 Train_Loss: 0.6112 Train_Acc: 71.106 Val_Loss: 0.5990  BEST VAL Loss: 0.5990  Val_Acc: 71.161

Epoch 34: Validation loss decreased (0.599003 --> 0.597508).  Saving model ...
	 Train_Loss: 0.6096 Train_Acc: 71.214 Val_Loss: 0.5975  BEST VAL Loss: 0.5975  Val_Acc: 70.978

Epoch 35: Validation loss decreased (0.597508 --> 0.595970).  Saving model ...
	 Train_Loss: 0.6081 Train_Acc: 71.403 Val_Loss: 0.5960  BEST VAL Loss: 0.5960  Val_Acc: 71.234

Epoch 36: Validation loss decreased (0.595970 --> 0.594462).  Saving model ...
	 Train_Loss: 0.6066 Train_Acc: 71.592 Val_Loss: 0.5945  BEST VAL Loss: 0.5945  Val_Acc: 71.444

Epoch 37: Validation loss decreased (0.594462 --> 0.592970).  Saving model ...
	 Train_Loss: 0.6050 Train_Acc: 71.847 Val_Loss: 0.5930  BEST VAL Loss: 0.5930  Val_Acc: 71.545

Epoch 38: Validation loss decreased (0.592970 --> 0.591548).  Saving model ...
	 Train_Loss: 0.6036 Train_Acc: 71.664 Val_Loss: 0.5915  BEST VAL Loss: 0.5915  Val_Acc: 71.641

Epoch 39: Validation loss decreased (0.591548 --> 0.590204).  Saving model ...
	 Train_Loss: 0.6022 Train_Acc: 71.968 Val_Loss: 0.5902  BEST VAL Loss: 0.5902  Val_Acc: 71.586

Epoch 40: Validation loss decreased (0.590204 --> 0.588872).  Saving model ...
	 Train_Loss: 0.6008 Train_Acc: 71.928 Val_Loss: 0.5889  BEST VAL Loss: 0.5889  Val_Acc: 71.490

Epoch 41: Validation loss decreased (0.588872 --> 0.587518).  Saving model ...
	 Train_Loss: 0.5994 Train_Acc: 72.086 Val_Loss: 0.5875  BEST VAL Loss: 0.5875  Val_Acc: 72.066

Epoch 42: Validation loss decreased (0.587518 --> 0.586271).  Saving model ...
	 Train_Loss: 0.5981 Train_Acc: 72.211 Val_Loss: 0.5863  BEST VAL Loss: 0.5863  Val_Acc: 71.682

Epoch 43: Validation loss decreased (0.586271 --> 0.585041).  Saving model ...
	 Train_Loss: 0.5968 Train_Acc: 72.252 Val_Loss: 0.5850  BEST VAL Loss: 0.5850  Val_Acc: 72.158

Epoch 44: Validation loss decreased (0.585041 --> 0.583828).  Saving model ...
	 Train_Loss: 0.5955 Train_Acc: 72.467 Val_Loss: 0.5838  BEST VAL Loss: 0.5838  Val_Acc: 72.103

Epoch 45: Validation loss decreased (0.583828 --> 0.582648).  Saving model ...
	 Train_Loss: 0.5943 Train_Acc: 72.435 Val_Loss: 0.5826  BEST VAL Loss: 0.5826  Val_Acc: 72.025

Epoch 46: Validation loss decreased (0.582648 --> 0.581466).  Saving model ...
	 Train_Loss: 0.5931 Train_Acc: 72.444 Val_Loss: 0.5815  BEST VAL Loss: 0.5815  Val_Acc: 72.130

Epoch 47: Validation loss decreased (0.581466 --> 0.580380).  Saving model ...
	 Train_Loss: 0.5919 Train_Acc: 72.622 Val_Loss: 0.5804  BEST VAL Loss: 0.5804  Val_Acc: 71.980

Epoch 48: Validation loss decreased (0.580380 --> 0.579254).  Saving model ...
	 Train_Loss: 0.5907 Train_Acc: 72.702 Val_Loss: 0.5793  BEST VAL Loss: 0.5793  Val_Acc: 72.606

Epoch 49: Validation loss decreased (0.579254 --> 0.578305).  Saving model ...
	 Train_Loss: 0.5896 Train_Acc: 72.714 Val_Loss: 0.5783  BEST VAL Loss: 0.5783  Val_Acc: 71.650

Epoch 50: Validation loss decreased (0.578305 --> 0.577231).  Saving model ...
	 Train_Loss: 0.5884 Train_Acc: 72.894 Val_Loss: 0.5772  BEST VAL Loss: 0.5772  Val_Acc: 72.524

Epoch 51: Validation loss decreased (0.577231 --> 0.576197).  Saving model ...
	 Train_Loss: 0.5873 Train_Acc: 72.947 Val_Loss: 0.5762  BEST VAL Loss: 0.5762  Val_Acc: 72.501

Epoch 52: Validation loss decreased (0.576197 --> 0.575183).  Saving model ...
	 Train_Loss: 0.5862 Train_Acc: 73.079 Val_Loss: 0.5752  BEST VAL Loss: 0.5752  Val_Acc: 72.423

Epoch 53: Validation loss decreased (0.575183 --> 0.574200).  Saving model ...
	 Train_Loss: 0.5852 Train_Acc: 73.164 Val_Loss: 0.5742  BEST VAL Loss: 0.5742  Val_Acc: 72.835

Epoch 54: Validation loss decreased (0.574200 --> 0.573210).  Saving model ...
	 Train_Loss: 0.5841 Train_Acc: 73.160 Val_Loss: 0.5732  BEST VAL Loss: 0.5732  Val_Acc: 72.776

Epoch 55: Validation loss decreased (0.573210 --> 0.572266).  Saving model ...
	 Train_Loss: 0.5831 Train_Acc: 73.170 Val_Loss: 0.5723  BEST VAL Loss: 0.5723  Val_Acc: 72.620

Epoch 56: Validation loss decreased (0.572266 --> 0.571318).  Saving model ...
	 Train_Loss: 0.5821 Train_Acc: 73.228 Val_Loss: 0.5713  BEST VAL Loss: 0.5713  Val_Acc: 73.128

Epoch 57: Validation loss decreased (0.571318 --> 0.570402).  Saving model ...
	 Train_Loss: 0.5811 Train_Acc: 73.311 Val_Loss: 0.5704  BEST VAL Loss: 0.5704  Val_Acc: 72.922

Epoch 58: Validation loss decreased (0.570402 --> 0.569480).  Saving model ...
	 Train_Loss: 0.5801 Train_Acc: 73.494 Val_Loss: 0.5695  BEST VAL Loss: 0.5695  Val_Acc: 73.018

Epoch 59: Validation loss decreased (0.569480 --> 0.568567).  Saving model ...
	 Train_Loss: 0.5791 Train_Acc: 73.468 Val_Loss: 0.5686  BEST VAL Loss: 0.5686  Val_Acc: 73.224

Epoch 60: Validation loss decreased (0.568567 --> 0.567686).  Saving model ...
	 Train_Loss: 0.5782 Train_Acc: 73.453 Val_Loss: 0.5677  BEST VAL Loss: 0.5677  Val_Acc: 73.242

Epoch 61: Validation loss decreased (0.567686 --> 0.566803).  Saving model ...
	 Train_Loss: 0.5772 Train_Acc: 73.673 Val_Loss: 0.5668  BEST VAL Loss: 0.5668  Val_Acc: 73.215

Epoch 62: Validation loss decreased (0.566803 --> 0.565980).  Saving model ...
	 Train_Loss: 0.5763 Train_Acc: 73.632 Val_Loss: 0.5660  BEST VAL Loss: 0.5660  Val_Acc: 73.196

Epoch 63: Validation loss decreased (0.565980 --> 0.565159).  Saving model ...
	 Train_Loss: 0.5754 Train_Acc: 73.733 Val_Loss: 0.5652  BEST VAL Loss: 0.5652  Val_Acc: 73.384

Epoch 64: Validation loss decreased (0.565159 --> 0.564354).  Saving model ...
	 Train_Loss: 0.5745 Train_Acc: 73.713 Val_Loss: 0.5644  BEST VAL Loss: 0.5644  Val_Acc: 73.411

Epoch 65: Validation loss decreased (0.564354 --> 0.563601).  Saving model ...
	 Train_Loss: 0.5736 Train_Acc: 73.883 Val_Loss: 0.5636  BEST VAL Loss: 0.5636  Val_Acc: 73.334

Epoch 66: Validation loss decreased (0.563601 --> 0.562846).  Saving model ...
	 Train_Loss: 0.5728 Train_Acc: 73.880 Val_Loss: 0.5628  BEST VAL Loss: 0.5628  Val_Acc: 73.206

Epoch 67: Validation loss decreased (0.562846 --> 0.562070).  Saving model ...
	 Train_Loss: 0.5720 Train_Acc: 73.769 Val_Loss: 0.5621  BEST VAL Loss: 0.5621  Val_Acc: 73.315

Epoch 68: Validation loss decreased (0.562070 --> 0.561286).  Saving model ...
	 Train_Loss: 0.5711 Train_Acc: 73.946 Val_Loss: 0.5613  BEST VAL Loss: 0.5613  Val_Acc: 73.402

Epoch 69: Validation loss decreased (0.561286 --> 0.560562).  Saving model ...
	 Train_Loss: 0.5703 Train_Acc: 73.993 Val_Loss: 0.5606  BEST VAL Loss: 0.5606  Val_Acc: 73.462

Epoch 70: Validation loss decreased (0.560562 --> 0.559810).  Saving model ...
	 Train_Loss: 0.5695 Train_Acc: 74.031 Val_Loss: 0.5598  BEST VAL Loss: 0.5598  Val_Acc: 73.672

Epoch 71: Validation loss decreased (0.559810 --> 0.559088).  Saving model ...
	 Train_Loss: 0.5687 Train_Acc: 74.185 Val_Loss: 0.5591  BEST VAL Loss: 0.5591  Val_Acc: 73.544

Epoch 72: Validation loss decreased (0.559088 --> 0.558371).  Saving model ...
	 Train_Loss: 0.5679 Train_Acc: 74.192 Val_Loss: 0.5584  BEST VAL Loss: 0.5584  Val_Acc: 73.608

Epoch 73: Validation loss decreased (0.558371 --> 0.557645).  Saving model ...
	 Train_Loss: 0.5671 Train_Acc: 74.210 Val_Loss: 0.5576  BEST VAL Loss: 0.5576  Val_Acc: 73.988

Epoch 74: Validation loss decreased (0.557645 --> 0.556968).  Saving model ...
	 Train_Loss: 0.5664 Train_Acc: 74.320 Val_Loss: 0.5570  BEST VAL Loss: 0.5570  Val_Acc: 73.604

Epoch 75: Validation loss decreased (0.556968 --> 0.556336).  Saving model ...
	 Train_Loss: 0.5656 Train_Acc: 74.298 Val_Loss: 0.5563  BEST VAL Loss: 0.5563  Val_Acc: 73.640

Epoch 76: Validation loss decreased (0.556336 --> 0.555647).  Saving model ...
	 Train_Loss: 0.5649 Train_Acc: 74.372 Val_Loss: 0.5556  BEST VAL Loss: 0.5556  Val_Acc: 73.800

Epoch 77: Validation loss decreased (0.555647 --> 0.554971).  Saving model ...
	 Train_Loss: 0.5641 Train_Acc: 74.469 Val_Loss: 0.5550  BEST VAL Loss: 0.5550  Val_Acc: 73.947

Epoch 78: Validation loss decreased (0.554971 --> 0.554298).  Saving model ...
	 Train_Loss: 0.5634 Train_Acc: 74.487 Val_Loss: 0.5543  BEST VAL Loss: 0.5543  Val_Acc: 73.668

Epoch 79: Validation loss decreased (0.554298 --> 0.553608).  Saving model ...
	 Train_Loss: 0.5627 Train_Acc: 74.376 Val_Loss: 0.5536  BEST VAL Loss: 0.5536  Val_Acc: 74.198

Epoch 80: Validation loss decreased (0.553608 --> 0.552970).  Saving model ...
	 Train_Loss: 0.5620 Train_Acc: 74.585 Val_Loss: 0.5530  BEST VAL Loss: 0.5530  Val_Acc: 73.640

Epoch 81: Validation loss decreased (0.552970 --> 0.552346).  Saving model ...
	 Train_Loss: 0.5613 Train_Acc: 74.527 Val_Loss: 0.5523  BEST VAL Loss: 0.5523  Val_Acc: 74.043

Epoch 82: Validation loss decreased (0.552346 --> 0.551717).  Saving model ...
	 Train_Loss: 0.5606 Train_Acc: 74.642 Val_Loss: 0.5517  BEST VAL Loss: 0.5517  Val_Acc: 74.194

Epoch 83: Validation loss decreased (0.551717 --> 0.551084).  Saving model ...
	 Train_Loss: 0.5599 Train_Acc: 74.715 Val_Loss: 0.5511  BEST VAL Loss: 0.5511  Val_Acc: 74.235

Epoch 84: Validation loss decreased (0.551084 --> 0.550487).  Saving model ...
	 Train_Loss: 0.5592 Train_Acc: 74.955 Val_Loss: 0.5505  BEST VAL Loss: 0.5505  Val_Acc: 74.194

Epoch 85: Validation loss decreased (0.550487 --> 0.549865).  Saving model ...
	 Train_Loss: 0.5585 Train_Acc: 74.721 Val_Loss: 0.5499  BEST VAL Loss: 0.5499  Val_Acc: 74.125

Epoch 86: Validation loss decreased (0.549865 --> 0.549250).  Saving model ...
	 Train_Loss: 0.5579 Train_Acc: 74.678 Val_Loss: 0.5492  BEST VAL Loss: 0.5492  Val_Acc: 74.253

Epoch 87: Validation loss decreased (0.549250 --> 0.548646).  Saving model ...
	 Train_Loss: 0.5572 Train_Acc: 74.957 Val_Loss: 0.5486  BEST VAL Loss: 0.5486  Val_Acc: 74.281

Epoch 88: Validation loss decreased (0.548646 --> 0.548078).  Saving model ...
	 Train_Loss: 0.5566 Train_Acc: 74.888 Val_Loss: 0.5481  BEST VAL Loss: 0.5481  Val_Acc: 74.066

Epoch 89: Validation loss decreased (0.548078 --> 0.547532).  Saving model ...
	 Train_Loss: 0.5560 Train_Acc: 74.998 Val_Loss: 0.5475  BEST VAL Loss: 0.5475  Val_Acc: 74.441

Epoch 90: Validation loss decreased (0.547532 --> 0.546985).  Saving model ...
	 Train_Loss: 0.5553 Train_Acc: 75.083 Val_Loss: 0.5470  BEST VAL Loss: 0.5470  Val_Acc: 74.253

Epoch 91: Validation loss decreased (0.546985 --> 0.546439).  Saving model ...
	 Train_Loss: 0.5547 Train_Acc: 74.950 Val_Loss: 0.5464  BEST VAL Loss: 0.5464  Val_Acc: 73.997

Epoch 92: Validation loss decreased (0.546439 --> 0.545874).  Saving model ...
	 Train_Loss: 0.5541 Train_Acc: 75.105 Val_Loss: 0.5459  BEST VAL Loss: 0.5459  Val_Acc: 74.669

Epoch 93: Validation loss decreased (0.545874 --> 0.545327).  Saving model ...
	 Train_Loss: 0.5535 Train_Acc: 75.189 Val_Loss: 0.5453  BEST VAL Loss: 0.5453  Val_Acc: 74.560

Epoch 94: Validation loss decreased (0.545327 --> 0.544783).  Saving model ...
	 Train_Loss: 0.5529 Train_Acc: 75.208 Val_Loss: 0.5448  BEST VAL Loss: 0.5448  Val_Acc: 74.528

Epoch 95: Validation loss decreased (0.544783 --> 0.544281).  Saving model ...
	 Train_Loss: 0.5523 Train_Acc: 75.266 Val_Loss: 0.5443  BEST VAL Loss: 0.5443  Val_Acc: 74.546

Epoch 96: Validation loss decreased (0.544281 --> 0.543730).  Saving model ...
	 Train_Loss: 0.5517 Train_Acc: 75.246 Val_Loss: 0.5437  BEST VAL Loss: 0.5437  Val_Acc: 74.862

Epoch 97: Validation loss decreased (0.543730 --> 0.543227).  Saving model ...
	 Train_Loss: 0.5511 Train_Acc: 75.257 Val_Loss: 0.5432  BEST VAL Loss: 0.5432  Val_Acc: 74.884

Epoch 98: Validation loss decreased (0.543227 --> 0.542727).  Saving model ...
	 Train_Loss: 0.5505 Train_Acc: 75.302 Val_Loss: 0.5427  BEST VAL Loss: 0.5427  Val_Acc: 74.519

Epoch 99: Validation loss decreased (0.542727 --> 0.542247).  Saving model ...
	 Train_Loss: 0.5500 Train_Acc: 75.493 Val_Loss: 0.5422  BEST VAL Loss: 0.5422  Val_Acc: 74.555

LPS_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.45      0.46     82968
           1       0.53      0.55      0.54     91897

    accuracy                           0.50    174865
   macro avg       0.50      0.50      0.50    174865
weighted avg       0.50      0.50      0.50    174865

LPS_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.45      0.46     10371
           1       0.53      0.56      0.54     11488

    accuracy                           0.50     21859
   macro avg       0.50      0.50      0.50     21859
weighted avg       0.50      0.50      0.50     21859

LPS_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.45      0.46     10371
           1       0.53      0.55      0.54     11488

    accuracy                           0.50     21859
   macro avg       0.50      0.50      0.50     21859
weighted avg       0.50      0.50      0.50     21859

              precision    recall  f1-score   support

           0       0.47      0.45      0.46     10371
           1       0.53      0.55      0.54     11488

    accuracy                           0.50     21859
   macro avg       0.50      0.50      0.50     21859
weighted avg       0.50      0.50      0.50     21859

LPS_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.51      0.48     34887
           1       0.55      0.49      0.51     41617

    accuracy                           0.50     76504
   macro avg       0.50      0.50      0.50     76504
weighted avg       0.50      0.50      0.50     76504

              precision    recall  f1-score   support

           0       0.46      0.51      0.48     34887
           1       0.55      0.49      0.51     41617

    accuracy                           0.50     76504
   macro avg       0.50      0.50      0.50     76504
weighted avg       0.50      0.50      0.50     76504

completed
