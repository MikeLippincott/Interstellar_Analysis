[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '983698c5'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'fb7ea9f5'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1a422751'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'da1e386f'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_1.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_Nigericin_1.000_3.0_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (29461, 1276)
Number of total missing values across all columns: 31618
Data Subset Is Off
Wells held out for testing: ['L16' 'M22']
Wells to use for training, validation, and testing ['L17' 'M18' 'M19' 'L20' 'L21' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.278922).  Saving model ...
	 Train_Loss: 0.5600 Train_Acc: 78.067 Val_Loss: 0.2789  BEST VAL Loss: 0.2789  Val_Acc: 89.042

Epoch 1: Validation loss decreased (0.278922 --> 0.251249).  Saving model ...
	 Train_Loss: 0.4119 Train_Acc: 89.799 Val_Loss: 0.2512  BEST VAL Loss: 0.2512  Val_Acc: 92.035

Epoch 2: Validation loss decreased (0.251249 --> 0.228660).  Saving model ...
	 Train_Loss: 0.3420 Train_Acc: 92.246 Val_Loss: 0.2287  BEST VAL Loss: 0.2287  Val_Acc: 93.002

Epoch 3: Validation loss decreased (0.228660 --> 0.209512).  Saving model ...
	 Train_Loss: 0.2988 Train_Acc: 93.587 Val_Loss: 0.2095  BEST VAL Loss: 0.2095  Val_Acc: 93.923

Epoch 4: Validation loss decreased (0.209512 --> 0.198465).  Saving model ...
	 Train_Loss: 0.2680 Train_Acc: 94.330 Val_Loss: 0.1985  BEST VAL Loss: 0.1985  Val_Acc: 94.659

Epoch 5: Validation loss decreased (0.198465 --> 0.197886).  Saving model ...
	 Train_Loss: 0.2452 Train_Acc: 94.836 Val_Loss: 0.1979  BEST VAL Loss: 0.1979  Val_Acc: 94.613

Epoch 6: Validation loss decreased (0.197886 --> 0.188678).  Saving model ...
	 Train_Loss: 0.2288 Train_Acc: 95.193 Val_Loss: 0.1887  BEST VAL Loss: 0.1887  Val_Acc: 94.890

Epoch 7: Validation loss decreased (0.188678 --> 0.182535).  Saving model ...
	 Train_Loss: 0.2149 Train_Acc: 95.527 Val_Loss: 0.1825  BEST VAL Loss: 0.1825  Val_Acc: 95.120

Epoch 8: Validation loss decreased (0.182535 --> 0.177789).  Saving model ...
	 Train_Loss: 0.2030 Train_Acc: 95.792 Val_Loss: 0.1778  BEST VAL Loss: 0.1778  Val_Acc: 94.843

Epoch 9: Validation loss decreased (0.177789 --> 0.172898).  Saving model ...
	 Train_Loss: 0.1936 Train_Acc: 95.780 Val_Loss: 0.1729  BEST VAL Loss: 0.1729  Val_Acc: 95.580

Epoch 10: Validation loss decreased (0.172898 --> 0.168525).  Saving model ...
	 Train_Loss: 0.1857 Train_Acc: 95.993 Val_Loss: 0.1685  BEST VAL Loss: 0.1685  Val_Acc: 95.810

Epoch 11: Validation loss decreased (0.168525 --> 0.164917).  Saving model ...
	 Train_Loss: 0.1783 Train_Acc: 96.275 Val_Loss: 0.1649  BEST VAL Loss: 0.1649  Val_Acc: 95.856

Epoch 12: Validation loss decreased (0.164917 --> 0.160341).  Saving model ...
	 Train_Loss: 0.1718 Train_Acc: 96.391 Val_Loss: 0.1603  BEST VAL Loss: 0.1603  Val_Acc: 95.534

Epoch 13: Validation loss decreased (0.160341 --> 0.158647).  Saving model ...
	 Train_Loss: 0.1664 Train_Acc: 96.546 Val_Loss: 0.1586  BEST VAL Loss: 0.1586  Val_Acc: 95.994

Epoch 14: Validation loss decreased (0.158647 --> 0.156463).  Saving model ...
	 Train_Loss: 0.1618 Train_Acc: 96.218 Val_Loss: 0.1565  BEST VAL Loss: 0.1565  Val_Acc: 95.488

Epoch 15: Validation loss decreased (0.156463 --> 0.154181).  Saving model ...
	 Train_Loss: 0.1575 Train_Acc: 96.368 Val_Loss: 0.1542  BEST VAL Loss: 0.1542  Val_Acc: 95.948

Epoch 16: Validation loss decreased (0.154181 --> 0.152164).  Saving model ...
	 Train_Loss: 0.1536 Train_Acc: 96.500 Val_Loss: 0.1522  BEST VAL Loss: 0.1522  Val_Acc: 96.225

Epoch 17: Validation loss decreased (0.152164 --> 0.150473).  Saving model ...
	 Train_Loss: 0.1498 Train_Acc: 96.880 Val_Loss: 0.1505  BEST VAL Loss: 0.1505  Val_Acc: 95.764

Epoch 18: Validation loss did not decrease
	 Train_Loss: 0.1459 Train_Acc: 97.237 Val_Loss: 0.1514  BEST VAL Loss: 0.1505  Val_Acc: 95.580

Epoch 19: Validation loss did not decrease
	 Train_Loss: 0.1428 Train_Acc: 96.834 Val_Loss: 0.1528  BEST VAL Loss: 0.1505  Val_Acc: 95.396

Epoch 20: Validation loss did not decrease
	 Train_Loss: 0.1400 Train_Acc: 96.805 Val_Loss: 0.1522  BEST VAL Loss: 0.1505  Val_Acc: 95.994

Epoch 21: Validation loss did not decrease
	 Train_Loss: 0.1371 Train_Acc: 97.035 Val_Loss: 0.1520  BEST VAL Loss: 0.1505  Val_Acc: 96.133

Epoch 22: Validation loss did not decrease
	 Train_Loss: 0.1346 Train_Acc: 97.156 Val_Loss: 0.1531  BEST VAL Loss: 0.1505  Val_Acc: 95.994

Epoch 23: Validation loss did not decrease
	 Train_Loss: 0.1321 Train_Acc: 97.260 Val_Loss: 0.1519  BEST VAL Loss: 0.1505  Val_Acc: 95.856

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.1296 Train_Acc: 97.271 Val_Loss: 0.1529  BEST VAL Loss: 0.1505  Val_Acc: 96.271

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.1274 Train_Acc: 97.300 Val_Loss: 0.1535  BEST VAL Loss: 0.1505  Val_Acc: 96.087

Epoch 26: Validation loss did not decrease
	 Train_Loss: 0.1252 Train_Acc: 97.369 Val_Loss: 0.1519  BEST VAL Loss: 0.1505  Val_Acc: 96.317

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.1233 Train_Acc: 97.386 Val_Loss: 0.1528  BEST VAL Loss: 0.1505  Val_Acc: 96.271

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.1213 Train_Acc: 97.450 Val_Loss: 0.1523  BEST VAL Loss: 0.1505  Val_Acc: 96.409

Epoch 29: Validation loss did not decrease
	 Train_Loss: 0.1194 Train_Acc: 97.646 Val_Loss: 0.1524  BEST VAL Loss: 0.1505  Val_Acc: 96.547

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.1177 Train_Acc: 97.640 Val_Loss: 0.1523  BEST VAL Loss: 0.1505  Val_Acc: 96.271

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.1159 Train_Acc: 97.686 Val_Loss: 0.1518  BEST VAL Loss: 0.1505  Val_Acc: 96.731

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.1143 Train_Acc: 97.709 Val_Loss: 0.1509  BEST VAL Loss: 0.1505  Val_Acc: 96.547

Epoch 33: Validation loss did not decrease
Early stopped at epoch : 33
Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.54      0.54      0.54      9433
           1       0.46      0.46      0.46      7938

    accuracy                           0.50     17371
   macro avg       0.50      0.50      0.50     17371
weighted avg       0.50      0.50      0.50     17371

Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.54      0.55      1179
           1       0.46      0.47      0.47       993

    accuracy                           0.51      2172
   macro avg       0.51      0.51      0.51      2172
weighted avg       0.51      0.51      0.51      2172

Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.54      0.54      1180
           1       0.46      0.47      0.47       992

    accuracy                           0.51      2172
   macro avg       0.51      0.51      0.51      2172
weighted avg       0.51      0.51      0.51      2172

              precision    recall  f1-score   support

           0       0.55      0.54      0.54      1180
           1       0.46      0.47      0.47       992

    accuracy                           0.51      2172
   macro avg       0.51      0.51      0.51      2172
weighted avg       0.51      0.51      0.51      2172

Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.55      0.54      4017
           1       0.49      0.47      0.48      3729

    accuracy                           0.51      7746
   macro avg       0.51      0.51      0.51      7746
weighted avg       0.51      0.51      0.51      7746

              precision    recall  f1-score   support

           0       0.53      0.55      0.54      4017
           1       0.49      0.47      0.48      3729

    accuracy                           0.51      7746
   macro avg       0.51      0.51      0.51      7746
weighted avg       0.51      0.51      0.51      7746

completed
