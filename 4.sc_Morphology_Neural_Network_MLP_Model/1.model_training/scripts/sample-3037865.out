[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1af26ba5'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '4be49d39'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '39657588'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '84809dbc'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_0.100_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: Flagellin_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['Flagellin_0.100_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (30737, 1276)
Number of total missing values across all columns: 61474
Data Subset Is Off
Wells held out for testing: ['M18' 'L22']
Wells to use for training, validation, and testing ['L18' 'L19' 'M19' 'M22' 'L23' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.696304).  Saving model ...
	 Train_Loss: 0.8760 Train_Acc: 50.427 Val_Loss: 0.6963  BEST VAL Loss: 0.6963  Val_Acc: 55.393

Epoch 1: Validation loss decreased (0.696304 --> 0.695123).  Saving model ...
	 Train_Loss: 0.7917 Train_Acc: 52.963 Val_Loss: 0.6951  BEST VAL Loss: 0.6951  Val_Acc: 55.126

Epoch 2: Validation loss decreased (0.695123 --> 0.683960).  Saving model ...
	 Train_Loss: 0.7590 Train_Acc: 55.183 Val_Loss: 0.6840  BEST VAL Loss: 0.6840  Val_Acc: 59.343

Epoch 3: Validation loss decreased (0.683960 --> 0.677559).  Saving model ...
	 Train_Loss: 0.7368 Train_Acc: 58.157 Val_Loss: 0.6776  BEST VAL Loss: 0.6776  Val_Acc: 60.675

Epoch 4: Validation loss decreased (0.677559 --> 0.671037).  Saving model ...
	 Train_Loss: 0.7217 Train_Acc: 58.196 Val_Loss: 0.6710  BEST VAL Loss: 0.6710  Val_Acc: 61.873

Epoch 5: Validation loss decreased (0.671037 --> 0.667112).  Saving model ...
	 Train_Loss: 0.7083 Train_Acc: 61.497 Val_Loss: 0.6671  BEST VAL Loss: 0.6671  Val_Acc: 62.628

Epoch 6: Validation loss decreased (0.667112 --> 0.662079).  Saving model ...
	 Train_Loss: 0.6983 Train_Acc: 62.130 Val_Loss: 0.6621  BEST VAL Loss: 0.6621  Val_Acc: 65.158

Epoch 7: Validation loss decreased (0.662079 --> 0.660337).  Saving model ...
	 Train_Loss: 0.6878 Train_Acc: 63.600 Val_Loss: 0.6603  BEST VAL Loss: 0.6603  Val_Acc: 64.004

Epoch 8: Validation loss decreased (0.660337 --> 0.657246).  Saving model ...
	 Train_Loss: 0.6798 Train_Acc: 63.883 Val_Loss: 0.6572  BEST VAL Loss: 0.6572  Val_Acc: 65.601

Epoch 9: Validation loss decreased (0.657246 --> 0.653556).  Saving model ...
	 Train_Loss: 0.6729 Train_Acc: 64.832 Val_Loss: 0.6536  BEST VAL Loss: 0.6536  Val_Acc: 65.957

Epoch 10: Validation loss decreased (0.653556 --> 0.650577).  Saving model ...
	 Train_Loss: 0.6654 Train_Acc: 65.942 Val_Loss: 0.6506  BEST VAL Loss: 0.6506  Val_Acc: 66.400

Epoch 11: Validation loss decreased (0.650577 --> 0.646522).  Saving model ...
	 Train_Loss: 0.6618 Train_Acc: 66.008 Val_Loss: 0.6465  BEST VAL Loss: 0.6465  Val_Acc: 67.599

Epoch 12: Validation loss decreased (0.646522 --> 0.643045).  Saving model ...
	 Train_Loss: 0.6565 Train_Acc: 66.036 Val_Loss: 0.6430  BEST VAL Loss: 0.6430  Val_Acc: 68.486

Epoch 13: Validation loss decreased (0.643045 --> 0.641174).  Saving model ...
	 Train_Loss: 0.6514 Train_Acc: 67.423 Val_Loss: 0.6412  BEST VAL Loss: 0.6412  Val_Acc: 67.599

Epoch 14: Validation loss decreased (0.641174 --> 0.639001).  Saving model ...
	 Train_Loss: 0.6472 Train_Acc: 66.435 Val_Loss: 0.6390  BEST VAL Loss: 0.6390  Val_Acc: 68.531

Epoch 15: Validation loss decreased (0.639001 --> 0.637544).  Saving model ...
	 Train_Loss: 0.6432 Train_Acc: 67.168 Val_Loss: 0.6375  BEST VAL Loss: 0.6375  Val_Acc: 68.797

Epoch 16: Validation loss decreased (0.637544 --> 0.637475).  Saving model ...
	 Train_Loss: 0.6401 Train_Acc: 67.151 Val_Loss: 0.6375  BEST VAL Loss: 0.6375  Val_Acc: 68.753

Epoch 17: Validation loss decreased (0.637475 --> 0.634662).  Saving model ...
	 Train_Loss: 0.6371 Train_Acc: 67.101 Val_Loss: 0.6347  BEST VAL Loss: 0.6347  Val_Acc: 68.353

Epoch 18: Validation loss decreased (0.634662 --> 0.633019).  Saving model ...
	 Train_Loss: 0.6336 Train_Acc: 68.122 Val_Loss: 0.6330  BEST VAL Loss: 0.6330  Val_Acc: 69.463

Epoch 19: Validation loss decreased (0.633019 --> 0.631817).  Saving model ...
	 Train_Loss: 0.6297 Train_Acc: 68.788 Val_Loss: 0.6318  BEST VAL Loss: 0.6318  Val_Acc: 69.108

Epoch 20: Validation loss decreased (0.631817 --> 0.630719).  Saving model ...
	 Train_Loss: 0.6266 Train_Acc: 68.955 Val_Loss: 0.6307  BEST VAL Loss: 0.6307  Val_Acc: 68.620

Epoch 21: Validation loss decreased (0.630719 --> 0.628997).  Saving model ...
	 Train_Loss: 0.6231 Train_Acc: 69.737 Val_Loss: 0.6290  BEST VAL Loss: 0.6290  Val_Acc: 69.063

Epoch 22: Validation loss did not decrease
	 Train_Loss: 0.6194 Train_Acc: 70.392 Val_Loss: 0.6292  BEST VAL Loss: 0.6290  Val_Acc: 67.954

Epoch 23: Validation loss decreased (0.628997 --> 0.628024).  Saving model ...
	 Train_Loss: 0.6164 Train_Acc: 70.275 Val_Loss: 0.6280  BEST VAL Loss: 0.6280  Val_Acc: 69.507

Epoch 24: Validation loss decreased (0.628024 --> 0.626457).  Saving model ...
	 Train_Loss: 0.6134 Train_Acc: 70.164 Val_Loss: 0.6265  BEST VAL Loss: 0.6265  Val_Acc: 70.040

Epoch 25: Validation loss decreased (0.626457 --> 0.625644).  Saving model ...
	 Train_Loss: 0.6102 Train_Acc: 70.591 Val_Loss: 0.6256  BEST VAL Loss: 0.6256  Val_Acc: 69.374

Epoch 26: Validation loss decreased (0.625644 --> 0.625222).  Saving model ...
	 Train_Loss: 0.6072 Train_Acc: 71.191 Val_Loss: 0.6252  BEST VAL Loss: 0.6252  Val_Acc: 69.862

Epoch 27: Validation loss decreased (0.625222 --> 0.623702).  Saving model ...
	 Train_Loss: 0.6043 Train_Acc: 71.324 Val_Loss: 0.6237  BEST VAL Loss: 0.6237  Val_Acc: 70.262

Epoch 28: Validation loss decreased (0.623702 --> 0.622990).  Saving model ...
	 Train_Loss: 0.6015 Train_Acc: 71.424 Val_Loss: 0.6230  BEST VAL Loss: 0.6230  Val_Acc: 69.907

Epoch 29: Validation loss decreased (0.622990 --> 0.621712).  Saving model ...
	 Train_Loss: 0.5985 Train_Acc: 72.473 Val_Loss: 0.6217  BEST VAL Loss: 0.6217  Val_Acc: 69.596

Epoch 30: Validation loss decreased (0.621712 --> 0.620895).  Saving model ...
	 Train_Loss: 0.5955 Train_Acc: 72.772 Val_Loss: 0.6209  BEST VAL Loss: 0.6209  Val_Acc: 69.640

Epoch 31: Validation loss decreased (0.620895 --> 0.619634).  Saving model ...
	 Train_Loss: 0.5926 Train_Acc: 72.789 Val_Loss: 0.6196  BEST VAL Loss: 0.6196  Val_Acc: 69.729

Epoch 32: Validation loss decreased (0.619634 --> 0.618359).  Saving model ...
	 Train_Loss: 0.5897 Train_Acc: 73.421 Val_Loss: 0.6184  BEST VAL Loss: 0.6184  Val_Acc: 70.484

Epoch 33: Validation loss decreased (0.618359 --> 0.617613).  Saving model ...
	 Train_Loss: 0.5869 Train_Acc: 73.199 Val_Loss: 0.6176  BEST VAL Loss: 0.6176  Val_Acc: 69.374

Epoch 34: Validation loss decreased (0.617613 --> 0.617181).  Saving model ...
	 Train_Loss: 0.5843 Train_Acc: 73.211 Val_Loss: 0.6172  BEST VAL Loss: 0.6172  Val_Acc: 67.688

Epoch 35: Validation loss decreased (0.617181 --> 0.616989).  Saving model ...
	 Train_Loss: 0.5819 Train_Acc: 73.721 Val_Loss: 0.6170  BEST VAL Loss: 0.6170  Val_Acc: 69.640

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.5795 Train_Acc: 73.294 Val_Loss: 0.6175  BEST VAL Loss: 0.6170  Val_Acc: 69.507

Epoch 37: Validation loss decreased (0.616989 --> 0.616742).  Saving model ...
	 Train_Loss: 0.5775 Train_Acc: 73.571 Val_Loss: 0.6167  BEST VAL Loss: 0.6167  Val_Acc: 69.241

Epoch 38: Validation loss decreased (0.616742 --> 0.616579).  Saving model ...
	 Train_Loss: 0.5755 Train_Acc: 73.704 Val_Loss: 0.6166  BEST VAL Loss: 0.6166  Val_Acc: 69.197

Epoch 39: Validation loss decreased (0.616579 --> 0.616350).  Saving model ...
	 Train_Loss: 0.5734 Train_Acc: 73.222 Val_Loss: 0.6163  BEST VAL Loss: 0.6163  Val_Acc: 69.241

Epoch 40: Validation loss decreased (0.616350 --> 0.616294).  Saving model ...
	 Train_Loss: 0.5713 Train_Acc: 73.926 Val_Loss: 0.6163  BEST VAL Loss: 0.6163  Val_Acc: 69.774

Epoch 41: Validation loss decreased (0.616294 --> 0.616192).  Saving model ...
	 Train_Loss: 0.5693 Train_Acc: 74.487 Val_Loss: 0.6162  BEST VAL Loss: 0.6162  Val_Acc: 70.395

Epoch 42: Validation loss decreased (0.616192 --> 0.615594).  Saving model ...
	 Train_Loss: 0.5674 Train_Acc: 73.943 Val_Loss: 0.6156  BEST VAL Loss: 0.6156  Val_Acc: 68.353

Epoch 43: Validation loss decreased (0.615594 --> 0.615311).  Saving model ...
	 Train_Loss: 0.5656 Train_Acc: 74.304 Val_Loss: 0.6153  BEST VAL Loss: 0.6153  Val_Acc: 70.129

Epoch 44: Validation loss decreased (0.615311 --> 0.615128).  Saving model ...
	 Train_Loss: 0.5637 Train_Acc: 74.603 Val_Loss: 0.6151  BEST VAL Loss: 0.6151  Val_Acc: 69.552

Epoch 45: Validation loss decreased (0.615128 --> 0.614710).  Saving model ...
	 Train_Loss: 0.5619 Train_Acc: 74.126 Val_Loss: 0.6147  BEST VAL Loss: 0.6147  Val_Acc: 69.330

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.5601 Train_Acc: 74.487 Val_Loss: 0.6153  BEST VAL Loss: 0.6147  Val_Acc: 68.930

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.5584 Train_Acc: 74.720 Val_Loss: 0.6149  BEST VAL Loss: 0.6147  Val_Acc: 69.152

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.5565 Train_Acc: 74.958 Val_Loss: 0.6155  BEST VAL Loss: 0.6147  Val_Acc: 68.708

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.5546 Train_Acc: 75.297 Val_Loss: 0.6160  BEST VAL Loss: 0.6147  Val_Acc: 68.531

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.5527 Train_Acc: 75.413 Val_Loss: 0.6162  BEST VAL Loss: 0.6147  Val_Acc: 70.484

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.5508 Train_Acc: 76.246 Val_Loss: 0.6163  BEST VAL Loss: 0.6147  Val_Acc: 69.552

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.5491 Train_Acc: 74.925 Val_Loss: 0.6166  BEST VAL Loss: 0.6147  Val_Acc: 69.197

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.5475 Train_Acc: 75.180 Val_Loss: 0.6170  BEST VAL Loss: 0.6147  Val_Acc: 69.063

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.5458 Train_Acc: 76.240 Val_Loss: 0.6179  BEST VAL Loss: 0.6147  Val_Acc: 68.886

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.5441 Train_Acc: 76.157 Val_Loss: 0.6191  BEST VAL Loss: 0.6147  Val_Acc: 69.463

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.5425 Train_Acc: 76.240 Val_Loss: 0.6197  BEST VAL Loss: 0.6147  Val_Acc: 69.152

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.5408 Train_Acc: 76.401 Val_Loss: 0.6205  BEST VAL Loss: 0.6147  Val_Acc: 69.774

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.5392 Train_Acc: 76.828 Val_Loss: 0.6212  BEST VAL Loss: 0.6147  Val_Acc: 69.241

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.5377 Train_Acc: 76.640 Val_Loss: 0.6212  BEST VAL Loss: 0.6147  Val_Acc: 68.664

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.5363 Train_Acc: 76.113 Val_Loss: 0.6215  BEST VAL Loss: 0.6147  Val_Acc: 68.886

Epoch 61: Validation loss did not decrease
Early stopped at epoch : 61
Flagellin_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.77      0.81      0.79      8635
           1       0.82      0.78      0.80      9387

    accuracy                           0.79     18022
   macro avg       0.79      0.79      0.79     18022
weighted avg       0.79      0.79      0.79     18022

Flagellin_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.67      0.70      0.69      1079
           1       0.71      0.69      0.70      1174

    accuracy                           0.69      2253
   macro avg       0.69      0.69      0.69      2253
weighted avg       0.69      0.69      0.69      2253

Flagellin_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.66      0.71      0.68      1079
           1       0.71      0.67      0.69      1174

    accuracy                           0.69      2253
   macro avg       0.69      0.69      0.69      2253
weighted avg       0.69      0.69      0.69      2253

              precision    recall  f1-score   support

           0       0.66      0.71      0.68      1079
           1       0.71      0.67      0.69      1174

    accuracy                           0.69      2253
   macro avg       0.69      0.69      0.69      2253
weighted avg       0.69      0.69      0.69      2253

Flagellin_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.44      0.52      0.48      4135
           1       0.40      0.33      0.36      4074

    accuracy                           0.42      8209
   macro avg       0.42      0.42      0.42      8209
weighted avg       0.42      0.42      0.42      8209

              precision    recall  f1-score   support

           0       0.44      0.52      0.48      4135
           1       0.40      0.33      0.36      4074

    accuracy                           0.42      8209
   macro avg       0.42      0.42      0.42      8209
weighted avg       0.42      0.42      0.42      8209

completed
