[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '99176d5b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'ce9b4886'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1ceb640f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'c07c053a'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_0.100_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_100.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (30915, 1276)
Number of total missing values across all columns: 61830
Data Subset Is Off
Wells held out for testing: ['J16' 'L22']
Wells to use for training, validation, and testing ['J17' 'L18' 'L19' 'J20' 'J21' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.490683).  Saving model ...
	 Train_Loss: 0.6238 Train_Acc: 65.674 Val_Loss: 0.4907  BEST VAL Loss: 0.4907  Val_Acc: 81.614

Epoch 1: Validation loss decreased (0.490683 --> 0.424468).  Saving model ...
	 Train_Loss: 0.5601 Train_Acc: 77.344 Val_Loss: 0.4245  BEST VAL Loss: 0.4245  Val_Acc: 86.508

Epoch 2: Validation loss decreased (0.424468 --> 0.373951).  Saving model ...
	 Train_Loss: 0.5095 Train_Acc: 82.327 Val_Loss: 0.3740  BEST VAL Loss: 0.3740  Val_Acc: 89.727

Epoch 3: Validation loss decreased (0.373951 --> 0.332997).  Saving model ...
	 Train_Loss: 0.4648 Train_Acc: 86.087 Val_Loss: 0.3330  BEST VAL Loss: 0.3330  Val_Acc: 91.887

Epoch 4: Validation loss decreased (0.332997 --> 0.308191).  Saving model ...
	 Train_Loss: 0.4328 Train_Acc: 87.294 Val_Loss: 0.3082  BEST VAL Loss: 0.3082  Val_Acc: 91.931

Epoch 5: Validation loss decreased (0.308191 --> 0.288460).  Saving model ...
	 Train_Loss: 0.4072 Train_Acc: 88.545 Val_Loss: 0.2885  BEST VAL Loss: 0.2885  Val_Acc: 92.813

Epoch 6: Validation loss decreased (0.288460 --> 0.271447).  Saving model ...
	 Train_Loss: 0.3863 Train_Acc: 89.008 Val_Loss: 0.2714  BEST VAL Loss: 0.2714  Val_Acc: 93.563

Epoch 7: Validation loss decreased (0.271447 --> 0.262411).  Saving model ...
	 Train_Loss: 0.3705 Train_Acc: 89.102 Val_Loss: 0.2624  BEST VAL Loss: 0.2624  Val_Acc: 93.783

Epoch 8: Validation loss decreased (0.262411 --> 0.251815).  Saving model ...
	 Train_Loss: 0.3575 Train_Acc: 88.766 Val_Loss: 0.2518  BEST VAL Loss: 0.2518  Val_Acc: 94.444

Epoch 9: Validation loss decreased (0.251815 --> 0.245069).  Saving model ...
	 Train_Loss: 0.3453 Train_Acc: 89.835 Val_Loss: 0.2451  BEST VAL Loss: 0.2451  Val_Acc: 93.959

Epoch 10: Validation loss decreased (0.245069 --> 0.238747).  Saving model ...
	 Train_Loss: 0.3355 Train_Acc: 89.631 Val_Loss: 0.2387  BEST VAL Loss: 0.2387  Val_Acc: 93.695

Epoch 11: Validation loss decreased (0.238747 --> 0.232354).  Saving model ...
	 Train_Loss: 0.3271 Train_Acc: 89.642 Val_Loss: 0.2324  BEST VAL Loss: 0.2324  Val_Acc: 93.827

Epoch 12: Validation loss decreased (0.232354 --> 0.227264).  Saving model ...
	 Train_Loss: 0.3190 Train_Acc: 90.188 Val_Loss: 0.2273  BEST VAL Loss: 0.2273  Val_Acc: 94.621

Epoch 13: Validation loss decreased (0.227264 --> 0.222559).  Saving model ...
	 Train_Loss: 0.3116 Train_Acc: 90.486 Val_Loss: 0.2226  BEST VAL Loss: 0.2226  Val_Acc: 94.841

Epoch 14: Validation loss decreased (0.222559 --> 0.221427).  Saving model ...
	 Train_Loss: 0.3046 Train_Acc: 90.883 Val_Loss: 0.2214  BEST VAL Loss: 0.2214  Val_Acc: 94.356

Epoch 15: Validation loss decreased (0.221427 --> 0.217306).  Saving model ...
	 Train_Loss: 0.2998 Train_Acc: 90.083 Val_Loss: 0.2173  BEST VAL Loss: 0.2173  Val_Acc: 94.444

Epoch 16: Validation loss decreased (0.217306 --> 0.213556).  Saving model ...
	 Train_Loss: 0.2952 Train_Acc: 89.923 Val_Loss: 0.2136  BEST VAL Loss: 0.2136  Val_Acc: 93.783

Epoch 17: Validation loss decreased (0.213556 --> 0.210183).  Saving model ...
	 Train_Loss: 0.2904 Train_Acc: 90.557 Val_Loss: 0.2102  BEST VAL Loss: 0.2102  Val_Acc: 94.444

Epoch 18: Validation loss decreased (0.210183 --> 0.206559).  Saving model ...
	 Train_Loss: 0.2857 Train_Acc: 91.390 Val_Loss: 0.2066  BEST VAL Loss: 0.2066  Val_Acc: 95.062

Epoch 19: Validation loss decreased (0.206559 --> 0.204250).  Saving model ...
	 Train_Loss: 0.2810 Train_Acc: 91.373 Val_Loss: 0.2042  BEST VAL Loss: 0.2042  Val_Acc: 94.136

Epoch 20: Validation loss decreased (0.204250 --> 0.202620).  Saving model ...
	 Train_Loss: 0.2769 Train_Acc: 91.296 Val_Loss: 0.2026  BEST VAL Loss: 0.2026  Val_Acc: 94.268

Epoch 21: Validation loss decreased (0.202620 --> 0.200031).  Saving model ...
	 Train_Loss: 0.2730 Train_Acc: 91.186 Val_Loss: 0.2000  BEST VAL Loss: 0.2000  Val_Acc: 94.974

Epoch 22: Validation loss decreased (0.200031 --> 0.198233).  Saving model ...
	 Train_Loss: 0.2693 Train_Acc: 91.224 Val_Loss: 0.1982  BEST VAL Loss: 0.1982  Val_Acc: 94.709

Epoch 23: Validation loss decreased (0.198233 --> 0.195949).  Saving model ...
	 Train_Loss: 0.2658 Train_Acc: 91.594 Val_Loss: 0.1959  BEST VAL Loss: 0.1959  Val_Acc: 94.797

Epoch 24: Validation loss decreased (0.195949 --> 0.194875).  Saving model ...
	 Train_Loss: 0.2627 Train_Acc: 91.307 Val_Loss: 0.1949  BEST VAL Loss: 0.1949  Val_Acc: 93.034

Epoch 25: Validation loss decreased (0.194875 --> 0.194050).  Saving model ...
	 Train_Loss: 0.2602 Train_Acc: 90.844 Val_Loss: 0.1940  BEST VAL Loss: 0.1940  Val_Acc: 93.915

Epoch 26: Validation loss decreased (0.194050 --> 0.192665).  Saving model ...
	 Train_Loss: 0.2574 Train_Acc: 91.472 Val_Loss: 0.1927  BEST VAL Loss: 0.1927  Val_Acc: 94.180

Epoch 27: Validation loss decreased (0.192665 --> 0.190731).  Saving model ...
	 Train_Loss: 0.2545 Train_Acc: 91.946 Val_Loss: 0.1907  BEST VAL Loss: 0.1907  Val_Acc: 94.797

Epoch 28: Validation loss decreased (0.190731 --> 0.189284).  Saving model ...
	 Train_Loss: 0.2519 Train_Acc: 91.742 Val_Loss: 0.1893  BEST VAL Loss: 0.1893  Val_Acc: 94.489

Epoch 29: Validation loss decreased (0.189284 --> 0.187717).  Saving model ...
	 Train_Loss: 0.2494 Train_Acc: 91.572 Val_Loss: 0.1877  BEST VAL Loss: 0.1877  Val_Acc: 94.356

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.2472 Train_Acc: 91.544 Val_Loss: 0.1878  BEST VAL Loss: 0.1877  Val_Acc: 94.400

Epoch 31: Validation loss decreased (0.187717 --> 0.186179).  Saving model ...
	 Train_Loss: 0.2451 Train_Acc: 91.638 Val_Loss: 0.1862  BEST VAL Loss: 0.1862  Val_Acc: 94.885

Epoch 32: Validation loss decreased (0.186179 --> 0.185769).  Saving model ...
	 Train_Loss: 0.2429 Train_Acc: 92.079 Val_Loss: 0.1858  BEST VAL Loss: 0.1858  Val_Acc: 95.062

Epoch 33: Validation loss decreased (0.185769 --> 0.185210).  Saving model ...
	 Train_Loss: 0.2410 Train_Acc: 91.787 Val_Loss: 0.1852  BEST VAL Loss: 0.1852  Val_Acc: 95.018

Epoch 34: Validation loss decreased (0.185210 --> 0.184709).  Saving model ...
	 Train_Loss: 0.2391 Train_Acc: 91.676 Val_Loss: 0.1847  BEST VAL Loss: 0.1847  Val_Acc: 94.797

Epoch 35: Validation loss decreased (0.184709 --> 0.184142).  Saving model ...
	 Train_Loss: 0.2372 Train_Acc: 92.013 Val_Loss: 0.1841  BEST VAL Loss: 0.1841  Val_Acc: 94.841

Epoch 36: Validation loss decreased (0.184142 --> 0.183770).  Saving model ...
	 Train_Loss: 0.2354 Train_Acc: 92.250 Val_Loss: 0.1838  BEST VAL Loss: 0.1838  Val_Acc: 94.400

Epoch 37: Validation loss decreased (0.183770 --> 0.183476).  Saving model ...
	 Train_Loss: 0.2337 Train_Acc: 91.864 Val_Loss: 0.1835  BEST VAL Loss: 0.1835  Val_Acc: 93.386

Epoch 38: Validation loss decreased (0.183476 --> 0.182619).  Saving model ...
	 Train_Loss: 0.2322 Train_Acc: 92.266 Val_Loss: 0.1826  BEST VAL Loss: 0.1826  Val_Acc: 94.753

Epoch 39: Validation loss decreased (0.182619 --> 0.181699).  Saving model ...
	 Train_Loss: 0.2309 Train_Acc: 91.533 Val_Loss: 0.1817  BEST VAL Loss: 0.1817  Val_Acc: 93.739

Epoch 40: Validation loss decreased (0.181699 --> 0.180562).  Saving model ...
	 Train_Loss: 0.2295 Train_Acc: 91.875 Val_Loss: 0.1806  BEST VAL Loss: 0.1806  Val_Acc: 93.607

Epoch 41: Validation loss decreased (0.180562 --> 0.180039).  Saving model ...
	 Train_Loss: 0.2282 Train_Acc: 92.057 Val_Loss: 0.1800  BEST VAL Loss: 0.1800  Val_Acc: 93.959

Epoch 42: Validation loss decreased (0.180039 --> 0.179180).  Saving model ...
	 Train_Loss: 0.2271 Train_Acc: 91.379 Val_Loss: 0.1792  BEST VAL Loss: 0.1792  Val_Acc: 93.342

Epoch 43: Validation loss decreased (0.179180 --> 0.178280).  Saving model ...
	 Train_Loss: 0.2260 Train_Acc: 91.665 Val_Loss: 0.1783  BEST VAL Loss: 0.1783  Val_Acc: 93.739

Epoch 44: Validation loss decreased (0.178280 --> 0.177230).  Saving model ...
	 Train_Loss: 0.2248 Train_Acc: 91.853 Val_Loss: 0.1772  BEST VAL Loss: 0.1772  Val_Acc: 93.695

Epoch 45: Validation loss decreased (0.177230 --> 0.176387).  Saving model ...
	 Train_Loss: 0.2236 Train_Acc: 91.908 Val_Loss: 0.1764  BEST VAL Loss: 0.1764  Val_Acc: 94.004

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.2223 Train_Acc: 92.211 Val_Loss: 0.1764  BEST VAL Loss: 0.1764  Val_Acc: 95.194

Epoch 47: Validation loss decreased (0.176387 --> 0.175627).  Saving model ...
	 Train_Loss: 0.2211 Train_Acc: 92.161 Val_Loss: 0.1756  BEST VAL Loss: 0.1756  Val_Acc: 93.959

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.2200 Train_Acc: 92.073 Val_Loss: 0.1757  BEST VAL Loss: 0.1756  Val_Acc: 93.827

Epoch 49: Validation loss decreased (0.175627 --> 0.175270).  Saving model ...
	 Train_Loss: 0.2190 Train_Acc: 92.079 Val_Loss: 0.1753  BEST VAL Loss: 0.1753  Val_Acc: 93.739

Epoch 50: Validation loss decreased (0.175270 --> 0.174564).  Saving model ...
	 Train_Loss: 0.2183 Train_Acc: 91.522 Val_Loss: 0.1746  BEST VAL Loss: 0.1746  Val_Acc: 93.210

Epoch 51: Validation loss decreased (0.174564 --> 0.174267).  Saving model ...
	 Train_Loss: 0.2176 Train_Acc: 91.527 Val_Loss: 0.1743  BEST VAL Loss: 0.1743  Val_Acc: 94.709

Epoch 52: Validation loss decreased (0.174267 --> 0.174171).  Saving model ...
	 Train_Loss: 0.2167 Train_Acc: 92.035 Val_Loss: 0.1742  BEST VAL Loss: 0.1742  Val_Acc: 93.915

Epoch 53: Validation loss decreased (0.174171 --> 0.173846).  Saving model ...
	 Train_Loss: 0.2158 Train_Acc: 91.919 Val_Loss: 0.1738  BEST VAL Loss: 0.1738  Val_Acc: 94.092

Epoch 54: Validation loss decreased (0.173846 --> 0.173329).  Saving model ...
	 Train_Loss: 0.2149 Train_Acc: 92.432 Val_Loss: 0.1733  BEST VAL Loss: 0.1733  Val_Acc: 94.224

Epoch 55: Validation loss decreased (0.173329 --> 0.173002).  Saving model ...
	 Train_Loss: 0.2139 Train_Acc: 92.773 Val_Loss: 0.1730  BEST VAL Loss: 0.1730  Val_Acc: 94.048

Epoch 56: Validation loss decreased (0.173002 --> 0.172914).  Saving model ...
	 Train_Loss: 0.2130 Train_Acc: 92.332 Val_Loss: 0.1729  BEST VAL Loss: 0.1729  Val_Acc: 94.092

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.2121 Train_Acc: 92.757 Val_Loss: 0.1730  BEST VAL Loss: 0.1729  Val_Acc: 94.224

Epoch 58: Validation loss decreased (0.172914 --> 0.172517).  Saving model ...
	 Train_Loss: 0.2112 Train_Acc: 92.167 Val_Loss: 0.1725  BEST VAL Loss: 0.1725  Val_Acc: 94.092

Epoch 59: Validation loss decreased (0.172517 --> 0.172477).  Saving model ...
	 Train_Loss: 0.2103 Train_Acc: 92.454 Val_Loss: 0.1725  BEST VAL Loss: 0.1725  Val_Acc: 94.621

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.2094 Train_Acc: 92.702 Val_Loss: 0.1727  BEST VAL Loss: 0.1725  Val_Acc: 94.180

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.2086 Train_Acc: 92.487 Val_Loss: 0.1726  BEST VAL Loss: 0.1725  Val_Acc: 94.312

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.2077 Train_Acc: 92.779 Val_Loss: 0.1733  BEST VAL Loss: 0.1725  Val_Acc: 94.048

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.2069 Train_Acc: 92.735 Val_Loss: 0.1740  BEST VAL Loss: 0.1725  Val_Acc: 93.959

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.2061 Train_Acc: 92.872 Val_Loss: 0.1739  BEST VAL Loss: 0.1725  Val_Acc: 94.489

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.2056 Train_Acc: 92.222 Val_Loss: 0.1737  BEST VAL Loss: 0.1725  Val_Acc: 94.268

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.2050 Train_Acc: 92.062 Val_Loss: 0.1742  BEST VAL Loss: 0.1725  Val_Acc: 94.180

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.2043 Train_Acc: 92.884 Val_Loss: 0.1741  BEST VAL Loss: 0.1725  Val_Acc: 94.004

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.2036 Train_Acc: 92.382 Val_Loss: 0.1742  BEST VAL Loss: 0.1725  Val_Acc: 94.004

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.2030 Train_Acc: 92.542 Val_Loss: 0.1742  BEST VAL Loss: 0.1725  Val_Acc: 93.651

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.2022 Train_Acc: 93.060 Val_Loss: 0.1741  BEST VAL Loss: 0.1725  Val_Acc: 93.915

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.2015 Train_Acc: 92.867 Val_Loss: 0.1739  BEST VAL Loss: 0.1725  Val_Acc: 93.915

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.2008 Train_Acc: 92.729 Val_Loss: 0.1740  BEST VAL Loss: 0.1725  Val_Acc: 94.400

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.2002 Train_Acc: 92.310 Val_Loss: 0.1738  BEST VAL Loss: 0.1725  Val_Acc: 93.871

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.1996 Train_Acc: 92.492 Val_Loss: 0.1742  BEST VAL Loss: 0.1725  Val_Acc: 94.180

Epoch 75: Validation loss did not decrease
Early stopped at epoch : 75
Flagellin_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.45      0.46      8635
           1       0.52      0.55      0.53      9506

    accuracy                           0.50     18141
   macro avg       0.50      0.50      0.50     18141
weighted avg       0.50      0.50      0.50     18141

Flagellin_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.45      0.46      1079
           1       0.52      0.54      0.53      1189

    accuracy                           0.50      2268
   macro avg       0.49      0.49      0.49      2268
weighted avg       0.50      0.50      0.50      2268

Flagellin_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.45      0.46      1079
           1       0.52      0.55      0.54      1189

    accuracy                           0.50      2268
   macro avg       0.50      0.50      0.50      2268
weighted avg       0.50      0.50      0.50      2268

              precision    recall  f1-score   support

           0       0.48      0.45      0.46      1079
           1       0.52      0.55      0.54      1189

    accuracy                           0.50      2268
   macro avg       0.50      0.50      0.50      2268
weighted avg       0.50      0.50      0.50      2268

Flagellin_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.45      0.47      4135
           1       0.50      0.56      0.53      4103

    accuracy                           0.50      8238
   macro avg       0.50      0.50      0.50      8238
weighted avg       0.50      0.50      0.50      8238

              precision    recall  f1-score   support

           0       0.50      0.45      0.47      4135
           1       0.50      0.56      0.53      4103

    accuracy                           0.50      8238
   macro avg       0.50      0.50      0.50      8238
weighted avg       0.50      0.50      0.50      8238

completed
