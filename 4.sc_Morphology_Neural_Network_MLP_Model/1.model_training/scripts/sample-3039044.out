[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1097267f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'c26f0fdf'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1043d35e'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'f27c13ae'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_0.100_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (32438, 1276)
Number of total missing values across all columns: 64876
Data Subset Is Off
Wells held out for testing: ['C21' 'L22']
Wells to use for training, validation, and testing ['C16' 'C17' 'C20' 'L18' 'L19' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.649459).  Saving model ...
	 Train_Loss: 0.6777 Train_Acc: 56.846 Val_Loss: 0.6495  BEST VAL Loss: 0.6495  Val_Acc: 62.857

Epoch 1: Validation loss decreased (0.649459 --> 0.632989).  Saving model ...
	 Train_Loss: 0.6595 Train_Acc: 63.113 Val_Loss: 0.6330  BEST VAL Loss: 0.6330  Val_Acc: 66.303

Epoch 2: Validation loss decreased (0.632989 --> 0.620499).  Saving model ...
	 Train_Loss: 0.6427 Train_Acc: 66.586 Val_Loss: 0.6205  BEST VAL Loss: 0.6205  Val_Acc: 67.773

Epoch 3: Validation loss decreased (0.620499 --> 0.611294).  Saving model ...
	 Train_Loss: 0.6308 Train_Acc: 68.146 Val_Loss: 0.6113  BEST VAL Loss: 0.6113  Val_Acc: 69.706

Epoch 4: Validation loss decreased (0.611294 --> 0.602554).  Saving model ...
	 Train_Loss: 0.6197 Train_Acc: 69.649 Val_Loss: 0.6026  BEST VAL Loss: 0.6026  Val_Acc: 70.252

Epoch 5: Validation loss decreased (0.602554 --> 0.596566).  Saving model ...
	 Train_Loss: 0.6102 Train_Acc: 70.847 Val_Loss: 0.5966  BEST VAL Loss: 0.5966  Val_Acc: 70.210

Epoch 6: Validation loss decreased (0.596566 --> 0.590950).  Saving model ...
	 Train_Loss: 0.6006 Train_Acc: 71.330 Val_Loss: 0.5910  BEST VAL Loss: 0.5910  Val_Acc: 70.420

Epoch 7: Validation loss decreased (0.590950 --> 0.586405).  Saving model ...
	 Train_Loss: 0.5931 Train_Acc: 72.460 Val_Loss: 0.5864  BEST VAL Loss: 0.5864  Val_Acc: 71.639

Epoch 8: Validation loss decreased (0.586405 --> 0.582205).  Saving model ...
	 Train_Loss: 0.5857 Train_Acc: 73.174 Val_Loss: 0.5822  BEST VAL Loss: 0.5822  Val_Acc: 72.269

Epoch 9: Validation loss decreased (0.582205 --> 0.579056).  Saving model ...
	 Train_Loss: 0.5788 Train_Acc: 73.742 Val_Loss: 0.5791  BEST VAL Loss: 0.5791  Val_Acc: 71.681

Epoch 10: Validation loss decreased (0.579056 --> 0.576136).  Saving model ...
	 Train_Loss: 0.5729 Train_Acc: 74.167 Val_Loss: 0.5761  BEST VAL Loss: 0.5761  Val_Acc: 72.647

Epoch 11: Validation loss decreased (0.576136 --> 0.573510).  Saving model ...
	 Train_Loss: 0.5677 Train_Acc: 74.456 Val_Loss: 0.5735  BEST VAL Loss: 0.5735  Val_Acc: 72.059

Epoch 12: Validation loss decreased (0.573510 --> 0.571100).  Saving model ...
	 Train_Loss: 0.5630 Train_Acc: 74.913 Val_Loss: 0.5711  BEST VAL Loss: 0.5711  Val_Acc: 72.353

Epoch 13: Validation loss decreased (0.571100 --> 0.568764).  Saving model ...
	 Train_Loss: 0.5585 Train_Acc: 75.218 Val_Loss: 0.5688  BEST VAL Loss: 0.5688  Val_Acc: 71.597

Epoch 14: Validation loss decreased (0.568764 --> 0.567296).  Saving model ...
	 Train_Loss: 0.5545 Train_Acc: 74.997 Val_Loss: 0.5673  BEST VAL Loss: 0.5673  Val_Acc: 72.437

Epoch 15: Validation loss decreased (0.567296 --> 0.565399).  Saving model ...
	 Train_Loss: 0.5508 Train_Acc: 75.633 Val_Loss: 0.5654  BEST VAL Loss: 0.5654  Val_Acc: 72.983

Epoch 16: Validation loss decreased (0.565399 --> 0.563548).  Saving model ...
	 Train_Loss: 0.5472 Train_Acc: 76.405 Val_Loss: 0.5635  BEST VAL Loss: 0.5635  Val_Acc: 72.899

Epoch 17: Validation loss decreased (0.563548 --> 0.561321).  Saving model ...
	 Train_Loss: 0.5436 Train_Acc: 76.957 Val_Loss: 0.5613  BEST VAL Loss: 0.5613  Val_Acc: 74.160

Epoch 18: Validation loss decreased (0.561321 --> 0.559475).  Saving model ...
	 Train_Loss: 0.5403 Train_Acc: 76.883 Val_Loss: 0.5595  BEST VAL Loss: 0.5595  Val_Acc: 73.403

Epoch 19: Validation loss decreased (0.559475 --> 0.558054).  Saving model ...
	 Train_Loss: 0.5385 Train_Acc: 75.817 Val_Loss: 0.5581  BEST VAL Loss: 0.5581  Val_Acc: 72.773

Epoch 20: Validation loss decreased (0.558054 --> 0.556848).  Saving model ...
	 Train_Loss: 0.5364 Train_Acc: 75.954 Val_Loss: 0.5568  BEST VAL Loss: 0.5568  Val_Acc: 72.647

Epoch 21: Validation loss decreased (0.556848 --> 0.555357).  Saving model ...
	 Train_Loss: 0.5339 Train_Acc: 76.342 Val_Loss: 0.5554  BEST VAL Loss: 0.5554  Val_Acc: 73.193

Epoch 22: Validation loss decreased (0.555357 --> 0.554200).  Saving model ...
	 Train_Loss: 0.5313 Train_Acc: 77.624 Val_Loss: 0.5542  BEST VAL Loss: 0.5542  Val_Acc: 73.739

Epoch 23: Validation loss decreased (0.554200 --> 0.552675).  Saving model ...
	 Train_Loss: 0.5287 Train_Acc: 77.756 Val_Loss: 0.5527  BEST VAL Loss: 0.5527  Val_Acc: 73.361

Epoch 24: Validation loss decreased (0.552675 --> 0.551673).  Saving model ...
	 Train_Loss: 0.5261 Train_Acc: 78.291 Val_Loss: 0.5517  BEST VAL Loss: 0.5517  Val_Acc: 73.697

Epoch 25: Validation loss decreased (0.551673 --> 0.550568).  Saving model ...
	 Train_Loss: 0.5235 Train_Acc: 78.344 Val_Loss: 0.5506  BEST VAL Loss: 0.5506  Val_Acc: 75.294

Epoch 26: Validation loss decreased (0.550568 --> 0.549247).  Saving model ...
	 Train_Loss: 0.5210 Train_Acc: 78.312 Val_Loss: 0.5492  BEST VAL Loss: 0.5492  Val_Acc: 73.613

Epoch 27: Validation loss decreased (0.549247 --> 0.548426).  Saving model ...
	 Train_Loss: 0.5189 Train_Acc: 78.176 Val_Loss: 0.5484  BEST VAL Loss: 0.5484  Val_Acc: 74.076

Epoch 28: Validation loss decreased (0.548426 --> 0.547632).  Saving model ...
	 Train_Loss: 0.5170 Train_Acc: 78.517 Val_Loss: 0.5476  BEST VAL Loss: 0.5476  Val_Acc: 74.412

Epoch 29: Validation loss decreased (0.547632 --> 0.546788).  Saving model ...
	 Train_Loss: 0.5149 Train_Acc: 78.365 Val_Loss: 0.5468  BEST VAL Loss: 0.5468  Val_Acc: 74.748

Epoch 30: Validation loss decreased (0.546788 --> 0.546205).  Saving model ...
	 Train_Loss: 0.5129 Train_Acc: 78.638 Val_Loss: 0.5462  BEST VAL Loss: 0.5462  Val_Acc: 73.950

Epoch 31: Validation loss decreased (0.546205 --> 0.545557).  Saving model ...
	 Train_Loss: 0.5108 Train_Acc: 79.143 Val_Loss: 0.5456  BEST VAL Loss: 0.5456  Val_Acc: 74.370

Epoch 32: Validation loss decreased (0.545557 --> 0.544646).  Saving model ...
	 Train_Loss: 0.5088 Train_Acc: 78.838 Val_Loss: 0.5446  BEST VAL Loss: 0.5446  Val_Acc: 75.336

Epoch 33: Validation loss decreased (0.544646 --> 0.544010).  Saving model ...
	 Train_Loss: 0.5074 Train_Acc: 78.134 Val_Loss: 0.5440  BEST VAL Loss: 0.5440  Val_Acc: 75.252

Epoch 34: Validation loss decreased (0.544010 --> 0.543450).  Saving model ...
	 Train_Loss: 0.5062 Train_Acc: 78.102 Val_Loss: 0.5434  BEST VAL Loss: 0.5434  Val_Acc: 74.790

Epoch 35: Validation loss decreased (0.543450 --> 0.542851).  Saving model ...
	 Train_Loss: 0.5049 Train_Acc: 78.239 Val_Loss: 0.5429  BEST VAL Loss: 0.5429  Val_Acc: 75.168

Epoch 36: Validation loss decreased (0.542851 --> 0.542429).  Saving model ...
	 Train_Loss: 0.5035 Train_Acc: 78.633 Val_Loss: 0.5424  BEST VAL Loss: 0.5424  Val_Acc: 75.294

Epoch 37: Validation loss decreased (0.542429 --> 0.541615).  Saving model ...
	 Train_Loss: 0.5022 Train_Acc: 78.586 Val_Loss: 0.5416  BEST VAL Loss: 0.5416  Val_Acc: 75.000

Epoch 38: Validation loss decreased (0.541615 --> 0.540920).  Saving model ...
	 Train_Loss: 0.5007 Train_Acc: 79.400 Val_Loss: 0.5409  BEST VAL Loss: 0.5409  Val_Acc: 75.504

Epoch 39: Validation loss decreased (0.540920 --> 0.540210).  Saving model ...
	 Train_Loss: 0.4992 Train_Acc: 79.778 Val_Loss: 0.5402  BEST VAL Loss: 0.5402  Val_Acc: 75.294

Epoch 40: Validation loss decreased (0.540210 --> 0.539436).  Saving model ...
	 Train_Loss: 0.4975 Train_Acc: 79.605 Val_Loss: 0.5394  BEST VAL Loss: 0.5394  Val_Acc: 75.504

Epoch 41: Validation loss decreased (0.539436 --> 0.538610).  Saving model ...
	 Train_Loss: 0.4960 Train_Acc: 79.663 Val_Loss: 0.5386  BEST VAL Loss: 0.5386  Val_Acc: 75.714

Epoch 42: Validation loss decreased (0.538610 --> 0.538150).  Saving model ...
	 Train_Loss: 0.4944 Train_Acc: 80.561 Val_Loss: 0.5382  BEST VAL Loss: 0.5382  Val_Acc: 75.588

Epoch 43: Validation loss decreased (0.538150 --> 0.537598).  Saving model ...
	 Train_Loss: 0.4929 Train_Acc: 80.540 Val_Loss: 0.5376  BEST VAL Loss: 0.5376  Val_Acc: 76.008

Epoch 44: Validation loss decreased (0.537598 --> 0.536977).  Saving model ...
	 Train_Loss: 0.4914 Train_Acc: 80.267 Val_Loss: 0.5370  BEST VAL Loss: 0.5370  Val_Acc: 75.252

Epoch 45: Validation loss decreased (0.536977 --> 0.536400).  Saving model ...
	 Train_Loss: 0.4902 Train_Acc: 79.873 Val_Loss: 0.5364  BEST VAL Loss: 0.5364  Val_Acc: 75.588

Epoch 46: Validation loss decreased (0.536400 --> 0.535831).  Saving model ...
	 Train_Loss: 0.4887 Train_Acc: 80.808 Val_Loss: 0.5358  BEST VAL Loss: 0.5358  Val_Acc: 75.714

Epoch 47: Validation loss decreased (0.535831 --> 0.535335).  Saving model ...
	 Train_Loss: 0.4874 Train_Acc: 80.403 Val_Loss: 0.5353  BEST VAL Loss: 0.5353  Val_Acc: 75.966

Epoch 48: Validation loss decreased (0.535335 --> 0.534818).  Saving model ...
	 Train_Loss: 0.4861 Train_Acc: 80.950 Val_Loss: 0.5348  BEST VAL Loss: 0.5348  Val_Acc: 76.303

Epoch 49: Validation loss decreased (0.534818 --> 0.534390).  Saving model ...
	 Train_Loss: 0.4849 Train_Acc: 80.551 Val_Loss: 0.5344  BEST VAL Loss: 0.5344  Val_Acc: 76.429

Epoch 50: Validation loss decreased (0.534390 --> 0.533893).  Saving model ...
	 Train_Loss: 0.4836 Train_Acc: 80.713 Val_Loss: 0.5339  BEST VAL Loss: 0.5339  Val_Acc: 76.975

Epoch 51: Validation loss decreased (0.533893 --> 0.533217).  Saving model ...
	 Train_Loss: 0.4824 Train_Acc: 80.777 Val_Loss: 0.5332  BEST VAL Loss: 0.5332  Val_Acc: 77.185

Epoch 52: Validation loss decreased (0.533217 --> 0.532795).  Saving model ...
	 Train_Loss: 0.4809 Train_Acc: 81.932 Val_Loss: 0.5328  BEST VAL Loss: 0.5328  Val_Acc: 77.101

Epoch 53: Validation loss decreased (0.532795 --> 0.532176).  Saving model ...
	 Train_Loss: 0.4796 Train_Acc: 81.417 Val_Loss: 0.5322  BEST VAL Loss: 0.5322  Val_Acc: 76.513

Epoch 54: Validation loss decreased (0.532176 --> 0.531647).  Saving model ...
	 Train_Loss: 0.4784 Train_Acc: 81.396 Val_Loss: 0.5316  BEST VAL Loss: 0.5316  Val_Acc: 76.681

Epoch 55: Validation loss decreased (0.531647 --> 0.531096).  Saving model ...
	 Train_Loss: 0.4771 Train_Acc: 81.249 Val_Loss: 0.5311  BEST VAL Loss: 0.5311  Val_Acc: 77.353

Epoch 56: Validation loss decreased (0.531096 --> 0.530878).  Saving model ...
	 Train_Loss: 0.4759 Train_Acc: 81.801 Val_Loss: 0.5309  BEST VAL Loss: 0.5309  Val_Acc: 76.597

Epoch 57: Validation loss decreased (0.530878 --> 0.530408).  Saving model ...
	 Train_Loss: 0.4749 Train_Acc: 80.903 Val_Loss: 0.5304  BEST VAL Loss: 0.5304  Val_Acc: 76.387

Epoch 58: Validation loss decreased (0.530408 --> 0.529834).  Saving model ...
	 Train_Loss: 0.4740 Train_Acc: 81.202 Val_Loss: 0.5298  BEST VAL Loss: 0.5298  Val_Acc: 77.521

Epoch 59: Validation loss decreased (0.529834 --> 0.529359).  Saving model ...
	 Train_Loss: 0.4730 Train_Acc: 81.417 Val_Loss: 0.5294  BEST VAL Loss: 0.5294  Val_Acc: 76.513

Epoch 60: Validation loss decreased (0.529359 --> 0.529046).  Saving model ...
	 Train_Loss: 0.4720 Train_Acc: 81.607 Val_Loss: 0.5290  BEST VAL Loss: 0.5290  Val_Acc: 77.017

Epoch 61: Validation loss decreased (0.529046 --> 0.528374).  Saving model ...
	 Train_Loss: 0.4710 Train_Acc: 81.943 Val_Loss: 0.5284  BEST VAL Loss: 0.5284  Val_Acc: 77.563

Epoch 62: Validation loss decreased (0.528374 --> 0.528030).  Saving model ...
	 Train_Loss: 0.4698 Train_Acc: 82.142 Val_Loss: 0.5280  BEST VAL Loss: 0.5280  Val_Acc: 77.605

Epoch 63: Validation loss decreased (0.528030 --> 0.527810).  Saving model ...
	 Train_Loss: 0.4688 Train_Acc: 82.400 Val_Loss: 0.5278  BEST VAL Loss: 0.5278  Val_Acc: 77.227

Epoch 64: Validation loss decreased (0.527810 --> 0.527471).  Saving model ...
	 Train_Loss: 0.4677 Train_Acc: 82.405 Val_Loss: 0.5275  BEST VAL Loss: 0.5275  Val_Acc: 77.185

Epoch 65: Validation loss decreased (0.527471 --> 0.527007).  Saving model ...
	 Train_Loss: 0.4667 Train_Acc: 82.395 Val_Loss: 0.5270  BEST VAL Loss: 0.5270  Val_Acc: 77.899

Epoch 66: Validation loss decreased (0.527007 --> 0.526585).  Saving model ...
	 Train_Loss: 0.4657 Train_Acc: 82.542 Val_Loss: 0.5266  BEST VAL Loss: 0.5266  Val_Acc: 78.445

Epoch 67: Validation loss decreased (0.526585 --> 0.526135).  Saving model ...
	 Train_Loss: 0.4646 Train_Acc: 82.726 Val_Loss: 0.5261  BEST VAL Loss: 0.5261  Val_Acc: 78.151

Epoch 68: Validation loss decreased (0.526135 --> 0.525789).  Saving model ...
	 Train_Loss: 0.4636 Train_Acc: 82.505 Val_Loss: 0.5258  BEST VAL Loss: 0.5258  Val_Acc: 77.605

Epoch 69: Validation loss decreased (0.525789 --> 0.525479).  Saving model ...
	 Train_Loss: 0.4625 Train_Acc: 82.747 Val_Loss: 0.5255  BEST VAL Loss: 0.5255  Val_Acc: 77.185

Epoch 70: Validation loss decreased (0.525479 --> 0.525228).  Saving model ...
	 Train_Loss: 0.4615 Train_Acc: 82.915 Val_Loss: 0.5252  BEST VAL Loss: 0.5252  Val_Acc: 76.429

Epoch 71: Validation loss decreased (0.525228 --> 0.525056).  Saving model ...
	 Train_Loss: 0.4606 Train_Acc: 82.636 Val_Loss: 0.5251  BEST VAL Loss: 0.5251  Val_Acc: 77.227

Epoch 72: Validation loss decreased (0.525056 --> 0.524825).  Saving model ...
	 Train_Loss: 0.4598 Train_Acc: 82.521 Val_Loss: 0.5248  BEST VAL Loss: 0.5248  Val_Acc: 77.269

Epoch 73: Validation loss decreased (0.524825 --> 0.524314).  Saving model ...
	 Train_Loss: 0.4590 Train_Acc: 81.953 Val_Loss: 0.5243  BEST VAL Loss: 0.5243  Val_Acc: 77.857

Epoch 74: Validation loss decreased (0.524314 --> 0.524047).  Saving model ...
	 Train_Loss: 0.4582 Train_Acc: 82.857 Val_Loss: 0.5240  BEST VAL Loss: 0.5240  Val_Acc: 77.353

Epoch 75: Validation loss decreased (0.524047 --> 0.524013).  Saving model ...
	 Train_Loss: 0.4572 Train_Acc: 83.330 Val_Loss: 0.5240  BEST VAL Loss: 0.5240  Val_Acc: 77.311

Epoch 76: Validation loss decreased (0.524013 --> 0.523772).  Saving model ...
	 Train_Loss: 0.4563 Train_Acc: 82.941 Val_Loss: 0.5238  BEST VAL Loss: 0.5238  Val_Acc: 77.941

Epoch 77: Validation loss decreased (0.523772 --> 0.523456).  Saving model ...
	 Train_Loss: 0.4554 Train_Acc: 83.335 Val_Loss: 0.5235  BEST VAL Loss: 0.5235  Val_Acc: 78.319

Epoch 78: Validation loss decreased (0.523456 --> 0.523319).  Saving model ...
	 Train_Loss: 0.4545 Train_Acc: 83.293 Val_Loss: 0.5233  BEST VAL Loss: 0.5233  Val_Acc: 76.975

Epoch 79: Validation loss decreased (0.523319 --> 0.523087).  Saving model ...
	 Train_Loss: 0.4537 Train_Acc: 83.088 Val_Loss: 0.5231  BEST VAL Loss: 0.5231  Val_Acc: 77.689

Epoch 80: Validation loss decreased (0.523087 --> 0.522960).  Saving model ...
	 Train_Loss: 0.4528 Train_Acc: 83.330 Val_Loss: 0.5230  BEST VAL Loss: 0.5230  Val_Acc: 77.815

Epoch 81: Validation loss decreased (0.522960 --> 0.522755).  Saving model ...
	 Train_Loss: 0.4519 Train_Acc: 83.703 Val_Loss: 0.5228  BEST VAL Loss: 0.5228  Val_Acc: 78.319

Epoch 82: Validation loss decreased (0.522755 --> 0.522611).  Saving model ...
	 Train_Loss: 0.4510 Train_Acc: 83.482 Val_Loss: 0.5226  BEST VAL Loss: 0.5226  Val_Acc: 77.395

Epoch 83: Validation loss decreased (0.522611 --> 0.522361).  Saving model ...
	 Train_Loss: 0.4501 Train_Acc: 83.577 Val_Loss: 0.5224  BEST VAL Loss: 0.5224  Val_Acc: 77.647

Epoch 84: Validation loss decreased (0.522361 --> 0.522217).  Saving model ...
	 Train_Loss: 0.4494 Train_Acc: 82.962 Val_Loss: 0.5222  BEST VAL Loss: 0.5222  Val_Acc: 77.395

Epoch 85: Validation loss decreased (0.522217 --> 0.522094).  Saving model ...
	 Train_Loss: 0.4486 Train_Acc: 83.440 Val_Loss: 0.5221  BEST VAL Loss: 0.5221  Val_Acc: 77.269

Epoch 86: Validation loss decreased (0.522094 --> 0.521893).  Saving model ...
	 Train_Loss: 0.4478 Train_Acc: 83.466 Val_Loss: 0.5219  BEST VAL Loss: 0.5219  Val_Acc: 77.353

Epoch 87: Validation loss decreased (0.521893 --> 0.521634).  Saving model ...
	 Train_Loss: 0.4472 Train_Acc: 83.755 Val_Loss: 0.5216  BEST VAL Loss: 0.5216  Val_Acc: 77.269

Epoch 88: Validation loss decreased (0.521634 --> 0.521621).  Saving model ...
	 Train_Loss: 0.4463 Train_Acc: 83.419 Val_Loss: 0.5216  BEST VAL Loss: 0.5216  Val_Acc: 78.193

Epoch 89: Validation loss decreased (0.521621 --> 0.521583).  Saving model ...
	 Train_Loss: 0.4455 Train_Acc: 84.081 Val_Loss: 0.5216  BEST VAL Loss: 0.5216  Val_Acc: 78.109

Epoch 90: Validation loss decreased (0.521583 --> 0.521534).  Saving model ...
	 Train_Loss: 0.4446 Train_Acc: 84.270 Val_Loss: 0.5215  BEST VAL Loss: 0.5215  Val_Acc: 77.689

Epoch 91: Validation loss decreased (0.521534 --> 0.521417).  Saving model ...
	 Train_Loss: 0.4438 Train_Acc: 83.677 Val_Loss: 0.5214  BEST VAL Loss: 0.5214  Val_Acc: 77.941

Epoch 92: Validation loss decreased (0.521417 --> 0.521211).  Saving model ...
	 Train_Loss: 0.4432 Train_Acc: 83.051 Val_Loss: 0.5212  BEST VAL Loss: 0.5212  Val_Acc: 76.597

Epoch 93: Validation loss decreased (0.521211 --> 0.520954).  Saving model ...
	 Train_Loss: 0.4427 Train_Acc: 82.852 Val_Loss: 0.5210  BEST VAL Loss: 0.5210  Val_Acc: 76.975

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.4421 Train_Acc: 83.361 Val_Loss: 0.5210  BEST VAL Loss: 0.5210  Val_Acc: 77.185

Epoch 95: Validation loss decreased (0.520954 --> 0.520906).  Saving model ...
	 Train_Loss: 0.4414 Train_Acc: 83.293 Val_Loss: 0.5209  BEST VAL Loss: 0.5209  Val_Acc: 77.185

Epoch 96: Validation loss did not decrease
	 Train_Loss: 0.4407 Train_Acc: 83.466 Val_Loss: 0.5211  BEST VAL Loss: 0.5209  Val_Acc: 77.521

Epoch 97: Validation loss did not decrease
	 Train_Loss: 0.4400 Train_Acc: 83.766 Val_Loss: 0.5210  BEST VAL Loss: 0.5209  Val_Acc: 78.739

Epoch 98: Validation loss did not decrease
	 Train_Loss: 0.4393 Train_Acc: 83.797 Val_Loss: 0.5210  BEST VAL Loss: 0.5209  Val_Acc: 77.941

Epoch 99: Validation loss decreased (0.520906 --> 0.520782).  Saving model ...
	 Train_Loss: 0.4387 Train_Acc: 83.682 Val_Loss: 0.5208  BEST VAL Loss: 0.5208  Val_Acc: 77.773

Flagellin_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.83      0.87      8633
           1       0.87      0.95      0.91     10401

    accuracy                           0.89     19034
   macro avg       0.90      0.89      0.89     19034
weighted avg       0.90      0.89      0.89     19034

Flagellin_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.79      0.70      0.74      1080
           1       0.77      0.84      0.81      1300

    accuracy                           0.78      2380
   macro avg       0.78      0.77      0.77      2380
weighted avg       0.78      0.78      0.78      2380

Flagellin_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.78      0.69      0.73      1080
           1       0.76      0.84      0.80      1300

    accuracy                           0.77      2380
   macro avg       0.77      0.76      0.76      2380
weighted avg       0.77      0.77      0.77      2380

              precision    recall  f1-score   support

           0       0.78      0.69      0.73      1080
           1       0.76      0.84      0.80      1300

    accuracy                           0.77      2380
   macro avg       0.77      0.76      0.76      2380
weighted avg       0.77      0.77      0.77      2380

Flagellin_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.62      0.40      0.49      4135
           1       0.59      0.78      0.67      4509

    accuracy                           0.60      8644
   macro avg       0.60      0.59      0.58      8644
weighted avg       0.60      0.60      0.58      8644

              precision    recall  f1-score   support

           0       0.62      0.40      0.49      4135
           1       0.59      0.78      0.67      4509

    accuracy                           0.60      8644
   macro avg       0.60      0.59      0.58      8644
weighted avg       0.60      0.60      0.58      8644

completed
