[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '19e95d1a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '99ab7029'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'c09e0847'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'f7f8f6b0'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: H2O2_100.000_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: Flagellin_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['H2O2_100.000_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (42709, 1276)
Number of total missing values across all columns: 85418
Data Subset Is Off
Wells held out for testing: ['I22' 'M22']
Wells to use for training, validation, and testing ['H18' 'H19' 'H22' 'H23' 'I18' 'M18' 'I19' 'M19' 'I23' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.603560).  Saving model ...
	 Train_Loss: 0.6431 Train_Acc: 66.404 Val_Loss: 0.6036  BEST VAL Loss: 0.6036  Val_Acc: 67.012

Epoch 1: Validation loss decreased (0.603560 --> 0.565420).  Saving model ...
	 Train_Loss: 0.6178 Train_Acc: 68.122 Val_Loss: 0.5654  BEST VAL Loss: 0.5654  Val_Acc: 71.684

Epoch 2: Validation loss decreased (0.565420 --> 0.536243).  Saving model ...
	 Train_Loss: 0.5946 Train_Acc: 70.983 Val_Loss: 0.5362  BEST VAL Loss: 0.5362  Val_Acc: 75.993

Epoch 3: Validation loss decreased (0.536243 --> 0.519847).  Saving model ...
	 Train_Loss: 0.5765 Train_Acc: 72.645 Val_Loss: 0.5198  BEST VAL Loss: 0.5198  Val_Acc: 76.777

Epoch 4: Validation loss decreased (0.519847 --> 0.505244).  Saving model ...
	 Train_Loss: 0.5615 Train_Acc: 73.470 Val_Loss: 0.5052  BEST VAL Loss: 0.5052  Val_Acc: 77.952

Epoch 5: Validation loss decreased (0.505244 --> 0.494976).  Saving model ...
	 Train_Loss: 0.5497 Train_Acc: 73.722 Val_Loss: 0.4950  BEST VAL Loss: 0.4950  Val_Acc: 78.511

Epoch 6: Validation loss decreased (0.494976 --> 0.486519).  Saving model ...
	 Train_Loss: 0.5406 Train_Acc: 73.918 Val_Loss: 0.4865  BEST VAL Loss: 0.4865  Val_Acc: 80.134

Epoch 7: Validation loss decreased (0.486519 --> 0.478857).  Saving model ...
	 Train_Loss: 0.5328 Train_Acc: 74.051 Val_Loss: 0.4789  BEST VAL Loss: 0.4789  Val_Acc: 80.218

Epoch 8: Validation loss decreased (0.478857 --> 0.471620).  Saving model ...
	 Train_Loss: 0.5261 Train_Acc: 74.492 Val_Loss: 0.4716  BEST VAL Loss: 0.4716  Val_Acc: 80.722

Epoch 9: Validation loss decreased (0.471620 --> 0.466362).  Saving model ...
	 Train_Loss: 0.5203 Train_Acc: 74.978 Val_Loss: 0.4664  BEST VAL Loss: 0.4664  Val_Acc: 81.281

Epoch 10: Validation loss decreased (0.466362 --> 0.461384).  Saving model ...
	 Train_Loss: 0.5151 Train_Acc: 74.667 Val_Loss: 0.4614  BEST VAL Loss: 0.4614  Val_Acc: 81.002

Epoch 11: Validation loss decreased (0.461384 --> 0.456395).  Saving model ...
	 Train_Loss: 0.5106 Train_Acc: 74.908 Val_Loss: 0.4564  BEST VAL Loss: 0.4564  Val_Acc: 82.149

Epoch 12: Validation loss decreased (0.456395 --> 0.451920).  Saving model ...
	 Train_Loss: 0.5065 Train_Acc: 75.643 Val_Loss: 0.4519  BEST VAL Loss: 0.4519  Val_Acc: 82.065

Epoch 13: Validation loss decreased (0.451920 --> 0.448608).  Saving model ...
	 Train_Loss: 0.5031 Train_Acc: 75.052 Val_Loss: 0.4486  BEST VAL Loss: 0.4486  Val_Acc: 81.365

Epoch 14: Validation loss decreased (0.448608 --> 0.445452).  Saving model ...
	 Train_Loss: 0.4996 Train_Acc: 75.681 Val_Loss: 0.4455  BEST VAL Loss: 0.4455  Val_Acc: 81.477

Epoch 15: Validation loss decreased (0.445452 --> 0.442426).  Saving model ...
	 Train_Loss: 0.4963 Train_Acc: 75.303 Val_Loss: 0.4424  BEST VAL Loss: 0.4424  Val_Acc: 81.785

Epoch 16: Validation loss decreased (0.442426 --> 0.439554).  Saving model ...
	 Train_Loss: 0.4934 Train_Acc: 75.986 Val_Loss: 0.4396  BEST VAL Loss: 0.4396  Val_Acc: 82.345

Epoch 17: Validation loss decreased (0.439554 --> 0.437015).  Saving model ...
	 Train_Loss: 0.4907 Train_Acc: 75.685 Val_Loss: 0.4370  BEST VAL Loss: 0.4370  Val_Acc: 82.261

Epoch 18: Validation loss decreased (0.437015 --> 0.434595).  Saving model ...
	 Train_Loss: 0.4882 Train_Acc: 76.094 Val_Loss: 0.4346  BEST VAL Loss: 0.4346  Val_Acc: 82.065

Epoch 19: Validation loss decreased (0.434595 --> 0.432587).  Saving model ...
	 Train_Loss: 0.4858 Train_Acc: 76.244 Val_Loss: 0.4326  BEST VAL Loss: 0.4326  Val_Acc: 82.792

Epoch 20: Validation loss decreased (0.432587 --> 0.430198).  Saving model ...
	 Train_Loss: 0.4835 Train_Acc: 76.377 Val_Loss: 0.4302  BEST VAL Loss: 0.4302  Val_Acc: 82.541

Epoch 21: Validation loss decreased (0.430198 --> 0.428223).  Saving model ...
	 Train_Loss: 0.4814 Train_Acc: 76.419 Val_Loss: 0.4282  BEST VAL Loss: 0.4282  Val_Acc: 82.625

Epoch 22: Validation loss decreased (0.428223 --> 0.426370).  Saving model ...
	 Train_Loss: 0.4794 Train_Acc: 76.699 Val_Loss: 0.4264  BEST VAL Loss: 0.4264  Val_Acc: 82.541

Epoch 23: Validation loss decreased (0.426370 --> 0.424572).  Saving model ...
	 Train_Loss: 0.4775 Train_Acc: 76.475 Val_Loss: 0.4246  BEST VAL Loss: 0.4246  Val_Acc: 82.597

Epoch 24: Validation loss decreased (0.424572 --> 0.423281).  Saving model ...
	 Train_Loss: 0.4757 Train_Acc: 76.713 Val_Loss: 0.4233  BEST VAL Loss: 0.4233  Val_Acc: 83.212

Epoch 25: Validation loss decreased (0.423281 --> 0.421767).  Saving model ...
	 Train_Loss: 0.4740 Train_Acc: 76.577 Val_Loss: 0.4218  BEST VAL Loss: 0.4218  Val_Acc: 82.820

Epoch 26: Validation loss decreased (0.421767 --> 0.420333).  Saving model ...
	 Train_Loss: 0.4725 Train_Acc: 76.734 Val_Loss: 0.4203  BEST VAL Loss: 0.4203  Val_Acc: 83.408

Epoch 27: Validation loss decreased (0.420333 --> 0.419199).  Saving model ...
	 Train_Loss: 0.4709 Train_Acc: 76.755 Val_Loss: 0.4192  BEST VAL Loss: 0.4192  Val_Acc: 81.897

Epoch 28: Validation loss decreased (0.419199 --> 0.418203).  Saving model ...
	 Train_Loss: 0.4696 Train_Acc: 76.517 Val_Loss: 0.4182  BEST VAL Loss: 0.4182  Val_Acc: 83.072

Epoch 29: Validation loss decreased (0.418203 --> 0.417038).  Saving model ...
	 Train_Loss: 0.4682 Train_Acc: 77.035 Val_Loss: 0.4170  BEST VAL Loss: 0.4170  Val_Acc: 82.541

Epoch 30: Validation loss decreased (0.417038 --> 0.415872).  Saving model ...
	 Train_Loss: 0.4667 Train_Acc: 77.073 Val_Loss: 0.4159  BEST VAL Loss: 0.4159  Val_Acc: 82.121

Epoch 31: Validation loss decreased (0.415872 --> 0.414774).  Saving model ...
	 Train_Loss: 0.4654 Train_Acc: 77.087 Val_Loss: 0.4148  BEST VAL Loss: 0.4148  Val_Acc: 83.408

Epoch 32: Validation loss decreased (0.414774 --> 0.413687).  Saving model ...
	 Train_Loss: 0.4643 Train_Acc: 76.864 Val_Loss: 0.4137  BEST VAL Loss: 0.4137  Val_Acc: 82.652

Epoch 33: Validation loss decreased (0.413687 --> 0.412528).  Saving model ...
	 Train_Loss: 0.4630 Train_Acc: 77.469 Val_Loss: 0.4125  BEST VAL Loss: 0.4125  Val_Acc: 83.268

Epoch 34: Validation loss decreased (0.412528 --> 0.411453).  Saving model ...
	 Train_Loss: 0.4618 Train_Acc: 76.993 Val_Loss: 0.4115  BEST VAL Loss: 0.4115  Val_Acc: 83.716

Epoch 35: Validation loss decreased (0.411453 --> 0.410506).  Saving model ...
	 Train_Loss: 0.4606 Train_Acc: 77.203 Val_Loss: 0.4105  BEST VAL Loss: 0.4105  Val_Acc: 83.660

Epoch 36: Validation loss decreased (0.410506 --> 0.409621).  Saving model ...
	 Train_Loss: 0.4595 Train_Acc: 77.283 Val_Loss: 0.4096  BEST VAL Loss: 0.4096  Val_Acc: 83.408

Epoch 37: Validation loss decreased (0.409621 --> 0.408784).  Saving model ...
	 Train_Loss: 0.4584 Train_Acc: 77.266 Val_Loss: 0.4088  BEST VAL Loss: 0.4088  Val_Acc: 82.988

Epoch 38: Validation loss decreased (0.408784 --> 0.408143).  Saving model ...
	 Train_Loss: 0.4574 Train_Acc: 77.262 Val_Loss: 0.4081  BEST VAL Loss: 0.4081  Val_Acc: 83.464

Epoch 39: Validation loss decreased (0.408143 --> 0.407339).  Saving model ...
	 Train_Loss: 0.4564 Train_Acc: 77.112 Val_Loss: 0.4073  BEST VAL Loss: 0.4073  Val_Acc: 83.576

Epoch 40: Validation loss decreased (0.407339 --> 0.406451).  Saving model ...
	 Train_Loss: 0.4555 Train_Acc: 77.455 Val_Loss: 0.4065  BEST VAL Loss: 0.4065  Val_Acc: 83.576

Epoch 41: Validation loss decreased (0.406451 --> 0.405870).  Saving model ...
	 Train_Loss: 0.4545 Train_Acc: 77.784 Val_Loss: 0.4059  BEST VAL Loss: 0.4059  Val_Acc: 83.968

Epoch 42: Validation loss decreased (0.405870 --> 0.405310).  Saving model ...
	 Train_Loss: 0.4536 Train_Acc: 77.147 Val_Loss: 0.4053  BEST VAL Loss: 0.4053  Val_Acc: 83.128

Epoch 43: Validation loss decreased (0.405310 --> 0.404515).  Saving model ...
	 Train_Loss: 0.4528 Train_Acc: 77.423 Val_Loss: 0.4045  BEST VAL Loss: 0.4045  Val_Acc: 83.548

Epoch 44: Validation loss decreased (0.404515 --> 0.403768).  Saving model ...
	 Train_Loss: 0.4519 Train_Acc: 77.801 Val_Loss: 0.4038  BEST VAL Loss: 0.4038  Val_Acc: 83.296

Epoch 45: Validation loss decreased (0.403768 --> 0.402998).  Saving model ...
	 Train_Loss: 0.4510 Train_Acc: 77.875 Val_Loss: 0.4030  BEST VAL Loss: 0.4030  Val_Acc: 83.296

Epoch 46: Validation loss decreased (0.402998 --> 0.402308).  Saving model ...
	 Train_Loss: 0.4502 Train_Acc: 77.206 Val_Loss: 0.4023  BEST VAL Loss: 0.4023  Val_Acc: 83.856

Epoch 47: Validation loss decreased (0.402308 --> 0.401702).  Saving model ...
	 Train_Loss: 0.4494 Train_Acc: 77.609 Val_Loss: 0.4017  BEST VAL Loss: 0.4017  Val_Acc: 83.324

Epoch 48: Validation loss decreased (0.401702 --> 0.401323).  Saving model ...
	 Train_Loss: 0.4486 Train_Acc: 77.752 Val_Loss: 0.4013  BEST VAL Loss: 0.4013  Val_Acc: 83.352

Epoch 49: Validation loss decreased (0.401323 --> 0.400803).  Saving model ...
	 Train_Loss: 0.4478 Train_Acc: 77.672 Val_Loss: 0.4008  BEST VAL Loss: 0.4008  Val_Acc: 83.128

Epoch 50: Validation loss decreased (0.400803 --> 0.400315).  Saving model ...
	 Train_Loss: 0.4472 Train_Acc: 77.518 Val_Loss: 0.4003  BEST VAL Loss: 0.4003  Val_Acc: 82.988

Epoch 51: Validation loss decreased (0.400315 --> 0.399671).  Saving model ...
	 Train_Loss: 0.4464 Train_Acc: 77.910 Val_Loss: 0.3997  BEST VAL Loss: 0.3997  Val_Acc: 83.884

Epoch 52: Validation loss decreased (0.399671 --> 0.399246).  Saving model ...
	 Train_Loss: 0.4457 Train_Acc: 77.742 Val_Loss: 0.3992  BEST VAL Loss: 0.3992  Val_Acc: 83.716

Epoch 53: Validation loss decreased (0.399246 --> 0.398767).  Saving model ...
	 Train_Loss: 0.4449 Train_Acc: 77.777 Val_Loss: 0.3988  BEST VAL Loss: 0.3988  Val_Acc: 84.219

Epoch 54: Validation loss decreased (0.398767 --> 0.398332).  Saving model ...
	 Train_Loss: 0.4442 Train_Acc: 77.945 Val_Loss: 0.3983  BEST VAL Loss: 0.3983  Val_Acc: 83.240

Epoch 55: Validation loss decreased (0.398332 --> 0.397943).  Saving model ...
	 Train_Loss: 0.4435 Train_Acc: 77.574 Val_Loss: 0.3979  BEST VAL Loss: 0.3979  Val_Acc: 83.408

Epoch 56: Validation loss decreased (0.397943 --> 0.397569).  Saving model ...
	 Train_Loss: 0.4428 Train_Acc: 77.885 Val_Loss: 0.3976  BEST VAL Loss: 0.3976  Val_Acc: 83.240

Epoch 57: Validation loss decreased (0.397569 --> 0.397126).  Saving model ...
	 Train_Loss: 0.4422 Train_Acc: 77.672 Val_Loss: 0.3971  BEST VAL Loss: 0.3971  Val_Acc: 83.632

Epoch 58: Validation loss decreased (0.397126 --> 0.396670).  Saving model ...
	 Train_Loss: 0.4415 Train_Acc: 77.822 Val_Loss: 0.3967  BEST VAL Loss: 0.3967  Val_Acc: 83.912

Epoch 59: Validation loss decreased (0.396670 --> 0.396195).  Saving model ...
	 Train_Loss: 0.4409 Train_Acc: 77.924 Val_Loss: 0.3962  BEST VAL Loss: 0.3962  Val_Acc: 83.884

Epoch 60: Validation loss decreased (0.396195 --> 0.395857).  Saving model ...
	 Train_Loss: 0.4403 Train_Acc: 77.840 Val_Loss: 0.3959  BEST VAL Loss: 0.3959  Val_Acc: 84.051

Epoch 61: Validation loss decreased (0.395857 --> 0.395544).  Saving model ...
	 Train_Loss: 0.4397 Train_Acc: 77.672 Val_Loss: 0.3955  BEST VAL Loss: 0.3955  Val_Acc: 83.828

Epoch 62: Validation loss decreased (0.395544 --> 0.395393).  Saving model ...
	 Train_Loss: 0.4391 Train_Acc: 78.343 Val_Loss: 0.3954  BEST VAL Loss: 0.3954  Val_Acc: 83.716

Epoch 63: Validation loss decreased (0.395393 --> 0.395004).  Saving model ...
	 Train_Loss: 0.4385 Train_Acc: 78.280 Val_Loss: 0.3950  BEST VAL Loss: 0.3950  Val_Acc: 83.576

Epoch 64: Validation loss decreased (0.395004 --> 0.394671).  Saving model ...
	 Train_Loss: 0.4379 Train_Acc: 78.238 Val_Loss: 0.3947  BEST VAL Loss: 0.3947  Val_Acc: 83.604

Epoch 65: Validation loss decreased (0.394671 --> 0.394287).  Saving model ...
	 Train_Loss: 0.4373 Train_Acc: 78.403 Val_Loss: 0.3943  BEST VAL Loss: 0.3943  Val_Acc: 84.583

Epoch 66: Validation loss decreased (0.394287 --> 0.393922).  Saving model ...
	 Train_Loss: 0.4368 Train_Acc: 77.780 Val_Loss: 0.3939  BEST VAL Loss: 0.3939  Val_Acc: 83.940

Epoch 67: Validation loss decreased (0.393922 --> 0.393642).  Saving model ...
	 Train_Loss: 0.4362 Train_Acc: 77.658 Val_Loss: 0.3936  BEST VAL Loss: 0.3936  Val_Acc: 83.772

Epoch 68: Validation loss decreased (0.393642 --> 0.393377).  Saving model ...
	 Train_Loss: 0.4357 Train_Acc: 77.986 Val_Loss: 0.3934  BEST VAL Loss: 0.3934  Val_Acc: 83.632

Epoch 69: Validation loss decreased (0.393377 --> 0.393124).  Saving model ...
	 Train_Loss: 0.4351 Train_Acc: 78.354 Val_Loss: 0.3931  BEST VAL Loss: 0.3931  Val_Acc: 83.912

Epoch 70: Validation loss decreased (0.393124 --> 0.392776).  Saving model ...
	 Train_Loss: 0.4346 Train_Acc: 78.291 Val_Loss: 0.3928  BEST VAL Loss: 0.3928  Val_Acc: 83.436

Epoch 71: Validation loss decreased (0.392776 --> 0.392287).  Saving model ...
	 Train_Loss: 0.4341 Train_Acc: 77.910 Val_Loss: 0.3923  BEST VAL Loss: 0.3923  Val_Acc: 83.996

Epoch 72: Validation loss decreased (0.392287 --> 0.391967).  Saving model ...
	 Train_Loss: 0.4335 Train_Acc: 77.945 Val_Loss: 0.3920  BEST VAL Loss: 0.3920  Val_Acc: 83.520

Epoch 73: Validation loss decreased (0.391967 --> 0.391877).  Saving model ...
	 Train_Loss: 0.4331 Train_Acc: 77.882 Val_Loss: 0.3919  BEST VAL Loss: 0.3919  Val_Acc: 83.324

Epoch 74: Validation loss decreased (0.391877 --> 0.391569).  Saving model ...
	 Train_Loss: 0.4326 Train_Acc: 77.826 Val_Loss: 0.3916  BEST VAL Loss: 0.3916  Val_Acc: 84.024

Epoch 75: Validation loss decreased (0.391569 --> 0.391231).  Saving model ...
	 Train_Loss: 0.4321 Train_Acc: 78.266 Val_Loss: 0.3912  BEST VAL Loss: 0.3912  Val_Acc: 83.324

Epoch 76: Validation loss decreased (0.391231 --> 0.391024).  Saving model ...
	 Train_Loss: 0.4316 Train_Acc: 78.319 Val_Loss: 0.3910  BEST VAL Loss: 0.3910  Val_Acc: 84.135

Epoch 77: Validation loss decreased (0.391024 --> 0.390858).  Saving model ...
	 Train_Loss: 0.4311 Train_Acc: 78.119 Val_Loss: 0.3909  BEST VAL Loss: 0.3909  Val_Acc: 83.744

Epoch 78: Validation loss decreased (0.390858 --> 0.390715).  Saving model ...
	 Train_Loss: 0.4307 Train_Acc: 78.245 Val_Loss: 0.3907  BEST VAL Loss: 0.3907  Val_Acc: 84.331

Epoch 79: Validation loss decreased (0.390715 --> 0.390503).  Saving model ...
	 Train_Loss: 0.4302 Train_Acc: 78.067 Val_Loss: 0.3905  BEST VAL Loss: 0.3905  Val_Acc: 84.415

Epoch 80: Validation loss decreased (0.390503 --> 0.390230).  Saving model ...
	 Train_Loss: 0.4298 Train_Acc: 78.389 Val_Loss: 0.3902  BEST VAL Loss: 0.3902  Val_Acc: 84.471

Epoch 81: Validation loss decreased (0.390230 --> 0.390010).  Saving model ...
	 Train_Loss: 0.4293 Train_Acc: 78.406 Val_Loss: 0.3900  BEST VAL Loss: 0.3900  Val_Acc: 84.163

Epoch 82: Validation loss decreased (0.390010 --> 0.389862).  Saving model ...
	 Train_Loss: 0.4288 Train_Acc: 78.718 Val_Loss: 0.3899  BEST VAL Loss: 0.3899  Val_Acc: 83.996

Epoch 83: Validation loss decreased (0.389862 --> 0.389759).  Saving model ...
	 Train_Loss: 0.4283 Train_Acc: 78.298 Val_Loss: 0.3898  BEST VAL Loss: 0.3898  Val_Acc: 84.135

Epoch 84: Validation loss decreased (0.389759 --> 0.389529).  Saving model ...
	 Train_Loss: 0.4279 Train_Acc: 78.567 Val_Loss: 0.3895  BEST VAL Loss: 0.3895  Val_Acc: 83.912

Epoch 85: Validation loss decreased (0.389529 --> 0.389402).  Saving model ...
	 Train_Loss: 0.4274 Train_Acc: 78.452 Val_Loss: 0.3894  BEST VAL Loss: 0.3894  Val_Acc: 83.968

Epoch 86: Validation loss decreased (0.389402 --> 0.389128).  Saving model ...
	 Train_Loss: 0.4271 Train_Acc: 77.910 Val_Loss: 0.3891  BEST VAL Loss: 0.3891  Val_Acc: 84.555

Epoch 87: Validation loss decreased (0.389128 --> 0.388936).  Saving model ...
	 Train_Loss: 0.4267 Train_Acc: 78.347 Val_Loss: 0.3889  BEST VAL Loss: 0.3889  Val_Acc: 84.275

Epoch 88: Validation loss decreased (0.388936 --> 0.388935).  Saving model ...
	 Train_Loss: 0.4263 Train_Acc: 78.273 Val_Loss: 0.3889  BEST VAL Loss: 0.3889  Val_Acc: 83.744

Epoch 89: Validation loss decreased (0.388935 --> 0.388761).  Saving model ...
	 Train_Loss: 0.4259 Train_Acc: 78.693 Val_Loss: 0.3888  BEST VAL Loss: 0.3888  Val_Acc: 83.828

Epoch 90: Validation loss decreased (0.388761 --> 0.388624).  Saving model ...
	 Train_Loss: 0.4254 Train_Acc: 78.214 Val_Loss: 0.3886  BEST VAL Loss: 0.3886  Val_Acc: 84.947

Epoch 91: Validation loss decreased (0.388624 --> 0.388585).  Saving model ...
	 Train_Loss: 0.4250 Train_Acc: 78.266 Val_Loss: 0.3886  BEST VAL Loss: 0.3886  Val_Acc: 84.443

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.4246 Train_Acc: 78.711 Val_Loss: 0.3886  BEST VAL Loss: 0.3886  Val_Acc: 83.688

Epoch 93: Validation loss decreased (0.388585 --> 0.388462).  Saving model ...
	 Train_Loss: 0.4243 Train_Acc: 78.252 Val_Loss: 0.3885  BEST VAL Loss: 0.3885  Val_Acc: 83.912

Epoch 94: Validation loss decreased (0.388462 --> 0.388300).  Saving model ...
	 Train_Loss: 0.4239 Train_Acc: 78.245 Val_Loss: 0.3883  BEST VAL Loss: 0.3883  Val_Acc: 84.667

Epoch 95: Validation loss decreased (0.388300 --> 0.388159).  Saving model ...
	 Train_Loss: 0.4235 Train_Acc: 78.753 Val_Loss: 0.3882  BEST VAL Loss: 0.3882  Val_Acc: 83.940

Epoch 96: Validation loss decreased (0.388159 --> 0.387961).  Saving model ...
	 Train_Loss: 0.4232 Train_Acc: 78.504 Val_Loss: 0.3880  BEST VAL Loss: 0.3880  Val_Acc: 84.107

Epoch 97: Validation loss decreased (0.387961 --> 0.387813).  Saving model ...
	 Train_Loss: 0.4228 Train_Acc: 78.522 Val_Loss: 0.3878  BEST VAL Loss: 0.3878  Val_Acc: 84.191

Epoch 98: Validation loss decreased (0.387813 --> 0.387736).  Saving model ...
	 Train_Loss: 0.4225 Train_Acc: 78.165 Val_Loss: 0.3877  BEST VAL Loss: 0.3877  Val_Acc: 84.751

Epoch 99: Validation loss decreased (0.387736 --> 0.387614).  Saving model ...
	 Train_Loss: 0.4222 Train_Acc: 78.651 Val_Loss: 0.3876  BEST VAL Loss: 0.3876  Val_Acc: 84.975

H2O2_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.33      0.29      0.30      9434
           1       0.67      0.71      0.69     19153

    accuracy                           0.57     28587
   macro avg       0.50      0.50      0.50     28587
weighted avg       0.56      0.57      0.56     28587

H2O2_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.34      0.29      0.31      1179
           1       0.67      0.72      0.70      2395

    accuracy                           0.58      3574
   macro avg       0.50      0.50      0.50      3574
weighted avg       0.56      0.58      0.57      3574

H2O2_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.34      0.28      0.31      1179
           1       0.67      0.73      0.70      2395

    accuracy                           0.58      3574
   macro avg       0.51      0.51      0.51      3574
weighted avg       0.56      0.58      0.57      3574

              precision    recall  f1-score   support

           0       0.34      0.28      0.31      1179
           1       0.67      0.73      0.70      2395

    accuracy                           0.58      3574
   macro avg       0.51      0.51      0.51      3574
weighted avg       0.56      0.58      0.57      3574

H2O2_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.56      0.19      0.28      4017
           1       0.42      0.80      0.55      2957

    accuracy                           0.45      6974
   macro avg       0.49      0.50      0.42      6974
weighted avg       0.50      0.45      0.39      6974

              precision    recall  f1-score   support

           0       0.56      0.19      0.28      4017
           1       0.42      0.80      0.55      2957

    accuracy                           0.45      6974
   macro avg       0.49      0.50      0.42      6974
weighted avg       0.50      0.45      0.39      6974

completed
