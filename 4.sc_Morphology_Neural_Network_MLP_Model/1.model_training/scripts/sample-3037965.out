[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'f50e4348'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '5d985e65'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '37b65a2f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'fb3fddab'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_1.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_1.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (32676, 1276)
Number of total missing values across all columns: 32916
Data Subset Is Off
Wells held out for testing: ['D20' 'K16']
Wells to use for training, validation, and testing ['D16' 'D17' 'D21' 'K17' 'K20' 'K21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.624962).  Saving model ...
	 Train_Loss: 0.6713 Train_Acc: 53.890 Val_Loss: 0.6250  BEST VAL Loss: 0.6250  Val_Acc: 60.165

Epoch 1: Validation loss decreased (0.624962 --> 0.594166).  Saving model ...
	 Train_Loss: 0.6423 Train_Acc: 67.293 Val_Loss: 0.5942  BEST VAL Loss: 0.5942  Val_Acc: 79.712

Epoch 2: Validation loss decreased (0.594166 --> 0.563560).  Saving model ...
	 Train_Loss: 0.6171 Train_Acc: 68.816 Val_Loss: 0.5636  BEST VAL Loss: 0.5636  Val_Acc: 85.144

Epoch 3: Validation loss decreased (0.563560 --> 0.535113).  Saving model ...
	 Train_Loss: 0.5944 Train_Acc: 72.973 Val_Loss: 0.5351  BEST VAL Loss: 0.5351  Val_Acc: 87.654

Epoch 4: Validation loss decreased (0.535113 --> 0.508046).  Saving model ...
	 Train_Loss: 0.5735 Train_Acc: 75.077 Val_Loss: 0.5080  BEST VAL Loss: 0.5080  Val_Acc: 89.218

Epoch 5: Validation loss decreased (0.508046 --> 0.484114).  Saving model ...
	 Train_Loss: 0.5546 Train_Acc: 76.394 Val_Loss: 0.4841  BEST VAL Loss: 0.4841  Val_Acc: 90.412

Epoch 6: Validation loss decreased (0.484114 --> 0.463112).  Saving model ...
	 Train_Loss: 0.5383 Train_Acc: 76.754 Val_Loss: 0.4631  BEST VAL Loss: 0.4631  Val_Acc: 90.617

Epoch 7: Validation loss decreased (0.463112 --> 0.445418).  Saving model ...
	 Train_Loss: 0.5234 Train_Acc: 77.789 Val_Loss: 0.4454  BEST VAL Loss: 0.4454  Val_Acc: 91.193

Epoch 8: Validation loss decreased (0.445418 --> 0.428054).  Saving model ...
	 Train_Loss: 0.5102 Train_Acc: 78.349 Val_Loss: 0.4281  BEST VAL Loss: 0.4281  Val_Acc: 92.387

Epoch 9: Validation loss decreased (0.428054 --> 0.412401).  Saving model ...
	 Train_Loss: 0.4983 Train_Acc: 78.638 Val_Loss: 0.4124  BEST VAL Loss: 0.4124  Val_Acc: 92.510

Epoch 10: Validation loss decreased (0.412401 --> 0.398660).  Saving model ...
	 Train_Loss: 0.4873 Train_Acc: 78.833 Val_Loss: 0.3987  BEST VAL Loss: 0.3987  Val_Acc: 93.210

Epoch 11: Validation loss decreased (0.398660 --> 0.386038).  Saving model ...
	 Train_Loss: 0.4776 Train_Acc: 79.414 Val_Loss: 0.3860  BEST VAL Loss: 0.3860  Val_Acc: 93.086

Epoch 12: Validation loss decreased (0.386038 --> 0.374330).  Saving model ...
	 Train_Loss: 0.4682 Train_Acc: 80.042 Val_Loss: 0.3743  BEST VAL Loss: 0.3743  Val_Acc: 93.169

Epoch 13: Validation loss decreased (0.374330 --> 0.364017).  Saving model ...
	 Train_Loss: 0.4596 Train_Acc: 80.690 Val_Loss: 0.3640  BEST VAL Loss: 0.3640  Val_Acc: 93.251

Epoch 14: Validation loss decreased (0.364017 --> 0.354777).  Saving model ...
	 Train_Loss: 0.4522 Train_Acc: 80.104 Val_Loss: 0.3548  BEST VAL Loss: 0.3548  Val_Acc: 93.909

Epoch 15: Validation loss decreased (0.354777 --> 0.346221).  Saving model ...
	 Train_Loss: 0.4453 Train_Acc: 80.238 Val_Loss: 0.3462  BEST VAL Loss: 0.3462  Val_Acc: 93.169

Epoch 16: Validation loss decreased (0.346221 --> 0.338042).  Saving model ...
	 Train_Loss: 0.4388 Train_Acc: 80.541 Val_Loss: 0.3380  BEST VAL Loss: 0.3380  Val_Acc: 94.033

Epoch 17: Validation loss decreased (0.338042 --> 0.330850).  Saving model ...
	 Train_Loss: 0.4326 Train_Acc: 81.431 Val_Loss: 0.3308  BEST VAL Loss: 0.3308  Val_Acc: 93.951

Epoch 18: Validation loss decreased (0.330850 --> 0.323714).  Saving model ...
	 Train_Loss: 0.4270 Train_Acc: 81.148 Val_Loss: 0.3237  BEST VAL Loss: 0.3237  Val_Acc: 94.033

Epoch 19: Validation loss decreased (0.323714 --> 0.317311).  Saving model ...
	 Train_Loss: 0.4216 Train_Acc: 81.622 Val_Loss: 0.3173  BEST VAL Loss: 0.3173  Val_Acc: 93.951

Epoch 20: Validation loss decreased (0.317311 --> 0.311586).  Saving model ...
	 Train_Loss: 0.4168 Train_Acc: 81.123 Val_Loss: 0.3116  BEST VAL Loss: 0.3116  Val_Acc: 93.663

Epoch 21: Validation loss decreased (0.311586 --> 0.306087).  Saving model ...
	 Train_Loss: 0.4120 Train_Acc: 81.853 Val_Loss: 0.3061  BEST VAL Loss: 0.3061  Val_Acc: 94.280

Epoch 22: Validation loss decreased (0.306087 --> 0.301072).  Saving model ...
	 Train_Loss: 0.4077 Train_Acc: 81.694 Val_Loss: 0.3011  BEST VAL Loss: 0.3011  Val_Acc: 93.580

Epoch 23: Validation loss decreased (0.301072 --> 0.296168).  Saving model ...
	 Train_Loss: 0.4035 Train_Acc: 82.002 Val_Loss: 0.2962  BEST VAL Loss: 0.2962  Val_Acc: 93.786

Epoch 24: Validation loss decreased (0.296168 --> 0.291620).  Saving model ...
	 Train_Loss: 0.3994 Train_Acc: 82.111 Val_Loss: 0.2916  BEST VAL Loss: 0.2916  Val_Acc: 94.156

Epoch 25: Validation loss decreased (0.291620 --> 0.287350).  Saving model ...
	 Train_Loss: 0.3957 Train_Acc: 82.116 Val_Loss: 0.2874  BEST VAL Loss: 0.2874  Val_Acc: 94.527

Epoch 26: Validation loss decreased (0.287350 --> 0.282980).  Saving model ...
	 Train_Loss: 0.3923 Train_Acc: 81.807 Val_Loss: 0.2830  BEST VAL Loss: 0.2830  Val_Acc: 94.321

Epoch 27: Validation loss decreased (0.282980 --> 0.279125).  Saving model ...
	 Train_Loss: 0.3891 Train_Acc: 81.884 Val_Loss: 0.2791  BEST VAL Loss: 0.2791  Val_Acc: 94.568

Epoch 28: Validation loss decreased (0.279125 --> 0.275263).  Saving model ...
	 Train_Loss: 0.3861 Train_Acc: 81.894 Val_Loss: 0.2753  BEST VAL Loss: 0.2753  Val_Acc: 94.609

Epoch 29: Validation loss decreased (0.275263 --> 0.272048).  Saving model ...
	 Train_Loss: 0.3833 Train_Acc: 81.889 Val_Loss: 0.2720  BEST VAL Loss: 0.2720  Val_Acc: 93.333

Epoch 30: Validation loss decreased (0.272048 --> 0.268617).  Saving model ...
	 Train_Loss: 0.3803 Train_Acc: 82.363 Val_Loss: 0.2686  BEST VAL Loss: 0.2686  Val_Acc: 94.609

Epoch 31: Validation loss decreased (0.268617 --> 0.265480).  Saving model ...
	 Train_Loss: 0.3776 Train_Acc: 82.177 Val_Loss: 0.2655  BEST VAL Loss: 0.2655  Val_Acc: 94.444

Epoch 32: Validation loss decreased (0.265480 --> 0.262140).  Saving model ...
	 Train_Loss: 0.3750 Train_Acc: 82.450 Val_Loss: 0.2621  BEST VAL Loss: 0.2621  Val_Acc: 94.897

Epoch 33: Validation loss decreased (0.262140 --> 0.259130).  Saving model ...
	 Train_Loss: 0.3725 Train_Acc: 82.512 Val_Loss: 0.2591  BEST VAL Loss: 0.2591  Val_Acc: 94.897

Epoch 34: Validation loss decreased (0.259130 --> 0.256137).  Saving model ...
	 Train_Loss: 0.3701 Train_Acc: 82.450 Val_Loss: 0.2561  BEST VAL Loss: 0.2561  Val_Acc: 94.733

Epoch 35: Validation loss decreased (0.256137 --> 0.253426).  Saving model ...
	 Train_Loss: 0.3677 Train_Acc: 82.666 Val_Loss: 0.2534  BEST VAL Loss: 0.2534  Val_Acc: 94.979

Epoch 36: Validation loss decreased (0.253426 --> 0.251218).  Saving model ...
	 Train_Loss: 0.3656 Train_Acc: 82.527 Val_Loss: 0.2512  BEST VAL Loss: 0.2512  Val_Acc: 93.786

Epoch 37: Validation loss decreased (0.251218 --> 0.248713).  Saving model ...
	 Train_Loss: 0.3634 Train_Acc: 82.903 Val_Loss: 0.2487  BEST VAL Loss: 0.2487  Val_Acc: 95.103

Epoch 38: Validation loss decreased (0.248713 --> 0.246618).  Saving model ...
	 Train_Loss: 0.3612 Train_Acc: 82.733 Val_Loss: 0.2466  BEST VAL Loss: 0.2466  Val_Acc: 94.609

Epoch 39: Validation loss decreased (0.246618 --> 0.244299).  Saving model ...
	 Train_Loss: 0.3593 Train_Acc: 82.604 Val_Loss: 0.2443  BEST VAL Loss: 0.2443  Val_Acc: 95.226

Epoch 40: Validation loss decreased (0.244299 --> 0.242115).  Saving model ...
	 Train_Loss: 0.3574 Train_Acc: 82.821 Val_Loss: 0.2421  BEST VAL Loss: 0.2421  Val_Acc: 94.815

Epoch 41: Validation loss decreased (0.242115 --> 0.240029).  Saving model ...
	 Train_Loss: 0.3555 Train_Acc: 83.068 Val_Loss: 0.2400  BEST VAL Loss: 0.2400  Val_Acc: 94.856

Epoch 42: Validation loss decreased (0.240029 --> 0.238176).  Saving model ...
	 Train_Loss: 0.3537 Train_Acc: 83.191 Val_Loss: 0.2382  BEST VAL Loss: 0.2382  Val_Acc: 94.568

Epoch 43: Validation loss decreased (0.238176 --> 0.236362).  Saving model ...
	 Train_Loss: 0.3519 Train_Acc: 82.893 Val_Loss: 0.2364  BEST VAL Loss: 0.2364  Val_Acc: 94.650

Epoch 44: Validation loss decreased (0.236362 --> 0.234611).  Saving model ...
	 Train_Loss: 0.3503 Train_Acc: 82.625 Val_Loss: 0.2346  BEST VAL Loss: 0.2346  Val_Acc: 95.021

Epoch 45: Validation loss decreased (0.234611 --> 0.232748).  Saving model ...
	 Train_Loss: 0.3487 Train_Acc: 83.196 Val_Loss: 0.2327  BEST VAL Loss: 0.2327  Val_Acc: 95.062

Epoch 46: Validation loss decreased (0.232748 --> 0.230991).  Saving model ...
	 Train_Loss: 0.3471 Train_Acc: 83.206 Val_Loss: 0.2310  BEST VAL Loss: 0.2310  Val_Acc: 95.638

Epoch 47: Validation loss decreased (0.230991 --> 0.229322).  Saving model ...
	 Train_Loss: 0.3456 Train_Acc: 83.253 Val_Loss: 0.2293  BEST VAL Loss: 0.2293  Val_Acc: 95.432

Epoch 48: Validation loss decreased (0.229322 --> 0.227752).  Saving model ...
	 Train_Loss: 0.3441 Train_Acc: 83.037 Val_Loss: 0.2278  BEST VAL Loss: 0.2278  Val_Acc: 95.021

Epoch 49: Validation loss decreased (0.227752 --> 0.226112).  Saving model ...
	 Train_Loss: 0.3426 Train_Acc: 83.201 Val_Loss: 0.2261  BEST VAL Loss: 0.2261  Val_Acc: 95.350

Epoch 50: Validation loss decreased (0.226112 --> 0.224746).  Saving model ...
	 Train_Loss: 0.3412 Train_Acc: 83.289 Val_Loss: 0.2247  BEST VAL Loss: 0.2247  Val_Acc: 94.979

Epoch 51: Validation loss decreased (0.224746 --> 0.223188).  Saving model ...
	 Train_Loss: 0.3398 Train_Acc: 83.340 Val_Loss: 0.2232  BEST VAL Loss: 0.2232  Val_Acc: 95.350

Epoch 52: Validation loss decreased (0.223188 --> 0.221883).  Saving model ...
	 Train_Loss: 0.3385 Train_Acc: 83.314 Val_Loss: 0.2219  BEST VAL Loss: 0.2219  Val_Acc: 94.198

Epoch 53: Validation loss decreased (0.221883 --> 0.220763).  Saving model ...
	 Train_Loss: 0.3372 Train_Acc: 83.572 Val_Loss: 0.2208  BEST VAL Loss: 0.2208  Val_Acc: 93.909

Epoch 54: Validation loss decreased (0.220763 --> 0.219402).  Saving model ...
	 Train_Loss: 0.3358 Train_Acc: 83.561 Val_Loss: 0.2194  BEST VAL Loss: 0.2194  Val_Acc: 95.267

Epoch 55: Validation loss decreased (0.219402 --> 0.218098).  Saving model ...
	 Train_Loss: 0.3347 Train_Acc: 83.376 Val_Loss: 0.2181  BEST VAL Loss: 0.2181  Val_Acc: 94.979

Epoch 56: Validation loss decreased (0.218098 --> 0.216866).  Saving model ...
	 Train_Loss: 0.3335 Train_Acc: 83.227 Val_Loss: 0.2169  BEST VAL Loss: 0.2169  Val_Acc: 94.897

Epoch 57: Validation loss decreased (0.216866 --> 0.215641).  Saving model ...
	 Train_Loss: 0.3323 Train_Acc: 83.242 Val_Loss: 0.2156  BEST VAL Loss: 0.2156  Val_Acc: 95.144

Epoch 58: Validation loss decreased (0.215641 --> 0.214632).  Saving model ...
	 Train_Loss: 0.3311 Train_Acc: 83.654 Val_Loss: 0.2146  BEST VAL Loss: 0.2146  Val_Acc: 95.144

Epoch 59: Validation loss decreased (0.214632 --> 0.213646).  Saving model ...
	 Train_Loss: 0.3299 Train_Acc: 83.273 Val_Loss: 0.2136  BEST VAL Loss: 0.2136  Val_Acc: 94.280

Epoch 60: Validation loss decreased (0.213646 --> 0.212428).  Saving model ...
	 Train_Loss: 0.3288 Train_Acc: 83.736 Val_Loss: 0.2124  BEST VAL Loss: 0.2124  Val_Acc: 95.267

Epoch 61: Validation loss decreased (0.212428 --> 0.211383).  Saving model ...
	 Train_Loss: 0.3278 Train_Acc: 83.556 Val_Loss: 0.2114  BEST VAL Loss: 0.2114  Val_Acc: 95.226

Epoch 62: Validation loss decreased (0.211383 --> 0.210270).  Saving model ...
	 Train_Loss: 0.3266 Train_Acc: 83.850 Val_Loss: 0.2103  BEST VAL Loss: 0.2103  Val_Acc: 95.350

Epoch 63: Validation loss decreased (0.210270 --> 0.209520).  Saving model ...
	 Train_Loss: 0.3256 Train_Acc: 83.911 Val_Loss: 0.2095  BEST VAL Loss: 0.2095  Val_Acc: 94.198

Epoch 64: Validation loss decreased (0.209520 --> 0.208652).  Saving model ...
	 Train_Loss: 0.3246 Train_Acc: 83.340 Val_Loss: 0.2087  BEST VAL Loss: 0.2087  Val_Acc: 94.979

Epoch 65: Validation loss decreased (0.208652 --> 0.207681).  Saving model ...
	 Train_Loss: 0.3237 Train_Acc: 83.165 Val_Loss: 0.2077  BEST VAL Loss: 0.2077  Val_Acc: 94.938

Epoch 66: Validation loss decreased (0.207681 --> 0.206829).  Saving model ...
	 Train_Loss: 0.3228 Train_Acc: 83.155 Val_Loss: 0.2068  BEST VAL Loss: 0.2068  Val_Acc: 95.556

Epoch 67: Validation loss decreased (0.206829 --> 0.206358).  Saving model ...
	 Train_Loss: 0.3218 Train_Acc: 83.947 Val_Loss: 0.2064  BEST VAL Loss: 0.2064  Val_Acc: 94.527

Epoch 68: Validation loss decreased (0.206358 --> 0.205399).  Saving model ...
	 Train_Loss: 0.3209 Train_Acc: 83.572 Val_Loss: 0.2054  BEST VAL Loss: 0.2054  Val_Acc: 95.062

Epoch 69: Validation loss decreased (0.205399 --> 0.204821).  Saving model ...
	 Train_Loss: 0.3200 Train_Acc: 83.798 Val_Loss: 0.2048  BEST VAL Loss: 0.2048  Val_Acc: 94.691

Epoch 70: Validation loss decreased (0.204821 --> 0.204050).  Saving model ...
	 Train_Loss: 0.3190 Train_Acc: 83.695 Val_Loss: 0.2041  BEST VAL Loss: 0.2041  Val_Acc: 95.350

Epoch 71: Validation loss decreased (0.204050 --> 0.203174).  Saving model ...
	 Train_Loss: 0.3181 Train_Acc: 83.633 Val_Loss: 0.2032  BEST VAL Loss: 0.2032  Val_Acc: 95.473

Epoch 72: Validation loss decreased (0.203174 --> 0.202563).  Saving model ...
	 Train_Loss: 0.3173 Train_Acc: 83.860 Val_Loss: 0.2026  BEST VAL Loss: 0.2026  Val_Acc: 95.638

Epoch 73: Validation loss decreased (0.202563 --> 0.201980).  Saving model ...
	 Train_Loss: 0.3164 Train_Acc: 83.803 Val_Loss: 0.2020  BEST VAL Loss: 0.2020  Val_Acc: 93.827

Epoch 74: Validation loss decreased (0.201980 --> 0.201126).  Saving model ...
	 Train_Loss: 0.3156 Train_Acc: 83.525 Val_Loss: 0.2011  BEST VAL Loss: 0.2011  Val_Acc: 95.021

Epoch 75: Validation loss decreased (0.201126 --> 0.200392).  Saving model ...
	 Train_Loss: 0.3147 Train_Acc: 84.133 Val_Loss: 0.2004  BEST VAL Loss: 0.2004  Val_Acc: 95.556

Epoch 76: Validation loss decreased (0.200392 --> 0.199705).  Saving model ...
	 Train_Loss: 0.3139 Train_Acc: 83.886 Val_Loss: 0.1997  BEST VAL Loss: 0.1997  Val_Acc: 94.856

Epoch 77: Validation loss decreased (0.199705 --> 0.198952).  Saving model ...
	 Train_Loss: 0.3131 Train_Acc: 84.405 Val_Loss: 0.1990  BEST VAL Loss: 0.1990  Val_Acc: 95.350

Epoch 78: Validation loss decreased (0.198952 --> 0.198266).  Saving model ...
	 Train_Loss: 0.3124 Train_Acc: 84.117 Val_Loss: 0.1983  BEST VAL Loss: 0.1983  Val_Acc: 95.350

Epoch 79: Validation loss decreased (0.198266 --> 0.197551).  Saving model ...
	 Train_Loss: 0.3116 Train_Acc: 84.590 Val_Loss: 0.1976  BEST VAL Loss: 0.1976  Val_Acc: 95.350

Epoch 80: Validation loss decreased (0.197551 --> 0.197050).  Saving model ...
	 Train_Loss: 0.3109 Train_Acc: 84.081 Val_Loss: 0.1970  BEST VAL Loss: 0.1970  Val_Acc: 94.897

Epoch 81: Validation loss decreased (0.197050 --> 0.196459).  Saving model ...
	 Train_Loss: 0.3102 Train_Acc: 83.597 Val_Loss: 0.1965  BEST VAL Loss: 0.1965  Val_Acc: 95.144

Epoch 82: Validation loss decreased (0.196459 --> 0.195664).  Saving model ...
	 Train_Loss: 0.3095 Train_Acc: 84.277 Val_Loss: 0.1957  BEST VAL Loss: 0.1957  Val_Acc: 95.597

Epoch 83: Validation loss decreased (0.195664 --> 0.195198).  Saving model ...
	 Train_Loss: 0.3087 Train_Acc: 84.287 Val_Loss: 0.1952  BEST VAL Loss: 0.1952  Val_Acc: 95.185

Epoch 84: Validation loss decreased (0.195198 --> 0.194519).  Saving model ...
	 Train_Loss: 0.3081 Train_Acc: 83.644 Val_Loss: 0.1945  BEST VAL Loss: 0.1945  Val_Acc: 95.638

Epoch 85: Validation loss decreased (0.194519 --> 0.193991).  Saving model ...
	 Train_Loss: 0.3073 Train_Acc: 84.297 Val_Loss: 0.1940  BEST VAL Loss: 0.1940  Val_Acc: 95.103

Epoch 86: Validation loss decreased (0.193991 --> 0.193345).  Saving model ...
	 Train_Loss: 0.3067 Train_Acc: 83.958 Val_Loss: 0.1933  BEST VAL Loss: 0.1933  Val_Acc: 95.432

Epoch 87: Validation loss decreased (0.193345 --> 0.192721).  Saving model ...
	 Train_Loss: 0.3060 Train_Acc: 83.983 Val_Loss: 0.1927  BEST VAL Loss: 0.1927  Val_Acc: 95.432

Epoch 88: Validation loss decreased (0.192721 --> 0.192170).  Saving model ...
	 Train_Loss: 0.3054 Train_Acc: 84.246 Val_Loss: 0.1922  BEST VAL Loss: 0.1922  Val_Acc: 95.514

Epoch 89: Validation loss decreased (0.192170 --> 0.191527).  Saving model ...
	 Train_Loss: 0.3048 Train_Acc: 84.282 Val_Loss: 0.1915  BEST VAL Loss: 0.1915  Val_Acc: 95.350

Epoch 90: Validation loss decreased (0.191527 --> 0.190961).  Saving model ...
	 Train_Loss: 0.3041 Train_Acc: 84.215 Val_Loss: 0.1910  BEST VAL Loss: 0.1910  Val_Acc: 95.556

Epoch 91: Validation loss decreased (0.190961 --> 0.190545).  Saving model ...
	 Train_Loss: 0.3034 Train_Acc: 84.235 Val_Loss: 0.1905  BEST VAL Loss: 0.1905  Val_Acc: 95.226

Epoch 92: Validation loss decreased (0.190545 --> 0.190363).  Saving model ...
	 Train_Loss: 0.3029 Train_Acc: 83.891 Val_Loss: 0.1904  BEST VAL Loss: 0.1904  Val_Acc: 95.638

Epoch 93: Validation loss decreased (0.190363 --> 0.189676).  Saving model ...
	 Train_Loss: 0.3023 Train_Acc: 83.829 Val_Loss: 0.1897  BEST VAL Loss: 0.1897  Val_Acc: 95.926

Epoch 94: Validation loss decreased (0.189676 --> 0.189245).  Saving model ...
	 Train_Loss: 0.3017 Train_Acc: 83.834 Val_Loss: 0.1892  BEST VAL Loss: 0.1892  Val_Acc: 95.350

Epoch 95: Validation loss decreased (0.189245 --> 0.188913).  Saving model ...
	 Train_Loss: 0.3012 Train_Acc: 84.205 Val_Loss: 0.1889  BEST VAL Loss: 0.1889  Val_Acc: 95.432

Epoch 96: Validation loss decreased (0.188913 --> 0.188487).  Saving model ...
	 Train_Loss: 0.3006 Train_Acc: 84.390 Val_Loss: 0.1885  BEST VAL Loss: 0.1885  Val_Acc: 95.185

Epoch 97: Validation loss decreased (0.188487 --> 0.188131).  Saving model ...
	 Train_Loss: 0.3000 Train_Acc: 84.457 Val_Loss: 0.1881  BEST VAL Loss: 0.1881  Val_Acc: 95.391

Epoch 98: Validation loss decreased (0.188131 --> 0.187709).  Saving model ...
	 Train_Loss: 0.2993 Train_Acc: 84.817 Val_Loss: 0.1877  BEST VAL Loss: 0.1877  Val_Acc: 94.938

Epoch 99: Validation loss decreased (0.187709 --> 0.187344).  Saving model ...
	 Train_Loss: 0.2988 Train_Acc: 83.896 Val_Loss: 0.1873  BEST VAL Loss: 0.1873  Val_Acc: 95.432

LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.50      0.51      9832
           1       0.50      0.51      0.50      9604

    accuracy                           0.51     19436
   macro avg       0.51      0.51      0.51     19436
weighted avg       0.51      0.51      0.51     19436

LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.48      0.48      1229
           1       0.48      0.49      0.49      1201

    accuracy                           0.49      2430
   macro avg       0.49      0.49      0.49      2430
weighted avg       0.49      0.49      0.49      2430

LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.49      0.50      1229
           1       0.49      0.51      0.50      1201

    accuracy                           0.50      2430
   macro avg       0.50      0.50      0.50      2430
weighted avg       0.50      0.50      0.50      2430

              precision    recall  f1-score   support

           0       0.51      0.49      0.50      1229
           1       0.49      0.51      0.50      1201

    accuracy                           0.50      2430
   macro avg       0.50      0.50      0.50      2430
weighted avg       0.50      0.50      0.50      2430

LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.50      0.50      4168
           1       0.51      0.51      0.51      4212

    accuracy                           0.51      8380
   macro avg       0.51      0.51      0.51      8380
weighted avg       0.51      0.51      0.51      8380

              precision    recall  f1-score   support

           0       0.50      0.50      0.50      4168
           1       0.51      0.51      0.51      4212

    accuracy                           0.51      8380
   macro avg       0.51      0.51      0.51      8380
weighted avg       0.51      0.51      0.51      8380

completed
