[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '0adff6f7'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'd2856f33'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'c63e2785'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'c5965d5d'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: H2O2_100.000_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (44410, 1276)
Number of total missing values across all columns: 88820
Data Subset Is Off
Wells held out for testing: ['C21' 'H22']
Wells to use for training, validation, and testing ['C16' 'C17' 'H18' 'H19' 'C20' 'H23' 'I18' 'I19' 'I22' 'I23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.659071).  Saving model ...
	 Train_Loss: 0.6587 Train_Acc: 63.598 Val_Loss: 0.6591  BEST VAL Loss: 0.6591  Val_Acc: 63.578

Epoch 1: Validation loss decreased (0.659071 --> 0.657584).  Saving model ...
	 Train_Loss: 0.6575 Train_Acc: 63.594 Val_Loss: 0.6576  BEST VAL Loss: 0.6576  Val_Acc: 63.606

Epoch 2: Validation loss decreased (0.657584 --> 0.657208).  Saving model ...
	 Train_Loss: 0.6566 Train_Acc: 63.605 Val_Loss: 0.6572  BEST VAL Loss: 0.6572  Val_Acc: 63.606

Epoch 3: Validation loss decreased (0.657208 --> 0.656323).  Saving model ...
	 Train_Loss: 0.6561 Train_Acc: 63.605 Val_Loss: 0.6563  BEST VAL Loss: 0.6563  Val_Acc: 63.578

Epoch 4: Validation loss decreased (0.656323 --> 0.655313).  Saving model ...
	 Train_Loss: 0.6553 Train_Acc: 63.605 Val_Loss: 0.6553  BEST VAL Loss: 0.6553  Val_Acc: 63.578

Epoch 5: Validation loss decreased (0.655313 --> 0.654207).  Saving model ...
	 Train_Loss: 0.6544 Train_Acc: 63.601 Val_Loss: 0.6542  BEST VAL Loss: 0.6542  Val_Acc: 63.606

Epoch 6: Validation loss decreased (0.654207 --> 0.652748).  Saving model ...
	 Train_Loss: 0.6532 Train_Acc: 63.601 Val_Loss: 0.6527  BEST VAL Loss: 0.6527  Val_Acc: 63.606

Epoch 7: Validation loss decreased (0.652748 --> 0.650839).  Saving model ...
	 Train_Loss: 0.6519 Train_Acc: 63.587 Val_Loss: 0.6508  BEST VAL Loss: 0.6508  Val_Acc: 63.606

Epoch 8: Validation loss decreased (0.650839 --> 0.649025).  Saving model ...
	 Train_Loss: 0.6506 Train_Acc: 63.591 Val_Loss: 0.6490  BEST VAL Loss: 0.6490  Val_Acc: 63.606

Epoch 9: Validation loss decreased (0.649025 --> 0.646883).  Saving model ...
	 Train_Loss: 0.6491 Train_Acc: 63.591 Val_Loss: 0.6469  BEST VAL Loss: 0.6469  Val_Acc: 63.606

Epoch 10: Validation loss decreased (0.646883 --> 0.644558).  Saving model ...
	 Train_Loss: 0.6474 Train_Acc: 63.640 Val_Loss: 0.6446  BEST VAL Loss: 0.6446  Val_Acc: 63.606

Epoch 11: Validation loss decreased (0.644558 --> 0.641879).  Saving model ...
	 Train_Loss: 0.6455 Train_Acc: 63.790 Val_Loss: 0.6419  BEST VAL Loss: 0.6419  Val_Acc: 63.606

Epoch 12: Validation loss decreased (0.641879 --> 0.638961).  Saving model ...
	 Train_Loss: 0.6433 Train_Acc: 64.063 Val_Loss: 0.6390  BEST VAL Loss: 0.6390  Val_Acc: 63.662

Epoch 13: Validation loss decreased (0.638961 --> 0.635790).  Saving model ...
	 Train_Loss: 0.6411 Train_Acc: 64.269 Val_Loss: 0.6358  BEST VAL Loss: 0.6358  Val_Acc: 63.746

Epoch 14: Validation loss decreased (0.635790 --> 0.632082).  Saving model ...
	 Train_Loss: 0.6384 Train_Acc: 64.976 Val_Loss: 0.6321  BEST VAL Loss: 0.6321  Val_Acc: 64.866

Epoch 15: Validation loss decreased (0.632082 --> 0.628064).  Saving model ...
	 Train_Loss: 0.6353 Train_Acc: 65.631 Val_Loss: 0.6281  BEST VAL Loss: 0.6281  Val_Acc: 67.749

Epoch 16: Validation loss decreased (0.628064 --> 0.623782).  Saving model ...
	 Train_Loss: 0.6319 Train_Acc: 66.537 Val_Loss: 0.6238  BEST VAL Loss: 0.6238  Val_Acc: 69.317

Epoch 17: Validation loss decreased (0.623782 --> 0.619129).  Saving model ...
	 Train_Loss: 0.6283 Train_Acc: 67.409 Val_Loss: 0.6191  BEST VAL Loss: 0.6191  Val_Acc: 70.325

Epoch 18: Validation loss decreased (0.619129 --> 0.614404).  Saving model ...
	 Train_Loss: 0.6245 Train_Acc: 68.413 Val_Loss: 0.6144  BEST VAL Loss: 0.6144  Val_Acc: 71.865

Epoch 19: Validation loss decreased (0.614404 --> 0.609383).  Saving model ...
	 Train_Loss: 0.6205 Train_Acc: 69.585 Val_Loss: 0.6094  BEST VAL Loss: 0.6094  Val_Acc: 72.928

Epoch 20: Validation loss decreased (0.609383 --> 0.604587).  Saving model ...
	 Train_Loss: 0.6164 Train_Acc: 70.646 Val_Loss: 0.6046  BEST VAL Loss: 0.6046  Val_Acc: 73.796

Epoch 21: Validation loss decreased (0.604587 --> 0.599559).  Saving model ...
	 Train_Loss: 0.6122 Train_Acc: 71.608 Val_Loss: 0.5996  BEST VAL Loss: 0.5996  Val_Acc: 75.308

Epoch 22: Validation loss decreased (0.599559 --> 0.594788).  Saving model ...
	 Train_Loss: 0.6080 Train_Acc: 72.507 Val_Loss: 0.5948  BEST VAL Loss: 0.5948  Val_Acc: 75.672

Epoch 23: Validation loss decreased (0.594788 --> 0.590110).  Saving model ...
	 Train_Loss: 0.6038 Train_Acc: 72.952 Val_Loss: 0.5901  BEST VAL Loss: 0.5901  Val_Acc: 75.728

Epoch 24: Validation loss decreased (0.590110 --> 0.585356).  Saving model ...
	 Train_Loss: 0.5998 Train_Acc: 73.722 Val_Loss: 0.5854  BEST VAL Loss: 0.5854  Val_Acc: 77.464

Epoch 25: Validation loss decreased (0.585356 --> 0.580707).  Saving model ...
	 Train_Loss: 0.5957 Train_Acc: 74.530 Val_Loss: 0.5807  BEST VAL Loss: 0.5807  Val_Acc: 77.576

Epoch 26: Validation loss decreased (0.580707 --> 0.576387).  Saving model ...
	 Train_Loss: 0.5916 Train_Acc: 75.027 Val_Loss: 0.5764  BEST VAL Loss: 0.5764  Val_Acc: 77.744

Epoch 27: Validation loss decreased (0.576387 --> 0.572254).  Saving model ...
	 Train_Loss: 0.5877 Train_Acc: 75.829 Val_Loss: 0.5723  BEST VAL Loss: 0.5723  Val_Acc: 78.359

Epoch 28: Validation loss decreased (0.572254 --> 0.568163).  Saving model ...
	 Train_Loss: 0.5838 Train_Acc: 76.248 Val_Loss: 0.5682  BEST VAL Loss: 0.5682  Val_Acc: 78.499

Epoch 29: Validation loss decreased (0.568163 --> 0.564275).  Saving model ...
	 Train_Loss: 0.5802 Train_Acc: 76.220 Val_Loss: 0.5643  BEST VAL Loss: 0.5643  Val_Acc: 78.891

Epoch 30: Validation loss decreased (0.564275 --> 0.560640).  Saving model ...
	 Train_Loss: 0.5766 Train_Acc: 76.679 Val_Loss: 0.5606  BEST VAL Loss: 0.5606  Val_Acc: 78.471

Epoch 31: Validation loss decreased (0.560640 --> 0.556961).  Saving model ...
	 Train_Loss: 0.5730 Train_Acc: 76.868 Val_Loss: 0.5570  BEST VAL Loss: 0.5570  Val_Acc: 79.283

Epoch 32: Validation loss decreased (0.556961 --> 0.553647).  Saving model ...
	 Train_Loss: 0.5696 Train_Acc: 77.333 Val_Loss: 0.5536  BEST VAL Loss: 0.5536  Val_Acc: 78.303

Epoch 33: Validation loss decreased (0.553647 --> 0.550437).  Saving model ...
	 Train_Loss: 0.5663 Train_Acc: 77.515 Val_Loss: 0.5504  BEST VAL Loss: 0.5504  Val_Acc: 78.611

Epoch 34: Validation loss decreased (0.550437 --> 0.547379).  Saving model ...
	 Train_Loss: 0.5630 Train_Acc: 77.918 Val_Loss: 0.5474  BEST VAL Loss: 0.5474  Val_Acc: 79.227

Epoch 35: Validation loss decreased (0.547379 --> 0.544287).  Saving model ...
	 Train_Loss: 0.5598 Train_Acc: 78.156 Val_Loss: 0.5443  BEST VAL Loss: 0.5443  Val_Acc: 79.535

Epoch 36: Validation loss decreased (0.544287 --> 0.541259).  Saving model ...
	 Train_Loss: 0.5567 Train_Acc: 78.516 Val_Loss: 0.5413  BEST VAL Loss: 0.5413  Val_Acc: 79.255

Epoch 37: Validation loss decreased (0.541259 --> 0.538486).  Saving model ...
	 Train_Loss: 0.5537 Train_Acc: 78.429 Val_Loss: 0.5385  BEST VAL Loss: 0.5385  Val_Acc: 79.311

Epoch 38: Validation loss decreased (0.538486 --> 0.535872).  Saving model ...
	 Train_Loss: 0.5507 Train_Acc: 78.569 Val_Loss: 0.5359  BEST VAL Loss: 0.5359  Val_Acc: 79.675

Epoch 39: Validation loss decreased (0.535872 --> 0.534104).  Saving model ...
	 Train_Loss: 0.5478 Train_Acc: 79.209 Val_Loss: 0.5341  BEST VAL Loss: 0.5341  Val_Acc: 77.800

Epoch 40: Validation loss decreased (0.534104 --> 0.531675).  Saving model ...
	 Train_Loss: 0.5450 Train_Acc: 79.307 Val_Loss: 0.5317  BEST VAL Loss: 0.5317  Val_Acc: 79.703

Epoch 41: Validation loss decreased (0.531675 --> 0.529401).  Saving model ...
	 Train_Loss: 0.5421 Train_Acc: 79.528 Val_Loss: 0.5294  BEST VAL Loss: 0.5294  Val_Acc: 79.647

Epoch 42: Validation loss decreased (0.529401 --> 0.527010).  Saving model ...
	 Train_Loss: 0.5394 Train_Acc: 79.720 Val_Loss: 0.5270  BEST VAL Loss: 0.5270  Val_Acc: 80.235

Epoch 43: Validation loss decreased (0.527010 --> 0.524767).  Saving model ...
	 Train_Loss: 0.5367 Train_Acc: 79.986 Val_Loss: 0.5248  BEST VAL Loss: 0.5248  Val_Acc: 79.703

Epoch 44: Validation loss decreased (0.524767 --> 0.522502).  Saving model ...
	 Train_Loss: 0.5341 Train_Acc: 80.140 Val_Loss: 0.5225  BEST VAL Loss: 0.5225  Val_Acc: 79.731

Epoch 45: Validation loss decreased (0.522502 --> 0.520411).  Saving model ...
	 Train_Loss: 0.5316 Train_Acc: 80.658 Val_Loss: 0.5204  BEST VAL Loss: 0.5204  Val_Acc: 79.563

Epoch 46: Validation loss decreased (0.520411 --> 0.518458).  Saving model ...
	 Train_Loss: 0.5291 Train_Acc: 80.346 Val_Loss: 0.5185  BEST VAL Loss: 0.5185  Val_Acc: 79.703

Epoch 47: Validation loss decreased (0.518458 --> 0.516580).  Saving model ...
	 Train_Loss: 0.5266 Train_Acc: 80.819 Val_Loss: 0.5166  BEST VAL Loss: 0.5166  Val_Acc: 79.927

Epoch 48: Validation loss decreased (0.516580 --> 0.514843).  Saving model ...
	 Train_Loss: 0.5242 Train_Acc: 80.892 Val_Loss: 0.5148  BEST VAL Loss: 0.5148  Val_Acc: 79.843

Epoch 49: Validation loss decreased (0.514843 --> 0.513093).  Saving model ...
	 Train_Loss: 0.5218 Train_Acc: 81.078 Val_Loss: 0.5131  BEST VAL Loss: 0.5131  Val_Acc: 79.815

Epoch 50: Validation loss decreased (0.513093 --> 0.511429).  Saving model ...
	 Train_Loss: 0.5195 Train_Acc: 80.896 Val_Loss: 0.5114  BEST VAL Loss: 0.5114  Val_Acc: 79.563

Epoch 51: Validation loss decreased (0.511429 --> 0.509797).  Saving model ...
	 Train_Loss: 0.5173 Train_Acc: 81.232 Val_Loss: 0.5098  BEST VAL Loss: 0.5098  Val_Acc: 79.843

Epoch 52: Validation loss decreased (0.509797 --> 0.508060).  Saving model ...
	 Train_Loss: 0.5150 Train_Acc: 81.137 Val_Loss: 0.5081  BEST VAL Loss: 0.5081  Val_Acc: 79.927

Epoch 53: Validation loss decreased (0.508060 --> 0.506575).  Saving model ...
	 Train_Loss: 0.5129 Train_Acc: 81.428 Val_Loss: 0.5066  BEST VAL Loss: 0.5066  Val_Acc: 79.983

Epoch 54: Validation loss decreased (0.506575 --> 0.505182).  Saving model ...
	 Train_Loss: 0.5107 Train_Acc: 81.606 Val_Loss: 0.5052  BEST VAL Loss: 0.5052  Val_Acc: 80.123

Epoch 55: Validation loss decreased (0.505182 --> 0.503808).  Saving model ...
	 Train_Loss: 0.5086 Train_Acc: 81.564 Val_Loss: 0.5038  BEST VAL Loss: 0.5038  Val_Acc: 79.563

Epoch 56: Validation loss decreased (0.503808 --> 0.502426).  Saving model ...
	 Train_Loss: 0.5065 Train_Acc: 81.988 Val_Loss: 0.5024  BEST VAL Loss: 0.5024  Val_Acc: 80.571

Epoch 57: Validation loss decreased (0.502426 --> 0.501251).  Saving model ...
	 Train_Loss: 0.5044 Train_Acc: 82.075 Val_Loss: 0.5013  BEST VAL Loss: 0.5013  Val_Acc: 79.591

Epoch 58: Validation loss decreased (0.501251 --> 0.500014).  Saving model ...
	 Train_Loss: 0.5024 Train_Acc: 82.124 Val_Loss: 0.5000  BEST VAL Loss: 0.5000  Val_Acc: 79.675

Epoch 59: Validation loss decreased (0.500014 --> 0.499187).  Saving model ...
	 Train_Loss: 0.5004 Train_Acc: 82.513 Val_Loss: 0.4992  BEST VAL Loss: 0.4992  Val_Acc: 79.423

Epoch 60: Validation loss decreased (0.499187 --> 0.498127).  Saving model ...
	 Train_Loss: 0.4985 Train_Acc: 82.100 Val_Loss: 0.4981  BEST VAL Loss: 0.4981  Val_Acc: 79.703

Epoch 61: Validation loss decreased (0.498127 --> 0.497366).  Saving model ...
	 Train_Loss: 0.4966 Train_Acc: 82.177 Val_Loss: 0.4974  BEST VAL Loss: 0.4974  Val_Acc: 79.423

Epoch 62: Validation loss decreased (0.497366 --> 0.496358).  Saving model ...
	 Train_Loss: 0.4947 Train_Acc: 82.586 Val_Loss: 0.4964  BEST VAL Loss: 0.4964  Val_Acc: 79.703

Epoch 63: Validation loss decreased (0.496358 --> 0.495295).  Saving model ...
	 Train_Loss: 0.4928 Train_Acc: 82.751 Val_Loss: 0.4953  BEST VAL Loss: 0.4953  Val_Acc: 79.675

Epoch 64: Validation loss decreased (0.495295 --> 0.494185).  Saving model ...
	 Train_Loss: 0.4910 Train_Acc: 82.684 Val_Loss: 0.4942  BEST VAL Loss: 0.4942  Val_Acc: 80.487

Epoch 65: Validation loss decreased (0.494185 --> 0.493350).  Saving model ...
	 Train_Loss: 0.4891 Train_Acc: 82.569 Val_Loss: 0.4933  BEST VAL Loss: 0.4933  Val_Acc: 79.619

Epoch 66: Validation loss decreased (0.493350 --> 0.492208).  Saving model ...
	 Train_Loss: 0.4874 Train_Acc: 82.597 Val_Loss: 0.4922  BEST VAL Loss: 0.4922  Val_Acc: 80.263

Epoch 67: Validation loss decreased (0.492208 --> 0.491238).  Saving model ...
	 Train_Loss: 0.4856 Train_Acc: 82.726 Val_Loss: 0.4912  BEST VAL Loss: 0.4912  Val_Acc: 80.179

Epoch 68: Validation loss decreased (0.491238 --> 0.490353).  Saving model ...
	 Train_Loss: 0.4839 Train_Acc: 82.670 Val_Loss: 0.4904  BEST VAL Loss: 0.4904  Val_Acc: 80.515

Epoch 69: Validation loss decreased (0.490353 --> 0.489528).  Saving model ...
	 Train_Loss: 0.4821 Train_Acc: 83.335 Val_Loss: 0.4895  BEST VAL Loss: 0.4895  Val_Acc: 80.207

Epoch 70: Validation loss decreased (0.489528 --> 0.488619).  Saving model ...
	 Train_Loss: 0.4805 Train_Acc: 82.870 Val_Loss: 0.4886  BEST VAL Loss: 0.4886  Val_Acc: 80.291

Epoch 71: Validation loss decreased (0.488619 --> 0.488013).  Saving model ...
	 Train_Loss: 0.4789 Train_Acc: 82.873 Val_Loss: 0.4880  BEST VAL Loss: 0.4880  Val_Acc: 79.255

Epoch 72: Validation loss decreased (0.488013 --> 0.487179).  Saving model ...
	 Train_Loss: 0.4773 Train_Acc: 83.059 Val_Loss: 0.4872  BEST VAL Loss: 0.4872  Val_Acc: 80.179

Epoch 73: Validation loss decreased (0.487179 --> 0.486351).  Saving model ...
	 Train_Loss: 0.4757 Train_Acc: 83.398 Val_Loss: 0.4864  BEST VAL Loss: 0.4864  Val_Acc: 80.795

Epoch 74: Validation loss decreased (0.486351 --> 0.485515).  Saving model ...
	 Train_Loss: 0.4741 Train_Acc: 83.139 Val_Loss: 0.4855  BEST VAL Loss: 0.4855  Val_Acc: 80.627

Epoch 75: Validation loss decreased (0.485515 --> 0.484766).  Saving model ...
	 Train_Loss: 0.4726 Train_Acc: 83.332 Val_Loss: 0.4848  BEST VAL Loss: 0.4848  Val_Acc: 80.207

Epoch 76: Validation loss decreased (0.484766 --> 0.484023).  Saving model ...
	 Train_Loss: 0.4710 Train_Acc: 83.734 Val_Loss: 0.4840  BEST VAL Loss: 0.4840  Val_Acc: 80.459

Epoch 77: Validation loss decreased (0.484023 --> 0.483419).  Saving model ...
	 Train_Loss: 0.4695 Train_Acc: 83.489 Val_Loss: 0.4834  BEST VAL Loss: 0.4834  Val_Acc: 80.067

Epoch 78: Validation loss decreased (0.483419 --> 0.482989).  Saving model ...
	 Train_Loss: 0.4679 Train_Acc: 84.070 Val_Loss: 0.4830  BEST VAL Loss: 0.4830  Val_Acc: 79.115

Epoch 79: Validation loss decreased (0.482989 --> 0.482293).  Saving model ...
	 Train_Loss: 0.4664 Train_Acc: 83.395 Val_Loss: 0.4823  BEST VAL Loss: 0.4823  Val_Acc: 80.179

Epoch 80: Validation loss decreased (0.482293 --> 0.481729).  Saving model ...
	 Train_Loss: 0.4650 Train_Acc: 83.444 Val_Loss: 0.4817  BEST VAL Loss: 0.4817  Val_Acc: 79.955

Epoch 81: Validation loss decreased (0.481729 --> 0.481274).  Saving model ...
	 Train_Loss: 0.4636 Train_Acc: 83.888 Val_Loss: 0.4813  BEST VAL Loss: 0.4813  Val_Acc: 79.283

Epoch 82: Validation loss decreased (0.481274 --> 0.480655).  Saving model ...
	 Train_Loss: 0.4621 Train_Acc: 84.266 Val_Loss: 0.4807  BEST VAL Loss: 0.4807  Val_Acc: 80.291

Epoch 83: Validation loss decreased (0.480655 --> 0.480087).  Saving model ...
	 Train_Loss: 0.4606 Train_Acc: 84.192 Val_Loss: 0.4801  BEST VAL Loss: 0.4801  Val_Acc: 80.011

Epoch 84: Validation loss decreased (0.480087 --> 0.479824).  Saving model ...
	 Train_Loss: 0.4591 Train_Acc: 84.161 Val_Loss: 0.4798  BEST VAL Loss: 0.4798  Val_Acc: 79.479

Epoch 85: Validation loss decreased (0.479824 --> 0.479524).  Saving model ...
	 Train_Loss: 0.4578 Train_Acc: 83.318 Val_Loss: 0.4795  BEST VAL Loss: 0.4795  Val_Acc: 79.731

Epoch 86: Validation loss decreased (0.479524 --> 0.479076).  Saving model ...
	 Train_Loss: 0.4565 Train_Acc: 83.797 Val_Loss: 0.4791  BEST VAL Loss: 0.4791  Val_Acc: 79.759

Epoch 87: Validation loss decreased (0.479076 --> 0.478592).  Saving model ...
	 Train_Loss: 0.4553 Train_Acc: 83.335 Val_Loss: 0.4786  BEST VAL Loss: 0.4786  Val_Acc: 80.095

Epoch 88: Validation loss decreased (0.478592 --> 0.478058).  Saving model ...
	 Train_Loss: 0.4539 Train_Acc: 84.154 Val_Loss: 0.4781  BEST VAL Loss: 0.4781  Val_Acc: 80.571

Epoch 89: Validation loss decreased (0.478058 --> 0.477607).  Saving model ...
	 Train_Loss: 0.4526 Train_Acc: 84.374 Val_Loss: 0.4776  BEST VAL Loss: 0.4776  Val_Acc: 80.375

Epoch 90: Validation loss decreased (0.477607 --> 0.477259).  Saving model ...
	 Train_Loss: 0.4513 Train_Acc: 84.133 Val_Loss: 0.4773  BEST VAL Loss: 0.4773  Val_Acc: 79.143

Epoch 91: Validation loss decreased (0.477259 --> 0.476755).  Saving model ...
	 Train_Loss: 0.4500 Train_Acc: 83.825 Val_Loss: 0.4768  BEST VAL Loss: 0.4768  Val_Acc: 80.403

Epoch 92: Validation loss decreased (0.476755 --> 0.476536).  Saving model ...
	 Train_Loss: 0.4488 Train_Acc: 84.371 Val_Loss: 0.4765  BEST VAL Loss: 0.4765  Val_Acc: 80.151

Epoch 93: Validation loss decreased (0.476536 --> 0.476138).  Saving model ...
	 Train_Loss: 0.4476 Train_Acc: 84.367 Val_Loss: 0.4761  BEST VAL Loss: 0.4761  Val_Acc: 80.151

Epoch 94: Validation loss decreased (0.476138 --> 0.475771).  Saving model ...
	 Train_Loss: 0.4463 Train_Acc: 85.375 Val_Loss: 0.4758  BEST VAL Loss: 0.4758  Val_Acc: 80.263

Epoch 95: Validation loss decreased (0.475771 --> 0.475456).  Saving model ...
	 Train_Loss: 0.4450 Train_Acc: 84.920 Val_Loss: 0.4755  BEST VAL Loss: 0.4755  Val_Acc: 80.067

Epoch 96: Validation loss decreased (0.475456 --> 0.475194).  Saving model ...
	 Train_Loss: 0.4439 Train_Acc: 84.784 Val_Loss: 0.4752  BEST VAL Loss: 0.4752  Val_Acc: 79.871

Epoch 97: Validation loss decreased (0.475194 --> 0.474845).  Saving model ...
	 Train_Loss: 0.4426 Train_Acc: 84.906 Val_Loss: 0.4748  BEST VAL Loss: 0.4748  Val_Acc: 80.207

Epoch 98: Validation loss decreased (0.474845 --> 0.474553).  Saving model ...
	 Train_Loss: 0.4414 Train_Acc: 85.256 Val_Loss: 0.4746  BEST VAL Loss: 0.4746  Val_Acc: 80.039

Epoch 99: Validation loss decreased (0.474553 --> 0.474293).  Saving model ...
	 Train_Loss: 0.4402 Train_Acc: 84.787 Val_Loss: 0.4743  BEST VAL Loss: 0.4743  Val_Acc: 80.095

H2O2_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.64      0.65      0.64     18174
           1       0.37      0.36      0.36     10401

    accuracy                           0.54     28575
   macro avg       0.50      0.50      0.50     28575
weighted avg       0.54      0.54      0.54     28575

H2O2_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.63      0.65      0.64      2272
           1       0.35      0.33      0.34      1300

    accuracy                           0.54      3572
   macro avg       0.49      0.49      0.49      3572
weighted avg       0.53      0.54      0.53      3572

H2O2_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.63      0.63      0.63      2272
           1       0.36      0.35      0.35      1300

    accuracy                           0.53      3572
   macro avg       0.49      0.49      0.49      3572
weighted avg       0.53      0.53      0.53      3572

              precision    recall  f1-score   support

           0       0.63      0.63      0.63      2272
           1       0.36      0.35      0.35      1300

    accuracy                           0.53      3572
   macro avg       0.49      0.49      0.49      3572
weighted avg       0.53      0.53      0.53      3572

H2O2_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.61      0.54      4182
           1       0.52      0.39      0.45      4509

    accuracy                           0.50      8691
   macro avg       0.50      0.50      0.49      8691
weighted avg       0.50      0.50      0.49      8691

              precision    recall  f1-score   support

           0       0.48      0.61      0.54      4182
           1       0.52      0.39      0.45      4509

    accuracy                           0.50      8691
   macro avg       0.50      0.50      0.49      8691
weighted avg       0.50      0.50      0.49      8691

completed
