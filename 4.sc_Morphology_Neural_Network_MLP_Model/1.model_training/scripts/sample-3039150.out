[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1c87e699'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'afc57f18'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'e7dec13b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e76cc304'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Thapsigargin_10.000_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Thapsigargin_10.000_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'Thapsigargin_10.000_DMSO_0.025']
The dimensions of the data are: (310064, 1270)
Number of total missing values across all columns: 620128
Data Subset Is Off
Wells held out for testing: ['B08' 'L06']
Wells to use for training, validation, and testing ['B02' 'B03' 'B09' 'E06' 'E07' 'L07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.472561).  Saving model ...
	 Train_Loss: 0.5951 Train_Acc: 68.996 Val_Loss: 0.4726  BEST VAL Loss: 0.4726  Val_Acc: 80.872

Epoch 1: Validation loss decreased (0.472561 --> 0.463644).  Saving model ...
	 Train_Loss: 0.5622 Train_Acc: 75.125 Val_Loss: 0.4636  BEST VAL Loss: 0.4636  Val_Acc: 80.956

Epoch 2: Validation loss decreased (0.463644 --> 0.442975).  Saving model ...
	 Train_Loss: 0.5445 Train_Acc: 75.981 Val_Loss: 0.4430  BEST VAL Loss: 0.4430  Val_Acc: 84.200

Epoch 3: Validation loss decreased (0.442975 --> 0.435014).  Saving model ...
	 Train_Loss: 0.5325 Train_Acc: 76.803 Val_Loss: 0.4350  BEST VAL Loss: 0.4350  Val_Acc: 83.771

Epoch 4: Validation loss decreased (0.435014 --> 0.424514).  Saving model ...
	 Train_Loss: 0.5241 Train_Acc: 77.163 Val_Loss: 0.4245  BEST VAL Loss: 0.4245  Val_Acc: 85.203

Epoch 5: Validation loss decreased (0.424514 --> 0.415833).  Saving model ...
	 Train_Loss: 0.5171 Train_Acc: 77.681 Val_Loss: 0.4158  BEST VAL Loss: 0.4158  Val_Acc: 85.856

Epoch 6: Validation loss decreased (0.415833 --> 0.411714).  Saving model ...
	 Train_Loss: 0.5118 Train_Acc: 77.762 Val_Loss: 0.4117  BEST VAL Loss: 0.4117  Val_Acc: 84.682

Epoch 7: Validation loss decreased (0.411714 --> 0.409532).  Saving model ...
	 Train_Loss: 0.5069 Train_Acc: 78.214 Val_Loss: 0.4095  BEST VAL Loss: 0.4095  Val_Acc: 84.148

Epoch 8: Validation loss decreased (0.409532 --> 0.403389).  Saving model ...
	 Train_Loss: 0.5028 Train_Acc: 78.378 Val_Loss: 0.4034  BEST VAL Loss: 0.4034  Val_Acc: 86.753

Epoch 9: Validation loss decreased (0.403389 --> 0.400519).  Saving model ...
	 Train_Loss: 0.4992 Train_Acc: 78.677 Val_Loss: 0.4005  BEST VAL Loss: 0.4005  Val_Acc: 85.492

Epoch 10: Validation loss decreased (0.400519 --> 0.397871).  Saving model ...
	 Train_Loss: 0.4962 Train_Acc: 78.726 Val_Loss: 0.3979  BEST VAL Loss: 0.3979  Val_Acc: 85.532

Epoch 11: Validation loss decreased (0.397871 --> 0.394203).  Saving model ...
	 Train_Loss: 0.4936 Train_Acc: 78.842 Val_Loss: 0.3942  BEST VAL Loss: 0.3942  Val_Acc: 86.495

Epoch 12: Validation loss decreased (0.394203 --> 0.390812).  Saving model ...
	 Train_Loss: 0.4911 Train_Acc: 79.081 Val_Loss: 0.3908  BEST VAL Loss: 0.3908  Val_Acc: 87.051

Epoch 13: Validation loss decreased (0.390812 --> 0.388686).  Saving model ...
	 Train_Loss: 0.4888 Train_Acc: 79.323 Val_Loss: 0.3887  BEST VAL Loss: 0.3887  Val_Acc: 86.127

Epoch 14: Validation loss decreased (0.388686 --> 0.385637).  Saving model ...
	 Train_Loss: 0.4867 Train_Acc: 79.173 Val_Loss: 0.3856  BEST VAL Loss: 0.3856  Val_Acc: 87.423

Epoch 15: Validation loss decreased (0.385637 --> 0.384044).  Saving model ...
	 Train_Loss: 0.4847 Train_Acc: 79.287 Val_Loss: 0.3840  BEST VAL Loss: 0.3840  Val_Acc: 86.061

Epoch 16: Validation loss decreased (0.384044 --> 0.382929).  Saving model ...
	 Train_Loss: 0.4829 Train_Acc: 79.451 Val_Loss: 0.3829  BEST VAL Loss: 0.3829  Val_Acc: 86.101

Epoch 17: Validation loss decreased (0.382929 --> 0.380897).  Saving model ...
	 Train_Loss: 0.4813 Train_Acc: 79.316 Val_Loss: 0.3809  BEST VAL Loss: 0.3809  Val_Acc: 87.218

Epoch 18: Validation loss decreased (0.380897 --> 0.378532).  Saving model ...
	 Train_Loss: 0.4797 Train_Acc: 79.668 Val_Loss: 0.3785  BEST VAL Loss: 0.3785  Val_Acc: 87.686

Epoch 19: Validation loss decreased (0.378532 --> 0.376959).  Saving model ...
	 Train_Loss: 0.4782 Train_Acc: 79.662 Val_Loss: 0.3770  BEST VAL Loss: 0.3770  Val_Acc: 86.850

Epoch 20: Validation loss decreased (0.376959 --> 0.375295).  Saving model ...
	 Train_Loss: 0.4769 Train_Acc: 79.708 Val_Loss: 0.3753  BEST VAL Loss: 0.3753  Val_Acc: 87.397

Epoch 21: Validation loss decreased (0.375295 --> 0.374666).  Saving model ...
	 Train_Loss: 0.4755 Train_Acc: 79.900 Val_Loss: 0.3747  BEST VAL Loss: 0.3747  Val_Acc: 85.878

Epoch 22: Validation loss decreased (0.374666 --> 0.373172).  Saving model ...
	 Train_Loss: 0.4742 Train_Acc: 79.918 Val_Loss: 0.3732  BEST VAL Loss: 0.3732  Val_Acc: 87.537

Epoch 23: Validation loss decreased (0.373172 --> 0.372450).  Saving model ...
	 Train_Loss: 0.4729 Train_Acc: 80.090 Val_Loss: 0.3725  BEST VAL Loss: 0.3725  Val_Acc: 85.860

Epoch 24: Validation loss decreased (0.372450 --> 0.370815).  Saving model ...
	 Train_Loss: 0.4718 Train_Acc: 80.080 Val_Loss: 0.3708  BEST VAL Loss: 0.3708  Val_Acc: 87.721

Epoch 25: Validation loss decreased (0.370815 --> 0.369793).  Saving model ...
	 Train_Loss: 0.4707 Train_Acc: 80.162 Val_Loss: 0.3698  BEST VAL Loss: 0.3698  Val_Acc: 86.731

Epoch 26: Validation loss decreased (0.369793 --> 0.368860).  Saving model ...
	 Train_Loss: 0.4696 Train_Acc: 79.992 Val_Loss: 0.3689  BEST VAL Loss: 0.3689  Val_Acc: 86.600

Epoch 27: Validation loss decreased (0.368860 --> 0.367698).  Saving model ...
	 Train_Loss: 0.4687 Train_Acc: 80.123 Val_Loss: 0.3677  BEST VAL Loss: 0.3677  Val_Acc: 87.292

Epoch 28: Validation loss decreased (0.367698 --> 0.367520).  Saving model ...
	 Train_Loss: 0.4676 Train_Acc: 80.316 Val_Loss: 0.3675  BEST VAL Loss: 0.3675  Val_Acc: 85.676

Epoch 29: Validation loss decreased (0.367520 --> 0.366221).  Saving model ...
	 Train_Loss: 0.4667 Train_Acc: 80.230 Val_Loss: 0.3662  BEST VAL Loss: 0.3662  Val_Acc: 88.023

Epoch 30: Validation loss decreased (0.366221 --> 0.365429).  Saving model ...
	 Train_Loss: 0.4658 Train_Acc: 80.248 Val_Loss: 0.3654  BEST VAL Loss: 0.3654  Val_Acc: 87.314

Epoch 31: Validation loss decreased (0.365429 --> 0.364410).  Saving model ...
	 Train_Loss: 0.4651 Train_Acc: 80.193 Val_Loss: 0.3644  BEST VAL Loss: 0.3644  Val_Acc: 87.647

Epoch 32: Validation loss decreased (0.364410 --> 0.363284).  Saving model ...
	 Train_Loss: 0.4642 Train_Acc: 80.554 Val_Loss: 0.3633  BEST VAL Loss: 0.3633  Val_Acc: 87.909

Epoch 33: Validation loss decreased (0.363284 --> 0.363096).  Saving model ...
	 Train_Loss: 0.4635 Train_Acc: 80.438 Val_Loss: 0.3631  BEST VAL Loss: 0.3631  Val_Acc: 85.483

Epoch 34: Validation loss decreased (0.363096 --> 0.362164).  Saving model ...
	 Train_Loss: 0.4627 Train_Acc: 80.391 Val_Loss: 0.3622  BEST VAL Loss: 0.3622  Val_Acc: 87.717

Epoch 35: Validation loss decreased (0.362164 --> 0.361317).  Saving model ...
	 Train_Loss: 0.4619 Train_Acc: 80.443 Val_Loss: 0.3613  BEST VAL Loss: 0.3613  Val_Acc: 87.279

Epoch 36: Validation loss decreased (0.361317 --> 0.360200).  Saving model ...
	 Train_Loss: 0.4611 Train_Acc: 80.576 Val_Loss: 0.3602  BEST VAL Loss: 0.3602  Val_Acc: 87.936

Epoch 37: Validation loss decreased (0.360200 --> 0.359243).  Saving model ...
	 Train_Loss: 0.4604 Train_Acc: 80.546 Val_Loss: 0.3592  BEST VAL Loss: 0.3592  Val_Acc: 88.317

Epoch 38: Validation loss decreased (0.359243 --> 0.358923).  Saving model ...
	 Train_Loss: 0.4597 Train_Acc: 80.611 Val_Loss: 0.3589  BEST VAL Loss: 0.3589  Val_Acc: 86.723

Epoch 39: Validation loss decreased (0.358923 --> 0.358022).  Saving model ...
	 Train_Loss: 0.4590 Train_Acc: 80.741 Val_Loss: 0.3580  BEST VAL Loss: 0.3580  Val_Acc: 88.203

Epoch 40: Validation loss decreased (0.358022 --> 0.357229).  Saving model ...
	 Train_Loss: 0.4584 Train_Acc: 80.771 Val_Loss: 0.3572  BEST VAL Loss: 0.3572  Val_Acc: 88.015

Epoch 41: Validation loss decreased (0.357229 --> 0.356341).  Saving model ...
	 Train_Loss: 0.4577 Train_Acc: 80.879 Val_Loss: 0.3563  BEST VAL Loss: 0.3563  Val_Acc: 88.050

Epoch 42: Validation loss decreased (0.356341 --> 0.355424).  Saving model ...
	 Train_Loss: 0.4572 Train_Acc: 80.800 Val_Loss: 0.3554  BEST VAL Loss: 0.3554  Val_Acc: 88.457

Epoch 43: Validation loss decreased (0.355424 --> 0.354678).  Saving model ...
	 Train_Loss: 0.4566 Train_Acc: 80.757 Val_Loss: 0.3547  BEST VAL Loss: 0.3547  Val_Acc: 88.128

Epoch 44: Validation loss decreased (0.354678 --> 0.353836).  Saving model ...
	 Train_Loss: 0.4560 Train_Acc: 81.101 Val_Loss: 0.3538  BEST VAL Loss: 0.3538  Val_Acc: 88.382

Epoch 45: Validation loss decreased (0.353836 --> 0.353005).  Saving model ...
	 Train_Loss: 0.4554 Train_Acc: 80.837 Val_Loss: 0.3530  BEST VAL Loss: 0.3530  Val_Acc: 88.317

Epoch 46: Validation loss decreased (0.353005 --> 0.352295).  Saving model ...
	 Train_Loss: 0.4549 Train_Acc: 80.899 Val_Loss: 0.3523  BEST VAL Loss: 0.3523  Val_Acc: 87.988

Epoch 47: Validation loss decreased (0.352295 --> 0.351743).  Saving model ...
	 Train_Loss: 0.4543 Train_Acc: 80.894 Val_Loss: 0.3517  BEST VAL Loss: 0.3517  Val_Acc: 87.966

Epoch 48: Validation loss decreased (0.351743 --> 0.351054).  Saving model ...
	 Train_Loss: 0.4538 Train_Acc: 80.984 Val_Loss: 0.3511  BEST VAL Loss: 0.3511  Val_Acc: 88.216

Epoch 49: Validation loss decreased (0.351054 --> 0.350436).  Saving model ...
	 Train_Loss: 0.4532 Train_Acc: 81.082 Val_Loss: 0.3504  BEST VAL Loss: 0.3504  Val_Acc: 88.146

Epoch 50: Validation loss decreased (0.350436 --> 0.349916).  Saving model ...
	 Train_Loss: 0.4527 Train_Acc: 81.027 Val_Loss: 0.3499  BEST VAL Loss: 0.3499  Val_Acc: 87.717

Epoch 51: Validation loss decreased (0.349916 --> 0.349260).  Saving model ...
	 Train_Loss: 0.4522 Train_Acc: 81.025 Val_Loss: 0.3493  BEST VAL Loss: 0.3493  Val_Acc: 88.365

Epoch 52: Validation loss decreased (0.349260 --> 0.348982).  Saving model ...
	 Train_Loss: 0.4517 Train_Acc: 80.956 Val_Loss: 0.3490  BEST VAL Loss: 0.3490  Val_Acc: 87.130

Epoch 53: Validation loss decreased (0.348982 --> 0.348720).  Saving model ...
	 Train_Loss: 0.4513 Train_Acc: 81.092 Val_Loss: 0.3487  BEST VAL Loss: 0.3487  Val_Acc: 87.314

Epoch 54: Validation loss decreased (0.348720 --> 0.348152).  Saving model ...
	 Train_Loss: 0.4508 Train_Acc: 81.064 Val_Loss: 0.3482  BEST VAL Loss: 0.3482  Val_Acc: 88.115

Epoch 55: Validation loss decreased (0.348152 --> 0.347839).  Saving model ...
	 Train_Loss: 0.4504 Train_Acc: 81.097 Val_Loss: 0.3478  BEST VAL Loss: 0.3478  Val_Acc: 87.493

Epoch 56: Validation loss decreased (0.347839 --> 0.347089).  Saving model ...
	 Train_Loss: 0.4499 Train_Acc: 81.164 Val_Loss: 0.3471  BEST VAL Loss: 0.3471  Val_Acc: 88.965

Epoch 57: Validation loss decreased (0.347089 --> 0.346531).  Saving model ...
	 Train_Loss: 0.4495 Train_Acc: 81.242 Val_Loss: 0.3465  BEST VAL Loss: 0.3465  Val_Acc: 88.409

Epoch 58: Validation loss decreased (0.346531 --> 0.346127).  Saving model ...
	 Train_Loss: 0.4490 Train_Acc: 81.203 Val_Loss: 0.3461  BEST VAL Loss: 0.3461  Val_Acc: 87.879

Epoch 59: Validation loss decreased (0.346127 --> 0.345525).  Saving model ...
	 Train_Loss: 0.4486 Train_Acc: 81.355 Val_Loss: 0.3455  BEST VAL Loss: 0.3455  Val_Acc: 88.833

Epoch 60: Validation loss decreased (0.345525 --> 0.344949).  Saving model ...
	 Train_Loss: 0.4481 Train_Acc: 81.324 Val_Loss: 0.3449  BEST VAL Loss: 0.3449  Val_Acc: 88.952

Epoch 61: Validation loss decreased (0.344949 --> 0.344587).  Saving model ...
	 Train_Loss: 0.4477 Train_Acc: 81.234 Val_Loss: 0.3446  BEST VAL Loss: 0.3446  Val_Acc: 87.310

Epoch 62: Validation loss decreased (0.344587 --> 0.344058).  Saving model ...
	 Train_Loss: 0.4473 Train_Acc: 81.327 Val_Loss: 0.3441  BEST VAL Loss: 0.3441  Val_Acc: 88.417

Epoch 63: Validation loss decreased (0.344058 --> 0.343510).  Saving model ...
	 Train_Loss: 0.4470 Train_Acc: 81.183 Val_Loss: 0.3435  BEST VAL Loss: 0.3435  Val_Acc: 88.768

Epoch 64: Validation loss decreased (0.343510 --> 0.343075).  Saving model ...
	 Train_Loss: 0.4466 Train_Acc: 81.331 Val_Loss: 0.3431  BEST VAL Loss: 0.3431  Val_Acc: 88.304

Epoch 65: Validation loss decreased (0.343075 --> 0.342595).  Saving model ...
	 Train_Loss: 0.4462 Train_Acc: 81.307 Val_Loss: 0.3426  BEST VAL Loss: 0.3426  Val_Acc: 88.290

Epoch 66: Validation loss decreased (0.342595 --> 0.342231).  Saving model ...
	 Train_Loss: 0.4458 Train_Acc: 81.360 Val_Loss: 0.3422  BEST VAL Loss: 0.3422  Val_Acc: 88.058

Epoch 67: Validation loss decreased (0.342231 --> 0.341782).  Saving model ...
	 Train_Loss: 0.4454 Train_Acc: 81.413 Val_Loss: 0.3418  BEST VAL Loss: 0.3418  Val_Acc: 88.352

Epoch 68: Validation loss decreased (0.341782 --> 0.341477).  Saving model ...
	 Train_Loss: 0.4451 Train_Acc: 81.319 Val_Loss: 0.3415  BEST VAL Loss: 0.3415  Val_Acc: 87.888

Epoch 69: Validation loss decreased (0.341477 --> 0.341044).  Saving model ...
	 Train_Loss: 0.4447 Train_Acc: 81.531 Val_Loss: 0.3410  BEST VAL Loss: 0.3410  Val_Acc: 88.474

Epoch 70: Validation loss decreased (0.341044 --> 0.340754).  Saving model ...
	 Train_Loss: 0.4444 Train_Acc: 81.347 Val_Loss: 0.3408  BEST VAL Loss: 0.3408  Val_Acc: 87.861

Epoch 71: Validation loss decreased (0.340754 --> 0.340311).  Saving model ...
	 Train_Loss: 0.4441 Train_Acc: 81.481 Val_Loss: 0.3403  BEST VAL Loss: 0.3403  Val_Acc: 88.636

Epoch 72: Validation loss decreased (0.340311 --> 0.339969).  Saving model ...
	 Train_Loss: 0.4437 Train_Acc: 81.558 Val_Loss: 0.3400  BEST VAL Loss: 0.3400  Val_Acc: 88.076

Epoch 73: Validation loss decreased (0.339969 --> 0.339555).  Saving model ...
	 Train_Loss: 0.4434 Train_Acc: 81.538 Val_Loss: 0.3396  BEST VAL Loss: 0.3396  Val_Acc: 88.807

Epoch 74: Validation loss decreased (0.339555 --> 0.339258).  Saving model ...
	 Train_Loss: 0.4431 Train_Acc: 81.382 Val_Loss: 0.3393  BEST VAL Loss: 0.3393  Val_Acc: 88.080

Epoch 75: Validation loss decreased (0.339258 --> 0.338809).  Saving model ...
	 Train_Loss: 0.4428 Train_Acc: 81.471 Val_Loss: 0.3388  BEST VAL Loss: 0.3388  Val_Acc: 88.969

Epoch 76: Validation loss decreased (0.338809 --> 0.338385).  Saving model ...
	 Train_Loss: 0.4425 Train_Acc: 81.671 Val_Loss: 0.3384  BEST VAL Loss: 0.3384  Val_Acc: 88.864

Epoch 77: Validation loss decreased (0.338385 --> 0.338173).  Saving model ...
	 Train_Loss: 0.4422 Train_Acc: 81.581 Val_Loss: 0.3382  BEST VAL Loss: 0.3382  Val_Acc: 87.997

Epoch 78: Validation loss decreased (0.338173 --> 0.338047).  Saving model ...
	 Train_Loss: 0.4419 Train_Acc: 81.623 Val_Loss: 0.3380  BEST VAL Loss: 0.3380  Val_Acc: 87.577

Epoch 79: Validation loss decreased (0.338047 --> 0.337721).  Saving model ...
	 Train_Loss: 0.4416 Train_Acc: 81.563 Val_Loss: 0.3377  BEST VAL Loss: 0.3377  Val_Acc: 88.544

Epoch 80: Validation loss decreased (0.337721 --> 0.337307).  Saving model ...
	 Train_Loss: 0.4413 Train_Acc: 81.525 Val_Loss: 0.3373  BEST VAL Loss: 0.3373  Val_Acc: 88.956

Epoch 81: Validation loss decreased (0.337307 --> 0.336910).  Saving model ...
	 Train_Loss: 0.4410 Train_Acc: 81.662 Val_Loss: 0.3369  BEST VAL Loss: 0.3369  Val_Acc: 88.855

Epoch 82: Validation loss decreased (0.336910 --> 0.336610).  Saving model ...
	 Train_Loss: 0.4407 Train_Acc: 81.516 Val_Loss: 0.3366  BEST VAL Loss: 0.3366  Val_Acc: 88.803

Epoch 83: Validation loss decreased (0.336610 --> 0.336499).  Saving model ...
	 Train_Loss: 0.4405 Train_Acc: 81.550 Val_Loss: 0.3365  BEST VAL Loss: 0.3365  Val_Acc: 87.638

Epoch 84: Validation loss decreased (0.336499 --> 0.336244).  Saving model ...
	 Train_Loss: 0.4402 Train_Acc: 81.699 Val_Loss: 0.3362  BEST VAL Loss: 0.3362  Val_Acc: 88.527

Epoch 85: Validation loss decreased (0.336244 --> 0.336024).  Saving model ...
	 Train_Loss: 0.4399 Train_Acc: 81.603 Val_Loss: 0.3360  BEST VAL Loss: 0.3360  Val_Acc: 88.317

Epoch 86: Validation loss decreased (0.336024 --> 0.335732).  Saving model ...
	 Train_Loss: 0.4396 Train_Acc: 81.753 Val_Loss: 0.3357  BEST VAL Loss: 0.3357  Val_Acc: 88.492

Epoch 87: Validation loss decreased (0.335732 --> 0.335443).  Saving model ...
	 Train_Loss: 0.4394 Train_Acc: 81.585 Val_Loss: 0.3354  BEST VAL Loss: 0.3354  Val_Acc: 88.431

Epoch 88: Validation loss decreased (0.335443 --> 0.335093).  Saving model ...
	 Train_Loss: 0.4391 Train_Acc: 81.564 Val_Loss: 0.3351  BEST VAL Loss: 0.3351  Val_Acc: 89.035

Epoch 89: Validation loss decreased (0.335093 --> 0.334848).  Saving model ...
	 Train_Loss: 0.4389 Train_Acc: 81.543 Val_Loss: 0.3348  BEST VAL Loss: 0.3348  Val_Acc: 88.404

Epoch 90: Validation loss decreased (0.334848 --> 0.334563).  Saving model ...
	 Train_Loss: 0.4386 Train_Acc: 81.560 Val_Loss: 0.3346  BEST VAL Loss: 0.3346  Val_Acc: 88.479

Epoch 91: Validation loss decreased (0.334563 --> 0.334207).  Saving model ...
	 Train_Loss: 0.4384 Train_Acc: 81.838 Val_Loss: 0.3342  BEST VAL Loss: 0.3342  Val_Acc: 89.079

Epoch 92: Validation loss decreased (0.334207 --> 0.333922).  Saving model ...
	 Train_Loss: 0.4381 Train_Acc: 81.729 Val_Loss: 0.3339  BEST VAL Loss: 0.3339  Val_Acc: 88.895

Epoch 93: Validation loss decreased (0.333922 --> 0.333653).  Saving model ...
	 Train_Loss: 0.4379 Train_Acc: 81.978 Val_Loss: 0.3337  BEST VAL Loss: 0.3337  Val_Acc: 88.755

Epoch 94: Validation loss decreased (0.333653 --> 0.333484).  Saving model ...
	 Train_Loss: 0.4376 Train_Acc: 81.772 Val_Loss: 0.3335  BEST VAL Loss: 0.3335  Val_Acc: 87.905

Epoch 95: Validation loss decreased (0.333484 --> 0.333168).  Saving model ...
	 Train_Loss: 0.4374 Train_Acc: 81.751 Val_Loss: 0.3332  BEST VAL Loss: 0.3332  Val_Acc: 88.978

Epoch 96: Validation loss decreased (0.333168 --> 0.332913).  Saving model ...
	 Train_Loss: 0.4371 Train_Acc: 81.805 Val_Loss: 0.3329  BEST VAL Loss: 0.3329  Val_Acc: 88.693

Epoch 97: Validation loss decreased (0.332913 --> 0.332626).  Saving model ...
	 Train_Loss: 0.4369 Train_Acc: 81.691 Val_Loss: 0.3326  BEST VAL Loss: 0.3326  Val_Acc: 88.842

Epoch 98: Validation loss decreased (0.332626 --> 0.332377).  Saving model ...
	 Train_Loss: 0.4367 Train_Acc: 81.832 Val_Loss: 0.3324  BEST VAL Loss: 0.3324  Val_Acc: 88.658

Epoch 99: Validation loss decreased (0.332377 --> 0.332155).  Saving model ...
	 Train_Loss: 0.4365 Train_Acc: 81.719 Val_Loss: 0.3322  BEST VAL Loss: 0.3322  Val_Acc: 88.413

Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.85      0.95      0.90     85025
           1       0.95      0.86      0.90     97655

    accuracy                           0.90    182680
   macro avg       0.90      0.90      0.90    182680
weighted avg       0.90      0.90      0.90    182680

Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.84      0.93      0.88     10629
           1       0.93      0.84      0.89     12207

    accuracy                           0.88     22836
   macro avg       0.89      0.89      0.88     22836
weighted avg       0.89      0.88      0.88     22836

Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.84      0.93      0.88     10629
           1       0.93      0.84      0.88     12207

    accuracy                           0.88     22836
   macro avg       0.88      0.89      0.88     22836
weighted avg       0.89      0.88      0.88     22836

              precision    recall  f1-score   support

           0       0.84      0.93      0.88     10629
           1       0.93      0.84      0.88     12207

    accuracy                           0.88     22836
   macro avg       0.88      0.89      0.88     22836
weighted avg       0.89      0.88      0.88     22836

Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.74      0.86      0.80     36797
           1       0.87      0.75      0.81     44915

    accuracy                           0.80     81712
   macro avg       0.80      0.81      0.80     81712
weighted avg       0.81      0.80      0.80     81712

              precision    recall  f1-score   support

           0       0.74      0.86      0.80     36797
           1       0.87      0.75      0.81     44915

    accuracy                           0.80     81712
   macro avg       0.80      0.81      0.80     81712
weighted avg       0.81      0.80      0.80     81712

completed
