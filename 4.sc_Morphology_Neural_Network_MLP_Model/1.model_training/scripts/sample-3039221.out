[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '3404bf55'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '16d8e5a8'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '8a04e5c9'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'db6f1c36'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: DMSO_0.100_DMSO_0.025 treatment_name: Thapsigargin_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: DMSO_0.100_DMSO_0.025
TREATMENT_NAME: Thapsigargin_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'Thapsigargin_1.000_DMSO_0.025']
The dimensions of the data are: (49409, 1276)
Number of total missing values across all columns: 98818
Data Subset Is Off
Wells held out for testing: ['I14' 'K14']
Wells to use for training, validation, and testing ['B14' 'C14' 'D14' 'B15' 'C15' 'D15' 'J14' 'I15' 'J15' 'K15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.296064).  Saving model ...
	 Train_Loss: 0.3862 Train_Acc: 82.638 Val_Loss: 0.2961  BEST VAL Loss: 0.2961  Val_Acc: 88.481

Epoch 1: Validation loss decreased (0.296064 --> 0.278141).  Saving model ...
	 Train_Loss: 0.3404 Train_Acc: 87.089 Val_Loss: 0.2781  BEST VAL Loss: 0.2781  Val_Acc: 89.964

Epoch 2: Validation loss decreased (0.278141 --> 0.263205).  Saving model ...
	 Train_Loss: 0.3160 Train_Acc: 88.243 Val_Loss: 0.2632  BEST VAL Loss: 0.2632  Val_Acc: 90.377

Epoch 3: Validation loss decreased (0.263205 --> 0.254944).  Saving model ...
	 Train_Loss: 0.2976 Train_Acc: 89.252 Val_Loss: 0.2549  BEST VAL Loss: 0.2549  Val_Acc: 91.081

Epoch 4: Validation loss decreased (0.254944 --> 0.247585).  Saving model ...
	 Train_Loss: 0.2845 Train_Acc: 89.501 Val_Loss: 0.2476  BEST VAL Loss: 0.2476  Val_Acc: 90.936

Epoch 5: Validation loss decreased (0.247585 --> 0.242533).  Saving model ...
	 Train_Loss: 0.2743 Train_Acc: 89.677 Val_Loss: 0.2425  BEST VAL Loss: 0.2425  Val_Acc: 91.422

Epoch 6: Validation loss decreased (0.242533 --> 0.236050).  Saving model ...
	 Train_Loss: 0.2662 Train_Acc: 90.218 Val_Loss: 0.2361  BEST VAL Loss: 0.2361  Val_Acc: 92.053

Epoch 7: Validation loss decreased (0.236050 --> 0.233415).  Saving model ...
	 Train_Loss: 0.2587 Train_Acc: 90.461 Val_Loss: 0.2334  BEST VAL Loss: 0.2334  Val_Acc: 92.224

Epoch 8: Validation loss decreased (0.233415 --> 0.229635).  Saving model ...
	 Train_Loss: 0.2524 Train_Acc: 90.516 Val_Loss: 0.2296  BEST VAL Loss: 0.2296  Val_Acc: 92.637

Epoch 9: Validation loss decreased (0.229635 --> 0.225095).  Saving model ...
	 Train_Loss: 0.2467 Train_Acc: 90.938 Val_Loss: 0.2251  BEST VAL Loss: 0.2251  Val_Acc: 92.418

Epoch 10: Validation loss decreased (0.225095 --> 0.223974).  Saving model ...
	 Train_Loss: 0.2419 Train_Acc: 90.756 Val_Loss: 0.2240  BEST VAL Loss: 0.2240  Val_Acc: 92.345

Epoch 11: Validation loss decreased (0.223974 --> 0.221855).  Saving model ...
	 Train_Loss: 0.2375 Train_Acc: 91.053 Val_Loss: 0.2219  BEST VAL Loss: 0.2219  Val_Acc: 92.102

Epoch 12: Validation loss decreased (0.221855 --> 0.220101).  Saving model ...
	 Train_Loss: 0.2336 Train_Acc: 91.062 Val_Loss: 0.2201  BEST VAL Loss: 0.2201  Val_Acc: 92.248

Epoch 13: Validation loss decreased (0.220101 --> 0.218420).  Saving model ...
	 Train_Loss: 0.2301 Train_Acc: 90.698 Val_Loss: 0.2184  BEST VAL Loss: 0.2184  Val_Acc: 92.588

Epoch 14: Validation loss decreased (0.218420 --> 0.217396).  Saving model ...
	 Train_Loss: 0.2269 Train_Acc: 91.175 Val_Loss: 0.2174  BEST VAL Loss: 0.2174  Val_Acc: 92.467

Epoch 15: Validation loss decreased (0.217396 --> 0.216564).  Saving model ...
	 Train_Loss: 0.2240 Train_Acc: 91.199 Val_Loss: 0.2166  BEST VAL Loss: 0.2166  Val_Acc: 92.855

Epoch 16: Validation loss decreased (0.216564 --> 0.215454).  Saving model ...
	 Train_Loss: 0.2212 Train_Acc: 91.257 Val_Loss: 0.2155  BEST VAL Loss: 0.2155  Val_Acc: 92.151

Epoch 17: Validation loss decreased (0.215454 --> 0.214442).  Saving model ...
	 Train_Loss: 0.2186 Train_Acc: 91.357 Val_Loss: 0.2144  BEST VAL Loss: 0.2144  Val_Acc: 92.369

Epoch 18: Validation loss decreased (0.214442 --> 0.213730).  Saving model ...
	 Train_Loss: 0.2161 Train_Acc: 91.472 Val_Loss: 0.2137  BEST VAL Loss: 0.2137  Val_Acc: 92.637

Epoch 19: Validation loss decreased (0.213730 --> 0.213301).  Saving model ...
	 Train_Loss: 0.2136 Train_Acc: 91.627 Val_Loss: 0.2133  BEST VAL Loss: 0.2133  Val_Acc: 92.928

Epoch 20: Validation loss decreased (0.213301 --> 0.212809).  Saving model ...
	 Train_Loss: 0.2114 Train_Acc: 91.694 Val_Loss: 0.2128  BEST VAL Loss: 0.2128  Val_Acc: 92.296

Epoch 21: Validation loss decreased (0.212809 --> 0.211581).  Saving model ...
	 Train_Loss: 0.2094 Train_Acc: 91.482 Val_Loss: 0.2116  BEST VAL Loss: 0.2116  Val_Acc: 92.880

Epoch 22: Validation loss decreased (0.211581 --> 0.210825).  Saving model ...
	 Train_Loss: 0.2075 Train_Acc: 91.545 Val_Loss: 0.2108  BEST VAL Loss: 0.2108  Val_Acc: 92.515

Epoch 23: Validation loss decreased (0.210825 --> 0.210240).  Saving model ...
	 Train_Loss: 0.2056 Train_Acc: 91.828 Val_Loss: 0.2102  BEST VAL Loss: 0.2102  Val_Acc: 92.418

Epoch 24: Validation loss decreased (0.210240 --> 0.209831).  Saving model ...
	 Train_Loss: 0.2038 Train_Acc: 91.737 Val_Loss: 0.2098  BEST VAL Loss: 0.2098  Val_Acc: 92.977

Epoch 25: Validation loss decreased (0.209831 --> 0.209104).  Saving model ...
	 Train_Loss: 0.2020 Train_Acc: 91.928 Val_Loss: 0.2091  BEST VAL Loss: 0.2091  Val_Acc: 92.515

Epoch 26: Validation loss did not decrease
	 Train_Loss: 0.2005 Train_Acc: 91.658 Val_Loss: 0.2095  BEST VAL Loss: 0.2091  Val_Acc: 92.588

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.1991 Train_Acc: 91.658 Val_Loss: 0.2102  BEST VAL Loss: 0.2091  Val_Acc: 92.831

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.1977 Train_Acc: 91.749 Val_Loss: 0.2102  BEST VAL Loss: 0.2091  Val_Acc: 92.783

Epoch 29: Validation loss did not decrease
	 Train_Loss: 0.1963 Train_Acc: 91.898 Val_Loss: 0.2097  BEST VAL Loss: 0.2091  Val_Acc: 92.734

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.1950 Train_Acc: 91.901 Val_Loss: 0.2099  BEST VAL Loss: 0.2091  Val_Acc: 92.564

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.1938 Train_Acc: 91.959 Val_Loss: 0.2097  BEST VAL Loss: 0.2091  Val_Acc: 92.880

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.1926 Train_Acc: 91.886 Val_Loss: 0.2093  BEST VAL Loss: 0.2091  Val_Acc: 93.098

Epoch 33: Validation loss decreased (0.209104 --> 0.209103).  Saving model ...
	 Train_Loss: 0.1915 Train_Acc: 91.810 Val_Loss: 0.2091  BEST VAL Loss: 0.2091  Val_Acc: 92.807

Epoch 34: Validation loss decreased (0.209103 --> 0.208871).  Saving model ...
	 Train_Loss: 0.1904 Train_Acc: 91.913 Val_Loss: 0.2089  BEST VAL Loss: 0.2089  Val_Acc: 92.783

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.1892 Train_Acc: 92.177 Val_Loss: 0.2090  BEST VAL Loss: 0.2089  Val_Acc: 92.855

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.1882 Train_Acc: 91.788 Val_Loss: 0.2092  BEST VAL Loss: 0.2089  Val_Acc: 92.734

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.1872 Train_Acc: 91.980 Val_Loss: 0.2091  BEST VAL Loss: 0.2089  Val_Acc: 92.710

Epoch 38: Validation loss decreased (0.208871 --> 0.208829).  Saving model ...
	 Train_Loss: 0.1861 Train_Acc: 92.077 Val_Loss: 0.2088  BEST VAL Loss: 0.2088  Val_Acc: 93.147

Epoch 39: Validation loss decreased (0.208829 --> 0.208659).  Saving model ...
	 Train_Loss: 0.1852 Train_Acc: 92.141 Val_Loss: 0.2087  BEST VAL Loss: 0.2087  Val_Acc: 92.904

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.1842 Train_Acc: 92.323 Val_Loss: 0.2087  BEST VAL Loss: 0.2087  Val_Acc: 92.758

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.1833 Train_Acc: 92.022 Val_Loss: 0.2092  BEST VAL Loss: 0.2087  Val_Acc: 92.783

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.1825 Train_Acc: 92.010 Val_Loss: 0.2097  BEST VAL Loss: 0.2087  Val_Acc: 92.953

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.1816 Train_Acc: 92.317 Val_Loss: 0.2102  BEST VAL Loss: 0.2087  Val_Acc: 92.977

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.1808 Train_Acc: 92.256 Val_Loss: 0.2105  BEST VAL Loss: 0.2087  Val_Acc: 92.807

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.1800 Train_Acc: 92.387 Val_Loss: 0.2104  BEST VAL Loss: 0.2087  Val_Acc: 92.855

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.1791 Train_Acc: 92.287 Val_Loss: 0.2106  BEST VAL Loss: 0.2087  Val_Acc: 92.588

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.1784 Train_Acc: 92.287 Val_Loss: 0.2103  BEST VAL Loss: 0.2087  Val_Acc: 93.098

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.1777 Train_Acc: 92.047 Val_Loss: 0.2103  BEST VAL Loss: 0.2087  Val_Acc: 93.123

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.1770 Train_Acc: 92.247 Val_Loss: 0.2103  BEST VAL Loss: 0.2087  Val_Acc: 91.786

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.1762 Train_Acc: 92.253 Val_Loss: 0.2105  BEST VAL Loss: 0.2087  Val_Acc: 91.373

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.1755 Train_Acc: 92.341 Val_Loss: 0.2104  BEST VAL Loss: 0.2087  Val_Acc: 93.196

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.1747 Train_Acc: 92.399 Val_Loss: 0.2105  BEST VAL Loss: 0.2087  Val_Acc: 92.491

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.1741 Train_Acc: 92.107 Val_Loss: 0.2107  BEST VAL Loss: 0.2087  Val_Acc: 91.203

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.1735 Train_Acc: 92.262 Val_Loss: 0.2107  BEST VAL Loss: 0.2087  Val_Acc: 91.057

Epoch 55: Validation loss did not decrease
Early stopped at epoch : 55
DMSO_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.75      0.78      0.76     24644
           1       0.25      0.23      0.24      8273

    accuracy                           0.64     32917
   macro avg       0.50      0.50      0.50     32917
weighted avg       0.62      0.64      0.63     32917

DMSO_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.75      0.77      0.76      3081
           1       0.24      0.22      0.23      1034

    accuracy                           0.63      4115
   macro avg       0.50      0.50      0.50      4115
weighted avg       0.62      0.63      0.63      4115

DMSO_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.75      0.79      0.77      3081
           1       0.27      0.24      0.25      1034

    accuracy                           0.65      4115
   macro avg       0.51      0.51      0.51      4115
weighted avg       0.63      0.65      0.64      4115

              precision    recall  f1-score   support

           0       0.75      0.79      0.77      3081
           1       0.27      0.24      0.25      1034

    accuracy                           0.65      4115
   macro avg       0.51      0.51      0.51      4115
weighted avg       0.63      0.65      0.64      4115

DMSO_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.58      0.66      0.62      4837
           1       0.41      0.33      0.37      3425

    accuracy                           0.53      8262
   macro avg       0.50      0.50      0.49      8262
weighted avg       0.51      0.53      0.52      8262

              precision    recall  f1-score   support

           0       0.58      0.66      0.62      4837
           1       0.41      0.33      0.37      3425

    accuracy                           0.53      8262
   macro avg       0.50      0.50      0.49      8262
weighted avg       0.51      0.53      0.52      8262

completed
