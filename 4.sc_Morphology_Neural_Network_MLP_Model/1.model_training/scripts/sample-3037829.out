[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '8fef637f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '5a66440a'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'acdbca28'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'f4e14164'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_10.000_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (252405, 1270)
Number of total missing values across all columns: 504810
Data Subset Is Off
Wells held out for testing: ['E09' 'L10']
Wells to use for training, validation, and testing ['E02' 'E03' 'E08' 'L05' 'L11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.599602).  Saving model ...
	 Train_Loss: 0.6327 Train_Acc: 65.085 Val_Loss: 0.5996  BEST VAL Loss: 0.5996  Val_Acc: 67.394

Epoch 1: Validation loss decreased (0.599602 --> 0.579332).  Saving model ...
	 Train_Loss: 0.6120 Train_Acc: 67.777 Val_Loss: 0.5793  BEST VAL Loss: 0.5793  Val_Acc: 70.278

Epoch 2: Validation loss decreased (0.579332 --> 0.564803).  Saving model ...
	 Train_Loss: 0.5967 Train_Acc: 69.901 Val_Loss: 0.5648  BEST VAL Loss: 0.5648  Val_Acc: 72.505

Epoch 3: Validation loss decreased (0.564803 --> 0.552951).  Saving model ...
	 Train_Loss: 0.5846 Train_Acc: 71.525 Val_Loss: 0.5530  BEST VAL Loss: 0.5530  Val_Acc: 73.616

Epoch 4: Validation loss decreased (0.552951 --> 0.545383).  Saving model ...
	 Train_Loss: 0.5749 Train_Acc: 72.423 Val_Loss: 0.5454  BEST VAL Loss: 0.5454  Val_Acc: 73.621

Epoch 5: Validation loss decreased (0.545383 --> 0.536700).  Saving model ...
	 Train_Loss: 0.5664 Train_Acc: 73.228 Val_Loss: 0.5367  BEST VAL Loss: 0.5367  Val_Acc: 75.108

Epoch 6: Validation loss decreased (0.536700 --> 0.529452).  Saving model ...
	 Train_Loss: 0.5592 Train_Acc: 73.856 Val_Loss: 0.5295  BEST VAL Loss: 0.5295  Val_Acc: 75.439

Epoch 7: Validation loss decreased (0.529452 --> 0.524062).  Saving model ...
	 Train_Loss: 0.5531 Train_Acc: 74.254 Val_Loss: 0.5241  BEST VAL Loss: 0.5241  Val_Acc: 75.394

Epoch 8: Validation loss decreased (0.524062 --> 0.518155).  Saving model ...
	 Train_Loss: 0.5476 Train_Acc: 74.679 Val_Loss: 0.5182  BEST VAL Loss: 0.5182  Val_Acc: 76.252

Epoch 9: Validation loss decreased (0.518155 --> 0.513180).  Saving model ...
	 Train_Loss: 0.5425 Train_Acc: 75.153 Val_Loss: 0.5132  BEST VAL Loss: 0.5132  Val_Acc: 76.589

Epoch 10: Validation loss decreased (0.513180 --> 0.508681).  Saving model ...
	 Train_Loss: 0.5384 Train_Acc: 75.225 Val_Loss: 0.5087  BEST VAL Loss: 0.5087  Val_Acc: 77.055

Epoch 11: Validation loss decreased (0.508681 --> 0.505011).  Saving model ...
	 Train_Loss: 0.5344 Train_Acc: 75.534 Val_Loss: 0.5050  BEST VAL Loss: 0.5050  Val_Acc: 76.802

Epoch 12: Validation loss decreased (0.505011 --> 0.502158).  Saving model ...
	 Train_Loss: 0.5308 Train_Acc: 75.709 Val_Loss: 0.5022  BEST VAL Loss: 0.5022  Val_Acc: 76.875

Epoch 13: Validation loss decreased (0.502158 --> 0.499181).  Saving model ...
	 Train_Loss: 0.5274 Train_Acc: 75.956 Val_Loss: 0.4992  BEST VAL Loss: 0.4992  Val_Acc: 77.032

Epoch 14: Validation loss decreased (0.499181 --> 0.496730).  Saving model ...
	 Train_Loss: 0.5245 Train_Acc: 76.082 Val_Loss: 0.4967  BEST VAL Loss: 0.4967  Val_Acc: 77.229

Epoch 15: Validation loss decreased (0.496730 --> 0.495117).  Saving model ...
	 Train_Loss: 0.5218 Train_Acc: 76.082 Val_Loss: 0.4951  BEST VAL Loss: 0.4951  Val_Acc: 76.813

Epoch 16: Validation loss decreased (0.495117 --> 0.492476).  Saving model ...
	 Train_Loss: 0.5191 Train_Acc: 76.439 Val_Loss: 0.4925  BEST VAL Loss: 0.4925  Val_Acc: 77.554

Epoch 17: Validation loss decreased (0.492476 --> 0.490039).  Saving model ...
	 Train_Loss: 0.5168 Train_Acc: 76.466 Val_Loss: 0.4900  BEST VAL Loss: 0.4900  Val_Acc: 78.059

Epoch 18: Validation loss decreased (0.490039 --> 0.487791).  Saving model ...
	 Train_Loss: 0.5145 Train_Acc: 76.732 Val_Loss: 0.4878  BEST VAL Loss: 0.4878  Val_Acc: 77.778

Epoch 19: Validation loss decreased (0.487791 --> 0.485562).  Saving model ...
	 Train_Loss: 0.5124 Train_Acc: 76.651 Val_Loss: 0.4856  BEST VAL Loss: 0.4856  Val_Acc: 77.902

Epoch 20: Validation loss decreased (0.485562 --> 0.483796).  Saving model ...
	 Train_Loss: 0.5104 Train_Acc: 76.822 Val_Loss: 0.4838  BEST VAL Loss: 0.4838  Val_Acc: 78.042

Epoch 21: Validation loss decreased (0.483796 --> 0.482018).  Saving model ...
	 Train_Loss: 0.5086 Train_Acc: 76.876 Val_Loss: 0.4820  BEST VAL Loss: 0.4820  Val_Acc: 78.261

Epoch 22: Validation loss decreased (0.482018 --> 0.480183).  Saving model ...
	 Train_Loss: 0.5068 Train_Acc: 76.833 Val_Loss: 0.4802  BEST VAL Loss: 0.4802  Val_Acc: 78.311

Epoch 23: Validation loss decreased (0.480183 --> 0.478673).  Saving model ...
	 Train_Loss: 0.5053 Train_Acc: 76.957 Val_Loss: 0.4787  BEST VAL Loss: 0.4787  Val_Acc: 78.098

Epoch 24: Validation loss decreased (0.478673 --> 0.477055).  Saving model ...
	 Train_Loss: 0.5037 Train_Acc: 77.089 Val_Loss: 0.4771  BEST VAL Loss: 0.4771  Val_Acc: 78.457

Epoch 25: Validation loss decreased (0.477055 --> 0.475983).  Saving model ...
	 Train_Loss: 0.5022 Train_Acc: 77.097 Val_Loss: 0.4760  BEST VAL Loss: 0.4760  Val_Acc: 77.806

Epoch 26: Validation loss decreased (0.475983 --> 0.474694).  Saving model ...
	 Train_Loss: 0.5008 Train_Acc: 77.216 Val_Loss: 0.4747  BEST VAL Loss: 0.4747  Val_Acc: 78.446

Epoch 27: Validation loss decreased (0.474694 --> 0.473412).  Saving model ...
	 Train_Loss: 0.4994 Train_Acc: 77.283 Val_Loss: 0.4734  BEST VAL Loss: 0.4734  Val_Acc: 78.295

Epoch 28: Validation loss decreased (0.473412 --> 0.472108).  Saving model ...
	 Train_Loss: 0.4982 Train_Acc: 77.261 Val_Loss: 0.4721  BEST VAL Loss: 0.4721  Val_Acc: 78.727

Epoch 29: Validation loss decreased (0.472108 --> 0.470900).  Saving model ...
	 Train_Loss: 0.4969 Train_Acc: 77.317 Val_Loss: 0.4709  BEST VAL Loss: 0.4709  Val_Acc: 78.715

Epoch 30: Validation loss decreased (0.470900 --> 0.469786).  Saving model ...
	 Train_Loss: 0.4958 Train_Acc: 77.293 Val_Loss: 0.4698  BEST VAL Loss: 0.4698  Val_Acc: 78.569

Epoch 31: Validation loss decreased (0.469786 --> 0.468951).  Saving model ...
	 Train_Loss: 0.4947 Train_Acc: 77.425 Val_Loss: 0.4690  BEST VAL Loss: 0.4690  Val_Acc: 78.109

Epoch 32: Validation loss decreased (0.468951 --> 0.467861).  Saving model ...
	 Train_Loss: 0.4936 Train_Acc: 77.449 Val_Loss: 0.4679  BEST VAL Loss: 0.4679  Val_Acc: 79.058

Epoch 33: Validation loss decreased (0.467861 --> 0.466802).  Saving model ...
	 Train_Loss: 0.4926 Train_Acc: 77.361 Val_Loss: 0.4668  BEST VAL Loss: 0.4668  Val_Acc: 78.665

Epoch 34: Validation loss decreased (0.466802 --> 0.465766).  Saving model ...
	 Train_Loss: 0.4916 Train_Acc: 77.432 Val_Loss: 0.4658  BEST VAL Loss: 0.4658  Val_Acc: 78.648

Epoch 35: Validation loss decreased (0.465766 --> 0.464982).  Saving model ...
	 Train_Loss: 0.4907 Train_Acc: 77.567 Val_Loss: 0.4650  BEST VAL Loss: 0.4650  Val_Acc: 78.480

Epoch 36: Validation loss decreased (0.464982 --> 0.464087).  Saving model ...
	 Train_Loss: 0.4898 Train_Acc: 77.539 Val_Loss: 0.4641  BEST VAL Loss: 0.4641  Val_Acc: 78.850

Epoch 37: Validation loss decreased (0.464087 --> 0.463277).  Saving model ...
	 Train_Loss: 0.4889 Train_Acc: 77.628 Val_Loss: 0.4633  BEST VAL Loss: 0.4633  Val_Acc: 78.665

Epoch 38: Validation loss decreased (0.463277 --> 0.462801).  Saving model ...
	 Train_Loss: 0.4880 Train_Acc: 77.567 Val_Loss: 0.4628  BEST VAL Loss: 0.4628  Val_Acc: 78.401

Epoch 39: Validation loss decreased (0.462801 --> 0.462103).  Saving model ...
	 Train_Loss: 0.4872 Train_Acc: 77.619 Val_Loss: 0.4621  BEST VAL Loss: 0.4621  Val_Acc: 78.721

Epoch 40: Validation loss decreased (0.462103 --> 0.461458).  Saving model ...
	 Train_Loss: 0.4864 Train_Acc: 77.693 Val_Loss: 0.4615  BEST VAL Loss: 0.4615  Val_Acc: 78.328

Epoch 41: Validation loss decreased (0.461458 --> 0.460755).  Saving model ...
	 Train_Loss: 0.4856 Train_Acc: 77.726 Val_Loss: 0.4608  BEST VAL Loss: 0.4608  Val_Acc: 78.951

Epoch 42: Validation loss decreased (0.460755 --> 0.460087).  Saving model ...
	 Train_Loss: 0.4849 Train_Acc: 77.753 Val_Loss: 0.4601  BEST VAL Loss: 0.4601  Val_Acc: 78.833

Epoch 43: Validation loss decreased (0.460087 --> 0.459418).  Saving model ...
	 Train_Loss: 0.4842 Train_Acc: 77.741 Val_Loss: 0.4594  BEST VAL Loss: 0.4594  Val_Acc: 78.872

Epoch 44: Validation loss decreased (0.459418 --> 0.458777).  Saving model ...
	 Train_Loss: 0.4835 Train_Acc: 77.769 Val_Loss: 0.4588  BEST VAL Loss: 0.4588  Val_Acc: 78.738

Epoch 45: Validation loss decreased (0.458777 --> 0.458061).  Saving model ...
	 Train_Loss: 0.4829 Train_Acc: 77.721 Val_Loss: 0.4581  BEST VAL Loss: 0.4581  Val_Acc: 79.181

Epoch 46: Validation loss decreased (0.458061 --> 0.457376).  Saving model ...
	 Train_Loss: 0.4822 Train_Acc: 77.860 Val_Loss: 0.4574  BEST VAL Loss: 0.4574  Val_Acc: 79.046

Epoch 47: Validation loss decreased (0.457376 --> 0.456899).  Saving model ...
	 Train_Loss: 0.4816 Train_Acc: 77.841 Val_Loss: 0.4569  BEST VAL Loss: 0.4569  Val_Acc: 78.586

Epoch 48: Validation loss decreased (0.456899 --> 0.456412).  Saving model ...
	 Train_Loss: 0.4810 Train_Acc: 77.826 Val_Loss: 0.4564  BEST VAL Loss: 0.4564  Val_Acc: 78.682

Epoch 49: Validation loss decreased (0.456412 --> 0.455830).  Saving model ...
	 Train_Loss: 0.4804 Train_Acc: 77.779 Val_Loss: 0.4558  BEST VAL Loss: 0.4558  Val_Acc: 78.962

Epoch 50: Validation loss decreased (0.455830 --> 0.455252).  Saving model ...
	 Train_Loss: 0.4798 Train_Acc: 77.800 Val_Loss: 0.4553  BEST VAL Loss: 0.4553  Val_Acc: 78.917

Epoch 51: Validation loss decreased (0.455252 --> 0.454698).  Saving model ...
	 Train_Loss: 0.4793 Train_Acc: 77.886 Val_Loss: 0.4547  BEST VAL Loss: 0.4547  Val_Acc: 78.990

Epoch 52: Validation loss decreased (0.454698 --> 0.454131).  Saving model ...
	 Train_Loss: 0.4787 Train_Acc: 77.973 Val_Loss: 0.4541  BEST VAL Loss: 0.4541  Val_Acc: 79.226

Epoch 53: Validation loss decreased (0.454131 --> 0.453589).  Saving model ...
	 Train_Loss: 0.4782 Train_Acc: 77.889 Val_Loss: 0.4536  BEST VAL Loss: 0.4536  Val_Acc: 79.299

Epoch 54: Validation loss decreased (0.453589 --> 0.453139).  Saving model ...
	 Train_Loss: 0.4776 Train_Acc: 77.986 Val_Loss: 0.4531  BEST VAL Loss: 0.4531  Val_Acc: 78.603

Epoch 55: Validation loss decreased (0.453139 --> 0.452996).  Saving model ...
	 Train_Loss: 0.4771 Train_Acc: 78.053 Val_Loss: 0.4530  BEST VAL Loss: 0.4530  Val_Acc: 77.352

Epoch 56: Validation loss decreased (0.452996 --> 0.452507).  Saving model ...
	 Train_Loss: 0.4767 Train_Acc: 77.994 Val_Loss: 0.4525  BEST VAL Loss: 0.4525  Val_Acc: 78.979

Epoch 57: Validation loss decreased (0.452507 --> 0.452070).  Saving model ...
	 Train_Loss: 0.4762 Train_Acc: 78.097 Val_Loss: 0.4521  BEST VAL Loss: 0.4521  Val_Acc: 78.900

Epoch 58: Validation loss decreased (0.452070 --> 0.451556).  Saving model ...
	 Train_Loss: 0.4757 Train_Acc: 78.083 Val_Loss: 0.4516  BEST VAL Loss: 0.4516  Val_Acc: 79.332

Epoch 59: Validation loss decreased (0.451556 --> 0.451126).  Saving model ...
	 Train_Loss: 0.4752 Train_Acc: 78.142 Val_Loss: 0.4511  BEST VAL Loss: 0.4511  Val_Acc: 79.091

Epoch 60: Validation loss decreased (0.451126 --> 0.450695).  Saving model ...
	 Train_Loss: 0.4748 Train_Acc: 77.995 Val_Loss: 0.4507  BEST VAL Loss: 0.4507  Val_Acc: 79.069

Epoch 61: Validation loss decreased (0.450695 --> 0.450255).  Saving model ...
	 Train_Loss: 0.4743 Train_Acc: 78.109 Val_Loss: 0.4503  BEST VAL Loss: 0.4503  Val_Acc: 79.293

Epoch 62: Validation loss decreased (0.450255 --> 0.449814).  Saving model ...
	 Train_Loss: 0.4739 Train_Acc: 78.175 Val_Loss: 0.4498  BEST VAL Loss: 0.4498  Val_Acc: 79.248

Epoch 63: Validation loss decreased (0.449814 --> 0.449364).  Saving model ...
	 Train_Loss: 0.4735 Train_Acc: 78.068 Val_Loss: 0.4494  BEST VAL Loss: 0.4494  Val_Acc: 79.422

Epoch 64: Validation loss decreased (0.449364 --> 0.449002).  Saving model ...
	 Train_Loss: 0.4731 Train_Acc: 77.985 Val_Loss: 0.4490  BEST VAL Loss: 0.4490  Val_Acc: 79.243

Epoch 65: Validation loss decreased (0.449002 --> 0.448634).  Saving model ...
	 Train_Loss: 0.4727 Train_Acc: 78.048 Val_Loss: 0.4486  BEST VAL Loss: 0.4486  Val_Acc: 79.080

Epoch 66: Validation loss decreased (0.448634 --> 0.448321).  Saving model ...
	 Train_Loss: 0.4723 Train_Acc: 78.132 Val_Loss: 0.4483  BEST VAL Loss: 0.4483  Val_Acc: 78.861

Epoch 67: Validation loss decreased (0.448321 --> 0.447912).  Saving model ...
	 Train_Loss: 0.4719 Train_Acc: 78.175 Val_Loss: 0.4479  BEST VAL Loss: 0.4479  Val_Acc: 79.467

Epoch 68: Validation loss decreased (0.447912 --> 0.447584).  Saving model ...
	 Train_Loss: 0.4715 Train_Acc: 78.224 Val_Loss: 0.4476  BEST VAL Loss: 0.4476  Val_Acc: 79.046

Epoch 69: Validation loss decreased (0.447584 --> 0.447193).  Saving model ...
	 Train_Loss: 0.4711 Train_Acc: 78.208 Val_Loss: 0.4472  BEST VAL Loss: 0.4472  Val_Acc: 79.456

Epoch 70: Validation loss decreased (0.447193 --> 0.446852).  Saving model ...
	 Train_Loss: 0.4708 Train_Acc: 78.084 Val_Loss: 0.4469  BEST VAL Loss: 0.4469  Val_Acc: 79.175

Epoch 71: Validation loss decreased (0.446852 --> 0.446570).  Saving model ...
	 Train_Loss: 0.4705 Train_Acc: 78.133 Val_Loss: 0.4466  BEST VAL Loss: 0.4466  Val_Acc: 79.013

Epoch 72: Validation loss decreased (0.446570 --> 0.446238).  Saving model ...
	 Train_Loss: 0.4701 Train_Acc: 78.193 Val_Loss: 0.4462  BEST VAL Loss: 0.4462  Val_Acc: 79.473

Epoch 73: Validation loss decreased (0.446238 --> 0.445921).  Saving model ...
	 Train_Loss: 0.4698 Train_Acc: 78.172 Val_Loss: 0.4459  BEST VAL Loss: 0.4459  Val_Acc: 79.215

Epoch 74: Validation loss decreased (0.445921 --> 0.445586).  Saving model ...
	 Train_Loss: 0.4694 Train_Acc: 78.036 Val_Loss: 0.4456  BEST VAL Loss: 0.4456  Val_Acc: 79.215

Epoch 75: Validation loss decreased (0.445586 --> 0.445250).  Saving model ...
	 Train_Loss: 0.4691 Train_Acc: 78.273 Val_Loss: 0.4453  BEST VAL Loss: 0.4453  Val_Acc: 79.630

Epoch 76: Validation loss decreased (0.445250 --> 0.444970).  Saving model ...
	 Train_Loss: 0.4688 Train_Acc: 78.188 Val_Loss: 0.4450  BEST VAL Loss: 0.4450  Val_Acc: 79.029

Epoch 77: Validation loss decreased (0.444970 --> 0.444654).  Saving model ...
	 Train_Loss: 0.4685 Train_Acc: 78.279 Val_Loss: 0.4447  BEST VAL Loss: 0.4447  Val_Acc: 79.338

Epoch 78: Validation loss decreased (0.444654 --> 0.444390).  Saving model ...
	 Train_Loss: 0.4682 Train_Acc: 78.246 Val_Loss: 0.4444  BEST VAL Loss: 0.4444  Val_Acc: 79.271

Epoch 79: Validation loss decreased (0.444390 --> 0.444099).  Saving model ...
	 Train_Loss: 0.4679 Train_Acc: 78.189 Val_Loss: 0.4441  BEST VAL Loss: 0.4441  Val_Acc: 79.237

Epoch 80: Validation loss decreased (0.444099 --> 0.443807).  Saving model ...
	 Train_Loss: 0.4676 Train_Acc: 78.211 Val_Loss: 0.4438  BEST VAL Loss: 0.4438  Val_Acc: 79.512

Epoch 81: Validation loss decreased (0.443807 --> 0.443517).  Saving model ...
	 Train_Loss: 0.4673 Train_Acc: 78.163 Val_Loss: 0.4435  BEST VAL Loss: 0.4435  Val_Acc: 79.226

Epoch 82: Validation loss decreased (0.443517 --> 0.443336).  Saving model ...
	 Train_Loss: 0.4670 Train_Acc: 78.165 Val_Loss: 0.4433  BEST VAL Loss: 0.4433  Val_Acc: 78.642

Epoch 83: Validation loss decreased (0.443336 --> 0.443067).  Saving model ...
	 Train_Loss: 0.4667 Train_Acc: 78.231 Val_Loss: 0.4431  BEST VAL Loss: 0.4431  Val_Acc: 79.158

Epoch 84: Validation loss decreased (0.443067 --> 0.442835).  Saving model ...
	 Train_Loss: 0.4664 Train_Acc: 78.280 Val_Loss: 0.4428  BEST VAL Loss: 0.4428  Val_Acc: 79.422

Epoch 85: Validation loss decreased (0.442835 --> 0.442600).  Saving model ...
	 Train_Loss: 0.4662 Train_Acc: 78.219 Val_Loss: 0.4426  BEST VAL Loss: 0.4426  Val_Acc: 79.512

Epoch 86: Validation loss decreased (0.442600 --> 0.442331).  Saving model ...
	 Train_Loss: 0.4659 Train_Acc: 78.301 Val_Loss: 0.4423  BEST VAL Loss: 0.4423  Val_Acc: 79.366

Epoch 87: Validation loss decreased (0.442331 --> 0.442068).  Saving model ...
	 Train_Loss: 0.4656 Train_Acc: 78.172 Val_Loss: 0.4421  BEST VAL Loss: 0.4421  Val_Acc: 79.282

Epoch 88: Validation loss decreased (0.442068 --> 0.441816).  Saving model ...
	 Train_Loss: 0.4654 Train_Acc: 78.177 Val_Loss: 0.4418  BEST VAL Loss: 0.4418  Val_Acc: 79.355

Epoch 89: Validation loss decreased (0.441816 --> 0.441558).  Saving model ...
	 Train_Loss: 0.4651 Train_Acc: 78.304 Val_Loss: 0.4416  BEST VAL Loss: 0.4416  Val_Acc: 79.018

Epoch 90: Validation loss decreased (0.441558 --> 0.441302).  Saving model ...
	 Train_Loss: 0.4649 Train_Acc: 78.333 Val_Loss: 0.4413  BEST VAL Loss: 0.4413  Val_Acc: 79.686

Epoch 91: Validation loss decreased (0.441302 --> 0.441046).  Saving model ...
	 Train_Loss: 0.4646 Train_Acc: 78.390 Val_Loss: 0.4410  BEST VAL Loss: 0.4410  Val_Acc: 79.714

Epoch 92: Validation loss decreased (0.441046 --> 0.440789).  Saving model ...
	 Train_Loss: 0.4644 Train_Acc: 78.308 Val_Loss: 0.4408  BEST VAL Loss: 0.4408  Val_Acc: 79.461

Epoch 93: Validation loss decreased (0.440789 --> 0.440652).  Saving model ...
	 Train_Loss: 0.4641 Train_Acc: 78.381 Val_Loss: 0.4407  BEST VAL Loss: 0.4407  Val_Acc: 79.074

Epoch 94: Validation loss decreased (0.440652 --> 0.440431).  Saving model ...
	 Train_Loss: 0.4639 Train_Acc: 78.369 Val_Loss: 0.4404  BEST VAL Loss: 0.4404  Val_Acc: 79.271

Epoch 95: Validation loss decreased (0.440431 --> 0.440211).  Saving model ...
	 Train_Loss: 0.4636 Train_Acc: 78.393 Val_Loss: 0.4402  BEST VAL Loss: 0.4402  Val_Acc: 79.461

Epoch 96: Validation loss decreased (0.440211 --> 0.439978).  Saving model ...
	 Train_Loss: 0.4634 Train_Acc: 78.372 Val_Loss: 0.4400  BEST VAL Loss: 0.4400  Val_Acc: 79.484

Epoch 97: Validation loss decreased (0.439978 --> 0.439839).  Saving model ...
	 Train_Loss: 0.4632 Train_Acc: 78.376 Val_Loss: 0.4398  BEST VAL Loss: 0.4398  Val_Acc: 78.951

Epoch 98: Validation loss decreased (0.439839 --> 0.439619).  Saving model ...
	 Train_Loss: 0.4629 Train_Acc: 78.437 Val_Loss: 0.4396  BEST VAL Loss: 0.4396  Val_Acc: 79.366

Epoch 99: Validation loss decreased (0.439619 --> 0.439490).  Saving model ...
	 Train_Loss: 0.4627 Train_Acc: 78.449 Val_Loss: 0.4395  BEST VAL Loss: 0.4395  Val_Acc: 78.996

LPS_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.35      0.23      0.28     50422
           1       0.65      0.77      0.70     92173

    accuracy                           0.58    142595
   macro avg       0.50      0.50      0.49    142595
weighted avg       0.54      0.58      0.55    142595

LPS_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.34      0.22      0.27      6303
           1       0.64      0.77      0.70     11522

    accuracy                           0.57     17825
   macro avg       0.49      0.49      0.48     17825
weighted avg       0.54      0.57      0.55     17825

LPS_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.36      0.23      0.28      6303
           1       0.65      0.77      0.71     11522

    accuracy                           0.58     17825
   macro avg       0.50      0.50      0.49     17825
weighted avg       0.55      0.58      0.56     17825

              precision    recall  f1-score   support

           0       0.36      0.23      0.28      6303
           1       0.65      0.77      0.71     11522

    accuracy                           0.58     17825
   macro avg       0.50      0.50      0.49     17825
weighted avg       0.55      0.58      0.56     17825

LPS_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.44      0.38      0.41     32887
           1       0.56      0.61      0.58     41273

    accuracy                           0.51     74160
   macro avg       0.50      0.50      0.50     74160
weighted avg       0.50      0.51      0.51     74160

              precision    recall  f1-score   support

           0       0.44      0.38      0.41     32887
           1       0.56      0.61      0.58     41273

    accuracy                           0.51     74160
   macro avg       0.50      0.50      0.50     74160
weighted avg       0.50      0.51      0.51     74160

completed
