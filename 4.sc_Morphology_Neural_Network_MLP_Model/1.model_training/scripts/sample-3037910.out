[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'c9d801df'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '59da150b'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '5b4741a3'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'c391c236'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_0.100_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_0.100_DMSO_0.025
TREATMENT_NAME: Flagellin_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (33319, 1276)
Number of total missing values across all columns: 66638
Data Subset Is Off
Wells held out for testing: ['C21' 'M22']
Wells to use for training, validation, and testing ['C16' 'C17' 'C20' 'M18' 'M19' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.650089).  Saving model ...
	 Train_Loss: 0.6836 Train_Acc: 56.588 Val_Loss: 0.6501  BEST VAL Loss: 0.6501  Val_Acc: 63.024

Epoch 1: Validation loss decreased (0.650089 --> 0.629390).  Saving model ...
	 Train_Loss: 0.6629 Train_Acc: 63.046 Val_Loss: 0.6294  BEST VAL Loss: 0.6294  Val_Acc: 66.855

Epoch 2: Validation loss decreased (0.629390 --> 0.610059).  Saving model ...
	 Train_Loss: 0.6424 Train_Acc: 67.731 Val_Loss: 0.6101  BEST VAL Loss: 0.6101  Val_Acc: 69.798

Epoch 3: Validation loss decreased (0.610059 --> 0.597155).  Saving model ...
	 Train_Loss: 0.6256 Train_Acc: 70.115 Val_Loss: 0.5972  BEST VAL Loss: 0.5972  Val_Acc: 71.452

Epoch 4: Validation loss decreased (0.597155 --> 0.588760).  Saving model ...
	 Train_Loss: 0.6126 Train_Acc: 70.867 Val_Loss: 0.5888  BEST VAL Loss: 0.5888  Val_Acc: 70.363

Epoch 5: Validation loss decreased (0.588760 --> 0.579656).  Saving model ...
	 Train_Loss: 0.6003 Train_Acc: 72.737 Val_Loss: 0.5797  BEST VAL Loss: 0.5797  Val_Acc: 73.065

Epoch 6: Validation loss decreased (0.579656 --> 0.573294).  Saving model ...
	 Train_Loss: 0.5906 Train_Acc: 73.226 Val_Loss: 0.5733  BEST VAL Loss: 0.5733  Val_Acc: 72.621

Epoch 7: Validation loss decreased (0.573294 --> 0.566814).  Saving model ...
	 Train_Loss: 0.5818 Train_Acc: 74.366 Val_Loss: 0.5668  BEST VAL Loss: 0.5668  Val_Acc: 73.105

Epoch 8: Validation loss decreased (0.566814 --> 0.561884).  Saving model ...
	 Train_Loss: 0.5739 Train_Acc: 74.784 Val_Loss: 0.5619  BEST VAL Loss: 0.5619  Val_Acc: 73.790

Epoch 9: Validation loss decreased (0.561884 --> 0.556928).  Saving model ...
	 Train_Loss: 0.5673 Train_Acc: 75.657 Val_Loss: 0.5569  BEST VAL Loss: 0.5569  Val_Acc: 74.476

Epoch 10: Validation loss decreased (0.556928 --> 0.552510).  Saving model ...
	 Train_Loss: 0.5610 Train_Acc: 75.722 Val_Loss: 0.5525  BEST VAL Loss: 0.5525  Val_Acc: 73.992

Epoch 11: Validation loss decreased (0.552510 --> 0.549457).  Saving model ...
	 Train_Loss: 0.5556 Train_Acc: 76.015 Val_Loss: 0.5495  BEST VAL Loss: 0.5495  Val_Acc: 73.710

Epoch 12: Validation loss decreased (0.549457 --> 0.546458).  Saving model ...
	 Train_Loss: 0.5506 Train_Acc: 76.413 Val_Loss: 0.5465  BEST VAL Loss: 0.5465  Val_Acc: 74.274

Epoch 13: Validation loss decreased (0.546458 --> 0.543649).  Saving model ...
	 Train_Loss: 0.5456 Train_Acc: 77.169 Val_Loss: 0.5436  BEST VAL Loss: 0.5436  Val_Acc: 75.121

Epoch 14: Validation loss decreased (0.543649 --> 0.541732).  Saving model ...
	 Train_Loss: 0.5416 Train_Acc: 77.084 Val_Loss: 0.5417  BEST VAL Loss: 0.5417  Val_Acc: 74.073

Epoch 15: Validation loss decreased (0.541732 --> 0.540489).  Saving model ...
	 Train_Loss: 0.5376 Train_Acc: 77.447 Val_Loss: 0.5405  BEST VAL Loss: 0.5405  Val_Acc: 73.952

Epoch 16: Validation loss decreased (0.540489 --> 0.538856).  Saving model ...
	 Train_Loss: 0.5340 Train_Acc: 77.058 Val_Loss: 0.5389  BEST VAL Loss: 0.5389  Val_Acc: 73.871

Epoch 17: Validation loss decreased (0.538856 --> 0.538072).  Saving model ...
	 Train_Loss: 0.5304 Train_Acc: 78.057 Val_Loss: 0.5381  BEST VAL Loss: 0.5381  Val_Acc: 73.831

Epoch 18: Validation loss decreased (0.538072 --> 0.537099).  Saving model ...
	 Train_Loss: 0.5271 Train_Acc: 78.243 Val_Loss: 0.5371  BEST VAL Loss: 0.5371  Val_Acc: 74.879

Epoch 19: Validation loss decreased (0.537099 --> 0.536252).  Saving model ...
	 Train_Loss: 0.5243 Train_Acc: 77.880 Val_Loss: 0.5363  BEST VAL Loss: 0.5363  Val_Acc: 73.911

Epoch 20: Validation loss decreased (0.536252 --> 0.535355).  Saving model ...
	 Train_Loss: 0.5213 Train_Acc: 78.652 Val_Loss: 0.5354  BEST VAL Loss: 0.5354  Val_Acc: 74.355

Epoch 21: Validation loss decreased (0.535355 --> 0.534182).  Saving model ...
	 Train_Loss: 0.5188 Train_Acc: 78.339 Val_Loss: 0.5342  BEST VAL Loss: 0.5342  Val_Acc: 74.597

Epoch 22: Validation loss decreased (0.534182 --> 0.532970).  Saving model ...
	 Train_Loss: 0.5163 Train_Acc: 78.400 Val_Loss: 0.5330  BEST VAL Loss: 0.5330  Val_Acc: 75.000

Epoch 23: Validation loss decreased (0.532970 --> 0.531540).  Saving model ...
	 Train_Loss: 0.5141 Train_Acc: 78.581 Val_Loss: 0.5315  BEST VAL Loss: 0.5315  Val_Acc: 75.161

Epoch 24: Validation loss decreased (0.531540 --> 0.530351).  Saving model ...
	 Train_Loss: 0.5115 Train_Acc: 79.317 Val_Loss: 0.5304  BEST VAL Loss: 0.5304  Val_Acc: 76.048

Epoch 25: Validation loss decreased (0.530351 --> 0.529262).  Saving model ...
	 Train_Loss: 0.5093 Train_Acc: 78.990 Val_Loss: 0.5293  BEST VAL Loss: 0.5293  Val_Acc: 75.282

Epoch 26: Validation loss decreased (0.529262 --> 0.528717).  Saving model ...
	 Train_Loss: 0.5072 Train_Acc: 79.312 Val_Loss: 0.5287  BEST VAL Loss: 0.5287  Val_Acc: 74.315

Epoch 27: Validation loss decreased (0.528717 --> 0.528230).  Saving model ...
	 Train_Loss: 0.5052 Train_Acc: 79.539 Val_Loss: 0.5282  BEST VAL Loss: 0.5282  Val_Acc: 75.202

Epoch 28: Validation loss decreased (0.528230 --> 0.527907).  Saving model ...
	 Train_Loss: 0.5031 Train_Acc: 79.700 Val_Loss: 0.5279  BEST VAL Loss: 0.5279  Val_Acc: 74.839

Epoch 29: Validation loss decreased (0.527907 --> 0.527461).  Saving model ...
	 Train_Loss: 0.5011 Train_Acc: 80.099 Val_Loss: 0.5275  BEST VAL Loss: 0.5275  Val_Acc: 74.919

Epoch 30: Validation loss decreased (0.527461 --> 0.527433).  Saving model ...
	 Train_Loss: 0.4990 Train_Acc: 80.023 Val_Loss: 0.5274  BEST VAL Loss: 0.5274  Val_Acc: 75.282

Epoch 31: Validation loss decreased (0.527433 --> 0.526995).  Saving model ...
	 Train_Loss: 0.4973 Train_Acc: 79.953 Val_Loss: 0.5270  BEST VAL Loss: 0.5270  Val_Acc: 75.040

Epoch 32: Validation loss decreased (0.526995 --> 0.526931).  Saving model ...
	 Train_Loss: 0.4955 Train_Acc: 80.179 Val_Loss: 0.5269  BEST VAL Loss: 0.5269  Val_Acc: 74.556

Epoch 33: Validation loss decreased (0.526931 --> 0.526719).  Saving model ...
	 Train_Loss: 0.4938 Train_Acc: 80.603 Val_Loss: 0.5267  BEST VAL Loss: 0.5267  Val_Acc: 75.000

Epoch 34: Validation loss decreased (0.526719 --> 0.526694).  Saving model ...
	 Train_Loss: 0.4919 Train_Acc: 80.845 Val_Loss: 0.5267  BEST VAL Loss: 0.5267  Val_Acc: 74.758

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.4901 Train_Acc: 81.122 Val_Loss: 0.5267  BEST VAL Loss: 0.5267  Val_Acc: 75.565

Epoch 36: Validation loss decreased (0.526694 --> 0.526409).  Saving model ...
	 Train_Loss: 0.4886 Train_Acc: 80.406 Val_Loss: 0.5264  BEST VAL Loss: 0.5264  Val_Acc: 74.758

Epoch 37: Validation loss decreased (0.526409 --> 0.526199).  Saving model ...
	 Train_Loss: 0.4869 Train_Acc: 81.143 Val_Loss: 0.5262  BEST VAL Loss: 0.5262  Val_Acc: 75.685

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.4854 Train_Acc: 81.042 Val_Loss: 0.5263  BEST VAL Loss: 0.5262  Val_Acc: 74.355

Epoch 39: Validation loss decreased (0.526199 --> 0.526127).  Saving model ...
	 Train_Loss: 0.4841 Train_Acc: 80.648 Val_Loss: 0.5261  BEST VAL Loss: 0.5261  Val_Acc: 75.202

Epoch 40: Validation loss decreased (0.526127 --> 0.525774).  Saving model ...
	 Train_Loss: 0.4828 Train_Acc: 81.087 Val_Loss: 0.5258  BEST VAL Loss: 0.5258  Val_Acc: 75.000

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.4814 Train_Acc: 80.825 Val_Loss: 0.5260  BEST VAL Loss: 0.5258  Val_Acc: 73.952

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.4803 Train_Acc: 80.623 Val_Loss: 0.5260  BEST VAL Loss: 0.5258  Val_Acc: 74.476

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.4794 Train_Acc: 80.124 Val_Loss: 0.5259  BEST VAL Loss: 0.5258  Val_Acc: 74.839

Epoch 44: Validation loss decreased (0.525774 --> 0.525722).  Saving model ...
	 Train_Loss: 0.4784 Train_Acc: 80.522 Val_Loss: 0.5257  BEST VAL Loss: 0.5257  Val_Acc: 75.081

Epoch 45: Validation loss decreased (0.525722 --> 0.525615).  Saving model ...
	 Train_Loss: 0.4774 Train_Acc: 80.437 Val_Loss: 0.5256  BEST VAL Loss: 0.5256  Val_Acc: 74.556

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.4765 Train_Acc: 80.356 Val_Loss: 0.5256  BEST VAL Loss: 0.5256  Val_Acc: 73.347

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.4756 Train_Acc: 80.149 Val_Loss: 0.5257  BEST VAL Loss: 0.5256  Val_Acc: 74.516

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.4749 Train_Acc: 79.650 Val_Loss: 0.5258  BEST VAL Loss: 0.5256  Val_Acc: 73.831

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.4741 Train_Acc: 80.245 Val_Loss: 0.5262  BEST VAL Loss: 0.5256  Val_Acc: 73.871

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.4732 Train_Acc: 80.643 Val_Loss: 0.5265  BEST VAL Loss: 0.5256  Val_Acc: 73.911

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.4725 Train_Acc: 80.487 Val_Loss: 0.5267  BEST VAL Loss: 0.5256  Val_Acc: 73.710

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.4717 Train_Acc: 80.220 Val_Loss: 0.5270  BEST VAL Loss: 0.5256  Val_Acc: 73.387

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.4709 Train_Acc: 80.780 Val_Loss: 0.5271  BEST VAL Loss: 0.5256  Val_Acc: 74.274

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.4701 Train_Acc: 80.548 Val_Loss: 0.5273  BEST VAL Loss: 0.5256  Val_Acc: 74.234

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.4694 Train_Acc: 80.573 Val_Loss: 0.5275  BEST VAL Loss: 0.5256  Val_Acc: 73.306

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.4686 Train_Acc: 80.895 Val_Loss: 0.5278  BEST VAL Loss: 0.5256  Val_Acc: 73.952

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.4679 Train_Acc: 80.860 Val_Loss: 0.5281  BEST VAL Loss: 0.5256  Val_Acc: 74.476

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.4670 Train_Acc: 81.243 Val_Loss: 0.5283  BEST VAL Loss: 0.5256  Val_Acc: 74.395

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.4661 Train_Acc: 81.682 Val_Loss: 0.5289  BEST VAL Loss: 0.5256  Val_Acc: 73.992

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.4653 Train_Acc: 81.279 Val_Loss: 0.5292  BEST VAL Loss: 0.5256  Val_Acc: 74.435

Epoch 61: Validation loss did not decrease
Early stopped at epoch : 61
LPS_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.90      0.79      0.84      9433
           1       0.83      0.92      0.87     10400

    accuracy                           0.86     19833
   macro avg       0.87      0.86      0.86     19833
weighted avg       0.86      0.86      0.86     19833

LPS_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.77      0.67      0.71      1180
           1       0.73      0.82      0.77      1300

    accuracy                           0.75      2480
   macro avg       0.75      0.74      0.74      2480
weighted avg       0.75      0.75      0.74      2480

LPS_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.80      0.71      0.75      1179
           1       0.76      0.84      0.80      1301

    accuracy                           0.77      2480
   macro avg       0.78      0.77      0.77      2480
weighted avg       0.78      0.77      0.77      2480

              precision    recall  f1-score   support

           0       0.80      0.71      0.75      1179
           1       0.76      0.84      0.80      1301

    accuracy                           0.77      2480
   macro avg       0.78      0.77      0.77      2480
weighted avg       0.78      0.77      0.77      2480

LPS_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.76      0.68      0.72      4017
           1       0.74      0.81      0.77      4509

    accuracy                           0.75      8526
   macro avg       0.75      0.74      0.75      8526
weighted avg       0.75      0.75      0.75      8526

              precision    recall  f1-score   support

           0       0.76      0.68      0.72      4017
           1       0.74      0.81      0.77      4509

    accuracy                           0.75      8526
   macro avg       0.75      0.74      0.75      8526
weighted avg       0.75      0.75      0.75      8526

completed
