[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '764264cd'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '4359d1fd'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '5d2a1f61'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '0d07713f'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_10.000_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_10.000_DMSO_0.025']
The dimensions of the data are: (34320, 1276)
Number of total missing values across all columns: 68640
Data Subset Is Off
Wells held out for testing: ['C20' 'E21']
Wells to use for training, validation, and testing ['C16' 'E16' 'C17' 'E17' 'E20' 'C21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.687530).  Saving model ...
	 Train_Loss: 0.6931 Train_Acc: 51.811 Val_Loss: 0.6875  BEST VAL Loss: 0.6875  Val_Acc: 57.643

Epoch 1: Validation loss decreased (0.687530 --> 0.686317).  Saving model ...
	 Train_Loss: 0.6918 Train_Acc: 53.504 Val_Loss: 0.6863  BEST VAL Loss: 0.6863  Val_Acc: 59.277

Epoch 2: Validation loss decreased (0.686317 --> 0.683931).  Saving model ...
	 Train_Loss: 0.6904 Train_Acc: 55.269 Val_Loss: 0.6839  BEST VAL Loss: 0.6839  Val_Acc: 61.455

Epoch 3: Validation loss decreased (0.683931 --> 0.681594).  Saving model ...
	 Train_Loss: 0.6893 Train_Acc: 55.949 Val_Loss: 0.6816  BEST VAL Loss: 0.6816  Val_Acc: 63.516

Epoch 4: Validation loss decreased (0.681594 --> 0.679817).  Saving model ...
	 Train_Loss: 0.6883 Train_Acc: 56.324 Val_Loss: 0.6798  BEST VAL Loss: 0.6798  Val_Acc: 62.855

Epoch 5: Validation loss decreased (0.679817 --> 0.678724).  Saving model ...
	 Train_Loss: 0.6874 Train_Acc: 57.063 Val_Loss: 0.6787  BEST VAL Loss: 0.6787  Val_Acc: 63.477

Epoch 6: Validation loss decreased (0.678724 --> 0.677516).  Saving model ...
	 Train_Loss: 0.6867 Train_Acc: 57.019 Val_Loss: 0.6775  BEST VAL Loss: 0.6775  Val_Acc: 63.672

Epoch 7: Validation loss decreased (0.677516 --> 0.676445).  Saving model ...
	 Train_Loss: 0.6860 Train_Acc: 57.520 Val_Loss: 0.6764  BEST VAL Loss: 0.6764  Val_Acc: 63.555

Epoch 8: Validation loss decreased (0.676445 --> 0.675498).  Saving model ...
	 Train_Loss: 0.6854 Train_Acc: 57.909 Val_Loss: 0.6755  BEST VAL Loss: 0.6755  Val_Acc: 63.983

Epoch 9: Validation loss decreased (0.675498 --> 0.674570).  Saving model ...
	 Train_Loss: 0.6847 Train_Acc: 58.386 Val_Loss: 0.6746  BEST VAL Loss: 0.6746  Val_Acc: 64.683

Epoch 10: Validation loss decreased (0.674570 --> 0.673788).  Saving model ...
	 Train_Loss: 0.6842 Train_Acc: 57.899 Val_Loss: 0.6738  BEST VAL Loss: 0.6738  Val_Acc: 64.800

Epoch 11: Validation loss decreased (0.673788 --> 0.672976).  Saving model ...
	 Train_Loss: 0.6837 Train_Acc: 58.687 Val_Loss: 0.6730  BEST VAL Loss: 0.6730  Val_Acc: 64.644

Epoch 12: Validation loss decreased (0.672976 --> 0.672195).  Saving model ...
	 Train_Loss: 0.6831 Train_Acc: 59.047 Val_Loss: 0.6722  BEST VAL Loss: 0.6722  Val_Acc: 64.839

Epoch 13: Validation loss decreased (0.672195 --> 0.671766).  Saving model ...
	 Train_Loss: 0.6828 Train_Acc: 58.011 Val_Loss: 0.6718  BEST VAL Loss: 0.6718  Val_Acc: 64.216

Epoch 14: Validation loss decreased (0.671766 --> 0.671110).  Saving model ...
	 Train_Loss: 0.6824 Train_Acc: 59.003 Val_Loss: 0.6711  BEST VAL Loss: 0.6711  Val_Acc: 64.722

Epoch 15: Validation loss decreased (0.671110 --> 0.670608).  Saving model ...
	 Train_Loss: 0.6819 Train_Acc: 58.993 Val_Loss: 0.6706  BEST VAL Loss: 0.6706  Val_Acc: 64.489

Epoch 16: Validation loss decreased (0.670608 --> 0.670366).  Saving model ...
	 Train_Loss: 0.6818 Train_Acc: 58.011 Val_Loss: 0.6704  BEST VAL Loss: 0.6704  Val_Acc: 64.061

Epoch 17: Validation loss decreased (0.670366 --> 0.670040).  Saving model ...
	 Train_Loss: 0.6815 Train_Acc: 58.930 Val_Loss: 0.6700  BEST VAL Loss: 0.6700  Val_Acc: 64.683

Epoch 18: Validation loss decreased (0.670040 --> 0.669622).  Saving model ...
	 Train_Loss: 0.6812 Train_Acc: 59.280 Val_Loss: 0.6696  BEST VAL Loss: 0.6696  Val_Acc: 64.955

Epoch 19: Validation loss decreased (0.669622 --> 0.669207).  Saving model ...
	 Train_Loss: 0.6807 Train_Acc: 59.820 Val_Loss: 0.6692  BEST VAL Loss: 0.6692  Val_Acc: 64.372

Epoch 20: Validation loss decreased (0.669207 --> 0.668959).  Saving model ...
	 Train_Loss: 0.6805 Train_Acc: 58.818 Val_Loss: 0.6690  BEST VAL Loss: 0.6690  Val_Acc: 64.294

Epoch 21: Validation loss decreased (0.668959 --> 0.668699).  Saving model ...
	 Train_Loss: 0.6803 Train_Acc: 59.329 Val_Loss: 0.6687  BEST VAL Loss: 0.6687  Val_Acc: 64.566

Epoch 22: Validation loss decreased (0.668699 --> 0.668372).  Saving model ...
	 Train_Loss: 0.6800 Train_Acc: 59.601 Val_Loss: 0.6684  BEST VAL Loss: 0.6684  Val_Acc: 65.344

Epoch 23: Validation loss decreased (0.668372 --> 0.667952).  Saving model ...
	 Train_Loss: 0.6797 Train_Acc: 59.329 Val_Loss: 0.6680  BEST VAL Loss: 0.6680  Val_Acc: 66.044

Epoch 24: Validation loss decreased (0.667952 --> 0.667712).  Saving model ...
	 Train_Loss: 0.6796 Train_Acc: 59.188 Val_Loss: 0.6677  BEST VAL Loss: 0.6677  Val_Acc: 64.916

Epoch 25: Validation loss decreased (0.667712 --> 0.667413).  Saving model ...
	 Train_Loss: 0.6793 Train_Acc: 59.664 Val_Loss: 0.6674  BEST VAL Loss: 0.6674  Val_Acc: 65.072

Epoch 26: Validation loss decreased (0.667413 --> 0.667159).  Saving model ...
	 Train_Loss: 0.6791 Train_Acc: 59.859 Val_Loss: 0.6672  BEST VAL Loss: 0.6672  Val_Acc: 64.683

Epoch 27: Validation loss decreased (0.667159 --> 0.666876).  Saving model ...
	 Train_Loss: 0.6788 Train_Acc: 60.282 Val_Loss: 0.6669  BEST VAL Loss: 0.6669  Val_Acc: 65.266

Epoch 28: Validation loss decreased (0.666876 --> 0.666677).  Saving model ...
	 Train_Loss: 0.6786 Train_Acc: 59.475 Val_Loss: 0.6667  BEST VAL Loss: 0.6667  Val_Acc: 64.333

Epoch 29: Validation loss decreased (0.666677 --> 0.666432).  Saving model ...
	 Train_Loss: 0.6784 Train_Acc: 60.039 Val_Loss: 0.6664  BEST VAL Loss: 0.6664  Val_Acc: 65.266

Epoch 30: Validation loss decreased (0.666432 --> 0.666204).  Saving model ...
	 Train_Loss: 0.6782 Train_Acc: 60.053 Val_Loss: 0.6662  BEST VAL Loss: 0.6662  Val_Acc: 65.228

Epoch 31: Validation loss decreased (0.666204 --> 0.665966).  Saving model ...
	 Train_Loss: 0.6780 Train_Acc: 59.382 Val_Loss: 0.6660  BEST VAL Loss: 0.6660  Val_Acc: 65.422

Epoch 32: Validation loss decreased (0.665966 --> 0.665853).  Saving model ...
	 Train_Loss: 0.6780 Train_Acc: 59.164 Val_Loss: 0.6659  BEST VAL Loss: 0.6659  Val_Acc: 64.761

Epoch 33: Validation loss decreased (0.665853 --> 0.665658).  Saving model ...
	 Train_Loss: 0.6778 Train_Acc: 60.204 Val_Loss: 0.6657  BEST VAL Loss: 0.6657  Val_Acc: 65.266

Epoch 34: Validation loss decreased (0.665658 --> 0.665480).  Saving model ...
	 Train_Loss: 0.6776 Train_Acc: 60.019 Val_Loss: 0.6655  BEST VAL Loss: 0.6655  Val_Acc: 64.489

Epoch 35: Validation loss decreased (0.665480 --> 0.665331).  Saving model ...
	 Train_Loss: 0.6775 Train_Acc: 59.864 Val_Loss: 0.6653  BEST VAL Loss: 0.6653  Val_Acc: 65.150

Epoch 36: Validation loss decreased (0.665331 --> 0.665152).  Saving model ...
	 Train_Loss: 0.6772 Train_Acc: 60.632 Val_Loss: 0.6652  BEST VAL Loss: 0.6652  Val_Acc: 65.111

Epoch 37: Validation loss decreased (0.665152 --> 0.664991).  Saving model ...
	 Train_Loss: 0.6771 Train_Acc: 60.005 Val_Loss: 0.6650  BEST VAL Loss: 0.6650  Val_Acc: 64.955

Epoch 38: Validation loss decreased (0.664991 --> 0.664926).  Saving model ...
	 Train_Loss: 0.6769 Train_Acc: 60.379 Val_Loss: 0.6649  BEST VAL Loss: 0.6649  Val_Acc: 64.100

Epoch 39: Validation loss decreased (0.664926 --> 0.664826).  Saving model ...
	 Train_Loss: 0.6768 Train_Acc: 60.156 Val_Loss: 0.6648  BEST VAL Loss: 0.6648  Val_Acc: 64.411

Epoch 40: Validation loss decreased (0.664826 --> 0.664672).  Saving model ...
	 Train_Loss: 0.6766 Train_Acc: 60.564 Val_Loss: 0.6647  BEST VAL Loss: 0.6647  Val_Acc: 64.527

Epoch 41: Validation loss decreased (0.664672 --> 0.664532).  Saving model ...
	 Train_Loss: 0.6765 Train_Acc: 60.258 Val_Loss: 0.6645  BEST VAL Loss: 0.6645  Val_Acc: 64.722

Epoch 42: Validation loss decreased (0.664532 --> 0.664406).  Saving model ...
	 Train_Loss: 0.6763 Train_Acc: 60.457 Val_Loss: 0.6644  BEST VAL Loss: 0.6644  Val_Acc: 65.461

Epoch 43: Validation loss decreased (0.664406 --> 0.664324).  Saving model ...
	 Train_Loss: 0.6762 Train_Acc: 60.574 Val_Loss: 0.6643  BEST VAL Loss: 0.6643  Val_Acc: 64.333

Epoch 44: Validation loss decreased (0.664324 --> 0.664158).  Saving model ...
	 Train_Loss: 0.6761 Train_Acc: 60.195 Val_Loss: 0.6642  BEST VAL Loss: 0.6642  Val_Acc: 65.383

Epoch 45: Validation loss decreased (0.664158 --> 0.664048).  Saving model ...
	 Train_Loss: 0.6760 Train_Acc: 60.044 Val_Loss: 0.6640  BEST VAL Loss: 0.6640  Val_Acc: 65.305

Epoch 46: Validation loss decreased (0.664048 --> 0.663956).  Saving model ...
	 Train_Loss: 0.6759 Train_Acc: 59.713 Val_Loss: 0.6640  BEST VAL Loss: 0.6640  Val_Acc: 64.722

Epoch 47: Validation loss decreased (0.663956 --> 0.663871).  Saving model ...
	 Train_Loss: 0.6759 Train_Acc: 59.718 Val_Loss: 0.6639  BEST VAL Loss: 0.6639  Val_Acc: 65.228

Epoch 48: Validation loss decreased (0.663871 --> 0.663797).  Saving model ...
	 Train_Loss: 0.6758 Train_Acc: 59.971 Val_Loss: 0.6638  BEST VAL Loss: 0.6638  Val_Acc: 64.994

Epoch 49: Validation loss decreased (0.663797 --> 0.663711).  Saving model ...
	 Train_Loss: 0.6756 Train_Acc: 60.900 Val_Loss: 0.6637  BEST VAL Loss: 0.6637  Val_Acc: 64.955

Epoch 50: Validation loss decreased (0.663711 --> 0.663581).  Saving model ...
	 Train_Loss: 0.6755 Train_Acc: 61.211 Val_Loss: 0.6636  BEST VAL Loss: 0.6636  Val_Acc: 65.461

Epoch 51: Validation loss decreased (0.663581 --> 0.663503).  Saving model ...
	 Train_Loss: 0.6753 Train_Acc: 60.540 Val_Loss: 0.6635  BEST VAL Loss: 0.6635  Val_Acc: 64.527

Epoch 52: Validation loss decreased (0.663503 --> 0.663476).  Saving model ...
	 Train_Loss: 0.6753 Train_Acc: 60.331 Val_Loss: 0.6635  BEST VAL Loss: 0.6635  Val_Acc: 63.788

Epoch 53: Validation loss decreased (0.663476 --> 0.663379).  Saving model ...
	 Train_Loss: 0.6751 Train_Acc: 60.720 Val_Loss: 0.6634  BEST VAL Loss: 0.6634  Val_Acc: 64.761

Epoch 54: Validation loss decreased (0.663379 --> 0.663295).  Saving model ...
	 Train_Loss: 0.6750 Train_Acc: 60.968 Val_Loss: 0.6633  BEST VAL Loss: 0.6633  Val_Acc: 64.489

Epoch 55: Validation loss decreased (0.663295 --> 0.663208).  Saving model ...
	 Train_Loss: 0.6749 Train_Acc: 60.861 Val_Loss: 0.6632  BEST VAL Loss: 0.6632  Val_Acc: 65.189

Epoch 56: Validation loss decreased (0.663208 --> 0.663145).  Saving model ...
	 Train_Loss: 0.6748 Train_Acc: 60.598 Val_Loss: 0.6631  BEST VAL Loss: 0.6631  Val_Acc: 64.761

Epoch 57: Validation loss decreased (0.663145 --> 0.663075).  Saving model ...
	 Train_Loss: 0.6747 Train_Acc: 60.895 Val_Loss: 0.6631  BEST VAL Loss: 0.6631  Val_Acc: 65.111

Epoch 58: Validation loss decreased (0.663075 --> 0.663021).  Saving model ...
	 Train_Loss: 0.6746 Train_Acc: 60.749 Val_Loss: 0.6630  BEST VAL Loss: 0.6630  Val_Acc: 64.722

Epoch 59: Validation loss decreased (0.663021 --> 0.662963).  Saving model ...
	 Train_Loss: 0.6745 Train_Acc: 60.880 Val_Loss: 0.6630  BEST VAL Loss: 0.6630  Val_Acc: 64.255

Epoch 60: Validation loss decreased (0.662963 --> 0.662943).  Saving model ...
	 Train_Loss: 0.6744 Train_Acc: 60.919 Val_Loss: 0.6629  BEST VAL Loss: 0.6629  Val_Acc: 64.100

Epoch 61: Validation loss decreased (0.662943 --> 0.662878).  Saving model ...
	 Train_Loss: 0.6743 Train_Acc: 61.036 Val_Loss: 0.6629  BEST VAL Loss: 0.6629  Val_Acc: 64.450

Epoch 62: Validation loss decreased (0.662878 --> 0.662839).  Saving model ...
	 Train_Loss: 0.6742 Train_Acc: 60.676 Val_Loss: 0.6628  BEST VAL Loss: 0.6628  Val_Acc: 64.022

Epoch 63: Validation loss decreased (0.662839 --> 0.662817).  Saving model ...
	 Train_Loss: 0.6741 Train_Acc: 61.143 Val_Loss: 0.6628  BEST VAL Loss: 0.6628  Val_Acc: 63.750

Epoch 64: Validation loss decreased (0.662817 --> 0.662749).  Saving model ...
	 Train_Loss: 0.6740 Train_Acc: 60.822 Val_Loss: 0.6627  BEST VAL Loss: 0.6627  Val_Acc: 64.994

Epoch 65: Validation loss decreased (0.662749 --> 0.662712).  Saving model ...
	 Train_Loss: 0.6739 Train_Acc: 60.802 Val_Loss: 0.6627  BEST VAL Loss: 0.6627  Val_Acc: 65.150

Epoch 66: Validation loss decreased (0.662712 --> 0.662676).  Saving model ...
	 Train_Loss: 0.6738 Train_Acc: 60.948 Val_Loss: 0.6627  BEST VAL Loss: 0.6627  Val_Acc: 64.489

Epoch 67: Validation loss decreased (0.662676 --> 0.662637).  Saving model ...
	 Train_Loss: 0.6738 Train_Acc: 60.700 Val_Loss: 0.6626  BEST VAL Loss: 0.6626  Val_Acc: 64.605

Epoch 68: Validation loss decreased (0.662637 --> 0.662551).  Saving model ...
	 Train_Loss: 0.6737 Train_Acc: 60.909 Val_Loss: 0.6626  BEST VAL Loss: 0.6626  Val_Acc: 65.033

Epoch 69: Validation loss decreased (0.662551 --> 0.662491).  Saving model ...
	 Train_Loss: 0.6736 Train_Acc: 60.316 Val_Loss: 0.6625  BEST VAL Loss: 0.6625  Val_Acc: 64.955

Epoch 70: Validation loss decreased (0.662491 --> 0.662433).  Saving model ...
	 Train_Loss: 0.6736 Train_Acc: 61.021 Val_Loss: 0.6624  BEST VAL Loss: 0.6624  Val_Acc: 64.877

Epoch 71: Validation loss decreased (0.662433 --> 0.662388).  Saving model ...
	 Train_Loss: 0.6735 Train_Acc: 60.759 Val_Loss: 0.6624  BEST VAL Loss: 0.6624  Val_Acc: 64.955

Epoch 72: Validation loss decreased (0.662388 --> 0.662334).  Saving model ...
	 Train_Loss: 0.6734 Train_Acc: 60.987 Val_Loss: 0.6623  BEST VAL Loss: 0.6623  Val_Acc: 65.072

Epoch 73: Validation loss decreased (0.662334 --> 0.662268).  Saving model ...
	 Train_Loss: 0.6733 Train_Acc: 61.075 Val_Loss: 0.6623  BEST VAL Loss: 0.6623  Val_Acc: 64.916

Epoch 74: Validation loss decreased (0.662268 --> 0.662208).  Saving model ...
	 Train_Loss: 0.6732 Train_Acc: 61.221 Val_Loss: 0.6622  BEST VAL Loss: 0.6622  Val_Acc: 65.111

Epoch 75: Validation loss decreased (0.662208 --> 0.662177).  Saving model ...
	 Train_Loss: 0.6732 Train_Acc: 60.656 Val_Loss: 0.6622  BEST VAL Loss: 0.6622  Val_Acc: 64.722

Epoch 76: Validation loss decreased (0.662177 --> 0.662130).  Saving model ...
	 Train_Loss: 0.6731 Train_Acc: 61.240 Val_Loss: 0.6621  BEST VAL Loss: 0.6621  Val_Acc: 64.761

Epoch 77: Validation loss decreased (0.662130 --> 0.662089).  Saving model ...
	 Train_Loss: 0.6730 Train_Acc: 60.977 Val_Loss: 0.6621  BEST VAL Loss: 0.6621  Val_Acc: 65.150

Epoch 78: Validation loss decreased (0.662089 --> 0.662010).  Saving model ...
	 Train_Loss: 0.6730 Train_Acc: 61.143 Val_Loss: 0.6620  BEST VAL Loss: 0.6620  Val_Acc: 65.228

Epoch 79: Validation loss decreased (0.662010 --> 0.661942).  Saving model ...
	 Train_Loss: 0.6729 Train_Acc: 60.832 Val_Loss: 0.6619  BEST VAL Loss: 0.6619  Val_Acc: 65.422

Epoch 80: Validation loss decreased (0.661942 --> 0.661915).  Saving model ...
	 Train_Loss: 0.6729 Train_Acc: 60.438 Val_Loss: 0.6619  BEST VAL Loss: 0.6619  Val_Acc: 64.489

Epoch 81: Validation loss decreased (0.661915 --> 0.661870).  Saving model ...
	 Train_Loss: 0.6728 Train_Acc: 61.104 Val_Loss: 0.6619  BEST VAL Loss: 0.6619  Val_Acc: 64.955

Epoch 82: Validation loss decreased (0.661870 --> 0.661813).  Saving model ...
	 Train_Loss: 0.6727 Train_Acc: 60.870 Val_Loss: 0.6618  BEST VAL Loss: 0.6618  Val_Acc: 65.072

Epoch 83: Validation loss decreased (0.661813 --> 0.661775).  Saving model ...
	 Train_Loss: 0.6726 Train_Acc: 61.702 Val_Loss: 0.6618  BEST VAL Loss: 0.6618  Val_Acc: 64.489

Epoch 84: Validation loss decreased (0.661775 --> 0.661723).  Saving model ...
	 Train_Loss: 0.6726 Train_Acc: 61.337 Val_Loss: 0.6617  BEST VAL Loss: 0.6617  Val_Acc: 64.994

Epoch 85: Validation loss decreased (0.661723 --> 0.661679).  Saving model ...
	 Train_Loss: 0.6725 Train_Acc: 61.060 Val_Loss: 0.6617  BEST VAL Loss: 0.6617  Val_Acc: 64.877

Epoch 86: Validation loss decreased (0.661679 --> 0.661654).  Saving model ...
	 Train_Loss: 0.6724 Train_Acc: 61.575 Val_Loss: 0.6617  BEST VAL Loss: 0.6617  Val_Acc: 64.138

Epoch 87: Validation loss decreased (0.661654 --> 0.661637).  Saving model ...
	 Train_Loss: 0.6724 Train_Acc: 60.958 Val_Loss: 0.6616  BEST VAL Loss: 0.6616  Val_Acc: 64.333

Epoch 88: Validation loss decreased (0.661637 --> 0.661598).  Saving model ...
	 Train_Loss: 0.6723 Train_Acc: 61.070 Val_Loss: 0.6616  BEST VAL Loss: 0.6616  Val_Acc: 64.566

Epoch 89: Validation loss decreased (0.661598 --> 0.661557).  Saving model ...
	 Train_Loss: 0.6723 Train_Acc: 60.812 Val_Loss: 0.6616  BEST VAL Loss: 0.6616  Val_Acc: 64.994

Epoch 90: Validation loss decreased (0.661557 --> 0.661537).  Saving model ...
	 Train_Loss: 0.6722 Train_Acc: 61.245 Val_Loss: 0.6615  BEST VAL Loss: 0.6615  Val_Acc: 64.411

Epoch 91: Validation loss decreased (0.661537 --> 0.661512).  Saving model ...
	 Train_Loss: 0.6721 Train_Acc: 62.086 Val_Loss: 0.6615  BEST VAL Loss: 0.6615  Val_Acc: 64.566

Epoch 92: Validation loss decreased (0.661512 --> 0.661480).  Saving model ...
	 Train_Loss: 0.6721 Train_Acc: 61.172 Val_Loss: 0.6615  BEST VAL Loss: 0.6615  Val_Acc: 64.333

Epoch 93: Validation loss decreased (0.661480 --> 0.661457).  Saving model ...
	 Train_Loss: 0.6720 Train_Acc: 61.332 Val_Loss: 0.6615  BEST VAL Loss: 0.6615  Val_Acc: 64.683

Epoch 94: Validation loss decreased (0.661457 --> 0.661451).  Saving model ...
	 Train_Loss: 0.6719 Train_Acc: 61.007 Val_Loss: 0.6615  BEST VAL Loss: 0.6615  Val_Acc: 64.294

Epoch 95: Validation loss decreased (0.661451 --> 0.661426).  Saving model ...
	 Train_Loss: 0.6719 Train_Acc: 61.016 Val_Loss: 0.6614  BEST VAL Loss: 0.6614  Val_Acc: 64.605

Epoch 96: Validation loss decreased (0.661426 --> 0.661395).  Saving model ...
	 Train_Loss: 0.6719 Train_Acc: 60.914 Val_Loss: 0.6614  BEST VAL Loss: 0.6614  Val_Acc: 64.994

Epoch 97: Validation loss decreased (0.661395 --> 0.661345).  Saving model ...
	 Train_Loss: 0.6718 Train_Acc: 61.289 Val_Loss: 0.6613  BEST VAL Loss: 0.6613  Val_Acc: 65.422

Epoch 98: Validation loss decreased (0.661345 --> 0.661307).  Saving model ...
	 Train_Loss: 0.6718 Train_Acc: 61.089 Val_Loss: 0.6613  BEST VAL Loss: 0.6613  Val_Acc: 64.839

Epoch 99: Validation loss decreased (0.661307 --> 0.661289).  Saving model ...
	 Train_Loss: 0.6717 Train_Acc: 61.065 Val_Loss: 0.6613  BEST VAL Loss: 0.6613  Val_Acc: 64.100

LPS_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.75      0.73      0.74     10451
           1       0.72      0.74      0.73     10114

    accuracy                           0.74     20565
   macro avg       0.74      0.74      0.74     20565
weighted avg       0.74      0.74      0.74     20565

LPS_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.65      0.64      0.64      1307
           1       0.63      0.64      0.64      1264

    accuracy                           0.64      2571
   macro avg       0.64      0.64      0.64      2571
weighted avg       0.64      0.64      0.64      2571

LPS_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.65      0.64      0.65      1307
           1       0.64      0.65      0.64      1264

    accuracy                           0.64      2571
   macro avg       0.64      0.64      0.64      2571
weighted avg       0.64      0.64      0.64      2571

              precision    recall  f1-score   support

           0       0.65      0.64      0.65      1307
           1       0.64      0.65      0.64      1264

    accuracy                           0.64      2571
   macro avg       0.64      0.64      0.64      2571
weighted avg       0.64      0.64      0.64      2571

LPS_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.69      0.73      0.71      4445
           1       0.69      0.65      0.67      4168

    accuracy                           0.69      8613
   macro avg       0.69      0.69      0.69      8613
weighted avg       0.69      0.69      0.69      8613

              precision    recall  f1-score   support

           0       0.69      0.73      0.71      4445
           1       0.69      0.65      0.67      4168

    accuracy                           0.69      8613
   macro avg       0.69      0.69      0.69      8613
weighted avg       0.69      0.69      0.69      8613

completed
