[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '118fe8d7'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '3df9e847'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '5071b990'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'a4123f1a'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_0.010_DMSO_0.025 treatment_name: H2O2_100.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_0.010_DMSO_0.025
TREATMENT_NAME: H2O2_100.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (383616, 1270)
Number of total missing values across all columns: 767232
Data Subset Is Off
Wells held out for testing: ['B09' 'I10']
Wells to use for training, validation, and testing ['B02' 'B03' 'B08' 'H04' 'I04' 'H05' 'I05' 'H10' 'H11' 'I11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.367055).  Saving model ...
	 Train_Loss: 0.4590 Train_Acc: 77.933 Val_Loss: 0.3671  BEST VAL Loss: 0.3671  Val_Acc: 83.422

Epoch 1: Validation loss decreased (0.367055 --> 0.353629).  Saving model ...
	 Train_Loss: 0.4202 Train_Acc: 82.483 Val_Loss: 0.3536  BEST VAL Loss: 0.3536  Val_Acc: 84.922

Epoch 2: Validation loss decreased (0.353629 --> 0.343717).  Saving model ...
	 Train_Loss: 0.4004 Train_Acc: 83.612 Val_Loss: 0.3437  BEST VAL Loss: 0.3437  Val_Acc: 85.600

Epoch 3: Validation loss decreased (0.343717 --> 0.336139).  Saving model ...
	 Train_Loss: 0.3873 Train_Acc: 84.337 Val_Loss: 0.3361  BEST VAL Loss: 0.3361  Val_Acc: 86.202

Epoch 4: Validation loss decreased (0.336139 --> 0.329804).  Saving model ...
	 Train_Loss: 0.3780 Train_Acc: 84.675 Val_Loss: 0.3298  BEST VAL Loss: 0.3298  Val_Acc: 86.506

Epoch 5: Validation loss decreased (0.329804 --> 0.325657).  Saving model ...
	 Train_Loss: 0.3706 Train_Acc: 84.998 Val_Loss: 0.3257  BEST VAL Loss: 0.3257  Val_Acc: 86.688

Epoch 6: Validation loss decreased (0.325657 --> 0.321992).  Saving model ...
	 Train_Loss: 0.3644 Train_Acc: 85.411 Val_Loss: 0.3220  BEST VAL Loss: 0.3220  Val_Acc: 86.870

Epoch 7: Validation loss decreased (0.321992 --> 0.318433).  Saving model ...
	 Train_Loss: 0.3593 Train_Acc: 85.588 Val_Loss: 0.3184  BEST VAL Loss: 0.3184  Val_Acc: 87.225

Epoch 8: Validation loss decreased (0.318433 --> 0.314695).  Saving model ...
	 Train_Loss: 0.3550 Train_Acc: 85.691 Val_Loss: 0.3147  BEST VAL Loss: 0.3147  Val_Acc: 87.586

Epoch 9: Validation loss decreased (0.314695 --> 0.311257).  Saving model ...
	 Train_Loss: 0.3513 Train_Acc: 85.903 Val_Loss: 0.3113  BEST VAL Loss: 0.3113  Val_Acc: 87.806

Epoch 10: Validation loss decreased (0.311257 --> 0.308562).  Saving model ...
	 Train_Loss: 0.3481 Train_Acc: 86.011 Val_Loss: 0.3086  BEST VAL Loss: 0.3086  Val_Acc: 87.780

Epoch 11: Validation loss decreased (0.308562 --> 0.305918).  Saving model ...
	 Train_Loss: 0.3452 Train_Acc: 86.116 Val_Loss: 0.3059  BEST VAL Loss: 0.3059  Val_Acc: 88.110

Epoch 12: Validation loss decreased (0.305918 --> 0.304074).  Saving model ...
	 Train_Loss: 0.3426 Train_Acc: 86.176 Val_Loss: 0.3041  BEST VAL Loss: 0.3041  Val_Acc: 87.611

Epoch 13: Validation loss decreased (0.304074 --> 0.302198).  Saving model ...
	 Train_Loss: 0.3403 Train_Acc: 86.235 Val_Loss: 0.3022  BEST VAL Loss: 0.3022  Val_Acc: 87.984

Epoch 14: Validation loss decreased (0.302198 --> 0.300525).  Saving model ...
	 Train_Loss: 0.3382 Train_Acc: 86.350 Val_Loss: 0.3005  BEST VAL Loss: 0.3005  Val_Acc: 88.019

Epoch 15: Validation loss decreased (0.300525 --> 0.298739).  Saving model ...
	 Train_Loss: 0.3363 Train_Acc: 86.416 Val_Loss: 0.2987  BEST VAL Loss: 0.2987  Val_Acc: 88.195

Epoch 16: Validation loss decreased (0.298739 --> 0.297422).  Saving model ...
	 Train_Loss: 0.3344 Train_Acc: 86.558 Val_Loss: 0.2974  BEST VAL Loss: 0.2974  Val_Acc: 87.994

Epoch 17: Validation loss decreased (0.297422 --> 0.295832).  Saving model ...
	 Train_Loss: 0.3328 Train_Acc: 86.533 Val_Loss: 0.2958  BEST VAL Loss: 0.2958  Val_Acc: 88.502

Epoch 18: Validation loss decreased (0.295832 --> 0.294579).  Saving model ...
	 Train_Loss: 0.3312 Train_Acc: 86.636 Val_Loss: 0.2946  BEST VAL Loss: 0.2946  Val_Acc: 88.276

Epoch 19: Validation loss decreased (0.294579 --> 0.293316).  Saving model ...
	 Train_Loss: 0.3297 Train_Acc: 86.690 Val_Loss: 0.2933  BEST VAL Loss: 0.2933  Val_Acc: 88.374

Epoch 20: Validation loss decreased (0.293316 --> 0.292119).  Saving model ...
	 Train_Loss: 0.3283 Train_Acc: 86.740 Val_Loss: 0.2921  BEST VAL Loss: 0.2921  Val_Acc: 88.493

Epoch 21: Validation loss decreased (0.292119 --> 0.290974).  Saving model ...
	 Train_Loss: 0.3271 Train_Acc: 86.709 Val_Loss: 0.2910  BEST VAL Loss: 0.2910  Val_Acc: 88.590

Epoch 22: Validation loss decreased (0.290974 --> 0.289949).  Saving model ...
	 Train_Loss: 0.3259 Train_Acc: 86.820 Val_Loss: 0.2899  BEST VAL Loss: 0.2899  Val_Acc: 88.361

Epoch 23: Validation loss decreased (0.289949 --> 0.288818).  Saving model ...
	 Train_Loss: 0.3248 Train_Acc: 86.852 Val_Loss: 0.2888  BEST VAL Loss: 0.2888  Val_Acc: 88.728

Epoch 24: Validation loss decreased (0.288818 --> 0.287755).  Saving model ...
	 Train_Loss: 0.3237 Train_Acc: 86.836 Val_Loss: 0.2878  BEST VAL Loss: 0.2878  Val_Acc: 88.690

Epoch 25: Validation loss decreased (0.287755 --> 0.286858).  Saving model ...
	 Train_Loss: 0.3227 Train_Acc: 86.884 Val_Loss: 0.2869  BEST VAL Loss: 0.2869  Val_Acc: 88.452

Epoch 26: Validation loss decreased (0.286858 --> 0.286013).  Saving model ...
	 Train_Loss: 0.3217 Train_Acc: 86.958 Val_Loss: 0.2860  BEST VAL Loss: 0.2860  Val_Acc: 88.606

Epoch 27: Validation loss decreased (0.286013 --> 0.285220).  Saving model ...
	 Train_Loss: 0.3208 Train_Acc: 87.041 Val_Loss: 0.2852  BEST VAL Loss: 0.2852  Val_Acc: 88.618

Epoch 28: Validation loss decreased (0.285220 --> 0.284462).  Saving model ...
	 Train_Loss: 0.3199 Train_Acc: 86.981 Val_Loss: 0.2845  BEST VAL Loss: 0.2845  Val_Acc: 88.621

Epoch 29: Validation loss decreased (0.284462 --> 0.283587).  Saving model ...
	 Train_Loss: 0.3191 Train_Acc: 87.014 Val_Loss: 0.2836  BEST VAL Loss: 0.2836  Val_Acc: 88.760

Epoch 30: Validation loss decreased (0.283587 --> 0.282779).  Saving model ...
	 Train_Loss: 0.3182 Train_Acc: 87.068 Val_Loss: 0.2828  BEST VAL Loss: 0.2828  Val_Acc: 88.816

Epoch 31: Validation loss decreased (0.282779 --> 0.282099).  Saving model ...
	 Train_Loss: 0.3174 Train_Acc: 87.074 Val_Loss: 0.2821  BEST VAL Loss: 0.2821  Val_Acc: 88.794

Epoch 32: Validation loss decreased (0.282099 --> 0.281343).  Saving model ...
	 Train_Loss: 0.3167 Train_Acc: 87.119 Val_Loss: 0.2813  BEST VAL Loss: 0.2813  Val_Acc: 88.967

Epoch 33: Validation loss decreased (0.281343 --> 0.280673).  Saving model ...
	 Train_Loss: 0.3160 Train_Acc: 87.122 Val_Loss: 0.2807  BEST VAL Loss: 0.2807  Val_Acc: 88.967

Epoch 34: Validation loss decreased (0.280673 --> 0.280014).  Saving model ...
	 Train_Loss: 0.3153 Train_Acc: 87.156 Val_Loss: 0.2800  BEST VAL Loss: 0.2800  Val_Acc: 88.873

Epoch 35: Validation loss decreased (0.280014 --> 0.279395).  Saving model ...
	 Train_Loss: 0.3146 Train_Acc: 87.171 Val_Loss: 0.2794  BEST VAL Loss: 0.2794  Val_Acc: 88.901

Epoch 36: Validation loss decreased (0.279395 --> 0.278818).  Saving model ...
	 Train_Loss: 0.3140 Train_Acc: 87.244 Val_Loss: 0.2788  BEST VAL Loss: 0.2788  Val_Acc: 88.778

Epoch 37: Validation loss decreased (0.278818 --> 0.278279).  Saving model ...
	 Train_Loss: 0.3133 Train_Acc: 87.222 Val_Loss: 0.2783  BEST VAL Loss: 0.2783  Val_Acc: 88.948

Epoch 38: Validation loss decreased (0.278279 --> 0.277745).  Saving model ...
	 Train_Loss: 0.3128 Train_Acc: 87.238 Val_Loss: 0.2777  BEST VAL Loss: 0.2777  Val_Acc: 88.998

Epoch 39: Validation loss decreased (0.277745 --> 0.277227).  Saving model ...
	 Train_Loss: 0.3122 Train_Acc: 87.268 Val_Loss: 0.2772  BEST VAL Loss: 0.2772  Val_Acc: 88.879

Epoch 40: Validation loss decreased (0.277227 --> 0.276731).  Saving model ...
	 Train_Loss: 0.3116 Train_Acc: 87.269 Val_Loss: 0.2767  BEST VAL Loss: 0.2767  Val_Acc: 88.954

Epoch 41: Validation loss decreased (0.276731 --> 0.276259).  Saving model ...
	 Train_Loss: 0.3111 Train_Acc: 87.310 Val_Loss: 0.2763  BEST VAL Loss: 0.2763  Val_Acc: 88.819

Epoch 42: Validation loss decreased (0.276259 --> 0.275765).  Saving model ...
	 Train_Loss: 0.3105 Train_Acc: 87.283 Val_Loss: 0.2758  BEST VAL Loss: 0.2758  Val_Acc: 89.007

Epoch 43: Validation loss decreased (0.275765 --> 0.275282).  Saving model ...
	 Train_Loss: 0.3100 Train_Acc: 87.320 Val_Loss: 0.2753  BEST VAL Loss: 0.2753  Val_Acc: 89.070

Epoch 44: Validation loss decreased (0.275282 --> 0.274848).  Saving model ...
	 Train_Loss: 0.3095 Train_Acc: 87.308 Val_Loss: 0.2748  BEST VAL Loss: 0.2748  Val_Acc: 88.907

Epoch 45: Validation loss decreased (0.274848 --> 0.274406).  Saving model ...
	 Train_Loss: 0.3090 Train_Acc: 87.390 Val_Loss: 0.2744  BEST VAL Loss: 0.2744  Val_Acc: 89.023

Epoch 46: Validation loss decreased (0.274406 --> 0.273986).  Saving model ...
	 Train_Loss: 0.3085 Train_Acc: 87.433 Val_Loss: 0.2740  BEST VAL Loss: 0.2740  Val_Acc: 89.004

Epoch 47: Validation loss decreased (0.273986 --> 0.273622).  Saving model ...
	 Train_Loss: 0.3081 Train_Acc: 87.404 Val_Loss: 0.2736  BEST VAL Loss: 0.2736  Val_Acc: 88.888

Epoch 48: Validation loss decreased (0.273622 --> 0.273231).  Saving model ...
	 Train_Loss: 0.3077 Train_Acc: 87.368 Val_Loss: 0.2732  BEST VAL Loss: 0.2732  Val_Acc: 89.161

Epoch 49: Validation loss decreased (0.273231 --> 0.272870).  Saving model ...
	 Train_Loss: 0.3072 Train_Acc: 87.436 Val_Loss: 0.2729  BEST VAL Loss: 0.2729  Val_Acc: 89.039

Epoch 50: Validation loss decreased (0.272870 --> 0.272479).  Saving model ...
	 Train_Loss: 0.3068 Train_Acc: 87.408 Val_Loss: 0.2725  BEST VAL Loss: 0.2725  Val_Acc: 88.982

Epoch 51: Validation loss decreased (0.272479 --> 0.272115).  Saving model ...
	 Train_Loss: 0.3064 Train_Acc: 87.441 Val_Loss: 0.2721  BEST VAL Loss: 0.2721  Val_Acc: 89.167

Epoch 52: Validation loss decreased (0.272115 --> 0.271746).  Saving model ...
	 Train_Loss: 0.3060 Train_Acc: 87.438 Val_Loss: 0.2717  BEST VAL Loss: 0.2717  Val_Acc: 88.989

Epoch 53: Validation loss decreased (0.271746 --> 0.271414).  Saving model ...
	 Train_Loss: 0.3056 Train_Acc: 87.527 Val_Loss: 0.2714  BEST VAL Loss: 0.2714  Val_Acc: 89.105

Epoch 54: Validation loss decreased (0.271414 --> 0.271091).  Saving model ...
	 Train_Loss: 0.3052 Train_Acc: 87.477 Val_Loss: 0.2711  BEST VAL Loss: 0.2711  Val_Acc: 88.960

Epoch 55: Validation loss decreased (0.271091 --> 0.270792).  Saving model ...
	 Train_Loss: 0.3048 Train_Acc: 87.447 Val_Loss: 0.2708  BEST VAL Loss: 0.2708  Val_Acc: 88.851

Epoch 56: Validation loss decreased (0.270792 --> 0.270450).  Saving model ...
	 Train_Loss: 0.3045 Train_Acc: 87.517 Val_Loss: 0.2705  BEST VAL Loss: 0.2705  Val_Acc: 89.368

Epoch 57: Validation loss decreased (0.270450 --> 0.270167).  Saving model ...
	 Train_Loss: 0.3041 Train_Acc: 87.466 Val_Loss: 0.2702  BEST VAL Loss: 0.2702  Val_Acc: 89.039

Epoch 58: Validation loss decreased (0.270167 --> 0.269874).  Saving model ...
	 Train_Loss: 0.3038 Train_Acc: 87.492 Val_Loss: 0.2699  BEST VAL Loss: 0.2699  Val_Acc: 88.998

Epoch 59: Validation loss decreased (0.269874 --> 0.269569).  Saving model ...
	 Train_Loss: 0.3035 Train_Acc: 87.509 Val_Loss: 0.2696  BEST VAL Loss: 0.2696  Val_Acc: 89.155

Epoch 60: Validation loss decreased (0.269569 --> 0.269280).  Saving model ...
	 Train_Loss: 0.3031 Train_Acc: 87.466 Val_Loss: 0.2693  BEST VAL Loss: 0.2693  Val_Acc: 89.067

Epoch 61: Validation loss decreased (0.269280 --> 0.268993).  Saving model ...
	 Train_Loss: 0.3028 Train_Acc: 87.594 Val_Loss: 0.2690  BEST VAL Loss: 0.2690  Val_Acc: 89.277

Epoch 62: Validation loss decreased (0.268993 --> 0.268711).  Saving model ...
	 Train_Loss: 0.3025 Train_Acc: 87.604 Val_Loss: 0.2687  BEST VAL Loss: 0.2687  Val_Acc: 89.111

Epoch 63: Validation loss decreased (0.268711 --> 0.268446).  Saving model ...
	 Train_Loss: 0.3022 Train_Acc: 87.641 Val_Loss: 0.2684  BEST VAL Loss: 0.2684  Val_Acc: 89.142

Epoch 64: Validation loss decreased (0.268446 --> 0.268180).  Saving model ...
	 Train_Loss: 0.3019 Train_Acc: 87.665 Val_Loss: 0.2682  BEST VAL Loss: 0.2682  Val_Acc: 89.130

Epoch 65: Validation loss decreased (0.268180 --> 0.267901).  Saving model ...
	 Train_Loss: 0.3016 Train_Acc: 87.561 Val_Loss: 0.2679  BEST VAL Loss: 0.2679  Val_Acc: 89.186

Epoch 66: Validation loss decreased (0.267901 --> 0.267663).  Saving model ...
	 Train_Loss: 0.3013 Train_Acc: 87.591 Val_Loss: 0.2677  BEST VAL Loss: 0.2677  Val_Acc: 89.293

Epoch 67: Validation loss decreased (0.267663 --> 0.267430).  Saving model ...
	 Train_Loss: 0.3010 Train_Acc: 87.687 Val_Loss: 0.2674  BEST VAL Loss: 0.2674  Val_Acc: 89.045

Epoch 68: Validation loss decreased (0.267430 --> 0.267157).  Saving model ...
	 Train_Loss: 0.3007 Train_Acc: 87.621 Val_Loss: 0.2672  BEST VAL Loss: 0.2672  Val_Acc: 89.349

Epoch 69: Validation loss decreased (0.267157 --> 0.266915).  Saving model ...
	 Train_Loss: 0.3004 Train_Acc: 87.626 Val_Loss: 0.2669  BEST VAL Loss: 0.2669  Val_Acc: 89.312

Epoch 70: Validation loss decreased (0.266915 --> 0.266704).  Saving model ...
	 Train_Loss: 0.3001 Train_Acc: 87.595 Val_Loss: 0.2667  BEST VAL Loss: 0.2667  Val_Acc: 89.202

Epoch 71: Validation loss decreased (0.266704 --> 0.266483).  Saving model ...
	 Train_Loss: 0.2999 Train_Acc: 87.536 Val_Loss: 0.2665  BEST VAL Loss: 0.2665  Val_Acc: 89.218

Epoch 72: Validation loss decreased (0.266483 --> 0.266258).  Saving model ...
	 Train_Loss: 0.2997 Train_Acc: 87.566 Val_Loss: 0.2663  BEST VAL Loss: 0.2663  Val_Acc: 89.193

Epoch 73: Validation loss decreased (0.266258 --> 0.266018).  Saving model ...
	 Train_Loss: 0.2994 Train_Acc: 87.665 Val_Loss: 0.2660  BEST VAL Loss: 0.2660  Val_Acc: 89.255

Epoch 74: Validation loss decreased (0.266018 --> 0.265764).  Saving model ...
	 Train_Loss: 0.2991 Train_Acc: 87.692 Val_Loss: 0.2658  BEST VAL Loss: 0.2658  Val_Acc: 89.334

Epoch 75: Validation loss decreased (0.265764 --> 0.265554).  Saving model ...
	 Train_Loss: 0.2989 Train_Acc: 87.716 Val_Loss: 0.2656  BEST VAL Loss: 0.2656  Val_Acc: 89.375

Epoch 76: Validation loss decreased (0.265554 --> 0.265314).  Saving model ...
	 Train_Loss: 0.2986 Train_Acc: 87.641 Val_Loss: 0.2653  BEST VAL Loss: 0.2653  Val_Acc: 89.472

Epoch 77: Validation loss decreased (0.265314 --> 0.265121).  Saving model ...
	 Train_Loss: 0.2984 Train_Acc: 87.662 Val_Loss: 0.2651  BEST VAL Loss: 0.2651  Val_Acc: 89.211

Epoch 78: Validation loss decreased (0.265121 --> 0.264883).  Saving model ...
	 Train_Loss: 0.2982 Train_Acc: 87.700 Val_Loss: 0.2649  BEST VAL Loss: 0.2649  Val_Acc: 89.491

Epoch 79: Validation loss decreased (0.264883 --> 0.264681).  Saving model ...
	 Train_Loss: 0.2980 Train_Acc: 87.653 Val_Loss: 0.2647  BEST VAL Loss: 0.2647  Val_Acc: 89.409

Epoch 80: Validation loss decreased (0.264681 --> 0.264472).  Saving model ...
	 Train_Loss: 0.2977 Train_Acc: 87.747 Val_Loss: 0.2645  BEST VAL Loss: 0.2645  Val_Acc: 89.296

Epoch 81: Validation loss decreased (0.264472 --> 0.264267).  Saving model ...
	 Train_Loss: 0.2975 Train_Acc: 87.649 Val_Loss: 0.2643  BEST VAL Loss: 0.2643  Val_Acc: 89.513

Epoch 82: Validation loss decreased (0.264267 --> 0.264109).  Saving model ...
	 Train_Loss: 0.2973 Train_Acc: 87.752 Val_Loss: 0.2641  BEST VAL Loss: 0.2641  Val_Acc: 89.299

Epoch 83: Validation loss decreased (0.264109 --> 0.263910).  Saving model ...
	 Train_Loss: 0.2971 Train_Acc: 87.678 Val_Loss: 0.2639  BEST VAL Loss: 0.2639  Val_Acc: 89.406

Epoch 84: Validation loss decreased (0.263910 --> 0.263741).  Saving model ...
	 Train_Loss: 0.2968 Train_Acc: 87.743 Val_Loss: 0.2637  BEST VAL Loss: 0.2637  Val_Acc: 89.302

Epoch 85: Validation loss decreased (0.263741 --> 0.263564).  Saving model ...
	 Train_Loss: 0.2966 Train_Acc: 87.759 Val_Loss: 0.2636  BEST VAL Loss: 0.2636  Val_Acc: 89.362

Epoch 86: Validation loss decreased (0.263564 --> 0.263371).  Saving model ...
	 Train_Loss: 0.2964 Train_Acc: 87.874 Val_Loss: 0.2634  BEST VAL Loss: 0.2634  Val_Acc: 89.466

Epoch 87: Validation loss decreased (0.263371 --> 0.263181).  Saving model ...
	 Train_Loss: 0.2962 Train_Acc: 87.758 Val_Loss: 0.2632  BEST VAL Loss: 0.2632  Val_Acc: 89.488

Epoch 88: Validation loss decreased (0.263181 --> 0.263019).  Saving model ...
	 Train_Loss: 0.2960 Train_Acc: 87.719 Val_Loss: 0.2630  BEST VAL Loss: 0.2630  Val_Acc: 89.328

Epoch 89: Validation loss decreased (0.263019 --> 0.262837).  Saving model ...
	 Train_Loss: 0.2958 Train_Acc: 87.713 Val_Loss: 0.2628  BEST VAL Loss: 0.2628  Val_Acc: 89.384

Epoch 90: Validation loss decreased (0.262837 --> 0.262660).  Saving model ...
	 Train_Loss: 0.2956 Train_Acc: 87.863 Val_Loss: 0.2627  BEST VAL Loss: 0.2627  Val_Acc: 89.412

Epoch 91: Validation loss decreased (0.262660 --> 0.262503).  Saving model ...
	 Train_Loss: 0.2954 Train_Acc: 87.832 Val_Loss: 0.2625  BEST VAL Loss: 0.2625  Val_Acc: 89.324

Epoch 92: Validation loss decreased (0.262503 --> 0.262333).  Saving model ...
	 Train_Loss: 0.2952 Train_Acc: 87.798 Val_Loss: 0.2623  BEST VAL Loss: 0.2623  Val_Acc: 89.547

Epoch 93: Validation loss decreased (0.262333 --> 0.262166).  Saving model ...
	 Train_Loss: 0.2950 Train_Acc: 87.818 Val_Loss: 0.2622  BEST VAL Loss: 0.2622  Val_Acc: 89.459

Epoch 94: Validation loss decreased (0.262166 --> 0.262031).  Saving model ...
	 Train_Loss: 0.2949 Train_Acc: 87.782 Val_Loss: 0.2620  BEST VAL Loss: 0.2620  Val_Acc: 89.221

Epoch 95: Validation loss decreased (0.262031 --> 0.261885).  Saving model ...
	 Train_Loss: 0.2947 Train_Acc: 87.855 Val_Loss: 0.2619  BEST VAL Loss: 0.2619  Val_Acc: 89.522

Epoch 96: Validation loss decreased (0.261885 --> 0.261704).  Saving model ...
	 Train_Loss: 0.2945 Train_Acc: 87.764 Val_Loss: 0.2617  BEST VAL Loss: 0.2617  Val_Acc: 89.641

Epoch 97: Validation loss decreased (0.261704 --> 0.261580).  Saving model ...
	 Train_Loss: 0.2943 Train_Acc: 87.826 Val_Loss: 0.2616  BEST VAL Loss: 0.2616  Val_Acc: 89.431

Epoch 98: Validation loss decreased (0.261580 --> 0.261449).  Saving model ...
	 Train_Loss: 0.2941 Train_Acc: 87.912 Val_Loss: 0.2614  BEST VAL Loss: 0.2614  Val_Acc: 89.447

Epoch 99: Validation loss decreased (0.261449 --> 0.261294).  Saving model ...
	 Train_Loss: 0.2939 Train_Acc: 87.854 Val_Loss: 0.2613  BEST VAL Loss: 0.2613  Val_Acc: 89.607

LPS_0.010_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.91      0.95      0.93    169561
           1       0.90      0.82      0.86     85371

    accuracy                           0.91    254932
   macro avg       0.90      0.89      0.89    254932
weighted avg       0.91      0.91      0.91    254932

LPS_0.010_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.90      0.95      0.92     21195
           1       0.88      0.80      0.84     10672

    accuracy                           0.90     31867
   macro avg       0.89      0.87      0.88     31867
weighted avg       0.90      0.90      0.89     31867

LPS_0.010_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.90      0.94      0.92     21196
           1       0.87      0.80      0.83     10671

    accuracy                           0.89     31867
   macro avg       0.89      0.87      0.88     31867
weighted avg       0.89      0.89      0.89     31867

              precision    recall  f1-score   support

           0       0.90      0.94      0.92     21196
           1       0.87      0.80      0.83     10671

    accuracy                           0.89     31867
   macro avg       0.89      0.87      0.88     31867
weighted avg       0.89      0.89      0.89     31867

LPS_0.010_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.59      0.94      0.73     28584
           1       0.92      0.49      0.64     36366

    accuracy                           0.69     64950
   macro avg       0.76      0.72      0.68     64950
weighted avg       0.77      0.69      0.68     64950

              precision    recall  f1-score   support

           0       0.59      0.94      0.73     28584
           1       0.92      0.49      0.64     36366

    accuracy                           0.69     64950
   macro avg       0.76      0.72      0.68     64950
weighted avg       0.77      0.69      0.68     64950

completed
