[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'a3e9e0e2'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '7739358e'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '95a8bac5'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'b20de36e'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_10.000_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_10.000_DMSO_0.025']
The dimensions of the data are: (32669, 1276)
Number of total missing values across all columns: 65338
Data Subset Is Off
Wells held out for testing: ['B20' 'E21']
Wells to use for training, validation, and testing ['B16' 'E16' 'B17' 'E17' 'E20' 'B21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.692961).  Saving model ...
	 Train_Loss: 0.7141 Train_Acc: 52.021 Val_Loss: 0.6930  BEST VAL Loss: 0.6930  Val_Acc: 51.009

Epoch 1: Validation loss decreased (0.692961 --> 0.690827).  Saving model ...
	 Train_Loss: 0.7031 Train_Acc: 50.800 Val_Loss: 0.6908  BEST VAL Loss: 0.6908  Val_Acc: 53.793

Epoch 2: Validation loss decreased (0.690827 --> 0.687411).  Saving model ...
	 Train_Loss: 0.6974 Train_Acc: 54.129 Val_Loss: 0.6874  BEST VAL Loss: 0.6874  Val_Acc: 57.103

Epoch 3: Validation loss decreased (0.687411 --> 0.682981).  Saving model ...
	 Train_Loss: 0.6919 Train_Acc: 56.339 Val_Loss: 0.6830  BEST VAL Loss: 0.6830  Val_Acc: 59.040

Epoch 4: Validation loss decreased (0.682981 --> 0.675816).  Saving model ...
	 Train_Loss: 0.6876 Train_Acc: 57.565 Val_Loss: 0.6758  BEST VAL Loss: 0.6758  Val_Acc: 63.640

Epoch 5: Validation loss decreased (0.675816 --> 0.667652).  Saving model ...
	 Train_Loss: 0.6830 Train_Acc: 58.862 Val_Loss: 0.6677  BEST VAL Loss: 0.6677  Val_Acc: 66.949

Epoch 6: Validation loss decreased (0.667652 --> 0.661363).  Saving model ...
	 Train_Loss: 0.6794 Train_Acc: 59.770 Val_Loss: 0.6614  BEST VAL Loss: 0.6614  Val_Acc: 68.644

Epoch 7: Validation loss decreased (0.661363 --> 0.656191).  Saving model ...
	 Train_Loss: 0.6759 Train_Acc: 60.532 Val_Loss: 0.6562  BEST VAL Loss: 0.6562  Val_Acc: 69.370

Epoch 8: Validation loss decreased (0.656191 --> 0.651309).  Saving model ...
	 Train_Loss: 0.6723 Train_Acc: 61.248 Val_Loss: 0.6513  BEST VAL Loss: 0.6513  Val_Acc: 68.846

Epoch 9: Validation loss decreased (0.651309 --> 0.645292).  Saving model ...
	 Train_Loss: 0.6692 Train_Acc: 61.541 Val_Loss: 0.6453  BEST VAL Loss: 0.6453  Val_Acc: 70.379

Epoch 10: Validation loss decreased (0.645292 --> 0.640911).  Saving model ...
	 Train_Loss: 0.6664 Train_Acc: 61.652 Val_Loss: 0.6409  BEST VAL Loss: 0.6409  Val_Acc: 71.065

Epoch 11: Validation loss decreased (0.640911 --> 0.636274).  Saving model ...
	 Train_Loss: 0.6640 Train_Acc: 61.369 Val_Loss: 0.6363  BEST VAL Loss: 0.6363  Val_Acc: 71.630

Epoch 12: Validation loss decreased (0.636274 --> 0.632065).  Saving model ...
	 Train_Loss: 0.6611 Train_Acc: 62.858 Val_Loss: 0.6321  BEST VAL Loss: 0.6321  Val_Acc: 71.267

Epoch 13: Validation loss decreased (0.632065 --> 0.627843).  Saving model ...
	 Train_Loss: 0.6585 Train_Acc: 64.063 Val_Loss: 0.6278  BEST VAL Loss: 0.6278  Val_Acc: 71.953

Epoch 14: Validation loss decreased (0.627843 --> 0.624130).  Saving model ...
	 Train_Loss: 0.6561 Train_Acc: 64.452 Val_Loss: 0.6241  BEST VAL Loss: 0.6241  Val_Acc: 72.155

Epoch 15: Validation loss decreased (0.624130 --> 0.620331).  Saving model ...
	 Train_Loss: 0.6539 Train_Acc: 64.765 Val_Loss: 0.6203  BEST VAL Loss: 0.6203  Val_Acc: 72.760

Epoch 16: Validation loss decreased (0.620331 --> 0.616484).  Saving model ...
	 Train_Loss: 0.6513 Train_Acc: 65.935 Val_Loss: 0.6165  BEST VAL Loss: 0.6165  Val_Acc: 73.204

Epoch 17: Validation loss decreased (0.616484 --> 0.613146).  Saving model ...
	 Train_Loss: 0.6490 Train_Acc: 65.981 Val_Loss: 0.6131  BEST VAL Loss: 0.6131  Val_Acc: 73.446

Epoch 18: Validation loss decreased (0.613146 --> 0.609921).  Saving model ...
	 Train_Loss: 0.6467 Train_Acc: 66.445 Val_Loss: 0.6099  BEST VAL Loss: 0.6099  Val_Acc: 72.720

Epoch 19: Validation loss decreased (0.609921 --> 0.607427).  Saving model ...
	 Train_Loss: 0.6447 Train_Acc: 66.773 Val_Loss: 0.6074  BEST VAL Loss: 0.6074  Val_Acc: 72.115

Epoch 20: Validation loss decreased (0.607427 --> 0.604914).  Saving model ...
	 Train_Loss: 0.6430 Train_Acc: 66.788 Val_Loss: 0.6049  BEST VAL Loss: 0.6049  Val_Acc: 72.720

Epoch 21: Validation loss decreased (0.604914 --> 0.602421).  Saving model ...
	 Train_Loss: 0.6412 Train_Acc: 66.949 Val_Loss: 0.6024  BEST VAL Loss: 0.6024  Val_Acc: 73.729

Epoch 22: Validation loss decreased (0.602421 --> 0.599672).  Saving model ...
	 Train_Loss: 0.6397 Train_Acc: 66.616 Val_Loss: 0.5997  BEST VAL Loss: 0.5997  Val_Acc: 74.697

Epoch 23: Validation loss decreased (0.599672 --> 0.597604).  Saving model ...
	 Train_Loss: 0.6381 Train_Acc: 67.408 Val_Loss: 0.5976  BEST VAL Loss: 0.5976  Val_Acc: 74.173

Epoch 24: Validation loss decreased (0.597604 --> 0.595561).  Saving model ...
	 Train_Loss: 0.6366 Train_Acc: 67.519 Val_Loss: 0.5956  BEST VAL Loss: 0.5956  Val_Acc: 74.011

Epoch 25: Validation loss decreased (0.595561 --> 0.593470).  Saving model ...
	 Train_Loss: 0.6351 Train_Acc: 68.316 Val_Loss: 0.5935  BEST VAL Loss: 0.5935  Val_Acc: 74.617

Epoch 26: Validation loss decreased (0.593470 --> 0.591298).  Saving model ...
	 Train_Loss: 0.6338 Train_Acc: 67.489 Val_Loss: 0.5913  BEST VAL Loss: 0.5913  Val_Acc: 75.424

Epoch 27: Validation loss decreased (0.591298 --> 0.589358).  Saving model ...
	 Train_Loss: 0.6325 Train_Acc: 68.079 Val_Loss: 0.5894  BEST VAL Loss: 0.5894  Val_Acc: 74.859

Epoch 28: Validation loss decreased (0.589358 --> 0.587458).  Saving model ...
	 Train_Loss: 0.6313 Train_Acc: 67.701 Val_Loss: 0.5875  BEST VAL Loss: 0.5875  Val_Acc: 75.061

Epoch 29: Validation loss decreased (0.587458 --> 0.585431).  Saving model ...
	 Train_Loss: 0.6300 Train_Acc: 68.271 Val_Loss: 0.5854  BEST VAL Loss: 0.5854  Val_Acc: 75.141

Epoch 30: Validation loss decreased (0.585431 --> 0.583658).  Saving model ...
	 Train_Loss: 0.6286 Train_Acc: 69.038 Val_Loss: 0.5837  BEST VAL Loss: 0.5837  Val_Acc: 74.899

Epoch 31: Validation loss decreased (0.583658 --> 0.582101).  Saving model ...
	 Train_Loss: 0.6274 Train_Acc: 68.392 Val_Loss: 0.5821  BEST VAL Loss: 0.5821  Val_Acc: 75.424

Epoch 32: Validation loss decreased (0.582101 --> 0.580713).  Saving model ...
	 Train_Loss: 0.6263 Train_Acc: 68.776 Val_Loss: 0.5807  BEST VAL Loss: 0.5807  Val_Acc: 74.536

Epoch 33: Validation loss decreased (0.580713 --> 0.579214).  Saving model ...
	 Train_Loss: 0.6253 Train_Acc: 68.453 Val_Loss: 0.5792  BEST VAL Loss: 0.5792  Val_Acc: 74.697

Epoch 34: Validation loss decreased (0.579214 --> 0.577691).  Saving model ...
	 Train_Loss: 0.6241 Train_Acc: 69.214 Val_Loss: 0.5777  BEST VAL Loss: 0.5777  Val_Acc: 74.617

Epoch 35: Validation loss decreased (0.577691 --> 0.576491).  Saving model ...
	 Train_Loss: 0.6231 Train_Acc: 68.927 Val_Loss: 0.5765  BEST VAL Loss: 0.5765  Val_Acc: 74.011

Epoch 36: Validation loss decreased (0.576491 --> 0.574995).  Saving model ...
	 Train_Loss: 0.6221 Train_Acc: 68.604 Val_Loss: 0.5750  BEST VAL Loss: 0.5750  Val_Acc: 75.545

Epoch 37: Validation loss decreased (0.574995 --> 0.573665).  Saving model ...
	 Train_Loss: 0.6212 Train_Acc: 69.164 Val_Loss: 0.5737  BEST VAL Loss: 0.5737  Val_Acc: 75.948

Epoch 38: Validation loss decreased (0.573665 --> 0.572292).  Saving model ...
	 Train_Loss: 0.6203 Train_Acc: 69.209 Val_Loss: 0.5723  BEST VAL Loss: 0.5723  Val_Acc: 75.504

Epoch 39: Validation loss decreased (0.572292 --> 0.571182).  Saving model ...
	 Train_Loss: 0.6193 Train_Acc: 69.911 Val_Loss: 0.5712  BEST VAL Loss: 0.5712  Val_Acc: 76.150

Epoch 40: Validation loss decreased (0.571182 --> 0.569875).  Saving model ...
	 Train_Loss: 0.6184 Train_Acc: 69.916 Val_Loss: 0.5699  BEST VAL Loss: 0.5699  Val_Acc: 76.675

Epoch 41: Validation loss decreased (0.569875 --> 0.568764).  Saving model ...
	 Train_Loss: 0.6176 Train_Acc: 69.290 Val_Loss: 0.5688  BEST VAL Loss: 0.5688  Val_Acc: 75.948

Epoch 42: Validation loss decreased (0.568764 --> 0.567601).  Saving model ...
	 Train_Loss: 0.6168 Train_Acc: 69.310 Val_Loss: 0.5676  BEST VAL Loss: 0.5676  Val_Acc: 76.675

Epoch 43: Validation loss decreased (0.567601 --> 0.566830).  Saving model ...
	 Train_Loss: 0.6161 Train_Acc: 69.169 Val_Loss: 0.5668  BEST VAL Loss: 0.5668  Val_Acc: 75.585

Epoch 44: Validation loss decreased (0.566830 --> 0.565731).  Saving model ...
	 Train_Loss: 0.6153 Train_Acc: 70.027 Val_Loss: 0.5657  BEST VAL Loss: 0.5657  Val_Acc: 75.706

Epoch 45: Validation loss decreased (0.565731 --> 0.564675).  Saving model ...
	 Train_Loss: 0.6146 Train_Acc: 69.436 Val_Loss: 0.5647  BEST VAL Loss: 0.5647  Val_Acc: 76.150

Epoch 46: Validation loss decreased (0.564675 --> 0.563970).  Saving model ...
	 Train_Loss: 0.6139 Train_Acc: 69.537 Val_Loss: 0.5640  BEST VAL Loss: 0.5640  Val_Acc: 75.545

Epoch 47: Validation loss decreased (0.563970 --> 0.563066).  Saving model ...
	 Train_Loss: 0.6133 Train_Acc: 69.694 Val_Loss: 0.5631  BEST VAL Loss: 0.5631  Val_Acc: 75.424

Epoch 48: Validation loss decreased (0.563066 --> 0.562213).  Saving model ...
	 Train_Loss: 0.6127 Train_Acc: 69.053 Val_Loss: 0.5622  BEST VAL Loss: 0.5622  Val_Acc: 76.271

Epoch 49: Validation loss decreased (0.562213 --> 0.561359).  Saving model ...
	 Train_Loss: 0.6121 Train_Acc: 69.830 Val_Loss: 0.5614  BEST VAL Loss: 0.5614  Val_Acc: 76.473

Epoch 50: Validation loss decreased (0.561359 --> 0.560585).  Saving model ...
	 Train_Loss: 0.6114 Train_Acc: 70.445 Val_Loss: 0.5606  BEST VAL Loss: 0.5606  Val_Acc: 75.666

Epoch 51: Validation loss decreased (0.560585 --> 0.559720).  Saving model ...
	 Train_Loss: 0.6107 Train_Acc: 70.188 Val_Loss: 0.5597  BEST VAL Loss: 0.5597  Val_Acc: 76.069

Epoch 52: Validation loss decreased (0.559720 --> 0.558974).  Saving model ...
	 Train_Loss: 0.6101 Train_Acc: 70.491 Val_Loss: 0.5590  BEST VAL Loss: 0.5590  Val_Acc: 76.150

Epoch 53: Validation loss decreased (0.558974 --> 0.558330).  Saving model ...
	 Train_Loss: 0.6095 Train_Acc: 69.885 Val_Loss: 0.5583  BEST VAL Loss: 0.5583  Val_Acc: 75.948

Epoch 54: Validation loss decreased (0.558330 --> 0.557637).  Saving model ...
	 Train_Loss: 0.6089 Train_Acc: 70.365 Val_Loss: 0.5576  BEST VAL Loss: 0.5576  Val_Acc: 76.271

Epoch 55: Validation loss decreased (0.557637 --> 0.556895).  Saving model ...
	 Train_Loss: 0.6083 Train_Acc: 70.077 Val_Loss: 0.5569  BEST VAL Loss: 0.5569  Val_Acc: 76.957

Epoch 56: Validation loss decreased (0.556895 --> 0.556409).  Saving model ...
	 Train_Loss: 0.6078 Train_Acc: 70.032 Val_Loss: 0.5564  BEST VAL Loss: 0.5564  Val_Acc: 75.303

Epoch 57: Validation loss decreased (0.556409 --> 0.555686).  Saving model ...
	 Train_Loss: 0.6073 Train_Acc: 70.556 Val_Loss: 0.5557  BEST VAL Loss: 0.5557  Val_Acc: 76.634

Epoch 58: Validation loss decreased (0.555686 --> 0.555031).  Saving model ...
	 Train_Loss: 0.6067 Train_Acc: 70.456 Val_Loss: 0.5550  BEST VAL Loss: 0.5550  Val_Acc: 76.836

Epoch 59: Validation loss decreased (0.555031 --> 0.554405).  Saving model ...
	 Train_Loss: 0.6062 Train_Acc: 70.259 Val_Loss: 0.5544  BEST VAL Loss: 0.5544  Val_Acc: 76.796

Epoch 60: Validation loss decreased (0.554405 --> 0.553727).  Saving model ...
	 Train_Loss: 0.6056 Train_Acc: 70.632 Val_Loss: 0.5537  BEST VAL Loss: 0.5537  Val_Acc: 76.271

Epoch 61: Validation loss decreased (0.553727 --> 0.553201).  Saving model ...
	 Train_Loss: 0.6051 Train_Acc: 70.456 Val_Loss: 0.5532  BEST VAL Loss: 0.5532  Val_Acc: 76.554

Epoch 62: Validation loss decreased (0.553201 --> 0.552592).  Saving model ...
	 Train_Loss: 0.6046 Train_Acc: 70.425 Val_Loss: 0.5526  BEST VAL Loss: 0.5526  Val_Acc: 76.675

Epoch 63: Validation loss decreased (0.552592 --> 0.552179).  Saving model ...
	 Train_Loss: 0.6042 Train_Acc: 70.405 Val_Loss: 0.5522  BEST VAL Loss: 0.5522  Val_Acc: 75.948

Epoch 64: Validation loss decreased (0.552179 --> 0.551663).  Saving model ...
	 Train_Loss: 0.6037 Train_Acc: 70.556 Val_Loss: 0.5517  BEST VAL Loss: 0.5517  Val_Acc: 76.392

Epoch 65: Validation loss decreased (0.551663 --> 0.551225).  Saving model ...
	 Train_Loss: 0.6033 Train_Acc: 70.249 Val_Loss: 0.5512  BEST VAL Loss: 0.5512  Val_Acc: 75.626

Epoch 66: Validation loss decreased (0.551225 --> 0.550826).  Saving model ...
	 Train_Loss: 0.6029 Train_Acc: 70.067 Val_Loss: 0.5508  BEST VAL Loss: 0.5508  Val_Acc: 76.796

Epoch 67: Validation loss decreased (0.550826 --> 0.550346).  Saving model ...
	 Train_Loss: 0.6024 Train_Acc: 70.975 Val_Loss: 0.5503  BEST VAL Loss: 0.5503  Val_Acc: 76.715

Epoch 68: Validation loss decreased (0.550346 --> 0.549855).  Saving model ...
	 Train_Loss: 0.6020 Train_Acc: 70.551 Val_Loss: 0.5499  BEST VAL Loss: 0.5499  Val_Acc: 76.513

Epoch 69: Validation loss decreased (0.549855 --> 0.549433).  Saving model ...
	 Train_Loss: 0.6015 Train_Acc: 70.334 Val_Loss: 0.5494  BEST VAL Loss: 0.5494  Val_Acc: 76.513

Epoch 70: Validation loss decreased (0.549433 --> 0.549004).  Saving model ...
	 Train_Loss: 0.6011 Train_Acc: 70.940 Val_Loss: 0.5490  BEST VAL Loss: 0.5490  Val_Acc: 76.433

Epoch 71: Validation loss decreased (0.549004 --> 0.548654).  Saving model ...
	 Train_Loss: 0.6007 Train_Acc: 70.683 Val_Loss: 0.5487  BEST VAL Loss: 0.5487  Val_Acc: 76.069

Epoch 72: Validation loss decreased (0.548654 --> 0.548266).  Saving model ...
	 Train_Loss: 0.6003 Train_Acc: 70.244 Val_Loss: 0.5483  BEST VAL Loss: 0.5483  Val_Acc: 75.908

Epoch 73: Validation loss decreased (0.548266 --> 0.547733).  Saving model ...
	 Train_Loss: 0.5999 Train_Acc: 71.202 Val_Loss: 0.5477  BEST VAL Loss: 0.5477  Val_Acc: 76.312

Epoch 74: Validation loss decreased (0.547733 --> 0.547295).  Saving model ...
	 Train_Loss: 0.5995 Train_Acc: 70.708 Val_Loss: 0.5473  BEST VAL Loss: 0.5473  Val_Acc: 76.433

Epoch 75: Validation loss decreased (0.547295 --> 0.546967).  Saving model ...
	 Train_Loss: 0.5991 Train_Acc: 70.723 Val_Loss: 0.5470  BEST VAL Loss: 0.5470  Val_Acc: 75.827

Epoch 76: Validation loss decreased (0.546967 --> 0.546526).  Saving model ...
	 Train_Loss: 0.5988 Train_Acc: 70.753 Val_Loss: 0.5465  BEST VAL Loss: 0.5465  Val_Acc: 76.312

Epoch 77: Validation loss decreased (0.546526 --> 0.546148).  Saving model ...
	 Train_Loss: 0.5984 Train_Acc: 70.652 Val_Loss: 0.5461  BEST VAL Loss: 0.5461  Val_Acc: 76.352

Epoch 78: Validation loss decreased (0.546148 --> 0.545667).  Saving model ...
	 Train_Loss: 0.5980 Train_Acc: 70.869 Val_Loss: 0.5457  BEST VAL Loss: 0.5457  Val_Acc: 77.038

Epoch 79: Validation loss decreased (0.545667 --> 0.545293).  Saving model ...
	 Train_Loss: 0.5976 Train_Acc: 71.545 Val_Loss: 0.5453  BEST VAL Loss: 0.5453  Val_Acc: 76.150

Epoch 80: Validation loss decreased (0.545293 --> 0.544945).  Saving model ...
	 Train_Loss: 0.5973 Train_Acc: 70.370 Val_Loss: 0.5449  BEST VAL Loss: 0.5449  Val_Acc: 76.877

Epoch 81: Validation loss decreased (0.544945 --> 0.544592).  Saving model ...
	 Train_Loss: 0.5970 Train_Acc: 70.844 Val_Loss: 0.5446  BEST VAL Loss: 0.5446  Val_Acc: 76.312

Epoch 82: Validation loss decreased (0.544592 --> 0.544215).  Saving model ...
	 Train_Loss: 0.5967 Train_Acc: 70.980 Val_Loss: 0.5442  BEST VAL Loss: 0.5442  Val_Acc: 76.917

Epoch 83: Validation loss decreased (0.544215 --> 0.543872).  Saving model ...
	 Train_Loss: 0.5964 Train_Acc: 70.789 Val_Loss: 0.5439  BEST VAL Loss: 0.5439  Val_Acc: 76.190

Epoch 84: Validation loss decreased (0.543872 --> 0.543560).  Saving model ...
	 Train_Loss: 0.5960 Train_Acc: 71.167 Val_Loss: 0.5436  BEST VAL Loss: 0.5436  Val_Acc: 76.594

Epoch 85: Validation loss decreased (0.543560 --> 0.543275).  Saving model ...
	 Train_Loss: 0.5957 Train_Acc: 70.794 Val_Loss: 0.5433  BEST VAL Loss: 0.5433  Val_Acc: 76.957

Epoch 86: Validation loss decreased (0.543275 --> 0.542991).  Saving model ...
	 Train_Loss: 0.5954 Train_Acc: 71.338 Val_Loss: 0.5430  BEST VAL Loss: 0.5430  Val_Acc: 76.836

Epoch 87: Validation loss decreased (0.542991 --> 0.542669).  Saving model ...
	 Train_Loss: 0.5950 Train_Acc: 71.308 Val_Loss: 0.5427  BEST VAL Loss: 0.5427  Val_Acc: 77.482

Epoch 88: Validation loss decreased (0.542669 --> 0.542382).  Saving model ...
	 Train_Loss: 0.5947 Train_Acc: 71.101 Val_Loss: 0.5424  BEST VAL Loss: 0.5424  Val_Acc: 76.554

Epoch 89: Validation loss decreased (0.542382 --> 0.542058).  Saving model ...
	 Train_Loss: 0.5945 Train_Acc: 70.874 Val_Loss: 0.5421  BEST VAL Loss: 0.5421  Val_Acc: 76.594

Epoch 90: Validation loss decreased (0.542058 --> 0.541747).  Saving model ...
	 Train_Loss: 0.5942 Train_Acc: 70.814 Val_Loss: 0.5417  BEST VAL Loss: 0.5417  Val_Acc: 76.433

Epoch 91: Validation loss decreased (0.541747 --> 0.541410).  Saving model ...
	 Train_Loss: 0.5939 Train_Acc: 71.429 Val_Loss: 0.5414  BEST VAL Loss: 0.5414  Val_Acc: 76.836

Epoch 92: Validation loss decreased (0.541410 --> 0.541134).  Saving model ...
	 Train_Loss: 0.5936 Train_Acc: 71.021 Val_Loss: 0.5411  BEST VAL Loss: 0.5411  Val_Acc: 76.715

Epoch 93: Validation loss decreased (0.541134 --> 0.540865).  Saving model ...
	 Train_Loss: 0.5933 Train_Acc: 70.990 Val_Loss: 0.5409  BEST VAL Loss: 0.5409  Val_Acc: 76.433

Epoch 94: Validation loss decreased (0.540865 --> 0.540520).  Saving model ...
	 Train_Loss: 0.5930 Train_Acc: 71.227 Val_Loss: 0.5405  BEST VAL Loss: 0.5405  Val_Acc: 76.998

Epoch 95: Validation loss decreased (0.540520 --> 0.540252).  Saving model ...
	 Train_Loss: 0.5927 Train_Acc: 71.293 Val_Loss: 0.5403  BEST VAL Loss: 0.5403  Val_Acc: 76.634

Epoch 96: Validation loss decreased (0.540252 --> 0.539921).  Saving model ...
	 Train_Loss: 0.5925 Train_Acc: 70.738 Val_Loss: 0.5399  BEST VAL Loss: 0.5399  Val_Acc: 77.724

Epoch 97: Validation loss decreased (0.539921 --> 0.539667).  Saving model ...
	 Train_Loss: 0.5922 Train_Acc: 71.434 Val_Loss: 0.5397  BEST VAL Loss: 0.5397  Val_Acc: 77.240

Epoch 98: Validation loss decreased (0.539667 --> 0.539390).  Saving model ...
	 Train_Loss: 0.5920 Train_Acc: 71.152 Val_Loss: 0.5394  BEST VAL Loss: 0.5394  Val_Acc: 77.038

Epoch 99: Validation loss decreased (0.539390 --> 0.539155).  Saving model ...
	 Train_Loss: 0.5917 Train_Acc: 71.566 Val_Loss: 0.5392  BEST VAL Loss: 0.5392  Val_Acc: 76.917

LPS_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.83      0.80      0.81      9707
           1       0.81      0.85      0.83     10114

    accuracy                           0.82     19821
   macro avg       0.82      0.82      0.82     19821
weighted avg       0.82      0.82      0.82     19821

LPS_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.79      0.73      0.75      1214
           1       0.75      0.81      0.78      1264

    accuracy                           0.77      2478
   macro avg       0.77      0.77      0.77      2478
weighted avg       0.77      0.77      0.77      2478

LPS_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.79      0.73      0.76      1214
           1       0.76      0.81      0.78      1264

    accuracy                           0.77      2478
   macro avg       0.77      0.77      0.77      2478
weighted avg       0.77      0.77      0.77      2478

              precision    recall  f1-score   support

           0       0.79      0.73      0.76      1214
           1       0.76      0.81      0.78      1264

    accuracy                           0.77      2478
   macro avg       0.77      0.77      0.77      2478
weighted avg       0.77      0.77      0.77      2478

LPS_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.75      0.69      0.72      3724
           1       0.74      0.79      0.77      4168

    accuracy                           0.74      7892
   macro avg       0.74      0.74      0.74      7892
weighted avg       0.74      0.74      0.74      7892

              precision    recall  f1-score   support

           0       0.75      0.69      0.72      3724
           1       0.74      0.79      0.77      4168

    accuracy                           0.74      7892
   macro avg       0.74      0.74      0.74      7892
weighted avg       0.74      0.74      0.74      7892

completed
