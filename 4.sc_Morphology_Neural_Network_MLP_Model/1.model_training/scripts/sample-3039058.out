[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'f4fe158d'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '9e0ade06'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '8a1995f1'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '80542a9c'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (312858, 1270)
Number of total missing values across all columns: 277194
Data Subset Is Off
Wells held out for testing: ['C09' 'L09']
Wells to use for training, validation, and testing ['C02' 'C03' 'C08' 'L02' 'L03' 'L08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.222649).  Saving model ...
	 Train_Loss: 0.3746 Train_Acc: 84.685 Val_Loss: 0.2226  BEST VAL Loss: 0.2226  Val_Acc: 91.627

Epoch 1: Validation loss decreased (0.222649 --> 0.214831).  Saving model ...
	 Train_Loss: 0.3227 Train_Acc: 89.552 Val_Loss: 0.2148  BEST VAL Loss: 0.2148  Val_Acc: 92.070

Epoch 2: Validation loss decreased (0.214831 --> 0.209949).  Saving model ...
	 Train_Loss: 0.2985 Train_Acc: 90.613 Val_Loss: 0.2099  BEST VAL Loss: 0.2099  Val_Acc: 92.433

Epoch 3: Validation loss decreased (0.209949 --> 0.204825).  Saving model ...
	 Train_Loss: 0.2840 Train_Acc: 91.021 Val_Loss: 0.2048  BEST VAL Loss: 0.2048  Val_Acc: 93.231

Epoch 4: Validation loss decreased (0.204825 --> 0.200507).  Saving model ...
	 Train_Loss: 0.2734 Train_Acc: 91.299 Val_Loss: 0.2005  BEST VAL Loss: 0.2005  Val_Acc: 93.252

Epoch 5: Validation loss did not decrease
	 Train_Loss: 0.2662 Train_Acc: 91.325 Val_Loss: 0.2006  BEST VAL Loss: 0.2005  Val_Acc: 93.117

Epoch 6: Validation loss decreased (0.200507 --> 0.196408).  Saving model ...
	 Train_Loss: 0.2606 Train_Acc: 91.481 Val_Loss: 0.1964  BEST VAL Loss: 0.1964  Val_Acc: 93.459

Epoch 7: Validation loss decreased (0.196408 --> 0.193466).  Saving model ...
	 Train_Loss: 0.2562 Train_Acc: 91.535 Val_Loss: 0.1935  BEST VAL Loss: 0.1935  Val_Acc: 93.357

Epoch 8: Validation loss decreased (0.193466 --> 0.190796).  Saving model ...
	 Train_Loss: 0.2526 Train_Acc: 91.569 Val_Loss: 0.1908  BEST VAL Loss: 0.1908  Val_Acc: 93.564

Epoch 9: Validation loss decreased (0.190796 --> 0.189247).  Saving model ...
	 Train_Loss: 0.2498 Train_Acc: 91.564 Val_Loss: 0.1892  BEST VAL Loss: 0.1892  Val_Acc: 93.357

Epoch 10: Validation loss decreased (0.189247 --> 0.187937).  Saving model ...
	 Train_Loss: 0.2473 Train_Acc: 91.640 Val_Loss: 0.1879  BEST VAL Loss: 0.1879  Val_Acc: 93.446

Epoch 11: Validation loss decreased (0.187937 --> 0.187502).  Saving model ...
	 Train_Loss: 0.2452 Train_Acc: 91.582 Val_Loss: 0.1875  BEST VAL Loss: 0.1875  Val_Acc: 93.543

Epoch 12: Validation loss decreased (0.187502 --> 0.186014).  Saving model ...
	 Train_Loss: 0.2433 Train_Acc: 91.699 Val_Loss: 0.1860  BEST VAL Loss: 0.1860  Val_Acc: 93.551

Epoch 13: Validation loss decreased (0.186014 --> 0.185238).  Saving model ...
	 Train_Loss: 0.2416 Train_Acc: 91.713 Val_Loss: 0.1852  BEST VAL Loss: 0.1852  Val_Acc: 93.577

Epoch 14: Validation loss decreased (0.185238 --> 0.184282).  Saving model ...
	 Train_Loss: 0.2401 Train_Acc: 91.726 Val_Loss: 0.1843  BEST VAL Loss: 0.1843  Val_Acc: 93.695

Epoch 15: Validation loss decreased (0.184282 --> 0.183630).  Saving model ...
	 Train_Loss: 0.2388 Train_Acc: 91.761 Val_Loss: 0.1836  BEST VAL Loss: 0.1836  Val_Acc: 93.307

Epoch 16: Validation loss decreased (0.183630 --> 0.183177).  Saving model ...
	 Train_Loss: 0.2375 Train_Acc: 91.805 Val_Loss: 0.1832  BEST VAL Loss: 0.1832  Val_Acc: 93.657

Epoch 17: Validation loss decreased (0.183177 --> 0.182182).  Saving model ...
	 Train_Loss: 0.2365 Train_Acc: 91.800 Val_Loss: 0.1822  BEST VAL Loss: 0.1822  Val_Acc: 93.539

Epoch 18: Validation loss decreased (0.182182 --> 0.181369).  Saving model ...
	 Train_Loss: 0.2356 Train_Acc: 91.649 Val_Loss: 0.1814  BEST VAL Loss: 0.1814  Val_Acc: 93.708

Epoch 19: Validation loss did not decrease
	 Train_Loss: 0.2346 Train_Acc: 91.885 Val_Loss: 0.1823  BEST VAL Loss: 0.1814  Val_Acc: 92.699

Epoch 20: Validation loss did not decrease
	 Train_Loss: 0.2337 Train_Acc: 91.906 Val_Loss: 0.1817  BEST VAL Loss: 0.1814  Val_Acc: 93.712

Epoch 21: Validation loss decreased (0.181369 --> 0.180899).  Saving model ...
	 Train_Loss: 0.2330 Train_Acc: 91.737 Val_Loss: 0.1809  BEST VAL Loss: 0.1809  Val_Acc: 93.758

Epoch 22: Validation loss decreased (0.180899 --> 0.180101).  Saving model ...
	 Train_Loss: 0.2323 Train_Acc: 91.828 Val_Loss: 0.1801  BEST VAL Loss: 0.1801  Val_Acc: 93.594

Epoch 23: Validation loss decreased (0.180101 --> 0.179790).  Saving model ...
	 Train_Loss: 0.2316 Train_Acc: 91.878 Val_Loss: 0.1798  BEST VAL Loss: 0.1798  Val_Acc: 93.817

Epoch 24: Validation loss decreased (0.179790 --> 0.179195).  Saving model ...
	 Train_Loss: 0.2310 Train_Acc: 91.870 Val_Loss: 0.1792  BEST VAL Loss: 0.1792  Val_Acc: 93.602

Epoch 25: Validation loss decreased (0.179195 --> 0.179141).  Saving model ...
	 Train_Loss: 0.2303 Train_Acc: 91.949 Val_Loss: 0.1791  BEST VAL Loss: 0.1791  Val_Acc: 93.378

Epoch 26: Validation loss decreased (0.179141 --> 0.178649).  Saving model ...
	 Train_Loss: 0.2297 Train_Acc: 92.019 Val_Loss: 0.1786  BEST VAL Loss: 0.1786  Val_Acc: 93.746

Epoch 27: Validation loss decreased (0.178649 --> 0.178097).  Saving model ...
	 Train_Loss: 0.2292 Train_Acc: 91.907 Val_Loss: 0.1781  BEST VAL Loss: 0.1781  Val_Acc: 93.788

Epoch 28: Validation loss decreased (0.178097 --> 0.177547).  Saving model ...
	 Train_Loss: 0.2286 Train_Acc: 91.991 Val_Loss: 0.1775  BEST VAL Loss: 0.1775  Val_Acc: 93.813

Epoch 29: Validation loss decreased (0.177547 --> 0.177116).  Saving model ...
	 Train_Loss: 0.2281 Train_Acc: 92.009 Val_Loss: 0.1771  BEST VAL Loss: 0.1771  Val_Acc: 93.796

Epoch 30: Validation loss decreased (0.177116 --> 0.176657).  Saving model ...
	 Train_Loss: 0.2277 Train_Acc: 91.946 Val_Loss: 0.1767  BEST VAL Loss: 0.1767  Val_Acc: 93.923

Epoch 31: Validation loss decreased (0.176657 --> 0.176290).  Saving model ...
	 Train_Loss: 0.2272 Train_Acc: 92.113 Val_Loss: 0.1763  BEST VAL Loss: 0.1763  Val_Acc: 93.944

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.2267 Train_Acc: 92.114 Val_Loss: 0.1765  BEST VAL Loss: 0.1763  Val_Acc: 93.754

Epoch 33: Validation loss decreased (0.176290 --> 0.176095).  Saving model ...
	 Train_Loss: 0.2263 Train_Acc: 92.046 Val_Loss: 0.1761  BEST VAL Loss: 0.1761  Val_Acc: 93.902

Epoch 34: Validation loss decreased (0.176095 --> 0.175738).  Saving model ...
	 Train_Loss: 0.2258 Train_Acc: 92.076 Val_Loss: 0.1757  BEST VAL Loss: 0.1757  Val_Acc: 93.805

Epoch 35: Validation loss decreased (0.175738 --> 0.175261).  Saving model ...
	 Train_Loss: 0.2254 Train_Acc: 92.089 Val_Loss: 0.1753  BEST VAL Loss: 0.1753  Val_Acc: 93.864

Epoch 36: Validation loss decreased (0.175261 --> 0.174948).  Saving model ...
	 Train_Loss: 0.2250 Train_Acc: 92.041 Val_Loss: 0.1749  BEST VAL Loss: 0.1749  Val_Acc: 93.610

Epoch 37: Validation loss decreased (0.174948 --> 0.174681).  Saving model ...
	 Train_Loss: 0.2246 Train_Acc: 92.118 Val_Loss: 0.1747  BEST VAL Loss: 0.1747  Val_Acc: 93.678

Epoch 38: Validation loss decreased (0.174681 --> 0.174578).  Saving model ...
	 Train_Loss: 0.2243 Train_Acc: 92.044 Val_Loss: 0.1746  BEST VAL Loss: 0.1746  Val_Acc: 93.796

Epoch 39: Validation loss decreased (0.174578 --> 0.174475).  Saving model ...
	 Train_Loss: 0.2240 Train_Acc: 92.083 Val_Loss: 0.1745  BEST VAL Loss: 0.1745  Val_Acc: 93.881

Epoch 40: Validation loss decreased (0.174475 --> 0.174195).  Saving model ...
	 Train_Loss: 0.2236 Train_Acc: 92.155 Val_Loss: 0.1742  BEST VAL Loss: 0.1742  Val_Acc: 93.872

Epoch 41: Validation loss decreased (0.174195 --> 0.173977).  Saving model ...
	 Train_Loss: 0.2233 Train_Acc: 92.195 Val_Loss: 0.1740  BEST VAL Loss: 0.1740  Val_Acc: 93.881

Epoch 42: Validation loss decreased (0.173977 --> 0.173809).  Saving model ...
	 Train_Loss: 0.2229 Train_Acc: 92.153 Val_Loss: 0.1738  BEST VAL Loss: 0.1738  Val_Acc: 93.889

Epoch 43: Validation loss decreased (0.173809 --> 0.173578).  Saving model ...
	 Train_Loss: 0.2226 Train_Acc: 92.232 Val_Loss: 0.1736  BEST VAL Loss: 0.1736  Val_Acc: 93.838

Epoch 44: Validation loss decreased (0.173578 --> 0.173444).  Saving model ...
	 Train_Loss: 0.2223 Train_Acc: 92.062 Val_Loss: 0.1734  BEST VAL Loss: 0.1734  Val_Acc: 93.902

Epoch 45: Validation loss decreased (0.173444 --> 0.173298).  Saving model ...
	 Train_Loss: 0.2221 Train_Acc: 92.167 Val_Loss: 0.1733  BEST VAL Loss: 0.1733  Val_Acc: 93.843

Epoch 46: Validation loss decreased (0.173298 --> 0.173113).  Saving model ...
	 Train_Loss: 0.2217 Train_Acc: 92.204 Val_Loss: 0.1731  BEST VAL Loss: 0.1731  Val_Acc: 93.868

Epoch 47: Validation loss decreased (0.173113 --> 0.172924).  Saving model ...
	 Train_Loss: 0.2215 Train_Acc: 92.273 Val_Loss: 0.1729  BEST VAL Loss: 0.1729  Val_Acc: 93.999

Epoch 48: Validation loss decreased (0.172924 --> 0.172762).  Saving model ...
	 Train_Loss: 0.2212 Train_Acc: 92.210 Val_Loss: 0.1728  BEST VAL Loss: 0.1728  Val_Acc: 93.982

Epoch 49: Validation loss decreased (0.172762 --> 0.172581).  Saving model ...
	 Train_Loss: 0.2209 Train_Acc: 92.188 Val_Loss: 0.1726  BEST VAL Loss: 0.1726  Val_Acc: 93.902

Epoch 50: Validation loss decreased (0.172581 --> 0.172408).  Saving model ...
	 Train_Loss: 0.2207 Train_Acc: 92.256 Val_Loss: 0.1724  BEST VAL Loss: 0.1724  Val_Acc: 93.978

Epoch 51: Validation loss decreased (0.172408 --> 0.172217).  Saving model ...
	 Train_Loss: 0.2204 Train_Acc: 92.262 Val_Loss: 0.1722  BEST VAL Loss: 0.1722  Val_Acc: 93.969

Epoch 52: Validation loss decreased (0.172217 --> 0.172052).  Saving model ...
	 Train_Loss: 0.2202 Train_Acc: 92.265 Val_Loss: 0.1721  BEST VAL Loss: 0.1721  Val_Acc: 93.602

Epoch 53: Validation loss decreased (0.172052 --> 0.171892).  Saving model ...
	 Train_Loss: 0.2199 Train_Acc: 92.288 Val_Loss: 0.1719  BEST VAL Loss: 0.1719  Val_Acc: 94.016

Epoch 54: Validation loss decreased (0.171892 --> 0.171751).  Saving model ...
	 Train_Loss: 0.2197 Train_Acc: 92.179 Val_Loss: 0.1718  BEST VAL Loss: 0.1718  Val_Acc: 93.957

Epoch 55: Validation loss decreased (0.171751 --> 0.171645).  Saving model ...
	 Train_Loss: 0.2195 Train_Acc: 92.111 Val_Loss: 0.1716  BEST VAL Loss: 0.1716  Val_Acc: 94.003

Epoch 56: Validation loss decreased (0.171645 --> 0.171417).  Saving model ...
	 Train_Loss: 0.2193 Train_Acc: 92.160 Val_Loss: 0.1714  BEST VAL Loss: 0.1714  Val_Acc: 94.146

Epoch 57: Validation loss decreased (0.171417 --> 0.171258).  Saving model ...
	 Train_Loss: 0.2191 Train_Acc: 92.265 Val_Loss: 0.1713  BEST VAL Loss: 0.1713  Val_Acc: 93.935

Epoch 58: Validation loss decreased (0.171258 --> 0.171142).  Saving model ...
	 Train_Loss: 0.2188 Train_Acc: 92.283 Val_Loss: 0.1711  BEST VAL Loss: 0.1711  Val_Acc: 93.973

Epoch 59: Validation loss decreased (0.171142 --> 0.170944).  Saving model ...
	 Train_Loss: 0.2186 Train_Acc: 92.419 Val_Loss: 0.1709  BEST VAL Loss: 0.1709  Val_Acc: 94.062

Epoch 60: Validation loss decreased (0.170944 --> 0.170712).  Saving model ...
	 Train_Loss: 0.2184 Train_Acc: 92.378 Val_Loss: 0.1707  BEST VAL Loss: 0.1707  Val_Acc: 94.248

Epoch 61: Validation loss decreased (0.170712 --> 0.170596).  Saving model ...
	 Train_Loss: 0.2182 Train_Acc: 92.290 Val_Loss: 0.1706  BEST VAL Loss: 0.1706  Val_Acc: 94.003

Epoch 62: Validation loss decreased (0.170596 --> 0.170506).  Saving model ...
	 Train_Loss: 0.2180 Train_Acc: 92.313 Val_Loss: 0.1705  BEST VAL Loss: 0.1705  Val_Acc: 94.016

Epoch 63: Validation loss decreased (0.170506 --> 0.170485).  Saving model ...
	 Train_Loss: 0.2178 Train_Acc: 92.302 Val_Loss: 0.1705  BEST VAL Loss: 0.1705  Val_Acc: 93.741

Epoch 64: Validation loss decreased (0.170485 --> 0.170339).  Saving model ...
	 Train_Loss: 0.2176 Train_Acc: 92.282 Val_Loss: 0.1703  BEST VAL Loss: 0.1703  Val_Acc: 93.919

Epoch 65: Validation loss decreased (0.170339 --> 0.170236).  Saving model ...
	 Train_Loss: 0.2174 Train_Acc: 92.398 Val_Loss: 0.1702  BEST VAL Loss: 0.1702  Val_Acc: 94.130

Epoch 66: Validation loss decreased (0.170236 --> 0.170058).  Saving model ...
	 Train_Loss: 0.2173 Train_Acc: 92.301 Val_Loss: 0.1701  BEST VAL Loss: 0.1701  Val_Acc: 94.037

Epoch 67: Validation loss decreased (0.170058 --> 0.169907).  Saving model ...
	 Train_Loss: 0.2171 Train_Acc: 92.258 Val_Loss: 0.1699  BEST VAL Loss: 0.1699  Val_Acc: 94.134

Epoch 68: Validation loss decreased (0.169907 --> 0.169708).  Saving model ...
	 Train_Loss: 0.2170 Train_Acc: 92.288 Val_Loss: 0.1697  BEST VAL Loss: 0.1697  Val_Acc: 94.121

Epoch 69: Validation loss decreased (0.169708 --> 0.169568).  Saving model ...
	 Train_Loss: 0.2168 Train_Acc: 92.338 Val_Loss: 0.1696  BEST VAL Loss: 0.1696  Val_Acc: 94.020

Epoch 70: Validation loss decreased (0.169568 --> 0.169397).  Saving model ...
	 Train_Loss: 0.2167 Train_Acc: 92.284 Val_Loss: 0.1694  BEST VAL Loss: 0.1694  Val_Acc: 93.973

Epoch 71: Validation loss decreased (0.169397 --> 0.169224).  Saving model ...
	 Train_Loss: 0.2165 Train_Acc: 92.356 Val_Loss: 0.1692  BEST VAL Loss: 0.1692  Val_Acc: 93.940

Epoch 72: Validation loss decreased (0.169224 --> 0.169127).  Saving model ...
	 Train_Loss: 0.2163 Train_Acc: 92.332 Val_Loss: 0.1691  BEST VAL Loss: 0.1691  Val_Acc: 94.104

Epoch 73: Validation loss decreased (0.169127 --> 0.168943).  Saving model ...
	 Train_Loss: 0.2162 Train_Acc: 92.230 Val_Loss: 0.1689  BEST VAL Loss: 0.1689  Val_Acc: 94.142

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.2161 Train_Acc: 92.320 Val_Loss: 0.1690  BEST VAL Loss: 0.1689  Val_Acc: 94.054

Epoch 75: Validation loss decreased (0.168943 --> 0.168929).  Saving model ...
	 Train_Loss: 0.2159 Train_Acc: 92.454 Val_Loss: 0.1689  BEST VAL Loss: 0.1689  Val_Acc: 94.227

Epoch 76: Validation loss decreased (0.168929 --> 0.168905).  Saving model ...
	 Train_Loss: 0.2158 Train_Acc: 92.440 Val_Loss: 0.1689  BEST VAL Loss: 0.1689  Val_Acc: 93.931

Epoch 77: Validation loss decreased (0.168905 --> 0.168769).  Saving model ...
	 Train_Loss: 0.2157 Train_Acc: 92.280 Val_Loss: 0.1688  BEST VAL Loss: 0.1688  Val_Acc: 93.931

Epoch 78: Validation loss decreased (0.168769 --> 0.168665).  Saving model ...
	 Train_Loss: 0.2155 Train_Acc: 92.360 Val_Loss: 0.1687  BEST VAL Loss: 0.1687  Val_Acc: 93.919

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.2154 Train_Acc: 92.256 Val_Loss: 0.1687  BEST VAL Loss: 0.1687  Val_Acc: 94.016

Epoch 80: Validation loss decreased (0.168665 --> 0.168613).  Saving model ...
	 Train_Loss: 0.2153 Train_Acc: 92.368 Val_Loss: 0.1686  BEST VAL Loss: 0.1686  Val_Acc: 94.176

Epoch 81: Validation loss decreased (0.168613 --> 0.168531).  Saving model ...
	 Train_Loss: 0.2151 Train_Acc: 92.325 Val_Loss: 0.1685  BEST VAL Loss: 0.1685  Val_Acc: 94.125

Epoch 82: Validation loss decreased (0.168531 --> 0.168467).  Saving model ...
	 Train_Loss: 0.2150 Train_Acc: 92.205 Val_Loss: 0.1685  BEST VAL Loss: 0.1685  Val_Acc: 94.214

Epoch 83: Validation loss decreased (0.168467 --> 0.168375).  Saving model ...
	 Train_Loss: 0.2149 Train_Acc: 92.314 Val_Loss: 0.1684  BEST VAL Loss: 0.1684  Val_Acc: 93.767

Epoch 84: Validation loss decreased (0.168375 --> 0.168240).  Saving model ...
	 Train_Loss: 0.2148 Train_Acc: 92.276 Val_Loss: 0.1682  BEST VAL Loss: 0.1682  Val_Acc: 93.940

Epoch 85: Validation loss decreased (0.168240 --> 0.168222).  Saving model ...
	 Train_Loss: 0.2147 Train_Acc: 92.404 Val_Loss: 0.1682  BEST VAL Loss: 0.1682  Val_Acc: 93.847

Epoch 86: Validation loss decreased (0.168222 --> 0.168155).  Saving model ...
	 Train_Loss: 0.2146 Train_Acc: 92.348 Val_Loss: 0.1682  BEST VAL Loss: 0.1682  Val_Acc: 93.821

Epoch 87: Validation loss decreased (0.168155 --> 0.168093).  Saving model ...
	 Train_Loss: 0.2145 Train_Acc: 92.154 Val_Loss: 0.1681  BEST VAL Loss: 0.1681  Val_Acc: 93.973

Epoch 88: Validation loss decreased (0.168093 --> 0.168001).  Saving model ...
	 Train_Loss: 0.2144 Train_Acc: 92.252 Val_Loss: 0.1680  BEST VAL Loss: 0.1680  Val_Acc: 93.881

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.2143 Train_Acc: 92.425 Val_Loss: 0.1681  BEST VAL Loss: 0.1680  Val_Acc: 93.623

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.2142 Train_Acc: 92.256 Val_Loss: 0.1681  BEST VAL Loss: 0.1680  Val_Acc: 94.003

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.2142 Train_Acc: 92.195 Val_Loss: 0.1680  BEST VAL Loss: 0.1680  Val_Acc: 93.990

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.2141 Train_Acc: 92.252 Val_Loss: 0.1681  BEST VAL Loss: 0.1680  Val_Acc: 93.910

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.2140 Train_Acc: 92.452 Val_Loss: 0.1681  BEST VAL Loss: 0.1680  Val_Acc: 94.168

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.2139 Train_Acc: 92.411 Val_Loss: 0.1680  BEST VAL Loss: 0.1680  Val_Acc: 94.151

Epoch 95: Validation loss decreased (0.168001 --> 0.167981).  Saving model ...
	 Train_Loss: 0.2138 Train_Acc: 92.499 Val_Loss: 0.1680  BEST VAL Loss: 0.1680  Val_Acc: 93.893

Epoch 96: Validation loss decreased (0.167981 --> 0.167937).  Saving model ...
	 Train_Loss: 0.2136 Train_Acc: 92.543 Val_Loss: 0.1679  BEST VAL Loss: 0.1679  Val_Acc: 94.058

Epoch 97: Validation loss decreased (0.167937 --> 0.167884).  Saving model ...
	 Train_Loss: 0.2135 Train_Acc: 92.423 Val_Loss: 0.1679  BEST VAL Loss: 0.1679  Val_Acc: 94.037

Epoch 98: Validation loss decreased (0.167884 --> 0.167802).  Saving model ...
	 Train_Loss: 0.2134 Train_Acc: 92.522 Val_Loss: 0.1678  BEST VAL Loss: 0.1678  Val_Acc: 94.083

Epoch 99: Validation loss decreased (0.167802 --> 0.167734).  Saving model ...
	 Train_Loss: 0.2133 Train_Acc: 92.491 Val_Loss: 0.1677  BEST VAL Loss: 0.1677  Val_Acc: 94.273

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.94      0.94      0.94     80324
           1       0.95      0.95      0.95    109228

    accuracy                           0.95    189552
   macro avg       0.95      0.95      0.95    189552
weighted avg       0.95      0.95      0.95    189552

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.94      0.93     10041
           1       0.95      0.95      0.95     13654

    accuracy                           0.94     23695
   macro avg       0.94      0.94      0.94     23695
weighted avg       0.94      0.94      0.94     23695

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.93      0.93     10041
           1       0.95      0.95      0.95     13654

    accuracy                           0.94     23695
   macro avg       0.94      0.94      0.94     23695
weighted avg       0.94      0.94      0.94     23695

              precision    recall  f1-score   support

           0       0.93      0.93      0.93     10041
           1       0.95      0.95      0.95     13654

    accuracy                           0.94     23695
   macro avg       0.94      0.94      0.94     23695
weighted avg       0.94      0.94      0.94     23695

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      0.93      0.96     38191
           1       0.93      0.99      0.96     37725

    accuracy                           0.96     75916
   macro avg       0.96      0.96      0.96     75916
weighted avg       0.96      0.96      0.96     75916

              precision    recall  f1-score   support

           0       0.99      0.93      0.96     38191
           1       0.93      0.99      0.96     37725

    accuracy                           0.96     75916
   macro avg       0.96      0.96      0.96     75916
weighted avg       0.96      0.96      0.96     75916

completed
