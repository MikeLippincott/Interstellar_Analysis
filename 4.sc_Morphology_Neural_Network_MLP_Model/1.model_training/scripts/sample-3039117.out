[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '93cb423b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '6eab3f26'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '4eebe233'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'a24ff770'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (29511, 1276)
Number of total missing values across all columns: 31718
Data Subset Is Off
Wells held out for testing: ['B20' 'L16']
Wells to use for training, validation, and testing ['B16' 'B17' 'B21' 'L17' 'L20' 'L21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.316979).  Saving model ...
	 Train_Loss: 0.5316 Train_Acc: 76.340 Val_Loss: 0.3170  BEST VAL Loss: 0.3170  Val_Acc: 91.568

Epoch 1: Validation loss decreased (0.316979 --> 0.269448).  Saving model ...
	 Train_Loss: 0.4501 Train_Acc: 86.728 Val_Loss: 0.2694  BEST VAL Loss: 0.2694  Val_Acc: 93.563

Epoch 2: Validation loss decreased (0.269448 --> 0.234350).  Saving model ...
	 Train_Loss: 0.3998 Train_Acc: 89.510 Val_Loss: 0.2344  BEST VAL Loss: 0.2344  Val_Acc: 95.422

Epoch 3: Validation loss decreased (0.234350 --> 0.212594).  Saving model ...
	 Train_Loss: 0.3692 Train_Acc: 90.689 Val_Loss: 0.2126  BEST VAL Loss: 0.2126  Val_Acc: 96.056

Epoch 4: Validation loss decreased (0.212594 --> 0.196858).  Saving model ...
	 Train_Loss: 0.3444 Train_Acc: 91.919 Val_Loss: 0.1969  BEST VAL Loss: 0.1969  Val_Acc: 96.102

Epoch 5: Validation loss decreased (0.196858 --> 0.184103).  Saving model ...
	 Train_Loss: 0.3252 Train_Acc: 92.537 Val_Loss: 0.1841  BEST VAL Loss: 0.1841  Val_Acc: 96.782

Epoch 6: Validation loss decreased (0.184103 --> 0.177695).  Saving model ...
	 Train_Loss: 0.3114 Train_Acc: 92.559 Val_Loss: 0.1777  BEST VAL Loss: 0.1777  Val_Acc: 96.192

Epoch 7: Validation loss decreased (0.177695 --> 0.173543).  Saving model ...
	 Train_Loss: 0.3003 Train_Acc: 92.735 Val_Loss: 0.1735  BEST VAL Loss: 0.1735  Val_Acc: 96.464

Epoch 8: Validation loss decreased (0.173543 --> 0.168788).  Saving model ...
	 Train_Loss: 0.2915 Train_Acc: 92.843 Val_Loss: 0.1688  BEST VAL Loss: 0.1688  Val_Acc: 96.283

Epoch 9: Validation loss decreased (0.168788 --> 0.163581).  Saving model ...
	 Train_Loss: 0.2835 Train_Acc: 93.358 Val_Loss: 0.1636  BEST VAL Loss: 0.1636  Val_Acc: 96.782

Epoch 10: Validation loss decreased (0.163581 --> 0.160327).  Saving model ...
	 Train_Loss: 0.2756 Train_Acc: 93.953 Val_Loss: 0.1603  BEST VAL Loss: 0.1603  Val_Acc: 96.464

Epoch 11: Validation loss decreased (0.160327 --> 0.158343).  Saving model ...
	 Train_Loss: 0.2658 Train_Acc: 95.285 Val_Loss: 0.1583  BEST VAL Loss: 0.1583  Val_Acc: 96.872

Epoch 12: Validation loss decreased (0.158343 --> 0.154921).  Saving model ...
	 Train_Loss: 0.2570 Train_Acc: 95.716 Val_Loss: 0.1549  BEST VAL Loss: 0.1549  Val_Acc: 97.189

Epoch 13: Validation loss decreased (0.154921 --> 0.152274).  Saving model ...
	 Train_Loss: 0.2495 Train_Acc: 95.330 Val_Loss: 0.1523  BEST VAL Loss: 0.1523  Val_Acc: 97.008

Epoch 14: Validation loss decreased (0.152274 --> 0.149126).  Saving model ...
	 Train_Loss: 0.2433 Train_Acc: 95.387 Val_Loss: 0.1491  BEST VAL Loss: 0.1491  Val_Acc: 97.189

Epoch 15: Validation loss decreased (0.149126 --> 0.146467).  Saving model ...
	 Train_Loss: 0.2373 Train_Acc: 95.608 Val_Loss: 0.1465  BEST VAL Loss: 0.1465  Val_Acc: 97.099

Epoch 16: Validation loss decreased (0.146467 --> 0.143904).  Saving model ...
	 Train_Loss: 0.2320 Train_Acc: 95.580 Val_Loss: 0.1439  BEST VAL Loss: 0.1439  Val_Acc: 97.053

Epoch 17: Validation loss decreased (0.143904 --> 0.142509).  Saving model ...
	 Train_Loss: 0.2269 Train_Acc: 95.880 Val_Loss: 0.1425  BEST VAL Loss: 0.1425  Val_Acc: 96.510

Epoch 18: Validation loss decreased (0.142509 --> 0.141272).  Saving model ...
	 Train_Loss: 0.2224 Train_Acc: 95.818 Val_Loss: 0.1413  BEST VAL Loss: 0.1413  Val_Acc: 97.053

Epoch 19: Validation loss decreased (0.141272 --> 0.139816).  Saving model ...
	 Train_Loss: 0.2177 Train_Acc: 96.362 Val_Loss: 0.1398  BEST VAL Loss: 0.1398  Val_Acc: 97.461

Epoch 20: Validation loss decreased (0.139816 --> 0.138253).  Saving model ...
	 Train_Loss: 0.2134 Train_Acc: 96.486 Val_Loss: 0.1383  BEST VAL Loss: 0.1383  Val_Acc: 97.144

Epoch 21: Validation loss decreased (0.138253 --> 0.136554).  Saving model ...
	 Train_Loss: 0.2097 Train_Acc: 96.163 Val_Loss: 0.1366  BEST VAL Loss: 0.1366  Val_Acc: 97.371

Epoch 22: Validation loss decreased (0.136554 --> 0.135366).  Saving model ...
	 Train_Loss: 0.2062 Train_Acc: 96.265 Val_Loss: 0.1354  BEST VAL Loss: 0.1354  Val_Acc: 97.189

Epoch 23: Validation loss decreased (0.135366 --> 0.134288).  Saving model ...
	 Train_Loss: 0.2032 Train_Acc: 96.084 Val_Loss: 0.1343  BEST VAL Loss: 0.1343  Val_Acc: 97.325

Epoch 24: Validation loss decreased (0.134288 --> 0.133707).  Saving model ...
	 Train_Loss: 0.1999 Train_Acc: 96.651 Val_Loss: 0.1337  BEST VAL Loss: 0.1337  Val_Acc: 97.189

Epoch 25: Validation loss decreased (0.133707 --> 0.132732).  Saving model ...
	 Train_Loss: 0.1969 Train_Acc: 96.622 Val_Loss: 0.1327  BEST VAL Loss: 0.1327  Val_Acc: 97.824

Epoch 26: Validation loss did not decrease
	 Train_Loss: 0.1940 Train_Acc: 96.798 Val_Loss: 0.1330  BEST VAL Loss: 0.1327  Val_Acc: 97.325

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.1913 Train_Acc: 96.679 Val_Loss: 0.1333  BEST VAL Loss: 0.1327  Val_Acc: 97.008

Epoch 28: Validation loss decreased (0.132732 --> 0.132529).  Saving model ...
	 Train_Loss: 0.1887 Train_Acc: 96.702 Val_Loss: 0.1325  BEST VAL Loss: 0.1325  Val_Acc: 97.144

Epoch 29: Validation loss decreased (0.132529 --> 0.131643).  Saving model ...
	 Train_Loss: 0.1863 Train_Acc: 96.900 Val_Loss: 0.1316  BEST VAL Loss: 0.1316  Val_Acc: 97.053

Epoch 30: Validation loss decreased (0.131643 --> 0.130980).  Saving model ...
	 Train_Loss: 0.1841 Train_Acc: 96.792 Val_Loss: 0.1310  BEST VAL Loss: 0.1310  Val_Acc: 96.691

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.1826 Train_Acc: 96.401 Val_Loss: 0.1311  BEST VAL Loss: 0.1310  Val_Acc: 97.325

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.1807 Train_Acc: 96.702 Val_Loss: 0.1316  BEST VAL Loss: 0.1310  Val_Acc: 97.416

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.1794 Train_Acc: 96.186 Val_Loss: 0.1315  BEST VAL Loss: 0.1310  Val_Acc: 97.189

Epoch 34: Validation loss did not decrease
	 Train_Loss: 0.1776 Train_Acc: 96.736 Val_Loss: 0.1319  BEST VAL Loss: 0.1310  Val_Acc: 97.371

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.1758 Train_Acc: 96.951 Val_Loss: 0.1313  BEST VAL Loss: 0.1310  Val_Acc: 97.779

Epoch 36: Validation loss decreased (0.130980 --> 0.130715).  Saving model ...
	 Train_Loss: 0.1739 Train_Acc: 97.212 Val_Loss: 0.1307  BEST VAL Loss: 0.1307  Val_Acc: 97.552

Epoch 37: Validation loss decreased (0.130715 --> 0.129753).  Saving model ...
	 Train_Loss: 0.1723 Train_Acc: 97.070 Val_Loss: 0.1298  BEST VAL Loss: 0.1298  Val_Acc: 97.597

Epoch 38: Validation loss decreased (0.129753 --> 0.129098).  Saving model ...
	 Train_Loss: 0.1706 Train_Acc: 97.059 Val_Loss: 0.1291  BEST VAL Loss: 0.1291  Val_Acc: 97.643

Epoch 39: Validation loss decreased (0.129098 --> 0.128845).  Saving model ...
	 Train_Loss: 0.1689 Train_Acc: 97.433 Val_Loss: 0.1288  BEST VAL Loss: 0.1288  Val_Acc: 97.597

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.1671 Train_Acc: 97.320 Val_Loss: 0.1300  BEST VAL Loss: 0.1288  Val_Acc: 97.325

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.1655 Train_Acc: 97.467 Val_Loss: 0.1292  BEST VAL Loss: 0.1288  Val_Acc: 97.461

Epoch 42: Validation loss decreased (0.128845 --> 0.128670).  Saving model ...
	 Train_Loss: 0.1641 Train_Acc: 96.991 Val_Loss: 0.1287  BEST VAL Loss: 0.1287  Val_Acc: 97.688

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.1625 Train_Acc: 97.563 Val_Loss: 0.1287  BEST VAL Loss: 0.1287  Val_Acc: 97.416

Epoch 44: Validation loss decreased (0.128670 --> 0.128627).  Saving model ...
	 Train_Loss: 0.1612 Train_Acc: 97.064 Val_Loss: 0.1286  BEST VAL Loss: 0.1286  Val_Acc: 96.782

Epoch 45: Validation loss decreased (0.128627 --> 0.128169).  Saving model ...
	 Train_Loss: 0.1601 Train_Acc: 96.775 Val_Loss: 0.1282  BEST VAL Loss: 0.1282  Val_Acc: 97.053

Epoch 46: Validation loss decreased (0.128169 --> 0.127399).  Saving model ...
	 Train_Loss: 0.1590 Train_Acc: 96.979 Val_Loss: 0.1274  BEST VAL Loss: 0.1274  Val_Acc: 97.416

Epoch 47: Validation loss decreased (0.127399 --> 0.127255).  Saving model ...
	 Train_Loss: 0.1578 Train_Acc: 97.246 Val_Loss: 0.1273  BEST VAL Loss: 0.1273  Val_Acc: 97.643

Epoch 48: Validation loss decreased (0.127255 --> 0.126780).  Saving model ...
	 Train_Loss: 0.1568 Train_Acc: 97.206 Val_Loss: 0.1268  BEST VAL Loss: 0.1268  Val_Acc: 97.461

Epoch 49: Validation loss decreased (0.126780 --> 0.126568).  Saving model ...
	 Train_Loss: 0.1557 Train_Acc: 97.212 Val_Loss: 0.1266  BEST VAL Loss: 0.1266  Val_Acc: 97.280

Epoch 50: Validation loss decreased (0.126568 --> 0.126232).  Saving model ...
	 Train_Loss: 0.1545 Train_Acc: 97.501 Val_Loss: 0.1262  BEST VAL Loss: 0.1262  Val_Acc: 97.688

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.1533 Train_Acc: 97.654 Val_Loss: 0.1272  BEST VAL Loss: 0.1262  Val_Acc: 97.235

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.1522 Train_Acc: 97.240 Val_Loss: 0.1271  BEST VAL Loss: 0.1262  Val_Acc: 97.461

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.1511 Train_Acc: 97.620 Val_Loss: 0.1269  BEST VAL Loss: 0.1262  Val_Acc: 97.733

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.1500 Train_Acc: 97.546 Val_Loss: 0.1274  BEST VAL Loss: 0.1262  Val_Acc: 97.779

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.1492 Train_Acc: 97.495 Val_Loss: 0.1275  BEST VAL Loss: 0.1262  Val_Acc: 97.461

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.1485 Train_Acc: 96.815 Val_Loss: 0.1282  BEST VAL Loss: 0.1262  Val_Acc: 97.235

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.1479 Train_Acc: 97.087 Val_Loss: 0.1277  BEST VAL Loss: 0.1262  Val_Acc: 97.733

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.1472 Train_Acc: 97.206 Val_Loss: 0.1274  BEST VAL Loss: 0.1262  Val_Acc: 97.461

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.1464 Train_Acc: 97.376 Val_Loss: 0.1269  BEST VAL Loss: 0.1262  Val_Acc: 97.779

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.1456 Train_Acc: 97.399 Val_Loss: 0.1281  BEST VAL Loss: 0.1262  Val_Acc: 97.552

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.1448 Train_Acc: 97.575 Val_Loss: 0.1284  BEST VAL Loss: 0.1262  Val_Acc: 97.643

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.1441 Train_Acc: 97.399 Val_Loss: 0.1281  BEST VAL Loss: 0.1262  Val_Acc: 97.915

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.1432 Train_Acc: 97.614 Val_Loss: 0.1284  BEST VAL Loss: 0.1262  Val_Acc: 97.507

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.1424 Train_Acc: 97.739 Val_Loss: 0.1283  BEST VAL Loss: 0.1262  Val_Acc: 97.824

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.1416 Train_Acc: 97.688 Val_Loss: 0.1285  BEST VAL Loss: 0.1262  Val_Acc: 97.507

Epoch 66: Validation loss did not decrease
Early stopped at epoch : 66
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      1.00      1.00      9707
           1       1.00      0.99      1.00      7939

    accuracy                           1.00     17646
   macro avg       1.00      1.00      1.00     17646
weighted avg       1.00      1.00      1.00     17646

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.98      0.98      1214
           1       0.97      0.97      0.97       992

    accuracy                           0.98      2206
   macro avg       0.98      0.98      0.98      2206
weighted avg       0.98      0.98      0.98      2206

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.98      0.98      1214
           1       0.97      0.97      0.97       992

    accuracy                           0.97      2206
   macro avg       0.97      0.97      0.97      2206
weighted avg       0.97      0.97      0.97      2206

              precision    recall  f1-score   support

           0       0.97      0.98      0.98      1214
           1       0.97      0.97      0.97       992

    accuracy                           0.97      2206
   macro avg       0.97      0.97      0.97      2206
weighted avg       0.97      0.97      0.97      2206

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.94      0.98      0.96      3724
           1       0.98      0.94      0.96      3729

    accuracy                           0.96      7453
   macro avg       0.96      0.96      0.96      7453
weighted avg       0.96      0.96      0.96      7453

              precision    recall  f1-score   support

           0       0.94      0.98      0.96      3724
           1       0.98      0.94      0.96      3729

    accuracy                           0.96      7453
   macro avg       0.96      0.96      0.96      7453
weighted avg       0.96      0.96      0.96      7453

completed
