[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '77d9fce6'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '3e61f4f0'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '4a76fa2a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'b11c52ca'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: H2O2_100.000_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: Flagellin_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['H2O2_100.000_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (42709, 1276)
Number of total missing values across all columns: 85418
Data Subset Is Off
Wells held out for testing: ['I22' 'M22']
Wells to use for training, validation, and testing ['H18' 'H19' 'H22' 'H23' 'I18' 'M18' 'I19' 'M19' 'I23' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.558589).  Saving model ...
	 Train_Loss: 0.6177 Train_Acc: 67.055 Val_Loss: 0.5586  BEST VAL Loss: 0.5586  Val_Acc: 67.935

Epoch 1: Validation loss decreased (0.558589 --> 0.530844).  Saving model ...
	 Train_Loss: 0.5934 Train_Acc: 69.769 Val_Loss: 0.5308  BEST VAL Loss: 0.5308  Val_Acc: 73.811

Epoch 2: Validation loss decreased (0.530844 --> 0.513626).  Saving model ...
	 Train_Loss: 0.5725 Train_Acc: 72.383 Val_Loss: 0.5136  BEST VAL Loss: 0.5136  Val_Acc: 75.154

Epoch 3: Validation loss decreased (0.513626 --> 0.499382).  Saving model ...
	 Train_Loss: 0.5572 Train_Acc: 73.138 Val_Loss: 0.4994  BEST VAL Loss: 0.4994  Val_Acc: 77.504

Epoch 4: Validation loss decreased (0.499382 --> 0.489403).  Saving model ...
	 Train_Loss: 0.5455 Train_Acc: 73.610 Val_Loss: 0.4894  BEST VAL Loss: 0.4894  Val_Acc: 78.735

Epoch 5: Validation loss decreased (0.489403 --> 0.479744).  Saving model ...
	 Train_Loss: 0.5359 Train_Acc: 74.139 Val_Loss: 0.4797  BEST VAL Loss: 0.4797  Val_Acc: 80.246

Epoch 6: Validation loss decreased (0.479744 --> 0.472091).  Saving model ...
	 Train_Loss: 0.5277 Train_Acc: 74.698 Val_Loss: 0.4721  BEST VAL Loss: 0.4721  Val_Acc: 79.799

Epoch 7: Validation loss decreased (0.472091 --> 0.466146).  Saving model ...
	 Train_Loss: 0.5204 Train_Acc: 74.810 Val_Loss: 0.4661  BEST VAL Loss: 0.4661  Val_Acc: 80.218

Epoch 8: Validation loss decreased (0.466146 --> 0.461033).  Saving model ...
	 Train_Loss: 0.5142 Train_Acc: 75.401 Val_Loss: 0.4610  BEST VAL Loss: 0.4610  Val_Acc: 80.470

Epoch 9: Validation loss decreased (0.461033 --> 0.456137).  Saving model ...
	 Train_Loss: 0.5089 Train_Acc: 75.464 Val_Loss: 0.4561  BEST VAL Loss: 0.4561  Val_Acc: 81.086

Epoch 10: Validation loss decreased (0.456137 --> 0.451685).  Saving model ...
	 Train_Loss: 0.5040 Train_Acc: 75.601 Val_Loss: 0.4517  BEST VAL Loss: 0.4517  Val_Acc: 81.813

Epoch 11: Validation loss decreased (0.451685 --> 0.447073).  Saving model ...
	 Train_Loss: 0.4993 Train_Acc: 76.195 Val_Loss: 0.4471  BEST VAL Loss: 0.4471  Val_Acc: 82.065

Epoch 12: Validation loss decreased (0.447073 --> 0.443712).  Saving model ...
	 Train_Loss: 0.4953 Train_Acc: 75.947 Val_Loss: 0.4437  BEST VAL Loss: 0.4437  Val_Acc: 82.205

Epoch 13: Validation loss decreased (0.443712 --> 0.440839).  Saving model ...
	 Train_Loss: 0.4915 Train_Acc: 76.136 Val_Loss: 0.4408  BEST VAL Loss: 0.4408  Val_Acc: 81.589

Epoch 14: Validation loss decreased (0.440839 --> 0.438022).  Saving model ...
	 Train_Loss: 0.4882 Train_Acc: 76.202 Val_Loss: 0.4380  BEST VAL Loss: 0.4380  Val_Acc: 82.569

Epoch 15: Validation loss decreased (0.438022 --> 0.435529).  Saving model ...
	 Train_Loss: 0.4850 Train_Acc: 76.269 Val_Loss: 0.4355  BEST VAL Loss: 0.4355  Val_Acc: 81.841

Epoch 16: Validation loss decreased (0.435529 --> 0.433009).  Saving model ...
	 Train_Loss: 0.4821 Train_Acc: 76.332 Val_Loss: 0.4330  BEST VAL Loss: 0.4330  Val_Acc: 82.261

Epoch 17: Validation loss decreased (0.433009 --> 0.430940).  Saving model ...
	 Train_Loss: 0.4795 Train_Acc: 76.759 Val_Loss: 0.4309  BEST VAL Loss: 0.4309  Val_Acc: 82.625

Epoch 18: Validation loss decreased (0.430940 --> 0.428589).  Saving model ...
	 Train_Loss: 0.4770 Train_Acc: 76.951 Val_Loss: 0.4286  BEST VAL Loss: 0.4286  Val_Acc: 82.764

Epoch 19: Validation loss decreased (0.428589 --> 0.426691).  Saving model ...
	 Train_Loss: 0.4747 Train_Acc: 76.538 Val_Loss: 0.4267  BEST VAL Loss: 0.4267  Val_Acc: 82.652

Epoch 20: Validation loss decreased (0.426691 --> 0.424728).  Saving model ...
	 Train_Loss: 0.4724 Train_Acc: 76.818 Val_Loss: 0.4247  BEST VAL Loss: 0.4247  Val_Acc: 82.848

Epoch 21: Validation loss decreased (0.424728 --> 0.422875).  Saving model ...
	 Train_Loss: 0.4703 Train_Acc: 77.224 Val_Loss: 0.4229  BEST VAL Loss: 0.4229  Val_Acc: 83.072

Epoch 22: Validation loss decreased (0.422875 --> 0.421028).  Saving model ...
	 Train_Loss: 0.4682 Train_Acc: 77.231 Val_Loss: 0.4210  BEST VAL Loss: 0.4210  Val_Acc: 83.268

Epoch 23: Validation loss decreased (0.421028 --> 0.419457).  Saving model ...
	 Train_Loss: 0.4661 Train_Acc: 77.231 Val_Loss: 0.4195  BEST VAL Loss: 0.4195  Val_Acc: 83.408

Epoch 24: Validation loss decreased (0.419457 --> 0.417902).  Saving model ...
	 Train_Loss: 0.4644 Train_Acc: 77.004 Val_Loss: 0.4179  BEST VAL Loss: 0.4179  Val_Acc: 83.324

Epoch 25: Validation loss decreased (0.417902 --> 0.416341).  Saving model ...
	 Train_Loss: 0.4625 Train_Acc: 77.714 Val_Loss: 0.4163  BEST VAL Loss: 0.4163  Val_Acc: 83.352

Epoch 26: Validation loss decreased (0.416341 --> 0.415124).  Saving model ...
	 Train_Loss: 0.4610 Train_Acc: 77.136 Val_Loss: 0.4151  BEST VAL Loss: 0.4151  Val_Acc: 82.904

Epoch 27: Validation loss decreased (0.415124 --> 0.413755).  Saving model ...
	 Train_Loss: 0.4595 Train_Acc: 77.119 Val_Loss: 0.4138  BEST VAL Loss: 0.4138  Val_Acc: 83.380

Epoch 28: Validation loss decreased (0.413755 --> 0.412690).  Saving model ...
	 Train_Loss: 0.4580 Train_Acc: 77.168 Val_Loss: 0.4127  BEST VAL Loss: 0.4127  Val_Acc: 82.960

Epoch 29: Validation loss decreased (0.412690 --> 0.411613).  Saving model ...
	 Train_Loss: 0.4566 Train_Acc: 77.399 Val_Loss: 0.4116  BEST VAL Loss: 0.4116  Val_Acc: 82.820

Epoch 30: Validation loss decreased (0.411613 --> 0.410630).  Saving model ...
	 Train_Loss: 0.4553 Train_Acc: 77.332 Val_Loss: 0.4106  BEST VAL Loss: 0.4106  Val_Acc: 83.072

Epoch 31: Validation loss decreased (0.410630 --> 0.409681).  Saving model ...
	 Train_Loss: 0.4540 Train_Acc: 77.532 Val_Loss: 0.4097  BEST VAL Loss: 0.4097  Val_Acc: 83.016

Epoch 32: Validation loss decreased (0.409681 --> 0.408510).  Saving model ...
	 Train_Loss: 0.4526 Train_Acc: 77.703 Val_Loss: 0.4085  BEST VAL Loss: 0.4085  Val_Acc: 83.548

Epoch 33: Validation loss decreased (0.408510 --> 0.407652).  Saving model ...
	 Train_Loss: 0.4512 Train_Acc: 77.553 Val_Loss: 0.4077  BEST VAL Loss: 0.4077  Val_Acc: 83.520

Epoch 34: Validation loss decreased (0.407652 --> 0.406762).  Saving model ...
	 Train_Loss: 0.4501 Train_Acc: 77.364 Val_Loss: 0.4068  BEST VAL Loss: 0.4068  Val_Acc: 84.107

Epoch 35: Validation loss decreased (0.406762 --> 0.405772).  Saving model ...
	 Train_Loss: 0.4489 Train_Acc: 77.934 Val_Loss: 0.4058  BEST VAL Loss: 0.4058  Val_Acc: 83.828

Epoch 36: Validation loss decreased (0.405772 --> 0.405083).  Saving model ...
	 Train_Loss: 0.4477 Train_Acc: 77.710 Val_Loss: 0.4051  BEST VAL Loss: 0.4051  Val_Acc: 83.380

Epoch 37: Validation loss decreased (0.405083 --> 0.404220).  Saving model ...
	 Train_Loss: 0.4465 Train_Acc: 78.063 Val_Loss: 0.4042  BEST VAL Loss: 0.4042  Val_Acc: 83.072

Epoch 38: Validation loss decreased (0.404220 --> 0.403571).  Saving model ...
	 Train_Loss: 0.4455 Train_Acc: 77.917 Val_Loss: 0.4036  BEST VAL Loss: 0.4036  Val_Acc: 83.604

Epoch 39: Validation loss decreased (0.403571 --> 0.402809).  Saving model ...
	 Train_Loss: 0.4445 Train_Acc: 77.448 Val_Loss: 0.4028  BEST VAL Loss: 0.4028  Val_Acc: 83.268

Epoch 40: Validation loss decreased (0.402809 --> 0.402202).  Saving model ...
	 Train_Loss: 0.4435 Train_Acc: 78.144 Val_Loss: 0.4022  BEST VAL Loss: 0.4022  Val_Acc: 83.184

Epoch 41: Validation loss decreased (0.402202 --> 0.401694).  Saving model ...
	 Train_Loss: 0.4425 Train_Acc: 78.119 Val_Loss: 0.4017  BEST VAL Loss: 0.4017  Val_Acc: 83.128

Epoch 42: Validation loss decreased (0.401694 --> 0.401169).  Saving model ...
	 Train_Loss: 0.4415 Train_Acc: 78.081 Val_Loss: 0.4012  BEST VAL Loss: 0.4012  Val_Acc: 82.792

Epoch 43: Validation loss decreased (0.401169 --> 0.400593).  Saving model ...
	 Train_Loss: 0.4405 Train_Acc: 78.067 Val_Loss: 0.4006  BEST VAL Loss: 0.4006  Val_Acc: 83.800

Epoch 44: Validation loss decreased (0.400593 --> 0.399901).  Saving model ...
	 Train_Loss: 0.4395 Train_Acc: 78.154 Val_Loss: 0.3999  BEST VAL Loss: 0.3999  Val_Acc: 83.240

Epoch 45: Validation loss decreased (0.399901 --> 0.399516).  Saving model ...
	 Train_Loss: 0.4387 Train_Acc: 77.931 Val_Loss: 0.3995  BEST VAL Loss: 0.3995  Val_Acc: 83.464

Epoch 46: Validation loss decreased (0.399516 --> 0.399167).  Saving model ...
	 Train_Loss: 0.4377 Train_Acc: 78.322 Val_Loss: 0.3992  BEST VAL Loss: 0.3992  Val_Acc: 83.184

Epoch 47: Validation loss decreased (0.399167 --> 0.398639).  Saving model ...
	 Train_Loss: 0.4369 Train_Acc: 77.714 Val_Loss: 0.3986  BEST VAL Loss: 0.3986  Val_Acc: 83.464

Epoch 48: Validation loss decreased (0.398639 --> 0.398286).  Saving model ...
	 Train_Loss: 0.4359 Train_Acc: 78.469 Val_Loss: 0.3983  BEST VAL Loss: 0.3983  Val_Acc: 83.604

Epoch 49: Validation loss decreased (0.398286 --> 0.398089).  Saving model ...
	 Train_Loss: 0.4351 Train_Acc: 77.875 Val_Loss: 0.3981  BEST VAL Loss: 0.3981  Val_Acc: 82.708

Epoch 50: Validation loss decreased (0.398089 --> 0.397812).  Saving model ...
	 Train_Loss: 0.4343 Train_Acc: 78.315 Val_Loss: 0.3978  BEST VAL Loss: 0.3978  Val_Acc: 83.352

Epoch 51: Validation loss decreased (0.397812 --> 0.397583).  Saving model ...
	 Train_Loss: 0.4335 Train_Acc: 78.448 Val_Loss: 0.3976  BEST VAL Loss: 0.3976  Val_Acc: 83.940

Epoch 52: Validation loss decreased (0.397583 --> 0.397313).  Saving model ...
	 Train_Loss: 0.4327 Train_Acc: 78.378 Val_Loss: 0.3973  BEST VAL Loss: 0.3973  Val_Acc: 83.100

Epoch 53: Validation loss decreased (0.397313 --> 0.396886).  Saving model ...
	 Train_Loss: 0.4321 Train_Acc: 78.200 Val_Loss: 0.3969  BEST VAL Loss: 0.3969  Val_Acc: 83.660

Epoch 54: Validation loss decreased (0.396886 --> 0.396468).  Saving model ...
	 Train_Loss: 0.4315 Train_Acc: 77.707 Val_Loss: 0.3965  BEST VAL Loss: 0.3965  Val_Acc: 83.856

Epoch 55: Validation loss decreased (0.396468 --> 0.396362).  Saving model ...
	 Train_Loss: 0.4308 Train_Acc: 78.126 Val_Loss: 0.3964  BEST VAL Loss: 0.3964  Val_Acc: 83.884

Epoch 56: Validation loss decreased (0.396362 --> 0.395964).  Saving model ...
	 Train_Loss: 0.4301 Train_Acc: 78.168 Val_Loss: 0.3960  BEST VAL Loss: 0.3960  Val_Acc: 83.408

Epoch 57: Validation loss decreased (0.395964 --> 0.395760).  Saving model ...
	 Train_Loss: 0.4294 Train_Acc: 78.137 Val_Loss: 0.3958  BEST VAL Loss: 0.3958  Val_Acc: 83.800

Epoch 58: Validation loss decreased (0.395760 --> 0.395500).  Saving model ...
	 Train_Loss: 0.4286 Train_Acc: 78.788 Val_Loss: 0.3955  BEST VAL Loss: 0.3955  Val_Acc: 84.163

Epoch 59: Validation loss decreased (0.395500 --> 0.395326).  Saving model ...
	 Train_Loss: 0.4279 Train_Acc: 78.389 Val_Loss: 0.3953  BEST VAL Loss: 0.3953  Val_Acc: 83.380

Epoch 60: Validation loss decreased (0.395326 --> 0.395265).  Saving model ...
	 Train_Loss: 0.4272 Train_Acc: 78.340 Val_Loss: 0.3953  BEST VAL Loss: 0.3953  Val_Acc: 83.828

Epoch 61: Validation loss decreased (0.395265 --> 0.395061).  Saving model ...
	 Train_Loss: 0.4266 Train_Acc: 78.564 Val_Loss: 0.3951  BEST VAL Loss: 0.3951  Val_Acc: 83.828

Epoch 62: Validation loss decreased (0.395061 --> 0.394780).  Saving model ...
	 Train_Loss: 0.4260 Train_Acc: 78.196 Val_Loss: 0.3948  BEST VAL Loss: 0.3948  Val_Acc: 83.968

Epoch 63: Validation loss decreased (0.394780 --> 0.394632).  Saving model ...
	 Train_Loss: 0.4254 Train_Acc: 78.263 Val_Loss: 0.3946  BEST VAL Loss: 0.3946  Val_Acc: 83.660

Epoch 64: Validation loss decreased (0.394632 --> 0.394486).  Saving model ...
	 Train_Loss: 0.4248 Train_Acc: 78.662 Val_Loss: 0.3945  BEST VAL Loss: 0.3945  Val_Acc: 83.856

Epoch 65: Validation loss decreased (0.394486 --> 0.394282).  Saving model ...
	 Train_Loss: 0.4242 Train_Acc: 78.997 Val_Loss: 0.3943  BEST VAL Loss: 0.3943  Val_Acc: 83.828

Epoch 66: Validation loss decreased (0.394282 --> 0.394187).  Saving model ...
	 Train_Loss: 0.4236 Train_Acc: 78.987 Val_Loss: 0.3942  BEST VAL Loss: 0.3942  Val_Acc: 83.800

Epoch 67: Validation loss decreased (0.394187 --> 0.394044).  Saving model ...
	 Train_Loss: 0.4230 Train_Acc: 78.501 Val_Loss: 0.3940  BEST VAL Loss: 0.3940  Val_Acc: 83.660

Epoch 68: Validation loss decreased (0.394044 --> 0.393913).  Saving model ...
	 Train_Loss: 0.4224 Train_Acc: 78.410 Val_Loss: 0.3939  BEST VAL Loss: 0.3939  Val_Acc: 83.996

Epoch 69: Validation loss decreased (0.393913 --> 0.393878).  Saving model ...
	 Train_Loss: 0.4219 Train_Acc: 78.392 Val_Loss: 0.3939  BEST VAL Loss: 0.3939  Val_Acc: 84.135

Epoch 70: Validation loss decreased (0.393878 --> 0.393763).  Saving model ...
	 Train_Loss: 0.4213 Train_Acc: 78.494 Val_Loss: 0.3938  BEST VAL Loss: 0.3938  Val_Acc: 83.716

Epoch 71: Validation loss decreased (0.393763 --> 0.393531).  Saving model ...
	 Train_Loss: 0.4207 Train_Acc: 78.375 Val_Loss: 0.3935  BEST VAL Loss: 0.3935  Val_Acc: 84.387

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.4202 Train_Acc: 78.777 Val_Loss: 0.3936  BEST VAL Loss: 0.3935  Val_Acc: 83.436

Epoch 73: Validation loss decreased (0.393531 --> 0.393515).  Saving model ...
	 Train_Loss: 0.4197 Train_Acc: 78.392 Val_Loss: 0.3935  BEST VAL Loss: 0.3935  Val_Acc: 83.408

Epoch 74: Validation loss decreased (0.393515 --> 0.393442).  Saving model ...
	 Train_Loss: 0.4192 Train_Acc: 78.739 Val_Loss: 0.3934  BEST VAL Loss: 0.3934  Val_Acc: 84.024

Epoch 75: Validation loss decreased (0.393442 --> 0.393296).  Saving model ...
	 Train_Loss: 0.4187 Train_Acc: 78.592 Val_Loss: 0.3933  BEST VAL Loss: 0.3933  Val_Acc: 83.688

Epoch 76: Validation loss decreased (0.393296 --> 0.393238).  Saving model ...
	 Train_Loss: 0.4182 Train_Acc: 78.420 Val_Loss: 0.3932  BEST VAL Loss: 0.3932  Val_Acc: 84.079

Epoch 77: Validation loss decreased (0.393238 --> 0.393170).  Saving model ...
	 Train_Loss: 0.4176 Train_Acc: 78.844 Val_Loss: 0.3932  BEST VAL Loss: 0.3932  Val_Acc: 83.800

Epoch 78: Validation loss decreased (0.393170 --> 0.393149).  Saving model ...
	 Train_Loss: 0.4171 Train_Acc: 79.053 Val_Loss: 0.3931  BEST VAL Loss: 0.3931  Val_Acc: 83.772

Epoch 79: Validation loss decreased (0.393149 --> 0.393027).  Saving model ...
	 Train_Loss: 0.4166 Train_Acc: 78.861 Val_Loss: 0.3930  BEST VAL Loss: 0.3930  Val_Acc: 83.744

Epoch 80: Validation loss decreased (0.393027 --> 0.392939).  Saving model ...
	 Train_Loss: 0.4161 Train_Acc: 78.973 Val_Loss: 0.3929  BEST VAL Loss: 0.3929  Val_Acc: 83.800

Epoch 81: Validation loss decreased (0.392939 --> 0.392887).  Saving model ...
	 Train_Loss: 0.4157 Train_Acc: 78.893 Val_Loss: 0.3929  BEST VAL Loss: 0.3929  Val_Acc: 83.520

Epoch 82: Validation loss decreased (0.392887 --> 0.392737).  Saving model ...
	 Train_Loss: 0.4152 Train_Acc: 78.941 Val_Loss: 0.3927  BEST VAL Loss: 0.3927  Val_Acc: 83.940

Epoch 83: Validation loss decreased (0.392737 --> 0.392653).  Saving model ...
	 Train_Loss: 0.4148 Train_Acc: 78.816 Val_Loss: 0.3927  BEST VAL Loss: 0.3927  Val_Acc: 83.464

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.4142 Train_Acc: 79.158 Val_Loss: 0.3927  BEST VAL Loss: 0.3927  Val_Acc: 83.744

Epoch 85: Validation loss decreased (0.392653 --> 0.392616).  Saving model ...
	 Train_Loss: 0.4138 Train_Acc: 79.088 Val_Loss: 0.3926  BEST VAL Loss: 0.3926  Val_Acc: 83.744

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.4133 Train_Acc: 79.085 Val_Loss: 0.3926  BEST VAL Loss: 0.3926  Val_Acc: 83.716

Epoch 87: Validation loss decreased (0.392616 --> 0.392541).  Saving model ...
	 Train_Loss: 0.4129 Train_Acc: 79.004 Val_Loss: 0.3925  BEST VAL Loss: 0.3925  Val_Acc: 83.996

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.4124 Train_Acc: 79.351 Val_Loss: 0.3926  BEST VAL Loss: 0.3925  Val_Acc: 83.688

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.4120 Train_Acc: 78.924 Val_Loss: 0.3927  BEST VAL Loss: 0.3925  Val_Acc: 84.275

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.4115 Train_Acc: 79.435 Val_Loss: 0.3927  BEST VAL Loss: 0.3925  Val_Acc: 84.191

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.4111 Train_Acc: 78.809 Val_Loss: 0.3926  BEST VAL Loss: 0.3925  Val_Acc: 84.079

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.4107 Train_Acc: 79.277 Val_Loss: 0.3927  BEST VAL Loss: 0.3925  Val_Acc: 84.639

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.4103 Train_Acc: 79.130 Val_Loss: 0.3929  BEST VAL Loss: 0.3925  Val_Acc: 84.163

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.4099 Train_Acc: 79.144 Val_Loss: 0.3929  BEST VAL Loss: 0.3925  Val_Acc: 84.163

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.4095 Train_Acc: 79.249 Val_Loss: 0.3929  BEST VAL Loss: 0.3925  Val_Acc: 83.940

Epoch 96: Validation loss did not decrease
	 Train_Loss: 0.4091 Train_Acc: 79.319 Val_Loss: 0.3931  BEST VAL Loss: 0.3925  Val_Acc: 84.079

Epoch 97: Validation loss did not decrease
	 Train_Loss: 0.4087 Train_Acc: 79.183 Val_Loss: 0.3932  BEST VAL Loss: 0.3925  Val_Acc: 84.024

Epoch 98: Validation loss did not decrease
	 Train_Loss: 0.4083 Train_Acc: 79.337 Val_Loss: 0.3934  BEST VAL Loss: 0.3925  Val_Acc: 83.856

Epoch 99: Validation loss did not decrease
	 Train_Loss: 0.4079 Train_Acc: 79.057 Val_Loss: 0.3935  BEST VAL Loss: 0.3925  Val_Acc: 84.163

H2O2_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.86      0.85      0.85      9434
           1       0.93      0.93      0.93     19153

    accuracy                           0.90     28587
   macro avg       0.89      0.89      0.89     28587
weighted avg       0.90      0.90      0.90     28587

H2O2_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.76      0.75      0.75      1179
           1       0.88      0.89      0.88      2395

    accuracy                           0.84      3574
   macro avg       0.82      0.82      0.82      3574
weighted avg       0.84      0.84      0.84      3574

H2O2_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.75      0.72      0.73      1179
           1       0.86      0.88      0.87      2395

    accuracy                           0.83      3574
   macro avg       0.81      0.80      0.80      3574
weighted avg       0.83      0.83      0.83      3574

              precision    recall  f1-score   support

           0       0.75      0.72      0.73      1179
           1       0.86      0.88      0.87      2395

    accuracy                           0.83      3574
   macro avg       0.81      0.80      0.80      3574
weighted avg       0.83      0.83      0.83      3574

H2O2_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.95      0.37      0.54      4017
           1       0.53      0.97      0.69      2957

    accuracy                           0.63      6974
   macro avg       0.74      0.67      0.61      6974
weighted avg       0.77      0.63      0.60      6974

              precision    recall  f1-score   support

           0       0.95      0.37      0.54      4017
           1       0.53      0.97      0.69      2957

    accuracy                           0.63      6974
   macro avg       0.74      0.67      0.61      6974
weighted avg       0.77      0.63      0.60      6974

completed
