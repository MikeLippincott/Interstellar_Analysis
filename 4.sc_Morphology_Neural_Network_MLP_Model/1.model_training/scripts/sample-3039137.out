[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '51fd1903'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'f1c976b1'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'cbf9bf14'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '22dd948d'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_1.000_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_1.000_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_1.000_DMSO_0.025']
The dimensions of the data are: (282513, 1270)
Number of total missing values across all columns: 565026
Data Subset Is Off
Wells held out for testing: ['B08' 'D08']
Wells to use for training, validation, and testing ['B02' 'B03' 'B09' 'D02' 'D03' 'D09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.651900).  Saving model ...
	 Train_Loss: 1.0075 Train_Acc: 58.123 Val_Loss: 0.6519  BEST VAL Loss: 0.6519  Val_Acc: 58.797

Epoch 1: Validation loss decreased (0.651900 --> 0.645134).  Saving model ...
	 Train_Loss: 0.8629 Train_Acc: 60.643 Val_Loss: 0.6451  BEST VAL Loss: 0.6451  Val_Acc: 60.748

Epoch 2: Validation loss decreased (0.645134 --> 0.633571).  Saving model ...
	 Train_Loss: 0.7815 Train_Acc: 61.725 Val_Loss: 0.6336  BEST VAL Loss: 0.6336  Val_Acc: 63.360

Epoch 3: Validation loss decreased (0.633571 --> 0.625373).  Saving model ...
	 Train_Loss: 0.7558 Train_Acc: 61.804 Val_Loss: 0.6254  BEST VAL Loss: 0.6254  Val_Acc: 65.214

Epoch 4: Validation loss decreased (0.625373 --> 0.616438).  Saving model ...
	 Train_Loss: 0.7455 Train_Acc: 62.386 Val_Loss: 0.6164  BEST VAL Loss: 0.6164  Val_Acc: 65.622

Epoch 5: Validation loss decreased (0.616438 --> 0.613309).  Saving model ...
	 Train_Loss: 0.7191 Train_Acc: 63.789 Val_Loss: 0.6133  BEST VAL Loss: 0.6133  Val_Acc: 64.636

Epoch 6: Validation loss decreased (0.613309 --> 0.606386).  Saving model ...
	 Train_Loss: 0.7106 Train_Acc: 63.167 Val_Loss: 0.6064  BEST VAL Loss: 0.6064  Val_Acc: 66.165

Epoch 7: Validation loss decreased (0.606386 --> 0.601741).  Saving model ...
	 Train_Loss: 0.7074 Train_Acc: 63.415 Val_Loss: 0.6017  BEST VAL Loss: 0.6017  Val_Acc: 66.209

Epoch 8: Validation loss decreased (0.601741 --> 0.596078).  Saving model ...
	 Train_Loss: 0.6923 Train_Acc: 64.828 Val_Loss: 0.5961  BEST VAL Loss: 0.5961  Val_Acc: 66.689

Epoch 9: Validation loss decreased (0.596078 --> 0.592110).  Saving model ...
	 Train_Loss: 0.6879 Train_Acc: 63.315 Val_Loss: 0.5921  BEST VAL Loss: 0.5921  Val_Acc: 67.180

Epoch 10: Validation loss decreased (0.592110 --> 0.589840).  Saving model ...
	 Train_Loss: 0.6765 Train_Acc: 65.024 Val_Loss: 0.5898  BEST VAL Loss: 0.5898  Val_Acc: 66.403

Epoch 11: Validation loss decreased (0.589840 --> 0.586270).  Saving model ...
	 Train_Loss: 0.6738 Train_Acc: 64.026 Val_Loss: 0.5863  BEST VAL Loss: 0.5863  Val_Acc: 67.383

Epoch 12: Validation loss decreased (0.586270 --> 0.583130).  Saving model ...
	 Train_Loss: 0.6662 Train_Acc: 65.086 Val_Loss: 0.5831  BEST VAL Loss: 0.5831  Val_Acc: 66.990

Epoch 13: Validation loss decreased (0.583130 --> 0.579466).  Saving model ...
	 Train_Loss: 0.6637 Train_Acc: 64.438 Val_Loss: 0.5795  BEST VAL Loss: 0.5795  Val_Acc: 67.403

Epoch 14: Validation loss decreased (0.579466 --> 0.579306).  Saving model ...
	 Train_Loss: 0.6565 Train_Acc: 65.389 Val_Loss: 0.5793  BEST VAL Loss: 0.5793  Val_Acc: 63.753

Epoch 15: Validation loss decreased (0.579306 --> 0.576213).  Saving model ...
	 Train_Loss: 0.6554 Train_Acc: 64.160 Val_Loss: 0.5762  BEST VAL Loss: 0.5762  Val_Acc: 67.612

Epoch 16: Validation loss decreased (0.576213 --> 0.574327).  Saving model ...
	 Train_Loss: 0.6495 Train_Acc: 65.408 Val_Loss: 0.5743  BEST VAL Loss: 0.5743  Val_Acc: 67.199

Epoch 17: Validation loss decreased (0.574327 --> 0.571919).  Saving model ...
	 Train_Loss: 0.6473 Train_Acc: 64.770 Val_Loss: 0.5719  BEST VAL Loss: 0.5719  Val_Acc: 67.514

Epoch 18: Validation loss decreased (0.571919 --> 0.569985).  Saving model ...
	 Train_Loss: 0.6425 Train_Acc: 65.416 Val_Loss: 0.5700  BEST VAL Loss: 0.5700  Val_Acc: 67.413

Epoch 19: Validation loss did not decrease
	 Train_Loss: 0.6416 Train_Acc: 64.439 Val_Loss: 0.5702  BEST VAL Loss: 0.5700  Val_Acc: 65.495

Epoch 20: Validation loss decreased (0.569985 --> 0.568283).  Saving model ...
	 Train_Loss: 0.6370 Train_Acc: 65.710 Val_Loss: 0.5683  BEST VAL Loss: 0.5683  Val_Acc: 67.777

Epoch 21: Validation loss decreased (0.568283 --> 0.566599).  Saving model ...
	 Train_Loss: 0.6334 Train_Acc: 65.417 Val_Loss: 0.5666  BEST VAL Loss: 0.5666  Val_Acc: 67.903

Epoch 22: Validation loss decreased (0.566599 --> 0.564913).  Saving model ...
	 Train_Loss: 0.6305 Train_Acc: 64.913 Val_Loss: 0.5649  BEST VAL Loss: 0.5649  Val_Acc: 67.645

Epoch 23: Validation loss decreased (0.564913 --> 0.564672).  Saving model ...
	 Train_Loss: 0.6278 Train_Acc: 65.663 Val_Loss: 0.5647  BEST VAL Loss: 0.5647  Val_Acc: 67.010

Epoch 24: Validation loss decreased (0.564672 --> 0.563226).  Saving model ...
	 Train_Loss: 0.6259 Train_Acc: 64.877 Val_Loss: 0.5632  BEST VAL Loss: 0.5632  Val_Acc: 67.796

Epoch 25: Validation loss decreased (0.563226 --> 0.561916).  Saving model ...
	 Train_Loss: 0.6231 Train_Acc: 65.590 Val_Loss: 0.5619  BEST VAL Loss: 0.5619  Val_Acc: 67.102

Epoch 26: Validation loss decreased (0.561916 --> 0.560517).  Saving model ...
	 Train_Loss: 0.6223 Train_Acc: 64.585 Val_Loss: 0.5605  BEST VAL Loss: 0.5605  Val_Acc: 67.689

Epoch 27: Validation loss decreased (0.560517 --> 0.559493).  Saving model ...
	 Train_Loss: 0.6192 Train_Acc: 66.176 Val_Loss: 0.5595  BEST VAL Loss: 0.5595  Val_Acc: 68.107

Epoch 28: Validation loss decreased (0.559493 --> 0.558587).  Saving model ...
	 Train_Loss: 0.6174 Train_Acc: 65.528 Val_Loss: 0.5586  BEST VAL Loss: 0.5586  Val_Acc: 68.034

Epoch 29: Validation loss decreased (0.558587 --> 0.557424).  Saving model ...
	 Train_Loss: 0.6155 Train_Acc: 65.373 Val_Loss: 0.5574  BEST VAL Loss: 0.5574  Val_Acc: 68.068

Epoch 30: Validation loss decreased (0.557424 --> 0.556347).  Saving model ...
	 Train_Loss: 0.6146 Train_Acc: 65.172 Val_Loss: 0.5563  BEST VAL Loss: 0.5563  Val_Acc: 67.568

Epoch 31: Validation loss decreased (0.556347 --> 0.555237).  Saving model ...
	 Train_Loss: 0.6119 Train_Acc: 66.226 Val_Loss: 0.5552  BEST VAL Loss: 0.5552  Val_Acc: 68.233

Epoch 32: Validation loss decreased (0.555237 --> 0.554256).  Saving model ...
	 Train_Loss: 0.6108 Train_Acc: 65.291 Val_Loss: 0.5543  BEST VAL Loss: 0.5543  Val_Acc: 67.709

Epoch 33: Validation loss decreased (0.554256 --> 0.553396).  Saving model ...
	 Train_Loss: 0.6088 Train_Acc: 65.969 Val_Loss: 0.5534  BEST VAL Loss: 0.5534  Val_Acc: 67.840

Epoch 34: Validation loss did not decrease
	 Train_Loss: 0.6067 Train_Acc: 66.047 Val_Loss: 0.5534  BEST VAL Loss: 0.5534  Val_Acc: 66.350

Epoch 35: Validation loss decreased (0.553396 --> 0.552577).  Saving model ...
	 Train_Loss: 0.6054 Train_Acc: 65.375 Val_Loss: 0.5526  BEST VAL Loss: 0.5526  Val_Acc: 67.951

Epoch 36: Validation loss decreased (0.552577 --> 0.551797).  Saving model ...
	 Train_Loss: 0.6041 Train_Acc: 65.398 Val_Loss: 0.5518  BEST VAL Loss: 0.5518  Val_Acc: 67.990

Epoch 37: Validation loss decreased (0.551797 --> 0.551216).  Saving model ...
	 Train_Loss: 0.6023 Train_Acc: 66.041 Val_Loss: 0.5512  BEST VAL Loss: 0.5512  Val_Acc: 68.010

Epoch 38: Validation loss decreased (0.551216 --> 0.550337).  Saving model ...
	 Train_Loss: 0.6016 Train_Acc: 65.009 Val_Loss: 0.5503  BEST VAL Loss: 0.5503  Val_Acc: 68.194

Epoch 39: Validation loss decreased (0.550337 --> 0.549595).  Saving model ...
	 Train_Loss: 0.6000 Train_Acc: 66.099 Val_Loss: 0.5496  BEST VAL Loss: 0.5496  Val_Acc: 67.898

Epoch 40: Validation loss decreased (0.549595 --> 0.549164).  Saving model ...
	 Train_Loss: 0.5984 Train_Acc: 65.850 Val_Loss: 0.5492  BEST VAL Loss: 0.5492  Val_Acc: 67.369

Epoch 41: Validation loss decreased (0.549164 --> 0.548749).  Saving model ...
	 Train_Loss: 0.5973 Train_Acc: 65.543 Val_Loss: 0.5487  BEST VAL Loss: 0.5487  Val_Acc: 66.714

Epoch 42: Validation loss decreased (0.548749 --> 0.548589).  Saving model ...
	 Train_Loss: 0.5958 Train_Acc: 66.070 Val_Loss: 0.5486  BEST VAL Loss: 0.5486  Val_Acc: 68.199

Epoch 43: Validation loss decreased (0.548589 --> 0.548305).  Saving model ...
	 Train_Loss: 0.5945 Train_Acc: 66.048 Val_Loss: 0.5483  BEST VAL Loss: 0.5483  Val_Acc: 66.961

Epoch 44: Validation loss decreased (0.548305 --> 0.547562).  Saving model ...
	 Train_Loss: 0.5938 Train_Acc: 65.530 Val_Loss: 0.5476  BEST VAL Loss: 0.5476  Val_Acc: 67.976

Epoch 45: Validation loss decreased (0.547562 --> 0.547282).  Saving model ...
	 Train_Loss: 0.5924 Train_Acc: 66.092 Val_Loss: 0.5473  BEST VAL Loss: 0.5473  Val_Acc: 66.602

Epoch 46: Validation loss decreased (0.547282 --> 0.546511).  Saving model ...
	 Train_Loss: 0.5922 Train_Acc: 65.394 Val_Loss: 0.5465  BEST VAL Loss: 0.5465  Val_Acc: 68.073

Epoch 47: Validation loss decreased (0.546511 --> 0.545784).  Saving model ...
	 Train_Loss: 0.5907 Train_Acc: 66.503 Val_Loss: 0.5458  BEST VAL Loss: 0.5458  Val_Acc: 68.553

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.5894 Train_Acc: 66.270 Val_Loss: 0.5458  BEST VAL Loss: 0.5458  Val_Acc: 65.689

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.5882 Train_Acc: 65.888 Val_Loss: 0.5481  BEST VAL Loss: 0.5458  Val_Acc: 64.622

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.5872 Train_Acc: 65.954 Val_Loss: 0.5479  BEST VAL Loss: 0.5458  Val_Acc: 68.218

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.5866 Train_Acc: 65.928 Val_Loss: 0.5576  BEST VAL Loss: 0.5458  Val_Acc: 60.729

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.5856 Train_Acc: 65.797 Val_Loss: 0.5568  BEST VAL Loss: 0.5458  Val_Acc: 68.558

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.5844 Train_Acc: 66.429 Val_Loss: 0.5568  BEST VAL Loss: 0.5458  Val_Acc: 68.204

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.5836 Train_Acc: 65.993 Val_Loss: 0.5564  BEST VAL Loss: 0.5458  Val_Acc: 66.791

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.5831 Train_Acc: 65.547 Val_Loss: 0.5563  BEST VAL Loss: 0.5458  Val_Acc: 67.165

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.5822 Train_Acc: 65.988 Val_Loss: 0.5559  BEST VAL Loss: 0.5458  Val_Acc: 68.422

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.5812 Train_Acc: 66.207 Val_Loss: 0.5555  BEST VAL Loss: 0.5458  Val_Acc: 66.908

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.5803 Train_Acc: 66.042 Val_Loss: 0.5560  BEST VAL Loss: 0.5458  Val_Acc: 65.369

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.5796 Train_Acc: 65.944 Val_Loss: 0.5555  BEST VAL Loss: 0.5458  Val_Acc: 68.451

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.5787 Train_Acc: 66.160 Val_Loss: 0.5551  BEST VAL Loss: 0.5458  Val_Acc: 67.922

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.5781 Train_Acc: 65.834 Val_Loss: 0.5548  BEST VAL Loss: 0.5458  Val_Acc: 68.238

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.5771 Train_Acc: 66.276 Val_Loss: 0.5561  BEST VAL Loss: 0.5458  Val_Acc: 66.704

Epoch 63: Validation loss did not decrease
Early stopped at epoch : 63
LPS_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.64      0.96      0.76     85027
           1       0.90      0.42      0.57     79796

    accuracy                           0.70    164823
   macro avg       0.77      0.69      0.67    164823
weighted avg       0.77      0.70      0.67    164823

LPS_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.63      0.95      0.76     10628
           1       0.88      0.41      0.56      9975

    accuracy                           0.69     20603
   macro avg       0.75      0.68      0.66     20603
weighted avg       0.75      0.69      0.66     20603

LPS_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.63      0.95      0.76     10628
           1       0.88      0.42      0.56      9975

    accuracy                           0.69     20603
   macro avg       0.76      0.68      0.66     20603
weighted avg       0.75      0.69      0.66     20603

              precision    recall  f1-score   support

           0       0.63      0.95      0.76     10628
           1       0.88      0.42      0.56      9975

    accuracy                           0.69     20603
   macro avg       0.76      0.68      0.66     20603
weighted avg       0.75      0.69      0.66     20603

LPS_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.46      0.88      0.61     36797
           1       0.29      0.05      0.08     39687

    accuracy                           0.45     76484
   macro avg       0.38      0.46      0.34     76484
weighted avg       0.37      0.45      0.33     76484

              precision    recall  f1-score   support

           0       0.46      0.88      0.61     36797
           1       0.29      0.05      0.08     39687

    accuracy                           0.45     76484
   macro avg       0.38      0.46      0.34     76484
weighted avg       0.37      0.45      0.33     76484

completed
