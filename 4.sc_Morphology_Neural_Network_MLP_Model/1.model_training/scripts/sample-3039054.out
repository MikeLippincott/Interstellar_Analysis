[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '6beebe4a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '0643f475'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1b2a6c66'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '7f613d68'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (304610, 1270)
Number of total missing values across all columns: 277194
Data Subset Is Off
Wells held out for testing: ['C08' 'K08']
Wells to use for training, validation, and testing ['C02' 'C03' 'C09' 'K02' 'K03' 'K09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.330536).  Saving model ...
	 Train_Loss: 0.4530 Train_Acc: 79.077 Val_Loss: 0.3305  BEST VAL Loss: 0.3305  Val_Acc: 86.292

Epoch 1: Validation loss decreased (0.330536 --> 0.316293).  Saving model ...
	 Train_Loss: 0.4079 Train_Acc: 84.023 Val_Loss: 0.3163  BEST VAL Loss: 0.3163  Val_Acc: 87.680

Epoch 2: Validation loss decreased (0.316293 --> 0.305105).  Saving model ...
	 Train_Loss: 0.3852 Train_Acc: 85.165 Val_Loss: 0.3051  BEST VAL Loss: 0.3051  Val_Acc: 88.592

Epoch 3: Validation loss decreased (0.305105 --> 0.298566).  Saving model ...
	 Train_Loss: 0.3709 Train_Acc: 85.847 Val_Loss: 0.2986  BEST VAL Loss: 0.2986  Val_Acc: 88.933

Epoch 4: Validation loss decreased (0.298566 --> 0.293648).  Saving model ...
	 Train_Loss: 0.3615 Train_Acc: 86.136 Val_Loss: 0.2936  BEST VAL Loss: 0.2936  Val_Acc: 89.015

Epoch 5: Validation loss decreased (0.293648 --> 0.288891).  Saving model ...
	 Train_Loss: 0.3540 Train_Acc: 86.388 Val_Loss: 0.2889  BEST VAL Loss: 0.2889  Val_Acc: 89.155

Epoch 6: Validation loss decreased (0.288891 --> 0.284651).  Saving model ...
	 Train_Loss: 0.3477 Train_Acc: 86.720 Val_Loss: 0.2847  BEST VAL Loss: 0.2847  Val_Acc: 89.526

Epoch 7: Validation loss decreased (0.284651 --> 0.281215).  Saving model ...
	 Train_Loss: 0.3425 Train_Acc: 86.921 Val_Loss: 0.2812  BEST VAL Loss: 0.2812  Val_Acc: 89.709

Epoch 8: Validation loss decreased (0.281215 --> 0.278501).  Saving model ...
	 Train_Loss: 0.3382 Train_Acc: 86.956 Val_Loss: 0.2785  BEST VAL Loss: 0.2785  Val_Acc: 89.557

Epoch 9: Validation loss decreased (0.278501 --> 0.275541).  Saving model ...
	 Train_Loss: 0.3344 Train_Acc: 87.140 Val_Loss: 0.2755  BEST VAL Loss: 0.2755  Val_Acc: 90.124

Epoch 10: Validation loss decreased (0.275541 --> 0.274295).  Saving model ...
	 Train_Loss: 0.3311 Train_Acc: 87.268 Val_Loss: 0.2743  BEST VAL Loss: 0.2743  Val_Acc: 89.705

Epoch 11: Validation loss decreased (0.274295 --> 0.272207).  Saving model ...
	 Train_Loss: 0.3282 Train_Acc: 87.321 Val_Loss: 0.2722  BEST VAL Loss: 0.2722  Val_Acc: 90.032

Epoch 12: Validation loss decreased (0.272207 --> 0.270350).  Saving model ...
	 Train_Loss: 0.3254 Train_Acc: 87.518 Val_Loss: 0.2703  BEST VAL Loss: 0.2703  Val_Acc: 90.019

Epoch 13: Validation loss decreased (0.270350 --> 0.268899).  Saving model ...
	 Train_Loss: 0.3229 Train_Acc: 87.605 Val_Loss: 0.2689  BEST VAL Loss: 0.2689  Val_Acc: 90.102

Epoch 14: Validation loss decreased (0.268899 --> 0.267680).  Saving model ...
	 Train_Loss: 0.3206 Train_Acc: 87.670 Val_Loss: 0.2677  BEST VAL Loss: 0.2677  Val_Acc: 90.150

Epoch 15: Validation loss decreased (0.267680 --> 0.266507).  Saving model ...
	 Train_Loss: 0.3187 Train_Acc: 87.600 Val_Loss: 0.2665  BEST VAL Loss: 0.2665  Val_Acc: 90.019

Epoch 16: Validation loss decreased (0.266507 --> 0.265445).  Saving model ...
	 Train_Loss: 0.3169 Train_Acc: 87.715 Val_Loss: 0.2654  BEST VAL Loss: 0.2654  Val_Acc: 90.194

Epoch 17: Validation loss decreased (0.265445 --> 0.264841).  Saving model ...
	 Train_Loss: 0.3151 Train_Acc: 87.796 Val_Loss: 0.2648  BEST VAL Loss: 0.2648  Val_Acc: 90.089

Epoch 18: Validation loss decreased (0.264841 --> 0.264046).  Saving model ...
	 Train_Loss: 0.3136 Train_Acc: 87.813 Val_Loss: 0.2640  BEST VAL Loss: 0.2640  Val_Acc: 90.010

Epoch 19: Validation loss decreased (0.264046 --> 0.262800).  Saving model ...
	 Train_Loss: 0.3121 Train_Acc: 87.954 Val_Loss: 0.2628  BEST VAL Loss: 0.2628  Val_Acc: 90.360

Epoch 20: Validation loss decreased (0.262800 --> 0.262319).  Saving model ...
	 Train_Loss: 0.3108 Train_Acc: 87.874 Val_Loss: 0.2623  BEST VAL Loss: 0.2623  Val_Acc: 90.181

Epoch 21: Validation loss decreased (0.262319 --> 0.261525).  Saving model ...
	 Train_Loss: 0.3094 Train_Acc: 87.995 Val_Loss: 0.2615  BEST VAL Loss: 0.2615  Val_Acc: 90.185

Epoch 22: Validation loss decreased (0.261525 --> 0.260414).  Saving model ...
	 Train_Loss: 0.3081 Train_Acc: 88.063 Val_Loss: 0.2604  BEST VAL Loss: 0.2604  Val_Acc: 90.355

Epoch 23: Validation loss decreased (0.260414 --> 0.259649).  Saving model ...
	 Train_Loss: 0.3070 Train_Acc: 87.998 Val_Loss: 0.2596  BEST VAL Loss: 0.2596  Val_Acc: 90.473

Epoch 24: Validation loss decreased (0.259649 --> 0.259024).  Saving model ...
	 Train_Loss: 0.3059 Train_Acc: 88.008 Val_Loss: 0.2590  BEST VAL Loss: 0.2590  Val_Acc: 90.434

Epoch 25: Validation loss decreased (0.259024 --> 0.258226).  Saving model ...
	 Train_Loss: 0.3049 Train_Acc: 87.961 Val_Loss: 0.2582  BEST VAL Loss: 0.2582  Val_Acc: 90.630

Epoch 26: Validation loss decreased (0.258226 --> 0.257491).  Saving model ...
	 Train_Loss: 0.3040 Train_Acc: 88.082 Val_Loss: 0.2575  BEST VAL Loss: 0.2575  Val_Acc: 90.264

Epoch 27: Validation loss decreased (0.257491 --> 0.257331).  Saving model ...
	 Train_Loss: 0.3032 Train_Acc: 87.978 Val_Loss: 0.2573  BEST VAL Loss: 0.2573  Val_Acc: 90.351

Epoch 28: Validation loss decreased (0.257331 --> 0.257063).  Saving model ...
	 Train_Loss: 0.3024 Train_Acc: 88.049 Val_Loss: 0.2571  BEST VAL Loss: 0.2571  Val_Acc: 90.233

Epoch 29: Validation loss decreased (0.257063 --> 0.256665).  Saving model ...
	 Train_Loss: 0.3015 Train_Acc: 88.224 Val_Loss: 0.2567  BEST VAL Loss: 0.2567  Val_Acc: 90.517

Epoch 30: Validation loss decreased (0.256665 --> 0.256029).  Saving model ...
	 Train_Loss: 0.3007 Train_Acc: 88.224 Val_Loss: 0.2560  BEST VAL Loss: 0.2560  Val_Acc: 90.604

Epoch 31: Validation loss decreased (0.256029 --> 0.255428).  Saving model ...
	 Train_Loss: 0.2998 Train_Acc: 88.305 Val_Loss: 0.2554  BEST VAL Loss: 0.2554  Val_Acc: 90.547

Epoch 32: Validation loss decreased (0.255428 --> 0.254665).  Saving model ...
	 Train_Loss: 0.2990 Train_Acc: 88.315 Val_Loss: 0.2547  BEST VAL Loss: 0.2547  Val_Acc: 90.700

Epoch 33: Validation loss decreased (0.254665 --> 0.254301).  Saving model ...
	 Train_Loss: 0.2983 Train_Acc: 88.339 Val_Loss: 0.2543  BEST VAL Loss: 0.2543  Val_Acc: 90.639

Epoch 34: Validation loss decreased (0.254301 --> 0.253991).  Saving model ...
	 Train_Loss: 0.2976 Train_Acc: 88.325 Val_Loss: 0.2540  BEST VAL Loss: 0.2540  Val_Acc: 90.822

Epoch 35: Validation loss decreased (0.253991 --> 0.253490).  Saving model ...
	 Train_Loss: 0.2970 Train_Acc: 88.341 Val_Loss: 0.2535  BEST VAL Loss: 0.2535  Val_Acc: 90.630

Epoch 36: Validation loss decreased (0.253490 --> 0.252913).  Saving model ...
	 Train_Loss: 0.2963 Train_Acc: 88.344 Val_Loss: 0.2529  BEST VAL Loss: 0.2529  Val_Acc: 90.792

Epoch 37: Validation loss decreased (0.252913 --> 0.252669).  Saving model ...
	 Train_Loss: 0.2957 Train_Acc: 88.295 Val_Loss: 0.2527  BEST VAL Loss: 0.2527  Val_Acc: 90.656

Epoch 38: Validation loss decreased (0.252669 --> 0.252283).  Saving model ...
	 Train_Loss: 0.2950 Train_Acc: 88.341 Val_Loss: 0.2523  BEST VAL Loss: 0.2523  Val_Acc: 90.648

Epoch 39: Validation loss decreased (0.252283 --> 0.251938).  Saving model ...
	 Train_Loss: 0.2945 Train_Acc: 88.373 Val_Loss: 0.2519  BEST VAL Loss: 0.2519  Val_Acc: 90.635

Epoch 40: Validation loss decreased (0.251938 --> 0.251387).  Saving model ...
	 Train_Loss: 0.2939 Train_Acc: 88.351 Val_Loss: 0.2514  BEST VAL Loss: 0.2514  Val_Acc: 90.883

Epoch 41: Validation loss decreased (0.251387 --> 0.251024).  Saving model ...
	 Train_Loss: 0.2934 Train_Acc: 88.383 Val_Loss: 0.2510  BEST VAL Loss: 0.2510  Val_Acc: 90.578

Epoch 42: Validation loss decreased (0.251024 --> 0.250664).  Saving model ...
	 Train_Loss: 0.2928 Train_Acc: 88.416 Val_Loss: 0.2507  BEST VAL Loss: 0.2507  Val_Acc: 90.739

Epoch 43: Validation loss decreased (0.250664 --> 0.250471).  Saving model ...
	 Train_Loss: 0.2924 Train_Acc: 88.386 Val_Loss: 0.2505  BEST VAL Loss: 0.2505  Val_Acc: 90.683

Epoch 44: Validation loss decreased (0.250471 --> 0.250452).  Saving model ...
	 Train_Loss: 0.2919 Train_Acc: 88.397 Val_Loss: 0.2505  BEST VAL Loss: 0.2505  Val_Acc: 90.539

Epoch 45: Validation loss decreased (0.250452 --> 0.249924).  Saving model ...
	 Train_Loss: 0.2914 Train_Acc: 88.542 Val_Loss: 0.2499  BEST VAL Loss: 0.2499  Val_Acc: 90.949

Epoch 46: Validation loss decreased (0.249924 --> 0.249401).  Saving model ...
	 Train_Loss: 0.2909 Train_Acc: 88.465 Val_Loss: 0.2494  BEST VAL Loss: 0.2494  Val_Acc: 91.093

Epoch 47: Validation loss decreased (0.249401 --> 0.248936).  Saving model ...
	 Train_Loss: 0.2904 Train_Acc: 88.522 Val_Loss: 0.2489  BEST VAL Loss: 0.2489  Val_Acc: 91.067

Epoch 48: Validation loss decreased (0.248936 --> 0.248709).  Saving model ...
	 Train_Loss: 0.2900 Train_Acc: 88.496 Val_Loss: 0.2487  BEST VAL Loss: 0.2487  Val_Acc: 90.739

Epoch 49: Validation loss decreased (0.248709 --> 0.248481).  Saving model ...
	 Train_Loss: 0.2895 Train_Acc: 88.575 Val_Loss: 0.2485  BEST VAL Loss: 0.2485  Val_Acc: 90.896

Epoch 50: Validation loss decreased (0.248481 --> 0.248024).  Saving model ...
	 Train_Loss: 0.2891 Train_Acc: 88.606 Val_Loss: 0.2480  BEST VAL Loss: 0.2480  Val_Acc: 91.088

Epoch 51: Validation loss decreased (0.248024 --> 0.247740).  Saving model ...
	 Train_Loss: 0.2886 Train_Acc: 88.640 Val_Loss: 0.2477  BEST VAL Loss: 0.2477  Val_Acc: 91.014

Epoch 52: Validation loss decreased (0.247740 --> 0.247536).  Saving model ...
	 Train_Loss: 0.2882 Train_Acc: 88.623 Val_Loss: 0.2475  BEST VAL Loss: 0.2475  Val_Acc: 90.888

Epoch 53: Validation loss decreased (0.247536 --> 0.247274).  Saving model ...
	 Train_Loss: 0.2878 Train_Acc: 88.628 Val_Loss: 0.2473  BEST VAL Loss: 0.2473  Val_Acc: 90.861

Epoch 54: Validation loss decreased (0.247274 --> 0.247265).  Saving model ...
	 Train_Loss: 0.2874 Train_Acc: 88.618 Val_Loss: 0.2473  BEST VAL Loss: 0.2473  Val_Acc: 90.434

Epoch 55: Validation loss decreased (0.247265 --> 0.247105).  Saving model ...
	 Train_Loss: 0.2870 Train_Acc: 88.642 Val_Loss: 0.2471  BEST VAL Loss: 0.2471  Val_Acc: 90.923

Epoch 56: Validation loss decreased (0.247105 --> 0.247077).  Saving model ...
	 Train_Loss: 0.2867 Train_Acc: 88.700 Val_Loss: 0.2471  BEST VAL Loss: 0.2471  Val_Acc: 90.800

Epoch 57: Validation loss decreased (0.247077 --> 0.246708).  Saving model ...
	 Train_Loss: 0.2863 Train_Acc: 88.625 Val_Loss: 0.2467  BEST VAL Loss: 0.2467  Val_Acc: 91.045

Epoch 58: Validation loss decreased (0.246708 --> 0.246590).  Saving model ...
	 Train_Loss: 0.2859 Train_Acc: 88.670 Val_Loss: 0.2466  BEST VAL Loss: 0.2466  Val_Acc: 90.757

Epoch 59: Validation loss decreased (0.246590 --> 0.246299).  Saving model ...
	 Train_Loss: 0.2856 Train_Acc: 88.620 Val_Loss: 0.2463  BEST VAL Loss: 0.2463  Val_Acc: 91.206

Epoch 60: Validation loss decreased (0.246299 --> 0.246019).  Saving model ...
	 Train_Loss: 0.2853 Train_Acc: 88.712 Val_Loss: 0.2460  BEST VAL Loss: 0.2460  Val_Acc: 90.875

Epoch 61: Validation loss decreased (0.246019 --> 0.245829).  Saving model ...
	 Train_Loss: 0.2849 Train_Acc: 88.730 Val_Loss: 0.2458  BEST VAL Loss: 0.2458  Val_Acc: 91.136

Epoch 62: Validation loss decreased (0.245829 --> 0.245724).  Saving model ...
	 Train_Loss: 0.2846 Train_Acc: 88.679 Val_Loss: 0.2457  BEST VAL Loss: 0.2457  Val_Acc: 90.669

Epoch 63: Validation loss decreased (0.245724 --> 0.245458).  Saving model ...
	 Train_Loss: 0.2843 Train_Acc: 88.699 Val_Loss: 0.2455  BEST VAL Loss: 0.2455  Val_Acc: 91.254

Epoch 64: Validation loss decreased (0.245458 --> 0.245220).  Saving model ...
	 Train_Loss: 0.2839 Train_Acc: 88.698 Val_Loss: 0.2452  BEST VAL Loss: 0.2452  Val_Acc: 90.984

Epoch 65: Validation loss decreased (0.245220 --> 0.245038).  Saving model ...
	 Train_Loss: 0.2836 Train_Acc: 88.779 Val_Loss: 0.2450  BEST VAL Loss: 0.2450  Val_Acc: 90.905

Epoch 66: Validation loss decreased (0.245038 --> 0.244875).  Saving model ...
	 Train_Loss: 0.2833 Train_Acc: 88.748 Val_Loss: 0.2449  BEST VAL Loss: 0.2449  Val_Acc: 91.005

Epoch 67: Validation loss decreased (0.244875 --> 0.244729).  Saving model ...
	 Train_Loss: 0.2830 Train_Acc: 88.586 Val_Loss: 0.2447  BEST VAL Loss: 0.2447  Val_Acc: 91.023

Epoch 68: Validation loss decreased (0.244729 --> 0.244546).  Saving model ...
	 Train_Loss: 0.2828 Train_Acc: 88.716 Val_Loss: 0.2445  BEST VAL Loss: 0.2445  Val_Acc: 91.036

Epoch 69: Validation loss decreased (0.244546 --> 0.244501).  Saving model ...
	 Train_Loss: 0.2825 Train_Acc: 88.912 Val_Loss: 0.2445  BEST VAL Loss: 0.2445  Val_Acc: 90.875

Epoch 70: Validation loss decreased (0.244501 --> 0.244244).  Saving model ...
	 Train_Loss: 0.2821 Train_Acc: 88.803 Val_Loss: 0.2442  BEST VAL Loss: 0.2442  Val_Acc: 91.123

Epoch 71: Validation loss decreased (0.244244 --> 0.244136).  Saving model ...
	 Train_Loss: 0.2819 Train_Acc: 88.693 Val_Loss: 0.2441  BEST VAL Loss: 0.2441  Val_Acc: 91.246

Epoch 72: Validation loss decreased (0.244136 --> 0.244055).  Saving model ...
	 Train_Loss: 0.2816 Train_Acc: 88.706 Val_Loss: 0.2441  BEST VAL Loss: 0.2441  Val_Acc: 91.128

Epoch 73: Validation loss decreased (0.244055 --> 0.244036).  Saving model ...
	 Train_Loss: 0.2813 Train_Acc: 88.807 Val_Loss: 0.2440  BEST VAL Loss: 0.2440  Val_Acc: 91.036

Epoch 74: Validation loss decreased (0.244036 --> 0.243966).  Saving model ...
	 Train_Loss: 0.2811 Train_Acc: 88.657 Val_Loss: 0.2440  BEST VAL Loss: 0.2440  Val_Acc: 90.971

Epoch 75: Validation loss decreased (0.243966 --> 0.243867).  Saving model ...
	 Train_Loss: 0.2809 Train_Acc: 88.844 Val_Loss: 0.2439  BEST VAL Loss: 0.2439  Val_Acc: 91.128

Epoch 76: Validation loss decreased (0.243867 --> 0.243752).  Saving model ...
	 Train_Loss: 0.2806 Train_Acc: 88.807 Val_Loss: 0.2438  BEST VAL Loss: 0.2438  Val_Acc: 90.944

Epoch 77: Validation loss decreased (0.243752 --> 0.243699).  Saving model ...
	 Train_Loss: 0.2804 Train_Acc: 88.790 Val_Loss: 0.2437  BEST VAL Loss: 0.2437  Val_Acc: 91.040

Epoch 78: Validation loss decreased (0.243699 --> 0.243620).  Saving model ...
	 Train_Loss: 0.2801 Train_Acc: 88.698 Val_Loss: 0.2436  BEST VAL Loss: 0.2436  Val_Acc: 91.128

Epoch 79: Validation loss decreased (0.243620 --> 0.243424).  Saving model ...
	 Train_Loss: 0.2799 Train_Acc: 88.811 Val_Loss: 0.2434  BEST VAL Loss: 0.2434  Val_Acc: 91.128

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.2796 Train_Acc: 88.722 Val_Loss: 0.2435  BEST VAL Loss: 0.2434  Val_Acc: 91.023

Epoch 81: Validation loss decreased (0.243424 --> 0.243281).  Saving model ...
	 Train_Loss: 0.2795 Train_Acc: 88.663 Val_Loss: 0.2433  BEST VAL Loss: 0.2433  Val_Acc: 91.328

Epoch 82: Validation loss decreased (0.243281 --> 0.243203).  Saving model ...
	 Train_Loss: 0.2792 Train_Acc: 88.837 Val_Loss: 0.2432  BEST VAL Loss: 0.2432  Val_Acc: 91.123

Epoch 83: Validation loss decreased (0.243203 --> 0.243075).  Saving model ...
	 Train_Loss: 0.2790 Train_Acc: 88.802 Val_Loss: 0.2431  BEST VAL Loss: 0.2431  Val_Acc: 91.193

Epoch 84: Validation loss decreased (0.243075 --> 0.243004).  Saving model ...
	 Train_Loss: 0.2788 Train_Acc: 88.830 Val_Loss: 0.2430  BEST VAL Loss: 0.2430  Val_Acc: 91.080

Epoch 85: Validation loss decreased (0.243004 --> 0.242851).  Saving model ...
	 Train_Loss: 0.2786 Train_Acc: 88.864 Val_Loss: 0.2429  BEST VAL Loss: 0.2429  Val_Acc: 91.350

Epoch 86: Validation loss decreased (0.242851 --> 0.242734).  Saving model ...
	 Train_Loss: 0.2784 Train_Acc: 88.869 Val_Loss: 0.2427  BEST VAL Loss: 0.2427  Val_Acc: 91.141

Epoch 87: Validation loss decreased (0.242734 --> 0.242586).  Saving model ...
	 Train_Loss: 0.2782 Train_Acc: 88.805 Val_Loss: 0.2426  BEST VAL Loss: 0.2426  Val_Acc: 91.005

Epoch 88: Validation loss decreased (0.242586 --> 0.242426).  Saving model ...
	 Train_Loss: 0.2780 Train_Acc: 88.817 Val_Loss: 0.2424  BEST VAL Loss: 0.2424  Val_Acc: 91.294

Epoch 89: Validation loss decreased (0.242426 --> 0.242349).  Saving model ...
	 Train_Loss: 0.2778 Train_Acc: 88.794 Val_Loss: 0.2423  BEST VAL Loss: 0.2423  Val_Acc: 91.075

Epoch 90: Validation loss decreased (0.242349 --> 0.242345).  Saving model ...
	 Train_Loss: 0.2776 Train_Acc: 88.902 Val_Loss: 0.2423  BEST VAL Loss: 0.2423  Val_Acc: 90.971

Epoch 91: Validation loss decreased (0.242345 --> 0.242179).  Saving model ...
	 Train_Loss: 0.2774 Train_Acc: 88.916 Val_Loss: 0.2422  BEST VAL Loss: 0.2422  Val_Acc: 91.219

Epoch 92: Validation loss decreased (0.242179 --> 0.242082).  Saving model ...
	 Train_Loss: 0.2772 Train_Acc: 88.902 Val_Loss: 0.2421  BEST VAL Loss: 0.2421  Val_Acc: 90.966

Epoch 93: Validation loss decreased (0.242082 --> 0.241983).  Saving model ...
	 Train_Loss: 0.2770 Train_Acc: 88.903 Val_Loss: 0.2420  BEST VAL Loss: 0.2420  Val_Acc: 91.167

Epoch 94: Validation loss decreased (0.241983 --> 0.241911).  Saving model ...
	 Train_Loss: 0.2768 Train_Acc: 88.905 Val_Loss: 0.2419  BEST VAL Loss: 0.2419  Val_Acc: 91.001

Epoch 95: Validation loss decreased (0.241911 --> 0.241805).  Saving model ...
	 Train_Loss: 0.2766 Train_Acc: 88.940 Val_Loss: 0.2418  BEST VAL Loss: 0.2418  Val_Acc: 91.167

Epoch 96: Validation loss decreased (0.241805 --> 0.241741).  Saving model ...
	 Train_Loss: 0.2764 Train_Acc: 88.919 Val_Loss: 0.2417  BEST VAL Loss: 0.2417  Val_Acc: 91.320

Epoch 97: Validation loss decreased (0.241741 --> 0.241595).  Saving model ...
	 Train_Loss: 0.2763 Train_Acc: 88.879 Val_Loss: 0.2416  BEST VAL Loss: 0.2416  Val_Acc: 91.355

Epoch 98: Validation loss decreased (0.241595 --> 0.241456).  Saving model ...
	 Train_Loss: 0.2761 Train_Acc: 88.964 Val_Loss: 0.2415  BEST VAL Loss: 0.2415  Val_Acc: 91.254

Epoch 99: Validation loss decreased (0.241456 --> 0.241337).  Saving model ...
	 Train_Loss: 0.2759 Train_Acc: 88.976 Val_Loss: 0.2413  BEST VAL Loss: 0.2413  Val_Acc: 91.298

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.91      0.92     82968
           1       0.92      0.94      0.93    100339

    accuracy                           0.93    183307
   macro avg       0.93      0.93      0.93    183307
weighted avg       0.93      0.93      0.93    183307

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.92      0.89      0.90     10371
           1       0.91      0.93      0.92     12543

    accuracy                           0.91     22914
   macro avg       0.91      0.91      0.91     22914
weighted avg       0.91      0.91      0.91     22914

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.91      0.89      0.90     10371
           1       0.91      0.93      0.92     12543

    accuracy                           0.91     22914
   macro avg       0.91      0.91      0.91     22914
weighted avg       0.91      0.91      0.91     22914

              precision    recall  f1-score   support

           0       0.91      0.89      0.90     10371
           1       0.91      0.93      0.92     12543

    accuracy                           0.91     22914
   macro avg       0.91      0.91      0.91     22914
weighted avg       0.91      0.91      0.91     22914

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.92      0.98      0.94     34887
           1       0.98      0.92      0.95     40588

    accuracy                           0.95     75475
   macro avg       0.95      0.95      0.95     75475
weighted avg       0.95      0.95      0.95     75475

              precision    recall  f1-score   support

           0       0.92      0.98      0.94     34887
           1       0.98      0.92      0.95     40588

    accuracy                           0.95     75475
   macro avg       0.95      0.95      0.95     75475
weighted avg       0.95      0.95      0.95     75475

completed
