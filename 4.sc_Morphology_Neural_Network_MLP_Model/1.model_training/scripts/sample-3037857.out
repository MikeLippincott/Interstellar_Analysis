[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ef12a6b6'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '9cb0016d'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '994c677b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'f53a3956'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: DMSO_0.100_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: DMSO_0.100_DMSO_0.025
TREATMENT_NAME: Flagellin_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (51452, 1276)
Number of total missing values across all columns: 102904
Data Subset Is Off
Wells held out for testing: ['I14' 'M23']
Wells to use for training, validation, and testing ['B14' 'C14' 'B15' 'C15' 'J14' 'I15' 'J15' 'M18' 'M19' 'M22']
Number of in features:  1251
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.553061).  Saving model ...
	 Train_Loss: 0.5797 Train_Acc: 71.836 Val_Loss: 0.5531  BEST VAL Loss: 0.5531  Val_Acc: 72.341

Epoch 1: Validation loss decreased (0.553061 --> 0.543714).  Saving model ...
	 Train_Loss: 0.5623 Train_Acc: 72.329 Val_Loss: 0.5437  BEST VAL Loss: 0.5437  Val_Acc: 72.341

Epoch 2: Validation loss decreased (0.543714 --> 0.536747).  Saving model ...
	 Train_Loss: 0.5520 Train_Acc: 72.329 Val_Loss: 0.5367  BEST VAL Loss: 0.5367  Val_Acc: 72.341

Epoch 3: Validation loss decreased (0.536747 --> 0.531807).  Saving model ...
	 Train_Loss: 0.5443 Train_Acc: 72.411 Val_Loss: 0.5318  BEST VAL Loss: 0.5318  Val_Acc: 72.341

Epoch 4: Validation loss decreased (0.531807 --> 0.531374).  Saving model ...
	 Train_Loss: 0.5381 Train_Acc: 72.455 Val_Loss: 0.5314  BEST VAL Loss: 0.5314  Val_Acc: 72.341

Epoch 5: Validation loss decreased (0.531374 --> 0.528665).  Saving model ...
	 Train_Loss: 0.5320 Train_Acc: 72.476 Val_Loss: 0.5287  BEST VAL Loss: 0.5287  Val_Acc: 72.341

Epoch 6: Validation loss decreased (0.528665 --> 0.523948).  Saving model ...
	 Train_Loss: 0.5267 Train_Acc: 72.764 Val_Loss: 0.5239  BEST VAL Loss: 0.5239  Val_Acc: 76.567

Epoch 7: Validation loss decreased (0.523948 --> 0.523533).  Saving model ...
	 Train_Loss: 0.5214 Train_Acc: 75.285 Val_Loss: 0.5235  BEST VAL Loss: 0.5235  Val_Acc: 73.327

Epoch 8: Validation loss decreased (0.523533 --> 0.519860).  Saving model ...
	 Train_Loss: 0.5166 Train_Acc: 75.317 Val_Loss: 0.5199  BEST VAL Loss: 0.5199  Val_Acc: 76.497

Epoch 9: Validation loss decreased (0.519860 --> 0.517860).  Saving model ...
	 Train_Loss: 0.5128 Train_Acc: 75.969 Val_Loss: 0.5179  BEST VAL Loss: 0.5179  Val_Acc: 75.652

Epoch 10: Validation loss decreased (0.517860 --> 0.514872).  Saving model ...
	 Train_Loss: 0.5090 Train_Acc: 76.318 Val_Loss: 0.5149  BEST VAL Loss: 0.5149  Val_Acc: 77.131

Epoch 11: Validation loss decreased (0.514872 --> 0.512044).  Saving model ...
	 Train_Loss: 0.5056 Train_Acc: 76.679 Val_Loss: 0.5120  BEST VAL Loss: 0.5120  Val_Acc: 76.591

Epoch 12: Validation loss decreased (0.512044 --> 0.508900).  Saving model ...
	 Train_Loss: 0.5021 Train_Acc: 76.735 Val_Loss: 0.5089  BEST VAL Loss: 0.5089  Val_Acc: 78.493

Epoch 13: Validation loss decreased (0.508900 --> 0.506108).  Saving model ...
	 Train_Loss: 0.4988 Train_Acc: 76.802 Val_Loss: 0.5061  BEST VAL Loss: 0.5061  Val_Acc: 77.976

Epoch 14: Validation loss decreased (0.506108 --> 0.505616).  Saving model ...
	 Train_Loss: 0.4958 Train_Acc: 77.345 Val_Loss: 0.5056  BEST VAL Loss: 0.5056  Val_Acc: 75.464

Epoch 15: Validation loss decreased (0.505616 --> 0.503510).  Saving model ...
	 Train_Loss: 0.4932 Train_Acc: 77.286 Val_Loss: 0.5035  BEST VAL Loss: 0.5035  Val_Acc: 77.272

Epoch 16: Validation loss decreased (0.503510 --> 0.501774).  Saving model ...
	 Train_Loss: 0.4903 Train_Acc: 77.630 Val_Loss: 0.5018  BEST VAL Loss: 0.5018  Val_Acc: 77.530

Epoch 17: Validation loss decreased (0.501774 --> 0.499460).  Saving model ...
	 Train_Loss: 0.4878 Train_Acc: 77.615 Val_Loss: 0.4995  BEST VAL Loss: 0.4995  Val_Acc: 78.187

Epoch 18: Validation loss decreased (0.499460 --> 0.497634).  Saving model ...
	 Train_Loss: 0.4854 Train_Acc: 77.759 Val_Loss: 0.4976  BEST VAL Loss: 0.4976  Val_Acc: 77.812

Epoch 19: Validation loss decreased (0.497634 --> 0.495858).  Saving model ...
	 Train_Loss: 0.4831 Train_Acc: 77.662 Val_Loss: 0.4959  BEST VAL Loss: 0.4959  Val_Acc: 78.633

Epoch 20: Validation loss decreased (0.495858 --> 0.494095).  Saving model ...
	 Train_Loss: 0.4812 Train_Acc: 77.553 Val_Loss: 0.4941  BEST VAL Loss: 0.4941  Val_Acc: 78.493

Epoch 21: Validation loss decreased (0.494095 --> 0.492782).  Saving model ...
	 Train_Loss: 0.4789 Train_Acc: 78.234 Val_Loss: 0.4928  BEST VAL Loss: 0.4928  Val_Acc: 78.211

Epoch 22: Validation loss decreased (0.492782 --> 0.491990).  Saving model ...
	 Train_Loss: 0.4769 Train_Acc: 77.838 Val_Loss: 0.4920  BEST VAL Loss: 0.4920  Val_Acc: 78.446

Epoch 23: Validation loss decreased (0.491990 --> 0.490951).  Saving model ...
	 Train_Loss: 0.4750 Train_Acc: 78.431 Val_Loss: 0.4910  BEST VAL Loss: 0.4910  Val_Acc: 77.882

Epoch 24: Validation loss decreased (0.490951 --> 0.490320).  Saving model ...
	 Train_Loss: 0.4734 Train_Acc: 77.870 Val_Loss: 0.4903  BEST VAL Loss: 0.4903  Val_Acc: 78.352

Epoch 25: Validation loss decreased (0.490320 --> 0.488594).  Saving model ...
	 Train_Loss: 0.4718 Train_Acc: 77.926 Val_Loss: 0.4886  BEST VAL Loss: 0.4886  Val_Acc: 78.986

Epoch 26: Validation loss decreased (0.488594 --> 0.487740).  Saving model ...
	 Train_Loss: 0.4702 Train_Acc: 78.581 Val_Loss: 0.4877  BEST VAL Loss: 0.4877  Val_Acc: 78.986

Epoch 27: Validation loss decreased (0.487740 --> 0.486393).  Saving model ...
	 Train_Loss: 0.4685 Train_Acc: 78.349 Val_Loss: 0.4864  BEST VAL Loss: 0.4864  Val_Acc: 79.526

Epoch 28: Validation loss decreased (0.486393 --> 0.485296).  Saving model ...
	 Train_Loss: 0.4669 Train_Acc: 78.384 Val_Loss: 0.4853  BEST VAL Loss: 0.4853  Val_Acc: 79.408

Epoch 29: Validation loss decreased (0.485296 --> 0.483792).  Saving model ...
	 Train_Loss: 0.4654 Train_Acc: 78.419 Val_Loss: 0.4838  BEST VAL Loss: 0.4838  Val_Acc: 79.526

Epoch 30: Validation loss decreased (0.483792 --> 0.483415).  Saving model ...
	 Train_Loss: 0.4639 Train_Acc: 78.478 Val_Loss: 0.4834  BEST VAL Loss: 0.4834  Val_Acc: 78.798

Epoch 31: Validation loss decreased (0.483415 --> 0.482143).  Saving model ...
	 Train_Loss: 0.4624 Train_Acc: 78.742 Val_Loss: 0.4821  BEST VAL Loss: 0.4821  Val_Acc: 79.878

Epoch 32: Validation loss decreased (0.482143 --> 0.482020).  Saving model ...
	 Train_Loss: 0.4611 Train_Acc: 78.493 Val_Loss: 0.4820  BEST VAL Loss: 0.4820  Val_Acc: 77.436

Epoch 33: Validation loss decreased (0.482020 --> 0.481600).  Saving model ...
	 Train_Loss: 0.4598 Train_Acc: 78.369 Val_Loss: 0.4816  BEST VAL Loss: 0.4816  Val_Acc: 77.953

Epoch 34: Validation loss decreased (0.481600 --> 0.480694).  Saving model ...
	 Train_Loss: 0.4585 Train_Acc: 78.733 Val_Loss: 0.4807  BEST VAL Loss: 0.4807  Val_Acc: 78.633

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.4572 Train_Acc: 78.504 Val_Loss: 0.4808  BEST VAL Loss: 0.4807  Val_Acc: 78.164

Epoch 36: Validation loss decreased (0.480694 --> 0.480117).  Saving model ...
	 Train_Loss: 0.4559 Train_Acc: 78.639 Val_Loss: 0.4801  BEST VAL Loss: 0.4801  Val_Acc: 79.972

Epoch 37: Validation loss decreased (0.480117 --> 0.480024).  Saving model ...
	 Train_Loss: 0.4549 Train_Acc: 78.810 Val_Loss: 0.4800  BEST VAL Loss: 0.4800  Val_Acc: 79.267

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.4537 Train_Acc: 78.724 Val_Loss: 0.4807  BEST VAL Loss: 0.4800  Val_Acc: 78.516

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.4527 Train_Acc: 78.645 Val_Loss: 0.4804  BEST VAL Loss: 0.4800  Val_Acc: 78.798

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.4515 Train_Acc: 78.874 Val_Loss: 0.4802  BEST VAL Loss: 0.4800  Val_Acc: 78.657

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.4505 Train_Acc: 78.906 Val_Loss: 0.4803  BEST VAL Loss: 0.4800  Val_Acc: 78.422

Epoch 42: Validation loss decreased (0.480024 --> 0.480001).  Saving model ...
	 Train_Loss: 0.4495 Train_Acc: 79.006 Val_Loss: 0.4800  BEST VAL Loss: 0.4800  Val_Acc: 79.009

Epoch 43: Validation loss decreased (0.480001 --> 0.479780).  Saving model ...
	 Train_Loss: 0.4486 Train_Acc: 78.716 Val_Loss: 0.4798  BEST VAL Loss: 0.4798  Val_Acc: 78.540

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.4476 Train_Acc: 78.868 Val_Loss: 0.4799  BEST VAL Loss: 0.4798  Val_Acc: 77.272

Epoch 45: Validation loss decreased (0.479780 --> 0.479552).  Saving model ...
	 Train_Loss: 0.4468 Train_Acc: 79.000 Val_Loss: 0.4796  BEST VAL Loss: 0.4796  Val_Acc: 79.455

Epoch 46: Validation loss decreased (0.479552 --> 0.479088).  Saving model ...
	 Train_Loss: 0.4459 Train_Acc: 78.660 Val_Loss: 0.4791  BEST VAL Loss: 0.4791  Val_Acc: 78.704

Epoch 47: Validation loss decreased (0.479088 --> 0.478938).  Saving model ...
	 Train_Loss: 0.4449 Train_Acc: 78.909 Val_Loss: 0.4789  BEST VAL Loss: 0.4789  Val_Acc: 78.493

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.4441 Train_Acc: 79.053 Val_Loss: 0.4794  BEST VAL Loss: 0.4789  Val_Acc: 77.530

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.4433 Train_Acc: 79.432 Val_Loss: 0.4793  BEST VAL Loss: 0.4789  Val_Acc: 79.150

Epoch 50: Validation loss decreased (0.478938 --> 0.478841).  Saving model ...
	 Train_Loss: 0.4423 Train_Acc: 80.503 Val_Loss: 0.4788  BEST VAL Loss: 0.4788  Val_Acc: 78.610

Epoch 51: Validation loss decreased (0.478841 --> 0.478283).  Saving model ...
	 Train_Loss: 0.4414 Train_Acc: 80.233 Val_Loss: 0.4783  BEST VAL Loss: 0.4783  Val_Acc: 79.526

Epoch 52: Validation loss decreased (0.478283 --> 0.477508).  Saving model ...
	 Train_Loss: 0.4406 Train_Acc: 80.148 Val_Loss: 0.4775  BEST VAL Loss: 0.4775  Val_Acc: 79.549

Epoch 53: Validation loss decreased (0.477508 --> 0.476962).  Saving model ...
	 Train_Loss: 0.4396 Train_Acc: 80.377 Val_Loss: 0.4770  BEST VAL Loss: 0.4770  Val_Acc: 79.667

Epoch 54: Validation loss decreased (0.476962 --> 0.476772).  Saving model ...
	 Train_Loss: 0.4386 Train_Acc: 80.221 Val_Loss: 0.4768  BEST VAL Loss: 0.4768  Val_Acc: 78.962

Epoch 55: Validation loss decreased (0.476772 --> 0.476197).  Saving model ...
	 Train_Loss: 0.4378 Train_Acc: 80.248 Val_Loss: 0.4762  BEST VAL Loss: 0.4762  Val_Acc: 79.667

Epoch 56: Validation loss decreased (0.476197 --> 0.476068).  Saving model ...
	 Train_Loss: 0.4370 Train_Acc: 80.183 Val_Loss: 0.4761  BEST VAL Loss: 0.4761  Val_Acc: 79.080

Epoch 57: Validation loss decreased (0.476068 --> 0.475747).  Saving model ...
	 Train_Loss: 0.4361 Train_Acc: 80.568 Val_Loss: 0.4757  BEST VAL Loss: 0.4757  Val_Acc: 80.066

Epoch 58: Validation loss decreased (0.475747 --> 0.475543).  Saving model ...
	 Train_Loss: 0.4352 Train_Acc: 80.380 Val_Loss: 0.4755  BEST VAL Loss: 0.4755  Val_Acc: 79.150

Epoch 59: Validation loss decreased (0.475543 --> 0.475068).  Saving model ...
	 Train_Loss: 0.4345 Train_Acc: 79.922 Val_Loss: 0.4751  BEST VAL Loss: 0.4751  Val_Acc: 79.620

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.4338 Train_Acc: 80.374 Val_Loss: 0.4751  BEST VAL Loss: 0.4751  Val_Acc: 78.986

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.4330 Train_Acc: 80.427 Val_Loss: 0.4763  BEST VAL Loss: 0.4751  Val_Acc: 78.070

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.4323 Train_Acc: 80.224 Val_Loss: 0.4762  BEST VAL Loss: 0.4751  Val_Acc: 79.291

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.4316 Train_Acc: 80.368 Val_Loss: 0.4761  BEST VAL Loss: 0.4751  Val_Acc: 79.831

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.4308 Train_Acc: 80.641 Val_Loss: 0.4760  BEST VAL Loss: 0.4751  Val_Acc: 79.361

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.4301 Train_Acc: 80.277 Val_Loss: 0.4757  BEST VAL Loss: 0.4751  Val_Acc: 78.774

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.4294 Train_Acc: 80.732 Val_Loss: 0.4757  BEST VAL Loss: 0.4751  Val_Acc: 77.647

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.4287 Train_Acc: 80.544 Val_Loss: 0.4762  BEST VAL Loss: 0.4751  Val_Acc: 76.192

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.4281 Train_Acc: 80.345 Val_Loss: 0.4761  BEST VAL Loss: 0.4751  Val_Acc: 78.892

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.4274 Train_Acc: 80.708 Val_Loss: 0.4764  BEST VAL Loss: 0.4751  Val_Acc: 79.714

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.4267 Train_Acc: 80.641 Val_Loss: 0.4764  BEST VAL Loss: 0.4751  Val_Acc: 78.587

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.4261 Train_Acc: 80.576 Val_Loss: 0.4761  BEST VAL Loss: 0.4751  Val_Acc: 79.878

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.4255 Train_Acc: 80.700 Val_Loss: 0.4765  BEST VAL Loss: 0.4751  Val_Acc: 78.774

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.4248 Train_Acc: 80.703 Val_Loss: 0.4764  BEST VAL Loss: 0.4751  Val_Acc: 79.479

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.4242 Train_Acc: 80.532 Val_Loss: 0.4761  BEST VAL Loss: 0.4751  Val_Acc: 79.502

Epoch 75: Validation loss did not decrease
Early stopped at epoch : 75
DMSO_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.72      0.79      0.76     24644
           1       0.27      0.20      0.23      9428

    accuracy                           0.63     34072
   macro avg       0.50      0.50      0.49     34072
weighted avg       0.60      0.63      0.61     34072

DMSO_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.73      0.81      0.77      3081
           1       0.29      0.20      0.24      1178

    accuracy                           0.64      4259
   macro avg       0.51      0.51      0.50      4259
weighted avg       0.60      0.64      0.62      4259

DMSO_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.72      0.80      0.76      3081
           1       0.27      0.19      0.23      1178

    accuracy                           0.63      4259
   macro avg       0.50      0.50      0.49      4259
weighted avg       0.60      0.63      0.61      4259

              precision    recall  f1-score   support

           0       0.72      0.80      0.76      3081
           1       0.27      0.19      0.23      1178

    accuracy                           0.63      4259
   macro avg       0.50      0.50      0.49      4259
weighted avg       0.60      0.63      0.61      4259

DMSO_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.60      0.57      4837
           1       0.45      0.40      0.42      4025

    accuracy                           0.51      8862
   macro avg       0.50      0.50      0.50      8862
weighted avg       0.50      0.51      0.50      8862

              precision    recall  f1-score   support

           0       0.55      0.60      0.57      4837
           1       0.45      0.40      0.42      4025

    accuracy                           0.51      8862
   macro avg       0.50      0.50      0.50      8862
weighted avg       0.50      0.51      0.50      8862

completed
