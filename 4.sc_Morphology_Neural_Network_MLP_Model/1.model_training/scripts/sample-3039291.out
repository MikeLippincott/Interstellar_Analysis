[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '6213c100'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '945b0dd0'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd9233843'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '3fe2f1aa'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 treatment_name: H2O2_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
TREATMENT_NAME: H2O2_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['H2O2_100.000_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (43118, 1276)
Number of total missing values across all columns: 53800
Data Subset Is Off
Wells held out for testing: ['H22' 'K16']
Wells to use for training, validation, and testing ['H18' 'H19' 'H23' 'K17' 'I18' 'I19' 'K20' 'K21' 'I22' 'I23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.402223).  Saving model ...
	 Train_Loss: 0.5480 Train_Acc: 75.139 Val_Loss: 0.4022  BEST VAL Loss: 0.4022  Val_Acc: 85.373

Epoch 1: Validation loss decreased (0.402223 --> 0.354338).  Saving model ...
	 Train_Loss: 0.4827 Train_Acc: 80.301 Val_Loss: 0.3543  BEST VAL Loss: 0.3543  Val_Acc: 89.174

Epoch 2: Validation loss decreased (0.354338 --> 0.322156).  Saving model ...
	 Train_Loss: 0.4388 Train_Acc: 82.202 Val_Loss: 0.3222  BEST VAL Loss: 0.3222  Val_Acc: 90.786

Epoch 3: Validation loss decreased (0.322156 --> 0.298138).  Saving model ...
	 Train_Loss: 0.4069 Train_Acc: 83.401 Val_Loss: 0.2981  BEST VAL Loss: 0.2981  Val_Acc: 91.420

Epoch 4: Validation loss decreased (0.298138 --> 0.280936).  Saving model ...
	 Train_Loss: 0.3813 Train_Acc: 85.323 Val_Loss: 0.2809  BEST VAL Loss: 0.2809  Val_Acc: 92.168

Epoch 5: Validation loss decreased (0.280936 --> 0.266579).  Saving model ...
	 Train_Loss: 0.3605 Train_Acc: 88.044 Val_Loss: 0.2666  BEST VAL Loss: 0.2666  Val_Acc: 92.312

Epoch 6: Validation loss decreased (0.266579 --> 0.255414).  Saving model ...
	 Train_Loss: 0.3433 Train_Acc: 89.139 Val_Loss: 0.2554  BEST VAL Loss: 0.2554  Val_Acc: 92.485

Epoch 7: Validation loss decreased (0.255414 --> 0.246427).  Saving model ...
	 Train_Loss: 0.3280 Train_Acc: 90.233 Val_Loss: 0.2464  BEST VAL Loss: 0.2464  Val_Acc: 92.514

Epoch 8: Validation loss decreased (0.246427 --> 0.238615).  Saving model ...
	 Train_Loss: 0.3147 Train_Acc: 90.784 Val_Loss: 0.2386  BEST VAL Loss: 0.2386  Val_Acc: 92.917

Epoch 9: Validation loss decreased (0.238615 --> 0.233113).  Saving model ...
	 Train_Loss: 0.3039 Train_Acc: 90.784 Val_Loss: 0.2331  BEST VAL Loss: 0.2331  Val_Acc: 93.090

Epoch 10: Validation loss decreased (0.233113 --> 0.228211).  Saving model ...
	 Train_Loss: 0.2939 Train_Acc: 91.443 Val_Loss: 0.2282  BEST VAL Loss: 0.2282  Val_Acc: 93.234

Epoch 11: Validation loss decreased (0.228211 --> 0.224243).  Saving model ...
	 Train_Loss: 0.2850 Train_Acc: 91.608 Val_Loss: 0.2242  BEST VAL Loss: 0.2242  Val_Acc: 93.349

Epoch 12: Validation loss decreased (0.224243 --> 0.221201).  Saving model ...
	 Train_Loss: 0.2774 Train_Acc: 91.752 Val_Loss: 0.2212  BEST VAL Loss: 0.2212  Val_Acc: 93.435

Epoch 13: Validation loss decreased (0.221201 --> 0.218245).  Saving model ...
	 Train_Loss: 0.2705 Train_Acc: 91.724 Val_Loss: 0.2182  BEST VAL Loss: 0.2182  Val_Acc: 93.608

Epoch 14: Validation loss decreased (0.218245 --> 0.215985).  Saving model ...
	 Train_Loss: 0.2641 Train_Acc: 91.968 Val_Loss: 0.2160  BEST VAL Loss: 0.2160  Val_Acc: 93.349

Epoch 15: Validation loss decreased (0.215985 --> 0.214056).  Saving model ...
	 Train_Loss: 0.2580 Train_Acc: 92.354 Val_Loss: 0.2141  BEST VAL Loss: 0.2141  Val_Acc: 93.579

Epoch 16: Validation loss decreased (0.214056 --> 0.212387).  Saving model ...
	 Train_Loss: 0.2527 Train_Acc: 92.426 Val_Loss: 0.2124  BEST VAL Loss: 0.2124  Val_Acc: 93.752

Epoch 17: Validation loss decreased (0.212387 --> 0.210844).  Saving model ...
	 Train_Loss: 0.2476 Train_Acc: 92.692 Val_Loss: 0.2108  BEST VAL Loss: 0.2108  Val_Acc: 93.521

Epoch 18: Validation loss decreased (0.210844 --> 0.209808).  Saving model ...
	 Train_Loss: 0.2431 Train_Acc: 92.400 Val_Loss: 0.2098  BEST VAL Loss: 0.2098  Val_Acc: 93.781

Epoch 19: Validation loss decreased (0.209808 --> 0.209237).  Saving model ...
	 Train_Loss: 0.2389 Train_Acc: 92.436 Val_Loss: 0.2092  BEST VAL Loss: 0.2092  Val_Acc: 93.406

Epoch 20: Validation loss decreased (0.209237 --> 0.208363).  Saving model ...
	 Train_Loss: 0.2350 Train_Acc: 92.526 Val_Loss: 0.2084  BEST VAL Loss: 0.2084  Val_Acc: 93.262

Epoch 21: Validation loss decreased (0.208363 --> 0.208052).  Saving model ...
	 Train_Loss: 0.2314 Train_Acc: 92.760 Val_Loss: 0.2081  BEST VAL Loss: 0.2081  Val_Acc: 93.579

Epoch 22: Validation loss did not decrease
	 Train_Loss: 0.2279 Train_Acc: 92.753 Val_Loss: 0.2082  BEST VAL Loss: 0.2081  Val_Acc: 93.205

Epoch 23: Validation loss decreased (0.208052 --> 0.207576).  Saving model ...
	 Train_Loss: 0.2248 Train_Acc: 93.750 Val_Loss: 0.2076  BEST VAL Loss: 0.2076  Val_Acc: 93.838

Epoch 24: Validation loss decreased (0.207576 --> 0.207568).  Saving model ...
	 Train_Loss: 0.2217 Train_Acc: 93.995 Val_Loss: 0.2076  BEST VAL Loss: 0.2076  Val_Acc: 93.665

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.2185 Train_Acc: 94.272 Val_Loss: 0.2076  BEST VAL Loss: 0.2076  Val_Acc: 93.493

Epoch 26: Validation loss decreased (0.207568 --> 0.207234).  Saving model ...
	 Train_Loss: 0.2157 Train_Acc: 93.974 Val_Loss: 0.2072  BEST VAL Loss: 0.2072  Val_Acc: 93.579

Epoch 27: Validation loss decreased (0.207234 --> 0.207074).  Saving model ...
	 Train_Loss: 0.2130 Train_Acc: 94.092 Val_Loss: 0.2071  BEST VAL Loss: 0.2071  Val_Acc: 93.637

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.2104 Train_Acc: 93.959 Val_Loss: 0.2075  BEST VAL Loss: 0.2071  Val_Acc: 93.262

Epoch 29: Validation loss did not decrease
	 Train_Loss: 0.2080 Train_Acc: 94.193 Val_Loss: 0.2085  BEST VAL Loss: 0.2071  Val_Acc: 93.234

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.2056 Train_Acc: 94.276 Val_Loss: 0.2088  BEST VAL Loss: 0.2071  Val_Acc: 93.665

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.2034 Train_Acc: 94.186 Val_Loss: 0.2093  BEST VAL Loss: 0.2071  Val_Acc: 93.694

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.2012 Train_Acc: 94.647 Val_Loss: 0.2097  BEST VAL Loss: 0.2071  Val_Acc: 93.665

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.1991 Train_Acc: 94.344 Val_Loss: 0.2101  BEST VAL Loss: 0.2071  Val_Acc: 93.723

Epoch 34: Validation loss did not decrease
	 Train_Loss: 0.1971 Train_Acc: 94.308 Val_Loss: 0.2103  BEST VAL Loss: 0.2071  Val_Acc: 93.521

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.1952 Train_Acc: 94.492 Val_Loss: 0.2108  BEST VAL Loss: 0.2071  Val_Acc: 93.694

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.1934 Train_Acc: 94.600 Val_Loss: 0.2117  BEST VAL Loss: 0.2071  Val_Acc: 93.234

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.1917 Train_Acc: 94.470 Val_Loss: 0.2126  BEST VAL Loss: 0.2071  Val_Acc: 93.435

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.1899 Train_Acc: 94.694 Val_Loss: 0.2134  BEST VAL Loss: 0.2071  Val_Acc: 93.406

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.1884 Train_Acc: 94.395 Val_Loss: 0.2141  BEST VAL Loss: 0.2071  Val_Acc: 92.830

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.1869 Train_Acc: 94.568 Val_Loss: 0.2149  BEST VAL Loss: 0.2071  Val_Acc: 93.521

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.1853 Train_Acc: 94.683 Val_Loss: 0.2158  BEST VAL Loss: 0.2071  Val_Acc: 93.550

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.1837 Train_Acc: 94.877 Val_Loss: 0.2169  BEST VAL Loss: 0.2071  Val_Acc: 93.752

Epoch 43: Validation loss did not decrease
Early stopped at epoch : 43
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.65      0.66      0.66     18174
           1       0.34      0.33      0.34      9604

    accuracy                           0.55     27778
   macro avg       0.50      0.50      0.50     27778
weighted avg       0.55      0.55      0.55     27778

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.65      0.66      0.66      2272
           1       0.34      0.32      0.33      1201

    accuracy                           0.55      3473
   macro avg       0.49      0.49      0.49      3473
weighted avg       0.54      0.55      0.54      3473

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.65      0.65      0.65      2272
           1       0.33      0.32      0.32      1201

    accuracy                           0.54      3473
   macro avg       0.49      0.49      0.49      3473
weighted avg       0.54      0.54      0.54      3473

              precision    recall  f1-score   support

           0       0.65      0.65      0.65      2272
           1       0.33      0.32      0.32      1201

    accuracy                           0.54      3473
   macro avg       0.49      0.49      0.49      3473
weighted avg       0.54      0.54      0.54      3473

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.55      0.52      4182
           1       0.50      0.44      0.47      4212

    accuracy                           0.50      8394
   macro avg       0.50      0.50      0.50      8394
weighted avg       0.50      0.50      0.50      8394

              precision    recall  f1-score   support

           0       0.50      0.55      0.52      4182
           1       0.50      0.44      0.47      4212

    accuracy                           0.50      8394
   macro avg       0.50      0.50      0.50      8394
weighted avg       0.50      0.50      0.50      8394

completed
