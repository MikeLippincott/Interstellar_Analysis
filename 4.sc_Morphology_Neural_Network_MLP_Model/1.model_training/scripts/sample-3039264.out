[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '2cd82cbe'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '8c44720a'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '367e2922'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'a42fbefd'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_0.010_DMSO_0.025 treatment_name: Thapsigargin_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_0.010_DMSO_0.025
TREATMENT_NAME: Thapsigargin_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'LPS_0.010_DMSO_0.025']
The dimensions of the data are: (29625, 1276)
Number of total missing values across all columns: 59250
Data Subset Is Off
Wells held out for testing: ['D14' 'B20']
Wells to use for training, validation, and testing ['D15' 'B16' 'B17' 'B21' 'K14' 'K15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.536339).  Saving model ...
	 Train_Loss: 0.6114 Train_Acc: 68.619 Val_Loss: 0.5363  BEST VAL Loss: 0.5363  Val_Acc: 75.133

Epoch 1: Validation loss decreased (0.536339 --> 0.500134).  Saving model ...
	 Train_Loss: 0.5512 Train_Acc: 78.615 Val_Loss: 0.5001  BEST VAL Loss: 0.5001  Val_Acc: 78.982

Epoch 2: Validation loss decreased (0.500134 --> 0.472004).  Saving model ...
	 Train_Loss: 0.5109 Train_Acc: 81.187 Val_Loss: 0.4720  BEST VAL Loss: 0.4720  Val_Acc: 81.283

Epoch 3: Validation loss decreased (0.472004 --> 0.451541).  Saving model ...
	 Train_Loss: 0.4808 Train_Acc: 82.719 Val_Loss: 0.4515  BEST VAL Loss: 0.4515  Val_Acc: 82.301

Epoch 4: Validation loss decreased (0.451541 --> 0.434148).  Saving model ...
	 Train_Loss: 0.4571 Train_Acc: 84.180 Val_Loss: 0.4341  BEST VAL Loss: 0.4341  Val_Acc: 83.717

Epoch 5: Validation loss decreased (0.434148 --> 0.419790).  Saving model ...
	 Train_Loss: 0.4378 Train_Acc: 84.877 Val_Loss: 0.4198  BEST VAL Loss: 0.4198  Val_Acc: 84.735

Epoch 6: Validation loss decreased (0.419790 --> 0.407082).  Saving model ...
	 Train_Loss: 0.4215 Train_Acc: 85.706 Val_Loss: 0.4071  BEST VAL Loss: 0.4071  Val_Acc: 85.619

Epoch 7: Validation loss decreased (0.407082 --> 0.395802).  Saving model ...
	 Train_Loss: 0.4075 Train_Acc: 86.470 Val_Loss: 0.3958  BEST VAL Loss: 0.3958  Val_Acc: 86.903

Epoch 8: Validation loss decreased (0.395802 --> 0.386448).  Saving model ...
	 Train_Loss: 0.3952 Train_Acc: 87.051 Val_Loss: 0.3864  BEST VAL Loss: 0.3864  Val_Acc: 86.681

Epoch 9: Validation loss decreased (0.386448 --> 0.378047).  Saving model ...
	 Train_Loss: 0.3842 Train_Acc: 87.532 Val_Loss: 0.3780  BEST VAL Loss: 0.3780  Val_Acc: 86.858

Epoch 10: Validation loss decreased (0.378047 --> 0.370695).  Saving model ...
	 Train_Loss: 0.3745 Train_Acc: 88.173 Val_Loss: 0.3707  BEST VAL Loss: 0.3707  Val_Acc: 86.947

Epoch 11: Validation loss decreased (0.370695 --> 0.364041).  Saving model ...
	 Train_Loss: 0.3657 Train_Acc: 88.644 Val_Loss: 0.3640  BEST VAL Loss: 0.3640  Val_Acc: 87.522

Epoch 12: Validation loss decreased (0.364041 --> 0.358093).  Saving model ...
	 Train_Loss: 0.3574 Train_Acc: 89.014 Val_Loss: 0.3581  BEST VAL Loss: 0.3581  Val_Acc: 87.301

Epoch 13: Validation loss decreased (0.358093 --> 0.352748).  Saving model ...
	 Train_Loss: 0.3501 Train_Acc: 88.832 Val_Loss: 0.3527  BEST VAL Loss: 0.3527  Val_Acc: 87.876

Epoch 14: Validation loss decreased (0.352748 --> 0.347967).  Saving model ...
	 Train_Loss: 0.3432 Train_Acc: 89.573 Val_Loss: 0.3480  BEST VAL Loss: 0.3480  Val_Acc: 87.832

Epoch 15: Validation loss decreased (0.347967 --> 0.343449).  Saving model ...
	 Train_Loss: 0.3370 Train_Acc: 89.595 Val_Loss: 0.3434  BEST VAL Loss: 0.3434  Val_Acc: 87.920

Epoch 16: Validation loss decreased (0.343449 --> 0.339845).  Saving model ...
	 Train_Loss: 0.3312 Train_Acc: 89.927 Val_Loss: 0.3398  BEST VAL Loss: 0.3398  Val_Acc: 87.743

Epoch 17: Validation loss decreased (0.339845 --> 0.335990).  Saving model ...
	 Train_Loss: 0.3258 Train_Acc: 89.905 Val_Loss: 0.3360  BEST VAL Loss: 0.3360  Val_Acc: 88.363

Epoch 18: Validation loss decreased (0.335990 --> 0.332490).  Saving model ...
	 Train_Loss: 0.3206 Train_Acc: 90.397 Val_Loss: 0.3325  BEST VAL Loss: 0.3325  Val_Acc: 88.230

Epoch 19: Validation loss decreased (0.332490 --> 0.329227).  Saving model ...
	 Train_Loss: 0.3158 Train_Acc: 90.226 Val_Loss: 0.3292  BEST VAL Loss: 0.3292  Val_Acc: 88.761

Epoch 20: Validation loss decreased (0.329227 --> 0.326037).  Saving model ...
	 Train_Loss: 0.3112 Train_Acc: 90.624 Val_Loss: 0.3260  BEST VAL Loss: 0.3260  Val_Acc: 88.540

Epoch 21: Validation loss decreased (0.326037 --> 0.323353).  Saving model ...
	 Train_Loss: 0.3070 Train_Acc: 90.685 Val_Loss: 0.3234  BEST VAL Loss: 0.3234  Val_Acc: 88.805

Epoch 22: Validation loss decreased (0.323353 --> 0.320881).  Saving model ...
	 Train_Loss: 0.3029 Train_Acc: 90.934 Val_Loss: 0.3209  BEST VAL Loss: 0.3209  Val_Acc: 88.496

Epoch 23: Validation loss decreased (0.320881 --> 0.318225).  Saving model ...
	 Train_Loss: 0.2990 Train_Acc: 91.078 Val_Loss: 0.3182  BEST VAL Loss: 0.3182  Val_Acc: 89.159

Epoch 24: Validation loss decreased (0.318225 --> 0.315856).  Saving model ...
	 Train_Loss: 0.2955 Train_Acc: 91.061 Val_Loss: 0.3159  BEST VAL Loss: 0.3159  Val_Acc: 89.115

Epoch 25: Validation loss decreased (0.315856 --> 0.313700).  Saving model ...
	 Train_Loss: 0.2920 Train_Acc: 91.166 Val_Loss: 0.3137  BEST VAL Loss: 0.3137  Val_Acc: 89.248

Epoch 26: Validation loss decreased (0.313700 --> 0.311930).  Saving model ...
	 Train_Loss: 0.2886 Train_Acc: 91.946 Val_Loss: 0.3119  BEST VAL Loss: 0.3119  Val_Acc: 88.274

Epoch 27: Validation loss decreased (0.311930 --> 0.310161).  Saving model ...
	 Train_Loss: 0.2853 Train_Acc: 91.924 Val_Loss: 0.3102  BEST VAL Loss: 0.3102  Val_Acc: 88.673

Epoch 28: Validation loss decreased (0.310161 --> 0.308523).  Saving model ...
	 Train_Loss: 0.2821 Train_Acc: 92.173 Val_Loss: 0.3085  BEST VAL Loss: 0.3085  Val_Acc: 88.628

Epoch 29: Validation loss decreased (0.308523 --> 0.306730).  Saving model ...
	 Train_Loss: 0.2793 Train_Acc: 91.680 Val_Loss: 0.3067  BEST VAL Loss: 0.3067  Val_Acc: 88.894

Epoch 30: Validation loss decreased (0.306730 --> 0.304991).  Saving model ...
	 Train_Loss: 0.2764 Train_Acc: 92.129 Val_Loss: 0.3050  BEST VAL Loss: 0.3050  Val_Acc: 88.982

Epoch 31: Validation loss decreased (0.304991 --> 0.303269).  Saving model ...
	 Train_Loss: 0.2735 Train_Acc: 92.112 Val_Loss: 0.3033  BEST VAL Loss: 0.3033  Val_Acc: 89.248

Epoch 32: Validation loss decreased (0.303269 --> 0.301599).  Saving model ...
	 Train_Loss: 0.2708 Train_Acc: 92.239 Val_Loss: 0.3016  BEST VAL Loss: 0.3016  Val_Acc: 89.336

Epoch 33: Validation loss decreased (0.301599 --> 0.300102).  Saving model ...
	 Train_Loss: 0.2683 Train_Acc: 92.195 Val_Loss: 0.3001  BEST VAL Loss: 0.3001  Val_Acc: 89.336

Epoch 34: Validation loss decreased (0.300102 --> 0.298754).  Saving model ...
	 Train_Loss: 0.2658 Train_Acc: 92.494 Val_Loss: 0.2988  BEST VAL Loss: 0.2988  Val_Acc: 89.159

Epoch 35: Validation loss decreased (0.298754 --> 0.297425).  Saving model ...
	 Train_Loss: 0.2635 Train_Acc: 92.261 Val_Loss: 0.2974  BEST VAL Loss: 0.2974  Val_Acc: 89.336

Epoch 36: Validation loss decreased (0.297425 --> 0.296144).  Saving model ...
	 Train_Loss: 0.2611 Train_Acc: 92.665 Val_Loss: 0.2961  BEST VAL Loss: 0.2961  Val_Acc: 89.248

Epoch 37: Validation loss decreased (0.296144 --> 0.294886).  Saving model ...
	 Train_Loss: 0.2589 Train_Acc: 92.909 Val_Loss: 0.2949  BEST VAL Loss: 0.2949  Val_Acc: 89.336

Epoch 38: Validation loss decreased (0.294886 --> 0.293777).  Saving model ...
	 Train_Loss: 0.2566 Train_Acc: 93.080 Val_Loss: 0.2938  BEST VAL Loss: 0.2938  Val_Acc: 89.027

Epoch 39: Validation loss decreased (0.293777 --> 0.292626).  Saving model ...
	 Train_Loss: 0.2544 Train_Acc: 92.991 Val_Loss: 0.2926  BEST VAL Loss: 0.2926  Val_Acc: 89.248

Epoch 40: Validation loss decreased (0.292626 --> 0.291494).  Saving model ...
	 Train_Loss: 0.2524 Train_Acc: 92.897 Val_Loss: 0.2915  BEST VAL Loss: 0.2915  Val_Acc: 89.867

Epoch 41: Validation loss decreased (0.291494 --> 0.290458).  Saving model ...
	 Train_Loss: 0.2504 Train_Acc: 93.052 Val_Loss: 0.2905  BEST VAL Loss: 0.2905  Val_Acc: 89.292

Epoch 42: Validation loss decreased (0.290458 --> 0.289601).  Saving model ...
	 Train_Loss: 0.2483 Train_Acc: 93.561 Val_Loss: 0.2896  BEST VAL Loss: 0.2896  Val_Acc: 89.071

Epoch 43: Validation loss decreased (0.289601 --> 0.288729).  Saving model ...
	 Train_Loss: 0.2464 Train_Acc: 93.301 Val_Loss: 0.2887  BEST VAL Loss: 0.2887  Val_Acc: 89.336

Epoch 44: Validation loss decreased (0.288729 --> 0.288549).  Saving model ...
	 Train_Loss: 0.2444 Train_Acc: 93.489 Val_Loss: 0.2885  BEST VAL Loss: 0.2885  Val_Acc: 88.053

Epoch 45: Validation loss decreased (0.288549 --> 0.287765).  Saving model ...
	 Train_Loss: 0.2428 Train_Acc: 92.765 Val_Loss: 0.2878  BEST VAL Loss: 0.2878  Val_Acc: 89.248

Epoch 46: Validation loss decreased (0.287765 --> 0.286905).  Saving model ...
	 Train_Loss: 0.2410 Train_Acc: 93.650 Val_Loss: 0.2869  BEST VAL Loss: 0.2869  Val_Acc: 89.823

Epoch 47: Validation loss decreased (0.286905 --> 0.286240).  Saving model ...
	 Train_Loss: 0.2392 Train_Acc: 93.788 Val_Loss: 0.2862  BEST VAL Loss: 0.2862  Val_Acc: 89.204

Epoch 48: Validation loss decreased (0.286240 --> 0.285553).  Saving model ...
	 Train_Loss: 0.2375 Train_Acc: 93.495 Val_Loss: 0.2856  BEST VAL Loss: 0.2856  Val_Acc: 89.381

Epoch 49: Validation loss decreased (0.285553 --> 0.284987).  Saving model ...
	 Train_Loss: 0.2359 Train_Acc: 93.373 Val_Loss: 0.2850  BEST VAL Loss: 0.2850  Val_Acc: 89.159

Epoch 50: Validation loss decreased (0.284987 --> 0.284320).  Saving model ...
	 Train_Loss: 0.2342 Train_Acc: 94.120 Val_Loss: 0.2843  BEST VAL Loss: 0.2843  Val_Acc: 89.690

Epoch 51: Validation loss decreased (0.284320 --> 0.283831).  Saving model ...
	 Train_Loss: 0.2326 Train_Acc: 93.816 Val_Loss: 0.2838  BEST VAL Loss: 0.2838  Val_Acc: 89.336

Epoch 52: Validation loss decreased (0.283831 --> 0.283179).  Saving model ...
	 Train_Loss: 0.2309 Train_Acc: 94.092 Val_Loss: 0.2832  BEST VAL Loss: 0.2832  Val_Acc: 89.646

Epoch 53: Validation loss decreased (0.283179 --> 0.282528).  Saving model ...
	 Train_Loss: 0.2294 Train_Acc: 93.899 Val_Loss: 0.2825  BEST VAL Loss: 0.2825  Val_Acc: 89.513

Epoch 54: Validation loss decreased (0.282528 --> 0.282007).  Saving model ...
	 Train_Loss: 0.2279 Train_Acc: 94.374 Val_Loss: 0.2820  BEST VAL Loss: 0.2820  Val_Acc: 89.558

Epoch 55: Validation loss decreased (0.282007 --> 0.281534).  Saving model ...
	 Train_Loss: 0.2263 Train_Acc: 94.441 Val_Loss: 0.2815  BEST VAL Loss: 0.2815  Val_Acc: 89.558

Epoch 56: Validation loss decreased (0.281534 --> 0.281125).  Saving model ...
	 Train_Loss: 0.2247 Train_Acc: 94.590 Val_Loss: 0.2811  BEST VAL Loss: 0.2811  Val_Acc: 89.425

Epoch 57: Validation loss decreased (0.281125 --> 0.280651).  Saving model ...
	 Train_Loss: 0.2233 Train_Acc: 94.518 Val_Loss: 0.2807  BEST VAL Loss: 0.2807  Val_Acc: 89.690

Epoch 58: Validation loss decreased (0.280651 --> 0.280171).  Saving model ...
	 Train_Loss: 0.2220 Train_Acc: 93.744 Val_Loss: 0.2802  BEST VAL Loss: 0.2802  Val_Acc: 89.159

Epoch 59: Validation loss decreased (0.280171 --> 0.279816).  Saving model ...
	 Train_Loss: 0.2206 Train_Acc: 94.867 Val_Loss: 0.2798  BEST VAL Loss: 0.2798  Val_Acc: 89.690

Epoch 60: Validation loss decreased (0.279816 --> 0.279363).  Saving model ...
	 Train_Loss: 0.2192 Train_Acc: 94.695 Val_Loss: 0.2794  BEST VAL Loss: 0.2794  Val_Acc: 89.602

Epoch 61: Validation loss decreased (0.279363 --> 0.278965).  Saving model ...
	 Train_Loss: 0.2178 Train_Acc: 94.795 Val_Loss: 0.2790  BEST VAL Loss: 0.2790  Val_Acc: 89.381

Epoch 62: Validation loss decreased (0.278965 --> 0.278786).  Saving model ...
	 Train_Loss: 0.2164 Train_Acc: 94.811 Val_Loss: 0.2788  BEST VAL Loss: 0.2788  Val_Acc: 89.248

Epoch 63: Validation loss decreased (0.278786 --> 0.278403).  Saving model ...
	 Train_Loss: 0.2151 Train_Acc: 94.773 Val_Loss: 0.2784  BEST VAL Loss: 0.2784  Val_Acc: 89.204

Epoch 64: Validation loss decreased (0.278403 --> 0.278086).  Saving model ...
	 Train_Loss: 0.2138 Train_Acc: 95.038 Val_Loss: 0.2781  BEST VAL Loss: 0.2781  Val_Acc: 89.469

Epoch 65: Validation loss decreased (0.278086 --> 0.277799).  Saving model ...
	 Train_Loss: 0.2125 Train_Acc: 94.706 Val_Loss: 0.2778  BEST VAL Loss: 0.2778  Val_Acc: 89.425

Epoch 66: Validation loss decreased (0.277799 --> 0.277645).  Saving model ...
	 Train_Loss: 0.2113 Train_Acc: 94.645 Val_Loss: 0.2776  BEST VAL Loss: 0.2776  Val_Acc: 89.292

Epoch 67: Validation loss decreased (0.277645 --> 0.277420).  Saving model ...
	 Train_Loss: 0.2101 Train_Acc: 94.905 Val_Loss: 0.2774  BEST VAL Loss: 0.2774  Val_Acc: 89.159

Epoch 68: Validation loss decreased (0.277420 --> 0.277188).  Saving model ...
	 Train_Loss: 0.2089 Train_Acc: 95.099 Val_Loss: 0.2772  BEST VAL Loss: 0.2772  Val_Acc: 89.513

Epoch 69: Validation loss decreased (0.277188 --> 0.277070).  Saving model ...
	 Train_Loss: 0.2077 Train_Acc: 95.315 Val_Loss: 0.2771  BEST VAL Loss: 0.2771  Val_Acc: 89.027

Epoch 70: Validation loss decreased (0.277070 --> 0.276829).  Saving model ...
	 Train_Loss: 0.2065 Train_Acc: 95.171 Val_Loss: 0.2768  BEST VAL Loss: 0.2768  Val_Acc: 89.646

Epoch 71: Validation loss decreased (0.276829 --> 0.276631).  Saving model ...
	 Train_Loss: 0.2053 Train_Acc: 95.398 Val_Loss: 0.2766  BEST VAL Loss: 0.2766  Val_Acc: 89.115

Epoch 72: Validation loss decreased (0.276631 --> 0.276397).  Saving model ...
	 Train_Loss: 0.2044 Train_Acc: 94.253 Val_Loss: 0.2764  BEST VAL Loss: 0.2764  Val_Acc: 89.159

Epoch 73: Validation loss decreased (0.276397 --> 0.276260).  Saving model ...
	 Train_Loss: 0.2033 Train_Acc: 95.265 Val_Loss: 0.2763  BEST VAL Loss: 0.2763  Val_Acc: 89.292

Epoch 74: Validation loss decreased (0.276260 --> 0.276106).  Saving model ...
	 Train_Loss: 0.2021 Train_Acc: 95.630 Val_Loss: 0.2761  BEST VAL Loss: 0.2761  Val_Acc: 89.292

Epoch 75: Validation loss decreased (0.276106 --> 0.276050).  Saving model ...
	 Train_Loss: 0.2010 Train_Acc: 95.331 Val_Loss: 0.2761  BEST VAL Loss: 0.2761  Val_Acc: 89.204

Epoch 76: Validation loss decreased (0.276050 --> 0.275907).  Saving model ...
	 Train_Loss: 0.1999 Train_Acc: 95.713 Val_Loss: 0.2759  BEST VAL Loss: 0.2759  Val_Acc: 89.071

Epoch 77: Validation loss decreased (0.275907 --> 0.275802).  Saving model ...
	 Train_Loss: 0.1988 Train_Acc: 95.713 Val_Loss: 0.2758  BEST VAL Loss: 0.2758  Val_Acc: 89.071

Epoch 78: Validation loss decreased (0.275802 --> 0.275683).  Saving model ...
	 Train_Loss: 0.1978 Train_Acc: 95.259 Val_Loss: 0.2757  BEST VAL Loss: 0.2757  Val_Acc: 89.469

Epoch 79: Validation loss decreased (0.275683 --> 0.275614).  Saving model ...
	 Train_Loss: 0.1968 Train_Acc: 95.768 Val_Loss: 0.2756  BEST VAL Loss: 0.2756  Val_Acc: 89.204

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.1957 Train_Acc: 95.835 Val_Loss: 0.2756  BEST VAL Loss: 0.2756  Val_Acc: 89.071

Epoch 81: Validation loss decreased (0.275614 --> 0.275596).  Saving model ...
	 Train_Loss: 0.1947 Train_Acc: 95.907 Val_Loss: 0.2756  BEST VAL Loss: 0.2756  Val_Acc: 89.381

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.1937 Train_Acc: 95.995 Val_Loss: 0.2756  BEST VAL Loss: 0.2756  Val_Acc: 89.248

Epoch 83: Validation loss decreased (0.275596 --> 0.275538).  Saving model ...
	 Train_Loss: 0.1926 Train_Acc: 96.150 Val_Loss: 0.2755  BEST VAL Loss: 0.2755  Val_Acc: 89.115

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.1917 Train_Acc: 95.691 Val_Loss: 0.2756  BEST VAL Loss: 0.2755  Val_Acc: 89.336

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.1907 Train_Acc: 96.078 Val_Loss: 0.2756  BEST VAL Loss: 0.2755  Val_Acc: 89.115

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.1897 Train_Acc: 96.012 Val_Loss: 0.2756  BEST VAL Loss: 0.2755  Val_Acc: 89.646

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.1888 Train_Acc: 96.111 Val_Loss: 0.2756  BEST VAL Loss: 0.2755  Val_Acc: 88.938

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.1878 Train_Acc: 96.366 Val_Loss: 0.2756  BEST VAL Loss: 0.2755  Val_Acc: 89.292

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.1868 Train_Acc: 96.299 Val_Loss: 0.2757  BEST VAL Loss: 0.2755  Val_Acc: 89.204

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.1859 Train_Acc: 96.233 Val_Loss: 0.2757  BEST VAL Loss: 0.2755  Val_Acc: 89.159

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.1850 Train_Acc: 96.438 Val_Loss: 0.2759  BEST VAL Loss: 0.2755  Val_Acc: 88.894

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.1841 Train_Acc: 96.476 Val_Loss: 0.2760  BEST VAL Loss: 0.2755  Val_Acc: 88.761

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.1832 Train_Acc: 96.427 Val_Loss: 0.2761  BEST VAL Loss: 0.2755  Val_Acc: 88.938

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.1823 Train_Acc: 96.321 Val_Loss: 0.2763  BEST VAL Loss: 0.2755  Val_Acc: 88.938

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.1814 Train_Acc: 96.299 Val_Loss: 0.2764  BEST VAL Loss: 0.2755  Val_Acc: 89.336

Epoch 96: Validation loss did not decrease
	 Train_Loss: 0.1806 Train_Acc: 96.344 Val_Loss: 0.2764  BEST VAL Loss: 0.2755  Val_Acc: 89.646

Epoch 97: Validation loss did not decrease
	 Train_Loss: 0.1798 Train_Acc: 96.167 Val_Loss: 0.2765  BEST VAL Loss: 0.2755  Val_Acc: 88.982

Epoch 98: Validation loss did not decrease
	 Train_Loss: 0.1790 Train_Acc: 96.078 Val_Loss: 0.2766  BEST VAL Loss: 0.2755  Val_Acc: 89.204

Epoch 99: Validation loss did not decrease
Early stopped at epoch : 99
LPS_0.010_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.98      0.98      9707
           1       0.98      0.98      0.98      8371

    accuracy                           0.98     18078
   macro avg       0.98      0.98      0.98     18078
weighted avg       0.98      0.98      0.98     18078

LPS_0.010_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.88      0.92      0.90      1214
           1       0.90      0.86      0.88      1046

    accuracy                           0.89      2260
   macro avg       0.89      0.89      0.89      2260
weighted avg       0.89      0.89      0.89      2260

LPS_0.010_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.91      0.92      0.92      1214
           1       0.90      0.90      0.90      1046

    accuracy                           0.91      2260
   macro avg       0.91      0.91      0.91      2260
weighted avg       0.91      0.91      0.91      2260

              precision    recall  f1-score   support

           0       0.91      0.92      0.92      1214
           1       0.90      0.90      0.90      1046

    accuracy                           0.91      2260
   macro avg       0.91      0.91      0.91      2260
weighted avg       0.91      0.91      0.91      2260

LPS_0.010_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.89      0.92      0.90      3724
           1       0.90      0.87      0.89      3303

    accuracy                           0.90      7027
   macro avg       0.90      0.89      0.90      7027
weighted avg       0.90      0.90      0.90      7027

              precision    recall  f1-score   support

           0       0.89      0.92      0.90      3724
           1       0.90      0.87      0.89      3303

    accuracy                           0.90      7027
   macro avg       0.90      0.89      0.90      7027
weighted avg       0.90      0.90      0.90      7027

completed
