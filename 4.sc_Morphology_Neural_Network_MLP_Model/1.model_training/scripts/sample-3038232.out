[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '2ef7ded4'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'ddccb942'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '7686fb4a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'd6f11d7e'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: LPS_10.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: LPS_10.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (330751, 1270)
Number of total missing values across all columns: 312980
Data Subset Is Off
Wells held out for testing: ['E09' 'L09']
Wells to use for training, validation, and testing ['E02' 'E03' 'E08' 'L02' 'L03' 'L08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.186385).  Saving model ...
	 Train_Loss: 0.3154 Train_Acc: 86.039 Val_Loss: 0.1864  BEST VAL Loss: 0.1864  Val_Acc: 93.005

Epoch 1: Validation loss decreased (0.186385 --> 0.163049).  Saving model ...
	 Train_Loss: 0.2550 Train_Acc: 93.117 Val_Loss: 0.1630  BEST VAL Loss: 0.1630  Val_Acc: 94.856

Epoch 2: Validation loss decreased (0.163049 --> 0.147930).  Saving model ...
	 Train_Loss: 0.2233 Train_Acc: 94.271 Val_Loss: 0.1479  BEST VAL Loss: 0.1479  Val_Acc: 95.663

Epoch 3: Validation loss decreased (0.147930 --> 0.138295).  Saving model ...
	 Train_Loss: 0.2034 Train_Acc: 94.818 Val_Loss: 0.1383  BEST VAL Loss: 0.1383  Val_Acc: 95.849

Epoch 4: Validation loss decreased (0.138295 --> 0.131427).  Saving model ...
	 Train_Loss: 0.1893 Train_Acc: 95.191 Val_Loss: 0.1314  BEST VAL Loss: 0.1314  Val_Acc: 96.008

Epoch 5: Validation loss decreased (0.131427 --> 0.126189).  Saving model ...
	 Train_Loss: 0.1790 Train_Acc: 95.322 Val_Loss: 0.1262  BEST VAL Loss: 0.1262  Val_Acc: 96.231

Epoch 6: Validation loss decreased (0.126189 --> 0.121807).  Saving model ...
	 Train_Loss: 0.1708 Train_Acc: 95.537 Val_Loss: 0.1218  BEST VAL Loss: 0.1218  Val_Acc: 96.433

Epoch 7: Validation loss decreased (0.121807 --> 0.118279).  Saving model ...
	 Train_Loss: 0.1643 Train_Acc: 95.644 Val_Loss: 0.1183  BEST VAL Loss: 0.1183  Val_Acc: 96.453

Epoch 8: Validation loss decreased (0.118279 --> 0.115110).  Saving model ...
	 Train_Loss: 0.1588 Train_Acc: 95.736 Val_Loss: 0.1151  BEST VAL Loss: 0.1151  Val_Acc: 96.528

Epoch 9: Validation loss decreased (0.115110 --> 0.112568).  Saving model ...
	 Train_Loss: 0.1542 Train_Acc: 95.883 Val_Loss: 0.1126  BEST VAL Loss: 0.1126  Val_Acc: 96.604

Epoch 10: Validation loss decreased (0.112568 --> 0.111149).  Saving model ...
	 Train_Loss: 0.1503 Train_Acc: 95.868 Val_Loss: 0.1111  BEST VAL Loss: 0.1111  Val_Acc: 96.397

Epoch 11: Validation loss decreased (0.111149 --> 0.109243).  Saving model ...
	 Train_Loss: 0.1469 Train_Acc: 95.949 Val_Loss: 0.1092  BEST VAL Loss: 0.1092  Val_Acc: 96.616

Epoch 12: Validation loss decreased (0.109243 --> 0.107478).  Saving model ...
	 Train_Loss: 0.1439 Train_Acc: 95.995 Val_Loss: 0.1075  BEST VAL Loss: 0.1075  Val_Acc: 96.715

Epoch 13: Validation loss decreased (0.107478 --> 0.106136).  Saving model ...
	 Train_Loss: 0.1412 Train_Acc: 95.987 Val_Loss: 0.1061  BEST VAL Loss: 0.1061  Val_Acc: 96.660

Epoch 14: Validation loss decreased (0.106136 --> 0.104797).  Saving model ...
	 Train_Loss: 0.1388 Train_Acc: 96.100 Val_Loss: 0.1048  BEST VAL Loss: 0.1048  Val_Acc: 96.687

Epoch 15: Validation loss decreased (0.104797 --> 0.103576).  Saving model ...
	 Train_Loss: 0.1367 Train_Acc: 96.088 Val_Loss: 0.1036  BEST VAL Loss: 0.1036  Val_Acc: 96.719

Epoch 16: Validation loss decreased (0.103576 --> 0.102543).  Saving model ...
	 Train_Loss: 0.1347 Train_Acc: 96.191 Val_Loss: 0.1025  BEST VAL Loss: 0.1025  Val_Acc: 96.687

Epoch 17: Validation loss decreased (0.102543 --> 0.101465).  Saving model ...
	 Train_Loss: 0.1329 Train_Acc: 96.142 Val_Loss: 0.1015  BEST VAL Loss: 0.1015  Val_Acc: 96.818

Epoch 18: Validation loss decreased (0.101465 --> 0.100527).  Saving model ...
	 Train_Loss: 0.1312 Train_Acc: 96.209 Val_Loss: 0.1005  BEST VAL Loss: 0.1005  Val_Acc: 96.822

Epoch 19: Validation loss decreased (0.100527 --> 0.099832).  Saving model ...
	 Train_Loss: 0.1297 Train_Acc: 96.241 Val_Loss: 0.0998  BEST VAL Loss: 0.0998  Val_Acc: 96.652

Epoch 20: Validation loss decreased (0.099832 --> 0.099019).  Saving model ...
	 Train_Loss: 0.1282 Train_Acc: 96.315 Val_Loss: 0.0990  BEST VAL Loss: 0.0990  Val_Acc: 96.874

Epoch 21: Validation loss decreased (0.099019 --> 0.098245).  Saving model ...
	 Train_Loss: 0.1269 Train_Acc: 96.242 Val_Loss: 0.0982  BEST VAL Loss: 0.0982  Val_Acc: 96.806

Epoch 22: Validation loss decreased (0.098245 --> 0.097426).  Saving model ...
	 Train_Loss: 0.1256 Train_Acc: 96.317 Val_Loss: 0.0974  BEST VAL Loss: 0.0974  Val_Acc: 96.957

Epoch 23: Validation loss decreased (0.097426 --> 0.096729).  Saving model ...
	 Train_Loss: 0.1244 Train_Acc: 96.388 Val_Loss: 0.0967  BEST VAL Loss: 0.0967  Val_Acc: 96.854

Epoch 24: Validation loss decreased (0.096729 --> 0.096052).  Saving model ...
	 Train_Loss: 0.1233 Train_Acc: 96.360 Val_Loss: 0.0961  BEST VAL Loss: 0.0961  Val_Acc: 96.795

Epoch 25: Validation loss decreased (0.096052 --> 0.095550).  Saving model ...
	 Train_Loss: 0.1222 Train_Acc: 96.421 Val_Loss: 0.0955  BEST VAL Loss: 0.0955  Val_Acc: 96.926

Epoch 26: Validation loss decreased (0.095550 --> 0.095045).  Saving model ...
	 Train_Loss: 0.1212 Train_Acc: 96.404 Val_Loss: 0.0950  BEST VAL Loss: 0.0950  Val_Acc: 96.854

Epoch 27: Validation loss decreased (0.095045 --> 0.094532).  Saving model ...
	 Train_Loss: 0.1203 Train_Acc: 96.440 Val_Loss: 0.0945  BEST VAL Loss: 0.0945  Val_Acc: 96.898

Epoch 28: Validation loss decreased (0.094532 --> 0.093946).  Saving model ...
	 Train_Loss: 0.1194 Train_Acc: 96.473 Val_Loss: 0.0939  BEST VAL Loss: 0.0939  Val_Acc: 96.989

Epoch 29: Validation loss decreased (0.093946 --> 0.093651).  Saving model ...
	 Train_Loss: 0.1186 Train_Acc: 96.444 Val_Loss: 0.0937  BEST VAL Loss: 0.0937  Val_Acc: 96.727

Epoch 30: Validation loss decreased (0.093651 --> 0.093496).  Saving model ...
	 Train_Loss: 0.1178 Train_Acc: 96.465 Val_Loss: 0.0935  BEST VAL Loss: 0.0935  Val_Acc: 96.695

Epoch 31: Validation loss decreased (0.093496 --> 0.093138).  Saving model ...
	 Train_Loss: 0.1170 Train_Acc: 96.454 Val_Loss: 0.0931  BEST VAL Loss: 0.0931  Val_Acc: 96.926

Epoch 32: Validation loss decreased (0.093138 --> 0.092677).  Saving model ...
	 Train_Loss: 0.1163 Train_Acc: 96.457 Val_Loss: 0.0927  BEST VAL Loss: 0.0927  Val_Acc: 96.985

Epoch 33: Validation loss decreased (0.092677 --> 0.092281).  Saving model ...
	 Train_Loss: 0.1156 Train_Acc: 96.491 Val_Loss: 0.0923  BEST VAL Loss: 0.0923  Val_Acc: 96.822

Epoch 34: Validation loss decreased (0.092281 --> 0.091927).  Saving model ...
	 Train_Loss: 0.1149 Train_Acc: 96.509 Val_Loss: 0.0919  BEST VAL Loss: 0.0919  Val_Acc: 96.886

Epoch 35: Validation loss decreased (0.091927 --> 0.091622).  Saving model ...
	 Train_Loss: 0.1142 Train_Acc: 96.557 Val_Loss: 0.0916  BEST VAL Loss: 0.0916  Val_Acc: 96.882

Epoch 36: Validation loss decreased (0.091622 --> 0.091255).  Saving model ...
	 Train_Loss: 0.1136 Train_Acc: 96.559 Val_Loss: 0.0913  BEST VAL Loss: 0.0913  Val_Acc: 97.017

Epoch 37: Validation loss decreased (0.091255 --> 0.090946).  Saving model ...
	 Train_Loss: 0.1130 Train_Acc: 96.549 Val_Loss: 0.0909  BEST VAL Loss: 0.0909  Val_Acc: 97.100

Epoch 38: Validation loss decreased (0.090946 --> 0.090585).  Saving model ...
	 Train_Loss: 0.1124 Train_Acc: 96.576 Val_Loss: 0.0906  BEST VAL Loss: 0.0906  Val_Acc: 97.092

Epoch 39: Validation loss decreased (0.090585 --> 0.090257).  Saving model ...
	 Train_Loss: 0.1119 Train_Acc: 96.546 Val_Loss: 0.0903  BEST VAL Loss: 0.0903  Val_Acc: 97.033

Epoch 40: Validation loss decreased (0.090257 --> 0.089933).  Saving model ...
	 Train_Loss: 0.1113 Train_Acc: 96.552 Val_Loss: 0.0899  BEST VAL Loss: 0.0899  Val_Acc: 97.108

Epoch 41: Validation loss decreased (0.089933 --> 0.089729).  Saving model ...
	 Train_Loss: 0.1108 Train_Acc: 96.573 Val_Loss: 0.0897  BEST VAL Loss: 0.0897  Val_Acc: 96.854

Epoch 42: Validation loss decreased (0.089729 --> 0.089459).  Saving model ...
	 Train_Loss: 0.1103 Train_Acc: 96.582 Val_Loss: 0.0895  BEST VAL Loss: 0.0895  Val_Acc: 97.053

Epoch 43: Validation loss decreased (0.089459 --> 0.089184).  Saving model ...
	 Train_Loss: 0.1098 Train_Acc: 96.574 Val_Loss: 0.0892  BEST VAL Loss: 0.0892  Val_Acc: 97.025

Epoch 44: Validation loss decreased (0.089184 --> 0.088917).  Saving model ...
	 Train_Loss: 0.1093 Train_Acc: 96.649 Val_Loss: 0.0889  BEST VAL Loss: 0.0889  Val_Acc: 97.077

Epoch 45: Validation loss decreased (0.088917 --> 0.088735).  Saving model ...
	 Train_Loss: 0.1089 Train_Acc: 96.665 Val_Loss: 0.0887  BEST VAL Loss: 0.0887  Val_Acc: 96.997

Epoch 46: Validation loss decreased (0.088735 --> 0.088645).  Saving model ...
	 Train_Loss: 0.1084 Train_Acc: 96.625 Val_Loss: 0.0886  BEST VAL Loss: 0.0886  Val_Acc: 96.755

Epoch 47: Validation loss decreased (0.088645 --> 0.088427).  Saving model ...
	 Train_Loss: 0.1080 Train_Acc: 96.588 Val_Loss: 0.0884  BEST VAL Loss: 0.0884  Val_Acc: 97.144

Epoch 48: Validation loss decreased (0.088427 --> 0.088152).  Saving model ...
	 Train_Loss: 0.1076 Train_Acc: 96.620 Val_Loss: 0.0882  BEST VAL Loss: 0.0882  Val_Acc: 97.100

Epoch 49: Validation loss decreased (0.088152 --> 0.087926).  Saving model ...
	 Train_Loss: 0.1072 Train_Acc: 96.654 Val_Loss: 0.0879  BEST VAL Loss: 0.0879  Val_Acc: 97.077

Epoch 50: Validation loss decreased (0.087926 --> 0.087701).  Saving model ...
	 Train_Loss: 0.1068 Train_Acc: 96.718 Val_Loss: 0.0877  BEST VAL Loss: 0.0877  Val_Acc: 97.184

Epoch 51: Validation loss decreased (0.087701 --> 0.087511).  Saving model ...
	 Train_Loss: 0.1064 Train_Acc: 96.669 Val_Loss: 0.0875  BEST VAL Loss: 0.0875  Val_Acc: 97.088

Epoch 52: Validation loss decreased (0.087511 --> 0.087340).  Saving model ...
	 Train_Loss: 0.1061 Train_Acc: 96.680 Val_Loss: 0.0873  BEST VAL Loss: 0.0873  Val_Acc: 97.136

Epoch 53: Validation loss decreased (0.087340 --> 0.087142).  Saving model ...
	 Train_Loss: 0.1057 Train_Acc: 96.660 Val_Loss: 0.0871  BEST VAL Loss: 0.0871  Val_Acc: 97.196

Epoch 54: Validation loss decreased (0.087142 --> 0.086965).  Saving model ...
	 Train_Loss: 0.1054 Train_Acc: 96.659 Val_Loss: 0.0870  BEST VAL Loss: 0.0870  Val_Acc: 97.045

Epoch 55: Validation loss decreased (0.086965 --> 0.086823).  Saving model ...
	 Train_Loss: 0.1050 Train_Acc: 96.693 Val_Loss: 0.0868  BEST VAL Loss: 0.0868  Val_Acc: 97.092

Epoch 56: Validation loss decreased (0.086823 --> 0.086623).  Saving model ...
	 Train_Loss: 0.1047 Train_Acc: 96.655 Val_Loss: 0.0866  BEST VAL Loss: 0.0866  Val_Acc: 97.196

Epoch 57: Validation loss decreased (0.086623 --> 0.086491).  Saving model ...
	 Train_Loss: 0.1044 Train_Acc: 96.654 Val_Loss: 0.0865  BEST VAL Loss: 0.0865  Val_Acc: 96.989

Epoch 58: Validation loss decreased (0.086491 --> 0.086331).  Saving model ...
	 Train_Loss: 0.1041 Train_Acc: 96.702 Val_Loss: 0.0863  BEST VAL Loss: 0.0863  Val_Acc: 97.176

Epoch 59: Validation loss decreased (0.086331 --> 0.086194).  Saving model ...
	 Train_Loss: 0.1037 Train_Acc: 96.737 Val_Loss: 0.0862  BEST VAL Loss: 0.0862  Val_Acc: 97.120

Epoch 60: Validation loss decreased (0.086194 --> 0.086079).  Saving model ...
	 Train_Loss: 0.1034 Train_Acc: 96.691 Val_Loss: 0.0861  BEST VAL Loss: 0.0861  Val_Acc: 97.045

Epoch 61: Validation loss decreased (0.086079 --> 0.085941).  Saving model ...
	 Train_Loss: 0.1032 Train_Acc: 96.684 Val_Loss: 0.0859  BEST VAL Loss: 0.0859  Val_Acc: 97.164

Epoch 62: Validation loss decreased (0.085941 --> 0.085772).  Saving model ...
	 Train_Loss: 0.1029 Train_Acc: 96.710 Val_Loss: 0.0858  BEST VAL Loss: 0.0858  Val_Acc: 97.124

Epoch 63: Validation loss decreased (0.085772 --> 0.085684).  Saving model ...
	 Train_Loss: 0.1026 Train_Acc: 96.739 Val_Loss: 0.0857  BEST VAL Loss: 0.0857  Val_Acc: 97.041

Epoch 64: Validation loss decreased (0.085684 --> 0.085585).  Saving model ...
	 Train_Loss: 0.1023 Train_Acc: 96.780 Val_Loss: 0.0856  BEST VAL Loss: 0.0856  Val_Acc: 97.200

Epoch 65: Validation loss decreased (0.085585 --> 0.085458).  Saving model ...
	 Train_Loss: 0.1020 Train_Acc: 96.731 Val_Loss: 0.0855  BEST VAL Loss: 0.0855  Val_Acc: 97.124

Epoch 66: Validation loss decreased (0.085458 --> 0.085267).  Saving model ...
	 Train_Loss: 0.1018 Train_Acc: 96.798 Val_Loss: 0.0853  BEST VAL Loss: 0.0853  Val_Acc: 97.180

Epoch 67: Validation loss decreased (0.085267 --> 0.085179).  Saving model ...
	 Train_Loss: 0.1015 Train_Acc: 96.795 Val_Loss: 0.0852  BEST VAL Loss: 0.0852  Val_Acc: 97.188

Epoch 68: Validation loss decreased (0.085179 --> 0.085074).  Saving model ...
	 Train_Loss: 0.1013 Train_Acc: 96.787 Val_Loss: 0.0851  BEST VAL Loss: 0.0851  Val_Acc: 97.216

Epoch 69: Validation loss decreased (0.085074 --> 0.084985).  Saving model ...
	 Train_Loss: 0.1010 Train_Acc: 96.749 Val_Loss: 0.0850  BEST VAL Loss: 0.0850  Val_Acc: 97.212

Epoch 70: Validation loss decreased (0.084985 --> 0.084874).  Saving model ...
	 Train_Loss: 0.1008 Train_Acc: 96.745 Val_Loss: 0.0849  BEST VAL Loss: 0.0849  Val_Acc: 97.180

Epoch 71: Validation loss decreased (0.084874 --> 0.084749).  Saving model ...
	 Train_Loss: 0.1005 Train_Acc: 96.752 Val_Loss: 0.0847  BEST VAL Loss: 0.0847  Val_Acc: 97.184

Epoch 72: Validation loss decreased (0.084749 --> 0.084634).  Saving model ...
	 Train_Loss: 0.1003 Train_Acc: 96.774 Val_Loss: 0.0846  BEST VAL Loss: 0.0846  Val_Acc: 97.228

Epoch 73: Validation loss decreased (0.084634 --> 0.084515).  Saving model ...
	 Train_Loss: 0.1001 Train_Acc: 96.812 Val_Loss: 0.0845  BEST VAL Loss: 0.0845  Val_Acc: 97.243

Epoch 74: Validation loss decreased (0.084515 --> 0.084404).  Saving model ...
	 Train_Loss: 0.0998 Train_Acc: 96.800 Val_Loss: 0.0844  BEST VAL Loss: 0.0844  Val_Acc: 97.224

Epoch 75: Validation loss decreased (0.084404 --> 0.084302).  Saving model ...
	 Train_Loss: 0.0996 Train_Acc: 96.776 Val_Loss: 0.0843  BEST VAL Loss: 0.0843  Val_Acc: 97.156

Epoch 76: Validation loss decreased (0.084302 --> 0.084193).  Saving model ...
	 Train_Loss: 0.0994 Train_Acc: 96.827 Val_Loss: 0.0842  BEST VAL Loss: 0.0842  Val_Acc: 97.184

Epoch 77: Validation loss decreased (0.084193 --> 0.084087).  Saving model ...
	 Train_Loss: 0.0992 Train_Acc: 96.788 Val_Loss: 0.0841  BEST VAL Loss: 0.0841  Val_Acc: 97.152

Epoch 78: Validation loss decreased (0.084087 --> 0.083983).  Saving model ...
	 Train_Loss: 0.0990 Train_Acc: 96.782 Val_Loss: 0.0840  BEST VAL Loss: 0.0840  Val_Acc: 97.140

Epoch 79: Validation loss decreased (0.083983 --> 0.083864).  Saving model ...
	 Train_Loss: 0.0988 Train_Acc: 96.747 Val_Loss: 0.0839  BEST VAL Loss: 0.0839  Val_Acc: 97.287

Epoch 80: Validation loss decreased (0.083864 --> 0.083842).  Saving model ...
	 Train_Loss: 0.0986 Train_Acc: 96.805 Val_Loss: 0.0838  BEST VAL Loss: 0.0838  Val_Acc: 96.969

Epoch 81: Validation loss decreased (0.083842 --> 0.083735).  Saving model ...
	 Train_Loss: 0.0984 Train_Acc: 96.764 Val_Loss: 0.0837  BEST VAL Loss: 0.0837  Val_Acc: 97.231

Epoch 82: Validation loss decreased (0.083735 --> 0.083641).  Saving model ...
	 Train_Loss: 0.0982 Train_Acc: 96.791 Val_Loss: 0.0836  BEST VAL Loss: 0.0836  Val_Acc: 97.291

Epoch 83: Validation loss decreased (0.083641 --> 0.083590).  Saving model ...
	 Train_Loss: 0.0980 Train_Acc: 96.797 Val_Loss: 0.0836  BEST VAL Loss: 0.0836  Val_Acc: 97.188

Epoch 84: Validation loss decreased (0.083590 --> 0.083482).  Saving model ...
	 Train_Loss: 0.0978 Train_Acc: 96.837 Val_Loss: 0.0835  BEST VAL Loss: 0.0835  Val_Acc: 97.156

Epoch 85: Validation loss decreased (0.083482 --> 0.083411).  Saving model ...
	 Train_Loss: 0.0976 Train_Acc: 96.900 Val_Loss: 0.0834  BEST VAL Loss: 0.0834  Val_Acc: 97.065

Epoch 86: Validation loss decreased (0.083411 --> 0.083332).  Saving model ...
	 Train_Loss: 0.0975 Train_Acc: 96.853 Val_Loss: 0.0833  BEST VAL Loss: 0.0833  Val_Acc: 97.124

Epoch 87: Validation loss decreased (0.083332 --> 0.083251).  Saving model ...
	 Train_Loss: 0.0973 Train_Acc: 96.766 Val_Loss: 0.0833  BEST VAL Loss: 0.0833  Val_Acc: 97.275

Epoch 88: Validation loss decreased (0.083251 --> 0.083185).  Saving model ...
	 Train_Loss: 0.0971 Train_Acc: 96.834 Val_Loss: 0.0832  BEST VAL Loss: 0.0832  Val_Acc: 97.136

Epoch 89: Validation loss decreased (0.083185 --> 0.083088).  Saving model ...
	 Train_Loss: 0.0969 Train_Acc: 96.819 Val_Loss: 0.0831  BEST VAL Loss: 0.0831  Val_Acc: 97.279

Epoch 90: Validation loss decreased (0.083088 --> 0.083006).  Saving model ...
	 Train_Loss: 0.0968 Train_Acc: 96.842 Val_Loss: 0.0830  BEST VAL Loss: 0.0830  Val_Acc: 97.172

Epoch 91: Validation loss decreased (0.083006 --> 0.082940).  Saving model ...
	 Train_Loss: 0.0966 Train_Acc: 96.823 Val_Loss: 0.0829  BEST VAL Loss: 0.0829  Val_Acc: 97.132

Epoch 92: Validation loss decreased (0.082940 --> 0.082871).  Saving model ...
	 Train_Loss: 0.0964 Train_Acc: 96.858 Val_Loss: 0.0829  BEST VAL Loss: 0.0829  Val_Acc: 97.168

Epoch 93: Validation loss decreased (0.082871 --> 0.082799).  Saving model ...
	 Train_Loss: 0.0963 Train_Acc: 96.839 Val_Loss: 0.0828  BEST VAL Loss: 0.0828  Val_Acc: 97.319

Epoch 94: Validation loss decreased (0.082799 --> 0.082726).  Saving model ...
	 Train_Loss: 0.0961 Train_Acc: 96.836 Val_Loss: 0.0827  BEST VAL Loss: 0.0827  Val_Acc: 97.077

Epoch 95: Validation loss decreased (0.082726 --> 0.082685).  Saving model ...
	 Train_Loss: 0.0959 Train_Acc: 96.873 Val_Loss: 0.0827  BEST VAL Loss: 0.0827  Val_Acc: 97.243

Epoch 96: Validation loss decreased (0.082685 --> 0.082624).  Saving model ...
	 Train_Loss: 0.0958 Train_Acc: 96.872 Val_Loss: 0.0826  BEST VAL Loss: 0.0826  Val_Acc: 97.184

Epoch 97: Validation loss decreased (0.082624 --> 0.082554).  Saving model ...
	 Train_Loss: 0.0956 Train_Acc: 96.880 Val_Loss: 0.0826  BEST VAL Loss: 0.0826  Val_Acc: 97.208

Epoch 98: Validation loss decreased (0.082554 --> 0.082510).  Saving model ...
	 Train_Loss: 0.0955 Train_Acc: 96.877 Val_Loss: 0.0825  BEST VAL Loss: 0.0825  Val_Acc: 97.287

Epoch 99: Validation loss decreased (0.082510 --> 0.082442).  Saving model ...
	 Train_Loss: 0.0953 Train_Acc: 96.887 Val_Loss: 0.0824  BEST VAL Loss: 0.0824  Val_Acc: 97.283

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.46      0.46     92173
           1       0.54      0.54      0.54    109228

    accuracy                           0.50    201401
   macro avg       0.50      0.50      0.50    201401
weighted avg       0.50      0.50      0.50    201401

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.45      0.45      0.45     11522
           1       0.54      0.54      0.54     13654

    accuracy                           0.50     25176
   macro avg       0.50      0.50      0.50     25176
weighted avg       0.50      0.50      0.50     25176

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.46      0.46     11522
           1       0.54      0.54      0.54     13654

    accuracy                           0.50     25176
   macro avg       0.50      0.50      0.50     25176
weighted avg       0.50      0.50      0.50     25176

              precision    recall  f1-score   support

           0       0.46      0.46      0.46     11522
           1       0.54      0.54      0.54     13654

    accuracy                           0.50     25176
   macro avg       0.50      0.50      0.50     25176
weighted avg       0.50      0.50      0.50     25176

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.46      0.49     41273
           1       0.48      0.53      0.50     37725

    accuracy                           0.50     78998
   macro avg       0.50      0.50      0.50     78998
weighted avg       0.50      0.50      0.50     78998

              precision    recall  f1-score   support

           0       0.52      0.46      0.49     41273
           1       0.48      0.53      0.50     37725

    accuracy                           0.50     78998
   macro avg       0.50      0.50      0.50     78998
weighted avg       0.50      0.50      0.50     78998

completed
