[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '514439e0'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '953c3018'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'c213d898'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '86c53c7a'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_0.010_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_0.010_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (31846, 1276)
Number of total missing values across all columns: 63692
Data Subset Is Off
Wells held out for testing: ['B20' 'J16']
Wells to use for training, validation, and testing ['B16' 'B17' 'B21' 'J17' 'J20' 'J21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.295084).  Saving model ...
	 Train_Loss: 0.4940 Train_Acc: 76.373 Val_Loss: 0.2951  BEST VAL Loss: 0.2951  Val_Acc: 88.385

Epoch 1: Validation loss decreased (0.295084 --> 0.252782).  Saving model ...
	 Train_Loss: 0.4119 Train_Acc: 87.296 Val_Loss: 0.2528  BEST VAL Loss: 0.2528  Val_Acc: 92.506

Epoch 2: Validation loss decreased (0.252782 --> 0.222375).  Saving model ...
	 Train_Loss: 0.3623 Train_Acc: 90.325 Val_Loss: 0.2224  BEST VAL Loss: 0.2224  Val_Acc: 93.047

Epoch 3: Validation loss decreased (0.222375 --> 0.199680).  Saving model ...
	 Train_Loss: 0.3274 Train_Acc: 92.095 Val_Loss: 0.1997  BEST VAL Loss: 0.1997  Val_Acc: 94.754

Epoch 4: Validation loss decreased (0.199680 --> 0.185001).  Saving model ...
	 Train_Loss: 0.2999 Train_Acc: 93.385 Val_Loss: 0.1850  BEST VAL Loss: 0.1850  Val_Acc: 95.004

Epoch 5: Validation loss decreased (0.185001 --> 0.175722).  Saving model ...
	 Train_Loss: 0.2814 Train_Acc: 93.562 Val_Loss: 0.1757  BEST VAL Loss: 0.1757  Val_Acc: 94.754

Epoch 6: Validation loss decreased (0.175722 --> 0.167773).  Saving model ...
	 Train_Loss: 0.2665 Train_Acc: 93.843 Val_Loss: 0.1678  BEST VAL Loss: 0.1678  Val_Acc: 95.212

Epoch 7: Validation loss decreased (0.167773 --> 0.161193).  Saving model ...
	 Train_Loss: 0.2540 Train_Acc: 94.379 Val_Loss: 0.1612  BEST VAL Loss: 0.1612  Val_Acc: 95.670

Epoch 8: Validation loss decreased (0.161193 --> 0.154229).  Saving model ...
	 Train_Loss: 0.2444 Train_Acc: 94.457 Val_Loss: 0.1542  BEST VAL Loss: 0.1542  Val_Acc: 96.170

Epoch 9: Validation loss decreased (0.154229 --> 0.149196).  Saving model ...
	 Train_Loss: 0.2355 Train_Acc: 94.738 Val_Loss: 0.1492  BEST VAL Loss: 0.1492  Val_Acc: 96.003

Epoch 10: Validation loss decreased (0.149196 --> 0.145862).  Saving model ...
	 Train_Loss: 0.2275 Train_Acc: 95.035 Val_Loss: 0.1459  BEST VAL Loss: 0.1459  Val_Acc: 96.378

Epoch 11: Validation loss decreased (0.145862 --> 0.143496).  Saving model ...
	 Train_Loss: 0.2208 Train_Acc: 94.962 Val_Loss: 0.1435  BEST VAL Loss: 0.1435  Val_Acc: 96.170

Epoch 12: Validation loss decreased (0.143496 --> 0.141376).  Saving model ...
	 Train_Loss: 0.2150 Train_Acc: 95.155 Val_Loss: 0.1414  BEST VAL Loss: 0.1414  Val_Acc: 96.295

Epoch 13: Validation loss decreased (0.141376 --> 0.138523).  Saving model ...
	 Train_Loss: 0.2102 Train_Acc: 94.993 Val_Loss: 0.1385  BEST VAL Loss: 0.1385  Val_Acc: 96.253

Epoch 14: Validation loss decreased (0.138523 --> 0.136246).  Saving model ...
	 Train_Loss: 0.2054 Train_Acc: 95.020 Val_Loss: 0.1362  BEST VAL Loss: 0.1362  Val_Acc: 96.045

Epoch 15: Validation loss decreased (0.136246 --> 0.134049).  Saving model ...
	 Train_Loss: 0.2013 Train_Acc: 95.384 Val_Loss: 0.1340  BEST VAL Loss: 0.1340  Val_Acc: 96.545

Epoch 16: Validation loss decreased (0.134049 --> 0.131877).  Saving model ...
	 Train_Loss: 0.1970 Train_Acc: 95.654 Val_Loss: 0.1319  BEST VAL Loss: 0.1319  Val_Acc: 96.669

Epoch 17: Validation loss decreased (0.131877 --> 0.129617).  Saving model ...
	 Train_Loss: 0.1932 Train_Acc: 95.608 Val_Loss: 0.1296  BEST VAL Loss: 0.1296  Val_Acc: 97.336

Epoch 18: Validation loss decreased (0.129617 --> 0.128293).  Saving model ...
	 Train_Loss: 0.1898 Train_Acc: 95.821 Val_Loss: 0.1283  BEST VAL Loss: 0.1283  Val_Acc: 96.170

Epoch 19: Validation loss decreased (0.128293 --> 0.126729).  Saving model ...
	 Train_Loss: 0.1868 Train_Acc: 95.410 Val_Loss: 0.1267  BEST VAL Loss: 0.1267  Val_Acc: 96.503

Epoch 20: Validation loss decreased (0.126729 --> 0.125441).  Saving model ...
	 Train_Loss: 0.1839 Train_Acc: 95.847 Val_Loss: 0.1254  BEST VAL Loss: 0.1254  Val_Acc: 96.794

Epoch 21: Validation loss decreased (0.125441 --> 0.124099).  Saving model ...
	 Train_Loss: 0.1810 Train_Acc: 95.909 Val_Loss: 0.1241  BEST VAL Loss: 0.1241  Val_Acc: 96.586

Epoch 22: Validation loss decreased (0.124099 --> 0.122816).  Saving model ...
	 Train_Loss: 0.1786 Train_Acc: 95.660 Val_Loss: 0.1228  BEST VAL Loss: 0.1228  Val_Acc: 96.503

Epoch 23: Validation loss decreased (0.122816 --> 0.121592).  Saving model ...
	 Train_Loss: 0.1762 Train_Acc: 96.060 Val_Loss: 0.1216  BEST VAL Loss: 0.1216  Val_Acc: 96.711

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.1738 Train_Acc: 96.133 Val_Loss: 0.1217  BEST VAL Loss: 0.1216  Val_Acc: 96.545

Epoch 25: Validation loss decreased (0.121592 --> 0.120827).  Saving model ...
	 Train_Loss: 0.1720 Train_Acc: 95.743 Val_Loss: 0.1208  BEST VAL Loss: 0.1208  Val_Acc: 96.711

Epoch 26: Validation loss decreased (0.120827 --> 0.120616).  Saving model ...
	 Train_Loss: 0.1701 Train_Acc: 95.738 Val_Loss: 0.1206  BEST VAL Loss: 0.1206  Val_Acc: 96.545

Epoch 27: Validation loss decreased (0.120616 --> 0.120414).  Saving model ...
	 Train_Loss: 0.1681 Train_Acc: 96.045 Val_Loss: 0.1204  BEST VAL Loss: 0.1204  Val_Acc: 96.378

Epoch 28: Validation loss decreased (0.120414 --> 0.120021).  Saving model ...
	 Train_Loss: 0.1664 Train_Acc: 95.868 Val_Loss: 0.1200  BEST VAL Loss: 0.1200  Val_Acc: 96.128

Epoch 29: Validation loss decreased (0.120021 --> 0.119657).  Saving model ...
	 Train_Loss: 0.1646 Train_Acc: 96.081 Val_Loss: 0.1197  BEST VAL Loss: 0.1197  Val_Acc: 96.503

Epoch 30: Validation loss decreased (0.119657 --> 0.119206).  Saving model ...
	 Train_Loss: 0.1631 Train_Acc: 96.092 Val_Loss: 0.1192  BEST VAL Loss: 0.1192  Val_Acc: 96.919

Epoch 31: Validation loss decreased (0.119206 --> 0.118802).  Saving model ...
	 Train_Loss: 0.1615 Train_Acc: 96.243 Val_Loss: 0.1188  BEST VAL Loss: 0.1188  Val_Acc: 96.461

Epoch 32: Validation loss decreased (0.118802 --> 0.118588).  Saving model ...
	 Train_Loss: 0.1599 Train_Acc: 96.383 Val_Loss: 0.1186  BEST VAL Loss: 0.1186  Val_Acc: 96.711

Epoch 33: Validation loss decreased (0.118588 --> 0.117939).  Saving model ...
	 Train_Loss: 0.1584 Train_Acc: 96.034 Val_Loss: 0.1179  BEST VAL Loss: 0.1179  Val_Acc: 96.711

Epoch 34: Validation loss decreased (0.117939 --> 0.117510).  Saving model ...
	 Train_Loss: 0.1571 Train_Acc: 96.040 Val_Loss: 0.1175  BEST VAL Loss: 0.1175  Val_Acc: 96.711

Epoch 35: Validation loss decreased (0.117510 --> 0.117178).  Saving model ...
	 Train_Loss: 0.1560 Train_Acc: 95.998 Val_Loss: 0.1172  BEST VAL Loss: 0.1172  Val_Acc: 96.669

Epoch 36: Validation loss decreased (0.117178 --> 0.116841).  Saving model ...
	 Train_Loss: 0.1548 Train_Acc: 95.915 Val_Loss: 0.1168  BEST VAL Loss: 0.1168  Val_Acc: 96.336

Epoch 37: Validation loss decreased (0.116841 --> 0.116532).  Saving model ...
	 Train_Loss: 0.1535 Train_Acc: 96.451 Val_Loss: 0.1165  BEST VAL Loss: 0.1165  Val_Acc: 96.919

Epoch 38: Validation loss decreased (0.116532 --> 0.116002).  Saving model ...
	 Train_Loss: 0.1523 Train_Acc: 96.279 Val_Loss: 0.1160  BEST VAL Loss: 0.1160  Val_Acc: 97.211

Epoch 39: Validation loss decreased (0.116002 --> 0.115871).  Saving model ...
	 Train_Loss: 0.1512 Train_Acc: 96.248 Val_Loss: 0.1159  BEST VAL Loss: 0.1159  Val_Acc: 96.586

Epoch 40: Validation loss decreased (0.115871 --> 0.115719).  Saving model ...
	 Train_Loss: 0.1501 Train_Acc: 96.258 Val_Loss: 0.1157  BEST VAL Loss: 0.1157  Val_Acc: 96.753

Epoch 41: Validation loss decreased (0.115719 --> 0.115406).  Saving model ...
	 Train_Loss: 0.1489 Train_Acc: 96.570 Val_Loss: 0.1154  BEST VAL Loss: 0.1154  Val_Acc: 96.794

Epoch 42: Validation loss decreased (0.115406 --> 0.114903).  Saving model ...
	 Train_Loss: 0.1477 Train_Acc: 96.534 Val_Loss: 0.1149  BEST VAL Loss: 0.1149  Val_Acc: 97.086

Epoch 43: Validation loss decreased (0.114903 --> 0.114626).  Saving model ...
	 Train_Loss: 0.1468 Train_Acc: 96.305 Val_Loss: 0.1146  BEST VAL Loss: 0.1146  Val_Acc: 96.461

Epoch 44: Validation loss decreased (0.114626 --> 0.114141).  Saving model ...
	 Train_Loss: 0.1458 Train_Acc: 96.648 Val_Loss: 0.1141  BEST VAL Loss: 0.1141  Val_Acc: 96.961

Epoch 45: Validation loss decreased (0.114141 --> 0.114042).  Saving model ...
	 Train_Loss: 0.1449 Train_Acc: 96.596 Val_Loss: 0.1140  BEST VAL Loss: 0.1140  Val_Acc: 96.878

Epoch 46: Validation loss decreased (0.114042 --> 0.113642).  Saving model ...
	 Train_Loss: 0.1441 Train_Acc: 96.123 Val_Loss: 0.1136  BEST VAL Loss: 0.1136  Val_Acc: 97.419

Epoch 47: Validation loss decreased (0.113642 --> 0.113346).  Saving model ...
	 Train_Loss: 0.1432 Train_Acc: 96.570 Val_Loss: 0.1133  BEST VAL Loss: 0.1133  Val_Acc: 96.586

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.1423 Train_Acc: 96.779 Val_Loss: 0.1136  BEST VAL Loss: 0.1133  Val_Acc: 96.961

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.1415 Train_Acc: 96.310 Val_Loss: 0.1137  BEST VAL Loss: 0.1133  Val_Acc: 96.503

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.1408 Train_Acc: 96.128 Val_Loss: 0.1136  BEST VAL Loss: 0.1133  Val_Acc: 96.919

Epoch 51: Validation loss decreased (0.113346 --> 0.113317).  Saving model ...
	 Train_Loss: 0.1402 Train_Acc: 96.050 Val_Loss: 0.1133  BEST VAL Loss: 0.1133  Val_Acc: 97.211

Epoch 52: Validation loss decreased (0.113317 --> 0.113259).  Saving model ...
	 Train_Loss: 0.1394 Train_Acc: 96.321 Val_Loss: 0.1133  BEST VAL Loss: 0.1133  Val_Acc: 96.586

Epoch 53: Validation loss decreased (0.113259 --> 0.112953).  Saving model ...
	 Train_Loss: 0.1386 Train_Acc: 96.706 Val_Loss: 0.1130  BEST VAL Loss: 0.1130  Val_Acc: 96.836

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.1380 Train_Acc: 96.289 Val_Loss: 0.1131  BEST VAL Loss: 0.1130  Val_Acc: 96.420

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.1373 Train_Acc: 96.362 Val_Loss: 0.1130  BEST VAL Loss: 0.1130  Val_Acc: 96.628

Epoch 56: Validation loss decreased (0.112953 --> 0.112797).  Saving model ...
	 Train_Loss: 0.1366 Train_Acc: 96.576 Val_Loss: 0.1128  BEST VAL Loss: 0.1128  Val_Acc: 96.919

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.1359 Train_Acc: 96.654 Val_Loss: 0.1129  BEST VAL Loss: 0.1128  Val_Acc: 96.378

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.1351 Train_Acc: 96.685 Val_Loss: 0.1131  BEST VAL Loss: 0.1128  Val_Acc: 96.586

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.1346 Train_Acc: 96.378 Val_Loss: 0.1135  BEST VAL Loss: 0.1128  Val_Acc: 96.836

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.1340 Train_Acc: 96.492 Val_Loss: 0.1133  BEST VAL Loss: 0.1128  Val_Acc: 96.545

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.1333 Train_Acc: 96.825 Val_Loss: 0.1132  BEST VAL Loss: 0.1128  Val_Acc: 96.794

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.1326 Train_Acc: 96.810 Val_Loss: 0.1134  BEST VAL Loss: 0.1128  Val_Acc: 96.503

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.1319 Train_Acc: 96.799 Val_Loss: 0.1135  BEST VAL Loss: 0.1128  Val_Acc: 96.753

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.1313 Train_Acc: 96.648 Val_Loss: 0.1141  BEST VAL Loss: 0.1128  Val_Acc: 96.503

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.1308 Train_Acc: 96.336 Val_Loss: 0.1141  BEST VAL Loss: 0.1128  Val_Acc: 96.461

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.1303 Train_Acc: 96.331 Val_Loss: 0.1143  BEST VAL Loss: 0.1128  Val_Acc: 96.586

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.1298 Train_Acc: 96.820 Val_Loss: 0.1144  BEST VAL Loss: 0.1128  Val_Acc: 96.628

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.1293 Train_Acc: 96.445 Val_Loss: 0.1146  BEST VAL Loss: 0.1128  Val_Acc: 96.711

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.1289 Train_Acc: 96.440 Val_Loss: 0.1150  BEST VAL Loss: 0.1128  Val_Acc: 96.669

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.1284 Train_Acc: 96.846 Val_Loss: 0.1153  BEST VAL Loss: 0.1128  Val_Acc: 96.503

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.1280 Train_Acc: 96.336 Val_Loss: 0.1156  BEST VAL Loss: 0.1128  Val_Acc: 96.461

Epoch 72: Validation loss did not decrease
Early stopped at epoch : 72
LPS_0.010_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.50      0.51      9707
           1       0.49      0.49      0.49      9508

    accuracy                           0.50     19215
   macro avg       0.50      0.50      0.50     19215
weighted avg       0.50      0.50      0.50     19215

LPS_0.010_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.51      0.51      1214
           1       0.50      0.49      0.50      1188

    accuracy                           0.50      2402
   macro avg       0.50      0.50      0.50      2402
weighted avg       0.50      0.50      0.50      2402

LPS_0.010_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.52      0.52      1214
           1       0.51      0.51      0.51      1188

    accuracy                           0.51      2402
   macro avg       0.51      0.51      0.51      2402
weighted avg       0.51      0.51      0.51      2402

              precision    recall  f1-score   support

           0       0.52      0.52      0.52      1214
           1       0.51      0.51      0.51      1188

    accuracy                           0.51      2402
   macro avg       0.51      0.51      0.51      2402
weighted avg       0.51      0.51      0.51      2402

LPS_0.010_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.48      0.48      3724
           1       0.52      0.52      0.52      4103

    accuracy                           0.50      7827
   macro avg       0.50      0.50      0.50      7827
weighted avg       0.50      0.50      0.50      7827

              precision    recall  f1-score   support

           0       0.48      0.48      0.48      3724
           1       0.52      0.52      0.52      4103

    accuracy                           0.50      7827
   macro avg       0.50      0.50      0.50      7827
weighted avg       0.50      0.50      0.50      7827

completed
