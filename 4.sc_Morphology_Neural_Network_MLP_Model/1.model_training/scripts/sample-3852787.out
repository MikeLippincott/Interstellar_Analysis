[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 18688 bytes to train_binary_model.py
[NbConvertApp] Converting notebook ../notebooks/train_multiclass_model.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/nbformat/__init__.py:93: MissingIDFieldWarning: Code cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.
  validate(nb)
[NbConvertApp] Writing 40895 bytes to train_multiclass_model.py
[NbConvertApp] Converting notebook ../notebooks/train_regression_model.ipynb to script
[NbConvertApp] Writing 25120 bytes to train_regression_model.py
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:254: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_descriptive["labels"] = df1["labels"]
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:281: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels.drop_duplicates(inplace=True)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1015: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1016: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1015: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1016: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:571: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:585: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  model_stats_df = pd.concat([model_stats_df, stats_df], axis=0)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:645: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:854: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  confusion_matrix_df["apoptosis"] = confusion_matrix_df["apoptosis"] / sum_of_columns[0]
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:856: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  confusion_matrix_df["healthy"] = confusion_matrix_df["healthy"] / sum_of_columns[1]
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:859: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  confusion_matrix_df["pyroptosis"] / sum_of_columns[2]
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:890: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_split_conf_mat_df_all = pd.concat(
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:932: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1133: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless
  warnings.warn(
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1133: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless
  warnings.warn(
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:1131: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  confusion_matrix_df["apoptosis"] = confusion_matrix_df["apoptosis"] / sum_of_columns[0]
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:1133: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  confusion_matrix_df["healthy"] = confusion_matrix_df["healthy"] / sum_of_columns[1]
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:1136: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  confusion_matrix_df["pyroptosis"] / sum_of_columns[2]
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:1213: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:1400: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  confusion_matrix_df["apoptosis"] = confusion_matrix_df["apoptosis"] / sum_of_columns[0]
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:1402: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  confusion_matrix_df["healthy"] = confusion_matrix_df["healthy"] / sum_of_columns[1]
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:1405: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  confusion_matrix_df["pyroptosis"] / sum_of_columns[2]
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:1482: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
SHSY5Y MultiClass_MLP True
[0.954878893196544, 0.4803479499984947, 0.5647731568049614]
Data Subset Is Off
(165097,) (41275,) (218078,) 424450     93196
424451     93197
424452     93198
424453     93199
424454     93200
           ...  
446996    509986
446997    509987
446998    509988
446999    509989
447000    509990
Name: labeled_data_index, Length: 22551, dtype: int64 (150901,)
(165097,) (41275,) (218078,) 424450     93196
424451     93197
424452     93198
424453     93199
424454     93200
           ...  
446996    509986
446997    509987
446998    509988
446999    509989
447000    509990
Name: labeled_data_index, Length: 22551, dtype: int64 (150901,)
597902
(7972,) (93463,) (63662,)
(1993,) (23367,) (15915,)
(9965,) (116830,) (91283,)
(0,) (0,) (22551,)
(7048,) (77041,) (66812,)
(165097, 1251) (41275, 1251) (218078, 1251) (22551, 1251) (150901, 1251)
(165097,) (41275,) (218078,) (22551,) (150901,)
Number of in features:  1251
Number of out features:  3
Multi_Class
SGD
Epoch 0: Validation loss decreased (inf --> 0.620541).  Saving model ...
	 Train_Loss: 0.6733 Train_Acc: 69.112 Val_Loss: 0.6205  BEST VAL Loss: 0.6205  Val_Acc: 70.382

Epoch 1: Validation loss decreased (0.620541 --> 0.615472).  Saving model ...
	 Train_Loss: 0.6490 Train_Acc: 70.746 Val_Loss: 0.6155  BEST VAL Loss: 0.6155  Val_Acc: 71.971

Epoch 2: Validation loss decreased (0.615472 --> 0.612263).  Saving model ...
	 Train_Loss: 0.6339 Train_Acc: 71.797 Val_Loss: 0.6123  BEST VAL Loss: 0.6123  Val_Acc: 68.560

Epoch 3: Validation loss did not decrease
	 Train_Loss: 0.6228 Train_Acc: 72.314 Val_Loss: 0.6157  BEST VAL Loss: 0.6123  Val_Acc: 68.521

Epoch 4: Validation loss decreased (0.612263 --> 0.606675).  Saving model ...
	 Train_Loss: 0.6140 Train_Acc: 72.804 Val_Loss: 0.6067  BEST VAL Loss: 0.6067  Val_Acc: 72.892

Epoch 5: Validation loss decreased (0.606675 --> 0.601282).  Saving model ...
	 Train_Loss: 0.6063 Train_Acc: 73.403 Val_Loss: 0.6013  BEST VAL Loss: 0.6013  Val_Acc: 74.403

Epoch 6: Validation loss decreased (0.601282 --> 0.595556).  Saving model ...
	 Train_Loss: 0.5995 Train_Acc: 73.812 Val_Loss: 0.5956  BEST VAL Loss: 0.5956  Val_Acc: 73.410

Epoch 7: Validation loss decreased (0.595556 --> 0.593719).  Saving model ...
	 Train_Loss: 0.5936 Train_Acc: 74.012 Val_Loss: 0.5937  BEST VAL Loss: 0.5937  Val_Acc: 70.815

Epoch 8: Validation loss decreased (0.593719 --> 0.590700).  Saving model ...
	 Train_Loss: 0.5882 Train_Acc: 74.298 Val_Loss: 0.5907  BEST VAL Loss: 0.5907  Val_Acc: 74.975

Epoch 9: Validation loss decreased (0.590700 --> 0.587648).  Saving model ...
	 Train_Loss: 0.5834 Train_Acc: 74.452 Val_Loss: 0.5876  BEST VAL Loss: 0.5876  Val_Acc: 73.732

Epoch 10: Validation loss decreased (0.587648 --> 0.584748).  Saving model ...
	 Train_Loss: 0.5791 Train_Acc: 74.794 Val_Loss: 0.5847  BEST VAL Loss: 0.5847  Val_Acc: 74.464

Epoch 11: Validation loss decreased (0.584748 --> 0.584202).  Saving model ...
	 Train_Loss: 0.5751 Train_Acc: 74.975 Val_Loss: 0.5842  BEST VAL Loss: 0.5842  Val_Acc: 71.753

Epoch 12: Validation loss decreased (0.584202 --> 0.582682).  Saving model ...
	 Train_Loss: 0.5714 Train_Acc: 75.041 Val_Loss: 0.5827  BEST VAL Loss: 0.5827  Val_Acc: 72.499

Epoch 13: Validation loss decreased (0.582682 --> 0.580220).  Saving model ...
	 Train_Loss: 0.5678 Train_Acc: 75.452 Val_Loss: 0.5802  BEST VAL Loss: 0.5802  Val_Acc: 74.188

Epoch 14: Validation loss decreased (0.580220 --> 0.578883).  Saving model ...
	 Train_Loss: 0.5645 Train_Acc: 75.606 Val_Loss: 0.5789  BEST VAL Loss: 0.5789  Val_Acc: 75.472

Epoch 15: Validation loss decreased (0.578883 --> 0.576894).  Saving model ...
	 Train_Loss: 0.5612 Train_Acc: 75.733 Val_Loss: 0.5769  BEST VAL Loss: 0.5769  Val_Acc: 74.917

Epoch 16: Validation loss decreased (0.576894 --> 0.576578).  Saving model ...
	 Train_Loss: 0.5582 Train_Acc: 75.891 Val_Loss: 0.5766  BEST VAL Loss: 0.5766  Val_Acc: 72.426

Epoch 17: Validation loss decreased (0.576578 --> 0.575678).  Saving model ...
	 Train_Loss: 0.5553 Train_Acc: 76.094 Val_Loss: 0.5757  BEST VAL Loss: 0.5757  Val_Acc: 73.970

Epoch 18: Validation loss decreased (0.575678 --> 0.574275).  Saving model ...
	 Train_Loss: 0.5526 Train_Acc: 76.195 Val_Loss: 0.5743  BEST VAL Loss: 0.5743  Val_Acc: 75.404

Epoch 19: Validation loss did not decrease
	 Train_Loss: 0.5500 Train_Acc: 76.037 Val_Loss: 0.5743  BEST VAL Loss: 0.5743  Val_Acc: 74.503

Epoch 20: Validation loss decreased (0.574275 --> 0.573600).  Saving model ...
	 Train_Loss: 0.5474 Train_Acc: 76.445 Val_Loss: 0.5736  BEST VAL Loss: 0.5736  Val_Acc: 72.918

Epoch 21: Validation loss decreased (0.573600 --> 0.573494).  Saving model ...
	 Train_Loss: 0.5451 Train_Acc: 76.506 Val_Loss: 0.5735  BEST VAL Loss: 0.5735  Val_Acc: 75.331

Epoch 22: Validation loss decreased (0.573494 --> 0.572483).  Saving model ...
	 Train_Loss: 0.5429 Train_Acc: 76.558 Val_Loss: 0.5725  BEST VAL Loss: 0.5725  Val_Acc: 75.457

Epoch 23: Validation loss decreased (0.572483 --> 0.572365).  Saving model ...
	 Train_Loss: 0.5406 Train_Acc: 76.759 Val_Loss: 0.5724  BEST VAL Loss: 0.5724  Val_Acc: 75.733

Epoch 24: Validation loss decreased (0.572365 --> 0.571617).  Saving model ...
	 Train_Loss: 0.5384 Train_Acc: 76.783 Val_Loss: 0.5716  BEST VAL Loss: 0.5716  Val_Acc: 75.501

Epoch 25: Validation loss decreased (0.571617 --> 0.570993).  Saving model ...
	 Train_Loss: 0.5364 Train_Acc: 77.080 Val_Loss: 0.5710  BEST VAL Loss: 0.5710  Val_Acc: 75.385

Epoch 26: Validation loss decreased (0.570993 --> 0.570245).  Saving model ...
	 Train_Loss: 0.5344 Train_Acc: 77.020 Val_Loss: 0.5702  BEST VAL Loss: 0.5702  Val_Acc: 75.406

Epoch 27: Validation loss decreased (0.570245 --> 0.569363).  Saving model ...
	 Train_Loss: 0.5325 Train_Acc: 77.164 Val_Loss: 0.5694  BEST VAL Loss: 0.5694  Val_Acc: 75.300

Epoch 28: Validation loss decreased (0.569363 --> 0.568962).  Saving model ...
	 Train_Loss: 0.5307 Train_Acc: 77.193 Val_Loss: 0.5690  BEST VAL Loss: 0.5690  Val_Acc: 74.151

Epoch 29: Validation loss decreased (0.568962 --> 0.568462).  Saving model ...
	 Train_Loss: 0.5290 Train_Acc: 77.363 Val_Loss: 0.5685  BEST VAL Loss: 0.5685  Val_Acc: 74.546

Epoch 30: Validation loss decreased (0.568462 --> 0.567914).  Saving model ...
	 Train_Loss: 0.5272 Train_Acc: 77.484 Val_Loss: 0.5679  BEST VAL Loss: 0.5679  Val_Acc: 73.936

Epoch 31: Validation loss decreased (0.567914 --> 0.567698).  Saving model ...
	 Train_Loss: 0.5255 Train_Acc: 77.519 Val_Loss: 0.5677  BEST VAL Loss: 0.5677  Val_Acc: 75.608

Epoch 32: Validation loss decreased (0.567698 --> 0.567488).  Saving model ...
	 Train_Loss: 0.5239 Train_Acc: 77.806 Val_Loss: 0.5675  BEST VAL Loss: 0.5675  Val_Acc: 75.561

Epoch 33: Validation loss decreased (0.567488 --> 0.567212).  Saving model ...
	 Train_Loss: 0.5222 Train_Acc: 77.665 Val_Loss: 0.5672  BEST VAL Loss: 0.5672  Val_Acc: 75.593

Epoch 34: Validation loss decreased (0.567212 --> 0.567113).  Saving model ...
	 Train_Loss: 0.5207 Train_Acc: 77.686 Val_Loss: 0.5671  BEST VAL Loss: 0.5671  Val_Acc: 73.420

Epoch 35: Validation loss decreased (0.567113 --> 0.566996).  Saving model ...
	 Train_Loss: 0.5191 Train_Acc: 77.967 Val_Loss: 0.5670  BEST VAL Loss: 0.5670  Val_Acc: 73.536

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.5176 Train_Acc: 77.888 Val_Loss: 0.5670  BEST VAL Loss: 0.5670  Val_Acc: 75.462

Epoch 37: Validation loss decreased (0.566996 --> 0.566698).  Saving model ...
	 Train_Loss: 0.5162 Train_Acc: 77.931 Val_Loss: 0.5667  BEST VAL Loss: 0.5667  Val_Acc: 75.222

Epoch 38: Validation loss decreased (0.566698 --> 0.566406).  Saving model ...
	 Train_Loss: 0.5148 Train_Acc: 78.162 Val_Loss: 0.5664  BEST VAL Loss: 0.5664  Val_Acc: 74.888

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.5135 Train_Acc: 78.023 Val_Loss: 0.5667  BEST VAL Loss: 0.5664  Val_Acc: 75.491

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.5121 Train_Acc: 78.287 Val_Loss: 0.5666  BEST VAL Loss: 0.5664  Val_Acc: 75.927

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.5108 Train_Acc: 78.326 Val_Loss: 0.5667  BEST VAL Loss: 0.5664  Val_Acc: 73.955

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.5096 Train_Acc: 78.308 Val_Loss: 0.5669  BEST VAL Loss: 0.5664  Val_Acc: 74.457

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.5083 Train_Acc: 78.382 Val_Loss: 0.5675  BEST VAL Loss: 0.5664  Val_Acc: 75.685

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.5070 Train_Acc: 78.536 Val_Loss: 0.5675  BEST VAL Loss: 0.5664  Val_Acc: 74.634

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.5059 Train_Acc: 78.445 Val_Loss: 0.5676  BEST VAL Loss: 0.5664  Val_Acc: 75.881

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.5047 Train_Acc: 78.499 Val_Loss: 0.5681  BEST VAL Loss: 0.5664  Val_Acc: 73.519

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.5036 Train_Acc: 78.541 Val_Loss: 0.5683  BEST VAL Loss: 0.5664  Val_Acc: 74.764

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.5025 Train_Acc: 78.736 Val_Loss: 0.5682  BEST VAL Loss: 0.5664  Val_Acc: 74.890

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.5014 Train_Acc: 78.883 Val_Loss: 0.5707  BEST VAL Loss: 0.5664  Val_Acc: 73.795

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.5003 Train_Acc: 78.781 Val_Loss: 0.5706  BEST VAL Loss: 0.5664  Val_Acc: 75.193

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.4993 Train_Acc: 78.815 Val_Loss: 0.5706  BEST VAL Loss: 0.5664  Val_Acc: 75.816

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.4983 Train_Acc: 78.886 Val_Loss: 0.5708  BEST VAL Loss: 0.5664  Val_Acc: 75.426

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.4972 Train_Acc: 79.035 Val_Loss: 0.5710  BEST VAL Loss: 0.5664  Val_Acc: 75.859

Epoch 54: Validation loss did not decrease
Early stopped at epoch : 54
MultiClass_MLP_shuffle
              precision    recall  f1-score   support

           0       0.05      0.05      0.05      7972
           1       0.57      0.56      0.56     93463
           2       0.38      0.39      0.39     63662

    accuracy                           0.47    165097
   macro avg       0.33      0.33      0.33    165097
weighted avg       0.47      0.47      0.47    165097

MultiClass_MLP_shuffle
              precision    recall  f1-score   support

           0       0.05      0.05      0.05      1993
           1       0.56      0.56      0.56     23367
           2       0.38      0.39      0.39     15915

    accuracy                           0.47     41275
   macro avg       0.33      0.33      0.33     41275
weighted avg       0.47      0.47      0.47     41275

MultiClass_MLP_shuffle
              precision    recall  f1-score   support

           0       0.05      0.05      0.05      9965
           1       0.54      0.56      0.55    116830
           2       0.42      0.40      0.41     91283

    accuracy                           0.47    218078
   macro avg       0.33      0.33      0.33    218078
weighted avg       0.46      0.47      0.47    218078

Precision for class 0: 0.04734085414987913
Recall for class 0: 0.04716507777220271
Precision for class 1: 0.5363752735681546
Recall for class 1: 0.5559102970127535
Precision for class 2: 0.4179061620628266
Recall for class 2: 0.3985955763942903
3
              precision    recall  f1-score   support

           0       0.05      0.05      0.05      9965
           1       0.54      0.56      0.55    116830
           2       0.42      0.40      0.41     91283

    accuracy                           0.47    218078
   macro avg       0.33      0.33      0.33    218078
weighted avg       0.46      0.47      0.47    218078

MultiClass_MLP_shuffle
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       0.00      0.00      0.00         0
           2       1.00      0.63      0.78     22551

    accuracy                           0.63     22551
   macro avg       0.33      0.21      0.26     22551
weighted avg       1.00      0.63      0.78     22551

Precision for class 0: 0.0
Recall for class 0: 0.0
Precision for class 1: 0.0
Recall for class 1: 0.0
Precision for class 2: 1.0
Recall for class 2: 0.6347833798944614
3
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       0.00      0.00      0.00         0
           2       1.00      0.63      0.78     22551

    accuracy                           0.63     22551
   macro avg       0.33      0.21      0.26     22551
weighted avg       1.00      0.63      0.78     22551

MultiClass_MLP_shuffle
              precision    recall  f1-score   support

           0       0.04      0.04      0.04      7048
           1       0.51      0.54      0.52     77041
           2       0.44      0.42      0.43     66812

    accuracy                           0.46    150901
   macro avg       0.33      0.33      0.33    150901
weighted avg       0.46      0.46      0.46    150901

Precision for class 0: 0.04436860068259386
Recall for class 0: 0.04242338251986379
Precision for class 1: 0.508039971906305
Recall for class 1: 0.5351825651276593
Precision for class 2: 0.4406793111657805
Recall for class 2: 0.4155690594503981
3
              precision    recall  f1-score   support

           0       0.04      0.04      0.04      7048
           1       0.51      0.54      0.52     77041
           2       0.44      0.42      0.43     66812

    accuracy                           0.46    150901
   macro avg       0.33      0.33      0.33    150901
weighted avg       0.46      0.46      0.46    150901

Done
