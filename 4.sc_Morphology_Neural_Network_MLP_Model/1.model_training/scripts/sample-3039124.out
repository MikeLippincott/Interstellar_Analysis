[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'c1879601'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e4080489'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b94cc5fb'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '68a15e1f'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_100.000_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_100.000_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (31846, 1276)
Number of total missing values across all columns: 63692
Data Subset Is Off
Wells held out for testing: ['B20' 'J16']
Wells to use for training, validation, and testing ['B16' 'B17' 'B21' 'J17' 'J20' 'J21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.273436).  Saving model ...
	 Train_Loss: 0.4177 Train_Acc: 80.021 Val_Loss: 0.2734  BEST VAL Loss: 0.2734  Val_Acc: 89.009

Epoch 1: Validation loss decreased (0.273436 --> 0.248387).  Saving model ...
	 Train_Loss: 0.3491 Train_Acc: 88.519 Val_Loss: 0.2484  BEST VAL Loss: 0.2484  Val_Acc: 92.090

Epoch 2: Validation loss decreased (0.248387 --> 0.223605).  Saving model ...
	 Train_Loss: 0.3079 Train_Acc: 91.116 Val_Loss: 0.2236  BEST VAL Loss: 0.2236  Val_Acc: 94.047

Epoch 3: Validation loss decreased (0.223605 --> 0.205318).  Saving model ...
	 Train_Loss: 0.2804 Train_Acc: 92.173 Val_Loss: 0.2053  BEST VAL Loss: 0.2053  Val_Acc: 94.421

Epoch 4: Validation loss decreased (0.205318 --> 0.194000).  Saving model ...
	 Train_Loss: 0.2604 Train_Acc: 93.099 Val_Loss: 0.1940  BEST VAL Loss: 0.1940  Val_Acc: 94.380

Epoch 5: Validation loss decreased (0.194000 --> 0.189910).  Saving model ...
	 Train_Loss: 0.2445 Train_Acc: 93.510 Val_Loss: 0.1899  BEST VAL Loss: 0.1899  Val_Acc: 93.880

Epoch 6: Validation loss decreased (0.189910 --> 0.181027).  Saving model ...
	 Train_Loss: 0.2319 Train_Acc: 94.114 Val_Loss: 0.1810  BEST VAL Loss: 0.1810  Val_Acc: 95.420

Epoch 7: Validation loss decreased (0.181027 --> 0.172545).  Saving model ...
	 Train_Loss: 0.2207 Train_Acc: 94.645 Val_Loss: 0.1725  BEST VAL Loss: 0.1725  Val_Acc: 95.462

Epoch 8: Validation loss decreased (0.172545 --> 0.167302).  Saving model ...
	 Train_Loss: 0.2113 Train_Acc: 94.889 Val_Loss: 0.1673  BEST VAL Loss: 0.1673  Val_Acc: 95.462

Epoch 9: Validation loss decreased (0.167302 --> 0.162388).  Saving model ...
	 Train_Loss: 0.2030 Train_Acc: 95.108 Val_Loss: 0.1624  BEST VAL Loss: 0.1624  Val_Acc: 95.629

Epoch 10: Validation loss decreased (0.162388 --> 0.157040).  Saving model ...
	 Train_Loss: 0.1957 Train_Acc: 95.332 Val_Loss: 0.1570  BEST VAL Loss: 0.1570  Val_Acc: 96.253

Epoch 11: Validation loss decreased (0.157040 --> 0.152413).  Saving model ...
	 Train_Loss: 0.1889 Train_Acc: 95.701 Val_Loss: 0.1524  BEST VAL Loss: 0.1524  Val_Acc: 96.128

Epoch 12: Validation loss decreased (0.152413 --> 0.149004).  Saving model ...
	 Train_Loss: 0.1828 Train_Acc: 95.956 Val_Loss: 0.1490  BEST VAL Loss: 0.1490  Val_Acc: 95.754

Epoch 13: Validation loss decreased (0.149004 --> 0.145018).  Saving model ...
	 Train_Loss: 0.1774 Train_Acc: 95.863 Val_Loss: 0.1450  BEST VAL Loss: 0.1450  Val_Acc: 96.461

Epoch 14: Validation loss decreased (0.145018 --> 0.141284).  Saving model ...
	 Train_Loss: 0.1724 Train_Acc: 96.055 Val_Loss: 0.1413  BEST VAL Loss: 0.1413  Val_Acc: 96.336

Epoch 15: Validation loss decreased (0.141284 --> 0.138263).  Saving model ...
	 Train_Loss: 0.1679 Train_Acc: 96.024 Val_Loss: 0.1383  BEST VAL Loss: 0.1383  Val_Acc: 96.711

Epoch 16: Validation loss decreased (0.138263 --> 0.135251).  Saving model ...
	 Train_Loss: 0.1637 Train_Acc: 96.222 Val_Loss: 0.1353  BEST VAL Loss: 0.1353  Val_Acc: 96.628

Epoch 17: Validation loss decreased (0.135251 --> 0.133048).  Saving model ...
	 Train_Loss: 0.1597 Train_Acc: 96.550 Val_Loss: 0.1330  BEST VAL Loss: 0.1330  Val_Acc: 96.128

Epoch 18: Validation loss decreased (0.133048 --> 0.130684).  Saving model ...
	 Train_Loss: 0.1563 Train_Acc: 96.274 Val_Loss: 0.1307  BEST VAL Loss: 0.1307  Val_Acc: 96.628

Epoch 19: Validation loss decreased (0.130684 --> 0.128169).  Saving model ...
	 Train_Loss: 0.1529 Train_Acc: 96.706 Val_Loss: 0.1282  BEST VAL Loss: 0.1282  Val_Acc: 96.836

Epoch 20: Validation loss decreased (0.128169 --> 0.126004).  Saving model ...
	 Train_Loss: 0.1495 Train_Acc: 96.654 Val_Loss: 0.1260  BEST VAL Loss: 0.1260  Val_Acc: 96.836

Epoch 21: Validation loss decreased (0.126004 --> 0.124009).  Saving model ...
	 Train_Loss: 0.1464 Train_Acc: 96.602 Val_Loss: 0.1240  BEST VAL Loss: 0.1240  Val_Acc: 96.503

Epoch 22: Validation loss decreased (0.124009 --> 0.122315).  Saving model ...
	 Train_Loss: 0.1435 Train_Acc: 96.591 Val_Loss: 0.1223  BEST VAL Loss: 0.1223  Val_Acc: 96.753

Epoch 23: Validation loss decreased (0.122315 --> 0.121201).  Saving model ...
	 Train_Loss: 0.1408 Train_Acc: 96.815 Val_Loss: 0.1212  BEST VAL Loss: 0.1212  Val_Acc: 96.586

Epoch 24: Validation loss decreased (0.121201 --> 0.119702).  Saving model ...
	 Train_Loss: 0.1384 Train_Acc: 96.784 Val_Loss: 0.1197  BEST VAL Loss: 0.1197  Val_Acc: 96.545

Epoch 25: Validation loss decreased (0.119702 --> 0.118563).  Saving model ...
	 Train_Loss: 0.1360 Train_Acc: 96.950 Val_Loss: 0.1186  BEST VAL Loss: 0.1186  Val_Acc: 96.961

Epoch 26: Validation loss decreased (0.118563 --> 0.117496).  Saving model ...
	 Train_Loss: 0.1335 Train_Acc: 97.221 Val_Loss: 0.1175  BEST VAL Loss: 0.1175  Val_Acc: 96.753

Epoch 27: Validation loss decreased (0.117496 --> 0.116899).  Saving model ...
	 Train_Loss: 0.1314 Train_Acc: 96.914 Val_Loss: 0.1169  BEST VAL Loss: 0.1169  Val_Acc: 95.712

Epoch 28: Validation loss decreased (0.116899 --> 0.116200).  Saving model ...
	 Train_Loss: 0.1294 Train_Acc: 97.008 Val_Loss: 0.1162  BEST VAL Loss: 0.1162  Val_Acc: 96.878

Epoch 29: Validation loss decreased (0.116200 --> 0.115681).  Saving model ...
	 Train_Loss: 0.1274 Train_Acc: 97.075 Val_Loss: 0.1157  BEST VAL Loss: 0.1157  Val_Acc: 96.586

Epoch 30: Validation loss decreased (0.115681 --> 0.114888).  Saving model ...
	 Train_Loss: 0.1255 Train_Acc: 97.106 Val_Loss: 0.1149  BEST VAL Loss: 0.1149  Val_Acc: 96.919

Epoch 31: Validation loss decreased (0.114888 --> 0.114210).  Saving model ...
	 Train_Loss: 0.1236 Train_Acc: 97.263 Val_Loss: 0.1142  BEST VAL Loss: 0.1142  Val_Acc: 96.461

Epoch 32: Validation loss decreased (0.114210 --> 0.113520).  Saving model ...
	 Train_Loss: 0.1219 Train_Acc: 97.138 Val_Loss: 0.1135  BEST VAL Loss: 0.1135  Val_Acc: 96.878

Epoch 33: Validation loss decreased (0.113520 --> 0.112786).  Saving model ...
	 Train_Loss: 0.1203 Train_Acc: 96.779 Val_Loss: 0.1128  BEST VAL Loss: 0.1128  Val_Acc: 96.794

Epoch 34: Validation loss decreased (0.112786 --> 0.111963).  Saving model ...
	 Train_Loss: 0.1186 Train_Acc: 97.309 Val_Loss: 0.1120  BEST VAL Loss: 0.1120  Val_Acc: 96.919

Epoch 35: Validation loss decreased (0.111963 --> 0.111561).  Saving model ...
	 Train_Loss: 0.1170 Train_Acc: 97.335 Val_Loss: 0.1116  BEST VAL Loss: 0.1116  Val_Acc: 96.336

Epoch 36: Validation loss decreased (0.111561 --> 0.111295).  Saving model ...
	 Train_Loss: 0.1155 Train_Acc: 97.309 Val_Loss: 0.1113  BEST VAL Loss: 0.1113  Val_Acc: 96.753

Epoch 37: Validation loss decreased (0.111295 --> 0.110785).  Saving model ...
	 Train_Loss: 0.1140 Train_Acc: 97.351 Val_Loss: 0.1108  BEST VAL Loss: 0.1108  Val_Acc: 96.753

Epoch 38: Validation loss decreased (0.110785 --> 0.110070).  Saving model ...
	 Train_Loss: 0.1127 Train_Acc: 97.226 Val_Loss: 0.1101  BEST VAL Loss: 0.1101  Val_Acc: 96.919

Epoch 39: Validation loss decreased (0.110070 --> 0.109824).  Saving model ...
	 Train_Loss: 0.1113 Train_Acc: 97.309 Val_Loss: 0.1098  BEST VAL Loss: 0.1098  Val_Acc: 97.002

Epoch 40: Validation loss decreased (0.109824 --> 0.109190).  Saving model ...
	 Train_Loss: 0.1100 Train_Acc: 97.263 Val_Loss: 0.1092  BEST VAL Loss: 0.1092  Val_Acc: 96.919

Epoch 41: Validation loss decreased (0.109190 --> 0.109055).  Saving model ...
	 Train_Loss: 0.1088 Train_Acc: 97.481 Val_Loss: 0.1091  BEST VAL Loss: 0.1091  Val_Acc: 96.753

Epoch 42: Validation loss decreased (0.109055 --> 0.108773).  Saving model ...
	 Train_Loss: 0.1076 Train_Acc: 97.289 Val_Loss: 0.1088  BEST VAL Loss: 0.1088  Val_Acc: 96.961

Epoch 43: Validation loss decreased (0.108773 --> 0.108404).  Saving model ...
	 Train_Loss: 0.1065 Train_Acc: 97.533 Val_Loss: 0.1084  BEST VAL Loss: 0.1084  Val_Acc: 96.753

Epoch 44: Validation loss decreased (0.108404 --> 0.108122).  Saving model ...
	 Train_Loss: 0.1053 Train_Acc: 97.715 Val_Loss: 0.1081  BEST VAL Loss: 0.1081  Val_Acc: 97.127

Epoch 45: Validation loss decreased (0.108122 --> 0.108018).  Saving model ...
	 Train_Loss: 0.1042 Train_Acc: 97.518 Val_Loss: 0.1080  BEST VAL Loss: 0.1080  Val_Acc: 96.628

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.1031 Train_Acc: 97.674 Val_Loss: 0.1084  BEST VAL Loss: 0.1080  Val_Acc: 96.794

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.1022 Train_Acc: 97.596 Val_Loss: 0.1085  BEST VAL Loss: 0.1080  Val_Acc: 96.378

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.1012 Train_Acc: 97.606 Val_Loss: 0.1081  BEST VAL Loss: 0.1080  Val_Acc: 97.044

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.1002 Train_Acc: 97.575 Val_Loss: 0.1083  BEST VAL Loss: 0.1080  Val_Acc: 96.128

Epoch 50: Validation loss decreased (0.108018 --> 0.108009).  Saving model ...
	 Train_Loss: 0.0993 Train_Acc: 97.502 Val_Loss: 0.1080  BEST VAL Loss: 0.1080  Val_Acc: 97.086

Epoch 51: Validation loss decreased (0.108009 --> 0.107915).  Saving model ...
	 Train_Loss: 0.0983 Train_Acc: 97.726 Val_Loss: 0.1079  BEST VAL Loss: 0.1079  Val_Acc: 96.669

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.0974 Train_Acc: 97.809 Val_Loss: 0.1079  BEST VAL Loss: 0.1079  Val_Acc: 96.794

Epoch 53: Validation loss decreased (0.107915 --> 0.107728).  Saving model ...
	 Train_Loss: 0.0965 Train_Acc: 97.809 Val_Loss: 0.1077  BEST VAL Loss: 0.1077  Val_Acc: 97.169

Epoch 54: Validation loss decreased (0.107728 --> 0.107443).  Saving model ...
	 Train_Loss: 0.0955 Train_Acc: 97.861 Val_Loss: 0.1074  BEST VAL Loss: 0.1074  Val_Acc: 97.044

Epoch 55: Validation loss decreased (0.107443 --> 0.107290).  Saving model ...
	 Train_Loss: 0.0947 Train_Acc: 97.726 Val_Loss: 0.1073  BEST VAL Loss: 0.1073  Val_Acc: 96.794

Epoch 56: Validation loss decreased (0.107290 --> 0.107161).  Saving model ...
	 Train_Loss: 0.0939 Train_Acc: 97.861 Val_Loss: 0.1072  BEST VAL Loss: 0.1072  Val_Acc: 97.044

Epoch 57: Validation loss decreased (0.107161 --> 0.106967).  Saving model ...
	 Train_Loss: 0.0930 Train_Acc: 97.897 Val_Loss: 0.1070  BEST VAL Loss: 0.1070  Val_Acc: 96.711

Epoch 58: Validation loss decreased (0.106967 --> 0.106736).  Saving model ...
	 Train_Loss: 0.0923 Train_Acc: 97.721 Val_Loss: 0.1067  BEST VAL Loss: 0.1067  Val_Acc: 96.919

Epoch 59: Validation loss decreased (0.106736 --> 0.106703).  Saving model ...
	 Train_Loss: 0.0915 Train_Acc: 97.741 Val_Loss: 0.1067  BEST VAL Loss: 0.1067  Val_Acc: 96.753

Epoch 60: Validation loss decreased (0.106703 --> 0.106505).  Saving model ...
	 Train_Loss: 0.0908 Train_Acc: 97.913 Val_Loss: 0.1065  BEST VAL Loss: 0.1065  Val_Acc: 96.794

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.0901 Train_Acc: 97.840 Val_Loss: 0.1067  BEST VAL Loss: 0.1065  Val_Acc: 96.753

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.0894 Train_Acc: 97.819 Val_Loss: 0.1067  BEST VAL Loss: 0.1065  Val_Acc: 97.002

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.0887 Train_Acc: 97.819 Val_Loss: 0.1068  BEST VAL Loss: 0.1065  Val_Acc: 96.753

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.0881 Train_Acc: 97.819 Val_Loss: 0.1068  BEST VAL Loss: 0.1065  Val_Acc: 96.461

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.0874 Train_Acc: 97.819 Val_Loss: 0.1068  BEST VAL Loss: 0.1065  Val_Acc: 96.878

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.0869 Train_Acc: 97.684 Val_Loss: 0.1067  BEST VAL Loss: 0.1065  Val_Acc: 96.753

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.0862 Train_Acc: 97.929 Val_Loss: 0.1066  BEST VAL Loss: 0.1065  Val_Acc: 96.919

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.0856 Train_Acc: 98.043 Val_Loss: 0.1069  BEST VAL Loss: 0.1065  Val_Acc: 96.295

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.0850 Train_Acc: 97.991 Val_Loss: 0.1071  BEST VAL Loss: 0.1065  Val_Acc: 96.669

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.0844 Train_Acc: 97.923 Val_Loss: 0.1070  BEST VAL Loss: 0.1065  Val_Acc: 97.127

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.0839 Train_Acc: 97.950 Val_Loss: 0.1071  BEST VAL Loss: 0.1065  Val_Acc: 96.878

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.0833 Train_Acc: 98.028 Val_Loss: 0.1071  BEST VAL Loss: 0.1065  Val_Acc: 96.586

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.0828 Train_Acc: 98.028 Val_Loss: 0.1072  BEST VAL Loss: 0.1065  Val_Acc: 96.919

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.0822 Train_Acc: 97.861 Val_Loss: 0.1070  BEST VAL Loss: 0.1065  Val_Acc: 96.711

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.0817 Train_Acc: 98.126 Val_Loss: 0.1073  BEST VAL Loss: 0.1065  Val_Acc: 96.753

Epoch 76: Validation loss did not decrease
Early stopped at epoch : 76
LPS_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.50      0.50      9707
           1       0.49      0.50      0.50      9508

    accuracy                           0.50     19215
   macro avg       0.50      0.50      0.50     19215
weighted avg       0.50      0.50      0.50     19215

LPS_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.51      0.51      1214
           1       0.50      0.51      0.50      1188

    accuracy                           0.51      2402
   macro avg       0.51      0.51      0.51      2402
weighted avg       0.51      0.51      0.51      2402

LPS_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.51      0.51      1214
           1       0.50      0.50      0.50      1188

    accuracy                           0.51      2402
   macro avg       0.51      0.51      0.51      2402
weighted avg       0.51      0.51      0.51      2402

              precision    recall  f1-score   support

           0       0.51      0.51      0.51      1214
           1       0.50      0.50      0.50      1188

    accuracy                           0.51      2402
   macro avg       0.51      0.51      0.51      2402
weighted avg       0.51      0.51      0.51      2402

LPS_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.48      0.48      3724
           1       0.52      0.52      0.52      4103

    accuracy                           0.50      7827
   macro avg       0.50      0.50      0.50      7827
weighted avg       0.50      0.50      0.50      7827

              precision    recall  f1-score   support

           0       0.47      0.48      0.48      3724
           1       0.52      0.52      0.52      4103

    accuracy                           0.50      7827
   macro avg       0.50      0.50      0.50      7827
weighted avg       0.50      0.50      0.50      7827

completed
