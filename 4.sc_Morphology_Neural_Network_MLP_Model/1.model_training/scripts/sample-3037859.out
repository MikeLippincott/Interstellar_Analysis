[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'c427cd1e'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'fe97b7e3'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '3946334f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'ee353c40'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: DMSO_0.100_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: DMSO_0.100_DMSO_0.025
TREATMENT_NAME: Flagellin_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (51452, 1276)
Number of total missing values across all columns: 102904
Data Subset Is Off
Wells held out for testing: ['I14' 'M23']
Wells to use for training, validation, and testing ['B14' 'C14' 'B15' 'C15' 'J14' 'I15' 'J15' 'M18' 'M19' 'M22']
Number of in features:  1251
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.539617).  Saving model ...
	 Train_Loss: 0.5910 Train_Acc: 67.630 Val_Loss: 0.5396  BEST VAL Loss: 0.5396  Val_Acc: 72.341

Epoch 1: Validation loss decreased (0.539617 --> 0.532350).  Saving model ...
	 Train_Loss: 0.5659 Train_Acc: 72.332 Val_Loss: 0.5323  BEST VAL Loss: 0.5323  Val_Acc: 72.341

Epoch 2: Validation loss did not decrease
	 Train_Loss: 0.5508 Train_Acc: 72.344 Val_Loss: 0.5346  BEST VAL Loss: 0.5323  Val_Acc: 72.341

Epoch 3: Validation loss decreased (0.532350 --> 0.531694).  Saving model ...
	 Train_Loss: 0.5404 Train_Acc: 74.055 Val_Loss: 0.5317  BEST VAL Loss: 0.5317  Val_Acc: 75.135

Epoch 4: Validation loss decreased (0.531694 --> 0.529729).  Saving model ...
	 Train_Loss: 0.5319 Train_Acc: 75.047 Val_Loss: 0.5297  BEST VAL Loss: 0.5297  Val_Acc: 75.628

Epoch 5: Validation loss decreased (0.529729 --> 0.527686).  Saving model ...
	 Train_Loss: 0.5254 Train_Acc: 74.974 Val_Loss: 0.5277  BEST VAL Loss: 0.5277  Val_Acc: 75.487

Epoch 6: Validation loss decreased (0.527686 --> 0.526003).  Saving model ...
	 Train_Loss: 0.5198 Train_Acc: 75.235 Val_Loss: 0.5260  BEST VAL Loss: 0.5260  Val_Acc: 75.839

Epoch 7: Validation loss decreased (0.526003 --> 0.523496).  Saving model ...
	 Train_Loss: 0.5149 Train_Acc: 75.426 Val_Loss: 0.5235  BEST VAL Loss: 0.5235  Val_Acc: 75.863

Epoch 8: Validation loss decreased (0.523496 --> 0.522511).  Saving model ...
	 Train_Loss: 0.5102 Train_Acc: 76.095 Val_Loss: 0.5225  BEST VAL Loss: 0.5225  Val_Acc: 76.591

Epoch 9: Validation loss decreased (0.522511 --> 0.520527).  Saving model ...
	 Train_Loss: 0.5062 Train_Acc: 76.600 Val_Loss: 0.5205  BEST VAL Loss: 0.5205  Val_Acc: 76.802

Epoch 10: Validation loss decreased (0.520527 --> 0.519681).  Saving model ...
	 Train_Loss: 0.5026 Train_Acc: 76.805 Val_Loss: 0.5197  BEST VAL Loss: 0.5197  Val_Acc: 76.567

Epoch 11: Validation loss decreased (0.519681 --> 0.517739).  Saving model ...
	 Train_Loss: 0.4993 Train_Acc: 76.693 Val_Loss: 0.5177  BEST VAL Loss: 0.5177  Val_Acc: 77.201

Epoch 12: Validation loss decreased (0.517739 --> 0.516322).  Saving model ...
	 Train_Loss: 0.4965 Train_Acc: 77.231 Val_Loss: 0.5163  BEST VAL Loss: 0.5163  Val_Acc: 77.342

Epoch 13: Validation loss decreased (0.516322 --> 0.515008).  Saving model ...
	 Train_Loss: 0.4937 Train_Acc: 77.374 Val_Loss: 0.5150  BEST VAL Loss: 0.5150  Val_Acc: 77.389

Epoch 14: Validation loss decreased (0.515008 --> 0.514249).  Saving model ...
	 Train_Loss: 0.4910 Train_Acc: 77.366 Val_Loss: 0.5142  BEST VAL Loss: 0.5142  Val_Acc: 76.990

Epoch 15: Validation loss decreased (0.514249 --> 0.513071).  Saving model ...
	 Train_Loss: 0.4886 Train_Acc: 77.550 Val_Loss: 0.5131  BEST VAL Loss: 0.5131  Val_Acc: 77.882

Epoch 16: Validation loss decreased (0.513071 --> 0.512533).  Saving model ...
	 Train_Loss: 0.4864 Train_Acc: 77.430 Val_Loss: 0.5125  BEST VAL Loss: 0.5125  Val_Acc: 77.201

Epoch 17: Validation loss decreased (0.512533 --> 0.512082).  Saving model ...
	 Train_Loss: 0.4842 Train_Acc: 77.653 Val_Loss: 0.5121  BEST VAL Loss: 0.5121  Val_Acc: 76.614

Epoch 18: Validation loss decreased (0.512082 --> 0.510819).  Saving model ...
	 Train_Loss: 0.4822 Train_Acc: 77.979 Val_Loss: 0.5108  BEST VAL Loss: 0.5108  Val_Acc: 77.765

Epoch 19: Validation loss decreased (0.510819 --> 0.510344).  Saving model ...
	 Train_Loss: 0.4802 Train_Acc: 78.008 Val_Loss: 0.5103  BEST VAL Loss: 0.5103  Val_Acc: 77.366

Epoch 20: Validation loss decreased (0.510344 --> 0.509644).  Saving model ...
	 Train_Loss: 0.4782 Train_Acc: 78.284 Val_Loss: 0.5096  BEST VAL Loss: 0.5096  Val_Acc: 77.835

Epoch 21: Validation loss decreased (0.509644 --> 0.508810).  Saving model ...
	 Train_Loss: 0.4766 Train_Acc: 78.205 Val_Loss: 0.5088  BEST VAL Loss: 0.5088  Val_Acc: 77.013

Epoch 22: Validation loss decreased (0.508810 --> 0.508171).  Saving model ...
	 Train_Loss: 0.4747 Train_Acc: 78.651 Val_Loss: 0.5082  BEST VAL Loss: 0.5082  Val_Acc: 77.882

Epoch 23: Validation loss decreased (0.508171 --> 0.507656).  Saving model ...
	 Train_Loss: 0.4730 Train_Acc: 78.745 Val_Loss: 0.5077  BEST VAL Loss: 0.5077  Val_Acc: 77.906

Epoch 24: Validation loss decreased (0.507656 --> 0.507000).  Saving model ...
	 Train_Loss: 0.4715 Train_Acc: 78.525 Val_Loss: 0.5070  BEST VAL Loss: 0.5070  Val_Acc: 78.023

Epoch 25: Validation loss decreased (0.507000 --> 0.506517).  Saving model ...
	 Train_Loss: 0.4700 Train_Acc: 78.757 Val_Loss: 0.5065  BEST VAL Loss: 0.5065  Val_Acc: 77.859

Epoch 26: Validation loss did not decrease
	 Train_Loss: 0.4684 Train_Acc: 78.868 Val_Loss: 0.5071  BEST VAL Loss: 0.5065  Val_Acc: 77.976

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.4669 Train_Acc: 79.030 Val_Loss: 0.5068  BEST VAL Loss: 0.5065  Val_Acc: 78.093

Epoch 28: Validation loss decreased (0.506517 --> 0.506470).  Saving model ...
	 Train_Loss: 0.4653 Train_Acc: 79.176 Val_Loss: 0.5065  BEST VAL Loss: 0.5065  Val_Acc: 78.234

Epoch 29: Validation loss decreased (0.506470 --> 0.506006).  Saving model ...
	 Train_Loss: 0.4638 Train_Acc: 79.223 Val_Loss: 0.5060  BEST VAL Loss: 0.5060  Val_Acc: 78.117

Epoch 30: Validation loss decreased (0.506006 --> 0.505805).  Saving model ...
	 Train_Loss: 0.4625 Train_Acc: 78.836 Val_Loss: 0.5058  BEST VAL Loss: 0.5058  Val_Acc: 78.046

Epoch 31: Validation loss decreased (0.505805 --> 0.505473).  Saving model ...
	 Train_Loss: 0.4612 Train_Acc: 79.306 Val_Loss: 0.5055  BEST VAL Loss: 0.5055  Val_Acc: 77.413

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.4598 Train_Acc: 79.646 Val_Loss: 0.5055  BEST VAL Loss: 0.5055  Val_Acc: 77.342

Epoch 33: Validation loss decreased (0.505473 --> 0.505117).  Saving model ...
	 Train_Loss: 0.4585 Train_Acc: 79.397 Val_Loss: 0.5051  BEST VAL Loss: 0.5051  Val_Acc: 77.788

Epoch 34: Validation loss decreased (0.505117 --> 0.504707).  Saving model ...
	 Train_Loss: 0.4573 Train_Acc: 79.661 Val_Loss: 0.5047  BEST VAL Loss: 0.5047  Val_Acc: 77.718

Epoch 35: Validation loss decreased (0.504707 --> 0.504103).  Saving model ...
	 Train_Loss: 0.4561 Train_Acc: 79.675 Val_Loss: 0.5041  BEST VAL Loss: 0.5041  Val_Acc: 78.093

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.4550 Train_Acc: 79.722 Val_Loss: 0.5041  BEST VAL Loss: 0.5041  Val_Acc: 77.600

Epoch 37: Validation loss decreased (0.504103 --> 0.504088).  Saving model ...
	 Train_Loss: 0.4539 Train_Acc: 79.664 Val_Loss: 0.5041  BEST VAL Loss: 0.5041  Val_Acc: 77.342

Epoch 38: Validation loss decreased (0.504088 --> 0.503821).  Saving model ...
	 Train_Loss: 0.4528 Train_Acc: 79.643 Val_Loss: 0.5038  BEST VAL Loss: 0.5038  Val_Acc: 77.413

Epoch 39: Validation loss decreased (0.503821 --> 0.503561).  Saving model ...
	 Train_Loss: 0.4518 Train_Acc: 79.664 Val_Loss: 0.5036  BEST VAL Loss: 0.5036  Val_Acc: 78.164

Epoch 40: Validation loss decreased (0.503561 --> 0.503389).  Saving model ...
	 Train_Loss: 0.4509 Train_Acc: 79.708 Val_Loss: 0.5034  BEST VAL Loss: 0.5034  Val_Acc: 77.718

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.4498 Train_Acc: 80.016 Val_Loss: 0.5034  BEST VAL Loss: 0.5034  Val_Acc: 78.093

Epoch 42: Validation loss decreased (0.503389 --> 0.503368).  Saving model ...
	 Train_Loss: 0.4489 Train_Acc: 79.716 Val_Loss: 0.5034  BEST VAL Loss: 0.5034  Val_Acc: 78.187

Epoch 43: Validation loss decreased (0.503368 --> 0.503016).  Saving model ...
	 Train_Loss: 0.4479 Train_Acc: 79.893 Val_Loss: 0.5030  BEST VAL Loss: 0.5030  Val_Acc: 77.976

Epoch 44: Validation loss decreased (0.503016 --> 0.502546).  Saving model ...
	 Train_Loss: 0.4470 Train_Acc: 79.995 Val_Loss: 0.5025  BEST VAL Loss: 0.5025  Val_Acc: 78.046

Epoch 45: Validation loss decreased (0.502546 --> 0.502506).  Saving model ...
	 Train_Loss: 0.4461 Train_Acc: 79.951 Val_Loss: 0.5025  BEST VAL Loss: 0.5025  Val_Acc: 78.164

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.4453 Train_Acc: 80.139 Val_Loss: 0.5027  BEST VAL Loss: 0.5025  Val_Acc: 77.647

Epoch 47: Validation loss decreased (0.502506 --> 0.502479).  Saving model ...
	 Train_Loss: 0.4445 Train_Acc: 80.254 Val_Loss: 0.5025  BEST VAL Loss: 0.5025  Val_Acc: 78.046

Epoch 48: Validation loss decreased (0.502479 --> 0.502411).  Saving model ...
	 Train_Loss: 0.4436 Train_Acc: 80.133 Val_Loss: 0.5024  BEST VAL Loss: 0.5024  Val_Acc: 78.164

Epoch 49: Validation loss decreased (0.502411 --> 0.502303).  Saving model ...
	 Train_Loss: 0.4428 Train_Acc: 80.212 Val_Loss: 0.5023  BEST VAL Loss: 0.5023  Val_Acc: 78.305

Epoch 50: Validation loss decreased (0.502303 --> 0.502024).  Saving model ...
	 Train_Loss: 0.4419 Train_Acc: 80.186 Val_Loss: 0.5020  BEST VAL Loss: 0.5020  Val_Acc: 78.070

Epoch 51: Validation loss decreased (0.502024 --> 0.501925).  Saving model ...
	 Train_Loss: 0.4412 Train_Acc: 80.124 Val_Loss: 0.5019  BEST VAL Loss: 0.5019  Val_Acc: 78.093

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.4404 Train_Acc: 80.283 Val_Loss: 0.5022  BEST VAL Loss: 0.5019  Val_Acc: 78.046

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.4397 Train_Acc: 80.136 Val_Loss: 0.5020  BEST VAL Loss: 0.5019  Val_Acc: 78.211

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.4390 Train_Acc: 80.113 Val_Loss: 0.5022  BEST VAL Loss: 0.5019  Val_Acc: 77.389

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.4383 Train_Acc: 80.057 Val_Loss: 0.5019  BEST VAL Loss: 0.5019  Val_Acc: 78.093

Epoch 56: Validation loss decreased (0.501925 --> 0.501906).  Saving model ...
	 Train_Loss: 0.4376 Train_Acc: 80.483 Val_Loss: 0.5019  BEST VAL Loss: 0.5019  Val_Acc: 78.070

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.4369 Train_Acc: 80.418 Val_Loss: 0.5019  BEST VAL Loss: 0.5019  Val_Acc: 77.483

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.4362 Train_Acc: 80.374 Val_Loss: 0.5019  BEST VAL Loss: 0.5019  Val_Acc: 78.375

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.4356 Train_Acc: 80.356 Val_Loss: 0.5021  BEST VAL Loss: 0.5019  Val_Acc: 77.929

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.4350 Train_Acc: 80.333 Val_Loss: 0.5021  BEST VAL Loss: 0.5019  Val_Acc: 78.680

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.4343 Train_Acc: 80.353 Val_Loss: 0.5021  BEST VAL Loss: 0.5019  Val_Acc: 77.624

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.4337 Train_Acc: 80.958 Val_Loss: 0.5022  BEST VAL Loss: 0.5019  Val_Acc: 78.000

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.4330 Train_Acc: 80.491 Val_Loss: 0.5022  BEST VAL Loss: 0.5019  Val_Acc: 78.352

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.4324 Train_Acc: 80.456 Val_Loss: 0.5020  BEST VAL Loss: 0.5019  Val_Acc: 78.446

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.4318 Train_Acc: 81.196 Val_Loss: 0.5022  BEST VAL Loss: 0.5019  Val_Acc: 78.352

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.4312 Train_Acc: 81.125 Val_Loss: 0.5023  BEST VAL Loss: 0.5019  Val_Acc: 78.305

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.4305 Train_Acc: 82.393 Val_Loss: 0.5023  BEST VAL Loss: 0.5019  Val_Acc: 78.704

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.4299 Train_Acc: 82.188 Val_Loss: 0.5025  BEST VAL Loss: 0.5019  Val_Acc: 78.516

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.4293 Train_Acc: 82.085 Val_Loss: 0.5025  BEST VAL Loss: 0.5019  Val_Acc: 78.798

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.4287 Train_Acc: 82.243 Val_Loss: 0.5025  BEST VAL Loss: 0.5019  Val_Acc: 78.211

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.4282 Train_Acc: 82.402 Val_Loss: 0.5025  BEST VAL Loss: 0.5019  Val_Acc: 78.000

Epoch 72: Validation loss did not decrease
Early stopped at epoch : 72
DMSO_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.85      0.95      0.90     24644
           1       0.83      0.58      0.68      9428

    accuracy                           0.85     34072
   macro avg       0.84      0.77      0.79     34072
weighted avg       0.85      0.85      0.84     34072

DMSO_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.80      0.92      0.86      3081
           1       0.67      0.41      0.51      1178

    accuracy                           0.78      4259
   macro avg       0.74      0.67      0.68      4259
weighted avg       0.77      0.78      0.76      4259

DMSO_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.81      0.92      0.86      3081
           1       0.68      0.44      0.53      1178

    accuracy                           0.79      4259
   macro avg       0.75      0.68      0.70      4259
weighted avg       0.77      0.79      0.77      4259

              precision    recall  f1-score   support

           0       0.81      0.92      0.86      3081
           1       0.68      0.44      0.53      1178

    accuracy                           0.79      4259
   macro avg       0.75      0.68      0.70      4259
weighted avg       0.77      0.79      0.77      4259

DMSO_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.68      0.85      0.76      4837
           1       0.74      0.52      0.61      4025

    accuracy                           0.70      8862
   macro avg       0.71      0.69      0.69      8862
weighted avg       0.71      0.70      0.69      8862

              precision    recall  f1-score   support

           0       0.68      0.85      0.76      4837
           1       0.74      0.52      0.61      4025

    accuracy                           0.70      8862
   macro avg       0.71      0.69      0.69      8862
weighted avg       0.71      0.70      0.69      8862

completed
