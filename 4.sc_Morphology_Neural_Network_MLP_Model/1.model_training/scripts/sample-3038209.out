[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '35520e06'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '31d008d7'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd6422ef9'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e06aaa07'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: H2O2_100.000_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['H2O2_100.000_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (42887, 1276)
Number of total missing values across all columns: 85774
Data Subset Is Off
Wells held out for testing: ['H22' 'J16']
Wells to use for training, validation, and testing ['H18' 'H19' 'H23' 'J17' 'I18' 'I19' 'J20' 'J21' 'I22' 'I23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.314780).  Saving model ...
	 Train_Loss: 0.5662 Train_Acc: 71.460 Val_Loss: 0.3148  BEST VAL Loss: 0.3148  Val_Acc: 87.663

Epoch 1: Validation loss decreased (0.314780 --> 0.270729).  Saving model ...
	 Train_Loss: 0.4530 Train_Acc: 83.826 Val_Loss: 0.2707  BEST VAL Loss: 0.2707  Val_Acc: 91.159

Epoch 2: Validation loss decreased (0.270729 --> 0.234813).  Saving model ...
	 Train_Loss: 0.3862 Train_Acc: 89.118 Val_Loss: 0.2348  BEST VAL Loss: 0.2348  Val_Acc: 92.921

Epoch 3: Validation loss decreased (0.234813 --> 0.208529).  Saving model ...
	 Train_Loss: 0.3425 Train_Acc: 91.326 Val_Loss: 0.2085  BEST VAL Loss: 0.2085  Val_Acc: 94.626

Epoch 4: Validation loss decreased (0.208529 --> 0.192667).  Saving model ...
	 Train_Loss: 0.3113 Train_Acc: 92.431 Val_Loss: 0.1927  BEST VAL Loss: 0.1927  Val_Acc: 94.770

Epoch 5: Validation loss decreased (0.192667 --> 0.180026).  Saving model ...
	 Train_Loss: 0.2886 Train_Acc: 92.789 Val_Loss: 0.1800  BEST VAL Loss: 0.1800  Val_Acc: 95.522

Epoch 6: Validation loss decreased (0.180026 --> 0.171006).  Saving model ...
	 Train_Loss: 0.2703 Train_Acc: 93.620 Val_Loss: 0.1710  BEST VAL Loss: 0.1710  Val_Acc: 95.608

Epoch 7: Validation loss decreased (0.171006 --> 0.163240).  Saving model ...
	 Train_Loss: 0.2561 Train_Acc: 93.638 Val_Loss: 0.1632  BEST VAL Loss: 0.1632  Val_Acc: 95.926

Epoch 8: Validation loss decreased (0.163240 --> 0.157532).  Saving model ...
	 Train_Loss: 0.2441 Train_Acc: 93.945 Val_Loss: 0.1575  BEST VAL Loss: 0.1575  Val_Acc: 96.099

Epoch 9: Validation loss decreased (0.157532 --> 0.152088).  Saving model ...
	 Train_Loss: 0.2345 Train_Acc: 93.905 Val_Loss: 0.1521  BEST VAL Loss: 0.1521  Val_Acc: 96.128

Epoch 10: Validation loss decreased (0.152088 --> 0.148745).  Saving model ...
	 Train_Loss: 0.2255 Train_Acc: 94.285 Val_Loss: 0.1487  BEST VAL Loss: 0.1487  Val_Acc: 96.417

Epoch 11: Validation loss decreased (0.148745 --> 0.143906).  Saving model ...
	 Train_Loss: 0.2184 Train_Acc: 94.165 Val_Loss: 0.1439  BEST VAL Loss: 0.1439  Val_Acc: 96.417

Epoch 12: Validation loss decreased (0.143906 --> 0.139685).  Saving model ...
	 Train_Loss: 0.2119 Train_Acc: 94.292 Val_Loss: 0.1397  BEST VAL Loss: 0.1397  Val_Acc: 96.677

Epoch 13: Validation loss decreased (0.139685 --> 0.136152).  Saving model ...
	 Train_Loss: 0.2061 Train_Acc: 94.498 Val_Loss: 0.1362  BEST VAL Loss: 0.1362  Val_Acc: 96.677

Epoch 14: Validation loss decreased (0.136152 --> 0.134081).  Saving model ...
	 Train_Loss: 0.2008 Train_Acc: 94.552 Val_Loss: 0.1341  BEST VAL Loss: 0.1341  Val_Acc: 96.331

Epoch 15: Validation loss decreased (0.134081 --> 0.130984).  Saving model ...
	 Train_Loss: 0.1961 Train_Acc: 94.668 Val_Loss: 0.1310  BEST VAL Loss: 0.1310  Val_Acc: 96.677

Epoch 16: Validation loss decreased (0.130984 --> 0.128716).  Saving model ...
	 Train_Loss: 0.1915 Train_Acc: 94.899 Val_Loss: 0.1287  BEST VAL Loss: 0.1287  Val_Acc: 96.648

Epoch 17: Validation loss decreased (0.128716 --> 0.126932).  Saving model ...
	 Train_Loss: 0.1876 Train_Acc: 94.805 Val_Loss: 0.1269  BEST VAL Loss: 0.1269  Val_Acc: 96.359

Epoch 18: Validation loss decreased (0.126932 --> 0.125612).  Saving model ...
	 Train_Loss: 0.1844 Train_Acc: 94.476 Val_Loss: 0.1256  BEST VAL Loss: 0.1256  Val_Acc: 96.591

Epoch 19: Validation loss decreased (0.125612 --> 0.123717).  Saving model ...
	 Train_Loss: 0.1811 Train_Acc: 94.711 Val_Loss: 0.1237  BEST VAL Loss: 0.1237  Val_Acc: 96.793

Epoch 20: Validation loss decreased (0.123717 --> 0.121953).  Saving model ...
	 Train_Loss: 0.1781 Train_Acc: 94.765 Val_Loss: 0.1220  BEST VAL Loss: 0.1220  Val_Acc: 96.273

Epoch 21: Validation loss decreased (0.121953 --> 0.120749).  Saving model ...
	 Train_Loss: 0.1754 Train_Acc: 94.816 Val_Loss: 0.1207  BEST VAL Loss: 0.1207  Val_Acc: 96.504

Epoch 22: Validation loss decreased (0.120749 --> 0.119179).  Saving model ...
	 Train_Loss: 0.1730 Train_Acc: 94.769 Val_Loss: 0.1192  BEST VAL Loss: 0.1192  Val_Acc: 97.053

Epoch 23: Validation loss decreased (0.119179 --> 0.118081).  Saving model ...
	 Train_Loss: 0.1704 Train_Acc: 95.123 Val_Loss: 0.1181  BEST VAL Loss: 0.1181  Val_Acc: 96.619

Epoch 24: Validation loss decreased (0.118081 --> 0.117047).  Saving model ...
	 Train_Loss: 0.1681 Train_Acc: 95.014 Val_Loss: 0.1170  BEST VAL Loss: 0.1170  Val_Acc: 96.562

Epoch 25: Validation loss decreased (0.117047 --> 0.116098).  Saving model ...
	 Train_Loss: 0.1658 Train_Acc: 95.112 Val_Loss: 0.1161  BEST VAL Loss: 0.1161  Val_Acc: 96.562

Epoch 26: Validation loss decreased (0.116098 --> 0.114875).  Saving model ...
	 Train_Loss: 0.1638 Train_Acc: 95.105 Val_Loss: 0.1149  BEST VAL Loss: 0.1149  Val_Acc: 97.024

Epoch 27: Validation loss decreased (0.114875 --> 0.113647).  Saving model ...
	 Train_Loss: 0.1616 Train_Acc: 95.296 Val_Loss: 0.1136  BEST VAL Loss: 0.1136  Val_Acc: 96.706

Epoch 28: Validation loss decreased (0.113647 --> 0.113118).  Saving model ...
	 Train_Loss: 0.1596 Train_Acc: 95.318 Val_Loss: 0.1131  BEST VAL Loss: 0.1131  Val_Acc: 96.562

Epoch 29: Validation loss decreased (0.113118 --> 0.111718).  Saving model ...
	 Train_Loss: 0.1579 Train_Acc: 95.249 Val_Loss: 0.1117  BEST VAL Loss: 0.1117  Val_Acc: 97.371

Epoch 30: Validation loss decreased (0.111718 --> 0.110950).  Saving model ...
	 Train_Loss: 0.1561 Train_Acc: 95.531 Val_Loss: 0.1110  BEST VAL Loss: 0.1110  Val_Acc: 96.966

Epoch 31: Validation loss decreased (0.110950 --> 0.110057).  Saving model ...
	 Train_Loss: 0.1544 Train_Acc: 95.434 Val_Loss: 0.1101  BEST VAL Loss: 0.1101  Val_Acc: 97.428

Epoch 32: Validation loss decreased (0.110057 --> 0.109204).  Saving model ...
	 Train_Loss: 0.1529 Train_Acc: 95.484 Val_Loss: 0.1092  BEST VAL Loss: 0.1092  Val_Acc: 96.995

Epoch 33: Validation loss decreased (0.109204 --> 0.108501).  Saving model ...
	 Train_Loss: 0.1514 Train_Acc: 95.311 Val_Loss: 0.1085  BEST VAL Loss: 0.1085  Val_Acc: 96.793

Epoch 34: Validation loss decreased (0.108501 --> 0.108172).  Saving model ...
	 Train_Loss: 0.1501 Train_Acc: 95.159 Val_Loss: 0.1082  BEST VAL Loss: 0.1082  Val_Acc: 96.706

Epoch 35: Validation loss decreased (0.108172 --> 0.107569).  Saving model ...
	 Train_Loss: 0.1488 Train_Acc: 95.365 Val_Loss: 0.1076  BEST VAL Loss: 0.1076  Val_Acc: 97.168

Epoch 36: Validation loss decreased (0.107569 --> 0.107161).  Saving model ...
	 Train_Loss: 0.1475 Train_Acc: 95.618 Val_Loss: 0.1072  BEST VAL Loss: 0.1072  Val_Acc: 96.822

Epoch 37: Validation loss decreased (0.107161 --> 0.106486).  Saving model ...
	 Train_Loss: 0.1462 Train_Acc: 95.484 Val_Loss: 0.1065  BEST VAL Loss: 0.1065  Val_Acc: 97.140

Epoch 38: Validation loss decreased (0.106486 --> 0.105713).  Saving model ...
	 Train_Loss: 0.1449 Train_Acc: 95.665 Val_Loss: 0.1057  BEST VAL Loss: 0.1057  Val_Acc: 97.082

Epoch 39: Validation loss decreased (0.105713 --> 0.105369).  Saving model ...
	 Train_Loss: 0.1437 Train_Acc: 95.553 Val_Loss: 0.1054  BEST VAL Loss: 0.1054  Val_Acc: 96.995

Epoch 40: Validation loss decreased (0.105369 --> 0.104943).  Saving model ...
	 Train_Loss: 0.1425 Train_Acc: 95.694 Val_Loss: 0.1049  BEST VAL Loss: 0.1049  Val_Acc: 96.880

Epoch 41: Validation loss decreased (0.104943 --> 0.104901).  Saving model ...
	 Train_Loss: 0.1415 Train_Acc: 95.665 Val_Loss: 0.1049  BEST VAL Loss: 0.1049  Val_Acc: 96.619

Epoch 42: Validation loss decreased (0.104901 --> 0.104476).  Saving model ...
	 Train_Loss: 0.1404 Train_Acc: 95.658 Val_Loss: 0.1045  BEST VAL Loss: 0.1045  Val_Acc: 97.111

Epoch 43: Validation loss decreased (0.104476 --> 0.104258).  Saving model ...
	 Train_Loss: 0.1393 Train_Acc: 95.571 Val_Loss: 0.1043  BEST VAL Loss: 0.1043  Val_Acc: 96.706

Epoch 44: Validation loss decreased (0.104258 --> 0.104030).  Saving model ...
	 Train_Loss: 0.1385 Train_Acc: 95.466 Val_Loss: 0.1040  BEST VAL Loss: 0.1040  Val_Acc: 96.937

Epoch 45: Validation loss decreased (0.104030 --> 0.103698).  Saving model ...
	 Train_Loss: 0.1376 Train_Acc: 95.484 Val_Loss: 0.1037  BEST VAL Loss: 0.1037  Val_Acc: 96.822

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.1367 Train_Acc: 95.730 Val_Loss: 0.1038  BEST VAL Loss: 0.1037  Val_Acc: 96.706

Epoch 47: Validation loss decreased (0.103698 --> 0.103367).  Saving model ...
	 Train_Loss: 0.1359 Train_Acc: 95.553 Val_Loss: 0.1034  BEST VAL Loss: 0.1034  Val_Acc: 97.024

Epoch 48: Validation loss decreased (0.103367 --> 0.103026).  Saving model ...
	 Train_Loss: 0.1350 Train_Acc: 95.719 Val_Loss: 0.1030  BEST VAL Loss: 0.1030  Val_Acc: 97.053

Epoch 49: Validation loss decreased (0.103026 --> 0.102805).  Saving model ...
	 Train_Loss: 0.1341 Train_Acc: 95.701 Val_Loss: 0.1028  BEST VAL Loss: 0.1028  Val_Acc: 96.822

Epoch 50: Validation loss decreased (0.102805 --> 0.102472).  Saving model ...
	 Train_Loss: 0.1332 Train_Acc: 95.849 Val_Loss: 0.1025  BEST VAL Loss: 0.1025  Val_Acc: 96.648

Epoch 51: Validation loss decreased (0.102472 --> 0.102195).  Saving model ...
	 Train_Loss: 0.1324 Train_Acc: 95.802 Val_Loss: 0.1022  BEST VAL Loss: 0.1022  Val_Acc: 96.937

Epoch 52: Validation loss decreased (0.102195 --> 0.101976).  Saving model ...
	 Train_Loss: 0.1316 Train_Acc: 95.795 Val_Loss: 0.1020  BEST VAL Loss: 0.1020  Val_Acc: 97.082

Epoch 53: Validation loss decreased (0.101976 --> 0.101856).  Saving model ...
	 Train_Loss: 0.1308 Train_Acc: 95.889 Val_Loss: 0.1019  BEST VAL Loss: 0.1019  Val_Acc: 97.313

Epoch 54: Validation loss decreased (0.101856 --> 0.101709).  Saving model ...
	 Train_Loss: 0.1301 Train_Acc: 95.791 Val_Loss: 0.1017  BEST VAL Loss: 0.1017  Val_Acc: 96.735

Epoch 55: Validation loss decreased (0.101709 --> 0.101360).  Saving model ...
	 Train_Loss: 0.1294 Train_Acc: 95.780 Val_Loss: 0.1014  BEST VAL Loss: 0.1014  Val_Acc: 97.053

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.1287 Train_Acc: 95.683 Val_Loss: 0.1015  BEST VAL Loss: 0.1014  Val_Acc: 96.995

Epoch 57: Validation loss decreased (0.101360 --> 0.101243).  Saving model ...
	 Train_Loss: 0.1281 Train_Acc: 95.607 Val_Loss: 0.1012  BEST VAL Loss: 0.1012  Val_Acc: 96.504

Epoch 58: Validation loss decreased (0.101243 --> 0.100909).  Saving model ...
	 Train_Loss: 0.1275 Train_Acc: 95.614 Val_Loss: 0.1009  BEST VAL Loss: 0.1009  Val_Acc: 97.226

Epoch 59: Validation loss decreased (0.100909 --> 0.100780).  Saving model ...
	 Train_Loss: 0.1268 Train_Acc: 95.863 Val_Loss: 0.1008  BEST VAL Loss: 0.1008  Val_Acc: 96.764

Epoch 60: Validation loss decreased (0.100780 --> 0.100713).  Saving model ...
	 Train_Loss: 0.1262 Train_Acc: 95.784 Val_Loss: 0.1007  BEST VAL Loss: 0.1007  Val_Acc: 96.995

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.1255 Train_Acc: 95.903 Val_Loss: 0.1009  BEST VAL Loss: 0.1007  Val_Acc: 96.706

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.1249 Train_Acc: 95.762 Val_Loss: 0.1010  BEST VAL Loss: 0.1007  Val_Acc: 97.024

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.1244 Train_Acc: 95.867 Val_Loss: 0.1011  BEST VAL Loss: 0.1007  Val_Acc: 96.966

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.1239 Train_Acc: 95.697 Val_Loss: 0.1009  BEST VAL Loss: 0.1007  Val_Acc: 97.053

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.1233 Train_Acc: 95.860 Val_Loss: 0.1008  BEST VAL Loss: 0.1007  Val_Acc: 96.880

Epoch 66: Validation loss decreased (0.100713 --> 0.100478).  Saving model ...
	 Train_Loss: 0.1228 Train_Acc: 95.835 Val_Loss: 0.1005  BEST VAL Loss: 0.1005  Val_Acc: 97.168

Epoch 67: Validation loss decreased (0.100478 --> 0.100330).  Saving model ...
	 Train_Loss: 0.1222 Train_Acc: 95.683 Val_Loss: 0.1003  BEST VAL Loss: 0.1003  Val_Acc: 96.880

Epoch 68: Validation loss decreased (0.100330 --> 0.100310).  Saving model ...
	 Train_Loss: 0.1218 Train_Acc: 95.502 Val_Loss: 0.1003  BEST VAL Loss: 0.1003  Val_Acc: 96.937

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.1213 Train_Acc: 95.809 Val_Loss: 0.1003  BEST VAL Loss: 0.1003  Val_Acc: 97.197

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.1208 Train_Acc: 95.874 Val_Loss: 0.1004  BEST VAL Loss: 0.1003  Val_Acc: 97.226

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.1204 Train_Acc: 95.668 Val_Loss: 0.1004  BEST VAL Loss: 0.1003  Val_Acc: 97.197

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.1199 Train_Acc: 95.762 Val_Loss: 0.1006  BEST VAL Loss: 0.1003  Val_Acc: 96.619

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.1195 Train_Acc: 96.055 Val_Loss: 0.1006  BEST VAL Loss: 0.1003  Val_Acc: 97.226

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.1190 Train_Acc: 95.986 Val_Loss: 0.1006  BEST VAL Loss: 0.1003  Val_Acc: 97.226

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.1186 Train_Acc: 95.647 Val_Loss: 0.1006  BEST VAL Loss: 0.1003  Val_Acc: 97.255

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.1181 Train_Acc: 95.997 Val_Loss: 0.1005  BEST VAL Loss: 0.1003  Val_Acc: 97.400

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.1177 Train_Acc: 95.730 Val_Loss: 0.1006  BEST VAL Loss: 0.1003  Val_Acc: 97.140

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.1173 Train_Acc: 95.925 Val_Loss: 0.1007  BEST VAL Loss: 0.1003  Val_Acc: 96.619

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.1170 Train_Acc: 95.878 Val_Loss: 0.1004  BEST VAL Loss: 0.1003  Val_Acc: 97.140

Epoch 80: Validation loss decreased (0.100310 --> 0.100173).  Saving model ...
	 Train_Loss: 0.1166 Train_Acc: 95.968 Val_Loss: 0.1002  BEST VAL Loss: 0.1002  Val_Acc: 97.400

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.1162 Train_Acc: 96.044 Val_Loss: 0.1005  BEST VAL Loss: 0.1002  Val_Acc: 96.937

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.1158 Train_Acc: 95.686 Val_Loss: 0.1008  BEST VAL Loss: 0.1002  Val_Acc: 96.851

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.1154 Train_Acc: 95.979 Val_Loss: 0.1008  BEST VAL Loss: 0.1002  Val_Acc: 97.053

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.1150 Train_Acc: 95.712 Val_Loss: 0.1006  BEST VAL Loss: 0.1002  Val_Acc: 96.966

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.1147 Train_Acc: 95.863 Val_Loss: 0.1007  BEST VAL Loss: 0.1002  Val_Acc: 97.168

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.1143 Train_Acc: 95.838 Val_Loss: 0.1006  BEST VAL Loss: 0.1002  Val_Acc: 97.140

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.1140 Train_Acc: 95.853 Val_Loss: 0.1004  BEST VAL Loss: 0.1002  Val_Acc: 97.053

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.1136 Train_Acc: 95.921 Val_Loss: 0.1002  BEST VAL Loss: 0.1002  Val_Acc: 97.226

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.1132 Train_Acc: 96.217 Val_Loss: 0.1004  BEST VAL Loss: 0.1002  Val_Acc: 96.995

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.1128 Train_Acc: 96.120 Val_Loss: 0.1002  BEST VAL Loss: 0.1002  Val_Acc: 96.995

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.1125 Train_Acc: 96.033 Val_Loss: 0.1005  BEST VAL Loss: 0.1002  Val_Acc: 96.908

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.1122 Train_Acc: 96.040 Val_Loss: 0.1003  BEST VAL Loss: 0.1002  Val_Acc: 97.111

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.1118 Train_Acc: 96.156 Val_Loss: 0.1005  BEST VAL Loss: 0.1002  Val_Acc: 96.880

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.1115 Train_Acc: 95.863 Val_Loss: 0.1005  BEST VAL Loss: 0.1002  Val_Acc: 96.966

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.1112 Train_Acc: 95.824 Val_Loss: 0.1004  BEST VAL Loss: 0.1002  Val_Acc: 96.937

Epoch 96: Validation loss did not decrease
Early stopped at epoch : 96
H2O2_100.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.66      0.66      0.66     18174
           1       0.34      0.34      0.34      9506

    accuracy                           0.55     27680
   macro avg       0.50      0.50      0.50     27680
weighted avg       0.55      0.55      0.55     27680

H2O2_100.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.65      0.65      0.65      2272
           1       0.33      0.33      0.33      1189

    accuracy                           0.54      3461
   macro avg       0.49      0.49      0.49      3461
weighted avg       0.54      0.54      0.54      3461

H2O2_100.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.66      0.66      0.66      2272
           1       0.34      0.34      0.34      1189

    accuracy                           0.55      3461
   macro avg       0.50      0.50      0.50      3461
weighted avg       0.55      0.55      0.55      3461

              precision    recall  f1-score   support

           0       0.66      0.66      0.66      2272
           1       0.34      0.34      0.34      1189

    accuracy                           0.55      3461
   macro avg       0.50      0.50      0.50      3461
weighted avg       0.55      0.55      0.55      3461

H2O2_100.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.54      0.52      4182
           1       0.49      0.46      0.48      4103

    accuracy                           0.50      8285
   macro avg       0.50      0.50      0.50      8285
weighted avg       0.50      0.50      0.50      8285

              precision    recall  f1-score   support

           0       0.50      0.54      0.52      4182
           1       0.49      0.46      0.48      4103

    accuracy                           0.50      8285
   macro avg       0.50      0.50      0.50      8285
weighted avg       0.50      0.50      0.50      8285

completed
