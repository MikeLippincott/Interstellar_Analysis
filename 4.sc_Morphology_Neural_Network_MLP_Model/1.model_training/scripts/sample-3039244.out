[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '6a468c5f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '5328287d'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1d160b16'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '4c7b8c2c'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 treatment_name: Thapsigargin_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
TREATMENT_NAME: Thapsigargin_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (329622, 1270)
Number of total missing values across all columns: 296912
Data Subset Is Off
Wells held out for testing: ['K06' 'M09']
Wells to use for training, validation, and testing ['D06' 'D07' 'K07' 'M02' 'M03' 'M08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.160236).  Saving model ...
	 Train_Loss: 0.2365 Train_Acc: 90.245 Val_Loss: 0.1602  BEST VAL Loss: 0.1602  Val_Acc: 93.769

Epoch 1: Validation loss decreased (0.160236 --> 0.148532).  Saving model ...
	 Train_Loss: 0.2035 Train_Acc: 93.327 Val_Loss: 0.1485  BEST VAL Loss: 0.1485  Val_Acc: 94.691

Epoch 2: Validation loss decreased (0.148532 --> 0.140741).  Saving model ...
	 Train_Loss: 0.1871 Train_Acc: 94.052 Val_Loss: 0.1407  BEST VAL Loss: 0.1407  Val_Acc: 95.233

Epoch 3: Validation loss decreased (0.140741 --> 0.134995).  Saving model ...
	 Train_Loss: 0.1768 Train_Acc: 94.425 Val_Loss: 0.1350  BEST VAL Loss: 0.1350  Val_Acc: 95.631

Epoch 4: Validation loss decreased (0.134995 --> 0.130864).  Saving model ...
	 Train_Loss: 0.1690 Train_Acc: 94.776 Val_Loss: 0.1309  BEST VAL Loss: 0.1309  Val_Acc: 95.585

Epoch 5: Validation loss decreased (0.130864 --> 0.126956).  Saving model ...
	 Train_Loss: 0.1631 Train_Acc: 94.955 Val_Loss: 0.1270  BEST VAL Loss: 0.1270  Val_Acc: 95.999

Epoch 6: Validation loss decreased (0.126956 --> 0.123862).  Saving model ...
	 Train_Loss: 0.1585 Train_Acc: 95.027 Val_Loss: 0.1239  BEST VAL Loss: 0.1239  Val_Acc: 96.098

Epoch 7: Validation loss decreased (0.123862 --> 0.121068).  Saving model ...
	 Train_Loss: 0.1544 Train_Acc: 95.283 Val_Loss: 0.1211  BEST VAL Loss: 0.1211  Val_Acc: 96.202

Epoch 8: Validation loss decreased (0.121068 --> 0.119172).  Saving model ...
	 Train_Loss: 0.1510 Train_Acc: 95.333 Val_Loss: 0.1192  BEST VAL Loss: 0.1192  Val_Acc: 96.288

Epoch 9: Validation loss decreased (0.119172 --> 0.117258).  Saving model ...
	 Train_Loss: 0.1480 Train_Acc: 95.384 Val_Loss: 0.1173  BEST VAL Loss: 0.1173  Val_Acc: 96.346

Epoch 10: Validation loss decreased (0.117258 --> 0.115488).  Saving model ...
	 Train_Loss: 0.1455 Train_Acc: 95.498 Val_Loss: 0.1155  BEST VAL Loss: 0.1155  Val_Acc: 96.417

Epoch 11: Validation loss decreased (0.115488 --> 0.114207).  Saving model ...
	 Train_Loss: 0.1432 Train_Acc: 95.544 Val_Loss: 0.1142  BEST VAL Loss: 0.1142  Val_Acc: 96.388

Epoch 12: Validation loss decreased (0.114207 --> 0.112816).  Saving model ...
	 Train_Loss: 0.1411 Train_Acc: 95.650 Val_Loss: 0.1128  BEST VAL Loss: 0.1128  Val_Acc: 96.475

Epoch 13: Validation loss decreased (0.112816 --> 0.111354).  Saving model ...
	 Train_Loss: 0.1393 Train_Acc: 95.644 Val_Loss: 0.1114  BEST VAL Loss: 0.1114  Val_Acc: 96.706

Epoch 14: Validation loss decreased (0.111354 --> 0.110176).  Saving model ...
	 Train_Loss: 0.1376 Train_Acc: 95.705 Val_Loss: 0.1102  BEST VAL Loss: 0.1102  Val_Acc: 96.648

Epoch 15: Validation loss decreased (0.110176 --> 0.109231).  Saving model ...
	 Train_Loss: 0.1360 Train_Acc: 95.787 Val_Loss: 0.1092  BEST VAL Loss: 0.1092  Val_Acc: 96.433

Epoch 16: Validation loss decreased (0.109231 --> 0.108103).  Saving model ...
	 Train_Loss: 0.1346 Train_Acc: 95.800 Val_Loss: 0.1081  BEST VAL Loss: 0.1081  Val_Acc: 96.690

Epoch 17: Validation loss decreased (0.108103 --> 0.107193).  Saving model ...
	 Train_Loss: 0.1332 Train_Acc: 95.832 Val_Loss: 0.1072  BEST VAL Loss: 0.1072  Val_Acc: 96.682

Epoch 18: Validation loss decreased (0.107193 --> 0.106208).  Saving model ...
	 Train_Loss: 0.1320 Train_Acc: 95.854 Val_Loss: 0.1062  BEST VAL Loss: 0.1062  Val_Acc: 96.694

Epoch 19: Validation loss decreased (0.106208 --> 0.105250).  Saving model ...
	 Train_Loss: 0.1309 Train_Acc: 95.935 Val_Loss: 0.1052  BEST VAL Loss: 0.1052  Val_Acc: 96.864

Epoch 20: Validation loss decreased (0.105250 --> 0.104449).  Saving model ...
	 Train_Loss: 0.1297 Train_Acc: 95.965 Val_Loss: 0.1044  BEST VAL Loss: 0.1044  Val_Acc: 96.802

Epoch 21: Validation loss decreased (0.104449 --> 0.103859).  Saving model ...
	 Train_Loss: 0.1287 Train_Acc: 95.994 Val_Loss: 0.1039  BEST VAL Loss: 0.1039  Val_Acc: 96.768

Epoch 22: Validation loss decreased (0.103859 --> 0.103281).  Saving model ...
	 Train_Loss: 0.1278 Train_Acc: 95.964 Val_Loss: 0.1033  BEST VAL Loss: 0.1033  Val_Acc: 96.669

Epoch 23: Validation loss decreased (0.103281 --> 0.102717).  Saving model ...
	 Train_Loss: 0.1268 Train_Acc: 96.031 Val_Loss: 0.1027  BEST VAL Loss: 0.1027  Val_Acc: 96.884

Epoch 24: Validation loss decreased (0.102717 --> 0.102138).  Saving model ...
	 Train_Loss: 0.1260 Train_Acc: 96.027 Val_Loss: 0.1021  BEST VAL Loss: 0.1021  Val_Acc: 96.785

Epoch 25: Validation loss decreased (0.102138 --> 0.101706).  Saving model ...
	 Train_Loss: 0.1251 Train_Acc: 96.142 Val_Loss: 0.1017  BEST VAL Loss: 0.1017  Val_Acc: 96.859

Epoch 26: Validation loss decreased (0.101706 --> 0.101271).  Saving model ...
	 Train_Loss: 0.1243 Train_Acc: 96.164 Val_Loss: 0.1013  BEST VAL Loss: 0.1013  Val_Acc: 96.864

Epoch 27: Validation loss decreased (0.101271 --> 0.100835).  Saving model ...
	 Train_Loss: 0.1235 Train_Acc: 96.113 Val_Loss: 0.1008  BEST VAL Loss: 0.1008  Val_Acc: 96.855

Epoch 28: Validation loss decreased (0.100835 --> 0.100339).  Saving model ...
	 Train_Loss: 0.1228 Train_Acc: 96.130 Val_Loss: 0.1003  BEST VAL Loss: 0.1003  Val_Acc: 96.855

Epoch 29: Validation loss decreased (0.100339 --> 0.099854).  Saving model ...
	 Train_Loss: 0.1221 Train_Acc: 96.201 Val_Loss: 0.0999  BEST VAL Loss: 0.0999  Val_Acc: 96.963

Epoch 30: Validation loss decreased (0.099854 --> 0.099435).  Saving model ...
	 Train_Loss: 0.1214 Train_Acc: 96.257 Val_Loss: 0.0994  BEST VAL Loss: 0.0994  Val_Acc: 97.004

Epoch 31: Validation loss decreased (0.099435 --> 0.099054).  Saving model ...
	 Train_Loss: 0.1208 Train_Acc: 96.162 Val_Loss: 0.0991  BEST VAL Loss: 0.0991  Val_Acc: 96.930

Epoch 32: Validation loss decreased (0.099054 --> 0.098709).  Saving model ...
	 Train_Loss: 0.1202 Train_Acc: 96.154 Val_Loss: 0.0987  BEST VAL Loss: 0.0987  Val_Acc: 96.888

Epoch 33: Validation loss decreased (0.098709 --> 0.098385).  Saving model ...
	 Train_Loss: 0.1196 Train_Acc: 96.199 Val_Loss: 0.0984  BEST VAL Loss: 0.0984  Val_Acc: 96.781

Epoch 34: Validation loss decreased (0.098385 --> 0.098112).  Saving model ...
	 Train_Loss: 0.1190 Train_Acc: 96.240 Val_Loss: 0.0981  BEST VAL Loss: 0.0981  Val_Acc: 96.855

Epoch 35: Validation loss decreased (0.098112 --> 0.097789).  Saving model ...
	 Train_Loss: 0.1185 Train_Acc: 96.233 Val_Loss: 0.0978  BEST VAL Loss: 0.0978  Val_Acc: 96.897

Epoch 36: Validation loss decreased (0.097789 --> 0.097419).  Saving model ...
	 Train_Loss: 0.1179 Train_Acc: 96.319 Val_Loss: 0.0974  BEST VAL Loss: 0.0974  Val_Acc: 96.946

Epoch 37: Validation loss decreased (0.097419 --> 0.097183).  Saving model ...
	 Train_Loss: 0.1174 Train_Acc: 96.282 Val_Loss: 0.0972  BEST VAL Loss: 0.0972  Val_Acc: 96.789

Epoch 38: Validation loss decreased (0.097183 --> 0.096909).  Saving model ...
	 Train_Loss: 0.1169 Train_Acc: 96.288 Val_Loss: 0.0969  BEST VAL Loss: 0.0969  Val_Acc: 97.071

Epoch 39: Validation loss decreased (0.096909 --> 0.096600).  Saving model ...
	 Train_Loss: 0.1164 Train_Acc: 96.391 Val_Loss: 0.0966  BEST VAL Loss: 0.0966  Val_Acc: 96.926

Epoch 40: Validation loss decreased (0.096600 --> 0.096346).  Saving model ...
	 Train_Loss: 0.1160 Train_Acc: 96.300 Val_Loss: 0.0963  BEST VAL Loss: 0.0963  Val_Acc: 96.897

Epoch 41: Validation loss decreased (0.096346 --> 0.096088).  Saving model ...
	 Train_Loss: 0.1155 Train_Acc: 96.350 Val_Loss: 0.0961  BEST VAL Loss: 0.0961  Val_Acc: 96.971

Epoch 42: Validation loss decreased (0.096088 --> 0.095947).  Saving model ...
	 Train_Loss: 0.1151 Train_Acc: 96.307 Val_Loss: 0.0959  BEST VAL Loss: 0.0959  Val_Acc: 96.971

Epoch 43: Validation loss decreased (0.095947 --> 0.095790).  Saving model ...
	 Train_Loss: 0.1146 Train_Acc: 96.361 Val_Loss: 0.0958  BEST VAL Loss: 0.0958  Val_Acc: 96.884

Epoch 44: Validation loss decreased (0.095790 --> 0.095586).  Saving model ...
	 Train_Loss: 0.1142 Train_Acc: 96.412 Val_Loss: 0.0956  BEST VAL Loss: 0.0956  Val_Acc: 96.884

Epoch 45: Validation loss decreased (0.095586 --> 0.095361).  Saving model ...
	 Train_Loss: 0.1138 Train_Acc: 96.348 Val_Loss: 0.0954  BEST VAL Loss: 0.0954  Val_Acc: 96.971

Epoch 46: Validation loss decreased (0.095361 --> 0.095175).  Saving model ...
	 Train_Loss: 0.1134 Train_Acc: 96.408 Val_Loss: 0.0952  BEST VAL Loss: 0.0952  Val_Acc: 97.017

Epoch 47: Validation loss decreased (0.095175 --> 0.094904).  Saving model ...
	 Train_Loss: 0.1130 Train_Acc: 96.462 Val_Loss: 0.0949  BEST VAL Loss: 0.0949  Val_Acc: 97.075

Epoch 48: Validation loss decreased (0.094904 --> 0.094813).  Saving model ...
	 Train_Loss: 0.1126 Train_Acc: 96.447 Val_Loss: 0.0948  BEST VAL Loss: 0.0948  Val_Acc: 97.037

Epoch 49: Validation loss decreased (0.094813 --> 0.094624).  Saving model ...
	 Train_Loss: 0.1123 Train_Acc: 96.414 Val_Loss: 0.0946  BEST VAL Loss: 0.0946  Val_Acc: 96.992

Epoch 50: Validation loss decreased (0.094624 --> 0.094451).  Saving model ...
	 Train_Loss: 0.1119 Train_Acc: 96.451 Val_Loss: 0.0945  BEST VAL Loss: 0.0945  Val_Acc: 97.042

Epoch 51: Validation loss decreased (0.094451 --> 0.094244).  Saving model ...
	 Train_Loss: 0.1115 Train_Acc: 96.525 Val_Loss: 0.0942  BEST VAL Loss: 0.0942  Val_Acc: 97.083

Epoch 52: Validation loss decreased (0.094244 --> 0.094086).  Saving model ...
	 Train_Loss: 0.1112 Train_Acc: 96.408 Val_Loss: 0.0941  BEST VAL Loss: 0.0941  Val_Acc: 96.864

Epoch 53: Validation loss decreased (0.094086 --> 0.093951).  Saving model ...
	 Train_Loss: 0.1109 Train_Acc: 96.480 Val_Loss: 0.0940  BEST VAL Loss: 0.0940  Val_Acc: 97.046

Epoch 54: Validation loss decreased (0.093951 --> 0.093760).  Saving model ...
	 Train_Loss: 0.1106 Train_Acc: 96.483 Val_Loss: 0.0938  BEST VAL Loss: 0.0938  Val_Acc: 97.228

Epoch 55: Validation loss decreased (0.093760 --> 0.093600).  Saving model ...
	 Train_Loss: 0.1103 Train_Acc: 96.473 Val_Loss: 0.0936  BEST VAL Loss: 0.0936  Val_Acc: 96.975

Epoch 56: Validation loss decreased (0.093600 --> 0.093391).  Saving model ...
	 Train_Loss: 0.1099 Train_Acc: 96.518 Val_Loss: 0.0934  BEST VAL Loss: 0.0934  Val_Acc: 97.025

Epoch 57: Validation loss decreased (0.093391 --> 0.093245).  Saving model ...
	 Train_Loss: 0.1096 Train_Acc: 96.443 Val_Loss: 0.0932  BEST VAL Loss: 0.0932  Val_Acc: 97.000

Epoch 58: Validation loss decreased (0.093245 --> 0.093096).  Saving model ...
	 Train_Loss: 0.1093 Train_Acc: 96.504 Val_Loss: 0.0931  BEST VAL Loss: 0.0931  Val_Acc: 97.166

Epoch 59: Validation loss decreased (0.093096 --> 0.092922).  Saving model ...
	 Train_Loss: 0.1091 Train_Acc: 96.449 Val_Loss: 0.0929  BEST VAL Loss: 0.0929  Val_Acc: 97.141

Epoch 60: Validation loss decreased (0.092922 --> 0.092792).  Saving model ...
	 Train_Loss: 0.1088 Train_Acc: 96.565 Val_Loss: 0.0928  BEST VAL Loss: 0.0928  Val_Acc: 97.017

Epoch 61: Validation loss decreased (0.092792 --> 0.092677).  Saving model ...
	 Train_Loss: 0.1085 Train_Acc: 96.535 Val_Loss: 0.0927  BEST VAL Loss: 0.0927  Val_Acc: 97.050

Epoch 62: Validation loss decreased (0.092677 --> 0.092556).  Saving model ...
	 Train_Loss: 0.1082 Train_Acc: 96.513 Val_Loss: 0.0926  BEST VAL Loss: 0.0926  Val_Acc: 96.988

Epoch 63: Validation loss decreased (0.092556 --> 0.092481).  Saving model ...
	 Train_Loss: 0.1079 Train_Acc: 96.572 Val_Loss: 0.0925  BEST VAL Loss: 0.0925  Val_Acc: 97.013

Epoch 64: Validation loss decreased (0.092481 --> 0.092360).  Saving model ...
	 Train_Loss: 0.1077 Train_Acc: 96.541 Val_Loss: 0.0924  BEST VAL Loss: 0.0924  Val_Acc: 97.008

Epoch 65: Validation loss decreased (0.092360 --> 0.092206).  Saving model ...
	 Train_Loss: 0.1074 Train_Acc: 96.578 Val_Loss: 0.0922  BEST VAL Loss: 0.0922  Val_Acc: 97.133

Epoch 66: Validation loss decreased (0.092206 --> 0.092073).  Saving model ...
	 Train_Loss: 0.1072 Train_Acc: 96.571 Val_Loss: 0.0921  BEST VAL Loss: 0.0921  Val_Acc: 97.166

Epoch 67: Validation loss decreased (0.092073 --> 0.091917).  Saving model ...
	 Train_Loss: 0.1069 Train_Acc: 96.557 Val_Loss: 0.0919  BEST VAL Loss: 0.0919  Val_Acc: 97.079

Epoch 68: Validation loss decreased (0.091917 --> 0.091786).  Saving model ...
	 Train_Loss: 0.1067 Train_Acc: 96.580 Val_Loss: 0.0918  BEST VAL Loss: 0.0918  Val_Acc: 97.133

Epoch 69: Validation loss decreased (0.091786 --> 0.091702).  Saving model ...
	 Train_Loss: 0.1065 Train_Acc: 96.564 Val_Loss: 0.0917  BEST VAL Loss: 0.0917  Val_Acc: 97.128

Epoch 70: Validation loss decreased (0.091702 --> 0.091634).  Saving model ...
	 Train_Loss: 0.1062 Train_Acc: 96.613 Val_Loss: 0.0916  BEST VAL Loss: 0.0916  Val_Acc: 97.224

Epoch 71: Validation loss decreased (0.091634 --> 0.091558).  Saving model ...
	 Train_Loss: 0.1060 Train_Acc: 96.641 Val_Loss: 0.0916  BEST VAL Loss: 0.0916  Val_Acc: 97.128

Epoch 72: Validation loss decreased (0.091558 --> 0.091433).  Saving model ...
	 Train_Loss: 0.1058 Train_Acc: 96.592 Val_Loss: 0.0914  BEST VAL Loss: 0.0914  Val_Acc: 97.174

Epoch 73: Validation loss decreased (0.091433 --> 0.091390).  Saving model ...
	 Train_Loss: 0.1055 Train_Acc: 96.620 Val_Loss: 0.0914  BEST VAL Loss: 0.0914  Val_Acc: 97.021

Epoch 74: Validation loss decreased (0.091390 --> 0.091322).  Saving model ...
	 Train_Loss: 0.1053 Train_Acc: 96.615 Val_Loss: 0.0913  BEST VAL Loss: 0.0913  Val_Acc: 97.095

Epoch 75: Validation loss decreased (0.091322 --> 0.091236).  Saving model ...
	 Train_Loss: 0.1051 Train_Acc: 96.633 Val_Loss: 0.0912  BEST VAL Loss: 0.0912  Val_Acc: 97.116

Epoch 76: Validation loss decreased (0.091236 --> 0.091125).  Saving model ...
	 Train_Loss: 0.1049 Train_Acc: 96.593 Val_Loss: 0.0911  BEST VAL Loss: 0.0911  Val_Acc: 97.071

Epoch 77: Validation loss decreased (0.091125 --> 0.091043).  Saving model ...
	 Train_Loss: 0.1047 Train_Acc: 96.632 Val_Loss: 0.0910  BEST VAL Loss: 0.0910  Val_Acc: 97.095

Epoch 78: Validation loss decreased (0.091043 --> 0.090975).  Saving model ...
	 Train_Loss: 0.1045 Train_Acc: 96.689 Val_Loss: 0.0910  BEST VAL Loss: 0.0910  Val_Acc: 97.137

Epoch 79: Validation loss decreased (0.090975 --> 0.090885).  Saving model ...
	 Train_Loss: 0.1043 Train_Acc: 96.658 Val_Loss: 0.0909  BEST VAL Loss: 0.0909  Val_Acc: 97.190

Epoch 80: Validation loss decreased (0.090885 --> 0.090808).  Saving model ...
	 Train_Loss: 0.1041 Train_Acc: 96.719 Val_Loss: 0.0908  BEST VAL Loss: 0.0908  Val_Acc: 97.079

Epoch 81: Validation loss decreased (0.090808 --> 0.090729).  Saving model ...
	 Train_Loss: 0.1039 Train_Acc: 96.647 Val_Loss: 0.0907  BEST VAL Loss: 0.0907  Val_Acc: 97.244

Epoch 82: Validation loss decreased (0.090729 --> 0.090613).  Saving model ...
	 Train_Loss: 0.1037 Train_Acc: 96.701 Val_Loss: 0.0906  BEST VAL Loss: 0.0906  Val_Acc: 97.228

Epoch 83: Validation loss decreased (0.090613 --> 0.090537).  Saving model ...
	 Train_Loss: 0.1035 Train_Acc: 96.711 Val_Loss: 0.0905  BEST VAL Loss: 0.0905  Val_Acc: 97.046

Epoch 84: Validation loss decreased (0.090537 --> 0.090478).  Saving model ...
	 Train_Loss: 0.1033 Train_Acc: 96.751 Val_Loss: 0.0905  BEST VAL Loss: 0.0905  Val_Acc: 97.091

Epoch 85: Validation loss decreased (0.090478 --> 0.090413).  Saving model ...
	 Train_Loss: 0.1031 Train_Acc: 96.677 Val_Loss: 0.0904  BEST VAL Loss: 0.0904  Val_Acc: 97.116

Epoch 86: Validation loss decreased (0.090413 --> 0.090348).  Saving model ...
	 Train_Loss: 0.1029 Train_Acc: 96.723 Val_Loss: 0.0903  BEST VAL Loss: 0.0903  Val_Acc: 97.228

Epoch 87: Validation loss decreased (0.090348 --> 0.090260).  Saving model ...
	 Train_Loss: 0.1027 Train_Acc: 96.685 Val_Loss: 0.0903  BEST VAL Loss: 0.0903  Val_Acc: 97.203

Epoch 88: Validation loss decreased (0.090260 --> 0.090164).  Saving model ...
	 Train_Loss: 0.1026 Train_Acc: 96.699 Val_Loss: 0.0902  BEST VAL Loss: 0.0902  Val_Acc: 97.166

Epoch 89: Validation loss decreased (0.090164 --> 0.090058).  Saving model ...
	 Train_Loss: 0.1024 Train_Acc: 96.708 Val_Loss: 0.0901  BEST VAL Loss: 0.0901  Val_Acc: 97.327

Epoch 90: Validation loss decreased (0.090058 --> 0.089989).  Saving model ...
	 Train_Loss: 0.1022 Train_Acc: 96.750 Val_Loss: 0.0900  BEST VAL Loss: 0.0900  Val_Acc: 97.170

Epoch 91: Validation loss decreased (0.089989 --> 0.089948).  Saving model ...
	 Train_Loss: 0.1020 Train_Acc: 96.723 Val_Loss: 0.0899  BEST VAL Loss: 0.0899  Val_Acc: 97.141

Epoch 92: Validation loss decreased (0.089948 --> 0.089879).  Saving model ...
	 Train_Loss: 0.1018 Train_Acc: 96.708 Val_Loss: 0.0899  BEST VAL Loss: 0.0899  Val_Acc: 97.211

Epoch 93: Validation loss decreased (0.089879 --> 0.089846).  Saving model ...
	 Train_Loss: 0.1017 Train_Acc: 96.712 Val_Loss: 0.0898  BEST VAL Loss: 0.0898  Val_Acc: 97.145

Epoch 94: Validation loss decreased (0.089846 --> 0.089764).  Saving model ...
	 Train_Loss: 0.1015 Train_Acc: 96.725 Val_Loss: 0.0898  BEST VAL Loss: 0.0898  Val_Acc: 97.141

Epoch 95: Validation loss decreased (0.089764 --> 0.089751).  Saving model ...
	 Train_Loss: 0.1013 Train_Acc: 96.740 Val_Loss: 0.0898  BEST VAL Loss: 0.0898  Val_Acc: 96.975

Epoch 96: Validation loss decreased (0.089751 --> 0.089679).  Saving model ...
	 Train_Loss: 0.1012 Train_Acc: 96.750 Val_Loss: 0.0897  BEST VAL Loss: 0.0897  Val_Acc: 97.116

Epoch 97: Validation loss decreased (0.089679 --> 0.089607).  Saving model ...
	 Train_Loss: 0.1010 Train_Acc: 96.759 Val_Loss: 0.0896  BEST VAL Loss: 0.0896  Val_Acc: 97.211

Epoch 98: Validation loss decreased (0.089607 --> 0.089565).  Saving model ...
	 Train_Loss: 0.1009 Train_Acc: 96.766 Val_Loss: 0.0896  BEST VAL Loss: 0.0896  Val_Acc: 97.116

Epoch 99: Validation loss decreased (0.089565 --> 0.089500).  Saving model ...
	 Train_Loss: 0.1007 Train_Acc: 96.740 Val_Loss: 0.0895  BEST VAL Loss: 0.0895  Val_Acc: 97.116

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.54      0.54      0.54    105242
           1       0.46      0.46      0.46     88098

    accuracy                           0.50    193340
   macro avg       0.50      0.50      0.50    193340
weighted avg       0.50      0.50      0.50    193340

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.55      0.55     13155
           1       0.46      0.46      0.46     11013

    accuracy                           0.51     24168
   macro avg       0.50      0.50      0.50     24168
weighted avg       0.51      0.51      0.51     24168

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.54      0.54      0.54     13155
           1       0.45      0.46      0.46     11013

    accuracy                           0.50     24168
   macro avg       0.50      0.50      0.50     24168
weighted avg       0.50      0.50      0.50     24168

              precision    recall  f1-score   support

           0       0.54      0.54      0.54     13155
           1       0.45      0.46      0.46     11013

    accuracy                           0.50     24168
   macro avg       0.50      0.50      0.50     24168
weighted avg       0.50      0.50      0.50     24168

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.57      0.55      0.56     49614
           1       0.44      0.45      0.44     38332

    accuracy                           0.51     87946
   macro avg       0.50      0.50      0.50     87946
weighted avg       0.51      0.51      0.51     87946

              precision    recall  f1-score   support

           0       0.57      0.55      0.56     49614
           1       0.44      0.45      0.44     38332

    accuracy                           0.51     87946
   macro avg       0.50      0.50      0.50     87946
weighted avg       0.51      0.51      0.51     87946

completed
