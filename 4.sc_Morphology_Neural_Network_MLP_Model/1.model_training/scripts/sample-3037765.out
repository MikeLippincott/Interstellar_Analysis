[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '969505a4'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '48138de5'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '5eda47ef'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '3b97f245'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_0.100_DMSO_0.025 treatment_name: DMSO_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_0.100_DMSO_0.025
TREATMENT_NAME: DMSO_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'DMSO_0.100_DMSO_0.025']
The dimensions of the data are: (353727, 1270)
Number of total missing values across all columns: 707454
Data Subset Is Off
Wells held out for testing: ['C09' 'J06']
Wells to use for training, validation, and testing ['C02' 'C03' 'B06' 'C06' 'B07' 'C07' 'C08' 'I06' 'I07' 'J07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.416723).  Saving model ...
	 Train_Loss: 0.5022 Train_Acc: 74.653 Val_Loss: 0.4167  BEST VAL Loss: 0.4167  Val_Acc: 80.137

Epoch 1: Validation loss decreased (0.416723 --> 0.395875).  Saving model ...
	 Train_Loss: 0.4601 Train_Acc: 80.050 Val_Loss: 0.3959  BEST VAL Loss: 0.3959  Val_Acc: 82.771

Epoch 2: Validation loss decreased (0.395875 --> 0.382692).  Saving model ...
	 Train_Loss: 0.4397 Train_Acc: 81.090 Val_Loss: 0.3827  BEST VAL Loss: 0.3827  Val_Acc: 83.515

Epoch 3: Validation loss decreased (0.382692 --> 0.375311).  Saving model ...
	 Train_Loss: 0.4261 Train_Acc: 81.747 Val_Loss: 0.3753  BEST VAL Loss: 0.3753  Val_Acc: 84.140

Epoch 4: Validation loss decreased (0.375311 --> 0.369841).  Saving model ...
	 Train_Loss: 0.4166 Train_Acc: 81.976 Val_Loss: 0.3698  BEST VAL Loss: 0.3698  Val_Acc: 84.025

Epoch 5: Validation loss decreased (0.369841 --> 0.365293).  Saving model ...
	 Train_Loss: 0.4098 Train_Acc: 82.117 Val_Loss: 0.3653  BEST VAL Loss: 0.3653  Val_Acc: 84.383

Epoch 6: Validation loss decreased (0.365293 --> 0.361166).  Saving model ...
	 Train_Loss: 0.4041 Train_Acc: 82.316 Val_Loss: 0.3612  BEST VAL Loss: 0.3612  Val_Acc: 84.755

Epoch 7: Validation loss decreased (0.361166 --> 0.357018).  Saving model ...
	 Train_Loss: 0.3994 Train_Acc: 82.568 Val_Loss: 0.3570  BEST VAL Loss: 0.3570  Val_Acc: 85.287

Epoch 8: Validation loss decreased (0.357018 --> 0.354033).  Saving model ...
	 Train_Loss: 0.3956 Train_Acc: 82.590 Val_Loss: 0.3540  BEST VAL Loss: 0.3540  Val_Acc: 85.141

Epoch 9: Validation loss decreased (0.354033 --> 0.352624).  Saving model ...
	 Train_Loss: 0.3923 Train_Acc: 82.631 Val_Loss: 0.3526  BEST VAL Loss: 0.3526  Val_Acc: 84.891

Epoch 10: Validation loss decreased (0.352624 --> 0.350769).  Saving model ...
	 Train_Loss: 0.3895 Train_Acc: 82.663 Val_Loss: 0.3508  BEST VAL Loss: 0.3508  Val_Acc: 84.950

Epoch 11: Validation loss decreased (0.350769 --> 0.348816).  Saving model ...
	 Train_Loss: 0.3870 Train_Acc: 82.668 Val_Loss: 0.3488  BEST VAL Loss: 0.3488  Val_Acc: 85.297

Epoch 12: Validation loss decreased (0.348816 --> 0.347120).  Saving model ...
	 Train_Loss: 0.3846 Train_Acc: 82.890 Val_Loss: 0.3471  BEST VAL Loss: 0.3471  Val_Acc: 85.005

Epoch 13: Validation loss decreased (0.347120 --> 0.345387).  Saving model ...
	 Train_Loss: 0.3826 Train_Acc: 82.901 Val_Loss: 0.3454  BEST VAL Loss: 0.3454  Val_Acc: 85.395

Epoch 14: Validation loss decreased (0.345387 --> 0.343840).  Saving model ...
	 Train_Loss: 0.3807 Train_Acc: 82.926 Val_Loss: 0.3438  BEST VAL Loss: 0.3438  Val_Acc: 85.673

Epoch 15: Validation loss decreased (0.343840 --> 0.342416).  Saving model ...
	 Train_Loss: 0.3788 Train_Acc: 83.031 Val_Loss: 0.3424  BEST VAL Loss: 0.3424  Val_Acc: 85.780

Epoch 16: Validation loss decreased (0.342416 --> 0.341376).  Saving model ...
	 Train_Loss: 0.3773 Train_Acc: 83.089 Val_Loss: 0.3414  BEST VAL Loss: 0.3414  Val_Acc: 85.547

Epoch 17: Validation loss decreased (0.341376 --> 0.340065).  Saving model ...
	 Train_Loss: 0.3759 Train_Acc: 82.982 Val_Loss: 0.3401  BEST VAL Loss: 0.3401  Val_Acc: 85.603

Epoch 18: Validation loss decreased (0.340065 --> 0.339504).  Saving model ...
	 Train_Loss: 0.3744 Train_Acc: 83.156 Val_Loss: 0.3395  BEST VAL Loss: 0.3395  Val_Acc: 85.610

Epoch 19: Validation loss decreased (0.339504 --> 0.338729).  Saving model ...
	 Train_Loss: 0.3732 Train_Acc: 83.027 Val_Loss: 0.3387  BEST VAL Loss: 0.3387  Val_Acc: 85.054

Epoch 20: Validation loss decreased (0.338729 --> 0.337728).  Saving model ...
	 Train_Loss: 0.3720 Train_Acc: 83.224 Val_Loss: 0.3377  BEST VAL Loss: 0.3377  Val_Acc: 85.735

Epoch 21: Validation loss decreased (0.337728 --> 0.337091).  Saving model ...
	 Train_Loss: 0.3708 Train_Acc: 83.240 Val_Loss: 0.3371  BEST VAL Loss: 0.3371  Val_Acc: 85.631

Epoch 22: Validation loss decreased (0.337091 --> 0.336473).  Saving model ...
	 Train_Loss: 0.3697 Train_Acc: 83.236 Val_Loss: 0.3365  BEST VAL Loss: 0.3365  Val_Acc: 85.589

Epoch 23: Validation loss decreased (0.336473 --> 0.336366).  Saving model ...
	 Train_Loss: 0.3687 Train_Acc: 83.152 Val_Loss: 0.3364  BEST VAL Loss: 0.3364  Val_Acc: 85.478

Epoch 24: Validation loss decreased (0.336366 --> 0.335478).  Saving model ...
	 Train_Loss: 0.3677 Train_Acc: 83.110 Val_Loss: 0.3355  BEST VAL Loss: 0.3355  Val_Acc: 86.149

Epoch 25: Validation loss decreased (0.335478 --> 0.334714).  Saving model ...
	 Train_Loss: 0.3669 Train_Acc: 83.303 Val_Loss: 0.3347  BEST VAL Loss: 0.3347  Val_Acc: 85.860

Epoch 26: Validation loss decreased (0.334714 --> 0.334466).  Saving model ...
	 Train_Loss: 0.3660 Train_Acc: 83.336 Val_Loss: 0.3345  BEST VAL Loss: 0.3345  Val_Acc: 85.440

Epoch 27: Validation loss decreased (0.334466 --> 0.333904).  Saving model ...
	 Train_Loss: 0.3652 Train_Acc: 83.319 Val_Loss: 0.3339  BEST VAL Loss: 0.3339  Val_Acc: 85.968

Epoch 28: Validation loss decreased (0.333904 --> 0.333331).  Saving model ...
	 Train_Loss: 0.3644 Train_Acc: 83.368 Val_Loss: 0.3333  BEST VAL Loss: 0.3333  Val_Acc: 85.878

Epoch 29: Validation loss decreased (0.333331 --> 0.333173).  Saving model ...
	 Train_Loss: 0.3636 Train_Acc: 83.371 Val_Loss: 0.3332  BEST VAL Loss: 0.3332  Val_Acc: 85.513

Epoch 30: Validation loss decreased (0.333173 --> 0.332882).  Saving model ...
	 Train_Loss: 0.3630 Train_Acc: 83.256 Val_Loss: 0.3329  BEST VAL Loss: 0.3329  Val_Acc: 85.812

Epoch 31: Validation loss decreased (0.332882 --> 0.332577).  Saving model ...
	 Train_Loss: 0.3623 Train_Acc: 83.398 Val_Loss: 0.3326  BEST VAL Loss: 0.3326  Val_Acc: 86.037

Epoch 32: Validation loss decreased (0.332577 --> 0.332465).  Saving model ...
	 Train_Loss: 0.3616 Train_Acc: 83.494 Val_Loss: 0.3325  BEST VAL Loss: 0.3325  Val_Acc: 85.377

Epoch 33: Validation loss decreased (0.332465 --> 0.332116).  Saving model ...
	 Train_Loss: 0.3610 Train_Acc: 83.291 Val_Loss: 0.3321  BEST VAL Loss: 0.3321  Val_Acc: 85.780

Epoch 34: Validation loss decreased (0.332116 --> 0.331695).  Saving model ...
	 Train_Loss: 0.3604 Train_Acc: 83.518 Val_Loss: 0.3317  BEST VAL Loss: 0.3317  Val_Acc: 86.163

Epoch 35: Validation loss decreased (0.331695 --> 0.331247).  Saving model ...
	 Train_Loss: 0.3598 Train_Acc: 83.332 Val_Loss: 0.3312  BEST VAL Loss: 0.3312  Val_Acc: 85.846

Epoch 36: Validation loss decreased (0.331247 --> 0.330829).  Saving model ...
	 Train_Loss: 0.3593 Train_Acc: 83.412 Val_Loss: 0.3308  BEST VAL Loss: 0.3308  Val_Acc: 85.968

Epoch 37: Validation loss decreased (0.330829 --> 0.330326).  Saving model ...
	 Train_Loss: 0.3587 Train_Acc: 83.521 Val_Loss: 0.3303  BEST VAL Loss: 0.3303  Val_Acc: 85.871

Epoch 38: Validation loss decreased (0.330326 --> 0.329882).  Saving model ...
	 Train_Loss: 0.3582 Train_Acc: 83.451 Val_Loss: 0.3299  BEST VAL Loss: 0.3299  Val_Acc: 86.041

Epoch 39: Validation loss decreased (0.329882 --> 0.329522).  Saving model ...
	 Train_Loss: 0.3577 Train_Acc: 83.400 Val_Loss: 0.3295  BEST VAL Loss: 0.3295  Val_Acc: 86.041

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.3572 Train_Acc: 83.459 Val_Loss: 0.3296  BEST VAL Loss: 0.3295  Val_Acc: 85.259

Epoch 41: Validation loss decreased (0.329522 --> 0.329072).  Saving model ...
	 Train_Loss: 0.3567 Train_Acc: 83.518 Val_Loss: 0.3291  BEST VAL Loss: 0.3291  Val_Acc: 86.385

Epoch 42: Validation loss decreased (0.329072 --> 0.328618).  Saving model ...
	 Train_Loss: 0.3563 Train_Acc: 83.540 Val_Loss: 0.3286  BEST VAL Loss: 0.3286  Val_Acc: 85.926

Epoch 43: Validation loss decreased (0.328618 --> 0.328441).  Saving model ...
	 Train_Loss: 0.3558 Train_Acc: 83.471 Val_Loss: 0.3284  BEST VAL Loss: 0.3284  Val_Acc: 86.458

Epoch 44: Validation loss decreased (0.328441 --> 0.328185).  Saving model ...
	 Train_Loss: 0.3554 Train_Acc: 83.428 Val_Loss: 0.3282  BEST VAL Loss: 0.3282  Val_Acc: 85.812

Epoch 45: Validation loss decreased (0.328185 --> 0.327877).  Saving model ...
	 Train_Loss: 0.3550 Train_Acc: 83.517 Val_Loss: 0.3279  BEST VAL Loss: 0.3279  Val_Acc: 85.718

Epoch 46: Validation loss decreased (0.327877 --> 0.327448).  Saving model ...
	 Train_Loss: 0.3546 Train_Acc: 83.599 Val_Loss: 0.3274  BEST VAL Loss: 0.3274  Val_Acc: 86.110

Epoch 47: Validation loss decreased (0.327448 --> 0.327043).  Saving model ...
	 Train_Loss: 0.3542 Train_Acc: 83.521 Val_Loss: 0.3270  BEST VAL Loss: 0.3270  Val_Acc: 86.114

Epoch 48: Validation loss decreased (0.327043 --> 0.326834).  Saving model ...
	 Train_Loss: 0.3538 Train_Acc: 83.648 Val_Loss: 0.3268  BEST VAL Loss: 0.3268  Val_Acc: 86.027

Epoch 49: Validation loss decreased (0.326834 --> 0.326611).  Saving model ...
	 Train_Loss: 0.3534 Train_Acc: 83.726 Val_Loss: 0.3266  BEST VAL Loss: 0.3266  Val_Acc: 85.725

Epoch 50: Validation loss decreased (0.326611 --> 0.326349).  Saving model ...
	 Train_Loss: 0.3531 Train_Acc: 83.550 Val_Loss: 0.3263  BEST VAL Loss: 0.3263  Val_Acc: 85.725

Epoch 51: Validation loss decreased (0.326349 --> 0.325961).  Saving model ...
	 Train_Loss: 0.3527 Train_Acc: 83.714 Val_Loss: 0.3260  BEST VAL Loss: 0.3260  Val_Acc: 86.545

Epoch 52: Validation loss decreased (0.325961 --> 0.325800).  Saving model ...
	 Train_Loss: 0.3524 Train_Acc: 83.468 Val_Loss: 0.3258  BEST VAL Loss: 0.3258  Val_Acc: 85.443

Epoch 53: Validation loss decreased (0.325800 --> 0.325540).  Saving model ...
	 Train_Loss: 0.3521 Train_Acc: 83.537 Val_Loss: 0.3255  BEST VAL Loss: 0.3255  Val_Acc: 85.704

Epoch 54: Validation loss decreased (0.325540 --> 0.325222).  Saving model ...
	 Train_Loss: 0.3517 Train_Acc: 83.586 Val_Loss: 0.3252  BEST VAL Loss: 0.3252  Val_Acc: 86.333

Epoch 55: Validation loss decreased (0.325222 --> 0.325020).  Saving model ...
	 Train_Loss: 0.3514 Train_Acc: 83.641 Val_Loss: 0.3250  BEST VAL Loss: 0.3250  Val_Acc: 86.295

Epoch 56: Validation loss decreased (0.325020 --> 0.324960).  Saving model ...
	 Train_Loss: 0.3511 Train_Acc: 83.553 Val_Loss: 0.3250  BEST VAL Loss: 0.3250  Val_Acc: 85.686

Epoch 57: Validation loss decreased (0.324960 --> 0.324870).  Saving model ...
	 Train_Loss: 0.3508 Train_Acc: 83.615 Val_Loss: 0.3249  BEST VAL Loss: 0.3249  Val_Acc: 85.714

Epoch 58: Validation loss decreased (0.324870 --> 0.324637).  Saving model ...
	 Train_Loss: 0.3505 Train_Acc: 83.671 Val_Loss: 0.3246  BEST VAL Loss: 0.3246  Val_Acc: 86.041

Epoch 59: Validation loss decreased (0.324637 --> 0.324363).  Saving model ...
	 Train_Loss: 0.3502 Train_Acc: 83.558 Val_Loss: 0.3244  BEST VAL Loss: 0.3244  Val_Acc: 86.329

Epoch 60: Validation loss decreased (0.324363 --> 0.324128).  Saving model ...
	 Train_Loss: 0.3499 Train_Acc: 83.759 Val_Loss: 0.3241  BEST VAL Loss: 0.3241  Val_Acc: 85.791

Epoch 61: Validation loss decreased (0.324128 --> 0.323892).  Saving model ...
	 Train_Loss: 0.3497 Train_Acc: 83.451 Val_Loss: 0.3239  BEST VAL Loss: 0.3239  Val_Acc: 86.006

Epoch 62: Validation loss decreased (0.323892 --> 0.323712).  Saving model ...
	 Train_Loss: 0.3494 Train_Acc: 83.750 Val_Loss: 0.3237  BEST VAL Loss: 0.3237  Val_Acc: 85.909

Epoch 63: Validation loss decreased (0.323712 --> 0.323640).  Saving model ...
	 Train_Loss: 0.3491 Train_Acc: 83.585 Val_Loss: 0.3236  BEST VAL Loss: 0.3236  Val_Acc: 85.923

Epoch 64: Validation loss decreased (0.323640 --> 0.323459).  Saving model ...
	 Train_Loss: 0.3489 Train_Acc: 83.693 Val_Loss: 0.3235  BEST VAL Loss: 0.3235  Val_Acc: 86.110

Epoch 65: Validation loss decreased (0.323459 --> 0.323349).  Saving model ...
	 Train_Loss: 0.3486 Train_Acc: 83.631 Val_Loss: 0.3233  BEST VAL Loss: 0.3233  Val_Acc: 85.947

Epoch 66: Validation loss decreased (0.323349 --> 0.323110).  Saving model ...
	 Train_Loss: 0.3484 Train_Acc: 83.583 Val_Loss: 0.3231  BEST VAL Loss: 0.3231  Val_Acc: 86.152

Epoch 67: Validation loss decreased (0.323110 --> 0.322795).  Saving model ...
	 Train_Loss: 0.3481 Train_Acc: 83.751 Val_Loss: 0.3228  BEST VAL Loss: 0.3228  Val_Acc: 86.427

Epoch 68: Validation loss decreased (0.322795 --> 0.322593).  Saving model ...
	 Train_Loss: 0.3479 Train_Acc: 83.716 Val_Loss: 0.3226  BEST VAL Loss: 0.3226  Val_Acc: 85.888

Epoch 69: Validation loss decreased (0.322593 --> 0.322409).  Saving model ...
	 Train_Loss: 0.3476 Train_Acc: 83.782 Val_Loss: 0.3224  BEST VAL Loss: 0.3224  Val_Acc: 86.180

Epoch 70: Validation loss decreased (0.322409 --> 0.322212).  Saving model ...
	 Train_Loss: 0.3474 Train_Acc: 83.640 Val_Loss: 0.3222  BEST VAL Loss: 0.3222  Val_Acc: 85.937

Epoch 71: Validation loss decreased (0.322212 --> 0.322181).  Saving model ...
	 Train_Loss: 0.3472 Train_Acc: 83.773 Val_Loss: 0.3222  BEST VAL Loss: 0.3222  Val_Acc: 85.506

Epoch 72: Validation loss decreased (0.322181 --> 0.322039).  Saving model ...
	 Train_Loss: 0.3470 Train_Acc: 83.681 Val_Loss: 0.3220  BEST VAL Loss: 0.3220  Val_Acc: 86.395

Epoch 73: Validation loss decreased (0.322039 --> 0.321821).  Saving model ...
	 Train_Loss: 0.3467 Train_Acc: 83.836 Val_Loss: 0.3218  BEST VAL Loss: 0.3218  Val_Acc: 86.597

Epoch 74: Validation loss decreased (0.321821 --> 0.321727).  Saving model ...
	 Train_Loss: 0.3465 Train_Acc: 83.759 Val_Loss: 0.3217  BEST VAL Loss: 0.3217  Val_Acc: 86.395

Epoch 75: Validation loss decreased (0.321727 --> 0.321706).  Saving model ...
	 Train_Loss: 0.3463 Train_Acc: 83.797 Val_Loss: 0.3217  BEST VAL Loss: 0.3217  Val_Acc: 86.156

Epoch 76: Validation loss decreased (0.321706 --> 0.321498).  Saving model ...
	 Train_Loss: 0.3461 Train_Acc: 83.660 Val_Loss: 0.3215  BEST VAL Loss: 0.3215  Val_Acc: 86.448

Epoch 77: Validation loss decreased (0.321498 --> 0.321365).  Saving model ...
	 Train_Loss: 0.3459 Train_Acc: 83.812 Val_Loss: 0.3214  BEST VAL Loss: 0.3214  Val_Acc: 86.548

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.3457 Train_Acc: 83.688 Val_Loss: 0.3214  BEST VAL Loss: 0.3214  Val_Acc: 85.982

Epoch 79: Validation loss decreased (0.321365 --> 0.321303).  Saving model ...
	 Train_Loss: 0.3455 Train_Acc: 83.620 Val_Loss: 0.3213  BEST VAL Loss: 0.3213  Val_Acc: 86.361

Epoch 80: Validation loss decreased (0.321303 --> 0.321217).  Saving model ...
	 Train_Loss: 0.3453 Train_Acc: 83.765 Val_Loss: 0.3212  BEST VAL Loss: 0.3212  Val_Acc: 86.083

Epoch 81: Validation loss decreased (0.321217 --> 0.321079).  Saving model ...
	 Train_Loss: 0.3451 Train_Acc: 83.607 Val_Loss: 0.3211  BEST VAL Loss: 0.3211  Val_Acc: 86.211

Epoch 82: Validation loss decreased (0.321079 --> 0.320990).  Saving model ...
	 Train_Loss: 0.3449 Train_Acc: 83.756 Val_Loss: 0.3210  BEST VAL Loss: 0.3210  Val_Acc: 86.065

Epoch 83: Validation loss decreased (0.320990 --> 0.320865).  Saving model ...
	 Train_Loss: 0.3447 Train_Acc: 83.703 Val_Loss: 0.3209  BEST VAL Loss: 0.3209  Val_Acc: 86.031

Epoch 84: Validation loss decreased (0.320865 --> 0.320712).  Saving model ...
	 Train_Loss: 0.3445 Train_Acc: 83.879 Val_Loss: 0.3207  BEST VAL Loss: 0.3207  Val_Acc: 86.128

Epoch 85: Validation loss decreased (0.320712 --> 0.320574).  Saving model ...
	 Train_Loss: 0.3443 Train_Acc: 83.666 Val_Loss: 0.3206  BEST VAL Loss: 0.3206  Val_Acc: 86.100

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.3442 Train_Acc: 83.665 Val_Loss: 0.3206  BEST VAL Loss: 0.3206  Val_Acc: 85.964

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.3440 Train_Acc: 83.542 Val_Loss: 0.3206  BEST VAL Loss: 0.3206  Val_Acc: 85.773

Epoch 88: Validation loss decreased (0.320574 --> 0.320430).  Saving model ...
	 Train_Loss: 0.3439 Train_Acc: 83.673 Val_Loss: 0.3204  BEST VAL Loss: 0.3204  Val_Acc: 86.312

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.3437 Train_Acc: 83.583 Val_Loss: 0.3204  BEST VAL Loss: 0.3204  Val_Acc: 85.885

Epoch 90: Validation loss decreased (0.320430 --> 0.320343).  Saving model ...
	 Train_Loss: 0.3435 Train_Acc: 83.935 Val_Loss: 0.3203  BEST VAL Loss: 0.3203  Val_Acc: 86.493

Epoch 91: Validation loss decreased (0.320343 --> 0.320235).  Saving model ...
	 Train_Loss: 0.3434 Train_Acc: 83.780 Val_Loss: 0.3202  BEST VAL Loss: 0.3202  Val_Acc: 86.611

Epoch 92: Validation loss decreased (0.320235 --> 0.320119).  Saving model ...
	 Train_Loss: 0.3432 Train_Acc: 83.898 Val_Loss: 0.3201  BEST VAL Loss: 0.3201  Val_Acc: 86.260

Epoch 93: Validation loss decreased (0.320119 --> 0.320020).  Saving model ...
	 Train_Loss: 0.3430 Train_Acc: 83.899 Val_Loss: 0.3200  BEST VAL Loss: 0.3200  Val_Acc: 86.461

Epoch 94: Validation loss decreased (0.320020 --> 0.319983).  Saving model ...
	 Train_Loss: 0.3429 Train_Acc: 83.780 Val_Loss: 0.3200  BEST VAL Loss: 0.3200  Val_Acc: 86.454

Epoch 95: Validation loss decreased (0.319983 --> 0.319938).  Saving model ...
	 Train_Loss: 0.3427 Train_Acc: 83.744 Val_Loss: 0.3199  BEST VAL Loss: 0.3199  Val_Acc: 86.072

Epoch 96: Validation loss decreased (0.319938 --> 0.319804).  Saving model ...
	 Train_Loss: 0.3426 Train_Acc: 83.581 Val_Loss: 0.3198  BEST VAL Loss: 0.3198  Val_Acc: 86.194

Epoch 97: Validation loss decreased (0.319804 --> 0.319740).  Saving model ...
	 Train_Loss: 0.3425 Train_Acc: 83.778 Val_Loss: 0.3197  BEST VAL Loss: 0.3197  Val_Acc: 86.434

Epoch 98: Validation loss decreased (0.319740 --> 0.319716).  Saving model ...
	 Train_Loss: 0.3423 Train_Acc: 83.778 Val_Loss: 0.3197  BEST VAL Loss: 0.3197  Val_Acc: 86.017

Epoch 99: Validation loss decreased (0.319716 --> 0.319621).  Saving model ...
	 Train_Loss: 0.3422 Train_Acc: 83.797 Val_Loss: 0.3196  BEST VAL Loss: 0.3196  Val_Acc: 86.559

LPS_0.100_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.65      0.63      0.64    149884
           1       0.35      0.36      0.35     80324

    accuracy                           0.54    230208
   macro avg       0.50      0.50      0.50    230208
weighted avg       0.54      0.54      0.54    230208

LPS_0.100_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.65      0.64      0.65     18736
           1       0.35      0.37      0.36     10041

    accuracy                           0.54     28777
   macro avg       0.50      0.50      0.50     28777
weighted avg       0.55      0.54      0.55     28777

LPS_0.100_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.65      0.64      0.64     18736
           1       0.35      0.37      0.36     10041

    accuracy                           0.54     28777
   macro avg       0.50      0.50      0.50     28777
weighted avg       0.55      0.54      0.54     28777

              precision    recall  f1-score   support

           0       0.65      0.64      0.64     18736
           1       0.35      0.37      0.36     10041

    accuracy                           0.54     28777
   macro avg       0.50      0.50      0.50     28777
weighted avg       0.55      0.54      0.54     28777

LPS_0.100_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.42      0.55      0.48     27774
           1       0.58      0.44      0.50     38191

    accuracy                           0.49     65965
   macro avg       0.50      0.50      0.49     65965
weighted avg       0.51      0.49      0.49     65965

              precision    recall  f1-score   support

           0       0.42      0.55      0.48     27774
           1       0.58      0.44      0.50     38191

    accuracy                           0.49     65965
   macro avg       0.50      0.50      0.49     65965
weighted avg       0.51      0.49      0.49     65965

completed
