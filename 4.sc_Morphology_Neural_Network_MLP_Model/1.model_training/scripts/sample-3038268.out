[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'a2183d19'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '71b45e63'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'e254ac13'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '1906989e'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: H2O2_100.000_DMSO_0.025 treatment_name: LPS_10.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: LPS_10.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (43710, 1276)
Number of total missing values across all columns: 87420
Data Subset Is Off
Wells held out for testing: ['E21' 'H22']
Wells to use for training, validation, and testing ['E16' 'E17' 'H18' 'H19' 'E20' 'H23' 'I18' 'I19' 'I22' 'I23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.582598).  Saving model ...
	 Train_Loss: 0.6226 Train_Acc: 63.107 Val_Loss: 0.5826  BEST VAL Loss: 0.5826  Val_Acc: 67.845

Epoch 1: Validation loss decreased (0.582598 --> 0.565714).  Saving model ...
	 Train_Loss: 0.5970 Train_Acc: 68.731 Val_Loss: 0.5657  BEST VAL Loss: 0.5657  Val_Acc: 69.853

Epoch 2: Validation loss decreased (0.565714 --> 0.552861).  Saving model ...
	 Train_Loss: 0.5787 Train_Acc: 71.400 Val_Loss: 0.5529  BEST VAL Loss: 0.5529  Val_Acc: 71.719

Epoch 3: Validation loss decreased (0.552861 --> 0.542538).  Saving model ...
	 Train_Loss: 0.5645 Train_Acc: 72.850 Val_Loss: 0.5425  BEST VAL Loss: 0.5425  Val_Acc: 73.275

Epoch 4: Validation loss decreased (0.542538 --> 0.533600).  Saving model ...
	 Train_Loss: 0.5526 Train_Acc: 74.260 Val_Loss: 0.5336  BEST VAL Loss: 0.5336  Val_Acc: 74.067

Epoch 5: Validation loss decreased (0.533600 --> 0.525636).  Saving model ...
	 Train_Loss: 0.5422 Train_Acc: 75.010 Val_Loss: 0.5256  BEST VAL Loss: 0.5256  Val_Acc: 74.972

Epoch 6: Validation loss decreased (0.525636 --> 0.518088).  Saving model ...
	 Train_Loss: 0.5329 Train_Acc: 75.685 Val_Loss: 0.5181  BEST VAL Loss: 0.5181  Val_Acc: 75.594

Epoch 7: Validation loss decreased (0.518088 --> 0.511749).  Saving model ...
	 Train_Loss: 0.5248 Train_Acc: 76.639 Val_Loss: 0.5117  BEST VAL Loss: 0.5117  Val_Acc: 76.244

Epoch 8: Validation loss decreased (0.511749 --> 0.506318).  Saving model ...
	 Train_Loss: 0.5172 Train_Acc: 77.064 Val_Loss: 0.5063  BEST VAL Loss: 0.5063  Val_Acc: 76.329

Epoch 9: Validation loss decreased (0.506318 --> 0.501277).  Saving model ...
	 Train_Loss: 0.5104 Train_Acc: 77.576 Val_Loss: 0.5013  BEST VAL Loss: 0.5013  Val_Acc: 76.923

Epoch 10: Validation loss decreased (0.501277 --> 0.496726).  Saving model ...
	 Train_Loss: 0.5043 Train_Acc: 77.944 Val_Loss: 0.4967  BEST VAL Loss: 0.4967  Val_Acc: 77.489

Epoch 11: Validation loss decreased (0.496726 --> 0.492506).  Saving model ...
	 Train_Loss: 0.4985 Train_Acc: 78.075 Val_Loss: 0.4925  BEST VAL Loss: 0.4925  Val_Acc: 77.771

Epoch 12: Validation loss decreased (0.492506 --> 0.488170).  Saving model ...
	 Train_Loss: 0.4933 Train_Acc: 78.750 Val_Loss: 0.4882  BEST VAL Loss: 0.4882  Val_Acc: 78.507

Epoch 13: Validation loss decreased (0.488170 --> 0.484469).  Saving model ...
	 Train_Loss: 0.4883 Train_Acc: 79.160 Val_Loss: 0.4845  BEST VAL Loss: 0.4845  Val_Acc: 78.592

Epoch 14: Validation loss decreased (0.484469 --> 0.480853).  Saving model ...
	 Train_Loss: 0.4837 Train_Acc: 78.980 Val_Loss: 0.4809  BEST VAL Loss: 0.4809  Val_Acc: 78.903

Epoch 15: Validation loss decreased (0.480853 --> 0.477708).  Saving model ...
	 Train_Loss: 0.4793 Train_Acc: 79.991 Val_Loss: 0.4777  BEST VAL Loss: 0.4777  Val_Acc: 79.072

Epoch 16: Validation loss decreased (0.477708 --> 0.474611).  Saving model ...
	 Train_Loss: 0.4754 Train_Acc: 79.666 Val_Loss: 0.4746  BEST VAL Loss: 0.4746  Val_Acc: 79.299

Epoch 17: Validation loss decreased (0.474611 --> 0.471667).  Saving model ...
	 Train_Loss: 0.4716 Train_Acc: 80.206 Val_Loss: 0.4717  BEST VAL Loss: 0.4717  Val_Acc: 79.355

Epoch 18: Validation loss decreased (0.471667 --> 0.469217).  Saving model ...
	 Train_Loss: 0.4681 Train_Acc: 80.316 Val_Loss: 0.4692  BEST VAL Loss: 0.4692  Val_Acc: 79.186

Epoch 19: Validation loss decreased (0.469217 --> 0.467053).  Saving model ...
	 Train_Loss: 0.4647 Train_Acc: 80.426 Val_Loss: 0.4671  BEST VAL Loss: 0.4671  Val_Acc: 79.525

Epoch 20: Validation loss decreased (0.467053 --> 0.464762).  Saving model ...
	 Train_Loss: 0.4615 Train_Acc: 80.804 Val_Loss: 0.4648  BEST VAL Loss: 0.4648  Val_Acc: 79.836

Epoch 21: Validation loss decreased (0.464762 --> 0.462608).  Saving model ...
	 Train_Loss: 0.4585 Train_Acc: 80.836 Val_Loss: 0.4626  BEST VAL Loss: 0.4626  Val_Acc: 79.497

Epoch 22: Validation loss decreased (0.462608 --> 0.460749).  Saving model ...
	 Train_Loss: 0.4556 Train_Acc: 81.023 Val_Loss: 0.4607  BEST VAL Loss: 0.4607  Val_Acc: 79.751

Epoch 23: Validation loss decreased (0.460749 --> 0.458776).  Saving model ...
	 Train_Loss: 0.4528 Train_Acc: 81.306 Val_Loss: 0.4588  BEST VAL Loss: 0.4588  Val_Acc: 79.921

Epoch 24: Validation loss decreased (0.458776 --> 0.456971).  Saving model ...
	 Train_Loss: 0.4501 Train_Acc: 81.359 Val_Loss: 0.4570  BEST VAL Loss: 0.4570  Val_Acc: 79.638

Epoch 25: Validation loss decreased (0.456971 --> 0.455534).  Saving model ...
	 Train_Loss: 0.4476 Train_Acc: 81.666 Val_Loss: 0.4555  BEST VAL Loss: 0.4555  Val_Acc: 79.638

Epoch 26: Validation loss decreased (0.455534 --> 0.453943).  Saving model ...
	 Train_Loss: 0.4451 Train_Acc: 81.833 Val_Loss: 0.4539  BEST VAL Loss: 0.4539  Val_Acc: 80.175

Epoch 27: Validation loss decreased (0.453943 --> 0.452237).  Saving model ...
	 Train_Loss: 0.4427 Train_Acc: 81.893 Val_Loss: 0.4522  BEST VAL Loss: 0.4522  Val_Acc: 79.921

Epoch 28: Validation loss decreased (0.452237 --> 0.450782).  Saving model ...
	 Train_Loss: 0.4405 Train_Acc: 82.154 Val_Loss: 0.4508  BEST VAL Loss: 0.4508  Val_Acc: 79.949

Epoch 29: Validation loss decreased (0.450782 --> 0.449429).  Saving model ...
	 Train_Loss: 0.4383 Train_Acc: 82.409 Val_Loss: 0.4494  BEST VAL Loss: 0.4494  Val_Acc: 80.006

Epoch 30: Validation loss decreased (0.449429 --> 0.448091).  Saving model ...
	 Train_Loss: 0.4362 Train_Acc: 82.366 Val_Loss: 0.4481  BEST VAL Loss: 0.4481  Val_Acc: 80.175

Epoch 31: Validation loss decreased (0.448091 --> 0.446740).  Saving model ...
	 Train_Loss: 0.4341 Train_Acc: 82.632 Val_Loss: 0.4467  BEST VAL Loss: 0.4467  Val_Acc: 80.006

Epoch 32: Validation loss decreased (0.446740 --> 0.445448).  Saving model ...
	 Train_Loss: 0.4321 Train_Acc: 82.359 Val_Loss: 0.4454  BEST VAL Loss: 0.4454  Val_Acc: 80.260

Epoch 33: Validation loss decreased (0.445448 --> 0.444380).  Saving model ...
	 Train_Loss: 0.4302 Train_Acc: 82.759 Val_Loss: 0.4444  BEST VAL Loss: 0.4444  Val_Acc: 79.695

Epoch 34: Validation loss decreased (0.444380 --> 0.443170).  Saving model ...
	 Train_Loss: 0.4283 Train_Acc: 82.773 Val_Loss: 0.4432  BEST VAL Loss: 0.4432  Val_Acc: 80.571

Epoch 35: Validation loss decreased (0.443170 --> 0.442483).  Saving model ...
	 Train_Loss: 0.4266 Train_Acc: 82.819 Val_Loss: 0.4425  BEST VAL Loss: 0.4425  Val_Acc: 80.119

Epoch 36: Validation loss decreased (0.442483 --> 0.441490).  Saving model ...
	 Train_Loss: 0.4248 Train_Acc: 83.077 Val_Loss: 0.4415  BEST VAL Loss: 0.4415  Val_Acc: 80.430

Epoch 37: Validation loss decreased (0.441490 --> 0.440316).  Saving model ...
	 Train_Loss: 0.4230 Train_Acc: 82.936 Val_Loss: 0.4403  BEST VAL Loss: 0.4403  Val_Acc: 80.260

Epoch 38: Validation loss decreased (0.440316 --> 0.439411).  Saving model ...
	 Train_Loss: 0.4213 Train_Acc: 83.247 Val_Loss: 0.4394  BEST VAL Loss: 0.4394  Val_Acc: 80.288

Epoch 39: Validation loss decreased (0.439411 --> 0.438465).  Saving model ...
	 Train_Loss: 0.4197 Train_Acc: 83.169 Val_Loss: 0.4385  BEST VAL Loss: 0.4385  Val_Acc: 80.684

Epoch 40: Validation loss decreased (0.438465 --> 0.437608).  Saving model ...
	 Train_Loss: 0.4181 Train_Acc: 83.286 Val_Loss: 0.4376  BEST VAL Loss: 0.4376  Val_Acc: 80.458

Epoch 41: Validation loss decreased (0.437608 --> 0.436711).  Saving model ...
	 Train_Loss: 0.4165 Train_Acc: 83.385 Val_Loss: 0.4367  BEST VAL Loss: 0.4367  Val_Acc: 80.317

Epoch 42: Validation loss decreased (0.436711 --> 0.435759).  Saving model ...
	 Train_Loss: 0.4150 Train_Acc: 83.678 Val_Loss: 0.4358  BEST VAL Loss: 0.4358  Val_Acc: 80.656

Epoch 43: Validation loss decreased (0.435759 --> 0.434722).  Saving model ...
	 Train_Loss: 0.4135 Train_Acc: 83.618 Val_Loss: 0.4347  BEST VAL Loss: 0.4347  Val_Acc: 81.109

Epoch 44: Validation loss decreased (0.434722 --> 0.433914).  Saving model ...
	 Train_Loss: 0.4121 Train_Acc: 83.494 Val_Loss: 0.4339  BEST VAL Loss: 0.4339  Val_Acc: 80.090

Epoch 45: Validation loss decreased (0.433914 --> 0.433087).  Saving model ...
	 Train_Loss: 0.4107 Train_Acc: 83.887 Val_Loss: 0.4331  BEST VAL Loss: 0.4331  Val_Acc: 80.260

Epoch 46: Validation loss decreased (0.433087 --> 0.432381).  Saving model ...
	 Train_Loss: 0.4092 Train_Acc: 83.925 Val_Loss: 0.4324  BEST VAL Loss: 0.4324  Val_Acc: 80.430

Epoch 47: Validation loss decreased (0.432381 --> 0.431735).  Saving model ...
	 Train_Loss: 0.4079 Train_Acc: 83.763 Val_Loss: 0.4317  BEST VAL Loss: 0.4317  Val_Acc: 81.109

Epoch 48: Validation loss decreased (0.431735 --> 0.431087).  Saving model ...
	 Train_Loss: 0.4066 Train_Acc: 83.975 Val_Loss: 0.4311  BEST VAL Loss: 0.4311  Val_Acc: 81.137

Epoch 49: Validation loss decreased (0.431087 --> 0.430323).  Saving model ...
	 Train_Loss: 0.4053 Train_Acc: 84.120 Val_Loss: 0.4303  BEST VAL Loss: 0.4303  Val_Acc: 80.995

Epoch 50: Validation loss decreased (0.430323 --> 0.429691).  Saving model ...
	 Train_Loss: 0.4041 Train_Acc: 84.173 Val_Loss: 0.4297  BEST VAL Loss: 0.4297  Val_Acc: 80.798

Epoch 51: Validation loss decreased (0.429691 --> 0.429143).  Saving model ...
	 Train_Loss: 0.4028 Train_Acc: 84.622 Val_Loss: 0.4291  BEST VAL Loss: 0.4291  Val_Acc: 80.628

Epoch 52: Validation loss decreased (0.429143 --> 0.428564).  Saving model ...
	 Train_Loss: 0.4016 Train_Acc: 84.201 Val_Loss: 0.4286  BEST VAL Loss: 0.4286  Val_Acc: 80.656

Epoch 53: Validation loss decreased (0.428564 --> 0.427992).  Saving model ...
	 Train_Loss: 0.4004 Train_Acc: 84.495 Val_Loss: 0.4280  BEST VAL Loss: 0.4280  Val_Acc: 80.713

Epoch 54: Validation loss decreased (0.427992 --> 0.427450).  Saving model ...
	 Train_Loss: 0.3992 Train_Acc: 84.484 Val_Loss: 0.4275  BEST VAL Loss: 0.4275  Val_Acc: 80.854

Epoch 55: Validation loss decreased (0.427450 --> 0.426926).  Saving model ...
	 Train_Loss: 0.3980 Train_Acc: 84.516 Val_Loss: 0.4269  BEST VAL Loss: 0.4269  Val_Acc: 80.911

Epoch 56: Validation loss decreased (0.426926 --> 0.426416).  Saving model ...
	 Train_Loss: 0.3969 Train_Acc: 84.488 Val_Loss: 0.4264  BEST VAL Loss: 0.4264  Val_Acc: 81.165

Epoch 57: Validation loss decreased (0.426416 --> 0.425925).  Saving model ...
	 Train_Loss: 0.3958 Train_Acc: 84.618 Val_Loss: 0.4259  BEST VAL Loss: 0.4259  Val_Acc: 80.628

Epoch 58: Validation loss decreased (0.425925 --> 0.425360).  Saving model ...
	 Train_Loss: 0.3947 Train_Acc: 84.968 Val_Loss: 0.4254  BEST VAL Loss: 0.4254  Val_Acc: 80.769

Epoch 59: Validation loss decreased (0.425360 --> 0.424937).  Saving model ...
	 Train_Loss: 0.3936 Train_Acc: 84.777 Val_Loss: 0.4249  BEST VAL Loss: 0.4249  Val_Acc: 81.024

Epoch 60: Validation loss decreased (0.424937 --> 0.424488).  Saving model ...
	 Train_Loss: 0.3925 Train_Acc: 84.912 Val_Loss: 0.4245  BEST VAL Loss: 0.4245  Val_Acc: 80.571

Epoch 61: Validation loss decreased (0.424488 --> 0.424033).  Saving model ...
	 Train_Loss: 0.3915 Train_Acc: 84.951 Val_Loss: 0.4240  BEST VAL Loss: 0.4240  Val_Acc: 81.420

Epoch 62: Validation loss decreased (0.424033 --> 0.423656).  Saving model ...
	 Train_Loss: 0.3904 Train_Acc: 85.089 Val_Loss: 0.4237  BEST VAL Loss: 0.4237  Val_Acc: 81.193

Epoch 63: Validation loss decreased (0.423656 --> 0.423273).  Saving model ...
	 Train_Loss: 0.3894 Train_Acc: 85.127 Val_Loss: 0.4233  BEST VAL Loss: 0.4233  Val_Acc: 81.137

Epoch 64: Validation loss decreased (0.423273 --> 0.422869).  Saving model ...
	 Train_Loss: 0.3884 Train_Acc: 84.958 Val_Loss: 0.4229  BEST VAL Loss: 0.4229  Val_Acc: 81.476

Epoch 65: Validation loss decreased (0.422869 --> 0.422497).  Saving model ...
	 Train_Loss: 0.3874 Train_Acc: 85.375 Val_Loss: 0.4225  BEST VAL Loss: 0.4225  Val_Acc: 81.193

Epoch 66: Validation loss decreased (0.422497 --> 0.422109).  Saving model ...
	 Train_Loss: 0.3864 Train_Acc: 85.329 Val_Loss: 0.4221  BEST VAL Loss: 0.4221  Val_Acc: 81.929

Epoch 67: Validation loss decreased (0.422109 --> 0.421697).  Saving model ...
	 Train_Loss: 0.3854 Train_Acc: 85.329 Val_Loss: 0.4217  BEST VAL Loss: 0.4217  Val_Acc: 81.448

Epoch 68: Validation loss decreased (0.421697 --> 0.421353).  Saving model ...
	 Train_Loss: 0.3844 Train_Acc: 85.255 Val_Loss: 0.4214  BEST VAL Loss: 0.4214  Val_Acc: 81.533

Epoch 69: Validation loss decreased (0.421353 --> 0.420996).  Saving model ...
	 Train_Loss: 0.3835 Train_Acc: 85.435 Val_Loss: 0.4210  BEST VAL Loss: 0.4210  Val_Acc: 81.476

Epoch 70: Validation loss decreased (0.420996 --> 0.420691).  Saving model ...
	 Train_Loss: 0.3825 Train_Acc: 85.697 Val_Loss: 0.4207  BEST VAL Loss: 0.4207  Val_Acc: 81.618

Epoch 71: Validation loss decreased (0.420691 --> 0.420271).  Saving model ...
	 Train_Loss: 0.3816 Train_Acc: 85.612 Val_Loss: 0.4203  BEST VAL Loss: 0.4203  Val_Acc: 81.307

Epoch 72: Validation loss decreased (0.420271 --> 0.419908).  Saving model ...
	 Train_Loss: 0.3806 Train_Acc: 85.863 Val_Loss: 0.4199  BEST VAL Loss: 0.4199  Val_Acc: 81.335

Epoch 73: Validation loss decreased (0.419908 --> 0.419586).  Saving model ...
	 Train_Loss: 0.3797 Train_Acc: 86.174 Val_Loss: 0.4196  BEST VAL Loss: 0.4196  Val_Acc: 81.335

Epoch 74: Validation loss decreased (0.419586 --> 0.419253).  Saving model ...
	 Train_Loss: 0.3788 Train_Acc: 85.884 Val_Loss: 0.4193  BEST VAL Loss: 0.4193  Val_Acc: 81.533

Epoch 75: Validation loss decreased (0.419253 --> 0.418958).  Saving model ...
	 Train_Loss: 0.3779 Train_Acc: 85.856 Val_Loss: 0.4190  BEST VAL Loss: 0.4190  Val_Acc: 81.307

Epoch 76: Validation loss decreased (0.418958 --> 0.418765).  Saving model ...
	 Train_Loss: 0.3771 Train_Acc: 85.905 Val_Loss: 0.4188  BEST VAL Loss: 0.4188  Val_Acc: 81.420

Epoch 77: Validation loss decreased (0.418765 --> 0.418416).  Saving model ...
	 Train_Loss: 0.3762 Train_Acc: 85.845 Val_Loss: 0.4184  BEST VAL Loss: 0.4184  Val_Acc: 81.561

Epoch 78: Validation loss decreased (0.418416 --> 0.418098).  Saving model ...
	 Train_Loss: 0.3753 Train_Acc: 86.114 Val_Loss: 0.4181  BEST VAL Loss: 0.4181  Val_Acc: 81.222

Epoch 79: Validation loss decreased (0.418098 --> 0.417804).  Saving model ...
	 Train_Loss: 0.3745 Train_Acc: 86.181 Val_Loss: 0.4178  BEST VAL Loss: 0.4178  Val_Acc: 81.307

Epoch 80: Validation loss decreased (0.417804 --> 0.417507).  Saving model ...
	 Train_Loss: 0.3737 Train_Acc: 86.117 Val_Loss: 0.4175  BEST VAL Loss: 0.4175  Val_Acc: 81.109

Epoch 81: Validation loss decreased (0.417507 --> 0.417259).  Saving model ...
	 Train_Loss: 0.3729 Train_Acc: 86.308 Val_Loss: 0.4173  BEST VAL Loss: 0.4173  Val_Acc: 81.505

Epoch 82: Validation loss decreased (0.417259 --> 0.417013).  Saving model ...
	 Train_Loss: 0.3721 Train_Acc: 86.227 Val_Loss: 0.4170  BEST VAL Loss: 0.4170  Val_Acc: 81.363

Epoch 83: Validation loss decreased (0.417013 --> 0.416699).  Saving model ...
	 Train_Loss: 0.3713 Train_Acc: 86.209 Val_Loss: 0.4167  BEST VAL Loss: 0.4167  Val_Acc: 81.702

Epoch 84: Validation loss decreased (0.416699 --> 0.416517).  Saving model ...
	 Train_Loss: 0.3705 Train_Acc: 86.425 Val_Loss: 0.4165  BEST VAL Loss: 0.4165  Val_Acc: 81.589

Epoch 85: Validation loss decreased (0.416517 --> 0.416361).  Saving model ...
	 Train_Loss: 0.3697 Train_Acc: 86.259 Val_Loss: 0.4164  BEST VAL Loss: 0.4164  Val_Acc: 80.939

Epoch 86: Validation loss decreased (0.416361 --> 0.416196).  Saving model ...
	 Train_Loss: 0.3689 Train_Acc: 86.329 Val_Loss: 0.4162  BEST VAL Loss: 0.4162  Val_Acc: 81.335

Epoch 87: Validation loss decreased (0.416196 --> 0.415989).  Saving model ...
	 Train_Loss: 0.3681 Train_Acc: 86.595 Val_Loss: 0.4160  BEST VAL Loss: 0.4160  Val_Acc: 81.985

Epoch 88: Validation loss decreased (0.415989 --> 0.415776).  Saving model ...
	 Train_Loss: 0.3674 Train_Acc: 86.471 Val_Loss: 0.4158  BEST VAL Loss: 0.4158  Val_Acc: 81.193

Epoch 89: Validation loss decreased (0.415776 --> 0.415554).  Saving model ...
	 Train_Loss: 0.3666 Train_Acc: 86.591 Val_Loss: 0.4156  BEST VAL Loss: 0.4156  Val_Acc: 81.618

Epoch 90: Validation loss decreased (0.415554 --> 0.415342).  Saving model ...
	 Train_Loss: 0.3659 Train_Acc: 86.616 Val_Loss: 0.4153  BEST VAL Loss: 0.4153  Val_Acc: 81.335

Epoch 91: Validation loss decreased (0.415342 --> 0.415201).  Saving model ...
	 Train_Loss: 0.3651 Train_Acc: 86.595 Val_Loss: 0.4152  BEST VAL Loss: 0.4152  Val_Acc: 81.024

Epoch 92: Validation loss decreased (0.415201 --> 0.414970).  Saving model ...
	 Train_Loss: 0.3644 Train_Acc: 86.793 Val_Loss: 0.4150  BEST VAL Loss: 0.4150  Val_Acc: 81.646

Epoch 93: Validation loss decreased (0.414970 --> 0.414793).  Saving model ...
	 Train_Loss: 0.3637 Train_Acc: 86.725 Val_Loss: 0.4148  BEST VAL Loss: 0.4148  Val_Acc: 81.505

Epoch 94: Validation loss decreased (0.414793 --> 0.414682).  Saving model ...
	 Train_Loss: 0.3629 Train_Acc: 87.167 Val_Loss: 0.4147  BEST VAL Loss: 0.4147  Val_Acc: 81.702

Epoch 95: Validation loss decreased (0.414682 --> 0.414499).  Saving model ...
	 Train_Loss: 0.3622 Train_Acc: 86.612 Val_Loss: 0.4145  BEST VAL Loss: 0.4145  Val_Acc: 81.391

Epoch 96: Validation loss decreased (0.414499 --> 0.414264).  Saving model ...
	 Train_Loss: 0.3615 Train_Acc: 86.800 Val_Loss: 0.4143  BEST VAL Loss: 0.4143  Val_Acc: 81.420

Epoch 97: Validation loss decreased (0.414264 --> 0.414261).  Saving model ...
	 Train_Loss: 0.3608 Train_Acc: 86.930 Val_Loss: 0.4143  BEST VAL Loss: 0.4143  Val_Acc: 81.165

Epoch 98: Validation loss decreased (0.414261 --> 0.414164).  Saving model ...
	 Train_Loss: 0.3601 Train_Acc: 86.937 Val_Loss: 0.4142  BEST VAL Loss: 0.4142  Val_Acc: 81.533

Epoch 99: Validation loss decreased (0.414164 --> 0.414091).  Saving model ...
	 Train_Loss: 0.3594 Train_Acc: 87.022 Val_Loss: 0.4141  BEST VAL Loss: 0.4141  Val_Acc: 81.278

H2O2_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.64      0.64      0.64     18174
           1       0.35      0.35      0.35     10113

    accuracy                           0.54     28287
   macro avg       0.49      0.49      0.49     28287
weighted avg       0.54      0.54      0.54     28287

H2O2_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.63      0.65      0.64      2272
           1       0.34      0.33      0.33      1264

    accuracy                           0.53      3536
   macro avg       0.49      0.49      0.49      3536
weighted avg       0.53      0.53      0.53      3536

H2O2_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.63      0.64      0.64      2272
           1       0.34      0.33      0.34      1265

    accuracy                           0.53      3537
   macro avg       0.49      0.49      0.49      3537
weighted avg       0.53      0.53      0.53      3537

              precision    recall  f1-score   support

           0       0.63      0.64      0.64      2272
           1       0.34      0.33      0.34      1265

    accuracy                           0.53      3537
   macro avg       0.49      0.49      0.49      3537
weighted avg       0.53      0.53      0.53      3537

H2O2_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.55      0.52      4182
           1       0.50      0.45      0.47      4168

    accuracy                           0.50      8350
   macro avg       0.50      0.50      0.50      8350
weighted avg       0.50      0.50      0.50      8350

              precision    recall  f1-score   support

           0       0.50      0.55      0.52      4182
           1       0.50      0.45      0.47      4168

    accuracy                           0.50      8350
   macro avg       0.50      0.50      0.50      8350
weighted avg       0.50      0.50      0.50      8350

completed
