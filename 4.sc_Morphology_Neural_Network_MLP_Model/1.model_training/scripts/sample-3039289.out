[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '7a316c33'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '67f47800'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '6b277b45'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'daf4a7e8'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Flagellin_1.000_DMSO_0.025 treatment_name: H2O2_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Flagellin_1.000_DMSO_0.025
TREATMENT_NAME: H2O2_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['H2O2_100.000_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (345083, 1270)
Number of total missing values across all columns: 726782
Data Subset Is Off
Wells held out for testing: ['I05' 'M10']
Wells to use for training, validation, and testing ['H04' 'I04' 'H05' 'H10' 'I10' 'H11' 'I11' 'M05' 'M11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.403977).  Saving model ...
	 Train_Loss: 0.4930 Train_Acc: 76.337 Val_Loss: 0.4040  BEST VAL Loss: 0.4040  Val_Acc: 80.471

Epoch 1: Validation loss decreased (0.403977 --> 0.371977).  Saving model ...
	 Train_Loss: 0.4395 Train_Acc: 82.473 Val_Loss: 0.3720  BEST VAL Loss: 0.3720  Val_Acc: 85.644

Epoch 2: Validation loss decreased (0.371977 --> 0.355060).  Saving model ...
	 Train_Loss: 0.4075 Train_Acc: 84.624 Val_Loss: 0.3551  BEST VAL Loss: 0.3551  Val_Acc: 85.641

Epoch 3: Validation loss decreased (0.355060 --> 0.338051).  Saving model ...
	 Train_Loss: 0.3857 Train_Acc: 85.689 Val_Loss: 0.3381  BEST VAL Loss: 0.3381  Val_Acc: 87.799

Epoch 4: Validation loss decreased (0.338051 --> 0.325495).  Saving model ...
	 Train_Loss: 0.3697 Train_Acc: 86.475 Val_Loss: 0.3255  BEST VAL Loss: 0.3255  Val_Acc: 88.373

Epoch 5: Validation loss decreased (0.325495 --> 0.315619).  Saving model ...
	 Train_Loss: 0.3572 Train_Acc: 86.989 Val_Loss: 0.3156  BEST VAL Loss: 0.3156  Val_Acc: 88.684

Epoch 6: Validation loss decreased (0.315619 --> 0.308165).  Saving model ...
	 Train_Loss: 0.3471 Train_Acc: 87.442 Val_Loss: 0.3082  BEST VAL Loss: 0.3082  Val_Acc: 88.687

Epoch 7: Validation loss decreased (0.308165 --> 0.301341).  Saving model ...
	 Train_Loss: 0.3387 Train_Acc: 87.679 Val_Loss: 0.3013  BEST VAL Loss: 0.3013  Val_Acc: 89.189

Epoch 8: Validation loss decreased (0.301341 --> 0.295385).  Saving model ...
	 Train_Loss: 0.3315 Train_Acc: 87.905 Val_Loss: 0.2954  BEST VAL Loss: 0.2954  Val_Acc: 89.496

Epoch 9: Validation loss decreased (0.295385 --> 0.291215).  Saving model ...
	 Train_Loss: 0.3254 Train_Acc: 88.019 Val_Loss: 0.2912  BEST VAL Loss: 0.2912  Val_Acc: 89.297

Epoch 10: Validation loss decreased (0.291215 --> 0.286793).  Saving model ...
	 Train_Loss: 0.3200 Train_Acc: 88.238 Val_Loss: 0.2868  BEST VAL Loss: 0.2868  Val_Acc: 89.813

Epoch 11: Validation loss decreased (0.286793 --> 0.282711).  Saving model ...
	 Train_Loss: 0.3151 Train_Acc: 88.365 Val_Loss: 0.2827  BEST VAL Loss: 0.2827  Val_Acc: 89.889

Epoch 12: Validation loss decreased (0.282711 --> 0.279801).  Saving model ...
	 Train_Loss: 0.3108 Train_Acc: 88.388 Val_Loss: 0.2798  BEST VAL Loss: 0.2798  Val_Acc: 89.871

Epoch 13: Validation loss decreased (0.279801 --> 0.276490).  Saving model ...
	 Train_Loss: 0.3069 Train_Acc: 88.498 Val_Loss: 0.2765  BEST VAL Loss: 0.2765  Val_Acc: 90.149

Epoch 14: Validation loss decreased (0.276490 --> 0.273818).  Saving model ...
	 Train_Loss: 0.3034 Train_Acc: 88.658 Val_Loss: 0.2738  BEST VAL Loss: 0.2738  Val_Acc: 90.275

Epoch 15: Validation loss decreased (0.273818 --> 0.271205).  Saving model ...
	 Train_Loss: 0.3001 Train_Acc: 88.639 Val_Loss: 0.2712  BEST VAL Loss: 0.2712  Val_Acc: 90.387

Epoch 16: Validation loss decreased (0.271205 --> 0.268617).  Saving model ...
	 Train_Loss: 0.2971 Train_Acc: 88.701 Val_Loss: 0.2686  BEST VAL Loss: 0.2686  Val_Acc: 90.600

Epoch 17: Validation loss decreased (0.268617 --> 0.266707).  Saving model ...
	 Train_Loss: 0.2943 Train_Acc: 88.796 Val_Loss: 0.2667  BEST VAL Loss: 0.2667  Val_Acc: 90.293

Epoch 18: Validation loss decreased (0.266707 --> 0.264894).  Saving model ...
	 Train_Loss: 0.2918 Train_Acc: 89.086 Val_Loss: 0.2649  BEST VAL Loss: 0.2649  Val_Acc: 90.279

Epoch 19: Validation loss decreased (0.264894 --> 0.263001).  Saving model ...
	 Train_Loss: 0.2894 Train_Acc: 89.109 Val_Loss: 0.2630  BEST VAL Loss: 0.2630  Val_Acc: 90.550

Epoch 20: Validation loss decreased (0.263001 --> 0.261220).  Saving model ...
	 Train_Loss: 0.2872 Train_Acc: 89.178 Val_Loss: 0.2612  BEST VAL Loss: 0.2612  Val_Acc: 90.474

Epoch 21: Validation loss decreased (0.261220 --> 0.259480).  Saving model ...
	 Train_Loss: 0.2851 Train_Acc: 89.349 Val_Loss: 0.2595  BEST VAL Loss: 0.2595  Val_Acc: 90.622

Epoch 22: Validation loss decreased (0.259480 --> 0.257870).  Saving model ...
	 Train_Loss: 0.2832 Train_Acc: 89.351 Val_Loss: 0.2579  BEST VAL Loss: 0.2579  Val_Acc: 90.481

Epoch 23: Validation loss decreased (0.257870 --> 0.256354).  Saving model ...
	 Train_Loss: 0.2814 Train_Acc: 89.414 Val_Loss: 0.2564  BEST VAL Loss: 0.2564  Val_Acc: 90.586

Epoch 24: Validation loss decreased (0.256354 --> 0.255221).  Saving model ...
	 Train_Loss: 0.2797 Train_Acc: 89.385 Val_Loss: 0.2552  BEST VAL Loss: 0.2552  Val_Acc: 90.514

Epoch 25: Validation loss decreased (0.255221 --> 0.253858).  Saving model ...
	 Train_Loss: 0.2780 Train_Acc: 89.479 Val_Loss: 0.2539  BEST VAL Loss: 0.2539  Val_Acc: 90.788

Epoch 26: Validation loss decreased (0.253858 --> 0.252561).  Saving model ...
	 Train_Loss: 0.2764 Train_Acc: 89.550 Val_Loss: 0.2526  BEST VAL Loss: 0.2526  Val_Acc: 90.777

Epoch 27: Validation loss decreased (0.252561 --> 0.251475).  Saving model ...
	 Train_Loss: 0.2749 Train_Acc: 89.576 Val_Loss: 0.2515  BEST VAL Loss: 0.2515  Val_Acc: 90.795

Epoch 28: Validation loss decreased (0.251475 --> 0.250425).  Saving model ...
	 Train_Loss: 0.2735 Train_Acc: 89.668 Val_Loss: 0.2504  BEST VAL Loss: 0.2504  Val_Acc: 90.647

Epoch 29: Validation loss decreased (0.250425 --> 0.249360).  Saving model ...
	 Train_Loss: 0.2722 Train_Acc: 89.618 Val_Loss: 0.2494  BEST VAL Loss: 0.2494  Val_Acc: 90.849

Epoch 30: Validation loss decreased (0.249360 --> 0.248346).  Saving model ...
	 Train_Loss: 0.2709 Train_Acc: 89.676 Val_Loss: 0.2483  BEST VAL Loss: 0.2483  Val_Acc: 90.784

Epoch 31: Validation loss decreased (0.248346 --> 0.247332).  Saving model ...
	 Train_Loss: 0.2697 Train_Acc: 89.730 Val_Loss: 0.2473  BEST VAL Loss: 0.2473  Val_Acc: 90.875

Epoch 32: Validation loss decreased (0.247332 --> 0.246408).  Saving model ...
	 Train_Loss: 0.2685 Train_Acc: 89.719 Val_Loss: 0.2464  BEST VAL Loss: 0.2464  Val_Acc: 90.965

Epoch 33: Validation loss decreased (0.246408 --> 0.245525).  Saving model ...
	 Train_Loss: 0.2673 Train_Acc: 89.826 Val_Loss: 0.2455  BEST VAL Loss: 0.2455  Val_Acc: 91.044

Epoch 34: Validation loss decreased (0.245525 --> 0.244681).  Saving model ...
	 Train_Loss: 0.2662 Train_Acc: 89.766 Val_Loss: 0.2447  BEST VAL Loss: 0.2447  Val_Acc: 91.001

Epoch 35: Validation loss decreased (0.244681 --> 0.243947).  Saving model ...
	 Train_Loss: 0.2652 Train_Acc: 89.768 Val_Loss: 0.2439  BEST VAL Loss: 0.2439  Val_Acc: 90.976

Epoch 36: Validation loss decreased (0.243947 --> 0.243195).  Saving model ...
	 Train_Loss: 0.2642 Train_Acc: 89.859 Val_Loss: 0.2432  BEST VAL Loss: 0.2432  Val_Acc: 91.037

Epoch 37: Validation loss decreased (0.243195 --> 0.242591).  Saving model ...
	 Train_Loss: 0.2633 Train_Acc: 89.821 Val_Loss: 0.2426  BEST VAL Loss: 0.2426  Val_Acc: 90.716

Epoch 38: Validation loss decreased (0.242591 --> 0.241831).  Saving model ...
	 Train_Loss: 0.2623 Train_Acc: 89.998 Val_Loss: 0.2418  BEST VAL Loss: 0.2418  Val_Acc: 91.181

Epoch 39: Validation loss decreased (0.241831 --> 0.241111).  Saving model ...
	 Train_Loss: 0.2614 Train_Acc: 89.900 Val_Loss: 0.2411  BEST VAL Loss: 0.2411  Val_Acc: 91.207

Epoch 40: Validation loss decreased (0.241111 --> 0.240423).  Saving model ...
	 Train_Loss: 0.2606 Train_Acc: 89.941 Val_Loss: 0.2404  BEST VAL Loss: 0.2404  Val_Acc: 91.131

Epoch 41: Validation loss decreased (0.240423 --> 0.239797).  Saving model ...
	 Train_Loss: 0.2597 Train_Acc: 90.002 Val_Loss: 0.2398  BEST VAL Loss: 0.2398  Val_Acc: 91.163

Epoch 42: Validation loss decreased (0.239797 --> 0.239342).  Saving model ...
	 Train_Loss: 0.2590 Train_Acc: 89.952 Val_Loss: 0.2393  BEST VAL Loss: 0.2393  Val_Acc: 90.839

Epoch 43: Validation loss decreased (0.239342 --> 0.238738).  Saving model ...
	 Train_Loss: 0.2582 Train_Acc: 90.022 Val_Loss: 0.2387  BEST VAL Loss: 0.2387  Val_Acc: 91.225

Epoch 44: Validation loss decreased (0.238738 --> 0.238254).  Saving model ...
	 Train_Loss: 0.2574 Train_Acc: 89.996 Val_Loss: 0.2383  BEST VAL Loss: 0.2383  Val_Acc: 91.077

Epoch 45: Validation loss decreased (0.238254 --> 0.237757).  Saving model ...
	 Train_Loss: 0.2567 Train_Acc: 89.997 Val_Loss: 0.2378  BEST VAL Loss: 0.2378  Val_Acc: 91.124

Epoch 46: Validation loss decreased (0.237757 --> 0.237194).  Saving model ...
	 Train_Loss: 0.2560 Train_Acc: 90.058 Val_Loss: 0.2372  BEST VAL Loss: 0.2372  Val_Acc: 91.272

Epoch 47: Validation loss decreased (0.237194 --> 0.236684).  Saving model ...
	 Train_Loss: 0.2553 Train_Acc: 90.049 Val_Loss: 0.2367  BEST VAL Loss: 0.2367  Val_Acc: 91.044

Epoch 48: Validation loss decreased (0.236684 --> 0.236146).  Saving model ...
	 Train_Loss: 0.2546 Train_Acc: 90.061 Val_Loss: 0.2361  BEST VAL Loss: 0.2361  Val_Acc: 91.358

Epoch 49: Validation loss decreased (0.236146 --> 0.235704).  Saving model ...
	 Train_Loss: 0.2540 Train_Acc: 90.085 Val_Loss: 0.2357  BEST VAL Loss: 0.2357  Val_Acc: 90.958

Epoch 50: Validation loss decreased (0.235704 --> 0.235263).  Saving model ...
	 Train_Loss: 0.2534 Train_Acc: 90.090 Val_Loss: 0.2353  BEST VAL Loss: 0.2353  Val_Acc: 91.167

Epoch 51: Validation loss decreased (0.235263 --> 0.234886).  Saving model ...
	 Train_Loss: 0.2528 Train_Acc: 90.056 Val_Loss: 0.2349  BEST VAL Loss: 0.2349  Val_Acc: 91.138

Epoch 52: Validation loss decreased (0.234886 --> 0.234533).  Saving model ...
	 Train_Loss: 0.2522 Train_Acc: 90.198 Val_Loss: 0.2345  BEST VAL Loss: 0.2345  Val_Acc: 90.795

Epoch 53: Validation loss decreased (0.234533 --> 0.234149).  Saving model ...
	 Train_Loss: 0.2516 Train_Acc: 90.104 Val_Loss: 0.2341  BEST VAL Loss: 0.2341  Val_Acc: 91.008

Epoch 54: Validation loss decreased (0.234149 --> 0.233739).  Saving model ...
	 Train_Loss: 0.2510 Train_Acc: 90.189 Val_Loss: 0.2337  BEST VAL Loss: 0.2337  Val_Acc: 91.308

Epoch 55: Validation loss decreased (0.233739 --> 0.233304).  Saving model ...
	 Train_Loss: 0.2505 Train_Acc: 90.150 Val_Loss: 0.2333  BEST VAL Loss: 0.2333  Val_Acc: 91.412

Epoch 56: Validation loss decreased (0.233304 --> 0.232871).  Saving model ...
	 Train_Loss: 0.2500 Train_Acc: 90.240 Val_Loss: 0.2329  BEST VAL Loss: 0.2329  Val_Acc: 91.456

Epoch 57: Validation loss decreased (0.232871 --> 0.232497).  Saving model ...
	 Train_Loss: 0.2494 Train_Acc: 90.280 Val_Loss: 0.2325  BEST VAL Loss: 0.2325  Val_Acc: 91.203

Epoch 58: Validation loss decreased (0.232497 --> 0.232126).  Saving model ...
	 Train_Loss: 0.2489 Train_Acc: 90.207 Val_Loss: 0.2321  BEST VAL Loss: 0.2321  Val_Acc: 91.196

Epoch 59: Validation loss decreased (0.232126 --> 0.231764).  Saving model ...
	 Train_Loss: 0.2484 Train_Acc: 90.262 Val_Loss: 0.2318  BEST VAL Loss: 0.2318  Val_Acc: 91.297

Epoch 60: Validation loss decreased (0.231764 --> 0.231386).  Saving model ...
	 Train_Loss: 0.2479 Train_Acc: 90.222 Val_Loss: 0.2314  BEST VAL Loss: 0.2314  Val_Acc: 91.355

Epoch 61: Validation loss decreased (0.231386 --> 0.231003).  Saving model ...
	 Train_Loss: 0.2475 Train_Acc: 90.177 Val_Loss: 0.2310  BEST VAL Loss: 0.2310  Val_Acc: 91.337

Epoch 62: Validation loss decreased (0.231003 --> 0.230680).  Saving model ...
	 Train_Loss: 0.2470 Train_Acc: 90.220 Val_Loss: 0.2307  BEST VAL Loss: 0.2307  Val_Acc: 91.441

Epoch 63: Validation loss decreased (0.230680 --> 0.230416).  Saving model ...
	 Train_Loss: 0.2466 Train_Acc: 90.266 Val_Loss: 0.2304  BEST VAL Loss: 0.2304  Val_Acc: 91.279

Epoch 64: Validation loss decreased (0.230416 --> 0.230077).  Saving model ...
	 Train_Loss: 0.2461 Train_Acc: 90.196 Val_Loss: 0.2301  BEST VAL Loss: 0.2301  Val_Acc: 91.391

Epoch 65: Validation loss decreased (0.230077 --> 0.229775).  Saving model ...
	 Train_Loss: 0.2457 Train_Acc: 90.241 Val_Loss: 0.2298  BEST VAL Loss: 0.2298  Val_Acc: 91.279

Epoch 66: Validation loss decreased (0.229775 --> 0.229470).  Saving model ...
	 Train_Loss: 0.2453 Train_Acc: 90.286 Val_Loss: 0.2295  BEST VAL Loss: 0.2295  Val_Acc: 91.452

Epoch 67: Validation loss decreased (0.229470 --> 0.229173).  Saving model ...
	 Train_Loss: 0.2449 Train_Acc: 90.364 Val_Loss: 0.2292  BEST VAL Loss: 0.2292  Val_Acc: 91.308

Epoch 68: Validation loss decreased (0.229173 --> 0.228905).  Saving model ...
	 Train_Loss: 0.2445 Train_Acc: 90.246 Val_Loss: 0.2289  BEST VAL Loss: 0.2289  Val_Acc: 91.477

Epoch 69: Validation loss decreased (0.228905 --> 0.228668).  Saving model ...
	 Train_Loss: 0.2441 Train_Acc: 90.314 Val_Loss: 0.2287  BEST VAL Loss: 0.2287  Val_Acc: 91.218

Epoch 70: Validation loss decreased (0.228668 --> 0.228409).  Saving model ...
	 Train_Loss: 0.2437 Train_Acc: 90.343 Val_Loss: 0.2284  BEST VAL Loss: 0.2284  Val_Acc: 91.445

Epoch 71: Validation loss decreased (0.228409 --> 0.228145).  Saving model ...
	 Train_Loss: 0.2433 Train_Acc: 90.322 Val_Loss: 0.2281  BEST VAL Loss: 0.2281  Val_Acc: 91.456

Epoch 72: Validation loss decreased (0.228145 --> 0.227872).  Saving model ...
	 Train_Loss: 0.2429 Train_Acc: 90.331 Val_Loss: 0.2279  BEST VAL Loss: 0.2279  Val_Acc: 91.532

Epoch 73: Validation loss decreased (0.227872 --> 0.227610).  Saving model ...
	 Train_Loss: 0.2425 Train_Acc: 90.341 Val_Loss: 0.2276  BEST VAL Loss: 0.2276  Val_Acc: 91.319

Epoch 74: Validation loss decreased (0.227610 --> 0.227408).  Saving model ...
	 Train_Loss: 0.2422 Train_Acc: 90.320 Val_Loss: 0.2274  BEST VAL Loss: 0.2274  Val_Acc: 91.174

Epoch 75: Validation loss decreased (0.227408 --> 0.227152).  Saving model ...
	 Train_Loss: 0.2419 Train_Acc: 90.359 Val_Loss: 0.2272  BEST VAL Loss: 0.2272  Val_Acc: 91.496

Epoch 76: Validation loss decreased (0.227152 --> 0.226945).  Saving model ...
	 Train_Loss: 0.2415 Train_Acc: 90.367 Val_Loss: 0.2269  BEST VAL Loss: 0.2269  Val_Acc: 91.521

Epoch 77: Validation loss decreased (0.226945 --> 0.226727).  Saving model ...
	 Train_Loss: 0.2412 Train_Acc: 90.358 Val_Loss: 0.2267  BEST VAL Loss: 0.2267  Val_Acc: 91.394

Epoch 78: Validation loss decreased (0.226727 --> 0.226509).  Saving model ...
	 Train_Loss: 0.2408 Train_Acc: 90.427 Val_Loss: 0.2265  BEST VAL Loss: 0.2265  Val_Acc: 91.416

Epoch 79: Validation loss decreased (0.226509 --> 0.226310).  Saving model ...
	 Train_Loss: 0.2405 Train_Acc: 90.421 Val_Loss: 0.2263  BEST VAL Loss: 0.2263  Val_Acc: 91.506

Epoch 80: Validation loss decreased (0.226310 --> 0.226099).  Saving model ...
	 Train_Loss: 0.2402 Train_Acc: 90.441 Val_Loss: 0.2261  BEST VAL Loss: 0.2261  Val_Acc: 91.600

Epoch 81: Validation loss decreased (0.226099 --> 0.225940).  Saving model ...
	 Train_Loss: 0.2399 Train_Acc: 90.349 Val_Loss: 0.2259  BEST VAL Loss: 0.2259  Val_Acc: 91.163

Epoch 82: Validation loss decreased (0.225940 --> 0.225727).  Saving model ...
	 Train_Loss: 0.2396 Train_Acc: 90.466 Val_Loss: 0.2257  BEST VAL Loss: 0.2257  Val_Acc: 91.420

Epoch 83: Validation loss decreased (0.225727 --> 0.225497).  Saving model ...
	 Train_Loss: 0.2393 Train_Acc: 90.406 Val_Loss: 0.2255  BEST VAL Loss: 0.2255  Val_Acc: 91.510

Epoch 84: Validation loss decreased (0.225497 --> 0.225291).  Saving model ...
	 Train_Loss: 0.2389 Train_Acc: 90.501 Val_Loss: 0.2253  BEST VAL Loss: 0.2253  Val_Acc: 91.506

Epoch 85: Validation loss decreased (0.225291 --> 0.225108).  Saving model ...
	 Train_Loss: 0.2387 Train_Acc: 90.445 Val_Loss: 0.2251  BEST VAL Loss: 0.2251  Val_Acc: 91.384

Epoch 86: Validation loss decreased (0.225108 --> 0.224925).  Saving model ...
	 Train_Loss: 0.2384 Train_Acc: 90.437 Val_Loss: 0.2249  BEST VAL Loss: 0.2249  Val_Acc: 91.459

Epoch 87: Validation loss decreased (0.224925 --> 0.224725).  Saving model ...
	 Train_Loss: 0.2381 Train_Acc: 90.548 Val_Loss: 0.2247  BEST VAL Loss: 0.2247  Val_Acc: 91.611

Epoch 88: Validation loss decreased (0.224725 --> 0.224536).  Saving model ...
	 Train_Loss: 0.2378 Train_Acc: 90.487 Val_Loss: 0.2245  BEST VAL Loss: 0.2245  Val_Acc: 91.593

Epoch 89: Validation loss decreased (0.224536 --> 0.224327).  Saving model ...
	 Train_Loss: 0.2375 Train_Acc: 90.463 Val_Loss: 0.2243  BEST VAL Loss: 0.2243  Val_Acc: 91.532

Epoch 90: Validation loss decreased (0.224327 --> 0.224141).  Saving model ...
	 Train_Loss: 0.2373 Train_Acc: 90.414 Val_Loss: 0.2241  BEST VAL Loss: 0.2241  Val_Acc: 91.600

Epoch 91: Validation loss decreased (0.224141 --> 0.223951).  Saving model ...
	 Train_Loss: 0.2370 Train_Acc: 90.450 Val_Loss: 0.2240  BEST VAL Loss: 0.2240  Val_Acc: 91.362

Epoch 92: Validation loss decreased (0.223951 --> 0.223778).  Saving model ...
	 Train_Loss: 0.2367 Train_Acc: 90.489 Val_Loss: 0.2238  BEST VAL Loss: 0.2238  Val_Acc: 91.571

Epoch 93: Validation loss decreased (0.223778 --> 0.223613).  Saving model ...
	 Train_Loss: 0.2365 Train_Acc: 90.470 Val_Loss: 0.2236  BEST VAL Loss: 0.2236  Val_Acc: 91.264

Epoch 94: Validation loss decreased (0.223613 --> 0.223427).  Saving model ...
	 Train_Loss: 0.2362 Train_Acc: 90.491 Val_Loss: 0.2234  BEST VAL Loss: 0.2234  Val_Acc: 91.535

Epoch 95: Validation loss decreased (0.223427 --> 0.223255).  Saving model ...
	 Train_Loss: 0.2359 Train_Acc: 90.539 Val_Loss: 0.2233  BEST VAL Loss: 0.2233  Val_Acc: 91.510

Epoch 96: Validation loss decreased (0.223255 --> 0.223080).  Saving model ...
	 Train_Loss: 0.2357 Train_Acc: 90.482 Val_Loss: 0.2231  BEST VAL Loss: 0.2231  Val_Acc: 91.607

Epoch 97: Validation loss decreased (0.223080 --> 0.222948).  Saving model ...
	 Train_Loss: 0.2354 Train_Acc: 90.502 Val_Loss: 0.2229  BEST VAL Loss: 0.2229  Val_Acc: 91.340

Epoch 98: Validation loss decreased (0.222948 --> 0.222808).  Saving model ...
	 Train_Loss: 0.2352 Train_Acc: 90.497 Val_Loss: 0.2228  BEST VAL Loss: 0.2228  Val_Acc: 91.524

Epoch 99: Validation loss decreased (0.222808 --> 0.222657).  Saving model ...
	 Train_Loss: 0.2350 Train_Acc: 90.542 Val_Loss: 0.2227  BEST VAL Loss: 0.2227  Val_Acc: 91.579

Flagellin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.25      0.24      0.25     56123
           1       0.75      0.75      0.75    165500

    accuracy                           0.62    221623
   macro avg       0.50      0.50      0.50    221623
weighted avg       0.62      0.62      0.62    221623

Flagellin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.25      0.24      0.25      7015
           1       0.75      0.76      0.75     20688

    accuracy                           0.63     27703
   macro avg       0.50      0.50      0.50     27703
weighted avg       0.62      0.63      0.62     27703

Flagellin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.26      0.25      0.25      7015
           1       0.75      0.76      0.75     20688

    accuracy                           0.63     27703
   macro avg       0.50      0.50      0.50     27703
weighted avg       0.62      0.63      0.63     27703

              precision    recall  f1-score   support

           0       0.26      0.25      0.25      7015
           1       0.75      0.76      0.75     20688

    accuracy                           0.63     27703
   macro avg       0.50      0.50      0.50     27703
weighted avg       0.62      0.63      0.63     27703

Flagellin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.50      0.33      0.40     34394
           1       0.49      0.67      0.57     33660

    accuracy                           0.50     68054
   macro avg       0.50      0.50      0.48     68054
weighted avg       0.50      0.50      0.48     68054

              precision    recall  f1-score   support

           0       0.50      0.33      0.40     34394
           1       0.49      0.67      0.57     33660

    accuracy                           0.50     68054
   macro avg       0.50      0.50      0.48     68054
weighted avg       0.50      0.50      0.48     68054

completed
