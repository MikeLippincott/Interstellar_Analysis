[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '8d471132'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '33d291f9'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'a4417b7e'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '1ccb6780'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: Flagellin_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_Nigericin_1.000_3.0_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (278808, 1270)
Number of total missing values across all columns: 245710
Data Subset Is Off
Wells held out for testing: ['L08' 'M10']
Wells to use for training, validation, and testing ['L02' 'L03' 'M05' 'L09' 'M11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.315002).  Saving model ...
	 Train_Loss: 0.4451 Train_Acc: 72.435 Val_Loss: 0.3150  BEST VAL Loss: 0.3150  Val_Acc: 92.483

Epoch 1: Validation loss decreased (0.315002 --> 0.268086).  Saving model ...
	 Train_Loss: 0.3753 Train_Acc: 91.883 Val_Loss: 0.2681  BEST VAL Loss: 0.2681  Val_Acc: 95.713

Epoch 2: Validation loss decreased (0.268086 --> 0.236475).  Saving model ...
	 Train_Loss: 0.3316 Train_Acc: 93.648 Val_Loss: 0.2365  BEST VAL Loss: 0.2365  Val_Acc: 96.664

Epoch 3: Validation loss decreased (0.236475 --> 0.214541).  Saving model ...
	 Train_Loss: 0.2994 Train_Acc: 94.630 Val_Loss: 0.2145  BEST VAL Loss: 0.2145  Val_Acc: 96.993

Epoch 4: Validation loss decreased (0.214541 --> 0.197132).  Saving model ...
	 Train_Loss: 0.2756 Train_Acc: 95.157 Val_Loss: 0.1971  BEST VAL Loss: 0.1971  Val_Acc: 97.525

Epoch 5: Validation loss decreased (0.197132 --> 0.183694).  Saving model ...
	 Train_Loss: 0.2574 Train_Acc: 95.453 Val_Loss: 0.1837  BEST VAL Loss: 0.1837  Val_Acc: 97.601

Epoch 6: Validation loss decreased (0.183694 --> 0.172424).  Saving model ...
	 Train_Loss: 0.2422 Train_Acc: 95.842 Val_Loss: 0.1724  BEST VAL Loss: 0.1724  Val_Acc: 98.036

Epoch 7: Validation loss decreased (0.172424 --> 0.163580).  Saving model ...
	 Train_Loss: 0.2295 Train_Acc: 96.050 Val_Loss: 0.1636  BEST VAL Loss: 0.1636  Val_Acc: 97.950

Epoch 8: Validation loss decreased (0.163580 --> 0.155684).  Saving model ...
	 Train_Loss: 0.2187 Train_Acc: 96.267 Val_Loss: 0.1557  BEST VAL Loss: 0.1557  Val_Acc: 98.228

Epoch 9: Validation loss decreased (0.155684 --> 0.148886).  Saving model ...
	 Train_Loss: 0.2096 Train_Acc: 96.434 Val_Loss: 0.1489  BEST VAL Loss: 0.1489  Val_Acc: 98.355

Epoch 10: Validation loss decreased (0.148886 --> 0.144967).  Saving model ...
	 Train_Loss: 0.2015 Train_Acc: 96.650 Val_Loss: 0.1450  BEST VAL Loss: 0.1450  Val_Acc: 97.677

Epoch 11: Validation loss decreased (0.144967 --> 0.139561).  Saving model ...
	 Train_Loss: 0.1945 Train_Acc: 96.711 Val_Loss: 0.1396  BEST VAL Loss: 0.1396  Val_Acc: 98.446

Epoch 12: Validation loss decreased (0.139561 --> 0.134772).  Saving model ...
	 Train_Loss: 0.1884 Train_Acc: 96.768 Val_Loss: 0.1348  BEST VAL Loss: 0.1348  Val_Acc: 98.547

Epoch 13: Validation loss decreased (0.134772 --> 0.130733).  Saving model ...
	 Train_Loss: 0.1829 Train_Acc: 96.878 Val_Loss: 0.1307  BEST VAL Loss: 0.1307  Val_Acc: 98.542

Epoch 14: Validation loss decreased (0.130733 --> 0.126986).  Saving model ...
	 Train_Loss: 0.1779 Train_Acc: 96.905 Val_Loss: 0.1270  BEST VAL Loss: 0.1270  Val_Acc: 98.578

Epoch 15: Validation loss decreased (0.126986 --> 0.124852).  Saving model ...
	 Train_Loss: 0.1734 Train_Acc: 97.027 Val_Loss: 0.1249  BEST VAL Loss: 0.1249  Val_Acc: 97.985

Epoch 16: Validation loss decreased (0.124852 --> 0.121802).  Saving model ...
	 Train_Loss: 0.1693 Train_Acc: 97.159 Val_Loss: 0.1218  BEST VAL Loss: 0.1218  Val_Acc: 98.664

Epoch 17: Validation loss decreased (0.121802 --> 0.118998).  Saving model ...
	 Train_Loss: 0.1656 Train_Acc: 97.119 Val_Loss: 0.1190  BEST VAL Loss: 0.1190  Val_Acc: 98.618

Epoch 18: Validation loss decreased (0.118998 --> 0.116661).  Saving model ...
	 Train_Loss: 0.1622 Train_Acc: 97.153 Val_Loss: 0.1167  BEST VAL Loss: 0.1167  Val_Acc: 98.522

Epoch 19: Validation loss decreased (0.116661 --> 0.114254).  Saving model ...
	 Train_Loss: 0.1590 Train_Acc: 97.240 Val_Loss: 0.1143  BEST VAL Loss: 0.1143  Val_Acc: 98.709

Epoch 20: Validation loss decreased (0.114254 --> 0.111981).  Saving model ...
	 Train_Loss: 0.1560 Train_Acc: 97.304 Val_Loss: 0.1120  BEST VAL Loss: 0.1120  Val_Acc: 98.694

Epoch 21: Validation loss decreased (0.111981 --> 0.110026).  Saving model ...
	 Train_Loss: 0.1532 Train_Acc: 97.346 Val_Loss: 0.1100  BEST VAL Loss: 0.1100  Val_Acc: 98.684

Epoch 22: Validation loss decreased (0.110026 --> 0.108059).  Saving model ...
	 Train_Loss: 0.1506 Train_Acc: 97.392 Val_Loss: 0.1081  BEST VAL Loss: 0.1081  Val_Acc: 98.689

Epoch 23: Validation loss decreased (0.108059 --> 0.106190).  Saving model ...
	 Train_Loss: 0.1482 Train_Acc: 97.423 Val_Loss: 0.1062  BEST VAL Loss: 0.1062  Val_Acc: 98.810

Epoch 24: Validation loss decreased (0.106190 --> 0.104437).  Saving model ...
	 Train_Loss: 0.1460 Train_Acc: 97.392 Val_Loss: 0.1044  BEST VAL Loss: 0.1044  Val_Acc: 98.790

Epoch 25: Validation loss decreased (0.104437 --> 0.102855).  Saving model ...
	 Train_Loss: 0.1440 Train_Acc: 97.336 Val_Loss: 0.1029  BEST VAL Loss: 0.1029  Val_Acc: 98.795

Epoch 26: Validation loss decreased (0.102855 --> 0.101415).  Saving model ...
	 Train_Loss: 0.1420 Train_Acc: 97.480 Val_Loss: 0.1014  BEST VAL Loss: 0.1014  Val_Acc: 98.780

Epoch 27: Validation loss decreased (0.101415 --> 0.100149).  Saving model ...
	 Train_Loss: 0.1401 Train_Acc: 97.483 Val_Loss: 0.1001  BEST VAL Loss: 0.1001  Val_Acc: 98.664

Epoch 28: Validation loss decreased (0.100149 --> 0.098818).  Saving model ...
	 Train_Loss: 0.1384 Train_Acc: 97.488 Val_Loss: 0.0988  BEST VAL Loss: 0.0988  Val_Acc: 98.846

Epoch 29: Validation loss decreased (0.098818 --> 0.097994).  Saving model ...
	 Train_Loss: 0.1367 Train_Acc: 97.549 Val_Loss: 0.0980  BEST VAL Loss: 0.0980  Val_Acc: 98.618

Epoch 30: Validation loss decreased (0.097994 --> 0.096790).  Saving model ...
	 Train_Loss: 0.1352 Train_Acc: 97.553 Val_Loss: 0.0968  BEST VAL Loss: 0.0968  Val_Acc: 98.846

Epoch 31: Validation loss decreased (0.096790 --> 0.095760).  Saving model ...
	 Train_Loss: 0.1337 Train_Acc: 97.601 Val_Loss: 0.0958  BEST VAL Loss: 0.0958  Val_Acc: 98.871

Epoch 32: Validation loss decreased (0.095760 --> 0.094687).  Saving model ...
	 Train_Loss: 0.1322 Train_Acc: 97.649 Val_Loss: 0.0947  BEST VAL Loss: 0.0947  Val_Acc: 98.891

Epoch 33: Validation loss decreased (0.094687 --> 0.093675).  Saving model ...
	 Train_Loss: 0.1309 Train_Acc: 97.629 Val_Loss: 0.0937  BEST VAL Loss: 0.0937  Val_Acc: 98.876

Epoch 34: Validation loss decreased (0.093675 --> 0.092688).  Saving model ...
	 Train_Loss: 0.1297 Train_Acc: 97.564 Val_Loss: 0.0927  BEST VAL Loss: 0.0927  Val_Acc: 98.856

Epoch 35: Validation loss decreased (0.092688 --> 0.091992).  Saving model ...
	 Train_Loss: 0.1284 Train_Acc: 97.665 Val_Loss: 0.0920  BEST VAL Loss: 0.0920  Val_Acc: 98.669

Epoch 36: Validation loss decreased (0.091992 --> 0.091271).  Saving model ...
	 Train_Loss: 0.1272 Train_Acc: 97.667 Val_Loss: 0.0913  BEST VAL Loss: 0.0913  Val_Acc: 98.654

Epoch 37: Validation loss decreased (0.091271 --> 0.090393).  Saving model ...
	 Train_Loss: 0.1261 Train_Acc: 97.725 Val_Loss: 0.0904  BEST VAL Loss: 0.0904  Val_Acc: 98.912

Epoch 38: Validation loss decreased (0.090393 --> 0.089624).  Saving model ...
	 Train_Loss: 0.1250 Train_Acc: 97.657 Val_Loss: 0.0896  BEST VAL Loss: 0.0896  Val_Acc: 98.861

Epoch 39: Validation loss decreased (0.089624 --> 0.088932).  Saving model ...
	 Train_Loss: 0.1240 Train_Acc: 97.708 Val_Loss: 0.0889  BEST VAL Loss: 0.0889  Val_Acc: 98.927

Epoch 40: Validation loss decreased (0.088932 --> 0.088245).  Saving model ...
	 Train_Loss: 0.1230 Train_Acc: 97.774 Val_Loss: 0.0882  BEST VAL Loss: 0.0882  Val_Acc: 98.891

Epoch 41: Validation loss decreased (0.088245 --> 0.087497).  Saving model ...
	 Train_Loss: 0.1220 Train_Acc: 97.812 Val_Loss: 0.0875  BEST VAL Loss: 0.0875  Val_Acc: 98.957

Epoch 42: Validation loss decreased (0.087497 --> 0.086807).  Saving model ...
	 Train_Loss: 0.1211 Train_Acc: 97.785 Val_Loss: 0.0868  BEST VAL Loss: 0.0868  Val_Acc: 98.947

Epoch 43: Validation loss decreased (0.086807 --> 0.086379).  Saving model ...
	 Train_Loss: 0.1201 Train_Acc: 97.787 Val_Loss: 0.0864  BEST VAL Loss: 0.0864  Val_Acc: 98.846

Epoch 44: Validation loss decreased (0.086379 --> 0.085794).  Saving model ...
	 Train_Loss: 0.1193 Train_Acc: 97.820 Val_Loss: 0.0858  BEST VAL Loss: 0.0858  Val_Acc: 98.861

Epoch 45: Validation loss decreased (0.085794 --> 0.085224).  Saving model ...
	 Train_Loss: 0.1185 Train_Acc: 97.775 Val_Loss: 0.0852  BEST VAL Loss: 0.0852  Val_Acc: 98.846

Epoch 46: Validation loss decreased (0.085224 --> 0.084657).  Saving model ...
	 Train_Loss: 0.1177 Train_Acc: 97.768 Val_Loss: 0.0847  BEST VAL Loss: 0.0847  Val_Acc: 98.932

Epoch 47: Validation loss decreased (0.084657 --> 0.084068).  Saving model ...
	 Train_Loss: 0.1169 Train_Acc: 97.780 Val_Loss: 0.0841  BEST VAL Loss: 0.0841  Val_Acc: 98.937

Epoch 48: Validation loss decreased (0.084068 --> 0.083540).  Saving model ...
	 Train_Loss: 0.1161 Train_Acc: 97.885 Val_Loss: 0.0835  BEST VAL Loss: 0.0835  Val_Acc: 98.957

Epoch 49: Validation loss decreased (0.083540 --> 0.083000).  Saving model ...
	 Train_Loss: 0.1153 Train_Acc: 97.946 Val_Loss: 0.0830  BEST VAL Loss: 0.0830  Val_Acc: 99.008

Epoch 50: Validation loss decreased (0.083000 --> 0.082478).  Saving model ...
	 Train_Loss: 0.1146 Train_Acc: 97.949 Val_Loss: 0.0825  BEST VAL Loss: 0.0825  Val_Acc: 99.008

Epoch 51: Validation loss decreased (0.082478 --> 0.082116).  Saving model ...
	 Train_Loss: 0.1139 Train_Acc: 97.927 Val_Loss: 0.0821  BEST VAL Loss: 0.0821  Val_Acc: 98.902

Epoch 52: Validation loss decreased (0.082116 --> 0.081894).  Saving model ...
	 Train_Loss: 0.1132 Train_Acc: 97.859 Val_Loss: 0.0819  BEST VAL Loss: 0.0819  Val_Acc: 98.856

Epoch 53: Validation loss decreased (0.081894 --> 0.081506).  Saving model ...
	 Train_Loss: 0.1126 Train_Acc: 97.896 Val_Loss: 0.0815  BEST VAL Loss: 0.0815  Val_Acc: 98.947

Epoch 54: Validation loss decreased (0.081506 --> 0.081066).  Saving model ...
	 Train_Loss: 0.1119 Train_Acc: 97.912 Val_Loss: 0.0811  BEST VAL Loss: 0.0811  Val_Acc: 98.983

Epoch 55: Validation loss decreased (0.081066 --> 0.080650).  Saving model ...
	 Train_Loss: 0.1113 Train_Acc: 97.892 Val_Loss: 0.0807  BEST VAL Loss: 0.0807  Val_Acc: 98.988

Epoch 56: Validation loss decreased (0.080650 --> 0.080222).  Saving model ...
	 Train_Loss: 0.1107 Train_Acc: 97.934 Val_Loss: 0.0802  BEST VAL Loss: 0.0802  Val_Acc: 98.993

Epoch 57: Validation loss decreased (0.080222 --> 0.079801).  Saving model ...
	 Train_Loss: 0.1101 Train_Acc: 97.907 Val_Loss: 0.0798  BEST VAL Loss: 0.0798  Val_Acc: 99.038

Epoch 58: Validation loss decreased (0.079801 --> 0.079463).  Saving model ...
	 Train_Loss: 0.1095 Train_Acc: 97.950 Val_Loss: 0.0795  BEST VAL Loss: 0.0795  Val_Acc: 98.917

Epoch 59: Validation loss decreased (0.079463 --> 0.079095).  Saving model ...
	 Train_Loss: 0.1090 Train_Acc: 97.964 Val_Loss: 0.0791  BEST VAL Loss: 0.0791  Val_Acc: 99.003

Epoch 60: Validation loss decreased (0.079095 --> 0.078778).  Saving model ...
	 Train_Loss: 0.1085 Train_Acc: 97.914 Val_Loss: 0.0788  BEST VAL Loss: 0.0788  Val_Acc: 98.897

Epoch 61: Validation loss decreased (0.078778 --> 0.078533).  Saving model ...
	 Train_Loss: 0.1079 Train_Acc: 97.980 Val_Loss: 0.0785  BEST VAL Loss: 0.0785  Val_Acc: 98.972

Epoch 62: Validation loss decreased (0.078533 --> 0.078190).  Saving model ...
	 Train_Loss: 0.1075 Train_Acc: 97.947 Val_Loss: 0.0782  BEST VAL Loss: 0.0782  Val_Acc: 98.978

Epoch 63: Validation loss decreased (0.078190 --> 0.077930).  Saving model ...
	 Train_Loss: 0.1069 Train_Acc: 97.992 Val_Loss: 0.0779  BEST VAL Loss: 0.0779  Val_Acc: 98.937

Epoch 64: Validation loss decreased (0.077930 --> 0.077628).  Saving model ...
	 Train_Loss: 0.1065 Train_Acc: 97.975 Val_Loss: 0.0776  BEST VAL Loss: 0.0776  Val_Acc: 98.962

Epoch 65: Validation loss decreased (0.077628 --> 0.077331).  Saving model ...
	 Train_Loss: 0.1060 Train_Acc: 97.935 Val_Loss: 0.0773  BEST VAL Loss: 0.0773  Val_Acc: 99.043

Epoch 66: Validation loss decreased (0.077331 --> 0.077043).  Saving model ...
	 Train_Loss: 0.1055 Train_Acc: 97.985 Val_Loss: 0.0770  BEST VAL Loss: 0.0770  Val_Acc: 99.053

Epoch 67: Validation loss decreased (0.077043 --> 0.076786).  Saving model ...
	 Train_Loss: 0.1051 Train_Acc: 97.935 Val_Loss: 0.0768  BEST VAL Loss: 0.0768  Val_Acc: 98.922

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.1047 Train_Acc: 98.016 Val_Loss: 0.0768  BEST VAL Loss: 0.0768  Val_Acc: 98.082

Epoch 69: Validation loss decreased (0.076786 --> 0.076493).  Saving model ...
	 Train_Loss: 0.1043 Train_Acc: 97.972 Val_Loss: 0.0765  BEST VAL Loss: 0.0765  Val_Acc: 99.043

Epoch 70: Validation loss decreased (0.076493 --> 0.076198).  Saving model ...
	 Train_Loss: 0.1038 Train_Acc: 98.030 Val_Loss: 0.0762  BEST VAL Loss: 0.0762  Val_Acc: 99.023

Epoch 71: Validation loss decreased (0.076198 --> 0.075933).  Saving model ...
	 Train_Loss: 0.1034 Train_Acc: 98.050 Val_Loss: 0.0759  BEST VAL Loss: 0.0759  Val_Acc: 99.023

Epoch 72: Validation loss decreased (0.075933 --> 0.075782).  Saving model ...
	 Train_Loss: 0.1030 Train_Acc: 98.028 Val_Loss: 0.0758  BEST VAL Loss: 0.0758  Val_Acc: 98.790

Epoch 73: Validation loss decreased (0.075782 --> 0.075539).  Saving model ...
	 Train_Loss: 0.1026 Train_Acc: 98.049 Val_Loss: 0.0755  BEST VAL Loss: 0.0755  Val_Acc: 98.957

Epoch 74: Validation loss decreased (0.075539 --> 0.075310).  Saving model ...
	 Train_Loss: 0.1022 Train_Acc: 98.079 Val_Loss: 0.0753  BEST VAL Loss: 0.0753  Val_Acc: 98.947

Epoch 75: Validation loss decreased (0.075310 --> 0.075091).  Saving model ...
	 Train_Loss: 0.1018 Train_Acc: 98.067 Val_Loss: 0.0751  BEST VAL Loss: 0.0751  Val_Acc: 98.972

Epoch 76: Validation loss decreased (0.075091 --> 0.074890).  Saving model ...
	 Train_Loss: 0.1014 Train_Acc: 98.135 Val_Loss: 0.0749  BEST VAL Loss: 0.0749  Val_Acc: 98.836

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.1010 Train_Acc: 98.039 Val_Loss: 0.0780  BEST VAL Loss: 0.0749  Val_Acc: 96.077

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.1007 Train_Acc: 97.947 Val_Loss: 0.0777  BEST VAL Loss: 0.0749  Val_Acc: 98.983

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.1004 Train_Acc: 98.052 Val_Loss: 0.0774  BEST VAL Loss: 0.0749  Val_Acc: 98.998

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.1000 Train_Acc: 98.059 Val_Loss: 0.0772  BEST VAL Loss: 0.0749  Val_Acc: 98.993

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.0997 Train_Acc: 98.075 Val_Loss: 0.0770  BEST VAL Loss: 0.0749  Val_Acc: 99.003

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.0993 Train_Acc: 98.095 Val_Loss: 0.0767  BEST VAL Loss: 0.0749  Val_Acc: 99.053

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.0990 Train_Acc: 98.123 Val_Loss: 0.0766  BEST VAL Loss: 0.0749  Val_Acc: 98.978

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.0987 Train_Acc: 98.116 Val_Loss: 0.0764  BEST VAL Loss: 0.0749  Val_Acc: 98.952

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.0984 Train_Acc: 98.089 Val_Loss: 0.0762  BEST VAL Loss: 0.0749  Val_Acc: 98.755

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.0980 Train_Acc: 98.087 Val_Loss: 0.0760  BEST VAL Loss: 0.0749  Val_Acc: 99.074

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.0977 Train_Acc: 98.112 Val_Loss: 0.0758  BEST VAL Loss: 0.0749  Val_Acc: 99.013

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.0974 Train_Acc: 98.156 Val_Loss: 0.0756  BEST VAL Loss: 0.0749  Val_Acc: 99.008

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.0971 Train_Acc: 98.156 Val_Loss: 0.0754  BEST VAL Loss: 0.0749  Val_Acc: 99.033

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.0968 Train_Acc: 98.199 Val_Loss: 0.0752  BEST VAL Loss: 0.0749  Val_Acc: 99.104

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.0965 Train_Acc: 98.180 Val_Loss: 0.0750  BEST VAL Loss: 0.0749  Val_Acc: 99.023

Epoch 92: Validation loss decreased (0.074890 --> 0.074820).  Saving model ...
	 Train_Loss: 0.0962 Train_Acc: 98.123 Val_Loss: 0.0748  BEST VAL Loss: 0.0748  Val_Acc: 99.053

Epoch 93: Validation loss decreased (0.074820 --> 0.074667).  Saving model ...
	 Train_Loss: 0.0959 Train_Acc: 98.170 Val_Loss: 0.0747  BEST VAL Loss: 0.0747  Val_Acc: 99.023

Epoch 94: Validation loss decreased (0.074667 --> 0.074493).  Saving model ...
	 Train_Loss: 0.0957 Train_Acc: 98.142 Val_Loss: 0.0745  BEST VAL Loss: 0.0745  Val_Acc: 99.069

Epoch 95: Validation loss decreased (0.074493 --> 0.074339).  Saving model ...
	 Train_Loss: 0.0954 Train_Acc: 98.182 Val_Loss: 0.0743  BEST VAL Loss: 0.0743  Val_Acc: 98.962

Epoch 96: Validation loss decreased (0.074339 --> 0.074155).  Saving model ...
	 Train_Loss: 0.0951 Train_Acc: 98.180 Val_Loss: 0.0742  BEST VAL Loss: 0.0742  Val_Acc: 99.119

Epoch 97: Validation loss decreased (0.074155 --> 0.074036).  Saving model ...
	 Train_Loss: 0.0948 Train_Acc: 98.123 Val_Loss: 0.0740  BEST VAL Loss: 0.0740  Val_Acc: 98.988

Epoch 98: Validation loss decreased (0.074036 --> 0.073901).  Saving model ...
	 Train_Loss: 0.0946 Train_Acc: 98.132 Val_Loss: 0.0739  BEST VAL Loss: 0.0739  Val_Acc: 99.089

Epoch 99: Validation loss decreased (0.073901 --> 0.073734).  Saving model ...
	 Train_Loss: 0.0943 Train_Acc: 98.227 Val_Loss: 0.0737  BEST VAL Loss: 0.0737  Val_Acc: 99.053

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56122
           1       1.00      1.00      1.00    101921

    accuracy                           1.00    158043
   macro avg       1.00      1.00      1.00    158043
weighted avg       1.00      1.00      1.00    158043

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      0.98      0.99      7015
           1       0.99      0.99      0.99     12741

    accuracy                           0.99     19756
   macro avg       0.99      0.99      0.99     19756
weighted avg       0.99      0.99      0.99     19756

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      0.99      0.99      7016
           1       0.99      1.00      0.99     12740

    accuracy                           0.99     19756
   macro avg       0.99      0.99      0.99     19756
weighted avg       0.99      0.99      0.99     19756

              precision    recall  f1-score   support

           0       0.99      0.99      0.99      7016
           1       0.99      1.00      0.99     12740

    accuracy                           0.99     19756
   macro avg       0.99      0.99      0.99     19756
weighted avg       0.99      0.99      0.99     19756

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.84      0.82      0.83     34394
           1       0.87      0.89      0.88     46859

    accuracy                           0.86     81253
   macro avg       0.86      0.85      0.85     81253
weighted avg       0.86      0.86      0.86     81253

              precision    recall  f1-score   support

           0       0.84      0.82      0.83     34394
           1       0.87      0.89      0.88     46859

    accuracy                           0.86     81253
   macro avg       0.86      0.85      0.85     81253
weighted avg       0.86      0.86      0.86     81253

completed
