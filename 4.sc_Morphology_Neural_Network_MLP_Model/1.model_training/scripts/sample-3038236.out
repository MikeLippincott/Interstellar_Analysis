[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '4621423b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '44800b36'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ca09a1f2'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'cf6d0dda'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 treatment_name: LPS_10.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
TREATMENT_NAME: LPS_10.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (337656, 1270)
Number of total missing values across all columns: 312980
Data Subset Is Off
Wells held out for testing: ['E09' 'M09']
Wells to use for training, validation, and testing ['E02' 'E03' 'E08' 'M02' 'M03' 'M08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.166112).  Saving model ...
	 Train_Loss: 0.3072 Train_Acc: 86.874 Val_Loss: 0.1661  BEST VAL Loss: 0.1661  Val_Acc: 93.986

Epoch 1: Validation loss decreased (0.166112 --> 0.157110).  Saving model ...
	 Train_Loss: 0.2688 Train_Acc: 92.073 Val_Loss: 0.1571  BEST VAL Loss: 0.1571  Val_Acc: 94.412

Epoch 2: Validation loss decreased (0.157110 --> 0.150823).  Saving model ...
	 Train_Loss: 0.2511 Train_Acc: 92.659 Val_Loss: 0.1508  BEST VAL Loss: 0.1508  Val_Acc: 95.068

Epoch 3: Validation loss decreased (0.150823 --> 0.144513).  Saving model ...
	 Train_Loss: 0.2398 Train_Acc: 93.050 Val_Loss: 0.1445  BEST VAL Loss: 0.1445  Val_Acc: 95.372

Epoch 4: Validation loss decreased (0.144513 --> 0.140419).  Saving model ...
	 Train_Loss: 0.2323 Train_Acc: 93.155 Val_Loss: 0.1404  BEST VAL Loss: 0.1404  Val_Acc: 95.526

Epoch 5: Validation loss decreased (0.140419 --> 0.136707).  Saving model ...
	 Train_Loss: 0.2268 Train_Acc: 93.354 Val_Loss: 0.1367  BEST VAL Loss: 0.1367  Val_Acc: 95.696

Epoch 6: Validation loss decreased (0.136707 --> 0.133911).  Saving model ...
	 Train_Loss: 0.2219 Train_Acc: 93.550 Val_Loss: 0.1339  BEST VAL Loss: 0.1339  Val_Acc: 96.000

Epoch 7: Validation loss decreased (0.133911 --> 0.131653).  Saving model ...
	 Train_Loss: 0.2180 Train_Acc: 93.793 Val_Loss: 0.1317  BEST VAL Loss: 0.1317  Val_Acc: 95.927

Epoch 8: Validation loss decreased (0.131653 --> 0.130916).  Saving model ...
	 Train_Loss: 0.2147 Train_Acc: 93.826 Val_Loss: 0.1309  BEST VAL Loss: 0.1309  Val_Acc: 95.713

Epoch 9: Validation loss decreased (0.130916 --> 0.130179).  Saving model ...
	 Train_Loss: 0.2124 Train_Acc: 93.715 Val_Loss: 0.1302  BEST VAL Loss: 0.1302  Val_Acc: 95.551

Epoch 10: Validation loss decreased (0.130179 --> 0.128545).  Saving model ...
	 Train_Loss: 0.2101 Train_Acc: 93.808 Val_Loss: 0.1285  BEST VAL Loss: 0.1285  Val_Acc: 96.008

Epoch 11: Validation loss decreased (0.128545 --> 0.127268).  Saving model ...
	 Train_Loss: 0.2080 Train_Acc: 93.925 Val_Loss: 0.1273  BEST VAL Loss: 0.1273  Val_Acc: 95.907

Epoch 12: Validation loss decreased (0.127268 --> 0.126291).  Saving model ...
	 Train_Loss: 0.2065 Train_Acc: 93.706 Val_Loss: 0.1263  BEST VAL Loss: 0.1263  Val_Acc: 96.053

Epoch 13: Validation loss decreased (0.126291 --> 0.125365).  Saving model ...
	 Train_Loss: 0.2049 Train_Acc: 93.981 Val_Loss: 0.1254  BEST VAL Loss: 0.1254  Val_Acc: 96.094

Epoch 14: Validation loss decreased (0.125365 --> 0.124273).  Saving model ...
	 Train_Loss: 0.2037 Train_Acc: 93.840 Val_Loss: 0.1243  BEST VAL Loss: 0.1243  Val_Acc: 96.081

Epoch 15: Validation loss decreased (0.124273 --> 0.123276).  Saving model ...
	 Train_Loss: 0.2022 Train_Acc: 94.155 Val_Loss: 0.1233  BEST VAL Loss: 0.1233  Val_Acc: 95.863

Epoch 16: Validation loss decreased (0.123276 --> 0.122384).  Saving model ...
	 Train_Loss: 0.2009 Train_Acc: 94.132 Val_Loss: 0.1224  BEST VAL Loss: 0.1224  Val_Acc: 96.102

Epoch 17: Validation loss decreased (0.122384 --> 0.121282).  Saving model ...
	 Train_Loss: 0.1996 Train_Acc: 94.220 Val_Loss: 0.1213  BEST VAL Loss: 0.1213  Val_Acc: 96.418

Epoch 18: Validation loss decreased (0.121282 --> 0.120983).  Saving model ...
	 Train_Loss: 0.1984 Train_Acc: 94.258 Val_Loss: 0.1210  BEST VAL Loss: 0.1210  Val_Acc: 95.749

Epoch 19: Validation loss decreased (0.120983 --> 0.120499).  Saving model ...
	 Train_Loss: 0.1975 Train_Acc: 94.118 Val_Loss: 0.1205  BEST VAL Loss: 0.1205  Val_Acc: 96.102

Epoch 20: Validation loss decreased (0.120499 --> 0.119986).  Saving model ...
	 Train_Loss: 0.1966 Train_Acc: 94.215 Val_Loss: 0.1200  BEST VAL Loss: 0.1200  Val_Acc: 96.264

Epoch 21: Validation loss decreased (0.119986 --> 0.119507).  Saving model ...
	 Train_Loss: 0.1956 Train_Acc: 94.274 Val_Loss: 0.1195  BEST VAL Loss: 0.1195  Val_Acc: 96.223

Epoch 22: Validation loss decreased (0.119507 --> 0.119343).  Saving model ...
	 Train_Loss: 0.1948 Train_Acc: 94.307 Val_Loss: 0.1193  BEST VAL Loss: 0.1193  Val_Acc: 95.781

Epoch 23: Validation loss decreased (0.119343 --> 0.118902).  Saving model ...
	 Train_Loss: 0.1942 Train_Acc: 94.052 Val_Loss: 0.1189  BEST VAL Loss: 0.1189  Val_Acc: 96.150

Epoch 24: Validation loss decreased (0.118902 --> 0.118670).  Saving model ...
	 Train_Loss: 0.1935 Train_Acc: 94.218 Val_Loss: 0.1187  BEST VAL Loss: 0.1187  Val_Acc: 95.526

Epoch 25: Validation loss decreased (0.118670 --> 0.118371).  Saving model ...
	 Train_Loss: 0.1931 Train_Acc: 94.039 Val_Loss: 0.1184  BEST VAL Loss: 0.1184  Val_Acc: 96.126

Epoch 26: Validation loss decreased (0.118371 --> 0.118085).  Saving model ...
	 Train_Loss: 0.1926 Train_Acc: 94.134 Val_Loss: 0.1181  BEST VAL Loss: 0.1181  Val_Acc: 96.308

Epoch 27: Validation loss decreased (0.118085 --> 0.117826).  Saving model ...
	 Train_Loss: 0.1920 Train_Acc: 94.207 Val_Loss: 0.1178  BEST VAL Loss: 0.1178  Val_Acc: 96.292

Epoch 28: Validation loss decreased (0.117826 --> 0.117548).  Saving model ...
	 Train_Loss: 0.1915 Train_Acc: 94.204 Val_Loss: 0.1175  BEST VAL Loss: 0.1175  Val_Acc: 96.243

Epoch 29: Validation loss decreased (0.117548 --> 0.117305).  Saving model ...
	 Train_Loss: 0.1911 Train_Acc: 94.230 Val_Loss: 0.1173  BEST VAL Loss: 0.1173  Val_Acc: 95.935

Epoch 30: Validation loss decreased (0.117305 --> 0.116950).  Saving model ...
	 Train_Loss: 0.1905 Train_Acc: 94.465 Val_Loss: 0.1169  BEST VAL Loss: 0.1169  Val_Acc: 96.211

Epoch 31: Validation loss decreased (0.116950 --> 0.116670).  Saving model ...
	 Train_Loss: 0.1899 Train_Acc: 94.397 Val_Loss: 0.1167  BEST VAL Loss: 0.1167  Val_Acc: 96.102

Epoch 32: Validation loss decreased (0.116670 --> 0.116465).  Saving model ...
	 Train_Loss: 0.1895 Train_Acc: 94.237 Val_Loss: 0.1165  BEST VAL Loss: 0.1165  Val_Acc: 96.175

Epoch 33: Validation loss decreased (0.116465 --> 0.116170).  Saving model ...
	 Train_Loss: 0.1890 Train_Acc: 94.428 Val_Loss: 0.1162  BEST VAL Loss: 0.1162  Val_Acc: 96.284

Epoch 34: Validation loss decreased (0.116170 --> 0.115817).  Saving model ...
	 Train_Loss: 0.1886 Train_Acc: 94.277 Val_Loss: 0.1158  BEST VAL Loss: 0.1158  Val_Acc: 96.369

Epoch 35: Validation loss decreased (0.115817 --> 0.115576).  Saving model ...
	 Train_Loss: 0.1881 Train_Acc: 94.513 Val_Loss: 0.1156  BEST VAL Loss: 0.1156  Val_Acc: 96.325

Epoch 36: Validation loss decreased (0.115576 --> 0.115393).  Saving model ...
	 Train_Loss: 0.1878 Train_Acc: 94.326 Val_Loss: 0.1154  BEST VAL Loss: 0.1154  Val_Acc: 96.203

Epoch 37: Validation loss decreased (0.115393 --> 0.115109).  Saving model ...
	 Train_Loss: 0.1874 Train_Acc: 94.306 Val_Loss: 0.1151  BEST VAL Loss: 0.1151  Val_Acc: 96.243

Epoch 38: Validation loss decreased (0.115109 --> 0.114855).  Saving model ...
	 Train_Loss: 0.1871 Train_Acc: 94.326 Val_Loss: 0.1149  BEST VAL Loss: 0.1149  Val_Acc: 96.207

Epoch 39: Validation loss decreased (0.114855 --> 0.114656).  Saving model ...
	 Train_Loss: 0.1868 Train_Acc: 94.269 Val_Loss: 0.1147  BEST VAL Loss: 0.1147  Val_Acc: 96.045

Epoch 40: Validation loss decreased (0.114656 --> 0.114501).  Saving model ...
	 Train_Loss: 0.1865 Train_Acc: 94.380 Val_Loss: 0.1145  BEST VAL Loss: 0.1145  Val_Acc: 96.118

Epoch 41: Validation loss decreased (0.114501 --> 0.114231).  Saving model ...
	 Train_Loss: 0.1861 Train_Acc: 94.403 Val_Loss: 0.1142  BEST VAL Loss: 0.1142  Val_Acc: 96.316

Epoch 42: Validation loss decreased (0.114231 --> 0.114041).  Saving model ...
	 Train_Loss: 0.1857 Train_Acc: 94.511 Val_Loss: 0.1140  BEST VAL Loss: 0.1140  Val_Acc: 96.061

Epoch 43: Validation loss decreased (0.114041 --> 0.113816).  Saving model ...
	 Train_Loss: 0.1853 Train_Acc: 94.671 Val_Loss: 0.1138  BEST VAL Loss: 0.1138  Val_Acc: 96.150

Epoch 44: Validation loss decreased (0.113816 --> 0.113651).  Saving model ...
	 Train_Loss: 0.1850 Train_Acc: 94.320 Val_Loss: 0.1137  BEST VAL Loss: 0.1137  Val_Acc: 96.272

Epoch 45: Validation loss decreased (0.113651 --> 0.113506).  Saving model ...
	 Train_Loss: 0.1848 Train_Acc: 94.296 Val_Loss: 0.1135  BEST VAL Loss: 0.1135  Val_Acc: 95.956

Epoch 46: Validation loss decreased (0.113506 --> 0.113309).  Saving model ...
	 Train_Loss: 0.1845 Train_Acc: 94.295 Val_Loss: 0.1133  BEST VAL Loss: 0.1133  Val_Acc: 96.353

Epoch 47: Validation loss decreased (0.113309 --> 0.113221).  Saving model ...
	 Train_Loss: 0.1843 Train_Acc: 94.399 Val_Loss: 0.1132  BEST VAL Loss: 0.1132  Val_Acc: 96.248

Epoch 48: Validation loss decreased (0.113221 --> 0.112966).  Saving model ...
	 Train_Loss: 0.1839 Train_Acc: 94.718 Val_Loss: 0.1130  BEST VAL Loss: 0.1130  Val_Acc: 96.470

Epoch 49: Validation loss decreased (0.112966 --> 0.112740).  Saving model ...
	 Train_Loss: 0.1835 Train_Acc: 94.749 Val_Loss: 0.1127  BEST VAL Loss: 0.1127  Val_Acc: 96.361

Epoch 50: Validation loss decreased (0.112740 --> 0.112544).  Saving model ...
	 Train_Loss: 0.1831 Train_Acc: 94.686 Val_Loss: 0.1125  BEST VAL Loss: 0.1125  Val_Acc: 96.341

Epoch 51: Validation loss decreased (0.112544 --> 0.112342).  Saving model ...
	 Train_Loss: 0.1828 Train_Acc: 94.712 Val_Loss: 0.1123  BEST VAL Loss: 0.1123  Val_Acc: 96.653

Epoch 52: Validation loss decreased (0.112342 --> 0.112231).  Saving model ...
	 Train_Loss: 0.1825 Train_Acc: 94.534 Val_Loss: 0.1122  BEST VAL Loss: 0.1122  Val_Acc: 96.462

Epoch 53: Validation loss decreased (0.112231 --> 0.112127).  Saving model ...
	 Train_Loss: 0.1823 Train_Acc: 94.450 Val_Loss: 0.1121  BEST VAL Loss: 0.1121  Val_Acc: 95.907

Epoch 54: Validation loss decreased (0.112127 --> 0.111995).  Saving model ...
	 Train_Loss: 0.1821 Train_Acc: 94.353 Val_Loss: 0.1120  BEST VAL Loss: 0.1120  Val_Acc: 96.353

Epoch 55: Validation loss decreased (0.111995 --> 0.111819).  Saving model ...
	 Train_Loss: 0.1818 Train_Acc: 94.568 Val_Loss: 0.1118  BEST VAL Loss: 0.1118  Val_Acc: 96.304

Epoch 56: Validation loss decreased (0.111819 --> 0.111755).  Saving model ...
	 Train_Loss: 0.1816 Train_Acc: 94.648 Val_Loss: 0.1118  BEST VAL Loss: 0.1118  Val_Acc: 96.243

Epoch 57: Validation loss decreased (0.111755 --> 0.111710).  Saving model ...
	 Train_Loss: 0.1813 Train_Acc: 94.511 Val_Loss: 0.1117  BEST VAL Loss: 0.1117  Val_Acc: 95.757

Epoch 58: Validation loss decreased (0.111710 --> 0.111677).  Saving model ...
	 Train_Loss: 0.1813 Train_Acc: 94.202 Val_Loss: 0.1117  BEST VAL Loss: 0.1117  Val_Acc: 96.195

Epoch 59: Validation loss decreased (0.111677 --> 0.111518).  Saving model ...
	 Train_Loss: 0.1812 Train_Acc: 94.335 Val_Loss: 0.1115  BEST VAL Loss: 0.1115  Val_Acc: 96.345

Epoch 60: Validation loss decreased (0.111518 --> 0.111437).  Saving model ...
	 Train_Loss: 0.1809 Train_Acc: 94.661 Val_Loss: 0.1114  BEST VAL Loss: 0.1114  Val_Acc: 96.175

Epoch 61: Validation loss decreased (0.111437 --> 0.111335).  Saving model ...
	 Train_Loss: 0.1807 Train_Acc: 94.648 Val_Loss: 0.1113  BEST VAL Loss: 0.1113  Val_Acc: 96.406

Epoch 62: Validation loss decreased (0.111335 --> 0.111145).  Saving model ...
	 Train_Loss: 0.1804 Train_Acc: 94.614 Val_Loss: 0.1111  BEST VAL Loss: 0.1111  Val_Acc: 96.543

Epoch 63: Validation loss decreased (0.111145 --> 0.111010).  Saving model ...
	 Train_Loss: 0.1803 Train_Acc: 94.546 Val_Loss: 0.1110  BEST VAL Loss: 0.1110  Val_Acc: 96.365

Epoch 64: Validation loss decreased (0.111010 --> 0.110861).  Saving model ...
	 Train_Loss: 0.1801 Train_Acc: 94.612 Val_Loss: 0.1109  BEST VAL Loss: 0.1109  Val_Acc: 96.458

Epoch 65: Validation loss decreased (0.110861 --> 0.110749).  Saving model ...
	 Train_Loss: 0.1798 Train_Acc: 94.640 Val_Loss: 0.1107  BEST VAL Loss: 0.1107  Val_Acc: 96.280

Epoch 66: Validation loss decreased (0.110749 --> 0.110719).  Saving model ...
	 Train_Loss: 0.1796 Train_Acc: 94.611 Val_Loss: 0.1107  BEST VAL Loss: 0.1107  Val_Acc: 95.773

Epoch 67: Validation loss decreased (0.110719 --> 0.110618).  Saving model ...
	 Train_Loss: 0.1795 Train_Acc: 94.415 Val_Loss: 0.1106  BEST VAL Loss: 0.1106  Val_Acc: 96.531

Epoch 68: Validation loss decreased (0.110618 --> 0.110521).  Saving model ...
	 Train_Loss: 0.1793 Train_Acc: 94.431 Val_Loss: 0.1105  BEST VAL Loss: 0.1105  Val_Acc: 96.183

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.1792 Train_Acc: 94.294 Val_Loss: 0.1106  BEST VAL Loss: 0.1105  Val_Acc: 96.122

Epoch 70: Validation loss decreased (0.110521 --> 0.110476).  Saving model ...
	 Train_Loss: 0.1791 Train_Acc: 94.429 Val_Loss: 0.1105  BEST VAL Loss: 0.1105  Val_Acc: 96.329

Epoch 71: Validation loss decreased (0.110476 --> 0.110343).  Saving model ...
	 Train_Loss: 0.1789 Train_Acc: 94.663 Val_Loss: 0.1103  BEST VAL Loss: 0.1103  Val_Acc: 96.329

Epoch 72: Validation loss decreased (0.110343 --> 0.110267).  Saving model ...
	 Train_Loss: 0.1787 Train_Acc: 94.711 Val_Loss: 0.1103  BEST VAL Loss: 0.1103  Val_Acc: 96.369

Epoch 73: Validation loss decreased (0.110267 --> 0.110126).  Saving model ...
	 Train_Loss: 0.1785 Train_Acc: 94.612 Val_Loss: 0.1101  BEST VAL Loss: 0.1101  Val_Acc: 96.389

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.1785 Train_Acc: 94.450 Val_Loss: 0.1102  BEST VAL Loss: 0.1101  Val_Acc: 96.041

Epoch 75: Validation loss decreased (0.110126 --> 0.110093).  Saving model ...
	 Train_Loss: 0.1783 Train_Acc: 94.464 Val_Loss: 0.1101  BEST VAL Loss: 0.1101  Val_Acc: 96.175

Epoch 76: Validation loss decreased (0.110093 --> 0.110036).  Saving model ...
	 Train_Loss: 0.1782 Train_Acc: 94.684 Val_Loss: 0.1100  BEST VAL Loss: 0.1100  Val_Acc: 96.199

Epoch 77: Validation loss decreased (0.110036 --> 0.109923).  Saving model ...
	 Train_Loss: 0.1779 Train_Acc: 94.858 Val_Loss: 0.1099  BEST VAL Loss: 0.1099  Val_Acc: 96.547

Epoch 78: Validation loss decreased (0.109923 --> 0.109833).  Saving model ...
	 Train_Loss: 0.1778 Train_Acc: 94.640 Val_Loss: 0.1098  BEST VAL Loss: 0.1098  Val_Acc: 96.786

Epoch 79: Validation loss decreased (0.109833 --> 0.109728).  Saving model ...
	 Train_Loss: 0.1776 Train_Acc: 94.618 Val_Loss: 0.1097  BEST VAL Loss: 0.1097  Val_Acc: 96.474

Epoch 80: Validation loss decreased (0.109728 --> 0.109684).  Saving model ...
	 Train_Loss: 0.1775 Train_Acc: 94.730 Val_Loss: 0.1097  BEST VAL Loss: 0.1097  Val_Acc: 96.353

Epoch 81: Validation loss decreased (0.109684 --> 0.109631).  Saving model ...
	 Train_Loss: 0.1773 Train_Acc: 94.786 Val_Loss: 0.1096  BEST VAL Loss: 0.1096  Val_Acc: 96.454

Epoch 82: Validation loss decreased (0.109631 --> 0.109550).  Saving model ...
	 Train_Loss: 0.1771 Train_Acc: 94.715 Val_Loss: 0.1095  BEST VAL Loss: 0.1095  Val_Acc: 96.507

Epoch 83: Validation loss decreased (0.109550 --> 0.109444).  Saving model ...
	 Train_Loss: 0.1769 Train_Acc: 94.768 Val_Loss: 0.1094  BEST VAL Loss: 0.1094  Val_Acc: 96.714

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.1768 Train_Acc: 94.678 Val_Loss: 0.1094  BEST VAL Loss: 0.1094  Val_Acc: 96.450

Epoch 85: Validation loss decreased (0.109444 --> 0.109323).  Saving model ...
	 Train_Loss: 0.1766 Train_Acc: 94.751 Val_Loss: 0.1093  BEST VAL Loss: 0.1093  Val_Acc: 96.584

Epoch 86: Validation loss decreased (0.109323 --> 0.109252).  Saving model ...
	 Train_Loss: 0.1764 Train_Acc: 94.840 Val_Loss: 0.1093  BEST VAL Loss: 0.1093  Val_Acc: 96.256

Epoch 87: Validation loss decreased (0.109252 --> 0.109227).  Saving model ...
	 Train_Loss: 0.1763 Train_Acc: 94.612 Val_Loss: 0.1092  BEST VAL Loss: 0.1092  Val_Acc: 96.381

Epoch 88: Validation loss decreased (0.109227 --> 0.109221).  Saving model ...
	 Train_Loss: 0.1762 Train_Acc: 94.533 Val_Loss: 0.1092  BEST VAL Loss: 0.1092  Val_Acc: 95.814

Epoch 89: Validation loss decreased (0.109221 --> 0.109138).  Saving model ...
	 Train_Loss: 0.1761 Train_Acc: 94.639 Val_Loss: 0.1091  BEST VAL Loss: 0.1091  Val_Acc: 96.418

Epoch 90: Validation loss decreased (0.109138 --> 0.109058).  Saving model ...
	 Train_Loss: 0.1760 Train_Acc: 94.661 Val_Loss: 0.1091  BEST VAL Loss: 0.1091  Val_Acc: 96.260

Epoch 91: Validation loss decreased (0.109058 --> 0.109017).  Saving model ...
	 Train_Loss: 0.1758 Train_Acc: 94.703 Val_Loss: 0.1090  BEST VAL Loss: 0.1090  Val_Acc: 96.389

Epoch 92: Validation loss decreased (0.109017 --> 0.108924).  Saving model ...
	 Train_Loss: 0.1757 Train_Acc: 94.787 Val_Loss: 0.1089  BEST VAL Loss: 0.1089  Val_Acc: 96.357

Epoch 93: Validation loss decreased (0.108924 --> 0.108844).  Saving model ...
	 Train_Loss: 0.1756 Train_Acc: 94.756 Val_Loss: 0.1088  BEST VAL Loss: 0.1088  Val_Acc: 96.499

Epoch 94: Validation loss decreased (0.108844 --> 0.108711).  Saving model ...
	 Train_Loss: 0.1754 Train_Acc: 94.865 Val_Loss: 0.1087  BEST VAL Loss: 0.1087  Val_Acc: 96.746

Epoch 95: Validation loss decreased (0.108711 --> 0.108653).  Saving model ...
	 Train_Loss: 0.1753 Train_Acc: 94.516 Val_Loss: 0.1087  BEST VAL Loss: 0.1087  Val_Acc: 96.560

Epoch 96: Validation loss decreased (0.108653 --> 0.108549).  Saving model ...
	 Train_Loss: 0.1752 Train_Acc: 94.653 Val_Loss: 0.1085  BEST VAL Loss: 0.1085  Val_Acc: 96.568

Epoch 97: Validation loss decreased (0.108549 --> 0.108510).  Saving model ...
	 Train_Loss: 0.1751 Train_Acc: 94.845 Val_Loss: 0.1085  BEST VAL Loss: 0.1085  Val_Acc: 96.470

Epoch 98: Validation loss decreased (0.108510 --> 0.108501).  Saving model ...
	 Train_Loss: 0.1750 Train_Acc: 94.409 Val_Loss: 0.1085  BEST VAL Loss: 0.1085  Val_Acc: 96.077

Epoch 99: Validation loss decreased (0.108501 --> 0.108454).  Saving model ...
	 Train_Loss: 0.1750 Train_Acc: 94.574 Val_Loss: 0.1085  BEST VAL Loss: 0.1085  Val_Acc: 96.434

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.47      0.47     92173
           1       0.53      0.54      0.53    105242

    accuracy                           0.50    197415
   macro avg       0.50      0.50      0.50    197415
weighted avg       0.50      0.50      0.50    197415

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.47      0.48     11522
           1       0.54      0.55      0.54     13155

    accuracy                           0.51     24677
   macro avg       0.51      0.51      0.51     24677
weighted avg       0.51      0.51      0.51     24677

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.46      0.46     11522
           1       0.53      0.53      0.53     13155

    accuracy                           0.50     24677
   macro avg       0.50      0.50      0.50     24677
weighted avg       0.50      0.50      0.50     24677

              precision    recall  f1-score   support

           0       0.46      0.46      0.46     11522
           1       0.53      0.53      0.53     13155

    accuracy                           0.50     24677
   macro avg       0.50      0.50      0.50     24677
weighted avg       0.50      0.50      0.50     24677

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.45      0.41      0.43     41273
           1       0.54      0.58      0.56     49614

    accuracy                           0.51     90887
   macro avg       0.50      0.50      0.50     90887
weighted avg       0.50      0.51      0.50     90887

              precision    recall  f1-score   support

           0       0.45      0.41      0.43     41273
           1       0.54      0.58      0.56     49614

    accuracy                           0.51     90887
   macro avg       0.50      0.50      0.50     90887
weighted avg       0.50      0.51      0.50     90887

completed
