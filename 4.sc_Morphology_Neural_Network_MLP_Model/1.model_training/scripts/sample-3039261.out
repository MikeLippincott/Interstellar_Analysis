[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b8a8adff'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '229e9305'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'f5341128'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'df573db3'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_0.100_DMSO_0.025 treatment_name: Thapsigargin_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_0.100_DMSO_0.025
TREATMENT_NAME: Thapsigargin_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'Thapsigargin_1.000_DMSO_0.025']
The dimensions of the data are: (287053, 1270)
Number of total missing values across all columns: 574106
Data Subset Is Off
Wells held out for testing: ['C08' 'K06']
Wells to use for training, validation, and testing ['C02' 'C03' 'C09' 'D06' 'D07' 'K07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.528986).  Saving model ...
	 Train_Loss: 0.5580 Train_Acc: 71.023 Val_Loss: 0.5290  BEST VAL Loss: 0.5290  Val_Acc: 73.700

Epoch 1: Validation loss decreased (0.528986 --> 0.519271).  Saving model ...
	 Train_Loss: 0.5358 Train_Acc: 74.473 Val_Loss: 0.5193  BEST VAL Loss: 0.5193  Val_Acc: 74.911

Epoch 2: Validation loss decreased (0.519271 --> 0.507343).  Saving model ...
	 Train_Loss: 0.5235 Train_Acc: 75.496 Val_Loss: 0.5073  BEST VAL Loss: 0.5073  Val_Acc: 76.903

Epoch 3: Validation loss decreased (0.507343 --> 0.498759).  Saving model ...
	 Train_Loss: 0.5148 Train_Acc: 76.296 Val_Loss: 0.4988  BEST VAL Loss: 0.4988  Val_Acc: 77.857

Epoch 4: Validation loss decreased (0.498759 --> 0.492805).  Saving model ...
	 Train_Loss: 0.5080 Train_Acc: 76.789 Val_Loss: 0.4928  BEST VAL Loss: 0.4928  Val_Acc: 78.091

Epoch 5: Validation loss decreased (0.492805 --> 0.488670).  Saving model ...
	 Train_Loss: 0.5025 Train_Acc: 77.326 Val_Loss: 0.4887  BEST VAL Loss: 0.4887  Val_Acc: 77.731

Epoch 6: Validation loss decreased (0.488670 --> 0.484879).  Saving model ...
	 Train_Loss: 0.4979 Train_Acc: 77.767 Val_Loss: 0.4849  BEST VAL Loss: 0.4849  Val_Acc: 78.316

Epoch 7: Validation loss decreased (0.484879 --> 0.480605).  Saving model ...
	 Train_Loss: 0.4940 Train_Acc: 77.808 Val_Loss: 0.4806  BEST VAL Loss: 0.4806  Val_Acc: 78.994

Epoch 8: Validation loss decreased (0.480605 --> 0.477874).  Saving model ...
	 Train_Loss: 0.4905 Train_Acc: 78.232 Val_Loss: 0.4779  BEST VAL Loss: 0.4779  Val_Acc: 78.877

Epoch 9: Validation loss decreased (0.477874 --> 0.475029).  Saving model ...
	 Train_Loss: 0.4872 Train_Acc: 78.489 Val_Loss: 0.4750  BEST VAL Loss: 0.4750  Val_Acc: 79.471

Epoch 10: Validation loss decreased (0.475029 --> 0.472186).  Saving model ...
	 Train_Loss: 0.4843 Train_Acc: 78.735 Val_Loss: 0.4722  BEST VAL Loss: 0.4722  Val_Acc: 79.536

Epoch 11: Validation loss decreased (0.472186 --> 0.469518).  Saving model ...
	 Train_Loss: 0.4815 Train_Acc: 79.042 Val_Loss: 0.4695  BEST VAL Loss: 0.4695  Val_Acc: 79.906

Epoch 12: Validation loss decreased (0.469518 --> 0.466998).  Saving model ...
	 Train_Loss: 0.4791 Train_Acc: 79.017 Val_Loss: 0.4670  BEST VAL Loss: 0.4670  Val_Acc: 79.980

Epoch 13: Validation loss decreased (0.466998 --> 0.464726).  Saving model ...
	 Train_Loss: 0.4768 Train_Acc: 79.260 Val_Loss: 0.4647  BEST VAL Loss: 0.4647  Val_Acc: 80.345

Epoch 14: Validation loss decreased (0.464726 --> 0.462989).  Saving model ...
	 Train_Loss: 0.4746 Train_Acc: 79.537 Val_Loss: 0.4630  BEST VAL Loss: 0.4630  Val_Acc: 80.004

Epoch 15: Validation loss decreased (0.462989 --> 0.461138).  Saving model ...
	 Train_Loss: 0.4726 Train_Acc: 79.654 Val_Loss: 0.4611  BEST VAL Loss: 0.4611  Val_Acc: 80.387

Epoch 16: Validation loss decreased (0.461138 --> 0.459372).  Saving model ...
	 Train_Loss: 0.4708 Train_Acc: 79.655 Val_Loss: 0.4594  BEST VAL Loss: 0.4594  Val_Acc: 80.326

Epoch 17: Validation loss decreased (0.459372 --> 0.457935).  Saving model ...
	 Train_Loss: 0.4690 Train_Acc: 79.758 Val_Loss: 0.4579  BEST VAL Loss: 0.4579  Val_Acc: 80.373

Epoch 18: Validation loss decreased (0.457935 --> 0.456218).  Saving model ...
	 Train_Loss: 0.4673 Train_Acc: 80.067 Val_Loss: 0.4562  BEST VAL Loss: 0.4562  Val_Acc: 80.972

Epoch 19: Validation loss decreased (0.456218 --> 0.454758).  Saving model ...
	 Train_Loss: 0.4658 Train_Acc: 79.983 Val_Loss: 0.4548  BEST VAL Loss: 0.4548  Val_Acc: 80.481

Epoch 20: Validation loss decreased (0.454758 --> 0.453254).  Saving model ...
	 Train_Loss: 0.4642 Train_Acc: 80.194 Val_Loss: 0.4533  BEST VAL Loss: 0.4533  Val_Acc: 81.004

Epoch 21: Validation loss decreased (0.453254 --> 0.451808).  Saving model ...
	 Train_Loss: 0.4627 Train_Acc: 80.281 Val_Loss: 0.4518  BEST VAL Loss: 0.4518  Val_Acc: 81.196

Epoch 22: Validation loss decreased (0.451808 --> 0.450342).  Saving model ...
	 Train_Loss: 0.4613 Train_Acc: 80.474 Val_Loss: 0.4503  BEST VAL Loss: 0.4503  Val_Acc: 81.416

Epoch 23: Validation loss decreased (0.450342 --> 0.449039).  Saving model ...
	 Train_Loss: 0.4598 Train_Acc: 80.516 Val_Loss: 0.4490  BEST VAL Loss: 0.4490  Val_Acc: 81.631

Epoch 24: Validation loss decreased (0.449039 --> 0.447726).  Saving model ...
	 Train_Loss: 0.4584 Train_Acc: 80.672 Val_Loss: 0.4477  BEST VAL Loss: 0.4477  Val_Acc: 81.697

Epoch 25: Validation loss decreased (0.447726 --> 0.446402).  Saving model ...
	 Train_Loss: 0.4570 Train_Acc: 80.809 Val_Loss: 0.4464  BEST VAL Loss: 0.4464  Val_Acc: 81.655

Epoch 26: Validation loss decreased (0.446402 --> 0.445127).  Saving model ...
	 Train_Loss: 0.4557 Train_Acc: 80.803 Val_Loss: 0.4451  BEST VAL Loss: 0.4451  Val_Acc: 81.505

Epoch 27: Validation loss decreased (0.445127 --> 0.443949).  Saving model ...
	 Train_Loss: 0.4544 Train_Acc: 80.905 Val_Loss: 0.4439  BEST VAL Loss: 0.4439  Val_Acc: 81.561

Epoch 28: Validation loss decreased (0.443949 --> 0.442810).  Saving model ...
	 Train_Loss: 0.4532 Train_Acc: 81.021 Val_Loss: 0.4428  BEST VAL Loss: 0.4428  Val_Acc: 81.711

Epoch 29: Validation loss decreased (0.442810 --> 0.441547).  Saving model ...
	 Train_Loss: 0.4520 Train_Acc: 81.069 Val_Loss: 0.4415  BEST VAL Loss: 0.4415  Val_Acc: 82.300

Epoch 30: Validation loss decreased (0.441547 --> 0.440254).  Saving model ...
	 Train_Loss: 0.4508 Train_Acc: 81.097 Val_Loss: 0.4403  BEST VAL Loss: 0.4403  Val_Acc: 82.001

Epoch 31: Validation loss decreased (0.440254 --> 0.439363).  Saving model ...
	 Train_Loss: 0.4497 Train_Acc: 81.111 Val_Loss: 0.4394  BEST VAL Loss: 0.4394  Val_Acc: 81.809

Epoch 32: Validation loss decreased (0.439363 --> 0.438301).  Saving model ...
	 Train_Loss: 0.4486 Train_Acc: 81.322 Val_Loss: 0.4383  BEST VAL Loss: 0.4383  Val_Acc: 82.230

Epoch 33: Validation loss decreased (0.438301 --> 0.437124).  Saving model ...
	 Train_Loss: 0.4476 Train_Acc: 81.334 Val_Loss: 0.4371  BEST VAL Loss: 0.4371  Val_Acc: 82.440

Epoch 34: Validation loss decreased (0.437124 --> 0.436253).  Saving model ...
	 Train_Loss: 0.4466 Train_Acc: 81.317 Val_Loss: 0.4363  BEST VAL Loss: 0.4363  Val_Acc: 82.197

Epoch 35: Validation loss decreased (0.436253 --> 0.435413).  Saving model ...
	 Train_Loss: 0.4457 Train_Acc: 81.328 Val_Loss: 0.4354  BEST VAL Loss: 0.4354  Val_Acc: 82.001

Epoch 36: Validation loss decreased (0.435413 --> 0.434601).  Saving model ...
	 Train_Loss: 0.4448 Train_Acc: 81.479 Val_Loss: 0.4346  BEST VAL Loss: 0.4346  Val_Acc: 81.874

Epoch 37: Validation loss decreased (0.434601 --> 0.433739).  Saving model ...
	 Train_Loss: 0.4439 Train_Acc: 81.528 Val_Loss: 0.4337  BEST VAL Loss: 0.4337  Val_Acc: 81.795

Epoch 38: Validation loss decreased (0.433739 --> 0.433068).  Saving model ...
	 Train_Loss: 0.4430 Train_Acc: 81.520 Val_Loss: 0.4331  BEST VAL Loss: 0.4331  Val_Acc: 81.322

Epoch 39: Validation loss decreased (0.433068 --> 0.432116).  Saving model ...
	 Train_Loss: 0.4422 Train_Acc: 81.410 Val_Loss: 0.4321  BEST VAL Loss: 0.4321  Val_Acc: 82.824

Epoch 40: Validation loss decreased (0.432116 --> 0.431304).  Saving model ...
	 Train_Loss: 0.4414 Train_Acc: 81.492 Val_Loss: 0.4313  BEST VAL Loss: 0.4313  Val_Acc: 82.333

Epoch 41: Validation loss decreased (0.431304 --> 0.430465).  Saving model ...
	 Train_Loss: 0.4406 Train_Acc: 81.650 Val_Loss: 0.4305  BEST VAL Loss: 0.4305  Val_Acc: 82.688

Epoch 42: Validation loss decreased (0.430465 --> 0.429698).  Saving model ...
	 Train_Loss: 0.4399 Train_Acc: 81.414 Val_Loss: 0.4297  BEST VAL Loss: 0.4297  Val_Acc: 82.276

Epoch 43: Validation loss decreased (0.429698 --> 0.428941).  Saving model ...
	 Train_Loss: 0.4391 Train_Acc: 81.652 Val_Loss: 0.4289  BEST VAL Loss: 0.4289  Val_Acc: 82.543

Epoch 44: Validation loss decreased (0.428941 --> 0.428181).  Saving model ...
	 Train_Loss: 0.4384 Train_Acc: 81.715 Val_Loss: 0.4282  BEST VAL Loss: 0.4282  Val_Acc: 82.651

Epoch 45: Validation loss decreased (0.428181 --> 0.427525).  Saving model ...
	 Train_Loss: 0.4377 Train_Acc: 81.760 Val_Loss: 0.4275  BEST VAL Loss: 0.4275  Val_Acc: 82.295

Epoch 46: Validation loss decreased (0.427525 --> 0.426805).  Saving model ...
	 Train_Loss: 0.4370 Train_Acc: 81.838 Val_Loss: 0.4268  BEST VAL Loss: 0.4268  Val_Acc: 82.683

Epoch 47: Validation loss decreased (0.426805 --> 0.426214).  Saving model ...
	 Train_Loss: 0.4363 Train_Acc: 81.888 Val_Loss: 0.4262  BEST VAL Loss: 0.4262  Val_Acc: 82.290

Epoch 48: Validation loss decreased (0.426214 --> 0.425495).  Saving model ...
	 Train_Loss: 0.4357 Train_Acc: 81.844 Val_Loss: 0.4255  BEST VAL Loss: 0.4255  Val_Acc: 82.767

Epoch 49: Validation loss decreased (0.425495 --> 0.424813).  Saving model ...
	 Train_Loss: 0.4350 Train_Acc: 81.944 Val_Loss: 0.4248  BEST VAL Loss: 0.4248  Val_Acc: 82.810

Epoch 50: Validation loss decreased (0.424813 --> 0.424231).  Saving model ...
	 Train_Loss: 0.4344 Train_Acc: 81.865 Val_Loss: 0.4242  BEST VAL Loss: 0.4242  Val_Acc: 82.314

Epoch 51: Validation loss decreased (0.424231 --> 0.423732).  Saving model ...
	 Train_Loss: 0.4338 Train_Acc: 81.857 Val_Loss: 0.4237  BEST VAL Loss: 0.4237  Val_Acc: 82.356

Epoch 52: Validation loss decreased (0.423732 --> 0.423125).  Saving model ...
	 Train_Loss: 0.4332 Train_Acc: 81.900 Val_Loss: 0.4231  BEST VAL Loss: 0.4231  Val_Acc: 82.870

Epoch 53: Validation loss decreased (0.423125 --> 0.422486).  Saving model ...
	 Train_Loss: 0.4326 Train_Acc: 81.914 Val_Loss: 0.4225  BEST VAL Loss: 0.4225  Val_Acc: 82.955

Epoch 54: Validation loss decreased (0.422486 --> 0.421979).  Saving model ...
	 Train_Loss: 0.4321 Train_Acc: 81.916 Val_Loss: 0.4220  BEST VAL Loss: 0.4220  Val_Acc: 82.342

Epoch 55: Validation loss decreased (0.421979 --> 0.421401).  Saving model ...
	 Train_Loss: 0.4316 Train_Acc: 81.984 Val_Loss: 0.4214  BEST VAL Loss: 0.4214  Val_Acc: 83.043

Epoch 56: Validation loss decreased (0.421401 --> 0.421002).  Saving model ...
	 Train_Loss: 0.4311 Train_Acc: 82.004 Val_Loss: 0.4210  BEST VAL Loss: 0.4210  Val_Acc: 82.290

Epoch 57: Validation loss decreased (0.421002 --> 0.420520).  Saving model ...
	 Train_Loss: 0.4305 Train_Acc: 82.107 Val_Loss: 0.4205  BEST VAL Loss: 0.4205  Val_Acc: 82.669

Epoch 58: Validation loss decreased (0.420520 --> 0.419989).  Saving model ...
	 Train_Loss: 0.4301 Train_Acc: 81.989 Val_Loss: 0.4200  BEST VAL Loss: 0.4200  Val_Acc: 82.847

Epoch 59: Validation loss decreased (0.419989 --> 0.419554).  Saving model ...
	 Train_Loss: 0.4296 Train_Acc: 82.074 Val_Loss: 0.4196  BEST VAL Loss: 0.4196  Val_Acc: 82.945

Epoch 60: Validation loss decreased (0.419554 --> 0.419046).  Saving model ...
	 Train_Loss: 0.4291 Train_Acc: 82.129 Val_Loss: 0.4190  BEST VAL Loss: 0.4190  Val_Acc: 83.006

Epoch 61: Validation loss decreased (0.419046 --> 0.418674).  Saving model ...
	 Train_Loss: 0.4286 Train_Acc: 82.172 Val_Loss: 0.4187  BEST VAL Loss: 0.4187  Val_Acc: 82.599

Epoch 62: Validation loss decreased (0.418674 --> 0.418211).  Saving model ...
	 Train_Loss: 0.4281 Train_Acc: 82.183 Val_Loss: 0.4182  BEST VAL Loss: 0.4182  Val_Acc: 83.048

Epoch 63: Validation loss decreased (0.418211 --> 0.417857).  Saving model ...
	 Train_Loss: 0.4277 Train_Acc: 82.099 Val_Loss: 0.4179  BEST VAL Loss: 0.4179  Val_Acc: 82.211

Epoch 64: Validation loss decreased (0.417857 --> 0.417390).  Saving model ...
	 Train_Loss: 0.4272 Train_Acc: 82.271 Val_Loss: 0.4174  BEST VAL Loss: 0.4174  Val_Acc: 83.118

Epoch 65: Validation loss decreased (0.417390 --> 0.416932).  Saving model ...
	 Train_Loss: 0.4268 Train_Acc: 82.218 Val_Loss: 0.4169  BEST VAL Loss: 0.4169  Val_Acc: 83.207

Epoch 66: Validation loss decreased (0.416932 --> 0.416494).  Saving model ...
	 Train_Loss: 0.4264 Train_Acc: 82.215 Val_Loss: 0.4165  BEST VAL Loss: 0.4165  Val_Acc: 83.081

Epoch 67: Validation loss decreased (0.416494 --> 0.416107).  Saving model ...
	 Train_Loss: 0.4260 Train_Acc: 82.174 Val_Loss: 0.4161  BEST VAL Loss: 0.4161  Val_Acc: 82.623

Epoch 68: Validation loss decreased (0.416107 --> 0.415715).  Saving model ...
	 Train_Loss: 0.4256 Train_Acc: 82.283 Val_Loss: 0.4157  BEST VAL Loss: 0.4157  Val_Acc: 83.221

Epoch 69: Validation loss decreased (0.415715 --> 0.415349).  Saving model ...
	 Train_Loss: 0.4252 Train_Acc: 82.237 Val_Loss: 0.4153  BEST VAL Loss: 0.4153  Val_Acc: 83.025

Epoch 70: Validation loss decreased (0.415349 --> 0.415004).  Saving model ...
	 Train_Loss: 0.4248 Train_Acc: 82.337 Val_Loss: 0.4150  BEST VAL Loss: 0.4150  Val_Acc: 82.796

Epoch 71: Validation loss decreased (0.415004 --> 0.414621).  Saving model ...
	 Train_Loss: 0.4244 Train_Acc: 82.333 Val_Loss: 0.4146  BEST VAL Loss: 0.4146  Val_Acc: 83.118

Epoch 72: Validation loss decreased (0.414621 --> 0.414221).  Saving model ...
	 Train_Loss: 0.4240 Train_Acc: 82.348 Val_Loss: 0.4142  BEST VAL Loss: 0.4142  Val_Acc: 83.273

Epoch 73: Validation loss decreased (0.414221 --> 0.413866).  Saving model ...
	 Train_Loss: 0.4237 Train_Acc: 82.350 Val_Loss: 0.4139  BEST VAL Loss: 0.4139  Val_Acc: 83.043

Epoch 74: Validation loss decreased (0.413866 --> 0.413543).  Saving model ...
	 Train_Loss: 0.4233 Train_Acc: 82.302 Val_Loss: 0.4135  BEST VAL Loss: 0.4135  Val_Acc: 83.193

Epoch 75: Validation loss decreased (0.413543 --> 0.413209).  Saving model ...
	 Train_Loss: 0.4229 Train_Acc: 82.387 Val_Loss: 0.4132  BEST VAL Loss: 0.4132  Val_Acc: 83.076

Epoch 76: Validation loss decreased (0.413209 --> 0.412910).  Saving model ...
	 Train_Loss: 0.4226 Train_Acc: 82.257 Val_Loss: 0.4129  BEST VAL Loss: 0.4129  Val_Acc: 82.884

Epoch 77: Validation loss decreased (0.412910 --> 0.412612).  Saving model ...
	 Train_Loss: 0.4223 Train_Acc: 82.390 Val_Loss: 0.4126  BEST VAL Loss: 0.4126  Val_Acc: 82.828

Epoch 78: Validation loss decreased (0.412612 --> 0.412320).  Saving model ...
	 Train_Loss: 0.4220 Train_Acc: 82.309 Val_Loss: 0.4123  BEST VAL Loss: 0.4123  Val_Acc: 82.969

Epoch 79: Validation loss decreased (0.412320 --> 0.411955).  Saving model ...
	 Train_Loss: 0.4216 Train_Acc: 82.423 Val_Loss: 0.4120  BEST VAL Loss: 0.4120  Val_Acc: 83.249

Epoch 80: Validation loss decreased (0.411955 --> 0.411668).  Saving model ...
	 Train_Loss: 0.4213 Train_Acc: 82.338 Val_Loss: 0.4117  BEST VAL Loss: 0.4117  Val_Acc: 83.029

Epoch 81: Validation loss decreased (0.411668 --> 0.411395).  Saving model ...
	 Train_Loss: 0.4210 Train_Acc: 82.385 Val_Loss: 0.4114  BEST VAL Loss: 0.4114  Val_Acc: 82.889

Epoch 82: Validation loss decreased (0.411395 --> 0.411189).  Saving model ...
	 Train_Loss: 0.4206 Train_Acc: 82.446 Val_Loss: 0.4112  BEST VAL Loss: 0.4112  Val_Acc: 82.903

Epoch 83: Validation loss decreased (0.411189 --> 0.410881).  Saving model ...
	 Train_Loss: 0.4204 Train_Acc: 82.437 Val_Loss: 0.4109  BEST VAL Loss: 0.4109  Val_Acc: 83.071

Epoch 84: Validation loss decreased (0.410881 --> 0.410591).  Saving model ...
	 Train_Loss: 0.4200 Train_Acc: 82.456 Val_Loss: 0.4106  BEST VAL Loss: 0.4106  Val_Acc: 83.301

Epoch 85: Validation loss decreased (0.410591 --> 0.410356).  Saving model ...
	 Train_Loss: 0.4197 Train_Acc: 82.601 Val_Loss: 0.4104  BEST VAL Loss: 0.4104  Val_Acc: 82.908

Epoch 86: Validation loss decreased (0.410356 --> 0.410076).  Saving model ...
	 Train_Loss: 0.4195 Train_Acc: 82.371 Val_Loss: 0.4101  BEST VAL Loss: 0.4101  Val_Acc: 83.095

Epoch 87: Validation loss decreased (0.410076 --> 0.409811).  Saving model ...
	 Train_Loss: 0.4192 Train_Acc: 82.438 Val_Loss: 0.4098  BEST VAL Loss: 0.4098  Val_Acc: 83.142

Epoch 88: Validation loss decreased (0.409811 --> 0.409580).  Saving model ...
	 Train_Loss: 0.4189 Train_Acc: 82.515 Val_Loss: 0.4096  BEST VAL Loss: 0.4096  Val_Acc: 82.936

Epoch 89: Validation loss decreased (0.409580 --> 0.409373).  Saving model ...
	 Train_Loss: 0.4186 Train_Acc: 82.565 Val_Loss: 0.4094  BEST VAL Loss: 0.4094  Val_Acc: 82.800

Epoch 90: Validation loss decreased (0.409373 --> 0.409103).  Saving model ...
	 Train_Loss: 0.4183 Train_Acc: 82.504 Val_Loss: 0.4091  BEST VAL Loss: 0.4091  Val_Acc: 83.418

Epoch 91: Validation loss decreased (0.409103 --> 0.408823).  Saving model ...
	 Train_Loss: 0.4181 Train_Acc: 82.524 Val_Loss: 0.4088  BEST VAL Loss: 0.4088  Val_Acc: 83.277

Epoch 92: Validation loss decreased (0.408823 --> 0.408612).  Saving model ...
	 Train_Loss: 0.4178 Train_Acc: 82.624 Val_Loss: 0.4086  BEST VAL Loss: 0.4086  Val_Acc: 83.188

Epoch 93: Validation loss decreased (0.408612 --> 0.408395).  Saving model ...
	 Train_Loss: 0.4175 Train_Acc: 82.555 Val_Loss: 0.4084  BEST VAL Loss: 0.4084  Val_Acc: 83.273

Epoch 94: Validation loss decreased (0.408395 --> 0.408175).  Saving model ...
	 Train_Loss: 0.4173 Train_Acc: 82.509 Val_Loss: 0.4082  BEST VAL Loss: 0.4082  Val_Acc: 83.254

Epoch 95: Validation loss decreased (0.408175 --> 0.407988).  Saving model ...
	 Train_Loss: 0.4170 Train_Acc: 82.696 Val_Loss: 0.4080  BEST VAL Loss: 0.4080  Val_Acc: 82.898

Epoch 96: Validation loss decreased (0.407988 --> 0.407747).  Saving model ...
	 Train_Loss: 0.4168 Train_Acc: 82.527 Val_Loss: 0.4077  BEST VAL Loss: 0.4077  Val_Acc: 83.188

Epoch 97: Validation loss decreased (0.407747 --> 0.407511).  Saving model ...
	 Train_Loss: 0.4165 Train_Acc: 82.600 Val_Loss: 0.4075  BEST VAL Loss: 0.4075  Val_Acc: 83.132

Epoch 98: Validation loss decreased (0.407511 --> 0.407276).  Saving model ...
	 Train_Loss: 0.4163 Train_Acc: 82.665 Val_Loss: 0.4073  BEST VAL Loss: 0.4073  Val_Acc: 83.801

Epoch 99: Validation loss decreased (0.407276 --> 0.407064).  Saving model ...
	 Train_Loss: 0.4160 Train_Acc: 82.714 Val_Loss: 0.4071  BEST VAL Loss: 0.4071  Val_Acc: 83.399

LPS_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.47      0.48     82968
           1       0.52      0.53      0.52     88098

    accuracy                           0.50    171066
   macro avg       0.50      0.50      0.50    171066
weighted avg       0.50      0.50      0.50    171066

LPS_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.46      0.47     10371
           1       0.52      0.54      0.53     11013

    accuracy                           0.50     21384
   macro avg       0.50      0.50      0.50     21384
weighted avg       0.50      0.50      0.50     21384

LPS_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.47      0.48     10371
           1       0.52      0.53      0.53     11013

    accuracy                           0.50     21384
   macro avg       0.50      0.50      0.50     21384
weighted avg       0.50      0.50      0.50     21384

              precision    recall  f1-score   support

           0       0.49      0.47      0.48     10371
           1       0.52      0.53      0.53     11013

    accuracy                           0.50     21384
   macro avg       0.50      0.50      0.50     21384
weighted avg       0.50      0.50      0.50     21384

LPS_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.45      0.46     34887
           1       0.52      0.55      0.53     38332

    accuracy                           0.50     73219
   macro avg       0.50      0.50      0.50     73219
weighted avg       0.50      0.50      0.50     73219

              precision    recall  f1-score   support

           0       0.47      0.45      0.46     34887
           1       0.52      0.55      0.53     38332

    accuracy                           0.50     73219
   macro avg       0.50      0.50      0.50     73219
weighted avg       0.50      0.50      0.50     73219

completed
