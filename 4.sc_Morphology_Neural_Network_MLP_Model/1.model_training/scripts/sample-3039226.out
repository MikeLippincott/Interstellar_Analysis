[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1f1f42f2'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '4e65e016'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '60f90cd2'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '03ba35a1'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_0.100_DMSO_0.025 treatment_name: Thapsigargin_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: Thapsigargin_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (28694, 1276)
Number of total missing values across all columns: 57388
Data Subset Is Off
Wells held out for testing: ['D14' 'L22']
Wells to use for training, validation, and testing ['D15' 'K14' 'K15' 'L18' 'L19' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.444207).  Saving model ...
	 Train_Loss: 0.5621 Train_Acc: 67.402 Val_Loss: 0.4442  BEST VAL Loss: 0.4442  Val_Acc: 81.138

Epoch 1: Validation loss decreased (0.444207 --> 0.420003).  Saving model ...
	 Train_Loss: 0.5209 Train_Acc: 72.159 Val_Loss: 0.4200  BEST VAL Loss: 0.4200  Val_Acc: 82.549

Epoch 2: Validation loss decreased (0.420003 --> 0.407164).  Saving model ...
	 Train_Loss: 0.5030 Train_Acc: 72.701 Val_Loss: 0.4072  BEST VAL Loss: 0.4072  Val_Acc: 83.678

Epoch 3: Validation loss decreased (0.407164 --> 0.401380).  Saving model ...
	 Train_Loss: 0.4890 Train_Acc: 73.971 Val_Loss: 0.4014  BEST VAL Loss: 0.4014  Val_Acc: 83.349

Epoch 4: Validation loss decreased (0.401380 --> 0.395693).  Saving model ...
	 Train_Loss: 0.4852 Train_Acc: 74.371 Val_Loss: 0.3957  BEST VAL Loss: 0.3957  Val_Acc: 84.760

Epoch 5: Validation loss did not decrease
	 Train_Loss: 0.4830 Train_Acc: 71.871 Val_Loss: 0.3991  BEST VAL Loss: 0.3957  Val_Acc: 81.091

Epoch 6: Validation loss did not decrease
	 Train_Loss: 0.4830 Train_Acc: 73.071 Val_Loss: 0.4012  BEST VAL Loss: 0.3957  Val_Acc: 83.678

Epoch 7: Validation loss did not decrease
	 Train_Loss: 0.4818 Train_Acc: 73.847 Val_Loss: 0.3989  BEST VAL Loss: 0.3957  Val_Acc: 84.760

Epoch 8: Validation loss did not decrease
	 Train_Loss: 0.4800 Train_Acc: 71.895 Val_Loss: 0.3960  BEST VAL Loss: 0.3957  Val_Acc: 82.738

Epoch 9: Validation loss decreased (0.395693 --> 0.391584).  Saving model ...
	 Train_Loss: 0.4756 Train_Acc: 74.406 Val_Loss: 0.3916  BEST VAL Loss: 0.3916  Val_Acc: 85.372

Epoch 10: Validation loss decreased (0.391584 --> 0.388227).  Saving model ...
	 Train_Loss: 0.4730 Train_Acc: 74.700 Val_Loss: 0.3882  BEST VAL Loss: 0.3882  Val_Acc: 85.748

Epoch 11: Validation loss decreased (0.388227 --> 0.382936).  Saving model ...
	 Train_Loss: 0.4686 Train_Acc: 75.041 Val_Loss: 0.3829  BEST VAL Loss: 0.3829  Val_Acc: 85.701

Epoch 12: Validation loss decreased (0.382936 --> 0.381015).  Saving model ...
	 Train_Loss: 0.4655 Train_Acc: 73.953 Val_Loss: 0.3810  BEST VAL Loss: 0.3810  Val_Acc: 83.114

Epoch 13: Validation loss decreased (0.381015 --> 0.377338).  Saving model ...
	 Train_Loss: 0.4617 Train_Acc: 73.871 Val_Loss: 0.3773  BEST VAL Loss: 0.3773  Val_Acc: 85.748

Epoch 14: Validation loss decreased (0.377338 --> 0.373308).  Saving model ...
	 Train_Loss: 0.4583 Train_Acc: 75.100 Val_Loss: 0.3733  BEST VAL Loss: 0.3733  Val_Acc: 86.453

Epoch 15: Validation loss decreased (0.373308 --> 0.370395).  Saving model ...
	 Train_Loss: 0.4553 Train_Acc: 75.806 Val_Loss: 0.3704  BEST VAL Loss: 0.3704  Val_Acc: 86.500

Epoch 16: Validation loss decreased (0.370395 --> 0.366553).  Saving model ...
	 Train_Loss: 0.4528 Train_Acc: 75.259 Val_Loss: 0.3666  BEST VAL Loss: 0.3666  Val_Acc: 86.924

Epoch 17: Validation loss decreased (0.366553 --> 0.364015).  Saving model ...
	 Train_Loss: 0.4496 Train_Acc: 77.017 Val_Loss: 0.3640  BEST VAL Loss: 0.3640  Val_Acc: 87.112

Epoch 18: Validation loss decreased (0.364015 --> 0.362937).  Saving model ...
	 Train_Loss: 0.4499 Train_Acc: 74.871 Val_Loss: 0.3629  BEST VAL Loss: 0.3629  Val_Acc: 85.607

Epoch 19: Validation loss decreased (0.362937 --> 0.362723).  Saving model ...
	 Train_Loss: 0.4484 Train_Acc: 74.571 Val_Loss: 0.3627  BEST VAL Loss: 0.3627  Val_Acc: 84.807

Epoch 20: Validation loss decreased (0.362723 --> 0.360844).  Saving model ...
	 Train_Loss: 0.4467 Train_Acc: 75.223 Val_Loss: 0.3608  BEST VAL Loss: 0.3608  Val_Acc: 85.607

Epoch 21: Validation loss decreased (0.360844 --> 0.359146).  Saving model ...
	 Train_Loss: 0.4452 Train_Acc: 75.676 Val_Loss: 0.3591  BEST VAL Loss: 0.3591  Val_Acc: 85.936

Epoch 22: Validation loss decreased (0.359146 --> 0.356858).  Saving model ...
	 Train_Loss: 0.4433 Train_Acc: 76.717 Val_Loss: 0.3569  BEST VAL Loss: 0.3569  Val_Acc: 87.253

Epoch 23: Validation loss decreased (0.356858 --> 0.354334).  Saving model ...
	 Train_Loss: 0.4408 Train_Acc: 76.811 Val_Loss: 0.3543  BEST VAL Loss: 0.3543  Val_Acc: 87.488

Epoch 24: Validation loss decreased (0.354334 --> 0.352211).  Saving model ...
	 Train_Loss: 0.4385 Train_Acc: 76.811 Val_Loss: 0.3522  BEST VAL Loss: 0.3522  Val_Acc: 87.253

Epoch 25: Validation loss decreased (0.352211 --> 0.349924).  Saving model ...
	 Train_Loss: 0.4364 Train_Acc: 77.382 Val_Loss: 0.3499  BEST VAL Loss: 0.3499  Val_Acc: 87.535

Epoch 26: Validation loss decreased (0.349924 --> 0.349099).  Saving model ...
	 Train_Loss: 0.4348 Train_Acc: 76.764 Val_Loss: 0.3491  BEST VAL Loss: 0.3491  Val_Acc: 86.783

Epoch 27: Validation loss decreased (0.349099 --> 0.347827).  Saving model ...
	 Train_Loss: 0.4333 Train_Acc: 76.694 Val_Loss: 0.3478  BEST VAL Loss: 0.3478  Val_Acc: 87.300

Epoch 28: Validation loss decreased (0.347827 --> 0.346030).  Saving model ...
	 Train_Loss: 0.4311 Train_Acc: 78.035 Val_Loss: 0.3460  BEST VAL Loss: 0.3460  Val_Acc: 87.582

Epoch 29: Validation loss decreased (0.346030 --> 0.344547).  Saving model ...
	 Train_Loss: 0.4287 Train_Acc: 78.005 Val_Loss: 0.3445  BEST VAL Loss: 0.3445  Val_Acc: 87.865

Epoch 30: Validation loss decreased (0.344547 --> 0.343692).  Saving model ...
	 Train_Loss: 0.4263 Train_Acc: 77.776 Val_Loss: 0.3437  BEST VAL Loss: 0.3437  Val_Acc: 87.817

Epoch 31: Validation loss decreased (0.343692 --> 0.342561).  Saving model ...
	 Train_Loss: 0.4245 Train_Acc: 77.729 Val_Loss: 0.3426  BEST VAL Loss: 0.3426  Val_Acc: 88.053

Epoch 32: Validation loss decreased (0.342561 --> 0.341598).  Saving model ...
	 Train_Loss: 0.4230 Train_Acc: 77.717 Val_Loss: 0.3416  BEST VAL Loss: 0.3416  Val_Acc: 87.206

Epoch 33: Validation loss decreased (0.341598 --> 0.341489).  Saving model ...
	 Train_Loss: 0.4228 Train_Acc: 74.453 Val_Loss: 0.3415  BEST VAL Loss: 0.3415  Val_Acc: 84.431

Epoch 34: Validation loss decreased (0.341489 --> 0.341125).  Saving model ...
	 Train_Loss: 0.4228 Train_Acc: 74.682 Val_Loss: 0.3411  BEST VAL Loss: 0.3411  Val_Acc: 85.701

Epoch 35: Validation loss decreased (0.341125 --> 0.340224).  Saving model ...
	 Train_Loss: 0.4221 Train_Acc: 75.323 Val_Loss: 0.3402  BEST VAL Loss: 0.3402  Val_Acc: 86.124

Epoch 36: Validation loss decreased (0.340224 --> 0.339499).  Saving model ...
	 Train_Loss: 0.4214 Train_Acc: 76.164 Val_Loss: 0.3395  BEST VAL Loss: 0.3395  Val_Acc: 87.488

Epoch 37: Validation loss decreased (0.339499 --> 0.338592).  Saving model ...
	 Train_Loss: 0.4211 Train_Acc: 75.318 Val_Loss: 0.3386  BEST VAL Loss: 0.3386  Val_Acc: 86.077

Epoch 38: Validation loss decreased (0.338592 --> 0.337519).  Saving model ...
	 Train_Loss: 0.4207 Train_Acc: 76.076 Val_Loss: 0.3375  BEST VAL Loss: 0.3375  Val_Acc: 87.018

Epoch 39: Validation loss decreased (0.337519 --> 0.336915).  Saving model ...
	 Train_Loss: 0.4199 Train_Acc: 76.500 Val_Loss: 0.3369  BEST VAL Loss: 0.3369  Val_Acc: 86.830

Epoch 40: Validation loss decreased (0.336915 --> 0.335701).  Saving model ...
	 Train_Loss: 0.4188 Train_Acc: 77.023 Val_Loss: 0.3357  BEST VAL Loss: 0.3357  Val_Acc: 87.629

Epoch 41: Validation loss decreased (0.335701 --> 0.334667).  Saving model ...
	 Train_Loss: 0.4174 Train_Acc: 78.111 Val_Loss: 0.3347  BEST VAL Loss: 0.3347  Val_Acc: 88.100

Epoch 42: Validation loss decreased (0.334667 --> 0.334167).  Saving model ...
	 Train_Loss: 0.4161 Train_Acc: 77.452 Val_Loss: 0.3342  BEST VAL Loss: 0.3342  Val_Acc: 87.582

Epoch 43: Validation loss decreased (0.334167 --> 0.332985).  Saving model ...
	 Train_Loss: 0.4148 Train_Acc: 78.352 Val_Loss: 0.3330  BEST VAL Loss: 0.3330  Val_Acc: 88.006

Epoch 44: Validation loss decreased (0.332985 --> 0.332063).  Saving model ...
	 Train_Loss: 0.4136 Train_Acc: 77.946 Val_Loss: 0.3321  BEST VAL Loss: 0.3321  Val_Acc: 88.147

Epoch 45: Validation loss decreased (0.332063 --> 0.330716).  Saving model ...
	 Train_Loss: 0.4129 Train_Acc: 78.229 Val_Loss: 0.3307  BEST VAL Loss: 0.3307  Val_Acc: 87.253

Epoch 46: Validation loss decreased (0.330716 --> 0.329816).  Saving model ...
	 Train_Loss: 0.4117 Train_Acc: 78.140 Val_Loss: 0.3298  BEST VAL Loss: 0.3298  Val_Acc: 88.194

Epoch 47: Validation loss decreased (0.329816 --> 0.328822).  Saving model ...
	 Train_Loss: 0.4105 Train_Acc: 78.017 Val_Loss: 0.3288  BEST VAL Loss: 0.3288  Val_Acc: 88.852

Epoch 48: Validation loss decreased (0.328822 --> 0.328685).  Saving model ...
	 Train_Loss: 0.4099 Train_Acc: 77.229 Val_Loss: 0.3287  BEST VAL Loss: 0.3287  Val_Acc: 86.877

Epoch 49: Validation loss decreased (0.328685 --> 0.327936).  Saving model ...
	 Train_Loss: 0.4096 Train_Acc: 78.146 Val_Loss: 0.3279  BEST VAL Loss: 0.3279  Val_Acc: 88.241

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.4107 Train_Acc: 73.906 Val_Loss: 0.3282  BEST VAL Loss: 0.3279  Val_Acc: 82.408

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.4108 Train_Acc: 72.142 Val_Loss: 0.3286  BEST VAL Loss: 0.3279  Val_Acc: 83.772

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.4102 Train_Acc: 74.224 Val_Loss: 0.3281  BEST VAL Loss: 0.3279  Val_Acc: 85.654

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.4097 Train_Acc: 74.929 Val_Loss: 0.3280  BEST VAL Loss: 0.3279  Val_Acc: 86.312

Epoch 54: Validation loss decreased (0.327936 --> 0.327818).  Saving model ...
	 Train_Loss: 0.4100 Train_Acc: 74.041 Val_Loss: 0.3278  BEST VAL Loss: 0.3278  Val_Acc: 84.948

Epoch 55: Validation loss decreased (0.327818 --> 0.327437).  Saving model ...
	 Train_Loss: 0.4098 Train_Acc: 75.312 Val_Loss: 0.3274  BEST VAL Loss: 0.3274  Val_Acc: 86.971

Epoch 56: Validation loss decreased (0.327437 --> 0.326819).  Saving model ...
	 Train_Loss: 0.4094 Train_Acc: 76.276 Val_Loss: 0.3268  BEST VAL Loss: 0.3268  Val_Acc: 87.676

Epoch 57: Validation loss decreased (0.326819 --> 0.325981).  Saving model ...
	 Train_Loss: 0.4090 Train_Acc: 76.700 Val_Loss: 0.3260  BEST VAL Loss: 0.3260  Val_Acc: 87.112

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.4099 Train_Acc: 75.841 Val_Loss: 0.3263  BEST VAL Loss: 0.3260  Val_Acc: 86.124

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.4109 Train_Acc: 72.136 Val_Loss: 0.3273  BEST VAL Loss: 0.3260  Val_Acc: 84.055

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.4113 Train_Acc: 75.235 Val_Loss: 0.3274  BEST VAL Loss: 0.3260  Val_Acc: 86.830

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.4112 Train_Acc: 75.753 Val_Loss: 0.3275  BEST VAL Loss: 0.3260  Val_Acc: 86.171

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.4117 Train_Acc: 75.729 Val_Loss: 0.3275  BEST VAL Loss: 0.3260  Val_Acc: 85.748

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.4116 Train_Acc: 76.705 Val_Loss: 0.3274  BEST VAL Loss: 0.3260  Val_Acc: 87.253

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.4113 Train_Acc: 76.376 Val_Loss: 0.3272  BEST VAL Loss: 0.3260  Val_Acc: 87.394

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.4110 Train_Acc: 76.529 Val_Loss: 0.3268  BEST VAL Loss: 0.3260  Val_Acc: 87.300

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.4105 Train_Acc: 76.994 Val_Loss: 0.3263  BEST VAL Loss: 0.3260  Val_Acc: 87.582

Epoch 67: Validation loss decreased (0.325981 --> 0.325787).  Saving model ...
	 Train_Loss: 0.4100 Train_Acc: 77.082 Val_Loss: 0.3258  BEST VAL Loss: 0.3258  Val_Acc: 88.100

Epoch 68: Validation loss decreased (0.325787 --> 0.325024).  Saving model ...
	 Train_Loss: 0.4093 Train_Acc: 77.329 Val_Loss: 0.3250  BEST VAL Loss: 0.3250  Val_Acc: 88.147

Epoch 69: Validation loss decreased (0.325024 --> 0.324682).  Saving model ...
	 Train_Loss: 0.4088 Train_Acc: 77.835 Val_Loss: 0.3247  BEST VAL Loss: 0.3247  Val_Acc: 88.053

Epoch 70: Validation loss decreased (0.324682 --> 0.324225).  Saving model ...
	 Train_Loss: 0.4080 Train_Acc: 77.893 Val_Loss: 0.3242  BEST VAL Loss: 0.3242  Val_Acc: 88.194

Epoch 71: Validation loss decreased (0.324225 --> 0.323662).  Saving model ...
	 Train_Loss: 0.4076 Train_Acc: 78.035 Val_Loss: 0.3237  BEST VAL Loss: 0.3237  Val_Acc: 88.147

Epoch 72: Validation loss decreased (0.323662 --> 0.323095).  Saving model ...
	 Train_Loss: 0.4067 Train_Acc: 78.093 Val_Loss: 0.3231  BEST VAL Loss: 0.3231  Val_Acc: 88.382

Epoch 73: Validation loss decreased (0.323095 --> 0.322230).  Saving model ...
	 Train_Loss: 0.4059 Train_Acc: 78.829 Val_Loss: 0.3222  BEST VAL Loss: 0.3222  Val_Acc: 88.758

Epoch 74: Validation loss decreased (0.322230 --> 0.321568).  Saving model ...
	 Train_Loss: 0.4051 Train_Acc: 79.105 Val_Loss: 0.3216  BEST VAL Loss: 0.3216  Val_Acc: 88.758

Epoch 75: Validation loss decreased (0.321568 --> 0.321522).  Saving model ...
	 Train_Loss: 0.4048 Train_Acc: 77.923 Val_Loss: 0.3215  BEST VAL Loss: 0.3215  Val_Acc: 88.053

Epoch 76: Validation loss decreased (0.321522 --> 0.321144).  Saving model ...
	 Train_Loss: 0.4045 Train_Acc: 76.547 Val_Loss: 0.3211  BEST VAL Loss: 0.3211  Val_Acc: 86.453

Epoch 77: Validation loss decreased (0.321144 --> 0.320847).  Saving model ...
	 Train_Loss: 0.4039 Train_Acc: 77.541 Val_Loss: 0.3208  BEST VAL Loss: 0.3208  Val_Acc: 88.382

Epoch 78: Validation loss decreased (0.320847 --> 0.320488).  Saving model ...
	 Train_Loss: 0.4042 Train_Acc: 77.417 Val_Loss: 0.3205  BEST VAL Loss: 0.3205  Val_Acc: 87.394

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.4042 Train_Acc: 75.853 Val_Loss: 0.3208  BEST VAL Loss: 0.3205  Val_Acc: 83.302

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.4039 Train_Acc: 75.882 Val_Loss: 0.3208  BEST VAL Loss: 0.3205  Val_Acc: 85.889

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.4042 Train_Acc: 76.394 Val_Loss: 0.3208  BEST VAL Loss: 0.3205  Val_Acc: 86.500

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.4044 Train_Acc: 76.811 Val_Loss: 0.3206  BEST VAL Loss: 0.3205  Val_Acc: 87.535

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.4049 Train_Acc: 77.147 Val_Loss: 0.3207  BEST VAL Loss: 0.3205  Val_Acc: 87.770

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.4051 Train_Acc: 74.371 Val_Loss: 0.3211  BEST VAL Loss: 0.3205  Val_Acc: 85.042

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.4053 Train_Acc: 75.588 Val_Loss: 0.3211  BEST VAL Loss: 0.3205  Val_Acc: 86.265

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.4057 Train_Acc: 74.324 Val_Loss: 0.3216  BEST VAL Loss: 0.3205  Val_Acc: 86.830

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.4058 Train_Acc: 76.259 Val_Loss: 0.3216  BEST VAL Loss: 0.3205  Val_Acc: 86.830

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.4056 Train_Acc: 77.347 Val_Loss: 0.3214  BEST VAL Loss: 0.3205  Val_Acc: 88.053

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.4053 Train_Acc: 77.588 Val_Loss: 0.3213  BEST VAL Loss: 0.3205  Val_Acc: 87.959

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.4048 Train_Acc: 77.935 Val_Loss: 0.3208  BEST VAL Loss: 0.3205  Val_Acc: 88.194

Epoch 91: Validation loss decreased (0.320488 --> 0.320465).  Saving model ...
	 Train_Loss: 0.4044 Train_Acc: 78.282 Val_Loss: 0.3205  BEST VAL Loss: 0.3205  Val_Acc: 88.194

Epoch 92: Validation loss decreased (0.320465 --> 0.320227).  Saving model ...
	 Train_Loss: 0.4041 Train_Acc: 78.040 Val_Loss: 0.3202  BEST VAL Loss: 0.3202  Val_Acc: 88.570

Epoch 93: Validation loss decreased (0.320227 --> 0.319624).  Saving model ...
	 Train_Loss: 0.4037 Train_Acc: 79.070 Val_Loss: 0.3196  BEST VAL Loss: 0.3196  Val_Acc: 88.006

Epoch 94: Validation loss decreased (0.319624 --> 0.319050).  Saving model ...
	 Train_Loss: 0.4034 Train_Acc: 78.105 Val_Loss: 0.3190  BEST VAL Loss: 0.3190  Val_Acc: 88.523

Epoch 95: Validation loss decreased (0.319050 --> 0.318474).  Saving model ...
	 Train_Loss: 0.4031 Train_Acc: 78.582 Val_Loss: 0.3185  BEST VAL Loss: 0.3185  Val_Acc: 88.241

Epoch 96: Validation loss decreased (0.318474 --> 0.317857).  Saving model ...
	 Train_Loss: 0.4028 Train_Acc: 78.681 Val_Loss: 0.3179  BEST VAL Loss: 0.3179  Val_Acc: 89.040

Epoch 97: Validation loss decreased (0.317857 --> 0.317380).  Saving model ...
	 Train_Loss: 0.4021 Train_Acc: 79.352 Val_Loss: 0.3174  BEST VAL Loss: 0.3174  Val_Acc: 88.711

Epoch 98: Validation loss decreased (0.317380 --> 0.317265).  Saving model ...
	 Train_Loss: 0.4017 Train_Acc: 78.482 Val_Loss: 0.3173  BEST VAL Loss: 0.3173  Val_Acc: 88.288

Epoch 99: Validation loss decreased (0.317265 --> 0.317119).  Saving model ...
	 Train_Loss: 0.4015 Train_Acc: 75.717 Val_Loss: 0.3171  BEST VAL Loss: 0.3171  Val_Acc: 84.149

Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.58      0.54      8634
           1       0.49      0.43      0.46      8370

    accuracy                           0.50     17004
   macro avg       0.50      0.50      0.50     17004
weighted avg       0.50      0.50      0.50     17004

Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.59      0.55      1080
           1       0.51      0.43      0.46      1046

    accuracy                           0.51      2126
   macro avg       0.51      0.51      0.51      2126
weighted avg       0.51      0.51      0.51      2126

Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.60      0.55      1079
           1       0.49      0.40      0.44      1047

    accuracy                           0.50      2126
   macro avg       0.50      0.50      0.50      2126
weighted avg       0.50      0.50      0.50      2126

              precision    recall  f1-score   support

           0       0.51      0.60      0.55      1079
           1       0.49      0.40      0.44      1047

    accuracy                           0.50      2126
   macro avg       0.50      0.50      0.50      2126
weighted avg       0.50      0.50      0.50      2126

Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.56      0.61      0.58      4135
           1       0.45      0.41      0.43      3303

    accuracy                           0.52      7438
   macro avg       0.51      0.51      0.51      7438
weighted avg       0.51      0.52      0.52      7438

              precision    recall  f1-score   support

           0       0.56      0.61      0.58      4135
           1       0.45      0.41      0.43      3303

    accuracy                           0.52      7438
   macro avg       0.51      0.51      0.51      7438
weighted avg       0.51      0.52      0.52      7438

completed
