[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '2175d070'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'ac8c6463'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '19731e19'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '05756ee8'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_100.000_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_100.000_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (298032, 1270)
Number of total missing values across all columns: 596064
Data Subset Is Off
Wells held out for testing: ['C08' 'J08']
Wells to use for training, validation, and testing ['C02' 'C03' 'C09' 'J02' 'J03' 'J09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.685614).  Saving model ...
	 Train_Loss: 0.6898 Train_Acc: 52.934 Val_Loss: 0.6856  BEST VAL Loss: 0.6856  Val_Acc: 54.221

Epoch 1: Validation loss decreased (0.685614 --> 0.683696).  Saving model ...
	 Train_Loss: 0.6870 Train_Acc: 54.593 Val_Loss: 0.6837  BEST VAL Loss: 0.6837  Val_Acc: 55.562

Epoch 2: Validation loss decreased (0.683696 --> 0.681669).  Saving model ...
	 Train_Loss: 0.6847 Train_Acc: 55.859 Val_Loss: 0.6817  BEST VAL Loss: 0.6817  Val_Acc: 56.859

Epoch 3: Validation loss decreased (0.681669 --> 0.679797).  Saving model ...
	 Train_Loss: 0.6827 Train_Acc: 56.782 Val_Loss: 0.6798  BEST VAL Loss: 0.6798  Val_Acc: 58.143

Epoch 4: Validation loss decreased (0.679797 --> 0.677934).  Saving model ...
	 Train_Loss: 0.6807 Train_Acc: 57.577 Val_Loss: 0.6779  BEST VAL Loss: 0.6779  Val_Acc: 58.568

Epoch 5: Validation loss decreased (0.677934 --> 0.676103).  Saving model ...
	 Train_Loss: 0.6789 Train_Acc: 58.315 Val_Loss: 0.6761  BEST VAL Loss: 0.6761  Val_Acc: 59.196

Epoch 6: Validation loss decreased (0.676103 --> 0.674397).  Saving model ...
	 Train_Loss: 0.6771 Train_Acc: 58.671 Val_Loss: 0.6744  BEST VAL Loss: 0.6744  Val_Acc: 59.670

Epoch 7: Validation loss decreased (0.674397 --> 0.672913).  Saving model ...
	 Train_Loss: 0.6755 Train_Acc: 59.112 Val_Loss: 0.6729  BEST VAL Loss: 0.6729  Val_Acc: 59.931

Epoch 8: Validation loss decreased (0.672913 --> 0.671572).  Saving model ...
	 Train_Loss: 0.6739 Train_Acc: 59.701 Val_Loss: 0.6716  BEST VAL Loss: 0.6716  Val_Acc: 60.015

Epoch 9: Validation loss decreased (0.671572 --> 0.670216).  Saving model ...
	 Train_Loss: 0.6725 Train_Acc: 60.153 Val_Loss: 0.6702  BEST VAL Loss: 0.6702  Val_Acc: 60.599

Epoch 10: Validation loss decreased (0.670216 --> 0.668874).  Saving model ...
	 Train_Loss: 0.6711 Train_Acc: 60.209 Val_Loss: 0.6689  BEST VAL Loss: 0.6689  Val_Acc: 60.962

Epoch 11: Validation loss decreased (0.668874 --> 0.667712).  Saving model ...
	 Train_Loss: 0.6698 Train_Acc: 60.677 Val_Loss: 0.6677  BEST VAL Loss: 0.6677  Val_Acc: 61.153

Epoch 12: Validation loss decreased (0.667712 --> 0.666485).  Saving model ...
	 Train_Loss: 0.6686 Train_Acc: 60.950 Val_Loss: 0.6665  BEST VAL Loss: 0.6665  Val_Acc: 61.312

Epoch 13: Validation loss decreased (0.666485 --> 0.665410).  Saving model ...
	 Train_Loss: 0.6674 Train_Acc: 61.186 Val_Loss: 0.6654  BEST VAL Loss: 0.6654  Val_Acc: 61.485

Epoch 14: Validation loss decreased (0.665410 --> 0.664366).  Saving model ...
	 Train_Loss: 0.6662 Train_Acc: 61.498 Val_Loss: 0.6644  BEST VAL Loss: 0.6644  Val_Acc: 61.604

Epoch 15: Validation loss decreased (0.664366 --> 0.663355).  Saving model ...
	 Train_Loss: 0.6651 Train_Acc: 61.668 Val_Loss: 0.6634  BEST VAL Loss: 0.6634  Val_Acc: 62.060

Epoch 16: Validation loss decreased (0.663355 --> 0.662405).  Saving model ...
	 Train_Loss: 0.6641 Train_Acc: 61.989 Val_Loss: 0.6624  BEST VAL Loss: 0.6624  Val_Acc: 62.202

Epoch 17: Validation loss decreased (0.662405 --> 0.661445).  Saving model ...
	 Train_Loss: 0.6631 Train_Acc: 61.958 Val_Loss: 0.6614  BEST VAL Loss: 0.6614  Val_Acc: 62.627

Epoch 18: Validation loss decreased (0.661445 --> 0.660636).  Saving model ...
	 Train_Loss: 0.6621 Train_Acc: 62.362 Val_Loss: 0.6606  BEST VAL Loss: 0.6606  Val_Acc: 62.578

Epoch 19: Validation loss decreased (0.660636 --> 0.659775).  Saving model ...
	 Train_Loss: 0.6612 Train_Acc: 62.423 Val_Loss: 0.6598  BEST VAL Loss: 0.6598  Val_Acc: 62.981

Epoch 20: Validation loss decreased (0.659775 --> 0.658886).  Saving model ...
	 Train_Loss: 0.6603 Train_Acc: 62.588 Val_Loss: 0.6589  BEST VAL Loss: 0.6589  Val_Acc: 63.450

Epoch 21: Validation loss decreased (0.658886 --> 0.658126).  Saving model ...
	 Train_Loss: 0.6595 Train_Acc: 62.668 Val_Loss: 0.6581  BEST VAL Loss: 0.6581  Val_Acc: 63.056

Epoch 22: Validation loss decreased (0.658126 --> 0.657281).  Saving model ...
	 Train_Loss: 0.6586 Train_Acc: 62.945 Val_Loss: 0.6573  BEST VAL Loss: 0.6573  Val_Acc: 63.618

Epoch 23: Validation loss decreased (0.657281 --> 0.656475).  Saving model ...
	 Train_Loss: 0.6578 Train_Acc: 63.262 Val_Loss: 0.6565  BEST VAL Loss: 0.6565  Val_Acc: 63.601

Epoch 24: Validation loss decreased (0.656475 --> 0.655709).  Saving model ...
	 Train_Loss: 0.6570 Train_Acc: 63.194 Val_Loss: 0.6557  BEST VAL Loss: 0.6557  Val_Acc: 63.561

Epoch 25: Validation loss decreased (0.655709 --> 0.654949).  Saving model ...
	 Train_Loss: 0.6562 Train_Acc: 63.337 Val_Loss: 0.6549  BEST VAL Loss: 0.6549  Val_Acc: 63.809

Epoch 26: Validation loss decreased (0.654949 --> 0.654181).  Saving model ...
	 Train_Loss: 0.6555 Train_Acc: 63.389 Val_Loss: 0.6542  BEST VAL Loss: 0.6542  Val_Acc: 64.296

Epoch 27: Validation loss decreased (0.654181 --> 0.653469).  Saving model ...
	 Train_Loss: 0.6548 Train_Acc: 63.568 Val_Loss: 0.6535  BEST VAL Loss: 0.6535  Val_Acc: 64.265

Epoch 28: Validation loss decreased (0.653469 --> 0.652693).  Saving model ...
	 Train_Loss: 0.6540 Train_Acc: 63.584 Val_Loss: 0.6527  BEST VAL Loss: 0.6527  Val_Acc: 64.535

Epoch 29: Validation loss decreased (0.652693 --> 0.651992).  Saving model ...
	 Train_Loss: 0.6533 Train_Acc: 63.814 Val_Loss: 0.6520  BEST VAL Loss: 0.6520  Val_Acc: 64.442

Epoch 30: Validation loss decreased (0.651992 --> 0.651336).  Saving model ...
	 Train_Loss: 0.6526 Train_Acc: 63.939 Val_Loss: 0.6513  BEST VAL Loss: 0.6513  Val_Acc: 64.579

Epoch 31: Validation loss decreased (0.651336 --> 0.650660).  Saving model ...
	 Train_Loss: 0.6519 Train_Acc: 63.887 Val_Loss: 0.6507  BEST VAL Loss: 0.6507  Val_Acc: 64.893

Epoch 32: Validation loss decreased (0.650660 --> 0.649982).  Saving model ...
	 Train_Loss: 0.6513 Train_Acc: 64.028 Val_Loss: 0.6500  BEST VAL Loss: 0.6500  Val_Acc: 64.942

Epoch 33: Validation loss decreased (0.649982 --> 0.649324).  Saving model ...
	 Train_Loss: 0.6506 Train_Acc: 64.104 Val_Loss: 0.6493  BEST VAL Loss: 0.6493  Val_Acc: 65.137

Epoch 34: Validation loss decreased (0.649324 --> 0.648656).  Saving model ...
	 Train_Loss: 0.6499 Train_Acc: 64.115 Val_Loss: 0.6487  BEST VAL Loss: 0.6487  Val_Acc: 65.194

Epoch 35: Validation loss decreased (0.648656 --> 0.647978).  Saving model ...
	 Train_Loss: 0.6493 Train_Acc: 64.327 Val_Loss: 0.6480  BEST VAL Loss: 0.6480  Val_Acc: 65.314

Epoch 36: Validation loss decreased (0.647978 --> 0.647316).  Saving model ...
	 Train_Loss: 0.6487 Train_Acc: 64.485 Val_Loss: 0.6473  BEST VAL Loss: 0.6473  Val_Acc: 65.137

Epoch 37: Validation loss decreased (0.647316 --> 0.646638).  Saving model ...
	 Train_Loss: 0.6481 Train_Acc: 64.489 Val_Loss: 0.6466  BEST VAL Loss: 0.6466  Val_Acc: 65.517

Epoch 38: Validation loss decreased (0.646638 --> 0.645989).  Saving model ...
	 Train_Loss: 0.6475 Train_Acc: 64.491 Val_Loss: 0.6460  BEST VAL Loss: 0.6460  Val_Acc: 65.703

Epoch 39: Validation loss decreased (0.645989 --> 0.645414).  Saving model ...
	 Train_Loss: 0.6469 Train_Acc: 64.666 Val_Loss: 0.6454  BEST VAL Loss: 0.6454  Val_Acc: 65.774

Epoch 40: Validation loss decreased (0.645414 --> 0.644735).  Saving model ...
	 Train_Loss: 0.6463 Train_Acc: 64.746 Val_Loss: 0.6447  BEST VAL Loss: 0.6447  Val_Acc: 66.124

Epoch 41: Validation loss decreased (0.644735 --> 0.644098).  Saving model ...
	 Train_Loss: 0.6458 Train_Acc: 64.726 Val_Loss: 0.6441  BEST VAL Loss: 0.6441  Val_Acc: 65.942

Epoch 42: Validation loss decreased (0.644098 --> 0.643424).  Saving model ...
	 Train_Loss: 0.6452 Train_Acc: 65.074 Val_Loss: 0.6434  BEST VAL Loss: 0.6434  Val_Acc: 66.119

Epoch 43: Validation loss decreased (0.643424 --> 0.642758).  Saving model ...
	 Train_Loss: 0.6446 Train_Acc: 64.912 Val_Loss: 0.6428  BEST VAL Loss: 0.6428  Val_Acc: 66.283

Epoch 44: Validation loss decreased (0.642758 --> 0.642101).  Saving model ...
	 Train_Loss: 0.6440 Train_Acc: 65.122 Val_Loss: 0.6421  BEST VAL Loss: 0.6421  Val_Acc: 66.367

Epoch 45: Validation loss decreased (0.642101 --> 0.641449).  Saving model ...
	 Train_Loss: 0.6435 Train_Acc: 64.970 Val_Loss: 0.6414  BEST VAL Loss: 0.6414  Val_Acc: 66.624

Epoch 46: Validation loss decreased (0.641449 --> 0.640854).  Saving model ...
	 Train_Loss: 0.6429 Train_Acc: 65.117 Val_Loss: 0.6409  BEST VAL Loss: 0.6409  Val_Acc: 66.770

Epoch 47: Validation loss decreased (0.640854 --> 0.640304).  Saving model ...
	 Train_Loss: 0.6424 Train_Acc: 65.242 Val_Loss: 0.6403  BEST VAL Loss: 0.6403  Val_Acc: 66.429

Epoch 48: Validation loss decreased (0.640304 --> 0.639696).  Saving model ...
	 Train_Loss: 0.6419 Train_Acc: 65.332 Val_Loss: 0.6397  BEST VAL Loss: 0.6397  Val_Acc: 66.717

Epoch 49: Validation loss decreased (0.639696 --> 0.639158).  Saving model ...
	 Train_Loss: 0.6413 Train_Acc: 65.432 Val_Loss: 0.6392  BEST VAL Loss: 0.6392  Val_Acc: 66.659

Epoch 50: Validation loss decreased (0.639158 --> 0.638608).  Saving model ...
	 Train_Loss: 0.6408 Train_Acc: 65.519 Val_Loss: 0.6386  BEST VAL Loss: 0.6386  Val_Acc: 66.526

Epoch 51: Validation loss decreased (0.638608 --> 0.638016).  Saving model ...
	 Train_Loss: 0.6403 Train_Acc: 65.507 Val_Loss: 0.6380  BEST VAL Loss: 0.6380  Val_Acc: 66.987

Epoch 52: Validation loss decreased (0.638016 --> 0.637541).  Saving model ...
	 Train_Loss: 0.6398 Train_Acc: 65.550 Val_Loss: 0.6375  BEST VAL Loss: 0.6375  Val_Acc: 66.580

Epoch 53: Validation loss decreased (0.637541 --> 0.636953).  Saving model ...
	 Train_Loss: 0.6393 Train_Acc: 65.460 Val_Loss: 0.6370  BEST VAL Loss: 0.6370  Val_Acc: 67.306

Epoch 54: Validation loss decreased (0.636953 --> 0.636403).  Saving model ...
	 Train_Loss: 0.6388 Train_Acc: 65.707 Val_Loss: 0.6364  BEST VAL Loss: 0.6364  Val_Acc: 67.018

Epoch 55: Validation loss decreased (0.636403 --> 0.635850).  Saving model ...
	 Train_Loss: 0.6383 Train_Acc: 65.597 Val_Loss: 0.6359  BEST VAL Loss: 0.6359  Val_Acc: 67.412

Epoch 56: Validation loss decreased (0.635850 --> 0.635296).  Saving model ...
	 Train_Loss: 0.6379 Train_Acc: 65.826 Val_Loss: 0.6353  BEST VAL Loss: 0.6353  Val_Acc: 67.257

Epoch 57: Validation loss decreased (0.635296 --> 0.634760).  Saving model ...
	 Train_Loss: 0.6374 Train_Acc: 65.748 Val_Loss: 0.6348  BEST VAL Loss: 0.6348  Val_Acc: 67.434

Epoch 58: Validation loss decreased (0.634760 --> 0.634241).  Saving model ...
	 Train_Loss: 0.6369 Train_Acc: 65.862 Val_Loss: 0.6342  BEST VAL Loss: 0.6342  Val_Acc: 67.115

Epoch 59: Validation loss decreased (0.634241 --> 0.633670).  Saving model ...
	 Train_Loss: 0.6364 Train_Acc: 65.894 Val_Loss: 0.6337  BEST VAL Loss: 0.6337  Val_Acc: 67.460

Epoch 60: Validation loss decreased (0.633670 --> 0.633133).  Saving model ...
	 Train_Loss: 0.6360 Train_Acc: 65.858 Val_Loss: 0.6331  BEST VAL Loss: 0.6331  Val_Acc: 67.518

Epoch 61: Validation loss decreased (0.633133 --> 0.632620).  Saving model ...
	 Train_Loss: 0.6356 Train_Acc: 65.786 Val_Loss: 0.6326  BEST VAL Loss: 0.6326  Val_Acc: 67.615

Epoch 62: Validation loss decreased (0.632620 --> 0.632097).  Saving model ...
	 Train_Loss: 0.6351 Train_Acc: 65.942 Val_Loss: 0.6321  BEST VAL Loss: 0.6321  Val_Acc: 67.832

Epoch 63: Validation loss decreased (0.632097 --> 0.631591).  Saving model ...
	 Train_Loss: 0.6347 Train_Acc: 66.073 Val_Loss: 0.6316  BEST VAL Loss: 0.6316  Val_Acc: 67.602

Epoch 64: Validation loss decreased (0.631591 --> 0.631138).  Saving model ...
	 Train_Loss: 0.6342 Train_Acc: 66.039 Val_Loss: 0.6311  BEST VAL Loss: 0.6311  Val_Acc: 67.562

Epoch 65: Validation loss decreased (0.631138 --> 0.630709).  Saving model ...
	 Train_Loss: 0.6338 Train_Acc: 66.087 Val_Loss: 0.6307  BEST VAL Loss: 0.6307  Val_Acc: 67.589

Epoch 66: Validation loss decreased (0.630709 --> 0.630212).  Saving model ...
	 Train_Loss: 0.6334 Train_Acc: 66.090 Val_Loss: 0.6302  BEST VAL Loss: 0.6302  Val_Acc: 67.669

Epoch 67: Validation loss decreased (0.630212 --> 0.629714).  Saving model ...
	 Train_Loss: 0.6330 Train_Acc: 66.009 Val_Loss: 0.6297  BEST VAL Loss: 0.6297  Val_Acc: 67.916

Epoch 68: Validation loss decreased (0.629714 --> 0.629256).  Saving model ...
	 Train_Loss: 0.6326 Train_Acc: 66.365 Val_Loss: 0.6293  BEST VAL Loss: 0.6293  Val_Acc: 67.947

Epoch 69: Validation loss decreased (0.629256 --> 0.628812).  Saving model ...
	 Train_Loss: 0.6322 Train_Acc: 66.220 Val_Loss: 0.6288  BEST VAL Loss: 0.6288  Val_Acc: 67.624

Epoch 70: Validation loss decreased (0.628812 --> 0.628392).  Saving model ...
	 Train_Loss: 0.6318 Train_Acc: 66.201 Val_Loss: 0.6284  BEST VAL Loss: 0.6284  Val_Acc: 67.580

Epoch 71: Validation loss decreased (0.628392 --> 0.627963).  Saving model ...
	 Train_Loss: 0.6314 Train_Acc: 66.243 Val_Loss: 0.6280  BEST VAL Loss: 0.6280  Val_Acc: 67.761

Epoch 72: Validation loss decreased (0.627963 --> 0.627507).  Saving model ...
	 Train_Loss: 0.6310 Train_Acc: 66.271 Val_Loss: 0.6275  BEST VAL Loss: 0.6275  Val_Acc: 68.195

Epoch 73: Validation loss decreased (0.627507 --> 0.627060).  Saving model ...
	 Train_Loss: 0.6306 Train_Acc: 66.383 Val_Loss: 0.6271  BEST VAL Loss: 0.6271  Val_Acc: 67.761

Epoch 74: Validation loss decreased (0.627060 --> 0.626663).  Saving model ...
	 Train_Loss: 0.6302 Train_Acc: 66.324 Val_Loss: 0.6267  BEST VAL Loss: 0.6267  Val_Acc: 67.620

Epoch 75: Validation loss decreased (0.626663 --> 0.626237).  Saving model ...
	 Train_Loss: 0.6299 Train_Acc: 66.292 Val_Loss: 0.6262  BEST VAL Loss: 0.6262  Val_Acc: 68.063

Epoch 76: Validation loss decreased (0.626237 --> 0.625855).  Saving model ...
	 Train_Loss: 0.6295 Train_Acc: 66.421 Val_Loss: 0.6259  BEST VAL Loss: 0.6259  Val_Acc: 67.753

Epoch 77: Validation loss decreased (0.625855 --> 0.625395).  Saving model ...
	 Train_Loss: 0.6291 Train_Acc: 66.392 Val_Loss: 0.6254  BEST VAL Loss: 0.6254  Val_Acc: 68.204

Epoch 78: Validation loss decreased (0.625395 --> 0.625008).  Saving model ...
	 Train_Loss: 0.6288 Train_Acc: 66.436 Val_Loss: 0.6250  BEST VAL Loss: 0.6250  Val_Acc: 68.018

Epoch 79: Validation loss decreased (0.625008 --> 0.624639).  Saving model ...
	 Train_Loss: 0.6284 Train_Acc: 66.356 Val_Loss: 0.6246  BEST VAL Loss: 0.6246  Val_Acc: 67.801

Epoch 80: Validation loss decreased (0.624639 --> 0.624236).  Saving model ...
	 Train_Loss: 0.6281 Train_Acc: 66.428 Val_Loss: 0.6242  BEST VAL Loss: 0.6242  Val_Acc: 68.209

Epoch 81: Validation loss decreased (0.624236 --> 0.623860).  Saving model ...
	 Train_Loss: 0.6277 Train_Acc: 66.475 Val_Loss: 0.6239  BEST VAL Loss: 0.6239  Val_Acc: 68.093

Epoch 82: Validation loss decreased (0.623860 --> 0.623470).  Saving model ...
	 Train_Loss: 0.6274 Train_Acc: 66.418 Val_Loss: 0.6235  BEST VAL Loss: 0.6235  Val_Acc: 68.129

Epoch 83: Validation loss decreased (0.623470 --> 0.623073).  Saving model ...
	 Train_Loss: 0.6271 Train_Acc: 66.597 Val_Loss: 0.6231  BEST VAL Loss: 0.6231  Val_Acc: 68.425

Epoch 84: Validation loss decreased (0.623073 --> 0.622686).  Saving model ...
	 Train_Loss: 0.6268 Train_Acc: 66.448 Val_Loss: 0.6227  BEST VAL Loss: 0.6227  Val_Acc: 68.439

Epoch 85: Validation loss decreased (0.622686 --> 0.622351).  Saving model ...
	 Train_Loss: 0.6264 Train_Acc: 66.455 Val_Loss: 0.6224  BEST VAL Loss: 0.6224  Val_Acc: 68.518

Epoch 86: Validation loss decreased (0.622351 --> 0.621969).  Saving model ...
	 Train_Loss: 0.6261 Train_Acc: 66.698 Val_Loss: 0.6220  BEST VAL Loss: 0.6220  Val_Acc: 68.417

Epoch 87: Validation loss decreased (0.621969 --> 0.621585).  Saving model ...
	 Train_Loss: 0.6258 Train_Acc: 66.653 Val_Loss: 0.6216  BEST VAL Loss: 0.6216  Val_Acc: 68.372

Epoch 88: Validation loss decreased (0.621585 --> 0.621276).  Saving model ...
	 Train_Loss: 0.6255 Train_Acc: 66.750 Val_Loss: 0.6213  BEST VAL Loss: 0.6213  Val_Acc: 68.023

Epoch 89: Validation loss decreased (0.621276 --> 0.620909).  Saving model ...
	 Train_Loss: 0.6251 Train_Acc: 66.733 Val_Loss: 0.6209  BEST VAL Loss: 0.6209  Val_Acc: 68.456

Epoch 90: Validation loss decreased (0.620909 --> 0.620561).  Saving model ...
	 Train_Loss: 0.6248 Train_Acc: 66.647 Val_Loss: 0.6206  BEST VAL Loss: 0.6206  Val_Acc: 68.523

Epoch 91: Validation loss decreased (0.620561 --> 0.620185).  Saving model ...
	 Train_Loss: 0.6245 Train_Acc: 66.652 Val_Loss: 0.6202  BEST VAL Loss: 0.6202  Val_Acc: 68.452

Epoch 92: Validation loss decreased (0.620185 --> 0.619901).  Saving model ...
	 Train_Loss: 0.6242 Train_Acc: 66.728 Val_Loss: 0.6199  BEST VAL Loss: 0.6199  Val_Acc: 67.894

Epoch 93: Validation loss decreased (0.619901 --> 0.619595).  Saving model ...
	 Train_Loss: 0.6239 Train_Acc: 66.742 Val_Loss: 0.6196  BEST VAL Loss: 0.6196  Val_Acc: 68.160

Epoch 94: Validation loss decreased (0.619595 --> 0.619267).  Saving model ...
	 Train_Loss: 0.6237 Train_Acc: 66.721 Val_Loss: 0.6193  BEST VAL Loss: 0.6193  Val_Acc: 68.687

Epoch 95: Validation loss decreased (0.619267 --> 0.618922).  Saving model ...
	 Train_Loss: 0.6234 Train_Acc: 66.798 Val_Loss: 0.6189  BEST VAL Loss: 0.6189  Val_Acc: 68.642

Epoch 96: Validation loss decreased (0.618922 --> 0.618585).  Saving model ...
	 Train_Loss: 0.6231 Train_Acc: 66.876 Val_Loss: 0.6186  BEST VAL Loss: 0.6186  Val_Acc: 68.549

Epoch 97: Validation loss decreased (0.618585 --> 0.618265).  Saving model ...
	 Train_Loss: 0.6228 Train_Acc: 66.833 Val_Loss: 0.6183  BEST VAL Loss: 0.6183  Val_Acc: 68.279

Epoch 98: Validation loss decreased (0.618265 --> 0.617947).  Saving model ...
	 Train_Loss: 0.6225 Train_Acc: 67.032 Val_Loss: 0.6179  BEST VAL Loss: 0.6179  Val_Acc: 68.359

Epoch 99: Validation loss decreased (0.617947 --> 0.617648).  Saving model ...
	 Train_Loss: 0.6222 Train_Acc: 66.843 Val_Loss: 0.6176  BEST VAL Loss: 0.6176  Val_Acc: 68.288

LPS_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.69      0.73      0.71     82968
           1       0.76      0.72      0.74     97752

    accuracy                           0.73    180720
   macro avg       0.72      0.73      0.72    180720
weighted avg       0.73      0.72      0.73    180720

LPS_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.65      0.68      0.66     10371
           1       0.72      0.68      0.70     12220

    accuracy                           0.68     22591
   macro avg       0.68      0.68      0.68     22591
weighted avg       0.68      0.68      0.68     22591

LPS_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.65      0.68      0.66     10371
           1       0.72      0.69      0.70     12220

    accuracy                           0.68     22591
   macro avg       0.68      0.68      0.68     22591
weighted avg       0.69      0.68      0.68     22591

              precision    recall  f1-score   support

           0       0.65      0.68      0.66     10371
           1       0.72      0.69      0.70     12220

    accuracy                           0.68     22591
   macro avg       0.68      0.68      0.68     22591
weighted avg       0.69      0.68      0.68     22591

LPS_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.58      0.77      0.66     34887
           1       0.69      0.48      0.57     37243

    accuracy                           0.62     72130
   macro avg       0.64      0.63      0.62     72130
weighted avg       0.64      0.62      0.62     72130

              precision    recall  f1-score   support

           0       0.58      0.77      0.66     34887
           1       0.69      0.48      0.57     37243

    accuracy                           0.62     72130
   macro avg       0.64      0.63      0.62     72130
weighted avg       0.64      0.62      0.62     72130

completed
