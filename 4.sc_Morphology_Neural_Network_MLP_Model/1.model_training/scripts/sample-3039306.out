[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'bd193cb2'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '4c01400b'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd57229cb'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '9b05eb6c'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_100.000_DMSO_0.025 treatment_name: H2O2_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_100.000_DMSO_0.025
TREATMENT_NAME: H2O2_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['H2O2_100.000_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (399971, 1270)
Number of total missing values across all columns: 799942
Data Subset Is Off
Wells held out for testing: ['I10' 'J08']
Wells to use for training, validation, and testing ['H04' 'I04' 'H05' 'I05' 'H10' 'H11' 'I11' 'J02' 'J03' 'J09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.486215).  Saving model ...
	 Train_Loss: 0.5564 Train_Acc: 71.768 Val_Loss: 0.4862  BEST VAL Loss: 0.4862  Val_Acc: 77.310

Epoch 1: Validation loss decreased (0.486215 --> 0.461840).  Saving model ...
	 Train_Loss: 0.5161 Train_Acc: 77.123 Val_Loss: 0.4618  BEST VAL Loss: 0.4618  Val_Acc: 79.407

Epoch 2: Validation loss decreased (0.461840 --> 0.448235).  Saving model ...
	 Train_Loss: 0.4920 Train_Acc: 79.020 Val_Loss: 0.4482  BEST VAL Loss: 0.4482  Val_Acc: 80.461

Epoch 3: Validation loss decreased (0.448235 --> 0.432104).  Saving model ...
	 Train_Loss: 0.4746 Train_Acc: 80.237 Val_Loss: 0.4321  BEST VAL Loss: 0.4321  Val_Acc: 82.732

Epoch 4: Validation loss decreased (0.432104 --> 0.420330).  Saving model ...
	 Train_Loss: 0.4609 Train_Acc: 81.204 Val_Loss: 0.4203  BEST VAL Loss: 0.4203  Val_Acc: 83.154

Epoch 5: Validation loss decreased (0.420330 --> 0.409674).  Saving model ...
	 Train_Loss: 0.4498 Train_Acc: 81.861 Val_Loss: 0.4097  BEST VAL Loss: 0.4097  Val_Acc: 83.828

Epoch 6: Validation loss decreased (0.409674 --> 0.402116).  Saving model ...
	 Train_Loss: 0.4408 Train_Acc: 82.200 Val_Loss: 0.4021  BEST VAL Loss: 0.4021  Val_Acc: 83.645

Epoch 7: Validation loss decreased (0.402116 --> 0.394980).  Saving model ...
	 Train_Loss: 0.4332 Train_Acc: 82.547 Val_Loss: 0.3950  BEST VAL Loss: 0.3950  Val_Acc: 84.492

Epoch 8: Validation loss decreased (0.394980 --> 0.388725).  Saving model ...
	 Train_Loss: 0.4267 Train_Acc: 82.819 Val_Loss: 0.3887  BEST VAL Loss: 0.3887  Val_Acc: 84.600

Epoch 9: Validation loss decreased (0.388725 --> 0.384134).  Saving model ...
	 Train_Loss: 0.4209 Train_Acc: 83.122 Val_Loss: 0.3841  BEST VAL Loss: 0.3841  Val_Acc: 84.863

Epoch 10: Validation loss decreased (0.384134 --> 0.382351).  Saving model ...
	 Train_Loss: 0.4159 Train_Acc: 83.226 Val_Loss: 0.3824  BEST VAL Loss: 0.3824  Val_Acc: 83.522

Epoch 11: Validation loss decreased (0.382351 --> 0.377841).  Saving model ...
	 Train_Loss: 0.4113 Train_Acc: 83.469 Val_Loss: 0.3778  BEST VAL Loss: 0.3778  Val_Acc: 85.324

Epoch 12: Validation loss decreased (0.377841 --> 0.374022).  Saving model ...
	 Train_Loss: 0.4073 Train_Acc: 83.566 Val_Loss: 0.3740  BEST VAL Loss: 0.3740  Val_Acc: 85.375

Epoch 13: Validation loss decreased (0.374022 --> 0.371155).  Saving model ...
	 Train_Loss: 0.4036 Train_Acc: 83.779 Val_Loss: 0.3712  BEST VAL Loss: 0.3712  Val_Acc: 84.776

Epoch 14: Validation loss decreased (0.371155 --> 0.368734).  Saving model ...
	 Train_Loss: 0.4002 Train_Acc: 83.801 Val_Loss: 0.3687  BEST VAL Loss: 0.3687  Val_Acc: 84.749

Epoch 15: Validation loss decreased (0.368734 --> 0.365998).  Saving model ...
	 Train_Loss: 0.3971 Train_Acc: 83.948 Val_Loss: 0.3660  BEST VAL Loss: 0.3660  Val_Acc: 85.480

Epoch 16: Validation loss decreased (0.365998 --> 0.364360).  Saving model ...
	 Train_Loss: 0.3943 Train_Acc: 84.045 Val_Loss: 0.3644  BEST VAL Loss: 0.3644  Val_Acc: 84.675

Epoch 17: Validation loss decreased (0.364360 --> 0.362176).  Saving model ...
	 Train_Loss: 0.3918 Train_Acc: 84.000 Val_Loss: 0.3622  BEST VAL Loss: 0.3622  Val_Acc: 85.602

Epoch 18: Validation loss decreased (0.362176 --> 0.360085).  Saving model ...
	 Train_Loss: 0.3893 Train_Acc: 84.152 Val_Loss: 0.3601  BEST VAL Loss: 0.3601  Val_Acc: 85.495

Epoch 19: Validation loss decreased (0.360085 --> 0.357731).  Saving model ...
	 Train_Loss: 0.3871 Train_Acc: 84.216 Val_Loss: 0.3577  BEST VAL Loss: 0.3577  Val_Acc: 85.881

Epoch 20: Validation loss decreased (0.357731 --> 0.355641).  Saving model ...
	 Train_Loss: 0.3849 Train_Acc: 84.200 Val_Loss: 0.3556  BEST VAL Loss: 0.3556  Val_Acc: 86.141

Epoch 21: Validation loss decreased (0.355641 --> 0.353797).  Saving model ...
	 Train_Loss: 0.3830 Train_Acc: 84.257 Val_Loss: 0.3538  BEST VAL Loss: 0.3538  Val_Acc: 86.072

Epoch 22: Validation loss decreased (0.353797 --> 0.351857).  Saving model ...
	 Train_Loss: 0.3811 Train_Acc: 84.324 Val_Loss: 0.3519  BEST VAL Loss: 0.3519  Val_Acc: 86.204

Epoch 23: Validation loss decreased (0.351857 --> 0.350279).  Saving model ...
	 Train_Loss: 0.3794 Train_Acc: 84.459 Val_Loss: 0.3503  BEST VAL Loss: 0.3503  Val_Acc: 86.087

Epoch 24: Validation loss decreased (0.350279 --> 0.349367).  Saving model ...
	 Train_Loss: 0.3777 Train_Acc: 84.403 Val_Loss: 0.3494  BEST VAL Loss: 0.3494  Val_Acc: 85.438

Epoch 25: Validation loss decreased (0.349367 --> 0.347901).  Saving model ...
	 Train_Loss: 0.3762 Train_Acc: 84.485 Val_Loss: 0.3479  BEST VAL Loss: 0.3479  Val_Acc: 86.258

Epoch 26: Validation loss decreased (0.347901 --> 0.346927).  Saving model ...
	 Train_Loss: 0.3748 Train_Acc: 84.479 Val_Loss: 0.3469  BEST VAL Loss: 0.3469  Val_Acc: 85.650

Epoch 27: Validation loss decreased (0.346927 --> 0.345560).  Saving model ...
	 Train_Loss: 0.3734 Train_Acc: 84.460 Val_Loss: 0.3456  BEST VAL Loss: 0.3456  Val_Acc: 86.222

Epoch 28: Validation loss decreased (0.345560 --> 0.344362).  Saving model ...
	 Train_Loss: 0.3721 Train_Acc: 84.569 Val_Loss: 0.3444  BEST VAL Loss: 0.3444  Val_Acc: 86.183

Epoch 29: Validation loss decreased (0.344362 --> 0.343052).  Saving model ...
	 Train_Loss: 0.3708 Train_Acc: 84.587 Val_Loss: 0.3431  BEST VAL Loss: 0.3431  Val_Acc: 86.407

Epoch 30: Validation loss decreased (0.343052 --> 0.341977).  Saving model ...
	 Train_Loss: 0.3696 Train_Acc: 84.624 Val_Loss: 0.3420  BEST VAL Loss: 0.3420  Val_Acc: 86.156

Epoch 31: Validation loss decreased (0.341977 --> 0.341035).  Saving model ...
	 Train_Loss: 0.3685 Train_Acc: 84.645 Val_Loss: 0.3410  BEST VAL Loss: 0.3410  Val_Acc: 86.168

Epoch 32: Validation loss decreased (0.341035 --> 0.340066).  Saving model ...
	 Train_Loss: 0.3674 Train_Acc: 84.610 Val_Loss: 0.3401  BEST VAL Loss: 0.3401  Val_Acc: 86.102

Epoch 33: Validation loss decreased (0.340066 --> 0.339238).  Saving model ...
	 Train_Loss: 0.3663 Train_Acc: 84.695 Val_Loss: 0.3392  BEST VAL Loss: 0.3392  Val_Acc: 86.051

Epoch 34: Validation loss decreased (0.339238 --> 0.338199).  Saving model ...
	 Train_Loss: 0.3653 Train_Acc: 84.728 Val_Loss: 0.3382  BEST VAL Loss: 0.3382  Val_Acc: 86.485

Epoch 35: Validation loss decreased (0.338199 --> 0.337282).  Saving model ...
	 Train_Loss: 0.3644 Train_Acc: 84.740 Val_Loss: 0.3373  BEST VAL Loss: 0.3373  Val_Acc: 86.518

Epoch 36: Validation loss decreased (0.337282 --> 0.336311).  Saving model ...
	 Train_Loss: 0.3634 Train_Acc: 84.832 Val_Loss: 0.3363  BEST VAL Loss: 0.3363  Val_Acc: 86.653

Epoch 37: Validation loss decreased (0.336311 --> 0.336001).  Saving model ...
	 Train_Loss: 0.3625 Train_Acc: 84.799 Val_Loss: 0.3360  BEST VAL Loss: 0.3360  Val_Acc: 85.504

Epoch 38: Validation loss decreased (0.336001 --> 0.335301).  Saving model ...
	 Train_Loss: 0.3616 Train_Acc: 84.843 Val_Loss: 0.3353  BEST VAL Loss: 0.3353  Val_Acc: 86.443

Epoch 39: Validation loss decreased (0.335301 --> 0.334468).  Saving model ...
	 Train_Loss: 0.3608 Train_Acc: 84.842 Val_Loss: 0.3345  BEST VAL Loss: 0.3345  Val_Acc: 86.467

Epoch 40: Validation loss decreased (0.334468 --> 0.333699).  Saving model ...
	 Train_Loss: 0.3600 Train_Acc: 84.822 Val_Loss: 0.3337  BEST VAL Loss: 0.3337  Val_Acc: 86.470

Epoch 41: Validation loss decreased (0.333699 --> 0.332899).  Saving model ...
	 Train_Loss: 0.3592 Train_Acc: 84.931 Val_Loss: 0.3329  BEST VAL Loss: 0.3329  Val_Acc: 86.629

Epoch 42: Validation loss decreased (0.332899 --> 0.332189).  Saving model ...
	 Train_Loss: 0.3584 Train_Acc: 84.851 Val_Loss: 0.3322  BEST VAL Loss: 0.3322  Val_Acc: 86.605

Epoch 43: Validation loss decreased (0.332189 --> 0.331488).  Saving model ...
	 Train_Loss: 0.3577 Train_Acc: 84.867 Val_Loss: 0.3315  BEST VAL Loss: 0.3315  Val_Acc: 86.611

Epoch 44: Validation loss decreased (0.331488 --> 0.330901).  Saving model ...
	 Train_Loss: 0.3570 Train_Acc: 84.858 Val_Loss: 0.3309  BEST VAL Loss: 0.3309  Val_Acc: 86.386

Epoch 45: Validation loss decreased (0.330901 --> 0.330203).  Saving model ...
	 Train_Loss: 0.3563 Train_Acc: 84.953 Val_Loss: 0.3302  BEST VAL Loss: 0.3302  Val_Acc: 86.734

Epoch 46: Validation loss decreased (0.330203 --> 0.329539).  Saving model ...
	 Train_Loss: 0.3556 Train_Acc: 84.878 Val_Loss: 0.3295  BEST VAL Loss: 0.3295  Val_Acc: 86.668

Epoch 47: Validation loss decreased (0.329539 --> 0.328983).  Saving model ...
	 Train_Loss: 0.3550 Train_Acc: 84.970 Val_Loss: 0.3290  BEST VAL Loss: 0.3290  Val_Acc: 86.443

Epoch 48: Validation loss decreased (0.328983 --> 0.328404).  Saving model ...
	 Train_Loss: 0.3544 Train_Acc: 85.015 Val_Loss: 0.3284  BEST VAL Loss: 0.3284  Val_Acc: 86.638

Epoch 49: Validation loss decreased (0.328404 --> 0.327831).  Saving model ...
	 Train_Loss: 0.3537 Train_Acc: 85.074 Val_Loss: 0.3278  BEST VAL Loss: 0.3278  Val_Acc: 86.650

Epoch 50: Validation loss decreased (0.327831 --> 0.327224).  Saving model ...
	 Train_Loss: 0.3532 Train_Acc: 84.950 Val_Loss: 0.3272  BEST VAL Loss: 0.3272  Val_Acc: 86.692

Epoch 51: Validation loss decreased (0.327224 --> 0.326750).  Saving model ...
	 Train_Loss: 0.3526 Train_Acc: 84.950 Val_Loss: 0.3268  BEST VAL Loss: 0.3268  Val_Acc: 86.485

Epoch 52: Validation loss decreased (0.326750 --> 0.326474).  Saving model ...
	 Train_Loss: 0.3520 Train_Acc: 85.006 Val_Loss: 0.3265  BEST VAL Loss: 0.3265  Val_Acc: 86.204

Epoch 53: Validation loss decreased (0.326474 --> 0.325960).  Saving model ...
	 Train_Loss: 0.3515 Train_Acc: 85.061 Val_Loss: 0.3260  BEST VAL Loss: 0.3260  Val_Acc: 86.701

Epoch 54: Validation loss decreased (0.325960 --> 0.325774).  Saving model ...
	 Train_Loss: 0.3510 Train_Acc: 84.990 Val_Loss: 0.3258  BEST VAL Loss: 0.3258  Val_Acc: 85.797

Epoch 55: Validation loss decreased (0.325774 --> 0.325203).  Saving model ...
	 Train_Loss: 0.3504 Train_Acc: 85.128 Val_Loss: 0.3252  BEST VAL Loss: 0.3252  Val_Acc: 86.955

Epoch 56: Validation loss decreased (0.325203 --> 0.324679).  Saving model ...
	 Train_Loss: 0.3499 Train_Acc: 85.013 Val_Loss: 0.3247  BEST VAL Loss: 0.3247  Val_Acc: 86.847

Epoch 57: Validation loss decreased (0.324679 --> 0.324215).  Saving model ...
	 Train_Loss: 0.3494 Train_Acc: 85.084 Val_Loss: 0.3242  BEST VAL Loss: 0.3242  Val_Acc: 86.739

Epoch 58: Validation loss decreased (0.324215 --> 0.323656).  Saving model ...
	 Train_Loss: 0.3490 Train_Acc: 85.029 Val_Loss: 0.3237  BEST VAL Loss: 0.3237  Val_Acc: 87.146

Epoch 59: Validation loss decreased (0.323656 --> 0.323212).  Saving model ...
	 Train_Loss: 0.3485 Train_Acc: 85.126 Val_Loss: 0.3232  BEST VAL Loss: 0.3232  Val_Acc: 86.802

Epoch 60: Validation loss decreased (0.323212 --> 0.322769).  Saving model ...
	 Train_Loss: 0.3480 Train_Acc: 85.120 Val_Loss: 0.3228  BEST VAL Loss: 0.3228  Val_Acc: 86.829

Epoch 61: Validation loss decreased (0.322769 --> 0.322686).  Saving model ...
	 Train_Loss: 0.3476 Train_Acc: 85.049 Val_Loss: 0.3227  BEST VAL Loss: 0.3227  Val_Acc: 85.788

Epoch 62: Validation loss decreased (0.322686 --> 0.322419).  Saving model ...
	 Train_Loss: 0.3471 Train_Acc: 85.114 Val_Loss: 0.3224  BEST VAL Loss: 0.3224  Val_Acc: 86.964

Epoch 63: Validation loss decreased (0.322419 --> 0.321972).  Saving model ...
	 Train_Loss: 0.3467 Train_Acc: 85.166 Val_Loss: 0.3220  BEST VAL Loss: 0.3220  Val_Acc: 86.931

Epoch 64: Validation loss decreased (0.321972 --> 0.321561).  Saving model ...
	 Train_Loss: 0.3463 Train_Acc: 85.097 Val_Loss: 0.3216  BEST VAL Loss: 0.3216  Val_Acc: 87.051

Epoch 65: Validation loss decreased (0.321561 --> 0.321168).  Saving model ...
	 Train_Loss: 0.3459 Train_Acc: 85.168 Val_Loss: 0.3212  BEST VAL Loss: 0.3212  Val_Acc: 86.865

Epoch 66: Validation loss decreased (0.321168 --> 0.320945).  Saving model ...
	 Train_Loss: 0.3455 Train_Acc: 85.206 Val_Loss: 0.3209  BEST VAL Loss: 0.3209  Val_Acc: 86.329

Epoch 67: Validation loss decreased (0.320945 --> 0.320540).  Saving model ...
	 Train_Loss: 0.3451 Train_Acc: 85.181 Val_Loss: 0.3205  BEST VAL Loss: 0.3205  Val_Acc: 86.892

Epoch 68: Validation loss decreased (0.320540 --> 0.320203).  Saving model ...
	 Train_Loss: 0.3447 Train_Acc: 85.219 Val_Loss: 0.3202  BEST VAL Loss: 0.3202  Val_Acc: 86.823

Epoch 69: Validation loss decreased (0.320203 --> 0.319787).  Saving model ...
	 Train_Loss: 0.3443 Train_Acc: 85.147 Val_Loss: 0.3198  BEST VAL Loss: 0.3198  Val_Acc: 87.233

Epoch 70: Validation loss decreased (0.319787 --> 0.319405).  Saving model ...
	 Train_Loss: 0.3439 Train_Acc: 85.228 Val_Loss: 0.3194  BEST VAL Loss: 0.3194  Val_Acc: 87.123

Epoch 71: Validation loss decreased (0.319405 --> 0.319047).  Saving model ...
	 Train_Loss: 0.3436 Train_Acc: 85.236 Val_Loss: 0.3190  BEST VAL Loss: 0.3190  Val_Acc: 86.787

Epoch 72: Validation loss decreased (0.319047 --> 0.318676).  Saving model ...
	 Train_Loss: 0.3432 Train_Acc: 85.256 Val_Loss: 0.3187  BEST VAL Loss: 0.3187  Val_Acc: 87.221

Epoch 73: Validation loss decreased (0.318676 --> 0.318389).  Saving model ...
	 Train_Loss: 0.3428 Train_Acc: 85.215 Val_Loss: 0.3184  BEST VAL Loss: 0.3184  Val_Acc: 86.868

Epoch 74: Validation loss decreased (0.318389 --> 0.318004).  Saving model ...
	 Train_Loss: 0.3425 Train_Acc: 85.308 Val_Loss: 0.3180  BEST VAL Loss: 0.3180  Val_Acc: 87.188

Epoch 75: Validation loss decreased (0.318004 --> 0.317736).  Saving model ...
	 Train_Loss: 0.3421 Train_Acc: 85.290 Val_Loss: 0.3177  BEST VAL Loss: 0.3177  Val_Acc: 87.006

Epoch 76: Validation loss decreased (0.317736 --> 0.317387).  Saving model ...
	 Train_Loss: 0.3418 Train_Acc: 85.257 Val_Loss: 0.3174  BEST VAL Loss: 0.3174  Val_Acc: 87.284

Epoch 77: Validation loss decreased (0.317387 --> 0.317206).  Saving model ...
	 Train_Loss: 0.3415 Train_Acc: 85.222 Val_Loss: 0.3172  BEST VAL Loss: 0.3172  Val_Acc: 86.524

Epoch 78: Validation loss decreased (0.317206 --> 0.316891).  Saving model ...
	 Train_Loss: 0.3412 Train_Acc: 85.309 Val_Loss: 0.3169  BEST VAL Loss: 0.3169  Val_Acc: 87.158

Epoch 79: Validation loss decreased (0.316891 --> 0.316560).  Saving model ...
	 Train_Loss: 0.3408 Train_Acc: 85.265 Val_Loss: 0.3166  BEST VAL Loss: 0.3166  Val_Acc: 87.117

Epoch 80: Validation loss decreased (0.316560 --> 0.316292).  Saving model ...
	 Train_Loss: 0.3405 Train_Acc: 85.266 Val_Loss: 0.3163  BEST VAL Loss: 0.3163  Val_Acc: 87.108

Epoch 81: Validation loss decreased (0.316292 --> 0.316081).  Saving model ...
	 Train_Loss: 0.3402 Train_Acc: 85.282 Val_Loss: 0.3161  BEST VAL Loss: 0.3161  Val_Acc: 86.790

Epoch 82: Validation loss decreased (0.316081 --> 0.315759).  Saving model ...
	 Train_Loss: 0.3399 Train_Acc: 85.228 Val_Loss: 0.3158  BEST VAL Loss: 0.3158  Val_Acc: 87.299

Epoch 83: Validation loss decreased (0.315759 --> 0.315534).  Saving model ...
	 Train_Loss: 0.3396 Train_Acc: 85.307 Val_Loss: 0.3155  BEST VAL Loss: 0.3155  Val_Acc: 87.096

Epoch 84: Validation loss decreased (0.315534 --> 0.315187).  Saving model ...
	 Train_Loss: 0.3393 Train_Acc: 85.307 Val_Loss: 0.3152  BEST VAL Loss: 0.3152  Val_Acc: 87.410

Epoch 85: Validation loss decreased (0.315187 --> 0.314984).  Saving model ...
	 Train_Loss: 0.3391 Train_Acc: 85.319 Val_Loss: 0.3150  BEST VAL Loss: 0.3150  Val_Acc: 86.865

Epoch 86: Validation loss decreased (0.314984 --> 0.314714).  Saving model ...
	 Train_Loss: 0.3388 Train_Acc: 85.295 Val_Loss: 0.3147  BEST VAL Loss: 0.3147  Val_Acc: 87.245

Epoch 87: Validation loss decreased (0.314714 --> 0.314392).  Saving model ...
	 Train_Loss: 0.3385 Train_Acc: 85.352 Val_Loss: 0.3144  BEST VAL Loss: 0.3144  Val_Acc: 87.305

Epoch 88: Validation loss decreased (0.314392 --> 0.314234).  Saving model ...
	 Train_Loss: 0.3382 Train_Acc: 85.333 Val_Loss: 0.3142  BEST VAL Loss: 0.3142  Val_Acc: 86.701

Epoch 89: Validation loss decreased (0.314234 --> 0.313988).  Saving model ...
	 Train_Loss: 0.3379 Train_Acc: 85.378 Val_Loss: 0.3140  BEST VAL Loss: 0.3140  Val_Acc: 87.072

Epoch 90: Validation loss decreased (0.313988 --> 0.313728).  Saving model ...
	 Train_Loss: 0.3377 Train_Acc: 85.349 Val_Loss: 0.3137  BEST VAL Loss: 0.3137  Val_Acc: 87.293

Epoch 91: Validation loss decreased (0.313728 --> 0.313474).  Saving model ...
	 Train_Loss: 0.3374 Train_Acc: 85.303 Val_Loss: 0.3135  BEST VAL Loss: 0.3135  Val_Acc: 87.257

Epoch 92: Validation loss decreased (0.313474 --> 0.313241).  Saving model ...
	 Train_Loss: 0.3371 Train_Acc: 85.416 Val_Loss: 0.3132  BEST VAL Loss: 0.3132  Val_Acc: 87.149

Epoch 93: Validation loss decreased (0.313241 --> 0.313006).  Saving model ...
	 Train_Loss: 0.3369 Train_Acc: 85.434 Val_Loss: 0.3130  BEST VAL Loss: 0.3130  Val_Acc: 87.239

Epoch 94: Validation loss decreased (0.313006 --> 0.312757).  Saving model ...
	 Train_Loss: 0.3366 Train_Acc: 85.397 Val_Loss: 0.3128  BEST VAL Loss: 0.3128  Val_Acc: 87.305

Epoch 95: Validation loss decreased (0.312757 --> 0.312510).  Saving model ...
	 Train_Loss: 0.3364 Train_Acc: 85.380 Val_Loss: 0.3125  BEST VAL Loss: 0.3125  Val_Acc: 87.278

Epoch 96: Validation loss decreased (0.312510 --> 0.312288).  Saving model ...
	 Train_Loss: 0.3361 Train_Acc: 85.360 Val_Loss: 0.3123  BEST VAL Loss: 0.3123  Val_Acc: 87.251

Epoch 97: Validation loss decreased (0.312288 --> 0.312048).  Saving model ...
	 Train_Loss: 0.3359 Train_Acc: 85.383 Val_Loss: 0.3120  BEST VAL Loss: 0.3120  Val_Acc: 87.296

Epoch 98: Validation loss decreased (0.312048 --> 0.311849).  Saving model ...
	 Train_Loss: 0.3357 Train_Acc: 85.409 Val_Loss: 0.3118  BEST VAL Loss: 0.3118  Val_Acc: 87.194

Epoch 99: Validation loss decreased (0.311849 --> 0.311625).  Saving model ...
	 Train_Loss: 0.3354 Train_Acc: 85.342 Val_Loss: 0.3116  BEST VAL Loss: 0.3116  Val_Acc: 87.359

LPS_100.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.63      0.67      0.65    169560
           1       0.36      0.33      0.35     97754

    accuracy                           0.54    267314
   macro avg       0.50      0.50      0.50    267314
weighted avg       0.53      0.54      0.54    267314

LPS_100.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.63      0.67      0.65     21196
           1       0.36      0.33      0.35     12219

    accuracy                           0.54     33415
   macro avg       0.50      0.50      0.50     33415
weighted avg       0.53      0.54      0.54     33415

LPS_100.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.63      0.66      0.65     21196
           1       0.36      0.32      0.34     12219

    accuracy                           0.54     33415
   macro avg       0.49      0.49      0.49     33415
weighted avg       0.53      0.54      0.53     33415

              precision    recall  f1-score   support

           0       0.63      0.66      0.65     21196
           1       0.36      0.32      0.34     12219

    accuracy                           0.54     33415
   macro avg       0.49      0.49      0.49     33415
weighted avg       0.53      0.54      0.53     33415

LPS_100.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.43      0.63      0.51     28584
           1       0.56      0.37      0.45     37243

    accuracy                           0.48     65827
   macro avg       0.50      0.50      0.48     65827
weighted avg       0.51      0.48      0.48     65827

              precision    recall  f1-score   support

           0       0.43      0.63      0.51     28584
           1       0.56      0.37      0.45     37243

    accuracy                           0.48     65827
   macro avg       0.50      0.50      0.48     65827
weighted avg       0.51      0.48      0.48     65827

completed
