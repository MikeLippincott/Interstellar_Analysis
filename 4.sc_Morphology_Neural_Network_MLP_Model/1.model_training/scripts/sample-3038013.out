[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '16e103ea'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'ea9b09d3'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'eefe2504'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '4e2b9557'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_Nigericin_1.000_1.0_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (340274, 1270)
Number of total missing values across all columns: 0
Data Subset Is Off
Wells held out for testing: ['K08' 'L09']
Wells to use for training, validation, and testing ['K02' 'K03' 'K09' 'L02' 'L03' 'L08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.567536).  Saving model ...
	 Train_Loss: 0.6347 Train_Acc: 62.086 Val_Loss: 0.5675  BEST VAL Loss: 0.5675  Val_Acc: 70.130

Epoch 1: Validation loss decreased (0.567536 --> 0.555268).  Saving model ...
	 Train_Loss: 0.6063 Train_Acc: 68.821 Val_Loss: 0.5553  BEST VAL Loss: 0.5553  Val_Acc: 71.237

Epoch 2: Validation loss decreased (0.555268 --> 0.547226).  Saving model ...
	 Train_Loss: 0.5909 Train_Acc: 70.090 Val_Loss: 0.5472  BEST VAL Loss: 0.5472  Val_Acc: 72.386

Epoch 3: Validation loss decreased (0.547226 --> 0.538562).  Saving model ...
	 Train_Loss: 0.5805 Train_Acc: 70.987 Val_Loss: 0.5386  BEST VAL Loss: 0.5386  Val_Acc: 73.665

Epoch 4: Validation loss decreased (0.538562 --> 0.532362).  Saving model ...
	 Train_Loss: 0.5727 Train_Acc: 71.445 Val_Loss: 0.5324  BEST VAL Loss: 0.5324  Val_Acc: 74.031

Epoch 5: Validation loss decreased (0.532362 --> 0.528364).  Saving model ...
	 Train_Loss: 0.5663 Train_Acc: 71.923 Val_Loss: 0.5284  BEST VAL Loss: 0.5284  Val_Acc: 73.810

Epoch 6: Validation loss decreased (0.528364 --> 0.524517).  Saving model ...
	 Train_Loss: 0.5612 Train_Acc: 72.214 Val_Loss: 0.5245  BEST VAL Loss: 0.5245  Val_Acc: 74.566

Epoch 7: Validation loss decreased (0.524517 --> 0.521462).  Saving model ...
	 Train_Loss: 0.5570 Train_Acc: 72.372 Val_Loss: 0.5215  BEST VAL Loss: 0.5215  Val_Acc: 74.398

Epoch 8: Validation loss decreased (0.521462 --> 0.520741).  Saving model ...
	 Train_Loss: 0.5534 Train_Acc: 72.794 Val_Loss: 0.5207  BEST VAL Loss: 0.5207  Val_Acc: 74.299

Epoch 9: Validation loss decreased (0.520741 --> 0.517849).  Saving model ...
	 Train_Loss: 0.5502 Train_Acc: 72.871 Val_Loss: 0.5178  BEST VAL Loss: 0.5178  Val_Acc: 75.123

Epoch 10: Validation loss decreased (0.517849 --> 0.515657).  Saving model ...
	 Train_Loss: 0.5473 Train_Acc: 73.015 Val_Loss: 0.5157  BEST VAL Loss: 0.5157  Val_Acc: 75.303

Epoch 11: Validation loss decreased (0.515657 --> 0.513040).  Saving model ...
	 Train_Loss: 0.5447 Train_Acc: 73.121 Val_Loss: 0.5130  BEST VAL Loss: 0.5130  Val_Acc: 75.780

Epoch 12: Validation loss decreased (0.513040 --> 0.510760).  Saving model ...
	 Train_Loss: 0.5424 Train_Acc: 73.276 Val_Loss: 0.5108  BEST VAL Loss: 0.5108  Val_Acc: 75.757

Epoch 13: Validation loss decreased (0.510760 --> 0.509013).  Saving model ...
	 Train_Loss: 0.5403 Train_Acc: 73.384 Val_Loss: 0.5090  BEST VAL Loss: 0.5090  Val_Acc: 75.528

Epoch 14: Validation loss decreased (0.509013 --> 0.507764).  Saving model ...
	 Train_Loss: 0.5383 Train_Acc: 73.574 Val_Loss: 0.5078  BEST VAL Loss: 0.5078  Val_Acc: 75.451

Epoch 15: Validation loss decreased (0.507764 --> 0.506521).  Saving model ...
	 Train_Loss: 0.5365 Train_Acc: 73.699 Val_Loss: 0.5065  BEST VAL Loss: 0.5065  Val_Acc: 74.993

Epoch 16: Validation loss decreased (0.506521 --> 0.505276).  Saving model ...
	 Train_Loss: 0.5349 Train_Acc: 73.696 Val_Loss: 0.5053  BEST VAL Loss: 0.5053  Val_Acc: 75.543

Epoch 17: Validation loss decreased (0.505276 --> 0.503962).  Saving model ...
	 Train_Loss: 0.5334 Train_Acc: 73.743 Val_Loss: 0.5040  BEST VAL Loss: 0.5040  Val_Acc: 75.768

Epoch 18: Validation loss decreased (0.503962 --> 0.502612).  Saving model ...
	 Train_Loss: 0.5320 Train_Acc: 73.844 Val_Loss: 0.5026  BEST VAL Loss: 0.5026  Val_Acc: 76.337

Epoch 19: Validation loss decreased (0.502612 --> 0.501235).  Saving model ...
	 Train_Loss: 0.5306 Train_Acc: 74.011 Val_Loss: 0.5012  BEST VAL Loss: 0.5012  Val_Acc: 76.096

Epoch 20: Validation loss decreased (0.501235 --> 0.500216).  Saving model ...
	 Train_Loss: 0.5294 Train_Acc: 73.984 Val_Loss: 0.5002  BEST VAL Loss: 0.5002  Val_Acc: 75.738

Epoch 21: Validation loss decreased (0.500216 --> 0.499269).  Saving model ...
	 Train_Loss: 0.5282 Train_Acc: 73.885 Val_Loss: 0.4993  BEST VAL Loss: 0.4993  Val_Acc: 76.478

Epoch 22: Validation loss decreased (0.499269 --> 0.498300).  Saving model ...
	 Train_Loss: 0.5272 Train_Acc: 74.057 Val_Loss: 0.4983  BEST VAL Loss: 0.4983  Val_Acc: 76.364

Epoch 23: Validation loss decreased (0.498300 --> 0.497461).  Saving model ...
	 Train_Loss: 0.5261 Train_Acc: 74.024 Val_Loss: 0.4975  BEST VAL Loss: 0.4975  Val_Acc: 76.253

Epoch 24: Validation loss decreased (0.497461 --> 0.496910).  Saving model ...
	 Train_Loss: 0.5251 Train_Acc: 74.222 Val_Loss: 0.4969  BEST VAL Loss: 0.4969  Val_Acc: 76.368

Epoch 25: Validation loss decreased (0.496910 --> 0.496177).  Saving model ...
	 Train_Loss: 0.5242 Train_Acc: 74.222 Val_Loss: 0.4962  BEST VAL Loss: 0.4962  Val_Acc: 76.398

Epoch 26: Validation loss decreased (0.496177 --> 0.495386).  Saving model ...
	 Train_Loss: 0.5233 Train_Acc: 74.244 Val_Loss: 0.4954  BEST VAL Loss: 0.4954  Val_Acc: 76.455

Epoch 27: Validation loss decreased (0.495386 --> 0.494591).  Saving model ...
	 Train_Loss: 0.5224 Train_Acc: 74.314 Val_Loss: 0.4946  BEST VAL Loss: 0.4946  Val_Acc: 76.581

Epoch 28: Validation loss decreased (0.494591 --> 0.494284).  Saving model ...
	 Train_Loss: 0.5216 Train_Acc: 74.344 Val_Loss: 0.4943  BEST VAL Loss: 0.4943  Val_Acc: 75.619

Epoch 29: Validation loss decreased (0.494284 --> 0.493611).  Saving model ...
	 Train_Loss: 0.5209 Train_Acc: 74.393 Val_Loss: 0.4936  BEST VAL Loss: 0.4936  Val_Acc: 76.146

Epoch 30: Validation loss decreased (0.493611 --> 0.493149).  Saving model ...
	 Train_Loss: 0.5201 Train_Acc: 74.394 Val_Loss: 0.4931  BEST VAL Loss: 0.4931  Val_Acc: 76.436

Epoch 31: Validation loss decreased (0.493149 --> 0.492679).  Saving model ...
	 Train_Loss: 0.5194 Train_Acc: 74.445 Val_Loss: 0.4927  BEST VAL Loss: 0.4927  Val_Acc: 76.490

Epoch 32: Validation loss decreased (0.492679 --> 0.491858).  Saving model ...
	 Train_Loss: 0.5187 Train_Acc: 74.473 Val_Loss: 0.4919  BEST VAL Loss: 0.4919  Val_Acc: 76.875

Epoch 33: Validation loss decreased (0.491858 --> 0.491382).  Saving model ...
	 Train_Loss: 0.5181 Train_Acc: 74.497 Val_Loss: 0.4914  BEST VAL Loss: 0.4914  Val_Acc: 76.207

Epoch 34: Validation loss decreased (0.491382 --> 0.490721).  Saving model ...
	 Train_Loss: 0.5174 Train_Acc: 74.592 Val_Loss: 0.4907  BEST VAL Loss: 0.4907  Val_Acc: 76.848

Epoch 35: Validation loss decreased (0.490721 --> 0.490168).  Saving model ...
	 Train_Loss: 0.5168 Train_Acc: 74.516 Val_Loss: 0.4902  BEST VAL Loss: 0.4902  Val_Acc: 76.810

Epoch 36: Validation loss decreased (0.490168 --> 0.489474).  Saving model ...
	 Train_Loss: 0.5163 Train_Acc: 74.566 Val_Loss: 0.4895  BEST VAL Loss: 0.4895  Val_Acc: 76.883

Epoch 37: Validation loss decreased (0.489474 --> 0.488971).  Saving model ...
	 Train_Loss: 0.5157 Train_Acc: 74.606 Val_Loss: 0.4890  BEST VAL Loss: 0.4890  Val_Acc: 76.910

Epoch 38: Validation loss decreased (0.488971 --> 0.488381).  Saving model ...
	 Train_Loss: 0.5152 Train_Acc: 74.608 Val_Loss: 0.4884  BEST VAL Loss: 0.4884  Val_Acc: 76.845

Epoch 39: Validation loss decreased (0.488381 --> 0.487817).  Saving model ...
	 Train_Loss: 0.5146 Train_Acc: 74.676 Val_Loss: 0.4878  BEST VAL Loss: 0.4878  Val_Acc: 76.509

Epoch 40: Validation loss decreased (0.487817 --> 0.487174).  Saving model ...
	 Train_Loss: 0.5141 Train_Acc: 74.585 Val_Loss: 0.4872  BEST VAL Loss: 0.4872  Val_Acc: 77.234

Epoch 41: Validation loss decreased (0.487174 --> 0.486856).  Saving model ...
	 Train_Loss: 0.5137 Train_Acc: 74.563 Val_Loss: 0.4869  BEST VAL Loss: 0.4869  Val_Acc: 76.364

Epoch 42: Validation loss decreased (0.486856 --> 0.486365).  Saving model ...
	 Train_Loss: 0.5132 Train_Acc: 74.743 Val_Loss: 0.4864  BEST VAL Loss: 0.4864  Val_Acc: 77.215

Epoch 43: Validation loss decreased (0.486365 --> 0.485938).  Saving model ...
	 Train_Loss: 0.5127 Train_Acc: 74.645 Val_Loss: 0.4859  BEST VAL Loss: 0.4859  Val_Acc: 77.001

Epoch 44: Validation loss decreased (0.485938 --> 0.485807).  Saving model ...
	 Train_Loss: 0.5122 Train_Acc: 74.923 Val_Loss: 0.4858  BEST VAL Loss: 0.4858  Val_Acc: 76.368

Epoch 45: Validation loss decreased (0.485807 --> 0.485506).  Saving model ...
	 Train_Loss: 0.5118 Train_Acc: 74.877 Val_Loss: 0.4855  BEST VAL Loss: 0.4855  Val_Acc: 76.406

Epoch 46: Validation loss decreased (0.485506 --> 0.485111).  Saving model ...
	 Train_Loss: 0.5114 Train_Acc: 74.796 Val_Loss: 0.4851  BEST VAL Loss: 0.4851  Val_Acc: 76.841

Epoch 47: Validation loss decreased (0.485111 --> 0.484653).  Saving model ...
	 Train_Loss: 0.5109 Train_Acc: 74.825 Val_Loss: 0.4847  BEST VAL Loss: 0.4847  Val_Acc: 77.226

Epoch 48: Validation loss decreased (0.484653 --> 0.484323).  Saving model ...
	 Train_Loss: 0.5105 Train_Acc: 74.889 Val_Loss: 0.4843  BEST VAL Loss: 0.4843  Val_Acc: 76.910

Epoch 49: Validation loss decreased (0.484323 --> 0.483905).  Saving model ...
	 Train_Loss: 0.5101 Train_Acc: 74.771 Val_Loss: 0.4839  BEST VAL Loss: 0.4839  Val_Acc: 77.337

Epoch 50: Validation loss decreased (0.483905 --> 0.483491).  Saving model ...
	 Train_Loss: 0.5098 Train_Acc: 74.932 Val_Loss: 0.4835  BEST VAL Loss: 0.4835  Val_Acc: 77.165

Epoch 51: Validation loss decreased (0.483491 --> 0.483136).  Saving model ...
	 Train_Loss: 0.5094 Train_Acc: 74.944 Val_Loss: 0.4831  BEST VAL Loss: 0.4831  Val_Acc: 76.665

Epoch 52: Validation loss decreased (0.483136 --> 0.482773).  Saving model ...
	 Train_Loss: 0.5090 Train_Acc: 75.039 Val_Loss: 0.4828  BEST VAL Loss: 0.4828  Val_Acc: 77.169

Epoch 53: Validation loss decreased (0.482773 --> 0.482353).  Saving model ...
	 Train_Loss: 0.5086 Train_Acc: 74.996 Val_Loss: 0.4824  BEST VAL Loss: 0.4824  Val_Acc: 77.501

Epoch 54: Validation loss decreased (0.482353 --> 0.482003).  Saving model ...
	 Train_Loss: 0.5083 Train_Acc: 74.997 Val_Loss: 0.4820  BEST VAL Loss: 0.4820  Val_Acc: 77.066

Epoch 55: Validation loss decreased (0.482003 --> 0.481702).  Saving model ...
	 Train_Loss: 0.5079 Train_Acc: 75.068 Val_Loss: 0.4817  BEST VAL Loss: 0.4817  Val_Acc: 77.184

Epoch 56: Validation loss decreased (0.481702 --> 0.481576).  Saving model ...
	 Train_Loss: 0.5076 Train_Acc: 75.035 Val_Loss: 0.4816  BEST VAL Loss: 0.4816  Val_Acc: 76.245

Epoch 57: Validation loss decreased (0.481576 --> 0.481291).  Saving model ...
	 Train_Loss: 0.5072 Train_Acc: 75.058 Val_Loss: 0.4813  BEST VAL Loss: 0.4813  Val_Acc: 77.173

Epoch 58: Validation loss decreased (0.481291 --> 0.480899).  Saving model ...
	 Train_Loss: 0.5069 Train_Acc: 74.955 Val_Loss: 0.4809  BEST VAL Loss: 0.4809  Val_Acc: 77.333

Epoch 59: Validation loss decreased (0.480899 --> 0.480610).  Saving model ...
	 Train_Loss: 0.5066 Train_Acc: 75.208 Val_Loss: 0.4806  BEST VAL Loss: 0.4806  Val_Acc: 76.959

Epoch 60: Validation loss decreased (0.480610 --> 0.480324).  Saving model ...
	 Train_Loss: 0.5063 Train_Acc: 75.082 Val_Loss: 0.4803  BEST VAL Loss: 0.4803  Val_Acc: 77.150

Epoch 61: Validation loss decreased (0.480324 --> 0.479979).  Saving model ...
	 Train_Loss: 0.5060 Train_Acc: 75.147 Val_Loss: 0.4800  BEST VAL Loss: 0.4800  Val_Acc: 77.314

Epoch 62: Validation loss decreased (0.479979 --> 0.479684).  Saving model ...
	 Train_Loss: 0.5057 Train_Acc: 75.125 Val_Loss: 0.4797  BEST VAL Loss: 0.4797  Val_Acc: 77.364

Epoch 63: Validation loss decreased (0.479684 --> 0.479404).  Saving model ...
	 Train_Loss: 0.5054 Train_Acc: 75.004 Val_Loss: 0.4794  BEST VAL Loss: 0.4794  Val_Acc: 76.917

Epoch 64: Validation loss decreased (0.479404 --> 0.479119).  Saving model ...
	 Train_Loss: 0.5051 Train_Acc: 75.093 Val_Loss: 0.4791  BEST VAL Loss: 0.4791  Val_Acc: 77.345

Epoch 65: Validation loss decreased (0.479119 --> 0.478848).  Saving model ...
	 Train_Loss: 0.5049 Train_Acc: 75.258 Val_Loss: 0.4788  BEST VAL Loss: 0.4788  Val_Acc: 77.093

Epoch 66: Validation loss decreased (0.478848 --> 0.478679).  Saving model ...
	 Train_Loss: 0.5046 Train_Acc: 75.124 Val_Loss: 0.4787  BEST VAL Loss: 0.4787  Val_Acc: 76.703

Epoch 67: Validation loss decreased (0.478679 --> 0.478460).  Saving model ...
	 Train_Loss: 0.5043 Train_Acc: 75.218 Val_Loss: 0.4785  BEST VAL Loss: 0.4785  Val_Acc: 76.795

Epoch 68: Validation loss decreased (0.478460 --> 0.478176).  Saving model ...
	 Train_Loss: 0.5041 Train_Acc: 75.150 Val_Loss: 0.4782  BEST VAL Loss: 0.4782  Val_Acc: 77.303

Epoch 69: Validation loss decreased (0.478176 --> 0.477961).  Saving model ...
	 Train_Loss: 0.5038 Train_Acc: 75.208 Val_Loss: 0.4780  BEST VAL Loss: 0.4780  Val_Acc: 77.089

Epoch 70: Validation loss decreased (0.477961 --> 0.477716).  Saving model ...
	 Train_Loss: 0.5036 Train_Acc: 75.188 Val_Loss: 0.4777  BEST VAL Loss: 0.4777  Val_Acc: 77.318

Epoch 71: Validation loss decreased (0.477716 --> 0.477467).  Saving model ...
	 Train_Loss: 0.5033 Train_Acc: 75.221 Val_Loss: 0.4775  BEST VAL Loss: 0.4775  Val_Acc: 77.478

Epoch 72: Validation loss decreased (0.477467 --> 0.477239).  Saving model ...
	 Train_Loss: 0.5031 Train_Acc: 75.133 Val_Loss: 0.4772  BEST VAL Loss: 0.4772  Val_Acc: 77.391

Epoch 73: Validation loss decreased (0.477239 --> 0.477037).  Saving model ...
	 Train_Loss: 0.5028 Train_Acc: 75.306 Val_Loss: 0.4770  BEST VAL Loss: 0.4770  Val_Acc: 77.009

Epoch 74: Validation loss decreased (0.477037 --> 0.476814).  Saving model ...
	 Train_Loss: 0.5026 Train_Acc: 75.195 Val_Loss: 0.4768  BEST VAL Loss: 0.4768  Val_Acc: 77.406

Epoch 75: Validation loss decreased (0.476814 --> 0.476597).  Saving model ...
	 Train_Loss: 0.5024 Train_Acc: 75.287 Val_Loss: 0.4766  BEST VAL Loss: 0.4766  Val_Acc: 77.329

Epoch 76: Validation loss decreased (0.476597 --> 0.476362).  Saving model ...
	 Train_Loss: 0.5021 Train_Acc: 75.328 Val_Loss: 0.4764  BEST VAL Loss: 0.4764  Val_Acc: 77.268

Epoch 77: Validation loss decreased (0.476362 --> 0.476133).  Saving model ...
	 Train_Loss: 0.5019 Train_Acc: 75.373 Val_Loss: 0.4761  BEST VAL Loss: 0.4761  Val_Acc: 77.135

Epoch 78: Validation loss decreased (0.476133 --> 0.475911).  Saving model ...
	 Train_Loss: 0.5017 Train_Acc: 75.128 Val_Loss: 0.4759  BEST VAL Loss: 0.4759  Val_Acc: 77.425

Epoch 79: Validation loss decreased (0.475911 --> 0.475721).  Saving model ...
	 Train_Loss: 0.5015 Train_Acc: 75.352 Val_Loss: 0.4757  BEST VAL Loss: 0.4757  Val_Acc: 77.726

Epoch 80: Validation loss decreased (0.475721 --> 0.475570).  Saving model ...
	 Train_Loss: 0.5013 Train_Acc: 75.201 Val_Loss: 0.4756  BEST VAL Loss: 0.4756  Val_Acc: 77.482

Epoch 81: Validation loss decreased (0.475570 --> 0.475326).  Saving model ...
	 Train_Loss: 0.5010 Train_Acc: 75.350 Val_Loss: 0.4753  BEST VAL Loss: 0.4753  Val_Acc: 77.433

Epoch 82: Validation loss decreased (0.475326 --> 0.475139).  Saving model ...
	 Train_Loss: 0.5008 Train_Acc: 75.310 Val_Loss: 0.4751  BEST VAL Loss: 0.4751  Val_Acc: 77.406

Epoch 83: Validation loss decreased (0.475139 --> 0.475006).  Saving model ...
	 Train_Loss: 0.5006 Train_Acc: 75.354 Val_Loss: 0.4750  BEST VAL Loss: 0.4750  Val_Acc: 77.352

Epoch 84: Validation loss decreased (0.475006 --> 0.474814).  Saving model ...
	 Train_Loss: 0.5004 Train_Acc: 75.271 Val_Loss: 0.4748  BEST VAL Loss: 0.4748  Val_Acc: 77.612

Epoch 85: Validation loss decreased (0.474814 --> 0.474628).  Saving model ...
	 Train_Loss: 0.5003 Train_Acc: 75.298 Val_Loss: 0.4746  BEST VAL Loss: 0.4746  Val_Acc: 77.310

Epoch 86: Validation loss decreased (0.474628 --> 0.474447).  Saving model ...
	 Train_Loss: 0.5001 Train_Acc: 75.326 Val_Loss: 0.4744  BEST VAL Loss: 0.4744  Val_Acc: 77.650

Epoch 87: Validation loss decreased (0.474447 --> 0.474243).  Saving model ...
	 Train_Loss: 0.4999 Train_Acc: 75.445 Val_Loss: 0.4742  BEST VAL Loss: 0.4742  Val_Acc: 77.413

Epoch 88: Validation loss decreased (0.474243 --> 0.474045).  Saving model ...
	 Train_Loss: 0.4997 Train_Acc: 75.301 Val_Loss: 0.4740  BEST VAL Loss: 0.4740  Val_Acc: 77.681

Epoch 89: Validation loss decreased (0.474045 --> 0.473898).  Saving model ...
	 Train_Loss: 0.4995 Train_Acc: 75.409 Val_Loss: 0.4739  BEST VAL Loss: 0.4739  Val_Acc: 77.329

Epoch 90: Validation loss decreased (0.473898 --> 0.473720).  Saving model ...
	 Train_Loss: 0.4993 Train_Acc: 75.446 Val_Loss: 0.4737  BEST VAL Loss: 0.4737  Val_Acc: 77.337

Epoch 91: Validation loss decreased (0.473720 --> 0.473563).  Saving model ...
	 Train_Loss: 0.4991 Train_Acc: 75.399 Val_Loss: 0.4736  BEST VAL Loss: 0.4736  Val_Acc: 77.265

Epoch 92: Validation loss decreased (0.473563 --> 0.473474).  Saving model ...
	 Train_Loss: 0.4990 Train_Acc: 75.373 Val_Loss: 0.4735  BEST VAL Loss: 0.4735  Val_Acc: 76.879

Epoch 93: Validation loss decreased (0.473474 --> 0.473301).  Saving model ...
	 Train_Loss: 0.4988 Train_Acc: 75.495 Val_Loss: 0.4733  BEST VAL Loss: 0.4733  Val_Acc: 77.295

Epoch 94: Validation loss decreased (0.473301 --> 0.473123).  Saving model ...
	 Train_Loss: 0.4986 Train_Acc: 75.453 Val_Loss: 0.4731  BEST VAL Loss: 0.4731  Val_Acc: 77.371

Epoch 95: Validation loss decreased (0.473123 --> 0.472986).  Saving model ...
	 Train_Loss: 0.4984 Train_Acc: 75.408 Val_Loss: 0.4730  BEST VAL Loss: 0.4730  Val_Acc: 77.284

Epoch 96: Validation loss decreased (0.472986 --> 0.472822).  Saving model ...
	 Train_Loss: 0.4983 Train_Acc: 75.369 Val_Loss: 0.4728  BEST VAL Loss: 0.4728  Val_Acc: 77.520

Epoch 97: Validation loss decreased (0.472822 --> 0.472640).  Saving model ...
	 Train_Loss: 0.4981 Train_Acc: 75.543 Val_Loss: 0.4726  BEST VAL Loss: 0.4726  Val_Acc: 77.425

Epoch 98: Validation loss decreased (0.472640 --> 0.472475).  Saving model ...
	 Train_Loss: 0.4979 Train_Acc: 75.380 Val_Loss: 0.4725  BEST VAL Loss: 0.4725  Val_Acc: 77.478

Epoch 99: Validation loss decreased (0.472475 --> 0.472303).  Saving model ...
	 Train_Loss: 0.4978 Train_Acc: 75.355 Val_Loss: 0.4723  BEST VAL Loss: 0.4723  Val_Acc: 77.776

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.44      0.46    100340
           1       0.52      0.56      0.54    109228

    accuracy                           0.50    209568
   macro avg       0.50      0.50      0.50    209568
weighted avg       0.50      0.50      0.50    209568

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.43      0.46     12543
           1       0.52      0.57      0.54     13654

    accuracy                           0.50     26197
   macro avg       0.50      0.50      0.50     26197
weighted avg       0.50      0.50      0.50     26197

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.44      0.46     12542
           1       0.53      0.57      0.55     13654

    accuracy                           0.51     26196
   macro avg       0.51      0.51      0.50     26196
weighted avg       0.51      0.51      0.51     26196

              precision    recall  f1-score   support

           0       0.49      0.44      0.46     12542
           1       0.53      0.57      0.55     13654

    accuracy                           0.51     26196
   macro avg       0.51      0.51      0.50     26196
weighted avg       0.51      0.51      0.51     26196

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.33      0.40     40588
           1       0.48      0.67      0.56     37725

    accuracy                           0.49     78313
   macro avg       0.50      0.50      0.48     78313
weighted avg       0.50      0.49      0.48     78313

              precision    recall  f1-score   support

           0       0.52      0.33      0.40     40588
           1       0.48      0.67      0.56     37725

    accuracy                           0.49     78313
   macro avg       0.50      0.50      0.48     78313
weighted avg       0.50      0.49      0.48     78313

completed
