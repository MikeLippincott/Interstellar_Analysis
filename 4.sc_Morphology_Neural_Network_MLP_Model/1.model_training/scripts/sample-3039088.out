[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'c718762a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '95eec872'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '02b46cad'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '059715f7'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Thapsigargin_10.000_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Thapsigargin_10.000_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'Thapsigargin_10.000_DMSO_0.025']
The dimensions of the data are: (305581, 1270)
Number of total missing values across all columns: 611162
Data Subset Is Off
Wells held out for testing: ['C08' 'L06']
Wells to use for training, validation, and testing ['C02' 'C03' 'C09' 'E06' 'E07' 'L07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.475256).  Saving model ...
	 Train_Loss: 0.5772 Train_Acc: 68.279 Val_Loss: 0.4753  BEST VAL Loss: 0.4753  Val_Acc: 77.354

Epoch 1: Validation loss decreased (0.475256 --> 0.454012).  Saving model ...
	 Train_Loss: 0.5330 Train_Acc: 75.077 Val_Loss: 0.4540  BEST VAL Loss: 0.4540  Val_Acc: 80.087

Epoch 2: Validation loss decreased (0.454012 --> 0.440322).  Saving model ...
	 Train_Loss: 0.5096 Train_Acc: 77.507 Val_Loss: 0.4403  BEST VAL Loss: 0.4403  Val_Acc: 81.314

Epoch 3: Validation loss decreased (0.440322 --> 0.428394).  Saving model ...
	 Train_Loss: 0.4935 Train_Acc: 78.841 Val_Loss: 0.4284  BEST VAL Loss: 0.4284  Val_Acc: 82.532

Epoch 4: Validation loss decreased (0.428394 --> 0.419502).  Saving model ...
	 Train_Loss: 0.4811 Train_Acc: 79.712 Val_Loss: 0.4195  BEST VAL Loss: 0.4195  Val_Acc: 82.913

Epoch 5: Validation loss decreased (0.419502 --> 0.412068).  Saving model ...
	 Train_Loss: 0.4714 Train_Acc: 80.247 Val_Loss: 0.4121  BEST VAL Loss: 0.4121  Val_Acc: 83.555

Epoch 6: Validation loss decreased (0.412068 --> 0.405414).  Saving model ...
	 Train_Loss: 0.4635 Train_Acc: 80.765 Val_Loss: 0.4054  BEST VAL Loss: 0.4054  Val_Acc: 84.015

Epoch 7: Validation loss decreased (0.405414 --> 0.399493).  Saving model ...
	 Train_Loss: 0.4564 Train_Acc: 81.082 Val_Loss: 0.3995  BEST VAL Loss: 0.3995  Val_Acc: 84.308

Epoch 8: Validation loss decreased (0.399493 --> 0.395207).  Saving model ...
	 Train_Loss: 0.4505 Train_Acc: 81.398 Val_Loss: 0.3952  BEST VAL Loss: 0.3952  Val_Acc: 84.542

Epoch 9: Validation loss decreased (0.395207 --> 0.390907).  Saving model ...
	 Train_Loss: 0.4453 Train_Acc: 81.730 Val_Loss: 0.3909  BEST VAL Loss: 0.3909  Val_Acc: 84.915

Epoch 10: Validation loss decreased (0.390907 --> 0.386885).  Saving model ...
	 Train_Loss: 0.4406 Train_Acc: 81.967 Val_Loss: 0.3869  BEST VAL Loss: 0.3869  Val_Acc: 85.220

Epoch 11: Validation loss decreased (0.386885 --> 0.383095).  Saving model ...
	 Train_Loss: 0.4364 Train_Acc: 82.240 Val_Loss: 0.3831  BEST VAL Loss: 0.3831  Val_Acc: 85.566

Epoch 12: Validation loss decreased (0.383095 --> 0.379531).  Saving model ...
	 Train_Loss: 0.4326 Train_Acc: 82.423 Val_Loss: 0.3795  BEST VAL Loss: 0.3795  Val_Acc: 85.619

Epoch 13: Validation loss decreased (0.379531 --> 0.376650).  Saving model ...
	 Train_Loss: 0.4294 Train_Acc: 82.370 Val_Loss: 0.3766  BEST VAL Loss: 0.3766  Val_Acc: 85.628

Epoch 14: Validation loss decreased (0.376650 --> 0.373993).  Saving model ...
	 Train_Loss: 0.4261 Train_Acc: 82.733 Val_Loss: 0.3740  BEST VAL Loss: 0.3740  Val_Acc: 85.424

Epoch 15: Validation loss decreased (0.373993 --> 0.371254).  Saving model ...
	 Train_Loss: 0.4232 Train_Acc: 82.821 Val_Loss: 0.3713  BEST VAL Loss: 0.3713  Val_Acc: 85.933

Epoch 16: Validation loss decreased (0.371254 --> 0.368585).  Saving model ...
	 Train_Loss: 0.4206 Train_Acc: 82.894 Val_Loss: 0.3686  BEST VAL Loss: 0.3686  Val_Acc: 85.845

Epoch 17: Validation loss decreased (0.368585 --> 0.366138).  Saving model ...
	 Train_Loss: 0.4182 Train_Acc: 82.909 Val_Loss: 0.3661  BEST VAL Loss: 0.3661  Val_Acc: 85.978

Epoch 18: Validation loss decreased (0.366138 --> 0.364882).  Saving model ...
	 Train_Loss: 0.4158 Train_Acc: 83.128 Val_Loss: 0.3649  BEST VAL Loss: 0.3649  Val_Acc: 85.291

Epoch 19: Validation loss decreased (0.364882 --> 0.363010).  Saving model ...
	 Train_Loss: 0.4138 Train_Acc: 83.031 Val_Loss: 0.3630  BEST VAL Loss: 0.3630  Val_Acc: 85.898

Epoch 20: Validation loss decreased (0.363010 --> 0.361121).  Saving model ...
	 Train_Loss: 0.4117 Train_Acc: 83.186 Val_Loss: 0.3611  BEST VAL Loss: 0.3611  Val_Acc: 86.057

Epoch 21: Validation loss decreased (0.361121 --> 0.359386).  Saving model ...
	 Train_Loss: 0.4097 Train_Acc: 83.285 Val_Loss: 0.3594  BEST VAL Loss: 0.3594  Val_Acc: 86.137

Epoch 22: Validation loss decreased (0.359386 --> 0.357734).  Saving model ...
	 Train_Loss: 0.4079 Train_Acc: 83.265 Val_Loss: 0.3577  BEST VAL Loss: 0.3577  Val_Acc: 86.199

Epoch 23: Validation loss decreased (0.357734 --> 0.356115).  Saving model ...
	 Train_Loss: 0.4063 Train_Acc: 83.284 Val_Loss: 0.3561  BEST VAL Loss: 0.3561  Val_Acc: 86.133

Epoch 24: Validation loss decreased (0.356115 --> 0.354804).  Saving model ...
	 Train_Loss: 0.4047 Train_Acc: 83.301 Val_Loss: 0.3548  BEST VAL Loss: 0.3548  Val_Acc: 86.031

Epoch 25: Validation loss decreased (0.354804 --> 0.353689).  Saving model ...
	 Train_Loss: 0.4031 Train_Acc: 83.461 Val_Loss: 0.3537  BEST VAL Loss: 0.3537  Val_Acc: 85.902

Epoch 26: Validation loss decreased (0.353689 --> 0.352632).  Saving model ...
	 Train_Loss: 0.4016 Train_Acc: 83.542 Val_Loss: 0.3526  BEST VAL Loss: 0.3526  Val_Acc: 86.009

Epoch 27: Validation loss decreased (0.352632 --> 0.351485).  Saving model ...
	 Train_Loss: 0.4002 Train_Acc: 83.515 Val_Loss: 0.3515  BEST VAL Loss: 0.3515  Val_Acc: 86.491

Epoch 28: Validation loss decreased (0.351485 --> 0.350218).  Saving model ...
	 Train_Loss: 0.3989 Train_Acc: 83.551 Val_Loss: 0.3502  BEST VAL Loss: 0.3502  Val_Acc: 86.562

Epoch 29: Validation loss decreased (0.350218 --> 0.349180).  Saving model ...
	 Train_Loss: 0.3976 Train_Acc: 83.628 Val_Loss: 0.3492  BEST VAL Loss: 0.3492  Val_Acc: 86.310

Epoch 30: Validation loss decreased (0.349180 --> 0.347839).  Saving model ...
	 Train_Loss: 0.3965 Train_Acc: 83.590 Val_Loss: 0.3478  BEST VAL Loss: 0.3478  Val_Acc: 86.673

Epoch 31: Validation loss decreased (0.347839 --> 0.346862).  Saving model ...
	 Train_Loss: 0.3953 Train_Acc: 83.591 Val_Loss: 0.3469  BEST VAL Loss: 0.3469  Val_Acc: 86.474

Epoch 32: Validation loss decreased (0.346862 --> 0.345875).  Saving model ...
	 Train_Loss: 0.3942 Train_Acc: 83.724 Val_Loss: 0.3459  BEST VAL Loss: 0.3459  Val_Acc: 86.389

Epoch 33: Validation loss decreased (0.345875 --> 0.344821).  Saving model ...
	 Train_Loss: 0.3931 Train_Acc: 83.719 Val_Loss: 0.3448  BEST VAL Loss: 0.3448  Val_Acc: 86.558

Epoch 34: Validation loss decreased (0.344821 --> 0.344118).  Saving model ...
	 Train_Loss: 0.3921 Train_Acc: 83.652 Val_Loss: 0.3441  BEST VAL Loss: 0.3441  Val_Acc: 86.310

Epoch 35: Validation loss decreased (0.344118 --> 0.343151).  Saving model ...
	 Train_Loss: 0.3911 Train_Acc: 83.696 Val_Loss: 0.3432  BEST VAL Loss: 0.3432  Val_Acc: 86.624

Epoch 36: Validation loss decreased (0.343151 --> 0.342123).  Saving model ...
	 Train_Loss: 0.3902 Train_Acc: 83.749 Val_Loss: 0.3421  BEST VAL Loss: 0.3421  Val_Acc: 86.606

Epoch 37: Validation loss decreased (0.342123 --> 0.341316).  Saving model ...
	 Train_Loss: 0.3893 Train_Acc: 83.865 Val_Loss: 0.3413  BEST VAL Loss: 0.3413  Val_Acc: 86.624

Epoch 38: Validation loss decreased (0.341316 --> 0.340516).  Saving model ...
	 Train_Loss: 0.3884 Train_Acc: 83.872 Val_Loss: 0.3405  BEST VAL Loss: 0.3405  Val_Acc: 86.726

Epoch 39: Validation loss decreased (0.340516 --> 0.339662).  Saving model ...
	 Train_Loss: 0.3875 Train_Acc: 83.912 Val_Loss: 0.3397  BEST VAL Loss: 0.3397  Val_Acc: 86.792

Epoch 40: Validation loss decreased (0.339662 --> 0.338897).  Saving model ...
	 Train_Loss: 0.3867 Train_Acc: 83.889 Val_Loss: 0.3389  BEST VAL Loss: 0.3389  Val_Acc: 86.810

Epoch 41: Validation loss decreased (0.338897 --> 0.338228).  Saving model ...
	 Train_Loss: 0.3859 Train_Acc: 83.891 Val_Loss: 0.3382  BEST VAL Loss: 0.3382  Val_Acc: 86.642

Epoch 42: Validation loss decreased (0.338228 --> 0.337497).  Saving model ...
	 Train_Loss: 0.3852 Train_Acc: 83.944 Val_Loss: 0.3375  BEST VAL Loss: 0.3375  Val_Acc: 86.978

Epoch 43: Validation loss decreased (0.337497 --> 0.336686).  Saving model ...
	 Train_Loss: 0.3844 Train_Acc: 84.003 Val_Loss: 0.3367  BEST VAL Loss: 0.3367  Val_Acc: 86.930

Epoch 44: Validation loss decreased (0.336686 --> 0.336046).  Saving model ...
	 Train_Loss: 0.3837 Train_Acc: 84.003 Val_Loss: 0.3360  BEST VAL Loss: 0.3360  Val_Acc: 86.828

Epoch 45: Validation loss decreased (0.336046 --> 0.335412).  Saving model ...
	 Train_Loss: 0.3830 Train_Acc: 83.912 Val_Loss: 0.3354  BEST VAL Loss: 0.3354  Val_Acc: 86.934

Epoch 46: Validation loss decreased (0.335412 --> 0.334697).  Saving model ...
	 Train_Loss: 0.3823 Train_Acc: 84.061 Val_Loss: 0.3347  BEST VAL Loss: 0.3347  Val_Acc: 86.854

Epoch 47: Validation loss decreased (0.334697 --> 0.334003).  Saving model ...
	 Train_Loss: 0.3816 Train_Acc: 83.948 Val_Loss: 0.3340  BEST VAL Loss: 0.3340  Val_Acc: 87.040

Epoch 48: Validation loss decreased (0.334003 --> 0.333550).  Saving model ...
	 Train_Loss: 0.3810 Train_Acc: 84.019 Val_Loss: 0.3335  BEST VAL Loss: 0.3335  Val_Acc: 86.624

Epoch 49: Validation loss decreased (0.333550 --> 0.332866).  Saving model ...
	 Train_Loss: 0.3804 Train_Acc: 84.126 Val_Loss: 0.3329  BEST VAL Loss: 0.3329  Val_Acc: 87.209

Epoch 50: Validation loss decreased (0.332866 --> 0.332356).  Saving model ...
	 Train_Loss: 0.3797 Train_Acc: 84.194 Val_Loss: 0.3324  BEST VAL Loss: 0.3324  Val_Acc: 86.739

Epoch 51: Validation loss decreased (0.332356 --> 0.332029).  Saving model ...
	 Train_Loss: 0.3791 Train_Acc: 84.148 Val_Loss: 0.3320  BEST VAL Loss: 0.3320  Val_Acc: 86.389

Epoch 52: Validation loss decreased (0.332029 --> 0.331416).  Saving model ...
	 Train_Loss: 0.3785 Train_Acc: 84.112 Val_Loss: 0.3314  BEST VAL Loss: 0.3314  Val_Acc: 87.200

Epoch 53: Validation loss decreased (0.331416 --> 0.330992).  Saving model ...
	 Train_Loss: 0.3780 Train_Acc: 84.159 Val_Loss: 0.3310  BEST VAL Loss: 0.3310  Val_Acc: 86.682

Epoch 54: Validation loss decreased (0.330992 --> 0.330658).  Saving model ...
	 Train_Loss: 0.3774 Train_Acc: 84.150 Val_Loss: 0.3307  BEST VAL Loss: 0.3307  Val_Acc: 86.527

Epoch 55: Validation loss decreased (0.330658 --> 0.330115).  Saving model ...
	 Train_Loss: 0.3769 Train_Acc: 84.160 Val_Loss: 0.3301  BEST VAL Loss: 0.3301  Val_Acc: 87.080

Epoch 56: Validation loss decreased (0.330115 --> 0.329611).  Saving model ...
	 Train_Loss: 0.3764 Train_Acc: 84.169 Val_Loss: 0.3296  BEST VAL Loss: 0.3296  Val_Acc: 86.894

Epoch 57: Validation loss decreased (0.329611 --> 0.329148).  Saving model ...
	 Train_Loss: 0.3759 Train_Acc: 84.248 Val_Loss: 0.3291  BEST VAL Loss: 0.3291  Val_Acc: 87.107

Epoch 58: Validation loss decreased (0.329148 --> 0.328578).  Saving model ...
	 Train_Loss: 0.3754 Train_Acc: 84.200 Val_Loss: 0.3286  BEST VAL Loss: 0.3286  Val_Acc: 87.235

Epoch 59: Validation loss decreased (0.328578 --> 0.328183).  Saving model ...
	 Train_Loss: 0.3749 Train_Acc: 84.241 Val_Loss: 0.3282  BEST VAL Loss: 0.3282  Val_Acc: 86.859

Epoch 60: Validation loss decreased (0.328183 --> 0.327647).  Saving model ...
	 Train_Loss: 0.3744 Train_Acc: 84.332 Val_Loss: 0.3276  BEST VAL Loss: 0.3276  Val_Acc: 87.346

Epoch 61: Validation loss decreased (0.327647 --> 0.327214).  Saving model ...
	 Train_Loss: 0.3739 Train_Acc: 84.331 Val_Loss: 0.3272  BEST VAL Loss: 0.3272  Val_Acc: 87.147

Epoch 62: Validation loss decreased (0.327214 --> 0.326703).  Saving model ...
	 Train_Loss: 0.3735 Train_Acc: 84.207 Val_Loss: 0.3267  BEST VAL Loss: 0.3267  Val_Acc: 87.284

Epoch 63: Validation loss decreased (0.326703 --> 0.326273).  Saving model ...
	 Train_Loss: 0.3730 Train_Acc: 84.295 Val_Loss: 0.3263  BEST VAL Loss: 0.3263  Val_Acc: 87.076

Epoch 64: Validation loss decreased (0.326273 --> 0.325783).  Saving model ...
	 Train_Loss: 0.3726 Train_Acc: 84.244 Val_Loss: 0.3258  BEST VAL Loss: 0.3258  Val_Acc: 87.328

Epoch 65: Validation loss decreased (0.325783 --> 0.325457).  Saving model ...
	 Train_Loss: 0.3722 Train_Acc: 84.247 Val_Loss: 0.3255  BEST VAL Loss: 0.3255  Val_Acc: 86.939

Epoch 66: Validation loss decreased (0.325457 --> 0.325094).  Saving model ...
	 Train_Loss: 0.3718 Train_Acc: 84.399 Val_Loss: 0.3251  BEST VAL Loss: 0.3251  Val_Acc: 87.120

Epoch 67: Validation loss decreased (0.325094 --> 0.324756).  Saving model ...
	 Train_Loss: 0.3713 Train_Acc: 84.360 Val_Loss: 0.3248  BEST VAL Loss: 0.3248  Val_Acc: 86.930

Epoch 68: Validation loss decreased (0.324756 --> 0.324385).  Saving model ...
	 Train_Loss: 0.3709 Train_Acc: 84.333 Val_Loss: 0.3244  BEST VAL Loss: 0.3244  Val_Acc: 87.262

Epoch 69: Validation loss decreased (0.324385 --> 0.324026).  Saving model ...
	 Train_Loss: 0.3706 Train_Acc: 84.410 Val_Loss: 0.3240  BEST VAL Loss: 0.3240  Val_Acc: 87.364

Epoch 70: Validation loss decreased (0.324026 --> 0.323623).  Saving model ...
	 Train_Loss: 0.3702 Train_Acc: 84.414 Val_Loss: 0.3236  BEST VAL Loss: 0.3236  Val_Acc: 87.333

Epoch 71: Validation loss decreased (0.323623 --> 0.323375).  Saving model ...
	 Train_Loss: 0.3698 Train_Acc: 84.335 Val_Loss: 0.3234  BEST VAL Loss: 0.3234  Val_Acc: 86.925

Epoch 72: Validation loss decreased (0.323375 --> 0.323154).  Saving model ...
	 Train_Loss: 0.3694 Train_Acc: 84.393 Val_Loss: 0.3232  BEST VAL Loss: 0.3232  Val_Acc: 86.664

Epoch 73: Validation loss decreased (0.323154 --> 0.322770).  Saving model ...
	 Train_Loss: 0.3690 Train_Acc: 84.417 Val_Loss: 0.3228  BEST VAL Loss: 0.3228  Val_Acc: 87.262

Epoch 74: Validation loss decreased (0.322770 --> 0.322444).  Saving model ...
	 Train_Loss: 0.3687 Train_Acc: 84.418 Val_Loss: 0.3224  BEST VAL Loss: 0.3224  Val_Acc: 87.244

Epoch 75: Validation loss decreased (0.322444 --> 0.322108).  Saving model ...
	 Train_Loss: 0.3683 Train_Acc: 84.467 Val_Loss: 0.3221  BEST VAL Loss: 0.3221  Val_Acc: 87.200

Epoch 76: Validation loss decreased (0.322108 --> 0.321784).  Saving model ...
	 Train_Loss: 0.3680 Train_Acc: 84.432 Val_Loss: 0.3218  BEST VAL Loss: 0.3218  Val_Acc: 87.253

Epoch 77: Validation loss decreased (0.321784 --> 0.321429).  Saving model ...
	 Train_Loss: 0.3676 Train_Acc: 84.385 Val_Loss: 0.3214  BEST VAL Loss: 0.3214  Val_Acc: 87.404

Epoch 78: Validation loss decreased (0.321429 --> 0.321040).  Saving model ...
	 Train_Loss: 0.3673 Train_Acc: 84.513 Val_Loss: 0.3210  BEST VAL Loss: 0.3210  Val_Acc: 87.523

Epoch 79: Validation loss decreased (0.321040 --> 0.320717).  Saving model ...
	 Train_Loss: 0.3670 Train_Acc: 84.390 Val_Loss: 0.3207  BEST VAL Loss: 0.3207  Val_Acc: 87.355

Epoch 80: Validation loss decreased (0.320717 --> 0.320407).  Saving model ...
	 Train_Loss: 0.3666 Train_Acc: 84.558 Val_Loss: 0.3204  BEST VAL Loss: 0.3204  Val_Acc: 87.421

Epoch 81: Validation loss decreased (0.320407 --> 0.320078).  Saving model ...
	 Train_Loss: 0.3663 Train_Acc: 84.584 Val_Loss: 0.3201  BEST VAL Loss: 0.3201  Val_Acc: 87.501

Epoch 82: Validation loss decreased (0.320078 --> 0.319780).  Saving model ...
	 Train_Loss: 0.3660 Train_Acc: 84.542 Val_Loss: 0.3198  BEST VAL Loss: 0.3198  Val_Acc: 87.399

Epoch 83: Validation loss decreased (0.319780 --> 0.319464).  Saving model ...
	 Train_Loss: 0.3656 Train_Acc: 84.604 Val_Loss: 0.3195  BEST VAL Loss: 0.3195  Val_Acc: 87.492

Epoch 84: Validation loss decreased (0.319464 --> 0.319150).  Saving model ...
	 Train_Loss: 0.3653 Train_Acc: 84.562 Val_Loss: 0.3192  BEST VAL Loss: 0.3192  Val_Acc: 87.523

Epoch 85: Validation loss decreased (0.319150 --> 0.318897).  Saving model ...
	 Train_Loss: 0.3650 Train_Acc: 84.545 Val_Loss: 0.3189  BEST VAL Loss: 0.3189  Val_Acc: 87.258

Epoch 86: Validation loss decreased (0.318897 --> 0.318580).  Saving model ...
	 Train_Loss: 0.3647 Train_Acc: 84.481 Val_Loss: 0.3186  BEST VAL Loss: 0.3186  Val_Acc: 87.647

Epoch 87: Validation loss decreased (0.318580 --> 0.318315).  Saving model ...
	 Train_Loss: 0.3645 Train_Acc: 84.587 Val_Loss: 0.3183  BEST VAL Loss: 0.3183  Val_Acc: 87.448

Epoch 88: Validation loss decreased (0.318315 --> 0.318025).  Saving model ...
	 Train_Loss: 0.3642 Train_Acc: 84.508 Val_Loss: 0.3180  BEST VAL Loss: 0.3180  Val_Acc: 87.408

Epoch 89: Validation loss decreased (0.318025 --> 0.317791).  Saving model ...
	 Train_Loss: 0.3639 Train_Acc: 84.551 Val_Loss: 0.3178  BEST VAL Loss: 0.3178  Val_Acc: 87.262

Epoch 90: Validation loss decreased (0.317791 --> 0.317574).  Saving model ...
	 Train_Loss: 0.3636 Train_Acc: 84.506 Val_Loss: 0.3176  BEST VAL Loss: 0.3176  Val_Acc: 87.444

Epoch 91: Validation loss decreased (0.317574 --> 0.317291).  Saving model ...
	 Train_Loss: 0.3633 Train_Acc: 84.509 Val_Loss: 0.3173  BEST VAL Loss: 0.3173  Val_Acc: 87.355

Epoch 92: Validation loss decreased (0.317291 --> 0.317094).  Saving model ...
	 Train_Loss: 0.3631 Train_Acc: 84.423 Val_Loss: 0.3171  BEST VAL Loss: 0.3171  Val_Acc: 87.271

Epoch 93: Validation loss decreased (0.317094 --> 0.316785).  Saving model ...
	 Train_Loss: 0.3628 Train_Acc: 84.594 Val_Loss: 0.3168  BEST VAL Loss: 0.3168  Val_Acc: 87.603

Epoch 94: Validation loss decreased (0.316785 --> 0.316533).  Saving model ...
	 Train_Loss: 0.3626 Train_Acc: 84.538 Val_Loss: 0.3165  BEST VAL Loss: 0.3165  Val_Acc: 87.386

Epoch 95: Validation loss decreased (0.316533 --> 0.316339).  Saving model ...
	 Train_Loss: 0.3623 Train_Acc: 84.485 Val_Loss: 0.3163  BEST VAL Loss: 0.3163  Val_Acc: 87.076

Epoch 96: Validation loss decreased (0.316339 --> 0.316080).  Saving model ...
	 Train_Loss: 0.3621 Train_Acc: 84.666 Val_Loss: 0.3161  BEST VAL Loss: 0.3161  Val_Acc: 87.497

Epoch 97: Validation loss decreased (0.316080 --> 0.315864).  Saving model ...
	 Train_Loss: 0.3618 Train_Acc: 84.570 Val_Loss: 0.3159  BEST VAL Loss: 0.3159  Val_Acc: 87.390

Epoch 98: Validation loss decreased (0.315864 --> 0.315659).  Saving model ...
	 Train_Loss: 0.3616 Train_Acc: 84.490 Val_Loss: 0.3157  BEST VAL Loss: 0.3157  Val_Acc: 87.492

Epoch 99: Validation loss decreased (0.315659 --> 0.315410).  Saving model ...
	 Train_Loss: 0.3614 Train_Acc: 84.710 Val_Loss: 0.3154  BEST VAL Loss: 0.3154  Val_Acc: 87.585

Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.86      0.90      0.88     82968
           1       0.91      0.88      0.90     97655

    accuracy                           0.89    180623
   macro avg       0.89      0.89      0.89    180623
weighted avg       0.89      0.89      0.89    180623

Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.85      0.89      0.87     10371
           1       0.90      0.87      0.88     12207

    accuracy                           0.88     22578
   macro avg       0.87      0.88      0.88     22578
weighted avg       0.88      0.88      0.88     22578

Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.85      0.89      0.87     10371
           1       0.90      0.87      0.88     12207

    accuracy                           0.88     22578
   macro avg       0.88      0.88      0.88     22578
weighted avg       0.88      0.88      0.88     22578

              precision    recall  f1-score   support

           0       0.85      0.89      0.87     10371
           1       0.90      0.87      0.88     12207

    accuracy                           0.88     22578
   macro avg       0.88      0.88      0.88     22578
weighted avg       0.88      0.88      0.88     22578

Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.77      0.81      0.79     34887
           1       0.84      0.81      0.83     44915

    accuracy                           0.81     79802
   macro avg       0.81      0.81      0.81     79802
weighted avg       0.81      0.81      0.81     79802

              precision    recall  f1-score   support

           0       0.77      0.81      0.79     34887
           1       0.84      0.81      0.83     44915

    accuracy                           0.81     79802
   macro avg       0.81      0.81      0.81     79802
weighted avg       0.81      0.81      0.81     79802

completed
