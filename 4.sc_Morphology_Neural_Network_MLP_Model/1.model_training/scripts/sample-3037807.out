[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '78a30e9a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '44cdcf2b'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '9d5d3d61'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '76d4fcd6'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Flagellin_1.000_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Flagellin_1.000_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Flagellin_0.100_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (200462, 1270)
Number of total missing values across all columns: 437540
Data Subset Is Off
Wells held out for testing: ['L10' 'M10']
Wells to use for training, validation, and testing ['L05' 'M05' 'L11' 'M11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.672944).  Saving model ...
	 Train_Loss: 0.7028 Train_Acc: 53.408 Val_Loss: 0.6729  BEST VAL Loss: 0.6729  Val_Acc: 60.042

Epoch 1: Validation loss decreased (0.672944 --> 0.665601).  Saving model ...
	 Train_Loss: 0.6859 Train_Acc: 58.001 Val_Loss: 0.6656  BEST VAL Loss: 0.6656  Val_Acc: 64.997

Epoch 2: Validation loss decreased (0.665601 --> 0.654633).  Saving model ...
	 Train_Loss: 0.6751 Train_Acc: 61.129 Val_Loss: 0.6546  BEST VAL Loss: 0.6546  Val_Acc: 67.317

Epoch 3: Validation loss decreased (0.654633 --> 0.642566).  Saving model ...
	 Train_Loss: 0.6656 Train_Acc: 63.618 Val_Loss: 0.6426  BEST VAL Loss: 0.6426  Val_Acc: 68.061

Epoch 4: Validation loss decreased (0.642566 --> 0.637270).  Saving model ...
	 Train_Loss: 0.6567 Train_Acc: 65.316 Val_Loss: 0.6373  BEST VAL Loss: 0.6373  Val_Acc: 66.949

Epoch 5: Validation loss decreased (0.637270 --> 0.627696).  Saving model ...
	 Train_Loss: 0.6484 Train_Acc: 66.262 Val_Loss: 0.6277  BEST VAL Loss: 0.6277  Val_Acc: 70.764

Epoch 6: Validation loss decreased (0.627696 --> 0.620058).  Saving model ...
	 Train_Loss: 0.6410 Train_Acc: 67.241 Val_Loss: 0.6201  BEST VAL Loss: 0.6201  Val_Acc: 71.424

Epoch 7: Validation loss decreased (0.620058 --> 0.611408).  Saving model ...
	 Train_Loss: 0.6344 Train_Acc: 68.158 Val_Loss: 0.6114  BEST VAL Loss: 0.6114  Val_Acc: 72.032

Epoch 8: Validation loss decreased (0.611408 --> 0.602326).  Saving model ...
	 Train_Loss: 0.6283 Train_Acc: 69.065 Val_Loss: 0.6023  BEST VAL Loss: 0.6023  Val_Acc: 74.270

Epoch 9: Validation loss decreased (0.602326 --> 0.596996).  Saving model ...
	 Train_Loss: 0.6230 Train_Acc: 69.355 Val_Loss: 0.5970  BEST VAL Loss: 0.5970  Val_Acc: 71.822

Epoch 10: Validation loss decreased (0.596996 --> 0.590073).  Saving model ...
	 Train_Loss: 0.6181 Train_Acc: 69.802 Val_Loss: 0.5901  BEST VAL Loss: 0.5901  Val_Acc: 74.360

Epoch 11: Validation loss decreased (0.590073 --> 0.584073).  Saving model ...
	 Train_Loss: 0.6137 Train_Acc: 69.956 Val_Loss: 0.5841  BEST VAL Loss: 0.5841  Val_Acc: 74.720

Epoch 12: Validation loss decreased (0.584073 --> 0.579402).  Saving model ...
	 Train_Loss: 0.6096 Train_Acc: 70.601 Val_Loss: 0.5794  BEST VAL Loss: 0.5794  Val_Acc: 73.955

Epoch 13: Validation loss decreased (0.579402 --> 0.575491).  Saving model ...
	 Train_Loss: 0.6059 Train_Acc: 70.890 Val_Loss: 0.5755  BEST VAL Loss: 0.5755  Val_Acc: 74.608

Epoch 14: Validation loss decreased (0.575491 --> 0.571031).  Saving model ...
	 Train_Loss: 0.6026 Train_Acc: 70.862 Val_Loss: 0.5710  BEST VAL Loss: 0.5710  Val_Acc: 75.306

Epoch 15: Validation loss decreased (0.571031 --> 0.568155).  Saving model ...
	 Train_Loss: 0.5995 Train_Acc: 71.420 Val_Loss: 0.5682  BEST VAL Loss: 0.5682  Val_Acc: 74.803

Epoch 16: Validation loss decreased (0.568155 --> 0.564933).  Saving model ...
	 Train_Loss: 0.5967 Train_Acc: 71.298 Val_Loss: 0.5649  BEST VAL Loss: 0.5649  Val_Acc: 74.818

Epoch 17: Validation loss decreased (0.564933 --> 0.561505).  Saving model ...
	 Train_Loss: 0.5941 Train_Acc: 71.743 Val_Loss: 0.5615  BEST VAL Loss: 0.5615  Val_Acc: 75.561

Epoch 18: Validation loss decreased (0.561505 --> 0.557689).  Saving model ...
	 Train_Loss: 0.5916 Train_Acc: 71.977 Val_Loss: 0.5577  BEST VAL Loss: 0.5577  Val_Acc: 76.237

Epoch 19: Validation loss decreased (0.557689 --> 0.555626).  Saving model ...
	 Train_Loss: 0.5892 Train_Acc: 72.061 Val_Loss: 0.5556  BEST VAL Loss: 0.5556  Val_Acc: 74.833

Epoch 20: Validation loss decreased (0.555626 --> 0.552809).  Saving model ...
	 Train_Loss: 0.5870 Train_Acc: 72.532 Val_Loss: 0.5528  BEST VAL Loss: 0.5528  Val_Acc: 75.343

Epoch 21: Validation loss decreased (0.552809 --> 0.550005).  Saving model ...
	 Train_Loss: 0.5850 Train_Acc: 72.474 Val_Loss: 0.5500  BEST VAL Loss: 0.5500  Val_Acc: 76.455

Epoch 22: Validation loss decreased (0.550005 --> 0.547699).  Saving model ...
	 Train_Loss: 0.5830 Train_Acc: 72.888 Val_Loss: 0.5477  BEST VAL Loss: 0.5477  Val_Acc: 76.732

Epoch 23: Validation loss decreased (0.547699 --> 0.545196).  Saving model ...
	 Train_Loss: 0.5813 Train_Acc: 72.714 Val_Loss: 0.5452  BEST VAL Loss: 0.5452  Val_Acc: 77.063

Epoch 24: Validation loss decreased (0.545196 --> 0.543304).  Saving model ...
	 Train_Loss: 0.5796 Train_Acc: 72.808 Val_Loss: 0.5433  BEST VAL Loss: 0.5433  Val_Acc: 76.522

Epoch 25: Validation loss decreased (0.543304 --> 0.540893).  Saving model ...
	 Train_Loss: 0.5780 Train_Acc: 73.052 Val_Loss: 0.5409  BEST VAL Loss: 0.5409  Val_Acc: 76.290

Epoch 26: Validation loss decreased (0.540893 --> 0.539226).  Saving model ...
	 Train_Loss: 0.5764 Train_Acc: 73.132 Val_Loss: 0.5392  BEST VAL Loss: 0.5392  Val_Acc: 76.395

Epoch 27: Validation loss decreased (0.539226 --> 0.537248).  Saving model ...
	 Train_Loss: 0.5749 Train_Acc: 73.397 Val_Loss: 0.5372  BEST VAL Loss: 0.5372  Val_Acc: 76.320

Epoch 28: Validation loss decreased (0.537248 --> 0.535524).  Saving model ...
	 Train_Loss: 0.5735 Train_Acc: 73.328 Val_Loss: 0.5355  BEST VAL Loss: 0.5355  Val_Acc: 76.845

Epoch 29: Validation loss decreased (0.535524 --> 0.533888).  Saving model ...
	 Train_Loss: 0.5721 Train_Acc: 73.297 Val_Loss: 0.5339  BEST VAL Loss: 0.5339  Val_Acc: 76.808

Epoch 30: Validation loss decreased (0.533888 --> 0.532482).  Saving model ...
	 Train_Loss: 0.5708 Train_Acc: 73.529 Val_Loss: 0.5325  BEST VAL Loss: 0.5325  Val_Acc: 76.417

Epoch 31: Validation loss decreased (0.532482 --> 0.531142).  Saving model ...
	 Train_Loss: 0.5694 Train_Acc: 73.697 Val_Loss: 0.5311  BEST VAL Loss: 0.5311  Val_Acc: 76.575

Epoch 32: Validation loss decreased (0.531142 --> 0.530023).  Saving model ...
	 Train_Loss: 0.5682 Train_Acc: 73.751 Val_Loss: 0.5300  BEST VAL Loss: 0.5300  Val_Acc: 76.274

Epoch 33: Validation loss decreased (0.530023 --> 0.528685).  Saving model ...
	 Train_Loss: 0.5670 Train_Acc: 73.760 Val_Loss: 0.5287  BEST VAL Loss: 0.5287  Val_Acc: 76.695

Epoch 34: Validation loss decreased (0.528685 --> 0.527511).  Saving model ...
	 Train_Loss: 0.5659 Train_Acc: 73.761 Val_Loss: 0.5275  BEST VAL Loss: 0.5275  Val_Acc: 76.627

Epoch 35: Validation loss decreased (0.527511 --> 0.526279).  Saving model ...
	 Train_Loss: 0.5648 Train_Acc: 73.953 Val_Loss: 0.5263  BEST VAL Loss: 0.5263  Val_Acc: 77.153

Epoch 36: Validation loss decreased (0.526279 --> 0.525149).  Saving model ...
	 Train_Loss: 0.5638 Train_Acc: 73.796 Val_Loss: 0.5251  BEST VAL Loss: 0.5251  Val_Acc: 76.342

Epoch 37: Validation loss decreased (0.525149 --> 0.523791).  Saving model ...
	 Train_Loss: 0.5628 Train_Acc: 73.759 Val_Loss: 0.5238  BEST VAL Loss: 0.5238  Val_Acc: 77.378

Epoch 38: Validation loss decreased (0.523791 --> 0.522444).  Saving model ...
	 Train_Loss: 0.5619 Train_Acc: 73.825 Val_Loss: 0.5224  BEST VAL Loss: 0.5224  Val_Acc: 77.063

Epoch 39: Validation loss decreased (0.522444 --> 0.521419).  Saving model ...
	 Train_Loss: 0.5609 Train_Acc: 74.055 Val_Loss: 0.5214  BEST VAL Loss: 0.5214  Val_Acc: 76.995

Epoch 40: Validation loss decreased (0.521419 --> 0.520593).  Saving model ...
	 Train_Loss: 0.5600 Train_Acc: 73.912 Val_Loss: 0.5206  BEST VAL Loss: 0.5206  Val_Acc: 76.642

Epoch 41: Validation loss decreased (0.520593 --> 0.519762).  Saving model ...
	 Train_Loss: 0.5591 Train_Acc: 74.150 Val_Loss: 0.5198  BEST VAL Loss: 0.5198  Val_Acc: 76.567

Epoch 42: Validation loss decreased (0.519762 --> 0.518666).  Saving model ...
	 Train_Loss: 0.5582 Train_Acc: 74.055 Val_Loss: 0.5187  BEST VAL Loss: 0.5187  Val_Acc: 77.656

Epoch 43: Validation loss decreased (0.518666 --> 0.517700).  Saving model ...
	 Train_Loss: 0.5574 Train_Acc: 74.142 Val_Loss: 0.5177  BEST VAL Loss: 0.5177  Val_Acc: 77.010

Epoch 44: Validation loss decreased (0.517700 --> 0.516829).  Saving model ...
	 Train_Loss: 0.5566 Train_Acc: 74.370 Val_Loss: 0.5168  BEST VAL Loss: 0.5168  Val_Acc: 77.814

Epoch 45: Validation loss decreased (0.516829 --> 0.516045).  Saving model ...
	 Train_Loss: 0.5559 Train_Acc: 74.085 Val_Loss: 0.5160  BEST VAL Loss: 0.5160  Val_Acc: 77.318

Epoch 46: Validation loss decreased (0.516045 --> 0.515226).  Saving model ...
	 Train_Loss: 0.5552 Train_Acc: 74.264 Val_Loss: 0.5152  BEST VAL Loss: 0.5152  Val_Acc: 77.468

Epoch 47: Validation loss decreased (0.515226 --> 0.514318).  Saving model ...
	 Train_Loss: 0.5545 Train_Acc: 74.217 Val_Loss: 0.5143  BEST VAL Loss: 0.5143  Val_Acc: 77.363

Epoch 48: Validation loss decreased (0.514318 --> 0.513581).  Saving model ...
	 Train_Loss: 0.5537 Train_Acc: 74.260 Val_Loss: 0.5136  BEST VAL Loss: 0.5136  Val_Acc: 77.874

Epoch 49: Validation loss decreased (0.513581 --> 0.512611).  Saving model ...
	 Train_Loss: 0.5530 Train_Acc: 74.561 Val_Loss: 0.5126  BEST VAL Loss: 0.5126  Val_Acc: 77.919

Epoch 50: Validation loss decreased (0.512611 --> 0.511965).  Saving model ...
	 Train_Loss: 0.5524 Train_Acc: 74.233 Val_Loss: 0.5120  BEST VAL Loss: 0.5120  Val_Acc: 76.898

Epoch 51: Validation loss decreased (0.511965 --> 0.511339).  Saving model ...
	 Train_Loss: 0.5517 Train_Acc: 74.423 Val_Loss: 0.5113  BEST VAL Loss: 0.5113  Val_Acc: 77.281

Epoch 52: Validation loss decreased (0.511339 --> 0.510743).  Saving model ...
	 Train_Loss: 0.5511 Train_Acc: 74.359 Val_Loss: 0.5107  BEST VAL Loss: 0.5107  Val_Acc: 77.829

Epoch 53: Validation loss decreased (0.510743 --> 0.510032).  Saving model ...
	 Train_Loss: 0.5505 Train_Acc: 74.589 Val_Loss: 0.5100  BEST VAL Loss: 0.5100  Val_Acc: 77.190

Epoch 54: Validation loss decreased (0.510032 --> 0.509265).  Saving model ...
	 Train_Loss: 0.5499 Train_Acc: 74.674 Val_Loss: 0.5093  BEST VAL Loss: 0.5093  Val_Acc: 78.039

Epoch 55: Validation loss decreased (0.509265 --> 0.508693).  Saving model ...
	 Train_Loss: 0.5493 Train_Acc: 74.740 Val_Loss: 0.5087  BEST VAL Loss: 0.5087  Val_Acc: 77.438

Epoch 56: Validation loss decreased (0.508693 --> 0.508008).  Saving model ...
	 Train_Loss: 0.5487 Train_Acc: 74.513 Val_Loss: 0.5080  BEST VAL Loss: 0.5080  Val_Acc: 78.069

Epoch 57: Validation loss decreased (0.508008 --> 0.507357).  Saving model ...
	 Train_Loss: 0.5481 Train_Acc: 74.663 Val_Loss: 0.5074  BEST VAL Loss: 0.5074  Val_Acc: 77.709

Epoch 58: Validation loss decreased (0.507357 --> 0.506561).  Saving model ...
	 Train_Loss: 0.5475 Train_Acc: 74.712 Val_Loss: 0.5066  BEST VAL Loss: 0.5066  Val_Acc: 77.919

Epoch 59: Validation loss decreased (0.506561 --> 0.505882).  Saving model ...
	 Train_Loss: 0.5470 Train_Acc: 74.695 Val_Loss: 0.5059  BEST VAL Loss: 0.5059  Val_Acc: 77.859

Epoch 60: Validation loss decreased (0.505882 --> 0.505128).  Saving model ...
	 Train_Loss: 0.5464 Train_Acc: 74.789 Val_Loss: 0.5051  BEST VAL Loss: 0.5051  Val_Acc: 78.031

Epoch 61: Validation loss decreased (0.505128 --> 0.504431).  Saving model ...
	 Train_Loss: 0.5458 Train_Acc: 74.914 Val_Loss: 0.5044  BEST VAL Loss: 0.5044  Val_Acc: 77.956

Epoch 62: Validation loss decreased (0.504431 --> 0.503851).  Saving model ...
	 Train_Loss: 0.5453 Train_Acc: 74.843 Val_Loss: 0.5039  BEST VAL Loss: 0.5039  Val_Acc: 78.099

Epoch 63: Validation loss decreased (0.503851 --> 0.503372).  Saving model ...
	 Train_Loss: 0.5448 Train_Acc: 74.738 Val_Loss: 0.5034  BEST VAL Loss: 0.5034  Val_Acc: 77.551

Epoch 64: Validation loss decreased (0.503372 --> 0.502764).  Saving model ...
	 Train_Loss: 0.5443 Train_Acc: 74.981 Val_Loss: 0.5028  BEST VAL Loss: 0.5028  Val_Acc: 78.242

Epoch 65: Validation loss decreased (0.502764 --> 0.502199).  Saving model ...
	 Train_Loss: 0.5437 Train_Acc: 75.046 Val_Loss: 0.5022  BEST VAL Loss: 0.5022  Val_Acc: 77.964

Epoch 66: Validation loss decreased (0.502199 --> 0.501507).  Saving model ...
	 Train_Loss: 0.5432 Train_Acc: 74.974 Val_Loss: 0.5015  BEST VAL Loss: 0.5015  Val_Acc: 78.775

Epoch 67: Validation loss decreased (0.501507 --> 0.500919).  Saving model ...
	 Train_Loss: 0.5428 Train_Acc: 75.111 Val_Loss: 0.5009  BEST VAL Loss: 0.5009  Val_Acc: 78.197

Epoch 68: Validation loss decreased (0.500919 --> 0.500486).  Saving model ...
	 Train_Loss: 0.5423 Train_Acc: 75.043 Val_Loss: 0.5005  BEST VAL Loss: 0.5005  Val_Acc: 78.197

Epoch 69: Validation loss decreased (0.500486 --> 0.500026).  Saving model ...
	 Train_Loss: 0.5418 Train_Acc: 75.006 Val_Loss: 0.5000  BEST VAL Loss: 0.5000  Val_Acc: 77.986

Epoch 70: Validation loss decreased (0.500026 --> 0.499426).  Saving model ...
	 Train_Loss: 0.5413 Train_Acc: 75.290 Val_Loss: 0.4994  BEST VAL Loss: 0.4994  Val_Acc: 78.152

Epoch 71: Validation loss decreased (0.499426 --> 0.498877).  Saving model ...
	 Train_Loss: 0.5409 Train_Acc: 75.135 Val_Loss: 0.4989  BEST VAL Loss: 0.4989  Val_Acc: 78.294

Epoch 72: Validation loss decreased (0.498877 --> 0.498537).  Saving model ...
	 Train_Loss: 0.5404 Train_Acc: 75.211 Val_Loss: 0.4985  BEST VAL Loss: 0.4985  Val_Acc: 77.633

Epoch 73: Validation loss decreased (0.498537 --> 0.498064).  Saving model ...
	 Train_Loss: 0.5399 Train_Acc: 75.258 Val_Loss: 0.4981  BEST VAL Loss: 0.4981  Val_Acc: 77.656

Epoch 74: Validation loss decreased (0.498064 --> 0.497580).  Saving model ...
	 Train_Loss: 0.5395 Train_Acc: 75.134 Val_Loss: 0.4976  BEST VAL Loss: 0.4976  Val_Acc: 78.197

Epoch 75: Validation loss decreased (0.497580 --> 0.497120).  Saving model ...
	 Train_Loss: 0.5390 Train_Acc: 75.431 Val_Loss: 0.4971  BEST VAL Loss: 0.4971  Val_Acc: 77.814

Epoch 76: Validation loss decreased (0.497120 --> 0.496524).  Saving model ...
	 Train_Loss: 0.5386 Train_Acc: 75.457 Val_Loss: 0.4965  BEST VAL Loss: 0.4965  Val_Acc: 78.422

Epoch 77: Validation loss decreased (0.496524 --> 0.496094).  Saving model ...
	 Train_Loss: 0.5382 Train_Acc: 75.276 Val_Loss: 0.4961  BEST VAL Loss: 0.4961  Val_Acc: 78.302

Epoch 78: Validation loss decreased (0.496094 --> 0.495561).  Saving model ...
	 Train_Loss: 0.5378 Train_Acc: 75.189 Val_Loss: 0.4956  BEST VAL Loss: 0.4956  Val_Acc: 78.091

Epoch 79: Validation loss decreased (0.495561 --> 0.495172).  Saving model ...
	 Train_Loss: 0.5373 Train_Acc: 75.334 Val_Loss: 0.4952  BEST VAL Loss: 0.4952  Val_Acc: 77.926

Epoch 80: Validation loss decreased (0.495172 --> 0.494837).  Saving model ...
	 Train_Loss: 0.5369 Train_Acc: 75.516 Val_Loss: 0.4948  BEST VAL Loss: 0.4948  Val_Acc: 77.498

Epoch 81: Validation loss decreased (0.494837 --> 0.494384).  Saving model ...
	 Train_Loss: 0.5365 Train_Acc: 75.340 Val_Loss: 0.4944  BEST VAL Loss: 0.4944  Val_Acc: 78.805

Epoch 82: Validation loss decreased (0.494384 --> 0.493935).  Saving model ...
	 Train_Loss: 0.5361 Train_Acc: 75.485 Val_Loss: 0.4939  BEST VAL Loss: 0.4939  Val_Acc: 78.512

Epoch 83: Validation loss decreased (0.493935 --> 0.493449).  Saving model ...
	 Train_Loss: 0.5358 Train_Acc: 75.635 Val_Loss: 0.4934  BEST VAL Loss: 0.4934  Val_Acc: 78.632

Epoch 84: Validation loss decreased (0.493449 --> 0.493115).  Saving model ...
	 Train_Loss: 0.5354 Train_Acc: 75.658 Val_Loss: 0.4931  BEST VAL Loss: 0.4931  Val_Acc: 77.746

Epoch 85: Validation loss decreased (0.493115 --> 0.492699).  Saving model ...
	 Train_Loss: 0.5350 Train_Acc: 75.600 Val_Loss: 0.4927  BEST VAL Loss: 0.4927  Val_Acc: 78.617

Epoch 86: Validation loss decreased (0.492699 --> 0.492167).  Saving model ...
	 Train_Loss: 0.5346 Train_Acc: 75.870 Val_Loss: 0.4922  BEST VAL Loss: 0.4922  Val_Acc: 79.000

Epoch 87: Validation loss decreased (0.492167 --> 0.491744).  Saving model ...
	 Train_Loss: 0.5342 Train_Acc: 75.757 Val_Loss: 0.4917  BEST VAL Loss: 0.4917  Val_Acc: 78.459

Epoch 88: Validation loss decreased (0.491744 --> 0.491329).  Saving model ...
	 Train_Loss: 0.5338 Train_Acc: 75.605 Val_Loss: 0.4913  BEST VAL Loss: 0.4913  Val_Acc: 78.640

Epoch 89: Validation loss decreased (0.491329 --> 0.490935).  Saving model ...
	 Train_Loss: 0.5335 Train_Acc: 75.890 Val_Loss: 0.4909  BEST VAL Loss: 0.4909  Val_Acc: 78.632

Epoch 90: Validation loss decreased (0.490935 --> 0.490505).  Saving model ...
	 Train_Loss: 0.5331 Train_Acc: 75.588 Val_Loss: 0.4905  BEST VAL Loss: 0.4905  Val_Acc: 78.497

Epoch 91: Validation loss decreased (0.490505 --> 0.490045).  Saving model ...
	 Train_Loss: 0.5327 Train_Acc: 75.820 Val_Loss: 0.4900  BEST VAL Loss: 0.4900  Val_Acc: 78.279

Epoch 92: Validation loss decreased (0.490045 --> 0.489689).  Saving model ...
	 Train_Loss: 0.5324 Train_Acc: 75.792 Val_Loss: 0.4897  BEST VAL Loss: 0.4897  Val_Acc: 78.579

Epoch 93: Validation loss decreased (0.489689 --> 0.489370).  Saving model ...
	 Train_Loss: 0.5321 Train_Acc: 75.828 Val_Loss: 0.4894  BEST VAL Loss: 0.4894  Val_Acc: 78.219

Epoch 94: Validation loss decreased (0.489370 --> 0.489153).  Saving model ...
	 Train_Loss: 0.5317 Train_Acc: 75.998 Val_Loss: 0.4892  BEST VAL Loss: 0.4892  Val_Acc: 77.476

Epoch 95: Validation loss decreased (0.489153 --> 0.488792).  Saving model ...
	 Train_Loss: 0.5314 Train_Acc: 75.903 Val_Loss: 0.4888  BEST VAL Loss: 0.4888  Val_Acc: 78.497

Epoch 96: Validation loss decreased (0.488792 --> 0.488381).  Saving model ...
	 Train_Loss: 0.5310 Train_Acc: 75.673 Val_Loss: 0.4884  BEST VAL Loss: 0.4884  Val_Acc: 78.549

Epoch 97: Validation loss decreased (0.488381 --> 0.488103).  Saving model ...
	 Train_Loss: 0.5307 Train_Acc: 75.875 Val_Loss: 0.4881  BEST VAL Loss: 0.4881  Val_Acc: 78.377

Epoch 98: Validation loss decreased (0.488103 --> 0.487800).  Saving model ...
	 Train_Loss: 0.5304 Train_Acc: 75.810 Val_Loss: 0.4878  BEST VAL Loss: 0.4878  Val_Acc: 78.917

Epoch 99: Validation loss decreased (0.487800 --> 0.487431).  Saving model ...
	 Train_Loss: 0.5301 Train_Acc: 76.073 Val_Loss: 0.4874  BEST VAL Loss: 0.4874  Val_Acc: 79.180

Flagellin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.47      0.47     50422
           1       0.53      0.52      0.52     56121

    accuracy                           0.50    106543
   macro avg       0.50      0.50      0.50    106543
weighted avg       0.50      0.50      0.50    106543

Flagellin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.47      0.47      6303
           1       0.53      0.53      0.53      7016

    accuracy                           0.50     13319
   macro avg       0.50      0.50      0.50     13319
weighted avg       0.50      0.50      0.50     13319

Flagellin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.47      0.47      6303
           1       0.53      0.53      0.53      7016

    accuracy                           0.50     13319
   macro avg       0.50      0.50      0.50     13319
weighted avg       0.50      0.50      0.50     13319

              precision    recall  f1-score   support

           0       0.47      0.47      0.47      6303
           1       0.53      0.53      0.53      7016

    accuracy                           0.50     13319
   macro avg       0.50      0.50      0.50     13319
weighted avg       0.50      0.50      0.50     13319

Flagellin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.66      0.56     32887
           1       0.51      0.34      0.41     34394

    accuracy                           0.50     67281
   macro avg       0.50      0.50      0.49     67281
weighted avg       0.50      0.50      0.48     67281

              precision    recall  f1-score   support

           0       0.49      0.66      0.56     32887
           1       0.51      0.34      0.41     34394

    accuracy                           0.50     67281
   macro avg       0.50      0.50      0.49     67281
weighted avg       0.50      0.50      0.48     67281

completed
