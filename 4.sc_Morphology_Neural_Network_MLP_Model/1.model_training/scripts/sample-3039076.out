[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'c3c58773'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '17596cc8'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '856078b1'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e97005c0'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_1.000_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_1.000_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_1.000_DMSO_0.025']
The dimensions of the data are: (278030, 1270)
Number of total missing values across all columns: 556060
Data Subset Is Off
Wells held out for testing: ['C08' 'D08']
Wells to use for training, validation, and testing ['C02' 'C03' 'C09' 'D02' 'D03' 'D09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.679513).  Saving model ...
	 Train_Loss: 0.6886 Train_Acc: 53.202 Val_Loss: 0.6795  BEST VAL Loss: 0.6795  Val_Acc: 57.805

Epoch 1: Validation loss decreased (0.679513 --> 0.671186).  Saving model ...
	 Train_Loss: 0.6812 Train_Acc: 57.792 Val_Loss: 0.6712  BEST VAL Loss: 0.6712  Val_Acc: 59.840

Epoch 2: Validation loss decreased (0.671186 --> 0.662257).  Saving model ...
	 Train_Loss: 0.6737 Train_Acc: 60.077 Val_Loss: 0.6623  BEST VAL Loss: 0.6623  Val_Acc: 62.278

Epoch 3: Validation loss decreased (0.662257 --> 0.654353).  Saving model ...
	 Train_Loss: 0.6666 Train_Acc: 61.726 Val_Loss: 0.6544  BEST VAL Loss: 0.6544  Val_Acc: 63.251

Epoch 4: Validation loss decreased (0.654353 --> 0.647587).  Saving model ...
	 Train_Loss: 0.6600 Train_Acc: 62.774 Val_Loss: 0.6476  BEST VAL Loss: 0.6476  Val_Acc: 64.096

Epoch 5: Validation loss decreased (0.647587 --> 0.641465).  Saving model ...
	 Train_Loss: 0.6542 Train_Acc: 63.473 Val_Loss: 0.6415  BEST VAL Loss: 0.6415  Val_Acc: 65.000

Epoch 6: Validation loss decreased (0.641465 --> 0.636002).  Saving model ...
	 Train_Loss: 0.6490 Train_Acc: 64.096 Val_Loss: 0.6360  BEST VAL Loss: 0.6360  Val_Acc: 65.492

Epoch 7: Validation loss decreased (0.636002 --> 0.630969).  Saving model ...
	 Train_Loss: 0.6443 Train_Acc: 64.581 Val_Loss: 0.6310  BEST VAL Loss: 0.6310  Val_Acc: 65.576

Epoch 8: Validation loss decreased (0.630969 --> 0.626309).  Saving model ...
	 Train_Loss: 0.6400 Train_Acc: 64.896 Val_Loss: 0.6263  BEST VAL Loss: 0.6263  Val_Acc: 65.885

Epoch 9: Validation loss decreased (0.626309 --> 0.622374).  Saving model ...
	 Train_Loss: 0.6359 Train_Acc: 65.532 Val_Loss: 0.6224  BEST VAL Loss: 0.6224  Val_Acc: 66.165

Epoch 10: Validation loss decreased (0.622374 --> 0.618406).  Saving model ...
	 Train_Loss: 0.6322 Train_Acc: 65.731 Val_Loss: 0.6184  BEST VAL Loss: 0.6184  Val_Acc: 66.583

Epoch 11: Validation loss decreased (0.618406 --> 0.614874).  Saving model ...
	 Train_Loss: 0.6287 Train_Acc: 66.115 Val_Loss: 0.6149  BEST VAL Loss: 0.6149  Val_Acc: 67.075

Epoch 12: Validation loss decreased (0.614874 --> 0.611305).  Saving model ...
	 Train_Loss: 0.6255 Train_Acc: 66.532 Val_Loss: 0.6113  BEST VAL Loss: 0.6113  Val_Acc: 67.989

Epoch 13: Validation loss decreased (0.611305 --> 0.608649).  Saving model ...
	 Train_Loss: 0.6225 Train_Acc: 67.128 Val_Loss: 0.6086  BEST VAL Loss: 0.6086  Val_Acc: 66.834

Epoch 14: Validation loss decreased (0.608649 --> 0.605564).  Saving model ...
	 Train_Loss: 0.6197 Train_Acc: 67.322 Val_Loss: 0.6056  BEST VAL Loss: 0.6056  Val_Acc: 68.043

Epoch 15: Validation loss decreased (0.605564 --> 0.602655).  Saving model ...
	 Train_Loss: 0.6171 Train_Acc: 67.546 Val_Loss: 0.6027  BEST VAL Loss: 0.6027  Val_Acc: 68.269

Epoch 16: Validation loss decreased (0.602655 --> 0.600053).  Saving model ...
	 Train_Loss: 0.6146 Train_Acc: 67.697 Val_Loss: 0.6001  BEST VAL Loss: 0.6001  Val_Acc: 68.298

Epoch 17: Validation loss decreased (0.600053 --> 0.597561).  Saving model ...
	 Train_Loss: 0.6123 Train_Acc: 68.011 Val_Loss: 0.5976  BEST VAL Loss: 0.5976  Val_Acc: 68.667

Epoch 18: Validation loss decreased (0.597561 --> 0.595250).  Saving model ...
	 Train_Loss: 0.6101 Train_Acc: 68.203 Val_Loss: 0.5952  BEST VAL Loss: 0.5952  Val_Acc: 68.687

Epoch 19: Validation loss decreased (0.595250 --> 0.593215).  Saving model ...
	 Train_Loss: 0.6080 Train_Acc: 68.430 Val_Loss: 0.5932  BEST VAL Loss: 0.5932  Val_Acc: 68.741

Epoch 20: Validation loss decreased (0.593215 --> 0.591227).  Saving model ...
	 Train_Loss: 0.6061 Train_Acc: 68.363 Val_Loss: 0.5912  BEST VAL Loss: 0.5912  Val_Acc: 68.529

Epoch 21: Validation loss decreased (0.591227 --> 0.589453).  Saving model ...
	 Train_Loss: 0.6042 Train_Acc: 68.677 Val_Loss: 0.5895  BEST VAL Loss: 0.5895  Val_Acc: 68.618

Epoch 22: Validation loss decreased (0.589453 --> 0.587658).  Saving model ...
	 Train_Loss: 0.6025 Train_Acc: 68.702 Val_Loss: 0.5877  BEST VAL Loss: 0.5877  Val_Acc: 69.036

Epoch 23: Validation loss decreased (0.587658 --> 0.585866).  Saving model ...
	 Train_Loss: 0.6008 Train_Acc: 69.028 Val_Loss: 0.5859  BEST VAL Loss: 0.5859  Val_Acc: 69.748

Epoch 24: Validation loss decreased (0.585866 --> 0.584086).  Saving model ...
	 Train_Loss: 0.5991 Train_Acc: 69.101 Val_Loss: 0.5841  BEST VAL Loss: 0.5841  Val_Acc: 69.871

Epoch 25: Validation loss decreased (0.584086 --> 0.582653).  Saving model ...
	 Train_Loss: 0.5975 Train_Acc: 69.251 Val_Loss: 0.5827  BEST VAL Loss: 0.5827  Val_Acc: 69.267

Epoch 26: Validation loss decreased (0.582653 --> 0.581131).  Saving model ...
	 Train_Loss: 0.5961 Train_Acc: 69.227 Val_Loss: 0.5811  BEST VAL Loss: 0.5811  Val_Acc: 69.729

Epoch 27: Validation loss decreased (0.581131 --> 0.579559).  Saving model ...
	 Train_Loss: 0.5946 Train_Acc: 69.453 Val_Loss: 0.5796  BEST VAL Loss: 0.5796  Val_Acc: 70.333

Epoch 28: Validation loss decreased (0.579559 --> 0.578058).  Saving model ...
	 Train_Loss: 0.5932 Train_Acc: 69.440 Val_Loss: 0.5781  BEST VAL Loss: 0.5781  Val_Acc: 70.407

Epoch 29: Validation loss decreased (0.578058 --> 0.576684).  Saving model ...
	 Train_Loss: 0.5919 Train_Acc: 69.555 Val_Loss: 0.5767  BEST VAL Loss: 0.5767  Val_Acc: 70.373

Epoch 30: Validation loss decreased (0.576684 --> 0.575392).  Saving model ...
	 Train_Loss: 0.5906 Train_Acc: 69.570 Val_Loss: 0.5754  BEST VAL Loss: 0.5754  Val_Acc: 69.989

Epoch 31: Validation loss decreased (0.575392 --> 0.574071).  Saving model ...
	 Train_Loss: 0.5894 Train_Acc: 69.613 Val_Loss: 0.5741  BEST VAL Loss: 0.5741  Val_Acc: 70.436

Epoch 32: Validation loss decreased (0.574071 --> 0.572850).  Saving model ...
	 Train_Loss: 0.5882 Train_Acc: 69.737 Val_Loss: 0.5728  BEST VAL Loss: 0.5728  Val_Acc: 70.717

Epoch 33: Validation loss decreased (0.572850 --> 0.571809).  Saving model ...
	 Train_Loss: 0.5871 Train_Acc: 69.715 Val_Loss: 0.5718  BEST VAL Loss: 0.5718  Val_Acc: 69.660

Epoch 34: Validation loss decreased (0.571809 --> 0.570660).  Saving model ...
	 Train_Loss: 0.5860 Train_Acc: 69.807 Val_Loss: 0.5707  BEST VAL Loss: 0.5707  Val_Acc: 70.579

Epoch 35: Validation loss decreased (0.570660 --> 0.569642).  Saving model ...
	 Train_Loss: 0.5849 Train_Acc: 69.842 Val_Loss: 0.5696  BEST VAL Loss: 0.5696  Val_Acc: 69.925

Epoch 36: Validation loss decreased (0.569642 --> 0.568508).  Saving model ...
	 Train_Loss: 0.5839 Train_Acc: 69.989 Val_Loss: 0.5685  BEST VAL Loss: 0.5685  Val_Acc: 71.243

Epoch 37: Validation loss decreased (0.568508 --> 0.567522).  Saving model ...
	 Train_Loss: 0.5828 Train_Acc: 70.011 Val_Loss: 0.5675  BEST VAL Loss: 0.5675  Val_Acc: 70.451

Epoch 38: Validation loss decreased (0.567522 --> 0.566613).  Saving model ...
	 Train_Loss: 0.5819 Train_Acc: 69.953 Val_Loss: 0.5666  BEST VAL Loss: 0.5666  Val_Acc: 70.451

Epoch 39: Validation loss decreased (0.566613 --> 0.565741).  Saving model ...
	 Train_Loss: 0.5809 Train_Acc: 70.030 Val_Loss: 0.5657  BEST VAL Loss: 0.5657  Val_Acc: 70.427

Epoch 40: Validation loss decreased (0.565741 --> 0.564852).  Saving model ...
	 Train_Loss: 0.5800 Train_Acc: 70.011 Val_Loss: 0.5649  BEST VAL Loss: 0.5649  Val_Acc: 71.016

Epoch 41: Validation loss decreased (0.564852 --> 0.564076).  Saving model ...
	 Train_Loss: 0.5792 Train_Acc: 70.015 Val_Loss: 0.5641  BEST VAL Loss: 0.5641  Val_Acc: 70.358

Epoch 42: Validation loss decreased (0.564076 --> 0.563267).  Saving model ...
	 Train_Loss: 0.5783 Train_Acc: 70.143 Val_Loss: 0.5633  BEST VAL Loss: 0.5633  Val_Acc: 70.677

Epoch 43: Validation loss decreased (0.563267 --> 0.562492).  Saving model ...
	 Train_Loss: 0.5775 Train_Acc: 70.304 Val_Loss: 0.5625  BEST VAL Loss: 0.5625  Val_Acc: 70.574

Epoch 44: Validation loss decreased (0.562492 --> 0.561702).  Saving model ...
	 Train_Loss: 0.5766 Train_Acc: 70.130 Val_Loss: 0.5617  BEST VAL Loss: 0.5617  Val_Acc: 70.491

Epoch 45: Validation loss decreased (0.561702 --> 0.560945).  Saving model ...
	 Train_Loss: 0.5759 Train_Acc: 70.167 Val_Loss: 0.5609  BEST VAL Loss: 0.5609  Val_Acc: 70.751

Epoch 46: Validation loss decreased (0.560945 --> 0.560170).  Saving model ...
	 Train_Loss: 0.5751 Train_Acc: 70.268 Val_Loss: 0.5602  BEST VAL Loss: 0.5602  Val_Acc: 71.169

Epoch 47: Validation loss decreased (0.560170 --> 0.559410).  Saving model ...
	 Train_Loss: 0.5743 Train_Acc: 70.261 Val_Loss: 0.5594  BEST VAL Loss: 0.5594  Val_Acc: 71.184

Epoch 48: Validation loss decreased (0.559410 --> 0.558913).  Saving model ...
	 Train_Loss: 0.5736 Train_Acc: 70.404 Val_Loss: 0.5589  BEST VAL Loss: 0.5589  Val_Acc: 70.083

Epoch 49: Validation loss decreased (0.558913 --> 0.558284).  Saving model ...
	 Train_Loss: 0.5729 Train_Acc: 70.324 Val_Loss: 0.5583  BEST VAL Loss: 0.5583  Val_Acc: 70.820

Epoch 50: Validation loss decreased (0.558284 --> 0.557650).  Saving model ...
	 Train_Loss: 0.5722 Train_Acc: 70.293 Val_Loss: 0.5576  BEST VAL Loss: 0.5576  Val_Acc: 70.938

Epoch 51: Validation loss decreased (0.557650 --> 0.556992).  Saving model ...
	 Train_Loss: 0.5715 Train_Acc: 70.513 Val_Loss: 0.5570  BEST VAL Loss: 0.5570  Val_Acc: 71.557

Epoch 52: Validation loss decreased (0.556992 --> 0.556341).  Saving model ...
	 Train_Loss: 0.5709 Train_Acc: 70.419 Val_Loss: 0.5563  BEST VAL Loss: 0.5563  Val_Acc: 71.346

Epoch 53: Validation loss decreased (0.556341 --> 0.555720).  Saving model ...
	 Train_Loss: 0.5703 Train_Acc: 70.391 Val_Loss: 0.5557  BEST VAL Loss: 0.5557  Val_Acc: 71.154

Epoch 54: Validation loss decreased (0.555720 --> 0.555220).  Saving model ...
	 Train_Loss: 0.5696 Train_Acc: 70.409 Val_Loss: 0.5552  BEST VAL Loss: 0.5552  Val_Acc: 70.653

Epoch 55: Validation loss decreased (0.555220 --> 0.554721).  Saving model ...
	 Train_Loss: 0.5690 Train_Acc: 70.525 Val_Loss: 0.5547  BEST VAL Loss: 0.5547  Val_Acc: 70.604

Epoch 56: Validation loss decreased (0.554721 --> 0.554172).  Saving model ...
	 Train_Loss: 0.5684 Train_Acc: 70.721 Val_Loss: 0.5542  BEST VAL Loss: 0.5542  Val_Acc: 71.213

Epoch 57: Validation loss decreased (0.554172 --> 0.553605).  Saving model ...
	 Train_Loss: 0.5678 Train_Acc: 70.669 Val_Loss: 0.5536  BEST VAL Loss: 0.5536  Val_Acc: 71.243

Epoch 58: Validation loss decreased (0.553605 --> 0.553049).  Saving model ...
	 Train_Loss: 0.5672 Train_Acc: 70.578 Val_Loss: 0.5530  BEST VAL Loss: 0.5530  Val_Acc: 71.449

Epoch 59: Validation loss decreased (0.553049 --> 0.552501).  Saving model ...
	 Train_Loss: 0.5667 Train_Acc: 70.748 Val_Loss: 0.5525  BEST VAL Loss: 0.5525  Val_Acc: 71.493

Epoch 60: Validation loss decreased (0.552501 --> 0.551994).  Saving model ...
	 Train_Loss: 0.5661 Train_Acc: 70.600 Val_Loss: 0.5520  BEST VAL Loss: 0.5520  Val_Acc: 71.301

Epoch 61: Validation loss decreased (0.551994 --> 0.551454).  Saving model ...
	 Train_Loss: 0.5656 Train_Acc: 70.689 Val_Loss: 0.5515  BEST VAL Loss: 0.5515  Val_Acc: 71.783

Epoch 62: Validation loss decreased (0.551454 --> 0.550902).  Saving model ...
	 Train_Loss: 0.5650 Train_Acc: 70.680 Val_Loss: 0.5509  BEST VAL Loss: 0.5509  Val_Acc: 71.606

Epoch 63: Validation loss decreased (0.550902 --> 0.550404).  Saving model ...
	 Train_Loss: 0.5645 Train_Acc: 70.798 Val_Loss: 0.5504  BEST VAL Loss: 0.5504  Val_Acc: 71.685

Epoch 64: Validation loss decreased (0.550404 --> 0.549943).  Saving model ...
	 Train_Loss: 0.5640 Train_Acc: 70.899 Val_Loss: 0.5499  BEST VAL Loss: 0.5499  Val_Acc: 71.243

Epoch 65: Validation loss decreased (0.549943 --> 0.549445).  Saving model ...
	 Train_Loss: 0.5635 Train_Acc: 70.873 Val_Loss: 0.5494  BEST VAL Loss: 0.5494  Val_Acc: 71.660

Epoch 66: Validation loss decreased (0.549445 --> 0.549045).  Saving model ...
	 Train_Loss: 0.5630 Train_Acc: 70.704 Val_Loss: 0.5490  BEST VAL Loss: 0.5490  Val_Acc: 70.894

Epoch 67: Validation loss decreased (0.549045 --> 0.548605).  Saving model ...
	 Train_Loss: 0.5625 Train_Acc: 70.841 Val_Loss: 0.5486  BEST VAL Loss: 0.5486  Val_Acc: 71.739

Epoch 68: Validation loss decreased (0.548605 --> 0.548175).  Saving model ...
	 Train_Loss: 0.5621 Train_Acc: 70.789 Val_Loss: 0.5482  BEST VAL Loss: 0.5482  Val_Acc: 71.395

Epoch 69: Validation loss decreased (0.548175 --> 0.547730).  Saving model ...
	 Train_Loss: 0.5616 Train_Acc: 70.852 Val_Loss: 0.5477  BEST VAL Loss: 0.5477  Val_Acc: 71.768

Epoch 70: Validation loss decreased (0.547730 --> 0.547281).  Saving model ...
	 Train_Loss: 0.5611 Train_Acc: 70.849 Val_Loss: 0.5473  BEST VAL Loss: 0.5473  Val_Acc: 71.754

Epoch 71: Validation loss decreased (0.547281 --> 0.546877).  Saving model ...
	 Train_Loss: 0.5607 Train_Acc: 70.920 Val_Loss: 0.5469  BEST VAL Loss: 0.5469  Val_Acc: 71.395

Epoch 72: Validation loss decreased (0.546877 --> 0.546457).  Saving model ...
	 Train_Loss: 0.5603 Train_Acc: 70.963 Val_Loss: 0.5465  BEST VAL Loss: 0.5465  Val_Acc: 71.881

Epoch 73: Validation loss decreased (0.546457 --> 0.546054).  Saving model ...
	 Train_Loss: 0.5598 Train_Acc: 71.005 Val_Loss: 0.5461  BEST VAL Loss: 0.5461  Val_Acc: 71.714

Epoch 74: Validation loss decreased (0.546054 --> 0.545700).  Saving model ...
	 Train_Loss: 0.5594 Train_Acc: 70.935 Val_Loss: 0.5457  BEST VAL Loss: 0.5457  Val_Acc: 71.272

Epoch 75: Validation loss decreased (0.545700 --> 0.545319).  Saving model ...
	 Train_Loss: 0.5590 Train_Acc: 70.952 Val_Loss: 0.5453  BEST VAL Loss: 0.5453  Val_Acc: 71.945

Epoch 76: Validation loss decreased (0.545319 --> 0.544933).  Saving model ...
	 Train_Loss: 0.5586 Train_Acc: 70.968 Val_Loss: 0.5449  BEST VAL Loss: 0.5449  Val_Acc: 71.886

Epoch 77: Validation loss decreased (0.544933 --> 0.544554).  Saving model ...
	 Train_Loss: 0.5582 Train_Acc: 71.091 Val_Loss: 0.5446  BEST VAL Loss: 0.5446  Val_Acc: 71.665

Epoch 78: Validation loss decreased (0.544554 --> 0.544281).  Saving model ...
	 Train_Loss: 0.5578 Train_Acc: 71.048 Val_Loss: 0.5443  BEST VAL Loss: 0.5443  Val_Acc: 71.036

Epoch 79: Validation loss decreased (0.544281 --> 0.543947).  Saving model ...
	 Train_Loss: 0.5574 Train_Acc: 71.094 Val_Loss: 0.5439  BEST VAL Loss: 0.5439  Val_Acc: 71.970

Epoch 80: Validation loss decreased (0.543947 --> 0.543617).  Saving model ...
	 Train_Loss: 0.5570 Train_Acc: 71.146 Val_Loss: 0.5436  BEST VAL Loss: 0.5436  Val_Acc: 71.670

Epoch 81: Validation loss decreased (0.543617 --> 0.543299).  Saving model ...
	 Train_Loss: 0.5566 Train_Acc: 71.092 Val_Loss: 0.5433  BEST VAL Loss: 0.5433  Val_Acc: 71.709

Epoch 82: Validation loss decreased (0.543299 --> 0.542972).  Saving model ...
	 Train_Loss: 0.5563 Train_Acc: 70.944 Val_Loss: 0.5430  BEST VAL Loss: 0.5430  Val_Acc: 71.665

Epoch 83: Validation loss decreased (0.542972 --> 0.542670).  Saving model ...
	 Train_Loss: 0.5559 Train_Acc: 71.170 Val_Loss: 0.5427  BEST VAL Loss: 0.5427  Val_Acc: 71.665

Epoch 84: Validation loss decreased (0.542670 --> 0.542365).  Saving model ...
	 Train_Loss: 0.5556 Train_Acc: 71.027 Val_Loss: 0.5424  BEST VAL Loss: 0.5424  Val_Acc: 71.587

Epoch 85: Validation loss decreased (0.542365 --> 0.542050).  Saving model ...
	 Train_Loss: 0.5552 Train_Acc: 71.179 Val_Loss: 0.5420  BEST VAL Loss: 0.5420  Val_Acc: 71.827

Epoch 86: Validation loss decreased (0.542050 --> 0.541714).  Saving model ...
	 Train_Loss: 0.5548 Train_Acc: 71.211 Val_Loss: 0.5417  BEST VAL Loss: 0.5417  Val_Acc: 72.250

Epoch 87: Validation loss decreased (0.541714 --> 0.541418).  Saving model ...
	 Train_Loss: 0.5545 Train_Acc: 71.145 Val_Loss: 0.5414  BEST VAL Loss: 0.5414  Val_Acc: 71.994

Epoch 88: Validation loss decreased (0.541418 --> 0.541147).  Saving model ...
	 Train_Loss: 0.5542 Train_Acc: 71.151 Val_Loss: 0.5411  BEST VAL Loss: 0.5411  Val_Acc: 71.724

Epoch 89: Validation loss decreased (0.541147 --> 0.540849).  Saving model ...
	 Train_Loss: 0.5538 Train_Acc: 71.270 Val_Loss: 0.5408  BEST VAL Loss: 0.5408  Val_Acc: 71.980

Epoch 90: Validation loss decreased (0.540849 --> 0.540559).  Saving model ...
	 Train_Loss: 0.5535 Train_Acc: 71.117 Val_Loss: 0.5406  BEST VAL Loss: 0.5406  Val_Acc: 71.886

Epoch 91: Validation loss decreased (0.540559 --> 0.540277).  Saving model ...
	 Train_Loss: 0.5532 Train_Acc: 71.204 Val_Loss: 0.5403  BEST VAL Loss: 0.5403  Val_Acc: 71.940

Epoch 92: Validation loss decreased (0.540277 --> 0.540016).  Saving model ...
	 Train_Loss: 0.5529 Train_Acc: 71.180 Val_Loss: 0.5400  BEST VAL Loss: 0.5400  Val_Acc: 71.783

Epoch 93: Validation loss decreased (0.540016 --> 0.539755).  Saving model ...
	 Train_Loss: 0.5526 Train_Acc: 71.282 Val_Loss: 0.5398  BEST VAL Loss: 0.5398  Val_Acc: 72.073

Epoch 94: Validation loss decreased (0.539755 --> 0.539483).  Saving model ...
	 Train_Loss: 0.5523 Train_Acc: 71.139 Val_Loss: 0.5395  BEST VAL Loss: 0.5395  Val_Acc: 71.739

Epoch 95: Validation loss decreased (0.539483 --> 0.539181).  Saving model ...
	 Train_Loss: 0.5520 Train_Acc: 71.265 Val_Loss: 0.5392  BEST VAL Loss: 0.5392  Val_Acc: 72.574

Epoch 96: Validation loss decreased (0.539181 --> 0.538914).  Saving model ...
	 Train_Loss: 0.5517 Train_Acc: 71.324 Val_Loss: 0.5389  BEST VAL Loss: 0.5389  Val_Acc: 71.950

Epoch 97: Validation loss decreased (0.538914 --> 0.538635).  Saving model ...
	 Train_Loss: 0.5514 Train_Acc: 71.269 Val_Loss: 0.5386  BEST VAL Loss: 0.5386  Val_Acc: 72.270

Epoch 98: Validation loss decreased (0.538635 --> 0.538379).  Saving model ...
	 Train_Loss: 0.5511 Train_Acc: 71.221 Val_Loss: 0.5384  BEST VAL Loss: 0.5384  Val_Acc: 71.724

Epoch 99: Validation loss decreased (0.538379 --> 0.538104).  Saving model ...
	 Train_Loss: 0.5508 Train_Acc: 71.312 Val_Loss: 0.5381  BEST VAL Loss: 0.5381  Val_Acc: 72.162

LPS_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.78      0.72      0.75     82968
           1       0.73      0.79      0.76     79796

    accuracy                           0.75    162764
   macro avg       0.76      0.76      0.75    162764
weighted avg       0.76      0.75      0.75    162764

LPS_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.74      0.69      0.72     10371
           1       0.70      0.75      0.73      9975

    accuracy                           0.72     20346
   macro avg       0.72      0.72      0.72     20346
weighted avg       0.72      0.72      0.72     20346

LPS_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.75      0.69      0.72     10371
           1       0.70      0.76      0.73      9975

    accuracy                           0.73     20346
   macro avg       0.73      0.73      0.73     20346
weighted avg       0.73      0.73      0.73     20346

              precision    recall  f1-score   support

           0       0.75      0.69      0.72     10371
           1       0.70      0.76      0.73      9975

    accuracy                           0.73     20346
   macro avg       0.73      0.73      0.73     20346
weighted avg       0.73      0.73      0.73     20346

LPS_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.43      0.73      0.54     34887
           1       0.39      0.15      0.22     39687

    accuracy                           0.42     74574
   macro avg       0.41      0.44      0.38     74574
weighted avg       0.41      0.42      0.37     74574

              precision    recall  f1-score   support

           0       0.43      0.73      0.54     34887
           1       0.39      0.15      0.22     39687

    accuracy                           0.42     74574
   macro avg       0.41      0.44      0.38     74574
weighted avg       0.41      0.42      0.37     74574

completed
