[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'dff7afd6'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '8d6b9d56'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ef1873cb'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '471848ea'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_Nigericin_1.000_1.0_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (340274, 1270)
Number of total missing values across all columns: 0
Data Subset Is Off
Wells held out for testing: ['K08' 'L09']
Wells to use for training, validation, and testing ['K02' 'K03' 'K09' 'L02' 'L03' 'L08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.648170).  Saving model ...
	 Train_Loss: 0.6774 Train_Acc: 55.627 Val_Loss: 0.6482  BEST VAL Loss: 0.6482  Val_Acc: 64.191

Epoch 1: Validation loss decreased (0.648170 --> 0.629911).  Saving model ...
	 Train_Loss: 0.6616 Train_Acc: 60.499 Val_Loss: 0.6299  BEST VAL Loss: 0.6299  Val_Acc: 68.512

Epoch 2: Validation loss decreased (0.629911 --> 0.616001).  Saving model ...
	 Train_Loss: 0.6481 Train_Acc: 64.493 Val_Loss: 0.6160  BEST VAL Loss: 0.6160  Val_Acc: 70.332

Epoch 3: Validation loss decreased (0.616001 --> 0.605721).  Saving model ...
	 Train_Loss: 0.6377 Train_Acc: 65.881 Val_Loss: 0.6057  BEST VAL Loss: 0.6057  Val_Acc: 71.126

Epoch 4: Validation loss decreased (0.605721 --> 0.596804).  Saving model ...
	 Train_Loss: 0.6294 Train_Acc: 67.613 Val_Loss: 0.5968  BEST VAL Loss: 0.5968  Val_Acc: 71.699

Epoch 5: Validation loss decreased (0.596804 --> 0.590355).  Saving model ...
	 Train_Loss: 0.6225 Train_Acc: 68.590 Val_Loss: 0.5904  BEST VAL Loss: 0.5904  Val_Acc: 72.379

Epoch 6: Validation loss decreased (0.590355 --> 0.585535).  Saving model ...
	 Train_Loss: 0.6169 Train_Acc: 69.105 Val_Loss: 0.5855  BEST VAL Loss: 0.5855  Val_Acc: 72.340

Epoch 7: Validation loss decreased (0.585535 --> 0.581039).  Saving model ...
	 Train_Loss: 0.6120 Train_Acc: 69.454 Val_Loss: 0.5810  BEST VAL Loss: 0.5810  Val_Acc: 72.714

Epoch 8: Validation loss decreased (0.581039 --> 0.577697).  Saving model ...
	 Train_Loss: 0.6079 Train_Acc: 69.607 Val_Loss: 0.5777  BEST VAL Loss: 0.5777  Val_Acc: 72.978

Epoch 9: Validation loss decreased (0.577697 --> 0.574089).  Saving model ...
	 Train_Loss: 0.6043 Train_Acc: 69.855 Val_Loss: 0.5741  BEST VAL Loss: 0.5741  Val_Acc: 73.111

Epoch 10: Validation loss decreased (0.574089 --> 0.570923).  Saving model ...
	 Train_Loss: 0.6010 Train_Acc: 70.174 Val_Loss: 0.5709  BEST VAL Loss: 0.5709  Val_Acc: 73.188

Epoch 11: Validation loss decreased (0.570923 --> 0.567568).  Saving model ...
	 Train_Loss: 0.5980 Train_Acc: 70.317 Val_Loss: 0.5676  BEST VAL Loss: 0.5676  Val_Acc: 73.558

Epoch 12: Validation loss decreased (0.567568 --> 0.564692).  Saving model ...
	 Train_Loss: 0.5953 Train_Acc: 70.474 Val_Loss: 0.5647  BEST VAL Loss: 0.5647  Val_Acc: 73.741

Epoch 13: Validation loss decreased (0.564692 --> 0.562706).  Saving model ...
	 Train_Loss: 0.5930 Train_Acc: 70.491 Val_Loss: 0.5627  BEST VAL Loss: 0.5627  Val_Acc: 73.600

Epoch 14: Validation loss decreased (0.562706 --> 0.560228).  Saving model ...
	 Train_Loss: 0.5907 Train_Acc: 70.738 Val_Loss: 0.5602  BEST VAL Loss: 0.5602  Val_Acc: 73.909

Epoch 15: Validation loss decreased (0.560228 --> 0.558100).  Saving model ...
	 Train_Loss: 0.5887 Train_Acc: 70.968 Val_Loss: 0.5581  BEST VAL Loss: 0.5581  Val_Acc: 74.008

Epoch 16: Validation loss decreased (0.558100 --> 0.556169).  Saving model ...
	 Train_Loss: 0.5869 Train_Acc: 71.272 Val_Loss: 0.5562  BEST VAL Loss: 0.5562  Val_Acc: 74.020

Epoch 17: Validation loss decreased (0.556169 --> 0.554305).  Saving model ...
	 Train_Loss: 0.5851 Train_Acc: 71.555 Val_Loss: 0.5543  BEST VAL Loss: 0.5543  Val_Acc: 74.146

Epoch 18: Validation loss decreased (0.554305 --> 0.552495).  Saving model ...
	 Train_Loss: 0.5835 Train_Acc: 71.623 Val_Loss: 0.5525  BEST VAL Loss: 0.5525  Val_Acc: 74.070

Epoch 19: Validation loss decreased (0.552495 --> 0.550860).  Saving model ...
	 Train_Loss: 0.5819 Train_Acc: 71.723 Val_Loss: 0.5509  BEST VAL Loss: 0.5509  Val_Acc: 73.947

Epoch 20: Validation loss decreased (0.550860 --> 0.549940).  Saving model ...
	 Train_Loss: 0.5805 Train_Acc: 71.897 Val_Loss: 0.5499  BEST VAL Loss: 0.5499  Val_Acc: 74.058

Epoch 21: Validation loss decreased (0.549940 --> 0.548639).  Saving model ...
	 Train_Loss: 0.5792 Train_Acc: 71.987 Val_Loss: 0.5486  BEST VAL Loss: 0.5486  Val_Acc: 74.085

Epoch 22: Validation loss decreased (0.548639 --> 0.547508).  Saving model ...
	 Train_Loss: 0.5779 Train_Acc: 72.084 Val_Loss: 0.5475  BEST VAL Loss: 0.5475  Val_Acc: 74.493

Epoch 23: Validation loss decreased (0.547508 --> 0.546151).  Saving model ...
	 Train_Loss: 0.5767 Train_Acc: 72.168 Val_Loss: 0.5462  BEST VAL Loss: 0.5462  Val_Acc: 74.852

Epoch 24: Validation loss decreased (0.546151 --> 0.545290).  Saving model ...
	 Train_Loss: 0.5756 Train_Acc: 72.221 Val_Loss: 0.5453  BEST VAL Loss: 0.5453  Val_Acc: 74.531

Epoch 25: Validation loss decreased (0.545290 --> 0.544177).  Saving model ...
	 Train_Loss: 0.5746 Train_Acc: 72.295 Val_Loss: 0.5442  BEST VAL Loss: 0.5442  Val_Acc: 74.921

Epoch 26: Validation loss decreased (0.544177 --> 0.543241).  Saving model ...
	 Train_Loss: 0.5735 Train_Acc: 72.469 Val_Loss: 0.5432  BEST VAL Loss: 0.5432  Val_Acc: 74.772

Epoch 27: Validation loss decreased (0.543241 --> 0.542180).  Saving model ...
	 Train_Loss: 0.5725 Train_Acc: 72.462 Val_Loss: 0.5422  BEST VAL Loss: 0.5422  Val_Acc: 75.299

Epoch 28: Validation loss decreased (0.542180 --> 0.541192).  Saving model ...
	 Train_Loss: 0.5715 Train_Acc: 72.539 Val_Loss: 0.5412  BEST VAL Loss: 0.5412  Val_Acc: 74.463

Epoch 29: Validation loss decreased (0.541192 --> 0.540495).  Saving model ...
	 Train_Loss: 0.5706 Train_Acc: 72.675 Val_Loss: 0.5405  BEST VAL Loss: 0.5405  Val_Acc: 74.802

Epoch 30: Validation loss decreased (0.540495 --> 0.539521).  Saving model ...
	 Train_Loss: 0.5697 Train_Acc: 72.630 Val_Loss: 0.5395  BEST VAL Loss: 0.5395  Val_Acc: 74.680

Epoch 31: Validation loss decreased (0.539521 --> 0.538588).  Saving model ...
	 Train_Loss: 0.5689 Train_Acc: 72.670 Val_Loss: 0.5386  BEST VAL Loss: 0.5386  Val_Acc: 75.123

Epoch 32: Validation loss decreased (0.538588 --> 0.537797).  Saving model ...
	 Train_Loss: 0.5681 Train_Acc: 72.678 Val_Loss: 0.5378  BEST VAL Loss: 0.5378  Val_Acc: 75.253

Epoch 33: Validation loss decreased (0.537797 --> 0.536947).  Saving model ...
	 Train_Loss: 0.5673 Train_Acc: 72.810 Val_Loss: 0.5369  BEST VAL Loss: 0.5369  Val_Acc: 75.184

Epoch 34: Validation loss decreased (0.536947 --> 0.536128).  Saving model ...
	 Train_Loss: 0.5666 Train_Acc: 72.774 Val_Loss: 0.5361  BEST VAL Loss: 0.5361  Val_Acc: 75.245

Epoch 35: Validation loss decreased (0.536128 --> 0.535313).  Saving model ...
	 Train_Loss: 0.5659 Train_Acc: 72.773 Val_Loss: 0.5353  BEST VAL Loss: 0.5353  Val_Acc: 75.390

Epoch 36: Validation loss decreased (0.535313 --> 0.534674).  Saving model ...
	 Train_Loss: 0.5652 Train_Acc: 72.921 Val_Loss: 0.5347  BEST VAL Loss: 0.5347  Val_Acc: 74.886

Epoch 37: Validation loss decreased (0.534674 --> 0.533953).  Saving model ...
	 Train_Loss: 0.5645 Train_Acc: 72.816 Val_Loss: 0.5340  BEST VAL Loss: 0.5340  Val_Acc: 75.257

Epoch 38: Validation loss decreased (0.533953 --> 0.533241).  Saving model ...
	 Train_Loss: 0.5639 Train_Acc: 72.842 Val_Loss: 0.5332  BEST VAL Loss: 0.5332  Val_Acc: 74.944

Epoch 39: Validation loss decreased (0.533241 --> 0.532662).  Saving model ...
	 Train_Loss: 0.5633 Train_Acc: 72.951 Val_Loss: 0.5327  BEST VAL Loss: 0.5327  Val_Acc: 75.482

Epoch 40: Validation loss decreased (0.532662 --> 0.531945).  Saving model ...
	 Train_Loss: 0.5627 Train_Acc: 72.968 Val_Loss: 0.5319  BEST VAL Loss: 0.5319  Val_Acc: 75.612

Epoch 41: Validation loss decreased (0.531945 --> 0.531295).  Saving model ...
	 Train_Loss: 0.5621 Train_Acc: 72.948 Val_Loss: 0.5313  BEST VAL Loss: 0.5313  Val_Acc: 75.318

Epoch 42: Validation loss decreased (0.531295 --> 0.530773).  Saving model ...
	 Train_Loss: 0.5616 Train_Acc: 72.965 Val_Loss: 0.5308  BEST VAL Loss: 0.5308  Val_Acc: 75.474

Epoch 43: Validation loss decreased (0.530773 --> 0.530152).  Saving model ...
	 Train_Loss: 0.5610 Train_Acc: 73.045 Val_Loss: 0.5302  BEST VAL Loss: 0.5302  Val_Acc: 75.383

Epoch 44: Validation loss decreased (0.530152 --> 0.529602).  Saving model ...
	 Train_Loss: 0.5605 Train_Acc: 73.009 Val_Loss: 0.5296  BEST VAL Loss: 0.5296  Val_Acc: 75.371

Epoch 45: Validation loss decreased (0.529602 --> 0.529061).  Saving model ...
	 Train_Loss: 0.5600 Train_Acc: 73.119 Val_Loss: 0.5291  BEST VAL Loss: 0.5291  Val_Acc: 75.303

Epoch 46: Validation loss decreased (0.529061 --> 0.528505).  Saving model ...
	 Train_Loss: 0.5595 Train_Acc: 73.088 Val_Loss: 0.5285  BEST VAL Loss: 0.5285  Val_Acc: 75.753

Epoch 47: Validation loss decreased (0.528505 --> 0.528018).  Saving model ...
	 Train_Loss: 0.5591 Train_Acc: 73.144 Val_Loss: 0.5280  BEST VAL Loss: 0.5280  Val_Acc: 75.306

Epoch 48: Validation loss decreased (0.528018 --> 0.527492).  Saving model ...
	 Train_Loss: 0.5586 Train_Acc: 73.131 Val_Loss: 0.5275  BEST VAL Loss: 0.5275  Val_Acc: 75.463

Epoch 49: Validation loss decreased (0.527492 --> 0.527040).  Saving model ...
	 Train_Loss: 0.5581 Train_Acc: 73.165 Val_Loss: 0.5270  BEST VAL Loss: 0.5270  Val_Acc: 75.009

Epoch 50: Validation loss decreased (0.527040 --> 0.526688).  Saving model ...
	 Train_Loss: 0.5577 Train_Acc: 73.161 Val_Loss: 0.5267  BEST VAL Loss: 0.5267  Val_Acc: 75.616

Epoch 51: Validation loss decreased (0.526688 --> 0.526272).  Saving model ...
	 Train_Loss: 0.5573 Train_Acc: 73.239 Val_Loss: 0.5263  BEST VAL Loss: 0.5263  Val_Acc: 75.230

Epoch 52: Validation loss decreased (0.526272 --> 0.525811).  Saving model ...
	 Train_Loss: 0.5569 Train_Acc: 73.148 Val_Loss: 0.5258  BEST VAL Loss: 0.5258  Val_Acc: 75.776

Epoch 53: Validation loss decreased (0.525811 --> 0.525367).  Saving model ...
	 Train_Loss: 0.5565 Train_Acc: 73.294 Val_Loss: 0.5254  BEST VAL Loss: 0.5254  Val_Acc: 75.772

Epoch 54: Validation loss decreased (0.525367 --> 0.524900).  Saving model ...
	 Train_Loss: 0.5561 Train_Acc: 73.223 Val_Loss: 0.5249  BEST VAL Loss: 0.5249  Val_Acc: 75.654

Epoch 55: Validation loss decreased (0.524900 --> 0.524530).  Saving model ...
	 Train_Loss: 0.5557 Train_Acc: 73.254 Val_Loss: 0.5245  BEST VAL Loss: 0.5245  Val_Acc: 75.543

Epoch 56: Validation loss decreased (0.524530 --> 0.524111).  Saving model ...
	 Train_Loss: 0.5554 Train_Acc: 73.240 Val_Loss: 0.5241  BEST VAL Loss: 0.5241  Val_Acc: 75.589

Epoch 57: Validation loss decreased (0.524111 --> 0.523798).  Saving model ...
	 Train_Loss: 0.5550 Train_Acc: 73.288 Val_Loss: 0.5238  BEST VAL Loss: 0.5238  Val_Acc: 76.009

Epoch 58: Validation loss decreased (0.523798 --> 0.523419).  Saving model ...
	 Train_Loss: 0.5546 Train_Acc: 73.345 Val_Loss: 0.5234  BEST VAL Loss: 0.5234  Val_Acc: 75.978

Epoch 59: Validation loss decreased (0.523419 --> 0.523133).  Saving model ...
	 Train_Loss: 0.5543 Train_Acc: 73.302 Val_Loss: 0.5231  BEST VAL Loss: 0.5231  Val_Acc: 75.837

Epoch 60: Validation loss decreased (0.523133 --> 0.522761).  Saving model ...
	 Train_Loss: 0.5539 Train_Acc: 73.324 Val_Loss: 0.5228  BEST VAL Loss: 0.5228  Val_Acc: 75.528

Epoch 61: Validation loss decreased (0.522761 --> 0.522362).  Saving model ...
	 Train_Loss: 0.5536 Train_Acc: 73.373 Val_Loss: 0.5224  BEST VAL Loss: 0.5224  Val_Acc: 75.909

Epoch 62: Validation loss decreased (0.522362 --> 0.522085).  Saving model ...
	 Train_Loss: 0.5533 Train_Acc: 73.370 Val_Loss: 0.5221  BEST VAL Loss: 0.5221  Val_Acc: 75.364

Epoch 63: Validation loss decreased (0.522085 --> 0.521708).  Saving model ...
	 Train_Loss: 0.5530 Train_Acc: 73.383 Val_Loss: 0.5217  BEST VAL Loss: 0.5217  Val_Acc: 75.864

Epoch 64: Validation loss decreased (0.521708 --> 0.521438).  Saving model ...
	 Train_Loss: 0.5527 Train_Acc: 73.328 Val_Loss: 0.5214  BEST VAL Loss: 0.5214  Val_Acc: 75.875

Epoch 65: Validation loss decreased (0.521438 --> 0.521121).  Saving model ...
	 Train_Loss: 0.5524 Train_Acc: 73.307 Val_Loss: 0.5211  BEST VAL Loss: 0.5211  Val_Acc: 75.791

Epoch 66: Validation loss decreased (0.521121 --> 0.520755).  Saving model ...
	 Train_Loss: 0.5521 Train_Acc: 73.387 Val_Loss: 0.5208  BEST VAL Loss: 0.5208  Val_Acc: 76.222

Epoch 67: Validation loss decreased (0.520755 --> 0.520511).  Saving model ...
	 Train_Loss: 0.5518 Train_Acc: 73.426 Val_Loss: 0.5205  BEST VAL Loss: 0.5205  Val_Acc: 75.757

Epoch 68: Validation loss decreased (0.520511 --> 0.520227).  Saving model ...
	 Train_Loss: 0.5515 Train_Acc: 73.534 Val_Loss: 0.5202  BEST VAL Loss: 0.5202  Val_Acc: 75.856

Epoch 69: Validation loss decreased (0.520227 --> 0.519932).  Saving model ...
	 Train_Loss: 0.5513 Train_Acc: 73.469 Val_Loss: 0.5199  BEST VAL Loss: 0.5199  Val_Acc: 75.902

Epoch 70: Validation loss decreased (0.519932 --> 0.519678).  Saving model ...
	 Train_Loss: 0.5510 Train_Acc: 73.453 Val_Loss: 0.5197  BEST VAL Loss: 0.5197  Val_Acc: 75.845

Epoch 71: Validation loss decreased (0.519678 --> 0.519385).  Saving model ...
	 Train_Loss: 0.5507 Train_Acc: 73.443 Val_Loss: 0.5194  BEST VAL Loss: 0.5194  Val_Acc: 75.661

Epoch 72: Validation loss decreased (0.519385 --> 0.519073).  Saving model ...
	 Train_Loss: 0.5505 Train_Acc: 73.357 Val_Loss: 0.5191  BEST VAL Loss: 0.5191  Val_Acc: 75.925

Epoch 73: Validation loss decreased (0.519073 --> 0.518737).  Saving model ...
	 Train_Loss: 0.5502 Train_Acc: 73.505 Val_Loss: 0.5187  BEST VAL Loss: 0.5187  Val_Acc: 76.032

Epoch 74: Validation loss decreased (0.518737 --> 0.518471).  Saving model ...
	 Train_Loss: 0.5500 Train_Acc: 73.565 Val_Loss: 0.5185  BEST VAL Loss: 0.5185  Val_Acc: 75.600

Epoch 75: Validation loss decreased (0.518471 --> 0.518240).  Saving model ...
	 Train_Loss: 0.5498 Train_Acc: 73.505 Val_Loss: 0.5182  BEST VAL Loss: 0.5182  Val_Acc: 75.825

Epoch 76: Validation loss decreased (0.518240 --> 0.518067).  Saving model ...
	 Train_Loss: 0.5495 Train_Acc: 73.650 Val_Loss: 0.5181  BEST VAL Loss: 0.5181  Val_Acc: 75.436

Epoch 77: Validation loss decreased (0.518067 --> 0.517801).  Saving model ...
	 Train_Loss: 0.5493 Train_Acc: 73.485 Val_Loss: 0.5178  BEST VAL Loss: 0.5178  Val_Acc: 75.871

Epoch 78: Validation loss decreased (0.517801 --> 0.517523).  Saving model ...
	 Train_Loss: 0.5491 Train_Acc: 73.521 Val_Loss: 0.5175  BEST VAL Loss: 0.5175  Val_Acc: 75.898

Epoch 79: Validation loss decreased (0.517523 --> 0.517266).  Saving model ...
	 Train_Loss: 0.5488 Train_Acc: 73.566 Val_Loss: 0.5173  BEST VAL Loss: 0.5173  Val_Acc: 75.986

Epoch 80: Validation loss decreased (0.517266 --> 0.517016).  Saving model ...
	 Train_Loss: 0.5486 Train_Acc: 73.556 Val_Loss: 0.5170  BEST VAL Loss: 0.5170  Val_Acc: 75.997

Epoch 81: Validation loss decreased (0.517016 --> 0.516789).  Saving model ...
	 Train_Loss: 0.5484 Train_Acc: 73.403 Val_Loss: 0.5168  BEST VAL Loss: 0.5168  Val_Acc: 75.971

Epoch 82: Validation loss decreased (0.516789 --> 0.516551).  Saving model ...
	 Train_Loss: 0.5482 Train_Acc: 73.521 Val_Loss: 0.5166  BEST VAL Loss: 0.5166  Val_Acc: 75.951

Epoch 83: Validation loss decreased (0.516551 --> 0.516286).  Saving model ...
	 Train_Loss: 0.5480 Train_Acc: 73.614 Val_Loss: 0.5163  BEST VAL Loss: 0.5163  Val_Acc: 76.028

Epoch 84: Validation loss decreased (0.516286 --> 0.516121).  Saving model ...
	 Train_Loss: 0.5478 Train_Acc: 73.592 Val_Loss: 0.5161  BEST VAL Loss: 0.5161  Val_Acc: 75.703

Epoch 85: Validation loss decreased (0.516121 --> 0.515929).  Saving model ...
	 Train_Loss: 0.5476 Train_Acc: 73.523 Val_Loss: 0.5159  BEST VAL Loss: 0.5159  Val_Acc: 75.490

Epoch 86: Validation loss decreased (0.515929 --> 0.515721).  Saving model ...
	 Train_Loss: 0.5474 Train_Acc: 73.604 Val_Loss: 0.5157  BEST VAL Loss: 0.5157  Val_Acc: 75.574

Epoch 87: Validation loss decreased (0.515721 --> 0.515507).  Saving model ...
	 Train_Loss: 0.5472 Train_Acc: 73.650 Val_Loss: 0.5155  BEST VAL Loss: 0.5155  Val_Acc: 75.990

Epoch 88: Validation loss decreased (0.515507 --> 0.515287).  Saving model ...
	 Train_Loss: 0.5470 Train_Acc: 73.590 Val_Loss: 0.5153  BEST VAL Loss: 0.5153  Val_Acc: 75.986

Epoch 89: Validation loss decreased (0.515287 --> 0.515019).  Saving model ...
	 Train_Loss: 0.5468 Train_Acc: 73.579 Val_Loss: 0.5150  BEST VAL Loss: 0.5150  Val_Acc: 75.959

Epoch 90: Validation loss decreased (0.515019 --> 0.514830).  Saving model ...
	 Train_Loss: 0.5466 Train_Acc: 73.649 Val_Loss: 0.5148  BEST VAL Loss: 0.5148  Val_Acc: 75.974

Epoch 91: Validation loss decreased (0.514830 --> 0.514590).  Saving model ...
	 Train_Loss: 0.5464 Train_Acc: 73.755 Val_Loss: 0.5146  BEST VAL Loss: 0.5146  Val_Acc: 75.833

Epoch 92: Validation loss decreased (0.514590 --> 0.514460).  Saving model ...
	 Train_Loss: 0.5462 Train_Acc: 73.723 Val_Loss: 0.5145  BEST VAL Loss: 0.5145  Val_Acc: 76.043

Epoch 93: Validation loss decreased (0.514460 --> 0.514255).  Saving model ...
	 Train_Loss: 0.5461 Train_Acc: 73.669 Val_Loss: 0.5143  BEST VAL Loss: 0.5143  Val_Acc: 76.131

Epoch 94: Validation loss decreased (0.514255 --> 0.514138).  Saving model ...
	 Train_Loss: 0.5459 Train_Acc: 73.592 Val_Loss: 0.5141  BEST VAL Loss: 0.5141  Val_Acc: 75.650

Epoch 95: Validation loss decreased (0.514138 --> 0.513944).  Saving model ...
	 Train_Loss: 0.5457 Train_Acc: 73.754 Val_Loss: 0.5139  BEST VAL Loss: 0.5139  Val_Acc: 75.955

Epoch 96: Validation loss decreased (0.513944 --> 0.513757).  Saving model ...
	 Train_Loss: 0.5455 Train_Acc: 73.627 Val_Loss: 0.5138  BEST VAL Loss: 0.5138  Val_Acc: 75.932

Epoch 97: Validation loss decreased (0.513757 --> 0.513585).  Saving model ...
	 Train_Loss: 0.5454 Train_Acc: 73.752 Val_Loss: 0.5136  BEST VAL Loss: 0.5136  Val_Acc: 75.909

Epoch 98: Validation loss decreased (0.513585 --> 0.513399).  Saving model ...
	 Train_Loss: 0.5452 Train_Acc: 73.613 Val_Loss: 0.5134  BEST VAL Loss: 0.5134  Val_Acc: 76.089

Epoch 99: Validation loss decreased (0.513399 --> 0.513213).  Saving model ...
	 Train_Loss: 0.5450 Train_Acc: 73.680 Val_Loss: 0.5132  BEST VAL Loss: 0.5132  Val_Acc: 76.253

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.77      0.73      0.75    100340
           1       0.77      0.80      0.78    109228

    accuracy                           0.77    209568
   macro avg       0.77      0.77      0.77    209568
weighted avg       0.77      0.77      0.77    209568

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.77      0.72      0.74     12543
           1       0.76      0.80      0.78     13654

    accuracy                           0.76     26197
   macro avg       0.76      0.76      0.76     26197
weighted avg       0.76      0.76      0.76     26197

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.76      0.72      0.74     12542
           1       0.76      0.79      0.77     13654

    accuracy                           0.76     26196
   macro avg       0.76      0.76      0.76     26196
weighted avg       0.76      0.76      0.76     26196

              precision    recall  f1-score   support

           0       0.76      0.72      0.74     12542
           1       0.76      0.79      0.77     13654

    accuracy                           0.76     26196
   macro avg       0.76      0.76      0.76     26196
weighted avg       0.76      0.76      0.76     26196

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.71      0.50      0.58     40588
           1       0.59      0.78      0.67     37725

    accuracy                           0.63     78313
   macro avg       0.65      0.64      0.63     78313
weighted avg       0.65      0.63      0.63     78313

              precision    recall  f1-score   support

           0       0.71      0.50      0.58     40588
           1       0.59      0.78      0.67     37725

    accuracy                           0.63     78313
   macro avg       0.65      0.64      0.63     78313
weighted avg       0.65      0.63      0.63     78313

completed
