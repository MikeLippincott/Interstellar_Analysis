[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '96183d3b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '86a2e082'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '2e5c2ed3'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '075fe35b'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_1.000_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_1.000_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (31386, 1276)
Number of total missing values across all columns: 62772
Data Subset Is Off
Wells held out for testing: ['D21' 'L22']
Wells to use for training, validation, and testing ['D16' 'D17' 'D20' 'L18' 'L19' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.655593).  Saving model ...
	 Train_Loss: 0.6824 Train_Acc: 55.851 Val_Loss: 0.6556  BEST VAL Loss: 0.6556  Val_Acc: 61.595

Epoch 1: Validation loss decreased (0.655593 --> 0.641111).  Saving model ...
	 Train_Loss: 0.6695 Train_Acc: 60.846 Val_Loss: 0.6411  BEST VAL Loss: 0.6411  Val_Acc: 64.038

Epoch 2: Validation loss decreased (0.641111 --> 0.631084).  Saving model ...
	 Train_Loss: 0.6560 Train_Acc: 64.200 Val_Loss: 0.6311  BEST VAL Loss: 0.6311  Val_Acc: 65.881

Epoch 3: Validation loss decreased (0.631084 --> 0.620475).  Saving model ...
	 Train_Loss: 0.6432 Train_Acc: 67.077 Val_Loss: 0.6205  BEST VAL Loss: 0.6205  Val_Acc: 67.638

Epoch 4: Validation loss decreased (0.620475 --> 0.610552).  Saving model ...
	 Train_Loss: 0.6308 Train_Acc: 69.483 Val_Loss: 0.6106  BEST VAL Loss: 0.6106  Val_Acc: 69.953

Epoch 5: Validation loss decreased (0.610552 --> 0.600827).  Saving model ...
	 Train_Loss: 0.6194 Train_Acc: 71.086 Val_Loss: 0.6008  BEST VAL Loss: 0.6008  Val_Acc: 71.882

Epoch 6: Validation loss decreased (0.600827 --> 0.592909).  Saving model ...
	 Train_Loss: 0.6089 Train_Acc: 71.997 Val_Loss: 0.5929  BEST VAL Loss: 0.5929  Val_Acc: 71.710

Epoch 7: Validation loss decreased (0.592909 --> 0.584972).  Saving model ...
	 Train_Loss: 0.5991 Train_Acc: 73.074 Val_Loss: 0.5850  BEST VAL Loss: 0.5850  Val_Acc: 73.125

Epoch 8: Validation loss decreased (0.584972 --> 0.578659).  Saving model ...
	 Train_Loss: 0.5900 Train_Acc: 74.263 Val_Loss: 0.5787  BEST VAL Loss: 0.5787  Val_Acc: 73.253

Epoch 9: Validation loss decreased (0.578659 --> 0.572762).  Saving model ...
	 Train_Loss: 0.5821 Train_Acc: 74.654 Val_Loss: 0.5728  BEST VAL Loss: 0.5728  Val_Acc: 73.725

Epoch 10: Validation loss decreased (0.572762 --> 0.568688).  Saving model ...
	 Train_Loss: 0.5744 Train_Acc: 75.501 Val_Loss: 0.5687  BEST VAL Loss: 0.5687  Val_Acc: 73.682

Epoch 11: Validation loss decreased (0.568688 --> 0.564264).  Saving model ...
	 Train_Loss: 0.5673 Train_Acc: 75.603 Val_Loss: 0.5643  BEST VAL Loss: 0.5643  Val_Acc: 74.796

Epoch 12: Validation loss decreased (0.564264 --> 0.559945).  Saving model ...
	 Train_Loss: 0.5609 Train_Acc: 75.914 Val_Loss: 0.5599  BEST VAL Loss: 0.5599  Val_Acc: 74.325

Epoch 13: Validation loss decreased (0.559945 --> 0.555715).  Saving model ...
	 Train_Loss: 0.5551 Train_Acc: 76.417 Val_Loss: 0.5557  BEST VAL Loss: 0.5557  Val_Acc: 74.625

Epoch 14: Validation loss decreased (0.555715 --> 0.552676).  Saving model ...
	 Train_Loss: 0.5500 Train_Acc: 76.337 Val_Loss: 0.5527  BEST VAL Loss: 0.5527  Val_Acc: 75.225

Epoch 15: Validation loss decreased (0.552676 --> 0.549302).  Saving model ...
	 Train_Loss: 0.5447 Train_Acc: 76.835 Val_Loss: 0.5493  BEST VAL Loss: 0.5493  Val_Acc: 75.396

Epoch 16: Validation loss decreased (0.549302 --> 0.547433).  Saving model ...
	 Train_Loss: 0.5400 Train_Acc: 76.905 Val_Loss: 0.5474  BEST VAL Loss: 0.5474  Val_Acc: 74.411

Epoch 17: Validation loss decreased (0.547433 --> 0.544986).  Saving model ...
	 Train_Loss: 0.5354 Train_Acc: 77.157 Val_Loss: 0.5450  BEST VAL Loss: 0.5450  Val_Acc: 75.482

Epoch 18: Validation loss decreased (0.544986 --> 0.543276).  Saving model ...
	 Train_Loss: 0.5308 Train_Acc: 77.880 Val_Loss: 0.5433  BEST VAL Loss: 0.5433  Val_Acc: 75.868

Epoch 19: Validation loss decreased (0.543276 --> 0.541340).  Saving model ...
	 Train_Loss: 0.5267 Train_Acc: 77.634 Val_Loss: 0.5413  BEST VAL Loss: 0.5413  Val_Acc: 74.496

Epoch 20: Validation loss decreased (0.541340 --> 0.539319).  Saving model ...
	 Train_Loss: 0.5228 Train_Acc: 77.784 Val_Loss: 0.5393  BEST VAL Loss: 0.5393  Val_Acc: 75.439

Epoch 21: Validation loss decreased (0.539319 --> 0.537840).  Saving model ...
	 Train_Loss: 0.5189 Train_Acc: 78.368 Val_Loss: 0.5378  BEST VAL Loss: 0.5378  Val_Acc: 75.396

Epoch 22: Validation loss decreased (0.537840 --> 0.536701).  Saving model ...
	 Train_Loss: 0.5153 Train_Acc: 78.373 Val_Loss: 0.5367  BEST VAL Loss: 0.5367  Val_Acc: 74.496

Epoch 23: Validation loss decreased (0.536701 --> 0.535495).  Saving model ...
	 Train_Loss: 0.5119 Train_Acc: 78.373 Val_Loss: 0.5355  BEST VAL Loss: 0.5355  Val_Acc: 74.282

Epoch 24: Validation loss decreased (0.535495 --> 0.534555).  Saving model ...
	 Train_Loss: 0.5085 Train_Acc: 78.802 Val_Loss: 0.5346  BEST VAL Loss: 0.5346  Val_Acc: 75.782

Epoch 25: Validation loss decreased (0.534555 --> 0.533419).  Saving model ...
	 Train_Loss: 0.5054 Train_Acc: 78.754 Val_Loss: 0.5334  BEST VAL Loss: 0.5334  Val_Acc: 75.182

Epoch 26: Validation loss decreased (0.533419 --> 0.532330).  Saving model ...
	 Train_Loss: 0.5023 Train_Acc: 79.113 Val_Loss: 0.5323  BEST VAL Loss: 0.5323  Val_Acc: 75.525

Epoch 27: Validation loss decreased (0.532330 --> 0.531823).  Saving model ...
	 Train_Loss: 0.4995 Train_Acc: 78.796 Val_Loss: 0.5318  BEST VAL Loss: 0.5318  Val_Acc: 74.668

Epoch 28: Validation loss decreased (0.531823 --> 0.531268).  Saving model ...
	 Train_Loss: 0.4966 Train_Acc: 79.659 Val_Loss: 0.5313  BEST VAL Loss: 0.5313  Val_Acc: 74.882

Epoch 29: Validation loss decreased (0.531268 --> 0.529899).  Saving model ...
	 Train_Loss: 0.4939 Train_Acc: 79.825 Val_Loss: 0.5299  BEST VAL Loss: 0.5299  Val_Acc: 75.354

Epoch 30: Validation loss decreased (0.529899 --> 0.529426).  Saving model ...
	 Train_Loss: 0.4913 Train_Acc: 79.177 Val_Loss: 0.5294  BEST VAL Loss: 0.5294  Val_Acc: 74.839

Epoch 31: Validation loss decreased (0.529426 --> 0.528881).  Saving model ...
	 Train_Loss: 0.4890 Train_Acc: 79.204 Val_Loss: 0.5289  BEST VAL Loss: 0.5289  Val_Acc: 74.368

Epoch 32: Validation loss decreased (0.528881 --> 0.528455).  Saving model ...
	 Train_Loss: 0.4867 Train_Acc: 79.418 Val_Loss: 0.5285  BEST VAL Loss: 0.5285  Val_Acc: 75.482

Epoch 33: Validation loss decreased (0.528455 --> 0.528008).  Saving model ...
	 Train_Loss: 0.4843 Train_Acc: 80.206 Val_Loss: 0.5280  BEST VAL Loss: 0.5280  Val_Acc: 75.825

Epoch 34: Validation loss decreased (0.528008 --> 0.527141).  Saving model ...
	 Train_Loss: 0.4819 Train_Acc: 80.088 Val_Loss: 0.5271  BEST VAL Loss: 0.5271  Val_Acc: 75.654

Epoch 35: Validation loss decreased (0.527141 --> 0.526607).  Saving model ...
	 Train_Loss: 0.4797 Train_Acc: 79.756 Val_Loss: 0.5266  BEST VAL Loss: 0.5266  Val_Acc: 75.868

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.4776 Train_Acc: 79.986 Val_Loss: 0.5269  BEST VAL Loss: 0.5266  Val_Acc: 75.697

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.4755 Train_Acc: 79.949 Val_Loss: 0.5274  BEST VAL Loss: 0.5266  Val_Acc: 74.368

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.4735 Train_Acc: 79.991 Val_Loss: 0.5272  BEST VAL Loss: 0.5266  Val_Acc: 75.782

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.4715 Train_Acc: 79.788 Val_Loss: 0.5269  BEST VAL Loss: 0.5266  Val_Acc: 75.825

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.4696 Train_Acc: 80.275 Val_Loss: 0.5268  BEST VAL Loss: 0.5266  Val_Acc: 75.525

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.4677 Train_Acc: 80.506 Val_Loss: 0.5268  BEST VAL Loss: 0.5266  Val_Acc: 75.311

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.4658 Train_Acc: 80.565 Val_Loss: 0.5267  BEST VAL Loss: 0.5266  Val_Acc: 75.311

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.4640 Train_Acc: 80.447 Val_Loss: 0.5267  BEST VAL Loss: 0.5266  Val_Acc: 75.568

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.4622 Train_Acc: 80.704 Val_Loss: 0.5269  BEST VAL Loss: 0.5266  Val_Acc: 75.396

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.4605 Train_Acc: 80.731 Val_Loss: 0.5270  BEST VAL Loss: 0.5266  Val_Acc: 75.825

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.4587 Train_Acc: 80.822 Val_Loss: 0.5273  BEST VAL Loss: 0.5266  Val_Acc: 75.139

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.4570 Train_Acc: 81.063 Val_Loss: 0.5274  BEST VAL Loss: 0.5266  Val_Acc: 75.568

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.4555 Train_Acc: 80.581 Val_Loss: 0.5273  BEST VAL Loss: 0.5266  Val_Acc: 76.254

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.4538 Train_Acc: 80.897 Val_Loss: 0.5275  BEST VAL Loss: 0.5266  Val_Acc: 75.268

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.4523 Train_Acc: 81.031 Val_Loss: 0.5274  BEST VAL Loss: 0.5266  Val_Acc: 74.925

Epoch 51: Validation loss did not decrease
Early stopped at epoch : 51
LPS_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.42      0.44      8635
           1       0.53      0.58      0.56     10027

    accuracy                           0.50     18662
   macro avg       0.50      0.50      0.50     18662
weighted avg       0.50      0.50      0.50     18662

LPS_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.41      0.43      1079
           1       0.53      0.58      0.56      1254

    accuracy                           0.50      2333
   macro avg       0.50      0.50      0.49      2333
weighted avg       0.50      0.50      0.50      2333

LPS_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.42      0.44      1079
           1       0.54      0.58      0.56      1254

    accuracy                           0.51      2333
   macro avg       0.50      0.50      0.50      2333
weighted avg       0.50      0.51      0.50      2333

              precision    recall  f1-score   support

           0       0.46      0.42      0.44      1079
           1       0.54      0.58      0.56      1254

    accuracy                           0.51      2333
   macro avg       0.50      0.50      0.50      2333
weighted avg       0.50      0.51      0.50      2333

LPS_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.49      0.50      4135
           1       0.48      0.50      0.49      3923

    accuracy                           0.50      8058
   macro avg       0.50      0.50      0.50      8058
weighted avg       0.50      0.50      0.50      8058

              precision    recall  f1-score   support

           0       0.51      0.49      0.50      4135
           1       0.48      0.50      0.49      3923

    accuracy                           0.50      8058
   macro avg       0.50      0.50      0.50      8058
weighted avg       0.50      0.50      0.50      8058

completed
