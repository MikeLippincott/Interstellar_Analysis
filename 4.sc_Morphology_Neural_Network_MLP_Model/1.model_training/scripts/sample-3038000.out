[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'bf8cd233'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '5cb3bd21'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '2935fc01'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'c4c773dd'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_0.100_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_Nigericin_1.000_3.0_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (28580, 1276)
Number of total missing values across all columns: 29856
Data Subset Is Off
Wells held out for testing: ['L16' 'L22']
Wells to use for training, validation, and testing ['L17' 'L18' 'L19' 'L20' 'L21' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.250806).  Saving model ...
	 Train_Loss: 0.4166 Train_Acc: 77.878 Val_Loss: 0.2508  BEST VAL Loss: 0.2508  Val_Acc: 89.913

Epoch 1: Validation loss decreased (0.250806 --> 0.227834).  Saving model ...
	 Train_Loss: 0.3408 Train_Acc: 87.129 Val_Loss: 0.2278  BEST VAL Loss: 0.2278  Val_Acc: 91.940

Epoch 2: Validation loss decreased (0.227834 --> 0.203978).  Saving model ...
	 Train_Loss: 0.2977 Train_Acc: 89.434 Val_Loss: 0.2040  BEST VAL Loss: 0.2040  Val_Acc: 92.712

Epoch 3: Validation loss decreased (0.203978 --> 0.190273).  Saving model ...
	 Train_Loss: 0.2685 Train_Acc: 91.280 Val_Loss: 0.1903  BEST VAL Loss: 0.1903  Val_Acc: 94.160

Epoch 4: Validation loss decreased (0.190273 --> 0.182329).  Saving model ...
	 Train_Loss: 0.2467 Train_Acc: 93.501 Val_Loss: 0.1823  BEST VAL Loss: 0.1823  Val_Acc: 94.546

Epoch 5: Validation loss decreased (0.182329 --> 0.173731).  Saving model ...
	 Train_Loss: 0.2286 Train_Acc: 94.364 Val_Loss: 0.1737  BEST VAL Loss: 0.1737  Val_Acc: 95.077

Epoch 6: Validation loss decreased (0.173731 --> 0.164097).  Saving model ...
	 Train_Loss: 0.2138 Train_Acc: 94.871 Val_Loss: 0.1641  BEST VAL Loss: 0.1641  Val_Acc: 95.125

Epoch 7: Validation loss decreased (0.164097 --> 0.157805).  Saving model ...
	 Train_Loss: 0.2019 Train_Acc: 95.245 Val_Loss: 0.1578  BEST VAL Loss: 0.1578  Val_Acc: 95.222

Epoch 8: Validation loss decreased (0.157805 --> 0.152087).  Saving model ...
	 Train_Loss: 0.1919 Train_Acc: 95.758 Val_Loss: 0.1521  BEST VAL Loss: 0.1521  Val_Acc: 95.753

Epoch 9: Validation loss decreased (0.152087 --> 0.148232).  Saving model ...
	 Train_Loss: 0.1829 Train_Acc: 95.957 Val_Loss: 0.1482  BEST VAL Loss: 0.1482  Val_Acc: 96.187

Epoch 10: Validation loss decreased (0.148232 --> 0.143566).  Saving model ...
	 Train_Loss: 0.1753 Train_Acc: 96.126 Val_Loss: 0.1436  BEST VAL Loss: 0.1436  Val_Acc: 96.187

Epoch 11: Validation loss decreased (0.143566 --> 0.143198).  Saving model ...
	 Train_Loss: 0.1681 Train_Acc: 96.482 Val_Loss: 0.1432  BEST VAL Loss: 0.1432  Val_Acc: 95.656

Epoch 12: Validation loss decreased (0.143198 --> 0.140768).  Saving model ...
	 Train_Loss: 0.1617 Train_Acc: 96.729 Val_Loss: 0.1408  BEST VAL Loss: 0.1408  Val_Acc: 96.042

Epoch 13: Validation loss decreased (0.140768 --> 0.138915).  Saving model ...
	 Train_Loss: 0.1559 Train_Acc: 97.049 Val_Loss: 0.1389  BEST VAL Loss: 0.1389  Val_Acc: 96.284

Epoch 14: Validation loss decreased (0.138915 --> 0.135453).  Saving model ...
	 Train_Loss: 0.1508 Train_Acc: 96.959 Val_Loss: 0.1355  BEST VAL Loss: 0.1355  Val_Acc: 96.670

Epoch 15: Validation loss decreased (0.135453 --> 0.132944).  Saving model ...
	 Train_Loss: 0.1459 Train_Acc: 97.315 Val_Loss: 0.1329  BEST VAL Loss: 0.1329  Val_Acc: 96.477

Epoch 16: Validation loss decreased (0.132944 --> 0.129563).  Saving model ...
	 Train_Loss: 0.1413 Train_Acc: 97.411 Val_Loss: 0.1296  BEST VAL Loss: 0.1296  Val_Acc: 96.332

Epoch 17: Validation loss decreased (0.129563 --> 0.128962).  Saving model ...
	 Train_Loss: 0.1371 Train_Acc: 97.520 Val_Loss: 0.1290  BEST VAL Loss: 0.1290  Val_Acc: 96.477

Epoch 18: Validation loss decreased (0.128962 --> 0.128121).  Saving model ...
	 Train_Loss: 0.1333 Train_Acc: 97.387 Val_Loss: 0.1281  BEST VAL Loss: 0.1281  Val_Acc: 96.815

Epoch 19: Validation loss decreased (0.128121 --> 0.127812).  Saving model ...
	 Train_Loss: 0.1299 Train_Acc: 97.592 Val_Loss: 0.1278  BEST VAL Loss: 0.1278  Val_Acc: 96.477

Epoch 20: Validation loss decreased (0.127812 --> 0.126073).  Saving model ...
	 Train_Loss: 0.1265 Train_Acc: 97.816 Val_Loss: 0.1261  BEST VAL Loss: 0.1261  Val_Acc: 96.959

Epoch 21: Validation loss decreased (0.126073 --> 0.125744).  Saving model ...
	 Train_Loss: 0.1232 Train_Acc: 97.924 Val_Loss: 0.1257  BEST VAL Loss: 0.1257  Val_Acc: 96.332

Epoch 22: Validation loss decreased (0.125744 --> 0.124049).  Saving model ...
	 Train_Loss: 0.1204 Train_Acc: 97.822 Val_Loss: 0.1240  BEST VAL Loss: 0.1240  Val_Acc: 96.863

Epoch 23: Validation loss decreased (0.124049 --> 0.122883).  Saving model ...
	 Train_Loss: 0.1176 Train_Acc: 97.894 Val_Loss: 0.1229  BEST VAL Loss: 0.1229  Val_Acc: 96.622

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.1151 Train_Acc: 97.966 Val_Loss: 0.1230  BEST VAL Loss: 0.1229  Val_Acc: 96.815

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.1130 Train_Acc: 97.767 Val_Loss: 0.1235  BEST VAL Loss: 0.1229  Val_Acc: 96.670

Epoch 26: Validation loss decreased (0.122883 --> 0.122423).  Saving model ...
	 Train_Loss: 0.1107 Train_Acc: 98.069 Val_Loss: 0.1224  BEST VAL Loss: 0.1224  Val_Acc: 97.008

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.1086 Train_Acc: 98.021 Val_Loss: 0.1225  BEST VAL Loss: 0.1224  Val_Acc: 96.863

Epoch 28: Validation loss decreased (0.122423 --> 0.121394).  Saving model ...
	 Train_Loss: 0.1066 Train_Acc: 98.087 Val_Loss: 0.1214  BEST VAL Loss: 0.1214  Val_Acc: 96.670

Epoch 29: Validation loss decreased (0.121394 --> 0.120175).  Saving model ...
	 Train_Loss: 0.1046 Train_Acc: 98.274 Val_Loss: 0.1202  BEST VAL Loss: 0.1202  Val_Acc: 97.056

Epoch 30: Validation loss decreased (0.120175 --> 0.119202).  Saving model ...
	 Train_Loss: 0.1028 Train_Acc: 98.292 Val_Loss: 0.1192  BEST VAL Loss: 0.1192  Val_Acc: 96.863

Epoch 31: Validation loss decreased (0.119202 --> 0.117687).  Saving model ...
	 Train_Loss: 0.1011 Train_Acc: 98.383 Val_Loss: 0.1177  BEST VAL Loss: 0.1177  Val_Acc: 97.297

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.0994 Train_Acc: 98.425 Val_Loss: 0.1187  BEST VAL Loss: 0.1177  Val_Acc: 97.201

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.0977 Train_Acc: 98.497 Val_Loss: 0.1185  BEST VAL Loss: 0.1177  Val_Acc: 96.911

Epoch 34: Validation loss did not decrease
	 Train_Loss: 0.0962 Train_Acc: 98.401 Val_Loss: 0.1183  BEST VAL Loss: 0.1177  Val_Acc: 96.766

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.0948 Train_Acc: 98.280 Val_Loss: 0.1182  BEST VAL Loss: 0.1177  Val_Acc: 96.670

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.0935 Train_Acc: 98.208 Val_Loss: 0.1181  BEST VAL Loss: 0.1177  Val_Acc: 97.008

Epoch 37: Validation loss decreased (0.117687 --> 0.116965).  Saving model ...
	 Train_Loss: 0.0922 Train_Acc: 98.232 Val_Loss: 0.1170  BEST VAL Loss: 0.1170  Val_Acc: 97.442

Epoch 38: Validation loss decreased (0.116965 --> 0.116748).  Saving model ...
	 Train_Loss: 0.0909 Train_Acc: 98.407 Val_Loss: 0.1167  BEST VAL Loss: 0.1167  Val_Acc: 97.008

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.0897 Train_Acc: 98.467 Val_Loss: 0.1174  BEST VAL Loss: 0.1167  Val_Acc: 96.718

Epoch 40: Validation loss decreased (0.116748 --> 0.116475).  Saving model ...
	 Train_Loss: 0.0885 Train_Acc: 98.510 Val_Loss: 0.1165  BEST VAL Loss: 0.1165  Val_Acc: 97.153

Epoch 41: Validation loss decreased (0.116475 --> 0.116019).  Saving model ...
	 Train_Loss: 0.0874 Train_Acc: 98.510 Val_Loss: 0.1160  BEST VAL Loss: 0.1160  Val_Acc: 96.815

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.0863 Train_Acc: 98.630 Val_Loss: 0.1163  BEST VAL Loss: 0.1160  Val_Acc: 96.911

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.0852 Train_Acc: 98.630 Val_Loss: 0.1162  BEST VAL Loss: 0.1160  Val_Acc: 97.201

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.0842 Train_Acc: 98.691 Val_Loss: 0.1170  BEST VAL Loss: 0.1160  Val_Acc: 96.959

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.0832 Train_Acc: 98.594 Val_Loss: 0.1164  BEST VAL Loss: 0.1160  Val_Acc: 96.670

Epoch 46: Validation loss decreased (0.116019 --> 0.115926).  Saving model ...
	 Train_Loss: 0.0823 Train_Acc: 98.582 Val_Loss: 0.1159  BEST VAL Loss: 0.1159  Val_Acc: 96.622

Epoch 47: Validation loss decreased (0.115926 --> 0.115252).  Saving model ...
	 Train_Loss: 0.0814 Train_Acc: 98.491 Val_Loss: 0.1153  BEST VAL Loss: 0.1153  Val_Acc: 97.008

Epoch 48: Validation loss decreased (0.115252 --> 0.114611).  Saving model ...
	 Train_Loss: 0.0805 Train_Acc: 98.485 Val_Loss: 0.1146  BEST VAL Loss: 0.1146  Val_Acc: 97.008

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.0797 Train_Acc: 98.407 Val_Loss: 0.1159  BEST VAL Loss: 0.1146  Val_Acc: 97.249

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.0789 Train_Acc: 98.443 Val_Loss: 0.1153  BEST VAL Loss: 0.1146  Val_Acc: 97.346

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.0781 Train_Acc: 98.672 Val_Loss: 0.1153  BEST VAL Loss: 0.1146  Val_Acc: 96.766

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.0773 Train_Acc: 98.715 Val_Loss: 0.1152  BEST VAL Loss: 0.1146  Val_Acc: 96.911

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.0765 Train_Acc: 98.757 Val_Loss: 0.1154  BEST VAL Loss: 0.1146  Val_Acc: 97.297

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.0758 Train_Acc: 98.672 Val_Loss: 0.1152  BEST VAL Loss: 0.1146  Val_Acc: 97.249

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.0751 Train_Acc: 98.636 Val_Loss: 0.1151  BEST VAL Loss: 0.1146  Val_Acc: 97.153

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.0744 Train_Acc: 98.727 Val_Loss: 0.1153  BEST VAL Loss: 0.1146  Val_Acc: 97.249

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.0737 Train_Acc: 98.721 Val_Loss: 0.1151  BEST VAL Loss: 0.1146  Val_Acc: 96.815

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.0730 Train_Acc: 98.769 Val_Loss: 0.1149  BEST VAL Loss: 0.1146  Val_Acc: 97.008

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.0724 Train_Acc: 98.866 Val_Loss: 0.1148  BEST VAL Loss: 0.1146  Val_Acc: 96.959

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.0717 Train_Acc: 98.757 Val_Loss: 0.1152  BEST VAL Loss: 0.1146  Val_Acc: 97.201

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.0711 Train_Acc: 98.847 Val_Loss: 0.1151  BEST VAL Loss: 0.1146  Val_Acc: 96.959

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.0705 Train_Acc: 98.968 Val_Loss: 0.1153  BEST VAL Loss: 0.1146  Val_Acc: 97.442

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.0699 Train_Acc: 98.799 Val_Loss: 0.1148  BEST VAL Loss: 0.1146  Val_Acc: 97.346

Epoch 64: Validation loss decreased (0.114611 --> 0.114180).  Saving model ...
	 Train_Loss: 0.0693 Train_Acc: 98.853 Val_Loss: 0.1142  BEST VAL Loss: 0.1142  Val_Acc: 97.153

Epoch 65: Validation loss decreased (0.114180 --> 0.113806).  Saving model ...
	 Train_Loss: 0.0687 Train_Acc: 98.866 Val_Loss: 0.1138  BEST VAL Loss: 0.1138  Val_Acc: 97.201

Epoch 66: Validation loss decreased (0.113806 --> 0.113797).  Saving model ...
	 Train_Loss: 0.0682 Train_Acc: 98.805 Val_Loss: 0.1138  BEST VAL Loss: 0.1138  Val_Acc: 97.104

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.0677 Train_Acc: 98.799 Val_Loss: 0.1139  BEST VAL Loss: 0.1138  Val_Acc: 97.201

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.0671 Train_Acc: 98.938 Val_Loss: 0.1140  BEST VAL Loss: 0.1138  Val_Acc: 97.008

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.0667 Train_Acc: 98.908 Val_Loss: 0.1141  BEST VAL Loss: 0.1138  Val_Acc: 97.249

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.0663 Train_Acc: 98.660 Val_Loss: 0.1148  BEST VAL Loss: 0.1138  Val_Acc: 96.863

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.0658 Train_Acc: 98.709 Val_Loss: 0.1153  BEST VAL Loss: 0.1138  Val_Acc: 96.959

Epoch 72: Validation loss did not decrease
	 Train_Loss: 0.0653 Train_Acc: 98.872 Val_Loss: 0.1157  BEST VAL Loss: 0.1138  Val_Acc: 96.863

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.0649 Train_Acc: 98.932 Val_Loss: 0.1162  BEST VAL Loss: 0.1138  Val_Acc: 97.249

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.0644 Train_Acc: 98.757 Val_Loss: 0.1161  BEST VAL Loss: 0.1138  Val_Acc: 97.104

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.0640 Train_Acc: 99.028 Val_Loss: 0.1158  BEST VAL Loss: 0.1138  Val_Acc: 97.104

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.0635 Train_Acc: 98.938 Val_Loss: 0.1158  BEST VAL Loss: 0.1138  Val_Acc: 97.442

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.0631 Train_Acc: 98.980 Val_Loss: 0.1157  BEST VAL Loss: 0.1138  Val_Acc: 97.346

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.0626 Train_Acc: 98.932 Val_Loss: 0.1156  BEST VAL Loss: 0.1138  Val_Acc: 97.587

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.0622 Train_Acc: 99.028 Val_Loss: 0.1157  BEST VAL Loss: 0.1138  Val_Acc: 97.008

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.0618 Train_Acc: 98.938 Val_Loss: 0.1163  BEST VAL Loss: 0.1138  Val_Acc: 97.394

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.0614 Train_Acc: 99.035 Val_Loss: 0.1173  BEST VAL Loss: 0.1138  Val_Acc: 97.442

Epoch 82: Validation loss did not decrease
Early stopped at epoch : 82
Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.52      0.52      8634
           1       0.48      0.48      0.48      7938

    accuracy                           0.50     16572
   macro avg       0.50      0.50      0.50     16572
weighted avg       0.50      0.50      0.50     16572

Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.50      0.51      1080
           1       0.47      0.47      0.47       992

    accuracy                           0.49      2072
   macro avg       0.49      0.49      0.49      2072
weighted avg       0.49      0.49      0.49      2072

Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.52      0.52      1079
           1       0.48      0.48      0.48       993

    accuracy                           0.50      2072
   macro avg       0.50      0.50      0.50      2072
weighted avg       0.50      0.50      0.50      2072

              precision    recall  f1-score   support

           0       0.52      0.52      0.52      1079
           1       0.48      0.48      0.48       993

    accuracy                           0.50      2072
   macro avg       0.50      0.50      0.50      2072
weighted avg       0.50      0.50      0.50      2072

Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.54      0.53      4135
           1       0.48      0.47      0.47      3729

    accuracy                           0.50      7864
   macro avg       0.50      0.50      0.50      7864
weighted avg       0.50      0.50      0.50      7864

              precision    recall  f1-score   support

           0       0.53      0.54      0.53      4135
           1       0.48      0.47      0.47      3729

    accuracy                           0.50      7864
   macro avg       0.50      0.50      0.50      7864
weighted avg       0.50      0.50      0.50      7864

completed
