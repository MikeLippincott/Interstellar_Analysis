[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '727bfa80'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '93be96a1'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '00b9e83a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '01726225'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: DMSO_0.100_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: DMSO_0.100_DMSO_0.025
TREATMENT_NAME: Flagellin_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (319677, 1270)
Number of total missing values across all columns: 675970
Data Subset Is Off
Wells held out for testing: ['J06' 'M10']
Wells to use for training, validation, and testing ['B06' 'C06' 'B07' 'C07' 'I06' 'I07' 'J07' 'M05' 'M11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.376567).  Saving model ...
	 Train_Loss: 0.5079 Train_Acc: 75.731 Val_Loss: 0.3766  BEST VAL Loss: 0.3766  Val_Acc: 83.123

Epoch 1: Validation loss decreased (0.376567 --> 0.354049).  Saving model ...
	 Train_Loss: 0.4525 Train_Acc: 81.077 Val_Loss: 0.3540  BEST VAL Loss: 0.3540  Val_Acc: 85.274

Epoch 2: Validation loss did not decrease
	 Train_Loss: 0.4280 Train_Acc: 82.116 Val_Loss: 0.3668  BEST VAL Loss: 0.3540  Val_Acc: 82.381

Epoch 3: Validation loss did not decrease
	 Train_Loss: 0.4137 Train_Acc: 82.883 Val_Loss: 0.4439  BEST VAL Loss: 0.3540  Val_Acc: 67.326

Epoch 4: Validation loss did not decrease
	 Train_Loss: 0.4342 Train_Acc: 78.823 Val_Loss: 0.4242  BEST VAL Loss: 0.3540  Val_Acc: 84.482

Epoch 5: Validation loss did not decrease
	 Train_Loss: 0.4211 Train_Acc: 82.861 Val_Loss: 0.4017  BEST VAL Loss: 0.3540  Val_Acc: 87.472

Epoch 6: Validation loss did not decrease
	 Train_Loss: 0.4064 Train_Acc: 84.906 Val_Loss: 0.3837  BEST VAL Loss: 0.3540  Val_Acc: 88.000

Epoch 7: Validation loss did not decrease
	 Train_Loss: 0.3949 Train_Acc: 85.312 Val_Loss: 0.3713  BEST VAL Loss: 0.3540  Val_Acc: 87.558

Epoch 8: Validation loss did not decrease
	 Train_Loss: 0.3863 Train_Acc: 84.969 Val_Loss: 0.3599  BEST VAL Loss: 0.3540  Val_Acc: 88.066

Epoch 9: Validation loss decreased (0.354049 --> 0.351196).  Saving model ...
	 Train_Loss: 0.3790 Train_Acc: 85.151 Val_Loss: 0.3512  BEST VAL Loss: 0.3512  Val_Acc: 88.416

Epoch 10: Validation loss decreased (0.351196 --> 0.344725).  Saving model ...
	 Train_Loss: 0.3731 Train_Acc: 85.665 Val_Loss: 0.3447  BEST VAL Loss: 0.3447  Val_Acc: 88.167

Epoch 11: Validation loss decreased (0.344725 --> 0.339174).  Saving model ...
	 Train_Loss: 0.3678 Train_Acc: 85.502 Val_Loss: 0.3392  BEST VAL Loss: 0.3392  Val_Acc: 88.094

Epoch 12: Validation loss decreased (0.339174 --> 0.333496).  Saving model ...
	 Train_Loss: 0.3629 Train_Acc: 86.004 Val_Loss: 0.3335  BEST VAL Loss: 0.3335  Val_Acc: 88.331

Epoch 13: Validation loss did not decrease
	 Train_Loss: 0.3608 Train_Acc: 84.376 Val_Loss: 0.6915  BEST VAL Loss: 0.3335  Val_Acc: 36.601

Epoch 14: Validation loss did not decrease
	 Train_Loss: 0.3873 Train_Acc: 79.458 Val_Loss: 0.6668  BEST VAL Loss: 0.3335  Val_Acc: 85.938

Epoch 15: Validation loss did not decrease
	 Train_Loss: 0.3855 Train_Acc: 82.392 Val_Loss: 0.6428  BEST VAL Loss: 0.3335  Val_Acc: 87.080

Epoch 16: Validation loss did not decrease
	 Train_Loss: 0.3816 Train_Acc: 84.840 Val_Loss: 0.6208  BEST VAL Loss: 0.3335  Val_Acc: 87.837

Epoch 17: Validation loss did not decrease
	 Train_Loss: 0.3779 Train_Acc: 84.877 Val_Loss: 0.6050  BEST VAL Loss: 0.3335  Val_Acc: 83.838

Epoch 18: Validation loss did not decrease
	 Train_Loss: 0.3743 Train_Acc: 84.862 Val_Loss: 0.5887  BEST VAL Loss: 0.3335  Val_Acc: 86.878

Epoch 19: Validation loss did not decrease
	 Train_Loss: 0.3713 Train_Acc: 84.840 Val_Loss: 0.5729  BEST VAL Loss: 0.3335  Val_Acc: 88.323

Epoch 20: Validation loss did not decrease
	 Train_Loss: 0.3676 Train_Acc: 85.742 Val_Loss: 0.5578  BEST VAL Loss: 0.3335  Val_Acc: 88.268

Epoch 21: Validation loss did not decrease
	 Train_Loss: 0.3642 Train_Acc: 86.225 Val_Loss: 0.5441  BEST VAL Loss: 0.3335  Val_Acc: 88.832

Epoch 22: Validation loss did not decrease
	 Train_Loss: 0.3612 Train_Acc: 86.196 Val_Loss: 0.5323  BEST VAL Loss: 0.3335  Val_Acc: 87.853

Epoch 23: Validation loss did not decrease
	 Train_Loss: 0.3591 Train_Acc: 85.257 Val_Loss: 0.5239  BEST VAL Loss: 0.3335  Val_Acc: 83.818

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.3602 Train_Acc: 82.951 Val_Loss: 0.5137  BEST VAL Loss: 0.3335  Val_Acc: 87.985

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.3578 Train_Acc: 85.291 Val_Loss: 0.5040  BEST VAL Loss: 0.3335  Val_Acc: 88.960

Epoch 26: Validation loss did not decrease
	 Train_Loss: 0.3555 Train_Acc: 85.907 Val_Loss: 0.4950  BEST VAL Loss: 0.3335  Val_Acc: 88.863

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.3535 Train_Acc: 85.534 Val_Loss: 0.4892  BEST VAL Loss: 0.3335  Val_Acc: 85.309

Epoch 28: Validation loss did not decrease
Early stopped at epoch : 28
DMSO_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.73      0.72      0.72    149884
           1       0.27      0.28      0.28     56123

    accuracy                           0.60    206007
   macro avg       0.50      0.50      0.50    206007
weighted avg       0.60      0.60      0.60    206007

DMSO_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.73      0.72      0.72     18736
           1       0.27      0.28      0.28      7015

    accuracy                           0.60     25751
   macro avg       0.50      0.50      0.50     25751
weighted avg       0.60      0.60      0.60     25751

DMSO_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.73      0.72      0.72     18736
           1       0.27      0.28      0.27      7015

    accuracy                           0.60     25751
   macro avg       0.50      0.50      0.50     25751
weighted avg       0.60      0.60      0.60     25751

              precision    recall  f1-score   support

           0       0.73      0.72      0.72     18736
           1       0.27      0.28      0.27      7015

    accuracy                           0.60     25751
   macro avg       0.50      0.50      0.50     25751
weighted avg       0.60      0.60      0.60     25751

DMSO_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
DMSO_0.100_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.45      0.65      0.53     27774
           1       0.55      0.35      0.43     34394

    accuracy                           0.48     62168
   macro avg       0.50      0.50      0.48     62168
weighted avg       0.51      0.48      0.47     62168

              precision    recall  f1-score   support

           0       0.45      0.65      0.53     27774
           1       0.55      0.35      0.43     34394

    accuracy                           0.48     62168
   macro avg       0.50      0.50      0.48     62168
weighted avg       0.51      0.48      0.47     62168

completed
