[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '44d0c818'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '71eb24b5'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'c9ae73bb'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'fda82390'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_0.100_DMSO_0.025 treatment_name: LPS_10.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: LPS_10.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (31738, 1276)
Number of total missing values across all columns: 63476
Data Subset Is Off
Wells held out for testing: ['E21' 'L22']
Wells to use for training, validation, and testing ['E16' 'E17' 'E20' 'L18' 'L19' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.669836).  Saving model ...
	 Train_Loss: 0.7079 Train_Acc: 55.497 Val_Loss: 0.6698  BEST VAL Loss: 0.6698  Val_Acc: 59.599

Epoch 1: Validation loss decreased (0.669836 --> 0.660358).  Saving model ...
	 Train_Loss: 0.6839 Train_Acc: 59.375 Val_Loss: 0.6604  BEST VAL Loss: 0.6604  Val_Acc: 60.708

Epoch 2: Validation loss decreased (0.660358 --> 0.652562).  Saving model ...
	 Train_Loss: 0.6681 Train_Acc: 62.053 Val_Loss: 0.6526  BEST VAL Loss: 0.6526  Val_Acc: 63.225

Epoch 3: Validation loss decreased (0.652562 --> 0.643731).  Saving model ...
	 Train_Loss: 0.6553 Train_Acc: 64.112 Val_Loss: 0.6437  BEST VAL Loss: 0.6437  Val_Acc: 64.164

Epoch 4: Validation loss decreased (0.643731 --> 0.636261).  Saving model ...
	 Train_Loss: 0.6447 Train_Acc: 65.525 Val_Loss: 0.6363  BEST VAL Loss: 0.6363  Val_Acc: 66.425

Epoch 5: Validation loss decreased (0.636261 --> 0.627679).  Saving model ...
	 Train_Loss: 0.6346 Train_Acc: 67.355 Val_Loss: 0.6277  BEST VAL Loss: 0.6277  Val_Acc: 67.534

Epoch 6: Validation loss decreased (0.627679 --> 0.621111).  Saving model ...
	 Train_Loss: 0.6250 Train_Acc: 68.587 Val_Loss: 0.6211  BEST VAL Loss: 0.6211  Val_Acc: 69.326

Epoch 7: Validation loss decreased (0.621111 --> 0.616026).  Saving model ...
	 Train_Loss: 0.6170 Train_Acc: 69.211 Val_Loss: 0.6160  BEST VAL Loss: 0.6160  Val_Acc: 67.363

Epoch 8: Validation loss decreased (0.616026 --> 0.610737).  Saving model ...
	 Train_Loss: 0.6102 Train_Acc: 69.344 Val_Loss: 0.6107  BEST VAL Loss: 0.6107  Val_Acc: 69.582

Epoch 9: Validation loss decreased (0.610737 --> 0.605757).  Saving model ...
	 Train_Loss: 0.6038 Train_Acc: 69.937 Val_Loss: 0.6058  BEST VAL Loss: 0.6058  Val_Acc: 70.094

Epoch 10: Validation loss decreased (0.605757 --> 0.600538).  Saving model ...
	 Train_Loss: 0.5978 Train_Acc: 70.262 Val_Loss: 0.6005  BEST VAL Loss: 0.6005  Val_Acc: 69.582

Epoch 11: Validation loss decreased (0.600538 --> 0.595358).  Saving model ...
	 Train_Loss: 0.5922 Train_Acc: 70.502 Val_Loss: 0.5954  BEST VAL Loss: 0.5954  Val_Acc: 71.715

Epoch 12: Validation loss decreased (0.595358 --> 0.592450).  Saving model ...
	 Train_Loss: 0.5872 Train_Acc: 70.545 Val_Loss: 0.5924  BEST VAL Loss: 0.5924  Val_Acc: 69.795

Epoch 13: Validation loss decreased (0.592450 --> 0.590047).  Saving model ...
	 Train_Loss: 0.5828 Train_Acc: 70.742 Val_Loss: 0.5900  BEST VAL Loss: 0.5900  Val_Acc: 69.881

Epoch 14: Validation loss decreased (0.590047 --> 0.586637).  Saving model ...
	 Train_Loss: 0.5789 Train_Acc: 70.785 Val_Loss: 0.5866  BEST VAL Loss: 0.5866  Val_Acc: 70.350

Epoch 15: Validation loss decreased (0.586637 --> 0.583491).  Saving model ...
	 Train_Loss: 0.5750 Train_Acc: 71.051 Val_Loss: 0.5835  BEST VAL Loss: 0.5835  Val_Acc: 70.137

Epoch 16: Validation loss decreased (0.583491 --> 0.580930).  Saving model ...
	 Train_Loss: 0.5715 Train_Acc: 70.907 Val_Loss: 0.5809  BEST VAL Loss: 0.5809  Val_Acc: 70.051

Epoch 17: Validation loss decreased (0.580930 --> 0.578540).  Saving model ...
	 Train_Loss: 0.5684 Train_Acc: 70.961 Val_Loss: 0.5785  BEST VAL Loss: 0.5785  Val_Acc: 70.606

Epoch 18: Validation loss decreased (0.578540 --> 0.576483).  Saving model ...
	 Train_Loss: 0.5654 Train_Acc: 71.323 Val_Loss: 0.5765  BEST VAL Loss: 0.5765  Val_Acc: 71.160

Epoch 19: Validation loss decreased (0.576483 --> 0.573916).  Saving model ...
	 Train_Loss: 0.5625 Train_Acc: 71.302 Val_Loss: 0.5739  BEST VAL Loss: 0.5739  Val_Acc: 70.947

Epoch 20: Validation loss decreased (0.573916 --> 0.572070).  Saving model ...
	 Train_Loss: 0.5595 Train_Acc: 71.633 Val_Loss: 0.5721  BEST VAL Loss: 0.5721  Val_Acc: 70.776

Epoch 21: Validation loss decreased (0.572070 --> 0.570460).  Saving model ...
	 Train_Loss: 0.5568 Train_Acc: 71.867 Val_Loss: 0.5705  BEST VAL Loss: 0.5705  Val_Acc: 70.478

Epoch 22: Validation loss decreased (0.570460 --> 0.568622).  Saving model ...
	 Train_Loss: 0.5543 Train_Acc: 71.478 Val_Loss: 0.5686  BEST VAL Loss: 0.5686  Val_Acc: 70.606

Epoch 23: Validation loss decreased (0.568622 --> 0.566798).  Saving model ...
	 Train_Loss: 0.5520 Train_Acc: 71.526 Val_Loss: 0.5668  BEST VAL Loss: 0.5668  Val_Acc: 69.966

Epoch 24: Validation loss decreased (0.566798 --> 0.565124).  Saving model ...
	 Train_Loss: 0.5498 Train_Acc: 71.798 Val_Loss: 0.5651  BEST VAL Loss: 0.5651  Val_Acc: 72.099

Epoch 25: Validation loss decreased (0.565124 --> 0.563384).  Saving model ...
	 Train_Loss: 0.5477 Train_Acc: 71.771 Val_Loss: 0.5634  BEST VAL Loss: 0.5634  Val_Acc: 70.776

Epoch 26: Validation loss decreased (0.563384 --> 0.562133).  Saving model ...
	 Train_Loss: 0.5457 Train_Acc: 71.857 Val_Loss: 0.5621  BEST VAL Loss: 0.5621  Val_Acc: 70.691

Epoch 27: Validation loss decreased (0.562133 --> 0.561292).  Saving model ...
	 Train_Loss: 0.5438 Train_Acc: 71.921 Val_Loss: 0.5613  BEST VAL Loss: 0.5613  Val_Acc: 73.038

Epoch 28: Validation loss decreased (0.561292 --> 0.560217).  Saving model ...
	 Train_Loss: 0.5419 Train_Acc: 73.425 Val_Loss: 0.5602  BEST VAL Loss: 0.5602  Val_Acc: 72.611

Epoch 29: Validation loss decreased (0.560217 --> 0.559063).  Saving model ...
	 Train_Loss: 0.5401 Train_Acc: 73.361 Val_Loss: 0.5591  BEST VAL Loss: 0.5591  Val_Acc: 73.635

Epoch 30: Validation loss decreased (0.559063 --> 0.557738).  Saving model ...
	 Train_Loss: 0.5384 Train_Acc: 73.537 Val_Loss: 0.5577  BEST VAL Loss: 0.5577  Val_Acc: 71.971

Epoch 31: Validation loss decreased (0.557738 --> 0.556269).  Saving model ...
	 Train_Loss: 0.5368 Train_Acc: 73.340 Val_Loss: 0.5563  BEST VAL Loss: 0.5563  Val_Acc: 73.336

Epoch 32: Validation loss decreased (0.556269 --> 0.555287).  Saving model ...
	 Train_Loss: 0.5352 Train_Acc: 73.521 Val_Loss: 0.5553  BEST VAL Loss: 0.5553  Val_Acc: 73.166

Epoch 33: Validation loss decreased (0.555287 --> 0.554493).  Saving model ...
	 Train_Loss: 0.5338 Train_Acc: 73.308 Val_Loss: 0.5545  BEST VAL Loss: 0.5545  Val_Acc: 72.782

Epoch 34: Validation loss decreased (0.554493 --> 0.553804).  Saving model ...
	 Train_Loss: 0.5324 Train_Acc: 73.804 Val_Loss: 0.5538  BEST VAL Loss: 0.5538  Val_Acc: 73.677

Epoch 35: Validation loss decreased (0.553804 --> 0.552496).  Saving model ...
	 Train_Loss: 0.5308 Train_Acc: 74.204 Val_Loss: 0.5525  BEST VAL Loss: 0.5525  Val_Acc: 73.549

Epoch 36: Validation loss decreased (0.552496 --> 0.551783).  Saving model ...
	 Train_Loss: 0.5293 Train_Acc: 74.401 Val_Loss: 0.5518  BEST VAL Loss: 0.5518  Val_Acc: 73.336

Epoch 37: Validation loss decreased (0.551783 --> 0.551102).  Saving model ...
	 Train_Loss: 0.5281 Train_Acc: 73.628 Val_Loss: 0.5511  BEST VAL Loss: 0.5511  Val_Acc: 73.080

Epoch 38: Validation loss decreased (0.551102 --> 0.550050).  Saving model ...
	 Train_Loss: 0.5268 Train_Acc: 73.985 Val_Loss: 0.5500  BEST VAL Loss: 0.5500  Val_Acc: 73.080

Epoch 39: Validation loss decreased (0.550050 --> 0.549055).  Saving model ...
	 Train_Loss: 0.5254 Train_Acc: 74.577 Val_Loss: 0.5491  BEST VAL Loss: 0.5491  Val_Acc: 73.422

Epoch 40: Validation loss decreased (0.549055 --> 0.548281).  Saving model ...
	 Train_Loss: 0.5241 Train_Acc: 74.273 Val_Loss: 0.5483  BEST VAL Loss: 0.5483  Val_Acc: 73.891

Epoch 41: Validation loss decreased (0.548281 --> 0.546867).  Saving model ...
	 Train_Loss: 0.5230 Train_Acc: 73.996 Val_Loss: 0.5469  BEST VAL Loss: 0.5469  Val_Acc: 74.275

Epoch 42: Validation loss decreased (0.546867 --> 0.546108).  Saving model ...
	 Train_Loss: 0.5219 Train_Acc: 74.316 Val_Loss: 0.5461  BEST VAL Loss: 0.5461  Val_Acc: 73.336

Epoch 43: Validation loss decreased (0.546108 --> 0.545431).  Saving model ...
	 Train_Loss: 0.5207 Train_Acc: 74.455 Val_Loss: 0.5454  BEST VAL Loss: 0.5454  Val_Acc: 73.763

Epoch 44: Validation loss decreased (0.545431 --> 0.544837).  Saving model ...
	 Train_Loss: 0.5196 Train_Acc: 74.727 Val_Loss: 0.5448  BEST VAL Loss: 0.5448  Val_Acc: 73.763

Epoch 45: Validation loss decreased (0.544837 --> 0.544232).  Saving model ...
	 Train_Loss: 0.5185 Train_Acc: 74.876 Val_Loss: 0.5442  BEST VAL Loss: 0.5442  Val_Acc: 73.677

Epoch 46: Validation loss decreased (0.544232 --> 0.543389).  Saving model ...
	 Train_Loss: 0.5174 Train_Acc: 74.828 Val_Loss: 0.5434  BEST VAL Loss: 0.5434  Val_Acc: 73.891

Epoch 47: Validation loss decreased (0.543389 --> 0.543044).  Saving model ...
	 Train_Loss: 0.5164 Train_Acc: 74.497 Val_Loss: 0.5430  BEST VAL Loss: 0.5430  Val_Acc: 74.104

Epoch 48: Validation loss decreased (0.543044 --> 0.542059).  Saving model ...
	 Train_Loss: 0.5154 Train_Acc: 74.551 Val_Loss: 0.5421  BEST VAL Loss: 0.5421  Val_Acc: 74.445

Epoch 49: Validation loss decreased (0.542059 --> 0.541792).  Saving model ...
	 Train_Loss: 0.5145 Train_Acc: 74.764 Val_Loss: 0.5418  BEST VAL Loss: 0.5418  Val_Acc: 73.592

Epoch 50: Validation loss decreased (0.541792 --> 0.541164).  Saving model ...
	 Train_Loss: 0.5135 Train_Acc: 75.132 Val_Loss: 0.5412  BEST VAL Loss: 0.5412  Val_Acc: 74.573

Epoch 51: Validation loss decreased (0.541164 --> 0.540353).  Saving model ...
	 Train_Loss: 0.5125 Train_Acc: 75.415 Val_Loss: 0.5404  BEST VAL Loss: 0.5404  Val_Acc: 75.085

Epoch 52: Validation loss decreased (0.540353 --> 0.539737).  Saving model ...
	 Train_Loss: 0.5116 Train_Acc: 75.548 Val_Loss: 0.5397  BEST VAL Loss: 0.5397  Val_Acc: 74.787

Epoch 53: Validation loss decreased (0.539737 --> 0.539183).  Saving model ...
	 Train_Loss: 0.5106 Train_Acc: 75.345 Val_Loss: 0.5392  BEST VAL Loss: 0.5392  Val_Acc: 74.403

Epoch 54: Validation loss decreased (0.539183 --> 0.538662).  Saving model ...
	 Train_Loss: 0.5097 Train_Acc: 74.913 Val_Loss: 0.5387  BEST VAL Loss: 0.5387  Val_Acc: 74.616

Epoch 55: Validation loss decreased (0.538662 --> 0.537886).  Saving model ...
	 Train_Loss: 0.5089 Train_Acc: 75.233 Val_Loss: 0.5379  BEST VAL Loss: 0.5379  Val_Acc: 75.000

Epoch 56: Validation loss decreased (0.537886 --> 0.537244).  Saving model ...
	 Train_Loss: 0.5081 Train_Acc: 75.308 Val_Loss: 0.5372  BEST VAL Loss: 0.5372  Val_Acc: 74.787

Epoch 57: Validation loss decreased (0.537244 --> 0.536688).  Saving model ...
	 Train_Loss: 0.5072 Train_Acc: 75.452 Val_Loss: 0.5367  BEST VAL Loss: 0.5367  Val_Acc: 74.872

Epoch 58: Validation loss decreased (0.536688 --> 0.536238).  Saving model ...
	 Train_Loss: 0.5064 Train_Acc: 75.292 Val_Loss: 0.5362  BEST VAL Loss: 0.5362  Val_Acc: 74.019

Epoch 59: Validation loss decreased (0.536238 --> 0.535893).  Saving model ...
	 Train_Loss: 0.5057 Train_Acc: 75.089 Val_Loss: 0.5359  BEST VAL Loss: 0.5359  Val_Acc: 74.445

Epoch 60: Validation loss decreased (0.535893 --> 0.535587).  Saving model ...
	 Train_Loss: 0.5049 Train_Acc: 75.335 Val_Loss: 0.5356  BEST VAL Loss: 0.5356  Val_Acc: 75.299

Epoch 61: Validation loss decreased (0.535587 --> 0.535135).  Saving model ...
	 Train_Loss: 0.5042 Train_Acc: 75.409 Val_Loss: 0.5351  BEST VAL Loss: 0.5351  Val_Acc: 74.147

Epoch 62: Validation loss decreased (0.535135 --> 0.535016).  Saving model ...
	 Train_Loss: 0.5035 Train_Acc: 75.319 Val_Loss: 0.5350  BEST VAL Loss: 0.5350  Val_Acc: 74.104

Epoch 63: Validation loss decreased (0.535016 --> 0.534488).  Saving model ...
	 Train_Loss: 0.5029 Train_Acc: 74.881 Val_Loss: 0.5345  BEST VAL Loss: 0.5345  Val_Acc: 74.531

Epoch 64: Validation loss decreased (0.534488 --> 0.534016).  Saving model ...
	 Train_Loss: 0.5021 Train_Acc: 75.911 Val_Loss: 0.5340  BEST VAL Loss: 0.5340  Val_Acc: 75.256

Epoch 65: Validation loss decreased (0.534016 --> 0.533614).  Saving model ...
	 Train_Loss: 0.5013 Train_Acc: 76.316 Val_Loss: 0.5336  BEST VAL Loss: 0.5336  Val_Acc: 75.683

Epoch 66: Validation loss decreased (0.533614 --> 0.533211).  Saving model ...
	 Train_Loss: 0.5006 Train_Acc: 75.745 Val_Loss: 0.5332  BEST VAL Loss: 0.5332  Val_Acc: 74.573

Epoch 67: Validation loss decreased (0.533211 --> 0.532878).  Saving model ...
	 Train_Loss: 0.4999 Train_Acc: 76.220 Val_Loss: 0.5329  BEST VAL Loss: 0.5329  Val_Acc: 75.341

Epoch 68: Validation loss decreased (0.532878 --> 0.532573).  Saving model ...
	 Train_Loss: 0.4992 Train_Acc: 75.751 Val_Loss: 0.5326  BEST VAL Loss: 0.5326  Val_Acc: 74.019

Epoch 69: Validation loss decreased (0.532573 --> 0.532425).  Saving model ...
	 Train_Loss: 0.4985 Train_Acc: 75.783 Val_Loss: 0.5324  BEST VAL Loss: 0.5324  Val_Acc: 74.915

Epoch 70: Validation loss decreased (0.532425 --> 0.532215).  Saving model ...
	 Train_Loss: 0.4979 Train_Acc: 76.108 Val_Loss: 0.5322  BEST VAL Loss: 0.5322  Val_Acc: 74.872

Epoch 71: Validation loss decreased (0.532215 --> 0.531803).  Saving model ...
	 Train_Loss: 0.4972 Train_Acc: 76.082 Val_Loss: 0.5318  BEST VAL Loss: 0.5318  Val_Acc: 74.659

Epoch 72: Validation loss decreased (0.531803 --> 0.531451).  Saving model ...
	 Train_Loss: 0.4966 Train_Acc: 76.146 Val_Loss: 0.5315  BEST VAL Loss: 0.5315  Val_Acc: 74.829

Epoch 73: Validation loss decreased (0.531451 --> 0.531118).  Saving model ...
	 Train_Loss: 0.4959 Train_Acc: 76.188 Val_Loss: 0.5311  BEST VAL Loss: 0.5311  Val_Acc: 75.555

Epoch 74: Validation loss decreased (0.531118 --> 0.530802).  Saving model ...
	 Train_Loss: 0.4953 Train_Acc: 76.178 Val_Loss: 0.5308  BEST VAL Loss: 0.5308  Val_Acc: 74.531

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.4947 Train_Acc: 75.799 Val_Loss: 0.5308  BEST VAL Loss: 0.5308  Val_Acc: 74.317

Epoch 76: Validation loss decreased (0.530802 --> 0.530338).  Saving model ...
	 Train_Loss: 0.4942 Train_Acc: 75.761 Val_Loss: 0.5303  BEST VAL Loss: 0.5303  Val_Acc: 75.555

Epoch 77: Validation loss decreased (0.530338 --> 0.529998).  Saving model ...
	 Train_Loss: 0.4936 Train_Acc: 76.476 Val_Loss: 0.5300  BEST VAL Loss: 0.5300  Val_Acc: 74.403

Epoch 78: Validation loss decreased (0.529998 --> 0.529754).  Saving model ...
	 Train_Loss: 0.4930 Train_Acc: 76.023 Val_Loss: 0.5298  BEST VAL Loss: 0.5298  Val_Acc: 75.299

Epoch 79: Validation loss decreased (0.529754 --> 0.529292).  Saving model ...
	 Train_Loss: 0.4925 Train_Acc: 76.044 Val_Loss: 0.5293  BEST VAL Loss: 0.5293  Val_Acc: 75.213

Epoch 80: Validation loss decreased (0.529292 --> 0.529053).  Saving model ...
	 Train_Loss: 0.4919 Train_Acc: 76.316 Val_Loss: 0.5291  BEST VAL Loss: 0.5291  Val_Acc: 74.787

Epoch 81: Validation loss decreased (0.529053 --> 0.528736).  Saving model ...
	 Train_Loss: 0.4914 Train_Acc: 76.375 Val_Loss: 0.5287  BEST VAL Loss: 0.5287  Val_Acc: 75.597

Epoch 82: Validation loss decreased (0.528736 --> 0.528439).  Saving model ...
	 Train_Loss: 0.4908 Train_Acc: 76.263 Val_Loss: 0.5284  BEST VAL Loss: 0.5284  Val_Acc: 75.085

Epoch 83: Validation loss decreased (0.528439 --> 0.528259).  Saving model ...
	 Train_Loss: 0.4903 Train_Acc: 76.199 Val_Loss: 0.5283  BEST VAL Loss: 0.5283  Val_Acc: 74.957

Epoch 84: Validation loss decreased (0.528259 --> 0.528092).  Saving model ...
	 Train_Loss: 0.4897 Train_Acc: 76.311 Val_Loss: 0.5281  BEST VAL Loss: 0.5281  Val_Acc: 76.024

Epoch 85: Validation loss decreased (0.528092 --> 0.527838).  Saving model ...
	 Train_Loss: 0.4892 Train_Acc: 76.242 Val_Loss: 0.5278  BEST VAL Loss: 0.5278  Val_Acc: 74.701

Epoch 86: Validation loss decreased (0.527838 --> 0.527501).  Saving model ...
	 Train_Loss: 0.4887 Train_Acc: 76.466 Val_Loss: 0.5275  BEST VAL Loss: 0.5275  Val_Acc: 75.811

Epoch 87: Validation loss decreased (0.527501 --> 0.527449).  Saving model ...
	 Train_Loss: 0.4882 Train_Acc: 76.151 Val_Loss: 0.5274  BEST VAL Loss: 0.5274  Val_Acc: 74.829

Epoch 88: Validation loss decreased (0.527449 --> 0.527109).  Saving model ...
	 Train_Loss: 0.4877 Train_Acc: 77.052 Val_Loss: 0.5271  BEST VAL Loss: 0.5271  Val_Acc: 75.768

Epoch 89: Validation loss decreased (0.527109 --> 0.526916).  Saving model ...
	 Train_Loss: 0.4871 Train_Acc: 76.604 Val_Loss: 0.5269  BEST VAL Loss: 0.5269  Val_Acc: 75.256

Epoch 90: Validation loss decreased (0.526916 --> 0.526651).  Saving model ...
	 Train_Loss: 0.4866 Train_Acc: 76.540 Val_Loss: 0.5267  BEST VAL Loss: 0.5267  Val_Acc: 75.085

Epoch 91: Validation loss decreased (0.526651 --> 0.526467).  Saving model ...
	 Train_Loss: 0.4861 Train_Acc: 76.556 Val_Loss: 0.5265  BEST VAL Loss: 0.5265  Val_Acc: 75.043

Epoch 92: Validation loss decreased (0.526467 --> 0.526213).  Saving model ...
	 Train_Loss: 0.4857 Train_Acc: 76.487 Val_Loss: 0.5262  BEST VAL Loss: 0.5262  Val_Acc: 75.128

Epoch 93: Validation loss decreased (0.526213 --> 0.525956).  Saving model ...
	 Train_Loss: 0.4853 Train_Acc: 76.338 Val_Loss: 0.5260  BEST VAL Loss: 0.5260  Val_Acc: 74.915

Epoch 94: Validation loss decreased (0.525956 --> 0.525823).  Saving model ...
	 Train_Loss: 0.4848 Train_Acc: 76.823 Val_Loss: 0.5258  BEST VAL Loss: 0.5258  Val_Acc: 75.640

Epoch 95: Validation loss decreased (0.525823 --> 0.525624).  Saving model ...
	 Train_Loss: 0.4843 Train_Acc: 76.796 Val_Loss: 0.5256  BEST VAL Loss: 0.5256  Val_Acc: 75.299

Epoch 96: Validation loss decreased (0.525624 --> 0.525488).  Saving model ...
	 Train_Loss: 0.4839 Train_Acc: 76.594 Val_Loss: 0.5255  BEST VAL Loss: 0.5255  Val_Acc: 75.640

Epoch 97: Validation loss decreased (0.525488 --> 0.525318).  Saving model ...
	 Train_Loss: 0.4835 Train_Acc: 76.092 Val_Loss: 0.5253  BEST VAL Loss: 0.5253  Val_Acc: 74.659

Epoch 98: Validation loss did not decrease
	 Train_Loss: 0.4831 Train_Acc: 76.076 Val_Loss: 0.5253  BEST VAL Loss: 0.5253  Val_Acc: 74.061

Epoch 99: Validation loss decreased (0.525318 --> 0.525213).  Saving model ...
	 Train_Loss: 0.4827 Train_Acc: 76.279 Val_Loss: 0.5252  BEST VAL Loss: 0.5252  Val_Acc: 74.915

Flagellin_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.52      0.49      8634
           1       0.54      0.47      0.50     10113

    accuracy                           0.50     18747
   macro avg       0.50      0.50      0.50     18747
weighted avg       0.50      0.50      0.50     18747

Flagellin_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.45      0.50      0.47      1080
           1       0.53      0.48      0.50      1264

    accuracy                           0.49      2344
   macro avg       0.49      0.49      0.49      2344
weighted avg       0.49      0.49      0.49      2344

Flagellin_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.52      0.49      1079
           1       0.54      0.48      0.51      1265

    accuracy                           0.50      2344
   macro avg       0.50      0.50      0.50      2344
weighted avg       0.50      0.50      0.50      2344

              precision    recall  f1-score   support

           0       0.46      0.52      0.49      1079
           1       0.54      0.48      0.51      1265

    accuracy                           0.50      2344
   macro avg       0.50      0.50      0.50      2344
weighted avg       0.50      0.50      0.50      2344

Flagellin_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.40      0.44      4135
           1       0.49      0.57      0.53      4168

    accuracy                           0.49      8303
   macro avg       0.49      0.49      0.48      8303
weighted avg       0.49      0.49      0.48      8303

              precision    recall  f1-score   support

           0       0.48      0.40      0.44      4135
           1       0.49      0.57      0.53      4168

    accuracy                           0.49      8303
   macro avg       0.49      0.49      0.48      8303
weighted avg       0.49      0.49      0.48      8303

completed
