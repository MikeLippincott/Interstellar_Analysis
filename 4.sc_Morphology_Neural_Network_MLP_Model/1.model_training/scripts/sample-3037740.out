[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '12ea7316'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '75ea988f'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '83e0c746'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'c352c676'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: DMSO_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: DMSO_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (49295, 1276)
Number of total missing values across all columns: 71286
Data Subset Is Off
Wells held out for testing: ['I14' 'L20']
Wells to use for training, validation, and testing ['B14' 'C14' 'B15' 'C15' 'J14' 'I15' 'J15' 'L16' 'L17' 'L21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.155847).  Saving model ...
	 Train_Loss: 0.2613 Train_Acc: 89.283 Val_Loss: 0.1558  BEST VAL Loss: 0.1558  Val_Acc: 94.126

Epoch 1: Validation loss decreased (0.155847 --> 0.132388).  Saving model ...
	 Train_Loss: 0.2038 Train_Acc: 94.028 Val_Loss: 0.1324  BEST VAL Loss: 0.1324  Val_Acc: 96.092

Epoch 2: Validation loss decreased (0.132388 --> 0.117129).  Saving model ...
	 Train_Loss: 0.1737 Train_Acc: 95.300 Val_Loss: 0.1171  BEST VAL Loss: 0.1171  Val_Acc: 97.209

Epoch 3: Validation loss decreased (0.117129 --> 0.104909).  Saving model ...
	 Train_Loss: 0.1550 Train_Acc: 95.983 Val_Loss: 0.1049  BEST VAL Loss: 0.1049  Val_Acc: 97.184

Epoch 4: Validation loss decreased (0.104909 --> 0.097232).  Saving model ...
	 Train_Loss: 0.1414 Train_Acc: 96.495 Val_Loss: 0.0972  BEST VAL Loss: 0.0972  Val_Acc: 97.112

Epoch 5: Validation loss decreased (0.097232 --> 0.092596).  Saving model ...
	 Train_Loss: 0.1319 Train_Acc: 96.401 Val_Loss: 0.0926  BEST VAL Loss: 0.0926  Val_Acc: 97.136

Epoch 6: Validation loss decreased (0.092596 --> 0.090329).  Saving model ...
	 Train_Loss: 0.1238 Train_Acc: 96.978 Val_Loss: 0.0903  BEST VAL Loss: 0.0903  Val_Acc: 97.379

Epoch 7: Validation loss decreased (0.090329 --> 0.087780).  Saving model ...
	 Train_Loss: 0.1178 Train_Acc: 96.835 Val_Loss: 0.0878  BEST VAL Loss: 0.0878  Val_Acc: 97.694

Epoch 8: Validation loss decreased (0.087780 --> 0.084489).  Saving model ...
	 Train_Loss: 0.1125 Train_Acc: 97.005 Val_Loss: 0.0845  BEST VAL Loss: 0.0845  Val_Acc: 97.646

Epoch 9: Validation loss decreased (0.084489 --> 0.082169).  Saving model ...
	 Train_Loss: 0.1083 Train_Acc: 97.069 Val_Loss: 0.0822  BEST VAL Loss: 0.0822  Val_Acc: 97.403

Epoch 10: Validation loss decreased (0.082169 --> 0.081766).  Saving model ...
	 Train_Loss: 0.1047 Train_Acc: 97.117 Val_Loss: 0.0818  BEST VAL Loss: 0.0818  Val_Acc: 97.961

Epoch 11: Validation loss decreased (0.081766 --> 0.080523).  Saving model ...
	 Train_Loss: 0.1013 Train_Acc: 97.254 Val_Loss: 0.0805  BEST VAL Loss: 0.0805  Val_Acc: 97.670

Epoch 12: Validation loss decreased (0.080523 --> 0.079454).  Saving model ...
	 Train_Loss: 0.0978 Train_Acc: 97.573 Val_Loss: 0.0795  BEST VAL Loss: 0.0795  Val_Acc: 97.694

Epoch 13: Validation loss decreased (0.079454 --> 0.078271).  Saving model ...
	 Train_Loss: 0.0950 Train_Acc: 97.478 Val_Loss: 0.0783  BEST VAL Loss: 0.0783  Val_Acc: 97.937

Epoch 14: Validation loss decreased (0.078271 --> 0.077997).  Saving model ...
	 Train_Loss: 0.0928 Train_Acc: 97.272 Val_Loss: 0.0780  BEST VAL Loss: 0.0780  Val_Acc: 97.913

Epoch 15: Validation loss did not decrease
	 Train_Loss: 0.0904 Train_Acc: 97.609 Val_Loss: 0.0781  BEST VAL Loss: 0.0780  Val_Acc: 97.913

Epoch 16: Validation loss decreased (0.077997 --> 0.077797).  Saving model ...
	 Train_Loss: 0.0881 Train_Acc: 97.736 Val_Loss: 0.0778  BEST VAL Loss: 0.0778  Val_Acc: 97.791

Epoch 17: Validation loss decreased (0.077797 --> 0.077289).  Saving model ...
	 Train_Loss: 0.0862 Train_Acc: 97.709 Val_Loss: 0.0773  BEST VAL Loss: 0.0773  Val_Acc: 97.888

Epoch 18: Validation loss did not decrease
	 Train_Loss: 0.0844 Train_Acc: 97.657 Val_Loss: 0.0773  BEST VAL Loss: 0.0773  Val_Acc: 97.791

Epoch 19: Validation loss decreased (0.077289 --> 0.076518).  Saving model ...
	 Train_Loss: 0.0826 Train_Acc: 97.745 Val_Loss: 0.0765  BEST VAL Loss: 0.0765  Val_Acc: 98.058

Epoch 20: Validation loss did not decrease
	 Train_Loss: 0.0811 Train_Acc: 97.782 Val_Loss: 0.0765  BEST VAL Loss: 0.0765  Val_Acc: 97.937

Epoch 21: Validation loss decreased (0.076518 --> 0.075681).  Saving model ...
	 Train_Loss: 0.0796 Train_Acc: 97.852 Val_Loss: 0.0757  BEST VAL Loss: 0.0757  Val_Acc: 98.277

Epoch 22: Validation loss decreased (0.075681 --> 0.075286).  Saving model ...
	 Train_Loss: 0.0783 Train_Acc: 97.806 Val_Loss: 0.0753  BEST VAL Loss: 0.0753  Val_Acc: 97.864

Epoch 23: Validation loss decreased (0.075286 --> 0.074319).  Saving model ...
	 Train_Loss: 0.0770 Train_Acc: 97.946 Val_Loss: 0.0743  BEST VAL Loss: 0.0743  Val_Acc: 98.325

Epoch 24: Validation loss decreased (0.074319 --> 0.074120).  Saving model ...
	 Train_Loss: 0.0759 Train_Acc: 97.833 Val_Loss: 0.0741  BEST VAL Loss: 0.0741  Val_Acc: 98.180

Epoch 25: Validation loss decreased (0.074120 --> 0.073682).  Saving model ...
	 Train_Loss: 0.0748 Train_Acc: 97.909 Val_Loss: 0.0737  BEST VAL Loss: 0.0737  Val_Acc: 97.888

Epoch 26: Validation loss decreased (0.073682 --> 0.072740).  Saving model ...
	 Train_Loss: 0.0737 Train_Acc: 97.882 Val_Loss: 0.0727  BEST VAL Loss: 0.0727  Val_Acc: 98.252

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.0727 Train_Acc: 97.855 Val_Loss: 0.0730  BEST VAL Loss: 0.0727  Val_Acc: 97.888

Epoch 28: Validation loss decreased (0.072740 --> 0.072547).  Saving model ...
	 Train_Loss: 0.0717 Train_Acc: 98.034 Val_Loss: 0.0725  BEST VAL Loss: 0.0725  Val_Acc: 98.034

Epoch 29: Validation loss decreased (0.072547 --> 0.072095).  Saving model ...
	 Train_Loss: 0.0709 Train_Acc: 98.000 Val_Loss: 0.0721  BEST VAL Loss: 0.0721  Val_Acc: 97.937

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.0700 Train_Acc: 97.958 Val_Loss: 0.0725  BEST VAL Loss: 0.0721  Val_Acc: 97.816

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.0693 Train_Acc: 97.882 Val_Loss: 0.0721  BEST VAL Loss: 0.0721  Val_Acc: 98.034

Epoch 32: Validation loss decreased (0.072095 --> 0.071871).  Saving model ...
	 Train_Loss: 0.0684 Train_Acc: 98.192 Val_Loss: 0.0719  BEST VAL Loss: 0.0719  Val_Acc: 98.010

Epoch 33: Validation loss decreased (0.071871 --> 0.071559).  Saving model ...
	 Train_Loss: 0.0677 Train_Acc: 97.943 Val_Loss: 0.0716  BEST VAL Loss: 0.0716  Val_Acc: 98.228

Epoch 34: Validation loss decreased (0.071559 --> 0.071555).  Saving model ...
	 Train_Loss: 0.0670 Train_Acc: 98.122 Val_Loss: 0.0716  BEST VAL Loss: 0.0716  Val_Acc: 97.937

Epoch 35: Validation loss decreased (0.071555 --> 0.071146).  Saving model ...
	 Train_Loss: 0.0663 Train_Acc: 98.049 Val_Loss: 0.0711  BEST VAL Loss: 0.0711  Val_Acc: 97.961

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.0656 Train_Acc: 98.116 Val_Loss: 0.0713  BEST VAL Loss: 0.0711  Val_Acc: 98.107

Epoch 37: Validation loss decreased (0.071146 --> 0.071017).  Saving model ...
	 Train_Loss: 0.0650 Train_Acc: 98.195 Val_Loss: 0.0710  BEST VAL Loss: 0.0710  Val_Acc: 98.107

Epoch 38: Validation loss decreased (0.071017 --> 0.070674).  Saving model ...
	 Train_Loss: 0.0643 Train_Acc: 98.116 Val_Loss: 0.0707  BEST VAL Loss: 0.0707  Val_Acc: 98.107

Epoch 39: Validation loss decreased (0.070674 --> 0.070604).  Saving model ...
	 Train_Loss: 0.0637 Train_Acc: 98.210 Val_Loss: 0.0706  BEST VAL Loss: 0.0706  Val_Acc: 98.204

Epoch 40: Validation loss decreased (0.070604 --> 0.070557).  Saving model ...
	 Train_Loss: 0.0631 Train_Acc: 98.104 Val_Loss: 0.0706  BEST VAL Loss: 0.0706  Val_Acc: 97.816

Epoch 41: Validation loss decreased (0.070557 --> 0.070535).  Saving model ...
	 Train_Loss: 0.0626 Train_Acc: 98.094 Val_Loss: 0.0705  BEST VAL Loss: 0.0705  Val_Acc: 97.985

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.0620 Train_Acc: 98.237 Val_Loss: 0.0709  BEST VAL Loss: 0.0705  Val_Acc: 98.083

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.0614 Train_Acc: 98.231 Val_Loss: 0.0716  BEST VAL Loss: 0.0705  Val_Acc: 98.155

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.0609 Train_Acc: 98.143 Val_Loss: 0.0716  BEST VAL Loss: 0.0705  Val_Acc: 98.204

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.0604 Train_Acc: 98.170 Val_Loss: 0.0717  BEST VAL Loss: 0.0705  Val_Acc: 98.301

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.0599 Train_Acc: 98.237 Val_Loss: 0.0713  BEST VAL Loss: 0.0705  Val_Acc: 98.252

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.0595 Train_Acc: 98.046 Val_Loss: 0.0715  BEST VAL Loss: 0.0705  Val_Acc: 98.228

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.0590 Train_Acc: 98.246 Val_Loss: 0.0713  BEST VAL Loss: 0.0705  Val_Acc: 98.107

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.0586 Train_Acc: 98.234 Val_Loss: 0.0716  BEST VAL Loss: 0.0705  Val_Acc: 98.083

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.0582 Train_Acc: 98.155 Val_Loss: 0.0716  BEST VAL Loss: 0.0705  Val_Acc: 98.058

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.0577 Train_Acc: 98.371 Val_Loss: 0.0719  BEST VAL Loss: 0.0705  Val_Acc: 97.888

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.0573 Train_Acc: 98.264 Val_Loss: 0.0718  BEST VAL Loss: 0.0705  Val_Acc: 98.277

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.0569 Train_Acc: 98.258 Val_Loss: 0.0720  BEST VAL Loss: 0.0705  Val_Acc: 98.083

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.0565 Train_Acc: 98.173 Val_Loss: 0.0719  BEST VAL Loss: 0.0705  Val_Acc: 98.325

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.0561 Train_Acc: 98.228 Val_Loss: 0.0721  BEST VAL Loss: 0.0705  Val_Acc: 98.010

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.0558 Train_Acc: 98.113 Val_Loss: 0.0723  BEST VAL Loss: 0.0705  Val_Acc: 98.180

Epoch 57: Validation loss did not decrease
Early stopped at epoch : 57
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.75      0.75      0.75     24644
           1       0.25      0.25      0.25      8312

    accuracy                           0.62     32956
   macro avg       0.50      0.50      0.50     32956
weighted avg       0.62      0.62      0.62     32956

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.75      0.75      0.75      3081
           1       0.25      0.25      0.25      1039

    accuracy                           0.62      4120
   macro avg       0.50      0.50      0.50      4120
weighted avg       0.62      0.62      0.62      4120

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.74      0.75      0.75      3081
           1       0.24      0.23      0.23      1039

    accuracy                           0.62      4120
   macro avg       0.49      0.49      0.49      4120
weighted avg       0.62      0.62      0.62      4120

              precision    recall  f1-score   support

           0       0.74      0.75      0.75      3081
           1       0.24      0.23      0.23      1039

    accuracy                           0.62      4120
   macro avg       0.49      0.49      0.49      4120
weighted avg       0.62      0.62      0.62      4120

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.60      0.61      0.60      4837
           1       0.41      0.40      0.40      3262

    accuracy                           0.52      8099
   macro avg       0.50      0.50      0.50      8099
weighted avg       0.52      0.52      0.52      8099

              precision    recall  f1-score   support

           0       0.60      0.61      0.60      4837
           1       0.41      0.40      0.40      3262

    accuracy                           0.52      8099
   macro avg       0.50      0.50      0.50      8099
weighted avg       0.52      0.52      0.52      8099

completed
