[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '2efb0b1d'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '42934171'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '5e7113e2'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'decf3ae3'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Flagellin_0.100_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_100.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (255350, 1270)
Number of total missing values across all columns: 510700
Data Subset Is Off
Wells held out for testing: ['J08' 'L10']
Wells to use for training, validation, and testing ['J02' 'J03' 'J09' 'L05' 'L11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.502916).  Saving model ...
	 Train_Loss: 0.5727 Train_Acc: 70.744 Val_Loss: 0.5029  BEST VAL Loss: 0.5029  Val_Acc: 75.310

Epoch 1: Validation loss decreased (0.502916 --> 0.487800).  Saving model ...
	 Train_Loss: 0.5396 Train_Acc: 74.445 Val_Loss: 0.4878  BEST VAL Loss: 0.4878  Val_Acc: 76.390

Epoch 2: Validation loss decreased (0.487800 --> 0.479628).  Saving model ...
	 Train_Loss: 0.5240 Train_Acc: 75.326 Val_Loss: 0.4796  BEST VAL Loss: 0.4796  Val_Acc: 77.335

Epoch 3: Validation loss decreased (0.479628 --> 0.475006).  Saving model ...
	 Train_Loss: 0.5133 Train_Acc: 76.018 Val_Loss: 0.4750  BEST VAL Loss: 0.4750  Val_Acc: 77.135

Epoch 4: Validation loss decreased (0.475006 --> 0.471913).  Saving model ...
	 Train_Loss: 0.5063 Train_Acc: 76.142 Val_Loss: 0.4719  BEST VAL Loss: 0.4719  Val_Acc: 77.173

Epoch 5: Validation loss decreased (0.471913 --> 0.468625).  Saving model ...
	 Train_Loss: 0.5010 Train_Acc: 76.343 Val_Loss: 0.4686  BEST VAL Loss: 0.4686  Val_Acc: 77.897

Epoch 6: Validation loss decreased (0.468625 --> 0.465803).  Saving model ...
	 Train_Loss: 0.4966 Train_Acc: 76.743 Val_Loss: 0.4658  BEST VAL Loss: 0.4658  Val_Acc: 77.988

Epoch 7: Validation loss decreased (0.465803 --> 0.463206).  Saving model ...
	 Train_Loss: 0.4927 Train_Acc: 76.844 Val_Loss: 0.4632  BEST VAL Loss: 0.4632  Val_Acc: 77.907

Epoch 8: Validation loss decreased (0.463206 --> 0.460628).  Saving model ...
	 Train_Loss: 0.4894 Train_Acc: 77.054 Val_Loss: 0.4606  BEST VAL Loss: 0.4606  Val_Acc: 78.458

Epoch 9: Validation loss decreased (0.460628 --> 0.458153).  Saving model ...
	 Train_Loss: 0.4865 Train_Acc: 77.216 Val_Loss: 0.4582  BEST VAL Loss: 0.4582  Val_Acc: 78.436

Epoch 10: Validation loss decreased (0.458153 --> 0.456567).  Saving model ...
	 Train_Loss: 0.4840 Train_Acc: 77.310 Val_Loss: 0.4566  BEST VAL Loss: 0.4566  Val_Acc: 78.247

Epoch 11: Validation loss decreased (0.456567 --> 0.455038).  Saving model ...
	 Train_Loss: 0.4817 Train_Acc: 77.468 Val_Loss: 0.4550  BEST VAL Loss: 0.4550  Val_Acc: 78.442

Epoch 12: Validation loss decreased (0.455038 --> 0.454478).  Saving model ...
	 Train_Loss: 0.4796 Train_Acc: 77.562 Val_Loss: 0.4545  BEST VAL Loss: 0.4545  Val_Acc: 78.345

Epoch 13: Validation loss decreased (0.454478 --> 0.453292).  Saving model ...
	 Train_Loss: 0.4777 Train_Acc: 77.480 Val_Loss: 0.4533  BEST VAL Loss: 0.4533  Val_Acc: 78.652

Epoch 14: Validation loss decreased (0.453292 --> 0.451676).  Saving model ...
	 Train_Loss: 0.4759 Train_Acc: 77.673 Val_Loss: 0.4517  BEST VAL Loss: 0.4517  Val_Acc: 79.187

Epoch 15: Validation loss decreased (0.451676 --> 0.450262).  Saving model ...
	 Train_Loss: 0.4741 Train_Acc: 77.907 Val_Loss: 0.4503  BEST VAL Loss: 0.4503  Val_Acc: 78.804

Epoch 16: Validation loss decreased (0.450262 --> 0.450203).  Saving model ...
	 Train_Loss: 0.4726 Train_Acc: 77.843 Val_Loss: 0.4502  BEST VAL Loss: 0.4502  Val_Acc: 77.772

Epoch 17: Validation loss decreased (0.450203 --> 0.449058).  Saving model ...
	 Train_Loss: 0.4712 Train_Acc: 77.701 Val_Loss: 0.4491  BEST VAL Loss: 0.4491  Val_Acc: 79.516

Epoch 18: Validation loss decreased (0.449058 --> 0.448271).  Saving model ...
	 Train_Loss: 0.4698 Train_Acc: 77.934 Val_Loss: 0.4483  BEST VAL Loss: 0.4483  Val_Acc: 78.177

Epoch 19: Validation loss decreased (0.448271 --> 0.447175).  Saving model ...
	 Train_Loss: 0.4685 Train_Acc: 78.056 Val_Loss: 0.4472  BEST VAL Loss: 0.4472  Val_Acc: 78.976

Epoch 20: Validation loss decreased (0.447175 --> 0.446545).  Saving model ...
	 Train_Loss: 0.4672 Train_Acc: 78.093 Val_Loss: 0.4465  BEST VAL Loss: 0.4465  Val_Acc: 78.760

Epoch 21: Validation loss decreased (0.446545 --> 0.445426).  Saving model ...
	 Train_Loss: 0.4660 Train_Acc: 78.040 Val_Loss: 0.4454  BEST VAL Loss: 0.4454  Val_Acc: 79.322

Epoch 22: Validation loss decreased (0.445426 --> 0.445076).  Saving model ...
	 Train_Loss: 0.4649 Train_Acc: 78.259 Val_Loss: 0.4451  BEST VAL Loss: 0.4451  Val_Acc: 78.895

Epoch 23: Validation loss decreased (0.445076 --> 0.444562).  Saving model ...
	 Train_Loss: 0.4640 Train_Acc: 78.199 Val_Loss: 0.4446  BEST VAL Loss: 0.4446  Val_Acc: 78.760

Epoch 24: Validation loss decreased (0.444562 --> 0.443688).  Saving model ...
	 Train_Loss: 0.4631 Train_Acc: 78.162 Val_Loss: 0.4437  BEST VAL Loss: 0.4437  Val_Acc: 79.279

Epoch 25: Validation loss decreased (0.443688 --> 0.443055).  Saving model ...
	 Train_Loss: 0.4620 Train_Acc: 78.319 Val_Loss: 0.4431  BEST VAL Loss: 0.4431  Val_Acc: 79.111

Epoch 26: Validation loss decreased (0.443055 --> 0.442320).  Saving model ...
	 Train_Loss: 0.4611 Train_Acc: 78.266 Val_Loss: 0.4423  BEST VAL Loss: 0.4423  Val_Acc: 79.138

Epoch 27: Validation loss decreased (0.442320 --> 0.441558).  Saving model ...
	 Train_Loss: 0.4602 Train_Acc: 78.322 Val_Loss: 0.4416  BEST VAL Loss: 0.4416  Val_Acc: 79.289

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.4593 Train_Acc: 78.435 Val_Loss: 0.4417  BEST VAL Loss: 0.4416  Val_Acc: 78.069

Epoch 29: Validation loss decreased (0.441558 --> 0.440944).  Saving model ...
	 Train_Loss: 0.4586 Train_Acc: 78.278 Val_Loss: 0.4409  BEST VAL Loss: 0.4409  Val_Acc: 79.554

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.4577 Train_Acc: 78.465 Val_Loss: 0.4410  BEST VAL Loss: 0.4409  Val_Acc: 78.123

Epoch 31: Validation loss decreased (0.440944 --> 0.440757).  Saving model ...
	 Train_Loss: 0.4571 Train_Acc: 78.211 Val_Loss: 0.4408  BEST VAL Loss: 0.4408  Val_Acc: 78.382

Epoch 32: Validation loss decreased (0.440757 --> 0.440693).  Saving model ...
	 Train_Loss: 0.4564 Train_Acc: 78.336 Val_Loss: 0.4407  BEST VAL Loss: 0.4407  Val_Acc: 77.875

Epoch 33: Validation loss decreased (0.440693 --> 0.440334).  Saving model ...
	 Train_Loss: 0.4557 Train_Acc: 78.474 Val_Loss: 0.4403  BEST VAL Loss: 0.4403  Val_Acc: 79.133

Epoch 34: Validation loss decreased (0.440334 --> 0.439876).  Saving model ...
	 Train_Loss: 0.4550 Train_Acc: 78.453 Val_Loss: 0.4399  BEST VAL Loss: 0.4399  Val_Acc: 79.381

Epoch 35: Validation loss decreased (0.439876 --> 0.439354).  Saving model ...
	 Train_Loss: 0.4543 Train_Acc: 78.524 Val_Loss: 0.4394  BEST VAL Loss: 0.4394  Val_Acc: 79.273

Epoch 36: Validation loss decreased (0.439354 --> 0.438884).  Saving model ...
	 Train_Loss: 0.4537 Train_Acc: 78.403 Val_Loss: 0.4389  BEST VAL Loss: 0.4389  Val_Acc: 79.338

Epoch 37: Validation loss decreased (0.438884 --> 0.438499).  Saving model ...
	 Train_Loss: 0.4531 Train_Acc: 78.477 Val_Loss: 0.4385  BEST VAL Loss: 0.4385  Val_Acc: 79.435

Epoch 38: Validation loss decreased (0.438499 --> 0.437958).  Saving model ...
	 Train_Loss: 0.4524 Train_Acc: 78.648 Val_Loss: 0.4380  BEST VAL Loss: 0.4380  Val_Acc: 79.473

Epoch 39: Validation loss decreased (0.437958 --> 0.437638).  Saving model ...
	 Train_Loss: 0.4519 Train_Acc: 78.617 Val_Loss: 0.4376  BEST VAL Loss: 0.4376  Val_Acc: 79.122

Epoch 40: Validation loss decreased (0.437638 --> 0.437370).  Saving model ...
	 Train_Loss: 0.4513 Train_Acc: 78.601 Val_Loss: 0.4374  BEST VAL Loss: 0.4374  Val_Acc: 79.603

Epoch 41: Validation loss decreased (0.437370 --> 0.436939).  Saving model ...
	 Train_Loss: 0.4507 Train_Acc: 78.579 Val_Loss: 0.4369  BEST VAL Loss: 0.4369  Val_Acc: 79.246

Epoch 42: Validation loss decreased (0.436939 --> 0.436576).  Saving model ...
	 Train_Loss: 0.4502 Train_Acc: 78.576 Val_Loss: 0.4366  BEST VAL Loss: 0.4366  Val_Acc: 79.495

Epoch 43: Validation loss decreased (0.436576 --> 0.436252).  Saving model ...
	 Train_Loss: 0.4496 Train_Acc: 78.766 Val_Loss: 0.4363  BEST VAL Loss: 0.4363  Val_Acc: 79.473

Epoch 44: Validation loss decreased (0.436252 --> 0.435905).  Saving model ...
	 Train_Loss: 0.4491 Train_Acc: 78.649 Val_Loss: 0.4359  BEST VAL Loss: 0.4359  Val_Acc: 79.084

Epoch 45: Validation loss decreased (0.435905 --> 0.435549).  Saving model ...
	 Train_Loss: 0.4486 Train_Acc: 78.602 Val_Loss: 0.4355  BEST VAL Loss: 0.4355  Val_Acc: 79.430

Epoch 46: Validation loss decreased (0.435549 --> 0.435112).  Saving model ...
	 Train_Loss: 0.4482 Train_Acc: 78.671 Val_Loss: 0.4351  BEST VAL Loss: 0.4351  Val_Acc: 79.581

Epoch 47: Validation loss decreased (0.435112 --> 0.434612).  Saving model ...
	 Train_Loss: 0.4478 Train_Acc: 78.683 Val_Loss: 0.4346  BEST VAL Loss: 0.4346  Val_Acc: 79.808

Epoch 48: Validation loss decreased (0.434612 --> 0.434547).  Saving model ...
	 Train_Loss: 0.4473 Train_Acc: 78.773 Val_Loss: 0.4345  BEST VAL Loss: 0.4345  Val_Acc: 78.480

Epoch 49: Validation loss decreased (0.434547 --> 0.434211).  Saving model ...
	 Train_Loss: 0.4468 Train_Acc: 78.877 Val_Loss: 0.4342  BEST VAL Loss: 0.4342  Val_Acc: 79.522

Epoch 50: Validation loss decreased (0.434211 --> 0.433875).  Saving model ...
	 Train_Loss: 0.4464 Train_Acc: 78.760 Val_Loss: 0.4339  BEST VAL Loss: 0.4339  Val_Acc: 79.667

Epoch 51: Validation loss decreased (0.433875 --> 0.433604).  Saving model ...
	 Train_Loss: 0.4459 Train_Acc: 78.820 Val_Loss: 0.4336  BEST VAL Loss: 0.4336  Val_Acc: 79.554

Epoch 52: Validation loss decreased (0.433604 --> 0.433327).  Saving model ...
	 Train_Loss: 0.4455 Train_Acc: 78.771 Val_Loss: 0.4333  BEST VAL Loss: 0.4333  Val_Acc: 79.133

Epoch 53: Validation loss decreased (0.433327 --> 0.433179).  Saving model ...
	 Train_Loss: 0.4451 Train_Acc: 78.616 Val_Loss: 0.4332  BEST VAL Loss: 0.4332  Val_Acc: 79.182

Epoch 54: Validation loss decreased (0.433179 --> 0.432747).  Saving model ...
	 Train_Loss: 0.4448 Train_Acc: 78.752 Val_Loss: 0.4327  BEST VAL Loss: 0.4327  Val_Acc: 80.094

Epoch 55: Validation loss decreased (0.432747 --> 0.432580).  Saving model ...
	 Train_Loss: 0.4444 Train_Acc: 78.771 Val_Loss: 0.4326  BEST VAL Loss: 0.4326  Val_Acc: 79.192

Epoch 56: Validation loss decreased (0.432580 --> 0.432449).  Saving model ...
	 Train_Loss: 0.4440 Train_Acc: 78.937 Val_Loss: 0.4324  BEST VAL Loss: 0.4324  Val_Acc: 79.397

Epoch 57: Validation loss decreased (0.432449 --> 0.432238).  Saving model ...
	 Train_Loss: 0.4437 Train_Acc: 78.862 Val_Loss: 0.4322  BEST VAL Loss: 0.4322  Val_Acc: 79.300

Epoch 58: Validation loss decreased (0.432238 --> 0.432021).  Saving model ...
	 Train_Loss: 0.4433 Train_Acc: 78.935 Val_Loss: 0.4320  BEST VAL Loss: 0.4320  Val_Acc: 79.662

Epoch 59: Validation loss decreased (0.432021 --> 0.431722).  Saving model ...
	 Train_Loss: 0.4430 Train_Acc: 78.825 Val_Loss: 0.4317  BEST VAL Loss: 0.4317  Val_Acc: 79.883

Epoch 60: Validation loss decreased (0.431722 --> 0.431558).  Saving model ...
	 Train_Loss: 0.4426 Train_Acc: 78.861 Val_Loss: 0.4316  BEST VAL Loss: 0.4316  Val_Acc: 79.246

Epoch 61: Validation loss decreased (0.431558 --> 0.431442).  Saving model ...
	 Train_Loss: 0.4423 Train_Acc: 78.789 Val_Loss: 0.4314  BEST VAL Loss: 0.4314  Val_Acc: 79.289

Epoch 62: Validation loss decreased (0.431442 --> 0.431193).  Saving model ...
	 Train_Loss: 0.4419 Train_Acc: 78.926 Val_Loss: 0.4312  BEST VAL Loss: 0.4312  Val_Acc: 79.673

Epoch 63: Validation loss decreased (0.431193 --> 0.431056).  Saving model ...
	 Train_Loss: 0.4416 Train_Acc: 78.947 Val_Loss: 0.4311  BEST VAL Loss: 0.4311  Val_Acc: 78.933

Epoch 64: Validation loss decreased (0.431056 --> 0.430786).  Saving model ...
	 Train_Loss: 0.4412 Train_Acc: 78.960 Val_Loss: 0.4308  BEST VAL Loss: 0.4308  Val_Acc: 79.500

Epoch 65: Validation loss decreased (0.430786 --> 0.430663).  Saving model ...
	 Train_Loss: 0.4409 Train_Acc: 78.992 Val_Loss: 0.4307  BEST VAL Loss: 0.4307  Val_Acc: 79.397

Epoch 66: Validation loss decreased (0.430663 --> 0.430407).  Saving model ...
	 Train_Loss: 0.4406 Train_Acc: 79.056 Val_Loss: 0.4304  BEST VAL Loss: 0.4304  Val_Acc: 79.775

Epoch 67: Validation loss decreased (0.430407 --> 0.430208).  Saving model ...
	 Train_Loss: 0.4403 Train_Acc: 79.086 Val_Loss: 0.4302  BEST VAL Loss: 0.4302  Val_Acc: 80.013

Epoch 68: Validation loss decreased (0.430208 --> 0.429920).  Saving model ...
	 Train_Loss: 0.4400 Train_Acc: 78.916 Val_Loss: 0.4299  BEST VAL Loss: 0.4299  Val_Acc: 79.711

Epoch 69: Validation loss decreased (0.429920 --> 0.429721).  Saving model ...
	 Train_Loss: 0.4397 Train_Acc: 78.990 Val_Loss: 0.4297  BEST VAL Loss: 0.4297  Val_Acc: 79.954

Epoch 70: Validation loss decreased (0.429721 --> 0.429541).  Saving model ...
	 Train_Loss: 0.4394 Train_Acc: 78.918 Val_Loss: 0.4295  BEST VAL Loss: 0.4295  Val_Acc: 79.759

Epoch 71: Validation loss decreased (0.429541 --> 0.429289).  Saving model ...
	 Train_Loss: 0.4391 Train_Acc: 79.194 Val_Loss: 0.4293  BEST VAL Loss: 0.4293  Val_Acc: 79.748

Epoch 72: Validation loss decreased (0.429289 --> 0.429122).  Saving model ...
	 Train_Loss: 0.4388 Train_Acc: 79.031 Val_Loss: 0.4291  BEST VAL Loss: 0.4291  Val_Acc: 80.062

Epoch 73: Validation loss decreased (0.429122 --> 0.428982).  Saving model ...
	 Train_Loss: 0.4385 Train_Acc: 78.972 Val_Loss: 0.4290  BEST VAL Loss: 0.4290  Val_Acc: 79.797

Epoch 74: Validation loss decreased (0.428982 --> 0.428829).  Saving model ...
	 Train_Loss: 0.4382 Train_Acc: 79.038 Val_Loss: 0.4288  BEST VAL Loss: 0.4288  Val_Acc: 80.045

Epoch 75: Validation loss decreased (0.428829 --> 0.428766).  Saving model ...
	 Train_Loss: 0.4380 Train_Acc: 78.923 Val_Loss: 0.4288  BEST VAL Loss: 0.4288  Val_Acc: 79.349

Epoch 76: Validation loss decreased (0.428766 --> 0.428549).  Saving model ...
	 Train_Loss: 0.4377 Train_Acc: 78.993 Val_Loss: 0.4285  BEST VAL Loss: 0.4285  Val_Acc: 79.910

Epoch 77: Validation loss decreased (0.428549 --> 0.428389).  Saving model ...
	 Train_Loss: 0.4374 Train_Acc: 78.966 Val_Loss: 0.4284  BEST VAL Loss: 0.4284  Val_Acc: 79.408

Epoch 78: Validation loss decreased (0.428389 --> 0.428282).  Saving model ...
	 Train_Loss: 0.4372 Train_Acc: 78.952 Val_Loss: 0.4283  BEST VAL Loss: 0.4283  Val_Acc: 79.840

Epoch 79: Validation loss decreased (0.428282 --> 0.428086).  Saving model ...
	 Train_Loss: 0.4370 Train_Acc: 79.100 Val_Loss: 0.4281  BEST VAL Loss: 0.4281  Val_Acc: 79.781

Epoch 80: Validation loss decreased (0.428086 --> 0.428033).  Saving model ...
	 Train_Loss: 0.4367 Train_Acc: 79.045 Val_Loss: 0.4280  BEST VAL Loss: 0.4280  Val_Acc: 78.496

Epoch 81: Validation loss decreased (0.428033 --> 0.427926).  Saving model ...
	 Train_Loss: 0.4365 Train_Acc: 79.202 Val_Loss: 0.4279  BEST VAL Loss: 0.4279  Val_Acc: 79.748

Epoch 82: Validation loss decreased (0.427926 --> 0.427881).  Saving model ...
	 Train_Loss: 0.4362 Train_Acc: 79.060 Val_Loss: 0.4279  BEST VAL Loss: 0.4279  Val_Acc: 79.387

Epoch 83: Validation loss decreased (0.427881 --> 0.427763).  Saving model ...
	 Train_Loss: 0.4360 Train_Acc: 79.007 Val_Loss: 0.4278  BEST VAL Loss: 0.4278  Val_Acc: 79.257

Epoch 84: Validation loss decreased (0.427763 --> 0.427665).  Saving model ...
	 Train_Loss: 0.4358 Train_Acc: 78.982 Val_Loss: 0.4277  BEST VAL Loss: 0.4277  Val_Acc: 79.500

Epoch 85: Validation loss decreased (0.427665 --> 0.427615).  Saving model ...
	 Train_Loss: 0.4356 Train_Acc: 79.099 Val_Loss: 0.4276  BEST VAL Loss: 0.4276  Val_Acc: 78.577

Epoch 86: Validation loss decreased (0.427615 --> 0.427438).  Saving model ...
	 Train_Loss: 0.4353 Train_Acc: 79.350 Val_Loss: 0.4274  BEST VAL Loss: 0.4274  Val_Acc: 79.581

Epoch 87: Validation loss decreased (0.427438 --> 0.427302).  Saving model ...
	 Train_Loss: 0.4350 Train_Acc: 79.272 Val_Loss: 0.4273  BEST VAL Loss: 0.4273  Val_Acc: 79.333

Epoch 88: Validation loss decreased (0.427302 --> 0.427217).  Saving model ...
	 Train_Loss: 0.4348 Train_Acc: 79.066 Val_Loss: 0.4272  BEST VAL Loss: 0.4272  Val_Acc: 79.192

Epoch 89: Validation loss decreased (0.427217 --> 0.427149).  Saving model ...
	 Train_Loss: 0.4346 Train_Acc: 79.267 Val_Loss: 0.4271  BEST VAL Loss: 0.4271  Val_Acc: 79.419

Epoch 90: Validation loss decreased (0.427149 --> 0.426987).  Saving model ...
	 Train_Loss: 0.4344 Train_Acc: 79.128 Val_Loss: 0.4270  BEST VAL Loss: 0.4270  Val_Acc: 79.792

Epoch 91: Validation loss decreased (0.426987 --> 0.426813).  Saving model ...
	 Train_Loss: 0.4342 Train_Acc: 79.128 Val_Loss: 0.4268  BEST VAL Loss: 0.4268  Val_Acc: 80.083

Epoch 92: Validation loss decreased (0.426813 --> 0.426700).  Saving model ...
	 Train_Loss: 0.4340 Train_Acc: 79.161 Val_Loss: 0.4267  BEST VAL Loss: 0.4267  Val_Acc: 79.889

Epoch 93: Validation loss decreased (0.426700 --> 0.426589).  Saving model ...
	 Train_Loss: 0.4338 Train_Acc: 79.257 Val_Loss: 0.4266  BEST VAL Loss: 0.4266  Val_Acc: 79.646

Epoch 94: Validation loss decreased (0.426589 --> 0.426548).  Saving model ...
	 Train_Loss: 0.4336 Train_Acc: 79.266 Val_Loss: 0.4265  BEST VAL Loss: 0.4265  Val_Acc: 78.955

Epoch 95: Validation loss decreased (0.426548 --> 0.426382).  Saving model ...
	 Train_Loss: 0.4334 Train_Acc: 79.227 Val_Loss: 0.4264  BEST VAL Loss: 0.4264  Val_Acc: 80.024

Epoch 96: Validation loss decreased (0.426382 --> 0.426282).  Saving model ...
	 Train_Loss: 0.4332 Train_Acc: 79.030 Val_Loss: 0.4263  BEST VAL Loss: 0.4263  Val_Acc: 79.770

Epoch 97: Validation loss decreased (0.426282 --> 0.426247).  Saving model ...
	 Train_Loss: 0.4330 Train_Acc: 79.133 Val_Loss: 0.4262  BEST VAL Loss: 0.4262  Val_Acc: 79.646

Epoch 98: Validation loss decreased (0.426247 --> 0.426115).  Saving model ...
	 Train_Loss: 0.4328 Train_Acc: 79.169 Val_Loss: 0.4261  BEST VAL Loss: 0.4261  Val_Acc: 79.819

Epoch 99: Validation loss decreased (0.426115 --> 0.425986).  Saving model ...
	 Train_Loss: 0.4326 Train_Acc: 79.223 Val_Loss: 0.4260  BEST VAL Loss: 0.4260  Val_Acc: 79.711

Flagellin_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.34      0.26      0.29     50422
           1       0.66      0.74      0.70     97754

    accuracy                           0.58    148176
   macro avg       0.50      0.50      0.50    148176
weighted avg       0.55      0.58      0.56    148176

Flagellin_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.34      0.26      0.29      6303
           1       0.66      0.74      0.70     12219

    accuracy                           0.58     18522
   macro avg       0.50      0.50      0.50     18522
weighted avg       0.55      0.58      0.56     18522

Flagellin_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.34      0.25      0.29      6303
           1       0.66      0.75      0.70     12219

    accuracy                           0.58     18522
   macro avg       0.50      0.50      0.49     18522
weighted avg       0.55      0.58      0.56     18522

              precision    recall  f1-score   support

           0       0.34      0.25      0.29      6303
           1       0.66      0.75      0.70     12219

    accuracy                           0.58     18522
   macro avg       0.50      0.50      0.49     18522
weighted avg       0.55      0.58      0.56     18522

Flagellin_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_LPS_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.33      0.38     32887
           1       0.53      0.67      0.59     37243

    accuracy                           0.51     70130
   macro avg       0.50      0.50      0.49     70130
weighted avg       0.50      0.51      0.50     70130

              precision    recall  f1-score   support

           0       0.47      0.33      0.38     32887
           1       0.53      0.67      0.59     37243

    accuracy                           0.51     70130
   macro avg       0.50      0.50      0.49     70130
weighted avg       0.50      0.51      0.50     70130

completed
