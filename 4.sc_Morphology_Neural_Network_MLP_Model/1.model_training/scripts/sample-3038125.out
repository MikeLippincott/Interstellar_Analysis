[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1e621e8a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '1903dbcb'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '9658a467'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '46185c31'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_10.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (31212, 1276)
Number of total missing values across all columns: 33620
Data Subset Is Off
Wells held out for testing: ['E20' 'M16']
Wells to use for training, validation, and testing ['E16' 'E17' 'E21' 'M17' 'M20' 'M21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.469675).  Saving model ...
	 Train_Loss: 0.5984 Train_Acc: 72.059 Val_Loss: 0.4697  BEST VAL Loss: 0.4697  Val_Acc: 89.651

Epoch 1: Validation loss decreased (0.469675 --> 0.377842).  Saving model ...
	 Train_Loss: 0.5426 Train_Acc: 80.189 Val_Loss: 0.3778  BEST VAL Loss: 0.3778  Val_Acc: 92.799

Epoch 2: Validation loss decreased (0.377842 --> 0.314807).  Saving model ...
	 Train_Loss: 0.4843 Train_Acc: 82.189 Val_Loss: 0.3148  BEST VAL Loss: 0.3148  Val_Acc: 94.006

Epoch 3: Validation loss decreased (0.314807 --> 0.277742).  Saving model ...
	 Train_Loss: 0.4465 Train_Acc: 82.496 Val_Loss: 0.2777  BEST VAL Loss: 0.2777  Val_Acc: 94.394

Epoch 4: Validation loss decreased (0.277742 --> 0.247765).  Saving model ...
	 Train_Loss: 0.4171 Train_Acc: 84.146 Val_Loss: 0.2478  BEST VAL Loss: 0.2478  Val_Acc: 95.947

Epoch 5: Validation loss decreased (0.247765 --> 0.226593).  Saving model ...
	 Train_Loss: 0.3951 Train_Acc: 84.329 Val_Loss: 0.2266  BEST VAL Loss: 0.2266  Val_Acc: 95.903

Epoch 6: Validation loss decreased (0.226593 --> 0.210672).  Saving model ...
	 Train_Loss: 0.3767 Train_Acc: 85.412 Val_Loss: 0.2107  BEST VAL Loss: 0.2107  Val_Acc: 96.119

Epoch 7: Validation loss decreased (0.210672 --> 0.198945).  Saving model ...
	 Train_Loss: 0.3615 Train_Acc: 85.526 Val_Loss: 0.1989  BEST VAL Loss: 0.1989  Val_Acc: 96.205

Epoch 8: Validation loss decreased (0.198945 --> 0.189728).  Saving model ...
	 Train_Loss: 0.3513 Train_Acc: 84.782 Val_Loss: 0.1897  BEST VAL Loss: 0.1897  Val_Acc: 96.119

Epoch 9: Validation loss decreased (0.189728 --> 0.181938).  Saving model ...
	 Train_Loss: 0.3411 Train_Acc: 85.752 Val_Loss: 0.1819  BEST VAL Loss: 0.1819  Val_Acc: 96.593

Epoch 10: Validation loss decreased (0.181938 --> 0.174204).  Saving model ...
	 Train_Loss: 0.3325 Train_Acc: 85.811 Val_Loss: 0.1742  BEST VAL Loss: 0.1742  Val_Acc: 96.723

Epoch 11: Validation loss decreased (0.174204 --> 0.169295).  Saving model ...
	 Train_Loss: 0.3251 Train_Acc: 86.151 Val_Loss: 0.1693  BEST VAL Loss: 0.1693  Val_Acc: 96.205

Epoch 12: Validation loss decreased (0.169295 --> 0.163740).  Saving model ...
	 Train_Loss: 0.3191 Train_Acc: 85.957 Val_Loss: 0.1637  BEST VAL Loss: 0.1637  Val_Acc: 96.378

Epoch 13: Validation loss decreased (0.163740 --> 0.159283).  Saving model ...
	 Train_Loss: 0.3133 Train_Acc: 86.437 Val_Loss: 0.1593  BEST VAL Loss: 0.1593  Val_Acc: 96.550

Epoch 14: Validation loss decreased (0.159283 --> 0.156426).  Saving model ...
	 Train_Loss: 0.3076 Train_Acc: 86.658 Val_Loss: 0.1564  BEST VAL Loss: 0.1564  Val_Acc: 96.378

Epoch 15: Validation loss decreased (0.156426 --> 0.153176).  Saving model ...
	 Train_Loss: 0.3031 Train_Acc: 86.194 Val_Loss: 0.1532  BEST VAL Loss: 0.1532  Val_Acc: 96.378

Epoch 16: Validation loss decreased (0.153176 --> 0.150895).  Saving model ...
	 Train_Loss: 0.2991 Train_Acc: 86.394 Val_Loss: 0.1509  BEST VAL Loss: 0.1509  Val_Acc: 96.680

Epoch 17: Validation loss decreased (0.150895 --> 0.148369).  Saving model ...
	 Train_Loss: 0.2957 Train_Acc: 86.232 Val_Loss: 0.1484  BEST VAL Loss: 0.1484  Val_Acc: 96.507

Epoch 18: Validation loss decreased (0.148369 --> 0.145933).  Saving model ...
	 Train_Loss: 0.2921 Train_Acc: 86.803 Val_Loss: 0.1459  BEST VAL Loss: 0.1459  Val_Acc: 96.723

Epoch 19: Validation loss decreased (0.145933 --> 0.143776).  Saving model ...
	 Train_Loss: 0.2891 Train_Acc: 86.394 Val_Loss: 0.1438  BEST VAL Loss: 0.1438  Val_Acc: 96.636

Epoch 20: Validation loss decreased (0.143776 --> 0.141703).  Saving model ...
	 Train_Loss: 0.2865 Train_Acc: 86.216 Val_Loss: 0.1417  BEST VAL Loss: 0.1417  Val_Acc: 96.766

Epoch 21: Validation loss decreased (0.141703 --> 0.139954).  Saving model ...
	 Train_Loss: 0.2838 Train_Acc: 86.841 Val_Loss: 0.1400  BEST VAL Loss: 0.1400  Val_Acc: 96.809

Epoch 22: Validation loss decreased (0.139954 --> 0.137883).  Saving model ...
	 Train_Loss: 0.2811 Train_Acc: 86.943 Val_Loss: 0.1379  BEST VAL Loss: 0.1379  Val_Acc: 97.197

Epoch 23: Validation loss decreased (0.137883 --> 0.136089).  Saving model ...
	 Train_Loss: 0.2789 Train_Acc: 86.474 Val_Loss: 0.1361  BEST VAL Loss: 0.1361  Val_Acc: 97.068

Epoch 24: Validation loss decreased (0.136089 --> 0.134659).  Saving model ...
	 Train_Loss: 0.2766 Train_Acc: 86.868 Val_Loss: 0.1347  BEST VAL Loss: 0.1347  Val_Acc: 96.938

Epoch 25: Validation loss decreased (0.134659 --> 0.133375).  Saving model ...
	 Train_Loss: 0.2747 Train_Acc: 86.544 Val_Loss: 0.1334  BEST VAL Loss: 0.1334  Val_Acc: 96.421

Epoch 26: Validation loss decreased (0.133375 --> 0.132635).  Saving model ...
	 Train_Loss: 0.2728 Train_Acc: 86.830 Val_Loss: 0.1326  BEST VAL Loss: 0.1326  Val_Acc: 96.895

Epoch 27: Validation loss decreased (0.132635 --> 0.131582).  Saving model ...
	 Train_Loss: 0.2707 Train_Acc: 87.235 Val_Loss: 0.1316  BEST VAL Loss: 0.1316  Val_Acc: 97.499

Epoch 28: Validation loss decreased (0.131582 --> 0.130504).  Saving model ...
	 Train_Loss: 0.2690 Train_Acc: 86.674 Val_Loss: 0.1305  BEST VAL Loss: 0.1305  Val_Acc: 96.852

Epoch 29: Validation loss decreased (0.130504 --> 0.129655).  Saving model ...
	 Train_Loss: 0.2674 Train_Acc: 86.916 Val_Loss: 0.1297  BEST VAL Loss: 0.1297  Val_Acc: 97.197

Epoch 30: Validation loss decreased (0.129655 --> 0.128611).  Saving model ...
	 Train_Loss: 0.2659 Train_Acc: 86.970 Val_Loss: 0.1286  BEST VAL Loss: 0.1286  Val_Acc: 97.456

Epoch 31: Validation loss decreased (0.128611 --> 0.127769).  Saving model ...
	 Train_Loss: 0.2645 Train_Acc: 86.889 Val_Loss: 0.1278  BEST VAL Loss: 0.1278  Val_Acc: 97.326

Epoch 32: Validation loss decreased (0.127769 --> 0.126729).  Saving model ...
	 Train_Loss: 0.2629 Train_Acc: 87.375 Val_Loss: 0.1267  BEST VAL Loss: 0.1267  Val_Acc: 97.025

Epoch 33: Validation loss decreased (0.126729 --> 0.125877).  Saving model ...
	 Train_Loss: 0.2616 Train_Acc: 86.636 Val_Loss: 0.1259  BEST VAL Loss: 0.1259  Val_Acc: 97.326

Epoch 34: Validation loss decreased (0.125877 --> 0.125110).  Saving model ...
	 Train_Loss: 0.2603 Train_Acc: 86.987 Val_Loss: 0.1251  BEST VAL Loss: 0.1251  Val_Acc: 97.283

Epoch 35: Validation loss decreased (0.125110 --> 0.124722).  Saving model ...
	 Train_Loss: 0.2591 Train_Acc: 87.003 Val_Loss: 0.1247  BEST VAL Loss: 0.1247  Val_Acc: 96.895

Epoch 36: Validation loss decreased (0.124722 --> 0.123937).  Saving model ...
	 Train_Loss: 0.2580 Train_Acc: 87.019 Val_Loss: 0.1239  BEST VAL Loss: 0.1239  Val_Acc: 97.068

Epoch 37: Validation loss decreased (0.123937 --> 0.123237).  Saving model ...
	 Train_Loss: 0.2569 Train_Acc: 87.321 Val_Loss: 0.1232  BEST VAL Loss: 0.1232  Val_Acc: 97.068

Epoch 38: Validation loss decreased (0.123237 --> 0.122290).  Saving model ...
	 Train_Loss: 0.2558 Train_Acc: 87.019 Val_Loss: 0.1223  BEST VAL Loss: 0.1223  Val_Acc: 97.197

Epoch 39: Validation loss decreased (0.122290 --> 0.121635).  Saving model ...
	 Train_Loss: 0.2548 Train_Acc: 87.024 Val_Loss: 0.1216  BEST VAL Loss: 0.1216  Val_Acc: 96.593

Epoch 40: Validation loss decreased (0.121635 --> 0.121417).  Saving model ...
	 Train_Loss: 0.2537 Train_Acc: 87.472 Val_Loss: 0.1214  BEST VAL Loss: 0.1214  Val_Acc: 96.723

Epoch 41: Validation loss decreased (0.121417 --> 0.121090).  Saving model ...
	 Train_Loss: 0.2527 Train_Acc: 87.353 Val_Loss: 0.1211  BEST VAL Loss: 0.1211  Val_Acc: 96.938

Epoch 42: Validation loss decreased (0.121090 --> 0.120844).  Saving model ...
	 Train_Loss: 0.2516 Train_Acc: 87.412 Val_Loss: 0.1208  BEST VAL Loss: 0.1208  Val_Acc: 96.852

Epoch 43: Validation loss decreased (0.120844 --> 0.120615).  Saving model ...
	 Train_Loss: 0.2507 Train_Acc: 87.418 Val_Loss: 0.1206  BEST VAL Loss: 0.1206  Val_Acc: 96.852

Epoch 44: Validation loss decreased (0.120615 --> 0.120203).  Saving model ...
	 Train_Loss: 0.2499 Train_Acc: 86.987 Val_Loss: 0.1202  BEST VAL Loss: 0.1202  Val_Acc: 97.025

Epoch 45: Validation loss decreased (0.120203 --> 0.119819).  Saving model ...
	 Train_Loss: 0.2490 Train_Acc: 87.391 Val_Loss: 0.1198  BEST VAL Loss: 0.1198  Val_Acc: 97.283

Epoch 46: Validation loss decreased (0.119819 --> 0.119462).  Saving model ...
	 Train_Loss: 0.2481 Train_Acc: 87.526 Val_Loss: 0.1195  BEST VAL Loss: 0.1195  Val_Acc: 97.240

Epoch 47: Validation loss decreased (0.119462 --> 0.119270).  Saving model ...
	 Train_Loss: 0.2473 Train_Acc: 87.121 Val_Loss: 0.1193  BEST VAL Loss: 0.1193  Val_Acc: 97.068

Epoch 48: Validation loss decreased (0.119270 --> 0.118927).  Saving model ...
	 Train_Loss: 0.2466 Train_Acc: 87.164 Val_Loss: 0.1189  BEST VAL Loss: 0.1189  Val_Acc: 97.154

Epoch 49: Validation loss decreased (0.118927 --> 0.118703).  Saving model ...
	 Train_Loss: 0.2459 Train_Acc: 87.094 Val_Loss: 0.1187  BEST VAL Loss: 0.1187  Val_Acc: 97.413

Epoch 50: Validation loss decreased (0.118703 --> 0.118220).  Saving model ...
	 Train_Loss: 0.2452 Train_Acc: 87.062 Val_Loss: 0.1182  BEST VAL Loss: 0.1182  Val_Acc: 97.197

Epoch 51: Validation loss decreased (0.118220 --> 0.118071).  Saving model ...
	 Train_Loss: 0.2446 Train_Acc: 87.030 Val_Loss: 0.1181  BEST VAL Loss: 0.1181  Val_Acc: 97.068

Epoch 52: Validation loss decreased (0.118071 --> 0.117766).  Saving model ...
	 Train_Loss: 0.2440 Train_Acc: 87.229 Val_Loss: 0.1178  BEST VAL Loss: 0.1178  Val_Acc: 96.766

Epoch 53: Validation loss decreased (0.117766 --> 0.117427).  Saving model ...
	 Train_Loss: 0.2433 Train_Acc: 87.725 Val_Loss: 0.1174  BEST VAL Loss: 0.1174  Val_Acc: 96.895

Epoch 54: Validation loss decreased (0.117427 --> 0.117127).  Saving model ...
	 Train_Loss: 0.2427 Train_Acc: 87.396 Val_Loss: 0.1171  BEST VAL Loss: 0.1171  Val_Acc: 96.895

Epoch 55: Validation loss decreased (0.117127 --> 0.116739).  Saving model ...
	 Train_Loss: 0.2421 Train_Acc: 87.412 Val_Loss: 0.1167  BEST VAL Loss: 0.1167  Val_Acc: 97.283

Epoch 56: Validation loss decreased (0.116739 --> 0.116339).  Saving model ...
	 Train_Loss: 0.2415 Train_Acc: 87.321 Val_Loss: 0.1163  BEST VAL Loss: 0.1163  Val_Acc: 97.585

Epoch 57: Validation loss decreased (0.116339 --> 0.116064).  Saving model ...
	 Train_Loss: 0.2410 Train_Acc: 87.040 Val_Loss: 0.1161  BEST VAL Loss: 0.1161  Val_Acc: 97.326

Epoch 58: Validation loss decreased (0.116064 --> 0.115751).  Saving model ...
	 Train_Loss: 0.2405 Train_Acc: 87.321 Val_Loss: 0.1158  BEST VAL Loss: 0.1158  Val_Acc: 97.197

Epoch 59: Validation loss decreased (0.115751 --> 0.115521).  Saving model ...
	 Train_Loss: 0.2400 Train_Acc: 87.439 Val_Loss: 0.1155  BEST VAL Loss: 0.1155  Val_Acc: 97.326

Epoch 60: Validation loss decreased (0.115521 --> 0.115289).  Saving model ...
	 Train_Loss: 0.2396 Train_Acc: 86.889 Val_Loss: 0.1153  BEST VAL Loss: 0.1153  Val_Acc: 96.981

Epoch 61: Validation loss decreased (0.115289 --> 0.115202).  Saving model ...
	 Train_Loss: 0.2391 Train_Acc: 86.916 Val_Loss: 0.1152  BEST VAL Loss: 0.1152  Val_Acc: 97.413

Epoch 62: Validation loss decreased (0.115202 --> 0.114974).  Saving model ...
	 Train_Loss: 0.2387 Train_Acc: 87.305 Val_Loss: 0.1150  BEST VAL Loss: 0.1150  Val_Acc: 96.852

Epoch 63: Validation loss decreased (0.114974 --> 0.114710).  Saving model ...
	 Train_Loss: 0.2382 Train_Acc: 87.547 Val_Loss: 0.1147  BEST VAL Loss: 0.1147  Val_Acc: 97.370

Epoch 64: Validation loss decreased (0.114710 --> 0.114642).  Saving model ...
	 Train_Loss: 0.2378 Train_Acc: 87.111 Val_Loss: 0.1146  BEST VAL Loss: 0.1146  Val_Acc: 97.025

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.2373 Train_Acc: 87.186 Val_Loss: 0.1148  BEST VAL Loss: 0.1146  Val_Acc: 96.723

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.2369 Train_Acc: 87.062 Val_Loss: 0.1148  BEST VAL Loss: 0.1146  Val_Acc: 97.025

Epoch 67: Validation loss decreased (0.114642 --> 0.114526).  Saving model ...
	 Train_Loss: 0.2365 Train_Acc: 87.105 Val_Loss: 0.1145  BEST VAL Loss: 0.1145  Val_Acc: 97.197

Epoch 68: Validation loss decreased (0.114526 --> 0.114403).  Saving model ...
	 Train_Loss: 0.2362 Train_Acc: 86.879 Val_Loss: 0.1144  BEST VAL Loss: 0.1144  Val_Acc: 97.068

Epoch 69: Validation loss decreased (0.114403 --> 0.114251).  Saving model ...
	 Train_Loss: 0.2359 Train_Acc: 87.385 Val_Loss: 0.1143  BEST VAL Loss: 0.1143  Val_Acc: 96.981

Epoch 70: Validation loss decreased (0.114251 --> 0.114223).  Saving model ...
	 Train_Loss: 0.2355 Train_Acc: 87.380 Val_Loss: 0.1142  BEST VAL Loss: 0.1142  Val_Acc: 97.154

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.2351 Train_Acc: 87.682 Val_Loss: 0.1142  BEST VAL Loss: 0.1142  Val_Acc: 97.154

Epoch 72: Validation loss decreased (0.114223 --> 0.114097).  Saving model ...
	 Train_Loss: 0.2347 Train_Acc: 87.369 Val_Loss: 0.1141  BEST VAL Loss: 0.1141  Val_Acc: 97.111

Epoch 73: Validation loss decreased (0.114097 --> 0.113853).  Saving model ...
	 Train_Loss: 0.2345 Train_Acc: 87.402 Val_Loss: 0.1139  BEST VAL Loss: 0.1139  Val_Acc: 97.240

Epoch 74: Validation loss decreased (0.113853 --> 0.113602).  Saving model ...
	 Train_Loss: 0.2342 Train_Acc: 87.482 Val_Loss: 0.1136  BEST VAL Loss: 0.1136  Val_Acc: 97.111

Epoch 75: Validation loss decreased (0.113602 --> 0.113402).  Saving model ...
	 Train_Loss: 0.2339 Train_Acc: 87.267 Val_Loss: 0.1134  BEST VAL Loss: 0.1134  Val_Acc: 97.585

Epoch 76: Validation loss decreased (0.113402 --> 0.113259).  Saving model ...
	 Train_Loss: 0.2335 Train_Acc: 87.736 Val_Loss: 0.1133  BEST VAL Loss: 0.1133  Val_Acc: 97.068

Epoch 77: Validation loss decreased (0.113259 --> 0.113196).  Saving model ...
	 Train_Loss: 0.2331 Train_Acc: 87.509 Val_Loss: 0.1132  BEST VAL Loss: 0.1132  Val_Acc: 97.370

Epoch 78: Validation loss decreased (0.113196 --> 0.112833).  Saving model ...
	 Train_Loss: 0.2328 Train_Acc: 87.342 Val_Loss: 0.1128  BEST VAL Loss: 0.1128  Val_Acc: 97.326

Epoch 79: Validation loss decreased (0.112833 --> 0.112610).  Saving model ...
	 Train_Loss: 0.2325 Train_Acc: 87.326 Val_Loss: 0.1126  BEST VAL Loss: 0.1126  Val_Acc: 97.628

Epoch 80: Validation loss decreased (0.112610 --> 0.112498).  Saving model ...
	 Train_Loss: 0.2323 Train_Acc: 87.256 Val_Loss: 0.1125  BEST VAL Loss: 0.1125  Val_Acc: 97.370

Epoch 81: Validation loss decreased (0.112498 --> 0.112289).  Saving model ...
	 Train_Loss: 0.2320 Train_Acc: 87.536 Val_Loss: 0.1123  BEST VAL Loss: 0.1123  Val_Acc: 97.542

Epoch 82: Validation loss decreased (0.112289 --> 0.112070).  Saving model ...
	 Train_Loss: 0.2316 Train_Acc: 87.558 Val_Loss: 0.1121  BEST VAL Loss: 0.1121  Val_Acc: 97.283

Epoch 83: Validation loss decreased (0.112070 --> 0.111885).  Saving model ...
	 Train_Loss: 0.2314 Train_Acc: 86.884 Val_Loss: 0.1119  BEST VAL Loss: 0.1119  Val_Acc: 97.111

Epoch 84: Validation loss decreased (0.111885 --> 0.111679).  Saving model ...
	 Train_Loss: 0.2312 Train_Acc: 87.170 Val_Loss: 0.1117  BEST VAL Loss: 0.1117  Val_Acc: 97.197

Epoch 85: Validation loss decreased (0.111679 --> 0.111518).  Saving model ...
	 Train_Loss: 0.2310 Train_Acc: 87.348 Val_Loss: 0.1115  BEST VAL Loss: 0.1115  Val_Acc: 97.370

Epoch 86: Validation loss decreased (0.111518 --> 0.111352).  Saving model ...
	 Train_Loss: 0.2307 Train_Acc: 87.391 Val_Loss: 0.1114  BEST VAL Loss: 0.1114  Val_Acc: 97.370

Epoch 87: Validation loss decreased (0.111352 --> 0.111228).  Saving model ...
	 Train_Loss: 0.2304 Train_Acc: 87.434 Val_Loss: 0.1112  BEST VAL Loss: 0.1112  Val_Acc: 97.671

Epoch 88: Validation loss decreased (0.111228 --> 0.111116).  Saving model ...
	 Train_Loss: 0.2301 Train_Acc: 87.321 Val_Loss: 0.1111  BEST VAL Loss: 0.1111  Val_Acc: 97.413

Epoch 89: Validation loss decreased (0.111116 --> 0.111051).  Saving model ...
	 Train_Loss: 0.2299 Train_Acc: 87.294 Val_Loss: 0.1111  BEST VAL Loss: 0.1111  Val_Acc: 97.283

Epoch 90: Validation loss decreased (0.111051 --> 0.110921).  Saving model ...
	 Train_Loss: 0.2297 Train_Acc: 87.294 Val_Loss: 0.1109  BEST VAL Loss: 0.1109  Val_Acc: 97.283

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.2294 Train_Acc: 87.466 Val_Loss: 0.1110  BEST VAL Loss: 0.1109  Val_Acc: 97.499

Epoch 92: Validation loss decreased (0.110921 --> 0.110888).  Saving model ...
	 Train_Loss: 0.2292 Train_Acc: 87.353 Val_Loss: 0.1109  BEST VAL Loss: 0.1109  Val_Acc: 97.111

Epoch 93: Validation loss decreased (0.110888 --> 0.110842).  Saving model ...
	 Train_Loss: 0.2289 Train_Acc: 87.310 Val_Loss: 0.1108  BEST VAL Loss: 0.1108  Val_Acc: 97.240

Epoch 94: Validation loss decreased (0.110842 --> 0.110837).  Saving model ...
	 Train_Loss: 0.2287 Train_Acc: 87.520 Val_Loss: 0.1108  BEST VAL Loss: 0.1108  Val_Acc: 97.413

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.2284 Train_Acc: 87.310 Val_Loss: 0.1109  BEST VAL Loss: 0.1108  Val_Acc: 97.240

Epoch 96: Validation loss decreased (0.110837 --> 0.110803).  Saving model ...
	 Train_Loss: 0.2282 Train_Acc: 87.429 Val_Loss: 0.1108  BEST VAL Loss: 0.1108  Val_Acc: 97.671

Epoch 97: Validation loss did not decrease
	 Train_Loss: 0.2280 Train_Acc: 87.213 Val_Loss: 0.1109  BEST VAL Loss: 0.1108  Val_Acc: 96.852

Epoch 98: Validation loss did not decrease
	 Train_Loss: 0.2278 Train_Acc: 87.456 Val_Loss: 0.1108  BEST VAL Loss: 0.1108  Val_Acc: 97.154

Epoch 99: Validation loss decreased (0.110803 --> 0.110724).  Saving model ...
	 Train_Loss: 0.2276 Train_Acc: 87.402 Val_Loss: 0.1107  BEST VAL Loss: 0.1107  Val_Acc: 97.671

LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     10114
           1       1.00      1.00      1.00      8436

    accuracy                           1.00     18550
   macro avg       1.00      1.00      1.00     18550
weighted avg       1.00      1.00      1.00     18550

LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.97      0.98      1264
           1       0.97      0.98      0.97      1055

    accuracy                           0.98      2319
   macro avg       0.98      0.98      0.98      2319
weighted avg       0.98      0.98      0.98      2319

LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.98      0.98      1264
           1       0.98      0.97      0.97      1055

    accuracy                           0.98      2319
   macro avg       0.98      0.98      0.98      2319
weighted avg       0.98      0.98      0.98      2319

              precision    recall  f1-score   support

           0       0.98      0.98      0.98      1264
           1       0.98      0.97      0.97      1055

    accuracy                           0.98      2319
   macro avg       0.98      0.98      0.98      2319
weighted avg       0.98      0.98      0.98      2319

LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_10.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.98      0.98      4168
           1       0.98      0.97      0.97      3856

    accuracy                           0.98      8024
   macro avg       0.98      0.97      0.98      8024
weighted avg       0.98      0.98      0.98      8024

              precision    recall  f1-score   support

           0       0.97      0.98      0.98      4168
           1       0.98      0.97      0.97      3856

    accuracy                           0.98      8024
   macro avg       0.98      0.97      0.98      8024
weighted avg       0.98      0.98      0.98      8024

completed
