[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '0d748ef4'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'ad67108c'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '59025ece'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '02f554a8'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 treatment_name: DMSO_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
TREATMENT_NAME: DMSO_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (396296, 1270)
Number of total missing values across all columns: 430260
Data Subset Is Off
Wells held out for testing: ['J06' 'M08']
Wells to use for training, validation, and testing ['B06' 'C06' 'B07' 'C07' 'I06' 'I07' 'J07' 'M02' 'M03' 'M09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.151740).  Saving model ...
	 Train_Loss: 0.2761 Train_Acc: 88.937 Val_Loss: 0.1517  BEST VAL Loss: 0.1517  Val_Acc: 94.263

Epoch 1: Validation loss decreased (0.151740 --> 0.143114).  Saving model ...
	 Train_Loss: 0.2417 Train_Acc: 92.534 Val_Loss: 0.1431  BEST VAL Loss: 0.1431  Val_Acc: 94.944

Epoch 2: Validation loss decreased (0.143114 --> 0.138012).  Saving model ...
	 Train_Loss: 0.2252 Train_Acc: 93.022 Val_Loss: 0.1380  BEST VAL Loss: 0.1380  Val_Acc: 94.990

Epoch 3: Validation loss decreased (0.138012 --> 0.134776).  Saving model ...
	 Train_Loss: 0.2157 Train_Acc: 93.257 Val_Loss: 0.1348  BEST VAL Loss: 0.1348  Val_Acc: 95.413

Epoch 4: Validation loss decreased (0.134776 --> 0.133600).  Saving model ...
	 Train_Loss: 0.2086 Train_Acc: 93.533 Val_Loss: 0.1336  BEST VAL Loss: 0.1336  Val_Acc: 95.117

Epoch 5: Validation loss decreased (0.133600 --> 0.132341).  Saving model ...
	 Train_Loss: 0.2039 Train_Acc: 93.353 Val_Loss: 0.1323  BEST VAL Loss: 0.1323  Val_Acc: 95.249

Epoch 6: Validation loss decreased (0.132341 --> 0.130133).  Saving model ...
	 Train_Loss: 0.1994 Train_Acc: 93.794 Val_Loss: 0.1301  BEST VAL Loss: 0.1301  Val_Acc: 95.560

Epoch 7: Validation loss decreased (0.130133 --> 0.129226).  Saving model ...
	 Train_Loss: 0.1958 Train_Acc: 93.900 Val_Loss: 0.1292  BEST VAL Loss: 0.1292  Val_Acc: 95.160

Epoch 8: Validation loss decreased (0.129226 --> 0.128398).  Saving model ...
	 Train_Loss: 0.1937 Train_Acc: 93.587 Val_Loss: 0.1284  BEST VAL Loss: 0.1284  Val_Acc: 95.576

Epoch 9: Validation loss decreased (0.128398 --> 0.126958).  Saving model ...
	 Train_Loss: 0.1916 Train_Acc: 93.812 Val_Loss: 0.1270  BEST VAL Loss: 0.1270  Val_Acc: 95.801

Epoch 10: Validation loss decreased (0.126958 --> 0.126121).  Saving model ...
	 Train_Loss: 0.1896 Train_Acc: 93.867 Val_Loss: 0.1261  BEST VAL Loss: 0.1261  Val_Acc: 95.440

Epoch 11: Validation loss decreased (0.126121 --> 0.125138).  Saving model ...
	 Train_Loss: 0.1884 Train_Acc: 93.711 Val_Loss: 0.1251  BEST VAL Loss: 0.1251  Val_Acc: 95.893

Epoch 12: Validation loss did not decrease
	 Train_Loss: 0.1868 Train_Acc: 93.984 Val_Loss: 0.1256  BEST VAL Loss: 0.1251  Val_Acc: 95.292

Epoch 13: Validation loss decreased (0.125138 --> 0.125066).  Saving model ...
	 Train_Loss: 0.1858 Train_Acc: 93.770 Val_Loss: 0.1251  BEST VAL Loss: 0.1251  Val_Acc: 95.656

Epoch 14: Validation loss decreased (0.125066 --> 0.124490).  Saving model ...
	 Train_Loss: 0.1849 Train_Acc: 93.803 Val_Loss: 0.1245  BEST VAL Loss: 0.1245  Val_Acc: 95.493

Epoch 15: Validation loss decreased (0.124490 --> 0.123620).  Saving model ...
	 Train_Loss: 0.1835 Train_Acc: 94.192 Val_Loss: 0.1236  BEST VAL Loss: 0.1236  Val_Acc: 96.051

Epoch 16: Validation loss did not decrease
	 Train_Loss: 0.1823 Train_Acc: 94.124 Val_Loss: 0.1238  BEST VAL Loss: 0.1236  Val_Acc: 95.132

Epoch 17: Validation loss did not decrease
	 Train_Loss: 0.1816 Train_Acc: 93.867 Val_Loss: 0.1240  BEST VAL Loss: 0.1236  Val_Acc: 95.055

Epoch 18: Validation loss decreased (0.123620 --> 0.123305).  Saving model ...
	 Train_Loss: 0.1810 Train_Acc: 93.749 Val_Loss: 0.1233  BEST VAL Loss: 0.1233  Val_Acc: 95.755

Epoch 19: Validation loss decreased (0.123305 --> 0.122743).  Saving model ...
	 Train_Loss: 0.1801 Train_Acc: 94.111 Val_Loss: 0.1227  BEST VAL Loss: 0.1227  Val_Acc: 95.832

Epoch 20: Validation loss decreased (0.122743 --> 0.122202).  Saving model ...
	 Train_Loss: 0.1792 Train_Acc: 94.208 Val_Loss: 0.1222  BEST VAL Loss: 0.1222  Val_Acc: 95.909

Epoch 21: Validation loss decreased (0.122202 --> 0.121832).  Saving model ...
	 Train_Loss: 0.1785 Train_Acc: 94.124 Val_Loss: 0.1218  BEST VAL Loss: 0.1218  Val_Acc: 95.838

Epoch 22: Validation loss decreased (0.121832 --> 0.121513).  Saving model ...
	 Train_Loss: 0.1779 Train_Acc: 94.051 Val_Loss: 0.1215  BEST VAL Loss: 0.1215  Val_Acc: 95.761

Epoch 23: Validation loss decreased (0.121513 --> 0.120970).  Saving model ...
	 Train_Loss: 0.1771 Train_Acc: 94.302 Val_Loss: 0.1210  BEST VAL Loss: 0.1210  Val_Acc: 96.131

Epoch 24: Validation loss decreased (0.120970 --> 0.120603).  Saving model ...
	 Train_Loss: 0.1763 Train_Acc: 94.361 Val_Loss: 0.1206  BEST VAL Loss: 0.1206  Val_Acc: 95.860

Epoch 25: Validation loss decreased (0.120603 --> 0.120221).  Saving model ...
	 Train_Loss: 0.1755 Train_Acc: 94.371 Val_Loss: 0.1202  BEST VAL Loss: 0.1202  Val_Acc: 95.924

Epoch 26: Validation loss decreased (0.120221 --> 0.119823).  Saving model ...
	 Train_Loss: 0.1748 Train_Acc: 94.421 Val_Loss: 0.1198  BEST VAL Loss: 0.1198  Val_Acc: 96.103

Epoch 27: Validation loss decreased (0.119823 --> 0.119781).  Saving model ...
	 Train_Loss: 0.1745 Train_Acc: 93.973 Val_Loss: 0.1198  BEST VAL Loss: 0.1198  Val_Acc: 95.480

Epoch 28: Validation loss decreased (0.119781 --> 0.119648).  Saving model ...
	 Train_Loss: 0.1742 Train_Acc: 94.101 Val_Loss: 0.1196  BEST VAL Loss: 0.1196  Val_Acc: 95.736

Epoch 29: Validation loss decreased (0.119648 --> 0.119328).  Saving model ...
	 Train_Loss: 0.1739 Train_Acc: 93.957 Val_Loss: 0.1193  BEST VAL Loss: 0.1193  Val_Acc: 95.866

Epoch 30: Validation loss decreased (0.119328 --> 0.118964).  Saving model ...
	 Train_Loss: 0.1736 Train_Acc: 94.012 Val_Loss: 0.1190  BEST VAL Loss: 0.1190  Val_Acc: 95.924

Epoch 31: Validation loss decreased (0.118964 --> 0.118637).  Saving model ...
	 Train_Loss: 0.1731 Train_Acc: 94.410 Val_Loss: 0.1186  BEST VAL Loss: 0.1186  Val_Acc: 96.078

Epoch 32: Validation loss decreased (0.118637 --> 0.118363).  Saving model ...
	 Train_Loss: 0.1724 Train_Acc: 94.544 Val_Loss: 0.1184  BEST VAL Loss: 0.1184  Val_Acc: 95.881

Epoch 33: Validation loss decreased (0.118363 --> 0.118032).  Saving model ...
	 Train_Loss: 0.1719 Train_Acc: 94.526 Val_Loss: 0.1180  BEST VAL Loss: 0.1180  Val_Acc: 96.097

Epoch 34: Validation loss decreased (0.118032 --> 0.117670).  Saving model ...
	 Train_Loss: 0.1716 Train_Acc: 94.240 Val_Loss: 0.1177  BEST VAL Loss: 0.1177  Val_Acc: 96.088

Epoch 35: Validation loss decreased (0.117670 --> 0.117336).  Saving model ...
	 Train_Loss: 0.1713 Train_Acc: 94.210 Val_Loss: 0.1173  BEST VAL Loss: 0.1173  Val_Acc: 96.109

Epoch 36: Validation loss decreased (0.117336 --> 0.117304).  Saving model ...
	 Train_Loss: 0.1710 Train_Acc: 94.247 Val_Loss: 0.1173  BEST VAL Loss: 0.1173  Val_Acc: 95.786

Epoch 37: Validation loss decreased (0.117304 --> 0.117107).  Saving model ...
	 Train_Loss: 0.1708 Train_Acc: 93.933 Val_Loss: 0.1171  BEST VAL Loss: 0.1171  Val_Acc: 95.937

Epoch 38: Validation loss decreased (0.117107 --> 0.116780).  Saving model ...
	 Train_Loss: 0.1704 Train_Acc: 94.436 Val_Loss: 0.1168  BEST VAL Loss: 0.1168  Val_Acc: 96.094

Epoch 39: Validation loss decreased (0.116780 --> 0.116501).  Saving model ...
	 Train_Loss: 0.1699 Train_Acc: 94.440 Val_Loss: 0.1165  BEST VAL Loss: 0.1165  Val_Acc: 96.183

Epoch 40: Validation loss decreased (0.116501 --> 0.116293).  Saving model ...
	 Train_Loss: 0.1696 Train_Acc: 94.263 Val_Loss: 0.1163  BEST VAL Loss: 0.1163  Val_Acc: 96.060

Epoch 41: Validation loss decreased (0.116293 --> 0.116159).  Saving model ...
	 Train_Loss: 0.1693 Train_Acc: 94.311 Val_Loss: 0.1162  BEST VAL Loss: 0.1162  Val_Acc: 96.001

Epoch 42: Validation loss decreased (0.116159 --> 0.115964).  Saving model ...
	 Train_Loss: 0.1689 Train_Acc: 94.476 Val_Loss: 0.1160  BEST VAL Loss: 0.1160  Val_Acc: 96.115

Epoch 43: Validation loss decreased (0.115964 --> 0.115769).  Saving model ...
	 Train_Loss: 0.1686 Train_Acc: 94.441 Val_Loss: 0.1158  BEST VAL Loss: 0.1158  Val_Acc: 95.903

Epoch 44: Validation loss decreased (0.115769 --> 0.115600).  Saving model ...
	 Train_Loss: 0.1683 Train_Acc: 94.459 Val_Loss: 0.1156  BEST VAL Loss: 0.1156  Val_Acc: 96.143

Epoch 45: Validation loss decreased (0.115600 --> 0.115301).  Saving model ...
	 Train_Loss: 0.1679 Train_Acc: 94.534 Val_Loss: 0.1153  BEST VAL Loss: 0.1153  Val_Acc: 96.282

Epoch 46: Validation loss decreased (0.115301 --> 0.115220).  Saving model ...
	 Train_Loss: 0.1675 Train_Acc: 94.520 Val_Loss: 0.1152  BEST VAL Loss: 0.1152  Val_Acc: 95.934

Epoch 47: Validation loss decreased (0.115220 --> 0.114958).  Saving model ...
	 Train_Loss: 0.1671 Train_Acc: 94.582 Val_Loss: 0.1150  BEST VAL Loss: 0.1150  Val_Acc: 96.300

Epoch 48: Validation loss decreased (0.114958 --> 0.114944).  Saving model ...
	 Train_Loss: 0.1668 Train_Acc: 94.610 Val_Loss: 0.1149  BEST VAL Loss: 0.1149  Val_Acc: 95.940

Epoch 49: Validation loss decreased (0.114944 --> 0.114839).  Saving model ...
	 Train_Loss: 0.1666 Train_Acc: 94.244 Val_Loss: 0.1148  BEST VAL Loss: 0.1148  Val_Acc: 95.940

Epoch 50: Validation loss decreased (0.114839 --> 0.114629).  Saving model ...
	 Train_Loss: 0.1663 Train_Acc: 94.467 Val_Loss: 0.1146  BEST VAL Loss: 0.1146  Val_Acc: 96.371

Epoch 51: Validation loss decreased (0.114629 --> 0.114497).  Saving model ...
	 Train_Loss: 0.1661 Train_Acc: 94.323 Val_Loss: 0.1145  BEST VAL Loss: 0.1145  Val_Acc: 96.060

Epoch 52: Validation loss decreased (0.114497 --> 0.114344).  Saving model ...
	 Train_Loss: 0.1659 Train_Acc: 94.371 Val_Loss: 0.1143  BEST VAL Loss: 0.1143  Val_Acc: 96.085

Epoch 53: Validation loss decreased (0.114344 --> 0.114120).  Saving model ...
	 Train_Loss: 0.1656 Train_Acc: 94.658 Val_Loss: 0.1141  BEST VAL Loss: 0.1141  Val_Acc: 96.242

Epoch 54: Validation loss decreased (0.114120 --> 0.113964).  Saving model ...
	 Train_Loss: 0.1653 Train_Acc: 94.571 Val_Loss: 0.1140  BEST VAL Loss: 0.1140  Val_Acc: 96.171

Epoch 55: Validation loss decreased (0.113964 --> 0.113787).  Saving model ...
	 Train_Loss: 0.1652 Train_Acc: 94.456 Val_Loss: 0.1138  BEST VAL Loss: 0.1138  Val_Acc: 96.214

Epoch 56: Validation loss decreased (0.113787 --> 0.113580).  Saving model ...
	 Train_Loss: 0.1648 Train_Acc: 94.721 Val_Loss: 0.1136  BEST VAL Loss: 0.1136  Val_Acc: 96.257

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.1646 Train_Acc: 94.630 Val_Loss: 0.1136  BEST VAL Loss: 0.1136  Val_Acc: 95.832

Epoch 58: Validation loss decreased (0.113580 --> 0.113410).  Saving model ...
	 Train_Loss: 0.1644 Train_Acc: 94.637 Val_Loss: 0.1134  BEST VAL Loss: 0.1134  Val_Acc: 96.303

Epoch 59: Validation loss decreased (0.113410 --> 0.113238).  Saving model ...
	 Train_Loss: 0.1641 Train_Acc: 94.622 Val_Loss: 0.1132  BEST VAL Loss: 0.1132  Val_Acc: 96.279

Epoch 60: Validation loss decreased (0.113238 --> 0.113140).  Saving model ...
	 Train_Loss: 0.1639 Train_Acc: 94.640 Val_Loss: 0.1131  BEST VAL Loss: 0.1131  Val_Acc: 96.097

Epoch 61: Validation loss decreased (0.113140 --> 0.113124).  Saving model ...
	 Train_Loss: 0.1637 Train_Acc: 94.525 Val_Loss: 0.1131  BEST VAL Loss: 0.1131  Val_Acc: 95.798

Epoch 62: Validation loss decreased (0.113124 --> 0.113020).  Saving model ...
	 Train_Loss: 0.1635 Train_Acc: 94.470 Val_Loss: 0.1130  BEST VAL Loss: 0.1130  Val_Acc: 95.998

Epoch 63: Validation loss decreased (0.113020 --> 0.112856).  Saving model ...
	 Train_Loss: 0.1633 Train_Acc: 94.693 Val_Loss: 0.1129  BEST VAL Loss: 0.1129  Val_Acc: 96.229

Epoch 64: Validation loss decreased (0.112856 --> 0.112747).  Saving model ...
	 Train_Loss: 0.1631 Train_Acc: 94.527 Val_Loss: 0.1127  BEST VAL Loss: 0.1127  Val_Acc: 96.205

Epoch 65: Validation loss decreased (0.112747 --> 0.112583).  Saving model ...
	 Train_Loss: 0.1629 Train_Acc: 94.581 Val_Loss: 0.1126  BEST VAL Loss: 0.1126  Val_Acc: 96.424

Epoch 66: Validation loss decreased (0.112583 --> 0.112446).  Saving model ...
	 Train_Loss: 0.1627 Train_Acc: 94.551 Val_Loss: 0.1124  BEST VAL Loss: 0.1124  Val_Acc: 96.183

Epoch 67: Validation loss decreased (0.112446 --> 0.112348).  Saving model ...
	 Train_Loss: 0.1625 Train_Acc: 94.624 Val_Loss: 0.1123  BEST VAL Loss: 0.1123  Val_Acc: 96.254

Epoch 68: Validation loss decreased (0.112348 --> 0.112174).  Saving model ...
	 Train_Loss: 0.1623 Train_Acc: 94.785 Val_Loss: 0.1122  BEST VAL Loss: 0.1122  Val_Acc: 96.399

Epoch 69: Validation loss decreased (0.112174 --> 0.111995).  Saving model ...
	 Train_Loss: 0.1620 Train_Acc: 94.743 Val_Loss: 0.1120  BEST VAL Loss: 0.1120  Val_Acc: 96.374

Epoch 70: Validation loss decreased (0.111995 --> 0.111867).  Saving model ...
	 Train_Loss: 0.1618 Train_Acc: 94.638 Val_Loss: 0.1119  BEST VAL Loss: 0.1119  Val_Acc: 96.220

Epoch 71: Validation loss decreased (0.111867 --> 0.111761).  Saving model ...
	 Train_Loss: 0.1616 Train_Acc: 94.782 Val_Loss: 0.1118  BEST VAL Loss: 0.1118  Val_Acc: 96.285

Epoch 72: Validation loss decreased (0.111761 --> 0.111578).  Saving model ...
	 Train_Loss: 0.1614 Train_Acc: 94.714 Val_Loss: 0.1116  BEST VAL Loss: 0.1116  Val_Acc: 96.584

Epoch 73: Validation loss decreased (0.111578 --> 0.111479).  Saving model ...
	 Train_Loss: 0.1612 Train_Acc: 94.592 Val_Loss: 0.1115  BEST VAL Loss: 0.1115  Val_Acc: 96.115

Epoch 74: Validation loss decreased (0.111479 --> 0.111461).  Saving model ...
	 Train_Loss: 0.1611 Train_Acc: 94.385 Val_Loss: 0.1115  BEST VAL Loss: 0.1115  Val_Acc: 95.844

Epoch 75: Validation loss decreased (0.111461 --> 0.111432).  Saving model ...
	 Train_Loss: 0.1610 Train_Acc: 94.420 Val_Loss: 0.1114  BEST VAL Loss: 0.1114  Val_Acc: 95.986

Epoch 76: Validation loss decreased (0.111432 --> 0.111313).  Saving model ...
	 Train_Loss: 0.1608 Train_Acc: 94.689 Val_Loss: 0.1113  BEST VAL Loss: 0.1113  Val_Acc: 96.368

Epoch 77: Validation loss decreased (0.111313 --> 0.111226).  Saving model ...
	 Train_Loss: 0.1607 Train_Acc: 94.686 Val_Loss: 0.1112  BEST VAL Loss: 0.1112  Val_Acc: 96.180

Epoch 78: Validation loss decreased (0.111226 --> 0.111147).  Saving model ...
	 Train_Loss: 0.1605 Train_Acc: 94.555 Val_Loss: 0.1111  BEST VAL Loss: 0.1111  Val_Acc: 96.063

Epoch 79: Validation loss decreased (0.111147 --> 0.111008).  Saving model ...
	 Train_Loss: 0.1604 Train_Acc: 94.478 Val_Loss: 0.1110  BEST VAL Loss: 0.1110  Val_Acc: 96.405

Epoch 80: Validation loss decreased (0.111008 --> 0.110979).  Saving model ...
	 Train_Loss: 0.1604 Train_Acc: 94.272 Val_Loss: 0.1110  BEST VAL Loss: 0.1110  Val_Acc: 95.964

Epoch 81: Validation loss decreased (0.110979 --> 0.110928).  Saving model ...
	 Train_Loss: 0.1603 Train_Acc: 94.403 Val_Loss: 0.1109  BEST VAL Loss: 0.1109  Val_Acc: 96.029

Epoch 82: Validation loss decreased (0.110928 --> 0.110812).  Saving model ...
	 Train_Loss: 0.1602 Train_Acc: 94.392 Val_Loss: 0.1108  BEST VAL Loss: 0.1108  Val_Acc: 96.414

Epoch 83: Validation loss decreased (0.110812 --> 0.110685).  Saving model ...
	 Train_Loss: 0.1601 Train_Acc: 94.600 Val_Loss: 0.1107  BEST VAL Loss: 0.1107  Val_Acc: 96.310

Epoch 84: Validation loss decreased (0.110685 --> 0.110607).  Saving model ...
	 Train_Loss: 0.1600 Train_Acc: 94.492 Val_Loss: 0.1106  BEST VAL Loss: 0.1106  Val_Acc: 96.291

Epoch 85: Validation loss decreased (0.110607 --> 0.110544).  Saving model ...
	 Train_Loss: 0.1598 Train_Acc: 94.624 Val_Loss: 0.1105  BEST VAL Loss: 0.1105  Val_Acc: 96.106

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.1598 Train_Acc: 94.398 Val_Loss: 0.1105  BEST VAL Loss: 0.1105  Val_Acc: 95.773

Epoch 87: Validation loss decreased (0.110544 --> 0.110478).  Saving model ...
	 Train_Loss: 0.1597 Train_Acc: 94.466 Val_Loss: 0.1105  BEST VAL Loss: 0.1105  Val_Acc: 96.041

Epoch 88: Validation loss decreased (0.110478 --> 0.110427).  Saving model ...
	 Train_Loss: 0.1595 Train_Acc: 94.629 Val_Loss: 0.1104  BEST VAL Loss: 0.1104  Val_Acc: 96.134

Epoch 89: Validation loss decreased (0.110427 --> 0.110420).  Saving model ...
	 Train_Loss: 0.1594 Train_Acc: 94.422 Val_Loss: 0.1104  BEST VAL Loss: 0.1104  Val_Acc: 95.927

Epoch 90: Validation loss decreased (0.110420 --> 0.110388).  Saving model ...
	 Train_Loss: 0.1594 Train_Acc: 94.240 Val_Loss: 0.1104  BEST VAL Loss: 0.1104  Val_Acc: 96.032

Epoch 91: Validation loss decreased (0.110388 --> 0.110335).  Saving model ...
	 Train_Loss: 0.1593 Train_Acc: 94.414 Val_Loss: 0.1103  BEST VAL Loss: 0.1103  Val_Acc: 96.282

Epoch 92: Validation loss decreased (0.110335 --> 0.110262).  Saving model ...
	 Train_Loss: 0.1592 Train_Acc: 94.632 Val_Loss: 0.1103  BEST VAL Loss: 0.1103  Val_Acc: 96.371

Epoch 93: Validation loss decreased (0.110262 --> 0.110209).  Saving model ...
	 Train_Loss: 0.1591 Train_Acc: 94.628 Val_Loss: 0.1102  BEST VAL Loss: 0.1102  Val_Acc: 96.112

Epoch 94: Validation loss decreased (0.110209 --> 0.110117).  Saving model ...
	 Train_Loss: 0.1590 Train_Acc: 94.709 Val_Loss: 0.1101  BEST VAL Loss: 0.1101  Val_Acc: 96.340

Epoch 95: Validation loss decreased (0.110117 --> 0.110031).  Saving model ...
	 Train_Loss: 0.1589 Train_Acc: 94.563 Val_Loss: 0.1100  BEST VAL Loss: 0.1100  Val_Acc: 96.347

Epoch 96: Validation loss decreased (0.110031 --> 0.109927).  Saving model ...
	 Train_Loss: 0.1588 Train_Acc: 94.678 Val_Loss: 0.1099  BEST VAL Loss: 0.1099  Val_Acc: 96.245

Epoch 97: Validation loss decreased (0.109927 --> 0.109829).  Saving model ...
	 Train_Loss: 0.1587 Train_Acc: 94.598 Val_Loss: 0.1098  BEST VAL Loss: 0.1098  Val_Acc: 96.433

Epoch 98: Validation loss decreased (0.109829 --> 0.109730).  Saving model ...
	 Train_Loss: 0.1585 Train_Acc: 94.672 Val_Loss: 0.1097  BEST VAL Loss: 0.1097  Val_Acc: 96.359

Epoch 99: Validation loss decreased (0.109730 --> 0.109674).  Saving model ...
	 Train_Loss: 0.1584 Train_Acc: 94.594 Val_Loss: 0.1097  BEST VAL Loss: 0.1097  Val_Acc: 96.353

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.58      0.58      0.58    149884
           1       0.42      0.42      0.42    109598

    accuracy                           0.51    259482
   macro avg       0.50      0.50      0.50    259482
weighted avg       0.51      0.51      0.51    259482

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.58      0.58      0.58     18736
           1       0.43      0.42      0.42     13700

    accuracy                           0.51     32436
   macro avg       0.50      0.50      0.50     32436
weighted avg       0.51      0.51      0.51     32436

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.58      0.58      0.58     18736
           1       0.42      0.42      0.42     13700

    accuracy                           0.51     32436
   macro avg       0.50      0.50      0.50     32436
weighted avg       0.51      0.51      0.51     32436

              precision    recall  f1-score   support

           0       0.58      0.58      0.58     18736
           1       0.42      0.42      0.42     13700

    accuracy                           0.51     32436
   macro avg       0.50      0.50      0.50     32436
weighted avg       0.51      0.51      0.51     32436

LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_10.0_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.38      0.47      0.43     27774
           1       0.61      0.52      0.56     44168

    accuracy                           0.50     71942
   macro avg       0.50      0.50      0.49     71942
weighted avg       0.52      0.50      0.51     71942

              precision    recall  f1-score   support

           0       0.38      0.47      0.43     27774
           1       0.61      0.52      0.56     44168

    accuracy                           0.50     71942
   macro avg       0.50      0.50      0.49     71942
weighted avg       0.52      0.50      0.51     71942

completed
