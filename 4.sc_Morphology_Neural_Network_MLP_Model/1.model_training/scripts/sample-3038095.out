[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '66d44ef8'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'b4f0d1a6'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '64b35d64'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '22d94014'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_0.100_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_Nigericin_1.000_10.0_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (29330, 1276)
Number of total missing values across all columns: 29856
Data Subset Is Off
Wells held out for testing: ['M16' 'L22']
Wells to use for training, validation, and testing ['M17' 'L18' 'L19' 'M20' 'M21' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.375657).  Saving model ...
	 Train_Loss: 0.6115 Train_Acc: 65.802 Val_Loss: 0.3757  BEST VAL Loss: 0.3757  Val_Acc: 84.770

Epoch 1: Validation loss decreased (0.375657 --> 0.340242).  Saving model ...
	 Train_Loss: 0.5202 Train_Acc: 77.740 Val_Loss: 0.3402  BEST VAL Loss: 0.3402  Val_Acc: 88.660

Epoch 2: Validation loss decreased (0.340242 --> 0.302271).  Saving model ...
	 Train_Loss: 0.4686 Train_Acc: 80.950 Val_Loss: 0.3023  BEST VAL Loss: 0.3023  Val_Acc: 89.831

Epoch 3: Validation loss decreased (0.302271 --> 0.275948).  Saving model ...
	 Train_Loss: 0.4332 Train_Acc: 84.471 Val_Loss: 0.2759  BEST VAL Loss: 0.2759  Val_Acc: 91.565

Epoch 4: Validation loss decreased (0.275948 --> 0.262475).  Saving model ...
	 Train_Loss: 0.4057 Train_Acc: 86.146 Val_Loss: 0.2625  BEST VAL Loss: 0.2625  Val_Acc: 92.924

Epoch 5: Validation loss decreased (0.262475 --> 0.252523).  Saving model ...
	 Train_Loss: 0.3843 Train_Acc: 86.246 Val_Loss: 0.2525  BEST VAL Loss: 0.2525  Val_Acc: 93.346

Epoch 6: Validation loss decreased (0.252523 --> 0.237244).  Saving model ...
	 Train_Loss: 0.3691 Train_Acc: 87.247 Val_Loss: 0.2372  BEST VAL Loss: 0.2372  Val_Acc: 92.596

Epoch 7: Validation loss decreased (0.237244 --> 0.229426).  Saving model ...
	 Train_Loss: 0.3549 Train_Acc: 87.745 Val_Loss: 0.2294  BEST VAL Loss: 0.2294  Val_Acc: 92.690

Epoch 8: Validation loss decreased (0.229426 --> 0.224416).  Saving model ...
	 Train_Loss: 0.3423 Train_Acc: 88.284 Val_Loss: 0.2244  BEST VAL Loss: 0.2244  Val_Acc: 93.346

Epoch 9: Validation loss decreased (0.224416 --> 0.217043).  Saving model ...
	 Train_Loss: 0.3324 Train_Acc: 88.202 Val_Loss: 0.2170  BEST VAL Loss: 0.2170  Val_Acc: 93.018

Epoch 10: Validation loss decreased (0.217043 --> 0.216432).  Saving model ...
	 Train_Loss: 0.3243 Train_Acc: 87.751 Val_Loss: 0.2164  BEST VAL Loss: 0.2164  Val_Acc: 94.424

Epoch 11: Validation loss decreased (0.216432 --> 0.213863).  Saving model ...
	 Train_Loss: 0.3189 Train_Acc: 87.944 Val_Loss: 0.2139  BEST VAL Loss: 0.2139  Val_Acc: 92.221

Epoch 12: Validation loss decreased (0.213863 --> 0.207511).  Saving model ...
	 Train_Loss: 0.3125 Train_Acc: 88.114 Val_Loss: 0.2075  BEST VAL Loss: 0.2075  Val_Acc: 92.924

Epoch 13: Validation loss decreased (0.207511 --> 0.205151).  Saving model ...
	 Train_Loss: 0.3073 Train_Acc: 88.606 Val_Loss: 0.2052  BEST VAL Loss: 0.2052  Val_Acc: 92.362

Epoch 14: Validation loss decreased (0.205151 --> 0.203316).  Saving model ...
	 Train_Loss: 0.3025 Train_Acc: 88.278 Val_Loss: 0.2033  BEST VAL Loss: 0.2033  Val_Acc: 92.362

Epoch 15: Validation loss decreased (0.203316 --> 0.200724).  Saving model ...
	 Train_Loss: 0.2982 Train_Acc: 88.202 Val_Loss: 0.2007  BEST VAL Loss: 0.2007  Val_Acc: 92.502

Epoch 16: Validation loss decreased (0.200724 --> 0.196933).  Saving model ...
	 Train_Loss: 0.2938 Train_Acc: 88.530 Val_Loss: 0.1969  BEST VAL Loss: 0.1969  Val_Acc: 94.002

Epoch 17: Validation loss decreased (0.196933 --> 0.193318).  Saving model ...
	 Train_Loss: 0.2891 Train_Acc: 89.098 Val_Loss: 0.1933  BEST VAL Loss: 0.1933  Val_Acc: 94.330

Epoch 18: Validation loss decreased (0.193318 --> 0.193304).  Saving model ...
	 Train_Loss: 0.2849 Train_Acc: 89.415 Val_Loss: 0.1933  BEST VAL Loss: 0.1933  Val_Acc: 94.330

Epoch 19: Validation loss decreased (0.193304 --> 0.190865).  Saving model ...
	 Train_Loss: 0.2808 Train_Acc: 89.210 Val_Loss: 0.1909  BEST VAL Loss: 0.1909  Val_Acc: 94.283

Epoch 20: Validation loss decreased (0.190865 --> 0.189652).  Saving model ...
	 Train_Loss: 0.2767 Train_Acc: 89.585 Val_Loss: 0.1897  BEST VAL Loss: 0.1897  Val_Acc: 93.908

Epoch 21: Validation loss decreased (0.189652 --> 0.187396).  Saving model ...
	 Train_Loss: 0.2726 Train_Acc: 90.147 Val_Loss: 0.1874  BEST VAL Loss: 0.1874  Val_Acc: 93.861

Epoch 22: Validation loss decreased (0.187396 --> 0.187034).  Saving model ...
	 Train_Loss: 0.2687 Train_Acc: 90.358 Val_Loss: 0.1870  BEST VAL Loss: 0.1870  Val_Acc: 94.377

Epoch 23: Validation loss decreased (0.187034 --> 0.184641).  Saving model ...
	 Train_Loss: 0.2647 Train_Acc: 90.627 Val_Loss: 0.1846  BEST VAL Loss: 0.1846  Val_Acc: 94.049

Epoch 24: Validation loss decreased (0.184641 --> 0.183909).  Saving model ...
	 Train_Loss: 0.2614 Train_Acc: 90.581 Val_Loss: 0.1839  BEST VAL Loss: 0.1839  Val_Acc: 94.658

Epoch 25: Validation loss decreased (0.183909 --> 0.181772).  Saving model ...
	 Train_Loss: 0.2580 Train_Acc: 90.627 Val_Loss: 0.1818  BEST VAL Loss: 0.1818  Val_Acc: 94.658

Epoch 26: Validation loss decreased (0.181772 --> 0.180016).  Saving model ...
	 Train_Loss: 0.2549 Train_Acc: 90.557 Val_Loss: 0.1800  BEST VAL Loss: 0.1800  Val_Acc: 94.283

Epoch 27: Validation loss decreased (0.180016 --> 0.178416).  Saving model ...
	 Train_Loss: 0.2524 Train_Acc: 90.241 Val_Loss: 0.1784  BEST VAL Loss: 0.1784  Val_Acc: 94.845

Epoch 28: Validation loss decreased (0.178416 --> 0.177425).  Saving model ...
	 Train_Loss: 0.2497 Train_Acc: 90.657 Val_Loss: 0.1774  BEST VAL Loss: 0.1774  Val_Acc: 94.424

Epoch 29: Validation loss decreased (0.177425 --> 0.176462).  Saving model ...
	 Train_Loss: 0.2475 Train_Acc: 90.481 Val_Loss: 0.1765  BEST VAL Loss: 0.1765  Val_Acc: 94.705

Epoch 30: Validation loss decreased (0.176462 --> 0.175739).  Saving model ...
	 Train_Loss: 0.2454 Train_Acc: 90.686 Val_Loss: 0.1757  BEST VAL Loss: 0.1757  Val_Acc: 93.814

Epoch 31: Validation loss decreased (0.175739 --> 0.174754).  Saving model ...
	 Train_Loss: 0.2436 Train_Acc: 90.170 Val_Loss: 0.1748  BEST VAL Loss: 0.1748  Val_Acc: 95.127

Epoch 32: Validation loss decreased (0.174754 --> 0.173012).  Saving model ...
	 Train_Loss: 0.2417 Train_Acc: 90.592 Val_Loss: 0.1730  BEST VAL Loss: 0.1730  Val_Acc: 94.283

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.2395 Train_Acc: 90.797 Val_Loss: 0.1731  BEST VAL Loss: 0.1730  Val_Acc: 94.002

Epoch 34: Validation loss decreased (0.173012 --> 0.172269).  Saving model ...
	 Train_Loss: 0.2374 Train_Acc: 91.061 Val_Loss: 0.1723  BEST VAL Loss: 0.1723  Val_Acc: 94.377

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.2353 Train_Acc: 91.365 Val_Loss: 0.1733  BEST VAL Loss: 0.1723  Val_Acc: 94.424

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.2338 Train_Acc: 90.709 Val_Loss: 0.1727  BEST VAL Loss: 0.1723  Val_Acc: 94.658

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.2329 Train_Acc: 90.592 Val_Loss: 0.1734  BEST VAL Loss: 0.1723  Val_Acc: 94.002

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.2320 Train_Acc: 90.188 Val_Loss: 0.1728  BEST VAL Loss: 0.1723  Val_Acc: 94.330

Epoch 39: Validation loss decreased (0.172269 --> 0.171876).  Saving model ...
	 Train_Loss: 0.2306 Train_Acc: 90.569 Val_Loss: 0.1719  BEST VAL Loss: 0.1719  Val_Acc: 94.517

Epoch 40: Validation loss decreased (0.171876 --> 0.171299).  Saving model ...
	 Train_Loss: 0.2293 Train_Acc: 90.551 Val_Loss: 0.1713  BEST VAL Loss: 0.1713  Val_Acc: 94.377

Epoch 41: Validation loss decreased (0.171299 --> 0.170430).  Saving model ...
	 Train_Loss: 0.2276 Train_Acc: 90.850 Val_Loss: 0.1704  BEST VAL Loss: 0.1704  Val_Acc: 94.517

Epoch 42: Validation loss decreased (0.170430 --> 0.168938).  Saving model ...
	 Train_Loss: 0.2262 Train_Acc: 90.686 Val_Loss: 0.1689  BEST VAL Loss: 0.1689  Val_Acc: 94.330

Epoch 43: Validation loss decreased (0.168938 --> 0.167829).  Saving model ...
	 Train_Loss: 0.2249 Train_Acc: 91.032 Val_Loss: 0.1678  BEST VAL Loss: 0.1678  Val_Acc: 94.517

Epoch 44: Validation loss decreased (0.167829 --> 0.166971).  Saving model ...
	 Train_Loss: 0.2235 Train_Acc: 91.219 Val_Loss: 0.1670  BEST VAL Loss: 0.1670  Val_Acc: 94.658

Epoch 45: Validation loss decreased (0.166971 --> 0.166127).  Saving model ...
	 Train_Loss: 0.2223 Train_Acc: 90.914 Val_Loss: 0.1661  BEST VAL Loss: 0.1661  Val_Acc: 95.314

Epoch 46: Validation loss decreased (0.166127 --> 0.165058).  Saving model ...
	 Train_Loss: 0.2213 Train_Acc: 91.617 Val_Loss: 0.1651  BEST VAL Loss: 0.1651  Val_Acc: 95.642

Epoch 47: Validation loss decreased (0.165058 --> 0.164657).  Saving model ...
	 Train_Loss: 0.2203 Train_Acc: 91.166 Val_Loss: 0.1647  BEST VAL Loss: 0.1647  Val_Acc: 94.424

Epoch 48: Validation loss decreased (0.164657 --> 0.163749).  Saving model ...
	 Train_Loss: 0.2192 Train_Acc: 90.692 Val_Loss: 0.1637  BEST VAL Loss: 0.1637  Val_Acc: 94.986

Epoch 49: Validation loss decreased (0.163749 --> 0.163009).  Saving model ...
	 Train_Loss: 0.2180 Train_Acc: 91.459 Val_Loss: 0.1630  BEST VAL Loss: 0.1630  Val_Acc: 94.845

Epoch 50: Validation loss decreased (0.163009 --> 0.162403).  Saving model ...
	 Train_Loss: 0.2169 Train_Acc: 91.020 Val_Loss: 0.1624  BEST VAL Loss: 0.1624  Val_Acc: 94.424

Epoch 51: Validation loss decreased (0.162403 --> 0.161623).  Saving model ...
	 Train_Loss: 0.2159 Train_Acc: 91.231 Val_Loss: 0.1616  BEST VAL Loss: 0.1616  Val_Acc: 95.267

Epoch 52: Validation loss decreased (0.161623 --> 0.161023).  Saving model ...
	 Train_Loss: 0.2149 Train_Acc: 91.090 Val_Loss: 0.1610  BEST VAL Loss: 0.1610  Val_Acc: 95.080

Epoch 53: Validation loss decreased (0.161023 --> 0.160121).  Saving model ...
	 Train_Loss: 0.2139 Train_Acc: 91.155 Val_Loss: 0.1601  BEST VAL Loss: 0.1601  Val_Acc: 94.049

Epoch 54: Validation loss decreased (0.160121 --> 0.159386).  Saving model ...
	 Train_Loss: 0.2130 Train_Acc: 91.096 Val_Loss: 0.1594  BEST VAL Loss: 0.1594  Val_Acc: 94.377

Epoch 55: Validation loss decreased (0.159386 --> 0.158697).  Saving model ...
	 Train_Loss: 0.2121 Train_Acc: 91.008 Val_Loss: 0.1587  BEST VAL Loss: 0.1587  Val_Acc: 95.173

Epoch 56: Validation loss decreased (0.158697 --> 0.158124).  Saving model ...
	 Train_Loss: 0.2112 Train_Acc: 91.664 Val_Loss: 0.1581  BEST VAL Loss: 0.1581  Val_Acc: 95.736

Epoch 57: Validation loss decreased (0.158124 --> 0.157070).  Saving model ...
	 Train_Loss: 0.2103 Train_Acc: 91.817 Val_Loss: 0.1571  BEST VAL Loss: 0.1571  Val_Acc: 95.501

Epoch 58: Validation loss decreased (0.157070 --> 0.156862).  Saving model ...
	 Train_Loss: 0.2094 Train_Acc: 91.330 Val_Loss: 0.1569  BEST VAL Loss: 0.1569  Val_Acc: 95.455

Epoch 59: Validation loss decreased (0.156862 --> 0.156075).  Saving model ...
	 Train_Loss: 0.2084 Train_Acc: 91.389 Val_Loss: 0.1561  BEST VAL Loss: 0.1561  Val_Acc: 95.829

Epoch 60: Validation loss decreased (0.156075 --> 0.155653).  Saving model ...
	 Train_Loss: 0.2076 Train_Acc: 91.670 Val_Loss: 0.1557  BEST VAL Loss: 0.1557  Val_Acc: 95.455

Epoch 61: Validation loss decreased (0.155653 --> 0.155054).  Saving model ...
	 Train_Loss: 0.2069 Train_Acc: 91.565 Val_Loss: 0.1551  BEST VAL Loss: 0.1551  Val_Acc: 95.548

Epoch 62: Validation loss decreased (0.155054 --> 0.154355).  Saving model ...
	 Train_Loss: 0.2063 Train_Acc: 90.803 Val_Loss: 0.1544  BEST VAL Loss: 0.1544  Val_Acc: 95.361

Epoch 63: Validation loss decreased (0.154355 --> 0.154140).  Saving model ...
	 Train_Loss: 0.2055 Train_Acc: 91.354 Val_Loss: 0.1541  BEST VAL Loss: 0.1541  Val_Acc: 95.408

Epoch 64: Validation loss decreased (0.154140 --> 0.153376).  Saving model ...
	 Train_Loss: 0.2050 Train_Acc: 90.897 Val_Loss: 0.1534  BEST VAL Loss: 0.1534  Val_Acc: 95.033

Epoch 65: Validation loss decreased (0.153376 --> 0.152923).  Saving model ...
	 Train_Loss: 0.2042 Train_Acc: 91.342 Val_Loss: 0.1529  BEST VAL Loss: 0.1529  Val_Acc: 95.361

Epoch 66: Validation loss decreased (0.152923 --> 0.152490).  Saving model ...
	 Train_Loss: 0.2034 Train_Acc: 91.512 Val_Loss: 0.1525  BEST VAL Loss: 0.1525  Val_Acc: 95.127

Epoch 67: Validation loss decreased (0.152490 --> 0.152064).  Saving model ...
	 Train_Loss: 0.2027 Train_Acc: 91.465 Val_Loss: 0.1521  BEST VAL Loss: 0.1521  Val_Acc: 95.267

Epoch 68: Validation loss decreased (0.152064 --> 0.151795).  Saving model ...
	 Train_Loss: 0.2020 Train_Acc: 91.916 Val_Loss: 0.1518  BEST VAL Loss: 0.1518  Val_Acc: 94.236

Epoch 69: Validation loss decreased (0.151795 --> 0.151563).  Saving model ...
	 Train_Loss: 0.2014 Train_Acc: 91.201 Val_Loss: 0.1516  BEST VAL Loss: 0.1516  Val_Acc: 96.017

Epoch 70: Validation loss decreased (0.151563 --> 0.150992).  Saving model ...
	 Train_Loss: 0.2007 Train_Acc: 91.863 Val_Loss: 0.1510  BEST VAL Loss: 0.1510  Val_Acc: 96.017

Epoch 71: Validation loss decreased (0.150992 --> 0.150557).  Saving model ...
	 Train_Loss: 0.1999 Train_Acc: 91.858 Val_Loss: 0.1506  BEST VAL Loss: 0.1506  Val_Acc: 95.642

Epoch 72: Validation loss decreased (0.150557 --> 0.150276).  Saving model ...
	 Train_Loss: 0.1991 Train_Acc: 91.940 Val_Loss: 0.1503  BEST VAL Loss: 0.1503  Val_Acc: 95.408

Epoch 73: Validation loss decreased (0.150276 --> 0.150264).  Saving model ...
	 Train_Loss: 0.1983 Train_Acc: 92.191 Val_Loss: 0.1503  BEST VAL Loss: 0.1503  Val_Acc: 95.361

Epoch 74: Validation loss decreased (0.150264 --> 0.149935).  Saving model ...
	 Train_Loss: 0.1975 Train_Acc: 92.303 Val_Loss: 0.1499  BEST VAL Loss: 0.1499  Val_Acc: 95.501

Epoch 75: Validation loss decreased (0.149935 --> 0.149838).  Saving model ...
	 Train_Loss: 0.1970 Train_Acc: 91.061 Val_Loss: 0.1498  BEST VAL Loss: 0.1498  Val_Acc: 95.501

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.1966 Train_Acc: 90.692 Val_Loss: 0.1508  BEST VAL Loss: 0.1498  Val_Acc: 94.799

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.1959 Train_Acc: 92.051 Val_Loss: 0.1507  BEST VAL Loss: 0.1498  Val_Acc: 95.314

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.1954 Train_Acc: 91.664 Val_Loss: 0.1502  BEST VAL Loss: 0.1498  Val_Acc: 94.939

Epoch 79: Validation loss did not decrease
	 Train_Loss: 0.1950 Train_Acc: 91.770 Val_Loss: 0.1505  BEST VAL Loss: 0.1498  Val_Acc: 95.689

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.1944 Train_Acc: 91.805 Val_Loss: 0.1505  BEST VAL Loss: 0.1498  Val_Acc: 95.736

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.1938 Train_Acc: 91.834 Val_Loss: 0.1510  BEST VAL Loss: 0.1498  Val_Acc: 94.564

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.1933 Train_Acc: 91.541 Val_Loss: 0.1506  BEST VAL Loss: 0.1498  Val_Acc: 95.783

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.1928 Train_Acc: 92.068 Val_Loss: 0.1500  BEST VAL Loss: 0.1498  Val_Acc: 96.439

Epoch 84: Validation loss decreased (0.149838 --> 0.149757).  Saving model ...
	 Train_Loss: 0.1922 Train_Acc: 91.852 Val_Loss: 0.1498  BEST VAL Loss: 0.1498  Val_Acc: 95.314

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.1916 Train_Acc: 91.922 Val_Loss: 0.1499  BEST VAL Loss: 0.1498  Val_Acc: 95.783

Epoch 86: Validation loss decreased (0.149757 --> 0.149651).  Saving model ...
	 Train_Loss: 0.1910 Train_Acc: 91.863 Val_Loss: 0.1497  BEST VAL Loss: 0.1497  Val_Acc: 96.111

Epoch 87: Validation loss decreased (0.149651 --> 0.149296).  Saving model ...
	 Train_Loss: 0.1904 Train_Acc: 91.916 Val_Loss: 0.1493  BEST VAL Loss: 0.1493  Val_Acc: 96.392

Epoch 88: Validation loss decreased (0.149296 --> 0.149051).  Saving model ...
	 Train_Loss: 0.1898 Train_Acc: 92.250 Val_Loss: 0.1491  BEST VAL Loss: 0.1491  Val_Acc: 96.157

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.1893 Train_Acc: 92.490 Val_Loss: 0.1491  BEST VAL Loss: 0.1491  Val_Acc: 94.986

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.1888 Train_Acc: 91.981 Val_Loss: 0.1513  BEST VAL Loss: 0.1491  Val_Acc: 94.283

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.1889 Train_Acc: 90.176 Val_Loss: 0.1510  BEST VAL Loss: 0.1491  Val_Acc: 95.314

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.1890 Train_Acc: 90.124 Val_Loss: 0.1506  BEST VAL Loss: 0.1491  Val_Acc: 95.361

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.1890 Train_Acc: 90.499 Val_Loss: 0.1505  BEST VAL Loss: 0.1491  Val_Acc: 95.080

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.1889 Train_Acc: 90.827 Val_Loss: 0.1505  BEST VAL Loss: 0.1491  Val_Acc: 94.330

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.1888 Train_Acc: 90.920 Val_Loss: 0.1503  BEST VAL Loss: 0.1491  Val_Acc: 95.173

Epoch 96: Validation loss did not decrease
	 Train_Loss: 0.1886 Train_Acc: 91.207 Val_Loss: 0.1505  BEST VAL Loss: 0.1491  Val_Acc: 95.361

Epoch 97: Validation loss did not decrease
	 Train_Loss: 0.1883 Train_Acc: 91.453 Val_Loss: 0.1503  BEST VAL Loss: 0.1491  Val_Acc: 95.220

Epoch 98: Validation loss did not decrease
	 Train_Loss: 0.1881 Train_Acc: 91.172 Val_Loss: 0.1500  BEST VAL Loss: 0.1491  Val_Acc: 95.314

Epoch 99: Validation loss did not decrease
	 Train_Loss: 0.1878 Train_Acc: 91.471 Val_Loss: 0.1496  BEST VAL Loss: 0.1491  Val_Acc: 95.642

Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.49      0.50      8635
           1       0.50      0.52      0.51      8436

    accuracy                           0.50     17071
   macro avg       0.51      0.51      0.50     17071
weighted avg       0.51      0.50      0.50     17071

Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.48      0.49      1079
           1       0.48      0.50      0.49      1055

    accuracy                           0.49      2134
   macro avg       0.49      0.49      0.49      2134
weighted avg       0.49      0.49      0.49      2134

Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.46      0.47      1079
           1       0.47      0.50      0.48      1055

    accuracy                           0.48      2134
   macro avg       0.48      0.48      0.48      2134
weighted avg       0.48      0.48      0.48      2134

              precision    recall  f1-score   support

           0       0.48      0.46      0.47      1079
           1       0.47      0.50      0.48      1055

    accuracy                           0.48      2134
   macro avg       0.48      0.48      0.48      2134
weighted avg       0.48      0.48      0.48      2134

Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.50      0.51      4135
           1       0.48      0.49      0.49      3856

    accuracy                           0.50      7991
   macro avg       0.50      0.50      0.50      7991
weighted avg       0.50      0.50      0.50      7991

              precision    recall  f1-score   support

           0       0.51      0.50      0.51      4135
           1       0.48      0.49      0.49      3856

    accuracy                           0.50      7991
   macro avg       0.50      0.50      0.50      7991
weighted avg       0.50      0.50      0.50      7991

completed
