[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '3bbf1a76'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'a1e3d603'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '5912e348'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '6507df40'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: H2O2_100.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['H2O2_100.000_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (406549, 1270)
Number of total missing values across all columns: 481072
Data Subset Is Off
Wells held out for testing: ['I10' 'K08']
Wells to use for training, validation, and testing ['H04' 'I04' 'H05' 'I05' 'H10' 'H11' 'I11' 'K02' 'K03' 'K09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.269333).  Saving model ...
	 Train_Loss: 0.3796 Train_Acc: 83.168 Val_Loss: 0.2693  BEST VAL Loss: 0.2693  Val_Acc: 88.627

Epoch 1: Validation loss decreased (0.269333 --> 0.255967).  Saving model ...
	 Train_Loss: 0.3457 Train_Acc: 86.941 Val_Loss: 0.2560  BEST VAL Loss: 0.2560  Val_Acc: 89.857

Epoch 2: Validation loss decreased (0.255967 --> 0.249692).  Saving model ...
	 Train_Loss: 0.3284 Train_Acc: 87.863 Val_Loss: 0.2497  BEST VAL Loss: 0.2497  Val_Acc: 90.091

Epoch 3: Validation loss decreased (0.249692 --> 0.245917).  Saving model ...
	 Train_Loss: 0.3170 Train_Acc: 88.325 Val_Loss: 0.2459  BEST VAL Loss: 0.2459  Val_Acc: 90.474

Epoch 4: Validation loss decreased (0.245917 --> 0.241928).  Saving model ...
	 Train_Loss: 0.3086 Train_Acc: 88.689 Val_Loss: 0.2419  BEST VAL Loss: 0.2419  Val_Acc: 90.687

Epoch 5: Validation loss decreased (0.241928 --> 0.238407).  Saving model ...
	 Train_Loss: 0.3024 Train_Acc: 88.921 Val_Loss: 0.2384  BEST VAL Loss: 0.2384  Val_Acc: 90.989

Epoch 6: Validation loss decreased (0.238407 --> 0.235145).  Saving model ...
	 Train_Loss: 0.2972 Train_Acc: 89.192 Val_Loss: 0.2351  BEST VAL Loss: 0.2351  Val_Acc: 91.152

Epoch 7: Validation loss decreased (0.235145 --> 0.232515).  Saving model ...
	 Train_Loss: 0.2929 Train_Acc: 89.225 Val_Loss: 0.2325  BEST VAL Loss: 0.2325  Val_Acc: 91.075

Epoch 8: Validation loss decreased (0.232515 --> 0.230589).  Saving model ...
	 Train_Loss: 0.2893 Train_Acc: 89.397 Val_Loss: 0.2306  BEST VAL Loss: 0.2306  Val_Acc: 91.268

Epoch 9: Validation loss decreased (0.230589 --> 0.228512).  Saving model ...
	 Train_Loss: 0.2861 Train_Acc: 89.496 Val_Loss: 0.2285  BEST VAL Loss: 0.2285  Val_Acc: 91.348

Epoch 10: Validation loss decreased (0.228512 --> 0.227027).  Saving model ...
	 Train_Loss: 0.2835 Train_Acc: 89.544 Val_Loss: 0.2270  BEST VAL Loss: 0.2270  Val_Acc: 91.413

Epoch 11: Validation loss decreased (0.227027 --> 0.225601).  Saving model ...
	 Train_Loss: 0.2810 Train_Acc: 89.667 Val_Loss: 0.2256  BEST VAL Loss: 0.2256  Val_Acc: 91.167

Epoch 12: Validation loss decreased (0.225601 --> 0.224538).  Saving model ...
	 Train_Loss: 0.2789 Train_Acc: 89.708 Val_Loss: 0.2245  BEST VAL Loss: 0.2245  Val_Acc: 91.188

Epoch 13: Validation loss decreased (0.224538 --> 0.223493).  Saving model ...
	 Train_Loss: 0.2769 Train_Acc: 89.789 Val_Loss: 0.2235  BEST VAL Loss: 0.2235  Val_Acc: 91.378

Epoch 14: Validation loss decreased (0.223493 --> 0.222196).  Saving model ...
	 Train_Loss: 0.2752 Train_Acc: 89.841 Val_Loss: 0.2222  BEST VAL Loss: 0.2222  Val_Acc: 91.653

Epoch 15: Validation loss decreased (0.222196 --> 0.220851).  Saving model ...
	 Train_Loss: 0.2735 Train_Acc: 89.881 Val_Loss: 0.2209  BEST VAL Loss: 0.2209  Val_Acc: 91.846

Epoch 16: Validation loss decreased (0.220851 --> 0.219796).  Saving model ...
	 Train_Loss: 0.2720 Train_Acc: 89.952 Val_Loss: 0.2198  BEST VAL Loss: 0.2198  Val_Acc: 91.739

Epoch 17: Validation loss decreased (0.219796 --> 0.218478).  Saving model ...
	 Train_Loss: 0.2706 Train_Acc: 90.006 Val_Loss: 0.2185  BEST VAL Loss: 0.2185  Val_Acc: 92.095

Epoch 18: Validation loss decreased (0.218478 --> 0.217790).  Saving model ...
	 Train_Loss: 0.2693 Train_Acc: 90.055 Val_Loss: 0.2178  BEST VAL Loss: 0.2178  Val_Acc: 91.707

Epoch 19: Validation loss decreased (0.217790 --> 0.216827).  Saving model ...
	 Train_Loss: 0.2680 Train_Acc: 90.114 Val_Loss: 0.2168  BEST VAL Loss: 0.2168  Val_Acc: 91.970

Epoch 20: Validation loss decreased (0.216827 --> 0.216047).  Saving model ...
	 Train_Loss: 0.2669 Train_Acc: 90.110 Val_Loss: 0.2160  BEST VAL Loss: 0.2160  Val_Acc: 91.858

Epoch 21: Validation loss decreased (0.216047 --> 0.215242).  Saving model ...
	 Train_Loss: 0.2658 Train_Acc: 90.171 Val_Loss: 0.2152  BEST VAL Loss: 0.2152  Val_Acc: 92.039

Epoch 22: Validation loss decreased (0.215242 --> 0.214449).  Saving model ...
	 Train_Loss: 0.2647 Train_Acc: 90.254 Val_Loss: 0.2144  BEST VAL Loss: 0.2144  Val_Acc: 92.018

Epoch 23: Validation loss decreased (0.214449 --> 0.213918).  Saving model ...
	 Train_Loss: 0.2637 Train_Acc: 90.188 Val_Loss: 0.2139  BEST VAL Loss: 0.2139  Val_Acc: 91.941

Epoch 24: Validation loss decreased (0.213918 --> 0.213283).  Saving model ...
	 Train_Loss: 0.2627 Train_Acc: 90.268 Val_Loss: 0.2133  BEST VAL Loss: 0.2133  Val_Acc: 91.959

Epoch 25: Validation loss decreased (0.213283 --> 0.212633).  Saving model ...
	 Train_Loss: 0.2619 Train_Acc: 90.278 Val_Loss: 0.2126  BEST VAL Loss: 0.2126  Val_Acc: 92.074

Epoch 26: Validation loss decreased (0.212633 --> 0.212000).  Saving model ...
	 Train_Loss: 0.2610 Train_Acc: 90.336 Val_Loss: 0.2120  BEST VAL Loss: 0.2120  Val_Acc: 92.294

Epoch 27: Validation loss decreased (0.212000 --> 0.211437).  Saving model ...
	 Train_Loss: 0.2602 Train_Acc: 90.353 Val_Loss: 0.2114  BEST VAL Loss: 0.2114  Val_Acc: 92.163

Epoch 28: Validation loss decreased (0.211437 --> 0.211080).  Saving model ...
	 Train_Loss: 0.2594 Train_Acc: 90.374 Val_Loss: 0.2111  BEST VAL Loss: 0.2111  Val_Acc: 91.923

Epoch 29: Validation loss decreased (0.211080 --> 0.210482).  Saving model ...
	 Train_Loss: 0.2586 Train_Acc: 90.409 Val_Loss: 0.2105  BEST VAL Loss: 0.2105  Val_Acc: 92.169

Epoch 30: Validation loss decreased (0.210482 --> 0.210078).  Saving model ...
	 Train_Loss: 0.2579 Train_Acc: 90.489 Val_Loss: 0.2101  BEST VAL Loss: 0.2101  Val_Acc: 92.157

Epoch 31: Validation loss decreased (0.210078 --> 0.209585).  Saving model ...
	 Train_Loss: 0.2572 Train_Acc: 90.602 Val_Loss: 0.2096  BEST VAL Loss: 0.2096  Val_Acc: 92.163

Epoch 32: Validation loss decreased (0.209585 --> 0.209103).  Saving model ...
	 Train_Loss: 0.2565 Train_Acc: 90.453 Val_Loss: 0.2091  BEST VAL Loss: 0.2091  Val_Acc: 92.421

Epoch 33: Validation loss decreased (0.209103 --> 0.208617).  Saving model ...
	 Train_Loss: 0.2558 Train_Acc: 90.503 Val_Loss: 0.2086  BEST VAL Loss: 0.2086  Val_Acc: 92.380

Epoch 34: Validation loss decreased (0.208617 --> 0.207995).  Saving model ...
	 Train_Loss: 0.2552 Train_Acc: 90.493 Val_Loss: 0.2080  BEST VAL Loss: 0.2080  Val_Acc: 92.611

Epoch 35: Validation loss decreased (0.207995 --> 0.207535).  Saving model ...
	 Train_Loss: 0.2545 Train_Acc: 90.578 Val_Loss: 0.2075  BEST VAL Loss: 0.2075  Val_Acc: 92.320

Epoch 36: Validation loss decreased (0.207535 --> 0.207110).  Saving model ...
	 Train_Loss: 0.2539 Train_Acc: 90.655 Val_Loss: 0.2071  BEST VAL Loss: 0.2071  Val_Acc: 92.252

Epoch 37: Validation loss decreased (0.207110 --> 0.206657).  Saving model ...
	 Train_Loss: 0.2534 Train_Acc: 90.672 Val_Loss: 0.2067  BEST VAL Loss: 0.2067  Val_Acc: 92.593

Epoch 38: Validation loss decreased (0.206657 --> 0.206200).  Saving model ...
	 Train_Loss: 0.2528 Train_Acc: 90.681 Val_Loss: 0.2062  BEST VAL Loss: 0.2062  Val_Acc: 92.646

Epoch 39: Validation loss decreased (0.206200 --> 0.205935).  Saving model ...
	 Train_Loss: 0.2523 Train_Acc: 90.727 Val_Loss: 0.2059  BEST VAL Loss: 0.2059  Val_Acc: 92.062

Epoch 40: Validation loss decreased (0.205935 --> 0.205569).  Saving model ...
	 Train_Loss: 0.2517 Train_Acc: 90.828 Val_Loss: 0.2056  BEST VAL Loss: 0.2056  Val_Acc: 92.335

Epoch 41: Validation loss decreased (0.205569 --> 0.205196).  Saving model ...
	 Train_Loss: 0.2512 Train_Acc: 90.809 Val_Loss: 0.2052  BEST VAL Loss: 0.2052  Val_Acc: 92.486

Epoch 42: Validation loss decreased (0.205196 --> 0.204942).  Saving model ...
	 Train_Loss: 0.2507 Train_Acc: 90.798 Val_Loss: 0.2049  BEST VAL Loss: 0.2049  Val_Acc: 92.024

Epoch 43: Validation loss decreased (0.204942 --> 0.204538).  Saving model ...
	 Train_Loss: 0.2502 Train_Acc: 90.796 Val_Loss: 0.2045  BEST VAL Loss: 0.2045  Val_Acc: 92.504

Epoch 44: Validation loss decreased (0.204538 --> 0.204095).  Saving model ...
	 Train_Loss: 0.2497 Train_Acc: 90.863 Val_Loss: 0.2041  BEST VAL Loss: 0.2041  Val_Acc: 92.753

Epoch 45: Validation loss decreased (0.204095 --> 0.203808).  Saving model ...
	 Train_Loss: 0.2492 Train_Acc: 90.895 Val_Loss: 0.2038  BEST VAL Loss: 0.2038  Val_Acc: 92.314

Epoch 46: Validation loss decreased (0.203808 --> 0.203470).  Saving model ...
	 Train_Loss: 0.2488 Train_Acc: 90.834 Val_Loss: 0.2035  BEST VAL Loss: 0.2035  Val_Acc: 92.578

Epoch 47: Validation loss decreased (0.203470 --> 0.203201).  Saving model ...
	 Train_Loss: 0.2483 Train_Acc: 90.872 Val_Loss: 0.2032  BEST VAL Loss: 0.2032  Val_Acc: 92.640

Epoch 48: Validation loss decreased (0.203201 --> 0.202921).  Saving model ...
	 Train_Loss: 0.2478 Train_Acc: 90.949 Val_Loss: 0.2029  BEST VAL Loss: 0.2029  Val_Acc: 92.365

Epoch 49: Validation loss decreased (0.202921 --> 0.202700).  Saving model ...
	 Train_Loss: 0.2474 Train_Acc: 90.910 Val_Loss: 0.2027  BEST VAL Loss: 0.2027  Val_Acc: 92.557

Epoch 50: Validation loss decreased (0.202700 --> 0.202395).  Saving model ...
	 Train_Loss: 0.2470 Train_Acc: 90.877 Val_Loss: 0.2024  BEST VAL Loss: 0.2024  Val_Acc: 92.569

Epoch 51: Validation loss decreased (0.202395 --> 0.202102).  Saving model ...
	 Train_Loss: 0.2466 Train_Acc: 90.877 Val_Loss: 0.2021  BEST VAL Loss: 0.2021  Val_Acc: 92.534

Epoch 52: Validation loss decreased (0.202102 --> 0.201844).  Saving model ...
	 Train_Loss: 0.2462 Train_Acc: 90.994 Val_Loss: 0.2018  BEST VAL Loss: 0.2018  Val_Acc: 92.430

Epoch 53: Validation loss decreased (0.201844 --> 0.201525).  Saving model ...
	 Train_Loss: 0.2458 Train_Acc: 91.046 Val_Loss: 0.2015  BEST VAL Loss: 0.2015  Val_Acc: 92.510

Epoch 54: Validation loss decreased (0.201525 --> 0.201179).  Saving model ...
	 Train_Loss: 0.2454 Train_Acc: 90.997 Val_Loss: 0.2012  BEST VAL Loss: 0.2012  Val_Acc: 92.765

Epoch 55: Validation loss decreased (0.201179 --> 0.200902).  Saving model ...
	 Train_Loss: 0.2451 Train_Acc: 90.972 Val_Loss: 0.2009  BEST VAL Loss: 0.2009  Val_Acc: 92.664

Epoch 56: Validation loss decreased (0.200902 --> 0.200706).  Saving model ...
	 Train_Loss: 0.2447 Train_Acc: 91.030 Val_Loss: 0.2007  BEST VAL Loss: 0.2007  Val_Acc: 92.777

Epoch 57: Validation loss decreased (0.200706 --> 0.200414).  Saving model ...
	 Train_Loss: 0.2444 Train_Acc: 91.014 Val_Loss: 0.2004  BEST VAL Loss: 0.2004  Val_Acc: 92.741

Epoch 58: Validation loss decreased (0.200414 --> 0.200187).  Saving model ...
	 Train_Loss: 0.2440 Train_Acc: 91.101 Val_Loss: 0.2002  BEST VAL Loss: 0.2002  Val_Acc: 92.611

Epoch 59: Validation loss decreased (0.200187 --> 0.199985).  Saving model ...
	 Train_Loss: 0.2437 Train_Acc: 91.124 Val_Loss: 0.2000  BEST VAL Loss: 0.2000  Val_Acc: 92.827

Epoch 60: Validation loss decreased (0.199985 --> 0.199789).  Saving model ...
	 Train_Loss: 0.2433 Train_Acc: 91.065 Val_Loss: 0.1998  BEST VAL Loss: 0.1998  Val_Acc: 92.670

Epoch 61: Validation loss decreased (0.199789 --> 0.199632).  Saving model ...
	 Train_Loss: 0.2430 Train_Acc: 91.092 Val_Loss: 0.1996  BEST VAL Loss: 0.1996  Val_Acc: 92.640

Epoch 62: Validation loss decreased (0.199632 --> 0.199389).  Saving model ...
	 Train_Loss: 0.2427 Train_Acc: 91.043 Val_Loss: 0.1994  BEST VAL Loss: 0.1994  Val_Acc: 92.830

Epoch 63: Validation loss decreased (0.199389 --> 0.199194).  Saving model ...
	 Train_Loss: 0.2424 Train_Acc: 91.091 Val_Loss: 0.1992  BEST VAL Loss: 0.1992  Val_Acc: 92.794

Epoch 64: Validation loss decreased (0.199194 --> 0.198949).  Saving model ...
	 Train_Loss: 0.2421 Train_Acc: 91.090 Val_Loss: 0.1989  BEST VAL Loss: 0.1989  Val_Acc: 92.774

Epoch 65: Validation loss decreased (0.198949 --> 0.198739).  Saving model ...
	 Train_Loss: 0.2418 Train_Acc: 91.154 Val_Loss: 0.1987  BEST VAL Loss: 0.1987  Val_Acc: 92.851

Epoch 66: Validation loss decreased (0.198739 --> 0.198482).  Saving model ...
	 Train_Loss: 0.2415 Train_Acc: 91.231 Val_Loss: 0.1985  BEST VAL Loss: 0.1985  Val_Acc: 92.969

Epoch 67: Validation loss decreased (0.198482 --> 0.198316).  Saving model ...
	 Train_Loss: 0.2412 Train_Acc: 91.120 Val_Loss: 0.1983  BEST VAL Loss: 0.1983  Val_Acc: 92.821

Epoch 68: Validation loss decreased (0.198316 --> 0.198121).  Saving model ...
	 Train_Loss: 0.2409 Train_Acc: 91.220 Val_Loss: 0.1981  BEST VAL Loss: 0.1981  Val_Acc: 92.703

Epoch 69: Validation loss decreased (0.198121 --> 0.197888).  Saving model ...
	 Train_Loss: 0.2406 Train_Acc: 91.245 Val_Loss: 0.1979  BEST VAL Loss: 0.1979  Val_Acc: 92.845

Epoch 70: Validation loss decreased (0.197888 --> 0.197731).  Saving model ...
	 Train_Loss: 0.2403 Train_Acc: 91.335 Val_Loss: 0.1977  BEST VAL Loss: 0.1977  Val_Acc: 92.800

Epoch 71: Validation loss decreased (0.197731 --> 0.197516).  Saving model ...
	 Train_Loss: 0.2400 Train_Acc: 91.271 Val_Loss: 0.1975  BEST VAL Loss: 0.1975  Val_Acc: 92.830

Epoch 72: Validation loss decreased (0.197516 --> 0.197387).  Saving model ...
	 Train_Loss: 0.2398 Train_Acc: 91.209 Val_Loss: 0.1974  BEST VAL Loss: 0.1974  Val_Acc: 92.877

Epoch 73: Validation loss decreased (0.197387 --> 0.197208).  Saving model ...
	 Train_Loss: 0.2395 Train_Acc: 91.269 Val_Loss: 0.1972  BEST VAL Loss: 0.1972  Val_Acc: 92.759

Epoch 74: Validation loss decreased (0.197208 --> 0.197031).  Saving model ...
	 Train_Loss: 0.2393 Train_Acc: 91.301 Val_Loss: 0.1970  BEST VAL Loss: 0.1970  Val_Acc: 92.780

Epoch 75: Validation loss decreased (0.197031 --> 0.196881).  Saving model ...
	 Train_Loss: 0.2390 Train_Acc: 91.332 Val_Loss: 0.1969  BEST VAL Loss: 0.1969  Val_Acc: 92.916

Epoch 76: Validation loss decreased (0.196881 --> 0.196696).  Saving model ...
	 Train_Loss: 0.2388 Train_Acc: 91.270 Val_Loss: 0.1967  BEST VAL Loss: 0.1967  Val_Acc: 92.723

Epoch 77: Validation loss decreased (0.196696 --> 0.196595).  Saving model ...
	 Train_Loss: 0.2385 Train_Acc: 91.350 Val_Loss: 0.1966  BEST VAL Loss: 0.1966  Val_Acc: 92.297

Epoch 78: Validation loss decreased (0.196595 --> 0.196570).  Saving model ...
	 Train_Loss: 0.2383 Train_Acc: 91.321 Val_Loss: 0.1966  BEST VAL Loss: 0.1966  Val_Acc: 92.009

Epoch 79: Validation loss decreased (0.196570 --> 0.196425).  Saving model ...
	 Train_Loss: 0.2380 Train_Acc: 91.260 Val_Loss: 0.1964  BEST VAL Loss: 0.1964  Val_Acc: 92.768

Epoch 80: Validation loss decreased (0.196425 --> 0.196257).  Saving model ...
	 Train_Loss: 0.2378 Train_Acc: 91.400 Val_Loss: 0.1963  BEST VAL Loss: 0.1963  Val_Acc: 93.008

Epoch 81: Validation loss decreased (0.196257 --> 0.196096).  Saving model ...
	 Train_Loss: 0.2375 Train_Acc: 91.436 Val_Loss: 0.1961  BEST VAL Loss: 0.1961  Val_Acc: 92.732

Epoch 82: Validation loss decreased (0.196096 --> 0.195935).  Saving model ...
	 Train_Loss: 0.2373 Train_Acc: 91.402 Val_Loss: 0.1959  BEST VAL Loss: 0.1959  Val_Acc: 92.685

Epoch 83: Validation loss decreased (0.195935 --> 0.195791).  Saving model ...
	 Train_Loss: 0.2371 Train_Acc: 91.462 Val_Loss: 0.1958  BEST VAL Loss: 0.1958  Val_Acc: 92.750

Epoch 84: Validation loss decreased (0.195791 --> 0.195665).  Saving model ...
	 Train_Loss: 0.2369 Train_Acc: 91.471 Val_Loss: 0.1957  BEST VAL Loss: 0.1957  Val_Acc: 92.664

Epoch 85: Validation loss decreased (0.195665 --> 0.195542).  Saving model ...
	 Train_Loss: 0.2367 Train_Acc: 91.408 Val_Loss: 0.1955  BEST VAL Loss: 0.1955  Val_Acc: 92.928

Epoch 86: Validation loss decreased (0.195542 --> 0.195420).  Saving model ...
	 Train_Loss: 0.2365 Train_Acc: 91.546 Val_Loss: 0.1954  BEST VAL Loss: 0.1954  Val_Acc: 93.088

Epoch 87: Validation loss decreased (0.195420 --> 0.195377).  Saving model ...
	 Train_Loss: 0.2362 Train_Acc: 91.514 Val_Loss: 0.1954  BEST VAL Loss: 0.1954  Val_Acc: 92.691

Epoch 88: Validation loss decreased (0.195377 --> 0.195272).  Saving model ...
	 Train_Loss: 0.2360 Train_Acc: 91.488 Val_Loss: 0.1953  BEST VAL Loss: 0.1953  Val_Acc: 92.756

Epoch 89: Validation loss decreased (0.195272 --> 0.195158).  Saving model ...
	 Train_Loss: 0.2358 Train_Acc: 91.394 Val_Loss: 0.1952  BEST VAL Loss: 0.1952  Val_Acc: 92.584

Epoch 90: Validation loss decreased (0.195158 --> 0.195031).  Saving model ...
	 Train_Loss: 0.2356 Train_Acc: 91.525 Val_Loss: 0.1950  BEST VAL Loss: 0.1950  Val_Acc: 92.978

Epoch 91: Validation loss decreased (0.195031 --> 0.194946).  Saving model ...
	 Train_Loss: 0.2354 Train_Acc: 91.528 Val_Loss: 0.1949  BEST VAL Loss: 0.1949  Val_Acc: 92.620

Epoch 92: Validation loss decreased (0.194946 --> 0.194834).  Saving model ...
	 Train_Loss: 0.2352 Train_Acc: 91.571 Val_Loss: 0.1948  BEST VAL Loss: 0.1948  Val_Acc: 92.774

Epoch 93: Validation loss decreased (0.194834 --> 0.194696).  Saving model ...
	 Train_Loss: 0.2350 Train_Acc: 91.569 Val_Loss: 0.1947  BEST VAL Loss: 0.1947  Val_Acc: 92.919

Epoch 94: Validation loss decreased (0.194696 --> 0.194543).  Saving model ...
	 Train_Loss: 0.2348 Train_Acc: 91.625 Val_Loss: 0.1945  BEST VAL Loss: 0.1945  Val_Acc: 92.827

Epoch 95: Validation loss decreased (0.194543 --> 0.194432).  Saving model ...
	 Train_Loss: 0.2346 Train_Acc: 91.596 Val_Loss: 0.1944  BEST VAL Loss: 0.1944  Val_Acc: 92.898

Epoch 96: Validation loss decreased (0.194432 --> 0.194320).  Saving model ...
	 Train_Loss: 0.2344 Train_Acc: 91.618 Val_Loss: 0.1943  BEST VAL Loss: 0.1943  Val_Acc: 92.972

Epoch 97: Validation loss decreased (0.194320 --> 0.194231).  Saving model ...
	 Train_Loss: 0.2342 Train_Acc: 91.568 Val_Loss: 0.1942  BEST VAL Loss: 0.1942  Val_Acc: 92.940

Epoch 98: Validation loss decreased (0.194231 --> 0.194166).  Saving model ...
	 Train_Loss: 0.2340 Train_Acc: 91.538 Val_Loss: 0.1942  BEST VAL Loss: 0.1942  Val_Acc: 93.017

Epoch 99: Validation loss decreased (0.194166 --> 0.194010).  Saving model ...
	 Train_Loss: 0.2338 Train_Acc: 91.620 Val_Loss: 0.1940  BEST VAL Loss: 0.1940  Val_Acc: 93.011

H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.63      0.64      0.63    169562
           1       0.37      0.36      0.37    100339

    accuracy                           0.54    269901
   macro avg       0.50      0.50      0.50    269901
weighted avg       0.53      0.54      0.53    269901

H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.63      0.64      0.63     21195
           1       0.37      0.36      0.36     12543

    accuracy                           0.53     33738
   macro avg       0.50      0.50      0.50     33738
weighted avg       0.53      0.53      0.53     33738

H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.63      0.64      0.63     21195
           1       0.37      0.36      0.36     12543

    accuracy                           0.54     33738
   macro avg       0.50      0.50      0.50     33738
weighted avg       0.53      0.54      0.53     33738

              precision    recall  f1-score   support

           0       0.63      0.64      0.63     21195
           1       0.37      0.36      0.36     12543

    accuracy                           0.54     33738
   macro avg       0.50      0.50      0.50     33738
weighted avg       0.53      0.54      0.53     33738

H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.41      0.50      0.45     28584
           1       0.59      0.50      0.54     40588

    accuracy                           0.50     69172
   macro avg       0.50      0.50      0.50     69172
weighted avg       0.52      0.50      0.50     69172

              precision    recall  f1-score   support

           0       0.41      0.50      0.45     28584
           1       0.59      0.50      0.54     40588

    accuracy                           0.50     69172
   macro avg       0.50      0.50      0.50     69172
weighted avg       0.52      0.50      0.50     69172

completed
