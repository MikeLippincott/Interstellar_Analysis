[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '967fd40a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e6b54cd2'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '453a5639'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '87ecfec4'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: DMSO_0.100_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: DMSO_0.100_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (50045, 1276)
Number of total missing values across all columns: 71286
Data Subset Is Off
Wells held out for testing: ['I14' 'M21']
Wells to use for training, validation, and testing ['B14' 'C14' 'B15' 'C15' 'J14' 'I15' 'J15' 'M16' 'M17' 'M20']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.163792).  Saving model ...
	 Train_Loss: 0.3217 Train_Acc: 87.995 Val_Loss: 0.1638  BEST VAL Loss: 0.1638  Val_Acc: 94.321

Epoch 1: Validation loss decreased (0.163792 --> 0.137285).  Saving model ...
	 Train_Loss: 0.2432 Train_Acc: 93.568 Val_Loss: 0.1373  BEST VAL Loss: 0.1373  Val_Acc: 96.262

Epoch 2: Validation loss decreased (0.137285 --> 0.124181).  Saving model ...
	 Train_Loss: 0.2032 Train_Acc: 95.182 Val_Loss: 0.1242  BEST VAL Loss: 0.1242  Val_Acc: 96.909

Epoch 3: Validation loss decreased (0.124181 --> 0.111670).  Saving model ...
	 Train_Loss: 0.1783 Train_Acc: 96.129 Val_Loss: 0.1117  BEST VAL Loss: 0.1117  Val_Acc: 97.412

Epoch 4: Validation loss decreased (0.111670 --> 0.101423).  Saving model ...
	 Train_Loss: 0.1606 Train_Acc: 96.471 Val_Loss: 0.1014  BEST VAL Loss: 0.1014  Val_Acc: 97.580

Epoch 5: Validation loss decreased (0.101423 --> 0.094311).  Saving model ...
	 Train_Loss: 0.1479 Train_Acc: 96.695 Val_Loss: 0.0943  BEST VAL Loss: 0.0943  Val_Acc: 97.460

Epoch 6: Validation loss decreased (0.094311 --> 0.089651).  Saving model ...
	 Train_Loss: 0.1378 Train_Acc: 96.893 Val_Loss: 0.0897  BEST VAL Loss: 0.0897  Val_Acc: 97.460

Epoch 7: Validation loss decreased (0.089651 --> 0.086402).  Saving model ...
	 Train_Loss: 0.1293 Train_Acc: 97.229 Val_Loss: 0.0864  BEST VAL Loss: 0.0864  Val_Acc: 97.987

Epoch 8: Validation loss decreased (0.086402 --> 0.082640).  Saving model ...
	 Train_Loss: 0.1229 Train_Acc: 97.175 Val_Loss: 0.0826  BEST VAL Loss: 0.0826  Val_Acc: 98.107

Epoch 9: Validation loss decreased (0.082640 --> 0.081111).  Saving model ...
	 Train_Loss: 0.1173 Train_Acc: 97.423 Val_Loss: 0.0811  BEST VAL Loss: 0.0811  Val_Acc: 97.676

Epoch 10: Validation loss decreased (0.081111 --> 0.078980).  Saving model ...
	 Train_Loss: 0.1127 Train_Acc: 97.498 Val_Loss: 0.0790  BEST VAL Loss: 0.0790  Val_Acc: 97.460

Epoch 11: Validation loss decreased (0.078980 --> 0.078184).  Saving model ...
	 Train_Loss: 0.1084 Train_Acc: 97.492 Val_Loss: 0.0782  BEST VAL Loss: 0.0782  Val_Acc: 98.083

Epoch 12: Validation loss decreased (0.078184 --> 0.076278).  Saving model ...
	 Train_Loss: 0.1046 Train_Acc: 97.804 Val_Loss: 0.0763  BEST VAL Loss: 0.0763  Val_Acc: 98.251

Epoch 13: Validation loss decreased (0.076278 --> 0.075721).  Saving model ...
	 Train_Loss: 0.1013 Train_Acc: 97.549 Val_Loss: 0.0757  BEST VAL Loss: 0.0757  Val_Acc: 97.771

Epoch 14: Validation loss decreased (0.075721 --> 0.073762).  Saving model ...
	 Train_Loss: 0.0982 Train_Acc: 97.684 Val_Loss: 0.0738  BEST VAL Loss: 0.0738  Val_Acc: 98.299

Epoch 15: Validation loss decreased (0.073762 --> 0.072359).  Saving model ...
	 Train_Loss: 0.0956 Train_Acc: 97.603 Val_Loss: 0.0724  BEST VAL Loss: 0.0724  Val_Acc: 98.059

Epoch 16: Validation loss decreased (0.072359 --> 0.071484).  Saving model ...
	 Train_Loss: 0.0935 Train_Acc: 97.711 Val_Loss: 0.0715  BEST VAL Loss: 0.0715  Val_Acc: 97.891

Epoch 17: Validation loss decreased (0.071484 --> 0.070697).  Saving model ...
	 Train_Loss: 0.0912 Train_Acc: 97.816 Val_Loss: 0.0707  BEST VAL Loss: 0.0707  Val_Acc: 97.987

Epoch 18: Validation loss decreased (0.070697 --> 0.069723).  Saving model ...
	 Train_Loss: 0.0891 Train_Acc: 97.861 Val_Loss: 0.0697  BEST VAL Loss: 0.0697  Val_Acc: 98.251

Epoch 19: Validation loss decreased (0.069723 --> 0.069230).  Saving model ...
	 Train_Loss: 0.0872 Train_Acc: 97.969 Val_Loss: 0.0692  BEST VAL Loss: 0.0692  Val_Acc: 97.819

Epoch 20: Validation loss decreased (0.069230 --> 0.069149).  Saving model ...
	 Train_Loss: 0.0854 Train_Acc: 97.921 Val_Loss: 0.0691  BEST VAL Loss: 0.0691  Val_Acc: 98.275

Epoch 21: Validation loss decreased (0.069149 --> 0.068233).  Saving model ...
	 Train_Loss: 0.0836 Train_Acc: 98.184 Val_Loss: 0.0682  BEST VAL Loss: 0.0682  Val_Acc: 98.299

Epoch 22: Validation loss decreased (0.068233 --> 0.067476).  Saving model ...
	 Train_Loss: 0.0820 Train_Acc: 98.089 Val_Loss: 0.0675  BEST VAL Loss: 0.0675  Val_Acc: 98.251

Epoch 23: Validation loss did not decrease
	 Train_Loss: 0.0805 Train_Acc: 98.068 Val_Loss: 0.0676  BEST VAL Loss: 0.0675  Val_Acc: 97.460

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.0789 Train_Acc: 98.274 Val_Loss: 0.0680  BEST VAL Loss: 0.0675  Val_Acc: 98.083

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.0775 Train_Acc: 98.370 Val_Loss: 0.0679  BEST VAL Loss: 0.0675  Val_Acc: 98.347

Epoch 26: Validation loss did not decrease
	 Train_Loss: 0.0763 Train_Acc: 98.439 Val_Loss: 0.0675  BEST VAL Loss: 0.0675  Val_Acc: 98.442

Epoch 27: Validation loss decreased (0.067476 --> 0.067277).  Saving model ...
	 Train_Loss: 0.0751 Train_Acc: 98.340 Val_Loss: 0.0673  BEST VAL Loss: 0.0673  Val_Acc: 98.442

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.0738 Train_Acc: 98.682 Val_Loss: 0.0673  BEST VAL Loss: 0.0673  Val_Acc: 98.299

Epoch 29: Validation loss decreased (0.067277 --> 0.066740).  Saving model ...
	 Train_Loss: 0.0730 Train_Acc: 98.256 Val_Loss: 0.0667  BEST VAL Loss: 0.0667  Val_Acc: 98.442

Epoch 30: Validation loss decreased (0.066740 --> 0.066117).  Saving model ...
	 Train_Loss: 0.0720 Train_Acc: 98.397 Val_Loss: 0.0661  BEST VAL Loss: 0.0661  Val_Acc: 98.347

Epoch 31: Validation loss decreased (0.066117 --> 0.065942).  Saving model ...
	 Train_Loss: 0.0711 Train_Acc: 98.298 Val_Loss: 0.0659  BEST VAL Loss: 0.0659  Val_Acc: 98.466

Epoch 32: Validation loss decreased (0.065942 --> 0.065891).  Saving model ...
	 Train_Loss: 0.0701 Train_Acc: 98.583 Val_Loss: 0.0659  BEST VAL Loss: 0.0659  Val_Acc: 98.466

Epoch 33: Validation loss decreased (0.065891 --> 0.065594).  Saving model ...
	 Train_Loss: 0.0691 Train_Acc: 98.805 Val_Loss: 0.0656  BEST VAL Loss: 0.0656  Val_Acc: 98.347

Epoch 34: Validation loss decreased (0.065594 --> 0.065343).  Saving model ...
	 Train_Loss: 0.0681 Train_Acc: 98.610 Val_Loss: 0.0653  BEST VAL Loss: 0.0653  Val_Acc: 98.370

Epoch 35: Validation loss decreased (0.065343 --> 0.065330).  Saving model ...
	 Train_Loss: 0.0671 Train_Acc: 98.874 Val_Loss: 0.0653  BEST VAL Loss: 0.0653  Val_Acc: 98.203

Epoch 36: Validation loss decreased (0.065330 --> 0.064984).  Saving model ...
	 Train_Loss: 0.0663 Train_Acc: 98.760 Val_Loss: 0.0650  BEST VAL Loss: 0.0650  Val_Acc: 98.251

Epoch 37: Validation loss decreased (0.064984 --> 0.064441).  Saving model ...
	 Train_Loss: 0.0656 Train_Acc: 98.475 Val_Loss: 0.0644  BEST VAL Loss: 0.0644  Val_Acc: 98.347

Epoch 38: Validation loss decreased (0.064441 --> 0.064084).  Saving model ...
	 Train_Loss: 0.0649 Train_Acc: 98.580 Val_Loss: 0.0641  BEST VAL Loss: 0.0641  Val_Acc: 98.562

Epoch 39: Validation loss decreased (0.064084 --> 0.063922).  Saving model ...
	 Train_Loss: 0.0642 Train_Acc: 98.808 Val_Loss: 0.0639  BEST VAL Loss: 0.0639  Val_Acc: 98.490

Epoch 40: Validation loss decreased (0.063922 --> 0.063720).  Saving model ...
	 Train_Loss: 0.0635 Train_Acc: 98.667 Val_Loss: 0.0637  BEST VAL Loss: 0.0637  Val_Acc: 98.538

Epoch 41: Validation loss decreased (0.063720 --> 0.063544).  Saving model ...
	 Train_Loss: 0.0630 Train_Acc: 98.628 Val_Loss: 0.0635  BEST VAL Loss: 0.0635  Val_Acc: 98.562

Epoch 42: Validation loss decreased (0.063544 --> 0.063362).  Saving model ...
	 Train_Loss: 0.0624 Train_Acc: 98.691 Val_Loss: 0.0634  BEST VAL Loss: 0.0634  Val_Acc: 98.586

Epoch 43: Validation loss decreased (0.063362 --> 0.063235).  Saving model ...
	 Train_Loss: 0.0618 Train_Acc: 98.865 Val_Loss: 0.0632  BEST VAL Loss: 0.0632  Val_Acc: 98.275

Epoch 44: Validation loss decreased (0.063235 --> 0.063147).  Saving model ...
	 Train_Loss: 0.0612 Train_Acc: 98.748 Val_Loss: 0.0631  BEST VAL Loss: 0.0631  Val_Acc: 98.490

Epoch 45: Validation loss decreased (0.063147 --> 0.063045).  Saving model ...
	 Train_Loss: 0.0606 Train_Acc: 98.877 Val_Loss: 0.0630  BEST VAL Loss: 0.0630  Val_Acc: 98.347

Epoch 46: Validation loss decreased (0.063045 --> 0.062686).  Saving model ...
	 Train_Loss: 0.0601 Train_Acc: 98.709 Val_Loss: 0.0627  BEST VAL Loss: 0.0627  Val_Acc: 98.299

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.0596 Train_Acc: 98.661 Val_Loss: 0.0629  BEST VAL Loss: 0.0627  Val_Acc: 98.275

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.0590 Train_Acc: 98.712 Val_Loss: 0.0635  BEST VAL Loss: 0.0627  Val_Acc: 98.323

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.0585 Train_Acc: 98.814 Val_Loss: 0.0636  BEST VAL Loss: 0.0627  Val_Acc: 98.370

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.0581 Train_Acc: 98.856 Val_Loss: 0.0634  BEST VAL Loss: 0.0627  Val_Acc: 98.299

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.0577 Train_Acc: 98.739 Val_Loss: 0.0634  BEST VAL Loss: 0.0627  Val_Acc: 98.418

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.0572 Train_Acc: 98.775 Val_Loss: 0.0635  BEST VAL Loss: 0.0627  Val_Acc: 97.939

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.0567 Train_Acc: 98.826 Val_Loss: 0.0638  BEST VAL Loss: 0.0627  Val_Acc: 98.442

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.0563 Train_Acc: 98.933 Val_Loss: 0.0641  BEST VAL Loss: 0.0627  Val_Acc: 98.562

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.0558 Train_Acc: 98.930 Val_Loss: 0.0642  BEST VAL Loss: 0.0627  Val_Acc: 98.370

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.0554 Train_Acc: 98.903 Val_Loss: 0.0643  BEST VAL Loss: 0.0627  Val_Acc: 98.562

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.0549 Train_Acc: 99.110 Val_Loss: 0.0646  BEST VAL Loss: 0.0627  Val_Acc: 98.347

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.0545 Train_Acc: 98.957 Val_Loss: 0.0645  BEST VAL Loss: 0.0627  Val_Acc: 98.418

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.0540 Train_Acc: 98.987 Val_Loss: 0.0643  BEST VAL Loss: 0.0627  Val_Acc: 98.610

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.0536 Train_Acc: 99.032 Val_Loss: 0.0644  BEST VAL Loss: 0.0627  Val_Acc: 98.347

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.0531 Train_Acc: 99.035 Val_Loss: 0.0642  BEST VAL Loss: 0.0627  Val_Acc: 98.442

Epoch 62: Validation loss did not decrease
Early stopped at epoch : 62
DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.74      0.74      0.74     24644
           1       0.26      0.26      0.26      8734

    accuracy                           0.61     33378
   macro avg       0.50      0.50      0.50     33378
weighted avg       0.61      0.61      0.61     33378

DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.74      0.74      0.74      3081
           1       0.26      0.26      0.26      1092

    accuracy                           0.61      4173
   macro avg       0.50      0.50      0.50      4173
weighted avg       0.61      0.61      0.61      4173

DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.74      0.73      0.74      3081
           1       0.26      0.26      0.26      1092

    accuracy                           0.61      4173
   macro avg       0.50      0.50      0.50      4173
weighted avg       0.61      0.61      0.61      4173

              precision    recall  f1-score   support

           0       0.74      0.73      0.74      3081
           1       0.26      0.26      0.26      1092

    accuracy                           0.61      4173
   macro avg       0.50      0.50      0.50      4173
weighted avg       0.61      0.61      0.61      4173

DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.58      0.59      0.58      4837
           1       0.42      0.41      0.41      3484

    accuracy                           0.51      8321
   macro avg       0.50      0.50      0.50      8321
weighted avg       0.51      0.51      0.51      8321

              precision    recall  f1-score   support

           0       0.58      0.59      0.58      4837
           1       0.42      0.41      0.41      3484

    accuracy                           0.51      8321
   macro avg       0.50      0.50      0.50      8321
weighted avg       0.51      0.51      0.51      8321

completed
