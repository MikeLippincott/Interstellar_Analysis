[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '5440889d'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'b7a8bb89'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '6a812d98'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'ed611d52'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Thapsigargin_10.000_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Thapsigargin_10.000_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'Thapsigargin_10.000_DMSO_0.025']
The dimensions of the data are: (310064, 1270)
Number of total missing values across all columns: 620128
Data Subset Is Off
Wells held out for testing: ['B08' 'L06']
Wells to use for training, validation, and testing ['B02' 'B03' 'B09' 'E06' 'E07' 'L07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.437154).  Saving model ...
	 Train_Loss: 0.5687 Train_Acc: 68.517 Val_Loss: 0.4372  BEST VAL Loss: 0.4372  Val_Acc: 81.266

Epoch 1: Validation loss decreased (0.437154 --> 0.413586).  Saving model ...
	 Train_Loss: 0.5311 Train_Acc: 76.064 Val_Loss: 0.4136  BEST VAL Loss: 0.4136  Val_Acc: 83.097

Epoch 2: Validation loss decreased (0.413586 --> 0.400529).  Saving model ...
	 Train_Loss: 0.5103 Train_Acc: 77.792 Val_Loss: 0.4005  BEST VAL Loss: 0.4005  Val_Acc: 84.586

Epoch 3: Validation loss decreased (0.400529 --> 0.389814).  Saving model ...
	 Train_Loss: 0.4969 Train_Acc: 78.634 Val_Loss: 0.3898  BEST VAL Loss: 0.3898  Val_Acc: 85.720

Epoch 4: Validation loss decreased (0.389814 --> 0.380450).  Saving model ...
	 Train_Loss: 0.4869 Train_Acc: 79.536 Val_Loss: 0.3804  BEST VAL Loss: 0.3804  Val_Acc: 85.759

Epoch 5: Validation loss decreased (0.380450 --> 0.371714).  Saving model ...
	 Train_Loss: 0.4789 Train_Acc: 80.326 Val_Loss: 0.3717  BEST VAL Loss: 0.3717  Val_Acc: 86.460

Epoch 6: Validation loss decreased (0.371714 --> 0.365647).  Saving model ...
	 Train_Loss: 0.4725 Train_Acc: 80.244 Val_Loss: 0.3656  BEST VAL Loss: 0.3656  Val_Acc: 86.863

Epoch 7: Validation loss decreased (0.365647 --> 0.361884).  Saving model ...
	 Train_Loss: 0.4671 Train_Acc: 80.758 Val_Loss: 0.3619  BEST VAL Loss: 0.3619  Val_Acc: 86.359

Epoch 8: Validation loss decreased (0.361884 --> 0.357433).  Saving model ...
	 Train_Loss: 0.4625 Train_Acc: 80.920 Val_Loss: 0.3574  BEST VAL Loss: 0.3574  Val_Acc: 86.964

Epoch 9: Validation loss decreased (0.357433 --> 0.354676).  Saving model ...
	 Train_Loss: 0.4585 Train_Acc: 81.004 Val_Loss: 0.3547  BEST VAL Loss: 0.3547  Val_Acc: 86.464

Epoch 10: Validation loss decreased (0.354676 --> 0.351250).  Saving model ...
	 Train_Loss: 0.4551 Train_Acc: 81.204 Val_Loss: 0.3513  BEST VAL Loss: 0.3513  Val_Acc: 87.112

Epoch 11: Validation loss decreased (0.351250 --> 0.348828).  Saving model ...
	 Train_Loss: 0.4519 Train_Acc: 81.756 Val_Loss: 0.3488  BEST VAL Loss: 0.3488  Val_Acc: 86.653

Epoch 12: Validation loss decreased (0.348828 --> 0.345529).  Saving model ...
	 Train_Loss: 0.4491 Train_Acc: 81.593 Val_Loss: 0.3455  BEST VAL Loss: 0.3455  Val_Acc: 87.708

Epoch 13: Validation loss decreased (0.345529 --> 0.342655).  Saving model ...
	 Train_Loss: 0.4465 Train_Acc: 81.493 Val_Loss: 0.3427  BEST VAL Loss: 0.3427  Val_Acc: 87.528

Epoch 14: Validation loss decreased (0.342655 --> 0.339573).  Saving model ...
	 Train_Loss: 0.4440 Train_Acc: 81.649 Val_Loss: 0.3396  BEST VAL Loss: 0.3396  Val_Acc: 88.146

Epoch 15: Validation loss decreased (0.339573 --> 0.337162).  Saving model ...
	 Train_Loss: 0.4418 Train_Acc: 81.904 Val_Loss: 0.3372  BEST VAL Loss: 0.3372  Val_Acc: 87.892

Epoch 16: Validation loss decreased (0.337162 --> 0.334428).  Saving model ...
	 Train_Loss: 0.4398 Train_Acc: 81.806 Val_Loss: 0.3344  BEST VAL Loss: 0.3344  Val_Acc: 87.984

Epoch 17: Validation loss decreased (0.334428 --> 0.332523).  Saving model ...
	 Train_Loss: 0.4380 Train_Acc: 82.025 Val_Loss: 0.3325  BEST VAL Loss: 0.3325  Val_Acc: 87.844

Epoch 18: Validation loss decreased (0.332523 --> 0.330927).  Saving model ...
	 Train_Loss: 0.4362 Train_Acc: 82.400 Val_Loss: 0.3309  BEST VAL Loss: 0.3309  Val_Acc: 87.765

Epoch 19: Validation loss decreased (0.330927 --> 0.329335).  Saving model ...
	 Train_Loss: 0.4346 Train_Acc: 82.530 Val_Loss: 0.3293  BEST VAL Loss: 0.3293  Val_Acc: 87.717

Epoch 20: Validation loss decreased (0.329335 --> 0.327439).  Saving model ...
	 Train_Loss: 0.4332 Train_Acc: 82.365 Val_Loss: 0.3274  BEST VAL Loss: 0.3274  Val_Acc: 88.509

Epoch 21: Validation loss decreased (0.327439 --> 0.326228).  Saving model ...
	 Train_Loss: 0.4317 Train_Acc: 82.630 Val_Loss: 0.3262  BEST VAL Loss: 0.3262  Val_Acc: 87.778

Epoch 22: Validation loss decreased (0.326228 --> 0.324481).  Saving model ...
	 Train_Loss: 0.4304 Train_Acc: 82.475 Val_Loss: 0.3245  BEST VAL Loss: 0.3245  Val_Acc: 88.474

Epoch 23: Validation loss decreased (0.324481 --> 0.322863).  Saving model ...
	 Train_Loss: 0.4293 Train_Acc: 82.491 Val_Loss: 0.3229  BEST VAL Loss: 0.3229  Val_Acc: 88.531

Epoch 24: Validation loss decreased (0.322863 --> 0.321942).  Saving model ...
	 Train_Loss: 0.4281 Train_Acc: 82.666 Val_Loss: 0.3219  BEST VAL Loss: 0.3219  Val_Acc: 88.233

Epoch 25: Validation loss decreased (0.321942 --> 0.320922).  Saving model ...
	 Train_Loss: 0.4271 Train_Acc: 82.602 Val_Loss: 0.3209  BEST VAL Loss: 0.3209  Val_Acc: 88.063

Epoch 26: Validation loss decreased (0.320922 --> 0.319745).  Saving model ...
	 Train_Loss: 0.4260 Train_Acc: 82.670 Val_Loss: 0.3197  BEST VAL Loss: 0.3197  Val_Acc: 88.142

Epoch 27: Validation loss decreased (0.319745 --> 0.318444).  Saving model ...
	 Train_Loss: 0.4250 Train_Acc: 82.734 Val_Loss: 0.3184  BEST VAL Loss: 0.3184  Val_Acc: 88.755

Epoch 28: Validation loss decreased (0.318444 --> 0.317163).  Saving model ...
	 Train_Loss: 0.4240 Train_Acc: 82.936 Val_Loss: 0.3172  BEST VAL Loss: 0.3172  Val_Acc: 88.838

Epoch 29: Validation loss decreased (0.317163 --> 0.316075).  Saving model ...
	 Train_Loss: 0.4231 Train_Acc: 82.686 Val_Loss: 0.3161  BEST VAL Loss: 0.3161  Val_Acc: 88.685

Epoch 30: Validation loss decreased (0.316075 --> 0.315445).  Saving model ...
	 Train_Loss: 0.4223 Train_Acc: 82.724 Val_Loss: 0.3154  BEST VAL Loss: 0.3154  Val_Acc: 88.045

Epoch 31: Validation loss decreased (0.315445 --> 0.314487).  Saving model ...
	 Train_Loss: 0.4214 Train_Acc: 83.063 Val_Loss: 0.3145  BEST VAL Loss: 0.3145  Val_Acc: 88.431

Epoch 32: Validation loss decreased (0.314487 --> 0.313510).  Saving model ...
	 Train_Loss: 0.4206 Train_Acc: 82.830 Val_Loss: 0.3135  BEST VAL Loss: 0.3135  Val_Acc: 88.776

Epoch 33: Validation loss decreased (0.313510 --> 0.312649).  Saving model ...
	 Train_Loss: 0.4199 Train_Acc: 82.789 Val_Loss: 0.3126  BEST VAL Loss: 0.3126  Val_Acc: 88.400

Epoch 34: Validation loss decreased (0.312649 --> 0.311982).  Saving model ...
	 Train_Loss: 0.4192 Train_Acc: 83.089 Val_Loss: 0.3120  BEST VAL Loss: 0.3120  Val_Acc: 88.220

Epoch 35: Validation loss decreased (0.311982 --> 0.311228).  Saving model ...
	 Train_Loss: 0.4184 Train_Acc: 83.209 Val_Loss: 0.3112  BEST VAL Loss: 0.3112  Val_Acc: 88.601

Epoch 36: Validation loss decreased (0.311228 --> 0.310382).  Saving model ...
	 Train_Loss: 0.4177 Train_Acc: 83.282 Val_Loss: 0.3104  BEST VAL Loss: 0.3104  Val_Acc: 88.987

Epoch 37: Validation loss decreased (0.310382 --> 0.309770).  Saving model ...
	 Train_Loss: 0.4171 Train_Acc: 83.057 Val_Loss: 0.3098  BEST VAL Loss: 0.3098  Val_Acc: 88.286

Epoch 38: Validation loss decreased (0.309770 --> 0.308988).  Saving model ...
	 Train_Loss: 0.4164 Train_Acc: 83.335 Val_Loss: 0.3090  BEST VAL Loss: 0.3090  Val_Acc: 88.663

Epoch 39: Validation loss decreased (0.308988 --> 0.308540).  Saving model ...
	 Train_Loss: 0.4158 Train_Acc: 83.276 Val_Loss: 0.3085  BEST VAL Loss: 0.3085  Val_Acc: 88.382

Epoch 40: Validation loss decreased (0.308540 --> 0.307847).  Saving model ...
	 Train_Loss: 0.4152 Train_Acc: 83.230 Val_Loss: 0.3078  BEST VAL Loss: 0.3078  Val_Acc: 88.790

Epoch 41: Validation loss decreased (0.307847 --> 0.307057).  Saving model ...
	 Train_Loss: 0.4146 Train_Acc: 83.377 Val_Loss: 0.3071  BEST VAL Loss: 0.3071  Val_Acc: 88.847

Epoch 42: Validation loss decreased (0.307057 --> 0.306535).  Saving model ...
	 Train_Loss: 0.4141 Train_Acc: 83.074 Val_Loss: 0.3065  BEST VAL Loss: 0.3065  Val_Acc: 88.781

Epoch 43: Validation loss decreased (0.306535 --> 0.306266).  Saving model ...
	 Train_Loss: 0.4136 Train_Acc: 83.226 Val_Loss: 0.3063  BEST VAL Loss: 0.3063  Val_Acc: 88.142

Epoch 44: Validation loss decreased (0.306266 --> 0.305643).  Saving model ...
	 Train_Loss: 0.4131 Train_Acc: 83.149 Val_Loss: 0.3056  BEST VAL Loss: 0.3056  Val_Acc: 88.776

Epoch 45: Validation loss decreased (0.305643 --> 0.305544).  Saving model ...
	 Train_Loss: 0.4125 Train_Acc: 83.263 Val_Loss: 0.3055  BEST VAL Loss: 0.3055  Val_Acc: 87.655

Epoch 46: Validation loss decreased (0.305544 --> 0.305106).  Saving model ...
	 Train_Loss: 0.4121 Train_Acc: 83.236 Val_Loss: 0.3051  BEST VAL Loss: 0.3051  Val_Acc: 88.930

Epoch 47: Validation loss decreased (0.305106 --> 0.304534).  Saving model ...
	 Train_Loss: 0.4116 Train_Acc: 83.463 Val_Loss: 0.3045  BEST VAL Loss: 0.3045  Val_Acc: 89.004

Epoch 48: Validation loss decreased (0.304534 --> 0.304029).  Saving model ...
	 Train_Loss: 0.4112 Train_Acc: 83.378 Val_Loss: 0.3040  BEST VAL Loss: 0.3040  Val_Acc: 88.925

Epoch 49: Validation loss decreased (0.304029 --> 0.303483).  Saving model ...
	 Train_Loss: 0.4107 Train_Acc: 83.454 Val_Loss: 0.3035  BEST VAL Loss: 0.3035  Val_Acc: 88.733

Epoch 50: Validation loss decreased (0.303483 --> 0.303191).  Saving model ...
	 Train_Loss: 0.4103 Train_Acc: 83.210 Val_Loss: 0.3032  BEST VAL Loss: 0.3032  Val_Acc: 88.746

Epoch 51: Validation loss decreased (0.303191 --> 0.302896).  Saving model ...
	 Train_Loss: 0.4099 Train_Acc: 83.338 Val_Loss: 0.3029  BEST VAL Loss: 0.3029  Val_Acc: 88.886

Epoch 52: Validation loss decreased (0.302896 --> 0.302193).  Saving model ...
	 Train_Loss: 0.4095 Train_Acc: 83.532 Val_Loss: 0.3022  BEST VAL Loss: 0.3022  Val_Acc: 89.258

Epoch 53: Validation loss decreased (0.302193 --> 0.301642).  Saving model ...
	 Train_Loss: 0.4091 Train_Acc: 83.488 Val_Loss: 0.3016  BEST VAL Loss: 0.3016  Val_Acc: 89.022

Epoch 54: Validation loss decreased (0.301642 --> 0.301201).  Saving model ...
	 Train_Loss: 0.4087 Train_Acc: 83.428 Val_Loss: 0.3012  BEST VAL Loss: 0.3012  Val_Acc: 88.785

Epoch 55: Validation loss decreased (0.301201 --> 0.300637).  Saving model ...
	 Train_Loss: 0.4083 Train_Acc: 83.407 Val_Loss: 0.3006  BEST VAL Loss: 0.3006  Val_Acc: 89.048

Epoch 56: Validation loss decreased (0.300637 --> 0.300156).  Saving model ...
	 Train_Loss: 0.4079 Train_Acc: 83.466 Val_Loss: 0.3002  BEST VAL Loss: 0.3002  Val_Acc: 88.978

Epoch 57: Validation loss decreased (0.300156 --> 0.299904).  Saving model ...
	 Train_Loss: 0.4075 Train_Acc: 83.455 Val_Loss: 0.2999  BEST VAL Loss: 0.2999  Val_Acc: 88.724

Epoch 58: Validation loss decreased (0.299904 --> 0.299526).  Saving model ...
	 Train_Loss: 0.4072 Train_Acc: 83.460 Val_Loss: 0.2995  BEST VAL Loss: 0.2995  Val_Acc: 88.895

Epoch 59: Validation loss decreased (0.299526 --> 0.299034).  Saving model ...
	 Train_Loss: 0.4068 Train_Acc: 83.437 Val_Loss: 0.2990  BEST VAL Loss: 0.2990  Val_Acc: 89.214

Epoch 60: Validation loss decreased (0.299034 --> 0.298687).  Saving model ...
	 Train_Loss: 0.4065 Train_Acc: 83.414 Val_Loss: 0.2987  BEST VAL Loss: 0.2987  Val_Acc: 88.663

Epoch 61: Validation loss decreased (0.298687 --> 0.298182).  Saving model ...
	 Train_Loss: 0.4061 Train_Acc: 83.524 Val_Loss: 0.2982  BEST VAL Loss: 0.2982  Val_Acc: 89.144

Epoch 62: Validation loss decreased (0.298182 --> 0.297784).  Saving model ...
	 Train_Loss: 0.4058 Train_Acc: 83.770 Val_Loss: 0.2978  BEST VAL Loss: 0.2978  Val_Acc: 88.974

Epoch 63: Validation loss decreased (0.297784 --> 0.297370).  Saving model ...
	 Train_Loss: 0.4055 Train_Acc: 83.645 Val_Loss: 0.2974  BEST VAL Loss: 0.2974  Val_Acc: 89.039

Epoch 64: Validation loss decreased (0.297370 --> 0.297090).  Saving model ...
	 Train_Loss: 0.4052 Train_Acc: 83.382 Val_Loss: 0.2971  BEST VAL Loss: 0.2971  Val_Acc: 89.092

Epoch 65: Validation loss decreased (0.297090 --> 0.296618).  Saving model ...
	 Train_Loss: 0.4048 Train_Acc: 83.624 Val_Loss: 0.2966  BEST VAL Loss: 0.2966  Val_Acc: 89.394

Epoch 66: Validation loss decreased (0.296618 --> 0.296370).  Saving model ...
	 Train_Loss: 0.4045 Train_Acc: 83.579 Val_Loss: 0.2964  BEST VAL Loss: 0.2964  Val_Acc: 88.566

Epoch 67: Validation loss decreased (0.296370 --> 0.295985).  Saving model ...
	 Train_Loss: 0.4042 Train_Acc: 83.546 Val_Loss: 0.2960  BEST VAL Loss: 0.2960  Val_Acc: 89.109

Epoch 68: Validation loss decreased (0.295985 --> 0.295582).  Saving model ...
	 Train_Loss: 0.4039 Train_Acc: 83.772 Val_Loss: 0.2956  BEST VAL Loss: 0.2956  Val_Acc: 89.416

Epoch 69: Validation loss decreased (0.295582 --> 0.295252).  Saving model ...
	 Train_Loss: 0.4036 Train_Acc: 83.704 Val_Loss: 0.2953  BEST VAL Loss: 0.2953  Val_Acc: 89.017

Epoch 70: Validation loss decreased (0.295252 --> 0.294912).  Saving model ...
	 Train_Loss: 0.4033 Train_Acc: 83.727 Val_Loss: 0.2949  BEST VAL Loss: 0.2949  Val_Acc: 89.337

Epoch 71: Validation loss decreased (0.294912 --> 0.294567).  Saving model ...
	 Train_Loss: 0.4030 Train_Acc: 83.761 Val_Loss: 0.2946  BEST VAL Loss: 0.2946  Val_Acc: 89.101

Epoch 72: Validation loss decreased (0.294567 --> 0.294279).  Saving model ...
	 Train_Loss: 0.4027 Train_Acc: 83.630 Val_Loss: 0.2943  BEST VAL Loss: 0.2943  Val_Acc: 89.149

Epoch 73: Validation loss decreased (0.294279 --> 0.293893).  Saving model ...
	 Train_Loss: 0.4024 Train_Acc: 83.559 Val_Loss: 0.2939  BEST VAL Loss: 0.2939  Val_Acc: 89.455

Epoch 74: Validation loss decreased (0.293893 --> 0.293658).  Saving model ...
	 Train_Loss: 0.4021 Train_Acc: 83.824 Val_Loss: 0.2937  BEST VAL Loss: 0.2937  Val_Acc: 89.026

Epoch 75: Validation loss decreased (0.293658 --> 0.293344).  Saving model ...
	 Train_Loss: 0.4018 Train_Acc: 83.622 Val_Loss: 0.2933  BEST VAL Loss: 0.2933  Val_Acc: 89.228

Epoch 76: Validation loss decreased (0.293344 --> 0.293101).  Saving model ...
	 Train_Loss: 0.4016 Train_Acc: 83.765 Val_Loss: 0.2931  BEST VAL Loss: 0.2931  Val_Acc: 88.842

Epoch 77: Validation loss decreased (0.293101 --> 0.292765).  Saving model ...
	 Train_Loss: 0.4014 Train_Acc: 83.696 Val_Loss: 0.2928  BEST VAL Loss: 0.2928  Val_Acc: 89.446

Epoch 78: Validation loss decreased (0.292765 --> 0.292595).  Saving model ...
	 Train_Loss: 0.4011 Train_Acc: 83.791 Val_Loss: 0.2926  BEST VAL Loss: 0.2926  Val_Acc: 88.829

Epoch 79: Validation loss decreased (0.292595 --> 0.292369).  Saving model ...
	 Train_Loss: 0.4009 Train_Acc: 83.963 Val_Loss: 0.2924  BEST VAL Loss: 0.2924  Val_Acc: 89.350

Epoch 80: Validation loss decreased (0.292369 --> 0.292108).  Saving model ...
	 Train_Loss: 0.4006 Train_Acc: 83.896 Val_Loss: 0.2921  BEST VAL Loss: 0.2921  Val_Acc: 89.341

Epoch 81: Validation loss decreased (0.292108 --> 0.291843).  Saving model ...
	 Train_Loss: 0.4004 Train_Acc: 83.805 Val_Loss: 0.2918  BEST VAL Loss: 0.2918  Val_Acc: 88.991

Epoch 82: Validation loss decreased (0.291843 --> 0.291694).  Saving model ...
	 Train_Loss: 0.4001 Train_Acc: 83.955 Val_Loss: 0.2917  BEST VAL Loss: 0.2917  Val_Acc: 89.004

Epoch 83: Validation loss decreased (0.291694 --> 0.291437).  Saving model ...
	 Train_Loss: 0.3999 Train_Acc: 83.853 Val_Loss: 0.2914  BEST VAL Loss: 0.2914  Val_Acc: 89.328

Epoch 84: Validation loss decreased (0.291437 --> 0.291312).  Saving model ...
	 Train_Loss: 0.3997 Train_Acc: 83.738 Val_Loss: 0.2913  BEST VAL Loss: 0.2913  Val_Acc: 88.995

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.3995 Train_Acc: 83.812 Val_Loss: 0.2914  BEST VAL Loss: 0.2913  Val_Acc: 88.339

Epoch 86: Validation loss decreased (0.291312 --> 0.291194).  Saving model ...
	 Train_Loss: 0.3993 Train_Acc: 83.737 Val_Loss: 0.2912  BEST VAL Loss: 0.2912  Val_Acc: 89.096

Epoch 87: Validation loss decreased (0.291194 --> 0.291024).  Saving model ...
	 Train_Loss: 0.3991 Train_Acc: 83.755 Val_Loss: 0.2910  BEST VAL Loss: 0.2910  Val_Acc: 88.890

Epoch 88: Validation loss decreased (0.291024 --> 0.290749).  Saving model ...
	 Train_Loss: 0.3989 Train_Acc: 83.819 Val_Loss: 0.2907  BEST VAL Loss: 0.2907  Val_Acc: 89.293

Epoch 89: Validation loss decreased (0.290749 --> 0.290491).  Saving model ...
	 Train_Loss: 0.3987 Train_Acc: 83.848 Val_Loss: 0.2905  BEST VAL Loss: 0.2905  Val_Acc: 89.359

Epoch 90: Validation loss decreased (0.290491 --> 0.290252).  Saving model ...
	 Train_Loss: 0.3985 Train_Acc: 83.847 Val_Loss: 0.2903  BEST VAL Loss: 0.2903  Val_Acc: 89.306

Epoch 91: Validation loss decreased (0.290252 --> 0.289988).  Saving model ...
	 Train_Loss: 0.3982 Train_Acc: 83.872 Val_Loss: 0.2900  BEST VAL Loss: 0.2900  Val_Acc: 89.582

Epoch 92: Validation loss decreased (0.289988 --> 0.289751).  Saving model ...
	 Train_Loss: 0.3980 Train_Acc: 83.846 Val_Loss: 0.2898  BEST VAL Loss: 0.2898  Val_Acc: 89.438

Epoch 93: Validation loss decreased (0.289751 --> 0.289530).  Saving model ...
	 Train_Loss: 0.3978 Train_Acc: 84.055 Val_Loss: 0.2895  BEST VAL Loss: 0.2895  Val_Acc: 89.276

Epoch 94: Validation loss decreased (0.289530 --> 0.289274).  Saving model ...
	 Train_Loss: 0.3976 Train_Acc: 83.912 Val_Loss: 0.2893  BEST VAL Loss: 0.2893  Val_Acc: 89.407

Epoch 95: Validation loss decreased (0.289274 --> 0.289246).  Saving model ...
	 Train_Loss: 0.3974 Train_Acc: 83.919 Val_Loss: 0.2892  BEST VAL Loss: 0.2892  Val_Acc: 88.343

Epoch 96: Validation loss decreased (0.289246 --> 0.289005).  Saving model ...
	 Train_Loss: 0.3972 Train_Acc: 84.000 Val_Loss: 0.2890  BEST VAL Loss: 0.2890  Val_Acc: 89.486

Epoch 97: Validation loss decreased (0.289005 --> 0.288734).  Saving model ...
	 Train_Loss: 0.3971 Train_Acc: 84.049 Val_Loss: 0.2887  BEST VAL Loss: 0.2887  Val_Acc: 89.543

Epoch 98: Validation loss decreased (0.288734 --> 0.288571).  Saving model ...
	 Train_Loss: 0.3969 Train_Acc: 84.032 Val_Loss: 0.2886  BEST VAL Loss: 0.2886  Val_Acc: 89.464

Epoch 99: Validation loss decreased (0.288571 --> 0.288443).  Saving model ...
	 Train_Loss: 0.3967 Train_Acc: 83.733 Val_Loss: 0.2884  BEST VAL Loss: 0.2884  Val_Acc: 89.127

Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.45      0.46     85025
           1       0.53      0.55      0.54     97655

    accuracy                           0.50    182680
   macro avg       0.50      0.50      0.50    182680
weighted avg       0.50      0.50      0.50    182680

Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.45      0.46     10629
           1       0.53      0.55      0.54     12207

    accuracy                           0.50     22836
   macro avg       0.50      0.50      0.50     22836
weighted avg       0.50      0.50      0.50     22836

Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.46      0.47     10629
           1       0.54      0.55      0.55     12207

    accuracy                           0.51     22836
   macro avg       0.51      0.51      0.51     22836
weighted avg       0.51      0.51      0.51     22836

              precision    recall  f1-score   support

           0       0.47      0.46      0.47     10629
           1       0.54      0.55      0.55     12207

    accuracy                           0.51     22836
   macro avg       0.51      0.51      0.51     22836
weighted avg       0.51      0.51      0.51     22836

Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.45      0.43      0.44     36797
           1       0.55      0.57      0.56     44915

    accuracy                           0.51     81712
   macro avg       0.50      0.50      0.50     81712
weighted avg       0.50      0.51      0.51     81712

              precision    recall  f1-score   support

           0       0.45      0.43      0.44     36797
           1       0.55      0.57      0.56     44915

    accuracy                           0.51     81712
   macro avg       0.50      0.50      0.50     81712
weighted avg       0.50      0.51      0.51     81712

completed
