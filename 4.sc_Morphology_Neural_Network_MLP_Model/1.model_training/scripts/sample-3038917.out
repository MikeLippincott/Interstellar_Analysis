[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '66bb03b0'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'f9355b15'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '51129a93'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '9d5db61c'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_0.100_DMSO_0.025 treatment_name: LPS_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_0.100_DMSO_0.025
TREATMENT_NAME: LPS_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_1.000_DMSO_0.025']
The dimensions of the data are: (278030, 1270)
Number of total missing values across all columns: 556060
Data Subset Is Off
Wells held out for testing: ['C08' 'D08']
Wells to use for training, validation, and testing ['C02' 'C03' 'C09' 'D02' 'D03' 'D09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.641089).  Saving model ...
	 Train_Loss: 0.6905 Train_Acc: 56.399 Val_Loss: 0.6411  BEST VAL Loss: 0.6411  Val_Acc: 62.479

Epoch 1: Validation loss decreased (0.641089 --> 0.634071).  Saving model ...
	 Train_Loss: 0.6684 Train_Acc: 60.747 Val_Loss: 0.6341  BEST VAL Loss: 0.6341  Val_Acc: 63.030

Epoch 2: Validation loss decreased (0.634071 --> 0.625979).  Saving model ...
	 Train_Loss: 0.6569 Train_Acc: 61.848 Val_Loss: 0.6260  BEST VAL Loss: 0.6260  Val_Acc: 63.669

Epoch 3: Validation loss decreased (0.625979 --> 0.619771).  Saving model ...
	 Train_Loss: 0.6498 Train_Acc: 61.969 Val_Loss: 0.6198  BEST VAL Loss: 0.6198  Val_Acc: 64.937

Epoch 4: Validation loss decreased (0.619771 --> 0.613164).  Saving model ...
	 Train_Loss: 0.6432 Train_Acc: 62.639 Val_Loss: 0.6132  BEST VAL Loss: 0.6132  Val_Acc: 65.811

Epoch 5: Validation loss decreased (0.613164 --> 0.608268).  Saving model ...
	 Train_Loss: 0.6377 Train_Acc: 63.399 Val_Loss: 0.6083  BEST VAL Loss: 0.6083  Val_Acc: 65.462

Epoch 6: Validation loss decreased (0.608268 --> 0.604618).  Saving model ...
	 Train_Loss: 0.6331 Train_Acc: 63.806 Val_Loss: 0.6046  BEST VAL Loss: 0.6046  Val_Acc: 66.072

Epoch 7: Validation loss decreased (0.604618 --> 0.602199).  Saving model ...
	 Train_Loss: 0.6289 Train_Acc: 64.090 Val_Loss: 0.6022  BEST VAL Loss: 0.6022  Val_Acc: 65.939

Epoch 8: Validation loss decreased (0.602199 --> 0.598936).  Saving model ...
	 Train_Loss: 0.6257 Train_Acc: 63.910 Val_Loss: 0.5989  BEST VAL Loss: 0.5989  Val_Acc: 66.455

Epoch 9: Validation loss decreased (0.598936 --> 0.595890).  Saving model ...
	 Train_Loss: 0.6227 Train_Acc: 64.059 Val_Loss: 0.5959  BEST VAL Loss: 0.5959  Val_Acc: 66.038

Epoch 10: Validation loss decreased (0.595890 --> 0.593641).  Saving model ...
	 Train_Loss: 0.6199 Train_Acc: 64.229 Val_Loss: 0.5936  BEST VAL Loss: 0.5936  Val_Acc: 66.180

Epoch 11: Validation loss decreased (0.593641 --> 0.591247).  Saving model ...
	 Train_Loss: 0.6173 Train_Acc: 64.262 Val_Loss: 0.5912  BEST VAL Loss: 0.5912  Val_Acc: 67.389

Epoch 12: Validation loss decreased (0.591247 --> 0.589367).  Saving model ...
	 Train_Loss: 0.6150 Train_Acc: 64.373 Val_Loss: 0.5894  BEST VAL Loss: 0.5894  Val_Acc: 66.981

Epoch 13: Validation loss decreased (0.589367 --> 0.587090).  Saving model ...
	 Train_Loss: 0.6130 Train_Acc: 64.460 Val_Loss: 0.5871  BEST VAL Loss: 0.5871  Val_Acc: 66.908

Epoch 14: Validation loss decreased (0.587090 --> 0.585041).  Saving model ...
	 Train_Loss: 0.6110 Train_Acc: 64.434 Val_Loss: 0.5850  BEST VAL Loss: 0.5850  Val_Acc: 67.556

Epoch 15: Validation loss decreased (0.585041 --> 0.583456).  Saving model ...
	 Train_Loss: 0.6091 Train_Acc: 64.653 Val_Loss: 0.5835  BEST VAL Loss: 0.5835  Val_Acc: 67.886

Epoch 16: Validation loss decreased (0.583456 --> 0.582029).  Saving model ...
	 Train_Loss: 0.6073 Train_Acc: 64.575 Val_Loss: 0.5820  BEST VAL Loss: 0.5820  Val_Acc: 66.790

Epoch 17: Validation loss decreased (0.582029 --> 0.580064).  Saving model ...
	 Train_Loss: 0.6057 Train_Acc: 64.510 Val_Loss: 0.5801  BEST VAL Loss: 0.5801  Val_Acc: 67.104

Epoch 18: Validation loss decreased (0.580064 --> 0.579495).  Saving model ...
	 Train_Loss: 0.6040 Train_Acc: 64.938 Val_Loss: 0.5795  BEST VAL Loss: 0.5795  Val_Acc: 67.522

Epoch 19: Validation loss decreased (0.579495 --> 0.578061).  Saving model ...
	 Train_Loss: 0.6025 Train_Acc: 64.898 Val_Loss: 0.5781  BEST VAL Loss: 0.5781  Val_Acc: 68.249

Epoch 20: Validation loss decreased (0.578061 --> 0.576746).  Saving model ...
	 Train_Loss: 0.6011 Train_Acc: 64.820 Val_Loss: 0.5767  BEST VAL Loss: 0.5767  Val_Acc: 67.856

Epoch 21: Validation loss decreased (0.576746 --> 0.575729).  Saving model ...
	 Train_Loss: 0.5999 Train_Acc: 64.737 Val_Loss: 0.5757  BEST VAL Loss: 0.5757  Val_Acc: 68.259

Epoch 22: Validation loss decreased (0.575729 --> 0.574707).  Saving model ...
	 Train_Loss: 0.5986 Train_Acc: 64.705 Val_Loss: 0.5747  BEST VAL Loss: 0.5747  Val_Acc: 66.824

Epoch 23: Validation loss decreased (0.574707 --> 0.573763).  Saving model ...
	 Train_Loss: 0.5975 Train_Acc: 64.448 Val_Loss: 0.5738  BEST VAL Loss: 0.5738  Val_Acc: 67.669

Epoch 24: Validation loss decreased (0.573763 --> 0.572441).  Saving model ...
	 Train_Loss: 0.5963 Train_Acc: 64.848 Val_Loss: 0.5724  BEST VAL Loss: 0.5724  Val_Acc: 68.387

Epoch 25: Validation loss decreased (0.572441 --> 0.571444).  Saving model ...
	 Train_Loss: 0.5952 Train_Acc: 64.967 Val_Loss: 0.5714  BEST VAL Loss: 0.5714  Val_Acc: 68.180

Epoch 26: Validation loss decreased (0.571444 --> 0.570572).  Saving model ...
	 Train_Loss: 0.5942 Train_Acc: 64.847 Val_Loss: 0.5706  BEST VAL Loss: 0.5706  Val_Acc: 67.483

Epoch 27: Validation loss decreased (0.570572 --> 0.569607).  Saving model ...
	 Train_Loss: 0.5932 Train_Acc: 64.893 Val_Loss: 0.5696  BEST VAL Loss: 0.5696  Val_Acc: 68.235

Epoch 28: Validation loss decreased (0.569607 --> 0.568390).  Saving model ...
	 Train_Loss: 0.5922 Train_Acc: 65.150 Val_Loss: 0.5684  BEST VAL Loss: 0.5684  Val_Acc: 68.928

Epoch 29: Validation loss decreased (0.568390 --> 0.567572).  Saving model ...
	 Train_Loss: 0.5912 Train_Acc: 64.865 Val_Loss: 0.5676  BEST VAL Loss: 0.5676  Val_Acc: 67.232

Epoch 30: Validation loss decreased (0.567572 --> 0.566729).  Saving model ...
	 Train_Loss: 0.5904 Train_Acc: 64.757 Val_Loss: 0.5667  BEST VAL Loss: 0.5667  Val_Acc: 68.426

Epoch 31: Validation loss decreased (0.566729 --> 0.565505).  Saving model ...
	 Train_Loss: 0.5895 Train_Acc: 65.057 Val_Loss: 0.5655  BEST VAL Loss: 0.5655  Val_Acc: 69.483

Epoch 32: Validation loss decreased (0.565505 --> 0.564713).  Saving model ...
	 Train_Loss: 0.5887 Train_Acc: 65.094 Val_Loss: 0.5647  BEST VAL Loss: 0.5647  Val_Acc: 68.682

Epoch 33: Validation loss decreased (0.564713 --> 0.563839).  Saving model ...
	 Train_Loss: 0.5880 Train_Acc: 64.716 Val_Loss: 0.5638  BEST VAL Loss: 0.5638  Val_Acc: 68.461

Epoch 34: Validation loss decreased (0.563839 --> 0.562934).  Saving model ...
	 Train_Loss: 0.5873 Train_Acc: 65.137 Val_Loss: 0.5629  BEST VAL Loss: 0.5629  Val_Acc: 69.286

Epoch 35: Validation loss decreased (0.562934 --> 0.562008).  Saving model ...
	 Train_Loss: 0.5865 Train_Acc: 65.234 Val_Loss: 0.5620  BEST VAL Loss: 0.5620  Val_Acc: 69.355

Epoch 36: Validation loss decreased (0.562008 --> 0.561103).  Saving model ...
	 Train_Loss: 0.5857 Train_Acc: 65.095 Val_Loss: 0.5611  BEST VAL Loss: 0.5611  Val_Acc: 68.328

Epoch 37: Validation loss decreased (0.561103 --> 0.560545).  Saving model ...
	 Train_Loss: 0.5850 Train_Acc: 65.412 Val_Loss: 0.5605  BEST VAL Loss: 0.5605  Val_Acc: 69.183

Epoch 38: Validation loss decreased (0.560545 --> 0.559789).  Saving model ...
	 Train_Loss: 0.5843 Train_Acc: 65.237 Val_Loss: 0.5598  BEST VAL Loss: 0.5598  Val_Acc: 69.611

Epoch 39: Validation loss decreased (0.559789 --> 0.558969).  Saving model ...
	 Train_Loss: 0.5836 Train_Acc: 65.388 Val_Loss: 0.5590  BEST VAL Loss: 0.5590  Val_Acc: 68.908

Epoch 40: Validation loss decreased (0.558969 --> 0.558420).  Saving model ...
	 Train_Loss: 0.5830 Train_Acc: 65.165 Val_Loss: 0.5584  BEST VAL Loss: 0.5584  Val_Acc: 68.952

Epoch 41: Validation loss decreased (0.558420 --> 0.557752).  Saving model ...
	 Train_Loss: 0.5823 Train_Acc: 65.390 Val_Loss: 0.5578  BEST VAL Loss: 0.5578  Val_Acc: 69.542

Epoch 42: Validation loss decreased (0.557752 --> 0.557019).  Saving model ...
	 Train_Loss: 0.5817 Train_Acc: 65.494 Val_Loss: 0.5570  BEST VAL Loss: 0.5570  Val_Acc: 70.201

Epoch 43: Validation loss decreased (0.557019 --> 0.556425).  Saving model ...
	 Train_Loss: 0.5811 Train_Acc: 65.769 Val_Loss: 0.5564  BEST VAL Loss: 0.5564  Val_Acc: 69.773

Epoch 44: Validation loss decreased (0.556425 --> 0.555786).  Saving model ...
	 Train_Loss: 0.5806 Train_Acc: 65.369 Val_Loss: 0.5558  BEST VAL Loss: 0.5558  Val_Acc: 70.245

Epoch 45: Validation loss decreased (0.555786 --> 0.555021).  Saving model ...
	 Train_Loss: 0.5800 Train_Acc: 65.395 Val_Loss: 0.5550  BEST VAL Loss: 0.5550  Val_Acc: 68.682

Epoch 46: Validation loss decreased (0.555021 --> 0.554424).  Saving model ...
	 Train_Loss: 0.5795 Train_Acc: 65.541 Val_Loss: 0.5544  BEST VAL Loss: 0.5544  Val_Acc: 70.387

Epoch 47: Validation loss decreased (0.554424 --> 0.553850).  Saving model ...
	 Train_Loss: 0.5789 Train_Acc: 65.573 Val_Loss: 0.5538  BEST VAL Loss: 0.5538  Val_Acc: 70.476

Epoch 48: Validation loss decreased (0.553850 --> 0.553219).  Saving model ...
	 Train_Loss: 0.5784 Train_Acc: 65.543 Val_Loss: 0.5532  BEST VAL Loss: 0.5532  Val_Acc: 70.205

Epoch 49: Validation loss decreased (0.553219 --> 0.552870).  Saving model ...
	 Train_Loss: 0.5779 Train_Acc: 65.526 Val_Loss: 0.5529  BEST VAL Loss: 0.5529  Val_Acc: 69.380

Epoch 50: Validation loss decreased (0.552870 --> 0.552496).  Saving model ...
	 Train_Loss: 0.5774 Train_Acc: 65.747 Val_Loss: 0.5525  BEST VAL Loss: 0.5525  Val_Acc: 68.279

Epoch 51: Validation loss decreased (0.552496 --> 0.551965).  Saving model ...
	 Train_Loss: 0.5770 Train_Acc: 65.611 Val_Loss: 0.5520  BEST VAL Loss: 0.5520  Val_Acc: 70.289

Epoch 52: Validation loss decreased (0.551965 --> 0.551530).  Saving model ...
	 Train_Loss: 0.5764 Train_Acc: 65.997 Val_Loss: 0.5515  BEST VAL Loss: 0.5515  Val_Acc: 68.485

Epoch 53: Validation loss decreased (0.551530 --> 0.551013).  Saving model ...
	 Train_Loss: 0.5760 Train_Acc: 65.596 Val_Loss: 0.5510  BEST VAL Loss: 0.5510  Val_Acc: 68.176

Epoch 54: Validation loss decreased (0.551013 --> 0.550643).  Saving model ...
	 Train_Loss: 0.5756 Train_Acc: 65.623 Val_Loss: 0.5506  BEST VAL Loss: 0.5506  Val_Acc: 70.240

Epoch 55: Validation loss decreased (0.550643 --> 0.550348).  Saving model ...
	 Train_Loss: 0.5751 Train_Acc: 65.583 Val_Loss: 0.5503  BEST VAL Loss: 0.5503  Val_Acc: 68.628

Epoch 56: Validation loss decreased (0.550348 --> 0.549993).  Saving model ...
	 Train_Loss: 0.5747 Train_Acc: 65.860 Val_Loss: 0.5500  BEST VAL Loss: 0.5500  Val_Acc: 70.171

Epoch 57: Validation loss decreased (0.549993 --> 0.549619).  Saving model ...
	 Train_Loss: 0.5743 Train_Acc: 65.837 Val_Loss: 0.5496  BEST VAL Loss: 0.5496  Val_Acc: 70.589

Epoch 58: Validation loss decreased (0.549619 --> 0.549166).  Saving model ...
	 Train_Loss: 0.5739 Train_Acc: 65.940 Val_Loss: 0.5492  BEST VAL Loss: 0.5492  Val_Acc: 70.722

Epoch 59: Validation loss decreased (0.549166 --> 0.548641).  Saving model ...
	 Train_Loss: 0.5735 Train_Acc: 65.844 Val_Loss: 0.5486  BEST VAL Loss: 0.5486  Val_Acc: 69.247

Epoch 60: Validation loss decreased (0.548641 --> 0.548129).  Saving model ...
	 Train_Loss: 0.5730 Train_Acc: 65.937 Val_Loss: 0.5481  BEST VAL Loss: 0.5481  Val_Acc: 70.230

Epoch 61: Validation loss decreased (0.548129 --> 0.547776).  Saving model ...
	 Train_Loss: 0.5727 Train_Acc: 65.964 Val_Loss: 0.5478  BEST VAL Loss: 0.5478  Val_Acc: 69.709

Epoch 62: Validation loss decreased (0.547776 --> 0.547439).  Saving model ...
	 Train_Loss: 0.5723 Train_Acc: 65.902 Val_Loss: 0.5474  BEST VAL Loss: 0.5474  Val_Acc: 70.535

Epoch 63: Validation loss decreased (0.547439 --> 0.547006).  Saving model ...
	 Train_Loss: 0.5719 Train_Acc: 65.902 Val_Loss: 0.5470  BEST VAL Loss: 0.5470  Val_Acc: 70.495

Epoch 64: Validation loss decreased (0.547006 --> 0.546672).  Saving model ...
	 Train_Loss: 0.5715 Train_Acc: 66.018 Val_Loss: 0.5467  BEST VAL Loss: 0.5467  Val_Acc: 70.230

Epoch 65: Validation loss decreased (0.546672 --> 0.546334).  Saving model ...
	 Train_Loss: 0.5711 Train_Acc: 65.980 Val_Loss: 0.5463  BEST VAL Loss: 0.5463  Val_Acc: 70.830

Epoch 66: Validation loss decreased (0.546334 --> 0.545960).  Saving model ...
	 Train_Loss: 0.5708 Train_Acc: 66.110 Val_Loss: 0.5460  BEST VAL Loss: 0.5460  Val_Acc: 70.495

Epoch 67: Validation loss decreased (0.545960 --> 0.545692).  Saving model ...
	 Train_Loss: 0.5704 Train_Acc: 65.990 Val_Loss: 0.5457  BEST VAL Loss: 0.5457  Val_Acc: 70.839

Epoch 68: Validation loss decreased (0.545692 --> 0.545351).  Saving model ...
	 Train_Loss: 0.5701 Train_Acc: 65.913 Val_Loss: 0.5454  BEST VAL Loss: 0.5454  Val_Acc: 70.663

Epoch 69: Validation loss decreased (0.545351 --> 0.545013).  Saving model ...
	 Train_Loss: 0.5698 Train_Acc: 65.961 Val_Loss: 0.5450  BEST VAL Loss: 0.5450  Val_Acc: 70.525

Epoch 70: Validation loss decreased (0.545013 --> 0.544619).  Saving model ...
	 Train_Loss: 0.5695 Train_Acc: 65.951 Val_Loss: 0.5446  BEST VAL Loss: 0.5446  Val_Acc: 70.648

Epoch 71: Validation loss decreased (0.544619 --> 0.544544).  Saving model ...
	 Train_Loss: 0.5692 Train_Acc: 65.964 Val_Loss: 0.5445  BEST VAL Loss: 0.5445  Val_Acc: 70.215

Epoch 72: Validation loss decreased (0.544544 --> 0.544429).  Saving model ...
	 Train_Loss: 0.5688 Train_Acc: 65.892 Val_Loss: 0.5444  BEST VAL Loss: 0.5444  Val_Acc: 69.011

Epoch 73: Validation loss decreased (0.544429 --> 0.544204).  Saving model ...
	 Train_Loss: 0.5685 Train_Acc: 65.814 Val_Loss: 0.5442  BEST VAL Loss: 0.5442  Val_Acc: 70.574

Epoch 74: Validation loss decreased (0.544204 --> 0.543858).  Saving model ...
	 Train_Loss: 0.5683 Train_Acc: 65.922 Val_Loss: 0.5439  BEST VAL Loss: 0.5439  Val_Acc: 68.367

Epoch 75: Validation loss decreased (0.543858 --> 0.543581).  Saving model ...
	 Train_Loss: 0.5679 Train_Acc: 66.189 Val_Loss: 0.5436  BEST VAL Loss: 0.5436  Val_Acc: 70.918

Epoch 76: Validation loss decreased (0.543581 --> 0.543377).  Saving model ...
	 Train_Loss: 0.5676 Train_Acc: 66.080 Val_Loss: 0.5434  BEST VAL Loss: 0.5434  Val_Acc: 70.549

Epoch 77: Validation loss decreased (0.543377 --> 0.543194).  Saving model ...
	 Train_Loss: 0.5674 Train_Acc: 65.816 Val_Loss: 0.5432  BEST VAL Loss: 0.5432  Val_Acc: 70.166

Epoch 78: Validation loss decreased (0.543194 --> 0.542758).  Saving model ...
	 Train_Loss: 0.5671 Train_Acc: 65.983 Val_Loss: 0.5428  BEST VAL Loss: 0.5428  Val_Acc: 71.090

Epoch 79: Validation loss decreased (0.542758 --> 0.542380).  Saving model ...
	 Train_Loss: 0.5668 Train_Acc: 66.077 Val_Loss: 0.5424  BEST VAL Loss: 0.5424  Val_Acc: 71.110

Epoch 80: Validation loss decreased (0.542380 --> 0.542170).  Saving model ...
	 Train_Loss: 0.5665 Train_Acc: 66.410 Val_Loss: 0.5422  BEST VAL Loss: 0.5422  Val_Acc: 70.751

Epoch 81: Validation loss decreased (0.542170 --> 0.541910).  Saving model ...
	 Train_Loss: 0.5662 Train_Acc: 66.146 Val_Loss: 0.5419  BEST VAL Loss: 0.5419  Val_Acc: 70.063

Epoch 82: Validation loss decreased (0.541910 --> 0.541621).  Saving model ...
	 Train_Loss: 0.5660 Train_Acc: 66.272 Val_Loss: 0.5416  BEST VAL Loss: 0.5416  Val_Acc: 70.628

Epoch 83: Validation loss decreased (0.541621 --> 0.541335).  Saving model ...
	 Train_Loss: 0.5657 Train_Acc: 66.290 Val_Loss: 0.5413  BEST VAL Loss: 0.5413  Val_Acc: 71.066

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.5654 Train_Acc: 66.431 Val_Loss: 0.5414  BEST VAL Loss: 0.5413  Val_Acc: 68.746

Epoch 85: Validation loss decreased (0.541335 --> 0.541246).  Saving model ...
	 Train_Loss: 0.5652 Train_Acc: 65.861 Val_Loss: 0.5412  BEST VAL Loss: 0.5412  Val_Acc: 70.687

Epoch 86: Validation loss decreased (0.541246 --> 0.541038).  Saving model ...
	 Train_Loss: 0.5649 Train_Acc: 66.295 Val_Loss: 0.5410  BEST VAL Loss: 0.5410  Val_Acc: 70.731

Epoch 87: Validation loss decreased (0.541038 --> 0.540830).  Saving model ...
	 Train_Loss: 0.5647 Train_Acc: 66.031 Val_Loss: 0.5408  BEST VAL Loss: 0.5408  Val_Acc: 68.839

Epoch 88: Validation loss decreased (0.540830 --> 0.540542).  Saving model ...
	 Train_Loss: 0.5644 Train_Acc: 66.194 Val_Loss: 0.5405  BEST VAL Loss: 0.5405  Val_Acc: 71.326

Epoch 89: Validation loss decreased (0.540542 --> 0.540300).  Saving model ...
	 Train_Loss: 0.5642 Train_Acc: 66.424 Val_Loss: 0.5403  BEST VAL Loss: 0.5403  Val_Acc: 71.026

Epoch 90: Validation loss decreased (0.540300 --> 0.539959).  Saving model ...
	 Train_Loss: 0.5639 Train_Acc: 66.008 Val_Loss: 0.5400  BEST VAL Loss: 0.5400  Val_Acc: 70.682

Epoch 91: Validation loss decreased (0.539959 --> 0.539700).  Saving model ...
	 Train_Loss: 0.5637 Train_Acc: 66.217 Val_Loss: 0.5397  BEST VAL Loss: 0.5397  Val_Acc: 70.756

Epoch 92: Validation loss decreased (0.539700 --> 0.539526).  Saving model ...
	 Train_Loss: 0.5635 Train_Acc: 66.215 Val_Loss: 0.5395  BEST VAL Loss: 0.5395  Val_Acc: 70.137

Epoch 93: Validation loss decreased (0.539526 --> 0.539306).  Saving model ...
	 Train_Loss: 0.5632 Train_Acc: 66.461 Val_Loss: 0.5393  BEST VAL Loss: 0.5393  Val_Acc: 70.402

Epoch 94: Validation loss decreased (0.539306 --> 0.539008).  Saving model ...
	 Train_Loss: 0.5630 Train_Acc: 66.215 Val_Loss: 0.5390  BEST VAL Loss: 0.5390  Val_Acc: 70.987

Epoch 95: Validation loss decreased (0.539008 --> 0.538774).  Saving model ...
	 Train_Loss: 0.5628 Train_Acc: 65.992 Val_Loss: 0.5388  BEST VAL Loss: 0.5388  Val_Acc: 70.810

Epoch 96: Validation loss decreased (0.538774 --> 0.538594).  Saving model ...
	 Train_Loss: 0.5625 Train_Acc: 66.128 Val_Loss: 0.5386  BEST VAL Loss: 0.5386  Val_Acc: 70.908

Epoch 97: Validation loss decreased (0.538594 --> 0.538405).  Saving model ...
	 Train_Loss: 0.5624 Train_Acc: 66.060 Val_Loss: 0.5384  BEST VAL Loss: 0.5384  Val_Acc: 68.908

Epoch 98: Validation loss decreased (0.538405 --> 0.538300).  Saving model ...
	 Train_Loss: 0.5622 Train_Acc: 66.139 Val_Loss: 0.5383  BEST VAL Loss: 0.5383  Val_Acc: 69.989

Epoch 99: Validation loss decreased (0.538300 --> 0.538097).  Saving model ...
	 Train_Loss: 0.5620 Train_Acc: 65.981 Val_Loss: 0.5381  BEST VAL Loss: 0.5381  Val_Acc: 70.957

LPS_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.68      0.58     82968
           1       0.49      0.31      0.38     79796

    accuracy                           0.50    162764
   macro avg       0.50      0.50      0.48    162764
weighted avg       0.50      0.50      0.49    162764

LPS_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.69      0.59     10371
           1       0.49      0.31      0.38      9975

    accuracy                           0.50     20346
   macro avg       0.50      0.50      0.48     20346
weighted avg       0.50      0.50      0.48     20346

LPS_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.68      0.58     10371
           1       0.49      0.31      0.38      9975

    accuracy                           0.50     20346
   macro avg       0.50      0.50      0.48     20346
weighted avg       0.50      0.50      0.48     20346

              precision    recall  f1-score   support

           0       0.51      0.68      0.58     10371
           1       0.49      0.31      0.38      9975

    accuracy                           0.50     20346
   macro avg       0.50      0.50      0.48     20346
weighted avg       0.50      0.50      0.48     20346

LPS_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.100_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.94      0.62     34887
           1       0.53      0.06      0.10     39687

    accuracy                           0.47     74574
   macro avg       0.50      0.50      0.36     74574
weighted avg       0.50      0.47      0.35     74574

              precision    recall  f1-score   support

           0       0.47      0.94      0.62     34887
           1       0.53      0.06      0.10     39687

    accuracy                           0.47     74574
   macro avg       0.50      0.50      0.36     74574
weighted avg       0.50      0.47      0.35     74574

completed
