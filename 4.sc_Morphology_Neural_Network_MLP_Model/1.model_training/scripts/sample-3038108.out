[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '96736ce1'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '6c5f572a'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '12f7a701'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '26386e4d'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_Nigericin_1.000_3.0_DMSO_0.025'
 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (28054, 1276)
Number of total missing values across all columns: 0
Data Subset Is Off
Wells held out for testing: ['L16' 'M20']
Wells to use for training, validation, and testing ['M16' 'L17' 'M17' 'L20' 'L21' 'M21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.697540).  Saving model ...
	 Train_Loss: 0.6952 Train_Acc: 50.567 Val_Loss: 0.6975  BEST VAL Loss: 0.6975  Val_Acc: 52.367

Epoch 1: Validation loss decreased (0.697540 --> 0.689293).  Saving model ...
	 Train_Loss: 0.6904 Train_Acc: 52.513 Val_Loss: 0.6893  BEST VAL Loss: 0.6893  Val_Acc: 56.662

Epoch 2: Validation loss decreased (0.689293 --> 0.684809).  Saving model ...
	 Train_Loss: 0.6861 Train_Acc: 56.027 Val_Loss: 0.6848  BEST VAL Loss: 0.6848  Val_Acc: 59.932

Epoch 3: Validation loss decreased (0.684809 --> 0.678774).  Saving model ...
	 Train_Loss: 0.6817 Train_Acc: 59.096 Val_Loss: 0.6788  BEST VAL Loss: 0.6788  Val_Acc: 62.518

Epoch 4: Validation loss decreased (0.678774 --> 0.676967).  Saving model ...
	 Train_Loss: 0.6775 Train_Acc: 60.688 Val_Loss: 0.6770  BEST VAL Loss: 0.6770  Val_Acc: 64.519

Epoch 5: Validation loss decreased (0.676967 --> 0.670879).  Saving model ...
	 Train_Loss: 0.6733 Train_Acc: 61.768 Val_Loss: 0.6709  BEST VAL Loss: 0.6709  Val_Acc: 65.935

Epoch 6: Validation loss decreased (0.670879 --> 0.666857).  Saving model ...
	 Train_Loss: 0.6692 Train_Acc: 62.933 Val_Loss: 0.6669  BEST VAL Loss: 0.6669  Val_Acc: 66.276

Epoch 7: Validation loss decreased (0.666857 --> 0.663297).  Saving model ...
	 Train_Loss: 0.6656 Train_Acc: 63.592 Val_Loss: 0.6633  BEST VAL Loss: 0.6633  Val_Acc: 67.252

Epoch 8: Validation loss decreased (0.663297 --> 0.659527).  Saving model ...
	 Train_Loss: 0.6620 Train_Acc: 64.696 Val_Loss: 0.6595  BEST VAL Loss: 0.6595  Val_Acc: 67.057

Epoch 9: Validation loss decreased (0.659527 --> 0.655677).  Saving model ...
	 Train_Loss: 0.6585 Train_Acc: 65.386 Val_Loss: 0.6557  BEST VAL Loss: 0.6557  Val_Acc: 67.643

Epoch 10: Validation loss decreased (0.655677 --> 0.652775).  Saving model ...
	 Train_Loss: 0.6554 Train_Acc: 65.550 Val_Loss: 0.6528  BEST VAL Loss: 0.6528  Val_Acc: 67.936

Epoch 11: Validation loss decreased (0.652775 --> 0.648815).  Saving model ...
	 Train_Loss: 0.6522 Train_Acc: 66.203 Val_Loss: 0.6488  BEST VAL Loss: 0.6488  Val_Acc: 68.375

Epoch 12: Validation loss decreased (0.648815 --> 0.646920).  Saving model ...
	 Train_Loss: 0.6491 Train_Acc: 66.728 Val_Loss: 0.6469  BEST VAL Loss: 0.6469  Val_Acc: 68.814

Epoch 13: Validation loss decreased (0.646920 --> 0.643369).  Saving model ...
	 Train_Loss: 0.6462 Train_Acc: 67.411 Val_Loss: 0.6434  BEST VAL Loss: 0.6434  Val_Acc: 68.912

Epoch 14: Validation loss decreased (0.643369 --> 0.641610).  Saving model ...
	 Train_Loss: 0.6434 Train_Acc: 67.258 Val_Loss: 0.6416  BEST VAL Loss: 0.6416  Val_Acc: 69.204

Epoch 15: Validation loss decreased (0.641610 --> 0.639062).  Saving model ...
	 Train_Loss: 0.6409 Train_Acc: 67.814 Val_Loss: 0.6391  BEST VAL Loss: 0.6391  Val_Acc: 69.253

Epoch 16: Validation loss decreased (0.639062 --> 0.636499).  Saving model ...
	 Train_Loss: 0.6384 Train_Acc: 67.990 Val_Loss: 0.6365  BEST VAL Loss: 0.6365  Val_Acc: 68.863

Epoch 17: Validation loss decreased (0.636499 --> 0.635103).  Saving model ...
	 Train_Loss: 0.6359 Train_Acc: 68.546 Val_Loss: 0.6351  BEST VAL Loss: 0.6351  Val_Acc: 69.204

Epoch 18: Validation loss decreased (0.635103 --> 0.632248).  Saving model ...
	 Train_Loss: 0.6335 Train_Acc: 68.771 Val_Loss: 0.6322  BEST VAL Loss: 0.6322  Val_Acc: 69.741

Epoch 19: Validation loss decreased (0.632248 --> 0.630082).  Saving model ...
	 Train_Loss: 0.6311 Train_Acc: 68.674 Val_Loss: 0.6301  BEST VAL Loss: 0.6301  Val_Acc: 70.181

Epoch 20: Validation loss decreased (0.630082 --> 0.628183).  Saving model ...
	 Train_Loss: 0.6288 Train_Acc: 69.357 Val_Loss: 0.6282  BEST VAL Loss: 0.6282  Val_Acc: 70.083

Epoch 21: Validation loss decreased (0.628183 --> 0.625164).  Saving model ...
	 Train_Loss: 0.6265 Train_Acc: 69.607 Val_Loss: 0.6252  BEST VAL Loss: 0.6252  Val_Acc: 70.669

Epoch 22: Validation loss decreased (0.625164 --> 0.623119).  Saving model ...
	 Train_Loss: 0.6244 Train_Acc: 69.577 Val_Loss: 0.6231  BEST VAL Loss: 0.6231  Val_Acc: 70.522

Epoch 23: Validation loss decreased (0.623119 --> 0.620619).  Saving model ...
	 Train_Loss: 0.6224 Train_Acc: 69.943 Val_Loss: 0.6206  BEST VAL Loss: 0.6206  Val_Acc: 70.620

Epoch 24: Validation loss decreased (0.620619 --> 0.618371).  Saving model ...
	 Train_Loss: 0.6203 Train_Acc: 70.400 Val_Loss: 0.6184  BEST VAL Loss: 0.6184  Val_Acc: 70.864

Epoch 25: Validation loss decreased (0.618371 --> 0.617058).  Saving model ...
	 Train_Loss: 0.6183 Train_Acc: 70.455 Val_Loss: 0.6171  BEST VAL Loss: 0.6171  Val_Acc: 71.254

Epoch 26: Validation loss decreased (0.617058 --> 0.615134).  Saving model ...
	 Train_Loss: 0.6163 Train_Acc: 70.693 Val_Loss: 0.6151  BEST VAL Loss: 0.6151  Val_Acc: 71.059

Epoch 27: Validation loss decreased (0.615134 --> 0.613564).  Saving model ...
	 Train_Loss: 0.6144 Train_Acc: 70.717 Val_Loss: 0.6136  BEST VAL Loss: 0.6136  Val_Acc: 71.596

Epoch 28: Validation loss decreased (0.613564 --> 0.612625).  Saving model ...
	 Train_Loss: 0.6126 Train_Acc: 70.736 Val_Loss: 0.6126  BEST VAL Loss: 0.6126  Val_Acc: 71.108

Epoch 29: Validation loss decreased (0.612625 --> 0.610332).  Saving model ...
	 Train_Loss: 0.6109 Train_Acc: 71.230 Val_Loss: 0.6103  BEST VAL Loss: 0.6103  Val_Acc: 71.352

Epoch 30: Validation loss decreased (0.610332 --> 0.608815).  Saving model ...
	 Train_Loss: 0.6091 Train_Acc: 71.681 Val_Loss: 0.6088  BEST VAL Loss: 0.6088  Val_Acc: 71.742

Epoch 31: Validation loss decreased (0.608815 --> 0.606033).  Saving model ...
	 Train_Loss: 0.6074 Train_Acc: 71.327 Val_Loss: 0.6060  BEST VAL Loss: 0.6060  Val_Acc: 71.254

Epoch 32: Validation loss decreased (0.606033 --> 0.603986).  Saving model ...
	 Train_Loss: 0.6057 Train_Acc: 72.139 Val_Loss: 0.6040  BEST VAL Loss: 0.6040  Val_Acc: 70.864

Epoch 33: Validation loss decreased (0.603986 --> 0.602854).  Saving model ...
	 Train_Loss: 0.6041 Train_Acc: 71.645 Val_Loss: 0.6029  BEST VAL Loss: 0.6029  Val_Acc: 72.182

Epoch 34: Validation loss decreased (0.602854 --> 0.601450).  Saving model ...
	 Train_Loss: 0.6025 Train_Acc: 72.060 Val_Loss: 0.6015  BEST VAL Loss: 0.6015  Val_Acc: 71.791

Epoch 35: Validation loss decreased (0.601450 --> 0.600839).  Saving model ...
	 Train_Loss: 0.6009 Train_Acc: 72.114 Val_Loss: 0.6008  BEST VAL Loss: 0.6008  Val_Acc: 72.182

Epoch 36: Validation loss decreased (0.600839 --> 0.599367).  Saving model ...
	 Train_Loss: 0.5993 Train_Acc: 72.480 Val_Loss: 0.5994  BEST VAL Loss: 0.5994  Val_Acc: 71.498

Epoch 37: Validation loss decreased (0.599367 --> 0.597738).  Saving model ...
	 Train_Loss: 0.5977 Train_Acc: 72.779 Val_Loss: 0.5977  BEST VAL Loss: 0.5977  Val_Acc: 72.572

Epoch 38: Validation loss decreased (0.597738 --> 0.596539).  Saving model ...
	 Train_Loss: 0.5963 Train_Acc: 72.444 Val_Loss: 0.5965  BEST VAL Loss: 0.5965  Val_Acc: 71.645

Epoch 39: Validation loss decreased (0.596539 --> 0.595284).  Saving model ...
	 Train_Loss: 0.5948 Train_Acc: 72.877 Val_Loss: 0.5953  BEST VAL Loss: 0.5953  Val_Acc: 72.377

Epoch 40: Validation loss decreased (0.595284 --> 0.595010).  Saving model ...
	 Train_Loss: 0.5934 Train_Acc: 72.371 Val_Loss: 0.5950  BEST VAL Loss: 0.5950  Val_Acc: 71.791

Epoch 41: Validation loss decreased (0.595010 --> 0.593860).  Saving model ...
	 Train_Loss: 0.5920 Train_Acc: 73.030 Val_Loss: 0.5939  BEST VAL Loss: 0.5939  Val_Acc: 71.498

Epoch 42: Validation loss decreased (0.593860 --> 0.593313).  Saving model ...
	 Train_Loss: 0.5906 Train_Acc: 73.188 Val_Loss: 0.5933  BEST VAL Loss: 0.5933  Val_Acc: 72.230

Epoch 43: Validation loss decreased (0.593313 --> 0.592599).  Saving model ...
	 Train_Loss: 0.5893 Train_Acc: 73.164 Val_Loss: 0.5926  BEST VAL Loss: 0.5926  Val_Acc: 71.059

Epoch 44: Validation loss decreased (0.592599 --> 0.591892).  Saving model ...
	 Train_Loss: 0.5880 Train_Acc: 73.335 Val_Loss: 0.5919  BEST VAL Loss: 0.5919  Val_Acc: 71.401

Epoch 45: Validation loss decreased (0.591892 --> 0.590550).  Saving model ...
	 Train_Loss: 0.5867 Train_Acc: 73.499 Val_Loss: 0.5905  BEST VAL Loss: 0.5905  Val_Acc: 72.328

Epoch 46: Validation loss decreased (0.590550 --> 0.589900).  Saving model ...
	 Train_Loss: 0.5854 Train_Acc: 73.493 Val_Loss: 0.5899  BEST VAL Loss: 0.5899  Val_Acc: 72.035

Epoch 47: Validation loss decreased (0.589900 --> 0.589456).  Saving model ...
	 Train_Loss: 0.5841 Train_Acc: 73.585 Val_Loss: 0.5895  BEST VAL Loss: 0.5895  Val_Acc: 71.401

Epoch 48: Validation loss decreased (0.589456 --> 0.588375).  Saving model ...
	 Train_Loss: 0.5830 Train_Acc: 73.664 Val_Loss: 0.5884  BEST VAL Loss: 0.5884  Val_Acc: 72.572

Epoch 49: Validation loss decreased (0.588375 --> 0.587605).  Saving model ...
	 Train_Loss: 0.5819 Train_Acc: 73.810 Val_Loss: 0.5876  BEST VAL Loss: 0.5876  Val_Acc: 72.328

Epoch 50: Validation loss decreased (0.587605 --> 0.586606).  Saving model ...
	 Train_Loss: 0.5807 Train_Acc: 73.579 Val_Loss: 0.5866  BEST VAL Loss: 0.5866  Val_Acc: 72.962

Epoch 51: Validation loss decreased (0.586606 --> 0.585465).  Saving model ...
	 Train_Loss: 0.5795 Train_Acc: 74.079 Val_Loss: 0.5855  BEST VAL Loss: 0.5855  Val_Acc: 71.938

Epoch 52: Validation loss decreased (0.585465 --> 0.584147).  Saving model ...
	 Train_Loss: 0.5784 Train_Acc: 74.542 Val_Loss: 0.5841  BEST VAL Loss: 0.5841  Val_Acc: 72.572

Epoch 53: Validation loss decreased (0.584147 --> 0.583166).  Saving model ...
	 Train_Loss: 0.5773 Train_Acc: 74.494 Val_Loss: 0.5832  BEST VAL Loss: 0.5832  Val_Acc: 72.474

Epoch 54: Validation loss decreased (0.583166 --> 0.581979).  Saving model ...
	 Train_Loss: 0.5763 Train_Acc: 73.939 Val_Loss: 0.5820  BEST VAL Loss: 0.5820  Val_Acc: 71.303

Epoch 55: Validation loss decreased (0.581979 --> 0.581314).  Saving model ...
	 Train_Loss: 0.5752 Train_Acc: 74.512 Val_Loss: 0.5813  BEST VAL Loss: 0.5813  Val_Acc: 72.377

Epoch 56: Validation loss decreased (0.581314 --> 0.580489).  Saving model ...
	 Train_Loss: 0.5741 Train_Acc: 74.713 Val_Loss: 0.5805  BEST VAL Loss: 0.5805  Val_Acc: 71.645

Epoch 57: Validation loss decreased (0.580489 --> 0.579597).  Saving model ...
	 Train_Loss: 0.5731 Train_Acc: 74.280 Val_Loss: 0.5796  BEST VAL Loss: 0.5796  Val_Acc: 72.621

Epoch 58: Validation loss decreased (0.579597 --> 0.578827).  Saving model ...
	 Train_Loss: 0.5721 Train_Acc: 74.701 Val_Loss: 0.5788  BEST VAL Loss: 0.5788  Val_Acc: 71.303

Epoch 59: Validation loss decreased (0.578827 --> 0.577315).  Saving model ...
	 Train_Loss: 0.5711 Train_Acc: 74.768 Val_Loss: 0.5773  BEST VAL Loss: 0.5773  Val_Acc: 72.279

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.5701 Train_Acc: 74.549 Val_Loss: 0.5776  BEST VAL Loss: 0.5773  Val_Acc: 72.767

Epoch 61: Validation loss decreased (0.577315 --> 0.576862).  Saving model ...
	 Train_Loss: 0.5691 Train_Acc: 75.323 Val_Loss: 0.5769  BEST VAL Loss: 0.5769  Val_Acc: 71.889

Epoch 62: Validation loss decreased (0.576862 --> 0.576237).  Saving model ...
	 Train_Loss: 0.5681 Train_Acc: 74.793 Val_Loss: 0.5762  BEST VAL Loss: 0.5762  Val_Acc: 72.377

Epoch 63: Validation loss decreased (0.576237 --> 0.575424).  Saving model ...
	 Train_Loss: 0.5672 Train_Acc: 75.104 Val_Loss: 0.5754  BEST VAL Loss: 0.5754  Val_Acc: 72.182

Epoch 64: Validation loss decreased (0.575424 --> 0.574327).  Saving model ...
	 Train_Loss: 0.5662 Train_Acc: 74.841 Val_Loss: 0.5743  BEST VAL Loss: 0.5743  Val_Acc: 72.474

Epoch 65: Validation loss decreased (0.574327 --> 0.573861).  Saving model ...
	 Train_Loss: 0.5653 Train_Acc: 74.854 Val_Loss: 0.5739  BEST VAL Loss: 0.5739  Val_Acc: 72.230

Epoch 66: Validation loss decreased (0.573861 --> 0.573233).  Saving model ...
	 Train_Loss: 0.5644 Train_Acc: 75.055 Val_Loss: 0.5732  BEST VAL Loss: 0.5732  Val_Acc: 72.865

Epoch 67: Validation loss decreased (0.573233 --> 0.572512).  Saving model ...
	 Train_Loss: 0.5636 Train_Acc: 74.847 Val_Loss: 0.5725  BEST VAL Loss: 0.5725  Val_Acc: 72.182

Epoch 68: Validation loss decreased (0.572512 --> 0.571766).  Saving model ...
	 Train_Loss: 0.5627 Train_Acc: 74.902 Val_Loss: 0.5718  BEST VAL Loss: 0.5718  Val_Acc: 72.230

Epoch 69: Validation loss decreased (0.571766 --> 0.571619).  Saving model ...
	 Train_Loss: 0.5618 Train_Acc: 75.287 Val_Loss: 0.5716  BEST VAL Loss: 0.5716  Val_Acc: 72.230

Epoch 70: Validation loss decreased (0.571619 --> 0.571026).  Saving model ...
	 Train_Loss: 0.5610 Train_Acc: 75.409 Val_Loss: 0.5710  BEST VAL Loss: 0.5710  Val_Acc: 72.523

Epoch 71: Validation loss decreased (0.571026 --> 0.570063).  Saving model ...
	 Train_Loss: 0.5602 Train_Acc: 75.226 Val_Loss: 0.5701  BEST VAL Loss: 0.5701  Val_Acc: 72.962

Epoch 72: Validation loss decreased (0.570063 --> 0.569397).  Saving model ...
	 Train_Loss: 0.5593 Train_Acc: 75.201 Val_Loss: 0.5694  BEST VAL Loss: 0.5694  Val_Acc: 72.328

Epoch 73: Validation loss decreased (0.569397 --> 0.569298).  Saving model ...
	 Train_Loss: 0.5585 Train_Acc: 75.165 Val_Loss: 0.5693  BEST VAL Loss: 0.5693  Val_Acc: 72.084

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.5577 Train_Acc: 75.714 Val_Loss: 0.5694  BEST VAL Loss: 0.5693  Val_Acc: 71.840

Epoch 75: Validation loss decreased (0.569298 --> 0.569150).  Saving model ...
	 Train_Loss: 0.5569 Train_Acc: 76.007 Val_Loss: 0.5691  BEST VAL Loss: 0.5691  Val_Acc: 72.230

Epoch 76: Validation loss decreased (0.569150 --> 0.568943).  Saving model ...
	 Train_Loss: 0.5562 Train_Acc: 76.110 Val_Loss: 0.5689  BEST VAL Loss: 0.5689  Val_Acc: 72.182

Epoch 77: Validation loss decreased (0.568943 --> 0.568111).  Saving model ...
	 Train_Loss: 0.5554 Train_Acc: 75.561 Val_Loss: 0.5681  BEST VAL Loss: 0.5681  Val_Acc: 72.767

Epoch 78: Validation loss decreased (0.568111 --> 0.567771).  Saving model ...
	 Train_Loss: 0.5546 Train_Acc: 75.769 Val_Loss: 0.5678  BEST VAL Loss: 0.5678  Val_Acc: 72.523

Epoch 79: Validation loss decreased (0.567771 --> 0.567188).  Saving model ...
	 Train_Loss: 0.5538 Train_Acc: 75.970 Val_Loss: 0.5672  BEST VAL Loss: 0.5672  Val_Acc: 72.279

Epoch 80: Validation loss decreased (0.567188 --> 0.566732).  Saving model ...
	 Train_Loss: 0.5530 Train_Acc: 76.007 Val_Loss: 0.5667  BEST VAL Loss: 0.5667  Val_Acc: 72.621

Epoch 81: Validation loss decreased (0.566732 --> 0.566434).  Saving model ...
	 Train_Loss: 0.5523 Train_Acc: 76.074 Val_Loss: 0.5664  BEST VAL Loss: 0.5664  Val_Acc: 71.157

Epoch 82: Validation loss decreased (0.566434 --> 0.566226).  Saving model ...
	 Train_Loss: 0.5515 Train_Acc: 75.897 Val_Loss: 0.5662  BEST VAL Loss: 0.5662  Val_Acc: 71.449

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.5508 Train_Acc: 75.409 Val_Loss: 0.5663  BEST VAL Loss: 0.5662  Val_Acc: 72.718

Epoch 84: Validation loss decreased (0.566226 --> 0.565899).  Saving model ...
	 Train_Loss: 0.5501 Train_Acc: 76.153 Val_Loss: 0.5659  BEST VAL Loss: 0.5659  Val_Acc: 72.718

Epoch 85: Validation loss decreased (0.565899 --> 0.565623).  Saving model ...
	 Train_Loss: 0.5494 Train_Acc: 76.275 Val_Loss: 0.5656  BEST VAL Loss: 0.5656  Val_Acc: 72.426

Epoch 86: Validation loss decreased (0.565623 --> 0.565208).  Saving model ...
	 Train_Loss: 0.5486 Train_Acc: 76.190 Val_Loss: 0.5652  BEST VAL Loss: 0.5652  Val_Acc: 72.426

Epoch 87: Validation loss decreased (0.565208 --> 0.564668).  Saving model ...
	 Train_Loss: 0.5480 Train_Acc: 76.354 Val_Loss: 0.5647  BEST VAL Loss: 0.5647  Val_Acc: 72.133

Epoch 88: Validation loss decreased (0.564668 --> 0.564269).  Saving model ...
	 Train_Loss: 0.5472 Train_Acc: 76.659 Val_Loss: 0.5643  BEST VAL Loss: 0.5643  Val_Acc: 73.060

Epoch 89: Validation loss decreased (0.564269 --> 0.564086).  Saving model ...
	 Train_Loss: 0.5466 Train_Acc: 76.452 Val_Loss: 0.5641  BEST VAL Loss: 0.5641  Val_Acc: 72.670

Epoch 90: Validation loss decreased (0.564086 --> 0.563776).  Saving model ...
	 Train_Loss: 0.5459 Train_Acc: 76.482 Val_Loss: 0.5638  BEST VAL Loss: 0.5638  Val_Acc: 72.670

Epoch 91: Validation loss decreased (0.563776 --> 0.563438).  Saving model ...
	 Train_Loss: 0.5452 Train_Acc: 76.263 Val_Loss: 0.5634  BEST VAL Loss: 0.5634  Val_Acc: 72.377

Epoch 92: Validation loss decreased (0.563438 --> 0.563247).  Saving model ...
	 Train_Loss: 0.5446 Train_Acc: 76.287 Val_Loss: 0.5632  BEST VAL Loss: 0.5632  Val_Acc: 72.377

Epoch 93: Validation loss decreased (0.563247 --> 0.562855).  Saving model ...
	 Train_Loss: 0.5440 Train_Acc: 76.397 Val_Loss: 0.5629  BEST VAL Loss: 0.5629  Val_Acc: 72.914

Epoch 94: Validation loss decreased (0.562855 --> 0.562253).  Saving model ...
	 Train_Loss: 0.5433 Train_Acc: 76.568 Val_Loss: 0.5623  BEST VAL Loss: 0.5623  Val_Acc: 72.914

Epoch 95: Validation loss decreased (0.562253 --> 0.561641).  Saving model ...
	 Train_Loss: 0.5427 Train_Acc: 76.373 Val_Loss: 0.5616  BEST VAL Loss: 0.5616  Val_Acc: 72.474

Epoch 96: Validation loss decreased (0.561641 --> 0.561056).  Saving model ...
	 Train_Loss: 0.5420 Train_Acc: 76.556 Val_Loss: 0.5611  BEST VAL Loss: 0.5611  Val_Acc: 72.962

Epoch 97: Validation loss decreased (0.561056 --> 0.560784).  Saving model ...
	 Train_Loss: 0.5414 Train_Acc: 76.836 Val_Loss: 0.5608  BEST VAL Loss: 0.5608  Val_Acc: 72.572

Epoch 98: Validation loss did not decrease
	 Train_Loss: 0.5408 Train_Acc: 77.025 Val_Loss: 0.5609  BEST VAL Loss: 0.5608  Val_Acc: 72.621

Epoch 99: Validation loss decreased (0.560784 --> 0.560514).  Saving model ...
	 Train_Loss: 0.5402 Train_Acc: 76.885 Val_Loss: 0.5605  BEST VAL Loss: 0.5605  Val_Acc: 71.791

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.43      0.47      8453
           1       0.48      0.56      0.52      7939

    accuracy                           0.49     16392
   macro avg       0.49      0.49      0.49     16392
weighted avg       0.49      0.49      0.49     16392

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.43      0.46      1057
           1       0.48      0.55      0.51       992

    accuracy                           0.49      2049
   macro avg       0.49      0.49      0.49      2049
weighted avg       0.49      0.49      0.49      2049

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.53      0.45      0.49      1057
           1       0.50      0.57      0.53       992

    accuracy                           0.51      2049
   macro avg       0.51      0.51      0.51      2049
weighted avg       0.51      0.51      0.51      2049

              precision    recall  f1-score   support

           0       0.53      0.45      0.49      1057
           1       0.50      0.57      0.53       992

    accuracy                           0.51      2049
   macro avg       0.51      0.51      0.51      2049
weighted avg       0.51      0.51      0.51      2049

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.27      0.35      3835
           1       0.49      0.74      0.59      3729

    accuracy                           0.50      7564
   macro avg       0.50      0.50      0.47      7564
weighted avg       0.50      0.50      0.47      7564

              precision    recall  f1-score   support

           0       0.51      0.27      0.35      3835
           1       0.49      0.74      0.59      3729

    accuracy                           0.50      7564
   macro avg       0.50      0.50      0.47      7564
weighted avg       0.50      0.50      0.47      7564

completed
