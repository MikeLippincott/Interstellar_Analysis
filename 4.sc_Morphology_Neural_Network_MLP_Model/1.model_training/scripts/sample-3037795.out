[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ac65600e'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '0d2104d8'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '08f7cc55'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '1492bd2a'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: DMSO_0.100_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: DMSO_0.100_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (50571, 1276)
Number of total missing values across all columns: 101142
Data Subset Is Off
Wells held out for testing: ['I14' 'L23']
Wells to use for training, validation, and testing ['B14' 'C14' 'B15' 'C15' 'J14' 'I15' 'J15' 'L18' 'L19' 'L22']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.526115).  Saving model ...
	 Train_Loss: 0.5741 Train_Acc: 71.604 Val_Loss: 0.5261  BEST VAL Loss: 0.5261  Val_Acc: 72.563

Epoch 1: Validation loss decreased (0.526115 --> 0.520963).  Saving model ...
	 Train_Loss: 0.5514 Train_Acc: 73.816 Val_Loss: 0.5210  BEST VAL Loss: 0.5210  Val_Acc: 74.466

Epoch 2: Validation loss decreased (0.520963 --> 0.508660).  Saving model ...
	 Train_Loss: 0.5389 Train_Acc: 74.829 Val_Loss: 0.5087  BEST VAL Loss: 0.5087  Val_Acc: 76.274

Epoch 3: Validation loss decreased (0.508660 --> 0.507282).  Saving model ...
	 Train_Loss: 0.5287 Train_Acc: 75.499 Val_Loss: 0.5073  BEST VAL Loss: 0.5073  Val_Acc: 75.805

Epoch 4: Validation loss decreased (0.507282 --> 0.504550).  Saving model ...
	 Train_Loss: 0.5215 Train_Acc: 75.918 Val_Loss: 0.5046  BEST VAL Loss: 0.5046  Val_Acc: 76.204

Epoch 5: Validation loss decreased (0.504550 --> 0.500756).  Saving model ...
	 Train_Loss: 0.5155 Train_Acc: 76.670 Val_Loss: 0.5008  BEST VAL Loss: 0.5008  Val_Acc: 77.566

Epoch 6: Validation loss decreased (0.500756 --> 0.497725).  Saving model ...
	 Train_Loss: 0.5101 Train_Acc: 76.899 Val_Loss: 0.4977  BEST VAL Loss: 0.4977  Val_Acc: 77.613

Epoch 7: Validation loss decreased (0.497725 --> 0.496051).  Saving model ...
	 Train_Loss: 0.5055 Train_Acc: 77.196 Val_Loss: 0.4961  BEST VAL Loss: 0.4961  Val_Acc: 77.144

Epoch 8: Validation loss decreased (0.496051 --> 0.493344).  Saving model ...
	 Train_Loss: 0.5019 Train_Acc: 76.741 Val_Loss: 0.4933  BEST VAL Loss: 0.4933  Val_Acc: 77.919

Epoch 9: Validation loss decreased (0.493344 --> 0.489692).  Saving model ...
	 Train_Loss: 0.4981 Train_Acc: 77.322 Val_Loss: 0.4897  BEST VAL Loss: 0.4897  Val_Acc: 78.459

Epoch 10: Validation loss decreased (0.489692 --> 0.487820).  Saving model ...
	 Train_Loss: 0.4947 Train_Acc: 77.446 Val_Loss: 0.4878  BEST VAL Loss: 0.4878  Val_Acc: 78.389

Epoch 11: Validation loss decreased (0.487820 --> 0.486076).  Saving model ...
	 Train_Loss: 0.4912 Train_Acc: 77.689 Val_Loss: 0.4861  BEST VAL Loss: 0.4861  Val_Acc: 78.764

Epoch 12: Validation loss decreased (0.486076 --> 0.484887).  Saving model ...
	 Train_Loss: 0.4879 Train_Acc: 78.083 Val_Loss: 0.4849  BEST VAL Loss: 0.4849  Val_Acc: 78.013

Epoch 13: Validation loss decreased (0.484887 --> 0.484382).  Saving model ...
	 Train_Loss: 0.4852 Train_Acc: 78.106 Val_Loss: 0.4844  BEST VAL Loss: 0.4844  Val_Acc: 78.271

Epoch 14: Validation loss decreased (0.484382 --> 0.483075).  Saving model ...
	 Train_Loss: 0.4826 Train_Acc: 78.048 Val_Loss: 0.4831  BEST VAL Loss: 0.4831  Val_Acc: 78.506

Epoch 15: Validation loss decreased (0.483075 --> 0.482672).  Saving model ...
	 Train_Loss: 0.4804 Train_Acc: 78.394 Val_Loss: 0.4827  BEST VAL Loss: 0.4827  Val_Acc: 78.248

Epoch 16: Validation loss decreased (0.482672 --> 0.481609).  Saving model ...
	 Train_Loss: 0.4783 Train_Acc: 78.244 Val_Loss: 0.4816  BEST VAL Loss: 0.4816  Val_Acc: 78.952

Epoch 17: Validation loss decreased (0.481609 --> 0.480113).  Saving model ...
	 Train_Loss: 0.4762 Train_Acc: 78.394 Val_Loss: 0.4801  BEST VAL Loss: 0.4801  Val_Acc: 78.529

Epoch 18: Validation loss decreased (0.480113 --> 0.479385).  Saving model ...
	 Train_Loss: 0.4744 Train_Acc: 78.250 Val_Loss: 0.4794  BEST VAL Loss: 0.4794  Val_Acc: 78.389

Epoch 19: Validation loss decreased (0.479385 --> 0.478767).  Saving model ...
	 Train_Loss: 0.4724 Train_Acc: 78.567 Val_Loss: 0.4788  BEST VAL Loss: 0.4788  Val_Acc: 79.140

Epoch 20: Validation loss decreased (0.478767 --> 0.478444).  Saving model ...
	 Train_Loss: 0.4705 Train_Acc: 78.799 Val_Loss: 0.4784  BEST VAL Loss: 0.4784  Val_Acc: 78.694

Epoch 21: Validation loss decreased (0.478444 --> 0.477771).  Saving model ...
	 Train_Loss: 0.4686 Train_Acc: 78.741 Val_Loss: 0.4778  BEST VAL Loss: 0.4778  Val_Acc: 78.858

Epoch 22: Validation loss decreased (0.477771 --> 0.477373).  Saving model ...
	 Train_Loss: 0.4669 Train_Acc: 78.667 Val_Loss: 0.4774  BEST VAL Loss: 0.4774  Val_Acc: 78.506

Epoch 23: Validation loss decreased (0.477373 --> 0.476648).  Saving model ...
	 Train_Loss: 0.4652 Train_Acc: 79.061 Val_Loss: 0.4766  BEST VAL Loss: 0.4766  Val_Acc: 79.140

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.4635 Train_Acc: 79.120 Val_Loss: 0.4767  BEST VAL Loss: 0.4766  Val_Acc: 78.342

Epoch 25: Validation loss decreased (0.476648 --> 0.476266).  Saving model ...
	 Train_Loss: 0.4616 Train_Acc: 79.255 Val_Loss: 0.4763  BEST VAL Loss: 0.4763  Val_Acc: 79.164

Epoch 26: Validation loss decreased (0.476266 --> 0.476184).  Saving model ...
	 Train_Loss: 0.4598 Train_Acc: 79.319 Val_Loss: 0.4762  BEST VAL Loss: 0.4762  Val_Acc: 78.647

Epoch 27: Validation loss decreased (0.476184 --> 0.475460).  Saving model ...
	 Train_Loss: 0.4583 Train_Acc: 78.949 Val_Loss: 0.4755  BEST VAL Loss: 0.4755  Val_Acc: 79.234

Epoch 28: Validation loss decreased (0.475460 --> 0.475046).  Saving model ...
	 Train_Loss: 0.4570 Train_Acc: 79.313 Val_Loss: 0.4750  BEST VAL Loss: 0.4750  Val_Acc: 78.905

Epoch 29: Validation loss did not decrease
	 Train_Loss: 0.4558 Train_Acc: 79.087 Val_Loss: 0.4756  BEST VAL Loss: 0.4750  Val_Acc: 78.835

Epoch 30: Validation loss decreased (0.475046 --> 0.474914).  Saving model ...
	 Train_Loss: 0.4546 Train_Acc: 79.234 Val_Loss: 0.4749  BEST VAL Loss: 0.4749  Val_Acc: 79.164

Epoch 31: Validation loss decreased (0.474914 --> 0.474553).  Saving model ...
	 Train_Loss: 0.4534 Train_Acc: 79.234 Val_Loss: 0.4746  BEST VAL Loss: 0.4746  Val_Acc: 78.811

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.4522 Train_Acc: 79.290 Val_Loss: 0.4747  BEST VAL Loss: 0.4746  Val_Acc: 78.929

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.4509 Train_Acc: 79.777 Val_Loss: 0.4746  BEST VAL Loss: 0.4746  Val_Acc: 78.858

Epoch 34: Validation loss did not decrease
	 Train_Loss: 0.4497 Train_Acc: 79.287 Val_Loss: 0.4752  BEST VAL Loss: 0.4746  Val_Acc: 78.342

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.4487 Train_Acc: 79.187 Val_Loss: 0.4748  BEST VAL Loss: 0.4746  Val_Acc: 78.952

Epoch 36: Validation loss decreased (0.474553 --> 0.474524).  Saving model ...
	 Train_Loss: 0.4476 Train_Acc: 79.231 Val_Loss: 0.4745  BEST VAL Loss: 0.4745  Val_Acc: 79.375

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.4466 Train_Acc: 79.463 Val_Loss: 0.4748  BEST VAL Loss: 0.4745  Val_Acc: 78.764

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.4455 Train_Acc: 79.343 Val_Loss: 0.4749  BEST VAL Loss: 0.4745  Val_Acc: 79.046

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.4445 Train_Acc: 79.545 Val_Loss: 0.4751  BEST VAL Loss: 0.4745  Val_Acc: 79.211

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.4435 Train_Acc: 79.401 Val_Loss: 0.4752  BEST VAL Loss: 0.4745  Val_Acc: 78.929

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.4423 Train_Acc: 79.904 Val_Loss: 0.4750  BEST VAL Loss: 0.4745  Val_Acc: 79.258

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.4413 Train_Acc: 79.998 Val_Loss: 0.4748  BEST VAL Loss: 0.4745  Val_Acc: 79.399

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.4402 Train_Acc: 80.089 Val_Loss: 0.4748  BEST VAL Loss: 0.4745  Val_Acc: 79.093

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.4394 Train_Acc: 79.763 Val_Loss: 0.4750  BEST VAL Loss: 0.4745  Val_Acc: 78.623

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.4386 Train_Acc: 79.792 Val_Loss: 0.4750  BEST VAL Loss: 0.4745  Val_Acc: 79.587

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.4376 Train_Acc: 79.680 Val_Loss: 0.4754  BEST VAL Loss: 0.4745  Val_Acc: 78.811

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.4366 Train_Acc: 80.109 Val_Loss: 0.4757  BEST VAL Loss: 0.4745  Val_Acc: 78.741

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.4357 Train_Acc: 79.848 Val_Loss: 0.4760  BEST VAL Loss: 0.4745  Val_Acc: 78.436

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.4349 Train_Acc: 80.121 Val_Loss: 0.4761  BEST VAL Loss: 0.4745  Val_Acc: 79.093

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.4341 Train_Acc: 79.989 Val_Loss: 0.4764  BEST VAL Loss: 0.4745  Val_Acc: 79.046

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.4333 Train_Acc: 79.836 Val_Loss: 0.4762  BEST VAL Loss: 0.4745  Val_Acc: 78.835

Epoch 52: Validation loss did not decrease
Early stopped at epoch : 52
DMSO_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.72      0.80      0.76     24644
           1       0.28      0.21      0.24      9407

    accuracy                           0.63     34051
   macro avg       0.50      0.50      0.50     34051
weighted avg       0.60      0.63      0.61     34051

DMSO_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.72      0.80      0.76      3081
           1       0.26      0.19      0.22      1176

    accuracy                           0.63      4257
   macro avg       0.49      0.49      0.49      4257
weighted avg       0.59      0.63      0.61      4257

DMSO_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.72      0.79      0.75      3081
           1       0.25      0.19      0.21      1176

    accuracy                           0.62      4257
   macro avg       0.49      0.49      0.48      4257
weighted avg       0.59      0.62      0.60      4257

              precision    recall  f1-score   support

           0       0.72      0.79      0.75      3081
           1       0.25      0.19      0.21      1176

    accuracy                           0.62      4257
   macro avg       0.49      0.49      0.48      4257
weighted avg       0.59      0.62      0.60      4257

DMSO_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.61      0.73      0.67      4837
           1       0.42      0.30      0.35      3169

    accuracy                           0.56      8006
   macro avg       0.51      0.51      0.51      8006
weighted avg       0.54      0.56      0.54      8006

              precision    recall  f1-score   support

           0       0.61      0.73      0.67      4837
           1       0.42      0.30      0.35      3169

    accuracy                           0.56      8006
   macro avg       0.51      0.51      0.51      8006
weighted avg       0.54      0.56      0.54      8006

completed
