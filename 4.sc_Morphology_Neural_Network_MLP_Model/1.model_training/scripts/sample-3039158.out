[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'de92f8fd'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '88cc0ecf'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1be66678'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'f529c08a'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: H2O2_100.000_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (383616, 1270)
Number of total missing values across all columns: 767232
Data Subset Is Off
Wells held out for testing: ['B09' 'I10']
Wells to use for training, validation, and testing ['B02' 'B03' 'B08' 'H04' 'I04' 'H05' 'I05' 'H10' 'H11' 'I11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.438973).  Saving model ...
	 Train_Loss: 0.5382 Train_Acc: 72.310 Val_Loss: 0.4390  BEST VAL Loss: 0.4390  Val_Acc: 81.203

Epoch 1: Validation loss decreased (0.438973 --> 0.413315).  Saving model ...
	 Train_Loss: 0.4975 Train_Acc: 78.684 Val_Loss: 0.4133  BEST VAL Loss: 0.4133  Val_Acc: 83.340

Epoch 2: Validation loss decreased (0.413315 --> 0.397092).  Saving model ...
	 Train_Loss: 0.4743 Train_Acc: 80.525 Val_Loss: 0.3971  BEST VAL Loss: 0.3971  Val_Acc: 84.689

Epoch 3: Validation loss decreased (0.397092 --> 0.385468).  Saving model ...
	 Train_Loss: 0.4592 Train_Acc: 81.276 Val_Loss: 0.3855  BEST VAL Loss: 0.3855  Val_Acc: 85.600

Epoch 4: Validation loss decreased (0.385468 --> 0.378182).  Saving model ...
	 Train_Loss: 0.4485 Train_Acc: 81.586 Val_Loss: 0.3782  BEST VAL Loss: 0.3782  Val_Acc: 85.163

Epoch 5: Validation loss decreased (0.378182 --> 0.372689).  Saving model ...
	 Train_Loss: 0.4399 Train_Acc: 82.173 Val_Loss: 0.3727  BEST VAL Loss: 0.3727  Val_Acc: 85.904

Epoch 6: Validation loss decreased (0.372689 --> 0.367492).  Saving model ...
	 Train_Loss: 0.4336 Train_Acc: 82.172 Val_Loss: 0.3675  BEST VAL Loss: 0.3675  Val_Acc: 86.117

Epoch 7: Validation loss decreased (0.367492 --> 0.362571).  Saving model ...
	 Train_Loss: 0.4279 Train_Acc: 82.489 Val_Loss: 0.3626  BEST VAL Loss: 0.3626  Val_Acc: 86.748

Epoch 8: Validation loss decreased (0.362571 --> 0.358553).  Saving model ...
	 Train_Loss: 0.4232 Train_Acc: 82.522 Val_Loss: 0.3586  BEST VAL Loss: 0.3586  Val_Acc: 86.723

Epoch 9: Validation loss decreased (0.358553 --> 0.355136).  Saving model ...
	 Train_Loss: 0.4192 Train_Acc: 82.770 Val_Loss: 0.3551  BEST VAL Loss: 0.3551  Val_Acc: 86.732

Epoch 10: Validation loss decreased (0.355136 --> 0.352083).  Saving model ...
	 Train_Loss: 0.4157 Train_Acc: 82.808 Val_Loss: 0.3521  BEST VAL Loss: 0.3521  Val_Acc: 86.795

Epoch 11: Validation loss decreased (0.352083 --> 0.349047).  Saving model ...
	 Train_Loss: 0.4126 Train_Acc: 82.930 Val_Loss: 0.3490  BEST VAL Loss: 0.3490  Val_Acc: 87.178

Epoch 12: Validation loss decreased (0.349047 --> 0.346293).  Saving model ...
	 Train_Loss: 0.4098 Train_Acc: 83.136 Val_Loss: 0.3463  BEST VAL Loss: 0.3463  Val_Acc: 87.219

Epoch 13: Validation loss decreased (0.346293 --> 0.344071).  Saving model ...
	 Train_Loss: 0.4074 Train_Acc: 83.034 Val_Loss: 0.3441  BEST VAL Loss: 0.3441  Val_Acc: 87.426

Epoch 14: Validation loss decreased (0.344071 --> 0.342456).  Saving model ...
	 Train_Loss: 0.4051 Train_Acc: 83.167 Val_Loss: 0.3425  BEST VAL Loss: 0.3425  Val_Acc: 86.695

Epoch 15: Validation loss decreased (0.342456 --> 0.340543).  Saving model ...
	 Train_Loss: 0.4031 Train_Acc: 83.147 Val_Loss: 0.3405  BEST VAL Loss: 0.3405  Val_Acc: 87.580

Epoch 16: Validation loss decreased (0.340543 --> 0.338985).  Saving model ...
	 Train_Loss: 0.4013 Train_Acc: 83.139 Val_Loss: 0.3390  BEST VAL Loss: 0.3390  Val_Acc: 87.307

Epoch 17: Validation loss decreased (0.338985 --> 0.337685).  Saving model ...
	 Train_Loss: 0.3996 Train_Acc: 83.276 Val_Loss: 0.3377  BEST VAL Loss: 0.3377  Val_Acc: 87.460

Epoch 18: Validation loss decreased (0.337685 --> 0.336599).  Saving model ...
	 Train_Loss: 0.3979 Train_Acc: 83.349 Val_Loss: 0.3366  BEST VAL Loss: 0.3366  Val_Acc: 87.470

Epoch 19: Validation loss decreased (0.336599 --> 0.335149).  Saving model ...
	 Train_Loss: 0.3964 Train_Acc: 83.325 Val_Loss: 0.3351  BEST VAL Loss: 0.3351  Val_Acc: 87.464

Epoch 20: Validation loss decreased (0.335149 --> 0.334094).  Saving model ...
	 Train_Loss: 0.3950 Train_Acc: 83.334 Val_Loss: 0.3341  BEST VAL Loss: 0.3341  Val_Acc: 87.451

Epoch 21: Validation loss decreased (0.334094 --> 0.332972).  Saving model ...
	 Train_Loss: 0.3936 Train_Acc: 83.390 Val_Loss: 0.3330  BEST VAL Loss: 0.3330  Val_Acc: 87.724

Epoch 22: Validation loss decreased (0.332972 --> 0.331893).  Saving model ...
	 Train_Loss: 0.3923 Train_Acc: 83.504 Val_Loss: 0.3319  BEST VAL Loss: 0.3319  Val_Acc: 87.536

Epoch 23: Validation loss decreased (0.331893 --> 0.330943).  Saving model ...
	 Train_Loss: 0.3911 Train_Acc: 83.525 Val_Loss: 0.3309  BEST VAL Loss: 0.3309  Val_Acc: 87.737

Epoch 24: Validation loss decreased (0.330943 --> 0.330096).  Saving model ...
	 Train_Loss: 0.3900 Train_Acc: 83.435 Val_Loss: 0.3301  BEST VAL Loss: 0.3301  Val_Acc: 87.664

Epoch 25: Validation loss decreased (0.330096 --> 0.329393).  Saving model ...
	 Train_Loss: 0.3890 Train_Acc: 83.535 Val_Loss: 0.3294  BEST VAL Loss: 0.3294  Val_Acc: 87.959

Epoch 26: Validation loss decreased (0.329393 --> 0.328852).  Saving model ...
	 Train_Loss: 0.3880 Train_Acc: 83.480 Val_Loss: 0.3289  BEST VAL Loss: 0.3289  Val_Acc: 87.733

Epoch 27: Validation loss decreased (0.328852 --> 0.328018).  Saving model ...
	 Train_Loss: 0.3869 Train_Acc: 83.543 Val_Loss: 0.3280  BEST VAL Loss: 0.3280  Val_Acc: 87.617

Epoch 28: Validation loss decreased (0.328018 --> 0.327354).  Saving model ...
	 Train_Loss: 0.3859 Train_Acc: 83.569 Val_Loss: 0.3274  BEST VAL Loss: 0.3274  Val_Acc: 88.104

Epoch 29: Validation loss decreased (0.327354 --> 0.326630).  Saving model ...
	 Train_Loss: 0.3850 Train_Acc: 83.659 Val_Loss: 0.3266  BEST VAL Loss: 0.3266  Val_Acc: 88.047

Epoch 30: Validation loss decreased (0.326630 --> 0.326018).  Saving model ...
	 Train_Loss: 0.3842 Train_Acc: 83.457 Val_Loss: 0.3260  BEST VAL Loss: 0.3260  Val_Acc: 87.482

Epoch 31: Validation loss decreased (0.326018 --> 0.325322).  Saving model ...
	 Train_Loss: 0.3833 Train_Acc: 83.568 Val_Loss: 0.3253  BEST VAL Loss: 0.3253  Val_Acc: 87.777

Epoch 32: Validation loss decreased (0.325322 --> 0.324753).  Saving model ...
	 Train_Loss: 0.3825 Train_Acc: 83.709 Val_Loss: 0.3248  BEST VAL Loss: 0.3248  Val_Acc: 87.903

Epoch 33: Validation loss decreased (0.324753 --> 0.324196).  Saving model ...
	 Train_Loss: 0.3818 Train_Acc: 83.564 Val_Loss: 0.3242  BEST VAL Loss: 0.3242  Val_Acc: 88.041

Epoch 34: Validation loss decreased (0.324196 --> 0.323452).  Saving model ...
	 Train_Loss: 0.3810 Train_Acc: 83.623 Val_Loss: 0.3235  BEST VAL Loss: 0.3235  Val_Acc: 88.050

Epoch 35: Validation loss decreased (0.323452 --> 0.322707).  Saving model ...
	 Train_Loss: 0.3802 Train_Acc: 83.750 Val_Loss: 0.3227  BEST VAL Loss: 0.3227  Val_Acc: 88.188

Epoch 36: Validation loss decreased (0.322707 --> 0.322083).  Saving model ...
	 Train_Loss: 0.3796 Train_Acc: 83.572 Val_Loss: 0.3221  BEST VAL Loss: 0.3221  Val_Acc: 87.890

Epoch 37: Validation loss decreased (0.322083 --> 0.321541).  Saving model ...
	 Train_Loss: 0.3789 Train_Acc: 83.666 Val_Loss: 0.3215  BEST VAL Loss: 0.3215  Val_Acc: 87.677

Epoch 38: Validation loss decreased (0.321541 --> 0.320997).  Saving model ...
	 Train_Loss: 0.3783 Train_Acc: 83.645 Val_Loss: 0.3210  BEST VAL Loss: 0.3210  Val_Acc: 87.975

Epoch 39: Validation loss decreased (0.320997 --> 0.320434).  Saving model ...
	 Train_Loss: 0.3777 Train_Acc: 83.680 Val_Loss: 0.3204  BEST VAL Loss: 0.3204  Val_Acc: 87.831

Epoch 40: Validation loss decreased (0.320434 --> 0.320037).  Saving model ...
	 Train_Loss: 0.3770 Train_Acc: 83.907 Val_Loss: 0.3200  BEST VAL Loss: 0.3200  Val_Acc: 88.198

Epoch 41: Validation loss decreased (0.320037 --> 0.319606).  Saving model ...
	 Train_Loss: 0.3764 Train_Acc: 83.818 Val_Loss: 0.3196  BEST VAL Loss: 0.3196  Val_Acc: 88.361

Epoch 42: Validation loss decreased (0.319606 --> 0.319127).  Saving model ...
	 Train_Loss: 0.3759 Train_Acc: 83.663 Val_Loss: 0.3191  BEST VAL Loss: 0.3191  Val_Acc: 88.148

Epoch 43: Validation loss decreased (0.319127 --> 0.318592).  Saving model ...
	 Train_Loss: 0.3754 Train_Acc: 83.742 Val_Loss: 0.3186  BEST VAL Loss: 0.3186  Val_Acc: 88.336

Epoch 44: Validation loss decreased (0.318592 --> 0.318107).  Saving model ...
	 Train_Loss: 0.3748 Train_Acc: 83.829 Val_Loss: 0.3181  BEST VAL Loss: 0.3181  Val_Acc: 88.308

Epoch 45: Validation loss decreased (0.318107 --> 0.317657).  Saving model ...
	 Train_Loss: 0.3743 Train_Acc: 83.698 Val_Loss: 0.3177  BEST VAL Loss: 0.3177  Val_Acc: 88.345

Epoch 46: Validation loss decreased (0.317657 --> 0.317452).  Saving model ...
	 Train_Loss: 0.3738 Train_Acc: 83.871 Val_Loss: 0.3175  BEST VAL Loss: 0.3175  Val_Acc: 88.182

Epoch 47: Validation loss decreased (0.317452 --> 0.317138).  Saving model ...
	 Train_Loss: 0.3733 Train_Acc: 83.955 Val_Loss: 0.3171  BEST VAL Loss: 0.3171  Val_Acc: 87.997

Epoch 48: Validation loss decreased (0.317138 --> 0.316679).  Saving model ...
	 Train_Loss: 0.3728 Train_Acc: 83.730 Val_Loss: 0.3167  BEST VAL Loss: 0.3167  Val_Acc: 88.063

Epoch 49: Validation loss decreased (0.316679 --> 0.316282).  Saving model ...
	 Train_Loss: 0.3723 Train_Acc: 83.877 Val_Loss: 0.3163  BEST VAL Loss: 0.3163  Val_Acc: 87.897

Epoch 50: Validation loss decreased (0.316282 --> 0.316000).  Saving model ...
	 Train_Loss: 0.3718 Train_Acc: 84.033 Val_Loss: 0.3160  BEST VAL Loss: 0.3160  Val_Acc: 88.396

Epoch 51: Validation loss decreased (0.316000 --> 0.315801).  Saving model ...
	 Train_Loss: 0.3713 Train_Acc: 83.831 Val_Loss: 0.3158  BEST VAL Loss: 0.3158  Val_Acc: 88.126

Epoch 52: Validation loss decreased (0.315801 --> 0.315360).  Saving model ...
	 Train_Loss: 0.3709 Train_Acc: 83.838 Val_Loss: 0.3154  BEST VAL Loss: 0.3154  Val_Acc: 88.374

Epoch 53: Validation loss decreased (0.315360 --> 0.315150).  Saving model ...
	 Train_Loss: 0.3705 Train_Acc: 83.807 Val_Loss: 0.3152  BEST VAL Loss: 0.3152  Val_Acc: 88.057

Epoch 54: Validation loss decreased (0.315150 --> 0.314753).  Saving model ...
	 Train_Loss: 0.3701 Train_Acc: 83.646 Val_Loss: 0.3148  BEST VAL Loss: 0.3148  Val_Acc: 88.217

Epoch 55: Validation loss decreased (0.314753 --> 0.314404).  Saving model ...
	 Train_Loss: 0.3697 Train_Acc: 83.930 Val_Loss: 0.3144  BEST VAL Loss: 0.3144  Val_Acc: 87.900

Epoch 56: Validation loss decreased (0.314404 --> 0.314072).  Saving model ...
	 Train_Loss: 0.3693 Train_Acc: 84.061 Val_Loss: 0.3141  BEST VAL Loss: 0.3141  Val_Acc: 88.339

Epoch 57: Validation loss decreased (0.314072 --> 0.313788).  Saving model ...
	 Train_Loss: 0.3689 Train_Acc: 84.008 Val_Loss: 0.3138  BEST VAL Loss: 0.3138  Val_Acc: 88.188

Epoch 58: Validation loss decreased (0.313788 --> 0.313589).  Saving model ...
	 Train_Loss: 0.3685 Train_Acc: 83.804 Val_Loss: 0.3136  BEST VAL Loss: 0.3136  Val_Acc: 88.254

Epoch 59: Validation loss decreased (0.313589 --> 0.313230).  Saving model ...
	 Train_Loss: 0.3681 Train_Acc: 83.745 Val_Loss: 0.3132  BEST VAL Loss: 0.3132  Val_Acc: 88.342

Epoch 60: Validation loss decreased (0.313230 --> 0.312991).  Saving model ...
	 Train_Loss: 0.3678 Train_Acc: 83.929 Val_Loss: 0.3130  BEST VAL Loss: 0.3130  Val_Acc: 88.210

Epoch 61: Validation loss decreased (0.312991 --> 0.312752).  Saving model ...
	 Train_Loss: 0.3674 Train_Acc: 84.017 Val_Loss: 0.3128  BEST VAL Loss: 0.3128  Val_Acc: 88.455

Epoch 62: Validation loss decreased (0.312752 --> 0.312564).  Saving model ...
	 Train_Loss: 0.3670 Train_Acc: 84.078 Val_Loss: 0.3126  BEST VAL Loss: 0.3126  Val_Acc: 87.203

Epoch 63: Validation loss decreased (0.312564 --> 0.312224).  Saving model ...
	 Train_Loss: 0.3667 Train_Acc: 84.128 Val_Loss: 0.3122  BEST VAL Loss: 0.3122  Val_Acc: 88.615

Epoch 64: Validation loss decreased (0.312224 --> 0.311970).  Saving model ...
	 Train_Loss: 0.3663 Train_Acc: 83.817 Val_Loss: 0.3120  BEST VAL Loss: 0.3120  Val_Acc: 88.292

Epoch 65: Validation loss decreased (0.311970 --> 0.311715).  Saving model ...
	 Train_Loss: 0.3660 Train_Acc: 83.999 Val_Loss: 0.3117  BEST VAL Loss: 0.3117  Val_Acc: 88.091

Epoch 66: Validation loss decreased (0.311715 --> 0.311431).  Saving model ...
	 Train_Loss: 0.3657 Train_Acc: 83.964 Val_Loss: 0.3114  BEST VAL Loss: 0.3114  Val_Acc: 87.928

Epoch 67: Validation loss decreased (0.311431 --> 0.311167).  Saving model ...
	 Train_Loss: 0.3654 Train_Acc: 84.053 Val_Loss: 0.3112  BEST VAL Loss: 0.3112  Val_Acc: 88.006

Epoch 68: Validation loss decreased (0.311167 --> 0.311020).  Saving model ...
	 Train_Loss: 0.3650 Train_Acc: 83.991 Val_Loss: 0.3110  BEST VAL Loss: 0.3110  Val_Acc: 88.367

Epoch 69: Validation loss decreased (0.311020 --> 0.310805).  Saving model ...
	 Train_Loss: 0.3647 Train_Acc: 83.992 Val_Loss: 0.3108  BEST VAL Loss: 0.3108  Val_Acc: 88.248

Epoch 70: Validation loss decreased (0.310805 --> 0.310582).  Saving model ...
	 Train_Loss: 0.3645 Train_Acc: 83.906 Val_Loss: 0.3106  BEST VAL Loss: 0.3106  Val_Acc: 88.326

Epoch 71: Validation loss decreased (0.310582 --> 0.310445).  Saving model ...
	 Train_Loss: 0.3642 Train_Acc: 84.047 Val_Loss: 0.3104  BEST VAL Loss: 0.3104  Val_Acc: 88.825

Epoch 72: Validation loss decreased (0.310445 --> 0.310284).  Saving model ...
	 Train_Loss: 0.3639 Train_Acc: 84.075 Val_Loss: 0.3103  BEST VAL Loss: 0.3103  Val_Acc: 88.163

Epoch 73: Validation loss decreased (0.310284 --> 0.310104).  Saving model ...
	 Train_Loss: 0.3636 Train_Acc: 83.875 Val_Loss: 0.3101  BEST VAL Loss: 0.3101  Val_Acc: 88.308

Epoch 74: Validation loss decreased (0.310104 --> 0.309964).  Saving model ...
	 Train_Loss: 0.3634 Train_Acc: 84.033 Val_Loss: 0.3100  BEST VAL Loss: 0.3100  Val_Acc: 88.477

Epoch 75: Validation loss decreased (0.309964 --> 0.309752).  Saving model ...
	 Train_Loss: 0.3631 Train_Acc: 84.058 Val_Loss: 0.3098  BEST VAL Loss: 0.3098  Val_Acc: 88.797

Epoch 76: Validation loss decreased (0.309752 --> 0.309543).  Saving model ...
	 Train_Loss: 0.3628 Train_Acc: 84.089 Val_Loss: 0.3095  BEST VAL Loss: 0.3095  Val_Acc: 88.389

Epoch 77: Validation loss decreased (0.309543 --> 0.309368).  Saving model ...
	 Train_Loss: 0.3625 Train_Acc: 83.955 Val_Loss: 0.3094  BEST VAL Loss: 0.3094  Val_Acc: 87.915

Epoch 78: Validation loss decreased (0.309368 --> 0.309234).  Saving model ...
	 Train_Loss: 0.3623 Train_Acc: 84.057 Val_Loss: 0.3092  BEST VAL Loss: 0.3092  Val_Acc: 87.363

Epoch 79: Validation loss decreased (0.309234 --> 0.309020).  Saving model ...
	 Train_Loss: 0.3620 Train_Acc: 83.947 Val_Loss: 0.3090  BEST VAL Loss: 0.3090  Val_Acc: 88.314

Epoch 80: Validation loss decreased (0.309020 --> 0.308790).  Saving model ...
	 Train_Loss: 0.3618 Train_Acc: 84.049 Val_Loss: 0.3088  BEST VAL Loss: 0.3088  Val_Acc: 88.101

Epoch 81: Validation loss decreased (0.308790 --> 0.308552).  Saving model ...
	 Train_Loss: 0.3615 Train_Acc: 84.126 Val_Loss: 0.3086  BEST VAL Loss: 0.3086  Val_Acc: 88.326

Epoch 82: Validation loss decreased (0.308552 --> 0.308336).  Saving model ...
	 Train_Loss: 0.3613 Train_Acc: 84.170 Val_Loss: 0.3083  BEST VAL Loss: 0.3083  Val_Acc: 88.590

Epoch 83: Validation loss decreased (0.308336 --> 0.308075).  Saving model ...
	 Train_Loss: 0.3611 Train_Acc: 84.077 Val_Loss: 0.3081  BEST VAL Loss: 0.3081  Val_Acc: 88.502

Epoch 84: Validation loss decreased (0.308075 --> 0.307860).  Saving model ...
	 Train_Loss: 0.3608 Train_Acc: 84.138 Val_Loss: 0.3079  BEST VAL Loss: 0.3079  Val_Acc: 88.452

Epoch 85: Validation loss decreased (0.307860 --> 0.307697).  Saving model ...
	 Train_Loss: 0.3606 Train_Acc: 84.123 Val_Loss: 0.3077  BEST VAL Loss: 0.3077  Val_Acc: 87.934

Epoch 86: Validation loss decreased (0.307697 --> 0.307459).  Saving model ...
	 Train_Loss: 0.3603 Train_Acc: 84.110 Val_Loss: 0.3075  BEST VAL Loss: 0.3075  Val_Acc: 88.706

Epoch 87: Validation loss decreased (0.307459 --> 0.307316).  Saving model ...
	 Train_Loss: 0.3601 Train_Acc: 84.071 Val_Loss: 0.3073  BEST VAL Loss: 0.3073  Val_Acc: 88.097

Epoch 88: Validation loss decreased (0.307316 --> 0.307094).  Saving model ...
	 Train_Loss: 0.3598 Train_Acc: 84.245 Val_Loss: 0.3071  BEST VAL Loss: 0.3071  Val_Acc: 88.829

Epoch 89: Validation loss decreased (0.307094 --> 0.306891).  Saving model ...
	 Train_Loss: 0.3596 Train_Acc: 84.213 Val_Loss: 0.3069  BEST VAL Loss: 0.3069  Val_Acc: 88.744

Epoch 90: Validation loss decreased (0.306891 --> 0.306767).  Saving model ...
	 Train_Loss: 0.3594 Train_Acc: 84.094 Val_Loss: 0.3068  BEST VAL Loss: 0.3068  Val_Acc: 88.800

Epoch 91: Validation loss decreased (0.306767 --> 0.306655).  Saving model ...
	 Train_Loss: 0.3592 Train_Acc: 84.073 Val_Loss: 0.3067  BEST VAL Loss: 0.3067  Val_Acc: 88.593

Epoch 92: Validation loss decreased (0.306655 --> 0.306408).  Saving model ...
	 Train_Loss: 0.3590 Train_Acc: 84.011 Val_Loss: 0.3064  BEST VAL Loss: 0.3064  Val_Acc: 88.631

Epoch 93: Validation loss decreased (0.306408 --> 0.306202).  Saving model ...
	 Train_Loss: 0.3588 Train_Acc: 84.232 Val_Loss: 0.3062  BEST VAL Loss: 0.3062  Val_Acc: 88.148

Epoch 94: Validation loss decreased (0.306202 --> 0.306129).  Saving model ...
	 Train_Loss: 0.3585 Train_Acc: 84.229 Val_Loss: 0.3061  BEST VAL Loss: 0.3061  Val_Acc: 88.797

Epoch 95: Validation loss decreased (0.306129 --> 0.306028).  Saving model ...
	 Train_Loss: 0.3583 Train_Acc: 84.258 Val_Loss: 0.3060  BEST VAL Loss: 0.3060  Val_Acc: 88.534

Epoch 96: Validation loss decreased (0.306028 --> 0.305868).  Saving model ...
	 Train_Loss: 0.3581 Train_Acc: 84.147 Val_Loss: 0.3059  BEST VAL Loss: 0.3059  Val_Acc: 88.697

Epoch 97: Validation loss decreased (0.305868 --> 0.305679).  Saving model ...
	 Train_Loss: 0.3580 Train_Acc: 84.191 Val_Loss: 0.3057  BEST VAL Loss: 0.3057  Val_Acc: 88.521

Epoch 98: Validation loss decreased (0.305679 --> 0.305604).  Saving model ...
	 Train_Loss: 0.3578 Train_Acc: 84.170 Val_Loss: 0.3056  BEST VAL Loss: 0.3056  Val_Acc: 88.487

Epoch 99: Validation loss decreased (0.305604 --> 0.305440).  Saving model ...
	 Train_Loss: 0.3575 Train_Acc: 84.255 Val_Loss: 0.3054  BEST VAL Loss: 0.3054  Val_Acc: 88.603

H2O2_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.94      0.91      0.92    169561
           1       0.83      0.89      0.86     85371

    accuracy                           0.90    254932
   macro avg       0.89      0.90      0.89    254932
weighted avg       0.90      0.90      0.90    254932

H2O2_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.90      0.91     21195
           1       0.81      0.87      0.84     10672

    accuracy                           0.89     31867
   macro avg       0.87      0.88      0.87     31867
weighted avg       0.89      0.89      0.89     31867

H2O2_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.90      0.91     21196
           1       0.81      0.87      0.84     10671

    accuracy                           0.89     31867
   macro avg       0.87      0.88      0.87     31867
weighted avg       0.89      0.89      0.89     31867

              precision    recall  f1-score   support

           0       0.93      0.90      0.91     21196
           1       0.81      0.87      0.84     10671

    accuracy                           0.89     31867
   macro avg       0.87      0.88      0.87     31867
weighted avg       0.89      0.89      0.89     31867

H2O2_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.63      0.90      0.74     28584
           1       0.88      0.59      0.71     36366

    accuracy                           0.73     64950
   macro avg       0.76      0.75      0.73     64950
weighted avg       0.77      0.73      0.72     64950

              precision    recall  f1-score   support

           0       0.63      0.90      0.74     28584
           1       0.88      0.59      0.71     36366

    accuracy                           0.73     64950
   macro avg       0.76      0.75      0.73     64950
weighted avg       0.77      0.73      0.72     64950

completed
