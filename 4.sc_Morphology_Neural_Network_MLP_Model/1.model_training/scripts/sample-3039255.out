[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '2029fe77'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '79e09327'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '721519df'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'a1aad633'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_1.000_DMSO_0.025 treatment_name: Thapsigargin_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_1.000_DMSO_0.025
TREATMENT_NAME: Thapsigargin_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'LPS_1.000_DMSO_0.025']
The dimensions of the data are: (30224, 1276)
Number of total missing values across all columns: 60448
Data Subset Is Off
Wells held out for testing: ['D14' 'D20']
Wells to use for training, validation, and testing ['D15' 'D16' 'D17' 'D21' 'K14' 'K15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.496450).  Saving model ...
	 Train_Loss: 0.6413 Train_Acc: 61.431 Val_Loss: 0.4965  BEST VAL Loss: 0.4965  Val_Acc: 76.538

Epoch 1: Validation loss decreased (0.496450 --> 0.470064).  Saving model ...
	 Train_Loss: 0.5851 Train_Acc: 71.139 Val_Loss: 0.4701  BEST VAL Loss: 0.4701  Val_Acc: 80.360

Epoch 2: Validation loss decreased (0.470064 --> 0.455239).  Saving model ...
	 Train_Loss: 0.5573 Train_Acc: 72.738 Val_Loss: 0.4552  BEST VAL Loss: 0.4552  Val_Acc: 79.877

Epoch 3: Validation loss decreased (0.455239 --> 0.439770).  Saving model ...
	 Train_Loss: 0.5372 Train_Acc: 73.908 Val_Loss: 0.4398  BEST VAL Loss: 0.4398  Val_Acc: 81.503

Epoch 4: Validation loss decreased (0.439770 --> 0.424897).  Saving model ...
	 Train_Loss: 0.5215 Train_Acc: 75.265 Val_Loss: 0.4249  BEST VAL Loss: 0.4249  Val_Acc: 83.172

Epoch 5: Validation loss decreased (0.424897 --> 0.413316).  Saving model ...
	 Train_Loss: 0.5095 Train_Acc: 75.304 Val_Loss: 0.4133  BEST VAL Loss: 0.4133  Val_Acc: 83.568

Epoch 6: Validation loss decreased (0.413316 --> 0.405967).  Saving model ...
	 Train_Loss: 0.4998 Train_Acc: 75.595 Val_Loss: 0.4060  BEST VAL Loss: 0.4060  Val_Acc: 83.963

Epoch 7: Validation loss decreased (0.405967 --> 0.400388).  Saving model ...
	 Train_Loss: 0.4918 Train_Acc: 76.029 Val_Loss: 0.4004  BEST VAL Loss: 0.4004  Val_Acc: 84.402

Epoch 8: Validation loss decreased (0.400388 --> 0.392796).  Saving model ...
	 Train_Loss: 0.4845 Train_Acc: 76.562 Val_Loss: 0.3928  BEST VAL Loss: 0.3928  Val_Acc: 85.062

Epoch 9: Validation loss decreased (0.392796 --> 0.387172).  Saving model ...
	 Train_Loss: 0.4779 Train_Acc: 78.194 Val_Loss: 0.3872  BEST VAL Loss: 0.3872  Val_Acc: 85.281

Epoch 10: Validation loss decreased (0.387172 --> 0.380621).  Saving model ...
	 Train_Loss: 0.4726 Train_Acc: 77.886 Val_Loss: 0.3806  BEST VAL Loss: 0.3806  Val_Acc: 87.170

Epoch 11: Validation loss decreased (0.380621 --> 0.376934).  Saving model ...
	 Train_Loss: 0.4676 Train_Acc: 77.732 Val_Loss: 0.3769  BEST VAL Loss: 0.3769  Val_Acc: 85.413

Epoch 12: Validation loss decreased (0.376934 --> 0.372383).  Saving model ...
	 Train_Loss: 0.4635 Train_Acc: 78.237 Val_Loss: 0.3724  BEST VAL Loss: 0.3724  Val_Acc: 86.775

Epoch 13: Validation loss decreased (0.372383 --> 0.368103).  Saving model ...
	 Train_Loss: 0.4588 Train_Acc: 78.814 Val_Loss: 0.3681  BEST VAL Loss: 0.3681  Val_Acc: 86.160

Epoch 14: Validation loss decreased (0.368103 --> 0.364979).  Saving model ...
	 Train_Loss: 0.4549 Train_Acc: 79.358 Val_Loss: 0.3650  BEST VAL Loss: 0.3650  Val_Acc: 86.160

Epoch 15: Validation loss decreased (0.364979 --> 0.361117).  Saving model ...
	 Train_Loss: 0.4511 Train_Acc: 78.908 Val_Loss: 0.3611  BEST VAL Loss: 0.3611  Val_Acc: 85.896

Epoch 16: Validation loss decreased (0.361117 --> 0.357327).  Saving model ...
	 Train_Loss: 0.4476 Train_Acc: 78.787 Val_Loss: 0.3573  BEST VAL Loss: 0.3573  Val_Acc: 86.599

Epoch 17: Validation loss decreased (0.357327 --> 0.354965).  Saving model ...
	 Train_Loss: 0.4444 Train_Acc: 79.237 Val_Loss: 0.3550  BEST VAL Loss: 0.3550  Val_Acc: 86.731

Epoch 18: Validation loss decreased (0.354965 --> 0.351935).  Saving model ...
	 Train_Loss: 0.4415 Train_Acc: 79.611 Val_Loss: 0.3519  BEST VAL Loss: 0.3519  Val_Acc: 86.643

Epoch 19: Validation loss decreased (0.351935 --> 0.348868).  Saving model ...
	 Train_Loss: 0.4391 Train_Acc: 79.232 Val_Loss: 0.3489  BEST VAL Loss: 0.3489  Val_Acc: 87.786

Epoch 20: Validation loss decreased (0.348868 --> 0.347008).  Saving model ...
	 Train_Loss: 0.4365 Train_Acc: 80.215 Val_Loss: 0.3470  BEST VAL Loss: 0.3470  Val_Acc: 87.390

Epoch 21: Validation loss decreased (0.347008 --> 0.345048).  Saving model ...
	 Train_Loss: 0.4339 Train_Acc: 79.787 Val_Loss: 0.3450  BEST VAL Loss: 0.3450  Val_Acc: 87.258

Epoch 22: Validation loss decreased (0.345048 --> 0.342690).  Saving model ...
	 Train_Loss: 0.4315 Train_Acc: 79.952 Val_Loss: 0.3427  BEST VAL Loss: 0.3427  Val_Acc: 87.698

Epoch 23: Validation loss decreased (0.342690 --> 0.339836).  Saving model ...
	 Train_Loss: 0.4292 Train_Acc: 80.149 Val_Loss: 0.3398  BEST VAL Loss: 0.3398  Val_Acc: 88.401

Epoch 24: Validation loss decreased (0.339836 --> 0.338154).  Saving model ...
	 Train_Loss: 0.4271 Train_Acc: 80.353 Val_Loss: 0.3382  BEST VAL Loss: 0.3382  Val_Acc: 87.214

Epoch 25: Validation loss decreased (0.338154 --> 0.337363).  Saving model ...
	 Train_Loss: 0.4253 Train_Acc: 80.364 Val_Loss: 0.3374  BEST VAL Loss: 0.3374  Val_Acc: 86.555

Epoch 26: Validation loss decreased (0.337363 --> 0.335329).  Saving model ...
	 Train_Loss: 0.4233 Train_Acc: 80.562 Val_Loss: 0.3353  BEST VAL Loss: 0.3353  Val_Acc: 88.181

Epoch 27: Validation loss decreased (0.335329 --> 0.333511).  Saving model ...
	 Train_Loss: 0.4215 Train_Acc: 80.474 Val_Loss: 0.3335  BEST VAL Loss: 0.3335  Val_Acc: 87.698

Epoch 28: Validation loss decreased (0.333511 --> 0.331197).  Saving model ...
	 Train_Loss: 0.4195 Train_Acc: 81.155 Val_Loss: 0.3312  BEST VAL Loss: 0.3312  Val_Acc: 88.093

Epoch 29: Validation loss decreased (0.331197 --> 0.328998).  Saving model ...
	 Train_Loss: 0.4178 Train_Acc: 80.704 Val_Loss: 0.3290  BEST VAL Loss: 0.3290  Val_Acc: 88.708

Epoch 30: Validation loss decreased (0.328998 --> 0.327572).  Saving model ...
	 Train_Loss: 0.4161 Train_Acc: 80.897 Val_Loss: 0.3276  BEST VAL Loss: 0.3276  Val_Acc: 87.873

Epoch 31: Validation loss decreased (0.327572 --> 0.326009).  Saving model ...
	 Train_Loss: 0.4144 Train_Acc: 80.858 Val_Loss: 0.3260  BEST VAL Loss: 0.3260  Val_Acc: 87.346

Epoch 32: Validation loss decreased (0.326009 --> 0.324251).  Saving model ...
	 Train_Loss: 0.4129 Train_Acc: 80.704 Val_Loss: 0.3243  BEST VAL Loss: 0.3243  Val_Acc: 88.533

Epoch 33: Validation loss decreased (0.324251 --> 0.323317).  Saving model ...
	 Train_Loss: 0.4115 Train_Acc: 81.029 Val_Loss: 0.3233  BEST VAL Loss: 0.3233  Val_Acc: 88.445

Epoch 34: Validation loss decreased (0.323317 --> 0.321834).  Saving model ...
	 Train_Loss: 0.4099 Train_Acc: 81.050 Val_Loss: 0.3218  BEST VAL Loss: 0.3218  Val_Acc: 88.620

Epoch 35: Validation loss decreased (0.321834 --> 0.320884).  Saving model ...
	 Train_Loss: 0.4083 Train_Acc: 81.111 Val_Loss: 0.3209  BEST VAL Loss: 0.3209  Val_Acc: 87.346

Epoch 36: Validation loss decreased (0.320884 --> 0.319320).  Saving model ...
	 Train_Loss: 0.4070 Train_Acc: 81.204 Val_Loss: 0.3193  BEST VAL Loss: 0.3193  Val_Acc: 88.357

Epoch 37: Validation loss decreased (0.319320 --> 0.317648).  Saving model ...
	 Train_Loss: 0.4054 Train_Acc: 81.897 Val_Loss: 0.3176  BEST VAL Loss: 0.3176  Val_Acc: 88.576

Epoch 38: Validation loss decreased (0.317648 --> 0.315733).  Saving model ...
	 Train_Loss: 0.4039 Train_Acc: 81.468 Val_Loss: 0.3157  BEST VAL Loss: 0.3157  Val_Acc: 88.664

Epoch 39: Validation loss decreased (0.315733 --> 0.315218).  Saving model ...
	 Train_Loss: 0.4026 Train_Acc: 81.353 Val_Loss: 0.3152  BEST VAL Loss: 0.3152  Val_Acc: 88.401

Epoch 40: Validation loss decreased (0.315218 --> 0.313870).  Saving model ...
	 Train_Loss: 0.4013 Train_Acc: 82.056 Val_Loss: 0.3139  BEST VAL Loss: 0.3139  Val_Acc: 88.401

Epoch 41: Validation loss decreased (0.313870 --> 0.312792).  Saving model ...
	 Train_Loss: 0.3999 Train_Acc: 82.364 Val_Loss: 0.3128  BEST VAL Loss: 0.3128  Val_Acc: 89.060

Epoch 42: Validation loss decreased (0.312792 --> 0.312126).  Saving model ...
	 Train_Loss: 0.3986 Train_Acc: 81.485 Val_Loss: 0.3121  BEST VAL Loss: 0.3121  Val_Acc: 87.478

Epoch 43: Validation loss decreased (0.312126 --> 0.311824).  Saving model ...
	 Train_Loss: 0.3976 Train_Acc: 81.468 Val_Loss: 0.3118  BEST VAL Loss: 0.3118  Val_Acc: 87.566

Epoch 44: Validation loss decreased (0.311824 --> 0.310526).  Saving model ...
	 Train_Loss: 0.3965 Train_Acc: 81.446 Val_Loss: 0.3105  BEST VAL Loss: 0.3105  Val_Acc: 88.708

Epoch 45: Validation loss decreased (0.310526 --> 0.309410).  Saving model ...
	 Train_Loss: 0.3953 Train_Acc: 82.369 Val_Loss: 0.3094  BEST VAL Loss: 0.3094  Val_Acc: 88.840

Epoch 46: Validation loss decreased (0.309410 --> 0.308166).  Saving model ...
	 Train_Loss: 0.3943 Train_Acc: 81.353 Val_Loss: 0.3082  BEST VAL Loss: 0.3082  Val_Acc: 88.752

Epoch 47: Validation loss decreased (0.308166 --> 0.307212).  Saving model ...
	 Train_Loss: 0.3933 Train_Acc: 81.671 Val_Loss: 0.3072  BEST VAL Loss: 0.3072  Val_Acc: 88.005

Epoch 48: Validation loss decreased (0.307212 --> 0.306613).  Saving model ...
	 Train_Loss: 0.3921 Train_Acc: 82.473 Val_Loss: 0.3066  BEST VAL Loss: 0.3066  Val_Acc: 89.060

Epoch 49: Validation loss decreased (0.306613 --> 0.305929).  Saving model ...
	 Train_Loss: 0.3911 Train_Acc: 82.089 Val_Loss: 0.3059  BEST VAL Loss: 0.3059  Val_Acc: 88.576

Epoch 50: Validation loss decreased (0.305929 --> 0.305349).  Saving model ...
	 Train_Loss: 0.3901 Train_Acc: 81.671 Val_Loss: 0.3053  BEST VAL Loss: 0.3053  Val_Acc: 88.313

Epoch 51: Validation loss decreased (0.305349 --> 0.304436).  Saving model ...
	 Train_Loss: 0.3892 Train_Acc: 82.204 Val_Loss: 0.3044  BEST VAL Loss: 0.3044  Val_Acc: 88.005

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.3883 Train_Acc: 82.100 Val_Loss: 0.3045  BEST VAL Loss: 0.3044  Val_Acc: 87.786

Epoch 53: Validation loss decreased (0.304436 --> 0.304173).  Saving model ...
	 Train_Loss: 0.3874 Train_Acc: 82.166 Val_Loss: 0.3042  BEST VAL Loss: 0.3042  Val_Acc: 87.566

Epoch 54: Validation loss decreased (0.304173 --> 0.303698).  Saving model ...
	 Train_Loss: 0.3865 Train_Acc: 82.166 Val_Loss: 0.3037  BEST VAL Loss: 0.3037  Val_Acc: 88.620

Epoch 55: Validation loss decreased (0.303698 --> 0.302723).  Saving model ...
	 Train_Loss: 0.3855 Train_Acc: 82.962 Val_Loss: 0.3027  BEST VAL Loss: 0.3027  Val_Acc: 89.367

Epoch 56: Validation loss decreased (0.302723 --> 0.302018).  Saving model ...
	 Train_Loss: 0.3847 Train_Acc: 82.265 Val_Loss: 0.3020  BEST VAL Loss: 0.3020  Val_Acc: 88.840

Epoch 57: Validation loss decreased (0.302018 --> 0.301566).  Saving model ...
	 Train_Loss: 0.3841 Train_Acc: 82.309 Val_Loss: 0.3016  BEST VAL Loss: 0.3016  Val_Acc: 87.698

Epoch 58: Validation loss decreased (0.301566 --> 0.301051).  Saving model ...
	 Train_Loss: 0.3833 Train_Acc: 82.199 Val_Loss: 0.3011  BEST VAL Loss: 0.3011  Val_Acc: 88.708

Epoch 59: Validation loss decreased (0.301051 --> 0.300694).  Saving model ...
	 Train_Loss: 0.3824 Train_Acc: 82.787 Val_Loss: 0.3007  BEST VAL Loss: 0.3007  Val_Acc: 88.752

Epoch 60: Validation loss decreased (0.300694 --> 0.300213).  Saving model ...
	 Train_Loss: 0.3818 Train_Acc: 82.380 Val_Loss: 0.3002  BEST VAL Loss: 0.3002  Val_Acc: 88.796

Epoch 61: Validation loss decreased (0.300213 --> 0.299677).  Saving model ...
	 Train_Loss: 0.3811 Train_Acc: 81.930 Val_Loss: 0.2997  BEST VAL Loss: 0.2997  Val_Acc: 87.830

Epoch 62: Validation loss decreased (0.299677 --> 0.299223).  Saving model ...
	 Train_Loss: 0.3805 Train_Acc: 82.215 Val_Loss: 0.2992  BEST VAL Loss: 0.2992  Val_Acc: 88.005

Epoch 63: Validation loss decreased (0.299223 --> 0.298812).  Saving model ...
	 Train_Loss: 0.3798 Train_Acc: 82.287 Val_Loss: 0.2988  BEST VAL Loss: 0.2988  Val_Acc: 88.533

Epoch 64: Validation loss decreased (0.298812 --> 0.298195).  Saving model ...
	 Train_Loss: 0.3791 Train_Acc: 82.331 Val_Loss: 0.2982  BEST VAL Loss: 0.2982  Val_Acc: 88.840

Epoch 65: Validation loss decreased (0.298195 --> 0.297542).  Saving model ...
	 Train_Loss: 0.3783 Train_Acc: 82.677 Val_Loss: 0.2975  BEST VAL Loss: 0.2975  Val_Acc: 88.445

Epoch 66: Validation loss decreased (0.297542 --> 0.296966).  Saving model ...
	 Train_Loss: 0.3778 Train_Acc: 82.336 Val_Loss: 0.2970  BEST VAL Loss: 0.2970  Val_Acc: 88.445

Epoch 67: Validation loss decreased (0.296966 --> 0.296350).  Saving model ...
	 Train_Loss: 0.3771 Train_Acc: 82.710 Val_Loss: 0.2964  BEST VAL Loss: 0.2964  Val_Acc: 88.049

Epoch 68: Validation loss decreased (0.296350 --> 0.295600).  Saving model ...
	 Train_Loss: 0.3763 Train_Acc: 82.622 Val_Loss: 0.2956  BEST VAL Loss: 0.2956  Val_Acc: 88.533

Epoch 69: Validation loss decreased (0.295600 --> 0.295231).  Saving model ...
	 Train_Loss: 0.3757 Train_Acc: 82.160 Val_Loss: 0.2952  BEST VAL Loss: 0.2952  Val_Acc: 88.225

Epoch 70: Validation loss decreased (0.295231 --> 0.294793).  Saving model ...
	 Train_Loss: 0.3751 Train_Acc: 82.539 Val_Loss: 0.2948  BEST VAL Loss: 0.2948  Val_Acc: 87.961

Epoch 71: Validation loss decreased (0.294793 --> 0.294690).  Saving model ...
	 Train_Loss: 0.3744 Train_Acc: 82.682 Val_Loss: 0.2947  BEST VAL Loss: 0.2947  Val_Acc: 88.445

Epoch 72: Validation loss decreased (0.294690 --> 0.294294).  Saving model ...
	 Train_Loss: 0.3738 Train_Acc: 82.430 Val_Loss: 0.2943  BEST VAL Loss: 0.2943  Val_Acc: 88.181

Epoch 73: Validation loss decreased (0.294294 --> 0.293753).  Saving model ...
	 Train_Loss: 0.3731 Train_Acc: 82.721 Val_Loss: 0.2938  BEST VAL Loss: 0.2938  Val_Acc: 87.961

Epoch 74: Validation loss decreased (0.293753 --> 0.293144).  Saving model ...
	 Train_Loss: 0.3725 Train_Acc: 82.908 Val_Loss: 0.2931  BEST VAL Loss: 0.2931  Val_Acc: 88.664

Epoch 75: Validation loss decreased (0.293144 --> 0.292860).  Saving model ...
	 Train_Loss: 0.3718 Train_Acc: 82.880 Val_Loss: 0.2929  BEST VAL Loss: 0.2929  Val_Acc: 88.840

Epoch 76: Validation loss decreased (0.292860 --> 0.292389).  Saving model ...
	 Train_Loss: 0.3712 Train_Acc: 83.034 Val_Loss: 0.2924  BEST VAL Loss: 0.2924  Val_Acc: 89.192

Epoch 77: Validation loss decreased (0.292389 --> 0.292097).  Saving model ...
	 Train_Loss: 0.3706 Train_Acc: 83.017 Val_Loss: 0.2921  BEST VAL Loss: 0.2921  Val_Acc: 89.236

Epoch 78: Validation loss decreased (0.292097 --> 0.291616).  Saving model ...
	 Train_Loss: 0.3700 Train_Acc: 82.880 Val_Loss: 0.2916  BEST VAL Loss: 0.2916  Val_Acc: 88.928

Epoch 79: Validation loss decreased (0.291616 --> 0.291209).  Saving model ...
	 Train_Loss: 0.3694 Train_Acc: 82.726 Val_Loss: 0.2912  BEST VAL Loss: 0.2912  Val_Acc: 88.884

Epoch 80: Validation loss decreased (0.291209 --> 0.290951).  Saving model ...
	 Train_Loss: 0.3689 Train_Acc: 82.776 Val_Loss: 0.2910  BEST VAL Loss: 0.2910  Val_Acc: 89.455

Epoch 81: Validation loss decreased (0.290951 --> 0.290498).  Saving model ...
	 Train_Loss: 0.3683 Train_Acc: 83.034 Val_Loss: 0.2905  BEST VAL Loss: 0.2905  Val_Acc: 89.104

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.3678 Train_Acc: 83.116 Val_Loss: 0.2905  BEST VAL Loss: 0.2905  Val_Acc: 89.104

Epoch 83: Validation loss decreased (0.290498 --> 0.289982).  Saving model ...
	 Train_Loss: 0.3672 Train_Acc: 82.990 Val_Loss: 0.2900  BEST VAL Loss: 0.2900  Val_Acc: 88.576

Epoch 84: Validation loss decreased (0.289982 --> 0.289784).  Saving model ...
	 Train_Loss: 0.3666 Train_Acc: 83.309 Val_Loss: 0.2898  BEST VAL Loss: 0.2898  Val_Acc: 88.357

Epoch 85: Validation loss decreased (0.289784 --> 0.289594).  Saving model ...
	 Train_Loss: 0.3661 Train_Acc: 83.188 Val_Loss: 0.2896  BEST VAL Loss: 0.2896  Val_Acc: 89.236

Epoch 86: Validation loss decreased (0.289594 --> 0.289438).  Saving model ...
	 Train_Loss: 0.3656 Train_Acc: 83.155 Val_Loss: 0.2894  BEST VAL Loss: 0.2894  Val_Acc: 88.972

Epoch 87: Validation loss decreased (0.289438 --> 0.289126).  Saving model ...
	 Train_Loss: 0.3651 Train_Acc: 82.984 Val_Loss: 0.2891  BEST VAL Loss: 0.2891  Val_Acc: 88.972

Epoch 88: Validation loss decreased (0.289126 --> 0.289087).  Saving model ...
	 Train_Loss: 0.3646 Train_Acc: 83.199 Val_Loss: 0.2891  BEST VAL Loss: 0.2891  Val_Acc: 88.928

Epoch 89: Validation loss decreased (0.289087 --> 0.288980).  Saving model ...
	 Train_Loss: 0.3641 Train_Acc: 82.710 Val_Loss: 0.2890  BEST VAL Loss: 0.2890  Val_Acc: 89.192

Epoch 90: Validation loss decreased (0.288980 --> 0.288736).  Saving model ...
	 Train_Loss: 0.3636 Train_Acc: 82.935 Val_Loss: 0.2887  BEST VAL Loss: 0.2887  Val_Acc: 88.840

Epoch 91: Validation loss decreased (0.288736 --> 0.288263).  Saving model ...
	 Train_Loss: 0.3632 Train_Acc: 82.968 Val_Loss: 0.2883  BEST VAL Loss: 0.2883  Val_Acc: 88.752

Epoch 92: Validation loss decreased (0.288263 --> 0.287969).  Saving model ...
	 Train_Loss: 0.3628 Train_Acc: 82.951 Val_Loss: 0.2880  BEST VAL Loss: 0.2880  Val_Acc: 89.192

Epoch 93: Validation loss decreased (0.287969 --> 0.287740).  Saving model ...
	 Train_Loss: 0.3623 Train_Acc: 83.160 Val_Loss: 0.2877  BEST VAL Loss: 0.2877  Val_Acc: 89.587

Epoch 94: Validation loss decreased (0.287740 --> 0.287603).  Saving model ...
	 Train_Loss: 0.3618 Train_Acc: 83.616 Val_Loss: 0.2876  BEST VAL Loss: 0.2876  Val_Acc: 89.236

Epoch 95: Validation loss decreased (0.287603 --> 0.287409).  Saving model ...
	 Train_Loss: 0.3614 Train_Acc: 83.397 Val_Loss: 0.2874  BEST VAL Loss: 0.2874  Val_Acc: 88.489

Epoch 96: Validation loss decreased (0.287409 --> 0.287317).  Saving model ...
	 Train_Loss: 0.3610 Train_Acc: 83.144 Val_Loss: 0.2873  BEST VAL Loss: 0.2873  Val_Acc: 88.840

Epoch 97: Validation loss decreased (0.287317 --> 0.286953).  Saving model ...
	 Train_Loss: 0.3604 Train_Acc: 83.226 Val_Loss: 0.2870  BEST VAL Loss: 0.2870  Val_Acc: 88.884

Epoch 98: Validation loss decreased (0.286953 --> 0.286704).  Saving model ...
	 Train_Loss: 0.3600 Train_Acc: 83.116 Val_Loss: 0.2867  BEST VAL Loss: 0.2867  Val_Acc: 88.752

Epoch 99: Validation loss decreased (0.286704 --> 0.286486).  Saving model ...
	 Train_Loss: 0.3596 Train_Acc: 83.270 Val_Loss: 0.2865  BEST VAL Loss: 0.2865  Val_Acc: 88.357

LPS_1.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.54      0.51      0.52      9832
           1       0.45      0.48      0.47      8369

    accuracy                           0.50     18201
   macro avg       0.49      0.49      0.49     18201
weighted avg       0.50      0.50      0.50     18201

LPS_1.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.54      0.51      0.52      1229
           1       0.46      0.50      0.48      1047

    accuracy                           0.50      2276
   macro avg       0.50      0.50      0.50      2276
weighted avg       0.51      0.50      0.50      2276

LPS_1.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.51      0.53      1229
           1       0.47      0.51      0.49      1047

    accuracy                           0.51      2276
   macro avg       0.51      0.51      0.51      2276
weighted avg       0.51      0.51      0.51      2276

              precision    recall  f1-score   support

           0       0.55      0.51      0.53      1229
           1       0.47      0.51      0.49      1047

    accuracy                           0.51      2276
   macro avg       0.51      0.51      0.51      2276
weighted avg       0.51      0.51      0.51      2276

LPS_1.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.56      0.52      0.54      4168
           1       0.44      0.48      0.46      3303

    accuracy                           0.50      7471
   macro avg       0.50      0.50      0.50      7471
weighted avg       0.51      0.50      0.50      7471

              precision    recall  f1-score   support

           0       0.56      0.52      0.54      4168
           1       0.44      0.48      0.46      3303

    accuracy                           0.50      7471
   macro avg       0.50      0.50      0.50      7471
weighted avg       0.51      0.50      0.50      7471

completed
