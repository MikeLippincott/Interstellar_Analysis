[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ae6af929'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'efe53db4'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '787ec762'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '4e508287'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_0.100_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (32438, 1276)
Number of total missing values across all columns: 64876
Data Subset Is Off
Wells held out for testing: ['C21' 'L22']
Wells to use for training, validation, and testing ['C16' 'C17' 'C20' 'L18' 'L19' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.656248).  Saving model ...
	 Train_Loss: 0.6777 Train_Acc: 57.980 Val_Loss: 0.6562  BEST VAL Loss: 0.6562  Val_Acc: 62.479

Epoch 1: Validation loss decreased (0.656248 --> 0.642140).  Saving model ...
	 Train_Loss: 0.6626 Train_Acc: 61.774 Val_Loss: 0.6421  BEST VAL Loss: 0.6421  Val_Acc: 65.168

Epoch 2: Validation loss decreased (0.642140 --> 0.629476).  Saving model ...
	 Train_Loss: 0.6509 Train_Acc: 63.954 Val_Loss: 0.6295  BEST VAL Loss: 0.6295  Val_Acc: 67.395

Epoch 3: Validation loss decreased (0.629476 --> 0.619303).  Saving model ...
	 Train_Loss: 0.6414 Train_Acc: 64.658 Val_Loss: 0.6193  BEST VAL Loss: 0.6193  Val_Acc: 68.361

Epoch 4: Validation loss decreased (0.619303 --> 0.612173).  Saving model ...
	 Train_Loss: 0.6340 Train_Acc: 65.483 Val_Loss: 0.6122  BEST VAL Loss: 0.6122  Val_Acc: 68.908

Epoch 5: Validation loss decreased (0.612173 --> 0.603546).  Saving model ...
	 Train_Loss: 0.6259 Train_Acc: 66.161 Val_Loss: 0.6035  BEST VAL Loss: 0.6035  Val_Acc: 69.454

Epoch 6: Validation loss decreased (0.603546 --> 0.597425).  Saving model ...
	 Train_Loss: 0.6185 Train_Acc: 67.227 Val_Loss: 0.5974  BEST VAL Loss: 0.5974  Val_Acc: 70.588

Epoch 7: Validation loss decreased (0.597425 --> 0.591895).  Saving model ...
	 Train_Loss: 0.6120 Train_Acc: 67.521 Val_Loss: 0.5919  BEST VAL Loss: 0.5919  Val_Acc: 70.252

Epoch 8: Validation loss decreased (0.591895 --> 0.585358).  Saving model ...
	 Train_Loss: 0.6055 Train_Acc: 67.637 Val_Loss: 0.5854  BEST VAL Loss: 0.5854  Val_Acc: 70.798

Epoch 9: Validation loss decreased (0.585358 --> 0.580362).  Saving model ...
	 Train_Loss: 0.6003 Train_Acc: 67.642 Val_Loss: 0.5804  BEST VAL Loss: 0.5804  Val_Acc: 70.924

Epoch 10: Validation loss decreased (0.580362 --> 0.576408).  Saving model ...
	 Train_Loss: 0.5945 Train_Acc: 71.871 Val_Loss: 0.5764  BEST VAL Loss: 0.5764  Val_Acc: 72.563

Epoch 11: Validation loss decreased (0.576408 --> 0.572805).  Saving model ...
	 Train_Loss: 0.5898 Train_Acc: 72.617 Val_Loss: 0.5728  BEST VAL Loss: 0.5728  Val_Acc: 72.437

Epoch 12: Validation loss decreased (0.572805 --> 0.568652).  Saving model ...
	 Train_Loss: 0.5852 Train_Acc: 73.710 Val_Loss: 0.5687  BEST VAL Loss: 0.5687  Val_Acc: 72.101

Epoch 13: Validation loss decreased (0.568652 --> 0.565234).  Saving model ...
	 Train_Loss: 0.5804 Train_Acc: 74.504 Val_Loss: 0.5652  BEST VAL Loss: 0.5652  Val_Acc: 73.193

Epoch 14: Validation loss decreased (0.565234 --> 0.562302).  Saving model ...
	 Train_Loss: 0.5770 Train_Acc: 74.220 Val_Loss: 0.5623  BEST VAL Loss: 0.5623  Val_Acc: 73.235

Epoch 15: Validation loss decreased (0.562302 --> 0.559081).  Saving model ...
	 Train_Loss: 0.5735 Train_Acc: 74.992 Val_Loss: 0.5591  BEST VAL Loss: 0.5591  Val_Acc: 73.487

Epoch 16: Validation loss decreased (0.559081 --> 0.555917).  Saving model ...
	 Train_Loss: 0.5696 Train_Acc: 74.346 Val_Loss: 0.5559  BEST VAL Loss: 0.5559  Val_Acc: 74.580

Epoch 17: Validation loss decreased (0.555917 --> 0.552706).  Saving model ...
	 Train_Loss: 0.5661 Train_Acc: 75.323 Val_Loss: 0.5527  BEST VAL Loss: 0.5527  Val_Acc: 75.630

Epoch 18: Validation loss decreased (0.552706 --> 0.550363).  Saving model ...
	 Train_Loss: 0.5625 Train_Acc: 75.906 Val_Loss: 0.5504  BEST VAL Loss: 0.5504  Val_Acc: 74.664

Epoch 19: Validation loss decreased (0.550363 --> 0.548175).  Saving model ...
	 Train_Loss: 0.5595 Train_Acc: 75.313 Val_Loss: 0.5482  BEST VAL Loss: 0.5482  Val_Acc: 74.412

Epoch 20: Validation loss decreased (0.548175 --> 0.546149).  Saving model ...
	 Train_Loss: 0.5564 Train_Acc: 76.043 Val_Loss: 0.5461  BEST VAL Loss: 0.5461  Val_Acc: 74.874

Epoch 21: Validation loss decreased (0.546149 --> 0.544184).  Saving model ...
	 Train_Loss: 0.5536 Train_Acc: 76.873 Val_Loss: 0.5442  BEST VAL Loss: 0.5442  Val_Acc: 74.454

Epoch 22: Validation loss decreased (0.544184 --> 0.542754).  Saving model ...
	 Train_Loss: 0.5516 Train_Acc: 74.199 Val_Loss: 0.5428  BEST VAL Loss: 0.5428  Val_Acc: 73.235

Epoch 23: Validation loss decreased (0.542754 --> 0.540947).  Saving model ...
	 Train_Loss: 0.5492 Train_Acc: 75.780 Val_Loss: 0.5409  BEST VAL Loss: 0.5409  Val_Acc: 74.832

Epoch 24: Validation loss decreased (0.540947 --> 0.539359).  Saving model ...
	 Train_Loss: 0.5466 Train_Acc: 76.899 Val_Loss: 0.5394  BEST VAL Loss: 0.5394  Val_Acc: 75.588

Epoch 25: Validation loss decreased (0.539359 --> 0.537214).  Saving model ...
	 Train_Loss: 0.5435 Train_Acc: 77.960 Val_Loss: 0.5372  BEST VAL Loss: 0.5372  Val_Acc: 75.714

Epoch 26: Validation loss decreased (0.537214 --> 0.535754).  Saving model ...
	 Train_Loss: 0.5404 Train_Acc: 77.918 Val_Loss: 0.5358  BEST VAL Loss: 0.5358  Val_Acc: 75.798

Epoch 27: Validation loss decreased (0.535754 --> 0.534312).  Saving model ...
	 Train_Loss: 0.5383 Train_Acc: 77.020 Val_Loss: 0.5343  BEST VAL Loss: 0.5343  Val_Acc: 74.664

Epoch 28: Validation loss decreased (0.534312 --> 0.532654).  Saving model ...
	 Train_Loss: 0.5370 Train_Acc: 76.637 Val_Loss: 0.5327  BEST VAL Loss: 0.5327  Val_Acc: 74.664

Epoch 29: Validation loss decreased (0.532654 --> 0.531420).  Saving model ...
	 Train_Loss: 0.5356 Train_Acc: 75.160 Val_Loss: 0.5314  BEST VAL Loss: 0.5314  Val_Acc: 75.084

Epoch 30: Validation loss decreased (0.531420 --> 0.530240).  Saving model ...
	 Train_Loss: 0.5338 Train_Acc: 77.850 Val_Loss: 0.5302  BEST VAL Loss: 0.5302  Val_Acc: 76.008

Epoch 31: Validation loss decreased (0.530240 --> 0.528749).  Saving model ...
	 Train_Loss: 0.5320 Train_Acc: 77.304 Val_Loss: 0.5287  BEST VAL Loss: 0.5287  Val_Acc: 75.630

Epoch 32: Validation loss decreased (0.528749 --> 0.527479).  Saving model ...
	 Train_Loss: 0.5298 Train_Acc: 77.976 Val_Loss: 0.5275  BEST VAL Loss: 0.5275  Val_Acc: 76.429

Epoch 33: Validation loss decreased (0.527479 --> 0.525892).  Saving model ...
	 Train_Loss: 0.5278 Train_Acc: 78.549 Val_Loss: 0.5259  BEST VAL Loss: 0.5259  Val_Acc: 76.218

Epoch 34: Validation loss decreased (0.525892 --> 0.524438).  Saving model ...
	 Train_Loss: 0.5259 Train_Acc: 78.969 Val_Loss: 0.5244  BEST VAL Loss: 0.5244  Val_Acc: 76.513

Epoch 35: Validation loss decreased (0.524438 --> 0.523456).  Saving model ...
	 Train_Loss: 0.5241 Train_Acc: 78.890 Val_Loss: 0.5235  BEST VAL Loss: 0.5235  Val_Acc: 76.092

Epoch 36: Validation loss decreased (0.523456 --> 0.522638).  Saving model ...
	 Train_Loss: 0.5222 Train_Acc: 79.080 Val_Loss: 0.5226  BEST VAL Loss: 0.5226  Val_Acc: 75.924

Epoch 37: Validation loss decreased (0.522638 --> 0.521467).  Saving model ...
	 Train_Loss: 0.5203 Train_Acc: 79.484 Val_Loss: 0.5215  BEST VAL Loss: 0.5215  Val_Acc: 77.101

Epoch 38: Validation loss decreased (0.521467 --> 0.520087).  Saving model ...
	 Train_Loss: 0.5186 Train_Acc: 79.316 Val_Loss: 0.5201  BEST VAL Loss: 0.5201  Val_Acc: 76.134

Epoch 39: Validation loss decreased (0.520087 --> 0.519255).  Saving model ...
	 Train_Loss: 0.5164 Train_Acc: 79.295 Val_Loss: 0.5193  BEST VAL Loss: 0.5193  Val_Acc: 75.378

Epoch 40: Validation loss decreased (0.519255 --> 0.518322).  Saving model ...
	 Train_Loss: 0.5144 Train_Acc: 79.904 Val_Loss: 0.5183  BEST VAL Loss: 0.5183  Val_Acc: 75.378

Epoch 41: Validation loss decreased (0.518322 --> 0.517659).  Saving model ...
	 Train_Loss: 0.5125 Train_Acc: 80.009 Val_Loss: 0.5177  BEST VAL Loss: 0.5177  Val_Acc: 75.840

Epoch 42: Validation loss decreased (0.517659 --> 0.516862).  Saving model ...
	 Train_Loss: 0.5105 Train_Acc: 80.251 Val_Loss: 0.5169  BEST VAL Loss: 0.5169  Val_Acc: 75.924

Epoch 43: Validation loss decreased (0.516862 --> 0.515680).  Saving model ...
	 Train_Loss: 0.5086 Train_Acc: 80.109 Val_Loss: 0.5157  BEST VAL Loss: 0.5157  Val_Acc: 76.807

Epoch 44: Validation loss decreased (0.515680 --> 0.514922).  Saving model ...
	 Train_Loss: 0.5071 Train_Acc: 79.311 Val_Loss: 0.5149  BEST VAL Loss: 0.5149  Val_Acc: 75.756

Epoch 45: Validation loss decreased (0.514922 --> 0.514509).  Saving model ...
	 Train_Loss: 0.5057 Train_Acc: 80.057 Val_Loss: 0.5145  BEST VAL Loss: 0.5145  Val_Acc: 75.504

Epoch 46: Validation loss decreased (0.514509 --> 0.513871).  Saving model ...
	 Train_Loss: 0.5044 Train_Acc: 79.826 Val_Loss: 0.5139  BEST VAL Loss: 0.5139  Val_Acc: 77.269

Epoch 47: Validation loss decreased (0.513871 --> 0.513365).  Saving model ...
	 Train_Loss: 0.5033 Train_Acc: 79.652 Val_Loss: 0.5134  BEST VAL Loss: 0.5134  Val_Acc: 75.798

Epoch 48: Validation loss decreased (0.513365 --> 0.512846).  Saving model ...
	 Train_Loss: 0.5020 Train_Acc: 79.794 Val_Loss: 0.5128  BEST VAL Loss: 0.5128  Val_Acc: 76.261

Epoch 49: Validation loss decreased (0.512846 --> 0.511915).  Saving model ...
	 Train_Loss: 0.5008 Train_Acc: 80.262 Val_Loss: 0.5119  BEST VAL Loss: 0.5119  Val_Acc: 77.143

Epoch 50: Validation loss decreased (0.511915 --> 0.511279).  Saving model ...
	 Train_Loss: 0.4997 Train_Acc: 79.883 Val_Loss: 0.5113  BEST VAL Loss: 0.5113  Val_Acc: 77.101

Epoch 51: Validation loss decreased (0.511279 --> 0.510819).  Saving model ...
	 Train_Loss: 0.4982 Train_Acc: 80.551 Val_Loss: 0.5108  BEST VAL Loss: 0.5108  Val_Acc: 77.017

Epoch 52: Validation loss decreased (0.510819 --> 0.510140).  Saving model ...
	 Train_Loss: 0.4969 Train_Acc: 80.519 Val_Loss: 0.5101  BEST VAL Loss: 0.5101  Val_Acc: 76.807

Epoch 53: Validation loss decreased (0.510140 --> 0.509405).  Saving model ...
	 Train_Loss: 0.4956 Train_Acc: 80.640 Val_Loss: 0.5094  BEST VAL Loss: 0.5094  Val_Acc: 76.471

Epoch 54: Validation loss decreased (0.509405 --> 0.509043).  Saving model ...
	 Train_Loss: 0.4943 Train_Acc: 80.698 Val_Loss: 0.5090  BEST VAL Loss: 0.5090  Val_Acc: 76.555

Epoch 55: Validation loss decreased (0.509043 --> 0.508678).  Saving model ...
	 Train_Loss: 0.4931 Train_Acc: 79.952 Val_Loss: 0.5087  BEST VAL Loss: 0.5087  Val_Acc: 76.387

Epoch 56: Validation loss decreased (0.508678 --> 0.508252).  Saving model ...
	 Train_Loss: 0.4918 Train_Acc: 81.249 Val_Loss: 0.5083  BEST VAL Loss: 0.5083  Val_Acc: 75.798

Epoch 57: Validation loss decreased (0.508252 --> 0.507637).  Saving model ...
	 Train_Loss: 0.4906 Train_Acc: 80.918 Val_Loss: 0.5076  BEST VAL Loss: 0.5076  Val_Acc: 76.345

Epoch 58: Validation loss decreased (0.507637 --> 0.507609).  Saving model ...
	 Train_Loss: 0.4894 Train_Acc: 80.340 Val_Loss: 0.5076  BEST VAL Loss: 0.5076  Val_Acc: 77.017

Epoch 59: Validation loss decreased (0.507609 --> 0.507214).  Saving model ...
	 Train_Loss: 0.4880 Train_Acc: 82.095 Val_Loss: 0.5072  BEST VAL Loss: 0.5072  Val_Acc: 76.218

Epoch 60: Validation loss decreased (0.507214 --> 0.506911).  Saving model ...
	 Train_Loss: 0.4868 Train_Acc: 81.685 Val_Loss: 0.5069  BEST VAL Loss: 0.5069  Val_Acc: 76.513

Epoch 61: Validation loss decreased (0.506911 --> 0.506661).  Saving model ...
	 Train_Loss: 0.4855 Train_Acc: 81.628 Val_Loss: 0.5067  BEST VAL Loss: 0.5067  Val_Acc: 76.681

Epoch 62: Validation loss decreased (0.506661 --> 0.506396).  Saving model ...
	 Train_Loss: 0.4845 Train_Acc: 81.475 Val_Loss: 0.5064  BEST VAL Loss: 0.5064  Val_Acc: 76.849

Epoch 63: Validation loss decreased (0.506396 --> 0.506000).  Saving model ...
	 Train_Loss: 0.4836 Train_Acc: 80.934 Val_Loss: 0.5060  BEST VAL Loss: 0.5060  Val_Acc: 76.008

Epoch 64: Validation loss decreased (0.506000 --> 0.505857).  Saving model ...
	 Train_Loss: 0.4826 Train_Acc: 81.034 Val_Loss: 0.5059  BEST VAL Loss: 0.5059  Val_Acc: 77.269

Epoch 65: Validation loss decreased (0.505857 --> 0.505486).  Saving model ...
	 Train_Loss: 0.4815 Train_Acc: 81.838 Val_Loss: 0.5055  BEST VAL Loss: 0.5055  Val_Acc: 76.429

Epoch 66: Validation loss decreased (0.505486 --> 0.505411).  Saving model ...
	 Train_Loss: 0.4807 Train_Acc: 80.041 Val_Loss: 0.5054  BEST VAL Loss: 0.5054  Val_Acc: 75.546

Epoch 67: Validation loss decreased (0.505411 --> 0.505172).  Saving model ...
	 Train_Loss: 0.4798 Train_Acc: 81.013 Val_Loss: 0.5052  BEST VAL Loss: 0.5052  Val_Acc: 76.303

Epoch 68: Validation loss decreased (0.505172 --> 0.505011).  Saving model ...
	 Train_Loss: 0.4789 Train_Acc: 81.659 Val_Loss: 0.5050  BEST VAL Loss: 0.5050  Val_Acc: 76.134

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.4781 Train_Acc: 81.354 Val_Loss: 0.5050  BEST VAL Loss: 0.5050  Val_Acc: 75.126

Epoch 70: Validation loss decreased (0.505011 --> 0.504697).  Saving model ...
	 Train_Loss: 0.4774 Train_Acc: 79.957 Val_Loss: 0.5047  BEST VAL Loss: 0.5047  Val_Acc: 76.681

Epoch 71: Validation loss decreased (0.504697 --> 0.504414).  Saving model ...
	 Train_Loss: 0.4767 Train_Acc: 80.204 Val_Loss: 0.5044  BEST VAL Loss: 0.5044  Val_Acc: 75.882

Epoch 72: Validation loss decreased (0.504414 --> 0.504204).  Saving model ...
	 Train_Loss: 0.4760 Train_Acc: 81.622 Val_Loss: 0.5042  BEST VAL Loss: 0.5042  Val_Acc: 76.471

Epoch 73: Validation loss decreased (0.504204 --> 0.503983).  Saving model ...
	 Train_Loss: 0.4753 Train_Acc: 80.514 Val_Loss: 0.5040  BEST VAL Loss: 0.5040  Val_Acc: 76.008

Epoch 74: Validation loss decreased (0.503983 --> 0.503700).  Saving model ...
	 Train_Loss: 0.4744 Train_Acc: 81.622 Val_Loss: 0.5037  BEST VAL Loss: 0.5037  Val_Acc: 76.597

Epoch 75: Validation loss decreased (0.503700 --> 0.503515).  Saving model ...
	 Train_Loss: 0.4734 Train_Acc: 82.174 Val_Loss: 0.5035  BEST VAL Loss: 0.5035  Val_Acc: 77.311

Epoch 76: Validation loss decreased (0.503515 --> 0.503311).  Saving model ...
	 Train_Loss: 0.4724 Train_Acc: 82.311 Val_Loss: 0.5033  BEST VAL Loss: 0.5033  Val_Acc: 76.723

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.4716 Train_Acc: 82.001 Val_Loss: 0.5035  BEST VAL Loss: 0.5033  Val_Acc: 76.975

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.4706 Train_Acc: 82.904 Val_Loss: 0.5034  BEST VAL Loss: 0.5033  Val_Acc: 77.311

Epoch 79: Validation loss decreased (0.503311 --> 0.503225).  Saving model ...
	 Train_Loss: 0.4695 Train_Acc: 82.841 Val_Loss: 0.5032  BEST VAL Loss: 0.5032  Val_Acc: 77.017

Epoch 80: Validation loss decreased (0.503225 --> 0.502940).  Saving model ...
	 Train_Loss: 0.4686 Train_Acc: 83.283 Val_Loss: 0.5029  BEST VAL Loss: 0.5029  Val_Acc: 76.429

Epoch 81: Validation loss decreased (0.502940 --> 0.502927).  Saving model ...
	 Train_Loss: 0.4680 Train_Acc: 81.433 Val_Loss: 0.5029  BEST VAL Loss: 0.5029  Val_Acc: 76.681

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.4671 Train_Acc: 81.995 Val_Loss: 0.5029  BEST VAL Loss: 0.5029  Val_Acc: 76.933

Epoch 83: Validation loss decreased (0.502927 --> 0.502873).  Saving model ...
	 Train_Loss: 0.4663 Train_Acc: 82.358 Val_Loss: 0.5029  BEST VAL Loss: 0.5029  Val_Acc: 77.101

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.4654 Train_Acc: 82.626 Val_Loss: 0.5029  BEST VAL Loss: 0.5029  Val_Acc: 77.311

Epoch 85: Validation loss decreased (0.502873 --> 0.502714).  Saving model ...
	 Train_Loss: 0.4644 Train_Acc: 83.151 Val_Loss: 0.5027  BEST VAL Loss: 0.5027  Val_Acc: 76.723

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.4636 Train_Acc: 83.267 Val_Loss: 0.5027  BEST VAL Loss: 0.5027  Val_Acc: 77.479

Epoch 87: Validation loss decreased (0.502714 --> 0.502691).  Saving model ...
	 Train_Loss: 0.4627 Train_Acc: 82.831 Val_Loss: 0.5027  BEST VAL Loss: 0.5027  Val_Acc: 77.059

Epoch 88: Validation loss decreased (0.502691 --> 0.502586).  Saving model ...
	 Train_Loss: 0.4618 Train_Acc: 83.761 Val_Loss: 0.5026  BEST VAL Loss: 0.5026  Val_Acc: 76.176

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.4613 Train_Acc: 81.391 Val_Loss: 0.5029  BEST VAL Loss: 0.5026  Val_Acc: 75.252

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.4607 Train_Acc: 81.638 Val_Loss: 0.5029  BEST VAL Loss: 0.5026  Val_Acc: 75.798

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.4599 Train_Acc: 82.642 Val_Loss: 0.5029  BEST VAL Loss: 0.5026  Val_Acc: 75.882

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.4592 Train_Acc: 82.946 Val_Loss: 0.5031  BEST VAL Loss: 0.5026  Val_Acc: 76.387

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.4584 Train_Acc: 82.515 Val_Loss: 0.5031  BEST VAL Loss: 0.5026  Val_Acc: 76.933

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.4576 Train_Acc: 83.577 Val_Loss: 0.5032  BEST VAL Loss: 0.5026  Val_Acc: 77.017

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.4568 Train_Acc: 83.051 Val_Loss: 0.5032  BEST VAL Loss: 0.5026  Val_Acc: 76.513

Epoch 96: Validation loss did not decrease
	 Train_Loss: 0.4561 Train_Acc: 82.510 Val_Loss: 0.5031  BEST VAL Loss: 0.5026  Val_Acc: 77.227

Epoch 97: Validation loss did not decrease
	 Train_Loss: 0.4553 Train_Acc: 83.330 Val_Loss: 0.5034  BEST VAL Loss: 0.5026  Val_Acc: 77.269

Epoch 98: Validation loss did not decrease
	 Train_Loss: 0.4546 Train_Acc: 83.009 Val_Loss: 0.5033  BEST VAL Loss: 0.5026  Val_Acc: 77.605

Epoch 99: Validation loss did not decrease
	 Train_Loss: 0.4539 Train_Acc: 83.892 Val_Loss: 0.5031  BEST VAL Loss: 0.5026  Val_Acc: 76.975

Flagellin_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.51      0.48      8633
           1       0.55      0.50      0.52     10401

    accuracy                           0.50     19034
   macro avg       0.50      0.50      0.50     19034
weighted avg       0.51      0.50      0.50     19034

Flagellin_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.45      0.52      0.48      1080
           1       0.54      0.48      0.51      1300

    accuracy                           0.50      2380
   macro avg       0.50      0.50      0.50      2380
weighted avg       0.50      0.50      0.50      2380

Flagellin_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.53      0.49      1080
           1       0.55      0.48      0.51      1300

    accuracy                           0.50      2380
   macro avg       0.51      0.51      0.50      2380
weighted avg       0.51      0.50      0.50      2380

              precision    recall  f1-score   support

           0       0.46      0.53      0.49      1080
           1       0.55      0.48      0.51      1300

    accuracy                           0.50      2380
   macro avg       0.51      0.51      0.50      2380
weighted avg       0.51      0.50      0.50      2380

Flagellin_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.42      0.45      4135
           1       0.52      0.57      0.54      4509

    accuracy                           0.50      8644
   macro avg       0.50      0.50      0.50      8644
weighted avg       0.50      0.50      0.50      8644

              precision    recall  f1-score   support

           0       0.47      0.42      0.45      4135
           1       0.52      0.57      0.54      4509

    accuracy                           0.50      8644
   macro avg       0.50      0.50      0.50      8644
weighted avg       0.50      0.50      0.50      8644

completed
