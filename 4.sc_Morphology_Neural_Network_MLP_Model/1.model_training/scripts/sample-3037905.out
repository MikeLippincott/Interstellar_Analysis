[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'e2b36d62'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'd3e3cb37'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '5974e36b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'bcd089e2'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_1.000_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_1.000_DMSO_0.025
TREATMENT_NAME: Flagellin_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (32267, 1276)
Number of total missing values across all columns: 64534
Data Subset Is Off
Wells held out for testing: ['D21' 'M22']
Wells to use for training, validation, and testing ['D16' 'D17' 'D20' 'M18' 'M19' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.692396).  Saving model ...
	 Train_Loss: 0.6928 Train_Acc: 52.993 Val_Loss: 0.6924  BEST VAL Loss: 0.6924  Val_Acc: 51.747

Epoch 1: Validation loss decreased (0.692396 --> 0.689464).  Saving model ...
	 Train_Loss: 0.6909 Train_Acc: 54.745 Val_Loss: 0.6895  BEST VAL Loss: 0.6895  Val_Acc: 55.857

Epoch 2: Validation loss decreased (0.689464 --> 0.685193).  Saving model ...
	 Train_Loss: 0.6879 Train_Acc: 56.528 Val_Loss: 0.6852  BEST VAL Loss: 0.6852  Val_Acc: 58.364

Epoch 3: Validation loss decreased (0.685193 --> 0.680945).  Saving model ...
	 Train_Loss: 0.6842 Train_Acc: 58.240 Val_Loss: 0.6809  BEST VAL Loss: 0.6809  Val_Acc: 59.351

Epoch 4: Validation loss decreased (0.680945 --> 0.677352).  Saving model ...
	 Train_Loss: 0.6806 Train_Acc: 59.761 Val_Loss: 0.6774  BEST VAL Loss: 0.6774  Val_Acc: 59.762

Epoch 5: Validation loss decreased (0.677352 --> 0.674325).  Saving model ...
	 Train_Loss: 0.6768 Train_Acc: 61.600 Val_Loss: 0.6743  BEST VAL Loss: 0.6743  Val_Acc: 61.077

Epoch 6: Validation loss decreased (0.674325 --> 0.670820).  Saving model ...
	 Train_Loss: 0.6729 Train_Acc: 62.242 Val_Loss: 0.6708  BEST VAL Loss: 0.6708  Val_Acc: 61.693

Epoch 7: Validation loss decreased (0.670820 --> 0.666543).  Saving model ...
	 Train_Loss: 0.6693 Train_Acc: 63.584 Val_Loss: 0.6665  BEST VAL Loss: 0.6665  Val_Acc: 64.324

Epoch 8: Validation loss decreased (0.666543 --> 0.662668).  Saving model ...
	 Train_Loss: 0.6652 Train_Acc: 65.187 Val_Loss: 0.6627  BEST VAL Loss: 0.6627  Val_Acc: 64.242

Epoch 9: Validation loss decreased (0.662668 --> 0.658719).  Saving model ...
	 Train_Loss: 0.6611 Train_Acc: 65.711 Val_Loss: 0.6587  BEST VAL Loss: 0.6587  Val_Acc: 65.968

Epoch 10: Validation loss decreased (0.658719 --> 0.654251).  Saving model ...
	 Train_Loss: 0.6576 Train_Acc: 66.302 Val_Loss: 0.6543  BEST VAL Loss: 0.6543  Val_Acc: 68.352

Epoch 11: Validation loss decreased (0.654251 --> 0.650235).  Saving model ...
	 Train_Loss: 0.6531 Train_Acc: 68.167 Val_Loss: 0.6502  BEST VAL Loss: 0.6502  Val_Acc: 67.982

Epoch 12: Validation loss decreased (0.650235 --> 0.646836).  Saving model ...
	 Train_Loss: 0.6491 Train_Acc: 68.239 Val_Loss: 0.6468  BEST VAL Loss: 0.6468  Val_Acc: 68.311

Epoch 13: Validation loss decreased (0.646836 --> 0.643378).  Saving model ...
	 Train_Loss: 0.6454 Train_Acc: 69.143 Val_Loss: 0.6434  BEST VAL Loss: 0.6434  Val_Acc: 68.105

Epoch 14: Validation loss decreased (0.643378 --> 0.639907).  Saving model ...
	 Train_Loss: 0.6419 Train_Acc: 69.493 Val_Loss: 0.6399  BEST VAL Loss: 0.6399  Val_Acc: 70.037

Epoch 15: Validation loss decreased (0.639907 --> 0.636447).  Saving model ...
	 Train_Loss: 0.6384 Train_Acc: 69.930 Val_Loss: 0.6364  BEST VAL Loss: 0.6364  Val_Acc: 70.530

Epoch 16: Validation loss decreased (0.636447 --> 0.633385).  Saving model ...
	 Train_Loss: 0.6351 Train_Acc: 70.731 Val_Loss: 0.6334  BEST VAL Loss: 0.6334  Val_Acc: 69.790

Epoch 17: Validation loss decreased (0.633385 --> 0.630813).  Saving model ...
	 Train_Loss: 0.6321 Train_Acc: 70.541 Val_Loss: 0.6308  BEST VAL Loss: 0.6308  Val_Acc: 69.174

Epoch 18: Validation loss decreased (0.630813 --> 0.628468).  Saving model ...
	 Train_Loss: 0.6292 Train_Acc: 71.081 Val_Loss: 0.6285  BEST VAL Loss: 0.6285  Val_Acc: 69.626

Epoch 19: Validation loss decreased (0.628468 --> 0.626240).  Saving model ...
	 Train_Loss: 0.6263 Train_Acc: 71.574 Val_Loss: 0.6262  BEST VAL Loss: 0.6262  Val_Acc: 70.489

Epoch 20: Validation loss decreased (0.626240 --> 0.624096).  Saving model ...
	 Train_Loss: 0.6234 Train_Acc: 71.882 Val_Loss: 0.6241  BEST VAL Loss: 0.6241  Val_Acc: 70.695

Epoch 21: Validation loss decreased (0.624096 --> 0.621902).  Saving model ...
	 Train_Loss: 0.6206 Train_Acc: 72.555 Val_Loss: 0.6219  BEST VAL Loss: 0.6219  Val_Acc: 71.558

Epoch 22: Validation loss decreased (0.621902 --> 0.619925).  Saving model ...
	 Train_Loss: 0.6177 Train_Acc: 73.049 Val_Loss: 0.6199  BEST VAL Loss: 0.6199  Val_Acc: 70.325

Epoch 23: Validation loss decreased (0.619925 --> 0.618236).  Saving model ...
	 Train_Loss: 0.6153 Train_Acc: 72.283 Val_Loss: 0.6182  BEST VAL Loss: 0.6182  Val_Acc: 71.188

Epoch 24: Validation loss decreased (0.618236 --> 0.616895).  Saving model ...
	 Train_Loss: 0.6129 Train_Acc: 72.915 Val_Loss: 0.6169  BEST VAL Loss: 0.6169  Val_Acc: 70.900

Epoch 25: Validation loss decreased (0.616895 --> 0.615128).  Saving model ...
	 Train_Loss: 0.6104 Train_Acc: 73.398 Val_Loss: 0.6151  BEST VAL Loss: 0.6151  Val_Acc: 71.476

Epoch 26: Validation loss decreased (0.615128 --> 0.613526).  Saving model ...
	 Train_Loss: 0.6081 Train_Acc: 73.449 Val_Loss: 0.6135  BEST VAL Loss: 0.6135  Val_Acc: 71.681

Epoch 27: Validation loss decreased (0.613526 --> 0.611905).  Saving model ...
	 Train_Loss: 0.6059 Train_Acc: 73.398 Val_Loss: 0.6119  BEST VAL Loss: 0.6119  Val_Acc: 72.092

Epoch 28: Validation loss decreased (0.611905 --> 0.610273).  Saving model ...
	 Train_Loss: 0.6039 Train_Acc: 73.783 Val_Loss: 0.6103  BEST VAL Loss: 0.6103  Val_Acc: 72.709

Epoch 29: Validation loss decreased (0.610273 --> 0.608842).  Saving model ...
	 Train_Loss: 0.6018 Train_Acc: 73.948 Val_Loss: 0.6088  BEST VAL Loss: 0.6088  Val_Acc: 71.804

Epoch 30: Validation loss decreased (0.608842 --> 0.607566).  Saving model ...
	 Train_Loss: 0.5998 Train_Acc: 74.539 Val_Loss: 0.6076  BEST VAL Loss: 0.6076  Val_Acc: 71.928

Epoch 31: Validation loss decreased (0.607566 --> 0.606383).  Saving model ...
	 Train_Loss: 0.5980 Train_Acc: 73.999 Val_Loss: 0.6064  BEST VAL Loss: 0.6064  Val_Acc: 71.722

Epoch 32: Validation loss decreased (0.606383 --> 0.605258).  Saving model ...
	 Train_Loss: 0.5961 Train_Acc: 74.374 Val_Loss: 0.6053  BEST VAL Loss: 0.6053  Val_Acc: 72.791

Epoch 33: Validation loss decreased (0.605258 --> 0.604083).  Saving model ...
	 Train_Loss: 0.5943 Train_Acc: 74.251 Val_Loss: 0.6041  BEST VAL Loss: 0.6041  Val_Acc: 72.215

Epoch 34: Validation loss decreased (0.604083 --> 0.602922).  Saving model ...
	 Train_Loss: 0.5927 Train_Acc: 74.785 Val_Loss: 0.6029  BEST VAL Loss: 0.6029  Val_Acc: 73.531

Epoch 35: Validation loss decreased (0.602922 --> 0.602263).  Saving model ...
	 Train_Loss: 0.5907 Train_Acc: 75.089 Val_Loss: 0.6023  BEST VAL Loss: 0.6023  Val_Acc: 71.763

Epoch 36: Validation loss decreased (0.602263 --> 0.601505).  Saving model ...
	 Train_Loss: 0.5890 Train_Acc: 75.227 Val_Loss: 0.6015  BEST VAL Loss: 0.6015  Val_Acc: 72.544

Epoch 37: Validation loss decreased (0.601505 --> 0.600689).  Saving model ...
	 Train_Loss: 0.5874 Train_Acc: 75.027 Val_Loss: 0.6007  BEST VAL Loss: 0.6007  Val_Acc: 72.133

Epoch 38: Validation loss decreased (0.600689 --> 0.599645).  Saving model ...
	 Train_Loss: 0.5857 Train_Acc: 75.890 Val_Loss: 0.5996  BEST VAL Loss: 0.5996  Val_Acc: 73.531

Epoch 39: Validation loss decreased (0.599645 --> 0.598961).  Saving model ...
	 Train_Loss: 0.5839 Train_Acc: 76.121 Val_Loss: 0.5990  BEST VAL Loss: 0.5990  Val_Acc: 73.161

Epoch 40: Validation loss decreased (0.598961 --> 0.597931).  Saving model ...
	 Train_Loss: 0.5824 Train_Acc: 75.536 Val_Loss: 0.5979  BEST VAL Loss: 0.5979  Val_Acc: 73.736

Epoch 41: Validation loss decreased (0.597931 --> 0.597235).  Saving model ...
	 Train_Loss: 0.5809 Train_Acc: 75.741 Val_Loss: 0.5972  BEST VAL Loss: 0.5972  Val_Acc: 72.380

Epoch 42: Validation loss decreased (0.597235 --> 0.596501).  Saving model ...
	 Train_Loss: 0.5795 Train_Acc: 75.340 Val_Loss: 0.5965  BEST VAL Loss: 0.5965  Val_Acc: 72.750

Epoch 43: Validation loss decreased (0.596501 --> 0.595743).  Saving model ...
	 Train_Loss: 0.5781 Train_Acc: 75.921 Val_Loss: 0.5957  BEST VAL Loss: 0.5957  Val_Acc: 73.777

Epoch 44: Validation loss decreased (0.595743 --> 0.595061).  Saving model ...
	 Train_Loss: 0.5767 Train_Acc: 76.471 Val_Loss: 0.5951  BEST VAL Loss: 0.5951  Val_Acc: 72.133

Epoch 45: Validation loss decreased (0.595061 --> 0.594475).  Saving model ...
	 Train_Loss: 0.5753 Train_Acc: 75.978 Val_Loss: 0.5945  BEST VAL Loss: 0.5945  Val_Acc: 72.215

Epoch 46: Validation loss decreased (0.594475 --> 0.594049).  Saving model ...
	 Train_Loss: 0.5740 Train_Acc: 76.332 Val_Loss: 0.5940  BEST VAL Loss: 0.5940  Val_Acc: 72.462

Epoch 47: Validation loss decreased (0.594049 --> 0.593493).  Saving model ...
	 Train_Loss: 0.5727 Train_Acc: 76.476 Val_Loss: 0.5935  BEST VAL Loss: 0.5935  Val_Acc: 73.120

Epoch 48: Validation loss decreased (0.593493 --> 0.593279).  Saving model ...
	 Train_Loss: 0.5713 Train_Acc: 76.831 Val_Loss: 0.5933  BEST VAL Loss: 0.5933  Val_Acc: 72.133

Epoch 49: Validation loss decreased (0.593279 --> 0.592833).  Saving model ...
	 Train_Loss: 0.5701 Train_Acc: 76.270 Val_Loss: 0.5928  BEST VAL Loss: 0.5928  Val_Acc: 73.243

Epoch 50: Validation loss decreased (0.592833 --> 0.592261).  Saving model ...
	 Train_Loss: 0.5691 Train_Acc: 75.736 Val_Loss: 0.5923  BEST VAL Loss: 0.5923  Val_Acc: 73.161

Epoch 51: Validation loss decreased (0.592261 --> 0.591721).  Saving model ...
	 Train_Loss: 0.5679 Train_Acc: 76.471 Val_Loss: 0.5917  BEST VAL Loss: 0.5917  Val_Acc: 73.448

Epoch 52: Validation loss decreased (0.591721 --> 0.591312).  Saving model ...
	 Train_Loss: 0.5667 Train_Acc: 76.486 Val_Loss: 0.5913  BEST VAL Loss: 0.5913  Val_Acc: 73.161

Epoch 53: Validation loss decreased (0.591312 --> 0.591054).  Saving model ...
	 Train_Loss: 0.5655 Train_Acc: 77.365 Val_Loss: 0.5911  BEST VAL Loss: 0.5911  Val_Acc: 73.654

Epoch 54: Validation loss decreased (0.591054 --> 0.590781).  Saving model ...
	 Train_Loss: 0.5642 Train_Acc: 77.159 Val_Loss: 0.5908  BEST VAL Loss: 0.5908  Val_Acc: 73.859

Epoch 55: Validation loss decreased (0.590781 --> 0.590557).  Saving model ...
	 Train_Loss: 0.5631 Train_Acc: 77.201 Val_Loss: 0.5906  BEST VAL Loss: 0.5906  Val_Acc: 73.983

Epoch 56: Validation loss decreased (0.590557 --> 0.590053).  Saving model ...
	 Train_Loss: 0.5621 Train_Acc: 76.579 Val_Loss: 0.5901  BEST VAL Loss: 0.5901  Val_Acc: 73.942

Epoch 57: Validation loss decreased (0.590053 --> 0.589763).  Saving model ...
	 Train_Loss: 0.5610 Train_Acc: 77.339 Val_Loss: 0.5898  BEST VAL Loss: 0.5898  Val_Acc: 73.818

Epoch 58: Validation loss decreased (0.589763 --> 0.589461).  Saving model ...
	 Train_Loss: 0.5599 Train_Acc: 77.303 Val_Loss: 0.5895  BEST VAL Loss: 0.5895  Val_Acc: 73.818

Epoch 59: Validation loss decreased (0.589461 --> 0.589047).  Saving model ...
	 Train_Loss: 0.5589 Train_Acc: 77.180 Val_Loss: 0.5890  BEST VAL Loss: 0.5890  Val_Acc: 74.229

Epoch 60: Validation loss decreased (0.589047 --> 0.588681).  Saving model ...
	 Train_Loss: 0.5579 Train_Acc: 77.201 Val_Loss: 0.5887  BEST VAL Loss: 0.5887  Val_Acc: 74.024

Epoch 61: Validation loss decreased (0.588681 --> 0.588492).  Saving model ...
	 Train_Loss: 0.5570 Train_Acc: 77.596 Val_Loss: 0.5885  BEST VAL Loss: 0.5885  Val_Acc: 73.695

Epoch 62: Validation loss decreased (0.588492 --> 0.588399).  Saving model ...
	 Train_Loss: 0.5559 Train_Acc: 77.853 Val_Loss: 0.5884  BEST VAL Loss: 0.5884  Val_Acc: 73.572

Epoch 63: Validation loss decreased (0.588399 --> 0.588233).  Saving model ...
	 Train_Loss: 0.5549 Train_Acc: 77.817 Val_Loss: 0.5882  BEST VAL Loss: 0.5882  Val_Acc: 73.901

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.5538 Train_Acc: 78.161 Val_Loss: 0.5885  BEST VAL Loss: 0.5882  Val_Acc: 73.366

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.5528 Train_Acc: 77.894 Val_Loss: 0.5887  BEST VAL Loss: 0.5882  Val_Acc: 74.024

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.5519 Train_Acc: 77.642 Val_Loss: 0.5886  BEST VAL Loss: 0.5882  Val_Acc: 73.983

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.5509 Train_Acc: 78.362 Val_Loss: 0.5884  BEST VAL Loss: 0.5882  Val_Acc: 73.859

Epoch 68: Validation loss decreased (0.588233 --> 0.588115).  Saving model ...
	 Train_Loss: 0.5501 Train_Acc: 77.555 Val_Loss: 0.5881  BEST VAL Loss: 0.5881  Val_Acc: 73.983

Epoch 69: Validation loss decreased (0.588115 --> 0.587985).  Saving model ...
	 Train_Loss: 0.5492 Train_Acc: 77.514 Val_Loss: 0.5880  BEST VAL Loss: 0.5880  Val_Acc: 73.736

Epoch 70: Validation loss decreased (0.587985 --> 0.587922).  Saving model ...
	 Train_Loss: 0.5484 Train_Acc: 78.064 Val_Loss: 0.5879  BEST VAL Loss: 0.5879  Val_Acc: 73.407

Epoch 71: Validation loss decreased (0.587922 --> 0.587853).  Saving model ...
	 Train_Loss: 0.5474 Train_Acc: 78.449 Val_Loss: 0.5879  BEST VAL Loss: 0.5879  Val_Acc: 74.065

Epoch 72: Validation loss decreased (0.587853 --> 0.587812).  Saving model ...
	 Train_Loss: 0.5466 Train_Acc: 77.833 Val_Loss: 0.5878  BEST VAL Loss: 0.5878  Val_Acc: 73.942

Epoch 73: Validation loss did not decrease
	 Train_Loss: 0.5459 Train_Acc: 77.632 Val_Loss: 0.5879  BEST VAL Loss: 0.5878  Val_Acc: 73.531

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.5450 Train_Acc: 78.444 Val_Loss: 0.5879  BEST VAL Loss: 0.5878  Val_Acc: 73.942

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.5443 Train_Acc: 77.982 Val_Loss: 0.5879  BEST VAL Loss: 0.5878  Val_Acc: 73.120

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.5434 Train_Acc: 78.449 Val_Loss: 0.5879  BEST VAL Loss: 0.5878  Val_Acc: 74.188

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.5427 Train_Acc: 78.223 Val_Loss: 0.5878  BEST VAL Loss: 0.5878  Val_Acc: 73.901

Epoch 78: Validation loss decreased (0.587812 --> 0.587600).  Saving model ...
	 Train_Loss: 0.5419 Train_Acc: 77.884 Val_Loss: 0.5876  BEST VAL Loss: 0.5876  Val_Acc: 74.928

Epoch 79: Validation loss decreased (0.587600 --> 0.587500).  Saving model ...
	 Train_Loss: 0.5412 Train_Acc: 78.239 Val_Loss: 0.5875  BEST VAL Loss: 0.5875  Val_Acc: 74.599

Epoch 80: Validation loss decreased (0.587500 --> 0.587421).  Saving model ...
	 Train_Loss: 0.5404 Train_Acc: 78.588 Val_Loss: 0.5874  BEST VAL Loss: 0.5874  Val_Acc: 75.051

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.5396 Train_Acc: 78.506 Val_Loss: 0.5875  BEST VAL Loss: 0.5874  Val_Acc: 72.955

Epoch 82: Validation loss decreased (0.587421 --> 0.587405).  Saving model ...
	 Train_Loss: 0.5389 Train_Acc: 78.480 Val_Loss: 0.5874  BEST VAL Loss: 0.5874  Val_Acc: 73.654

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.5382 Train_Acc: 78.737 Val_Loss: 0.5876  BEST VAL Loss: 0.5874  Val_Acc: 74.353

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.5374 Train_Acc: 78.922 Val_Loss: 0.5875  BEST VAL Loss: 0.5874  Val_Acc: 74.394

Epoch 85: Validation loss decreased (0.587405 --> 0.587377).  Saving model ...
	 Train_Loss: 0.5368 Train_Acc: 78.208 Val_Loss: 0.5874  BEST VAL Loss: 0.5874  Val_Acc: 73.736

Epoch 86: Validation loss decreased (0.587377 --> 0.587367).  Saving model ...
	 Train_Loss: 0.5362 Train_Acc: 78.593 Val_Loss: 0.5874  BEST VAL Loss: 0.5874  Val_Acc: 73.859

Epoch 87: Validation loss decreased (0.587367 --> 0.587307).  Saving model ...
	 Train_Loss: 0.5355 Train_Acc: 79.009 Val_Loss: 0.5873  BEST VAL Loss: 0.5873  Val_Acc: 73.243

Epoch 88: Validation loss decreased (0.587307 --> 0.587285).  Saving model ...
	 Train_Loss: 0.5348 Train_Acc: 78.578 Val_Loss: 0.5873  BEST VAL Loss: 0.5873  Val_Acc: 73.613

Epoch 89: Validation loss decreased (0.587285 --> 0.587261).  Saving model ...
	 Train_Loss: 0.5341 Train_Acc: 78.855 Val_Loss: 0.5873  BEST VAL Loss: 0.5873  Val_Acc: 74.599

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.5334 Train_Acc: 79.184 Val_Loss: 0.5873  BEST VAL Loss: 0.5873  Val_Acc: 74.846

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.5327 Train_Acc: 78.891 Val_Loss: 0.5873  BEST VAL Loss: 0.5873  Val_Acc: 73.079

Epoch 92: Validation loss decreased (0.587261 --> 0.587198).  Saving model ...
	 Train_Loss: 0.5322 Train_Acc: 78.973 Val_Loss: 0.5872  BEST VAL Loss: 0.5872  Val_Acc: 73.531

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.5314 Train_Acc: 79.374 Val_Loss: 0.5874  BEST VAL Loss: 0.5872  Val_Acc: 74.394

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.5308 Train_Acc: 79.472 Val_Loss: 0.5874  BEST VAL Loss: 0.5872  Val_Acc: 74.353

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.5301 Train_Acc: 79.194 Val_Loss: 0.5875  BEST VAL Loss: 0.5872  Val_Acc: 73.818

Epoch 96: Validation loss did not decrease
	 Train_Loss: 0.5295 Train_Acc: 78.711 Val_Loss: 0.5875  BEST VAL Loss: 0.5872  Val_Acc: 73.120

Epoch 97: Validation loss did not decrease
	 Train_Loss: 0.5289 Train_Acc: 78.968 Val_Loss: 0.5874  BEST VAL Loss: 0.5872  Val_Acc: 74.599

Epoch 98: Validation loss did not decrease
	 Train_Loss: 0.5283 Train_Acc: 79.261 Val_Loss: 0.5875  BEST VAL Loss: 0.5872  Val_Acc: 74.188

Epoch 99: Validation loss did not decrease
	 Train_Loss: 0.5278 Train_Acc: 78.644 Val_Loss: 0.5875  BEST VAL Loss: 0.5872  Val_Acc: 74.640

LPS_1.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.96      0.74      0.84      9434
           1       0.80      0.97      0.88     10027

    accuracy                           0.86     19461
   macro avg       0.88      0.86      0.86     19461
weighted avg       0.88      0.86      0.86     19461

LPS_1.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.81      0.60      0.69      1179
           1       0.70      0.86      0.77      1254

    accuracy                           0.74      2433
   macro avg       0.75      0.73      0.73      2433
weighted avg       0.75      0.74      0.73      2433

LPS_1.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.78      0.60      0.68      1179
           1       0.69      0.85      0.76      1254

    accuracy                           0.73      2433
   macro avg       0.74      0.72      0.72      2433
weighted avg       0.74      0.73      0.72      2433

              precision    recall  f1-score   support

           0       0.78      0.60      0.68      1179
           1       0.69      0.85      0.76      1254

    accuracy                           0.73      2433
   macro avg       0.74      0.72      0.72      2433
weighted avg       0.74      0.73      0.72      2433

LPS_1.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_1.000_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.56      0.36      0.44      4017
           1       0.52      0.71      0.60      3923

    accuracy                           0.53      7940
   macro avg       0.54      0.54      0.52      7940
weighted avg       0.54      0.53      0.52      7940

              precision    recall  f1-score   support

           0       0.56      0.36      0.44      4017
           1       0.52      0.71      0.60      3923

    accuracy                           0.53      7940
   macro avg       0.54      0.54      0.52      7940
weighted avg       0.54      0.53      0.52      7940

completed
