[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '472609e6'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '919cafab'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '0c6addab'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'de6516b8'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: Flagellin_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_Nigericin_1.000_3.0_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (29461, 1276)
Number of total missing values across all columns: 31618
Data Subset Is Off
Wells held out for testing: ['L16' 'M22']
Wells to use for training, validation, and testing ['L17' 'M18' 'M19' 'L20' 'L21' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.389932).  Saving model ...
	 Train_Loss: 0.5275 Train_Acc: 74.515 Val_Loss: 0.3899  BEST VAL Loss: 0.3899  Val_Acc: 86.096

Epoch 1: Validation loss decreased (0.389932 --> 0.350972).  Saving model ...
	 Train_Loss: 0.4536 Train_Acc: 85.251 Val_Loss: 0.3510  BEST VAL Loss: 0.3510  Val_Acc: 89.963

Epoch 2: Validation loss decreased (0.350972 --> 0.322987).  Saving model ...
	 Train_Loss: 0.4072 Train_Acc: 88.176 Val_Loss: 0.3230  BEST VAL Loss: 0.3230  Val_Acc: 91.390

Epoch 3: Validation loss decreased (0.322987 --> 0.301002).  Saving model ...
	 Train_Loss: 0.3749 Train_Acc: 89.862 Val_Loss: 0.3010  BEST VAL Loss: 0.3010  Val_Acc: 92.634

Epoch 4: Validation loss decreased (0.301002 --> 0.283258).  Saving model ...
	 Train_Loss: 0.3508 Train_Acc: 90.582 Val_Loss: 0.2833  BEST VAL Loss: 0.2833  Val_Acc: 93.002

Epoch 5: Validation loss decreased (0.283258 --> 0.268570).  Saving model ...
	 Train_Loss: 0.3310 Train_Acc: 91.601 Val_Loss: 0.2686  BEST VAL Loss: 0.2686  Val_Acc: 93.646

Epoch 6: Validation loss decreased (0.268570 --> 0.256119).  Saving model ...
	 Train_Loss: 0.3144 Train_Acc: 92.159 Val_Loss: 0.2561  BEST VAL Loss: 0.2561  Val_Acc: 93.831

Epoch 7: Validation loss decreased (0.256119 --> 0.244844).  Saving model ...
	 Train_Loss: 0.2998 Train_Acc: 92.960 Val_Loss: 0.2448  BEST VAL Loss: 0.2448  Val_Acc: 94.245

Epoch 8: Validation loss decreased (0.244844 --> 0.235310).  Saving model ...
	 Train_Loss: 0.2873 Train_Acc: 93.316 Val_Loss: 0.2353  BEST VAL Loss: 0.2353  Val_Acc: 94.567

Epoch 9: Validation loss decreased (0.235310 --> 0.226843).  Saving model ...
	 Train_Loss: 0.2762 Train_Acc: 93.777 Val_Loss: 0.2268  BEST VAL Loss: 0.2268  Val_Acc: 94.429

Epoch 10: Validation loss decreased (0.226843 --> 0.219159).  Saving model ...
	 Train_Loss: 0.2661 Train_Acc: 94.082 Val_Loss: 0.2192  BEST VAL Loss: 0.2192  Val_Acc: 95.120

Epoch 11: Validation loss decreased (0.219159 --> 0.212044).  Saving model ...
	 Train_Loss: 0.2575 Train_Acc: 94.312 Val_Loss: 0.2120  BEST VAL Loss: 0.2120  Val_Acc: 95.580

Epoch 12: Validation loss decreased (0.212044 --> 0.205437).  Saving model ...
	 Train_Loss: 0.2494 Train_Acc: 94.721 Val_Loss: 0.2054  BEST VAL Loss: 0.2054  Val_Acc: 95.442

Epoch 13: Validation loss decreased (0.205437 --> 0.199552).  Saving model ...
	 Train_Loss: 0.2419 Train_Acc: 94.917 Val_Loss: 0.1996  BEST VAL Loss: 0.1996  Val_Acc: 95.488

Epoch 14: Validation loss decreased (0.199552 --> 0.194027).  Saving model ...
	 Train_Loss: 0.2351 Train_Acc: 95.090 Val_Loss: 0.1940  BEST VAL Loss: 0.1940  Val_Acc: 95.626

Epoch 15: Validation loss decreased (0.194027 --> 0.188772).  Saving model ...
	 Train_Loss: 0.2287 Train_Acc: 95.458 Val_Loss: 0.1888  BEST VAL Loss: 0.1888  Val_Acc: 96.087

Epoch 16: Validation loss decreased (0.188772 --> 0.184060).  Saving model ...
	 Train_Loss: 0.2227 Train_Acc: 95.613 Val_Loss: 0.1841  BEST VAL Loss: 0.1841  Val_Acc: 96.041

Epoch 17: Validation loss decreased (0.184060 --> 0.179471).  Saving model ...
	 Train_Loss: 0.2173 Train_Acc: 95.682 Val_Loss: 0.1795  BEST VAL Loss: 0.1795  Val_Acc: 96.087

Epoch 18: Validation loss decreased (0.179471 --> 0.175256).  Saving model ...
	 Train_Loss: 0.2121 Train_Acc: 95.890 Val_Loss: 0.1753  BEST VAL Loss: 0.1753  Val_Acc: 96.179

Epoch 19: Validation loss decreased (0.175256 --> 0.171403).  Saving model ...
	 Train_Loss: 0.2073 Train_Acc: 96.160 Val_Loss: 0.1714  BEST VAL Loss: 0.1714  Val_Acc: 96.133

Epoch 20: Validation loss decreased (0.171403 --> 0.167630).  Saving model ...
	 Train_Loss: 0.2028 Train_Acc: 96.201 Val_Loss: 0.1676  BEST VAL Loss: 0.1676  Val_Acc: 96.639

Epoch 21: Validation loss decreased (0.167630 --> 0.164145).  Saving model ...
	 Train_Loss: 0.1984 Train_Acc: 96.368 Val_Loss: 0.1641  BEST VAL Loss: 0.1641  Val_Acc: 96.501

Epoch 22: Validation loss decreased (0.164145 --> 0.160849).  Saving model ...
	 Train_Loss: 0.1943 Train_Acc: 96.604 Val_Loss: 0.1608  BEST VAL Loss: 0.1608  Val_Acc: 96.639

Epoch 23: Validation loss decreased (0.160849 --> 0.157708).  Saving model ...
	 Train_Loss: 0.1906 Train_Acc: 96.696 Val_Loss: 0.1577  BEST VAL Loss: 0.1577  Val_Acc: 96.547

Epoch 24: Validation loss decreased (0.157708 --> 0.154739).  Saving model ...
	 Train_Loss: 0.1868 Train_Acc: 96.880 Val_Loss: 0.1547  BEST VAL Loss: 0.1547  Val_Acc: 96.777

Epoch 25: Validation loss decreased (0.154739 --> 0.152034).  Saving model ...
	 Train_Loss: 0.1835 Train_Acc: 96.886 Val_Loss: 0.1520  BEST VAL Loss: 0.1520  Val_Acc: 96.869

Epoch 26: Validation loss decreased (0.152034 --> 0.149479).  Saving model ...
	 Train_Loss: 0.1802 Train_Acc: 96.932 Val_Loss: 0.1495  BEST VAL Loss: 0.1495  Val_Acc: 96.777

Epoch 27: Validation loss decreased (0.149479 --> 0.147038).  Saving model ...
	 Train_Loss: 0.1770 Train_Acc: 97.122 Val_Loss: 0.1470  BEST VAL Loss: 0.1470  Val_Acc: 96.685

Epoch 28: Validation loss decreased (0.147038 --> 0.144695).  Saving model ...
	 Train_Loss: 0.1739 Train_Acc: 97.260 Val_Loss: 0.1447  BEST VAL Loss: 0.1447  Val_Acc: 96.961

Epoch 29: Validation loss decreased (0.144695 --> 0.142509).  Saving model ...
	 Train_Loss: 0.1710 Train_Acc: 97.225 Val_Loss: 0.1425  BEST VAL Loss: 0.1425  Val_Acc: 96.823

Epoch 30: Validation loss decreased (0.142509 --> 0.140454).  Saving model ...
	 Train_Loss: 0.1683 Train_Acc: 97.139 Val_Loss: 0.1405  BEST VAL Loss: 0.1405  Val_Acc: 96.869

Epoch 31: Validation loss decreased (0.140454 --> 0.138455).  Saving model ...
	 Train_Loss: 0.1656 Train_Acc: 97.243 Val_Loss: 0.1385  BEST VAL Loss: 0.1385  Val_Acc: 96.777

Epoch 32: Validation loss decreased (0.138455 --> 0.136577).  Saving model ...
	 Train_Loss: 0.1630 Train_Acc: 97.409 Val_Loss: 0.1366  BEST VAL Loss: 0.1366  Val_Acc: 96.915

Epoch 33: Validation loss decreased (0.136577 --> 0.134831).  Saving model ...
	 Train_Loss: 0.1606 Train_Acc: 97.530 Val_Loss: 0.1348  BEST VAL Loss: 0.1348  Val_Acc: 96.915

Epoch 34: Validation loss decreased (0.134831 --> 0.133140).  Saving model ...
	 Train_Loss: 0.1583 Train_Acc: 97.398 Val_Loss: 0.1331  BEST VAL Loss: 0.1331  Val_Acc: 96.915

Epoch 35: Validation loss decreased (0.133140 --> 0.131638).  Saving model ...
	 Train_Loss: 0.1560 Train_Acc: 97.513 Val_Loss: 0.1316  BEST VAL Loss: 0.1316  Val_Acc: 96.639

Epoch 36: Validation loss decreased (0.131638 --> 0.130119).  Saving model ...
	 Train_Loss: 0.1538 Train_Acc: 97.789 Val_Loss: 0.1301  BEST VAL Loss: 0.1301  Val_Acc: 96.915

Epoch 37: Validation loss decreased (0.130119 --> 0.128607).  Saving model ...
	 Train_Loss: 0.1517 Train_Acc: 97.749 Val_Loss: 0.1286  BEST VAL Loss: 0.1286  Val_Acc: 97.053

Epoch 38: Validation loss decreased (0.128607 --> 0.127214).  Saving model ...
	 Train_Loss: 0.1497 Train_Acc: 97.726 Val_Loss: 0.1272  BEST VAL Loss: 0.1272  Val_Acc: 96.915

Epoch 39: Validation loss decreased (0.127214 --> 0.125818).  Saving model ...
	 Train_Loss: 0.1477 Train_Acc: 97.784 Val_Loss: 0.1258  BEST VAL Loss: 0.1258  Val_Acc: 97.053

Epoch 40: Validation loss decreased (0.125818 --> 0.124462).  Saving model ...
	 Train_Loss: 0.1458 Train_Acc: 97.732 Val_Loss: 0.1245  BEST VAL Loss: 0.1245  Val_Acc: 97.192

Epoch 41: Validation loss decreased (0.124462 --> 0.123134).  Saving model ...
	 Train_Loss: 0.1440 Train_Acc: 97.818 Val_Loss: 0.1231  BEST VAL Loss: 0.1231  Val_Acc: 97.099

Epoch 42: Validation loss decreased (0.123134 --> 0.121843).  Saving model ...
	 Train_Loss: 0.1422 Train_Acc: 97.905 Val_Loss: 0.1218  BEST VAL Loss: 0.1218  Val_Acc: 97.053

Epoch 43: Validation loss decreased (0.121843 --> 0.120686).  Saving model ...
	 Train_Loss: 0.1405 Train_Acc: 97.979 Val_Loss: 0.1207  BEST VAL Loss: 0.1207  Val_Acc: 97.192

Epoch 44: Validation loss decreased (0.120686 --> 0.119598).  Saving model ...
	 Train_Loss: 0.1388 Train_Acc: 97.945 Val_Loss: 0.1196  BEST VAL Loss: 0.1196  Val_Acc: 97.053

Epoch 45: Validation loss decreased (0.119598 --> 0.118564).  Saving model ...
	 Train_Loss: 0.1372 Train_Acc: 98.077 Val_Loss: 0.1186  BEST VAL Loss: 0.1186  Val_Acc: 97.007

Epoch 46: Validation loss decreased (0.118564 --> 0.117476).  Saving model ...
	 Train_Loss: 0.1356 Train_Acc: 98.008 Val_Loss: 0.1175  BEST VAL Loss: 0.1175  Val_Acc: 97.192

Epoch 47: Validation loss decreased (0.117476 --> 0.116524).  Saving model ...
	 Train_Loss: 0.1341 Train_Acc: 98.112 Val_Loss: 0.1165  BEST VAL Loss: 0.1165  Val_Acc: 97.145

Epoch 48: Validation loss decreased (0.116524 --> 0.115536).  Saving model ...
	 Train_Loss: 0.1326 Train_Acc: 98.187 Val_Loss: 0.1155  BEST VAL Loss: 0.1155  Val_Acc: 97.284

Epoch 49: Validation loss decreased (0.115536 --> 0.114585).  Saving model ...
	 Train_Loss: 0.1312 Train_Acc: 98.002 Val_Loss: 0.1146  BEST VAL Loss: 0.1146  Val_Acc: 96.961

Epoch 50: Validation loss decreased (0.114585 --> 0.113669).  Saving model ...
	 Train_Loss: 0.1298 Train_Acc: 98.158 Val_Loss: 0.1137  BEST VAL Loss: 0.1137  Val_Acc: 97.053

Epoch 51: Validation loss decreased (0.113669 --> 0.112853).  Saving model ...
	 Train_Loss: 0.1284 Train_Acc: 98.118 Val_Loss: 0.1129  BEST VAL Loss: 0.1129  Val_Acc: 97.053

Epoch 52: Validation loss decreased (0.112853 --> 0.112061).  Saving model ...
	 Train_Loss: 0.1271 Train_Acc: 98.187 Val_Loss: 0.1121  BEST VAL Loss: 0.1121  Val_Acc: 97.099

Epoch 53: Validation loss decreased (0.112061 --> 0.111240).  Saving model ...
	 Train_Loss: 0.1259 Train_Acc: 98.071 Val_Loss: 0.1112  BEST VAL Loss: 0.1112  Val_Acc: 97.192

Epoch 54: Validation loss decreased (0.111240 --> 0.110447).  Saving model ...
	 Train_Loss: 0.1246 Train_Acc: 98.054 Val_Loss: 0.1104  BEST VAL Loss: 0.1104  Val_Acc: 97.099

Epoch 55: Validation loss decreased (0.110447 --> 0.109668).  Saving model ...
	 Train_Loss: 0.1234 Train_Acc: 98.146 Val_Loss: 0.1097  BEST VAL Loss: 0.1097  Val_Acc: 97.376

Epoch 56: Validation loss decreased (0.109668 --> 0.108943).  Saving model ...
	 Train_Loss: 0.1222 Train_Acc: 98.428 Val_Loss: 0.1089  BEST VAL Loss: 0.1089  Val_Acc: 97.099

Epoch 57: Validation loss decreased (0.108943 --> 0.108332).  Saving model ...
	 Train_Loss: 0.1211 Train_Acc: 98.227 Val_Loss: 0.1083  BEST VAL Loss: 0.1083  Val_Acc: 97.192

Epoch 58: Validation loss decreased (0.108332 --> 0.107672).  Saving model ...
	 Train_Loss: 0.1199 Train_Acc: 98.532 Val_Loss: 0.1077  BEST VAL Loss: 0.1077  Val_Acc: 97.284

Epoch 59: Validation loss decreased (0.107672 --> 0.107005).  Saving model ...
	 Train_Loss: 0.1188 Train_Acc: 98.227 Val_Loss: 0.1070  BEST VAL Loss: 0.1070  Val_Acc: 97.376

Epoch 60: Validation loss decreased (0.107005 --> 0.106368).  Saving model ...
	 Train_Loss: 0.1177 Train_Acc: 98.342 Val_Loss: 0.1064  BEST VAL Loss: 0.1064  Val_Acc: 97.330

Epoch 61: Validation loss decreased (0.106368 --> 0.105783).  Saving model ...
	 Train_Loss: 0.1166 Train_Acc: 98.451 Val_Loss: 0.1058  BEST VAL Loss: 0.1058  Val_Acc: 97.330

Epoch 62: Validation loss decreased (0.105783 --> 0.105202).  Saving model ...
	 Train_Loss: 0.1156 Train_Acc: 98.457 Val_Loss: 0.1052  BEST VAL Loss: 0.1052  Val_Acc: 97.422

Epoch 63: Validation loss decreased (0.105202 --> 0.104704).  Saving model ...
	 Train_Loss: 0.1145 Train_Acc: 98.497 Val_Loss: 0.1047  BEST VAL Loss: 0.1047  Val_Acc: 97.468

Epoch 64: Validation loss decreased (0.104704 --> 0.104145).  Saving model ...
	 Train_Loss: 0.1136 Train_Acc: 98.365 Val_Loss: 0.1041  BEST VAL Loss: 0.1041  Val_Acc: 97.468

Epoch 65: Validation loss decreased (0.104145 --> 0.103693).  Saving model ...
	 Train_Loss: 0.1126 Train_Acc: 98.526 Val_Loss: 0.1037  BEST VAL Loss: 0.1037  Val_Acc: 97.238

Epoch 66: Validation loss decreased (0.103693 --> 0.103228).  Saving model ...
	 Train_Loss: 0.1117 Train_Acc: 98.607 Val_Loss: 0.1032  BEST VAL Loss: 0.1032  Val_Acc: 97.330

Epoch 67: Validation loss decreased (0.103228 --> 0.102771).  Saving model ...
	 Train_Loss: 0.1107 Train_Acc: 98.480 Val_Loss: 0.1028  BEST VAL Loss: 0.1028  Val_Acc: 97.422

Epoch 68: Validation loss decreased (0.102771 --> 0.102339).  Saving model ...
	 Train_Loss: 0.1098 Train_Acc: 98.440 Val_Loss: 0.1023  BEST VAL Loss: 0.1023  Val_Acc: 97.284

Epoch 69: Validation loss decreased (0.102339 --> 0.101939).  Saving model ...
	 Train_Loss: 0.1089 Train_Acc: 98.630 Val_Loss: 0.1019  BEST VAL Loss: 0.1019  Val_Acc: 97.376

Epoch 70: Validation loss decreased (0.101939 --> 0.101565).  Saving model ...
	 Train_Loss: 0.1080 Train_Acc: 98.670 Val_Loss: 0.1016  BEST VAL Loss: 0.1016  Val_Acc: 97.284

Epoch 71: Validation loss decreased (0.101565 --> 0.101200).  Saving model ...
	 Train_Loss: 0.1071 Train_Acc: 98.687 Val_Loss: 0.1012  BEST VAL Loss: 0.1012  Val_Acc: 97.376

Epoch 72: Validation loss decreased (0.101200 --> 0.100775).  Saving model ...
	 Train_Loss: 0.1063 Train_Acc: 98.561 Val_Loss: 0.1008  BEST VAL Loss: 0.1008  Val_Acc: 97.192

Epoch 73: Validation loss decreased (0.100775 --> 0.100402).  Saving model ...
	 Train_Loss: 0.1055 Train_Acc: 98.601 Val_Loss: 0.1004  BEST VAL Loss: 0.1004  Val_Acc: 97.468

Epoch 74: Validation loss decreased (0.100402 --> 0.100034).  Saving model ...
	 Train_Loss: 0.1046 Train_Acc: 98.791 Val_Loss: 0.1000  BEST VAL Loss: 0.1000  Val_Acc: 97.330

Epoch 75: Validation loss decreased (0.100034 --> 0.099677).  Saving model ...
	 Train_Loss: 0.1038 Train_Acc: 98.693 Val_Loss: 0.0997  BEST VAL Loss: 0.0997  Val_Acc: 97.238

Epoch 76: Validation loss decreased (0.099677 --> 0.099315).  Saving model ...
	 Train_Loss: 0.1030 Train_Acc: 98.739 Val_Loss: 0.0993  BEST VAL Loss: 0.0993  Val_Acc: 97.514

Epoch 77: Validation loss decreased (0.099315 --> 0.099027).  Saving model ...
	 Train_Loss: 0.1023 Train_Acc: 98.601 Val_Loss: 0.0990  BEST VAL Loss: 0.0990  Val_Acc: 97.468

Epoch 78: Validation loss decreased (0.099027 --> 0.098678).  Saving model ...
	 Train_Loss: 0.1015 Train_Acc: 98.607 Val_Loss: 0.0987  BEST VAL Loss: 0.0987  Val_Acc: 97.560

Epoch 79: Validation loss decreased (0.098678 --> 0.098418).  Saving model ...
	 Train_Loss: 0.1008 Train_Acc: 98.734 Val_Loss: 0.0984  BEST VAL Loss: 0.0984  Val_Acc: 97.606

Epoch 80: Validation loss decreased (0.098418 --> 0.098050).  Saving model ...
	 Train_Loss: 0.1000 Train_Acc: 98.705 Val_Loss: 0.0981  BEST VAL Loss: 0.0981  Val_Acc: 97.422

Epoch 81: Validation loss decreased (0.098050 --> 0.097771).  Saving model ...
	 Train_Loss: 0.0993 Train_Acc: 98.883 Val_Loss: 0.0978  BEST VAL Loss: 0.0978  Val_Acc: 97.376

Epoch 82: Validation loss decreased (0.097771 --> 0.097479).  Saving model ...
	 Train_Loss: 0.0986 Train_Acc: 98.774 Val_Loss: 0.0975  BEST VAL Loss: 0.0975  Val_Acc: 97.376

Epoch 83: Validation loss decreased (0.097479 --> 0.097222).  Saving model ...
	 Train_Loss: 0.0979 Train_Acc: 98.757 Val_Loss: 0.0972  BEST VAL Loss: 0.0972  Val_Acc: 97.145

Epoch 84: Validation loss decreased (0.097222 --> 0.096955).  Saving model ...
	 Train_Loss: 0.0972 Train_Acc: 98.831 Val_Loss: 0.0970  BEST VAL Loss: 0.0970  Val_Acc: 97.468

Epoch 85: Validation loss decreased (0.096955 --> 0.096686).  Saving model ...
	 Train_Loss: 0.0966 Train_Acc: 98.636 Val_Loss: 0.0967  BEST VAL Loss: 0.0967  Val_Acc: 97.376

Epoch 86: Validation loss decreased (0.096686 --> 0.096482).  Saving model ...
	 Train_Loss: 0.0959 Train_Acc: 98.929 Val_Loss: 0.0965  BEST VAL Loss: 0.0965  Val_Acc: 97.238

Epoch 87: Validation loss decreased (0.096482 --> 0.096274).  Saving model ...
	 Train_Loss: 0.0952 Train_Acc: 98.636 Val_Loss: 0.0963  BEST VAL Loss: 0.0963  Val_Acc: 97.330

Epoch 88: Validation loss decreased (0.096274 --> 0.096039).  Saving model ...
	 Train_Loss: 0.0946 Train_Acc: 98.906 Val_Loss: 0.0960  BEST VAL Loss: 0.0960  Val_Acc: 97.376

Epoch 89: Validation loss decreased (0.096039 --> 0.095809).  Saving model ...
	 Train_Loss: 0.0940 Train_Acc: 98.958 Val_Loss: 0.0958  BEST VAL Loss: 0.0958  Val_Acc: 97.053

Epoch 90: Validation loss decreased (0.095809 --> 0.095586).  Saving model ...
	 Train_Loss: 0.0933 Train_Acc: 98.975 Val_Loss: 0.0956  BEST VAL Loss: 0.0956  Val_Acc: 97.053

Epoch 91: Validation loss decreased (0.095586 --> 0.095314).  Saving model ...
	 Train_Loss: 0.0927 Train_Acc: 98.854 Val_Loss: 0.0953  BEST VAL Loss: 0.0953  Val_Acc: 97.192

Epoch 92: Validation loss decreased (0.095314 --> 0.095063).  Saving model ...
	 Train_Loss: 0.0921 Train_Acc: 98.774 Val_Loss: 0.0951  BEST VAL Loss: 0.0951  Val_Acc: 97.192

Epoch 93: Validation loss decreased (0.095063 --> 0.094845).  Saving model ...
	 Train_Loss: 0.0916 Train_Acc: 98.768 Val_Loss: 0.0948  BEST VAL Loss: 0.0948  Val_Acc: 97.376

Epoch 94: Validation loss decreased (0.094845 --> 0.094639).  Saving model ...
	 Train_Loss: 0.0910 Train_Acc: 98.912 Val_Loss: 0.0946  BEST VAL Loss: 0.0946  Val_Acc: 97.238

Epoch 95: Validation loss decreased (0.094639 --> 0.094443).  Saving model ...
	 Train_Loss: 0.0904 Train_Acc: 98.975 Val_Loss: 0.0944  BEST VAL Loss: 0.0944  Val_Acc: 97.422

Epoch 96: Validation loss decreased (0.094443 --> 0.094202).  Saving model ...
	 Train_Loss: 0.0898 Train_Acc: 98.785 Val_Loss: 0.0942  BEST VAL Loss: 0.0942  Val_Acc: 97.376

Epoch 97: Validation loss decreased (0.094202 --> 0.093950).  Saving model ...
	 Train_Loss: 0.0893 Train_Acc: 98.906 Val_Loss: 0.0939  BEST VAL Loss: 0.0939  Val_Acc: 97.468

Epoch 98: Validation loss decreased (0.093950 --> 0.093724).  Saving model ...
	 Train_Loss: 0.0888 Train_Acc: 98.797 Val_Loss: 0.0937  BEST VAL Loss: 0.0937  Val_Acc: 97.376

Epoch 99: Validation loss decreased (0.093724 --> 0.093510).  Saving model ...
	 Train_Loss: 0.0882 Train_Acc: 98.877 Val_Loss: 0.0935  BEST VAL Loss: 0.0935  Val_Acc: 97.422

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      9433
           1       1.00      1.00      1.00      7938

    accuracy                           1.00     17371
   macro avg       1.00      1.00      1.00     17371
weighted avg       1.00      1.00      1.00     17371

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.98      0.98      1179
           1       0.98      0.97      0.97       993

    accuracy                           0.97      2172
   macro avg       0.97      0.97      0.97      2172
weighted avg       0.97      0.97      0.97      2172

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.97      0.97      1180
           1       0.96      0.96      0.96       992

    accuracy                           0.97      2172
   macro avg       0.97      0.97      0.97      2172
weighted avg       0.97      0.97      0.97      2172

              precision    recall  f1-score   support

           0       0.97      0.97      0.97      1180
           1       0.96      0.96      0.96       992

    accuracy                           0.97      2172
   macro avg       0.97      0.97      0.97      2172
weighted avg       0.97      0.97      0.97      2172

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.97      0.95      4017
           1       0.97      0.93      0.95      3729

    accuracy                           0.95      7746
   macro avg       0.95      0.95      0.95      7746
weighted avg       0.95      0.95      0.95      7746

              precision    recall  f1-score   support

           0       0.93      0.97      0.95      4017
           1       0.97      0.93      0.95      3729

    accuracy                           0.95      7746
   macro avg       0.95      0.95      0.95      7746
weighted avg       0.95      0.95      0.95      7746

completed
