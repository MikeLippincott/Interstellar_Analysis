[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '4b0e6987'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '54f0acd0'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b5ad8ebf'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '0ea7e06f'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Flagellin_0.100_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (238995, 1270)
Number of total missing values across all columns: 477990
Data Subset Is Off
Wells held out for testing: ['B09' 'L10']
Wells to use for training, validation, and testing ['B02' 'B03' 'B08' 'L05' 'L11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.525051).  Saving model ...
	 Train_Loss: 0.6094 Train_Acc: 67.318 Val_Loss: 0.5251  BEST VAL Loss: 0.5251  Val_Acc: 74.286

Epoch 1: Validation loss decreased (0.525051 --> 0.497715).  Saving model ...
	 Train_Loss: 0.5630 Train_Acc: 73.364 Val_Loss: 0.4977  BEST VAL Loss: 0.4977  Val_Acc: 77.137

Epoch 2: Validation loss decreased (0.497715 --> 0.481763).  Saving model ...
	 Train_Loss: 0.5385 Train_Acc: 75.441 Val_Loss: 0.4818  BEST VAL Loss: 0.4818  Val_Acc: 78.356

Epoch 3: Validation loss decreased (0.481763 --> 0.470708).  Saving model ...
	 Train_Loss: 0.5232 Train_Acc: 76.306 Val_Loss: 0.4707  BEST VAL Loss: 0.4707  Val_Acc: 79.246

Epoch 4: Validation loss decreased (0.470708 --> 0.462643).  Saving model ...
	 Train_Loss: 0.5115 Train_Acc: 77.135 Val_Loss: 0.4626  BEST VAL Loss: 0.4626  Val_Acc: 79.582

Epoch 5: Validation loss decreased (0.462643 --> 0.456534).  Saving model ...
	 Train_Loss: 0.5030 Train_Acc: 77.372 Val_Loss: 0.4565  BEST VAL Loss: 0.4565  Val_Acc: 80.018

Epoch 6: Validation loss decreased (0.456534 --> 0.451062).  Saving model ...
	 Train_Loss: 0.4960 Train_Acc: 77.892 Val_Loss: 0.4511  BEST VAL Loss: 0.4511  Val_Acc: 80.318

Epoch 7: Validation loss decreased (0.451062 --> 0.446580).  Saving model ...
	 Train_Loss: 0.4899 Train_Acc: 78.183 Val_Loss: 0.4466  BEST VAL Loss: 0.4466  Val_Acc: 80.795

Epoch 8: Validation loss decreased (0.446580 --> 0.443002).  Saving model ...
	 Train_Loss: 0.4844 Train_Acc: 78.542 Val_Loss: 0.4430  BEST VAL Loss: 0.4430  Val_Acc: 80.200

Epoch 9: Validation loss decreased (0.443002 --> 0.438952).  Saving model ...
	 Train_Loss: 0.4797 Train_Acc: 78.778 Val_Loss: 0.4390  BEST VAL Loss: 0.4390  Val_Acc: 81.219

Epoch 10: Validation loss decreased (0.438952 --> 0.435413).  Saving model ...
	 Train_Loss: 0.4757 Train_Acc: 78.800 Val_Loss: 0.4354  BEST VAL Loss: 0.4354  Val_Acc: 80.878

Epoch 11: Validation loss decreased (0.435413 --> 0.432528).  Saving model ...
	 Train_Loss: 0.4722 Train_Acc: 78.866 Val_Loss: 0.4325  BEST VAL Loss: 0.4325  Val_Acc: 81.267

Epoch 12: Validation loss decreased (0.432528 --> 0.430103).  Saving model ...
	 Train_Loss: 0.4688 Train_Acc: 79.111 Val_Loss: 0.4301  BEST VAL Loss: 0.4301  Val_Acc: 81.290

Epoch 13: Validation loss decreased (0.430103 --> 0.427973).  Saving model ...
	 Train_Loss: 0.4658 Train_Acc: 79.189 Val_Loss: 0.4280  BEST VAL Loss: 0.4280  Val_Acc: 81.137

Epoch 14: Validation loss decreased (0.427973 --> 0.425916).  Saving model ...
	 Train_Loss: 0.4630 Train_Acc: 79.332 Val_Loss: 0.4259  BEST VAL Loss: 0.4259  Val_Acc: 81.113

Epoch 15: Validation loss decreased (0.425916 --> 0.423621).  Saving model ...
	 Train_Loss: 0.4605 Train_Acc: 79.513 Val_Loss: 0.4236  BEST VAL Loss: 0.4236  Val_Acc: 81.302

Epoch 16: Validation loss decreased (0.423621 --> 0.422014).  Saving model ...
	 Train_Loss: 0.4582 Train_Acc: 79.505 Val_Loss: 0.4220  BEST VAL Loss: 0.4220  Val_Acc: 81.166

Epoch 17: Validation loss decreased (0.422014 --> 0.420150).  Saving model ...
	 Train_Loss: 0.4561 Train_Acc: 79.549 Val_Loss: 0.4201  BEST VAL Loss: 0.4201  Val_Acc: 81.785

Epoch 18: Validation loss decreased (0.420150 --> 0.419035).  Saving model ...
	 Train_Loss: 0.4540 Train_Acc: 79.717 Val_Loss: 0.4190  BEST VAL Loss: 0.4190  Val_Acc: 81.278

Epoch 19: Validation loss decreased (0.419035 --> 0.417818).  Saving model ...
	 Train_Loss: 0.4521 Train_Acc: 79.808 Val_Loss: 0.4178  BEST VAL Loss: 0.4178  Val_Acc: 81.420

Epoch 20: Validation loss decreased (0.417818 --> 0.416445).  Saving model ...
	 Train_Loss: 0.4503 Train_Acc: 79.770 Val_Loss: 0.4164  BEST VAL Loss: 0.4164  Val_Acc: 81.879

Epoch 21: Validation loss decreased (0.416445 --> 0.415039).  Saving model ...
	 Train_Loss: 0.4486 Train_Acc: 79.767 Val_Loss: 0.4150  BEST VAL Loss: 0.4150  Val_Acc: 81.809

Epoch 22: Validation loss decreased (0.415039 --> 0.413673).  Saving model ...
	 Train_Loss: 0.4470 Train_Acc: 79.929 Val_Loss: 0.4137  BEST VAL Loss: 0.4137  Val_Acc: 81.985

Epoch 23: Validation loss decreased (0.413673 --> 0.412473).  Saving model ...
	 Train_Loss: 0.4454 Train_Acc: 80.023 Val_Loss: 0.4125  BEST VAL Loss: 0.4125  Val_Acc: 81.744

Epoch 24: Validation loss decreased (0.412473 --> 0.411408).  Saving model ...
	 Train_Loss: 0.4438 Train_Acc: 80.206 Val_Loss: 0.4114  BEST VAL Loss: 0.4114  Val_Acc: 81.956

Epoch 25: Validation loss decreased (0.411408 --> 0.410321).  Saving model ...
	 Train_Loss: 0.4424 Train_Acc: 80.280 Val_Loss: 0.4103  BEST VAL Loss: 0.4103  Val_Acc: 82.044

Epoch 26: Validation loss decreased (0.410321 --> 0.408994).  Saving model ...
	 Train_Loss: 0.4411 Train_Acc: 79.987 Val_Loss: 0.4090  BEST VAL Loss: 0.4090  Val_Acc: 82.309

Epoch 27: Validation loss decreased (0.408994 --> 0.408436).  Saving model ...
	 Train_Loss: 0.4398 Train_Acc: 80.162 Val_Loss: 0.4084  BEST VAL Loss: 0.4084  Val_Acc: 81.726

Epoch 28: Validation loss decreased (0.408436 --> 0.407457).  Saving model ...
	 Train_Loss: 0.4388 Train_Acc: 79.941 Val_Loss: 0.4075  BEST VAL Loss: 0.4075  Val_Acc: 82.262

Epoch 29: Validation loss decreased (0.407457 --> 0.406631).  Saving model ...
	 Train_Loss: 0.4375 Train_Acc: 80.268 Val_Loss: 0.4066  BEST VAL Loss: 0.4066  Val_Acc: 81.862

Epoch 30: Validation loss decreased (0.406631 --> 0.405832).  Saving model ...
	 Train_Loss: 0.4364 Train_Acc: 80.184 Val_Loss: 0.4058  BEST VAL Loss: 0.4058  Val_Acc: 82.180

Epoch 31: Validation loss decreased (0.405832 --> 0.405511).  Saving model ...
	 Train_Loss: 0.4354 Train_Acc: 80.238 Val_Loss: 0.4055  BEST VAL Loss: 0.4055  Val_Acc: 81.903

Epoch 32: Validation loss decreased (0.405511 --> 0.404626).  Saving model ...
	 Train_Loss: 0.4344 Train_Acc: 80.201 Val_Loss: 0.4046  BEST VAL Loss: 0.4046  Val_Acc: 82.121

Epoch 33: Validation loss decreased (0.404626 --> 0.404252).  Saving model ...
	 Train_Loss: 0.4335 Train_Acc: 79.986 Val_Loss: 0.4043  BEST VAL Loss: 0.4043  Val_Acc: 82.068

Epoch 34: Validation loss decreased (0.404252 --> 0.403387).  Saving model ...
	 Train_Loss: 0.4326 Train_Acc: 80.341 Val_Loss: 0.4034  BEST VAL Loss: 0.4034  Val_Acc: 82.380

Epoch 35: Validation loss decreased (0.403387 --> 0.402690).  Saving model ...
	 Train_Loss: 0.4317 Train_Acc: 80.461 Val_Loss: 0.4027  BEST VAL Loss: 0.4027  Val_Acc: 82.180

Epoch 36: Validation loss decreased (0.402690 --> 0.402041).  Saving model ...
	 Train_Loss: 0.4308 Train_Acc: 80.428 Val_Loss: 0.4020  BEST VAL Loss: 0.4020  Val_Acc: 82.191

Epoch 37: Validation loss decreased (0.402041 --> 0.401365).  Saving model ...
	 Train_Loss: 0.4299 Train_Acc: 80.514 Val_Loss: 0.4014  BEST VAL Loss: 0.4014  Val_Acc: 82.333

Epoch 38: Validation loss decreased (0.401365 --> 0.400770).  Saving model ...
	 Train_Loss: 0.4291 Train_Acc: 80.338 Val_Loss: 0.4008  BEST VAL Loss: 0.4008  Val_Acc: 82.415

Epoch 39: Validation loss decreased (0.400770 --> 0.400075).  Saving model ...
	 Train_Loss: 0.4283 Train_Acc: 80.402 Val_Loss: 0.4001  BEST VAL Loss: 0.4001  Val_Acc: 82.339

Epoch 40: Validation loss decreased (0.400075 --> 0.399806).  Saving model ...
	 Train_Loss: 0.4276 Train_Acc: 80.408 Val_Loss: 0.3998  BEST VAL Loss: 0.3998  Val_Acc: 81.973

Epoch 41: Validation loss decreased (0.399806 --> 0.399291).  Saving model ...
	 Train_Loss: 0.4268 Train_Acc: 80.444 Val_Loss: 0.3993  BEST VAL Loss: 0.3993  Val_Acc: 82.097

Epoch 42: Validation loss decreased (0.399291 --> 0.398825).  Saving model ...
	 Train_Loss: 0.4261 Train_Acc: 80.526 Val_Loss: 0.3988  BEST VAL Loss: 0.3988  Val_Acc: 82.280

Epoch 43: Validation loss decreased (0.398825 --> 0.398521).  Saving model ...
	 Train_Loss: 0.4254 Train_Acc: 80.565 Val_Loss: 0.3985  BEST VAL Loss: 0.3985  Val_Acc: 82.197

Epoch 44: Validation loss decreased (0.398521 --> 0.398198).  Saving model ...
	 Train_Loss: 0.4247 Train_Acc: 80.532 Val_Loss: 0.3982  BEST VAL Loss: 0.3982  Val_Acc: 82.144

Epoch 45: Validation loss decreased (0.398198 --> 0.397846).  Saving model ...
	 Train_Loss: 0.4240 Train_Acc: 80.523 Val_Loss: 0.3978  BEST VAL Loss: 0.3978  Val_Acc: 82.415

Epoch 46: Validation loss decreased (0.397846 --> 0.397444).  Saving model ...
	 Train_Loss: 0.4234 Train_Acc: 80.772 Val_Loss: 0.3974  BEST VAL Loss: 0.3974  Val_Acc: 82.415

Epoch 47: Validation loss decreased (0.397444 --> 0.397140).  Saving model ...
	 Train_Loss: 0.4227 Train_Acc: 80.698 Val_Loss: 0.3971  BEST VAL Loss: 0.3971  Val_Acc: 82.392

Epoch 48: Validation loss decreased (0.397140 --> 0.396665).  Saving model ...
	 Train_Loss: 0.4221 Train_Acc: 80.538 Val_Loss: 0.3967  BEST VAL Loss: 0.3967  Val_Acc: 82.315

Epoch 49: Validation loss decreased (0.396665 --> 0.396207).  Saving model ...
	 Train_Loss: 0.4215 Train_Acc: 80.708 Val_Loss: 0.3962  BEST VAL Loss: 0.3962  Val_Acc: 82.834

Epoch 50: Validation loss decreased (0.396207 --> 0.395650).  Saving model ...
	 Train_Loss: 0.4209 Train_Acc: 80.732 Val_Loss: 0.3956  BEST VAL Loss: 0.3956  Val_Acc: 82.940

Epoch 51: Validation loss decreased (0.395650 --> 0.395252).  Saving model ...
	 Train_Loss: 0.4203 Train_Acc: 80.838 Val_Loss: 0.3953  BEST VAL Loss: 0.3953  Val_Acc: 82.692

Epoch 52: Validation loss decreased (0.395252 --> 0.394779).  Saving model ...
	 Train_Loss: 0.4197 Train_Acc: 80.852 Val_Loss: 0.3948  BEST VAL Loss: 0.3948  Val_Acc: 82.586

Epoch 53: Validation loss decreased (0.394779 --> 0.394347).  Saving model ...
	 Train_Loss: 0.4193 Train_Acc: 80.386 Val_Loss: 0.3943  BEST VAL Loss: 0.3943  Val_Acc: 82.675

Epoch 54: Validation loss decreased (0.394347 --> 0.393953).  Saving model ...
	 Train_Loss: 0.4187 Train_Acc: 80.680 Val_Loss: 0.3940  BEST VAL Loss: 0.3940  Val_Acc: 82.439

Epoch 55: Validation loss decreased (0.393953 --> 0.393582).  Saving model ...
	 Train_Loss: 0.4183 Train_Acc: 80.532 Val_Loss: 0.3936  BEST VAL Loss: 0.3936  Val_Acc: 82.409

Epoch 56: Validation loss decreased (0.393582 --> 0.393125).  Saving model ...
	 Train_Loss: 0.4177 Train_Acc: 80.914 Val_Loss: 0.3931  BEST VAL Loss: 0.3931  Val_Acc: 82.710

Epoch 57: Validation loss decreased (0.393125 --> 0.392902).  Saving model ...
	 Train_Loss: 0.4172 Train_Acc: 80.594 Val_Loss: 0.3929  BEST VAL Loss: 0.3929  Val_Acc: 82.586

Epoch 58: Validation loss decreased (0.392902 --> 0.392699).  Saving model ...
	 Train_Loss: 0.4168 Train_Acc: 80.531 Val_Loss: 0.3927  BEST VAL Loss: 0.3927  Val_Acc: 82.887

Epoch 59: Validation loss decreased (0.392699 --> 0.392370).  Saving model ...
	 Train_Loss: 0.4164 Train_Acc: 80.519 Val_Loss: 0.3924  BEST VAL Loss: 0.3924  Val_Acc: 82.651

Epoch 60: Validation loss decreased (0.392370 --> 0.392022).  Saving model ...
	 Train_Loss: 0.4160 Train_Acc: 80.610 Val_Loss: 0.3920  BEST VAL Loss: 0.3920  Val_Acc: 82.327

Epoch 61: Validation loss decreased (0.392022 --> 0.391637).  Saving model ...
	 Train_Loss: 0.4155 Train_Acc: 80.603 Val_Loss: 0.3916  BEST VAL Loss: 0.3916  Val_Acc: 82.722

Epoch 62: Validation loss decreased (0.391637 --> 0.391246).  Saving model ...
	 Train_Loss: 0.4151 Train_Acc: 80.733 Val_Loss: 0.3912  BEST VAL Loss: 0.3912  Val_Acc: 83.093

Epoch 63: Validation loss decreased (0.391246 --> 0.391067).  Saving model ...
	 Train_Loss: 0.4146 Train_Acc: 80.830 Val_Loss: 0.3911  BEST VAL Loss: 0.3911  Val_Acc: 82.551

Epoch 64: Validation loss decreased (0.391067 --> 0.390764).  Saving model ...
	 Train_Loss: 0.4142 Train_Acc: 80.820 Val_Loss: 0.3908  BEST VAL Loss: 0.3908  Val_Acc: 82.999

Epoch 65: Validation loss decreased (0.390764 --> 0.390468).  Saving model ...
	 Train_Loss: 0.4138 Train_Acc: 80.670 Val_Loss: 0.3905  BEST VAL Loss: 0.3905  Val_Acc: 82.975

Epoch 66: Validation loss decreased (0.390468 --> 0.390204).  Saving model ...
	 Train_Loss: 0.4134 Train_Acc: 80.648 Val_Loss: 0.3902  BEST VAL Loss: 0.3902  Val_Acc: 82.415

Epoch 67: Validation loss decreased (0.390204 --> 0.389917).  Saving model ...
	 Train_Loss: 0.4130 Train_Acc: 80.925 Val_Loss: 0.3899  BEST VAL Loss: 0.3899  Val_Acc: 82.946

Epoch 68: Validation loss decreased (0.389917 --> 0.389631).  Saving model ...
	 Train_Loss: 0.4126 Train_Acc: 80.789 Val_Loss: 0.3896  BEST VAL Loss: 0.3896  Val_Acc: 82.798

Epoch 69: Validation loss decreased (0.389631 --> 0.389328).  Saving model ...
	 Train_Loss: 0.4123 Train_Acc: 80.710 Val_Loss: 0.3893  BEST VAL Loss: 0.3893  Val_Acc: 82.663

Epoch 70: Validation loss decreased (0.389328 --> 0.389132).  Saving model ...
	 Train_Loss: 0.4119 Train_Acc: 80.637 Val_Loss: 0.3891  BEST VAL Loss: 0.3891  Val_Acc: 82.704

Epoch 71: Validation loss decreased (0.389132 --> 0.388841).  Saving model ...
	 Train_Loss: 0.4115 Train_Acc: 80.666 Val_Loss: 0.3888  BEST VAL Loss: 0.3888  Val_Acc: 82.934

Epoch 72: Validation loss decreased (0.388841 --> 0.388618).  Saving model ...
	 Train_Loss: 0.4112 Train_Acc: 80.812 Val_Loss: 0.3886  BEST VAL Loss: 0.3886  Val_Acc: 82.669

Epoch 73: Validation loss decreased (0.388618 --> 0.388473).  Saving model ...
	 Train_Loss: 0.4108 Train_Acc: 80.910 Val_Loss: 0.3885  BEST VAL Loss: 0.3885  Val_Acc: 82.698

Epoch 74: Validation loss decreased (0.388473 --> 0.388183).  Saving model ...
	 Train_Loss: 0.4104 Train_Acc: 80.802 Val_Loss: 0.3882  BEST VAL Loss: 0.3882  Val_Acc: 82.810

Epoch 75: Validation loss decreased (0.388183 --> 0.387948).  Saving model ...
	 Train_Loss: 0.4101 Train_Acc: 80.891 Val_Loss: 0.3879  BEST VAL Loss: 0.3879  Val_Acc: 82.993

Epoch 76: Validation loss decreased (0.387948 --> 0.387787).  Saving model ...
	 Train_Loss: 0.4097 Train_Acc: 81.018 Val_Loss: 0.3878  BEST VAL Loss: 0.3878  Val_Acc: 82.875

Epoch 77: Validation loss decreased (0.387787 --> 0.387516).  Saving model ...
	 Train_Loss: 0.4094 Train_Acc: 80.827 Val_Loss: 0.3875  BEST VAL Loss: 0.3875  Val_Acc: 82.957

Epoch 78: Validation loss decreased (0.387516 --> 0.387262).  Saving model ...
	 Train_Loss: 0.4091 Train_Acc: 80.857 Val_Loss: 0.3873  BEST VAL Loss: 0.3873  Val_Acc: 82.663

Epoch 79: Validation loss decreased (0.387262 --> 0.387049).  Saving model ...
	 Train_Loss: 0.4088 Train_Acc: 80.896 Val_Loss: 0.3870  BEST VAL Loss: 0.3870  Val_Acc: 82.839

Epoch 80: Validation loss decreased (0.387049 --> 0.386942).  Saving model ...
	 Train_Loss: 0.4084 Train_Acc: 81.033 Val_Loss: 0.3869  BEST VAL Loss: 0.3869  Val_Acc: 82.515

Epoch 81: Validation loss decreased (0.386942 --> 0.386707).  Saving model ...
	 Train_Loss: 0.4081 Train_Acc: 81.126 Val_Loss: 0.3867  BEST VAL Loss: 0.3867  Val_Acc: 82.804

Epoch 82: Validation loss decreased (0.386707 --> 0.386524).  Saving model ...
	 Train_Loss: 0.4078 Train_Acc: 80.910 Val_Loss: 0.3865  BEST VAL Loss: 0.3865  Val_Acc: 82.969

Epoch 83: Validation loss decreased (0.386524 --> 0.386301).  Saving model ...
	 Train_Loss: 0.4075 Train_Acc: 80.916 Val_Loss: 0.3863  BEST VAL Loss: 0.3863  Val_Acc: 82.987

Epoch 84: Validation loss decreased (0.386301 --> 0.386130).  Saving model ...
	 Train_Loss: 0.4072 Train_Acc: 81.040 Val_Loss: 0.3861  BEST VAL Loss: 0.3861  Val_Acc: 82.781

Epoch 85: Validation loss decreased (0.386130 --> 0.385902).  Saving model ...
	 Train_Loss: 0.4069 Train_Acc: 81.059 Val_Loss: 0.3859  BEST VAL Loss: 0.3859  Val_Acc: 82.775

Epoch 86: Validation loss decreased (0.385902 --> 0.385813).  Saving model ...
	 Train_Loss: 0.4066 Train_Acc: 80.988 Val_Loss: 0.3858  BEST VAL Loss: 0.3858  Val_Acc: 82.851

Epoch 87: Validation loss decreased (0.385813 --> 0.385714).  Saving model ...
	 Train_Loss: 0.4063 Train_Acc: 81.006 Val_Loss: 0.3857  BEST VAL Loss: 0.3857  Val_Acc: 83.046

Epoch 88: Validation loss decreased (0.385714 --> 0.385611).  Saving model ...
	 Train_Loss: 0.4060 Train_Acc: 81.121 Val_Loss: 0.3856  BEST VAL Loss: 0.3856  Val_Acc: 82.669

Epoch 89: Validation loss decreased (0.385611 --> 0.385491).  Saving model ...
	 Train_Loss: 0.4057 Train_Acc: 81.061 Val_Loss: 0.3855  BEST VAL Loss: 0.3855  Val_Acc: 82.904

Epoch 90: Validation loss decreased (0.385491 --> 0.385322).  Saving model ...
	 Train_Loss: 0.4054 Train_Acc: 80.870 Val_Loss: 0.3853  BEST VAL Loss: 0.3853  Val_Acc: 82.733

Epoch 91: Validation loss decreased (0.385322 --> 0.385157).  Saving model ...
	 Train_Loss: 0.4052 Train_Acc: 80.849 Val_Loss: 0.3852  BEST VAL Loss: 0.3852  Val_Acc: 82.610

Epoch 92: Validation loss decreased (0.385157 --> 0.384979).  Saving model ...
	 Train_Loss: 0.4049 Train_Acc: 80.894 Val_Loss: 0.3850  BEST VAL Loss: 0.3850  Val_Acc: 83.040

Epoch 93: Validation loss decreased (0.384979 --> 0.384810).  Saving model ...
	 Train_Loss: 0.4047 Train_Acc: 80.911 Val_Loss: 0.3848  BEST VAL Loss: 0.3848  Val_Acc: 82.869

Epoch 94: Validation loss decreased (0.384810 --> 0.384655).  Saving model ...
	 Train_Loss: 0.4044 Train_Acc: 81.008 Val_Loss: 0.3847  BEST VAL Loss: 0.3847  Val_Acc: 82.898

Epoch 95: Validation loss decreased (0.384655 --> 0.384459).  Saving model ...
	 Train_Loss: 0.4042 Train_Acc: 80.841 Val_Loss: 0.3845  BEST VAL Loss: 0.3845  Val_Acc: 82.675

Epoch 96: Validation loss decreased (0.384459 --> 0.384313).  Saving model ...
	 Train_Loss: 0.4039 Train_Acc: 80.993 Val_Loss: 0.3843  BEST VAL Loss: 0.3843  Val_Acc: 83.099

Epoch 97: Validation loss decreased (0.384313 --> 0.384196).  Saving model ...
	 Train_Loss: 0.4036 Train_Acc: 81.053 Val_Loss: 0.3842  BEST VAL Loss: 0.3842  Val_Acc: 82.810

Epoch 98: Validation loss decreased (0.384196 --> 0.384138).  Saving model ...
	 Train_Loss: 0.4034 Train_Acc: 80.921 Val_Loss: 0.3841  BEST VAL Loss: 0.3841  Val_Acc: 82.845

Epoch 99: Validation loss decreased (0.384138 --> 0.384031).  Saving model ...
	 Train_Loss: 0.4032 Train_Acc: 80.760 Val_Loss: 0.3840  BEST VAL Loss: 0.3840  Val_Acc: 83.004

Flagellin_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.80      0.79      0.80     50422
           1       0.88      0.89      0.88     85370

    accuracy                           0.85    135792
   macro avg       0.84      0.84      0.84    135792
weighted avg       0.85      0.85      0.85    135792

Flagellin_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.78      0.75      0.77      6303
           1       0.86      0.88      0.87     10672

    accuracy                           0.83     16975
   macro avg       0.82      0.81      0.82     16975
weighted avg       0.83      0.83      0.83     16975

Flagellin_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.78      0.77      0.77      6303
           1       0.86      0.87      0.87     10672

    accuracy                           0.83     16975
   macro avg       0.82      0.82      0.82     16975
weighted avg       0.83      0.83      0.83     16975

              precision    recall  f1-score   support

           0       0.78      0.77      0.77      6303
           1       0.86      0.87      0.87     10672

    accuracy                           0.83     16975
   macro avg       0.82      0.82      0.82     16975
weighted avg       0.83      0.83      0.83     16975

Flagellin_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.57      0.69      0.63     32887
           1       0.66      0.54      0.59     36366

    accuracy                           0.61     69253
   macro avg       0.62      0.61      0.61     69253
weighted avg       0.62      0.61      0.61     69253

              precision    recall  f1-score   support

           0       0.57      0.69      0.63     32887
           1       0.66      0.54      0.59     36366

    accuracy                           0.61     69253
   macro avg       0.62      0.61      0.61     69253
weighted avg       0.62      0.61      0.61     69253

completed
