[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '6ce51353'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '6548896d'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'fe0622e5'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'c6d63ba8'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_1.000_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_1.000_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_1.000_DMSO_0.025']
The dimensions of the data are: (278030, 1270)
Number of total missing values across all columns: 556060
Data Subset Is Off
Wells held out for testing: ['C08' 'D08']
Wells to use for training, validation, and testing ['C02' 'C03' 'C09' 'D02' 'D03' 'D09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.673855).  Saving model ...
	 Train_Loss: 0.6843 Train_Acc: 54.937 Val_Loss: 0.6739  BEST VAL Loss: 0.6739  Val_Acc: 58.636

Epoch 1: Validation loss decreased (0.673855 --> 0.664709).  Saving model ...
	 Train_Loss: 0.6766 Train_Acc: 58.903 Val_Loss: 0.6647  BEST VAL Loss: 0.6647  Val_Acc: 61.786

Epoch 2: Validation loss decreased (0.664709 --> 0.656259).  Saving model ...
	 Train_Loss: 0.6691 Train_Acc: 60.768 Val_Loss: 0.6563  BEST VAL Loss: 0.6563  Val_Acc: 63.344

Epoch 3: Validation loss decreased (0.656259 --> 0.649545).  Saving model ...
	 Train_Loss: 0.6625 Train_Acc: 62.231 Val_Loss: 0.6495  BEST VAL Loss: 0.6495  Val_Acc: 64.037

Epoch 4: Validation loss decreased (0.649545 --> 0.643192).  Saving model ...
	 Train_Loss: 0.6567 Train_Acc: 63.077 Val_Loss: 0.6432  BEST VAL Loss: 0.6432  Val_Acc: 65.261

Epoch 5: Validation loss decreased (0.643192 --> 0.638241).  Saving model ...
	 Train_Loss: 0.6517 Train_Acc: 63.910 Val_Loss: 0.6382  BEST VAL Loss: 0.6382  Val_Acc: 65.271

Epoch 6: Validation loss decreased (0.638241 --> 0.633313).  Saving model ...
	 Train_Loss: 0.6471 Train_Acc: 64.581 Val_Loss: 0.6333  BEST VAL Loss: 0.6333  Val_Acc: 66.219

Epoch 7: Validation loss decreased (0.633313 --> 0.628404).  Saving model ...
	 Train_Loss: 0.6427 Train_Acc: 65.100 Val_Loss: 0.6284  BEST VAL Loss: 0.6284  Val_Acc: 67.330

Epoch 8: Validation loss decreased (0.628404 --> 0.623714).  Saving model ...
	 Train_Loss: 0.6385 Train_Acc: 65.672 Val_Loss: 0.6237  BEST VAL Loss: 0.6237  Val_Acc: 67.832

Epoch 9: Validation loss decreased (0.623714 --> 0.619337).  Saving model ...
	 Train_Loss: 0.6346 Train_Acc: 65.897 Val_Loss: 0.6193  BEST VAL Loss: 0.6193  Val_Acc: 68.298

Epoch 10: Validation loss decreased (0.619337 --> 0.615212).  Saving model ...
	 Train_Loss: 0.6310 Train_Acc: 66.278 Val_Loss: 0.6152  BEST VAL Loss: 0.6152  Val_Acc: 68.628

Epoch 11: Validation loss decreased (0.615212 --> 0.611226).  Saving model ...
	 Train_Loss: 0.6276 Train_Acc: 66.578 Val_Loss: 0.6112  BEST VAL Loss: 0.6112  Val_Acc: 68.952

Epoch 12: Validation loss decreased (0.611226 --> 0.607747).  Saving model ...
	 Train_Loss: 0.6243 Train_Acc: 66.884 Val_Loss: 0.6077  BEST VAL Loss: 0.6077  Val_Acc: 68.913

Epoch 13: Validation loss decreased (0.607747 --> 0.604731).  Saving model ...
	 Train_Loss: 0.6212 Train_Acc: 67.194 Val_Loss: 0.6047  BEST VAL Loss: 0.6047  Val_Acc: 69.311

Epoch 14: Validation loss decreased (0.604731 --> 0.601639).  Saving model ...
	 Train_Loss: 0.6184 Train_Acc: 67.501 Val_Loss: 0.6016  BEST VAL Loss: 0.6016  Val_Acc: 69.213

Epoch 15: Validation loss decreased (0.601639 --> 0.598478).  Saving model ...
	 Train_Loss: 0.6157 Train_Acc: 67.582 Val_Loss: 0.5985  BEST VAL Loss: 0.5985  Val_Acc: 69.852

Epoch 16: Validation loss decreased (0.598478 --> 0.595829).  Saving model ...
	 Train_Loss: 0.6132 Train_Acc: 67.975 Val_Loss: 0.5958  BEST VAL Loss: 0.5958  Val_Acc: 69.935

Epoch 17: Validation loss decreased (0.595829 --> 0.593578).  Saving model ...
	 Train_Loss: 0.6108 Train_Acc: 67.964 Val_Loss: 0.5936  BEST VAL Loss: 0.5936  Val_Acc: 69.847

Epoch 18: Validation loss decreased (0.593578 --> 0.590905).  Saving model ...
	 Train_Loss: 0.6086 Train_Acc: 68.183 Val_Loss: 0.5909  BEST VAL Loss: 0.5909  Val_Acc: 70.495

Epoch 19: Validation loss decreased (0.590905 --> 0.588354).  Saving model ...
	 Train_Loss: 0.6066 Train_Acc: 68.191 Val_Loss: 0.5884  BEST VAL Loss: 0.5884  Val_Acc: 71.012

Epoch 20: Validation loss decreased (0.588354 --> 0.586094).  Saving model ...
	 Train_Loss: 0.6046 Train_Acc: 68.370 Val_Loss: 0.5861  BEST VAL Loss: 0.5861  Val_Acc: 70.599

Epoch 21: Validation loss decreased (0.586094 --> 0.584275).  Saving model ...
	 Train_Loss: 0.6028 Train_Acc: 68.600 Val_Loss: 0.5843  BEST VAL Loss: 0.5843  Val_Acc: 70.358

Epoch 22: Validation loss decreased (0.584275 --> 0.582251).  Saving model ...
	 Train_Loss: 0.6010 Train_Acc: 68.617 Val_Loss: 0.5823  BEST VAL Loss: 0.5823  Val_Acc: 70.908

Epoch 23: Validation loss decreased (0.582251 --> 0.580430).  Saving model ...
	 Train_Loss: 0.5994 Train_Acc: 68.701 Val_Loss: 0.5804  BEST VAL Loss: 0.5804  Val_Acc: 70.771

Epoch 24: Validation loss decreased (0.580430 --> 0.578627).  Saving model ...
	 Train_Loss: 0.5978 Train_Acc: 68.879 Val_Loss: 0.5786  BEST VAL Loss: 0.5786  Val_Acc: 70.908

Epoch 25: Validation loss decreased (0.578627 --> 0.576858).  Saving model ...
	 Train_Loss: 0.5963 Train_Acc: 68.908 Val_Loss: 0.5769  BEST VAL Loss: 0.5769  Val_Acc: 71.601

Epoch 26: Validation loss decreased (0.576858 --> 0.575222).  Saving model ...
	 Train_Loss: 0.5948 Train_Acc: 69.073 Val_Loss: 0.5752  BEST VAL Loss: 0.5752  Val_Acc: 71.547

Epoch 27: Validation loss decreased (0.575222 --> 0.573606).  Saving model ...
	 Train_Loss: 0.5934 Train_Acc: 69.228 Val_Loss: 0.5736  BEST VAL Loss: 0.5736  Val_Acc: 71.267

Epoch 28: Validation loss decreased (0.573606 --> 0.572065).  Saving model ...
	 Train_Loss: 0.5920 Train_Acc: 69.455 Val_Loss: 0.5721  BEST VAL Loss: 0.5721  Val_Acc: 71.906

Epoch 29: Validation loss decreased (0.572065 --> 0.570758).  Saving model ...
	 Train_Loss: 0.5907 Train_Acc: 69.270 Val_Loss: 0.5708  BEST VAL Loss: 0.5708  Val_Acc: 71.365

Epoch 30: Validation loss decreased (0.570758 --> 0.569312).  Saving model ...
	 Train_Loss: 0.5894 Train_Acc: 69.446 Val_Loss: 0.5693  BEST VAL Loss: 0.5693  Val_Acc: 71.837

Epoch 31: Validation loss decreased (0.569312 --> 0.567912).  Saving model ...
	 Train_Loss: 0.5882 Train_Acc: 69.630 Val_Loss: 0.5679  BEST VAL Loss: 0.5679  Val_Acc: 71.837

Epoch 32: Validation loss decreased (0.567912 --> 0.566563).  Saving model ...
	 Train_Loss: 0.5871 Train_Acc: 69.415 Val_Loss: 0.5666  BEST VAL Loss: 0.5666  Val_Acc: 72.284

Epoch 33: Validation loss decreased (0.566563 --> 0.565380).  Saving model ...
	 Train_Loss: 0.5860 Train_Acc: 69.659 Val_Loss: 0.5654  BEST VAL Loss: 0.5654  Val_Acc: 71.827

Epoch 34: Validation loss decreased (0.565380 --> 0.564093).  Saving model ...
	 Train_Loss: 0.5849 Train_Acc: 69.780 Val_Loss: 0.5641  BEST VAL Loss: 0.5641  Val_Acc: 71.945

Epoch 35: Validation loss decreased (0.564093 --> 0.562945).  Saving model ...
	 Train_Loss: 0.5838 Train_Acc: 69.727 Val_Loss: 0.5629  BEST VAL Loss: 0.5629  Val_Acc: 72.422

Epoch 36: Validation loss decreased (0.562945 --> 0.561810).  Saving model ...
	 Train_Loss: 0.5828 Train_Acc: 69.839 Val_Loss: 0.5618  BEST VAL Loss: 0.5618  Val_Acc: 72.068

Epoch 37: Validation loss decreased (0.561810 --> 0.560778).  Saving model ...
	 Train_Loss: 0.5818 Train_Acc: 69.660 Val_Loss: 0.5608  BEST VAL Loss: 0.5608  Val_Acc: 71.498

Epoch 38: Validation loss decreased (0.560778 --> 0.559746).  Saving model ...
	 Train_Loss: 0.5809 Train_Acc: 69.811 Val_Loss: 0.5597  BEST VAL Loss: 0.5597  Val_Acc: 72.624

Epoch 39: Validation loss decreased (0.559746 --> 0.558871).  Saving model ...
	 Train_Loss: 0.5799 Train_Acc: 70.038 Val_Loss: 0.5589  BEST VAL Loss: 0.5589  Val_Acc: 72.019

Epoch 40: Validation loss decreased (0.558871 --> 0.557831).  Saving model ...
	 Train_Loss: 0.5791 Train_Acc: 69.901 Val_Loss: 0.5578  BEST VAL Loss: 0.5578  Val_Acc: 72.589

Epoch 41: Validation loss decreased (0.557831 --> 0.556878).  Saving model ...
	 Train_Loss: 0.5782 Train_Acc: 69.977 Val_Loss: 0.5569  BEST VAL Loss: 0.5569  Val_Acc: 72.339

Epoch 42: Validation loss decreased (0.556878 --> 0.555945).  Saving model ...
	 Train_Loss: 0.5774 Train_Acc: 69.917 Val_Loss: 0.5559  BEST VAL Loss: 0.5559  Val_Acc: 72.201

Epoch 43: Validation loss decreased (0.555945 --> 0.555041).  Saving model ...
	 Train_Loss: 0.5766 Train_Acc: 69.966 Val_Loss: 0.5550  BEST VAL Loss: 0.5550  Val_Acc: 72.540

Epoch 44: Validation loss decreased (0.555041 --> 0.554182).  Saving model ...
	 Train_Loss: 0.5758 Train_Acc: 70.043 Val_Loss: 0.5542  BEST VAL Loss: 0.5542  Val_Acc: 72.673

Epoch 45: Validation loss decreased (0.554182 --> 0.553426).  Saving model ...
	 Train_Loss: 0.5750 Train_Acc: 70.114 Val_Loss: 0.5534  BEST VAL Loss: 0.5534  Val_Acc: 71.990

Epoch 46: Validation loss decreased (0.553426 --> 0.552586).  Saving model ...
	 Train_Loss: 0.5743 Train_Acc: 70.061 Val_Loss: 0.5526  BEST VAL Loss: 0.5526  Val_Acc: 72.943

Epoch 47: Validation loss decreased (0.552586 --> 0.552017).  Saving model ...
	 Train_Loss: 0.5736 Train_Acc: 70.218 Val_Loss: 0.5520  BEST VAL Loss: 0.5520  Val_Acc: 72.378

Epoch 48: Validation loss decreased (0.552017 --> 0.551228).  Saving model ...
	 Train_Loss: 0.5729 Train_Acc: 70.182 Val_Loss: 0.5512  BEST VAL Loss: 0.5512  Val_Acc: 72.791

Epoch 49: Validation loss decreased (0.551228 --> 0.550487).  Saving model ...
	 Train_Loss: 0.5722 Train_Acc: 70.175 Val_Loss: 0.5505  BEST VAL Loss: 0.5505  Val_Acc: 72.820

Epoch 50: Validation loss decreased (0.550487 --> 0.549715).  Saving model ...
	 Train_Loss: 0.5715 Train_Acc: 70.282 Val_Loss: 0.5497  BEST VAL Loss: 0.5497  Val_Acc: 72.589

Epoch 51: Validation loss decreased (0.549715 --> 0.548937).  Saving model ...
	 Train_Loss: 0.5709 Train_Acc: 70.396 Val_Loss: 0.5489  BEST VAL Loss: 0.5489  Val_Acc: 73.140

Epoch 52: Validation loss decreased (0.548937 --> 0.548310).  Saving model ...
	 Train_Loss: 0.5702 Train_Acc: 70.350 Val_Loss: 0.5483  BEST VAL Loss: 0.5483  Val_Acc: 72.737

Epoch 53: Validation loss decreased (0.548310 --> 0.547583).  Saving model ...
	 Train_Loss: 0.5696 Train_Acc: 70.313 Val_Loss: 0.5476  BEST VAL Loss: 0.5476  Val_Acc: 72.845

Epoch 54: Validation loss decreased (0.547583 --> 0.546952).  Saving model ...
	 Train_Loss: 0.5690 Train_Acc: 70.517 Val_Loss: 0.5470  BEST VAL Loss: 0.5470  Val_Acc: 72.206

Epoch 55: Validation loss decreased (0.546952 --> 0.546344).  Saving model ...
	 Train_Loss: 0.5684 Train_Acc: 70.436 Val_Loss: 0.5463  BEST VAL Loss: 0.5463  Val_Acc: 72.501

Epoch 56: Validation loss decreased (0.546344 --> 0.545712).  Saving model ...
	 Train_Loss: 0.5678 Train_Acc: 70.476 Val_Loss: 0.5457  BEST VAL Loss: 0.5457  Val_Acc: 72.432

Epoch 57: Validation loss decreased (0.545712 --> 0.545078).  Saving model ...
	 Train_Loss: 0.5672 Train_Acc: 70.502 Val_Loss: 0.5451  BEST VAL Loss: 0.5451  Val_Acc: 72.992

Epoch 58: Validation loss decreased (0.545078 --> 0.544524).  Saving model ...
	 Train_Loss: 0.5667 Train_Acc: 70.483 Val_Loss: 0.5445  BEST VAL Loss: 0.5445  Val_Acc: 72.555

Epoch 59: Validation loss decreased (0.544524 --> 0.543901).  Saving model ...
	 Train_Loss: 0.5662 Train_Acc: 70.554 Val_Loss: 0.5439  BEST VAL Loss: 0.5439  Val_Acc: 72.948

Epoch 60: Validation loss decreased (0.543901 --> 0.543342).  Saving model ...
	 Train_Loss: 0.5656 Train_Acc: 70.513 Val_Loss: 0.5433  BEST VAL Loss: 0.5433  Val_Acc: 72.270

Epoch 61: Validation loss decreased (0.543342 --> 0.542786).  Saving model ...
	 Train_Loss: 0.5651 Train_Acc: 70.657 Val_Loss: 0.5428  BEST VAL Loss: 0.5428  Val_Acc: 73.292

Epoch 62: Validation loss decreased (0.542786 --> 0.542229).  Saving model ...
	 Train_Loss: 0.5646 Train_Acc: 70.572 Val_Loss: 0.5422  BEST VAL Loss: 0.5422  Val_Acc: 72.869

Epoch 63: Validation loss decreased (0.542229 --> 0.541741).  Saving model ...
	 Train_Loss: 0.5641 Train_Acc: 70.601 Val_Loss: 0.5417  BEST VAL Loss: 0.5417  Val_Acc: 73.169

Epoch 64: Validation loss decreased (0.541741 --> 0.541256).  Saving model ...
	 Train_Loss: 0.5636 Train_Acc: 70.690 Val_Loss: 0.5413  BEST VAL Loss: 0.5413  Val_Acc: 72.383

Epoch 65: Validation loss decreased (0.541256 --> 0.540755).  Saving model ...
	 Train_Loss: 0.5632 Train_Acc: 70.779 Val_Loss: 0.5408  BEST VAL Loss: 0.5408  Val_Acc: 73.051

Epoch 66: Validation loss decreased (0.540755 --> 0.540273).  Saving model ...
	 Train_Loss: 0.5627 Train_Acc: 70.707 Val_Loss: 0.5403  BEST VAL Loss: 0.5403  Val_Acc: 72.830

Epoch 67: Validation loss decreased (0.540273 --> 0.539777).  Saving model ...
	 Train_Loss: 0.5622 Train_Acc: 70.879 Val_Loss: 0.5398  BEST VAL Loss: 0.5398  Val_Acc: 72.938

Epoch 68: Validation loss decreased (0.539777 --> 0.539269).  Saving model ...
	 Train_Loss: 0.5618 Train_Acc: 70.651 Val_Loss: 0.5393  BEST VAL Loss: 0.5393  Val_Acc: 73.199

Epoch 69: Validation loss decreased (0.539269 --> 0.538775).  Saving model ...
	 Train_Loss: 0.5613 Train_Acc: 70.753 Val_Loss: 0.5388  BEST VAL Loss: 0.5388  Val_Acc: 73.071

Epoch 70: Validation loss decreased (0.538775 --> 0.538311).  Saving model ...
	 Train_Loss: 0.5609 Train_Acc: 70.618 Val_Loss: 0.5383  BEST VAL Loss: 0.5383  Val_Acc: 73.238

Epoch 71: Validation loss decreased (0.538311 --> 0.537938).  Saving model ...
	 Train_Loss: 0.5605 Train_Acc: 70.701 Val_Loss: 0.5379  BEST VAL Loss: 0.5379  Val_Acc: 72.928

Epoch 72: Validation loss decreased (0.537938 --> 0.537523).  Saving model ...
	 Train_Loss: 0.5601 Train_Acc: 70.897 Val_Loss: 0.5375  BEST VAL Loss: 0.5375  Val_Acc: 73.302

Epoch 73: Validation loss decreased (0.537523 --> 0.537101).  Saving model ...
	 Train_Loss: 0.5597 Train_Acc: 70.866 Val_Loss: 0.5371  BEST VAL Loss: 0.5371  Val_Acc: 73.381

Epoch 74: Validation loss decreased (0.537101 --> 0.536726).  Saving model ...
	 Train_Loss: 0.5593 Train_Acc: 70.755 Val_Loss: 0.5367  BEST VAL Loss: 0.5367  Val_Acc: 72.977

Epoch 75: Validation loss decreased (0.536726 --> 0.536285).  Saving model ...
	 Train_Loss: 0.5589 Train_Acc: 70.907 Val_Loss: 0.5363  BEST VAL Loss: 0.5363  Val_Acc: 73.282

Epoch 76: Validation loss decreased (0.536285 --> 0.535838).  Saving model ...
	 Train_Loss: 0.5585 Train_Acc: 71.006 Val_Loss: 0.5358  BEST VAL Loss: 0.5358  Val_Acc: 73.233

Epoch 77: Validation loss decreased (0.535838 --> 0.535440).  Saving model ...
	 Train_Loss: 0.5581 Train_Acc: 70.880 Val_Loss: 0.5354  BEST VAL Loss: 0.5354  Val_Acc: 73.258

Epoch 78: Validation loss decreased (0.535440 --> 0.535131).  Saving model ...
	 Train_Loss: 0.5578 Train_Acc: 70.948 Val_Loss: 0.5351  BEST VAL Loss: 0.5351  Val_Acc: 73.032

Epoch 79: Validation loss decreased (0.535131 --> 0.534722).  Saving model ...
	 Train_Loss: 0.5574 Train_Acc: 70.929 Val_Loss: 0.5347  BEST VAL Loss: 0.5347  Val_Acc: 73.646

Epoch 80: Validation loss decreased (0.534722 --> 0.534345).  Saving model ...
	 Train_Loss: 0.5571 Train_Acc: 70.959 Val_Loss: 0.5343  BEST VAL Loss: 0.5343  Val_Acc: 73.415

Epoch 81: Validation loss decreased (0.534345 --> 0.533961).  Saving model ...
	 Train_Loss: 0.5567 Train_Acc: 70.940 Val_Loss: 0.5340  BEST VAL Loss: 0.5340  Val_Acc: 73.223

Epoch 82: Validation loss decreased (0.533961 --> 0.533622).  Saving model ...
	 Train_Loss: 0.5564 Train_Acc: 71.073 Val_Loss: 0.5336  BEST VAL Loss: 0.5336  Val_Acc: 72.894

Epoch 83: Validation loss decreased (0.533622 --> 0.533246).  Saving model ...
	 Train_Loss: 0.5560 Train_Acc: 70.964 Val_Loss: 0.5332  BEST VAL Loss: 0.5332  Val_Acc: 73.503

Epoch 84: Validation loss decreased (0.533246 --> 0.532884).  Saving model ...
	 Train_Loss: 0.5557 Train_Acc: 71.187 Val_Loss: 0.5329  BEST VAL Loss: 0.5329  Val_Acc: 73.420

Epoch 85: Validation loss decreased (0.532884 --> 0.532516).  Saving model ...
	 Train_Loss: 0.5553 Train_Acc: 71.082 Val_Loss: 0.5325  BEST VAL Loss: 0.5325  Val_Acc: 73.331

Epoch 86: Validation loss decreased (0.532516 --> 0.532197).  Saving model ...
	 Train_Loss: 0.5550 Train_Acc: 71.003 Val_Loss: 0.5322  BEST VAL Loss: 0.5322  Val_Acc: 73.331

Epoch 87: Validation loss decreased (0.532197 --> 0.531857).  Saving model ...
	 Train_Loss: 0.5547 Train_Acc: 71.080 Val_Loss: 0.5319  BEST VAL Loss: 0.5319  Val_Acc: 73.646

Epoch 88: Validation loss decreased (0.531857 --> 0.531563).  Saving model ...
	 Train_Loss: 0.5544 Train_Acc: 71.041 Val_Loss: 0.5316  BEST VAL Loss: 0.5316  Val_Acc: 73.582

Epoch 89: Validation loss decreased (0.531563 --> 0.531237).  Saving model ...
	 Train_Loss: 0.5541 Train_Acc: 71.174 Val_Loss: 0.5312  BEST VAL Loss: 0.5312  Val_Acc: 73.208

Epoch 90: Validation loss decreased (0.531237 --> 0.530921).  Saving model ...
	 Train_Loss: 0.5538 Train_Acc: 71.078 Val_Loss: 0.5309  BEST VAL Loss: 0.5309  Val_Acc: 72.963

Epoch 91: Validation loss decreased (0.530921 --> 0.530601).  Saving model ...
	 Train_Loss: 0.5535 Train_Acc: 71.149 Val_Loss: 0.5306  BEST VAL Loss: 0.5306  Val_Acc: 73.400

Epoch 92: Validation loss decreased (0.530601 --> 0.530288).  Saving model ...
	 Train_Loss: 0.5532 Train_Acc: 71.162 Val_Loss: 0.5303  BEST VAL Loss: 0.5303  Val_Acc: 74.015

Epoch 93: Validation loss decreased (0.530288 --> 0.529969).  Saving model ...
	 Train_Loss: 0.5529 Train_Acc: 71.318 Val_Loss: 0.5300  BEST VAL Loss: 0.5300  Val_Acc: 73.675

Epoch 94: Validation loss decreased (0.529969 --> 0.529717).  Saving model ...
	 Train_Loss: 0.5526 Train_Acc: 71.216 Val_Loss: 0.5297  BEST VAL Loss: 0.5297  Val_Acc: 73.469

Epoch 95: Validation loss decreased (0.529717 --> 0.529404).  Saving model ...
	 Train_Loss: 0.5523 Train_Acc: 71.257 Val_Loss: 0.5294  BEST VAL Loss: 0.5294  Val_Acc: 73.464

Epoch 96: Validation loss decreased (0.529404 --> 0.529130).  Saving model ...
	 Train_Loss: 0.5520 Train_Acc: 71.032 Val_Loss: 0.5291  BEST VAL Loss: 0.5291  Val_Acc: 73.341

Epoch 97: Validation loss decreased (0.529130 --> 0.528827).  Saving model ...
	 Train_Loss: 0.5518 Train_Acc: 71.224 Val_Loss: 0.5288  BEST VAL Loss: 0.5288  Val_Acc: 73.518

Epoch 98: Validation loss decreased (0.528827 --> 0.528606).  Saving model ...
	 Train_Loss: 0.5515 Train_Acc: 71.239 Val_Loss: 0.5286  BEST VAL Loss: 0.5286  Val_Acc: 73.356

Epoch 99: Validation loss decreased (0.528606 --> 0.528356).  Saving model ...
	 Train_Loss: 0.5512 Train_Acc: 71.214 Val_Loss: 0.5284  BEST VAL Loss: 0.5284  Val_Acc: 73.828

LPS_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.42      0.46     82968
           1       0.49      0.58      0.53     79796

    accuracy                           0.50    162764
   macro avg       0.50      0.50      0.49    162764
weighted avg       0.50      0.50      0.49    162764

LPS_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.42      0.46     10371
           1       0.49      0.57      0.53      9975

    accuracy                           0.50     20346
   macro avg       0.50      0.50      0.49     20346
weighted avg       0.50      0.50      0.49     20346

LPS_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.42      0.46     10371
           1       0.49      0.58      0.53      9975

    accuracy                           0.50     20346
   macro avg       0.50      0.50      0.50     20346
weighted avg       0.50      0.50      0.50     20346

              precision    recall  f1-score   support

           0       0.51      0.42      0.46     10371
           1       0.49      0.58      0.53      9975

    accuracy                           0.50     20346
   macro avg       0.50      0.50      0.50     20346
weighted avg       0.50      0.50      0.50     20346

LPS_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.80      0.59     34887
           1       0.54      0.21      0.30     39687

    accuracy                           0.48     74574
   macro avg       0.50      0.50      0.44     74574
weighted avg       0.51      0.48      0.44     74574

              precision    recall  f1-score   support

           0       0.47      0.80      0.59     34887
           1       0.54      0.21      0.30     39687

    accuracy                           0.48     74574
   macro avg       0.50      0.50      0.44     74574
weighted avg       0.51      0.48      0.44     74574

completed
