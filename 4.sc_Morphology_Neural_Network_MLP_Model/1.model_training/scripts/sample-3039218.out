[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'fd294ee3'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e8c5a469'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '74a04f9b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'dd049535'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: H2O2_100.000_DMSO_0.025 treatment_name: Thapsigargin_10.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: Thapsigargin_10.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (40112, 1276)
Number of total missing values across all columns: 80224
Data Subset Is Off
Wells held out for testing: ['E14' 'H22']
Wells to use for training, validation, and testing ['E15' 'H18' 'H19' 'H23' 'L14' 'L15' 'I18' 'I19' 'I22' 'I23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.300378).  Saving model ...
	 Train_Loss: 0.4957 Train_Acc: 74.746 Val_Loss: 0.3004  BEST VAL Loss: 0.3004  Val_Acc: 88.967

Epoch 1: Validation loss decreased (0.300378 --> 0.270808).  Saving model ...
	 Train_Loss: 0.4059 Train_Acc: 85.160 Val_Loss: 0.2708  BEST VAL Loss: 0.2708  Val_Acc: 91.364

Epoch 2: Validation loss decreased (0.270808 --> 0.248092).  Saving model ...
	 Train_Loss: 0.3602 Train_Acc: 86.708 Val_Loss: 0.2481  BEST VAL Loss: 0.2481  Val_Acc: 92.471

Epoch 3: Validation loss decreased (0.248092 --> 0.236417).  Saving model ...
	 Train_Loss: 0.3350 Train_Acc: 87.754 Val_Loss: 0.2364  BEST VAL Loss: 0.2364  Val_Acc: 92.225

Epoch 4: Validation loss decreased (0.236417 --> 0.233560).  Saving model ...
	 Train_Loss: 0.3237 Train_Acc: 85.990 Val_Loss: 0.2336  BEST VAL Loss: 0.2336  Val_Acc: 91.395

Epoch 5: Validation loss decreased (0.233560 --> 0.230081).  Saving model ...
	 Train_Loss: 0.3121 Train_Acc: 86.585 Val_Loss: 0.2301  BEST VAL Loss: 0.2301  Val_Acc: 91.641

Epoch 6: Validation loss decreased (0.230081 --> 0.223878).  Saving model ...
	 Train_Loss: 0.2995 Train_Acc: 87.462 Val_Loss: 0.2239  BEST VAL Loss: 0.2239  Val_Acc: 92.747

Epoch 7: Validation loss decreased (0.223878 --> 0.218135).  Saving model ...
	 Train_Loss: 0.2869 Train_Acc: 88.660 Val_Loss: 0.2181  BEST VAL Loss: 0.2181  Val_Acc: 92.348

Epoch 8: Validation loss decreased (0.218135 --> 0.213492).  Saving model ...
	 Train_Loss: 0.2759 Train_Acc: 91.020 Val_Loss: 0.2135  BEST VAL Loss: 0.2135  Val_Acc: 93.085

Epoch 9: Validation loss decreased (0.213492 --> 0.209475).  Saving model ...
	 Train_Loss: 0.2672 Train_Acc: 90.989 Val_Loss: 0.2095  BEST VAL Loss: 0.2095  Val_Acc: 93.178

Epoch 10: Validation loss decreased (0.209475 --> 0.205130).  Saving model ...
	 Train_Loss: 0.2596 Train_Acc: 91.227 Val_Loss: 0.2051  BEST VAL Loss: 0.2051  Val_Acc: 93.608

Epoch 11: Validation loss decreased (0.205130 --> 0.201863).  Saving model ...
	 Train_Loss: 0.2520 Train_Acc: 92.157 Val_Loss: 0.2019  BEST VAL Loss: 0.2019  Val_Acc: 93.485

Epoch 12: Validation loss decreased (0.201863 --> 0.198576).  Saving model ...
	 Train_Loss: 0.2451 Train_Acc: 92.261 Val_Loss: 0.1986  BEST VAL Loss: 0.1986  Val_Acc: 93.946

Epoch 13: Validation loss decreased (0.198576 --> 0.195364).  Saving model ...
	 Train_Loss: 0.2390 Train_Acc: 92.657 Val_Loss: 0.1954  BEST VAL Loss: 0.1954  Val_Acc: 93.823

Epoch 14: Validation loss decreased (0.195364 --> 0.192908).  Saving model ...
	 Train_Loss: 0.2335 Train_Acc: 92.465 Val_Loss: 0.1929  BEST VAL Loss: 0.1929  Val_Acc: 93.485

Epoch 15: Validation loss decreased (0.192908 --> 0.190680).  Saving model ...
	 Train_Loss: 0.2286 Train_Acc: 92.972 Val_Loss: 0.1907  BEST VAL Loss: 0.1907  Val_Acc: 93.731

Epoch 16: Validation loss decreased (0.190680 --> 0.188235).  Saving model ...
	 Train_Loss: 0.2243 Train_Acc: 93.018 Val_Loss: 0.1882  BEST VAL Loss: 0.1882  Val_Acc: 93.731

Epoch 17: Validation loss decreased (0.188235 --> 0.187359).  Saving model ...
	 Train_Loss: 0.2212 Train_Acc: 91.416 Val_Loss: 0.1874  BEST VAL Loss: 0.1874  Val_Acc: 93.946

Epoch 18: Validation loss decreased (0.187359 --> 0.185458).  Saving model ...
	 Train_Loss: 0.2185 Train_Acc: 91.377 Val_Loss: 0.1855  BEST VAL Loss: 0.1855  Val_Acc: 94.192

Epoch 19: Validation loss decreased (0.185458 --> 0.183945).  Saving model ...
	 Train_Loss: 0.2163 Train_Acc: 91.562 Val_Loss: 0.1839  BEST VAL Loss: 0.1839  Val_Acc: 93.762

Epoch 20: Validation loss decreased (0.183945 --> 0.182245).  Saving model ...
	 Train_Loss: 0.2140 Train_Acc: 92.257 Val_Loss: 0.1822  BEST VAL Loss: 0.1822  Val_Acc: 94.222

Epoch 21: Validation loss decreased (0.182245 --> 0.180723).  Saving model ...
	 Train_Loss: 0.2122 Train_Acc: 91.081 Val_Loss: 0.1807  BEST VAL Loss: 0.1807  Val_Acc: 94.100

Epoch 22: Validation loss decreased (0.180723 --> 0.179248).  Saving model ...
	 Train_Loss: 0.2101 Train_Acc: 91.846 Val_Loss: 0.1792  BEST VAL Loss: 0.1792  Val_Acc: 94.530

Epoch 23: Validation loss decreased (0.179248 --> 0.177916).  Saving model ...
	 Train_Loss: 0.2080 Train_Acc: 92.088 Val_Loss: 0.1779  BEST VAL Loss: 0.1779  Val_Acc: 94.038

Epoch 24: Validation loss decreased (0.177916 --> 0.177000).  Saving model ...
	 Train_Loss: 0.2066 Train_Acc: 91.608 Val_Loss: 0.1770  BEST VAL Loss: 0.1770  Val_Acc: 93.977

Epoch 25: Validation loss decreased (0.177000 --> 0.175665).  Saving model ...
	 Train_Loss: 0.2047 Train_Acc: 91.938 Val_Loss: 0.1757  BEST VAL Loss: 0.1757  Val_Acc: 94.622

Epoch 26: Validation loss decreased (0.175665 --> 0.174981).  Saving model ...
	 Train_Loss: 0.2025 Train_Acc: 93.087 Val_Loss: 0.1750  BEST VAL Loss: 0.1750  Val_Acc: 94.499

Epoch 27: Validation loss decreased (0.174981 --> 0.174399).  Saving model ...
	 Train_Loss: 0.2003 Train_Acc: 93.287 Val_Loss: 0.1744  BEST VAL Loss: 0.1744  Val_Acc: 94.284

Epoch 28: Validation loss decreased (0.174399 --> 0.173992).  Saving model ...
	 Train_Loss: 0.1980 Train_Acc: 93.802 Val_Loss: 0.1740  BEST VAL Loss: 0.1740  Val_Acc: 94.345

Epoch 29: Validation loss decreased (0.173992 --> 0.173306).  Saving model ...
	 Train_Loss: 0.1957 Train_Acc: 94.178 Val_Loss: 0.1733  BEST VAL Loss: 0.1733  Val_Acc: 94.345

Epoch 30: Validation loss decreased (0.173306 --> 0.172650).  Saving model ...
	 Train_Loss: 0.1934 Train_Acc: 94.202 Val_Loss: 0.1726  BEST VAL Loss: 0.1726  Val_Acc: 94.468

Epoch 31: Validation loss decreased (0.172650 --> 0.172644).  Saving model ...
	 Train_Loss: 0.1917 Train_Acc: 93.675 Val_Loss: 0.1726  BEST VAL Loss: 0.1726  Val_Acc: 94.653

Epoch 32: Validation loss decreased (0.172644 --> 0.171903).  Saving model ...
	 Train_Loss: 0.1898 Train_Acc: 93.959 Val_Loss: 0.1719  BEST VAL Loss: 0.1719  Val_Acc: 94.499

Epoch 33: Validation loss did not decrease
	 Train_Loss: 0.1876 Train_Acc: 94.628 Val_Loss: 0.1719  BEST VAL Loss: 0.1719  Val_Acc: 95.052

Epoch 34: Validation loss decreased (0.171903 --> 0.171588).  Saving model ...
	 Train_Loss: 0.1860 Train_Acc: 94.021 Val_Loss: 0.1716  BEST VAL Loss: 0.1716  Val_Acc: 94.776

Epoch 35: Validation loss decreased (0.171588 --> 0.171347).  Saving model ...
	 Train_Loss: 0.1842 Train_Acc: 94.351 Val_Loss: 0.1713  BEST VAL Loss: 0.1713  Val_Acc: 94.315

Epoch 36: Validation loss decreased (0.171347 --> 0.171262).  Saving model ...
	 Train_Loss: 0.1824 Train_Acc: 94.778 Val_Loss: 0.1713  BEST VAL Loss: 0.1713  Val_Acc: 94.868

Epoch 37: Validation loss decreased (0.171262 --> 0.170726).  Saving model ...
	 Train_Loss: 0.1812 Train_Acc: 94.171 Val_Loss: 0.1707  BEST VAL Loss: 0.1707  Val_Acc: 94.161

Epoch 38: Validation loss decreased (0.170726 --> 0.170363).  Saving model ...
	 Train_Loss: 0.1797 Train_Acc: 94.578 Val_Loss: 0.1704  BEST VAL Loss: 0.1704  Val_Acc: 94.161

Epoch 39: Validation loss decreased (0.170363 --> 0.170258).  Saving model ...
	 Train_Loss: 0.1781 Train_Acc: 94.647 Val_Loss: 0.1703  BEST VAL Loss: 0.1703  Val_Acc: 94.776

Epoch 40: Validation loss decreased (0.170258 --> 0.170002).  Saving model ...
	 Train_Loss: 0.1766 Train_Acc: 94.705 Val_Loss: 0.1700  BEST VAL Loss: 0.1700  Val_Acc: 94.253

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.1750 Train_Acc: 95.012 Val_Loss: 0.1701  BEST VAL Loss: 0.1700  Val_Acc: 94.929

Epoch 42: Validation loss decreased (0.170002 --> 0.169872).  Saving model ...
	 Train_Loss: 0.1735 Train_Acc: 95.147 Val_Loss: 0.1699  BEST VAL Loss: 0.1699  Val_Acc: 94.929

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.1721 Train_Acc: 95.020 Val_Loss: 0.1703  BEST VAL Loss: 0.1699  Val_Acc: 95.022

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.1707 Train_Acc: 94.951 Val_Loss: 0.1705  BEST VAL Loss: 0.1699  Val_Acc: 94.899

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.1694 Train_Acc: 95.231 Val_Loss: 0.1703  BEST VAL Loss: 0.1699  Val_Acc: 94.868

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.1682 Train_Acc: 95.081 Val_Loss: 0.1701  BEST VAL Loss: 0.1699  Val_Acc: 95.390

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.1669 Train_Acc: 95.270 Val_Loss: 0.1702  BEST VAL Loss: 0.1699  Val_Acc: 95.052

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.1657 Train_Acc: 95.112 Val_Loss: 0.1704  BEST VAL Loss: 0.1699  Val_Acc: 94.929

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.1646 Train_Acc: 95.224 Val_Loss: 0.1708  BEST VAL Loss: 0.1699  Val_Acc: 94.960

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.1636 Train_Acc: 95.331 Val_Loss: 0.1709  BEST VAL Loss: 0.1699  Val_Acc: 95.329

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.1625 Train_Acc: 95.331 Val_Loss: 0.1712  BEST VAL Loss: 0.1699  Val_Acc: 94.899

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.1615 Train_Acc: 95.128 Val_Loss: 0.1712  BEST VAL Loss: 0.1699  Val_Acc: 94.991

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.1605 Train_Acc: 95.343 Val_Loss: 0.1715  BEST VAL Loss: 0.1699  Val_Acc: 94.683

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.1595 Train_Acc: 95.270 Val_Loss: 0.1718  BEST VAL Loss: 0.1699  Val_Acc: 94.868

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.1586 Train_Acc: 95.254 Val_Loss: 0.1719  BEST VAL Loss: 0.1699  Val_Acc: 94.530

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.1587 Train_Acc: 92.849 Val_Loss: 0.1730  BEST VAL Loss: 0.1699  Val_Acc: 93.762

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.1585 Train_Acc: 93.295 Val_Loss: 0.1735  BEST VAL Loss: 0.1699  Val_Acc: 94.714

Epoch 58: Validation loss did not decrease
Early stopped at epoch : 58
H2O2_100.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      0.98      0.98     18174
           1       0.95      0.97      0.96      7850

    accuracy                           0.98     26024
   macro avg       0.97      0.98      0.97     26024
weighted avg       0.98      0.98      0.98     26024

H2O2_100.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.96      0.96      2272
           1       0.91      0.92      0.92       982

    accuracy                           0.95      3254
   macro avg       0.94      0.94      0.94      3254
weighted avg       0.95      0.95      0.95      3254

H2O2_100.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.96      0.96      0.96      2272
           1       0.91      0.92      0.92       982

    accuracy                           0.95      3254
   macro avg       0.94      0.94      0.94      3254
weighted avg       0.95      0.95      0.95      3254

              precision    recall  f1-score   support

           0       0.96      0.96      0.96      2272
           1       0.91      0.92      0.92       982

    accuracy                           0.95      3254
   macro avg       0.94      0.94      0.94      3254
weighted avg       0.95      0.95      0.95      3254

H2O2_100.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.94      0.95      0.95      4182
           1       0.94      0.93      0.94      3398

    accuracy                           0.94      7580
   macro avg       0.94      0.94      0.94      7580
weighted avg       0.94      0.94      0.94      7580

              precision    recall  f1-score   support

           0       0.94      0.95      0.95      4182
           1       0.94      0.93      0.94      3398

    accuracy                           0.94      7580
   macro avg       0.94      0.94      0.94      7580
weighted avg       0.94      0.94      0.94      7580

completed
