[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'bbd4efbb'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '574e2ff4'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '9e179f50'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'f8529c31'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_10.000_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_10.000_DMSO_0.025
TREATMENT_NAME: LPS_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_10.000_DMSO_0.025']
The dimensions of the data are: (295087, 1270)
Number of total missing values across all columns: 590174
Data Subset Is Off
Wells held out for testing: ['C08' 'E08']
Wells to use for training, validation, and testing ['C02' 'C03' 'C09' 'E02' 'E03' 'E09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.622291).  Saving model ...
	 Train_Loss: 0.6513 Train_Acc: 61.415 Val_Loss: 0.6223  BEST VAL Loss: 0.6223  Val_Acc: 64.861

Epoch 1: Validation loss decreased (0.622291 --> 0.615049).  Saving model ...
	 Train_Loss: 0.6367 Train_Acc: 64.600 Val_Loss: 0.6150  BEST VAL Loss: 0.6150  Val_Acc: 65.433

Epoch 2: Validation loss decreased (0.615049 --> 0.613747).  Saving model ...
	 Train_Loss: 0.6294 Train_Acc: 65.297 Val_Loss: 0.6137  BEST VAL Loss: 0.6137  Val_Acc: 65.584

Epoch 3: Validation loss decreased (0.613747 --> 0.609138).  Saving model ...
	 Train_Loss: 0.6242 Train_Acc: 65.700 Val_Loss: 0.6091  BEST VAL Loss: 0.6091  Val_Acc: 67.240

Epoch 4: Validation loss decreased (0.609138 --> 0.606799).  Saving model ...
	 Train_Loss: 0.6205 Train_Acc: 66.070 Val_Loss: 0.6068  BEST VAL Loss: 0.6068  Val_Acc: 66.613

Epoch 5: Validation loss decreased (0.606799 --> 0.604617).  Saving model ...
	 Train_Loss: 0.6173 Train_Acc: 66.442 Val_Loss: 0.6046  BEST VAL Loss: 0.6046  Val_Acc: 66.815

Epoch 6: Validation loss decreased (0.604617 --> 0.602386).  Saving model ...
	 Train_Loss: 0.6147 Train_Acc: 66.742 Val_Loss: 0.6024  BEST VAL Loss: 0.6024  Val_Acc: 67.272

Epoch 7: Validation loss decreased (0.602386 --> 0.600606).  Saving model ...
	 Train_Loss: 0.6124 Train_Acc: 66.694 Val_Loss: 0.6006  BEST VAL Loss: 0.6006  Val_Acc: 67.450

Epoch 8: Validation loss decreased (0.600606 --> 0.598962).  Saving model ...
	 Train_Loss: 0.6105 Train_Acc: 66.855 Val_Loss: 0.5990  BEST VAL Loss: 0.5990  Val_Acc: 67.643

Epoch 9: Validation loss decreased (0.598962 --> 0.597880).  Saving model ...
	 Train_Loss: 0.6088 Train_Acc: 66.906 Val_Loss: 0.5979  BEST VAL Loss: 0.5979  Val_Acc: 67.245

Epoch 10: Validation loss decreased (0.597880 --> 0.596270).  Saving model ...
	 Train_Loss: 0.6073 Train_Acc: 67.173 Val_Loss: 0.5963  BEST VAL Loss: 0.5963  Val_Acc: 68.333

Epoch 11: Validation loss decreased (0.596270 --> 0.594849).  Saving model ...
	 Train_Loss: 0.6059 Train_Acc: 67.151 Val_Loss: 0.5948  BEST VAL Loss: 0.5948  Val_Acc: 68.311

Epoch 12: Validation loss decreased (0.594849 --> 0.594118).  Saving model ...
	 Train_Loss: 0.6046 Train_Acc: 67.232 Val_Loss: 0.5941  BEST VAL Loss: 0.5941  Val_Acc: 67.954

Epoch 13: Validation loss decreased (0.594118 --> 0.592976).  Saving model ...
	 Train_Loss: 0.6034 Train_Acc: 67.557 Val_Loss: 0.5930  BEST VAL Loss: 0.5930  Val_Acc: 68.498

Epoch 14: Validation loss decreased (0.592976 --> 0.592066).  Saving model ...
	 Train_Loss: 0.6022 Train_Acc: 67.411 Val_Loss: 0.5921  BEST VAL Loss: 0.5921  Val_Acc: 68.407

Epoch 15: Validation loss decreased (0.592066 --> 0.590981).  Saving model ...
	 Train_Loss: 0.6012 Train_Acc: 67.636 Val_Loss: 0.5910  BEST VAL Loss: 0.5910  Val_Acc: 68.846

Epoch 16: Validation loss decreased (0.590981 --> 0.590292).  Saving model ...
	 Train_Loss: 0.6002 Train_Acc: 67.786 Val_Loss: 0.5903  BEST VAL Loss: 0.5903  Val_Acc: 68.379

Epoch 17: Validation loss decreased (0.590292 --> 0.589290).  Saving model ...
	 Train_Loss: 0.5992 Train_Acc: 67.597 Val_Loss: 0.5893  BEST VAL Loss: 0.5893  Val_Acc: 68.773

Epoch 18: Validation loss decreased (0.589290 --> 0.588416).  Saving model ...
	 Train_Loss: 0.5984 Train_Acc: 67.624 Val_Loss: 0.5884  BEST VAL Loss: 0.5884  Val_Acc: 68.544

Epoch 19: Validation loss decreased (0.588416 --> 0.587656).  Saving model ...
	 Train_Loss: 0.5975 Train_Acc: 67.846 Val_Loss: 0.5877  BEST VAL Loss: 0.5877  Val_Acc: 68.805

Epoch 20: Validation loss decreased (0.587656 --> 0.587017).  Saving model ...
	 Train_Loss: 0.5967 Train_Acc: 67.897 Val_Loss: 0.5870  BEST VAL Loss: 0.5870  Val_Acc: 68.974

Epoch 21: Validation loss decreased (0.587017 --> 0.586305).  Saving model ...
	 Train_Loss: 0.5959 Train_Acc: 67.817 Val_Loss: 0.5863  BEST VAL Loss: 0.5863  Val_Acc: 68.892

Epoch 22: Validation loss decreased (0.586305 --> 0.585806).  Saving model ...
	 Train_Loss: 0.5952 Train_Acc: 67.920 Val_Loss: 0.5858  BEST VAL Loss: 0.5858  Val_Acc: 68.841

Epoch 23: Validation loss decreased (0.585806 --> 0.585079).  Saving model ...
	 Train_Loss: 0.5945 Train_Acc: 68.019 Val_Loss: 0.5851  BEST VAL Loss: 0.5851  Val_Acc: 69.413

Epoch 24: Validation loss decreased (0.585079 --> 0.584568).  Saving model ...
	 Train_Loss: 0.5938 Train_Acc: 67.931 Val_Loss: 0.5846  BEST VAL Loss: 0.5846  Val_Acc: 68.928

Epoch 25: Validation loss decreased (0.584568 --> 0.584015).  Saving model ...
	 Train_Loss: 0.5931 Train_Acc: 68.024 Val_Loss: 0.5840  BEST VAL Loss: 0.5840  Val_Acc: 69.198

Epoch 26: Validation loss decreased (0.584015 --> 0.583334).  Saving model ...
	 Train_Loss: 0.5925 Train_Acc: 67.932 Val_Loss: 0.5833  BEST VAL Loss: 0.5833  Val_Acc: 69.404

Epoch 27: Validation loss decreased (0.583334 --> 0.582734).  Saving model ...
	 Train_Loss: 0.5920 Train_Acc: 67.944 Val_Loss: 0.5827  BEST VAL Loss: 0.5827  Val_Acc: 69.193

Epoch 28: Validation loss decreased (0.582734 --> 0.582256).  Saving model ...
	 Train_Loss: 0.5914 Train_Acc: 68.040 Val_Loss: 0.5823  BEST VAL Loss: 0.5823  Val_Acc: 69.258

Epoch 29: Validation loss decreased (0.582256 --> 0.581655).  Saving model ...
	 Train_Loss: 0.5908 Train_Acc: 68.003 Val_Loss: 0.5817  BEST VAL Loss: 0.5817  Val_Acc: 69.573

Epoch 30: Validation loss decreased (0.581655 --> 0.581079).  Saving model ...
	 Train_Loss: 0.5903 Train_Acc: 68.059 Val_Loss: 0.5811  BEST VAL Loss: 0.5811  Val_Acc: 69.344

Epoch 31: Validation loss decreased (0.581079 --> 0.580631).  Saving model ...
	 Train_Loss: 0.5898 Train_Acc: 68.024 Val_Loss: 0.5806  BEST VAL Loss: 0.5806  Val_Acc: 69.372

Epoch 32: Validation loss decreased (0.580631 --> 0.580106).  Saving model ...
	 Train_Loss: 0.5894 Train_Acc: 67.936 Val_Loss: 0.5801  BEST VAL Loss: 0.5801  Val_Acc: 69.262

Epoch 33: Validation loss decreased (0.580106 --> 0.579552).  Saving model ...
	 Train_Loss: 0.5889 Train_Acc: 68.087 Val_Loss: 0.5796  BEST VAL Loss: 0.5796  Val_Acc: 69.564

Epoch 34: Validation loss decreased (0.579552 --> 0.579114).  Saving model ...
	 Train_Loss: 0.5884 Train_Acc: 68.187 Val_Loss: 0.5791  BEST VAL Loss: 0.5791  Val_Acc: 69.518

Epoch 35: Validation loss decreased (0.579114 --> 0.578658).  Saving model ...
	 Train_Loss: 0.5880 Train_Acc: 68.159 Val_Loss: 0.5787  BEST VAL Loss: 0.5787  Val_Acc: 69.203

Epoch 36: Validation loss decreased (0.578658 --> 0.578338).  Saving model ...
	 Train_Loss: 0.5876 Train_Acc: 68.010 Val_Loss: 0.5783  BEST VAL Loss: 0.5783  Val_Acc: 69.175

Epoch 37: Validation loss decreased (0.578338 --> 0.577874).  Saving model ...
	 Train_Loss: 0.5871 Train_Acc: 68.190 Val_Loss: 0.5779  BEST VAL Loss: 0.5779  Val_Acc: 69.651

Epoch 38: Validation loss decreased (0.577874 --> 0.577490).  Saving model ...
	 Train_Loss: 0.5867 Train_Acc: 68.192 Val_Loss: 0.5775  BEST VAL Loss: 0.5775  Val_Acc: 69.587

Epoch 39: Validation loss decreased (0.577490 --> 0.577053).  Saving model ...
	 Train_Loss: 0.5863 Train_Acc: 68.229 Val_Loss: 0.5771  BEST VAL Loss: 0.5771  Val_Acc: 69.889

Epoch 40: Validation loss decreased (0.577053 --> 0.576640).  Saving model ...
	 Train_Loss: 0.5859 Train_Acc: 68.145 Val_Loss: 0.5766  BEST VAL Loss: 0.5766  Val_Acc: 69.573

Epoch 41: Validation loss decreased (0.576640 --> 0.576346).  Saving model ...
	 Train_Loss: 0.5855 Train_Acc: 68.229 Val_Loss: 0.5763  BEST VAL Loss: 0.5763  Val_Acc: 69.376

Epoch 42: Validation loss decreased (0.576346 --> 0.576057).  Saving model ...
	 Train_Loss: 0.5852 Train_Acc: 68.276 Val_Loss: 0.5761  BEST VAL Loss: 0.5761  Val_Acc: 69.532

Epoch 43: Validation loss decreased (0.576057 --> 0.575746).  Saving model ...
	 Train_Loss: 0.5849 Train_Acc: 68.186 Val_Loss: 0.5757  BEST VAL Loss: 0.5757  Val_Acc: 69.518

Epoch 44: Validation loss decreased (0.575746 --> 0.575352).  Saving model ...
	 Train_Loss: 0.5845 Train_Acc: 68.409 Val_Loss: 0.5754  BEST VAL Loss: 0.5754  Val_Acc: 69.720

Epoch 45: Validation loss decreased (0.575352 --> 0.575020).  Saving model ...
	 Train_Loss: 0.5842 Train_Acc: 68.274 Val_Loss: 0.5750  BEST VAL Loss: 0.5750  Val_Acc: 69.871

Epoch 46: Validation loss decreased (0.575020 --> 0.574730).  Saving model ...
	 Train_Loss: 0.5838 Train_Acc: 68.393 Val_Loss: 0.5747  BEST VAL Loss: 0.5747  Val_Acc: 69.610

Epoch 47: Validation loss decreased (0.574730 --> 0.574440).  Saving model ...
	 Train_Loss: 0.5835 Train_Acc: 68.179 Val_Loss: 0.5744  BEST VAL Loss: 0.5744  Val_Acc: 69.569

Epoch 48: Validation loss decreased (0.574440 --> 0.574132).  Saving model ...
	 Train_Loss: 0.5832 Train_Acc: 68.288 Val_Loss: 0.5741  BEST VAL Loss: 0.5741  Val_Acc: 69.724

Epoch 49: Validation loss decreased (0.574132 --> 0.573863).  Saving model ...
	 Train_Loss: 0.5829 Train_Acc: 68.250 Val_Loss: 0.5739  BEST VAL Loss: 0.5739  Val_Acc: 69.582

Epoch 50: Validation loss decreased (0.573863 --> 0.573706).  Saving model ...
	 Train_Loss: 0.5826 Train_Acc: 68.338 Val_Loss: 0.5737  BEST VAL Loss: 0.5737  Val_Acc: 69.523

Epoch 51: Validation loss decreased (0.573706 --> 0.573495).  Saving model ...
	 Train_Loss: 0.5823 Train_Acc: 68.421 Val_Loss: 0.5735  BEST VAL Loss: 0.5735  Val_Acc: 69.866

Epoch 52: Validation loss decreased (0.573495 --> 0.573282).  Saving model ...
	 Train_Loss: 0.5821 Train_Acc: 68.328 Val_Loss: 0.5733  BEST VAL Loss: 0.5733  Val_Acc: 69.509

Epoch 53: Validation loss decreased (0.573282 --> 0.573009).  Saving model ...
	 Train_Loss: 0.5818 Train_Acc: 68.397 Val_Loss: 0.5730  BEST VAL Loss: 0.5730  Val_Acc: 69.852

Epoch 54: Validation loss decreased (0.573009 --> 0.572757).  Saving model ...
	 Train_Loss: 0.5815 Train_Acc: 68.401 Val_Loss: 0.5728  BEST VAL Loss: 0.5728  Val_Acc: 69.857

Epoch 55: Validation loss decreased (0.572757 --> 0.572521).  Saving model ...
	 Train_Loss: 0.5813 Train_Acc: 68.257 Val_Loss: 0.5725  BEST VAL Loss: 0.5725  Val_Acc: 69.683

Epoch 56: Validation loss decreased (0.572521 --> 0.572300).  Saving model ...
	 Train_Loss: 0.5810 Train_Acc: 68.379 Val_Loss: 0.5723  BEST VAL Loss: 0.5723  Val_Acc: 70.026

Epoch 57: Validation loss decreased (0.572300 --> 0.572062).  Saving model ...
	 Train_Loss: 0.5808 Train_Acc: 68.620 Val_Loss: 0.5721  BEST VAL Loss: 0.5721  Val_Acc: 69.843

Epoch 58: Validation loss decreased (0.572062 --> 0.571922).  Saving model ...
	 Train_Loss: 0.5805 Train_Acc: 68.353 Val_Loss: 0.5719  BEST VAL Loss: 0.5719  Val_Acc: 69.473

Epoch 59: Validation loss decreased (0.571922 --> 0.571721).  Saving model ...
	 Train_Loss: 0.5803 Train_Acc: 68.476 Val_Loss: 0.5717  BEST VAL Loss: 0.5717  Val_Acc: 70.022

Epoch 60: Validation loss decreased (0.571721 --> 0.571506).  Saving model ...
	 Train_Loss: 0.5801 Train_Acc: 68.397 Val_Loss: 0.5715  BEST VAL Loss: 0.5715  Val_Acc: 69.925

Epoch 61: Validation loss decreased (0.571506 --> 0.571274).  Saving model ...
	 Train_Loss: 0.5798 Train_Acc: 68.439 Val_Loss: 0.5713  BEST VAL Loss: 0.5713  Val_Acc: 70.003

Epoch 62: Validation loss decreased (0.571274 --> 0.571027).  Saving model ...
	 Train_Loss: 0.5796 Train_Acc: 68.479 Val_Loss: 0.5710  BEST VAL Loss: 0.5710  Val_Acc: 70.214

Epoch 63: Validation loss decreased (0.571027 --> 0.570886).  Saving model ...
	 Train_Loss: 0.5794 Train_Acc: 68.438 Val_Loss: 0.5709  BEST VAL Loss: 0.5709  Val_Acc: 69.893

Epoch 64: Validation loss decreased (0.570886 --> 0.570751).  Saving model ...
	 Train_Loss: 0.5792 Train_Acc: 68.617 Val_Loss: 0.5708  BEST VAL Loss: 0.5708  Val_Acc: 69.651

Epoch 65: Validation loss decreased (0.570751 --> 0.570581).  Saving model ...
	 Train_Loss: 0.5790 Train_Acc: 68.374 Val_Loss: 0.5706  BEST VAL Loss: 0.5706  Val_Acc: 69.720

Epoch 66: Validation loss decreased (0.570581 --> 0.570414).  Saving model ...
	 Train_Loss: 0.5788 Train_Acc: 68.548 Val_Loss: 0.5704  BEST VAL Loss: 0.5704  Val_Acc: 69.541

Epoch 67: Validation loss decreased (0.570414 --> 0.570209).  Saving model ...
	 Train_Loss: 0.5786 Train_Acc: 68.507 Val_Loss: 0.5702  BEST VAL Loss: 0.5702  Val_Acc: 69.944

Epoch 68: Validation loss decreased (0.570209 --> 0.570046).  Saving model ...
	 Train_Loss: 0.5784 Train_Acc: 68.488 Val_Loss: 0.5700  BEST VAL Loss: 0.5700  Val_Acc: 69.930

Epoch 69: Validation loss decreased (0.570046 --> 0.569890).  Saving model ...
	 Train_Loss: 0.5782 Train_Acc: 68.596 Val_Loss: 0.5699  BEST VAL Loss: 0.5699  Val_Acc: 69.701

Epoch 70: Validation loss decreased (0.569890 --> 0.569701).  Saving model ...
	 Train_Loss: 0.5780 Train_Acc: 68.381 Val_Loss: 0.5697  BEST VAL Loss: 0.5697  Val_Acc: 69.820

Epoch 71: Validation loss decreased (0.569701 --> 0.569530).  Saving model ...
	 Train_Loss: 0.5778 Train_Acc: 68.541 Val_Loss: 0.5695  BEST VAL Loss: 0.5695  Val_Acc: 69.930

Epoch 72: Validation loss decreased (0.569530 --> 0.569378).  Saving model ...
	 Train_Loss: 0.5777 Train_Acc: 68.626 Val_Loss: 0.5694  BEST VAL Loss: 0.5694  Val_Acc: 69.852

Epoch 73: Validation loss decreased (0.569378 --> 0.569206).  Saving model ...
	 Train_Loss: 0.5775 Train_Acc: 68.628 Val_Loss: 0.5692  BEST VAL Loss: 0.5692  Val_Acc: 69.935

Epoch 74: Validation loss decreased (0.569206 --> 0.569092).  Saving model ...
	 Train_Loss: 0.5773 Train_Acc: 68.542 Val_Loss: 0.5691  BEST VAL Loss: 0.5691  Val_Acc: 70.031

Epoch 75: Validation loss decreased (0.569092 --> 0.568973).  Saving model ...
	 Train_Loss: 0.5771 Train_Acc: 68.612 Val_Loss: 0.5690  BEST VAL Loss: 0.5690  Val_Acc: 69.591

Epoch 76: Validation loss decreased (0.568973 --> 0.568881).  Saving model ...
	 Train_Loss: 0.5770 Train_Acc: 68.493 Val_Loss: 0.5689  BEST VAL Loss: 0.5689  Val_Acc: 69.871

Epoch 77: Validation loss decreased (0.568881 --> 0.568772).  Saving model ...
	 Train_Loss: 0.5768 Train_Acc: 68.500 Val_Loss: 0.5688  BEST VAL Loss: 0.5688  Val_Acc: 69.756

Epoch 78: Validation loss decreased (0.568772 --> 0.568647).  Saving model ...
	 Train_Loss: 0.5766 Train_Acc: 68.638 Val_Loss: 0.5686  BEST VAL Loss: 0.5686  Val_Acc: 69.816

Epoch 79: Validation loss decreased (0.568647 --> 0.568520).  Saving model ...
	 Train_Loss: 0.5765 Train_Acc: 68.573 Val_Loss: 0.5685  BEST VAL Loss: 0.5685  Val_Acc: 70.104

Epoch 80: Validation loss decreased (0.568520 --> 0.568451).  Saving model ...
	 Train_Loss: 0.5763 Train_Acc: 68.618 Val_Loss: 0.5685  BEST VAL Loss: 0.5685  Val_Acc: 69.939

Epoch 81: Validation loss decreased (0.568451 --> 0.568322).  Saving model ...
	 Train_Loss: 0.5762 Train_Acc: 68.575 Val_Loss: 0.5683  BEST VAL Loss: 0.5683  Val_Acc: 70.044

Epoch 82: Validation loss decreased (0.568322 --> 0.568188).  Saving model ...
	 Train_Loss: 0.5760 Train_Acc: 68.651 Val_Loss: 0.5682  BEST VAL Loss: 0.5682  Val_Acc: 70.291

Epoch 83: Validation loss decreased (0.568188 --> 0.568080).  Saving model ...
	 Train_Loss: 0.5759 Train_Acc: 68.617 Val_Loss: 0.5681  BEST VAL Loss: 0.5681  Val_Acc: 70.072

Epoch 84: Validation loss decreased (0.568080 --> 0.567961).  Saving model ...
	 Train_Loss: 0.5757 Train_Acc: 68.627 Val_Loss: 0.5680  BEST VAL Loss: 0.5680  Val_Acc: 69.834

Epoch 85: Validation loss decreased (0.567961 --> 0.567877).  Saving model ...
	 Train_Loss: 0.5756 Train_Acc: 68.715 Val_Loss: 0.5679  BEST VAL Loss: 0.5679  Val_Acc: 70.140

Epoch 86: Validation loss decreased (0.567877 --> 0.567762).  Saving model ...
	 Train_Loss: 0.5754 Train_Acc: 68.687 Val_Loss: 0.5678  BEST VAL Loss: 0.5678  Val_Acc: 70.214

Epoch 87: Validation loss decreased (0.567762 --> 0.567680).  Saving model ...
	 Train_Loss: 0.5753 Train_Acc: 68.654 Val_Loss: 0.5677  BEST VAL Loss: 0.5677  Val_Acc: 69.857

Epoch 88: Validation loss decreased (0.567680 --> 0.567568).  Saving model ...
	 Train_Loss: 0.5752 Train_Acc: 68.656 Val_Loss: 0.5676  BEST VAL Loss: 0.5676  Val_Acc: 70.177

Epoch 89: Validation loss decreased (0.567568 --> 0.567448).  Saving model ...
	 Train_Loss: 0.5750 Train_Acc: 68.720 Val_Loss: 0.5674  BEST VAL Loss: 0.5674  Val_Acc: 69.779

Epoch 90: Validation loss decreased (0.567448 --> 0.567417).  Saving model ...
	 Train_Loss: 0.5749 Train_Acc: 68.704 Val_Loss: 0.5674  BEST VAL Loss: 0.5674  Val_Acc: 69.656

Epoch 91: Validation loss decreased (0.567417 --> 0.567347).  Saving model ...
	 Train_Loss: 0.5747 Train_Acc: 68.771 Val_Loss: 0.5673  BEST VAL Loss: 0.5673  Val_Acc: 70.264

Epoch 92: Validation loss decreased (0.567347 --> 0.567259).  Saving model ...
	 Train_Loss: 0.5746 Train_Acc: 68.630 Val_Loss: 0.5673  BEST VAL Loss: 0.5673  Val_Acc: 70.003

Epoch 93: Validation loss decreased (0.567259 --> 0.567158).  Saving model ...
	 Train_Loss: 0.5745 Train_Acc: 68.679 Val_Loss: 0.5672  BEST VAL Loss: 0.5672  Val_Acc: 70.076

Epoch 94: Validation loss decreased (0.567158 --> 0.567099).  Saving model ...
	 Train_Loss: 0.5744 Train_Acc: 68.744 Val_Loss: 0.5671  BEST VAL Loss: 0.5671  Val_Acc: 69.925

Epoch 95: Validation loss decreased (0.567099 --> 0.566991).  Saving model ...
	 Train_Loss: 0.5742 Train_Acc: 68.833 Val_Loss: 0.5670  BEST VAL Loss: 0.5670  Val_Acc: 70.058

Epoch 96: Validation loss decreased (0.566991 --> 0.566900).  Saving model ...
	 Train_Loss: 0.5741 Train_Acc: 68.495 Val_Loss: 0.5669  BEST VAL Loss: 0.5669  Val_Acc: 70.269

Epoch 97: Validation loss decreased (0.566900 --> 0.566786).  Saving model ...
	 Train_Loss: 0.5740 Train_Acc: 68.800 Val_Loss: 0.5668  BEST VAL Loss: 0.5668  Val_Acc: 70.145

Epoch 98: Validation loss decreased (0.566786 --> 0.566670).  Saving model ...
	 Train_Loss: 0.5739 Train_Acc: 68.786 Val_Loss: 0.5667  BEST VAL Loss: 0.5667  Val_Acc: 70.159

Epoch 99: Validation loss decreased (0.566670 --> 0.566614).  Saving model ...
	 Train_Loss: 0.5737 Train_Acc: 68.757 Val_Loss: 0.5666  BEST VAL Loss: 0.5666  Val_Acc: 69.962

LPS_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.47      0.47     82968
           1       0.53      0.52      0.53     91897

    accuracy                           0.50    174865
   macro avg       0.50      0.50      0.50    174865
weighted avg       0.50      0.50      0.50    174865

LPS_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.47      0.47     10371
           1       0.53      0.53      0.53     11488

    accuracy                           0.50     21859
   macro avg       0.50      0.50      0.50     21859
weighted avg       0.50      0.50      0.50     21859

LPS_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.48      0.48     10371
           1       0.53      0.52      0.52     11488

    accuracy                           0.50     21859
   macro avg       0.50      0.50      0.50     21859
weighted avg       0.50      0.50      0.50     21859

              precision    recall  f1-score   support

           0       0.48      0.48      0.48     10371
           1       0.53      0.52      0.52     11488

    accuracy                           0.50     21859
   macro avg       0.50      0.50      0.50     21859
weighted avg       0.50      0.50      0.50     21859

LPS_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_10.000_DMSO_0.025_vs_LPS_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.57      0.51     34887
           1       0.54      0.43      0.48     41617

    accuracy                           0.49     76504
   macro avg       0.50      0.50      0.49     76504
weighted avg       0.50      0.49      0.49     76504

              precision    recall  f1-score   support

           0       0.46      0.57      0.51     34887
           1       0.54      0.43      0.48     41617

    accuracy                           0.49     76504
   macro avg       0.50      0.50      0.49     76504
weighted avg       0.50      0.49      0.49     76504

completed
