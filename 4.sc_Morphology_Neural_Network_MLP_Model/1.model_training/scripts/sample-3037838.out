[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '62636ca3'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '7bf7530b'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b27bc4d1'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '321f7fd8'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_0.100_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_0.100_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (32438, 1276)
Number of total missing values across all columns: 64876
Data Subset Is Off
Wells held out for testing: ['C21' 'L22']
Wells to use for training, validation, and testing ['C16' 'C17' 'C20' 'L18' 'L19' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.662671).  Saving model ...
	 Train_Loss: 0.7230 Train_Acc: 53.299 Val_Loss: 0.6627  BEST VAL Loss: 0.6627  Val_Acc: 59.412

Epoch 1: Validation loss decreased (0.662671 --> 0.652073).  Saving model ...
	 Train_Loss: 0.6946 Train_Acc: 57.970 Val_Loss: 0.6521  BEST VAL Loss: 0.6521  Val_Acc: 63.529

Epoch 2: Validation loss decreased (0.652073 --> 0.640183).  Saving model ...
	 Train_Loss: 0.6735 Train_Acc: 61.521 Val_Loss: 0.6402  BEST VAL Loss: 0.6402  Val_Acc: 66.303

Epoch 3: Validation loss decreased (0.640183 --> 0.630063).  Saving model ...
	 Train_Loss: 0.6584 Train_Acc: 62.567 Val_Loss: 0.6301  BEST VAL Loss: 0.6301  Val_Acc: 68.151

Epoch 4: Validation loss decreased (0.630063 --> 0.621053).  Saving model ...
	 Train_Loss: 0.6459 Train_Acc: 63.949 Val_Loss: 0.6211  BEST VAL Loss: 0.6211  Val_Acc: 69.664

Epoch 5: Validation loss decreased (0.621053 --> 0.613217).  Saving model ...
	 Train_Loss: 0.6359 Train_Acc: 64.227 Val_Loss: 0.6132  BEST VAL Loss: 0.6132  Val_Acc: 71.050

Epoch 6: Validation loss decreased (0.613217 --> 0.607052).  Saving model ...
	 Train_Loss: 0.6272 Train_Acc: 64.747 Val_Loss: 0.6071  BEST VAL Loss: 0.6071  Val_Acc: 70.840

Epoch 7: Validation loss decreased (0.607052 --> 0.601587).  Saving model ...
	 Train_Loss: 0.6217 Train_Acc: 64.837 Val_Loss: 0.6016  BEST VAL Loss: 0.6016  Val_Acc: 70.756

Epoch 8: Validation loss decreased (0.601587 --> 0.597799).  Saving model ...
	 Train_Loss: 0.6162 Train_Acc: 64.569 Val_Loss: 0.5978  BEST VAL Loss: 0.5978  Val_Acc: 71.387

Epoch 9: Validation loss decreased (0.597799 --> 0.593721).  Saving model ...
	 Train_Loss: 0.6109 Train_Acc: 65.294 Val_Loss: 0.5937  BEST VAL Loss: 0.5937  Val_Acc: 71.050

Epoch 10: Validation loss decreased (0.593721 --> 0.589538).  Saving model ...
	 Train_Loss: 0.6060 Train_Acc: 65.961 Val_Loss: 0.5895  BEST VAL Loss: 0.5895  Val_Acc: 72.605

Epoch 11: Validation loss decreased (0.589538 --> 0.586516).  Saving model ...
	 Train_Loss: 0.6013 Train_Acc: 66.313 Val_Loss: 0.5865  BEST VAL Loss: 0.5865  Val_Acc: 72.185

Epoch 12: Validation loss decreased (0.586516 --> 0.583817).  Saving model ...
	 Train_Loss: 0.5974 Train_Acc: 66.182 Val_Loss: 0.5838  BEST VAL Loss: 0.5838  Val_Acc: 71.975

Epoch 13: Validation loss decreased (0.583817 --> 0.581041).  Saving model ...
	 Train_Loss: 0.5942 Train_Acc: 66.591 Val_Loss: 0.5810  BEST VAL Loss: 0.5810  Val_Acc: 72.395

Epoch 14: Validation loss decreased (0.581041 --> 0.578926).  Saving model ...
	 Train_Loss: 0.5907 Train_Acc: 66.407 Val_Loss: 0.5789  BEST VAL Loss: 0.5789  Val_Acc: 72.437

Epoch 15: Validation loss decreased (0.578926 --> 0.577061).  Saving model ...
	 Train_Loss: 0.5877 Train_Acc: 66.886 Val_Loss: 0.5771  BEST VAL Loss: 0.5771  Val_Acc: 72.185

Epoch 16: Validation loss decreased (0.577061 --> 0.574867).  Saving model ...
	 Train_Loss: 0.5848 Train_Acc: 66.597 Val_Loss: 0.5749  BEST VAL Loss: 0.5749  Val_Acc: 72.773

Epoch 17: Validation loss decreased (0.574867 --> 0.572758).  Saving model ...
	 Train_Loss: 0.5822 Train_Acc: 67.506 Val_Loss: 0.5728  BEST VAL Loss: 0.5728  Val_Acc: 72.227

Epoch 18: Validation loss decreased (0.572758 --> 0.571026).  Saving model ...
	 Train_Loss: 0.5795 Train_Acc: 68.325 Val_Loss: 0.5710  BEST VAL Loss: 0.5710  Val_Acc: 73.235

Epoch 19: Validation loss decreased (0.571026 --> 0.569052).  Saving model ...
	 Train_Loss: 0.5771 Train_Acc: 67.222 Val_Loss: 0.5691  BEST VAL Loss: 0.5691  Val_Acc: 73.655

Epoch 20: Validation loss decreased (0.569052 --> 0.567489).  Saving model ...
	 Train_Loss: 0.5747 Train_Acc: 67.400 Val_Loss: 0.5675  BEST VAL Loss: 0.5675  Val_Acc: 72.941

Epoch 21: Validation loss decreased (0.567489 --> 0.565836).  Saving model ...
	 Train_Loss: 0.5727 Train_Acc: 67.758 Val_Loss: 0.5658  BEST VAL Loss: 0.5658  Val_Acc: 72.605

Epoch 22: Validation loss decreased (0.565836 --> 0.564471).  Saving model ...
	 Train_Loss: 0.5709 Train_Acc: 67.490 Val_Loss: 0.5645  BEST VAL Loss: 0.5645  Val_Acc: 73.571

Epoch 23: Validation loss decreased (0.564471 --> 0.563287).  Saving model ...
	 Train_Loss: 0.5694 Train_Acc: 67.353 Val_Loss: 0.5633  BEST VAL Loss: 0.5633  Val_Acc: 72.731

Epoch 24: Validation loss decreased (0.563287 --> 0.562110).  Saving model ...
	 Train_Loss: 0.5681 Train_Acc: 67.217 Val_Loss: 0.5621  BEST VAL Loss: 0.5621  Val_Acc: 72.563

Epoch 25: Validation loss decreased (0.562110 --> 0.560966).  Saving model ...
	 Train_Loss: 0.5666 Train_Acc: 68.945 Val_Loss: 0.5610  BEST VAL Loss: 0.5610  Val_Acc: 72.563

Epoch 26: Validation loss decreased (0.560966 --> 0.559874).  Saving model ...
	 Train_Loss: 0.5652 Train_Acc: 68.625 Val_Loss: 0.5599  BEST VAL Loss: 0.5599  Val_Acc: 72.059

Epoch 27: Validation loss decreased (0.559874 --> 0.558873).  Saving model ...
	 Train_Loss: 0.5639 Train_Acc: 69.544 Val_Loss: 0.5589  BEST VAL Loss: 0.5589  Val_Acc: 72.563

Epoch 28: Validation loss decreased (0.558873 --> 0.557701).  Saving model ...
	 Train_Loss: 0.5627 Train_Acc: 68.414 Val_Loss: 0.5577  BEST VAL Loss: 0.5577  Val_Acc: 72.941

Epoch 29: Validation loss decreased (0.557701 --> 0.556605).  Saving model ...
	 Train_Loss: 0.5616 Train_Acc: 68.367 Val_Loss: 0.5566  BEST VAL Loss: 0.5566  Val_Acc: 72.941

Epoch 30: Validation loss decreased (0.556605 --> 0.555768).  Saving model ...
	 Train_Loss: 0.5605 Train_Acc: 67.863 Val_Loss: 0.5558  BEST VAL Loss: 0.5558  Val_Acc: 73.613

Epoch 31: Validation loss decreased (0.555768 --> 0.554818).  Saving model ...
	 Train_Loss: 0.5593 Train_Acc: 69.087 Val_Loss: 0.5548  BEST VAL Loss: 0.5548  Val_Acc: 73.908

Epoch 32: Validation loss decreased (0.554818 --> 0.553747).  Saving model ...
	 Train_Loss: 0.5582 Train_Acc: 69.176 Val_Loss: 0.5537  BEST VAL Loss: 0.5537  Val_Acc: 72.731

Epoch 33: Validation loss decreased (0.553747 --> 0.552646).  Saving model ...
	 Train_Loss: 0.5568 Train_Acc: 70.201 Val_Loss: 0.5526  BEST VAL Loss: 0.5526  Val_Acc: 73.824

Epoch 34: Validation loss decreased (0.552646 --> 0.551624).  Saving model ...
	 Train_Loss: 0.5555 Train_Acc: 69.817 Val_Loss: 0.5516  BEST VAL Loss: 0.5516  Val_Acc: 73.529

Epoch 35: Validation loss decreased (0.551624 --> 0.550644).  Saving model ...
	 Train_Loss: 0.5542 Train_Acc: 69.849 Val_Loss: 0.5506  BEST VAL Loss: 0.5506  Val_Acc: 74.034

Epoch 36: Validation loss decreased (0.550644 --> 0.549826).  Saving model ...
	 Train_Loss: 0.5530 Train_Acc: 69.633 Val_Loss: 0.5498  BEST VAL Loss: 0.5498  Val_Acc: 73.445

Epoch 37: Validation loss decreased (0.549826 --> 0.548866).  Saving model ...
	 Train_Loss: 0.5518 Train_Acc: 70.290 Val_Loss: 0.5489  BEST VAL Loss: 0.5489  Val_Acc: 73.445

Epoch 38: Validation loss decreased (0.548866 --> 0.548134).  Saving model ...
	 Train_Loss: 0.5506 Train_Acc: 70.358 Val_Loss: 0.5481  BEST VAL Loss: 0.5481  Val_Acc: 73.235

Epoch 39: Validation loss decreased (0.548134 --> 0.547533).  Saving model ...
	 Train_Loss: 0.5499 Train_Acc: 69.302 Val_Loss: 0.5475  BEST VAL Loss: 0.5475  Val_Acc: 72.815

Epoch 40: Validation loss decreased (0.547533 --> 0.546944).  Saving model ...
	 Train_Loss: 0.5490 Train_Acc: 69.959 Val_Loss: 0.5469  BEST VAL Loss: 0.5469  Val_Acc: 73.655

Epoch 41: Validation loss decreased (0.546944 --> 0.546116).  Saving model ...
	 Train_Loss: 0.5481 Train_Acc: 69.812 Val_Loss: 0.5461  BEST VAL Loss: 0.5461  Val_Acc: 74.412

Epoch 42: Validation loss decreased (0.546116 --> 0.545380).  Saving model ...
	 Train_Loss: 0.5470 Train_Acc: 70.484 Val_Loss: 0.5454  BEST VAL Loss: 0.5454  Val_Acc: 73.067

Epoch 43: Validation loss decreased (0.545380 --> 0.544738).  Saving model ...
	 Train_Loss: 0.5461 Train_Acc: 70.164 Val_Loss: 0.5447  BEST VAL Loss: 0.5447  Val_Acc: 73.109

Epoch 44: Validation loss decreased (0.544738 --> 0.544111).  Saving model ...
	 Train_Loss: 0.5451 Train_Acc: 70.222 Val_Loss: 0.5441  BEST VAL Loss: 0.5441  Val_Acc: 73.571

Epoch 45: Validation loss decreased (0.544111 --> 0.543628).  Saving model ...
	 Train_Loss: 0.5442 Train_Acc: 70.248 Val_Loss: 0.5436  BEST VAL Loss: 0.5436  Val_Acc: 72.269

Epoch 46: Validation loss decreased (0.543628 --> 0.543019).  Saving model ...
	 Train_Loss: 0.5434 Train_Acc: 70.085 Val_Loss: 0.5430  BEST VAL Loss: 0.5430  Val_Acc: 73.235

Epoch 47: Validation loss decreased (0.543019 --> 0.542521).  Saving model ...
	 Train_Loss: 0.5427 Train_Acc: 70.216 Val_Loss: 0.5425  BEST VAL Loss: 0.5425  Val_Acc: 73.109

Epoch 48: Validation loss decreased (0.542521 --> 0.541879).  Saving model ...
	 Train_Loss: 0.5421 Train_Acc: 69.518 Val_Loss: 0.5419  BEST VAL Loss: 0.5419  Val_Acc: 74.244

Epoch 49: Validation loss decreased (0.541879 --> 0.541291).  Saving model ...
	 Train_Loss: 0.5414 Train_Acc: 69.849 Val_Loss: 0.5413  BEST VAL Loss: 0.5413  Val_Acc: 73.277

Epoch 50: Validation loss decreased (0.541291 --> 0.540639).  Saving model ...
	 Train_Loss: 0.5406 Train_Acc: 70.605 Val_Loss: 0.5406  BEST VAL Loss: 0.5406  Val_Acc: 73.824

Epoch 51: Validation loss decreased (0.540639 --> 0.540083).  Saving model ...
	 Train_Loss: 0.5400 Train_Acc: 69.943 Val_Loss: 0.5401  BEST VAL Loss: 0.5401  Val_Acc: 73.445

Epoch 52: Validation loss decreased (0.540083 --> 0.539544).  Saving model ...
	 Train_Loss: 0.5391 Train_Acc: 69.801 Val_Loss: 0.5395  BEST VAL Loss: 0.5395  Val_Acc: 72.815

Epoch 53: Validation loss decreased (0.539544 --> 0.538919).  Saving model ...
	 Train_Loss: 0.5382 Train_Acc: 70.264 Val_Loss: 0.5389  BEST VAL Loss: 0.5389  Val_Acc: 73.613

Epoch 54: Validation loss decreased (0.538919 --> 0.538341).  Saving model ...
	 Train_Loss: 0.5375 Train_Acc: 70.563 Val_Loss: 0.5383  BEST VAL Loss: 0.5383  Val_Acc: 73.908

Epoch 55: Validation loss decreased (0.538341 --> 0.537777).  Saving model ...
	 Train_Loss: 0.5366 Train_Acc: 70.747 Val_Loss: 0.5378  BEST VAL Loss: 0.5378  Val_Acc: 73.697

Epoch 56: Validation loss decreased (0.537777 --> 0.537192).  Saving model ...
	 Train_Loss: 0.5360 Train_Acc: 70.752 Val_Loss: 0.5372  BEST VAL Loss: 0.5372  Val_Acc: 73.866

Epoch 57: Validation loss decreased (0.537192 --> 0.536827).  Saving model ...
	 Train_Loss: 0.5354 Train_Acc: 70.316 Val_Loss: 0.5368  BEST VAL Loss: 0.5368  Val_Acc: 72.731

Epoch 58: Validation loss decreased (0.536827 --> 0.536360).  Saving model ...
	 Train_Loss: 0.5347 Train_Acc: 70.379 Val_Loss: 0.5364  BEST VAL Loss: 0.5364  Val_Acc: 73.109

Epoch 59: Validation loss decreased (0.536360 --> 0.535951).  Saving model ...
	 Train_Loss: 0.5342 Train_Acc: 70.274 Val_Loss: 0.5360  BEST VAL Loss: 0.5360  Val_Acc: 73.739

Epoch 60: Validation loss decreased (0.535951 --> 0.535495).  Saving model ...
	 Train_Loss: 0.5335 Train_Acc: 70.637 Val_Loss: 0.5355  BEST VAL Loss: 0.5355  Val_Acc: 73.697

Epoch 61: Validation loss decreased (0.535495 --> 0.535150).  Saving model ...
	 Train_Loss: 0.5331 Train_Acc: 69.943 Val_Loss: 0.5351  BEST VAL Loss: 0.5351  Val_Acc: 73.067

Epoch 62: Validation loss decreased (0.535150 --> 0.534832).  Saving model ...
	 Train_Loss: 0.5325 Train_Acc: 70.758 Val_Loss: 0.5348  BEST VAL Loss: 0.5348  Val_Acc: 72.899

Epoch 63: Validation loss decreased (0.534832 --> 0.534438).  Saving model ...
	 Train_Loss: 0.5319 Train_Acc: 70.343 Val_Loss: 0.5344  BEST VAL Loss: 0.5344  Val_Acc: 73.067

Epoch 64: Validation loss decreased (0.534438 --> 0.534136).  Saving model ...
	 Train_Loss: 0.5314 Train_Acc: 69.980 Val_Loss: 0.5341  BEST VAL Loss: 0.5341  Val_Acc: 73.571

Epoch 65: Validation loss decreased (0.534136 --> 0.533697).  Saving model ...
	 Train_Loss: 0.5309 Train_Acc: 69.801 Val_Loss: 0.5337  BEST VAL Loss: 0.5337  Val_Acc: 73.824

Epoch 66: Validation loss decreased (0.533697 --> 0.533302).  Saving model ...
	 Train_Loss: 0.5303 Train_Acc: 70.316 Val_Loss: 0.5333  BEST VAL Loss: 0.5333  Val_Acc: 73.739

Epoch 67: Validation loss decreased (0.533302 --> 0.533029).  Saving model ...
	 Train_Loss: 0.5299 Train_Acc: 70.437 Val_Loss: 0.5330  BEST VAL Loss: 0.5330  Val_Acc: 72.731

Epoch 68: Validation loss decreased (0.533029 --> 0.532731).  Saving model ...
	 Train_Loss: 0.5294 Train_Acc: 70.416 Val_Loss: 0.5327  BEST VAL Loss: 0.5327  Val_Acc: 73.487

Epoch 69: Validation loss decreased (0.532731 --> 0.532408).  Saving model ...
	 Train_Loss: 0.5288 Train_Acc: 70.742 Val_Loss: 0.5324  BEST VAL Loss: 0.5324  Val_Acc: 73.824

Epoch 70: Validation loss decreased (0.532408 --> 0.532126).  Saving model ...
	 Train_Loss: 0.5283 Train_Acc: 70.458 Val_Loss: 0.5321  BEST VAL Loss: 0.5321  Val_Acc: 73.992

Epoch 71: Validation loss decreased (0.532126 --> 0.531866).  Saving model ...
	 Train_Loss: 0.5277 Train_Acc: 70.653 Val_Loss: 0.5319  BEST VAL Loss: 0.5319  Val_Acc: 73.067

Epoch 72: Validation loss decreased (0.531866 --> 0.531529).  Saving model ...
	 Train_Loss: 0.5272 Train_Acc: 70.195 Val_Loss: 0.5315  BEST VAL Loss: 0.5315  Val_Acc: 73.866

Epoch 73: Validation loss decreased (0.531529 --> 0.531222).  Saving model ...
	 Train_Loss: 0.5267 Train_Acc: 70.253 Val_Loss: 0.5312  BEST VAL Loss: 0.5312  Val_Acc: 73.697

Epoch 74: Validation loss decreased (0.531222 --> 0.531065).  Saving model ...
	 Train_Loss: 0.5265 Train_Acc: 69.975 Val_Loss: 0.5311  BEST VAL Loss: 0.5311  Val_Acc: 73.235

Epoch 75: Validation loss decreased (0.531065 --> 0.530819).  Saving model ...
	 Train_Loss: 0.5261 Train_Acc: 70.216 Val_Loss: 0.5308  BEST VAL Loss: 0.5308  Val_Acc: 74.244

Epoch 76: Validation loss decreased (0.530819 --> 0.530501).  Saving model ...
	 Train_Loss: 0.5256 Train_Acc: 70.369 Val_Loss: 0.5305  BEST VAL Loss: 0.5305  Val_Acc: 73.992

Epoch 77: Validation loss decreased (0.530501 --> 0.530266).  Saving model ...
	 Train_Loss: 0.5252 Train_Acc: 70.469 Val_Loss: 0.5303  BEST VAL Loss: 0.5303  Val_Acc: 73.361

Epoch 78: Validation loss decreased (0.530266 --> 0.529921).  Saving model ...
	 Train_Loss: 0.5248 Train_Acc: 70.490 Val_Loss: 0.5299  BEST VAL Loss: 0.5299  Val_Acc: 72.941

Epoch 79: Validation loss decreased (0.529921 --> 0.529621).  Saving model ...
	 Train_Loss: 0.5244 Train_Acc: 70.463 Val_Loss: 0.5296  BEST VAL Loss: 0.5296  Val_Acc: 73.151

Epoch 80: Validation loss decreased (0.529621 --> 0.529418).  Saving model ...
	 Train_Loss: 0.5240 Train_Acc: 70.484 Val_Loss: 0.5294  BEST VAL Loss: 0.5294  Val_Acc: 73.319

Epoch 81: Validation loss decreased (0.529418 --> 0.529212).  Saving model ...
	 Train_Loss: 0.5235 Train_Acc: 70.695 Val_Loss: 0.5292  BEST VAL Loss: 0.5292  Val_Acc: 72.689

Epoch 82: Validation loss decreased (0.529212 --> 0.528983).  Saving model ...
	 Train_Loss: 0.5230 Train_Acc: 71.068 Val_Loss: 0.5290  BEST VAL Loss: 0.5290  Val_Acc: 73.151

Epoch 83: Validation loss decreased (0.528983 --> 0.528784).  Saving model ...
	 Train_Loss: 0.5226 Train_Acc: 70.547 Val_Loss: 0.5288  BEST VAL Loss: 0.5288  Val_Acc: 73.151

Epoch 84: Validation loss decreased (0.528784 --> 0.528549).  Saving model ...
	 Train_Loss: 0.5222 Train_Acc: 70.695 Val_Loss: 0.5285  BEST VAL Loss: 0.5285  Val_Acc: 72.521

Epoch 85: Validation loss decreased (0.528549 --> 0.528375).  Saving model ...
	 Train_Loss: 0.5218 Train_Acc: 70.794 Val_Loss: 0.5284  BEST VAL Loss: 0.5284  Val_Acc: 73.025

Epoch 86: Validation loss decreased (0.528375 --> 0.528171).  Saving model ...
	 Train_Loss: 0.5215 Train_Acc: 70.227 Val_Loss: 0.5282  BEST VAL Loss: 0.5282  Val_Acc: 73.361

Epoch 87: Validation loss decreased (0.528171 --> 0.527929).  Saving model ...
	 Train_Loss: 0.5212 Train_Acc: 70.301 Val_Loss: 0.5279  BEST VAL Loss: 0.5279  Val_Acc: 74.076

Epoch 88: Validation loss decreased (0.527929 --> 0.527763).  Saving model ...
	 Train_Loss: 0.5207 Train_Acc: 71.068 Val_Loss: 0.5278  BEST VAL Loss: 0.5278  Val_Acc: 73.739

Epoch 89: Validation loss decreased (0.527763 --> 0.527548).  Saving model ...
	 Train_Loss: 0.5203 Train_Acc: 70.936 Val_Loss: 0.5275  BEST VAL Loss: 0.5275  Val_Acc: 73.571

Epoch 90: Validation loss decreased (0.527548 --> 0.527358).  Saving model ...
	 Train_Loss: 0.5199 Train_Acc: 70.547 Val_Loss: 0.5274  BEST VAL Loss: 0.5274  Val_Acc: 74.076

Epoch 91: Validation loss decreased (0.527358 --> 0.527311).  Saving model ...
	 Train_Loss: 0.5196 Train_Acc: 70.453 Val_Loss: 0.5273  BEST VAL Loss: 0.5273  Val_Acc: 72.815

Epoch 92: Validation loss decreased (0.527311 --> 0.527165).  Saving model ...
	 Train_Loss: 0.5192 Train_Acc: 70.831 Val_Loss: 0.5272  BEST VAL Loss: 0.5272  Val_Acc: 73.361

Epoch 93: Validation loss decreased (0.527165 --> 0.527021).  Saving model ...
	 Train_Loss: 0.5188 Train_Acc: 70.826 Val_Loss: 0.5270  BEST VAL Loss: 0.5270  Val_Acc: 74.538

Epoch 94: Validation loss decreased (0.527021 --> 0.526856).  Saving model ...
	 Train_Loss: 0.5184 Train_Acc: 70.322 Val_Loss: 0.5269  BEST VAL Loss: 0.5269  Val_Acc: 73.319

Epoch 95: Validation loss decreased (0.526856 --> 0.526744).  Saving model ...
	 Train_Loss: 0.5181 Train_Acc: 70.332 Val_Loss: 0.5267  BEST VAL Loss: 0.5267  Val_Acc: 73.487

Epoch 96: Validation loss decreased (0.526744 --> 0.526491).  Saving model ...
	 Train_Loss: 0.5177 Train_Acc: 70.884 Val_Loss: 0.5265  BEST VAL Loss: 0.5265  Val_Acc: 73.950

Epoch 97: Validation loss decreased (0.526491 --> 0.526383).  Saving model ...
	 Train_Loss: 0.5174 Train_Acc: 71.099 Val_Loss: 0.5264  BEST VAL Loss: 0.5264  Val_Acc: 73.445

Epoch 98: Validation loss decreased (0.526383 --> 0.526312).  Saving model ...
	 Train_Loss: 0.5170 Train_Acc: 70.920 Val_Loss: 0.5263  BEST VAL Loss: 0.5263  Val_Acc: 73.739

Epoch 99: Validation loss decreased (0.526312 --> 0.526227).  Saving model ...
	 Train_Loss: 0.5167 Train_Acc: 70.474 Val_Loss: 0.5262  BEST VAL Loss: 0.5262  Val_Acc: 73.529

LPS_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.75      0.85      0.80      8633
           1       0.86      0.76      0.81     10401

    accuracy                           0.80     19034
   macro avg       0.80      0.81      0.80     19034
weighted avg       0.81      0.80      0.80     19034

LPS_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.68      0.77      0.73      1080
           1       0.79      0.70      0.74      1300

    accuracy                           0.74      2380
   macro avg       0.74      0.74      0.73      2380
weighted avg       0.74      0.74      0.74      2380

LPS_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.68      0.79      0.73      1080
           1       0.80      0.69      0.74      1300

    accuracy                           0.74      2380
   macro avg       0.74      0.74      0.74      2380
weighted avg       0.74      0.74      0.74      2380

              precision    recall  f1-score   support

           0       0.68      0.79      0.73      1080
           1       0.80      0.69      0.74      1300

    accuracy                           0.74      2380
   macro avg       0.74      0.74      0.74      2380
weighted avg       0.74      0.74      0.74      2380

LPS_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.100_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.57      0.52      0.55      4135
           1       0.59      0.64      0.61      4509

    accuracy                           0.58      8644
   macro avg       0.58      0.58      0.58      8644
weighted avg       0.58      0.58      0.58      8644

              precision    recall  f1-score   support

           0       0.57      0.52      0.55      4135
           1       0.59      0.64      0.61      4509

    accuracy                           0.58      8644
   macro avg       0.58      0.58      0.58      8644
weighted avg       0.58      0.58      0.58      8644

completed
