[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '6ef8259d'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'dba5c06e'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '12b655a0'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '89af354d'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: DMSO_0.100_DMSO_0.025 treatment_name: Thapsigargin_10.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: DMSO_0.100_DMSO_0.025
TREATMENT_NAME: Thapsigargin_10.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'Thapsigargin_10.000_DMSO_0.025']
The dimensions of the data are: (48855, 1276)
Number of total missing values across all columns: 97710
Data Subset Is Off
Wells held out for testing: ['I14' 'L14']
Wells to use for training, validation, and testing ['B14' 'C14' 'E14' 'B15' 'C15' 'E15' 'J14' 'I15' 'J15' 'L15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.490417).  Saving model ...
	 Train_Loss: 0.6053 Train_Acc: 78.851 Val_Loss: 0.4904  BEST VAL Loss: 0.4904  Val_Acc: 91.740

Epoch 1: Validation loss decreased (0.490417 --> 0.445596).  Saving model ...
	 Train_Loss: 0.5366 Train_Acc: 88.124 Val_Loss: 0.4456  BEST VAL Loss: 0.4456  Val_Acc: 92.134

Epoch 2: Validation loss decreased (0.445596 --> 0.405323).  Saving model ...
	 Train_Loss: 0.4898 Train_Acc: 89.230 Val_Loss: 0.4053  BEST VAL Loss: 0.4053  Val_Acc: 92.871

Epoch 3: Validation loss decreased (0.405323 --> 0.376015).  Saving model ...
	 Train_Loss: 0.4568 Train_Acc: 89.621 Val_Loss: 0.3760  BEST VAL Loss: 0.3760  Val_Acc: 93.363

Epoch 4: Validation loss decreased (0.376015 --> 0.354600).  Saving model ...
	 Train_Loss: 0.4320 Train_Acc: 90.039 Val_Loss: 0.3546  BEST VAL Loss: 0.3546  Val_Acc: 93.437

Epoch 5: Validation loss decreased (0.354600 --> 0.335751).  Saving model ...
	 Train_Loss: 0.4129 Train_Acc: 90.177 Val_Loss: 0.3358  BEST VAL Loss: 0.3358  Val_Acc: 93.633

Epoch 6: Validation loss decreased (0.335751 --> 0.320388).  Saving model ...
	 Train_Loss: 0.3970 Train_Acc: 90.641 Val_Loss: 0.3204  BEST VAL Loss: 0.3204  Val_Acc: 93.584

Epoch 7: Validation loss decreased (0.320388 --> 0.309742).  Saving model ...
	 Train_Loss: 0.3841 Train_Acc: 90.789 Val_Loss: 0.3097  BEST VAL Loss: 0.3097  Val_Acc: 93.437

Epoch 8: Validation loss decreased (0.309742 --> 0.299483).  Saving model ...
	 Train_Loss: 0.3732 Train_Acc: 91.096 Val_Loss: 0.2995  BEST VAL Loss: 0.2995  Val_Acc: 93.977

Epoch 9: Validation loss decreased (0.299483 --> 0.290401).  Saving model ...
	 Train_Loss: 0.3640 Train_Acc: 91.265 Val_Loss: 0.2904  BEST VAL Loss: 0.2904  Val_Acc: 94.543

Epoch 10: Validation loss decreased (0.290401 --> 0.282324).  Saving model ...
	 Train_Loss: 0.3557 Train_Acc: 91.508 Val_Loss: 0.2823  BEST VAL Loss: 0.2823  Val_Acc: 93.904

Epoch 11: Validation loss decreased (0.282324 --> 0.275256).  Saving model ...
	 Train_Loss: 0.3482 Train_Acc: 91.459 Val_Loss: 0.2753  BEST VAL Loss: 0.2753  Val_Acc: 93.805

Epoch 12: Validation loss decreased (0.275256 --> 0.267593).  Saving model ...
	 Train_Loss: 0.3411 Train_Acc: 91.554 Val_Loss: 0.2676  BEST VAL Loss: 0.2676  Val_Acc: 94.641

Epoch 13: Validation loss decreased (0.267593 --> 0.260807).  Saving model ...
	 Train_Loss: 0.3351 Train_Acc: 91.373 Val_Loss: 0.2608  BEST VAL Loss: 0.2608  Val_Acc: 94.666

Epoch 14: Validation loss decreased (0.260807 --> 0.256865).  Saving model ...
	 Train_Loss: 0.3295 Train_Acc: 91.385 Val_Loss: 0.2569  BEST VAL Loss: 0.2569  Val_Acc: 93.609

Epoch 15: Validation loss decreased (0.256865 --> 0.252434).  Saving model ...
	 Train_Loss: 0.3244 Train_Acc: 91.284 Val_Loss: 0.2524  BEST VAL Loss: 0.2524  Val_Acc: 94.371

Epoch 16: Validation loss decreased (0.252434 --> 0.248238).  Saving model ...
	 Train_Loss: 0.3192 Train_Acc: 91.111 Val_Loss: 0.2482  BEST VAL Loss: 0.2482  Val_Acc: 94.789

Epoch 17: Validation loss decreased (0.248238 --> 0.243419).  Saving model ...
	 Train_Loss: 0.3139 Train_Acc: 91.394 Val_Loss: 0.2434  BEST VAL Loss: 0.2434  Val_Acc: 94.789

Epoch 18: Validation loss decreased (0.243419 --> 0.239315).  Saving model ...
	 Train_Loss: 0.3092 Train_Acc: 90.939 Val_Loss: 0.2393  BEST VAL Loss: 0.2393  Val_Acc: 94.322

Epoch 19: Validation loss decreased (0.239315 --> 0.235662).  Saving model ...
	 Train_Loss: 0.3050 Train_Acc: 91.170 Val_Loss: 0.2357  BEST VAL Loss: 0.2357  Val_Acc: 94.494

Epoch 20: Validation loss decreased (0.235662 --> 0.233011).  Saving model ...
	 Train_Loss: 0.3009 Train_Acc: 91.234 Val_Loss: 0.2330  BEST VAL Loss: 0.2330  Val_Acc: 93.535

Epoch 21: Validation loss decreased (0.233011 --> 0.229857).  Saving model ...
	 Train_Loss: 0.2972 Train_Acc: 91.065 Val_Loss: 0.2299  BEST VAL Loss: 0.2299  Val_Acc: 93.879

Epoch 22: Validation loss decreased (0.229857 --> 0.227422).  Saving model ...
	 Train_Loss: 0.2936 Train_Acc: 91.465 Val_Loss: 0.2274  BEST VAL Loss: 0.2274  Val_Acc: 94.567

Epoch 23: Validation loss decreased (0.227422 --> 0.225448).  Saving model ...
	 Train_Loss: 0.2901 Train_Acc: 91.459 Val_Loss: 0.2254  BEST VAL Loss: 0.2254  Val_Acc: 94.027

Epoch 24: Validation loss decreased (0.225448 --> 0.223554).  Saving model ...
	 Train_Loss: 0.2869 Train_Acc: 91.609 Val_Loss: 0.2236  BEST VAL Loss: 0.2236  Val_Acc: 93.068

Epoch 25: Validation loss decreased (0.223554 --> 0.221496).  Saving model ...
	 Train_Loss: 0.2837 Train_Acc: 91.551 Val_Loss: 0.2215  BEST VAL Loss: 0.2215  Val_Acc: 94.395

Epoch 26: Validation loss decreased (0.221496 --> 0.219426).  Saving model ...
	 Train_Loss: 0.2807 Train_Acc: 91.867 Val_Loss: 0.2194  BEST VAL Loss: 0.2194  Val_Acc: 94.199

Epoch 27: Validation loss decreased (0.219426 --> 0.218130).  Saving model ...
	 Train_Loss: 0.2781 Train_Acc: 91.563 Val_Loss: 0.2181  BEST VAL Loss: 0.2181  Val_Acc: 94.272

Epoch 28: Validation loss decreased (0.218130 --> 0.216257).  Saving model ...
	 Train_Loss: 0.2754 Train_Acc: 91.711 Val_Loss: 0.2163  BEST VAL Loss: 0.2163  Val_Acc: 94.641

Epoch 29: Validation loss decreased (0.216257 --> 0.214816).  Saving model ...
	 Train_Loss: 0.2730 Train_Acc: 91.741 Val_Loss: 0.2148  BEST VAL Loss: 0.2148  Val_Acc: 93.068

Epoch 30: Validation loss decreased (0.214816 --> 0.212892).  Saving model ...
	 Train_Loss: 0.2705 Train_Acc: 91.652 Val_Loss: 0.2129  BEST VAL Loss: 0.2129  Val_Acc: 94.223

Epoch 31: Validation loss decreased (0.212892 --> 0.211525).  Saving model ...
	 Train_Loss: 0.2681 Train_Acc: 91.864 Val_Loss: 0.2115  BEST VAL Loss: 0.2115  Val_Acc: 94.297

Epoch 32: Validation loss decreased (0.211525 --> 0.210619).  Saving model ...
	 Train_Loss: 0.2659 Train_Acc: 91.960 Val_Loss: 0.2106  BEST VAL Loss: 0.2106  Val_Acc: 93.461

Epoch 33: Validation loss decreased (0.210619 --> 0.209683).  Saving model ...
	 Train_Loss: 0.2639 Train_Acc: 91.542 Val_Loss: 0.2097  BEST VAL Loss: 0.2097  Val_Acc: 94.715

Epoch 34: Validation loss decreased (0.209683 --> 0.207799).  Saving model ...
	 Train_Loss: 0.2619 Train_Acc: 92.003 Val_Loss: 0.2078  BEST VAL Loss: 0.2078  Val_Acc: 94.592

Epoch 35: Validation loss decreased (0.207799 --> 0.206678).  Saving model ...
	 Train_Loss: 0.2600 Train_Acc: 92.012 Val_Loss: 0.2067  BEST VAL Loss: 0.2067  Val_Acc: 93.830

Epoch 36: Validation loss decreased (0.206678 --> 0.205578).  Saving model ...
	 Train_Loss: 0.2582 Train_Acc: 91.714 Val_Loss: 0.2056  BEST VAL Loss: 0.2056  Val_Acc: 95.157

Epoch 37: Validation loss decreased (0.205578 --> 0.204692).  Saving model ...
	 Train_Loss: 0.2564 Train_Acc: 92.156 Val_Loss: 0.2047  BEST VAL Loss: 0.2047  Val_Acc: 94.469

Epoch 38: Validation loss decreased (0.204692 --> 0.203113).  Saving model ...
	 Train_Loss: 0.2548 Train_Acc: 92.037 Val_Loss: 0.2031  BEST VAL Loss: 0.2031  Val_Acc: 94.961

Epoch 39: Validation loss decreased (0.203113 --> 0.201999).  Saving model ...
	 Train_Loss: 0.2532 Train_Acc: 91.874 Val_Loss: 0.2020  BEST VAL Loss: 0.2020  Val_Acc: 94.395

Epoch 40: Validation loss decreased (0.201999 --> 0.200536).  Saving model ...
	 Train_Loss: 0.2516 Train_Acc: 91.637 Val_Loss: 0.2005  BEST VAL Loss: 0.2005  Val_Acc: 94.543

Epoch 41: Validation loss decreased (0.200536 --> 0.199165).  Saving model ...
	 Train_Loss: 0.2501 Train_Acc: 91.993 Val_Loss: 0.1992  BEST VAL Loss: 0.1992  Val_Acc: 94.617

Epoch 42: Validation loss decreased (0.199165 --> 0.197854).  Saving model ...
	 Train_Loss: 0.2487 Train_Acc: 92.129 Val_Loss: 0.1979  BEST VAL Loss: 0.1979  Val_Acc: 94.002

Epoch 43: Validation loss decreased (0.197854 --> 0.196930).  Saving model ...
	 Train_Loss: 0.2473 Train_Acc: 91.960 Val_Loss: 0.1969  BEST VAL Loss: 0.1969  Val_Acc: 93.559

Epoch 44: Validation loss decreased (0.196930 --> 0.196371).  Saving model ...
	 Train_Loss: 0.2461 Train_Acc: 91.717 Val_Loss: 0.1964  BEST VAL Loss: 0.1964  Val_Acc: 94.272

Epoch 45: Validation loss decreased (0.196371 --> 0.195447).  Saving model ...
	 Train_Loss: 0.2450 Train_Acc: 91.824 Val_Loss: 0.1954  BEST VAL Loss: 0.1954  Val_Acc: 94.985

Epoch 46: Validation loss decreased (0.195447 --> 0.194840).  Saving model ...
	 Train_Loss: 0.2438 Train_Acc: 91.646 Val_Loss: 0.1948  BEST VAL Loss: 0.1948  Val_Acc: 94.518

Epoch 47: Validation loss decreased (0.194840 --> 0.193891).  Saving model ...
	 Train_Loss: 0.2425 Train_Acc: 91.898 Val_Loss: 0.1939  BEST VAL Loss: 0.1939  Val_Acc: 94.149

Epoch 48: Validation loss decreased (0.193891 --> 0.193193).  Saving model ...
	 Train_Loss: 0.2413 Train_Acc: 92.276 Val_Loss: 0.1932  BEST VAL Loss: 0.1932  Val_Acc: 94.617

Epoch 49: Validation loss decreased (0.193193 --> 0.192226).  Saving model ...
	 Train_Loss: 0.2402 Train_Acc: 92.153 Val_Loss: 0.1922  BEST VAL Loss: 0.1922  Val_Acc: 94.543

Epoch 50: Validation loss decreased (0.192226 --> 0.191482).  Saving model ...
	 Train_Loss: 0.2391 Train_Acc: 92.083 Val_Loss: 0.1915  BEST VAL Loss: 0.1915  Val_Acc: 94.715

Epoch 51: Validation loss decreased (0.191482 --> 0.190996).  Saving model ...
	 Train_Loss: 0.2380 Train_Acc: 92.667 Val_Loss: 0.1910  BEST VAL Loss: 0.1910  Val_Acc: 94.272

Epoch 52: Validation loss decreased (0.190996 --> 0.190787).  Saving model ...
	 Train_Loss: 0.2370 Train_Acc: 92.430 Val_Loss: 0.1908  BEST VAL Loss: 0.1908  Val_Acc: 94.715

Epoch 53: Validation loss decreased (0.190787 --> 0.190155).  Saving model ...
	 Train_Loss: 0.2360 Train_Acc: 92.249 Val_Loss: 0.1902  BEST VAL Loss: 0.1902  Val_Acc: 94.813

Epoch 54: Validation loss decreased (0.190155 --> 0.190011).  Saving model ...
	 Train_Loss: 0.2350 Train_Acc: 92.507 Val_Loss: 0.1900  BEST VAL Loss: 0.1900  Val_Acc: 94.764

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.2341 Train_Acc: 92.479 Val_Loss: 0.1901  BEST VAL Loss: 0.1900  Val_Acc: 94.297

Epoch 56: Validation loss decreased (0.190011 --> 0.189425).  Saving model ...
	 Train_Loss: 0.2332 Train_Acc: 92.667 Val_Loss: 0.1894  BEST VAL Loss: 0.1894  Val_Acc: 94.862

Epoch 57: Validation loss decreased (0.189425 --> 0.188821).  Saving model ...
	 Train_Loss: 0.2324 Train_Acc: 92.206 Val_Loss: 0.1888  BEST VAL Loss: 0.1888  Val_Acc: 93.928

Epoch 58: Validation loss decreased (0.188821 --> 0.188045).  Saving model ...
	 Train_Loss: 0.2316 Train_Acc: 92.479 Val_Loss: 0.1880  BEST VAL Loss: 0.1880  Val_Acc: 94.420

Epoch 59: Validation loss decreased (0.188045 --> 0.187591).  Saving model ...
	 Train_Loss: 0.2307 Train_Acc: 92.654 Val_Loss: 0.1876  BEST VAL Loss: 0.1876  Val_Acc: 94.592

Epoch 60: Validation loss decreased (0.187591 --> 0.186901).  Saving model ...
	 Train_Loss: 0.2299 Train_Acc: 92.359 Val_Loss: 0.1869  BEST VAL Loss: 0.1869  Val_Acc: 94.617

Epoch 61: Validation loss decreased (0.186901 --> 0.186699).  Saving model ...
	 Train_Loss: 0.2290 Train_Acc: 92.415 Val_Loss: 0.1867  BEST VAL Loss: 0.1867  Val_Acc: 94.494

Epoch 62: Validation loss decreased (0.186699 --> 0.186368).  Saving model ...
	 Train_Loss: 0.2283 Train_Acc: 92.215 Val_Loss: 0.1864  BEST VAL Loss: 0.1864  Val_Acc: 94.100

Epoch 63: Validation loss decreased (0.186368 --> 0.186186).  Saving model ...
	 Train_Loss: 0.2276 Train_Acc: 92.249 Val_Loss: 0.1862  BEST VAL Loss: 0.1862  Val_Acc: 94.494

Epoch 64: Validation loss decreased (0.186186 --> 0.185902).  Saving model ...
	 Train_Loss: 0.2269 Train_Acc: 92.273 Val_Loss: 0.1859  BEST VAL Loss: 0.1859  Val_Acc: 93.707

Epoch 65: Validation loss decreased (0.185902 --> 0.185478).  Saving model ...
	 Train_Loss: 0.2262 Train_Acc: 92.181 Val_Loss: 0.1855  BEST VAL Loss: 0.1855  Val_Acc: 94.789

Epoch 66: Validation loss decreased (0.185478 --> 0.185264).  Saving model ...
	 Train_Loss: 0.2255 Train_Acc: 92.390 Val_Loss: 0.1853  BEST VAL Loss: 0.1853  Val_Acc: 94.617

Epoch 67: Validation loss decreased (0.185264 --> 0.185076).  Saving model ...
	 Train_Loss: 0.2249 Train_Acc: 92.301 Val_Loss: 0.1851  BEST VAL Loss: 0.1851  Val_Acc: 93.879

Epoch 68: Validation loss decreased (0.185076 --> 0.184688).  Saving model ...
	 Train_Loss: 0.2242 Train_Acc: 92.396 Val_Loss: 0.1847  BEST VAL Loss: 0.1847  Val_Acc: 94.297

Epoch 69: Validation loss decreased (0.184688 --> 0.184177).  Saving model ...
	 Train_Loss: 0.2235 Train_Acc: 92.396 Val_Loss: 0.1842  BEST VAL Loss: 0.1842  Val_Acc: 94.641

Epoch 70: Validation loss decreased (0.184177 --> 0.183861).  Saving model ...
	 Train_Loss: 0.2229 Train_Acc: 92.584 Val_Loss: 0.1839  BEST VAL Loss: 0.1839  Val_Acc: 93.068

Epoch 71: Validation loss decreased (0.183861 --> 0.183677).  Saving model ...
	 Train_Loss: 0.2223 Train_Acc: 92.310 Val_Loss: 0.1837  BEST VAL Loss: 0.1837  Val_Acc: 94.617

Epoch 72: Validation loss decreased (0.183677 --> 0.183175).  Saving model ...
	 Train_Loss: 0.2217 Train_Acc: 92.670 Val_Loss: 0.1832  BEST VAL Loss: 0.1832  Val_Acc: 94.051

Epoch 73: Validation loss decreased (0.183175 --> 0.182857).  Saving model ...
	 Train_Loss: 0.2212 Train_Acc: 92.325 Val_Loss: 0.1829  BEST VAL Loss: 0.1829  Val_Acc: 94.912

Epoch 74: Validation loss decreased (0.182857 --> 0.182447).  Saving model ...
	 Train_Loss: 0.2207 Train_Acc: 92.270 Val_Loss: 0.1824  BEST VAL Loss: 0.1824  Val_Acc: 94.322

Epoch 75: Validation loss decreased (0.182447 --> 0.181915).  Saving model ...
	 Train_Loss: 0.2202 Train_Acc: 92.080 Val_Loss: 0.1819  BEST VAL Loss: 0.1819  Val_Acc: 94.518

Epoch 76: Validation loss decreased (0.181915 --> 0.181439).  Saving model ...
	 Train_Loss: 0.2197 Train_Acc: 92.061 Val_Loss: 0.1814  BEST VAL Loss: 0.1814  Val_Acc: 94.346

Epoch 77: Validation loss decreased (0.181439 --> 0.180905).  Saving model ...
	 Train_Loss: 0.2192 Train_Acc: 92.150 Val_Loss: 0.1809  BEST VAL Loss: 0.1809  Val_Acc: 94.813

Epoch 78: Validation loss decreased (0.180905 --> 0.180647).  Saving model ...
	 Train_Loss: 0.2187 Train_Acc: 92.375 Val_Loss: 0.1806  BEST VAL Loss: 0.1806  Val_Acc: 94.076

Epoch 79: Validation loss decreased (0.180647 --> 0.180430).  Saving model ...
	 Train_Loss: 0.2182 Train_Acc: 92.596 Val_Loss: 0.1804  BEST VAL Loss: 0.1804  Val_Acc: 94.051

Epoch 80: Validation loss decreased (0.180430 --> 0.180366).  Saving model ...
	 Train_Loss: 0.2178 Train_Acc: 92.153 Val_Loss: 0.1804  BEST VAL Loss: 0.1804  Val_Acc: 94.469

Epoch 81: Validation loss decreased (0.180366 --> 0.180080).  Saving model ...
	 Train_Loss: 0.2173 Train_Acc: 92.565 Val_Loss: 0.1801  BEST VAL Loss: 0.1801  Val_Acc: 94.125

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.2169 Train_Acc: 92.783 Val_Loss: 0.1802  BEST VAL Loss: 0.1801  Val_Acc: 95.084

Epoch 83: Validation loss decreased (0.180080 --> 0.179935).  Saving model ...
	 Train_Loss: 0.2165 Train_Acc: 92.568 Val_Loss: 0.1799  BEST VAL Loss: 0.1799  Val_Acc: 94.543

Epoch 84: Validation loss decreased (0.179935 --> 0.179544).  Saving model ...
	 Train_Loss: 0.2161 Train_Acc: 92.150 Val_Loss: 0.1795  BEST VAL Loss: 0.1795  Val_Acc: 94.789

Epoch 85: Validation loss decreased (0.179544 --> 0.179193).  Saving model ...
	 Train_Loss: 0.2156 Train_Acc: 92.427 Val_Loss: 0.1792  BEST VAL Loss: 0.1792  Val_Acc: 94.789

Epoch 86: Validation loss decreased (0.179193 --> 0.178944).  Saving model ...
	 Train_Loss: 0.2151 Train_Acc: 92.375 Val_Loss: 0.1789  BEST VAL Loss: 0.1789  Val_Acc: 94.469

Epoch 87: Validation loss decreased (0.178944 --> 0.178577).  Saving model ...
	 Train_Loss: 0.2147 Train_Acc: 92.488 Val_Loss: 0.1786  BEST VAL Loss: 0.1786  Val_Acc: 94.985

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.2142 Train_Acc: 92.470 Val_Loss: 0.1786  BEST VAL Loss: 0.1786  Val_Acc: 94.371

Epoch 89: Validation loss decreased (0.178577 --> 0.178553).  Saving model ...
	 Train_Loss: 0.2138 Train_Acc: 92.544 Val_Loss: 0.1786  BEST VAL Loss: 0.1786  Val_Acc: 94.690

Epoch 90: Validation loss decreased (0.178553 --> 0.178422).  Saving model ...
	 Train_Loss: 0.2133 Train_Acc: 92.771 Val_Loss: 0.1784  BEST VAL Loss: 0.1784  Val_Acc: 94.149

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.2130 Train_Acc: 92.504 Val_Loss: 0.1788  BEST VAL Loss: 0.1784  Val_Acc: 94.371

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.2125 Train_Acc: 92.716 Val_Loss: 0.1788  BEST VAL Loss: 0.1784  Val_Acc: 94.420

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.2120 Train_Acc: 93.054 Val_Loss: 0.1786  BEST VAL Loss: 0.1784  Val_Acc: 94.739

Epoch 94: Validation loss decreased (0.178422 --> 0.178318).  Saving model ...
	 Train_Loss: 0.2116 Train_Acc: 93.164 Val_Loss: 0.1783  BEST VAL Loss: 0.1783  Val_Acc: 94.617

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.2111 Train_Acc: 92.955 Val_Loss: 0.1792  BEST VAL Loss: 0.1783  Val_Acc: 94.666

Epoch 96: Validation loss did not decrease
	 Train_Loss: 0.2108 Train_Acc: 92.676 Val_Loss: 0.1790  BEST VAL Loss: 0.1783  Val_Acc: 94.690

Epoch 97: Validation loss did not decrease
	 Train_Loss: 0.2104 Train_Acc: 92.648 Val_Loss: 0.1789  BEST VAL Loss: 0.1783  Val_Acc: 93.953

Epoch 98: Validation loss did not decrease
	 Train_Loss: 0.2099 Train_Acc: 92.943 Val_Loss: 0.1787  BEST VAL Loss: 0.1783  Val_Acc: 94.838

Epoch 99: Validation loss did not decrease
	 Train_Loss: 0.2095 Train_Acc: 92.983 Val_Loss: 0.1788  BEST VAL Loss: 0.1783  Val_Acc: 94.322

DMSO_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.76      0.79      0.77     24644
           1       0.24      0.20      0.22      7892

    accuracy                           0.65     32536
   macro avg       0.50      0.50      0.50     32536
weighted avg       0.63      0.65      0.64     32536

DMSO_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.76      0.80      0.78      3081
           1       0.24      0.19      0.21       987

    accuracy                           0.65      4068
   macro avg       0.50      0.50      0.49      4068
weighted avg       0.63      0.65      0.64      4068

DMSO_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.76      0.80      0.78      3081
           1       0.26      0.22      0.24       987

    accuracy                           0.66      4068
   macro avg       0.51      0.51      0.51      4068
weighted avg       0.64      0.66      0.65      4068

              precision    recall  f1-score   support

           0       0.76      0.80      0.78      3081
           1       0.26      0.22      0.24       987

    accuracy                           0.66      4068
   macro avg       0.51      0.51      0.51      4068
weighted avg       0.64      0.66      0.65      4068

DMSO_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
DMSO_0.100_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.59      0.66      0.62      4837
           1       0.40      0.33      0.36      3346

    accuracy                           0.53      8183
   macro avg       0.50      0.50      0.49      8183
weighted avg       0.51      0.53      0.52      8183

              precision    recall  f1-score   support

           0       0.59      0.66      0.62      4837
           1       0.40      0.33      0.36      3346

    accuracy                           0.53      8183
   macro avg       0.50      0.50      0.49      8183
weighted avg       0.51      0.53      0.52      8183

completed
