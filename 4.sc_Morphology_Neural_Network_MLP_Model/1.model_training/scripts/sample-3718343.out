[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 18688 bytes to train_binary_model.py
[NbConvertApp] Converting notebook ../notebooks/train_multiclass_model.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: MissingIDFieldWarning: Code cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.
  validate(nb)
[NbConvertApp] Writing 31106 bytes to train_multiclass_model.py
[NbConvertApp] Converting notebook ../notebooks/train_regression_model.ipynb to script
[NbConvertApp] Writing 25120 bytes to train_regression_model.py
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:313: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels.drop_duplicates(inplace=True)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1015: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1016: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1015: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1016: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1036: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:577: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:651: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1219: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:879: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1219: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:1095: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
SHSY5Y MultiClass_MLP_h202_remove True
[0.954878893196544, 0.4803479499984947, 0.5647731568049614]
Data Subset Is Off
(156754,) (39189,) (230445,) (144614,)
(156754,) (39189,) (230445,) (144614,)
571002
(7972,) (85003,) (63779,)
(1993,) (21251,) (15945,)
(9965,) (106254,) (114226,)
(7048,) (71293,) (66273,)
(156754, 1251) (39189, 1251) (230445, 1251) (144614, 1251)
(156754,) (39189,) (230445,) (144614,)
Number of in features:  1251
Number of out features:  3
Multi_Class
SGD
Epoch 0: Validation loss decreased (inf --> 0.616579).  Saving model ...
	 Train_Loss: 0.6836 Train_Acc: 68.408 Val_Loss: 0.6166  BEST VAL Loss: 0.6166  Val_Acc: 70.607

Epoch 1: Validation loss decreased (0.616579 --> 0.606370).  Saving model ...
	 Train_Loss: 0.6571 Train_Acc: 70.281 Val_Loss: 0.6064  BEST VAL Loss: 0.6064  Val_Acc: 71.211

Epoch 2: Validation loss decreased (0.606370 --> 0.600042).  Saving model ...
	 Train_Loss: 0.6427 Train_Acc: 70.952 Val_Loss: 0.6000  BEST VAL Loss: 0.6000  Val_Acc: 71.500

Epoch 3: Validation loss decreased (0.600042 --> 0.594339).  Saving model ...
	 Train_Loss: 0.6323 Train_Acc: 71.481 Val_Loss: 0.5943  BEST VAL Loss: 0.5943  Val_Acc: 72.719

Epoch 4: Validation loss decreased (0.594339 --> 0.589322).  Saving model ...
	 Train_Loss: 0.6243 Train_Acc: 71.833 Val_Loss: 0.5893  BEST VAL Loss: 0.5893  Val_Acc: 72.944

Epoch 5: Validation loss decreased (0.589322 --> 0.585256).  Saving model ...
	 Train_Loss: 0.6181 Train_Acc: 71.955 Val_Loss: 0.5853  BEST VAL Loss: 0.5853  Val_Acc: 73.018

Epoch 6: Validation loss decreased (0.585256 --> 0.582488).  Saving model ...
	 Train_Loss: 0.6125 Train_Acc: 72.339 Val_Loss: 0.5825  BEST VAL Loss: 0.5825  Val_Acc: 73.709

Epoch 7: Validation loss decreased (0.582488 --> 0.581741).  Saving model ...
	 Train_Loss: 0.6078 Train_Acc: 72.510 Val_Loss: 0.5817  BEST VAL Loss: 0.5817  Val_Acc: 73.574

Epoch 8: Validation loss decreased (0.581741 --> 0.579779).  Saving model ...
	 Train_Loss: 0.6035 Train_Acc: 72.750 Val_Loss: 0.5798  BEST VAL Loss: 0.5798  Val_Acc: 74.171

Epoch 9: Validation loss decreased (0.579779 --> 0.576992).  Saving model ...
	 Train_Loss: 0.5997 Train_Acc: 72.870 Val_Loss: 0.5770  BEST VAL Loss: 0.5770  Val_Acc: 73.735

Epoch 10: Validation loss decreased (0.576992 --> 0.575135).  Saving model ...
	 Train_Loss: 0.5963 Train_Acc: 73.197 Val_Loss: 0.5751  BEST VAL Loss: 0.5751  Val_Acc: 73.508

Epoch 11: Validation loss decreased (0.575135 --> 0.573666).  Saving model ...
	 Train_Loss: 0.5932 Train_Acc: 73.310 Val_Loss: 0.5737  BEST VAL Loss: 0.5737  Val_Acc: 74.110

Epoch 12: Validation loss decreased (0.573666 --> 0.572416).  Saving model ...
	 Train_Loss: 0.5905 Train_Acc: 73.277 Val_Loss: 0.5724  BEST VAL Loss: 0.5724  Val_Acc: 74.707

Epoch 13: Validation loss decreased (0.572416 --> 0.571165).  Saving model ...
	 Train_Loss: 0.5879 Train_Acc: 73.544 Val_Loss: 0.5712  BEST VAL Loss: 0.5712  Val_Acc: 74.202

Epoch 14: Validation loss decreased (0.571165 --> 0.569771).  Saving model ...
	 Train_Loss: 0.5855 Train_Acc: 73.604 Val_Loss: 0.5698  BEST VAL Loss: 0.5698  Val_Acc: 74.230

Epoch 15: Validation loss decreased (0.569771 --> 0.568979).  Saving model ...
	 Train_Loss: 0.5832 Train_Acc: 73.710 Val_Loss: 0.5690  BEST VAL Loss: 0.5690  Val_Acc: 74.016

Epoch 16: Validation loss decreased (0.568979 --> 0.567535).  Saving model ...
	 Train_Loss: 0.5811 Train_Acc: 73.738 Val_Loss: 0.5675  BEST VAL Loss: 0.5675  Val_Acc: 74.284

Epoch 17: Validation loss decreased (0.567535 --> 0.566601).  Saving model ...
	 Train_Loss: 0.5791 Train_Acc: 73.927 Val_Loss: 0.5666  BEST VAL Loss: 0.5666  Val_Acc: 73.480

Epoch 18: Validation loss decreased (0.566601 --> 0.565527).  Saving model ...
	 Train_Loss: 0.5772 Train_Acc: 73.918 Val_Loss: 0.5655  BEST VAL Loss: 0.5655  Val_Acc: 74.337

Epoch 19: Validation loss decreased (0.565527 --> 0.564641).  Saving model ...
	 Train_Loss: 0.5755 Train_Acc: 74.001 Val_Loss: 0.5646  BEST VAL Loss: 0.5646  Val_Acc: 74.276

Epoch 20: Validation loss decreased (0.564641 --> 0.563716).  Saving model ...
	 Train_Loss: 0.5738 Train_Acc: 74.153 Val_Loss: 0.5637  BEST VAL Loss: 0.5637  Val_Acc: 74.776

Epoch 21: Validation loss decreased (0.563716 --> 0.562808).  Saving model ...
	 Train_Loss: 0.5721 Train_Acc: 74.325 Val_Loss: 0.5628  BEST VAL Loss: 0.5628  Val_Acc: 75.008

Epoch 22: Validation loss decreased (0.562808 --> 0.561907).  Saving model ...
	 Train_Loss: 0.5705 Train_Acc: 74.313 Val_Loss: 0.5619  BEST VAL Loss: 0.5619  Val_Acc: 74.567

Epoch 23: Validation loss decreased (0.561907 --> 0.560935).  Saving model ...
	 Train_Loss: 0.5690 Train_Acc: 74.420 Val_Loss: 0.5609  BEST VAL Loss: 0.5609  Val_Acc: 74.983

Epoch 24: Validation loss decreased (0.560935 --> 0.560102).  Saving model ...
	 Train_Loss: 0.5676 Train_Acc: 74.450 Val_Loss: 0.5601  BEST VAL Loss: 0.5601  Val_Acc: 75.440

Epoch 25: Validation loss decreased (0.560102 --> 0.559367).  Saving model ...
	 Train_Loss: 0.5662 Train_Acc: 74.413 Val_Loss: 0.5594  BEST VAL Loss: 0.5594  Val_Acc: 74.830

Epoch 26: Validation loss decreased (0.559367 --> 0.558689).  Saving model ...
	 Train_Loss: 0.5649 Train_Acc: 74.579 Val_Loss: 0.5587  BEST VAL Loss: 0.5587  Val_Acc: 75.202

Epoch 27: Validation loss decreased (0.558689 --> 0.557980).  Saving model ...
	 Train_Loss: 0.5636 Train_Acc: 74.611 Val_Loss: 0.5580  BEST VAL Loss: 0.5580  Val_Acc: 75.080

Epoch 28: Validation loss decreased (0.557980 --> 0.557398).  Saving model ...
	 Train_Loss: 0.5624 Train_Acc: 74.612 Val_Loss: 0.5574  BEST VAL Loss: 0.5574  Val_Acc: 74.819

Epoch 29: Validation loss decreased (0.557398 --> 0.556902).  Saving model ...
	 Train_Loss: 0.5612 Train_Acc: 74.801 Val_Loss: 0.5569  BEST VAL Loss: 0.5569  Val_Acc: 75.072

Epoch 30: Validation loss decreased (0.556902 --> 0.556402).  Saving model ...
	 Train_Loss: 0.5601 Train_Acc: 74.725 Val_Loss: 0.5564  BEST VAL Loss: 0.5564  Val_Acc: 75.327

Epoch 31: Validation loss decreased (0.556402 --> 0.555927).  Saving model ...
	 Train_Loss: 0.5590 Train_Acc: 74.722 Val_Loss: 0.5559  BEST VAL Loss: 0.5559  Val_Acc: 74.574

Epoch 32: Validation loss decreased (0.555927 --> 0.555431).  Saving model ...
	 Train_Loss: 0.5579 Train_Acc: 74.819 Val_Loss: 0.5554  BEST VAL Loss: 0.5554  Val_Acc: 75.360

Epoch 33: Validation loss decreased (0.555431 --> 0.555104).  Saving model ...
	 Train_Loss: 0.5570 Train_Acc: 74.742 Val_Loss: 0.5551  BEST VAL Loss: 0.5551  Val_Acc: 75.279

Epoch 34: Validation loss decreased (0.555104 --> 0.554773).  Saving model ...
	 Train_Loss: 0.5560 Train_Acc: 74.914 Val_Loss: 0.5548  BEST VAL Loss: 0.5548  Val_Acc: 74.552

Epoch 35: Validation loss decreased (0.554773 --> 0.554325).  Saving model ...
	 Train_Loss: 0.5551 Train_Acc: 74.806 Val_Loss: 0.5543  BEST VAL Loss: 0.5543  Val_Acc: 74.937

Epoch 36: Validation loss decreased (0.554325 --> 0.554029).  Saving model ...
	 Train_Loss: 0.5542 Train_Acc: 74.847 Val_Loss: 0.5540  BEST VAL Loss: 0.5540  Val_Acc: 74.960

Epoch 37: Validation loss decreased (0.554029 --> 0.553999).  Saving model ...
	 Train_Loss: 0.5533 Train_Acc: 74.861 Val_Loss: 0.5540  BEST VAL Loss: 0.5540  Val_Acc: 74.868

Epoch 38: Validation loss decreased (0.553999 --> 0.553632).  Saving model ...
	 Train_Loss: 0.5524 Train_Acc: 75.040 Val_Loss: 0.5536  BEST VAL Loss: 0.5536  Val_Acc: 75.381

Epoch 39: Validation loss decreased (0.553632 --> 0.553304).  Saving model ...
	 Train_Loss: 0.5516 Train_Acc: 75.005 Val_Loss: 0.5533  BEST VAL Loss: 0.5533  Val_Acc: 75.511

Epoch 40: Validation loss decreased (0.553304 --> 0.553057).  Saving model ...
	 Train_Loss: 0.5507 Train_Acc: 75.063 Val_Loss: 0.5531  BEST VAL Loss: 0.5531  Val_Acc: 74.814

Epoch 41: Validation loss decreased (0.553057 --> 0.552902).  Saving model ...
	 Train_Loss: 0.5499 Train_Acc: 75.171 Val_Loss: 0.5529  BEST VAL Loss: 0.5529  Val_Acc: 74.470

Epoch 42: Validation loss decreased (0.552902 --> 0.552737).  Saving model ...
	 Train_Loss: 0.5491 Train_Acc: 75.293 Val_Loss: 0.5527  BEST VAL Loss: 0.5527  Val_Acc: 75.455

Epoch 43: Validation loss decreased (0.552737 --> 0.552574).  Saving model ...
	 Train_Loss: 0.5484 Train_Acc: 75.139 Val_Loss: 0.5526  BEST VAL Loss: 0.5526  Val_Acc: 74.498

Epoch 44: Validation loss decreased (0.552574 --> 0.552304).  Saving model ...
	 Train_Loss: 0.5476 Train_Acc: 75.173 Val_Loss: 0.5523  BEST VAL Loss: 0.5523  Val_Acc: 74.725

Epoch 45: Validation loss decreased (0.552304 --> 0.552103).  Saving model ...
	 Train_Loss: 0.5469 Train_Acc: 75.300 Val_Loss: 0.5521  BEST VAL Loss: 0.5521  Val_Acc: 75.052

Epoch 46: Validation loss decreased (0.552103 --> 0.551845).  Saving model ...
	 Train_Loss: 0.5462 Train_Acc: 75.222 Val_Loss: 0.5518  BEST VAL Loss: 0.5518  Val_Acc: 75.473

Epoch 47: Validation loss decreased (0.551845 --> 0.551714).  Saving model ...
	 Train_Loss: 0.5455 Train_Acc: 75.298 Val_Loss: 0.5517  BEST VAL Loss: 0.5517  Val_Acc: 74.957

Epoch 48: Validation loss decreased (0.551714 --> 0.551624).  Saving model ...
	 Train_Loss: 0.5449 Train_Acc: 75.395 Val_Loss: 0.5516  BEST VAL Loss: 0.5516  Val_Acc: 75.189

Epoch 49: Validation loss decreased (0.551624 --> 0.551524).  Saving model ...
	 Train_Loss: 0.5442 Train_Acc: 75.392 Val_Loss: 0.5515  BEST VAL Loss: 0.5515  Val_Acc: 75.182

Epoch 50: Validation loss decreased (0.551524 --> 0.551392).  Saving model ...
	 Train_Loss: 0.5436 Train_Acc: 75.403 Val_Loss: 0.5514  BEST VAL Loss: 0.5514  Val_Acc: 74.883

Epoch 51: Validation loss decreased (0.551392 --> 0.551209).  Saving model ...
	 Train_Loss: 0.5430 Train_Acc: 75.352 Val_Loss: 0.5512  BEST VAL Loss: 0.5512  Val_Acc: 75.253

Epoch 52: Validation loss decreased (0.551209 --> 0.551059).  Saving model ...
	 Train_Loss: 0.5424 Train_Acc: 75.346 Val_Loss: 0.5511  BEST VAL Loss: 0.5511  Val_Acc: 74.947

Epoch 53: Validation loss decreased (0.551059 --> 0.550920).  Saving model ...
	 Train_Loss: 0.5418 Train_Acc: 75.315 Val_Loss: 0.5509  BEST VAL Loss: 0.5509  Val_Acc: 75.115

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.5412 Train_Acc: 75.638 Val_Loss: 0.5510  BEST VAL Loss: 0.5509  Val_Acc: 75.070

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.5406 Train_Acc: 75.333 Val_Loss: 0.5510  BEST VAL Loss: 0.5509  Val_Acc: 75.491

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.5400 Train_Acc: 75.696 Val_Loss: 0.5510  BEST VAL Loss: 0.5509  Val_Acc: 75.307

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.5394 Train_Acc: 75.458 Val_Loss: 0.5510  BEST VAL Loss: 0.5509  Val_Acc: 74.651

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.5389 Train_Acc: 75.548 Val_Loss: 0.5510  BEST VAL Loss: 0.5509  Val_Acc: 74.916

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.5383 Train_Acc: 75.639 Val_Loss: 0.5510  BEST VAL Loss: 0.5509  Val_Acc: 75.600

Epoch 60: Validation loss decreased (0.550920 --> 0.550915).  Saving model ...
	 Train_Loss: 0.5378 Train_Acc: 75.527 Val_Loss: 0.5509  BEST VAL Loss: 0.5509  Val_Acc: 75.674

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.5373 Train_Acc: 75.576 Val_Loss: 0.5510  BEST VAL Loss: 0.5509  Val_Acc: 75.373

Epoch 62: Validation loss decreased (0.550915 --> 0.550905).  Saving model ...
	 Train_Loss: 0.5368 Train_Acc: 75.643 Val_Loss: 0.5509  BEST VAL Loss: 0.5509  Val_Acc: 74.508

Epoch 63: Validation loss decreased (0.550905 --> 0.550775).  Saving model ...
	 Train_Loss: 0.5363 Train_Acc: 75.681 Val_Loss: 0.5508  BEST VAL Loss: 0.5508  Val_Acc: 75.575

Epoch 64: Validation loss decreased (0.550775 --> 0.550766).  Saving model ...
	 Train_Loss: 0.5358 Train_Acc: 75.730 Val_Loss: 0.5508  BEST VAL Loss: 0.5508  Val_Acc: 75.531

Epoch 65: Validation loss decreased (0.550766 --> 0.550613).  Saving model ...
	 Train_Loss: 0.5353 Train_Acc: 75.697 Val_Loss: 0.5506  BEST VAL Loss: 0.5506  Val_Acc: 75.697

Epoch 66: Validation loss decreased (0.550613 --> 0.550544).  Saving model ...
	 Train_Loss: 0.5349 Train_Acc: 75.768 Val_Loss: 0.5505  BEST VAL Loss: 0.5505  Val_Acc: 75.261

Epoch 67: Validation loss decreased (0.550544 --> 0.550364).  Saving model ...
	 Train_Loss: 0.5344 Train_Acc: 75.795 Val_Loss: 0.5504  BEST VAL Loss: 0.5504  Val_Acc: 75.243

Epoch 68: Validation loss decreased (0.550364 --> 0.550295).  Saving model ...
	 Train_Loss: 0.5340 Train_Acc: 75.718 Val_Loss: 0.5503  BEST VAL Loss: 0.5503  Val_Acc: 75.542

Epoch 69: Validation loss decreased (0.550295 --> 0.550270).  Saving model ...
	 Train_Loss: 0.5335 Train_Acc: 75.915 Val_Loss: 0.5503  BEST VAL Loss: 0.5503  Val_Acc: 75.001

Epoch 70: Validation loss decreased (0.550270 --> 0.550249).  Saving model ...
	 Train_Loss: 0.5331 Train_Acc: 75.788 Val_Loss: 0.5502  BEST VAL Loss: 0.5502  Val_Acc: 74.656

Epoch 71: Validation loss decreased (0.550249 --> 0.550188).  Saving model ...
	 Train_Loss: 0.5326 Train_Acc: 75.570 Val_Loss: 0.5502  BEST VAL Loss: 0.5502  Val_Acc: 74.794

Epoch 72: Validation loss decreased (0.550188 --> 0.550069).  Saving model ...
	 Train_Loss: 0.5322 Train_Acc: 75.769 Val_Loss: 0.5501  BEST VAL Loss: 0.5501  Val_Acc: 75.396

Epoch 73: Validation loss decreased (0.550069 --> 0.550029).  Saving model ...
	 Train_Loss: 0.5318 Train_Acc: 75.987 Val_Loss: 0.5500  BEST VAL Loss: 0.5500  Val_Acc: 75.654

Epoch 74: Validation loss did not decrease
	 Train_Loss: 0.5314 Train_Acc: 75.734 Val_Loss: 0.5502  BEST VAL Loss: 0.5500  Val_Acc: 75.322

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.5310 Train_Acc: 75.753 Val_Loss: 0.5503  BEST VAL Loss: 0.5500  Val_Acc: 74.840

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.5306 Train_Acc: 75.816 Val_Loss: 0.5502  BEST VAL Loss: 0.5500  Val_Acc: 75.725

Epoch 77: Validation loss did not decrease
	 Train_Loss: 0.5302 Train_Acc: 75.871 Val_Loss: 0.5501  BEST VAL Loss: 0.5500  Val_Acc: 75.526

Epoch 78: Validation loss did not decrease
	 Train_Loss: 0.5298 Train_Acc: 75.942 Val_Loss: 0.5501  BEST VAL Loss: 0.5500  Val_Acc: 75.498

Epoch 79: Validation loss decreased (0.550029 --> 0.550006).  Saving model ...
	 Train_Loss: 0.5294 Train_Acc: 75.928 Val_Loss: 0.5500  BEST VAL Loss: 0.5500  Val_Acc: 75.626

Epoch 80: Validation loss decreased (0.550006 --> 0.549990).  Saving model ...
	 Train_Loss: 0.5290 Train_Acc: 75.982 Val_Loss: 0.5500  BEST VAL Loss: 0.5500  Val_Acc: 74.916

Epoch 81: Validation loss decreased (0.549990 --> 0.549986).  Saving model ...
	 Train_Loss: 0.5287 Train_Acc: 75.959 Val_Loss: 0.5500  BEST VAL Loss: 0.5500  Val_Acc: 74.809

Epoch 82: Validation loss decreased (0.549986 --> 0.549917).  Saving model ...
	 Train_Loss: 0.5283 Train_Acc: 75.981 Val_Loss: 0.5499  BEST VAL Loss: 0.5499  Val_Acc: 75.577

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.5279 Train_Acc: 75.957 Val_Loss: 0.5501  BEST VAL Loss: 0.5499  Val_Acc: 74.947

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.5276 Train_Acc: 75.990 Val_Loss: 0.5501  BEST VAL Loss: 0.5499  Val_Acc: 75.687

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.5273 Train_Acc: 75.990 Val_Loss: 0.5501  BEST VAL Loss: 0.5499  Val_Acc: 75.776

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.5269 Train_Acc: 76.082 Val_Loss: 0.5502  BEST VAL Loss: 0.5499  Val_Acc: 74.899

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.5266 Train_Acc: 75.939 Val_Loss: 0.5502  BEST VAL Loss: 0.5499  Val_Acc: 75.182

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.5262 Train_Acc: 76.020 Val_Loss: 0.5501  BEST VAL Loss: 0.5499  Val_Acc: 75.756

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.5259 Train_Acc: 76.169 Val_Loss: 0.5502  BEST VAL Loss: 0.5499  Val_Acc: 75.605

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.5256 Train_Acc: 76.024 Val_Loss: 0.5502  BEST VAL Loss: 0.5499  Val_Acc: 75.725

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.5252 Train_Acc: 76.055 Val_Loss: 0.5502  BEST VAL Loss: 0.5499  Val_Acc: 75.391

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.5249 Train_Acc: 75.983 Val_Loss: 0.5502  BEST VAL Loss: 0.5499  Val_Acc: 75.728

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.5246 Train_Acc: 76.034 Val_Loss: 0.5502  BEST VAL Loss: 0.5499  Val_Acc: 74.294

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.5243 Train_Acc: 76.044 Val_Loss: 0.5502  BEST VAL Loss: 0.5499  Val_Acc: 75.557

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.5240 Train_Acc: 76.177 Val_Loss: 0.5503  BEST VAL Loss: 0.5499  Val_Acc: 75.861

Epoch 96: Validation loss did not decrease
	 Train_Loss: 0.5237 Train_Acc: 76.089 Val_Loss: 0.5502  BEST VAL Loss: 0.5499  Val_Acc: 75.478

Epoch 97: Validation loss did not decrease
	 Train_Loss: 0.5234 Train_Acc: 76.225 Val_Loss: 0.5502  BEST VAL Loss: 0.5499  Val_Acc: 75.654

Epoch 98: Validation loss did not decrease
Early stopped at epoch : 98
MultiClass_MLP_h202_remove_shuffle
              precision    recall  f1-score   support

           0       0.05      0.05      0.05      7972
           1       0.54      0.59      0.56     85003
           2       0.41      0.36      0.38     63779

    accuracy                           0.47    156754
   macro avg       0.33      0.33      0.33    156754
weighted avg       0.46      0.47      0.46    156754

MultiClass_MLP_h202_remove_shuffle
              precision    recall  f1-score   support

           0       0.04      0.04      0.04      1993
           1       0.54      0.59      0.57     21251
           2       0.41      0.36      0.38     15945

    accuracy                           0.47     39189
   macro avg       0.33      0.33      0.33     39189
weighted avg       0.46      0.47      0.46     39189

MultiClass_MLP_h202_remove_shuffle
              precision    recall  f1-score   support

           0       0.04      0.04      0.04      9965
           1       0.46      0.56      0.51    106254
           2       0.50      0.39      0.44    114226

    accuracy                           0.46    230445
   macro avg       0.33      0.33      0.33    230445
weighted avg       0.46      0.46      0.45    230445

Precision for class 0: 0.043194374686087396
Recall for class 0: 0.04315102860010035
Precision for class 1: 0.46171950713000137
Recall for class 1: 0.5649669659495172
Precision for class 2: 0.4963968345196516
Recall for class 2: 0.39318543939208234
3
              precision    recall  f1-score   support

           0       0.04      0.04      0.04      9965
           1       0.46      0.56      0.51    106254
           2       0.50      0.39      0.44    114226

    accuracy                           0.46    230445
   macro avg       0.33      0.33      0.33    230445
weighted avg       0.46      0.46      0.45    230445

MultiClass_MLP_h202_remove_shuffle
              precision    recall  f1-score   support

           0       0.05      0.05      0.05      7048
           1       0.49      0.57      0.53     71293
           2       0.46      0.38      0.42     66273

    accuracy                           0.46    144614
   macro avg       0.33      0.33      0.33    144614
weighted avg       0.46      0.46      0.46    144614

Precision for class 0: 0.05108499095840868
Recall for class 0: 0.04809875141884223
Precision for class 1: 0.4937980844716596
Recall for class 1: 0.5734784621211059
Precision for class 2: 0.4590348127072724
Recall for class 2: 0.38220693193306476
3
              precision    recall  f1-score   support

           0       0.05      0.05      0.05      7048
           1       0.49      0.57      0.53     71293
           2       0.46      0.38      0.42     66273

    accuracy                           0.46    144614
   macro avg       0.33      0.33      0.33    144614
weighted avg       0.46      0.46      0.46    144614

Done
