[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '615f7f0d'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'f2e83513'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '5aec1a90'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'fdf1d6d5'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: H2O2_100.000_DMSO_0.025 treatment_name: Thapsigargin_10.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: Thapsigargin_10.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (407520, 1270)
Number of total missing values across all columns: 815040
Data Subset Is Off
Wells held out for testing: ['I10' 'L06']
Wells to use for training, validation, and testing ['E06' 'E07' 'H04' 'I04' 'H05' 'I05' 'H10' 'H11' 'I11' 'L07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.244600).  Saving model ...
	 Train_Loss: 0.4230 Train_Acc: 78.501 Val_Loss: 0.2446  BEST VAL Loss: 0.2446  Val_Acc: 89.315

Epoch 1: Validation loss decreased (0.244600 --> 0.229981).  Saving model ...
	 Train_Loss: 0.3640 Train_Acc: 85.686 Val_Loss: 0.2300  BEST VAL Loss: 0.2300  Val_Acc: 91.300

Epoch 2: Validation loss decreased (0.229981 --> 0.220100).  Saving model ...
	 Train_Loss: 0.3360 Train_Acc: 86.960 Val_Loss: 0.2201  BEST VAL Loss: 0.2201  Val_Acc: 91.941

Epoch 3: Validation loss decreased (0.220100 --> 0.213313).  Saving model ...
	 Train_Loss: 0.3193 Train_Acc: 87.503 Val_Loss: 0.2133  BEST VAL Loss: 0.2133  Val_Acc: 91.809

Epoch 4: Validation loss decreased (0.213313 --> 0.207631).  Saving model ...
	 Train_Loss: 0.3078 Train_Acc: 87.930 Val_Loss: 0.2076  BEST VAL Loss: 0.2076  Val_Acc: 92.471

Epoch 5: Validation loss decreased (0.207631 --> 0.203814).  Saving model ...
	 Train_Loss: 0.2990 Train_Acc: 88.226 Val_Loss: 0.2038  BEST VAL Loss: 0.2038  Val_Acc: 92.336

Epoch 6: Validation loss decreased (0.203814 --> 0.200174).  Saving model ...
	 Train_Loss: 0.2923 Train_Acc: 88.354 Val_Loss: 0.2002  BEST VAL Loss: 0.2002  Val_Acc: 92.905

Epoch 7: Validation loss decreased (0.200174 --> 0.197359).  Saving model ...
	 Train_Loss: 0.2867 Train_Acc: 88.644 Val_Loss: 0.1974  BEST VAL Loss: 0.1974  Val_Acc: 92.782

Epoch 8: Validation loss decreased (0.197359 --> 0.195029).  Saving model ...
	 Train_Loss: 0.2819 Train_Acc: 88.819 Val_Loss: 0.1950  BEST VAL Loss: 0.1950  Val_Acc: 92.839

Epoch 9: Validation loss decreased (0.195029 --> 0.192975).  Saving model ...
	 Train_Loss: 0.2781 Train_Acc: 88.759 Val_Loss: 0.1930  BEST VAL Loss: 0.1930  Val_Acc: 92.911

Epoch 10: Validation loss decreased (0.192975 --> 0.191164).  Saving model ...
	 Train_Loss: 0.2748 Train_Acc: 88.868 Val_Loss: 0.1912  BEST VAL Loss: 0.1912  Val_Acc: 93.156

Epoch 11: Validation loss decreased (0.191164 --> 0.189799).  Saving model ...
	 Train_Loss: 0.2719 Train_Acc: 88.864 Val_Loss: 0.1898  BEST VAL Loss: 0.1898  Val_Acc: 92.872

Epoch 12: Validation loss decreased (0.189799 --> 0.188184).  Saving model ...
	 Train_Loss: 0.2692 Train_Acc: 89.029 Val_Loss: 0.1882  BEST VAL Loss: 0.1882  Val_Acc: 92.860

Epoch 13: Validation loss decreased (0.188184 --> 0.186817).  Saving model ...
	 Train_Loss: 0.2669 Train_Acc: 89.015 Val_Loss: 0.1868  BEST VAL Loss: 0.1868  Val_Acc: 93.034

Epoch 14: Validation loss decreased (0.186817 --> 0.185522).  Saving model ...
	 Train_Loss: 0.2648 Train_Acc: 89.141 Val_Loss: 0.1855  BEST VAL Loss: 0.1855  Val_Acc: 93.222

Epoch 15: Validation loss decreased (0.185522 --> 0.184488).  Saving model ...
	 Train_Loss: 0.2629 Train_Acc: 89.128 Val_Loss: 0.1845  BEST VAL Loss: 0.1845  Val_Acc: 93.156

Epoch 16: Validation loss decreased (0.184488 --> 0.183341).  Saving model ...
	 Train_Loss: 0.2612 Train_Acc: 89.210 Val_Loss: 0.1833  BEST VAL Loss: 0.1833  Val_Acc: 93.046

Epoch 17: Validation loss decreased (0.183341 --> 0.182306).  Saving model ...
	 Train_Loss: 0.2595 Train_Acc: 89.352 Val_Loss: 0.1823  BEST VAL Loss: 0.1823  Val_Acc: 93.273

Epoch 18: Validation loss decreased (0.182306 --> 0.181273).  Saving model ...
	 Train_Loss: 0.2581 Train_Acc: 89.141 Val_Loss: 0.1813  BEST VAL Loss: 0.1813  Val_Acc: 93.240

Epoch 19: Validation loss decreased (0.181273 --> 0.180624).  Saving model ...
	 Train_Loss: 0.2568 Train_Acc: 89.190 Val_Loss: 0.1806  BEST VAL Loss: 0.1806  Val_Acc: 93.093

Epoch 20: Validation loss decreased (0.180624 --> 0.179599).  Saving model ...
	 Train_Loss: 0.2555 Train_Acc: 89.379 Val_Loss: 0.1796  BEST VAL Loss: 0.1796  Val_Acc: 93.698

Epoch 21: Validation loss decreased (0.179599 --> 0.178865).  Saving model ...
	 Train_Loss: 0.2542 Train_Acc: 89.415 Val_Loss: 0.1789  BEST VAL Loss: 0.1789  Val_Acc: 93.324

Epoch 22: Validation loss decreased (0.178865 --> 0.178067).  Saving model ...
	 Train_Loss: 0.2531 Train_Acc: 89.435 Val_Loss: 0.1781  BEST VAL Loss: 0.1781  Val_Acc: 93.456

Epoch 23: Validation loss decreased (0.178067 --> 0.177220).  Saving model ...
	 Train_Loss: 0.2520 Train_Acc: 89.421 Val_Loss: 0.1772  BEST VAL Loss: 0.1772  Val_Acc: 93.480

Epoch 24: Validation loss decreased (0.177220 --> 0.176662).  Saving model ...
	 Train_Loss: 0.2511 Train_Acc: 89.444 Val_Loss: 0.1767  BEST VAL Loss: 0.1767  Val_Acc: 93.225

Epoch 25: Validation loss decreased (0.176662 --> 0.175965).  Saving model ...
	 Train_Loss: 0.2501 Train_Acc: 89.533 Val_Loss: 0.1760  BEST VAL Loss: 0.1760  Val_Acc: 93.731

Epoch 26: Validation loss decreased (0.175965 --> 0.175337).  Saving model ...
	 Train_Loss: 0.2492 Train_Acc: 89.563 Val_Loss: 0.1753  BEST VAL Loss: 0.1753  Val_Acc: 93.557

Epoch 27: Validation loss decreased (0.175337 --> 0.174641).  Saving model ...
	 Train_Loss: 0.2483 Train_Acc: 89.647 Val_Loss: 0.1746  BEST VAL Loss: 0.1746  Val_Acc: 93.647

Epoch 28: Validation loss decreased (0.174641 --> 0.174118).  Saving model ...
	 Train_Loss: 0.2474 Train_Acc: 89.678 Val_Loss: 0.1741  BEST VAL Loss: 0.1741  Val_Acc: 93.689

Epoch 29: Validation loss decreased (0.174118 --> 0.173517).  Saving model ...
	 Train_Loss: 0.2467 Train_Acc: 89.643 Val_Loss: 0.1735  BEST VAL Loss: 0.1735  Val_Acc: 93.602

Epoch 30: Validation loss decreased (0.173517 --> 0.172965).  Saving model ...
	 Train_Loss: 0.2459 Train_Acc: 89.613 Val_Loss: 0.1730  BEST VAL Loss: 0.1730  Val_Acc: 93.590

Epoch 31: Validation loss decreased (0.172965 --> 0.172411).  Saving model ...
	 Train_Loss: 0.2452 Train_Acc: 89.676 Val_Loss: 0.1724  BEST VAL Loss: 0.1724  Val_Acc: 93.710

Epoch 32: Validation loss decreased (0.172411 --> 0.172021).  Saving model ...
	 Train_Loss: 0.2446 Train_Acc: 89.619 Val_Loss: 0.1720  BEST VAL Loss: 0.1720  Val_Acc: 93.303

Epoch 33: Validation loss decreased (0.172021 --> 0.171603).  Saving model ...
	 Train_Loss: 0.2439 Train_Acc: 89.625 Val_Loss: 0.1716  BEST VAL Loss: 0.1716  Val_Acc: 93.399

Epoch 34: Validation loss decreased (0.171603 --> 0.171128).  Saving model ...
	 Train_Loss: 0.2433 Train_Acc: 89.799 Val_Loss: 0.1711  BEST VAL Loss: 0.1711  Val_Acc: 93.743

Epoch 35: Validation loss decreased (0.171128 --> 0.170737).  Saving model ...
	 Train_Loss: 0.2427 Train_Acc: 89.786 Val_Loss: 0.1707  BEST VAL Loss: 0.1707  Val_Acc: 93.872

Epoch 36: Validation loss decreased (0.170737 --> 0.170288).  Saving model ...
	 Train_Loss: 0.2421 Train_Acc: 89.730 Val_Loss: 0.1703  BEST VAL Loss: 0.1703  Val_Acc: 93.779

Epoch 37: Validation loss decreased (0.170288 --> 0.169893).  Saving model ...
	 Train_Loss: 0.2416 Train_Acc: 89.699 Val_Loss: 0.1699  BEST VAL Loss: 0.1699  Val_Acc: 93.677

Epoch 38: Validation loss decreased (0.169893 --> 0.169594).  Saving model ...
	 Train_Loss: 0.2410 Train_Acc: 89.822 Val_Loss: 0.1696  BEST VAL Loss: 0.1696  Val_Acc: 93.495

Epoch 39: Validation loss decreased (0.169594 --> 0.169143).  Saving model ...
	 Train_Loss: 0.2405 Train_Acc: 89.785 Val_Loss: 0.1691  BEST VAL Loss: 0.1691  Val_Acc: 93.680

Epoch 40: Validation loss decreased (0.169143 --> 0.168757).  Saving model ...
	 Train_Loss: 0.2400 Train_Acc: 89.844 Val_Loss: 0.1688  BEST VAL Loss: 0.1688  Val_Acc: 93.920

Epoch 41: Validation loss decreased (0.168757 --> 0.168402).  Saving model ...
	 Train_Loss: 0.2395 Train_Acc: 89.915 Val_Loss: 0.1684  BEST VAL Loss: 0.1684  Val_Acc: 93.659

Epoch 42: Validation loss decreased (0.168402 --> 0.168034).  Saving model ...
	 Train_Loss: 0.2390 Train_Acc: 89.825 Val_Loss: 0.1680  BEST VAL Loss: 0.1680  Val_Acc: 93.740

Epoch 43: Validation loss decreased (0.168034 --> 0.167693).  Saving model ...
	 Train_Loss: 0.2386 Train_Acc: 89.897 Val_Loss: 0.1677  BEST VAL Loss: 0.1677  Val_Acc: 94.060

Epoch 44: Validation loss decreased (0.167693 --> 0.167449).  Saving model ...
	 Train_Loss: 0.2381 Train_Acc: 89.838 Val_Loss: 0.1674  BEST VAL Loss: 0.1674  Val_Acc: 93.554

Epoch 45: Validation loss decreased (0.167449 --> 0.167121).  Saving model ...
	 Train_Loss: 0.2377 Train_Acc: 89.965 Val_Loss: 0.1671  BEST VAL Loss: 0.1671  Val_Acc: 93.872

Epoch 46: Validation loss decreased (0.167121 --> 0.166909).  Saving model ...
	 Train_Loss: 0.2372 Train_Acc: 89.985 Val_Loss: 0.1669  BEST VAL Loss: 0.1669  Val_Acc: 93.818

Epoch 47: Validation loss decreased (0.166909 --> 0.166680).  Saving model ...
	 Train_Loss: 0.2368 Train_Acc: 89.958 Val_Loss: 0.1667  BEST VAL Loss: 0.1667  Val_Acc: 93.950

Epoch 48: Validation loss decreased (0.166680 --> 0.166451).  Saving model ...
	 Train_Loss: 0.2364 Train_Acc: 89.934 Val_Loss: 0.1665  BEST VAL Loss: 0.1665  Val_Acc: 93.755

Epoch 49: Validation loss decreased (0.166451 --> 0.166179).  Saving model ...
	 Train_Loss: 0.2360 Train_Acc: 89.931 Val_Loss: 0.1662  BEST VAL Loss: 0.1662  Val_Acc: 93.890

Epoch 50: Validation loss decreased (0.166179 --> 0.165947).  Saving model ...
	 Train_Loss: 0.2357 Train_Acc: 89.921 Val_Loss: 0.1659  BEST VAL Loss: 0.1659  Val_Acc: 93.776

Epoch 51: Validation loss decreased (0.165947 --> 0.165689).  Saving model ...
	 Train_Loss: 0.2353 Train_Acc: 90.072 Val_Loss: 0.1657  BEST VAL Loss: 0.1657  Val_Acc: 93.692

Epoch 52: Validation loss decreased (0.165689 --> 0.165455).  Saving model ...
	 Train_Loss: 0.2349 Train_Acc: 89.976 Val_Loss: 0.1655  BEST VAL Loss: 0.1655  Val_Acc: 93.830

Epoch 53: Validation loss decreased (0.165455 --> 0.165240).  Saving model ...
	 Train_Loss: 0.2345 Train_Acc: 90.028 Val_Loss: 0.1652  BEST VAL Loss: 0.1652  Val_Acc: 93.752

Epoch 54: Validation loss decreased (0.165240 --> 0.165076).  Saving model ...
	 Train_Loss: 0.2342 Train_Acc: 90.028 Val_Loss: 0.1651  BEST VAL Loss: 0.1651  Val_Acc: 93.857

Epoch 55: Validation loss decreased (0.165076 --> 0.164830).  Saving model ...
	 Train_Loss: 0.2338 Train_Acc: 90.048 Val_Loss: 0.1648  BEST VAL Loss: 0.1648  Val_Acc: 93.887

Epoch 56: Validation loss decreased (0.164830 --> 0.164625).  Saving model ...
	 Train_Loss: 0.2335 Train_Acc: 89.965 Val_Loss: 0.1646  BEST VAL Loss: 0.1646  Val_Acc: 93.815

Epoch 57: Validation loss decreased (0.164625 --> 0.164395).  Saving model ...
	 Train_Loss: 0.2332 Train_Acc: 90.103 Val_Loss: 0.1644  BEST VAL Loss: 0.1644  Val_Acc: 93.860

Epoch 58: Validation loss decreased (0.164395 --> 0.164220).  Saving model ...
	 Train_Loss: 0.2329 Train_Acc: 90.026 Val_Loss: 0.1642  BEST VAL Loss: 0.1642  Val_Acc: 94.030

Epoch 59: Validation loss decreased (0.164220 --> 0.164022).  Saving model ...
	 Train_Loss: 0.2326 Train_Acc: 89.976 Val_Loss: 0.1640  BEST VAL Loss: 0.1640  Val_Acc: 93.803

Epoch 60: Validation loss decreased (0.164022 --> 0.163764).  Saving model ...
	 Train_Loss: 0.2323 Train_Acc: 90.071 Val_Loss: 0.1638  BEST VAL Loss: 0.1638  Val_Acc: 94.027

Epoch 61: Validation loss decreased (0.163764 --> 0.163553).  Saving model ...
	 Train_Loss: 0.2320 Train_Acc: 89.988 Val_Loss: 0.1636  BEST VAL Loss: 0.1636  Val_Acc: 93.959

Epoch 62: Validation loss decreased (0.163553 --> 0.163361).  Saving model ...
	 Train_Loss: 0.2317 Train_Acc: 90.049 Val_Loss: 0.1634  BEST VAL Loss: 0.1634  Val_Acc: 93.857

Epoch 63: Validation loss decreased (0.163361 --> 0.163194).  Saving model ...
	 Train_Loss: 0.2314 Train_Acc: 90.077 Val_Loss: 0.1632  BEST VAL Loss: 0.1632  Val_Acc: 94.039

Epoch 64: Validation loss decreased (0.163194 --> 0.162975).  Saving model ...
	 Train_Loss: 0.2312 Train_Acc: 90.135 Val_Loss: 0.1630  BEST VAL Loss: 0.1630  Val_Acc: 93.866

Epoch 65: Validation loss decreased (0.162975 --> 0.162857).  Saving model ...
	 Train_Loss: 0.2309 Train_Acc: 90.212 Val_Loss: 0.1629  BEST VAL Loss: 0.1629  Val_Acc: 93.767

Epoch 66: Validation loss decreased (0.162857 --> 0.162683).  Saving model ...
	 Train_Loss: 0.2306 Train_Acc: 90.078 Val_Loss: 0.1627  BEST VAL Loss: 0.1627  Val_Acc: 93.947

Epoch 67: Validation loss decreased (0.162683 --> 0.162479).  Saving model ...
	 Train_Loss: 0.2304 Train_Acc: 90.109 Val_Loss: 0.1625  BEST VAL Loss: 0.1625  Val_Acc: 93.872

Epoch 68: Validation loss decreased (0.162479 --> 0.162271).  Saving model ...
	 Train_Loss: 0.2301 Train_Acc: 90.145 Val_Loss: 0.1623  BEST VAL Loss: 0.1623  Val_Acc: 93.893

Epoch 69: Validation loss decreased (0.162271 --> 0.162104).  Saving model ...
	 Train_Loss: 0.2299 Train_Acc: 90.129 Val_Loss: 0.1621  BEST VAL Loss: 0.1621  Val_Acc: 94.033

Epoch 70: Validation loss decreased (0.162104 --> 0.161873).  Saving model ...
	 Train_Loss: 0.2296 Train_Acc: 90.128 Val_Loss: 0.1619  BEST VAL Loss: 0.1619  Val_Acc: 93.980

Epoch 71: Validation loss decreased (0.161873 --> 0.161671).  Saving model ...
	 Train_Loss: 0.2294 Train_Acc: 90.113 Val_Loss: 0.1617  BEST VAL Loss: 0.1617  Val_Acc: 94.027

Epoch 72: Validation loss decreased (0.161671 --> 0.161486).  Saving model ...
	 Train_Loss: 0.2291 Train_Acc: 90.191 Val_Loss: 0.1615  BEST VAL Loss: 0.1615  Val_Acc: 93.980

Epoch 73: Validation loss decreased (0.161486 --> 0.161299).  Saving model ...
	 Train_Loss: 0.2289 Train_Acc: 90.091 Val_Loss: 0.1613  BEST VAL Loss: 0.1613  Val_Acc: 93.920

Epoch 74: Validation loss decreased (0.161299 --> 0.161099).  Saving model ...
	 Train_Loss: 0.2287 Train_Acc: 90.074 Val_Loss: 0.1611  BEST VAL Loss: 0.1611  Val_Acc: 93.989

Epoch 75: Validation loss decreased (0.161099 --> 0.160969).  Saving model ...
	 Train_Loss: 0.2285 Train_Acc: 90.127 Val_Loss: 0.1610  BEST VAL Loss: 0.1610  Val_Acc: 93.689

Epoch 76: Validation loss decreased (0.160969 --> 0.160869).  Saving model ...
	 Train_Loss: 0.2283 Train_Acc: 90.245 Val_Loss: 0.1609  BEST VAL Loss: 0.1609  Val_Acc: 93.953

Epoch 77: Validation loss decreased (0.160869 --> 0.160722).  Saving model ...
	 Train_Loss: 0.2281 Train_Acc: 90.109 Val_Loss: 0.1607  BEST VAL Loss: 0.1607  Val_Acc: 93.992

Epoch 78: Validation loss decreased (0.160722 --> 0.160610).  Saving model ...
	 Train_Loss: 0.2279 Train_Acc: 90.159 Val_Loss: 0.1606  BEST VAL Loss: 0.1606  Val_Acc: 94.054

Epoch 79: Validation loss decreased (0.160610 --> 0.160434).  Saving model ...
	 Train_Loss: 0.2276 Train_Acc: 90.239 Val_Loss: 0.1604  BEST VAL Loss: 0.1604  Val_Acc: 93.962

Epoch 80: Validation loss decreased (0.160434 --> 0.160279).  Saving model ...
	 Train_Loss: 0.2275 Train_Acc: 90.213 Val_Loss: 0.1603  BEST VAL Loss: 0.1603  Val_Acc: 93.935

Epoch 81: Validation loss decreased (0.160279 --> 0.160133).  Saving model ...
	 Train_Loss: 0.2272 Train_Acc: 90.218 Val_Loss: 0.1601  BEST VAL Loss: 0.1601  Val_Acc: 94.105

Epoch 82: Validation loss decreased (0.160133 --> 0.159986).  Saving model ...
	 Train_Loss: 0.2270 Train_Acc: 90.217 Val_Loss: 0.1600  BEST VAL Loss: 0.1600  Val_Acc: 94.108

Epoch 83: Validation loss decreased (0.159986 --> 0.159888).  Saving model ...
	 Train_Loss: 0.2269 Train_Acc: 90.179 Val_Loss: 0.1599  BEST VAL Loss: 0.1599  Val_Acc: 94.165

Epoch 84: Validation loss decreased (0.159888 --> 0.159759).  Saving model ...
	 Train_Loss: 0.2267 Train_Acc: 90.193 Val_Loss: 0.1598  BEST VAL Loss: 0.1598  Val_Acc: 93.848

Epoch 85: Validation loss decreased (0.159759 --> 0.159635).  Saving model ...
	 Train_Loss: 0.2265 Train_Acc: 90.201 Val_Loss: 0.1596  BEST VAL Loss: 0.1596  Val_Acc: 94.075

Epoch 86: Validation loss decreased (0.159635 --> 0.159532).  Saving model ...
	 Train_Loss: 0.2263 Train_Acc: 90.149 Val_Loss: 0.1595  BEST VAL Loss: 0.1595  Val_Acc: 94.042

Epoch 87: Validation loss decreased (0.159532 --> 0.159424).  Saving model ...
	 Train_Loss: 0.2261 Train_Acc: 90.227 Val_Loss: 0.1594  BEST VAL Loss: 0.1594  Val_Acc: 94.069

Epoch 88: Validation loss decreased (0.159424 --> 0.159337).  Saving model ...
	 Train_Loss: 0.2259 Train_Acc: 90.231 Val_Loss: 0.1593  BEST VAL Loss: 0.1593  Val_Acc: 94.123

Epoch 89: Validation loss decreased (0.159337 --> 0.159244).  Saving model ...
	 Train_Loss: 0.2258 Train_Acc: 90.293 Val_Loss: 0.1592  BEST VAL Loss: 0.1592  Val_Acc: 93.965

Epoch 90: Validation loss decreased (0.159244 --> 0.159125).  Saving model ...
	 Train_Loss: 0.2256 Train_Acc: 90.239 Val_Loss: 0.1591  BEST VAL Loss: 0.1591  Val_Acc: 94.189

Epoch 91: Validation loss decreased (0.159125 --> 0.158983).  Saving model ...
	 Train_Loss: 0.2254 Train_Acc: 90.292 Val_Loss: 0.1590  BEST VAL Loss: 0.1590  Val_Acc: 94.030

Epoch 92: Validation loss decreased (0.158983 --> 0.158854).  Saving model ...
	 Train_Loss: 0.2252 Train_Acc: 90.285 Val_Loss: 0.1589  BEST VAL Loss: 0.1589  Val_Acc: 94.231

Epoch 93: Validation loss decreased (0.158854 --> 0.158754).  Saving model ...
	 Train_Loss: 0.2251 Train_Acc: 90.273 Val_Loss: 0.1588  BEST VAL Loss: 0.1588  Val_Acc: 94.024

Epoch 94: Validation loss decreased (0.158754 --> 0.158661).  Saving model ...
	 Train_Loss: 0.2249 Train_Acc: 90.289 Val_Loss: 0.1587  BEST VAL Loss: 0.1587  Val_Acc: 94.147

Epoch 95: Validation loss decreased (0.158661 --> 0.158565).  Saving model ...
	 Train_Loss: 0.2247 Train_Acc: 90.306 Val_Loss: 0.1586  BEST VAL Loss: 0.1586  Val_Acc: 94.051

Epoch 96: Validation loss decreased (0.158565 --> 0.158478).  Saving model ...
	 Train_Loss: 0.2246 Train_Acc: 90.295 Val_Loss: 0.1585  BEST VAL Loss: 0.1585  Val_Acc: 94.016

Epoch 97: Validation loss decreased (0.158478 --> 0.158352).  Saving model ...
	 Train_Loss: 0.2244 Train_Acc: 90.306 Val_Loss: 0.1584  BEST VAL Loss: 0.1584  Val_Acc: 94.210

Epoch 98: Validation loss decreased (0.158352 --> 0.158233).  Saving model ...
	 Train_Loss: 0.2242 Train_Acc: 90.343 Val_Loss: 0.1582  BEST VAL Loss: 0.1582  Val_Acc: 94.108

Epoch 99: Validation loss decreased (0.158233 --> 0.158110).  Saving model ...
	 Train_Loss: 0.2241 Train_Acc: 90.447 Val_Loss: 0.1581  BEST VAL Loss: 0.1581  Val_Acc: 94.213

H2O2_100.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.63      0.62      0.63    169561
           1       0.36      0.38      0.37     97655

    accuracy                           0.53    267216
   macro avg       0.50      0.50      0.50    267216
weighted avg       0.54      0.53      0.53    267216

H2O2_100.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.64      0.63      0.63     21196
           1       0.37      0.38      0.37     12207

    accuracy                           0.54     33403
   macro avg       0.50      0.50      0.50     33403
weighted avg       0.54      0.54      0.54     33403

H2O2_100.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.64      0.63      0.63     21195
           1       0.37      0.38      0.37     12207

    accuracy                           0.54     33402
   macro avg       0.50      0.50      0.50     33402
weighted avg       0.54      0.54      0.54     33402

              precision    recall  f1-score   support

           0       0.64      0.63      0.63     21195
           1       0.37      0.38      0.37     12207

    accuracy                           0.54     33402
   macro avg       0.50      0.50      0.50     33402
weighted avg       0.54      0.54      0.54     33402

H2O2_100.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.39      0.43      0.41     28584
           1       0.61      0.57      0.59     44915

    accuracy                           0.52     73499
   macro avg       0.50      0.50      0.50     73499
weighted avg       0.52      0.52      0.52     73499

              precision    recall  f1-score   support

           0       0.39      0.43      0.41     28584
           1       0.61      0.57      0.59     44915

    accuracy                           0.52     73499
   macro avg       0.50      0.50      0.50     73499
weighted avg       0.52      0.52      0.52     73499

completed
