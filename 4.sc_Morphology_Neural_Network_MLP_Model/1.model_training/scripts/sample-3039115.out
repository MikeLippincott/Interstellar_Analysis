[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '9fee523f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'afde7e21'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ed0a035d'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '015aa371'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
TREATMENT_NAME: LPS_0.010_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (309093, 1270)
Number of total missing values across all columns: 286160
Data Subset Is Off
Wells held out for testing: ['B08' 'K08']
Wells to use for training, validation, and testing ['B02' 'B03' 'B09' 'K02' 'K03' 'K09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.332858).  Saving model ...
	 Train_Loss: 0.4645 Train_Acc: 78.900 Val_Loss: 0.3329  BEST VAL Loss: 0.3329  Val_Acc: 86.129

Epoch 1: Validation loss decreased (0.332858 --> 0.313980).  Saving model ...
	 Train_Loss: 0.4150 Train_Acc: 84.401 Val_Loss: 0.3140  BEST VAL Loss: 0.3140  Val_Acc: 87.510

Epoch 2: Validation loss decreased (0.313980 --> 0.302006).  Saving model ...
	 Train_Loss: 0.3919 Train_Acc: 85.555 Val_Loss: 0.3020  BEST VAL Loss: 0.3020  Val_Acc: 88.468

Epoch 3: Validation loss decreased (0.302006 --> 0.294082).  Saving model ...
	 Train_Loss: 0.3765 Train_Acc: 86.487 Val_Loss: 0.2941  BEST VAL Loss: 0.2941  Val_Acc: 88.969

Epoch 4: Validation loss decreased (0.294082 --> 0.288154).  Saving model ...
	 Train_Loss: 0.3656 Train_Acc: 86.835 Val_Loss: 0.2882  BEST VAL Loss: 0.2882  Val_Acc: 89.120

Epoch 5: Validation loss decreased (0.288154 --> 0.282635).  Saving model ...
	 Train_Loss: 0.3576 Train_Acc: 87.105 Val_Loss: 0.2826  BEST VAL Loss: 0.2826  Val_Acc: 89.534

Epoch 6: Validation loss decreased (0.282635 --> 0.278331).  Saving model ...
	 Train_Loss: 0.3513 Train_Acc: 87.285 Val_Loss: 0.2783  BEST VAL Loss: 0.2783  Val_Acc: 89.841

Epoch 7: Validation loss decreased (0.278331 --> 0.274521).  Saving model ...
	 Train_Loss: 0.3462 Train_Acc: 87.521 Val_Loss: 0.2745  BEST VAL Loss: 0.2745  Val_Acc: 89.927

Epoch 8: Validation loss decreased (0.274521 --> 0.272046).  Saving model ...
	 Train_Loss: 0.3418 Train_Acc: 87.672 Val_Loss: 0.2720  BEST VAL Loss: 0.2720  Val_Acc: 89.966

Epoch 9: Validation loss decreased (0.272046 --> 0.269882).  Saving model ...
	 Train_Loss: 0.3379 Train_Acc: 87.808 Val_Loss: 0.2699  BEST VAL Loss: 0.2699  Val_Acc: 89.888

Epoch 10: Validation loss decreased (0.269882 --> 0.267913).  Saving model ...
	 Train_Loss: 0.3345 Train_Acc: 87.938 Val_Loss: 0.2679  BEST VAL Loss: 0.2679  Val_Acc: 90.035

Epoch 11: Validation loss decreased (0.267913 --> 0.266055).  Saving model ...
	 Train_Loss: 0.3317 Train_Acc: 87.970 Val_Loss: 0.2661  BEST VAL Loss: 0.2661  Val_Acc: 90.173

Epoch 12: Validation loss decreased (0.266055 --> 0.264515).  Saving model ...
	 Train_Loss: 0.3291 Train_Acc: 88.037 Val_Loss: 0.2645  BEST VAL Loss: 0.2645  Val_Acc: 90.117

Epoch 13: Validation loss decreased (0.264515 --> 0.262861).  Saving model ...
	 Train_Loss: 0.3267 Train_Acc: 88.161 Val_Loss: 0.2629  BEST VAL Loss: 0.2629  Val_Acc: 90.298

Epoch 14: Validation loss decreased (0.262861 --> 0.261364).  Saving model ...
	 Train_Loss: 0.3246 Train_Acc: 88.272 Val_Loss: 0.2614  BEST VAL Loss: 0.2614  Val_Acc: 90.264

Epoch 15: Validation loss decreased (0.261364 --> 0.260185).  Saving model ...
	 Train_Loss: 0.3226 Train_Acc: 88.370 Val_Loss: 0.2602  BEST VAL Loss: 0.2602  Val_Acc: 90.061

Epoch 16: Validation loss decreased (0.260185 --> 0.258927).  Saving model ...
	 Train_Loss: 0.3208 Train_Acc: 88.341 Val_Loss: 0.2589  BEST VAL Loss: 0.2589  Val_Acc: 90.445

Epoch 17: Validation loss decreased (0.258927 --> 0.257726).  Saving model ...
	 Train_Loss: 0.3190 Train_Acc: 88.546 Val_Loss: 0.2577  BEST VAL Loss: 0.2577  Val_Acc: 90.419

Epoch 18: Validation loss decreased (0.257726 --> 0.256628).  Saving model ...
	 Train_Loss: 0.3175 Train_Acc: 88.490 Val_Loss: 0.2566  BEST VAL Loss: 0.2566  Val_Acc: 90.492

Epoch 19: Validation loss decreased (0.256628 --> 0.255897).  Saving model ...
	 Train_Loss: 0.3160 Train_Acc: 88.545 Val_Loss: 0.2559  BEST VAL Loss: 0.2559  Val_Acc: 90.277

Epoch 20: Validation loss decreased (0.255897 --> 0.254946).  Saving model ...
	 Train_Loss: 0.3147 Train_Acc: 88.586 Val_Loss: 0.2549  BEST VAL Loss: 0.2549  Val_Acc: 90.613

Epoch 21: Validation loss decreased (0.254946 --> 0.254000).  Saving model ...
	 Train_Loss: 0.3134 Train_Acc: 88.628 Val_Loss: 0.2540  BEST VAL Loss: 0.2540  Val_Acc: 90.561

Epoch 22: Validation loss decreased (0.254000 --> 0.253182).  Saving model ...
	 Train_Loss: 0.3122 Train_Acc: 88.665 Val_Loss: 0.2532  BEST VAL Loss: 0.2532  Val_Acc: 90.570

Epoch 23: Validation loss decreased (0.253182 --> 0.252414).  Saving model ...
	 Train_Loss: 0.3111 Train_Acc: 88.713 Val_Loss: 0.2524  BEST VAL Loss: 0.2524  Val_Acc: 90.704

Epoch 24: Validation loss decreased (0.252414 --> 0.251596).  Saving model ...
	 Train_Loss: 0.3100 Train_Acc: 88.762 Val_Loss: 0.2516  BEST VAL Loss: 0.2516  Val_Acc: 90.881

Epoch 25: Validation loss decreased (0.251596 --> 0.250914).  Saving model ...
	 Train_Loss: 0.3089 Train_Acc: 88.856 Val_Loss: 0.2509  BEST VAL Loss: 0.2509  Val_Acc: 90.665

Epoch 26: Validation loss decreased (0.250914 --> 0.250211).  Saving model ...
	 Train_Loss: 0.3079 Train_Acc: 88.864 Val_Loss: 0.2502  BEST VAL Loss: 0.2502  Val_Acc: 90.639

Epoch 27: Validation loss decreased (0.250211 --> 0.249634).  Saving model ...
	 Train_Loss: 0.3070 Train_Acc: 88.838 Val_Loss: 0.2496  BEST VAL Loss: 0.2496  Val_Acc: 90.652

Epoch 28: Validation loss decreased (0.249634 --> 0.249083).  Saving model ...
	 Train_Loss: 0.3061 Train_Acc: 88.930 Val_Loss: 0.2491  BEST VAL Loss: 0.2491  Val_Acc: 90.635

Epoch 29: Validation loss decreased (0.249083 --> 0.248540).  Saving model ...
	 Train_Loss: 0.3052 Train_Acc: 88.930 Val_Loss: 0.2485  BEST VAL Loss: 0.2485  Val_Acc: 90.574

Epoch 30: Validation loss decreased (0.248540 --> 0.248108).  Saving model ...
	 Train_Loss: 0.3043 Train_Acc: 89.008 Val_Loss: 0.2481  BEST VAL Loss: 0.2481  Val_Acc: 90.505

Epoch 31: Validation loss decreased (0.248108 --> 0.247613).  Saving model ...
	 Train_Loss: 0.3035 Train_Acc: 88.925 Val_Loss: 0.2476  BEST VAL Loss: 0.2476  Val_Acc: 90.777

Epoch 32: Validation loss decreased (0.247613 --> 0.247033).  Saving model ...
	 Train_Loss: 0.3028 Train_Acc: 88.996 Val_Loss: 0.2470  BEST VAL Loss: 0.2470  Val_Acc: 90.833

Epoch 33: Validation loss decreased (0.247033 --> 0.246556).  Saving model ...
	 Train_Loss: 0.3020 Train_Acc: 89.104 Val_Loss: 0.2466  BEST VAL Loss: 0.2466  Val_Acc: 90.889

Epoch 34: Validation loss decreased (0.246556 --> 0.246117).  Saving model ...
	 Train_Loss: 0.3013 Train_Acc: 89.112 Val_Loss: 0.2461  BEST VAL Loss: 0.2461  Val_Acc: 90.708

Epoch 35: Validation loss decreased (0.246117 --> 0.245635).  Saving model ...
	 Train_Loss: 0.3007 Train_Acc: 89.126 Val_Loss: 0.2456  BEST VAL Loss: 0.2456  Val_Acc: 90.946

Epoch 36: Validation loss decreased (0.245635 --> 0.245187).  Saving model ...
	 Train_Loss: 0.3000 Train_Acc: 89.153 Val_Loss: 0.2452  BEST VAL Loss: 0.2452  Val_Acc: 90.872

Epoch 37: Validation loss decreased (0.245187 --> 0.244674).  Saving model ...
	 Train_Loss: 0.2994 Train_Acc: 89.205 Val_Loss: 0.2447  BEST VAL Loss: 0.2447  Val_Acc: 91.140

Epoch 38: Validation loss decreased (0.244674 --> 0.244238).  Saving model ...
	 Train_Loss: 0.2987 Train_Acc: 89.157 Val_Loss: 0.2442  BEST VAL Loss: 0.2442  Val_Acc: 90.946

Epoch 39: Validation loss decreased (0.244238 --> 0.243784).  Saving model ...
	 Train_Loss: 0.2981 Train_Acc: 89.243 Val_Loss: 0.2438  BEST VAL Loss: 0.2438  Val_Acc: 90.920

Epoch 40: Validation loss decreased (0.243784 --> 0.243375).  Saving model ...
	 Train_Loss: 0.2976 Train_Acc: 89.132 Val_Loss: 0.2434  BEST VAL Loss: 0.2434  Val_Acc: 91.110

Epoch 41: Validation loss decreased (0.243375 --> 0.243035).  Saving model ...
	 Train_Loss: 0.2970 Train_Acc: 89.197 Val_Loss: 0.2430  BEST VAL Loss: 0.2430  Val_Acc: 90.695

Epoch 42: Validation loss decreased (0.243035 --> 0.242734).  Saving model ...
	 Train_Loss: 0.2965 Train_Acc: 89.163 Val_Loss: 0.2427  BEST VAL Loss: 0.2427  Val_Acc: 91.006

Epoch 43: Validation loss decreased (0.242734 --> 0.242429).  Saving model ...
	 Train_Loss: 0.2959 Train_Acc: 89.269 Val_Loss: 0.2424  BEST VAL Loss: 0.2424  Val_Acc: 90.859

Epoch 44: Validation loss decreased (0.242429 --> 0.242060).  Saving model ...
	 Train_Loss: 0.2954 Train_Acc: 89.297 Val_Loss: 0.2421  BEST VAL Loss: 0.2421  Val_Acc: 90.928

Epoch 45: Validation loss decreased (0.242060 --> 0.241733).  Saving model ...
	 Train_Loss: 0.2949 Train_Acc: 89.258 Val_Loss: 0.2417  BEST VAL Loss: 0.2417  Val_Acc: 91.028

Epoch 46: Validation loss decreased (0.241733 --> 0.241403).  Saving model ...
	 Train_Loss: 0.2944 Train_Acc: 89.366 Val_Loss: 0.2414  BEST VAL Loss: 0.2414  Val_Acc: 90.825

Epoch 47: Validation loss decreased (0.241403 --> 0.241092).  Saving model ...
	 Train_Loss: 0.2939 Train_Acc: 89.348 Val_Loss: 0.2411  BEST VAL Loss: 0.2411  Val_Acc: 90.950

Epoch 48: Validation loss decreased (0.241092 --> 0.240751).  Saving model ...
	 Train_Loss: 0.2935 Train_Acc: 89.284 Val_Loss: 0.2408  BEST VAL Loss: 0.2408  Val_Acc: 91.127

Epoch 49: Validation loss decreased (0.240751 --> 0.240379).  Saving model ...
	 Train_Loss: 0.2930 Train_Acc: 89.457 Val_Loss: 0.2404  BEST VAL Loss: 0.2404  Val_Acc: 91.127

Epoch 50: Validation loss decreased (0.240379 --> 0.240043).  Saving model ...
	 Train_Loss: 0.2925 Train_Acc: 89.428 Val_Loss: 0.2400  BEST VAL Loss: 0.2400  Val_Acc: 91.032

Epoch 51: Validation loss decreased (0.240043 --> 0.239746).  Saving model ...
	 Train_Loss: 0.2921 Train_Acc: 89.481 Val_Loss: 0.2397  BEST VAL Loss: 0.2397  Val_Acc: 90.967

Epoch 52: Validation loss decreased (0.239746 --> 0.239463).  Saving model ...
	 Train_Loss: 0.2917 Train_Acc: 89.386 Val_Loss: 0.2395  BEST VAL Loss: 0.2395  Val_Acc: 90.971

Epoch 53: Validation loss decreased (0.239463 --> 0.239212).  Saving model ...
	 Train_Loss: 0.2913 Train_Acc: 89.439 Val_Loss: 0.2392  BEST VAL Loss: 0.2392  Val_Acc: 91.028

Epoch 54: Validation loss decreased (0.239212 --> 0.238948).  Saving model ...
	 Train_Loss: 0.2909 Train_Acc: 89.413 Val_Loss: 0.2389  BEST VAL Loss: 0.2389  Val_Acc: 90.980

Epoch 55: Validation loss decreased (0.238948 --> 0.238747).  Saving model ...
	 Train_Loss: 0.2905 Train_Acc: 89.515 Val_Loss: 0.2387  BEST VAL Loss: 0.2387  Val_Acc: 90.902

Epoch 56: Validation loss decreased (0.238747 --> 0.238524).  Saving model ...
	 Train_Loss: 0.2901 Train_Acc: 89.517 Val_Loss: 0.2385  BEST VAL Loss: 0.2385  Val_Acc: 91.144

Epoch 57: Validation loss decreased (0.238524 --> 0.238314).  Saving model ...
	 Train_Loss: 0.2897 Train_Acc: 89.526 Val_Loss: 0.2383  BEST VAL Loss: 0.2383  Val_Acc: 91.088

Epoch 58: Validation loss decreased (0.238314 --> 0.238099).  Saving model ...
	 Train_Loss: 0.2893 Train_Acc: 89.480 Val_Loss: 0.2381  BEST VAL Loss: 0.2381  Val_Acc: 91.101

Epoch 59: Validation loss decreased (0.238099 --> 0.237844).  Saving model ...
	 Train_Loss: 0.2889 Train_Acc: 89.541 Val_Loss: 0.2378  BEST VAL Loss: 0.2378  Val_Acc: 91.084

Epoch 60: Validation loss decreased (0.237844 --> 0.237606).  Saving model ...
	 Train_Loss: 0.2886 Train_Acc: 89.580 Val_Loss: 0.2376  BEST VAL Loss: 0.2376  Val_Acc: 91.131

Epoch 61: Validation loss decreased (0.237606 --> 0.237357).  Saving model ...
	 Train_Loss: 0.2882 Train_Acc: 89.596 Val_Loss: 0.2374  BEST VAL Loss: 0.2374  Val_Acc: 91.179

Epoch 62: Validation loss decreased (0.237357 --> 0.237173).  Saving model ...
	 Train_Loss: 0.2879 Train_Acc: 89.555 Val_Loss: 0.2372  BEST VAL Loss: 0.2372  Val_Acc: 91.032

Epoch 63: Validation loss decreased (0.237173 --> 0.236907).  Saving model ...
	 Train_Loss: 0.2876 Train_Acc: 89.589 Val_Loss: 0.2369  BEST VAL Loss: 0.2369  Val_Acc: 91.386

Epoch 64: Validation loss decreased (0.236907 --> 0.236703).  Saving model ...
	 Train_Loss: 0.2872 Train_Acc: 89.592 Val_Loss: 0.2367  BEST VAL Loss: 0.2367  Val_Acc: 91.153

Epoch 65: Validation loss decreased (0.236703 --> 0.236520).  Saving model ...
	 Train_Loss: 0.2869 Train_Acc: 89.588 Val_Loss: 0.2365  BEST VAL Loss: 0.2365  Val_Acc: 91.187

Epoch 66: Validation loss decreased (0.236520 --> 0.236318).  Saving model ...
	 Train_Loss: 0.2866 Train_Acc: 89.623 Val_Loss: 0.2363  BEST VAL Loss: 0.2363  Val_Acc: 91.153

Epoch 67: Validation loss decreased (0.236318 --> 0.236143).  Saving model ...
	 Train_Loss: 0.2863 Train_Acc: 89.655 Val_Loss: 0.2361  BEST VAL Loss: 0.2361  Val_Acc: 91.002

Epoch 68: Validation loss decreased (0.236143 --> 0.235919).  Saving model ...
	 Train_Loss: 0.2860 Train_Acc: 89.683 Val_Loss: 0.2359  BEST VAL Loss: 0.2359  Val_Acc: 91.295

Epoch 69: Validation loss decreased (0.235919 --> 0.235708).  Saving model ...
	 Train_Loss: 0.2857 Train_Acc: 89.735 Val_Loss: 0.2357  BEST VAL Loss: 0.2357  Val_Acc: 91.222

Epoch 70: Validation loss decreased (0.235708 --> 0.235503).  Saving model ...
	 Train_Loss: 0.2854 Train_Acc: 89.730 Val_Loss: 0.2355  BEST VAL Loss: 0.2355  Val_Acc: 91.166

Epoch 71: Validation loss decreased (0.235503 --> 0.235327).  Saving model ...
	 Train_Loss: 0.2851 Train_Acc: 89.717 Val_Loss: 0.2353  BEST VAL Loss: 0.2353  Val_Acc: 90.989

Epoch 72: Validation loss decreased (0.235327 --> 0.235109).  Saving model ...
	 Train_Loss: 0.2848 Train_Acc: 89.704 Val_Loss: 0.2351  BEST VAL Loss: 0.2351  Val_Acc: 91.269

Epoch 73: Validation loss decreased (0.235109 --> 0.234903).  Saving model ...
	 Train_Loss: 0.2845 Train_Acc: 89.637 Val_Loss: 0.2349  BEST VAL Loss: 0.2349  Val_Acc: 91.377

Epoch 74: Validation loss decreased (0.234903 --> 0.234738).  Saving model ...
	 Train_Loss: 0.2842 Train_Acc: 89.809 Val_Loss: 0.2347  BEST VAL Loss: 0.2347  Val_Acc: 91.213

Epoch 75: Validation loss decreased (0.234738 --> 0.234619).  Saving model ...
	 Train_Loss: 0.2839 Train_Acc: 89.744 Val_Loss: 0.2346  BEST VAL Loss: 0.2346  Val_Acc: 90.842

Epoch 76: Validation loss decreased (0.234619 --> 0.234474).  Saving model ...
	 Train_Loss: 0.2837 Train_Acc: 89.714 Val_Loss: 0.2345  BEST VAL Loss: 0.2345  Val_Acc: 91.127

Epoch 77: Validation loss decreased (0.234474 --> 0.234316).  Saving model ...
	 Train_Loss: 0.2834 Train_Acc: 89.604 Val_Loss: 0.2343  BEST VAL Loss: 0.2343  Val_Acc: 91.282

Epoch 78: Validation loss decreased (0.234316 --> 0.234180).  Saving model ...
	 Train_Loss: 0.2832 Train_Acc: 89.724 Val_Loss: 0.2342  BEST VAL Loss: 0.2342  Val_Acc: 91.131

Epoch 79: Validation loss decreased (0.234180 --> 0.234049).  Saving model ...
	 Train_Loss: 0.2829 Train_Acc: 89.763 Val_Loss: 0.2340  BEST VAL Loss: 0.2340  Val_Acc: 91.192

Epoch 80: Validation loss decreased (0.234049 --> 0.233919).  Saving model ...
	 Train_Loss: 0.2826 Train_Acc: 89.915 Val_Loss: 0.2339  BEST VAL Loss: 0.2339  Val_Acc: 91.066

Epoch 81: Validation loss decreased (0.233919 --> 0.233761).  Saving model ...
	 Train_Loss: 0.2824 Train_Acc: 89.829 Val_Loss: 0.2338  BEST VAL Loss: 0.2338  Val_Acc: 91.343

Epoch 82: Validation loss decreased (0.233761 --> 0.233642).  Saving model ...
	 Train_Loss: 0.2821 Train_Acc: 89.674 Val_Loss: 0.2336  BEST VAL Loss: 0.2336  Val_Acc: 91.110

Epoch 83: Validation loss decreased (0.233642 --> 0.233515).  Saving model ...
	 Train_Loss: 0.2819 Train_Acc: 89.742 Val_Loss: 0.2335  BEST VAL Loss: 0.2335  Val_Acc: 91.196

Epoch 84: Validation loss decreased (0.233515 --> 0.233407).  Saving model ...
	 Train_Loss: 0.2817 Train_Acc: 89.770 Val_Loss: 0.2334  BEST VAL Loss: 0.2334  Val_Acc: 91.135

Epoch 85: Validation loss decreased (0.233407 --> 0.233297).  Saving model ...
	 Train_Loss: 0.2814 Train_Acc: 89.760 Val_Loss: 0.2333  BEST VAL Loss: 0.2333  Val_Acc: 91.243

Epoch 86: Validation loss decreased (0.233297 --> 0.233152).  Saving model ...
	 Train_Loss: 0.2812 Train_Acc: 89.797 Val_Loss: 0.2332  BEST VAL Loss: 0.2332  Val_Acc: 91.321

Epoch 87: Validation loss decreased (0.233152 --> 0.233028).  Saving model ...
	 Train_Loss: 0.2810 Train_Acc: 89.765 Val_Loss: 0.2330  BEST VAL Loss: 0.2330  Val_Acc: 91.101

Epoch 88: Validation loss decreased (0.233028 --> 0.232926).  Saving model ...
	 Train_Loss: 0.2808 Train_Acc: 89.919 Val_Loss: 0.2329  BEST VAL Loss: 0.2329  Val_Acc: 91.131

Epoch 89: Validation loss decreased (0.232926 --> 0.232818).  Saving model ...
	 Train_Loss: 0.2805 Train_Acc: 89.821 Val_Loss: 0.2328  BEST VAL Loss: 0.2328  Val_Acc: 91.287

Epoch 90: Validation loss decreased (0.232818 --> 0.232695).  Saving model ...
	 Train_Loss: 0.2803 Train_Acc: 89.891 Val_Loss: 0.2327  BEST VAL Loss: 0.2327  Val_Acc: 91.287

Epoch 91: Validation loss decreased (0.232695 --> 0.232577).  Saving model ...
	 Train_Loss: 0.2801 Train_Acc: 89.863 Val_Loss: 0.2326  BEST VAL Loss: 0.2326  Val_Acc: 91.205

Epoch 92: Validation loss decreased (0.232577 --> 0.232434).  Saving model ...
	 Train_Loss: 0.2799 Train_Acc: 89.902 Val_Loss: 0.2324  BEST VAL Loss: 0.2324  Val_Acc: 91.291

Epoch 93: Validation loss decreased (0.232434 --> 0.232299).  Saving model ...
	 Train_Loss: 0.2797 Train_Acc: 89.828 Val_Loss: 0.2323  BEST VAL Loss: 0.2323  Val_Acc: 91.278

Epoch 94: Validation loss decreased (0.232299 --> 0.232185).  Saving model ...
	 Train_Loss: 0.2795 Train_Acc: 89.826 Val_Loss: 0.2322  BEST VAL Loss: 0.2322  Val_Acc: 91.317

Epoch 95: Validation loss decreased (0.232185 --> 0.232107).  Saving model ...
	 Train_Loss: 0.2793 Train_Acc: 89.900 Val_Loss: 0.2321  BEST VAL Loss: 0.2321  Val_Acc: 91.213

Epoch 96: Validation loss decreased (0.232107 --> 0.232003).  Saving model ...
	 Train_Loss: 0.2790 Train_Acc: 89.979 Val_Loss: 0.2320  BEST VAL Loss: 0.2320  Val_Acc: 91.287

Epoch 97: Validation loss decreased (0.232003 --> 0.231892).  Saving model ...
	 Train_Loss: 0.2788 Train_Acc: 89.921 Val_Loss: 0.2319  BEST VAL Loss: 0.2319  Val_Acc: 91.287

Epoch 98: Validation loss decreased (0.231892 --> 0.231812).  Saving model ...
	 Train_Loss: 0.2786 Train_Acc: 89.953 Val_Loss: 0.2318  BEST VAL Loss: 0.2318  Val_Acc: 91.118

Epoch 99: Validation loss decreased (0.231812 --> 0.231708).  Saving model ...
	 Train_Loss: 0.2784 Train_Acc: 89.920 Val_Loss: 0.2317  BEST VAL Loss: 0.2317  Val_Acc: 91.196

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.92      0.91      0.92     85027
           1       0.93      0.94      0.93    100339

    accuracy                           0.93    185366
   macro avg       0.93      0.93      0.93    185366
weighted avg       0.93      0.93      0.93    185366

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.91      0.90      0.90     10628
           1       0.91      0.93      0.92     12543

    accuracy                           0.91     23171
   macro avg       0.91      0.91      0.91     23171
weighted avg       0.91      0.91      0.91     23171

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.91      0.90      0.90     10628
           1       0.91      0.92      0.92     12543

    accuracy                           0.91     23171
   macro avg       0.91      0.91      0.91     23171
weighted avg       0.91      0.91      0.91     23171

              precision    recall  f1-score   support

           0       0.91      0.90      0.90     10628
           1       0.91      0.92      0.92     12543

    accuracy                           0.91     23171
   macro avg       0.91      0.91      0.91     23171
weighted avg       0.91      0.91      0.91     23171

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_LPS_0.010_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.97      0.95     36797
           1       0.97      0.94      0.95     40588

    accuracy                           0.95     77385
   macro avg       0.95      0.95      0.95     77385
weighted avg       0.95      0.95      0.95     77385

              precision    recall  f1-score   support

           0       0.93      0.97      0.95     36797
           1       0.97      0.94      0.95     40588

    accuracy                           0.95     77385
   macro avg       0.95      0.95      0.95     77385
weighted avg       0.95      0.95      0.95     77385

completed
