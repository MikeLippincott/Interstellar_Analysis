[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '9a55c81c'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'ba52885c'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'f88e7f89'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '0d547898'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_1.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_Nigericin_1.000_3.0_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (29461, 1276)
Number of total missing values across all columns: 31618
Data Subset Is Off
Wells held out for testing: ['L16' 'M22']
Wells to use for training, validation, and testing ['L17' 'M18' 'M19' 'L20' 'L21' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.302670).  Saving model ...
	 Train_Loss: 0.6758 Train_Acc: 76.656 Val_Loss: 0.3027  BEST VAL Loss: 0.3027  Val_Acc: 88.122

Epoch 1: Validation loss decreased (0.302670 --> 0.265515).  Saving model ...
	 Train_Loss: 0.4818 Train_Acc: 88.878 Val_Loss: 0.2655  BEST VAL Loss: 0.2655  Val_Acc: 90.976

Epoch 2: Validation loss decreased (0.265515 --> 0.233909).  Saving model ...
	 Train_Loss: 0.3924 Train_Acc: 91.941 Val_Loss: 0.2339  BEST VAL Loss: 0.2339  Val_Acc: 93.232

Epoch 3: Validation loss decreased (0.233909 --> 0.211521).  Saving model ...
	 Train_Loss: 0.3396 Train_Acc: 93.155 Val_Loss: 0.2115  BEST VAL Loss: 0.2115  Val_Acc: 94.751

Epoch 4: Validation loss decreased (0.211521 --> 0.195126).  Saving model ...
	 Train_Loss: 0.3027 Train_Acc: 94.370 Val_Loss: 0.1951  BEST VAL Loss: 0.1951  Val_Acc: 95.028

Epoch 5: Validation loss decreased (0.195126 --> 0.182803).  Saving model ...
	 Train_Loss: 0.2743 Train_Acc: 95.187 Val_Loss: 0.1828  BEST VAL Loss: 0.1828  Val_Acc: 95.488

Epoch 6: Validation loss decreased (0.182803 --> 0.174786).  Saving model ...
	 Train_Loss: 0.2539 Train_Acc: 94.951 Val_Loss: 0.1748  BEST VAL Loss: 0.1748  Val_Acc: 95.304

Epoch 7: Validation loss decreased (0.174786 --> 0.169180).  Saving model ...
	 Train_Loss: 0.2368 Train_Acc: 95.585 Val_Loss: 0.1692  BEST VAL Loss: 0.1692  Val_Acc: 95.764

Epoch 8: Validation loss decreased (0.169180 --> 0.164681).  Saving model ...
	 Train_Loss: 0.2239 Train_Acc: 95.360 Val_Loss: 0.1647  BEST VAL Loss: 0.1647  Val_Acc: 95.304

Epoch 9: Validation loss decreased (0.164681 --> 0.160933).  Saving model ...
	 Train_Loss: 0.2127 Train_Acc: 95.815 Val_Loss: 0.1609  BEST VAL Loss: 0.1609  Val_Acc: 95.304

Epoch 10: Validation loss decreased (0.160933 --> 0.158517).  Saving model ...
	 Train_Loss: 0.2033 Train_Acc: 95.803 Val_Loss: 0.1585  BEST VAL Loss: 0.1585  Val_Acc: 95.626

Epoch 11: Validation loss decreased (0.158517 --> 0.156390).  Saving model ...
	 Train_Loss: 0.1948 Train_Acc: 96.224 Val_Loss: 0.1564  BEST VAL Loss: 0.1564  Val_Acc: 95.672

Epoch 12: Validation loss decreased (0.156390 --> 0.154281).  Saving model ...
	 Train_Loss: 0.1870 Train_Acc: 96.385 Val_Loss: 0.1543  BEST VAL Loss: 0.1543  Val_Acc: 95.120

Epoch 13: Validation loss decreased (0.154281 --> 0.152051).  Saving model ...
	 Train_Loss: 0.1803 Train_Acc: 96.592 Val_Loss: 0.1521  BEST VAL Loss: 0.1521  Val_Acc: 95.764

Epoch 14: Validation loss decreased (0.152051 --> 0.150528).  Saving model ...
	 Train_Loss: 0.1741 Train_Acc: 96.719 Val_Loss: 0.1505  BEST VAL Loss: 0.1505  Val_Acc: 95.580

Epoch 15: Validation loss decreased (0.150528 --> 0.148501).  Saving model ...
	 Train_Loss: 0.1683 Train_Acc: 97.064 Val_Loss: 0.1485  BEST VAL Loss: 0.1485  Val_Acc: 96.225

Epoch 16: Validation loss decreased (0.148501 --> 0.147078).  Saving model ...
	 Train_Loss: 0.1632 Train_Acc: 96.742 Val_Loss: 0.1471  BEST VAL Loss: 0.1471  Val_Acc: 95.672

Epoch 17: Validation loss decreased (0.147078 --> 0.145688).  Saving model ...
	 Train_Loss: 0.1591 Train_Acc: 96.650 Val_Loss: 0.1457  BEST VAL Loss: 0.1457  Val_Acc: 95.948

Epoch 18: Validation loss decreased (0.145688 --> 0.144500).  Saving model ...
	 Train_Loss: 0.1552 Train_Acc: 97.030 Val_Loss: 0.1445  BEST VAL Loss: 0.1445  Val_Acc: 96.179

Epoch 19: Validation loss decreased (0.144500 --> 0.142896).  Saving model ...
	 Train_Loss: 0.1516 Train_Acc: 96.978 Val_Loss: 0.1429  BEST VAL Loss: 0.1429  Val_Acc: 96.547

Epoch 20: Validation loss decreased (0.142896 --> 0.141709).  Saving model ...
	 Train_Loss: 0.1482 Train_Acc: 97.225 Val_Loss: 0.1417  BEST VAL Loss: 0.1417  Val_Acc: 96.639

Epoch 21: Validation loss decreased (0.141709 --> 0.139957).  Saving model ...
	 Train_Loss: 0.1448 Train_Acc: 97.519 Val_Loss: 0.1400  BEST VAL Loss: 0.1400  Val_Acc: 97.099

Epoch 22: Validation loss decreased (0.139957 --> 0.138485).  Saving model ...
	 Train_Loss: 0.1418 Train_Acc: 97.231 Val_Loss: 0.1385  BEST VAL Loss: 0.1385  Val_Acc: 96.731

Epoch 23: Validation loss decreased (0.138485 --> 0.137649).  Saving model ...
	 Train_Loss: 0.1389 Train_Acc: 97.404 Val_Loss: 0.1376  BEST VAL Loss: 0.1376  Val_Acc: 96.823

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.1361 Train_Acc: 97.398 Val_Loss: 0.1379  BEST VAL Loss: 0.1376  Val_Acc: 96.041

Epoch 25: Validation loss did not decrease
	 Train_Loss: 0.1335 Train_Acc: 97.375 Val_Loss: 0.1381  BEST VAL Loss: 0.1376  Val_Acc: 96.271

Epoch 26: Validation loss decreased (0.137649 --> 0.137392).  Saving model ...
	 Train_Loss: 0.1312 Train_Acc: 97.369 Val_Loss: 0.1374  BEST VAL Loss: 0.1374  Val_Acc: 96.317

Epoch 27: Validation loss decreased (0.137392 --> 0.137370).  Saving model ...
	 Train_Loss: 0.1288 Train_Acc: 97.663 Val_Loss: 0.1374  BEST VAL Loss: 0.1374  Val_Acc: 95.902

Epoch 28: Validation loss decreased (0.137370 --> 0.136893).  Saving model ...
	 Train_Loss: 0.1267 Train_Acc: 97.496 Val_Loss: 0.1369  BEST VAL Loss: 0.1369  Val_Acc: 96.363

Epoch 29: Validation loss decreased (0.136893 --> 0.136843).  Saving model ...
	 Train_Loss: 0.1249 Train_Acc: 97.352 Val_Loss: 0.1368  BEST VAL Loss: 0.1368  Val_Acc: 96.731

Epoch 30: Validation loss decreased (0.136843 --> 0.136440).  Saving model ...
	 Train_Loss: 0.1230 Train_Acc: 97.427 Val_Loss: 0.1364  BEST VAL Loss: 0.1364  Val_Acc: 96.823

Epoch 31: Validation loss decreased (0.136440 --> 0.135752).  Saving model ...
	 Train_Loss: 0.1213 Train_Acc: 97.438 Val_Loss: 0.1358  BEST VAL Loss: 0.1358  Val_Acc: 96.593

Epoch 32: Validation loss decreased (0.135752 --> 0.135254).  Saving model ...
	 Train_Loss: 0.1194 Train_Acc: 97.807 Val_Loss: 0.1353  BEST VAL Loss: 0.1353  Val_Acc: 96.685

Epoch 33: Validation loss decreased (0.135254 --> 0.134792).  Saving model ...
	 Train_Loss: 0.1176 Train_Acc: 97.905 Val_Loss: 0.1348  BEST VAL Loss: 0.1348  Val_Acc: 96.915

Epoch 34: Validation loss decreased (0.134792 --> 0.134710).  Saving model ...
	 Train_Loss: 0.1159 Train_Acc: 97.847 Val_Loss: 0.1347  BEST VAL Loss: 0.1347  Val_Acc: 97.007

Epoch 35: Validation loss did not decrease
	 Train_Loss: 0.1142 Train_Acc: 97.951 Val_Loss: 0.1351  BEST VAL Loss: 0.1347  Val_Acc: 96.593

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.1125 Train_Acc: 98.175 Val_Loss: 0.1350  BEST VAL Loss: 0.1347  Val_Acc: 96.547

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.1111 Train_Acc: 97.818 Val_Loss: 0.1354  BEST VAL Loss: 0.1347  Val_Acc: 96.547

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.1098 Train_Acc: 97.882 Val_Loss: 0.1358  BEST VAL Loss: 0.1347  Val_Acc: 96.087

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.1086 Train_Acc: 97.720 Val_Loss: 0.1362  BEST VAL Loss: 0.1347  Val_Acc: 96.593

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.1074 Train_Acc: 97.720 Val_Loss: 0.1364  BEST VAL Loss: 0.1347  Val_Acc: 96.731

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.1062 Train_Acc: 97.847 Val_Loss: 0.1367  BEST VAL Loss: 0.1347  Val_Acc: 96.501

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.1051 Train_Acc: 97.939 Val_Loss: 0.1372  BEST VAL Loss: 0.1347  Val_Acc: 97.007

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.1039 Train_Acc: 98.031 Val_Loss: 0.1373  BEST VAL Loss: 0.1347  Val_Acc: 97.192

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.1028 Train_Acc: 97.945 Val_Loss: 0.1372  BEST VAL Loss: 0.1347  Val_Acc: 96.961

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.1018 Train_Acc: 97.928 Val_Loss: 0.1372  BEST VAL Loss: 0.1347  Val_Acc: 97.007

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.1008 Train_Acc: 98.112 Val_Loss: 0.1373  BEST VAL Loss: 0.1347  Val_Acc: 96.685

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.0998 Train_Acc: 98.221 Val_Loss: 0.1377  BEST VAL Loss: 0.1347  Val_Acc: 96.961

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.0988 Train_Acc: 98.187 Val_Loss: 0.1382  BEST VAL Loss: 0.1347  Val_Acc: 96.777

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.0979 Train_Acc: 97.876 Val_Loss: 0.1387  BEST VAL Loss: 0.1347  Val_Acc: 97.099

Epoch 50: Validation loss did not decrease
Early stopped at epoch : 50
Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      1.00      1.00      9433
           1       1.00      0.99      0.99      7938

    accuracy                           0.99     17371
   macro avg       0.99      0.99      0.99     17371
weighted avg       0.99      0.99      0.99     17371

Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.98      0.97      1179
           1       0.97      0.96      0.97       993

    accuracy                           0.97      2172
   macro avg       0.97      0.97      0.97      2172
weighted avg       0.97      0.97      0.97      2172

Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.96      0.96      1180
           1       0.95      0.96      0.96       992

    accuracy                           0.96      2172
   macro avg       0.96      0.96      0.96      2172
weighted avg       0.96      0.96      0.96      2172

              precision    recall  f1-score   support

           0       0.97      0.96      0.96      1180
           1       0.95      0.96      0.96       992

    accuracy                           0.96      2172
   macro avg       0.96      0.96      0.96      2172
weighted avg       0.96      0.96      0.96      2172

Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_3.0_DMSO_0.025
              precision    recall  f1-score   support

           0       0.93      0.97      0.95      4017
           1       0.97      0.92      0.94      3729

    accuracy                           0.95      7746
   macro avg       0.95      0.94      0.94      7746
weighted avg       0.95      0.95      0.94      7746

              precision    recall  f1-score   support

           0       0.93      0.97      0.95      4017
           1       0.97      0.92      0.94      3729

    accuracy                           0.95      7746
   macro avg       0.95      0.94      0.94      7746
weighted avg       0.95      0.95      0.94      7746

completed
