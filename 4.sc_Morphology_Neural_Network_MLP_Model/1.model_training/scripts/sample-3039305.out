[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '70625aad'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '6c84b1e2'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '3887187f'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '1000aef9'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_100.000_DMSO_0.025 treatment_name: H2O2_100.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_100.000_DMSO_0.025
TREATMENT_NAME: H2O2_100.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['H2O2_100.000_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (42887, 1276)
Number of total missing values across all columns: 85774
Data Subset Is Off
Wells held out for testing: ['H22' 'J16']
Wells to use for training, validation, and testing ['H18' 'H19' 'H23' 'J17' 'I18' 'I19' 'J20' 'J21' 'I22' 'I23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.518858).  Saving model ...
	 Train_Loss: 0.6159 Train_Acc: 71.597 Val_Loss: 0.5189  BEST VAL Loss: 0.5189  Val_Acc: 90.234

Epoch 1: Validation loss decreased (0.518858 --> 0.469618).  Saving model ...
	 Train_Loss: 0.5554 Train_Acc: 84.202 Val_Loss: 0.4696  BEST VAL Loss: 0.4696  Val_Acc: 93.355

Epoch 2: Validation loss decreased (0.469618 --> 0.431993).  Saving model ...
	 Train_Loss: 0.5132 Train_Acc: 86.030 Val_Loss: 0.4320  BEST VAL Loss: 0.4320  Val_Acc: 94.452

Epoch 3: Validation loss decreased (0.431993 --> 0.401172).  Saving model ...
	 Train_Loss: 0.4793 Train_Acc: 88.053 Val_Loss: 0.4012  BEST VAL Loss: 0.4012  Val_Acc: 95.030

Epoch 4: Validation loss decreased (0.401172 --> 0.375602).  Saving model ...
	 Train_Loss: 0.4511 Train_Acc: 90.296 Val_Loss: 0.3756  BEST VAL Loss: 0.3756  Val_Acc: 95.348

Epoch 5: Validation loss decreased (0.375602 --> 0.353654).  Saving model ...
	 Train_Loss: 0.4273 Train_Acc: 91.488 Val_Loss: 0.3537  BEST VAL Loss: 0.3537  Val_Acc: 95.810

Epoch 6: Validation loss decreased (0.353654 --> 0.335572).  Saving model ...
	 Train_Loss: 0.4075 Train_Acc: 91.973 Val_Loss: 0.3356  BEST VAL Loss: 0.3356  Val_Acc: 95.897

Epoch 7: Validation loss decreased (0.335572 --> 0.319434).  Saving model ...
	 Train_Loss: 0.3905 Train_Acc: 92.666 Val_Loss: 0.3194  BEST VAL Loss: 0.3194  Val_Acc: 96.215

Epoch 8: Validation loss decreased (0.319434 --> 0.305555).  Saving model ...
	 Train_Loss: 0.3760 Train_Acc: 92.941 Val_Loss: 0.3056  BEST VAL Loss: 0.3056  Val_Acc: 96.128

Epoch 9: Validation loss decreased (0.305555 --> 0.293266).  Saving model ...
	 Train_Loss: 0.3632 Train_Acc: 93.248 Val_Loss: 0.2933  BEST VAL Loss: 0.2933  Val_Acc: 96.446

Epoch 10: Validation loss decreased (0.293266 --> 0.282364).  Saving model ...
	 Train_Loss: 0.3515 Train_Acc: 93.721 Val_Loss: 0.2824  BEST VAL Loss: 0.2824  Val_Acc: 96.591

Epoch 11: Validation loss decreased (0.282364 --> 0.272834).  Saving model ...
	 Train_Loss: 0.3415 Train_Acc: 93.638 Val_Loss: 0.2728  BEST VAL Loss: 0.2728  Val_Acc: 96.417

Epoch 12: Validation loss decreased (0.272834 --> 0.264118).  Saving model ...
	 Train_Loss: 0.3322 Train_Acc: 94.010 Val_Loss: 0.2641  BEST VAL Loss: 0.2641  Val_Acc: 96.619

Epoch 13: Validation loss decreased (0.264118 --> 0.256579).  Saving model ...
	 Train_Loss: 0.3243 Train_Acc: 94.097 Val_Loss: 0.2566  BEST VAL Loss: 0.2566  Val_Acc: 96.070

Epoch 14: Validation loss decreased (0.256579 --> 0.249659).  Saving model ...
	 Train_Loss: 0.3171 Train_Acc: 93.970 Val_Loss: 0.2497  BEST VAL Loss: 0.2497  Val_Acc: 96.417

Epoch 15: Validation loss decreased (0.249659 --> 0.243197).  Saving model ...
	 Train_Loss: 0.3104 Train_Acc: 94.321 Val_Loss: 0.2432  BEST VAL Loss: 0.2432  Val_Acc: 96.677

Epoch 16: Validation loss decreased (0.243197 --> 0.237390).  Saving model ...
	 Train_Loss: 0.3045 Train_Acc: 94.140 Val_Loss: 0.2374  BEST VAL Loss: 0.2374  Val_Acc: 96.591

Epoch 17: Validation loss decreased (0.237390 --> 0.232050).  Saving model ...
	 Train_Loss: 0.2990 Train_Acc: 94.357 Val_Loss: 0.2321  BEST VAL Loss: 0.2321  Val_Acc: 96.446

Epoch 18: Validation loss decreased (0.232050 --> 0.227231).  Saving model ...
	 Train_Loss: 0.2939 Train_Acc: 94.299 Val_Loss: 0.2272  BEST VAL Loss: 0.2272  Val_Acc: 96.562

Epoch 19: Validation loss decreased (0.227231 --> 0.222701).  Saving model ...
	 Train_Loss: 0.2892 Train_Acc: 94.422 Val_Loss: 0.2227  BEST VAL Loss: 0.2227  Val_Acc: 96.475

Epoch 20: Validation loss decreased (0.222701 --> 0.218539).  Saving model ...
	 Train_Loss: 0.2849 Train_Acc: 94.299 Val_Loss: 0.2185  BEST VAL Loss: 0.2185  Val_Acc: 96.619

Epoch 21: Validation loss decreased (0.218539 --> 0.214558).  Saving model ...
	 Train_Loss: 0.2809 Train_Acc: 94.404 Val_Loss: 0.2146  BEST VAL Loss: 0.2146  Val_Acc: 96.793

Epoch 22: Validation loss decreased (0.214558 --> 0.210899).  Saving model ...
	 Train_Loss: 0.2772 Train_Acc: 94.566 Val_Loss: 0.2109  BEST VAL Loss: 0.2109  Val_Acc: 96.735

Epoch 23: Validation loss decreased (0.210899 --> 0.207464).  Saving model ...
	 Train_Loss: 0.2738 Train_Acc: 94.574 Val_Loss: 0.2075  BEST VAL Loss: 0.2075  Val_Acc: 96.880

Epoch 24: Validation loss decreased (0.207464 --> 0.204199).  Saving model ...
	 Train_Loss: 0.2704 Train_Acc: 94.621 Val_Loss: 0.2042  BEST VAL Loss: 0.2042  Val_Acc: 96.822

Epoch 25: Validation loss decreased (0.204199 --> 0.201281).  Saving model ...
	 Train_Loss: 0.2671 Train_Acc: 94.852 Val_Loss: 0.2013  BEST VAL Loss: 0.2013  Val_Acc: 96.417

Epoch 26: Validation loss decreased (0.201281 --> 0.198440).  Saving model ...
	 Train_Loss: 0.2641 Train_Acc: 94.668 Val_Loss: 0.1984  BEST VAL Loss: 0.1984  Val_Acc: 96.880

Epoch 27: Validation loss decreased (0.198440 --> 0.195744).  Saving model ...
	 Train_Loss: 0.2612 Train_Acc: 94.946 Val_Loss: 0.1957  BEST VAL Loss: 0.1957  Val_Acc: 96.793

Epoch 28: Validation loss decreased (0.195744 --> 0.193382).  Saving model ...
	 Train_Loss: 0.2586 Train_Acc: 94.809 Val_Loss: 0.1934  BEST VAL Loss: 0.1934  Val_Acc: 97.082

Epoch 29: Validation loss decreased (0.193382 --> 0.190953).  Saving model ...
	 Train_Loss: 0.2559 Train_Acc: 94.935 Val_Loss: 0.1910  BEST VAL Loss: 0.1910  Val_Acc: 96.995

Epoch 30: Validation loss decreased (0.190953 --> 0.188853).  Saving model ...
	 Train_Loss: 0.2534 Train_Acc: 94.935 Val_Loss: 0.1889  BEST VAL Loss: 0.1889  Val_Acc: 96.475

Epoch 31: Validation loss decreased (0.188853 --> 0.186710).  Saving model ...
	 Train_Loss: 0.2514 Train_Acc: 94.740 Val_Loss: 0.1867  BEST VAL Loss: 0.1867  Val_Acc: 96.966

Epoch 32: Validation loss decreased (0.186710 --> 0.184690).  Saving model ...
	 Train_Loss: 0.2490 Train_Acc: 95.105 Val_Loss: 0.1847  BEST VAL Loss: 0.1847  Val_Acc: 96.706

Epoch 33: Validation loss decreased (0.184690 --> 0.182760).  Saving model ...
	 Train_Loss: 0.2470 Train_Acc: 94.809 Val_Loss: 0.1828  BEST VAL Loss: 0.1828  Val_Acc: 96.880

Epoch 34: Validation loss decreased (0.182760 --> 0.180851).  Saving model ...
	 Train_Loss: 0.2450 Train_Acc: 95.025 Val_Loss: 0.1809  BEST VAL Loss: 0.1809  Val_Acc: 97.255

Epoch 35: Validation loss decreased (0.180851 --> 0.179133).  Saving model ...
	 Train_Loss: 0.2430 Train_Acc: 95.166 Val_Loss: 0.1791  BEST VAL Loss: 0.1791  Val_Acc: 97.111

Epoch 36: Validation loss decreased (0.179133 --> 0.177516).  Saving model ...
	 Train_Loss: 0.2411 Train_Acc: 95.123 Val_Loss: 0.1775  BEST VAL Loss: 0.1775  Val_Acc: 96.880

Epoch 37: Validation loss decreased (0.177516 --> 0.175959).  Saving model ...
	 Train_Loss: 0.2393 Train_Acc: 95.011 Val_Loss: 0.1760  BEST VAL Loss: 0.1760  Val_Acc: 97.168

Epoch 38: Validation loss decreased (0.175959 --> 0.174482).  Saving model ...
	 Train_Loss: 0.2377 Train_Acc: 95.134 Val_Loss: 0.1745  BEST VAL Loss: 0.1745  Val_Acc: 96.966

Epoch 39: Validation loss decreased (0.174482 --> 0.173049).  Saving model ...
	 Train_Loss: 0.2361 Train_Acc: 95.000 Val_Loss: 0.1730  BEST VAL Loss: 0.1730  Val_Acc: 97.197

Epoch 40: Validation loss decreased (0.173049 --> 0.171656).  Saving model ...
	 Train_Loss: 0.2344 Train_Acc: 95.242 Val_Loss: 0.1717  BEST VAL Loss: 0.1717  Val_Acc: 96.822

Epoch 41: Validation loss decreased (0.171656 --> 0.170341).  Saving model ...
	 Train_Loss: 0.2329 Train_Acc: 95.130 Val_Loss: 0.1703  BEST VAL Loss: 0.1703  Val_Acc: 96.908

Epoch 42: Validation loss decreased (0.170341 --> 0.169064).  Saving model ...
	 Train_Loss: 0.2314 Train_Acc: 95.242 Val_Loss: 0.1691  BEST VAL Loss: 0.1691  Val_Acc: 96.995

Epoch 43: Validation loss decreased (0.169064 --> 0.167958).  Saving model ...
	 Train_Loss: 0.2299 Train_Acc: 95.491 Val_Loss: 0.1680  BEST VAL Loss: 0.1680  Val_Acc: 96.591

Epoch 44: Validation loss decreased (0.167958 --> 0.166708).  Saving model ...
	 Train_Loss: 0.2285 Train_Acc: 95.159 Val_Loss: 0.1667  BEST VAL Loss: 0.1667  Val_Acc: 97.168

Epoch 45: Validation loss decreased (0.166708 --> 0.165602).  Saving model ...
	 Train_Loss: 0.2271 Train_Acc: 95.441 Val_Loss: 0.1656  BEST VAL Loss: 0.1656  Val_Acc: 96.648

Epoch 46: Validation loss decreased (0.165602 --> 0.164491).  Saving model ...
	 Train_Loss: 0.2258 Train_Acc: 95.448 Val_Loss: 0.1645  BEST VAL Loss: 0.1645  Val_Acc: 97.024

Epoch 47: Validation loss decreased (0.164491 --> 0.163422).  Saving model ...
	 Train_Loss: 0.2245 Train_Acc: 95.322 Val_Loss: 0.1634  BEST VAL Loss: 0.1634  Val_Acc: 96.880

Epoch 48: Validation loss decreased (0.163422 --> 0.162364).  Saving model ...
	 Train_Loss: 0.2233 Train_Acc: 95.257 Val_Loss: 0.1624  BEST VAL Loss: 0.1624  Val_Acc: 97.082

Epoch 49: Validation loss decreased (0.162364 --> 0.161324).  Saving model ...
	 Train_Loss: 0.2222 Train_Acc: 95.434 Val_Loss: 0.1613  BEST VAL Loss: 0.1613  Val_Acc: 96.822

Epoch 50: Validation loss decreased (0.161324 --> 0.160334).  Saving model ...
	 Train_Loss: 0.2210 Train_Acc: 95.412 Val_Loss: 0.1603  BEST VAL Loss: 0.1603  Val_Acc: 97.082

Epoch 51: Validation loss decreased (0.160334 --> 0.159389).  Saving model ...
	 Train_Loss: 0.2199 Train_Acc: 95.488 Val_Loss: 0.1594  BEST VAL Loss: 0.1594  Val_Acc: 96.706

Epoch 52: Validation loss decreased (0.159389 --> 0.158481).  Saving model ...
	 Train_Loss: 0.2190 Train_Acc: 95.155 Val_Loss: 0.1585  BEST VAL Loss: 0.1585  Val_Acc: 96.937

Epoch 53: Validation loss decreased (0.158481 --> 0.157588).  Saving model ...
	 Train_Loss: 0.2179 Train_Acc: 95.387 Val_Loss: 0.1576  BEST VAL Loss: 0.1576  Val_Acc: 97.082

Epoch 54: Validation loss decreased (0.157588 --> 0.156737).  Saving model ...
	 Train_Loss: 0.2169 Train_Acc: 95.571 Val_Loss: 0.1567  BEST VAL Loss: 0.1567  Val_Acc: 97.284

Epoch 55: Validation loss decreased (0.156737 --> 0.155947).  Saving model ...
	 Train_Loss: 0.2159 Train_Acc: 95.480 Val_Loss: 0.1559  BEST VAL Loss: 0.1559  Val_Acc: 96.793

Epoch 56: Validation loss decreased (0.155947 --> 0.155131).  Saving model ...
	 Train_Loss: 0.2149 Train_Acc: 95.524 Val_Loss: 0.1551  BEST VAL Loss: 0.1551  Val_Acc: 97.168

Epoch 57: Validation loss decreased (0.155131 --> 0.154359).  Saving model ...
	 Train_Loss: 0.2139 Train_Acc: 95.600 Val_Loss: 0.1544  BEST VAL Loss: 0.1544  Val_Acc: 97.111

Epoch 58: Validation loss decreased (0.154359 --> 0.153616).  Saving model ...
	 Train_Loss: 0.2130 Train_Acc: 95.524 Val_Loss: 0.1536  BEST VAL Loss: 0.1536  Val_Acc: 97.053

Epoch 59: Validation loss decreased (0.153616 --> 0.152956).  Saving model ...
	 Train_Loss: 0.2122 Train_Acc: 95.415 Val_Loss: 0.1530  BEST VAL Loss: 0.1530  Val_Acc: 96.880

Epoch 60: Validation loss decreased (0.152956 --> 0.152254).  Saving model ...
	 Train_Loss: 0.2113 Train_Acc: 95.639 Val_Loss: 0.1523  BEST VAL Loss: 0.1523  Val_Acc: 97.024

Epoch 61: Validation loss decreased (0.152254 --> 0.151592).  Saving model ...
	 Train_Loss: 0.2105 Train_Acc: 95.462 Val_Loss: 0.1516  BEST VAL Loss: 0.1516  Val_Acc: 97.255

Epoch 62: Validation loss decreased (0.151592 --> 0.150979).  Saving model ...
	 Train_Loss: 0.2098 Train_Acc: 95.303 Val_Loss: 0.1510  BEST VAL Loss: 0.1510  Val_Acc: 96.851

Epoch 63: Validation loss decreased (0.150979 --> 0.150339).  Saving model ...
	 Train_Loss: 0.2089 Train_Acc: 95.679 Val_Loss: 0.1503  BEST VAL Loss: 0.1503  Val_Acc: 97.371

Epoch 64: Validation loss decreased (0.150339 --> 0.149732).  Saving model ...
	 Train_Loss: 0.2081 Train_Acc: 95.549 Val_Loss: 0.1497  BEST VAL Loss: 0.1497  Val_Acc: 96.966

Epoch 65: Validation loss decreased (0.149732 --> 0.149121).  Saving model ...
	 Train_Loss: 0.2074 Train_Acc: 95.517 Val_Loss: 0.1491  BEST VAL Loss: 0.1491  Val_Acc: 97.140

Epoch 66: Validation loss decreased (0.149121 --> 0.148511).  Saving model ...
	 Train_Loss: 0.2066 Train_Acc: 95.780 Val_Loss: 0.1485  BEST VAL Loss: 0.1485  Val_Acc: 97.082

Epoch 67: Validation loss decreased (0.148511 --> 0.147901).  Saving model ...
	 Train_Loss: 0.2058 Train_Acc: 95.751 Val_Loss: 0.1479  BEST VAL Loss: 0.1479  Val_Acc: 97.255

Epoch 68: Validation loss decreased (0.147901 --> 0.147363).  Saving model ...
	 Train_Loss: 0.2051 Train_Acc: 95.589 Val_Loss: 0.1474  BEST VAL Loss: 0.1474  Val_Acc: 96.908

Epoch 69: Validation loss decreased (0.147363 --> 0.146813).  Saving model ...
	 Train_Loss: 0.2045 Train_Acc: 95.614 Val_Loss: 0.1468  BEST VAL Loss: 0.1468  Val_Acc: 97.140

Epoch 70: Validation loss decreased (0.146813 --> 0.146267).  Saving model ...
	 Train_Loss: 0.2038 Train_Acc: 95.621 Val_Loss: 0.1463  BEST VAL Loss: 0.1463  Val_Acc: 97.111

Epoch 71: Validation loss decreased (0.146267 --> 0.145797).  Saving model ...
	 Train_Loss: 0.2031 Train_Acc: 95.759 Val_Loss: 0.1458  BEST VAL Loss: 0.1458  Val_Acc: 97.313

Epoch 72: Validation loss decreased (0.145797 --> 0.145304).  Saving model ...
	 Train_Loss: 0.2025 Train_Acc: 95.715 Val_Loss: 0.1453  BEST VAL Loss: 0.1453  Val_Acc: 97.053

Epoch 73: Validation loss decreased (0.145304 --> 0.144803).  Saving model ...
	 Train_Loss: 0.2018 Train_Acc: 95.679 Val_Loss: 0.1448  BEST VAL Loss: 0.1448  Val_Acc: 97.024

Epoch 74: Validation loss decreased (0.144803 --> 0.144310).  Saving model ...
	 Train_Loss: 0.2012 Train_Acc: 95.795 Val_Loss: 0.1443  BEST VAL Loss: 0.1443  Val_Acc: 97.400

Epoch 75: Validation loss decreased (0.144310 --> 0.143817).  Saving model ...
	 Train_Loss: 0.2006 Train_Acc: 95.639 Val_Loss: 0.1438  BEST VAL Loss: 0.1438  Val_Acc: 97.197

Epoch 76: Validation loss decreased (0.143817 --> 0.143478).  Saving model ...
	 Train_Loss: 0.2001 Train_Acc: 95.365 Val_Loss: 0.1435  BEST VAL Loss: 0.1435  Val_Acc: 96.417

Epoch 77: Validation loss decreased (0.143478 --> 0.143004).  Saving model ...
	 Train_Loss: 0.1995 Train_Acc: 95.733 Val_Loss: 0.1430  BEST VAL Loss: 0.1430  Val_Acc: 97.255

Epoch 78: Validation loss decreased (0.143004 --> 0.142576).  Saving model ...
	 Train_Loss: 0.1990 Train_Acc: 95.603 Val_Loss: 0.1426  BEST VAL Loss: 0.1426  Val_Acc: 97.226

Epoch 79: Validation loss decreased (0.142576 --> 0.142146).  Saving model ...
	 Train_Loss: 0.1984 Train_Acc: 95.712 Val_Loss: 0.1421  BEST VAL Loss: 0.1421  Val_Acc: 97.111

Epoch 80: Validation loss decreased (0.142146 --> 0.141838).  Saving model ...
	 Train_Loss: 0.1979 Train_Acc: 95.629 Val_Loss: 0.1418  BEST VAL Loss: 0.1418  Val_Acc: 96.533

Epoch 81: Validation loss decreased (0.141838 --> 0.141445).  Saving model ...
	 Train_Loss: 0.1974 Train_Acc: 95.748 Val_Loss: 0.1414  BEST VAL Loss: 0.1414  Val_Acc: 97.140

Epoch 82: Validation loss decreased (0.141445 --> 0.141101).  Saving model ...
	 Train_Loss: 0.1968 Train_Acc: 95.697 Val_Loss: 0.1411  BEST VAL Loss: 0.1411  Val_Acc: 96.793

Epoch 83: Validation loss decreased (0.141101 --> 0.140730).  Saving model ...
	 Train_Loss: 0.1963 Train_Acc: 95.849 Val_Loss: 0.1407  BEST VAL Loss: 0.1407  Val_Acc: 97.024

Epoch 84: Validation loss decreased (0.140730 --> 0.140386).  Saving model ...
	 Train_Loss: 0.1958 Train_Acc: 95.856 Val_Loss: 0.1404  BEST VAL Loss: 0.1404  Val_Acc: 96.793

Epoch 85: Validation loss decreased (0.140386 --> 0.140033).  Saving model ...
	 Train_Loss: 0.1953 Train_Acc: 95.780 Val_Loss: 0.1400  BEST VAL Loss: 0.1400  Val_Acc: 97.226

Epoch 86: Validation loss decreased (0.140033 --> 0.139651).  Saving model ...
	 Train_Loss: 0.1948 Train_Acc: 95.762 Val_Loss: 0.1397  BEST VAL Loss: 0.1397  Val_Acc: 97.342

Epoch 87: Validation loss decreased (0.139651 --> 0.139309).  Saving model ...
	 Train_Loss: 0.1943 Train_Acc: 95.733 Val_Loss: 0.1393  BEST VAL Loss: 0.1393  Val_Acc: 96.966

Epoch 88: Validation loss decreased (0.139309 --> 0.138955).  Saving model ...
	 Train_Loss: 0.1938 Train_Acc: 95.708 Val_Loss: 0.1390  BEST VAL Loss: 0.1390  Val_Acc: 97.197

Epoch 89: Validation loss decreased (0.138955 --> 0.138641).  Saving model ...
	 Train_Loss: 0.1933 Train_Acc: 95.806 Val_Loss: 0.1386  BEST VAL Loss: 0.1386  Val_Acc: 96.851

Epoch 90: Validation loss decreased (0.138641 --> 0.138295).  Saving model ...
	 Train_Loss: 0.1928 Train_Acc: 95.979 Val_Loss: 0.1383  BEST VAL Loss: 0.1383  Val_Acc: 97.082

Epoch 91: Validation loss decreased (0.138295 --> 0.138000).  Saving model ...
	 Train_Loss: 0.1924 Train_Acc: 95.751 Val_Loss: 0.1380  BEST VAL Loss: 0.1380  Val_Acc: 96.822

Epoch 92: Validation loss decreased (0.138000 --> 0.137701).  Saving model ...
	 Train_Loss: 0.1919 Train_Acc: 95.813 Val_Loss: 0.1377  BEST VAL Loss: 0.1377  Val_Acc: 96.966

Epoch 93: Validation loss decreased (0.137701 --> 0.137393).  Saving model ...
	 Train_Loss: 0.1914 Train_Acc: 95.788 Val_Loss: 0.1374  BEST VAL Loss: 0.1374  Val_Acc: 97.168

Epoch 94: Validation loss decreased (0.137393 --> 0.137100).  Saving model ...
	 Train_Loss: 0.1910 Train_Acc: 95.907 Val_Loss: 0.1371  BEST VAL Loss: 0.1371  Val_Acc: 97.197

Epoch 95: Validation loss decreased (0.137100 --> 0.136818).  Saving model ...
	 Train_Loss: 0.1906 Train_Acc: 95.791 Val_Loss: 0.1368  BEST VAL Loss: 0.1368  Val_Acc: 96.966

Epoch 96: Validation loss decreased (0.136818 --> 0.136589).  Saving model ...
	 Train_Loss: 0.1902 Train_Acc: 95.961 Val_Loss: 0.1366  BEST VAL Loss: 0.1366  Val_Acc: 96.822

Epoch 97: Validation loss decreased (0.136589 --> 0.136323).  Saving model ...
	 Train_Loss: 0.1898 Train_Acc: 95.762 Val_Loss: 0.1363  BEST VAL Loss: 0.1363  Val_Acc: 97.082

Epoch 98: Validation loss decreased (0.136323 --> 0.136046).  Saving model ...
	 Train_Loss: 0.1894 Train_Acc: 95.719 Val_Loss: 0.1360  BEST VAL Loss: 0.1360  Val_Acc: 97.082

Epoch 99: Validation loss decreased (0.136046 --> 0.135804).  Saving model ...
	 Train_Loss: 0.1891 Train_Acc: 95.719 Val_Loss: 0.1358  BEST VAL Loss: 0.1358  Val_Acc: 96.908

LPS_100.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.99      0.99     18174
           1       0.99      0.96      0.97      9506

    accuracy                           0.98     27680
   macro avg       0.98      0.98      0.98     27680
weighted avg       0.98      0.98      0.98     27680

LPS_100.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.98      0.98      2272
           1       0.97      0.94      0.95      1189

    accuracy                           0.97      3461
   macro avg       0.97      0.96      0.97      3461
weighted avg       0.97      0.97      0.97      3461

LPS_100.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.98      0.97      2272
           1       0.97      0.94      0.95      1189

    accuracy                           0.97      3461
   macro avg       0.97      0.96      0.96      3461
weighted avg       0.97      0.97      0.97      3461

              precision    recall  f1-score   support

           0       0.97      0.98      0.97      2272
           1       0.97      0.94      0.95      1189

    accuracy                           0.97      3461
   macro avg       0.97      0.96      0.96      3461
weighted avg       0.97      0.97      0.97      3461

LPS_100.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_100.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.92      0.99      0.96      4182
           1       0.99      0.92      0.95      4103

    accuracy                           0.95      8285
   macro avg       0.96      0.95      0.95      8285
weighted avg       0.96      0.95      0.95      8285

              precision    recall  f1-score   support

           0       0.92      0.99      0.96      4182
           1       0.99      0.92      0.95      4103

    accuracy                           0.95      8285
   macro avg       0.96      0.95      0.95      8285
weighted avg       0.96      0.95      0.95      8285

completed
