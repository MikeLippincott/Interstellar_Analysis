[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '8e58efff'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'c2144cdf'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'c13a4222'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '2ce2c22c'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Flagellin_0.100_DMSO_0.025 treatment_name: DMSO_0.100_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: DMSO_0.100_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (311045, 1270)
Number of total missing values across all columns: 622090
Data Subset Is Off
Wells held out for testing: ['J06' 'L10']
Wells to use for training, validation, and testing ['B06' 'C06' 'B07' 'C07' 'I06' 'I07' 'J07' 'L05' 'L11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.484364).  Saving model ...
	 Train_Loss: 0.5649 Train_Acc: 70.878 Val_Loss: 0.4844  BEST VAL Loss: 0.4844  Val_Acc: 76.744

Epoch 1: Validation loss decreased (0.484364 --> 0.460983).  Saving model ...
	 Train_Loss: 0.5216 Train_Acc: 77.762 Val_Loss: 0.4610  BEST VAL Loss: 0.4610  Val_Acc: 79.572

Epoch 2: Validation loss decreased (0.460983 --> 0.444479).  Saving model ...
	 Train_Loss: 0.4946 Train_Acc: 79.781 Val_Loss: 0.4445  BEST VAL Loss: 0.4445  Val_Acc: 81.345

Epoch 3: Validation loss decreased (0.444479 --> 0.430024).  Saving model ...
	 Train_Loss: 0.4755 Train_Acc: 80.937 Val_Loss: 0.4300  BEST VAL Loss: 0.4300  Val_Acc: 82.675

Epoch 4: Validation loss decreased (0.430024 --> 0.419135).  Saving model ...
	 Train_Loss: 0.4612 Train_Acc: 81.621 Val_Loss: 0.4191  BEST VAL Loss: 0.4191  Val_Acc: 83.106

Epoch 5: Validation loss decreased (0.419135 --> 0.410036).  Saving model ...
	 Train_Loss: 0.4499 Train_Acc: 82.047 Val_Loss: 0.4100  BEST VAL Loss: 0.4100  Val_Acc: 83.630

Epoch 6: Validation loss decreased (0.410036 --> 0.406012).  Saving model ...
	 Train_Loss: 0.4406 Train_Acc: 82.506 Val_Loss: 0.4060  BEST VAL Loss: 0.4060  Val_Acc: 81.828

Epoch 7: Validation loss decreased (0.406012 --> 0.399962).  Saving model ...
	 Train_Loss: 0.4329 Train_Acc: 82.769 Val_Loss: 0.4000  BEST VAL Loss: 0.4000  Val_Acc: 84.001

Epoch 8: Validation loss decreased (0.399962 --> 0.395400).  Saving model ...
	 Train_Loss: 0.4265 Train_Acc: 82.998 Val_Loss: 0.3954  BEST VAL Loss: 0.3954  Val_Acc: 83.498

Epoch 9: Validation loss decreased (0.395400 --> 0.390621).  Saving model ...
	 Train_Loss: 0.4209 Train_Acc: 83.144 Val_Loss: 0.3906  BEST VAL Loss: 0.3906  Val_Acc: 84.125

Epoch 10: Validation loss decreased (0.390621 --> 0.386736).  Saving model ...
	 Train_Loss: 0.4159 Train_Acc: 83.258 Val_Loss: 0.3867  BEST VAL Loss: 0.3867  Val_Acc: 83.857

Epoch 11: Validation loss decreased (0.386736 --> 0.382925).  Saving model ...
	 Train_Loss: 0.4116 Train_Acc: 83.420 Val_Loss: 0.3829  BEST VAL Loss: 0.3829  Val_Acc: 84.189

Epoch 12: Validation loss decreased (0.382925 --> 0.380036).  Saving model ...
	 Train_Loss: 0.4077 Train_Acc: 83.588 Val_Loss: 0.3800  BEST VAL Loss: 0.3800  Val_Acc: 84.221

Epoch 13: Validation loss decreased (0.380036 --> 0.376749).  Saving model ...
	 Train_Loss: 0.4041 Train_Acc: 83.717 Val_Loss: 0.3767  BEST VAL Loss: 0.3767  Val_Acc: 84.624

Epoch 14: Validation loss decreased (0.376749 --> 0.374267).  Saving model ...
	 Train_Loss: 0.4008 Train_Acc: 83.811 Val_Loss: 0.3743  BEST VAL Loss: 0.3743  Val_Acc: 84.368

Epoch 15: Validation loss decreased (0.374267 --> 0.371783).  Saving model ...
	 Train_Loss: 0.3979 Train_Acc: 83.895 Val_Loss: 0.3718  BEST VAL Loss: 0.3718  Val_Acc: 84.752

Epoch 16: Validation loss decreased (0.371783 --> 0.369456).  Saving model ...
	 Train_Loss: 0.3951 Train_Acc: 84.067 Val_Loss: 0.3695  BEST VAL Loss: 0.3695  Val_Acc: 84.828

Epoch 17: Validation loss decreased (0.369456 --> 0.367157).  Saving model ...
	 Train_Loss: 0.3925 Train_Acc: 84.155 Val_Loss: 0.3672  BEST VAL Loss: 0.3672  Val_Acc: 84.860

Epoch 18: Validation loss decreased (0.367157 --> 0.365249).  Saving model ...
	 Train_Loss: 0.3902 Train_Acc: 84.281 Val_Loss: 0.3652  BEST VAL Loss: 0.3652  Val_Acc: 84.412

Epoch 19: Validation loss decreased (0.365249 --> 0.363358).  Saving model ...
	 Train_Loss: 0.3879 Train_Acc: 84.395 Val_Loss: 0.3634  BEST VAL Loss: 0.3634  Val_Acc: 84.472

Epoch 20: Validation loss decreased (0.363358 --> 0.361616).  Saving model ...
	 Train_Loss: 0.3858 Train_Acc: 84.428 Val_Loss: 0.3616  BEST VAL Loss: 0.3616  Val_Acc: 85.003

Epoch 21: Validation loss decreased (0.361616 --> 0.360271).  Saving model ...
	 Train_Loss: 0.3837 Train_Acc: 84.549 Val_Loss: 0.3603  BEST VAL Loss: 0.3603  Val_Acc: 85.015

Epoch 22: Validation loss decreased (0.360271 --> 0.359255).  Saving model ...
	 Train_Loss: 0.3818 Train_Acc: 84.553 Val_Loss: 0.3593  BEST VAL Loss: 0.3593  Val_Acc: 84.680

Epoch 23: Validation loss decreased (0.359255 --> 0.357586).  Saving model ...
	 Train_Loss: 0.3800 Train_Acc: 84.654 Val_Loss: 0.3576  BEST VAL Loss: 0.3576  Val_Acc: 84.892

Epoch 24: Validation loss decreased (0.357586 --> 0.356162).  Saving model ...
	 Train_Loss: 0.3783 Train_Acc: 84.718 Val_Loss: 0.3562  BEST VAL Loss: 0.3562  Val_Acc: 85.303

Epoch 25: Validation loss decreased (0.356162 --> 0.354774).  Saving model ...
	 Train_Loss: 0.3766 Train_Acc: 84.768 Val_Loss: 0.3548  BEST VAL Loss: 0.3548  Val_Acc: 85.327

Epoch 26: Validation loss decreased (0.354774 --> 0.353385).  Saving model ...
	 Train_Loss: 0.3751 Train_Acc: 84.835 Val_Loss: 0.3534  BEST VAL Loss: 0.3534  Val_Acc: 85.315

Epoch 27: Validation loss decreased (0.353385 --> 0.352316).  Saving model ...
	 Train_Loss: 0.3736 Train_Acc: 84.884 Val_Loss: 0.3523  BEST VAL Loss: 0.3523  Val_Acc: 85.091

Epoch 28: Validation loss decreased (0.352316 --> 0.350968).  Saving model ...
	 Train_Loss: 0.3722 Train_Acc: 84.887 Val_Loss: 0.3510  BEST VAL Loss: 0.3510  Val_Acc: 85.670

Epoch 29: Validation loss decreased (0.350968 --> 0.349817).  Saving model ...
	 Train_Loss: 0.3708 Train_Acc: 85.005 Val_Loss: 0.3498  BEST VAL Loss: 0.3498  Val_Acc: 85.375

Epoch 30: Validation loss decreased (0.349817 --> 0.348741).  Saving model ...
	 Train_Loss: 0.3695 Train_Acc: 85.023 Val_Loss: 0.3487  BEST VAL Loss: 0.3487  Val_Acc: 85.758

Epoch 31: Validation loss decreased (0.348741 --> 0.347635).  Saving model ...
	 Train_Loss: 0.3682 Train_Acc: 85.042 Val_Loss: 0.3476  BEST VAL Loss: 0.3476  Val_Acc: 85.582

Epoch 32: Validation loss decreased (0.347635 --> 0.346506).  Saving model ...
	 Train_Loss: 0.3670 Train_Acc: 85.137 Val_Loss: 0.3465  BEST VAL Loss: 0.3465  Val_Acc: 85.598

Epoch 33: Validation loss decreased (0.346506 --> 0.345604).  Saving model ...
	 Train_Loss: 0.3658 Train_Acc: 85.200 Val_Loss: 0.3456  BEST VAL Loss: 0.3456  Val_Acc: 85.674

Epoch 34: Validation loss decreased (0.345604 --> 0.344883).  Saving model ...
	 Train_Loss: 0.3647 Train_Acc: 85.232 Val_Loss: 0.3449  BEST VAL Loss: 0.3449  Val_Acc: 85.782

Epoch 35: Validation loss decreased (0.344883 --> 0.343954).  Saving model ...
	 Train_Loss: 0.3636 Train_Acc: 85.240 Val_Loss: 0.3440  BEST VAL Loss: 0.3440  Val_Acc: 85.790

Epoch 36: Validation loss decreased (0.343954 --> 0.343118).  Saving model ...
	 Train_Loss: 0.3626 Train_Acc: 85.152 Val_Loss: 0.3431  BEST VAL Loss: 0.3431  Val_Acc: 85.199

Epoch 37: Validation loss decreased (0.343118 --> 0.342545).  Saving model ...
	 Train_Loss: 0.3616 Train_Acc: 85.270 Val_Loss: 0.3425  BEST VAL Loss: 0.3425  Val_Acc: 85.091

Epoch 38: Validation loss decreased (0.342545 --> 0.341635).  Saving model ...
	 Train_Loss: 0.3606 Train_Acc: 85.289 Val_Loss: 0.3416  BEST VAL Loss: 0.3416  Val_Acc: 86.070

Epoch 39: Validation loss decreased (0.341635 --> 0.340799).  Saving model ...
	 Train_Loss: 0.3596 Train_Acc: 85.356 Val_Loss: 0.3408  BEST VAL Loss: 0.3408  Val_Acc: 85.802

Epoch 40: Validation loss decreased (0.340799 --> 0.339993).  Saving model ...
	 Train_Loss: 0.3587 Train_Acc: 85.346 Val_Loss: 0.3400  BEST VAL Loss: 0.3400  Val_Acc: 85.898

Epoch 41: Validation loss decreased (0.339993 --> 0.339360).  Saving model ...
	 Train_Loss: 0.3578 Train_Acc: 85.454 Val_Loss: 0.3394  BEST VAL Loss: 0.3394  Val_Acc: 85.946

Epoch 42: Validation loss decreased (0.339360 --> 0.338764).  Saving model ...
	 Train_Loss: 0.3569 Train_Acc: 85.499 Val_Loss: 0.3388  BEST VAL Loss: 0.3388  Val_Acc: 85.387

Epoch 43: Validation loss decreased (0.338764 --> 0.337976).  Saving model ...
	 Train_Loss: 0.3561 Train_Acc: 85.342 Val_Loss: 0.3380  BEST VAL Loss: 0.3380  Val_Acc: 86.106

Epoch 44: Validation loss decreased (0.337976 --> 0.337188).  Saving model ...
	 Train_Loss: 0.3553 Train_Acc: 85.525 Val_Loss: 0.3372  BEST VAL Loss: 0.3372  Val_Acc: 86.154

Epoch 45: Validation loss decreased (0.337188 --> 0.336550).  Saving model ...
	 Train_Loss: 0.3545 Train_Acc: 85.495 Val_Loss: 0.3366  BEST VAL Loss: 0.3366  Val_Acc: 85.922

Epoch 46: Validation loss decreased (0.336550 --> 0.335861).  Saving model ...
	 Train_Loss: 0.3538 Train_Acc: 85.448 Val_Loss: 0.3359  BEST VAL Loss: 0.3359  Val_Acc: 86.265

Epoch 47: Validation loss decreased (0.335861 --> 0.335249).  Saving model ...
	 Train_Loss: 0.3530 Train_Acc: 85.508 Val_Loss: 0.3352  BEST VAL Loss: 0.3352  Val_Acc: 86.261

Epoch 48: Validation loss decreased (0.335249 --> 0.334758).  Saving model ...
	 Train_Loss: 0.3523 Train_Acc: 85.514 Val_Loss: 0.3348  BEST VAL Loss: 0.3348  Val_Acc: 85.942

Epoch 49: Validation loss decreased (0.334758 --> 0.334159).  Saving model ...
	 Train_Loss: 0.3516 Train_Acc: 85.511 Val_Loss: 0.3342  BEST VAL Loss: 0.3342  Val_Acc: 86.329

Epoch 50: Validation loss decreased (0.334159 --> 0.333652).  Saving model ...
	 Train_Loss: 0.3509 Train_Acc: 85.465 Val_Loss: 0.3337  BEST VAL Loss: 0.3337  Val_Acc: 86.058

Epoch 51: Validation loss decreased (0.333652 --> 0.333041).  Saving model ...
	 Train_Loss: 0.3502 Train_Acc: 85.585 Val_Loss: 0.3330  BEST VAL Loss: 0.3330  Val_Acc: 86.245

Epoch 52: Validation loss decreased (0.333041 --> 0.332666).  Saving model ...
	 Train_Loss: 0.3496 Train_Acc: 85.628 Val_Loss: 0.3327  BEST VAL Loss: 0.3327  Val_Acc: 86.138

Epoch 53: Validation loss decreased (0.332666 --> 0.332187).  Saving model ...
	 Train_Loss: 0.3490 Train_Acc: 85.605 Val_Loss: 0.3322  BEST VAL Loss: 0.3322  Val_Acc: 85.890

Epoch 54: Validation loss decreased (0.332187 --> 0.331807).  Saving model ...
	 Train_Loss: 0.3484 Train_Acc: 85.619 Val_Loss: 0.3318  BEST VAL Loss: 0.3318  Val_Acc: 86.329

Epoch 55: Validation loss decreased (0.331807 --> 0.331200).  Saving model ...
	 Train_Loss: 0.3478 Train_Acc: 85.522 Val_Loss: 0.3312  BEST VAL Loss: 0.3312  Val_Acc: 86.321

Epoch 56: Validation loss decreased (0.331200 --> 0.330611).  Saving model ...
	 Train_Loss: 0.3472 Train_Acc: 85.579 Val_Loss: 0.3306  BEST VAL Loss: 0.3306  Val_Acc: 86.309

Epoch 57: Validation loss decreased (0.330611 --> 0.330335).  Saving model ...
	 Train_Loss: 0.3466 Train_Acc: 85.661 Val_Loss: 0.3303  BEST VAL Loss: 0.3303  Val_Acc: 85.730

Epoch 58: Validation loss decreased (0.330335 --> 0.330000).  Saving model ...
	 Train_Loss: 0.3461 Train_Acc: 85.722 Val_Loss: 0.3300  BEST VAL Loss: 0.3300  Val_Acc: 86.142

Epoch 59: Validation loss decreased (0.330000 --> 0.329545).  Saving model ...
	 Train_Loss: 0.3455 Train_Acc: 85.791 Val_Loss: 0.3295  BEST VAL Loss: 0.3295  Val_Acc: 86.034

Epoch 60: Validation loss decreased (0.329545 --> 0.329205).  Saving model ...
	 Train_Loss: 0.3450 Train_Acc: 85.698 Val_Loss: 0.3292  BEST VAL Loss: 0.3292  Val_Acc: 86.134

Epoch 61: Validation loss decreased (0.329205 --> 0.328779).  Saving model ...
	 Train_Loss: 0.3445 Train_Acc: 85.697 Val_Loss: 0.3288  BEST VAL Loss: 0.3288  Val_Acc: 86.369

Epoch 62: Validation loss decreased (0.328779 --> 0.328360).  Saving model ...
	 Train_Loss: 0.3440 Train_Acc: 85.695 Val_Loss: 0.3284  BEST VAL Loss: 0.3284  Val_Acc: 86.477

Epoch 63: Validation loss decreased (0.328360 --> 0.327974).  Saving model ...
	 Train_Loss: 0.3435 Train_Acc: 85.752 Val_Loss: 0.3280  BEST VAL Loss: 0.3280  Val_Acc: 86.134

Epoch 64: Validation loss decreased (0.327974 --> 0.327616).  Saving model ...
	 Train_Loss: 0.3430 Train_Acc: 85.768 Val_Loss: 0.3276  BEST VAL Loss: 0.3276  Val_Acc: 85.986

Epoch 65: Validation loss decreased (0.327616 --> 0.327214).  Saving model ...
	 Train_Loss: 0.3425 Train_Acc: 85.691 Val_Loss: 0.3272  BEST VAL Loss: 0.3272  Val_Acc: 86.433

Epoch 66: Validation loss decreased (0.327214 --> 0.326699).  Saving model ...
	 Train_Loss: 0.3421 Train_Acc: 85.734 Val_Loss: 0.3267  BEST VAL Loss: 0.3267  Val_Acc: 86.489

Epoch 67: Validation loss decreased (0.326699 --> 0.326297).  Saving model ...
	 Train_Loss: 0.3416 Train_Acc: 85.697 Val_Loss: 0.3263  BEST VAL Loss: 0.3263  Val_Acc: 86.497

Epoch 68: Validation loss decreased (0.326297 --> 0.325931).  Saving model ...
	 Train_Loss: 0.3412 Train_Acc: 85.776 Val_Loss: 0.3259  BEST VAL Loss: 0.3259  Val_Acc: 86.122

Epoch 69: Validation loss decreased (0.325931 --> 0.325548).  Saving model ...
	 Train_Loss: 0.3407 Train_Acc: 85.769 Val_Loss: 0.3255  BEST VAL Loss: 0.3255  Val_Acc: 86.489

Epoch 70: Validation loss decreased (0.325548 --> 0.325114).  Saving model ...
	 Train_Loss: 0.3403 Train_Acc: 85.857 Val_Loss: 0.3251  BEST VAL Loss: 0.3251  Val_Acc: 86.661

Epoch 71: Validation loss decreased (0.325114 --> 0.324860).  Saving model ...
	 Train_Loss: 0.3399 Train_Acc: 85.760 Val_Loss: 0.3249  BEST VAL Loss: 0.3249  Val_Acc: 85.710

Epoch 72: Validation loss decreased (0.324860 --> 0.324544).  Saving model ...
	 Train_Loss: 0.3395 Train_Acc: 85.847 Val_Loss: 0.3245  BEST VAL Loss: 0.3245  Val_Acc: 86.421

Epoch 73: Validation loss decreased (0.324544 --> 0.324181).  Saving model ...
	 Train_Loss: 0.3391 Train_Acc: 85.849 Val_Loss: 0.3242  BEST VAL Loss: 0.3242  Val_Acc: 86.425

Epoch 74: Validation loss decreased (0.324181 --> 0.323892).  Saving model ...
	 Train_Loss: 0.3387 Train_Acc: 85.794 Val_Loss: 0.3239  BEST VAL Loss: 0.3239  Val_Acc: 86.098

Epoch 75: Validation loss decreased (0.323892 --> 0.323666).  Saving model ...
	 Train_Loss: 0.3383 Train_Acc: 85.865 Val_Loss: 0.3237  BEST VAL Loss: 0.3237  Val_Acc: 86.297

Epoch 76: Validation loss decreased (0.323666 --> 0.323436).  Saving model ...
	 Train_Loss: 0.3379 Train_Acc: 85.823 Val_Loss: 0.3234  BEST VAL Loss: 0.3234  Val_Acc: 86.261

Epoch 77: Validation loss decreased (0.323436 --> 0.323089).  Saving model ...
	 Train_Loss: 0.3375 Train_Acc: 85.837 Val_Loss: 0.3231  BEST VAL Loss: 0.3231  Val_Acc: 86.685

Epoch 78: Validation loss decreased (0.323089 --> 0.322744).  Saving model ...
	 Train_Loss: 0.3372 Train_Acc: 85.882 Val_Loss: 0.3227  BEST VAL Loss: 0.3227  Val_Acc: 86.880

Epoch 79: Validation loss decreased (0.322744 --> 0.322426).  Saving model ...
	 Train_Loss: 0.3368 Train_Acc: 85.861 Val_Loss: 0.3224  BEST VAL Loss: 0.3224  Val_Acc: 86.525

Epoch 80: Validation loss decreased (0.322426 --> 0.322155).  Saving model ...
	 Train_Loss: 0.3365 Train_Acc: 85.898 Val_Loss: 0.3222  BEST VAL Loss: 0.3222  Val_Acc: 86.461

Epoch 81: Validation loss decreased (0.322155 --> 0.322012).  Saving model ...
	 Train_Loss: 0.3361 Train_Acc: 85.825 Val_Loss: 0.3220  BEST VAL Loss: 0.3220  Val_Acc: 86.709

Epoch 82: Validation loss decreased (0.322012 --> 0.321671).  Saving model ...
	 Train_Loss: 0.3358 Train_Acc: 85.882 Val_Loss: 0.3217  BEST VAL Loss: 0.3217  Val_Acc: 86.745

Epoch 83: Validation loss decreased (0.321671 --> 0.321431).  Saving model ...
	 Train_Loss: 0.3354 Train_Acc: 85.899 Val_Loss: 0.3214  BEST VAL Loss: 0.3214  Val_Acc: 86.221

Epoch 84: Validation loss decreased (0.321431 --> 0.321078).  Saving model ...
	 Train_Loss: 0.3351 Train_Acc: 85.889 Val_Loss: 0.3211  BEST VAL Loss: 0.3211  Val_Acc: 86.665

Epoch 85: Validation loss decreased (0.321078 --> 0.320770).  Saving model ...
	 Train_Loss: 0.3348 Train_Acc: 85.861 Val_Loss: 0.3208  BEST VAL Loss: 0.3208  Val_Acc: 86.653

Epoch 86: Validation loss decreased (0.320770 --> 0.320528).  Saving model ...
	 Train_Loss: 0.3345 Train_Acc: 85.895 Val_Loss: 0.3205  BEST VAL Loss: 0.3205  Val_Acc: 86.557

Epoch 87: Validation loss decreased (0.320528 --> 0.320276).  Saving model ...
	 Train_Loss: 0.3341 Train_Acc: 85.882 Val_Loss: 0.3203  BEST VAL Loss: 0.3203  Val_Acc: 86.609

Epoch 88: Validation loss decreased (0.320276 --> 0.319986).  Saving model ...
	 Train_Loss: 0.3338 Train_Acc: 85.963 Val_Loss: 0.3200  BEST VAL Loss: 0.3200  Val_Acc: 86.777

Epoch 89: Validation loss decreased (0.319986 --> 0.319714).  Saving model ...
	 Train_Loss: 0.3335 Train_Acc: 85.929 Val_Loss: 0.3197  BEST VAL Loss: 0.3197  Val_Acc: 86.533

Epoch 90: Validation loss decreased (0.319714 --> 0.319609).  Saving model ...
	 Train_Loss: 0.3332 Train_Acc: 85.903 Val_Loss: 0.3196  BEST VAL Loss: 0.3196  Val_Acc: 86.565

Epoch 91: Validation loss decreased (0.319609 --> 0.319339).  Saving model ...
	 Train_Loss: 0.3329 Train_Acc: 85.976 Val_Loss: 0.3193  BEST VAL Loss: 0.3193  Val_Acc: 86.561

Epoch 92: Validation loss decreased (0.319339 --> 0.319057).  Saving model ...
	 Train_Loss: 0.3326 Train_Acc: 85.919 Val_Loss: 0.3191  BEST VAL Loss: 0.3191  Val_Acc: 86.980

Epoch 93: Validation loss decreased (0.319057 --> 0.318898).  Saving model ...
	 Train_Loss: 0.3324 Train_Acc: 86.030 Val_Loss: 0.3189  BEST VAL Loss: 0.3189  Val_Acc: 86.158

Epoch 94: Validation loss decreased (0.318898 --> 0.318712).  Saving model ...
	 Train_Loss: 0.3321 Train_Acc: 85.921 Val_Loss: 0.3187  BEST VAL Loss: 0.3187  Val_Acc: 86.673

Epoch 95: Validation loss decreased (0.318712 --> 0.318548).  Saving model ...
	 Train_Loss: 0.3318 Train_Acc: 86.041 Val_Loss: 0.3185  BEST VAL Loss: 0.3185  Val_Acc: 86.673

Epoch 96: Validation loss decreased (0.318548 --> 0.318359).  Saving model ...
	 Train_Loss: 0.3315 Train_Acc: 86.019 Val_Loss: 0.3184  BEST VAL Loss: 0.3184  Val_Acc: 86.174

Epoch 97: Validation loss decreased (0.318359 --> 0.318146).  Saving model ...
	 Train_Loss: 0.3313 Train_Acc: 85.963 Val_Loss: 0.3181  BEST VAL Loss: 0.3181  Val_Acc: 86.665

Epoch 98: Validation loss decreased (0.318146 --> 0.317900).  Saving model ...
	 Train_Loss: 0.3310 Train_Acc: 85.982 Val_Loss: 0.3179  BEST VAL Loss: 0.3179  Val_Acc: 86.829

Epoch 99: Validation loss decreased (0.317900 --> 0.317651).  Saving model ...
	 Train_Loss: 0.3307 Train_Acc: 86.029 Val_Loss: 0.3177  BEST VAL Loss: 0.3177  Val_Acc: 86.801

Flagellin_0.100_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.75      0.80      0.78    149884
           1       0.25      0.20      0.22     50422

    accuracy                           0.65    200306
   macro avg       0.50      0.50      0.50    200306
weighted avg       0.62      0.65      0.64    200306

Flagellin_0.100_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.75      0.80      0.78     18736
           1       0.25      0.20      0.22      6303

    accuracy                           0.65     25039
   macro avg       0.50      0.50      0.50     25039
weighted avg       0.62      0.65      0.64     25039

Flagellin_0.100_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.75      0.80      0.78     18736
           1       0.26      0.20      0.22      6303

    accuracy                           0.65     25039
   macro avg       0.50      0.50      0.50     25039
weighted avg       0.63      0.65      0.64     25039

              precision    recall  f1-score   support

           0       0.75      0.80      0.78     18736
           1       0.26      0.20      0.22      6303

    accuracy                           0.65     25039
   macro avg       0.50      0.50      0.50     25039
weighted avg       0.63      0.65      0.64     25039

Flagellin_0.100_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_DMSO_0.100_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.46      0.60      0.52     27774
           1       0.54      0.40      0.46     32887

    accuracy                           0.49     60661
   macro avg       0.50      0.50      0.49     60661
weighted avg       0.50      0.49      0.49     60661

              precision    recall  f1-score   support

           0       0.46      0.60      0.52     27774
           1       0.54      0.40      0.46     32887

    accuracy                           0.49     60661
   macro avg       0.50      0.50      0.49     60661
weighted avg       0.50      0.49      0.49     60661

completed
