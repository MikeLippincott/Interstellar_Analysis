[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '22f9c278'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '397c718a'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '14e2cabf'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'fbfc9ba5'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_1.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_1.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_10.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (320599, 1270)
Number of total missing values across all columns: 278866
Data Subset Is Off
Wells held out for testing: ['D09' 'M09']
Wells to use for training, validation, and testing ['D02' 'D03' 'D08' 'M02' 'M03' 'M08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.264369).  Saving model ...
	 Train_Loss: 0.4351 Train_Acc: 78.423 Val_Loss: 0.2644  BEST VAL Loss: 0.2644  Val_Acc: 89.948

Epoch 1: Validation loss decreased (0.264369 --> 0.233783).  Saving model ...
	 Train_Loss: 0.3702 Train_Acc: 87.622 Val_Loss: 0.2338  BEST VAL Loss: 0.2338  Val_Acc: 92.351

Epoch 2: Validation loss decreased (0.233783 --> 0.217519).  Saving model ...
	 Train_Loss: 0.3341 Train_Acc: 89.455 Val_Loss: 0.2175  BEST VAL Loss: 0.2175  Val_Acc: 93.065

Epoch 3: Validation loss decreased (0.217519 --> 0.206298).  Saving model ...
	 Train_Loss: 0.3115 Train_Acc: 90.158 Val_Loss: 0.2063  BEST VAL Loss: 0.2063  Val_Acc: 93.409

Epoch 4: Validation loss decreased (0.206298 --> 0.201035).  Saving model ...
	 Train_Loss: 0.2961 Train_Acc: 90.707 Val_Loss: 0.2010  BEST VAL Loss: 0.2010  Val_Acc: 93.124

Epoch 5: Validation loss decreased (0.201035 --> 0.194721).  Saving model ...
	 Train_Loss: 0.2844 Train_Acc: 91.033 Val_Loss: 0.1947  BEST VAL Loss: 0.1947  Val_Acc: 93.835

Epoch 6: Validation loss decreased (0.194721 --> 0.191093).  Saving model ...
	 Train_Loss: 0.2748 Train_Acc: 91.363 Val_Loss: 0.1911  BEST VAL Loss: 0.1911  Val_Acc: 93.741

Epoch 7: Validation loss decreased (0.191093 --> 0.186975).  Saving model ...
	 Train_Loss: 0.2672 Train_Acc: 91.607 Val_Loss: 0.1870  BEST VAL Loss: 0.1870  Val_Acc: 94.217

Epoch 8: Validation loss decreased (0.186975 --> 0.182582).  Saving model ...
	 Train_Loss: 0.2605 Train_Acc: 91.769 Val_Loss: 0.1826  BEST VAL Loss: 0.1826  Val_Acc: 94.613

Epoch 9: Validation loss decreased (0.182582 --> 0.178984).  Saving model ...
	 Train_Loss: 0.2548 Train_Acc: 92.180 Val_Loss: 0.1790  BEST VAL Loss: 0.1790  Val_Acc: 94.672

Epoch 10: Validation loss decreased (0.178984 --> 0.175585).  Saving model ...
	 Train_Loss: 0.2498 Train_Acc: 92.405 Val_Loss: 0.1756  BEST VAL Loss: 0.1756  Val_Acc: 94.876

Epoch 11: Validation loss decreased (0.175585 --> 0.172683).  Saving model ...
	 Train_Loss: 0.2452 Train_Acc: 92.800 Val_Loss: 0.1727  BEST VAL Loss: 0.1727  Val_Acc: 94.749

Epoch 12: Validation loss decreased (0.172683 --> 0.170502).  Saving model ...
	 Train_Loss: 0.2412 Train_Acc: 93.130 Val_Loss: 0.1705  BEST VAL Loss: 0.1705  Val_Acc: 94.672

Epoch 13: Validation loss decreased (0.170502 --> 0.168313).  Saving model ...
	 Train_Loss: 0.2373 Train_Acc: 93.459 Val_Loss: 0.1683  BEST VAL Loss: 0.1683  Val_Acc: 94.893

Epoch 14: Validation loss decreased (0.168313 --> 0.166558).  Saving model ...
	 Train_Loss: 0.2337 Train_Acc: 93.620 Val_Loss: 0.1666  BEST VAL Loss: 0.1666  Val_Acc: 94.791

Epoch 15: Validation loss decreased (0.166558 --> 0.164628).  Saving model ...
	 Train_Loss: 0.2304 Train_Acc: 93.707 Val_Loss: 0.1646  BEST VAL Loss: 0.1646  Val_Acc: 95.055

Epoch 16: Validation loss decreased (0.164628 --> 0.163795).  Saving model ...
	 Train_Loss: 0.2273 Train_Acc: 93.642 Val_Loss: 0.1638  BEST VAL Loss: 0.1638  Val_Acc: 94.506

Epoch 17: Validation loss decreased (0.163795 --> 0.162882).  Saving model ...
	 Train_Loss: 0.2246 Train_Acc: 93.816 Val_Loss: 0.1629  BEST VAL Loss: 0.1629  Val_Acc: 94.774

Epoch 18: Validation loss decreased (0.162882 --> 0.161173).  Saving model ...
	 Train_Loss: 0.2221 Train_Acc: 93.820 Val_Loss: 0.1612  BEST VAL Loss: 0.1612  Val_Acc: 95.297

Epoch 19: Validation loss decreased (0.161173 --> 0.159715).  Saving model ...
	 Train_Loss: 0.2197 Train_Acc: 93.951 Val_Loss: 0.1597  BEST VAL Loss: 0.1597  Val_Acc: 95.272

Epoch 20: Validation loss decreased (0.159715 --> 0.158537).  Saving model ...
	 Train_Loss: 0.2175 Train_Acc: 93.950 Val_Loss: 0.1585  BEST VAL Loss: 0.1585  Val_Acc: 95.097

Epoch 21: Validation loss decreased (0.158537 --> 0.157456).  Saving model ...
	 Train_Loss: 0.2155 Train_Acc: 93.959 Val_Loss: 0.1575  BEST VAL Loss: 0.1575  Val_Acc: 95.021

Epoch 22: Validation loss decreased (0.157456 --> 0.156816).  Saving model ...
	 Train_Loss: 0.2135 Train_Acc: 94.037 Val_Loss: 0.1568  BEST VAL Loss: 0.1568  Val_Acc: 94.825

Epoch 23: Validation loss decreased (0.156816 --> 0.155929).  Saving model ...
	 Train_Loss: 0.2118 Train_Acc: 94.012 Val_Loss: 0.1559  BEST VAL Loss: 0.1559  Val_Acc: 95.021

Epoch 24: Validation loss decreased (0.155929 --> 0.155079).  Saving model ...
	 Train_Loss: 0.2101 Train_Acc: 94.118 Val_Loss: 0.1551  BEST VAL Loss: 0.1551  Val_Acc: 95.076

Epoch 25: Validation loss decreased (0.155079 --> 0.154059).  Saving model ...
	 Train_Loss: 0.2084 Train_Acc: 94.122 Val_Loss: 0.1541  BEST VAL Loss: 0.1541  Val_Acc: 95.374

Epoch 26: Validation loss decreased (0.154059 --> 0.153226).  Saving model ...
	 Train_Loss: 0.2069 Train_Acc: 94.172 Val_Loss: 0.1532  BEST VAL Loss: 0.1532  Val_Acc: 95.204

Epoch 27: Validation loss decreased (0.153226 --> 0.152373).  Saving model ...
	 Train_Loss: 0.2054 Train_Acc: 94.218 Val_Loss: 0.1524  BEST VAL Loss: 0.1524  Val_Acc: 95.221

Epoch 28: Validation loss did not decrease
	 Train_Loss: 0.2040 Train_Acc: 94.257 Val_Loss: 0.1524  BEST VAL Loss: 0.1524  Val_Acc: 94.294

Epoch 29: Validation loss decreased (0.152373 --> 0.151459).  Saving model ...
	 Train_Loss: 0.2027 Train_Acc: 94.264 Val_Loss: 0.1515  BEST VAL Loss: 0.1515  Val_Acc: 95.552

Epoch 30: Validation loss decreased (0.151459 --> 0.150751).  Saving model ...
	 Train_Loss: 0.2014 Train_Acc: 94.319 Val_Loss: 0.1508  BEST VAL Loss: 0.1508  Val_Acc: 95.046

Epoch 31: Validation loss decreased (0.150751 --> 0.150035).  Saving model ...
	 Train_Loss: 0.2002 Train_Acc: 94.475 Val_Loss: 0.1500  BEST VAL Loss: 0.1500  Val_Acc: 95.293

Epoch 32: Validation loss decreased (0.150035 --> 0.149603).  Saving model ...
	 Train_Loss: 0.1990 Train_Acc: 94.462 Val_Loss: 0.1496  BEST VAL Loss: 0.1496  Val_Acc: 95.221

Epoch 33: Validation loss decreased (0.149603 --> 0.149034).  Saving model ...
	 Train_Loss: 0.1978 Train_Acc: 94.512 Val_Loss: 0.1490  BEST VAL Loss: 0.1490  Val_Acc: 95.352

Epoch 34: Validation loss decreased (0.149034 --> 0.148273).  Saving model ...
	 Train_Loss: 0.1966 Train_Acc: 94.583 Val_Loss: 0.1483  BEST VAL Loss: 0.1483  Val_Acc: 95.586

Epoch 35: Validation loss decreased (0.148273 --> 0.147765).  Saving model ...
	 Train_Loss: 0.1956 Train_Acc: 94.553 Val_Loss: 0.1478  BEST VAL Loss: 0.1478  Val_Acc: 95.370

Epoch 36: Validation loss did not decrease
	 Train_Loss: 0.1945 Train_Acc: 94.678 Val_Loss: 0.1479  BEST VAL Loss: 0.1478  Val_Acc: 94.477

Epoch 37: Validation loss decreased (0.147765 --> 0.147403).  Saving model ...
	 Train_Loss: 0.1935 Train_Acc: 94.675 Val_Loss: 0.1474  BEST VAL Loss: 0.1474  Val_Acc: 95.272

Epoch 38: Validation loss decreased (0.147403 --> 0.146817).  Saving model ...
	 Train_Loss: 0.1926 Train_Acc: 94.641 Val_Loss: 0.1468  BEST VAL Loss: 0.1468  Val_Acc: 95.514

Epoch 39: Validation loss decreased (0.146817 --> 0.146215).  Saving model ...
	 Train_Loss: 0.1916 Train_Acc: 94.743 Val_Loss: 0.1462  BEST VAL Loss: 0.1462  Val_Acc: 95.557

Epoch 40: Validation loss decreased (0.146215 --> 0.145654).  Saving model ...
	 Train_Loss: 0.1907 Train_Acc: 94.719 Val_Loss: 0.1457  BEST VAL Loss: 0.1457  Val_Acc: 95.688

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.1898 Train_Acc: 94.716 Val_Loss: 0.1470  BEST VAL Loss: 0.1457  Val_Acc: 93.707

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.1890 Train_Acc: 94.759 Val_Loss: 0.1465  BEST VAL Loss: 0.1457  Val_Acc: 95.620

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.1882 Train_Acc: 94.837 Val_Loss: 0.1459  BEST VAL Loss: 0.1457  Val_Acc: 95.493

Epoch 44: Validation loss decreased (0.145654 --> 0.145460).  Saving model ...
	 Train_Loss: 0.1874 Train_Acc: 94.809 Val_Loss: 0.1455  BEST VAL Loss: 0.1455  Val_Acc: 95.531

Epoch 45: Validation loss decreased (0.145460 --> 0.144993).  Saving model ...
	 Train_Loss: 0.1866 Train_Acc: 94.848 Val_Loss: 0.1450  BEST VAL Loss: 0.1450  Val_Acc: 95.518

Epoch 46: Validation loss decreased (0.144993 --> 0.144524).  Saving model ...
	 Train_Loss: 0.1859 Train_Acc: 94.801 Val_Loss: 0.1445  BEST VAL Loss: 0.1445  Val_Acc: 95.510

Epoch 47: Validation loss decreased (0.144524 --> 0.144176).  Saving model ...
	 Train_Loss: 0.1851 Train_Acc: 94.842 Val_Loss: 0.1442  BEST VAL Loss: 0.1442  Val_Acc: 95.263

Epoch 48: Validation loss decreased (0.144176 --> 0.143756).  Saving model ...
	 Train_Loss: 0.1844 Train_Acc: 94.889 Val_Loss: 0.1438  BEST VAL Loss: 0.1438  Val_Acc: 95.484

Epoch 49: Validation loss decreased (0.143756 --> 0.143304).  Saving model ...
	 Train_Loss: 0.1837 Train_Acc: 94.889 Val_Loss: 0.1433  BEST VAL Loss: 0.1433  Val_Acc: 95.633

Epoch 50: Validation loss decreased (0.143304 --> 0.142939).  Saving model ...
	 Train_Loss: 0.1831 Train_Acc: 94.789 Val_Loss: 0.1429  BEST VAL Loss: 0.1429  Val_Acc: 95.565

Epoch 51: Validation loss decreased (0.142939 --> 0.142630).  Saving model ...
	 Train_Loss: 0.1824 Train_Acc: 94.940 Val_Loss: 0.1426  BEST VAL Loss: 0.1426  Val_Acc: 95.370

Epoch 52: Validation loss decreased (0.142630 --> 0.142342).  Saving model ...
	 Train_Loss: 0.1818 Train_Acc: 94.962 Val_Loss: 0.1423  BEST VAL Loss: 0.1423  Val_Acc: 95.506

Epoch 53: Validation loss decreased (0.142342 --> 0.141969).  Saving model ...
	 Train_Loss: 0.1812 Train_Acc: 94.902 Val_Loss: 0.1420  BEST VAL Loss: 0.1420  Val_Acc: 95.463

Epoch 54: Validation loss decreased (0.141969 --> 0.141804).  Saving model ...
	 Train_Loss: 0.1805 Train_Acc: 95.022 Val_Loss: 0.1418  BEST VAL Loss: 0.1418  Val_Acc: 95.161

Epoch 55: Validation loss decreased (0.141804 --> 0.141554).  Saving model ...
	 Train_Loss: 0.1799 Train_Acc: 94.942 Val_Loss: 0.1416  BEST VAL Loss: 0.1416  Val_Acc: 95.370

Epoch 56: Validation loss decreased (0.141554 --> 0.141387).  Saving model ...
	 Train_Loss: 0.1794 Train_Acc: 94.996 Val_Loss: 0.1414  BEST VAL Loss: 0.1414  Val_Acc: 95.250

Epoch 57: Validation loss decreased (0.141387 --> 0.141053).  Saving model ...
	 Train_Loss: 0.1788 Train_Acc: 94.971 Val_Loss: 0.1411  BEST VAL Loss: 0.1411  Val_Acc: 95.595

Epoch 58: Validation loss decreased (0.141053 --> 0.140885).  Saving model ...
	 Train_Loss: 0.1782 Train_Acc: 94.941 Val_Loss: 0.1409  BEST VAL Loss: 0.1409  Val_Acc: 95.276

Epoch 59: Validation loss decreased (0.140885 --> 0.140560).  Saving model ...
	 Train_Loss: 0.1777 Train_Acc: 95.007 Val_Loss: 0.1406  BEST VAL Loss: 0.1406  Val_Acc: 95.506

Epoch 60: Validation loss decreased (0.140560 --> 0.140239).  Saving model ...
	 Train_Loss: 0.1771 Train_Acc: 95.077 Val_Loss: 0.1402  BEST VAL Loss: 0.1402  Val_Acc: 95.646

Epoch 61: Validation loss decreased (0.140239 --> 0.139923).  Saving model ...
	 Train_Loss: 0.1766 Train_Acc: 95.048 Val_Loss: 0.1399  BEST VAL Loss: 0.1399  Val_Acc: 95.688

Epoch 62: Validation loss decreased (0.139923 --> 0.139763).  Saving model ...
	 Train_Loss: 0.1761 Train_Acc: 94.989 Val_Loss: 0.1398  BEST VAL Loss: 0.1398  Val_Acc: 95.501

Epoch 63: Validation loss decreased (0.139763 --> 0.139519).  Saving model ...
	 Train_Loss: 0.1757 Train_Acc: 94.974 Val_Loss: 0.1395  BEST VAL Loss: 0.1395  Val_Acc: 95.501

Epoch 64: Validation loss decreased (0.139519 --> 0.139234).  Saving model ...
	 Train_Loss: 0.1752 Train_Acc: 94.937 Val_Loss: 0.1392  BEST VAL Loss: 0.1392  Val_Acc: 95.752

Epoch 65: Validation loss decreased (0.139234 --> 0.138953).  Saving model ...
	 Train_Loss: 0.1747 Train_Acc: 95.066 Val_Loss: 0.1390  BEST VAL Loss: 0.1390  Val_Acc: 95.578

Epoch 66: Validation loss decreased (0.138953 --> 0.138653).  Saving model ...
	 Train_Loss: 0.1743 Train_Acc: 95.038 Val_Loss: 0.1387  BEST VAL Loss: 0.1387  Val_Acc: 95.829

Epoch 67: Validation loss decreased (0.138653 --> 0.138485).  Saving model ...
	 Train_Loss: 0.1738 Train_Acc: 94.995 Val_Loss: 0.1385  BEST VAL Loss: 0.1385  Val_Acc: 95.493

Epoch 68: Validation loss decreased (0.138485 --> 0.138199).  Saving model ...
	 Train_Loss: 0.1734 Train_Acc: 95.041 Val_Loss: 0.1382  BEST VAL Loss: 0.1382  Val_Acc: 95.671

Epoch 69: Validation loss decreased (0.138199 --> 0.137913).  Saving model ...
	 Train_Loss: 0.1730 Train_Acc: 95.069 Val_Loss: 0.1379  BEST VAL Loss: 0.1379  Val_Acc: 95.739

Epoch 70: Validation loss decreased (0.137913 --> 0.137643).  Saving model ...
	 Train_Loss: 0.1725 Train_Acc: 95.046 Val_Loss: 0.1376  BEST VAL Loss: 0.1376  Val_Acc: 95.731

Epoch 71: Validation loss decreased (0.137643 --> 0.137453).  Saving model ...
	 Train_Loss: 0.1722 Train_Acc: 95.051 Val_Loss: 0.1375  BEST VAL Loss: 0.1375  Val_Acc: 95.518

Epoch 72: Validation loss decreased (0.137453 --> 0.137357).  Saving model ...
	 Train_Loss: 0.1718 Train_Acc: 95.079 Val_Loss: 0.1374  BEST VAL Loss: 0.1374  Val_Acc: 95.280

Epoch 73: Validation loss decreased (0.137357 --> 0.137132).  Saving model ...
	 Train_Loss: 0.1714 Train_Acc: 95.048 Val_Loss: 0.1371  BEST VAL Loss: 0.1371  Val_Acc: 95.663

Epoch 74: Validation loss decreased (0.137132 --> 0.136906).  Saving model ...
	 Train_Loss: 0.1710 Train_Acc: 95.106 Val_Loss: 0.1369  BEST VAL Loss: 0.1369  Val_Acc: 95.688

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.1706 Train_Acc: 95.149 Val_Loss: 0.1370  BEST VAL Loss: 0.1369  Val_Acc: 94.812

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.1703 Train_Acc: 95.014 Val_Loss: 0.1370  BEST VAL Loss: 0.1369  Val_Acc: 94.923

Epoch 77: Validation loss decreased (0.136906 --> 0.136829).  Saving model ...
	 Train_Loss: 0.1699 Train_Acc: 95.130 Val_Loss: 0.1368  BEST VAL Loss: 0.1368  Val_Acc: 95.688

Epoch 78: Validation loss decreased (0.136829 --> 0.136662).  Saving model ...
	 Train_Loss: 0.1695 Train_Acc: 95.118 Val_Loss: 0.1367  BEST VAL Loss: 0.1367  Val_Acc: 95.561

Epoch 79: Validation loss decreased (0.136662 --> 0.136482).  Saving model ...
	 Train_Loss: 0.1692 Train_Acc: 95.154 Val_Loss: 0.1365  BEST VAL Loss: 0.1365  Val_Acc: 95.688

Epoch 80: Validation loss decreased (0.136482 --> 0.136302).  Saving model ...
	 Train_Loss: 0.1688 Train_Acc: 95.132 Val_Loss: 0.1363  BEST VAL Loss: 0.1363  Val_Acc: 95.561

Epoch 81: Validation loss decreased (0.136302 --> 0.136142).  Saving model ...
	 Train_Loss: 0.1685 Train_Acc: 95.139 Val_Loss: 0.1361  BEST VAL Loss: 0.1361  Val_Acc: 95.654

Epoch 82: Validation loss decreased (0.136142 --> 0.136002).  Saving model ...
	 Train_Loss: 0.1682 Train_Acc: 95.092 Val_Loss: 0.1360  BEST VAL Loss: 0.1360  Val_Acc: 95.514

Epoch 83: Validation loss decreased (0.136002 --> 0.135809).  Saving model ...
	 Train_Loss: 0.1678 Train_Acc: 95.065 Val_Loss: 0.1358  BEST VAL Loss: 0.1358  Val_Acc: 95.735

Epoch 84: Validation loss decreased (0.135809 --> 0.135704).  Saving model ...
	 Train_Loss: 0.1675 Train_Acc: 95.088 Val_Loss: 0.1357  BEST VAL Loss: 0.1357  Val_Acc: 95.578

Epoch 85: Validation loss decreased (0.135704 --> 0.135541).  Saving model ...
	 Train_Loss: 0.1672 Train_Acc: 95.160 Val_Loss: 0.1355  BEST VAL Loss: 0.1355  Val_Acc: 95.646

Epoch 86: Validation loss decreased (0.135541 --> 0.135407).  Saving model ...
	 Train_Loss: 0.1669 Train_Acc: 95.151 Val_Loss: 0.1354  BEST VAL Loss: 0.1354  Val_Acc: 95.680

Epoch 87: Validation loss decreased (0.135407 --> 0.135221).  Saving model ...
	 Train_Loss: 0.1666 Train_Acc: 95.192 Val_Loss: 0.1352  BEST VAL Loss: 0.1352  Val_Acc: 95.778

Epoch 88: Validation loss decreased (0.135221 --> 0.135089).  Saving model ...
	 Train_Loss: 0.1663 Train_Acc: 95.199 Val_Loss: 0.1351  BEST VAL Loss: 0.1351  Val_Acc: 95.591

Epoch 89: Validation loss decreased (0.135089 --> 0.134942).  Saving model ...
	 Train_Loss: 0.1660 Train_Acc: 95.192 Val_Loss: 0.1349  BEST VAL Loss: 0.1349  Val_Acc: 95.612

Epoch 90: Validation loss decreased (0.134942 --> 0.134783).  Saving model ...
	 Train_Loss: 0.1657 Train_Acc: 95.196 Val_Loss: 0.1348  BEST VAL Loss: 0.1348  Val_Acc: 95.680

Epoch 91: Validation loss decreased (0.134783 --> 0.134628).  Saving model ...
	 Train_Loss: 0.1654 Train_Acc: 95.189 Val_Loss: 0.1346  BEST VAL Loss: 0.1346  Val_Acc: 95.667

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.1651 Train_Acc: 95.146 Val_Loss: 0.1347  BEST VAL Loss: 0.1346  Val_Acc: 95.089

Epoch 93: Validation loss decreased (0.134628 --> 0.134561).  Saving model ...
	 Train_Loss: 0.1649 Train_Acc: 95.205 Val_Loss: 0.1346  BEST VAL Loss: 0.1346  Val_Acc: 95.705

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.1646 Train_Acc: 95.294 Val_Loss: 0.1347  BEST VAL Loss: 0.1346  Val_Acc: 95.212

Epoch 95: Validation loss did not decrease
	 Train_Loss: 0.1643 Train_Acc: 95.143 Val_Loss: 0.1346  BEST VAL Loss: 0.1346  Val_Acc: 95.595

Epoch 96: Validation loss decreased (0.134561 --> 0.134448).  Saving model ...
	 Train_Loss: 0.1641 Train_Acc: 95.233 Val_Loss: 0.1344  BEST VAL Loss: 0.1344  Val_Acc: 95.667

Epoch 97: Validation loss did not decrease
	 Train_Loss: 0.1638 Train_Acc: 95.242 Val_Loss: 0.1345  BEST VAL Loss: 0.1344  Val_Acc: 95.119

Epoch 98: Validation loss decreased (0.134448 --> 0.134323).  Saving model ...
	 Train_Loss: 0.1635 Train_Acc: 95.155 Val_Loss: 0.1343  BEST VAL Loss: 0.1343  Val_Acc: 95.722

Epoch 99: Validation loss decreased (0.134323 --> 0.134222).  Saving model ...
	 Train_Loss: 0.1633 Train_Acc: 95.233 Val_Loss: 0.1342  BEST VAL Loss: 0.1342  Val_Acc: 95.544

LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.44      0.43      0.44     82897
           1       0.56      0.56      0.56    105241

    accuracy                           0.51    188138
   macro avg       0.50      0.50      0.50    188138
weighted avg       0.51      0.51      0.51    188138

LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.44      0.44      0.44     10362
           1       0.56      0.57      0.56     13156

    accuracy                           0.51     23518
   macro avg       0.50      0.50      0.50     23518
weighted avg       0.51      0.51      0.51     23518

LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.44      0.43      0.44     10363
           1       0.56      0.57      0.56     13155

    accuracy                           0.51     23518
   macro avg       0.50      0.50      0.50     23518
weighted avg       0.51      0.51      0.51     23518

              precision    recall  f1-score   support

           0       0.44      0.43      0.44     10363
           1       0.56      0.57      0.56     13155

    accuracy                           0.51     23518
   macro avg       0.50      0.50      0.50     23518
weighted avg       0.51      0.51      0.51     23518

LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_1.000_DMSO_0.025_vs_LPS_Nigericin_1.000_10.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.42      0.15      0.22     35811
           1       0.58      0.85      0.69     49614

    accuracy                           0.56     85425
   macro avg       0.50      0.50      0.46     85425
weighted avg       0.51      0.56      0.49     85425

              precision    recall  f1-score   support

           0       0.42      0.15      0.22     35811
           1       0.58      0.85      0.69     49614

    accuracy                           0.56     85425
   macro avg       0.50      0.50      0.46     85425
weighted avg       0.51      0.56      0.49     85425

completed
