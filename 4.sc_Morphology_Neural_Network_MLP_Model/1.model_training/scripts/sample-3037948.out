[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '32117f04'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'dd2315f8'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'f9bce088'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'a65a6606'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_Nigericin_1.000_1.0_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (29870, 1276)
Number of total missing values across all columns: 0
Data Subset Is Off
Wells held out for testing: ['L16' 'K20']
Wells to use for training, validation, and testing ['K16' 'K17' 'L17' 'L20' 'K21' 'L21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.353244).  Saving model ...
	 Train_Loss: 0.4895 Train_Acc: 75.631 Val_Loss: 0.3532  BEST VAL Loss: 0.3532  Val_Acc: 84.650

Epoch 1: Validation loss decreased (0.353244 --> 0.322111).  Saving model ...
	 Train_Loss: 0.4195 Train_Acc: 83.274 Val_Loss: 0.3221  BEST VAL Loss: 0.3221  Val_Acc: 88.217

Epoch 2: Validation loss decreased (0.322111 --> 0.300217).  Saving model ...
	 Train_Loss: 0.3766 Train_Acc: 86.813 Val_Loss: 0.3002  BEST VAL Loss: 0.3002  Val_Acc: 90.113

Epoch 3: Validation loss decreased (0.300217 --> 0.275705).  Saving model ...
	 Train_Loss: 0.3448 Train_Acc: 88.879 Val_Loss: 0.2757  BEST VAL Loss: 0.2757  Val_Acc: 90.700

Epoch 4: Validation loss decreased (0.275705 --> 0.262269).  Saving model ...
	 Train_Loss: 0.3187 Train_Acc: 90.313 Val_Loss: 0.2623  BEST VAL Loss: 0.2623  Val_Acc: 91.558

Epoch 5: Validation loss decreased (0.262269 --> 0.250409).  Saving model ...
	 Train_Loss: 0.2988 Train_Acc: 91.002 Val_Loss: 0.2504  BEST VAL Loss: 0.2504  Val_Acc: 92.551

Epoch 6: Validation loss decreased (0.250409 --> 0.242631).  Saving model ...
	 Train_Loss: 0.2817 Train_Acc: 91.950 Val_Loss: 0.2426  BEST VAL Loss: 0.2426  Val_Acc: 92.325

Epoch 7: Validation loss decreased (0.242631 --> 0.232375).  Saving model ...
	 Train_Loss: 0.2675 Train_Acc: 92.086 Val_Loss: 0.2324  BEST VAL Loss: 0.2324  Val_Acc: 93.499

Epoch 8: Validation loss decreased (0.232375 --> 0.226141).  Saving model ...
	 Train_Loss: 0.2551 Train_Acc: 92.599 Val_Loss: 0.2261  BEST VAL Loss: 0.2261  Val_Acc: 93.409

Epoch 9: Validation loss decreased (0.226141 --> 0.219433).  Saving model ...
	 Train_Loss: 0.2450 Train_Acc: 92.594 Val_Loss: 0.2194  BEST VAL Loss: 0.2194  Val_Acc: 93.679

Epoch 10: Validation loss decreased (0.219433 --> 0.213689).  Saving model ...
	 Train_Loss: 0.2360 Train_Acc: 93.249 Val_Loss: 0.2137  BEST VAL Loss: 0.2137  Val_Acc: 93.725

Epoch 11: Validation loss decreased (0.213689 --> 0.209166).  Saving model ...
	 Train_Loss: 0.2279 Train_Acc: 93.243 Val_Loss: 0.2092  BEST VAL Loss: 0.2092  Val_Acc: 94.131

Epoch 12: Validation loss decreased (0.209166 --> 0.205259).  Saving model ...
	 Train_Loss: 0.2208 Train_Acc: 93.576 Val_Loss: 0.2053  BEST VAL Loss: 0.2053  Val_Acc: 93.725

Epoch 13: Validation loss decreased (0.205259 --> 0.201939).  Saving model ...
	 Train_Loss: 0.2143 Train_Acc: 93.853 Val_Loss: 0.2019  BEST VAL Loss: 0.2019  Val_Acc: 93.815

Epoch 14: Validation loss decreased (0.201939 --> 0.199058).  Saving model ...
	 Train_Loss: 0.2086 Train_Acc: 93.853 Val_Loss: 0.1991  BEST VAL Loss: 0.1991  Val_Acc: 94.312

Epoch 15: Validation loss decreased (0.199058 --> 0.195976).  Saving model ...
	 Train_Loss: 0.2032 Train_Acc: 94.146 Val_Loss: 0.1960  BEST VAL Loss: 0.1960  Val_Acc: 94.582

Epoch 16: Validation loss decreased (0.195976 --> 0.193388).  Saving model ...
	 Train_Loss: 0.1982 Train_Acc: 94.022 Val_Loss: 0.1934  BEST VAL Loss: 0.1934  Val_Acc: 94.447

Epoch 17: Validation loss decreased (0.193388 --> 0.192695).  Saving model ...
	 Train_Loss: 0.1934 Train_Acc: 94.491 Val_Loss: 0.1927  BEST VAL Loss: 0.1927  Val_Acc: 93.995

Epoch 18: Validation loss decreased (0.192695 --> 0.191122).  Saving model ...
	 Train_Loss: 0.1889 Train_Acc: 94.541 Val_Loss: 0.1911  BEST VAL Loss: 0.1911  Val_Acc: 94.447

Epoch 19: Validation loss decreased (0.191122 --> 0.189504).  Saving model ...
	 Train_Loss: 0.1850 Train_Acc: 94.372 Val_Loss: 0.1895  BEST VAL Loss: 0.1895  Val_Acc: 94.628

Epoch 20: Validation loss decreased (0.189504 --> 0.189432).  Saving model ...
	 Train_Loss: 0.1815 Train_Acc: 94.728 Val_Loss: 0.1894  BEST VAL Loss: 0.1894  Val_Acc: 94.131

Epoch 21: Validation loss decreased (0.189432 --> 0.188565).  Saving model ...
	 Train_Loss: 0.1782 Train_Acc: 94.530 Val_Loss: 0.1886  BEST VAL Loss: 0.1886  Val_Acc: 94.537

Epoch 22: Validation loss decreased (0.188565 --> 0.187785).  Saving model ...
	 Train_Loss: 0.1753 Train_Acc: 94.558 Val_Loss: 0.1878  BEST VAL Loss: 0.1878  Val_Acc: 94.357

Epoch 23: Validation loss did not decrease
	 Train_Loss: 0.1722 Train_Acc: 94.818 Val_Loss: 0.1884  BEST VAL Loss: 0.1878  Val_Acc: 94.582

Epoch 24: Validation loss did not decrease
	 Train_Loss: 0.1694 Train_Acc: 94.993 Val_Loss: 0.1878  BEST VAL Loss: 0.1878  Val_Acc: 94.989

Epoch 25: Validation loss decreased (0.187785 --> 0.187114).  Saving model ...
	 Train_Loss: 0.1668 Train_Acc: 94.857 Val_Loss: 0.1871  BEST VAL Loss: 0.1871  Val_Acc: 94.537

Epoch 26: Validation loss decreased (0.187114 --> 0.186786).  Saving model ...
	 Train_Loss: 0.1644 Train_Acc: 94.728 Val_Loss: 0.1868  BEST VAL Loss: 0.1868  Val_Acc: 94.718

Epoch 27: Validation loss decreased (0.186786 --> 0.186202).  Saving model ...
	 Train_Loss: 0.1619 Train_Acc: 95.445 Val_Loss: 0.1862  BEST VAL Loss: 0.1862  Val_Acc: 94.673

Epoch 28: Validation loss decreased (0.186202 --> 0.186127).  Saving model ...
	 Train_Loss: 0.1597 Train_Acc: 95.021 Val_Loss: 0.1861  BEST VAL Loss: 0.1861  Val_Acc: 94.853

Epoch 29: Validation loss decreased (0.186127 --> 0.185808).  Saving model ...
	 Train_Loss: 0.1577 Train_Acc: 94.722 Val_Loss: 0.1858  BEST VAL Loss: 0.1858  Val_Acc: 94.718

Epoch 30: Validation loss decreased (0.185808 --> 0.184685).  Saving model ...
	 Train_Loss: 0.1558 Train_Acc: 94.908 Val_Loss: 0.1847  BEST VAL Loss: 0.1847  Val_Acc: 94.673

Epoch 31: Validation loss decreased (0.184685 --> 0.184179).  Saving model ...
	 Train_Loss: 0.1539 Train_Acc: 94.959 Val_Loss: 0.1842  BEST VAL Loss: 0.1842  Val_Acc: 94.266

Epoch 32: Validation loss did not decrease
	 Train_Loss: 0.1521 Train_Acc: 95.247 Val_Loss: 0.1846  BEST VAL Loss: 0.1842  Val_Acc: 94.853

Epoch 33: Validation loss decreased (0.184179 --> 0.183573).  Saving model ...
	 Train_Loss: 0.1502 Train_Acc: 95.326 Val_Loss: 0.1836  BEST VAL Loss: 0.1836  Val_Acc: 94.537

Epoch 34: Validation loss decreased (0.183573 --> 0.183345).  Saving model ...
	 Train_Loss: 0.1485 Train_Acc: 95.315 Val_Loss: 0.1833  BEST VAL Loss: 0.1833  Val_Acc: 94.989

Epoch 35: Validation loss decreased (0.183345 --> 0.182892).  Saving model ...
	 Train_Loss: 0.1468 Train_Acc: 95.450 Val_Loss: 0.1829  BEST VAL Loss: 0.1829  Val_Acc: 94.537

Epoch 36: Validation loss decreased (0.182892 --> 0.182477).  Saving model ...
	 Train_Loss: 0.1453 Train_Acc: 95.219 Val_Loss: 0.1825  BEST VAL Loss: 0.1825  Val_Acc: 94.718

Epoch 37: Validation loss decreased (0.182477 --> 0.182032).  Saving model ...
	 Train_Loss: 0.1438 Train_Acc: 95.473 Val_Loss: 0.1820  BEST VAL Loss: 0.1820  Val_Acc: 94.402

Epoch 38: Validation loss decreased (0.182032 --> 0.181302).  Saving model ...
	 Train_Loss: 0.1424 Train_Acc: 95.230 Val_Loss: 0.1813  BEST VAL Loss: 0.1813  Val_Acc: 94.944

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.1411 Train_Acc: 95.236 Val_Loss: 0.1815  BEST VAL Loss: 0.1813  Val_Acc: 94.447

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.1397 Train_Acc: 95.399 Val_Loss: 0.1819  BEST VAL Loss: 0.1813  Val_Acc: 94.763

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.1384 Train_Acc: 95.428 Val_Loss: 0.1815  BEST VAL Loss: 0.1813  Val_Acc: 94.944

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.1372 Train_Acc: 95.670 Val_Loss: 0.1819  BEST VAL Loss: 0.1813  Val_Acc: 94.808

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.1358 Train_Acc: 95.710 Val_Loss: 0.1834  BEST VAL Loss: 0.1813  Val_Acc: 94.537

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.1347 Train_Acc: 95.433 Val_Loss: 0.1838  BEST VAL Loss: 0.1813  Val_Acc: 94.266

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.1336 Train_Acc: 95.524 Val_Loss: 0.1843  BEST VAL Loss: 0.1813  Val_Acc: 94.357

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.1327 Train_Acc: 95.461 Val_Loss: 0.1838  BEST VAL Loss: 0.1813  Val_Acc: 95.214

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.1317 Train_Acc: 95.433 Val_Loss: 0.1833  BEST VAL Loss: 0.1813  Val_Acc: 94.131

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.1307 Train_Acc: 95.557 Val_Loss: 0.1835  BEST VAL Loss: 0.1813  Val_Acc: 94.673

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.1298 Train_Acc: 95.642 Val_Loss: 0.1829  BEST VAL Loss: 0.1813  Val_Acc: 94.492

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.1288 Train_Acc: 95.490 Val_Loss: 0.1833  BEST VAL Loss: 0.1813  Val_Acc: 93.770

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.1279 Train_Acc: 95.524 Val_Loss: 0.1831  BEST VAL Loss: 0.1813  Val_Acc: 93.454

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.1271 Train_Acc: 95.569 Val_Loss: 0.1837  BEST VAL Loss: 0.1813  Val_Acc: 94.718

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.1262 Train_Acc: 95.484 Val_Loss: 0.1840  BEST VAL Loss: 0.1813  Val_Acc: 94.944

Epoch 54: Validation loss did not decrease
Early stopped at epoch : 54
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.56      0.56      0.56      9777
           1       0.46      0.45      0.45      7938

    accuracy                           0.51     17715
   macro avg       0.51      0.51      0.51     17715
weighted avg       0.51      0.51      0.51     17715

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.55      0.55      1222
           1       0.44      0.44      0.44       993

    accuracy                           0.50      2215
   macro avg       0.50      0.50      0.50      2215
weighted avg       0.50      0.50      0.50      2215

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.56      0.57      0.57      1223
           1       0.46      0.44      0.45       992

    accuracy                           0.52      2215
   macro avg       0.51      0.51      0.51      2215
weighted avg       0.51      0.52      0.52      2215

              precision    recall  f1-score   support

           0       0.56      0.57      0.57      1223
           1       0.46      0.44      0.45       992

    accuracy                           0.52      2215
   macro avg       0.51      0.51      0.51      2215
weighted avg       0.51      0.52      0.52      2215

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.52      0.61      0.56      3996
           1       0.49      0.40      0.44      3729

    accuracy                           0.51      7725
   macro avg       0.50      0.50      0.50      7725
weighted avg       0.50      0.51      0.50      7725

              precision    recall  f1-score   support

           0       0.52      0.61      0.56      3996
           1       0.49      0.40      0.44      3729

    accuracy                           0.51      7725
   macro avg       0.50      0.50      0.50      7725
weighted avg       0.50      0.51      0.50      7725

completed
