[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '584367ef'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '199f50eb'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'c09c48de'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '05fedc75'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_100.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_100.000_DMSO_0.025
TREATMENT_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_100.000_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (325448, 1270)
Number of total missing values across all columns: 318870
Data Subset Is Off
Wells held out for testing: ['K08' 'J09']
Wells to use for training, validation, and testing ['J02' 'K02' 'J03' 'K03' 'J08' 'K09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.654284).  Saving model ...
	 Train_Loss: 0.6875 Train_Acc: 51.081 Val_Loss: 0.6543  BEST VAL Loss: 0.6543  Val_Acc: 51.157

Epoch 1: Validation loss decreased (0.654284 --> 0.616830).  Saving model ...
	 Train_Loss: 0.6539 Train_Acc: 65.395 Val_Loss: 0.6168  BEST VAL Loss: 0.6168  Val_Acc: 72.427

Epoch 2: Validation loss decreased (0.616830 --> 0.590160).  Saving model ...
	 Train_Loss: 0.6283 Train_Acc: 70.752 Val_Loss: 0.5902  BEST VAL Loss: 0.5902  Val_Acc: 74.643

Epoch 3: Validation loss decreased (0.590160 --> 0.565563).  Saving model ...
	 Train_Loss: 0.6067 Train_Acc: 72.725 Val_Loss: 0.5656  BEST VAL Loss: 0.5656  Val_Acc: 77.365

Epoch 4: Validation loss decreased (0.565563 --> 0.542594).  Saving model ...
	 Train_Loss: 0.5866 Train_Acc: 74.771 Val_Loss: 0.5426  BEST VAL Loss: 0.5426  Val_Acc: 80.152

Epoch 5: Validation loss decreased (0.542594 --> 0.521506).  Saving model ...
	 Train_Loss: 0.5675 Train_Acc: 76.618 Val_Loss: 0.5215  BEST VAL Loss: 0.5215  Val_Acc: 82.108

Epoch 6: Validation loss decreased (0.521506 --> 0.502581).  Saving model ...
	 Train_Loss: 0.5503 Train_Acc: 77.750 Val_Loss: 0.5026  BEST VAL Loss: 0.5026  Val_Acc: 83.302

Epoch 7: Validation loss decreased (0.502581 --> 0.486156).  Saving model ...
	 Train_Loss: 0.5353 Train_Acc: 78.591 Val_Loss: 0.4862  BEST VAL Loss: 0.4862  Val_Acc: 84.158

Epoch 8: Validation loss decreased (0.486156 --> 0.472146).  Saving model ...
	 Train_Loss: 0.5222 Train_Acc: 79.239 Val_Loss: 0.4721  BEST VAL Loss: 0.4721  Val_Acc: 84.647

Epoch 9: Validation loss decreased (0.472146 --> 0.460477).  Saving model ...
	 Train_Loss: 0.5108 Train_Acc: 79.595 Val_Loss: 0.4605  BEST VAL Loss: 0.4605  Val_Acc: 85.034

Epoch 10: Validation loss decreased (0.460477 --> 0.450154).  Saving model ...
	 Train_Loss: 0.5008 Train_Acc: 80.014 Val_Loss: 0.4502  BEST VAL Loss: 0.4502  Val_Acc: 85.217

Epoch 11: Validation loss decreased (0.450154 --> 0.441208).  Saving model ...
	 Train_Loss: 0.4921 Train_Acc: 80.186 Val_Loss: 0.4412  BEST VAL Loss: 0.4412  Val_Acc: 85.315

Epoch 12: Validation loss decreased (0.441208 --> 0.433089).  Saving model ...
	 Train_Loss: 0.4845 Train_Acc: 80.328 Val_Loss: 0.4331  BEST VAL Loss: 0.4331  Val_Acc: 85.755

Epoch 13: Validation loss decreased (0.433089 --> 0.426069).  Saving model ...
	 Train_Loss: 0.4777 Train_Acc: 80.439 Val_Loss: 0.4261  BEST VAL Loss: 0.4261  Val_Acc: 85.710

Epoch 14: Validation loss decreased (0.426069 --> 0.419746).  Saving model ...
	 Train_Loss: 0.4716 Train_Acc: 80.575 Val_Loss: 0.4197  BEST VAL Loss: 0.4197  Val_Acc: 86.134

Epoch 15: Validation loss decreased (0.419746 --> 0.414037).  Saving model ...
	 Train_Loss: 0.4661 Train_Acc: 80.724 Val_Loss: 0.4140  BEST VAL Loss: 0.4140  Val_Acc: 86.044

Epoch 16: Validation loss decreased (0.414037 --> 0.409162).  Saving model ...
	 Train_Loss: 0.4610 Train_Acc: 80.869 Val_Loss: 0.4092  BEST VAL Loss: 0.4092  Val_Acc: 85.914

Epoch 17: Validation loss decreased (0.409162 --> 0.404339).  Saving model ...
	 Train_Loss: 0.4564 Train_Acc: 81.008 Val_Loss: 0.4043  BEST VAL Loss: 0.4043  Val_Acc: 86.590

Epoch 18: Validation loss decreased (0.404339 --> 0.400031).  Saving model ...
	 Train_Loss: 0.4522 Train_Acc: 81.093 Val_Loss: 0.4000  BEST VAL Loss: 0.4000  Val_Acc: 86.383

Epoch 19: Validation loss decreased (0.400031 --> 0.396207).  Saving model ...
	 Train_Loss: 0.4483 Train_Acc: 81.247 Val_Loss: 0.3962  BEST VAL Loss: 0.3962  Val_Acc: 86.550

Epoch 20: Validation loss decreased (0.396207 --> 0.392738).  Saving model ...
	 Train_Loss: 0.4448 Train_Acc: 81.132 Val_Loss: 0.3927  BEST VAL Loss: 0.3927  Val_Acc: 86.387

Epoch 21: Validation loss decreased (0.392738 --> 0.389302).  Saving model ...
	 Train_Loss: 0.4414 Train_Acc: 81.395 Val_Loss: 0.3893  BEST VAL Loss: 0.3893  Val_Acc: 86.664

Epoch 22: Validation loss decreased (0.389302 --> 0.386245).  Saving model ...
	 Train_Loss: 0.4383 Train_Acc: 81.328 Val_Loss: 0.3862  BEST VAL Loss: 0.3862  Val_Acc: 86.790

Epoch 23: Validation loss decreased (0.386245 --> 0.383418).  Saving model ...
	 Train_Loss: 0.4354 Train_Acc: 81.572 Val_Loss: 0.3834  BEST VAL Loss: 0.3834  Val_Acc: 86.696

Epoch 24: Validation loss decreased (0.383418 --> 0.380672).  Saving model ...
	 Train_Loss: 0.4326 Train_Acc: 81.946 Val_Loss: 0.3807  BEST VAL Loss: 0.3807  Val_Acc: 86.880

Epoch 25: Validation loss decreased (0.380672 --> 0.379217).  Saving model ...
	 Train_Loss: 0.4301 Train_Acc: 81.780 Val_Loss: 0.3792  BEST VAL Loss: 0.3792  Val_Acc: 84.838

Epoch 26: Validation loss decreased (0.379217 --> 0.376711).  Saving model ...
	 Train_Loss: 0.4277 Train_Acc: 81.941 Val_Loss: 0.3767  BEST VAL Loss: 0.3767  Val_Acc: 86.831

Epoch 27: Validation loss decreased (0.376711 --> 0.374312).  Saving model ...
	 Train_Loss: 0.4253 Train_Acc: 82.037 Val_Loss: 0.3743  BEST VAL Loss: 0.3743  Val_Acc: 86.953

Epoch 28: Validation loss decreased (0.374312 --> 0.372005).  Saving model ...
	 Train_Loss: 0.4232 Train_Acc: 82.060 Val_Loss: 0.3720  BEST VAL Loss: 0.3720  Val_Acc: 87.193

Epoch 29: Validation loss decreased (0.372005 --> 0.369870).  Saving model ...
	 Train_Loss: 0.4211 Train_Acc: 82.179 Val_Loss: 0.3699  BEST VAL Loss: 0.3699  Val_Acc: 86.867

Epoch 30: Validation loss decreased (0.369870 --> 0.367815).  Saving model ...
	 Train_Loss: 0.4191 Train_Acc: 82.148 Val_Loss: 0.3678  BEST VAL Loss: 0.3678  Val_Acc: 87.450

Epoch 31: Validation loss decreased (0.367815 --> 0.365732).  Saving model ...
	 Train_Loss: 0.4172 Train_Acc: 82.148 Val_Loss: 0.3657  BEST VAL Loss: 0.3657  Val_Acc: 87.544

Epoch 32: Validation loss decreased (0.365732 --> 0.363842).  Saving model ...
	 Train_Loss: 0.4154 Train_Acc: 82.303 Val_Loss: 0.3638  BEST VAL Loss: 0.3638  Val_Acc: 87.381

Epoch 33: Validation loss decreased (0.363842 --> 0.362262).  Saving model ...
	 Train_Loss: 0.4137 Train_Acc: 82.309 Val_Loss: 0.3623  BEST VAL Loss: 0.3623  Val_Acc: 86.859

Epoch 34: Validation loss decreased (0.362262 --> 0.360473).  Saving model ...
	 Train_Loss: 0.4121 Train_Acc: 82.322 Val_Loss: 0.3605  BEST VAL Loss: 0.3605  Val_Acc: 87.564

Epoch 35: Validation loss decreased (0.360473 --> 0.358822).  Saving model ...
	 Train_Loss: 0.4106 Train_Acc: 82.272 Val_Loss: 0.3588  BEST VAL Loss: 0.3588  Val_Acc: 87.536

Epoch 36: Validation loss decreased (0.358822 --> 0.357393).  Saving model ...
	 Train_Loss: 0.4091 Train_Acc: 82.363 Val_Loss: 0.3574  BEST VAL Loss: 0.3574  Val_Acc: 87.291

Epoch 37: Validation loss decreased (0.357393 --> 0.355829).  Saving model ...
	 Train_Loss: 0.4076 Train_Acc: 82.390 Val_Loss: 0.3558  BEST VAL Loss: 0.3558  Val_Acc: 87.597

Epoch 38: Validation loss decreased (0.355829 --> 0.354446).  Saving model ...
	 Train_Loss: 0.4062 Train_Acc: 82.523 Val_Loss: 0.3544  BEST VAL Loss: 0.3544  Val_Acc: 87.365

Epoch 39: Validation loss decreased (0.354446 --> 0.353081).  Saving model ...
	 Train_Loss: 0.4049 Train_Acc: 82.569 Val_Loss: 0.3531  BEST VAL Loss: 0.3531  Val_Acc: 87.511

Epoch 40: Validation loss decreased (0.353081 --> 0.351968).  Saving model ...
	 Train_Loss: 0.4036 Train_Acc: 82.593 Val_Loss: 0.3520  BEST VAL Loss: 0.3520  Val_Acc: 86.977

Epoch 41: Validation loss decreased (0.351968 --> 0.350654).  Saving model ...
	 Train_Loss: 0.4024 Train_Acc: 82.470 Val_Loss: 0.3507  BEST VAL Loss: 0.3507  Val_Acc: 87.658

Epoch 42: Validation loss decreased (0.350654 --> 0.349470).  Saving model ...
	 Train_Loss: 0.4012 Train_Acc: 82.545 Val_Loss: 0.3495  BEST VAL Loss: 0.3495  Val_Acc: 87.646

Epoch 43: Validation loss decreased (0.349470 --> 0.348522).  Saving model ...
	 Train_Loss: 0.4001 Train_Acc: 82.677 Val_Loss: 0.3485  BEST VAL Loss: 0.3485  Val_Acc: 86.929

Epoch 44: Validation loss decreased (0.348522 --> 0.347301).  Saving model ...
	 Train_Loss: 0.3990 Train_Acc: 82.587 Val_Loss: 0.3473  BEST VAL Loss: 0.3473  Val_Acc: 87.764

Epoch 45: Validation loss decreased (0.347301 --> 0.346222).  Saving model ...
	 Train_Loss: 0.3980 Train_Acc: 82.593 Val_Loss: 0.3462  BEST VAL Loss: 0.3462  Val_Acc: 87.642

Epoch 46: Validation loss decreased (0.346222 --> 0.345289).  Saving model ...
	 Train_Loss: 0.3969 Train_Acc: 82.742 Val_Loss: 0.3453  BEST VAL Loss: 0.3453  Val_Acc: 87.100

Epoch 47: Validation loss decreased (0.345289 --> 0.344218).  Saving model ...
	 Train_Loss: 0.3959 Train_Acc: 82.716 Val_Loss: 0.3442  BEST VAL Loss: 0.3442  Val_Acc: 87.817

Epoch 48: Validation loss decreased (0.344218 --> 0.343411).  Saving model ...
	 Train_Loss: 0.3950 Train_Acc: 82.778 Val_Loss: 0.3434  BEST VAL Loss: 0.3434  Val_Acc: 87.197

Epoch 49: Validation loss decreased (0.343411 --> 0.342523).  Saving model ...
	 Train_Loss: 0.3941 Train_Acc: 82.650 Val_Loss: 0.3425  BEST VAL Loss: 0.3425  Val_Acc: 87.430

Epoch 50: Validation loss decreased (0.342523 --> 0.342297).  Saving model ...
	 Train_Loss: 0.3932 Train_Acc: 82.813 Val_Loss: 0.3423  BEST VAL Loss: 0.3423  Val_Acc: 85.356

Epoch 51: Validation loss decreased (0.342297 --> 0.341389).  Saving model ...
	 Train_Loss: 0.3923 Train_Acc: 82.745 Val_Loss: 0.3414  BEST VAL Loss: 0.3414  Val_Acc: 87.711

Epoch 52: Validation loss decreased (0.341389 --> 0.340607).  Saving model ...
	 Train_Loss: 0.3915 Train_Acc: 82.899 Val_Loss: 0.3406  BEST VAL Loss: 0.3406  Val_Acc: 87.259

Epoch 53: Validation loss decreased (0.340607 --> 0.339747).  Saving model ...
	 Train_Loss: 0.3906 Train_Acc: 82.936 Val_Loss: 0.3397  BEST VAL Loss: 0.3397  Val_Acc: 87.711

Epoch 54: Validation loss decreased (0.339747 --> 0.338970).  Saving model ...
	 Train_Loss: 0.3898 Train_Acc: 82.843 Val_Loss: 0.3390  BEST VAL Loss: 0.3390  Val_Acc: 87.601

Epoch 55: Validation loss decreased (0.338970 --> 0.338144).  Saving model ...
	 Train_Loss: 0.3891 Train_Acc: 82.809 Val_Loss: 0.3381  BEST VAL Loss: 0.3381  Val_Acc: 87.821

Epoch 56: Validation loss decreased (0.338144 --> 0.337553).  Saving model ...
	 Train_Loss: 0.3883 Train_Acc: 82.879 Val_Loss: 0.3376  BEST VAL Loss: 0.3376  Val_Acc: 86.798

Epoch 57: Validation loss decreased (0.337553 --> 0.336796).  Saving model ...
	 Train_Loss: 0.3876 Train_Acc: 82.900 Val_Loss: 0.3368  BEST VAL Loss: 0.3368  Val_Acc: 87.829

Epoch 58: Validation loss decreased (0.336796 --> 0.336065).  Saving model ...
	 Train_Loss: 0.3869 Train_Acc: 82.811 Val_Loss: 0.3361  BEST VAL Loss: 0.3361  Val_Acc: 87.784

Epoch 59: Validation loss decreased (0.336065 --> 0.335354).  Saving model ...
	 Train_Loss: 0.3862 Train_Acc: 82.966 Val_Loss: 0.3354  BEST VAL Loss: 0.3354  Val_Acc: 87.625

Epoch 60: Validation loss decreased (0.335354 --> 0.334678).  Saving model ...
	 Train_Loss: 0.3855 Train_Acc: 82.898 Val_Loss: 0.3347  BEST VAL Loss: 0.3347  Val_Acc: 87.674

Epoch 61: Validation loss decreased (0.334678 --> 0.334052).  Saving model ...
	 Train_Loss: 0.3849 Train_Acc: 82.973 Val_Loss: 0.3341  BEST VAL Loss: 0.3341  Val_Acc: 87.723

Epoch 62: Validation loss decreased (0.334052 --> 0.333380).  Saving model ...
	 Train_Loss: 0.3842 Train_Acc: 83.029 Val_Loss: 0.3334  BEST VAL Loss: 0.3334  Val_Acc: 87.674

Epoch 63: Validation loss decreased (0.333380 --> 0.332667).  Saving model ...
	 Train_Loss: 0.3836 Train_Acc: 82.962 Val_Loss: 0.3327  BEST VAL Loss: 0.3327  Val_Acc: 88.029

Epoch 64: Validation loss decreased (0.332667 --> 0.331988).  Saving model ...
	 Train_Loss: 0.3830 Train_Acc: 82.943 Val_Loss: 0.3320  BEST VAL Loss: 0.3320  Val_Acc: 88.004

Epoch 65: Validation loss decreased (0.331988 --> 0.331357).  Saving model ...
	 Train_Loss: 0.3824 Train_Acc: 82.986 Val_Loss: 0.3314  BEST VAL Loss: 0.3314  Val_Acc: 87.919

Epoch 66: Validation loss decreased (0.331357 --> 0.330927).  Saving model ...
	 Train_Loss: 0.3818 Train_Acc: 82.947 Val_Loss: 0.3309  BEST VAL Loss: 0.3309  Val_Acc: 87.291

Epoch 67: Validation loss decreased (0.330927 --> 0.330416).  Saving model ...
	 Train_Loss: 0.3813 Train_Acc: 83.078 Val_Loss: 0.3304  BEST VAL Loss: 0.3304  Val_Acc: 87.397

Epoch 68: Validation loss decreased (0.330416 --> 0.329880).  Saving model ...
	 Train_Loss: 0.3807 Train_Acc: 82.993 Val_Loss: 0.3299  BEST VAL Loss: 0.3299  Val_Acc: 87.605

Epoch 69: Validation loss decreased (0.329880 --> 0.329363).  Saving model ...
	 Train_Loss: 0.3802 Train_Acc: 82.985 Val_Loss: 0.3294  BEST VAL Loss: 0.3294  Val_Acc: 87.650

Epoch 70: Validation loss decreased (0.329363 --> 0.328825).  Saving model ...
	 Train_Loss: 0.3797 Train_Acc: 83.000 Val_Loss: 0.3288  BEST VAL Loss: 0.3288  Val_Acc: 87.756

Epoch 71: Validation loss decreased (0.328825 --> 0.328356).  Saving model ...
	 Train_Loss: 0.3792 Train_Acc: 83.017 Val_Loss: 0.3284  BEST VAL Loss: 0.3284  Val_Acc: 87.654

Epoch 72: Validation loss decreased (0.328356 --> 0.327786).  Saving model ...
	 Train_Loss: 0.3786 Train_Acc: 83.054 Val_Loss: 0.3278  BEST VAL Loss: 0.3278  Val_Acc: 88.090

Epoch 73: Validation loss decreased (0.327786 --> 0.327240).  Saving model ...
	 Train_Loss: 0.3781 Train_Acc: 83.077 Val_Loss: 0.3272  BEST VAL Loss: 0.3272  Val_Acc: 88.094

Epoch 74: Validation loss decreased (0.327240 --> 0.326765).  Saving model ...
	 Train_Loss: 0.3777 Train_Acc: 83.060 Val_Loss: 0.3268  BEST VAL Loss: 0.3268  Val_Acc: 87.874

Epoch 75: Validation loss decreased (0.326765 --> 0.326355).  Saving model ...
	 Train_Loss: 0.3772 Train_Acc: 83.101 Val_Loss: 0.3264  BEST VAL Loss: 0.3264  Val_Acc: 87.503

Epoch 76: Validation loss decreased (0.326355 --> 0.325844).  Saving model ...
	 Train_Loss: 0.3768 Train_Acc: 83.068 Val_Loss: 0.3258  BEST VAL Loss: 0.3258  Val_Acc: 87.972

Epoch 77: Validation loss decreased (0.325844 --> 0.325588).  Saving model ...
	 Train_Loss: 0.3763 Train_Acc: 83.259 Val_Loss: 0.3256  BEST VAL Loss: 0.3256  Val_Acc: 86.562

Epoch 78: Validation loss decreased (0.325588 --> 0.325083).  Saving model ...
	 Train_Loss: 0.3758 Train_Acc: 83.216 Val_Loss: 0.3251  BEST VAL Loss: 0.3251  Val_Acc: 88.065

Epoch 79: Validation loss decreased (0.325083 --> 0.324711).  Saving model ...
	 Train_Loss: 0.3754 Train_Acc: 83.265 Val_Loss: 0.3247  BEST VAL Loss: 0.3247  Val_Acc: 87.564

Epoch 80: Validation loss decreased (0.324711 --> 0.324312).  Saving model ...
	 Train_Loss: 0.3749 Train_Acc: 83.195 Val_Loss: 0.3243  BEST VAL Loss: 0.3243  Val_Acc: 87.943

Epoch 81: Validation loss decreased (0.324312 --> 0.323939).  Saving model ...
	 Train_Loss: 0.3745 Train_Acc: 83.069 Val_Loss: 0.3239  BEST VAL Loss: 0.3239  Val_Acc: 87.385

Epoch 82: Validation loss decreased (0.323939 --> 0.323583).  Saving model ...
	 Train_Loss: 0.3741 Train_Acc: 83.141 Val_Loss: 0.3236  BEST VAL Loss: 0.3236  Val_Acc: 87.821

Epoch 83: Validation loss decreased (0.323583 --> 0.323124).  Saving model ...
	 Train_Loss: 0.3737 Train_Acc: 83.213 Val_Loss: 0.3231  BEST VAL Loss: 0.3231  Val_Acc: 88.012

Epoch 84: Validation loss decreased (0.323124 --> 0.322721).  Saving model ...
	 Train_Loss: 0.3733 Train_Acc: 83.294 Val_Loss: 0.3227  BEST VAL Loss: 0.3227  Val_Acc: 87.874

Epoch 85: Validation loss decreased (0.322721 --> 0.322323).  Saving model ...
	 Train_Loss: 0.3729 Train_Acc: 83.172 Val_Loss: 0.3223  BEST VAL Loss: 0.3223  Val_Acc: 87.780

Epoch 86: Validation loss decreased (0.322323 --> 0.321877).  Saving model ...
	 Train_Loss: 0.3725 Train_Acc: 83.172 Val_Loss: 0.3219  BEST VAL Loss: 0.3219  Val_Acc: 88.277

Epoch 87: Validation loss decreased (0.321877 --> 0.321549).  Saving model ...
	 Train_Loss: 0.3722 Train_Acc: 83.232 Val_Loss: 0.3215  BEST VAL Loss: 0.3215  Val_Acc: 87.711

Epoch 88: Validation loss decreased (0.321549 --> 0.321126).  Saving model ...
	 Train_Loss: 0.3718 Train_Acc: 83.193 Val_Loss: 0.3211  BEST VAL Loss: 0.3211  Val_Acc: 88.253

Epoch 89: Validation loss decreased (0.321126 --> 0.320795).  Saving model ...
	 Train_Loss: 0.3714 Train_Acc: 83.176 Val_Loss: 0.3208  BEST VAL Loss: 0.3208  Val_Acc: 87.646

Epoch 90: Validation loss decreased (0.320795 --> 0.320448).  Saving model ...
	 Train_Loss: 0.3711 Train_Acc: 83.238 Val_Loss: 0.3204  BEST VAL Loss: 0.3204  Val_Acc: 87.825

Epoch 91: Validation loss decreased (0.320448 --> 0.320160).  Saving model ...
	 Train_Loss: 0.3707 Train_Acc: 83.177 Val_Loss: 0.3202  BEST VAL Loss: 0.3202  Val_Acc: 87.686

Epoch 92: Validation loss decreased (0.320160 --> 0.319827).  Saving model ...
	 Train_Loss: 0.3704 Train_Acc: 83.284 Val_Loss: 0.3198  BEST VAL Loss: 0.3198  Val_Acc: 87.845

Epoch 93: Validation loss decreased (0.319827 --> 0.319448).  Saving model ...
	 Train_Loss: 0.3700 Train_Acc: 83.299 Val_Loss: 0.3194  BEST VAL Loss: 0.3194  Val_Acc: 88.037

Epoch 94: Validation loss decreased (0.319448 --> 0.319138).  Saving model ...
	 Train_Loss: 0.3697 Train_Acc: 83.279 Val_Loss: 0.3191  BEST VAL Loss: 0.3191  Val_Acc: 87.792

Epoch 95: Validation loss decreased (0.319138 --> 0.318788).  Saving model ...
	 Train_Loss: 0.3694 Train_Acc: 83.264 Val_Loss: 0.3188  BEST VAL Loss: 0.3188  Val_Acc: 87.996

Epoch 96: Validation loss decreased (0.318788 --> 0.318434).  Saving model ...
	 Train_Loss: 0.3691 Train_Acc: 83.262 Val_Loss: 0.3184  BEST VAL Loss: 0.3184  Val_Acc: 88.245

Epoch 97: Validation loss decreased (0.318434 --> 0.318138).  Saving model ...
	 Train_Loss: 0.3687 Train_Acc: 83.275 Val_Loss: 0.3181  BEST VAL Loss: 0.3181  Val_Acc: 87.915

Epoch 98: Validation loss decreased (0.318138 --> 0.317788).  Saving model ...
	 Train_Loss: 0.3684 Train_Acc: 83.300 Val_Loss: 0.3178  BEST VAL Loss: 0.3178  Val_Acc: 88.094

Epoch 99: Validation loss decreased (0.317788 --> 0.317501).  Saving model ...
	 Train_Loss: 0.3681 Train_Acc: 83.463 Val_Loss: 0.3175  BEST VAL Loss: 0.3175  Val_Acc: 87.805

LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.49      0.49     95989
           1       0.51      0.51      0.51    100339

    accuracy                           0.50    196328
   macro avg       0.50      0.50      0.50    196328
weighted avg       0.50      0.50      0.50    196328

LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.49      0.49     11999
           1       0.51      0.52      0.52     12543

    accuracy                           0.50     24542
   macro avg       0.50      0.50      0.50     24542
weighted avg       0.50      0.50      0.50     24542

LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.48      0.48     11999
           1       0.51      0.51      0.51     12543

    accuracy                           0.50     24542
   macro avg       0.49      0.49      0.49     24542
weighted avg       0.50      0.50      0.50     24542

              precision    recall  f1-score   support

           0       0.48      0.48      0.48     11999
           1       0.51      0.51      0.51     12543

    accuracy                           0.50     24542
   macro avg       0.49      0.49      0.49     24542
weighted avg       0.50      0.50      0.50     24542

LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_100.000_DMSO_0.025_vs_LPS_Nigericin_1.000_1.0_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.49      0.49     39448
           1       0.51      0.51      0.51     40588

    accuracy                           0.50     80036
   macro avg       0.50      0.50      0.50     80036
weighted avg       0.50      0.50      0.50     80036

              precision    recall  f1-score   support

           0       0.49      0.49      0.49     39448
           1       0.51      0.51      0.51     40588

    accuracy                           0.50     80036
   macro avg       0.50      0.50      0.50     80036
weighted avg       0.50      0.50      0.50     80036

completed
