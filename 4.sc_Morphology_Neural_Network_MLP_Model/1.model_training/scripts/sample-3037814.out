[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '3a6edd94'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '152e2d1c'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '4a46c6d5'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '547df635'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_1.0_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_Nigericin_1.000_1.0_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (261928, 1270)
Number of total missing values across all columns: 191830
Data Subset Is Off
Wells held out for testing: ['K08' 'L10']
Wells to use for training, validation, and testing ['K02' 'K03' 'K09' 'L05' 'L11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.199982).  Saving model ...
	 Train_Loss: 0.3207 Train_Acc: 87.734 Val_Loss: 0.2000  BEST VAL Loss: 0.2000  Val_Acc: 91.908

Epoch 1: Validation loss decreased (0.199982 --> 0.168785).  Saving model ...
	 Train_Loss: 0.2626 Train_Acc: 92.087 Val_Loss: 0.1688  BEST VAL Loss: 0.1688  Val_Acc: 94.895

Epoch 2: Validation loss decreased (0.168785 --> 0.161117).  Saving model ...
	 Train_Loss: 0.2352 Train_Acc: 93.045 Val_Loss: 0.1611  BEST VAL Loss: 0.1611  Val_Acc: 94.248

Epoch 3: Validation loss decreased (0.161117 --> 0.150279).  Saving model ...
	 Train_Loss: 0.2179 Train_Acc: 93.656 Val_Loss: 0.1503  BEST VAL Loss: 0.1503  Val_Acc: 95.378

Epoch 4: Validation loss decreased (0.150279 --> 0.141794).  Saving model ...
	 Train_Loss: 0.2055 Train_Acc: 94.061 Val_Loss: 0.1418  BEST VAL Loss: 0.1418  Val_Acc: 95.835

Epoch 5: Validation loss decreased (0.141794 --> 0.135358).  Saving model ...
	 Train_Loss: 0.1961 Train_Acc: 94.298 Val_Loss: 0.1354  BEST VAL Loss: 0.1354  Val_Acc: 95.999

Epoch 6: Validation loss decreased (0.135358 --> 0.130632).  Saving model ...
	 Train_Loss: 0.1890 Train_Acc: 94.464 Val_Loss: 0.1306  BEST VAL Loss: 0.1306  Val_Acc: 96.073

Epoch 7: Validation loss decreased (0.130632 --> 0.126697).  Saving model ...
	 Train_Loss: 0.1830 Train_Acc: 94.670 Val_Loss: 0.1267  BEST VAL Loss: 0.1267  Val_Acc: 96.180

Epoch 8: Validation loss decreased (0.126697 --> 0.124299).  Saving model ...
	 Train_Loss: 0.1779 Train_Acc: 94.796 Val_Loss: 0.1243  BEST VAL Loss: 0.1243  Val_Acc: 95.782

Epoch 9: Validation loss decreased (0.124299 --> 0.121663).  Saving model ...
	 Train_Loss: 0.1738 Train_Acc: 94.848 Val_Loss: 0.1217  BEST VAL Loss: 0.1217  Val_Acc: 96.238

Epoch 10: Validation loss decreased (0.121663 --> 0.119224).  Saving model ...
	 Train_Loss: 0.1701 Train_Acc: 94.885 Val_Loss: 0.1192  BEST VAL Loss: 0.1192  Val_Acc: 96.291

Epoch 11: Validation loss decreased (0.119224 --> 0.117168).  Saving model ...
	 Train_Loss: 0.1669 Train_Acc: 94.997 Val_Loss: 0.1172  BEST VAL Loss: 0.1172  Val_Acc: 96.360

Epoch 12: Validation loss decreased (0.117168 --> 0.116071).  Saving model ...
	 Train_Loss: 0.1641 Train_Acc: 95.046 Val_Loss: 0.1161  BEST VAL Loss: 0.1161  Val_Acc: 96.137

Epoch 13: Validation loss decreased (0.116071 --> 0.114454).  Saving model ...
	 Train_Loss: 0.1615 Train_Acc: 95.122 Val_Loss: 0.1145  BEST VAL Loss: 0.1145  Val_Acc: 96.482

Epoch 14: Validation loss decreased (0.114454 --> 0.113076).  Saving model ...
	 Train_Loss: 0.1592 Train_Acc: 95.197 Val_Loss: 0.1131  BEST VAL Loss: 0.1131  Val_Acc: 96.519

Epoch 15: Validation loss decreased (0.113076 --> 0.111659).  Saving model ...
	 Train_Loss: 0.1570 Train_Acc: 95.297 Val_Loss: 0.1117  BEST VAL Loss: 0.1117  Val_Acc: 96.609

Epoch 16: Validation loss decreased (0.111659 --> 0.110292).  Saving model ...
	 Train_Loss: 0.1550 Train_Acc: 95.243 Val_Loss: 0.1103  BEST VAL Loss: 0.1103  Val_Acc: 96.726

Epoch 17: Validation loss decreased (0.110292 --> 0.109313).  Saving model ...
	 Train_Loss: 0.1532 Train_Acc: 95.340 Val_Loss: 0.1093  BEST VAL Loss: 0.1093  Val_Acc: 96.493

Epoch 18: Validation loss decreased (0.109313 --> 0.108387).  Saving model ...
	 Train_Loss: 0.1515 Train_Acc: 95.402 Val_Loss: 0.1084  BEST VAL Loss: 0.1084  Val_Acc: 96.583

Epoch 19: Validation loss decreased (0.108387 --> 0.107612).  Saving model ...
	 Train_Loss: 0.1501 Train_Acc: 95.429 Val_Loss: 0.1076  BEST VAL Loss: 0.1076  Val_Acc: 96.408

Epoch 20: Validation loss decreased (0.107612 --> 0.106594).  Saving model ...
	 Train_Loss: 0.1486 Train_Acc: 95.454 Val_Loss: 0.1066  BEST VAL Loss: 0.1066  Val_Acc: 96.822

Epoch 21: Validation loss decreased (0.106594 --> 0.105976).  Saving model ...
	 Train_Loss: 0.1472 Train_Acc: 95.501 Val_Loss: 0.1060  BEST VAL Loss: 0.1060  Val_Acc: 96.418

Epoch 22: Validation loss decreased (0.105976 --> 0.105275).  Saving model ...
	 Train_Loss: 0.1460 Train_Acc: 95.499 Val_Loss: 0.1053  BEST VAL Loss: 0.1053  Val_Acc: 96.503

Epoch 23: Validation loss decreased (0.105275 --> 0.104519).  Saving model ...
	 Train_Loss: 0.1448 Train_Acc: 95.617 Val_Loss: 0.1045  BEST VAL Loss: 0.1045  Val_Acc: 96.769

Epoch 24: Validation loss decreased (0.104519 --> 0.103885).  Saving model ...
	 Train_Loss: 0.1436 Train_Acc: 95.579 Val_Loss: 0.1039  BEST VAL Loss: 0.1039  Val_Acc: 96.662

Epoch 25: Validation loss decreased (0.103885 --> 0.103283).  Saving model ...
	 Train_Loss: 0.1426 Train_Acc: 95.576 Val_Loss: 0.1033  BEST VAL Loss: 0.1033  Val_Acc: 96.647

Epoch 26: Validation loss decreased (0.103283 --> 0.102672).  Saving model ...
	 Train_Loss: 0.1416 Train_Acc: 95.601 Val_Loss: 0.1027  BEST VAL Loss: 0.1027  Val_Acc: 96.668

Epoch 27: Validation loss decreased (0.102672 --> 0.102150).  Saving model ...
	 Train_Loss: 0.1406 Train_Acc: 95.616 Val_Loss: 0.1022  BEST VAL Loss: 0.1022  Val_Acc: 96.578

Epoch 28: Validation loss decreased (0.102150 --> 0.101605).  Saving model ...
	 Train_Loss: 0.1397 Train_Acc: 95.663 Val_Loss: 0.1016  BEST VAL Loss: 0.1016  Val_Acc: 96.758

Epoch 29: Validation loss decreased (0.101605 --> 0.101158).  Saving model ...
	 Train_Loss: 0.1389 Train_Acc: 95.632 Val_Loss: 0.1012  BEST VAL Loss: 0.1012  Val_Acc: 96.721

Epoch 30: Validation loss decreased (0.101158 --> 0.100739).  Saving model ...
	 Train_Loss: 0.1381 Train_Acc: 95.714 Val_Loss: 0.1007  BEST VAL Loss: 0.1007  Val_Acc: 96.678

Epoch 31: Validation loss decreased (0.100739 --> 0.100284).  Saving model ...
	 Train_Loss: 0.1373 Train_Acc: 95.683 Val_Loss: 0.1003  BEST VAL Loss: 0.1003  Val_Acc: 96.885

Epoch 32: Validation loss decreased (0.100284 --> 0.099882).  Saving model ...
	 Train_Loss: 0.1365 Train_Acc: 95.796 Val_Loss: 0.0999  BEST VAL Loss: 0.0999  Val_Acc: 96.779

Epoch 33: Validation loss decreased (0.099882 --> 0.099631).  Saving model ...
	 Train_Loss: 0.1358 Train_Acc: 95.720 Val_Loss: 0.0996  BEST VAL Loss: 0.0996  Val_Acc: 96.779

Epoch 34: Validation loss decreased (0.099631 --> 0.099361).  Saving model ...
	 Train_Loss: 0.1350 Train_Acc: 95.806 Val_Loss: 0.0994  BEST VAL Loss: 0.0994  Val_Acc: 96.662

Epoch 35: Validation loss decreased (0.099361 --> 0.099038).  Saving model ...
	 Train_Loss: 0.1344 Train_Acc: 95.797 Val_Loss: 0.0990  BEST VAL Loss: 0.0990  Val_Acc: 96.731

Epoch 36: Validation loss decreased (0.099038 --> 0.098713).  Saving model ...
	 Train_Loss: 0.1337 Train_Acc: 95.876 Val_Loss: 0.0987  BEST VAL Loss: 0.0987  Val_Acc: 96.822

Epoch 37: Validation loss decreased (0.098713 --> 0.098372).  Saving model ...
	 Train_Loss: 0.1330 Train_Acc: 95.834 Val_Loss: 0.0984  BEST VAL Loss: 0.0984  Val_Acc: 96.875

Epoch 38: Validation loss decreased (0.098372 --> 0.098172).  Saving model ...
	 Train_Loss: 0.1324 Train_Acc: 95.813 Val_Loss: 0.0982  BEST VAL Loss: 0.0982  Val_Acc: 96.636

Epoch 39: Validation loss decreased (0.098172 --> 0.097869).  Saving model ...
	 Train_Loss: 0.1318 Train_Acc: 95.902 Val_Loss: 0.0979  BEST VAL Loss: 0.0979  Val_Acc: 96.981

Epoch 40: Validation loss decreased (0.097869 --> 0.097758).  Saving model ...
	 Train_Loss: 0.1313 Train_Acc: 95.881 Val_Loss: 0.0978  BEST VAL Loss: 0.0978  Val_Acc: 96.493

Epoch 41: Validation loss decreased (0.097758 --> 0.097586).  Saving model ...
	 Train_Loss: 0.1308 Train_Acc: 95.828 Val_Loss: 0.0976  BEST VAL Loss: 0.0976  Val_Acc: 96.631

Epoch 42: Validation loss decreased (0.097586 --> 0.097342).  Saving model ...
	 Train_Loss: 0.1302 Train_Acc: 95.895 Val_Loss: 0.0973  BEST VAL Loss: 0.0973  Val_Acc: 96.816

Epoch 43: Validation loss decreased (0.097342 --> 0.097120).  Saving model ...
	 Train_Loss: 0.1297 Train_Acc: 95.911 Val_Loss: 0.0971  BEST VAL Loss: 0.0971  Val_Acc: 96.774

Epoch 44: Validation loss decreased (0.097120 --> 0.096909).  Saving model ...
	 Train_Loss: 0.1292 Train_Acc: 95.941 Val_Loss: 0.0969  BEST VAL Loss: 0.0969  Val_Acc: 96.917

Epoch 45: Validation loss decreased (0.096909 --> 0.096671).  Saving model ...
	 Train_Loss: 0.1287 Train_Acc: 95.934 Val_Loss: 0.0967  BEST VAL Loss: 0.0967  Val_Acc: 96.944

Epoch 46: Validation loss decreased (0.096671 --> 0.096401).  Saving model ...
	 Train_Loss: 0.1283 Train_Acc: 95.956 Val_Loss: 0.0964  BEST VAL Loss: 0.0964  Val_Acc: 97.023

Epoch 47: Validation loss decreased (0.096401 --> 0.096246).  Saving model ...
	 Train_Loss: 0.1278 Train_Acc: 95.919 Val_Loss: 0.0962  BEST VAL Loss: 0.0962  Val_Acc: 97.002

Epoch 48: Validation loss decreased (0.096246 --> 0.096050).  Saving model ...
	 Train_Loss: 0.1274 Train_Acc: 95.990 Val_Loss: 0.0960  BEST VAL Loss: 0.0960  Val_Acc: 96.991

Epoch 49: Validation loss decreased (0.096050 --> 0.095879).  Saving model ...
	 Train_Loss: 0.1269 Train_Acc: 95.982 Val_Loss: 0.0959  BEST VAL Loss: 0.0959  Val_Acc: 96.800

Epoch 50: Validation loss decreased (0.095879 --> 0.095737).  Saving model ...
	 Train_Loss: 0.1265 Train_Acc: 96.022 Val_Loss: 0.0957  BEST VAL Loss: 0.0957  Val_Acc: 96.737

Epoch 51: Validation loss decreased (0.095737 --> 0.095593).  Saving model ...
	 Train_Loss: 0.1261 Train_Acc: 96.002 Val_Loss: 0.0956  BEST VAL Loss: 0.0956  Val_Acc: 96.843

Epoch 52: Validation loss decreased (0.095593 --> 0.095376).  Saving model ...
	 Train_Loss: 0.1257 Train_Acc: 96.009 Val_Loss: 0.0954  BEST VAL Loss: 0.0954  Val_Acc: 96.811

Epoch 53: Validation loss decreased (0.095376 --> 0.095210).  Saving model ...
	 Train_Loss: 0.1253 Train_Acc: 95.925 Val_Loss: 0.0952  BEST VAL Loss: 0.0952  Val_Acc: 96.822

Epoch 54: Validation loss decreased (0.095210 --> 0.095013).  Saving model ...
	 Train_Loss: 0.1249 Train_Acc: 96.007 Val_Loss: 0.0950  BEST VAL Loss: 0.0950  Val_Acc: 97.013

Epoch 55: Validation loss decreased (0.095013 --> 0.094842).  Saving model ...
	 Train_Loss: 0.1245 Train_Acc: 96.036 Val_Loss: 0.0948  BEST VAL Loss: 0.0948  Val_Acc: 96.997

Epoch 56: Validation loss decreased (0.094842 --> 0.094718).  Saving model ...
	 Train_Loss: 0.1242 Train_Acc: 96.033 Val_Loss: 0.0947  BEST VAL Loss: 0.0947  Val_Acc: 96.811

Epoch 57: Validation loss decreased (0.094718 --> 0.094485).  Saving model ...
	 Train_Loss: 0.1238 Train_Acc: 96.012 Val_Loss: 0.0945  BEST VAL Loss: 0.0945  Val_Acc: 97.103

Epoch 58: Validation loss decreased (0.094485 --> 0.094326).  Saving model ...
	 Train_Loss: 0.1235 Train_Acc: 96.038 Val_Loss: 0.0943  BEST VAL Loss: 0.0943  Val_Acc: 96.875

Epoch 59: Validation loss decreased (0.094326 --> 0.094157).  Saving model ...
	 Train_Loss: 0.1231 Train_Acc: 96.146 Val_Loss: 0.0942  BEST VAL Loss: 0.0942  Val_Acc: 97.124

Epoch 60: Validation loss decreased (0.094157 --> 0.094023).  Saving model ...
	 Train_Loss: 0.1228 Train_Acc: 96.106 Val_Loss: 0.0940  BEST VAL Loss: 0.0940  Val_Acc: 97.002

Epoch 61: Validation loss decreased (0.094023 --> 0.093841).  Saving model ...
	 Train_Loss: 0.1224 Train_Acc: 96.069 Val_Loss: 0.0938  BEST VAL Loss: 0.0938  Val_Acc: 97.140

Epoch 62: Validation loss decreased (0.093841 --> 0.093721).  Saving model ...
	 Train_Loss: 0.1221 Train_Acc: 96.125 Val_Loss: 0.0937  BEST VAL Loss: 0.0937  Val_Acc: 96.891

Epoch 63: Validation loss decreased (0.093721 --> 0.093610).  Saving model ...
	 Train_Loss: 0.1218 Train_Acc: 96.064 Val_Loss: 0.0936  BEST VAL Loss: 0.0936  Val_Acc: 96.965

Epoch 64: Validation loss decreased (0.093610 --> 0.093493).  Saving model ...
	 Train_Loss: 0.1215 Train_Acc: 96.122 Val_Loss: 0.0935  BEST VAL Loss: 0.0935  Val_Acc: 96.843

Epoch 65: Validation loss decreased (0.093493 --> 0.093392).  Saving model ...
	 Train_Loss: 0.1212 Train_Acc: 96.110 Val_Loss: 0.0934  BEST VAL Loss: 0.0934  Val_Acc: 96.933

Epoch 66: Validation loss decreased (0.093392 --> 0.093289).  Saving model ...
	 Train_Loss: 0.1210 Train_Acc: 96.077 Val_Loss: 0.0933  BEST VAL Loss: 0.0933  Val_Acc: 96.960

Epoch 67: Validation loss decreased (0.093289 --> 0.093163).  Saving model ...
	 Train_Loss: 0.1207 Train_Acc: 96.159 Val_Loss: 0.0932  BEST VAL Loss: 0.0932  Val_Acc: 97.113

Epoch 68: Validation loss decreased (0.093163 --> 0.093106).  Saving model ...
	 Train_Loss: 0.1204 Train_Acc: 96.065 Val_Loss: 0.0931  BEST VAL Loss: 0.0931  Val_Acc: 96.944

Epoch 69: Validation loss decreased (0.093106 --> 0.093034).  Saving model ...
	 Train_Loss: 0.1201 Train_Acc: 96.154 Val_Loss: 0.0930  BEST VAL Loss: 0.0930  Val_Acc: 96.986

Epoch 70: Validation loss decreased (0.093034 --> 0.092941).  Saving model ...
	 Train_Loss: 0.1198 Train_Acc: 96.126 Val_Loss: 0.0929  BEST VAL Loss: 0.0929  Val_Acc: 96.954

Epoch 71: Validation loss decreased (0.092941 --> 0.092831).  Saving model ...
	 Train_Loss: 0.1196 Train_Acc: 96.173 Val_Loss: 0.0928  BEST VAL Loss: 0.0928  Val_Acc: 96.986

Epoch 72: Validation loss decreased (0.092831 --> 0.092749).  Saving model ...
	 Train_Loss: 0.1193 Train_Acc: 96.073 Val_Loss: 0.0927  BEST VAL Loss: 0.0927  Val_Acc: 96.938

Epoch 73: Validation loss decreased (0.092749 --> 0.092707).  Saving model ...
	 Train_Loss: 0.1191 Train_Acc: 96.177 Val_Loss: 0.0927  BEST VAL Loss: 0.0927  Val_Acc: 96.949

Epoch 74: Validation loss decreased (0.092707 --> 0.092646).  Saving model ...
	 Train_Loss: 0.1188 Train_Acc: 96.235 Val_Loss: 0.0926  BEST VAL Loss: 0.0926  Val_Acc: 96.949

Epoch 75: Validation loss decreased (0.092646 --> 0.092625).  Saving model ...
	 Train_Loss: 0.1186 Train_Acc: 96.136 Val_Loss: 0.0926  BEST VAL Loss: 0.0926  Val_Acc: 97.044

Epoch 76: Validation loss decreased (0.092625 --> 0.092565).  Saving model ...
	 Train_Loss: 0.1184 Train_Acc: 96.139 Val_Loss: 0.0926  BEST VAL Loss: 0.0926  Val_Acc: 96.965

Epoch 77: Validation loss decreased (0.092565 --> 0.092508).  Saving model ...
	 Train_Loss: 0.1181 Train_Acc: 96.285 Val_Loss: 0.0925  BEST VAL Loss: 0.0925  Val_Acc: 96.975

Epoch 78: Validation loss decreased (0.092508 --> 0.092434).  Saving model ...
	 Train_Loss: 0.1179 Train_Acc: 96.196 Val_Loss: 0.0924  BEST VAL Loss: 0.0924  Val_Acc: 97.018

Epoch 79: Validation loss decreased (0.092434 --> 0.092361).  Saving model ...
	 Train_Loss: 0.1177 Train_Acc: 96.175 Val_Loss: 0.0924  BEST VAL Loss: 0.0924  Val_Acc: 96.997

Epoch 80: Validation loss decreased (0.092361 --> 0.092297).  Saving model ...
	 Train_Loss: 0.1174 Train_Acc: 96.163 Val_Loss: 0.0923  BEST VAL Loss: 0.0923  Val_Acc: 97.055

Epoch 81: Validation loss decreased (0.092297 --> 0.092239).  Saving model ...
	 Train_Loss: 0.1172 Train_Acc: 96.219 Val_Loss: 0.0922  BEST VAL Loss: 0.0922  Val_Acc: 97.055

Epoch 82: Validation loss decreased (0.092239 --> 0.092215).  Saving model ...
	 Train_Loss: 0.1170 Train_Acc: 96.241 Val_Loss: 0.0922  BEST VAL Loss: 0.0922  Val_Acc: 96.997

Epoch 83: Validation loss decreased (0.092215 --> 0.092174).  Saving model ...
	 Train_Loss: 0.1168 Train_Acc: 96.266 Val_Loss: 0.0922  BEST VAL Loss: 0.0922  Val_Acc: 97.039

Epoch 84: Validation loss decreased (0.092174 --> 0.092144).  Saving model ...
	 Train_Loss: 0.1166 Train_Acc: 96.241 Val_Loss: 0.0921  BEST VAL Loss: 0.0921  Val_Acc: 96.928

Epoch 85: Validation loss decreased (0.092144 --> 0.092045).  Saving model ...
	 Train_Loss: 0.1164 Train_Acc: 96.251 Val_Loss: 0.0920  BEST VAL Loss: 0.0920  Val_Acc: 97.113

Epoch 86: Validation loss decreased (0.092045 --> 0.091965).  Saving model ...
	 Train_Loss: 0.1161 Train_Acc: 96.283 Val_Loss: 0.0920  BEST VAL Loss: 0.0920  Val_Acc: 97.119

Epoch 87: Validation loss decreased (0.091965 --> 0.091903).  Saving model ...
	 Train_Loss: 0.1159 Train_Acc: 96.307 Val_Loss: 0.0919  BEST VAL Loss: 0.0919  Val_Acc: 96.864

Epoch 88: Validation loss decreased (0.091903 --> 0.091838).  Saving model ...
	 Train_Loss: 0.1157 Train_Acc: 96.269 Val_Loss: 0.0918  BEST VAL Loss: 0.0918  Val_Acc: 97.156

Epoch 89: Validation loss decreased (0.091838 --> 0.091806).  Saving model ...
	 Train_Loss: 0.1155 Train_Acc: 96.235 Val_Loss: 0.0918  BEST VAL Loss: 0.0918  Val_Acc: 97.002

Epoch 90: Validation loss decreased (0.091806 --> 0.091805).  Saving model ...
	 Train_Loss: 0.1153 Train_Acc: 96.331 Val_Loss: 0.0918  BEST VAL Loss: 0.0918  Val_Acc: 96.991

Epoch 91: Validation loss decreased (0.091805 --> 0.091744).  Saving model ...
	 Train_Loss: 0.1151 Train_Acc: 96.218 Val_Loss: 0.0917  BEST VAL Loss: 0.0917  Val_Acc: 97.076

Epoch 92: Validation loss decreased (0.091744 --> 0.091708).  Saving model ...
	 Train_Loss: 0.1150 Train_Acc: 96.281 Val_Loss: 0.0917  BEST VAL Loss: 0.0917  Val_Acc: 97.039

Epoch 93: Validation loss decreased (0.091708 --> 0.091685).  Saving model ...
	 Train_Loss: 0.1148 Train_Acc: 96.280 Val_Loss: 0.0917  BEST VAL Loss: 0.0917  Val_Acc: 97.055

Epoch 94: Validation loss decreased (0.091685 --> 0.091630).  Saving model ...
	 Train_Loss: 0.1146 Train_Acc: 96.280 Val_Loss: 0.0916  BEST VAL Loss: 0.0916  Val_Acc: 97.034

Epoch 95: Validation loss decreased (0.091630 --> 0.091596).  Saving model ...
	 Train_Loss: 0.1144 Train_Acc: 96.252 Val_Loss: 0.0916  BEST VAL Loss: 0.0916  Val_Acc: 97.156

Epoch 96: Validation loss decreased (0.091596 --> 0.091543).  Saving model ...
	 Train_Loss: 0.1142 Train_Acc: 96.319 Val_Loss: 0.0915  BEST VAL Loss: 0.0915  Val_Acc: 97.098

Epoch 97: Validation loss decreased (0.091543 --> 0.091496).  Saving model ...
	 Train_Loss: 0.1141 Train_Acc: 96.315 Val_Loss: 0.0915  BEST VAL Loss: 0.0915  Val_Acc: 97.039

Epoch 98: Validation loss decreased (0.091496 --> 0.091439).  Saving model ...
	 Train_Loss: 0.1139 Train_Acc: 96.350 Val_Loss: 0.0914  BEST VAL Loss: 0.0914  Val_Acc: 97.082

Epoch 99: Validation loss decreased (0.091439 --> 0.091400).  Saving model ...
	 Train_Loss: 0.1137 Train_Acc: 96.262 Val_Loss: 0.0914  BEST VAL Loss: 0.0914  Val_Acc: 97.092

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.97      0.97     50422
           1       0.98      0.99      0.99    100339

    accuracy                           0.98    150761
   macro avg       0.98      0.98      0.98    150761
weighted avg       0.98      0.98      0.98    150761

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.97      0.95      0.96      6303
           1       0.97      0.98      0.98     12543

    accuracy                           0.97     18846
   macro avg       0.97      0.96      0.97     18846
weighted avg       0.97      0.97      0.97     18846

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.96      0.95      0.96      6303
           1       0.98      0.98      0.98     12543

    accuracy                           0.97     18846
   macro avg       0.97      0.97      0.97     18846
weighted avg       0.97      0.97      0.97     18846

              precision    recall  f1-score   support

           0       0.96      0.95      0.96      6303
           1       0.98      0.98      0.98     12543

    accuracy                           0.97     18846
   macro avg       0.97      0.97      0.97     18846
weighted avg       0.97      0.97      0.97     18846

LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_1.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.95      0.96     32887
           1       0.96      0.98      0.97     40588

    accuracy                           0.97     73475
   macro avg       0.97      0.96      0.97     73475
weighted avg       0.97      0.97      0.97     73475

              precision    recall  f1-score   support

           0       0.98      0.95      0.96     32887
           1       0.96      0.98      0.97     40588

    accuracy                           0.97     73475
   macro avg       0.97      0.96      0.97     73475
weighted avg       0.97      0.97      0.97     73475

completed
