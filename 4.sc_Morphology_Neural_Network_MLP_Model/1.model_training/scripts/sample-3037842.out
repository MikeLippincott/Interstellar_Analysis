[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '8380b86a'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'b6e15ca0'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'fc949820'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'bee9113e'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_0.010_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_0.010_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (30787, 1276)
Number of total missing values across all columns: 61574
Data Subset Is Off
Wells held out for testing: ['B16' 'L22']
Wells to use for training, validation, and testing ['B17' 'B20' 'B21' 'L18' 'L19' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.650410).  Saving model ...
	 Train_Loss: 0.6826 Train_Acc: 54.345 Val_Loss: 0.6504  BEST VAL Loss: 0.6504  Val_Acc: 61.518

Epoch 1: Validation loss decreased (0.650410 --> 0.636411).  Saving model ...
	 Train_Loss: 0.6661 Train_Acc: 61.386 Val_Loss: 0.6364  BEST VAL Loss: 0.6364  Val_Acc: 64.916

Epoch 2: Validation loss decreased (0.636411 --> 0.625404).  Saving model ...
	 Train_Loss: 0.6544 Train_Acc: 63.588 Val_Loss: 0.6254  BEST VAL Loss: 0.6254  Val_Acc: 65.225

Epoch 3: Validation loss decreased (0.625404 --> 0.616395).  Saving model ...
	 Train_Loss: 0.6435 Train_Acc: 65.574 Val_Loss: 0.6164  BEST VAL Loss: 0.6164  Val_Acc: 67.034

Epoch 4: Validation loss decreased (0.616395 --> 0.608971).  Saving model ...
	 Train_Loss: 0.6347 Train_Acc: 66.347 Val_Loss: 0.6090  BEST VAL Loss: 0.6090  Val_Acc: 67.432

Epoch 5: Validation loss decreased (0.608971 --> 0.603674).  Saving model ...
	 Train_Loss: 0.6278 Train_Acc: 67.169 Val_Loss: 0.6037  BEST VAL Loss: 0.6037  Val_Acc: 66.858

Epoch 6: Validation loss decreased (0.603674 --> 0.598801).  Saving model ...
	 Train_Loss: 0.6214 Train_Acc: 68.272 Val_Loss: 0.5988  BEST VAL Loss: 0.5988  Val_Acc: 68.226

Epoch 7: Validation loss decreased (0.598801 --> 0.595873).  Saving model ...
	 Train_Loss: 0.6159 Train_Acc: 68.377 Val_Loss: 0.5959  BEST VAL Loss: 0.5959  Val_Acc: 67.211

Epoch 8: Validation loss decreased (0.595873 --> 0.593184).  Saving model ...
	 Train_Loss: 0.6114 Train_Acc: 68.901 Val_Loss: 0.5932  BEST VAL Loss: 0.5932  Val_Acc: 68.226

Epoch 9: Validation loss decreased (0.593184 --> 0.590848).  Saving model ...
	 Train_Loss: 0.6070 Train_Acc: 69.834 Val_Loss: 0.5908  BEST VAL Loss: 0.5908  Val_Acc: 69.064

Epoch 10: Validation loss decreased (0.590848 --> 0.588331).  Saving model ...
	 Train_Loss: 0.6030 Train_Acc: 69.966 Val_Loss: 0.5883  BEST VAL Loss: 0.5883  Val_Acc: 69.726

Epoch 11: Validation loss decreased (0.588331 --> 0.586002).  Saving model ...
	 Train_Loss: 0.5988 Train_Acc: 70.303 Val_Loss: 0.5860  BEST VAL Loss: 0.5860  Val_Acc: 68.623

Epoch 12: Validation loss decreased (0.586002 --> 0.583765).  Saving model ...
	 Train_Loss: 0.5942 Train_Acc: 71.296 Val_Loss: 0.5838  BEST VAL Loss: 0.5838  Val_Acc: 70.124

Epoch 13: Validation loss decreased (0.583765 --> 0.582016).  Saving model ...
	 Train_Loss: 0.5902 Train_Acc: 71.605 Val_Loss: 0.5820  BEST VAL Loss: 0.5820  Val_Acc: 70.653

Epoch 14: Validation loss decreased (0.582016 --> 0.580155).  Saving model ...
	 Train_Loss: 0.5864 Train_Acc: 71.831 Val_Loss: 0.5802  BEST VAL Loss: 0.5802  Val_Acc: 70.786

Epoch 15: Validation loss decreased (0.580155 --> 0.578336).  Saving model ...
	 Train_Loss: 0.5829 Train_Acc: 72.212 Val_Loss: 0.5783  BEST VAL Loss: 0.5783  Val_Acc: 70.079

Epoch 16: Validation loss decreased (0.578336 --> 0.576415).  Saving model ...
	 Train_Loss: 0.5791 Train_Acc: 72.565 Val_Loss: 0.5764  BEST VAL Loss: 0.5764  Val_Acc: 69.594

Epoch 17: Validation loss decreased (0.576415 --> 0.574218).  Saving model ...
	 Train_Loss: 0.5756 Train_Acc: 72.847 Val_Loss: 0.5742  BEST VAL Loss: 0.5742  Val_Acc: 69.815

Epoch 18: Validation loss decreased (0.574218 --> 0.572340).  Saving model ...
	 Train_Loss: 0.5723 Train_Acc: 73.277 Val_Loss: 0.5723  BEST VAL Loss: 0.5723  Val_Acc: 69.947

Epoch 19: Validation loss decreased (0.572340 --> 0.570825).  Saving model ...
	 Train_Loss: 0.5690 Train_Acc: 73.432 Val_Loss: 0.5708  BEST VAL Loss: 0.5708  Val_Acc: 70.300

Epoch 20: Validation loss decreased (0.570825 --> 0.569212).  Saving model ...
	 Train_Loss: 0.5661 Train_Acc: 73.641 Val_Loss: 0.5692  BEST VAL Loss: 0.5692  Val_Acc: 69.991

Epoch 21: Validation loss decreased (0.569212 --> 0.567684).  Saving model ...
	 Train_Loss: 0.5631 Train_Acc: 74.033 Val_Loss: 0.5677  BEST VAL Loss: 0.5677  Val_Acc: 70.521

Epoch 22: Validation loss decreased (0.567684 --> 0.566150).  Saving model ...
	 Train_Loss: 0.5603 Train_Acc: 74.022 Val_Loss: 0.5662  BEST VAL Loss: 0.5662  Val_Acc: 69.638

Epoch 23: Validation loss decreased (0.566150 --> 0.564691).  Saving model ...
	 Train_Loss: 0.5577 Train_Acc: 74.083 Val_Loss: 0.5647  BEST VAL Loss: 0.5647  Val_Acc: 71.536

Epoch 24: Validation loss decreased (0.564691 --> 0.563303).  Saving model ...
	 Train_Loss: 0.5551 Train_Acc: 74.182 Val_Loss: 0.5633  BEST VAL Loss: 0.5633  Val_Acc: 71.227

Epoch 25: Validation loss decreased (0.563303 --> 0.562405).  Saving model ...
	 Train_Loss: 0.5524 Train_Acc: 75.087 Val_Loss: 0.5624  BEST VAL Loss: 0.5624  Val_Acc: 70.697

Epoch 26: Validation loss decreased (0.562405 --> 0.561341).  Saving model ...
	 Train_Loss: 0.5501 Train_Acc: 74.441 Val_Loss: 0.5613  BEST VAL Loss: 0.5613  Val_Acc: 70.609

Epoch 27: Validation loss decreased (0.561341 --> 0.560625).  Saving model ...
	 Train_Loss: 0.5480 Train_Acc: 74.701 Val_Loss: 0.5606  BEST VAL Loss: 0.5606  Val_Acc: 71.094

Epoch 28: Validation loss decreased (0.560625 --> 0.559885).  Saving model ...
	 Train_Loss: 0.5456 Train_Acc: 74.899 Val_Loss: 0.5599  BEST VAL Loss: 0.5599  Val_Acc: 70.962

Epoch 29: Validation loss decreased (0.559885 --> 0.559166).  Saving model ...
	 Train_Loss: 0.5434 Train_Acc: 75.473 Val_Loss: 0.5592  BEST VAL Loss: 0.5592  Val_Acc: 70.477

Epoch 30: Validation loss decreased (0.559166 --> 0.558437).  Saving model ...
	 Train_Loss: 0.5412 Train_Acc: 75.346 Val_Loss: 0.5584  BEST VAL Loss: 0.5584  Val_Acc: 71.227

Epoch 31: Validation loss decreased (0.558437 --> 0.557598).  Saving model ...
	 Train_Loss: 0.5392 Train_Acc: 75.550 Val_Loss: 0.5576  BEST VAL Loss: 0.5576  Val_Acc: 71.006

Epoch 32: Validation loss decreased (0.557598 --> 0.557010).  Saving model ...
	 Train_Loss: 0.5371 Train_Acc: 75.732 Val_Loss: 0.5570  BEST VAL Loss: 0.5570  Val_Acc: 71.359

Epoch 33: Validation loss decreased (0.557010 --> 0.556459).  Saving model ...
	 Train_Loss: 0.5352 Train_Acc: 75.937 Val_Loss: 0.5565  BEST VAL Loss: 0.5565  Val_Acc: 71.227

Epoch 34: Validation loss decreased (0.556459 --> 0.555948).  Saving model ...
	 Train_Loss: 0.5332 Train_Acc: 75.732 Val_Loss: 0.5559  BEST VAL Loss: 0.5559  Val_Acc: 71.756

Epoch 35: Validation loss decreased (0.555948 --> 0.555795).  Saving model ...
	 Train_Loss: 0.5314 Train_Acc: 76.345 Val_Loss: 0.5558  BEST VAL Loss: 0.5558  Val_Acc: 71.801

Epoch 36: Validation loss decreased (0.555795 --> 0.555261).  Saving model ...
	 Train_Loss: 0.5295 Train_Acc: 76.312 Val_Loss: 0.5553  BEST VAL Loss: 0.5553  Val_Acc: 71.094

Epoch 37: Validation loss decreased (0.555261 --> 0.554795).  Saving model ...
	 Train_Loss: 0.5277 Train_Acc: 76.439 Val_Loss: 0.5548  BEST VAL Loss: 0.5548  Val_Acc: 70.653

Epoch 38: Validation loss decreased (0.554795 --> 0.554474).  Saving model ...
	 Train_Loss: 0.5259 Train_Acc: 76.157 Val_Loss: 0.5545  BEST VAL Loss: 0.5545  Val_Acc: 70.256

Epoch 39: Validation loss decreased (0.554474 --> 0.554284).  Saving model ...
	 Train_Loss: 0.5244 Train_Acc: 76.350 Val_Loss: 0.5543  BEST VAL Loss: 0.5543  Val_Acc: 70.697

Epoch 40: Validation loss decreased (0.554284 --> 0.553892).  Saving model ...
	 Train_Loss: 0.5227 Train_Acc: 76.533 Val_Loss: 0.5539  BEST VAL Loss: 0.5539  Val_Acc: 71.801

Epoch 41: Validation loss decreased (0.553892 --> 0.553805).  Saving model ...
	 Train_Loss: 0.5210 Train_Acc: 76.786 Val_Loss: 0.5538  BEST VAL Loss: 0.5538  Val_Acc: 70.786

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.5194 Train_Acc: 76.533 Val_Loss: 0.5539  BEST VAL Loss: 0.5538  Val_Acc: 70.962

Epoch 43: Validation loss decreased (0.553805 --> 0.553580).  Saving model ...
	 Train_Loss: 0.5180 Train_Acc: 76.036 Val_Loss: 0.5536  BEST VAL Loss: 0.5536  Val_Acc: 70.918

Epoch 44: Validation loss decreased (0.553580 --> 0.553374).  Saving model ...
	 Train_Loss: 0.5166 Train_Acc: 76.842 Val_Loss: 0.5534  BEST VAL Loss: 0.5534  Val_Acc: 71.139

Epoch 45: Validation loss decreased (0.553374 --> 0.552981).  Saving model ...
	 Train_Loss: 0.5152 Train_Acc: 77.134 Val_Loss: 0.5530  BEST VAL Loss: 0.5530  Val_Acc: 71.006

Epoch 46: Validation loss decreased (0.552981 --> 0.552846).  Saving model ...
	 Train_Loss: 0.5138 Train_Acc: 76.715 Val_Loss: 0.5528  BEST VAL Loss: 0.5528  Val_Acc: 70.830

Epoch 47: Validation loss decreased (0.552846 --> 0.552721).  Saving model ...
	 Train_Loss: 0.5125 Train_Acc: 77.002 Val_Loss: 0.5527  BEST VAL Loss: 0.5527  Val_Acc: 71.580

Epoch 48: Validation loss decreased (0.552721 --> 0.552640).  Saving model ...
	 Train_Loss: 0.5111 Train_Acc: 77.443 Val_Loss: 0.5526  BEST VAL Loss: 0.5526  Val_Acc: 70.565

Epoch 49: Validation loss decreased (0.552640 --> 0.552263).  Saving model ...
	 Train_Loss: 0.5099 Train_Acc: 77.217 Val_Loss: 0.5523  BEST VAL Loss: 0.5523  Val_Acc: 70.300

Epoch 50: Validation loss decreased (0.552263 --> 0.552067).  Saving model ...
	 Train_Loss: 0.5085 Train_Acc: 77.482 Val_Loss: 0.5521  BEST VAL Loss: 0.5521  Val_Acc: 70.874

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.5072 Train_Acc: 77.482 Val_Loss: 0.5521  BEST VAL Loss: 0.5521  Val_Acc: 70.168

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.5059 Train_Acc: 77.564 Val_Loss: 0.5522  BEST VAL Loss: 0.5521  Val_Acc: 69.815

Epoch 53: Validation loss decreased (0.552067 --> 0.552063).  Saving model ...
	 Train_Loss: 0.5047 Train_Acc: 77.548 Val_Loss: 0.5521  BEST VAL Loss: 0.5521  Val_Acc: 71.271

Epoch 54: Validation loss did not decrease
	 Train_Loss: 0.5033 Train_Acc: 78.067 Val_Loss: 0.5522  BEST VAL Loss: 0.5521  Val_Acc: 70.344

Epoch 55: Validation loss did not decrease
	 Train_Loss: 0.5021 Train_Acc: 77.658 Val_Loss: 0.5521  BEST VAL Loss: 0.5521  Val_Acc: 71.139

Epoch 56: Validation loss decreased (0.552063 --> 0.551963).  Saving model ...
	 Train_Loss: 0.5008 Train_Acc: 78.381 Val_Loss: 0.5520  BEST VAL Loss: 0.5520  Val_Acc: 70.697

Epoch 57: Validation loss did not decrease
	 Train_Loss: 0.4995 Train_Acc: 78.574 Val_Loss: 0.5520  BEST VAL Loss: 0.5520  Val_Acc: 70.168

Epoch 58: Validation loss did not decrease
	 Train_Loss: 0.4984 Train_Acc: 78.122 Val_Loss: 0.5521  BEST VAL Loss: 0.5520  Val_Acc: 70.079

Epoch 59: Validation loss did not decrease
	 Train_Loss: 0.4973 Train_Acc: 77.901 Val_Loss: 0.5523  BEST VAL Loss: 0.5520  Val_Acc: 71.006

Epoch 60: Validation loss did not decrease
	 Train_Loss: 0.4962 Train_Acc: 78.210 Val_Loss: 0.5525  BEST VAL Loss: 0.5520  Val_Acc: 69.373

Epoch 61: Validation loss did not decrease
	 Train_Loss: 0.4952 Train_Acc: 77.818 Val_Loss: 0.5528  BEST VAL Loss: 0.5520  Val_Acc: 70.653

Epoch 62: Validation loss did not decrease
	 Train_Loss: 0.4941 Train_Acc: 78.227 Val_Loss: 0.5532  BEST VAL Loss: 0.5520  Val_Acc: 70.697

Epoch 63: Validation loss did not decrease
	 Train_Loss: 0.4930 Train_Acc: 78.122 Val_Loss: 0.5536  BEST VAL Loss: 0.5520  Val_Acc: 69.550

Epoch 64: Validation loss did not decrease
	 Train_Loss: 0.4921 Train_Acc: 78.210 Val_Loss: 0.5538  BEST VAL Loss: 0.5520  Val_Acc: 70.741

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.4910 Train_Acc: 78.431 Val_Loss: 0.5539  BEST VAL Loss: 0.5520  Val_Acc: 69.771

Epoch 66: Validation loss did not decrease
	 Train_Loss: 0.4899 Train_Acc: 78.508 Val_Loss: 0.5541  BEST VAL Loss: 0.5520  Val_Acc: 70.212

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.4889 Train_Acc: 78.381 Val_Loss: 0.5541  BEST VAL Loss: 0.5520  Val_Acc: 71.139

Epoch 68: Validation loss did not decrease
	 Train_Loss: 0.4880 Train_Acc: 78.359 Val_Loss: 0.5543  BEST VAL Loss: 0.5520  Val_Acc: 71.094

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.4870 Train_Acc: 78.458 Val_Loss: 0.5543  BEST VAL Loss: 0.5520  Val_Acc: 70.653

Epoch 70: Validation loss did not decrease
	 Train_Loss: 0.4859 Train_Acc: 78.607 Val_Loss: 0.5544  BEST VAL Loss: 0.5520  Val_Acc: 70.124

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.4850 Train_Acc: 78.624 Val_Loss: 0.5546  BEST VAL Loss: 0.5520  Val_Acc: 71.580

Epoch 72: Validation loss did not decrease
Early stopped at epoch : 72
LPS_0.010_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.91      0.76      0.83      8634
           1       0.81      0.93      0.87      9489

    accuracy                           0.85     18123
   macro avg       0.86      0.84      0.85     18123
weighted avg       0.86      0.85      0.85     18123

LPS_0.010_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.75      0.59      0.66      1080
           1       0.68      0.82      0.75      1186

    accuracy                           0.71      2266
   macro avg       0.71      0.70      0.70      2266
weighted avg       0.71      0.71      0.70      2266

LPS_0.010_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.72      0.62      0.67      1079
           1       0.69      0.78      0.73      1187

    accuracy                           0.70      2266
   macro avg       0.71      0.70      0.70      2266
weighted avg       0.71      0.70      0.70      2266

              precision    recall  f1-score   support

           0       0.72      0.62      0.67      1079
           1       0.69      0.78      0.73      1187

    accuracy                           0.70      2266
   macro avg       0.71      0.70      0.70      2266
weighted avg       0.71      0.70      0.70      2266

LPS_0.010_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_0.010_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.70      0.45      0.55      4135
           1       0.59      0.80      0.68      3997

    accuracy                           0.62      8132
   macro avg       0.64      0.63      0.61      8132
weighted avg       0.64      0.62      0.61      8132

              precision    recall  f1-score   support

           0       0.70      0.45      0.55      4135
           1       0.59      0.80      0.68      3997

    accuracy                           0.62      8132
   macro avg       0.64      0.63      0.61      8132
weighted avg       0.64      0.62      0.61      8132

completed
