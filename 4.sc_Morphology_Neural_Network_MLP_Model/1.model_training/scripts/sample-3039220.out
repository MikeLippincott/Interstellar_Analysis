[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '061fa1e1'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'e1c0fc2e'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '3adb8e7d'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '6dfebe3e'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: H2O2_100.000_DMSO_0.025 treatment_name: Thapsigargin_10.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: Thapsigargin_10.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (407520, 1270)
Number of total missing values across all columns: 815040
Data Subset Is Off
Wells held out for testing: ['I10' 'L06']
Wells to use for training, validation, and testing ['E06' 'E07' 'H04' 'I04' 'H05' 'I05' 'H10' 'H11' 'I11' 'L07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.240869).  Saving model ...
	 Train_Loss: 0.4082 Train_Acc: 79.714 Val_Loss: 0.2409  BEST VAL Loss: 0.2409  Val_Acc: 89.154

Epoch 1: Validation loss decreased (0.240869 --> 0.222345).  Saving model ...
	 Train_Loss: 0.3528 Train_Acc: 85.428 Val_Loss: 0.2223  BEST VAL Loss: 0.2223  Val_Acc: 91.121

Epoch 2: Validation loss decreased (0.222345 --> 0.214109).  Saving model ...
	 Train_Loss: 0.3281 Train_Acc: 86.490 Val_Loss: 0.2141  BEST VAL Loss: 0.2141  Val_Acc: 91.591

Epoch 3: Validation loss decreased (0.214109 --> 0.207685).  Saving model ...
	 Train_Loss: 0.3130 Train_Acc: 87.230 Val_Loss: 0.2077  BEST VAL Loss: 0.2077  Val_Acc: 91.911

Epoch 4: Validation loss decreased (0.207685 --> 0.203027).  Saving model ...
	 Train_Loss: 0.3025 Train_Acc: 87.609 Val_Loss: 0.2030  BEST VAL Loss: 0.2030  Val_Acc: 92.114

Epoch 5: Validation loss decreased (0.203027 --> 0.199269).  Saving model ...
	 Train_Loss: 0.2947 Train_Acc: 87.850 Val_Loss: 0.1993  BEST VAL Loss: 0.1993  Val_Acc: 92.468

Epoch 6: Validation loss decreased (0.199269 --> 0.196172).  Saving model ...
	 Train_Loss: 0.2885 Train_Acc: 88.174 Val_Loss: 0.1962  BEST VAL Loss: 0.1962  Val_Acc: 92.519

Epoch 7: Validation loss decreased (0.196172 --> 0.193494).  Saving model ...
	 Train_Loss: 0.2834 Train_Acc: 88.268 Val_Loss: 0.1935  BEST VAL Loss: 0.1935  Val_Acc: 92.788

Epoch 8: Validation loss decreased (0.193494 --> 0.191967).  Saving model ...
	 Train_Loss: 0.2792 Train_Acc: 88.396 Val_Loss: 0.1920  BEST VAL Loss: 0.1920  Val_Acc: 92.492

Epoch 9: Validation loss decreased (0.191967 --> 0.190143).  Saving model ...
	 Train_Loss: 0.2757 Train_Acc: 88.467 Val_Loss: 0.1901  BEST VAL Loss: 0.1901  Val_Acc: 92.854

Epoch 10: Validation loss decreased (0.190143 --> 0.188457).  Saving model ...
	 Train_Loss: 0.2725 Train_Acc: 88.611 Val_Loss: 0.1885  BEST VAL Loss: 0.1885  Val_Acc: 92.677

Epoch 11: Validation loss decreased (0.188457 --> 0.187096).  Saving model ...
	 Train_Loss: 0.2697 Train_Acc: 88.708 Val_Loss: 0.1871  BEST VAL Loss: 0.1871  Val_Acc: 92.926

Epoch 12: Validation loss decreased (0.187096 --> 0.185740).  Saving model ...
	 Train_Loss: 0.2672 Train_Acc: 88.820 Val_Loss: 0.1857  BEST VAL Loss: 0.1857  Val_Acc: 92.899

Epoch 13: Validation loss decreased (0.185740 --> 0.184808).  Saving model ...
	 Train_Loss: 0.2651 Train_Acc: 88.776 Val_Loss: 0.1848  BEST VAL Loss: 0.1848  Val_Acc: 92.818

Epoch 14: Validation loss decreased (0.184808 --> 0.183572).  Saving model ...
	 Train_Loss: 0.2632 Train_Acc: 88.889 Val_Loss: 0.1836  BEST VAL Loss: 0.1836  Val_Acc: 93.093

Epoch 15: Validation loss decreased (0.183572 --> 0.182402).  Saving model ...
	 Train_Loss: 0.2613 Train_Acc: 89.038 Val_Loss: 0.1824  BEST VAL Loss: 0.1824  Val_Acc: 93.031

Epoch 16: Validation loss decreased (0.182402 --> 0.181296).  Saving model ...
	 Train_Loss: 0.2597 Train_Acc: 89.029 Val_Loss: 0.1813  BEST VAL Loss: 0.1813  Val_Acc: 93.144

Epoch 17: Validation loss decreased (0.181296 --> 0.180310).  Saving model ...
	 Train_Loss: 0.2582 Train_Acc: 89.218 Val_Loss: 0.1803  BEST VAL Loss: 0.1803  Val_Acc: 93.213

Epoch 18: Validation loss decreased (0.180310 --> 0.179491).  Saving model ...
	 Train_Loss: 0.2568 Train_Acc: 89.161 Val_Loss: 0.1795  BEST VAL Loss: 0.1795  Val_Acc: 93.285

Epoch 19: Validation loss decreased (0.179491 --> 0.178866).  Saving model ...
	 Train_Loss: 0.2554 Train_Acc: 89.203 Val_Loss: 0.1789  BEST VAL Loss: 0.1789  Val_Acc: 93.022

Epoch 20: Validation loss decreased (0.178866 --> 0.178052).  Saving model ...
	 Train_Loss: 0.2542 Train_Acc: 89.145 Val_Loss: 0.1781  BEST VAL Loss: 0.1781  Val_Acc: 93.444

Epoch 21: Validation loss decreased (0.178052 --> 0.177470).  Saving model ...
	 Train_Loss: 0.2531 Train_Acc: 89.179 Val_Loss: 0.1775  BEST VAL Loss: 0.1775  Val_Acc: 93.288

Epoch 22: Validation loss decreased (0.177470 --> 0.176763).  Saving model ...
	 Train_Loss: 0.2520 Train_Acc: 89.359 Val_Loss: 0.1768  BEST VAL Loss: 0.1768  Val_Acc: 93.315

Epoch 23: Validation loss decreased (0.176763 --> 0.176213).  Saving model ...
	 Train_Loss: 0.2509 Train_Acc: 89.424 Val_Loss: 0.1762  BEST VAL Loss: 0.1762  Val_Acc: 93.246

Epoch 24: Validation loss decreased (0.176213 --> 0.175657).  Saving model ...
	 Train_Loss: 0.2500 Train_Acc: 89.377 Val_Loss: 0.1757  BEST VAL Loss: 0.1757  Val_Acc: 93.270

Epoch 25: Validation loss decreased (0.175657 --> 0.175060).  Saving model ...
	 Train_Loss: 0.2491 Train_Acc: 89.389 Val_Loss: 0.1751  BEST VAL Loss: 0.1751  Val_Acc: 93.629

Epoch 26: Validation loss decreased (0.175060 --> 0.174471).  Saving model ...
	 Train_Loss: 0.2482 Train_Acc: 89.501 Val_Loss: 0.1745  BEST VAL Loss: 0.1745  Val_Acc: 93.626

Epoch 27: Validation loss decreased (0.174471 --> 0.173842).  Saving model ...
	 Train_Loss: 0.2474 Train_Acc: 89.530 Val_Loss: 0.1738  BEST VAL Loss: 0.1738  Val_Acc: 93.650

Epoch 28: Validation loss decreased (0.173842 --> 0.173427).  Saving model ...
	 Train_Loss: 0.2466 Train_Acc: 89.523 Val_Loss: 0.1734  BEST VAL Loss: 0.1734  Val_Acc: 93.357

Epoch 29: Validation loss decreased (0.173427 --> 0.173084).  Saving model ...
	 Train_Loss: 0.2459 Train_Acc: 89.516 Val_Loss: 0.1731  BEST VAL Loss: 0.1731  Val_Acc: 93.300

Epoch 30: Validation loss decreased (0.173084 --> 0.172772).  Saving model ...
	 Train_Loss: 0.2452 Train_Acc: 89.614 Val_Loss: 0.1728  BEST VAL Loss: 0.1728  Val_Acc: 93.330

Epoch 31: Validation loss decreased (0.172772 --> 0.172353).  Saving model ...
	 Train_Loss: 0.2445 Train_Acc: 89.587 Val_Loss: 0.1724  BEST VAL Loss: 0.1724  Val_Acc: 93.465

Epoch 32: Validation loss decreased (0.172353 --> 0.171939).  Saving model ...
	 Train_Loss: 0.2438 Train_Acc: 89.637 Val_Loss: 0.1719  BEST VAL Loss: 0.1719  Val_Acc: 93.545

Epoch 33: Validation loss decreased (0.171939 --> 0.171447).  Saving model ...
	 Train_Loss: 0.2432 Train_Acc: 89.681 Val_Loss: 0.1714  BEST VAL Loss: 0.1714  Val_Acc: 93.698

Epoch 34: Validation loss decreased (0.171447 --> 0.170975).  Saving model ...
	 Train_Loss: 0.2425 Train_Acc: 89.652 Val_Loss: 0.1710  BEST VAL Loss: 0.1710  Val_Acc: 93.560

Epoch 35: Validation loss decreased (0.170975 --> 0.170676).  Saving model ...
	 Train_Loss: 0.2419 Train_Acc: 89.689 Val_Loss: 0.1707  BEST VAL Loss: 0.1707  Val_Acc: 93.551

Epoch 36: Validation loss decreased (0.170676 --> 0.170269).  Saving model ...
	 Train_Loss: 0.2414 Train_Acc: 89.653 Val_Loss: 0.1703  BEST VAL Loss: 0.1703  Val_Acc: 93.698

Epoch 37: Validation loss decreased (0.170269 --> 0.169926).  Saving model ...
	 Train_Loss: 0.2408 Train_Acc: 89.790 Val_Loss: 0.1699  BEST VAL Loss: 0.1699  Val_Acc: 93.540

Epoch 38: Validation loss decreased (0.169926 --> 0.169509).  Saving model ...
	 Train_Loss: 0.2402 Train_Acc: 89.744 Val_Loss: 0.1695  BEST VAL Loss: 0.1695  Val_Acc: 93.659

Epoch 39: Validation loss decreased (0.169509 --> 0.169244).  Saving model ...
	 Train_Loss: 0.2397 Train_Acc: 89.680 Val_Loss: 0.1692  BEST VAL Loss: 0.1692  Val_Acc: 93.563

Epoch 40: Validation loss decreased (0.169244 --> 0.168944).  Saving model ...
	 Train_Loss: 0.2392 Train_Acc: 89.688 Val_Loss: 0.1689  BEST VAL Loss: 0.1689  Val_Acc: 93.617

Epoch 41: Validation loss decreased (0.168944 --> 0.168681).  Saving model ...
	 Train_Loss: 0.2388 Train_Acc: 89.675 Val_Loss: 0.1687  BEST VAL Loss: 0.1687  Val_Acc: 93.650

Epoch 42: Validation loss decreased (0.168681 --> 0.168332).  Saving model ...
	 Train_Loss: 0.2383 Train_Acc: 89.821 Val_Loss: 0.1683  BEST VAL Loss: 0.1683  Val_Acc: 93.626

Epoch 43: Validation loss decreased (0.168332 --> 0.168012).  Saving model ...
	 Train_Loss: 0.2379 Train_Acc: 89.857 Val_Loss: 0.1680  BEST VAL Loss: 0.1680  Val_Acc: 93.644

Epoch 44: Validation loss decreased (0.168012 --> 0.167694).  Saving model ...
	 Train_Loss: 0.2374 Train_Acc: 89.810 Val_Loss: 0.1677  BEST VAL Loss: 0.1677  Val_Acc: 93.653

Epoch 45: Validation loss decreased (0.167694 --> 0.167395).  Saving model ...
	 Train_Loss: 0.2370 Train_Acc: 89.853 Val_Loss: 0.1674  BEST VAL Loss: 0.1674  Val_Acc: 93.725

Epoch 46: Validation loss decreased (0.167395 --> 0.167107).  Saving model ...
	 Train_Loss: 0.2365 Train_Acc: 89.906 Val_Loss: 0.1671  BEST VAL Loss: 0.1671  Val_Acc: 93.629

Epoch 47: Validation loss decreased (0.167107 --> 0.166856).  Saving model ...
	 Train_Loss: 0.2361 Train_Acc: 89.898 Val_Loss: 0.1669  BEST VAL Loss: 0.1669  Val_Acc: 93.767

Epoch 48: Validation loss decreased (0.166856 --> 0.166625).  Saving model ...
	 Train_Loss: 0.2357 Train_Acc: 89.887 Val_Loss: 0.1666  BEST VAL Loss: 0.1666  Val_Acc: 93.659

Epoch 49: Validation loss decreased (0.166625 --> 0.166291).  Saving model ...
	 Train_Loss: 0.2354 Train_Acc: 89.867 Val_Loss: 0.1663  BEST VAL Loss: 0.1663  Val_Acc: 93.749

Epoch 50: Validation loss decreased (0.166291 --> 0.165979).  Saving model ...
	 Train_Loss: 0.2350 Train_Acc: 89.914 Val_Loss: 0.1660  BEST VAL Loss: 0.1660  Val_Acc: 93.884

Epoch 51: Validation loss decreased (0.165979 --> 0.165710).  Saving model ...
	 Train_Loss: 0.2346 Train_Acc: 89.819 Val_Loss: 0.1657  BEST VAL Loss: 0.1657  Val_Acc: 93.803

Epoch 52: Validation loss decreased (0.165710 --> 0.165411).  Saving model ...
	 Train_Loss: 0.2343 Train_Acc: 89.893 Val_Loss: 0.1654  BEST VAL Loss: 0.1654  Val_Acc: 93.842

Epoch 53: Validation loss decreased (0.165411 --> 0.165194).  Saving model ...
	 Train_Loss: 0.2339 Train_Acc: 89.968 Val_Loss: 0.1652  BEST VAL Loss: 0.1652  Val_Acc: 93.848

Epoch 54: Validation loss decreased (0.165194 --> 0.164969).  Saving model ...
	 Train_Loss: 0.2336 Train_Acc: 89.945 Val_Loss: 0.1650  BEST VAL Loss: 0.1650  Val_Acc: 93.650

Epoch 55: Validation loss decreased (0.164969 --> 0.164737).  Saving model ...
	 Train_Loss: 0.2333 Train_Acc: 89.978 Val_Loss: 0.1647  BEST VAL Loss: 0.1647  Val_Acc: 93.872

Epoch 56: Validation loss decreased (0.164737 --> 0.164543).  Saving model ...
	 Train_Loss: 0.2329 Train_Acc: 89.964 Val_Loss: 0.1645  BEST VAL Loss: 0.1645  Val_Acc: 93.680

Epoch 57: Validation loss decreased (0.164543 --> 0.164299).  Saving model ...
	 Train_Loss: 0.2326 Train_Acc: 89.959 Val_Loss: 0.1643  BEST VAL Loss: 0.1643  Val_Acc: 93.785

Epoch 58: Validation loss decreased (0.164299 --> 0.164055).  Saving model ...
	 Train_Loss: 0.2323 Train_Acc: 89.972 Val_Loss: 0.1641  BEST VAL Loss: 0.1641  Val_Acc: 93.782

Epoch 59: Validation loss decreased (0.164055 --> 0.163878).  Saving model ...
	 Train_Loss: 0.2320 Train_Acc: 89.950 Val_Loss: 0.1639  BEST VAL Loss: 0.1639  Val_Acc: 93.863

Epoch 60: Validation loss decreased (0.163878 --> 0.163639).  Saving model ...
	 Train_Loss: 0.2317 Train_Acc: 90.024 Val_Loss: 0.1636  BEST VAL Loss: 0.1636  Val_Acc: 93.839

Epoch 61: Validation loss decreased (0.163639 --> 0.163411).  Saving model ...
	 Train_Loss: 0.2315 Train_Acc: 89.974 Val_Loss: 0.1634  BEST VAL Loss: 0.1634  Val_Acc: 93.785

Epoch 62: Validation loss decreased (0.163411 --> 0.163240).  Saving model ...
	 Train_Loss: 0.2312 Train_Acc: 90.070 Val_Loss: 0.1632  BEST VAL Loss: 0.1632  Val_Acc: 93.665

Epoch 63: Validation loss decreased (0.163240 --> 0.163053).  Saving model ...
	 Train_Loss: 0.2309 Train_Acc: 90.056 Val_Loss: 0.1631  BEST VAL Loss: 0.1631  Val_Acc: 93.869

Epoch 64: Validation loss decreased (0.163053 --> 0.162895).  Saving model ...
	 Train_Loss: 0.2306 Train_Acc: 90.106 Val_Loss: 0.1629  BEST VAL Loss: 0.1629  Val_Acc: 93.839

Epoch 65: Validation loss decreased (0.162895 --> 0.162686).  Saving model ...
	 Train_Loss: 0.2303 Train_Acc: 90.051 Val_Loss: 0.1627  BEST VAL Loss: 0.1627  Val_Acc: 93.896

Epoch 66: Validation loss decreased (0.162686 --> 0.162502).  Saving model ...
	 Train_Loss: 0.2301 Train_Acc: 90.049 Val_Loss: 0.1625  BEST VAL Loss: 0.1625  Val_Acc: 93.932

Epoch 67: Validation loss decreased (0.162502 --> 0.162300).  Saving model ...
	 Train_Loss: 0.2298 Train_Acc: 90.078 Val_Loss: 0.1623  BEST VAL Loss: 0.1623  Val_Acc: 93.911

Epoch 68: Validation loss decreased (0.162300 --> 0.162136).  Saving model ...
	 Train_Loss: 0.2296 Train_Acc: 90.059 Val_Loss: 0.1621  BEST VAL Loss: 0.1621  Val_Acc: 93.863

Epoch 69: Validation loss decreased (0.162136 --> 0.161982).  Saving model ...
	 Train_Loss: 0.2293 Train_Acc: 90.055 Val_Loss: 0.1620  BEST VAL Loss: 0.1620  Val_Acc: 93.656

Epoch 70: Validation loss decreased (0.161982 --> 0.161801).  Saving model ...
	 Train_Loss: 0.2291 Train_Acc: 90.019 Val_Loss: 0.1618  BEST VAL Loss: 0.1618  Val_Acc: 93.911

Epoch 71: Validation loss decreased (0.161801 --> 0.161625).  Saving model ...
	 Train_Loss: 0.2288 Train_Acc: 90.056 Val_Loss: 0.1616  BEST VAL Loss: 0.1616  Val_Acc: 93.797

Epoch 72: Validation loss decreased (0.161625 --> 0.161508).  Saving model ...
	 Train_Loss: 0.2286 Train_Acc: 90.081 Val_Loss: 0.1615  BEST VAL Loss: 0.1615  Val_Acc: 93.929

Epoch 73: Validation loss decreased (0.161508 --> 0.161389).  Saving model ...
	 Train_Loss: 0.2284 Train_Acc: 90.195 Val_Loss: 0.1614  BEST VAL Loss: 0.1614  Val_Acc: 93.899

Epoch 74: Validation loss decreased (0.161389 --> 0.161237).  Saving model ...
	 Train_Loss: 0.2281 Train_Acc: 90.218 Val_Loss: 0.1612  BEST VAL Loss: 0.1612  Val_Acc: 93.827

Epoch 75: Validation loss decreased (0.161237 --> 0.161116).  Saving model ...
	 Train_Loss: 0.2279 Train_Acc: 90.116 Val_Loss: 0.1611  BEST VAL Loss: 0.1611  Val_Acc: 94.024

Epoch 76: Validation loss decreased (0.161116 --> 0.160956).  Saving model ...
	 Train_Loss: 0.2277 Train_Acc: 90.084 Val_Loss: 0.1610  BEST VAL Loss: 0.1610  Val_Acc: 94.051

Epoch 77: Validation loss decreased (0.160956 --> 0.160848).  Saving model ...
	 Train_Loss: 0.2275 Train_Acc: 90.100 Val_Loss: 0.1608  BEST VAL Loss: 0.1608  Val_Acc: 93.776

Epoch 78: Validation loss decreased (0.160848 --> 0.160721).  Saving model ...
	 Train_Loss: 0.2273 Train_Acc: 90.075 Val_Loss: 0.1607  BEST VAL Loss: 0.1607  Val_Acc: 93.776

Epoch 79: Validation loss decreased (0.160721 --> 0.160596).  Saving model ...
	 Train_Loss: 0.2271 Train_Acc: 90.101 Val_Loss: 0.1606  BEST VAL Loss: 0.1606  Val_Acc: 93.935

Epoch 80: Validation loss decreased (0.160596 --> 0.160462).  Saving model ...
	 Train_Loss: 0.2269 Train_Acc: 90.173 Val_Loss: 0.1605  BEST VAL Loss: 0.1605  Val_Acc: 94.007

Epoch 81: Validation loss decreased (0.160462 --> 0.160352).  Saving model ...
	 Train_Loss: 0.2267 Train_Acc: 90.229 Val_Loss: 0.1604  BEST VAL Loss: 0.1604  Val_Acc: 93.860

Epoch 82: Validation loss decreased (0.160352 --> 0.160219).  Saving model ...
	 Train_Loss: 0.2265 Train_Acc: 90.162 Val_Loss: 0.1602  BEST VAL Loss: 0.1602  Val_Acc: 93.890

Epoch 83: Validation loss decreased (0.160219 --> 0.160089).  Saving model ...
	 Train_Loss: 0.2263 Train_Acc: 90.230 Val_Loss: 0.1601  BEST VAL Loss: 0.1601  Val_Acc: 93.875

Epoch 84: Validation loss decreased (0.160089 --> 0.159933).  Saving model ...
	 Train_Loss: 0.2261 Train_Acc: 90.276 Val_Loss: 0.1599  BEST VAL Loss: 0.1599  Val_Acc: 93.941

Epoch 85: Validation loss decreased (0.159933 --> 0.159817).  Saving model ...
	 Train_Loss: 0.2259 Train_Acc: 90.219 Val_Loss: 0.1598  BEST VAL Loss: 0.1598  Val_Acc: 93.953

Epoch 86: Validation loss decreased (0.159817 --> 0.159709).  Saving model ...
	 Train_Loss: 0.2257 Train_Acc: 90.242 Val_Loss: 0.1597  BEST VAL Loss: 0.1597  Val_Acc: 94.010

Epoch 87: Validation loss decreased (0.159709 --> 0.159604).  Saving model ...
	 Train_Loss: 0.2255 Train_Acc: 90.243 Val_Loss: 0.1596  BEST VAL Loss: 0.1596  Val_Acc: 94.024

Epoch 88: Validation loss decreased (0.159604 --> 0.159516).  Saving model ...
	 Train_Loss: 0.2253 Train_Acc: 90.123 Val_Loss: 0.1595  BEST VAL Loss: 0.1595  Val_Acc: 93.914

Epoch 89: Validation loss decreased (0.159516 --> 0.159410).  Saving model ...
	 Train_Loss: 0.2252 Train_Acc: 90.238 Val_Loss: 0.1594  BEST VAL Loss: 0.1594  Val_Acc: 93.839

Epoch 90: Validation loss decreased (0.159410 --> 0.159349).  Saving model ...
	 Train_Loss: 0.2250 Train_Acc: 90.233 Val_Loss: 0.1593  BEST VAL Loss: 0.1593  Val_Acc: 93.896

Epoch 91: Validation loss decreased (0.159349 --> 0.159224).  Saving model ...
	 Train_Loss: 0.2248 Train_Acc: 90.207 Val_Loss: 0.1592  BEST VAL Loss: 0.1592  Val_Acc: 93.935

Epoch 92: Validation loss decreased (0.159224 --> 0.159088).  Saving model ...
	 Train_Loss: 0.2247 Train_Acc: 90.289 Val_Loss: 0.1591  BEST VAL Loss: 0.1591  Val_Acc: 93.995

Epoch 93: Validation loss decreased (0.159088 --> 0.158953).  Saving model ...
	 Train_Loss: 0.2245 Train_Acc: 90.256 Val_Loss: 0.1590  BEST VAL Loss: 0.1590  Val_Acc: 93.995

Epoch 94: Validation loss decreased (0.158953 --> 0.158853).  Saving model ...
	 Train_Loss: 0.2243 Train_Acc: 90.289 Val_Loss: 0.1589  BEST VAL Loss: 0.1589  Val_Acc: 93.719

Epoch 95: Validation loss decreased (0.158853 --> 0.158722).  Saving model ...
	 Train_Loss: 0.2241 Train_Acc: 90.292 Val_Loss: 0.1587  BEST VAL Loss: 0.1587  Val_Acc: 93.974

Epoch 96: Validation loss decreased (0.158722 --> 0.158590).  Saving model ...
	 Train_Loss: 0.2240 Train_Acc: 90.406 Val_Loss: 0.1586  BEST VAL Loss: 0.1586  Val_Acc: 93.971

Epoch 97: Validation loss decreased (0.158590 --> 0.158468).  Saving model ...
	 Train_Loss: 0.2238 Train_Acc: 90.313 Val_Loss: 0.1585  BEST VAL Loss: 0.1585  Val_Acc: 93.956

Epoch 98: Validation loss decreased (0.158468 --> 0.158363).  Saving model ...
	 Train_Loss: 0.2236 Train_Acc: 90.337 Val_Loss: 0.1584  BEST VAL Loss: 0.1584  Val_Acc: 94.001

Epoch 99: Validation loss decreased (0.158363 --> 0.158285).  Saving model ...
	 Train_Loss: 0.2235 Train_Acc: 90.243 Val_Loss: 0.1583  BEST VAL Loss: 0.1583  Val_Acc: 93.827

H2O2_100.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.96      0.95      0.96    169561
           1       0.92      0.93      0.93     97655

    accuracy                           0.95    267216
   macro avg       0.94      0.94      0.94    267216
weighted avg       0.95      0.95      0.95    267216

H2O2_100.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.95      0.95      0.95     21196
           1       0.91      0.92      0.92     12207

    accuracy                           0.94     33403
   macro avg       0.93      0.93      0.93     33403
weighted avg       0.94      0.94      0.94     33403

H2O2_100.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.95      0.95      0.95     21195
           1       0.91      0.92      0.92     12207

    accuracy                           0.94     33402
   macro avg       0.93      0.94      0.93     33402
weighted avg       0.94      0.94      0.94     33402

              precision    recall  f1-score   support

           0       0.95      0.95      0.95     21195
           1       0.91      0.92      0.92     12207

    accuracy                           0.94     33402
   macro avg       0.93      0.94      0.93     33402
weighted avg       0.94      0.94      0.94     33402

H2O2_100.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_Thapsigargin_10.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.83      0.94      0.88     28584
           1       0.96      0.88      0.91     44915

    accuracy                           0.90     73499
   macro avg       0.89      0.91      0.90     73499
weighted avg       0.91      0.90      0.90     73499

              precision    recall  f1-score   support

           0       0.83      0.94      0.88     28584
           1       0.96      0.88      0.91     44915

    accuracy                           0.90     73499
   macro avg       0.89      0.91      0.90     73499
weighted avg       0.91      0.90      0.90     73499

completed
