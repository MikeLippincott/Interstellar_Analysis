[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '16989a84'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '24341819'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '9eea561c'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '2ad42fab'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: H2O2_100.000_DMSO_0.025 treatment_name: Thapsigargin_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: Thapsigargin_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (40666, 1276)
Number of total missing values across all columns: 81332
Data Subset Is Off
Wells held out for testing: ['D14' 'H22']
Wells to use for training, validation, and testing ['D15' 'H18' 'H19' 'H23' 'K14' 'K15' 'I18' 'I19' 'I22' 'I23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.501124).  Saving model ...
	 Train_Loss: 0.5979 Train_Acc: 66.846 Val_Loss: 0.5011  BEST VAL Loss: 0.5011  Val_Acc: 79.271

Epoch 1: Validation loss decreased (0.501124 --> 0.465533).  Saving model ...
	 Train_Loss: 0.5385 Train_Acc: 80.078 Val_Loss: 0.4655  BEST VAL Loss: 0.4655  Val_Acc: 83.368

Epoch 2: Validation loss decreased (0.465533 --> 0.439015).  Saving model ...
	 Train_Loss: 0.4983 Train_Acc: 83.408 Val_Loss: 0.4390  BEST VAL Loss: 0.4390  Val_Acc: 85.508

Epoch 3: Validation loss decreased (0.439015 --> 0.417139).  Saving model ...
	 Train_Loss: 0.4693 Train_Acc: 84.678 Val_Loss: 0.4171  BEST VAL Loss: 0.4171  Val_Acc: 86.261

Epoch 4: Validation loss decreased (0.417139 --> 0.399016).  Saving model ...
	 Train_Loss: 0.4456 Train_Acc: 86.019 Val_Loss: 0.3990  BEST VAL Loss: 0.3990  Val_Acc: 86.894

Epoch 5: Validation loss decreased (0.399016 --> 0.384480).  Saving model ...
	 Train_Loss: 0.4263 Train_Acc: 86.806 Val_Loss: 0.3845  BEST VAL Loss: 0.3845  Val_Acc: 87.798

Epoch 6: Validation loss decreased (0.384480 --> 0.370864).  Saving model ...
	 Train_Loss: 0.4097 Train_Acc: 87.477 Val_Loss: 0.3709  BEST VAL Loss: 0.3709  Val_Acc: 88.280

Epoch 7: Validation loss decreased (0.370864 --> 0.359964).  Saving model ...
	 Train_Loss: 0.3954 Train_Acc: 88.204 Val_Loss: 0.3600  BEST VAL Loss: 0.3600  Val_Acc: 88.822

Epoch 8: Validation loss decreased (0.359964 --> 0.350288).  Saving model ...
	 Train_Loss: 0.3828 Train_Acc: 88.765 Val_Loss: 0.3503  BEST VAL Loss: 0.3503  Val_Acc: 89.304

Epoch 9: Validation loss decreased (0.350288 --> 0.341120).  Saving model ...
	 Train_Loss: 0.3717 Train_Acc: 89.108 Val_Loss: 0.3411  BEST VAL Loss: 0.3411  Val_Acc: 89.756

Epoch 10: Validation loss decreased (0.341120 --> 0.333363).  Saving model ...
	 Train_Loss: 0.3620 Train_Acc: 89.206 Val_Loss: 0.3334  BEST VAL Loss: 0.3334  Val_Acc: 90.208

Epoch 11: Validation loss decreased (0.333363 --> 0.325737).  Saving model ...
	 Train_Loss: 0.3527 Train_Acc: 90.016 Val_Loss: 0.3257  BEST VAL Loss: 0.3257  Val_Acc: 90.118

Epoch 12: Validation loss decreased (0.325737 --> 0.319361).  Saving model ...
	 Train_Loss: 0.3445 Train_Acc: 90.235 Val_Loss: 0.3194  BEST VAL Loss: 0.3194  Val_Acc: 90.268

Epoch 13: Validation loss decreased (0.319361 --> 0.313360).  Saving model ...
	 Train_Loss: 0.3369 Train_Acc: 90.468 Val_Loss: 0.3134  BEST VAL Loss: 0.3134  Val_Acc: 90.630

Epoch 14: Validation loss decreased (0.313360 --> 0.307810).  Saving model ...
	 Train_Loss: 0.3298 Train_Acc: 90.706 Val_Loss: 0.3078  BEST VAL Loss: 0.3078  Val_Acc: 90.841

Epoch 15: Validation loss decreased (0.307810 --> 0.302069).  Saving model ...
	 Train_Loss: 0.3233 Train_Acc: 90.954 Val_Loss: 0.3021  BEST VAL Loss: 0.3021  Val_Acc: 91.021

Epoch 16: Validation loss decreased (0.302069 --> 0.297192).  Saving model ...
	 Train_Loss: 0.3172 Train_Acc: 91.252 Val_Loss: 0.2972  BEST VAL Loss: 0.2972  Val_Acc: 91.112

Epoch 17: Validation loss decreased (0.297192 --> 0.292478).  Saving model ...
	 Train_Loss: 0.3116 Train_Acc: 91.331 Val_Loss: 0.2925  BEST VAL Loss: 0.2925  Val_Acc: 91.594

Epoch 18: Validation loss decreased (0.292478 --> 0.288208).  Saving model ...
	 Train_Loss: 0.3062 Train_Acc: 91.538 Val_Loss: 0.2882  BEST VAL Loss: 0.2882  Val_Acc: 91.413

Epoch 19: Validation loss decreased (0.288208 --> 0.284429).  Saving model ...
	 Train_Loss: 0.3013 Train_Acc: 91.945 Val_Loss: 0.2844  BEST VAL Loss: 0.2844  Val_Acc: 91.503

Epoch 20: Validation loss decreased (0.284429 --> 0.280760).  Saving model ...
	 Train_Loss: 0.2966 Train_Acc: 91.990 Val_Loss: 0.2808  BEST VAL Loss: 0.2808  Val_Acc: 91.534

Epoch 21: Validation loss decreased (0.280760 --> 0.277268).  Saving model ...
	 Train_Loss: 0.2922 Train_Acc: 92.054 Val_Loss: 0.2773  BEST VAL Loss: 0.2773  Val_Acc: 91.684

Epoch 22: Validation loss decreased (0.277268 --> 0.274026).  Saving model ...
	 Train_Loss: 0.2879 Train_Acc: 92.314 Val_Loss: 0.2740  BEST VAL Loss: 0.2740  Val_Acc: 91.684

Epoch 23: Validation loss decreased (0.274026 --> 0.271293).  Saving model ...
	 Train_Loss: 0.2838 Train_Acc: 92.461 Val_Loss: 0.2713  BEST VAL Loss: 0.2713  Val_Acc: 91.684

Epoch 24: Validation loss decreased (0.271293 --> 0.268079).  Saving model ...
	 Train_Loss: 0.2800 Train_Acc: 92.597 Val_Loss: 0.2681  BEST VAL Loss: 0.2681  Val_Acc: 92.016

Epoch 25: Validation loss decreased (0.268079 --> 0.265267).  Saving model ...
	 Train_Loss: 0.2764 Train_Acc: 92.642 Val_Loss: 0.2653  BEST VAL Loss: 0.2653  Val_Acc: 92.136

Epoch 26: Validation loss decreased (0.265267 --> 0.262460).  Saving model ...
	 Train_Loss: 0.2729 Train_Acc: 92.748 Val_Loss: 0.2625  BEST VAL Loss: 0.2625  Val_Acc: 91.835

Epoch 27: Validation loss decreased (0.262460 --> 0.260301).  Saving model ...
	 Train_Loss: 0.2696 Train_Acc: 93.113 Val_Loss: 0.2603  BEST VAL Loss: 0.2603  Val_Acc: 91.955

Epoch 28: Validation loss decreased (0.260301 --> 0.257992).  Saving model ...
	 Train_Loss: 0.2664 Train_Acc: 92.966 Val_Loss: 0.2580  BEST VAL Loss: 0.2580  Val_Acc: 92.287

Epoch 29: Validation loss decreased (0.257992 --> 0.255762).  Saving model ...
	 Train_Loss: 0.2633 Train_Acc: 93.354 Val_Loss: 0.2558  BEST VAL Loss: 0.2558  Val_Acc: 92.196

Epoch 30: Validation loss decreased (0.255762 --> 0.253682).  Saving model ...
	 Train_Loss: 0.2602 Train_Acc: 93.301 Val_Loss: 0.2537  BEST VAL Loss: 0.2537  Val_Acc: 92.166

Epoch 31: Validation loss decreased (0.253682 --> 0.251842).  Saving model ...
	 Train_Loss: 0.2574 Train_Acc: 93.298 Val_Loss: 0.2518  BEST VAL Loss: 0.2518  Val_Acc: 92.588

Epoch 32: Validation loss decreased (0.251842 --> 0.249826).  Saving model ...
	 Train_Loss: 0.2547 Train_Acc: 93.641 Val_Loss: 0.2498  BEST VAL Loss: 0.2498  Val_Acc: 92.227

Epoch 33: Validation loss decreased (0.249826 --> 0.247798).  Saving model ...
	 Train_Loss: 0.2520 Train_Acc: 93.622 Val_Loss: 0.2478  BEST VAL Loss: 0.2478  Val_Acc: 92.709

Epoch 34: Validation loss decreased (0.247798 --> 0.246091).  Saving model ...
	 Train_Loss: 0.2495 Train_Acc: 93.625 Val_Loss: 0.2461  BEST VAL Loss: 0.2461  Val_Acc: 92.739

Epoch 35: Validation loss decreased (0.246091 --> 0.244389).  Saving model ...
	 Train_Loss: 0.2470 Train_Acc: 93.818 Val_Loss: 0.2444  BEST VAL Loss: 0.2444  Val_Acc: 92.618

Epoch 36: Validation loss decreased (0.244389 --> 0.242635).  Saving model ...
	 Train_Loss: 0.2446 Train_Acc: 93.885 Val_Loss: 0.2426  BEST VAL Loss: 0.2426  Val_Acc: 92.739

Epoch 37: Validation loss decreased (0.242635 --> 0.240952).  Saving model ...
	 Train_Loss: 0.2424 Train_Acc: 93.720 Val_Loss: 0.2410  BEST VAL Loss: 0.2410  Val_Acc: 92.588

Epoch 38: Validation loss decreased (0.240952 --> 0.239351).  Saving model ...
	 Train_Loss: 0.2401 Train_Acc: 93.938 Val_Loss: 0.2394  BEST VAL Loss: 0.2394  Val_Acc: 92.829

Epoch 39: Validation loss decreased (0.239351 --> 0.238046).  Saving model ...
	 Train_Loss: 0.2380 Train_Acc: 93.946 Val_Loss: 0.2380  BEST VAL Loss: 0.2380  Val_Acc: 92.648

Epoch 40: Validation loss decreased (0.238046 --> 0.236984).  Saving model ...
	 Train_Loss: 0.2359 Train_Acc: 94.179 Val_Loss: 0.2370  BEST VAL Loss: 0.2370  Val_Acc: 93.010

Epoch 41: Validation loss decreased (0.236984 --> 0.235769).  Saving model ...
	 Train_Loss: 0.2338 Train_Acc: 94.383 Val_Loss: 0.2358  BEST VAL Loss: 0.2358  Val_Acc: 92.739

Epoch 42: Validation loss decreased (0.235769 --> 0.234361).  Saving model ...
	 Train_Loss: 0.2318 Train_Acc: 94.390 Val_Loss: 0.2344  BEST VAL Loss: 0.2344  Val_Acc: 92.920

Epoch 43: Validation loss decreased (0.234361 --> 0.232845).  Saving model ...
	 Train_Loss: 0.2298 Train_Acc: 94.311 Val_Loss: 0.2328  BEST VAL Loss: 0.2328  Val_Acc: 93.040

Epoch 44: Validation loss decreased (0.232845 --> 0.231839).  Saving model ...
	 Train_Loss: 0.2279 Train_Acc: 94.522 Val_Loss: 0.2318  BEST VAL Loss: 0.2318  Val_Acc: 93.010

Epoch 45: Validation loss decreased (0.231839 --> 0.230600).  Saving model ...
	 Train_Loss: 0.2260 Train_Acc: 94.541 Val_Loss: 0.2306  BEST VAL Loss: 0.2306  Val_Acc: 92.950

Epoch 46: Validation loss decreased (0.230600 --> 0.229490).  Saving model ...
	 Train_Loss: 0.2242 Train_Acc: 94.586 Val_Loss: 0.2295  BEST VAL Loss: 0.2295  Val_Acc: 93.251

Epoch 47: Validation loss decreased (0.229490 --> 0.228313).  Saving model ...
	 Train_Loss: 0.2225 Train_Acc: 94.518 Val_Loss: 0.2283  BEST VAL Loss: 0.2283  Val_Acc: 92.829

Epoch 48: Validation loss decreased (0.228313 --> 0.227198).  Saving model ...
	 Train_Loss: 0.2208 Train_Acc: 94.605 Val_Loss: 0.2272  BEST VAL Loss: 0.2272  Val_Acc: 93.010

Epoch 49: Validation loss decreased (0.227198 --> 0.226195).  Saving model ...
	 Train_Loss: 0.2192 Train_Acc: 94.903 Val_Loss: 0.2262  BEST VAL Loss: 0.2262  Val_Acc: 92.980

Epoch 50: Validation loss decreased (0.226195 --> 0.225197).  Saving model ...
	 Train_Loss: 0.2176 Train_Acc: 94.582 Val_Loss: 0.2252  BEST VAL Loss: 0.2252  Val_Acc: 93.341

Epoch 51: Validation loss decreased (0.225197 --> 0.224123).  Saving model ...
	 Train_Loss: 0.2160 Train_Acc: 94.748 Val_Loss: 0.2241  BEST VAL Loss: 0.2241  Val_Acc: 93.341

Epoch 52: Validation loss decreased (0.224123 --> 0.223136).  Saving model ...
	 Train_Loss: 0.2145 Train_Acc: 94.823 Val_Loss: 0.2231  BEST VAL Loss: 0.2231  Val_Acc: 93.341

Epoch 53: Validation loss decreased (0.223136 --> 0.222132).  Saving model ...
	 Train_Loss: 0.2130 Train_Acc: 94.748 Val_Loss: 0.2221  BEST VAL Loss: 0.2221  Val_Acc: 93.251

Epoch 54: Validation loss decreased (0.222132 --> 0.221355).  Saving model ...
	 Train_Loss: 0.2115 Train_Acc: 95.099 Val_Loss: 0.2214  BEST VAL Loss: 0.2214  Val_Acc: 93.251

Epoch 55: Validation loss decreased (0.221355 --> 0.220396).  Saving model ...
	 Train_Loss: 0.2100 Train_Acc: 94.846 Val_Loss: 0.2204  BEST VAL Loss: 0.2204  Val_Acc: 93.191

Epoch 56: Validation loss decreased (0.220396 --> 0.219754).  Saving model ...
	 Train_Loss: 0.2086 Train_Acc: 94.974 Val_Loss: 0.2198  BEST VAL Loss: 0.2198  Val_Acc: 93.191

Epoch 57: Validation loss decreased (0.219754 --> 0.219037).  Saving model ...
	 Train_Loss: 0.2073 Train_Acc: 94.982 Val_Loss: 0.2190  BEST VAL Loss: 0.2190  Val_Acc: 93.100

Epoch 58: Validation loss decreased (0.219037 --> 0.218187).  Saving model ...
	 Train_Loss: 0.2059 Train_Acc: 95.223 Val_Loss: 0.2182  BEST VAL Loss: 0.2182  Val_Acc: 93.371

Epoch 59: Validation loss decreased (0.218187 --> 0.217673).  Saving model ...
	 Train_Loss: 0.2046 Train_Acc: 95.302 Val_Loss: 0.2177  BEST VAL Loss: 0.2177  Val_Acc: 93.311

Epoch 60: Validation loss decreased (0.217673 --> 0.217036).  Saving model ...
	 Train_Loss: 0.2033 Train_Acc: 95.144 Val_Loss: 0.2170  BEST VAL Loss: 0.2170  Val_Acc: 93.010

Epoch 61: Validation loss decreased (0.217036 --> 0.216145).  Saving model ...
	 Train_Loss: 0.2021 Train_Acc: 95.106 Val_Loss: 0.2161  BEST VAL Loss: 0.2161  Val_Acc: 93.522

Epoch 62: Validation loss decreased (0.216145 --> 0.215469).  Saving model ...
	 Train_Loss: 0.2008 Train_Acc: 95.340 Val_Loss: 0.2155  BEST VAL Loss: 0.2155  Val_Acc: 93.251

Epoch 63: Validation loss decreased (0.215469 --> 0.214771).  Saving model ...
	 Train_Loss: 0.1996 Train_Acc: 95.366 Val_Loss: 0.2148  BEST VAL Loss: 0.2148  Val_Acc: 93.311

Epoch 64: Validation loss decreased (0.214771 --> 0.214120).  Saving model ...
	 Train_Loss: 0.1984 Train_Acc: 95.023 Val_Loss: 0.2141  BEST VAL Loss: 0.2141  Val_Acc: 93.522

Epoch 65: Validation loss decreased (0.214120 --> 0.213734).  Saving model ...
	 Train_Loss: 0.1972 Train_Acc: 95.340 Val_Loss: 0.2137  BEST VAL Loss: 0.2137  Val_Acc: 93.341

Epoch 66: Validation loss decreased (0.213734 --> 0.213064).  Saving model ...
	 Train_Loss: 0.1961 Train_Acc: 95.468 Val_Loss: 0.2131  BEST VAL Loss: 0.2131  Val_Acc: 93.161

Epoch 67: Validation loss decreased (0.213064 --> 0.212539).  Saving model ...
	 Train_Loss: 0.1949 Train_Acc: 95.453 Val_Loss: 0.2125  BEST VAL Loss: 0.2125  Val_Acc: 93.402

Epoch 68: Validation loss decreased (0.212539 --> 0.211925).  Saving model ...
	 Train_Loss: 0.1938 Train_Acc: 95.532 Val_Loss: 0.2119  BEST VAL Loss: 0.2119  Val_Acc: 93.552

Epoch 69: Validation loss decreased (0.211925 --> 0.211588).  Saving model ...
	 Train_Loss: 0.1927 Train_Acc: 95.502 Val_Loss: 0.2116  BEST VAL Loss: 0.2116  Val_Acc: 93.311

Epoch 70: Validation loss decreased (0.211588 --> 0.210959).  Saving model ...
	 Train_Loss: 0.1916 Train_Acc: 95.453 Val_Loss: 0.2110  BEST VAL Loss: 0.2110  Val_Acc: 93.643

Epoch 71: Validation loss decreased (0.210959 --> 0.210561).  Saving model ...
	 Train_Loss: 0.1906 Train_Acc: 95.596 Val_Loss: 0.2106  BEST VAL Loss: 0.2106  Val_Acc: 93.552

Epoch 72: Validation loss decreased (0.210561 --> 0.210110).  Saving model ...
	 Train_Loss: 0.1895 Train_Acc: 95.626 Val_Loss: 0.2101  BEST VAL Loss: 0.2101  Val_Acc: 93.341

Epoch 73: Validation loss decreased (0.210110 --> 0.209659).  Saving model ...
	 Train_Loss: 0.1885 Train_Acc: 95.679 Val_Loss: 0.2097  BEST VAL Loss: 0.2097  Val_Acc: 93.432

Epoch 74: Validation loss decreased (0.209659 --> 0.209127).  Saving model ...
	 Train_Loss: 0.1874 Train_Acc: 95.705 Val_Loss: 0.2091  BEST VAL Loss: 0.2091  Val_Acc: 93.402

Epoch 75: Validation loss decreased (0.209127 --> 0.208929).  Saving model ...
	 Train_Loss: 0.1865 Train_Acc: 95.615 Val_Loss: 0.2089  BEST VAL Loss: 0.2089  Val_Acc: 93.070

Epoch 76: Validation loss decreased (0.208929 --> 0.208672).  Saving model ...
	 Train_Loss: 0.1855 Train_Acc: 95.856 Val_Loss: 0.2087  BEST VAL Loss: 0.2087  Val_Acc: 93.703

Epoch 77: Validation loss decreased (0.208672 --> 0.208539).  Saving model ...
	 Train_Loss: 0.1845 Train_Acc: 95.942 Val_Loss: 0.2085  BEST VAL Loss: 0.2085  Val_Acc: 93.613

Epoch 78: Validation loss decreased (0.208539 --> 0.207968).  Saving model ...
	 Train_Loss: 0.1835 Train_Acc: 95.848 Val_Loss: 0.2080  BEST VAL Loss: 0.2080  Val_Acc: 93.371

Epoch 79: Validation loss decreased (0.207968 --> 0.207625).  Saving model ...
	 Train_Loss: 0.1826 Train_Acc: 96.006 Val_Loss: 0.2076  BEST VAL Loss: 0.2076  Val_Acc: 93.552

Epoch 80: Validation loss decreased (0.207625 --> 0.207192).  Saving model ...
	 Train_Loss: 0.1817 Train_Acc: 95.641 Val_Loss: 0.2072  BEST VAL Loss: 0.2072  Val_Acc: 93.492

Epoch 81: Validation loss decreased (0.207192 --> 0.206748).  Saving model ...
	 Train_Loss: 0.1808 Train_Acc: 96.010 Val_Loss: 0.2067  BEST VAL Loss: 0.2067  Val_Acc: 93.703

Epoch 82: Validation loss decreased (0.206748 --> 0.206384).  Saving model ...
	 Train_Loss: 0.1799 Train_Acc: 95.822 Val_Loss: 0.2064  BEST VAL Loss: 0.2064  Val_Acc: 93.643

Epoch 83: Validation loss decreased (0.206384 --> 0.206231).  Saving model ...
	 Train_Loss: 0.1790 Train_Acc: 95.897 Val_Loss: 0.2062  BEST VAL Loss: 0.2062  Val_Acc: 93.823

Epoch 84: Validation loss decreased (0.206231 --> 0.205856).  Saving model ...
	 Train_Loss: 0.1781 Train_Acc: 96.202 Val_Loss: 0.2059  BEST VAL Loss: 0.2059  Val_Acc: 93.462

Epoch 85: Validation loss decreased (0.205856 --> 0.205479).  Saving model ...
	 Train_Loss: 0.1773 Train_Acc: 96.116 Val_Loss: 0.2055  BEST VAL Loss: 0.2055  Val_Acc: 93.552

Epoch 86: Validation loss decreased (0.205479 --> 0.205123).  Saving model ...
	 Train_Loss: 0.1764 Train_Acc: 96.022 Val_Loss: 0.2051  BEST VAL Loss: 0.2051  Val_Acc: 93.552

Epoch 87: Validation loss decreased (0.205123 --> 0.204730).  Saving model ...
	 Train_Loss: 0.1756 Train_Acc: 96.131 Val_Loss: 0.2047  BEST VAL Loss: 0.2047  Val_Acc: 93.763

Epoch 88: Validation loss decreased (0.204730 --> 0.204292).  Saving model ...
	 Train_Loss: 0.1748 Train_Acc: 96.074 Val_Loss: 0.2043  BEST VAL Loss: 0.2043  Val_Acc: 93.643

Epoch 89: Validation loss decreased (0.204292 --> 0.203951).  Saving model ...
	 Train_Loss: 0.1740 Train_Acc: 96.006 Val_Loss: 0.2040  BEST VAL Loss: 0.2040  Val_Acc: 93.582

Epoch 90: Validation loss decreased (0.203951 --> 0.203632).  Saving model ...
	 Train_Loss: 0.1732 Train_Acc: 96.063 Val_Loss: 0.2036  BEST VAL Loss: 0.2036  Val_Acc: 93.643

Epoch 91: Validation loss decreased (0.203632 --> 0.203309).  Saving model ...
	 Train_Loss: 0.1724 Train_Acc: 96.266 Val_Loss: 0.2033  BEST VAL Loss: 0.2033  Val_Acc: 93.462

Epoch 92: Validation loss decreased (0.203309 --> 0.202880).  Saving model ...
	 Train_Loss: 0.1716 Train_Acc: 96.180 Val_Loss: 0.2029  BEST VAL Loss: 0.2029  Val_Acc: 93.673

Epoch 93: Validation loss decreased (0.202880 --> 0.202566).  Saving model ...
	 Train_Loss: 0.1708 Train_Acc: 96.289 Val_Loss: 0.2026  BEST VAL Loss: 0.2026  Val_Acc: 94.004

Epoch 94: Validation loss decreased (0.202566 --> 0.202454).  Saving model ...
	 Train_Loss: 0.1701 Train_Acc: 96.161 Val_Loss: 0.2025  BEST VAL Loss: 0.2025  Val_Acc: 93.854

Epoch 95: Validation loss decreased (0.202454 --> 0.202085).  Saving model ...
	 Train_Loss: 0.1694 Train_Acc: 96.101 Val_Loss: 0.2021  BEST VAL Loss: 0.2021  Val_Acc: 93.884

Epoch 96: Validation loss decreased (0.202085 --> 0.201922).  Saving model ...
	 Train_Loss: 0.1686 Train_Acc: 96.500 Val_Loss: 0.2019  BEST VAL Loss: 0.2019  Val_Acc: 93.432

Epoch 97: Validation loss decreased (0.201922 --> 0.201701).  Saving model ...
	 Train_Loss: 0.1679 Train_Acc: 96.379 Val_Loss: 0.2017  BEST VAL Loss: 0.2017  Val_Acc: 93.341

Epoch 98: Validation loss decreased (0.201701 --> 0.201512).  Saving model ...
	 Train_Loss: 0.1672 Train_Acc: 96.315 Val_Loss: 0.2015  BEST VAL Loss: 0.2015  Val_Acc: 93.552

Epoch 99: Validation loss decreased (0.201512 --> 0.201259).  Saving model ...
	 Train_Loss: 0.1664 Train_Acc: 96.500 Val_Loss: 0.2013  BEST VAL Loss: 0.2013  Val_Acc: 93.613

H2O2_100.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.69      0.70      0.69     18174
           1       0.32      0.32      0.32      8369

    accuracy                           0.58     26543
   macro avg       0.51      0.51      0.51     26543
weighted avg       0.57      0.58      0.58     26543

H2O2_100.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.69      0.70      0.69      2272
           1       0.32      0.30      0.31      1047

    accuracy                           0.58      3319
   macro avg       0.50      0.50      0.50      3319
weighted avg       0.57      0.58      0.57      3319

H2O2_100.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.69      0.70      0.70      2272
           1       0.33      0.32      0.32      1047

    accuracy                           0.58      3319
   macro avg       0.51      0.51      0.51      3319
weighted avg       0.58      0.58      0.58      3319

              precision    recall  f1-score   support

           0       0.69      0.70      0.70      2272
           1       0.33      0.32      0.32      1047

    accuracy                           0.58      3319
   macro avg       0.51      0.51      0.51      3319
weighted avg       0.58      0.58      0.58      3319

H2O2_100.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
H2O2_100.000_DMSO_0.025_vs_Thapsigargin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.56      0.59      0.58      4182
           1       0.44      0.41      0.43      3303

    accuracy                           0.51      7485
   macro avg       0.50      0.50      0.50      7485
weighted avg       0.51      0.51      0.51      7485

              precision    recall  f1-score   support

           0       0.56      0.59      0.58      4182
           1       0.44      0.41      0.43      3303

    accuracy                           0.51      7485
   macro avg       0.50      0.50      0.50      7485
weighted avg       0.51      0.51      0.51      7485

completed
