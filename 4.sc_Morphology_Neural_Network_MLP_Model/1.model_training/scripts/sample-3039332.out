[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ef039d77'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'a10a4252'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ff5edca7'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '9f819bdc'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Thapsigargin_10.000_DMSO_0.025 treatment_name: H2O2_100.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Thapsigargin_10.000_DMSO_0.025
TREATMENT_NAME: H2O2_100.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (407520, 1270)
Number of total missing values across all columns: 815040
Data Subset Is Off
Wells held out for testing: ['I10' 'L06']
Wells to use for training, validation, and testing ['E06' 'E07' 'H04' 'I04' 'H05' 'I05' 'H10' 'H11' 'I11' 'L07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.464437).  Saving model ...
	 Train_Loss: 0.6109 Train_Acc: 67.892 Val_Loss: 0.4644  BEST VAL Loss: 0.4644  Val_Acc: 81.154

Epoch 1: Validation loss decreased (0.464437 --> 0.436189).  Saving model ...
	 Train_Loss: 0.5269 Train_Acc: 79.711 Val_Loss: 0.4362  BEST VAL Loss: 0.4362  Val_Acc: 80.532

Epoch 2: Validation loss decreased (0.436189 --> 0.369980).  Saving model ...
	 Train_Loss: 0.4717 Train_Acc: 83.166 Val_Loss: 0.3700  BEST VAL Loss: 0.3700  Val_Acc: 89.806

Epoch 3: Validation loss decreased (0.369980 --> 0.332112).  Saving model ...
	 Train_Loss: 0.4350 Train_Acc: 84.971 Val_Loss: 0.3321  BEST VAL Loss: 0.3321  Val_Acc: 90.339

Epoch 4: Validation loss decreased (0.332112 --> 0.304797).  Saving model ...
	 Train_Loss: 0.4095 Train_Acc: 85.880 Val_Loss: 0.3048  BEST VAL Loss: 0.3048  Val_Acc: 91.812

Epoch 5: Validation loss decreased (0.304797 --> 0.286512).  Saving model ...
	 Train_Loss: 0.3908 Train_Acc: 86.336 Val_Loss: 0.2865  BEST VAL Loss: 0.2865  Val_Acc: 91.570

Epoch 6: Validation loss decreased (0.286512 --> 0.272454).  Saving model ...
	 Train_Loss: 0.3761 Train_Acc: 86.656 Val_Loss: 0.2725  BEST VAL Loss: 0.2725  Val_Acc: 91.785

Epoch 7: Validation loss decreased (0.272454 --> 0.261702).  Saving model ...
	 Train_Loss: 0.3644 Train_Acc: 87.080 Val_Loss: 0.2617  BEST VAL Loss: 0.2617  Val_Acc: 92.082

Epoch 8: Validation loss decreased (0.261702 --> 0.251010).  Saving model ...
	 Train_Loss: 0.3545 Train_Acc: 87.318 Val_Loss: 0.2510  BEST VAL Loss: 0.2510  Val_Acc: 93.204

Epoch 9: Validation loss decreased (0.251010 --> 0.242284).  Saving model ...
	 Train_Loss: 0.3461 Train_Acc: 87.552 Val_Loss: 0.2423  BEST VAL Loss: 0.2423  Val_Acc: 93.156

Epoch 10: Validation loss decreased (0.242284 --> 0.237029).  Saving model ...
	 Train_Loss: 0.3388 Train_Acc: 87.693 Val_Loss: 0.2370  BEST VAL Loss: 0.2370  Val_Acc: 91.842

Epoch 11: Validation loss decreased (0.237029 --> 0.231043).  Saving model ...
	 Train_Loss: 0.3325 Train_Acc: 87.774 Val_Loss: 0.2310  BEST VAL Loss: 0.2310  Val_Acc: 93.087

Epoch 12: Validation loss decreased (0.231043 --> 0.224928).  Saving model ...
	 Train_Loss: 0.3269 Train_Acc: 87.960 Val_Loss: 0.2249  BEST VAL Loss: 0.2249  Val_Acc: 93.719

Epoch 13: Validation loss decreased (0.224928 --> 0.219809).  Saving model ...
	 Train_Loss: 0.3219 Train_Acc: 88.056 Val_Loss: 0.2198  BEST VAL Loss: 0.2198  Val_Acc: 93.638

Epoch 14: Validation loss decreased (0.219809 --> 0.215583).  Saving model ...
	 Train_Loss: 0.3176 Train_Acc: 88.182 Val_Loss: 0.2156  BEST VAL Loss: 0.2156  Val_Acc: 93.435

Epoch 15: Validation loss decreased (0.215583 --> 0.211290).  Saving model ...
	 Train_Loss: 0.3136 Train_Acc: 88.174 Val_Loss: 0.2113  BEST VAL Loss: 0.2113  Val_Acc: 93.905

Epoch 16: Validation loss decreased (0.211290 --> 0.207856).  Saving model ...
	 Train_Loss: 0.3101 Train_Acc: 88.198 Val_Loss: 0.2079  BEST VAL Loss: 0.2079  Val_Acc: 93.614

Epoch 17: Validation loss decreased (0.207856 --> 0.204647).  Saving model ...
	 Train_Loss: 0.3068 Train_Acc: 88.336 Val_Loss: 0.2046  BEST VAL Loss: 0.2046  Val_Acc: 93.944

Epoch 18: Validation loss decreased (0.204647 --> 0.201784).  Saving model ...
	 Train_Loss: 0.3038 Train_Acc: 88.340 Val_Loss: 0.2018  BEST VAL Loss: 0.2018  Val_Acc: 93.623

Epoch 19: Validation loss decreased (0.201784 --> 0.199646).  Saving model ...
	 Train_Loss: 0.3011 Train_Acc: 88.374 Val_Loss: 0.1996  BEST VAL Loss: 0.1996  Val_Acc: 93.156

Epoch 20: Validation loss decreased (0.199646 --> 0.197920).  Saving model ...
	 Train_Loss: 0.2985 Train_Acc: 88.436 Val_Loss: 0.1979  BEST VAL Loss: 0.1979  Val_Acc: 92.857

Epoch 21: Validation loss decreased (0.197920 --> 0.195720).  Saving model ...
	 Train_Loss: 0.2962 Train_Acc: 88.501 Val_Loss: 0.1957  BEST VAL Loss: 0.1957  Val_Acc: 93.728

Epoch 22: Validation loss decreased (0.195720 --> 0.194224).  Saving model ...
	 Train_Loss: 0.2940 Train_Acc: 88.565 Val_Loss: 0.1942  BEST VAL Loss: 0.1942  Val_Acc: 93.228

Epoch 23: Validation loss decreased (0.194224 --> 0.192184).  Saving model ...
	 Train_Loss: 0.2920 Train_Acc: 88.553 Val_Loss: 0.1922  BEST VAL Loss: 0.1922  Val_Acc: 94.019

Epoch 24: Validation loss decreased (0.192184 --> 0.190203).  Saving model ...
	 Train_Loss: 0.2901 Train_Acc: 88.558 Val_Loss: 0.1902  BEST VAL Loss: 0.1902  Val_Acc: 94.048

Epoch 25: Validation loss decreased (0.190203 --> 0.188450).  Saving model ...
	 Train_Loss: 0.2883 Train_Acc: 88.577 Val_Loss: 0.1884  BEST VAL Loss: 0.1884  Val_Acc: 94.045

Epoch 26: Validation loss decreased (0.188450 --> 0.186710).  Saving model ...
	 Train_Loss: 0.2866 Train_Acc: 88.695 Val_Loss: 0.1867  BEST VAL Loss: 0.1867  Val_Acc: 94.048

Epoch 27: Validation loss decreased (0.186710 --> 0.185142).  Saving model ...
	 Train_Loss: 0.2850 Train_Acc: 88.809 Val_Loss: 0.1851  BEST VAL Loss: 0.1851  Val_Acc: 94.051

Epoch 28: Validation loss decreased (0.185142 --> 0.183516).  Saving model ...
	 Train_Loss: 0.2835 Train_Acc: 88.693 Val_Loss: 0.1835  BEST VAL Loss: 0.1835  Val_Acc: 94.324

Epoch 29: Validation loss decreased (0.183516 --> 0.182124).  Saving model ...
	 Train_Loss: 0.2821 Train_Acc: 88.723 Val_Loss: 0.1821  BEST VAL Loss: 0.1821  Val_Acc: 94.126

Epoch 30: Validation loss decreased (0.182124 --> 0.181083).  Saving model ...
	 Train_Loss: 0.2807 Train_Acc: 88.765 Val_Loss: 0.1811  BEST VAL Loss: 0.1811  Val_Acc: 93.563

Epoch 31: Validation loss decreased (0.181083 --> 0.179883).  Saving model ...
	 Train_Loss: 0.2794 Train_Acc: 88.779 Val_Loss: 0.1799  BEST VAL Loss: 0.1799  Val_Acc: 94.010

Epoch 32: Validation loss decreased (0.179883 --> 0.178727).  Saving model ...
	 Train_Loss: 0.2782 Train_Acc: 88.848 Val_Loss: 0.1787  BEST VAL Loss: 0.1787  Val_Acc: 94.078

Epoch 33: Validation loss decreased (0.178727 --> 0.177694).  Saving model ...
	 Train_Loss: 0.2770 Train_Acc: 88.893 Val_Loss: 0.1777  BEST VAL Loss: 0.1777  Val_Acc: 93.878

Epoch 34: Validation loss decreased (0.177694 --> 0.176543).  Saving model ...
	 Train_Loss: 0.2759 Train_Acc: 88.794 Val_Loss: 0.1765  BEST VAL Loss: 0.1765  Val_Acc: 94.231

Epoch 35: Validation loss decreased (0.176543 --> 0.175409).  Saving model ...
	 Train_Loss: 0.2749 Train_Acc: 88.871 Val_Loss: 0.1754  BEST VAL Loss: 0.1754  Val_Acc: 94.291

Epoch 36: Validation loss decreased (0.175409 --> 0.174463).  Saving model ...
	 Train_Loss: 0.2739 Train_Acc: 88.875 Val_Loss: 0.1745  BEST VAL Loss: 0.1745  Val_Acc: 94.007

Epoch 37: Validation loss decreased (0.174463 --> 0.173519).  Saving model ...
	 Train_Loss: 0.2729 Train_Acc: 88.949 Val_Loss: 0.1735  BEST VAL Loss: 0.1735  Val_Acc: 94.174

Epoch 38: Validation loss decreased (0.173519 --> 0.172539).  Saving model ...
	 Train_Loss: 0.2719 Train_Acc: 88.984 Val_Loss: 0.1725  BEST VAL Loss: 0.1725  Val_Acc: 94.228

Epoch 39: Validation loss decreased (0.172539 --> 0.171583).  Saving model ...
	 Train_Loss: 0.2710 Train_Acc: 89.046 Val_Loss: 0.1716  BEST VAL Loss: 0.1716  Val_Acc: 94.342

Epoch 40: Validation loss decreased (0.171583 --> 0.170740).  Saving model ...
	 Train_Loss: 0.2701 Train_Acc: 89.013 Val_Loss: 0.1707  BEST VAL Loss: 0.1707  Val_Acc: 94.312

Epoch 41: Validation loss decreased (0.170740 --> 0.169950).  Saving model ...
	 Train_Loss: 0.2693 Train_Acc: 88.869 Val_Loss: 0.1700  BEST VAL Loss: 0.1700  Val_Acc: 94.156

Epoch 42: Validation loss decreased (0.169950 --> 0.169159).  Saving model ...
	 Train_Loss: 0.2685 Train_Acc: 89.012 Val_Loss: 0.1692  BEST VAL Loss: 0.1692  Val_Acc: 94.213

Epoch 43: Validation loss decreased (0.169159 --> 0.168339).  Saving model ...
	 Train_Loss: 0.2677 Train_Acc: 89.002 Val_Loss: 0.1683  BEST VAL Loss: 0.1683  Val_Acc: 94.605

Epoch 44: Validation loss decreased (0.168339 --> 0.167567).  Saving model ...
	 Train_Loss: 0.2670 Train_Acc: 88.939 Val_Loss: 0.1676  BEST VAL Loss: 0.1676  Val_Acc: 94.459

Epoch 45: Validation loss decreased (0.167567 --> 0.167369).  Saving model ...
	 Train_Loss: 0.2663 Train_Acc: 89.008 Val_Loss: 0.1674  BEST VAL Loss: 0.1674  Val_Acc: 92.911

Epoch 46: Validation loss decreased (0.167369 --> 0.166657).  Saving model ...
	 Train_Loss: 0.2656 Train_Acc: 89.072 Val_Loss: 0.1667  BEST VAL Loss: 0.1667  Val_Acc: 94.321

Epoch 47: Validation loss decreased (0.166657 --> 0.165990).  Saving model ...
	 Train_Loss: 0.2649 Train_Acc: 89.095 Val_Loss: 0.1660  BEST VAL Loss: 0.1660  Val_Acc: 94.432

Epoch 48: Validation loss decreased (0.165990 --> 0.165589).  Saving model ...
	 Train_Loss: 0.2642 Train_Acc: 89.119 Val_Loss: 0.1656  BEST VAL Loss: 0.1656  Val_Acc: 93.776

Epoch 49: Validation loss decreased (0.165589 --> 0.165015).  Saving model ...
	 Train_Loss: 0.2636 Train_Acc: 89.087 Val_Loss: 0.1650  BEST VAL Loss: 0.1650  Val_Acc: 94.228

Epoch 50: Validation loss decreased (0.165015 --> 0.164471).  Saving model ...
	 Train_Loss: 0.2630 Train_Acc: 89.115 Val_Loss: 0.1645  BEST VAL Loss: 0.1645  Val_Acc: 94.165

Epoch 51: Validation loss decreased (0.164471 --> 0.163877).  Saving model ...
	 Train_Loss: 0.2624 Train_Acc: 89.169 Val_Loss: 0.1639  BEST VAL Loss: 0.1639  Val_Acc: 94.432

Epoch 52: Validation loss decreased (0.163877 --> 0.163303).  Saving model ...
	 Train_Loss: 0.2618 Train_Acc: 89.143 Val_Loss: 0.1633  BEST VAL Loss: 0.1633  Val_Acc: 94.498

Epoch 53: Validation loss decreased (0.163303 --> 0.162810).  Saving model ...
	 Train_Loss: 0.2613 Train_Acc: 89.064 Val_Loss: 0.1628  BEST VAL Loss: 0.1628  Val_Acc: 94.384

Epoch 54: Validation loss decreased (0.162810 --> 0.162254).  Saving model ...
	 Train_Loss: 0.2607 Train_Acc: 89.142 Val_Loss: 0.1623  BEST VAL Loss: 0.1623  Val_Acc: 94.402

Epoch 55: Validation loss decreased (0.162254 --> 0.161694).  Saving model ...
	 Train_Loss: 0.2602 Train_Acc: 89.188 Val_Loss: 0.1617  BEST VAL Loss: 0.1617  Val_Acc: 94.554

Epoch 56: Validation loss decreased (0.161694 --> 0.161223).  Saving model ...
	 Train_Loss: 0.2596 Train_Acc: 89.193 Val_Loss: 0.1612  BEST VAL Loss: 0.1612  Val_Acc: 94.378

Epoch 57: Validation loss decreased (0.161223 --> 0.160781).  Saving model ...
	 Train_Loss: 0.2591 Train_Acc: 89.285 Val_Loss: 0.1608  BEST VAL Loss: 0.1608  Val_Acc: 94.354

Epoch 58: Validation loss decreased (0.160781 --> 0.160269).  Saving model ...
	 Train_Loss: 0.2586 Train_Acc: 89.194 Val_Loss: 0.1603  BEST VAL Loss: 0.1603  Val_Acc: 94.563

Epoch 59: Validation loss decreased (0.160269 --> 0.159751).  Saving model ...
	 Train_Loss: 0.2582 Train_Acc: 89.208 Val_Loss: 0.1598  BEST VAL Loss: 0.1598  Val_Acc: 94.677

Epoch 60: Validation loss decreased (0.159751 --> 0.159302).  Saving model ...
	 Train_Loss: 0.2577 Train_Acc: 89.336 Val_Loss: 0.1593  BEST VAL Loss: 0.1593  Val_Acc: 94.498

Epoch 61: Validation loss decreased (0.159302 --> 0.158830).  Saving model ...
	 Train_Loss: 0.2572 Train_Acc: 89.265 Val_Loss: 0.1588  BEST VAL Loss: 0.1588  Val_Acc: 94.641

Epoch 62: Validation loss decreased (0.158830 --> 0.158483).  Saving model ...
	 Train_Loss: 0.2568 Train_Acc: 89.274 Val_Loss: 0.1585  BEST VAL Loss: 0.1585  Val_Acc: 94.069

Epoch 63: Validation loss decreased (0.158483 --> 0.158288).  Saving model ...
	 Train_Loss: 0.2563 Train_Acc: 89.293 Val_Loss: 0.1583  BEST VAL Loss: 0.1583  Val_Acc: 93.857

Epoch 64: Validation loss decreased (0.158288 --> 0.157853).  Saving model ...
	 Train_Loss: 0.2559 Train_Acc: 89.315 Val_Loss: 0.1579  BEST VAL Loss: 0.1579  Val_Acc: 94.761

Epoch 65: Validation loss decreased (0.157853 --> 0.157501).  Saving model ...
	 Train_Loss: 0.2555 Train_Acc: 89.211 Val_Loss: 0.1575  BEST VAL Loss: 0.1575  Val_Acc: 94.354

Epoch 66: Validation loss decreased (0.157501 --> 0.157074).  Saving model ...
	 Train_Loss: 0.2551 Train_Acc: 89.314 Val_Loss: 0.1571  BEST VAL Loss: 0.1571  Val_Acc: 94.635

Epoch 67: Validation loss decreased (0.157074 --> 0.156707).  Saving model ...
	 Train_Loss: 0.2547 Train_Acc: 89.322 Val_Loss: 0.1567  BEST VAL Loss: 0.1567  Val_Acc: 94.387

Epoch 68: Validation loss decreased (0.156707 --> 0.156335).  Saving model ...
	 Train_Loss: 0.2543 Train_Acc: 89.318 Val_Loss: 0.1563  BEST VAL Loss: 0.1563  Val_Acc: 94.617

Epoch 69: Validation loss decreased (0.156335 --> 0.156124).  Saving model ...
	 Train_Loss: 0.2539 Train_Acc: 89.321 Val_Loss: 0.1561  BEST VAL Loss: 0.1561  Val_Acc: 93.965

Epoch 70: Validation loss decreased (0.156124 --> 0.155765).  Saving model ...
	 Train_Loss: 0.2535 Train_Acc: 89.320 Val_Loss: 0.1558  BEST VAL Loss: 0.1558  Val_Acc: 94.569

Epoch 71: Validation loss decreased (0.155765 --> 0.155367).  Saving model ...
	 Train_Loss: 0.2532 Train_Acc: 89.416 Val_Loss: 0.1554  BEST VAL Loss: 0.1554  Val_Acc: 94.587

Epoch 72: Validation loss decreased (0.155367 --> 0.155006).  Saving model ...
	 Train_Loss: 0.2528 Train_Acc: 89.388 Val_Loss: 0.1550  BEST VAL Loss: 0.1550  Val_Acc: 94.620

Epoch 73: Validation loss decreased (0.155006 --> 0.154675).  Saving model ...
	 Train_Loss: 0.2524 Train_Acc: 89.413 Val_Loss: 0.1547  BEST VAL Loss: 0.1547  Val_Acc: 94.414

Epoch 74: Validation loss decreased (0.154675 --> 0.154300).  Saving model ...
	 Train_Loss: 0.2521 Train_Acc: 89.301 Val_Loss: 0.1543  BEST VAL Loss: 0.1543  Val_Acc: 94.728

Epoch 75: Validation loss decreased (0.154300 --> 0.153971).  Saving model ...
	 Train_Loss: 0.2518 Train_Acc: 89.393 Val_Loss: 0.1540  BEST VAL Loss: 0.1540  Val_Acc: 94.668

Epoch 76: Validation loss decreased (0.153971 --> 0.153655).  Saving model ...
	 Train_Loss: 0.2514 Train_Acc: 89.308 Val_Loss: 0.1537  BEST VAL Loss: 0.1537  Val_Acc: 94.674

Epoch 77: Validation loss decreased (0.153655 --> 0.153421).  Saving model ...
	 Train_Loss: 0.2511 Train_Acc: 89.288 Val_Loss: 0.1534  BEST VAL Loss: 0.1534  Val_Acc: 94.345

Epoch 78: Validation loss decreased (0.153421 --> 0.153134).  Saving model ...
	 Train_Loss: 0.2508 Train_Acc: 89.356 Val_Loss: 0.1531  BEST VAL Loss: 0.1531  Val_Acc: 94.536

Epoch 79: Validation loss decreased (0.153134 --> 0.152823).  Saving model ...
	 Train_Loss: 0.2505 Train_Acc: 89.489 Val_Loss: 0.1528  BEST VAL Loss: 0.1528  Val_Acc: 94.704

Epoch 80: Validation loss decreased (0.152823 --> 0.152710).  Saving model ...
	 Train_Loss: 0.2502 Train_Acc: 89.446 Val_Loss: 0.1527  BEST VAL Loss: 0.1527  Val_Acc: 93.707

Epoch 81: Validation loss decreased (0.152710 --> 0.152433).  Saving model ...
	 Train_Loss: 0.2499 Train_Acc: 89.383 Val_Loss: 0.1524  BEST VAL Loss: 0.1524  Val_Acc: 94.536

Epoch 82: Validation loss decreased (0.152433 --> 0.152259).  Saving model ...
	 Train_Loss: 0.2496 Train_Acc: 89.386 Val_Loss: 0.1523  BEST VAL Loss: 0.1523  Val_Acc: 94.276

Epoch 83: Validation loss decreased (0.152259 --> 0.152249).  Saving model ...
	 Train_Loss: 0.2493 Train_Acc: 89.359 Val_Loss: 0.1522  BEST VAL Loss: 0.1522  Val_Acc: 93.620

Epoch 84: Validation loss decreased (0.152249 --> 0.151951).  Saving model ...
	 Train_Loss: 0.2490 Train_Acc: 89.474 Val_Loss: 0.1520  BEST VAL Loss: 0.1520  Val_Acc: 94.731

Epoch 85: Validation loss decreased (0.151951 --> 0.151893).  Saving model ...
	 Train_Loss: 0.2488 Train_Acc: 89.480 Val_Loss: 0.1519  BEST VAL Loss: 0.1519  Val_Acc: 94.515

Epoch 86: Validation loss decreased (0.151893 --> 0.151585).  Saving model ...
	 Train_Loss: 0.2485 Train_Acc: 89.482 Val_Loss: 0.1516  BEST VAL Loss: 0.1516  Val_Acc: 94.749

Epoch 87: Validation loss decreased (0.151585 --> 0.151356).  Saving model ...
	 Train_Loss: 0.2482 Train_Acc: 89.473 Val_Loss: 0.1514  BEST VAL Loss: 0.1514  Val_Acc: 94.390

Epoch 88: Validation loss decreased (0.151356 --> 0.151088).  Saving model ...
	 Train_Loss: 0.2480 Train_Acc: 89.422 Val_Loss: 0.1511  BEST VAL Loss: 0.1511  Val_Acc: 94.701

Epoch 89: Validation loss decreased (0.151088 --> 0.150905).  Saving model ...
	 Train_Loss: 0.2477 Train_Acc: 89.502 Val_Loss: 0.1509  BEST VAL Loss: 0.1509  Val_Acc: 94.459

Epoch 90: Validation loss decreased (0.150905 --> 0.150646).  Saving model ...
	 Train_Loss: 0.2474 Train_Acc: 89.480 Val_Loss: 0.1506  BEST VAL Loss: 0.1506  Val_Acc: 94.674

Epoch 91: Validation loss decreased (0.150646 --> 0.150408).  Saving model ...
	 Train_Loss: 0.2472 Train_Acc: 89.491 Val_Loss: 0.1504  BEST VAL Loss: 0.1504  Val_Acc: 94.614

Epoch 92: Validation loss decreased (0.150408 --> 0.150174).  Saving model ...
	 Train_Loss: 0.2469 Train_Acc: 89.529 Val_Loss: 0.1502  BEST VAL Loss: 0.1502  Val_Acc: 94.728

Epoch 93: Validation loss decreased (0.150174 --> 0.149981).  Saving model ...
	 Train_Loss: 0.2467 Train_Acc: 89.491 Val_Loss: 0.1500  BEST VAL Loss: 0.1500  Val_Acc: 94.417

Epoch 94: Validation loss decreased (0.149981 --> 0.149734).  Saving model ...
	 Train_Loss: 0.2464 Train_Acc: 89.519 Val_Loss: 0.1497  BEST VAL Loss: 0.1497  Val_Acc: 94.689

Epoch 95: Validation loss decreased (0.149734 --> 0.149502).  Saving model ...
	 Train_Loss: 0.2462 Train_Acc: 89.461 Val_Loss: 0.1495  BEST VAL Loss: 0.1495  Val_Acc: 94.782

Epoch 96: Validation loss decreased (0.149502 --> 0.149275).  Saving model ...
	 Train_Loss: 0.2460 Train_Acc: 89.521 Val_Loss: 0.1493  BEST VAL Loss: 0.1493  Val_Acc: 94.788

Epoch 97: Validation loss decreased (0.149275 --> 0.149062).  Saving model ...
	 Train_Loss: 0.2457 Train_Acc: 89.471 Val_Loss: 0.1491  BEST VAL Loss: 0.1491  Val_Acc: 94.755

Epoch 98: Validation loss decreased (0.149062 --> 0.148844).  Saving model ...
	 Train_Loss: 0.2455 Train_Acc: 89.533 Val_Loss: 0.1488  BEST VAL Loss: 0.1488  Val_Acc: 94.716

Epoch 99: Validation loss decreased (0.148844 --> 0.148616).  Saving model ...
	 Train_Loss: 0.2453 Train_Acc: 89.558 Val_Loss: 0.1486  BEST VAL Loss: 0.1486  Val_Acc: 94.740

Thapsigargin_10.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.96      0.98      0.97    169561
           1       0.96      0.93      0.94     97655

    accuracy                           0.96    267216
   macro avg       0.96      0.95      0.96    267216
weighted avg       0.96      0.96      0.96    267216

Thapsigargin_10.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.95      0.97      0.96     21196
           1       0.94      0.91      0.93     12207

    accuracy                           0.95     33403
   macro avg       0.95      0.94      0.94     33403
weighted avg       0.95      0.95      0.95     33403

Thapsigargin_10.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.95      0.97      0.96     21195
           1       0.95      0.91      0.93     12207

    accuracy                           0.95     33402
   macro avg       0.95      0.94      0.95     33402
weighted avg       0.95      0.95      0.95     33402

              precision    recall  f1-score   support

           0       0.95      0.97      0.96     21195
           1       0.95      0.91      0.93     12207

    accuracy                           0.95     33402
   macro avg       0.95      0.94      0.95     33402
weighted avg       0.95      0.95      0.95     33402

Thapsigargin_10.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Thapsigargin_10.000_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.82      0.96      0.89     28584
           1       0.97      0.87      0.92     44915

    accuracy                           0.91     73499
   macro avg       0.90      0.92      0.90     73499
weighted avg       0.91      0.91      0.91     73499

              precision    recall  f1-score   support

           0       0.82      0.96      0.89     28584
           1       0.97      0.87      0.92     44915

    accuracy                           0.91     73499
   macro avg       0.90      0.92      0.90     73499
weighted avg       0.91      0.91      0.91     73499

completed
