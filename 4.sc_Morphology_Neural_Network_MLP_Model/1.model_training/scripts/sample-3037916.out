[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd1707565'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'c71b1bdb'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '65651e90'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '64b3c77f'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_0.010_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_0.010_DMSO_0.025
TREATMENT_NAME: Flagellin_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (247627, 1270)
Number of total missing values across all columns: 531870
Data Subset Is Off
Wells held out for testing: ['B09' 'M10']
Wells to use for training, validation, and testing ['B02' 'B03' 'B08' 'M05' 'M11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.622398).  Saving model ...
	 Train_Loss: 0.6546 Train_Acc: 59.855 Val_Loss: 0.6224  BEST VAL Loss: 0.6224  Val_Acc: 66.065

Epoch 1: Validation loss decreased (0.622398 --> 0.605033).  Saving model ...
	 Train_Loss: 0.6308 Train_Acc: 67.643 Val_Loss: 0.6050  BEST VAL Loss: 0.6050  Val_Acc: 70.645

Epoch 2: Validation loss decreased (0.605033 --> 0.589983).  Saving model ...
	 Train_Loss: 0.6123 Train_Acc: 71.071 Val_Loss: 0.5900  BEST VAL Loss: 0.5900  Val_Acc: 73.071

Epoch 3: Validation loss decreased (0.589983 --> 0.577001).  Saving model ...
	 Train_Loss: 0.5974 Train_Acc: 72.659 Val_Loss: 0.5770  BEST VAL Loss: 0.5770  Val_Acc: 74.495

Epoch 4: Validation loss decreased (0.577001 --> 0.565988).  Saving model ...
	 Train_Loss: 0.5849 Train_Acc: 73.822 Val_Loss: 0.5660  BEST VAL Loss: 0.5660  Val_Acc: 75.366

Epoch 5: Validation loss decreased (0.565988 --> 0.556380).  Saving model ...
	 Train_Loss: 0.5743 Train_Acc: 74.655 Val_Loss: 0.5564  BEST VAL Loss: 0.5564  Val_Acc: 76.316

Epoch 6: Validation loss decreased (0.556380 --> 0.548367).  Saving model ...
	 Train_Loss: 0.5650 Train_Acc: 75.325 Val_Loss: 0.5484  BEST VAL Loss: 0.5484  Val_Acc: 76.740

Epoch 7: Validation loss decreased (0.548367 --> 0.541432).  Saving model ...
	 Train_Loss: 0.5569 Train_Acc: 75.988 Val_Loss: 0.5414  BEST VAL Loss: 0.5414  Val_Acc: 76.808

Epoch 8: Validation loss decreased (0.541432 --> 0.535356).  Saving model ...
	 Train_Loss: 0.5498 Train_Acc: 76.347 Val_Loss: 0.5354  BEST VAL Loss: 0.5354  Val_Acc: 77.390

Epoch 9: Validation loss decreased (0.535356 --> 0.529840).  Saving model ...
	 Train_Loss: 0.5435 Train_Acc: 76.624 Val_Loss: 0.5298  BEST VAL Loss: 0.5298  Val_Acc: 77.554

Epoch 10: Validation loss decreased (0.529840 --> 0.524865).  Saving model ...
	 Train_Loss: 0.5379 Train_Acc: 76.949 Val_Loss: 0.5249  BEST VAL Loss: 0.5249  Val_Acc: 78.170

Epoch 11: Validation loss decreased (0.524865 --> 0.520332).  Saving model ...
	 Train_Loss: 0.5328 Train_Acc: 77.359 Val_Loss: 0.5203  BEST VAL Loss: 0.5203  Val_Acc: 78.108

Epoch 12: Validation loss decreased (0.520332 --> 0.516190).  Saving model ...
	 Train_Loss: 0.5281 Train_Acc: 77.592 Val_Loss: 0.5162  BEST VAL Loss: 0.5162  Val_Acc: 78.419

Epoch 13: Validation loss decreased (0.516190 --> 0.512401).  Saving model ...
	 Train_Loss: 0.5238 Train_Acc: 77.872 Val_Loss: 0.5124  BEST VAL Loss: 0.5124  Val_Acc: 78.611

Epoch 14: Validation loss decreased (0.512401 --> 0.508879).  Saving model ...
	 Train_Loss: 0.5198 Train_Acc: 78.016 Val_Loss: 0.5089  BEST VAL Loss: 0.5089  Val_Acc: 78.702

Epoch 15: Validation loss decreased (0.508879 --> 0.505687).  Saving model ...
	 Train_Loss: 0.5162 Train_Acc: 78.174 Val_Loss: 0.5057  BEST VAL Loss: 0.5057  Val_Acc: 78.634

Epoch 16: Validation loss decreased (0.505687 --> 0.502634).  Saving model ...
	 Train_Loss: 0.5128 Train_Acc: 78.442 Val_Loss: 0.5026  BEST VAL Loss: 0.5026  Val_Acc: 78.860

Epoch 17: Validation loss decreased (0.502634 --> 0.499751).  Saving model ...
	 Train_Loss: 0.5095 Train_Acc: 78.539 Val_Loss: 0.4998  BEST VAL Loss: 0.4998  Val_Acc: 79.352

Epoch 18: Validation loss decreased (0.499751 --> 0.497241).  Saving model ...
	 Train_Loss: 0.5064 Train_Acc: 78.732 Val_Loss: 0.4972  BEST VAL Loss: 0.4972  Val_Acc: 79.024

Epoch 19: Validation loss decreased (0.497241 --> 0.494782).  Saving model ...
	 Train_Loss: 0.5036 Train_Acc: 78.868 Val_Loss: 0.4948  BEST VAL Loss: 0.4948  Val_Acc: 79.335

Epoch 20: Validation loss decreased (0.494782 --> 0.492300).  Saving model ...
	 Train_Loss: 0.5008 Train_Acc: 79.128 Val_Loss: 0.4923  BEST VAL Loss: 0.4923  Val_Acc: 79.657

Epoch 21: Validation loss decreased (0.492300 --> 0.490055).  Saving model ...
	 Train_Loss: 0.4983 Train_Acc: 79.073 Val_Loss: 0.4901  BEST VAL Loss: 0.4901  Val_Acc: 79.623

Epoch 22: Validation loss decreased (0.490055 --> 0.487939).  Saving model ...
	 Train_Loss: 0.4959 Train_Acc: 79.198 Val_Loss: 0.4879  BEST VAL Loss: 0.4879  Val_Acc: 79.821

Epoch 23: Validation loss decreased (0.487939 --> 0.485979).  Saving model ...
	 Train_Loss: 0.4935 Train_Acc: 79.375 Val_Loss: 0.4860  BEST VAL Loss: 0.4860  Val_Acc: 79.731

Epoch 24: Validation loss decreased (0.485979 --> 0.484115).  Saving model ...
	 Train_Loss: 0.4913 Train_Acc: 79.515 Val_Loss: 0.4841  BEST VAL Loss: 0.4841  Val_Acc: 79.816

Epoch 25: Validation loss decreased (0.484115 --> 0.482149).  Saving model ...
	 Train_Loss: 0.4892 Train_Acc: 79.620 Val_Loss: 0.4821  BEST VAL Loss: 0.4821  Val_Acc: 80.211

Epoch 26: Validation loss decreased (0.482149 --> 0.480326).  Saving model ...
	 Train_Loss: 0.4872 Train_Acc: 79.665 Val_Loss: 0.4803  BEST VAL Loss: 0.4803  Val_Acc: 79.929

Epoch 27: Validation loss decreased (0.480326 --> 0.478650).  Saving model ...
	 Train_Loss: 0.4853 Train_Acc: 79.631 Val_Loss: 0.4787  BEST VAL Loss: 0.4787  Val_Acc: 80.053

Epoch 28: Validation loss decreased (0.478650 --> 0.477088).  Saving model ...
	 Train_Loss: 0.4834 Train_Acc: 79.787 Val_Loss: 0.4771  BEST VAL Loss: 0.4771  Val_Acc: 79.968

Epoch 29: Validation loss decreased (0.477088 --> 0.475579).  Saving model ...
	 Train_Loss: 0.4817 Train_Acc: 79.821 Val_Loss: 0.4756  BEST VAL Loss: 0.4756  Val_Acc: 80.014

Epoch 30: Validation loss decreased (0.475579 --> 0.474141).  Saving model ...
	 Train_Loss: 0.4800 Train_Acc: 79.964 Val_Loss: 0.4741  BEST VAL Loss: 0.4741  Val_Acc: 80.002

Epoch 31: Validation loss decreased (0.474141 --> 0.472716).  Saving model ...
	 Train_Loss: 0.4784 Train_Acc: 80.092 Val_Loss: 0.4727  BEST VAL Loss: 0.4727  Val_Acc: 80.228

Epoch 32: Validation loss decreased (0.472716 --> 0.471398).  Saving model ...
	 Train_Loss: 0.4768 Train_Acc: 80.127 Val_Loss: 0.4714  BEST VAL Loss: 0.4714  Val_Acc: 79.946

Epoch 33: Validation loss decreased (0.471398 --> 0.470351).  Saving model ...
	 Train_Loss: 0.4753 Train_Acc: 80.089 Val_Loss: 0.4704  BEST VAL Loss: 0.4704  Val_Acc: 80.127

Epoch 34: Validation loss decreased (0.470351 --> 0.469134).  Saving model ...
	 Train_Loss: 0.4738 Train_Acc: 80.211 Val_Loss: 0.4691  BEST VAL Loss: 0.4691  Val_Acc: 80.488

Epoch 35: Validation loss decreased (0.469134 --> 0.467907).  Saving model ...
	 Train_Loss: 0.4724 Train_Acc: 80.287 Val_Loss: 0.4679  BEST VAL Loss: 0.4679  Val_Acc: 80.466

Epoch 36: Validation loss decreased (0.467907 --> 0.466767).  Saving model ...
	 Train_Loss: 0.4711 Train_Acc: 80.291 Val_Loss: 0.4668  BEST VAL Loss: 0.4668  Val_Acc: 80.347

Epoch 37: Validation loss decreased (0.466767 --> 0.465622).  Saving model ...
	 Train_Loss: 0.4698 Train_Acc: 80.418 Val_Loss: 0.4656  BEST VAL Loss: 0.4656  Val_Acc: 80.619

Epoch 38: Validation loss decreased (0.465622 --> 0.464542).  Saving model ...
	 Train_Loss: 0.4685 Train_Acc: 80.304 Val_Loss: 0.4645  BEST VAL Loss: 0.4645  Val_Acc: 80.562

Epoch 39: Validation loss decreased (0.464542 --> 0.463626).  Saving model ...
	 Train_Loss: 0.4673 Train_Acc: 80.366 Val_Loss: 0.4636  BEST VAL Loss: 0.4636  Val_Acc: 80.223

Epoch 40: Validation loss decreased (0.463626 --> 0.462736).  Saving model ...
	 Train_Loss: 0.4661 Train_Acc: 80.484 Val_Loss: 0.4627  BEST VAL Loss: 0.4627  Val_Acc: 80.330

Epoch 41: Validation loss decreased (0.462736 --> 0.461748).  Saving model ...
	 Train_Loss: 0.4650 Train_Acc: 80.522 Val_Loss: 0.4617  BEST VAL Loss: 0.4617  Val_Acc: 80.635

Epoch 42: Validation loss decreased (0.461748 --> 0.460889).  Saving model ...
	 Train_Loss: 0.4639 Train_Acc: 80.557 Val_Loss: 0.4609  BEST VAL Loss: 0.4609  Val_Acc: 80.330

Epoch 43: Validation loss decreased (0.460889 --> 0.459958).  Saving model ...
	 Train_Loss: 0.4628 Train_Acc: 80.529 Val_Loss: 0.4600  BEST VAL Loss: 0.4600  Val_Acc: 80.743

Epoch 44: Validation loss decreased (0.459958 --> 0.459177).  Saving model ...
	 Train_Loss: 0.4617 Train_Acc: 80.670 Val_Loss: 0.4592  BEST VAL Loss: 0.4592  Val_Acc: 80.771

Epoch 45: Validation loss decreased (0.459177 --> 0.458293).  Saving model ...
	 Train_Loss: 0.4607 Train_Acc: 80.714 Val_Loss: 0.4583  BEST VAL Loss: 0.4583  Val_Acc: 80.828

Epoch 46: Validation loss decreased (0.458293 --> 0.457493).  Saving model ...
	 Train_Loss: 0.4597 Train_Acc: 80.716 Val_Loss: 0.4575  BEST VAL Loss: 0.4575  Val_Acc: 80.703

Epoch 47: Validation loss decreased (0.457493 --> 0.456731).  Saving model ...
	 Train_Loss: 0.4588 Train_Acc: 80.726 Val_Loss: 0.4567  BEST VAL Loss: 0.4567  Val_Acc: 80.630

Epoch 48: Validation loss decreased (0.456731 --> 0.455986).  Saving model ...
	 Train_Loss: 0.4578 Train_Acc: 80.826 Val_Loss: 0.4560  BEST VAL Loss: 0.4560  Val_Acc: 80.505

Epoch 49: Validation loss decreased (0.455986 --> 0.455264).  Saving model ...
	 Train_Loss: 0.4569 Train_Acc: 80.766 Val_Loss: 0.4553  BEST VAL Loss: 0.4553  Val_Acc: 80.703

Epoch 50: Validation loss decreased (0.455264 --> 0.454525).  Saving model ...
	 Train_Loss: 0.4560 Train_Acc: 80.834 Val_Loss: 0.4545  BEST VAL Loss: 0.4545  Val_Acc: 80.980

Epoch 51: Validation loss decreased (0.454525 --> 0.453916).  Saving model ...
	 Train_Loss: 0.4552 Train_Acc: 80.947 Val_Loss: 0.4539  BEST VAL Loss: 0.4539  Val_Acc: 80.896

Epoch 52: Validation loss decreased (0.453916 --> 0.453246).  Saving model ...
	 Train_Loss: 0.4543 Train_Acc: 80.953 Val_Loss: 0.4532  BEST VAL Loss: 0.4532  Val_Acc: 80.828

Epoch 53: Validation loss decreased (0.453246 --> 0.452536).  Saving model ...
	 Train_Loss: 0.4535 Train_Acc: 80.940 Val_Loss: 0.4525  BEST VAL Loss: 0.4525  Val_Acc: 81.076

Epoch 54: Validation loss decreased (0.452536 --> 0.451852).  Saving model ...
	 Train_Loss: 0.4527 Train_Acc: 80.962 Val_Loss: 0.4519  BEST VAL Loss: 0.4519  Val_Acc: 80.975

Epoch 55: Validation loss decreased (0.451852 --> 0.451215).  Saving model ...
	 Train_Loss: 0.4519 Train_Acc: 80.882 Val_Loss: 0.4512  BEST VAL Loss: 0.4512  Val_Acc: 80.924

Epoch 56: Validation loss decreased (0.451215 --> 0.450793).  Saving model ...
	 Train_Loss: 0.4511 Train_Acc: 81.000 Val_Loss: 0.4508  BEST VAL Loss: 0.4508  Val_Acc: 80.449

Epoch 57: Validation loss decreased (0.450793 --> 0.450158).  Saving model ...
	 Train_Loss: 0.4504 Train_Acc: 80.956 Val_Loss: 0.4502  BEST VAL Loss: 0.4502  Val_Acc: 81.263

Epoch 58: Validation loss decreased (0.450158 --> 0.449534).  Saving model ...
	 Train_Loss: 0.4496 Train_Acc: 81.137 Val_Loss: 0.4495  BEST VAL Loss: 0.4495  Val_Acc: 81.014

Epoch 59: Validation loss decreased (0.449534 --> 0.448919).  Saving model ...
	 Train_Loss: 0.4489 Train_Acc: 81.193 Val_Loss: 0.4489  BEST VAL Loss: 0.4489  Val_Acc: 81.060

Epoch 60: Validation loss decreased (0.448919 --> 0.448314).  Saving model ...
	 Train_Loss: 0.4482 Train_Acc: 81.184 Val_Loss: 0.4483  BEST VAL Loss: 0.4483  Val_Acc: 81.156

Epoch 61: Validation loss decreased (0.448314 --> 0.447721).  Saving model ...
	 Train_Loss: 0.4475 Train_Acc: 81.046 Val_Loss: 0.4477  BEST VAL Loss: 0.4477  Val_Acc: 81.223

Epoch 62: Validation loss decreased (0.447721 --> 0.447173).  Saving model ...
	 Train_Loss: 0.4468 Train_Acc: 81.172 Val_Loss: 0.4472  BEST VAL Loss: 0.4472  Val_Acc: 81.054

Epoch 63: Validation loss decreased (0.447173 --> 0.446602).  Saving model ...
	 Train_Loss: 0.4461 Train_Acc: 81.171 Val_Loss: 0.4466  BEST VAL Loss: 0.4466  Val_Acc: 81.060

Epoch 64: Validation loss decreased (0.446602 --> 0.446093).  Saving model ...
	 Train_Loss: 0.4455 Train_Acc: 81.169 Val_Loss: 0.4461  BEST VAL Loss: 0.4461  Val_Acc: 81.127

Epoch 65: Validation loss decreased (0.446093 --> 0.445563).  Saving model ...
	 Train_Loss: 0.4448 Train_Acc: 81.246 Val_Loss: 0.4456  BEST VAL Loss: 0.4456  Val_Acc: 81.246

Epoch 66: Validation loss decreased (0.445563 --> 0.445059).  Saving model ...
	 Train_Loss: 0.4442 Train_Acc: 81.173 Val_Loss: 0.4451  BEST VAL Loss: 0.4451  Val_Acc: 81.348

Epoch 67: Validation loss decreased (0.445059 --> 0.444535).  Saving model ...
	 Train_Loss: 0.4436 Train_Acc: 81.200 Val_Loss: 0.4445  BEST VAL Loss: 0.4445  Val_Acc: 81.337

Epoch 68: Validation loss decreased (0.444535 --> 0.444056).  Saving model ...
	 Train_Loss: 0.4430 Train_Acc: 81.323 Val_Loss: 0.4441  BEST VAL Loss: 0.4441  Val_Acc: 81.393

Epoch 69: Validation loss decreased (0.444056 --> 0.443569).  Saving model ...
	 Train_Loss: 0.4424 Train_Acc: 81.290 Val_Loss: 0.4436  BEST VAL Loss: 0.4436  Val_Acc: 81.031

Epoch 70: Validation loss decreased (0.443569 --> 0.443108).  Saving model ...
	 Train_Loss: 0.4418 Train_Acc: 81.220 Val_Loss: 0.4431  BEST VAL Loss: 0.4431  Val_Acc: 81.269

Epoch 71: Validation loss decreased (0.443108 --> 0.442674).  Saving model ...
	 Train_Loss: 0.4412 Train_Acc: 81.344 Val_Loss: 0.4427  BEST VAL Loss: 0.4427  Val_Acc: 81.190

Epoch 72: Validation loss decreased (0.442674 --> 0.442234).  Saving model ...
	 Train_Loss: 0.4407 Train_Acc: 81.335 Val_Loss: 0.4422  BEST VAL Loss: 0.4422  Val_Acc: 81.195

Epoch 73: Validation loss decreased (0.442234 --> 0.441799).  Saving model ...
	 Train_Loss: 0.4401 Train_Acc: 81.364 Val_Loss: 0.4418  BEST VAL Loss: 0.4418  Val_Acc: 81.291

Epoch 74: Validation loss decreased (0.441799 --> 0.441353).  Saving model ...
	 Train_Loss: 0.4396 Train_Acc: 81.430 Val_Loss: 0.4414  BEST VAL Loss: 0.4414  Val_Acc: 81.303

Epoch 75: Validation loss decreased (0.441353 --> 0.440969).  Saving model ...
	 Train_Loss: 0.4390 Train_Acc: 81.351 Val_Loss: 0.4410  BEST VAL Loss: 0.4410  Val_Acc: 81.404

Epoch 76: Validation loss decreased (0.440969 --> 0.440572).  Saving model ...
	 Train_Loss: 0.4385 Train_Acc: 81.348 Val_Loss: 0.4406  BEST VAL Loss: 0.4406  Val_Acc: 81.116

Epoch 77: Validation loss decreased (0.440572 --> 0.440202).  Saving model ...
	 Train_Loss: 0.4380 Train_Acc: 81.451 Val_Loss: 0.4402  BEST VAL Loss: 0.4402  Val_Acc: 81.455

Epoch 78: Validation loss decreased (0.440202 --> 0.439799).  Saving model ...
	 Train_Loss: 0.4375 Train_Acc: 81.350 Val_Loss: 0.4398  BEST VAL Loss: 0.4398  Val_Acc: 81.501

Epoch 79: Validation loss decreased (0.439799 --> 0.439502).  Saving model ...
	 Train_Loss: 0.4370 Train_Acc: 81.472 Val_Loss: 0.4395  BEST VAL Loss: 0.4395  Val_Acc: 81.223

Epoch 80: Validation loss decreased (0.439502 --> 0.439149).  Saving model ...
	 Train_Loss: 0.4365 Train_Acc: 81.522 Val_Loss: 0.4391  BEST VAL Loss: 0.4391  Val_Acc: 81.444

Epoch 81: Validation loss decreased (0.439149 --> 0.438766).  Saving model ...
	 Train_Loss: 0.4360 Train_Acc: 81.591 Val_Loss: 0.4388  BEST VAL Loss: 0.4388  Val_Acc: 81.489

Epoch 82: Validation loss decreased (0.438766 --> 0.438410).  Saving model ...
	 Train_Loss: 0.4355 Train_Acc: 81.456 Val_Loss: 0.4384  BEST VAL Loss: 0.4384  Val_Acc: 81.495

Epoch 83: Validation loss decreased (0.438410 --> 0.438035).  Saving model ...
	 Train_Loss: 0.4350 Train_Acc: 81.468 Val_Loss: 0.4380  BEST VAL Loss: 0.4380  Val_Acc: 81.342

Epoch 84: Validation loss decreased (0.438035 --> 0.437801).  Saving model ...
	 Train_Loss: 0.4346 Train_Acc: 81.532 Val_Loss: 0.4378  BEST VAL Loss: 0.4378  Val_Acc: 81.105

Epoch 85: Validation loss decreased (0.437801 --> 0.437420).  Saving model ...
	 Train_Loss: 0.4341 Train_Acc: 81.701 Val_Loss: 0.4374  BEST VAL Loss: 0.4374  Val_Acc: 81.540

Epoch 86: Validation loss decreased (0.437420 --> 0.437059).  Saving model ...
	 Train_Loss: 0.4337 Train_Acc: 81.593 Val_Loss: 0.4371  BEST VAL Loss: 0.4371  Val_Acc: 81.891

Epoch 87: Validation loss decreased (0.437059 --> 0.436709).  Saving model ...
	 Train_Loss: 0.4332 Train_Acc: 81.670 Val_Loss: 0.4367  BEST VAL Loss: 0.4367  Val_Acc: 81.715

Epoch 88: Validation loss decreased (0.436709 --> 0.436399).  Saving model ...
	 Train_Loss: 0.4328 Train_Acc: 81.608 Val_Loss: 0.4364  BEST VAL Loss: 0.4364  Val_Acc: 81.704

Epoch 89: Validation loss decreased (0.436399 --> 0.436069).  Saving model ...
	 Train_Loss: 0.4323 Train_Acc: 81.651 Val_Loss: 0.4361  BEST VAL Loss: 0.4361  Val_Acc: 81.512

Epoch 90: Validation loss decreased (0.436069 --> 0.435708).  Saving model ...
	 Train_Loss: 0.4319 Train_Acc: 81.598 Val_Loss: 0.4357  BEST VAL Loss: 0.4357  Val_Acc: 81.438

Epoch 91: Validation loss decreased (0.435708 --> 0.435358).  Saving model ...
	 Train_Loss: 0.4315 Train_Acc: 81.655 Val_Loss: 0.4354  BEST VAL Loss: 0.4354  Val_Acc: 81.461

Epoch 92: Validation loss decreased (0.435358 --> 0.435045).  Saving model ...
	 Train_Loss: 0.4310 Train_Acc: 81.655 Val_Loss: 0.4350  BEST VAL Loss: 0.4350  Val_Acc: 81.591

Epoch 93: Validation loss decreased (0.435045 --> 0.434747).  Saving model ...
	 Train_Loss: 0.4307 Train_Acc: 81.567 Val_Loss: 0.4347  BEST VAL Loss: 0.4347  Val_Acc: 81.337

Epoch 94: Validation loss decreased (0.434747 --> 0.434509).  Saving model ...
	 Train_Loss: 0.4302 Train_Acc: 81.681 Val_Loss: 0.4345  BEST VAL Loss: 0.4345  Val_Acc: 81.551

Epoch 95: Validation loss decreased (0.434509 --> 0.434199).  Saving model ...
	 Train_Loss: 0.4298 Train_Acc: 81.658 Val_Loss: 0.4342  BEST VAL Loss: 0.4342  Val_Acc: 81.484

Epoch 96: Validation loss decreased (0.434199 --> 0.433949).  Saving model ...
	 Train_Loss: 0.4295 Train_Acc: 81.622 Val_Loss: 0.4339  BEST VAL Loss: 0.4339  Val_Acc: 81.065

Epoch 97: Validation loss decreased (0.433949 --> 0.433653).  Saving model ...
	 Train_Loss: 0.4291 Train_Acc: 81.682 Val_Loss: 0.4337  BEST VAL Loss: 0.4337  Val_Acc: 81.896

Epoch 98: Validation loss decreased (0.433653 --> 0.433363).  Saving model ...
	 Train_Loss: 0.4287 Train_Acc: 81.734 Val_Loss: 0.4334  BEST VAL Loss: 0.4334  Val_Acc: 81.410

Epoch 99: Validation loss decreased (0.433363 --> 0.433110).  Saving model ...
	 Train_Loss: 0.4283 Train_Acc: 81.818 Val_Loss: 0.4331  BEST VAL Loss: 0.4331  Val_Acc: 81.348

LPS_0.010_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.40      0.36      0.38     56123
           1       0.60      0.65      0.63     85370

    accuracy                           0.53    141493
   macro avg       0.50      0.50      0.50    141493
weighted avg       0.52      0.53      0.53    141493

LPS_0.010_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.40      0.36      0.38      7015
           1       0.60      0.65      0.63     10672

    accuracy                           0.53     17687
   macro avg       0.50      0.50      0.50     17687
weighted avg       0.52      0.53      0.53     17687

LPS_0.010_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.40      0.36      0.38      7015
           1       0.61      0.65      0.63     10672

    accuracy                           0.54     17687
   macro avg       0.51      0.51      0.50     17687
weighted avg       0.53      0.54      0.53     17687

              precision    recall  f1-score   support

           0       0.40      0.36      0.38      7015
           1       0.61      0.65      0.63     10672

    accuracy                           0.54     17687
   macro avg       0.51      0.51      0.50     17687
weighted avg       0.53      0.54      0.53     17687

LPS_0.010_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_Flagellin_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.48      0.23      0.31     34394
           1       0.51      0.77      0.62     36366

    accuracy                           0.51     70760
   macro avg       0.50      0.50      0.46     70760
weighted avg       0.50      0.51      0.47     70760

              precision    recall  f1-score   support

           0       0.48      0.23      0.31     34394
           1       0.51      0.77      0.62     36366

    accuracy                           0.51     70760
   macro avg       0.50      0.50      0.46     70760
weighted avg       0.50      0.51      0.47     70760

completed
