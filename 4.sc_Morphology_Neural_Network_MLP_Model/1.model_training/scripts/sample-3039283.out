[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '315b3c6b'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '412ddd6d'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'e4cbfecf'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '221c8217'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_0.100_DMSO_0.025 treatment_name: H2O2_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: H2O2_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['H2O2_100.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (41828, 1276)
Number of total missing values across all columns: 83656
Data Subset Is Off
Wells held out for testing: ['I22' 'L22']
Wells to use for training, validation, and testing ['H18' 'H19' 'H22' 'H23' 'I18' 'L18' 'I19' 'L19' 'I23' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.590256).  Saving model ...
	 Train_Loss: 0.6188 Train_Acc: 68.627 Val_Loss: 0.5903  BEST VAL Loss: 0.5903  Val_Acc: 68.941

Epoch 1: Validation loss decreased (0.590256 --> 0.581893).  Saving model ...
	 Train_Loss: 0.6048 Train_Acc: 68.925 Val_Loss: 0.5819  BEST VAL Loss: 0.5819  Val_Acc: 68.941

Epoch 2: Validation loss decreased (0.581893 --> 0.573190).  Saving model ...
	 Train_Loss: 0.5941 Train_Acc: 68.922 Val_Loss: 0.5732  BEST VAL Loss: 0.5732  Val_Acc: 68.941

Epoch 3: Validation loss decreased (0.573190 --> 0.567381).  Saving model ...
	 Train_Loss: 0.5858 Train_Acc: 68.915 Val_Loss: 0.5674  BEST VAL Loss: 0.5674  Val_Acc: 68.941

Epoch 4: Validation loss decreased (0.567381 --> 0.562948).  Saving model ...
	 Train_Loss: 0.5794 Train_Acc: 68.925 Val_Loss: 0.5629  BEST VAL Loss: 0.5629  Val_Acc: 68.941

Epoch 5: Validation loss decreased (0.562948 --> 0.558994).  Saving model ...
	 Train_Loss: 0.5734 Train_Acc: 68.925 Val_Loss: 0.5590  BEST VAL Loss: 0.5590  Val_Acc: 68.941

Epoch 6: Validation loss decreased (0.558994 --> 0.556372).  Saving model ...
	 Train_Loss: 0.5681 Train_Acc: 68.925 Val_Loss: 0.5564  BEST VAL Loss: 0.5564  Val_Acc: 68.941

Epoch 7: Validation loss decreased (0.556372 --> 0.553556).  Saving model ...
	 Train_Loss: 0.5635 Train_Acc: 69.548 Val_Loss: 0.5536  BEST VAL Loss: 0.5536  Val_Acc: 68.941

Epoch 8: Validation loss decreased (0.553556 --> 0.550842).  Saving model ...
	 Train_Loss: 0.5595 Train_Acc: 71.185 Val_Loss: 0.5508  BEST VAL Loss: 0.5508  Val_Acc: 71.992

Epoch 9: Validation loss decreased (0.550842 --> 0.548703).  Saving model ...
	 Train_Loss: 0.5556 Train_Acc: 72.204 Val_Loss: 0.5487  BEST VAL Loss: 0.5487  Val_Acc: 72.712

Epoch 10: Validation loss decreased (0.548703 --> 0.546471).  Saving model ...
	 Train_Loss: 0.5521 Train_Acc: 72.539 Val_Loss: 0.5465  BEST VAL Loss: 0.5465  Val_Acc: 71.877

Epoch 11: Validation loss decreased (0.546471 --> 0.545355).  Saving model ...
	 Train_Loss: 0.5489 Train_Acc: 72.582 Val_Loss: 0.5454  BEST VAL Loss: 0.5454  Val_Acc: 71.330

Epoch 12: Validation loss decreased (0.545355 --> 0.543656).  Saving model ...
	 Train_Loss: 0.5460 Train_Acc: 72.852 Val_Loss: 0.5437  BEST VAL Loss: 0.5437  Val_Acc: 72.222

Epoch 13: Validation loss decreased (0.543656 --> 0.542773).  Saving model ...
	 Train_Loss: 0.5431 Train_Acc: 73.424 Val_Loss: 0.5428  BEST VAL Loss: 0.5428  Val_Acc: 70.927

Epoch 14: Validation loss decreased (0.542773 --> 0.541802).  Saving model ...
	 Train_Loss: 0.5408 Train_Acc: 73.215 Val_Loss: 0.5418  BEST VAL Loss: 0.5418  Val_Acc: 71.733

Epoch 15: Validation loss decreased (0.541802 --> 0.540796).  Saving model ...
	 Train_Loss: 0.5384 Train_Acc: 73.309 Val_Loss: 0.5408  BEST VAL Loss: 0.5408  Val_Acc: 72.309

Epoch 16: Validation loss decreased (0.540796 --> 0.539613).  Saving model ...
	 Train_Loss: 0.5359 Train_Acc: 73.751 Val_Loss: 0.5396  BEST VAL Loss: 0.5396  Val_Acc: 72.309

Epoch 17: Validation loss decreased (0.539613 --> 0.538850).  Saving model ...
	 Train_Loss: 0.5340 Train_Acc: 73.719 Val_Loss: 0.5388  BEST VAL Loss: 0.5388  Val_Acc: 72.395

Epoch 18: Validation loss decreased (0.538850 --> 0.538006).  Saving model ...
	 Train_Loss: 0.5318 Train_Acc: 74.043 Val_Loss: 0.5380  BEST VAL Loss: 0.5380  Val_Acc: 72.395

Epoch 19: Validation loss decreased (0.538006 --> 0.536855).  Saving model ...
	 Train_Loss: 0.5299 Train_Acc: 74.676 Val_Loss: 0.5369  BEST VAL Loss: 0.5369  Val_Acc: 72.050

Epoch 20: Validation loss decreased (0.536855 --> 0.536295).  Saving model ...
	 Train_Loss: 0.5280 Train_Acc: 74.439 Val_Loss: 0.5363  BEST VAL Loss: 0.5363  Val_Acc: 71.416

Epoch 21: Validation loss decreased (0.536295 --> 0.536043).  Saving model ...
	 Train_Loss: 0.5260 Train_Acc: 74.727 Val_Loss: 0.5360  BEST VAL Loss: 0.5360  Val_Acc: 72.712

Epoch 22: Validation loss decreased (0.536043 --> 0.535293).  Saving model ...
	 Train_Loss: 0.5241 Train_Acc: 75.126 Val_Loss: 0.5353  BEST VAL Loss: 0.5353  Val_Acc: 71.445

Epoch 23: Validation loss decreased (0.535293 --> 0.534588).  Saving model ...
	 Train_Loss: 0.5223 Train_Acc: 74.870 Val_Loss: 0.5346  BEST VAL Loss: 0.5346  Val_Acc: 71.157

Epoch 24: Validation loss decreased (0.534588 --> 0.534163).  Saving model ...
	 Train_Loss: 0.5206 Train_Acc: 75.256 Val_Loss: 0.5342  BEST VAL Loss: 0.5342  Val_Acc: 72.596

Epoch 25: Validation loss decreased (0.534163 --> 0.533658).  Saving model ...
	 Train_Loss: 0.5189 Train_Acc: 75.349 Val_Loss: 0.5337  BEST VAL Loss: 0.5337  Val_Acc: 72.942

Epoch 26: Validation loss decreased (0.533658 --> 0.533092).  Saving model ...
	 Train_Loss: 0.5173 Train_Acc: 75.155 Val_Loss: 0.5331  BEST VAL Loss: 0.5331  Val_Acc: 71.762

Epoch 27: Validation loss decreased (0.533092 --> 0.532773).  Saving model ...
	 Train_Loss: 0.5158 Train_Acc: 75.903 Val_Loss: 0.5328  BEST VAL Loss: 0.5328  Val_Acc: 71.589

Epoch 28: Validation loss decreased (0.532773 --> 0.532661).  Saving model ...
	 Train_Loss: 0.5144 Train_Acc: 75.608 Val_Loss: 0.5327  BEST VAL Loss: 0.5327  Val_Acc: 71.963

Epoch 29: Validation loss decreased (0.532661 --> 0.532213).  Saving model ...
	 Train_Loss: 0.5129 Train_Acc: 75.695 Val_Loss: 0.5322  BEST VAL Loss: 0.5322  Val_Acc: 73.028

Epoch 30: Validation loss did not decrease
	 Train_Loss: 0.5115 Train_Acc: 76.465 Val_Loss: 0.5323  BEST VAL Loss: 0.5322  Val_Acc: 72.280

Epoch 31: Validation loss did not decrease
	 Train_Loss: 0.5101 Train_Acc: 76.098 Val_Loss: 0.5323  BEST VAL Loss: 0.5322  Val_Acc: 71.963

Epoch 32: Validation loss decreased (0.532213 --> 0.531934).  Saving model ...
	 Train_Loss: 0.5088 Train_Acc: 76.350 Val_Loss: 0.5319  BEST VAL Loss: 0.5319  Val_Acc: 72.855

Epoch 33: Validation loss decreased (0.531934 --> 0.531388).  Saving model ...
	 Train_Loss: 0.5075 Train_Acc: 76.555 Val_Loss: 0.5314  BEST VAL Loss: 0.5314  Val_Acc: 73.115

Epoch 34: Validation loss decreased (0.531388 --> 0.531181).  Saving model ...
	 Train_Loss: 0.5061 Train_Acc: 76.871 Val_Loss: 0.5312  BEST VAL Loss: 0.5312  Val_Acc: 72.222

Epoch 35: Validation loss decreased (0.531181 --> 0.531088).  Saving model ...
	 Train_Loss: 0.5048 Train_Acc: 76.691 Val_Loss: 0.5311  BEST VAL Loss: 0.5311  Val_Acc: 71.934

Epoch 36: Validation loss decreased (0.531088 --> 0.530970).  Saving model ...
	 Train_Loss: 0.5037 Train_Acc: 76.778 Val_Loss: 0.5310  BEST VAL Loss: 0.5310  Val_Acc: 72.078

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.5025 Train_Acc: 76.997 Val_Loss: 0.5310  BEST VAL Loss: 0.5310  Val_Acc: 72.050

Epoch 38: Validation loss did not decrease
	 Train_Loss: 0.5014 Train_Acc: 77.188 Val_Loss: 0.5313  BEST VAL Loss: 0.5310  Val_Acc: 71.992

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.5003 Train_Acc: 77.001 Val_Loss: 0.5315  BEST VAL Loss: 0.5310  Val_Acc: 72.453

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.4992 Train_Acc: 77.073 Val_Loss: 0.5316  BEST VAL Loss: 0.5310  Val_Acc: 71.877

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.4980 Train_Acc: 77.569 Val_Loss: 0.5316  BEST VAL Loss: 0.5310  Val_Acc: 72.050

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.4970 Train_Acc: 77.235 Val_Loss: 0.5319  BEST VAL Loss: 0.5310  Val_Acc: 71.934

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.4959 Train_Acc: 77.883 Val_Loss: 0.5322  BEST VAL Loss: 0.5310  Val_Acc: 72.337

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.4948 Train_Acc: 77.613 Val_Loss: 0.5323  BEST VAL Loss: 0.5310  Val_Acc: 72.337

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.4938 Train_Acc: 77.652 Val_Loss: 0.5324  BEST VAL Loss: 0.5310  Val_Acc: 72.683

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.4927 Train_Acc: 78.458 Val_Loss: 0.5328  BEST VAL Loss: 0.5310  Val_Acc: 72.913

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.4917 Train_Acc: 78.116 Val_Loss: 0.5329  BEST VAL Loss: 0.5310  Val_Acc: 73.345

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.4906 Train_Acc: 78.095 Val_Loss: 0.5331  BEST VAL Loss: 0.5310  Val_Acc: 72.769

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.4896 Train_Acc: 78.390 Val_Loss: 0.5333  BEST VAL Loss: 0.5310  Val_Acc: 72.280

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.4886 Train_Acc: 78.322 Val_Loss: 0.5333  BEST VAL Loss: 0.5310  Val_Acc: 72.481

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.4876 Train_Acc: 78.487 Val_Loss: 0.5336  BEST VAL Loss: 0.5310  Val_Acc: 72.021

Epoch 52: Validation loss did not decrease
Early stopped at epoch : 52
Flagellin_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.31      0.34      0.32      8635
           1       0.69      0.67      0.68     19153

    accuracy                           0.56     27788
   macro avg       0.50      0.50      0.50     27788
weighted avg       0.57      0.56      0.57     27788

Flagellin_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.31      0.32      0.32      1079
           1       0.69      0.68      0.68      2395

    accuracy                           0.57      3474
   macro avg       0.50      0.50      0.50      3474
weighted avg       0.57      0.57      0.57      3474

Flagellin_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.32      0.33      0.32      1079
           1       0.69      0.68      0.69      2395

    accuracy                           0.57      3474
   macro avg       0.50      0.50      0.50      3474
weighted avg       0.57      0.57      0.57      3474

              precision    recall  f1-score   support

           0       0.32      0.33      0.32      1079
           1       0.69      0.68      0.69      2395

    accuracy                           0.57      3474
   macro avg       0.50      0.50      0.50      3474
weighted avg       0.57      0.57      0.57      3474

Flagellin_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.57      0.33      0.42      4135
           1       0.41      0.66      0.51      2957

    accuracy                           0.46      7092
   macro avg       0.49      0.49      0.46      7092
weighted avg       0.50      0.46      0.45      7092

              precision    recall  f1-score   support

           0       0.57      0.33      0.42      4135
           1       0.41      0.66      0.51      2957

    accuracy                           0.46      7092
   macro avg       0.49      0.49      0.46      7092
weighted avg       0.50      0.46      0.45      7092

completed
