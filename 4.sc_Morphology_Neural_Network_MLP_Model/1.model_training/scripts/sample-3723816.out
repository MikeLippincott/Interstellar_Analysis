[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 18688 bytes to train_binary_model.py
[NbConvertApp] Converting notebook ../notebooks/train_multiclass_model.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: MissingIDFieldWarning: Code cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.
  validate(nb)
[NbConvertApp] Writing 31143 bytes to train_multiclass_model.py
[NbConvertApp] Converting notebook ../notebooks/train_regression_model.ipynb to script
[NbConvertApp] Writing 25120 bytes to train_regression_model.py
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:314: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels.drop_duplicates(inplace=True)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1015: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1016: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1015: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1016: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1036: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:578: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:652: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1219: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:880: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1219: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/train_multiclass_model.py:1096: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_labels["new_labels"] = df_labels["new_labels"].astype(str)
PBMC MultiClass_MLP_h202_remove False
[0.9436581681188537, 0.5245113046249099, 0.5318305272562364]
Data Subset Is Off
(1417094,) (354274,) (2112741,) (1474037,)
(1417094,) (354274,) (2112741,) (1474037,)
5358146
(95929,) (683836,) (637329,)
(23982,) (170959,) (159333,)
(119910,) (854797,) (1138034,)
(75619,) (711982,) (686436,)
(1417094, 1245) (354274, 1245) (2112741, 1245) (1474037, 1245)
(1417094,) (354274,) (2112741,) (1474037,)
Number of in features:  1245
Number of out features:  3
Multi_Class
Adam
Epoch 0: Validation loss decreased (inf --> 0.638845).  Saving model ...
	 Train_Loss: 0.7103 Train_Acc: 70.077 Val_Loss: 0.6388  BEST VAL Loss: 0.6388  Val_Acc: 73.812

Epoch 1: Validation loss decreased (0.638845 --> 0.621379).  Saving model ...
	 Train_Loss: 0.6852 Train_Acc: 72.518 Val_Loss: 0.6214  BEST VAL Loss: 0.6214  Val_Acc: 75.228

Epoch 2: Validation loss decreased (0.621379 --> 0.610633).  Saving model ...
	 Train_Loss: 0.6698 Train_Acc: 73.486 Val_Loss: 0.6106  BEST VAL Loss: 0.6106  Val_Acc: 76.165

Epoch 3: Validation loss decreased (0.610633 --> 0.601911).  Saving model ...
	 Train_Loss: 0.6588 Train_Acc: 74.092 Val_Loss: 0.6019  BEST VAL Loss: 0.6019  Val_Acc: 76.636

Epoch 4: Validation loss decreased (0.601911 --> 0.594731).  Saving model ...
	 Train_Loss: 0.6504 Train_Acc: 74.498 Val_Loss: 0.5947  BEST VAL Loss: 0.5947  Val_Acc: 77.119

Epoch 5: Validation loss decreased (0.594731 --> 0.589892).  Saving model ...
	 Train_Loss: 0.6435 Train_Acc: 74.887 Val_Loss: 0.5899  BEST VAL Loss: 0.5899  Val_Acc: 77.159

Epoch 6: Validation loss decreased (0.589892 --> 0.584632).  Saving model ...
	 Train_Loss: 0.6379 Train_Acc: 75.102 Val_Loss: 0.5846  BEST VAL Loss: 0.5846  Val_Acc: 77.651

Epoch 7: Validation loss decreased (0.584632 --> 0.580270).  Saving model ...
	 Train_Loss: 0.6332 Train_Acc: 75.233 Val_Loss: 0.5803  BEST VAL Loss: 0.5803  Val_Acc: 77.743

Epoch 8: Validation loss decreased (0.580270 --> 0.576634).  Saving model ...
	 Train_Loss: 0.6290 Train_Acc: 75.426 Val_Loss: 0.5766  BEST VAL Loss: 0.5766  Val_Acc: 77.813

Epoch 9: Validation loss decreased (0.576634 --> 0.573441).  Saving model ...
	 Train_Loss: 0.6254 Train_Acc: 75.612 Val_Loss: 0.5734  BEST VAL Loss: 0.5734  Val_Acc: 78.148

Epoch 10: Validation loss decreased (0.573441 --> 0.570091).  Saving model ...
	 Train_Loss: 0.6222 Train_Acc: 75.740 Val_Loss: 0.5701  BEST VAL Loss: 0.5701  Val_Acc: 78.277

Epoch 11: Validation loss decreased (0.570091 --> 0.567430).  Saving model ...
	 Train_Loss: 0.6193 Train_Acc: 75.823 Val_Loss: 0.5674  BEST VAL Loss: 0.5674  Val_Acc: 78.250

Epoch 12: Validation loss decreased (0.567430 --> 0.565046).  Saving model ...
	 Train_Loss: 0.6167 Train_Acc: 75.901 Val_Loss: 0.5650  BEST VAL Loss: 0.5650  Val_Acc: 78.413

Epoch 13: Validation loss decreased (0.565046 --> 0.562690).  Saving model ...
	 Train_Loss: 0.6143 Train_Acc: 76.032 Val_Loss: 0.5627  BEST VAL Loss: 0.5627  Val_Acc: 78.647

Epoch 14: Validation loss decreased (0.562690 --> 0.560478).  Saving model ...
	 Train_Loss: 0.6121 Train_Acc: 76.099 Val_Loss: 0.5605  BEST VAL Loss: 0.5605  Val_Acc: 78.485

Epoch 15: Validation loss decreased (0.560478 --> 0.558537).  Saving model ...
	 Train_Loss: 0.6101 Train_Acc: 76.170 Val_Loss: 0.5585  BEST VAL Loss: 0.5585  Val_Acc: 78.839

Epoch 16: Validation loss decreased (0.558537 --> 0.556555).  Saving model ...
	 Train_Loss: 0.6082 Train_Acc: 76.243 Val_Loss: 0.5566  BEST VAL Loss: 0.5566  Val_Acc: 78.715

Epoch 17: Validation loss decreased (0.556555 --> 0.554776).  Saving model ...
	 Train_Loss: 0.6065 Train_Acc: 76.276 Val_Loss: 0.5548  BEST VAL Loss: 0.5548  Val_Acc: 79.032

Epoch 18: Validation loss decreased (0.554776 --> 0.553294).  Saving model ...
	 Train_Loss: 0.6049 Train_Acc: 76.301 Val_Loss: 0.5533  BEST VAL Loss: 0.5533  Val_Acc: 78.796

Epoch 19: Validation loss decreased (0.553294 --> 0.551870).  Saving model ...
	 Train_Loss: 0.6034 Train_Acc: 76.369 Val_Loss: 0.5519  BEST VAL Loss: 0.5519  Val_Acc: 79.099

Epoch 20: Validation loss decreased (0.551870 --> 0.550470).  Saving model ...
	 Train_Loss: 0.6019 Train_Acc: 76.447 Val_Loss: 0.5505  BEST VAL Loss: 0.5505  Val_Acc: 79.061

Epoch 21: Validation loss decreased (0.550470 --> 0.549094).  Saving model ...
	 Train_Loss: 0.6005 Train_Acc: 76.472 Val_Loss: 0.5491  BEST VAL Loss: 0.5491  Val_Acc: 79.200

Epoch 22: Validation loss decreased (0.549094 --> 0.547940).  Saving model ...
	 Train_Loss: 0.5993 Train_Acc: 76.535 Val_Loss: 0.5479  BEST VAL Loss: 0.5479  Val_Acc: 78.947

Epoch 23: Validation loss decreased (0.547940 --> 0.546801).  Saving model ...
	 Train_Loss: 0.5981 Train_Acc: 76.520 Val_Loss: 0.5468  BEST VAL Loss: 0.5468  Val_Acc: 79.050

Epoch 24: Validation loss decreased (0.546801 --> 0.545670).  Saving model ...
	 Train_Loss: 0.5969 Train_Acc: 76.623 Val_Loss: 0.5457  BEST VAL Loss: 0.5457  Val_Acc: 79.171

Epoch 25: Validation loss decreased (0.545670 --> 0.544536).  Saving model ...
	 Train_Loss: 0.5958 Train_Acc: 76.623 Val_Loss: 0.5445  BEST VAL Loss: 0.5445  Val_Acc: 79.336

Epoch 26: Validation loss decreased (0.544536 --> 0.543550).  Saving model ...
	 Train_Loss: 0.5948 Train_Acc: 76.656 Val_Loss: 0.5436  BEST VAL Loss: 0.5436  Val_Acc: 79.238

Epoch 27: Validation loss decreased (0.543550 --> 0.542682).  Saving model ...
	 Train_Loss: 0.5938 Train_Acc: 76.691 Val_Loss: 0.5427  BEST VAL Loss: 0.5427  Val_Acc: 79.286

Epoch 28: Validation loss decreased (0.542682 --> 0.541883).  Saving model ...
	 Train_Loss: 0.5928 Train_Acc: 76.719 Val_Loss: 0.5419  BEST VAL Loss: 0.5419  Val_Acc: 79.143

Epoch 29: Validation loss decreased (0.541883 --> 0.540987).  Saving model ...
	 Train_Loss: 0.5919 Train_Acc: 76.749 Val_Loss: 0.5410  BEST VAL Loss: 0.5410  Val_Acc: 79.455

Epoch 30: Validation loss decreased (0.540987 --> 0.540187).  Saving model ...
	 Train_Loss: 0.5910 Train_Acc: 76.794 Val_Loss: 0.5402  BEST VAL Loss: 0.5402  Val_Acc: 79.262

Epoch 31: Validation loss decreased (0.540187 --> 0.539434).  Saving model ...
	 Train_Loss: 0.5902 Train_Acc: 76.808 Val_Loss: 0.5394  BEST VAL Loss: 0.5394  Val_Acc: 79.292

Epoch 32: Validation loss decreased (0.539434 --> 0.538663).  Saving model ...
	 Train_Loss: 0.5894 Train_Acc: 76.845 Val_Loss: 0.5387  BEST VAL Loss: 0.5387  Val_Acc: 79.399

Epoch 33: Validation loss decreased (0.538663 --> 0.537996).  Saving model ...
	 Train_Loss: 0.5886 Train_Acc: 76.841 Val_Loss: 0.5380  BEST VAL Loss: 0.5380  Val_Acc: 79.412

Epoch 34: Validation loss decreased (0.537996 --> 0.537242).  Saving model ...
	 Train_Loss: 0.5878 Train_Acc: 76.869 Val_Loss: 0.5372  BEST VAL Loss: 0.5372  Val_Acc: 79.389

Epoch 35: Validation loss decreased (0.537242 --> 0.536571).  Saving model ...
	 Train_Loss: 0.5871 Train_Acc: 76.869 Val_Loss: 0.5366  BEST VAL Loss: 0.5366  Val_Acc: 79.571

Epoch 36: Validation loss decreased (0.536571 --> 0.535938).  Saving model ...
	 Train_Loss: 0.5864 Train_Acc: 76.959 Val_Loss: 0.5359  BEST VAL Loss: 0.5359  Val_Acc: 79.410

Epoch 37: Validation loss decreased (0.535938 --> 0.535341).  Saving model ...
	 Train_Loss: 0.5858 Train_Acc: 76.905 Val_Loss: 0.5353  BEST VAL Loss: 0.5353  Val_Acc: 79.370

Epoch 38: Validation loss decreased (0.535341 --> 0.534732).  Saving model ...
	 Train_Loss: 0.5851 Train_Acc: 76.979 Val_Loss: 0.5347  BEST VAL Loss: 0.5347  Val_Acc: 79.506

Epoch 39: Validation loss decreased (0.534732 --> 0.534237).  Saving model ...
	 Train_Loss: 0.5845 Train_Acc: 76.971 Val_Loss: 0.5342  BEST VAL Loss: 0.5342  Val_Acc: 79.335

Epoch 40: Validation loss decreased (0.534237 --> 0.533565).  Saving model ...
	 Train_Loss: 0.5839 Train_Acc: 77.018 Val_Loss: 0.5336  BEST VAL Loss: 0.5336  Val_Acc: 79.759

Epoch 41: Validation loss decreased (0.533565 --> 0.533096).  Saving model ...
	 Train_Loss: 0.5833 Train_Acc: 76.981 Val_Loss: 0.5331  BEST VAL Loss: 0.5331  Val_Acc: 79.503

Epoch 42: Validation loss decreased (0.533096 --> 0.532605).  Saving model ...
	 Train_Loss: 0.5827 Train_Acc: 77.022 Val_Loss: 0.5326  BEST VAL Loss: 0.5326  Val_Acc: 79.680

Epoch 43: Validation loss decreased (0.532605 --> 0.532076).  Saving model ...
	 Train_Loss: 0.5822 Train_Acc: 77.068 Val_Loss: 0.5321  BEST VAL Loss: 0.5321  Val_Acc: 79.779

Epoch 44: Validation loss decreased (0.532076 --> 0.531555).  Saving model ...
	 Train_Loss: 0.5816 Train_Acc: 77.044 Val_Loss: 0.5316  BEST VAL Loss: 0.5316  Val_Acc: 79.873

Epoch 45: Validation loss decreased (0.531555 --> 0.531046).  Saving model ...
	 Train_Loss: 0.5811 Train_Acc: 77.106 Val_Loss: 0.5310  BEST VAL Loss: 0.5310  Val_Acc: 79.601

Epoch 46: Validation loss decreased (0.531046 --> 0.530537).  Saving model ...
	 Train_Loss: 0.5806 Train_Acc: 77.118 Val_Loss: 0.5305  BEST VAL Loss: 0.5305  Val_Acc: 79.574

Epoch 47: Validation loss decreased (0.530537 --> 0.530005).  Saving model ...
	 Train_Loss: 0.5801 Train_Acc: 77.091 Val_Loss: 0.5300  BEST VAL Loss: 0.5300  Val_Acc: 79.800

Epoch 48: Validation loss decreased (0.530005 --> 0.529515).  Saving model ...
	 Train_Loss: 0.5797 Train_Acc: 77.130 Val_Loss: 0.5295  BEST VAL Loss: 0.5295  Val_Acc: 79.803

Epoch 49: Validation loss decreased (0.529515 --> 0.529055).  Saving model ...
	 Train_Loss: 0.5792 Train_Acc: 77.171 Val_Loss: 0.5291  BEST VAL Loss: 0.5291  Val_Acc: 79.701

Epoch 50: Validation loss decreased (0.529055 --> 0.528538).  Saving model ...
	 Train_Loss: 0.5787 Train_Acc: 77.121 Val_Loss: 0.5285  BEST VAL Loss: 0.5285  Val_Acc: 79.954

Epoch 51: Validation loss decreased (0.528538 --> 0.528123).  Saving model ...
	 Train_Loss: 0.5783 Train_Acc: 77.188 Val_Loss: 0.5281  BEST VAL Loss: 0.5281  Val_Acc: 79.803

Epoch 52: Validation loss decreased (0.528123 --> 0.527783).  Saving model ...
	 Train_Loss: 0.5779 Train_Acc: 77.123 Val_Loss: 0.5278  BEST VAL Loss: 0.5278  Val_Acc: 79.399

Epoch 53: Validation loss decreased (0.527783 --> 0.527316).  Saving model ...
	 Train_Loss: 0.5774 Train_Acc: 77.171 Val_Loss: 0.5273  BEST VAL Loss: 0.5273  Val_Acc: 79.894

Epoch 54: Validation loss decreased (0.527316 --> 0.526908).  Saving model ...
	 Train_Loss: 0.5770 Train_Acc: 77.200 Val_Loss: 0.5269  BEST VAL Loss: 0.5269  Val_Acc: 79.836

Epoch 55: Validation loss decreased (0.526908 --> 0.526613).  Saving model ...
	 Train_Loss: 0.5767 Train_Acc: 77.175 Val_Loss: 0.5266  BEST VAL Loss: 0.5266  Val_Acc: 79.578

Epoch 56: Validation loss decreased (0.526613 --> 0.526214).  Saving model ...
	 Train_Loss: 0.5763 Train_Acc: 77.181 Val_Loss: 0.5262  BEST VAL Loss: 0.5262  Val_Acc: 79.822

Epoch 57: Validation loss decreased (0.526214 --> 0.525903).  Saving model ...
	 Train_Loss: 0.5759 Train_Acc: 77.256 Val_Loss: 0.5259  BEST VAL Loss: 0.5259  Val_Acc: 79.791

Epoch 58: Validation loss decreased (0.525903 --> 0.525518).  Saving model ...
	 Train_Loss: 0.5755 Train_Acc: 77.236 Val_Loss: 0.5255  BEST VAL Loss: 0.5255  Val_Acc: 79.713

Epoch 59: Validation loss decreased (0.525518 --> 0.525182).  Saving model ...
	 Train_Loss: 0.5752 Train_Acc: 77.251 Val_Loss: 0.5252  BEST VAL Loss: 0.5252  Val_Acc: 79.839

Epoch 60: Validation loss decreased (0.525182 --> 0.524831).  Saving model ...
	 Train_Loss: 0.5748 Train_Acc: 77.302 Val_Loss: 0.5248  BEST VAL Loss: 0.5248  Val_Acc: 79.860

Epoch 61: Validation loss decreased (0.524831 --> 0.524475).  Saving model ...
	 Train_Loss: 0.5744 Train_Acc: 77.242 Val_Loss: 0.5245  BEST VAL Loss: 0.5245  Val_Acc: 79.991

Epoch 62: Validation loss decreased (0.524475 --> 0.524118).  Saving model ...
	 Train_Loss: 0.5741 Train_Acc: 77.293 Val_Loss: 0.5241  BEST VAL Loss: 0.5241  Val_Acc: 80.005

Epoch 63: Validation loss decreased (0.524118 --> 0.523757).  Saving model ...
	 Train_Loss: 0.5738 Train_Acc: 77.251 Val_Loss: 0.5238  BEST VAL Loss: 0.5238  Val_Acc: 80.118

Epoch 64: Validation loss decreased (0.523757 --> 0.523450).  Saving model ...
	 Train_Loss: 0.5734 Train_Acc: 77.314 Val_Loss: 0.5234  BEST VAL Loss: 0.5234  Val_Acc: 80.052

Epoch 65: Validation loss decreased (0.523450 --> 0.523114).  Saving model ...
	 Train_Loss: 0.5731 Train_Acc: 77.308 Val_Loss: 0.5231  BEST VAL Loss: 0.5231  Val_Acc: 79.993

Epoch 66: Validation loss decreased (0.523114 --> 0.522889).  Saving model ...
	 Train_Loss: 0.5728 Train_Acc: 77.326 Val_Loss: 0.5229  BEST VAL Loss: 0.5229  Val_Acc: 79.602

Epoch 67: Validation loss decreased (0.522889 --> 0.522583).  Saving model ...
	 Train_Loss: 0.5725 Train_Acc: 77.337 Val_Loss: 0.5226  BEST VAL Loss: 0.5226  Val_Acc: 79.937

Epoch 68: Validation loss decreased (0.522583 --> 0.522263).  Saving model ...
	 Train_Loss: 0.5722 Train_Acc: 77.295 Val_Loss: 0.5223  BEST VAL Loss: 0.5223  Val_Acc: 80.064

Epoch 69: Validation loss decreased (0.522263 --> 0.521947).  Saving model ...
	 Train_Loss: 0.5719 Train_Acc: 77.343 Val_Loss: 0.5219  BEST VAL Loss: 0.5219  Val_Acc: 80.104

Epoch 70: Validation loss decreased (0.521947 --> 0.521789).  Saving model ...
	 Train_Loss: 0.5716 Train_Acc: 77.317 Val_Loss: 0.5218  BEST VAL Loss: 0.5218  Val_Acc: 79.589

Epoch 71: Validation loss decreased (0.521789 --> 0.521522).  Saving model ...
	 Train_Loss: 0.5713 Train_Acc: 77.347 Val_Loss: 0.5215  BEST VAL Loss: 0.5215  Val_Acc: 79.889

Epoch 72: Validation loss decreased (0.521522 --> 0.521238).  Saving model ...
	 Train_Loss: 0.5711 Train_Acc: 77.389 Val_Loss: 0.5212  BEST VAL Loss: 0.5212  Val_Acc: 79.976

Epoch 73: Validation loss decreased (0.521238 --> 0.520971).  Saving model ...
	 Train_Loss: 0.5708 Train_Acc: 77.384 Val_Loss: 0.5210  BEST VAL Loss: 0.5210  Val_Acc: 80.080

Epoch 74: Validation loss decreased (0.520971 --> 0.520701).  Saving model ...
	 Train_Loss: 0.5705 Train_Acc: 77.357 Val_Loss: 0.5207  BEST VAL Loss: 0.5207  Val_Acc: 80.031

Epoch 75: Validation loss decreased (0.520701 --> 0.520512).  Saving model ...
	 Train_Loss: 0.5702 Train_Acc: 77.374 Val_Loss: 0.5205  BEST VAL Loss: 0.5205  Val_Acc: 79.694

Epoch 76: Validation loss decreased (0.520512 --> 0.520231).  Saving model ...
	 Train_Loss: 0.5700 Train_Acc: 77.408 Val_Loss: 0.5202  BEST VAL Loss: 0.5202  Val_Acc: 80.158

Epoch 77: Validation loss decreased (0.520231 --> 0.519951).  Saving model ...
	 Train_Loss: 0.5697 Train_Acc: 77.418 Val_Loss: 0.5200  BEST VAL Loss: 0.5200  Val_Acc: 80.246

Epoch 78: Validation loss decreased (0.519951 --> 0.519693).  Saving model ...
	 Train_Loss: 0.5695 Train_Acc: 77.402 Val_Loss: 0.5197  BEST VAL Loss: 0.5197  Val_Acc: 80.108

Epoch 79: Validation loss decreased (0.519693 --> 0.519468).  Saving model ...
	 Train_Loss: 0.5692 Train_Acc: 77.415 Val_Loss: 0.5195  BEST VAL Loss: 0.5195  Val_Acc: 79.814

Epoch 80: Validation loss decreased (0.519468 --> 0.519269).  Saving model ...
	 Train_Loss: 0.5690 Train_Acc: 77.418 Val_Loss: 0.5193  BEST VAL Loss: 0.5193  Val_Acc: 80.217

Epoch 81: Validation loss decreased (0.519269 --> 0.519036).  Saving model ...
	 Train_Loss: 0.5687 Train_Acc: 77.434 Val_Loss: 0.5190  BEST VAL Loss: 0.5190  Val_Acc: 80.256

Epoch 82: Validation loss decreased (0.519036 --> 0.518800).  Saving model ...
	 Train_Loss: 0.5685 Train_Acc: 77.473 Val_Loss: 0.5188  BEST VAL Loss: 0.5188  Val_Acc: 80.071

Epoch 83: Validation loss decreased (0.518800 --> 0.518562).  Saving model ...
	 Train_Loss: 0.5683 Train_Acc: 77.431 Val_Loss: 0.5186  BEST VAL Loss: 0.5186  Val_Acc: 80.294

Epoch 84: Validation loss decreased (0.518562 --> 0.518330).  Saving model ...
	 Train_Loss: 0.5680 Train_Acc: 77.436 Val_Loss: 0.5183  BEST VAL Loss: 0.5183  Val_Acc: 80.039

Epoch 85: Validation loss decreased (0.518330 --> 0.518129).  Saving model ...
	 Train_Loss: 0.5678 Train_Acc: 77.453 Val_Loss: 0.5181  BEST VAL Loss: 0.5181  Val_Acc: 80.093

Epoch 86: Validation loss decreased (0.518129 --> 0.517969).  Saving model ...
	 Train_Loss: 0.5676 Train_Acc: 77.465 Val_Loss: 0.5180  BEST VAL Loss: 0.5180  Val_Acc: 80.044

Epoch 87: Validation loss decreased (0.517969 --> 0.517735).  Saving model ...
	 Train_Loss: 0.5674 Train_Acc: 77.456 Val_Loss: 0.5177  BEST VAL Loss: 0.5177  Val_Acc: 80.207

Epoch 88: Validation loss decreased (0.517735 --> 0.517532).  Saving model ...
	 Train_Loss: 0.5671 Train_Acc: 77.491 Val_Loss: 0.5175  BEST VAL Loss: 0.5175  Val_Acc: 80.101

Epoch 89: Validation loss decreased (0.517532 --> 0.517356).  Saving model ...
	 Train_Loss: 0.5669 Train_Acc: 77.493 Val_Loss: 0.5174  BEST VAL Loss: 0.5174  Val_Acc: 80.042

Epoch 90: Validation loss decreased (0.517356 --> 0.517185).  Saving model ...
	 Train_Loss: 0.5667 Train_Acc: 77.509 Val_Loss: 0.5172  BEST VAL Loss: 0.5172  Val_Acc: 80.051

Epoch 91: Validation loss decreased (0.517185 --> 0.516982).  Saving model ...
	 Train_Loss: 0.5665 Train_Acc: 77.514 Val_Loss: 0.5170  BEST VAL Loss: 0.5170  Val_Acc: 80.065

Epoch 92: Validation loss decreased (0.516982 --> 0.516795).  Saving model ...
	 Train_Loss: 0.5663 Train_Acc: 77.484 Val_Loss: 0.5168  BEST VAL Loss: 0.5168  Val_Acc: 80.155

Epoch 93: Validation loss decreased (0.516795 --> 0.516604).  Saving model ...
	 Train_Loss: 0.5661 Train_Acc: 77.512 Val_Loss: 0.5166  BEST VAL Loss: 0.5166  Val_Acc: 80.163

Epoch 94: Validation loss decreased (0.516604 --> 0.516403).  Saving model ...
	 Train_Loss: 0.5659 Train_Acc: 77.486 Val_Loss: 0.5164  BEST VAL Loss: 0.5164  Val_Acc: 80.169

Epoch 95: Validation loss decreased (0.516403 --> 0.516194).  Saving model ...
	 Train_Loss: 0.5657 Train_Acc: 77.455 Val_Loss: 0.5162  BEST VAL Loss: 0.5162  Val_Acc: 80.254

Epoch 96: Validation loss decreased (0.516194 --> 0.515969).  Saving model ...
	 Train_Loss: 0.5655 Train_Acc: 77.548 Val_Loss: 0.5160  BEST VAL Loss: 0.5160  Val_Acc: 80.275

Epoch 97: Validation loss decreased (0.515969 --> 0.515760).  Saving model ...
	 Train_Loss: 0.5654 Train_Acc: 77.526 Val_Loss: 0.5158  BEST VAL Loss: 0.5158  Val_Acc: 80.264

Epoch 98: Validation loss decreased (0.515760 --> 0.515598).  Saving model ...
	 Train_Loss: 0.5652 Train_Acc: 77.537 Val_Loss: 0.5156  BEST VAL Loss: 0.5156  Val_Acc: 80.104

Epoch 99: Validation loss decreased (0.515598 --> 0.515445).  Saving model ...
	 Train_Loss: 0.5650 Train_Acc: 77.511 Val_Loss: 0.5154  BEST VAL Loss: 0.5154  Val_Acc: 80.312

MultiClass_MLP_h202_remove
              precision    recall  f1-score   support

           0       0.68      0.53      0.59     95929
           1       0.82      0.85      0.84    683836
           2       0.83      0.81      0.82    637329

    accuracy                           0.81   1417094
   macro avg       0.78      0.73      0.75   1417094
weighted avg       0.81      0.81      0.81   1417094

MultiClass_MLP_h202_remove
              precision    recall  f1-score   support

           0       0.66      0.50      0.57     23982
           1       0.81      0.85      0.83    170959
           2       0.82      0.80      0.81    159333

    accuracy                           0.80    354274
   macro avg       0.76      0.72      0.73    354274
weighted avg       0.80      0.80      0.80    354274

MultiClass_MLP_h202_remove
              precision    recall  f1-score   support

           0       0.60      0.50      0.54    119910
           1       0.77      0.85      0.80    854797
           2       0.87      0.81      0.84   1138034

    accuracy                           0.81   2112741
   macro avg       0.74      0.72      0.73   2112741
weighted avg       0.81      0.81      0.81   2112741

Precision for class 0: 0.5964815777893347
Recall for class 0: 0.4973813693603536
Precision for class 1: 0.7667388258453601
Recall for class 1: 0.8456966975784894
Precision for class 2: 0.8650360303945118
Recall for class 2: 0.8132691993385084
3
              precision    recall  f1-score   support

           0       0.60      0.50      0.54    119910
           1       0.77      0.85      0.80    854797
           2       0.87      0.81      0.84   1138034

    accuracy                           0.81   2112741
   macro avg       0.74      0.72      0.73   2112741
weighted avg       0.81      0.81      0.81   2112741

MultiClass_MLP_h202_remove
              precision    recall  f1-score   support

           0       0.40      0.32      0.35     75619
           1       0.78      0.74      0.76    711982
           2       0.72      0.79      0.75    686436

    accuracy                           0.74   1474037
   macro avg       0.64      0.61      0.62   1474037
weighted avg       0.74      0.74      0.74   1474037

Precision for class 0: 0.3977848101265823
Recall for class 0: 0.31583332231317524
Precision for class 1: 0.7837341077574299
Recall for class 1: 0.7372405482161066
Precision for class 2: 0.7242614060828859
Recall for class 2: 0.7852633020412683
3
              precision    recall  f1-score   support

           0       0.40      0.32      0.35     75619
           1       0.78      0.74      0.76    711982
           2       0.72      0.79      0.75    686436

    accuracy                           0.74   1474037
   macro avg       0.64      0.61      0.62   1474037
weighted avg       0.74      0.74      0.74   1474037

Done
