[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '0733261d'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '1c58448d'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '1c2f0204'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '807ae9d7'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Flagellin_1.000_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Flagellin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_100.000_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (263982, 1270)
Number of total missing values across all columns: 564580
Data Subset Is Off
Wells held out for testing: ['J08' 'M10']
Wells to use for training, validation, and testing ['J02' 'J03' 'J09' 'M05' 'M11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
SGD
Epoch 0: Validation loss decreased (inf --> 0.558399).  Saving model ...
	 Train_Loss: 0.6066 Train_Acc: 67.063 Val_Loss: 0.5584  BEST VAL Loss: 0.5584  Val_Acc: 71.989

Epoch 1: Validation loss decreased (0.558399 --> 0.540160).  Saving model ...
	 Train_Loss: 0.5788 Train_Acc: 72.303 Val_Loss: 0.5402  BEST VAL Loss: 0.5402  Val_Acc: 74.468

Epoch 2: Validation loss decreased (0.540160 --> 0.528132).  Saving model ...
	 Train_Loss: 0.5614 Train_Acc: 73.993 Val_Loss: 0.5281  BEST VAL Loss: 0.5281  Val_Acc: 75.628

Epoch 3: Validation loss decreased (0.528132 --> 0.519182).  Saving model ...
	 Train_Loss: 0.5492 Train_Acc: 74.817 Val_Loss: 0.5192  BEST VAL Loss: 0.5192  Val_Acc: 76.314

Epoch 4: Validation loss decreased (0.519182 --> 0.512709).  Saving model ...
	 Train_Loss: 0.5400 Train_Acc: 75.420 Val_Loss: 0.5127  BEST VAL Loss: 0.5127  Val_Acc: 76.683

Epoch 5: Validation loss decreased (0.512709 --> 0.507185).  Saving model ...
	 Train_Loss: 0.5328 Train_Acc: 75.806 Val_Loss: 0.5072  BEST VAL Loss: 0.5072  Val_Acc: 76.922

Epoch 6: Validation loss decreased (0.507185 --> 0.502689).  Saving model ...
	 Train_Loss: 0.5270 Train_Acc: 76.241 Val_Loss: 0.5027  BEST VAL Loss: 0.5027  Val_Acc: 77.187

Epoch 7: Validation loss decreased (0.502689 --> 0.498873).  Saving model ...
	 Train_Loss: 0.5219 Train_Acc: 76.573 Val_Loss: 0.4989  BEST VAL Loss: 0.4989  Val_Acc: 77.510

Epoch 8: Validation loss decreased (0.498873 --> 0.495566).  Saving model ...
	 Train_Loss: 0.5175 Train_Acc: 76.757 Val_Loss: 0.4956  BEST VAL Loss: 0.4956  Val_Acc: 77.827

Epoch 9: Validation loss decreased (0.495566 --> 0.492552).  Saving model ...
	 Train_Loss: 0.5138 Train_Acc: 76.873 Val_Loss: 0.4926  BEST VAL Loss: 0.4926  Val_Acc: 77.801

Epoch 10: Validation loss decreased (0.492552 --> 0.489825).  Saving model ...
	 Train_Loss: 0.5104 Train_Acc: 77.120 Val_Loss: 0.4898  BEST VAL Loss: 0.4898  Val_Acc: 78.212

Epoch 11: Validation loss decreased (0.489825 --> 0.487330).  Saving model ...
	 Train_Loss: 0.5074 Train_Acc: 77.266 Val_Loss: 0.4873  BEST VAL Loss: 0.4873  Val_Acc: 78.409

Epoch 12: Validation loss decreased (0.487330 --> 0.485013).  Saving model ...
	 Train_Loss: 0.5046 Train_Acc: 77.548 Val_Loss: 0.4850  BEST VAL Loss: 0.4850  Val_Acc: 78.544

Epoch 13: Validation loss decreased (0.485013 --> 0.482841).  Saving model ...
	 Train_Loss: 0.5021 Train_Acc: 77.605 Val_Loss: 0.4828  BEST VAL Loss: 0.4828  Val_Acc: 78.934

Epoch 14: Validation loss decreased (0.482841 --> 0.480965).  Saving model ...
	 Train_Loss: 0.4996 Train_Acc: 77.855 Val_Loss: 0.4810  BEST VAL Loss: 0.4810  Val_Acc: 78.737

Epoch 15: Validation loss decreased (0.480965 --> 0.479032).  Saving model ...
	 Train_Loss: 0.4973 Train_Acc: 77.960 Val_Loss: 0.4790  BEST VAL Loss: 0.4790  Val_Acc: 78.945

Epoch 16: Validation loss decreased (0.479032 --> 0.477177).  Saving model ...
	 Train_Loss: 0.4951 Train_Acc: 78.161 Val_Loss: 0.4772  BEST VAL Loss: 0.4772  Val_Acc: 79.168

Epoch 17: Validation loss decreased (0.477177 --> 0.475529).  Saving model ...
	 Train_Loss: 0.4931 Train_Acc: 78.199 Val_Loss: 0.4755  BEST VAL Loss: 0.4755  Val_Acc: 79.215

Epoch 18: Validation loss decreased (0.475529 --> 0.473882).  Saving model ...
	 Train_Loss: 0.4912 Train_Acc: 78.245 Val_Loss: 0.4739  BEST VAL Loss: 0.4739  Val_Acc: 79.579

Epoch 19: Validation loss decreased (0.473882 --> 0.472281).  Saving model ...
	 Train_Loss: 0.4894 Train_Acc: 78.368 Val_Loss: 0.4723  BEST VAL Loss: 0.4723  Val_Acc: 79.657

Epoch 20: Validation loss decreased (0.472281 --> 0.470799).  Saving model ...
	 Train_Loss: 0.4876 Train_Acc: 78.603 Val_Loss: 0.4708  BEST VAL Loss: 0.4708  Val_Acc: 79.932

Epoch 21: Validation loss decreased (0.470799 --> 0.469439).  Saving model ...
	 Train_Loss: 0.4859 Train_Acc: 78.648 Val_Loss: 0.4694  BEST VAL Loss: 0.4694  Val_Acc: 79.797

Epoch 22: Validation loss decreased (0.469439 --> 0.468024).  Saving model ...
	 Train_Loss: 0.4843 Train_Acc: 78.772 Val_Loss: 0.4680  BEST VAL Loss: 0.4680  Val_Acc: 80.156

Epoch 23: Validation loss decreased (0.468024 --> 0.466781).  Saving model ...
	 Train_Loss: 0.4827 Train_Acc: 78.776 Val_Loss: 0.4668  BEST VAL Loss: 0.4668  Val_Acc: 79.901

Epoch 24: Validation loss decreased (0.466781 --> 0.465557).  Saving model ...
	 Train_Loss: 0.4812 Train_Acc: 78.825 Val_Loss: 0.4656  BEST VAL Loss: 0.4656  Val_Acc: 79.896

Epoch 25: Validation loss decreased (0.465557 --> 0.464265).  Saving model ...
	 Train_Loss: 0.4798 Train_Acc: 78.927 Val_Loss: 0.4643  BEST VAL Loss: 0.4643  Val_Acc: 80.328

Epoch 26: Validation loss decreased (0.464265 --> 0.463254).  Saving model ...
	 Train_Loss: 0.4784 Train_Acc: 79.114 Val_Loss: 0.4633  BEST VAL Loss: 0.4633  Val_Acc: 79.730

Epoch 27: Validation loss decreased (0.463254 --> 0.462241).  Saving model ...
	 Train_Loss: 0.4771 Train_Acc: 79.063 Val_Loss: 0.4622  BEST VAL Loss: 0.4622  Val_Acc: 80.016

Epoch 28: Validation loss decreased (0.462241 --> 0.461106).  Saving model ...
	 Train_Loss: 0.4758 Train_Acc: 79.112 Val_Loss: 0.4611  BEST VAL Loss: 0.4611  Val_Acc: 80.478

Epoch 29: Validation loss decreased (0.461106 --> 0.459970).  Saving model ...
	 Train_Loss: 0.4746 Train_Acc: 79.133 Val_Loss: 0.4600  BEST VAL Loss: 0.4600  Val_Acc: 80.452

Epoch 30: Validation loss decreased (0.459970 --> 0.458922).  Saving model ...
	 Train_Loss: 0.4734 Train_Acc: 79.331 Val_Loss: 0.4589  BEST VAL Loss: 0.4589  Val_Acc: 80.172

Epoch 31: Validation loss decreased (0.458922 --> 0.457935).  Saving model ...
	 Train_Loss: 0.4722 Train_Acc: 79.346 Val_Loss: 0.4579  BEST VAL Loss: 0.4579  Val_Acc: 80.468

Epoch 32: Validation loss decreased (0.457935 --> 0.456891).  Saving model ...
	 Train_Loss: 0.4711 Train_Acc: 79.351 Val_Loss: 0.4569  BEST VAL Loss: 0.4569  Val_Acc: 80.697

Epoch 33: Validation loss decreased (0.456891 --> 0.455913).  Saving model ...
	 Train_Loss: 0.4700 Train_Acc: 79.481 Val_Loss: 0.4559  BEST VAL Loss: 0.4559  Val_Acc: 80.676

Epoch 34: Validation loss decreased (0.455913 --> 0.454974).  Saving model ...
	 Train_Loss: 0.4689 Train_Acc: 79.435 Val_Loss: 0.4550  BEST VAL Loss: 0.4550  Val_Acc: 80.785

Epoch 35: Validation loss decreased (0.454974 --> 0.453993).  Saving model ...
	 Train_Loss: 0.4679 Train_Acc: 79.565 Val_Loss: 0.4540  BEST VAL Loss: 0.4540  Val_Acc: 80.988

Epoch 36: Validation loss decreased (0.453993 --> 0.453070).  Saving model ...
	 Train_Loss: 0.4668 Train_Acc: 79.570 Val_Loss: 0.4531  BEST VAL Loss: 0.4531  Val_Acc: 80.811

Epoch 37: Validation loss decreased (0.453070 --> 0.452204).  Saving model ...
	 Train_Loss: 0.4658 Train_Acc: 79.672 Val_Loss: 0.4522  BEST VAL Loss: 0.4522  Val_Acc: 80.655

Epoch 38: Validation loss decreased (0.452204 --> 0.451349).  Saving model ...
	 Train_Loss: 0.4648 Train_Acc: 79.682 Val_Loss: 0.4513  BEST VAL Loss: 0.4513  Val_Acc: 81.076

Epoch 39: Validation loss decreased (0.451349 --> 0.450484).  Saving model ...
	 Train_Loss: 0.4639 Train_Acc: 79.587 Val_Loss: 0.4505  BEST VAL Loss: 0.4505  Val_Acc: 80.993

Epoch 40: Validation loss decreased (0.450484 --> 0.449742).  Saving model ...
	 Train_Loss: 0.4630 Train_Acc: 79.601 Val_Loss: 0.4497  BEST VAL Loss: 0.4497  Val_Acc: 80.764

Epoch 41: Validation loss decreased (0.449742 --> 0.448889).  Saving model ...
	 Train_Loss: 0.4621 Train_Acc: 79.775 Val_Loss: 0.4489  BEST VAL Loss: 0.4489  Val_Acc: 81.310

Epoch 42: Validation loss decreased (0.448889 --> 0.448045).  Saving model ...
	 Train_Loss: 0.4612 Train_Acc: 79.722 Val_Loss: 0.4480  BEST VAL Loss: 0.4480  Val_Acc: 81.284

Epoch 43: Validation loss decreased (0.448045 --> 0.447284).  Saving model ...
	 Train_Loss: 0.4604 Train_Acc: 79.802 Val_Loss: 0.4473  BEST VAL Loss: 0.4473  Val_Acc: 81.076

Epoch 44: Validation loss decreased (0.447284 --> 0.446561).  Saving model ...
	 Train_Loss: 0.4595 Train_Acc: 79.938 Val_Loss: 0.4466  BEST VAL Loss: 0.4466  Val_Acc: 80.925

Epoch 45: Validation loss decreased (0.446561 --> 0.445816).  Saving model ...
	 Train_Loss: 0.4587 Train_Acc: 79.925 Val_Loss: 0.4458  BEST VAL Loss: 0.4458  Val_Acc: 81.357

Epoch 46: Validation loss decreased (0.445816 --> 0.445121).  Saving model ...
	 Train_Loss: 0.4579 Train_Acc: 79.880 Val_Loss: 0.4451  BEST VAL Loss: 0.4451  Val_Acc: 81.076

Epoch 47: Validation loss decreased (0.445121 --> 0.444401).  Saving model ...
	 Train_Loss: 0.4571 Train_Acc: 80.023 Val_Loss: 0.4444  BEST VAL Loss: 0.4444  Val_Acc: 81.092

Epoch 48: Validation loss decreased (0.444401 --> 0.443709).  Saving model ...
	 Train_Loss: 0.4564 Train_Acc: 80.021 Val_Loss: 0.4437  BEST VAL Loss: 0.4437  Val_Acc: 81.435

Epoch 49: Validation loss decreased (0.443709 --> 0.443000).  Saving model ...
	 Train_Loss: 0.4556 Train_Acc: 80.101 Val_Loss: 0.4430  BEST VAL Loss: 0.4430  Val_Acc: 81.347

Epoch 50: Validation loss decreased (0.443000 --> 0.442304).  Saving model ...
	 Train_Loss: 0.4549 Train_Acc: 80.128 Val_Loss: 0.4423  BEST VAL Loss: 0.4423  Val_Acc: 81.430

Epoch 51: Validation loss decreased (0.442304 --> 0.441672).  Saving model ...
	 Train_Loss: 0.4542 Train_Acc: 80.014 Val_Loss: 0.4417  BEST VAL Loss: 0.4417  Val_Acc: 81.253

Epoch 52: Validation loss decreased (0.441672 --> 0.441004).  Saving model ...
	 Train_Loss: 0.4535 Train_Acc: 80.068 Val_Loss: 0.4410  BEST VAL Loss: 0.4410  Val_Acc: 81.347

Epoch 53: Validation loss decreased (0.441004 --> 0.440384).  Saving model ...
	 Train_Loss: 0.4528 Train_Acc: 80.031 Val_Loss: 0.4404  BEST VAL Loss: 0.4404  Val_Acc: 81.024

Epoch 54: Validation loss decreased (0.440384 --> 0.439746).  Saving model ...
	 Train_Loss: 0.4522 Train_Acc: 80.169 Val_Loss: 0.4397  BEST VAL Loss: 0.4397  Val_Acc: 81.461

Epoch 55: Validation loss decreased (0.439746 --> 0.439097).  Saving model ...
	 Train_Loss: 0.4515 Train_Acc: 80.140 Val_Loss: 0.4391  BEST VAL Loss: 0.4391  Val_Acc: 81.575

Epoch 56: Validation loss decreased (0.439097 --> 0.438469).  Saving model ...
	 Train_Loss: 0.4509 Train_Acc: 80.118 Val_Loss: 0.4385  BEST VAL Loss: 0.4385  Val_Acc: 81.534

Epoch 57: Validation loss decreased (0.438469 --> 0.437839).  Saving model ...
	 Train_Loss: 0.4503 Train_Acc: 80.175 Val_Loss: 0.4378  BEST VAL Loss: 0.4378  Val_Acc: 81.747

Epoch 58: Validation loss decreased (0.437839 --> 0.437238).  Saving model ...
	 Train_Loss: 0.4497 Train_Acc: 80.253 Val_Loss: 0.4372  BEST VAL Loss: 0.4372  Val_Acc: 81.502

Epoch 59: Validation loss decreased (0.437238 --> 0.436680).  Saving model ...
	 Train_Loss: 0.4491 Train_Acc: 80.227 Val_Loss: 0.4367  BEST VAL Loss: 0.4367  Val_Acc: 81.450

Epoch 60: Validation loss decreased (0.436680 --> 0.436084).  Saving model ...
	 Train_Loss: 0.4485 Train_Acc: 80.348 Val_Loss: 0.4361  BEST VAL Loss: 0.4361  Val_Acc: 81.726

Epoch 61: Validation loss decreased (0.436084 --> 0.435506).  Saving model ...
	 Train_Loss: 0.4479 Train_Acc: 80.313 Val_Loss: 0.4355  BEST VAL Loss: 0.4355  Val_Acc: 81.554

Epoch 62: Validation loss decreased (0.435506 --> 0.434943).  Saving model ...
	 Train_Loss: 0.4474 Train_Acc: 80.273 Val_Loss: 0.4349  BEST VAL Loss: 0.4349  Val_Acc: 81.716

Epoch 63: Validation loss decreased (0.434943 --> 0.434517).  Saving model ...
	 Train_Loss: 0.4468 Train_Acc: 80.385 Val_Loss: 0.4345  BEST VAL Loss: 0.4345  Val_Acc: 81.175

Epoch 64: Validation loss decreased (0.434517 --> 0.433996).  Saving model ...
	 Train_Loss: 0.4463 Train_Acc: 80.482 Val_Loss: 0.4340  BEST VAL Loss: 0.4340  Val_Acc: 81.762

Epoch 65: Validation loss decreased (0.433996 --> 0.433491).  Saving model ...
	 Train_Loss: 0.4457 Train_Acc: 80.397 Val_Loss: 0.4335  BEST VAL Loss: 0.4335  Val_Acc: 81.814

Epoch 66: Validation loss decreased (0.433491 --> 0.432974).  Saving model ...
	 Train_Loss: 0.4452 Train_Acc: 80.411 Val_Loss: 0.4330  BEST VAL Loss: 0.4330  Val_Acc: 81.622

Epoch 67: Validation loss decreased (0.432974 --> 0.432524).  Saving model ...
	 Train_Loss: 0.4447 Train_Acc: 80.391 Val_Loss: 0.4325  BEST VAL Loss: 0.4325  Val_Acc: 81.684

Epoch 68: Validation loss decreased (0.432524 --> 0.432057).  Saving model ...
	 Train_Loss: 0.4442 Train_Acc: 80.435 Val_Loss: 0.4321  BEST VAL Loss: 0.4321  Val_Acc: 81.872

Epoch 69: Validation loss decreased (0.432057 --> 0.431587).  Saving model ...
	 Train_Loss: 0.4437 Train_Acc: 80.492 Val_Loss: 0.4316  BEST VAL Loss: 0.4316  Val_Acc: 81.851

Epoch 70: Validation loss decreased (0.431587 --> 0.431140).  Saving model ...
	 Train_Loss: 0.4432 Train_Acc: 80.523 Val_Loss: 0.4311  BEST VAL Loss: 0.4311  Val_Acc: 81.586

Epoch 71: Validation loss decreased (0.431140 --> 0.430698).  Saving model ...
	 Train_Loss: 0.4427 Train_Acc: 80.529 Val_Loss: 0.4307  BEST VAL Loss: 0.4307  Val_Acc: 81.918

Epoch 72: Validation loss decreased (0.430698 --> 0.430273).  Saving model ...
	 Train_Loss: 0.4422 Train_Acc: 80.493 Val_Loss: 0.4303  BEST VAL Loss: 0.4303  Val_Acc: 81.783

Epoch 73: Validation loss decreased (0.430273 --> 0.429824).  Saving model ...
	 Train_Loss: 0.4418 Train_Acc: 80.563 Val_Loss: 0.4298  BEST VAL Loss: 0.4298  Val_Acc: 81.762

Epoch 74: Validation loss decreased (0.429824 --> 0.429383).  Saving model ...
	 Train_Loss: 0.4413 Train_Acc: 80.589 Val_Loss: 0.4294  BEST VAL Loss: 0.4294  Val_Acc: 81.747

Epoch 75: Validation loss decreased (0.429383 --> 0.429014).  Saving model ...
	 Train_Loss: 0.4409 Train_Acc: 80.636 Val_Loss: 0.4290  BEST VAL Loss: 0.4290  Val_Acc: 81.508

Epoch 76: Validation loss decreased (0.429014 --> 0.428638).  Saving model ...
	 Train_Loss: 0.4405 Train_Acc: 80.541 Val_Loss: 0.4286  BEST VAL Loss: 0.4286  Val_Acc: 81.638

Epoch 77: Validation loss decreased (0.428638 --> 0.428269).  Saving model ...
	 Train_Loss: 0.4400 Train_Acc: 80.539 Val_Loss: 0.4283  BEST VAL Loss: 0.4283  Val_Acc: 81.508

Epoch 78: Validation loss decreased (0.428269 --> 0.427892).  Saving model ...
	 Train_Loss: 0.4396 Train_Acc: 80.563 Val_Loss: 0.4279  BEST VAL Loss: 0.4279  Val_Acc: 81.788

Epoch 79: Validation loss decreased (0.427892 --> 0.427488).  Saving model ...
	 Train_Loss: 0.4392 Train_Acc: 80.550 Val_Loss: 0.4275  BEST VAL Loss: 0.4275  Val_Acc: 81.820

Epoch 80: Validation loss decreased (0.427488 --> 0.427124).  Saving model ...
	 Train_Loss: 0.4388 Train_Acc: 80.506 Val_Loss: 0.4271  BEST VAL Loss: 0.4271  Val_Acc: 82.038

Epoch 81: Validation loss decreased (0.427124 --> 0.426777).  Saving model ...
	 Train_Loss: 0.4384 Train_Acc: 80.662 Val_Loss: 0.4268  BEST VAL Loss: 0.4268  Val_Acc: 81.944

Epoch 82: Validation loss decreased (0.426777 --> 0.426423).  Saving model ...
	 Train_Loss: 0.4380 Train_Acc: 80.665 Val_Loss: 0.4264  BEST VAL Loss: 0.4264  Val_Acc: 81.664

Epoch 83: Validation loss decreased (0.426423 --> 0.426058).  Saving model ...
	 Train_Loss: 0.4376 Train_Acc: 80.644 Val_Loss: 0.4261  BEST VAL Loss: 0.4261  Val_Acc: 82.100

Epoch 84: Validation loss decreased (0.426058 --> 0.425780).  Saving model ...
	 Train_Loss: 0.4372 Train_Acc: 80.715 Val_Loss: 0.4258  BEST VAL Loss: 0.4258  Val_Acc: 81.518

Epoch 85: Validation loss decreased (0.425780 --> 0.425456).  Saving model ...
	 Train_Loss: 0.4368 Train_Acc: 80.630 Val_Loss: 0.4255  BEST VAL Loss: 0.4255  Val_Acc: 81.622

Epoch 86: Validation loss decreased (0.425456 --> 0.425093).  Saving model ...
	 Train_Loss: 0.4365 Train_Acc: 80.679 Val_Loss: 0.4251  BEST VAL Loss: 0.4251  Val_Acc: 81.976

Epoch 87: Validation loss decreased (0.425093 --> 0.424782).  Saving model ...
	 Train_Loss: 0.4361 Train_Acc: 80.635 Val_Loss: 0.4248  BEST VAL Loss: 0.4248  Val_Acc: 81.768

Epoch 88: Validation loss decreased (0.424782 --> 0.424427).  Saving model ...
	 Train_Loss: 0.4357 Train_Acc: 80.672 Val_Loss: 0.4244  BEST VAL Loss: 0.4244  Val_Acc: 82.022

Epoch 89: Validation loss decreased (0.424427 --> 0.424120).  Saving model ...
	 Train_Loss: 0.4354 Train_Acc: 80.714 Val_Loss: 0.4241  BEST VAL Loss: 0.4241  Val_Acc: 81.736

Epoch 90: Validation loss decreased (0.424120 --> 0.423796).  Saving model ...
	 Train_Loss: 0.4350 Train_Acc: 80.680 Val_Loss: 0.4238  BEST VAL Loss: 0.4238  Val_Acc: 82.028

Epoch 91: Validation loss decreased (0.423796 --> 0.423481).  Saving model ...
	 Train_Loss: 0.4347 Train_Acc: 80.669 Val_Loss: 0.4235  BEST VAL Loss: 0.4235  Val_Acc: 81.872

Epoch 92: Validation loss decreased (0.423481 --> 0.423183).  Saving model ...
	 Train_Loss: 0.4344 Train_Acc: 80.750 Val_Loss: 0.4232  BEST VAL Loss: 0.4232  Val_Acc: 81.939

Epoch 93: Validation loss decreased (0.423183 --> 0.422854).  Saving model ...
	 Train_Loss: 0.4340 Train_Acc: 80.723 Val_Loss: 0.4229  BEST VAL Loss: 0.4229  Val_Acc: 82.054

Epoch 94: Validation loss decreased (0.422854 --> 0.422546).  Saving model ...
	 Train_Loss: 0.4337 Train_Acc: 80.755 Val_Loss: 0.4225  BEST VAL Loss: 0.4225  Val_Acc: 81.898

Epoch 95: Validation loss decreased (0.422546 --> 0.422266).  Saving model ...
	 Train_Loss: 0.4334 Train_Acc: 80.669 Val_Loss: 0.4223  BEST VAL Loss: 0.4223  Val_Acc: 81.898

Epoch 96: Validation loss decreased (0.422266 --> 0.421949).  Saving model ...
	 Train_Loss: 0.4331 Train_Acc: 80.801 Val_Loss: 0.4219  BEST VAL Loss: 0.4219  Val_Acc: 82.048

Epoch 97: Validation loss decreased (0.421949 --> 0.421687).  Saving model ...
	 Train_Loss: 0.4327 Train_Acc: 80.834 Val_Loss: 0.4217  BEST VAL Loss: 0.4217  Val_Acc: 81.794

Epoch 98: Validation loss decreased (0.421687 --> 0.421406).  Saving model ...
	 Train_Loss: 0.4324 Train_Acc: 80.744 Val_Loss: 0.4214  BEST VAL Loss: 0.4214  Val_Acc: 81.986

Epoch 99: Validation loss decreased (0.421406 --> 0.421122).  Saving model ...
	 Train_Loss: 0.4321 Train_Acc: 80.867 Val_Loss: 0.4211  BEST VAL Loss: 0.4211  Val_Acc: 82.199

Flagellin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.85      0.68      0.75     56122
           1       0.83      0.93      0.88     97753

    accuracy                           0.84    153875
   macro avg       0.84      0.80      0.82    153875
weighted avg       0.84      0.84      0.83    153875

Flagellin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.83      0.65      0.73      7015
           1       0.82      0.92      0.87     12220

    accuracy                           0.82     19235
   macro avg       0.82      0.78      0.80     19235
weighted avg       0.82      0.82      0.82     19235

Flagellin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.82      0.65      0.72      7016
           1       0.82      0.92      0.87     12219

    accuracy                           0.82     19235
   macro avg       0.82      0.78      0.79     19235
weighted avg       0.82      0.82      0.81     19235

              precision    recall  f1-score   support

           0       0.82      0.65      0.72      7016
           1       0.82      0.92      0.87     12219

    accuracy                           0.82     19235
   macro avg       0.82      0.78      0.79     19235
weighted avg       0.82      0.82      0.81     19235

Flagellin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_1.000_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.86      0.39      0.54     34394
           1       0.63      0.94      0.75     37243

    accuracy                           0.68     71637
   macro avg       0.74      0.67      0.65     71637
weighted avg       0.74      0.68      0.65     71637

              precision    recall  f1-score   support

           0       0.86      0.39      0.54     34394
           1       0.63      0.94      0.75     37243

    accuracy                           0.68     71637
   macro avg       0.74      0.67      0.65     71637
weighted avg       0.74      0.68      0.65     71637

completed
