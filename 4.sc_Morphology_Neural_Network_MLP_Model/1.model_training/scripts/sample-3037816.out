[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '4869dd03'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '1978d68c'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'cd2aaacb'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '1cdd76c4'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_Nigericin_1.000_3.0_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (28580, 1276)
Number of total missing values across all columns: 29856
Data Subset Is Off
Wells held out for testing: ['L16' 'L22']
Wells to use for training, validation, and testing ['L17' 'L18' 'L19' 'L20' 'L21' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.327759).  Saving model ...
	 Train_Loss: 0.5526 Train_Acc: 70.197 Val_Loss: 0.3278  BEST VAL Loss: 0.3278  Val_Acc: 89.286

Epoch 1: Validation loss decreased (0.327759 --> 0.283096).  Saving model ...
	 Train_Loss: 0.4581 Train_Acc: 79.037 Val_Loss: 0.2831  BEST VAL Loss: 0.2831  Val_Acc: 89.286

Epoch 2: Validation loss decreased (0.283096 --> 0.259240).  Saving model ...
	 Train_Loss: 0.4077 Train_Acc: 84.576 Val_Loss: 0.2592  BEST VAL Loss: 0.2592  Val_Acc: 89.768

Epoch 3: Validation loss decreased (0.259240 --> 0.237811).  Saving model ...
	 Train_Loss: 0.3714 Train_Acc: 89.162 Val_Loss: 0.2378  BEST VAL Loss: 0.2378  Val_Acc: 91.409

Epoch 4: Validation loss decreased (0.237811 --> 0.222468).  Saving model ...
	 Train_Loss: 0.3437 Train_Acc: 91.679 Val_Loss: 0.2225  BEST VAL Loss: 0.2225  Val_Acc: 92.664

Epoch 5: Validation loss decreased (0.222468 --> 0.208872).  Saving model ...
	 Train_Loss: 0.3225 Train_Acc: 92.083 Val_Loss: 0.2089  BEST VAL Loss: 0.2089  Val_Acc: 93.485

Epoch 6: Validation loss decreased (0.208872 --> 0.199674).  Saving model ...
	 Train_Loss: 0.3037 Train_Acc: 93.224 Val_Loss: 0.1997  BEST VAL Loss: 0.1997  Val_Acc: 94.305

Epoch 7: Validation loss decreased (0.199674 --> 0.191055).  Saving model ...
	 Train_Loss: 0.2875 Train_Acc: 93.706 Val_Loss: 0.1911  BEST VAL Loss: 0.1911  Val_Acc: 94.643

Epoch 8: Validation loss decreased (0.191055 --> 0.184806).  Saving model ...
	 Train_Loss: 0.2737 Train_Acc: 94.352 Val_Loss: 0.1848  BEST VAL Loss: 0.1848  Val_Acc: 93.822

Epoch 9: Validation loss decreased (0.184806 --> 0.178153).  Saving model ...
	 Train_Loss: 0.2622 Train_Acc: 94.829 Val_Loss: 0.1782  BEST VAL Loss: 0.1782  Val_Acc: 95.125

Epoch 10: Validation loss decreased (0.178153 --> 0.172159).  Saving model ...
	 Train_Loss: 0.2516 Train_Acc: 94.829 Val_Loss: 0.1722  BEST VAL Loss: 0.1722  Val_Acc: 94.836

Epoch 11: Validation loss decreased (0.172159 --> 0.168509).  Saving model ...
	 Train_Loss: 0.2422 Train_Acc: 95.082 Val_Loss: 0.1685  BEST VAL Loss: 0.1685  Val_Acc: 95.222

Epoch 12: Validation loss did not decrease
	 Train_Loss: 0.2343 Train_Acc: 95.287 Val_Loss: 0.1692  BEST VAL Loss: 0.1685  Val_Acc: 94.884

Epoch 13: Validation loss decreased (0.168509 --> 0.165237).  Saving model ...
	 Train_Loss: 0.2271 Train_Acc: 95.215 Val_Loss: 0.1652  BEST VAL Loss: 0.1652  Val_Acc: 95.319

Epoch 14: Validation loss decreased (0.165237 --> 0.161728).  Saving model ...
	 Train_Loss: 0.2212 Train_Acc: 95.064 Val_Loss: 0.1617  BEST VAL Loss: 0.1617  Val_Acc: 94.691

Epoch 15: Validation loss decreased (0.161728 --> 0.159870).  Saving model ...
	 Train_Loss: 0.2159 Train_Acc: 94.859 Val_Loss: 0.1599  BEST VAL Loss: 0.1599  Val_Acc: 95.270

Epoch 16: Validation loss decreased (0.159870 --> 0.157219).  Saving model ...
	 Train_Loss: 0.2109 Train_Acc: 95.323 Val_Loss: 0.1572  BEST VAL Loss: 0.1572  Val_Acc: 95.270

Epoch 17: Validation loss decreased (0.157219 --> 0.154552).  Saving model ...
	 Train_Loss: 0.2057 Train_Acc: 95.776 Val_Loss: 0.1546  BEST VAL Loss: 0.1546  Val_Acc: 95.367

Epoch 18: Validation loss decreased (0.154552 --> 0.152464).  Saving model ...
	 Train_Loss: 0.2009 Train_Acc: 95.824 Val_Loss: 0.1525  BEST VAL Loss: 0.1525  Val_Acc: 95.656

Epoch 19: Validation loss decreased (0.152464 --> 0.151086).  Saving model ...
	 Train_Loss: 0.1960 Train_Acc: 96.452 Val_Loss: 0.1511  BEST VAL Loss: 0.1511  Val_Acc: 95.705

Epoch 20: Validation loss decreased (0.151086 --> 0.150246).  Saving model ...
	 Train_Loss: 0.1915 Train_Acc: 96.446 Val_Loss: 0.1502  BEST VAL Loss: 0.1502  Val_Acc: 95.946

Epoch 21: Validation loss decreased (0.150246 --> 0.148788).  Saving model ...
	 Train_Loss: 0.1876 Train_Acc: 96.223 Val_Loss: 0.1488  BEST VAL Loss: 0.1488  Val_Acc: 95.656

Epoch 22: Validation loss decreased (0.148788 --> 0.147402).  Saving model ...
	 Train_Loss: 0.1837 Train_Acc: 96.524 Val_Loss: 0.1474  BEST VAL Loss: 0.1474  Val_Acc: 95.849

Epoch 23: Validation loss decreased (0.147402 --> 0.146470).  Saving model ...
	 Train_Loss: 0.1801 Train_Acc: 96.760 Val_Loss: 0.1465  BEST VAL Loss: 0.1465  Val_Acc: 96.139

Epoch 24: Validation loss decreased (0.146470 --> 0.145366).  Saving model ...
	 Train_Loss: 0.1771 Train_Acc: 96.247 Val_Loss: 0.1454  BEST VAL Loss: 0.1454  Val_Acc: 96.332

Epoch 25: Validation loss decreased (0.145366 --> 0.145188).  Saving model ...
	 Train_Loss: 0.1739 Train_Acc: 96.633 Val_Loss: 0.1452  BEST VAL Loss: 0.1452  Val_Acc: 95.608

Epoch 26: Validation loss decreased (0.145188 --> 0.144941).  Saving model ...
	 Train_Loss: 0.1707 Train_Acc: 96.748 Val_Loss: 0.1449  BEST VAL Loss: 0.1449  Val_Acc: 95.753

Epoch 27: Validation loss decreased (0.144941 --> 0.144772).  Saving model ...
	 Train_Loss: 0.1679 Train_Acc: 96.741 Val_Loss: 0.1448  BEST VAL Loss: 0.1448  Val_Acc: 95.125

Epoch 28: Validation loss decreased (0.144772 --> 0.144522).  Saving model ...
	 Train_Loss: 0.1652 Train_Acc: 96.560 Val_Loss: 0.1445  BEST VAL Loss: 0.1445  Val_Acc: 95.560

Epoch 29: Validation loss decreased (0.144522 --> 0.144069).  Saving model ...
	 Train_Loss: 0.1629 Train_Acc: 96.711 Val_Loss: 0.1441  BEST VAL Loss: 0.1441  Val_Acc: 95.801

Epoch 30: Validation loss decreased (0.144069 --> 0.143661).  Saving model ...
	 Train_Loss: 0.1606 Train_Acc: 96.681 Val_Loss: 0.1437  BEST VAL Loss: 0.1437  Val_Acc: 95.898

Epoch 31: Validation loss decreased (0.143661 --> 0.143604).  Saving model ...
	 Train_Loss: 0.1584 Train_Acc: 96.458 Val_Loss: 0.1436  BEST VAL Loss: 0.1436  Val_Acc: 95.415

Epoch 32: Validation loss decreased (0.143604 --> 0.143260).  Saving model ...
	 Train_Loss: 0.1565 Train_Acc: 96.717 Val_Loss: 0.1433  BEST VAL Loss: 0.1433  Val_Acc: 95.705

Epoch 33: Validation loss decreased (0.143260 --> 0.142556).  Saving model ...
	 Train_Loss: 0.1546 Train_Acc: 96.766 Val_Loss: 0.1426  BEST VAL Loss: 0.1426  Val_Acc: 96.042

Epoch 34: Validation loss decreased (0.142556 --> 0.142178).  Saving model ...
	 Train_Loss: 0.1526 Train_Acc: 96.953 Val_Loss: 0.1422  BEST VAL Loss: 0.1422  Val_Acc: 95.560

Epoch 35: Validation loss decreased (0.142178 --> 0.141297).  Saving model ...
	 Train_Loss: 0.1508 Train_Acc: 97.098 Val_Loss: 0.1413  BEST VAL Loss: 0.1413  Val_Acc: 96.091

Epoch 36: Validation loss decreased (0.141297 --> 0.141155).  Saving model ...
	 Train_Loss: 0.1490 Train_Acc: 96.995 Val_Loss: 0.1412  BEST VAL Loss: 0.1412  Val_Acc: 95.849

Epoch 37: Validation loss did not decrease
	 Train_Loss: 0.1475 Train_Acc: 96.748 Val_Loss: 0.1412  BEST VAL Loss: 0.1412  Val_Acc: 95.560

Epoch 38: Validation loss decreased (0.141155 --> 0.140918).  Saving model ...
	 Train_Loss: 0.1458 Train_Acc: 97.122 Val_Loss: 0.1409  BEST VAL Loss: 0.1409  Val_Acc: 95.608

Epoch 39: Validation loss did not decrease
	 Train_Loss: 0.1441 Train_Acc: 97.116 Val_Loss: 0.1412  BEST VAL Loss: 0.1409  Val_Acc: 95.946

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.1423 Train_Acc: 97.719 Val_Loss: 0.1413  BEST VAL Loss: 0.1409  Val_Acc: 96.091

Epoch 41: Validation loss did not decrease
	 Train_Loss: 0.1404 Train_Acc: 97.508 Val_Loss: 0.1416  BEST VAL Loss: 0.1409  Val_Acc: 95.705

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.1388 Train_Acc: 97.496 Val_Loss: 0.1422  BEST VAL Loss: 0.1409  Val_Acc: 95.801

Epoch 43: Validation loss did not decrease
	 Train_Loss: 0.1373 Train_Acc: 97.182 Val_Loss: 0.1429  BEST VAL Loss: 0.1409  Val_Acc: 95.415

Epoch 44: Validation loss did not decrease
	 Train_Loss: 0.1359 Train_Acc: 97.303 Val_Loss: 0.1429  BEST VAL Loss: 0.1409  Val_Acc: 95.705

Epoch 45: Validation loss did not decrease
	 Train_Loss: 0.1348 Train_Acc: 97.007 Val_Loss: 0.1424  BEST VAL Loss: 0.1409  Val_Acc: 95.994

Epoch 46: Validation loss did not decrease
	 Train_Loss: 0.1338 Train_Acc: 96.977 Val_Loss: 0.1422  BEST VAL Loss: 0.1409  Val_Acc: 95.174

Epoch 47: Validation loss did not decrease
	 Train_Loss: 0.1326 Train_Acc: 96.965 Val_Loss: 0.1421  BEST VAL Loss: 0.1409  Val_Acc: 96.284

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.1314 Train_Acc: 97.224 Val_Loss: 0.1427  BEST VAL Loss: 0.1409  Val_Acc: 95.801

Epoch 49: Validation loss did not decrease
	 Train_Loss: 0.1303 Train_Acc: 97.019 Val_Loss: 0.1437  BEST VAL Loss: 0.1409  Val_Acc: 95.898

Epoch 50: Validation loss did not decrease
	 Train_Loss: 0.1292 Train_Acc: 97.254 Val_Loss: 0.1433  BEST VAL Loss: 0.1409  Val_Acc: 96.525

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.1281 Train_Acc: 97.399 Val_Loss: 0.1442  BEST VAL Loss: 0.1409  Val_Acc: 96.139

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.1270 Train_Acc: 97.357 Val_Loss: 0.1438  BEST VAL Loss: 0.1409  Val_Acc: 96.380

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.1260 Train_Acc: 97.520 Val_Loss: 0.1436  BEST VAL Loss: 0.1409  Val_Acc: 96.429

Epoch 54: Validation loss did not decrease
Early stopped at epoch : 54
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       1.00      0.99      0.99      8634
           1       0.98      1.00      0.99      7938

    accuracy                           0.99     16572
   macro avg       0.99      0.99      0.99     16572
weighted avg       0.99      0.99      0.99     16572

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.94      0.96      1080
           1       0.93      0.98      0.96       992

    accuracy                           0.96      2072
   macro avg       0.96      0.96      0.96      2072
weighted avg       0.96      0.96      0.96      2072

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.98      0.95      0.96      1079
           1       0.95      0.98      0.96       993

    accuracy                           0.96      2072
   macro avg       0.96      0.96      0.96      2072
weighted avg       0.96      0.96      0.96      2072

              precision    recall  f1-score   support

           0       0.98      0.95      0.96      1079
           1       0.95      0.98      0.96       993

    accuracy                           0.96      2072
   macro avg       0.96      0.96      0.96      2072
weighted avg       0.96      0.96      0.96      2072

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.94      0.92      0.93      4135
           1       0.91      0.94      0.92      3729

    accuracy                           0.93      7864
   macro avg       0.93      0.93      0.93      7864
weighted avg       0.93      0.93      0.93      7864

              precision    recall  f1-score   support

           0       0.94      0.92      0.93      4135
           1       0.91      0.94      0.92      3729

    accuracy                           0.93      7864
   macro avg       0.93      0.93      0.93      7864
weighted avg       0.93      0.93      0.93      7864

completed
