[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '91ab5471'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '4d846369'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b97f0e82'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '8e9061c8'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Flagellin_1.000_DMSO_0.025 treatment_name: LPS_1.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Flagellin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_1.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (32267, 1276)
Number of total missing values across all columns: 64534
Data Subset Is Off
Wells held out for testing: ['D21' 'M22']
Wells to use for training, validation, and testing ['D16' 'D17' 'D20' 'M18' 'M19' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.685444).  Saving model ...
	 Train_Loss: 0.7000 Train_Acc: 48.476 Val_Loss: 0.6854  BEST VAL Loss: 0.6854  Val_Acc: 48.459

Epoch 1: Validation loss decreased (0.685444 --> 0.680295).  Saving model ...
	 Train_Loss: 0.6892 Train_Acc: 56.328 Val_Loss: 0.6803  BEST VAL Loss: 0.6803  Val_Acc: 59.597

Epoch 2: Validation loss decreased (0.680295 --> 0.675506).  Saving model ...
	 Train_Loss: 0.6827 Train_Acc: 60.778 Val_Loss: 0.6755  BEST VAL Loss: 0.6755  Val_Acc: 61.488

Epoch 3: Validation loss decreased (0.675506 --> 0.670132).  Saving model ...
	 Train_Loss: 0.6766 Train_Acc: 62.222 Val_Loss: 0.6701  BEST VAL Loss: 0.6701  Val_Acc: 63.337

Epoch 4: Validation loss decreased (0.670132 --> 0.666569).  Saving model ...
	 Train_Loss: 0.6713 Train_Acc: 63.542 Val_Loss: 0.6666  BEST VAL Loss: 0.6666  Val_Acc: 63.872

Epoch 5: Validation loss decreased (0.666569 --> 0.662529).  Saving model ...
	 Train_Loss: 0.6661 Train_Acc: 64.524 Val_Loss: 0.6625  BEST VAL Loss: 0.6625  Val_Acc: 65.023

Epoch 6: Validation loss decreased (0.662529 --> 0.659230).  Saving model ...
	 Train_Loss: 0.6616 Train_Acc: 65.392 Val_Loss: 0.6592  BEST VAL Loss: 0.6592  Val_Acc: 65.557

Epoch 7: Validation loss decreased (0.659230 --> 0.655039).  Saving model ...
	 Train_Loss: 0.6573 Train_Acc: 66.173 Val_Loss: 0.6550  BEST VAL Loss: 0.6550  Val_Acc: 66.790

Epoch 8: Validation loss decreased (0.655039 --> 0.651938).  Saving model ...
	 Train_Loss: 0.6533 Train_Acc: 66.831 Val_Loss: 0.6519  BEST VAL Loss: 0.6519  Val_Acc: 67.735

Epoch 9: Validation loss decreased (0.651938 --> 0.648086).  Saving model ...
	 Train_Loss: 0.6497 Train_Acc: 66.949 Val_Loss: 0.6481  BEST VAL Loss: 0.6481  Val_Acc: 68.105

Epoch 10: Validation loss decreased (0.648086 --> 0.645021).  Saving model ...
	 Train_Loss: 0.6462 Train_Acc: 67.828 Val_Loss: 0.6450  BEST VAL Loss: 0.6450  Val_Acc: 68.681

Epoch 11: Validation loss decreased (0.645021 --> 0.642402).  Saving model ...
	 Train_Loss: 0.6428 Train_Acc: 68.069 Val_Loss: 0.6424  BEST VAL Loss: 0.6424  Val_Acc: 68.393

Epoch 12: Validation loss decreased (0.642402 --> 0.639299).  Saving model ...
	 Train_Loss: 0.6398 Train_Acc: 68.614 Val_Loss: 0.6393  BEST VAL Loss: 0.6393  Val_Acc: 68.270

Epoch 13: Validation loss decreased (0.639299 --> 0.636350).  Saving model ...
	 Train_Loss: 0.6370 Train_Acc: 68.511 Val_Loss: 0.6363  BEST VAL Loss: 0.6363  Val_Acc: 69.338

Epoch 14: Validation loss decreased (0.636350 --> 0.633872).  Saving model ...
	 Train_Loss: 0.6344 Train_Acc: 68.470 Val_Loss: 0.6339  BEST VAL Loss: 0.6339  Val_Acc: 69.462

Epoch 15: Validation loss decreased (0.633872 --> 0.631371).  Saving model ...
	 Train_Loss: 0.6322 Train_Acc: 68.558 Val_Loss: 0.6314  BEST VAL Loss: 0.6314  Val_Acc: 69.955

Epoch 16: Validation loss decreased (0.631371 --> 0.628866).  Saving model ...
	 Train_Loss: 0.6298 Train_Acc: 69.853 Val_Loss: 0.6289  BEST VAL Loss: 0.6289  Val_Acc: 70.242

Epoch 17: Validation loss decreased (0.628866 --> 0.626387).  Saving model ...
	 Train_Loss: 0.6277 Train_Acc: 69.683 Val_Loss: 0.6264  BEST VAL Loss: 0.6264  Val_Acc: 70.448

Epoch 18: Validation loss decreased (0.626387 --> 0.624325).  Saving model ...
	 Train_Loss: 0.6256 Train_Acc: 69.760 Val_Loss: 0.6243  BEST VAL Loss: 0.6243  Val_Acc: 69.667

Epoch 19: Validation loss decreased (0.624325 --> 0.622810).  Saving model ...
	 Train_Loss: 0.6237 Train_Acc: 69.883 Val_Loss: 0.6228  BEST VAL Loss: 0.6228  Val_Acc: 69.873

Epoch 20: Validation loss decreased (0.622810 --> 0.620858).  Saving model ...
	 Train_Loss: 0.6219 Train_Acc: 70.094 Val_Loss: 0.6209  BEST VAL Loss: 0.6209  Val_Acc: 70.242

Epoch 21: Validation loss decreased (0.620858 --> 0.619023).  Saving model ...
	 Train_Loss: 0.6202 Train_Acc: 70.243 Val_Loss: 0.6190  BEST VAL Loss: 0.6190  Val_Acc: 69.914

Epoch 22: Validation loss decreased (0.619023 --> 0.617291).  Saving model ...
	 Train_Loss: 0.6184 Train_Acc: 70.459 Val_Loss: 0.6173  BEST VAL Loss: 0.6173  Val_Acc: 70.859

Epoch 23: Validation loss decreased (0.617291 --> 0.615747).  Saving model ...
	 Train_Loss: 0.6167 Train_Acc: 70.536 Val_Loss: 0.6157  BEST VAL Loss: 0.6157  Val_Acc: 70.777

Epoch 24: Validation loss decreased (0.615747 --> 0.614048).  Saving model ...
	 Train_Loss: 0.6152 Train_Acc: 70.937 Val_Loss: 0.6140  BEST VAL Loss: 0.6140  Val_Acc: 71.434

Epoch 25: Validation loss decreased (0.614048 --> 0.612539).  Saving model ...
	 Train_Loss: 0.6136 Train_Acc: 71.009 Val_Loss: 0.6125  BEST VAL Loss: 0.6125  Val_Acc: 72.298

Epoch 26: Validation loss decreased (0.612539 --> 0.611218).  Saving model ...
	 Train_Loss: 0.6122 Train_Acc: 71.230 Val_Loss: 0.6112  BEST VAL Loss: 0.6112  Val_Acc: 71.393

Epoch 27: Validation loss decreased (0.611218 --> 0.610115).  Saving model ...
	 Train_Loss: 0.6108 Train_Acc: 71.322 Val_Loss: 0.6101  BEST VAL Loss: 0.6101  Val_Acc: 70.818

Epoch 28: Validation loss decreased (0.610115 --> 0.608927).  Saving model ...
	 Train_Loss: 0.6095 Train_Acc: 71.589 Val_Loss: 0.6089  BEST VAL Loss: 0.6089  Val_Acc: 70.982

Epoch 29: Validation loss decreased (0.608927 --> 0.607913).  Saving model ...
	 Train_Loss: 0.6083 Train_Acc: 71.014 Val_Loss: 0.6079  BEST VAL Loss: 0.6079  Val_Acc: 70.736

Epoch 30: Validation loss decreased (0.607913 --> 0.606977).  Saving model ...
	 Train_Loss: 0.6070 Train_Acc: 71.358 Val_Loss: 0.6070  BEST VAL Loss: 0.6070  Val_Acc: 71.106

Epoch 31: Validation loss decreased (0.606977 --> 0.605605).  Saving model ...
	 Train_Loss: 0.6058 Train_Acc: 71.440 Val_Loss: 0.6056  BEST VAL Loss: 0.6056  Val_Acc: 71.887

Epoch 32: Validation loss decreased (0.605605 --> 0.604652).  Saving model ...
	 Train_Loss: 0.6047 Train_Acc: 71.250 Val_Loss: 0.6047  BEST VAL Loss: 0.6047  Val_Acc: 71.599

Epoch 33: Validation loss decreased (0.604652 --> 0.603697).  Saving model ...
	 Train_Loss: 0.6037 Train_Acc: 71.466 Val_Loss: 0.6037  BEST VAL Loss: 0.6037  Val_Acc: 70.900

Epoch 34: Validation loss decreased (0.603697 --> 0.602655).  Saving model ...
	 Train_Loss: 0.6026 Train_Acc: 71.594 Val_Loss: 0.6027  BEST VAL Loss: 0.6027  Val_Acc: 71.722

Epoch 35: Validation loss decreased (0.602655 --> 0.601700).  Saving model ...
	 Train_Loss: 0.6017 Train_Acc: 71.173 Val_Loss: 0.6017  BEST VAL Loss: 0.6017  Val_Acc: 72.462

Epoch 36: Validation loss decreased (0.601700 --> 0.601075).  Saving model ...
	 Train_Loss: 0.6008 Train_Acc: 71.523 Val_Loss: 0.6011  BEST VAL Loss: 0.6011  Val_Acc: 71.969

Epoch 37: Validation loss decreased (0.601075 --> 0.600311).  Saving model ...
	 Train_Loss: 0.5998 Train_Acc: 71.923 Val_Loss: 0.6003  BEST VAL Loss: 0.6003  Val_Acc: 71.352

Epoch 38: Validation loss decreased (0.600311 --> 0.599377).  Saving model ...
	 Train_Loss: 0.5988 Train_Acc: 72.432 Val_Loss: 0.5994  BEST VAL Loss: 0.5994  Val_Acc: 71.106

Epoch 39: Validation loss decreased (0.599377 --> 0.598552).  Saving model ...
	 Train_Loss: 0.5981 Train_Acc: 71.600 Val_Loss: 0.5986  BEST VAL Loss: 0.5986  Val_Acc: 72.380

Epoch 40: Validation loss decreased (0.598552 --> 0.597694).  Saving model ...
	 Train_Loss: 0.5972 Train_Acc: 71.908 Val_Loss: 0.5977  BEST VAL Loss: 0.5977  Val_Acc: 72.215

Epoch 41: Validation loss decreased (0.597694 --> 0.596934).  Saving model ...
	 Train_Loss: 0.5965 Train_Acc: 71.579 Val_Loss: 0.5969  BEST VAL Loss: 0.5969  Val_Acc: 71.969

Epoch 42: Validation loss decreased (0.596934 --> 0.596342).  Saving model ...
	 Train_Loss: 0.5957 Train_Acc: 72.144 Val_Loss: 0.5963  BEST VAL Loss: 0.5963  Val_Acc: 72.503

Epoch 43: Validation loss decreased (0.596342 --> 0.595754).  Saving model ...
	 Train_Loss: 0.5948 Train_Acc: 72.596 Val_Loss: 0.5958  BEST VAL Loss: 0.5958  Val_Acc: 72.298

Epoch 44: Validation loss decreased (0.595754 --> 0.595180).  Saving model ...
	 Train_Loss: 0.5940 Train_Acc: 72.360 Val_Loss: 0.5952  BEST VAL Loss: 0.5952  Val_Acc: 72.544

Epoch 45: Validation loss decreased (0.595180 --> 0.594633).  Saving model ...
	 Train_Loss: 0.5932 Train_Acc: 72.298 Val_Loss: 0.5946  BEST VAL Loss: 0.5946  Val_Acc: 71.928

Epoch 46: Validation loss decreased (0.594633 --> 0.594032).  Saving model ...
	 Train_Loss: 0.5925 Train_Acc: 72.134 Val_Loss: 0.5940  BEST VAL Loss: 0.5940  Val_Acc: 71.188

Epoch 47: Validation loss decreased (0.594032 --> 0.593406).  Saving model ...
	 Train_Loss: 0.5918 Train_Acc: 72.160 Val_Loss: 0.5934  BEST VAL Loss: 0.5934  Val_Acc: 72.298

Epoch 48: Validation loss decreased (0.593406 --> 0.592825).  Saving model ...
	 Train_Loss: 0.5911 Train_Acc: 72.710 Val_Loss: 0.5928  BEST VAL Loss: 0.5928  Val_Acc: 71.845

Epoch 49: Validation loss decreased (0.592825 --> 0.592177).  Saving model ...
	 Train_Loss: 0.5905 Train_Acc: 71.964 Val_Loss: 0.5922  BEST VAL Loss: 0.5922  Val_Acc: 72.955

Epoch 50: Validation loss decreased (0.592177 --> 0.591493).  Saving model ...
	 Train_Loss: 0.5898 Train_Acc: 72.432 Val_Loss: 0.5915  BEST VAL Loss: 0.5915  Val_Acc: 73.490

Epoch 51: Validation loss decreased (0.591493 --> 0.590852).  Saving model ...
	 Train_Loss: 0.5892 Train_Acc: 72.535 Val_Loss: 0.5909  BEST VAL Loss: 0.5909  Val_Acc: 72.955

Epoch 52: Validation loss decreased (0.590852 --> 0.590258).  Saving model ...
	 Train_Loss: 0.5885 Train_Acc: 72.632 Val_Loss: 0.5903  BEST VAL Loss: 0.5903  Val_Acc: 72.133

Epoch 53: Validation loss decreased (0.590258 --> 0.589597).  Saving model ...
	 Train_Loss: 0.5879 Train_Acc: 72.720 Val_Loss: 0.5896  BEST VAL Loss: 0.5896  Val_Acc: 72.955

Epoch 54: Validation loss decreased (0.589597 --> 0.589085).  Saving model ...
	 Train_Loss: 0.5873 Train_Acc: 72.745 Val_Loss: 0.5891  BEST VAL Loss: 0.5891  Val_Acc: 72.955

Epoch 55: Validation loss decreased (0.589085 --> 0.588513).  Saving model ...
	 Train_Loss: 0.5867 Train_Acc: 72.581 Val_Loss: 0.5885  BEST VAL Loss: 0.5885  Val_Acc: 72.873

Epoch 56: Validation loss decreased (0.588513 --> 0.588061).  Saving model ...
	 Train_Loss: 0.5861 Train_Acc: 72.869 Val_Loss: 0.5881  BEST VAL Loss: 0.5881  Val_Acc: 72.873

Epoch 57: Validation loss decreased (0.588061 --> 0.587594).  Saving model ...
	 Train_Loss: 0.5855 Train_Acc: 72.478 Val_Loss: 0.5876  BEST VAL Loss: 0.5876  Val_Acc: 73.161

Epoch 58: Validation loss decreased (0.587594 --> 0.587072).  Saving model ...
	 Train_Loss: 0.5849 Train_Acc: 73.290 Val_Loss: 0.5871  BEST VAL Loss: 0.5871  Val_Acc: 73.613

Epoch 59: Validation loss decreased (0.587072 --> 0.586646).  Saving model ...
	 Train_Loss: 0.5843 Train_Acc: 73.044 Val_Loss: 0.5866  BEST VAL Loss: 0.5866  Val_Acc: 72.832

Epoch 60: Validation loss decreased (0.586646 --> 0.586244).  Saving model ...
	 Train_Loss: 0.5838 Train_Acc: 72.483 Val_Loss: 0.5862  BEST VAL Loss: 0.5862  Val_Acc: 72.791

Epoch 61: Validation loss decreased (0.586244 --> 0.585655).  Saving model ...
	 Train_Loss: 0.5833 Train_Acc: 72.848 Val_Loss: 0.5857  BEST VAL Loss: 0.5857  Val_Acc: 73.284

Epoch 62: Validation loss decreased (0.585655 --> 0.585175).  Saving model ...
	 Train_Loss: 0.5829 Train_Acc: 72.376 Val_Loss: 0.5852  BEST VAL Loss: 0.5852  Val_Acc: 72.626

Epoch 63: Validation loss decreased (0.585175 --> 0.584718).  Saving model ...
	 Train_Loss: 0.5825 Train_Acc: 72.684 Val_Loss: 0.5847  BEST VAL Loss: 0.5847  Val_Acc: 74.024

Epoch 64: Validation loss decreased (0.584718 --> 0.584468).  Saving model ...
	 Train_Loss: 0.5819 Train_Acc: 73.131 Val_Loss: 0.5845  BEST VAL Loss: 0.5845  Val_Acc: 73.736

Epoch 65: Validation loss decreased (0.584468 --> 0.584053).  Saving model ...
	 Train_Loss: 0.5815 Train_Acc: 72.751 Val_Loss: 0.5841  BEST VAL Loss: 0.5841  Val_Acc: 73.695

Epoch 66: Validation loss decreased (0.584053 --> 0.583773).  Saving model ...
	 Train_Loss: 0.5811 Train_Acc: 72.730 Val_Loss: 0.5838  BEST VAL Loss: 0.5838  Val_Acc: 72.503

Epoch 67: Validation loss decreased (0.583773 --> 0.583628).  Saving model ...
	 Train_Loss: 0.5806 Train_Acc: 73.023 Val_Loss: 0.5836  BEST VAL Loss: 0.5836  Val_Acc: 72.503

Epoch 68: Validation loss decreased (0.583628 --> 0.583314).  Saving model ...
	 Train_Loss: 0.5802 Train_Acc: 73.172 Val_Loss: 0.5833  BEST VAL Loss: 0.5833  Val_Acc: 72.914

Epoch 69: Validation loss decreased (0.583314 --> 0.582846).  Saving model ...
	 Train_Loss: 0.5798 Train_Acc: 73.182 Val_Loss: 0.5828  BEST VAL Loss: 0.5828  Val_Acc: 73.777

Epoch 70: Validation loss decreased (0.582846 --> 0.582632).  Saving model ...
	 Train_Loss: 0.5793 Train_Acc: 73.229 Val_Loss: 0.5826  BEST VAL Loss: 0.5826  Val_Acc: 72.421

Epoch 71: Validation loss decreased (0.582632 --> 0.582352).  Saving model ...
	 Train_Loss: 0.5790 Train_Acc: 72.787 Val_Loss: 0.5824  BEST VAL Loss: 0.5824  Val_Acc: 72.339

Epoch 72: Validation loss decreased (0.582352 --> 0.581992).  Saving model ...
	 Train_Loss: 0.5786 Train_Acc: 72.895 Val_Loss: 0.5820  BEST VAL Loss: 0.5820  Val_Acc: 73.366

Epoch 73: Validation loss decreased (0.581992 --> 0.581708).  Saving model ...
	 Train_Loss: 0.5782 Train_Acc: 73.131 Val_Loss: 0.5817  BEST VAL Loss: 0.5817  Val_Acc: 72.544

Epoch 74: Validation loss decreased (0.581708 --> 0.581430).  Saving model ...
	 Train_Loss: 0.5778 Train_Acc: 72.879 Val_Loss: 0.5814  BEST VAL Loss: 0.5814  Val_Acc: 72.750

Epoch 75: Validation loss decreased (0.581430 --> 0.581156).  Saving model ...
	 Train_Loss: 0.5774 Train_Acc: 73.131 Val_Loss: 0.5812  BEST VAL Loss: 0.5812  Val_Acc: 72.133

Epoch 76: Validation loss decreased (0.581156 --> 0.580848).  Saving model ...
	 Train_Loss: 0.5771 Train_Acc: 73.300 Val_Loss: 0.5808  BEST VAL Loss: 0.5808  Val_Acc: 73.859

Epoch 77: Validation loss decreased (0.580848 --> 0.580500).  Saving model ...
	 Train_Loss: 0.5767 Train_Acc: 72.869 Val_Loss: 0.5805  BEST VAL Loss: 0.5805  Val_Acc: 73.983

Epoch 78: Validation loss decreased (0.580500 --> 0.580255).  Saving model ...
	 Train_Loss: 0.5764 Train_Acc: 73.218 Val_Loss: 0.5803  BEST VAL Loss: 0.5803  Val_Acc: 73.654

Epoch 79: Validation loss decreased (0.580255 --> 0.579965).  Saving model ...
	 Train_Loss: 0.5760 Train_Acc: 72.992 Val_Loss: 0.5800  BEST VAL Loss: 0.5800  Val_Acc: 73.325

Epoch 80: Validation loss decreased (0.579965 --> 0.579680).  Saving model ...
	 Train_Loss: 0.5757 Train_Acc: 72.992 Val_Loss: 0.5797  BEST VAL Loss: 0.5797  Val_Acc: 74.106

Epoch 81: Validation loss decreased (0.579680 --> 0.579543).  Saving model ...
	 Train_Loss: 0.5753 Train_Acc: 73.198 Val_Loss: 0.5795  BEST VAL Loss: 0.5795  Val_Acc: 72.421

Epoch 82: Validation loss decreased (0.579543 --> 0.579319).  Saving model ...
	 Train_Loss: 0.5750 Train_Acc: 73.105 Val_Loss: 0.5793  BEST VAL Loss: 0.5793  Val_Acc: 72.996

Epoch 83: Validation loss decreased (0.579319 --> 0.579003).  Saving model ...
	 Train_Loss: 0.5746 Train_Acc: 73.439 Val_Loss: 0.5790  BEST VAL Loss: 0.5790  Val_Acc: 73.859

Epoch 84: Validation loss decreased (0.579003 --> 0.578834).  Saving model ...
	 Train_Loss: 0.5743 Train_Acc: 73.208 Val_Loss: 0.5788  BEST VAL Loss: 0.5788  Val_Acc: 72.791

Epoch 85: Validation loss decreased (0.578834 --> 0.578612).  Saving model ...
	 Train_Loss: 0.5740 Train_Acc: 73.383 Val_Loss: 0.5786  BEST VAL Loss: 0.5786  Val_Acc: 73.942

Epoch 86: Validation loss decreased (0.578612 --> 0.578345).  Saving model ...
	 Train_Loss: 0.5736 Train_Acc: 73.552 Val_Loss: 0.5783  BEST VAL Loss: 0.5783  Val_Acc: 73.777

Epoch 87: Validation loss decreased (0.578345 --> 0.578147).  Saving model ...
	 Train_Loss: 0.5733 Train_Acc: 73.290 Val_Loss: 0.5781  BEST VAL Loss: 0.5781  Val_Acc: 72.421

Epoch 88: Validation loss decreased (0.578147 --> 0.578087).  Saving model ...
	 Train_Loss: 0.5730 Train_Acc: 72.915 Val_Loss: 0.5781  BEST VAL Loss: 0.5781  Val_Acc: 72.791

Epoch 89: Validation loss decreased (0.578087 --> 0.577924).  Saving model ...
	 Train_Loss: 0.5727 Train_Acc: 73.198 Val_Loss: 0.5779  BEST VAL Loss: 0.5779  Val_Acc: 72.339

Epoch 90: Validation loss decreased (0.577924 --> 0.577638).  Saving model ...
	 Train_Loss: 0.5724 Train_Acc: 73.367 Val_Loss: 0.5776  BEST VAL Loss: 0.5776  Val_Acc: 73.859

Epoch 91: Validation loss decreased (0.577638 --> 0.577352).  Saving model ...
	 Train_Loss: 0.5721 Train_Acc: 73.342 Val_Loss: 0.5774  BEST VAL Loss: 0.5774  Val_Acc: 73.572

Epoch 92: Validation loss decreased (0.577352 --> 0.577150).  Saving model ...
	 Train_Loss: 0.5718 Train_Acc: 73.157 Val_Loss: 0.5772  BEST VAL Loss: 0.5772  Val_Acc: 73.366

Epoch 93: Validation loss decreased (0.577150 --> 0.576891).  Saving model ...
	 Train_Loss: 0.5716 Train_Acc: 73.079 Val_Loss: 0.5769  BEST VAL Loss: 0.5769  Val_Acc: 73.448

Epoch 94: Validation loss decreased (0.576891 --> 0.576852).  Saving model ...
	 Train_Loss: 0.5713 Train_Acc: 73.218 Val_Loss: 0.5769  BEST VAL Loss: 0.5769  Val_Acc: 73.407

Epoch 95: Validation loss decreased (0.576852 --> 0.576681).  Saving model ...
	 Train_Loss: 0.5710 Train_Acc: 73.747 Val_Loss: 0.5767  BEST VAL Loss: 0.5767  Val_Acc: 73.243

Epoch 96: Validation loss decreased (0.576681 --> 0.576507).  Saving model ...
	 Train_Loss: 0.5707 Train_Acc: 73.383 Val_Loss: 0.5765  BEST VAL Loss: 0.5765  Val_Acc: 72.750

Epoch 97: Validation loss decreased (0.576507 --> 0.576385).  Saving model ...
	 Train_Loss: 0.5704 Train_Acc: 73.691 Val_Loss: 0.5764  BEST VAL Loss: 0.5764  Val_Acc: 72.832

Epoch 98: Validation loss decreased (0.576385 --> 0.576238).  Saving model ...
	 Train_Loss: 0.5701 Train_Acc: 73.968 Val_Loss: 0.5762  BEST VAL Loss: 0.5762  Val_Acc: 73.161

Epoch 99: Validation loss decreased (0.576238 --> 0.576011).  Saving model ...
	 Train_Loss: 0.5698 Train_Acc: 73.496 Val_Loss: 0.5760  BEST VAL Loss: 0.5760  Val_Acc: 73.983

Flagellin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.41      0.45      9434
           1       0.52      0.60      0.55     10027

    accuracy                           0.51     19461
   macro avg       0.50      0.50      0.50     19461
weighted avg       0.50      0.51      0.50     19461

Flagellin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.47      0.40      0.43      1179
           1       0.51      0.59      0.54      1254

    accuracy                           0.49      2433
   macro avg       0.49      0.49      0.49      2433
weighted avg       0.49      0.49      0.49      2433

Flagellin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.44      0.47      1179
           1       0.53      0.60      0.57      1254

    accuracy                           0.52      2433
   macro avg       0.52      0.52      0.52      2433
weighted avg       0.52      0.52      0.52      2433

              precision    recall  f1-score   support

           0       0.51      0.44      0.47      1179
           1       0.53      0.60      0.57      1254

    accuracy                           0.52      2433
   macro avg       0.52      0.52      0.52      2433
weighted avg       0.52      0.52      0.52      2433

Flagellin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Flagellin_1.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.51      0.45      0.48      4017
           1       0.50      0.55      0.52      3923

    accuracy                           0.50      7940
   macro avg       0.50      0.50      0.50      7940
weighted avg       0.50      0.50      0.50      7940

              precision    recall  f1-score   support

           0       0.51      0.45      0.48      4017
           1       0.50      0.55      0.52      3923

    accuracy                           0.50      7940
   macro avg       0.50      0.50      0.50      7940
weighted avg       0.50      0.50      0.50      7940

completed
