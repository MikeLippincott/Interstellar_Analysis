[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'd2ccd3c7'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '9e594711'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'a8f6b729'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'da07055b'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_0.010_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_0.010_DMSO_0.025
TREATMENT_NAME: LPS_100.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (302515, 1270)
Number of total missing values across all columns: 605030
Data Subset Is Off
Wells held out for testing: ['B08' 'J08']
Wells to use for training, validation, and testing ['B02' 'B03' 'B09' 'J02' 'J03' 'J09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.637925).  Saving model ...
	 Train_Loss: 0.6663 Train_Acc: 59.541 Val_Loss: 0.6379  BEST VAL Loss: 0.6379  Val_Acc: 63.292

Epoch 1: Validation loss decreased (0.637925 --> 0.629210).  Saving model ...
	 Train_Loss: 0.6502 Train_Acc: 63.571 Val_Loss: 0.6292  BEST VAL Loss: 0.6292  Val_Acc: 65.008

Epoch 2: Validation loss decreased (0.629210 --> 0.623858).  Saving model ...
	 Train_Loss: 0.6404 Train_Acc: 64.935 Val_Loss: 0.6239  BEST VAL Loss: 0.6239  Val_Acc: 65.660

Epoch 3: Validation loss decreased (0.623858 --> 0.620588).  Saving model ...
	 Train_Loss: 0.6333 Train_Acc: 65.662 Val_Loss: 0.6206  BEST VAL Loss: 0.6206  Val_Acc: 65.826

Epoch 4: Validation loss decreased (0.620588 --> 0.617556).  Saving model ...
	 Train_Loss: 0.6282 Train_Acc: 66.237 Val_Loss: 0.6176  BEST VAL Loss: 0.6176  Val_Acc: 66.605

Epoch 5: Validation loss decreased (0.617556 --> 0.614036).  Saving model ...
	 Train_Loss: 0.6237 Train_Acc: 66.713 Val_Loss: 0.6140  BEST VAL Loss: 0.6140  Val_Acc: 67.713

Epoch 6: Validation loss decreased (0.614036 --> 0.611146).  Saving model ...
	 Train_Loss: 0.6199 Train_Acc: 67.071 Val_Loss: 0.6111  BEST VAL Loss: 0.6111  Val_Acc: 67.682

Epoch 7: Validation loss decreased (0.611146 --> 0.609077).  Saving model ...
	 Train_Loss: 0.6167 Train_Acc: 67.145 Val_Loss: 0.6091  BEST VAL Loss: 0.6091  Val_Acc: 67.621

Epoch 8: Validation loss decreased (0.609077 --> 0.607003).  Saving model ...
	 Train_Loss: 0.6139 Train_Acc: 67.430 Val_Loss: 0.6070  BEST VAL Loss: 0.6070  Val_Acc: 68.002

Epoch 9: Validation loss decreased (0.607003 --> 0.604904).  Saving model ...
	 Train_Loss: 0.6114 Train_Acc: 67.607 Val_Loss: 0.6049  BEST VAL Loss: 0.6049  Val_Acc: 68.728

Epoch 10: Validation loss decreased (0.604904 --> 0.603039).  Saving model ...
	 Train_Loss: 0.6090 Train_Acc: 67.869 Val_Loss: 0.6030  BEST VAL Loss: 0.6030  Val_Acc: 68.400

Epoch 11: Validation loss decreased (0.603039 --> 0.601053).  Saving model ...
	 Train_Loss: 0.6068 Train_Acc: 68.021 Val_Loss: 0.6011  BEST VAL Loss: 0.6011  Val_Acc: 69.061

Epoch 12: Validation loss decreased (0.601053 --> 0.599154).  Saving model ...
	 Train_Loss: 0.6046 Train_Acc: 68.265 Val_Loss: 0.5992  BEST VAL Loss: 0.5992  Val_Acc: 69.341

Epoch 13: Validation loss decreased (0.599154 --> 0.597332).  Saving model ...
	 Train_Loss: 0.6025 Train_Acc: 68.476 Val_Loss: 0.5973  BEST VAL Loss: 0.5973  Val_Acc: 69.301

Epoch 14: Validation loss decreased (0.597332 --> 0.595491).  Saving model ...
	 Train_Loss: 0.6005 Train_Acc: 68.745 Val_Loss: 0.5955  BEST VAL Loss: 0.5955  Val_Acc: 69.660

Epoch 15: Validation loss decreased (0.595491 --> 0.593822).  Saving model ...
	 Train_Loss: 0.5985 Train_Acc: 68.844 Val_Loss: 0.5938  BEST VAL Loss: 0.5938  Val_Acc: 69.905

Epoch 16: Validation loss decreased (0.593822 --> 0.591872).  Saving model ...
	 Train_Loss: 0.5966 Train_Acc: 69.059 Val_Loss: 0.5919  BEST VAL Loss: 0.5919  Val_Acc: 70.291

Epoch 17: Validation loss decreased (0.591872 --> 0.590192).  Saving model ...
	 Train_Loss: 0.5947 Train_Acc: 69.292 Val_Loss: 0.5902  BEST VAL Loss: 0.5902  Val_Acc: 70.330

Epoch 18: Validation loss decreased (0.590192 --> 0.588380).  Saving model ...
	 Train_Loss: 0.5928 Train_Acc: 69.632 Val_Loss: 0.5884  BEST VAL Loss: 0.5884  Val_Acc: 70.693

Epoch 19: Validation loss decreased (0.588380 --> 0.586632).  Saving model ...
	 Train_Loss: 0.5911 Train_Acc: 69.562 Val_Loss: 0.5866  BEST VAL Loss: 0.5866  Val_Acc: 70.877

Epoch 20: Validation loss decreased (0.586632 --> 0.585062).  Saving model ...
	 Train_Loss: 0.5894 Train_Acc: 69.746 Val_Loss: 0.5851  BEST VAL Loss: 0.5851  Val_Acc: 70.912

Epoch 21: Validation loss decreased (0.585062 --> 0.583521).  Saving model ...
	 Train_Loss: 0.5877 Train_Acc: 69.893 Val_Loss: 0.5835  BEST VAL Loss: 0.5835  Val_Acc: 71.035

Epoch 22: Validation loss decreased (0.583521 --> 0.582014).  Saving model ...
	 Train_Loss: 0.5861 Train_Acc: 69.981 Val_Loss: 0.5820  BEST VAL Loss: 0.5820  Val_Acc: 71.113

Epoch 23: Validation loss decreased (0.582014 --> 0.580766).  Saving model ...
	 Train_Loss: 0.5846 Train_Acc: 70.107 Val_Loss: 0.5808  BEST VAL Loss: 0.5808  Val_Acc: 71.030

Epoch 24: Validation loss decreased (0.580766 --> 0.579382).  Saving model ...
	 Train_Loss: 0.5832 Train_Acc: 70.148 Val_Loss: 0.5794  BEST VAL Loss: 0.5794  Val_Acc: 71.267

Epoch 25: Validation loss decreased (0.579382 --> 0.578066).  Saving model ...
	 Train_Loss: 0.5819 Train_Acc: 70.247 Val_Loss: 0.5781  BEST VAL Loss: 0.5781  Val_Acc: 71.389

Epoch 26: Validation loss decreased (0.578066 --> 0.576857).  Saving model ...
	 Train_Loss: 0.5805 Train_Acc: 70.386 Val_Loss: 0.5769  BEST VAL Loss: 0.5769  Val_Acc: 71.591

Epoch 27: Validation loss decreased (0.576857 --> 0.575663).  Saving model ...
	 Train_Loss: 0.5793 Train_Acc: 70.454 Val_Loss: 0.5757  BEST VAL Loss: 0.5757  Val_Acc: 71.512

Epoch 28: Validation loss decreased (0.575663 --> 0.574544).  Saving model ...
	 Train_Loss: 0.5781 Train_Acc: 70.604 Val_Loss: 0.5745  BEST VAL Loss: 0.5745  Val_Acc: 71.459

Epoch 29: Validation loss decreased (0.574544 --> 0.573427).  Saving model ...
	 Train_Loss: 0.5769 Train_Acc: 70.493 Val_Loss: 0.5734  BEST VAL Loss: 0.5734  Val_Acc: 71.507

Epoch 30: Validation loss decreased (0.573427 --> 0.572551).  Saving model ...
	 Train_Loss: 0.5758 Train_Acc: 70.589 Val_Loss: 0.5726  BEST VAL Loss: 0.5726  Val_Acc: 71.481

Epoch 31: Validation loss decreased (0.572551 --> 0.571642).  Saving model ...
	 Train_Loss: 0.5747 Train_Acc: 70.599 Val_Loss: 0.5716  BEST VAL Loss: 0.5716  Val_Acc: 71.621

Epoch 32: Validation loss decreased (0.571642 --> 0.570632).  Saving model ...
	 Train_Loss: 0.5737 Train_Acc: 70.659 Val_Loss: 0.5706  BEST VAL Loss: 0.5706  Val_Acc: 72.317

Epoch 33: Validation loss decreased (0.570632 --> 0.569776).  Saving model ...
	 Train_Loss: 0.5727 Train_Acc: 70.778 Val_Loss: 0.5698  BEST VAL Loss: 0.5698  Val_Acc: 71.617

Epoch 34: Validation loss decreased (0.569776 --> 0.568849).  Saving model ...
	 Train_Loss: 0.5718 Train_Acc: 70.769 Val_Loss: 0.5688  BEST VAL Loss: 0.5688  Val_Acc: 72.173

Epoch 35: Validation loss decreased (0.568849 --> 0.568066).  Saving model ...
	 Train_Loss: 0.5708 Train_Acc: 70.821 Val_Loss: 0.5681  BEST VAL Loss: 0.5681  Val_Acc: 71.691

Epoch 36: Validation loss decreased (0.568066 --> 0.567237).  Saving model ...
	 Train_Loss: 0.5699 Train_Acc: 70.870 Val_Loss: 0.5672  BEST VAL Loss: 0.5672  Val_Acc: 72.186

Epoch 37: Validation loss decreased (0.567237 --> 0.566435).  Saving model ...
	 Train_Loss: 0.5691 Train_Acc: 70.829 Val_Loss: 0.5664  BEST VAL Loss: 0.5664  Val_Acc: 72.243

Epoch 38: Validation loss decreased (0.566435 --> 0.565708).  Saving model ...
	 Train_Loss: 0.5683 Train_Acc: 70.974 Val_Loss: 0.5657  BEST VAL Loss: 0.5657  Val_Acc: 72.300

Epoch 39: Validation loss decreased (0.565708 --> 0.565110).  Saving model ...
	 Train_Loss: 0.5675 Train_Acc: 70.801 Val_Loss: 0.5651  BEST VAL Loss: 0.5651  Val_Acc: 72.050

Epoch 40: Validation loss decreased (0.565110 --> 0.564464).  Saving model ...
	 Train_Loss: 0.5667 Train_Acc: 71.050 Val_Loss: 0.5645  BEST VAL Loss: 0.5645  Val_Acc: 72.212

Epoch 41: Validation loss decreased (0.564464 --> 0.563886).  Saving model ...
	 Train_Loss: 0.5660 Train_Acc: 70.990 Val_Loss: 0.5639  BEST VAL Loss: 0.5639  Val_Acc: 72.054

Epoch 42: Validation loss decreased (0.563886 --> 0.563325).  Saving model ...
	 Train_Loss: 0.5652 Train_Acc: 71.218 Val_Loss: 0.5633  BEST VAL Loss: 0.5633  Val_Acc: 71.949

Epoch 43: Validation loss decreased (0.563325 --> 0.562804).  Saving model ...
	 Train_Loss: 0.5646 Train_Acc: 70.984 Val_Loss: 0.5628  BEST VAL Loss: 0.5628  Val_Acc: 72.002

Epoch 44: Validation loss decreased (0.562804 --> 0.562324).  Saving model ...
	 Train_Loss: 0.5639 Train_Acc: 71.132 Val_Loss: 0.5623  BEST VAL Loss: 0.5623  Val_Acc: 72.142

Epoch 45: Validation loss decreased (0.562324 --> 0.561732).  Saving model ...
	 Train_Loss: 0.5632 Train_Acc: 71.165 Val_Loss: 0.5617  BEST VAL Loss: 0.5617  Val_Acc: 72.321

Epoch 46: Validation loss decreased (0.561732 --> 0.561236).  Saving model ...
	 Train_Loss: 0.5626 Train_Acc: 71.226 Val_Loss: 0.5612  BEST VAL Loss: 0.5612  Val_Acc: 72.216

Epoch 47: Validation loss decreased (0.561236 --> 0.560755).  Saving model ...
	 Train_Loss: 0.5619 Train_Acc: 71.157 Val_Loss: 0.5608  BEST VAL Loss: 0.5608  Val_Acc: 72.536

Epoch 48: Validation loss decreased (0.560755 --> 0.560213).  Saving model ...
	 Train_Loss: 0.5614 Train_Acc: 71.139 Val_Loss: 0.5602  BEST VAL Loss: 0.5602  Val_Acc: 72.418

Epoch 49: Validation loss decreased (0.560213 --> 0.559783).  Saving model ...
	 Train_Loss: 0.5608 Train_Acc: 71.289 Val_Loss: 0.5598  BEST VAL Loss: 0.5598  Val_Acc: 72.335

Epoch 50: Validation loss decreased (0.559783 --> 0.559430).  Saving model ...
	 Train_Loss: 0.5602 Train_Acc: 71.247 Val_Loss: 0.5594  BEST VAL Loss: 0.5594  Val_Acc: 72.216

Epoch 51: Validation loss decreased (0.559430 --> 0.559064).  Saving model ...
	 Train_Loss: 0.5596 Train_Acc: 71.236 Val_Loss: 0.5591  BEST VAL Loss: 0.5591  Val_Acc: 72.405

Epoch 52: Validation loss decreased (0.559064 --> 0.558683).  Saving model ...
	 Train_Loss: 0.5591 Train_Acc: 71.164 Val_Loss: 0.5587  BEST VAL Loss: 0.5587  Val_Acc: 72.597

Epoch 53: Validation loss decreased (0.558683 --> 0.558257).  Saving model ...
	 Train_Loss: 0.5586 Train_Acc: 71.435 Val_Loss: 0.5583  BEST VAL Loss: 0.5583  Val_Acc: 72.615

Epoch 54: Validation loss decreased (0.558257 --> 0.557907).  Saving model ...
	 Train_Loss: 0.5581 Train_Acc: 71.315 Val_Loss: 0.5579  BEST VAL Loss: 0.5579  Val_Acc: 72.400

Epoch 55: Validation loss decreased (0.557907 --> 0.557586).  Saving model ...
	 Train_Loss: 0.5576 Train_Acc: 71.276 Val_Loss: 0.5576  BEST VAL Loss: 0.5576  Val_Acc: 72.243

Epoch 56: Validation loss decreased (0.557586 --> 0.557254).  Saving model ...
	 Train_Loss: 0.5571 Train_Acc: 71.425 Val_Loss: 0.5573  BEST VAL Loss: 0.5573  Val_Acc: 72.173

Epoch 57: Validation loss decreased (0.557254 --> 0.556978).  Saving model ...
	 Train_Loss: 0.5566 Train_Acc: 71.497 Val_Loss: 0.5570  BEST VAL Loss: 0.5570  Val_Acc: 72.265

Epoch 58: Validation loss decreased (0.556978 --> 0.556607).  Saving model ...
	 Train_Loss: 0.5562 Train_Acc: 71.441 Val_Loss: 0.5566  BEST VAL Loss: 0.5566  Val_Acc: 72.413

Epoch 59: Validation loss decreased (0.556607 --> 0.556290).  Saving model ...
	 Train_Loss: 0.5557 Train_Acc: 71.353 Val_Loss: 0.5563  BEST VAL Loss: 0.5563  Val_Acc: 72.383

Epoch 60: Validation loss decreased (0.556290 --> 0.555947).  Saving model ...
	 Train_Loss: 0.5553 Train_Acc: 71.392 Val_Loss: 0.5559  BEST VAL Loss: 0.5559  Val_Acc: 72.098

Epoch 61: Validation loss decreased (0.555947 --> 0.555580).  Saving model ...
	 Train_Loss: 0.5549 Train_Acc: 71.446 Val_Loss: 0.5556  BEST VAL Loss: 0.5556  Val_Acc: 72.422

Epoch 62: Validation loss decreased (0.555580 --> 0.555282).  Saving model ...
	 Train_Loss: 0.5545 Train_Acc: 71.422 Val_Loss: 0.5553  BEST VAL Loss: 0.5553  Val_Acc: 72.374

Epoch 63: Validation loss decreased (0.555282 --> 0.554999).  Saving model ...
	 Train_Loss: 0.5540 Train_Acc: 71.599 Val_Loss: 0.5550  BEST VAL Loss: 0.5550  Val_Acc: 72.313

Epoch 64: Validation loss decreased (0.554999 --> 0.554693).  Saving model ...
	 Train_Loss: 0.5536 Train_Acc: 71.544 Val_Loss: 0.5547  BEST VAL Loss: 0.5547  Val_Acc: 72.610

Epoch 65: Validation loss decreased (0.554693 --> 0.554441).  Saving model ...
	 Train_Loss: 0.5532 Train_Acc: 71.542 Val_Loss: 0.5544  BEST VAL Loss: 0.5544  Val_Acc: 72.081

Epoch 66: Validation loss decreased (0.554441 --> 0.554120).  Saving model ...
	 Train_Loss: 0.5528 Train_Acc: 71.538 Val_Loss: 0.5541  BEST VAL Loss: 0.5541  Val_Acc: 72.829

Epoch 67: Validation loss decreased (0.554120 --> 0.553826).  Saving model ...
	 Train_Loss: 0.5524 Train_Acc: 71.592 Val_Loss: 0.5538  BEST VAL Loss: 0.5538  Val_Acc: 72.619

Epoch 68: Validation loss decreased (0.553826 --> 0.553577).  Saving model ...
	 Train_Loss: 0.5521 Train_Acc: 71.684 Val_Loss: 0.5536  BEST VAL Loss: 0.5536  Val_Acc: 72.755

Epoch 69: Validation loss decreased (0.553577 --> 0.553320).  Saving model ...
	 Train_Loss: 0.5517 Train_Acc: 71.560 Val_Loss: 0.5533  BEST VAL Loss: 0.5533  Val_Acc: 72.400

Epoch 70: Validation loss decreased (0.553320 --> 0.553076).  Saving model ...
	 Train_Loss: 0.5513 Train_Acc: 71.520 Val_Loss: 0.5531  BEST VAL Loss: 0.5531  Val_Acc: 72.243

Epoch 71: Validation loss decreased (0.553076 --> 0.552864).  Saving model ...
	 Train_Loss: 0.5510 Train_Acc: 71.611 Val_Loss: 0.5529  BEST VAL Loss: 0.5529  Val_Acc: 72.466

Epoch 72: Validation loss decreased (0.552864 --> 0.552637).  Saving model ...
	 Train_Loss: 0.5507 Train_Acc: 71.684 Val_Loss: 0.5526  BEST VAL Loss: 0.5526  Val_Acc: 72.492

Epoch 73: Validation loss decreased (0.552637 --> 0.552375).  Saving model ...
	 Train_Loss: 0.5503 Train_Acc: 71.685 Val_Loss: 0.5524  BEST VAL Loss: 0.5524  Val_Acc: 72.698

Epoch 74: Validation loss decreased (0.552375 --> 0.552178).  Saving model ...
	 Train_Loss: 0.5500 Train_Acc: 71.649 Val_Loss: 0.5522  BEST VAL Loss: 0.5522  Val_Acc: 72.597

Epoch 75: Validation loss decreased (0.552178 --> 0.551984).  Saving model ...
	 Train_Loss: 0.5497 Train_Acc: 71.723 Val_Loss: 0.5520  BEST VAL Loss: 0.5520  Val_Acc: 72.418

Epoch 76: Validation loss decreased (0.551984 --> 0.551762).  Saving model ...
	 Train_Loss: 0.5493 Train_Acc: 71.705 Val_Loss: 0.5518  BEST VAL Loss: 0.5518  Val_Acc: 72.777

Epoch 77: Validation loss decreased (0.551762 --> 0.551567).  Saving model ...
	 Train_Loss: 0.5490 Train_Acc: 71.769 Val_Loss: 0.5516  BEST VAL Loss: 0.5516  Val_Acc: 72.711

Epoch 78: Validation loss decreased (0.551567 --> 0.551383).  Saving model ...
	 Train_Loss: 0.5487 Train_Acc: 71.724 Val_Loss: 0.5514  BEST VAL Loss: 0.5514  Val_Acc: 72.387

Epoch 79: Validation loss decreased (0.551383 --> 0.551178).  Saving model ...
	 Train_Loss: 0.5484 Train_Acc: 71.723 Val_Loss: 0.5512  BEST VAL Loss: 0.5512  Val_Acc: 72.466

Epoch 80: Validation loss decreased (0.551178 --> 0.550967).  Saving model ...
	 Train_Loss: 0.5481 Train_Acc: 71.771 Val_Loss: 0.5510  BEST VAL Loss: 0.5510  Val_Acc: 72.807

Epoch 81: Validation loss decreased (0.550967 --> 0.550793).  Saving model ...
	 Train_Loss: 0.5478 Train_Acc: 71.707 Val_Loss: 0.5508  BEST VAL Loss: 0.5508  Val_Acc: 72.672

Epoch 82: Validation loss decreased (0.550793 --> 0.550550).  Saving model ...
	 Train_Loss: 0.5475 Train_Acc: 71.827 Val_Loss: 0.5505  BEST VAL Loss: 0.5505  Val_Acc: 72.720

Epoch 83: Validation loss decreased (0.550550 --> 0.550365).  Saving model ...
	 Train_Loss: 0.5472 Train_Acc: 71.840 Val_Loss: 0.5504  BEST VAL Loss: 0.5504  Val_Acc: 72.571

Epoch 84: Validation loss decreased (0.550365 --> 0.550184).  Saving model ...
	 Train_Loss: 0.5469 Train_Acc: 71.955 Val_Loss: 0.5502  BEST VAL Loss: 0.5502  Val_Acc: 72.702

Epoch 85: Validation loss decreased (0.550184 --> 0.549999).  Saving model ...
	 Train_Loss: 0.5467 Train_Acc: 71.871 Val_Loss: 0.5500  BEST VAL Loss: 0.5500  Val_Acc: 72.658

Epoch 86: Validation loss decreased (0.549999 --> 0.549900).  Saving model ...
	 Train_Loss: 0.5464 Train_Acc: 71.773 Val_Loss: 0.5499  BEST VAL Loss: 0.5499  Val_Acc: 72.746

Epoch 87: Validation loss decreased (0.549900 --> 0.549790).  Saving model ...
	 Train_Loss: 0.5461 Train_Acc: 71.876 Val_Loss: 0.5498  BEST VAL Loss: 0.5498  Val_Acc: 72.352

Epoch 88: Validation loss decreased (0.549790 --> 0.549635).  Saving model ...
	 Train_Loss: 0.5459 Train_Acc: 71.838 Val_Loss: 0.5496  BEST VAL Loss: 0.5496  Val_Acc: 72.768

Epoch 89: Validation loss decreased (0.549635 --> 0.549496).  Saving model ...
	 Train_Loss: 0.5456 Train_Acc: 71.857 Val_Loss: 0.5495  BEST VAL Loss: 0.5495  Val_Acc: 73.026

Epoch 90: Validation loss decreased (0.549496 --> 0.549384).  Saving model ...
	 Train_Loss: 0.5454 Train_Acc: 71.809 Val_Loss: 0.5494  BEST VAL Loss: 0.5494  Val_Acc: 72.737

Epoch 91: Validation loss decreased (0.549384 --> 0.549236).  Saving model ...
	 Train_Loss: 0.5451 Train_Acc: 71.840 Val_Loss: 0.5492  BEST VAL Loss: 0.5492  Val_Acc: 72.702

Epoch 92: Validation loss decreased (0.549236 --> 0.549049).  Saving model ...
	 Train_Loss: 0.5449 Train_Acc: 71.878 Val_Loss: 0.5490  BEST VAL Loss: 0.5490  Val_Acc: 72.921

Epoch 93: Validation loss decreased (0.549049 --> 0.548969).  Saving model ...
	 Train_Loss: 0.5447 Train_Acc: 71.872 Val_Loss: 0.5490  BEST VAL Loss: 0.5490  Val_Acc: 72.256

Epoch 94: Validation loss decreased (0.548969 --> 0.548833).  Saving model ...
	 Train_Loss: 0.5444 Train_Acc: 71.889 Val_Loss: 0.5488  BEST VAL Loss: 0.5488  Val_Acc: 72.877

Epoch 95: Validation loss decreased (0.548833 --> 0.548682).  Saving model ...
	 Train_Loss: 0.5442 Train_Acc: 71.881 Val_Loss: 0.5487  BEST VAL Loss: 0.5487  Val_Acc: 72.834

Epoch 96: Validation loss decreased (0.548682 --> 0.548511).  Saving model ...
	 Train_Loss: 0.5440 Train_Acc: 71.963 Val_Loss: 0.5485  BEST VAL Loss: 0.5485  Val_Acc: 72.807

Epoch 97: Validation loss decreased (0.548511 --> 0.548404).  Saving model ...
	 Train_Loss: 0.5437 Train_Acc: 71.928 Val_Loss: 0.5484  BEST VAL Loss: 0.5484  Val_Acc: 72.632

Epoch 98: Validation loss decreased (0.548404 --> 0.548297).  Saving model ...
	 Train_Loss: 0.5435 Train_Acc: 71.877 Val_Loss: 0.5483  BEST VAL Loss: 0.5483  Val_Acc: 72.553

Epoch 99: Validation loss decreased (0.548297 --> 0.548200).  Saving model ...
	 Train_Loss: 0.5433 Train_Acc: 71.888 Val_Loss: 0.5482  BEST VAL Loss: 0.5482  Val_Acc: 72.728

LPS_0.010_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.79      0.65      0.71     85026
           1       0.73      0.85      0.79     97753

    accuracy                           0.76    182779
   macro avg       0.76      0.75      0.75    182779
weighted avg       0.76      0.76      0.75    182779

LPS_0.010_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.76      0.61      0.67     10629
           1       0.71      0.83      0.77     12219

    accuracy                           0.73     22848
   macro avg       0.73      0.72      0.72     22848
weighted avg       0.73      0.73      0.72     22848

LPS_0.010_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.78      0.63      0.69     10628
           1       0.72      0.84      0.78     12220

    accuracy                           0.74     22848
   macro avg       0.75      0.73      0.74     22848
weighted avg       0.75      0.74      0.74     22848

              precision    recall  f1-score   support

           0       0.78      0.63      0.69     10628
           1       0.72      0.84      0.78     12220

    accuracy                           0.74     22848
   macro avg       0.75      0.73      0.74     22848
weighted avg       0.75      0.74      0.74     22848

LPS_0.010_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_0.010_DMSO_0.025_vs_LPS_100.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.53      0.42      0.47     36797
           1       0.53      0.64      0.58     37243

    accuracy                           0.53     74040
   macro avg       0.53      0.53      0.52     74040
weighted avg       0.53      0.53      0.52     74040

              precision    recall  f1-score   support

           0       0.53      0.42      0.47     36797
           1       0.53      0.64      0.58     37243

    accuracy                           0.53     74040
   macro avg       0.53      0.53      0.52     74040
weighted avg       0.53      0.53      0.52     74040

completed
