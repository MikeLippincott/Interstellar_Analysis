[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '34b73312'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'd967d043'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '080b4a7d'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '0585efe8'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: Flagellin_0.100_DMSO_0.025 treatment_name: H2O2_100.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: Flagellin_0.100_DMSO_0.025
TREATMENT_NAME: H2O2_100.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['H2O2_100.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (336451, 1270)
Number of total missing values across all columns: 672902
Data Subset Is Off
Wells held out for testing: ['I05' 'L10']
Wells to use for training, validation, and testing ['H04' 'I04' 'H05' 'H10' 'I10' 'H11' 'I11' 'L05' 'L11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.389005).  Saving model ...
	 Train_Loss: 0.4617 Train_Acc: 78.697 Val_Loss: 0.3890  BEST VAL Loss: 0.3890  Val_Acc: 81.564

Epoch 1: Validation loss decreased (0.389005 --> 0.376045).  Saving model ...
	 Train_Loss: 0.4228 Train_Acc: 82.285 Val_Loss: 0.3760  BEST VAL Loss: 0.3760  Val_Acc: 83.068

Epoch 2: Validation loss decreased (0.376045 --> 0.361635).  Saving model ...
	 Train_Loss: 0.4029 Train_Acc: 83.303 Val_Loss: 0.3616  BEST VAL Loss: 0.3616  Val_Acc: 85.132

Epoch 3: Validation loss decreased (0.361635 --> 0.353148).  Saving model ...
	 Train_Loss: 0.3910 Train_Acc: 83.623 Val_Loss: 0.3531  BEST VAL Loss: 0.3531  Val_Acc: 85.247

Epoch 4: Validation loss decreased (0.353148 --> 0.347834).  Saving model ...
	 Train_Loss: 0.3818 Train_Acc: 84.238 Val_Loss: 0.3478  BEST VAL Loss: 0.3478  Val_Acc: 85.232

Epoch 5: Validation loss decreased (0.347834 --> 0.343654).  Saving model ...
	 Train_Loss: 0.3749 Train_Acc: 84.452 Val_Loss: 0.3437  BEST VAL Loss: 0.3437  Val_Acc: 85.454

Epoch 6: Validation loss decreased (0.343654 --> 0.339553).  Saving model ...
	 Train_Loss: 0.3694 Train_Acc: 84.639 Val_Loss: 0.3396  BEST VAL Loss: 0.3396  Val_Acc: 85.977

Epoch 7: Validation loss decreased (0.339553 --> 0.336732).  Saving model ...
	 Train_Loss: 0.3648 Train_Acc: 84.747 Val_Loss: 0.3367  BEST VAL Loss: 0.3367  Val_Acc: 85.888

Epoch 8: Validation loss decreased (0.336732 --> 0.334417).  Saving model ...
	 Train_Loss: 0.3608 Train_Acc: 84.963 Val_Loss: 0.3344  BEST VAL Loss: 0.3344  Val_Acc: 85.817

Epoch 9: Validation loss decreased (0.334417 --> 0.332281).  Saving model ...
	 Train_Loss: 0.3574 Train_Acc: 85.104 Val_Loss: 0.3323  BEST VAL Loss: 0.3323  Val_Acc: 85.580

Epoch 10: Validation loss decreased (0.332281 --> 0.330648).  Saving model ...
	 Train_Loss: 0.3545 Train_Acc: 85.195 Val_Loss: 0.3306  BEST VAL Loss: 0.3306  Val_Acc: 85.884

Epoch 11: Validation loss decreased (0.330648 --> 0.328957).  Saving model ...
	 Train_Loss: 0.3520 Train_Acc: 85.115 Val_Loss: 0.3290  BEST VAL Loss: 0.3290  Val_Acc: 85.880

Epoch 12: Validation loss decreased (0.328957 --> 0.327313).  Saving model ...
	 Train_Loss: 0.3496 Train_Acc: 85.343 Val_Loss: 0.3273  BEST VAL Loss: 0.3273  Val_Acc: 86.307

Epoch 13: Validation loss decreased (0.327313 --> 0.326322).  Saving model ...
	 Train_Loss: 0.3475 Train_Acc: 85.359 Val_Loss: 0.3263  BEST VAL Loss: 0.3263  Val_Acc: 85.747

Epoch 14: Validation loss decreased (0.326322 --> 0.324619).  Saving model ...
	 Train_Loss: 0.3455 Train_Acc: 85.538 Val_Loss: 0.3246  BEST VAL Loss: 0.3246  Val_Acc: 86.670

Epoch 15: Validation loss decreased (0.324619 --> 0.323342).  Saving model ...
	 Train_Loss: 0.3438 Train_Acc: 85.418 Val_Loss: 0.3233  BEST VAL Loss: 0.3233  Val_Acc: 86.592

Epoch 16: Validation loss decreased (0.323342 --> 0.322252).  Saving model ...
	 Train_Loss: 0.3422 Train_Acc: 85.578 Val_Loss: 0.3223  BEST VAL Loss: 0.3223  Val_Acc: 86.444

Epoch 17: Validation loss decreased (0.322252 --> 0.320984).  Saving model ...
	 Train_Loss: 0.3407 Train_Acc: 85.582 Val_Loss: 0.3210  BEST VAL Loss: 0.3210  Val_Acc: 86.747

Epoch 18: Validation loss decreased (0.320984 --> 0.319760).  Saving model ...
	 Train_Loss: 0.3393 Train_Acc: 85.724 Val_Loss: 0.3198  BEST VAL Loss: 0.3198  Val_Acc: 86.888

Epoch 19: Validation loss decreased (0.319760 --> 0.318877).  Saving model ...
	 Train_Loss: 0.3380 Train_Acc: 85.667 Val_Loss: 0.3189  BEST VAL Loss: 0.3189  Val_Acc: 86.284

Epoch 20: Validation loss decreased (0.318877 --> 0.317917).  Saving model ...
	 Train_Loss: 0.3368 Train_Acc: 85.703 Val_Loss: 0.3179  BEST VAL Loss: 0.3179  Val_Acc: 86.770

Epoch 21: Validation loss decreased (0.317917 --> 0.317224).  Saving model ...
	 Train_Loss: 0.3356 Train_Acc: 85.835 Val_Loss: 0.3172  BEST VAL Loss: 0.3172  Val_Acc: 86.647

Epoch 22: Validation loss decreased (0.317224 --> 0.316282).  Saving model ...
	 Train_Loss: 0.3346 Train_Acc: 85.798 Val_Loss: 0.3163  BEST VAL Loss: 0.3163  Val_Acc: 86.914

Epoch 23: Validation loss decreased (0.316282 --> 0.315430).  Saving model ...
	 Train_Loss: 0.3335 Train_Acc: 85.913 Val_Loss: 0.3154  BEST VAL Loss: 0.3154  Val_Acc: 86.773

Epoch 24: Validation loss decreased (0.315430 --> 0.314757).  Saving model ...
	 Train_Loss: 0.3326 Train_Acc: 85.848 Val_Loss: 0.3148  BEST VAL Loss: 0.3148  Val_Acc: 86.740

Epoch 25: Validation loss decreased (0.314757 --> 0.314150).  Saving model ...
	 Train_Loss: 0.3316 Train_Acc: 85.907 Val_Loss: 0.3142  BEST VAL Loss: 0.3142  Val_Acc: 86.885

Epoch 26: Validation loss decreased (0.314150 --> 0.313396).  Saving model ...
	 Train_Loss: 0.3308 Train_Acc: 85.892 Val_Loss: 0.3134  BEST VAL Loss: 0.3134  Val_Acc: 87.136

Epoch 27: Validation loss decreased (0.313396 --> 0.312986).  Saving model ...
	 Train_Loss: 0.3299 Train_Acc: 86.031 Val_Loss: 0.3130  BEST VAL Loss: 0.3130  Val_Acc: 86.451

Epoch 28: Validation loss decreased (0.312986 --> 0.312432).  Saving model ...
	 Train_Loss: 0.3291 Train_Acc: 85.994 Val_Loss: 0.3124  BEST VAL Loss: 0.3124  Val_Acc: 86.707

Epoch 29: Validation loss decreased (0.312432 --> 0.311821).  Saving model ...
	 Train_Loss: 0.3284 Train_Acc: 85.991 Val_Loss: 0.3118  BEST VAL Loss: 0.3118  Val_Acc: 86.759

Epoch 30: Validation loss decreased (0.311821 --> 0.311463).  Saving model ...
	 Train_Loss: 0.3276 Train_Acc: 86.033 Val_Loss: 0.3115  BEST VAL Loss: 0.3115  Val_Acc: 86.614

Epoch 31: Validation loss decreased (0.311463 --> 0.311025).  Saving model ...
	 Train_Loss: 0.3269 Train_Acc: 86.070 Val_Loss: 0.3110  BEST VAL Loss: 0.3110  Val_Acc: 86.684

Epoch 32: Validation loss decreased (0.311025 --> 0.310520).  Saving model ...
	 Train_Loss: 0.3262 Train_Acc: 86.102 Val_Loss: 0.3105  BEST VAL Loss: 0.3105  Val_Acc: 86.807

Epoch 33: Validation loss decreased (0.310520 --> 0.310085).  Saving model ...
	 Train_Loss: 0.3256 Train_Acc: 86.029 Val_Loss: 0.3101  BEST VAL Loss: 0.3101  Val_Acc: 86.851

Epoch 34: Validation loss decreased (0.310085 --> 0.309571).  Saving model ...
	 Train_Loss: 0.3250 Train_Acc: 86.083 Val_Loss: 0.3096  BEST VAL Loss: 0.3096  Val_Acc: 87.059

Epoch 35: Validation loss decreased (0.309571 --> 0.309256).  Saving model ...
	 Train_Loss: 0.3244 Train_Acc: 86.126 Val_Loss: 0.3093  BEST VAL Loss: 0.3093  Val_Acc: 86.610

Epoch 36: Validation loss decreased (0.309256 --> 0.308855).  Saving model ...
	 Train_Loss: 0.3238 Train_Acc: 86.087 Val_Loss: 0.3089  BEST VAL Loss: 0.3089  Val_Acc: 86.777

Epoch 37: Validation loss decreased (0.308855 --> 0.308398).  Saving model ...
	 Train_Loss: 0.3233 Train_Acc: 86.141 Val_Loss: 0.3084  BEST VAL Loss: 0.3084  Val_Acc: 87.088

Epoch 38: Validation loss decreased (0.308398 --> 0.308081).  Saving model ...
	 Train_Loss: 0.3227 Train_Acc: 86.206 Val_Loss: 0.3081  BEST VAL Loss: 0.3081  Val_Acc: 86.840

Epoch 39: Validation loss decreased (0.308081 --> 0.307602).  Saving model ...
	 Train_Loss: 0.3222 Train_Acc: 86.213 Val_Loss: 0.3076  BEST VAL Loss: 0.3076  Val_Acc: 87.040

Epoch 40: Validation loss decreased (0.307602 --> 0.307312).  Saving model ...
	 Train_Loss: 0.3217 Train_Acc: 86.248 Val_Loss: 0.3073  BEST VAL Loss: 0.3073  Val_Acc: 86.770

Epoch 41: Validation loss decreased (0.307312 --> 0.306980).  Saving model ...
	 Train_Loss: 0.3212 Train_Acc: 86.288 Val_Loss: 0.3070  BEST VAL Loss: 0.3070  Val_Acc: 86.981

Epoch 42: Validation loss decreased (0.306980 --> 0.306642).  Saving model ...
	 Train_Loss: 0.3207 Train_Acc: 86.282 Val_Loss: 0.3066  BEST VAL Loss: 0.3066  Val_Acc: 87.066

Epoch 43: Validation loss decreased (0.306642 --> 0.306328).  Saving model ...
	 Train_Loss: 0.3202 Train_Acc: 86.265 Val_Loss: 0.3063  BEST VAL Loss: 0.3063  Val_Acc: 86.885

Epoch 44: Validation loss decreased (0.306328 --> 0.306153).  Saving model ...
	 Train_Loss: 0.3198 Train_Acc: 86.311 Val_Loss: 0.3062  BEST VAL Loss: 0.3062  Val_Acc: 86.770

Epoch 45: Validation loss decreased (0.306153 --> 0.305958).  Saving model ...
	 Train_Loss: 0.3194 Train_Acc: 86.308 Val_Loss: 0.3060  BEST VAL Loss: 0.3060  Val_Acc: 86.981

Epoch 46: Validation loss decreased (0.305958 --> 0.305781).  Saving model ...
	 Train_Loss: 0.3189 Train_Acc: 86.296 Val_Loss: 0.3058  BEST VAL Loss: 0.3058  Val_Acc: 86.977

Epoch 47: Validation loss decreased (0.305781 --> 0.305512).  Saving model ...
	 Train_Loss: 0.3185 Train_Acc: 86.297 Val_Loss: 0.3055  BEST VAL Loss: 0.3055  Val_Acc: 87.048

Epoch 48: Validation loss decreased (0.305512 --> 0.305432).  Saving model ...
	 Train_Loss: 0.3181 Train_Acc: 86.379 Val_Loss: 0.3054  BEST VAL Loss: 0.3054  Val_Acc: 86.747

Epoch 49: Validation loss decreased (0.305432 --> 0.305084).  Saving model ...
	 Train_Loss: 0.3177 Train_Acc: 86.351 Val_Loss: 0.3051  BEST VAL Loss: 0.3051  Val_Acc: 87.244

Epoch 50: Validation loss decreased (0.305084 --> 0.304756).  Saving model ...
	 Train_Loss: 0.3173 Train_Acc: 86.294 Val_Loss: 0.3048  BEST VAL Loss: 0.3048  Val_Acc: 87.125

Epoch 51: Validation loss decreased (0.304756 --> 0.304495).  Saving model ...
	 Train_Loss: 0.3169 Train_Acc: 86.319 Val_Loss: 0.3045  BEST VAL Loss: 0.3045  Val_Acc: 87.455

Epoch 52: Validation loss decreased (0.304495 --> 0.304203).  Saving model ...
	 Train_Loss: 0.3166 Train_Acc: 86.354 Val_Loss: 0.3042  BEST VAL Loss: 0.3042  Val_Acc: 87.136

Epoch 53: Validation loss decreased (0.304203 --> 0.303990).  Saving model ...
	 Train_Loss: 0.3162 Train_Acc: 86.346 Val_Loss: 0.3040  BEST VAL Loss: 0.3040  Val_Acc: 86.914

Epoch 54: Validation loss decreased (0.303990 --> 0.303730).  Saving model ...
	 Train_Loss: 0.3159 Train_Acc: 86.430 Val_Loss: 0.3037  BEST VAL Loss: 0.3037  Val_Acc: 87.244

Epoch 55: Validation loss decreased (0.303730 --> 0.303539).  Saving model ...
	 Train_Loss: 0.3155 Train_Acc: 86.507 Val_Loss: 0.3035  BEST VAL Loss: 0.3035  Val_Acc: 87.140

Epoch 56: Validation loss decreased (0.303539 --> 0.303353).  Saving model ...
	 Train_Loss: 0.3152 Train_Acc: 86.485 Val_Loss: 0.3034  BEST VAL Loss: 0.3034  Val_Acc: 87.240

Epoch 57: Validation loss decreased (0.303353 --> 0.303084).  Saving model ...
	 Train_Loss: 0.3148 Train_Acc: 86.384 Val_Loss: 0.3031  BEST VAL Loss: 0.3031  Val_Acc: 87.155

Epoch 58: Validation loss decreased (0.303084 --> 0.302879).  Saving model ...
	 Train_Loss: 0.3145 Train_Acc: 86.413 Val_Loss: 0.3029  BEST VAL Loss: 0.3029  Val_Acc: 86.973

Epoch 59: Validation loss decreased (0.302879 --> 0.302702).  Saving model ...
	 Train_Loss: 0.3142 Train_Acc: 86.458 Val_Loss: 0.3027  BEST VAL Loss: 0.3027  Val_Acc: 86.925

Epoch 60: Validation loss decreased (0.302702 --> 0.302619).  Saving model ...
	 Train_Loss: 0.3139 Train_Acc: 86.464 Val_Loss: 0.3026  BEST VAL Loss: 0.3026  Val_Acc: 86.799

Epoch 61: Validation loss decreased (0.302619 --> 0.302355).  Saving model ...
	 Train_Loss: 0.3136 Train_Acc: 86.461 Val_Loss: 0.3024  BEST VAL Loss: 0.3024  Val_Acc: 87.207

Epoch 62: Validation loss decreased (0.302355 --> 0.302150).  Saving model ...
	 Train_Loss: 0.3133 Train_Acc: 86.479 Val_Loss: 0.3022  BEST VAL Loss: 0.3022  Val_Acc: 87.214

Epoch 63: Validation loss decreased (0.302150 --> 0.302092).  Saving model ...
	 Train_Loss: 0.3130 Train_Acc: 86.529 Val_Loss: 0.3021  BEST VAL Loss: 0.3021  Val_Acc: 86.925

Epoch 64: Validation loss decreased (0.302092 --> 0.301848).  Saving model ...
	 Train_Loss: 0.3128 Train_Acc: 86.419 Val_Loss: 0.3018  BEST VAL Loss: 0.3018  Val_Acc: 87.322

Epoch 65: Validation loss decreased (0.301848 --> 0.301666).  Saving model ...
	 Train_Loss: 0.3125 Train_Acc: 86.563 Val_Loss: 0.3017  BEST VAL Loss: 0.3017  Val_Acc: 87.307

Epoch 66: Validation loss decreased (0.301666 --> 0.301421).  Saving model ...
	 Train_Loss: 0.3122 Train_Acc: 86.463 Val_Loss: 0.3014  BEST VAL Loss: 0.3014  Val_Acc: 87.522

Epoch 67: Validation loss decreased (0.301421 --> 0.301179).  Saving model ...
	 Train_Loss: 0.3119 Train_Acc: 86.536 Val_Loss: 0.3012  BEST VAL Loss: 0.3012  Val_Acc: 87.259

Epoch 68: Validation loss decreased (0.301179 --> 0.301029).  Saving model ...
	 Train_Loss: 0.3117 Train_Acc: 86.585 Val_Loss: 0.3010  BEST VAL Loss: 0.3010  Val_Acc: 87.192

Epoch 69: Validation loss decreased (0.301029 --> 0.300867).  Saving model ...
	 Train_Loss: 0.3114 Train_Acc: 86.534 Val_Loss: 0.3009  BEST VAL Loss: 0.3009  Val_Acc: 87.322

Epoch 70: Validation loss decreased (0.300867 --> 0.300802).  Saving model ...
	 Train_Loss: 0.3112 Train_Acc: 86.510 Val_Loss: 0.3008  BEST VAL Loss: 0.3008  Val_Acc: 87.033

Epoch 71: Validation loss decreased (0.300802 --> 0.300591).  Saving model ...
	 Train_Loss: 0.3109 Train_Acc: 86.597 Val_Loss: 0.3006  BEST VAL Loss: 0.3006  Val_Acc: 87.414

Epoch 72: Validation loss decreased (0.300591 --> 0.300401).  Saving model ...
	 Train_Loss: 0.3107 Train_Acc: 86.485 Val_Loss: 0.3004  BEST VAL Loss: 0.3004  Val_Acc: 87.311

Epoch 73: Validation loss decreased (0.300401 --> 0.300179).  Saving model ...
	 Train_Loss: 0.3105 Train_Acc: 86.610 Val_Loss: 0.3002  BEST VAL Loss: 0.3002  Val_Acc: 87.455

Epoch 74: Validation loss decreased (0.300179 --> 0.300046).  Saving model ...
	 Train_Loss: 0.3102 Train_Acc: 86.623 Val_Loss: 0.3000  BEST VAL Loss: 0.3000  Val_Acc: 87.177

Epoch 75: Validation loss decreased (0.300046 --> 0.299872).  Saving model ...
	 Train_Loss: 0.3100 Train_Acc: 86.626 Val_Loss: 0.2999  BEST VAL Loss: 0.2999  Val_Acc: 87.366

Epoch 76: Validation loss decreased (0.299872 --> 0.299688).  Saving model ...
	 Train_Loss: 0.3098 Train_Acc: 86.610 Val_Loss: 0.2997  BEST VAL Loss: 0.2997  Val_Acc: 87.400

Epoch 77: Validation loss decreased (0.299688 --> 0.299515).  Saving model ...
	 Train_Loss: 0.3095 Train_Acc: 86.613 Val_Loss: 0.2995  BEST VAL Loss: 0.2995  Val_Acc: 87.344

Epoch 78: Validation loss decreased (0.299515 --> 0.299410).  Saving model ...
	 Train_Loss: 0.3093 Train_Acc: 86.604 Val_Loss: 0.2994  BEST VAL Loss: 0.2994  Val_Acc: 87.177

Epoch 79: Validation loss decreased (0.299410 --> 0.299325).  Saving model ...
	 Train_Loss: 0.3091 Train_Acc: 86.570 Val_Loss: 0.2993  BEST VAL Loss: 0.2993  Val_Acc: 86.718

Epoch 80: Validation loss decreased (0.299325 --> 0.299168).  Saving model ...
	 Train_Loss: 0.3089 Train_Acc: 86.710 Val_Loss: 0.2992  BEST VAL Loss: 0.2992  Val_Acc: 87.459

Epoch 81: Validation loss decreased (0.299168 --> 0.299019).  Saving model ...
	 Train_Loss: 0.3087 Train_Acc: 86.674 Val_Loss: 0.2990  BEST VAL Loss: 0.2990  Val_Acc: 87.422

Epoch 82: Validation loss decreased (0.299019 --> 0.298869).  Saving model ...
	 Train_Loss: 0.3085 Train_Acc: 86.611 Val_Loss: 0.2989  BEST VAL Loss: 0.2989  Val_Acc: 87.144

Epoch 83: Validation loss decreased (0.298869 --> 0.298779).  Saving model ...
	 Train_Loss: 0.3082 Train_Acc: 86.646 Val_Loss: 0.2988  BEST VAL Loss: 0.2988  Val_Acc: 87.148

Epoch 84: Validation loss decreased (0.298779 --> 0.298618).  Saving model ...
	 Train_Loss: 0.3081 Train_Acc: 86.647 Val_Loss: 0.2986  BEST VAL Loss: 0.2986  Val_Acc: 87.274

Epoch 85: Validation loss decreased (0.298618 --> 0.298456).  Saving model ...
	 Train_Loss: 0.3079 Train_Acc: 86.613 Val_Loss: 0.2985  BEST VAL Loss: 0.2985  Val_Acc: 87.340

Epoch 86: Validation loss decreased (0.298456 --> 0.298322).  Saving model ...
	 Train_Loss: 0.3077 Train_Acc: 86.634 Val_Loss: 0.2983  BEST VAL Loss: 0.2983  Val_Acc: 87.403

Epoch 87: Validation loss decreased (0.298322 --> 0.298232).  Saving model ...
	 Train_Loss: 0.3075 Train_Acc: 86.743 Val_Loss: 0.2982  BEST VAL Loss: 0.2982  Val_Acc: 87.133

Epoch 88: Validation loss decreased (0.298232 --> 0.298120).  Saving model ...
	 Train_Loss: 0.3073 Train_Acc: 86.642 Val_Loss: 0.2981  BEST VAL Loss: 0.2981  Val_Acc: 87.214

Epoch 89: Validation loss decreased (0.298120 --> 0.297949).  Saving model ...
	 Train_Loss: 0.3071 Train_Acc: 86.699 Val_Loss: 0.2979  BEST VAL Loss: 0.2979  Val_Acc: 87.551

Epoch 90: Validation loss decreased (0.297949 --> 0.297802).  Saving model ...
	 Train_Loss: 0.3069 Train_Acc: 86.757 Val_Loss: 0.2978  BEST VAL Loss: 0.2978  Val_Acc: 87.385

Epoch 91: Validation loss decreased (0.297802 --> 0.297688).  Saving model ...
	 Train_Loss: 0.3067 Train_Acc: 86.688 Val_Loss: 0.2977  BEST VAL Loss: 0.2977  Val_Acc: 87.066

Epoch 92: Validation loss decreased (0.297688 --> 0.297590).  Saving model ...
	 Train_Loss: 0.3065 Train_Acc: 86.745 Val_Loss: 0.2976  BEST VAL Loss: 0.2976  Val_Acc: 87.203

Epoch 93: Validation loss decreased (0.297590 --> 0.297463).  Saving model ...
	 Train_Loss: 0.3064 Train_Acc: 86.691 Val_Loss: 0.2975  BEST VAL Loss: 0.2975  Val_Acc: 87.400

Epoch 94: Validation loss decreased (0.297463 --> 0.297357).  Saving model ...
	 Train_Loss: 0.3062 Train_Acc: 86.783 Val_Loss: 0.2974  BEST VAL Loss: 0.2974  Val_Acc: 87.288

Epoch 95: Validation loss decreased (0.297357 --> 0.297291).  Saving model ...
	 Train_Loss: 0.3060 Train_Acc: 86.728 Val_Loss: 0.2973  BEST VAL Loss: 0.2973  Val_Acc: 87.185

Epoch 96: Validation loss decreased (0.297291 --> 0.297211).  Saving model ...
	 Train_Loss: 0.3058 Train_Acc: 86.722 Val_Loss: 0.2972  BEST VAL Loss: 0.2972  Val_Acc: 87.140

Epoch 97: Validation loss decreased (0.297211 --> 0.297103).  Saving model ...
	 Train_Loss: 0.3057 Train_Acc: 86.700 Val_Loss: 0.2971  BEST VAL Loss: 0.2971  Val_Acc: 87.255

Epoch 98: Validation loss decreased (0.297103 --> 0.296988).  Saving model ...
	 Train_Loss: 0.3055 Train_Acc: 86.743 Val_Loss: 0.2970  BEST VAL Loss: 0.2970  Val_Acc: 87.055

Epoch 99: Validation loss decreased (0.296988 --> 0.296860).  Saving model ...
	 Train_Loss: 0.3053 Train_Acc: 86.754 Val_Loss: 0.2969  BEST VAL Loss: 0.2969  Val_Acc: 87.577

Flagellin_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.23      0.18      0.21     50422
           1       0.77      0.82      0.79    165500

    accuracy                           0.67    215922
   macro avg       0.50      0.50      0.50    215922
weighted avg       0.64      0.67      0.65    215922

Flagellin_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.24      0.19      0.21      6303
           1       0.77      0.82      0.79     20688

    accuracy                           0.67     26991
   macro avg       0.51      0.50      0.50     26991
weighted avg       0.65      0.67      0.66     26991

Flagellin_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.23      0.18      0.20      6303
           1       0.77      0.82      0.79     20688

    accuracy                           0.67     26991
   macro avg       0.50      0.50      0.50     26991
weighted avg       0.64      0.67      0.65     26991

              precision    recall  f1-score   support

           0       0.23      0.18      0.20      6303
           1       0.77      0.82      0.79     20688

    accuracy                           0.67     26991
   macro avg       0.50      0.50      0.50     26991
weighted avg       0.64      0.67      0.65     26991

Flagellin_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/PBMC
Flagellin_0.100_DMSO_0.025_vs_H2O2_100.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.49      0.35      0.41     32887
           1       0.50      0.64      0.56     33660

    accuracy                           0.50     66547
   macro avg       0.50      0.50      0.49     66547
weighted avg       0.50      0.50      0.49     66547

              precision    recall  f1-score   support

           0       0.49      0.35      0.41     32887
           1       0.50      0.64      0.56     33660

    accuracy                           0.50     66547
   macro avg       0.50      0.50      0.49     66547
weighted avg       0.50      0.50      0.49     66547

completed
