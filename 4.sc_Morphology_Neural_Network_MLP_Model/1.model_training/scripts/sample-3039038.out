[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '519a3349'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '416b0137'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '8caf0b63'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '647b21c7'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: H2O2_100.000_DMSO_0.025 treatment_name: LPS_1.000_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: H2O2_100.000_DMSO_0.025
TREATMENT_NAME: LPS_1.000_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (379969, 1270)
Number of total missing values across all columns: 759938
Data Subset Is Off
Wells held out for testing: ['D09' 'I10']
Wells to use for training, validation, and testing ['D02' 'D03' 'D08' 'H04' 'I04' 'H05' 'I05' 'H10' 'H11' 'I11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.344575).  Saving model ...
	 Train_Loss: 0.4586 Train_Acc: 78.159 Val_Loss: 0.3446  BEST VAL Loss: 0.3446  Val_Acc: 85.135

Epoch 1: Validation loss decreased (0.344575 --> 0.328416).  Saving model ...
	 Train_Loss: 0.4132 Train_Acc: 83.333 Val_Loss: 0.3284  BEST VAL Loss: 0.3284  Val_Acc: 86.701

Epoch 2: Validation loss decreased (0.328416 --> 0.319334).  Saving model ...
	 Train_Loss: 0.3907 Train_Acc: 84.349 Val_Loss: 0.3193  BEST VAL Loss: 0.3193  Val_Acc: 87.065

Epoch 3: Validation loss decreased (0.319334 --> 0.312755).  Saving model ...
	 Train_Loss: 0.3760 Train_Acc: 84.984 Val_Loss: 0.3128  BEST VAL Loss: 0.3128  Val_Acc: 87.601

Epoch 4: Validation loss decreased (0.312755 --> 0.307316).  Saving model ...
	 Train_Loss: 0.3656 Train_Acc: 85.318 Val_Loss: 0.3073  BEST VAL Loss: 0.3073  Val_Acc: 87.921

Epoch 5: Validation loss decreased (0.307316 --> 0.303056).  Saving model ...
	 Train_Loss: 0.3579 Train_Acc: 85.521 Val_Loss: 0.3031  BEST VAL Loss: 0.3031  Val_Acc: 88.260

Epoch 6: Validation loss decreased (0.303056 --> 0.299142).  Saving model ...
	 Train_Loss: 0.3517 Train_Acc: 85.655 Val_Loss: 0.2991  BEST VAL Loss: 0.2991  Val_Acc: 88.326

Epoch 7: Validation loss decreased (0.299142 --> 0.295922).  Saving model ...
	 Train_Loss: 0.3463 Train_Acc: 85.923 Val_Loss: 0.2959  BEST VAL Loss: 0.2959  Val_Acc: 88.567

Epoch 8: Validation loss decreased (0.295922 --> 0.292875).  Saving model ...
	 Train_Loss: 0.3419 Train_Acc: 86.043 Val_Loss: 0.2929  BEST VAL Loss: 0.2929  Val_Acc: 88.760

Epoch 9: Validation loss decreased (0.292875 --> 0.290405).  Saving model ...
	 Train_Loss: 0.3380 Train_Acc: 86.127 Val_Loss: 0.2904  BEST VAL Loss: 0.2904  Val_Acc: 88.700

Epoch 10: Validation loss decreased (0.290405 --> 0.288444).  Saving model ...
	 Train_Loss: 0.3346 Train_Acc: 86.201 Val_Loss: 0.2884  BEST VAL Loss: 0.2884  Val_Acc: 88.852

Epoch 11: Validation loss decreased (0.288444 --> 0.286372).  Saving model ...
	 Train_Loss: 0.3317 Train_Acc: 86.244 Val_Loss: 0.2864  BEST VAL Loss: 0.2864  Val_Acc: 88.919

Epoch 12: Validation loss decreased (0.286372 --> 0.284566).  Saving model ...
	 Train_Loss: 0.3291 Train_Acc: 86.334 Val_Loss: 0.2846  BEST VAL Loss: 0.2846  Val_Acc: 88.928

Epoch 13: Validation loss decreased (0.284566 --> 0.283031).  Saving model ...
	 Train_Loss: 0.3267 Train_Acc: 86.475 Val_Loss: 0.2830  BEST VAL Loss: 0.2830  Val_Acc: 89.008

Epoch 14: Validation loss decreased (0.283031 --> 0.281672).  Saving model ...
	 Train_Loss: 0.3245 Train_Acc: 86.514 Val_Loss: 0.2817  BEST VAL Loss: 0.2817  Val_Acc: 89.068

Epoch 15: Validation loss decreased (0.281672 --> 0.280189).  Saving model ...
	 Train_Loss: 0.3225 Train_Acc: 86.494 Val_Loss: 0.2802  BEST VAL Loss: 0.2802  Val_Acc: 89.191

Epoch 16: Validation loss decreased (0.280189 --> 0.278819).  Saving model ...
	 Train_Loss: 0.3206 Train_Acc: 86.525 Val_Loss: 0.2788  BEST VAL Loss: 0.2788  Val_Acc: 89.438

Epoch 17: Validation loss decreased (0.278819 --> 0.277676).  Saving model ...
	 Train_Loss: 0.3190 Train_Acc: 86.510 Val_Loss: 0.2777  BEST VAL Loss: 0.2777  Val_Acc: 89.125

Epoch 18: Validation loss decreased (0.277676 --> 0.276553).  Saving model ...
	 Train_Loss: 0.3175 Train_Acc: 86.536 Val_Loss: 0.2766  BEST VAL Loss: 0.2766  Val_Acc: 89.391

Epoch 19: Validation loss decreased (0.276553 --> 0.275479).  Saving model ...
	 Train_Loss: 0.3160 Train_Acc: 86.579 Val_Loss: 0.2755  BEST VAL Loss: 0.2755  Val_Acc: 89.185

Epoch 20: Validation loss decreased (0.275479 --> 0.274367).  Saving model ...
	 Train_Loss: 0.3146 Train_Acc: 86.721 Val_Loss: 0.2744  BEST VAL Loss: 0.2744  Val_Acc: 89.537

Epoch 21: Validation loss decreased (0.274367 --> 0.273353).  Saving model ...
	 Train_Loss: 0.3134 Train_Acc: 86.698 Val_Loss: 0.2734  BEST VAL Loss: 0.2734  Val_Acc: 89.271

Epoch 22: Validation loss decreased (0.273353 --> 0.272268).  Saving model ...
	 Train_Loss: 0.3121 Train_Acc: 86.732 Val_Loss: 0.2723  BEST VAL Loss: 0.2723  Val_Acc: 89.667

Epoch 23: Validation loss decreased (0.272268 --> 0.271260).  Saving model ...
	 Train_Loss: 0.3110 Train_Acc: 86.744 Val_Loss: 0.2713  BEST VAL Loss: 0.2713  Val_Acc: 89.600

Epoch 24: Validation loss decreased (0.271260 --> 0.270416).  Saving model ...
	 Train_Loss: 0.3099 Train_Acc: 86.731 Val_Loss: 0.2704  BEST VAL Loss: 0.2704  Val_Acc: 89.423

Epoch 25: Validation loss decreased (0.270416 --> 0.269568).  Saving model ...
	 Train_Loss: 0.3089 Train_Acc: 86.842 Val_Loss: 0.2696  BEST VAL Loss: 0.2696  Val_Acc: 89.553

Epoch 26: Validation loss decreased (0.269568 --> 0.268761).  Saving model ...
	 Train_Loss: 0.3079 Train_Acc: 86.909 Val_Loss: 0.2688  BEST VAL Loss: 0.2688  Val_Acc: 89.477

Epoch 27: Validation loss decreased (0.268761 --> 0.268019).  Saving model ...
	 Train_Loss: 0.3069 Train_Acc: 86.946 Val_Loss: 0.2680  BEST VAL Loss: 0.2680  Val_Acc: 89.660

Epoch 28: Validation loss decreased (0.268019 --> 0.267268).  Saving model ...
	 Train_Loss: 0.3060 Train_Acc: 86.970 Val_Loss: 0.2673  BEST VAL Loss: 0.2673  Val_Acc: 89.584

Epoch 29: Validation loss decreased (0.267268 --> 0.266496).  Saving model ...
	 Train_Loss: 0.3052 Train_Acc: 86.936 Val_Loss: 0.2665  BEST VAL Loss: 0.2665  Val_Acc: 89.819

Epoch 30: Validation loss decreased (0.266496 --> 0.265873).  Saving model ...
	 Train_Loss: 0.3044 Train_Acc: 86.944 Val_Loss: 0.2659  BEST VAL Loss: 0.2659  Val_Acc: 89.537

Epoch 31: Validation loss decreased (0.265873 --> 0.265170).  Saving model ...
	 Train_Loss: 0.3036 Train_Acc: 86.885 Val_Loss: 0.2652  BEST VAL Loss: 0.2652  Val_Acc: 89.705

Epoch 32: Validation loss decreased (0.265170 --> 0.264499).  Saving model ...
	 Train_Loss: 0.3029 Train_Acc: 86.995 Val_Loss: 0.2645  BEST VAL Loss: 0.2645  Val_Acc: 89.689

Epoch 33: Validation loss decreased (0.264499 --> 0.263942).  Saving model ...
	 Train_Loss: 0.3021 Train_Acc: 87.011 Val_Loss: 0.2639  BEST VAL Loss: 0.2639  Val_Acc: 89.613

Epoch 34: Validation loss decreased (0.263942 --> 0.263366).  Saving model ...
	 Train_Loss: 0.3014 Train_Acc: 86.942 Val_Loss: 0.2634  BEST VAL Loss: 0.2634  Val_Acc: 89.524

Epoch 35: Validation loss decreased (0.263366 --> 0.262740).  Saving model ...
	 Train_Loss: 0.3008 Train_Acc: 86.990 Val_Loss: 0.2627  BEST VAL Loss: 0.2627  Val_Acc: 89.901

Epoch 36: Validation loss decreased (0.262740 --> 0.262240).  Saving model ...
	 Train_Loss: 0.3001 Train_Acc: 87.055 Val_Loss: 0.2622  BEST VAL Loss: 0.2622  Val_Acc: 89.686

Epoch 37: Validation loss decreased (0.262240 --> 0.261768).  Saving model ...
	 Train_Loss: 0.2994 Train_Acc: 87.142 Val_Loss: 0.2618  BEST VAL Loss: 0.2618  Val_Acc: 89.695

Epoch 38: Validation loss decreased (0.261768 --> 0.261227).  Saving model ...
	 Train_Loss: 0.2988 Train_Acc: 87.119 Val_Loss: 0.2612  BEST VAL Loss: 0.2612  Val_Acc: 89.803

Epoch 39: Validation loss decreased (0.261227 --> 0.260751).  Saving model ...
	 Train_Loss: 0.2983 Train_Acc: 87.052 Val_Loss: 0.2608  BEST VAL Loss: 0.2608  Val_Acc: 89.797

Epoch 40: Validation loss decreased (0.260751 --> 0.260265).  Saving model ...
	 Train_Loss: 0.2977 Train_Acc: 87.052 Val_Loss: 0.2603  BEST VAL Loss: 0.2603  Val_Acc: 89.942

Epoch 41: Validation loss decreased (0.260265 --> 0.259767).  Saving model ...
	 Train_Loss: 0.2972 Train_Acc: 87.114 Val_Loss: 0.2598  BEST VAL Loss: 0.2598  Val_Acc: 89.873

Epoch 42: Validation loss decreased (0.259767 --> 0.259375).  Saving model ...
	 Train_Loss: 0.2966 Train_Acc: 87.228 Val_Loss: 0.2594  BEST VAL Loss: 0.2594  Val_Acc: 89.568

Epoch 43: Validation loss decreased (0.259375 --> 0.258907).  Saving model ...
	 Train_Loss: 0.2961 Train_Acc: 87.184 Val_Loss: 0.2589  BEST VAL Loss: 0.2589  Val_Acc: 89.968

Epoch 44: Validation loss decreased (0.258907 --> 0.258462).  Saving model ...
	 Train_Loss: 0.2956 Train_Acc: 87.194 Val_Loss: 0.2585  BEST VAL Loss: 0.2585  Val_Acc: 89.790

Epoch 45: Validation loss decreased (0.258462 --> 0.258050).  Saving model ...
	 Train_Loss: 0.2951 Train_Acc: 87.155 Val_Loss: 0.2581  BEST VAL Loss: 0.2581  Val_Acc: 89.930

Epoch 46: Validation loss decreased (0.258050 --> 0.257599).  Saving model ...
	 Train_Loss: 0.2946 Train_Acc: 87.193 Val_Loss: 0.2576  BEST VAL Loss: 0.2576  Val_Acc: 90.174

Epoch 47: Validation loss decreased (0.257599 --> 0.257246).  Saving model ...
	 Train_Loss: 0.2942 Train_Acc: 87.160 Val_Loss: 0.2572  BEST VAL Loss: 0.2572  Val_Acc: 89.977

Epoch 48: Validation loss decreased (0.257246 --> 0.256907).  Saving model ...
	 Train_Loss: 0.2937 Train_Acc: 87.155 Val_Loss: 0.2569  BEST VAL Loss: 0.2569  Val_Acc: 89.838

Epoch 49: Validation loss decreased (0.256907 --> 0.256600).  Saving model ...
	 Train_Loss: 0.2933 Train_Acc: 87.194 Val_Loss: 0.2566  BEST VAL Loss: 0.2566  Val_Acc: 89.854

Epoch 50: Validation loss decreased (0.256600 --> 0.256237).  Saving model ...
	 Train_Loss: 0.2928 Train_Acc: 87.253 Val_Loss: 0.2562  BEST VAL Loss: 0.2562  Val_Acc: 89.793

Epoch 51: Validation loss decreased (0.256237 --> 0.255892).  Saving model ...
	 Train_Loss: 0.2924 Train_Acc: 87.181 Val_Loss: 0.2559  BEST VAL Loss: 0.2559  Val_Acc: 90.003

Epoch 52: Validation loss decreased (0.255892 --> 0.255613).  Saving model ...
	 Train_Loss: 0.2920 Train_Acc: 87.330 Val_Loss: 0.2556  BEST VAL Loss: 0.2556  Val_Acc: 89.888

Epoch 53: Validation loss decreased (0.255613 --> 0.255251).  Saving model ...
	 Train_Loss: 0.2916 Train_Acc: 87.222 Val_Loss: 0.2553  BEST VAL Loss: 0.2553  Val_Acc: 90.079

Epoch 54: Validation loss decreased (0.255251 --> 0.254933).  Saving model ...
	 Train_Loss: 0.2912 Train_Acc: 87.264 Val_Loss: 0.2549  BEST VAL Loss: 0.2549  Val_Acc: 89.955

Epoch 55: Validation loss decreased (0.254933 --> 0.254605).  Saving model ...
	 Train_Loss: 0.2909 Train_Acc: 87.212 Val_Loss: 0.2546  BEST VAL Loss: 0.2546  Val_Acc: 90.164

Epoch 56: Validation loss decreased (0.254605 --> 0.254317).  Saving model ...
	 Train_Loss: 0.2905 Train_Acc: 87.328 Val_Loss: 0.2543  BEST VAL Loss: 0.2543  Val_Acc: 89.965

Epoch 57: Validation loss decreased (0.254317 --> 0.254009).  Saving model ...
	 Train_Loss: 0.2902 Train_Acc: 87.239 Val_Loss: 0.2540  BEST VAL Loss: 0.2540  Val_Acc: 90.091

Epoch 58: Validation loss decreased (0.254009 --> 0.253728).  Saving model ...
	 Train_Loss: 0.2898 Train_Acc: 87.246 Val_Loss: 0.2537  BEST VAL Loss: 0.2537  Val_Acc: 90.015

Epoch 59: Validation loss decreased (0.253728 --> 0.253425).  Saving model ...
	 Train_Loss: 0.2895 Train_Acc: 87.327 Val_Loss: 0.2534  BEST VAL Loss: 0.2534  Val_Acc: 90.082

Epoch 60: Validation loss decreased (0.253425 --> 0.253131).  Saving model ...
	 Train_Loss: 0.2891 Train_Acc: 87.331 Val_Loss: 0.2531  BEST VAL Loss: 0.2531  Val_Acc: 90.250

Epoch 61: Validation loss decreased (0.253131 --> 0.252835).  Saving model ...
	 Train_Loss: 0.2888 Train_Acc: 87.309 Val_Loss: 0.2528  BEST VAL Loss: 0.2528  Val_Acc: 89.968

Epoch 62: Validation loss decreased (0.252835 --> 0.252557).  Saving model ...
	 Train_Loss: 0.2884 Train_Acc: 87.281 Val_Loss: 0.2526  BEST VAL Loss: 0.2526  Val_Acc: 90.085

Epoch 63: Validation loss decreased (0.252557 --> 0.252279).  Saving model ...
	 Train_Loss: 0.2881 Train_Acc: 87.299 Val_Loss: 0.2523  BEST VAL Loss: 0.2523  Val_Acc: 90.145

Epoch 64: Validation loss decreased (0.252279 --> 0.252040).  Saving model ...
	 Train_Loss: 0.2878 Train_Acc: 87.389 Val_Loss: 0.2520  BEST VAL Loss: 0.2520  Val_Acc: 89.898

Epoch 65: Validation loss decreased (0.252040 --> 0.251776).  Saving model ...
	 Train_Loss: 0.2875 Train_Acc: 87.370 Val_Loss: 0.2518  BEST VAL Loss: 0.2518  Val_Acc: 90.088

Epoch 66: Validation loss decreased (0.251776 --> 0.251522).  Saving model ...
	 Train_Loss: 0.2872 Train_Acc: 87.328 Val_Loss: 0.2515  BEST VAL Loss: 0.2515  Val_Acc: 90.069

Epoch 67: Validation loss decreased (0.251522 --> 0.251256).  Saving model ...
	 Train_Loss: 0.2869 Train_Acc: 87.299 Val_Loss: 0.2513  BEST VAL Loss: 0.2513  Val_Acc: 90.180

Epoch 68: Validation loss decreased (0.251256 --> 0.251041).  Saving model ...
	 Train_Loss: 0.2866 Train_Acc: 87.357 Val_Loss: 0.2510  BEST VAL Loss: 0.2510  Val_Acc: 90.094

Epoch 69: Validation loss decreased (0.251041 --> 0.250765).  Saving model ...
	 Train_Loss: 0.2863 Train_Acc: 87.331 Val_Loss: 0.2508  BEST VAL Loss: 0.2508  Val_Acc: 90.231

Epoch 70: Validation loss decreased (0.250765 --> 0.250524).  Saving model ...
	 Train_Loss: 0.2860 Train_Acc: 87.258 Val_Loss: 0.2505  BEST VAL Loss: 0.2505  Val_Acc: 90.126

Epoch 71: Validation loss decreased (0.250524 --> 0.250275).  Saving model ...
	 Train_Loss: 0.2858 Train_Acc: 87.447 Val_Loss: 0.2503  BEST VAL Loss: 0.2503  Val_Acc: 90.148

Epoch 72: Validation loss decreased (0.250275 --> 0.250085).  Saving model ...
	 Train_Loss: 0.2855 Train_Acc: 87.469 Val_Loss: 0.2501  BEST VAL Loss: 0.2501  Val_Acc: 90.101

Epoch 73: Validation loss decreased (0.250085 --> 0.249859).  Saving model ...
	 Train_Loss: 0.2852 Train_Acc: 87.390 Val_Loss: 0.2499  BEST VAL Loss: 0.2499  Val_Acc: 90.164

Epoch 74: Validation loss decreased (0.249859 --> 0.249636).  Saving model ...
	 Train_Loss: 0.2849 Train_Acc: 87.405 Val_Loss: 0.2496  BEST VAL Loss: 0.2496  Val_Acc: 90.237

Epoch 75: Validation loss decreased (0.249636 --> 0.249423).  Saving model ...
	 Train_Loss: 0.2847 Train_Acc: 87.327 Val_Loss: 0.2494  BEST VAL Loss: 0.2494  Val_Acc: 90.262

Epoch 76: Validation loss decreased (0.249423 --> 0.249217).  Saving model ...
	 Train_Loss: 0.2844 Train_Acc: 87.439 Val_Loss: 0.2492  BEST VAL Loss: 0.2492  Val_Acc: 90.132

Epoch 77: Validation loss decreased (0.249217 --> 0.249020).  Saving model ...
	 Train_Loss: 0.2842 Train_Acc: 87.437 Val_Loss: 0.2490  BEST VAL Loss: 0.2490  Val_Acc: 90.018

Epoch 78: Validation loss decreased (0.249020 --> 0.248865).  Saving model ...
	 Train_Loss: 0.2839 Train_Acc: 87.347 Val_Loss: 0.2489  BEST VAL Loss: 0.2489  Val_Acc: 89.965

Epoch 79: Validation loss decreased (0.248865 --> 0.248713).  Saving model ...
	 Train_Loss: 0.2837 Train_Acc: 87.431 Val_Loss: 0.2487  BEST VAL Loss: 0.2487  Val_Acc: 89.968

Epoch 80: Validation loss decreased (0.248713 --> 0.248509).  Saving model ...
	 Train_Loss: 0.2835 Train_Acc: 87.434 Val_Loss: 0.2485  BEST VAL Loss: 0.2485  Val_Acc: 90.209

Epoch 81: Validation loss decreased (0.248509 --> 0.248357).  Saving model ...
	 Train_Loss: 0.2832 Train_Acc: 87.420 Val_Loss: 0.2484  BEST VAL Loss: 0.2484  Val_Acc: 90.199

Epoch 82: Validation loss decreased (0.248357 --> 0.248184).  Saving model ...
	 Train_Loss: 0.2830 Train_Acc: 87.502 Val_Loss: 0.2482  BEST VAL Loss: 0.2482  Val_Acc: 90.209

Epoch 83: Validation loss decreased (0.248184 --> 0.248013).  Saving model ...
	 Train_Loss: 0.2828 Train_Acc: 87.543 Val_Loss: 0.2480  BEST VAL Loss: 0.2480  Val_Acc: 90.209

Epoch 84: Validation loss decreased (0.248013 --> 0.247844).  Saving model ...
	 Train_Loss: 0.2825 Train_Acc: 87.505 Val_Loss: 0.2478  BEST VAL Loss: 0.2478  Val_Acc: 90.177

Epoch 85: Validation loss decreased (0.247844 --> 0.247648).  Saving model ...
	 Train_Loss: 0.2823 Train_Acc: 87.430 Val_Loss: 0.2476  BEST VAL Loss: 0.2476  Val_Acc: 90.323

Epoch 86: Validation loss decreased (0.247648 --> 0.247492).  Saving model ...
	 Train_Loss: 0.2821 Train_Acc: 87.396 Val_Loss: 0.2475  BEST VAL Loss: 0.2475  Val_Acc: 90.164

Epoch 87: Validation loss decreased (0.247492 --> 0.247313).  Saving model ...
	 Train_Loss: 0.2819 Train_Acc: 87.420 Val_Loss: 0.2473  BEST VAL Loss: 0.2473  Val_Acc: 90.237

Epoch 88: Validation loss decreased (0.247313 --> 0.247132).  Saving model ...
	 Train_Loss: 0.2817 Train_Acc: 87.506 Val_Loss: 0.2471  BEST VAL Loss: 0.2471  Val_Acc: 90.269

Epoch 89: Validation loss decreased (0.247132 --> 0.246958).  Saving model ...
	 Train_Loss: 0.2815 Train_Acc: 87.455 Val_Loss: 0.2470  BEST VAL Loss: 0.2470  Val_Acc: 90.266

Epoch 90: Validation loss decreased (0.246958 --> 0.246787).  Saving model ...
	 Train_Loss: 0.2813 Train_Acc: 87.488 Val_Loss: 0.2468  BEST VAL Loss: 0.2468  Val_Acc: 90.212

Epoch 91: Validation loss decreased (0.246787 --> 0.246613).  Saving model ...
	 Train_Loss: 0.2811 Train_Acc: 87.493 Val_Loss: 0.2466  BEST VAL Loss: 0.2466  Val_Acc: 90.288

Epoch 92: Validation loss decreased (0.246613 --> 0.246427).  Saving model ...
	 Train_Loss: 0.2809 Train_Acc: 87.579 Val_Loss: 0.2464  BEST VAL Loss: 0.2464  Val_Acc: 90.272

Epoch 93: Validation loss decreased (0.246427 --> 0.246258).  Saving model ...
	 Train_Loss: 0.2807 Train_Acc: 87.535 Val_Loss: 0.2463  BEST VAL Loss: 0.2463  Val_Acc: 90.253

Epoch 94: Validation loss decreased (0.246258 --> 0.246117).  Saving model ...
	 Train_Loss: 0.2805 Train_Acc: 87.523 Val_Loss: 0.2461  BEST VAL Loss: 0.2461  Val_Acc: 90.139

Epoch 95: Validation loss decreased (0.246117 --> 0.245967).  Saving model ...
	 Train_Loss: 0.2803 Train_Acc: 87.539 Val_Loss: 0.2460  BEST VAL Loss: 0.2460  Val_Acc: 90.148

Epoch 96: Validation loss decreased (0.245967 --> 0.245844).  Saving model ...
	 Train_Loss: 0.2801 Train_Acc: 87.531 Val_Loss: 0.2458  BEST VAL Loss: 0.2458  Val_Acc: 90.310

Epoch 97: Validation loss decreased (0.245844 --> 0.245718).  Saving model ...
	 Train_Loss: 0.2799 Train_Acc: 87.535 Val_Loss: 0.2457  BEST VAL Loss: 0.2457  Val_Acc: 90.183

Epoch 98: Validation loss decreased (0.245718 --> 0.245580).  Saving model ...
	 Train_Loss: 0.2797 Train_Acc: 87.453 Val_Loss: 0.2456  BEST VAL Loss: 0.2456  Val_Acc: 90.221

Epoch 99: Validation loss decreased (0.245580 --> 0.245429).  Saving model ...
	 Train_Loss: 0.2795 Train_Acc: 87.511 Val_Loss: 0.2454  BEST VAL Loss: 0.2454  Val_Acc: 90.174

H2O2_100.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.91      0.96      0.94    169560
           1       0.91      0.81      0.86     82898

    accuracy                           0.91    252458
   macro avg       0.91      0.89      0.90    252458
weighted avg       0.91      0.91      0.91    252458

H2O2_100.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.90      0.96      0.93     21196
           1       0.90      0.79      0.84     10362

    accuracy                           0.90     31558
   macro avg       0.90      0.87      0.88     31558
weighted avg       0.90      0.90      0.90     31558

H2O2_100.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.91      0.95      0.93     21196
           1       0.89      0.80      0.84     10362

    accuracy                           0.90     31558
   macro avg       0.90      0.88      0.89     31558
weighted avg       0.90      0.90      0.90     31558

              precision    recall  f1-score   support

           0       0.91      0.95      0.93     21196
           1       0.89      0.80      0.84     10362

    accuracy                           0.90     31558
   macro avg       0.90      0.88      0.89     31558
weighted avg       0.90      0.90      0.90     31558

H2O2_100.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
H2O2_100.000_DMSO_0.025_vs_LPS_1.000_DMSO_0.025
              precision    recall  f1-score   support

           0       0.48      0.91      0.63     28584
           1       0.74      0.21      0.33     35811

    accuracy                           0.52     64395
   macro avg       0.61      0.56      0.48     64395
weighted avg       0.62      0.52      0.46     64395

              precision    recall  f1-score   support

           0       0.48      0.91      0.63     28584
           1       0.74      0.21      0.33     35811

    accuracy                           0.52     64395
   macro avg       0.61      0.56      0.48     64395
weighted avg       0.62      0.52      0.46     64395

completed
