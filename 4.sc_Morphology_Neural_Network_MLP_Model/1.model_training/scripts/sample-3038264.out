[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'b7f97062'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '79a74dee'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to '433adbef'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'ab208a09'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: SHSY5Y control_name: Thapsigargin_1.000_DMSO_0.025 treatment_name: LPS_10.000_DMSO_0.025 shuffle: True
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: SHSY5Y
CONTROL_NAME: Thapsigargin_1.000_DMSO_0.025
TREATMENT_NAME: LPS_10.000_DMSO_0.025
SHUFFLE: True
True
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'LPS_10.000_DMSO_0.025']
The dimensions of the data are: (30576, 1276)
Number of total missing values across all columns: 61152
Data Subset Is Off
Wells held out for testing: ['D14' 'E20']
Wells to use for training, validation, and testing ['D15' 'E16' 'E17' 'E21' 'K14' 'K15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
RMSprop
Epoch 0: Validation loss decreased (inf --> 0.486695).  Saving model ...
	 Train_Loss: 0.6417 Train_Acc: 69.702 Val_Loss: 0.4867  BEST VAL Loss: 0.4867  Val_Acc: 78.754

Epoch 1: Validation loss decreased (0.486695 --> 0.465153).  Saving model ...
	 Train_Loss: 0.5739 Train_Acc: 75.453 Val_Loss: 0.4652  BEST VAL Loss: 0.4652  Val_Acc: 80.095

Epoch 2: Validation loss decreased (0.465153 --> 0.454849).  Saving model ...
	 Train_Loss: 0.5419 Train_Acc: 77.487 Val_Loss: 0.4548  BEST VAL Loss: 0.4548  Val_Acc: 82.562

Epoch 3: Validation loss decreased (0.454849 --> 0.443669).  Saving model ...
	 Train_Loss: 0.5209 Train_Acc: 78.748 Val_Loss: 0.4437  BEST VAL Loss: 0.4437  Val_Acc: 82.562

Epoch 4: Validation loss decreased (0.443669 --> 0.433657).  Saving model ...
	 Train_Loss: 0.5050 Train_Acc: 79.689 Val_Loss: 0.4337  BEST VAL Loss: 0.4337  Val_Acc: 83.990

Epoch 5: Validation loss decreased (0.433657 --> 0.424740).  Saving model ...
	 Train_Loss: 0.4918 Train_Acc: 80.869 Val_Loss: 0.4247  BEST VAL Loss: 0.4247  Val_Acc: 84.725

Epoch 6: Validation loss decreased (0.424740 --> 0.415566).  Saving model ...
	 Train_Loss: 0.4816 Train_Acc: 81.264 Val_Loss: 0.4156  BEST VAL Loss: 0.4156  Val_Acc: 86.110

Epoch 7: Validation loss decreased (0.415566 --> 0.408525).  Saving model ...
	 Train_Loss: 0.4719 Train_Acc: 82.265 Val_Loss: 0.4085  BEST VAL Loss: 0.4085  Val_Acc: 86.543

Epoch 8: Validation loss decreased (0.408525 --> 0.405140).  Saving model ...
	 Train_Loss: 0.4640 Train_Acc: 82.535 Val_Loss: 0.4051  BEST VAL Loss: 0.4051  Val_Acc: 85.331

Epoch 9: Validation loss decreased (0.405140 --> 0.398648).  Saving model ...
	 Train_Loss: 0.4566 Train_Acc: 83.076 Val_Loss: 0.3986  BEST VAL Loss: 0.3986  Val_Acc: 86.629

Epoch 10: Validation loss decreased (0.398648 --> 0.394151).  Saving model ...
	 Train_Loss: 0.4503 Train_Acc: 83.358 Val_Loss: 0.3942  BEST VAL Loss: 0.3942  Val_Acc: 87.408

Epoch 11: Validation loss decreased (0.394151 --> 0.391175).  Saving model ...
	 Train_Loss: 0.4444 Train_Acc: 83.985 Val_Loss: 0.3912  BEST VAL Loss: 0.3912  Val_Acc: 87.019

Epoch 12: Validation loss decreased (0.391175 --> 0.387333).  Saving model ...
	 Train_Loss: 0.4386 Train_Acc: 84.310 Val_Loss: 0.3873  BEST VAL Loss: 0.3873  Val_Acc: 86.932

Epoch 13: Validation loss decreased (0.387333 --> 0.383870).  Saving model ...
	 Train_Loss: 0.4334 Train_Acc: 84.694 Val_Loss: 0.3839  BEST VAL Loss: 0.3839  Val_Acc: 86.499

Epoch 14: Validation loss decreased (0.383870 --> 0.381871).  Saving model ...
	 Train_Loss: 0.4288 Train_Acc: 84.802 Val_Loss: 0.3819  BEST VAL Loss: 0.3819  Val_Acc: 88.057

Epoch 15: Validation loss decreased (0.381871 --> 0.378698).  Saving model ...
	 Train_Loss: 0.4243 Train_Acc: 85.397 Val_Loss: 0.3787  BEST VAL Loss: 0.3787  Val_Acc: 87.451

Epoch 16: Validation loss decreased (0.378698 --> 0.375796).  Saving model ...
	 Train_Loss: 0.4204 Train_Acc: 85.057 Val_Loss: 0.3758  BEST VAL Loss: 0.3758  Val_Acc: 87.408

Epoch 17: Validation loss decreased (0.375796 --> 0.373406).  Saving model ...
	 Train_Loss: 0.4165 Train_Acc: 85.679 Val_Loss: 0.3734  BEST VAL Loss: 0.3734  Val_Acc: 87.148

Epoch 18: Validation loss decreased (0.373406 --> 0.370941).  Saving model ...
	 Train_Loss: 0.4129 Train_Acc: 85.792 Val_Loss: 0.3709  BEST VAL Loss: 0.3709  Val_Acc: 88.360

Epoch 19: Validation loss decreased (0.370941 --> 0.368295).  Saving model ...
	 Train_Loss: 0.4097 Train_Acc: 85.603 Val_Loss: 0.3683  BEST VAL Loss: 0.3683  Val_Acc: 88.793

Epoch 20: Validation loss decreased (0.368295 --> 0.366605).  Saving model ...
	 Train_Loss: 0.4065 Train_Acc: 85.998 Val_Loss: 0.3666  BEST VAL Loss: 0.3666  Val_Acc: 88.273

Epoch 21: Validation loss decreased (0.366605 --> 0.364253).  Saving model ...
	 Train_Loss: 0.4037 Train_Acc: 85.901 Val_Loss: 0.3643  BEST VAL Loss: 0.3643  Val_Acc: 88.966

Epoch 22: Validation loss decreased (0.364253 --> 0.362110).  Saving model ...
	 Train_Loss: 0.4008 Train_Acc: 86.517 Val_Loss: 0.3621  BEST VAL Loss: 0.3621  Val_Acc: 88.576

Epoch 23: Validation loss decreased (0.362110 --> 0.359963).  Saving model ...
	 Train_Loss: 0.3980 Train_Acc: 86.653 Val_Loss: 0.3600  BEST VAL Loss: 0.3600  Val_Acc: 89.788

Epoch 24: Validation loss decreased (0.359963 --> 0.358944).  Saving model ...
	 Train_Loss: 0.3956 Train_Acc: 86.415 Val_Loss: 0.3589  BEST VAL Loss: 0.3589  Val_Acc: 89.225

Epoch 25: Validation loss decreased (0.358944 --> 0.357658).  Saving model ...
	 Train_Loss: 0.3933 Train_Acc: 86.382 Val_Loss: 0.3577  BEST VAL Loss: 0.3577  Val_Acc: 89.701

Epoch 26: Validation loss decreased (0.357658 --> 0.355487).  Saving model ...
	 Train_Loss: 0.3910 Train_Acc: 86.604 Val_Loss: 0.3555  BEST VAL Loss: 0.3555  Val_Acc: 88.879

Epoch 27: Validation loss decreased (0.355487 --> 0.353704).  Saving model ...
	 Train_Loss: 0.3887 Train_Acc: 86.815 Val_Loss: 0.3537  BEST VAL Loss: 0.3537  Val_Acc: 89.961

Epoch 28: Validation loss decreased (0.353704 --> 0.351813).  Saving model ...
	 Train_Loss: 0.3867 Train_Acc: 87.031 Val_Loss: 0.3518  BEST VAL Loss: 0.3518  Val_Acc: 89.528

Epoch 29: Validation loss decreased (0.351813 --> 0.350719).  Saving model ...
	 Train_Loss: 0.3848 Train_Acc: 86.761 Val_Loss: 0.3507  BEST VAL Loss: 0.3507  Val_Acc: 89.485

Epoch 30: Validation loss decreased (0.350719 --> 0.349144).  Saving model ...
	 Train_Loss: 0.3829 Train_Acc: 87.150 Val_Loss: 0.3491  BEST VAL Loss: 0.3491  Val_Acc: 89.528

Epoch 31: Validation loss decreased (0.349144 --> 0.347769).  Saving model ...
	 Train_Loss: 0.3811 Train_Acc: 86.728 Val_Loss: 0.3478  BEST VAL Loss: 0.3478  Val_Acc: 89.831

Epoch 32: Validation loss decreased (0.347769 --> 0.346982).  Saving model ...
	 Train_Loss: 0.3794 Train_Acc: 87.286 Val_Loss: 0.3470  BEST VAL Loss: 0.3470  Val_Acc: 88.317

Epoch 33: Validation loss decreased (0.346982 --> 0.345434).  Saving model ...
	 Train_Loss: 0.3777 Train_Acc: 87.313 Val_Loss: 0.3454  BEST VAL Loss: 0.3454  Val_Acc: 89.831

Epoch 34: Validation loss decreased (0.345434 --> 0.344473).  Saving model ...
	 Train_Loss: 0.3762 Train_Acc: 87.150 Val_Loss: 0.3445  BEST VAL Loss: 0.3445  Val_Acc: 89.442

Epoch 35: Validation loss decreased (0.344473 --> 0.342741).  Saving model ...
	 Train_Loss: 0.3747 Train_Acc: 87.188 Val_Loss: 0.3427  BEST VAL Loss: 0.3427  Val_Acc: 90.524

Epoch 36: Validation loss decreased (0.342741 --> 0.340877).  Saving model ...
	 Train_Loss: 0.3731 Train_Acc: 87.594 Val_Loss: 0.3409  BEST VAL Loss: 0.3409  Val_Acc: 90.697

Epoch 37: Validation loss decreased (0.340877 --> 0.340397).  Saving model ...
	 Train_Loss: 0.3716 Train_Acc: 87.724 Val_Loss: 0.3404  BEST VAL Loss: 0.3404  Val_Acc: 89.096

Epoch 38: Validation loss decreased (0.340397 --> 0.339455).  Saving model ...
	 Train_Loss: 0.3704 Train_Acc: 86.988 Val_Loss: 0.3395  BEST VAL Loss: 0.3395  Val_Acc: 90.177

Epoch 39: Validation loss decreased (0.339455 --> 0.338639).  Saving model ...
	 Train_Loss: 0.3690 Train_Acc: 87.924 Val_Loss: 0.3386  BEST VAL Loss: 0.3386  Val_Acc: 89.788

Epoch 40: Validation loss did not decrease
	 Train_Loss: 0.3676 Train_Acc: 87.870 Val_Loss: 0.3389  BEST VAL Loss: 0.3386  Val_Acc: 88.360

Epoch 41: Validation loss decreased (0.338639 --> 0.338365).  Saving model ...
	 Train_Loss: 0.3664 Train_Acc: 87.426 Val_Loss: 0.3384  BEST VAL Loss: 0.3384  Val_Acc: 90.480

Epoch 42: Validation loss decreased (0.338365 --> 0.337217).  Saving model ...
	 Train_Loss: 0.3652 Train_Acc: 87.865 Val_Loss: 0.3372  BEST VAL Loss: 0.3372  Val_Acc: 90.437

Epoch 43: Validation loss decreased (0.337217 --> 0.336338).  Saving model ...
	 Train_Loss: 0.3640 Train_Acc: 87.632 Val_Loss: 0.3363  BEST VAL Loss: 0.3363  Val_Acc: 90.610

Epoch 44: Validation loss decreased (0.336338 --> 0.335583).  Saving model ...
	 Train_Loss: 0.3629 Train_Acc: 87.643 Val_Loss: 0.3356  BEST VAL Loss: 0.3356  Val_Acc: 89.312

Epoch 45: Validation loss decreased (0.335583 --> 0.335286).  Saving model ...
	 Train_Loss: 0.3619 Train_Acc: 87.670 Val_Loss: 0.3353  BEST VAL Loss: 0.3353  Val_Acc: 90.004

Epoch 46: Validation loss decreased (0.335286 --> 0.334013).  Saving model ...
	 Train_Loss: 0.3607 Train_Acc: 88.178 Val_Loss: 0.3340  BEST VAL Loss: 0.3340  Val_Acc: 90.783

Epoch 47: Validation loss decreased (0.334013 --> 0.333022).  Saving model ...
	 Train_Loss: 0.3598 Train_Acc: 87.724 Val_Loss: 0.3330  BEST VAL Loss: 0.3330  Val_Acc: 90.740

Epoch 48: Validation loss decreased (0.333022 --> 0.332502).  Saving model ...
	 Train_Loss: 0.3587 Train_Acc: 88.016 Val_Loss: 0.3325  BEST VAL Loss: 0.3325  Val_Acc: 89.182

Epoch 49: Validation loss decreased (0.332502 --> 0.331953).  Saving model ...
	 Train_Loss: 0.3577 Train_Acc: 88.076 Val_Loss: 0.3320  BEST VAL Loss: 0.3320  Val_Acc: 89.312

Epoch 50: Validation loss decreased (0.331953 --> 0.331813).  Saving model ...
	 Train_Loss: 0.3566 Train_Acc: 88.178 Val_Loss: 0.3318  BEST VAL Loss: 0.3318  Val_Acc: 88.360

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.3558 Train_Acc: 87.626 Val_Loss: 0.3320  BEST VAL Loss: 0.3318  Val_Acc: 89.009

Epoch 52: Validation loss decreased (0.331813 --> 0.331163).  Saving model ...
	 Train_Loss: 0.3550 Train_Acc: 87.800 Val_Loss: 0.3312  BEST VAL Loss: 0.3312  Val_Acc: 90.134

Epoch 53: Validation loss decreased (0.331163 --> 0.330571).  Saving model ...
	 Train_Loss: 0.3541 Train_Acc: 88.108 Val_Loss: 0.3306  BEST VAL Loss: 0.3306  Val_Acc: 89.528

Epoch 54: Validation loss decreased (0.330571 --> 0.329707).  Saving model ...
	 Train_Loss: 0.3534 Train_Acc: 87.929 Val_Loss: 0.3297  BEST VAL Loss: 0.3297  Val_Acc: 90.567

Epoch 55: Validation loss decreased (0.329707 --> 0.329079).  Saving model ...
	 Train_Loss: 0.3525 Train_Acc: 88.157 Val_Loss: 0.3291  BEST VAL Loss: 0.3291  Val_Acc: 90.004

Epoch 56: Validation loss decreased (0.329079 --> 0.328315).  Saving model ...
	 Train_Loss: 0.3517 Train_Acc: 88.259 Val_Loss: 0.3283  BEST VAL Loss: 0.3283  Val_Acc: 90.221

Epoch 57: Validation loss decreased (0.328315 --> 0.327750).  Saving model ...
	 Train_Loss: 0.3508 Train_Acc: 88.487 Val_Loss: 0.3278  BEST VAL Loss: 0.3278  Val_Acc: 90.913

Epoch 58: Validation loss decreased (0.327750 --> 0.326980).  Saving model ...
	 Train_Loss: 0.3501 Train_Acc: 87.892 Val_Loss: 0.3270  BEST VAL Loss: 0.3270  Val_Acc: 90.480

Epoch 59: Validation loss decreased (0.326980 --> 0.326851).  Saving model ...
	 Train_Loss: 0.3493 Train_Acc: 88.476 Val_Loss: 0.3269  BEST VAL Loss: 0.3269  Val_Acc: 89.225

Epoch 60: Validation loss decreased (0.326851 --> 0.326406).  Saving model ...
	 Train_Loss: 0.3485 Train_Acc: 88.357 Val_Loss: 0.3264  BEST VAL Loss: 0.3264  Val_Acc: 90.264

Epoch 61: Validation loss decreased (0.326406 --> 0.326221).  Saving model ...
	 Train_Loss: 0.3477 Train_Acc: 88.243 Val_Loss: 0.3262  BEST VAL Loss: 0.3262  Val_Acc: 89.918

Epoch 62: Validation loss decreased (0.326221 --> 0.325440).  Saving model ...
	 Train_Loss: 0.3470 Train_Acc: 88.427 Val_Loss: 0.3254  BEST VAL Loss: 0.3254  Val_Acc: 90.567

Epoch 63: Validation loss decreased (0.325440 --> 0.324866).  Saving model ...
	 Train_Loss: 0.3464 Train_Acc: 88.027 Val_Loss: 0.3249  BEST VAL Loss: 0.3249  Val_Acc: 90.826

Epoch 64: Validation loss decreased (0.324866 --> 0.324689).  Saving model ...
	 Train_Loss: 0.3456 Train_Acc: 88.617 Val_Loss: 0.3247  BEST VAL Loss: 0.3247  Val_Acc: 90.480

Epoch 65: Validation loss decreased (0.324689 --> 0.324550).  Saving model ...
	 Train_Loss: 0.3449 Train_Acc: 88.579 Val_Loss: 0.3246  BEST VAL Loss: 0.3246  Val_Acc: 90.480

Epoch 66: Validation loss decreased (0.324550 --> 0.324061).  Saving model ...
	 Train_Loss: 0.3443 Train_Acc: 88.341 Val_Loss: 0.3241  BEST VAL Loss: 0.3241  Val_Acc: 90.221

Epoch 67: Validation loss decreased (0.324061 --> 0.323366).  Saving model ...
	 Train_Loss: 0.3437 Train_Acc: 88.357 Val_Loss: 0.3234  BEST VAL Loss: 0.3234  Val_Acc: 90.826

Epoch 68: Validation loss decreased (0.323366 --> 0.323011).  Saving model ...
	 Train_Loss: 0.3431 Train_Acc: 88.097 Val_Loss: 0.3230  BEST VAL Loss: 0.3230  Val_Acc: 90.048

Epoch 69: Validation loss did not decrease
	 Train_Loss: 0.3425 Train_Acc: 88.525 Val_Loss: 0.3231  BEST VAL Loss: 0.3230  Val_Acc: 88.360

Epoch 70: Validation loss decreased (0.323011 --> 0.322745).  Saving model ...
	 Train_Loss: 0.3420 Train_Acc: 88.005 Val_Loss: 0.3227  BEST VAL Loss: 0.3227  Val_Acc: 89.745

Epoch 71: Validation loss did not decrease
	 Train_Loss: 0.3413 Train_Acc: 88.822 Val_Loss: 0.3229  BEST VAL Loss: 0.3227  Val_Acc: 89.572

Epoch 72: Validation loss decreased (0.322745 --> 0.322635).  Saving model ...
	 Train_Loss: 0.3408 Train_Acc: 88.308 Val_Loss: 0.3226  BEST VAL Loss: 0.3226  Val_Acc: 90.134

Epoch 73: Validation loss decreased (0.322635 --> 0.322554).  Saving model ...
	 Train_Loss: 0.3401 Train_Acc: 89.017 Val_Loss: 0.3226  BEST VAL Loss: 0.3226  Val_Acc: 89.182

Epoch 74: Validation loss decreased (0.322554 --> 0.322232).  Saving model ...
	 Train_Loss: 0.3397 Train_Acc: 88.081 Val_Loss: 0.3222  BEST VAL Loss: 0.3222  Val_Acc: 90.524

Epoch 75: Validation loss decreased (0.322232 --> 0.321926).  Saving model ...
	 Train_Loss: 0.3393 Train_Acc: 88.059 Val_Loss: 0.3219  BEST VAL Loss: 0.3219  Val_Acc: 90.480

Epoch 76: Validation loss decreased (0.321926 --> 0.321789).  Saving model ...
	 Train_Loss: 0.3387 Train_Acc: 88.514 Val_Loss: 0.3218  BEST VAL Loss: 0.3218  Val_Acc: 91.216

Epoch 77: Validation loss decreased (0.321789 --> 0.321693).  Saving model ...
	 Train_Loss: 0.3382 Train_Acc: 88.519 Val_Loss: 0.3217  BEST VAL Loss: 0.3217  Val_Acc: 90.350

Epoch 78: Validation loss decreased (0.321693 --> 0.321565).  Saving model ...
	 Train_Loss: 0.3377 Train_Acc: 88.395 Val_Loss: 0.3216  BEST VAL Loss: 0.3216  Val_Acc: 90.826

Epoch 79: Validation loss decreased (0.321565 --> 0.321371).  Saving model ...
	 Train_Loss: 0.3372 Train_Acc: 88.833 Val_Loss: 0.3214  BEST VAL Loss: 0.3214  Val_Acc: 90.740

Epoch 80: Validation loss decreased (0.321371 --> 0.321119).  Saving model ...
	 Train_Loss: 0.3367 Train_Acc: 88.687 Val_Loss: 0.3211  BEST VAL Loss: 0.3211  Val_Acc: 90.394

Epoch 81: Validation loss decreased (0.321119 --> 0.320793).  Saving model ...
	 Train_Loss: 0.3362 Train_Acc: 88.638 Val_Loss: 0.3208  BEST VAL Loss: 0.3208  Val_Acc: 91.129

Epoch 82: Validation loss decreased (0.320793 --> 0.320723).  Saving model ...
	 Train_Loss: 0.3358 Train_Acc: 88.443 Val_Loss: 0.3207  BEST VAL Loss: 0.3207  Val_Acc: 89.918

Epoch 83: Validation loss decreased (0.320723 --> 0.320401).  Saving model ...
	 Train_Loss: 0.3353 Train_Acc: 88.552 Val_Loss: 0.3204  BEST VAL Loss: 0.3204  Val_Acc: 90.437

Epoch 84: Validation loss decreased (0.320401 --> 0.320024).  Saving model ...
	 Train_Loss: 0.3349 Train_Acc: 88.508 Val_Loss: 0.3200  BEST VAL Loss: 0.3200  Val_Acc: 90.567

Epoch 85: Validation loss decreased (0.320024 --> 0.319615).  Saving model ...
	 Train_Loss: 0.3345 Train_Acc: 88.703 Val_Loss: 0.3196  BEST VAL Loss: 0.3196  Val_Acc: 90.783

Epoch 86: Validation loss decreased (0.319615 --> 0.319342).  Saving model ...
	 Train_Loss: 0.3340 Train_Acc: 88.584 Val_Loss: 0.3193  BEST VAL Loss: 0.3193  Val_Acc: 90.350

Epoch 87: Validation loss decreased (0.319342 --> 0.318915).  Saving model ...
	 Train_Loss: 0.3335 Train_Acc: 88.995 Val_Loss: 0.3189  BEST VAL Loss: 0.3189  Val_Acc: 90.913

Epoch 88: Validation loss decreased (0.318915 --> 0.318640).  Saving model ...
	 Train_Loss: 0.3331 Train_Acc: 88.617 Val_Loss: 0.3186  BEST VAL Loss: 0.3186  Val_Acc: 90.826

Epoch 89: Validation loss decreased (0.318640 --> 0.318292).  Saving model ...
	 Train_Loss: 0.3327 Train_Acc: 88.590 Val_Loss: 0.3183  BEST VAL Loss: 0.3183  Val_Acc: 90.307

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.3323 Train_Acc: 88.600 Val_Loss: 0.3183  BEST VAL Loss: 0.3183  Val_Acc: 90.177

Epoch 91: Validation loss decreased (0.318292 --> 0.318224).  Saving model ...
	 Train_Loss: 0.3320 Train_Acc: 88.292 Val_Loss: 0.3182  BEST VAL Loss: 0.3182  Val_Acc: 90.870

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.3315 Train_Acc: 88.990 Val_Loss: 0.3183  BEST VAL Loss: 0.3182  Val_Acc: 90.307

Epoch 93: Validation loss decreased (0.318224 --> 0.318024).  Saving model ...
	 Train_Loss: 0.3312 Train_Acc: 88.752 Val_Loss: 0.3180  BEST VAL Loss: 0.3180  Val_Acc: 90.956

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.3307 Train_Acc: 89.006 Val_Loss: 0.3180  BEST VAL Loss: 0.3180  Val_Acc: 90.783

Epoch 95: Validation loss decreased (0.318024 --> 0.317798).  Saving model ...
	 Train_Loss: 0.3304 Train_Acc: 88.265 Val_Loss: 0.3178  BEST VAL Loss: 0.3178  Val_Acc: 90.134

Epoch 96: Validation loss decreased (0.317798 --> 0.317575).  Saving model ...
	 Train_Loss: 0.3301 Train_Acc: 88.514 Val_Loss: 0.3176  BEST VAL Loss: 0.3176  Val_Acc: 90.524

Epoch 97: Validation loss decreased (0.317575 --> 0.317416).  Saving model ...
	 Train_Loss: 0.3297 Train_Acc: 88.806 Val_Loss: 0.3174  BEST VAL Loss: 0.3174  Val_Acc: 90.437

Epoch 98: Validation loss decreased (0.317416 --> 0.317163).  Saving model ...
	 Train_Loss: 0.3293 Train_Acc: 88.590 Val_Loss: 0.3172  BEST VAL Loss: 0.3172  Val_Acc: 90.697

Epoch 99: Validation loss decreased (0.317163 --> 0.316833).  Saving model ...
	 Train_Loss: 0.3290 Train_Acc: 88.801 Val_Loss: 0.3168  BEST VAL Loss: 0.3168  Val_Acc: 90.740

Thapsigargin_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.52      0.53     10113
           1       0.45      0.48      0.47      8370

    accuracy                           0.50     18483
   macro avg       0.50      0.50      0.50     18483
weighted avg       0.51      0.50      0.50     18483

Thapsigargin_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.52      0.53      1264
           1       0.45      0.48      0.47      1047

    accuracy                           0.50      2311
   macro avg       0.50      0.50      0.50      2311
weighted avg       0.50      0.50      0.50      2311

Thapsigargin_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.56      0.53      0.54      1265
           1       0.47      0.50      0.48      1046

    accuracy                           0.51      2311
   macro avg       0.51      0.51      0.51      2311
weighted avg       0.52      0.51      0.51      2311

              precision    recall  f1-score   support

           0       0.56      0.53      0.54      1265
           1       0.47      0.50      0.48      1046

    accuracy                           0.51      2311
   macro avg       0.51      0.51      0.51      2311
weighted avg       0.52      0.51      0.51      2311

Thapsigargin_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
../../trained_models/model_save_states/Binary_Classification/SHSY5Y
Thapsigargin_1.000_DMSO_0.025_vs_LPS_10.000_DMSO_0.025_shuffle
              precision    recall  f1-score   support

           0       0.55      0.53      0.54      4168
           1       0.44      0.47      0.45      3303

    accuracy                           0.50      7471
   macro avg       0.50      0.50      0.50      7471
weighted avg       0.50      0.50      0.50      7471

              precision    recall  f1-score   support

           0       0.55      0.53      0.54      4168
           1       0.44      0.47      0.45      3303

    accuracy                           0.50      7471
   macro avg       0.50      0.50      0.50      7471
weighted avg       0.50      0.50      0.50      7471

completed
