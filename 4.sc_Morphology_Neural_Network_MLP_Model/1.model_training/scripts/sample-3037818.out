[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multi-class.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'ac1d28d0'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to '14afe61f'.
  validate(nb)
[NbConvertApp] Writing 14456 bytes to Hyperparameter_Optimization_model_multi-class.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_regression.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3e2c848c' detected. Corrected to 'de7247f3'.
  validate(nb)
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar/lib/python3.10/site-packages/nbformat/__init__.py:93: DuplicateCellId: Non-unique cell id '3c53f7e4' detected. Corrected to 'f694fea0'.
  validate(nb)
[NbConvertApp] Writing 12852 bytes to Hyperparameter_Optimization_model_regression.py
[NbConvertApp] Converting notebook ../notebooks/train_binary_model.ipynb to script
[NbConvertApp] Writing 19547 bytes to train_binary_model.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025 shuffle: False
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:997: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y1], palette="blue", label="Train")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:998: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.
  sns.lineplot(x=df[x], y=df[y2], palette="orange", label="Validation")
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1018: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
/gpfs/alpine1/scratch/mlippincott@xsede.org/Interstellar_Analysis/4.sc_Morphology_Neural_Network_MLP_Model/1.model_training/scripts/../../MLP_utils/utils.py:1324: UserWarning: The figure layout has changed to tight
  plt.tight_layout()
CELL_TYPE: PBMC
CONTROL_NAME: LPS_Nigericin_1.000_3.0_DMSO_0.025
TREATMENT_NAME: Flagellin_0.100_DMSO_0.025
SHUFFLE: False
False
Selected Catagories are:
['LPS_Nigericin_1.000_3.0_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (270176, 1270)
Number of total missing values across all columns: 191830
Data Subset Is Off
Wells held out for testing: ['L08' 'L10']
Wells to use for training, validation, and testing ['L02' 'L03' 'L05' 'L09' 'L11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
Adam
Epoch 0: Validation loss decreased (inf --> 0.060088).  Saving model ...
	 Train_Loss: 0.1481 Train_Acc: 94.090 Val_Loss: 0.0601  BEST VAL Loss: 0.0601  Val_Acc: 97.957

Epoch 1: Validation loss decreased (0.060088 --> 0.052599).  Saving model ...
	 Train_Loss: 0.1180 Train_Acc: 96.676 Val_Loss: 0.0526  BEST VAL Loss: 0.0526  Val_Acc: 98.440

Epoch 2: Validation loss decreased (0.052599 --> 0.048493).  Saving model ...
	 Train_Loss: 0.1026 Train_Acc: 97.217 Val_Loss: 0.0485  BEST VAL Loss: 0.0485  Val_Acc: 98.530

Epoch 3: Validation loss decreased (0.048493 --> 0.044772).  Saving model ...
	 Train_Loss: 0.0931 Train_Acc: 97.436 Val_Loss: 0.0448  BEST VAL Loss: 0.0448  Val_Acc: 98.761

Epoch 4: Validation loss decreased (0.044772 --> 0.042932).  Saving model ...
	 Train_Loss: 0.0866 Train_Acc: 97.563 Val_Loss: 0.0429  BEST VAL Loss: 0.0429  Val_Acc: 98.708

Epoch 5: Validation loss decreased (0.042932 --> 0.041213).  Saving model ...
	 Train_Loss: 0.0819 Train_Acc: 97.584 Val_Loss: 0.0412  BEST VAL Loss: 0.0412  Val_Acc: 98.829

Epoch 6: Validation loss decreased (0.041213 --> 0.040004).  Saving model ...
	 Train_Loss: 0.0780 Train_Acc: 97.814 Val_Loss: 0.0400  BEST VAL Loss: 0.0400  Val_Acc: 98.824

Epoch 7: Validation loss decreased (0.040004 --> 0.038867).  Saving model ...
	 Train_Loss: 0.0747 Train_Acc: 97.801 Val_Loss: 0.0389  BEST VAL Loss: 0.0389  Val_Acc: 98.913

Epoch 8: Validation loss decreased (0.038867 --> 0.038272).  Saving model ...
	 Train_Loss: 0.0720 Train_Acc: 97.898 Val_Loss: 0.0383  BEST VAL Loss: 0.0383  Val_Acc: 98.845

Epoch 9: Validation loss decreased (0.038272 --> 0.037241).  Saving model ...
	 Train_Loss: 0.0697 Train_Acc: 97.909 Val_Loss: 0.0372  BEST VAL Loss: 0.0372  Val_Acc: 99.008

Epoch 10: Validation loss decreased (0.037241 --> 0.036528).  Saving model ...
	 Train_Loss: 0.0677 Train_Acc: 97.968 Val_Loss: 0.0365  BEST VAL Loss: 0.0365  Val_Acc: 98.813

Epoch 11: Validation loss decreased (0.036528 --> 0.035829).  Saving model ...
	 Train_Loss: 0.0660 Train_Acc: 98.003 Val_Loss: 0.0358  BEST VAL Loss: 0.0358  Val_Acc: 98.876

Epoch 12: Validation loss decreased (0.035829 --> 0.035216).  Saving model ...
	 Train_Loss: 0.0645 Train_Acc: 97.999 Val_Loss: 0.0352  BEST VAL Loss: 0.0352  Val_Acc: 98.950

Epoch 13: Validation loss decreased (0.035216 --> 0.034563).  Saving model ...
	 Train_Loss: 0.0631 Train_Acc: 98.136 Val_Loss: 0.0346  BEST VAL Loss: 0.0346  Val_Acc: 99.060

Epoch 14: Validation loss decreased (0.034563 --> 0.034001).  Saving model ...
	 Train_Loss: 0.0618 Train_Acc: 98.112 Val_Loss: 0.0340  BEST VAL Loss: 0.0340  Val_Acc: 99.018

Epoch 15: Validation loss decreased (0.034001 --> 0.033599).  Saving model ...
	 Train_Loss: 0.0608 Train_Acc: 98.020 Val_Loss: 0.0336  BEST VAL Loss: 0.0336  Val_Acc: 98.923

Epoch 16: Validation loss decreased (0.033599 --> 0.033374).  Saving model ...
	 Train_Loss: 0.0598 Train_Acc: 98.132 Val_Loss: 0.0334  BEST VAL Loss: 0.0334  Val_Acc: 98.918

Epoch 17: Validation loss decreased (0.033374 --> 0.032866).  Saving model ...
	 Train_Loss: 0.0589 Train_Acc: 98.167 Val_Loss: 0.0329  BEST VAL Loss: 0.0329  Val_Acc: 99.060

Epoch 18: Validation loss decreased (0.032866 --> 0.032415).  Saving model ...
	 Train_Loss: 0.0579 Train_Acc: 98.240 Val_Loss: 0.0324  BEST VAL Loss: 0.0324  Val_Acc: 99.055

Epoch 19: Validation loss decreased (0.032415 --> 0.032105).  Saving model ...
	 Train_Loss: 0.0571 Train_Acc: 98.222 Val_Loss: 0.0321  BEST VAL Loss: 0.0321  Val_Acc: 98.976

Epoch 20: Validation loss decreased (0.032105 --> 0.031979).  Saving model ...
	 Train_Loss: 0.0563 Train_Acc: 98.215 Val_Loss: 0.0320  BEST VAL Loss: 0.0320  Val_Acc: 98.944

Epoch 21: Validation loss decreased (0.031979 --> 0.031707).  Saving model ...
	 Train_Loss: 0.0556 Train_Acc: 98.272 Val_Loss: 0.0317  BEST VAL Loss: 0.0317  Val_Acc: 99.071

Epoch 22: Validation loss decreased (0.031707 --> 0.031520).  Saving model ...
	 Train_Loss: 0.0549 Train_Acc: 98.299 Val_Loss: 0.0315  BEST VAL Loss: 0.0315  Val_Acc: 99.034

Epoch 23: Validation loss decreased (0.031520 --> 0.031197).  Saving model ...
	 Train_Loss: 0.0542 Train_Acc: 98.323 Val_Loss: 0.0312  BEST VAL Loss: 0.0312  Val_Acc: 99.092

Epoch 24: Validation loss decreased (0.031197 --> 0.031004).  Saving model ...
	 Train_Loss: 0.0536 Train_Acc: 98.290 Val_Loss: 0.0310  BEST VAL Loss: 0.0310  Val_Acc: 98.976

Epoch 25: Validation loss decreased (0.031004 --> 0.030797).  Saving model ...
	 Train_Loss: 0.0530 Train_Acc: 98.339 Val_Loss: 0.0308  BEST VAL Loss: 0.0308  Val_Acc: 99.139

Epoch 26: Validation loss decreased (0.030797 --> 0.030659).  Saving model ...
	 Train_Loss: 0.0525 Train_Acc: 98.335 Val_Loss: 0.0307  BEST VAL Loss: 0.0307  Val_Acc: 99.081

Epoch 27: Validation loss did not decrease
	 Train_Loss: 0.0520 Train_Acc: 98.363 Val_Loss: 0.0307  BEST VAL Loss: 0.0307  Val_Acc: 98.797

Epoch 28: Validation loss decreased (0.030659 --> 0.030479).  Saving model ...
	 Train_Loss: 0.0515 Train_Acc: 98.386 Val_Loss: 0.0305  BEST VAL Loss: 0.0305  Val_Acc: 99.107

Epoch 29: Validation loss decreased (0.030479 --> 0.030251).  Saving model ...
	 Train_Loss: 0.0510 Train_Acc: 98.398 Val_Loss: 0.0303  BEST VAL Loss: 0.0303  Val_Acc: 99.155

Epoch 30: Validation loss decreased (0.030251 --> 0.030161).  Saving model ...
	 Train_Loss: 0.0505 Train_Acc: 98.428 Val_Loss: 0.0302  BEST VAL Loss: 0.0302  Val_Acc: 99.060

Epoch 31: Validation loss decreased (0.030161 --> 0.030006).  Saving model ...
	 Train_Loss: 0.0500 Train_Acc: 98.430 Val_Loss: 0.0300  BEST VAL Loss: 0.0300  Val_Acc: 99.071

Epoch 32: Validation loss decreased (0.030006 --> 0.029845).  Saving model ...
	 Train_Loss: 0.0496 Train_Acc: 98.430 Val_Loss: 0.0298  BEST VAL Loss: 0.0298  Val_Acc: 99.123

Epoch 33: Validation loss decreased (0.029845 --> 0.029774).  Saving model ...
	 Train_Loss: 0.0492 Train_Acc: 98.436 Val_Loss: 0.0298  BEST VAL Loss: 0.0298  Val_Acc: 99.076

Epoch 34: Validation loss decreased (0.029774 --> 0.029708).  Saving model ...
	 Train_Loss: 0.0489 Train_Acc: 98.419 Val_Loss: 0.0297  BEST VAL Loss: 0.0297  Val_Acc: 99.076

Epoch 35: Validation loss decreased (0.029708 --> 0.029612).  Saving model ...
	 Train_Loss: 0.0485 Train_Acc: 98.413 Val_Loss: 0.0296  BEST VAL Loss: 0.0296  Val_Acc: 99.134

Epoch 36: Validation loss decreased (0.029612 --> 0.029421).  Saving model ...
	 Train_Loss: 0.0482 Train_Acc: 98.435 Val_Loss: 0.0294  BEST VAL Loss: 0.0294  Val_Acc: 99.149

Epoch 37: Validation loss decreased (0.029421 --> 0.029331).  Saving model ...
	 Train_Loss: 0.0479 Train_Acc: 98.492 Val_Loss: 0.0293  BEST VAL Loss: 0.0293  Val_Acc: 99.050

Epoch 38: Validation loss decreased (0.029331 --> 0.029160).  Saving model ...
	 Train_Loss: 0.0475 Train_Acc: 98.499 Val_Loss: 0.0292  BEST VAL Loss: 0.0292  Val_Acc: 99.223

Epoch 39: Validation loss decreased (0.029160 --> 0.029141).  Saving model ...
	 Train_Loss: 0.0472 Train_Acc: 98.467 Val_Loss: 0.0291  BEST VAL Loss: 0.0291  Val_Acc: 99.113

Epoch 40: Validation loss decreased (0.029141 --> 0.029037).  Saving model ...
	 Train_Loss: 0.0469 Train_Acc: 98.496 Val_Loss: 0.0290  BEST VAL Loss: 0.0290  Val_Acc: 99.113

Epoch 41: Validation loss decreased (0.029037 --> 0.028992).  Saving model ...
	 Train_Loss: 0.0466 Train_Acc: 98.474 Val_Loss: 0.0290  BEST VAL Loss: 0.0290  Val_Acc: 99.113

Epoch 42: Validation loss did not decrease
	 Train_Loss: 0.0463 Train_Acc: 98.526 Val_Loss: 0.0290  BEST VAL Loss: 0.0290  Val_Acc: 99.123

Epoch 43: Validation loss decreased (0.028992 --> 0.028938).  Saving model ...
	 Train_Loss: 0.0461 Train_Acc: 98.502 Val_Loss: 0.0289  BEST VAL Loss: 0.0289  Val_Acc: 99.165

Epoch 44: Validation loss decreased (0.028938 --> 0.028861).  Saving model ...
	 Train_Loss: 0.0458 Train_Acc: 98.540 Val_Loss: 0.0289  BEST VAL Loss: 0.0289  Val_Acc: 99.139

Epoch 45: Validation loss decreased (0.028861 --> 0.028770).  Saving model ...
	 Train_Loss: 0.0456 Train_Acc: 98.505 Val_Loss: 0.0288  BEST VAL Loss: 0.0288  Val_Acc: 99.065

Epoch 46: Validation loss decreased (0.028770 --> 0.028728).  Saving model ...
	 Train_Loss: 0.0454 Train_Acc: 98.505 Val_Loss: 0.0287  BEST VAL Loss: 0.0287  Val_Acc: 99.160

Epoch 47: Validation loss decreased (0.028728 --> 0.028723).  Saving model ...
	 Train_Loss: 0.0451 Train_Acc: 98.615 Val_Loss: 0.0287  BEST VAL Loss: 0.0287  Val_Acc: 99.055

Epoch 48: Validation loss did not decrease
	 Train_Loss: 0.0448 Train_Acc: 98.557 Val_Loss: 0.0288  BEST VAL Loss: 0.0287  Val_Acc: 99.023

Epoch 49: Validation loss decreased (0.028723 --> 0.028715).  Saving model ...
	 Train_Loss: 0.0446 Train_Acc: 98.626 Val_Loss: 0.0287  BEST VAL Loss: 0.0287  Val_Acc: 99.128

Epoch 50: Validation loss decreased (0.028715 --> 0.028694).  Saving model ...
	 Train_Loss: 0.0443 Train_Acc: 98.560 Val_Loss: 0.0287  BEST VAL Loss: 0.0287  Val_Acc: 99.149

Epoch 51: Validation loss did not decrease
	 Train_Loss: 0.0441 Train_Acc: 98.612 Val_Loss: 0.0287  BEST VAL Loss: 0.0287  Val_Acc: 99.202

Epoch 52: Validation loss did not decrease
	 Train_Loss: 0.0439 Train_Acc: 98.580 Val_Loss: 0.0287  BEST VAL Loss: 0.0287  Val_Acc: 99.207

Epoch 53: Validation loss did not decrease
	 Train_Loss: 0.0437 Train_Acc: 98.564 Val_Loss: 0.0287  BEST VAL Loss: 0.0287  Val_Acc: 99.044

Epoch 54: Validation loss decreased (0.028694 --> 0.028685).  Saving model ...
	 Train_Loss: 0.0435 Train_Acc: 98.603 Val_Loss: 0.0287  BEST VAL Loss: 0.0287  Val_Acc: 99.128

Epoch 55: Validation loss decreased (0.028685 --> 0.028631).  Saving model ...
	 Train_Loss: 0.0433 Train_Acc: 98.637 Val_Loss: 0.0286  BEST VAL Loss: 0.0286  Val_Acc: 99.170

Epoch 56: Validation loss did not decrease
	 Train_Loss: 0.0431 Train_Acc: 98.622 Val_Loss: 0.0286  BEST VAL Loss: 0.0286  Val_Acc: 99.097

Epoch 57: Validation loss decreased (0.028631 --> 0.028568).  Saving model ...
	 Train_Loss: 0.0429 Train_Acc: 98.611 Val_Loss: 0.0286  BEST VAL Loss: 0.0286  Val_Acc: 99.181

Epoch 58: Validation loss decreased (0.028568 --> 0.028495).  Saving model ...
	 Train_Loss: 0.0427 Train_Acc: 98.620 Val_Loss: 0.0285  BEST VAL Loss: 0.0285  Val_Acc: 99.202

Epoch 59: Validation loss decreased (0.028495 --> 0.028444).  Saving model ...
	 Train_Loss: 0.0425 Train_Acc: 98.635 Val_Loss: 0.0284  BEST VAL Loss: 0.0284  Val_Acc: 99.197

Epoch 60: Validation loss decreased (0.028444 --> 0.028415).  Saving model ...
	 Train_Loss: 0.0423 Train_Acc: 98.637 Val_Loss: 0.0284  BEST VAL Loss: 0.0284  Val_Acc: 99.181

Epoch 61: Validation loss decreased (0.028415 --> 0.028372).  Saving model ...
	 Train_Loss: 0.0421 Train_Acc: 98.651 Val_Loss: 0.0284  BEST VAL Loss: 0.0284  Val_Acc: 99.202

Epoch 62: Validation loss decreased (0.028372 --> 0.028341).  Saving model ...
	 Train_Loss: 0.0420 Train_Acc: 98.603 Val_Loss: 0.0283  BEST VAL Loss: 0.0283  Val_Acc: 99.092

Epoch 63: Validation loss decreased (0.028341 --> 0.028310).  Saving model ...
	 Train_Loss: 0.0418 Train_Acc: 98.641 Val_Loss: 0.0283  BEST VAL Loss: 0.0283  Val_Acc: 99.202

Epoch 64: Validation loss decreased (0.028310 --> 0.028270).  Saving model ...
	 Train_Loss: 0.0416 Train_Acc: 98.685 Val_Loss: 0.0283  BEST VAL Loss: 0.0283  Val_Acc: 99.186

Epoch 65: Validation loss did not decrease
	 Train_Loss: 0.0415 Train_Acc: 98.610 Val_Loss: 0.0283  BEST VAL Loss: 0.0283  Val_Acc: 99.086

Epoch 66: Validation loss decreased (0.028270 --> 0.028241).  Saving model ...
	 Train_Loss: 0.0413 Train_Acc: 98.643 Val_Loss: 0.0282  BEST VAL Loss: 0.0282  Val_Acc: 99.191

Epoch 67: Validation loss did not decrease
	 Train_Loss: 0.0411 Train_Acc: 98.702 Val_Loss: 0.0283  BEST VAL Loss: 0.0282  Val_Acc: 99.065

Epoch 68: Validation loss decreased (0.028241 --> 0.028200).  Saving model ...
	 Train_Loss: 0.0410 Train_Acc: 98.594 Val_Loss: 0.0282  BEST VAL Loss: 0.0282  Val_Acc: 99.207

Epoch 69: Validation loss decreased (0.028200 --> 0.028180).  Saving model ...
	 Train_Loss: 0.0409 Train_Acc: 98.691 Val_Loss: 0.0282  BEST VAL Loss: 0.0282  Val_Acc: 99.155

Epoch 70: Validation loss decreased (0.028180 --> 0.028170).  Saving model ...
	 Train_Loss: 0.0407 Train_Acc: 98.688 Val_Loss: 0.0282  BEST VAL Loss: 0.0282  Val_Acc: 99.123

Epoch 71: Validation loss decreased (0.028170 --> 0.028151).  Saving model ...
	 Train_Loss: 0.0406 Train_Acc: 98.659 Val_Loss: 0.0282  BEST VAL Loss: 0.0282  Val_Acc: 99.139

Epoch 72: Validation loss decreased (0.028151 --> 0.028125).  Saving model ...
	 Train_Loss: 0.0404 Train_Acc: 98.697 Val_Loss: 0.0281  BEST VAL Loss: 0.0281  Val_Acc: 99.160

Epoch 73: Validation loss decreased (0.028125 --> 0.028052).  Saving model ...
	 Train_Loss: 0.0403 Train_Acc: 98.663 Val_Loss: 0.0281  BEST VAL Loss: 0.0281  Val_Acc: 99.275

Epoch 74: Validation loss decreased (0.028052 --> 0.028031).  Saving model ...
	 Train_Loss: 0.0401 Train_Acc: 98.723 Val_Loss: 0.0280  BEST VAL Loss: 0.0280  Val_Acc: 99.128

Epoch 75: Validation loss did not decrease
	 Train_Loss: 0.0400 Train_Acc: 98.746 Val_Loss: 0.0280  BEST VAL Loss: 0.0280  Val_Acc: 99.170

Epoch 76: Validation loss did not decrease
	 Train_Loss: 0.0398 Train_Acc: 98.698 Val_Loss: 0.0280  BEST VAL Loss: 0.0280  Val_Acc: 99.176

Epoch 77: Validation loss decreased (0.028031 --> 0.028009).  Saving model ...
	 Train_Loss: 0.0397 Train_Acc: 98.661 Val_Loss: 0.0280  BEST VAL Loss: 0.0280  Val_Acc: 99.228

Epoch 78: Validation loss decreased (0.028009 --> 0.027994).  Saving model ...
	 Train_Loss: 0.0396 Train_Acc: 98.656 Val_Loss: 0.0280  BEST VAL Loss: 0.0280  Val_Acc: 99.113

Epoch 79: Validation loss decreased (0.027994 --> 0.027969).  Saving model ...
	 Train_Loss: 0.0395 Train_Acc: 98.662 Val_Loss: 0.0280  BEST VAL Loss: 0.0280  Val_Acc: 99.228

Epoch 80: Validation loss did not decrease
	 Train_Loss: 0.0394 Train_Acc: 98.704 Val_Loss: 0.0280  BEST VAL Loss: 0.0280  Val_Acc: 99.160

Epoch 81: Validation loss did not decrease
	 Train_Loss: 0.0393 Train_Acc: 98.681 Val_Loss: 0.0280  BEST VAL Loss: 0.0280  Val_Acc: 99.144

Epoch 82: Validation loss did not decrease
	 Train_Loss: 0.0391 Train_Acc: 98.717 Val_Loss: 0.0280  BEST VAL Loss: 0.0280  Val_Acc: 99.181

Epoch 83: Validation loss did not decrease
	 Train_Loss: 0.0390 Train_Acc: 98.721 Val_Loss: 0.0280  BEST VAL Loss: 0.0280  Val_Acc: 99.191

Epoch 84: Validation loss did not decrease
	 Train_Loss: 0.0389 Train_Acc: 98.741 Val_Loss: 0.0280  BEST VAL Loss: 0.0280  Val_Acc: 99.176

Epoch 85: Validation loss did not decrease
	 Train_Loss: 0.0388 Train_Acc: 98.760 Val_Loss: 0.0280  BEST VAL Loss: 0.0280  Val_Acc: 99.207

Epoch 86: Validation loss did not decrease
	 Train_Loss: 0.0387 Train_Acc: 98.794 Val_Loss: 0.0280  BEST VAL Loss: 0.0280  Val_Acc: 99.113

Epoch 87: Validation loss did not decrease
	 Train_Loss: 0.0385 Train_Acc: 98.816 Val_Loss: 0.0281  BEST VAL Loss: 0.0280  Val_Acc: 99.134

Epoch 88: Validation loss did not decrease
	 Train_Loss: 0.0384 Train_Acc: 98.772 Val_Loss: 0.0281  BEST VAL Loss: 0.0280  Val_Acc: 99.207

Epoch 89: Validation loss did not decrease
	 Train_Loss: 0.0383 Train_Acc: 98.753 Val_Loss: 0.0281  BEST VAL Loss: 0.0280  Val_Acc: 99.086

Epoch 90: Validation loss did not decrease
	 Train_Loss: 0.0382 Train_Acc: 98.711 Val_Loss: 0.0282  BEST VAL Loss: 0.0280  Val_Acc: 99.181

Epoch 91: Validation loss did not decrease
	 Train_Loss: 0.0381 Train_Acc: 98.794 Val_Loss: 0.0282  BEST VAL Loss: 0.0280  Val_Acc: 99.212

Epoch 92: Validation loss did not decrease
	 Train_Loss: 0.0380 Train_Acc: 98.758 Val_Loss: 0.0282  BEST VAL Loss: 0.0280  Val_Acc: 99.139

Epoch 93: Validation loss did not decrease
	 Train_Loss: 0.0379 Train_Acc: 98.695 Val_Loss: 0.0283  BEST VAL Loss: 0.0280  Val_Acc: 99.149

Epoch 94: Validation loss did not decrease
	 Train_Loss: 0.0378 Train_Acc: 98.791 Val_Loss: 0.0283  BEST VAL Loss: 0.0280  Val_Acc: 99.181

Epoch 95: Validation loss did not decrease
Early stopped at epoch : 95
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       1.00      0.99      0.99     50422
           1       1.00      1.00      1.00    101922

    accuracy                           1.00    152344
   macro avg       1.00      0.99      1.00    152344
weighted avg       1.00      1.00      1.00    152344

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      0.99      0.99      6303
           1       0.99      1.00      0.99     12740

    accuracy                           0.99     19043
   macro avg       0.99      0.99      0.99     19043
weighted avg       0.99      0.99      0.99     19043

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.99      0.98      0.99      6303
           1       0.99      1.00      0.99     12740

    accuracy                           0.99     19043
   macro avg       0.99      0.99      0.99     19043
weighted avg       0.99      0.99      0.99     19043

              precision    recall  f1-score   support

           0       0.99      0.98      0.99      6303
           1       0.99      1.00      0.99     12740

    accuracy                           0.99     19043
   macro avg       0.99      0.99      0.99     19043
weighted avg       0.99      0.99      0.99     19043

LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
../../trained_models/model_save_states/Binary_Classification/PBMC
LPS_Nigericin_1.000_3.0_DMSO_0.025_vs_Flagellin_0.100_DMSO_0.025
              precision    recall  f1-score   support

           0       0.82      0.98      0.89     32887
           1       0.98      0.85      0.91     46859

    accuracy                           0.90     79746
   macro avg       0.90      0.92      0.90     79746
weighted avg       0.92      0.90      0.91     79746

              precision    recall  f1-score   support

           0       0.82      0.98      0.89     32887
           1       0.98      0.85      0.91     46859

    accuracy                           0.90     79746
   macro avg       0.90      0.92      0.90     79746
weighted avg       0.92      0.90      0.91     79746

completed
