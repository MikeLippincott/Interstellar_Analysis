[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: PBMC control_name: Thapsigargin_10.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_3.0_DMSO_0.025
[I 2023-09-19 01:00:46,643] A new study created in memory with name: no-name-77776afa-4b56-46e8-991f-cf0148ac3942
[I 2023-09-19 01:02:35,191] Trial 0 finished with value: 0.07818450284405397 and parameters: {'n_layers': 1, 'n_units_l0': 4, 'dropout_0': 0.2478377747913594, 'learning_rate': 0.06851754549961286, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.07818450284405397.
[I 2023-09-19 01:04:26,518] Trial 1 finished with value: 0.08772996112990837 and parameters: {'n_layers': 3, 'n_units_l0': 5, 'dropout_0': 0.27372050163334444, 'n_units_l1': 2, 'dropout_1': 0.3139917428786754, 'n_units_l2': 9, 'dropout_2': 0.39868815155365434, 'learning_rate': 0.018715585928694375, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.07818450284405397.
[I 2023-09-19 01:06:17,985] Trial 2 finished with value: 0.21672604426741596 and parameters: {'n_layers': 2, 'n_units_l0': 2, 'dropout_0': 0.2577656840781446, 'n_units_l1': 10, 'dropout_1': 0.12945220282598266, 'learning_rate': 0.08117718431193756, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.07818450284405397.
[I 2023-09-19 01:08:06,945] Trial 3 finished with value: 0.14472763371295655 and parameters: {'n_layers': 1, 'n_units_l0': 4, 'dropout_0': 0.34412894990195053, 'learning_rate': 0.05786778526524239, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.07818450284405397.
[I 2023-09-19 01:09:56,295] Trial 4 finished with value: 0.08435950966408619 and parameters: {'n_layers': 1, 'n_units_l0': 3, 'dropout_0': 0.33875686921720505, 'learning_rate': 0.004004996923548581, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.07818450284405397.
[I 2023-09-19 01:11:52,191] Trial 5 finished with value: 0.07990792410878035 and parameters: {'n_layers': 3, 'n_units_l0': 7, 'dropout_0': 0.3766402296810829, 'n_units_l1': 9, 'dropout_1': 0.11338608191612659, 'n_units_l2': 4, 'dropout_2': 0.20852224389468363, 'learning_rate': 0.003992186942868372, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.07818450284405397.
[I 2023-09-19 01:12:11,760] Trial 6 pruned.
[I 2023-09-19 01:12:13,842] Trial 7 pruned.
[I 2023-09-19 01:12:16,153] Trial 8 pruned.
[I 2023-09-19 01:12:18,420] Trial 9 pruned.
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (341245, 1270)
Number of total missing values across all columns: 333968
Data Subset Is Off
Wells held out for testing: ['L06' 'L09']
Wells to use for training, validation, and testing ['E06' 'E07' 'L02' 'L03' 'L07' 'L08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 97.26375623525772
Validation Loss: 0.07767852453658214
Training Accuracy: 93.96634812913581
Training Loss: 0.12314624597700899
completed
