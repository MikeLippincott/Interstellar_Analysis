[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 treatment_name: Thapsigargin_1.000_DMSO_0.025
[I 2023-09-19 01:29:28,088] A new study created in memory with name: no-name-8ec19d64-3279-46b0-a540-a3dbe6412156
[I 2023-09-19 01:29:38,005] Trial 0 finished with value: 0.1571237180630366 and parameters: {'n_layers': 3, 'n_units_l0': 5, 'dropout_0': 0.34107075059097447, 'n_units_l1': 5, 'dropout_1': 0.1781457012658973, 'n_units_l2': 2, 'dropout_2': 0.3627798745879315, 'learning_rate': 0.01143926906747788, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.1571237180630366.
[I 2023-09-19 01:29:47,313] Trial 1 finished with value: 0.22202102462450665 and parameters: {'n_layers': 2, 'n_units_l0': 2, 'dropout_0': 0.34781302880543763, 'n_units_l1': 7, 'dropout_1': 0.3049000277305013, 'learning_rate': 0.060074749562308266, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.1571237180630366.
[I 2023-09-19 01:29:56,630] Trial 2 finished with value: 0.20886406814058625 and parameters: {'n_layers': 2, 'n_units_l0': 3, 'dropout_0': 0.20512983371054835, 'n_units_l1': 7, 'dropout_1': 0.2358327973268967, 'learning_rate': 0.05652469521645495, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.1571237180630366.
[I 2023-09-19 01:30:06,085] Trial 3 finished with value: 0.2599739489952723 and parameters: {'n_layers': 3, 'n_units_l0': 2, 'dropout_0': 0.21558910360328182, 'n_units_l1': 4, 'dropout_1': 0.3881046769174702, 'n_units_l2': 8, 'dropout_2': 0.3590584393357631, 'learning_rate': 0.037767162275661854, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.1571237180630366.
[I 2023-09-19 01:30:15,242] Trial 4 finished with value: 0.6193851137161254 and parameters: {'n_layers': 2, 'n_units_l0': 5, 'dropout_0': 0.23030081565688715, 'n_units_l1': 2, 'dropout_1': 0.1275528098369975, 'learning_rate': 0.010023267226508223, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.1571237180630366.
[I 2023-09-19 01:30:24,664] Trial 5 finished with value: 0.20849725415309275 and parameters: {'n_layers': 3, 'n_units_l0': 5, 'dropout_0': 0.3599886613870035, 'n_units_l1': 4, 'dropout_1': 0.17426802427253169, 'n_units_l2': 2, 'dropout_2': 0.16637351043791754, 'learning_rate': 0.04036153784508659, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.1571237180630366.
[I 2023-09-19 01:30:33,749] Trial 6 finished with value: 0.13981788287560146 and parameters: {'n_layers': 1, 'n_units_l0': 2, 'dropout_0': 0.3522248349041168, 'learning_rate': 0.06994426887958972, 'optimizer': 'SGD'}. Best is trial 6 with value: 0.13981788287560146.
[I 2023-09-19 01:30:43,149] Trial 7 finished with value: 0.09909023868540923 and parameters: {'n_layers': 1, 'n_units_l0': 10, 'dropout_0': 0.18311525976666249, 'learning_rate': 0.021054311995486064, 'optimizer': 'Adam'}. Best is trial 7 with value: 0.09909023868540923.
[I 2023-09-19 01:30:43,315] Trial 8 pruned.
[I 2023-09-19 01:30:52,456] Trial 9 finished with value: 0.11958017985026041 and parameters: {'n_layers': 1, 'n_units_l0': 3, 'dropout_0': 0.3257684088696994, 'learning_rate': 0.04548418655228017, 'optimizer': 'RMSprop'}. Best is trial 7 with value: 0.09909023868540923.
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (29984, 1276)
Number of total missing values across all columns: 27532
Data Subset Is Off
Wells held out for testing: ['D14' 'K20']
Wells to use for training, validation, and testing ['D15' 'K14' 'K15' 'K16' 'K17' 'K21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 96.69898633759365
Validation Loss: 0.10513101115822793
Training Accuracy: 98.21303796770815
Training Loss: 0.042936767011353946
completed
