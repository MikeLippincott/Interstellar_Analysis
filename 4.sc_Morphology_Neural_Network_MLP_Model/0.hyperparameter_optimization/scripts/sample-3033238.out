[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: PBMC control_name: Thapsigargin_1.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_10.0_DMSO_0.025
[I 2023-09-19 01:05:26,941] A new study created in memory with name: no-name-e0d869fd-543f-4517-bfc3-11e4f36889d6
[I 2023-09-19 01:06:53,813] Trial 0 finished with value: 0.19370195165872572 and parameters: {'n_layers': 2, 'n_units_l0': 3, 'dropout_0': 0.2161937769417039, 'n_units_l1': 5, 'dropout_1': 0.20527231922304792, 'learning_rate': 0.017463697340753124, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.19370195165872572.
[I 2023-09-19 01:08:22,844] Trial 1 finished with value: 0.15705123361349105 and parameters: {'n_layers': 3, 'n_units_l0': 8, 'dropout_0': 0.22451546830784397, 'n_units_l1': 2, 'dropout_1': 0.18827177091552083, 'n_units_l2': 10, 'dropout_2': 0.37423375910654466, 'learning_rate': 0.05143490983545215, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.15705123361349105.
[I 2023-09-19 01:09:54,643] Trial 2 finished with value: 0.16506697204113008 and parameters: {'n_layers': 3, 'n_units_l0': 3, 'dropout_0': 0.3010825596821196, 'n_units_l1': 9, 'dropout_1': 0.23720490585235, 'n_units_l2': 6, 'dropout_2': 0.35051561357186733, 'learning_rate': 0.0010246509708000267, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.15705123361349105.
[I 2023-09-19 01:11:24,546] Trial 3 finished with value: 0.6931320681571961 and parameters: {'n_layers': 3, 'n_units_l0': 2, 'dropout_0': 0.3566257648920027, 'n_units_l1': 6, 'dropout_1': 0.3361277884735815, 'n_units_l2': 7, 'dropout_2': 0.20044760582423574, 'learning_rate': 0.09806888243587156, 'optimizer': 'RMSprop'}. Best is trial 1 with value: 0.15705123361349105.
[I 2023-09-19 01:12:54,850] Trial 4 finished with value: 0.38405198959112163 and parameters: {'n_layers': 2, 'n_units_l0': 7, 'dropout_0': 0.3865253861954052, 'n_units_l1': 5, 'dropout_1': 0.11208183261216886, 'learning_rate': 0.09474265029809073, 'optimizer': 'RMSprop'}. Best is trial 1 with value: 0.15705123361349105.
[I 2023-09-19 01:13:15,678] Trial 5 pruned.
[I 2023-09-19 01:14:44,259] Trial 6 finished with value: 0.12290159338116645 and parameters: {'n_layers': 1, 'n_units_l0': 7, 'dropout_0': 0.13465800212667367, 'learning_rate': 0.04288742230903006, 'optimizer': 'Adam'}. Best is trial 6 with value: 0.12290159338116645.
[I 2023-09-19 01:16:11,405] Trial 7 finished with value: 0.1462432338178158 and parameters: {'n_layers': 1, 'n_units_l0': 10, 'dropout_0': 0.2515860947247669, 'learning_rate': 0.022510717466665695, 'optimizer': 'SGD'}. Best is trial 6 with value: 0.12290159338116645.
[I 2023-09-19 01:16:25,124] Trial 8 pruned.
[I 2023-09-19 01:17:53,883] Trial 9 finished with value: 0.1282890242636204 and parameters: {'n_layers': 2, 'n_units_l0': 9, 'dropout_0': 0.28717628615802593, 'n_units_l1': 6, 'dropout_1': 0.26004922425838645, 'learning_rate': 0.026599122937275104, 'optimizer': 'RMSprop'}. Best is trial 6 with value: 0.12290159338116645.
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (329622, 1270)
Number of total missing values across all columns: 296912
Data Subset Is Off
Wells held out for testing: ['K06' 'M09']
Wells to use for training, validation, and testing ['D06' 'D07' 'K07' 'M02' 'M03' 'M08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 95.78227408142999
Validation Loss: 0.11964640489220621
Training Accuracy: 95.33952622323369
Training Loss: 0.1237086395934685
completed
