[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: SHSY5Y control_name: Thapsigargin_10.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_1.0_DMSO_0.025
[I 2023-09-19 00:53:39,254] A new study created in memory with name: no-name-b259ff42-a04a-4019-9600-4ddf4ff01d1f
[I 2023-09-19 00:53:46,725] Trial 0 finished with value: 0.12661245991786324 and parameters: {'n_layers': 1, 'n_units_l0': 5, 'dropout_0': 0.24249434888516389, 'learning_rate': 0.055854411019489715, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.12661245991786324.
[I 2023-09-19 00:53:54,319] Trial 1 finished with value: 0.11578644228478271 and parameters: {'n_layers': 2, 'n_units_l0': 5, 'dropout_0': 0.35212397098524273, 'n_units_l1': 8, 'dropout_1': 0.17255198993478116, 'learning_rate': 0.010744848909032085, 'optimizer': 'RMSprop'}. Best is trial 1 with value: 0.11578644228478271.
[I 2023-09-19 00:54:01,871] Trial 2 finished with value: 0.10949724738796553 and parameters: {'n_layers': 1, 'n_units_l0': 10, 'dropout_0': 0.3248368109721289, 'learning_rate': 0.0703103798029414, 'optimizer': 'SGD'}. Best is trial 2 with value: 0.10949724738796553.
[I 2023-09-19 00:54:09,243] Trial 3 finished with value: 0.2080007492005825 and parameters: {'n_layers': 1, 'n_units_l0': 4, 'dropout_0': 0.1333394154486121, 'learning_rate': 0.011238775910589027, 'optimizer': 'SGD'}. Best is trial 2 with value: 0.10949724738796553.
[I 2023-09-19 00:54:16,968] Trial 4 finished with value: 0.0982515403876702 and parameters: {'n_layers': 2, 'n_units_l0': 3, 'dropout_0': 0.3863721444363447, 'n_units_l1': 5, 'dropout_1': 0.15952021101899053, 'learning_rate': 0.030793903617566072, 'optimizer': 'Adam'}. Best is trial 4 with value: 0.0982515403876702.
[I 2023-09-19 00:54:17,103] Trial 5 pruned.
[I 2023-09-19 00:54:17,328] Trial 6 pruned.
[I 2023-09-19 00:54:17,465] Trial 7 pruned.
[I 2023-09-19 00:54:17,613] Trial 8 pruned.
[I 2023-09-19 00:54:25,474] Trial 9 finished with value: 0.09758909439047178 and parameters: {'n_layers': 2, 'n_units_l0': 7, 'dropout_0': 0.3563378900614079, 'n_units_l1': 2, 'dropout_1': 0.12424199794175744, 'learning_rate': 0.07120656438993128, 'optimizer': 'Adam'}. Best is trial 9 with value: 0.09758909439047178.
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (29430, 1276)
Number of total missing values across all columns: 26424
Data Subset Is Off
Wells held out for testing: ['E14' 'K20']
Wells to use for training, validation, and testing ['E15' 'L14' 'L15' 'K16' 'K17' 'K21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 96.74682395644284
Validation Loss: 0.09730258668462437
Training Accuracy: 89.99149081007488
Training Loss: 0.1703844696117772
completed
