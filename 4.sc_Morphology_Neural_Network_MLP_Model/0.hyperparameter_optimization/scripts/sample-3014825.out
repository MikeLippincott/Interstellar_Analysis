[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: PBMC control_name: Thapsigargin_1.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_3.0_DMSO_0.025
[I 2023-09-17 20:05:00,299] A new study created in memory with name: no-name-302ea35e-9cb5-42a1-a903-a63ad8241ecf
[I 2023-09-17 20:06:26,098] Trial 0 finished with value: 0.1648101510465145 and parameters: {'n_layers': 2, 'n_units_l0': 3, 'dropout_0': 0.1032588795596253, 'n_units_l1': 2, 'dropout_1': 0.2933854428472683, 'learning_rate': 0.04204185155443155, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.1648101510465145.
[I 2023-09-17 20:07:55,632] Trial 1 finished with value: 0.6657843594551087 and parameters: {'n_layers': 3, 'n_units_l0': 7, 'dropout_0': 0.3740754894234418, 'n_units_l1': 3, 'dropout_1': 0.23462408200486787, 'n_units_l2': 8, 'dropout_2': 0.3610273538656904, 'learning_rate': 0.06154192450203716, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.1648101510465145.
[I 2023-09-17 20:09:21,519] Trial 2 finished with value: 0.17841337913274763 and parameters: {'n_layers': 1, 'n_units_l0': 7, 'dropout_0': 0.3474555377324693, 'learning_rate': 0.07830746204295781, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.1648101510465145.
[I 2023-09-17 20:10:46,933] Trial 3 finished with value: 0.20112451298236844 and parameters: {'n_layers': 2, 'n_units_l0': 5, 'dropout_0': 0.2932807584915948, 'n_units_l1': 6, 'dropout_1': 0.12021295120467451, 'learning_rate': 0.08151064763014969, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.1648101510465145.
[I 2023-09-17 20:12:14,274] Trial 4 finished with value: 0.4160823703050614 and parameters: {'n_layers': 2, 'n_units_l0': 7, 'dropout_0': 0.29321913339708805, 'n_units_l1': 8, 'dropout_1': 0.27335810308125813, 'learning_rate': 0.09378915821566522, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.1648101510465145.
[I 2023-09-17 20:12:15,913] Trial 5 pruned.
[I 2023-09-17 20:13:37,834] Trial 6 finished with value: 0.1192726402580738 and parameters: {'n_layers': 1, 'n_units_l0': 8, 'dropout_0': 0.139794180857554, 'learning_rate': 0.0980920563891445, 'optimizer': 'SGD'}. Best is trial 6 with value: 0.1192726402580738.
[I 2023-09-17 20:13:39,462] Trial 7 pruned.
[I 2023-09-17 20:13:41,325] Trial 8 pruned.
[I 2023-09-17 20:13:42,969] Trial 9 pruned.
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (322717, 1270)
Number of total missing values across all columns: 296912
Data Subset Is Off
Wells held out for testing: ['K06' 'L09']
Wells to use for training, validation, and testing ['D06' 'D07' 'K07' 'L02' 'L03' 'L08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 95.39657828589961
Validation Loss: 0.11849522951841354
Training Accuracy: 95.06110638125355
Training Loss: 0.12492577086268651
completed
