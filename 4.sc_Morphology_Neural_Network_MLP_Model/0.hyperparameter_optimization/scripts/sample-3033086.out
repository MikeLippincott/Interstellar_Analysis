[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: SHSY5Y control_name: LPS_0.010_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025
[I 2023-09-19 00:42:07,001] A new study created in memory with name: no-name-baa9d163-54ad-4172-a623-98af74dc5c47
[I 2023-09-19 00:42:16,170] Trial 0 finished with value: 0.6933160352706911 and parameters: {'n_layers': 3, 'n_units_l0': 2, 'dropout_0': 0.142140012929564, 'n_units_l1': 8, 'dropout_1': 0.30739103370500553, 'n_units_l2': 4, 'dropout_2': 0.26892093319515525, 'learning_rate': 0.03543069325062304, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.6933160352706911.
[I 2023-09-19 00:42:25,083] Trial 1 finished with value: 0.6318725589911144 and parameters: {'n_layers': 3, 'n_units_l0': 3, 'dropout_0': 0.3001462573348408, 'n_units_l1': 7, 'dropout_1': 0.18019822933101703, 'n_units_l2': 6, 'dropout_2': 0.3062247454336784, 'learning_rate': 0.040571155041981465, 'optimizer': 'RMSprop'}. Best is trial 1 with value: 0.6318725589911144.
[I 2023-09-19 00:42:33,483] Trial 2 finished with value: 0.6666661727428435 and parameters: {'n_layers': 1, 'n_units_l0': 2, 'dropout_0': 0.3146924353915112, 'learning_rate': 0.002304061468597155, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.6318725589911144.
[I 2023-09-19 00:42:42,287] Trial 3 finished with value: 0.6944610098997752 and parameters: {'n_layers': 3, 'n_units_l0': 3, 'dropout_0': 0.1556047681619128, 'n_units_l1': 5, 'dropout_1': 0.18116546035838033, 'n_units_l2': 5, 'dropout_2': 0.22153612722934113, 'learning_rate': 0.005330198780512951, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.6318725589911144.
[I 2023-09-19 00:42:50,933] Trial 4 finished with value: 0.566432933807373 and parameters: {'n_layers': 1, 'n_units_l0': 10, 'dropout_0': 0.22917641118523083, 'learning_rate': 0.01611004211629483, 'optimizer': 'Adam'}. Best is trial 4 with value: 0.566432933807373.
[I 2023-09-19 00:42:59,794] Trial 5 finished with value: 0.6275922175248464 and parameters: {'n_layers': 2, 'n_units_l0': 2, 'dropout_0': 0.2716017052701553, 'n_units_l1': 5, 'dropout_1': 0.31743767147861846, 'learning_rate': 0.08281070287761866, 'optimizer': 'Adam'}. Best is trial 4 with value: 0.566432933807373.
[I 2023-09-19 00:42:59,954] Trial 6 pruned.
[I 2023-09-19 00:43:08,585] Trial 7 finished with value: 0.5630649403731028 and parameters: {'n_layers': 1, 'n_units_l0': 8, 'dropout_0': 0.35715137645963424, 'learning_rate': 0.05730381995186938, 'optimizer': 'Adam'}. Best is trial 7 with value: 0.5630649403731028.
[I 2023-09-19 00:43:16,946] Trial 8 finished with value: 0.5605639410018921 and parameters: {'n_layers': 1, 'n_units_l0': 5, 'dropout_0': 0.12973662710880748, 'learning_rate': 0.01936860987608855, 'optimizer': 'RMSprop'}. Best is trial 8 with value: 0.5605639410018921.
[I 2023-09-19 00:43:25,561] Trial 9 finished with value: 0.5751031947135925 and parameters: {'n_layers': 1, 'n_units_l0': 9, 'dropout_0': 0.21653788058270051, 'learning_rate': 0.019244746093562585, 'optimizer': 'Adam'}. Best is trial 8 with value: 0.5605639410018921.
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (31668, 1276)
Number of total missing values across all columns: 63336
Data Subset Is Off
Wells held out for testing: ['B16' 'M22']
Wells to use for training, validation, and testing ['B17' 'B20' 'B21' 'M18' 'M19' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 70.5579036348267
Validation Loss: 0.5713094584147135
Training Accuracy: 74.96480287496036
Training Loss: 0.4817853535790192
completed
