[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: PBMC control_name: Thapsigargin_10.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_3.0_DMSO_0.025
[I 2023-09-17 20:03:36,933] A new study created in memory with name: no-name-871799ab-398b-44fc-be70-4b2bf6392133
[I 2023-09-17 20:06:01,648] Trial 0 finished with value: 0.060364104303029874 and parameters: {'n_layers': 1, 'n_units_l0': 10, 'dropout_0': 0.3091381281083274, 'learning_rate': 0.016381919470259812, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.060364104303029874.
[I 2023-09-17 20:08:05,594] Trial 1 finished with value: 0.08162485644221304 and parameters: {'n_layers': 3, 'n_units_l0': 4, 'dropout_0': 0.27377079639812396, 'n_units_l1': 3, 'dropout_1': 0.14143947621421307, 'n_units_l2': 8, 'dropout_2': 0.2395402500396904, 'learning_rate': 0.010955297515353773, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.060364104303029874.
[I 2023-09-17 20:10:13,905] Trial 2 finished with value: 0.11867824728099201 and parameters: {'n_layers': 2, 'n_units_l0': 7, 'dropout_0': 0.11444160944952814, 'n_units_l1': 2, 'dropout_1': 0.13352585110775805, 'learning_rate': 0.0058448409260469835, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.060364104303029874.
[I 2023-09-17 20:12:25,807] Trial 3 finished with value: 0.3164786286766713 and parameters: {'n_layers': 3, 'n_units_l0': 7, 'dropout_0': 0.38454674065139316, 'n_units_l1': 4, 'dropout_1': 0.1537002424990597, 'n_units_l2': 8, 'dropout_2': 0.27091179795770537, 'learning_rate': 0.04918979528236858, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.060364104303029874.
[I 2023-09-17 20:14:36,990] Trial 4 finished with value: 0.6571249983918208 and parameters: {'n_layers': 2, 'n_units_l0': 10, 'dropout_0': 0.2095177210519394, 'n_units_l1': 3, 'dropout_1': 0.37842513090338126, 'learning_rate': 0.07443991768977477, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.060364104303029874.
[I 2023-09-17 20:14:39,597] Trial 5 pruned.
[I 2023-09-17 20:14:42,257] Trial 6 pruned.
[I 2023-09-17 20:17:12,701] Trial 7 finished with value: 0.06913515599301227 and parameters: {'n_layers': 3, 'n_units_l0': 9, 'dropout_0': 0.2776577929235261, 'n_units_l1': 4, 'dropout_1': 0.12784029832503074, 'n_units_l2': 10, 'dropout_2': 0.3290401414899319, 'learning_rate': 0.02904100508576421, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.060364104303029874.
[I 2023-09-17 20:17:15,599] Trial 8 pruned.
[I 2023-09-17 20:17:18,893] Trial 9 pruned.
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (341245, 1270)
Number of total missing values across all columns: 333968
Data Subset Is Off
Wells held out for testing: ['L06' 'L09']
Wells to use for training, validation, and testing ['E06' 'E07' 'L02' 'L03' 'L07' 'L08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 97.95120064962684
Validation Loss: 0.061751316259973314
Training Accuracy: 97.2242088523465
Training Loss: 0.07377769819330333
completed
