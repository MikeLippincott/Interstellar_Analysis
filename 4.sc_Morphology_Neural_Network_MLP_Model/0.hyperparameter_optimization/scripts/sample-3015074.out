[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: SHSY5Y control_name: LPS_10.000_DMSO_0.025 treatment_name: Thapsigargin_1.000_DMSO_0.025
[I 2023-09-17 20:34:19,958] A new study created in memory with name: no-name-5b3930ef-0388-4b77-9316-4ccec020ca0a
[I 2023-09-17 20:34:29,580] Trial 0 finished with value: 0.36884180257717775 and parameters: {'n_layers': 3, 'n_units_l0': 8, 'dropout_0': 0.3198800987300831, 'n_units_l1': 8, 'dropout_1': 0.33010587135889247, 'n_units_l2': 8, 'dropout_2': 0.35390008644400817, 'learning_rate': 0.0658637350160376, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.36884180257717775.
[I 2023-09-17 20:34:38,965] Trial 1 finished with value: 0.43131744265556343 and parameters: {'n_layers': 3, 'n_units_l0': 4, 'dropout_0': 0.18903009682197786, 'n_units_l1': 3, 'dropout_1': 0.1696300830232719, 'n_units_l2': 6, 'dropout_2': 0.1888075599385049, 'learning_rate': 0.04127097671448816, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.36884180257717775.
[I 2023-09-17 20:34:48,213] Trial 2 finished with value: 0.3631893394390742 and parameters: {'n_layers': 2, 'n_units_l0': 5, 'dropout_0': 0.3712877892376265, 'n_units_l1': 2, 'dropout_1': 0.1821465608051076, 'learning_rate': 0.0936237359701777, 'optimizer': 'Adam'}. Best is trial 2 with value: 0.3631893394390742.
[I 2023-09-17 20:34:57,473] Trial 3 finished with value: 0.4533350072304407 and parameters: {'n_layers': 2, 'n_units_l0': 5, 'dropout_0': 0.30940665185459426, 'n_units_l1': 5, 'dropout_1': 0.39112217457369136, 'learning_rate': 0.04733507368992815, 'optimizer': 'RMSprop'}. Best is trial 2 with value: 0.3631893394390742.
[I 2023-09-17 20:35:06,929] Trial 4 finished with value: 0.30347109377384185 and parameters: {'n_layers': 2, 'n_units_l0': 6, 'dropout_0': 0.17367609115391813, 'n_units_l1': 3, 'dropout_1': 0.29719608380826423, 'learning_rate': 0.028326061270624002, 'optimizer': 'Adam'}. Best is trial 4 with value: 0.30347109377384185.
[I 2023-09-17 20:35:07,112] Trial 5 pruned.
[I 2023-09-17 20:35:16,303] Trial 6 finished with value: 0.332244456410408 and parameters: {'n_layers': 2, 'n_units_l0': 2, 'dropout_0': 0.1504426726695548, 'n_units_l1': 3, 'dropout_1': 0.24532058149492625, 'learning_rate': 0.056524236870660695, 'optimizer': 'SGD'}. Best is trial 4 with value: 0.30347109377384185.
[I 2023-09-17 20:35:20,430] Trial 7 pruned.
[I 2023-09-17 20:35:20,598] Trial 8 pruned.
[I 2023-09-17 20:35:29,901] Trial 9 finished with value: 0.33567725916703545 and parameters: {'n_layers': 1, 'n_units_l0': 10, 'dropout_0': 0.1902150021339189, 'learning_rate': 0.06467495060978323, 'optimizer': 'Adam'}. Best is trial 4 with value: 0.30347109377384185.
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'LPS_10.000_DMSO_0.025']
The dimensions of the data are: (30576, 1276)
Number of total missing values across all columns: 61152
Data Subset Is Off
Wells held out for testing: ['D14' 'E20']
Wells to use for training, validation, and testing ['D15' 'E16' 'E17' 'E21' 'K14' 'K15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 89.9575941151017
Validation Loss: 0.24436414023240405
Training Accuracy: 81.07244494941297
Training Loss: 0.33685256881149195
completed
