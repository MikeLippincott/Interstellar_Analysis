[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: SHSY5Y control_name: H2O2_100.000_DMSO_0.025 treatment_name: Thapsigargin_1.000_DMSO_0.025
[I 2023-09-19 01:32:20,869] A new study created in memory with name: no-name-f0d275fd-6e92-4ac4-a029-751367ba92e9
[I 2023-09-19 01:32:34,513] Trial 0 finished with value: 0.5182251372933387 and parameters: {'n_layers': 2, 'n_units_l0': 2, 'dropout_0': 0.3681867057524004, 'n_units_l1': 4, 'dropout_1': 0.16092240059073531, 'learning_rate': 0.0897918676787896, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.5182251372933387.
[I 2023-09-19 01:32:48,419] Trial 1 finished with value: 0.49104814186692236 and parameters: {'n_layers': 3, 'n_units_l0': 2, 'dropout_0': 0.3908303410510914, 'n_units_l1': 6, 'dropout_1': 0.3852212853122742, 'n_units_l2': 9, 'dropout_2': 0.18070358176355433, 'learning_rate': 0.03147155111669513, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.49104814186692236.
[I 2023-09-19 01:33:01,873] Trial 2 finished with value: 0.381592228859663 and parameters: {'n_layers': 2, 'n_units_l0': 2, 'dropout_0': 0.25618311835508245, 'n_units_l1': 5, 'dropout_1': 0.3558301850965838, 'learning_rate': 0.05252409793512167, 'optimizer': 'SGD'}. Best is trial 2 with value: 0.381592228859663.
[I 2023-09-19 01:33:15,953] Trial 3 finished with value: 0.4006457134336233 and parameters: {'n_layers': 3, 'n_units_l0': 10, 'dropout_0': 0.23883377296781802, 'n_units_l1': 8, 'dropout_1': 0.1734834747020575, 'n_units_l2': 6, 'dropout_2': 0.2658182248556725, 'learning_rate': 0.04218514626110842, 'optimizer': 'SGD'}. Best is trial 2 with value: 0.381592228859663.
[I 2023-09-19 01:33:30,138] Trial 4 finished with value: 0.41997714057564733 and parameters: {'n_layers': 3, 'n_units_l0': 9, 'dropout_0': 0.2100925879607644, 'n_units_l1': 7, 'dropout_1': 0.344050001684022, 'n_units_l2': 2, 'dropout_2': 0.2970239265109683, 'learning_rate': 0.05992381669793049, 'optimizer': 'RMSprop'}. Best is trial 2 with value: 0.381592228859663.
[I 2023-09-19 01:33:43,483] Trial 5 finished with value: 0.2489718198031187 and parameters: {'n_layers': 1, 'n_units_l0': 9, 'dropout_0': 0.38879287049325084, 'learning_rate': 0.07886573579213424, 'optimizer': 'SGD'}. Best is trial 5 with value: 0.2489718198031187.
[I 2023-09-19 01:33:56,847] Trial 6 finished with value: 0.2438795554637909 and parameters: {'n_layers': 1, 'n_units_l0': 9, 'dropout_0': 0.14794581022342654, 'learning_rate': 0.06510364485338085, 'optimizer': 'SGD'}. Best is trial 6 with value: 0.2438795554637909.
[I 2023-09-19 01:34:10,380] Trial 7 finished with value: 0.2462616741657257 and parameters: {'n_layers': 1, 'n_units_l0': 8, 'dropout_0': 0.34289993346333436, 'learning_rate': 0.016366731607720803, 'optimizer': 'RMSprop'}. Best is trial 6 with value: 0.2438795554637909.
[I 2023-09-19 01:34:10,636] Trial 8 pruned.
[I 2023-09-19 01:34:24,560] Trial 9 finished with value: 0.24869528852403164 and parameters: {'n_layers': 2, 'n_units_l0': 6, 'dropout_0': 0.3809269161303691, 'n_units_l1': 7, 'dropout_1': 0.19062000365496967, 'learning_rate': 0.04475066468449193, 'optimizer': 'Adam'}. Best is trial 6 with value: 0.2438795554637909.
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'H2O2_100.000_DMSO_0.025']
The dimensions of the data are: (40666, 1276)
Number of total missing values across all columns: 81332
Data Subset Is Off
Wells held out for testing: ['D14' 'H22']
Wells to use for training, validation, and testing ['D15' 'H18' 'H19' 'H23' 'K14' 'K15' 'I18' 'I19' 'I22' 'I23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 90.34528472431455
Validation Loss: 0.24225175574421884
Training Accuracy: 90.98014542440568
Training Loss: 0.22202033733880078
completed
