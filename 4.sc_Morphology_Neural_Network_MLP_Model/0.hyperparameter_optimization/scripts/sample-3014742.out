[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: SHSY5Y control_name: LPS_0.010_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025
[I 2023-09-17 19:45:50,219] A new study created in memory with name: no-name-08f4e27b-461c-497d-ab38-29a46543655f
[I 2023-09-17 19:45:59,565] Trial 0 finished with value: 0.5542806502183278 and parameters: {'n_layers': 3, 'n_units_l0': 7, 'dropout_0': 0.18102428121290026, 'n_units_l1': 5, 'dropout_1': 0.28429446449601825, 'n_units_l2': 6, 'dropout_2': 0.39246964634446213, 'learning_rate': 0.04791549599628405, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.5542806502183278.
[I 2023-09-17 19:46:08,486] Trial 1 finished with value: 0.5825989131132762 and parameters: {'n_layers': 2, 'n_units_l0': 8, 'dropout_0': 0.3243081732466291, 'n_units_l1': 3, 'dropout_1': 0.2850661281370888, 'learning_rate': 0.05453861051913524, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.5542806502183278.
[I 2023-09-17 19:46:17,115] Trial 2 finished with value: 0.6249044024944306 and parameters: {'n_layers': 1, 'n_units_l0': 9, 'dropout_0': 0.1583751588559145, 'learning_rate': 0.015998715771987585, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.5542806502183278.
[I 2023-09-17 19:46:25,921] Trial 3 finished with value: 0.6060119835535684 and parameters: {'n_layers': 1, 'n_units_l0': 10, 'dropout_0': 0.15989432157814232, 'learning_rate': 0.027798116117282, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.5542806502183278.
[I 2023-09-17 19:46:34,887] Trial 4 finished with value: 0.6260660640398661 and parameters: {'n_layers': 3, 'n_units_l0': 7, 'dropout_0': 0.22904850527799397, 'n_units_l1': 7, 'dropout_1': 0.24695693593852241, 'n_units_l2': 8, 'dropout_2': 0.33751955748660323, 'learning_rate': 0.044975004270914096, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.5542806502183278.
[I 2023-09-17 19:46:35,124] Trial 5 pruned.
[I 2023-09-17 19:46:35,281] Trial 6 pruned.
[I 2023-09-17 19:46:35,438] Trial 7 pruned.
[I 2023-09-17 19:46:44,819] Trial 8 finished with value: 0.5609894589583078 and parameters: {'n_layers': 3, 'n_units_l0': 10, 'dropout_0': 0.16301409931911057, 'n_units_l1': 8, 'dropout_1': 0.1006840435070291, 'n_units_l2': 9, 'dropout_2': 0.3110273497139187, 'learning_rate': 0.027143424750024722, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.5542806502183278.
[I 2023-09-17 19:46:45,065] Trial 9 pruned.
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (31668, 1276)
Number of total missing values across all columns: 63336
Data Subset Is Off
Wells held out for testing: ['B16' 'M22']
Wells to use for training, validation, and testing ['B17' 'B20' 'B21' 'M18' 'M19' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 69.9019442096365
Validation Loss: 0.591128696600596
Training Accuracy: 71.01712292569496
Training Loss: 0.561902284245742
completed
