[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: PBMC control_name: LPS_0.100_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_1.0_DMSO_0.025
[I 2023-09-17 19:54:29,542] A new study created in memory with name: no-name-681040b0-50da-4292-ae64-f6af1ac52cd8
[I 2023-09-17 19:56:23,452] Trial 0 finished with value: 0.2619395950695743 and parameters: {'n_layers': 1, 'n_units_l0': 9, 'dropout_0': 0.36771621926032183, 'learning_rate': 0.05933745970304132, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.2619395950695743.
[I 2023-09-17 19:58:03,231] Trial 1 finished with value: 0.5505196384761644 and parameters: {'n_layers': 1, 'n_units_l0': 2, 'dropout_0': 0.3943805893781498, 'learning_rate': 0.09975301812724062, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.2619395950695743.
[I 2023-09-17 19:59:50,850] Trial 2 finished with value: 0.2820900864704796 and parameters: {'n_layers': 3, 'n_units_l0': 8, 'dropout_0': 0.29289280112002847, 'n_units_l1': 3, 'dropout_1': 0.31721553463893176, 'n_units_l2': 6, 'dropout_2': 0.2111172214173558, 'learning_rate': 0.09750629985255543, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.2619395950695743.
[I 2023-09-17 20:01:36,677] Trial 3 finished with value: 0.2557686654899431 and parameters: {'n_layers': 2, 'n_units_l0': 5, 'dropout_0': 0.10262927935551813, 'n_units_l1': 2, 'dropout_1': 0.12025695342698388, 'learning_rate': 0.01809718674533523, 'optimizer': 'Adam'}. Best is trial 3 with value: 0.2557686654899431.
[I 2023-09-17 20:03:29,897] Trial 4 finished with value: 0.2716232398670653 and parameters: {'n_layers': 3, 'n_units_l0': 10, 'dropout_0': 0.33349436716731207, 'n_units_l1': 5, 'dropout_1': 0.15533301920290776, 'n_units_l2': 9, 'dropout_2': 0.22860835246988348, 'learning_rate': 0.015427690938556874, 'optimizer': 'RMSprop'}. Best is trial 3 with value: 0.2557686654899431.
[I 2023-09-17 20:03:42,957] Trial 5 pruned.
[I 2023-09-17 20:03:45,034] Trial 6 pruned.
[I 2023-09-17 20:03:47,126] Trial 7 pruned.
[I 2023-09-17 20:05:32,870] Trial 8 finished with value: 0.2453389244623806 and parameters: {'n_layers': 1, 'n_units_l0': 8, 'dropout_0': 0.23226124526446357, 'learning_rate': 0.0875198576581945, 'optimizer': 'SGD'}. Best is trial 8 with value: 0.2453389244623806.
[I 2023-09-17 20:05:43,707] Trial 9 pruned.
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (304610, 1270)
Number of total missing values across all columns: 277194
Data Subset Is Off
Wells held out for testing: ['C08' 'K08']
Wells to use for training, validation, and testing ['C02' 'C03' 'C09' 'K02' 'K03' 'K09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 89.9690145762416
Validation Loss: 0.2448857226708661
Training Accuracy: 88.14027833088753
Training Loss: 0.2786882113989281
completed
