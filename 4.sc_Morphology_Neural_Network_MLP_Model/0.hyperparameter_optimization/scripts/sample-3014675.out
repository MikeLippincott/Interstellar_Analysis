[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: PBMC control_name: Flagellin_0.100_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025
[I 2023-09-17 19:29:53,019] A new study created in memory with name: no-name-b188877f-ffcf-4e9b-b4f9-42381fa37550
[I 2023-09-17 19:30:16,210] Trial 0 finished with value: 0.002358930986389131 and parameters: {'n_layers': 1, 'n_units_l0': 3, 'dropout_0': 0.27451234799825164, 'learning_rate': 0.07046112959578314, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.002358930986389131.
[I 2023-09-17 19:30:39,246] Trial 1 finished with value: 0.7427973948547869 and parameters: {'n_layers': 1, 'n_units_l0': 3, 'dropout_0': 0.10293681623739259, 'learning_rate': 0.09767147603430645, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.002358930986389131.
[I 2023-09-17 19:31:03,448] Trial 2 finished with value: 0.6206369877756306 and parameters: {'n_layers': 3, 'n_units_l0': 3, 'dropout_0': 0.395045000016216, 'n_units_l1': 9, 'dropout_1': 0.1536108092204473, 'n_units_l2': 9, 'dropout_2': 0.2041004709045136, 'learning_rate': 0.07207966222354897, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.002358930986389131.
[I 2023-09-17 19:31:28,065] Trial 3 finished with value: 5.042166804081209e-07 and parameters: {'n_layers': 3, 'n_units_l0': 7, 'dropout_0': 0.31701308551305357, 'n_units_l1': 2, 'dropout_1': 0.3665558242162338, 'n_units_l2': 5, 'dropout_2': 0.30501838956885874, 'learning_rate': 0.028198673987905962, 'optimizer': 'Adam'}. Best is trial 3 with value: 5.042166804081209e-07.
[I 2023-09-17 19:31:51,469] Trial 4 finished with value: 3.353146275393166e-05 and parameters: {'n_layers': 3, 'n_units_l0': 5, 'dropout_0': 0.1217681539316436, 'n_units_l1': 4, 'dropout_1': 0.34985732790651985, 'n_units_l2': 7, 'dropout_2': 0.12046873893929821, 'learning_rate': 0.03611776071334209, 'optimizer': 'SGD'}. Best is trial 3 with value: 5.042166804081209e-07.
[I 2023-09-17 19:32:15,736] Trial 5 finished with value: 4.7337675578914815e-08 and parameters: {'n_layers': 3, 'n_units_l0': 4, 'dropout_0': 0.30474768700220234, 'n_units_l1': 3, 'dropout_1': 0.11386387357560025, 'n_units_l2': 4, 'dropout_2': 0.3365042596846709, 'learning_rate': 0.010001824111669876, 'optimizer': 'Adam'}. Best is trial 5 with value: 4.7337675578914815e-08.
[I 2023-09-17 19:32:39,575] Trial 6 finished with value: 4.48304122049889e-06 and parameters: {'n_layers': 2, 'n_units_l0': 3, 'dropout_0': 0.32201143147109434, 'n_units_l1': 2, 'dropout_1': 0.2719117952880833, 'learning_rate': 0.021203479505609586, 'optimizer': 'Adam'}. Best is trial 5 with value: 4.7337675578914815e-08.
[I 2023-09-17 19:33:02,955] Trial 7 finished with value: 2.59367290404303e-05 and parameters: {'n_layers': 2, 'n_units_l0': 8, 'dropout_0': 0.38996168164253975, 'n_units_l1': 4, 'dropout_1': 0.16367925353919532, 'learning_rate': 0.05018954158569626, 'optimizer': 'SGD'}. Best is trial 5 with value: 4.7337675578914815e-08.
[I 2023-09-17 19:33:27,013] Trial 8 finished with value: 5.372701480398124e-07 and parameters: {'n_layers': 2, 'n_units_l0': 8, 'dropout_0': 0.28154988391172375, 'n_units_l1': 8, 'dropout_1': 0.2880412512658521, 'learning_rate': 0.062314074211574914, 'optimizer': 'Adam'}. Best is trial 5 with value: 4.7337675578914815e-08.
[I 2023-09-17 19:33:27,512] Trial 9 pruned.
Selected Catagories are:
['Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (95915, 1270)
Number of total missing values across all columns: 191830
Data Subset Is Off
Wells held out for testing: ['L10']
Wells to use for training, validation, and testing ['L05' 'L11']
Number of in features:  1245
Number of out features:  1
Regression
cpu
Validation Loss: 2.002947832549616e-07
Training Loss: 0.00021465055279577176
completed
