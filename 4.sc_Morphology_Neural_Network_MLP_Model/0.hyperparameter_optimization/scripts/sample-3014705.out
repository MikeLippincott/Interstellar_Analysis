[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: SHSY5Y control_name: LPS_0.010_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025
[I 2023-09-17 19:37:09,685] A new study created in memory with name: no-name-de2a6199-52f5-4af1-a09e-b63ea2d778bb
[I 2023-09-17 19:37:18,868] Trial 0 finished with value: 0.6284786740938823 and parameters: {'n_layers': 1, 'n_units_l0': 6, 'dropout_0': 0.19277698607509253, 'learning_rate': 0.04559249865672377, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.6284786740938823.
[I 2023-09-17 19:37:27,954] Trial 1 finished with value: 0.6157277433077495 and parameters: {'n_layers': 2, 'n_units_l0': 7, 'dropout_0': 0.21571318686613628, 'n_units_l1': 5, 'dropout_1': 0.2693639458824201, 'learning_rate': 0.07712659903422428, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.6157277433077495.
[I 2023-09-17 19:37:37,042] Trial 2 finished with value: 0.66769433538119 and parameters: {'n_layers': 3, 'n_units_l0': 8, 'dropout_0': 0.14350246521228247, 'n_units_l1': 5, 'dropout_1': 0.2809900296321377, 'n_units_l2': 9, 'dropout_2': 0.13000072944689955, 'learning_rate': 0.030994634770207103, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.6157277433077495.
[I 2023-09-17 19:37:46,136] Trial 3 finished with value: 0.6922558430830638 and parameters: {'n_layers': 2, 'n_units_l0': 8, 'dropout_0': 0.1861127417478631, 'n_units_l1': 10, 'dropout_1': 0.19396925790047054, 'learning_rate': 0.09890050163679034, 'optimizer': 'RMSprop'}. Best is trial 1 with value: 0.6157277433077495.
[I 2023-09-17 19:37:55,397] Trial 4 finished with value: 0.6068257892131805 and parameters: {'n_layers': 2, 'n_units_l0': 10, 'dropout_0': 0.28962657369795597, 'n_units_l1': 9, 'dropout_1': 0.1356948567967941, 'learning_rate': 0.006695415238932139, 'optimizer': 'RMSprop'}. Best is trial 4 with value: 0.6068257892131805.
[I 2023-09-17 19:37:55,563] Trial 5 pruned.
[I 2023-09-17 19:37:55,735] Trial 6 pruned.
[I 2023-09-17 19:37:55,898] Trial 7 pruned.
[I 2023-09-17 19:37:56,150] Trial 8 pruned.
[I 2023-09-17 19:38:05,461] Trial 9 finished with value: 0.6350059016545614 and parameters: {'n_layers': 2, 'n_units_l0': 10, 'dropout_0': 0.1392976318074374, 'n_units_l1': 7, 'dropout_1': 0.13953239856086522, 'learning_rate': 0.020122879859988643, 'optimizer': 'Adam'}. Best is trial 4 with value: 0.6068257892131805.
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (30787, 1276)
Number of total missing values across all columns: 61574
Data Subset Is Off
Wells held out for testing: ['B16' 'L22']
Wells to use for training, validation, and testing ['B17' 'B20' 'B21' 'L18' 'L19' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 67.61606354810237
Validation Loss: 0.6088325766722362
Training Accuracy: 74.77095403630744
Training Loss: 0.5023766625084375
completed
