[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: PBMC control_name: Flagellin_0.100_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025
[I 2023-09-17 19:44:46,104] A new study created in memory with name: no-name-5221e1e8-c699-46bd-b1e1-4b6804f66e60
[I 2023-09-17 19:45:43,301] Trial 0 finished with value: 0.6914291052307404 and parameters: {'n_layers': 3, 'n_units_l0': 5, 'dropout_0': 0.21918479397282514, 'n_units_l1': 4, 'dropout_1': 0.3560326199717294, 'n_units_l2': 9, 'dropout_2': 0.39982058165156564, 'learning_rate': 0.05865619596777228, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.6914291052307404.
[I 2023-09-17 19:46:37,459] Trial 1 finished with value: 0.56284248820373 and parameters: {'n_layers': 1, 'n_units_l0': 8, 'dropout_0': 0.31732974468545605, 'learning_rate': 0.034135032433177656, 'optimizer': 'RMSprop'}. Best is trial 1 with value: 0.56284248820373.
[I 2023-09-17 19:47:32,343] Trial 2 finished with value: 0.6718424665927887 and parameters: {'n_layers': 2, 'n_units_l0': 3, 'dropout_0': 0.20939778756459326, 'n_units_l1': 8, 'dropout_1': 0.15147520974769774, 'learning_rate': 0.044642877929038295, 'optimizer': 'RMSprop'}. Best is trial 1 with value: 0.56284248820373.
[I 2023-09-17 19:48:26,424] Trial 3 finished with value: 0.586067790729659 and parameters: {'n_layers': 1, 'n_units_l0': 2, 'dropout_0': 0.2064461929862976, 'learning_rate': 0.09794279664629853, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.56284248820373.
[I 2023-09-17 19:49:20,821] Trial 4 finished with value: 0.5735504313026155 and parameters: {'n_layers': 1, 'n_units_l0': 3, 'dropout_0': 0.39152225416182984, 'learning_rate': 0.03704498843907989, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.56284248820373.
[I 2023-09-17 19:49:22,019] Trial 5 pruned.
[I 2023-09-17 19:49:23,023] Trial 6 pruned.
[I 2023-09-17 19:50:19,465] Trial 7 finished with value: 0.5068913728850228 and parameters: {'n_layers': 3, 'n_units_l0': 9, 'dropout_0': 0.3010306377224028, 'n_units_l1': 6, 'dropout_1': 0.18884857978076908, 'n_units_l2': 3, 'dropout_2': 0.28521142651734344, 'learning_rate': 0.006320072710003583, 'optimizer': 'Adam'}. Best is trial 7 with value: 0.5068913728850228.
[I 2023-09-17 19:50:20,556] Trial 8 pruned.
[I 2023-09-17 19:50:21,634] Trial 9 pruned.
Selected Catagories are:
['Flagellin_0.100_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (200462, 1270)
Number of total missing values across all columns: 437540
Data Subset Is Off
Wells held out for testing: ['L10' 'M10']
Wells to use for training, validation, and testing ['L05' 'M05' 'L11' 'M11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 75.94323898190554
Validation Loss: 0.5033031590495791
Training Accuracy: 71.96046666604094
Training Loss: 0.549346247170573
completed
