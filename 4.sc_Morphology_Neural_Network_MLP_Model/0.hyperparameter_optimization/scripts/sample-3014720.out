[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: SHSY5Y control_name: Flagellin_1.000_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025
[I 2023-09-17 19:42:57,699] A new study created in memory with name: no-name-5a11f568-f79b-4b98-847c-760422a758e3
[I 2023-09-17 19:43:01,838] Trial 0 finished with value: 0.01882192461566034 and parameters: {'n_layers': 1, 'n_units_l0': 6, 'dropout_0': 0.31594660429145327, 'learning_rate': 0.09918418242686505, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.01882192461566034.
[I 2023-09-17 19:43:05,932] Trial 1 finished with value: 0.10787546486302745 and parameters: {'n_layers': 2, 'n_units_l0': 10, 'dropout_0': 0.35231336604944796, 'n_units_l1': 2, 'dropout_1': 0.3552323135988452, 'learning_rate': 0.05641803171345145, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.01882192461566034.
[I 2023-09-17 19:43:09,992] Trial 2 finished with value: 0.0014426704711513593 and parameters: {'n_layers': 3, 'n_units_l0': 5, 'dropout_0': 0.167018604439642, 'n_units_l1': 10, 'dropout_1': 0.16269137103564563, 'n_units_l2': 9, 'dropout_2': 0.24203884089251773, 'learning_rate': 0.035752339433479226, 'optimizer': 'RMSprop'}. Best is trial 2 with value: 0.0014426704711513593.
[I 2023-09-17 19:43:14,288] Trial 3 finished with value: 7.290720707774162 and parameters: {'n_layers': 3, 'n_units_l0': 10, 'dropout_0': 0.26939546798279607, 'n_units_l1': 7, 'dropout_1': 0.2912448068834938, 'n_units_l2': 5, 'dropout_2': 0.2469945318864802, 'learning_rate': 0.06969449062405161, 'optimizer': 'RMSprop'}. Best is trial 2 with value: 0.0014426704711513593.
[I 2023-09-17 19:43:18,239] Trial 4 finished with value: 0.011742839806247502 and parameters: {'n_layers': 2, 'n_units_l0': 5, 'dropout_0': 0.31645597821140103, 'n_units_l1': 10, 'dropout_1': 0.32602645769306415, 'learning_rate': 0.009899026420051719, 'optimizer': 'RMSprop'}. Best is trial 2 with value: 0.0014426704711513593.
[I 2023-09-17 19:43:22,065] Trial 5 finished with value: 0.0016397675435291604 and parameters: {'n_layers': 1, 'n_units_l0': 4, 'dropout_0': 0.13288729273707697, 'learning_rate': 0.08699936178466064, 'optimizer': 'SGD'}. Best is trial 2 with value: 0.0014426704711513593.
[I 2023-09-17 19:43:22,137] Trial 6 pruned.
[I 2023-09-17 19:43:26,285] Trial 7 finished with value: 3.865349044389675e-05 and parameters: {'n_layers': 3, 'n_units_l0': 6, 'dropout_0': 0.12099597754020872, 'n_units_l1': 5, 'dropout_1': 0.3508182271323237, 'n_units_l2': 8, 'dropout_2': 0.23840987770655084, 'learning_rate': 0.070006888623645, 'optimizer': 'Adam'}. Best is trial 7 with value: 3.865349044389675e-05.
[I 2023-09-17 19:43:30,371] Trial 8 finished with value: 0.001084064369481439 and parameters: {'n_layers': 2, 'n_units_l0': 10, 'dropout_0': 0.1260184321282283, 'n_units_l1': 3, 'dropout_1': 0.3329708637558338, 'learning_rate': 0.0036700324050620747, 'optimizer': 'RMSprop'}. Best is trial 7 with value: 3.865349044389675e-05.
[I 2023-09-17 19:43:34,334] Trial 9 finished with value: 0.00011488654448612578 and parameters: {'n_layers': 3, 'n_units_l0': 4, 'dropout_0': 0.2561476975210862, 'n_units_l1': 7, 'dropout_1': 0.11329257189453668, 'n_units_l2': 4, 'dropout_2': 0.22651281913897459, 'learning_rate': 0.07381034047463864, 'optimizer': 'SGD'}. Best is trial 7 with value: 3.865349044389675e-05.
Selected Catagories are:
['Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (15809, 1276)
Number of total missing values across all columns: 31618
Data Subset Is Off
Wells held out for testing: ['M22']
Wells to use for training, validation, and testing ['M18' 'M19' 'M23']
Number of in features:  1251
Number of out features:  1
Regression
cpu
Validation Loss: 8.689810178322155e-05
Training Loss: 0.005604487218298487
completed
