[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: PBMC control_name: LPS_100.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_1.0_DMSO_0.025
[I 2023-09-17 19:51:27,185] A new study created in memory with name: no-name-96167dc4-1fd2-40c3-977b-c821c2a9c295
[I 2023-09-17 19:52:53,356] Trial 0 finished with value: 0.3510105330228806 and parameters: {'n_layers': 3, 'n_units_l0': 4, 'dropout_0': 0.16200007860744317, 'n_units_l1': 10, 'dropout_1': 0.2726979878889107, 'n_units_l2': 2, 'dropout_2': 0.25384040391562296, 'learning_rate': 0.004720131718806575, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.3510105330228806.
[I 2023-09-17 19:54:20,029] Trial 1 finished with value: 0.32681963615417486 and parameters: {'n_layers': 2, 'n_units_l0': 7, 'dropout_0': 0.14153958925578333, 'n_units_l1': 8, 'dropout_1': 0.21205429417844734, 'learning_rate': 0.06647966070859301, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.32681963615417486.
[I 2023-09-17 19:55:47,144] Trial 2 finished with value: 0.40589237101078035 and parameters: {'n_layers': 3, 'n_units_l0': 3, 'dropout_0': 0.35134565445622656, 'n_units_l1': 6, 'dropout_1': 0.29070075944803575, 'n_units_l2': 6, 'dropout_2': 0.2142180099144739, 'learning_rate': 0.09677110894172955, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.32681963615417486.
[I 2023-09-17 19:57:12,851] Trial 3 finished with value: 0.6727912821531297 and parameters: {'n_layers': 3, 'n_units_l0': 4, 'dropout_0': 0.170919512045849, 'n_units_l1': 9, 'dropout_1': 0.2695947699532573, 'n_units_l2': 10, 'dropout_2': 0.22326248775103885, 'learning_rate': 0.07246119584934578, 'optimizer': 'RMSprop'}. Best is trial 1 with value: 0.32681963615417486.
[I 2023-09-17 19:58:36,466] Trial 4 finished with value: 0.2995248041152954 and parameters: {'n_layers': 1, 'n_units_l0': 10, 'dropout_0': 0.24801853951718753, 'learning_rate': 0.059655954096075284, 'optimizer': 'SGD'}. Best is trial 4 with value: 0.2995248041152954.
[I 2023-09-17 20:00:00,433] Trial 5 finished with value: 0.2894396616697311 and parameters: {'n_layers': 1, 'n_units_l0': 9, 'dropout_0': 0.34122238322381565, 'learning_rate': 0.008714096981898234, 'optimizer': 'Adam'}. Best is trial 5 with value: 0.2894396616697311.
[I 2023-09-17 20:00:05,178] Trial 6 pruned.
[I 2023-09-17 20:00:06,997] Trial 7 pruned.
[I 2023-09-17 20:00:08,729] Trial 8 pruned.
[I 2023-09-17 20:01:32,259] Trial 9 finished with value: 0.3134238706827164 and parameters: {'n_layers': 1, 'n_units_l0': 5, 'dropout_0': 0.20562796989651916, 'learning_rate': 0.04514800604443774, 'optimizer': 'Adam'}. Best is trial 5 with value: 0.2894396616697311.
Selected Catagories are:
['LPS_100.000_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (325448, 1270)
Number of total missing values across all columns: 318870
Data Subset Is Off
Wells held out for testing: ['K08' 'J09']
Wells to use for training, validation, and testing ['J02' 'K02' 'J03' 'K03' 'J08' 'K09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 88.17097221090373
Validation Loss: 0.28539585310220716
Training Accuracy: 85.04566847316735
Training Loss: 0.3371834190121762
completed
