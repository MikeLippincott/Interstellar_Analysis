[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: SHSY5Y control_name: LPS_0.100_DMSO_0.025 treatment_name: Thapsigargin_1.000_DMSO_0.025
[I 2023-09-19 01:31:23,528] A new study created in memory with name: no-name-b1238892-2227-4264-bd65-ed6663901329
[I 2023-09-19 01:31:32,949] Trial 0 finished with value: 0.6895101602872213 and parameters: {'n_layers': 3, 'n_units_l0': 4, 'dropout_0': 0.12543515382852716, 'n_units_l1': 5, 'dropout_1': 0.20639542986612203, 'n_units_l2': 6, 'dropout_2': 0.24152999556976978, 'learning_rate': 0.07618161800404698, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.6895101602872213.
[I 2023-09-19 01:31:42,300] Trial 1 finished with value: 0.3267428759733836 and parameters: {'n_layers': 2, 'n_units_l0': 6, 'dropout_0': 0.1543256747857294, 'n_units_l1': 10, 'dropout_1': 0.12864289490989889, 'learning_rate': 0.03413715621213605, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.3267428759733836.
[I 2023-09-19 01:31:51,944] Trial 2 finished with value: 0.4698205085595449 and parameters: {'n_layers': 3, 'n_units_l0': 9, 'dropout_0': 0.2692530073468776, 'n_units_l1': 7, 'dropout_1': 0.3401752865562848, 'n_units_l2': 10, 'dropout_2': 0.330920071690955, 'learning_rate': 0.07203854454081571, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.3267428759733836.
[I 2023-09-19 01:32:01,516] Trial 3 finished with value: 0.3239881374438604 and parameters: {'n_layers': 3, 'n_units_l0': 7, 'dropout_0': 0.27528345446685365, 'n_units_l1': 7, 'dropout_1': 0.11335152411745197, 'n_units_l2': 9, 'dropout_2': 0.26400744662372455, 'learning_rate': 0.011203486794982847, 'optimizer': 'RMSprop'}. Best is trial 3 with value: 0.3239881374438604.
[I 2023-09-19 01:32:10,844] Trial 4 finished with value: 0.3585475311676661 and parameters: {'n_layers': 3, 'n_units_l0': 10, 'dropout_0': 0.3475861418337137, 'n_units_l1': 3, 'dropout_1': 0.15514838075149143, 'n_units_l2': 10, 'dropout_2': 0.3307728215491497, 'learning_rate': 0.08363713572097309, 'optimizer': 'SGD'}. Best is trial 3 with value: 0.3239881374438604.
[I 2023-09-19 01:32:11,083] Trial 5 pruned.
[I 2023-09-19 01:32:11,247] Trial 6 pruned.
[I 2023-09-19 01:32:11,413] Trial 7 pruned.
[I 2023-09-19 01:32:11,574] Trial 8 pruned.
[I 2023-09-19 01:32:11,829] Trial 9 pruned.
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'LPS_0.100_DMSO_0.025']
The dimensions of the data are: (31276, 1276)
Number of total missing values across all columns: 62552
Data Subset Is Off
Wells held out for testing: ['D14' 'C20']
Wells to use for training, validation, and testing ['D15' 'C16' 'C17' 'C21' 'K14' 'K15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 87.48576285592861
Validation Loss: 0.3053293572862943
Training Accuracy: 87.66252257995964
Training Loss: 0.2711022079932063
completed
