[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: PBMC control_name: Flagellin_0.100_DMSO_0.025 treatment_name: LPS_1.000_DMSO_0.025
[I 2023-09-19 01:15:09,744] A new study created in memory with name: no-name-d197f923-8ac6-4515-8e8b-6ef84f26c877
[I 2023-09-19 01:16:07,187] Trial 0 finished with value: 0.640165487878463 and parameters: {'n_layers': 2, 'n_units_l0': 2, 'dropout_0': 0.3577408957629231, 'n_units_l1': 7, 'dropout_1': 0.2795880533098156, 'learning_rate': 0.050213220308631144, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.640165487878463.
[I 2023-09-19 01:17:06,258] Trial 1 finished with value: 0.44210307019598344 and parameters: {'n_layers': 2, 'n_units_l0': 8, 'dropout_0': 0.20306100210295014, 'n_units_l1': 10, 'dropout_1': 0.19712880906853333, 'learning_rate': 0.029772187986597743, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.44210307019598344.
[I 2023-09-19 01:18:02,698] Trial 2 finished with value: 0.49968993463936967 and parameters: {'n_layers': 2, 'n_units_l0': 5, 'dropout_0': 0.2869226123580759, 'n_units_l1': 7, 'dropout_1': 0.34708970160705765, 'learning_rate': 0.06364267309332276, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.44210307019598344.
[I 2023-09-19 01:19:00,327] Trial 3 finished with value: 0.45136200526181397 and parameters: {'n_layers': 2, 'n_units_l0': 5, 'dropout_0': 0.15083616756175167, 'n_units_l1': 4, 'dropout_1': 0.1552671423001511, 'learning_rate': 0.006192577742889195, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.44210307019598344.
[I 2023-09-19 01:19:58,935] Trial 4 finished with value: 0.5238595743039075 and parameters: {'n_layers': 3, 'n_units_l0': 7, 'dropout_0': 0.10466864245994775, 'n_units_l1': 2, 'dropout_1': 0.10409209248159068, 'n_units_l2': 3, 'dropout_2': 0.10216338430304661, 'learning_rate': 0.05899259210575079, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.44210307019598344.
[I 2023-09-19 01:20:01,282] Trial 5 pruned.
[I 2023-09-19 01:20:02,460] Trial 6 pruned.
[I 2023-09-19 01:20:58,487] Trial 7 finished with value: 0.45979396364268127 and parameters: {'n_layers': 1, 'n_units_l0': 6, 'dropout_0': 0.19134467305247962, 'learning_rate': 0.08411631952791156, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.44210307019598344.
[I 2023-09-19 01:21:53,669] Trial 8 finished with value: 0.47217582380070405 and parameters: {'n_layers': 1, 'n_units_l0': 4, 'dropout_0': 0.18328452430651038, 'learning_rate': 0.07448578973987226, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.44210307019598344.
[I 2023-09-19 01:21:55,987] Trial 9 pruned.
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (235348, 1270)
Number of total missing values across all columns: 470696
Data Subset Is Off
Wells held out for testing: ['D09' 'L10']
Wells to use for training, validation, and testing ['D02' 'D03' 'D08' 'L05' 'L11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 79.20780078007802
Validation Loss: 0.44629433842266303
Training Accuracy: 77.69717971797178
Training Loss: 0.47047193899528295
completed
