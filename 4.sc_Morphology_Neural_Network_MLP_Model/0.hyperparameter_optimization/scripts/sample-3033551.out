[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: SHSY5Y control_name: DMSO_0.100_DMSO_0.025 treatment_name: Thapsigargin_10.000_DMSO_0.025
[I 2023-09-19 01:24:52,067] A new study created in memory with name: no-name-186e9e4e-130c-4667-ab34-0ff4b2b2f453
[I 2023-09-19 01:25:06,113] Trial 0 finished with value: 0.17505985736846924 and parameters: {'n_layers': 2, 'n_units_l0': 5, 'dropout_0': 0.3261456293113909, 'n_units_l1': 10, 'dropout_1': 0.10374485929887478, 'learning_rate': 0.017109648891038016, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.17505985736846924.
[I 2023-09-19 01:25:20,613] Trial 1 finished with value: 0.2264945625960827 and parameters: {'n_layers': 3, 'n_units_l0': 7, 'dropout_0': 0.3248415428284094, 'n_units_l1': 5, 'dropout_1': 0.3690784159007957, 'n_units_l2': 5, 'dropout_2': 0.31036619878415317, 'learning_rate': 0.002028446141495679, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.17505985736846924.
[I 2023-09-19 01:25:35,058] Trial 2 finished with value: 0.13815541619062424 and parameters: {'n_layers': 3, 'n_units_l0': 6, 'dropout_0': 0.17087422281682182, 'n_units_l1': 8, 'dropout_1': 0.352618699012338, 'n_units_l2': 3, 'dropout_2': 0.2012282686634465, 'learning_rate': 0.012381069334652703, 'optimizer': 'Adam'}. Best is trial 2 with value: 0.13815541619062424.
[I 2023-09-19 01:25:49,761] Trial 3 finished with value: 0.19331226885318756 and parameters: {'n_layers': 3, 'n_units_l0': 9, 'dropout_0': 0.23264301029266965, 'n_units_l1': 5, 'dropout_1': 0.2209954846090714, 'n_units_l2': 6, 'dropout_2': 0.12093980372936305, 'learning_rate': 0.03243626667890278, 'optimizer': 'Adam'}. Best is trial 2 with value: 0.13815541619062424.
[I 2023-09-19 01:26:03,753] Trial 4 finished with value: 0.13870943714678285 and parameters: {'n_layers': 1, 'n_units_l0': 3, 'dropout_0': 0.23734023214784025, 'learning_rate': 0.07283932802828996, 'optimizer': 'Adam'}. Best is trial 2 with value: 0.13815541619062424.
[I 2023-09-19 01:26:04,552] Trial 5 pruned.
[I 2023-09-19 01:26:04,799] Trial 6 pruned.
[I 2023-09-19 01:26:05,147] Trial 7 pruned.
[I 2023-09-19 01:26:05,388] Trial 8 pruned.
[I 2023-09-19 01:26:06,511] Trial 9 pruned.
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'Thapsigargin_10.000_DMSO_0.025']
The dimensions of the data are: (48855, 1276)
Number of total missing values across all columns: 97710
Data Subset Is Off
Wells held out for testing: ['I14' 'L14']
Wells to use for training, validation, and testing ['B14' 'C14' 'E14' 'B15' 'C15' 'E15' 'J14' 'I15' 'J15' 'L15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 94.94493608652901
Validation Loss: 0.15047321292757987
Training Accuracy: 91.27391197442834
Training Loss: 0.17607950028144953
completed
