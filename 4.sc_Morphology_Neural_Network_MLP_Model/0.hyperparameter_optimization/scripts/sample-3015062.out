[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: PBMC control_name: Flagellin_0.100_DMSO_0.025 treatment_name: Thapsigargin_1.000_DMSO_0.025
[I 2023-09-17 20:33:47,825] A new study created in memory with name: no-name-e0f82a1e-8497-45b3-a2a8-23c6d713ee62
[I 2023-09-17 20:35:27,217] Trial 0 finished with value: 0.45425682538085516 and parameters: {'n_layers': 2, 'n_units_l0': 5, 'dropout_0': 0.10348547776287811, 'n_units_l1': 8, 'dropout_1': 0.3896541603148739, 'learning_rate': 0.030048919956032667, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.45425682538085516.
[I 2023-09-17 20:36:51,229] Trial 1 finished with value: 0.4800235597954856 and parameters: {'n_layers': 1, 'n_units_l0': 3, 'dropout_0': 0.1783797244368314, 'learning_rate': 0.04484821832005204, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.45425682538085516.
[I 2023-09-17 20:38:10,771] Trial 2 finished with value: 0.658680781390932 and parameters: {'n_layers': 3, 'n_units_l0': 2, 'dropout_0': 0.18793871428498643, 'n_units_l1': 9, 'dropout_1': 0.20720135621246324, 'n_units_l2': 4, 'dropout_2': 0.2721911688055262, 'learning_rate': 0.051935202085118926, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.45425682538085516.
[I 2023-09-17 20:39:38,071] Trial 3 finished with value: 0.4754798758692212 and parameters: {'n_layers': 3, 'n_units_l0': 9, 'dropout_0': 0.14016726928079695, 'n_units_l1': 5, 'dropout_1': 0.2645054632983981, 'n_units_l2': 5, 'dropout_2': 0.30156338037432884, 'learning_rate': 0.02339173261537557, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.45425682538085516.
[I 2023-09-17 20:40:57,470] Trial 4 finished with value: 0.42562119510438706 and parameters: {'n_layers': 1, 'n_units_l0': 5, 'dropout_0': 0.30005555165603487, 'learning_rate': 0.0833250750419406, 'optimizer': 'SGD'}. Best is trial 4 with value: 0.42562119510438706.
[I 2023-09-17 20:42:20,693] Trial 5 finished with value: 0.4088220092985365 and parameters: {'n_layers': 1, 'n_units_l0': 9, 'dropout_0': 0.2658314425417624, 'learning_rate': 0.044686875996390304, 'optimizer': 'SGD'}. Best is trial 5 with value: 0.4088220092985365.
[I 2023-09-17 20:43:38,317] Trial 6 finished with value: 0.4121407954560386 and parameters: {'n_layers': 1, 'n_units_l0': 4, 'dropout_0': 0.23385620082121852, 'learning_rate': 0.06077805216671318, 'optimizer': 'Adam'}. Best is trial 5 with value: 0.4088220092985365.
[I 2023-09-17 20:45:04,743] Trial 7 finished with value: 0.40639101021819646 and parameters: {'n_layers': 2, 'n_units_l0': 8, 'dropout_0': 0.3159806545792345, 'n_units_l1': 7, 'dropout_1': 0.2710916635501801, 'learning_rate': 0.0530371692023012, 'optimizer': 'Adam'}. Best is trial 7 with value: 0.40639101021819646.
[I 2023-09-17 20:45:06,477] Trial 8 pruned.
[I 2023-09-17 20:45:08,219] Trial 9 pruned.
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (244371, 1270)
Number of total missing values across all columns: 488742
Data Subset Is Off
Wells held out for testing: ['K07' 'L10']
Wells to use for training, validation, and testing ['D06' 'D07' 'K06' 'L05' 'L11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 80.90556005086118
Validation Loss: 0.4067053920692868
Training Accuracy: 77.76525665570928
Training Loss: 0.46698467528648513
completed
