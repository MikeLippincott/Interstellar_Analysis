[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: SHSY5Y control_name: LPS_0.010_DMSO_0.025 treatment_name: Thapsigargin_10.000_DMSO_0.025
[I 2023-09-17 20:31:06,062] A new study created in memory with name: no-name-3cdb450c-df83-4597-8a9e-5121cc50678f
[I 2023-09-17 20:31:15,336] Trial 0 finished with value: 0.39333742737770083 and parameters: {'n_layers': 2, 'n_units_l0': 2, 'dropout_0': 0.18606382302069385, 'n_units_l1': 4, 'dropout_1': 0.24180839595537723, 'learning_rate': 0.0687661662082768, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.39333742737770083.
[I 2023-09-17 20:31:24,902] Trial 1 finished with value: 0.6877039758364358 and parameters: {'n_layers': 3, 'n_units_l0': 10, 'dropout_0': 0.3549841402571733, 'n_units_l1': 10, 'dropout_1': 0.2790242135921972, 'n_units_l2': 10, 'dropout_2': 0.13913269411110812, 'learning_rate': 0.0007257036113023063, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.39333742737770083.
[I 2023-09-17 20:31:34,213] Trial 2 finished with value: 0.5206485271453858 and parameters: {'n_layers': 3, 'n_units_l0': 5, 'dropout_0': 0.37646594267263345, 'n_units_l1': 5, 'dropout_1': 0.14848487834589172, 'n_units_l2': 3, 'dropout_2': 0.14861290299920937, 'learning_rate': 0.0978610225044084, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.39333742737770083.
[I 2023-09-17 20:31:43,571] Trial 3 finished with value: 0.2673241623242696 and parameters: {'n_layers': 3, 'n_units_l0': 8, 'dropout_0': 0.28174511665335644, 'n_units_l1': 10, 'dropout_1': 0.30244816763239224, 'n_units_l2': 3, 'dropout_2': 0.1990765421306001, 'learning_rate': 0.08311190638494068, 'optimizer': 'SGD'}. Best is trial 3 with value: 0.2673241623242696.
[I 2023-09-17 20:31:53,168] Trial 4 finished with value: 0.22784258008003236 and parameters: {'n_layers': 3, 'n_units_l0': 9, 'dropout_0': 0.25433848535687875, 'n_units_l1': 10, 'dropout_1': 0.10445224262192092, 'n_units_l2': 9, 'dropout_2': 0.20788464564310338, 'learning_rate': 0.005569152795096406, 'optimizer': 'Adam'}. Best is trial 4 with value: 0.22784258008003236.
[I 2023-09-17 20:32:02,145] Trial 5 finished with value: 0.22329697916905084 and parameters: {'n_layers': 1, 'n_units_l0': 8, 'dropout_0': 0.37449280516303685, 'learning_rate': 0.05793548279736567, 'optimizer': 'SGD'}. Best is trial 5 with value: 0.22329697916905084.
[I 2023-09-17 20:32:02,311] Trial 6 pruned.
[I 2023-09-17 20:32:10,893] Trial 7 pruned.
[I 2023-09-17 20:32:11,061] Trial 8 pruned.
[I 2023-09-17 20:32:20,805] Trial 9 finished with value: 0.26913549343744914 and parameters: {'n_layers': 3, 'n_units_l0': 7, 'dropout_0': 0.14845721473195123, 'n_units_l1': 10, 'dropout_1': 0.1619295799148235, 'n_units_l2': 7, 'dropout_2': 0.27303203796851444, 'learning_rate': 0.02735350542267638, 'optimizer': 'Adam'}. Best is trial 5 with value: 0.22329697916905084.
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'LPS_0.010_DMSO_0.025']
The dimensions of the data are: (29071, 1276)
Number of total missing values across all columns: 58142
Data Subset Is Off
Wells held out for testing: ['E14' 'B20']
Wells to use for training, validation, and testing ['E15' 'B16' 'B17' 'B21' 'L14' 'L15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 91.6783599088838
Validation Loss: 0.2228928718964259
Training Accuracy: 89.50270516544222
Training Loss: 0.25059871923592353
completed
