[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: SHSY5Y control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025
[I 2023-09-17 19:44:01,028] A new study created in memory with name: no-name-4fff14f0-ce3f-4454-adb1-3130b55822a4
[I 2023-09-17 19:44:09,966] Trial 0 finished with value: 0.3725789054234822 and parameters: {'n_layers': 2, 'n_units_l0': 5, 'dropout_0': 0.39855622004143465, 'n_units_l1': 5, 'dropout_1': 0.39979638486854396, 'learning_rate': 0.02780127308831639, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.3725789054234822.
[I 2023-09-17 19:44:19,191] Trial 1 finished with value: 0.639392975171407 and parameters: {'n_layers': 3, 'n_units_l0': 7, 'dropout_0': 0.14151998143999214, 'n_units_l1': 10, 'dropout_1': 0.22914903527437658, 'n_units_l2': 6, 'dropout_2': 0.3279135469568625, 'learning_rate': 0.09617464246233125, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.3725789054234822.
[I 2023-09-17 19:44:28,192] Trial 2 finished with value: 0.13833596900105477 and parameters: {'n_layers': 2, 'n_units_l0': 4, 'dropout_0': 0.26817706387282914, 'n_units_l1': 6, 'dropout_1': 0.11527795230869804, 'learning_rate': 0.012731171749023187, 'optimizer': 'Adam'}. Best is trial 2 with value: 0.13833596900105477.
[I 2023-09-17 19:44:37,565] Trial 3 finished with value: 0.21385040437181793 and parameters: {'n_layers': 3, 'n_units_l0': 10, 'dropout_0': 0.1969925367402524, 'n_units_l1': 5, 'dropout_1': 0.14906013498287415, 'n_units_l2': 10, 'dropout_2': 0.20675819490713723, 'learning_rate': 0.09443478847392012, 'optimizer': 'Adam'}. Best is trial 2 with value: 0.13833596900105477.
[I 2023-09-17 19:44:46,714] Trial 4 finished with value: 0.2366611620783806 and parameters: {'n_layers': 3, 'n_units_l0': 9, 'dropout_0': 0.11664390075589656, 'n_units_l1': 8, 'dropout_1': 0.36558588020340466, 'n_units_l2': 2, 'dropout_2': 0.37917054805882733, 'learning_rate': 0.039315675542652896, 'optimizer': 'Adam'}. Best is trial 2 with value: 0.13833596900105477.
[I 2023-09-17 19:44:46,967] Trial 5 pruned.
[I 2023-09-17 19:44:47,124] Trial 6 pruned.
[I 2023-09-17 19:44:47,284] Trial 7 pruned.
[I 2023-09-17 19:44:47,447] Trial 8 pruned.
[I 2023-09-17 19:44:56,288] Trial 9 finished with value: 0.16306554406881332 and parameters: {'n_layers': 1, 'n_units_l0': 6, 'dropout_0': 0.18225882848237646, 'learning_rate': 0.038981864585114614, 'optimizer': 'Adam'}. Best is trial 2 with value: 0.13833596900105477.
Selected Catagories are:
['LPS_Nigericin_1.000_3.0_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (29461, 1276)
Number of total missing values across all columns: 31618
Data Subset Is Off
Wells held out for testing: ['L16' 'M22']
Wells to use for training, validation, and testing ['L17' 'M18' 'M19' 'L20' 'L21' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 94.25322283609577
Validation Loss: 0.18558015391230584
Training Accuracy: 92.6813654942145
Training Loss: 0.20202501959270902
completed
