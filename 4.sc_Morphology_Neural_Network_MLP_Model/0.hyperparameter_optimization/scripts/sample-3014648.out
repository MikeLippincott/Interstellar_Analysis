[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 treatment_name: DMSO_0.100_DMSO_0.025
[I 2023-09-17 19:26:36,440] A new study created in memory with name: no-name-a3575952-e690-4518-bdd8-23dca09aff13
[I 2023-09-17 19:29:21,329] Trial 0 finished with value: 0.185288384141344 and parameters: {'n_layers': 3, 'n_units_l0': 2, 'dropout_0': 0.39275827334215696, 'n_units_l1': 9, 'dropout_1': 0.23994990282304468, 'n_units_l2': 10, 'dropout_2': 0.3228503923749372, 'learning_rate': 0.06483894792140002, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.185288384141344.
[I 2023-09-17 19:31:53,849] Trial 1 finished with value: 0.38045958670702845 and parameters: {'n_layers': 3, 'n_units_l0': 8, 'dropout_0': 0.2542506112084427, 'n_units_l1': 2, 'dropout_1': 0.17054547395658087, 'n_units_l2': 7, 'dropout_2': 0.2882983672949917, 'learning_rate': 0.07775277871120827, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.185288384141344.
[I 2023-09-17 19:34:30,586] Trial 2 finished with value: 0.15943908525687275 and parameters: {'n_layers': 2, 'n_units_l0': 9, 'dropout_0': 0.3524453659458089, 'n_units_l1': 3, 'dropout_1': 0.24119318896121764, 'learning_rate': 0.053272902650799064, 'optimizer': 'Adam'}. Best is trial 2 with value: 0.15943908525687275.
[I 2023-09-17 19:36:58,095] Trial 3 finished with value: 0.22087994494221427 and parameters: {'n_layers': 2, 'n_units_l0': 4, 'dropout_0': 0.134510974808417, 'n_units_l1': 4, 'dropout_1': 0.24869221789433715, 'learning_rate': 0.02049741303343954, 'optimizer': 'RMSprop'}. Best is trial 2 with value: 0.15943908525687275.
[I 2023-09-17 19:39:30,925] Trial 4 finished with value: 0.18526989741758865 and parameters: {'n_layers': 2, 'n_units_l0': 4, 'dropout_0': 0.32469554886947505, 'n_units_l1': 5, 'dropout_1': 0.2786355369180949, 'learning_rate': 0.05507197890721239, 'optimizer': 'Adam'}. Best is trial 2 with value: 0.15943908525687275.
[I 2023-09-17 19:39:34,314] Trial 5 pruned.
[I 2023-09-17 19:42:16,599] Trial 6 finished with value: 0.26123964740019856 and parameters: {'n_layers': 3, 'n_units_l0': 10, 'dropout_0': 0.3689392710193763, 'n_units_l1': 10, 'dropout_1': 0.13631976287059266, 'n_units_l2': 2, 'dropout_2': 0.19038805987560678, 'learning_rate': 0.04639672796785772, 'optimizer': 'Adam'}. Best is trial 2 with value: 0.15943908525687275.
[I 2023-09-17 19:44:52,566] Trial 7 finished with value: 0.108218771160552 and parameters: {'n_layers': 2, 'n_units_l0': 7, 'dropout_0': 0.25844158099300457, 'n_units_l1': 9, 'dropout_1': 0.35299203565660087, 'learning_rate': 0.013982147663582658, 'optimizer': 'Adam'}. Best is trial 7 with value: 0.108218771160552.
[I 2023-09-17 19:47:24,592] Trial 8 finished with value: 0.09407740593859644 and parameters: {'n_layers': 1, 'n_units_l0': 10, 'dropout_0': 0.1595517885067207, 'learning_rate': 0.09418706640124454, 'optimizer': 'SGD'}. Best is trial 8 with value: 0.09407740593859644.
[I 2023-09-17 19:49:54,686] Trial 9 finished with value: 0.11260837942813381 and parameters: {'n_layers': 1, 'n_units_l0': 7, 'dropout_0': 0.31840180984681854, 'learning_rate': 0.06803779324913727, 'optimizer': 'SGD'}. Best is trial 8 with value: 0.09407740593859644.
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (396296, 1270)
Number of total missing values across all columns: 430260
Data Subset Is Off
Wells held out for testing: ['J06' 'M08']
Wells to use for training, validation, and testing ['B06' 'C06' 'B07' 'C07' 'I06' 'I07' 'J07' 'M02' 'M03' 'M09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 96.58102108768034
Validation Loss: 0.09314133961769666
Training Accuracy: 96.03197138915225
Training Loss: 0.10545653236170228
completed
