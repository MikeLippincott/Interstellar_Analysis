[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: PBMC control_name: Thapsigargin_1.000_DMSO_0.025 treatment_name: LPS_100.000_DMSO_0.025
[I 2023-09-17 20:15:06,015] A new study created in memory with name: no-name-78884535-7dad-40e7-a287-6d1c7a6e8f44
[I 2023-09-17 20:16:25,060] Trial 0 finished with value: 0.6606227754553159 and parameters: {'n_layers': 1, 'n_units_l0': 4, 'dropout_0': 0.29574621424302416, 'learning_rate': 0.00036089944534165367, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.6606227754553159.
[I 2023-09-17 20:17:50,244] Trial 1 finished with value: 0.36082349259406327 and parameters: {'n_layers': 3, 'n_units_l0': 7, 'dropout_0': 0.17987686503143394, 'n_units_l1': 2, 'dropout_1': 0.35254645378610394, 'n_units_l2': 9, 'dropout_2': 0.20847887449172942, 'learning_rate': 0.0037811661635364226, 'optimizer': 'RMSprop'}. Best is trial 1 with value: 0.36082349259406327.
[I 2023-09-17 20:19:16,099] Trial 2 finished with value: 0.3470128583659728 and parameters: {'n_layers': 3, 'n_units_l0': 9, 'dropout_0': 0.2856008623072118, 'n_units_l1': 2, 'dropout_1': 0.17397710520694476, 'n_units_l2': 8, 'dropout_2': 0.1891012662920989, 'learning_rate': 0.005255330399739439, 'optimizer': 'Adam'}. Best is trial 2 with value: 0.3470128583659728.
[I 2023-09-17 20:20:39,860] Trial 3 finished with value: 0.32135732715949417 and parameters: {'n_layers': 2, 'n_units_l0': 10, 'dropout_0': 0.19639309402697264, 'n_units_l1': 5, 'dropout_1': 0.33789626413612517, 'learning_rate': 0.005148733120326223, 'optimizer': 'RMSprop'}. Best is trial 3 with value: 0.32135732715949417.
[I 2023-09-17 20:22:04,113] Trial 4 finished with value: 0.693531890362501 and parameters: {'n_layers': 3, 'n_units_l0': 4, 'dropout_0': 0.11658033281222677, 'n_units_l1': 8, 'dropout_1': 0.33671537347975866, 'n_units_l2': 6, 'dropout_2': 0.10921692386668302, 'learning_rate': 0.04654314434902466, 'optimizer': 'RMSprop'}. Best is trial 3 with value: 0.32135732715949417.
[I 2023-09-17 20:22:05,728] Trial 5 pruned.
[I 2023-09-17 20:22:07,341] Trial 6 pruned.
[I 2023-09-17 20:22:08,959] Trial 7 pruned.
[I 2023-09-17 20:23:31,627] Trial 8 finished with value: 0.30883411683142187 and parameters: {'n_layers': 1, 'n_units_l0': 10, 'dropout_0': 0.2598493611936171, 'learning_rate': 0.033008453396456625, 'optimizer': 'Adam'}. Best is trial 8 with value: 0.30883411683142187.
[I 2023-09-17 20:23:33,220] Trial 9 pruned.
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (307891, 1270)
Number of total missing values across all columns: 615782
Data Subset Is Off
Wells held out for testing: ['K06' 'J09']
Wells to use for training, validation, and testing ['D06' 'D07' 'J02' 'J03' 'K07' 'J08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 86.81166347992352
Validation Loss: 0.30336370173220834
Training Accuracy: 84.66480161661815
Training Loss: 0.34212821263558146
completed
