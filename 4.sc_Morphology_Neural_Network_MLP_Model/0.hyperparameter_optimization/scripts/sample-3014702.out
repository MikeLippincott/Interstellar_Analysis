[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: SHSY5Y control_name: LPS_0.100_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025
[I 2023-09-17 19:35:39,212] A new study created in memory with name: no-name-c55abbd9-e1aa-47f5-b88c-cca1eb6b2d58
[I 2023-09-17 19:35:48,163] Trial 0 finished with value: 0.6459399338563283 and parameters: {'n_layers': 3, 'n_units_l0': 7, 'dropout_0': 0.10503012268856855, 'n_units_l1': 4, 'dropout_1': 0.3060359830441878, 'n_units_l2': 8, 'dropout_2': 0.2844354077063338, 'learning_rate': 0.06086893284586422, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.6459399338563283.
[I 2023-09-17 19:35:57,082] Trial 1 finished with value: 0.688944981098175 and parameters: {'n_layers': 3, 'n_units_l0': 10, 'dropout_0': 0.1836227946374353, 'n_units_l1': 2, 'dropout_1': 0.1309334026741414, 'n_units_l2': 3, 'dropout_2': 0.3072439692603506, 'learning_rate': 0.07693677464550472, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.6459399338563283.
[I 2023-09-17 19:36:05,896] Trial 2 finished with value: 0.6888340373833973 and parameters: {'n_layers': 2, 'n_units_l0': 7, 'dropout_0': 0.12307418288879177, 'n_units_l1': 4, 'dropout_1': 0.2117292572987485, 'learning_rate': 0.07039313730088449, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.6459399338563283.
[I 2023-09-17 19:36:14,501] Trial 3 finished with value: 0.5620355274279912 and parameters: {'n_layers': 2, 'n_units_l0': 6, 'dropout_0': 0.22212748924892817, 'n_units_l1': 10, 'dropout_1': 0.23748041132007927, 'learning_rate': 0.011061806707893997, 'optimizer': 'RMSprop'}. Best is trial 3 with value: 0.5620355274279912.
[I 2023-09-17 19:36:22,763] Trial 4 finished with value: 0.5693456383546193 and parameters: {'n_layers': 1, 'n_units_l0': 5, 'dropout_0': 0.3115954197645808, 'learning_rate': 0.048219605619988816, 'optimizer': 'SGD'}. Best is trial 3 with value: 0.5620355274279912.
[I 2023-09-17 19:36:22,929] Trial 5 pruned.
[I 2023-09-17 19:36:23,089] Trial 6 pruned.
[I 2023-09-17 19:36:31,499] Trial 7 finished with value: 0.6054126954078675 and parameters: {'n_layers': 1, 'n_units_l0': 2, 'dropout_0': 0.10382859122035348, 'learning_rate': 0.04106093745701164, 'optimizer': 'Adam'}. Best is trial 3 with value: 0.5620355274279912.
[I 2023-09-17 19:36:31,739] Trial 8 pruned.
[I 2023-09-17 19:36:31,891] Trial 9 pruned.
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (32438, 1276)
Number of total missing values across all columns: 64876
Data Subset Is Off
Wells held out for testing: ['C21' 'L22']
Wells to use for training, validation, and testing ['C16' 'C17' 'C20' 'L18' 'L19' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 72.14201680672268
Validation Loss: 0.5699051610628764
Training Accuracy: 76.07765052012189
Training Loss: 0.47335317457467313
completed
