[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8867 bytes to Hyperparameter_Optimization_model_binary.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multiclass.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/nbformat/__init__.py:93: MissingIDFieldWarning: Code cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.
  validate(nb)
[NbConvertApp] Writing 15027 bytes to Hyperparameter_Optimization_model_multiclass.py
[I 2023-12-01 11:14:40,868] A new study created in memory with name: no-name-d38ff153-1d72-4871-87d8-2ba7598106c8
[I 2023-12-01 11:19:27,966] Trial 0 finished with value: 0.9180230050362076 and parameters: {'n_layers': 9, 'n_units_l0': 41, 'dropout_0': 0.2280186741949486, 'n_units_l1': 9, 'dropout_1': 0.3289475411062782, 'n_units_l2': 7, 'dropout_2': 0.13225981643206108, 'n_units_l3': 12, 'dropout_3': 0.32305459316086144, 'n_units_l4': 41, 'dropout_4': 0.14946480675686225, 'n_units_l5': 9, 'dropout_5': 0.17176280525178883, 'n_units_l6': 23, 'dropout_6': 0.12107221731492988, 'n_units_l7': 34, 'dropout_7': 0.33006803506046456, 'n_units_l8': 12, 'dropout_8': 0.21197418758522402, 'learning_rate': 0.05249964252071895, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.9180230050362076.
[I 2023-12-01 11:24:04,560] Trial 1 finished with value: 0.673774131307235 and parameters: {'n_layers': 6, 'n_units_l0': 15, 'dropout_0': 0.289254412823772, 'n_units_l1': 12, 'dropout_1': 0.38455119493192547, 'n_units_l2': 41, 'dropout_2': 0.1995888493393928, 'n_units_l3': 11, 'dropout_3': 0.3598778561696002, 'n_units_l4': 22, 'dropout_4': 0.3773253557536932, 'n_units_l5': 47, 'dropout_5': 0.19982419819962044, 'learning_rate': 0.04949997216158981, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.673774131307235.
[I 2023-12-01 11:28:40,002] Trial 2 finished with value: 0.6566688906458709 and parameters: {'n_layers': 6, 'n_units_l0': 11, 'dropout_0': 0.16562571085295164, 'n_units_l1': 13, 'dropout_1': 0.312692664867101, 'n_units_l2': 50, 'dropout_2': 0.20026095984467346, 'n_units_l3': 42, 'dropout_3': 0.1889278166215465, 'n_units_l4': 29, 'dropout_4': 0.15234185951576767, 'n_units_l5': 42, 'dropout_5': 0.3228548500451476, 'learning_rate': 0.024698871171732324, 'optimizer': 'SGD'}. Best is trial 2 with value: 0.6566688906458709.
[I 2023-12-01 11:32:49,872] Trial 3 finished with value: 0.5464878896872202 and parameters: {'n_layers': 1, 'n_units_l0': 11, 'dropout_0': 0.31446138013848945, 'learning_rate': 0.019093733762032338, 'optimizer': 'SGD'}. Best is trial 3 with value: 0.5464878896872202.
[I 2023-12-01 11:37:19,598] Trial 4 finished with value: 0.9235732422425197 and parameters: {'n_layers': 5, 'n_units_l0': 32, 'dropout_0': 0.3784422964819135, 'n_units_l1': 28, 'dropout_1': 0.19438122959895232, 'n_units_l2': 39, 'dropout_2': 0.20525332665479235, 'n_units_l3': 27, 'dropout_3': 0.2060832063942195, 'n_units_l4': 42, 'dropout_4': 0.1001916159962076, 'learning_rate': 0.09784539943325941, 'optimizer': 'RMSprop'}. Best is trial 3 with value: 0.5464878896872202.
[I 2023-12-01 11:41:49,518] Trial 5 finished with value: 0.5198339093037141 and parameters: {'n_layers': 4, 'n_units_l0': 49, 'dropout_0': 0.23690294676696902, 'n_units_l1': 29, 'dropout_1': 0.1979295827846112, 'n_units_l2': 14, 'dropout_2': 0.2545226984345296, 'n_units_l3': 47, 'dropout_3': 0.13324610844222579, 'learning_rate': 0.00869182482152521, 'optimizer': 'Adam'}. Best is trial 5 with value: 0.5198339093037141.
[I 2023-12-01 11:41:52,496] Trial 6 pruned. 
[I 2023-12-01 11:41:55,327] Trial 7 pruned. 
[I 2023-12-01 11:41:58,102] Trial 8 pruned. 
[I 2023-12-01 11:44:05,482] Trial 9 pruned. 
[I 2023-12-01 11:44:08,720] Trial 10 pruned. 
[I 2023-12-01 11:48:06,952] Trial 11 finished with value: 0.6421953996481039 and parameters: {'n_layers': 2, 'n_units_l0': 4, 'dropout_0': 0.30737441065639326, 'n_units_l1': 24, 'dropout_1': 0.10285901488677945, 'learning_rate': 0.017176121126843014, 'optimizer': 'Adam'}. Best is trial 5 with value: 0.5198339093037141.
[I 2023-12-01 11:52:11,816] Trial 12 finished with value: 0.5360095142171933 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_0': 0.32804778343999724, 'learning_rate': 0.014465278803854592, 'optimizer': 'Adam'}. Best is trial 5 with value: 0.5198339093037141.
[I 2023-12-01 11:56:27,494] Trial 13 finished with value: 0.5264343229165444 and parameters: {'n_layers': 3, 'n_units_l0': 21, 'dropout_0': 0.34279222271480025, 'n_units_l1': 26, 'dropout_1': 0.2714478708956031, 'n_units_l2': 28, 'dropout_2': 0.2742037880075148, 'learning_rate': 0.0013595723188313397, 'optimizer': 'Adam'}. Best is trial 5 with value: 0.5198339093037141.
[I 2023-12-01 11:56:30,104] Trial 14 pruned. 
[I 2023-12-01 11:56:35,477] Trial 15 pruned. 
[I 2023-12-01 11:56:41,013] Trial 16 pruned. 
[I 2023-12-01 12:01:00,905] Trial 17 finished with value: 0.5647042759335958 and parameters: {'n_layers': 3, 'n_units_l0': 44, 'dropout_0': 0.34025637272708387, 'n_units_l1': 35, 'dropout_1': 0.2297267043775595, 'n_units_l2': 17, 'dropout_2': 0.24084502585754838, 'learning_rate': 0.010498765565896115, 'optimizer': 'RMSprop'}. Best is trial 5 with value: 0.5198339093037141.
[I 2023-12-01 12:01:26,724] Trial 18 pruned. 
[I 2023-12-01 12:01:29,852] Trial 19 pruned. 
[I 2023-12-01 12:01:32,660] Trial 20 pruned. 
[I 2023-12-01 12:05:37,912] Trial 21 finished with value: 0.5270277094000425 and parameters: {'n_layers': 1, 'n_units_l0': 22, 'dropout_0': 0.344893138623382, 'learning_rate': 0.009538448374017157, 'optimizer': 'Adam'}. Best is trial 5 with value: 0.5198339093037141.
[I 2023-12-01 12:09:44,161] Trial 22 finished with value: 0.5276448312707437 and parameters: {'n_layers': 1, 'n_units_l0': 25, 'dropout_0': 0.3583083536071602, 'learning_rate': 0.0067153923152283145, 'optimizer': 'Adam'}. Best is trial 5 with value: 0.5198339093037141.
[I 2023-12-01 12:09:46,885] Trial 23 pruned. 
[I 2023-12-01 12:13:57,049] Trial 24 finished with value: 0.5530639354999248 and parameters: {'n_layers': 2, 'n_units_l0': 23, 'dropout_0': 0.36800483243542637, 'n_units_l1': 19, 'dropout_1': 0.15461671231958798, 'learning_rate': 0.02086200044433414, 'optimizer': 'Adam'}. Best is trial 5 with value: 0.5198339093037141.
[I 2023-12-01 12:13:59,606] Trial 25 pruned. 
[I 2023-12-01 12:14:02,220] Trial 26 pruned. 
[I 2023-12-01 12:14:04,851] Trial 27 pruned. 
[I 2023-12-01 12:18:20,587] Trial 28 finished with value: 0.5153092635594881 and parameters: {'n_layers': 2, 'n_units_l0': 33, 'dropout_0': 0.2558914913322639, 'n_units_l1': 38, 'dropout_1': 0.39680291126467204, 'learning_rate': 0.007191174851085008, 'optimizer': 'Adam'}. Best is trial 28 with value: 0.5153092635594881.
[I 2023-12-01 12:18:23,422] Trial 29 pruned. 
[I 2023-12-01 12:18:28,711] Trial 30 pruned. 
[I 2023-12-01 12:22:38,821] Trial 31 finished with value: 0.5647309296559065 and parameters: {'n_layers': 1, 'n_units_l0': 37, 'dropout_0': 0.21403324438419097, 'learning_rate': 0.00650573664942413, 'optimizer': 'Adam'}. Best is trial 28 with value: 0.5153092635594881.
[I 2023-12-01 12:26:54,438] Trial 32 finished with value: 0.5282449283813819 and parameters: {'n_layers': 2, 'n_units_l0': 33, 'dropout_0': 0.28505707052126306, 'n_units_l1': 44, 'dropout_1': 0.33960723084723415, 'learning_rate': 0.013743738993292053, 'optimizer': 'Adam'}. Best is trial 28 with value: 0.5153092635594881.
[I 2023-12-01 12:26:57,140] Trial 33 pruned. 
[I 2023-12-01 12:26:59,775] Trial 34 pruned. 
[I 2023-12-01 12:27:04,828] Trial 35 pruned. 
[I 2023-12-01 12:27:07,379] Trial 36 pruned. 
[I 2023-12-01 12:27:10,119] Trial 37 pruned. 
[I 2023-12-01 12:27:12,832] Trial 38 pruned. 
[I 2023-12-01 12:27:15,745] Trial 39 pruned. 
[I 2023-12-01 12:27:23,650] Trial 40 pruned. 
[I 2023-12-01 12:31:30,289] Trial 41 finished with value: 0.5259009749614276 and parameters: {'n_layers': 1, 'n_units_l0': 25, 'dropout_0': 0.3560891409349943, 'learning_rate': 0.005504385340532992, 'optimizer': 'Adam'}. Best is trial 28 with value: 0.5153092635594881.
[I 2023-12-01 12:31:32,769] Trial 42 pruned. 
[I 2023-12-01 12:31:37,725] Trial 43 pruned. 
[I 2023-12-01 12:32:12,654] Trial 44 pruned. 
[I 2023-12-01 12:33:09,228] Trial 45 pruned. 
[I 2023-12-01 12:33:11,844] Trial 46 pruned. 
[I 2023-12-01 12:33:14,403] Trial 47 pruned. 
[I 2023-12-01 12:33:17,398] Trial 48 pruned. 
[I 2023-12-01 12:37:29,088] Trial 49 finished with value: 0.523267203454788 and parameters: {'n_layers': 1, 'n_units_l0': 15, 'dropout_0': 0.3155810853856968, 'learning_rate': 0.002191192663494489, 'optimizer': 'Adam'}. Best is trial 28 with value: 0.5153092635594881.
Data Subset Is Off
Wells held out for testing: ['F14' 'D15' 'G17' 'H17' 'D18' 'E18' 'B19' 'G19' 'D20' 'F20' 'B21' 'C21'
 'E21' 'F22' 'H22' 'C23' 'J13' 'K13' 'L13' 'I14' 'L14' 'N14' 'O15' 'J16'
 'N16' 'O17' 'I18' 'L18' 'M18' 'O18' 'I20' 'K20' 'L21' 'M21' 'N22' 'O22'
 'J23' 'K23']
Wells to use for training, validation, and testing ['B13' 'C13' 'D13' 'E13' 'F13' 'G13' 'H13' 'B14' 'C14' 'D14' 'E14' 'F14'
 'G14' 'H14' 'B15' 'C15' 'D15' 'E15' 'F15' 'G15' 'H15' 'B16' 'C16' 'D16'
 'E16' 'F16' 'G16' 'H16' 'B17' 'C17' 'D17' 'E17' 'F17' 'G17' 'H17' 'B18'
 'C18' 'D18' 'E18' 'F18' 'G18' 'H18' 'B19' 'C19' 'D19' 'E19' 'F19' 'G19'
 'H19' 'B20' 'C20' 'D20' 'E20' 'F20' 'G20' 'H20' 'B21' 'C21' 'D21' 'E21'
 'F21' 'G21' 'H21' 'B22' 'C22' 'D22' 'E22' 'F22' 'G22' 'H22' 'B23' 'C23'
 'D23' 'E23' 'F23' 'G23' 'H23' 'I13' 'J13' 'K13' 'L13' 'M13' 'N13' 'O13'
 'I14' 'J14' 'K14' 'L14' 'M14' 'N14' 'O14' 'I15' 'J15' 'K15' 'L15' 'M15'
 'N15' 'O15' 'I16' 'J16' 'K16' 'L16' 'M16' 'N16' 'O16' 'I17' 'J17' 'K17'
 'L17' 'M17' 'N17' 'O17' 'I18' 'J18' 'K18' 'L18' 'M18' 'N18' 'O18' 'I19'
 'J19' 'K19' 'L19' 'M19' 'N19' 'O19' 'I20' 'J20' 'K20' 'L20' 'M20' 'N20'
 'O20' 'I21' 'J21' 'K21' 'L21' 'M21' 'N21' 'O21' 'I22' 'J22' 'K22' 'L22'
 'M22' 'N22' 'O22' 'I23' 'J23' 'K23' 'L23' 'M23' 'N23' 'O23']
(54607, 1277) (23407, 1277) (368987, 1277)
Shape for the 100% test set: (54607, 1277)

Shape for the 75% test set: (5851, 1277);
Shape for the 75% train set: (17556, 1277)

Shape for the 50% test set: (184493, 1277);
Shape for the 50% train set: (184494, 1277)
Shape for the holdout set: (150901, 1277)

    Testing set length: 202050

    Training set length: 152275

    Validation set length: 38069

    Treatment Holdout set length: 54607

    Holdout set length: 150901
(152275,) (38069,) (202050,) (54607,) (150901,)
597902
../indexes/SHSY5Y/multi_class
['apoptosis' 'healthy' 'pyroptosis'] [ 26978 295773 275151]
[0, 1, 2] [0.954878893196544, 0.505315252332322, 0.539805854471134]
Number of in features:  1251
Number of out features:  3
Multi_Class
cpu
Validation Accuracy: 78.15689931440279
Validation Loss: 0.5204968059062958
Training Accuracy: 79.65479560006567
Training Loss: 0.46276238932134284
Done
