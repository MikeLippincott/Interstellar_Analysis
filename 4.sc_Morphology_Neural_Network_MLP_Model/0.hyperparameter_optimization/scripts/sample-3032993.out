[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: PBMC control_name: DMSO_0.100_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025
[I 2023-09-19 00:16:01,838] A new study created in memory with name: no-name-a124de62-9328-4f33-bfe1-9b1afb9916dc
[I 2023-09-19 00:17:40,516] Trial 0 finished with value: 0.5621457145993527 and parameters: {'n_layers': 2, 'n_units_l0': 6, 'dropout_0': 0.13169438639365771, 'n_units_l1': 7, 'dropout_1': 0.1289114641967331, 'learning_rate': 0.09816974076842705, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.5621457145993527.
[I 2023-09-19 00:19:18,464] Trial 1 finished with value: 0.38530441845838836 and parameters: {'n_layers': 3, 'n_units_l0': 5, 'dropout_0': 0.3533953923900882, 'n_units_l1': 7, 'dropout_1': 0.11848838592083419, 'n_units_l2': 7, 'dropout_2': 0.30117462107995907, 'learning_rate': 0.05261348362135998, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.38530441845838836.
[I 2023-09-19 00:20:57,196] Trial 2 finished with value: 0.5537783871017968 and parameters: {'n_layers': 2, 'n_units_l0': 6, 'dropout_0': 0.12073846001448228, 'n_units_l1': 10, 'dropout_1': 0.31260297797371306, 'learning_rate': 0.04774854406708208, 'optimizer': 'RMSprop'}. Best is trial 1 with value: 0.38530441845838836.
[I 2023-09-19 00:22:38,878] Trial 3 finished with value: 0.562675968316885 and parameters: {'n_layers': 3, 'n_units_l0': 6, 'dropout_0': 0.2381054883948556, 'n_units_l1': 3, 'dropout_1': 0.26945211260422575, 'n_units_l2': 5, 'dropout_2': 0.29288623542959324, 'learning_rate': 0.06266304639803909, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.38530441845838836.
[I 2023-09-19 00:24:16,242] Trial 4 finished with value: 0.39399180079881957 and parameters: {'n_layers': 2, 'n_units_l0': 2, 'dropout_0': 0.3776924972260285, 'n_units_l1': 10, 'dropout_1': 0.216045111079889, 'learning_rate': 0.0965740451534897, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.38530441845838836.
[I 2023-09-19 00:25:51,560] Trial 5 finished with value: 0.3390528214207062 and parameters: {'n_layers': 1, 'n_units_l0': 9, 'dropout_0': 0.36044250717419823, 'learning_rate': 0.05090811003207771, 'optimizer': 'SGD'}. Best is trial 5 with value: 0.3390528214207062.
[I 2023-09-19 00:25:53,583] Trial 6 pruned.
[I 2023-09-19 00:27:28,813] Trial 7 finished with value: 0.35305816556398684 and parameters: {'n_layers': 1, 'n_units_l0': 4, 'dropout_0': 0.37393184376958266, 'learning_rate': 0.08726942551068352, 'optimizer': 'SGD'}. Best is trial 5 with value: 0.3390528214207062.
[I 2023-09-19 00:29:10,237] Trial 8 finished with value: 0.35620768787769175 and parameters: {'n_layers': 3, 'n_units_l0': 5, 'dropout_0': 0.22922137057269049, 'n_units_l1': 10, 'dropout_1': 0.25082829058807293, 'n_units_l2': 6, 'dropout_2': 0.24682743727145126, 'learning_rate': 0.02783921910773305, 'optimizer': 'Adam'}. Best is trial 5 with value: 0.3390528214207062.
[I 2023-09-19 00:29:12,207] Trial 9 pruned.
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (311045, 1270)
Number of total missing values across all columns: 622090
Data Subset Is Off
Wells held out for testing: ['J06' 'L10']
Wells to use for training, validation, and testing ['B06' 'C06' 'B07' 'C07' 'I06' 'I07' 'J07' 'L05' 'L11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 84.62119094213028
Validation Loss: 0.33576307303630387
Training Accuracy: 83.3507233932084
Training Loss: 0.36509082053727776
completed
