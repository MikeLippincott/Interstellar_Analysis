[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: Thapsigargin_1.000_DMSO_0.025
[I 2023-09-19 01:31:50,058] A new study created in memory with name: no-name-256052d8-2d7d-4f55-91c3-ae0b971227f2
[I 2023-09-19 01:33:15,544] Trial 0 finished with value: 0.3729008726119995 and parameters: {'n_layers': 2, 'n_units_l0': 8, 'dropout_0': 0.11234277907344731, 'n_units_l1': 9, 'dropout_1': 0.3932941153463465, 'learning_rate': 0.07024288413000994, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.3729008726119995.
[I 2023-09-19 01:34:39,901] Trial 1 finished with value: 0.20590190441012385 and parameters: {'n_layers': 1, 'n_units_l0': 10, 'dropout_0': 0.2219944873897595, 'learning_rate': 0.05484041410310579, 'optimizer': 'RMSprop'}. Best is trial 1 with value: 0.20590190441012385.
[I 2023-09-19 01:36:03,068] Trial 2 finished with value: 0.14637603731751445 and parameters: {'n_layers': 1, 'n_units_l0': 8, 'dropout_0': 0.3271624031262008, 'learning_rate': 0.06588802712415369, 'optimizer': 'Adam'}. Best is trial 2 with value: 0.14637603731751445.
[I 2023-09-19 01:37:27,222] Trial 3 finished with value: 0.3282438968896866 and parameters: {'n_layers': 1, 'n_units_l0': 10, 'dropout_0': 0.19014892405297995, 'learning_rate': 0.07962103873085716, 'optimizer': 'RMSprop'}. Best is trial 2 with value: 0.14637603731751445.
[I 2023-09-19 01:38:49,029] Trial 4 finished with value: 0.1238634069442749 and parameters: {'n_layers': 1, 'n_units_l0': 9, 'dropout_0': 0.1972304271877255, 'learning_rate': 0.07987402960709279, 'optimizer': 'SGD'}. Best is trial 4 with value: 0.1238634069442749.
[I 2023-09-19 01:38:50,565] Trial 5 pruned.
[I 2023-09-19 01:38:52,334] Trial 6 pruned.
[I 2023-09-19 01:38:53,933] Trial 7 pruned.
[I 2023-09-19 01:40:18,923] Trial 8 finished with value: 0.13583832100629806 and parameters: {'n_layers': 1, 'n_units_l0': 7, 'dropout_0': 0.3955127343256041, 'learning_rate': 0.021236006846305718, 'optimizer': 'Adam'}. Best is trial 4 with value: 0.1238634069442749.
[I 2023-09-19 01:41:48,063] Trial 9 finished with value: 0.1149097896695137 and parameters: {'n_layers': 3, 'n_units_l0': 9, 'dropout_0': 0.16534893390939953, 'n_units_l1': 7, 'dropout_1': 0.18261459504632932, 'n_units_l2': 5, 'dropout_2': 0.11942213143179284, 'learning_rate': 0.012985854411027209, 'optimizer': 'Adam'}. Best is trial 9 with value: 0.1149097896695137.
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (322717, 1270)
Number of total missing values across all columns: 296912
Data Subset Is Off
Wells held out for testing: ['K06' 'L09']
Wells to use for training, validation, and testing ['D06' 'D07' 'K07' 'L02' 'L03' 'L08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 95.68936998297251
Validation Loss: 0.10977644022107125
Training Accuracy: 94.85590488932134
Training Loss: 0.13538175684785603
completed
