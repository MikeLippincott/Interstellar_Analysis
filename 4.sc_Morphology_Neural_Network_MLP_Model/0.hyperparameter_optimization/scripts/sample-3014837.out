[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: SHSY5Y control_name: Flagellin_0.100_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_10.0_DMSO_0.025
[I 2023-09-17 20:06:10,162] A new study created in memory with name: no-name-5712f11d-9fe8-4751-a052-4a5609b52d8a
[I 2023-09-17 20:06:20,329] Trial 0 finished with value: 0.3676977676153183 and parameters: {'n_layers': 3, 'n_units_l0': 6, 'dropout_0': 0.2953348138068126, 'n_units_l1': 6, 'dropout_1': 0.14834856688070813, 'n_units_l2': 2, 'dropout_2': 0.32540167711267987, 'learning_rate': 0.03847135550722303, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.3676977676153183.
[I 2023-09-17 20:06:29,617] Trial 1 finished with value: 0.17249412760138508 and parameters: {'n_layers': 2, 'n_units_l0': 9, 'dropout_0': 0.19398363335644597, 'n_units_l1': 9, 'dropout_1': 0.2444966258876469, 'learning_rate': 0.0763031390257413, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.17249412760138508.
[I 2023-09-17 20:06:38,665] Trial 2 finished with value: 0.19724423060814542 and parameters: {'n_layers': 1, 'n_units_l0': 6, 'dropout_0': 0.39908278323224644, 'learning_rate': 0.06045567892673597, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.17249412760138508.
[I 2023-09-17 20:06:48,118] Trial 3 finished with value: 0.4324174811442693 and parameters: {'n_layers': 3, 'n_units_l0': 5, 'dropout_0': 0.3635434880348377, 'n_units_l1': 3, 'dropout_1': 0.2674550176616703, 'n_units_l2': 8, 'dropout_2': 0.31983647476569804, 'learning_rate': 0.0817414477462583, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.17249412760138508.
[I 2023-09-17 20:06:57,155] Trial 4 finished with value: 0.1787431127826373 and parameters: {'n_layers': 1, 'n_units_l0': 8, 'dropout_0': 0.23540610003284587, 'learning_rate': 0.046688854554403025, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.17249412760138508.
[I 2023-09-17 20:06:57,321] Trial 5 pruned.
[I 2023-09-17 20:06:57,495] Trial 6 pruned.
[I 2023-09-17 20:07:06,374] Trial 7 finished with value: 0.1460406157374382 and parameters: {'n_layers': 1, 'n_units_l0': 9, 'dropout_0': 0.3106177932206867, 'learning_rate': 0.07388105129895332, 'optimizer': 'SGD'}. Best is trial 7 with value: 0.1460406157374382.
[I 2023-09-17 20:07:06,548] Trial 8 pruned.
[I 2023-09-17 20:07:06,712] Trial 9 pruned.
Selected Catagories are:
['LPS_Nigericin_1.000_10.0_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (29330, 1276)
Number of total missing values across all columns: 29856
Data Subset Is Off
Wells held out for testing: ['M16' 'L22']
Wells to use for training, validation, and testing ['M17' 'L18' 'L19' 'M20' 'M21' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 95.0974695407685
Validation Loss: 0.14647245218356453
Training Accuracy: 93.68097943881436
Training Loss: 0.17291071542435227
completed
