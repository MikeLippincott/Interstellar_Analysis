[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: Thapsigargin_10.000_DMSO_0.025
[I 2023-09-19 01:28:03,647] A new study created in memory with name: no-name-8759d164-5b5a-4c65-861f-a1dae4ad0b08
[I 2023-09-19 01:29:51,289] Trial 0 finished with value: 0.05583709926129534 and parameters: {'n_layers': 2, 'n_units_l0': 9, 'dropout_0': 0.2108490355565105, 'n_units_l1': 5, 'dropout_1': 0.17173393239784712, 'learning_rate': 0.012876826595968692, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.05583709926129534.
[I 2023-09-19 01:31:36,641] Trial 1 finished with value: 0.1161946861531872 and parameters: {'n_layers': 1, 'n_units_l0': 4, 'dropout_0': 0.28320966360011224, 'learning_rate': 0.08278810798634642, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.05583709926129534.
[I 2023-09-19 01:33:24,595] Trial 2 finished with value: 0.1103196965989012 and parameters: {'n_layers': 3, 'n_units_l0': 4, 'dropout_0': 0.3178282782562163, 'n_units_l1': 3, 'dropout_1': 0.2775392427279726, 'n_units_l2': 10, 'dropout_2': 0.18538129091633493, 'learning_rate': 0.043478078632785924, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.05583709926129534.
[I 2023-09-19 01:35:09,993] Trial 3 finished with value: 0.1348495694077932 and parameters: {'n_layers': 1, 'n_units_l0': 3, 'dropout_0': 0.348255164076379, 'learning_rate': 0.012755934030859001, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.05583709926129534.
[I 2023-09-19 01:37:00,606] Trial 4 finished with value: 0.12093118865329484 and parameters: {'n_layers': 3, 'n_units_l0': 6, 'dropout_0': 0.37170443618163473, 'n_units_l1': 6, 'dropout_1': 0.15673503161937577, 'n_units_l2': 5, 'dropout_2': 0.310796398996702, 'learning_rate': 0.06464030960430757, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.05583709926129534.
[I 2023-09-19 01:38:47,692] Trial 5 finished with value: 0.11105326107201668 and parameters: {'n_layers': 1, 'n_units_l0': 10, 'dropout_0': 0.27274389400673216, 'learning_rate': 0.07798183699505158, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.05583709926129534.
[I 2023-09-19 01:38:49,795] Trial 6 pruned.
[I 2023-09-19 01:40:38,895] Trial 7 finished with value: 0.08401280584243627 and parameters: {'n_layers': 2, 'n_units_l0': 9, 'dropout_0': 0.2346733984073144, 'n_units_l1': 7, 'dropout_1': 0.11431361891997105, 'learning_rate': 0.06672125631881998, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.05583709926129534.
[I 2023-09-19 01:40:41,028] Trial 8 pruned.
[I 2023-09-19 01:40:43,271] Trial 9 pruned.
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (341245, 1270)
Number of total missing values across all columns: 333968
Data Subset Is Off
Wells held out for testing: ['L06' 'L09']
Wells to use for training, validation, and testing ['E06' 'E07' 'L02' 'L03' 'L07' 'L08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 98.07346970341442
Validation Loss: 0.06021162451173251
Training Accuracy: 97.14072205062764
Training Loss: 0.08554818169434288
completed
