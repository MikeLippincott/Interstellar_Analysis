[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_1.0_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_1.0_DMSO_0.025
[I 2023-09-19 00:51:52,990] A new study created in memory with name: no-name-1ba7bb67-a7f0-4aa0-b19f-2e0606ca717c
[I 2023-09-19 00:52:45,846] Trial 0 finished with value: 1.6902715786082645e-06 and parameters: {'n_layers': 1, 'n_units_l0': 6, 'dropout_0': 0.38296424793652817, 'learning_rate': 0.0660844513226218, 'optimizer': 'Adam'}. Best is trial 0 with value: 1.6902715786082645e-06.
[I 2023-09-19 00:53:38,539] Trial 1 finished with value: 6.232619194511594e-05 and parameters: {'n_layers': 2, 'n_units_l0': 5, 'dropout_0': 0.3008381276145054, 'n_units_l1': 6, 'dropout_1': 0.11592935438891905, 'learning_rate': 0.03084828077085134, 'optimizer': 'SGD'}. Best is trial 0 with value: 1.6902715786082645e-06.
[I 2023-09-19 00:54:32,263] Trial 2 finished with value: 2.354329379626891e-05 and parameters: {'n_layers': 1, 'n_units_l0': 8, 'dropout_0': 0.34346801202702437, 'learning_rate': 0.08297098584566168, 'optimizer': 'Adam'}. Best is trial 0 with value: 1.6902715786082645e-06.
[I 2023-09-19 00:55:26,371] Trial 3 finished with value: 3.7887633812367244e-07 and parameters: {'n_layers': 2, 'n_units_l0': 3, 'dropout_0': 0.16704059351054945, 'n_units_l1': 6, 'dropout_1': 0.18424860630229375, 'learning_rate': 0.057056802229836806, 'optimizer': 'Adam'}. Best is trial 3 with value: 3.7887633812367244e-07.
[I 2023-09-19 00:56:19,389] Trial 4 finished with value: 1.7741743133593781 and parameters: {'n_layers': 1, 'n_units_l0': 10, 'dropout_0': 0.29902438475306004, 'learning_rate': 0.0992551497164143, 'optimizer': 'Adam'}. Best is trial 3 with value: 3.7887633812367244e-07.
[I 2023-09-19 00:57:12,198] Trial 5 finished with value: 2.0255129991960472e-05 and parameters: {'n_layers': 1, 'n_units_l0': 6, 'dropout_0': 0.38392327080191513, 'learning_rate': 0.05590120050675064, 'optimizer': 'Adam'}. Best is trial 3 with value: 3.7887633812367244e-07.
[I 2023-09-19 00:58:07,216] Trial 6 finished with value: 2.4161168951651283e-06 and parameters: {'n_layers': 3, 'n_units_l0': 3, 'dropout_0': 0.1286765538522245, 'n_units_l1': 8, 'dropout_1': 0.24573380586384266, 'n_units_l2': 9, 'dropout_2': 0.2769627921330147, 'learning_rate': 0.06296583175710671, 'optimizer': 'SGD'}. Best is trial 3 with value: 3.7887633812367244e-07.
[I 2023-09-19 00:58:08,234] Trial 7 pruned.
[I 2023-09-19 00:58:16,785] Trial 8 pruned.
[I 2023-09-19 00:58:17,962] Trial 9 pruned.
Selected Catagories are:
['LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (166013, 1270)
Number of total missing values across all columns: 0
Data Subset Is Off
Wells held out for testing: ['K08']
Wells to use for training, validation, and testing ['K02' 'K03' 'K09']
Number of in features:  1245
Number of out features:  1
Regression
cpu
Validation Loss: 4.87889683317464e-08
Training Loss: 0.0007558737623193805
completed
