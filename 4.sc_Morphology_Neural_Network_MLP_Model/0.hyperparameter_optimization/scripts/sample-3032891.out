[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_3.0_DMSO_0.025 treatment_name: DMSO_0.100_DMSO_0.025
[I 2023-09-18 23:40:02,074] A new study created in memory with name: no-name-f74ce7ee-c090-4630-a0d5-dd81d840d9f0
[I 2023-09-18 23:42:01,516] Trial 0 finished with value: 0.08439009578432888 and parameters: {'n_layers': 2, 'n_units_l0': 10, 'dropout_0': 0.3809125640351575, 'n_units_l1': 3, 'dropout_1': 0.2871245434545394, 'learning_rate': 0.08449943728057348, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.08439009578432888.
[I 2023-09-18 23:44:01,073] Trial 1 finished with value: 0.43452760981861505 and parameters: {'n_layers': 2, 'n_units_l0': 5, 'dropout_0': 0.2569085254074115, 'n_units_l1': 8, 'dropout_1': 0.2907610402032147, 'learning_rate': 0.08852758827944411, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.08439009578432888.
[I 2023-09-18 23:46:00,058] Trial 2 finished with value: 0.08746877091471106 and parameters: {'n_layers': 3, 'n_units_l0': 5, 'dropout_0': 0.10839893375265985, 'n_units_l1': 8, 'dropout_1': 0.11165818547420693, 'n_units_l2': 5, 'dropout_2': 0.22429464001460586, 'learning_rate': 0.09859689423007993, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.08439009578432888.
[I 2023-09-18 23:48:03,786] Trial 3 finished with value: 0.1597308680601418 and parameters: {'n_layers': 3, 'n_units_l0': 6, 'dropout_0': 0.1300672016822013, 'n_units_l1': 3, 'dropout_1': 0.20638188010876776, 'n_units_l2': 10, 'dropout_2': 0.13526173053372026, 'learning_rate': 0.07652582455528963, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.08439009578432888.
[I 2023-09-18 23:50:00,022] Trial 4 finished with value: 0.2372360006906092 and parameters: {'n_layers': 1, 'n_units_l0': 4, 'dropout_0': 0.3930171445088023, 'learning_rate': 0.002919742536061394, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.08439009578432888.
[I 2023-09-18 23:51:57,804] Trial 5 finished with value: 0.10597468239720911 and parameters: {'n_layers': 1, 'n_units_l0': 7, 'dropout_0': 0.14233716155277926, 'learning_rate': 0.04108652315171144, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.08439009578432888.
[I 2023-09-18 23:53:56,588] Trial 6 finished with value: 0.09070301369996742 and parameters: {'n_layers': 1, 'n_units_l0': 7, 'dropout_0': 0.17986926684642812, 'learning_rate': 0.05880884144005861, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.08439009578432888.
[I 2023-09-18 23:56:00,573] Trial 7 finished with value: 0.09038671833695844 and parameters: {'n_layers': 3, 'n_units_l0': 8, 'dropout_0': 0.3032872663189105, 'n_units_l1': 4, 'dropout_1': 0.3255894539431845, 'n_units_l2': 5, 'dropout_2': 0.11429731398922537, 'learning_rate': 0.03687970284736745, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.08439009578432888.
[I 2023-09-18 23:58:02,815] Trial 8 finished with value: 0.08099086295813322 and parameters: {'n_layers': 2, 'n_units_l0': 9, 'dropout_0': 0.30225545821193006, 'n_units_l1': 9, 'dropout_1': 0.3145629084483696, 'learning_rate': 0.0247844421519948, 'optimizer': 'Adam'}. Best is trial 8 with value: 0.08099086295813322.
[I 2023-09-18 23:58:19,958] Trial 9 pruned.
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (389391, 1270)
Number of total missing values across all columns: 430260
Data Subset Is Off
Wells held out for testing: ['J06' 'L08']
Wells to use for training, validation, and testing ['B06' 'C06' 'B07' 'C07' 'I06' 'I07' 'J07' 'L02' 'L03' 'L09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 96.97127970517218
Validation Loss: 0.08109471833333373
Training Accuracy: 95.85027362334496
Training Loss: 0.11555735081168157
completed
