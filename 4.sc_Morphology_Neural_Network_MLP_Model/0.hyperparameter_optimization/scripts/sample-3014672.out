[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: SHSY5Y control_name: DMSO_0.100_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025
[I 2023-09-17 19:27:46,906] A new study created in memory with name: no-name-84d9ea26-b459-4bc9-b4a9-5496937246e7
[I 2023-09-17 19:28:08,128] Trial 0 finished with value: 0.5197967814207076 and parameters: {'n_layers': 3, 'n_units_l0': 7, 'dropout_0': 0.23051707871620541, 'n_units_l1': 10, 'dropout_1': 0.28388542839248326, 'n_units_l2': 9, 'dropout_2': 0.2523223822162482, 'learning_rate': 0.06849222657745349, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.5197967814207076.
[I 2023-09-17 19:28:26,660] Trial 1 finished with value: 0.49359846270084384 and parameters: {'n_layers': 1, 'n_units_l0': 4, 'dropout_0': 0.1456794462694575, 'learning_rate': 0.08286920751420172, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.49359846270084384.
[I 2023-09-17 19:28:47,714] Trial 2 finished with value: 0.48675089323520665 and parameters: {'n_layers': 1, 'n_units_l0': 7, 'dropout_0': 0.13504920224918765, 'learning_rate': 0.08714131636877248, 'optimizer': 'SGD'}. Best is trial 2 with value: 0.48675089323520665.
[I 2023-09-17 19:29:10,909] Trial 3 finished with value: 0.5333035031557083 and parameters: {'n_layers': 3, 'n_units_l0': 10, 'dropout_0': 0.26715720773313284, 'n_units_l1': 8, 'dropout_1': 0.20513855085859845, 'n_units_l2': 7, 'dropout_2': 0.12866746582539446, 'learning_rate': 0.04393510043641683, 'optimizer': 'SGD'}. Best is trial 2 with value: 0.48675089323520665.
[I 2023-09-17 19:29:31,195] Trial 4 finished with value: 0.48117199456691745 and parameters: {'n_layers': 1, 'n_units_l0': 10, 'dropout_0': 0.2314564577531046, 'learning_rate': 0.05746721679246755, 'optimizer': 'SGD'}. Best is trial 4 with value: 0.48117199456691745.
[I 2023-09-17 19:29:31,509] Trial 5 pruned.
[I 2023-09-17 19:29:32,312] Trial 6 pruned.
[I 2023-09-17 19:29:51,173] Trial 7 finished with value: 0.4912067155838013 and parameters: {'n_layers': 2, 'n_units_l0': 8, 'dropout_0': 0.24396988701565375, 'n_units_l1': 10, 'dropout_1': 0.18968099453701218, 'learning_rate': 0.0038448488067709236, 'optimizer': 'RMSprop'}. Best is trial 4 with value: 0.48117199456691745.
[I 2023-09-17 19:29:51,545] Trial 8 pruned.
[I 2023-09-17 19:29:51,985] Trial 9 pruned.
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (50571, 1276)
Number of total missing values across all columns: 101142
Data Subset Is Off
Wells held out for testing: ['I14' 'L23']
Wells to use for training, validation, and testing ['B14' 'C14' 'B15' 'C15' 'J14' 'I15' 'J15' 'L18' 'L19' 'L22']
Number of in features:  1251
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 76.28000939628848
Validation Loss: 0.4852275211811065
Training Accuracy: 77.95195442130921
Training Loss: 0.4543784073037761
completed
