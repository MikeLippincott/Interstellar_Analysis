[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: PBMC control_name: LPS_0.010_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025
[I 2023-09-19 00:31:51,624] A new study created in memory with name: no-name-7de934f0-689a-4257-9c28-eda5526a2562
[I 2023-09-19 00:32:49,847] Trial 0 finished with value: 0.4308678338106941 and parameters: {'n_layers': 2, 'n_units_l0': 7, 'dropout_0': 0.3880011660368651, 'n_units_l1': 5, 'dropout_1': 0.39343805011484634, 'learning_rate': 0.07854347821643053, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4308678338106941.
[I 2023-09-19 00:33:49,796] Trial 1 finished with value: 0.6439125399729785 and parameters: {'n_layers': 2, 'n_units_l0': 10, 'dropout_0': 0.23923823267767796, 'n_units_l1': 2, 'dropout_1': 0.23965018495663132, 'learning_rate': 0.07066343091901578, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4308678338106941.
[I 2023-09-19 00:34:45,892] Trial 2 finished with value: 0.4166622793323853 and parameters: {'n_layers': 1, 'n_units_l0': 6, 'dropout_0': 0.2897601560818265, 'learning_rate': 0.05917340576390679, 'optimizer': 'SGD'}. Best is trial 2 with value: 0.4166622793323853.
[I 2023-09-19 00:35:47,437] Trial 3 finished with value: 0.6597190073658438 and parameters: {'n_layers': 3, 'n_units_l0': 7, 'dropout_0': 0.3661860382441694, 'n_units_l1': 10, 'dropout_1': 0.1850941926696333, 'n_units_l2': 8, 'dropout_2': 0.1311503132793825, 'learning_rate': 0.08598258165031834, 'optimizer': 'Adam'}. Best is trial 2 with value: 0.4166622793323853.
[I 2023-09-19 00:36:46,001] Trial 4 finished with value: 0.45551580916432777 and parameters: {'n_layers': 3, 'n_units_l0': 4, 'dropout_0': 0.22283983424930812, 'n_units_l1': 8, 'dropout_1': 0.22415035955811924, 'n_units_l2': 10, 'dropout_2': 0.19963280057368854, 'learning_rate': 0.09408304814597435, 'optimizer': 'SGD'}. Best is trial 2 with value: 0.4166622793323853.
[I 2023-09-19 00:37:44,241] Trial 5 finished with value: 0.37159403176868666 and parameters: {'n_layers': 1, 'n_units_l0': 7, 'dropout_0': 0.2419776886978042, 'learning_rate': 0.0046469060456015565, 'optimizer': 'Adam'}. Best is trial 5 with value: 0.37159403176868666.
[I 2023-09-19 00:37:45,491] Trial 6 pruned.
[I 2023-09-19 00:37:46,604] Trial 7 pruned.
[I 2023-09-19 00:37:51,116] Trial 8 pruned.
[I 2023-09-19 00:37:52,354] Trial 9 pruned.
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (238995, 1270)
Number of total missing values across all columns: 477990
Data Subset Is Off
Wells held out for testing: ['B09' 'L10']
Wells to use for training, validation, and testing ['B02' 'B03' 'B08' 'L05' 'L11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 82.9344329896907
Validation Loss: 0.3666935309592415
Training Accuracy: 80.97983680923765
Training Loss: 0.3959926625560311
completed
