[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: PBMC control_name: Thapsigargin_1.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_10.0_DMSO_0.025
[I 2023-09-17 20:10:22,732] A new study created in memory with name: no-name-c8663564-8da7-4c5f-9643-ffbf89789f3c
[I 2023-09-17 20:11:53,072] Trial 0 finished with value: 0.19984891707301142 and parameters: {'n_layers': 3, 'n_units_l0': 9, 'dropout_0': 0.23390820614909988, 'n_units_l1': 9, 'dropout_1': 0.27411345852669555, 'n_units_l2': 9, 'dropout_2': 0.19922025377916824, 'learning_rate': 0.035137471919639174, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.19984891707301142.
[I 2023-09-17 20:13:17,893] Trial 1 finished with value: 0.12613435568809508 and parameters: {'n_layers': 1, 'n_units_l0': 8, 'dropout_0': 0.3764557558687356, 'learning_rate': 0.07913203434094378, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.12613435568809508.
[I 2023-09-17 20:14:45,289] Trial 2 finished with value: 0.13848466330766676 and parameters: {'n_layers': 2, 'n_units_l0': 10, 'dropout_0': 0.36479700772078605, 'n_units_l1': 10, 'dropout_1': 0.38998304705624987, 'learning_rate': 0.054874200219821125, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.12613435568809508.
[I 2023-09-17 20:16:11,501] Trial 3 finished with value: 0.1649992829203606 and parameters: {'n_layers': 2, 'n_units_l0': 4, 'dropout_0': 0.24857122521860803, 'n_units_l1': 6, 'dropout_1': 0.36513054871630224, 'learning_rate': 0.06994438428532447, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.12613435568809508.
[I 2023-09-17 20:17:40,343] Trial 4 finished with value: 0.4890031084060669 and parameters: {'n_layers': 3, 'n_units_l0': 5, 'dropout_0': 0.13554143856962914, 'n_units_l1': 3, 'dropout_1': 0.11332362582969842, 'n_units_l2': 7, 'dropout_2': 0.398063353738063, 'learning_rate': 0.03934708075630628, 'optimizer': 'RMSprop'}. Best is trial 1 with value: 0.12613435568809508.
[I 2023-09-17 20:17:42,048] Trial 5 pruned.
[I 2023-09-17 20:17:43,774] Trial 6 pruned.
[I 2023-09-17 20:17:45,542] Trial 7 pruned.
[I 2023-09-17 20:19:13,007] Trial 8 finished with value: 0.147444396173954 and parameters: {'n_layers': 2, 'n_units_l0': 5, 'dropout_0': 0.3275874889147997, 'n_units_l1': 4, 'dropout_1': 0.28691407620255327, 'learning_rate': 0.013726883176459717, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.12613435568809508.
[I 2023-09-17 20:19:14,805] Trial 9 pruned.
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (329622, 1270)
Number of total missing values across all columns: 296912
Data Subset Is Off
Wells held out for testing: ['K06' 'M09']
Wells to use for training, validation, and testing ['D06' 'D07' 'K07' 'M02' 'M03' 'M08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 94.71871896722939
Validation Loss: 0.13827653445005417
Training Accuracy: 93.47619737250439
Training Loss: 0.173671184356526
completed
