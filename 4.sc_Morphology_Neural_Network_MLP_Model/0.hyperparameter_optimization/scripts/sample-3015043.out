[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: SHSY5Y control_name: LPS_10.000_DMSO_0.025 treatment_name: Thapsigargin_10.000_DMSO_0.025
[I 2023-09-17 20:30:32,218] A new study created in memory with name: no-name-2e9a5c3b-65e9-4d71-a87c-78cf9742e171
[I 2023-09-17 20:30:40,369] Trial 0 finished with value: 0.44094997018575666 and parameters: {'n_layers': 3, 'n_units_l0': 8, 'dropout_0': 0.22220302636695854, 'n_units_l1': 10, 'dropout_1': 0.36794002982452245, 'n_units_l2': 10, 'dropout_2': 0.15379297824266158, 'learning_rate': 0.025160388923444472, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.44094997018575666.
[I 2023-09-17 20:30:48,057] Trial 1 finished with value: 0.18381919965147972 and parameters: {'n_layers': 1, 'n_units_l0': 8, 'dropout_0': 0.3041398453870928, 'learning_rate': 0.08919493654636146, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.18381919965147972.
[I 2023-09-17 20:30:56,001] Trial 2 finished with value: 0.29546154409646985 and parameters: {'n_layers': 3, 'n_units_l0': 10, 'dropout_0': 0.32936462578261383, 'n_units_l1': 2, 'dropout_1': 0.38604909654826647, 'n_units_l2': 6, 'dropout_2': 0.2036697920072858, 'learning_rate': 0.0915259904602494, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.18381919965147972.
[I 2023-09-17 20:31:03,893] Trial 3 finished with value: 0.188440684179465 and parameters: {'n_layers': 2, 'n_units_l0': 3, 'dropout_0': 0.3641680219594905, 'n_units_l1': 6, 'dropout_1': 0.17217581180131758, 'learning_rate': 0.0238985924701581, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.18381919965147972.
[I 2023-09-17 20:31:11,518] Trial 4 finished with value: 0.3411507624387741 and parameters: {'n_layers': 1, 'n_units_l0': 4, 'dropout_0': 0.2001076747179913, 'learning_rate': 0.08344628423567614, 'optimizer': 'RMSprop'}. Best is trial 1 with value: 0.18381919965147972.
[I 2023-09-17 20:31:19,471] Trial 5 finished with value: 0.2573327563206355 and parameters: {'n_layers': 3, 'n_units_l0': 4, 'dropout_0': 0.14056684404388498, 'n_units_l1': 5, 'dropout_1': 0.3390401795652722, 'n_units_l2': 6, 'dropout_2': 0.27542485029598285, 'learning_rate': 0.06119681369311765, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.18381919965147972.
[I 2023-09-17 20:31:19,696] Trial 6 pruned.
[I 2023-09-17 20:31:26,317] Trial 7 pruned.
[I 2023-09-17 20:31:34,159] Trial 8 finished with value: 0.24116149117549257 and parameters: {'n_layers': 3, 'n_units_l0': 2, 'dropout_0': 0.15799028777179652, 'n_units_l1': 3, 'dropout_1': 0.16159241210064496, 'n_units_l2': 4, 'dropout_2': 0.38112360113048716, 'learning_rate': 0.01475294760645358, 'optimizer': 'RMSprop'}. Best is trial 1 with value: 0.18381919965147972.
[I 2023-09-17 20:31:41,977] Trial 9 finished with value: 0.23923856745163602 and parameters: {'n_layers': 2, 'n_units_l0': 5, 'dropout_0': 0.1924153291927932, 'n_units_l1': 9, 'dropout_1': 0.19554599043150436, 'learning_rate': 0.027937392350068507, 'optimizer': 'RMSprop'}. Best is trial 1 with value: 0.18381919965147972.
Selected Catagories are:
['Thapsigargin_10.000_DMSO_0.025' 'LPS_10.000_DMSO_0.025']
The dimensions of the data are: (30022, 1276)
Number of total missing values across all columns: 60044
Data Subset Is Off
Wells held out for testing: ['E14' 'E20']
Wells to use for training, validation, and testing ['E15' 'E16' 'E17' 'E21' 'L14' 'L15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 92.61264470169192
Validation Loss: 0.19058574795722957
Training Accuracy: 91.98329993319972
Training Loss: 0.20874069142672755
completed
