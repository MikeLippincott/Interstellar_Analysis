[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: SHSY5Y control_name: Thapsigargin_1.000_DMSO_0.025 treatment_name: LPS_0.100_DMSO_0.025
[I 2023-09-17 20:25:01,598] A new study created in memory with name: no-name-a88b13e4-0772-47a9-b616-de5138415a05
[I 2023-09-17 20:25:11,558] Trial 0 finished with value: 0.5142383523782095 and parameters: {'n_layers': 2, 'n_units_l0': 4, 'dropout_0': 0.38758850426750524, 'n_units_l1': 7, 'dropout_1': 0.37593732329194696, 'learning_rate': 0.07667639119935536, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.5142383523782095.
[I 2023-09-17 20:25:20,711] Trial 1 finished with value: 0.6858873951435089 and parameters: {'n_layers': 3, 'n_units_l0': 5, 'dropout_0': 0.12169961288710278, 'n_units_l1': 8, 'dropout_1': 0.11392707095351748, 'n_units_l2': 6, 'dropout_2': 0.39099046695537987, 'learning_rate': 0.002454867179839161, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.5142383523782095.
[I 2023-09-17 20:25:30,006] Trial 2 finished with value: 0.40512398997942606 and parameters: {'n_layers': 2, 'n_units_l0': 7, 'dropout_0': 0.34709467230258895, 'n_units_l1': 9, 'dropout_1': 0.3791192125092018, 'learning_rate': 0.03298737374839751, 'optimizer': 'RMSprop'}. Best is trial 2 with value: 0.40512398997942606.
[I 2023-09-17 20:25:39,189] Trial 3 finished with value: 0.5993729084730148 and parameters: {'n_layers': 3, 'n_units_l0': 9, 'dropout_0': 0.14269200282589484, 'n_units_l1': 7, 'dropout_1': 0.24943791764363354, 'n_units_l2': 10, 'dropout_2': 0.2057556298613718, 'learning_rate': 0.02716349412107695, 'optimizer': 'SGD'}. Best is trial 2 with value: 0.40512398997942606.
[I 2023-09-17 20:25:48,678] Trial 4 finished with value: 0.31000015338261927 and parameters: {'n_layers': 3, 'n_units_l0': 8, 'dropout_0': 0.39633159063917023, 'n_units_l1': 10, 'dropout_1': 0.31222256088109046, 'n_units_l2': 7, 'dropout_2': 0.24046788724228138, 'learning_rate': 0.031580943546466, 'optimizer': 'Adam'}. Best is trial 4 with value: 0.31000015338261927.
[I 2023-09-17 20:25:48,936] Trial 5 pruned.
[I 2023-09-17 20:25:57,706] Trial 6 finished with value: 0.33667031268278763 and parameters: {'n_layers': 1, 'n_units_l0': 5, 'dropout_0': 0.18604093245986456, 'learning_rate': 0.08581956034830793, 'optimizer': 'Adam'}. Best is trial 4 with value: 0.31000015338261927.
[I 2023-09-17 20:25:57,870] Trial 7 pruned.
[I 2023-09-17 20:26:07,010] Trial 8 finished with value: 0.44630105773607887 and parameters: {'n_layers': 3, 'n_units_l0': 5, 'dropout_0': 0.11103973295325484, 'n_units_l1': 2, 'dropout_1': 0.1311959924396988, 'n_units_l2': 6, 'dropout_2': 0.13789810472764322, 'learning_rate': 0.08783270399273602, 'optimizer': 'Adam'}. Best is trial 4 with value: 0.31000015338261927.
[I 2023-09-17 20:26:16,059] Trial 9 finished with value: 0.29578625728686647 and parameters: {'n_layers': 2, 'n_units_l0': 6, 'dropout_0': 0.2300673514381352, 'n_units_l1': 3, 'dropout_1': 0.18648715462679696, 'learning_rate': 0.01033382855074981, 'optimizer': 'RMSprop'}. Best is trial 9 with value: 0.29578625728686647.
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'LPS_0.100_DMSO_0.025']
The dimensions of the data are: (31276, 1276)
Number of total missing values across all columns: 62552
Data Subset Is Off
Wells held out for testing: ['D14' 'C20']
Wells to use for training, validation, and testing ['D15' 'C16' 'C17' 'C21' 'K14' 'K15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 87.73140671483213
Validation Loss: 0.3069780242443085
Training Accuracy: 85.60323026245882
Training Loss: 0.2876780307449792
completed
