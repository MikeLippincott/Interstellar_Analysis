[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: PBMC control_name: LPS_0.100_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_1.0_DMSO_0.025
[I 2023-09-19 00:53:47,392] A new study created in memory with name: no-name-e5529b42-f38b-4e88-939b-7e0820790ab7
[I 2023-09-19 00:55:22,393] Trial 0 finished with value: 0.30039615432853284 and parameters: {'n_layers': 2, 'n_units_l0': 5, 'dropout_0': 0.19096012937836876, 'n_units_l1': 6, 'dropout_1': 0.3482041967000298, 'learning_rate': 0.02516566492171778, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.30039615432853284.
[I 2023-09-19 00:56:58,937] Trial 1 finished with value: 0.2901733691796013 and parameters: {'n_layers': 2, 'n_units_l0': 7, 'dropout_0': 0.25445352638139696, 'n_units_l1': 7, 'dropout_1': 0.2284656720220976, 'learning_rate': 0.04046782360308071, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.2901733691796013.
[I 2023-09-19 00:58:33,455] Trial 2 finished with value: 0.34343278431374086 and parameters: {'n_layers': 1, 'n_units_l0': 3, 'dropout_0': 0.34880512905910493, 'learning_rate': 0.07993235351675755, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.2901733691796013.
[I 2023-09-19 01:00:08,471] Trial 3 finished with value: 0.27120523428139476 and parameters: {'n_layers': 1, 'n_units_l0': 9, 'dropout_0': 0.3388287657132216, 'learning_rate': 0.06752806642432259, 'optimizer': 'Adam'}. Best is trial 3 with value: 0.27120523428139476.
[I 2023-09-19 01:01:46,075] Trial 4 finished with value: 0.24244890202646674 and parameters: {'n_layers': 3, 'n_units_l0': 9, 'dropout_0': 0.17683697347858013, 'n_units_l1': 8, 'dropout_1': 0.2723562579650273, 'n_units_l2': 7, 'dropout_2': 0.14462469322615742, 'learning_rate': 0.09101963160563128, 'optimizer': 'SGD'}. Best is trial 4 with value: 0.24244890202646674.
[I 2023-09-19 01:01:57,550] Trial 5 pruned.
[I 2023-09-19 01:03:35,058] Trial 6 finished with value: 0.24896926094656402 and parameters: {'n_layers': 2, 'n_units_l0': 9, 'dropout_0': 0.36438975344506186, 'n_units_l1': 9, 'dropout_1': 0.1345063032971135, 'learning_rate': 0.03591227842578066, 'optimizer': 'Adam'}. Best is trial 4 with value: 0.24244890202646674.
[I 2023-09-19 01:05:13,579] Trial 7 finished with value: 0.25080095677272135 and parameters: {'n_layers': 2, 'n_units_l0': 10, 'dropout_0': 0.22200730667665708, 'n_units_l1': 5, 'dropout_1': 0.26065376506755844, 'learning_rate': 0.08159466232627041, 'optimizer': 'Adam'}. Best is trial 4 with value: 0.24244890202646674.
[I 2023-09-19 01:05:42,787] Trial 8 pruned.
[I 2023-09-19 01:05:57,867] Trial 9 pruned.
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_Nigericin_1.000_1.0_DMSO_0.025']
The dimensions of the data are: (304610, 1270)
Number of total missing values across all columns: 277194
Data Subset Is Off
Wells held out for testing: ['C08' 'K08']
Wells to use for training, validation, and testing ['C02' 'C03' 'C09' 'K02' 'K03' 'K09']
Number of in features:  1245
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 89.21008990137034
Validation Loss: 0.2779233042053555
Training Accuracy: 86.64464532178258
Training Loss: 0.3189418774632656
completed
