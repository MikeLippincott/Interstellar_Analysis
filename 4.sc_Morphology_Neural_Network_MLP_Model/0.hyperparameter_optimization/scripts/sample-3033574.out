[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: PBMC control_name: LPS_0.100_DMSO_0.025 treatment_name: Thapsigargin_10.000_DMSO_0.025
[I 2023-09-19 01:28:27,867] A new study created in memory with name: no-name-17132413-7762-4cd4-a2ee-1c4c47d2a32d
[I 2023-09-19 01:29:58,282] Trial 0 finished with value: 0.5578092222628386 and parameters: {'n_layers': 1, 'n_units_l0': 5, 'dropout_0': 0.3439197379139667, 'learning_rate': 0.08266730289071818, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.5578092222628386.
[I 2023-09-19 01:31:35,935] Trial 1 finished with value: 0.47462590836960333 and parameters: {'n_layers': 3, 'n_units_l0': 2, 'dropout_0': 0.2282885607690499, 'n_units_l1': 7, 'dropout_1': 0.1533681831805327, 'n_units_l2': 2, 'dropout_2': 0.15231169373656947, 'learning_rate': 0.03337777201833135, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.47462590836960333.
[I 2023-09-19 01:33:09,362] Trial 2 finished with value: 0.38958503432895825 and parameters: {'n_layers': 3, 'n_units_l0': 5, 'dropout_0': 0.27619318443196994, 'n_units_l1': 3, 'dropout_1': 0.3435965858370812, 'n_units_l2': 5, 'dropout_2': 0.21699696943272245, 'learning_rate': 0.06368377640180314, 'optimizer': 'SGD'}. Best is trial 2 with value: 0.38958503432895825.
[I 2023-09-19 01:34:44,267] Trial 3 finished with value: 0.37509446810121116 and parameters: {'n_layers': 2, 'n_units_l0': 3, 'dropout_0': 0.13551014036200332, 'n_units_l1': 5, 'dropout_1': 0.30161473013640594, 'learning_rate': 0.02343639613367144, 'optimizer': 'SGD'}. Best is trial 3 with value: 0.37509446810121116.
[I 2023-09-19 01:36:20,042] Trial 4 finished with value: 0.31929867337579315 and parameters: {'n_layers': 3, 'n_units_l0': 10, 'dropout_0': 0.25218580739716556, 'n_units_l1': 7, 'dropout_1': 0.3287835683362335, 'n_units_l2': 10, 'dropout_2': 0.30951331676073185, 'learning_rate': 0.09092536864446013, 'optimizer': 'SGD'}. Best is trial 4 with value: 0.31929867337579315.
[I 2023-09-19 01:36:23,934] Trial 5 pruned.
[I 2023-09-19 01:37:56,042] Trial 6 finished with value: 0.3359164148050806 and parameters: {'n_layers': 1, 'n_units_l0': 9, 'dropout_0': 0.3952902396838074, 'learning_rate': 0.06717164484769152, 'optimizer': 'Adam'}. Best is trial 4 with value: 0.31929867337579315.
[I 2023-09-19 01:37:57,970] Trial 7 pruned.
[I 2023-09-19 01:37:59,738] Trial 8 pruned.
[I 2023-09-19 01:38:01,521] Trial 9 pruned.
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'Thapsigargin_10.000_DMSO_0.025']
The dimensions of the data are: (305581, 1270)
Number of total missing values across all columns: 611162
Data Subset Is Off
Wells held out for testing: ['C08' 'L06']
Wells to use for training, validation, and testing ['C02' 'C03' 'C09' 'E06' 'E07' 'L07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 86.43936575427406
Validation Loss: 0.3265298976328062
Training Accuracy: 83.50129274787818
Training Loss: 0.38079472115685264
completed
