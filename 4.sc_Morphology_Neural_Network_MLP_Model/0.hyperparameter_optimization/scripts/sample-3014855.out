[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: PBMC control_name: LPS_1.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_10.0_DMSO_0.025
[I 2023-09-17 20:09:10,275] A new study created in memory with name: no-name-596815ef-d284-497c-a80d-89ce9163810f
[I 2023-09-17 20:11:08,325] Trial 0 finished with value: 0.18131721655527755 and parameters: {'n_layers': 2, 'n_units_l0': 6, 'dropout_0': 0.31189996064080594, 'n_units_l1': 9, 'dropout_1': 0.24818614997210656, 'learning_rate': 0.030347613298680545, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.18131721655527755.
[I 2023-09-17 20:12:57,281] Trial 1 finished with value: 0.1762908831238747 and parameters: {'n_layers': 2, 'n_units_l0': 5, 'dropout_0': 0.10513395023374358, 'n_units_l1': 3, 'dropout_1': 0.13430125900040973, 'learning_rate': 0.0949210328654692, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.1762908831238747.
[I 2023-09-17 20:14:52,990] Trial 2 finished with value: 0.49850511065373815 and parameters: {'n_layers': 2, 'n_units_l0': 10, 'dropout_0': 0.1450300697938762, 'n_units_l1': 7, 'dropout_1': 0.3950197867711589, 'learning_rate': 0.09354650669389644, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.1762908831238747.
[I 2023-09-17 20:16:40,964] Trial 3 finished with value: 0.16659163463860746 and parameters: {'n_layers': 1, 'n_units_l0': 9, 'dropout_0': 0.2912120247286034, 'learning_rate': 0.02243406146074389, 'optimizer': 'SGD'}. Best is trial 3 with value: 0.16659163463860746.
[I 2023-09-17 20:18:24,582] Trial 4 finished with value: 0.1412165457258622 and parameters: {'n_layers': 1, 'n_units_l0': 10, 'dropout_0': 0.31690111498991336, 'learning_rate': 0.06564416257058929, 'optimizer': 'SGD'}. Best is trial 4 with value: 0.1412165457258622.
[I 2023-09-17 20:18:26,543] Trial 5 pruned.
[I 2023-09-17 20:18:46,557] Trial 6 pruned.
[I 2023-09-17 20:18:48,704] Trial 7 pruned.
[I 2023-09-17 20:20:36,325] Trial 8 finished with value: 0.15650046073521176 and parameters: {'n_layers': 2, 'n_units_l0': 9, 'dropout_0': 0.18833666901688, 'n_units_l1': 5, 'dropout_1': 0.26607318330054364, 'learning_rate': 0.01734610339998009, 'optimizer': 'RMSprop'}. Best is trial 4 with value: 0.1412165457258622.
[I 2023-09-17 20:22:17,632] Trial 9 finished with value: 0.15949229157840214 and parameters: {'n_layers': 1, 'n_units_l0': 6, 'dropout_0': 0.3542790926745548, 'learning_rate': 0.03863234015215795, 'optimizer': 'Adam'}. Best is trial 4 with value: 0.1412165457258622.
Selected Catagories are:
['LPS_1.000_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (320599, 1270)
Number of total missing values across all columns: 278866
Data Subset Is Off
Wells held out for testing: ['D09' 'M09']
Wells to use for training, validation, and testing ['D02' 'D03' 'D08' 'M02' 'M03' 'M08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 94.79283952717068
Validation Loss: 0.14035565943767628
Training Accuracy: 93.84805834015458
Training Loss: 0.16078230590495482
completed
