[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: PBMC control_name: Flagellin_1.000_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_10.0_DMSO_0.025
[I 2023-09-17 20:08:26,555] A new study created in memory with name: no-name-5977209c-452b-4ce8-b955-1f3cffb400d2
[I 2023-09-17 20:09:35,685] Trial 0 finished with value: 0.12282634547068959 and parameters: {'n_layers': 2, 'n_units_l0': 4, 'dropout_0': 0.3646977409821208, 'n_units_l1': 5, 'dropout_1': 0.21972437171083717, 'learning_rate': 0.05019474505755199, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.12282634547068959.
[I 2023-09-17 20:10:43,243] Trial 1 finished with value: 0.12809040350573406 and parameters: {'n_layers': 1, 'n_units_l0': 2, 'dropout_0': 0.10241572196201598, 'learning_rate': 0.04206166730523803, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.12282634547068959.
[I 2023-09-17 20:11:52,917] Trial 2 finished with value: 0.11290813785223733 and parameters: {'n_layers': 2, 'n_units_l0': 4, 'dropout_0': 0.32226751790263836, 'n_units_l1': 5, 'dropout_1': 0.10900324272148434, 'learning_rate': 0.08119854872111229, 'optimizer': 'SGD'}. Best is trial 2 with value: 0.11290813785223733.
[I 2023-09-17 20:13:06,009] Trial 3 finished with value: 0.0810057940795308 and parameters: {'n_layers': 2, 'n_units_l0': 7, 'dropout_0': 0.14990237363613884, 'n_units_l1': 3, 'dropout_1': 0.21593977053800262, 'learning_rate': 0.03642928053971821, 'optimizer': 'Adam'}. Best is trial 3 with value: 0.0810057940795308.
[I 2023-09-17 20:14:14,664] Trial 4 finished with value: 0.2427738188703855 and parameters: {'n_layers': 1, 'n_units_l0': 2, 'dropout_0': 0.2182019767034631, 'learning_rate': 0.09524720235715559, 'optimizer': 'RMSprop'}. Best is trial 3 with value: 0.0810057940795308.
[I 2023-09-17 20:14:16,103] Trial 5 pruned.
[I 2023-09-17 20:14:28,788] Trial 6 pruned.
[I 2023-09-17 20:14:30,230] Trial 7 pruned.
[I 2023-09-17 20:15:40,406] Trial 8 finished with value: 0.09857902880935442 and parameters: {'n_layers': 1, 'n_units_l0': 3, 'dropout_0': 0.1536190302923614, 'learning_rate': 0.006556269924078874, 'optimizer': 'Adam'}. Best is trial 3 with value: 0.0810057940795308.
[I 2023-09-17 20:15:41,809] Trial 9 pruned.
Selected Catagories are:
['LPS_Nigericin_1.000_10.0_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (285713, 1270)
Number of total missing values across all columns: 245710
Data Subset Is Off
Wells held out for testing: ['M08' 'M10']
Wells to use for training, validation, and testing ['M02' 'M03' 'M05' 'M09' 'M11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 97.2304498938019
Validation Loss: 0.08249120315980343
Training Accuracy: 95.51788559015208
Training Loss: 0.13234734907297485
completed
