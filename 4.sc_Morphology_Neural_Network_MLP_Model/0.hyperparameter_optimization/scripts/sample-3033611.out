[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: PBMC control_name: LPS_100.000_DMSO_0.025 treatment_name: Thapsigargin_1.000_DMSO_0.025
[I 2023-09-19 01:32:14,672] A new study created in memory with name: no-name-fd5ef2ee-0efd-4101-be97-024b86e248a1
[I 2023-09-19 01:33:58,268] Trial 0 finished with value: 0.6242357614263891 and parameters: {'n_layers': 1, 'n_units_l0': 8, 'dropout_0': 0.17481906317533485, 'learning_rate': 0.07850045718813616, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.6242357614263891.
[I 2023-09-19 01:35:57,300] Trial 1 finished with value: 0.41205255329608925 and parameters: {'n_layers': 3, 'n_units_l0': 10, 'dropout_0': 0.20870441288589314, 'n_units_l1': 8, 'dropout_1': 0.21610837968223107, 'n_units_l2': 8, 'dropout_2': 0.2664314559029291, 'learning_rate': 0.02999195791641758, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.41205255329608925.
[I 2023-09-19 01:37:47,130] Trial 2 finished with value: 0.39772552739828826 and parameters: {'n_layers': 2, 'n_units_l0': 9, 'dropout_0': 0.37923798372630435, 'n_units_l1': 3, 'dropout_1': 0.37780583175474625, 'learning_rate': 0.06336800853133005, 'optimizer': 'SGD'}. Best is trial 2 with value: 0.39772552739828826.
[I 2023-09-19 01:39:24,428] Trial 3 finished with value: 0.35862256449957686 and parameters: {'n_layers': 1, 'n_units_l0': 8, 'dropout_0': 0.2807560171024802, 'learning_rate': 0.060126541367736264, 'optimizer': 'SGD'}. Best is trial 3 with value: 0.35862256449957686.
[I 2023-09-19 01:41:05,535] Trial 4 finished with value: 0.44020882137119777 and parameters: {'n_layers': 2, 'n_units_l0': 8, 'dropout_0': 0.3674247700750559, 'n_units_l1': 7, 'dropout_1': 0.26192453116466846, 'learning_rate': 0.018506247296268444, 'optimizer': 'SGD'}. Best is trial 3 with value: 0.35862256449957686.
[I 2023-09-19 01:42:38,888] Trial 5 finished with value: 0.38462628729641435 and parameters: {'n_layers': 3, 'n_units_l0': 4, 'dropout_0': 0.26521063465867734, 'n_units_l1': 10, 'dropout_1': 0.3543752542539269, 'n_units_l2': 8, 'dropout_2': 0.3762778513193926, 'learning_rate': 0.010230482713288334, 'optimizer': 'RMSprop'}. Best is trial 3 with value: 0.35862256449957686.
[I 2023-09-19 01:42:40,826] Trial 6 pruned.
[I 2023-09-19 01:42:42,823] Trial 7 pruned.
[I 2023-09-19 01:42:44,664] Trial 8 pruned.
[I 2023-09-19 01:42:46,645] Trial 9 pruned.
Selected Catagories are:
['Thapsigargin_1.000_DMSO_0.025' 'LPS_100.000_DMSO_0.025']
The dimensions of the data are: (307891, 1270)
Number of total missing values across all columns: 615782
Data Subset Is Off
Wells held out for testing: ['K06' 'J09']
Wells to use for training, validation, and testing ['D06' 'D07' 'J02' 'J03' 'K07' 'J08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 84.07404832261429
Validation Loss: 0.3553868676349521
Training Accuracy: 80.57859284689931
Training Loss: 0.3997174283878223
completed
