[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: PBMC control_name: H2O2_100.000_DMSO_0.025 treatment_name: Flagellin_0.100_DMSO_0.025
[I 2023-09-19 00:34:10,224] A new study created in memory with name: no-name-0ccea2cc-f90c-4a58-b411-40ed561466f7
[I 2023-09-19 00:35:50,447] Trial 0 finished with value: 0.42866951430285416 and parameters: {'n_layers': 1, 'n_units_l0': 10, 'dropout_0': 0.24770337406388512, 'learning_rate': 0.005085260828125867, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.42866951430285416.
[I 2023-09-19 00:37:34,968] Trial 1 finished with value: 0.5422558645848874 and parameters: {'n_layers': 3, 'n_units_l0': 7, 'dropout_0': 0.16910346540779056, 'n_units_l1': 4, 'dropout_1': 0.2568904119748927, 'n_units_l2': 7, 'dropout_2': 0.2975359210503645, 'learning_rate': 0.05067125992110527, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.42866951430285416.
[I 2023-09-19 00:39:18,462] Trial 2 finished with value: 0.34651476248546875 and parameters: {'n_layers': 3, 'n_units_l0': 6, 'dropout_0': 0.314380179801275, 'n_units_l1': 10, 'dropout_1': 0.35209460027643846, 'n_units_l2': 7, 'dropout_2': 0.389376852070366, 'learning_rate': 0.0020268135250652453, 'optimizer': 'RMSprop'}. Best is trial 2 with value: 0.34651476248546875.
[I 2023-09-19 00:41:01,893] Trial 3 finished with value: 0.5442689967155456 and parameters: {'n_layers': 2, 'n_units_l0': 10, 'dropout_0': 0.2585429285584828, 'n_units_l1': 6, 'dropout_1': 0.2785640945136604, 'learning_rate': 0.09330093171568668, 'optimizer': 'RMSprop'}. Best is trial 2 with value: 0.34651476248546875.
[I 2023-09-19 00:42:42,052] Trial 4 finished with value: 0.3536497116088867 and parameters: {'n_layers': 2, 'n_units_l0': 9, 'dropout_0': 0.1846424022531289, 'n_units_l1': 5, 'dropout_1': 0.3652793095066287, 'learning_rate': 0.03767268973356095, 'optimizer': 'SGD'}. Best is trial 2 with value: 0.34651476248546875.
[I 2023-09-19 00:42:44,244] Trial 5 pruned.
[I 2023-09-19 00:44:23,920] Trial 6 finished with value: 0.34010027931796183 and parameters: {'n_layers': 1, 'n_units_l0': 4, 'dropout_0': 0.27658634416571615, 'learning_rate': 0.020593062050422918, 'optimizer': 'Adam'}. Best is trial 6 with value: 0.34010027931796183.
[I 2023-09-19 00:44:25,887] Trial 7 pruned.
[I 2023-09-19 00:44:28,072] Trial 8 pruned.
[I 2023-09-19 00:46:07,767] Trial 9 finished with value: 0.365150344438023 and parameters: {'n_layers': 1, 'n_units_l0': 10, 'dropout_0': 0.13710548037338785, 'learning_rate': 0.014221924743268012, 'optimizer': 'SGD'}. Best is trial 6 with value: 0.34010027931796183.
Selected Catagories are:
['H2O2_100.000_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (336451, 1270)
Number of total missing values across all columns: 672902
Data Subset Is Off
Wells held out for testing: ['I05' 'L10']
Wells to use for training, validation, and testing ['H04' 'I04' 'H05' 'H10' 'I10' 'H11' 'I11' 'L05' 'L11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 84.25808602867623
Validation Loss: 0.338080451378116
Training Accuracy: 82.12371134020617
Training Loss: 0.37618036220195117
completed
