[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: PBMC control_name: LPS_Nigericin_1.000_10.0_DMSO_0.025 treatment_name: LPS_10.000_DMSO_0.025
[I 2023-09-17 20:16:26,883] A new study created in memory with name: no-name-a3cc1415-d75d-4e5a-ab25-b341affca809
[I 2023-09-17 20:18:12,000] Trial 0 finished with value: 0.21060658051967618 and parameters: {'n_layers': 3, 'n_units_l0': 2, 'dropout_0': 0.22881230069534197, 'n_units_l1': 6, 'dropout_1': 0.11306182308475006, 'n_units_l2': 6, 'dropout_2': 0.21721775610338384, 'learning_rate': 0.05484214574699068, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.21060658051967618.
[I 2023-09-17 20:19:51,281] Trial 1 finished with value: 0.11495587918162346 and parameters: {'n_layers': 1, 'n_units_l0': 8, 'dropout_0': 0.2364775436672353, 'learning_rate': 0.03852340633069385, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.11495587918162346.
[I 2023-09-17 20:21:30,805] Trial 2 finished with value: 0.18853223991394047 and parameters: {'n_layers': 1, 'n_units_l0': 2, 'dropout_0': 0.3258530732202932, 'learning_rate': 0.059563421978490225, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.11495587918162346.
[I 2023-09-17 20:23:14,366] Trial 3 finished with value: 0.11233358146548271 and parameters: {'n_layers': 3, 'n_units_l0': 10, 'dropout_0': 0.18724056366772224, 'n_units_l1': 8, 'dropout_1': 0.101212870968016, 'n_units_l2': 2, 'dropout_2': 0.1458480670128033, 'learning_rate': 0.04472774598493633, 'optimizer': 'SGD'}. Best is trial 3 with value: 0.11233358146548271.
[I 2023-09-17 20:25:00,747] Trial 4 finished with value: 0.6811184204101564 and parameters: {'n_layers': 3, 'n_units_l0': 10, 'dropout_0': 0.3847972971828941, 'n_units_l1': 9, 'dropout_1': 0.3307533814944389, 'n_units_l2': 3, 'dropout_2': 0.38150965314378316, 'learning_rate': 0.09751831739196913, 'optimizer': 'Adam'}. Best is trial 3 with value: 0.11233358146548271.
[I 2023-09-17 20:25:02,760] Trial 5 pruned.
[I 2023-09-17 20:26:41,679] Trial 6 finished with value: 0.11509464493393898 and parameters: {'n_layers': 1, 'n_units_l0': 6, 'dropout_0': 0.3087603981598132, 'learning_rate': 0.07027708431106248, 'optimizer': 'SGD'}. Best is trial 3 with value: 0.11233358146548271.
[I 2023-09-17 20:26:43,864] Trial 7 pruned.
[I 2023-09-17 20:28:25,808] Trial 8 finished with value: 0.11059534046053887 and parameters: {'n_layers': 1, 'n_units_l0': 7, 'dropout_0': 0.35365008704267087, 'learning_rate': 0.02836699608964347, 'optimizer': 'Adam'}. Best is trial 8 with value: 0.11059534046053887.
[I 2023-09-17 20:28:27,913] Trial 9 pruned.
Selected Catagories are:
['LPS_10.000_DMSO_0.025' 'LPS_Nigericin_1.000_10.0_DMSO_0.025']
The dimensions of the data are: (337656, 1270)
Number of total missing values across all columns: 312980
Data Subset Is Off
Wells held out for testing: ['E09' 'M09']
Wells to use for training, validation, and testing ['E02' 'E03' 'E08' 'M02' 'M03' 'M08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 96.034282935527
Validation Loss: 0.13020508274435996
Training Accuracy: 94.2867360636223
Training Loss: 0.17470935796472162
completed
