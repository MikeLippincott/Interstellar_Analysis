[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: SHSY5Y control_name: Flagellin_0.100_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_10.0_DMSO_0.025
[I 2023-09-19 00:59:10,028] A new study created in memory with name: no-name-7ed490d8-d095-421c-80cd-de7286507a53
[I 2023-09-19 00:59:19,985] Trial 0 finished with value: 0.13433124164740243 and parameters: {'n_layers': 3, 'n_units_l0': 9, 'dropout_0': 0.3911453409965423, 'n_units_l1': 9, 'dropout_1': 0.15770468023801565, 'n_units_l2': 8, 'dropout_2': 0.38309078610832104, 'learning_rate': 0.047060127598029494, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.13433124164740243.
[I 2023-09-19 00:59:29,551] Trial 1 finished with value: 0.22980738530556358 and parameters: {'n_layers': 3, 'n_units_l0': 8, 'dropout_0': 0.3541276886437039, 'n_units_l1': 5, 'dropout_1': 0.3945723249370605, 'n_units_l2': 7, 'dropout_2': 0.3607060666037557, 'learning_rate': 0.06295587740687357, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.13433124164740243.
[I 2023-09-19 00:59:38,784] Trial 2 finished with value: 0.25629148383935285 and parameters: {'n_layers': 1, 'n_units_l0': 2, 'dropout_0': 0.17629495779964588, 'learning_rate': 0.026230283540363882, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.13433124164740243.
[I 2023-09-19 00:59:48,291] Trial 3 finished with value: 0.6962323697408039 and parameters: {'n_layers': 3, 'n_units_l0': 10, 'dropout_0': 0.2630372546987373, 'n_units_l1': 4, 'dropout_1': 0.3665952414410837, 'n_units_l2': 5, 'dropout_2': 0.2291311837999261, 'learning_rate': 0.07338699723735002, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.13433124164740243.
[I 2023-09-19 00:59:58,126] Trial 4 finished with value: 0.2487556273738543 and parameters: {'n_layers': 3, 'n_units_l0': 9, 'dropout_0': 0.14713047634261453, 'n_units_l1': 5, 'dropout_1': 0.21668850883106588, 'n_units_l2': 4, 'dropout_2': 0.20023873490849103, 'learning_rate': 0.06280679088968644, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.13433124164740243.
[I 2023-09-19 01:00:00,207] Trial 5 pruned.
[I 2023-09-19 01:00:00,370] Trial 6 pruned.
[I 2023-09-19 01:00:00,530] Trial 7 pruned.
[I 2023-09-19 01:00:00,770] Trial 8 pruned.
[I 2023-09-19 01:00:10,146] Trial 9 finished with value: 0.20078078975280125 and parameters: {'n_layers': 1, 'n_units_l0': 10, 'dropout_0': 0.16593484496373323, 'learning_rate': 0.0897191246242174, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.13433124164740243.
Selected Catagories are:
['LPS_Nigericin_1.000_10.0_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (29330, 1276)
Number of total missing values across all columns: 29856
Data Subset Is Off
Wells held out for testing: ['M16' 'L22']
Wells to use for training, validation, and testing ['M17' 'L18' 'L19' 'M20' 'M21' 'L23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 95.28397375820057
Validation Loss: 0.1313014360765616
Training Accuracy: 92.16402085408001
Training Loss: 0.1995263398355908
completed
