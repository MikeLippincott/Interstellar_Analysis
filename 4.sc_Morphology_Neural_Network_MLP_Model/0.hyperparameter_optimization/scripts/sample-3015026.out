[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: SHSY5Y control_name: DMSO_0.100_DMSO_0.025 treatment_name: Thapsigargin_10.000_DMSO_0.025
[I 2023-09-17 20:28:44,041] A new study created in memory with name: no-name-6ff802df-467c-47d3-ad14-e5235ab58e30
[I 2023-09-17 20:28:57,098] Trial 0 finished with value: 0.13223225438594818 and parameters: {'n_layers': 1, 'n_units_l0': 9, 'dropout_0': 0.31336483327463205, 'learning_rate': 0.07019625627681088, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.13223225438594818.
[I 2023-09-17 20:29:10,637] Trial 1 finished with value: 0.1953605600595474 and parameters: {'n_layers': 2, 'n_units_l0': 2, 'dropout_0': 0.23355833645946572, 'n_units_l1': 10, 'dropout_1': 0.12347294900127996, 'learning_rate': 0.009798124002994468, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.13223225438594818.
[I 2023-09-17 20:29:23,807] Trial 2 finished with value: 0.18996660804748533 and parameters: {'n_layers': 1, 'n_units_l0': 6, 'dropout_0': 0.3170141351072972, 'learning_rate': 0.023891503909997284, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.13223225438594818.
[I 2023-09-17 20:29:37,317] Trial 3 finished with value: 0.17948409435153007 and parameters: {'n_layers': 2, 'n_units_l0': 4, 'dropout_0': 0.34671769091847926, 'n_units_l1': 4, 'dropout_1': 0.302099517775457, 'learning_rate': 0.052958470102890995, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.13223225438594818.
[I 2023-09-17 20:29:50,533] Trial 4 finished with value: 0.127327348947525 and parameters: {'n_layers': 1, 'n_units_l0': 10, 'dropout_0': 0.30210536694237533, 'learning_rate': 0.07223122028301864, 'optimizer': 'SGD'}. Best is trial 4 with value: 0.127327348947525.
[I 2023-09-17 20:29:51,026] Trial 5 pruned.
[I 2023-09-17 20:30:05,039] Trial 6 finished with value: 0.20428700509667394 and parameters: {'n_layers': 2, 'n_units_l0': 10, 'dropout_0': 0.2876249051879675, 'n_units_l1': 7, 'dropout_1': 0.3509913060119444, 'learning_rate': 0.08046768412637743, 'optimizer': 'Adam'}. Best is trial 4 with value: 0.127327348947525.
[I 2023-09-17 20:30:05,280] Trial 7 pruned.
[I 2023-09-17 20:30:05,848] Trial 8 pruned.
[I 2023-09-17 20:30:19,246] Trial 9 finished with value: 0.13781004957854748 and parameters: {'n_layers': 1, 'n_units_l0': 6, 'dropout_0': 0.25305072699461484, 'learning_rate': 0.0756368192370826, 'optimizer': 'Adam'}. Best is trial 4 with value: 0.127327348947525.
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'Thapsigargin_10.000_DMSO_0.025']
The dimensions of the data are: (48855, 1276)
Number of total missing values across all columns: 97710
Data Subset Is Off
Wells held out for testing: ['I14' 'L14']
Wells to use for training, validation, and testing ['B14' 'C14' 'E14' 'B15' 'C15' 'E15' 'J14' 'I15' 'J15' 'L15']
Number of in features:  1251
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 94.9552605703048
Validation Loss: 0.1301502137184143
Training Accuracy: 94.6115072535038
Training Loss: 0.14818928079171614
completed
