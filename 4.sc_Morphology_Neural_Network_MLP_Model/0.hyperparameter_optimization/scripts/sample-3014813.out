[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: PBMC control_name: LPS_0.100_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_3.0_DMSO_0.025
[I 2023-09-17 20:01:37,495] A new study created in memory with name: no-name-cf276c8c-a9b7-4dc6-a186-70940dee4151
[I 2023-09-17 20:03:06,426] Trial 0 finished with value: 0.23581890955567356 and parameters: {'n_layers': 3, 'n_units_l0': 7, 'dropout_0': 0.1799140173524514, 'n_units_l1': 6, 'dropout_1': 0.15319002362130502, 'n_units_l2': 8, 'dropout_2': 0.12942732766229953, 'learning_rate': 0.035185122466774736, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.23581890955567356.
[I 2023-09-17 20:04:32,707] Trial 1 finished with value: 0.14555442040786148 and parameters: {'n_layers': 2, 'n_units_l0': 7, 'dropout_0': 0.11142243958897281, 'n_units_l1': 10, 'dropout_1': 0.19559569949885502, 'learning_rate': 0.06511176150992111, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.14555442040786148.
[I 2023-09-17 20:05:56,429] Trial 2 finished with value: 0.20553040596346062 and parameters: {'n_layers': 1, 'n_units_l0': 5, 'dropout_0': 0.3959294876677081, 'learning_rate': 0.07990415252000758, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.14555442040786148.
[I 2023-09-17 20:07:21,773] Trial 3 finished with value: 0.17541599187999965 and parameters: {'n_layers': 2, 'n_units_l0': 6, 'dropout_0': 0.31703342441472004, 'n_units_l1': 7, 'dropout_1': 0.16470462464563496, 'learning_rate': 0.03707780771491896, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.14555442040786148.
[I 2023-09-17 20:08:46,703] Trial 4 finished with value: 0.7630778904507557 and parameters: {'n_layers': 1, 'n_units_l0': 10, 'dropout_0': 0.3275725423372291, 'learning_rate': 0.09053007760198958, 'optimizer': 'RMSprop'}. Best is trial 1 with value: 0.14555442040786148.
[I 2023-09-17 20:09:08,887] Trial 5 pruned.
[I 2023-09-17 20:09:24,794] Trial 6 pruned.
[I 2023-09-17 20:10:50,392] Trial 7 finished with value: 0.17231754437709845 and parameters: {'n_layers': 2, 'n_units_l0': 4, 'dropout_0': 0.13710882759999768, 'n_units_l1': 5, 'dropout_1': 0.24405758281526954, 'learning_rate': 0.046526693212639296, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.14555442040786148.
[I 2023-09-17 20:10:52,111] Trial 8 pruned.
[I 2023-09-17 20:11:02,282] Trial 9 pruned.
Selected Catagories are:
['LPS_0.100_DMSO_0.025' 'LPS_Nigericin_1.000_3.0_DMSO_0.025']
The dimensions of the data are: (312858, 1270)
Number of total missing values across all columns: 277194
Data Subset Is Off
Wells held out for testing: ['C09' 'L09']
Wells to use for training, validation, and testing ['C02' 'C03' 'C08' 'L02' 'L03' 'L08']
Number of in features:  1245
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 94.518506013927
Validation Loss: 0.14334619120384257
Training Accuracy: 93.44124039841311
Training Loss: 0.16700730661498875
completed
