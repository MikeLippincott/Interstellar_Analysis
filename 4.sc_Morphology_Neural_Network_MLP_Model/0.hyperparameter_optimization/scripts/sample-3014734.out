[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: PBMC control_name: LPS_100.000_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025
[I 2023-09-17 19:46:11,556] A new study created in memory with name: no-name-ef782694-c70a-4a13-80c7-80c14656b3fb
[I 2023-09-17 19:47:31,040] Trial 0 finished with value: 0.5173390330076217 and parameters: {'n_layers': 2, 'n_units_l0': 5, 'dropout_0': 0.381910275527908, 'n_units_l1': 3, 'dropout_1': 0.2556590740724448, 'learning_rate': 0.008602236175629942, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.5173390330076217.
[I 2023-09-17 19:48:54,065] Trial 1 finished with value: 0.46246964147686953 and parameters: {'n_layers': 3, 'n_units_l0': 8, 'dropout_0': 0.2873513631472884, 'n_units_l1': 2, 'dropout_1': 0.11839143472354095, 'n_units_l2': 10, 'dropout_2': 0.2432802991709132, 'learning_rate': 0.0073250572485157334, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.46246964147686953.
[I 2023-09-17 19:50:14,234] Trial 2 finished with value: 0.6445832132697106 and parameters: {'n_layers': 3, 'n_units_l0': 6, 'dropout_0': 0.3677305897265316, 'n_units_l1': 4, 'dropout_1': 0.2057822772086717, 'n_units_l2': 4, 'dropout_2': 0.1284465792896523, 'learning_rate': 0.004675645639395241, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.46246964147686953.
[I 2023-09-17 19:51:34,695] Trial 3 finished with value: 0.6543945533037185 and parameters: {'n_layers': 3, 'n_units_l0': 4, 'dropout_0': 0.36029229678171515, 'n_units_l1': 5, 'dropout_1': 0.1304094426147131, 'n_units_l2': 2, 'dropout_2': 0.27254962932926463, 'learning_rate': 0.015852938243274762, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.46246964147686953.
[I 2023-09-17 19:52:58,195] Trial 4 finished with value: 0.6403946828246115 and parameters: {'n_layers': 3, 'n_units_l0': 10, 'dropout_0': 0.16191885823527738, 'n_units_l1': 10, 'dropout_1': 0.19983581749454749, 'n_units_l2': 9, 'dropout_2': 0.30615116376170226, 'learning_rate': 0.07428658044667294, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.46246964147686953.
[I 2023-09-17 19:52:59,852] Trial 5 pruned.
[I 2023-09-17 19:54:19,459] Trial 6 finished with value: 0.4934231835901738 and parameters: {'n_layers': 1, 'n_units_l0': 7, 'dropout_0': 0.35240064582210384, 'learning_rate': 0.08238420905061174, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.46246964147686953.
[I 2023-09-17 19:54:21,108] Trial 7 pruned.
[I 2023-09-17 19:55:41,921] Trial 8 finished with value: 0.43901624870300293 and parameters: {'n_layers': 2, 'n_units_l0': 9, 'dropout_0': 0.3222727132892613, 'n_units_l1': 9, 'dropout_1': 0.1310952075218431, 'learning_rate': 0.02114923541072317, 'optimizer': 'Adam'}. Best is trial 8 with value: 0.43901624870300293.
[I 2023-09-17 19:57:01,622] Trial 9 finished with value: 0.4498245567679405 and parameters: {'n_layers': 1, 'n_units_l0': 4, 'dropout_0': 0.115169049205203, 'learning_rate': 0.015175471049314082, 'optimizer': 'Adam'}. Best is trial 8 with value: 0.43901624870300293.
Selected Catagories are:
['LPS_100.000_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (263982, 1270)
Number of total missing values across all columns: 564580
Data Subset Is Off
Wells held out for testing: ['J08' 'M10']
Wells to use for training, validation, and testing ['J02' 'J03' 'J09' 'M05' 'M11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 79.01658435144267
Validation Loss: 0.4547563729584217
Training Accuracy: 76.80006498781478
Training Loss: 0.47300317264996566
completed
