[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: PBMC control_name: DMSO_0.100_DMSO_0.025 treatment_name: Thapsigargin_10.000_DMSO_0.025
[I 2023-09-19 01:26:08,633] A new study created in memory with name: no-name-adce6176-595f-4e31-a79f-f0b4a3111644
[I 2023-09-19 01:28:23,849] Trial 0 finished with value: 0.6663238489627838 and parameters: {'n_layers': 2, 'n_units_l0': 3, 'dropout_0': 0.20667528127190354, 'n_units_l1': 10, 'dropout_1': 0.34560743251226084, 'learning_rate': 0.06605445229516912, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.6663238489627838.
[I 2023-09-19 01:30:44,353] Trial 1 finished with value: 0.5568164423396511 and parameters: {'n_layers': 3, 'n_units_l0': 9, 'dropout_0': 0.10771252993735697, 'n_units_l1': 10, 'dropout_1': 0.1482985188773998, 'n_units_l2': 8, 'dropout_2': 0.1402313649446743, 'learning_rate': 0.0771066583239032, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.5568164423396511.
[I 2023-09-19 01:33:03,479] Trial 2 finished with value: 0.1526983328740443 and parameters: {'n_layers': 3, 'n_units_l0': 7, 'dropout_0': 0.15960507811180544, 'n_units_l1': 9, 'dropout_1': 0.3587908815887594, 'n_units_l2': 9, 'dropout_2': 0.18342455351188292, 'learning_rate': 0.0018486587891917833, 'optimizer': 'RMSprop'}. Best is trial 2 with value: 0.1526983328740443.
[I 2023-09-19 01:35:14,266] Trial 3 finished with value: 0.18588178671175432 and parameters: {'n_layers': 1, 'n_units_l0': 6, 'dropout_0': 0.16513962026846063, 'learning_rate': 0.041182799233251396, 'optimizer': 'SGD'}. Best is trial 2 with value: 0.1526983328740443.
[I 2023-09-19 01:37:30,173] Trial 4 finished with value: 0.39476290148112086 and parameters: {'n_layers': 3, 'n_units_l0': 2, 'dropout_0': 0.18265710264106655, 'n_units_l1': 10, 'dropout_1': 0.14638184047167985, 'n_units_l2': 5, 'dropout_2': 0.21661788811529423, 'learning_rate': 0.03144716054011337, 'optimizer': 'SGD'}. Best is trial 2 with value: 0.1526983328740443.
[I 2023-09-19 01:37:32,846] Trial 5 pruned.
[I 2023-09-19 01:37:45,972] Trial 6 pruned.
[I 2023-09-19 01:39:58,308] Trial 7 finished with value: 0.17333647577993333 and parameters: {'n_layers': 1, 'n_units_l0': 8, 'dropout_0': 0.2968986243750883, 'learning_rate': 0.002829890807865123, 'optimizer': 'RMSprop'}. Best is trial 2 with value: 0.1526983328740443.
[I 2023-09-19 01:40:14,226] Trial 8 pruned.
[I 2023-09-19 01:40:19,623] Trial 9 pruned.
Selected Catagories are:
['DMSO_0.100_DMSO_0.025' 'Thapsigargin_10.000_DMSO_0.025']
The dimensions of the data are: (382114, 1270)
Number of total missing values across all columns: 764228
Data Subset Is Off
Wells held out for testing: ['J06' 'L06']
Wells to use for training, validation, and testing ['B06' 'C06' 'B07' 'C07' 'E06' 'E07' 'I06' 'I07' 'J07' 'L07']
Number of in features:  1245
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 93.72665869501986
Validation Loss: 0.15364950426163212
Training Accuracy: 91.84505875841788
Training Loss: 0.19879459449240272
completed
