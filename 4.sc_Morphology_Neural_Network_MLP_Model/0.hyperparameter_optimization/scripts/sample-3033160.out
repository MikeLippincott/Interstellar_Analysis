[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: PBMC control_name: Flagellin_0.100_DMSO_0.025 treatment_name: LPS_Nigericin_1.000_3.0_DMSO_0.025
[I 2023-09-19 00:56:44,720] A new study created in memory with name: no-name-e626f91a-e317-43d2-8fd3-a07a32b75cc0
[I 2023-09-19 00:57:57,144] Trial 0 finished with value: 0.040633794453635345 and parameters: {'n_layers': 2, 'n_units_l0': 7, 'dropout_0': 0.29585074966572145, 'n_units_l1': 5, 'dropout_1': 0.1314946371105749, 'learning_rate': 0.01560541941123025, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.040633794453635345.
[I 2023-09-19 00:59:09,687] Trial 1 finished with value: 0.6348166287839412 and parameters: {'n_layers': 3, 'n_units_l0': 2, 'dropout_0': 0.22449408747054528, 'n_units_l1': 7, 'dropout_1': 0.15736464824253077, 'n_units_l2': 6, 'dropout_2': 0.1621663639463864, 'learning_rate': 0.095679580321157, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.040633794453635345.
[I 2023-09-19 01:00:21,584] Trial 2 finished with value: 0.28824745866656304 and parameters: {'n_layers': 2, 'n_units_l0': 7, 'dropout_0': 0.24935670181171748, 'n_units_l1': 9, 'dropout_1': 0.36833330629433003, 'learning_rate': 0.09143827310294438, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.040633794453635345.
[I 2023-09-19 01:01:35,106] Trial 3 finished with value: 0.6378158278465271 and parameters: {'n_layers': 3, 'n_units_l0': 7, 'dropout_0': 0.28228288747109787, 'n_units_l1': 8, 'dropout_1': 0.2770714323826424, 'n_units_l2': 5, 'dropout_2': 0.30310997904675985, 'learning_rate': 0.09701037217799516, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.040633794453635345.
[I 2023-09-19 01:02:46,226] Trial 4 finished with value: 0.10051839249953629 and parameters: {'n_layers': 3, 'n_units_l0': 4, 'dropout_0': 0.17081531178743703, 'n_units_l1': 5, 'dropout_1': 0.2690579993222889, 'n_units_l2': 3, 'dropout_2': 0.36105864545625954, 'learning_rate': 0.05185597361727697, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.040633794453635345.
[I 2023-09-19 01:03:57,417] Trial 5 finished with value: 0.05561451742937788 and parameters: {'n_layers': 2, 'n_units_l0': 10, 'dropout_0': 0.14291409708598293, 'n_units_l1': 2, 'dropout_1': 0.2817940659451492, 'learning_rate': 0.0831973804089503, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.040633794453635345.
[I 2023-09-19 01:05:12,244] Trial 6 finished with value: 0.040424206173862325 and parameters: {'n_layers': 3, 'n_units_l0': 7, 'dropout_0': 0.39822652862974306, 'n_units_l1': 10, 'dropout_1': 0.15998466794278376, 'n_units_l2': 6, 'dropout_2': 0.3913440823964839, 'learning_rate': 0.012461435562816543, 'optimizer': 'Adam'}. Best is trial 6 with value: 0.040424206173862325.
[I 2023-09-19 01:05:29,376] Trial 7 pruned.
[I 2023-09-19 01:06:43,221] Trial 8 finished with value: 0.20293138130009175 and parameters: {'n_layers': 3, 'n_units_l0': 9, 'dropout_0': 0.19380367130697612, 'n_units_l1': 6, 'dropout_1': 0.286310970158726, 'n_units_l2': 5, 'dropout_2': 0.18404078632990922, 'learning_rate': 0.06139799840517794, 'optimizer': 'Adam'}. Best is trial 6 with value: 0.040424206173862325.
[I 2023-09-19 01:06:44,645] Trial 9 pruned.
Selected Catagories are:
['LPS_Nigericin_1.000_3.0_DMSO_0.025' 'Flagellin_0.100_DMSO_0.025']
The dimensions of the data are: (270176, 1270)
Number of total missing values across all columns: 191830
Data Subset Is Off
Wells held out for testing: ['L08' 'L10']
Wells to use for training, validation, and testing ['L02' 'L03' 'L05' 'L09' 'L11']
Number of in features:  1245
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 98.46683820826549
Validation Loss: 0.04459919195156545
Training Accuracy: 94.31883106653362
Training Loss: 0.13354565588282605
completed
