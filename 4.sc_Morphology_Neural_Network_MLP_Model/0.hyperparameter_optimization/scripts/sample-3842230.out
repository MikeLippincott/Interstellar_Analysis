[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8867 bytes to Hyperparameter_Optimization_model_binary.py
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_multiclass.ipynb to script
/projects/mlippincott@xsede.org/software/anaconda/envs/Interstellar_python/lib/python3.10/site-packages/nbformat/__init__.py:93: MissingIDFieldWarning: Code cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.
  validate(nb)
[NbConvertApp] Writing 14974 bytes to Hyperparameter_Optimization_model_multiclass.py
[I 2023-11-22 12:49:01,319] A new study created in memory with name: no-name-84e839a6-5cff-47f1-a2c1-86abb662a2bd
[I 2023-11-22 12:53:39,803] Trial 0 finished with value: 0.9214871782915935 and parameters: {'n_layers': 13, 'n_units_l0': 32, 'dropout_0': 0.164719801611189, 'n_units_l1': 36, 'dropout_1': 0.26421089450097496, 'n_units_l2': 34, 'dropout_2': 0.3828416617815604, 'n_units_l3': 42, 'dropout_3': 0.18023098361960474, 'n_units_l4': 43, 'dropout_4': 0.25424193957001695, 'n_units_l5': 22, 'dropout_5': 0.15541007086236175, 'n_units_l6': 41, 'dropout_6': 0.25661937797808276, 'n_units_l7': 10, 'dropout_7': 0.1516723781499757, 'n_units_l8': 16, 'dropout_8': 0.22388446474387763, 'n_units_l9': 23, 'dropout_9': 0.39578757817146404, 'n_units_l10': 9, 'dropout_10': 0.3074825583653379, 'n_units_l11': 49, 'dropout_11': 0.31315404988037576, 'n_units_l12': 35, 'dropout_12': 0.3232213215252956, 'learning_rate': 0.032732959842192585, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.9214871782915935.
[I 2023-11-22 12:57:44,254] Trial 1 finished with value: 0.9448779308086347 and parameters: {'n_layers': 7, 'n_units_l0': 37, 'dropout_0': 0.21882621239715322, 'n_units_l1': 10, 'dropout_1': 0.3403952640361896, 'n_units_l2': 39, 'dropout_2': 0.36686889121906274, 'n_units_l3': 23, 'dropout_3': 0.32974722328935135, 'n_units_l4': 25, 'dropout_4': 0.37450544298790656, 'n_units_l5': 43, 'dropout_5': 0.20178028993443672, 'n_units_l6': 25, 'dropout_6': 0.3074657082047226, 'learning_rate': 0.08223841795386048, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.9214871782915935.
[I 2023-11-22 13:01:38,192] Trial 2 finished with value: 0.9256667217754183 and parameters: {'n_layers': 6, 'n_units_l0': 28, 'dropout_0': 0.13947026160785553, 'n_units_l1': 19, 'dropout_1': 0.19207450941094734, 'n_units_l2': 49, 'dropout_2': 0.161778800573398, 'n_units_l3': 5, 'dropout_3': 0.18149533297441522, 'n_units_l4': 5, 'dropout_4': 0.3527323904382279, 'n_units_l5': 35, 'dropout_5': 0.2790900360703641, 'learning_rate': 0.03216970724330469, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.9214871782915935.
[I 2023-11-22 13:05:44,464] Trial 3 finished with value: 0.9228309224049248 and parameters: {'n_layers': 7, 'n_units_l0': 47, 'dropout_0': 0.23573337408481695, 'n_units_l1': 42, 'dropout_1': 0.31534454878856455, 'n_units_l2': 2, 'dropout_2': 0.3018005512721608, 'n_units_l3': 20, 'dropout_3': 0.30940298717928005, 'n_units_l4': 30, 'dropout_4': 0.3070698639598185, 'n_units_l5': 25, 'dropout_5': 0.13122775627557084, 'n_units_l6': 13, 'dropout_6': 0.26532766497039706, 'learning_rate': 0.018891046208352226, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.9214871782915935.
[I 2023-11-22 13:09:26,064] Trial 4 finished with value: 0.9503877067991665 and parameters: {'n_layers': 5, 'n_units_l0': 5, 'dropout_0': 0.3726151556447469, 'n_units_l1': 38, 'dropout_1': 0.39261054751918556, 'n_units_l2': 17, 'dropout_2': 0.11725890622556821, 'n_units_l3': 12, 'dropout_3': 0.17886900405946443, 'n_units_l4': 11, 'dropout_4': 0.19084830860371266, 'learning_rate': 0.09252002080233977, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.9214871782915935.
[I 2023-11-22 13:13:07,831] Trial 5 finished with value: 0.7895251164407958 and parameters: {'n_layers': 3, 'n_units_l0': 29, 'dropout_0': 0.3919174341232907, 'n_units_l1': 20, 'dropout_1': 0.35932466651098427, 'n_units_l2': 45, 'dropout_2': 0.15688514004788973, 'learning_rate': 0.023966874108553724, 'optimizer': 'Adam'}. Best is trial 5 with value: 0.7895251164407958.
[I 2023-11-22 13:17:32,029] Trial 6 finished with value: 0.9213324096373151 and parameters: {'n_layers': 13, 'n_units_l0': 3, 'dropout_0': 0.18284660268892927, 'n_units_l1': 46, 'dropout_1': 0.16552608354041112, 'n_units_l2': 24, 'dropout_2': 0.3116275513628244, 'n_units_l3': 15, 'dropout_3': 0.2288172626209751, 'n_units_l4': 10, 'dropout_4': 0.2297547204377154, 'n_units_l5': 50, 'dropout_5': 0.28960467532623557, 'n_units_l6': 41, 'dropout_6': 0.23512600745960022, 'n_units_l7': 49, 'dropout_7': 0.21522364590327375, 'n_units_l8': 13, 'dropout_8': 0.26874138464619063, 'n_units_l9': 31, 'dropout_9': 0.1458899093236757, 'n_units_l10': 28, 'dropout_10': 0.21955419394431996, 'n_units_l11': 46, 'dropout_11': 0.21428266593990805, 'n_units_l12': 39, 'dropout_12': 0.29823736389411637, 'learning_rate': 0.08500592535515454, 'optimizer': 'SGD'}. Best is trial 5 with value: 0.7895251164407958.
[I 2023-11-22 13:17:34,453] Trial 7 pruned. 
[I 2023-11-22 13:21:13,127] Trial 8 finished with value: 0.5575721866034326 and parameters: {'n_layers': 3, 'n_units_l0': 33, 'dropout_0': 0.24291597733035475, 'n_units_l1': 7, 'dropout_1': 0.19338287535111007, 'n_units_l2': 50, 'dropout_2': 0.38512194989899473, 'learning_rate': 0.04248919807791556, 'optimizer': 'SGD'}. Best is trial 8 with value: 0.5575721866034326.
[I 2023-11-22 13:21:15,655] Trial 9 pruned. 
[I 2023-11-22 13:21:17,729] Trial 10 pruned. 
[I 2023-11-22 13:24:48,186] Trial 11 finished with value: 0.7369671682374819 and parameters: {'n_layers': 2, 'n_units_l0': 20, 'dropout_0': 0.3064152322005456, 'n_units_l1': 16, 'dropout_1': 0.10142281332004707, 'learning_rate': 0.05394194953985448, 'optimizer': 'Adam'}. Best is trial 8 with value: 0.5575721866034326.
[I 2023-11-22 13:28:18,659] Trial 12 finished with value: 0.5566911677164691 and parameters: {'n_layers': 2, 'n_units_l0': 14, 'dropout_0': 0.2977169686228536, 'n_units_l1': 12, 'dropout_1': 0.10041783608551323, 'learning_rate': 0.05461596856410496, 'optimizer': 'SGD'}. Best is trial 12 with value: 0.5566911677164691.
[I 2023-11-22 13:32:00,587] Trial 13 finished with value: 0.5841876030819756 and parameters: {'n_layers': 4, 'n_units_l0': 15, 'dropout_0': 0.29053030221080595, 'n_units_l1': 4, 'dropout_1': 0.10484610639820026, 'n_units_l2': 11, 'dropout_2': 0.22645277221079302, 'n_units_l3': 48, 'dropout_3': 0.1251269392751193, 'learning_rate': 0.053181377438549345, 'optimizer': 'SGD'}. Best is trial 12 with value: 0.5566911677164691.
[I 2023-11-22 13:32:03,083] Trial 14 pruned. 
[I 2023-11-22 13:35:26,433] Trial 15 finished with value: 0.5432412011140869 and parameters: {'n_layers': 1, 'n_units_l0': 23, 'dropout_0': 0.26308392959796284, 'learning_rate': 0.06561760183969936, 'optimizer': 'SGD'}. Best is trial 15 with value: 0.5432412011140869.
[I 2023-11-22 13:38:49,712] Trial 16 finished with value: 0.543088704603059 and parameters: {'n_layers': 1, 'n_units_l0': 22, 'dropout_0': 0.3218820563109912, 'learning_rate': 0.06778431070472593, 'optimizer': 'SGD'}. Best is trial 16 with value: 0.543088704603059.
[I 2023-11-22 13:42:13,553] Trial 17 finished with value: 0.5462456291843028 and parameters: {'n_layers': 1, 'n_units_l0': 22, 'dropout_0': 0.3555005503789368, 'learning_rate': 0.07782331265079295, 'optimizer': 'SGD'}. Best is trial 16 with value: 0.543088704603059.
[I 2023-11-22 13:42:16,042] Trial 18 pruned. 
[I 2023-11-22 13:42:18,163] Trial 19 pruned. 
[I 2023-11-22 13:42:20,802] Trial 20 pruned. 
[I 2023-11-22 13:45:44,526] Trial 21 finished with value: 0.544144906309389 and parameters: {'n_layers': 1, 'n_units_l0': 23, 'dropout_0': 0.3539107829834156, 'learning_rate': 0.07607545236309377, 'optimizer': 'SGD'}. Best is trial 16 with value: 0.543088704603059.
[I 2023-11-22 13:49:09,148] Trial 22 finished with value: 0.5397723420248146 and parameters: {'n_layers': 1, 'n_units_l0': 25, 'dropout_0': 0.3299145560433092, 'learning_rate': 0.07513694982677938, 'optimizer': 'SGD'}. Best is trial 22 with value: 0.5397723420248146.
[I 2023-11-22 13:52:43,900] Trial 23 finished with value: 0.5648762533139614 and parameters: {'n_layers': 3, 'n_units_l0': 24, 'dropout_0': 0.269884333171687, 'n_units_l1': 25, 'dropout_1': 0.39589873917635154, 'n_units_l2': 39, 'dropout_2': 0.25115457634453286, 'learning_rate': 0.0742759349103599, 'optimizer': 'SGD'}. Best is trial 22 with value: 0.5397723420248146.
[I 2023-11-22 13:56:14,150] Trial 24 finished with value: 0.5578150227949732 and parameters: {'n_layers': 2, 'n_units_l0': 18, 'dropout_0': 0.31891862094582835, 'n_units_l1': 31, 'dropout_1': 0.22420288485444137, 'learning_rate': 0.06170771350132657, 'optimizer': 'SGD'}. Best is trial 22 with value: 0.5397723420248146.
[I 2023-11-22 13:56:16,458] Trial 25 pruned. 
[I 2023-11-22 13:59:43,853] Trial 26 finished with value: 0.5396976895488443 and parameters: {'n_layers': 1, 'n_units_l0': 26, 'dropout_0': 0.2829693412607791, 'learning_rate': 0.04726159580451309, 'optimizer': 'SGD'}. Best is trial 26 with value: 0.5396976895488443.
[I 2023-11-22 13:59:46,034] Trial 27 pruned. 
[I 2023-11-22 13:59:48,388] Trial 28 pruned. 
[I 2023-11-22 13:59:50,580] Trial 29 pruned. 
[I 2023-11-22 13:59:53,108] Trial 30 pruned. 
[I 2023-11-22 14:03:17,943] Trial 31 finished with value: 0.5411285109037445 and parameters: {'n_layers': 1, 'n_units_l0': 25, 'dropout_0': 0.26976654090014385, 'learning_rate': 0.062076554995121866, 'optimizer': 'SGD'}. Best is trial 26 with value: 0.5396976895488443.
[I 2023-11-22 14:06:45,282] Trial 32 finished with value: 0.5399712734137263 and parameters: {'n_layers': 1, 'n_units_l0': 26, 'dropout_0': 0.28000077073848356, 'learning_rate': 0.0791456176111695, 'optimizer': 'SGD'}. Best is trial 26 with value: 0.5396976895488443.
[I 2023-11-22 14:10:19,608] Trial 33 finished with value: 0.5542903426786264 and parameters: {'n_layers': 2, 'n_units_l0': 34, 'dropout_0': 0.27556490663877564, 'n_units_l1': 33, 'dropout_1': 0.26508315558887396, 'learning_rate': 0.07902260131793475, 'optimizer': 'SGD'}. Best is trial 26 with value: 0.5396976895488443.
[I 2023-11-22 14:10:21,965] Trial 34 pruned. 
[I 2023-11-22 14:10:24,286] Trial 35 pruned. 
[I 2023-11-22 14:10:26,427] Trial 36 pruned. 
[I 2023-11-22 14:10:28,685] Trial 37 pruned. 
[I 2023-11-22 14:10:31,127] Trial 38 pruned. 
[I 2023-11-22 14:10:33,510] Trial 39 pruned. 
[I 2023-11-22 14:10:35,687] Trial 40 pruned. 
[I 2023-11-22 14:14:05,430] Trial 41 finished with value: 0.5364830810257366 and parameters: {'n_layers': 1, 'n_units_l0': 29, 'dropout_0': 0.29754635498334175, 'learning_rate': 0.07055814731511369, 'optimizer': 'SGD'}. Best is trial 41 with value: 0.5364830810257366.
[I 2023-11-22 14:14:07,499] Trial 42 pruned. 
[I 2023-11-22 14:17:37,929] Trial 43 finished with value: 0.5362689739607629 and parameters: {'n_layers': 1, 'n_units_l0': 50, 'dropout_0': 0.2761006792828209, 'learning_rate': 0.07149477000486187, 'optimizer': 'SGD'}. Best is trial 43 with value: 0.5362689739607629.
[I 2023-11-22 14:17:40,216] Trial 44 pruned. 
[I 2023-11-22 14:21:19,264] Trial 45 finished with value: 0.555852159481673 and parameters: {'n_layers': 2, 'n_units_l0': 45, 'dropout_0': 0.2812816394140583, 'n_units_l1': 39, 'dropout_1': 0.37086529113453, 'learning_rate': 0.07244376997277414, 'optimizer': 'SGD'}. Best is trial 43 with value: 0.5362689739607629.
[I 2023-11-22 14:24:50,565] Trial 46 finished with value: 0.5386278604893457 and parameters: {'n_layers': 1, 'n_units_l0': 49, 'dropout_0': 0.29446042057718047, 'learning_rate': 0.08512348832738043, 'optimizer': 'SGD'}. Best is trial 43 with value: 0.5362689739607629.
[I 2023-11-22 14:28:27,545] Trial 47 finished with value: 0.5579228705593517 and parameters: {'n_layers': 2, 'n_units_l0': 50, 'dropout_0': 0.3007512352496167, 'n_units_l1': 44, 'dropout_1': 0.3986616598545454, 'learning_rate': 0.08764656460800904, 'optimizer': 'SGD'}. Best is trial 43 with value: 0.5362689739607629.
[I 2023-11-22 14:28:30,411] Trial 48 pruned. 
[I 2023-11-22 14:28:32,567] Trial 49 pruned. 
Data Subset Is Off
Wells held out for testing: ['F14' 'D15' 'G17' 'H17' 'D18' 'E18' 'B19' 'G19' 'D20' 'F20' 'B21' 'C21'
 'E21' 'F22' 'H22' 'C23' 'J13' 'K13' 'L13' 'I14' 'L14' 'N14' 'O15' 'J16'
 'N16' 'O17' 'I18' 'L18' 'M18' 'O18' 'I20' 'K20' 'L21' 'M21' 'N22' 'O22'
 'J23' 'K23']
Wells to use for training, validation, and testing ['B13' 'C13' 'D13' 'E13' 'F13' 'G13' 'H13' 'B14' 'C14' 'D14' 'E14' 'F14'
 'G14' 'H14' 'B15' 'C15' 'D15' 'E15' 'F15' 'G15' 'H15' 'B16' 'C16' 'D16'
 'E16' 'F16' 'G16' 'H16' 'B17' 'C17' 'D17' 'E17' 'F17' 'G17' 'H17' 'B18'
 'C18' 'D18' 'E18' 'F18' 'G18' 'H18' 'B19' 'C19' 'D19' 'E19' 'F19' 'G19'
 'H19' 'B20' 'C20' 'D20' 'E20' 'F20' 'G20' 'H20' 'B21' 'C21' 'D21' 'E21'
 'F21' 'G21' 'H21' 'B22' 'C22' 'D22' 'E22' 'F22' 'G22' 'H22' 'B23' 'C23'
 'D23' 'E23' 'F23' 'G23' 'H23' 'I13' 'J13' 'K13' 'L13' 'M13' 'N13' 'O13'
 'I14' 'J14' 'K14' 'L14' 'M14' 'N14' 'O14' 'I15' 'J15' 'K15' 'L15' 'M15'
 'N15' 'O15' 'I16' 'J16' 'K16' 'L16' 'M16' 'N16' 'O16' 'I17' 'J17' 'K17'
 'L17' 'M17' 'N17' 'O17' 'I18' 'J18' 'K18' 'L18' 'M18' 'N18' 'O18' 'I19'
 'J19' 'K19' 'L19' 'M19' 'N19' 'O19' 'I20' 'J20' 'K20' 'L20' 'M20' 'N20'
 'O20' 'I21' 'J21' 'K21' 'L21' 'M21' 'N21' 'O21' 'I22' 'J22' 'K22' 'L22'
 'M22' 'N22' 'O22' 'I23' 'J23' 'K23' 'L23' 'M23' 'N23' 'O23']
(22551, 1277) (23407, 1277) (401043, 1277)
Shape for the 100% test set: (22551, 1277)

Shape for the 75% test set: (5851, 1277);
Shape for the 75% train set: (17556, 1277)

Shape for the 50% test set: (200521, 1277);
Shape for the 50% train set: (200522, 1277)
Shape for the holdout set: (150901, 1277)

    Testing set length: 218078

    Training set length: 165097

    Validation set length: 41275

    Treatment Holdout set length: 22551

    Holdout set length: 150901
(165097,) (41275,) (218078,) (22551,) (150901,)
597902
../indexes/SHSY5Y/multi_class
['apoptosis' 'healthy' 'pyroptosis'] [ 26978 310701 260223]
[0, 1, 2] [0.954878893196544, 0.4803479499984947, 0.5647731568049614]
Number of in features:  1251
Number of out features:  3
Multi_Class
cpu
Validation Accuracy: 75.68322228952151
Validation Loss: 0.5375701287104971
Training Accuracy: 78.1473133975784
Training Loss: 0.4682136663318757
Done
