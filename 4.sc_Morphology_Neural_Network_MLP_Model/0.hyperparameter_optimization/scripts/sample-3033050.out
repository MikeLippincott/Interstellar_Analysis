[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: PBMC control_name: Flagellin_1.000_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025
[I 2023-09-19 00:36:11,776] A new study created in memory with name: no-name-21019c95-1daf-4ed6-a020-bee80d05e992
[I 2023-09-19 00:36:40,985] Trial 0 finished with value: 0.0005419742169957411 and parameters: {'n_layers': 1, 'n_units_l0': 5, 'dropout_0': 0.32963639038362696, 'learning_rate': 0.03873617242535957, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.0005419742169957411.
[I 2023-09-19 00:37:11,630] Trial 1 finished with value: 7.188065333146915e-05 and parameters: {'n_layers': 3, 'n_units_l0': 10, 'dropout_0': 0.3600487298806978, 'n_units_l1': 3, 'dropout_1': 0.10929915233836203, 'n_units_l2': 4, 'dropout_2': 0.24819874815778895, 'learning_rate': 0.018607926166454448, 'optimizer': 'RMSprop'}. Best is trial 1 with value: 7.188065333146915e-05.
[I 2023-09-19 00:37:42,289] Trial 2 finished with value: 5.07630606068193e-05 and parameters: {'n_layers': 2, 'n_units_l0': 7, 'dropout_0': 0.2774991046260995, 'n_units_l1': 2, 'dropout_1': 0.171650162423017, 'learning_rate': 0.09670736026065756, 'optimizer': 'Adam'}. Best is trial 2 with value: 5.07630606068193e-05.
[I 2023-09-19 00:38:11,831] Trial 3 finished with value: 1.842947358070802 and parameters: {'n_layers': 1, 'n_units_l0': 10, 'dropout_0': 0.10607756777207614, 'learning_rate': 0.04386035920602374, 'optimizer': 'RMSprop'}. Best is trial 2 with value: 5.07630606068193e-05.
[I 2023-09-19 00:38:42,470] Trial 4 finished with value: 3.017757684328987e-05 and parameters: {'n_layers': 2, 'n_units_l0': 7, 'dropout_0': 0.25827545675712027, 'n_units_l1': 10, 'dropout_1': 0.24733837247877835, 'learning_rate': 0.061189877352819166, 'optimizer': 'Adam'}. Best is trial 4 with value: 3.017757684328987e-05.
[I 2023-09-19 00:38:43,072] Trial 5 pruned.
[I 2023-09-19 00:38:44,238] Trial 6 pruned.
[I 2023-09-19 00:39:14,514] Trial 7 finished with value: 9.995715136419392e-06 and parameters: {'n_layers': 3, 'n_units_l0': 9, 'dropout_0': 0.20884696361140656, 'n_units_l1': 9, 'dropout_1': 0.24758165551873962, 'n_units_l2': 8, 'dropout_2': 0.27685476053354924, 'learning_rate': 0.09149657424892942, 'optimizer': 'SGD'}. Best is trial 7 with value: 9.995715136419392e-06.
[I 2023-09-19 00:39:15,142] Trial 8 pruned.
[I 2023-09-19 00:39:45,267] Trial 9 finished with value: 1.620531422922955e-05 and parameters: {'n_layers': 3, 'n_units_l0': 2, 'dropout_0': 0.1679476508922655, 'n_units_l1': 8, 'dropout_1': 0.11717364614844225, 'n_units_l2': 6, 'dropout_2': 0.24319471780995597, 'learning_rate': 0.031140476839810315, 'optimizer': 'SGD'}. Best is trial 7 with value: 9.995715136419392e-06.
Selected Catagories are:
['Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (104547, 1270)
Number of total missing values across all columns: 245710
Data Subset Is Off
Wells held out for testing: ['M10']
Wells to use for training, validation, and testing ['M05' 'M11']
Number of in features:  1245
Number of out features:  1
Regression
cpu
Validation Loss: 1.0816684313823544e-05
Training Loss: 0.0002642270846674141
completed
