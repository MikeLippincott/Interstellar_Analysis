[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: SHSY5Y control_name: LPS_10.000_DMSO_0.025 treatment_name: LPS_0.010_DMSO_0.025
[I 2023-09-17 20:27:08,027] A new study created in memory with name: no-name-3837fb76-4a20-468f-a5cf-a683e37e1ddd
[I 2023-09-17 20:27:18,510] Trial 0 finished with value: 0.5769578464825947 and parameters: {'n_layers': 2, 'n_units_l0': 2, 'dropout_0': 0.2991936150486614, 'n_units_l1': 8, 'dropout_1': 0.19067448121570793, 'learning_rate': 0.029693745580734572, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.5769578464825947.
[I 2023-09-17 20:27:28,627] Trial 1 finished with value: 0.5571812407175699 and parameters: {'n_layers': 1, 'n_units_l0': 2, 'dropout_0': 0.36091847118405873, 'learning_rate': 0.01761193184880803, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.5571812407175699.
[I 2023-09-17 20:27:38,616] Trial 2 finished with value: 0.5993369201819102 and parameters: {'n_layers': 2, 'n_units_l0': 9, 'dropout_0': 0.29531098472237616, 'n_units_l1': 10, 'dropout_1': 0.10606319855065524, 'learning_rate': 0.046946415456277236, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.5571812407175699.
[I 2023-09-17 20:27:48,607] Trial 3 finished with value: 0.5430666848023733 and parameters: {'n_layers': 1, 'n_units_l0': 4, 'dropout_0': 0.28002305621664925, 'learning_rate': 0.09024211934642554, 'optimizer': 'SGD'}. Best is trial 3 with value: 0.5430666848023733.
[I 2023-09-17 20:27:58,864] Trial 4 finished with value: 0.5918097408612569 and parameters: {'n_layers': 2, 'n_units_l0': 10, 'dropout_0': 0.10267317850945275, 'n_units_l1': 3, 'dropout_1': 0.2761028586720858, 'learning_rate': 0.054299042791970134, 'optimizer': 'Adam'}. Best is trial 3 with value: 0.5430666848023733.
[I 2023-09-17 20:27:59,049] Trial 5 pruned.
[I 2023-09-17 20:27:59,325] Trial 6 pruned.
[I 2023-09-17 20:28:09,310] Trial 7 finished with value: 0.555543252627055 and parameters: {'n_layers': 1, 'n_units_l0': 3, 'dropout_0': 0.24396479772440707, 'learning_rate': 0.09042831624194898, 'optimizer': 'Adam'}. Best is trial 3 with value: 0.5430666848023733.
[I 2023-09-17 20:28:09,491] Trial 8 pruned.
[I 2023-09-17 20:28:19,917] Trial 9 finished with value: 0.546535605986913 and parameters: {'n_layers': 2, 'n_units_l0': 8, 'dropout_0': 0.2694913643719153, 'n_units_l1': 10, 'dropout_1': 0.1323432286457697, 'learning_rate': 0.03869223282354953, 'optimizer': 'Adam'}. Best is trial 3 with value: 0.5430666848023733.
Selected Catagories are:
['LPS_0.010_DMSO_0.025' 'LPS_10.000_DMSO_0.025']
The dimensions of the data are: (32669, 1276)
Number of total missing values across all columns: 65338
Data Subset Is Off
Wells held out for testing: ['B20' 'E21']
Wells to use for training, validation, and testing ['B16' 'E16' 'B17' 'E17' 'E20' 'B21']
Number of in features:  1251
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 72.96448748991122
Validation Loss: 0.5427861738204957
Training Accuracy: 73.46662630543364
Training Loss: 0.5198562892973423
completed
