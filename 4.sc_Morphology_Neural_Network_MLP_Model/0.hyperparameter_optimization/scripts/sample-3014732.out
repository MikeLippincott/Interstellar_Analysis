[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
[NbConvertApp] Converting notebook ../notebooks/Hyperparameter_Optimization_model_binary.ipynb to script
[NbConvertApp] Writing 8579 bytes to Hyperparameter_Optimization_model_binary.py
cell_type: SHSY5Y control_name: LPS_100.000_DMSO_0.025 treatment_name: Flagellin_1.000_DMSO_0.025
[I 2023-09-17 19:44:39,045] A new study created in memory with name: no-name-736b892b-670c-4ca3-9a00-42391fa19d59
[I 2023-09-17 19:44:52,231] Trial 0 finished with value: 0.2725216888387998 and parameters: {'n_layers': 3, 'n_units_l0': 10, 'dropout_0': 0.11371239336341445, 'n_units_l1': 5, 'dropout_1': 0.27416838597728954, 'n_units_l2': 3, 'dropout_2': 0.27650951421972886, 'learning_rate': 0.04137591073383423, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.2725216888387998.
[I 2023-09-17 19:45:04,255] Trial 1 finished with value: 0.34503258287906646 and parameters: {'n_layers': 3, 'n_units_l0': 4, 'dropout_0': 0.36494481628621, 'n_units_l1': 4, 'dropout_1': 0.390786658482869, 'n_units_l2': 10, 'dropout_2': 0.31165357752768263, 'learning_rate': 0.09516803102626607, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.2725216888387998.
[I 2023-09-17 19:45:16,295] Trial 2 finished with value: 0.6912302625179292 and parameters: {'n_layers': 3, 'n_units_l0': 7, 'dropout_0': 0.14308814451789076, 'n_units_l1': 7, 'dropout_1': 0.12792682263011154, 'n_units_l2': 7, 'dropout_2': 0.3851192450756332, 'learning_rate': 0.013865504595171399, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.2725216888387998.
[I 2023-09-17 19:45:27,501] Trial 3 finished with value: 0.25041311621665957 and parameters: {'n_layers': 1, 'n_units_l0': 7, 'dropout_0': 0.236804859492495, 'learning_rate': 0.08198373978150444, 'optimizer': 'Adam'}. Best is trial 3 with value: 0.25041311621665957.
[I 2023-09-17 19:45:38,865] Trial 4 finished with value: 0.29940528750419615 and parameters: {'n_layers': 2, 'n_units_l0': 2, 'dropout_0': 0.23712160759428363, 'n_units_l1': 10, 'dropout_1': 0.3537240447613884, 'learning_rate': 0.05870573178408431, 'optimizer': 'Adam'}. Best is trial 3 with value: 0.25041311621665957.
[I 2023-09-17 19:45:39,073] Trial 5 pruned.
[I 2023-09-17 19:45:39,274] Trial 6 pruned.
[I 2023-09-17 19:45:49,891] Trial 7 finished with value: 0.21519038091103238 and parameters: {'n_layers': 1, 'n_units_l0': 8, 'dropout_0': 0.15216601854348874, 'learning_rate': 0.02548261705347436, 'optimizer': 'Adam'}. Best is trial 7 with value: 0.21519038091103238.
[I 2023-09-17 19:45:50,168] Trial 8 pruned.
[I 2023-09-17 19:46:01,223] Trial 9 finished with value: 0.1983855211734772 and parameters: {'n_layers': 1, 'n_units_l0': 10, 'dropout_0': 0.1790762387129889, 'learning_rate': 0.091249028902194, 'optimizer': 'SGD'}. Best is trial 9 with value: 0.1983855211734772.
Selected Catagories are:
['LPS_100.000_DMSO_0.025' 'Flagellin_1.000_DMSO_0.025']
The dimensions of the data are: (31796, 1276)
Number of total missing values across all columns: 63592
Data Subset Is Off
Wells held out for testing: ['J16' 'M22']
Wells to use for training, validation, and testing ['J17' 'M18' 'M19' 'J20' 'J21' 'M23']
Number of in features:  1251
Number of out features:  2
Binary_Classification
cpu
Validation Accuracy: 92.83277027027026
Validation Loss: 0.19497417440017062
Training Accuracy: 91.95047518479409
Training Loss: 0.20166380356016908
completed
