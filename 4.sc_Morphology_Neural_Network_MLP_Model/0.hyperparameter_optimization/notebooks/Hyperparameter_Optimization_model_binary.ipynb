{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [3]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning via Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Being a binary model this notebook will be limited to predicting one class 1 or 0, yes or no.<br>\n",
    "### Here I will be predicting if a cell received a treatment or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[1]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import toml\n",
    "import torch\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MLP_utils.parameters import Parameters\n",
    "from MLP_utils.utils import (\n",
    "    Dataset_formatter,\n",
    "    data_split,\n",
    "    extract_best_trial_params,\n",
    "    objective_model_optimizer,\n",
    "    parameter_set,\n",
    "    plot_metric_vs_epoch,\n",
    "    results_output,\n",
    "    test_optimized_model,\n",
    "    train_optimized_model,\n",
    "    un_nest,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../..\")\n",
    "from utils.utils import df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Papermill is used for executing notebooks in the CLI with multiple parameters<br>\n",
    "Here the `injected-parameters` cell is used to inject parameters into the notebook via papermill.<br>\n",
    "This enables multiple notebooks to be executed with different parameters, preventing to manually update parameters or have multiple copies of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[2]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CELL_TYPE = \"PBMC\"\n",
    "MODEL_NAME = \"MultiClass_MLP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[3]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_configs_file = pathlib.Path(\"../../MLP_utils/binary_config.toml\").resolve(\n",
    "    strict=True\n",
    ")\n",
    "ml_configs = toml.load(ml_configs_file)\n",
    "params = Parameters()\n",
    "mlp_params = parameter_set(params, ml_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "overwrite params via command line arguments from papermill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_params.CELL_TYPE = CELL_TYPE\n",
    "mlp_params.MODEL_NAME = MODEL_NAME\n",
    "mlp_params.CONTROL_NAME = CONTROL_NAME\n",
    "mlp_params.TREATMENT_NAME = TREATMENT_NAME\n",
    "mlp_params.MODEL_NAME = MODEL_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data<br>\n",
    "set data file path under pathlib path for multi-system use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = pathlib.Path(\n",
    "    f\"../../../data/{mlp_params.CELL_TYPE}_preprocessed_sc_norm.parquet\"\n",
    ").resolve(strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pq.read_table(file_path).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up Data to be compatible with model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classification Models:<br>\n",
    "Comment out code if using regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter the oneb_Metadata_Treatment_Dose_Inhibitor_Dose column to only include the treatment and control via loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[\n",
    "    df[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"].isin(\n",
    "        [mlp_params.TREATMENT_NAME, mlp_params.CONTROL_NAME]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Selected Catagories are:\")\n",
    "print(df[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"].unique())\n",
    "df_stats(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mlp_params.DATA_SUBSET_OPTION == \"True\":\n",
    "    df = df.sample(n=mlp_params.DATA_SUBSET_NUMBER)\n",
    "    print(\"Data Subset Is On\")\n",
    "    print(f\"Data is subset to {mlp_params.DATA_SUBSET_NUMBER}\")\n",
    "else:\n",
    "    print(\"Data Subset Is Off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=0)\n",
    "wells_to_hold = (\n",
    "    df.groupby(\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\")\n",
    "    .agg(np.random.choice)[\"Metadata_Well\"]\n",
    "    .to_list()\n",
    ")\n",
    "df_holdout = df[df[\"Metadata_Well\"].isin(wells_to_hold)]\n",
    "df = df[~df[\"Metadata_Well\"].isin(wells_to_hold)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Wells held out for testing:\", df_holdout[\"Metadata_Well\"].unique())\n",
    "print(\n",
    "    \"Wells to use for training, validation, and testing\", df[\"Metadata_Well\"].unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code snippet for metadata extraction by Jenna Tomkinson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata = list(df.columns[df.columns.str.startswith(\"Metadata\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define which columns are data and which are descriptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descriptive = df[df_metadata]\n",
    "df_values = df.drop(columns=df_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "# Converting strings into numbers\n",
    "df_values[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"] = le.fit_transform(\n",
    "    df_values[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"]\n",
    ")\n",
    "# split into X and Y where Y are the predictive column and x are the observable data\n",
    "df_values_X = df_values.drop(\n",
    "    [\n",
    "        \"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\",\n",
    "        \"twob_Metadata_Treatment_Dose_Inhibitor_Dose\",\n",
    "        \"threeb_Metadata_Treatment_Dose_Inhibitor_Dose\",\n",
    "        \"fourb_Metadata_Treatment_Dose_Inhibitor_Dose\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "df_values_Y = df_values[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Data - All Models can proceed through this point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, X_val, Y_train, Y_test, Y_val = data_split(\n",
    "    X_vals=df_values_X,\n",
    "    y_vals=df_values_Y,\n",
    "    train_proportion=0.8,\n",
    "    val_proportion=0.1,\n",
    "    test_proportion=0.1,\n",
    "    seed=1,\n",
    "    params=params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "produce data objects for train, val and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset_formatter(\n",
    "    torch.FloatTensor(X_train.values), torch.FloatTensor(Y_train.values)\n",
    ")\n",
    "val_data = Dataset_formatter(\n",
    "    torch.FloatTensor(X_val.values), torch.FloatTensor(Y_val.values)\n",
    ")\n",
    "test_data = Dataset_formatter(\n",
    "    torch.FloatTensor(X_test.values), torch.FloatTensor(Y_test.values)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_params.IN_FEATURES = X_train.shape[1]\n",
    "print(\"Number of in features: \", mlp_params.IN_FEATURES)\n",
    "if mlp_params.MODEL_TYPE == \"Regression\":\n",
    "    mlp_params.OUT_FEATURES = 1\n",
    "else:\n",
    "    mlp_params.OUT_FEATURES = len(\n",
    "        df_values[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"].unique()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of out features: \", mlp_params.OUT_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mlp_params.OUT_FEATURES > 2:\n",
    "    mlp_params.MODEL_TYPE = \"Multi_Class\"\n",
    "elif mlp_params.OUT_FEATURES == 2:\n",
    "    mlp_params.OUT_FEATURES = mlp_params.OUT_FEATURES - 1\n",
    "    mlp_params.MODEL_TYPE = \"Binary_Classification\"\n",
    "elif mlp_params.OUT_FEATURES == 1:\n",
    "    mlp_params.MODEL_TYPE = \"Regression\"\n",
    "else:\n",
    "    pass\n",
    "print(mlp_params.MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert data class into a dataloader to be compatible with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_data, batch_size=mlp_params.BATCH_SIZE\n",
    ")\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    dataset=val_data, batch_size=mlp_params.BATCH_SIZE\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mlp_params.DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no accuracy function must be loss for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mlp_params.MODEL_TYPE == \"Regression\":\n",
    "    mlp_params.METRIC = \"loss\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wrap the objective function inside of a lambda function to pass args..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_lambda_func = lambda trial: objective_model_optimizer(\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    trial=trial,\n",
    "    params=params,\n",
    "    metric=mlp_params.METRIC,\n",
    "    return_info=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study is the object for model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=f\"{mlp_params.DIRECTION}\")\n",
    "# Here I apply the optimize function of the study to the objective function\n",
    "# This optimizes each parameter specified to be optimized from the defined search space\n",
    "study.optimize(objective_lambda_func, n_trials=mlp_params.N_TRIALS)\n",
    "# Prints out the best trial's optimized parameters\n",
    "objective_model_optimizer(\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    trial=study.best_trial,\n",
    "    params=params,\n",
    "    metric=mlp_params.METRIC,\n",
    "    return_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create graph directory for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_path = pathlib.Path(\n",
    "    f\"../../figures/{mlp_params.MODEL_TYPE}/{mlp_params.MODEL_NAME}/{mlp_params.CELL_TYPE}/hyperparameter_optimization\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlib.Path(graph_path).mkdir(parents=True, exist_ok=True)\n",
    "fig = optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_path = f\"{graph_path}/plot_optimization_history_graph\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image(pathlib.Path(f\"{graph_path}.png\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create graph directory for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_path = pathlib.Path(\n",
    "    f\"../../figures/{mlp_params.MODEL_TYPE}/{mlp_params.MODEL_NAME}/{mlp_params.CELL_TYPE}/hyperparameter_optimization\"\n",
    ").resolve(strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlib.Path(graph_path).mkdir(parents=True, exist_ok=True)\n",
    "fig = optuna.visualization.plot_intermediate_values(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_path = f\"{graph_path}/plot_intermediate_values_graph\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image(pathlib.Path(f\"{graph_path}.png\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = extract_best_trial_params(\n",
    "    study.best_params, params, model_name=mlp_params.MODEL_NAME\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
