{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type = \"PBMC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "aggregation = True\n",
    "nomic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pathlib.Path(f\"../data/{cell_type}_preprocessed_sc_norm.parquet\")\n",
    "\n",
    "data_df = pd.read_parquet(path)\n",
    "\n",
    "data_df.head()\n",
    "\n",
    "if nomic == True:\n",
    "    # import nomic data\n",
    "    nomic_df_path = pathlib.Path(\n",
    "        f\"../2.Nomic_nELISA_Analysis/Data/clean/Plate2/nELISA_plate_430420_{cell_type}_cleanup4correlation.csv\"\n",
    "    )\n",
    "    df_nomic = pd.read_csv(nomic_df_path)\n",
    "\n",
    "    # drop columns that contain [pgML]\n",
    "    df_nomic = df_nomic.drop(\n",
    "        columns=[col for col in df_nomic.columns if \"[pgML]\" in col]\n",
    "    )\n",
    "    # drop first 25 columns\n",
    "    # df_nomic = df_nomic.drop(columns=df_nomic.columns[3:25])\n",
    "    # df_nomic = df_nomic.drop(columns=df_nomic.columns[0:2])\n",
    "else:\n",
    "    df_nomic = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset each column that contains metadata\n",
    "metadata = data_df.filter(regex=\"Metadata\")\n",
    "\n",
    "# get all columns that are not metadata except for metadata_Well\n",
    "data = data_df.drop(metadata.columns, axis=1)\n",
    "\n",
    "# get the metadata_Well column\n",
    "metadata_well = metadata[\n",
    "    [\"Metadata_Well\", \"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"]\n",
    "]\n",
    "\n",
    "data_df = pd.merge(data, metadata_well, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (aggregation == True) and (nomic == True):\n",
    "\n",
    "    # subset each column that contains metadata\n",
    "    metadata = data_df.filter(regex=\"Metadata\")\n",
    "    data_df = data_df.drop(metadata.columns, axis=1)\n",
    "    data_df = pd.concat([data_df, metadata[\"Metadata_Well\"]], axis=1)\n",
    "    # groupby well and take mean of each well\n",
    "    data_df = data_df.groupby(\"Metadata_Well\").mean()\n",
    "    # drop duplicate rows in the metadata_well column\n",
    "    metadata = metadata.drop_duplicates(subset=[\"Metadata_Well\"])\n",
    "    # get the metadata for each well\n",
    "    data_df = pd.merge(\n",
    "        data_df, metadata, left_on=\"Metadata_Well\", right_on=\"Metadata_Well\"\n",
    "    )\n",
    "    data_df = pd.merge(\n",
    "        data_df,\n",
    "        df_nomic,\n",
    "        left_on=[\"Metadata_Well\", \"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"],\n",
    "        right_on=[\"Metadata_position_x\", \"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"],\n",
    "    )\n",
    "    data_df = data_df.drop(columns=[\"Metadata_position_x\"])\n",
    "    # drop all metadata columns\n",
    "    labeled_data = data_df[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"]\n",
    "    data_x = data_df.drop(metadata.columns, axis=1)\n",
    "\n",
    "elif (aggregation == True) and (nomic == False):\n",
    "    # subset each column that contains metadata\n",
    "    metadata = data.filter(regex=\"Metadata\")\n",
    "    data_df = data_df.drop(metadata.columns, axis=1)\n",
    "    data_df = pd.concat([data_df, metadata[\"Metadata_Well\"]], axis=1)\n",
    "    # groupby well and take mean of each well\n",
    "    data_df = data_df.groupby(\"Metadata_Well\").mean()\n",
    "    # drop duplicate rows in the metadata_well column\n",
    "    metadata = metadata.drop_duplicates(subset=[\"Metadata_Well\"])\n",
    "    # get the metadata for each well\n",
    "    data_df = pd.merge(\n",
    "        data_df,\n",
    "        df_nomic,\n",
    "        left_on=[\"Metadata_Well\", \"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"],\n",
    "        right_on=[\"Metadata_position_x\", \"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"],\n",
    "    )\n",
    "elif (aggregation == False) and (nomic == True):\n",
    "    data_df = pd.merge(\n",
    "        data_df,\n",
    "        df_nomic,\n",
    "        left_on=[\"Metadata_Well\", \"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"],\n",
    "        right_on=[\"Metadata_position_x\", \"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"],\n",
    "    )\n",
    "    data_df = data_df.drop(columns=[\"Metadata_position_x\"])\n",
    "elif aggregation == False and nomic == False:\n",
    "    pass\n",
    "else:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to save the data\n",
    "aggregated_data_path = pathlib.Path(\n",
    "    f\"../data/{cell_type}_preprocessed_sc_norm_aggregated.parquet\"\n",
    ")\n",
    "# save the data\n",
    "data_df.to_parquet(aggregated_data_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Interstellar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
