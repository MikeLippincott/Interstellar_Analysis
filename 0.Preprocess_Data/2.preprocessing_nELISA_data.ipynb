{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This noteboook pre-processes the nELISA data to be ready for exploratory analysis and machine learning."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pathlib\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import seaborn as sns\n",
                "from matplotlib.backends.backend_pdf import PdfPages\n",
                "from sklearn import preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "tags": [
                    "injected-parameters"
                ]
            },
            "outputs": [],
            "source": [
                "# Parameters\n",
                "cell_type = \"SHSY5Y\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "# set path to data\n",
                "data_path = pathlib.Path(\n",
                "    f\"../2.Nomic_nELISA_Analysis/Data/clean/Plate2/nELISA_plate_430420_{cell_type}.csv\"\n",
                ")\n",
                "\n",
                "preprocessing_path = pathlib.Path(\n",
                "    f\"../2.Nomic_nELISA_Analysis/Data/clean/Plate2/nELISA_plate_430420_{cell_type}_clean.parquet\"\n",
                ")\n",
                "\n",
                "# read in data\n",
                "nomic_df = pd.read_csv(data_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# select data only columns and make floats\n",
                "nELISA_data_values = nomic_df.filter(like=\"NSU\", axis=1).astype(\"float\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "# normalize data via max value in each column\n",
                "max_values = nELISA_data_values.max()  # find max value in each column\n",
                "nELISA_data_values_sensor_max_norm = nELISA_data_values.div(\n",
                "    max_values\n",
                ")  # divide each value in each column by max value in that column\n",
                "nELISA_data_values_sensor_max_norm.head()\n",
                "# min max normalization via sklearn\n",
                "\n",
                "# normalize data via min max normalization\n",
                "min_max_scaler = preprocessing.MinMaxScaler()\n",
                "nELISA_data_values_min_max_norm = min_max_scaler.fit_transform(nELISA_data_values)\n",
                "nELISA_data_values_min_max_norm = pd.DataFrame(\n",
                "    nELISA_data_values_min_max_norm, columns=nELISA_data_values.columns\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "# drop columns that are named with NSU\n",
                "Metadata = nomic_df.drop(nomic_df.filter(like=\"NSU\", axis=1), axis=1).drop(\n",
                "    nomic_df.filter(like=\"pgML\", axis=1), axis=1\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "# merge metadata and normalized data values\n",
                "analysis_df = pd.concat([Metadata, nELISA_data_values_min_max_norm], axis=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "# get rid of spaces\n",
                "analysis_df.replace(\" \", \"_\", regex=True, inplace=True)\n",
                "# replace all \"/\" with \"_per_\"\n",
                "analysis_df.replace(\"/\", \"_per_\", regex=True, inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "# replace nans with 0 in this case this is okay because the real nans were already removed on the basis of treatment name\n",
                "analysis_df[\"inducer1_concentration\"].replace(np.nan, 0, inplace=True)\n",
                "analysis_df[\"inducer2_concentration\"].replace(np.nan, 0, inplace=True)\n",
                "analysis_df[\"inhibitor_concentration\"].replace(np.nan, 0, inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "def perform_replacements(text):\n",
                "    replacements = {\n",
                "        \"%\": \"\",\n",
                "        \"_\u00b5M\": \"\",\n",
                "        \"_nM\": \"\",\n",
                "        \"_\u00b5g_per_ml\": \"\",\n",
                "    }\n",
                "    for key, value in replacements.items():\n",
                "        text = str(text).replace(key, value)\n",
                "    return text\n",
                "\n",
                "\n",
                "# Columns to which you want to apply the changes\n",
                "columns_to_apply = [\n",
                "    \"inducer1_concentration\",\n",
                "    \"inducer2_concentration\",\n",
                "    \"inhibitor_concentration\",\n",
                "]\n",
                "\n",
                "# Applying the custom function to selected columns using apply\n",
                "analysis_df[columns_to_apply] = analysis_df[columns_to_apply].apply(\n",
                "    lambda x: x.apply(perform_replacements)\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "# using an f string make \"inducer1_concentration\" have 3 decimal places\n",
                "analysis_df[\"inducer1_concentration\"] = analysis_df[\"inducer1_concentration\"].apply(\n",
                "    lambda x: f\"{float(x):.3f}\" if float(x) != 0 else float(x)\n",
                ")\n",
                "analysis_df[\"inducer2_concentration\"] = analysis_df[\"inducer2_concentration\"].apply(\n",
                "    lambda x: f\"{float(x):.3f}\" if float(x) != 0 else float(x)\n",
                ")\n",
                "analysis_df[\"inhibitor_concentration\"] = analysis_df[\"inhibitor_concentration\"].apply(\n",
                "    lambda x: f\"{float(x):.3f}\" if float(x) != 0 else float(x)\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "# treatment column merge\n",
                "conditions = [\n",
                "    (analysis_df[\"inducer2\"].isnull()),\n",
                "    analysis_df[\"inducer2\"].notnull(),\n",
                "]\n",
                "\n",
                "results = [\n",
                "    (analysis_df[\"inducer1\"]).astype(str),\n",
                "    (analysis_df[\"inducer1\"] + \"_\" + analysis_df[\"inducer2\"].astype(str)),\n",
                "]\n",
                "analysis_df[\"Treatment\"] = np.select(condlist=conditions, choicelist=results)\n",
                "\n",
                "\n",
                "# dose column merge\n",
                "results = [\n",
                "    (\n",
                "        analysis_df[\"inducer1_concentration\"].astype(str)\n",
                "        + \"_\"\n",
                "        + analysis_df[\"inducer1_concentration_unit\"].astype(str)\n",
                "    ),\n",
                "    (\n",
                "        analysis_df[\"inducer1_concentration\"].astype(str)\n",
                "        + \"_\"\n",
                "        + analysis_df[\"inducer1_concentration_unit\"].astype(str)\n",
                "        + \"_\"\n",
                "        + analysis_df[\"inducer2_concentration\"].astype(str)\n",
                "        + \"_\"\n",
                "        + analysis_df[\"inducer2_concentration_unit\"].astype(str)\n",
                "    ),\n",
                "]\n",
                "analysis_df[\"Dose\"] = np.select(condlist=conditions, choicelist=results)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "# one beta of inudcer1, inducer1 concentration, inhibitor, and inhibitor concentration all as 1 beta term\n",
                "analysis_df[\"oneb_Treatment_Dose_Inhibitor_Dose\"] = (\n",
                "    analysis_df[\"Treatment\"]\n",
                "    + \"_\"\n",
                "    + analysis_df[\"Dose\"].astype(str)\n",
                "    + \"_\"\n",
                "    + analysis_df[\"inhibitor\"].astype(str)\n",
                "    + \"_\"\n",
                "    + analysis_df[\"inhibitor_concentration\"].astype(str)\n",
                "    + \"_\"\n",
                "    + analysis_df[\"inhibitor_concentration_unit\"].astype(str)\n",
                ").astype(str)\n",
                "\n",
                "\n",
                "# two beta of inducer1, inhibitor, and inhibitor concentration all as 1 beta term + inducer1 concentration as 2nd beta term\n",
                "analysis_df[\"twob_Treatment_Dose_Inhibitor_Dose\"] = (\n",
                "    analysis_df[\"Treatment\"]\n",
                "    + \"_\"\n",
                "    + analysis_df[\"inhibitor\"].astype(str)\n",
                "    + \"_\"\n",
                "    + analysis_df[\"Dose\"].astype(str)\n",
                ").astype(str)\n",
                "\n",
                "# three beta of inducer 1 as 1 beta term, inducer1 concentration as 2nd beta term, inhibitor and inhibitor concentration as 3rd beta term\n",
                "analysis_df[\"threeb_Treatment_Dose_Inhibitor_Dose\"] = (\n",
                "    analysis_df[\"Treatment\"]\n",
                "    + \"__\"\n",
                "    + analysis_df[\"Dose\"].astype(str)\n",
                "    + \"__\"\n",
                "    + analysis_df[\"inhibitor\"].astype(str)\n",
                "    + \"_\"\n",
                "    + analysis_df[\"inhibitor_concentration\"].astype(str)\n",
                ").astype(str)\n",
                "\n",
                "# four beta of inducer 1 as 1 beta term, inducer1 concentration as 2nd beta term, inhibitor as 3rd beta term, and inhibitor concentration as 4th beta term\n",
                "analysis_df[\"fourb_Treatment_Dose_Inhibitor_Dose\"] = (\n",
                "    analysis_df[\"Treatment\"]\n",
                "    + \"__\"\n",
                "    + analysis_df[\"Dose\"].astype(str)\n",
                "    + \"__\"\n",
                "    + analysis_df[\"inhibitor\"].astype(str)\n",
                "    + \"__\"\n",
                "    + analysis_df[\"inhibitor_concentration\"].astype(str)\n",
                ").astype(str)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "None 0\n",
                        "\u00b5 u\n",
                        "nan 0\n"
                    ]
                }
            ],
            "source": [
                "replacement_dict = {\n",
                "    \"None\": \"0\",\n",
                "    \"\u00b5\": \"u\",\n",
                "    \"nan\": \"0\",\n",
                "}\n",
                "for pattern, replacement in replacement_dict.items():\n",
                "    print(pattern, replacement)\n",
                "    analysis_df[\"oneb_Treatment_Dose_Inhibitor_Dose\"] = analysis_df[\n",
                "        \"oneb_Treatment_Dose_Inhibitor_Dose\"\n",
                "    ].replace(to_replace=str(pattern), value=str(replacement), regex=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "# _0.03 to _0.025 for the DMSO concentration\n",
                "analysis_df[\"oneb_Treatment_Dose_Inhibitor_Dose\"] = analysis_df[\n",
                "    \"oneb_Treatment_Dose_Inhibitor_Dose\"\n",
                "].str.replace(\"_0.03\", \"_0.025\", regex=False)\n",
                "\n",
                "# _0.0250 to _0.025 for the DMSO concentration\n",
                "analysis_df[\"oneb_Treatment_Dose_Inhibitor_Dose\"] = analysis_df[\n",
                "    \"oneb_Treatment_Dose_Inhibitor_Dose\"\n",
                "].str.replace(\"_0.0250\", \"_0.025\", regex=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "# need to convert to strings to save as parquet\n",
                "# if the column is an object then convert it to a string\n",
                "for column in analysis_df.columns:\n",
                "    if analysis_df[column].dtype == \"object\":\n",
                "        analysis_df[column] = analysis_df[column].astype(str)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "analysis_df.to_parquet(preprocessing_path)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Interstellar",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "72ae02083a9ca7d143c492d1aec380c7bf553ec51bd66e90e72bba65228121b6"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
