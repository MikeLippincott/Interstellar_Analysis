{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "215ce1c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T05:40:46.596684Z",
     "iopub.status.busy": "2023-07-22T05:40:46.596359Z",
     "iopub.status.idle": "2023-07-22T05:40:47.783445Z",
     "shell.execute_reply": "2023-07-22T05:40:47.783025Z"
    },
    "papermill": {
     "duration": 1.193087,
     "end_time": "2023-07-22T05:40:47.784792",
     "exception": false,
     "start_time": "2023-07-22T05:40:46.591705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import itertools\n",
    "import pathlib\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import toml\n",
    "from joblib import dump\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.linear_model import ElasticNetCV, LogisticRegression, MultiTaskElasticNetCV\n",
    "\n",
    "# import mse\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# import RepeatedKFold\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RepeatedKFold,\n",
    "    StratifiedKFold,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.utils import parallel_backend, shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed0d80d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T05:40:47.789946Z",
     "iopub.status.busy": "2023-07-22T05:40:47.789675Z",
     "iopub.status.idle": "2023-07-22T05:40:47.792006Z",
     "shell.execute_reply": "2023-07-22T05:40:47.791688Z"
    },
    "papermill": {
     "duration": 0.005605,
     "end_time": "2023-07-22T05:40:47.792730",
     "exception": false,
     "start_time": "2023-07-22T05:40:47.787125",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "cell_type = \"PBMC\"\n",
    "aggregation = True\n",
    "nomic = True\n",
    "flag = True\n",
    "control = \"DMSO_0.100_DMSO_0.025\"\n",
    "treatment = \"LPS_100.000_DMSO_0.025\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9fbea76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T05:40:47.796788Z",
     "iopub.status.busy": "2023-07-22T05:40:47.796489Z",
     "iopub.status.idle": "2023-07-22T05:40:47.799099Z",
     "shell.execute_reply": "2023-07-22T05:40:47.798782Z"
    },
    "papermill": {
     "duration": 0.005391,
     "end_time": "2023-07-22T05:40:47.799818",
     "exception": false,
     "start_time": "2023-07-22T05:40:47.794427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_TYPE = \"regression\"\n",
    "if flag == False:\n",
    "    # read in toml file and get parameters\n",
    "    toml_path = pathlib.Path(\"single_class_config.toml\")\n",
    "    with open(toml_path, \"r\") as f:\n",
    "        config = toml.load(f)\n",
    "    control = config[\"logistic_regression_params\"][\"control\"]\n",
    "    treatment = config[\"logistic_regression_params\"][\"treatments\"]\n",
    "    aggregation = ast.literal_eval(config[\"logistic_regression_params\"][\"aggregation\"])\n",
    "    nomic = ast.literal_eval(config[\"logistic_regression_params\"][\"nomic\"])\n",
    "    cell_type = config[\"logistic_regression_params\"][\"cell_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1261124d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T05:40:47.803594Z",
     "iopub.status.busy": "2023-07-22T05:40:47.803381Z",
     "iopub.status.idle": "2023-07-22T05:44:22.592036Z",
     "shell.execute_reply": "2023-07-22T05:44:22.591001Z"
    },
    "papermill": {
     "duration": 214.792447,
     "end_time": "2023-07-22T05:44:22.593856",
     "exception": false,
     "start_time": "2023-07-22T05:40:47.801409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load training data from indexes and features dataframe\n",
    "# data_split_path = pathlib.Path(f\"../0.split_data/indexes/data_split_indexes.tsv\")\n",
    "# data_path = pathlib.Path(f\"../../data/{cell_type}_preprocessed_sc_norm.parquet\")\n",
    "data_path = pathlib.Path(\n",
    "    \"../../data/PBMC_subset_sc_norm_DMSO_0.100_DMSO_0.025_LPS_100.000_DMSO_0.025.parquet\"\n",
    ")\n",
    "\n",
    "# dataframe with only the labeled data we want (exclude certain phenotypic classes)\n",
    "data_df = pq.read_table(data_path).to_pandas()\n",
    "\n",
    "# import nomic data\n",
    "nomic_df_path = pathlib.Path(\n",
    "    f\"../../2.Nomic_nELISA_Analysis/Data/clean/Plate2/nELISA_plate_430420_{cell_type}_cleanup4correlation.csv\"\n",
    ")\n",
    "df_nomic = pd.read_csv(nomic_df_path)\n",
    "\n",
    "# clean up nomic data\n",
    "df_nomic = df_nomic.drop(columns=[col for col in df_nomic.columns if \"[pgML]\" in col])\n",
    "# drop first 25 columns (Metadata that is not needed)\n",
    "# df_nomic = df_nomic.drop(columns=df_nomic.columns[3:25])\n",
    "# df_nomic = df_nomic.drop(columns=df_nomic.columns[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf794861",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T05:44:22.654781Z",
     "iopub.status.busy": "2023-07-22T05:44:22.653962Z",
     "iopub.status.idle": "2023-07-22T05:44:22.810900Z",
     "shell.execute_reply": "2023-07-22T05:44:22.810222Z"
    },
    "papermill": {
     "duration": 0.162062,
     "end_time": "2023-07-22T05:44:22.812544",
     "exception": false,
     "start_time": "2023-07-22T05:44:22.650482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if (aggregation == True) and (nomic == True):\n",
    "    data_split_path = pathlib.Path(\n",
    "        f\"../0.split_data/indexes/{cell_type}/{MODEL_TYPE}/{control}_{treatment}/aggregated_sc_and_nomic_data_split_indexes.tsv\"\n",
    "    )\n",
    "    data_split_indexes = pd.read_csv(data_split_path, sep=\"\\t\", index_col=0)\n",
    "    # subset each column that contains metadata\n",
    "    metadata = data_df.filter(regex=\"Metadata\")\n",
    "    data_df = data_df.drop(metadata.columns, axis=1)\n",
    "    data_df = pd.concat([data_df, metadata[\"Metadata_Well\"]], axis=1)\n",
    "    # groupby well and take mean of each well\n",
    "    data_df = data_df.groupby(\"Metadata_Well\").mean()\n",
    "    # drop duplicate rows in the metadata_well column\n",
    "    metadata = metadata.drop_duplicates(subset=[\"Metadata_Well\"])\n",
    "    # get the metadata for each well\n",
    "    data_df = pd.merge(\n",
    "        data_df, metadata, left_on=\"Metadata_Well\", right_on=\"Metadata_Well\"\n",
    "    )\n",
    "    data_df = pd.merge(\n",
    "        data_df,\n",
    "        df_nomic,\n",
    "        left_on=[\"Metadata_Well\", \"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"],\n",
    "        right_on=[\"Metadata_position_x\", \"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"],\n",
    "    )\n",
    "    data_df = data_df.drop(columns=[\"Metadata_position_x\"])\n",
    "elif (aggregation == True) and (nomic == False):\n",
    "    data_split_path = pathlib.Path(\n",
    "        f\"../0.split_data/indexes/{cell_type}/{MODEL_TYPE}/{control}_{treatment}/aggregated_sc_data_split_indexes.tsv\"\n",
    "    )\n",
    "    data_split_indexes = pd.read_csv(data_split_path, sep=\"\\t\", index_col=0)\n",
    "    # subset each column that contains metadata\n",
    "    metadata = data_df.filter(regex=\"Metadata\")\n",
    "    data_df = data_df.drop(metadata.columns, axis=1)\n",
    "    data_df = pd.concat([data_df, metadata[\"Metadata_Well\"]], axis=1)\n",
    "    # groupby well and take mean of each well\n",
    "    data_df = data_df.groupby(\"Metadata_Well\").mean()\n",
    "    # drop duplicate rows in the metadata_well column\n",
    "    metadata = metadata.drop_duplicates(subset=[\"Metadata_Well\"])\n",
    "    # get the metadata for each well\n",
    "    data_df = pd.merge(\n",
    "        data_df,\n",
    "        df_nomic,\n",
    "        left_on=[\"Metadata_Well\", \"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"],\n",
    "        right_on=[\"Metadata_position_x\", \"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"],\n",
    "    )\n",
    "elif (aggregation == False) and (nomic == True):\n",
    "    data_split_path = pathlib.Path(\n",
    "        f\"../0.split_data/indexes/{cell_type}/{MODEL_TYPE}/{control}_{treatment}/sc_and_nomic_data_split_indexes.tsv\"\n",
    "    )\n",
    "    data_split_indexes = pd.read_csv(data_split_path, sep=\"\\t\", index_col=0)\n",
    "    data_df = pd.merge(\n",
    "        data_df,\n",
    "        df_nomic,\n",
    "        left_on=[\"Metadata_Well\", \"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"],\n",
    "        right_on=[\"Metadata_position_x\", \"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"],\n",
    "    )\n",
    "    data_df = data_df.drop(columns=[\"Metadata_position_x\"])\n",
    "elif aggregation == False and nomic == False:\n",
    "    data_split_path = pathlib.Path(\n",
    "        f\"../0.split_data/indexes/{cell_type}/{MODEL_TYPE}/{control}_{treatment}/sc_split_indexes.tsv\"\n",
    "    )\n",
    "    data_split_indexes = pd.read_csv(data_split_path, sep=\"\\t\", index_col=0)\n",
    "else:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2ec11da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T05:44:22.817688Z",
     "iopub.status.busy": "2023-07-22T05:44:22.816972Z",
     "iopub.status.idle": "2023-07-22T05:44:22.841932Z",
     "shell.execute_reply": "2023-07-22T05:44:22.841519Z"
    },
    "papermill": {
     "duration": 0.028408,
     "end_time": "2023-07-22T05:44:22.842747",
     "exception": false,
     "start_time": "2023-07-22T05:44:22.814339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select tht indexes for the training and test set\n",
    "train_indexes = data_split_indexes.loc[data_split_indexes[\"label\"] == \"train\"]\n",
    "test_indexes = data_split_indexes.loc[data_split_indexes[\"label\"] == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10d08adb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T05:44:22.847339Z",
     "iopub.status.busy": "2023-07-22T05:44:22.846705Z",
     "iopub.status.idle": "2023-07-22T05:44:23.372437Z",
     "shell.execute_reply": "2023-07-22T05:44:23.371833Z"
    },
    "papermill": {
     "duration": 0.529615,
     "end_time": "2023-07-22T05:44:23.373993",
     "exception": false,
     "start_time": "2023-07-22T05:44:22.844378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# subset data_df by indexes in data_split_indexes\n",
    "training_data = data_df.loc[train_indexes[\"labeled_data_index\"]]\n",
    "testing_data = data_df.loc[test_indexes[\"labeled_data_index\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5219c9ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T05:44:23.378812Z",
     "iopub.status.busy": "2023-07-22T05:44:23.378294Z",
     "iopub.status.idle": "2023-07-22T05:44:23.727187Z",
     "shell.execute_reply": "2023-07-22T05:44:23.726381Z"
    },
    "papermill": {
     "duration": 0.352839,
     "end_time": "2023-07-22T05:44:23.728560",
     "exception": false,
     "start_time": "2023-07-22T05:44:23.375721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get oneb_Metadata_Treatment_Dose_Inhibitor_Dose  =='DMSO_0.100_DMSO_0.025' and 'LPS_100.000_DMSO_0.025 and Thapsigargin_10.000_DMSO_0.025'\n",
    "training_data = training_data[\n",
    "    training_data[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"].isin(\n",
    "        [control, treatment]\n",
    "    )\n",
    "]\n",
    "testing_data = testing_data[\n",
    "    testing_data[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"].isin(\n",
    "        [control, treatment]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc7c0f87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T05:44:23.734194Z",
     "iopub.status.busy": "2023-07-22T05:44:23.733468Z",
     "iopub.status.idle": "2023-07-22T05:44:25.417043Z",
     "shell.execute_reply": "2023-07-22T05:44:25.416597Z"
    },
    "papermill": {
     "duration": 1.687722,
     "end_time": "2023-07-22T05:44:25.418506",
     "exception": false,
     "start_time": "2023-07-22T05:44:23.730784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# at random downsample the DMSO treatment to match the number of wells in the LPS treatment\n",
    "seed = 0\n",
    "# get the number of wells in the LPS treatment\n",
    "trt_wells = training_data[\n",
    "    training_data[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"] == treatment\n",
    "].shape[0]\n",
    "# get the number of wells in the DMSO treatment\n",
    "dmso_wells = training_data[\n",
    "    training_data[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"] == control\n",
    "].shape[0]\n",
    "# downsample the DMSO treatment to match the number of wells in the LPS treatment\n",
    "dmso_holdout = training_data[\n",
    "    training_data[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"] == control\n",
    "].sample(n=trt_wells, random_state=seed)\n",
    "# remove the downsampled DMSO wells from the data\n",
    "training_data = training_data.drop(dmso_holdout.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b292a431",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T05:44:25.424681Z",
     "iopub.status.busy": "2023-07-22T05:44:25.424485Z",
     "iopub.status.idle": "2023-07-22T05:44:25.599914Z",
     "shell.execute_reply": "2023-07-22T05:44:25.599440Z"
    },
    "papermill": {
     "duration": 0.179094,
     "end_time": "2023-07-22T05:44:25.601137",
     "exception": false,
     "start_time": "2023-07-22T05:44:25.422043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define metadata columns\n",
    "# subset each column that contains metadata\n",
    "metadata = training_data.filter(regex=\"Metadata\")\n",
    "# drop all metadata columns\n",
    "train_data_x = training_data.drop(metadata.columns, axis=1)\n",
    "train_treatments = training_data[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"]\n",
    "# get all columns that contain \"NSU\" in the column name\n",
    "train_data_y_cols = train_data_x.filter(regex=\"NSU\").columns\n",
    "train_data_y = training_data[train_data_y_cols]\n",
    "train_data_x = train_data_x.drop(train_data_y_cols, axis=1)\n",
    "\n",
    "\n",
    "# define metadata columns\n",
    "# subset each column that contains metadata\n",
    "metadata = testing_data.filter(regex=\"Metadata\")\n",
    "# drop all metadata columns\n",
    "test_data_x = testing_data.drop(metadata.columns, axis=1)\n",
    "test_treatments = testing_data[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"]\n",
    "# get all columns that contain \"NSU\" in the column name\n",
    "test_data_y_cols = test_data_x.filter(regex=\"NSU\").columns\n",
    "test_data_y = testing_data[test_data_y_cols]\n",
    "test_data_x = test_data_x.drop(test_data_y_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3623e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activin A [NSU]</th>\n",
       "      <th>AITRL (GITR Ligand) [NSU]</th>\n",
       "      <th>Amphiregulin [NSU]</th>\n",
       "      <th>Amyloid beta [NSU]</th>\n",
       "      <th>APRIL [NSU]</th>\n",
       "      <th>BAFF [NSU]</th>\n",
       "      <th>BCMA (TNFRSF17) [NSU]</th>\n",
       "      <th>BDNF [NSU]</th>\n",
       "      <th>BMP2 [NSU]</th>\n",
       "      <th>BMP3 [NSU]</th>\n",
       "      <th>...</th>\n",
       "      <th>TWEAK [NSU]</th>\n",
       "      <th>uPA [NSU]</th>\n",
       "      <th>VCAM-1 [NSU]</th>\n",
       "      <th>VEGF Receptor 2 (Flk-1) [NSU]</th>\n",
       "      <th>VEGF-A (165) [NSU]</th>\n",
       "      <th>VEGF-C [NSU]</th>\n",
       "      <th>VEGF-D [NSU]</th>\n",
       "      <th>VEGFR-1 [NSU]</th>\n",
       "      <th>WISP-1 (CCN4) [NSU]</th>\n",
       "      <th>XCL1 (Lymphotactin) [NSU]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.097710</td>\n",
       "      <td>0.461685</td>\n",
       "      <td>0.270477</td>\n",
       "      <td>0.514695</td>\n",
       "      <td>0.479281</td>\n",
       "      <td>0.270494</td>\n",
       "      <td>0.708849</td>\n",
       "      <td>0.134432</td>\n",
       "      <td>0.350986</td>\n",
       "      <td>0.216932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386063</td>\n",
       "      <td>0.469875</td>\n",
       "      <td>0.395392</td>\n",
       "      <td>0.560129</td>\n",
       "      <td>0.504521</td>\n",
       "      <td>0.490444</td>\n",
       "      <td>0.258834</td>\n",
       "      <td>0.238358</td>\n",
       "      <td>0.524276</td>\n",
       "      <td>0.250670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.061860</td>\n",
       "      <td>0.196318</td>\n",
       "      <td>0.236491</td>\n",
       "      <td>0.474891</td>\n",
       "      <td>0.174672</td>\n",
       "      <td>0.824721</td>\n",
       "      <td>0.704521</td>\n",
       "      <td>0.254823</td>\n",
       "      <td>0.443939</td>\n",
       "      <td>0.268677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.755683</td>\n",
       "      <td>0.374554</td>\n",
       "      <td>0.486915</td>\n",
       "      <td>0.389375</td>\n",
       "      <td>0.369421</td>\n",
       "      <td>0.680276</td>\n",
       "      <td>0.182956</td>\n",
       "      <td>0.263281</td>\n",
       "      <td>0.213596</td>\n",
       "      <td>0.064645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.706485</td>\n",
       "      <td>0.477823</td>\n",
       "      <td>0.806104</td>\n",
       "      <td>0.303776</td>\n",
       "      <td>0.254430</td>\n",
       "      <td>0.094280</td>\n",
       "      <td>0.670885</td>\n",
       "      <td>0.250955</td>\n",
       "      <td>0.470768</td>\n",
       "      <td>0.169451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.736028</td>\n",
       "      <td>0.428286</td>\n",
       "      <td>0.288884</td>\n",
       "      <td>0.527908</td>\n",
       "      <td>0.210755</td>\n",
       "      <td>0.448465</td>\n",
       "      <td>0.422773</td>\n",
       "      <td>0.535603</td>\n",
       "      <td>0.209011</td>\n",
       "      <td>0.170498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.060998</td>\n",
       "      <td>0.596601</td>\n",
       "      <td>0.129926</td>\n",
       "      <td>0.302610</td>\n",
       "      <td>0.559309</td>\n",
       "      <td>0.087533</td>\n",
       "      <td>0.541110</td>\n",
       "      <td>0.350256</td>\n",
       "      <td>0.528260</td>\n",
       "      <td>0.313411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254542</td>\n",
       "      <td>0.630644</td>\n",
       "      <td>0.586271</td>\n",
       "      <td>0.258029</td>\n",
       "      <td>0.561051</td>\n",
       "      <td>0.551671</td>\n",
       "      <td>0.582053</td>\n",
       "      <td>0.087565</td>\n",
       "      <td>0.140992</td>\n",
       "      <td>0.234191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.837820</td>\n",
       "      <td>0.574834</td>\n",
       "      <td>0.869218</td>\n",
       "      <td>0.394956</td>\n",
       "      <td>0.118325</td>\n",
       "      <td>0.192057</td>\n",
       "      <td>0.584911</td>\n",
       "      <td>0.411283</td>\n",
       "      <td>0.340821</td>\n",
       "      <td>0.253736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328239</td>\n",
       "      <td>0.315633</td>\n",
       "      <td>0.364173</td>\n",
       "      <td>0.607592</td>\n",
       "      <td>0.176816</td>\n",
       "      <td>0.378920</td>\n",
       "      <td>0.310344</td>\n",
       "      <td>0.651217</td>\n",
       "      <td>0.679571</td>\n",
       "      <td>0.222324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.686719</td>\n",
       "      <td>0.169058</td>\n",
       "      <td>0.759551</td>\n",
       "      <td>0.469769</td>\n",
       "      <td>0.464808</td>\n",
       "      <td>0.094883</td>\n",
       "      <td>0.345938</td>\n",
       "      <td>0.355706</td>\n",
       "      <td>0.262622</td>\n",
       "      <td>0.226736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360981</td>\n",
       "      <td>0.527316</td>\n",
       "      <td>0.405934</td>\n",
       "      <td>0.619578</td>\n",
       "      <td>0.329964</td>\n",
       "      <td>0.577830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.456104</td>\n",
       "      <td>0.255216</td>\n",
       "      <td>0.255703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Activin A [NSU]  AITRL (GITR Ligand) [NSU]  Amphiregulin [NSU]  \\\n",
       "0          0.097710                   0.461685            0.270477   \n",
       "4          0.061860                   0.196318            0.236491   \n",
       "6          0.706485                   0.477823            0.806104   \n",
       "8          0.060998                   0.596601            0.129926   \n",
       "10         0.837820                   0.574834            0.869218   \n",
       "11         0.686719                   0.169058            0.759551   \n",
       "\n",
       "    Amyloid beta [NSU]  APRIL [NSU]  BAFF [NSU]  BCMA (TNFRSF17) [NSU]  \\\n",
       "0             0.514695     0.479281    0.270494               0.708849   \n",
       "4             0.474891     0.174672    0.824721               0.704521   \n",
       "6             0.303776     0.254430    0.094280               0.670885   \n",
       "8             0.302610     0.559309    0.087533               0.541110   \n",
       "10            0.394956     0.118325    0.192057               0.584911   \n",
       "11            0.469769     0.464808    0.094883               0.345938   \n",
       "\n",
       "    BDNF [NSU]  BMP2 [NSU]  BMP3 [NSU]  ...  TWEAK [NSU]  uPA [NSU]  \\\n",
       "0     0.134432    0.350986    0.216932  ...     0.386063   0.469875   \n",
       "4     0.254823    0.443939    0.268677  ...     0.755683   0.374554   \n",
       "6     0.250955    0.470768    0.169451  ...     0.736028   0.428286   \n",
       "8     0.350256    0.528260    0.313411  ...     0.254542   0.630644   \n",
       "10    0.411283    0.340821    0.253736  ...     0.328239   0.315633   \n",
       "11    0.355706    0.262622    0.226736  ...     0.360981   0.527316   \n",
       "\n",
       "    VCAM-1 [NSU]  VEGF Receptor 2 (Flk-1) [NSU]  VEGF-A (165) [NSU]  \\\n",
       "0       0.395392                       0.560129            0.504521   \n",
       "4       0.486915                       0.389375            0.369421   \n",
       "6       0.288884                       0.527908            0.210755   \n",
       "8       0.586271                       0.258029            0.561051   \n",
       "10      0.364173                       0.607592            0.176816   \n",
       "11      0.405934                       0.619578            0.329964   \n",
       "\n",
       "    VEGF-C [NSU]  VEGF-D [NSU]  VEGFR-1 [NSU]  WISP-1 (CCN4) [NSU]  \\\n",
       "0       0.490444      0.258834       0.238358             0.524276   \n",
       "4       0.680276      0.182956       0.263281             0.213596   \n",
       "6       0.448465      0.422773       0.535603             0.209011   \n",
       "8       0.551671      0.582053       0.087565             0.140992   \n",
       "10      0.378920      0.310344       0.651217             0.679571   \n",
       "11      0.577830      0.000000       0.456104             0.255216   \n",
       "\n",
       "    XCL1 (Lymphotactin) [NSU]  \n",
       "0                    0.250670  \n",
       "4                    0.064645  \n",
       "6                    0.170498  \n",
       "8                    0.234191  \n",
       "10                   0.222324  \n",
       "11                   0.255703  \n",
       "\n",
       "[6 rows x 187 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1756ecc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 1245) (6, 187) (3, 1245) (3, 187)\n"
     ]
    }
   ],
   "source": [
    "print(train_data_x.shape, train_data_y.shape, test_data_x.shape, test_data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "189b81bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model path from parameters\n",
    "if (aggregation == True) and (nomic == True):\n",
    "    model_path = pathlib.Path(\n",
    "        f\"models/single_class/{cell_type}/aggregated_with_nomic/{MODEL_TYPE}/{control}__{treatment}\"\n",
    "    )\n",
    "elif (aggregation == True) and (nomic == False):\n",
    "    model_path = pathlib.Path(\n",
    "        f\"models/single_class/{cell_type}/aggregated/{MODEL_TYPE}/{control}__{treatment}\"\n",
    "    )\n",
    "elif (aggregation == False) and (nomic == True):\n",
    "    model_path = pathlib.Path(\n",
    "        f\"models/single_class/{cell_type}/sc_with_nomic/{MODEL_TYPE}/{control}__{treatment}\"\n",
    "    )\n",
    "elif (aggregation == False) and (nomic == False):\n",
    "    model_path = pathlib.Path(\n",
    "        f\"models/single_class/{cell_type}/sc/{MODEL_TYPE}/{control}__{treatment}\"\n",
    "    )\n",
    "else:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0b124c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- AITRL (GITR Ligand) [NSU]\n- APRIL [NSU]\n- Activin A [NSU]\n- Amphiregulin [NSU]\n- Amyloid beta [NSU]\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[39mfor\u001b[39;00m column \u001b[39min\u001b[39;00m train_data_x:\n\u001b[1;32m     38\u001b[0m         np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mshuffle(train_data_x[column]\u001b[39m.\u001b[39mvalues)\n\u001b[0;32m---> 39\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(train_data_x)\n\u001b[1;32m     40\u001b[0m \u001b[39m# get probabilities\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39m# probabilities = model.predict_proba(train_data_x)\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39m# get accuracy\u001b[39;00m\n\u001b[1;32m     43\u001b[0m MSE \u001b[39m=\u001b[39m mean_squared_error(train_data_y, predictions)\n",
      "File \u001b[0;32m~/miniconda3/envs/Interstellar/lib/python3.10/site-packages/sklearn/linear_model/_base.py:386\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    373\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[39m    Predict using the linear model.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[39m        Returns predicted values.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 386\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decision_function(X)\n",
      "File \u001b[0;32m~/miniconda3/envs/Interstellar/lib/python3.10/site-packages/sklearn/linear_model/_base.py:369\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_decision_function\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    367\u001b[0m     check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 369\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcoo\u001b[39;49m\u001b[39m\"\u001b[39;49m], reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    370\u001b[0m     \u001b[39mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\u001b[39m.\u001b[39mT, dense_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_\n",
      "File \u001b[0;32m~/miniconda3/envs/Interstellar/lib/python3.10/site-packages/sklearn/base.py:579\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_data\u001b[39m(\n\u001b[1;32m    509\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    510\u001b[0m     X\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mno_validation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params,\n\u001b[1;32m    516\u001b[0m ):\n\u001b[1;32m    517\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \n\u001b[1;32m    519\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[39m        validated.\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 579\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_feature_names(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    581\u001b[0m     \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tags()[\u001b[39m\"\u001b[39m\u001b[39mrequires_y\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    582\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    583\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m estimator \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    584\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mrequires y to be passed, but the target y is None.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    585\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/Interstellar/lib/python3.10/site-packages/sklearn/base.py:506\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m missing_names \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    502\u001b[0m     message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    503\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m     )\n\u001b[0;32m--> 506\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- AITRL (GITR Ligand) [NSU]\n- APRIL [NSU]\n- Activin A [NSU]\n- Amphiregulin [NSU]\n- Amyloid beta [NSU]\n- ...\n"
     ]
    }
   ],
   "source": [
    "shuffles = [\"final\", \"shuffled_baseline\"]\n",
    "feature_types = [\"CP\"]\n",
    "evaluation_types = [\"train\", \"test\"]\n",
    "# create stratified data sets for continuous labels\n",
    "compiled_predictions = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"Prediction\",\n",
    "        \"Actual_value\",\n",
    "        \"data_split\",\n",
    "        \"shuffled\",\n",
    "        \"feature_type\",\n",
    "        \"MSE\",\n",
    "        \"r2\",\n",
    "        \"treatment\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = MultiTaskElasticNetCV(\n",
    "    random_state=0,\n",
    "    max_iter=10,\n",
    "    cv=5,\n",
    "    l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.99],\n",
    "    alphas=[0.01, 0.1, 1, 10, 100],\n",
    ")\n",
    "# train model on training data on all combinations of model types, feature types, and phenotypic classes\n",
    "\n",
    "for shuffle, feature_type, evaluation_type in itertools.product(\n",
    "    shuffles, feature_types, evaluation_types\n",
    "):\n",
    "    model = joblib.load(\n",
    "        f\"../1.train_models/{model_path}/{shuffle}__{feature_type}_all_nomic.joblib\"\n",
    "    )\n",
    "\n",
    "    if evaluation_type == \"train\":\n",
    "        # get row that are labeled train in label column\n",
    "        # train_data_x = data_x.loc[data_x[\"label\"] == \"train\"]\n",
    "        # train_data_x = train_data_x.drop(\"label\", axis=1)\n",
    "        if shuffle == \"shuffled_baseline\":\n",
    "            for column in train_data_x:\n",
    "                np.random.shuffle(train_data_x[column].values)\n",
    "        predictions = model.predict(train_data_x)\n",
    "        # get probabilities\n",
    "        # probabilities = model.predict_proba(train_data_x)\n",
    "        # get accuracy\n",
    "        MSE = mean_squared_error(train_data_y, predictions)\n",
    "        # get r2 score\n",
    "        r2 = r2_score(train_data_y, predictions)\n",
    "        train_predictions_df = pd.DataFrame(\n",
    "            {\n",
    "                \"Prediction\": predictions,\n",
    "                \"Actual_value\": train_data_y,\n",
    "                \"data_split\": evaluation_type,\n",
    "                \"shuffled\": \"shuffled\" in shuffle,\n",
    "                \"feature_type\": feature_type,\n",
    "                \"MSE\": MSE,\n",
    "                \"r2\": r2,\n",
    "            }\n",
    "        )\n",
    "        # oneb_Metadata_Treatment_Dose_Inhibitor_Dose\n",
    "        train_predictions_df[\"treatment\"] = train_treatments\n",
    "\n",
    "        compiled_predictions = pd.concat(\n",
    "            [compiled_predictions, train_predictions_df], axis=0, ignore_index=True\n",
    "        )\n",
    "    elif evaluation_type == \"test\":\n",
    "\n",
    "        # get row that are labeled train in label column\n",
    "        # train_data_x = data_x.loc[data_x[\"label\"] == \"train\"]\n",
    "        # train_data_x = train_data_x.drop(\"label\", axis=1)\n",
    "        if shuffle == \"shuffled_baseline\":\n",
    "            for column in test_data_x:\n",
    "                np.random.shuffle(test_data_x[column].values)\n",
    "        predictions = model.predict(test_data_x)\n",
    "        print(predictions, test_data_y)\n",
    "        # get probabilities\n",
    "        # probabilities = model.predict_proba(train_data_x)\n",
    "        # get accuracy\n",
    "        MSE = mean_squared_error(test_data_y, predictions)\n",
    "        # get r2 score\n",
    "        r2 = r2_score(test_data_y, predictions)\n",
    "        test_predictions_df = pd.DataFrame(\n",
    "            {\n",
    "                \"Prediction\": predictions,\n",
    "                \"Actual_value\": test_data_y,\n",
    "                \"data_split\": evaluation_type,\n",
    "                \"shuffled\": \"shuffled\" in shuffle,\n",
    "                \"feature_type\": feature_type,\n",
    "                \"MSE\": MSE,\n",
    "                \"r2\": r2,\n",
    "            }\n",
    "        )\n",
    "        # oneb_Metadata_Treatment_Dose_Inhibitor_Dose\n",
    "        test_predictions_df[\"treatment\"] = test_treatments\n",
    "\n",
    "        compiled_predictions = pd.concat(\n",
    "            [compiled_predictions, test_predictions_df], axis=0, ignore_index=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904db665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Interstellar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 694.133243,
   "end_time": "2023-07-22T05:52:18.725810",
   "environment_variables": {},
   "exception": null,
   "input_path": "train_single_class.ipynb",
   "output_path": "train_single_class.ipynb",
   "parameters": {
    "aggregation": false,
    "cell_type": "PBMC",
    "control": "DMSO_0.100_DMSO_0.025",
    "flag": true,
    "nomic": false,
    "treatment": "Thapsigargin_1.000_DMSO_0.025"
   },
   "start_time": "2023-07-22T05:40:44.592567",
   "version": "2.4.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "72ae02083a9ca7d143c492d1aec380c7bf553ec51bd66e90e72bba65228121b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
