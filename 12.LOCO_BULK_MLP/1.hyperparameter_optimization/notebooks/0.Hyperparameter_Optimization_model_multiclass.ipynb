{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "8e60628c",
            "metadata": {
                "papermill": {
                    "duration": 0.002385,
                    "end_time": "2023-10-18T18:20:04.868387",
                    "exception": false,
                    "start_time": "2023-10-18T18:20:04.866002",
                    "status": "completed"
                },
                "tags": []
            },
            "source": [
                "## Hyperparameter tuning via Optuna"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8fac71a5",
            "metadata": {
                "papermill": {
                    "duration": 0.001919,
                    "end_time": "2023-10-18T18:20:04.873048",
                    "exception": false,
                    "start_time": "2023-10-18T18:20:04.871129",
                    "status": "completed"
                },
                "tags": []
            },
            "source": [
                "### Being a binary model this notebook will be limited to predicting one class 1 or 0, yes or no.\n",
                "### Here I will be predicting if a cell received a treatment or not"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "860a61dd",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-10-18T18:20:04.878009Z",
                    "iopub.status.busy": "2023-10-18T18:20:04.877582Z",
                    "iopub.status.idle": "2023-10-18T18:20:08.479452Z",
                    "shell.execute_reply": "2023-10-18T18:20:08.478953Z"
                },
                "papermill": {
                    "duration": 3.605361,
                    "end_time": "2023-10-18T18:20:08.480497",
                    "exception": false,
                    "start_time": "2023-10-18T18:20:04.875136",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "import argparse\n",
                "import json\n",
                "import pathlib\n",
                "import sys\n",
                "\n",
                "import numpy as np\n",
                "import optuna\n",
                "import pandas as pd\n",
                "import pyarrow.parquet as pq\n",
                "import toml\n",
                "import torch\n",
                "from sklearn import preprocessing\n",
                "\n",
                "MLP_parent_path = pathlib.Path(\"../../../utils/\")\n",
                "sys.path.append(str(MLP_parent_path.resolve()))\n",
                "MLP_path = pathlib.Path(\"../../../utils/MLP_utils\").resolve()\n",
                "\n",
                "from MLP_utils.parameters import Parameters\n",
                "from MLP_utils.utils import (\n",
                "    Dataset_formatter,\n",
                "    data_split,\n",
                "    extract_best_trial_params,\n",
                "    objective_model_optimizer,\n",
                "    parameter_set,\n",
                "    plot_metric_vs_epoch,\n",
                "    results_output,\n",
                "    test_optimized_model,\n",
                "    train_optimized_model,\n",
                "    un_nest,\n",
                ")\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "from utils import df_stats"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "15fbe814",
            "metadata": {},
            "outputs": [],
            "source": [
                "# set up the parser\n",
                "parser = argparse.ArgumentParser(description=\"Run hyperparameter optimization\")\n",
                "parser.add_argument(\n",
                "    \"--cell_type\",\n",
                "    type=str,\n",
                "    default=\"all\",\n",
                "    help=\"Cell type to run hyperparameter optimization for\",\n",
                ")\n",
                "parser.add_argument(\n",
                "    \"--model_name\",\n",
                "    type=str,\n",
                "    default=\"all\",\n",
                "    help=\"Model name to run hyperparameter optimization for\",\n",
                ")\n",
                "\n",
                "parser.add_argument(\n",
                "    \"--channel_combination_key\",\n",
                "    type=str,\n",
                "    default=\"all\",\n",
                "    help=\"key to a dictionary containing the feature types to split the data into\",\n",
                ")\n",
                "\n",
                "# parse arguments\n",
                "args = parser.parse_args()\n",
                "\n",
                "CELL_TYPE = args.cell_type\n",
                "MODEL_NAME = args.model_name\n",
                "channel_combination_key = args.channel_combination_key"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "c700d77e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# load in the channel combinations file\n",
                "channel_combinations_file_path = pathlib.Path(\n",
                "    f\"../../0.data_splits/results/feature_combinations_{CELL_TYPE}.toml\"\n",
                ").resolve(strict=True)\n",
                "channel_combinations = toml.load(channel_combinations_file_path)\n",
                "channel_combinations = channel_combinations[channel_combination_key]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "394294ce",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-10-18T18:20:08.498713Z",
                    "iopub.status.busy": "2023-10-18T18:20:08.498501Z",
                    "iopub.status.idle": "2023-10-18T18:20:08.502638Z",
                    "shell.execute_reply": "2023-10-18T18:20:08.502299Z"
                },
                "papermill": {
                    "duration": 0.007175,
                    "end_time": "2023-10-18T18:20:08.503377",
                    "exception": false,
                    "start_time": "2023-10-18T18:20:08.496202",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "ml_configs_file = pathlib.Path(MLP_path / \"multi_class_config.toml\").resolve(\n",
                "    strict=True\n",
                ")\n",
                "ml_configs = toml.load(ml_configs_file)\n",
                "params = Parameters()\n",
                "mlp_params = parameter_set(params, ml_configs, \"Bulk_Leave_One_Channel_Out_Params\")\n",
                "\n",
                "# overwrite params via command line arguments from papermill\n",
                "mlp_params.CELL_TYPE = CELL_TYPE\n",
                "mlp_params.MODEL_NAME = f\"{MODEL_NAME}_{channel_combination_key}\"\n",
                "MODEL_TYPE = mlp_params.MODEL_TYPE\n",
                "HYPERPARAMETER_BATCH_SIZE = mlp_params.HYPERPARAMETER_BATCH_SIZE"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "44baa945",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-10-18T18:20:08.507805Z",
                    "iopub.status.busy": "2023-10-18T18:20:08.507608Z"
                },
                "papermill": {
                    "duration": 54.581971,
                    "end_time": "2023-10-18T18:21:03.087265",
                    "exception": false,
                    "start_time": "2023-10-18T18:20:08.505294",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(154, 232)\n"
                    ]
                }
            ],
            "source": [
                "# Import Data\n",
                "# set data file path under pathlib path for multi-system use\n",
                "\n",
                "file_path = pathlib.Path(\n",
                "    f\"../../../data/{mlp_params.CELL_TYPE}_preprocessed_sc_norm_aggregated.parquet\"\n",
                ").resolve(strict=True)\n",
                "\n",
                "df1 = pd.read_parquet(file_path, columns=channel_combinations)\n",
                "print(df1.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "e8ef96f3",
            "metadata": {},
            "outputs": [],
            "source": [
                "# get paths for toml files\n",
                "ground_truth_file_path = pathlib.Path(MLP_path / \"ground_truth.toml\").resolve(\n",
                "    strict=True\n",
                ")\n",
                "treatment_splits_file_path = pathlib.Path(MLP_path / \"splits.toml\").resolve(strict=True)\n",
                "# read toml files\n",
                "ground_truth = toml.load(ground_truth_file_path)\n",
                "treatment_splits = toml.load(treatment_splits_file_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "29c1f3cb",
            "metadata": {},
            "outputs": [],
            "source": [
                "# get information from toml files\n",
                "apoptosis_groups_list = ground_truth[\"Apoptosis\"][\"apoptosis_groups_list\"]\n",
                "pyroptosis_groups_list = ground_truth[\"Pyroptosis\"][\"pyroptosis_groups_list\"]\n",
                "healthy_groups_list = ground_truth[\"Healthy\"][\"healthy_groups_list\"]\n",
                "test_split_100 = treatment_splits[\"splits\"][\"data_splits_100\"]\n",
                "test_split_75 = treatment_splits[\"splits\"][\"data_splits_75\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "159e2281",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Data Subset Is Off\n"
                    ]
                }
            ],
            "source": [
                "np.random.seed(0)\n",
                "if mlp_params.DATA_SUBSET_OPTION == \"True\":\n",
                "    df1 = df1.groupby(\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\").apply(\n",
                "        lambda x: x.sample(n=mlp_params.DATA_SUBSET_NUMBER, random_state=0)\n",
                "    )\n",
                "    print(\"Data Subset Is On\")\n",
                "    print(f\"Data is subset to {mlp_params.DATA_SUBSET_NUMBER} per treatment group\")\n",
                "    print(df1.shape)\n",
                "    df1.reset_index(drop=True, inplace=True)\n",
                "else:\n",
                "    print(\"Data Subset Is Off\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "6a6ec3fa",
            "metadata": {},
            "outputs": [],
            "source": [
                "# add apoptosis, pyroptosis and healthy columns to dataframe\n",
                "df1[\"apoptosis\"] = df1[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"].isin(\n",
                "    apoptosis_groups_list\n",
                ")\n",
                "df1[\"pyroptosis\"] = df1[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"].isin(\n",
                "    pyroptosis_groups_list\n",
                ")\n",
                "df1[\"healthy\"] = df1[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"].isin(\n",
                "    healthy_groups_list\n",
                ")\n",
                "\n",
                "# merge apoptosis, pyroptosis, and healthy columns into one column\n",
                "conditions = [\n",
                "    (df1[\"apoptosis\"] == True),\n",
                "    (df1[\"pyroptosis\"] == True),\n",
                "    (df1[\"healthy\"] == True),\n",
                "]\n",
                "choices = [\"apoptosis\", \"pyroptosis\", \"healthy\"]\n",
                "df1[\"labels\"] = np.select(conditions, choices, default=\"healthy\")\n",
                "\n",
                "# drop apoptosis, pyroptosis, and healthy columns\n",
                "df1.drop(columns=[\"apoptosis\", \"pyroptosis\", \"healthy\"], inplace=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3cb179dd",
            "metadata": {},
            "source": [
                "### Split said data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "686d1a5d",
            "metadata": {},
            "outputs": [],
            "source": [
                "index_path = pathlib.Path(f\"../../0.data_splits/indexes/{CELL_TYPE}/multi_class/\")\n",
                "\n",
                "\n",
                "# save indexes as tsv file\n",
                "index_data_path = pathlib.Path(\n",
                "    f\"{index_path}/{params.CELL_TYPE}_data_split_indexes.tsv\", sep=\"\\t\", index=False\n",
                ")\n",
                "indexes = pd.read_csv(index_data_path, sep=\"\\t\")\n",
                "\n",
                "# get the labeld_data_index column from the indexes dataframe for train label\n",
                "training_data_set_index = indexes.loc[\n",
                "    indexes[\"label\"] == \"train\", \"labeled_data_index\"\n",
                "].values\n",
                "val_data_set_index = indexes.loc[indexes[\"label\"] == \"val\", \"labeled_data_index\"].values\n",
                "testing_data_set_index = indexes.loc[\n",
                "    indexes[\"label\"] == \"test\", \"labeled_data_index\"\n",
                "].values\n",
                "treatment_holdout_index = indexes.loc[\n",
                "    indexes[\"label\"] == \"treatment_holdout\", \"labeled_data_index\"\n",
                "].values\n",
                "holdout_index = indexes.loc[indexes[\"label\"] == \"holdout\", \"labeled_data_index\"].values"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "5c486e00",
            "metadata": {
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "source": [
                "#### Set up Data to be compatible with model"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "95754baa",
            "metadata": {
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "source": [
                "##### Classification Models:\n",
                "Comment out code if using regression"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "786e3a76",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-10-18T18:19:56.707754Z",
                    "iopub.status.busy": "2023-10-18T18:19:56.707475Z",
                    "iopub.status.idle": "2023-10-18T18:19:56.711213Z",
                    "shell.execute_reply": "2023-10-18T18:19:56.710882Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# Code snippet for metadata extraction by Jenna Tomkinson\n",
                "df_metadata = list(df1.columns[df1.columns.str.contains(\"Metadata\")])\n",
                "\n",
                "# define which columns are data and which are descriptive\n",
                "df_descriptive = df1[df_metadata]\n",
                "df_values = df1.drop(columns=df_metadata)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "5a354640",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'apoptosis': 0.948051948051948,\n",
                            " 'healthy': 0.5194805194805194,\n",
                            " 'pyroptosis': 0.5324675324675325}"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# get weights\n",
                "class_weights_file = pathlib.Path(\n",
                "    f\"../../0.data_splits/class_weights/{CELL_TYPE}/multi_class/class_weights.json\"\n",
                ").resolve(strict=True)\n",
                "# read in the class weights file json into a dict\n",
                "with open(class_weights_file, \"r\") as file:\n",
                "    class_weights = json.load(file)\n",
                "\n",
                "class_weights"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "595afb65",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-10-18T18:19:56.717727Z",
                    "iopub.status.busy": "2023-10-18T18:19:56.717549Z",
                    "iopub.status.idle": "2023-10-18T18:19:56.720945Z",
                    "shell.execute_reply": "2023-10-18T18:19:56.720676Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([1, 2, 0])"
                        ]
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Creating label encoder\n",
                "le = preprocessing.LabelEncoder()\n",
                "df_values[\"new_labels\"] = le.fit_transform(df_values[\"labels\"])\n",
                "# make a dict encoder for the labels\n",
                "encoder = dict(zip(le.classes_, le.transform(le.classes_)))\n",
                "# change the keys and valules to be strings\n",
                "encoder = {str(key): str(value) for key, value in encoder.items()}\n",
                "# save the encoder as a json\n",
                "encoder_file = pathlib.Path(\n",
                "    f\"../../0.data_splits/class_weights/{CELL_TYPE}/multi_class/encoder.json\"\n",
                ")\n",
                "with open(encoder_file, \"w\") as file:\n",
                "    json.dump(encoder, file)\n",
                "\n",
                "# get mini dataframe that contains the decoder\n",
                "decoder = df_values[[\"labels\", \"new_labels\"]].drop_duplicates()\n",
                "# split into X and Y where Y are the predictive column and x are the observable data\n",
                "df_values_X = df_values.drop(\n",
                "    [\"new_labels\", \"labels\"],\n",
                "    axis=1,\n",
                ")\n",
                "df_values_Y = df_values[\"new_labels\"]\n",
                "df_values_Y.head()\n",
                "df_values_Y.unique()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "1747feea",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[0.948051948051948, 0.5194805194805194, 0.5324675324675325]"
                        ]
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# replace the class weights key with the encoder key's matching value\n",
                "class_weights = {encoder[key]: value for key, value in class_weights.items()}\n",
                "class_weights = [f for f in class_weights.values()]\n",
                "class_weights"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "260a048e",
            "metadata": {
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "source": [
                "#### Split Data - All Models can proceed through this point"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "b5b6d4fa",
            "metadata": {},
            "outputs": [],
            "source": [
                "# split into train and test sets from indexes previously defined\n",
                "\n",
                "X_train = df_values_X.loc[training_data_set_index]\n",
                "X_val = df_values_X.loc[val_data_set_index]\n",
                "X_test = df_values_X.loc[testing_data_set_index]\n",
                "X_holdout = df_values_X.loc[holdout_index]\n",
                "X_treatment_holdout = df_values_X.loc[treatment_holdout_index]\n",
                "\n",
                "Y_train = df_values_Y.loc[training_data_set_index]\n",
                "Y_val = df_values_Y.loc[val_data_set_index]\n",
                "Y_test = df_values_Y.loc[testing_data_set_index]\n",
                "Y_holdout = df_values_Y.loc[holdout_index]\n",
                "Y_treatment_holdout = df_values_Y.loc[treatment_holdout_index]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "ae525b7d",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "3"
                        ]
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "mlp_params.OUT_FEATURES = len(df_values_Y.unique())\n",
                "mlp_params.OUT_FEATURES"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "9ab7a090",
            "metadata": {},
            "outputs": [],
            "source": [
                "Y_train = torch.tensor(Y_train.values)\n",
                "Y_train = torch.nn.functional.one_hot(\n",
                "    Y_train, num_classes=mlp_params.OUT_FEATURES\n",
                ").float()\n",
                "\n",
                "Y_val = torch.tensor(Y_val.values)\n",
                "Y_val = torch.nn.functional.one_hot(Y_val, num_classes=mlp_params.OUT_FEATURES).float()\n",
                "\n",
                "Y_test = torch.tensor(Y_test.values)\n",
                "Y_test = torch.nn.functional.one_hot(\n",
                "    Y_test, num_classes=mlp_params.OUT_FEATURES\n",
                ").float()\n",
                "\n",
                "Y_holdout = torch.tensor(Y_holdout.values)\n",
                "Y_holdout = torch.nn.functional.one_hot(\n",
                "    Y_holdout, num_classes=mlp_params.OUT_FEATURES\n",
                ").float()\n",
                "\n",
                "Y_treatment_holdout = torch.tensor(Y_treatment_holdout.values)\n",
                "Y_treatment_holdout = torch.nn.functional.one_hot(\n",
                "    Y_treatment_holdout, num_classes=mlp_params.OUT_FEATURES\n",
                ").float()\n",
                "\n",
                "# convert the X dataframes to tensors\n",
                "X_train = torch.tensor(X_train.values)\n",
                "X_val = torch.tensor(X_val.values)\n",
                "X_test = torch.tensor(X_test.values)\n",
                "X_holdout = torch.tensor(X_holdout.values)\n",
                "X_treatment_holdout = torch.tensor(X_treatment_holdout.values)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "3c4e1896",
            "metadata": {},
            "outputs": [],
            "source": [
                "# produce data objects for train, val and test datasets\n",
                "train_data = torch.utils.data.TensorDataset(X_train, Y_train)\n",
                "val_data = torch.utils.data.TensorDataset(X_val, Y_val)\n",
                "test_data = torch.utils.data.TensorDataset(X_test, Y_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "id": "4382d712",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-10-18T18:16:16.631025Z",
                    "iopub.status.busy": "2023-10-18T18:16:16.630857Z",
                    "iopub.status.idle": "2023-10-18T18:16:16.634504Z",
                    "shell.execute_reply": "2023-10-18T18:16:16.634156Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Number of in features:  230\n",
                        "Number of out features:  3\n",
                        "Multi_Class\n"
                    ]
                }
            ],
            "source": [
                "mlp_params.IN_FEATURES = X_train.shape[1]\n",
                "print(\"Number of in features: \", mlp_params.IN_FEATURES)\n",
                "if mlp_params.MODEL_TYPE == \"Regression\":\n",
                "    mlp_params.OUT_FEATURES = 1\n",
                "else:\n",
                "    mlp_params.OUT_FEATURES = len(df_values[\"labels\"].unique())\n",
                "\n",
                "print(\"Number of out features: \", mlp_params.OUT_FEATURES)\n",
                "\n",
                "if mlp_params.OUT_FEATURES > 2:\n",
                "    mlp_params.MODEL_TYPE = \"Multi_Class\"\n",
                "elif mlp_params.OUT_FEATURES == 2:\n",
                "    mlp_params.OUT_FEATURES = mlp_params.OUT_FEATURES - 1\n",
                "    mlp_params.MODEL_TYPE = \"Binary_Classification\"\n",
                "elif mlp_params.OUT_FEATURES == 1:\n",
                "    mlp_params.MODEL_TYPE = \"Regression\"\n",
                "else:\n",
                "    pass\n",
                "print(mlp_params.MODEL_TYPE)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "77effa5c",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-10-18T18:16:16.642779Z",
                    "iopub.status.busy": "2023-10-18T18:16:16.642487Z",
                    "iopub.status.idle": "2023-10-18T18:16:16.645220Z",
                    "shell.execute_reply": "2023-10-18T18:16:16.644897Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# convert data class into a dataloader to be compatible with pytorch\n",
                "train_loader = torch.utils.data.DataLoader(\n",
                "    dataset=train_data, batch_size=mlp_params.HYPERPARAMETER_BATCH_SIZE, shuffle=True\n",
                ")\n",
                "valid_loader = torch.utils.data.DataLoader(\n",
                "    dataset=val_data, batch_size=mlp_params.HYPERPARAMETER_BATCH_SIZE, shuffle=False\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "id": "f471da39",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "3"
                        ]
                    },
                    "execution_count": 21,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "mlp_params.OUT_FEATURES"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "id": "cb7635c8",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-10-18T18:16:16.653709Z",
                    "iopub.status.busy": "2023-10-18T18:16:16.653361Z",
                    "iopub.status.idle": "2023-10-18T18:16:16.655989Z",
                    "shell.execute_reply": "2023-10-18T18:16:16.655583Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "cuda\n"
                    ]
                }
            ],
            "source": [
                "# check device\n",
                "print(mlp_params.DEVICE)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "id": "a969042f",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-10-18T18:16:16.663986Z",
                    "iopub.status.busy": "2023-10-18T18:16:16.663699Z",
                    "iopub.status.idle": "2023-10-18T18:17:37.283791Z",
                    "shell.execute_reply": "2023-10-18T18:17:37.283496Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-10-17 08:47:15,421] A new study created in memory with name: no-name-3e1aedfd-97f4-4e36-835b-f1ae52d69956\n",
                        "[I 2024-10-17 08:47:16,278] Trial 0 finished with value: 0.5639041197299958 and parameters: {'n_layers': 3, 'n_units_l0': 14, 'dropout_0': 0.11213150991585019, 'n_units_l1': 29, 'dropout_1': 0.3696974899712595, 'n_units_l2': 45, 'dropout_2': 0.2019961824623741, 'learning_rate': 0.020703677868176108, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.5639041197299958.\n",
                        "[I 2024-10-17 08:47:16,499] Trial 1 finished with value: 9.921136960983276 and parameters: {'n_layers': 4, 'n_units_l0': 33, 'dropout_0': 0.12634397981434337, 'n_units_l1': 21, 'dropout_1': 0.3962761427546295, 'n_units_l2': 24, 'dropout_2': 0.26701017778556135, 'n_units_l3': 37, 'dropout_3': 0.1669521123300815, 'learning_rate': 0.07415080104957664, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.5639041197299958.\n",
                        "[I 2024-10-17 08:47:16,826] Trial 2 finished with value: 0.4634128165245056 and parameters: {'n_layers': 11, 'n_units_l0': 11, 'dropout_0': 0.3099116207647335, 'n_units_l1': 15, 'dropout_1': 0.17906654944217065, 'n_units_l2': 23, 'dropout_2': 0.11956428618051321, 'n_units_l3': 45, 'dropout_3': 0.22551296600351528, 'n_units_l4': 24, 'dropout_4': 0.29905563140926, 'n_units_l5': 30, 'dropout_5': 0.22833322453413318, 'n_units_l6': 22, 'dropout_6': 0.1231917970301974, 'n_units_l7': 7, 'dropout_7': 0.28426948953319925, 'n_units_l8': 39, 'dropout_8': 0.2517707864535701, 'n_units_l9': 45, 'dropout_9': 0.2035147036928821, 'n_units_l10': 9, 'dropout_10': 0.3667310413988596, 'learning_rate': 0.047062442241535746, 'optimizer': 'Adam'}. Best is trial 2 with value: 0.4634128165245056.\n",
                        "[I 2024-10-17 08:47:17,015] Trial 3 finished with value: 0.5941367954015732 and parameters: {'n_layers': 4, 'n_units_l0': 44, 'dropout_0': 0.14913662549694534, 'n_units_l1': 49, 'dropout_1': 0.17500653145167494, 'n_units_l2': 16, 'dropout_2': 0.10234934721850213, 'n_units_l3': 48, 'dropout_3': 0.18332620541429273, 'learning_rate': 0.012997326003132775, 'optimizer': 'SGD'}. Best is trial 2 with value: 0.4634128165245056.\n",
                        "[I 2024-10-17 08:47:17,260] Trial 4 finished with value: 0.6912485027313232 and parameters: {'n_layers': 7, 'n_units_l0': 9, 'dropout_0': 0.142137276087344, 'n_units_l1': 5, 'dropout_1': 0.3474660150530041, 'n_units_l2': 26, 'dropout_2': 0.25418616465040744, 'n_units_l3': 15, 'dropout_3': 0.24352097928177432, 'n_units_l4': 2, 'dropout_4': 0.1197782643318403, 'n_units_l5': 18, 'dropout_5': 0.2709480917264198, 'n_units_l6': 49, 'dropout_6': 0.24145152995400976, 'learning_rate': 0.055896107856167214, 'optimizer': 'RMSprop'}. Best is trial 2 with value: 0.4634128165245056.\n",
                        "[I 2024-10-17 08:47:17,461] Trial 5 finished with value: 0.5500368016958237 and parameters: {'n_layers': 4, 'n_units_l0': 18, 'dropout_0': 0.3773806389134038, 'n_units_l1': 45, 'dropout_1': 0.3956174755592061, 'n_units_l2': 32, 'dropout_2': 0.11089019911134008, 'n_units_l3': 4, 'dropout_3': 0.12706139952857087, 'learning_rate': 0.07110710857657768, 'optimizer': 'SGD'}. Best is trial 2 with value: 0.4634128165245056.\n",
                        "[I 2024-10-17 08:47:17,791] Trial 6 finished with value: 0.5223787128925323 and parameters: {'n_layers': 11, 'n_units_l0': 41, 'dropout_0': 0.38201878097190334, 'n_units_l1': 49, 'dropout_1': 0.16391345574096738, 'n_units_l2': 46, 'dropout_2': 0.13682492776930144, 'n_units_l3': 20, 'dropout_3': 0.24681743085113483, 'n_units_l4': 30, 'dropout_4': 0.12981195877186577, 'n_units_l5': 6, 'dropout_5': 0.3686399933128631, 'n_units_l6': 34, 'dropout_6': 0.28188608399306425, 'n_units_l7': 33, 'dropout_7': 0.3590393560949362, 'n_units_l8': 35, 'dropout_8': 0.12537849218468358, 'n_units_l9': 4, 'dropout_9': 0.3491364967811041, 'n_units_l10': 22, 'dropout_10': 0.2515430645425486, 'learning_rate': 0.058046853424337526, 'optimizer': 'Adam'}. Best is trial 2 with value: 0.4634128165245056.\n",
                        "[I 2024-10-17 08:47:17,968] Trial 7 finished with value: 0.3191228596866131 and parameters: {'n_layers': 2, 'n_units_l0': 19, 'dropout_0': 0.2746586031562618, 'n_units_l1': 25, 'dropout_1': 0.2604544688301931, 'learning_rate': 0.09104122897002323, 'optimizer': 'Adam'}. Best is trial 7 with value: 0.3191228596866131.\n",
                        "[I 2024-10-17 08:47:17,976] Trial 8 pruned. \n",
                        "[I 2024-10-17 08:47:17,981] Trial 9 pruned. \n",
                        "[I 2024-10-17 08:47:18,435] Trial 10 finished with value: 0.5239728266000747 and parameters: {'n_layers': 15, 'n_units_l0': 2, 'dropout_0': 0.253580980668986, 'n_units_l1': 31, 'dropout_1': 0.27031634755414824, 'n_units_l2': 5, 'dropout_2': 0.31283217134848695, 'n_units_l3': 28, 'dropout_3': 0.37949342965606014, 'n_units_l4': 48, 'dropout_4': 0.3919229318831955, 'n_units_l5': 50, 'dropout_5': 0.3867586464924738, 'n_units_l6': 2, 'dropout_6': 0.397387049974306, 'n_units_l7': 3, 'dropout_7': 0.11045706865987112, 'n_units_l8': 2, 'dropout_8': 0.3775974453299311, 'n_units_l9': 9, 'dropout_9': 0.39576800642514853, 'n_units_l10': 50, 'dropout_10': 0.10346515692156857, 'n_units_l11': 46, 'dropout_11': 0.11186502311218827, 'n_units_l12': 32, 'dropout_12': 0.33214188559253144, 'n_units_l13': 17, 'dropout_13': 0.2517927564544601, 'n_units_l14': 8, 'dropout_14': 0.31806154973749623, 'learning_rate': 0.09939779622739814, 'optimizer': 'Adam'}. Best is trial 7 with value: 0.3191228596866131.\n",
                        "[I 2024-10-17 08:47:18,628] Trial 11 finished with value: 0.2729294754564762 and parameters: {'n_layers': 1, 'n_units_l0': 25, 'dropout_0': 0.2909207578371505, 'learning_rate': 0.03691332245489884, 'optimizer': 'Adam'}. Best is trial 11 with value: 0.2729294754564762.\n",
                        "[I 2024-10-17 08:47:18,813] Trial 12 finished with value: 0.37375684797763825 and parameters: {'n_layers': 1, 'n_units_l0': 23, 'dropout_0': 0.2702382197326575, 'learning_rate': 0.03347415545609579, 'optimizer': 'Adam'}. Best is trial 11 with value: 0.2729294754564762.\n",
                        "[I 2024-10-17 08:47:18,984] Trial 13 finished with value: 0.3245241253077984 and parameters: {'n_layers': 1, 'n_units_l0': 33, 'dropout_0': 0.18825429930062598, 'learning_rate': 0.03249147354139641, 'optimizer': 'Adam'}. Best is trial 11 with value: 0.2729294754564762.\n",
                        "[I 2024-10-17 08:47:19,030] Trial 14 pruned. \n",
                        "[I 2024-10-17 08:47:19,202] Trial 15 finished with value: 0.27155685603618623 and parameters: {'n_layers': 1, 'n_units_l0': 30, 'dropout_0': 0.21361471353371364, 'learning_rate': 0.041823281784090845, 'optimizer': 'Adam'}. Best is trial 15 with value: 0.27155685603618623.\n",
                        "[I 2024-10-17 08:47:19,269] Trial 16 pruned. \n",
                        "[I 2024-10-17 08:47:19,422] Trial 17 pruned. \n",
                        "[I 2024-10-17 08:47:19,592] Trial 18 finished with value: 0.3419858506321907 and parameters: {'n_layers': 1, 'n_units_l0': 28, 'dropout_0': 0.3139023475610193, 'learning_rate': 0.06422531107709642, 'optimizer': 'Adam'}. Best is trial 15 with value: 0.27155685603618623.\n",
                        "[I 2024-10-17 08:47:19,629] Trial 19 pruned. \n",
                        "[I 2024-10-17 08:47:19,652] Trial 20 pruned. \n",
                        "[I 2024-10-17 08:47:19,851] Trial 21 finished with value: 0.4705093936622143 and parameters: {'n_layers': 2, 'n_units_l0': 19, 'dropout_0': 0.2877193668826887, 'n_units_l1': 23, 'dropout_1': 0.30877211788695824, 'learning_rate': 0.04812168447476997, 'optimizer': 'Adam'}. Best is trial 15 with value: 0.27155685603618623.\n",
                        "[I 2024-10-17 08:47:19,871] Trial 22 pruned. \n",
                        "[I 2024-10-17 08:47:20,084] Trial 23 finished with value: 0.40225953593850133 and parameters: {'n_layers': 2, 'n_units_l0': 30, 'dropout_0': 0.1893451234885752, 'n_units_l1': 28, 'dropout_1': 0.29282265542863045, 'learning_rate': 0.0853661783954153, 'optimizer': 'Adam'}. Best is trial 15 with value: 0.27155685603618623.\n",
                        "[I 2024-10-17 08:47:20,118] Trial 24 pruned. \n",
                        "[I 2024-10-17 08:47:20,294] Trial 25 finished with value: 0.2725389474630356 and parameters: {'n_layers': 1, 'n_units_l0': 24, 'dropout_0': 0.2999309892776959, 'learning_rate': 0.05555027553933805, 'optimizer': 'Adam'}. Best is trial 15 with value: 0.27155685603618623.\n",
                        "[I 2024-10-17 08:47:20,467] Trial 26 finished with value: 0.322557465583086 and parameters: {'n_layers': 1, 'n_units_l0': 31, 'dropout_0': 0.3566063314010879, 'learning_rate': 0.05732805741730922, 'optimizer': 'Adam'}. Best is trial 15 with value: 0.27155685603618623.\n",
                        "[I 2024-10-17 08:47:20,514] Trial 27 pruned. \n",
                        "[I 2024-10-17 08:47:20,535] Trial 28 pruned. \n",
                        "[I 2024-10-17 08:47:20,556] Trial 29 pruned. \n",
                        "[I 2024-10-17 08:47:20,586] Trial 30 pruned. \n",
                        "[I 2024-10-17 08:47:20,603] Trial 31 pruned. \n",
                        "[I 2024-10-17 08:47:20,617] Trial 32 pruned. \n",
                        "[I 2024-10-17 08:47:20,634] Trial 33 pruned. \n",
                        "[I 2024-10-17 08:47:20,656] Trial 34 pruned. \n",
                        "[I 2024-10-17 08:47:20,669] Trial 35 pruned. \n",
                        "[I 2024-10-17 08:47:20,700] Trial 36 pruned. \n",
                        "[I 2024-10-17 08:47:20,723] Trial 37 pruned. \n",
                        "[I 2024-10-17 08:47:20,789] Trial 38 pruned. \n",
                        "[I 2024-10-17 08:47:20,817] Trial 39 pruned. \n",
                        "[I 2024-10-17 08:47:21,008] Trial 40 finished with value: 0.4143961957097054 and parameters: {'n_layers': 2, 'n_units_l0': 26, 'dropout_0': 0.2340749443553693, 'n_units_l1': 30, 'dropout_1': 0.2503331107464479, 'learning_rate': 0.04316018313214687, 'optimizer': 'Adam'}. Best is trial 15 with value: 0.27155685603618623.\n",
                        "[I 2024-10-17 08:47:21,022] Trial 41 pruned. \n",
                        "[I 2024-10-17 08:47:21,192] Trial 42 finished with value: 0.26166178300976756 and parameters: {'n_layers': 1, 'n_units_l0': 29, 'dropout_0': 0.34927260275828886, 'learning_rate': 0.058217070006617175, 'optimizer': 'Adam'}. Best is trial 42 with value: 0.26166178300976756.\n",
                        "[I 2024-10-17 08:47:21,218] Trial 43 pruned. \n",
                        "[I 2024-10-17 08:47:21,245] Trial 44 pruned. \n",
                        "[I 2024-10-17 08:47:21,260] Trial 45 pruned. \n",
                        "[I 2024-10-17 08:47:21,322] Trial 46 pruned. \n",
                        "[I 2024-10-17 08:47:21,351] Trial 47 pruned. \n",
                        "[I 2024-10-17 08:47:21,366] Trial 48 pruned. \n",
                        "[I 2024-10-17 08:47:21,415] Trial 49 pruned. \n",
                        "[I 2024-10-17 08:47:21,485] Trial 50 pruned. \n",
                        "[I 2024-10-17 08:47:21,524] Trial 51 pruned. \n",
                        "[I 2024-10-17 08:47:21,547] Trial 52 pruned. \n",
                        "[I 2024-10-17 08:47:21,727] Trial 53 finished with value: 0.31739054128527644 and parameters: {'n_layers': 1, 'n_units_l0': 34, 'dropout_0': 0.39829432043995316, 'learning_rate': 0.06840785432680103, 'optimizer': 'Adam'}. Best is trial 42 with value: 0.26166178300976756.\n",
                        "[I 2024-10-17 08:47:21,749] Trial 54 pruned. \n",
                        "[I 2024-10-17 08:47:21,770] Trial 55 pruned. \n",
                        "[I 2024-10-17 08:47:21,797] Trial 56 pruned. \n",
                        "[I 2024-10-17 08:47:21,830] Trial 57 pruned. \n",
                        "[I 2024-10-17 08:47:21,853] Trial 58 pruned. \n",
                        "[I 2024-10-17 08:47:21,869] Trial 59 pruned. \n",
                        "[I 2024-10-17 08:47:21,890] Trial 60 pruned. \n",
                        "[I 2024-10-17 08:47:22,063] Trial 61 finished with value: 0.24849661692976951 and parameters: {'n_layers': 1, 'n_units_l0': 31, 'dropout_0': 0.3762999576705968, 'learning_rate': 0.04951601367472882, 'optimizer': 'Adam'}. Best is trial 61 with value: 0.24849661692976951.\n",
                        "[I 2024-10-17 08:47:22,234] Trial 62 finished with value: 0.39094624280929563 and parameters: {'n_layers': 1, 'n_units_l0': 29, 'dropout_0': 0.3741980395408554, 'learning_rate': 0.04513383466507592, 'optimizer': 'Adam'}. Best is trial 61 with value: 0.24849661692976951.\n",
                        "[I 2024-10-17 08:47:22,410] Trial 63 finished with value: 0.2507683964073658 and parameters: {'n_layers': 1, 'n_units_l0': 32, 'dropout_0': 0.3895287755644878, 'learning_rate': 0.0490429822957596, 'optimizer': 'Adam'}. Best is trial 61 with value: 0.24849661692976951.\n",
                        "[I 2024-10-17 08:47:22,425] Trial 64 pruned. \n",
                        "[I 2024-10-17 08:47:22,451] Trial 65 pruned. \n",
                        "[I 2024-10-17 08:47:22,471] Trial 66 pruned. \n",
                        "[I 2024-10-17 08:47:22,650] Trial 67 finished with value: 0.2610770347714424 and parameters: {'n_layers': 1, 'n_units_l0': 40, 'dropout_0': 0.3511809126189559, 'learning_rate': 0.049999708902570404, 'optimizer': 'Adam'}. Best is trial 61 with value: 0.24849661692976951.\n",
                        "[I 2024-10-17 08:47:22,671] Trial 68 pruned. \n",
                        "[I 2024-10-17 08:47:22,728] Trial 69 pruned. \n",
                        "[I 2024-10-17 08:47:22,743] Trial 70 pruned. \n",
                        "[I 2024-10-17 08:47:22,763] Trial 71 pruned. \n",
                        "[I 2024-10-17 08:47:22,779] Trial 72 pruned. \n",
                        "[I 2024-10-17 08:47:22,806] Trial 73 pruned. \n",
                        "[I 2024-10-17 08:47:22,829] Trial 74 pruned. \n",
                        "[I 2024-10-17 08:47:22,855] Trial 75 pruned. \n",
                        "[I 2024-10-17 08:47:23,036] Trial 76 finished with value: 0.3281187452375889 and parameters: {'n_layers': 1, 'n_units_l0': 34, 'dropout_0': 0.3771926497265617, 'learning_rate': 0.061345342158832916, 'optimizer': 'Adam'}. Best is trial 61 with value: 0.24849661692976951.\n",
                        "[I 2024-10-17 08:47:23,051] Trial 77 pruned. \n",
                        "[I 2024-10-17 08:47:23,076] Trial 78 pruned. \n",
                        "[I 2024-10-17 08:47:23,102] Trial 79 pruned. \n",
                        "[I 2024-10-17 08:47:23,179] Trial 80 pruned. \n",
                        "[I 2024-10-17 08:47:23,213] Trial 81 pruned. \n",
                        "[I 2024-10-17 08:47:23,386] Trial 82 finished with value: 0.29681017726659775 and parameters: {'n_layers': 1, 'n_units_l0': 27, 'dropout_0': 0.2744556229649203, 'learning_rate': 0.051059997581038706, 'optimizer': 'Adam'}. Best is trial 61 with value: 0.24849661692976951.\n",
                        "[I 2024-10-17 08:47:23,560] Trial 83 finished with value: 0.2695023529976606 and parameters: {'n_layers': 1, 'n_units_l0': 27, 'dropout_0': 0.2752168215547978, 'learning_rate': 0.05168605535618605, 'optimizer': 'Adam'}. Best is trial 61 with value: 0.24849661692976951.\n",
                        "[I 2024-10-17 08:47:23,732] Trial 84 finished with value: 0.34448321476578714 and parameters: {'n_layers': 1, 'n_units_l0': 28, 'dropout_0': 0.2849379903050456, 'learning_rate': 0.05258529434905767, 'optimizer': 'Adam'}. Best is trial 61 with value: 0.24849661692976951.\n",
                        "[I 2024-10-17 08:47:23,753] Trial 85 pruned. \n",
                        "[I 2024-10-17 08:47:23,792] Trial 86 pruned. \n",
                        "[I 2024-10-17 08:47:23,812] Trial 87 pruned. \n",
                        "[I 2024-10-17 08:47:23,828] Trial 88 pruned. \n",
                        "[I 2024-10-17 08:47:23,843] Trial 89 pruned. \n",
                        "[I 2024-10-17 08:47:23,863] Trial 90 pruned. \n",
                        "[I 2024-10-17 08:47:23,908] Trial 91 pruned. \n",
                        "[I 2024-10-17 08:47:23,925] Trial 92 pruned. \n",
                        "[I 2024-10-17 08:47:23,944] Trial 93 pruned. \n",
                        "[I 2024-10-17 08:47:24,004] Trial 94 pruned. \n",
                        "[I 2024-10-17 08:47:24,025] Trial 95 pruned. \n",
                        "[I 2024-10-17 08:47:24,050] Trial 96 pruned. \n",
                        "[I 2024-10-17 08:47:24,223] Trial 97 finished with value: 0.24002882614731788 and parameters: {'n_layers': 1, 'n_units_l0': 24, 'dropout_0': 0.3442992279707427, 'learning_rate': 0.06031087034108431, 'optimizer': 'Adam'}. Best is trial 97 with value: 0.24002882614731788.\n",
                        "[I 2024-10-17 08:47:24,272] Trial 98 pruned. \n",
                        "[I 2024-10-17 08:47:24,292] Trial 99 pruned. \n",
                        "[I 2024-10-17 08:47:24,370] Trial 100 pruned. \n",
                        "[I 2024-10-17 08:47:24,386] Trial 101 pruned. \n",
                        "[I 2024-10-17 08:47:24,561] Trial 102 finished with value: 0.2612813837826252 and parameters: {'n_layers': 1, 'n_units_l0': 33, 'dropout_0': 0.3640614408417913, 'learning_rate': 0.04300781745574111, 'optimizer': 'Adam'}. Best is trial 97 with value: 0.24002882614731788.\n",
                        "[I 2024-10-17 08:47:24,576] Trial 103 pruned. \n",
                        "[I 2024-10-17 08:47:24,591] Trial 104 pruned. \n",
                        "[I 2024-10-17 08:47:24,612] Trial 105 pruned. \n",
                        "[I 2024-10-17 08:47:24,661] Trial 106 pruned. \n",
                        "[I 2024-10-17 08:47:24,676] Trial 107 pruned. \n",
                        "[I 2024-10-17 08:47:24,693] Trial 108 pruned. \n",
                        "[I 2024-10-17 08:47:24,714] Trial 109 pruned. \n",
                        "[I 2024-10-17 08:47:24,741] Trial 110 pruned. \n",
                        "[I 2024-10-17 08:47:24,757] Trial 111 pruned. \n",
                        "[I 2024-10-17 08:47:24,779] Trial 112 pruned. \n",
                        "[I 2024-10-17 08:47:24,798] Trial 113 pruned. \n",
                        "[I 2024-10-17 08:47:24,814] Trial 114 pruned. \n",
                        "[I 2024-10-17 08:47:24,830] Trial 115 pruned. \n",
                        "[I 2024-10-17 08:47:24,852] Trial 116 pruned. \n",
                        "[I 2024-10-17 08:47:25,032] Trial 117 finished with value: 0.2309013244509697 and parameters: {'n_layers': 1, 'n_units_l0': 33, 'dropout_0': 0.34051678447929884, 'learning_rate': 0.04754737738470151, 'optimizer': 'Adam'}. Best is trial 117 with value: 0.2309013244509697.\n",
                        "[I 2024-10-17 08:47:25,048] Trial 118 pruned. \n",
                        "[I 2024-10-17 08:47:25,069] Trial 119 pruned. \n",
                        "[I 2024-10-17 08:47:25,124] Trial 120 pruned. \n",
                        "[I 2024-10-17 08:47:25,301] Trial 121 finished with value: 0.31584295228123666 and parameters: {'n_layers': 1, 'n_units_l0': 35, 'dropout_0': 0.36108589338351393, 'learning_rate': 0.057589106144745286, 'optimizer': 'Adam'}. Best is trial 117 with value: 0.2309013244509697.\n",
                        "[I 2024-10-17 08:47:25,323] Trial 122 pruned. \n",
                        "[I 2024-10-17 08:47:25,506] Trial 123 finished with value: 0.2465194383263588 and parameters: {'n_layers': 1, 'n_units_l0': 31, 'dropout_0': 0.36840108363650115, 'learning_rate': 0.05393496108523539, 'optimizer': 'Adam'}. Best is trial 117 with value: 0.2309013244509697.\n",
                        "[I 2024-10-17 08:47:25,529] Trial 124 pruned. \n",
                        "[I 2024-10-17 08:47:25,707] Trial 125 finished with value: 0.2719399516284466 and parameters: {'n_layers': 1, 'n_units_l0': 27, 'dropout_0': 0.3413545003163327, 'learning_rate': 0.052307235651232735, 'optimizer': 'Adam'}. Best is trial 117 with value: 0.2309013244509697.\n",
                        "[I 2024-10-17 08:47:25,723] Trial 126 pruned. \n",
                        "[I 2024-10-17 08:47:25,748] Trial 127 pruned. \n",
                        "[I 2024-10-17 08:47:25,764] Trial 128 pruned. \n",
                        "[I 2024-10-17 08:47:25,782] Trial 129 pruned. \n",
                        "[I 2024-10-17 08:47:25,833] Trial 130 pruned. \n",
                        "[I 2024-10-17 08:47:25,854] Trial 131 pruned. \n",
                        "[I 2024-10-17 08:47:25,876] Trial 132 pruned. \n",
                        "[I 2024-10-17 08:47:25,913] Trial 133 pruned. \n",
                        "[I 2024-10-17 08:47:25,940] Trial 134 pruned. \n",
                        "[I 2024-10-17 08:47:25,963] Trial 135 pruned. \n",
                        "[I 2024-10-17 08:47:25,981] Trial 136 pruned. \n",
                        "[I 2024-10-17 08:47:25,999] Trial 137 pruned. \n",
                        "[I 2024-10-17 08:47:26,021] Trial 138 pruned. \n",
                        "[I 2024-10-17 08:47:26,052] Trial 139 pruned. \n",
                        "[I 2024-10-17 08:47:26,081] Trial 140 pruned. \n",
                        "[I 2024-10-17 08:47:26,097] Trial 141 pruned. \n",
                        "[I 2024-10-17 08:47:26,274] Trial 142 finished with value: 0.23925740912556648 and parameters: {'n_layers': 1, 'n_units_l0': 35, 'dropout_0': 0.2923468615936513, 'learning_rate': 0.05794780045767336, 'optimizer': 'Adam'}. Best is trial 117 with value: 0.2309013244509697.\n",
                        "[I 2024-10-17 08:47:26,291] Trial 143 pruned. \n",
                        "[I 2024-10-17 08:47:26,313] Trial 144 pruned. \n",
                        "[I 2024-10-17 08:47:26,329] Trial 145 pruned. \n",
                        "[I 2024-10-17 08:47:26,362] Trial 146 pruned. \n",
                        "[I 2024-10-17 08:47:26,413] Trial 147 pruned. \n",
                        "[I 2024-10-17 08:47:26,431] Trial 148 pruned. \n",
                        "[I 2024-10-17 08:47:26,448] Trial 149 pruned. \n",
                        "[I 2024-10-17 08:47:26,470] Trial 150 pruned. \n",
                        "[I 2024-10-17 08:47:26,650] Trial 151 finished with value: 0.3051897618174553 and parameters: {'n_layers': 1, 'n_units_l0': 33, 'dropout_0': 0.3577187431337743, 'learning_rate': 0.05848427277352647, 'optimizer': 'Adam'}. Best is trial 117 with value: 0.2309013244509697.\n",
                        "[I 2024-10-17 08:47:26,834] Trial 152 finished with value: 0.29524957403540614 and parameters: {'n_layers': 1, 'n_units_l0': 33, 'dropout_0': 0.35192714754602944, 'learning_rate': 0.05801190063367813, 'optimizer': 'Adam'}. Best is trial 117 with value: 0.2309013244509697.\n",
                        "[I 2024-10-17 08:47:26,852] Trial 153 pruned. \n",
                        "[I 2024-10-17 08:47:26,875] Trial 154 pruned. \n",
                        "[I 2024-10-17 08:47:26,929] Trial 155 pruned. \n",
                        "[I 2024-10-17 08:47:26,979] Trial 156 pruned. \n",
                        "[I 2024-10-17 08:47:26,997] Trial 157 pruned. \n",
                        "[I 2024-10-17 08:47:27,022] Trial 158 pruned. \n",
                        "[I 2024-10-17 08:47:27,202] Trial 159 finished with value: 0.31512086078524587 and parameters: {'n_layers': 1, 'n_units_l0': 31, 'dropout_0': 0.2820857533454927, 'learning_rate': 0.05742692014948682, 'optimizer': 'Adam'}. Best is trial 117 with value: 0.2309013244509697.\n",
                        "[I 2024-10-17 08:47:27,224] Trial 160 pruned. \n",
                        "[I 2024-10-17 08:47:27,409] Trial 161 finished with value: 0.30114675775170324 and parameters: {'n_layers': 1, 'n_units_l0': 33, 'dropout_0': 0.355758181418335, 'learning_rate': 0.05956115107349071, 'optimizer': 'Adam'}. Best is trial 117 with value: 0.2309013244509697.\n",
                        "[I 2024-10-17 08:47:27,428] Trial 162 pruned. \n",
                        "[I 2024-10-17 08:47:27,602] Trial 163 finished with value: 0.3032181429862976 and parameters: {'n_layers': 1, 'n_units_l0': 30, 'dropout_0': 0.36663582742953804, 'learning_rate': 0.06038206858276592, 'optimizer': 'Adam'}. Best is trial 117 with value: 0.2309013244509697.\n",
                        "[I 2024-10-17 08:47:27,619] Trial 164 pruned. \n",
                        "[I 2024-10-17 08:47:27,797] Trial 165 finished with value: 0.41237853437662125 and parameters: {'n_layers': 1, 'n_units_l0': 27, 'dropout_0': 0.3480248429935657, 'learning_rate': 0.05200175858784552, 'optimizer': 'Adam'}. Best is trial 117 with value: 0.2309013244509697.\n",
                        "[I 2024-10-17 08:47:27,814] Trial 166 pruned. \n",
                        "[I 2024-10-17 08:47:27,838] Trial 167 pruned. \n",
                        "[I 2024-10-17 08:47:27,854] Trial 168 pruned. \n",
                        "[I 2024-10-17 08:47:27,873] Trial 169 pruned. \n",
                        "[I 2024-10-17 08:47:27,896] Trial 170 pruned. \n",
                        "[I 2024-10-17 08:47:27,912] Trial 171 pruned. \n",
                        "[I 2024-10-17 08:47:27,932] Trial 172 pruned. \n",
                        "[I 2024-10-17 08:47:27,958] Trial 173 pruned. \n",
                        "[I 2024-10-17 08:47:28,011] Trial 174 pruned. \n",
                        "[I 2024-10-17 08:47:28,031] Trial 175 pruned. \n",
                        "[I 2024-10-17 08:47:28,050] Trial 176 pruned. \n",
                        "[I 2024-10-17 08:47:28,075] Trial 177 pruned. \n",
                        "[I 2024-10-17 08:47:28,115] Trial 178 pruned. \n",
                        "[I 2024-10-17 08:47:28,184] Trial 179 pruned. \n",
                        "[I 2024-10-17 08:47:28,257] Trial 180 pruned. \n",
                        "[I 2024-10-17 08:47:28,434] Trial 181 finished with value: 0.3411330968141556 and parameters: {'n_layers': 1, 'n_units_l0': 33, 'dropout_0': 0.3581977615631036, 'learning_rate': 0.057906405991174484, 'optimizer': 'Adam'}. Best is trial 117 with value: 0.2309013244509697.\n",
                        "[I 2024-10-17 08:47:28,464] Trial 182 pruned. \n",
                        "[I 2024-10-17 08:47:28,650] Trial 183 finished with value: 0.2735607255995274 and parameters: {'n_layers': 1, 'n_units_l0': 33, 'dropout_0': 0.3573559254239501, 'learning_rate': 0.05514603708794247, 'optimizer': 'Adam'}. Best is trial 117 with value: 0.2309013244509697.\n",
                        "[I 2024-10-17 08:47:28,667] Trial 184 pruned. \n",
                        "[I 2024-10-17 08:47:28,683] Trial 185 pruned. \n",
                        "[I 2024-10-17 08:47:28,736] Trial 186 pruned. \n",
                        "[I 2024-10-17 08:47:28,758] Trial 187 pruned. \n",
                        "[I 2024-10-17 08:47:28,775] Trial 188 pruned. \n",
                        "[I 2024-10-17 08:47:28,792] Trial 189 pruned. \n",
                        "[I 2024-10-17 08:47:28,814] Trial 190 pruned. \n",
                        "[I 2024-10-17 08:47:28,830] Trial 191 pruned. \n",
                        "[I 2024-10-17 08:47:28,846] Trial 192 pruned. \n",
                        "[I 2024-10-17 08:47:28,863] Trial 193 pruned. \n",
                        "[I 2024-10-17 08:47:28,882] Trial 194 pruned. \n",
                        "[I 2024-10-17 08:47:28,899] Trial 195 pruned. \n",
                        "[I 2024-10-17 08:47:28,915] Trial 196 pruned. \n",
                        "[I 2024-10-17 08:47:28,937] Trial 197 pruned. \n",
                        "[I 2024-10-17 08:47:28,953] Trial 198 pruned. \n",
                        "[I 2024-10-17 08:47:28,970] Trial 199 pruned. \n",
                        "[I 2024-10-17 08:47:28,993] Trial 200 pruned. \n",
                        "[I 2024-10-17 08:47:29,009] Trial 201 pruned. \n",
                        "[I 2024-10-17 08:47:29,042] Trial 202 pruned. \n",
                        "[I 2024-10-17 08:47:29,060] Trial 203 pruned. \n",
                        "[I 2024-10-17 08:47:29,247] Trial 204 finished with value: 0.30665970116853714 and parameters: {'n_layers': 1, 'n_units_l0': 23, 'dropout_0': 0.2724905440980525, 'learning_rate': 0.06266662555338744, 'optimizer': 'Adam'}. Best is trial 117 with value: 0.2309013244509697.\n",
                        "[I 2024-10-17 08:47:29,424] Trial 205 finished with value: 0.3459579341113567 and parameters: {'n_layers': 1, 'n_units_l0': 23, 'dropout_0': 0.267010627380242, 'learning_rate': 0.06509988299587842, 'optimizer': 'Adam'}. Best is trial 117 with value: 0.2309013244509697.\n",
                        "[I 2024-10-17 08:47:29,442] Trial 206 pruned. \n",
                        "[I 2024-10-17 08:47:29,459] Trial 207 pruned. \n",
                        "[I 2024-10-17 08:47:29,483] Trial 208 pruned. \n",
                        "[I 2024-10-17 08:47:29,506] Trial 209 pruned. \n",
                        "[I 2024-10-17 08:47:29,524] Trial 210 pruned. \n",
                        "[I 2024-10-17 08:47:29,542] Trial 211 pruned. \n",
                        "[I 2024-10-17 08:47:29,559] Trial 212 pruned. \n",
                        "[I 2024-10-17 08:47:29,604] Trial 213 pruned. \n",
                        "[I 2024-10-17 08:47:29,624] Trial 214 pruned. \n",
                        "[I 2024-10-17 08:47:29,642] Trial 215 pruned. \n",
                        "[I 2024-10-17 08:47:29,660] Trial 216 pruned. \n",
                        "[I 2024-10-17 08:47:29,683] Trial 217 pruned. \n",
                        "[I 2024-10-17 08:47:29,700] Trial 218 pruned. \n",
                        "[I 2024-10-17 08:47:29,718] Trial 219 pruned. \n",
                        "[I 2024-10-17 08:47:29,776] Trial 220 pruned. \n",
                        "[I 2024-10-17 08:47:29,794] Trial 221 pruned. \n",
                        "[I 2024-10-17 08:47:29,832] Trial 222 pruned. \n",
                        "[I 2024-10-17 08:47:29,879] Trial 223 pruned. \n",
                        "[I 2024-10-17 08:47:29,939] Trial 224 pruned. \n",
                        "[I 2024-10-17 08:47:29,963] Trial 225 pruned. \n",
                        "[I 2024-10-17 08:47:30,030] Trial 226 pruned. \n",
                        "[I 2024-10-17 08:47:30,055] Trial 227 pruned. \n",
                        "[I 2024-10-17 08:47:30,086] Trial 228 pruned. \n",
                        "[I 2024-10-17 08:47:30,105] Trial 229 pruned. \n",
                        "[I 2024-10-17 08:47:30,124] Trial 230 pruned. \n",
                        "[I 2024-10-17 08:47:30,158] Trial 231 pruned. \n",
                        "[I 2024-10-17 08:47:30,354] Trial 232 finished with value: 0.4329911033809185 and parameters: {'n_layers': 1, 'n_units_l0': 35, 'dropout_0': 0.3893475011970118, 'learning_rate': 0.07163812191507796, 'optimizer': 'Adam'}. Best is trial 117 with value: 0.2309013244509697.\n",
                        "[I 2024-10-17 08:47:30,375] Trial 233 pruned. \n",
                        "[I 2024-10-17 08:47:30,397] Trial 234 pruned. \n",
                        "[I 2024-10-17 08:47:30,583] Trial 235 finished with value: 0.29975943177938463 and parameters: {'n_layers': 1, 'n_units_l0': 33, 'dropout_0': 0.3966776279036079, 'learning_rate': 0.06212377337011604, 'optimizer': 'Adam'}. Best is trial 117 with value: 0.2309013244509697.\n",
                        "[I 2024-10-17 08:47:30,601] Trial 236 pruned. \n",
                        "[I 2024-10-17 08:47:30,629] Trial 237 pruned. \n",
                        "[I 2024-10-17 08:47:30,655] Trial 238 pruned. \n",
                        "[I 2024-10-17 08:47:30,677] Trial 239 pruned. \n",
                        "[I 2024-10-17 08:47:30,719] Trial 240 pruned. \n",
                        "[I 2024-10-17 08:47:30,739] Trial 241 pruned. \n",
                        "[I 2024-10-17 08:47:30,760] Trial 242 pruned. \n",
                        "[I 2024-10-17 08:47:30,784] Trial 243 pruned. \n",
                        "[I 2024-10-17 08:47:30,805] Trial 244 pruned. \n",
                        "[I 2024-10-17 08:47:30,825] Trial 245 pruned. \n",
                        "[I 2024-10-17 08:47:30,848] Trial 246 pruned. \n",
                        "[I 2024-10-17 08:47:30,870] Trial 247 pruned. \n",
                        "[I 2024-10-17 08:47:30,930] Trial 248 pruned. \n",
                        "[I 2024-10-17 08:47:30,949] Trial 249 pruned. \n",
                        "[I 2024-10-17 08:47:30,978] Trial 250 pruned. \n",
                        "[I 2024-10-17 08:47:31,002] Trial 251 pruned. \n",
                        "[I 2024-10-17 08:47:31,048] Trial 252 pruned. \n",
                        "[I 2024-10-17 08:47:31,075] Trial 253 pruned. \n",
                        "[I 2024-10-17 08:47:31,098] Trial 254 pruned. \n",
                        "[I 2024-10-17 08:47:31,117] Trial 255 pruned. \n",
                        "[I 2024-10-17 08:47:31,144] Trial 256 pruned. \n",
                        "[I 2024-10-17 08:47:31,163] Trial 257 pruned. \n",
                        "[I 2024-10-17 08:47:31,232] Trial 258 pruned. \n",
                        "[I 2024-10-17 08:47:31,256] Trial 259 pruned. \n",
                        "[I 2024-10-17 08:47:31,276] Trial 260 pruned. \n",
                        "[I 2024-10-17 08:47:31,296] Trial 261 pruned. \n",
                        "[I 2024-10-17 08:47:31,315] Trial 262 pruned. \n",
                        "[I 2024-10-17 08:47:31,340] Trial 263 pruned. \n",
                        "[I 2024-10-17 08:47:31,359] Trial 264 pruned. \n",
                        "[I 2024-10-17 08:47:31,378] Trial 265 pruned. \n",
                        "[I 2024-10-17 08:47:31,401] Trial 266 pruned. \n",
                        "[I 2024-10-17 08:47:31,421] Trial 267 pruned. \n",
                        "[I 2024-10-17 08:47:31,440] Trial 268 pruned. \n",
                        "[I 2024-10-17 08:47:31,459] Trial 269 pruned. \n",
                        "[I 2024-10-17 08:47:31,485] Trial 270 pruned. \n",
                        "[I 2024-10-17 08:47:31,504] Trial 271 pruned. \n",
                        "[I 2024-10-17 08:47:31,594] Trial 272 pruned. \n",
                        "[I 2024-10-17 08:47:31,613] Trial 273 pruned. \n",
                        "[I 2024-10-17 08:47:31,688] Trial 274 pruned. \n",
                        "[I 2024-10-17 08:47:31,715] Trial 275 pruned. \n",
                        "[I 2024-10-17 08:47:31,735] Trial 276 pruned. \n",
                        "[I 2024-10-17 08:47:31,778] Trial 277 pruned. \n",
                        "[I 2024-10-17 08:47:31,803] Trial 278 pruned. \n",
                        "[I 2024-10-17 08:47:31,823] Trial 279 pruned. \n",
                        "[I 2024-10-17 08:47:31,843] Trial 280 pruned. \n",
                        "[I 2024-10-17 08:47:31,869] Trial 281 pruned. \n",
                        "[I 2024-10-17 08:47:31,912] Trial 282 pruned. \n",
                        "[I 2024-10-17 08:47:31,938] Trial 283 pruned. \n",
                        "[I 2024-10-17 08:47:31,959] Trial 284 pruned. \n",
                        "[I 2024-10-17 08:47:31,984] Trial 285 pruned. \n",
                        "[I 2024-10-17 08:47:32,003] Trial 286 pruned. \n",
                        "[I 2024-10-17 08:47:32,022] Trial 287 pruned. \n",
                        "[I 2024-10-17 08:47:32,199] Trial 288 finished with value: 0.24531447671353818 and parameters: {'n_layers': 1, 'n_units_l0': 33, 'dropout_0': 0.3409098692751239, 'learning_rate': 0.04910434562880333, 'optimizer': 'Adam'}. Best is trial 117 with value: 0.2309013244509697.\n",
                        "[I 2024-10-17 08:47:32,293] Trial 289 pruned. \n",
                        "[I 2024-10-17 08:47:32,346] Trial 290 pruned. \n",
                        "[I 2024-10-17 08:47:32,365] Trial 291 pruned. \n",
                        "[I 2024-10-17 08:47:32,384] Trial 292 pruned. \n",
                        "[I 2024-10-17 08:47:32,404] Trial 293 pruned. \n",
                        "[I 2024-10-17 08:47:32,427] Trial 294 pruned. \n",
                        "[I 2024-10-17 08:47:32,453] Trial 295 pruned. \n",
                        "[I 2024-10-17 08:47:32,497] Trial 296 pruned. \n",
                        "[I 2024-10-17 08:47:32,518] Trial 297 pruned. \n",
                        "[I 2024-10-17 08:47:32,538] Trial 298 pruned. \n",
                        "[I 2024-10-17 08:47:32,597] Trial 299 pruned. \n",
                        "[I 2024-10-17 08:47:32,623] Trial 300 pruned. \n",
                        "[I 2024-10-17 08:47:32,647] Trial 301 pruned. \n",
                        "[I 2024-10-17 08:47:32,673] Trial 302 pruned. \n",
                        "[I 2024-10-17 08:47:32,700] Trial 303 pruned. \n",
                        "[I 2024-10-17 08:47:32,722] Trial 304 pruned. \n",
                        "[I 2024-10-17 08:47:32,741] Trial 305 pruned. \n",
                        "[I 2024-10-17 08:47:32,763] Trial 306 pruned. \n",
                        "[I 2024-10-17 08:47:32,784] Trial 307 pruned. \n",
                        "[I 2024-10-17 08:47:32,812] Trial 308 pruned. \n",
                        "[I 2024-10-17 08:47:32,832] Trial 309 pruned. \n",
                        "[I 2024-10-17 08:47:32,852] Trial 310 pruned. \n",
                        "[I 2024-10-17 08:47:32,872] Trial 311 pruned. \n",
                        "[I 2024-10-17 08:47:32,898] Trial 312 pruned. \n",
                        "[I 2024-10-17 08:47:32,917] Trial 313 pruned. \n",
                        "[I 2024-10-17 08:47:32,937] Trial 314 pruned. \n",
                        "[I 2024-10-17 08:47:32,957] Trial 315 pruned. \n",
                        "[I 2024-10-17 08:47:32,977] Trial 316 pruned. \n",
                        "[I 2024-10-17 08:47:33,003] Trial 317 pruned. \n",
                        "[I 2024-10-17 08:47:33,024] Trial 318 pruned. \n",
                        "[I 2024-10-17 08:47:33,050] Trial 319 pruned. \n",
                        "[I 2024-10-17 08:47:33,072] Trial 320 pruned. \n",
                        "[I 2024-10-17 08:47:33,103] Trial 321 pruned. \n",
                        "[I 2024-10-17 08:47:33,136] Trial 322 pruned. \n",
                        "[I 2024-10-17 08:47:33,163] Trial 323 pruned. \n",
                        "[I 2024-10-17 08:47:33,186] Trial 324 pruned. \n",
                        "[I 2024-10-17 08:47:33,209] Trial 325 pruned. \n",
                        "[I 2024-10-17 08:47:33,237] Trial 326 pruned. \n",
                        "[I 2024-10-17 08:47:33,279] Trial 327 pruned. \n",
                        "[I 2024-10-17 08:47:33,301] Trial 328 pruned. \n",
                        "[I 2024-10-17 08:47:33,390] Trial 329 pruned. \n",
                        "[I 2024-10-17 08:47:33,430] Trial 330 pruned. \n",
                        "[I 2024-10-17 08:47:33,453] Trial 331 pruned. \n",
                        "[I 2024-10-17 08:47:33,486] Trial 332 pruned. \n",
                        "[I 2024-10-17 08:47:33,513] Trial 333 pruned. \n",
                        "[I 2024-10-17 08:47:33,550] Trial 334 pruned. \n",
                        "[I 2024-10-17 08:47:33,571] Trial 335 pruned. \n",
                        "[I 2024-10-17 08:47:33,594] Trial 336 pruned. \n",
                        "[I 2024-10-17 08:47:33,614] Trial 337 pruned. \n",
                        "[I 2024-10-17 08:47:33,641] Trial 338 pruned. \n",
                        "[I 2024-10-17 08:47:33,661] Trial 339 pruned. \n",
                        "[I 2024-10-17 08:47:33,682] Trial 340 pruned. \n",
                        "[I 2024-10-17 08:47:33,709] Trial 341 pruned. \n",
                        "[I 2024-10-17 08:47:33,729] Trial 342 pruned. \n",
                        "[I 2024-10-17 08:47:33,749] Trial 343 pruned. \n",
                        "[I 2024-10-17 08:47:33,782] Trial 344 pruned. \n",
                        "[I 2024-10-17 08:47:33,809] Trial 345 pruned. \n",
                        "[I 2024-10-17 08:47:33,830] Trial 346 pruned. \n",
                        "[I 2024-10-17 08:47:33,850] Trial 347 pruned. \n",
                        "[I 2024-10-17 08:47:34,033] Trial 348 finished with value: 0.29123784288764 and parameters: {'n_layers': 1, 'n_units_l0': 30, 'dropout_0': 0.3653434706049412, 'learning_rate': 0.048975611880889475, 'optimizer': 'Adam'}. Best is trial 117 with value: 0.2309013244509697.\n",
                        "[I 2024-10-17 08:47:34,054] Trial 349 pruned. \n",
                        "[I 2024-10-17 08:47:34,075] Trial 350 pruned. \n",
                        "[I 2024-10-17 08:47:34,120] Trial 351 pruned. \n",
                        "[I 2024-10-17 08:47:34,147] Trial 352 pruned. \n",
                        "[I 2024-10-17 08:47:34,167] Trial 353 pruned. \n",
                        "[I 2024-10-17 08:47:34,347] Trial 354 finished with value: 0.2754799197614193 and parameters: {'n_layers': 1, 'n_units_l0': 30, 'dropout_0': 0.2711201759282552, 'learning_rate': 0.05125267228432693, 'optimizer': 'Adam'}. Best is trial 117 with value: 0.2309013244509697.\n",
                        "[I 2024-10-17 08:47:34,369] Trial 355 pruned. \n",
                        "[I 2024-10-17 08:47:34,400] Trial 356 pruned. \n",
                        "[I 2024-10-17 08:47:34,421] Trial 357 pruned. \n",
                        "[I 2024-10-17 08:47:34,441] Trial 358 pruned. \n",
                        "[I 2024-10-17 08:47:34,474] Trial 359 pruned. \n",
                        "[I 2024-10-17 08:47:34,501] Trial 360 pruned. \n",
                        "[I 2024-10-17 08:47:34,521] Trial 361 pruned. \n",
                        "[I 2024-10-17 08:47:34,577] Trial 362 pruned. \n",
                        "[I 2024-10-17 08:47:34,597] Trial 363 pruned. \n",
                        "[I 2024-10-17 08:47:34,623] Trial 364 pruned. \n",
                        "[I 2024-10-17 08:47:34,644] Trial 365 pruned. \n",
                        "[I 2024-10-17 08:47:34,664] Trial 366 pruned. \n",
                        "[I 2024-10-17 08:47:34,685] Trial 367 pruned. \n",
                        "[I 2024-10-17 08:47:34,705] Trial 368 pruned. \n",
                        "[I 2024-10-17 08:47:34,732] Trial 369 pruned. \n",
                        "[I 2024-10-17 08:47:34,752] Trial 370 pruned. \n",
                        "[I 2024-10-17 08:47:34,773] Trial 371 pruned. \n",
                        "[I 2024-10-17 08:47:34,795] Trial 372 pruned. \n",
                        "[I 2024-10-17 08:47:34,880] Trial 373 pruned. \n",
                        "[I 2024-10-17 08:47:34,908] Trial 374 pruned. \n",
                        "[I 2024-10-17 08:47:34,929] Trial 375 pruned. \n",
                        "[I 2024-10-17 08:47:34,950] Trial 376 pruned. \n",
                        "[I 2024-10-17 08:47:34,971] Trial 377 pruned. \n",
                        "[I 2024-10-17 08:47:34,992] Trial 378 pruned. \n",
                        "[I 2024-10-17 08:47:35,019] Trial 379 pruned. \n",
                        "[I 2024-10-17 08:47:35,041] Trial 380 pruned. \n",
                        "[I 2024-10-17 08:47:35,062] Trial 381 pruned. \n",
                        "[I 2024-10-17 08:47:35,084] Trial 382 pruned. \n",
                        "[I 2024-10-17 08:47:35,112] Trial 383 pruned. \n",
                        "[I 2024-10-17 08:47:35,133] Trial 384 pruned. \n",
                        "[I 2024-10-17 08:47:35,154] Trial 385 pruned. \n",
                        "[I 2024-10-17 08:47:35,175] Trial 386 pruned. \n",
                        "[I 2024-10-17 08:47:35,197] Trial 387 pruned. \n",
                        "[I 2024-10-17 08:47:35,225] Trial 388 pruned. \n",
                        "[I 2024-10-17 08:47:35,277] Trial 389 pruned. \n",
                        "[I 2024-10-17 08:47:35,300] Trial 390 pruned. \n",
                        "[I 2024-10-17 08:47:35,324] Trial 391 pruned. \n",
                        "[I 2024-10-17 08:47:35,346] Trial 392 pruned. \n",
                        "[I 2024-10-17 08:47:35,375] Trial 393 pruned. \n",
                        "[I 2024-10-17 08:47:35,397] Trial 394 pruned. \n",
                        "[I 2024-10-17 08:47:35,467] Trial 395 pruned. \n",
                        "[I 2024-10-17 08:47:35,489] Trial 396 pruned. \n",
                        "[I 2024-10-17 08:47:35,520] Trial 397 pruned. \n",
                        "[I 2024-10-17 08:47:35,541] Trial 398 pruned. \n",
                        "[I 2024-10-17 08:47:35,569] Trial 399 pruned. \n",
                        "[I 2024-10-17 08:47:35,591] Trial 400 pruned. \n",
                        "[I 2024-10-17 08:47:35,618] Trial 401 pruned. \n",
                        "[I 2024-10-17 08:47:35,639] Trial 402 pruned. \n",
                        "[I 2024-10-17 08:47:35,668] Trial 403 pruned. \n",
                        "[I 2024-10-17 08:47:35,691] Trial 404 pruned. \n",
                        "[I 2024-10-17 08:47:35,717] Trial 405 pruned. \n",
                        "[I 2024-10-17 08:47:35,753] Trial 406 pruned. \n",
                        "[I 2024-10-17 08:47:35,778] Trial 407 pruned. \n",
                        "[I 2024-10-17 08:47:35,800] Trial 408 pruned. \n",
                        "[I 2024-10-17 08:47:35,823] Trial 409 pruned. \n",
                        "[I 2024-10-17 08:47:35,858] Trial 410 pruned. \n",
                        "[I 2024-10-17 08:47:35,923] Trial 411 pruned. \n",
                        "[I 2024-10-17 08:47:35,945] Trial 412 pruned. \n",
                        "[I 2024-10-17 08:47:35,967] Trial 413 pruned. \n",
                        "[I 2024-10-17 08:47:35,988] Trial 414 pruned. \n",
                        "[I 2024-10-17 08:47:36,010] Trial 415 pruned. \n",
                        "[I 2024-10-17 08:47:36,038] Trial 416 pruned. \n",
                        "[I 2024-10-17 08:47:36,059] Trial 417 pruned. \n",
                        "[I 2024-10-17 08:47:36,081] Trial 418 pruned. \n",
                        "[I 2024-10-17 08:47:36,110] Trial 419 pruned. \n",
                        "[I 2024-10-17 08:47:36,131] Trial 420 pruned. \n",
                        "[I 2024-10-17 08:47:36,163] Trial 421 pruned. \n",
                        "[I 2024-10-17 08:47:36,186] Trial 422 pruned. \n",
                        "[I 2024-10-17 08:47:36,214] Trial 423 pruned. \n",
                        "[I 2024-10-17 08:47:36,235] Trial 424 pruned. \n",
                        "[I 2024-10-17 08:47:36,257] Trial 425 pruned. \n",
                        "[I 2024-10-17 08:47:36,286] Trial 426 pruned. \n",
                        "[I 2024-10-17 08:47:36,307] Trial 427 pruned. \n",
                        "[I 2024-10-17 08:47:36,329] Trial 428 pruned. \n",
                        "[I 2024-10-17 08:47:36,352] Trial 429 pruned. \n",
                        "[I 2024-10-17 08:47:36,375] Trial 430 pruned. \n",
                        "[I 2024-10-17 08:47:36,404] Trial 431 pruned. \n",
                        "[I 2024-10-17 08:47:36,436] Trial 432 pruned. \n",
                        "[I 2024-10-17 08:47:36,617] Trial 433 finished with value: 0.29567630305886267 and parameters: {'n_layers': 1, 'n_units_l0': 34, 'dropout_0': 0.3692365083647886, 'learning_rate': 0.052099539365567354, 'optimizer': 'Adam'}. Best is trial 117 with value: 0.2309013244509697.\n",
                        "[I 2024-10-17 08:47:36,669] Trial 434 pruned. \n",
                        "[I 2024-10-17 08:47:36,692] Trial 435 pruned. \n",
                        "[I 2024-10-17 08:47:36,714] Trial 436 pruned. \n",
                        "[I 2024-10-17 08:47:36,743] Trial 437 pruned. \n",
                        "[I 2024-10-17 08:47:36,766] Trial 438 pruned. \n",
                        "[I 2024-10-17 08:47:36,807] Trial 439 pruned. \n",
                        "[I 2024-10-17 08:47:36,830] Trial 440 pruned. \n",
                        "[I 2024-10-17 08:47:36,852] Trial 441 pruned. \n",
                        "[I 2024-10-17 08:47:36,882] Trial 442 pruned. \n",
                        "[I 2024-10-17 08:47:36,904] Trial 443 pruned. \n",
                        "[I 2024-10-17 08:47:36,958] Trial 444 pruned. \n",
                        "[I 2024-10-17 08:47:37,141] Trial 445 finished with value: 0.2669934593886137 and parameters: {'n_layers': 1, 'n_units_l0': 34, 'dropout_0': 0.349557239170333, 'learning_rate': 0.053782109820734184, 'optimizer': 'Adam'}. Best is trial 117 with value: 0.2309013244509697.\n",
                        "[I 2024-10-17 08:47:37,166] Trial 446 pruned. \n",
                        "[I 2024-10-17 08:47:37,197] Trial 447 pruned. \n",
                        "[I 2024-10-17 08:47:37,276] Trial 448 pruned. \n",
                        "[I 2024-10-17 08:47:37,298] Trial 449 pruned. \n",
                        "[I 2024-10-17 08:47:37,321] Trial 450 pruned. \n",
                        "[I 2024-10-17 08:47:37,357] Trial 451 pruned. \n",
                        "[I 2024-10-17 08:47:37,380] Trial 452 pruned. \n",
                        "[I 2024-10-17 08:47:37,409] Trial 453 pruned. \n",
                        "[I 2024-10-17 08:47:37,441] Trial 454 pruned. \n",
                        "[I 2024-10-17 08:47:37,466] Trial 455 pruned. \n",
                        "[I 2024-10-17 08:47:37,650] Trial 456 finished with value: 0.2893710832297802 and parameters: {'n_layers': 1, 'n_units_l0': 31, 'dropout_0': 0.38754491087002474, 'learning_rate': 0.0531511029281551, 'optimizer': 'Adam'}. Best is trial 117 with value: 0.2309013244509697.\n",
                        "[I 2024-10-17 08:47:37,674] Trial 457 pruned. \n",
                        "[I 2024-10-17 08:47:37,704] Trial 458 pruned. \n",
                        "[I 2024-10-17 08:47:37,728] Trial 459 pruned. \n",
                        "[I 2024-10-17 08:47:37,750] Trial 460 pruned. \n",
                        "[I 2024-10-17 08:47:37,935] Trial 461 finished with value: 0.2723949858546257 and parameters: {'n_layers': 1, 'n_units_l0': 35, 'dropout_0': 0.3882418411850154, 'learning_rate': 0.04720524801267958, 'optimizer': 'Adam'}. Best is trial 117 with value: 0.2309013244509697.\n",
                        "[I 2024-10-17 08:47:37,985] Trial 462 pruned. \n",
                        "[I 2024-10-17 08:47:38,007] Trial 463 pruned. \n",
                        "[I 2024-10-17 08:47:38,031] Trial 464 pruned. \n",
                        "[I 2024-10-17 08:47:38,061] Trial 465 pruned. \n",
                        "[I 2024-10-17 08:47:38,084] Trial 466 pruned. \n",
                        "[I 2024-10-17 08:47:38,108] Trial 467 pruned. \n",
                        "[I 2024-10-17 08:47:38,131] Trial 468 pruned. \n",
                        "[I 2024-10-17 08:47:38,156] Trial 469 pruned. \n",
                        "[I 2024-10-17 08:47:38,179] Trial 470 pruned. \n",
                        "[I 2024-10-17 08:47:38,209] Trial 471 pruned. \n",
                        "[I 2024-10-17 08:47:38,232] Trial 472 pruned. \n",
                        "[I 2024-10-17 08:47:38,263] Trial 473 pruned. \n",
                        "[I 2024-10-17 08:47:38,287] Trial 474 pruned. \n",
                        "[I 2024-10-17 08:47:38,310] Trial 475 pruned. \n",
                        "[I 2024-10-17 08:47:38,333] Trial 476 pruned. \n",
                        "[I 2024-10-17 08:47:38,365] Trial 477 pruned. \n",
                        "[I 2024-10-17 08:47:38,388] Trial 478 pruned. \n",
                        "[I 2024-10-17 08:47:38,435] Trial 479 pruned. \n",
                        "[I 2024-10-17 08:47:38,459] Trial 480 pruned. \n",
                        "[I 2024-10-17 08:47:38,484] Trial 481 pruned. \n",
                        "[I 2024-10-17 08:47:38,511] Trial 482 pruned. \n",
                        "[I 2024-10-17 08:47:38,610] Trial 483 pruned. \n",
                        "[I 2024-10-17 08:47:38,642] Trial 484 pruned. \n",
                        "[I 2024-10-17 08:47:38,667] Trial 485 pruned. \n",
                        "[I 2024-10-17 08:47:38,700] Trial 486 pruned. \n",
                        "[I 2024-10-17 08:47:38,804] Trial 487 pruned. \n",
                        "[I 2024-10-17 08:47:38,828] Trial 488 pruned. \n",
                        "[I 2024-10-17 08:47:38,850] Trial 489 pruned. \n",
                        "[I 2024-10-17 08:47:38,873] Trial 490 pruned. \n",
                        "[I 2024-10-17 08:47:38,897] Trial 491 pruned. \n",
                        "[I 2024-10-17 08:47:38,920] Trial 492 pruned. \n",
                        "[I 2024-10-17 08:47:38,951] Trial 493 pruned. \n",
                        "[I 2024-10-17 08:47:38,974] Trial 494 pruned. \n",
                        "[I 2024-10-17 08:47:38,998] Trial 495 pruned. \n",
                        "[I 2024-10-17 08:47:39,026] Trial 496 pruned. \n",
                        "[I 2024-10-17 08:47:39,059] Trial 497 pruned. \n",
                        "[I 2024-10-17 08:47:39,086] Trial 498 pruned. \n",
                        "[I 2024-10-17 08:47:39,110] Trial 499 pruned. \n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Validation Accuracy: 0.0\n",
                        "Validation Loss: 0.3696498507261276\n",
                        "Training Accuracy: 0.0\n",
                        "Training Loss: 0.09906801139004529\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "(0.0, 0.3696498507261276, 0.0, 0.09906801139004529)"
                        ]
                    },
                    "execution_count": 23,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# no accuracy function must be loss for regression\n",
                "if mlp_params.MODEL_TYPE == \"Regression\":\n",
                "    mlp_params.METRIC = \"loss\"\n",
                "    pass\n",
                "\n",
                "\n",
                "# wrap the objective function inside of a lambda function to pass args...\n",
                "objective_lambda_func = lambda trial: objective_model_optimizer(\n",
                "    train_loader,\n",
                "    valid_loader,\n",
                "    trial=trial,\n",
                "    params=params,\n",
                "    metric=mlp_params.METRIC,\n",
                "    return_info=False,\n",
                "    class_weights=class_weights,\n",
                ")\n",
                "\n",
                "\n",
                "# Study is the object for model optimization\n",
                "study = optuna.create_study(direction=f\"{mlp_params.DIRECTION}\")\n",
                "# Here I apply the optimize function of the study to the objective function\n",
                "# This optimizes each parameter specified to be optimized from the defined search space\n",
                "study.optimize(objective_lambda_func, n_trials=mlp_params.N_TRIALS)\n",
                "# Prints out the best trial's optimized parameters\n",
                "objective_model_optimizer(\n",
                "    train_loader,\n",
                "    valid_loader,\n",
                "    trial=study.best_trial,\n",
                "    params=params,\n",
                "    metric=mlp_params.METRIC,\n",
                "    return_info=True,\n",
                "    class_weights=class_weights,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "id": "b2620589",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-10-18T18:17:37.298015Z",
                    "iopub.status.busy": "2023-10-18T18:17:37.297873Z",
                    "iopub.status.idle": "2023-10-18T18:17:37.750921Z",
                    "shell.execute_reply": "2023-10-18T18:17:37.750533Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# create graph directory for this model\n",
                "graph_path = pathlib.Path(\n",
                "    f\"../../figures/{mlp_params.MODEL_TYPE}/{mlp_params.MODEL_NAME}/{mlp_params.CELL_TYPE}_{channel_combination_key}/hyperparameter_optimization\"\n",
                ")\n",
                "\n",
                "pathlib.Path(graph_path).mkdir(parents=True, exist_ok=True)\n",
                "fig = optuna.visualization.plot_optimization_history(study)\n",
                "\n",
                "\n",
                "graph_path = f\"{graph_path}/plot_optimization_history_graph\"\n",
                "\n",
                "fig.write_image(pathlib.Path(f\"{graph_path}.png\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "id": "92103de1",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-10-18T18:17:37.839841Z",
                    "iopub.status.busy": "2023-10-18T18:17:37.839637Z",
                    "iopub.status.idle": "2023-10-18T18:17:37.910906Z",
                    "shell.execute_reply": "2023-10-18T18:17:37.910591Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# create graph directory for this model\n",
                "graph_path = pathlib.Path(\n",
                "    f\"../../figures/{mlp_params.MODEL_TYPE}/{mlp_params.MODEL_NAME}/{mlp_params.CELL_TYPE}_{channel_combination_key}/hyperparameter_optimization\"\n",
                ").resolve(strict=True)\n",
                "\n",
                "pathlib.Path(graph_path).mkdir(parents=True, exist_ok=True)\n",
                "fig = optuna.visualization.plot_intermediate_values(study)\n",
                "\n",
                "graph_path = f\"{graph_path}/plot_intermediate_values_graph\"\n",
                "\n",
                "fig.write_image(pathlib.Path(f\"{graph_path}.png\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "id": "325a1ec3",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-10-18T18:17:37.971533Z",
                    "iopub.status.busy": "2023-10-18T18:17:37.971249Z",
                    "iopub.status.idle": "2023-10-18T18:17:37.974028Z",
                    "shell.execute_reply": "2023-10-18T18:17:37.973638Z"
                },
                "papermill": {
                    "duration": null,
                    "end_time": null,
                    "exception": null,
                    "start_time": null,
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "param_dict = extract_best_trial_params(\n",
                "    study.best_params, params, model_name=mlp_params.MODEL_NAME\n",
                ")"
            ]
        }
    ],
    "metadata": {
        "jupytext": {
            "cell_metadata_filter": "-all",
            "encoding": "# coding: utf-8",
            "executable": "/usr/bin/env python",
            "formats": "ipynb,py",
            "main_language": "python"
        },
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.15"
        },
        "papermill": {
            "default_parameters": {},
            "duration": 59.524284,
            "end_time": "2023-10-18T18:21:03.252265",
            "environment_variables": {},
            "exception": null,
            "input_path": "Hyperparameter_Optimization_model_binary.ipynb",
            "output_path": "Hyperparameter_Optimization_model_binary.ipynb",
            "parameters": {
                "CELL_TYPE": "PBMC",
                "CONTROL_NAME": "DMSO_0.100_%_DMSO_0.025_%",
                "MODEL_NAME": "DMSO_0.025_vs_Thapsigargin_10",
                "TREATMENT_NAME": "Thapsigargin_10.000_uM_DMSO_0.025_%"
            },
            "start_time": "2023-10-18T18:20:03.727981",
            "version": "2.4.0"
        },
        "vscode": {
            "interpreter": {
                "hash": "72ae02083a9ca7d143c492d1aec380c7bf553ec51bd66e90e72bba65228121b6"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
