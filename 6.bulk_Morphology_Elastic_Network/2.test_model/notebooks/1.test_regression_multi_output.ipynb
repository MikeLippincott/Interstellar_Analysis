{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import ast\n",
    "import itertools\n",
    "import pathlib\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# plot the predictions\n",
    "import seaborn as sns\n",
    "import toml\n",
    "from joblib import dump\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.linear_model import ElasticNetCV, LogisticRegression, MultiTaskElasticNetCV\n",
    "\n",
    "# import mse\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# import RepeatedKFold\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    LeaveOneOut,\n",
    "    RepeatedKFold,\n",
    "    StratifiedKFold,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.utils import parallel_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argparser = argparse.ArgumentParser()\n",
    "argparser.add_argument(\"--cell_type\", default=\"all\")\n",
    "argparser.add_argument(\"--shuffle\", default=\"False\")\n",
    "argparser.add_argument(\"--cytokine\", default=\"all\")\n",
    "\n",
    "args = argparser.parse_args()\n",
    "\n",
    "cell_type = args.cell_type\n",
    "shuffle = ast.literal_eval(args.shuffle)\n",
    "cytokine = args.cytokine\n",
    "print(cell_type, shuffle, cytokine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "aggregation = True\n",
    "nomic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set shuffle value\n",
    "if shuffle == True:\n",
    "    shuffle = \"shuffled_baseline\"\n",
    "else:\n",
    "    shuffle = \"final\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPE = \"regression\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data from indexes and features dataframe\n",
    "data_split_path = pathlib.Path(\n",
    "    f\"../../0.split_data/indexes/{cell_type}/regression/aggregated_sc_and_nomic_data_split_indexes.tsv\"\n",
    ")\n",
    "data_path = pathlib.Path(\n",
    "    f\"../../../data/{cell_type}_preprocessed_sc_norm_aggregated.parquet\"\n",
    ")\n",
    "\n",
    "# dataframe with only the labeled data we want (exclude certain phenotypic classes)\n",
    "data_df = pd.read_parquet(data_path)\n",
    "\n",
    "data_split_indexes = pd.read_csv(data_split_path, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select tht indexes for the training and test set\n",
    "train_indexes = data_split_indexes.loc[data_split_indexes[\"label\"] == \"train\"]\n",
    "test_indexes = data_split_indexes.loc[data_split_indexes[\"label\"] == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset data_df by indexes in data_split_indexes\n",
    "training_data = data_df.loc[train_indexes[\"labeled_data_index\"]]\n",
    "testing_data = data_df.loc[test_indexes[\"labeled_data_index\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define metadata columns\n",
    "# subset each column that contains metadata\n",
    "metadata_train = training_data.filter(regex=\"Metadata\")\n",
    "# drop all metadata columns\n",
    "train_data_x = training_data.drop(metadata_train.columns, axis=1)\n",
    "train_treatments = training_data[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"]\n",
    "# get all columns that contain \"NSU\" in the column name\n",
    "train_data_y_cols = train_data_x.filter(regex=\"NSU\").columns\n",
    "train_data_y = training_data[train_data_y_cols]\n",
    "train_data_x = train_data_x.drop(train_data_y_cols, axis=1)\n",
    "\n",
    "\n",
    "# define metadata columns\n",
    "# subset each column that contains metadata\n",
    "metadata_test = testing_data.filter(regex=\"Metadata\")\n",
    "# drop all metadata columns\n",
    "test_data_x = testing_data.drop(metadata_test.columns, axis=1)\n",
    "test_treatments = testing_data[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"]\n",
    "# get all columns that contain \"NSU\" in the column name\n",
    "test_data_y_cols = test_data_x.filter(regex=\"NSU\").columns\n",
    "test_data_y = testing_data[test_data_y_cols]\n",
    "test_data_x = test_data_x.drop(test_data_y_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data_x.shape, train_data_y.shape, test_data_x.shape, test_data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model path from parameters\n",
    "if (aggregation == True) and (nomic == True):\n",
    "    model_path = pathlib.Path(f\"models/regression/{cell_type}/aggregated_with_nomic/\")\n",
    "elif (aggregation == True) and (nomic == False):\n",
    "    model_path = pathlib.Path(f\"models/regression/{cell_type}/aggregated/\")\n",
    "elif (aggregation == False) and (nomic == True):\n",
    "    model_path = pathlib.Path(f\"models/regression/{cell_type}/sc_with_nomic/\")\n",
    "elif (aggregation == False) and (nomic == False):\n",
    "    model_path = pathlib.Path(f\"models/regression/{cell_type}/sc/\")\n",
    "else:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    \"train_data\": {\n",
    "        \"data_x\": train_data_x,\n",
    "        \"data_y\": train_data_y,\n",
    "        \"col_names\": train_data_y_cols,\n",
    "        \"metadata\": metadata_train,\n",
    "    },\n",
    "    \"test_data\": {\n",
    "        \"data_x\": test_data_x,\n",
    "        \"data_y\": test_data_y,\n",
    "        \"col_names\": test_data_y_cols,\n",
    "        \"metadata\": metadata_test,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation method\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# lsit of metrics to use\n",
    "metrics = [\"explained_variance\", \"neg_mean_absolute_error\", \"neg_mean_squared_error\"]\n",
    "output_metric_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blank df for concatenated results\n",
    "results_df = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"explained_variance\",\n",
    "        \"neg_mean_absolute_error\",\n",
    "        \"neg_mean_squared_error\",\n",
    "        \"well\",\n",
    "        \"treatment\",\n",
    "        \"r2\",\n",
    "        \"cytokine\",\n",
    "        \"data_split\",\n",
    "        \"shuffle\",\n",
    "        \"predicted_value\",\n",
    "        \"actual_value\",\n",
    "        \"log10_neg_mean_absolute_error\",\n",
    "        \"log10_neg_mean_squared_error\",\n",
    "        \"log10_explained_variance\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_split in data_dict:\n",
    "    print(data_split)\n",
    "    for i in data_dict[data_split]:\n",
    "        print(i)\n",
    "        data_x = data_dict[data_split][\"data_x\"]\n",
    "        data_y = data_dict[data_split][\"data_y\"]\n",
    "        col_names = data_dict[data_split][\"col_names\"]\n",
    "        metadata = data_dict[data_split][\"metadata\"]\n",
    "    if shuffle == \"shuffled_baseline\":\n",
    "        model = joblib.load(\n",
    "            f\"../../1.train_models/{model_path}/{cytokine}_shuffled_baseline__all_nomic.joblib\"\n",
    "        )\n",
    "    elif shuffle == \"final\":\n",
    "        model = joblib.load(\n",
    "            f\"../../1.train_models/{model_path}/{cytokine}_final__all_nomic.joblib\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "\n",
    "    # get the cytokine column of choice\n",
    "    y_selected = data_y[cytokine]\n",
    "\n",
    "    if shuffle == \"shuffled_baseline\":\n",
    "        for column in data_x:\n",
    "            np.random.shuffle(data_x[column].values)\n",
    "\n",
    "    # get predictions\n",
    "    predictions = model.predict(data_x)\n",
    "    for metric in metrics:\n",
    "        scores = cross_val_score(\n",
    "            model, data_x, y_selected, scoring=metric, cv=loo, n_jobs=-1\n",
    "        )\n",
    "        output_metric_scores[metric] = scores\n",
    "    r2 = r2_score(y_selected, predictions)\n",
    "    output_metric_scores[\"treatment\"] = metadata[\n",
    "        \"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"\n",
    "    ]\n",
    "    output_metric_scores[\"well\"] = metadata[\"Metadata_Well\"]\n",
    "    df = pd.DataFrame.from_dict(output_metric_scores)\n",
    "    df[\"r2\"] = r2\n",
    "    df[\"cytokine\"] = cytokine\n",
    "    df[\"data_split\"] = data_split\n",
    "    df[\"shuffle\"] = shuffle\n",
    "    df[\"predicted_value\"] = predictions\n",
    "    df[\"actual_value\"] = y_selected\n",
    "    df[\"log10_neg_mean_absolute_error\"] = -np.log10(-df[\"neg_mean_absolute_error\"])\n",
    "    df[\"log10_neg_mean_squared_error\"] = -np.log10(-df[\"neg_mean_squared_error\"])\n",
    "    df[\"log10_explained_variance\"] = -np.log10(df[\"explained_variance\"])\n",
    "\n",
    "    # replace \"[NSU]\" with \"\"\"\n",
    "    df[\"cytokine\"] = df[\"cytokine\"].replace(\"[ \\[\\]NSU]\", \"\", regex=True)\n",
    "    df[\"cytokine\"] = df[\"cytokine\"].replace(\" \", \"_\", regex=True)\n",
    "\n",
    "    # concat the dataframes\n",
    "    results_df = pd.concat([results_df, df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_df = results_df.drop(\n",
    "    columns=[\n",
    "        \"explained_variance\",\n",
    "        \"neg_mean_absolute_error\",\n",
    "        \"neg_mean_squared_error\",\n",
    "        \"well\",\n",
    "        \"treatment\",\n",
    "        \"r2\",\n",
    "        \"log10_neg_mean_absolute_error\",\n",
    "        \"log10_neg_mean_squared_error\",\n",
    "        \"log10_explained_variance\",\n",
    "    ]\n",
    ")\n",
    "# calculate the variance of the actual and predicted values per cytokine\n",
    "var_df = var_df.groupby([\"cytokine\", \"data_split\", \"shuffle\"]).var()\n",
    "var_df = pd.merge(\n",
    "    var_df,\n",
    "    results_df.groupby([\"cytokine\", \"data_split\", \"shuffle\"]).r2.unique(),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")\n",
    "var_df.reset_index(inplace=True)\n",
    "var_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model path from parameters\n",
    "if (aggregation == True) and (nomic == True):\n",
    "    results_path = pathlib.Path(\n",
    "        f\"../results/regression/{cell_type}/aggregated_with_nomic/\"\n",
    "    )\n",
    "elif (aggregation == True) and (nomic == False):\n",
    "    results_path = pathlib.Path(f\"../results/regression/{cell_type}/aggregated/\")\n",
    "elif (aggregation == False) and (nomic == True):\n",
    "    results_path = pathlib.Path(f\"../results/regression/{cell_type}/sc_with_nomic/\")\n",
    "elif (aggregation == False) and (nomic == False):\n",
    "    results_path = pathlib.Path(f\"../results/regression/{cell_type}/sc/\")\n",
    "else:\n",
    "    print(\"Error\")\n",
    "pathlib.Path(results_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the model training metrics file exists\n",
    "metrics_file = pathlib.Path(f\"{results_path}/{cytokine}_{shuffle}_model_stats.csv\")\n",
    "\n",
    "results_df.to_csv(metrics_file, index=False)\n",
    "\n",
    "# do the same for the variance df\n",
    "# check if the model training metrics file exists\n",
    "metrics_file = pathlib.Path(\n",
    "    f\"{results_path}/{cytokine}_{shuffle}_variance_r2_stats.csv\"\n",
    ")\n",
    "var_df.to_csv(metrics_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,../scripts//py:percent"
  },
  "kernelspec": {
   "display_name": "Interstellar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
