{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import argparse\n",
                "import ast\n",
                "import itertools\n",
                "import pathlib\n",
                "import sys\n",
                "import warnings\n",
                "\n",
                "import joblib\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import pyarrow.parquet as pq\n",
                "\n",
                "# plot the predictions\n",
                "import seaborn as sns\n",
                "import toml\n",
                "from joblib import dump\n",
                "from sklearn.exceptions import ConvergenceWarning\n",
                "from sklearn.linear_model import ElasticNetCV, LogisticRegression, MultiTaskElasticNetCV\n",
                "\n",
                "# import mse\n",
                "from sklearn.metrics import mean_squared_error, r2_score\n",
                "\n",
                "# import RepeatedKFold\n",
                "from sklearn.model_selection import (\n",
                "    GridSearchCV,\n",
                "    LeaveOneOut,\n",
                "    RepeatedKFold,\n",
                "    StratifiedKFold,\n",
                "    cross_val_score,\n",
                "    train_test_split,\n",
                ")\n",
                "from sklearn.utils import parallel_backend"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "argparser = argparse.ArgumentParser()\n",
                "argparser.add_argument(\"--cell_type\", default=\"all\")\n",
                "argparser.add_argument(\"--shuffle\", default=\"False\")\n",
                "argparser.add_argument(\"--cytokine\", default=\"all\")\n",
                "\n",
                "args = argparser.parse_args()\n",
                "\n",
                "cell_type = args.cell_type\n",
                "shuffle = ast.literal_eval(args.shuffle)\n",
                "cytokine = args.cytokine\n",
                "print(cell_type, shuffle, cytokine)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Parameters\n",
                "aggregation = True\n",
                "nomic = True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "# set shuffle value\n",
                "if shuffle == True:\n",
                "    shuffle = \"shuffled_baseline\"\n",
                "else:\n",
                "    shuffle = \"final\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "MODEL_TYPE = \"regression\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load training data from indexes and features dataframe\n",
                "data_split_path = pathlib.Path(\n",
                "    f\"../../0.split_data/indexes/{cell_type}/regression/aggregated_sc_and_nomic_data_split_indexes.tsv\"\n",
                ")\n",
                "data_path = pathlib.Path(\n",
                "    f\"../../../data/{cell_type}_preprocessed_sc_norm_aggregated_nomic.parquet\"\n",
                ")\n",
                "\n",
                "# dataframe with only the labeled data we want (exclude certain phenotypic classes)\n",
                "data_df = pd.read_parquet(data_path)\n",
                "\n",
                "data_split_indexes = pd.read_csv(data_split_path, sep=\"\\t\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "# rename column that contain the treatment dose to be a metadata column\n",
                "data_df.rename(\n",
                "    columns={\n",
                "        \"oneb_Treatment_Dose_Inhibitor_Dose\": \"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"\n",
                "    },\n",
                "    inplace=True,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "# remove duplicate columns\n",
                "data_df = data_df.loc[:, ~data_df.columns.duplicated()]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "# select tht indexes for the training and test set\n",
                "train_indexes = data_split_indexes.loc[data_split_indexes[\"label\"] == \"train\"]\n",
                "test_indexes = data_split_indexes.loc[data_split_indexes[\"label\"] == \"test\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "# subset data_df by indexes in data_split_indexes\n",
                "training_data = data_df.loc[train_indexes[\"labeled_data_index\"]]\n",
                "testing_data = data_df.loc[test_indexes[\"labeled_data_index\"]]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "# define metadata columns\n",
                "# subset each column that contains metadata\n",
                "metadata_train = training_data.filter(regex=\"Metadata\")\n",
                "# drop all metadata columns\n",
                "train_data_x = training_data.drop(metadata_train.columns, axis=1)\n",
                "train_treatments = training_data[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"]\n",
                "# get all columns that contain \"NSU\" in the column name where NSU = normalized signal units\n",
                "train_data_y_cols = train_data_x.filter(regex=\"NSU\").columns\n",
                "train_data_y = training_data[train_data_y_cols]\n",
                "train_data_x = train_data_x.drop(train_data_y_cols, axis=1)\n",
                "\n",
                "\n",
                "# define metadata columns\n",
                "# subset each column that contains metadata\n",
                "metadata_test = testing_data.filter(regex=\"Metadata\")\n",
                "# drop all metadata columns\n",
                "test_data_x = testing_data.drop(metadata_test.columns, axis=1)\n",
                "test_treatments = testing_data[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"]\n",
                "# get all columns that contain \"NSU\" in the column name\n",
                "test_data_y_cols = test_data_x.filter(regex=\"NSU\").columns\n",
                "test_data_y = testing_data[test_data_y_cols]\n",
                "test_data_x = test_data_x.drop(test_data_y_cols, axis=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(71, 1199) (71, 187) (83, 1199) (83, 187)\n"
                    ]
                }
            ],
            "source": [
                "print(train_data_x.shape, train_data_y.shape, test_data_x.shape, test_data_y.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "# set model path from parameters\n",
                "if (aggregation == True) and (nomic == True):\n",
                "    model_path = pathlib.Path(f\"models/regression/{cell_type}/aggregated_with_nomic/\")\n",
                "elif (aggregation == True) and (nomic == False):\n",
                "    model_path = pathlib.Path(f\"models/regression/{cell_type}/aggregated/\")\n",
                "elif (aggregation == False) and (nomic == True):\n",
                "    model_path = pathlib.Path(f\"models/regression/{cell_type}/sc_with_nomic/\")\n",
                "elif (aggregation == False) and (nomic == False):\n",
                "    model_path = pathlib.Path(f\"models/regression/{cell_type}/sc/\")\n",
                "else:\n",
                "    print(\"Error\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_dict = {\n",
                "    \"train_data\": {\n",
                "        \"data_x\": train_data_x,\n",
                "        \"data_y\": train_data_y,\n",
                "        \"col_names\": train_data_y_cols,\n",
                "        \"metadata\": metadata_train,\n",
                "    },\n",
                "    \"test_data\": {\n",
                "        \"data_x\": test_data_x,\n",
                "        \"data_y\": test_data_y,\n",
                "        \"col_names\": test_data_y_cols,\n",
                "        \"metadata\": metadata_test,\n",
                "    },\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "# cross validation method\n",
                "loo = LeaveOneOut()\n",
                "\n",
                "# lsit of metrics to use\n",
                "metrics = [\"explained_variance\", \"neg_mean_absolute_error\", \"neg_mean_squared_error\"]\n",
                "output_metric_scores = {}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "# blank df for concatenated results\n",
                "results_df = pd.DataFrame(\n",
                "    columns=[\n",
                "        \"explained_variance\",\n",
                "        \"neg_mean_absolute_error\",\n",
                "        \"neg_mean_squared_error\",\n",
                "        \"well\",\n",
                "        \"treatment\",\n",
                "        \"r2\",\n",
                "        \"cytokine\",\n",
                "        \"data_split\",\n",
                "        \"shuffle\",\n",
                "        \"predicted_value\",\n",
                "        \"actual_value\",\n",
                "        \"log10_neg_mean_absolute_error\",\n",
                "        \"log10_neg_mean_squared_error\",\n",
                "        \"log10_explained_variance\",\n",
                "    ]\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "train_data\n",
                        "data_x\n",
                        "data_y\n",
                        "col_names\n",
                        "metadata\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/tmp/ipykernel_411610/413048810.py:55: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
                        "  results_df = pd.concat([results_df, df], axis=0)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "test_data\n",
                        "data_x\n",
                        "data_y\n",
                        "col_names\n",
                        "metadata\n"
                    ]
                }
            ],
            "source": [
                "for data_split in data_dict:\n",
                "    print(data_split)\n",
                "    for i in data_dict[data_split]:\n",
                "        print(i)\n",
                "        data_x = data_dict[data_split][\"data_x\"]\n",
                "        data_y = data_dict[data_split][\"data_y\"]\n",
                "        col_names = data_dict[data_split][\"col_names\"]\n",
                "        metadata = data_dict[data_split][\"metadata\"]\n",
                "    if shuffle == \"shuffled_baseline\":\n",
                "        model = joblib.load(\n",
                "            f\"../../1.train_models/{model_path}/{cytokine}_shuffled_baseline__all_nomic.joblib\"\n",
                "        )\n",
                "    elif shuffle == \"final\":\n",
                "        model = joblib.load(\n",
                "            f\"../../1.train_models/{model_path}/{cytokine}_final__all_nomic.joblib\"\n",
                "        )\n",
                "    else:\n",
                "        print(\"Error\")\n",
                "\n",
                "    # get the cytokine column of choice\n",
                "    y_selected = data_y[cytokine]\n",
                "\n",
                "    if shuffle == \"shuffled_baseline\":\n",
                "        for column in data_x:\n",
                "            np.random.shuffle(data_x[column].values)\n",
                "\n",
                "    # get predictions\n",
                "    predictions = model.predict(data_x)\n",
                "    for metric in metrics:\n",
                "        scores = cross_val_score(\n",
                "            model, data_x, y_selected, scoring=metric, cv=loo, n_jobs=-1\n",
                "        )\n",
                "        output_metric_scores[metric] = scores\n",
                "    r2 = r2_score(y_selected, predictions)\n",
                "    output_metric_scores[\"treatment\"] = metadata[\n",
                "        \"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"\n",
                "    ]\n",
                "    output_metric_scores[\"well\"] = metadata[\"Metadata_Well\"].values\n",
                "    df = pd.DataFrame.from_dict(output_metric_scores)\n",
                "    df[\"r2\"] = r2\n",
                "    df[\"cytokine\"] = cytokine\n",
                "    df[\"data_split\"] = data_split\n",
                "    df[\"shuffle\"] = shuffle\n",
                "    df[\"predicted_value\"] = predictions\n",
                "    df[\"actual_value\"] = y_selected\n",
                "    df[\"log10_neg_mean_absolute_error\"] = -np.log10(-df[\"neg_mean_absolute_error\"])\n",
                "    df[\"log10_neg_mean_squared_error\"] = -np.log10(-df[\"neg_mean_squared_error\"])\n",
                "    df[\"log10_explained_variance\"] = -np.log10(df[\"explained_variance\"])\n",
                "\n",
                "    # replace \"[NSU]\" with \"\"\"\n",
                "    df[\"cytokine\"] = df[\"cytokine\"].replace(\"[ \\[\\]NSU]\", \"\", regex=True)\n",
                "    df[\"cytokine\"] = df[\"cytokine\"].replace(\" \", \"_\", regex=True)\n",
                "\n",
                "    # concat the dataframes\n",
                "    results_df = pd.concat([results_df, df], axis=0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>explained_variance</th>\n",
                            "      <th>neg_mean_absolute_error</th>\n",
                            "      <th>neg_mean_squared_error</th>\n",
                            "      <th>well</th>\n",
                            "      <th>treatment</th>\n",
                            "      <th>r2</th>\n",
                            "      <th>cytokine</th>\n",
                            "      <th>data_split</th>\n",
                            "      <th>shuffle</th>\n",
                            "      <th>predicted_value</th>\n",
                            "      <th>actual_value</th>\n",
                            "      <th>log10_neg_mean_absolute_error</th>\n",
                            "      <th>log10_neg_mean_squared_error</th>\n",
                            "      <th>log10_explained_variance</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>1.0</td>\n",
                            "      <td>-0.113421</td>\n",
                            "      <td>-0.012864</td>\n",
                            "      <td>B07</td>\n",
                            "      <td>DMSO_0.100_%_DMSO_0.025_%</td>\n",
                            "      <td>0.924271</td>\n",
                            "      <td>ActivinA</td>\n",
                            "      <td>train_data</td>\n",
                            "      <td>final</td>\n",
                            "      <td>0.153476</td>\n",
                            "      <td>0.061116</td>\n",
                            "      <td>0.945307</td>\n",
                            "      <td>1.890614</td>\n",
                            "      <td>-0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>1.0</td>\n",
                            "      <td>-0.030575</td>\n",
                            "      <td>-0.000935</td>\n",
                            "      <td>B08</td>\n",
                            "      <td>LPS_0.010_ug_per_ml_DMSO_0.025_%</td>\n",
                            "      <td>0.924271</td>\n",
                            "      <td>ActivinA</td>\n",
                            "      <td>train_data</td>\n",
                            "      <td>final</td>\n",
                            "      <td>0.769626</td>\n",
                            "      <td>0.791261</td>\n",
                            "      <td>1.514631</td>\n",
                            "      <td>3.029261</td>\n",
                            "      <td>-0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>8</th>\n",
                            "      <td>1.0</td>\n",
                            "      <td>-0.256996</td>\n",
                            "      <td>-0.066047</td>\n",
                            "      <td>B10</td>\n",
                            "      <td>LPS_Nigericin_100.000_ug_per_ml_1.000_uM_DMSO_...</td>\n",
                            "      <td>0.924271</td>\n",
                            "      <td>ActivinA</td>\n",
                            "      <td>train_data</td>\n",
                            "      <td>final</td>\n",
                            "      <td>0.204514</td>\n",
                            "      <td>0.052033</td>\n",
                            "      <td>0.590073</td>\n",
                            "      <td>1.180147</td>\n",
                            "      <td>-0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9</th>\n",
                            "      <td>1.0</td>\n",
                            "      <td>-0.057875</td>\n",
                            "      <td>-0.003350</td>\n",
                            "      <td>B11</td>\n",
                            "      <td>LPS_Nigericin_100.000_ug_per_ml_1.000_uM_DMSO_...</td>\n",
                            "      <td>0.924271</td>\n",
                            "      <td>ActivinA</td>\n",
                            "      <td>train_data</td>\n",
                            "      <td>final</td>\n",
                            "      <td>0.104448</td>\n",
                            "      <td>0.078860</td>\n",
                            "      <td>1.237507</td>\n",
                            "      <td>2.475014</td>\n",
                            "      <td>-0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>10</th>\n",
                            "      <td>1.0</td>\n",
                            "      <td>-0.194871</td>\n",
                            "      <td>-0.037975</td>\n",
                            "      <td>B12</td>\n",
                            "      <td>Media</td>\n",
                            "      <td>0.924271</td>\n",
                            "      <td>ActivinA</td>\n",
                            "      <td>train_data</td>\n",
                            "      <td>final</td>\n",
                            "      <td>0.199688</td>\n",
                            "      <td>0.062455</td>\n",
                            "      <td>0.710254</td>\n",
                            "      <td>1.420508</td>\n",
                            "      <td>-0.0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "    explained_variance  neg_mean_absolute_error  neg_mean_squared_error well  \\\n",
                            "5                  1.0                -0.113421               -0.012864  B07   \n",
                            "6                  1.0                -0.030575               -0.000935  B08   \n",
                            "8                  1.0                -0.256996               -0.066047  B10   \n",
                            "9                  1.0                -0.057875               -0.003350  B11   \n",
                            "10                 1.0                -0.194871               -0.037975  B12   \n",
                            "\n",
                            "                                            treatment        r2  cytokine  \\\n",
                            "5                           DMSO_0.100_%_DMSO_0.025_%  0.924271  ActivinA   \n",
                            "6                    LPS_0.010_ug_per_ml_DMSO_0.025_%  0.924271  ActivinA   \n",
                            "8   LPS_Nigericin_100.000_ug_per_ml_1.000_uM_DMSO_...  0.924271  ActivinA   \n",
                            "9   LPS_Nigericin_100.000_ug_per_ml_1.000_uM_DMSO_...  0.924271  ActivinA   \n",
                            "10                                              Media  0.924271  ActivinA   \n",
                            "\n",
                            "    data_split shuffle  predicted_value  actual_value  \\\n",
                            "5   train_data   final         0.153476      0.061116   \n",
                            "6   train_data   final         0.769626      0.791261   \n",
                            "8   train_data   final         0.204514      0.052033   \n",
                            "9   train_data   final         0.104448      0.078860   \n",
                            "10  train_data   final         0.199688      0.062455   \n",
                            "\n",
                            "    log10_neg_mean_absolute_error  log10_neg_mean_squared_error  \\\n",
                            "5                        0.945307                      1.890614   \n",
                            "6                        1.514631                      3.029261   \n",
                            "8                        0.590073                      1.180147   \n",
                            "9                        1.237507                      2.475014   \n",
                            "10                       0.710254                      1.420508   \n",
                            "\n",
                            "    log10_explained_variance  \n",
                            "5                       -0.0  \n",
                            "6                       -0.0  \n",
                            "8                       -0.0  \n",
                            "9                       -0.0  \n",
                            "10                      -0.0  "
                        ]
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "results_df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>cytokine</th>\n",
                            "      <th>data_split</th>\n",
                            "      <th>shuffle</th>\n",
                            "      <th>predicted_value</th>\n",
                            "      <th>actual_value</th>\n",
                            "      <th>r2</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>ActivinA</td>\n",
                            "      <td>test_data</td>\n",
                            "      <td>final</td>\n",
                            "      <td>0.070876</td>\n",
                            "      <td>0.088847</td>\n",
                            "      <td>[0.8640594228782839]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>ActivinA</td>\n",
                            "      <td>train_data</td>\n",
                            "      <td>final</td>\n",
                            "      <td>0.047436</td>\n",
                            "      <td>0.056173</td>\n",
                            "      <td>[0.9242714043764793]</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   cytokine  data_split shuffle  predicted_value  actual_value  \\\n",
                            "0  ActivinA   test_data   final         0.070876      0.088847   \n",
                            "1  ActivinA  train_data   final         0.047436      0.056173   \n",
                            "\n",
                            "                     r2  \n",
                            "0  [0.8640594228782839]  \n",
                            "1  [0.9242714043764793]  "
                        ]
                    },
                    "execution_count": 20,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "var_df = results_df.drop(\n",
                "    columns=[\n",
                "        \"explained_variance\",\n",
                "        \"neg_mean_absolute_error\",\n",
                "        \"neg_mean_squared_error\",\n",
                "        \"well\",\n",
                "        \"treatment\",\n",
                "        \"r2\",\n",
                "        \"log10_neg_mean_absolute_error\",\n",
                "        \"log10_neg_mean_squared_error\",\n",
                "        \"log10_explained_variance\",\n",
                "    ]\n",
                ")\n",
                "# calculate the variance of the actual and predicted values per cytokine\n",
                "var_df = var_df.groupby([\"cytokine\", \"data_split\", \"shuffle\"]).var()\n",
                "var_df = pd.merge(\n",
                "    var_df,\n",
                "    results_df.groupby([\"cytokine\", \"data_split\", \"shuffle\"]).r2.unique(),\n",
                "    left_index=True,\n",
                "    right_index=True,\n",
                ")\n",
                "var_df.reset_index(inplace=True)\n",
                "var_df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "# set model path from parameters\n",
                "if (aggregation == True) and (nomic == True):\n",
                "    results_path = pathlib.Path(\n",
                "        f\"../results/regression/{cell_type}/aggregated_with_nomic/\"\n",
                "    )\n",
                "elif (aggregation == True) and (nomic == False):\n",
                "    results_path = pathlib.Path(f\"../results/regression/{cell_type}/aggregated/\")\n",
                "elif (aggregation == False) and (nomic == True):\n",
                "    results_path = pathlib.Path(f\"../results/regression/{cell_type}/sc_with_nomic/\")\n",
                "elif (aggregation == False) and (nomic == False):\n",
                "    results_path = pathlib.Path(f\"../results/regression/{cell_type}/sc/\")\n",
                "else:\n",
                "    print(\"Error\")\n",
                "pathlib.Path(results_path).mkdir(parents=True, exist_ok=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": [
                "# check if the model training metrics file exists\n",
                "metrics_file = pathlib.Path(f\"{results_path}/{cytokine}_{shuffle}_model_stats.csv\")\n",
                "\n",
                "results_df.to_csv(metrics_file, index=False)\n",
                "\n",
                "# do the same for the variance df\n",
                "# check if the model training metrics file exists\n",
                "metrics_file = pathlib.Path(\n",
                "    f\"{results_path}/{cytokine}_{shuffle}_variance_r2_stats.csv\"\n",
                ")\n",
                "var_df.to_csv(metrics_file, index=False)"
            ]
        }
    ],
    "metadata": {
        "jupytext": {
            "formats": "ipynb,../scripts//py:percent"
        },
        "kernelspec": {
            "display_name": "Interstellar",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
