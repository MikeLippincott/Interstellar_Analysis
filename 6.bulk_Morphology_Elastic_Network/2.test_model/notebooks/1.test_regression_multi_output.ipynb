{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import argparse\n",
                "import ast\n",
                "import itertools\n",
                "import pathlib\n",
                "import sys\n",
                "import warnings\n",
                "\n",
                "import joblib\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import pyarrow.parquet as pq\n",
                "\n",
                "# plot the predictions\n",
                "import seaborn as sns\n",
                "import toml\n",
                "from joblib import dump\n",
                "from sklearn.exceptions import ConvergenceWarning\n",
                "from sklearn.linear_model import ElasticNetCV, LogisticRegression, MultiTaskElasticNetCV\n",
                "\n",
                "# import mse\n",
                "from sklearn.metrics import mean_squared_error, r2_score\n",
                "\n",
                "# import RepeatedKFold\n",
                "from sklearn.model_selection import (\n",
                "    GridSearchCV,\n",
                "    LeaveOneOut,\n",
                "    RepeatedKFold,\n",
                "    StratifiedKFold,\n",
                "    cross_val_score,\n",
                "    train_test_split,\n",
                ")\n",
                "from sklearn.utils import parallel_backend"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "argparser = argparse.ArgumentParser()\n",
                "argparser.add_argument(\"--cell_type\", default=\"all\")\n",
                "argparser.add_argument(\"--shuffle\", default=\"False\")\n",
                "argparser.add_argument(\"--cytokine\", default=\"all\")\n",
                "\n",
                "args = argparser.parse_args()\n",
                "\n",
                "cell_type = args.cell_type\n",
                "shuffle = ast.literal_eval(args.shuffle)\n",
                "cytokine = args.cytokine\n",
                "print(cell_type, shuffle, cytokine)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Parameters\n",
                "aggregation = True\n",
                "nomic = True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "# set shuffle value\n",
                "if shuffle == True:\n",
                "    shuffle = \"shuffled_baseline\"\n",
                "else:\n",
                "    shuffle = \"final\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "MODEL_TYPE = \"regression\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load training data from indexes and features dataframe\n",
                "data_split_path = pathlib.Path(\n",
                "    f\"../../0.split_data/indexes/{cell_type}/regression/aggregated_sc_and_nomic_data_split_indexes.tsv\"\n",
                ")\n",
                "data_path = pathlib.Path(\n",
                "    f\"../../../data/{cell_type}_preprocessed_sc_norm_aggregated.parquet\"\n",
                ")\n",
                "\n",
                "# dataframe with only the labeled data we want (exclude certain phenotypic classes)\n",
                "data_df = pd.read_parquet(data_path)\n",
                "\n",
                "data_split_indexes = pd.read_csv(data_split_path, sep=\"\\t\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "# select tht indexes for the training and test set\n",
                "train_indexes = data_split_indexes.loc[data_split_indexes[\"label\"] == \"train\"]\n",
                "test_indexes = data_split_indexes.loc[data_split_indexes[\"label\"] == \"test\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "# subset data_df by indexes in data_split_indexes\n",
                "training_data = data_df.loc[train_indexes[\"labeled_data_index\"]]\n",
                "testing_data = data_df.loc[test_indexes[\"labeled_data_index\"]]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "# define metadata columns\n",
                "# subset each column that contains metadata\n",
                "metadata_train = training_data.filter(regex=\"Metadata\")\n",
                "# drop all metadata columns\n",
                "train_data_x = training_data.drop(metadata_train.columns, axis=1)\n",
                "train_treatments = training_data[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"]\n",
                "# get all columns that contain \"NSU\" in the column name\n",
                "train_data_y_cols = train_data_x.filter(regex=\"NSU\").columns\n",
                "train_data_y = training_data[train_data_y_cols]\n",
                "train_data_x = train_data_x.drop(train_data_y_cols, axis=1)\n",
                "\n",
                "\n",
                "# define metadata columns\n",
                "# subset each column that contains metadata\n",
                "metadata_test = testing_data.filter(regex=\"Metadata\")\n",
                "# drop all metadata columns\n",
                "test_data_x = testing_data.drop(metadata_test.columns, axis=1)\n",
                "test_treatments = testing_data[\"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"]\n",
                "# get all columns that contain \"NSU\" in the column name\n",
                "test_data_y_cols = test_data_x.filter(regex=\"NSU\").columns\n",
                "test_data_y = testing_data[test_data_y_cols]\n",
                "test_data_x = test_data_x.drop(test_data_y_cols, axis=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(70, 1251) (70, 0) (82, 1251) (82, 0)\n"
                    ]
                }
            ],
            "source": [
                "print(train_data_x.shape, train_data_y.shape, test_data_x.shape, test_data_y.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "# set model path from parameters\n",
                "if (aggregation == True) and (nomic == True):\n",
                "    model_path = pathlib.Path(f\"models/regression/{cell_type}/aggregated_with_nomic/\")\n",
                "elif (aggregation == True) and (nomic == False):\n",
                "    model_path = pathlib.Path(f\"models/regression/{cell_type}/aggregated/\")\n",
                "elif (aggregation == False) and (nomic == True):\n",
                "    model_path = pathlib.Path(f\"models/regression/{cell_type}/sc_with_nomic/\")\n",
                "elif (aggregation == False) and (nomic == False):\n",
                "    model_path = pathlib.Path(f\"models/regression/{cell_type}/sc/\")\n",
                "else:\n",
                "    print(\"Error\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_dict = {\n",
                "    \"train_data\": {\n",
                "        \"data_x\": train_data_x,\n",
                "        \"data_y\": train_data_y,\n",
                "        \"col_names\": train_data_y_cols,\n",
                "        \"metadata\": metadata_train,\n",
                "    },\n",
                "    \"test_data\": {\n",
                "        \"data_x\": test_data_x,\n",
                "        \"data_y\": test_data_y,\n",
                "        \"col_names\": test_data_y_cols,\n",
                "        \"metadata\": metadata_test,\n",
                "    },\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "# cross validation method\n",
                "loo = LeaveOneOut()\n",
                "\n",
                "# lsit of metrics to use\n",
                "metrics = [\"explained_variance\", \"neg_mean_absolute_error\", \"neg_mean_squared_error\"]\n",
                "output_metric_scores = {}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "# blank df for concatenated results\n",
                "results_df = pd.DataFrame(\n",
                "    columns=[\n",
                "        \"explained_variance\",\n",
                "        \"neg_mean_absolute_error\",\n",
                "        \"neg_mean_squared_error\",\n",
                "        \"well\",\n",
                "        \"treatment\",\n",
                "        \"r2\",\n",
                "        \"cytokine\",\n",
                "        \"data_split\",\n",
                "        \"shuffle\",\n",
                "        \"predicted_value\",\n",
                "        \"actual_value\",\n",
                "        \"log10_neg_mean_absolute_error\",\n",
                "        \"log10_neg_mean_squared_error\",\n",
                "        \"log10_explained_variance\",\n",
                "    ]\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "train_data\n",
                        "data_x\n",
                        "data_y\n",
                        "col_names\n",
                        "metadata\n"
                    ]
                },
                {
                    "ename": "NameError",
                    "evalue": "name 'cytokine' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[1;32m/home/lippincm/Documents/ML/Interstellar_Analysis/6.bulk_Morphology_Elastic_Network/2.test_model/notebooks/1.test_regression_multi_output.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.13.161.59/home/lippincm/Documents/ML/Interstellar_Analysis/6.bulk_Morphology_Elastic_Network/2.test_model/notebooks/1.test_regression_multi_output.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     model \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39mload(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.13.161.59/home/lippincm/Documents/ML/Interstellar_Analysis/6.bulk_Morphology_Elastic_Network/2.test_model/notebooks/1.test_regression_multi_output.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m../../1.train_models/\u001b[39m\u001b[39m{\u001b[39;00mmodel_path\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mcytokine\u001b[39m}\u001b[39;00m\u001b[39m_shuffled_baseline__all_nomic.joblib\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.13.161.59/home/lippincm/Documents/ML/Interstellar_Analysis/6.bulk_Morphology_Elastic_Network/2.test_model/notebooks/1.test_regression_multi_output.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.13.161.59/home/lippincm/Documents/ML/Interstellar_Analysis/6.bulk_Morphology_Elastic_Network/2.test_model/notebooks/1.test_regression_multi_output.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39melif\u001b[39;00m shuffle \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfinal\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.13.161.59/home/lippincm/Documents/ML/Interstellar_Analysis/6.bulk_Morphology_Elastic_Network/2.test_model/notebooks/1.test_regression_multi_output.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     model \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39mload(\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.13.161.59/home/lippincm/Documents/ML/Interstellar_Analysis/6.bulk_Morphology_Elastic_Network/2.test_model/notebooks/1.test_regression_multi_output.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m../../1.train_models/\u001b[39m\u001b[39m{\u001b[39;00mmodel_path\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mcytokine\u001b[39m}\u001b[39;00m\u001b[39m_final__all_nomic.joblib\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.13.161.59/home/lippincm/Documents/ML/Interstellar_Analysis/6.bulk_Morphology_Elastic_Network/2.test_model/notebooks/1.test_regression_multi_output.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.13.161.59/home/lippincm/Documents/ML/Interstellar_Analysis/6.bulk_Morphology_Elastic_Network/2.test_model/notebooks/1.test_regression_multi_output.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.13.161.59/home/lippincm/Documents/ML/Interstellar_Analysis/6.bulk_Morphology_Elastic_Network/2.test_model/notebooks/1.test_regression_multi_output.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mError\u001b[39m\u001b[39m\"\u001b[39m)\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'cytokine' is not defined"
                    ]
                }
            ],
            "source": [
                "for data_split in data_dict:\n",
                "    print(data_split)\n",
                "    for i in data_dict[data_split]:\n",
                "        print(i)\n",
                "        data_x = data_dict[data_split][\"data_x\"]\n",
                "        data_y = data_dict[data_split][\"data_y\"]\n",
                "        col_names = data_dict[data_split][\"col_names\"]\n",
                "        metadata = data_dict[data_split][\"metadata\"]\n",
                "    if shuffle == \"shuffled_baseline\":\n",
                "        model = joblib.load(\n",
                "            f\"../../1.train_models/{model_path}/{cytokine}_shuffled_baseline__all_nomic.joblib\"\n",
                "        )\n",
                "    elif shuffle == \"final\":\n",
                "        model = joblib.load(\n",
                "            f\"../../1.train_models/{model_path}/{cytokine}_final__all_nomic.joblib\"\n",
                "        )\n",
                "    else:\n",
                "        print(\"Error\")\n",
                "\n",
                "    # get the cytokine column of choice\n",
                "    y_selected = data_y[cytokine]\n",
                "\n",
                "    if shuffle == \"shuffled_baseline\":\n",
                "        for column in data_x:\n",
                "            np.random.shuffle(data_x[column].values)\n",
                "\n",
                "    # get predictions\n",
                "    predictions = model.predict(data_x)\n",
                "    for metric in metrics:\n",
                "        scores = cross_val_score(\n",
                "            model, data_x, y_selected, scoring=metric, cv=loo, n_jobs=-1\n",
                "        )\n",
                "        output_metric_scores[metric] = scores\n",
                "    r2 = r2_score(y_selected, predictions)\n",
                "    output_metric_scores[\"treatment\"] = metadata[\n",
                "        \"oneb_Metadata_Treatment_Dose_Inhibitor_Dose\"\n",
                "    ]\n",
                "    output_metric_scores[\"well\"] = metadata[\"Metadata_Well\"]\n",
                "    df = pd.DataFrame.from_dict(output_metric_scores)\n",
                "    df[\"r2\"] = r2\n",
                "    df[\"cytokine\"] = cytokine\n",
                "    df[\"data_split\"] = data_split\n",
                "    df[\"shuffle\"] = shuffle\n",
                "    df[\"predicted_value\"] = predictions\n",
                "    df[\"actual_value\"] = y_selected\n",
                "    df[\"log10_neg_mean_absolute_error\"] = -np.log10(-df[\"neg_mean_absolute_error\"])\n",
                "    df[\"log10_neg_mean_squared_error\"] = -np.log10(-df[\"neg_mean_squared_error\"])\n",
                "    df[\"log10_explained_variance\"] = -np.log10(df[\"explained_variance\"])\n",
                "\n",
                "    # replace \"[NSU]\" with \"\"\"\n",
                "    df[\"cytokine\"] = df[\"cytokine\"].replace(\"[ \\[\\]NSU]\", \"\", regex=True)\n",
                "    df[\"cytokine\"] = df[\"cytokine\"].replace(\" \", \"_\", regex=True)\n",
                "\n",
                "    # concat the dataframes\n",
                "    results_df = pd.concat([results_df, df], axis=0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>explained_variance</th>\n",
                            "      <th>neg_mean_absolute_error</th>\n",
                            "      <th>neg_mean_squared_error</th>\n",
                            "      <th>well</th>\n",
                            "      <th>treatment</th>\n",
                            "      <th>r2</th>\n",
                            "      <th>cytokine</th>\n",
                            "      <th>data_split</th>\n",
                            "      <th>shuffle</th>\n",
                            "      <th>predicted_value</th>\n",
                            "      <th>actual_value</th>\n",
                            "      <th>log10_neg_mean_absolute_error</th>\n",
                            "      <th>log10_neg_mean_squared_error</th>\n",
                            "      <th>log10_explained_variance</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "Empty DataFrame\n",
                            "Columns: [explained_variance, neg_mean_absolute_error, neg_mean_squared_error, well, treatment, r2, cytokine, data_split, shuffle, predicted_value, actual_value, log10_neg_mean_absolute_error, log10_neg_mean_squared_error, log10_explained_variance]\n",
                            "Index: []"
                        ]
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "results_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "var_df = results_df.drop(\n",
                "    columns=[\n",
                "        \"explained_variance\",\n",
                "        \"neg_mean_absolute_error\",\n",
                "        \"neg_mean_squared_error\",\n",
                "        \"well\",\n",
                "        \"treatment\",\n",
                "        \"r2\",\n",
                "        \"log10_neg_mean_absolute_error\",\n",
                "        \"log10_neg_mean_squared_error\",\n",
                "        \"log10_explained_variance\",\n",
                "    ]\n",
                ")\n",
                "# calculate the variance of the actual and predicted values per cytokine\n",
                "var_df = var_df.groupby([\"cytokine\", \"data_split\", \"shuffle\"]).var()\n",
                "var_df = pd.merge(\n",
                "    var_df,\n",
                "    results_df.groupby([\"cytokine\", \"data_split\", \"shuffle\"]).r2.unique(),\n",
                "    left_index=True,\n",
                "    right_index=True,\n",
                ")\n",
                "var_df.reset_index(inplace=True)\n",
                "var_df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# set model path from parameters\n",
                "if (aggregation == True) and (nomic == True):\n",
                "    results_path = pathlib.Path(\n",
                "        f\"../results/regression/{cell_type}/aggregated_with_nomic/\"\n",
                "    )\n",
                "elif (aggregation == True) and (nomic == False):\n",
                "    results_path = pathlib.Path(f\"../results/regression/{cell_type}/aggregated/\")\n",
                "elif (aggregation == False) and (nomic == True):\n",
                "    results_path = pathlib.Path(f\"../results/regression/{cell_type}/sc_with_nomic/\")\n",
                "elif (aggregation == False) and (nomic == False):\n",
                "    results_path = pathlib.Path(f\"../results/regression/{cell_type}/sc/\")\n",
                "else:\n",
                "    print(\"Error\")\n",
                "pathlib.Path(results_path).mkdir(parents=True, exist_ok=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# check if the model training metrics file exists\n",
                "metrics_file = pathlib.Path(f\"{results_path}/{cytokine}_{shuffle}_model_stats.csv\")\n",
                "\n",
                "results_df.to_csv(metrics_file, index=False)\n",
                "\n",
                "# do the same for the variance df\n",
                "# check if the model training metrics file exists\n",
                "metrics_file = pathlib.Path(\n",
                "    f\"{results_path}/{cytokine}_{shuffle}_variance_r2_stats.csv\"\n",
                ")\n",
                "var_df.to_csv(metrics_file, index=False)"
            ]
        }
    ],
    "metadata": {
        "jupytext": {
            "formats": "ipynb,../scripts//py:percent"
        },
        "kernelspec": {
            "display_name": "Interstellar",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
